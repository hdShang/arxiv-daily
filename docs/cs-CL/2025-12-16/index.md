---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€»ï¼ˆwith DeepSeekï¼‰ - cs.CL - 2025-12-16
---

# cs.CLï¼ˆ2025-12-16ï¼‰

ğŸ“Š å…± **15** ç¯‡è®ºæ–‡
 | ğŸ”— **1** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#è§†è§‰é‡Œç¨‹è®¡" class="interest-badge">è§†è§‰é‡Œç¨‹è®¡ (7)</a>
<a href="#å¼ºåŒ–å­¦ä¹ " class="interest-badge">å¼ºåŒ–å­¦ä¹  (7)</a>
<a href="#äººå½¢æœºå™¨äºº" class="interest-badge">äººå½¢æœºå™¨äºº (1 ğŸ”—1)</a>
</div>

---


<h2 id="è§†è§‰é‡Œç¨‹è®¡">ğŸ”¬ è§†è§‰é‡Œç¨‹è®¡ (7 ç¯‡)</h2>

| # | é¢˜ç›® | ä¸€å¥è¯è¦ç‚¹ | ğŸ”— |
|---:|---|---|:---:|
| 1 | [MMGR: Multi-Modal Generative Reasoning](./papers/251214691v1-mmgr-multi-modal-generative-reasoning.html) | æå‡ºMMGRå¤šæ¨¡æ€ç”Ÿæˆæ¨ç†è¯„ä¼°æ¡†æ¶ï¼Œä»¥è§£å†³è§†é¢‘åŸºç¡€æ¨¡å‹åœ¨ç‰©ç†ã€é€»è¾‘å’Œç©ºé—´çº¦æŸä¸Šçš„æ¨ç†èƒ½åŠ›ä¸è¶³é—®é¢˜ã€‚ |  |
| 2 | [C-ing Clearly: Enhanced Binary Code Explanations using C code](./papers/251214500v1-c-ing-clearly-enhanced-binary-code-explanations-using-c-code.html) | æå‡ºC-ing Clearlyæ–¹æ³•ï¼Œåˆ©ç”¨Cä»£ç å¢å¼ºå¤§è¯­è¨€æ¨¡å‹å¯¹æ±‡ç¼–çš„ç†è§£ï¼Œä»¥è§£å†³äºŒè¿›åˆ¶ä»£ç åˆ†æä»»åŠ¡æ€§èƒ½ä¸è¶³çš„é—®é¢˜ã€‚ |  |
| 3 | [Polypersona: Persona-Grounded LLM for Synthetic Survey Responses](./papers/251214562v1-polypersona-persona-grounded-llm-for-synthetic-survey-responses.html) | æå‡ºPolyPersonaæ¡†æ¶ï¼Œé€šè¿‡è§’è‰²æ¡ä»¶åŒ–å¾®è°ƒå°å‹è¯­è¨€æ¨¡å‹ï¼Œé«˜æ•ˆç”Ÿæˆå¤šé¢†åŸŸåˆæˆè°ƒæŸ¥æ•°æ®ã€‚ |  |
| 4 | [Effect of Document Packing on the Latent Multi-Hop Reasoning Capabilities of Large Language Models](./papers/251214427v1-effect-of-document-packing-on-the-latent-multi-hop-reasoning-capabil.html) | ç ”ç©¶æ–‡æ¡£æ‰“åŒ…ç­–ç•¥å¯¹å¤§å‹è¯­è¨€æ¨¡å‹æ½œåœ¨å¤šè·³æ¨ç†èƒ½åŠ›çš„å½±å“ï¼Œä»¥ä¼˜åŒ–è®­ç»ƒæ•ˆç‡ä¸æ€§èƒ½ |  |
| 5 | [Step-Tagging: Toward controlling the generation of Language Reasoning Models through step monitoring](./papers/251214332v1-step-tagging-toward-controlling-the-generation-of-language-reasoning.html) | æå‡ºStep-Taggingæ¡†æ¶ï¼Œé€šè¿‡å®æ—¶ç›‘æ§æ¨ç†æ­¥éª¤ç±»å‹æ¥æ§åˆ¶è¯­è¨€æ¨ç†æ¨¡å‹çš„ç”Ÿæˆè¿‡ç¨‹ |  |
| 6 | [JMMMU-Pro: Image-based Japanese Multi-discipline Multimodal Understanding Benchmark via Vibe Benchmark Construction](./papers/251214620v1-jmmmu-pro-image-based-japanese-multi-discipline-multimodal-understan.html) | æå‡ºJMMMU-ProåŸºå‡†å’ŒVibe Benchmark Constructionæ–¹æ³•ï¼Œä»¥ä½æˆæœ¬æ„å»ºé«˜è´¨é‡æ—¥è¯­å¤šå­¦ç§‘å¤šæ¨¡æ€ç†è§£è¯„ä¼°å·¥å…· |  |
| 7 | [Efficient-DLM: From Autoregressive to Diffusion Language Models, and Beyond in Speed](./papers/251214067v1-efficient-dlm-from-autoregressive-to-diffusion-language-models-and-b.html) | æå‡ºEfficient-DLMæ¡†æ¶ï¼Œé€šè¿‡æ”¹è¿›AR-to-dLMè½¬æ¢æ–¹æ³•ï¼Œå®ç°é«˜æ•ˆæ‰©æ•£è¯­è¨€æ¨¡å‹ï¼Œåœ¨ä¿æŒä»»åŠ¡å‡†ç¡®æ€§çš„åŒæ—¶æå‡ç”Ÿæˆé€Ÿåº¦ã€‚ |  |


<h2 id="å¼ºåŒ–å­¦ä¹ ">ğŸ”¬ å¼ºåŒ–å­¦ä¹  (7 ç¯‡)</h2>

| # | é¢˜ç›® | ä¸€å¥è¯è¦ç‚¹ | ğŸ”— |
|---:|---|---|:---:|
| 8 | [VLegal-Bench: Cognitively Grounded Benchmark for Vietnamese Legal Reasoning of Large Language Models](./papers/251214554v1-vlegal-bench-cognitively-grounded-benchmark-for-vietnamese-legal-rea.html) | æå‡ºVLegal-BenchåŸºå‡†ä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹åœ¨è¶Šå—æ³•å¾‹æ¨ç†è¯„ä¼°ä¸­çš„æ ‡å‡†åŒ–ä¸è®¤çŸ¥æ·±åº¦ä¸è¶³é—®é¢˜ |  |
| 9 | [TiME: Tiny Monolingual Encoders for Efficient NLP Pipelines](./papers/251214645v1-time-tiny-monolingual-encoders-for-efficient-nlp-pipelines.html) | æå‡ºTiMEå°è§„æ¨¡å•è¯­ç¼–ç å™¨ï¼Œé€šè¿‡è’¸é¦è®­ç»ƒå®ç°é«˜æ•ˆNLPæµæ°´çº¿ï¼Œè§£å†³å¤§æ¨¡å‹åœ¨å®æ—¶å¤„ç†ä¸èƒ½æ•ˆæ–¹é¢çš„ä¸è¶³ã€‚ |  |
| 10 | [Dual Language Models: Balancing Training Efficiency and Overfitting Resilience](./papers/251214549v1-dual-language-models-balancing-training-efficiency-and-overfitting-r.html) | æå‡ºåŒç›®æ ‡è®­ç»ƒæ–¹æ³•ä»¥å¹³è¡¡è¯­è¨€æ¨¡å‹çš„è®­ç»ƒæ•ˆç‡ä¸è¿‡æ‹Ÿåˆé²æ£’æ€§ |  |
| 11 | [SASQ: Static Activation Scaling for Quantization-Aware Training in Large Language Models](./papers/251214481v1-sasq-static-activation-scaling-for-quantization-aware-training-in-la.html) | æå‡ºSASQæ¡†æ¶ä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹é‡åŒ–è®­ç»ƒä¸­æ¿€æ´»é‡åŒ–å› å­çš„ä¼˜åŒ–é—®é¢˜ï¼Œå®ç°é«˜æ•ˆé™æ€æ¨ç†ã€‚ |  |
| 12 | [From Context to EDUs: Faithful and Structured Context Compression via Elementary Discourse Unit Decomposition](./papers/251214244v1-from-context-to-edus-faithful-and-structured-context-compression-via.html) | æå‡ºåŸºäºåŸºæœ¬è¯è¯­å•å…ƒçš„ä¸Šä¸‹æ–‡å‹ç¼©æ¡†æ¶ï¼Œé€šè¿‡ç»“æ„åŒ–åˆ†è§£ä¸é€‰æ‹©è§£å†³é•¿æ–‡æœ¬å¤„ç†ä¸­çš„è®¡ç®—æˆæœ¬ä¸å™ªå£°é—®é¢˜ã€‚ |  |
| 13 | [Ladder Up, Memory Down: Low-Cost Fine-Tuning With Side Nets](./papers/251214237v1-ladder-up-memory-down-low-cost-fine-tuning-with-side-nets.html) | æå‡ºLadder Side Tuningæ–¹æ³•ï¼Œé€šè¿‡è½»é‡çº§ä¾§ç½‘ç»œè§£å†³å¤§è¯­è¨€æ¨¡å‹å¾®è°ƒä¸­çš„å†…å­˜ç“¶é¢ˆé—®é¢˜ã€‚ |  |
| 14 | [Scalable Frameworks for Real-World Audio-Visual Speech Recognition](./papers/251214083v1-scalable-frameworks-for-real-world-audio-visual-speech-recognition.html) | æå‡ºåˆ†å±‚å¯æ‰©å±•æ¡†æ¶ä»¥è§£å†³çœŸå®ä¸–ç•ŒéŸ³é¢‘-è§†è§‰è¯­éŸ³è¯†åˆ«ä¸­çš„é²æ£’æ€§é—®é¢˜ |  |


<h2 id="äººå½¢æœºå™¨äºº">ğŸ”¬ äººå½¢æœºå™¨äºº (1 ç¯‡)</h2>

| # | é¢˜ç›® | ä¸€å¥è¯è¦ç‚¹ | ğŸ”— |
|---:|---|---|:---:|
| 15 | [Low-Resource, High-Impact: Building Corpora for Inclusive Language Technologies](./papers/251214576v1-low-resource-high-impact-building-corpora-for-inclusive-language-tec.html) | æå‡ºä½èµ„æºè¯­è¨€NLPæ•™ç¨‹ï¼Œé€šè¿‡ç«¯åˆ°ç«¯æµç¨‹è§£å†³æ•°æ®ç¨€ç¼ºä¸æ–‡åŒ–å·®å¼‚é—®é¢˜ï¼Œä¿ƒè¿›åŒ…å®¹æ€§è¯­è¨€æŠ€æœ¯å‘å±•ã€‚ | âœ… |


[â¬…ï¸ è¿”å› cs.CL é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)