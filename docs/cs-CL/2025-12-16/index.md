---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€»ï¼ˆwith DeepSeekï¼‰ - cs.CL - 2025-12-16
---

# cs.CLï¼ˆ2025-12-16ï¼‰

ğŸ“Š å…± **18** ç¯‡è®ºæ–‡
 | ğŸ”— **3** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#å¼ºåŒ–å­¦ä¹ ä¸æ¨¡ä»¿å­¦ä¹ -rl-il" class="interest-badge">å¼ºåŒ–å­¦ä¹ ä¸æ¨¡ä»¿å­¦ä¹  (RL & IL) (8 ğŸ”—1)</a>
<a href="#äººå½¢åŒè¶³æœºå™¨äºº-humanoid-biped" class="interest-badge">äººå½¢/åŒè¶³æœºå™¨äºº (Humanoid & Biped) (3 ğŸ”—1)</a>
<a href="#3dæ„ŸçŸ¥ä¸çŠ¶æ€ä¼°è®¡-perception-state-est" class="interest-badge">3Dæ„ŸçŸ¥ä¸çŠ¶æ€ä¼°è®¡ (Perception & State Est) (3)</a>
<a href="#å…·èº«æ™ºèƒ½ä¸è¡¨å¾å­¦ä¹ -embodied-ai-representation" class="interest-badge">å…·èº«æ™ºèƒ½ä¸è¡¨å¾å­¦ä¹  (Embodied AI & Representation) (2)</a>
<a href="#åŠ¨ä½œç”Ÿæˆä¸ç‰©ç†åŠ¨ç”»-animation-physics" class="interest-badge">åŠ¨ä½œç”Ÿæˆä¸ç‰©ç†åŠ¨ç”» (Animation & Physics) (1 ğŸ”—1)</a>
<a href="#ä¸–ç•Œæ¨¡å‹ä¸é¢„æµ‹-world-models" class="interest-badge">ä¸–ç•Œæ¨¡å‹ä¸é¢„æµ‹ (World Models) (1)</a>
</div>

---


<h2 id="å¼ºåŒ–å­¦ä¹ ä¸æ¨¡ä»¿å­¦ä¹ -rl-il">ğŸ”¬ å¼ºåŒ–å­¦ä¹ ä¸æ¨¡ä»¿å­¦ä¹  (RL & IL) (8 ç¯‡)</h2>

| # | é¢˜ç›® | ä¸€å¥è¯è¦ç‚¹ | ğŸ”— |
|---:|---|---|:---:|
| 1 | [Polypersona: Persona-Grounded LLM for Synthetic Survey Responses](./papers/251214562v1-polypersona-persona-grounded-llm-for-synthetic-survey-responses.html) | PolyPersonaï¼šæå‡ºä¸€ç§åŸºäºè§’è‰²çš„å¤§è¯­è¨€æ¨¡å‹æ¡†æ¶ï¼Œç”¨äºåˆæˆè°ƒæŸ¥é—®å·å›å¤ã€‚ |  |
| 2 | [VLegal-Bench: Cognitively Grounded Benchmark for Vietnamese Legal Reasoning of Large Language Models](./papers/251214554v1-vlegal-bench-cognitively-grounded-benchmark-for-vietnamese-legal-rea.html) | æå‡ºVLegal-Benchï¼Œç”¨äºè¯„ä¼°LLMåœ¨è¶Šå—æ³•å¾‹æ¨ç†ä»»åŠ¡ä¸­çš„èƒ½åŠ›ã€‚ |  |
| 3 | [RecGPT-V2 Technical Report](./papers/251214503v1-recgpt-v2-technical-report.html) | RecGPT-V2ï¼šé€šè¿‡å±‚çº§å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå’Œå…ƒæç¤ºç­‰æŠ€æœ¯ï¼Œæå‡LLMåœ¨æ¨èç³»ç»Ÿä¸­çš„æ„å›¾æ¨ç†èƒ½åŠ› |  |
| 4 | [What Affects the Effective Depth of Large Language Models?](./papers/251214064v1-what-affects-the-effective-depth-of-large-language-models.html) | ç ”ç©¶æ­ç¤ºå¤§è¯­è¨€æ¨¡å‹æœ‰æ•ˆæ·±åº¦å—é™ï¼Œä¸ºæ¨¡å‹ä¼˜åŒ–æä¾›æ–°æ–¹å‘ | âœ… |
| 5 | [TiME: Tiny Monolingual Encoders for Efficient NLP Pipelines](./papers/251214645v1-time-tiny-monolingual-encoders-for-efficient-nlp-pipelines.html) | TiMEï¼šç”¨äºé«˜æ•ˆNLPæµæ°´çº¿çš„å¾®å‹å•è¯­ç¼–ç å™¨ |  |
| 6 | [C-ing Clearly: Enhanced Binary Code Explanations using C code](./papers/251214500v1-c-ing-clearly-enhanced-binary-code-explanations-using-c-code.html) | C-ing Clearlyï¼šåˆ©ç”¨Cä»£ç å¢å¼ºLLMå¯¹äºŒè¿›åˆ¶ä»£ç çš„ç†è§£ï¼Œæå‡ä»£ç è§£é‡Šèƒ½åŠ› |  |
| 7 | [SASQ: Static Activation Scaling for Quantization-Aware Training in Large Language Models](./papers/251214481v1-sasq-static-activation-scaling-for-quantization-aware-training-in-la.html) | SASQï¼šä¸€ç§è½»é‡çº§çš„é™æ€æ¿€æ´»é‡åŒ–è®­ç»ƒæ¡†æ¶ï¼Œç”¨äºæå‡å¤§è¯­è¨€æ¨¡å‹é‡åŒ–ç²¾åº¦ã€‚ |  |
| 8 | [CogMem: A Cognitive Memory Architecture for Sustained Multi-Turn Reasoning in Large Language Models](./papers/251214118v1-cogmem-a-cognitive-memory-architecture-for-sustained-multi-turn-reas.html) | CogMemï¼šä¸€ç§è®¤çŸ¥è®°å¿†æ¶æ„ï¼Œç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹ä¸­æŒç»­çš„å¤šè½®æ¨ç† |  |


<h2 id="äººå½¢åŒè¶³æœºå™¨äºº-humanoid-biped">ğŸ”¬ äººå½¢/åŒè¶³æœºå™¨äºº (Humanoid & Biped) (3 ç¯‡)</h2>

| # | é¢˜ç›® | ä¸€å¥è¯è¦ç‚¹ | ğŸ”— |
|---:|---|---|:---:|
| 9 | [Multilingual and Continuous Backchannel Prediction: A Cross-lingual Study](./papers/251214085v1-multilingual-and-continuous-backchannel-prediction-a-cross-lingual-s.html) | æå‡ºä¸€ç§å¤šè¯­ç§è¿ç»­æ€§Backchannelé¢„æµ‹æ¨¡å‹ï¼Œç”¨äºè·¨è¯­è¨€æ—¶åºè¡Œä¸ºç ”ç©¶ã€‚ |  |
| 10 | [Low-Resource, High-Impact: Building Corpora for Inclusive Language Technologies](./papers/251214576v1-low-resource-high-impact-building-corpora-for-inclusive-language-tec.html) | ä¸ºå¤šè¯­ç§å’Œä½èµ„æºè¯­è¨€æ„å»ºåŒ…å®¹æ€§è¯­è¨€æŠ€æœ¯çš„è¯­æ–™åº“ã€‚ | âœ… |
| 11 | [Two CFG Nahuatl for automatic corpora expansion](./papers/251214239v1-two-cfg-nahuatl-for-automatic-corpora-expansion.html) | æå‡ºä¸¤ç§CFGçº³ç“¦ç‰¹å°”è¯­è¯­æ³•ç”¨äºè‡ªåŠ¨è¯­æ–™åº“æ‰©å±•ï¼Œæå‡å°è¯­ç§LLMæ€§èƒ½ |  |


<h2 id="3dæ„ŸçŸ¥ä¸çŠ¶æ€ä¼°è®¡-perception-state-est">ğŸ”¬ 3Dæ„ŸçŸ¥ä¸çŠ¶æ€ä¼°è®¡ (Perception & State Est) (3 ç¯‡)</h2>

| # | é¢˜ç›® | ä¸€å¥è¯è¦ç‚¹ | ğŸ”— |
|---:|---|---|:---:|
| 12 | [Step-Tagging: Toward controlling the generation of Language Reasoning Models through step monitoring](./papers/251214332v1-step-tagging-toward-controlling-the-generation-of-language-reasoning.html) | æå‡ºStep-Taggingæ¡†æ¶ï¼Œé€šè¿‡æ­¥éª¤ç›‘æ§æ§åˆ¶è¯­è¨€æ¨ç†æ¨¡å‹ç”Ÿæˆè¿‡ç¨‹ |  |
| 13 | [Inflation Attitudes of Large Language Models](./papers/251214306v1-inflation-attitudes-of-large-language-models.html) | åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹æ¨¡æ‹Ÿé€šèƒ€é¢„æœŸï¼Œåˆ†æå…¶å¯¹å®è§‚ç»æµä¿¡å·çš„ååº” |  |
| 14 | [Efficient-DLM: From Autoregressive to Diffusion Language Models, and Beyond in Speed](./papers/251214067v1-efficient-dlm-from-autoregressive-to-diffusion-language-models-and-b.html) | æå‡ºEfficient-DLMï¼Œé€šè¿‡ARåˆ°dLMè½¬æ¢ï¼Œæå‡Diffusionè¯­è¨€æ¨¡å‹çš„è®­ç»ƒæ•ˆç‡å’Œæ¨ç†é€Ÿåº¦ã€‚ |  |


<h2 id="å…·èº«æ™ºèƒ½ä¸è¡¨å¾å­¦ä¹ -embodied-ai-representation">ğŸ”¬ å…·èº«æ™ºèƒ½ä¸è¡¨å¾å­¦ä¹  (Embodied AI & Representation) (2 ç¯‡)</h2>

| # | é¢˜ç›® | ä¸€å¥è¯è¦ç‚¹ | ğŸ”— |
|---:|---|---|:---:|
| 15 | [MMGR: Multi-Modal Generative Reasoning](./papers/251214691v1-mmgr-multi-modal-generative-reasoning.html) | æå‡ºMMGRå¤šæ¨¡æ€ç”Ÿæˆæ¨ç†è¯„ä¼°åŸºå‡†ï¼Œè¯Šæ–­è§†é¢‘ç”Ÿæˆæ¨¡å‹åœ¨ç‰©ç†ã€é€»è¾‘å’Œç©ºé—´æ¨ç†ä¸Šçš„ç¼ºé™·ã€‚ |  |
| 16 | [Scalable Frameworks for Real-World Audio-Visual Speech Recognition](./papers/251214083v1-scalable-frameworks-for-real-world-audio-visual-speech-recognition.html) | æå‡ºå¯æ‰©å±•æ¡†æ¶ï¼Œæå‡çœŸå®åœºæ™¯ä¸‹éŸ³è§†é¢‘è¯­éŸ³è¯†åˆ«çš„é²æ£’æ€§ã€‚ |  |


<h2 id="åŠ¨ä½œç”Ÿæˆä¸ç‰©ç†åŠ¨ç”»-animation-physics">ğŸ”¬ åŠ¨ä½œç”Ÿæˆä¸ç‰©ç†åŠ¨ç”» (Animation & Physics) (1 ç¯‡)</h2>

| # | é¢˜ç›® | ä¸€å¥è¯è¦ç‚¹ | ğŸ”— |
|---:|---|---|:---:|
| 17 | [Spoken DialogSum: An Emotion-Rich Conversational Dataset for Spoken Dialogue Summarization](./papers/251214687v1-spoken-dialogsum-an-emotion-rich-conversational-dataset-for-spoken-d.html) | æå‡ºSpoken DialogSumï¼Œä¸€ä¸ªå¯Œå«æƒ…æ„Ÿçš„å£è¯­å¯¹è¯æ‘˜è¦æ•°æ®é›†ï¼Œä¿ƒè¿›æƒ…æ„Ÿæ„ŸçŸ¥å£è¯­å¯¹è¯æ‘˜è¦ç ”ç©¶ã€‚ | âœ… |


<h2 id="ä¸–ç•Œæ¨¡å‹ä¸é¢„æµ‹-world-models">ğŸ”¬ ä¸–ç•Œæ¨¡å‹ä¸é¢„æµ‹ (World Models) (1 ç¯‡)</h2>

| # | é¢˜ç›® | ä¸€å¥è¯è¦ç‚¹ | ğŸ”— |
|---:|---|---|:---:|
| 18 | [Astraea: A State-Aware Scheduling Engine for LLM-Powered Agents](./papers/251214142v1-astraea-a-state-aware-scheduling-engine-for-llm-powered-agents.html) | Astraeaï¼šé¢å‘LLMé©±åŠ¨Agentçš„çŠ¶æ€æ„ŸçŸ¥è°ƒåº¦å¼•æ“ï¼Œä¼˜åŒ–ç«¯åˆ°ç«¯å»¶è¿Ÿ |  |


[â¬…ï¸ è¿”å› cs.CL é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)