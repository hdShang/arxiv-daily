---
layout: default
title: Multilingual and Continuous Backchannel Prediction: A Cross-lingual Study
---

# Multilingual and Continuous Backchannel Prediction: A Cross-lingual Study

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.14085" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.14085</a>
  <a href="https://arxiv.org/pdf/2512.14085.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14085" onclick="toggleFavorite(this, '2512.14085', 'Multilingual and Continuous Backchannel Prediction: A Cross-lingual Study')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Koji Inoue, Mikey Elmers, Yahui Fu, Zi Haur Pang, Taiga Mori, Divesh Lala, Keiko Ochi, Tatsuya Kawahara

**åˆ†ç±»**: cs.CL, cs.HC, cs.SD

**å‘å¸ƒæ—¥æœŸ**: 2025-12-18

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§å¤šè¯­ç§è¿ç»­åé€šé“é¢„æµ‹æ¨¡å‹ï¼Œç”¨äºç ”ç©¶è·¨è¯­è¨€çš„äº¤äº’æ—¶åºè¡Œä¸ºã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åé€šé“é¢„æµ‹` `å¤šè¯­ç§å­¦ä¹ ` `Transformer` `è·¨è¯­è¨€ç ”ç©¶` `å£è¯­å¯¹è¯ç³»ç»Ÿ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åé€šé“é¢„æµ‹æ¨¡å‹ç¼ºä¹è·¨è¯­è¨€çš„ç»Ÿä¸€æ€§ï¼Œéš¾ä»¥æ•æ‰ä¸åŒè¯­è¨€é—´äº¤äº’æ—¶åºçš„å·®å¼‚ã€‚
2. æå‡ºåŸºäºTransformerçš„å¤šè¯­ç§è¿ç»­åé€šé“é¢„æµ‹æ¨¡å‹ï¼Œè”åˆè®­ç»ƒå¤šç§è¯­è¨€ï¼Œå­¦ä¹ é€šç”¨å’Œç‰¹å®šè¯­è¨€çš„çº¿ç´¢ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨å¤šç§è¯­è¨€ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå¹¶æ­ç¤ºäº†ä¸åŒè¯­è¨€åœ¨åé€šé“é¢„æµ‹ä¸­å¯¹ä¸åŒçº¿ç´¢çš„ä¾èµ–ç¨‹åº¦ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äºæ—¥è¯­ã€è‹±è¯­å’Œæ±‰è¯­çš„å¤šè¯­ç§è¿ç»­åé€šé“é¢„æµ‹æ¨¡å‹ï¼Œå¹¶åˆ©ç”¨å®ƒæ¥ç ”ç©¶è·¨è¯­è¨€çš„æ—¶åºè¡Œä¸ºã€‚è¯¥æ¨¡å‹åŸºäºTransformerï¼Œåœ¨å¸§çº§åˆ«ä¸Šè¿è¡Œï¼Œå¹¶ä½¿ç”¨å¤§çº¦300å°æ—¶çš„äºŒå…ƒå¯¹è¯è¿›è¡Œè”åˆè®­ç»ƒï¼ŒåŒ…å«è¾…åŠ©ä»»åŠ¡ã€‚åœ¨æ‰€æœ‰ä¸‰ç§è¯­è¨€ä¸­ï¼Œå¤šè¯­ç§æ¨¡å‹éƒ½è¾¾åˆ°æˆ–è¶…è¿‡äº†å•è¯­åŸºçº¿ï¼Œè¡¨æ˜å®ƒå­¦ä¹ äº†è¯­è¨€é€šç”¨çš„çº¿ç´¢å’Œç‰¹å®šäºè¯­è¨€çš„æ—¶åºæ¨¡å¼ã€‚ä½¿ç”¨åŒè¯­è®­ç»ƒçš„é›¶æ ·æœ¬è¿ç§»ä»ç„¶æœ‰é™ï¼Œçªå‡ºäº†è·¨è¯­è¨€çš„å®è´¨æ€§å·®å¼‚ã€‚æ‰°åŠ¨åˆ†ææ­ç¤ºäº†ä¸åŒçš„çº¿ç´¢ä½¿ç”¨ï¼šæ—¥è¯­æ›´ä¾èµ–äºçŸ­æœŸè¯­è¨€ä¿¡æ¯ï¼Œè€Œè‹±è¯­å’Œæ±‰è¯­å¯¹é™éŸ³æ—¶é•¿å’ŒéŸµå¾‹å˜åŒ–æ›´æ•æ„Ÿï¼›å¤šè¯­ç§è®­ç»ƒé¼“åŠ±å…±äº«ä½†é€‚åº”æ€§å¼ºçš„è¡¨ç¤ºï¼Œå¹¶å‡å°‘å¯¹æ±‰è¯­ä¸­éŸ³é«˜çš„è¿‡åº¦ä¾èµ–ã€‚ä¸Šä¸‹æ–‡é•¿åº¦ç ”ç©¶è¿›ä¸€æ­¥è¡¨æ˜ï¼Œæ—¥è¯­ç›¸å¯¹æ›´èƒ½é€‚åº”è¾ƒçŸ­çš„ä¸Šä¸‹æ–‡ï¼Œè€Œæ±‰è¯­åˆ™æ˜æ˜¾å—ç›Šäºè¾ƒé•¿çš„ä¸Šä¸‹æ–‡ã€‚æœ€åï¼Œæˆ‘ä»¬å°†è®­ç»ƒå¥½çš„æ¨¡å‹é›†æˆåˆ°å®æ—¶å¤„ç†è½¯ä»¶ä¸­ï¼Œå±•ç¤ºäº†ä»…ä½¿ç”¨CPUçš„æ¨ç†ã€‚æ€»ä¹‹ï¼Œè¿™äº›å‘ç°æä¾›äº†ä¸€ä¸ªç»Ÿä¸€çš„æ¨¡å‹å’Œç»éªŒè¯æ®ï¼Œè¯æ˜äº†åé€šé“æ—¶åºåœ¨ä¸åŒè¯­è¨€ä¹‹é—´çš„å·®å¼‚ï¼Œä»è€Œä¸ºè®¾è®¡æ›´è‡ªç„¶ã€æ›´å…·æ–‡åŒ–æ„è¯†çš„å£è¯­å¯¹è¯ç³»ç»Ÿæä¾›äº†ä¿¡æ¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è·¨è¯­è¨€åé€šé“é¢„æµ‹çš„é—®é¢˜ã€‚ç°æœ‰çš„åé€šé“é¢„æµ‹æ¨¡å‹é€šå¸¸æ˜¯å•è¯­çš„ï¼Œæ— æ³•ç›´æ¥åº”ç”¨äºå¤šè¯­ç§ç¯å¢ƒï¼Œå¹¶ä¸”éš¾ä»¥æ•æ‰ä¸åŒè¯­è¨€ä¹‹é—´åé€šé“è¡Œä¸ºçš„ç»†å¾®å·®å¼‚ã€‚æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•å¯èƒ½è¿‡åº¦ä¾èµ–æŸäº›ç‰¹å®šçš„å£°å­¦æˆ–è¯­è¨€ç‰¹å¾ï¼Œå¯¼è‡´æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨Transformeræ¶æ„æ„å»ºä¸€ä¸ªå¤šè¯­ç§çš„åé€šé“é¢„æµ‹æ¨¡å‹ï¼Œé€šè¿‡è”åˆè®­ç»ƒå¤šç§è¯­è¨€çš„æ•°æ®ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ åˆ°è¯­è¨€é€šç”¨çš„ç‰¹å¾è¡¨ç¤ºä»¥åŠç‰¹å®šäºè¯­è¨€çš„æ—¶åºæ¨¡å¼ã€‚é€šè¿‡å¼•å…¥è¾…åŠ©ä»»åŠ¡ï¼Œå¯ä»¥è¿›ä¸€æ­¥æå‡æ¨¡å‹çš„å­¦ä¹ æ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰ä¸åŒè¯­è¨€åœ¨åé€šé“è¡Œä¸ºä¸Šçš„å·®å¼‚ï¼Œå¹¶æé«˜æ¨¡å‹åœ¨è·¨è¯­è¨€ç¯å¢ƒä¸‹çš„é¢„æµ‹å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¨¡å‹åŸºäºTransformeræ¶æ„ï¼Œè¾“å…¥ä¸ºè¯­éŸ³å¸§çº§åˆ«çš„ç‰¹å¾ï¼Œè¾“å‡ºä¸ºè¿ç»­çš„åé€šé“é¢„æµ‹æ¦‚ç‡ã€‚æ•´ä½“æµç¨‹åŒ…æ‹¬ï¼š1) ç‰¹å¾æå–ï¼šä»è¯­éŸ³ä¿¡å·ä¸­æå–å£°å­¦å’Œè¯­è¨€ç‰¹å¾ï¼›2) Transformerç¼–ç ï¼šä½¿ç”¨Transformerç¼–ç å™¨å¯¹ç‰¹å¾è¿›è¡Œç¼–ç ï¼Œå­¦ä¹ ä¸Šä¸‹æ–‡ç›¸å…³çš„è¡¨ç¤ºï¼›3) åé€šé“é¢„æµ‹ï¼šä½¿ç”¨å…¨è¿æ¥å±‚å°†ç¼–ç åçš„è¡¨ç¤ºæ˜ å°„åˆ°åé€šé“é¢„æµ‹æ¦‚ç‡ï¼›4) è¾…åŠ©ä»»åŠ¡ï¼šå¼•å…¥è¾…åŠ©ä»»åŠ¡ï¼Œä¾‹å¦‚è¯­è¨€è¯†åˆ«æˆ–è¯´è¯äººè¯†åˆ«ï¼Œä»¥æå‡æ¨¡å‹çš„å­¦ä¹ æ•ˆç‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†ä¸€ä¸ªå¤šè¯­ç§çš„åé€šé“é¢„æµ‹æ¨¡å‹ï¼Œèƒ½å¤ŸåŒæ—¶å¤„ç†å¤šç§è¯­è¨€ï¼›2) é€šè¿‡è”åˆè®­ç»ƒå’Œè¾…åŠ©ä»»åŠ¡ï¼Œæé«˜äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œå­¦ä¹ æ•ˆç‡ï¼›3) é€šè¿‡æ‰°åŠ¨åˆ†æï¼Œæ­ç¤ºäº†ä¸åŒè¯­è¨€åœ¨åé€šé“é¢„æµ‹ä¸­å¯¹ä¸åŒçº¿ç´¢çš„ä¾èµ–ç¨‹åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡å‹ä½¿ç”¨Transformerç¼–ç å™¨ï¼ŒåŒ…å«å¤šå±‚è‡ªæ³¨æ„åŠ›æœºåˆ¶å’Œå‰é¦ˆç¥ç»ç½‘ç»œã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬åé€šé“é¢„æµ‹çš„äº¤å‰ç†µæŸå¤±å’Œè¾…åŠ©ä»»åŠ¡çš„æŸå¤±ã€‚ä¸Šä¸‹æ–‡é•¿åº¦æ˜¯ä¸€ä¸ªé‡è¦çš„å‚æ•°ï¼Œå®éªŒä¸­æ¢ç´¢äº†ä¸åŒä¸Šä¸‹æ–‡é•¿åº¦å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜ä½¿ç”¨äº†æ•°æ®å¢å¼ºæŠ€æœ¯ï¼Œä¾‹å¦‚è¯­éŸ³é€Ÿåº¦æ‰°åŠ¨ï¼Œä»¥æé«˜æ¨¡å‹çš„é²æ£’æ€§ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.14085/x1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.14085/x2.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.14085/x3.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå¤šè¯­ç§æ¨¡å‹åœ¨æ—¥è¯­ã€è‹±è¯­å’Œæ±‰è¯­ä¸‰ç§è¯­è¨€ä¸Šå‡è¾¾åˆ°æˆ–è¶…è¿‡äº†å•è¯­åŸºçº¿æ¨¡å‹ã€‚æ‰°åŠ¨åˆ†ææ˜¾ç¤ºï¼Œæ—¥è¯­æ›´ä¾èµ–çŸ­æœŸè¯­è¨€ä¿¡æ¯ï¼Œè€Œè‹±è¯­å’Œæ±‰è¯­å¯¹é™éŸ³æ—¶é•¿å’ŒéŸµå¾‹å˜åŒ–æ›´æ•æ„Ÿã€‚ä¸Šä¸‹æ–‡é•¿åº¦ç ”ç©¶è¡¨æ˜ï¼Œæ±‰è¯­å—ç›Šäºæ›´é•¿çš„ä¸Šä¸‹æ–‡ã€‚è¯¥æ¨¡å‹å·²æˆåŠŸé›†æˆåˆ°å®æ—¶å¤„ç†è½¯ä»¶ä¸­ï¼Œå¹¶å®ç°äº†CPUä¸Šçš„é«˜æ•ˆæ¨ç†ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¤šè¯­ç§å£è¯­å¯¹è¯ç³»ç»Ÿï¼Œæå‡äººæœºäº¤äº’çš„è‡ªç„¶æ€§å’Œæµç•…æ€§ã€‚é€šè¿‡ç†è§£ä¸åŒè¯­è¨€çš„åé€šé“è¡Œä¸ºï¼Œç³»ç»Ÿå¯ä»¥æ›´å‡†ç¡®åœ°è¯†åˆ«ç”¨æˆ·çš„åé¦ˆï¼Œå¹¶åšå‡ºæ›´åˆé€‚çš„å“åº”ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹è¿˜å¯ä»¥ç”¨äºè·¨æ–‡åŒ–äº¤æµç ”ç©¶ï¼Œå¸®åŠ©äººä»¬æ›´å¥½åœ°ç†è§£ä¸åŒæ–‡åŒ–èƒŒæ™¯ä¸‹çš„æ²Ÿé€šæ–¹å¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present a multilingual, continuous backchannel prediction model for Japanese, English, and Chinese, and use it to investigate cross-linguistic timing behavior. The model is Transformer-based and operates at the frame level, jointly trained with auxiliary tasks on approximately 300 hours of dyadic conversations. Across all three languages, the multilingual model matches or surpasses monolingual baselines, indicating that it learns both language-universal cues and language-specific timing patterns. Zero-shot transfer with two-language training remains limited, underscoring substantive cross-lingual differences. Perturbation analyses reveal distinct cue usage: Japanese relies more on short-term linguistic information, whereas English and Chinese are more sensitive to silence duration and prosodic variation; multilingual training encourages shared yet adaptable representations and reduces overreliance on pitch in Chinese. A context-length study further shows that Japanese is relatively robust to shorter contexts, while Chinese benefits markedly from longer contexts. Finally, we integrate the trained model into a real-time processing software, demonstrating CPU-only inference. Together, these findings provide a unified model and empirical evidence for how backchannel timing differs across languages, informing the design of more natural, culturally-aware spoken dialogue systems.

