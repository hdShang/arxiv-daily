---
layout: default
title: Efficient Adaptive Rejection Sampling for Accelerating Speculative Decoding in Large Language Models
---

# Efficient Adaptive Rejection Sampling for Accelerating Speculative Decoding in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.13194" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.13194</a>
  <a href="https://arxiv.org/pdf/2512.13194.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.13194" onclick="toggleFavorite(this, '2512.13194', 'Efficient Adaptive Rejection Sampling for Accelerating Speculative Decoding in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chendong Sun, mingmin Chen, Lei Xu

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-18

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé«˜æ•ˆè‡ªé€‚åº”æ‹’ç»é‡‡æ ·(EARS)ä»¥åŠ é€Ÿå¤§è¯­è¨€æ¨¡å‹æ¨æµ‹è§£ç ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ¨æµ‹è§£ç ` `å¤§è¯­è¨€æ¨¡å‹` `æ‹’ç»é‡‡æ ·` `è‡ªé€‚åº”é˜ˆå€¼` `æ¨¡å‹ä¸ç¡®å®šæ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ¨æµ‹è§£ç ä¸­å›ºå®šçš„æ‹’ç»é‡‡æ ·é˜ˆå€¼å¯¼è‡´é«˜ä¸ç¡®å®šæ€§åœºæ™¯ä¸‹å‡ºç°ä¸å¿…è¦çš„tokenæ‹’ç»ï¼Œé™ä½æ•ˆç‡ã€‚
2. EARSé€šè¿‡ç›®æ ‡æ¨¡å‹é¢„æµ‹ä¸ç¡®å®šæ€§åŠ¨æ€è°ƒæ•´æ¥å—é˜ˆå€¼ï¼Œåœ¨ä¸ç¡®å®šæ—¶æ”¾å®½æ ‡å‡†ï¼Œå‡å°‘éšæœºæ‹’ç»ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒEARSæ˜¾è‘—æå‡äº†æ¨æµ‹è§£ç çš„ååé‡ï¼Œä¸”å¯¹æ¨¡å‹å‡†ç¡®ç‡çš„å½±å“å¯å¿½ç•¥ä¸è®¡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ¨æµ‹è§£ç æ˜¯ä¸€ç§é€šè¿‡åˆ©ç”¨å¿«é€Ÿè‰ç¨¿æ¨¡å‹æå‡ºå€™é€‰tokenåºåˆ—ï¼Œå¹¶ä½¿ç”¨å¤§å‹ç›®æ ‡æ¨¡å‹å¹¶è¡ŒéªŒè¯å®ƒä»¬æ¥åŠ é€Ÿå¤§å‹è¯­è¨€æ¨¡å‹(LLM)è‡ªå›å½’æ¨ç†çš„çªå‡ºæŠ€æœ¯ã€‚ç„¶è€Œï¼Œå…¶æ ¸å¿ƒç»„ä»¶â€”â€”æ‹’ç»é‡‡æ ·æœºåˆ¶â€”â€”ä¾èµ–äºå›ºå®šçš„ã€ä¸ä¸Šä¸‹æ–‡æ— å…³çš„éšæœºé˜ˆå€¼ã€‚è¿™å¯¼è‡´äº†é«˜ä¸ç¡®å®šæ€§ç”Ÿæˆåœºæ™¯ä¸­æ˜¾è‘—çš„â€œéšæœºæ‹’ç»â€é—®é¢˜ï¼Œå…¶ä¸­åˆç†çš„å€™é€‰tokenç”±äºéšæœºæœºä¼šè€Œè¢«é¢‘ç¹æ‹’ç»ï¼Œä»è€Œé™ä½äº†æ¨ç†æ•ˆç‡ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§é«˜æ•ˆè‡ªé€‚åº”æ‹’ç»é‡‡æ ·(EARS)æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡ç»“åˆç›®æ ‡æ¨¡å‹è‡ªèº«çš„é¢„æµ‹ä¸ç¡®å®šæ€§ï¼ˆä»¥1 - max(P_target)è¡¡é‡ï¼‰æ¥åŠ¨æ€è°ƒæ•´æ¥å—é˜ˆå€¼ã€‚é€šè¿‡å¼•å…¥ä¸æ­¤ä¸ç¡®å®šæ€§æˆæ¯”ä¾‹çš„å®¹å·®é¡¹ï¼ŒEARSåœ¨æ¨¡å‹ä¸ç¡®å®šæ—¶æ™ºèƒ½åœ°æ”¾å®½æ¥å—æ ‡å‡†ï¼Œåœ¨æ¨¡å‹æœ‰ä¿¡å¿ƒæ—¶ä¿æŒä¸¥æ ¼æ ‡å‡†ï¼Œä»è€Œæœ‰æ•ˆåœ°å‡å°‘éšæœºæ‹’ç»ã€‚åœ¨åˆ›é€ æ€§å†™ä½œå’Œå¼€æ”¾é¢†åŸŸé—®ç­”ä»»åŠ¡ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒEARSæ˜¾è‘—æé«˜äº†æ¨æµ‹è§£ç çš„æ•ˆç‡ï¼Œåœ¨GSM8KåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†é«˜è¾¾18.12%çš„ååé‡æå‡ï¼Œè€Œå‡†ç¡®ç‡ä»…ä¸‹é™äº†0.84%ã€‚è¯¥æ–¹æ³•ä¸éœ€è¦ä¿®æ”¹æ¨¡å‹æ¶æ„ï¼Œå¹¶ä¸”å¯ä»¥æ— ç¼é›†æˆåˆ°ç°æœ‰çš„æ¨æµ‹è§£ç æ¡†æ¶ä¸­ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæ¨æµ‹è§£ç æ—¨åœ¨åŠ é€ŸLLMçš„è‡ªå›å½’æ¨ç†ï¼Œä½†å…¶æ‹’ç»é‡‡æ ·æœºåˆ¶ä¾èµ–äºå›ºå®šçš„é˜ˆå€¼ï¼Œå¯¼è‡´åœ¨é«˜ä¸ç¡®å®šæ€§åœºæ™¯ä¸‹ï¼Œå³ä½¿æ˜¯åˆç†çš„å€™é€‰tokenä¹Ÿå¯èƒ½è¢«éšæœºæ‹’ç»ï¼Œé™ä½äº†æ¨ç†æ•ˆç‡ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†åˆ©ç”¨ç›®æ ‡æ¨¡å‹è‡ªèº«çš„ä¿¡æ¯æ¥åŠ¨æ€è°ƒæ•´æ¥å—æ ‡å‡†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šEARSçš„æ ¸å¿ƒåœ¨äºåˆ©ç”¨ç›®æ ‡æ¨¡å‹é¢„æµ‹çš„ä¸ç¡®å®šæ€§æ¥åŠ¨æ€è°ƒæ•´æ‹’ç»é‡‡æ ·çš„æ¥å—é˜ˆå€¼ã€‚å½“ç›®æ ‡æ¨¡å‹å¯¹é¢„æµ‹ç»“æœä¸ç¡®å®šæ—¶ï¼Œé€‚å½“æ”¾å®½æ¥å—æ ‡å‡†ï¼Œå…è®¸æ›´å¤šå¯èƒ½çš„tokené€šè¿‡ï¼Œä»è€Œå‡å°‘éšæœºæ‹’ç»ï¼›å½“æ¨¡å‹æœ‰ä¿¡å¿ƒæ—¶ï¼Œåˆ™ä¿æŒä¸¥æ ¼çš„æ ‡å‡†ã€‚è¿™æ ·å¯ä»¥åœ¨ä¿è¯ç”Ÿæˆè´¨é‡çš„å‰æä¸‹ï¼Œæé«˜æ¨ç†æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEARSå¯ä»¥æ— ç¼é›†æˆåˆ°ç°æœ‰çš„æ¨æµ‹è§£ç æ¡†æ¶ä¸­ã€‚å…¶ä¸»è¦æµç¨‹å¦‚ä¸‹ï¼šé¦–å…ˆï¼Œè‰ç¨¿æ¨¡å‹ç”Ÿæˆå€™é€‰tokenåºåˆ—ï¼›ç„¶åï¼Œç›®æ ‡æ¨¡å‹å¯¹è¿™äº›tokenè¿›è¡ŒéªŒè¯ã€‚åœ¨éªŒè¯è¿‡ç¨‹ä¸­ï¼ŒEARSæ ¹æ®ç›®æ ‡æ¨¡å‹é¢„æµ‹æ¦‚ç‡çš„æœ€å¤§å€¼(max(P_target))è®¡ç®—ä¸ç¡®å®šæ€§ï¼Œå¹¶åŸºäºæ­¤åŠ¨æ€è°ƒæ•´æ¥å—é˜ˆå€¼ã€‚æœ€åï¼Œæ ¹æ®è°ƒæ•´åçš„é˜ˆå€¼å†³å®šæ˜¯å¦æ¥å—å€™é€‰tokenã€‚

**å…³é”®åˆ›æ–°**ï¼šEARSçš„å…³é”®åˆ›æ–°åœ¨äºå¼•å…¥äº†è‡ªé€‚åº”çš„æ‹’ç»é‡‡æ ·æœºåˆ¶ï¼Œå®ƒä¸å†ä¾èµ–äºå›ºå®šçš„é˜ˆå€¼ï¼Œè€Œæ˜¯æ ¹æ®ç›®æ ‡æ¨¡å‹è‡ªèº«çš„é¢„æµ‹ä¸ç¡®å®šæ€§åŠ¨æ€è°ƒæ•´ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæ›´æ™ºèƒ½åœ°å¹³è¡¡ç”Ÿæˆè´¨é‡å’Œæ¨ç†æ•ˆç‡ï¼Œå°¤å…¶æ˜¯åœ¨é«˜ä¸ç¡®å®šæ€§åœºæ™¯ä¸‹ï¼Œèƒ½å¤Ÿæ˜¾è‘—å‡å°‘éšæœºæ‹’ç»ï¼Œæé«˜ååé‡ã€‚

**å…³é”®è®¾è®¡**ï¼šEARSçš„å…³é”®è®¾è®¡åœ¨äºå®¹å·®é¡¹çš„å¼•å…¥ï¼Œè¯¥å®¹å·®é¡¹ä¸ç›®æ ‡æ¨¡å‹é¢„æµ‹ä¸ç¡®å®šæ€§æˆæ¯”ä¾‹ã€‚å…·ä½“æ¥è¯´ï¼Œæ¥å—é˜ˆå€¼è¢«è°ƒæ•´ä¸ºåŸå§‹é˜ˆå€¼åŠ ä¸Šä¸€ä¸ªå®¹å·®å€¼ï¼Œè¯¥å®¹å·®å€¼ç­‰äº `alpha * (1 - max(P_target))`ï¼Œå…¶ä¸­ `alpha` æ˜¯ä¸€ä¸ªå¯è°ƒèŠ‚çš„è¶…å‚æ•°ï¼Œç”¨äºæ§åˆ¶å®¹å·®çš„å¼ºåº¦ã€‚`alpha` çš„é€‰æ‹©éœ€è¦æ ¹æ®å…·ä½“ä»»åŠ¡è¿›è¡Œè°ƒæ•´ï¼Œä»¥è¾¾åˆ°æœ€ä½³çš„æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒEARSåœ¨åˆ›é€ æ€§å†™ä½œå’Œå¼€æ”¾é¢†åŸŸé—®ç­”ä»»åŠ¡ä¸­æ˜¾è‘—æé«˜äº†æ¨æµ‹è§£ç çš„æ•ˆç‡ã€‚åœ¨GSM8KåŸºå‡†æµ‹è¯•ä¸­ï¼ŒEARSå®ç°äº†é«˜è¾¾18.12%çš„ååé‡æå‡ï¼Œè€Œå‡†ç¡®ç‡ä»…ä¸‹é™äº†0.84%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒEARSèƒ½å¤Ÿåœ¨ä¿è¯ç”Ÿæˆè´¨é‡çš„å‰æä¸‹ï¼Œæ˜¾è‘—åŠ é€ŸLLMçš„æ¨ç†è¿‡ç¨‹ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

EARSå¯å¹¿æ³›åº”ç”¨äºéœ€è¦å¿«é€Ÿç”Ÿæˆæ–‡æœ¬çš„åœºæ™¯ï¼Œä¾‹å¦‚èŠå¤©æœºå™¨äººã€æœºå™¨ç¿»è¯‘ã€æ–‡æœ¬æ‘˜è¦ã€ä»£ç ç”Ÿæˆç­‰ã€‚é€šè¿‡æé«˜LLMçš„æ¨ç†æ•ˆç‡ï¼ŒEARSèƒ½å¤Ÿé™ä½è®¡ç®—æˆæœ¬ï¼Œæå‡ç”¨æˆ·ä½“éªŒï¼Œå¹¶ä¿ƒè¿›LLMåœ¨èµ„æºå—é™ç¯å¢ƒä¸­çš„éƒ¨ç½²ã€‚æ­¤å¤–ï¼ŒEARSçš„è‡ªé€‚åº”ç‰¹æ€§ä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°åº”å¯¹å„ç§ç”Ÿæˆä»»åŠ¡ï¼Œå°¤å…¶æ˜¯åœ¨åˆ›é€ æ€§å†™ä½œå’Œå¼€æ”¾é¢†åŸŸé—®ç­”ç­‰é«˜ä¸ç¡®å®šæ€§åœºæ™¯ä¸­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Speculative Decoding is a prominent technique for accelerating the autoregressive inference of large language models (LLMs) by employing a fast draft model to propose candidate token sequences and a large target model to verify them in parallel. However, its core component -- the rejection sampling mechanism -- relies on a fixed, context-independent random threshold. This leads to a significant "random rejection" problem in high-uncertainty generation scenarios, where plausible candidate tokens are frequently rejected due to random chance, undermining inference efficiency. This paper introduces Efficient Adaptive Rejection Sampling (EARS), a novel method that dynamically adjusts the acceptance threshold by incorporating the target model's own predictive uncertainty, measured as 1 - max(P_target). By introducing a tolerance term proportional to this uncertainty, EARS intelligently relaxes the acceptance criterion when the model is uncertain, effectively reducing random rejections while maintaining strict standards when the model is confident. Experiments on creative writing and open-domain QA tasks demonstrate that EARS significantly enhances the efficiency of speculative decoding, achieving up to an 18.12% increase in throughput with a negligible 0.84% accuracy drop on the GSM8K benchmark. The method requires no modifications to model architectures and can be seamlessly integrated into existing speculative decoding frameworks.

