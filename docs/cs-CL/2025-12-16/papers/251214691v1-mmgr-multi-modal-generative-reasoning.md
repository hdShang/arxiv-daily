---
layout: default
title: MMGR: Multi-Modal Generative Reasoning
---

# MMGR: Multi-Modal Generative Reasoning

**arXiv**: [2512.14691v1](https://arxiv.org/abs/2512.14691) | [PDF](https://arxiv.org/pdf/2512.14691.pdf)

**ä½œè€…**: Zefan Cai, Haoyi Qiu, Tianyi Ma, Haozhe Zhao, Gengze Zhou, Kung-Hsiang Huang, Parisa Kordjamshidi, Minjia Zhang, Xiao Wen, Jiuxiang Gu, Nanyun Peng, Junjie Hu

**åˆ†ç±»**: cs.CL, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: work in progress

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMMGRå¤šæ¨¡æ€ç”ŸæˆæŽ¨ç†è¯„ä¼°åŸºå‡†ï¼Œè¯Šæ–­è§†é¢‘ç”Ÿæˆæ¨¡åž‹åœ¨ç‰©ç†ã€é€»è¾‘å’Œç©ºé—´æŽ¨ç†ä¸Šçš„ç¼ºé™·ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å…·èº«æ™ºèƒ½ä¸Žè¡¨å¾å­¦ä¹  (Embodied AI & Representation)** **3Dæ„ŸçŸ¥ä¸ŽçŠ¶æ€ä¼°è®¡ (Perception & State Est)** **ä¸–ç•Œæ¨¡åž‹ä¸Žé¢„æµ‹ (World Models)** **è‡ªåŠ¨é©¾é©¶ (Autonomous Driving)**

**å…³é”®è¯**: `è§†é¢‘ç”Ÿæˆ` `å¤šæ¨¡æ€æŽ¨ç†` `è¯„ä¼°åŸºå‡†` `ç‰©ç†å¸¸è¯†` `å…·èº«å¯¼èˆª`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è§†é¢‘ç”Ÿæˆæ¨¡åž‹ç¼ºä¹å¯¹ç‰©ç†ã€é€»è¾‘å’Œç©ºé—´çº¦æŸçš„æœ‰æ•ˆæŽ¨ç†ï¼Œä¼ ç»Ÿè¯„ä¼°æŒ‡æ ‡ä¾§é‡æ„ŸçŸ¥è´¨é‡ï¼Œå¿½ç•¥äº†æŽ¨ç†å¤±è´¥ã€‚
2. MMGRæ¡†æž¶é€šè¿‡äº”ç§æŽ¨ç†èƒ½åŠ›ï¼ˆç‰©ç†ã€é€»è¾‘ã€ç©ºé—´ã€æ—¶é—´ï¼‰å’Œä¸‰ä¸ªé¢†åŸŸï¼ˆæŠ½è±¡æŽ¨ç†ã€å…·èº«å¯¼èˆªã€ç‰©ç†å¸¸è¯†ï¼‰æ¥è¯„ä¼°ç”Ÿæˆæ¨¡åž‹çš„æŽ¨ç†èƒ½åŠ›ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒçŽ°æœ‰æ¨¡åž‹åœ¨ç‰©ç†å¸¸è¯†ä»»åŠ¡ä¸Šè¡¨çŽ°å°šå¯ï¼Œä½†åœ¨æŠ½è±¡æŽ¨ç†å’Œé•¿ç¨‹ç©ºé—´è§„åˆ’æ–¹é¢è¡¨çŽ°è¾ƒå·®ï¼Œå­˜åœ¨å…¨å±€ä¸€è‡´æ€§å¼±ç­‰é—®é¢˜ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†MMGRï¼ˆå¤šæ¨¡æ€ç”ŸæˆæŽ¨ç†è¯„ä¼°åŸºå‡†ï¼‰ï¼Œä¸€ä¸ªåŸºäºŽäº”ç§æŽ¨ç†èƒ½åŠ›çš„è¯„ä¼°æ¡†æž¶ï¼šç‰©ç†ã€é€»è¾‘ã€3Dç©ºé—´ã€2Dç©ºé—´å’Œæ—¶é—´ã€‚MMGRåœ¨ä¸‰ä¸ªé¢†åŸŸè¯„ä¼°ç”ŸæˆæŽ¨ç†ï¼šæŠ½è±¡æŽ¨ç†ï¼ˆARC-AGIã€æ•°ç‹¬ï¼‰ã€å…·èº«å¯¼èˆªï¼ˆçœŸå®žä¸–ç•Œ3Då¯¼èˆªå’Œå®šä½ï¼‰å’Œç‰©ç†å¸¸è¯†ï¼ˆä½“è‚²å’Œç»„åˆäº¤äº’ï¼‰ã€‚MMGRåº”ç”¨ç»†ç²’åº¦çš„æŒ‡æ ‡ï¼Œè¦æ±‚è§†é¢‘å’Œå›¾åƒç”Ÿæˆåœ¨æ•´ä½“ä¸Šæ˜¯æ­£ç¡®çš„ã€‚å¯¹é¢†å…ˆçš„è§†é¢‘æ¨¡åž‹ï¼ˆVeo-3ã€Sora-2ã€Wan-2.2ï¼‰å’Œå›¾åƒæ¨¡åž‹ï¼ˆNano-bananaã€Nano-banana Proã€GPT-4o-imageã€Qwen-imageï¼‰è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼Œæ­ç¤ºäº†è·¨é¢†åŸŸçš„æ˜¾è‘—æ€§èƒ½å·®è·ã€‚æ¨¡åž‹åœ¨ç‰©ç†å¸¸è¯†ä»»åŠ¡ä¸Šè¡¨çŽ°å‡ºé€‚åº¦çš„æˆåŠŸï¼Œä½†åœ¨æŠ½è±¡æŽ¨ç†æ–¹é¢è¡¨çŽ°ä¸ä½³ï¼ˆåœ¨ARC-AGIä¸Šçš„å‡†ç¡®çŽ‡ä½ŽäºŽ10%ï¼‰ï¼Œå¹¶ä¸”åœ¨å…·èº«çŽ¯å¢ƒä¸­çš„é•¿ç¨‹ç©ºé—´è§„åˆ’æ–¹é¢å­˜åœ¨å›°éš¾ã€‚åˆ†æžçªå‡ºäº†å½“å‰æ¨¡åž‹çš„å…³é”®å±€é™æ€§ï¼ŒåŒ…æ‹¬è¿‡åº¦ä¾èµ–æ„ŸçŸ¥æ•°æ®ã€å…¨å±€çŠ¶æ€ä¸€è‡´æ€§å¼±ä»¥åŠå¥–åŠ±è§†è§‰åˆç†æ€§è€Œéžå› æžœæ­£ç¡®æ€§çš„ç›®æ ‡ã€‚MMGRæä¾›äº†ä¸€ä¸ªç»Ÿä¸€çš„è¯Šæ–­åŸºå‡†ï¼Œå¹¶ä¸ºæŽ¨ç†æ„ŸçŸ¥çš„ç”Ÿæˆä¸–ç•Œæ¨¡åž‹æä¾›äº†ä¸€æ¡é€”å¾„ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰è§†é¢‘ç”Ÿæˆæ¨¡åž‹ï¼Œå¦‚Soraç­‰ï¼Œè™½ç„¶åœ¨è§†è§‰æ•ˆæžœä¸Šé€¼çœŸï¼Œä½†åœ¨ç†è§£å’Œæ¨¡æ‹ŸçœŸå®žä¸–ç•Œä¸­çš„ç‰©ç†è§„å¾‹ã€é€»è¾‘å…³ç³»å’Œç©ºé—´ç»“æž„æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚ä¼ ç»Ÿçš„è¯„ä¼°æŒ‡æ ‡ï¼Œå¦‚FVDï¼Œä¸»è¦å…³æ³¨ç”Ÿæˆè§†é¢‘çš„è§†è§‰è´¨é‡ï¼Œè€Œå¿½ç•¥äº†æ¨¡åž‹åœ¨æŽ¨ç†æ–¹é¢çš„ç¼ºé™·ï¼Œä¾‹å¦‚è¿åå› æžœå…³ç³»ã€ç‰©ç†å®šå¾‹æˆ–å…¨å±€ä¸€è‡´æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMMGRçš„æ ¸å¿ƒæ€è·¯æ˜¯è®¾è®¡ä¸€ä¸ªæ›´å…¨é¢çš„è¯„ä¼°æ¡†æž¶ï¼Œä¸ä»…å…³æ³¨ç”Ÿæˆè§†é¢‘çš„è§†è§‰è´¨é‡ï¼Œæ›´é‡è¦çš„æ˜¯è¯„ä¼°æ¨¡åž‹åœ¨ä¸åŒé¢†åŸŸçš„æŽ¨ç†èƒ½åŠ›ã€‚é€šè¿‡æž„å»ºåŒ…å«ç‰©ç†ã€é€»è¾‘ã€ç©ºé—´å’Œæ—¶é—´æŽ¨ç†æŒ‘æˆ˜çš„æµ‹è¯•ç”¨ä¾‹ï¼Œå¯ä»¥æ›´å‡†ç¡®åœ°è¯Šæ–­æ¨¡åž‹çš„ç¼ºé™·ï¼Œå¹¶æŽ¨åŠ¨æ¨¡åž‹æœç€æ›´æ™ºèƒ½ã€æ›´å¯é çš„æ–¹å‘å‘å±•ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šMMGRæ¡†æž¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦ç»„æˆéƒ¨åˆ†ï¼š1) äº”ç§æŽ¨ç†èƒ½åŠ›ï¼šç‰©ç†ã€é€»è¾‘ã€3Dç©ºé—´ã€2Dç©ºé—´å’Œæ—¶é—´æŽ¨ç†ã€‚2) ä¸‰ä¸ªè¯„ä¼°é¢†åŸŸï¼šæŠ½è±¡æŽ¨ç†ï¼ˆARC-AGIã€æ•°ç‹¬ï¼‰ã€å…·èº«å¯¼èˆªï¼ˆçœŸå®žä¸–ç•Œ3Då¯¼èˆªå’Œå®šä½ï¼‰å’Œç‰©ç†å¸¸è¯†ï¼ˆä½“è‚²å’Œç»„åˆäº¤äº’ï¼‰ã€‚3) ç»†ç²’åº¦çš„è¯„ä¼°æŒ‡æ ‡ï¼šè¿™äº›æŒ‡æ ‡ä¸ä»…å…³æ³¨å•ä¸ªè§†é¢‘å¸§çš„è´¨é‡ï¼Œæ›´å…³æ³¨æ•´ä¸ªè§†é¢‘åºåˆ—çš„è¿žè´¯æ€§å’Œä¸€è‡´æ€§ï¼Œä»¥åŠæ¨¡åž‹åœ¨è§£å†³ç‰¹å®šæŽ¨ç†é—®é¢˜æ—¶çš„å‡†ç¡®æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šMMGRçš„å…³é”®åˆ›æ–°åœ¨äºŽå…¶å¤šæ¨¡æ€å’Œç»†ç²’åº¦çš„è¯„ä¼°æ–¹æ³•ã€‚å®ƒä¸ä»…è¯„ä¼°è§†é¢‘ç”Ÿæˆæ¨¡åž‹çš„è§†è§‰è´¨é‡ï¼Œæ›´é‡è¦çš„æ˜¯è¯„ä¼°å…¶åœ¨ä¸åŒæŽ¨ç†ä»»åŠ¡ä¸Šçš„è¡¨çŽ°ã€‚é€šè¿‡è®¾è®¡ä¸“é—¨çš„æµ‹è¯•ç”¨ä¾‹å’Œè¯„ä¼°æŒ‡æ ‡ï¼ŒMMGRå¯ä»¥æ›´å‡†ç¡®åœ°è¯Šæ–­æ¨¡åž‹çš„ç¼ºé™·ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›æŒ‡å¯¼ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒMMGRæ›´æ³¨é‡æ¨¡åž‹çš„æŽ¨ç†èƒ½åŠ›ï¼Œè€Œéžä»…ä»…æ˜¯è§†è§‰æ•ˆæžœã€‚

**å…³é”®è®¾è®¡**ï¼šMMGRçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) é’ˆå¯¹æ¯ç§æŽ¨ç†èƒ½åŠ›å’Œè¯„ä¼°é¢†åŸŸï¼Œè®¾è®¡äº†ä¸“é—¨çš„æµ‹è¯•ç”¨ä¾‹ï¼Œä¾‹å¦‚ARC-AGIç”¨äºŽè¯„ä¼°æŠ½è±¡æŽ¨ç†ï¼Œå…·èº«å¯¼èˆªç”¨äºŽè¯„ä¼°ç©ºé—´æŽ¨ç†ã€‚2) å®šä¹‰äº†ç»†ç²’åº¦çš„è¯„ä¼°æŒ‡æ ‡ï¼Œä¾‹å¦‚åœ¨å…·èº«å¯¼èˆªä»»åŠ¡ä¸­ï¼Œä¸ä»…è¯„ä¼°æ¨¡åž‹æ˜¯å¦åˆ°è¾¾ç›®æ ‡ä½ç½®ï¼Œè¿˜è¯„ä¼°å…¶è·¯å¾„çš„åˆç†æ€§å’Œæ•ˆçŽ‡ã€‚3) é‡‡ç”¨äº†å¤šæ¨¡æ€çš„è¯„ä¼°æ–¹æ³•ï¼Œä¾‹å¦‚åœ¨ç‰©ç†å¸¸è¯†ä»»åŠ¡ä¸­ï¼ŒåŒæ—¶è¯„ä¼°è§†é¢‘å’Œå›¾åƒçš„ç”Ÿæˆè´¨é‡ï¼Œä»¥ç¡®ä¿æ¨¡åž‹èƒ½å¤Ÿç†è§£å’Œæ¨¡æ‹ŸçœŸå®žä¸–ç•Œçš„ç‰©ç†è§„å¾‹ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒçŽ°æœ‰é¢†å…ˆçš„è§†é¢‘æ¨¡åž‹ï¼ˆå¦‚Veo-3ã€Sora-2ã€Wan-2.2ï¼‰å’Œå›¾åƒæ¨¡åž‹ï¼ˆå¦‚Nano-bananaã€GPT-4o-imageï¼‰åœ¨MMGRåŸºå‡†ä¸Šè¡¨çŽ°å‡ºæ˜¾è‘—çš„æ€§èƒ½å·®è·ã€‚æ¨¡åž‹åœ¨ç‰©ç†å¸¸è¯†ä»»åŠ¡ä¸Šè¡¨çŽ°å°šå¯ï¼Œä½†åœ¨æŠ½è±¡æŽ¨ç†ï¼ˆARC-AGIå‡†ç¡®çŽ‡ä½ŽäºŽ10%ï¼‰å’Œé•¿ç¨‹ç©ºé—´è§„åˆ’æ–¹é¢è¡¨çŽ°ä¸ä½³ï¼Œçªæ˜¾äº†çŽ°æœ‰æ¨¡åž‹åœ¨æŽ¨ç†èƒ½åŠ›æ–¹é¢çš„ä¸è¶³ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

MMGRçš„ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽæå‡è§†é¢‘ç”Ÿæˆæ¨¡åž‹åœ¨è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººæŽ§åˆ¶ã€æ¸¸æˆAIç­‰é¢†åŸŸçš„æ€§èƒ½ã€‚é€šè¿‡æ›´å‡†ç¡®åœ°è¯„ä¼°å’Œæ”¹è¿›æ¨¡åž‹çš„æŽ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥ä½¿å…¶åœ¨å¤æ‚çŽ¯å¢ƒä¸­åšå‡ºæ›´å¯é ã€æ›´åˆç†çš„å†³ç­–ï¼Œä»Žè€Œæé«˜ç³»ç»Ÿçš„å®‰å…¨æ€§å’Œæ•ˆçŽ‡ã€‚æ­¤å¤–ï¼Œè¯¥åŸºå‡†ä¹Ÿæœ‰åŠ©äºŽæŽ¨åŠ¨é€šç”¨äººå·¥æ™ºèƒ½çš„å‘å±•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Video foundation models generate visually realistic and temporally coherent content, but their reliability as world simulators depends on whether they capture physical, logical, and spatial constraints. Existing metrics such as Frechet Video Distance (FVD) emphasize perceptual quality and overlook reasoning failures, including violations of causality, physics, and global consistency. We introduce MMGR (Multi-Modal Generative Reasoning Evaluation and Benchmark), a principled evaluation framework based on five reasoning abilities: Physical, Logical, 3D Spatial, 2D Spatial, and Temporal. MMGR evaluates generative reasoning across three domains: Abstract Reasoning (ARC-AGI, Sudoku), Embodied Navigation (real-world 3D navigation and localization), and Physical Commonsense (sports and compositional interactions). MMGR applies fine-grained metrics that require holistic correctness across both video and image generation. We benchmark leading video models (Veo-3, Sora-2, Wan-2.2) and image models (Nano-banana, Nano-banana Pro, GPT-4o-image, Qwen-image), revealing strong performance gaps across domains. Models show moderate success on Physical Commonsense tasks but perform poorly on Abstract Reasoning (below 10 percent accuracy on ARC-AGI) and struggle with long-horizon spatial planning in embodied settings. Our analysis highlights key limitations in current models, including overreliance on perceptual data, weak global state consistency, and objectives that reward visual plausibility over causal correctness. MMGR offers a unified diagnostic benchmark and a path toward reasoning-aware generative world models.

