---
layout: default
title: Scalable Frameworks for Real-World Audio-Visual Speech Recognition
---

# Scalable Frameworks for Real-World Audio-Visual Speech Recognition

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.14083" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.14083v1</a>
  <a href="https://arxiv.org/pdf/2512.14083.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14083v1" onclick="toggleFavorite(this, '2512.14083v1', 'Scalable Frameworks for Real-World Audio-Visual Speech Recognition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sungnyun Kim

**åˆ†ç±»**: eess.AS, cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: PhD Dissertation

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¯æ‰©å±•æ¡†æ¶ï¼Œè§£å†³çœŸå®åœºæ™¯ä¸‹éŸ³é¢‘-è§†è§‰è¯­éŸ³è¯†åˆ«çš„é²æ£’æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `éŸ³é¢‘-è§†è§‰è¯­éŸ³è¯†åˆ«` `å¤šæ¨¡æ€å­¦ä¹ ` `é²æ£’æ€§` `å¯æ‰©å±•æ€§` `æ·±åº¦å­¦ä¹ ` `ç‰¹å¾è¡¨ç¤ºå­¦ä¹ ` `è‡ªé€‚åº”æ¶æ„` `ç³»ç»Ÿé›†æˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰AVSRç³»ç»Ÿåœ¨çœŸå®åœºæ™¯ä¸­å—å£°å­¦å™ªå£°å’Œè§†è§‰å¹²æ‰°å½±å“ï¼Œæ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œç¼ºä¹é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚
2. è®ºæ–‡æå‡ºåˆ†å±‚æ–¹æ³•ï¼Œåˆ†åˆ«åœ¨è¡¨ç¤ºå±‚ã€æ¶æ„å±‚å’Œç³»ç»Ÿå±‚è¿›è¡Œä¼˜åŒ–ï¼Œæå‡AVSRç³»ç»Ÿåœ¨çœŸå®ç¯å¢ƒä¸‹çš„æ€§èƒ½ã€‚
3. é€šè¿‡æ„å»ºç»Ÿä¸€æ¨¡å‹å­¦ä¹ é²æ£’ç‰¹å¾ã€è‡ªé€‚åº”åˆ†é…è®¡ç®—èµ„æºã€é›†æˆå¤§è§„æ¨¡åŸºç¡€æ¨¡å‹ç­‰æ‰‹æ®µï¼Œæé«˜è¯†åˆ«ç²¾åº¦ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬è®ºæ–‡è‡´åŠ›äºè§£å†³éŸ³é¢‘-è§†è§‰è¯­éŸ³è¯†åˆ«(AVSR)ç³»ç»Ÿåœ¨çœŸå®ç¯å¢ƒä¸­æ€§èƒ½æ˜¾è‘—ä¸‹é™çš„é—®é¢˜ï¼Œè¯¥ç¯å¢ƒçš„ç‰¹ç‚¹æ˜¯ä¸å¯é¢„æµ‹çš„å£°å­¦å™ªå£°å’Œè§†è§‰å¹²æ‰°ã€‚è®ºæ–‡æå‡ºäº†ä¸€ç§ç³»ç»Ÿçš„ã€åˆ†å±‚çš„è§£å†³æ–¹æ¡ˆï¼Œä»¥åœ¨è¡¨ç¤ºã€æ¶æ„å’Œç³»ç»Ÿå±‚é¢å®ç°é²æ£’çš„å¯æ‰©å±•æ€§ã€‚åœ¨è¡¨ç¤ºå±‚é¢ï¼Œç ”ç©¶äº†æ„å»ºç»Ÿä¸€æ¨¡å‹çš„æ–¹æ³•ï¼Œè¯¥æ¨¡å‹å­¦ä¹ å¯¹å„ç§çœŸå®ç¯å¢ƒå¹²æ‰°å…·æœ‰å†…åœ¨é²æ£’æ€§çš„éŸ³é¢‘-è§†è§‰ç‰¹å¾ï¼Œä»è€Œæ— éœ€ä¸“ç”¨æ¨¡å—å³å¯æ¨å¹¿åˆ°æ–°ç¯å¢ƒã€‚åœ¨æ¶æ„å±‚é¢ï¼Œæ¢ç´¢äº†å¦‚ä½•æœ‰æ•ˆåœ°æ‰©å±•æ¨¡å‹å®¹é‡ï¼ŒåŒæ—¶ç¡®ä¿è‡ªé€‚åº”å’Œå¯é åœ°ä½¿ç”¨å¤šæ¨¡æ€è¾“å…¥ï¼Œå¼€å‘äº†ä¸€ä¸ªåŸºäºè¾“å…¥ç‰¹å¾æ™ºèƒ½åˆ†é…è®¡ç®—èµ„æºçš„æ¡†æ¶ã€‚åœ¨ç³»ç»Ÿå±‚é¢ï¼Œæå‡ºäº†é€šè¿‡ä¸å¤§è§„æ¨¡åŸºç¡€æ¨¡å‹è¿›è¡Œæ¨¡å—åŒ–é›†æˆæ¥æ‰©å±•ç³»ç»ŸåŠŸèƒ½çš„æ–¹æ³•ï¼Œåˆ©ç”¨å®ƒä»¬å¼ºå¤§çš„è®¤çŸ¥å’Œç”Ÿæˆèƒ½åŠ›æ¥æœ€å¤§åŒ–æœ€ç»ˆè¯†åˆ«ç²¾åº¦ã€‚é€šè¿‡åœ¨ä¸‰ä¸ªå±‚é¢ç³»ç»Ÿåœ°æä¾›è§£å†³æ–¹æ¡ˆï¼Œæœ¬è®ºæ–‡æ—¨åœ¨æ„å»ºä¸‹ä¸€ä»£é²æ£’ä¸”å¯æ‰©å±•çš„AVSRç³»ç»Ÿï¼Œåœ¨å®é™…åº”ç”¨ä¸­å…·æœ‰é«˜å¯é æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³çœŸå®åœºæ™¯ä¸‹éŸ³é¢‘-è§†è§‰è¯­éŸ³è¯†åˆ«ï¼ˆAVSRï¼‰ç³»ç»Ÿæ€§èƒ½ä¸‹é™çš„é—®é¢˜ã€‚ç°æœ‰AVSRç³»ç»Ÿåœ¨å®éªŒå®¤ç¯å¢ƒä¸‹è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨å®é™…åº”ç”¨ä¸­ï¼Œç”±äºå­˜åœ¨å„ç§å™ªå£°å¹²æ‰°ï¼ˆå¦‚èƒŒæ™¯å™ªå£°ã€é®æŒ¡ç­‰ï¼‰ï¼Œæ€§èƒ½ä¼šæ˜¾è‘—é™ä½ã€‚ç°æœ‰çš„è§£å†³æ–¹æ¡ˆé€šå¸¸é’ˆå¯¹ç‰¹å®šå™ªå£°è¿›è¡Œä¼˜åŒ–ï¼Œç¼ºä¹é€šç”¨æ€§å’Œé²æ£’æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é‡‡ç”¨ä¸€ç§åˆ†å±‚çš„æ–¹æ³•ï¼Œä»è¡¨ç¤ºã€æ¶æ„å’Œç³»ç»Ÿä¸‰ä¸ªå±‚é¢æ¥æå‡AVSRç³»ç»Ÿçš„é²æ£’æ€§å’Œå¯æ‰©å±•æ€§ã€‚é€šè¿‡å­¦ä¹ å¯¹å™ªå£°å…·æœ‰ä¸å˜æ€§çš„ç‰¹å¾è¡¨ç¤ºï¼Œè®¾è®¡è‡ªé€‚åº”çš„æ¶æ„ï¼Œå¹¶é›†æˆå¤–éƒ¨çŸ¥è¯†ï¼Œä»è€Œæé«˜ç³»ç»Ÿåœ¨å¤æ‚ç¯å¢ƒä¸‹çš„è¯†åˆ«ç²¾åº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡æå‡ºçš„æ¡†æ¶åŒ…å«ä¸‰ä¸ªä¸»è¦éƒ¨åˆ†ï¼š1) **é²æ£’ç‰¹å¾è¡¨ç¤ºå­¦ä¹ **ï¼šè®¾è®¡ç»Ÿä¸€çš„éŸ³é¢‘-è§†è§‰æ¨¡å‹ï¼Œå­¦ä¹ å¯¹å„ç§å™ªå£°å…·æœ‰é²æ£’æ€§çš„ç‰¹å¾ã€‚2) **è‡ªé€‚åº”æ¶æ„è®¾è®¡**ï¼šå¼€å‘èƒ½å¤Ÿæ ¹æ®è¾“å…¥ç‰¹å¾è‡ªé€‚åº”åˆ†é…è®¡ç®—èµ„æºçš„æ¶æ„ï¼Œæé«˜è®¡ç®—æ•ˆç‡ã€‚3) **ç³»ç»Ÿé›†æˆ**ï¼šå°†AVSRç³»ç»Ÿä¸å¤§è§„æ¨¡åŸºç¡€æ¨¡å‹é›†æˆï¼Œåˆ©ç”¨åŸºç¡€æ¨¡å‹çš„è®¤çŸ¥å’Œç”Ÿæˆèƒ½åŠ›æ¥æå‡è¯†åˆ«ç²¾åº¦ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§ç³»ç»Ÿæ€§çš„åˆ†å±‚æ–¹æ³•ï¼Œå°†AVSRç³»ç»Ÿçš„é²æ£’æ€§é—®é¢˜åˆ†è§£ä¸ºè¡¨ç¤ºã€æ¶æ„å’Œç³»ç»Ÿä¸‰ä¸ªå±‚é¢ï¼Œå¹¶åˆ†åˆ«æå‡ºäº†ç›¸åº”çš„è§£å†³æ–¹æ¡ˆã€‚è¿™ç§åˆ†å±‚æ–¹æ³•ä½¿å¾—ç³»ç»Ÿæ›´æ˜“äºæ‰©å±•å’Œç»´æŠ¤ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ›´å¥½åœ°åº”å¯¹çœŸå®åœºæ™¯ä¸­çš„å„ç§æŒ‘æˆ˜ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨é²æ£’ç‰¹å¾è¡¨ç¤ºå­¦ä¹ æ–¹é¢ï¼Œå¯èƒ½é‡‡ç”¨äº†å¯¹æ¯”å­¦ä¹ æˆ–å¯¹æŠ—è®­ç»ƒç­‰æ–¹æ³•ï¼Œä»¥æé«˜ç‰¹å¾å¯¹å™ªå£°çš„ä¸å˜æ€§ã€‚åœ¨è‡ªé€‚åº”æ¶æ„è®¾è®¡æ–¹é¢ï¼Œå¯èƒ½é‡‡ç”¨äº†æ³¨æ„åŠ›æœºåˆ¶æˆ–åŠ¨æ€è·¯ç”±ç­‰æ–¹æ³•ï¼Œä»¥æ ¹æ®è¾“å…¥ç‰¹å¾çš„é‡è¦æ€§è‡ªé€‚åº”åœ°åˆ†é…è®¡ç®—èµ„æºã€‚åœ¨ç³»ç»Ÿé›†æˆæ–¹é¢ï¼Œå¯èƒ½é‡‡ç”¨äº†å¾®è°ƒæˆ–çŸ¥è¯†è’¸é¦ç­‰æ–¹æ³•ï¼Œå°†å¤§è§„æ¨¡åŸºç¡€æ¨¡å‹çš„çŸ¥è¯†è¿ç§»åˆ°AVSRç³»ç»Ÿã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡é‡ç‚¹åœ¨äºæ¡†æ¶çš„æ­å»ºä¸è®¾è®¡æ€è·¯ï¼Œå…·ä½“çš„å®éªŒç»“æœéœ€è¦åœ¨è®ºæ–‡ä¸­æŸ¥æ‰¾ã€‚å¯ä»¥é¢„æœŸçš„æ˜¯ï¼Œé€šè¿‡æ‰€æå‡ºçš„åˆ†å±‚æ–¹æ³•ï¼ŒAVSRç³»ç»Ÿåœ¨å„ç§å™ªå£°ç¯å¢ƒä¸‹çš„è¯†åˆ«ç²¾åº¦å°†å¾—åˆ°æ˜¾è‘—æå‡ã€‚ä¸ä¼ ç»Ÿçš„AVSRç³»ç»Ÿç›¸æ¯”ï¼Œè¯¥ç³»ç»Ÿåœ¨é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›æ–¹é¢å…·æœ‰æ˜æ˜¾ä¼˜åŠ¿ã€‚å…·ä½“æ€§èƒ½æå‡å¹…åº¦å–å†³äºå®éªŒæ•°æ®é›†å’Œè¯„ä¼°æŒ‡æ ‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºå„ç§éœ€è¦è¯­éŸ³è¯†åˆ«çš„çœŸå®åœºæ™¯ï¼Œä¾‹å¦‚æ™ºèƒ½å®¶å±…ã€è½¦è½½è¯­éŸ³åŠ©æ‰‹ã€è§†é¢‘ä¼šè®®ã€å®‰é˜²ç›‘æ§ç­‰ã€‚é€šè¿‡æé«˜AVSRç³»ç»Ÿåœ¨å™ªå£°ç¯å¢ƒä¸‹çš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ï¼Œå¯ä»¥æ”¹å–„ç”¨æˆ·ä½“éªŒï¼Œæé«˜å·¥ä½œæ•ˆç‡ï¼Œå¹¶ä¸ºç›¸å…³åº”ç”¨å¸¦æ¥æ›´å¤§çš„å•†ä¸šä»·å€¼å’Œç¤¾ä¼šæ•ˆç›Šã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶è¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–å¤šæ¨¡æ€è¯†åˆ«ä»»åŠ¡ï¼Œä¾‹å¦‚å”‡è¯­è¯†åˆ«ã€æƒ…æ„Ÿè¯†åˆ«ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The practical deployment of Audio-Visual Speech Recognition (AVSR) systems is fundamentally challenged by significant performance degradation in real-world environments, characterized by unpredictable acoustic noise and visual interference. This dissertation posits that a systematic, hierarchical approach is essential to overcome these challenges, achieving the robust scalability at the representation, architecture, and system levels. At the representation level, we investigate methods for building a unified model that learns audio-visual features inherently robust to diverse real-world corruptions, thereby enabling generalization to new environments without specialized modules. To address architectural scalability, we explore how to efficiently expand model capacity while ensuring the adaptive and reliable use of multimodal inputs, developing a framework that intelligently allocates computational resources based on the input characteristics. Finally, at the system level, we present methods to expand the system's functionality through modular integration with large-scale foundation models, leveraging their powerful cognitive and generative capabilities to maximize final recognition accuracy. By systematically providing solutions at each of these three levels, this dissertation aims to build a next-generation, robust, and scalable AVSR system with high reliability in real-world applications.

