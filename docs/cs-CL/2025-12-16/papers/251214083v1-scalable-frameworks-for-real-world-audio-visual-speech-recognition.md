---
layout: default
title: Scalable Frameworks for Real-World Audio-Visual Speech Recognition
---

# Scalable Frameworks for Real-World Audio-Visual Speech Recognition

**arXiv**: [2512.14083v1](https://arxiv.org/abs/2512.14083) | [PDF](https://arxiv.org/pdf/2512.14083.pdf)

**ä½œè€…**: Sungnyun Kim

**åˆ†ç±»**: eess.AS, cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: PhD Dissertation

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåˆ†å±‚å¯æ‰©å±•æ¡†æž¶ä»¥è§£å†³çœŸå®žä¸–ç•ŒéŸ³é¢‘-è§†è§‰è¯­éŸ³è¯†åˆ«ä¸­çš„é²æ£’æ€§é—®é¢˜**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `éŸ³é¢‘-è§†è§‰è¯­éŸ³è¯†åˆ«` `å¤šæ¨¡æ€èžåˆ` `é²æ£’æ€§å­¦ä¹ ` `å¯æ‰©å±•æž¶æž„` `è‡ªé€‚åº”è®¡ç®—` `åŸºç¡€æ¨¡åž‹é›†æˆ` `çœŸå®žä¸–ç•Œåº”ç”¨` `åˆ†å±‚æ¡†æž¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçœŸå®žä¸–ç•ŒAVSRç³»ç»Ÿé¢ä¸´ä¸å¯é¢„æµ‹çš„å£°å­¦å™ªå£°å’Œè§†è§‰å¹²æ‰°ï¼Œå¯¼è‡´æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼ŒçŽ°æœ‰æ–¹æ³•ç¼ºä¹ç³»ç»Ÿæ€§çš„é²æ£’å¯æ‰©å±•è§£å†³æ–¹æ¡ˆã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨åˆ†å±‚æ–¹æ³•ï¼Œåœ¨è¡¨ç¤ºã€æž¶æž„å’Œç³»ç»Ÿä¸‰ä¸ªå±‚é¢åˆ†åˆ«æž„å»ºé²æ£’ç‰¹å¾ã€è‡ªé€‚åº”æž¶æž„å’Œæ¨¡å—åŒ–é›†æˆï¼Œå®žçŽ°æ•´ä½“å¯æ‰©å±•æ€§ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šé€šè¿‡åˆ†å±‚æ¡†æž¶ï¼Œç³»ç»Ÿåœ¨å™ªå£°å’Œå¹²æ‰°çŽ¯å¢ƒä¸‹è¡¨çŽ°å‡ºæ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›å’Œè¯†åˆ«å‡†ç¡®çŽ‡ï¼Œå…·ä½“æå‡å¹…åº¦æœªçŸ¥ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éŸ³é¢‘-è§†è§‰è¯­éŸ³è¯†åˆ«ï¼ˆAVSRï¼‰ç³»ç»Ÿåœ¨å®žé™…éƒ¨ç½²ä¸­é¢ä¸´æ ¹æœ¬æ€§æŒ‘æˆ˜ï¼Œå³åœ¨çœŸå®žä¸–ç•ŒçŽ¯å¢ƒä¸­ï¼ˆä»¥ä¸å¯é¢„æµ‹çš„å£°å­¦å™ªå£°å’Œè§†è§‰å¹²æ‰°ä¸ºç‰¹å¾ï¼‰æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚æœ¬è®ºæ–‡è®¤ä¸ºï¼Œç³»ç»Ÿæ€§çš„åˆ†å±‚æ–¹æ³•å¯¹äºŽå…‹æœè¿™äº›æŒ‘æˆ˜è‡³å…³é‡è¦ï¼Œæ—¨åœ¨åœ¨è¡¨ç¤ºã€æž¶æž„å’Œç³»ç»Ÿä¸‰ä¸ªå±‚é¢å®žçŽ°é²æ£’çš„å¯æ‰©å±•æ€§ã€‚åœ¨è¡¨ç¤ºå±‚é¢ï¼Œæˆ‘ä»¬ç ”ç©¶æž„å»ºç»Ÿä¸€æ¨¡åž‹çš„æ–¹æ³•ï¼Œè¯¥æ¨¡åž‹å­¦ä¹ å¯¹å¤šæ ·çœŸå®žä¸–ç•Œå¹²æ‰°å…·æœ‰å†…åœ¨é²æ£’æ€§çš„éŸ³é¢‘-è§†è§‰ç‰¹å¾ï¼Œä»Žè€Œæ— éœ€ä¸“é—¨æ¨¡å—å³å¯æ³›åŒ–åˆ°æ–°çŽ¯å¢ƒã€‚ä¸ºè§£å†³æž¶æž„å¯æ‰©å±•æ€§ï¼Œæˆ‘ä»¬æŽ¢ç´¢å¦‚ä½•é«˜æ•ˆæ‰©å±•æ¨¡åž‹å®¹é‡ï¼ŒåŒæ—¶ç¡®ä¿å¤šæ¨¡æ€è¾“å…¥çš„è‡ªé€‚åº”å’Œå¯é ä½¿ç”¨ï¼Œå¼€å‘äº†ä¸€ä¸ªåŸºäºŽè¾“å…¥ç‰¹å¾æ™ºèƒ½åˆ†é…è®¡ç®—èµ„æºçš„æ¡†æž¶ã€‚æœ€åŽï¼Œåœ¨ç³»ç»Ÿå±‚é¢ï¼Œæˆ‘ä»¬æå‡ºé€šè¿‡ä¸Žå¤§è§„æ¨¡åŸºç¡€æ¨¡åž‹çš„æ¨¡å—åŒ–é›†æˆæ¥æ‰©å±•ç³»ç»ŸåŠŸèƒ½çš„æ–¹æ³•ï¼Œåˆ©ç”¨å…¶å¼ºå¤§çš„è®¤çŸ¥å’Œç”Ÿæˆèƒ½åŠ›æœ€å¤§åŒ–æœ€ç»ˆè¯†åˆ«å‡†ç¡®çŽ‡ã€‚é€šè¿‡åœ¨è¿™ä¸‰ä¸ªå±‚é¢ç³»ç»Ÿæ€§åœ°æä¾›è§£å†³æ–¹æ¡ˆï¼Œæœ¬è®ºæ–‡æ—¨åœ¨æž„å»ºä¸€ä¸ªåœ¨çœŸå®žä¸–ç•Œåº”ç”¨ä¸­å…·æœ‰é«˜å¯é æ€§çš„ä¸‹ä¸€ä»£é²æ£’ä¸”å¯æ‰©å±•çš„AVSRç³»ç»Ÿã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³çœŸå®žä¸–ç•ŒéŸ³é¢‘-è§†è§‰è¯­éŸ³è¯†åˆ«ï¼ˆAVSRï¼‰ç³»ç»Ÿåœ¨ä¸å¯é¢„æµ‹å£°å­¦å™ªå£°å’Œè§†è§‰å¹²æ‰°ä¸‹çš„æ€§èƒ½é€€åŒ–é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•çš„ç—›ç‚¹åœ¨äºŽç¼ºä¹ç³»ç»Ÿæ€§çš„é²æ£’å¯æ‰©å±•è§£å†³æ–¹æ¡ˆï¼Œé€šå¸¸ä¾èµ–äºŽç‰¹å®šçŽ¯å¢ƒä¸‹çš„ä¸“é—¨æ¨¡å—ï¼Œéš¾ä»¥æ³›åŒ–åˆ°æ–°åœºæ™¯ï¼Œä¸”æ¨¡åž‹æ‰©å±•æ•ˆçŽ‡ä½Žä¸‹ï¼Œæ— æ³•è‡ªé€‚åº”å¤„ç†å¤šæ¨¡æ€è¾“å…¥ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºä¸€ä¸ªåˆ†å±‚å¯æ‰©å±•æ¡†æž¶ï¼Œé€šè¿‡åœ¨è¡¨ç¤ºã€æž¶æž„å’Œç³»ç»Ÿä¸‰ä¸ªå±‚é¢åˆ†åˆ«æž„å»ºé²æ£’æ€§ã€è‡ªé€‚åº”æ€§å’Œé›†æˆèƒ½åŠ›ï¼Œå®žçŽ°æ•´ä½“ç³»ç»Ÿçš„ç¨³å¥æ‰©å±•ã€‚è¿™ç§è®¾è®¡åŸºäºŽçœŸå®žä¸–ç•ŒçŽ¯å¢ƒçš„å¤æ‚æ€§ï¼Œéœ€è¦ä»Žç‰¹å¾å­¦ä¹ åˆ°ç³»ç»Ÿé›†æˆçš„å…¨æ–¹ä½ä¼˜åŒ–ï¼Œä»¥åº”å¯¹å¤šæ ·å¹²æ‰°å¹¶æœ€å¤§åŒ–è¯†åˆ«å‡†ç¡®çŽ‡ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æž¶æž„åˆ†ä¸ºä¸‰ä¸ªå±‚æ¬¡ï¼šè¡¨ç¤ºå±‚æž„å»ºç»Ÿä¸€æ¨¡åž‹å­¦ä¹ é²æ£’éŸ³é¢‘-è§†è§‰ç‰¹å¾ï¼›æž¶æž„å±‚å¼€å‘è‡ªé€‚åº”æ¡†æž¶ï¼Œæ ¹æ®è¾“å…¥ç‰¹å¾æ™ºèƒ½åˆ†é…è®¡ç®—èµ„æºä»¥æ‰©å±•æ¨¡åž‹å®¹é‡ï¼›ç³»ç»Ÿå±‚é€šè¿‡æ¨¡å—åŒ–é›†æˆå¤§è§„æ¨¡åŸºç¡€æ¨¡åž‹ï¼Œåˆ©ç”¨å…¶è®¤çŸ¥å’Œç”Ÿæˆèƒ½åŠ›å¢žå¼ºåŠŸèƒ½ã€‚æµç¨‹ä¸Šï¼Œä»Žåº•å±‚ç‰¹å¾æå–åˆ°é«˜å±‚ç³»ç»Ÿé›†æˆï¼Œé€å±‚é€’è¿›ä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°æ˜¯åˆ†å±‚å¯æ‰©å±•æ¡†æž¶ï¼Œå°†é²æ£’æ€§é—®é¢˜åˆ†è§£ä¸ºè¡¨ç¤ºã€æž¶æž„å’Œç³»ç»Ÿä¸‰ä¸ªå±‚é¢çš„å­é—®é¢˜ï¼Œå¹¶åˆ†åˆ«æä¾›ç³»ç»Ÿæ€§è§£å†³æ–¹æ¡ˆã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºŽï¼Œå®ƒé¿å…äº†å•ä¸€æ¨¡å—çš„å±€é™æ€§ï¼Œé€šè¿‡æ•´ä½“è®¾è®¡å®žçŽ°ä»Žç‰¹å¾åˆ°ç³»ç»Ÿçš„å…¨é¢å¯æ‰©å±•æ€§ï¼Œä»Žè€Œæ›´å¥½åœ°é€‚åº”çœŸå®žä¸–ç•ŒçŽ¯å¢ƒçš„åŠ¨æ€å˜åŒ–ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è¡¨ç¤ºå±‚ï¼Œå…³é”®è®¾è®¡åŒ…æ‹¬æž„å»ºç»Ÿä¸€æ¨¡åž‹ä»¥å­¦ä¹ å¯¹å¤šæ ·å¹²æ‰°å…·æœ‰å†…åœ¨é²æ£’æ€§çš„ç‰¹å¾ï¼Œå¯èƒ½æ¶‰åŠå¤šä»»åŠ¡å­¦ä¹ æˆ–æ•°æ®å¢žå¼ºæŠ€æœ¯ï¼›åœ¨æž¶æž„å±‚ï¼Œè®¾è®¡è‡ªé€‚åº”æ¡†æž¶ï¼ŒåŸºäºŽè¾“å…¥ç‰¹å¾ï¼ˆå¦‚å™ªå£°æ°´å¹³æˆ–è§†è§‰è´¨é‡ï¼‰åŠ¨æ€è°ƒæ•´è®¡ç®—èµ„æºåˆ†é…ï¼Œå¯èƒ½ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶æˆ–è½»é‡åŒ–æ¨¡å—ï¼›åœ¨ç³»ç»Ÿå±‚ï¼Œå…³é”®è®¾è®¡æ˜¯æ¨¡å—åŒ–é›†æˆå¤§è§„æ¨¡åŸºç¡€æ¨¡åž‹ï¼Œé€šè¿‡æŽ¥å£è®¾è®¡æˆ–å¾®è°ƒç­–ç•¥ï¼Œåˆ©ç”¨å…¶é¢„è®­ç»ƒèƒ½åŠ›æå‡è¯†åˆ«å‡†ç¡®çŽ‡ã€‚å…·ä½“å‚æ•°è®¾ç½®ã€æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æž„ç»†èŠ‚æœªçŸ¥ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

æœ€é‡è¦çš„å®žéªŒç»“æžœåŒ…æ‹¬ï¼šç³»ç»Ÿåœ¨çœŸå®žä¸–ç•Œå™ªå£°å’Œè§†è§‰å¹²æ‰°çŽ¯å¢ƒä¸‹è¡¨çŽ°å‡ºæ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›ï¼Œæ— éœ€ä¸“é—¨æ¨¡å—å³å¯é€‚åº”æ–°åœºæ™¯ï¼›é€šè¿‡è‡ªé€‚åº”æž¶æž„ï¼Œæ¨¡åž‹åœ¨æ‰©å±•å®¹é‡æ—¶ä¿æŒäº†è®¡ç®—æ•ˆçŽ‡ï¼Œå…·ä½“æ€§èƒ½æ•°æ®æœªçŸ¥ï¼›æ¨¡å—åŒ–é›†æˆå¤§è§„æ¨¡åŸºç¡€æ¨¡åž‹åŽï¼Œè¯†åˆ«å‡†ç¡®çŽ‡å¾—åˆ°æœ€å¤§åŒ–æå‡ï¼Œå¯¹æ¯”åŸºçº¿å¯èƒ½åŒ…æ‹¬ä¼ ç»ŸAVSRæ–¹æ³•æˆ–å•æ¨¡æ€ç³»ç»Ÿï¼Œæå‡å¹…åº¦æœªçŸ¥ã€‚æ•´ä½“æ¡†æž¶åœ¨ä¸‰ä¸ªå±‚é¢å‡éªŒè¯äº†å¯æ‰©å±•æ€§å’Œé²æ£’æ€§çš„æœ‰æ•ˆæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨çœŸå®žä¸–ç•ŒéŸ³é¢‘-è§†è§‰è¯­éŸ³è¯†åˆ«é¢†åŸŸå…·æœ‰å¹¿æ³›æ½œåœ¨åº”ç”¨ï¼Œå¦‚æ™ºèƒ½åŠ©æ‰‹ã€è§†é¢‘ä¼šè®®ç³»ç»Ÿã€è‡ªåŠ¨é©¾é©¶ä¸­çš„è½¦å†…äº¤äº’ã€åŒ»ç–—è¾…åŠ©è®¾å¤‡ï¼ˆå¦‚åŠ©å¬å™¨æˆ–è¯­éŸ³åº·å¤å·¥å…·ï¼‰ä»¥åŠå®‰å…¨ç›‘æŽ§åœºæ™¯ã€‚å…¶å®žé™…ä»·å€¼åœ¨äºŽæå‡ç³»ç»Ÿåœ¨å™ªå£°å’Œå¹²æ‰°çŽ¯å¢ƒä¸‹çš„é²æ£’æ€§å’Œå¯é æ€§ï¼Œæœªæ¥å¯èƒ½æŽ¨åŠ¨AVSRæŠ€æœ¯å‘æ›´å¤æ‚ã€åŠ¨æ€çš„çœŸå®žä¸–ç•Œéƒ¨ç½²è¿ˆè¿›ï¼Œä¿ƒè¿›å¤šæ¨¡æ€äººå·¥æ™ºèƒ½çš„å®žç”¨åŒ–å‘å±•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The practical deployment of Audio-Visual Speech Recognition (AVSR) systems is fundamentally challenged by significant performance degradation in real-world environments, characterized by unpredictable acoustic noise and visual interference. This dissertation posits that a systematic, hierarchical approach is essential to overcome these challenges, achieving the robust scalability at the representation, architecture, and system levels. At the representation level, we investigate methods for building a unified model that learns audio-visual features inherently robust to diverse real-world corruptions, thereby enabling generalization to new environments without specialized modules. To address architectural scalability, we explore how to efficiently expand model capacity while ensuring the adaptive and reliable use of multimodal inputs, developing a framework that intelligently allocates computational resources based on the input characteristics. Finally, at the system level, we present methods to expand the system's functionality through modular integration with large-scale foundation models, leveraging their powerful cognitive and generative capabilities to maximize final recognition accuracy. By systematically providing solutions at each of these three levels, this dissertation aims to build a next-generation, robust, and scalable AVSR system with high reliability in real-world applications.

