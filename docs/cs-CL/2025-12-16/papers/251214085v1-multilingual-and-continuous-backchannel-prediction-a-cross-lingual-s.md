---
layout: default
title: Multilingual and Continuous Backchannel Prediction: A Cross-lingual Study
---

# Multilingual and Continuous Backchannel Prediction: A Cross-lingual Study

**arXiv**: [2512.14085v1](https://arxiv.org/abs/2512.14085) | [PDF](https://arxiv.org/pdf/2512.14085.pdf)

**ä½œè€…**: Koji Inoue, Mikey Elmers, Yahui Fu, Zi Haur Pang, Taiga Mori, Divesh Lala, Keiko Ochi, Tatsuya Kawahara

**åˆ†ç±»**: cs.CL, cs.HC, cs.SD

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: This paper has been accepted for presentation at International Workshop on Spoken Dialogue Systems Technology 2026 (IWSDS 2026) and represents the author's version of the work

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§å¤šè¯­ç§è¿žç»­æ€§Backchannelé¢„æµ‹æ¨¡åž‹ï¼Œç”¨äºŽè·¨è¯­è¨€æ—¶åºè¡Œä¸ºç ”ç©¶ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **äººå½¢/åŒè¶³æœºå™¨äºº (Humanoid & Biped)** **3Dæ„ŸçŸ¥ä¸ŽçŠ¶æ€ä¼°è®¡ (Perception & State Est)**

**å…³é”®è¯**: `Backchannelé¢„æµ‹` `å¤šè¯­ç§å­¦ä¹ ` `è·¨è¯­è¨€ç ”ç©¶` `Transformer` `å£è¯­å¯¹è¯ç³»ç»Ÿ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰Backchannelé¢„æµ‹æ¨¡åž‹ç¼ºä¹è·¨è¯­è¨€æ³›åŒ–èƒ½åŠ›ï¼Œéš¾ä»¥æ•æ‰ä¸åŒè¯­è¨€çš„æ—¶åºç‰¹ç‚¹ã€‚
2. æå‡ºåŸºäºŽTransformerçš„å¤šè¯­ç§è”åˆè®­ç»ƒæ¨¡åž‹ï¼Œå­¦ä¹ è¯­è¨€é€šç”¨çº¿ç´¢å’Œç‰¹å®šè¯­è¨€æ—¶åºæ¨¡å¼ã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ¨¡åž‹åœ¨ä¸‰ç§è¯­è¨€ä¸Šå‡è¡¨çŽ°è‰¯å¥½ï¼Œå¹¶æ­ç¤ºäº†ä¸åŒè¯­è¨€Backchannelé¢„æµ‹çš„å…³é”®çº¿ç´¢å·®å¼‚ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äºŽæ—¥è¯­ã€è‹±è¯­å’Œæ±‰è¯­çš„å¤šè¯­ç§è¿žç»­æ€§Backchannelé¢„æµ‹æ¨¡åž‹ï¼Œå¹¶åˆ©ç”¨è¯¥æ¨¡åž‹ç ”ç©¶äº†è·¨è¯­è¨€çš„æ—¶åºè¡Œä¸ºã€‚è¯¥æ¨¡åž‹åŸºäºŽTransformeræž¶æž„ï¼Œåœ¨å¸§çº§åˆ«ä¸Šè¿è¡Œï¼Œå¹¶ä½¿ç”¨å¤§çº¦300å°æ—¶çš„äºŒå…ƒå¯¹è¯æ•°æ®è¿›è¡Œè”åˆè®­ç»ƒï¼ŒåŒæ—¶åŒ…å«è¾…åŠ©ä»»åŠ¡ã€‚åœ¨æ‰€æœ‰ä¸‰ç§è¯­è¨€ä¸­ï¼Œå¤šè¯­ç§æ¨¡åž‹éƒ½è¾¾åˆ°æˆ–è¶…è¿‡äº†å•è¯­åŸºçº¿ï¼Œè¡¨æ˜Žè¯¥æ¨¡åž‹å­¦ä¹ äº†è¯­è¨€é€šç”¨çš„çº¿ç´¢å’Œç‰¹å®šäºŽè¯­è¨€çš„æ—¶åºæ¨¡å¼ã€‚åŒè¯­è®­ç»ƒçš„é›¶æ ·æœ¬è¿ç§»æ•ˆæžœæœ‰é™ï¼Œçªå‡ºäº†è·¨è¯­è¨€çš„å®žè´¨æ€§å·®å¼‚ã€‚æ‰°åŠ¨åˆ†æžæ­ç¤ºäº†ä¸åŒçš„çº¿ç´¢ä½¿ç”¨æ–¹å¼ï¼šæ—¥è¯­æ›´ä¾èµ–äºŽçŸ­æœŸè¯­è¨€ä¿¡æ¯ï¼Œè€Œè‹±è¯­å’Œæ±‰è¯­å¯¹æ²‰é»˜æ—¶é•¿å’ŒéŸµå¾‹å˜åŒ–æ›´æ•æ„Ÿï¼›å¤šè¯­ç§è®­ç»ƒé¼“åŠ±å…±äº«ä½†å¯é€‚åº”çš„è¡¨ç¤ºï¼Œå¹¶å‡å°‘äº†æ±‰è¯­ä¸­å¯¹éŸ³é«˜çš„è¿‡åº¦ä¾èµ–ã€‚ä¸Šä¸‹æ–‡é•¿åº¦ç ”ç©¶è¿›ä¸€æ­¥è¡¨æ˜Žï¼Œæ—¥è¯­ç›¸å¯¹ä¸å—è¾ƒçŸ­ä¸Šä¸‹æ–‡çš„å½±å“ï¼Œè€Œæ±‰è¯­åˆ™æ˜Žæ˜¾å—ç›ŠäºŽè¾ƒé•¿çš„ä¸Šä¸‹æ–‡ã€‚æœ€åŽï¼Œæˆ‘ä»¬å°†è®­ç»ƒå¥½çš„æ¨¡åž‹é›†æˆåˆ°å®žæ—¶å¤„ç†è½¯ä»¶ä¸­ï¼Œå±•ç¤ºäº†ä»…ä½¿ç”¨CPUçš„æŽ¨ç†èƒ½åŠ›ã€‚æ€»ä¹‹ï¼Œè¿™äº›å‘çŽ°ä¸ºBackchannelæ—¶åºåœ¨ä¸åŒè¯­è¨€ä¹‹é—´çš„å·®å¼‚æä¾›äº†ä¸€ä¸ªç»Ÿä¸€çš„æ¨¡åž‹å’Œç»éªŒè¯æ®ï¼Œä»Žè€Œä¸ºè®¾è®¡æ›´è‡ªç„¶ã€æ›´å…·æ–‡åŒ–æ„è¯†çš„å£è¯­å¯¹è¯ç³»ç»Ÿæä¾›äº†ä¿¡æ¯ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šBackchannelé¢„æµ‹æ—¨åœ¨é¢„æµ‹å¯¹è¯ä¸­å¬è€…ä½•æ—¶ä»¥åŠå¦‚ä½•é€šè¿‡è¯¸å¦‚â€œå—¯â€ã€â€œæ˜¯â€ç­‰è¯è¯­æˆ–ç‚¹å¤´ç­‰è¡Œä¸ºæ¥å‘è¯´è¯è€…ä¼ è¾¾ç†è§£ã€åŒæ„æˆ–é¼“åŠ±ã€‚çŽ°æœ‰æ–¹æ³•é€šå¸¸é’ˆå¯¹ç‰¹å®šè¯­è¨€ï¼Œç¼ºä¹è·¨è¯­è¨€çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶ä¸”éš¾ä»¥æ•æ‰ä¸åŒè¯­è¨€ä¸­Backchannelè¡Œä¸ºçš„æ—¶åºç‰¹ç‚¹å’Œçº¿ç´¢å·®å¼‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤šè¯­ç§è”åˆè®­ç»ƒï¼Œä½¿æ¨¡åž‹èƒ½å¤ŸåŒæ—¶å­¦ä¹ ä¸åŒè¯­è¨€çš„Backchannelé¢„æµ‹ä»»åŠ¡ã€‚é€šè¿‡å…±äº«åº•å±‚è¡¨ç¤ºï¼Œæ¨¡åž‹å¯ä»¥å­¦ä¹ åˆ°è¯­è¨€é€šç”¨çš„çº¿ç´¢ï¼Œå¹¶é€šè¿‡ç‰¹å®šè¯­è¨€çš„åˆ†æ”¯æ¥æ•æ‰ç‰¹å®šäºŽè¯­è¨€çš„æ—¶åºæ¨¡å¼ã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨æé«˜æ¨¡åž‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶æ­ç¤ºä¸åŒè¯­è¨€ä¸­Backchannelè¡Œä¸ºçš„å…³é”®å·®å¼‚ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šè¯¥æ¨¡åž‹åŸºäºŽTransformeræž¶æž„ï¼Œè¾“å…¥ä¸ºè¯­éŸ³ç‰¹å¾ï¼ˆä¾‹å¦‚ï¼Œæ¢…å°”é¢‘è°±ç³»æ•°ï¼‰å’Œæ–‡æœ¬ç‰¹å¾ï¼ˆä¾‹å¦‚ï¼Œè¯åµŒå…¥ï¼‰ã€‚æ¨¡åž‹åŒ…å«ä¸€ä¸ªå…±äº«çš„Transformerç¼–ç å™¨ï¼Œç”¨äºŽæå–è¯­éŸ³å’Œæ–‡æœ¬çš„é€šç”¨è¡¨ç¤ºã€‚ç„¶åŽï¼Œé’ˆå¯¹æ¯ç§è¯­è¨€ï¼Œæ¨¡åž‹ä½¿ç”¨ä¸€ä¸ªç‰¹å®šäºŽè¯­è¨€çš„è§£ç å™¨æ¥é¢„æµ‹Backchannelè¡Œä¸ºã€‚æ­¤å¤–ï¼Œæ¨¡åž‹è¿˜ä½¿ç”¨è¾…åŠ©ä»»åŠ¡ï¼ˆä¾‹å¦‚ï¼Œè¯­éŸ³è¯†åˆ«ï¼‰æ¥æé«˜è¡¨ç¤ºçš„è´¨é‡ã€‚æ•´ä½“æµç¨‹åŒ…æ‹¬ç‰¹å¾æå–ã€Transformerç¼–ç ã€ç‰¹å®šè¯­è¨€è§£ç å’ŒBackchannelé¢„æµ‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽæå‡ºäº†ä¸€ä¸ªå¤šè¯­ç§çš„Backchannelé¢„æµ‹æ¨¡åž‹ï¼Œè¯¥æ¨¡åž‹èƒ½å¤ŸåŒæ—¶å­¦ä¹ ä¸åŒè¯­è¨€çš„Backchannelè¡Œä¸ºã€‚é€šè¿‡å¤šè¯­ç§è”åˆè®­ç»ƒï¼Œæ¨¡åž‹å¯ä»¥å­¦ä¹ åˆ°è¯­è¨€é€šç”¨çš„çº¿ç´¢å’Œç‰¹å®šäºŽè¯­è¨€çš„æ—¶åºæ¨¡å¼ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜é€šè¿‡æ‰°åŠ¨åˆ†æžæ­ç¤ºäº†ä¸åŒè¯­è¨€ä¸­Backchannelé¢„æµ‹çš„å…³é”®çº¿ç´¢å·®å¼‚ï¼Œä¾‹å¦‚ï¼Œæ—¥è¯­æ›´ä¾èµ–äºŽçŸ­æœŸè¯­è¨€ä¿¡æ¯ï¼Œè€Œè‹±è¯­å’Œæ±‰è¯­å¯¹æ²‰é»˜æ—¶é•¿å’ŒéŸµå¾‹å˜åŒ–æ›´æ•æ„Ÿã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡åž‹ä½¿ç”¨Transformerç¼–ç å™¨-è§£ç å™¨æž¶æž„ï¼Œç¼–ç å™¨å…±äº«ï¼Œè§£ç å™¨ç‰¹å®šäºŽè¯­è¨€ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬Backchannelé¢„æµ‹çš„äº¤å‰ç†µæŸå¤±å’Œè¾…åŠ©ä»»åŠ¡çš„æŸå¤±ã€‚è®­ç»ƒæ•°æ®åŒ…å«æ—¥è¯­ã€è‹±è¯­å’Œæ±‰è¯­çš„äºŒå…ƒå¯¹è¯æ•°æ®ï¼Œæ€»æ—¶é•¿çº¦ä¸º300å°æ—¶ã€‚æ¨¡åž‹ä½¿ç”¨Adamä¼˜åŒ–å™¨è¿›è¡Œè®­ç»ƒï¼Œå­¦ä¹ çŽ‡è®¾ç½®ä¸º5e-5ã€‚ä¸Šä¸‹æ–‡é•¿åº¦å¯¹æ¨¡åž‹æ€§èƒ½æœ‰å½±å“ï¼Œå®žéªŒä¸­æŽ¢ç´¢äº†ä¸åŒçš„ä¸Šä¸‹æ–‡é•¿åº¦è®¾ç½®ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼Œå¤šè¯­ç§æ¨¡åž‹åœ¨æ—¥è¯­ã€è‹±è¯­å’Œæ±‰è¯­çš„Backchannelé¢„æµ‹ä»»åŠ¡ä¸­å‡è¾¾åˆ°æˆ–è¶…è¿‡äº†å•è¯­åŸºçº¿ã€‚æ‰°åŠ¨åˆ†æžæ­ç¤ºäº†ä¸åŒè¯­è¨€ä¸­Backchannelé¢„æµ‹çš„å…³é”®çº¿ç´¢å·®å¼‚ï¼Œä¾‹å¦‚ï¼Œæ—¥è¯­æ›´ä¾èµ–äºŽçŸ­æœŸè¯­è¨€ä¿¡æ¯ï¼Œè€Œè‹±è¯­å’Œæ±‰è¯­å¯¹æ²‰é»˜æ—¶é•¿å’ŒéŸµå¾‹å˜åŒ–æ›´æ•æ„Ÿã€‚ä¸Šä¸‹æ–‡é•¿åº¦ç ”ç©¶è¡¨æ˜Žï¼Œæ—¥è¯­ç›¸å¯¹ä¸å—è¾ƒçŸ­ä¸Šä¸‹æ–‡çš„å½±å“ï¼Œè€Œæ±‰è¯­åˆ™æ˜Žæ˜¾å—ç›ŠäºŽè¾ƒé•¿çš„ä¸Šä¸‹æ–‡ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽå¼€å‘æ›´è‡ªç„¶ã€æ›´å…·æ–‡åŒ–æ„è¯†çš„å£è¯­å¯¹è¯ç³»ç»Ÿã€‚ä¾‹å¦‚ï¼Œåœ¨è·¨æ–‡åŒ–äº¤æµåœºæ™¯ä¸­ï¼Œç³»ç»Ÿå¯ä»¥æ ¹æ®ç”¨æˆ·çš„è¯­è¨€å’Œæ–‡åŒ–èƒŒæ™¯ï¼Œé¢„æµ‹å¹¶ç”Ÿæˆåˆé€‚çš„Backchannelè¡Œä¸ºï¼Œä»Žè€Œæé«˜äº¤æµçš„æµç•…æ€§å’Œè‡ªç„¶åº¦ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡åž‹è¿˜å¯ä»¥ç”¨äºŽåˆ†æžä¸åŒè¯­è¨€çš„Backchannelè¡Œä¸ºå·®å¼‚ï¼Œä¸ºè·¨æ–‡åŒ–äº¤æµç ”ç©¶æä¾›æ–°çš„è§†è§’ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We present a multilingual, continuous backchannel prediction model for Japanese, English, and Chinese, and use it to investigate cross-linguistic timing behavior. The model is Transformer-based and operates at the frame level, jointly trained with auxiliary tasks on approximately 300 hours of dyadic conversations. Across all three languages, the multilingual model matches or surpasses monolingual baselines, indicating that it learns both language-universal cues and language-specific timing patterns. Zero-shot transfer with two-language training remains limited, underscoring substantive cross-lingual differences. Perturbation analyses reveal distinct cue usage: Japanese relies more on short-term linguistic information, whereas English and Chinese are more sensitive to silence duration and prosodic variation; multilingual training encourages shared yet adaptable representations and reduces overreliance on pitch in Chinese. A context-length study further shows that Japanese is relatively robust to shorter contexts, while Chinese benefits markedly from longer contexts. Finally, we integrate the trained model into a real-time processing software, demonstrating CPU-only inference. Together, these findings provide a unified model and empirical evidence for how backchannel timing differs across languages, informing the design of more natural, culturally-aware spoken dialogue systems.

