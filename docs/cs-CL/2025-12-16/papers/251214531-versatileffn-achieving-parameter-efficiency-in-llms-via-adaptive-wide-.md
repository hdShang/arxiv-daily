---
layout: default
title: VersatileFFN: Achieving Parameter Efficiency in LLMs via Adaptive Wide-and-Deep Reuse
---

# VersatileFFN: Achieving Parameter Efficiency in LLMs via Adaptive Wide-and-Deep Reuse

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.14531" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.14531</a>
  <a href="https://arxiv.org/pdf/2512.14531.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14531" onclick="toggleFavorite(this, '2512.14531', 'VersatileFFN: Achieving Parameter Efficiency in LLMs via Adaptive Wide-and-Deep Reuse')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ying Nie, Kai Han, Hongguang Li, Hang Zhou, Tianyu Guo, Enhua Wu, Xinghao Chen, Yunhe Wang

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-12-18

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**VersatileFFNï¼šé€šè¿‡è‡ªé€‚åº”å®½æ·±å¤ç”¨æå‡LLMçš„å‚æ•°æ•ˆç‡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å‚æ•°é«˜æ•ˆ` `å¤§å‹è¯­è¨€æ¨¡å‹` `å‰é¦ˆç½‘ç»œ` `æ¨¡å‹å‹ç¼©` `å®½åº¦å¤ç”¨` `æ·±åº¦å¤ç”¨` `è‡ªé€‚åº”è·¯ç”±` `è®¤çŸ¥åŒè¿‡ç¨‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMå‚æ•°é«˜æ•ˆæ–¹æ³•ä¸»è¦é€šè¿‡å‹ç¼©é¢„è®­ç»ƒæ¨¡å‹å®ç°ï¼Œä½†æœªæœ‰æ•ˆæå‡æ¨¡å‹æ¶æ„æœ¬èº«çš„å®¹é‡ã€‚
2. VersatileFFNé€šè¿‡å®½åº¦å’Œæ·±åº¦ä¸¤ä¸ªç»´åº¦ä¸Šçš„å‚æ•°å¤ç”¨ï¼Œåœ¨å›ºå®šå‚æ•°é¢„ç®—ä¸‹æå‡æ¨¡å‹å®¹é‡ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒVersatileFFNåœ¨å¤šç§åŸºå‡†æµ‹è¯•å’Œæ¨¡å‹è§„æ¨¡ä¸Šå‡è¡¨ç°å‡ºæœ‰æ•ˆæ€§ï¼ŒéªŒè¯äº†å…¶å‚æ•°æ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¿«é€Ÿæ‰©å±•å¸¦æ¥äº†å“è¶Šçš„æ€§èƒ½ï¼Œä½†ä¹Ÿå¯¼è‡´äº†å·¨å¤§çš„å†…å­˜æˆæœ¬ã€‚ç°æœ‰çš„å‚æ•°é«˜æ•ˆæ–¹æ³•ï¼Œå¦‚å‰ªæå’Œé‡åŒ–ï¼Œä¸»è¦å‹ç¼©é¢„è®­ç»ƒæ¨¡å‹ï¼Œè€Œä¸å¢å¼ºæ¶æ„å®¹é‡ï¼Œä»è€Œè§¦åŠäº†åŸºç¡€æ¨¡å‹çš„è¡¨å¾ä¸Šé™ã€‚æœ¬æ–‡æå‡ºäº†VersatileFFNï¼Œä¸€ç§æ–°é¢–çš„å‰é¦ˆç½‘ç»œï¼ˆFFNï¼‰ï¼Œå®ƒèƒ½å¤Ÿåœ¨å›ºå®šçš„å‚æ•°é¢„ç®—å†…ï¼Œçµæ´»åœ°å¤ç”¨å®½åº¦å’Œæ·±åº¦ç»´åº¦ä¸Šçš„å‚æ•°ã€‚å—åˆ°è®¤çŸ¥åŒè¿‡ç¨‹ç†è®ºçš„å¯å‘ï¼ŒVersatileFFNåŒ…å«ä¸¤ä¸ªè‡ªé€‚åº”è·¯å¾„ï¼šä¸€ä¸ªå®½åº¦å¤šåŠŸèƒ½è·¯å¾„ï¼Œä»å•ä¸ªå…±äº«FFNç”Ÿæˆå­ä¸“å®¶æ··åˆï¼Œæ¨¡æ‹Ÿç¨€ç–ä¸“å®¶è·¯ç”±è€Œä¸å¢åŠ å‚æ•°ï¼›ä»¥åŠä¸€ä¸ªæ·±åº¦å¤šåŠŸèƒ½è·¯å¾„ï¼Œé€’å½’åœ°åº”ç”¨ç›¸åŒçš„FFNï¼Œä»¥æ¨¡æ‹Ÿæ›´æ·±å±‚æ¬¡çš„å¤æ‚tokenå¤„ç†ã€‚ä¸€ä¸ªéš¾åº¦æ„ŸçŸ¥é—¨æ§åŠ¨æ€åœ°å¹³è¡¡è¿™ä¸¤ä¸ªè·¯å¾„ï¼Œå¼•å¯¼â€œç®€å•â€tokené€šè¿‡é«˜æ•ˆçš„å®½åº¦è·¯å¾„ï¼Œå¹¶ä¸ºâ€œå›°éš¾â€tokenåˆ†é…æ›´æ·±å±‚æ¬¡çš„è¿­ä»£ç»†åŒ–ã€‚è‡³å…³é‡è¦çš„æ˜¯ï¼Œè¿™ä¸¤ä¸ªè·¯å¾„éƒ½å¤ç”¨ç›¸åŒçš„å‚æ•°ï¼Œå› æ­¤æ‰€æœ‰é¢å¤–çš„å®¹é‡éƒ½æ¥è‡ªè®¡ç®—è€Œéå†…å­˜ã€‚åœ¨å„ç§åŸºå‡†å’Œæ¨¡å‹è§„æ¨¡ä¸Šçš„å®éªŒè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è¿½æ±‚å“è¶Šæ€§èƒ½çš„åŒæ—¶ï¼Œé¢ä¸´ç€å·¨å¤§çš„å†…å­˜æˆæœ¬é—®é¢˜ã€‚ç°æœ‰çš„å‚æ•°é«˜æ•ˆæ–¹æ³•ï¼Œå¦‚å‰ªæå’Œé‡åŒ–ï¼Œä¸»è¦é›†ä¸­äºå‹ç¼©é¢„è®­ç»ƒæ¨¡å‹ï¼Œè€Œå¿½ç•¥äº†æ¨¡å‹æ¶æ„æœ¬èº«çš„å®¹é‡æå‡ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½å—é™äºåŸºç¡€æ¨¡å‹çš„è¡¨å¾èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šVersatileFFNçš„æ ¸å¿ƒæ€è·¯æ˜¯åœ¨å›ºå®šå‚æ•°é¢„ç®—ä¸‹ï¼Œé€šè¿‡å‚æ•°çš„çµæ´»å¤ç”¨ï¼ŒåŒæ—¶æå‡æ¨¡å‹çš„å®½åº¦å’Œæ·±åº¦ï¼Œä»è€Œå¢å¼ºæ¨¡å‹çš„è¡¨å¾èƒ½åŠ›ã€‚å€Ÿé‰´è®¤çŸ¥åŒè¿‡ç¨‹ç†è®ºï¼ŒåŒºåˆ†â€œç®€å•â€å’Œâ€œå›°éš¾â€çš„tokenï¼Œå¹¶é‡‡ç”¨ä¸åŒçš„å¤„ç†è·¯å¾„ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVersatileFFNåŒ…å«ä¸¤ä¸ªä¸»è¦è·¯å¾„ï¼šå®½åº¦å¤šåŠŸèƒ½è·¯å¾„å’Œæ·±åº¦å¤šåŠŸèƒ½è·¯å¾„ã€‚å®½åº¦è·¯å¾„é€šè¿‡å…±äº«çš„FFNç”Ÿæˆå­ä¸“å®¶æ··åˆï¼Œæ¨¡æ‹Ÿç¨€ç–ä¸“å®¶è·¯ç”±ã€‚æ·±åº¦è·¯å¾„åˆ™é€’å½’åº”ç”¨ç›¸åŒçš„FFNï¼Œæ¨¡æ‹Ÿæ›´æ·±å±‚æ¬¡çš„å¤„ç†ã€‚éš¾åº¦æ„ŸçŸ¥é—¨æ§æœºåˆ¶åŠ¨æ€å¹³è¡¡è¿™ä¸¤ä¸ªè·¯å¾„ï¼Œå°†â€œç®€å•â€tokenå¼•å¯¼è‡³å®½åº¦è·¯å¾„ï¼Œå°†â€œå›°éš¾â€tokenå¼•å¯¼è‡³æ·±åº¦è·¯å¾„ã€‚è¿™ä¸¤ä¸ªè·¯å¾„å…±äº«ç›¸åŒçš„å‚æ•°ã€‚

**å…³é”®åˆ›æ–°**ï¼šVersatileFFNçš„å…³é”®åˆ›æ–°åœ¨äºå‚æ•°çš„è‡ªé€‚åº”å®½æ·±å¤ç”¨ã€‚ä¸ä¼ ç»Ÿçš„å‚æ•°é«˜æ•ˆæ–¹æ³•ä¸åŒï¼ŒVersatileFFNä¸æ˜¯ç®€å•åœ°å‹ç¼©æ¨¡å‹ï¼Œè€Œæ˜¯é€šè¿‡å·§å¦™çš„æ¶æ„è®¾è®¡ï¼Œåœ¨ä¸å¢åŠ å‚æ•°é‡çš„å‰æä¸‹ï¼Œæå‡æ¨¡å‹çš„å®¹é‡ã€‚éš¾åº¦æ„ŸçŸ¥é—¨æ§æœºåˆ¶ä¹Ÿæ˜¯ä¸€ä¸ªåˆ›æ–°ç‚¹ï¼Œå®ƒèƒ½å¤Ÿæ ¹æ®tokençš„éš¾åº¦åŠ¨æ€è°ƒæ•´å¤„ç†è·¯å¾„ã€‚

**å…³é”®è®¾è®¡**ï¼šéš¾åº¦æ„ŸçŸ¥é—¨æ§æœºåˆ¶æ˜¯VersatileFFNçš„å…³é”®è®¾è®¡ä¹‹ä¸€ã€‚å…·ä½“å®ç°æ–¹å¼æœªçŸ¥ï¼Œä½†å…¶ç›®æ ‡æ˜¯æ ¹æ®tokençš„å¤æ‚ç¨‹åº¦ï¼ŒåŠ¨æ€åœ°åˆ†é…è®¡ç®—èµ„æºã€‚å®½åº¦è·¯å¾„å’Œæ·±åº¦è·¯å¾„çš„å…·ä½“ç½‘ç»œç»“æ„æœªçŸ¥ï¼Œä½†å®ƒä»¬éƒ½åŸºäºå…±äº«çš„FFNã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿè‡³å…³é‡è¦ï¼Œéœ€è¦å¹³è¡¡å®½åº¦è·¯å¾„å’Œæ·±åº¦è·¯å¾„çš„è´¡çŒ®ï¼Œå¹¶ç¡®ä¿æ¨¡å‹çš„æ•´ä½“æ€§èƒ½ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.14531/x1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.14531/x2.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.14531/x3.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡é€šè¿‡å®éªŒéªŒè¯äº†VersatileFFNçš„æœ‰æ•ˆæ€§ã€‚å…·ä½“æ€§èƒ½æ•°æ®æœªçŸ¥ï¼Œä½†å®éªŒç»“æœè¡¨æ˜ï¼ŒVersatileFFNåœ¨å¤šç§åŸºå‡†æµ‹è¯•å’Œæ¨¡å‹è§„æ¨¡ä¸Šå‡ä¼˜äºç°æœ‰çš„å‚æ•°é«˜æ•ˆæ–¹æ³•ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨ä¸å¢åŠ å‚æ•°é‡çš„å‰æä¸‹ï¼Œæ˜¾è‘—æå‡æ¨¡å‹çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶å‚æ•°æ•ˆç‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

VersatileFFNå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯ä»¥åº”ç”¨äºå„ç§éœ€è¦å‚æ•°é«˜æ•ˆçš„å¤§å‹è¯­è¨€æ¨¡å‹åœºæ™¯ï¼Œä¾‹å¦‚ç§»åŠ¨è®¾å¤‡ä¸Šçš„è‡ªç„¶è¯­è¨€å¤„ç†ã€èµ„æºå—é™ç¯å¢ƒä¸‹çš„æ¨¡å‹éƒ¨ç½²ç­‰ã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºé™ä½LLMçš„éƒ¨ç½²æˆæœ¬ï¼ŒåŠ é€ŸLLMåœ¨å„ä¸ªé¢†åŸŸçš„æ™®åŠå’Œåº”ç”¨ï¼Œå¹¶ä¸ºæœªæ¥çš„å‚æ•°é«˜æ•ˆæ¨¡å‹è®¾è®¡æä¾›æ–°çš„æ€è·¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The rapid scaling of Large Language Models (LLMs) has achieved remarkable performance, but it also leads to prohibitive memory costs. Existing parameter-efficient approaches such as pruning and quantization mainly compress pretrained models without enhancing architectural capacity, thereby hitting the representational ceiling of the base model. In this work, we propose VersatileFFN, a novel feed-forward network (FFN) that enables flexible reuse of parameters in both width and depth dimensions within a fixed parameter budget. Inspired by the dual-process theory of cognition, VersatileFFN comprises two adaptive pathways: a width-versatile path that generates a mixture of sub-experts from a single shared FFN, mimicking sparse expert routing without increasing parameters, and a depth-versatile path that recursively applies the same FFN to emulate deeper processing for complex tokens. A difficulty-aware gating dynamically balances the two pathways, steering "easy" tokens through the efficient width-wise route and allocating deeper iterative refinement to "hard" tokens. Crucially, both pathways reuse the same parameters, so all additional capacity comes from computation rather than memory. Experiments across diverse benchmarks and model scales demonstrate the effectiveness of the method. The code will be available atthis https URL.

