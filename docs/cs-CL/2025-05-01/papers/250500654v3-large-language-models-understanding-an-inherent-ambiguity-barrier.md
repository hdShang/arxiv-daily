---
layout: default
title: "Large Language Models Understanding: an Inherent Ambiguity Barrier"
---

# Large Language Models Understanding: an Inherent Ambiguity Barrier

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.00654" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.00654v3</a>
  <a href="https://arxiv.org/pdf/2505.00654.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.00654v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.00654v3', 'Large Language Models Understanding: an Inherent Ambiguity Barrier')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Daniel N. Nissani

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-01 (æ›´æ–°: 2025-05-08)

**å¤‡æ³¨**: submitted to NEURAL COMPUTATION

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå†…åœ¨æ¨¡ç³Šæ€§éšœç¢ä»¥è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ç†è§£é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ç†è§£èƒ½åŠ›` `æ¨¡ç³Šæ€§éšœç¢` `è‡ªç„¶è¯­è¨€å¤„ç†` `äººæœºäº¤äº’`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå½“å‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç†è§£å¯¹è¯å’Œä¸–ç•Œæ„ä¹‰æ–¹é¢å­˜åœ¨å†…åœ¨çš„æ¨¡ç³Šæ€§éšœç¢ï¼Œå¯¼è‡´å…¶æ— æ³•çœŸæ­£ç†è§£æ‰€ç”Ÿæˆçš„å†…å®¹ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šè®ºæ–‡é€šè¿‡æ€ç»´å®éªŒå’ŒåŠæ­£å¼çš„åˆ†æï¼Œæå‡ºäº†ä¸€ä¸ªåé©³è§‚ç‚¹ï¼Œå¼ºè°ƒæ¨¡ç³Šæ€§å¯¹ç†è§£çš„å½±å“ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šè™½ç„¶æœªæä¾›å…·ä½“å®éªŒç»“æœï¼Œä½†å¼ºè°ƒäº†æ¨¡ç³Šæ€§éšœç¢çš„å­˜åœ¨å¯¹LLMsç†è§£èƒ½åŠ›çš„é™åˆ¶ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å‡ºç°ï¼Œå…³äºå…¶ç†è§£ä¸–ç•Œå’Œå¯¹è¯æ„ä¹‰çš„èƒ½åŠ›å±•å¼€äº†æ¿€çƒˆçš„è®¨è®ºã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åé©³è§‚ç‚¹ï¼ŒåŸºäºæ€ç»´å®éªŒå’ŒåŠæ­£å¼çš„è€ƒè™‘ï¼ŒæŒ‡å‡ºå­˜åœ¨ä¸€ä¸ªå†…åœ¨çš„æ¨¡ç³Šæ€§éšœç¢ï¼Œé˜»ç¢LLMsçœŸæ­£ç†è§£å…¶æµç•…å¯¹è¯çš„å«ä¹‰ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨æ¢è®¨å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç†è§£å¯¹è¯å’Œä¸–ç•Œçš„èƒ½åŠ›ï¼ŒæŒ‡å‡ºç°æœ‰æ–¹æ³•æœªèƒ½è§£å†³çš„å†…åœ¨æ¨¡ç³Šæ€§éšœç¢ã€‚ç°æœ‰çš„å¯¹è¯ç”Ÿæˆæ¨¡å‹è™½ç„¶èƒ½å¤Ÿç”Ÿæˆæµç•…çš„è¯­è¨€ï¼Œä½†ç¼ºä¹å¯¹å…¶å†…å®¹çš„çœŸæ­£ç†è§£ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ€ç»´å®éªŒå’ŒåŠæ­£å¼çš„åˆ†æï¼Œæ­ç¤ºæ¨¡ç³Šæ€§å¦‚ä½•å½±å“LLMsçš„ç†è§£èƒ½åŠ›ã€‚ä½œè€…è®¤ä¸ºï¼Œæ¨¡ç³Šæ€§æ˜¯LLMsæ— æ³•çœŸæ­£ç†è§£å¯¹è¯å†…å®¹çš„æ ¹æœ¬åŸå› ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ€ç»´å®éªŒçš„è®¾è®¡å’Œæ¨¡ç³Šæ€§åˆ†æçš„æ¡†æ¶ï¼Œä¸»è¦é˜¶æ®µåŒ…æ‹¬å¯¹è¯ç”Ÿæˆã€æ¨¡ç³Šæ€§è¯†åˆ«å’Œç†è§£èƒ½åŠ›è¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†å†…åœ¨æ¨¡ç³Šæ€§éšœç¢çš„æ¦‚å¿µï¼Œå¼ºè°ƒäº†è¿™ä¸€éšœç¢ä¸ç°æœ‰ç†è§£æ¨¡å‹çš„æœ¬è´¨åŒºåˆ«ï¼ŒæŒ‡å‡ºLLMsçš„æµç•…æ€§å¹¶ä¸ç­‰åŒäºç†è§£ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­æœªè¯¦ç»†æè¿°å…·ä½“çš„å‚æ•°è®¾ç½®æˆ–ç½‘ç»œç»“æ„ï¼Œä½†å¼ºè°ƒäº†æ€ç»´å®éªŒçš„è®¾è®¡å’Œæ¨¡ç³Šæ€§åˆ†æçš„é‡è¦æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è™½ç„¶è®ºæ–‡æœªæä¾›å…·ä½“çš„å®éªŒæ•°æ®ï¼Œä½†å¼ºè°ƒäº†å†…åœ¨æ¨¡ç³Šæ€§éšœç¢å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ç†è§£èƒ½åŠ›çš„æ·±è¿œå½±å“ï¼ŒæŒ‡å‡ºè¿™ä¸€éšœç¢æ˜¯å½“å‰å¯¹è¯ç”ŸæˆæŠ€æœ¯çš„ä¸»è¦é™åˆ¶å› ç´ ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€å¯¹è¯ç³»ç»Ÿå’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æ·±å…¥ç†è§£å¤§å‹è¯­è¨€æ¨¡å‹çš„å±€é™æ€§ï¼Œå¯ä»¥æ¨åŠ¨æ›´å…·ç†è§£èƒ½åŠ›çš„AIç³»ç»Ÿçš„å¼€å‘ï¼Œæå‡äººæœºäº¤äº’çš„è´¨é‡å’Œæ•ˆç‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> A lively ongoing debate is taking place, since the extraordinary emergence of Large Language Models (LLMs) with regards to their capability to understand the world and capture the meaning of the dialogues in which they are involved. Arguments and counter-arguments have been proposed based upon thought experiments, anecdotal conversations between LLMs and humans, statistical linguistic analysis, philosophical considerations, and more. In this brief paper we present a counter-argument based upon a thought experiment and semi-formal considerations leading to an inherent ambiguity barrier which prevents LLMs from having any understanding of what their amazingly fluent dialogues mean.

