---
layout: default
title: DeepCritic: Deliberate Critique with Large Language Models
---

# DeepCritic: Deliberate Critique with Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.00662" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.00662v1</a>
  <a href="https://arxiv.org/pdf/2505.00662.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.00662v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.00662v1', 'DeepCritic: Deliberate Critique with Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wenkai Yang, Jingwen Chen, Yankai Lin, Ji-Rong Wen

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-01

**å¤‡æ³¨**: Work in progress. Data and models are available at https://github.com/RUCBM/DeepCritic

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDeepCriticä»¥è§£å†³LLMè¾“å‡ºåé¦ˆä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ‰¹è¯„èƒ½åŠ›` `æ•°å­¦è§£é¢˜` `å¼ºåŒ–å­¦ä¹ ` `è‡ªåŠ¨åŒ–ç›‘ç£` `æ·±åº¦å­¦ä¹ ` `æ•™è‚²æŠ€æœ¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„LLMæ‰¹è¯„è€…åœ¨æ•°å­¦è§£é¢˜è¿‡ç¨‹ä¸­æä¾›çš„åé¦ˆå¾€å¾€è¿‡äºè‚¤æµ…ï¼Œå¯¼è‡´ç”Ÿæˆæ¨¡å‹éš¾ä»¥è·å¾—æœ‰æ•ˆçš„çº é”™ä¿¡æ¯ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§ä¸¤é˜¶æ®µçš„æ¡†æ¶ï¼Œé€šè¿‡ç”Ÿæˆé•¿å½¢å¼çš„æ‰¹è¯„å’Œå¼ºåŒ–å­¦ä¹ æ¥æå‡LLMsçš„æ‰¹åˆ¤èƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ‰¹è¯„æ¨¡å‹åœ¨é”™è¯¯è¯†åˆ«åŸºå‡†ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰çš„LLMæ‰¹è¯„è€…ï¼Œèƒ½å¤Ÿæä¾›æ›´è¯¦ç»†çš„åé¦ˆã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¿«é€Ÿå‘å±•ï¼Œæä¾›å‡†ç¡®çš„åé¦ˆå’Œå¯æ‰©å±•çš„ç›‘ç£å˜å¾—æ„ˆå‘é‡è¦ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ä¸¤é˜¶æ®µæ¡†æ¶ï¼Œæ—¨åœ¨å¢å¼ºLLMsåœ¨æ•°å­¦è§£é¢˜ä¸­çš„æ‰¹åˆ¤èƒ½åŠ›ã€‚ç°æœ‰çš„LLMæ‰¹è¯„è€…å¾€å¾€æä¾›çš„åé¦ˆè¿‡äºè‚¤æµ…ï¼Œå¯¼è‡´åˆ¤æ–­å‡†ç¡®æ€§ä½ï¼Œæ— æ³•ä¸ºç”Ÿæˆæ¨¡å‹æä¾›è¶³å¤Ÿçš„çº é”™ä¿¡æ¯ã€‚é€šè¿‡åˆ©ç”¨Qwen2.5-72B-Instructç”Ÿæˆé•¿è¾¾4.5Kçš„æ‰¹è¯„ä½œä¸ºç›‘ç£å¾®è°ƒçš„ç§å­æ•°æ®ï¼Œå¹¶ç»“åˆå¼ºåŒ–å­¦ä¹ ï¼Œæœ¬æ–‡å¼€å‘çš„æ‰¹è¯„æ¨¡å‹åœ¨å¤šé¡¹é”™è¯¯è¯†åˆ«åŸºå‡†ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰çš„LLMæ‰¹è¯„è€…ï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å¸®åŠ©ç”Ÿæˆæ¨¡å‹ä¿®æ­£é”™è¯¯æ­¥éª¤ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰LLMæ‰¹è¯„è€…åœ¨æ•°å­¦è§£é¢˜ä¸­åé¦ˆä¸è¶³çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€æä¾›çš„æ‰¹è¯„è¿‡äºè¡¨é¢ï¼Œæ— æ³•æœ‰æ•ˆæŒ‡å¯¼ç”Ÿæˆæ¨¡å‹è¿›è¡Œçº é”™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºä¸€ç§ä¸¤é˜¶æ®µçš„æ¡†æ¶ï¼Œé¦–å…ˆç”Ÿæˆé•¿å½¢å¼çš„æ‰¹è¯„ä½œä¸ºç§å­æ•°æ®è¿›è¡Œå¾®è°ƒï¼Œç„¶åé€šè¿‡å¼ºåŒ–å­¦ä¹ è¿›ä¸€æ­¥æå‡æ‰¹è¯„èƒ½åŠ›ï¼Œä»¥å®ç°æ›´æ·±å…¥çš„é€æ­¥æ‰¹è¯„ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åˆ†ä¸ºä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µä½¿ç”¨Qwen2.5-72B-Instructç”Ÿæˆ4.5Kçš„é•¿å½¢å¼æ‰¹è¯„ä½œä¸ºç›‘ç£å¾®è°ƒçš„ç§å­æ•°æ®ï¼›ç¬¬äºŒé˜¶æ®µåˆ™å¯¹å¾®è°ƒåçš„æ¨¡å‹è¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œä½¿ç”¨äººç±»æ ‡æ³¨æ•°æ®æˆ–é€šè¿‡è’™ç‰¹å¡ç½—é‡‡æ ·è·å¾—çš„è‡ªåŠ¨æ ‡æ³¨æ•°æ®è¿›è¡Œè®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºé€šè¿‡ä¸¤é˜¶æ®µæ¡†æ¶å®ç°äº†å¯¹æ¯ä¸ªæ¨ç†æ­¥éª¤çš„æ·±åº¦æ‰¹è¯„ï¼Œæ˜¾è‘—æå‡äº†æ‰¹è¯„çš„å‡†ç¡®æ€§å’Œæœ‰æ•ˆæ€§ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿæä¾›æ›´ä¸ºè¯¦ç»†å’Œå¤šè§’åº¦çš„åé¦ˆã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†Qwen2.5-7B-Instructä½œä¸ºåŸºç¡€æ¨¡å‹ï¼Œç»“åˆå¤šç§æŸå¤±å‡½æ•°å’Œå‚æ•°è®¾ç½®ï¼Œä»¥ç¡®ä¿æ‰¹è¯„çš„å¤šæ ·æ€§å’Œæ·±åº¦ï¼ŒåŒæ—¶åˆ©ç”¨å¼ºåŒ–å­¦ä¹ ç­–ç•¥æ¥æ¿€åŠ±æ¨¡å‹çš„æ‰¹è¯„èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æå‡ºçš„DeepCriticæ¨¡å‹åœ¨å¤šé¡¹é”™è¯¯è¯†åˆ«åŸºå‡†ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰çš„LLMæ‰¹è¯„è€…ï¼ŒåŒ…æ‹¬åŒè§„æ¨¡çš„DeepSeek-R1-distillæ¨¡å‹å’ŒGPT-4oï¼Œæå‡å¹…åº¦è¾¾åˆ°XX%ï¼ˆå…·ä½“æ•°æ®å¾…è¡¥å……ï¼‰ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å¸®åŠ©ç”Ÿæˆæ¨¡å‹ä¿®æ­£é”™è¯¯æ­¥éª¤ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²æŠ€æœ¯ã€è‡ªåŠ¨åŒ–è¯„ä¼°ç³»ç»Ÿå’Œæ™ºèƒ½è¾…å¯¼å·¥å…·ã€‚é€šè¿‡æå‡LLMsçš„æ‰¹è¯„èƒ½åŠ›ï¼Œå¯ä»¥ä¸ºå­¦ç”Ÿæä¾›æ›´æœ‰æ•ˆçš„å­¦ä¹ åé¦ˆï¼Œå¸®åŠ©ä»–ä»¬æ›´å¥½åœ°ç†è§£å’Œçº æ­£é”™è¯¯ï¼Œä»è€Œæé«˜å­¦ä¹ æ•ˆç‡å’Œæ•ˆæœã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åœ¨æ›´å¹¿æ³›çš„é¢†åŸŸä¸­åº”ç”¨ï¼Œå¦‚æ™ºèƒ½é—®ç­”ç³»ç»Ÿå’Œè‡ªåŠ¨åŒ–å†…å®¹ç”Ÿæˆã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> As Large Language Models (LLMs) are rapidly evolving, providing accurate feedback and scalable oversight on their outputs becomes an urgent and critical problem. Leveraging LLMs as critique models to achieve automated supervision is a promising solution. In this work, we focus on studying and enhancing the math critique ability of LLMs. Current LLM critics provide critiques that are too shallow and superficial on each step, leading to low judgment accuracy and struggling to offer sufficient feedback for the LLM generator to correct mistakes. To tackle this issue, we propose a novel and effective two-stage framework to develop LLM critics that are capable of deliberately critiquing on each reasoning step of math solutions. In the first stage, we utilize Qwen2.5-72B-Instruct to generate 4.5K long-form critiques as seed data for supervised fine-tuning. Each seed critique consists of deliberate step-wise critiques that includes multi-perspective verifications as well as in-depth critiques of initial critiques for each reasoning step. Then, we perform reinforcement learning on the fine-tuned model with either existing human-labeled data from PRM800K or our automatically annotated data obtained via Monte Carlo sampling-based correctness estimation, to further incentivize its critique ability. Our developed critique model built on Qwen2.5-7B-Instruct not only significantly outperforms existing LLM critics (including the same-sized DeepSeek-R1-distill models and GPT-4o) on various error identification benchmarks, but also more effectively helps the LLM generator refine erroneous steps through more detailed feedback.

