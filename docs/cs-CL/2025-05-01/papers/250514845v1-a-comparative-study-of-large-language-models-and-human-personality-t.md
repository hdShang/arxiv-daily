---
layout: default
title: A Comparative Study of Large Language Models and Human Personality Traits
---

# A Comparative Study of Large Language Models and Human Personality Traits

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14845" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14845v1</a>
  <a href="https://arxiv.org/pdf/2505.14845.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14845v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14845v1', 'A Comparative Study of Large Language Models and Human Personality Traits')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wang Jiaqi, Wang bo, Guo fa, Cheng cheng, Yang li

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-01

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåˆ†å¸ƒå¼äººæ ¼æ¡†æ¶ä»¥åˆ†æå¤§å‹è¯­è¨€æ¨¡å‹çš„äººæ ¼ç‰¹å¾**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `äººæ ¼ç‰¹å¾` `åˆ†å¸ƒå¼äººæ ¼æ¡†æ¶` `äººæœºäº¤äº’` `å¿ƒç†å­¦` `åŠ¨æ€è¯„ä¼°` `è¾“å…¥æ•æ„Ÿæ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹çš„äººæ ¼ç‰¹å¾æ—¶ï¼Œç¼ºä¹ç¨³å®šæ€§å’Œä¸€è‡´æ€§ï¼Œéš¾ä»¥ä¸äººç±»äººæ ¼è¿›è¡Œæœ‰æ•ˆæ¯”è¾ƒã€‚
2. è®ºæ–‡æå‡ºåˆ†å¸ƒå¼äººæ ¼æ¡†æ¶ï¼Œå¼ºè°ƒLLMsçš„äººæ ¼ç‰¹å¾æ˜¯åŠ¨æ€çš„ï¼Œå—è¾“å…¥é©±åŠ¨ï¼Œé€‚åº”æ€§å¼ºã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMsåœ¨ä¸åŒæµ‹è¯•ä¸­çš„è¡¨ç°é«˜åº¦ä¾èµ–äºæç¤ºå’Œå‚æ•°è®¾ç½®ï¼Œå±•ç°å‡ºæµåŠ¨æ€§å’Œå¤–éƒ¨ä¾èµ–æ€§çš„äººæ ¼æ¨¡å¼ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è¯­è¨€ç†è§£å’Œç”Ÿæˆæ–¹é¢å±•ç°å‡ºç±»äººèƒ½åŠ›ï¼Œæˆä¸ºç¤¾ä¼šå’Œè®¤çŸ¥é¢†åŸŸçš„æ´»è·ƒå‚ä¸è€…ã€‚æœ¬ç ”ç©¶æ¢è®¨LLMsæ˜¯å¦è¡¨ç°å‡ºç±»ä¼¼äººæ ¼ç‰¹å¾ï¼Œä»¥åŠè¿™äº›ç‰¹å¾ä¸äººç±»äººæ ¼çš„æ¯”è¾ƒï¼Œé‡ç‚¹å…³æ³¨ä¼ ç»Ÿäººæ ¼è¯„ä¼°å·¥å…·çš„é€‚ç”¨æ€§ã€‚é€šè¿‡ä¸‰é¡¹å®è¯ç ”ç©¶ï¼Œå‘ç°LLMsåœ¨æµ‹è¯•-é‡æµ‹ç¨³å®šæ€§æ–¹é¢è¡¨ç°å‡ºæ›´é«˜çš„å˜å¼‚æ€§å’Œå¯¹è¾“å…¥çš„æ•æ„Ÿæ€§ï¼Œç¼ºä¹é•¿æœŸç¨³å®šæ€§ã€‚åŸºäºæ­¤ï¼Œæå‡ºåˆ†å¸ƒå¼äººæ ¼æ¡†æ¶ï¼Œå°†LLMsçš„äººæ ¼ç‰¹å¾æ¦‚å¿µåŒ–ä¸ºåŠ¨æ€å’Œè¾“å…¥é©±åŠ¨çš„ã€‚ç ”ç©¶ç»“æœä¸ºæ„å»ºLLMç‰¹å®šçš„äººæ ¼æ¡†æ¶å’Œä¿ƒè¿›äººæœºäº¤äº’æä¾›äº†è§è§£ï¼Œæ¨åŠ¨äº†è´Ÿè´£ä»»çš„äººå·¥æ™ºèƒ½å‘å±•ï¼Œæ‹“å±•äº†æ™ºèƒ½ç³»ç»Ÿæ—¶ä»£çš„äººæ ¼å¿ƒç†å­¦è¾¹ç•Œã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨äººæ ¼ç‰¹å¾è¯„ä¼°ä¸­çš„ç¨³å®šæ€§å’Œä¸€è‡´æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆæ•æ‰LLMsä¸äººç±»äººæ ¼çš„æ¯”è¾ƒï¼Œå¯¼è‡´è¯„ä¼°ç»“æœä¸å¯é ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„åˆ†å¸ƒå¼äººæ ¼æ¡†æ¶è®¤ä¸ºLLMsçš„äººæ ¼ç‰¹å¾æ˜¯åŠ¨æ€çš„ï¼Œå—è¾“å…¥å†…å®¹çš„å½±å“ï¼Œå¼ºè°ƒå…¶æµåŠ¨æ€§å’Œé€‚åº”æ€§ï¼Œä»¥æ­¤æ¥æ›´å¥½åœ°ç†è§£å’Œè¯„ä¼°LLMsçš„äººæ ¼è¡¨ç°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶åˆ†ä¸ºä¸‰é¡¹å®è¯ç ”ç©¶ï¼šç¬¬ä¸€é¡¹ç ”ç©¶æµ‹è¯•äº†LLMsçš„é‡æµ‹ç¨³å®šæ€§ï¼Œç¬¬äºŒé¡¹ç ”ç©¶åˆ†æäº†äººæ ¼æµ‹é‡çš„ä¸€è‡´æ€§ï¼Œç¬¬ä¸‰é¡¹ç ”ç©¶æ¢è®¨äº†è§’è‰²æ‰®æ¼”ä¸­çš„äººæ ¼ä¿æŒã€‚æ¯é¡¹ç ”ç©¶å‡é‡‡ç”¨è¡Œä¸ºåŸºç¡€çš„æ–¹æ³•è¿›è¡Œåˆ†æã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†åˆ†å¸ƒå¼äººæ ¼æ¡†æ¶ï¼Œå¼ºè°ƒLLMsçš„äººæ ¼ç‰¹å¾æ˜¯åŠ¨æ€å’Œè¾“å…¥é©±åŠ¨çš„ï¼Œä¸ä¼ ç»Ÿçš„äººæ ¼è¯„ä¼°æ–¹æ³•å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šç ”ç©¶ä¸­ä½¿ç”¨äº†ä¸åŒçš„æç¤ºå’Œå‚æ•°è®¾ç½®æ¥è¯„ä¼°LLMsçš„ååº”ï¼Œå‘ç°å…¶å¯¹é—®é¢˜æªè¾çš„æ•æ„Ÿæ€§è¾ƒé«˜ï¼Œå†…éƒ¨ä¸€è‡´æ€§ä½äºäººç±»ï¼Œæ˜¾ç¤ºå‡ºå…¶äººæ ¼ç‰¹å¾çš„æµåŠ¨æ€§å’Œå¤–éƒ¨ä¾èµ–æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMsåœ¨æµ‹è¯•ä¸­çš„è¡¨ç°é«˜åº¦ä¾èµ–äºè¾“å…¥æç¤ºï¼Œç¬¬ä¸€é¡¹ç ”ç©¶è¡¨æ˜å…¶é‡æµ‹ç¨³å®šæ€§ä½äºäººç±»ï¼Œç¬¬äºŒé¡¹ç ”ç©¶åˆ™å‘ç°å…¶å†…éƒ¨ä¸€è‡´æ€§æ˜¾è‘—ä½äºäººç±»ã€‚è¿™äº›å‘ç°ä¸ºç†è§£LLMsçš„äººæ ¼ç‰¹å¾æä¾›äº†é‡è¦è§è§£ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶ä¸ºå¤§å‹è¯­è¨€æ¨¡å‹çš„äººæ ¼ç‰¹å¾åˆ†ææä¾›äº†æ–°çš„è§†è§’ï¼Œæ½œåœ¨åº”ç”¨äºäººæœºäº¤äº’ã€æ™ºèƒ½å®¢æœå’Œä¸ªæ€§åŒ–æ¨èç³»ç»Ÿç­‰é¢†åŸŸã€‚é€šè¿‡ç†è§£LLMsçš„äººæ ¼ç‰¹å¾ï¼Œå¯ä»¥æå‡ç”¨æˆ·ä½“éªŒï¼Œä¿ƒè¿›æ›´è‡ªç„¶çš„äº¤äº’æ–¹å¼ï¼Œæ¨åŠ¨äººå·¥æ™ºèƒ½çš„è´Ÿè´£ä»»å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have demonstrated human-like capabilities in language comprehension and generation, becoming active participants in social and cognitive domains. This study investigates whether LLMs exhibit personality-like traits and how these traits compare with human personality, focusing on the applicability of conventional personality assessment tools. A behavior-based approach was used across three empirical studies. Study 1 examined test-retest stability and found that LLMs show higher variability and are more input-sensitive than humans, lacking long-term stability. Based on this, we propose the Distributed Personality Framework, conceptualizing LLM traits as dynamic and input-driven. Study 2 analyzed cross-variant consistency in personality measures and found LLMs' responses were highly sensitive to item wording, showing low internal consistency compared to humans. Study 3 explored personality retention during role-playing, showing LLM traits are shaped by prompt and parameter settings. These findings suggest that LLMs express fluid, externally dependent personality patterns, offering insights for constructing LLM-specific personality frameworks and advancing human-AI interaction. This work contributes to responsible AI development and extends the boundaries of personality psychology in the age of intelligent systems.

