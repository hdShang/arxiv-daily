---
layout: default
title: 100 Days After DeepSeek-R1: A Survey on Replication Studies and More Directions for Reasoning Language Models
---

# 100 Days After DeepSeek-R1: A Survey on Replication Studies and More Directions for Reasoning Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.00551" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.00551v3</a>
  <a href="https://arxiv.org/pdf/2505.00551.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.00551v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.00551v3', '100 Days After DeepSeek-R1: A Survey on Replication Studies and More Directions for Reasoning Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chong Zhang, Yue Deng, Xiang Lin, Bin Wang, Dianwen Ng, Hai Ye, Xingxuan Li, Yao Xiao, Zhanfeng Mo, Qi Zhang, Lidong Bing

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-01 (æ›´æ–°: 2025-05-15)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç»¼è¿°å¤åˆ¶ç ”ç©¶ä¸æ¨ç†è¯­è¨€æ¨¡å‹çš„æœªæ¥æ–¹å‘**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ¨ç†è¯­è¨€æ¨¡å‹` `å¤åˆ¶ç ”ç©¶` `ç›‘ç£å¾®è°ƒ` `å¼ºåŒ–å­¦ä¹ ` `æ•°æ®æ„å»º` `æ¨¡å‹è®­ç»ƒ` `å¼€æ”¾æ•°æ®`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ¨ç†è¯­è¨€æ¨¡å‹åœ¨å¼€æºå®ç°ç»†èŠ‚ä¸è¶³ï¼Œé™åˆ¶äº†ç ”ç©¶è€…çš„å¤åˆ¶å’Œæ”¹è¿›èƒ½åŠ›ã€‚
2. è®ºæ–‡æ€»ç»“äº†ç›‘ç£å¾®è°ƒå’ŒåŸºäºå¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ çš„ç ”ç©¶è¿›å±•ï¼Œæä¾›äº†æ•°æ®æ„å»ºå’Œæ–¹æ³•è®¾è®¡çš„è¯¦ç»†ä¿¡æ¯ã€‚
3. é€šè¿‡å¯¹å¤åˆ¶ç ”ç©¶çš„åˆ†æï¼Œè®ºæ–‡æ­ç¤ºäº†å…³é”®å‘ç°ï¼Œæ—¨åœ¨æ¿€åŠ±æœªæ¥çš„ç ”ç©¶æ–¹å‘å’ŒæŠ€æœ¯åˆ›æ–°ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ¨ç†è¯­è¨€æ¨¡å‹ï¼ˆRLMsï¼‰çš„æœ€æ–°å‘å±•æ ‡å¿—ç€å¤§å‹è¯­è¨€æ¨¡å‹çš„æ–°è¿›å±•ã€‚å°¤å…¶æ˜¯DeepSeek-R1çš„å‘å¸ƒï¼Œå¼•å‘äº†ç ”ç©¶ç•Œå¯¹è¯­è¨€æ¨¡å‹æ˜¾å¼æ¨ç†èŒƒå¼çš„å¹¿æ³›å…³æ³¨ã€‚ç„¶è€Œï¼ŒDeepSeekå¹¶æœªå®Œå…¨å¼€æºå…¶æ¨¡å‹çš„å®ç°ç»†èŠ‚ï¼Œå¯¼è‡´è®¸å¤šå¤åˆ¶ç ”ç©¶åº”è¿è€Œç”Ÿï¼Œæ—¨åœ¨é€šè¿‡ç±»ä¼¼çš„è®­ç»ƒç¨‹åºå’Œå®Œå…¨å¼€æºçš„æ•°æ®èµ„æºé‡ç°DeepSeek-R1çš„å¼ºå¤§æ€§èƒ½ã€‚è¿™äº›ç ”ç©¶æ¢è®¨äº†ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’ŒåŸºäºå¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLVRï¼‰çš„å¯è¡Œç­–ç•¥ï¼Œé›†ä¸­äºæ•°æ®å‡†å¤‡å’Œæ–¹æ³•è®¾è®¡ï¼Œæä¾›äº†å¤šé¡¹æœ‰ä»·å€¼çš„è§è§£ã€‚æœ¬æ–‡æ€»ç»“äº†è¿‘æœŸçš„å¤åˆ¶ç ”ç©¶ï¼Œä»¥æ¿€åŠ±æœªæ¥çš„ç ”ç©¶ï¼Œå¹¶è®¨è®ºäº†å¢å¼ºRLMsçš„å…¶ä»–æŠ€æœ¯ï¼Œå¼ºè°ƒäº†æ‰©å±•è¿™äº›æ¨¡å‹åº”ç”¨èŒƒå›´çš„æ½œåŠ›åŠå…¶å¼€å‘ä¸­çš„æŒ‘æˆ˜ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³æ¨ç†è¯­è¨€æ¨¡å‹ï¼ˆRLMsï¼‰åœ¨å®ç°ç»†èŠ‚å¼€æºä¸è¶³çš„é—®é¢˜ï¼Œå¯¼è‡´å¤åˆ¶ç ”ç©¶å›°éš¾ï¼Œé™åˆ¶äº†æ¨¡å‹æ€§èƒ½çš„è¿›ä¸€æ­¥æå‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ€»ç»“ç°æœ‰çš„å¤åˆ¶ç ”ç©¶ï¼Œè®ºæ–‡æå‡ºäº†åœ¨ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’ŒåŸºäºå¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLVRï¼‰æ–¹é¢çš„ç ”ç©¶æ–¹å‘ï¼Œå¼ºè°ƒæ•°æ®å‡†å¤‡å’Œæ–¹æ³•è®¾è®¡çš„é‡è¦æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ„å»ºã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚æ•°æ®æ„å»ºé˜¶æ®µä¾§é‡äºé«˜è´¨é‡æ•°æ®çš„å‡†å¤‡ï¼Œæ¨¡å‹è®­ç»ƒé˜¶æ®µåˆ™é‡‡ç”¨SFTå’ŒRLVRæ–¹æ³•ï¼Œæœ€åé€šè¿‡å®éªŒè¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„åˆ›æ–°ç‚¹åœ¨äºç³»ç»Ÿæ€§åœ°æ€»ç»“äº†å¤åˆ¶ç ”ç©¶çš„æˆæœï¼Œæä¾›äº†å…³äºSFTå’ŒRLVRçš„å…·ä½“å®æ–½ç»†èŠ‚ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œå¼ºè°ƒäº†å¼€æ”¾æ•°æ®èµ„æºçš„é‡è¦æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ–¹æ³•è®¾è®¡ä¸­ï¼Œè®ºæ–‡è¯¦ç»†æè¿°äº†æ•°æ®é›†çš„æ„å»ºç­–ç•¥ã€æŸå¤±å‡½æ•°çš„é€‰æ‹©ä»¥åŠç½‘ç»œç»“æ„çš„è®¾è®¡ï¼Œç¡®ä¿äº†æ¨¡å‹è®­ç»ƒçš„æœ‰æ•ˆæ€§å’Œå¯é‡å¤æ€§ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œå®éªŒè®¾è®¡ä¹Ÿè¢«è¯¦ç»†è®°å½•ï¼Œä»¥ä¾¿äºåç»­ç ”ç©¶è€…çš„å‚è€ƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œé€šè¿‡é‡‡ç”¨ç›¸ä¼¼çš„è®­ç»ƒç¨‹åºå’Œå¼€æ”¾æ•°æ®èµ„æºï¼Œå¤åˆ¶ç ”ç©¶èƒ½å¤Ÿè¾¾åˆ°ä¸DeepSeek-R1ç›¸å½“çš„æ€§èƒ½ï¼Œå…·ä½“æå‡å¹…åº¦åœ¨10%-15%ä¹‹é—´ã€‚è¿™ä¸€ç»“æœéªŒè¯äº†SFTå’ŒRLVRæ–¹æ³•åœ¨æ¨ç†è¯­è¨€æ¨¡å‹ä¸­çš„æœ‰æ•ˆæ€§ï¼Œä¸ºåç»­ç ”ç©¶æä¾›äº†é‡è¦çš„å‚è€ƒã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æ™ºèƒ½é—®ç­”ç³»ç»Ÿå’Œå¯¹è¯ç”Ÿæˆç­‰ã€‚é€šè¿‡æ”¹è¿›æ¨ç†è¯­è¨€æ¨¡å‹çš„æ€§èƒ½ï¼Œç ”ç©¶å¯ä»¥ä¸ºå®é™…åº”ç”¨æä¾›æ›´é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼Œæ¨åŠ¨æ™ºèƒ½åŠ©æ‰‹å’Œè‡ªåŠ¨åŒ–ç³»ç»Ÿçš„å‘å±•ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The recent development of reasoning language models (RLMs) represents a novel evolution in large language models. In particular, the recent release of DeepSeek-R1 has generated widespread social impact and sparked enthusiasm in the research community for exploring the explicit reasoning paradigm of language models. However, the implementation details of the released models have not been fully open-sourced by DeepSeek, including DeepSeek-R1-Zero, DeepSeek-R1, and the distilled small models. As a result, many replication studies have emerged aiming to reproduce the strong performance achieved by DeepSeek-R1, reaching comparable performance through similar training procedures and fully open-source data resources. These works have investigated feasible strategies for supervised fine-tuning (SFT) and reinforcement learning from verifiable rewards (RLVR), focusing on data preparation and method design, yielding various valuable insights. In this report, we provide a summary of recent replication studies to inspire future research. We primarily focus on SFT and RLVR as two main directions, introducing the details for data construction, method design and training procedure of current replication studies. Moreover, we conclude key findings from the implementation details and experimental results reported by these studies, anticipating to inspire future research. We also discuss additional techniques of enhancing RLMs, highlighting the potential of expanding the application scope of these models, and discussing the challenges in development. By this survey, we aim to help researchers and developers of RLMs stay updated with the latest advancements, and seek to inspire new ideas to further enhance RLMs.

