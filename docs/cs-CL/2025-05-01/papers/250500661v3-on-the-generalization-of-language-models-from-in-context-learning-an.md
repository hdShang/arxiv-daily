---
layout: default
title: "On the generalization of language models from in-context learning and finetuning: a controlled study"
---

# On the generalization of language models from in-context learning and finetuning: a controlled study

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.00661" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.00661v3</a>
  <a href="https://arxiv.org/pdf/2505.00661.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.00661v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.00661v3', 'On the generalization of language models from in-context learning and finetuning: a controlled study')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Andrew K. Lampinen, Arslan Chaudhry, Stephanie C. Y. Chan, Cody Wild, Diane Wan, Alex Ku, JÃ¶rg Bornschein, Razvan Pascanu, Murray Shanahan, James L. McClelland

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-01 (æ›´æ–°: 2025-11-10)

**å¤‡æ³¨**: FoRLM workshop, NeurIPS 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ–°æ–¹æ³•ä»¥æ”¹å–„è¯­è¨€æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯­è¨€æ¨¡å‹` `ä¸Šä¸‹æ–‡å­¦ä¹ ` `å¾®è°ƒ` `æ¨ç†èƒ½åŠ›` `æ³›åŒ–èƒ½åŠ›` `æ•°æ®é›†æ„å»º` `äººå·¥æ™ºèƒ½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¾®è°ƒåæ³›åŒ–èƒ½åŠ›ä¸è¶³ï¼Œæ— æ³•å¤„ç†ç®€å•çš„é€»è¾‘æ¨ç†å’Œå…³ç³»åè½¬ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹ ä¸å¾®è°ƒç›¸ç»“åˆçš„æ–¹æ³•ï¼Œå¢å¼ºæ¨¡å‹çš„æ¨ç†èƒ½åŠ›å’Œæ³›åŒ–èƒ½åŠ›ã€‚
3. å®éªŒè¡¨æ˜ï¼Œæ–°çš„æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæ˜¾è‘—æé«˜äº†æ¨¡å‹çš„æ³›åŒ–æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹å±•ç°å‡ºä»¤äººå…´å¥‹çš„èƒ½åŠ›ï¼Œä½†åœ¨å¾®è°ƒåå´å¯èƒ½è¡¨ç°å‡ºæƒŠäººçš„ç‹­çª„æ³›åŒ–èƒ½åŠ›ï¼Œä¾‹å¦‚æ— æ³•å¯¹è®­ç»ƒå…³ç³»çš„ç®€å•åè½¬è¿›è¡Œæ³›åŒ–ï¼Œæˆ–æ— æ³•åŸºäºè®­ç»ƒä¿¡æ¯è¿›è¡Œç®€å•çš„é€»è¾‘æ¨ç†ã€‚è¿™äº›å¾®è°ƒåæ³›åŒ–èƒ½åŠ›çš„ç¼ºå¤±æ˜¾è‘—å½±å“äº†æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚å¦ä¸€æ–¹é¢ï¼Œè¯­è¨€æ¨¡å‹çš„ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰å±•ç°å‡ºä¸åŒçš„å½’çº³åå·®å’Œæ¨ç†èƒ½åŠ›ã€‚æœ¬æ–‡æ¢è®¨äº†ICLä¸å¾®è°ƒåœ¨æ³›åŒ–å’Œæ¨ç†èƒ½åŠ›ä¸Šçš„å·®å¼‚ï¼Œæ„å»ºäº†å¤šä¸ªæ–°æ•°æ®é›†ä»¥è¯„ä¼°æ¨¡å‹åœ¨æ–°æ•°æ®ä¸Šå¯¹äº‹å®ä¿¡æ¯çš„æ³›åŒ–èƒ½åŠ›ã€‚ç ”ç©¶å‘ç°ï¼Œåœ¨æ•°æ®åŒ¹é…çš„è®¾ç½®ä¸­ï¼ŒICLåœ¨å¤šç§æ¨ç†ç±»å‹ä¸Šæ¯”å¾®è°ƒæ›´å…·çµæ´»æ€§ã€‚åŸºäºæ­¤ï¼Œæå‡ºäº†ä¸€ç§é€šè¿‡åœ¨å¾®è°ƒæ•°æ®ä¸­æ·»åŠ ä¸Šä¸‹æ–‡æ¨ç†ç—•è¿¹çš„æ–¹æ³•ï¼Œä»¥æé«˜å¾®è°ƒçš„æ³›åŒ–èƒ½åŠ›ï¼Œå®éªŒç»“æœæ˜¾ç¤ºè¯¥æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†å’ŒåŸºå‡†æµ‹è¯•ä¸­å‡æœ‰æ˜¾è‘—æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¾®è°ƒåæ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨é€»è¾‘æ¨ç†å’Œå…³ç³»åè½¬æ–¹é¢çš„è¡¨ç°ä¸ä½³ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†æ–°ä¿¡æ¯æ—¶å¸¸å¸¸æ— æ³•æœ‰æ•ˆæ³›åŒ–ï¼Œé™åˆ¶äº†æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ç»“åˆä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰ä¸å¾®è°ƒï¼Œé€šè¿‡åœ¨å¾®è°ƒæ•°æ®ä¸­å¼•å…¥ä¸Šä¸‹æ–‡æ¨ç†ç—•è¿¹ï¼Œæ¥æå‡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨åˆ©ç”¨ICLçš„çµæ´»æ€§æ¥å¼¥è¡¥å¾®è°ƒçš„ä¸è¶³ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€æ¨¡å‹è®­ç»ƒå’Œæ€§èƒ½è¯„ä¼°ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œæ„å»ºå¤šä¸ªæ–°æ•°æ®é›†ä»¥æµ‹è¯•æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼›å…¶æ¬¡ï¼Œé€šè¿‡ICLå’Œå¾®è°ƒä¸¤ç§æ–¹å¼å¯¹é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œè®­ç»ƒï¼›æœ€åï¼Œè¯„ä¼°æ¨¡å‹åœ¨ä¸åŒæµ‹è¯•é›†ä¸Šçš„è¡¨ç°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ä¸€ç§æ–°çš„å¾®è°ƒæ–¹æ³•ï¼Œé€šè¿‡å¼•å…¥ä¸Šä¸‹æ–‡æ¨ç†ç—•è¿¹æ¥å¢å¼ºæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„å¾®è°ƒæ–¹å¼æœ¬è´¨ä¸Šä¸åŒï¼Œå› ä¸ºå®ƒç»“åˆäº†ICLçš„ä¼˜åŠ¿ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å…³é”®è®¾è®¡ä¸Šï¼Œè®ºæ–‡è¯¦ç»†æè¿°äº†æ•°æ®é›†çš„æ„å»ºæ–¹å¼ã€æ¨¡å‹è®­ç»ƒä¸­çš„å‚æ•°è®¾ç½®ï¼Œä»¥åŠæŸå¤±å‡½æ•°çš„é€‰æ‹©ã€‚ç‰¹åˆ«æ˜¯åœ¨å¾®è°ƒé˜¶æ®µï¼ŒåŠ å…¥äº†ä¸Šä¸‹æ–‡æ¨ç†ç—•è¿¹ï¼Œä»¥ç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œæ³›åŒ–æ–°ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œé‡‡ç”¨æ–°æ–¹æ³•çš„æ¨¡å‹åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæ³›åŒ–æ€§èƒ½æ˜¾è‘—æå‡ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­ï¼Œç›¸è¾ƒäºä¼ ç»Ÿå¾®è°ƒæ–¹æ³•ï¼Œæ³›åŒ–èƒ½åŠ›æé«˜äº†20%ä»¥ä¸Šã€‚è¿™ä¸€å‘ç°ä¸ºè¯­è¨€æ¨¡å‹çš„è®­ç»ƒå’Œåº”ç”¨æä¾›äº†æ–°çš„æ€è·¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æ™ºèƒ½é—®ç­”ç³»ç»Ÿå’Œå¯¹è¯ç”Ÿæˆç­‰ã€‚é€šè¿‡æé«˜è¯­è¨€æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡è¿™äº›ç³»ç»Ÿåœ¨å¤„ç†å¤æ‚æ¨ç†ä»»åŠ¡æ—¶çš„è¡¨ç°ï¼Œè¿›è€Œæ¨åŠ¨äººå·¥æ™ºèƒ½åœ¨å®é™…åº”ç”¨ä¸­çš„å‘å±•ä¸è½åœ°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models exhibit exciting capabilities, yet can show surprisingly narrow generalization from finetuning. E.g. they can fail to generalize to simple reversals of relations they are trained on, or fail to make simple logical deductions based on trained information. These failures to generalize factual information from fine-tuning can significantly hinder the reasoning capabilities of these models. On the other hand, language models' in-context learning (ICL) shows different inductive biases and deductive reasoning capabilities. Here, we explore these differences in generalization and deductive reasoning between in-context- and fine-tuning-based learning. To do so, we constructed several novel datasets to evaluate and improve models' abilities to make generalizations over factual information from novel data. These datasets are designed to create clean tests of generalization, by isolating the knowledge in the dataset from that in pretraining. We expose pretrained large models to controlled subsets of the information in these datasets -- either through ICL or fine-tuning -- and evaluate their performance on test sets that require various types of generalization. We find overall that in data-matched settings, ICL can generalize several types of inferences more flexibly than fine-tuning (though we also find some qualifications of prior findings, such as cases when fine-tuning can generalize to reversals embedded in a larger structure of knowledge). We build on these findings to propose a method to enable improved generalization from fine-tuning: adding in-context reasoning traces to finetuning data. We show that this method improves generalization across various splits of our datasets and other benchmarks. Our results have implications for understanding the generalization afforded by different modes of learning in language models, and practically improving their performance.

