---
layout: default
title: Dual Decomposition of Weights and Singular Value Low Rank Adaptation
---

# Dual Decomposition of Weights and Singular Value Low Rank Adaptation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14367" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14367v2</a>
  <a href="https://arxiv.org/pdf/2505.14367.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14367v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14367v2', 'Dual Decomposition of Weights and Singular Value Low Rank Adaptation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jialong Han, Si Zhang, Ke Zhang

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20 (æ›´æ–°: 2025-05-21)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDuDeä»¥è§£å†³LoRAæ–¹æ³•çš„è®­ç»ƒä¸ç¨³å®šå’ŒçŸ¥è¯†è½¬ç§»æ•ˆç‡ä½çš„é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å‚æ•°é«˜æ•ˆå¾®è°ƒ` `ä½ç§©é€‚åº”` `å¥‡å¼‚å€¼åˆ†è§£` `çŸ¥è¯†è½¬ç§»` `è®­ç»ƒç¨³å®šæ€§` `å¤§å‹è¯­è¨€æ¨¡å‹` `é¢†åŸŸç‰¹å®šä»»åŠ¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„LoRAæ–¹æ³•åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¡¨ç°å‡ºä¸ç¨³å®šæ€§ï¼Œå¹¶ä¸”ä»é¢„è®­ç»ƒæ¨¡å‹ä¸­è½¬ç§»çŸ¥è¯†çš„æ•ˆç‡è¾ƒä½ã€‚
2. æœ¬æ–‡æå‡ºçš„DuDeæ–¹æ³•é€šè¿‡å°†æƒé‡çŸ©é˜µåˆ†è§£ä¸ºå¹…åº¦å’Œæ–¹å‘åˆ†é‡ï¼Œåˆ©ç”¨å¥‡å¼‚å€¼åˆ†è§£è¿›è¡Œåˆå§‹åŒ–ï¼Œä»è€Œæé«˜äº†è®­ç»ƒçš„ç¨³å®šæ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDuDeåœ¨MMLUå’ŒGSM8Kä»»åŠ¡ä¸Šåˆ†åˆ«è¾¾åˆ°äº†48.35%å’Œ62.53%çš„å‡†ç¡®ç‡ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰å·²æˆä¸ºé€‚åº”å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰äºä¸‹æ¸¸ä»»åŠ¡çš„é‡è¦èŒƒå¼ï¼Œå…¶ä¸­ä½ç§©é€‚åº”ï¼ˆLoRAï¼‰æ˜¯æœ€å¹¿æ³›é‡‡ç”¨çš„æ–¹æ³•ä¹‹ä¸€ã€‚ç„¶è€Œï¼Œç°æœ‰çš„LoRAæ–¹æ³•å­˜åœ¨ä¸¤ä¸ªåŸºæœ¬å±€é™æ€§ï¼šè®­ç»ƒåŠ¨æ€ä¸ç¨³å®šå’Œä»é¢„è®­ç»ƒæ¨¡å‹ä¸­çŸ¥è¯†è½¬ç§»æ•ˆç‡ä½ï¼Œè¿™ä¸»è¦æºäºé€‚é…å™¨å‚æ•°çš„éšæœºåˆå§‹åŒ–ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†DuDeï¼Œä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œé€šè¿‡å°†æƒé‡çŸ©é˜µåˆ†è§£ä¸ºå¹…åº¦å’Œæ–¹å‘åˆ†é‡ï¼Œå¹¶é‡‡ç”¨å¥‡å¼‚å€¼åˆ†è§£ï¼ˆSVDï¼‰è¿›è¡ŒåŸåˆ™æ€§åˆå§‹åŒ–ã€‚ç»¼åˆè¯„ä¼°è¡¨æ˜ï¼ŒDuDeåœ¨MMLUä¸Šè¾¾åˆ°äº†48.35%çš„å‡†ç¡®ç‡ï¼Œåœ¨GSM8Kä¸Šè¾¾åˆ°äº†62.53%ï¼ˆÂ±1.59ï¼‰çš„å‡†ç¡®ç‡ã€‚ç†è®ºåˆ†æå’Œå®è¯éªŒè¯å…±åŒè¡¨æ˜ï¼ŒDuDeçš„åˆ†è§£ç­–ç•¥å¢å¼ºäº†ä¼˜åŒ–çš„ç¨³å®šæ€§ï¼Œå¹¶æ›´å¥½åœ°ä¿ç•™äº†é¢„è®­ç»ƒè¡¨ç¤ºï¼Œå°¤å…¶é€‚ç”¨äºéœ€è¦ä¸“ä¸šçŸ¥è¯†çš„é¢†åŸŸç‰¹å®šä»»åŠ¡ã€‚DuDeçš„ç¨³å¥å®è¯è¡¨ç°å’Œä¸¥è°¨ç†è®ºåŸºç¡€ä½¿å…¶æˆä¸ºPEFTæ–¹æ³•è®ºåœ¨LLMsé¢†åŸŸçš„é‡è¦è´¡çŒ®ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰LoRAæ–¹æ³•åœ¨è®­ç»ƒåŠ¨æ€ä¸ç¨³å®šå’ŒçŸ¥è¯†è½¬ç§»æ•ˆç‡ä½çš„é—®é¢˜ï¼Œè¿™äº›é—®é¢˜ä¸»è¦æºäºé€‚é…å™¨å‚æ•°çš„éšæœºåˆå§‹åŒ–ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDuDeæ–¹æ³•é€šè¿‡å°†æƒé‡çŸ©é˜µåˆ†è§£ä¸ºå¹…åº¦å’Œæ–¹å‘åˆ†é‡ï¼Œé‡‡ç”¨å¥‡å¼‚å€¼åˆ†è§£ï¼ˆSVDï¼‰è¿›è¡Œåˆå§‹åŒ–ï¼Œä»è€Œå®ç°æ›´ç¨³å®šçš„è®­ç»ƒè¿‡ç¨‹å’Œæ›´æœ‰æ•ˆçš„çŸ¥è¯†ä¿ç•™ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDuDeçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æƒé‡åˆ†è§£æ¨¡å—ã€SVDåˆå§‹åŒ–æ¨¡å—å’Œé€‚é…å™¨è®­ç»ƒæ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡SVDå¯¹æƒé‡è¿›è¡Œåˆ†è§£ï¼Œç„¶ååŸºäºåˆ†è§£ç»“æœè¿›è¡Œé€‚é…å™¨çš„è®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šDuDeçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶æƒé‡åˆ†è§£ç­–ç•¥ï¼Œè¿™ä¸€ç­–ç•¥ä¸ä¼ ç»Ÿçš„éšæœºåˆå§‹åŒ–æ–¹æ³•æœ¬è´¨ä¸Šä¸åŒï¼Œèƒ½å¤Ÿæ˜¾è‘—æé«˜ä¼˜åŒ–çš„ç¨³å®šæ€§å’ŒçŸ¥è¯†è½¬ç§»çš„æ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼ŒDuDeé‡‡ç”¨äº†åŸºäºSVDçš„åˆå§‹åŒ–æ–¹æ³•ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸Šåˆ™è€ƒè™‘äº†é€‚åº”æ€§è°ƒæ•´ï¼Œä»¥ç¡®ä¿åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­èƒ½å¤Ÿæœ‰æ•ˆä¿ç•™é¢„è®­ç»ƒæ¨¡å‹çš„çŸ¥è¯†ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„ç»†èŠ‚å’Œå‚æ•°è®¾ç½®åœ¨å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

DuDeåœ¨MMLUä»»åŠ¡ä¸Šè¾¾åˆ°äº†48.35%çš„å‡†ç¡®ç‡ï¼Œåœ¨GSM8Kä»»åŠ¡ä¸Šè¾¾åˆ°äº†62.53%ï¼ˆÂ±1.59ï¼‰çš„å‡†ç¡®ç‡ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰LoRAæ–¹æ³•ï¼Œå±•ç¤ºäº†å…¶åœ¨è®­ç»ƒç¨³å®šæ€§å’ŒçŸ¥è¯†è½¬ç§»æ•ˆç‡æ–¹é¢çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€å¯¹è¯ç³»ç»Ÿå’Œé¢†åŸŸç‰¹å®šçš„çŸ¥è¯†åº”ç”¨ç­‰ã€‚é€šè¿‡æé«˜å¤§å‹è¯­è¨€æ¨¡å‹çš„é€‚åº”èƒ½åŠ›ï¼ŒDuDeèƒ½å¤Ÿåœ¨å¤šç§ä¸‹æ¸¸ä»»åŠ¡ä¸­å®ç°æ›´é«˜çš„æ€§èƒ½ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Parameter-Efficient Fine-Tuning (PEFT) has emerged as a critical paradigm for adapting Large Language Models (LLMs) to downstream tasks, among which Low-rank Adaptation (LoRA) represents one of the most widely adopted methodologies. However, existing LoRA-based approaches exhibit two fundamental limitations: unstable training dynamics and inefficient knowledge transfer from pre-trained models, both stemming from random initialization of adapter parameters. To overcome these challenges, we propose DuDe, a novel approach that decomposes weight matrices into magnitude and direction components, employing Singular Value Decomposition (SVD) for principled initialization. Our comprehensive evaluation demonstrates DuDe's superior performance and robustness, achieving up to 48.35\% accuracy on MMLU and 62.53\% ($\pm$ 1.59) accuracy on GSM8K. Our theoretical analysis and empirical validation collectively demonstrate that DuDe's decomposition strategy enhances optimization stability and better preserves pre-trained representations, particularly for domain-specific tasks requiring specialized knowledge. The combination of robust empirical performance and rigorous theoretical foundations establishes DuDe as a significant contribution to PEFT methodologies for LLMs.

