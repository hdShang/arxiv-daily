---
layout: default
title: Language Mixing in Reasoning Language Models: Patterns, Impact, and Internal Causes
---

# Language Mixing in Reasoning Language Models: Patterns, Impact, and Internal Causes

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14815" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14815v3</a>
  <a href="https://arxiv.org/pdf/2505.14815.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14815v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14815v3', 'Language Mixing in Reasoning Language Models: Patterns, Impact, and Internal Causes')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mingyang Wang, Lukas Lange, Heike Adel, Yunpu Ma, Jannik StrÃ¶tgen, Hinrich SchÃ¼tze

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20 (æ›´æ–°: 2025-09-19)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç³»ç»Ÿç ”ç©¶è¯­è¨€æ··åˆå¯¹æ¨ç†è¯­è¨€æ¨¡å‹çš„å½±å“åŠä¼˜åŒ–ç­–ç•¥**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ¨ç†è¯­è¨€æ¨¡å‹` `è¯­è¨€æ··åˆ` `å¤šè¯­è¨€å¤„ç†` `çº¦æŸè§£ç ` `æ¨¡å‹ä¼˜åŒ–` `æ€§èƒ½æå‡` `å†…éƒ¨è¡¨ç¤º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ¨ç†è¯­è¨€æ¨¡å‹åœ¨å¤„ç†å¤šè¯­è¨€ä»»åŠ¡æ—¶ï¼Œè¾“å‡ºä¸­å¸¸å‡ºç°è¯­è¨€æ··åˆç°è±¡ï¼Œå½±å“æ¨¡å‹æ€§èƒ½ï¼Œä¸”å…¶å½±å“æœºåˆ¶å°šä¸æ˜ç¡®ã€‚
2. æœ¬æ–‡é€šè¿‡ç³»ç»Ÿç ”ç©¶è¯­è¨€æ··åˆçš„æ¨¡å¼ã€å½±å“åŠå†…éƒ¨åŸå› ï¼Œæå‡ºé€šè¿‡çº¦æŸè§£ç ä¼˜åŒ–æ¨ç†è¯­è¨€é€‰æ‹©ï¼Œä»¥æé«˜æ¨¡å‹å‡†ç¡®æ€§ã€‚
3. ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œå¼ºåˆ¶æ¨¡å‹ä½¿ç”¨ç‰¹å®šè„šæœ¬è¿›è¡Œæ¨ç†èƒ½æ˜¾è‘—æå‡æ€§èƒ½ï¼Œä¸”æ¨ç†è½¨è¿¹ä¸å†…éƒ¨è¡¨ç¤ºä¹‹é—´å­˜åœ¨å¯†åˆ‡å…³ç³»ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ¨ç†è¯­è¨€æ¨¡å‹ï¼ˆRLMsï¼‰é€šè¿‡é“¾å¼æ€ç»´è¿‡ç¨‹åœ¨å¤æ‚ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†è¾“å‡ºä¸­å­˜åœ¨è¯­è¨€æ··åˆç°è±¡ï¼Œå³æ¨ç†æ­¥éª¤ä¸­åŒ…å«ä¸æç¤ºä¸åŒçš„è¯­è¨€æ ‡è®°ï¼Œè¿™å¯¹æ€§èƒ½äº§ç”Ÿå½±å“ã€‚æœ¬æ–‡é¦–æ¬¡ç³»ç»Ÿç ”ç©¶äº†15ç§è¯­è¨€ã€7ä¸ªä»»åŠ¡éš¾åº¦çº§åˆ«å’Œ18ä¸ªå­¦ç§‘é¢†åŸŸä¸­çš„è¯­è¨€æ··åˆæ¨¡å¼ã€å½±å“åŠå…¶å†…éƒ¨åŸå› ï¼Œè¡¨æ˜è¿™ä¸‰è€…å‡å¯¹è¯­è¨€æ··åˆæœ‰æ˜¾è‘—å½±å“ã€‚æ­¤å¤–ï¼Œç ”ç©¶å‘ç°æ¨ç†è¯­è¨€çš„é€‰æ‹©æ˜¾è‘—å½±å“æ¨¡å‹æ€§èƒ½ï¼Œé€šè¿‡çº¦æŸè§£ç å¼ºåˆ¶æ¨¡å‹ä½¿ç”¨æ‹‰ä¸æˆ–æ±‰å­—è„šæœ¬è¿›è¡Œæ¨ç†ï¼Œå‡†ç¡®æ€§æ˜¾è‘—æé«˜ã€‚æœ€åï¼Œæ¨ç†è½¨è¿¹çš„è„šæœ¬ç»„æˆä¸æ¨¡å‹å†…éƒ¨è¡¨ç¤ºå¯†åˆ‡ç›¸å…³ï¼Œè¡¨æ˜è¯­è¨€æ··åˆåæ˜ äº†RLMsçš„æ½œåœ¨å¤„ç†åå¥½ã€‚æˆ‘ä»¬çš„å‘ç°ä¸ºä¼˜åŒ–å¤šè¯­è¨€æ¨ç†æä¾›äº†å¯è¡Œçš„è§è§£ï¼Œå¹¶ä¸ºæ§åˆ¶æ¨ç†è¯­è¨€å¼€è¾Ÿäº†æ–°æ–¹å‘ï¼Œä»¥æ„å»ºæ›´å…·å¯è§£é‡Šæ€§å’Œé€‚åº”æ€§çš„RLMsã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ¨ç†è¯­è¨€æ¨¡å‹è¾“å‡ºä¸­è¯­è¨€æ··åˆç°è±¡å¯¹æ€§èƒ½çš„å½±å“ï¼Œç°æœ‰ç ”ç©¶å¯¹å…¶å½±å“æœºåˆ¶ç¼ºä¹ç³»ç»Ÿæ€§åˆ†æã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡ç³»ç»Ÿæ€§ç ”ç©¶è¯­è¨€æ··åˆçš„æ¨¡å¼ã€å½±å“åŠå†…éƒ¨åŸå› ï¼Œæ¢ç´¢å¦‚ä½•é€šè¿‡é€‰æ‹©åˆé€‚çš„æ¨ç†è¯­è¨€æ¥ä¼˜åŒ–æ¨¡å‹æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶æ¶µç›–15ç§è¯­è¨€ã€7ä¸ªä»»åŠ¡éš¾åº¦å’Œ18ä¸ªå­¦ç§‘é¢†åŸŸï¼Œé‡‡ç”¨å®éªŒè®¾è®¡åˆ†æè¯­è¨€æ··åˆçš„å½±å“å› ç´ ï¼Œè¯„ä¼°ä¸åŒæ¨ç†è¯­è¨€çš„æ€§èƒ½è¡¨ç°ã€‚

**å…³é”®åˆ›æ–°**ï¼šé¦–æ¬¡ç³»ç»Ÿæ€§åˆ†æè¯­è¨€æ··åˆåœ¨æ¨ç†è¯­è¨€æ¨¡å‹ä¸­çš„ä½œç”¨ï¼Œå‘ç°æ¨ç†è¯­è¨€é€‰æ‹©å¯¹æ¨¡å‹æ€§èƒ½æœ‰æ˜¾è‘—å½±å“ï¼Œæå‡ºçº¦æŸè§£ç ç­–ç•¥ä»¥ä¼˜åŒ–æ¨ç†è¿‡ç¨‹ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œè®¾ç½®äº†ä¸åŒçš„è¯­è¨€ç»„åˆå’Œä»»åŠ¡éš¾åº¦ï¼Œé‡‡ç”¨çº¦æŸè§£ç æŠ€æœ¯å¼ºåˆ¶æ¨¡å‹ä½¿ç”¨ç‰¹å®šè„šæœ¬è¿›è¡Œæ¨ç†ï¼Œè¯„ä¼°å…¶å¯¹å‡†ç¡®æ€§çš„å½±å“ã€‚é€šè¿‡å¯¹æ¯”å®éªŒï¼ŒéªŒè¯äº†æ¨¡å‹åœ¨ä¸åŒè¯­è¨€æ¡ä»¶ä¸‹çš„æ€§èƒ½å˜åŒ–ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå¼ºåˆ¶æ¨¡å‹ä½¿ç”¨æ‹‰ä¸æˆ–æ±‰å­—è„šæœ¬è¿›è¡Œæ¨ç†æ—¶ï¼Œå‡†ç¡®æ€§æ˜¾è‘—æé«˜ï¼Œæå‡å¹…åº¦è¾¾åˆ°XX%ï¼ˆå…·ä½“æ•°æ®éœ€æ ¹æ®åŸæ–‡è¡¥å……ï¼‰ã€‚æ­¤å¤–ï¼Œç ”ç©¶æ­ç¤ºäº†æ¨ç†è½¨è¿¹ä¸å†…éƒ¨è¡¨ç¤ºä¹‹é—´çš„å¯†åˆ‡å…³ç³»ï¼Œä¸ºç†è§£æ¨¡å‹è¡Œä¸ºæä¾›äº†æ–°çš„è§†è§’ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤šè¯­è¨€è‡ªç„¶è¯­è¨€å¤„ç†ã€è·¨è¯­è¨€ä¿¡æ¯æ£€ç´¢ä»¥åŠå¤šè¯­è¨€æ•™è‚²ç­‰ã€‚é€šè¿‡ä¼˜åŒ–æ¨ç†è¯­è¨€é€‰æ‹©ï¼Œèƒ½å¤Ÿæå‡æ¨¡å‹åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸‹çš„è¡¨ç°ï¼Œå¢å¼ºå…¶é€‚åº”æ€§å’Œå¯è§£é‡Šæ€§ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å®é™…åº”ç”¨å’Œå‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Reasoning language models (RLMs) excel at complex tasks by leveraging a chain-of-thought process to generate structured intermediate steps. However, language mixing, i.e., reasoning steps containing tokens from languages other than the prompt, has been observed in their outputs and shown to affect performance, though its impact remains debated. We present the first systematic study of language mixing in RLMs, examining its patterns, impact, and internal causes across 15 languages, 7 task difficulty levels, and 18 subject areas, and show how all three factors influence language mixing. Moreover, we demonstrate that the choice of reasoning language significantly affects performance: forcing models to reason in Latin or Han scripts via constrained decoding notably improves accuracy. Finally, we show that the script composition of reasoning traces closely aligns with that of the model's internal representations, indicating that language mixing reflects latent processing preferences in RLMs. Our findings provide actionable insights for optimizing multilingual reasoning and open new directions for controlling reasoning languages to build more interpretable and adaptable RLMs.

