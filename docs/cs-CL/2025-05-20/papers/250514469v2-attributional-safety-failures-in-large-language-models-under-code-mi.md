---
layout: default
title: Attributional Safety Failures in Large Language Models under Code-Mixed Perturbations
---

# Attributional Safety Failures in Large Language Models under Code-Mixed Perturbations

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14469" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14469v2</a>
  <a href="https://arxiv.org/pdf/2505.14469.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14469v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14469v2', 'Attributional Safety Failures in Large Language Models under Code-Mixed Perturbations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Somnath Banerjee, Pratyush Chatterjee, Shanu Kumar, Sayan Layek, Parag Agrawal, Rima Hazra, Animesh Mukherjee

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20 (æ›´æ–°: 2025-11-30)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSDAæ¡†æ¶ä»¥è§£å†³ä»£ç æ··åˆä¸‹LLMçš„å®‰å…¨æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å®‰å…¨æ€§` `ä»£ç æ··åˆ` `æ˜¾è‘—æ€§æ¼‚ç§»å½’å› ` `å¤šè¯­è¨€å¤„ç†` `å†…å®¹å®¡æ ¸` `ç¤¾äº¤åª’ä½“` `äººå·¥æ™ºèƒ½å®‰å…¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸‹çš„å®‰å…¨æ€§è¡¨ç°ä¸ä½³ï¼Œå°¤å…¶åœ¨ä»£ç æ··åˆæƒ…å†µä¸‹ï¼Œå®‰å…¨é˜²æŠ¤æœºåˆ¶å¤±æ•ˆã€‚
2. è®ºæ–‡æå‡ºäº†æ˜¾è‘—æ€§æ¼‚ç§»å½’å› ï¼ˆSDAï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨æ­ç¤ºæ¨¡å‹åœ¨ä»£ç æ··åˆè¾“å…¥ä¸‹çš„æ³¨æ„åŠ›åˆ†å¸ƒå˜åŒ–ï¼Œä»è€Œæ”¹å–„å®‰å…¨æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨ç¿»è¯‘æ¢å¤ç­–ç•¥åï¼Œæ¨¡å‹çš„å®‰å…¨æ€§æ¢å¤ç‡å¯è¾¾80%ï¼Œæ˜¾è‘—æé«˜äº†åœ¨ä»£ç æ··åˆç¯å¢ƒä¸‹çš„å®‰å…¨æ€§è¡¨ç°ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è‹±è¯­ä¸­è¡¨ç°å‡ºè¾ƒå¼ºçš„å®‰å…¨æ€§ï¼Œä½†æˆ‘ä»¬å‘ç°å…¶åœ¨ä»£ç æ··åˆæ‰°åŠ¨ä¸‹å­˜åœ¨ä¸¥é‡çš„å®‰å…¨æ¼æ´ã€‚ç³»ç»Ÿè¯„ä¼°æ˜¾ç¤ºï¼Œä»£ç æ··åˆä¼šå¯¼è‡´å®‰å…¨é˜²æŠ¤å¤±æ•ˆï¼Œæ”»å‡»æˆåŠŸç‡ä»å•ä¸€è‹±è¯­çš„9%æ¿€å¢è‡³69%ï¼Œåœ¨é˜¿æ‹‰ä¼¯è¯­å’Œå°åœ°è¯­ç­‰éè¥¿æ–¹è¯­å¢ƒä¸­ç”šè‡³è¶…è¿‡90%ã€‚ä¸ºäº†è§£é‡Šè¿™ä¸€ç°è±¡ï¼Œæˆ‘ä»¬å¼•å…¥äº†æ˜¾è‘—æ€§æ¼‚ç§»å½’å› ï¼ˆSDAï¼‰æ¡†æ¶ï¼Œæ­ç¤ºäº†æ¨¡å‹åœ¨ä»£ç æ··åˆæƒ…å†µä¸‹å¯¹å®‰å…¨å…³é”®æ ‡è®°çš„æ³¨æ„åŠ›æ¼‚ç§»ã€‚æœ€åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è½»é‡çº§çš„åŸºäºç¿»è¯‘çš„æ¢å¤ç­–ç•¥ï¼Œèƒ½å¤Ÿæ¢å¤çº¦80%çš„å®‰å…¨æ€§æŸå¤±ï¼Œä¸ºæå‡LLMçš„å®‰å…¨æ€§æä¾›äº†åˆ‡å®å¯è¡Œçš„è·¯å¾„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä»£ç æ··åˆè¾“å…¥ä¸‹çš„å®‰å…¨æ€§å¤±æ•ˆé—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸­æœªèƒ½æœ‰æ•ˆåº”å¯¹ä»£ç æ··åˆå¸¦æ¥çš„æŒ‘æˆ˜ï¼Œå¯¼è‡´å®‰å…¨é˜²æŠ¤æœºåˆ¶å¤±æ•ˆã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºæ˜¾è‘—æ€§æ¼‚ç§»å½’å› ï¼ˆSDAï¼‰æ¡†æ¶ï¼Œé€šè¿‡åˆ†ææ¨¡å‹åœ¨ä»£ç æ··åˆæƒ…å†µä¸‹çš„æ³¨æ„åŠ›åˆ†å¸ƒï¼Œæ­ç¤ºå…¶å¯¹å®‰å…¨å…³é”®æ ‡è®°çš„å¿½è§†ï¼Œä»è€Œä¸ºæ¢å¤å®‰å…¨æ€§æä¾›ä¾æ®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œæ¢å¤ç­–ç•¥ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡ä»£ç æ··åˆç”Ÿæˆè®­ç»ƒæ•°æ®ï¼›å…¶æ¬¡ï¼Œåˆ©ç”¨SDAæ¡†æ¶åˆ†ææ¨¡å‹çš„æ³¨æ„åŠ›åˆ†å¸ƒï¼›æœ€åï¼Œå®æ–½ç¿»è¯‘æ¢å¤ç­–ç•¥ä»¥æå‡å®‰å…¨æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥äº†SDAæ¡†æ¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«æ¨¡å‹åœ¨ä»£ç æ··åˆæƒ…å†µä¸‹çš„æ³¨æ„åŠ›æ¼‚ç§»ï¼Œæä¾›äº†æ–°çš„è§†è§’æ¥ç†è§£æ¨¡å‹çš„å®‰å…¨æ€§é—®é¢˜ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒSDAæ¡†æ¶æ›´å…·è§£é‡Šæ€§å’Œé’ˆå¯¹æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¼ºåŒ–å¯¹å®‰å…¨å…³é”®æ ‡è®°çš„å…³æ³¨ï¼ŒåŒæ—¶åœ¨ç¿»è¯‘æ¢å¤ç­–ç•¥ä¸­ï¼Œåˆ©ç”¨è½»é‡çº§çš„ç¿»è¯‘æ¨¡å‹è¿›è¡Œå®æ—¶æ¢å¤ï¼Œç¡®ä¿é«˜æ•ˆæ€§ä¸å‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ä»£ç æ··åˆè¾“å…¥ä¸‹ï¼Œæ”»å‡»æˆåŠŸç‡ä»9%æ¿€å¢è‡³69%ï¼Œåœ¨é˜¿æ‹‰ä¼¯è¯­å’Œå°åœ°è¯­ç­‰éè¥¿æ–¹è¯­å¢ƒä¸­ç”šè‡³è¶…è¿‡90%ã€‚é‡‡ç”¨ç¿»è¯‘æ¢å¤ç­–ç•¥åï¼Œæ¨¡å‹çš„å®‰å…¨æ€§æ¢å¤ç‡å¯è¾¾80%ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸‹çš„å®‰å…¨æ€§è¡¨ç°ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾äº¤åª’ä½“å†…å®¹å®¡æ ¸ã€åœ¨çº¿èŠå¤©æœºå™¨äººå’Œå¤šè¯­è¨€å®¢æˆ·æœåŠ¡ç­‰ã€‚é€šè¿‡æå‡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸‹çš„å®‰å…¨æ€§ï¼Œèƒ½å¤Ÿæœ‰æ•ˆä¿æŠ¤ç”¨æˆ·å…å—æœ‰å®³å†…å®¹çš„å½±å“ï¼Œå…·æœ‰é‡è¦çš„ç¤¾ä¼šä»·å€¼å’Œå®é™…æ„ä¹‰ã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶å¯èƒ½æ¨åŠ¨æ›´å¹¿æ³›çš„å®‰å…¨æ€§æ ‡å‡†åœ¨å¤šè¯­è¨€AIç³»ç»Ÿä¸­çš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While LLMs appear robustly safety-aligned in English, we uncover a catastrophic, overlooked weakness: attributional collapse under code-mixed perturbations. Our systematic evaluation of open models shows that the linguistic camouflage of code-mixing -- ``blending languages within a single conversation'' -- can cause safety guardrails to fail dramatically. Attack success rates (ASR) spike from a benign 9\% in monolingual English to 69\% under code-mixed inputs, with rates exceeding 90\% in non-Western contexts such as Arabic and Hindi. These effects hold not only on controlled synthetic datasets but also on real-world social media traces, revealing a serious risk for billions of users. To explain why this happens, we introduce saliency drift attribution (SDA), an interpretability framework that shows how, under code-mixing, the model's internal attention drifts away from safety-critical tokens (e.g., ``violence'' or ``corruption''), effectively blinding it to harmful intent. Finally, we propose a lightweight translation-based restoration strategy that recovers roughly 80\% of the safety lost to code-mixing, offering a practical path toward more equitable and robust LLM safety.

