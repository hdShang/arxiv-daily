---
layout: default
title: "MUG-Eval: A Proxy Evaluation Framework for Multilingual Generation Capabilities in Any Language"
---

# MUG-Eval: A Proxy Evaluation Framework for Multilingual Generation Capabilities in Any Language

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14395" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14395v2</a>
  <a href="https://arxiv.org/pdf/2505.14395.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14395v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14395v2', 'MUG-Eval: A Proxy Evaluation Framework for Multilingual Generation Capabilities in Any Language')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Seyoung Song, Seogyeong Jeong, Eunsu Kim, Jiho Jin, Dongkwan Kim, Jay Shin, Alice Oh

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20 (æ›´æ–°: 2025-09-19)

**å¤‡æ³¨**: To appear in Findings of EMNLP 2025

**DOI**: [10.18653/v1/2025.findings-emnlp.1061](https://doi.org/10.18653/v1/2025.findings-emnlp.1061)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMUG-Evalæ¡†æ¶ä»¥è¯„ä¼°å¤šè¯­è¨€ç”Ÿæˆèƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šè¯­è¨€ç”Ÿæˆ` `è¯„ä¼°æ¡†æ¶` `å¤§å‹è¯­è¨€æ¨¡å‹` `ä½èµ„æºè¯­è¨€` `å¯¹è¯ä»»åŠ¡` `ä»»åŠ¡æˆåŠŸç‡` `è‡ªç„¶è¯­è¨€å¤„ç†` `æ ‡å‡†åŒ–æ¯”è¾ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è¯„ä¼°æ–¹æ³•åœ¨ä½èµ„æºè¯­è¨€ä¸­çš„åº”ç”¨æœ‰é™ï¼Œå¯¼è‡´å¯¹å¤šè¯­è¨€ç”Ÿæˆèƒ½åŠ›çš„è¯„ä¼°é¢ä¸´æŒ‘æˆ˜ã€‚
2. MUG-Evalæ¡†æ¶é€šè¿‡å°†åŸºå‡†è½¬åŒ–ä¸ºå¯¹è¯ä»»åŠ¡ï¼Œä½¿ç”¨ä»»åŠ¡æˆåŠŸç‡ä½œä¸ºè¯„ä¼°æŒ‡æ ‡ï¼Œé¿å…äº†å¯¹ç‰¹å®šå·¥å…·å’Œæ•°æ®é›†çš„ä¾èµ–ã€‚
3. åœ¨30ç§è¯­è¨€ä¸Šè¯„ä¼°8ä¸ªLLMsï¼ŒMUG-Evalä¸ä¼ ç»ŸåŸºå‡†çš„ç›¸å…³æ€§è¶…è¿‡0.75ï¼Œæä¾›äº†æ ‡å‡†åŒ–æ¯”è¾ƒçš„å¯èƒ½æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ–‡æœ¬ç”Ÿæˆèƒ½åŠ›å°¤å…¶åœ¨ä½èµ„æºè¯­è¨€ä¸­é¢ä¸´æŒ‘æˆ˜ï¼Œç°æœ‰çš„ç›´æ¥è¯„ä¼°æ–¹æ³•ç¨€ç¼ºã€‚æœ¬æ–‡æå‡ºäº†MUG-Evalï¼Œä¸€ä¸ªæ–°é¢–çš„æ¡†æ¶ï¼Œé€šè¿‡å°†ç°æœ‰åŸºå‡†è½¬åŒ–ä¸ºå¯¹è¯ä»»åŠ¡æ¥è¯„ä¼°LLMsçš„å¤šè¯­è¨€ç”Ÿæˆèƒ½åŠ›ï¼Œå¹¶æµ‹é‡å…¶åœ¨è¿™äº›ä»»åŠ¡ä¸Šçš„å‡†ç¡®æ€§ã€‚æˆ‘ä»¬è®¾è®¡çš„å¯¹è¯ä»»åŠ¡è¦æ±‚åœ¨ç›®æ ‡è¯­è¨€ä¸­æœ‰æ•ˆæ²Ÿé€šï¼Œå¹¶ä½¿ç”¨ä»»åŠ¡æˆåŠŸç‡ä½œä¸ºæˆåŠŸå¯¹è¯ç”Ÿæˆçš„ä»£ç†æŒ‡æ ‡ã€‚è¯¥æ–¹æ³•å…·æœ‰ä¸¤ä¸ªä¸»è¦ä¼˜ç‚¹ï¼šä¸ä¾èµ–äºç‰¹å®šè¯­è¨€çš„NLPå·¥å…·æˆ–æ³¨é‡Šæ•°æ®é›†ï¼Œä¸”ä¸ä¾èµ–äºLLMsä½œä¸ºè¯„åˆ¤è€…ã€‚æˆ‘ä»¬åœ¨30ç§è¯­è¨€ä¸Šè¯„ä¼°äº†8ä¸ªLLMsï¼Œå‘ç°MUG-Evalä¸å·²å»ºç«‹çš„åŸºå‡†é«˜åº¦ç›¸å…³ï¼ˆ$r$ > 0.75ï¼‰ï¼Œå¹¶èƒ½å¤Ÿå®ç°è·¨è¯­è¨€å’Œæ¨¡å‹çš„æ ‡å‡†åŒ–æ¯”è¾ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šè¯­è¨€ç”Ÿæˆèƒ½åŠ›è¯„ä¼°ä¸­çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨ä½èµ„æºè¯­è¨€ä¸­ç¼ºä¹æœ‰æ•ˆçš„è¯„ä¼°æ–¹æ³•ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–äºç‰¹å®šçš„NLPå·¥å…·æˆ–é«˜èµ„æºè¯­è¨€çš„è¯„ä¼°æ ‡å‡†ï¼Œé™åˆ¶äº†å…¶é€‚ç”¨æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMUG-Evalæ¡†æ¶é€šè¿‡å°†ç°æœ‰çš„è¯„ä¼°åŸºå‡†è½¬åŒ–ä¸ºå¯¹è¯ä»»åŠ¡ï¼Œè®¾è®¡å‡ºéœ€è¦åœ¨ç›®æ ‡è¯­è¨€ä¸­è¿›è¡Œæœ‰æ•ˆæ²Ÿé€šçš„ä»»åŠ¡ï¼Œä»è€Œä½¿ç”¨ä»»åŠ¡æˆåŠŸç‡ä½œä¸ºç”Ÿæˆèƒ½åŠ›çš„ä»£ç†æŒ‡æ ‡ã€‚è¿™ç§è®¾è®¡ä½¿å¾—è¯„ä¼°ä¸å†ä¾èµ–äºç‰¹å®šè¯­è¨€çš„å·¥å…·å’Œæ•°æ®é›†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMUG-Evalçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä»»åŠ¡è®¾è®¡ã€æ‰§è¡Œå’Œè¯„ä¼°ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œè®¾è®¡å¯¹è¯ä»»åŠ¡ä»¥é€‚åº”ä¸åŒè¯­è¨€çš„ç‰¹ç‚¹ï¼›å…¶æ¬¡ï¼Œæ‰§è¡Œè¿™äº›ä»»åŠ¡å¹¶æ”¶é›†ç”Ÿæˆç»“æœï¼›æœ€åï¼Œé€šè¿‡è®¡ç®—ä»»åŠ¡æˆåŠŸç‡æ¥è¯„ä¼°ç”Ÿæˆèƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šMUG-Evalçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶ä¸ä¾èµ–äºè¯­è¨€ç‰¹å®šçš„å·¥å…·å’Œæ³¨é‡Šæ•°æ®é›†ï¼Œä¸”ä¸éœ€è¦LLMsä½œä¸ºè¯„åˆ¤è€…ï¼Œä»è€Œå…‹æœäº†ç°æœ‰æ–¹æ³•çš„å±€é™æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡è¿‡ç¨‹ä¸­ï¼Œä»»åŠ¡æˆåŠŸç‡è¢«é€‰ä¸ºè¯„ä¼°æŒ‡æ ‡ï¼Œç¡®ä¿äº†è¯„ä¼°çš„ç®€æ´æ€§å’Œæœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œæ¡†æ¶çš„çµæ´»æ€§ä½¿å…¶èƒ½å¤Ÿæ‰©å±•åˆ°æ•°åƒç§è¯­è¨€ï¼Œå…·æœ‰å¹¿æ³›çš„é€‚ç”¨æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å¯¹8ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹çš„è¯„ä¼°ä¸­ï¼ŒMUG-Evalåœ¨30ç§è¯­è¨€ä¸Šè¡¨ç°å‡ºä¸ä¼ ç»ŸåŸºå‡†çš„é«˜åº¦ç›¸å…³æ€§ï¼ˆ$r$ > 0.75ï¼‰ï¼Œæ˜¾ç¤ºå‡ºå…¶ä½œä¸ºå¤šè¯­è¨€ç”Ÿæˆèƒ½åŠ›è¯„ä¼°å·¥å…·çš„æœ‰æ•ˆæ€§å’Œå¯é æ€§ã€‚è¿™ä¸€ç»“æœè¡¨æ˜ï¼ŒMUG-Evalèƒ½å¤Ÿå®ç°è·¨è¯­è¨€å’Œæ¨¡å‹çš„æ ‡å‡†åŒ–æ¯”è¾ƒï¼Œå…·æœ‰é‡è¦çš„ç ”ç©¶ä»·å€¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MUG-Evalæ¡†æ¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨å¤šè¯­è¨€ç”Ÿæˆä»»åŠ¡çš„è¯„ä¼°ä¸­ã€‚å®ƒå¯ä»¥è¢«ç”¨äºä½èµ„æºè¯­è¨€çš„ç ”ç©¶ï¼Œå¸®åŠ©å¼€å‘æ›´å…·åŒ…å®¹æ€§çš„è¯­è¨€æ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶çš„æ ‡å‡†åŒ–è¯„ä¼°æ–¹æ³•ä¹Ÿå¯ä»¥ä¿ƒè¿›è·¨è¯­è¨€æ¨¡å‹çš„æ¯”è¾ƒå’Œä¼˜åŒ–ï¼Œæ¨åŠ¨å¤šè¯­è¨€å¤„ç†æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Evaluating text generation capabilities of large language models (LLMs) is challenging, particularly for low-resource languages where methods for direct assessment are scarce. We propose MUG-Eval, a novel framework that evaluates LLMs' multilingual generation capabilities by transforming existing benchmarks into conversational tasks and measuring the LLMs' accuracies on those tasks. We specifically designed these conversational tasks to require effective communication in the target language. Then, we simply use task success rate as a proxy for successful conversation generation. Our approach offers two key advantages: it is independent of language-specific NLP tools or annotated datasets, which are limited for most languages, and it does not rely on LLMs-as-judges, whose evaluation quality degrades outside a few high-resource languages. We evaluate 8 LLMs across 30 languages spanning high, mid, and low-resource categories, and we find that MUG-Eval correlates strongly with established benchmarks ($r$ > 0.75) while enabling standardized comparisons across languages and models. Our framework provides a robust and resource-efficient solution for evaluating multilingual generation that can be extended to thousands of languages.

