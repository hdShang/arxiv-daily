---
layout: default
title: "SEPS: A Separability Measure for Robust Unlearning in LLMs"
---

# SEPS: A Separability Measure for Robust Unlearning in LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14832" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14832v2</a>
  <a href="https://arxiv.org/pdf/2505.14832.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14832v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14832v2', 'SEPS: A Separability Measure for Robust Unlearning in LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wonje Jeung, Sangyeon Yoon, Albert No

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20 (æ›´æ–°: 2025-05-27)

**å¤‡æ³¨**: 32 pages

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSEPSæ¡†æ¶ä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹çš„æ··åˆæŸ¥è¯¢é—å¿˜é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `æœºå™¨é—å¿˜` `æ··åˆæŸ¥è¯¢` `è¯„ä¼°æ¡†æ¶` `æ•°æ®éšç§` `æ¨¡å‹æ›´æ–°` `ä¸ªæ€§åŒ–æ¨è`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„é—å¿˜æ–¹æ³•åœ¨å¤„ç†æ··åˆæŸ¥è¯¢æ—¶è¡¨ç°ä¸ä½³ï¼Œæ— æ³•æœ‰æ•ˆåŒºåˆ†é—å¿˜å’Œä¿ç•™å†…å®¹ã€‚
2. æœ¬æ–‡æå‡ºSEPSæ¡†æ¶ï¼Œé€šè¿‡æ··åˆæç¤ºç­–ç•¥å°†é—å¿˜å’Œä¿ç•™æŸ¥è¯¢æ•´åˆä¸ºç»Ÿä¸€çš„è®­ç»ƒç›®æ ‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ–°çš„æ–¹æ³•åœ¨å¤æ‚åœºæ™¯ä¸‹çš„é—å¿˜æ•ˆæœæ˜¾è‘—æå‡ï¼Œèƒ½å¤Ÿå¤„ç†å¤šè¾¾å…«ä¸ªæ··åˆæŸ¥è¯¢ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœºå™¨é—å¿˜æ—¨åœ¨ä»å¤§è¯­è¨€æ¨¡å‹ä¸­é€‰æ‹©æ€§åœ°ç§»é™¤ç‰¹å®šçŸ¥è¯†ï¼Œç¡®ä¿æ¨¡å‹å¿˜è®°æŒ‡å®šå†…å®¹çš„åŒæ—¶ä¿ç•™é‡è¦ä¿¡æ¯ã€‚ç°æœ‰çš„é—å¿˜è¯„ä¼°æŒ‡æ ‡ä¸»è¦å…³æ³¨æ¨¡å‹æ˜¯å¦æ­£ç¡®å›ç­”ä¿ç•™æŸ¥è¯¢å’Œæ‹’ç»é—å¿˜æŸ¥è¯¢ï¼Œä½†æœªèƒ½è€ƒè™‘åˆ°ç°å®åœºæ™¯ä¸­é—å¿˜æŸ¥è¯¢é€šå¸¸ä¸ä¿ç•™æŸ¥è¯¢å…±å­˜çš„æƒ…å†µã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†SEPSè¯„ä¼°æ¡†æ¶ï¼Œæ˜ç¡®æµ‹é‡æ¨¡å‹åœ¨å•ä¸ªæç¤ºä¸­é—å¿˜å’Œä¿ç•™ä¿¡æ¯çš„èƒ½åŠ›ã€‚é€šè¿‡åœ¨ä¸‰ä¸ªåŸºå‡†ä¸Šçš„å¹¿æ³›å®éªŒï¼Œæˆ‘ä»¬è¯†åˆ«å‡ºç°æœ‰é—å¿˜æ–¹æ³•çš„ä¸¤ä¸ªä¸»è¦å¤±è´¥æ¨¡å¼ï¼Œå¹¶æå‡ºäº†æ··åˆæç¤ºï¼ˆMPï¼‰é—å¿˜ç­–ç•¥ï¼Œæ˜¾è‘—æé«˜äº†é—å¿˜æ•ˆæœï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚åœºæ™¯ä¸­è¡¨ç°å‡ºè‰²ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è§£å†³çš„æ˜¯å¤§è¯­è¨€æ¨¡å‹åœ¨å¤„ç†æ··åˆæŸ¥è¯¢æ—¶çš„é—å¿˜é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨é¢å¯¹åŒæ—¶å‡ºç°çš„é—å¿˜å’Œä¿ç•™æŸ¥è¯¢æ—¶ï¼Œå¾€å¾€æ— æ³•æœ‰æ•ˆåŒºåˆ†ï¼Œå¯¼è‡´ä¿¡æ¯é—å¿˜ä¸å½“ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æå‡ºSEPSè¯„ä¼°æ¡†æ¶ï¼Œå¹¶å¼•å…¥æ··åˆæç¤ºï¼ˆMPï¼‰é—å¿˜ç­–ç•¥ï¼Œå°†é—å¿˜å’Œä¿ç•™æŸ¥è¯¢æ•´åˆä¸ºä¸€ä¸ªç»Ÿä¸€çš„è®­ç»ƒç›®æ ‡ï¼Œä»¥æé«˜æ¨¡å‹çš„é—å¿˜æ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šä¸€æ˜¯SEPSè¯„ä¼°æ¡†æ¶ï¼Œç”¨äºæµ‹é‡æ¨¡å‹åœ¨æ··åˆæŸ¥è¯¢ä¸‹çš„è¡¨ç°ï¼›äºŒæ˜¯MPé—å¿˜ç­–ç•¥ï¼Œé€šè¿‡è”åˆè®­ç»ƒæ¥ä¼˜åŒ–æ¨¡å‹çš„é—å¿˜å’Œä¿ç•™èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†æ··åˆæç¤ºé—å¿˜ç­–ç•¥ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•åœ¨å¤šæŸ¥è¯¢åœºæ™¯ä¸‹çš„å¤±æ•ˆé—®é¢˜ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨å¤æ‚æƒ…å†µä¸‹ä¿æŒæ›´é«˜çš„é—å¿˜å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å…³é”®è®¾è®¡ä¸Šï¼Œæœ¬æ–‡é‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡é—å¿˜å’Œä¿ç•™çš„ç›®æ ‡ï¼Œå¹¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†è°ƒæ•´ï¼Œä»¥é€‚åº”æ··åˆæŸ¥è¯¢çš„å¤„ç†éœ€æ±‚ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œè®­ç»ƒæµç¨‹åœ¨å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œé‡‡ç”¨æ··åˆæç¤ºé—å¿˜ç­–ç•¥çš„æ¨¡å‹åœ¨å¤„ç†å¤æ‚æŸ¥è¯¢æ—¶ï¼Œé—å¿˜æ•ˆæœæå‡äº†æ˜¾è‘—ï¼Œå°¤å…¶åœ¨å¤šè¾¾å…«ä¸ªæ··åˆæŸ¥è¯¢çš„åœºæ™¯ä¸­ï¼Œæ¨¡å‹çš„è¡¨ç°ä¼˜äºç°æœ‰åŸºçº¿ï¼Œå±•ç¤ºäº†æ›´å¼ºçš„é²æ£’æ€§å’Œé€‚åº”æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•°æ®éšç§ä¿æŠ¤ã€æ¨¡å‹æ›´æ–°å’Œä¸ªæ€§åŒ–æ¨èç­‰ã€‚é€šè¿‡æœ‰æ•ˆçš„é—å¿˜æœºåˆ¶ï¼Œæ¨¡å‹èƒ½å¤Ÿåœ¨ä¸æŸå¤±é‡è¦ä¿¡æ¯çš„æƒ…å†µä¸‹ï¼Œå¿«é€Ÿé€‚åº”æ–°çš„æ•°æ®éœ€æ±‚ï¼Œæå‡ç”¨æˆ·ä½“éªŒå’Œå®‰å…¨æ€§ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½åœ¨æ³•å¾‹åˆè§„å’Œé“å¾·AIç­‰é¢†åŸŸäº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Machine unlearning aims to selectively remove targeted knowledge from Large Language Models (LLMs), ensuring they forget specified content while retaining essential information. Existing unlearning metrics assess whether a model correctly answers retain queries and rejects forget queries, but they fail to capture real-world scenarios where forget queries rarely appear in isolation. In fact, forget and retain queries often coexist within the same prompt, making mixed-query evaluation crucial.
>   We introduce SEPS, an evaluation framework that explicitly measures a model's ability to both forget and retain information within a single prompt. Through extensive experiments across three benchmarks, we identify two key failure modes in existing unlearning methods: (1) untargeted unlearning indiscriminately erases both forget and retain content once a forget query appears, and (2) targeted unlearning overfits to single-query scenarios, leading to catastrophic failures when handling multiple queries. To address these issues, we propose Mixed Prompt (MP) unlearning, a strategy that integrates both forget and retain queries into a unified training objective. Our approach significantly improves unlearning effectiveness, demonstrating robustness even in complex settings with up to eight mixed forget and retain queries in a single prompt.

