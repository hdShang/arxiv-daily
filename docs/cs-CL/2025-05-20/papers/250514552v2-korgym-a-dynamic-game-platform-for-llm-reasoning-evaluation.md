---
layout: default
title: "KORGym: A Dynamic Game Platform for LLM Reasoning Evaluation"
---

# KORGym: A Dynamic Game Platform for LLM Reasoning Evaluation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14552" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14552v2</a>
  <a href="https://arxiv.org/pdf/2505.14552.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14552v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14552v2', 'KORGym: A Dynamic Game Platform for LLM Reasoning Evaluation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiajun Shi, Jian Yang, Jiaheng Liu, Xingyuan Bu, Jiangjie Chen, Junting Zhou, Kaijing Ma, Zhoufutu Wen, Bingli Wang, Yancheng He, Liang Song, Hualei Zhu, Shilong Li, Xingjian Wang, Wei Zhang, Ruibin Yuan, Yifan Yao, Wenjun Yang, Yunli Wang, Siyuan Fang, Siyu Yuan, Qianyu He, Xiangru Tang, Yingshui Tan, Wangchunshu Zhou, Zhaoxiang Zhang, Zhoujun Li, Wenhao Huang, Ge Zhang

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20 (æ›´æ–°: 2025-05-21)

**å¤‡æ³¨**: 22 pages

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºKORGymä»¥è§£å†³LLMæ¨ç†è¯„ä¼°çš„ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ¨ç†è¯„ä¼°` `åŠ¨æ€è¯„ä¼°å¹³å°` `å¼ºåŒ–å­¦ä¹ ` `å¤šæ¨¡æ€è¯„ä¼°` `çŸ¥è¯†æ­£äº¤æ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¯„ä¼°åŸºå‡†å¾€å¾€å±€é™äºç‰¹å®šé¢†åŸŸï¼Œæ— æ³•å…¨é¢åæ˜ å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚
2. KORGymæ˜¯ä¸€ä¸ªåŠ¨æ€è¯„ä¼°å¹³å°ï¼Œæä¾›å¤šç§æ¸¸æˆå½¢å¼ï¼Œæ”¯æŒäº¤äº’å¼è¯„ä¼°ï¼Œæ—¨åœ¨å…¨é¢è¯„ä¼°LLMçš„æ¨ç†èƒ½åŠ›ã€‚
3. é€šè¿‡å¯¹19ä¸ªLLMå’Œ8ä¸ªVLMçš„å®éªŒï¼Œå‘ç°æ¨¡å‹å®¶æ—å†…å­˜åœ¨ä¸€è‡´çš„æ¨ç†æ¨¡å¼ï¼Œé—­æºæ¨¡å‹è¡¨ç°ä¼˜è¶Šã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è¿›å±•å‡¸æ˜¾äº†å¯¹æ›´å…¨é¢è¯„ä¼°æ–¹æ³•çš„éœ€æ±‚ï¼Œä»¥å‡†ç¡®è¯„ä¼°å…¶æ¨ç†èƒ½åŠ›ã€‚ç°æœ‰åŸºå‡†å¾€å¾€æ˜¯ç‰¹å®šé¢†åŸŸçš„ï¼Œæ— æ³•å…¨é¢æ•æ‰LLMçš„é€šç”¨æ¨ç†æ½œåŠ›ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†çŸ¥è¯†æ­£äº¤æ¨ç†è®­ç»ƒåœºï¼ˆKORGymï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªåŠ¨æ€è¯„ä¼°å¹³å°ï¼Œçµæ„Ÿæ¥è‡ªKOR-Benchå’ŒGymnasiumã€‚KORGymæä¾›è¶…è¿‡äº”åç§æ–‡æœ¬æˆ–è§†è§‰æ ¼å¼çš„æ¸¸æˆï¼Œå¹¶æ”¯æŒäº¤äº’å¼ã€å¤šè½®è¯„ä¼°ä¸å¼ºåŒ–å­¦ä¹ åœºæ™¯ã€‚é€šè¿‡KORGymï¼Œæˆ‘ä»¬å¯¹19ä¸ªLLMå’Œ8ä¸ªVLMè¿›è¡Œäº†å¹¿æ³›å®éªŒï¼Œæ­ç¤ºäº†æ¨¡å‹å®¶æ—å†…çš„ä¸€è‡´æ¨ç†æ¨¡å¼ï¼Œå¹¶å±•ç¤ºäº†é—­æºæ¨¡å‹çš„ä¼˜è¶Šæ€§èƒ½ã€‚è¿›ä¸€æ­¥åˆ†æè€ƒå¯Ÿäº†æ¨¡æ€ã€æ¨ç†ç­–ç•¥ã€å¼ºåŒ–å­¦ä¹ æŠ€æœ¯å’Œå“åº”é•¿åº¦å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚æˆ‘ä»¬æœŸæœ›KORGymæˆä¸ºæ¨è¿›LLMæ¨ç†ç ”ç©¶å’Œå¼€å‘é€‚åˆå¤æ‚äº¤äº’ç¯å¢ƒçš„è¯„ä¼°æ–¹æ³•çš„é‡è¦èµ„æºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰è¯„ä¼°æ–¹æ³•æ— æ³•å…¨é¢æ•æ‰å¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›çš„é—®é¢˜ï¼Œç°æœ‰åŸºå‡†å¤šä¸ºé¢†åŸŸç‰¹å®šï¼Œç¼ºä¹é€šç”¨æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºKORGymä½œä¸ºåŠ¨æ€è¯„ä¼°å¹³å°ï¼Œé€šè¿‡æä¾›å¤šç§æ¸¸æˆå½¢å¼å’Œäº¤äº’å¼è¯„ä¼°ï¼Œæ—¨åœ¨å…¨é¢è€ƒå¯ŸLLMçš„æ¨ç†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šKORGymçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ¸¸æˆè®¾è®¡æ¨¡å—ã€è¯„ä¼°äº¤äº’æ¨¡å—å’Œæ•°æ®åˆ†ææ¨¡å—ï¼Œæ”¯æŒæ–‡æœ¬å’Œè§†è§‰æ ¼å¼çš„æ¸¸æˆï¼Œç»“åˆå¼ºåŒ–å­¦ä¹ åœºæ™¯è¿›è¡Œå¤šè½®è¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šKORGymçš„åˆ›æ–°åœ¨äºå…¶åŠ¨æ€æ€§å’Œå¤šæ ·æ€§ï¼Œèƒ½å¤Ÿåœ¨å¤æ‚çš„äº¤äº’ç¯å¢ƒä¸­è¿›è¡Œè¯„ä¼°ï¼ŒåŒºåˆ«äºä¼ ç»Ÿçš„é™æ€è¯„ä¼°åŸºå‡†ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒKORGymè®¾ç½®äº†å¤šç§æ¸¸æˆå‚æ•°ï¼Œé‡‡ç”¨äº†é€‚åº”æ€§æŸå¤±å‡½æ•°ï¼Œå¹¶ç»“åˆäº†å¼ºåŒ–å­¦ä¹ æŠ€æœ¯ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹çš„æ¨ç†è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒKORGymåœ¨è¯„ä¼°19ä¸ªLLMå’Œ8ä¸ªVLMæ—¶ï¼Œæ­ç¤ºäº†æ¨¡å‹å®¶æ—å†…çš„ä¸€è‡´æ¨ç†æ¨¡å¼ï¼Œä¸”é—­æºæ¨¡å‹çš„è¡¨ç°æ˜¾è‘—ä¼˜äºå¼€æºæ¨¡å‹ï¼Œè¿›ä¸€æ­¥éªŒè¯äº†è¯„ä¼°æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œåˆ›æ–°æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

KORGymçš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€äººå·¥æ™ºèƒ½æ•™è‚²å’Œæ™ºèƒ½æ¸¸æˆç­‰ã€‚å®ƒä¸ºç ”ç©¶äººå‘˜æä¾›äº†ä¸€ä¸ªå…¨é¢çš„è¯„ä¼°å·¥å…·ï¼Œèƒ½å¤Ÿåœ¨å¤æ‚çš„äº¤äº’ç¯å¢ƒä¸­æµ‹è¯•å’Œæå‡LLMçš„æ¨ç†èƒ½åŠ›ï¼Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advancements in large language models (LLMs) underscore the need for more comprehensive evaluation methods to accurately assess their reasoning capabilities. Existing benchmarks are often domain-specific and thus cannot fully capture an LLM's general reasoning potential. To address this limitation, we introduce the Knowledge Orthogonal Reasoning Gymnasium (KORGym), a dynamic evaluation platform inspired by KOR-Bench and Gymnasium. KORGym offers over fifty games in either textual or visual formats and supports interactive, multi-turn assessments with reinforcement learning scenarios. Using KORGym, we conduct extensive experiments on 19 LLMs and 8 VLMs, revealing consistent reasoning patterns within model families and demonstrating the superior performance of closed-source models. Further analysis examines the effects of modality, reasoning strategies, reinforcement learning techniques, and response length on model performance. We expect KORGym to become a valuable resource for advancing LLM reasoning research and developing evaluation methodologies suited to complex, interactive environments.

