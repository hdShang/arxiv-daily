---
layout: default
title: "Through a Compressed Lens: Investigating the Impact of Quantization on LLM Explainability and Interpretability"
---

# Through a Compressed Lens: Investigating the Impact of Quantization on LLM Explainability and Interpretability

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.13963" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.13963v1</a>
  <a href="https://arxiv.org/pdf/2505.13963.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.13963v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.13963v1', 'Through a Compressed Lens: Investigating the Impact of Quantization on LLM Explainability and Interpretability')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Qianli Wang, Mingyang Wang, Nils Feldhus, Simon Ostermann, Yuan Cao, Hinrich SchÃ¼tze, Sebastian MÃ¶ller, Vera Schmitt

**åˆ†ç±»**: cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20

**å¤‡æ³¨**: In submission

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç ”ç©¶é‡åŒ–å¯¹å¤§è¯­è¨€æ¨¡å‹å¯è§£é‡Šæ€§ä¸å¯ç†è§£æ€§çš„å½±å“**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é‡åŒ–æŠ€æœ¯` `å¤§è¯­è¨€æ¨¡å‹` `å¯è§£é‡Šæ€§` `å¯ç†è§£æ€§` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç ”ç©¶ä¸»è¦å…³æ³¨é‡åŒ–å¯¹LLMæ€§èƒ½çš„å½±å“ï¼Œä½†å¯¹å…¶å¯è§£é‡Šæ€§å’Œå¯ç†è§£æ€§çš„å½±å“å°šæœªæ¢è®¨ï¼Œå­˜åœ¨ç ”ç©¶ç©ºç™½ã€‚
2. æœ¬æ–‡é€šè¿‡å¯¹æ¯”ä¸‰ç§é‡åŒ–æŠ€æœ¯å’Œä¸¤ç§å¯è§£é‡Šæ€§ã€å¯ç†è§£æ€§æ–¹æ³•ï¼Œç³»ç»Ÿæ€§åœ°è¯„ä¼°é‡åŒ–å¯¹æ¨¡å‹é€æ˜åº¦çš„å½±å“ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œé‡åŒ–å¯¹å¯è§£é‡Šæ€§å’Œå¯ç†è§£æ€§çš„å½±å“ä¸ä¸€è‡´ï¼ŒæŸäº›æƒ…å†µä¸‹ç”šè‡³æå‡äº†æ¨¡å‹çš„é€æ˜åº¦ï¼Œæç¤ºéœ€è°¨æ…ä½¿ç”¨ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é‡åŒ–æ–¹æ³•å¹¿æ³›ç”¨äºåŠ é€Ÿæ¨ç†å’Œç®€åŒ–å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„éƒ¨ç½²ã€‚å°½ç®¡å…ˆå‰ç ”ç©¶å·²æ·±å…¥æ¢è®¨é‡åŒ–å¯¹LLMèƒ½åŠ›çš„å½±å“ï¼Œä½†å…¶å¯¹æ¨¡å‹å¯è§£é‡Šæ€§å’Œå¯ç†è§£æ€§çš„å½±å“å°šæœªè¢«å……åˆ†ç ”ç©¶ã€‚ä¸ºå¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæœ¬æ–‡é€šè¿‡ä¸‰ç§å¸¸è§çš„é‡åŒ–æŠ€æœ¯å’Œä¸¤ç§å¯è§£é‡Šæ€§æ–¹æ³•ï¼ˆåäº‹å®ç¤ºä¾‹å’Œè‡ªç„¶è¯­è¨€è§£é‡Šï¼‰ä»¥åŠä¸¤ç§å¯ç†è§£æ€§æ–¹æ³•ï¼ˆçŸ¥è¯†è®°å¿†åˆ†æå’Œæ½œåœ¨å¤šè·³æ¨ç†åˆ†æï¼‰è¿›è¡Œäº†å…¨é¢å®éªŒã€‚ç ”ç©¶å‘ç°ï¼Œé‡åŒ–å¯¹æ¨¡å‹çš„å¯è§£é‡Šæ€§å’Œå¯ç†è§£æ€§æœ‰æ˜¾è‘—å½±å“ï¼Œä¸”è¿™ç§å½±å“çš„æ–¹å‘ä¾èµ–äºé‡åŒ–æ–¹æ³•ã€å¯è§£é‡Šæ€§æˆ–å¯ç†è§£æ€§æ–¹æ³•åŠè¯„ä¼°åè®®ã€‚åœ¨æŸäº›è®¾ç½®ä¸­ï¼Œé‡åŒ–é™ä½äº†å¯è§£é‡Šæ€§ï¼Œè€Œåœ¨å…¶ä»–è®¾ç½®ä¸­åˆ™å¯èƒ½å¯¼è‡´æ”¹å–„ã€‚æ­¤ç ”ç©¶ä¸ºåœ¨éœ€è¦é€æ˜åº¦çš„åº”ç”¨ä¸­éƒ¨ç½²LLMsæä¾›äº†é‡è¦çš„å¯ç¤ºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨æ¢è®¨é‡åŒ–å¯¹å¤§è¯­è¨€æ¨¡å‹å¯è§£é‡Šæ€§å’Œå¯ç†è§£æ€§çš„å½±å“ï¼Œç°æœ‰ç ”ç©¶æœªèƒ½å……åˆ†è€ƒè™‘è¿™ä¸€é‡è¦æ–¹é¢ï¼Œå¯¼è‡´åœ¨å®é™…åº”ç”¨ä¸­å¯èƒ½å‡ºç°é€æ˜åº¦ä¸è¶³çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡ç³»ç»Ÿæ€§å®éªŒï¼Œç»“åˆä¸åŒçš„é‡åŒ–æŠ€æœ¯å’Œå¯è§£é‡Šæ€§æ–¹æ³•ï¼Œè¯„ä¼°é‡åŒ–å¯¹æ¨¡å‹é€æ˜åº¦çš„å½±å“ï¼Œæ—¨åœ¨æ­ç¤ºé‡åŒ–ä¸å¯è§£é‡Šæ€§ä¹‹é—´çš„å¤æ‚å…³ç³»ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨ä¸‰ç§é‡åŒ–æŠ€æœ¯ï¼ˆä¸åŒä½å®½ï¼‰ä¸ä¸¤ç§å¯è§£é‡Šæ€§æ–¹æ³•ï¼ˆåäº‹å®ç¤ºä¾‹ã€è‡ªç„¶è¯­è¨€è§£é‡Šï¼‰åŠä¸¤ç§å¯ç†è§£æ€§æ–¹æ³•ï¼ˆçŸ¥è¯†è®°å¿†åˆ†æã€æ½œåœ¨å¤šè·³æ¨ç†åˆ†æï¼‰è¿›è¡Œå®éªŒï¼Œæ„å»ºäº†ä¸€ä¸ªå¤šç»´åº¦çš„è¯„ä¼°æ¡†æ¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶é¦–æ¬¡ç³»ç»Ÿæ€§åœ°æ¢è®¨äº†é‡åŒ–å¯¹LLMå¯è§£é‡Šæ€§å’Œå¯ç†è§£æ€§çš„å½±å“ï¼Œæ­ç¤ºäº†é‡åŒ–æ–¹æ³•ä¸å¯è§£é‡Šæ€§æ–¹æ³•ä¹‹é—´çš„ç›¸äº’ä½œç”¨ï¼Œå¡«è¡¥äº†ç°æœ‰æ–‡çŒ®çš„ç©ºç™½ã€‚

**å…³é”®è®¾è®¡**ï¼šå®éªŒä¸­é‡‡ç”¨äº†ä¸åŒçš„é‡åŒ–ä½å®½å’Œè¯„ä¼°åè®®ï¼Œç»“åˆç”¨æˆ·ç ”ç©¶è¯„ä¼°å¯è§£é‡Šæ€§æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œç¡®ä¿äº†ç»“æœçš„å¯é æ€§å’Œå®ç”¨æ€§ã€‚å®éªŒè®¾è®¡è€ƒè™‘äº†å¤šç§å˜é‡ï¼Œä»¥å…¨é¢åæ˜ é‡åŒ–å¯¹æ¨¡å‹é€æ˜åº¦çš„å½±å“ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œé‡åŒ–å¯¹æ¨¡å‹å¯è§£é‡Šæ€§çš„å½±å“å…·æœ‰ä¸ç¡®å®šæ€§ã€‚åœ¨æŸäº›é…ç½®ä¸‹ï¼Œé‡åŒ–å¯¼è‡´å¯è§£é‡Šæ€§ä¸‹é™ï¼Œè€Œåœ¨å…¶ä»–é…ç½®ä¸‹åˆ™å¯èƒ½æå‡å¯è§£é‡Šæ€§ï¼Œæç¤ºç ”ç©¶è€…åœ¨éƒ¨ç½²LLMæ—¶éœ€è°¨æ…è€ƒè™‘é‡åŒ–ç­–ç•¥ã€‚å…·ä½“æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦åœ¨ä¸åŒå®éªŒè®¾ç½®ä¸­æœ‰æ‰€ä¸åŒï¼Œå¼ºè°ƒäº†é‡åŒ–æ–¹æ³•é€‰æ‹©çš„é‡è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æ™ºèƒ½å®¢æœå’Œå†³ç­–æ”¯æŒç³»ç»Ÿç­‰ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦é«˜é€æ˜åº¦å’Œå¯è§£é‡Šæ€§çš„åœºæ™¯ä¸­ã€‚ç ”ç©¶ç»“æœä¸ºå¼€å‘æ›´å…·é€æ˜åº¦çš„LLMæä¾›äº†ç†è®ºä¾æ®ï¼Œä¿ƒè¿›äº†ç›¸å…³æŠ€æœ¯çš„å®é™…åº”ç”¨ä¸æ¨å¹¿ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Quantization methods are widely used to accelerate inference and streamline the deployment of large language models (LLMs). While prior research has extensively investigated the degradation of various LLM capabilities due to quantization, its effects on model explainability and interpretability, which are crucial for understanding decision-making processes, remain unexplored. To address this gap, we conduct comprehensive experiments using three common quantization techniques at distinct bit widths, in conjunction with two explainability methods, counterfactual examples and natural language explanations, as well as two interpretability approaches, knowledge memorization analysis and latent multi-hop reasoning analysis. We complement our analysis with a thorough user study, evaluating selected explainability methods. Our findings reveal that, depending on the configuration, quantization can significantly impact model explainability and interpretability. Notably, the direction of this effect is not consistent, as it strongly depends on (1) the quantization method, (2) the explainability or interpretability approach, and (3) the evaluation protocol. In some settings, human evaluation shows that quantization degrades explainability, while in others, it even leads to improvements. Our work serves as a cautionary tale, demonstrating that quantization can unpredictably affect model transparency. This insight has important implications for deploying LLMs in applications where transparency is a critical requirement.

