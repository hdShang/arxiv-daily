---
layout: default
title: MultiHal: Multilingual Dataset for Knowledge-Graph Grounded Evaluation of LLM Hallucinations
---

# MultiHal: Multilingual Dataset for Knowledge-Graph Grounded Evaluation of LLM Hallucinations

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14101" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14101v2</a>
  <a href="https://arxiv.org/pdf/2505.14101.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14101v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14101v2', 'MultiHal: Multilingual Dataset for Knowledge-Graph Grounded Evaluation of LLM Hallucinations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ernests Lavrinovics, Russa Biswas, Katja Hose, Johannes Bjerva

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20 (æ›´æ–°: 2025-10-23)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMultiHalä»¥è§£å†³å¤šè¯­è¨€çŸ¥è¯†å›¾è°±åŸºç¡€çš„LLMå¹»è§‰è¯„ä¼°é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `çŸ¥è¯†å›¾è°±` `å¹»è§‰è¯„ä¼°` `å¤šè¯­è¨€å¤„ç†` `ç»“æ„åŒ–æ•°æ®` `è‡ªç„¶è¯­è¨€å¤„ç†` `äº‹å®æ ¸æŸ¥`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¹»è§‰è¯„ä¼°åŸºå‡†ä¸»è¦é›†ä¸­åœ¨è‹±è¯­æ•°æ®é›†ä¸Šï¼Œç¼ºä¹å¤šè¯­è¨€å’ŒçŸ¥è¯†å›¾è°±è·¯å¾„çš„æ”¯æŒï¼Œå¯¼è‡´è¯„ä¼°çš„å±€é™æ€§ã€‚
2. æœ¬æ–‡æå‡ºMultiHalï¼Œä¸€ä¸ªåŸºäºçŸ¥è¯†å›¾è°±çš„å¤šè¯­è¨€å¤šè·³è¯„ä¼°åŸºå‡†ï¼Œæ—¨åœ¨é€šè¿‡ç»“æ„åŒ–äº‹å®èµ„æºæ”¹å–„å¹»è§‰è¯„ä¼°ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒKGé›†æˆåœ¨è¯­ä¹‰ç›¸ä¼¼åº¦ã€NLIè•´æ¶µå’Œå¹»è§‰æ£€æµ‹æ–¹é¢ç›¸è¾ƒäºä¼ ç»ŸQAæ–¹æ³•æœ‰æ˜¾è‘—æå‡ï¼Œå¾—åˆ†æé«˜å¹…åº¦åœ¨0.12åˆ°0.42ä¹‹é—´ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å›ºæœ‰çš„å¿ å®æ€§å’Œäº‹å®æ€§é™åˆ¶ï¼Œé€šå¸¸è¢«ç§°ä¸ºå¹»è§‰ã€‚ç°æœ‰çš„è¯„ä¼°åŸºå‡†ä¸»è¦é›†ä¸­åœ¨è‹±è¯­æ•°æ®é›†ä¸Šï¼Œä¾èµ–äºè¡¥å……ä¿¡æ¯ä¸Šä¸‹æ–‡è€Œå¿½è§†äº†ç»“æ„åŒ–äº‹å®èµ„æºã€‚ä¸ºæ­¤ï¼ŒçŸ¥è¯†å›¾è°±ï¼ˆKGsï¼‰è¢«è®¤ä¸ºæ˜¯å‡è½»å¹»è§‰çš„æœ‰æ•ˆå·¥å…·ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåŸºäºçŸ¥è¯†å›¾è°±çš„å¤šè¯­è¨€å¤šè·³è¯„ä¼°åŸºå‡†MultiHalï¼Œæ—¨åœ¨æ”¹å–„ç”Ÿæˆæ–‡æœ¬çš„è¯„ä¼°ã€‚æˆ‘ä»¬ä»å¼€æ”¾åŸŸçŸ¥è¯†å›¾è°±ä¸­æŒ–æ˜äº†14ä¸‡æ¡KGè·¯å¾„ï¼Œç­›é€‰å‡ºé«˜è´¨é‡çš„2.59ä¸‡æ¡ã€‚åŸºçº¿è¯„ä¼°æ˜¾ç¤ºï¼ŒKGé›†æˆåœ¨å¤šä¸ªè¯­è¨€å’Œæ¨¡å‹ä¸Šæ˜¾è‘—æé«˜äº†è¯­ä¹‰ç›¸ä¼¼åº¦ã€NLIè•´æ¶µå’Œå¹»è§‰æ£€æµ‹çš„å¾—åˆ†ï¼Œå±•ç¤ºäº†å…¶æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆæ–‡æœ¬æ—¶çš„å¹»è§‰é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å¤šä¾èµ–äºè‹±è¯­æ•°æ®é›†å’Œéç»“æ„åŒ–ä¿¡æ¯ï¼Œç¼ºä¹å¤šè¯­è¨€å’ŒçŸ¥è¯†å›¾è°±çš„æ”¯æŒï¼Œå¯¼è‡´è¯„ä¼°æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºMultiHalåŸºå‡†ï¼Œé€šè¿‡å¼•å…¥çŸ¥è¯†å›¾è°±æä¾›ç»“æ„åŒ–äº‹å®ï¼Œå¢å¼ºå¤šè¯­è¨€å¹»è§‰è¯„ä¼°çš„æœ‰æ•ˆæ€§ï¼Œæ—¨åœ¨æ”¹å–„ç°æœ‰è¯„ä¼°æ–¹æ³•çš„å±€é™æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€KGè·¯å¾„æŒ–æ˜ä¸ç­›é€‰ã€è¯„ä¼°åŸºå‡†æ„å»ºç­‰é˜¶æ®µã€‚é¦–å…ˆä»å¼€æ”¾åŸŸçŸ¥è¯†å›¾è°±ä¸­æŒ–æ˜KGè·¯å¾„ï¼Œç„¶åç­›é€‰å‡ºé«˜è´¨é‡çš„è·¯å¾„ä»¥æ„å»ºè¯„ä¼°åŸºå‡†ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†çŸ¥è¯†å›¾è°±ä¸å¤šè¯­è¨€è¯„ä¼°ç»“åˆï¼Œå¡«è¡¥äº†ç°æœ‰è¯„ä¼°åŸºå‡†åœ¨å¤šè¯­è¨€å’Œç»“æ„åŒ–äº‹å®æ”¯æŒæ–¹é¢çš„ç©ºç™½ï¼Œæ˜¾è‘—æå‡äº†è¯„ä¼°çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®æ”¶é›†è¿‡ç¨‹ä¸­ï¼ŒæŒ–æ˜äº†14ä¸‡æ¡KGè·¯å¾„ï¼Œå¹¶ç»è¿‡ç­›é€‰ä¿ç•™äº†2.59ä¸‡æ¡é«˜è´¨é‡è·¯å¾„ï¼Œç¡®ä¿äº†è¯„ä¼°åŸºå‡†çš„æœ‰æ•ˆæ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMultiHalåœ¨å¤šä¸ªè¯­è¨€å’Œæ¨¡å‹ä¸Šç›¸è¾ƒäºä¼ ç»ŸQAæ–¹æ³•ï¼Œè¯­ä¹‰ç›¸ä¼¼åº¦å¾—åˆ†æé«˜äº†0.12åˆ°0.36ï¼ŒNLIè•´æ¶µå¾—åˆ†æé«˜äº†0.16åˆ°0.36ï¼Œå¹»è§‰æ£€æµ‹å¾—åˆ†æé«˜äº†0.29åˆ°0.42ï¼Œè¯æ˜äº†çŸ¥è¯†å›¾è°±é›†æˆçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤šè¯­è¨€ç”Ÿæˆæ¨¡å‹çš„è¯„ä¼°ã€çŸ¥è¯†å›¾è°±åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„åº”ç”¨ä»¥åŠå¹»è§‰æ£€æµ‹ä¸äº‹å®æ ¸æŸ¥ä»»åŠ¡ã€‚é€šè¿‡æä¾›ä¸€ä¸ªç»“æ„åŒ–çš„è¯„ä¼°åŸºå‡†ï¼ŒMultiHalæœ‰åŠ©äºæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„ç ”ç©¶è¿›å±•ï¼Œæå‡ç”Ÿæˆæ¨¡å‹çš„å¯é æ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have inherent limitations of faithfulness and factuality, commonly referred to as hallucinations. Several benchmarks have been developed that provide a test bed for factuality evaluation within the context of English-centric datasets, while relying on supplementary informative context like web links or text passages but ignoring the available structured factual resources. To this end, Knowledge Graphs (KGs) have been identified as a useful aid for hallucination mitigation, as they provide a structured way to represent the facts about entities and their relations with minimal linguistic overhead. We bridge the lack of KG paths and multilinguality for factual language modeling within the existing hallucination evaluation benchmarks and propose a KG-based multilingual, multihop benchmark called MultiHal framed for generative text evaluation. As part of our data collection pipeline, we mined 140k KG-paths from open-domain KGs, from which we pruned noisy KG-paths, curating a high-quality subset of 25.9k. Our baseline evaluation shows an absolute scale improvement by approximately 0.12 to 0.36 points for the semantic similarity score, 0.16 to 0.36 for NLI entailment and 0.29 to 0.42 for hallucination detection in KG-RAG over vanilla QA across multiple languages and multiple models, demonstrating the potential of KG integration. We anticipate MultiHal will foster future research towards several graph-based hallucination mitigation and fact-checking tasks.

