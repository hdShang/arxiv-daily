---
layout: default
title: Neural Incompatibility: The Unbridgeable Gap of Cross-Scale Parametric Knowledge Transfer in Large Language Models
---

# Neural Incompatibility: The Unbridgeable Gap of Cross-Scale Parametric Knowledge Transfer in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14436" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14436v1</a>
  <a href="https://arxiv.org/pdf/2505.14436.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14436v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14436v1', 'Neural Incompatibility: The Unbridgeable Gap of Cross-Scale Parametric Knowledge Transfer in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuqiao Tan, Shizhu He, Kang Liu, Jun Zhao

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20

**å¤‡æ³¨**: Accepted by ACL'25 Main. Code link: https://github.com/Trae1ounG/Neural_Incompatibility

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Trae1ounG/Neural_Incompatibility)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLaTenä»¥è§£å†³å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹é—´çŸ¥è¯†è½¬ç§»é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `çŸ¥è¯†è½¬ç§»` `å‚æ•°å¯¹é½` `LaTen` `ç¥ç»ä¸å…¼å®¹æ€§` `æœºå™¨å­¦ä¹ ` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„çŸ¥è¯†è½¬ç§»æ–¹æ³•åœ¨ä¸åŒè§„æ¨¡çš„LLMsä¹‹é—´å­˜åœ¨æ˜¾è‘—çš„ç»“æ„æ€§å·®å¼‚ï¼Œå¯¼è‡´è½¬ç§»æ•ˆæœä¸ç¨³å®šã€‚
2. æœ¬æ–‡æå‡ºäº†LaTenæ–¹æ³•ï¼Œé€šè¿‡å°‘é‡è®­ç»ƒæ­¥éª¤å®ç°ä¸åŒè§„æ¨¡LLMsçš„å‚æ•°ç©ºé—´å¯¹é½ï¼Œé™ä½äº†åç»­å¾®è°ƒçš„éœ€æ±‚ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒPostPKTå’ŒPrePKTåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å‡é¢ä¸´ç¨³å®šæ€§æŒ‘æˆ˜ï¼Œæ­ç¤ºäº†ç¥ç»ä¸å…¼å®¹æ€§å¯¹PKTçš„å½±å“ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æä¾›äº†ä¸€ä¸ªé€æ˜çš„å‚æ•°ç©ºé—´ï¼Œèƒ½å¤Ÿç¼–ç å¤§é‡çŸ¥è¯†å¹¶è¿›è¡Œåˆ†æå’Œè½¬ç§»ã€‚æœ¬æ–‡æ¢è®¨äº†è·¨è§„æ¨¡çš„å‚æ•°çŸ¥è¯†è½¬ç§»ï¼ˆPKTï¼‰é¢ä¸´çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†Post-Align PKTï¼ˆPostPKTï¼‰å’ŒPre-Align PKTï¼ˆPrePKTï¼‰ä¸¤ç§æ–¹æ³•ã€‚æˆ‘ä»¬å¼•å…¥çš„LaTenæ–¹æ³•é€šè¿‡å°‘é‡è®­ç»ƒæ­¥éª¤å¯¹ä¸åŒè§„æ¨¡çš„LLMsè¿›è¡Œå‚æ•°ç©ºé—´å¯¹é½ï¼Œå‡å°‘äº†åç»­å¾®è°ƒçš„æˆæœ¬ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå°½ç®¡PostPKTå’ŒPrePKTåœ¨å®ç°ç¨³å®šè½¬ç§»æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ï¼Œä½†æˆ‘ä»¬è¯†åˆ«å‡ºç¥ç»ä¸å…¼å®¹æ€§ä½œä¸ºä¸»è¦éšœç¢ï¼Œä¸ºæœªæ¥çš„PKTç ”ç©¶æä¾›äº†æ–°æ€è·¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä¸åŒè§„æ¨¡çš„å¤§å‹è¯­è¨€æ¨¡å‹ä¹‹é—´çš„çŸ¥è¯†è½¬ç§»é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å‚æ•°å¯¹é½å’Œåç»­å¾®è°ƒæ–¹é¢å­˜åœ¨é«˜æˆæœ¬å’Œä¸ç¨³å®šæ€§çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†LaTenæ–¹æ³•ï¼Œé€šè¿‡åœ¨å‚æ•°ç©ºé—´ä¸­è¿›è¡Œå¯¹é½ï¼Œå‡å°‘äº†å¯¹åç»­å¾®è°ƒçš„ä¾èµ–ï¼Œä»è€Œæé«˜äº†è·¨è§„æ¨¡çŸ¥è¯†è½¬ç§»çš„æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å‚æ•°å¯¹é½æ¨¡å—å’Œè®­ç»ƒæ­¥éª¤ã€‚é¦–å…ˆï¼Œé€šè¿‡å°‘é‡è®­ç»ƒæ­¥éª¤å¯¹ä¸åŒè§„æ¨¡çš„LLMsè¿›è¡Œå‚æ•°ç©ºé—´çš„åˆæ­¥å¯¹é½ï¼Œç„¶åè¿›è¡ŒçŸ¥è¯†è½¬ç§»ã€‚

**å…³é”®åˆ›æ–°**ï¼šLaTenæ–¹æ³•æ˜¯æœ¬ç ”ç©¶çš„æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼Œå®ƒé€šè¿‡ç®€åŒ–å¯¹é½è¿‡ç¨‹ï¼Œæ˜¾è‘—é™ä½äº†çŸ¥è¯†è½¬ç§»çš„å¤æ‚æ€§å’Œæˆæœ¬ï¼Œä¸ä¼ ç»Ÿçš„PostPKTæ–¹æ³•å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨LaTenä¸­ï¼Œå‚æ•°å¯¹é½çš„å…·ä½“å®ç°ä¾èµ–äºç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œä¼˜åŒ–ç­–ç•¥ï¼Œç¡®ä¿åœ¨å°‘é‡è®­ç»ƒæ­¥éª¤å†…å®ç°æœ‰æ•ˆçš„å¯¹é½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLaTenæ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æé«˜äº†çŸ¥è¯†è½¬ç§»çš„ç¨³å®šæ€§ï¼Œç›¸è¾ƒäºä¼ ç»ŸPostPKTæ–¹æ³•ï¼Œè½¬ç§»æ•ˆæœæå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œå±•ç¤ºäº†å…¶åœ¨è·¨è§„æ¨¡æ¨¡å‹åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æœºå™¨ç¿»è¯‘å’Œæ™ºèƒ½å¯¹è¯ç³»ç»Ÿç­‰ã€‚é€šè¿‡æé«˜ä¸åŒè§„æ¨¡æ¨¡å‹ä¹‹é—´çš„çŸ¥è¯†è½¬ç§»æ•ˆç‡ï¼Œèƒ½å¤ŸåŠ é€Ÿæ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ï¼Œé™ä½èµ„æºæ¶ˆè€—ï¼Œæ¨åŠ¨AIæŠ€æœ¯çš„æ™®åŠä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) offer a transparent brain with accessible parameters that encode extensive knowledge, which can be analyzed, located and transferred. Consequently, a key research challenge is to transcend traditional knowledge transfer paradigms rooted in symbolic language and achieve genuine Parametric Knowledge Transfer (PKT). Significantly, exploring effective methods for transferring knowledge across LLMs of different scales through parameters presents an intriguing and valuable research direction. In this paper, we first demonstrate $\textbf{Alignment}$ in parametric space is the fundamental prerequisite to achieve successful cross-scale PKT. We redefine the previously explored knowledge transfer as Post-Align PKT (PostPKT), which utilizes extracted parameters for LoRA initialization and requires subsequent fine-tune for alignment. Hence, to reduce cost for further fine-tuning, we introduce a novel Pre-Align PKT (PrePKT) paradigm and propose a solution called $\textbf{LaTen}$ ($\textbf{L}$oc$\textbf{a}$te-$\textbf{T}$h$\textbf{e}$n-Alig$\textbf{n}$) that aligns the parametric spaces of LLMs across scales only using several training steps without following training. Comprehensive experiments on four benchmarks demonstrate that both PostPKT and PrePKT face challenges in achieving consistently stable transfer. Through in-depth analysis, we identify $\textbf{Neural Incompatibility}$ as the ethological and parametric structural differences between LLMs of varying scales, presenting fundamental challenges to achieving effective PKT. These findings provide fresh insights into the parametric architectures of LLMs and highlight promising directions for future research on efficient PKT. Our code is available at https://github.com/Trae1ounG/Neural_Incompatibility.

