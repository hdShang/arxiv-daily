---
layout: default
title: From Templates to Natural Language: Generalization Challenges in Instruction-Tuned LLMs for Spatial Reasoning
---

# From Templates to Natural Language: Generalization Challenges in Instruction-Tuned LLMs for Spatial Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14425" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14425v2</a>
  <a href="https://arxiv.org/pdf/2505.14425.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14425v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14425v2', 'From Templates to Natural Language: Generalization Challenges in Instruction-Tuned LLMs for Spatial Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chalamalasetti Kranti, Sherzod Hakimov, David Schlangen

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20 (æ›´æ–°: 2025-08-18)

**å¤‡æ³¨**: 17 pages

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç ”ç©¶ç©ºé—´æ¨ç†ä¸­çš„æŒ‡ä»¤æ³›åŒ–æŒ‘æˆ˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æŒ‡ä»¤è°ƒä¼˜` `ç©ºé—´æ¨ç†` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ³›åŒ–èƒ½åŠ›` `åˆæˆæŒ‡ä»¤` `äººç±»æŒ‡ä»¤` `é”™è¯¯åˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æŒ‡ä»¤è°ƒä¼˜æ¨¡å‹åœ¨ä»åˆæˆæŒ‡ä»¤åˆ°äººç±»ç¼–å†™æŒ‡ä»¤çš„æ³›åŒ–ä¸Šå­˜åœ¨æ˜¾è‘—æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚çš„ç©ºé—´æ¨ç†ä»»åŠ¡ä¸­ã€‚
2. æœ¬æ–‡é€šè¿‡å¯¹å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»…ä½¿ç”¨åˆæˆæŒ‡ä»¤ï¼Œæ—¨åœ¨æé«˜å…¶åœ¨çœŸå®æŒ‡ä»¤ç¯å¢ƒä¸­çš„è¡¨ç°ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ¨¡å‹åœ¨ç®€å•ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨å¤æ‚ä»»åŠ¡ä¸­æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œæ­ç¤ºäº†æŒ‡ä»¤æ³›åŒ–çš„ä¸è¶³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æŒ‡ä»¤è°ƒä¼˜çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šç§ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨åŸºäºçœŸå®äººç±»æŒ‡ä»¤çš„ç¯å¢ƒä¸­è¿›è¡Œæ³›åŒ–ä»ç„¶é¢ä¸´æŒ‘æˆ˜ã€‚æœ¬æ–‡ç ”ç©¶äº†ç©ºé—´åŸºç¡€ä»»åŠ¡ä¸­çš„æ³›åŒ–é—®é¢˜ï¼Œæ¨¡å‹éœ€è¦åœ¨$2.5$Dç½‘æ ¼ä¸Šè§£é‡Šå’Œç¿»è¯‘æŒ‡ä»¤ä»¥æ„å»ºç‰©ä½“æ’åˆ—ã€‚æˆ‘ä»¬ä½¿ç”¨ä»…åŒ…å«åˆæˆæŒ‡ä»¤çš„å¾®è°ƒæ–¹æ³•ï¼Œå¹¶åœ¨åŒ…å«åˆæˆå’Œäººç±»ç¼–å†™æŒ‡ä»¤çš„åŸºå‡†æ•°æ®é›†ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚ç»“æœæ˜¾ç¤ºï¼Œå°½ç®¡æ¨¡å‹åœ¨ç®€å•ä»»åŠ¡ä¸Šæ³›åŒ–è‰¯å¥½ï¼Œä½†åœ¨å¤æ‚ä»»åŠ¡ä¸Šçš„æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚æˆ‘ä»¬å¯¹æŒ‡ä»¤æ³›åŒ–ä¸­çš„å·®è·è¿›è¡Œäº†è¯¦ç»†çš„é”™è¯¯åˆ†æã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æŒ‡ä»¤è°ƒä¼˜çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç©ºé—´æ¨ç†ä»»åŠ¡ä¸­ä»åˆæˆæŒ‡ä»¤æ³›åŒ–åˆ°äººç±»ç¼–å†™æŒ‡ä»¤çš„å›°éš¾ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚ä»»åŠ¡æ—¶è¡¨ç°ä¸ä½³ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡ä»…ä½¿ç”¨åˆæˆæŒ‡ä»¤å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œæ¢ç´¢å…¶åœ¨å¤æ‚ç©ºé—´åŸºç¡€ä»»åŠ¡ä¸­çš„æ³›åŒ–èƒ½åŠ›ï¼Œæ—¨åœ¨æé«˜æ¨¡å‹å¯¹çœŸå®æŒ‡ä»¤çš„ç†è§£å’Œæ‰§è¡Œèƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨äº†ä¸€ä¸ªä¸¤é˜¶æ®µçš„æµç¨‹ï¼Œé¦–å…ˆæ˜¯åˆæˆæŒ‡ä»¤çš„å¾®è°ƒé˜¶æ®µï¼Œå…¶æ¬¡æ˜¯åœ¨åŒ…å«åˆæˆå’Œäººç±»æŒ‡ä»¤çš„åŸºå‡†æ•°æ®é›†ä¸Šçš„è¯„ä¼°é˜¶æ®µï¼Œé‡ç‚¹å…³æ³¨æ¨¡å‹åœ¨ä¸åŒä»»åŠ¡å¤æ‚åº¦ä¸‹çš„è¡¨ç°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºå¯¹æŒ‡ä»¤æ³›åŒ–é—®é¢˜çš„æ·±å…¥åˆ†æï¼Œç‰¹åˆ«æ˜¯åœ¨å¤æ‚ä»»åŠ¡ä¸­æ€§èƒ½çš„æ˜¾è‘—ä¸‹é™ï¼Œæä¾›äº†å¯¹ç°æœ‰æ–¹æ³•çš„è¡¥å……å’Œæ”¹è¿›æ–¹å‘ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œå‚æ•°è®¾ç½®ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹å¯¹åˆæˆæŒ‡ä»¤çš„ç†è§£ï¼ŒåŒæ—¶åœ¨è¯„ä¼°é˜¶æ®µä½¿ç”¨äº†å¤šæ ·åŒ–çš„åŸºå‡†æ•°æ®é›†ï¼Œç¡®ä¿ç»“æœçš„å…¨é¢æ€§å’Œå¯é æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ¨¡å‹åœ¨ç®€å•ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ï¼Œå‡†ç¡®ç‡è¾¾åˆ°90%ä»¥ä¸Šï¼Œä½†åœ¨å¤æ‚ä»»åŠ¡ä¸­å‡†ç¡®ç‡ä¸‹é™è‡³60%ä»¥ä¸‹ï¼Œæ­ç¤ºäº†æŒ‡ä»¤æ³›åŒ–çš„æ˜¾è‘—å·®è·ã€‚è¿™ä¸€å‘ç°ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†é‡è¦çš„æ”¹è¿›æ–¹å‘ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬äººæœºäº¤äº’ã€æœºå™¨äººå¯¼èˆªå’Œæ™ºèƒ½åŠ©æ‰‹ç­‰åœºæ™¯ã€‚é€šè¿‡æé«˜æ¨¡å‹å¯¹å¤æ‚æŒ‡ä»¤çš„ç†è§£èƒ½åŠ›ï¼Œå¯ä»¥å¢å¼ºè¿™äº›ç³»ç»Ÿåœ¨çœŸå®ç¯å¢ƒä¸­çš„è¡¨ç°ï¼Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿçš„å®é™…åº”ç”¨å’Œå‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Instruction-tuned large language models (LLMs) have shown strong performance on a variety of tasks; however, generalizing from synthetic to human-authored instructions in grounded environments remains a challenge for them. In this work, we study generalization challenges in spatial grounding tasks where models interpret and translate instructions for building object arrangements on a $2.5$D grid. We fine-tune LLMs using only synthetic instructions and evaluate their performance on a benchmark dataset containing both synthetic and human-written instructions. Our results reveal that while models generalize well on simple tasks, their performance degrades significantly on more complex tasks. We present a detailed error analysis of the gaps in instruction generalization.

