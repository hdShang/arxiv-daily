---
layout: default
title: Universal Acoustic Adversarial Attacks for Flexible Control of Speech-LLMs
---

# Universal Acoustic Adversarial Attacks for Flexible Control of Speech-LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14286" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14286v1</a>
  <a href="https://arxiv.org/pdf/2505.14286.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14286v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14286v1', 'Universal Acoustic Adversarial Attacks for Flexible Control of Speech-LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Rao Ma, Mengjie Qian, Vyas Raina, Mark Gales, Kate Knill

**åˆ†ç±»**: cs.CL, cs.SD, eess.AS

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé€šç”¨å£°å­¦å¯¹æŠ—æ”»å‡»ä»¥çµæ´»æ§åˆ¶è¯­éŸ³å¤§è¯­è¨€æ¨¡å‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¯¹æŠ—æ”»å‡»` `è¯­éŸ³å¤§è¯­è¨€æ¨¡å‹` `å£°å­¦ç‰¹å¾` `è¾“å…¥å±æ€§é€‰æ‹©` `æ¨¡å‹å®‰å…¨æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¯­éŸ³å¤§è¯­è¨€æ¨¡å‹åœ¨çµæ´»æ€§ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä½†ä¹Ÿå› æ­¤æš´éœ²å‡ºå¯¹æŠ—æ”»å‡»çš„è„†å¼±æ€§ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§é€šç”¨å£°å­¦å¯¹æŠ—æ”»å‡»æ–¹æ³•ï¼Œé€šè¿‡åœ¨è¾“å…¥éŸ³é¢‘å‰é™„åŠ å›ºå®šçš„å¯¹æŠ—éŸ³é¢‘æ®µæ¥æ§åˆ¶æ¨¡å‹è¾“å‡ºã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œé’ˆå¯¹ç‰¹å®šè¾“å…¥å±æ€§çš„é€‰æ‹©æ€§æ”»å‡»èƒ½å¤Ÿæœ‰æ•ˆå½±å“æ¨¡å‹è¾“å‡ºï¼Œæ­ç¤ºäº†ç°æœ‰æ¨¡å‹çš„å®‰å…¨éšæ‚£ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€é¢„è®­ç»ƒè¯­éŸ³ç¼–ç å™¨ä¸å¤§å‹è¯­è¨€æ¨¡å‹çš„ç»“åˆï¼Œè¯­éŸ³å¤§è¯­è¨€æ¨¡å‹ï¼ˆSpeech LLMsï¼‰èƒ½å¤Ÿå¤„ç†å¤šç§å£è¯­è¯­è¨€å¤„ç†ä»»åŠ¡ã€‚ç„¶è€Œï¼Œè¿™ç§çµæ´»æ€§ä¹Ÿä½¿å¾—æ¨¡å‹æ›´å®¹æ˜“å—åˆ°å¯¹æŠ—æ”»å‡»ã€‚æœ¬æ–‡ç ”ç©¶äº†å¯¹è¯­éŸ³å¤§è¯­è¨€æ¨¡å‹çš„é€šç”¨å£°å­¦å¯¹æŠ—æ”»å‡»ï¼Œæå‡ºå°†å›ºå®šçš„å¯¹æŠ—éŸ³é¢‘æ®µé™„åŠ åˆ°åŸå§‹è¾“å…¥éŸ³é¢‘ä¸Šã€‚ç ”ç©¶å‘ç°ï¼Œè¿™ç§æ”»å‡»å¯ä»¥å¯¼è‡´æ¨¡å‹ä¸è¾“å‡ºç»“æœæˆ–æ‰§è¡Œä¿®æ”¹åçš„ä»»åŠ¡ï¼ŒåŒæ—¶è¿˜å¯ä»¥é€‰æ‹©æ€§æ¿€æ´»ï¼Œé’ˆå¯¹ç‰¹å®šè¾“å…¥å±æ€§å¦‚è¯´è¯è€…æ€§åˆ«æˆ–è¯­è¨€ã€‚ç ”ç©¶ç»“æœæ­ç¤ºäº†Qwen2-Audioå’ŒGranite-Speechçš„å…³é”®è„†å¼±æ€§ï¼Œå¼ºè°ƒäº†éœ€è¦æ›´å¼ºçš„è®­ç»ƒç­–ç•¥ä»¥æé«˜å¯¹æŠ—æ”»å‡»çš„æŠµæŠ—åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è¯­éŸ³å¤§è¯­è¨€æ¨¡å‹åœ¨çµæ´»æ€§å¸¦æ¥çš„å¯¹æŠ—æ”»å‡»è„†å¼±æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆæŠµå¾¡é’ˆå¯¹ç‰¹å®šè¾“å…¥å±æ€§çš„æ”»å‡»ï¼Œå¯¼è‡´æ¨¡å‹è¾“å‡ºä¸ç¨³å®šã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„æ ¸å¿ƒæ€è·¯æ˜¯ä½¿ç”¨å›ºå®šçš„å¯¹æŠ—éŸ³é¢‘æ®µï¼Œé™„åŠ åˆ°åŸå§‹è¾“å…¥éŸ³é¢‘ä¸Šï¼Œä»¥å®ç°å¯¹æ¨¡å‹è¾“å‡ºçš„çµæ´»æ§åˆ¶ã€‚è¿™ç§è®¾è®¡å…è®¸æ”»å‡»åœ¨ç‰¹å®šæ¡ä»¶ä¸‹æ¿€æ´»ï¼Œä»è€Œä¸å½±å“å…¶ä»–è¾“å…¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¯¹æŠ—éŸ³é¢‘ç”Ÿæˆã€è¾“å…¥éŸ³é¢‘å¤„ç†å’Œæ¨¡å‹è¾“å‡ºæ§åˆ¶ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆç”Ÿæˆé€šç”¨å¯¹æŠ—éŸ³é¢‘æ®µï¼Œç„¶åå°†å…¶ä¸åŸå§‹è¾“å…¥éŸ³é¢‘ç»“åˆï¼Œæœ€åé€šè¿‡æ¨¡å‹è¿›è¡Œå¤„ç†ä»¥è§‚å¯Ÿè¾“å‡ºå˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†é€‰æ‹©æ€§æ¿€æ´»çš„å¯¹æŠ—æ”»å‡»ç­–ç•¥ï¼Œä½¿å¾—æ”»å‡»èƒ½å¤Ÿé’ˆå¯¹ç‰¹å®šå±æ€§è€Œéæ™®éå½±å“ï¼Œä»è€Œå®ç°æ›´ç²¾ç»†çš„æ§åˆ¶ã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„å¹¿æ³›å½±å“å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé€‰æ‹©äº†é€‚åˆçš„å¯¹æŠ—éŸ³é¢‘é•¿åº¦å’Œé¢‘ç‡ç‰¹å¾ï¼ŒåŒæ—¶é‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–å¯¹æŠ—æ•ˆæœã€‚ç½‘ç»œç»“æ„ä¸Šï¼Œç»“åˆäº†é¢„è®­ç»ƒçš„è¯­éŸ³ç¼–ç å™¨ä¸è¯­è¨€æ¨¡å‹ï¼Œä»¥å¢å¼ºå¯¹æŠ—æ”»å‡»çš„æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé’ˆå¯¹Qwen2-Audioå’ŒGranite-Speechçš„å¯¹æŠ—æ”»å‡»æˆåŠŸç‡æ˜¾è‘—ï¼Œèƒ½å¤Ÿä½¿æ¨¡å‹åœ¨ç‰¹å®šè¾“å…¥æ¡ä»¶ä¸‹äº§ç”Ÿé”™è¯¯è¾“å‡ºã€‚ç ”ç©¶æ˜¾ç¤ºï¼Œé€‰æ‹©æ€§æ¿€æ´»çš„æ”»å‡»ç­–ç•¥åœ¨ç‰¹å®šå±æ€§ä¸‹çš„å½±å“åŠ›æ›´å¼ºï¼Œæ­ç¤ºäº†æ¨¡å‹çš„å®‰å…¨éšæ‚£ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è¯­éŸ³è¯†åˆ«ã€è¯­éŸ³åˆæˆå’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æé«˜æ¨¡å‹å¯¹å¯¹æŠ—æ”»å‡»çš„æŠµæŠ—åŠ›ï¼Œå¯ä»¥å¢å¼ºè¯­éŸ³å¤§è¯­è¨€æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„å®‰å…¨æ€§å’Œå¯é æ€§ï¼Œè¿›è€Œæ¨åŠ¨æ™ºèƒ½è¯­éŸ³æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The combination of pre-trained speech encoders with large language models has enabled the development of speech LLMs that can handle a wide range of spoken language processing tasks. While these models are powerful and flexible, this very flexibility may make them more vulnerable to adversarial attacks. To examine the extent of this problem, in this work we investigate universal acoustic adversarial attacks on speech LLMs. Here a fixed, universal, adversarial audio segment is prepended to the original input audio. We initially investigate attacks that cause the model to either produce no output or to perform a modified task overriding the original prompt. We then extend the nature of the attack to be selective so that it activates only when specific input attributes, such as a speaker gender or spoken language, are present. Inputs without the targeted attribute should be unaffected, allowing fine-grained control over the model outputs. Our findings reveal critical vulnerabilities in Qwen2-Audio and Granite-Speech and suggest that similar speech LLMs may be susceptible to universal adversarial attacks. This highlights the need for more robust training strategies and improved resistance to adversarial attacks.

