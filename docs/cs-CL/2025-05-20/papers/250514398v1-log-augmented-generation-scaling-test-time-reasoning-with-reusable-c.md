---
layout: default
title: "Log-Augmented Generation: Scaling Test-Time Reasoning with Reusable Computation"
---

# Log-Augmented Generation: Scaling Test-Time Reasoning with Reusable Computation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14398" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14398v1</a>
  <a href="https://arxiv.org/pdf/2505.14398.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14398v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14398v1', 'Log-Augmented Generation: Scaling Test-Time Reasoning with Reusable Computation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Peter Baile Chen, Yi Zhang, Dan Roth, Samuel Madden, Jacob Andreas, Michael Cafarella

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20

**å¤‡æ³¨**: Data and code are available at https://peterbaile.github.io/lag/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ—¥å¿—å¢å¼ºç”Ÿæˆæ¡†æ¶ä»¥æå‡æ¨¡å‹æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ—¥å¿—å¢å¼ºç”Ÿæˆ` `æ¨ç†èƒ½åŠ›` `å¤§å‹è¯­è¨€æ¨¡å‹` `çŸ¥è¯†é‡ç”¨` `KVç¼“å­˜` `æ™ºèƒ½åŠ©æ‰‹` `è‡ªåŠ¨åŒ–å®¢æœ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¨ç†èƒ½åŠ›ä¸Šå­˜åœ¨ä¸è¶³ï¼Œæ— æ³•æœ‰æ•ˆåˆ©ç”¨è¿‡å»çš„ç»éªŒè¿›è¡Œå­¦ä¹ å’Œé€‚åº”æ–°ä»»åŠ¡ã€‚
2. æœ¬æ–‡æå‡ºçš„æ—¥å¿—å¢å¼ºç”Ÿæˆï¼ˆLAGï¼‰æ¡†æ¶ï¼Œé€šè¿‡é‡ç”¨å…ˆå‰è®¡ç®—å’Œæ¨ç†ï¼Œæå‡æ¨¡å‹åœ¨æ–°ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLAGåœ¨çŸ¥è¯†å’Œæ¨ç†å¯†é›†å‹æ•°æ®é›†ä¸Šæ˜¾è‘—è¶…è¶Šäº†ä¸ä½¿ç”¨æ—¥å¿—çš„æ ‡å‡†ç³»ç»Ÿï¼Œæå‡æ•ˆæœæ˜æ˜¾ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡äººç±»èƒ½å¤Ÿè‡ªç„¶åœ°ä»è¿‡å»çš„ç»éªŒä¸­å­¦ä¹ å¹¶é€‚åº”ï¼Œä½†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åŠå…¶ä»£ç†æ¨¡å‹åœ¨ä¿ç•™å…ˆå‰ä»»åŠ¡çš„æ¨ç†å¹¶å°†å…¶åº”ç”¨äºæœªæ¥ä¸Šä¸‹æ–‡æ–¹é¢å­˜åœ¨å›°éš¾ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™æ€§ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶â€”â€”æ—¥å¿—å¢å¼ºç”Ÿæˆï¼ˆLAGï¼‰ï¼Œè¯¥æ¡†æ¶åœ¨æµ‹è¯•æ—¶ç›´æ¥é‡ç”¨è¿‡å»æ—¥å¿—ä¸­çš„è®¡ç®—å’Œæ¨ç†ï¼Œä»è€Œå¢å¼ºæ¨¡å‹ä»å…ˆå‰ä»»åŠ¡ä¸­å­¦ä¹ çš„èƒ½åŠ›ï¼Œå¹¶åœ¨æ–°ä»»åŠ¡ä¸­è¡¨ç°æ›´å¥½ï¼ŒåŒæ—¶ä¿æŒç³»ç»Ÿçš„é«˜æ•ˆæ€§å’Œå¯æ‰©å±•æ€§ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬çš„ç³»ç»Ÿä½¿ç”¨é”®å€¼ï¼ˆKVï¼‰ç¼“å­˜è¡¨ç¤ºä»»åŠ¡æ—¥å¿—ï¼Œç¼–ç å…ˆå‰ä»»åŠ¡çš„å®Œæ•´æ¨ç†ä¸Šä¸‹æ–‡ï¼ŒåŒæ—¶ä»…å­˜å‚¨é€‰å®šå­é›†çš„KVç¼“å­˜ã€‚å½“æ–°ä»»åŠ¡å‡ºç°æ—¶ï¼ŒLAGä»ç›¸å…³æ—¥å¿—ä¸­æ£€ç´¢KVå€¼ä»¥å¢å¼ºç”Ÿæˆã€‚æˆ‘ä»¬çš„ç ”ç©¶è¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—ä¼˜äºä¸åˆ©ç”¨æ—¥å¿—çš„æ ‡å‡†ä»£ç†ç³»ç»Ÿï¼Œä»¥åŠåŸºäºåæ€å’ŒKVç¼“å­˜æŠ€æœ¯çš„ç°æœ‰è§£å†³æ–¹æ¡ˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æµ‹è¯•æ—¶æ— æ³•æœ‰æ•ˆåˆ©ç”¨å…ˆå‰ä»»åŠ¡æ¨ç†çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–åæ€æœºåˆ¶æˆ–çŸ¥è¯†æå–ï¼Œå¯¼è‡´æ•ˆç‡ä½ä¸‹å’Œå‡†ç¡®æ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šLAGæ¡†æ¶é€šè¿‡ç›´æ¥é‡ç”¨å…ˆå‰ä»»åŠ¡çš„è®¡ç®—å’Œæ¨ç†ï¼Œé¿å…äº†é¢å¤–çš„çŸ¥è¯†æå–æ­¥éª¤ï¼Œä»è€Œæé«˜äº†æ¨¡å‹çš„å­¦ä¹ èƒ½åŠ›å’Œæ¨ç†æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLAGç³»ç»Ÿçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä»»åŠ¡æ—¥å¿—çš„KVç¼“å­˜è¡¨ç¤ºã€ç›¸å…³æ—¥å¿—çš„KVå€¼æ£€ç´¢å’Œç”Ÿæˆå¢å¼ºä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚ç³»ç»Ÿåœ¨æ–°ä»»åŠ¡å‡ºç°æ—¶ï¼Œé€šè¿‡æ£€ç´¢ç›¸å…³æ—¥å¿—ä¸­çš„KVå€¼æ¥å¢å¼ºç”Ÿæˆè¿‡ç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šLAGçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºç›´æ¥é‡ç”¨å…ˆå‰çš„æ¨ç†å’Œè®¡ç®—ï¼Œè€Œä¸æ˜¯ä¾èµ–åæ€æœºåˆ¶æˆ–é¢å¤–çš„çŸ¥è¯†æå–æ­¥éª¤ã€‚è¿™ä¸€è®¾è®¡ä½¿å¾—æ¨¡å‹åœ¨å¤„ç†æ–°ä»»åŠ¡æ—¶æ›´åŠ é«˜æ•ˆå’Œå‡†ç¡®ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚æ–¹é¢ï¼ŒLAGä½¿ç”¨äº†é€‰æ‹©æ€§å­˜å‚¨çš„KVç¼“å­˜ï¼Œä»…å­˜å‚¨ä¸ä»»åŠ¡ç›¸å…³çš„å­é›†ï¼Œç¡®ä¿äº†ç³»ç»Ÿçš„é«˜æ•ˆæ€§ã€‚åŒæ—¶ï¼Œè®¾è®¡äº†é€‚åº”æ€§å¼ºçš„æ£€ç´¢æœºåˆ¶ï¼Œä»¥ä¾¿åœ¨æ–°ä»»åŠ¡ä¸­å¿«é€Ÿè·å–ç›¸å…³ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLAGåœ¨çŸ¥è¯†å’Œæ¨ç†å¯†é›†å‹æ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºä¸ä½¿ç”¨æ—¥å¿—çš„æ ‡å‡†ä»£ç†ç³»ç»Ÿï¼Œæå‡å¹…åº¦è¾¾åˆ°XX%ã€‚ä¸ç°æœ‰åŸºäºåæ€å’ŒKVç¼“å­˜çš„æŠ€æœ¯ç›¸æ¯”ï¼ŒLAGåœ¨å‡†ç¡®æ€§å’Œæ•ˆç‡ä¸Šå‡æœ‰æ˜¾è‘—æ”¹å–„ï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å·¨å¤§æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨åœºæ™¯åŒ…æ‹¬æ™ºèƒ½åŠ©æ‰‹ã€è‡ªåŠ¨åŒ–å®¢æœã€æ•™è‚²è¾…å¯¼ç­‰é¢†åŸŸï¼Œèƒ½å¤Ÿå¸®åŠ©ç³»ç»Ÿæ›´å¥½åœ°ç†è§£ç”¨æˆ·éœ€æ±‚å¹¶æä¾›ä¸ªæ€§åŒ–æœåŠ¡ã€‚æœªæ¥ï¼ŒLAGæ¡†æ¶æœ‰æœ›åœ¨å¤šç§å¤æ‚ä»»åŠ¡ä¸­å®ç°æ›´é«˜æ•ˆçš„æ¨ç†å’Œå†³ç­–æ”¯æŒï¼Œæ¨åŠ¨äººå·¥æ™ºèƒ½çš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While humans naturally learn and adapt from past experiences, large language models (LLMs) and their agentic counterparts struggle to retain reasoning from previous tasks and apply them in future contexts. To address this limitation, we propose a novel framework, log-augmented generation (LAG) that directly reuses prior computation and reasoning from past logs at test time to enhance model's ability to learn from previous tasks and perform better on new, unseen challenges, all while keeping the system efficient and scalable. Specifically, our system represents task logs using key-value (KV) caches, encoding the full reasoning context of prior tasks while storing KV caches for only a selected subset of tokens. When a new task arises, LAG retrieves the KV values from relevant logs to augment generation. Our approach differs from reflection-based memory mechanisms by directly reusing prior reasoning and computations without requiring additional steps for knowledge extraction or distillation. Our method also goes beyond existing KV caching techniques, which primarily target efficiency gains rather than improving accuracy. Experiments on knowledge- and reasoning-intensive datasets demonstrate that our method significantly outperforms standard agentic systems that do not utilize logs, as well as existing solutions based on reflection and KV cache techniques.

