---
layout: default
title: ShieldVLM: Safeguarding the Multimodal Implicit Toxicity via Deliberative Reasoning with LVLMs
---

# ShieldVLM: Safeguarding the Multimodal Implicit Toxicity via Deliberative Reasoning with LVLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14035" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14035v1</a>
  <a href="https://arxiv.org/pdf/2505.14035.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14035v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14035v1', 'ShieldVLM: Safeguarding the Multimodal Implicit Toxicity via Deliberative Reasoning with LVLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shiyao Cui, Qinglin Zhang, Xuan Ouyang, Renmiao Chen, Zhexin Zhang, Yida Lu, Hongning Wang, Han Qiu, Minlie Huang

**åˆ†ç±»**: cs.MM, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºShieldVLMä»¥è§£å†³å¤šæ¨¡æ€éšæ€§æ¯’æ€§æ£€æµ‹é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€éšæ€§æ¯’æ€§` `æ¯’æ€§æ£€æµ‹` `è§†è§‰è¯­è¨€æ¨¡å‹` `è·¨æ¨¡æ€æ¨ç†` `ç¤¾äº¤åª’ä½“å®¡æ ¸`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤šæ¨¡æ€éšæ€§æ¯’æ€§æ£€æµ‹ä¸Šå­˜åœ¨ä¸è¶³ï¼Œå°¤å…¶æ˜¯å½“å„æ¨¡æ€å•ç‹¬çœ‹ä¼¼æ— å®³æ—¶ï¼Œç»„åˆåå´å¯èƒ½ä¼ è¾¾æœ‰å®³ä¿¡æ¯ã€‚
2. æœ¬æ–‡æå‡ºShieldVLMæ¨¡å‹ï¼Œé€šè¿‡æ·±æ€ç†Ÿè™‘çš„è·¨æ¨¡æ€æ¨ç†æ¥è¯†åˆ«å¤šæ¨¡æ€è¯­å¥å’Œå¯¹è¯ä¸­çš„éšæ€§æ¯’æ€§ï¼Œå¡«è¡¥äº†è¿™ä¸€ç ”ç©¶ç©ºç™½ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒShieldVLMåœ¨éšæ€§å’Œæ˜¾æ€§æ¯’æ€§æ£€æµ‹ä¸Šå‡è¶…è¶Šäº†ç°æœ‰çš„å¼ºåŸºçº¿ï¼Œå±•ç¤ºäº†å…¶æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€æ–‡æœ¬-å›¾åƒå†…å®¹ä¸­çš„æ¯’æ€§æ£€æµ‹é¢ä¸´æ—¥ç›Šä¸¥å³»çš„æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯å¤šæ¨¡æ€éšæ€§æ¯’æ€§é—®é¢˜ã€‚è¯¥é—®é¢˜åœ¨ç¤¾äº¤å¹³å°ä¸Šä¸ä»…ä»¥æ­£å¼å£°æ˜çš„å½¢å¼å‡ºç°ï¼Œè¿˜å¯èƒ½é€šè¿‡å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰å¼•å‘æœ‰æ¯’å¯¹è¯ã€‚å°½ç®¡åœ¨å•æ¨¡æ€æ–‡æœ¬æˆ–å›¾åƒçš„å®¡æŸ¥ä¸­å–å¾—äº†ä¸€å®šæˆåŠŸï¼Œä½†å¤šæ¨¡æ€å†…å®¹çš„æ¯’æ€§æ£€æµ‹ä»ç„¶æœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚ä¸ºå¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæœ¬æ–‡æ„å»ºäº†å¤šæ¨¡æ€éšæ€§æ¯’æ€§ï¼ˆMMITï¼‰çš„åˆ†ç±»æ³•ï¼Œå¹¶å¼•å…¥äº†åŒ…å«2100ä¸ªå¤šæ¨¡æ€è¯­å¥å’Œæç¤ºçš„MMITæ•°æ®é›†ã€‚æˆ‘ä»¬æå‡ºäº†ShieldVLMæ¨¡å‹ï¼Œé€šè¿‡æ·±æ€ç†Ÿè™‘çš„è·¨æ¨¡æ€æ¨ç†æ¥è¯†åˆ«å¤šæ¨¡æ€è¯­å¥ã€æç¤ºå’Œå¯¹è¯ä¸­çš„éšæ€§æ¯’æ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒShieldVLMåœ¨æ£€æµ‹éšæ€§å’Œæ˜¾æ€§æ¯’æ€§æ–¹é¢ä¼˜äºç°æœ‰å¼ºåŸºçº¿ã€‚è¯¥æ¨¡å‹å’Œæ•°æ®é›†å°†å…¬å¼€å‘å¸ƒï¼Œä»¥æ”¯æŒæœªæ¥çš„ç ”ç©¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€éšæ€§æ¯’æ€§æ£€æµ‹é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†å„æ¨¡æ€å•ç‹¬æ— å®³ä½†ç»„åˆåå¯èƒ½äº§ç”Ÿæ¯’æ€§çš„æƒ…å†µæ—¶å­˜åœ¨æ˜æ˜¾ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªèƒ½å¤Ÿè¿›è¡Œæ·±æ€ç†Ÿè™‘çš„è·¨æ¨¡æ€æ¨ç†çš„æ¨¡å‹ï¼Œä»¥è¯†åˆ«å¤šæ¨¡æ€å†…å®¹ä¸­çš„éšæ€§æ¯’æ€§ã€‚è¿™ç§è®¾è®¡èƒ½å¤Ÿæœ‰æ•ˆæ•æ‰æ¨¡æ€é—´çš„å¤æ‚å…³ç³»ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šShieldVLMçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€ç‰¹å¾æå–ã€è·¨æ¨¡æ€æ¨ç†æ¨¡å—å’Œæœ€ç»ˆçš„æ¯’æ€§åˆ¤åˆ«æ¨¡å—ã€‚æ¯ä¸ªæ¨¡å—ç›¸äº’åä½œï¼Œä»¥å®ç°é«˜æ•ˆçš„éšæ€§æ¯’æ€§æ£€æµ‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥äº†æ·±æ€ç†Ÿè™‘çš„æ¨ç†æœºåˆ¶ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨å¤šæ¨¡æ€å†…å®¹ä¸­è¯†åˆ«å‡ºéšæ€§æ¯’æ€§ï¼Œè¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„å•æ¨¡æ€æ£€æµ‹æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡å‹é‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡éšæ€§å’Œæ˜¾æ€§æ¯’æ€§çš„æ£€æµ‹ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†ä¼˜åŒ–ï¼Œä»¥å¢å¼ºè·¨æ¨¡æ€ç‰¹å¾çš„èåˆèƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒShieldVLMåœ¨éšæ€§æ¯’æ€§æ£€æµ‹ä¸Šç›¸è¾ƒäºç°æœ‰å¼ºåŸºçº¿æå‡äº†çº¦15%çš„å‡†ç¡®ç‡ï¼Œå¹¶åœ¨æ˜¾æ€§æ¯’æ€§æ£€æµ‹ä¸­ä¹Ÿè¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ã€‚è¿™è¡¨æ˜è¯¥æ¨¡å‹åœ¨å¤šæ¨¡æ€æ¯’æ€§æ£€æµ‹æ–¹é¢å…·æœ‰è¾ƒå¼ºçš„å®ç”¨æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾äº¤åª’ä½“å†…å®¹å®¡æ ¸ã€åœ¨çº¿ç¤¾åŒºç®¡ç†ä»¥åŠä»»ä½•éœ€è¦ç›‘æµ‹å¤šæ¨¡æ€å†…å®¹çš„åœºæ™¯ã€‚é€šè¿‡æœ‰æ•ˆæ£€æµ‹éšæ€§æ¯’æ€§ï¼Œèƒ½å¤Ÿå¸®åŠ©å¹³å°ç»´æŠ¤å¥åº·çš„äº¤æµç¯å¢ƒï¼Œå‡å°‘æœ‰å®³ä¿¡æ¯çš„ä¼ æ’­ï¼Œå…·æœ‰é‡è¦çš„ç¤¾ä¼šä»·å€¼å’Œå®é™…æ„ä¹‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Toxicity detection in multimodal text-image content faces growing challenges, especially with multimodal implicit toxicity, where each modality appears benign on its own but conveys hazard when combined. Multimodal implicit toxicity appears not only as formal statements in social platforms but also prompts that can lead to toxic dialogs from Large Vision-Language Models (LVLMs). Despite the success in unimodal text or image moderation, toxicity detection for multimodal content, particularly the multimodal implicit toxicity, remains underexplored. To fill this gap, we comprehensively build a taxonomy for multimodal implicit toxicity (MMIT) and introduce an MMIT-dataset, comprising 2,100 multimodal statements and prompts across 7 risk categories (31 sub-categories) and 5 typical cross-modal correlation modes. To advance the detection of multimodal implicit toxicity, we build ShieldVLM, a model which identifies implicit toxicity in multimodal statements, prompts and dialogs via deliberative cross-modal reasoning. Experiments show that ShieldVLM outperforms existing strong baselines in detecting both implicit and explicit toxicity. The model and dataset will be publicly available to support future researches. Warning: This paper contains potentially sensitive contents.

