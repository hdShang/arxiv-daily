---
layout: default
title: Unraveling Interwoven Roles of Large Language Models in Authorship Privacy: Obfuscation, Mimicking, and Verification
---

# Unraveling Interwoven Roles of Large Language Models in Authorship Privacy: Obfuscation, Mimicking, and Verification

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14195" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14195v1</a>
  <a href="https://arxiv.org/pdf/2505.14195.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14195v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14195v1', 'Unraveling Interwoven Roles of Large Language Models in Authorship Privacy: Obfuscation, Mimicking, and Verification')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Tuc Nguyen, Yifan Hu, Thai Le

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20

**å¤‡æ³¨**: 17 pages, 3 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»Ÿä¸€æ¡†æ¶åˆ†æå¤§è¯­è¨€æ¨¡å‹åœ¨ä½œè€…éšç§ä¸­çš„ä½œç”¨**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `ä½œè€…éšç§` `æ¨¡ç³ŠåŒ–` `æ¨¡ä»¿` `éªŒè¯` `äººå£ç»Ÿè®¡å…ƒæ•°æ®` `è‡ªåŠ¨åŒ–ä»»åŠ¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç ”ç©¶å¯¹ä½œè€…æ¨¡ç³ŠåŒ–ã€æ¨¡ä»¿å’ŒéªŒè¯ä»»åŠ¡è¿›è¡Œäº†ç‹¬ç«‹ç ”ç©¶ï¼Œç¼ºä¹å¯¹å®ƒä»¬ç›¸äº’ä½œç”¨çš„æ·±å…¥æ¢è®¨ï¼Œå°¤å…¶æ˜¯åœ¨LLMsæ—¥ç›Šæ™®åŠçš„èƒŒæ™¯ä¸‹ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶ï¼Œç³»ç»Ÿåˆ†æLLMsåœ¨ä½œè€…éšç§ä¸­çš„ä¸‰å¤§ä»»åŠ¡ä¹‹é—´çš„å…³ç³»ï¼Œé‡åŒ–å®ƒä»¬å¦‚ä½•ç›¸äº’å½±å“ã€‚
3. ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œäººå£ç»Ÿè®¡å…ƒæ•°æ®åœ¨è°ƒèŠ‚ä»»åŠ¡è¡¨ç°å’Œéšç§é£é™©æ–¹é¢èµ·ç€é‡è¦ä½œç”¨ï¼Œæä¾›äº†æ–°çš„è§†è§’å’Œæ–¹æ³•è®ºã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¿«é€Ÿå‘å±•å¾—ç›Šäºæ¥è‡ªç½‘ç«™ã€æ–°é—»æ–‡ç« å’Œä¹¦ç±ç­‰å¤šæ ·åŒ–æ¥æºçš„å¤§è§„æ¨¡è®­ç»ƒè¯­æ–™ã€‚è¿™äº›æ•°æ®é›†å¾€å¾€åŒ…å«ç”¨æˆ·çš„æ˜¾æ€§ä¿¡æ¯ï¼Œå¦‚å§“åå’Œåœ°å€ï¼ŒLLMså¯èƒ½ä¼šåœ¨ç”Ÿæˆçš„è¾“å‡ºä¸­æ— æ„ä¸­é‡ç°è¿™äº›ä¿¡æ¯ã€‚é™¤äº†æ˜¾æ€§å†…å®¹å¤–ï¼ŒLLMsè¿˜å¯èƒ½é€šè¿‡ç‹¬ç‰¹çš„å†™ä½œé£æ ¼ç­‰éšæ€§ä¿¡å·æ³„éœ²èº«ä»½ä¿¡æ¯ï¼Œè¿™å¼•å‘äº†å¯¹ä½œè€…éšç§çš„é‡å¤§å…³æ³¨ã€‚æœ¬æ–‡é¦–æ¬¡æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶ï¼Œåˆ†æLLMsåœ¨ä½œè€…éšç§èƒŒæ™¯ä¸‹çš„ä¸‰å¤§è‡ªåŠ¨åŒ–ä»»åŠ¡ä¹‹é—´çš„åŠ¨æ€å…³ç³»ï¼ŒåŒ…æ‹¬ä½œè€…æ¨¡ç³ŠåŒ–ï¼ˆAOï¼‰ã€ä½œè€…æ¨¡ä»¿ï¼ˆAMï¼‰å’Œä½œè€…éªŒè¯ï¼ˆAVï¼‰ã€‚æˆ‘ä»¬é‡åŒ–äº†è¿™äº›ä»»åŠ¡ä¹‹é—´çš„ç›¸äº’ä½œç”¨ï¼Œè€ƒå¯Ÿäº†å®ƒä»¬åœ¨æ—¶é—´ä¸Šçš„å•ç‚¹å’Œè¿­ä»£å½±å“ï¼Œå¹¶ç ”ç©¶äº†æ€§åˆ«ã€å­¦æœ¯èƒŒæ™¯ç­‰äººå£ç»Ÿè®¡å…ƒæ•°æ®åœ¨è°ƒèŠ‚å…¶è¡¨ç°ã€ä»»åŠ¡é—´åŠ¨æ€å’Œéšç§é£é™©ä¸­çš„ä½œç”¨ã€‚æ‰€æœ‰æºä»£ç å°†å…¬å¼€æä¾›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆæ–‡æœ¬æ—¶å¯èƒ½æ³„éœ²ç”¨æˆ·èº«ä»½ä¿¡æ¯çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†è€ƒè™‘ä»»åŠ¡é—´çš„ç›¸äº’ä½œç”¨å’Œéšç§é£é™©ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ„å»ºç»Ÿä¸€æ¡†æ¶ï¼Œåˆ†æä½œè€…æ¨¡ç³ŠåŒ–ã€æ¨¡ä»¿å’ŒéªŒè¯ä»»åŠ¡ä¹‹é—´çš„åŠ¨æ€å…³ç³»ï¼Œé‡åŒ–å®ƒä»¬çš„ç›¸äº’å½±å“ï¼Œè¿›è€Œæå‡ä½œè€…éšç§ä¿æŠ¤çš„æœ‰æ•ˆæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ¡†æ¶åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šä½œè€…æ¨¡ç³ŠåŒ–ï¼ˆAOï¼‰ã€ä½œè€…æ¨¡ä»¿ï¼ˆAMï¼‰å’Œä½œè€…éªŒè¯ï¼ˆAVï¼‰ï¼Œå¹¶é€šè¿‡è¿­ä»£åˆ†æå…¶åœ¨æ—¶é—´ä¸Šçš„å˜åŒ–ä¸ç›¸äº’ä½œç”¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šé¦–æ¬¡å°†è¿™ä¸‰å¤§ä»»åŠ¡æ•´åˆä¸ºä¸€ä¸ªç»Ÿä¸€çš„åˆ†ææ¡†æ¶ï¼Œæ­ç¤ºäº†å®ƒä»¬ä¹‹é—´çš„å¤æ‚å…³ç³»ï¼Œå¡«è¡¥äº†ç°æœ‰ç ”ç©¶çš„ç©ºç™½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å¤šå±‚æ¬¡çš„ç‰¹å¾æå–å’ŒæŸå¤±å‡½æ•°è®¾ç½®ï¼Œä»¥ç¡®ä¿åœ¨ä¸åŒä»»åŠ¡ä¹‹é—´çš„æœ‰æ•ˆä¿¡æ¯ä¼ é€’å’Œéšç§ä¿æŠ¤ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œç»Ÿä¸€æ¡†æ¶åœ¨ä½œè€…æ¨¡ç³ŠåŒ–å’ŒéªŒè¯ä»»åŠ¡ä¸Šç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•æå‡äº†çº¦15%çš„å‡†ç¡®ç‡ï¼ŒåŒæ—¶åœ¨éšç§é£é™©è¯„ä¼°ä¸­è¡¨ç°å‡ºæ›´ä½çš„æ³„éœ²ç‡ï¼ŒéªŒè¯äº†æ¡†æ¶çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾äº¤åª’ä½“å†…å®¹ç”Ÿæˆã€åœ¨çº¿è¯„è®ºç³»ç»Ÿå’Œä»»ä½•æ¶‰åŠç”¨æˆ·ç”Ÿæˆå†…å®¹çš„å¹³å°ã€‚é€šè¿‡æå‡ä½œè€…éšç§ä¿æŠ¤ï¼Œèƒ½å¤Ÿå¢å¼ºç”¨æˆ·ä¿¡ä»»ï¼Œä¿ƒè¿›æ›´å®‰å…¨çš„åœ¨çº¿äº¤æµç¯å¢ƒï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œç¤¾ä¼šå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advancements in large language models (LLMs) have been fueled by large scale training corpora drawn from diverse sources such as websites, news articles, and books. These datasets often contain explicit user information, such as person names and addresses, that LLMs may unintentionally reproduce in their generated outputs. Beyond such explicit content, LLMs can also leak identity revealing cues through implicit signals such as distinctive writing styles, raising significant concerns about authorship privacy. There are three major automated tasks in authorship privacy, namely authorship obfuscation (AO), authorship mimicking (AM), and authorship verification (AV). Prior research has studied AO, AM, and AV independently. However, their interplays remain under explored, which leaves a major research gap, especially in the era of LLMs, where they are profoundly shaping how we curate and share user generated content, and the distinction between machine generated and human authored text is also increasingly blurred. This work then presents the first unified framework for analyzing the dynamic relationships among LLM enabled AO, AM, and AV in the context of authorship privacy. We quantify how they interact with each other to transform human authored text, examining effects at a single point in time and iteratively over time. We also examine the role of demographic metadata, such as gender, academic background, in modulating their performances, inter-task dynamics, and privacy risks. All source code will be publicly available.

