---
layout: default
title: "Mind the Gap: Bridging Thought Leap for Improved Chain-of-Thought Tuning"
---

# Mind the Gap: Bridging Thought Leap for Improved Chain-of-Thought Tuning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14684" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14684v3</a>
  <a href="https://arxiv.org/pdf/2505.14684.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14684v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14684v3', 'Mind the Gap: Bridging Thought Leap for Improved Chain-of-Thought Tuning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Haolei Xu, Yuchen Yan, Yongliang Shen, Wenqi Zhang, Guiyang Hou, Shengpei Jiang, Kaitao Song, Weiming Lu, Jun Xiao, Yueting Zhuang

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20 (æ›´æ–°: 2025-11-27)

**å¤‡æ³¨**: Accepted to NeurIPS 2025. Camera ready version. Code: https://github.com/ZJU-REAL/Mind-the-Gap Project: https://zju-real.github.io/CoT-Bridge/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCoTæ€æƒ³è·ƒè¿æ¡¥æ¥ä»»åŠ¡ä»¥è§£å†³æ•°å­¦æ¨ç†ä¸­çš„ä¸­é—´æ­¥éª¤ç¼ºå¤±é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é“¾å¼æ¨ç†` `æ€æƒ³è·ƒè¿` `æ•°å­¦æ¨ç†` `æ¨¡å‹å¾®è°ƒ` `æ•°æ®é›†æ„å»º` `è‡ªåŠ¨æ¨ç†` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ•°å­¦CoTæ•°æ®é›†å› ä¸“å®¶çœç•¥ä¸­é—´æ­¥éª¤è€Œå¯¼è‡´æ€æƒ³è·ƒè¿ï¼Œå½±å“æ¨¡å‹çš„å­¦ä¹ æ•ˆæœå’Œæ³›åŒ–èƒ½åŠ›ã€‚
2. æœ¬æ–‡æå‡ºCoTæ€æƒ³è·ƒè¿æ¡¥æ¥ä»»åŠ¡ï¼Œè‡ªåŠ¨æ£€æµ‹å¹¶ç”Ÿæˆç¼ºå¤±çš„ä¸­é—´æ¨ç†æ­¥éª¤ï¼Œä»¥æ¢å¤æ¨ç†çš„å®Œæ•´æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŸºäºæ¡¥æ¥æ•°æ®é›†å¾®è°ƒçš„æ¨¡å‹åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼ŒNuminaMathçš„æå‡å¹…åº¦è¾¾åˆ°5.87%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ•°å­¦ä»»åŠ¡ä¸­é€šè¿‡é“¾å¼æ¨ç†ï¼ˆCoTï¼‰å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œç°æœ‰çš„æ•°å­¦CoTæ•°æ®é›†å¸¸å› ä¸“å®¶çœç•¥ä¸­é—´æ­¥éª¤è€Œå¯¼è‡´æ€æƒ³è·ƒè¿ï¼Œè¿™å¯¹æ¨¡å‹çš„å­¦ä¹ å’Œæ³›åŒ–äº§ç”Ÿè´Ÿé¢å½±å“ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†CoTæ€æƒ³è·ƒè¿æ¡¥æ¥ä»»åŠ¡ï¼Œæ—¨åœ¨è‡ªåŠ¨æ£€æµ‹è·ƒè¿å¹¶ç”Ÿæˆç¼ºå¤±çš„ä¸­é—´æ¨ç†æ­¥éª¤ï¼Œä»¥æ¢å¤CoTçš„å®Œæ•´æ€§å’Œè¿è´¯æ€§ã€‚æˆ‘ä»¬åŸºäºç»“æ„åŒ–çš„ScaleQuestMathæ•°æ®é›†æ„å»ºäº†ä¸“é—¨çš„è®­ç»ƒæ•°æ®é›†ScaleQM+ï¼Œå¹¶è®­ç»ƒäº†CoT-Bridgeä»¥æ¡¥æ¥æ€æƒ³è·ƒè¿ã€‚é€šè¿‡å¯¹æ•°å­¦æ¨ç†åŸºå‡†çš„å…¨é¢å®éªŒï¼Œæˆ‘ä»¬è¯æ˜äº†åœ¨æ¡¥æ¥æ•°æ®é›†ä¸Šå¾®è°ƒçš„æ¨¡å‹åœ¨æ€§èƒ½ä¸Šå§‹ç»ˆä¼˜äºåŸå§‹æ•°æ®é›†è®­ç»ƒçš„æ¨¡å‹ï¼ŒNuminaMathçš„æå‡å¹…åº¦é«˜è¾¾5.87%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰æ•°å­¦æ¨ç†æ¨¡å‹åœ¨è®­ç»ƒä¸­å› ä¸­é—´æ­¥éª¤ç¼ºå¤±è€Œå¯¼è‡´çš„æ€æƒ³è·ƒè¿é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨æ•°æ®é›†æ„å»ºæ—¶å¸¸å¸¸çœç•¥å…³é”®çš„æ¨ç†æ­¥éª¤ï¼Œå¯¼è‡´æ¨¡å‹å­¦ä¹ ä¸å®Œæ•´ï¼Œå½±å“å…¶æ³›åŒ–èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†CoTæ€æƒ³è·ƒè¿æ¡¥æ¥ä»»åŠ¡ï¼Œé€šè¿‡è‡ªåŠ¨æ£€æµ‹æ€æƒ³è·ƒè¿å¹¶ç”Ÿæˆç¼ºå¤±çš„æ¨ç†æ­¥éª¤ï¼Œæ¥æ¢å¤æ¨ç†è¿‡ç¨‹çš„å®Œæ•´æ€§å’Œè¿è´¯æ€§ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨æå‡æ¨¡å‹çš„å­¦ä¹ æ•ˆæœå’Œæ¨ç†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚é¦–å…ˆï¼Œæ„å»ºä¸“é—¨çš„ScaleQM+æ•°æ®é›†ï¼›å…¶æ¬¡ï¼Œè®­ç»ƒCoT-Bridgeæ¨¡å‹ä»¥æ¡¥æ¥æ€æƒ³è·ƒè¿ï¼›æœ€åï¼Œé€šè¿‡ç»¼åˆå®éªŒè¯„ä¼°æ¨¡å‹åœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†CoTæ€æƒ³è·ƒè¿æ¡¥æ¥ä»»åŠ¡ï¼Œå¹¶æ„å»ºäº†ä¸“é—¨çš„æ•°æ®é›†æ¥æ”¯æŒè¿™ä¸€ä»»åŠ¡ã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºï¼Œç°æœ‰æ–¹æ³•å¾€å¾€å¿½è§†ä¸­é—´æ­¥éª¤ï¼Œè€Œæœ¬ç ”ç©¶åˆ™å¼ºè°ƒå…¶é‡è¦æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–æ¨ç†æ­¥éª¤çš„ç”Ÿæˆè´¨é‡ï¼Œå¹¶è®¾è®¡äº†é€‚åº”æ€§å¼ºçš„ç½‘ç»œç»“æ„ï¼Œä»¥ä¾¿äºä¸ç°æœ‰ä¼˜åŒ–æŠ€æœ¯å…¼å®¹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŸºäºæ¡¥æ¥æ•°æ®é›†å¾®è°ƒçš„æ¨¡å‹åœ¨NuminaMathåŸºå‡†ä¸Šæå‡å¹…åº¦é«˜è¾¾5.87%ï¼Œåœ¨è’¸é¦æ•°æ®ä¸Šæå‡3.02%ï¼Œå¹¶ä¸ºå¼ºåŒ–å­¦ä¹ æä¾›äº†æ›´å¥½çš„èµ·å§‹ç‚¹ï¼Œæå‡å¹…åº¦ä¸º3.1%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œå¢å¼ºæ¨ç†å®Œæ•´æ€§èƒ½å¤Ÿå¸¦æ¥å¹¿æ³›çš„åº”ç”¨æ”¶ç›Šã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€è‡ªåŠ¨åŒ–æ¨ç†ç³»ç»Ÿå’Œæ™ºèƒ½é—®ç­”ç­‰ã€‚é€šè¿‡æå‡æ¨¡å‹çš„æ¨ç†å®Œæ•´æ€§ï¼Œèƒ½å¤Ÿåœ¨æ›´å¹¿æ³›çš„é€»è¾‘æ¨ç†ä»»åŠ¡ä¸­åº”ç”¨ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) have achieved remarkable progress on mathematical tasks through Chain-of-Thought (CoT) reasoning. However, existing mathematical CoT datasets often suffer from Thought Leaps due to experts omitting intermediate steps, which negatively impacts model learning and generalization. We propose the CoT Thought Leap Bridge Task, which aims to automatically detect leaps and generate missing intermediate reasoning steps to restore the completeness and coherence of CoT. To facilitate this, we constructed a specialized training dataset called ScaleQM+, based on the structured ScaleQuestMath dataset, and trained CoT-Bridge to bridge thought leaps. Through comprehensive experiments on mathematical reasoning benchmarks, we demonstrate that models fine-tuned on bridged datasets consistently outperform those trained on original datasets, with improvements of up to +5.87% on NuminaMath. Our approach effectively enhances distilled data (+3.02%) and provides better starting points for reinforcement learning (+3.1%), functioning as a plug-and-play module compatible with existing optimization techniques. Furthermore, CoT-Bridge demonstrate improved generalization to out-of-domain logical reasoning tasks, confirming that enhancing reasoning completeness yields broadly applicable benefits.

