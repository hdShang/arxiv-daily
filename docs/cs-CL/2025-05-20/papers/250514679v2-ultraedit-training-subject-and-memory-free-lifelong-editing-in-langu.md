---
layout: default
title: "UltraEdit: Training-, Subject-, and Memory-Free Lifelong Editing in Language Models"
---

# UltraEdit: Training-, Subject-, and Memory-Free Lifelong Editing in Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14679" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14679v2</a>
  <a href="https://arxiv.org/pdf/2505.14679.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14679v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14679v2', 'UltraEdit: Training-, Subject-, and Memory-Free Lifelong Editing in Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xiaojie Gu, Ziying Huang, Jia-Chen Gu, Kai Zhang

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20 (æ›´æ–°: 2025-09-26)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/XiaojieGu/UltraEdit)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºUltraEditä»¥è§£å†³å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„ç»ˆèº«ç¼–è¾‘é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç»ˆèº«å­¦ä¹ ` `æ¨¡å‹ç¼–è¾‘` `è¯­è¨€æ¨¡å‹` `é«˜æ•ˆè®¡ç®—` `æ•°æ®é›†æ„å»º` `è‡ªç„¶è¯­è¨€å¤„ç†` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ¨¡å‹ç¼–è¾‘æ–¹æ³•åœ¨å®é™…åº”ç”¨ä¸­éš¾ä»¥æ»¡è¶³å¤§è§„æ¨¡ç»ˆèº«é€‚åº”çš„éœ€æ±‚ï¼Œå°¤å…¶æ˜¯åœ¨æ•ˆç‡å’Œèµ„æºæ¶ˆè€—æ–¹é¢å­˜åœ¨æ˜æ˜¾ä¸è¶³ã€‚
2. UltraEdité€šè¿‡æ— è®­ç»ƒã€æ— ä¸»é¢˜å’Œæ— è®°å¿†çš„æ–¹å¼ï¼Œåˆ©ç”¨éšè—çŠ¶æ€å’Œæ¢¯åº¦ä¸€æ­¥è®¡ç®—å‚æ•°å˜åŒ–ï¼Œæä¾›äº†ä¸€ç§ç®€å•é«˜æ•ˆçš„ç»ˆèº«ç¼–è¾‘æ–¹æ¡ˆã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒUltraEditçš„ç¼–è¾‘é€Ÿåº¦æ¯”ä¹‹å‰çš„æœ€å…ˆè¿›æ–¹æ³•å¿«7å€ï¼Œä¸”æ˜¾å­˜ä½¿ç”¨é‡ä¸åˆ°å››åˆ†ä¹‹ä¸€ï¼Œæ”¯æŒé«˜è¾¾200ä¸‡æ¬¡ç¼–è¾‘ï¼Œå‡†ç¡®ç‡ä¿æŒé«˜æ°´å¹³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç»ˆèº«å­¦ä¹ ä½¿å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰èƒ½å¤Ÿé€šè¿‡ä¸æ–­æ›´æ–°å†…éƒ¨çŸ¥è¯†æ¥é€‚åº”ä¸æ–­å˜åŒ–çš„ä¿¡æ¯ã€‚ç†æƒ³çš„ç³»ç»Ÿåº”æ”¯æŒé«˜æ•ˆã€å¹¿æ³›çš„æ›´æ–°ï¼ŒåŒæ—¶ä¿æŒç°æœ‰èƒ½åŠ›å¹¶ç¡®ä¿å¯é éƒ¨ç½²ã€‚æ¨¡å‹ç¼–è¾‘ä½œä¸ºä¸€ç§æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆï¼Œæä¾›äº†ä¸€ç§é›†ä¸­ä¸”é«˜æ•ˆçš„æ–¹å¼æ¥ä¿®è®¢æ¨¡å‹çš„å†…éƒ¨çŸ¥è¯†ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºUltraEditï¼Œä¸€ç§æ— è®­ç»ƒã€æ— ä¸»é¢˜ã€æ— è®°å¿†çš„ç»ˆèº«ç¼–è¾‘æ–¹æ³•ï¼Œé€‚åˆè¶…å¤§è§„æ¨¡çš„å®é™…åº”ç”¨ã€‚UltraEdité€šè¿‡ä»…ä½¿ç”¨éšè—çŠ¶æ€åŠå…¶æ¢¯åº¦ä¸€æ­¥è®¡ç®—å‚æ•°å˜åŒ–ï¼Œæ˜¾è‘—æé«˜äº†æ•ˆç‡ã€‚è¯¥æ–¹æ³•åœ¨ç»ˆèº«è®¾ç½®ä¸­é‡‡ç”¨ç»ˆèº«å½’ä¸€åŒ–ç­–ç•¥ï¼ŒæŒç»­æ›´æ–°ç‰¹å¾ç»Ÿè®¡ï¼Œä»¥é€‚åº”åˆ†å¸ƒå˜åŒ–å¹¶ä¿æŒä¸€è‡´æ€§ã€‚UltraEditçš„ç¼–è¾‘é€Ÿåº¦æ¯”ä¹‹å‰çš„æœ€å…ˆè¿›æ–¹æ³•å¿«7å€ï¼ŒåŒæ—¶ä½¿ç”¨çš„æ˜¾å­˜ä¸åˆ°å››åˆ†ä¹‹ä¸€ï¼Œä½¿å…¶æˆä¸ºå”¯ä¸€èƒ½å¤Ÿåœ¨24GBæ¶ˆè´¹çº§GPUä¸Šç¼–è¾‘7B LLMçš„æ–¹æ³•ã€‚æˆ‘ä»¬æ„å»ºäº†UltraEditBenchï¼Œè¿™æ˜¯è¿„ä»Šä¸ºæ­¢è¯¥é¢†åŸŸæœ€å¤§çš„ç¼–è¾‘å¯¹æ•°æ®é›†ï¼Œæ”¯æŒé«˜è¾¾200ä¸‡æ¬¡ç¼–è¾‘ä¸”ä¿æŒé«˜å‡†ç¡®ç‡ã€‚ç»¼åˆå®éªŒè¡¨æ˜ï¼ŒUltraEditåœ¨å¤šç§æ¨¡å‹ç¼–è¾‘åœºæ™¯ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå‘å®‰å…¨å’Œå¯æ‰©å±•çš„ç»ˆèº«å­¦ä¹ è¿ˆå‡ºäº†é‡è¦ä¸€æ­¥ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰æ¨¡å‹ç¼–è¾‘æ–¹æ³•åœ¨å¤§è§„æ¨¡ç»ˆèº«å­¦ä¹ ä¸­çš„æ•ˆç‡å’Œèµ„æºæ¶ˆè€—é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•åœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶è¿›è¡Œé«˜æ•ˆçš„çŸ¥è¯†æ›´æ–°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šUltraEditçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ— è®­ç»ƒã€æ— ä¸»é¢˜å’Œæ— è®°å¿†çš„æ–¹å¼ï¼Œåˆ©ç”¨éšè—çŠ¶æ€å’Œæ¢¯åº¦ä¸€æ­¥è®¡ç®—å‚æ•°å˜åŒ–ï¼Œä»è€Œç®€åŒ–ç¼–è¾‘è¿‡ç¨‹ï¼Œæé«˜æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šUltraEditçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šå‚æ•°è®¡ç®—æ¨¡å—ã€ç»ˆèº«å½’ä¸€åŒ–æ¨¡å—å’Œç¼–è¾‘æ‰§è¡Œæ¨¡å—ã€‚å‚æ•°è®¡ç®—æ¨¡å—è´Ÿè´£æ ¹æ®éšè—çŠ¶æ€å’Œæ¢¯åº¦è®¡ç®—å‚æ•°å˜åŒ–ï¼Œç»ˆèº«å½’ä¸€åŒ–æ¨¡å—æŒç»­æ›´æ–°ç‰¹å¾ç»Ÿè®¡ï¼Œç¼–è¾‘æ‰§è¡Œæ¨¡å—åˆ™åº”ç”¨è¿™äº›å˜åŒ–è¿›è¡Œæ¨¡å‹ç¼–è¾‘ã€‚

**å…³é”®åˆ›æ–°**ï¼šUltraEditçš„å…³é”®åˆ›æ–°åœ¨äºå…¶æ— è®­ç»ƒã€æ— ä¸»é¢˜å’Œæ— è®°å¿†çš„è®¾è®¡ï¼Œä½¿å¾—æ¨¡å‹ç¼–è¾‘è¿‡ç¨‹æ›´åŠ é«˜æ•ˆä¸”é€‚åº”æ€§å¼ºã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿæ¨¡å‹ç¼–è¾‘æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºå…¶è®¡ç®—æ–¹å¼çš„ç®€åŒ–å’Œå¯¹èµ„æºçš„ä¼˜åŒ–ä½¿ç”¨ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼ŒUltraEdité‡‡ç”¨äº†åŠ¨æ€çš„ç‰¹å¾ç»Ÿè®¡æ›´æ–°æœºåˆ¶ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸Šæ³¨é‡ä¿æŒæ¨¡å‹çš„åŸæœ‰èƒ½åŠ›ï¼ŒåŒæ—¶å¼•å…¥äº†é«˜æ•ˆçš„æ¢¯åº¦è®¡ç®—æ–¹æ³•ï¼Œä»¥ç¡®ä¿ç¼–è¾‘è¿‡ç¨‹çš„å¿«é€Ÿæ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

UltraEditåœ¨å®éªŒä¸­è¡¨ç°å‡ºè‰²ï¼Œå…¶ç¼–è¾‘é€Ÿåº¦è¶…è¿‡äº†ä¹‹å‰çš„æœ€å…ˆè¿›æ–¹æ³•7å€ï¼Œä¸”æ˜¾å­˜ä½¿ç”¨é‡ä¸åˆ°å››åˆ†ä¹‹ä¸€ã€‚è¯¥æ–¹æ³•æ”¯æŒé«˜è¾¾200ä¸‡æ¬¡ç¼–è¾‘ï¼Œä¸”åœ¨å¤šç§æ¨¡å‹ç¼–è¾‘åœºæ™¯ä¸­ä¿æŒé«˜å‡†ç¡®ç‡ï¼Œå±•ç¤ºäº†å…¶åœ¨ç»ˆèº«å­¦ä¹ ä¸­çš„ä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

UltraEditçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼ŒåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€å¯¹è¯ç³»ç»Ÿå’Œæ™ºèƒ½åŠ©æ‰‹ç­‰ã€‚å…¶é«˜æ•ˆçš„ç»ˆèº«ç¼–è¾‘èƒ½åŠ›ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿå¿«é€Ÿé€‚åº”æ–°ä¿¡æ¯ï¼Œä¿æŒé«˜æ€§èƒ½ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Lifelong learning enables large language models (LLMs) to adapt to evolving information by continually updating their internal knowledge. An ideal system should support efficient, wide-ranging updates while preserving existing capabilities and ensuring reliable deployment. Model editing stands out as a promising solution for this goal, offering a focused and efficient way to revise a model's internal knowledge. Although recent paradigms have made notable progress, they often struggle to meet the demands of practical lifelong adaptation at scale. To bridge this gap, we propose UltraEdit, a training-, subject-, and memory-free approach that is well-suited for ultra-scalable, real-world lifelong model editing. UltraEdit fundamentally differs from traditional paradigms by computing parameter shifts in one step using only a hidden state and its gradient, making the approach simple yet efficient. To improve scalability in lifelong settings, UltraEdit employs a lifelong normalization strategy that continuously updates feature statistics across turns, allowing it to adapt to distributional shifts and maintain consistency over time. UltraEdit achieves editing speeds over 7x faster than the previous state-of-the-art method, which was also the fastest known approach, while using less than 1/4 the VRAM. This makes it the only method currently capable of editing a 7B LLM on a 24GB consumer-grade GPU. Furthermore, we construct UltraEditBench, the largest dataset in the field to date with over 2M editing pairs, and demonstrate that our method supports up to 2M edits while maintaining high accuracy. Comprehensive experiments on five datasets and six models show that UltraEdit consistently achieves superior performance across diverse model editing scenarios, taking a further step towards safe and scalable lifelong learning. Our code is available at: https://github.com/XiaojieGu/UltraEdit

