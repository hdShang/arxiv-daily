---
layout: default
title: Advancing Multi-Agent RAG Systems with Minimalist Reinforcement Learning
---

# Advancing Multi-Agent RAG Systems with Minimalist Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.17086" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.17086v3</a>
  <a href="https://arxiv.org/pdf/2505.17086.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.17086v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.17086v3', 'Advancing Multi-Agent RAG Systems with Minimalist Reinforcement Learning')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Yihong Wu, Liheng Ma, Muzhi Li, Jiaming Zhou, Lei Ding, Jianye Hao, Ho-fung Leung, Irwin King, Yingxue Zhang, Jian-Yun Nie

**ÂàÜÁ±ª**: cs.CL

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-20 (Êõ¥Êñ∞: 2025-11-24)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Mujica-MyGoÊ°ÜÊû∂‰ª•Ëß£ÂÜ≥Èïø‰∏ä‰∏ãÊñáÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öËΩÆ‰∫§‰∫í` `Ê£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàê` `Âº∫ÂåñÂ≠¶‰π†` `Èïø‰∏ä‰∏ãÊñá` `ÈóÆÁ≠îÁ≥ªÁªü` `Á≠ñÁï•‰ºòÂåñ` `‰ø°ÊÅØÊ£ÄÁ¥¢`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÂ§öËΩÆ‰∫§‰∫íÊñπÊ≥ïÂú®Â§ÑÁêÜÈïø‰∏ä‰∏ãÊñáÊó∂ÊïàÁéá‰Ωé‰∏ãÔºåÂØºËá¥‰ø°ÊÅØÂà©Áî®‰∏çÂÖÖÂàÜ„ÄÇ
2. ÊèêÂá∫Mujica-MyGoÊ°ÜÊû∂ÔºåÈÄöËøáÂàÜËß£Â§öËΩÆ‰∫§‰∫í‰∏∫Â≠ê‰∫§‰∫íÂíåÂºïÂÖ•ËΩªÈáèÁ∫ßÂº∫ÂåñÂ≠¶‰π†Êù•‰ºòÂåñÊé®ÁêÜËøáÁ®ã„ÄÇ
3. Âú®Â§öÁßçÈóÆÁ≠îÂü∫ÂáÜÊµãËØï‰∏≠ÔºåMujica-MyGoÁöÑÊÄßËÉΩÊòæËëó‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÁªìÂêàÁé∞‰ª£Ê£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºàRAGÔºâÁ≥ªÁªüÔºåÈÄöÂ∏∏ÈÄöËøáÂ§öËΩÆ‰∫§‰∫í‰∏éÊêúÁ¥¢ÂºïÊìéËøõË°åÂ§çÊùÇÊé®ÁêÜ„ÄÇÁÑ∂ËÄåÔºåÈöèÁùÄÊé¢Á¥¢Ê∑±Â∫¶ÁöÑÂ¢ûÂä†ÔºåÂ§öËΩÆ‰∫§‰∫í‰ºö‰∫ßÁîüÈïø‰∏ä‰∏ãÊñáÔºåÂØºËá¥LLMsÂú®ÊúâÊïàÂà©Áî®Èïø‰∏ä‰∏ãÊñá‰ø°ÊÅØÊñπÈù¢Èù¢‰∏¥ÊåëÊàò„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏ÄÈóÆÈ¢òÔºåÊú¨ÊñáÊèêÂá∫‰∫ÜMujica-MyGoÊ°ÜÊû∂ÔºåÊó®Âú®ÊèêÈ´òRAGÁ≥ªÁªü‰∏≠ÁöÑÂ§öËΩÆÊé®ÁêÜÊïàÁéá„ÄÇMujicaÈÄöËøáÂ∞ÜÂ§öËΩÆ‰∫§‰∫íÂàÜËß£‰∏∫Âêà‰ΩúÂ≠ê‰∫§‰∫íÊù•ÁºìËß£Èïø‰∏ä‰∏ãÊñáÈóÆÈ¢òÔºåËÄåMyGOÂàôÊòØ‰∏ÄÁßçËΩªÈáèÁ∫ßÂº∫ÂåñÂ≠¶‰π†ÁÆóÊ≥ïÔºåÊ∂àÈô§‰∫ÜÂØπ‰∏ä‰∏ãÊñáÂ≠¶‰π†ÁöÑ‰æùËµñ„ÄÇÂÆûÈ™åËØÅÊòéÔºåMujica-MyGoÂú®Â§öÁßçÈóÆÁ≠îÂü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞‰ºòÂºÇ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂú®Â§öËΩÆ‰∫§‰∫í‰∏≠Âõ†‰∏ä‰∏ãÊñáËøáÈïøËÄåÂØºËá¥ÁöÑ‰ø°ÊÅØÂà©Áî®ÊïàÁéá‰Ωé‰∏ãÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÁöÑRAGÁ≥ªÁªüÂú®Â§ÑÁêÜÂ§çÊùÇÊé®ÁêÜ‰ªªÂä°Êó∂ÔºåÈù¢‰∏¥ÁùÄ‰∏ä‰∏ãÊñáÈïøÂ∫¶ËøÖÈÄüÂ¢ûÈïøÁöÑÊåëÊàòÔºåÂ∞§ÂÖ∂ÊòØÂú®ÈúÄË¶ÅÂåÖÂê´Â∞ëÈáèÁ§∫‰æãÁöÑÊÉÖÂÜµ‰∏ã„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÊèêÂá∫MujicaÔºàÂ§öË∑≥ËÅîÂêàÊô∫ËÉΩÔºâÂíåMyGOÔºàÊûÅÁÆÄÁ≠ñÁï•Ê¢ØÂ∫¶‰ºòÂåñÔºâ‰∏§‰∏™Ê†∏ÂøÉÁªÑ‰ª∂„ÄÇMujicaÈÄöËøáÂ∞ÜÂ§öËΩÆ‰∫§‰∫íÂàÜËß£‰∏∫Â§ö‰∏™Âêà‰ΩúÁöÑÂ≠ê‰∫§‰∫íÔºåÈôç‰Ωé‰∫ÜÂØπÈïø‰∏ä‰∏ãÊñáÁöÑ‰æùËµñÔºåËÄåMyGOÂàôÈÄöËøáÂº∫ÂåñÂ≠¶‰π†‰ºòÂåñLLMsÁöÑÂêéÊúüËÆ≠ÁªÉÔºåÈÅøÂÖç‰∫ÜÂØπ‰∏ä‰∏ãÊñáÂ≠¶‰π†ÁöÑÈúÄÊ±Ç„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöMujica-MyGoÊ°ÜÊû∂ÂåÖÊã¨‰∏§‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöMujicaÊ®°ÂùóË¥üË¥£Â∞ÜÂ§çÊùÇÈóÆÈ¢òÂàÜËß£‰∏∫Â§ö‰∏™Â≠êÈóÆÈ¢òÂπ∂ËøõË°åÂçè‰ΩúÂ§ÑÁêÜÔºåMyGOÊ®°ÂùóÂàôË¥üË¥£ÈÄöËøáÂº∫ÂåñÂ≠¶‰π†‰ºòÂåñÊ®°ÂûãÁ≠ñÁï•„ÄÇÊï¥‰ΩìÊµÅÁ®ãÊòØÂÖàÈÄöËøáMujicaËøõË°åÈóÆÈ¢òÂàÜËß£ÔºåÂÜçÈÄöËøáMyGOËøõË°åÁ≠ñÁï•‰ºòÂåñ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöMujica-MyGoÁöÑÊúÄÂ§ßÂàõÊñ∞Âú®‰∫éÂ∞ÜÂ§öËΩÆ‰∫§‰∫íÁöÑÂ§çÊùÇÊÄßÈÄöËøáÂàÜËß£ÂíåÂêà‰ΩúÁöÑÊñπÂºèËøõË°åÁÆÄÂåñÔºåÂêåÊó∂ÂºïÂÖ•‰∫ÜËΩªÈáèÁ∫ßÁöÑÂº∫ÂåñÂ≠¶‰π†ÁÆóÊ≥ïMyGOÔºåÊòæËëóÊèêÈ´ò‰∫ÜÊ®°ÂûãÁöÑÊé®ÁêÜÊïàÁéá„ÄÇ‰∏é‰º†ÁªüÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•Ê°ÜÊû∂Âú®Â§ÑÁêÜÈïø‰∏ä‰∏ãÊñáÊó∂Ë°®Áé∞Âá∫Êõ¥È´òÁöÑÁÅµÊ¥ªÊÄßÂíåÊïàÁéá„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®MyGO‰∏≠ÔºåËÆæËÆ°‰∫ÜÁâπÂÆöÁöÑÊçüÂ§±ÂáΩÊï∞‰ª•Á°Æ‰øùÁ≠ñÁï•ÁöÑÊî∂ÊïõÊÄßÔºåÂπ∂ÈÄöËøáÁêÜËÆ∫ËØÅÊòé‰∫ÜÂÖ∂Êî∂ÊïõÂà∞ÊúÄ‰ºòÁ≠ñÁï•ÁöÑËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåMujicaÊ®°ÂùóÁöÑÂêà‰ΩúÊú∫Âà∂‰πüÁªèËøáÁ≤æÂøÉËÆæËÆ°Ôºå‰ª•Á°Æ‰øùÂêÑ‰∏™Â≠ê‰∫§‰∫í‰πãÈó¥ÁöÑ‰ø°ÊÅØÂÖ±‰∫´ÂíåÂçèÂêåÂ∑•‰Ωú„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®Â§öÁßçÈóÆÁ≠îÂü∫ÂáÜÊµãËØï‰∏≠ÔºåMujica-MyGoÊ°ÜÊû∂ÁöÑÊÄßËÉΩÊòæËëóÊèêÂçáÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§ÑÁêÜÈïø‰∏ä‰∏ãÊñáÊó∂ÔºåÁõ∏ËæÉ‰∫é‰º†ÁªüRAGÁ≥ªÁªüÔºåÊÄßËÉΩÊèêÂçáÂπÖÂ∫¶ËææÂà∞20%‰ª•‰∏äÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®Â§çÊùÇÊé®ÁêÜ‰ªªÂä°‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Êô∫ËÉΩÈóÆÁ≠îÁ≥ªÁªü„ÄÅÂØπËØùÁ≥ªÁªüÂíå‰ø°ÊÅØÊ£ÄÁ¥¢Á≠â„ÄÇÈÄöËøáÊèêÈ´òÂ§öËΩÆ‰∫§‰∫íÁöÑÊïàÁéáÔºåMujica-MyGoÊ°ÜÊû∂ËÉΩÂ§üÂú®Â§çÊùÇÁöÑÊé®ÁêÜ‰ªªÂä°‰∏≠Êèê‰æõÊõ¥ÂáÜÁ°ÆÂíåÂø´ÈÄüÁöÑÂìçÂ∫îÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Large Language Models (LLMs) equipped with modern Retrieval-Augmented Generation (RAG) systems often employ multi-turn interaction pipelines to interface with search engines for complex reasoning tasks. However, such multi-turn interactions inevitably produce long intermediate contexts, as context length grows exponentially with exploration depth. This leads to a well-known limitation of LLMs: their difficulty in effectively leveraging information from long contexts. This problem is further amplified in RAG systems that depend on in-context learning, where few-shot demonstrations must also be included in the prompt, compounding the context-length bottleneck. To address these challenges, we propose Mujica-MyGo, a unified framework for efficient multi-turn reasoning in RAG. Inspired by the divide-and-conquer principle, we introduce Mujica (Multi-hop Joint Intelligence for Complex Question Answering), a multi-agent RAG workflow that decomposes multi-turn interactions into cooperative sub-interactions, thereby mitigating long-context issues. To eliminate the dependency on in-context learning, we further develop MyGO (Minimalist Policy Gradient Optimization), a lightweight and efficient reinforcement learning algorithm that enables effective post-training of LLMs within complex RAG pipelines. We provide theoretical guarantees for MyGO's convergence to the optimal policy. Empirical evaluations across diverse question-answering benchmarks, covering both text corpora and knowledge graphs, show that Mujica-MyGO achieves superior performance.

