---
layout: default
title: EEG-to-Text Translation: A Model for Deciphering Human Brain Activity
---

# EEG-to-Text Translation: A Model for Deciphering Human Brain Activity

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.13936" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.13936v2</a>
  <a href="https://arxiv.org/pdf/2505.13936.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.13936v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.13936v2', 'EEG-to-Text Translation: A Model for Deciphering Human Brain Activity')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Saydul Akbar Murad, Ashim Dahal, Nick Rahimi

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20 (æ›´æ–°: 2025-12-08)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Mmurrad/EEG-To-text)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºR1 Translatorä»¥æå‡è„‘ç”µå›¾åˆ°æ–‡æœ¬ç¿»è¯‘æ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è„‘ç”µå›¾è§£ç ` `æ–‡æœ¬ç”Ÿæˆ` `åŒå‘LSTM` `å˜æ¢å™¨æ¨¡å‹` `æœºå™¨å­¦ä¹ ` `äººæœºäº¤äº’` `è„‘æœºæ¥å£`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰EEGåˆ°æ–‡æœ¬è§£ç æ¨¡å‹åœ¨æ€§èƒ½ä¸Šå­˜åœ¨æ˜¾è‘—é™åˆ¶ï¼Œéš¾ä»¥æ»¡è¶³å®é™…åº”ç”¨éœ€æ±‚ã€‚
2. æœ¬æ–‡æå‡ºçš„R1 Translatoræ¨¡å‹ç»“åˆäº†åŒå‘LSTMç¼–ç å™¨å’Œé¢„è®­ç»ƒçš„å˜æ¢å™¨è§£ç å™¨ï¼Œä»¥æé«˜è§£ç è´¨é‡ã€‚
3. R1 Translatoråœ¨ROUGEã€CERå’ŒWERç­‰æŒ‡æ ‡ä¸Šå‡ä¼˜äºT5å’ŒBrain Translatorï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹å¦‚Geminiå’ŒGPTçš„å¿«é€Ÿå‘å±•ï¼Œè¿æ¥äººè„‘ä¸è¯­è¨€å¤„ç†çš„ç ”ç©¶å˜å¾—æ„ˆå‘é‡è¦ã€‚ä¸ºäº†è§£å†³è„‘ç”µå›¾ï¼ˆEEGï¼‰ä¿¡å·è§£ç ä¸ºæ–‡æœ¬çš„æŒ‘æˆ˜ï¼Œç ”ç©¶è€…ä»¬æå‡ºäº†å¤šç§æ¨¡å‹ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹åœ¨æ€§èƒ½ä¸Šä»å­˜åœ¨æ˜¾è‘—é™åˆ¶ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°æ¨¡å‹R1 Translatorï¼Œæ—¨åœ¨æ”¹å–„EEGåˆ°æ–‡æœ¬è§£ç çš„æ€§èƒ½ã€‚R1 Translatorç»“åˆäº†åŒå‘LSTMç¼–ç å™¨å’Œé¢„è®­ç»ƒçš„åŸºäºå˜æ¢å™¨çš„è§£ç å™¨ï¼Œåˆ©ç”¨EEGç‰¹å¾ç”Ÿæˆé«˜è´¨é‡æ–‡æœ¬è¾“å‡ºã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒR1åœ¨ROUGEæŒ‡æ ‡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†T5å’ŒBrain Translatorï¼Œå…·ä½“ROUGE-1å¾—åˆ†ä¸º38.00%ï¼Œæ¯”T5é«˜å‡º9%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è„‘ç”µå›¾ï¼ˆEEGï¼‰ä¿¡å·è§£ç ä¸ºæ–‡æœ¬çš„æ€§èƒ½ä¸è¶³é—®é¢˜ã€‚ç°æœ‰æ¨¡å‹åœ¨è§£ç ç²¾åº¦å’Œæ–‡æœ¬è´¨é‡ä¸Šå­˜åœ¨æ˜¾è‘—çŸ­æ¿ï¼Œé™åˆ¶äº†å…¶å®é™…åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šR1 Translatoræ¨¡å‹é€šè¿‡ç»“åˆåŒå‘LSTMå’Œé¢„è®­ç»ƒçš„å˜æ¢å™¨ï¼Œæ—¨åœ¨æ›´å¥½åœ°æ•æ‰EEGä¿¡å·çš„æ—¶åºç‰¹å¾ï¼Œä»è€Œæå‡æ–‡æœ¬ç”Ÿæˆçš„è´¨é‡å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¨¡å‹çš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œä½¿ç”¨åŒå‘LSTMç¼–ç å™¨å¤„ç†EEGåµŒå…¥ï¼Œä»¥æ•æ‰ä¿¡å·çš„æ—¶åºä¾èµ–ï¼›å…¶æ¬¡ï¼Œå°†LSTMçš„è¾“å‡ºä¼ é€’ç»™å˜æ¢å™¨è§£ç å™¨ï¼Œè¿›è¡Œæ–‡æœ¬ç”Ÿæˆã€‚

**å…³é”®åˆ›æ–°**ï¼šR1 Translatorçš„ä¸»è¦åˆ›æ–°åœ¨äºå°†åŒå‘LSTMä¸å˜æ¢å™¨è§£ç å™¨ç›¸ç»“åˆï¼Œåˆ©ç”¨LSTMæ•æ‰æ—¶åºä¿¡æ¯ï¼Œæ˜¾è‘—æå‡äº†æ–‡æœ¬ç”Ÿæˆçš„è´¨é‡ï¼ŒåŒºåˆ«äºä»¥å¾€å•ä¸€æ¨¡å‹çš„è®¾è®¡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–æ–‡æœ¬ç”Ÿæˆæ•ˆæœï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šï¼ŒLSTMå’Œå˜æ¢å™¨çš„ç»“åˆä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å¤„ç†EEGä¿¡å·ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

R1 Translatoråœ¨å¤šä¸ªæ€§èƒ½æŒ‡æ ‡ä¸Šå‡è¡¨ç°ä¼˜å¼‚ï¼ŒROUGE-1å¾—åˆ†è¾¾åˆ°38.00%ï¼Œæ¯”T5é«˜å‡º9%ï¼›åœ¨ROUGE-Lä¸Šï¼ŒF1å¾—åˆ†ä¸º32.51%ï¼Œè¶…è¶ŠT5å’ŒBrain Translatorï¼›CERå’ŒWERåˆ†åˆ«ä¸º0.5795å’Œ0.7280ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è„‘æœºæ¥å£ã€åŒ»ç–—è¯Šæ–­å’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æé«˜EEGä¿¡å·è§£ç çš„å‡†ç¡®æ€§ï¼ŒR1 Translatorèƒ½å¤Ÿä¸ºè„‘ç”µå›¾åˆ†ææä¾›æ›´ä¸ºå¯é çš„å·¥å…·ï¼Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„å‘å±•ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> With the rapid advancement of large language models like Gemini, GPT, and others, bridging the gap between the human brain and language processing has become an important area of focus. To address this challenge, researchers have developed various models to decode EEG signals into text. However, these models still face significant performance limitations. To overcome these shortcomings, we propose a new model, R1 Translator, which aims to improve the performance of EEG-to-text decoding. The R1 Translator model combines a bidirectional LSTM encoder with a pretrained transformer-based decoder, utilizing EEG features to produce high-quality text outputs. The model processes EEG embeddings through the LSTM to capture sequential dependencies, which are then fed into the transformer decoder for effective text generation. The R1 Translator excels in ROUGE metrics, outperforming both T5 (previous research) and Brain Translator. Specifically, R1 achieves a ROUGE-1 score of 38.00% (P), which is up to 9% higher than T5 (34.89%) and 3% better than Brain (35.69%). It also leads in ROUGE-L, with a F1 score of 32.51%, outperforming T5 by 3% (29.67%) and Brain by 2% (30.38%). In terms of CER, R1 achieves a CER of 0.5795, which is 2% lower than T5 (0.5917) and 4% lower than Brain (0.6001). Additionally, R1 performs better in WER with a score of 0.7280, outperforming T5 by 4.3% (0.7610) and Brain by 3.6% (0.7553). Code is available at https://github.com/Mmurrad/EEG-To-text.

