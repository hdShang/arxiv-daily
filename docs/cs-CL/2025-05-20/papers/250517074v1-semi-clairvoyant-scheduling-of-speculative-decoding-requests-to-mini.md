---
layout: default
title: Semi-Clairvoyant Scheduling of Speculative Decoding Requests to Minimize LLM Inference Latency
---

# Semi-Clairvoyant Scheduling of Speculative Decoding Requests to Minimize LLM Inference Latency

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.17074" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.17074v1</a>
  <a href="https://arxiv.org/pdf/2505.17074.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.17074v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.17074v1', 'Semi-Clairvoyant Scheduling of Speculative Decoding Requests to Minimize LLM Inference Latency')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Ruixiao Li, Fahao Chen, Peng Li

**ÂàÜÁ±ª**: cs.CL, cs.AI, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-20

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫LAPS-SD‰ª•Ëß£ÂÜ≥LLMÊé®ÁêÜÂª∂ËøüÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `Êé®ÁêÜÂª∂Ëøü` `ËØ∑Ê±ÇË∞ÉÂ∫¶` `Âä®ÊÄÅ‰ºòÂÖàÁ∫ßÈòüÂàó` `ÂçäÈ¢ÑÁü•ÁÆóÊ≥ï` `‰ª§ÁâåÊé•ÂèóÁéá` `ÂÆûÈ™åÁªìÊûú`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÊé®ÁêÜËØ∑Ê±ÇË∞ÉÂ∫¶ÊñπÊ≥ï‰∏ªË¶Å‰æùËµñ‰∫éÈ¢ÑÊµãËæìÂá∫ÈïøÂ∫¶Êù•‰º∞ËÆ°ÊâßË°åÊó∂Èó¥ÔºåÂØºËá¥Âú®Âä®ÊÄÅÁéØÂ¢É‰∏ãË∞ÉÂ∫¶ÊïàÁéá‰Ωé‰∏ã„ÄÇ
2. LAPS-SDÁÆóÊ≥ïÈÄöËøáÂä®ÊÄÅÁª¥Êä§Â§ö‰∏™‰ºòÂÖàÁ∫ßÈòüÂàóÂíåËØ∑Ê±ÇÊâßË°åÊä¢Âç†ÔºåËÉΩÂ§üÊ†πÊçÆËØ∑Ê±ÇÁâπÂæÅËá™ÈÄÇÂ∫îË∞ÉÂ∫¶Ôºå‰ªéËÄåÈôç‰ΩéÊé®ÁêÜÂª∂Ëøü„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåLAPS-SDÂú®Êé®ÁêÜÂª∂ËøüÊñπÈù¢Áõ∏ÊØî‰∫éÊúÄÂÖàËøõÁöÑË∞ÉÂ∫¶ÊñπÊ≥ïÊúâÊòæËëóÊèêÂçáÔºåÂáèÂ∞ë‰∫ÜÁ∫¶39%ÁöÑÂª∂Ëøü„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËÆ∫ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫Least-Attained/Perceived-Service for Speculative DecodingÔºàLAPS-SDÔºâÁöÑÂçäÈ¢ÑÁü•ËØ∑Ê±ÇË∞ÉÂ∫¶ÁÆóÊ≥ïÔºåÊó®Âú®ÈÄöËøáÂä®ÊÄÅË∞ÉÂ∫¶Êé®ÁêÜËØ∑Ê±ÇÊù•Èôç‰ΩéÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑÊé®ÁêÜÂª∂Ëøü„ÄÇÁé∞ÊúâÊñπÊ≥ï‰ªÖÂü∫‰∫éÈ¢ÑÊµãÁöÑËæìÂá∫ÈïøÂ∫¶Êù•‰º∞ËÆ°ÊâßË°åÊó∂Èó¥ÔºåÂØºËá¥Ë∞ÉÂ∫¶ÊïàÁéá‰Ωé‰∏ã„ÄÇLAPS-SDÈÄöËøáÁª¥Êä§Â§ö‰∏™‰ºòÂÖàÁ∫ßÈòüÂàóÂπ∂ÂÖÅËÆ∏Ë∑®ÈòüÂàóÁöÑËØ∑Ê±ÇÊâßË°åÊä¢Âç†ÔºåËÉΩÂ§üÂú®Âä®ÊÄÅÁöÑ‰ª§ÁâåÊé•ÂèóÁéá‰∏ãÊúâÊïàË∞ÉÂ∫¶ËØ∑Ê±Ç„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåLAPS-SDÁõ∏ÊØî‰∫éÁé∞ÊúâÁöÑË∞ÉÂ∫¶ÊñπÊ≥ïÔºåÊé®ÁêÜÂª∂ËøüÂáèÂ∞ë‰∫ÜÁ∫¶39%„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáË¶ÅËß£ÂÜ≥ÁöÑÈóÆÈ¢òÊòØÂ¶Ç‰ΩïÂú®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÊé®ÁêÜ‰∏≠ÊúâÊïàË∞ÉÂ∫¶ËØ∑Ê±ÇÔºå‰ª•Â∫îÂØπÊé®ÁêÜÊó∂Èó¥ÁöÑ‰∏çÁ°ÆÂÆöÊÄß„ÄÇÁé∞ÊúâÊñπÊ≥ï‰ªÖ‰æùËµñ‰∫éËæìÂá∫ÈïøÂ∫¶Êù•‰º∞ËÆ°ÊâßË°åÊó∂Èó¥ÔºåÊó†Ê≥ïÂáÜÁ°ÆÂèçÊò†ÂÆûÈôÖÊÉÖÂÜµ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöLAPS-SDÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÁª¥Êä§Â§ö‰∏™‰ºòÂÖàÁ∫ßÈòüÂàóÂíåÂÖÅËÆ∏ËØ∑Ê±ÇÊä¢Âç†ÔºåÂä®ÊÄÅÈÄÇÂ∫îËØ∑Ê±ÇÁâπÂæÅÔºå‰ªéËÄåÂú®Êé®ÁêÜËøáÁ®ã‰∏≠ÊúâÊïàÈôç‰ΩéÂª∂Ëøü„ÄÇËøôÊ†∑ÁöÑËÆæËÆ°‰ΩøÂæóÁÆóÊ≥ïËÉΩÂ§üÂú®‰ª§ÁâåÊé•ÂèóÁéáÂä®ÊÄÅÂèòÂåñÊó∂‰ªçÁÑ∂‰øùÊåÅÈ´òÊïàË∞ÉÂ∫¶„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöLAPS-SDÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨Â§ö‰∏™‰ºòÂÖàÁ∫ßÈòüÂàó„ÄÅËØ∑Ê±ÇË∞ÉÂ∫¶Ê®°ÂùóÂíå‰ª§ÁâåÈ™åËØÅÊ®°Âùó„ÄÇËØ∑Ê±ÇÊ†πÊçÆÁâπÂæÅË¢´ÂàÜÈÖçÂà∞‰∏çÂêåÁöÑÈòüÂàó‰∏≠ÔºåË∞ÉÂ∫¶Ê®°ÂùóÊ†πÊçÆÂΩìÂâçÁöÑ‰ª§ÁâåÊé•ÂèóÁéáÂä®ÊÄÅË∞ÉÊï¥ËØ∑Ê±ÇÁöÑÊâßË°åÈ°∫Â∫è„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöLAPS-SDÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂ÂçäÈ¢ÑÁü•Ë∞ÉÂ∫¶Á≠ñÁï•ÔºåËÉΩÂ§üÂú®‰ª§ÁâåÊé•ÂèóÁéá‰∏çÁ®≥ÂÆöÊó∂ËøõË°åÊúâÊïàÁöÑËØ∑Ê±ÇË∞ÉÂ∫¶ÔºåÊòæËëóÊèêÈ´ò‰∫ÜÊé®ÁêÜÊïàÁéá„ÄÇËøô‰∏é‰º†ÁªüÊñπÊ≥ïÁöÑÈùôÊÄÅË∞ÉÂ∫¶ÂΩ¢Êàê‰∫ÜÈ≤úÊòéÂØπÊØî„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°‰∏≠ÔºåLAPS-SDÈááÁî®‰∫ÜÂä®ÊÄÅ‰ºòÂÖàÁ∫ßÈòüÂàóÂíåËØ∑Ê±ÇÊä¢Âç†Êú∫Âà∂ÔºåÁ°Æ‰øùÂú®‰ª§ÁâåÊé•ÂèóÁéáÁ®≥ÂÆöÂêéËÉΩÂ§üÂáÜÁ°Æ‰º∞ËÆ°ÊâßË°åÊó∂Èó¥„ÄÇÊ≠§Â§ñÔºåÁÆóÊ≥ïÁöÑÂèÇÊï∞ËÆæÁΩÆÂíåÈòüÂàóÁÆ°ÁêÜÁ≠ñÁï•‰πüÁªèËøáÁ≤æÂøÉËÆæËÆ°Ôºå‰ª•‰ºòÂåñÊï¥‰ΩìÊÄßËÉΩ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåLAPS-SDÁõ∏ÊØî‰∫éÊúÄÂÖàËøõÁöÑË∞ÉÂ∫¶ÊñπÊ≥ïÔºåÊé®ÁêÜÂª∂ËøüÂáèÂ∞ë‰∫ÜÁ∫¶39%„ÄÇËøô‰∏ÄÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÂ±ïÁ§∫‰∫ÜLAPS-SDÂú®Âä®ÊÄÅË∞ÉÂ∫¶ÁéØÂ¢É‰∏≠ÁöÑÊúâÊïàÊÄßÔºåÈ™åËØÅ‰∫ÜÂÖ∂Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÊΩúÂäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ„ÄÅÂØπËØùÁ≥ªÁªüÂíåÂÆûÊó∂ÊñáÊú¨ÁîüÊàêÁ≠âÂú∫ÊôØ„ÄÇÈÄöËøáÈôç‰ΩéÊé®ÁêÜÂª∂ËøüÔºåLAPS-SDËÉΩÂ§üÊèêÂçáÁî®Êà∑‰ΩìÈ™åÔºåÂ∞§ÂÖ∂ÊòØÂú®ÈúÄË¶ÅÂø´ÈÄüÂìçÂ∫îÁöÑÂ∫îÁî®‰∏≠ÔºåÂÖ∑ÊúâÊòæËëóÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÂΩ±ÂìçÂäõ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Speculative decoding accelerates Large Language Model (LLM) inference by employing a small speculative model (SSM) to generate multiple candidate tokens and verify them using the LLM in parallel. This technique has been widely integrated into LLM inference serving systems. However, inference requests typically exhibit uncertain execution time, which poses a significant challenge of efficiently scheduling requests in these systems. Existing work estimates execution time based solely on predicted output length, which could be inaccurate because execution time depends on both output length and token acceptance rate of verification by the LLM. In this paper, we propose a semi-clairvoyant request scheduling algorithm called Least-Attained/Perceived-Service for Speculative Decoding (LAPS-SD). Given a number of inference requests, LAPS-SD can effectively minimize average inference latency by adaptively scheduling requests according to their features during decoding. When the token acceptance rate is dynamic and execution time is difficult to estimate, LAPS-SD maintains multiple priority queues and allows request execution preemption across different queues. Once the token acceptance rate becomes stable, LAPS-SD can accurately estimate the execution time and schedule requests accordingly. Extensive experiments show that LAPS-SD reduces inference latency by approximately 39\% compared to state-of-the-art scheduling methods.

