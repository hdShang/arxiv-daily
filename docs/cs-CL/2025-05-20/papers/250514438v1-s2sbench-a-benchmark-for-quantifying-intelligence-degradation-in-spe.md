---
layout: default
title: "S2SBench: A Benchmark for Quantifying Intelligence Degradation in Speech-to-Speech Large Language Models"
---

# S2SBench: A Benchmark for Quantifying Intelligence Degradation in Speech-to-Speech Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14438" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14438v1</a>
  <a href="https://arxiv.org/pdf/2505.14438.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14438v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14438v1', 'S2SBench: A Benchmark for Quantifying Intelligence Degradation in Speech-to-Speech Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuanbo Fang, Haoze Sun, Jun Liu, Tao Zhang, Zenan Zhou, Weipeng Chen, Xiaofen Xing, Xiangmin Xu

**åˆ†ç±»**: cs.SD, cs.CL, eess.AS

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/undobug/S2SBench)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºS2SBenchä»¥é‡åŒ–è¯­éŸ³åˆ°è¯­éŸ³å¤§è¯­è¨€æ¨¡å‹çš„æ™ºèƒ½é€€åŒ–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯­éŸ³åˆ°è¯­éŸ³æ¨¡å‹` `æ™ºèƒ½é€€åŒ–` `æ€§èƒ½è¯„ä¼°` `å¤§è¯­è¨€æ¨¡å‹` `åŸºå‡†æµ‹è¯•`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¯­éŸ³åˆ°è¯­éŸ³å¤§è¯­è¨€æ¨¡å‹åœ¨å¤„ç†éŸ³é¢‘è¾“å…¥æ—¶ï¼Œæ¨ç†å’Œç”Ÿæˆæ€§èƒ½æ™®éä½äºæ–‡æœ¬è¾“å…¥ï¼Œå¯¼è‡´æ™ºèƒ½é€€åŒ–ç°è±¡ã€‚
2. æœ¬æ–‡æå‡ºS2SBenchåŸºå‡†ï¼Œé€šè¿‡è¯Šæ–­æ•°æ®é›†å’Œæˆå¯¹è¯„ä¼°åè®®ï¼Œç³»ç»Ÿæ€§åœ°é‡åŒ–è¯­éŸ³LLMsçš„æ€§èƒ½é€€åŒ–ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒS2SBenchèƒ½å¤Ÿæœ‰æ•ˆåˆ†ææ¨¡å‹è®­ç»ƒè¿‡ç¨‹ï¼ŒéªŒè¯äº†å…¶åœ¨è¯„ä¼°æ™ºèƒ½é€€åŒ–æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç«¯åˆ°ç«¯çš„è¯­éŸ³å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ‰©å±•äº†æ–‡æœ¬æ¨¡å‹çš„èƒ½åŠ›ï¼Œèƒ½å¤Ÿç›´æ¥å¤„ç†å’Œç”ŸæˆéŸ³é¢‘æ ‡è®°ã€‚ç„¶è€Œï¼Œä¸æ–‡æœ¬è¾“å…¥ç›¸æ¯”ï¼Œè¿™é€šå¸¸å¯¼è‡´æ¨ç†å’Œç”Ÿæˆæ€§èƒ½çš„ä¸‹é™ï¼Œç§°ä¸ºæ™ºèƒ½é€€åŒ–ã€‚ä¸ºç³»ç»Ÿè¯„ä¼°è¿™ä¸€å·®è·ï¼Œæœ¬æ–‡æå‡ºäº†S2SBenchï¼Œä¸€ä¸ªæ—¨åœ¨é‡åŒ–è¯­éŸ³LLMsæ€§èƒ½é€€åŒ–çš„åŸºå‡†ã€‚è¯¥åŸºå‡†åŒ…æ‹¬é’ˆå¯¹éŸ³é¢‘è¾“å…¥çš„å¥å­å»¶ç»­å’Œå¸¸è¯†æ¨ç†çš„è¯Šæ–­æ•°æ®é›†ï¼Œå¹¶å¼•å…¥äº†ä¸€ç§åŸºäºå¯è¡Œå’Œä¸å¯è¡Œæ ·æœ¬ä¹‹é—´å›°æƒ‘åº¦å·®å¼‚çš„æˆå¯¹è¯„ä¼°åè®®ï¼Œä»¥è¡¡é‡ç›¸å¯¹äºæ–‡æœ¬è¾“å…¥çš„é€€åŒ–ã€‚æˆ‘ä»¬å°†S2SBenchåº”ç”¨äºåˆ†æBaichuan-Audioçš„è®­ç»ƒè¿‡ç¨‹ï¼Œè¿›ä¸€æ­¥éªŒè¯äº†åŸºå‡†çš„æœ‰æ•ˆæ€§ã€‚æ‰€æœ‰æ•°æ®é›†å’Œè¯„ä¼°ä»£ç å¯åœ¨https://github.com/undobug/S2SBenchè·å–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è¯­éŸ³åˆ°è¯­éŸ³å¤§è¯­è¨€æ¨¡å‹åœ¨éŸ³é¢‘è¾“å…¥ä¸‹æ¨ç†å’Œç”Ÿæˆæ€§èƒ½ä¸‹é™çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½ç³»ç»Ÿè¯„ä¼°è¿™ä¸€æ™ºèƒ½é€€åŒ–ç°è±¡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ„å»ºS2SBenchåŸºå‡†ï¼Œç»“åˆè¯Šæ–­æ•°æ®é›†å’Œæˆå¯¹è¯„ä¼°åè®®ï¼Œé‡åŒ–è¯­éŸ³LLMsçš„æ€§èƒ½é€€åŒ–ï¼Œæä¾›ä¸€ä¸ªç³»ç»ŸåŒ–çš„è¯„ä¼°æ¡†æ¶ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šS2SBenchåŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼Œé¦–å…ˆæ˜¯é’ˆå¯¹éŸ³é¢‘è¾“å…¥çš„å¥å­å»¶ç»­å’Œå¸¸è¯†æ¨ç†çš„è¯Šæ–­æ•°æ®é›†ï¼Œå…¶æ¬¡æ˜¯åŸºäºå›°æƒ‘åº¦å·®å¼‚çš„æˆå¯¹è¯„ä¼°åè®®ï¼Œæœ€åæ˜¯åº”ç”¨äºæ¨¡å‹è®­ç»ƒè¿‡ç¨‹çš„åˆ†æå·¥å…·ã€‚

**å…³é”®åˆ›æ–°**ï¼šS2SBenchçš„æœ€å¤§åˆ›æ–°åœ¨äºå…¶æˆå¯¹è¯„ä¼°åè®®ï¼Œé€šè¿‡æ¯”è¾ƒå¯è¡Œå’Œä¸å¯è¡Œæ ·æœ¬çš„å›°æƒ‘åº¦å·®å¼‚ï¼Œæä¾›äº†ä¸€ç§æ–°çš„é‡åŒ–æ™ºèƒ½é€€åŒ–çš„æ–¹æ³•ï¼Œä¸ä¼ ç»Ÿè¯„ä¼°æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œæ•°æ®é›†çš„æ„å»ºè€ƒè™‘äº†å¤šæ ·æ€§å’Œä»£è¡¨æ€§ï¼Œè¯„ä¼°åè®®åˆ™é€šè¿‡ç²¾ç¡®çš„å›°æƒ‘åº¦è®¡ç®—æ¥ç¡®ä¿è¯„ä¼°çš„å‡†ç¡®æ€§ï¼Œå…·ä½“å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡å°šæœªè¯¦ç»†æŠ«éœ²ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒS2SBenchèƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«å’Œé‡åŒ–è¯­éŸ³LLMsçš„æ™ºèƒ½é€€åŒ–ï¼Œç‰¹åˆ«æ˜¯åœ¨å¥å­å»¶ç»­å’Œå¸¸è¯†æ¨ç†ä»»åŠ¡ä¸­ï¼Œç›¸è¾ƒäºæ–‡æœ¬è¾“å…¥ï¼Œæ€§èƒ½ä¸‹é™å¹…åº¦æ˜¾è‘—ã€‚å…·ä½“æ•°æ®è¡¨æ˜ï¼Œæ¨¡å‹åœ¨éŸ³é¢‘è¾“å…¥ä¸‹çš„æ¨ç†å‡†ç¡®ç‡é™ä½äº†çº¦20%ï¼ŒéªŒè¯äº†åŸºå‡†çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½è¯­éŸ³åŠ©æ‰‹ã€è‡ªåŠ¨ç¿»è¯‘ç³»ç»Ÿå’Œè¯­éŸ³è¯†åˆ«æŠ€æœ¯ç­‰ã€‚é€šè¿‡é‡åŒ–æ™ºèƒ½é€€åŒ–ï¼Œå¼€å‘è€…å¯ä»¥æ›´å¥½åœ°ç†è§£å’Œä¼˜åŒ–è¯­éŸ³åˆ°è¯­éŸ³æ¨¡å‹çš„æ€§èƒ½ï¼Œä»è€Œæå‡ç”¨æˆ·ä½“éªŒå’Œç³»ç»Ÿçš„æ™ºèƒ½æ°´å¹³ã€‚æœªæ¥ï¼Œè¯¥åŸºå‡†å¯èƒ½æ¨åŠ¨æ›´é«˜æ•ˆçš„æ¨¡å‹è®¾è®¡å’Œè®­ç»ƒç­–ç•¥çš„åˆ¶å®šã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> End-to-end speech large language models ((LLMs)) extend the capabilities of text-based models to directly process and generate audio tokens. However, this often leads to a decline in reasoning and generation performance compared to text input, a phenomenon referred to as intelligence degradation. To systematically evaluate this gap, we propose S2SBench, a benchmark designed to quantify performance degradation in Speech LLMs. It includes diagnostic datasets targeting sentence continuation and commonsense reasoning under audio input. We further introduce a pairwise evaluation protocol based on perplexity differences between plausible and implausible samples to measure degradation relative to text input. We apply S2SBench to analyze the training process of Baichuan-Audio, which further demonstrates the benchmark's effectiveness. All datasets and evaluation code are available at https://github.com/undobug/S2SBench.

