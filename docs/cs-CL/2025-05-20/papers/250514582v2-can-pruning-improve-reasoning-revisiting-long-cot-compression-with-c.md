---
layout: default
title: Can Pruning Improve Reasoning? Revisiting Long-CoT Compression with Capability in Mind for Better Reasoning
---

# Can Pruning Improve Reasoning? Revisiting Long-CoT Compression with Capability in Mind for Better Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14582" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14582v2</a>
  <a href="https://arxiv.org/pdf/2505.14582.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14582v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14582v2', 'Can Pruning Improve Reasoning? Revisiting Long-CoT Compression with Capability in Mind for Better Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shangziqi Zhao, Jiahao Yuan, Guisong Yang, Usman Naseem

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20 (æ›´æ–°: 2025-08-26)

**å¤‡æ³¨**: 19 pages,6 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPrune-on-Logicæ¡†æ¶ä»¥æå‡é•¿é“¾æ€ç»´æ¨ç†æ•ˆæœ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é•¿é“¾æ€ç»´` `æ¨ç†ä¼˜åŒ–` `æ¨¡å‹è’¸é¦` `é€»è¾‘å›¾` `è‡ªæˆ‘éªŒè¯` `é€‰æ‹©æ€§ä¿®å‰ª` `å°å‹è¯­è¨€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. é•¿é“¾æ€ç»´æ¨ç†çš„å†—é•¿é£æ ¼ä½¿å¾—å…¶åœ¨è’¸é¦åˆ°å°å‹è¯­è¨€æ¨¡å‹æ—¶æ•ˆæœä¸ä½³ï¼Œå½±å“äº†æ¨¡å‹çš„å®é™…åº”ç”¨ã€‚
2. æå‡ºPrune-on-Logicæ¡†æ¶ï¼Œé€šè¿‡å°†é•¿é“¾æ€ç»´è½¬åŒ–ä¸ºé€»è¾‘å›¾ï¼Œé€‰æ‹©æ€§ä¿®å‰ªä½æ•ˆæ¨ç†æ­¥éª¤ä»¥ä¼˜åŒ–æ¨ç†æ•ˆæœã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒéªŒè¯ä¿®å‰ªæ˜¾è‘—æé«˜äº†æ¨¡å‹çš„å‡†ç¡®æ€§ï¼Œå¹¶åœ¨å¤šä¸ªä»»åŠ¡å’Œæ¨¡å‹è§„æ¨¡ä¸Šä¿æŒä¸€è‡´çš„æ€§èƒ½æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é•¿é“¾æ€ç»´ï¼ˆLong-CoTï¼‰æ¨ç†æé«˜äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å‡†ç¡®æ€§ï¼Œä½†å…¶å†—é•¿çš„è‡ªæˆ‘åæ€é£æ ¼å¸¸å¸¸å¦¨ç¢æœ‰æ•ˆè’¸é¦åˆ°å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰ã€‚æœ¬æ–‡é€šè¿‡èƒ½åŠ›å¯¹é½çš„è§†è§’é‡æ–°å®¡è§†Long-CoTå‹ç¼©ï¼Œæå‡ºPrune-on-Logicæ¡†æ¶ï¼Œå°†Long-CoTè½¬åŒ–ä¸ºé€»è¾‘å›¾ï¼Œå¹¶åœ¨è‡ªæˆ‘éªŒè¯çº¦æŸä¸‹é€‰æ‹©æ€§åœ°ä¿®å‰ªä½æ•ˆæ¨ç†æ­¥éª¤ã€‚ç ”ç©¶è¡¨æ˜ï¼ŒéªŒè¯ä¿®å‰ªèƒ½æŒç»­æé«˜å‡†ç¡®æ€§å¹¶å‡å°‘ä»¤ç‰Œä½¿ç”¨ï¼Œè€Œæ¨ç†æˆ–æ— å·®åˆ«ä¿®å‰ªåˆ™ä¼šé™ä½æ€§èƒ½ã€‚æœ‰æ•ˆçš„ä¿®å‰ªç­–ç•¥èƒ½å¤Ÿå°†ç›‘ç£ä¸æ¨¡å‹èƒ½åŠ›å¯¹é½ï¼Œå°¤å…¶åœ¨æ›´å¤§æ¨¡å‹ä¸­è¡¨ç°æ›´ä½³ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³é•¿é“¾æ€ç»´æ¨ç†åœ¨è’¸é¦è¿‡ç¨‹ä¸­ç”±äºå†—é•¿å’Œä½æ•ˆæ­¥éª¤å¯¼è‡´çš„æ€§èƒ½ä¸‹é™é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆå¤„ç†æ¨ç†æ­¥éª¤çš„é€‰æ‹©æ€§ä¿®å‰ªï¼Œå½±å“äº†å°å‹è¯­è¨€æ¨¡å‹çš„è¡¨ç°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºPrune-on-Logicæ¡†æ¶ï¼Œé€šè¿‡å°†é•¿é“¾æ€ç»´è½¬åŒ–ä¸ºé€»è¾‘å›¾ï¼Œåˆ©ç”¨è‡ªæˆ‘éªŒè¯çº¦æŸé€‰æ‹©æ€§ä¿®å‰ªä½æ•ˆæ¨ç†æ­¥éª¤ï¼Œä»è€Œæå‡æ¨ç†çš„æœ‰æ•ˆæ€§å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé€»è¾‘å›¾æ„å»ºã€ä½æ•ˆæ­¥éª¤è¯†åˆ«å’ŒéªŒè¯ä¿®å‰ªã€‚é¦–å…ˆï¼Œå°†é•¿é“¾æ€ç»´è½¬åŒ–ä¸ºé€»è¾‘å›¾ï¼Œç„¶åè¯†åˆ«å‡ºä½æ•ˆæ¨ç†æ­¥éª¤ï¼Œæœ€ååœ¨éªŒè¯çº¦æŸä¸‹è¿›è¡Œä¿®å‰ªã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºé€šè¿‡é€»è¾‘å›¾çš„ç»“æ„åŒ–è¡¨ç¤ºå’Œè‡ªæˆ‘éªŒè¯æœºåˆ¶ï¼Œå®ç°äº†å¯¹æ¨ç†æ­¥éª¤çš„æœ‰æ•ˆé€‰æ‹©æ€§ä¿®å‰ªï¼Œä¸ä¼ ç»Ÿçš„æ— å·®åˆ«ä¿®å‰ªæ–¹æ³•å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†é’ˆå¯¹æ•´ä¸ªé“¾ã€æ ¸å¿ƒæ¨ç†å’ŒéªŒè¯çš„ä¸‰ç§ä¿®å‰ªç­–ç•¥ï¼ŒéªŒè¯ä¿®å‰ªè¢«è¯æ˜æ˜¯æœ€æœ‰æ•ˆçš„ï¼Œèƒ½å¤Ÿåœ¨å‡å°‘ä»¤ç‰Œä½¿ç”¨çš„åŒæ—¶æé«˜å‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒéªŒè¯ä¿®å‰ªç­–ç•¥åœ¨å¤šä¸ªä»»åŠ¡ä¸Šæ˜¾è‘—æé«˜äº†æ¨¡å‹çš„å‡†ç¡®æ€§ï¼Œå‡å°‘ä»¤ç‰Œä½¿ç”¨ï¼Œä¸”åœ¨è¾ƒå¤§æ¨¡å‹ä¸­æ•ˆæœæ›´ä¸ºæ˜¾è‘—ï¼Œæå‡å¹…åº¦å¯è¾¾XX%ï¼ˆå…·ä½“æ•°æ®éœ€æ ¹æ®å®éªŒç»“æœå¡«å†™ï¼‰ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æ™ºèƒ½é—®ç­”ç³»ç»Ÿå’Œå¯¹è¯ç”Ÿæˆç­‰ã€‚é€šè¿‡ä¼˜åŒ–æ¨ç†è¿‡ç¨‹ï¼ŒPrune-on-Logicæ¡†æ¶èƒ½å¤Ÿæå‡å°å‹è¯­è¨€æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„è¡¨ç°ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Long chain-of-thought (Long-CoT) reasoning improves accuracy in LLMs, yet its verbose, self-reflective style often hinders effective distillation into small language models (SLMs). We revisit Long-CoT compression through the lens of capability alignment and ask: Can pruning improve reasoning? We propose Prune-on-Logic, a structure-aware framework that transforms Long-CoT into logic graphs and selectively prunes low-utility reasoning steps under self-verification constraints. Through systematic analysis across three pruning strategies - targeting entire chains, core reasoning, and verification - we find that verification pruning consistently improves accuracy while reducing token usage, whereas reasoning or indiscriminate pruning degrades performance. Our study reveals that effective pruning aligns supervision with model capacity rather than merely shortening inputs. Gains hold across tasks, model scales, and CoT capability, with larger models benefiting more from pruning due to richer but more redundant reasoning. Our empirical findings highlight pruning as a structural optimization strategy for aligning CoT reasoning with SLM capacity.

