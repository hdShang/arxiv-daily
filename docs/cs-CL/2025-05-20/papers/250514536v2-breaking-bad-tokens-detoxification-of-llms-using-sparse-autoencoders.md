---
layout: default
title: Breaking Bad Tokens: Detoxification of LLMs Using Sparse Autoencoders
---

# Breaking Bad Tokens: Detoxification of LLMs Using Sparse Autoencoders

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14536" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14536v2</a>
  <a href="https://arxiv.org/pdf/2505.14536.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14536v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14536v2', 'Breaking Bad Tokens: Detoxification of LLMs Using Sparse Autoencoders')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Agam Goyal, Vedant Rathi, William Yeh, Yian Wang, Yuen Chen, Hari Sundaram

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20 (æ›´æ–°: 2025-10-23)

**å¤‡æ³¨**: EMNLP 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ©ç”¨ç¨€ç–è‡ªç¼–ç å™¨å®ç°å¤§å‹è¯­è¨€æ¨¡å‹çš„å»æ¯’åŒ–**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å»æ¯’åŒ–` `ç¨€ç–è‡ªç¼–ç å™¨` `æ¿€æ´»å¼•å¯¼` `å› æœå¹²é¢„` `å®‰å…¨æ€§` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å»æ¯’åŒ–æ–¹æ³•å¤šä¸ºè¡¨é¢ä¿®å¤ï¼Œå®¹æ˜“è¢«è¶Šç‹±æ”»å‡»è§„é¿ï¼Œæ— æ³•æœ‰æ•ˆè§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„æœ‰æ¯’è¾“å‡ºé—®é¢˜ã€‚
2. æœ¬æ–‡æå‡ºåˆ©ç”¨ç¨€ç–è‡ªç¼–ç å™¨è¯†åˆ«æ¯’æ€§ç›¸å…³æ–¹å‘ï¼Œé€šè¿‡æœ‰é’ˆå¯¹æ€§çš„æ¿€æ´»å¼•å¯¼è¿›è¡Œå»æ¯’åŒ–ï¼Œå¢å¼ºäº†å¹²é¢„çš„æœ‰æ•ˆæ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨è¾ƒå¼ºçš„å¼•å¯¼å¼ºåº¦ä¸‹ï¼Œæ¯’æ€§å‡å°‘å¯è¾¾20%ï¼ŒåŒæ—¶ä¿æŒäº†æ¨¡å‹çš„çŸ¥è¯†å’Œèƒ½åŠ›ï¼Œå°½ç®¡æµç•…æ€§å¯èƒ½æœ‰æ‰€ä¸‹é™ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç”¨æˆ·åº”ç”¨ä¸­å¹¿æ³›ä½¿ç”¨ï¼Œä½†ä»ä¼šç”Ÿæˆä¸è‰¯çš„æœ‰æ¯’è¾“å‡ºï¼Œå¦‚ç²—ä¿—è¯­è¨€å’Œè´¬æŸæ€§è¨€è®ºã€‚å°½ç®¡å­˜åœ¨å¤šç§å»æ¯’åŒ–æ–¹æ³•ï¼Œä½†å¤§å¤šæ•°ä»…è¿›è¡Œè¡¨é¢ä¿®å¤ï¼Œå®¹æ˜“è¢«è¶Šç‹±æ”»å‡»è§„é¿ã€‚æœ¬æ–‡åˆ©ç”¨ç¨€ç–è‡ªç¼–ç å™¨ï¼ˆSAEsï¼‰è¯†åˆ«æ¨¡å‹æ®‹å·®æµä¸­çš„æ¯’æ€§ç›¸å…³æ–¹å‘ï¼Œå¹¶é€šè¿‡ç›¸åº”çš„è§£ç å™¨å‘é‡è¿›è¡Œæœ‰é’ˆå¯¹æ€§çš„æ¿€æ´»å¼•å¯¼ã€‚æˆ‘ä»¬å¼•å…¥ä¸‰ç§å¼•å¯¼å¼ºåº¦ï¼Œå¹¶åœ¨GPT-2 Smallå’ŒGemma-2-2Bä¸Šè¿›è¡Œè¯„ä¼°ï¼Œæ­ç¤ºäº†æ¯’æ€§å‡å°‘ä¸è¯­è¨€æµç•…æ€§ä¹‹é—´çš„æƒè¡¡ã€‚åœ¨è¾ƒå¼ºçš„å¼•å¯¼å¼ºåº¦ä¸‹ï¼Œè¿™äº›å› æœå¹²é¢„åœ¨å‡å°‘æ¯’æ€§æ–¹é¢ä¼˜äºç«äº‰åŸºçº¿ï¼Œæœ€é«˜å¯å‡å°‘20%çš„æ¯’æ€§ï¼Œå°½ç®¡åœ¨GPT-2 Smallä¸Šæµç•…æ€§å¯èƒ½ä¼šæ˜¾è‘—ä¸‹é™ã€‚é‡è¦çš„æ˜¯ï¼Œå¼•å¯¼åçš„æ ‡å‡†NLPåŸºå‡†åˆ†æ•°ä¿æŒç¨³å®šï¼Œè¡¨æ˜æ¨¡å‹çš„çŸ¥è¯†å’Œä¸€èˆ¬èƒ½åŠ›å¾—ä»¥ä¿ç•™ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥è¡¨æ˜ï¼Œè¾ƒå®½çš„SAEsä¸­çš„ç‰¹å¾åˆ†ç¦»ä¼šå¦¨ç¢å®‰å…¨å¹²é¢„ï¼Œå¼ºè°ƒäº†åˆ†ç¦»ç‰¹å¾å­¦ä¹ çš„é‡è¦æ€§ã€‚æˆ‘ä»¬çš„å‘ç°çªæ˜¾äº†åŸºäºSAEçš„å› æœå¹²é¢„åœ¨LLMå»æ¯’åŒ–ä¸­çš„æ½œåŠ›å’Œå½“å‰å±€é™æ€§ï¼Œå¹¶ä¸ºæ›´å®‰å…¨çš„è¯­è¨€æ¨¡å‹éƒ¨ç½²æä¾›äº†å®é™…æŒ‡å¯¼ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„æœ‰æ¯’è¾“å‡ºé—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å¤šä¸ºè¡¨é¢ä¿®å¤ï¼Œå®¹æ˜“è¢«è§„é¿ï¼Œç¼ºä¹æœ‰æ•ˆæ€§å’Œé’ˆå¯¹æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡ç¨€ç–è‡ªç¼–ç å™¨ï¼ˆSAEsï¼‰è¯†åˆ«æ¨¡å‹æ®‹å·®æµä¸­çš„æ¯’æ€§æ–¹å‘ï¼Œè¿›è¡Œæœ‰é’ˆå¯¹æ€§çš„æ¿€æ´»å¼•å¯¼ï¼Œä»¥å®ç°æ›´æœ‰æ•ˆçš„å»æ¯’åŒ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ç¨€ç–è‡ªç¼–ç å™¨çš„è®­ç»ƒã€æ¯’æ€§æ–¹å‘çš„è¯†åˆ«ã€æ¿€æ´»å¼•å¯¼çš„å®æ–½ä»¥åŠæ•ˆæœè¯„ä¼°ï¼Œä¸»è¦æ¨¡å—åŒ…æ‹¬ç¼–ç å™¨ã€è§£ç å™¨å’Œæ¿€æ´»å¼•å¯¼æœºåˆ¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šå¼•å…¥äº†ä¸‰ç§ä¸åŒå¼ºåº¦çš„å¼•å¯¼ç­–ç•¥ï¼Œèƒ½å¤Ÿåœ¨å‡å°‘æ¯’æ€§çš„åŒæ—¶ä¿æŒè¯­è¨€æµç•…æ€§ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰çš„å»æ¯’åŒ–åŸºçº¿æ–¹æ³•ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ¯’æ€§è¯†åˆ«ï¼Œè°ƒæ•´äº†è§£ç å™¨çš„å‚æ•°è®¾ç½®ï¼Œä»¥å®ç°æœ€ä½³çš„æ¿€æ´»å¼•å¯¼æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨è¾ƒå¼ºçš„æ¿€æ´»å¼•å¯¼ä¸‹ï¼Œæ¯’æ€§å‡å°‘å¯è¾¾20%ï¼ŒåŒæ—¶åœ¨GPT-2 Smallä¸Šä¿æŒäº†æ ‡å‡†NLPåŸºå‡†åˆ†æ•°çš„ç¨³å®šï¼Œè¡¨æ˜æ¨¡å‹çš„çŸ¥è¯†å’Œèƒ½åŠ›æœªå—æŸã€‚æµç•…æ€§åœ¨ä¸åŒå¼•å¯¼å¼ºåº¦ä¸‹æœ‰æ‰€å˜åŒ–ï¼Œå¼ºè°ƒäº†æƒè¡¡çš„é‡è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨ç¤¾äº¤åª’ä½“ã€åœ¨çº¿å®¢æœå’Œå†…å®¹ç”Ÿæˆç­‰é¢†åŸŸï¼Œèƒ½å¤Ÿæœ‰æ•ˆå‡å°‘æœ‰æ¯’å†…å®¹çš„ç”Ÿæˆï¼Œæé«˜ç”¨æˆ·ä½“éªŒå’Œå®‰å…¨æ€§ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½æ¨åŠ¨æ›´å®‰å…¨çš„è¯­è¨€æ¨¡å‹éƒ¨ç½²ï¼Œä¿ƒè¿›äººæœºäº¤äº’çš„å¥åº·å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) are now ubiquitous in user-facing applications, yet they still generate undesirable toxic outputs, including profanity, vulgarity, and derogatory remarks. Although numerous detoxification methods exist, most apply broad, surface-level fixes and can therefore easily be circumvented by jailbreak attacks. In this paper we leverage sparse autoencoders (SAEs) to identify toxicity-related directions in the residual stream of models and perform targeted activation steering using the corresponding decoder vectors. We introduce three tiers of steering aggressiveness and evaluate them on GPT-2 Small and Gemma-2-2B, revealing trade-offs between toxicity reduction and language fluency. At stronger steering strengths, these causal interventions surpass competitive baselines in reducing toxicity by up to 20%, though fluency can degrade noticeably on GPT-2 Small depending on the aggressiveness. Crucially, standard NLP benchmark scores upon steering remain stable, indicating that the model's knowledge and general abilities are preserved. We further show that feature-splitting in wider SAEs hampers safety interventions, underscoring the importance of disentangled feature learning. Our findings highlight both the promise and the current limitations of SAE-based causal interventions for LLM detoxification, further suggesting practical guidelines for safer language-model deployment.

