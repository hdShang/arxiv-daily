---
layout: default
title: Truth or Twist? Optimal Model Selection for Reliable Label Flipping Evaluation in LLM-based Counterfactuals
---

# Truth or Twist? Optimal Model Selection for Reliable Label Flipping Evaluation in LLM-based Counterfactuals

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.13972" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.13972v3</a>
  <a href="https://arxiv.org/pdf/2505.13972.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.13972v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.13972v3', 'Truth or Twist? Optimal Model Selection for Reliable Label Flipping Evaluation in LLM-based Counterfactuals')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Qianli Wang, Van Bach Nguyen, Nils Feldhus, Luis Felipe Villa-Arenas, Christin Seifert, Sebastian MÃ¶ller, Vera Schmitt

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20 (æ›´æ–°: 2025-08-27)

**å¤‡æ³¨**: Accepted at INLG 2025, camera-ready version

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¼˜åŒ–æ¨¡å‹é€‰æ‹©æ–¹æ³•ä»¥æé«˜LLMåäº‹å®è¯„ä¼°çš„å¯é æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åäº‹å®ç”Ÿæˆ` `æ ‡ç­¾ç¿»è½¬` `æ¨¡å‹é€‰æ‹©` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ•°æ®å¢å¼º` `è¯„ä¼°æ–¹æ³•`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨è¯„ä¼°åäº‹å®ç”Ÿæˆçš„æœ‰æ•ˆæ€§æ—¶ï¼Œåˆ¤åˆ«æ¨¡å‹çš„é€‰æ‹©å¯¼è‡´ç»“æœä¸ä¸€è‡´ï¼Œå½±å“äº†æ¨¡å‹çš„æ€§èƒ½å’Œé²æ£’æ€§ã€‚
2. æœ¬æ–‡æå‡ºé€šè¿‡å®šä¹‰ç”Ÿæˆå™¨ä¸åˆ¤åˆ«æ¨¡å‹ä¹‹é—´çš„å…³ç³»ï¼Œæ¢ç´¢æœ€ä¼˜åˆ¤åˆ«æ¨¡å‹é€‰æ‹©ï¼Œä»¥æé«˜æ ‡ç­¾ç¿»è½¬è¯„ä¼°çš„å¯é æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œç‹¬ç«‹ä¸”æœªå¾®è°ƒçš„åˆ¤åˆ«æ¨¡å‹åœ¨è¯„ä¼°æ ‡ç­¾ç¿»è½¬æ—¶è¡¨ç°æœ€ä½³ï¼Œä½†ä¸ç”¨æˆ·ç ”ç©¶ç»“æœä¹‹é—´ä»å­˜åœ¨è¾ƒå¤§å·®è·ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åäº‹å®ç¤ºä¾‹è¢«å¹¿æ³›ç”¨äºé€šè¿‡åäº‹å®æ•°æ®å¢å¼ºï¼ˆCDAï¼‰æå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ€§èƒ½å’Œé²æ£’æ€§ã€‚ç„¶è€Œï¼Œç”¨äºè¯„ä¼°æ ‡ç­¾ç¿»è½¬çš„åˆ¤åˆ«æ¨¡å‹é€‰æ‹©å¯¼è‡´ç»“æœä¸ä¸€è‡´ã€‚æœ¬æ–‡å®šä¹‰äº†ç”Ÿæˆå™¨ä¸åˆ¤åˆ«æ¨¡å‹ä¹‹é—´çš„å››ç§å…³ç³»ï¼Œå¹¶é€šè¿‡å¤§é‡å®éªŒè¡¨æ˜ï¼Œç‹¬ç«‹ä¸”æœªå¾®è°ƒçš„åˆ¤åˆ«æ¨¡å‹æä¾›äº†æœ€å¯é çš„æ ‡ç­¾ç¿»è½¬è¯„ä¼°ã€‚å°½ç®¡å¦‚æ­¤ï¼Œæœ€æœ‰æ•ˆåˆ¤åˆ«æ¨¡å‹ä¸ç”¨æˆ·ç ”ç©¶ç»“æœä¹‹é—´ä»å­˜åœ¨æ˜¾è‘—å·®è·ï¼Œè¡¨æ˜CDAçš„å®Œå…¨è‡ªåŠ¨åŒ–æµç¨‹å¯èƒ½ä¸è¶³ï¼Œéœ€è¦äººå·¥å¹²é¢„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨åäº‹å®æ•°æ®å¢å¼ºï¼ˆCDAï¼‰ä¸­ï¼Œåˆ¤åˆ«æ¨¡å‹é€‰æ‹©å¯¼è‡´çš„æ ‡ç­¾ç¿»è½¬è¯„ä¼°ä¸ä¸€è‡´æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆè¯†åˆ«æœ€ä¼˜åˆ¤åˆ«æ¨¡å‹ï¼Œå½±å“äº†åäº‹å®ç¤ºä¾‹çš„æœ‰æ•ˆæ€§è¯„ä¼°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å®šä¹‰ç”Ÿæˆå™¨ä¸åˆ¤åˆ«æ¨¡å‹ä¹‹é—´çš„å››ç§å…³ç³»ï¼Œæ¢ç´¢ä¸åŒå…³ç³»å¯¹æ ‡ç­¾ç¿»è½¬è¯„ä¼°çš„å½±å“ï¼Œæå‡ºé€‰æ‹©ç‹¬ç«‹ä¸”æœªå¾®è°ƒçš„åˆ¤åˆ«æ¨¡å‹ä½œä¸ºæœ€ä½³æ–¹æ¡ˆã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶åŒ…æ‹¬ä¸¤ä¸ªæœ€å…ˆè¿›çš„LLMæ–¹æ³•ã€ä¸‰ä¸ªæ•°æ®é›†ã€å››ä¸ªç”Ÿæˆå™¨æ¨¡å‹å’Œ15ä¸ªåˆ¤åˆ«æ¨¡å‹çš„å¹¿æ³›å®éªŒï¼Œç»“åˆ90äººçš„ç”¨æˆ·ç ”ç©¶ï¼Œå½¢æˆå®Œæ•´çš„è¯„ä¼°æ¡†æ¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæ˜ç¡®äº†ç”Ÿæˆå™¨ä¸åˆ¤åˆ«æ¨¡å‹ä¹‹é—´çš„å…³ç³»å¯¹è¯„ä¼°ç»“æœçš„å½±å“ï¼Œæå‡ºäº†ç‹¬ç«‹å…³ç³»çš„åˆ¤åˆ«æ¨¡å‹åœ¨è¯„ä¼°ä¸­çš„ä¼˜è¶Šæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé€‰æ‹©äº†å¤šç§åˆ¤åˆ«æ¨¡å‹å¹¶è¿›è¡Œäº†ç³»ç»Ÿçš„å¯¹æ¯”ï¼Œå…³æ³¨æ¨¡å‹çš„ç‹¬ç«‹æ€§å’Œå¾®è°ƒçŠ¶æ€ï¼Œä»¥ç¡®ä¿è¯„ä¼°ç»“æœçš„å¯é æ€§ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡æœªåœ¨æ‘˜è¦ä¸­è¯¦ç»†è¯´æ˜ï¼Œéœ€å‚è€ƒåŸæ–‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œç‹¬ç«‹ä¸”æœªå¾®è°ƒçš„åˆ¤åˆ«æ¨¡å‹åœ¨æ ‡ç­¾ç¿»è½¬è¯„ä¼°ä¸­è¡¨ç°æœ€ä½³ï¼Œæ˜¾è‘—æé«˜äº†è¯„ä¼°çš„å¯é æ€§ã€‚å°½ç®¡å¦‚æ­¤ï¼Œæœ€æœ‰æ•ˆçš„åˆ¤åˆ«æ¨¡å‹ä¸ç”¨æˆ·ç ”ç©¶ç»“æœä¹‹é—´ä»å­˜åœ¨è¾ƒå¤§å·®è·ï¼Œæç¤ºæœªæ¥ç ”ç©¶éœ€å…³æ³¨äººå·¥å¹²é¢„çš„å¿…è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„åäº‹å®ç”Ÿæˆã€æ¨¡å‹è¯„ä¼°å’Œæ•°æ®å¢å¼ºç­‰ã€‚é€šè¿‡ä¼˜åŒ–åˆ¤åˆ«æ¨¡å‹çš„é€‰æ‹©ï¼Œå¯ä»¥æå‡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„æ€§èƒ½å’Œé²æ£’æ€§ï¼Œæ¨åŠ¨æ™ºèƒ½å¯¹è¯ç³»ç»Ÿã€æ–‡æœ¬ç”Ÿæˆç­‰æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Counterfactual examples are widely employed to enhance the performance and robustness of large language models (LLMs) through counterfactual data augmentation (CDA). However, the selection of the judge model used to evaluate label flipping, the primary metric for assessing the validity of generated counterfactuals for CDA, yields inconsistent results. To decipher this, we define four types of relationships between the counterfactual generator and judge models: being the same model, belonging to the same model family, being independent models, and having an distillation relationship. Through extensive experiments involving two state-of-the-art LLM-based methods, three datasets, four generator models, and 15 judge models, complemented by a user study (n = 90), we demonstrate that judge models with an independent, non-fine-tuned relationship to the generator model provide the most reliable label flipping evaluations. Relationships between the generator and judge models, which are closely aligned with the user study for CDA, result in better model performance and robustness. Nevertheless, we find that the gap between the most effective judge models and the results obtained from the user study remains considerably large. This suggests that a fully automated pipeline for CDA may be inadequate and requires human intervention.

