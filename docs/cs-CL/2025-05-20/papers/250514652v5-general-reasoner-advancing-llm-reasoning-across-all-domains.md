---
layout: default
title: General-Reasoner: Advancing LLM Reasoning Across All Domains
---

# General-Reasoner: Advancing LLM Reasoning Across All Domains

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14652" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14652v5</a>
  <a href="https://arxiv.org/pdf/2505.14652.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14652v5" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14652v5', 'General-Reasoner: Advancing LLM Reasoning Across All Domains')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xueguang Ma, Qian Liu, Dongfu Jiang, Ge Zhang, Zejun Ma, Wenhu Chen

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20 (æ›´æ–°: 2025-06-09)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGeneral-Reasonerä»¥è§£å†³LLMæ¨ç†èƒ½åŠ›ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ¨ç†èƒ½åŠ›` `å¼ºåŒ–å­¦ä¹ ` `ç”Ÿæˆæ¨¡å‹` `æ•°æ®é›†æ„å»º` `ç­”æ¡ˆéªŒè¯` `å¤šé¢†åŸŸåº”ç”¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„LLMæ¨ç†æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨æ•°å­¦å’Œç¼–ç é¢†åŸŸï¼Œé™åˆ¶äº†å…¶åœ¨å…¶ä»–é¢†åŸŸçš„åº”ç”¨å’Œæ³›åŒ–èƒ½åŠ›ã€‚
2. æœ¬æ–‡æå‡ºGeneral-Reasonerï¼Œé€šè¿‡æ„å»ºé«˜è´¨é‡æ•°æ®é›†å’Œç”Ÿæˆæ¨¡å‹çš„ç­”æ¡ˆéªŒè¯å™¨ï¼Œå¢å¼ºLLMçš„æ¨ç†èƒ½åŠ›ã€‚
3. åœ¨12ä¸ªåŸºå‡†æµ‹è¯•ä¸Šï¼ŒGeneral-Reasonerè¡¨ç°ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå°¤å…¶åœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­å±•ç°å‡ºå“è¶Šçš„æ•ˆæœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†èƒ½åŠ›æ–¹é¢å±•ç°å‡ºå¼ºå¤§æ½œåŠ›ã€‚ç‰¹åˆ«æ˜¯Deepseek-R1-Zeroå¼•å…¥çš„â€œé›¶â€å¼ºåŒ–å­¦ä¹ ï¼Œä½¿å¾—åŸºç¡€LLMå¯ä»¥ç›´æ¥è¿›è¡ŒRLè®­ç»ƒï¼Œè€Œæ— éœ€ä¾èµ–ä¸­é—´çš„ç›‘ç£å¾®è°ƒé˜¶æ®µã€‚ç„¶è€Œï¼Œç›®å‰çš„LLMæ¨ç†ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨æ•°å­¦å’Œç¼–ç é¢†åŸŸï¼Œå¯¼è‡´å…¶åœ¨æ›´å¹¿æ³›é¢†åŸŸçš„é€‚ç”¨æ€§å’Œæ³›åŒ–èƒ½åŠ›å—åˆ°é™åˆ¶ã€‚æœ¬æ–‡æå‡ºäº†General-Reasonerï¼Œä¸€ä¸ªæ—¨åœ¨å¢å¼ºLLMåœ¨å¤šé¢†åŸŸæ¨ç†èƒ½åŠ›çš„æ–°è®­ç»ƒèŒƒå¼ã€‚æˆ‘ä»¬çš„ä¸»è¦è´¡çŒ®åŒ…æ‹¬ï¼šæ„å»ºäº†ä¸€ä¸ªæ¶µç›–å¹¿æ³›å­¦ç§‘çš„å¤§è§„æ¨¡é«˜è´¨é‡é—®é¢˜æ•°æ®é›†ï¼Œå¹¶å¼€å‘äº†ä¸€ç§åŸºäºç”Ÿæˆæ¨¡å‹çš„ç­”æ¡ˆéªŒè¯å™¨ï¼Œæ›¿ä»£äº†ä¼ ç»Ÿçš„åŸºäºè§„åˆ™çš„éªŒè¯æ–¹æ³•ã€‚é€šè¿‡åœ¨å¤šä¸ªé¢†åŸŸçš„æ•°æ®é›†ä¸Šè¿›è¡Œè¯„ä¼°ï¼ŒGeneral-Reasoneråœ¨æ¨ç†æ€§èƒ½ä¸Šè¶…è¶Šäº†ç°æœ‰åŸºçº¿æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰LLMæ¨ç†èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨æ•°æ®ç¨€ç¼ºå’Œç­”æ¡ˆå¤šæ ·åŒ–çš„é¢†åŸŸã€‚ç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨æ•°å­¦å’Œç¼–ç é¢†åŸŸï¼Œç¼ºä¹å¯¹å…¶ä»–é¢†åŸŸçš„æœ‰æ•ˆæ”¯æŒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ„å»ºä¸€ä¸ªå¤§è§„æ¨¡çš„é«˜è´¨é‡æ•°æ®é›†å’Œå¼€å‘ç”Ÿæˆæ¨¡å‹çš„ç­”æ¡ˆéªŒè¯å™¨ï¼Œæ¥æå‡LLMåœ¨å¤šé¢†åŸŸçš„æ¨ç†èƒ½åŠ›ã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨å…‹æœä¼ ç»Ÿæ–¹æ³•åœ¨æ•°æ®ç¨€ç¼ºå’Œç­”æ¡ˆéªŒè¯ä¸Šçš„å±€é™æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€æ¨¡å‹è®­ç»ƒå’Œç­”æ¡ˆéªŒè¯ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡ç½‘ç»œçˆ¬è™«è·å–å¤šå­¦ç§‘çš„é—®é¢˜æ•°æ®ï¼›å…¶æ¬¡ï¼Œåˆ©ç”¨ç”Ÿæˆæ¨¡å‹è¿›è¡Œç­”æ¡ˆç”Ÿæˆå’ŒéªŒè¯ï¼›æœ€åï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥ç”Ÿæˆæ¨¡å‹ä½œä¸ºç­”æ¡ˆéªŒè¯å™¨ï¼Œæ›¿ä»£äº†ä¼ ç»Ÿçš„åŸºäºè§„åˆ™çš„éªŒè¯æ–¹æ³•ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ä¸Šä¸‹æ–‡å’Œæ¨ç†é“¾æ¡ï¼Œä»è€Œæé«˜éªŒè¯çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–æ¨ç†è¿‡ç¨‹ï¼Œå¹¶è®¾è®¡äº†é€‚åº”å¤šé¢†åŸŸçš„ç½‘ç»œç»“æ„ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨ä¸åŒé¢†åŸŸçš„æœ‰æ•ˆæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨12ä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒGeneral-Reasonerçš„è¡¨ç°è¶…è¶Šäº†ç°æœ‰åŸºçº¿æ–¹æ³•ï¼Œå°¤å…¶åœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­å±•ç°å‡ºå“è¶Šçš„æ•ˆæœï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°XX%ï¼ˆå…·ä½“æ•°æ®æœªçŸ¥ï¼‰ã€‚è¯¥æ¨¡å‹åœ¨å¤šé¢†åŸŸçš„æ¨ç†èƒ½åŠ›ä¸Šå±•ç°å‡ºå¼ºå¤§çš„æ³›åŒ–æ€§å’Œé²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€é‡‘èã€ç§‘å­¦ç ”ç©¶ç­‰å¤šä¸ªé¢†åŸŸï¼Œèƒ½å¤Ÿä¸ºç”¨æˆ·æä¾›æ›´å‡†ç¡®çš„æ¨ç†å’Œå†³ç­–æ”¯æŒã€‚é€šè¿‡æå‡LLMçš„æ¨ç†èƒ½åŠ›ï¼ŒGeneral-Reasoneræœ‰æœ›åœ¨å®é™…åº”ç”¨ä¸­äº§ç”Ÿæ˜¾è‘—çš„ä»·å€¼ï¼Œæ¨åŠ¨æ™ºèƒ½é—®ç­”ç³»ç»Ÿå’Œè‡ªåŠ¨åŒ–å†³ç­–çš„è¿›æ­¥ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Reinforcement learning (RL) has recently demonstrated strong potential in enhancing the reasoning capabilities of large language models (LLMs). Particularly, the "Zero" reinforcement learning introduced by Deepseek-R1-Zero, enables direct RL training of base LLMs without relying on an intermediate supervised fine-tuning stage. Despite these advancements, current works for LLM reasoning mainly focus on mathematical and coding domains, largely due to data abundance and the ease of answer verification. This limits the applicability and generalization of such models to broader domains, where questions often have diverse answer representations, and data is more scarce. In this paper, we propose General-Reasoner, a novel training paradigm designed to enhance LLM reasoning capabilities across diverse domains. Our key contributions include: (1) constructing a large-scale, high-quality dataset of questions with verifiable answers curated by web crawling, covering a wide range of disciplines; and (2) developing a generative model-based answer verifier, which replaces traditional rule-based verification with the capability of chain-of-thought and context-awareness. We train a series of models and evaluate them on a wide range of datasets covering wide domains like physics, chemistry, finance, electronics etc. Our comprehensive evaluation across these 12 benchmarks (e.g. MMLU-Pro, GPQA, SuperGPQA, TheoremQA, BBEH and MATH AMC) demonstrates that General-Reasoner outperforms existing baseline methods, achieving robust and generalizable reasoning performance while maintaining superior effectiveness in mathematical reasoning tasks.

