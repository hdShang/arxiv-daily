---
layout: default
title: MedArabiQ: Benchmarking Large Language Models on Arabic Medical Tasks
---

# MedArabiQ: Benchmarking Large Language Models on Arabic Medical Tasks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.03427" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.03427v2</a>
  <a href="https://arxiv.org/pdf/2505.03427.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.03427v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.03427v2', 'MedArabiQ: Benchmarking Large Language Models on Arabic Medical Tasks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mouath Abu Daoud, Chaimae Abouzahir, Leen Kharouf, Walid Al-Eisawi, Nizar Habash, Farah E. Shamout

**åˆ†ç±»**: cs.CL, cs.AI, cs.HC

**å‘å¸ƒæ—¥æœŸ**: 2025-05-06 (æ›´æ–°: 2025-08-22)

**å¤‡æ³¨**: 21 pages

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMedArabiQåŸºå‡†ä»¥è¯„ä¼°é˜¿æ‹‰ä¼¯åŒ»å­¦é¢†åŸŸçš„è¯­è¨€æ¨¡å‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `é˜¿æ‹‰ä¼¯åŒ»å­¦` `åŸºå‡†æ•°æ®é›†` `åè§ç¼“è§£` `å¤šä»»åŠ¡å­¦ä¹ ` `åŒ»ç–—åº”ç”¨` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é˜¿æ‹‰ä¼¯åŒ»å­¦é¢†åŸŸçš„åº”ç”¨æ•ˆæœå°šä¸æ˜ç¡®ï¼Œç¼ºä¹é«˜è´¨é‡çš„é¢†åŸŸç‰¹å®šæ•°æ®é›†å’ŒåŸºå‡†è¯„ä¼°ã€‚
2. æœ¬ç ”ç©¶æå‡ºäº†MedArabiQåŸºå‡†æ•°æ®é›†ï¼Œæ¶µç›–ä¸ƒä¸ªé˜¿æ‹‰ä¼¯åŒ»å­¦ä»»åŠ¡ï¼Œæ—¨åœ¨è¯„ä¼°å’Œæå‡LLMåœ¨è¯¥é¢†åŸŸçš„èƒ½åŠ›ã€‚
3. é€šè¿‡å¯¹äº”ä¸ªå…ˆè¿›çš„LLMè¿›è¡Œè¯„ä¼°ï¼Œç ”ç©¶å‘ç°éœ€è¦åˆ›å»ºæ–°çš„å¤šè¯­è¨€åŸºå‡†ï¼Œä»¥ä¿ƒè¿›LLMåœ¨åŒ»ç–—é¢†åŸŸçš„å…¬å¹³ä½¿ç”¨ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨åŒ»ç–—é¢†åŸŸå±•ç°å‡ºæ˜¾è‘—æ½œåŠ›ï¼Œä½†åœ¨é˜¿æ‹‰ä¼¯åŒ»å­¦é¢†åŸŸçš„æœ‰æ•ˆæ€§å°šæœªå¾—åˆ°æ¢ç´¢ï¼Œä¸»è¦ç”±äºç¼ºä¹é«˜è´¨é‡çš„é¢†åŸŸç‰¹å®šæ•°æ®é›†å’ŒåŸºå‡†ã€‚æœ¬ç ”ç©¶å¼•å…¥äº†MedArabiQï¼Œä¸€ä¸ªåŒ…å«ä¸ƒä¸ªé˜¿æ‹‰ä¼¯åŒ»å­¦ä»»åŠ¡çš„æ–°åŸºå‡†æ•°æ®é›†ï¼Œæ¶µç›–å¤šä¸ªä¸“ä¸šé¢†åŸŸï¼Œå¹¶åŒ…æ‹¬é€‰æ‹©é¢˜ã€å¡«ç©ºé¢˜å’ŒåŒ»æ‚£é—®ç­”ã€‚æˆ‘ä»¬é¦–å…ˆåˆ©ç”¨è¿‡å»çš„åŒ»å­¦è€ƒè¯•å’Œå…¬å¼€æ•°æ®é›†æ„å»ºäº†è¯¥æ•°æ®é›†ï¼Œå¹¶å¼•å…¥ä¸åŒçš„ä¿®æ”¹ä»¥è¯„ä¼°å„ç§LLMèƒ½åŠ›ï¼ŒåŒ…æ‹¬åè§ç¼“è§£ã€‚æˆ‘ä»¬å¯¹äº”ä¸ªæœ€å…ˆè¿›çš„å¼€æºå’Œä¸“æœ‰LLMè¿›è¡Œäº†å¹¿æ³›è¯„ä¼°ï¼ŒåŒ…æ‹¬GPT-4oã€Claude 3.5-Sonnetå’ŒGemini 1.5ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœå¼ºè°ƒäº†åˆ›å»ºæ–°çš„é«˜è´¨é‡åŸºå‡†çš„å¿…è¦æ€§ï¼Œä»¥ç¡®ä¿LLMåœ¨åŒ»ç–—é¢†åŸŸçš„å…¬å¹³éƒ¨ç½²å’Œå¯æ‰©å±•æ€§ã€‚é€šè¿‡å»ºç«‹è¿™ä¸€åŸºå‡†å¹¶å‘å¸ƒæ•°æ®é›†ï¼Œæˆ‘ä»¬ä¸ºæœªæ¥ç ”ç©¶æä¾›äº†åŸºç¡€ï¼Œæ—¨åœ¨è¯„ä¼°å’Œå¢å¼ºLLMçš„å¤šè¯­è¨€èƒ½åŠ›ï¼Œä»¥å®ç°ç”Ÿæˆæ€§äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„å…¬å¹³ä½¿ç”¨ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é˜¿æ‹‰ä¼¯åŒ»å­¦é¢†åŸŸåº”ç”¨çš„æœ‰æ•ˆæ€§é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•ç¼ºä¹é’ˆå¯¹é˜¿æ‹‰ä¼¯è¯­çš„é«˜è´¨é‡æ•°æ®é›†å’Œè¯„ä¼°åŸºå‡†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡é€šè¿‡æ„å»ºMedArabiQæ•°æ®é›†ï¼Œæ¶µç›–å¤šç§åŒ»å­¦ä»»åŠ¡ï¼Œè¯„ä¼°ä¸åŒLLMçš„èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åè§ç¼“è§£èƒ½åŠ›ï¼Œä»¥å®ç°æ›´å…¬å¹³çš„åŒ»ç–—åº”ç”¨ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€ä»»åŠ¡è®¾è®¡ã€æ¨¡å‹è¯„ä¼°ç­‰å¤šä¸ªé˜¶æ®µï¼Œæ¶‰åŠé€‰æ‹©é¢˜ã€å¡«ç©ºé¢˜å’Œé—®ç­”ç­‰ä»»åŠ¡ç±»å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºåˆ›å»ºäº†ä¸€ä¸ªä¸“é—¨é’ˆå¯¹é˜¿æ‹‰ä¼¯åŒ»å­¦é¢†åŸŸçš„å¤šä»»åŠ¡åŸºå‡†æ•°æ®é›†ï¼Œå¡«è¡¥äº†ç°æœ‰ç ”ç©¶ä¸­çš„ç©ºç™½ã€‚

**å…³é”®è®¾è®¡**ï¼šæ•°æ®é›†æ„å»ºè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†è¿‡å»åŒ»å­¦è€ƒè¯•å’Œå…¬å¼€æ•°æ®é›†ï¼Œè®¾è®¡äº†å¤šç§ä»»åŠ¡å½¢å¼ï¼Œå¹¶å¼•å…¥äº†åè§ç¼“è§£çš„è¯„ä¼°æœºåˆ¶ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€è¯„ä¼°çš„LLMåœ¨é˜¿æ‹‰ä¼¯åŒ»å­¦ä»»åŠ¡ä¸Šçš„è¡¨ç°å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œå°¤å…¶æ˜¯åœ¨åè§ç¼“è§£æ–¹é¢ã€‚é€šè¿‡ä¸ç°æœ‰åŸºçº¿çš„å¯¹æ¯”ï¼Œéƒ¨åˆ†æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šæå‡äº†20%ä»¥ä¸Šï¼Œè¡¨æ˜MedArabiQåŸºå‡†çš„æœ‰æ•ˆæ€§å’Œå¿…è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬é˜¿æ‹‰ä¼¯å›½å®¶çš„åŒ»ç–—æ•™è‚²ã€ä¸´åºŠå†³ç­–æ”¯æŒå’Œæ‚£è€…äº’åŠ¨ç­‰ã€‚é€šè¿‡æä¾›é«˜è´¨é‡çš„åŸºå‡†æ•°æ®é›†ï¼Œæœªæ¥çš„ç ”ç©¶å¯ä»¥è¿›ä¸€æ­¥æå‡LLMåœ¨é˜¿æ‹‰ä¼¯åŒ»å­¦é¢†åŸŸçš„åº”ç”¨æ•ˆæœï¼Œä¿ƒè¿›åŒ»ç–—æœåŠ¡çš„å…¬å¹³æ€§å’Œå¯åŠæ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have demonstrated significant promise for various applications in healthcare. However, their efficacy in the Arabic medical domain remains unexplored due to the lack of high-quality domain-specific datasets and benchmarks. This study introduces MedArabiQ, a novel benchmark dataset consisting of seven Arabic medical tasks, covering multiple specialties and including multiple choice questions, fill-in-the-blank, and patient-doctor question answering. We first constructed the dataset using past medical exams and publicly available datasets. We then introduced different modifications to evaluate various LLM capabilities, including bias mitigation. We conducted an extensive evaluation with five state-of-the-art open-source and proprietary LLMs, including GPT-4o, Claude 3.5-Sonnet, and Gemini 1.5. Our findings highlight the need for the creation of new high-quality benchmarks that span different languages to ensure fair deployment and scalability of LLMs in healthcare. By establishing this benchmark and releasing the dataset, we provide a foundation for future research aimed at evaluating and enhancing the multilingual capabilities of LLMs for the equitable use of generative AI in healthcare.

