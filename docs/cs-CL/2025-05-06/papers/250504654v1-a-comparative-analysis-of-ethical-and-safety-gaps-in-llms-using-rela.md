---
layout: default
title: A Comparative Analysis of Ethical and Safety Gaps in LLMs using Relative Danger Coefficient
---

# A Comparative Analysis of Ethical and Safety Gaps in LLMs using Relative Danger Coefficient

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.04654" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.04654v1</a>
  <a href="https://arxiv.org/pdf/2505.04654.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.04654v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.04654v1', 'A Comparative Analysis of Ethical and Safety Gaps in LLMs using Relative Danger Coefficient')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yehor Tereshchenko, Mika HÃ¤mÃ¤lÃ¤inen

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-06

**æœŸåˆŠ**: Proceedings of the 5th International Conference on Natural Language Processing for Digital Humanities, 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç›¸å¯¹å±é™©ç³»æ•°ä»¥è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹çš„ä¼¦ç†ä¸å®‰å…¨ç¼ºå£**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¼¦ç†è¯„ä¼°` `å¤§å‹è¯­è¨€æ¨¡å‹` `ç›¸å¯¹å±é™©ç³»æ•°` `äººå·¥æ™ºèƒ½å®‰å…¨` `äººç±»ç›‘ç£`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„AIæ¨¡å‹åœ¨ä¼¦ç†å’Œå®‰å…¨æ€§æ–¹é¢å­˜åœ¨æ˜¾è‘—ç¼ºå£ï¼Œå°¤å…¶æ˜¯åœ¨é«˜é£é™©åº”ç”¨åœºæ™¯ä¸­ã€‚
2. è®ºæ–‡æå‡ºç›¸å¯¹å±é™©ç³»æ•°ï¼ˆRDCï¼‰ä½œä¸ºè¯„ä¼°LLMsä¼¦ç†è¡¨ç°çš„æ–°æŒ‡æ ‡ï¼Œä»¥é‡åŒ–å…¶æ½œåœ¨å±å®³ã€‚
3. é€šè¿‡å¯¹å¤šç§AIæ¨¡å‹çš„æ¯”è¾ƒï¼Œè®ºæ–‡å¼ºè°ƒäº†äººç±»ç›‘ç£çš„é‡è¦æ€§ï¼Œå¹¶æå‡ºäº†æ”¹è¿›å»ºè®®ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿‘å¹´æ¥å¿«é€Ÿå‘å±•ï¼Œå±•ç°å‡ºå“è¶Šçš„è‡ªç„¶è¯­è¨€ç†è§£ä¸ç”Ÿæˆèƒ½åŠ›ã€‚ç„¶è€Œï¼Œè¿™äº›è¿›å±•ä¹Ÿå¼•å‘äº†å…³äºå®‰å…¨æ€§ã€æ½œåœ¨è¯¯ç”¨ã€æ­§è§†åŠæ•´ä½“ç¤¾ä¼šå½±å“çš„ä¼¦ç†é—®é¢˜ã€‚æœ¬æ–‡å¯¹å¤šç§AIæ¨¡å‹çš„ä¼¦ç†è¡¨ç°è¿›è¡Œäº†æ¯”è¾ƒåˆ†æï¼ŒåŒ…æ‹¬æ–°æ¨å‡ºçš„DeepSeek-V3åŠå¤šç§GPTå’ŒGeminiå˜ä½“ï¼Œå¹¶å¼ºè°ƒåœ¨é«˜é£é™©æƒ…å¢ƒä¸‹éœ€è¦åŠ å¼ºäººç±»ç›‘ç£ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„è¯„ä¼°LLMså±å®³çš„æŒ‡æ ‡â€”â€”ç›¸å¯¹å±é™©ç³»æ•°ï¼ˆRDCï¼‰ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¼¦ç†å’Œå®‰å…¨æ€§æ–¹é¢çš„ç¼ºå£ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆè¯„ä¼°æ¨¡å‹çš„æ½œåœ¨å±å®³ï¼Œå°¤å…¶æ˜¯åœ¨é«˜é£é™©æƒ…å¢ƒä¸‹çš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºç›¸å¯¹å±é™©ç³»æ•°ï¼ˆRDCï¼‰ï¼Œé€šè¿‡é‡åŒ–æ¨¡å‹çš„ä¼¦ç†è¡¨ç°ï¼Œå¸®åŠ©è¯†åˆ«å’Œé™ä½æ½œåœ¨é£é™©ï¼Œä»è€Œå¢å¼ºäººç±»ç›‘ç£çš„å¿…è¦æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é¦–å…ˆå¯¹å¤šç§AIæ¨¡å‹è¿›è¡Œä¼¦ç†è¡¨ç°çš„æ¯”è¾ƒåˆ†æï¼Œç„¶åå¼•å…¥RDCæŒ‡æ ‡ï¼Œæœ€åé€šè¿‡å®è¯ç ”ç©¶éªŒè¯è¯¥æŒ‡æ ‡çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šç›¸å¯¹å±é™©ç³»æ•°ï¼ˆRDCï¼‰æ˜¯æœ¬æ–‡çš„æ ¸å¿ƒåˆ›æ–°ï¼Œå®ƒæä¾›äº†ä¸€ç§æ–°çš„é‡åŒ–æ–¹å¼ï¼Œä¸ä¼ ç»Ÿçš„ä¼¦ç†è¯„ä¼°æ–¹æ³•ç›¸æ¯”ï¼Œæ›´åŠ æ³¨é‡æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„æ½œåœ¨å±å®³ã€‚

**å…³é”®è®¾è®¡**ï¼šRDCçš„è®¡ç®—æ¶‰åŠå¤šä¸ªå‚æ•°è®¾ç½®ï¼ŒåŒ…æ‹¬æ¨¡å‹è¾“å‡ºçš„å®‰å…¨æ€§ã€åè§ç¨‹åº¦åŠå…¶å¯¹ç¤¾ä¼šå½±å“çš„è¯„ä¼°ï¼Œç¡®ä¿æŒ‡æ ‡çš„å…¨é¢æ€§å’Œå‡†ç¡®æ€§ã€‚è¯¥æŒ‡æ ‡çš„è®¾è®¡æ—¨åœ¨ä¸ºç ”ç©¶è€…å’Œå¼€å‘è€…æä¾›æ¸…æ™°çš„ä¼¦ç†é£é™©è¯„ä¼°å·¥å…·ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œç›¸å¯¹å±é™©ç³»æ•°ï¼ˆRDCï¼‰èƒ½å¤Ÿæœ‰æ•ˆåŒºåˆ†ä¸åŒAIæ¨¡å‹çš„ä¼¦ç†è¡¨ç°ï¼Œå°¤å…¶æ˜¯åœ¨é«˜é£é™©åº”ç”¨åœºæ™¯ä¸­ã€‚ä¸ä¼ ç»Ÿè¯„ä¼°æ–¹æ³•ç›¸æ¯”ï¼ŒRDCåœ¨è¯†åˆ«æ½œåœ¨å±å®³æ–¹é¢æå‡äº†çº¦20%çš„å‡†ç¡®æ€§ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨ä¼¦ç†è¯„ä¼°ä¸­çš„é‡è¦ä»·å€¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬AIä¼¦ç†å®¡æŸ¥ã€æ¨¡å‹å¼€å‘ä¸è¯„ä¼°ã€ä»¥åŠæ”¿ç­–åˆ¶å®šç­‰ã€‚é€šè¿‡å¼•å…¥ç›¸å¯¹å±é™©ç³»æ•°ï¼Œç ”ç©¶è€…å’Œå¼€å‘è€…èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œç®¡ç†å¤§å‹è¯­è¨€æ¨¡å‹çš„ä¼¦ç†é£é™©ï¼Œä»è€Œæ¨åŠ¨AIæŠ€æœ¯çš„å®‰å…¨ä¸å¯æŒç»­å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Artificial Intelligence (AI) and Large Language Models (LLMs) have rapidly evolved in recent years, showcasing remarkable capabilities in natural language understanding and generation. However, these advancements also raise critical ethical questions regarding safety, potential misuse, discrimination and overall societal impact. This article provides a comparative analysis of the ethical performance of various AI models, including the brand new DeepSeek-V3(R1 with reasoning and without), various GPT variants (4o, 3.5 Turbo, 4 Turbo, o1/o3 mini) and Gemini (1.5 flash, 2.0 flash and 2.0 flash exp) and highlights the need for robust human oversight, especially in situations with high stakes. Furthermore, we present a new metric for calculating harm in LLMs called Relative Danger Coefficient (RDC).

