---
layout: default
title: An Information-Theoretic Framework for Robust Large Language Model Editing
---

# An Information-Theoretic Framework for Robust Large Language Model Editing

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.16227" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.16227v1</a>
  <a href="https://arxiv.org/pdf/2512.16227.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.16227v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.16227v1', 'An Information-Theoretic Framework for Robust Large Language Model Editing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Qizhou Chen, Chengyu Wang, Taolin Zhang, Xiaofeng He

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-18

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºä¿¡æ¯ç“¶é¢ˆçš„IBKEæ¡†æ¶ï¼Œç”¨äºç¨³å¥çš„å¤§è¯­è¨€æ¨¡å‹çŸ¥è¯†ç¼–è¾‘ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `çŸ¥è¯†ç¼–è¾‘` `ä¿¡æ¯ç“¶é¢ˆ` `æ¨¡å‹æ›´æ–°` `æ³›åŒ–æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ¨¡å‹ç¼–è¾‘æ–¹æ³•æ³›åŒ–æ€§å·®ï¼Œæ˜“äº§ç”Ÿå‰¯ä½œç”¨ï¼Œé™åˆ¶äº†å®é™…åº”ç”¨ã€‚
2. åˆ©ç”¨ä¿¡æ¯ç“¶é¢ˆç†è®ºï¼Œå‹ç¼©å¹¶éš”ç¦»çŸ¥è¯†ä¿®æ­£çš„å…³é”®ä¿¡æ¯ï¼Œå‡å°‘å¯¹æ— å…³è¡Œä¸ºçš„å¹²æ‰°ã€‚
3. IBKEåœ¨å¤šä¸ªLLMå’ŒåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºä¼˜å¼‚çš„å‡†ç¡®æ€§ã€é€šç”¨æ€§å’Œç‰¹å¼‚æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å·²æˆä¸ºç§‘å­¦ã€æŠ€æœ¯å’Œç¤¾ä¼šä¸­ä¸å¯æˆ–ç¼ºçš„å·¥å…·ï¼Œæ¨åŠ¨äº†å„ä¸ªé¢†åŸŸçš„å˜é©æ€§è¿›æ­¥ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹ä¸­å­˜åœ¨çš„é”™è¯¯æˆ–è¿‡æ—¶ä¿¡æ¯å¯èƒ½ä¼šæŸå®³å…¶å‡†ç¡®æ€§ï¼Œå¹¶é™åˆ¶å…¶å®‰å…¨éƒ¨ç½²ã€‚å¼€å‘æœ‰æ•ˆçš„ç­–ç•¥æ¥æ›´æ–°æ¨¡å‹çŸ¥è¯†ï¼ŒåŒæ—¶é¿å…å®Œå…¨é‡æ–°è®­ç»ƒçš„æˆæœ¬å’Œå¹²æ‰°ï¼Œä»ç„¶æ˜¯ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ã€‚å½“å‰çš„æ¨¡å‹ç¼–è¾‘æŠ€æœ¯å¸¸å¸¸éš¾ä»¥å°†ä¿®æ­£æ¨å¹¿åˆ°ç‹­çª„é¢†åŸŸä¹‹å¤–ï¼Œå¯¼è‡´æ„æƒ³ä¸åˆ°çš„åæœï¼Œå¹¶é™åˆ¶äº†å®ƒä»¬çš„å®é™…å½±å“ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŸºäºä¿¡æ¯ç“¶é¢ˆç†è®ºçš„LLMç¼–è¾‘æ–°æ¡†æ¶ã€‚è¯¥æ–¹æ³•ç²¾ç¡®åœ°å‹ç¼©å’Œéš”ç¦»äº†é€šç”¨çŸ¥è¯†ä¿®æ­£æ‰€éœ€çš„åŸºæœ¬ä¿¡æ¯ï¼ŒåŒæ—¶æœ€å¤§é™åº¦åœ°å‡å°‘å¯¹ä¸ç›¸å…³æ¨¡å‹è¡Œä¸ºçš„å¹²æ‰°ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æå‡ºäº†ä¿¡æ¯ç“¶é¢ˆçŸ¥è¯†ç¼–è¾‘å™¨ï¼ˆIBKEï¼‰ï¼Œå®ƒåˆ©ç”¨ç´§å‡‘çš„æ½œåœ¨è¡¨ç¤ºæ¥æŒ‡å¯¼åŸºäºæ¢¯åº¦çš„æ›´æ–°ï¼Œä»è€Œå®ç°ç¨³å¥ä¸”å¹¿æ³›é€‚ç”¨çš„æ¨¡å‹ç¼–è¾‘ã€‚æˆ‘ä»¬åœ¨å¤šä¸ªLLMæ¶æ„å’Œæ ‡å‡†åŸºå‡†ä»»åŠ¡ä¸ŠéªŒè¯äº†IBKEçš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜äº†å…¶æœ€å…ˆè¿›çš„å‡†ç¡®æ€§ä»¥åŠç¼–è¾‘çš„æ”¹è¿›çš„é€šç”¨æ€§å’Œç‰¹å¼‚æ€§ã€‚è¿™äº›å‘ç°ä¸ºå¼€æ”¾åŸŸçŸ¥è¯†ç¼–è¾‘å»ºç«‹äº†ä¸€ä¸ªç†è®ºä¸Šåˆç†ä¸”å®ç”¨çš„èŒƒä¾‹ï¼Œæé«˜äº†LLMåœ¨å®é™…åº”ç”¨ä¸­çš„æ•ˆç”¨å’Œå¯ä¿¡åº¦ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„å¤§è¯­è¨€æ¨¡å‹çŸ¥è¯†ç¼–è¾‘æ–¹æ³•ï¼Œéš¾ä»¥åœ¨ä¿è¯ç¼–è¾‘å‡†ç¡®æ€§çš„åŒæ—¶ï¼Œé¿å…å¯¹æ¨¡å‹å…¶ä»–çŸ¥è¯†çš„å¹²æ‰°ï¼Œå³æ³›åŒ–æ€§è¾ƒå·®ï¼Œå®¹æ˜“äº§ç”Ÿå‰¯ä½œç”¨ã€‚è¿™é™åˆ¶äº†LLMåœ¨å®é™…åœºæ™¯ä¸­çš„å¯é åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨ä¿¡æ¯ç“¶é¢ˆï¼ˆInformation Bottleneck, IBï¼‰ç†è®ºï¼Œåœ¨ç¼–è¾‘è¿‡ç¨‹ä¸­ï¼Œåªä¿ç•™ä¸å¾…ç¼–è¾‘çŸ¥è¯†ç›¸å…³çš„ä¿¡æ¯ï¼Œå»é™¤å†—ä½™ä¿¡æ¯ï¼Œä»è€Œæé«˜ç¼–è¾‘çš„æ³›åŒ–æ€§å’Œç‰¹å¼‚æ€§ã€‚é€šè¿‡å‹ç¼©å’Œéš”ç¦»å…³é”®ä¿¡æ¯ï¼Œå‡å°‘å¯¹æ¨¡å‹åŸæœ‰çŸ¥è¯†çš„å¹²æ‰°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šIBKEæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) **çŸ¥è¯†è¡¨ç¤ºå­¦ä¹ **ï¼šå°†éœ€è¦ç¼–è¾‘çš„çŸ¥è¯†ç¼–ç æˆç´§å‡‘çš„æ½œåœ¨è¡¨ç¤ºã€‚2) **ä¿¡æ¯ç“¶é¢ˆå‹ç¼©**ï¼šåˆ©ç”¨ä¿¡æ¯ç“¶é¢ˆåŸç†ï¼Œå¯¹æ½œåœ¨è¡¨ç¤ºè¿›è¡Œå‹ç¼©ï¼Œæå–å…³é”®ä¿¡æ¯ã€‚3) **æ¢¯åº¦å¼•å¯¼æ›´æ–°**ï¼šä½¿ç”¨å‹ç¼©åçš„æ½œåœ¨è¡¨ç¤ºï¼Œå¼•å¯¼åŸºäºæ¢¯åº¦çš„æ¨¡å‹å‚æ•°æ›´æ–°ã€‚4) **çŸ¥è¯†éªŒè¯**ï¼šè¯„ä¼°ç¼–è¾‘åçš„æ¨¡å‹åœ¨ç›¸å…³ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œä»¥åŠå¯¹å…¶ä»–çŸ¥è¯†çš„å½±å“ã€‚

**å…³é”®åˆ›æ–°**ï¼šIBKEçš„å…³é”®åˆ›æ–°åœ¨äºå°†ä¿¡æ¯ç“¶é¢ˆç†è®ºå¼•å…¥åˆ°å¤§è¯­è¨€æ¨¡å‹çŸ¥è¯†ç¼–è¾‘ä¸­ã€‚ä¸ä»¥å¾€ç›´æ¥ä¿®æ”¹æ¨¡å‹å‚æ•°çš„æ–¹æ³•ä¸åŒï¼ŒIBKEé€šè¿‡å‹ç¼©çŸ¥è¯†è¡¨ç¤ºï¼Œåªä¿ç•™å¿…è¦ä¿¡æ¯ï¼Œä»è€Œå®ç°äº†æ›´ç²¾ç¡®å’Œæ›´å…·æ³›åŒ–æ€§çš„ç¼–è¾‘ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆå‡å°‘ç¼–è¾‘å¯¹æ¨¡å‹å…¶ä»–çŸ¥è¯†çš„å¹²æ‰°ï¼Œæé«˜ç¼–è¾‘çš„å¯é æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šIBKEçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEï¼‰å­¦ä¹ çŸ¥è¯†çš„æ½œåœ¨è¡¨ç¤ºã€‚2) ä½¿ç”¨KLæ•£åº¦ä½œä¸ºä¿¡æ¯ç“¶é¢ˆçš„æ­£åˆ™åŒ–é¡¹ï¼Œæ§åˆ¶æ½œåœ¨è¡¨ç¤ºçš„ä¿¡æ¯é‡ã€‚3) è®¾è®¡ç‰¹å®šçš„æŸå¤±å‡½æ•°ï¼Œé¼“åŠ±æ¨¡å‹åœ¨ç¼–è¾‘åèƒ½å¤Ÿæ­£ç¡®å›ç­”ç›¸å…³é—®é¢˜ï¼ŒåŒæ—¶ä¿æŒå¯¹å…¶ä»–é—®é¢˜çš„å›ç­”ä¸å˜ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„é€‰æ‹©å–å†³äºæ‰€ä½¿ç”¨çš„LLMæ¶æ„å’Œæ•°æ®é›†ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16227v1/x1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16227v1/x2.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16227v1/x3.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒIBKEåœ¨å¤šä¸ªLLMæ¶æ„å’Œæ ‡å‡†åŸºå‡†ä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒIBKEåœ¨ç¼–è¾‘å‡†ç¡®æ€§ã€é€šç”¨æ€§å’Œç‰¹å¼‚æ€§æ–¹é¢å‡æœ‰æ˜¾è‘—æå‡ã€‚å…·ä½“æ•°æ®ï¼ˆåŸæ–‡æœªæä¾›ï¼‰è¡¨æ˜ï¼ŒIBKEèƒ½å¤Ÿåœ¨ä¿è¯ç¼–è¾‘æ•ˆæœçš„åŒæ—¶ï¼Œæœ€å¤§é™åº¦åœ°å‡å°‘å¯¹æ¨¡å‹å…¶ä»–çŸ¥è¯†çš„å¹²æ‰°ï¼Œä»è€Œæé«˜äº†ç¼–è¾‘çš„å¯é æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦æŒç»­æ›´æ–°çŸ¥è¯†çš„å¤§è¯­è¨€æ¨¡å‹åº”ç”¨åœºæ™¯ï¼Œä¾‹å¦‚ï¼šæ™ºèƒ½å®¢æœã€çŸ¥è¯†é—®ç­”ã€å†…å®¹ç”Ÿæˆç­‰ã€‚é€šè¿‡IBKEæ¡†æ¶ï¼Œå¯ä»¥é«˜æ•ˆã€å®‰å…¨åœ°æ›´æ–°æ¨¡å‹çŸ¥è¯†ï¼Œæé«˜æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚è¯¥æŠ€æœ¯è¿˜æœ‰åŠ©äºå‡å°‘æ¨¡å‹é”™è¯¯ä¿¡æ¯çš„ä¼ æ’­ï¼Œæå‡LLMçš„å¯ä¿¡åº¦ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have become indispensable tools in science, technology, and society, enabling transformative advances across diverse fields. However, errors or outdated information within these models can undermine their accuracy and restrict their safe deployment. Developing efficient strategies for updating model knowledge without the expense and disruption of full retraining remains a critical challenge. Current model editing techniques frequently struggle to generalize corrections beyond narrow domains, leading to unintended consequences and limiting their practical impact. Here, we introduce a novel framework for editing LLMs, grounded in information bottleneck theory. This approach precisely compresses and isolates the essential information required for generalizable knowledge correction while minimizing disruption to unrelated model behaviors. Building upon this foundation, we present the Information Bottleneck Knowledge Editor (IBKE), which leverages compact latent representations to guide gradient-based updates, enabling robust and broadly applicable model editing. We validate IBKE's effectiveness across multiple LLM architectures and standard benchmark tasks, demonstrating state-of-the-art accuracy and improved generality and specificity of edits. These findings establish a theoretically principled and practical paradigm for open-domain knowledge editing, advancing the utility and trustworthiness of LLMs in real-world applications.

