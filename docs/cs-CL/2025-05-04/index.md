---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CL - 2025-05-04
---

# cs.CLï¼ˆ2025-05-04ï¼‰

ğŸ“Š å…± **13** ç¯‡è®ºæ–‡
 | ğŸ”— **1** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (12 ğŸ”—1)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (12 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250502078v1-leceval-an-automated-metric-for-multimodal-knowledge-acquisition-in-.html">LecEval: An Automated Metric for Multimodal Knowledge Acquisition in Multimedia Learning</a></td>
  <td>æå‡ºLecEvalä»¥è§£å†³å¤šæ¨¡æ€çŸ¥è¯†è·å–è¯„ä¼°é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.02078v1" data-paper-url="./papers/250502078v1-leceval-an-automated-metric-for-multimodal-knowledge-acquisition-in-.html" onclick="toggleFavorite(this, '2505.02078v1', 'LecEval: An Automated Metric for Multimodal Knowledge Acquisition in Multimedia Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250501967v1-analyzing-cognitive-differences-among-large-language-models-through-.html">Analyzing Cognitive Differences Among Large Language Models through the Lens of Social Worldview</a></td>
  <td>æå‡ºç¤¾ä¼šä¸–ç•Œè§‚åˆ†ç±»æ³•ä»¥åˆ†æå¤§å‹è¯­è¨€æ¨¡å‹çš„è®¤çŸ¥å·®å¼‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.01967v1" data-paper-url="./papers/250501967v1-analyzing-cognitive-differences-among-large-language-models-through-.html" onclick="toggleFavorite(this, '2505.01967v1', 'Analyzing Cognitive Differences Among Large Language Models through the Lens of Social Worldview')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250502252v1-personalisation-or-prejudice-addressing-geographic-bias-in-hate-spee.html">Personalisation or Prejudice? Addressing Geographic Bias in Hate Speech Detection using Debias Tuning in Large Language Models</a></td>
  <td>æå‡ºå»åè§è°ƒä¼˜ä»¥è§£å†³ä»‡æ¨è¨€è®ºæ£€æµ‹ä¸­çš„åœ°ç†åè§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.02252v1" data-paper-url="./papers/250502252v1-personalisation-or-prejudice-addressing-geographic-bias-in-hate-spee.html" onclick="toggleFavorite(this, '2505.02252v1', 'Personalisation or Prejudice? Addressing Geographic Bias in Hate Speech Detection using Debias Tuning in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250502156v4-adaptive-thinking-via-mode-policy-optimization-for-social-language-a.html">Adaptive Thinking via Mode Policy Optimization for Social Language Agents</a></td>
  <td>æå‡ºè‡ªé€‚åº”æ¨¡å¼å­¦ä¹ ä»¥è§£å†³ç¤¾äº¤è¯­è¨€ä»£ç†çš„æ¨ç†æ·±åº¦é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.02156v4" data-paper-url="./papers/250502156v4-adaptive-thinking-via-mode-policy-optimization-for-social-language-a.html" onclick="toggleFavorite(this, '2505.02156v4', 'Adaptive Thinking via Mode Policy Optimization for Social Language Agents')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250502146v1-qimeng-xpiler-transcompiling-tensor-programs-for-deep-learning-syste.html">QiMeng-Xpiler: Transcompiling Tensor Programs for Deep Learning Systems with a Neural-Symbolic Approach</a></td>
  <td>æå‡ºQiMeng-Xpilerä»¥è§£å†³å¼‚æ„æ·±åº¦å­¦ä¹ ç³»ç»Ÿçš„ç¼–ç¨‹è´Ÿæ‹…é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.02146v1" data-paper-url="./papers/250502146v1-qimeng-xpiler-transcompiling-tensor-programs-for-deep-learning-syste.html" onclick="toggleFavorite(this, '2505.02146v1', 'QiMeng-Xpiler: Transcompiling Tensor Programs for Deep Learning Systems with a Neural-Symbolic Approach')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250502091v2-llm-optira-llm-driven-optimization-of-resource-allocation-for-non-co.html">LLM-OptiRA: LLM-Driven Optimization of Resource Allocation for Non-Convex Problems in Wireless Communications</a></td>
  <td>æå‡ºLLM-OptiRAä»¥è§£å†³æ— çº¿é€šä¿¡ä¸­çš„éå‡¸èµ„æºåˆ†é…é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.02091v2" data-paper-url="./papers/250502091v2-llm-optira-llm-driven-optimization-of-resource-allocation-for-non-co.html" onclick="toggleFavorite(this, '2505.02091v2', 'LLM-OptiRA: LLM-Driven Optimization of Resource Allocation for Non-Convex Problems in Wireless Communications')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250502171v1-a-new-hope-domain-agnostic-automatic-evaluation-of-text-chunking.html">A New HOPE: Domain-agnostic Automatic Evaluation of Text Chunking</a></td>
  <td>æå‡ºHOPEè¯„ä¼°æ–¹æ³•ä»¥ä¼˜åŒ–æ–‡æœ¬åˆ†å—ç­–ç•¥</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.02171v1" data-paper-url="./papers/250502171v1-a-new-hope-domain-agnostic-automatic-evaluation-of-text-chunking.html" onclick="toggleFavorite(this, '2505.02171v1', 'A New HOPE: Domain-agnostic Automatic Evaluation of Text Chunking')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250502872v2-decoding-open-ended-information-seeking-goals-from-eye-movements-in-.html">Decoding Open-Ended Information Seeking Goals from Eye Movements in Reading</a></td>
  <td>æå‡ºåŸºäºçœ¼åŠ¨æ•°æ®çš„å¼€æ”¾å¼ä¿¡æ¯å¯»æ±‚ç›®æ ‡è§£ç æ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.02872v2" data-paper-url="./papers/250502872v2-decoding-open-ended-information-seeking-goals-from-eye-movements-in-.html" onclick="toggleFavorite(this, '2505.02872v2', 'Decoding Open-Ended Information Seeking Goals from Eye Movements in Reading')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250600003v1-probing-audio-generation-capabilities-of-text-based-language-models.html">Probing Audio-Generation Capabilities of Text-Based Language Models</a></td>
  <td>æ¢è®¨æ–‡æœ¬åŸºç¡€è¯­è¨€æ¨¡å‹çš„éŸ³é¢‘ç”Ÿæˆèƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.00003v1" data-paper-url="./papers/250600003v1-probing-audio-generation-capabilities-of-text-based-language-models.html" onclick="toggleFavorite(this, '2506.00003v1', 'Probing Audio-Generation Capabilities of Text-Based Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250502177v1-measuring-hong-kong-massive-multi-task-language-understanding.html">Measuring Hong Kong Massive Multi-Task Language Understanding</a></td>
  <td>æå‡ºHKMMLUåŸºå‡†ä»¥è§£å†³é¦™æ¸¯å¤šè¯­è¨€ç†è§£è¯„ä¼°ä¸è¶³é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.02177v1" data-paper-url="./papers/250502177v1-measuring-hong-kong-massive-multi-task-language-understanding.html" onclick="toggleFavorite(this, '2505.02177v1', 'Measuring Hong Kong Massive Multi-Task Language Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250502172v3-identifying-legal-holdings-with-llms-a-systematic-study-of-performan.html">Identifying Legal Holdings with LLMs: A Systematic Study of Performance, Scale, and Memorization</a></td>
  <td>é€šè¿‡LLMsè¯†åˆ«æ³•å¾‹åˆ¤å†³ï¼Œæå‡æ³•å¾‹åˆ†æçš„å‡†ç¡®æ€§</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.02172v3" data-paper-url="./papers/250502172v3-identifying-legal-holdings-with-llms-a-systematic-study-of-performan.html" onclick="toggleFavorite(this, '2505.02172v3', 'Identifying Legal Holdings with LLMs: A Systematic Study of Performance, Scale, and Memorization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250502164v1-incorporating-legal-structure-in-retrieval-augmented-generation-a-ca.html">Incorporating Legal Structure in Retrieval-Augmented Generation: A Case Study on Copyright Fair Use</a></td>
  <td>æå‡ºåŸºäºæ³•å¾‹ç»“æ„çš„æ£€ç´¢å¢å¼ºç”Ÿæˆæ–¹æ³•ä»¥è§£å†³ç‰ˆæƒåˆç†ä½¿ç”¨é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.02164v1" data-paper-url="./papers/250502164v1-incorporating-legal-structure-in-retrieval-augmented-generation-a-ca.html" onclick="toggleFavorite(this, '2505.02164v1', 'Incorporating Legal Structure in Retrieval-Augmented Generation: A Case Study on Copyright Fair Use')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>13</td>
  <td><a href="./papers/250502142v1-exploring-the-potential-of-offline-rl-for-reasoning-in-llms-a-prelim.html">Exploring the Potential of Offline RL for Reasoning in LLMs: A Preliminary Study</a></td>
  <td>æ¢ç´¢ç¦»çº¿å¼ºåŒ–å­¦ä¹ æå‡å¤§è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">offline RL</span> <span class="paper-tag">DPO</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.02142v1" data-paper-url="./papers/250502142v1-exploring-the-potential-of-offline-rl-for-reasoning-in-llms-a-prelim.html" onclick="toggleFavorite(this, '2505.02142v1', 'Exploring the Potential of Offline RL for Reasoning in LLMs: A Preliminary Study')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CL é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)