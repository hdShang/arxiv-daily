---
layout: default
title: Measuring Hong Kong Massive Multi-Task Language Understanding
---

# Measuring Hong Kong Massive Multi-Task Language Understanding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.02177" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.02177v1</a>
  <a href="https://arxiv.org/pdf/2505.02177.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.02177v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.02177v1', 'Measuring Hong Kong Massive Multi-Task Language Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chuxue Cao, Zhenghao Zhu, Junqi Zhu, Guoying Lu, Siyu Peng, Juntao Dai, Weijie Shi, Sirui Han, Yike Guo

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-04

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHKMMLUåŸºå‡†ä»¥è§£å†³é¦™æ¸¯å¤šè¯­è¨€ç†è§£è¯„ä¼°ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šè¯­è¨€ç†è§£` `å¤§å‹è¯­è¨€æ¨¡å‹` `è¯„ä¼°åŸºå‡†` `é¦™æ¸¯è¯­è¨€` `æ–‡åŒ–çŸ¥è¯†` `ç¿»è¯‘ä»»åŠ¡` `ç¤¾ä¼šç§‘å­¦` `äººæ–‡å­¦ç§‘`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¯„ä¼°åŸºå‡†æœªèƒ½å……åˆ†è€ƒè™‘é¦™æ¸¯çš„è¯­è¨€å’Œæ–‡åŒ–ç‰¹ç‚¹ï¼Œå¯¼è‡´LLMsåœ¨è¯¥åœ°åŒºçš„è¡¨ç°ä¸è¶³ã€‚
2. è®ºæ–‡æå‡ºHKMMLUåŸºå‡†ï¼ŒåŒ…å«å¤šä»»åŠ¡è¯„ä¼°å’Œç¿»è¯‘ä»»åŠ¡ï¼Œæ—¨åœ¨å…¨é¢è¯„ä¼°é¦™æ¸¯çš„è¯­è¨€ç†è§£èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå½“å‰æœ€ä½³æ¨¡å‹åœ¨HKMMLUä¸Šçš„è¡¨ç°è¿œä½äºå…¶ä»–åŸºå‡†ï¼Œè¡¨æ˜éœ€è¦é’ˆå¯¹é¦™æ¸¯ç‰¹å®šçš„è¯­è¨€èƒ½åŠ›è¿›è¡Œæ”¹è¿›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šè¯­è¨€ç†è§£å¯¹äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è·¨æ–‡åŒ–é€‚ç”¨æ€§è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œé’ˆå¯¹é¦™æ¸¯ç‹¬ç‰¹è¯­è¨€ç¯å¢ƒçš„è¯„ä¼°åŸºå‡†å°šæœªå……åˆ†å¼€å‘ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºHKMMLUï¼Œä¸€ä¸ªå¤šä»»åŠ¡è¯­è¨€ç†è§£åŸºå‡†ï¼Œè¯„ä¼°é¦™æ¸¯çš„è¯­è¨€èƒ½åŠ›å’Œç¤¾ä¼šæ–‡åŒ–çŸ¥è¯†ã€‚HKMMLUåŒ…å«26,698é“å¤šé€‰é¢˜ï¼Œæ¶µç›–ç§‘å­¦ã€æŠ€æœ¯ã€å·¥ç¨‹ã€æ•°å­¦ï¼ˆSTEMï¼‰ã€ç¤¾ä¼šç§‘å­¦ã€äººæ–‡å­¦ç§‘åŠå…¶ä»–å››ä¸ªç±»åˆ«ã€‚æ­¤å¤–ï¼Œè¿˜åŒ…æ‹¬90,550ä¸ªæ™®é€šè¯-ç²¤è¯­ç¿»è¯‘ä»»åŠ¡ã€‚é€šè¿‡å¯¹GPT-4oã€Claude 3.7 SonnetåŠ18ä¸ªä¸åŒè§„æ¨¡çš„å¼€æºLLMsè¿›è¡Œå…¨é¢å®éªŒï¼Œç»“æœæ˜¾ç¤ºæœ€ä½³æ¨¡å‹DeepSeek-V3çš„å‡†ç¡®ç‡ä»…ä¸º75%ï¼Œæ˜¾è‘—ä½äºMMLUå’ŒCMMLUã€‚è¿™ä¸€è¡¨ç°å·®è·å‡¸æ˜¾äº†æå‡LLMsåœ¨é¦™æ¸¯ç‰¹å®šè¯­è¨€å’ŒçŸ¥è¯†é¢†åŸŸèƒ½åŠ›çš„å¿…è¦æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³é¦™æ¸¯ç‰¹æœ‰çš„è¯­è¨€å’Œæ–‡åŒ–èƒŒæ™¯ä¸‹ï¼Œç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹è¯„ä¼°åŸºå‡†ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†åæ˜ é¦™æ¸¯çš„è¯­è¨€å¤æ‚æ€§å’Œæ–‡åŒ–çŸ¥è¯†ï¼Œå¯¼è‡´LLMsåœ¨è¯¥åœ°åŒºçš„åº”ç”¨æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºHKMMLUåŸºå‡†ï¼Œè®¾è®¡äº†å¤šä»»åŠ¡è¯„ä¼°æ¡†æ¶ï¼Œç»“åˆå¤šç§è¯­è¨€å’Œæ–‡åŒ–èƒŒæ™¯çš„ä»»åŠ¡ï¼Œä»¥å…¨é¢è¯„ä¼°LLMsåœ¨é¦™æ¸¯çš„è¯­è¨€ç†è§£èƒ½åŠ›ã€‚é€šè¿‡å¼•å…¥æ™®é€šè¯-ç²¤è¯­ç¿»è¯‘ä»»åŠ¡ï¼Œå¢å¼ºäº†è¯„ä¼°çš„å¤šæ ·æ€§å’Œå®ç”¨æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šHKMMLUåŸºå‡†åŒ…æ‹¬26,698é“å¤šé€‰é¢˜ï¼Œåˆ†ä¸ºç§‘å­¦ã€æŠ€æœ¯ã€å·¥ç¨‹ã€æ•°å­¦ã€ç¤¾ä¼šç§‘å­¦ã€äººæ–‡å­¦ç§‘åŠå…¶ä»–å››ä¸ªç±»åˆ«ã€‚æ­¤å¤–ï¼Œå¢åŠ äº†90,550ä¸ªç¿»è¯‘ä»»åŠ¡ï¼Œå½¢æˆä¸€ä¸ªå¤šå±‚æ¬¡çš„è¯„ä¼°ä½“ç³»ï¼Œæ¶µç›–ä¸åŒé¢†åŸŸçš„çŸ¥è¯†å’Œè¯­è¨€èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šHKMMLUçš„æœ€å¤§åˆ›æ–°åœ¨äºå…¶é’ˆå¯¹é¦™æ¸¯ç‰¹å®šçš„è¯­è¨€å’Œæ–‡åŒ–èƒŒæ™¯è¿›è¡Œçš„è®¾è®¡ï¼Œå¡«è¡¥äº†ç°æœ‰è¯„ä¼°åŸºå‡†çš„ç©ºç™½ï¼Œä½¿å¾—LLMsçš„è¯„ä¼°æ›´åŠ å…¨é¢å’Œç²¾å‡†ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨äº†å¤šç§æ¨¡å‹ï¼ŒåŒ…æ‹¬GPT-4oå’ŒClaude 3.7 Sonnetï¼Œè¯„ä¼°äº†ä¸åŒæ¨¡å‹è§„æ¨¡ã€æç¤ºç­–ç•¥åŠé—®é¢˜å’Œæ¨ç†ä»¤ç‰Œé•¿åº¦å¯¹æ¨¡å‹è¡¨ç°çš„å½±å“ï¼Œç¡®ä¿äº†è¯„ä¼°çš„å…¨é¢æ€§å’Œç§‘å­¦æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæœ€ä½³æ¨¡å‹DeepSeek-V3åœ¨HKMMLUä¸Šçš„å‡†ç¡®ç‡ä»…ä¸º75%ï¼Œè¿œä½äºMMLUå’ŒCMMLUçš„è¡¨ç°ã€‚è¿™ä¸€ç»“æœå¼ºè°ƒäº†åœ¨é¦™æ¸¯ç‰¹å®šè¯­è¨€å’ŒçŸ¥è¯†é¢†åŸŸæå‡LLMsèƒ½åŠ›çš„ç´§è¿«æ€§ï¼Œè¡¨æ˜å½“å‰æ¨¡å‹åœ¨å¤šè¯­è¨€ç†è§£æ–¹é¢ä»æœ‰æ˜¾è‘—æå‡ç©ºé—´ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€æ–‡åŒ–äº¤æµå’Œäººå·¥æ™ºèƒ½åŠ©æ‰‹ç­‰ã€‚HKMMLUåŸºå‡†çš„å»ºç«‹å°†æ¨åŠ¨LLMsåœ¨é¦™æ¸¯åŠå…¶ä»–å¤šè¯­è¨€ç¯å¢ƒä¸­çš„åº”ç”¨ï¼Œæå‡å…¶åœ¨è·¨æ–‡åŒ–äº¤æµä¸­çš„æœ‰æ•ˆæ€§å’Œå‡†ç¡®æ€§ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multilingual understanding is crucial for the cross-cultural applicability of Large Language Models (LLMs). However, evaluation benchmarks designed for Hong Kong's unique linguistic landscape, which combines Traditional Chinese script with Cantonese as the spoken form and its cultural context, remain underdeveloped. To address this gap, we introduce HKMMLU, a multi-task language understanding benchmark that evaluates Hong Kong's linguistic competence and socio-cultural knowledge. The HKMMLU includes 26,698 multi-choice questions across 66 subjects, organized into four categories: Science, Technology, Engineering, and Mathematics (STEM), Social Sciences, Humanities, and Other. To evaluate the multilingual understanding ability of LLMs, 90,550 Mandarin-Cantonese translation tasks were additionally included. We conduct comprehensive experiments on GPT-4o, Claude 3.7 Sonnet, and 18 open-source LLMs of varying sizes on HKMMLU. The results show that the best-performing model, DeepSeek-V3, struggles to achieve an accuracy of 75\%, significantly lower than that of MMLU and CMMLU. This performance gap highlights the need to improve LLMs' capabilities in Hong Kong-specific language and knowledge domains. Furthermore, we investigate how question language, model size, prompting strategies, and question and reasoning token lengths affect model performance. We anticipate that HKMMLU will significantly advance the development of LLMs in multilingual and cross-cultural contexts, thereby enabling broader and more impactful applications.

