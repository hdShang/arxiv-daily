---
layout: default
title: Identifying Legal Holdings with LLMs: A Systematic Study of Performance, Scale, and Memorization
---

# Identifying Legal Holdings with LLMs: A Systematic Study of Performance, Scale, and Memorization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.02172" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.02172v3</a>
  <a href="https://arxiv.org/pdf/2505.02172.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.02172v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.02172v3', 'Identifying Legal Holdings with LLMs: A Systematic Study of Performance, Scale, and Memorization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chuck Arvin

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-04 (æ›´æ–°: 2025-05-24)

**å¤‡æ³¨**: Presented as a short paper at International Conference on Artificial Intelligence and Law 2025 (Chicago, IL)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é€šè¿‡LLMsè¯†åˆ«æ³•å¾‹åˆ¤å†³ï¼Œæå‡æ³•å¾‹åˆ†æçš„å‡†ç¡®æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ³•å¾‹åˆ†æ` `æ€§èƒ½è¯„ä¼°` `å¼•ç”¨åŒ¿ååŒ–` `å®è§‚F1åˆ†æ•°` `è‡ªåŠ¨åŒ–æ³•å¾‹å·¥å…·` `æ¡ˆä¾‹è¯†åˆ«`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ³•å¾‹åˆ†ææ–¹æ³•åœ¨å¤„ç†å¤æ‚æ³•å¾‹æ–‡æœ¬æ—¶å­˜åœ¨å‡†ç¡®æ€§ä¸è¶³å’Œæ•ˆç‡ä½ä¸‹çš„é—®é¢˜ã€‚
2. æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„è¯„ä¼°æ–¹æ³•ï¼Œé€šè¿‡å®éªŒéªŒè¯æ¨¡å‹åœ¨æ³•å¾‹åˆ¤å†³è¯†åˆ«ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ¨¡å‹è§„æ¨¡ä¸æ€§èƒ½å‘ˆæ­£ç›¸å…³ï¼Œä¸”åœ¨å¼•ç”¨åŒ¿ååŒ–æµ‹è¯•ä¸‹ä»èƒ½ä¿æŒé«˜æ°´å¹³çš„å‡†ç¡®æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰èƒ½åŠ›çš„ä¸æ–­æå‡ï¼Œè¯„ä¼°å…¶åœ¨æ—¢å®šåŸºå‡†ä¸Šçš„è¡¨ç°å˜å¾—è‡³å…³é‡è¦ã€‚æœ¬ç ”ç©¶é€šè¿‡ä¸€ç³»åˆ—å®éªŒè¯„ä¼°äº†ç°ä»£LLMsï¼ˆå‚æ•°èŒƒå›´ä»30äº¿åˆ°900äº¿ä»¥ä¸Šï¼‰åœ¨CaseHOLDæ³•å¾‹åŸºå‡†æ•°æ®é›†ä¸Šçš„è¡¨ç°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ¨¡å‹è§„æ¨¡çš„å¢åŠ èƒ½å¤Ÿæ˜¾è‘—æå‡ä»»åŠ¡æ€§èƒ½ï¼ŒGPT4oå’ŒAmazonNovaProç­‰æ›´å¼ºå¤§çš„æ¨¡å‹åˆ†åˆ«è¾¾åˆ°äº†0.744å’Œ0.720çš„å®è§‚F1åˆ†æ•°ã€‚è¿™äº›åˆ†æ•°ä¸è¯¥æ•°æ®é›†ä¸Šå·²å‘å¸ƒçš„æœ€ä½³ç»“æœç›¸å½“ï¼Œå¹¶ä¸”ä¸éœ€è¦ä»»ä½•å¤æ‚çš„æ¨¡å‹è®­ç»ƒã€å¾®è°ƒæˆ–å°‘é‡æç¤ºã€‚ä¸ºäº†ç¡®ä¿è¿™äº›å¼ºç»“æœä¸æ˜¯ç”±äºå¯¹è®­ç»ƒæ•°æ®ä¸­å¸æ³•æ„è§çš„è®°å¿†ï¼Œæˆ‘ä»¬å¼€å‘å¹¶åˆ©ç”¨äº†ä¸€ç§æ–°çš„å¼•ç”¨åŒ¿ååŒ–æµ‹è¯•ï¼Œç¡®ä¿æ¡ˆä¾‹åç§°å’Œå¼•ç”¨æ˜¯è™šæ„çš„ï¼ŒåŒæ—¶ä¿æŒè¯­ä¹‰æ„ä¹‰ã€‚åœ¨è¿™ç§æ¡ä»¶ä¸‹ï¼Œæ¨¡å‹ä»ä¿æŒå¼ºåŠ²è¡¨ç°ï¼ˆå®è§‚F1ä¸º0.728ï¼‰ï¼Œè¡¨æ˜å…¶æ€§èƒ½å¹¶éæºäºæœºæ¢°è®°å¿†ã€‚è¿™äº›å‘ç°å±•ç¤ºäº†LLMsåœ¨æ³•å¾‹ä»»åŠ¡ä¸­çš„æ½œåŠ›ä¸å½“å‰å±€é™æ€§ï¼Œå¯¹è‡ªåŠ¨åŒ–æ³•å¾‹åˆ†æå’Œæ³•å¾‹åŸºå‡†çš„å¼€å‘ä¸æµ‹é‡å…·æœ‰é‡è¦æ„ä¹‰ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ³•å¾‹åˆ¤å†³è¯†åˆ«ä»»åŠ¡ä¸­çš„è¡¨ç°è¯„ä¼°é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–äºå¤æ‚çš„è®­ç»ƒè¿‡ç¨‹ï¼Œéš¾ä»¥ç›´æ¥æ¯”è¾ƒæ¨¡å‹æ€§èƒ½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡è®¾è®¡ä¸€ç³»åˆ—å®éªŒï¼Œè¯„ä¼°ä¸åŒè§„æ¨¡çš„LLMsåœ¨æ³•å¾‹åŸºå‡†æ•°æ®é›†CaseHOLDä¸Šçš„è¡¨ç°ï¼Œç‰¹åˆ«å…³æ³¨æ¨¡å‹è§„æ¨¡å¯¹æ€§èƒ½çš„å½±å“ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†å‡†å¤‡ã€æ¨¡å‹é€‰æ‹©ã€æ€§èƒ½è¯„ä¼°å’Œå¼•ç”¨åŒ¿ååŒ–æµ‹è¯•å››ä¸ªä¸»è¦æ¨¡å—ã€‚æ•°æ®é›†ç”¨äºè®­ç»ƒå’Œæµ‹è¯•ï¼Œæ¨¡å‹åˆ™åŒ…æ‹¬ä»30äº¿åˆ°900äº¿å‚æ•°çš„å¤šç§LLMsã€‚

**å…³é”®åˆ›æ–°**ï¼šå¼•å…¥äº†å¼•ç”¨åŒ¿ååŒ–æµ‹è¯•ï¼Œç¡®ä¿æ¨¡å‹çš„é«˜æ€§èƒ½ä¸æ˜¯ç”±äºå¯¹è®­ç»ƒæ•°æ®çš„è®°å¿†ï¼Œè€Œæ˜¯åŸºäºå¯¹æ³•å¾‹æ–‡æœ¬çš„ç†è§£å’Œæ¨ç†èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šå®éªŒä¸­ä½¿ç”¨çš„æ¨¡å‹åŒ…æ‹¬GPT4oå’ŒAmazonNovaProï¼Œé‡‡ç”¨æ ‡å‡†çš„å®è§‚F1åˆ†æ•°ä½œä¸ºæ€§èƒ½è¯„ä¼°æŒ‡æ ‡ï¼Œç¡®ä¿ç»“æœçš„å¯æ¯”æ€§å’Œå¯é æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGPT4oå’ŒAmazonNovaProåœ¨CaseHOLDæ•°æ®é›†ä¸Šçš„å®è§‚F1åˆ†æ•°åˆ†åˆ«è¾¾åˆ°0.744å’Œ0.720ï¼Œè¡¨ç°å‡ºè‰²ã€‚å³ä½¿åœ¨å¼•ç”¨åŒ¿ååŒ–æµ‹è¯•ä¸‹ï¼Œæ¨¡å‹ä»èƒ½ä¿æŒ0.728çš„å®è§‚F1åˆ†æ•°ï¼Œè¡¨æ˜å…¶æ€§èƒ½å¹¶éæºäºç®€å•çš„è®°å¿†ï¼Œè€Œæ˜¯å…·å¤‡è¾ƒå¼ºçš„ç†è§£èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æˆæœå¯å¹¿æ³›åº”ç”¨äºæ³•å¾‹é¢†åŸŸçš„è‡ªåŠ¨åŒ–åˆ†æå·¥å…·ï¼Œå¸®åŠ©æ³•å¾‹ä»ä¸šè€…æ›´é«˜æ•ˆåœ°è¯†åˆ«å’Œåˆ†æåˆ¤å†³å†…å®¹ã€‚æœªæ¥ï¼Œéšç€LLMsæŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ï¼Œè¿™äº›å·¥å…·æœ‰æœ›æå‡æ³•å¾‹æœåŠ¡çš„è´¨é‡å’Œå¯åŠæ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> As large language models (LLMs) continue to advance in capabilities, it is essential to assess how they perform on established benchmarks. In this study, we present a suite of experiments to assess the performance of modern LLMs (ranging from 3B to 90B+ parameters) on CaseHOLD, a legal benchmark dataset for identifying case holdings. Our experiments demonstrate scaling effects - performance on this task improves with model size, with more capable models like GPT4o and AmazonNovaPro achieving macro F1 scores of 0.744 and 0.720 respectively. These scores are competitive with the best published results on this dataset, and do not require any technically sophisticated model training, fine-tuning or few-shot prompting. To ensure that these strong results are not due to memorization of judicial opinions contained in the training data, we develop and utilize a novel citation anonymization test that preserves semantic meaning while ensuring case names and citations are fictitious. Models maintain strong performance under these conditions (macro F1 of 0.728), suggesting the performance is not due to rote memorization. These findings demonstrate both the promise and current limitations of LLMs for legal tasks with important implications for the development and measurement of automated legal analytics and legal benchmarks.

