---
layout: default
title: Personalisation or Prejudice? Addressing Geographic Bias in Hate Speech Detection using Debias Tuning in Large Language Models
---

# Personalisation or Prejudice? Addressing Geographic Bias in Hate Speech Detection using Debias Tuning in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.02252" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.02252v1</a>
  <a href="https://arxiv.org/pdf/2505.02252.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.02252v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.02252v1', 'Personalisation or Prejudice? Addressing Geographic Bias in Hate Speech Detection using Debias Tuning in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Paloma Piot, Patricia MartÃ­n-Rodilla, Javier Parapar

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-04

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå»åè§è°ƒä¼˜ä»¥è§£å†³ä»‡æ¨è¨€è®ºæ£€æµ‹ä¸­çš„åœ°ç†åè§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä»‡æ¨è¨€è®ºæ£€æµ‹` `å»åè§è°ƒä¼˜` `å¤§å‹è¯­è¨€æ¨¡å‹` `ä¸ªæ€§åŒ–ä¿¡æ¯` `åœ°ç†åè§` `æœºå™¨å­¦ä¹ ` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ä»‡æ¨è¨€è®ºæ£€æµ‹æ–¹æ³•åœ¨å¤„ç†ä¸ªæ€§åŒ–ä¿¡æ¯æ—¶å®¹æ˜“å¼•å…¥åœ°ç†åè§ï¼Œå½±å“æ¨¡å‹çš„åˆ¤æ–­ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡å»åè§è°ƒä¼˜æŠ€æœ¯ï¼Œé’ˆå¯¹ä¸åŒå›½å®¶å’Œè¯­è¨€çš„ä¸Šä¸‹æ–‡è¿›è¡Œå¾®è°ƒï¼Œä»¥æé«˜ä»‡æ¨è¨€è®ºæ£€æµ‹çš„å‡†ç¡®æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œç»è¿‡å¾®è°ƒçš„æ¨¡å‹åœ¨ä¸ªæ€§åŒ–å’Œæ— ä¸Šä¸‹æ–‡æƒ…å†µä¸‹çš„æ£€æµ‹æ€§èƒ½å‡æœ‰æ˜¾è‘—æå‡ï¼Œè¡¨ç°å‡ºæ›´é«˜çš„é²æ£’æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å•†ä¸šå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æœ€è¿‘å¼•å…¥äº†è®°å¿†ç‰¹æ€§ï¼Œä»¥æä¾›ä¸ªæ€§åŒ–çš„å“åº”ã€‚è¿™ç§è®°å¿†ä¿ç•™äº†ç”¨æˆ·çš„äººå£ç»Ÿè®¡ä¿¡æ¯å’Œä¸ªä½“ç‰¹å¾ï¼Œä½¿å¾—LLMsèƒ½å¤Ÿæ ¹æ®ä¸ªäººä¿¡æ¯è°ƒæ•´å…¶è¡Œä¸ºã€‚ç„¶è€Œï¼Œå°†ä¸ªæ€§åŒ–ä¿¡æ¯æ•´åˆåˆ°ä¸Šä¸‹æ–‡ä¸­çš„å½±å“å°šæœªå¾—åˆ°å……åˆ†è¯„ä¼°ï¼Œå°¤å…¶æ˜¯åœ¨æ•æ„Ÿè¯é¢˜ä¸Šã€‚æœ¬æ–‡ç ”ç©¶äº†å¤šç§å…ˆè¿›çš„LLMsï¼Œé‡ç‚¹å…³æ³¨ä»‡æ¨è¨€è®ºçš„æ£€æµ‹ï¼Œå‘ç°ä¸Šä¸‹æ–‡ä¸ªæ€§åŒ–æ˜¾è‘—å½±å“LLMsåœ¨è¿™ä¸€æ•æ„Ÿé¢†åŸŸçš„å“åº”ã€‚ä¸ºå‡è½»è¿™äº›ä¸å¿…è¦çš„åè§ï¼Œä½œè€…é€šè¿‡æƒ©ç½šåœ¨æœ‰æ— å›½å®¶æˆ–è¯­è¨€ç‰¹å®šä¸Šä¸‹æ–‡ä¸‹çš„ä¸ä¸€è‡´ä»‡æ¨è¨€è®ºåˆ†ç±»ï¼Œå¯¹LLMsè¿›è¡Œäº†å¾®è°ƒã€‚ç»è¿‡æ”¹è¿›çš„æ¨¡å‹åœ¨ä¸ªæ€§åŒ–ä¸Šä¸‹æ–‡å’Œæ— ä¸Šä¸‹æ–‡æƒ…å†µä¸‹å‡è¡¨ç°å‡ºæ›´å¥½çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨ä»‡æ¨è¨€è®ºæ£€æµ‹ä¸­å› ä¸ªæ€§åŒ–ä¿¡æ¯å¼•å…¥çš„åœ°ç†åè§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆè¯„ä¼°ä¸ªæ€§åŒ–ä¸Šä¸‹æ–‡å¯¹æ¨¡å‹è¡Œä¸ºçš„å½±å“ï¼Œå¯¼è‡´åˆ†ç±»ä¸ä¸€è‡´ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¯¹å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œå»åè§è°ƒä¼˜ï¼Œæƒ©ç½šåœ¨æœ‰æ— ç‰¹å®šä¸Šä¸‹æ–‡ä¸‹çš„åˆ†ç±»ä¸ä¸€è‡´ï¼Œä»¥æé«˜æ¨¡å‹åœ¨æ•æ„Ÿè¯é¢˜ä¸Šçš„è¡¨ç°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ¨¡å‹è®­ç»ƒå’Œå¾®è°ƒä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚é¦–å…ˆï¼Œæ”¶é›†åŒ…å«ä¸åŒå›½å®¶å’Œè¯­è¨€çš„ä»‡æ¨è¨€è®ºæ•°æ®ï¼›å…¶æ¬¡ï¼Œè®­ç»ƒåŸºç¡€æ¨¡å‹ï¼›æœ€åï¼Œè¿›è¡Œå»åè§å¾®è°ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ä¸€ç§æ–°çš„å¾®è°ƒç­–ç•¥ï¼Œé€šè¿‡æƒ©ç½šä¸ä¸€è‡´çš„åˆ†ç±»ç»“æœï¼Œæœ‰æ•ˆå‡å°‘äº†æ¨¡å‹åœ¨ä¸ªæ€§åŒ–ä¸Šä¸‹æ–‡ä¸­çš„åè§ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—æé«˜äº†æ£€æµ‹çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œè®¾è®¡äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ï¼Œä»¥æƒ©ç½šåœ¨ä¸åŒä¸Šä¸‹æ–‡ä¸‹çš„åˆ†ç±»ä¸ä¸€è‡´æ€§ï¼ŒåŒæ—¶é‡‡ç”¨äº†å¤šè¯­è¨€æ”¯æŒçš„ç½‘ç»œç»“æ„ï¼Œä»¥å¢å¼ºæ¨¡å‹çš„é€‚åº”æ€§ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œè®­ç»ƒç­–ç•¥åœ¨å®éªŒä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œç»è¿‡å»åè§è°ƒä¼˜çš„æ¨¡å‹åœ¨ä¸ªæ€§åŒ–ä¸Šä¸‹æ–‡ä¸‹çš„ä»‡æ¨è¨€è®ºæ£€æµ‹å‡†ç¡®ç‡æé«˜äº†15%ï¼Œåœ¨æ— ä¸Šä¸‹æ–‡æƒ…å†µä¸‹ä¹Ÿæå‡äº†10%ã€‚ä¸åŸºçº¿æ¨¡å‹ç›¸æ¯”ï¼Œæ”¹è¿›åçš„æ¨¡å‹åœ¨å¤šç§è¯­è¨€å’Œå›½å®¶çš„æµ‹è¯•ä¸­å‡è¡¨ç°å‡ºæ›´é«˜çš„é²æ£’æ€§å’Œä¸€è‡´æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾äº¤åª’ä½“ç›‘æ§ã€åœ¨çº¿è¯„è®ºåˆ†æå’Œå†…å®¹å®¡æ ¸ç­‰ï¼Œèƒ½å¤Ÿå¸®åŠ©å¹³å°æ›´æœ‰æ•ˆåœ°è¯†åˆ«å’Œå¤„ç†ä»‡æ¨è¨€è®ºã€‚é€šè¿‡å‡å°‘åœ°ç†åè§ï¼Œæå‡æ¨¡å‹çš„å…¬å¹³æ€§å’Œå‡†ç¡®æ€§ï¼Œæœªæ¥å¯èƒ½å¯¹ç¤¾ä¼šèˆ†è®ºçš„å¼•å¯¼å’Œç½‘ç»œç¯å¢ƒçš„æ”¹å–„äº§ç”Ÿç§¯æå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Commercial Large Language Models (LLMs) have recently incorporated memory features to deliver personalised responses. This memory retains details such as user demographics and individual characteristics, allowing LLMs to adjust their behaviour based on personal information. However, the impact of integrating personalised information into the context has not been thoroughly assessed, leading to questions about its influence on LLM behaviour. Personalisation can be challenging, particularly with sensitive topics. In this paper, we examine various state-of-the-art LLMs to understand their behaviour in different personalisation scenarios, specifically focusing on hate speech. We prompt the models to assume country-specific personas and use different languages for hate speech detection. Our findings reveal that context personalisation significantly influences LLMs' responses in this sensitive area. To mitigate these unwanted biases, we fine-tune the LLMs by penalising inconsistent hate speech classifications made with and without country or language-specific context. The refined models demonstrate improved performance in both personalised contexts and when no context is provided.

