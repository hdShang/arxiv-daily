---
layout: default
title: "LecEval: An Automated Metric for Multimodal Knowledge Acquisition in Multimedia Learning"
---

# LecEval: An Automated Metric for Multimodal Knowledge Acquisition in Multimedia Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.02078" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.02078v1</a>
  <a href="https://arxiv.org/pdf/2505.02078.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.02078v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.02078v1', 'LecEval: An Automated Metric for Multimodal Knowledge Acquisition in Multimedia Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Joy Lim Jia Yin, Daniel Zhang-Li, Jifan Yu, Haoxuan Li, Shangqing Tu, Yuanchun Wang, Zhiyuan Liu, Huiqin Liu, Lei Hou, Juanzi Li, Bin Xu

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-04

**å¤‡æ³¨**: 6 pages, 3 figures

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/JoylimJY/LecEval)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLecEvalä»¥è§£å†³å¤šæ¨¡æ€çŸ¥è¯†è·å–è¯„ä¼°é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `è‡ªåŠ¨åŒ–è¯„ä¼°` `æ•™è‚²æŠ€æœ¯` `å¹»ç¯ç‰‡æ•™å­¦` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¯„ä¼°æ–¹æ³•åœ¨å¤šåª’ä½“æ•™å­¦è´¨é‡è¯„ä¼°ä¸­å­˜åœ¨å¯æ‰©å±•æ€§å’Œä¸Šä¸‹æ–‡æ•æ‰çš„ä¸è¶³ï¼Œéš¾ä»¥æ»¡è¶³å®é™…éœ€æ±‚ã€‚
2. æœ¬æ–‡æå‡ºLecEvalï¼Œé€šè¿‡æ¢…è€¶å°”çš„å¤šåª’ä½“å­¦ä¹ è®¤çŸ¥ç†è®ºï¼Œè®¾è®¡äº†ä¸€ç§è‡ªåŠ¨åŒ–è¯„ä¼°æŒ‡æ ‡ï¼Œæ¶µç›–å››ä¸ªè¯„ä¼°æ ‡å‡†ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŸºäºæ–°æ•°æ®é›†è®­ç»ƒçš„æ¨¡å‹åœ¨å‡†ç¡®æ€§å’Œé€‚åº”æ€§ä¸Šä¼˜äºä¼ ç»Ÿè¯„ä¼°æ–¹æ³•ï¼Œè¡¨ç°å‡ºæ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¯„ä¼°åŸºäºå¹»ç¯ç‰‡çš„å¤šåª’ä½“æ•™å­¦è´¨é‡å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ç°æœ‰æ–¹æ³•å¦‚äººå·¥è¯„ä¼°ã€åŸºäºå‚è€ƒçš„æŒ‡æ ‡å’Œå¤§å‹è¯­è¨€æ¨¡å‹è¯„ä¼°è€…å­˜åœ¨å¯æ‰©å±•æ€§ã€ä¸Šä¸‹æ–‡æ•æ‰æˆ–åè§ç­‰å±€é™æ€§ã€‚æœ¬æ–‡æå‡ºLecEvalï¼Œè¿™æ˜¯ä¸€ç§åŸºäºæ¢…è€¶å°”çš„å¤šåª’ä½“å­¦ä¹ è®¤çŸ¥ç†è®ºçš„è‡ªåŠ¨åŒ–æŒ‡æ ‡ï¼Œç”¨äºè¯„ä¼°åŸºäºå¹»ç¯ç‰‡çš„å­¦ä¹ ä¸­çš„å¤šæ¨¡æ€çŸ¥è¯†è·å–ã€‚LecEvalé€šè¿‡å†…å®¹ç›¸å…³æ€§ã€è¡¨è¾¾æ¸…æ™°åº¦ã€é€»è¾‘ç»“æ„å’Œè§‚ä¼—å‚ä¸åº¦å››ä¸ªæ ‡å‡†æ¥è¯„ä¼°æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬æ•´ç†äº†ä¸€ä¸ªåŒ…å«2000å¤šå¼ å¹»ç¯ç‰‡çš„å¤§è§„æ¨¡æ•°æ®é›†ï¼Œæ¥è‡ª50å¤šä¸ªåœ¨çº¿è¯¾ç¨‹è§†é¢‘ï¼Œå¹¶åœ¨è¿™äº›æ ‡å‡†ä¸Šè¿›è¡Œäº†ç»†è‡´çš„äººç±»è¯„åˆ†ã€‚åŸºäºè¯¥æ•°æ®é›†è®­ç»ƒçš„æ¨¡å‹åœ¨å‡†ç¡®æ€§å’Œé€‚åº”æ€§ä¸Šä¼˜äºç°æœ‰æŒ‡æ ‡ï¼Œå¼¥åˆäº†è‡ªåŠ¨åŒ–ä¸äººå·¥è¯„ä¼°ä¹‹é—´çš„å·®è·ã€‚æˆ‘ä»¬åœ¨https://github.com/JoylimJY/LecEvalä¸Šå‘å¸ƒäº†æ•°æ®é›†å’Œå·¥å…·åŒ…ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åŸºäºå¹»ç¯ç‰‡çš„å¤šåª’ä½“æ•™å­¦è¯„ä¼°ä¸­å­˜åœ¨çš„å¯æ‰©å±•æ€§å’Œä¸Šä¸‹æ–‡æ•æ‰ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¦‚äººå·¥è¯„ä¼°å’ŒåŸºäºå‚è€ƒçš„æŒ‡æ ‡åœ¨å®é™…åº”ç”¨ä¸­å­˜åœ¨å±€é™æ€§ï¼Œéš¾ä»¥æœ‰æ•ˆè¯„ä¼°å¤šæ¨¡æ€çŸ¥è¯†è·å–çš„è´¨é‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šLecEvalçš„æ ¸å¿ƒæ€è·¯æ˜¯åŸºäºæ¢…è€¶å°”çš„å¤šåª’ä½“å­¦ä¹ è®¤çŸ¥ç†è®ºï¼Œè®¾è®¡å‡ºä¸€ç§è‡ªåŠ¨åŒ–è¯„ä¼°æŒ‡æ ‡ï¼Œèƒ½å¤Ÿå…¨é¢è¯„ä¼°å¹»ç¯ç‰‡å†…å®¹çš„æœ‰æ•ˆæ€§ï¼Œæ¶µç›–å†…å®¹ç›¸å…³æ€§ã€è¡¨è¾¾æ¸…æ™°åº¦ã€é€»è¾‘ç»“æ„å’Œè§‚ä¼—å‚ä¸åº¦å››ä¸ªç»´åº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLecEvalçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚é¦–å…ˆï¼Œç ”ç©¶å›¢é˜Ÿæ•´ç†äº†ä¸€ä¸ªåŒ…å«2000å¤šå¼ å¹»ç¯ç‰‡çš„å¤§è§„æ¨¡æ•°æ®é›†ï¼Œå¹¶è¿›è¡Œç»†è‡´çš„äººç±»è¯„åˆ†ã€‚ç„¶åï¼ŒåŸºäºè¯¥æ•°æ®é›†è®­ç»ƒè¯„ä¼°æ¨¡å‹ï¼Œæœ€åé€šè¿‡æ¨¡å‹å¯¹æ–°å¹»ç¯ç‰‡è¿›è¡Œè‡ªåŠ¨åŒ–è¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šLecEvalçš„æœ€å¤§åˆ›æ–°åœ¨äºå…¶è‡ªåŠ¨åŒ–è¯„ä¼°èƒ½åŠ›ï¼Œèƒ½å¤Ÿåœ¨å¤šä¸ªç»´åº¦ä¸Šç»¼åˆè¯„ä¼°å¹»ç¯ç‰‡çš„æ•™å­¦æ•ˆæœï¼Œæ˜¾è‘—æé«˜äº†è¯„ä¼°çš„å‡†ç¡®æ€§å’Œé€‚åº”æ€§ï¼Œå¼¥è¡¥äº†ä¼ ç»Ÿæ–¹æ³•çš„ä¸è¶³ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç»†è‡´çš„è¯„åˆ†æ ‡å‡†å’ŒæŸå¤±å‡½æ•°ï¼Œä»¥ç¡®ä¿æ¨¡å‹èƒ½å¤Ÿå‡†ç¡®æ•æ‰åˆ°å¹»ç¯ç‰‡å†…å®¹çš„å¤šæ ·æ€§å’Œå¤æ‚æ€§ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLecEvalæ¨¡å‹åœ¨å‡†ç¡®æ€§å’Œé€‚åº”æ€§ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰è¯„ä¼°æŒ‡æ ‡ï¼Œå…·ä½“æ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼ŒæˆåŠŸå¼¥åˆäº†è‡ªåŠ¨åŒ–ä¸äººå·¥è¯„ä¼°ä¹‹é—´çš„å·®è·ï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

LecEvalçš„ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºåœ¨çº¿æ•™è‚²ã€åŸ¹è®­è¯¾ç¨‹å’Œå¤šåª’ä½“æ•™å­¦ç­‰é¢†åŸŸï¼Œå¸®åŠ©æ•™è‚²å·¥ä½œè€…å’Œè¯¾ç¨‹è®¾è®¡è€…æ›´æœ‰æ•ˆåœ°è¯„ä¼°å’Œä¼˜åŒ–æ•™å­¦å†…å®¹ã€‚æœªæ¥ï¼Œéšç€æ•™è‚²æŠ€æœ¯çš„å‘å±•ï¼Œè¯¥å·¥å…·æœ‰æœ›åœ¨æ›´å¤§èŒƒå›´å†…æ¨å¹¿ï¼Œæå‡å­¦ä¹ æ•ˆæœå’Œç”¨æˆ·ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Evaluating the quality of slide-based multimedia instruction is challenging. Existing methods like manual assessment, reference-based metrics, and large language model evaluators face limitations in scalability, context capture, or bias. In this paper, we introduce LecEval, an automated metric grounded in Mayer's Cognitive Theory of Multimedia Learning, to evaluate multimodal knowledge acquisition in slide-based learning. LecEval assesses effectiveness using four rubrics: Content Relevance (CR), Expressive Clarity (EC), Logical Structure (LS), and Audience Engagement (AE). We curate a large-scale dataset of over 2,000 slides from more than 50 online course videos, annotated with fine-grained human ratings across these rubrics. A model trained on this dataset demonstrates superior accuracy and adaptability compared to existing metrics, bridging the gap between automated and human assessments. We release our dataset and toolkits at https://github.com/JoylimJY/LecEval.

