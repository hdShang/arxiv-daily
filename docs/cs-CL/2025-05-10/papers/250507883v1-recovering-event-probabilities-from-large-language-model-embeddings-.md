---
layout: default
title: Recovering Event Probabilities from Large Language Model Embeddings via Axiomatic Constraints
---

# Recovering Event Probabilities from Large Language Model Embeddings via Axiomatic Constraints

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.07883" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.07883v1</a>
  <a href="https://arxiv.org/pdf/2505.07883.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.07883v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.07883v1', 'Recovering Event Probabilities from Large Language Model Embeddings via Axiomatic Constraints')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jian-Qiao Zhu, Haijiang Yan, Thomas L. Griffiths

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-10

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é€šè¿‡å…¬ç†çº¦æŸä»å¤§è¯­è¨€æ¨¡å‹åµŒå…¥ä¸­æ¢å¤äº‹ä»¶æ¦‚ç‡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `äº‹ä»¶æ¦‚ç‡` `å˜åˆ†è‡ªç¼–ç å™¨` `å…¬ç†çº¦æŸ` `æ½œåœ¨ç©ºé—´` `ä¸€è‡´æ€§` `å†³ç­–ç†è®º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„äº‹ä»¶æ¦‚ç‡å¸¸å¸¸ä¸ä¸€è‡´ï¼Œè¿åäº†æ¦‚ç‡ç†è®ºçš„åŸºæœ¬å…¬ç†ï¼Œå½±å“å†³ç­–çš„å‡†ç¡®æ€§ã€‚
2. æœ¬æ–‡æå‡ºé€šè¿‡æ‰©å±•çš„å˜åˆ†è‡ªç¼–ç å™¨æ–½åŠ å…¬ç†çº¦æŸï¼Œä»¥æ¢å¤æ½œåœ¨ç©ºé—´ä¸­çš„ä¸€è‡´äº‹ä»¶æ¦‚ç‡ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œä»åµŒå…¥ä¸­æ¢å¤çš„æ¦‚ç‡æ¯”ç›´æ¥ç”±æ¨¡å‹ç”Ÿæˆçš„æ¦‚ç‡æ›´å…·ä¸€è‡´æ€§ï¼Œå¹¶ä¸çœŸå®æ¦‚ç‡é«˜åº¦ä¸€è‡´ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨ä¸ç¡®å®šæ€§ä¸‹è¿›è¡Œç†æ€§å†³ç­–éœ€è¦å¯¹äº‹ä»¶çš„ä¿¡å¿µå…·æœ‰ä¸€è‡´æ€§ã€‚ç„¶è€Œï¼Œç°æœ‰çš„å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„äº‹ä»¶æ¦‚ç‡å¸¸å¸¸è¡¨ç°å‡ºä¸ä¸€è‡´æ€§ï¼Œè¿åäº†æ¦‚ç‡ç†è®ºçš„å…¬ç†ã€‚æœ¬æ–‡æ¢è®¨äº†æ˜¯å¦å¯ä»¥ä»æ¨¡å‹ä½¿ç”¨çš„åµŒå…¥ä¸­æ¢å¤ä¸€è‡´çš„äº‹ä»¶æ¦‚ç‡ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºåœ¨æ‰©å±•çš„å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEï¼‰ä¸­æ–½åŠ å…¬ç†çº¦æŸï¼Œå¦‚æ¦‚ç‡ç†è®ºçš„åŠ æ³•è§„åˆ™ï¼Œä»è€Œä½¿äº‹ä»¶æ¦‚ç‡åœ¨æ½œåœ¨ç©ºé—´ä¸­è‡ªç„¶å‡ºç°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä»åµŒå…¥ä¸­æ¢å¤çš„æ¦‚ç‡æ¯”æ¨¡å‹ç›´æ¥æŠ¥å‘Šçš„æ¦‚ç‡æ›´å…·ä¸€è‡´æ€§ï¼Œå¹¶ä¸çœŸå®æ¦‚ç‡ç´§å¯†å¯¹é½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„äº‹ä»¶æ¦‚ç‡ä¸ä¸€è‡´çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½æ»¡è¶³æ¦‚ç‡ç†è®ºçš„å…¬ç†ï¼Œå¯¼è‡´å†³ç­–ä¸å‡†ç¡®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡åœ¨å˜åˆ†è‡ªç¼–ç å™¨ä¸­æ–½åŠ å…¬ç†çº¦æŸï¼Œç‰¹åˆ«æ˜¯åŠ æ³•è§„åˆ™ï¼Œæ¥æ¢å¤æ½œåœ¨ç©ºé—´ä¸­çš„ä¸€è‡´äº‹ä»¶æ¦‚ç‡ï¼Œä½¿å¾—æ¨¡å‹åœ¨é‡æ„åµŒå…¥çš„åŒæ—¶èƒ½å¤Ÿé¢„æµ‹ç›¸å…³äº‹ä»¶çš„åµŒå…¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸€ä¸ªæ‰©å±•çš„å˜åˆ†è‡ªç¼–ç å™¨ï¼Œä¸»è¦æ¨¡å—åŒ…æ‹¬åµŒå…¥é‡æ„æ¨¡å—å’Œäº‹ä»¶åµŒå…¥é¢„æµ‹æ¨¡å—ã€‚æ¨¡å‹é€šè¿‡å­¦ä¹ é‡æ„åŸå§‹åµŒå…¥å’Œé¢„æµ‹è¯­ä¹‰ç›¸å…³äº‹ä»¶çš„åµŒå…¥æ¥å®ç°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†å…¬ç†çº¦æŸå¼•å…¥åˆ°æ½œåœ¨ç©ºé—´çš„å­¦ä¹ ä¸­ï¼Œä½¿å¾—äº‹ä»¶æ¦‚ç‡èƒ½å¤Ÿè‡ªç„¶åœ°ä»åµŒå…¥ä¸­æ¢å¤ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—æé«˜äº†æ¦‚ç‡çš„ä¸€è‡´æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡é‡æ„è¯¯å·®å’Œå…¬ç†çº¦æŸçš„æ»¡è¶³ç¨‹åº¦ï¼ŒåŒæ—¶ä¼˜åŒ–äº†ç½‘ç»œç»“æ„ä»¥æé«˜å­¦ä¹ æ•ˆç‡ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œå±‚æ¬¡ç»“æ„åœ¨å®éªŒä¸­è¿›è¡Œäº†è¯¦ç»†è°ƒä¼˜ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä»åµŒå…¥ä¸­æ¢å¤çš„äº‹ä»¶æ¦‚ç‡åœ¨ä¸€è‡´æ€§ä¸Šæ˜¾è‘—ä¼˜äºç›´æ¥ç”±æ¨¡å‹ç”Ÿæˆçš„æ¦‚ç‡ï¼Œå…·ä½“è¡¨ç°ä¸ºæ¢å¤çš„æ¦‚ç‡ä¸çœŸå®æ¦‚ç‡çš„å¯¹é½åº¦æ›´é«˜ï¼Œæå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬é‡‘èå†³ç­–ã€åŒ»ç–—è¯Šæ–­å’Œè‡ªåŠ¨åŒ–æ¨ç†ç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿä¸ºä¸ç¡®å®šæ€§å†³ç­–æä¾›æ›´å‡†ç¡®çš„æ¦‚ç‡ä¼°è®¡ï¼Œæå‡å†³ç­–çš„å¯é æ€§å’Œæœ‰æ•ˆæ€§ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½åœ¨å¤šç§åŸºäºè¯­è¨€æ¨¡å‹çš„åº”ç”¨ä¸­å¾—åˆ°æ¨å¹¿ï¼Œæ”¹å–„æ¨¡å‹çš„è¾“å‡ºä¸€è‡´æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Rational decision-making under uncertainty requires coherent degrees of belief in events. However, event probabilities generated by Large Language Models (LLMs) have been shown to exhibit incoherence, violating the axioms of probability theory. This raises the question of whether coherent event probabilities can be recovered from the embeddings used by the models. If so, those derived probabilities could be used as more accurate estimates in events involving uncertainty. To explore this question, we propose enforcing axiomatic constraints, such as the additive rule of probability theory, in the latent space learned by an extended variational autoencoder (VAE) applied to LLM embeddings. This approach enables event probabilities to naturally emerge in the latent space as the VAE learns to both reconstruct the original embeddings and predict the embeddings of semantically related events. We evaluate our method on complementary events (i.e., event A and its complement, event not-A), where the true probabilities of the two events must sum to 1. Experiment results on open-weight language models demonstrate that probabilities recovered from embeddings exhibit greater coherence than those directly reported by the corresponding models and align closely with the true probabilities.

