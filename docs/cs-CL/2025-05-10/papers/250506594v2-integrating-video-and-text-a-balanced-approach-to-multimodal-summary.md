---
layout: default
title: Integrating Video and Text: A Balanced Approach to Multimodal Summary Generation and Evaluation
---

# Integrating Video and Text: A Balanced Approach to Multimodal Summary Generation and Evaluation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.06594" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.06594v2</a>
  <a href="https://arxiv.org/pdf/2505.06594.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.06594v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.06594v2', 'Integrating Video and Text: A Balanced Approach to Multimodal Summary Generation and Evaluation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Galann Pennec, Zhengyuan Liu, Nicholas Asher, Philippe Muller, Nancy F. Chen

**åˆ†ç±»**: cs.CL, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-10 (æ›´æ–°: 2025-10-31)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé›¶-shotè§†é¢‘åˆ°æ–‡æœ¬æ‘˜è¦ç”Ÿæˆæ–¹æ³•ä»¥è§£å†³å¤šæ¨¡æ€ä¿¡æ¯æ•´åˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ‘˜è¦` `è§†è§‰-è¯­è¨€æ¨¡å‹` `é›¶-shotå­¦ä¹ ` `å‰§æœ¬ç”Ÿæˆ` `è§†é¢‘ç†è§£` `è¯„ä¼°æŒ‡æ ‡` `ä¿¡æ¯æ•´åˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨å¤„ç†å¤æ‚çš„å¤šæ¨¡æ€è¾“å…¥æ—¶ï¼Œéš¾ä»¥æœ‰æ•ˆæ•´åˆè§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯ï¼Œå¯¼è‡´æ‘˜è¦è´¨é‡ä¸é«˜ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§é›¶-shotè§†é¢‘åˆ°æ–‡æœ¬æ‘˜è¦ç”Ÿæˆæ–¹æ³•ï¼Œé€šè¿‡æ„å»ºå‰§æœ¬è¡¨ç¤ºæ¥æ•´åˆè§†é¢‘æ—¶åˆ»ã€å¯¹è¯å’Œè§’è‰²ä¿¡æ¯ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨MFactSumè¯„ä¼°çš„æ‘˜è¦åœ¨è§†è§‰ä¿¡æ¯ç›¸å…³æ€§ä¸Šæå‡äº†20%ï¼Œä¸”è§†é¢‘è¾“å…¥éœ€æ±‚å‡å°‘äº†75%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨æ€»ç»“å¤æ‚çš„å¤šæ¨¡æ€è¾“å…¥ï¼ˆå¦‚æ•´ä¸ªç”µè§†èŠ‚ç›®é›†ï¼‰æ—¶ï¼Œå¸¸å¸¸éš¾ä»¥å¹³è¡¡è§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§é›¶-shotè§†é¢‘åˆ°æ–‡æœ¬çš„æ‘˜è¦ç”Ÿæˆæ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ„å»ºäº†å‰§æœ¬è¡¨ç¤ºï¼Œæœ‰æ•ˆæ•´åˆäº†å…³é”®è§†é¢‘æ—¶åˆ»ã€å¯¹è¯å’Œè§’è‰²ä¿¡æ¯ã€‚ä¸ä»¥å¾€æ–¹æ³•ä¸åŒï¼Œæˆ‘ä»¬åœ¨é›¶-shotæ¡ä»¶ä¸‹åŒæ—¶ç”Ÿæˆå‰§æœ¬å¹¶å‘½åè§’è‰²ï¼Œä»…ä½¿ç”¨éŸ³é¢‘ã€è§†é¢‘å’Œè½¬å½•æ–‡æœ¬ä½œä¸ºè¾“å…¥ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æŒ‡å‡ºç°æœ‰çš„æ‘˜è¦è¯„ä¼°æŒ‡æ ‡æ— æ³•æœ‰æ•ˆè¯„ä¼°å¤šæ¨¡æ€å†…å®¹ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†MFactSumï¼Œè¿™æ˜¯ä¸€ç§å¤šæ¨¡æ€æŒ‡æ ‡ï¼Œèƒ½å¤ŸåŒæ—¶è¯„ä¼°è§†è§‰å’Œæ–‡æœ¬æ¨¡æ€çš„æ‘˜è¦ã€‚é€šè¿‡MFactSumï¼Œæˆ‘ä»¬åœ¨SummScreen3Dæ•°æ®é›†ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„å‰§æœ¬æ‘˜è¦ï¼Œç»“æœæ˜¾ç¤ºå…¶åœ¨ç”ŸæˆåŒ…å«20%æ›´å¤šç›¸å…³è§†è§‰ä¿¡æ¯çš„æ‘˜è¦æ—¶ï¼Œæ‰€éœ€è§†é¢‘è¾“å…¥å‡å°‘äº†75%ï¼Œä¼˜äºå½“å‰æœ€å…ˆè¿›çš„VLMsï¼Œå¦‚Gemini 1.5ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨å¤šæ¨¡æ€æ‘˜è¦ç”Ÿæˆä¸­æ— æ³•æœ‰æ•ˆæ•´åˆè§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯çš„é—®é¢˜ï¼Œå¯¼è‡´ç”Ÿæˆçš„æ‘˜è¦ç¼ºä¹ç›¸å…³æ€§å’Œå®Œæ•´æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºäº†ä¸€ç§é›¶-shotçš„æ‘˜è¦ç”Ÿæˆæ–¹æ³•ï¼Œé€šè¿‡æ„å»ºå‰§æœ¬è¡¨ç¤ºæ¥åŒæ—¶ç”Ÿæˆæ‘˜è¦å’Œè§’è‰²å‘½åï¼Œåˆ©ç”¨éŸ³é¢‘ã€è§†é¢‘å’Œè½¬å½•æ–‡æœ¬ä½œä¸ºè¾“å…¥ï¼Œé¿å…äº†å¯¹æ ‡æ³¨æ•°æ®çš„ä¾èµ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šè§†é¢‘åˆ†ææ¨¡å—ã€æ–‡æœ¬ç”Ÿæˆæ¨¡å—å’Œå¤šæ¨¡æ€è¯„ä¼°æ¨¡å—ã€‚è§†é¢‘åˆ†ææ¨¡å—æå–å…³é”®æ—¶åˆ»å’Œå¯¹è¯ï¼Œæ–‡æœ¬ç”Ÿæˆæ¨¡å—è´Ÿè´£ç”Ÿæˆå‰§æœ¬ï¼Œè¯„ä¼°æ¨¡å—ä½¿ç”¨MFactSumè¿›è¡Œè´¨é‡è¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºåŒæ—¶ç”Ÿæˆå‰§æœ¬å’Œè§’è‰²å‘½åçš„èƒ½åŠ›ï¼Œä¸”åœ¨é›¶-shotæ¡ä»¶ä¸‹è¿›è¡Œï¼Œæ˜¾è‘—æå‡äº†æ‘˜è¦çš„å¤šæ¨¡æ€æ•´åˆèƒ½åŠ›ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œå‡å°‘äº†å¯¹æ ‡æ³¨æ•°æ®çš„ä¾èµ–ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡è§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯çš„æƒé‡ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸­å¼•å…¥äº†å¤šæ¨¡æ€èåˆå±‚ï¼Œä»¥å¢å¼ºä¿¡æ¯çš„äº¤äº’å’Œæ•´åˆã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨MFactSumè¯„ä¼°çš„æ‘˜è¦åœ¨è§†è§‰ä¿¡æ¯ç›¸å…³æ€§ä¸Šæå‡äº†20%ï¼ŒåŒæ—¶æ‰€éœ€çš„è§†é¢‘è¾“å…¥é‡å‡å°‘äº†75%ã€‚ä¸å½“å‰æœ€å…ˆè¿›çš„VLMsï¼ˆå¦‚Gemini 1.5ï¼‰ç›¸æ¯”ï¼Œæœ¬æ–‡æ–¹æ³•åœ¨å¤šæ¨¡æ€æ‘˜è¦ç”Ÿæˆä¸Šè¡¨ç°å‡ºæ˜¾è‘—çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å½±è§†å†…å®¹çš„è‡ªåŠ¨æ‘˜è¦ç”Ÿæˆã€æ•™è‚²è§†é¢‘çš„å†…å®¹æç‚¼ä»¥åŠç¤¾äº¤åª’ä½“è§†é¢‘çš„å¿«é€Ÿä¿¡æ¯è·å–ã€‚é€šè¿‡æé«˜æ‘˜è¦çš„è´¨é‡å’Œç›¸å…³æ€§ï¼Œå¯ä»¥ä¸ºç”¨æˆ·æä¾›æ›´é«˜æ•ˆçš„ä¿¡æ¯è·å–æ–¹å¼ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision-Language Models (VLMs) often struggle to balance visual and textual information when summarizing complex multimodal inputs, such as entire TV show episodes. In this paper, we propose a zero-shot video-to-text summarization approach that builds its own screenplay representation of an episode, effectively integrating key video moments, dialogue, and character information into a unified document. Unlike previous approaches, we simultaneously generate screenplays and name the characters in zero-shot, using only the audio, video, and transcripts as input. Additionally, we highlight that existing summarization metrics can fail to assess the multimodal content in summaries. To address this, we introduce MFactSum, a multimodal metric that evaluates summaries with respect to both vision and text modalities. Using MFactSum, we evaluate our screenplay summaries on the SummScreen3D dataset, demonstrating superiority against state-of-the-art VLMs such as Gemini 1.5 by generating summaries containing 20% more relevant visual information while requiring 75% less of the video as input.

