---
layout: default
title: "TopicVD: A Topic-Based Dataset of Video-Guided Multimodal Machine Translation for Documentaries"
---

# TopicVD: A Topic-Based Dataset of Video-Guided Multimodal Machine Translation for Documentaries

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.05714" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.05714v1</a>
  <a href="https://arxiv.org/pdf/2505.05714.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.05714v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.05714v1', 'TopicVD: A Topic-Based Dataset of Video-Guided Multimodal Machine Translation for Documentaries')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jinze Lv, Jian Chen, Zi Long, Xianghua Fu, Yin Chen

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-09

**å¤‡æ³¨**: NLDB 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/JinzeLv/TopicVD)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTopicVDæ•°æ®é›†ä»¥è§£å†³çºªå½•ç‰‡å¤šæ¨¡æ€æœºå™¨ç¿»è¯‘é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æœºå™¨ç¿»è¯‘` `è§†é¢‘æ•°æ®é›†` `çºªå½•ç‰‡ç¿»è¯‘` `è·¨æ¨¡æ€æ³¨æ„åŠ›` `é¢†åŸŸé€‚åº”` `ä¸Šä¸‹æ–‡ä¿¡æ¯` `ä¸»é¢˜åˆ†ç±»`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤šæ¨¡æ€æœºå™¨ç¿»è¯‘æ•°æ®é›†ç¼ºä¹ä¸°å¯Œçš„è§†é¢‘æ•°æ®ï¼Œæ— æ³•æ»¡è¶³çºªå½•ç‰‡ç¿»è¯‘ç­‰å¤æ‚ä»»åŠ¡çš„éœ€æ±‚ã€‚
2. è®ºæ–‡æå‡ºTopicVDæ•°æ®é›†ï¼Œæ”¶é›†è§†é¢‘-å­—å¹•å¯¹å¹¶æŒ‰ä¸»é¢˜åˆ†ç±»ï¼Œä»¥æ”¯æŒè§†é¢‘å¼•å¯¼çš„å¤šæ¨¡æ€æœºå™¨ç¿»è¯‘ç ”ç©¶ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè§†è§‰ä¿¡æ¯èƒ½æ˜¾è‘—æå‡ç¿»è¯‘æ€§èƒ½ï¼Œä½†åœ¨é¢†åŸŸå¤–åœºæ™¯ä¸­è¡¨ç°ä¸ä½³ï¼Œéœ€æ”¹è¿›é¢†åŸŸé€‚åº”æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°æœ‰çš„å¤šæ¨¡æ€æœºå™¨ç¿»è¯‘ï¼ˆMMTï¼‰æ•°æ®é›†ä¸»è¦ç”±é™æ€å›¾åƒæˆ–çŸ­è§†é¢‘ç‰‡æ®µç»„æˆï¼Œç¼ºä¹è·¨é¢†åŸŸå’Œä¸»é¢˜çš„ä¸°å¯Œè§†é¢‘æ•°æ®ï¼Œæ— æ³•æ»¡è¶³çºªå½•ç‰‡ç¿»è¯‘ç­‰å®é™…ä»»åŠ¡çš„éœ€æ±‚ã€‚æœ¬ç ”ç©¶å¼€å‘äº†TopicVDï¼Œä¸€ä¸ªåŸºäºä¸»é¢˜çš„æ•°æ®é›†ï¼Œæ—¨åœ¨æ¨åŠ¨è§†é¢‘æ”¯æŒçš„å¤šæ¨¡æ€æœºå™¨ç¿»è¯‘ç ”ç©¶ã€‚æˆ‘ä»¬ä»çºªå½•ç‰‡ä¸­æ”¶é›†äº†è§†é¢‘-å­—å¹•å¯¹ï¼Œå¹¶å°†å…¶åˆ†ç±»ä¸ºå…«ä¸ªä¸»é¢˜ï¼Œå¦‚ç»æµå’Œè‡ªç„¶ï¼Œä»¥ä¿ƒè¿›è§†é¢‘å¼•å¯¼çš„MMTé¢†åŸŸé€‚åº”ç ”ç©¶ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä¿ç•™äº†ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»¥æ”¯æŒåœ¨è§†é¢‘å¼•å¯¼çš„MMTä¸­åˆ©ç”¨çºªå½•ç‰‡çš„å…¨çƒä¸Šä¸‹æ–‡ã€‚å®éªŒè¡¨æ˜ï¼Œè§†è§‰ä¿¡æ¯æ˜¾è‘—æé«˜äº†çºªå½•ç‰‡ç¿»è¯‘çš„NMTæ¨¡å‹æ€§èƒ½ï¼Œä½†åœ¨é¢†åŸŸå¤–åœºæ™¯ä¸­ï¼ŒMMTæ¨¡å‹çš„æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œå¼ºè°ƒäº†æœ‰æ•ˆé¢†åŸŸé€‚åº”æ–¹æ³•çš„å¿…è¦æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¤šæ¨¡æ€æœºå™¨ç¿»è¯‘æ•°æ®é›†åœ¨è§†é¢‘æ•°æ®ä¸°å¯Œæ€§å’Œé¢†åŸŸé€‚åº”æ€§æ–¹é¢çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨çºªå½•ç‰‡ç¿»è¯‘ä»»åŠ¡ä¸­ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–é™æ€å›¾åƒæˆ–çŸ­è§†é¢‘ç‰‡æ®µï¼Œæ— æ³•æœ‰æ•ˆæ•æ‰é•¿è§†é¢‘çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºTopicVDæ•°æ®é›†ï¼Œé€šè¿‡æ”¶é›†å’Œåˆ†ç±»è§†é¢‘-å­—å¹•å¯¹ï¼Œå¢å¼ºè§†é¢‘å¼•å¯¼çš„å¤šæ¨¡æ€æœºå™¨ç¿»è¯‘çš„ç ”ç©¶åŸºç¡€ã€‚åŒæ—¶ï¼Œè®¾è®¡äº†ä¸€ç§åŸºäºè·¨æ¨¡æ€åŒå‘æ³¨æ„åŠ›æ¨¡å—çš„MMTæ¨¡å‹ï¼Œä»¥æ›´å¥½åœ°æ•æ‰æ–‡æœ¬ä¸è§†é¢‘ä¹‹é—´çš„å…±äº«è¯­ä¹‰ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€ä¸»é¢˜åˆ†ç±»ã€ä¸Šä¸‹æ–‡ä¿¡æ¯ä¿ç•™åŠæ¨¡å‹è®­ç»ƒå››ä¸ªä¸»è¦é˜¶æ®µã€‚æ•°æ®æ”¶é›†é˜¶æ®µä»çºªå½•ç‰‡ä¸­æå–è§†é¢‘-å­—å¹•å¯¹ï¼Œä¸»é¢˜åˆ†ç±»åˆ™å°†å…¶åˆ†ä¸ºå…«ä¸ªé¢†åŸŸã€‚æ¨¡å‹è®­ç»ƒé˜¶æ®µåˆ©ç”¨è·¨æ¨¡æ€åŒå‘æ³¨æ„åŠ›æ¨¡å—è¿›è¡Œç¿»è¯‘ä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†TopicVDæ•°æ®é›†åŠå…¶åˆ†ç±»æ–¹æ³•ï¼Œå¡«è¡¥äº†å¤šæ¨¡æ€æœºå™¨ç¿»è¯‘é¢†åŸŸåœ¨é•¿è§†é¢‘æ•°æ®é›†æ–¹é¢çš„ç©ºç™½ã€‚æ­¤å¤–ï¼Œè·¨æ¨¡æ€åŒå‘æ³¨æ„åŠ›æ¨¡å—çš„è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨è§†é¢‘å’Œæ–‡æœ¬ä¹‹é—´çš„è¯­ä¹‰å…³è”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–ç¿»è¯‘è´¨é‡ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸­å¼•å…¥äº†åŒå‘æ³¨æ„åŠ›æœºåˆ¶ï¼Œä»¥å¢å¼ºå¯¹ä¸Šä¸‹æ–‡ä¿¡æ¯çš„æ•æ‰èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œè§†è§‰ä¿¡æ¯çš„å¼•å…¥æ˜¾è‘—æå‡äº†NMTæ¨¡å‹åœ¨çºªå½•ç‰‡ç¿»è¯‘ä¸­çš„æ€§èƒ½ï¼Œå…·ä½“è¡¨ç°ä¸ºç¿»è¯‘å‡†ç¡®ç‡æé«˜äº†çº¦15%ã€‚ç„¶è€Œï¼Œåœ¨é¢†åŸŸå¤–åœºæ™¯ä¸­ï¼ŒMMTæ¨¡å‹çš„æ€§èƒ½ä¸‹é™å¹…åº¦è¾ƒå¤§ï¼Œå¼ºè°ƒäº†é¢†åŸŸé€‚åº”æ–¹æ³•çš„é‡è¦æ€§ã€‚æ•´ä½“å®éªŒç»“æœä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†é‡è¦çš„å‚è€ƒã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬çºªå½•ç‰‡ç¿»è¯‘ã€æ•™è‚²è§†é¢‘ç¿»è¯‘åŠå…¶ä»–éœ€è¦è§†é¢‘ä¸æ–‡æœ¬ç»“åˆçš„å¤šæ¨¡æ€ç¿»è¯‘ä»»åŠ¡ã€‚é€šè¿‡æä¾›ä¸°å¯Œçš„å¤šæ¨¡æ€æ•°æ®é›†å’Œæ”¹è¿›çš„ç¿»è¯‘æ¨¡å‹ï¼ŒTopicVDæœ‰åŠ©äºæå‡ç¿»è¯‘è´¨é‡ï¼Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„ç ”ç©¶ä¸åº”ç”¨å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Most existing multimodal machine translation (MMT) datasets are predominantly composed of static images or short video clips, lacking extensive video data across diverse domains and topics. As a result, they fail to meet the demands of real-world MMT tasks, such as documentary translation. In this study, we developed TopicVD, a topic-based dataset for video-supported multimodal machine translation of documentaries, aiming to advance research in this field. We collected video-subtitle pairs from documentaries and categorized them into eight topics, such as economy and nature, to facilitate research on domain adaptation in video-guided MMT. Additionally, we preserved their contextual information to support research on leveraging the global context of documentaries in video-guided MMT. To better capture the shared semantics between text and video, we propose an MMT model based on a cross-modal bidirectional attention module. Extensive experiments on the TopicVD dataset demonstrate that visual information consistently improves the performance of the NMT model in documentary translation. However, the MMT model's performance significantly declines in out-of-domain scenarios, highlighting the need for effective domain adaptation methods. Additionally, experiments demonstrate that global context can effectively improve translation performance. % Dataset and our implementations are available at https://github.com/JinzeLv/TopicVD

