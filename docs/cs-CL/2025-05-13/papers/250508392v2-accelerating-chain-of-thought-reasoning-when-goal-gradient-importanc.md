---
layout: default
title: Accelerating Chain-of-Thought Reasoning: When Goal-Gradient Importance Meets Dynamic Skipping
---

# Accelerating Chain-of-Thought Reasoning: When Goal-Gradient Importance Meets Dynamic Skipping

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.08392" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.08392v2</a>
  <a href="https://arxiv.org/pdf/2505.08392.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.08392v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.08392v2', 'Accelerating Chain-of-Thought Reasoning: When Goal-Gradient Importance Meets Dynamic Skipping')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ren Zhuang, Ben Wang, Shuifa Sun

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-13 (æ›´æ–°: 2025-05-17)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAdaptive GoGI-Skipä»¥è§£å†³é•¿æ–‡æœ¬æ¨ç†æ•ˆç‡ä½ä¸‹é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é“¾å¼æ€ç»´` `åŠ¨æ€å‹ç¼©` `ç›®æ ‡æ¢¯åº¦é‡è¦æ€§` `è‡ªé€‚åº”è·³è¿‡` `æ¨ç†æ•ˆç‡` `è‡ªç„¶è¯­è¨€å¤„ç†` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„é“¾å¼æ€ç»´æ¨ç†æ–¹æ³•åœ¨å¤„ç†å¤æ‚ä»»åŠ¡æ—¶ï¼Œæ¨ç†è¿‡ç¨‹å¾€å¾€å†—é•¿ä¸”æ•ˆç‡ä½ä¸‹ï¼Œå¯¼è‡´è®¡ç®—èµ„æºæµªè´¹ã€‚
2. è®ºæ–‡æå‡ºçš„Adaptive GoGI-Skipæ¡†æ¶é€šè¿‡å¼•å…¥ç›®æ ‡æ¢¯åº¦é‡è¦æ€§å’Œè‡ªé€‚åº”åŠ¨æ€è·³è¿‡æœºåˆ¶ï¼Œå®ç°äº†åŠ¨æ€çš„CoTå‹ç¼©ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªæ¨ç†åŸºå‡†ä¸Šæ˜¾è‘—æå‡äº†æ•ˆç‡ï¼Œå¹³å‡å‡å°‘äº†45%çš„æ ‡è®°æ•°é‡ï¼Œå¹¶å®ç°äº†1.6-2.0å€çš„æ¨ç†é€Ÿåº¦æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹åˆ©ç”¨é“¾å¼æ€ç»´ï¼ˆCoTï¼‰æç¤ºè¿›è¡Œå¤æ‚ä»»åŠ¡ï¼Œä½†å…¶æ¨ç†è¿‡ç¨‹å¾€å¾€å†—é•¿ä¸”ä½æ•ˆï¼Œå¯¼è‡´æ˜¾è‘—çš„è®¡ç®—æˆæœ¬å’Œå»¶è¿Ÿã€‚ç›®å‰çš„CoTå‹ç¼©æŠ€æœ¯é€šå¸¸ä¾èµ–äºé€šç”¨çš„é‡è¦æ€§æŒ‡æ ‡å’Œé™æ€å‹ç¼©ç‡ï¼Œå¯èƒ½ä¼šæ— æ„ä¸­åˆ é™¤åŠŸèƒ½å…³é”®çš„æ ‡è®°æˆ–æ— æ³•é€‚åº”ä¸åŒçš„æ¨ç†å¤æ‚æ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†Adaptive GoGI-Skipï¼Œä¸€ä¸ªé€šè¿‡ç›‘ç£å¾®è°ƒå­¦ä¹ åŠ¨æ€CoTå‹ç¼©çš„æ–°æ¡†æ¶ã€‚è¯¥æ–¹æ³•å¼•å…¥äº†ä¸¤ä¸ªååŒåˆ›æ–°ï¼šç›®æ ‡æ¢¯åº¦é‡è¦æ€§ï¼ˆGoGIï¼‰ï¼Œé€šè¿‡æµ‹é‡ä¸­é—´è¡¨ç¤ºå¯¹æœ€ç»ˆç­”æ¡ˆæŸå¤±çš„æ¢¯åº¦å½±å“ï¼Œå‡†ç¡®è¯†åˆ«åŠŸèƒ½ç›¸å…³çš„æ ‡è®°ï¼›è‡ªé€‚åº”åŠ¨æ€è·³è¿‡ï¼ˆADSï¼‰ï¼Œæ ¹æ®è¿è¡Œæ—¶æ¨¡å‹çš„ä¸ç¡®å®šæ€§åŠ¨æ€è°ƒèŠ‚å‹ç¼©ç‡ï¼ŒåŒæ—¶é€šè¿‡è‡ªé€‚åº”Næ ‡è®°çº¦æŸç¡®ä¿å±€éƒ¨ä¸€è‡´æ€§ã€‚ç»è¿‡å‹ç¼©çš„MATHæ•°æ®è®­ç»ƒï¼ŒAdaptive GoGI-Skipåœ¨å¤šä¸ªæ¨ç†åŸºå‡†ä¸Šè¡¨ç°å‡ºå¼ºå¤§çš„è·¨é¢†åŸŸæ³›åŒ–èƒ½åŠ›ï¼Œå¹³å‡å‡å°‘CoTæ ‡è®°æ•°é‡è¶…è¿‡45%ï¼Œæ¨ç†é€Ÿåº¦æå‡1.6-2.0å€ï¼ŒåŒæ—¶ä¿æŒé«˜æ¨ç†å‡†ç¡®æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é“¾å¼æ€ç»´æ¨ç†ä¸­çš„å†—é•¿å’Œä½æ•ˆé—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¸¸ä¾èµ–é™æ€å‹ç¼©ç‡ï¼Œå¯èƒ½ä¼šåˆ é™¤å…³é”®æ ‡è®°æˆ–æ— æ³•é€‚åº”æ¨ç†å¤æ‚æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºAdaptive GoGI-Skipæ¡†æ¶ï¼Œé€šè¿‡ç›‘ç£å¾®è°ƒå®ç°åŠ¨æ€CoTå‹ç¼©ã€‚æ ¸å¿ƒåœ¨äºå¼•å…¥ç›®æ ‡æ¢¯åº¦é‡è¦æ€§ï¼ˆGoGIï¼‰å’Œè‡ªé€‚åº”åŠ¨æ€è·³è¿‡ï¼ˆADSï¼‰ï¼Œä»¥æé«˜æ¨ç†æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯GoGIæ¨¡å—ï¼Œé€šè¿‡è®¡ç®—ä¸­é—´è¡¨ç¤ºå¯¹æœ€ç»ˆç­”æ¡ˆæŸå¤±çš„å½±å“æ¥è¯†åˆ«é‡è¦æ ‡è®°ï¼›å…¶æ¬¡æ˜¯ADSæ¨¡å—ï¼Œæ ¹æ®æ¨¡å‹çš„ä¸ç¡®å®šæ€§åŠ¨æ€è°ƒæ•´å‹ç¼©ç‡ï¼Œç¡®ä¿æ¨ç†è¿‡ç¨‹çš„å±€éƒ¨ä¸€è‡´æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„ä¸»è¦åˆ›æ–°åœ¨äºå°†ç›®æ ‡å¯¼å‘çš„æ¢¯åº¦é‡è¦æ€§åº¦é‡ä¸åŠ¨æ€ã€ä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„è·³è¿‡æœºåˆ¶ç›¸ç»“åˆï¼Œè¿™æ˜¯é¦–æ¬¡åœ¨CoTå‹ç¼©ä¸­å®ç°è¿™ç§ç»Ÿä¸€ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒGoGIé€šè¿‡æ¢¯åº¦è®¡ç®—æ¥è¯„ä¼°æ ‡è®°çš„é‡è¦æ€§ï¼ŒADSåˆ™ä½¿ç”¨è‡ªé€‚åº”Næ ‡è®°çº¦æŸæ¥è°ƒèŠ‚å‹ç¼©ç‡ï¼Œç¡®ä¿åœ¨é«˜å‹ç¼©ç‡ä¸‹ä»èƒ½ä¿æŒæ¨ç†çš„å‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAdaptive GoGI-Skipåœ¨å¤šä¸ªæ¨ç†åŸºå‡†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå¹³å‡å‡å°‘CoTæ ‡è®°æ•°é‡è¶…è¿‡45%ï¼Œæ¨ç†é€Ÿåº¦æå‡1.6-2.0å€ï¼Œä¸”åœ¨é«˜å‹ç¼©ç‡ä¸‹ä»èƒ½ä¿æŒé«˜å‡†ç¡®æ€§ï¼Œæ˜¾è‘—è¶…è¶Šç°æœ‰åŸºçº¿ï¼Œæ¨åŠ¨äº†CoTæ¨ç†æ•ˆç‡ä¸å‡†ç¡®æ€§çš„å¹³è¡¡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æ™ºèƒ½é—®ç­”ç³»ç»Ÿå’Œæ•™è‚²æŠ€æœ¯ç­‰ã€‚é€šè¿‡æé«˜æ¨ç†æ•ˆç‡ï¼ŒAdaptive GoGI-Skipèƒ½å¤Ÿåœ¨èµ„æºæœ‰é™çš„ç¯å¢ƒä¸­å®ç°æ›´å¿«çš„å“åº”æ—¶é—´ï¼Œæå‡ç”¨æˆ·ä½“éªŒï¼Œæœªæ¥å¯èƒ½åœ¨å®æ—¶æ¨ç†å’Œå¤§è§„æ¨¡åº”ç”¨ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models leverage Chain-of-Thought (CoT) prompting for complex tasks, but their reasoning traces are often excessively verbose and inefficient, leading to significant computational costs and latency. Current CoT compression techniques typically rely on generic importance metrics and static compression rates, which may inadvertently remove functionally critical tokens or fail to adapt to varying reasoning complexity. To overcome these limitations, we propose Adaptive GoGI-Skip, a novel framework learning dynamic CoT compression via supervised fine-tuning. This approach introduces two synergistic innovations: (1) Goal-Gradient Importance (GoGI), a novel metric accurately identifying functionally relevant tokens by measuring the gradient influence of their intermediate representations on the final answer loss, and (2) Adaptive Dynamic Skipping (ADS), a mechanism dynamically regulating the compression rate based on runtime model uncertainty while ensuring local coherence through an adaptive N-token constraint. To our knowledge, this is the first work unifying a goal-oriented, gradient-based importance metric with dynamic, uncertainty-aware skipping for CoT compression. Trained on compressed MATH data, Adaptive GoGI-Skip demonstrates strong cross-domain generalization across diverse reasoning benchmarks including AIME, GPQA, and GSM8K. It achieves substantial efficiency gains - reducing CoT token counts by over 45% on average and delivering 1.6-2.0 times inference speedups - while maintaining high reasoning accuracy. Notably, it significantly outperforms existing baselines by preserving accuracy even at high effective compression rates, advancing the state of the art in the CoT reasoning efficiency-accuracy trade-off.

