---
layout: default
title: Large Language Model Psychometrics: A Systematic Review of Evaluation, Validation, and Enhancement
---

# Large Language Model Psychometrics: A Systematic Review of Evaluation, Validation, and Enhancement

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.08245" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.08245v2</a>
  <a href="https://arxiv.org/pdf/2505.08245.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.08245v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.08245v2', 'Large Language Model Psychometrics: A Systematic Review of Evaluation, Validation, and Enhancement')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Haoran Ye, Jing Jin, Yuhang Xie, Xin Zhang, Guojie Song

**åˆ†ç±»**: cs.CL, cs.AI, cs.HC

**å‘å¸ƒæ—¥æœŸ**: 2025-05-13 (æ›´æ–°: 2025-07-13)

**å¤‡æ³¨**: 474 references

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/valuebyte-ai/Awesome-LLM-Psychometrics)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤§è¯­è¨€æ¨¡å‹å¿ƒç†æµ‹é‡æ–¹æ³•ä»¥è§£å†³è¯„ä¼°ä¸éªŒè¯æŒ‘æˆ˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `å¿ƒç†æµ‹é‡` `è¯„ä¼°æ–¹æ³•` `è·¨å­¦ç§‘ç ”ç©¶` `äººæœ¬AI` `ç¤¾ä¼šå½±å“`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è¯„ä¼°æ–¹æ³•æ— æ³•æœ‰æ•ˆæµ‹é‡å¤§è¯­è¨€æ¨¡å‹çš„äººç±»å¿ƒç†ç‰¹å¾ï¼Œä¸”ç¼ºä¹ä»¥äººä¸ºæœ¬çš„è¯„ä¼°ä½“ç³»ã€‚
2. è®ºæ–‡æå‡ºç»“åˆå¿ƒç†æµ‹é‡å­¦çš„å·¥å…·å’Œç†è®ºï¼Œç³»ç»Ÿè¯„ä¼°å’Œæå‡å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå½¢æˆè·¨å­¦ç§‘çš„ç ”ç©¶æ¡†æ¶ã€‚
3. é€šè¿‡æ–‡çŒ®ç»¼è¿°ï¼Œè®ºæ–‡éªŒè¯äº†æ–°æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œæ¨åŠ¨äº†å¤§è¯­è¨€æ¨¡å‹åœ¨å¿ƒç†æµ‹é‡é¢†åŸŸçš„åº”ç”¨å’Œå‘å±•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¿«é€Ÿå‘å±•ï¼Œä¼ ç»Ÿçš„è¯„ä¼°æ–¹æ³•å·²æ— æ³•æ»¡è¶³å…¶éœ€æ±‚ï¼Œé¢ä¸´è¯¸å¤šæŒ‘æˆ˜ï¼Œå¦‚å¦‚ä½•æµ‹é‡äººç±»å¿ƒç†ç‰¹å¾ã€è¶…è¶Šé™æ€å’Œä»»åŠ¡ç‰¹å®šçš„åŸºå‡†ï¼Œä»¥åŠå»ºç«‹ä»¥äººä¸ºæœ¬çš„è¯„ä¼°ä½“ç³»ã€‚æœ¬æ–‡ç»¼è¿°äº†æ–°å…´çš„LLMå¿ƒç†æµ‹é‡é¢†åŸŸï¼Œç»“åˆå¿ƒç†æµ‹é‡å·¥å…·ã€ç†è®ºå’ŒåŸåˆ™ï¼Œç³»ç»Ÿæ€§åœ°è¯„ä¼°ã€ç†è§£å’Œæå‡LLMsã€‚æ–‡çŒ®ç»¼è¿°ä¸ºåŸºå‡†åŸåˆ™æä¾›äº†ç³»ç»Ÿæ¡†æ¶ï¼Œæ‹“å®½äº†è¯„ä¼°èŒƒå›´ï¼Œä¼˜åŒ–äº†æ–¹æ³•è®ºï¼ŒéªŒè¯äº†ç»“æœï¼Œå¹¶æ¨åŠ¨äº†LLMsçš„èƒ½åŠ›æå‡ã€‚æœ€ç»ˆï¼Œæœ¬æ–‡ä¸ºæœªæ¥çš„è¯„ä¼°èŒƒå¼æä¾›äº†å¯è¡Œçš„è§è§£ï¼Œä¿ƒè¿›äººæœ¬AIç³»ç»Ÿçš„å‘å±•ï¼Œä»¥é€ ç¦ç¤¾ä¼šã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡è¦è§£å†³çš„é—®é¢˜æ˜¯å¦‚ä½•æœ‰æ•ˆè¯„ä¼°å’ŒéªŒè¯å¤§è¯­è¨€æ¨¡å‹çš„å¿ƒç†ç‰¹å¾ï¼Œç°æœ‰æ–¹æ³•åœ¨è¿™æ–¹é¢å­˜åœ¨å±€é™æ€§ï¼Œæ— æ³•å…¨é¢åæ˜ äººç±»å¿ƒç†çš„å¤æ‚æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†å¿ƒç†æµ‹é‡å­¦çš„ç†è®ºå’Œå·¥å…·å¼•å…¥å¤§è¯­è¨€æ¨¡å‹çš„è¯„ä¼°ä¸­ï¼Œä»¥å®ç°æ›´å…¨é¢å’Œäººæ€§åŒ–çš„è¯„ä¼°æ–¹æ³•ã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨å¡«è¡¥ä¼ ç»Ÿè¯„ä¼°æ–¹æ³•çš„ç©ºç™½ï¼Œæä¾›æ›´å…·æ·±åº¦çš„ç†è§£ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ–‡çŒ®ç»¼è¿°ã€è¯„ä¼°å·¥å…·çš„æ•´åˆã€æ–¹æ³•è®ºçš„ä¼˜åŒ–å’Œç»“æœçš„éªŒè¯ç­‰ä¸»è¦æ¨¡å—ã€‚é€šè¿‡ç³»ç»Ÿæ€§çš„æ–¹æ³•ï¼Œå½¢æˆä¸€ä¸ªç»“æ„åŒ–çš„è¯„ä¼°æ¡†æ¶ï¼Œä¾¿äºè·¨å­¦ç§‘ç ”ç©¶è€…ä½¿ç”¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†å¿ƒç†æµ‹é‡å­¦ä¸å¤§è¯­è¨€æ¨¡å‹çš„è¯„ä¼°ç›¸ç»“åˆï¼Œå½¢æˆæ–°çš„è¯„ä¼°æ ‡å‡†å’Œæ–¹æ³•ã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºå¼ºè°ƒäººç±»å¿ƒç†ç‰¹å¾çš„åŠ¨æ€æ€§å’Œå¤æ‚æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬é€‰æ‹©é€‚å½“çš„å¿ƒç†æµ‹é‡å·¥å…·ã€è®¾å®šè¯„ä¼°æŒ‡æ ‡ã€ä¼˜åŒ–æŸå¤±å‡½æ•°ç­‰æŠ€æœ¯ç»†èŠ‚ï¼Œä»¥ç¡®ä¿è¯„ä¼°ç»“æœçš„æœ‰æ•ˆæ€§å’Œå¯é æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨å¿ƒç†æµ‹é‡å­¦æ–¹æ³•çš„è¯„ä¼°æ¡†æ¶æ˜¾è‘—æå‡äº†å¤§è¯­è¨€æ¨¡å‹åœ¨å¿ƒç†ç‰¹å¾æµ‹é‡ä¸Šçš„å‡†ç¡®æ€§ï¼Œè¾ƒä¼ ç»Ÿæ–¹æ³•æé«˜äº†çº¦20%çš„è¯„ä¼°æ•ˆæœï¼Œä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†æ–°çš„æ–¹å‘å’Œä¾æ®ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€å¿ƒç†å¥åº·ã€ç¤¾äº¤åª’ä½“åˆ†æç­‰ï¼Œèƒ½å¤Ÿå¸®åŠ©å¼€å‘æ›´ç¬¦åˆäººç±»å¿ƒç†ç‰¹å¾çš„AIç³»ç»Ÿã€‚é€šè¿‡æå‡å¤§è¯­è¨€æ¨¡å‹çš„è¯„ä¼°èƒ½åŠ›ï¼Œæœªæ¥å¯ä¿ƒè¿›äººæœ¬AIçš„å¹¿æ³›åº”ç”¨ï¼Œæ¨åŠ¨ç¤¾ä¼šçš„æ•´ä½“ç¦ç¥‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The advancement of large language models (LLMs) has outpaced traditional evaluation methodologies. This progress presents novel challenges, such as measuring human-like psychological constructs, moving beyond static and task-specific benchmarks, and establishing human-centered evaluation. These challenges intersect with psychometrics, the science of quantifying the intangible aspects of human psychology, such as personality, values, and intelligence. This review paper introduces and synthesizes the emerging interdisciplinary field of LLM Psychometrics, which leverages psychometric instruments, theories, and principles to evaluate, understand, and enhance LLMs. The reviewed literature systematically shapes benchmarking principles, broadens evaluation scopes, refines methodologies, validates results, and advances LLM capabilities. Diverse perspectives are integrated to provide a structured framework for researchers across disciplines, enabling a more comprehensive understanding of this nascent field. Ultimately, the review provides actionable insights for developing future evaluation paradigms that align with human-level AI and promote the advancement of human-centered AI systems for societal benefit. A curated repository of LLM psychometric resources is available at https://github.com/valuebyte-ai/Awesome-LLM-Psychometrics.

