---
layout: default
title: Evaluating the Effectiveness of Black-Box Prompt Optimization as the Scale of LLMs Continues to Grow
---

# Evaluating the Effectiveness of Black-Box Prompt Optimization as the Scale of LLMs Continues to Grow

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.08303" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.08303v1</a>
  <a href="https://arxiv.org/pdf/2505.08303.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.08303v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.08303v1', 'Evaluating the Effectiveness of Black-Box Prompt Optimization as the Scale of LLMs Continues to Grow')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Ziyu Zhou, Yihang Wu, Jingyuan Yang, Zhan Xiao, Rongjun Li

**ÂàÜÁ±ª**: cs.CL

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-13

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ËØÑ‰º∞ÈªëÁÆ±ÊèêÁ§∫‰ºòÂåñÂú®Â§ßËßÑÊ®°LLM‰∏≠ÁöÑÊúâÊïàÊÄß**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÈªëÁÆ±‰ºòÂåñ` `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ` `Ê®°ÂûãËßÑÊ®°` `ÊÄßËÉΩËØÑ‰º∞` `ÈÄÜÁº©ÊîæËßÑÂæã` `ÊèêÁ§∫‰ºòÂåñ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÈªëÁÆ±ÊèêÁ§∫‰ºòÂåñÊñπÊ≥ïÂú®Â∞èËßÑÊ®°Ê®°Âûã‰∏äË°®Áé∞ËâØÂ•ΩÔºå‰ΩÜÂú®Â§ßËßÑÊ®°Ê®°Âûã‰∏äÊïàÊûúÊúâÈôêÔºåÂ∞öÊú™ÂæóÂà∞ÂÖÖÂàÜÈ™åËØÅ„ÄÇ
2. Êú¨ÊñáËØÑ‰º∞‰∏âÁßçÈªëÁÆ±‰ºòÂåñÊñπÊ≥ïÂú®Â§ßÂûãLLM‰∏äÁöÑÊúâÊïàÊÄßÔºåÊé¢ËÆ®Ê®°ÂûãËßÑÊ®°ÂØπ‰ºòÂåñÊïàÊûúÁöÑÂΩ±Âìç„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÈöèÁùÄÊ®°ÂûãËßÑÊ®°ÁöÑÂ¢ûÂä†ÔºåÈªëÁÆ±‰ºòÂåñÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÊòæËëóÈôç‰ΩéÔºåÈ™åËØÅ‰∫ÜÊ®°ÂûãËßÑÊ®°ÂØπÊÄßËÉΩÁöÑÂΩ±Âìç„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÈªëÁÆ±ÊèêÁ§∫‰ºòÂåñÊñπÊ≥ï‰Ωú‰∏∫‰∏ÄÁßçÊúâÂâçÊôØÁöÑÁ≠ñÁï•ÔºåÊó®Âú®ÈÄöËøá‰ºòÂåñËæìÂÖ•ÊèêÁ§∫Êù•Êõ¥Â•ΩÂú∞ÂØπÈΩêÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÔºå‰ªéËÄåÊèêÂçáÂÖ∂‰ªªÂä°ÊÄßËÉΩ„ÄÇÂ∞ΩÁÆ°Ëøô‰∫õÊñπÊ≥ïÂú®Â∞èËßÑÊ®°Ê®°ÂûãÔºàÂ¶Ç7B„ÄÅ14BÔºâÊàñÊó©ÊúüÁâàÊú¨ÔºàÂ¶ÇGPT-3.5Ôºâ‰∏äÂèñÂæó‰∫ÜËâØÂ•ΩÊïàÊûúÔºå‰ΩÜÂú®Â§ßËßÑÊ®°Ê®°ÂûãÔºàÂ¶ÇDeepSeek V3Ôºå671BÔºâ‰∏äÔºåÂÖ∂ÊúâÊïàÊÄß‰ªçÁÑ∂Êú™Áü•„ÄÇÊú¨ÊñáÈÄâÊã©‰∏âÁßçÁü•ÂêçÁöÑÈªëÁÆ±‰ºòÂåñÊñπÊ≥ïÔºåÂú®Â§ßÂûãLLMÔºàDeepSeek V3ÂíåGemini 2.0 FlashÔºâ‰∏äËøõË°åËØÑ‰º∞ÔºåÁªìÊûúÊòæÁ§∫Ëøô‰∫õÊñπÊ≥ïÂú®Â§ßËßÑÊ®°LLM‰∏ä‰ªÖÊèê‰æõÊúâÈôêÁöÑÊÄßËÉΩÊèêÂçá„ÄÇÊàë‰ª¨ÂÅáËÆæÊ®°ÂûãËßÑÊ®°ÊòØÂØºËá¥ËßÇÂØüÂà∞ÁöÑÊúâÈôêÊî∂ÁõäÁöÑ‰∏ªË¶ÅÂõ†Á¥†ÔºåÂπ∂ÈÄöËøáÂØπ‰∏çÂêåËßÑÊ®°ÁöÑLLMÔºàQwen 2.5Á≥ªÂàóÔºå7BËá≥72BÔºâËøõË°åÂÆûÈ™åÔºåËßÇÂØüÂà∞ÈªëÁÆ±‰ºòÂåñÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÈöèÁùÄÊ®°ÂûãËßÑÊ®°ÁöÑÂ¢ûÂä†ËÄåÂáèÂº±„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥ÈªëÁÆ±ÊèêÁ§∫‰ºòÂåñÊñπÊ≥ïÂú®Â§ßËßÑÊ®°ËØ≠Ë®ÄÊ®°Âûã‰∏≠ÁöÑÊúâÊïàÊÄßÈóÆÈ¢ò„ÄÇÁé∞ÊúâÁ†îÁ©∂‰∏ªË¶ÅÈõÜ‰∏≠Âú®Â∞èËßÑÊ®°Ê®°Âûã‰∏äÔºåÁº∫‰πèÂØπÂ§ßËßÑÊ®°Ê®°ÂûãÁöÑÊ∑±ÂÖ•Êé¢ËÆ®„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÈÄöËøáÈÄâÊã©‰∏âÁßçÁü•ÂêçÁöÑÈªëÁÆ±‰ºòÂåñÊñπÊ≥ïÔºåËØÑ‰º∞ÂÖ∂Âú®‰∏çÂêåËßÑÊ®°LLM‰∏äÁöÑÊÄßËÉΩÔºåÊé¢Á¥¢Ê®°ÂûãËßÑÊ®°ÂØπ‰ºòÂåñÊïàÊûúÁöÑÂΩ±Âìç„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÁ†îÁ©∂ÈááÁî®‰∫ÜÂØπÊØîÂÆûÈ™åÁöÑÊñπÊ≥ïÔºåÈÄâÂèñDeepSeek V3ÂíåGemini 2.0 Flash‰Ωú‰∏∫Â§ßÂûãLLMÔºå‰ΩøÁî®Âõõ‰∏™Ëá™ÁÑ∂ËØ≠Ë®ÄÁêÜËß£ÔºàNLUÔºâÂíåËá™ÁÑ∂ËØ≠Ë®ÄÁîüÊàêÔºàNLGÔºâÊï∞ÊçÆÈõÜËøõË°åËØÑ‰º∞„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊú¨ÊñáÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éÈ¶ñÊ¨°Á≥ªÁªüÊÄßÂú∞ËØÑ‰º∞ÈªëÁÆ±ÊèêÁ§∫‰ºòÂåñÊñπÊ≥ïÂú®Ë∂ÖÂ§ßËßÑÊ®°LLM‰∏äÁöÑÊúâÊïàÊÄßÔºåÊèêÂá∫Ê®°ÂûãËßÑÊ®°ÊòØÂΩ±Âìç‰ºòÂåñÊïàÊûúÁöÑÂÖ≥ÈîÆÂõ†Á¥†„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂÆûÈ™å‰∏≠ÂØπ‰∏çÂêåËßÑÊ®°ÁöÑLLMÔºàÂ¶ÇQwen 2.5Á≥ªÂàóÔºå7BËá≥72BÔºâËøõË°å‰∫ÜÂØπÊØîÔºåËßÇÂØüÂà∞ÈªëÁÆ±‰ºòÂåñÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÈöèÁùÄÊ®°ÂûãËßÑÊ®°ÁöÑÂ¢ûÂä†ËÄåÂáèÂº±ÔºåÈ™åËØÅ‰∫ÜÈÄÜÁº©ÊîæËßÑÂæã„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåÈªëÁÆ±ÊèêÁ§∫‰ºòÂåñÊñπÊ≥ïÂú®DeepSeek V3ÂíåGemini 2.0 FlashÁ≠âÂ§ßËßÑÊ®°LLM‰∏ä‰ªÖÊèê‰æõÊúâÈôêÁöÑÊÄßËÉΩÊèêÂçáÔºå‰∏îÈöèÁùÄÊ®°ÂûãËßÑÊ®°ÁöÑÂ¢ûÂä†Ôºå‰ºòÂåñÊïàÊûúÊòæËëóÂáèÂº±ÔºåÈ™åËØÅ‰∫ÜÊ®°ÂûãËßÑÊ®°ÂØπ‰ºòÂåñÊïàÊûúÁöÑÂΩ±Âìç„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåÈöèÁùÄÊ®°ÂûãËßÑÊ®°‰ªé7BÂ¢ûÂä†Âà∞72BÔºå‰ºòÂåñÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÂëàÁé∞Âá∫ÈÄÜÁº©ÊîæËßÑÂæã„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ„ÄÅÂØπËØùÁ≥ªÁªüÂíåÊô∫ËÉΩÂä©ÊâãÁ≠â„ÄÇÈÄöËøá‰ºòÂåñÂ§ßËßÑÊ®°ËØ≠Ë®ÄÊ®°ÂûãÁöÑËæìÂÖ•ÊèêÁ§∫ÔºåÂèØ‰ª•ÊèêÂçáÂÖ∂Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑË°®Áé∞ÔºåËøõËÄåÊé®Âä®Êô∫ËÉΩÁ≥ªÁªüÁöÑÊô∫ËÉΩÂåñÂíå‰∫∫Êú∫‰∫§‰∫íÁöÑËá™ÁÑ∂ÊÄß„ÄÇÊú™Êù•ÔºåÈöèÁùÄÊ®°ÂûãËßÑÊ®°ÁöÑËøõ‰∏ÄÊ≠•Êâ©Â§ßÔºåÁêÜËß£ÂÖ∂‰ºòÂåñÊú∫Âà∂Â∞ÜÂØπÊ®°ÂûãÁöÑÂÆûÈôÖÂ∫îÁî®‰∫ßÁîüÊ∑±ËøúÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Black-Box prompt optimization methods have emerged as a promising strategy for refining input prompts to better align large language models (LLMs), thereby enhancing their task performance. Although these methods have demonstrated encouraging results, most studies and experiments have primarily focused on smaller-scale models (e.g., 7B, 14B) or earlier versions (e.g., GPT-3.5) of LLMs. As the scale of LLMs continues to increase, such as with DeepSeek V3 (671B), it remains an open question whether these black-box optimization techniques will continue to yield significant performance improvements for models of such scale. In response to this, we select three well-known black-box optimization methods and evaluate them on large-scale LLMs (DeepSeek V3 and Gemini 2.0 Flash) across four NLU and NLG datasets. The results show that these black-box prompt optimization methods offer only limited improvements on these large-scale LLMs. Furthermore, we hypothesize that the scale of the model is the primary factor contributing to the limited benefits observed. To explore this hypothesis, we conducted experiments on LLMs of varying sizes (Qwen 2.5 series, ranging from 7B to 72B) and observed an inverse scaling law, wherein the effectiveness of black-box optimization methods diminished as the model size increased.

