---
layout: default
title: A suite of LMs comprehend puzzle statements as well as humans
---

# A suite of LMs comprehend puzzle statements as well as humans

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.08996" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.08996v1</a>
  <a href="https://arxiv.org/pdf/2505.08996.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.08996v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.08996v1', 'A suite of LMs comprehend puzzle statements as well as humans')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Adele E Goldberg, Supantho Rakshit, Jennifer Hu, Kyle Mahowald

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-13

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é‡æ–°è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç†è§£è‹±è¯­è¯­å¥ä¸­çš„è¡¨ç°**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `è¯­è¨€ç†è§£` `å®éªŒè®¾è®¡` `äººç±»ä¸æ¨¡å‹æ¯”è¾ƒ` `è¯­ç”¨æ•æ„Ÿæ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç ”ç©¶è¡¨æ˜å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç†è§£ç®€å•è‹±è¯­è¯­å¥æ–¹é¢çš„è¡¨ç°è¢«ä½ä¼°ï¼Œä¸”äººç±»è¡¨ç°è¢«é«˜ä¼°ã€‚
2. æœ¬æ–‡é€šè¿‡å¯¹äººç±»åœ¨ä¸åŒæ¡ä»¶ä¸‹çš„ååº”è¿›è¡Œæ¯”è¾ƒï¼Œæå‡ºäº†æ›´è‡ªç„¶çš„ç†è§£æµ‹è¯•æ–¹æ³•ï¼Œé‡æ–°è¯„ä¼°äº†LMçš„èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGPT-4å’ŒGPT-o1æ¨¡å‹åœ¨ç†è§£èƒ½åŠ›ä¸Šè¶…è¶Šäº†äººç±»ï¼Œå°¤å…¶åœ¨é™åˆ¶é‡è¯»çš„æƒ…å†µä¸‹ï¼Œå‡†ç¡®ç‡æ˜¾è‘—æé«˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘æœŸç ”ç©¶è¡¨æ˜ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLMsï¼‰åœ¨ç†è§£ç®€å•è‹±è¯­è¯­å¥æ–¹é¢è¡¨ç°ä¸å¦‚äººç±»ï¼ˆDentellaç­‰ï¼Œ2024ï¼‰ã€‚æœ¬æ–‡é‡æ–°å®¡è§†è¿™äº›å‘ç°ï¼Œè®¤ä¸ºäººç±»è¡¨ç°è¢«é«˜ä¼°ï¼Œè€ŒLMèƒ½åŠ›è¢«ä½ä¼°ã€‚é€šè¿‡å¯¹äººç±»åœ¨ä¸¤ç§æ¡ä»¶ä¸‹çš„ååº”è¿›è¡Œæ¯”è¾ƒï¼Œå‘ç°å½“é™åˆ¶é‡è¯»æ—¶ï¼Œäººç±»çš„å‡†ç¡®ç‡æ˜¾è‘—ä¸‹é™ï¼ˆ73%ï¼‰ï¼Œä½äºFalcon-180B-Chatï¼ˆ76%ï¼‰å’ŒGPT-4ï¼ˆ81%ï¼‰ã€‚æœ€æ–°çš„GPT-o1æ¨¡å‹å®ç°äº†å®Œç¾å‡†ç¡®ç‡ã€‚ç»“æœè¿˜è¡¨æ˜ï¼Œäººç±»å’Œæ¨¡å‹åœ¨æ¶‰åŠæ½œåœ¨äº’æƒ è¡Œä¸ºçš„æŸ¥è¯¢æ—¶é¢ä¸´å…±åŒæŒ‘æˆ˜ï¼Œæç¤ºå­˜åœ¨å…±äº«çš„è¯­ç”¨æ•æ„Ÿæ€§è€Œéæ¨¡å‹ç‰¹å®šçš„ç¼ºé™·ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†åœ¨LMè¯„ä¼°ä¸­éœ€è¦æ›´è°¨æ…çš„å®éªŒè®¾è®¡å’Œç¼–ç å®è·µï¼Œå¹¶æŒ‘æˆ˜äº†å½“å‰æ¨¡å‹åœ¨è¯­è¨€ç†è§£æ–¹é¢å›ºæœ‰å¼±äºäººç±»çš„å‡è®¾ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç†è§£è‹±è¯­è¯­å¥æ—¶è¡¨ç°è¢«ä½ä¼°çš„é—®é¢˜ï¼Œç°æœ‰ç ”ç©¶æœªèƒ½å‡†ç¡®è¯„ä¼°äººç±»ä¸æ¨¡å‹çš„ç†è§£èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡è®¾è®¡ä¸¤ç§ä¸åŒçš„å®éªŒæ¡ä»¶ï¼ˆå…è®¸é‡è¯»ä¸é™åˆ¶é‡è¯»ï¼‰ï¼Œé‡æ–°è¯„ä¼°äººç±»å’Œæ¨¡å‹çš„ç†è§£èƒ½åŠ›ï¼Œå¼ºè°ƒå®éªŒè®¾è®¡å¯¹ç»“æœçš„å½±å“ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨äº†é¢„æ³¨å†Œçš„å®éªŒè®¾è®¡ï¼Œæ¯”è¾ƒäº†äººç±»åœ¨ä¸åŒæ¡ä»¶ä¸‹çš„ååº”ï¼Œå¹¶ä½¿ç”¨äº†å¤šç§æ¨¡å‹ï¼ˆå¦‚Falcon-180B-Chatã€GPT-4ã€GPT-o1ï¼‰è¿›è¡Œæ€§èƒ½è¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°åœ¨äºé€šè¿‡é™åˆ¶é‡è¯»æ¥æµ‹è¯•äººç±»ç†è§£èƒ½åŠ›ï¼Œå‘ç°äººç±»åœ¨æ­¤æ¡ä»¶ä¸‹çš„è¡¨ç°ä½äºå¤šä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼ŒæŒ‘æˆ˜äº†äººç±»ä¼˜äºæ¨¡å‹çš„ä¼ ç»Ÿè§‚ç‚¹ã€‚

**å…³é”®è®¾è®¡**ï¼šå®éªŒä¸­ä½¿ç”¨äº†æ ‡å‡†åŒ–çš„åˆºæ¿€ææ–™ï¼Œç»“åˆäº†å¯¹æ¨¡å‹è¾“å‡ºçš„æ¦‚ç‡åˆ†æå’Œè¯­æ³•è¯„åˆ†ï¼Œç¡®ä¿äº†è¯„ä¼°çš„ç³»ç»Ÿæ€§å’Œå‡†ç¡®æ€§ã€‚é€šè¿‡å¯¹ä¸åŒæ¨¡å‹çš„å“åº”è¿›è¡Œç¼–ç ï¼Œæ­ç¤ºäº†æ¨¡å‹æ€§èƒ½çš„ç³»ç»Ÿæ€§ä½ä¼°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå½“é™åˆ¶é‡è¯»æ—¶ï¼Œäººç±»çš„å‡†ç¡®ç‡é™è‡³73%ï¼Œä½äºFalcon-180B-Chatçš„76%å’ŒGPT-4çš„81%ã€‚æœ€æ–°çš„GPT-o1æ¨¡å‹å®ç°äº†å®Œç¾çš„å‡†ç¡®ç‡ï¼Œè¡¨æ˜å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç†è§£èƒ½åŠ›ä¸Šå…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œå°¤å…¶åœ¨ç‰¹å®šæ¡ä»¶ä¸‹ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æ•™è‚²æŠ€æœ¯å’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æ›´å‡†ç¡®åœ°è¯„ä¼°è¯­è¨€æ¨¡å‹çš„ç†è§£èƒ½åŠ›ï¼Œå¯ä»¥æ¨åŠ¨æ™ºèƒ½åŠ©æ‰‹ã€è‡ªåŠ¨ç¿»è¯‘å’Œæ•™è‚²å·¥å…·çš„å‘å±•ï¼Œæå‡ç”¨æˆ·ä½“éªŒå’Œå­¦ä¹ æ•ˆæœã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent claims suggest that large language models (LMs) underperform humans in comprehending minimally complex English statements (Dentella et al., 2024). Here, we revisit those findings and argue that human performance was overestimated, while LLM abilities were underestimated. Using the same stimuli, we report a preregistered study comparing human responses in two conditions: one allowed rereading (replicating the original study), and one that restricted rereading (a more naturalistic comprehension test). Human accuracy dropped significantly when rereading was restricted (73%), falling below that of Falcon-180B-Chat (76%) and GPT-4 (81%). The newer GPT-o1 model achieves perfect accuracy. Results further show that both humans and models are disproportionately challenged by queries involving potentially reciprocal actions (e.g., kissing), suggesting shared pragmatic sensitivities rather than model-specific deficits. Additional analyses using Llama-2-70B log probabilities, a recoding of open-ended model responses, and grammaticality ratings of other sentences reveal systematic underestimation of model performance. We find that GPT-4o can align with either naive or expert grammaticality judgments, depending on prompt framing. These findings underscore the need for more careful experimental design and coding practices in LLM evaluation, and they challenge the assumption that current models are inherently weaker than humans at language comprehension.

