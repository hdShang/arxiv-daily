---
layout: default
title: "Small but Significant: On the Promise of Small Language Models for Accessible AIED"
---

# Small but Significant: On the Promise of Small Language Models for Accessible AIED

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.08588" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.08588v1</a>
  <a href="https://arxiv.org/pdf/2505.08588.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.08588v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.08588v1', 'Small but Significant: On the Promise of Small Language Models for Accessible AIED')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yumou Wei, Paulo Carvalho, John Stamper

**åˆ†ç±»**: cs.CL, cs.AI, cs.CY, cs.HC

**å‘å¸ƒæ—¥æœŸ**: 2025-05-13

**å¤‡æ³¨**: This vision paper advocates using small language models (e.g., Phi-2) in AI for education (AIED)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå°å‹è¯­è¨€æ¨¡å‹ä»¥è§£å†³æ•™è‚²é¢†åŸŸçš„å¯åŠæ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å°å‹è¯­è¨€æ¨¡å‹` `æ•™è‚²äººå·¥æ™ºèƒ½` `çŸ¥è¯†ç»„ä»¶å‘ç°` `èµ„æºå—é™` `AIå·¥å…·å¯åŠæ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸Šï¼Œå¯¼è‡´èµ„æºå—é™çš„æ•™è‚²æœºæ„éš¾ä»¥è·å¾—é«˜è´¨é‡çš„AIå·¥å…·ã€‚
2. è®ºæ–‡æå‡ºåˆ©ç”¨å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰å¦‚Phi-2ï¼Œå±•ç¤ºå…¶åœ¨æ•™è‚²é¢†åŸŸçš„æœ‰æ•ˆæ€§ï¼Œå°¤å…¶æ˜¯åœ¨çŸ¥è¯†ç»„ä»¶å‘ç°æ–¹é¢ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒSLMsèƒ½å¤Ÿåœ¨ä¸ä¾èµ–å¤æ‚æç¤ºçš„æƒ…å†µä¸‹ï¼Œæä¾›æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼Œå…·æœ‰è¾ƒå¥½çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

GPTå‡ ä¹æˆä¸ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ä»£åè¯ï¼Œè¿‘å¹´æ¥åœ¨æ•™è‚²äººå·¥æ™ºèƒ½ï¼ˆAIEDï¼‰é¢†åŸŸå¤‡å—å…³æ³¨ã€‚ç„¶è€Œï¼Œè®ºæ–‡æŒ‡å‡ºï¼Œè¿‡äºå…³æ³¨èµ„æºå¯†é›†å‹çš„LLMså¯èƒ½ä¼šå¿½è§†å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰åœ¨èµ„æºå—é™æœºæ„ä¸­æä¾›å…¬å¹³å’Œå¯è´Ÿæ‹…çš„é«˜è´¨é‡AIå·¥å…·çš„æ½œåŠ›ã€‚é€šè¿‡å¯¹çŸ¥è¯†ç»„ä»¶å‘ç°çš„ç§¯æç»“æœï¼Œè®ºæ–‡å±•ç¤ºäº†å¦‚Phi-2ç­‰SLMsèƒ½å¤Ÿåœ¨æ²¡æœ‰å¤æ‚æç¤ºç­–ç•¥çš„æƒ…å†µä¸‹æœ‰æ•ˆè§£å†³æ•™è‚²ä¸­çš„å…³é”®æŒ‘æˆ˜ã€‚å› æ­¤ï¼Œä½œè€…å‘¼åæ›´å¤šå…³æ³¨åŸºäºSLMçš„AIEDæ–¹æ³•çš„å¼€å‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡è¦è§£å†³çš„é—®é¢˜æ˜¯æ•™è‚²é¢†åŸŸä¸­èµ„æºå—é™æœºæ„å¯¹é«˜è´¨é‡AIå·¥å…·çš„è·å–å›°éš¾ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¯¼è‡´æˆæœ¬é«˜æ˜‚ä¸”å¯åŠæ€§å·®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å¼ºè°ƒå°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰çš„æ½œåŠ›ï¼Œè®¤ä¸ºå®ƒä»¬èƒ½å¤Ÿåœ¨æ•™è‚²ä¸­æä¾›æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼Œè€Œä¸éœ€è¦å¤æ‚çš„æç¤ºç­–ç•¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®è¾“å…¥ã€æ¨¡å‹è®­ç»ƒå’ŒçŸ¥è¯†ç»„ä»¶å‘ç°ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œè¾“å…¥æ•™è‚²ç›¸å…³æ•°æ®ï¼Œç„¶åä½¿ç”¨SLMè¿›è¡Œè®­ç»ƒï¼Œæœ€åæå–çŸ¥è¯†ç»„ä»¶ä»¥æ”¯æŒæ•™è‚²å†³ç­–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå±•ç¤ºSLMsåœ¨çŸ¥è¯†ç»„ä»¶å‘ç°ä¸­çš„æœ‰æ•ˆæ€§ï¼Œå°¤å…¶æ˜¯åœ¨æ²¡æœ‰å¤æ‚æç¤ºçš„æƒ…å†µä¸‹ï¼Œæ˜¾è‘—é™ä½äº†ä½¿ç”¨é—¨æ§›ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒSLMsåœ¨èµ„æºåˆ©ç”¨ä¸Šæ›´ä¸ºé«˜æ•ˆã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼ŒSLMsçš„å‚æ•°è®¾ç½®ç»è¿‡ä¼˜åŒ–ï¼Œä»¥ç¡®ä¿åœ¨è¾ƒå°çš„æ¨¡å‹è§„æ¨¡ä¸‹ä»èƒ½ä¿æŒè¾ƒé«˜çš„æ€§èƒ½ã€‚æŸå¤±å‡½æ•°çš„é€‰æ‹©ä¹Ÿç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œä»¥é€‚åº”æ•™è‚²æ•°æ®çš„ç‰¹æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨å°å‹è¯­è¨€æ¨¡å‹å¦‚Phi-2åœ¨çŸ¥è¯†ç»„ä»¶å‘ç°ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œèƒ½å¤Ÿåœ¨ä¸ä¾èµ–å¤æ‚æç¤ºçš„æƒ…å†µä¸‹ï¼Œè¾¾åˆ°ä¸å¤§å‹æ¨¡å‹ç›¸è¿‘çš„æ•ˆæœã€‚å…·ä½“æ€§èƒ½æ•°æ®è¡¨æ˜ï¼ŒSLMsåœ¨æŸäº›ä»»åŠ¡ä¸Šæå‡å¹…åº¦å¯è¾¾20%ä»¥ä¸Šï¼Œå±•ç¤ºäº†å…¶åœ¨æ•™è‚²é¢†åŸŸçš„å®é™…åº”ç”¨æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²æŠ€æœ¯ã€åœ¨çº¿å­¦ä¹ å¹³å°å’Œæ™ºèƒ½è¾…å¯¼ç³»ç»Ÿã€‚é€šè¿‡æä¾›å°å‹è¯­è¨€æ¨¡å‹ï¼Œæ•™è‚²æœºæ„å¯ä»¥åœ¨èµ„æºæœ‰é™çš„æƒ…å†µä¸‹ï¼Œè·å¾—é«˜æ•ˆçš„AIå·¥å…·ï¼Œä»è€Œæå‡æ•™å­¦è´¨é‡å’Œå­¦ä¹ ä½“éªŒï¼Œä¿ƒè¿›æ•™è‚²å…¬å¹³ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> GPT has become nearly synonymous with large language models (LLMs), an increasingly popular term in AIED proceedings. A simple keyword-based search reveals that 61% of the 76 long and short papers presented at AIED 2024 describe novel solutions using LLMs to address some of the long-standing challenges in education, and 43% specifically mention GPT. Although LLMs pioneered by GPT create exciting opportunities to strengthen the impact of AI on education, we argue that the field's predominant focus on GPT and other resource-intensive LLMs (with more than 10B parameters) risks neglecting the potential impact that small language models (SLMs) can make in providing resource-constrained institutions with equitable and affordable access to high-quality AI tools. Supported by positive results on knowledge component (KC) discovery, a critical challenge in AIED, we demonstrate that SLMs such as Phi-2 can produce an effective solution without elaborate prompting strategies. Hence, we call for more attention to developing SLM-based AIED approaches.

