---
layout: default
title: "TUMS: Enhancing Tool-use Abilities of LLMs with Multi-structure Handlers"
---

# TUMS: Enhancing Tool-use Abilities of LLMs with Multi-structure Handlers

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.08402" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.08402v1</a>
  <a href="https://arxiv.org/pdf/2505.08402.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.08402v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.08402v1', 'TUMS: Enhancing Tool-use Abilities of LLMs with Multi-structure Handlers')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Aiyao He, Sijia Cui, Shuai Xu, Yanna Wang, Bo Xu

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-13

**å¤‡æ³¨**: Accepted to ICONIP 2024

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTUMSæ¡†æ¶ä»¥æå‡LLMsçš„å·¥å…·ä½¿ç”¨èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å·¥å…·ä½¿ç”¨` `è‡ªç„¶è¯­è¨€å¤„ç†` `ä»»åŠ¡åˆ†è§£` `å‚æ•°ç”Ÿæˆ` `æ™ºèƒ½åŠ©æ‰‹` `å¤šç»“æ„å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å·¥å…·è°ƒç”¨æ—¶ï¼ŒLLMsé¢ä¸´å‚æ•°ç”Ÿæˆä¸å‡†ç¡®å’Œæ‰§è¡Œä¸å½“çš„é—®é¢˜ï¼Œé™åˆ¶äº†å…¶æœ‰æ•ˆæ€§ã€‚
2. TUMSæ¡†æ¶é€šè¿‡æ„å›¾è¯†åˆ«ã€ä»»åŠ¡åˆ†è§£å’Œå¤šç»“æ„å¤„ç†ï¼Œæå‡äº†LLMsçš„å·¥å…·ä½¿ç”¨èƒ½åŠ›ï¼Œè§£å†³äº†å‚æ•°ç”Ÿæˆçš„ç²—ç³™æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTUMSåœ¨ToolQAåŸºå‡†ä¸Šåˆ†åˆ«æé«˜äº†19.6%å’Œ50.6%çš„æ€§èƒ½ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œæ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è§£å†³å¤šç§è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­å‘æŒ¥äº†è¶Šæ¥è¶Šé‡è¦çš„ä½œç”¨ï¼Œå°¤å…¶æ˜¯åœ¨è‡ªç„¶è¯­è¨€ç†è§£å’Œç”Ÿæˆæ–¹é¢ã€‚é€šè¿‡ä¸å¤–éƒ¨å·¥å…·çš„é›†æˆï¼ŒLLMsçš„æœ‰æ•ˆæ€§å¾—åˆ°äº†è¿›ä¸€æ­¥å¢å¼ºï¼Œèƒ½å¤Ÿæä¾›æ›´ç²¾ç¡®ã€åŠæ—¶å’Œä¸“ä¸šçš„å“åº”ã€‚ç„¶è€Œï¼ŒLLMsåœ¨æ‰§è¡Œä¸å¯æ‰§è¡Œçš„æ“ä½œå’Œä¸å½“æ“ä½œæ—¶ä»é¢ä¸´å›°éš¾ï¼Œè¿™ä¸»è¦å½’å› äºå‚æ•°è®¾ç½®ä¸å½“ã€‚æœ¬æ–‡æå‡ºäº†TUMSï¼Œä¸€ä¸ªæ–°é¢–çš„æ¡†æ¶ï¼Œé€šè¿‡å°†å·¥å…·çº§å¤„ç†è½¬å˜ä¸ºå‚æ•°çº§å¤„ç†ï¼Œæ¥å¢å¼ºLLMsçš„å·¥å…·ä½¿ç”¨èƒ½åŠ›ã€‚è¯¥æ¡†æ¶åŒ…æ‹¬å››ä¸ªå…³é”®ç»„ä»¶ï¼šæ„å›¾è¯†åˆ«å™¨ã€ä»»åŠ¡åˆ†è§£å™¨ã€å¤šç»“æ„å¤„ç†å™¨å’Œæ‰§è¡Œå™¨ã€‚å®è¯ç ”ç©¶è¡¨æ˜ï¼ŒTUMSæ¡†æ¶åœ¨ToolQAçš„ç®€å•å’Œå›°éš¾åŸºå‡†ä¸Šåˆ†åˆ«æé«˜äº†19.6%å’Œ50.6%çš„æ€§èƒ½ï¼Œä¸”é€šè¿‡æ¶ˆèå®éªŒå±•ç¤ºäº†å„éƒ¨åˆ†çš„å…³é”®è´¡çŒ®ï¼Œä¸ºæœªæ¥çš„å·¥å…·å¢å¼ºLLMsç ”ç©¶æä¾›äº†æ›´å¤šè§è§£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³LLMsåœ¨å·¥å…·è°ƒç”¨ä¸­é‡åˆ°çš„å‚æ•°ç”Ÿæˆä¸å‡†ç¡®å’Œæ‰§è¡Œä¸å½“çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–ç²—ç²’åº¦çš„å·¥å…·çº§å¤„ç†ï¼Œæœªèƒ½è€ƒè™‘ä¸åŒå·¥å…·çš„å¤æ‚æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šTUMSæ¡†æ¶çš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†å·¥å…·çº§å¤„ç†è½¬å˜ä¸ºå‚æ•°çº§å¤„ç†ï¼Œé€šè¿‡è¯†åˆ«ç”¨æˆ·æ„å›¾å’Œåˆ†è§£ä»»åŠ¡æ¥ç”Ÿæˆæ›´å‡†ç¡®çš„å‚æ•°ï¼Œä»è€Œæå‡LLMsçš„å·¥å…·ä½¿ç”¨èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTUMSæ¡†æ¶ç”±å››ä¸ªä¸»è¦æ¨¡å—ç»„æˆï¼šæ„å›¾è¯†åˆ«å™¨ï¼ˆè¯†åˆ«ç”¨æˆ·æ„å›¾ï¼‰ã€ä»»åŠ¡åˆ†è§£å™¨ï¼ˆå°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºç®€å•å­ä»»åŠ¡ï¼‰ã€å¤šç»“æ„å¤„ç†å™¨ï¼ˆç”Ÿæˆå‡†ç¡®å‚æ•°ï¼‰å’Œæ‰§è¡Œå™¨ï¼ˆæ‰§è¡Œå·¥å…·è°ƒç”¨ï¼‰ã€‚

**å…³é”®åˆ›æ–°**ï¼šTUMSçš„åˆ›æ–°åœ¨äºå…¶å¤šç»“æ„å¤„ç†å™¨ï¼Œèƒ½å¤Ÿæ ¹æ®ä¸åŒå·¥å…·çš„å¤æ‚æ€§ç”Ÿæˆç²¾ç¡®å‚æ•°ï¼Œè¿™ä¸€è®¾è®¡ä¸ç°æœ‰æ–¹æ³•çš„ç²—ç²’åº¦å¤„ç†æ–¹å¼å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œæ„å›¾è¯†åˆ«å™¨é‡‡ç”¨äº†å…ˆè¿›çš„è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯ï¼Œä»»åŠ¡åˆ†è§£å™¨ä½¿ç”¨äº†å±‚æ¬¡åŒ–çš„åˆ†è§£ç­–ç•¥ï¼Œå¤šç»“æ„å¤„ç†å™¨åˆ™ç»“åˆäº†å¤šç§å‚æ•°ç”Ÿæˆç­–ç•¥ï¼Œä»¥ç¡®ä¿ç”Ÿæˆçš„å‚æ•°é€‚åº”ä¸åŒå·¥å…·çš„éœ€æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTUMSæ¡†æ¶åœ¨ToolQAåŸºå‡†ä¸Šåˆ†åˆ«å®ç°äº†19.6%å’Œ50.6%çš„æ€§èƒ½æå‡ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚è¿™ä¸€æˆæœä¸ä»…éªŒè¯äº†æ¡†æ¶çš„æœ‰æ•ˆæ€§ï¼Œè¿˜ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†é‡è¦çš„å®éªŒä¾æ®ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

TUMSæ¡†æ¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½åŠ©æ‰‹ã€è‡ªåŠ¨åŒ–å·¥å…·è°ƒç”¨å’Œå¤æ‚ä»»åŠ¡çš„è‡ªåŠ¨åŒ–å¤„ç†ç­‰ã€‚é€šè¿‡æå‡LLMsçš„å·¥å…·ä½¿ç”¨èƒ½åŠ›ï¼Œè¯¥ç ”ç©¶èƒ½å¤Ÿåœ¨å®é™…åº”ç”¨ä¸­æä¾›æ›´é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿçš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recently, large language models(LLMs) have played an increasingly important role in solving a wide range of NLP tasks, leveraging their capabilities of natural language understanding and generating. Integration with external tools further enhances LLMs' effectiveness, providing more precise, timely, and specialized responses. However, LLMs still encounter difficulties with non-executable actions and improper actions, which are primarily attributed to incorrect parameters. The process of generating parameters by LLMs is confined to the tool level, employing the coarse-grained strategy without considering the different difficulties of various tools. To address this issue, we propose TUMS, a novel framework designed to enhance the tool-use capabilities of LLMs by transforming tool-level processing into parameter-level processing. Specifically, our framework consists of four key components: (1) an intent recognizer that identifies the user's intent to help LLMs better understand the task; (2) a task decomposer that breaks down complex tasks into simpler subtasks, each involving a tool call; (3) a subtask processor equipped with multi-structure handlers to generate accurate parameters; and (4) an executor. Our empirical studies have evidenced the effectiveness and efficiency of the TUMS framework with an average of 19.6\% and 50.6\% improvement separately on easy and hard benchmarks of ToolQA, meanwhile, we demonstrated the key contribution of each part with ablation experiments, offering more insights and stimulating future research on Tool-augmented LLMs.

