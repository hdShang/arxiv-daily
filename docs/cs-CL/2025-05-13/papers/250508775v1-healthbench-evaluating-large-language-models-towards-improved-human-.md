---
layout: default
title: HealthBench: Evaluating Large Language Models Towards Improved Human Health
---

# HealthBench: Evaluating Large Language Models Towards Improved Human Health

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.08775" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.08775v1</a>
  <a href="https://arxiv.org/pdf/2505.08775.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.08775v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.08775v1', 'HealthBench: Evaluating Large Language Models Towards Improved Human Health')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Rahul K. Arora, Jason Wei, Rebecca Soskin Hicks, Preston Bowman, Joaquin QuiÃ±onero-Candela, Foivos Tsimpourlas, Michael Sharman, Meghan Shah, Andrea Vallone, Alex Beutel, Johannes Heidecke, Karan Singhal

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-13

**å¤‡æ³¨**: Blog: https://openai.com/index/healthbench/ Code: https://github.com/openai/simple-evals

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHealthBenchä»¥è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åŒ»ç–—å¥åº·ä¸­çš„è¡¨ç°**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `åŒ»ç–—å¥åº·` `å¼€æ”¾å¼è¯„ä¼°` `å¯¹è¯ç³»ç»Ÿ` `æ€§èƒ½åŸºå‡†` `å¤šç»´åº¦è¯„åˆ†` `äººå·¥æ™ºèƒ½åº”ç”¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„åŒ»ç–—å¯¹è¯è¯„ä¼°æ–¹æ³•å¤šä¸ºé€‰æ‹©é¢˜æˆ–ç®€ç­”é¢˜ï¼Œç¼ºä¹çœŸå®çš„å¼€æ”¾å¼è¯„ä¼°ï¼Œéš¾ä»¥å…¨é¢åæ˜ æ¨¡å‹çš„å®é™…è¡¨ç°ã€‚
2. HealthBenché€šè¿‡5000ä¸ªå¤šè½®å¯¹è¯å’Œ48562ä¸ªè¯„åˆ†æ ‡å‡†ï¼Œæä¾›äº†ä¸€ç§æ–°çš„è¯„ä¼°æ¡†æ¶ï¼Œèƒ½å¤Ÿæ›´çœŸå®åœ°åæ˜ æ¨¡å‹åœ¨åŒ»ç–—åœºæ™¯ä¸­çš„è¡¨ç°ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¾ƒå°çš„æ¨¡å‹ï¼ˆå¦‚GPT-4.1 nanoï¼‰åœ¨æˆæœ¬å’Œæ€§èƒ½ä¸Šå‡ä¼˜äºæ›´å¤§çš„æ¨¡å‹ï¼Œå±•ç°å‡ºæ˜¾è‘—çš„æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬æå‡ºäº†HealthBenchï¼Œè¿™æ˜¯ä¸€ä¸ªå¼€æºåŸºå‡†ï¼Œç”¨äºæµ‹é‡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åŒ»ç–—é¢†åŸŸçš„æ€§èƒ½å’Œå®‰å…¨æ€§ã€‚HealthBenchåŒ…å«5000ä¸ªå¤šè½®å¯¹è¯ï¼Œæ¶‰åŠæ¨¡å‹ä¸ç”¨æˆ·æˆ–åŒ»ç–—ä¸“ä¸šäººå‘˜çš„äº’åŠ¨ã€‚å“åº”è¯„ä¼°é‡‡ç”¨262ååŒ»ç”Ÿåˆ›å»ºçš„ç‰¹å®šå¯¹è¯è¯„åˆ†æ ‡å‡†ã€‚ä¸ä»¥å¾€çš„å¤šé¡¹é€‰æ‹©æˆ–ç®€ç­”åŸºå‡†ä¸åŒï¼ŒHealthBenché€šè¿‡48562ä¸ªç‹¬ç‰¹çš„è¯„åˆ†æ ‡å‡†ï¼Œæ¶µç›–å¤šä¸ªå¥åº·æƒ…å¢ƒï¼ˆå¦‚ç´§æ€¥æƒ…å†µã€ä¸´åºŠæ•°æ®è½¬åŒ–ã€å…¨çƒå¥åº·ï¼‰å’Œè¡Œä¸ºç»´åº¦ï¼ˆå¦‚å‡†ç¡®æ€§ã€æŒ‡ä»¤éµå¾ªã€æ²Ÿé€šï¼‰å®ç°äº†ç°å®çš„å¼€æ”¾å¼è¯„ä¼°ã€‚è¿‡å»ä¸¤å¹´ä¸­ï¼ŒHealthBenchçš„è¡¨ç°æ˜¾ç¤ºå‡ºç¨³æ­¥çš„åˆæ­¥è¿›å±•ï¼ˆä¾‹å¦‚ï¼ŒGPT-3.5 Turboçš„å¾—åˆ†ä¸º16%ï¼Œè€ŒGPT-4oä¸º32%ï¼‰ï¼Œä»¥åŠæ›´å¿«é€Ÿçš„è¿‘æœŸæ”¹è¿›ï¼ˆo3å¾—åˆ†ä¸º60%ï¼‰ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³ç°æœ‰åŒ»ç–—å¯¹è¯è¯„ä¼°æ–¹æ³•çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯ç¼ºä¹å¼€æ”¾å¼è¯„ä¼°çš„çœŸå®åœºæ™¯ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½è¯„ä¼°ä¸å…¨é¢ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šHealthBenchçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ„å»ºä¸€ä¸ªåŒ…å«å¤šè½®å¯¹è¯çš„å¼€æ”¾å¼è¯„ä¼°æ¡†æ¶ï¼Œç»“åˆåŒ»ç”Ÿçš„ä¸“ä¸šè¯„åˆ†æ ‡å‡†ï¼Œå…¨é¢è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åŒ»ç–—å¥åº·é¢†åŸŸçš„è¡¨ç°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šHealthBenchçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€å¯¹è¯ç”Ÿæˆã€è¯„åˆ†æ ‡å‡†åˆ¶å®šå’Œæ€§èƒ½è¯„ä¼°å››ä¸ªä¸»è¦æ¨¡å—ã€‚æ•°æ®æ”¶é›†é˜¶æ®µé€šè¿‡ä¸ç”¨æˆ·å’ŒåŒ»ç–—ä¸“ä¸šäººå‘˜çš„äº’åŠ¨ç”Ÿæˆå¯¹è¯ï¼Œè¯„åˆ†æ ‡å‡†åˆ™ç”±åŒ»ç”Ÿå›¢é˜Ÿåˆ¶å®šã€‚

**å…³é”®åˆ›æ–°**ï¼šHealthBenchçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶å¼€æ”¾å¼è¯„ä¼°æœºåˆ¶å’Œå¤šç»´åº¦è¯„åˆ†æ ‡å‡†ï¼Œèƒ½å¤Ÿæ¶µç›–æ›´å¹¿æ³›çš„å¥åº·æƒ…å¢ƒå’Œè¡Œä¸ºç»´åº¦ï¼Œä¸ä¼ ç»Ÿçš„é€‰æ‹©é¢˜æˆ–ç®€ç­”é¢˜è¯„ä¼°æ–¹æ³•æœ¬è´¨ä¸Šä¸åŒã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸Šï¼ŒHealthBenché‡‡ç”¨äº†48562ä¸ªç‹¬ç‰¹çš„è¯„åˆ†æ ‡å‡†ï¼Œæ¶µç›–äº†å‡†ç¡®æ€§ã€æŒ‡ä»¤éµå¾ªå’Œæ²Ÿé€šç­‰å¤šä¸ªç»´åº¦ï¼Œç¡®ä¿è¯„ä¼°çš„å…¨é¢æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒHealthBenchçš„å¼•å…¥ä½¿å¾—æ¨¡å‹è¯„ä¼°çš„å‡†ç¡®æ€§å’Œå…¨é¢æ€§æ˜¾è‘—æå‡ã€‚GPT-3.5 Turboçš„å¾—åˆ†ä¸º16%ï¼Œè€ŒGPT-4oçš„å¾—åˆ†ä¸º32%ï¼Œæ›´å°çš„GPT-4.1 nanoæ¨¡å‹åœ¨æ€§èƒ½ä¸Šè¶…è¶Šäº†GPT-4oï¼Œä¸”æˆæœ¬é™ä½äº†25å€ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§ä»·æ¯”ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

HealthBenchçš„ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºåŒ»ç–—å¥åº·é¢†åŸŸï¼Œå°¤å…¶æ˜¯åœ¨å¤§å‹è¯­è¨€æ¨¡å‹çš„å¼€å‘å’Œè¯„ä¼°ä¸­ã€‚é€šè¿‡æä¾›ä¸€ä¸ªæ ‡å‡†åŒ–çš„è¯„ä¼°æ¡†æ¶ï¼ŒHealthBenchèƒ½å¤Ÿå¸®åŠ©å¼€å‘è€…ä¼˜åŒ–æ¨¡å‹æ€§èƒ½ï¼Œæå‡åŒ»ç–—æœåŠ¡è´¨é‡ï¼Œæœ€ç»ˆé€ ç¦äººç±»å¥åº·ã€‚æ­¤å¤–ï¼Œè¯¥åŸºå‡†è¿˜å¯ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›å‚è€ƒï¼Œæ¨åŠ¨åŒ»ç–—AIæŠ€æœ¯çš„è¿›æ­¥ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present HealthBench, an open-source benchmark measuring the performance and safety of large language models in healthcare. HealthBench consists of 5,000 multi-turn conversations between a model and an individual user or healthcare professional. Responses are evaluated using conversation-specific rubrics created by 262 physicians. Unlike previous multiple-choice or short-answer benchmarks, HealthBench enables realistic, open-ended evaluation through 48,562 unique rubric criteria spanning several health contexts (e.g., emergencies, transforming clinical data, global health) and behavioral dimensions (e.g., accuracy, instruction following, communication). HealthBench performance over the last two years reflects steady initial progress (compare GPT-3.5 Turbo's 16% to GPT-4o's 32%) and more rapid recent improvements (o3 scores 60%). Smaller models have especially improved: GPT-4.1 nano outperforms GPT-4o and is 25 times cheaper. We additionally release two HealthBench variations: HealthBench Consensus, which includes 34 particularly important dimensions of model behavior validated via physician consensus, and HealthBench Hard, where the current top score is 32%. We hope that HealthBench grounds progress towards model development and applications that benefit human health.

