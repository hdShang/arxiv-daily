---
layout: default
title: HCR-Reasoner: Synergizing Large Language Models and Theory for Human-like Causal Reasoning
---

# HCR-Reasoner: Synergizing Large Language Models and Theory for Human-like Causal Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.08750" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.08750v2</a>
  <a href="https://arxiv.org/pdf/2505.08750.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.08750v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.08750v2', 'HCR-Reasoner: Synergizing Large Language Models and Theory for Human-like Causal Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yanxi Zhang, Xin Cong, Zhong Zhang, Xiao Liu, Dongyan Zhao, Yesai Wu

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-13 (æ›´æ–°: 2025-10-18)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHCR-Reasonerä»¥è§£å†³äººç±»å› æœæ¨ç†çš„ç³»ç»Ÿæ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å› æœæ¨ç†` `å¤§å‹è¯­è¨€æ¨¡å‹` `å®é™…å› æœæ€§` `å› æœåˆ¤æ–­` `æ™ºèƒ½å†³ç­–` `å¿ƒç†è°ƒèŠ‚å› ç´ ` `ç†è®ºæŒ‡å¯¼æ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å› æœæ¨ç†ä¸­ç¼ºä¹ç³»ç»Ÿæ€§ï¼Œå®é™…å› æœæ€§å’Œå› æœåˆ¤æ–­çš„ç ”ç©¶å¤šä¸ºå­¤ç«‹è¿›è¡Œï¼Œå¯¼è‡´æ— æ³•æœ‰æ•ˆæ¨¡æ‹Ÿäººç±»çš„æ¨ç†è¿‡ç¨‹ã€‚
2. HCR-Reasoneræ¡†æ¶é€šè¿‡æ•´åˆå®é™…å› æœæ€§ç†è®ºä¸å› æœåˆ¤æ–­ï¼Œåˆ©ç”¨LLMså®ç°ç±»äººå› æœæ¨ç†ï¼Œæ¨¡æ‹Ÿäººç±»çš„å› æœé“¾è¯†åˆ«ä¸åˆ¤æ–­è¿‡ç¨‹ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒHCR-Reasoneråœ¨å› æœä¸€è‡´æ€§ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»ŸLLMsï¼Œä¸”é€šè¿‡ç†è®ºæŒ‡å¯¼çš„æ¨ç†æ–¹å¼æå‡äº†æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äººç±»çš„å› æœæ¨ç†èƒ½åŠ›æ˜¯å¼ºäººå·¥æ™ºèƒ½çš„åŸºç¡€ã€‚äººç±»é€šå¸¸é¦–å…ˆè¯†åˆ«äº‹ä»¶æ˜¯å¦å±äºå› æœé“¾ï¼Œç„¶åå—é“å¾·ã€å¸¸æ€å’Œæ„å›¾ç­‰è°ƒèŠ‚å› ç´ çš„å½±å“åšå‡ºæœ€ç»ˆåˆ¤æ–­ã€‚ç°æœ‰çš„å®é™…å› æœæ€§å’Œå› æœåˆ¤æ–­é¢†åŸŸç ”ç©¶ç›¸å¯¹å­¤ç«‹ï¼Œç¼ºä¹åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ç³»ç»Ÿæ–¹æ³•ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºHCR-Reasoneræ¡†æ¶ï¼Œç³»ç»Ÿæ€§åœ°å°†å®é™…å› æœæ€§ç†è®ºå’Œå› æœåˆ¤æ–­æ•´åˆåˆ°LLMsä¸­ï¼Œä»¥å®ç°ç±»äººå› æœæ¨ç†ã€‚é€šè¿‡å®é™…å› æœæ€§å½¢å¼åŒ–è¿‡æ»¤ç»“æ„ä¸Šå¿…è¦çš„å€™é€‰åŸå› ï¼Œå¹¶åˆ©ç”¨å› æœåˆ¤æ–­å› ç´ ç¡®å®šå¿ƒç†ä¸Šé€‰æ‹©çš„åŸå› ã€‚æˆ‘ä»¬è¿˜å¼•å…¥HCR-BenchåŸºå‡†ï¼ŒåŒ…å«1093ä¸ªå¸¦è¯¦ç»†æ¨ç†æ­¥éª¤çš„æ³¨é‡Šå®ä¾‹ã€‚ç»“æœè¡¨æ˜ï¼ŒHCR-Reasoneræ˜¾è‘—æé«˜äº†LLMsä¸äººç±»çš„å› æœä¸€è‡´æ€§ï¼Œç†è®ºæŒ‡å¯¼çš„æ¨ç†é›†æˆåœ¨å®ç°ç±»äººå› æœæ¨ç†ä¸­éå¸¸æœ‰æ•ˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å› æœæ¨ç†æ–¹æ³•åœ¨å®é™…å› æœæ€§ä¸å› æœåˆ¤æ–­ç ”ç©¶ä¸­çš„å­¤ç«‹æ€§é—®é¢˜ï¼Œç¼ºä¹ç³»ç»Ÿæ€§æ•´åˆå¯¼è‡´æ— æ³•æœ‰æ•ˆæ¨¡æ‹Ÿäººç±»å› æœæ¨ç†çš„å¤æ‚æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šHCR-Reasoneré€šè¿‡å°†å®é™…å› æœæ€§ç†è®ºä¸å› æœåˆ¤æ–­ç›¸ç»“åˆï¼Œåˆ©ç”¨LLMsè¿›è¡Œç±»äººå› æœæ¨ç†ï¼Œé¦–å…ˆè¯†åˆ«å› æœé“¾ä¸­çš„å€™é€‰åŸå› ï¼Œç„¶åé€šè¿‡å¿ƒç†è°ƒèŠ‚å› ç´ è¿›è¡Œæœ€ç»ˆåˆ¤æ–­ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šHCR-Reasoneræ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šå®é™…å› æœæ€§æ¨¡å—ç”¨äºç­›é€‰å€™é€‰åŸå› ï¼Œå› æœåˆ¤æ–­æ¨¡å—ç”¨äºè¯„ä¼°å¿ƒç†è°ƒèŠ‚å› ç´ çš„å½±å“ï¼Œæœ€ç»ˆè¾“å‡ºç±»äººå› æœæ¨ç†ç»“æœã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°åœ¨äºç³»ç»Ÿæ€§åœ°å°†ç†è®ºæŒ‡å¯¼çš„å› æœæ¨ç†æ–¹æ³•ä¸LLMsç»“åˆï¼Œå¡«è¡¥äº†å®é™…å› æœæ€§ä¸å› æœåˆ¤æ–­é¢†åŸŸçš„ç ”ç©¶ç©ºç™½ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–å› æœé“¾è¯†åˆ«çš„å‡†ç¡®æ€§ï¼Œå¹¶é€šè¿‡HCR-BenchåŸºå‡†è¿›è¡Œç»†è‡´çš„è¯„ä¼°ï¼Œç¡®ä¿æ¨¡å‹åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒHCR-Reasoneråœ¨å› æœä¸€è‡´æ€§æ–¹é¢ç›¸æ¯”ä¼ ç»ŸLLMsæœ‰æ˜¾è‘—æå‡ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨HCR-BenchåŸºå‡†ä¸Šï¼Œæ¨¡å‹çš„å› æœæ¨ç†å‡†ç¡®ç‡æé«˜äº†çº¦20%ï¼Œå±•ç¤ºäº†ç†è®ºæŒ‡å¯¼æ¨ç†çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

HCR-Reasonerçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ï¼ŒåŒ…æ‹¬æ™ºèƒ½åŠ©æ‰‹ã€è‡ªåŠ¨åŒ–å†³ç­–ç³»ç»Ÿä»¥åŠæ•™è‚²é¢†åŸŸçš„æ™ºèƒ½è¾…å¯¼ç­‰ã€‚é€šè¿‡æ¨¡æ‹Ÿäººç±»çš„å› æœæ¨ç†è¿‡ç¨‹ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæå‡æœºå™¨åœ¨å¤æ‚æƒ…å¢ƒä¸‹çš„å†³ç­–èƒ½åŠ›ï¼Œæ¨åŠ¨äººå·¥æ™ºèƒ½çš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Genuine human-like causal reasoning is fundamental for strong artificial intelligence. Humans typically identify whether an event is part of the causal chain first, and then influenced by modulatory factors such as morality, normality, and intention to make the final judgment. These two stages naturally map to the fields of 1) actual causality that provides formalisms for causal chain membership and 2) causal judgment from cognitive science that studies psychological modulators that influence causal selection. However, these two domains have largely been studied in isolation, leaving a gap for a systematic method based on LLMs. Therefore, we introduce HCR-Reasoner, a framework that systematically integrates the theory of actual causality and causal judgment into LLMs for human-like causal reasoning. It simulates humans by using actual causality formalisms to filter for structurally necessary candidate causes and causal judgment factors to determine the psychologically selected cause. For fine-grained evaluation, we introduce HCR-Bench, a challenging benchmark with 1,093 annotated instances with detailed reasoning steps. Results show HCR-Reasoner consistently and significantly improves LLMs' causal alignment with humans, and that explicitly integrating theory-guided reasoning into LLMs is highly effective for achieving faithful human-like causal reasoning.

