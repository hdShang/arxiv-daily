---
layout: default
title: "MultiHoax: A Dataset of Multi-hop False-Premise Questions"
---

# MultiHoax: A Dataset of Multi-hop False-Premise Questions

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.00264" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.00264v2</a>
  <a href="https://arxiv.org/pdf/2506.00264.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.00264v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.00264v2', 'MultiHoax: A Dataset of Multi-hop False-Premise Questions')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mohammadamin Shafiei, Hamidreza Saffari, Nafise Sadat Moosavi

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-30 (æ›´æ–°: 2025-06-04)

**å¤‡æ³¨**: accepted at ACL Findings 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMultiHoaxæ•°æ®é›†ä»¥è§£å†³å¤šè·³é”™è¯¯å‰æé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šè·³æ¨ç†` `é”™è¯¯å‰æ` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ•°æ®é›†æ„å»º` `çŸ¥è¯†æ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨å•è·³é”™è¯¯å‰æé—®é¢˜ï¼Œç¼ºä¹å¯¹å¤šè·³æ¨ç†çš„æœ‰æ•ˆè¯„ä¼°ï¼Œå¯¼è‡´æ¨¡å‹åœ¨å¤æ‚æ¨ç†åœºæ™¯ä¸­çš„è¡¨ç°ä¸ä½³ã€‚
2. è®ºæ–‡æå‡ºMultiHoaxæ•°æ®é›†ï¼Œä¸“æ³¨äºå¤šè·³é”™è¯¯å‰æé—®é¢˜ï¼Œåˆ©ç”¨ç»´åŸºç™¾ç§‘ä½œä¸ºçŸ¥è¯†æ¥æºï¼Œæ¶µç›–å¤šå›½å’Œå¤šç±»åˆ«çŸ¥è¯†ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå½“å‰æœ€å…ˆè¿›çš„è¯­è¨€æ¨¡å‹åœ¨å¤šè·³æ¨ç†ä»»åŠ¡ä¸­æ£€æµ‹é”™è¯¯å‰æçš„èƒ½åŠ›ä¸è¶³ï¼Œå¼ºè°ƒäº†è¯¥é¢†åŸŸçš„ç ”ç©¶éœ€æ±‚ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é«˜é£é™©é¢†åŸŸçš„å¹¿æ³›åº”ç”¨ï¼Œå…¶æ£€æµ‹é”™è¯¯å‡è®¾å’Œè¿›è¡Œæ‰¹åˆ¤æ€§æ¨ç†çš„èƒ½åŠ›è‡³å…³é‡è¦ã€‚é”™è¯¯å‰æé—®é¢˜ï¼ˆFPQsï¼‰ä½œä¸ºä¸€ç§é‡è¦çš„è¯„ä¼°æ–¹æ³•ï¼Œèƒ½å¤Ÿæ­ç¤ºç”±äºé”™è¯¯å‡è®¾å¯¼è‡´çš„ä¸æ­£ç¡®å“åº”ã€‚ç°æœ‰åŸºå‡†ä¸»è¦é›†ä¸­åœ¨å•è·³FPQsï¼Œè€Œç°å®ä¸–ç•Œçš„æ¨ç†å¾€å¾€éœ€è¦å¤šè·³æ¨ç†ï¼Œæ¨¡å‹å¿…é¡»åœ¨å¤šä¸ªæ¨ç†æ­¥éª¤ä¸­éªŒè¯ä¸€è‡´æ€§ï¼Œè€Œä¸æ˜¯ä¾èµ–è¡¨é¢çº¿ç´¢ã€‚ä¸ºå¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬æå‡ºäº†MultiHoaxï¼Œä¸€ä¸ªç”¨äºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚å¤šæ­¥éª¤æ¨ç†ä»»åŠ¡ä¸­å¤„ç†é”™è¯¯å‰æèƒ½åŠ›çš„åŸºå‡†ã€‚æˆ‘ä»¬çš„æ•°æ®é›†æ¶µç›–ä¸ƒä¸ªå›½å®¶å’Œåä¸ªå¤šæ ·çš„çŸ¥è¯†ç±»åˆ«ï¼Œä»¥ç»´åŸºç™¾ç§‘ä½œä¸ºä¸»è¦çŸ¥è¯†æ¥æºï¼Œä»¥ä¿ƒè¿›è·¨åŒºåŸŸçš„äº‹å®æ¨ç†ã€‚å®éªŒè¡¨æ˜ï¼Œæœ€å…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¸åŒå›½å®¶ã€çŸ¥è¯†ç±»åˆ«å’Œå¤šè·³æ¨ç†ç±»å‹ä¸­æ£€æµ‹é”™è¯¯å‰æçš„èƒ½åŠ›è¾ƒå¼±ï¼Œçªæ˜¾äº†æ”¹è¿›é”™è¯¯å‰ææ£€æµ‹å’Œå¢å¼ºå¤šè·³æ¨ç†èƒ½åŠ›çš„å¿…è¦æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†å¤šè·³é”™è¯¯å‰æé—®é¢˜æ—¶çš„ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­äºå•è·³æ¨ç†ï¼Œæ— æ³•æœ‰æ•ˆåº”å¯¹å¤æ‚æ¨ç†åœºæ™¯ä¸­çš„é”™è¯¯å‡è®¾ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºMultiHoaxæ•°æ®é›†ï¼Œé€šè¿‡å¤šè·³æ¨ç†ä»»åŠ¡è¯„ä¼°æ¨¡å‹çš„é”™è¯¯å‰ææ£€æµ‹èƒ½åŠ›ï¼Œå¼ºè°ƒæ¨¡å‹åœ¨å¤šä¸ªæ¨ç†æ­¥éª¤ä¸­éªŒè¯ä¸€è‡´æ€§çš„å¿…è¦æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚æ•°æ®é›†æ¶µç›–å¤šå›½å’Œå¤šç±»åˆ«çŸ¥è¯†ï¼Œæ¨¡å‹åˆ™åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œè®­ç»ƒå’Œæ€§èƒ½è¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥å¤šè·³æ¨ç†çš„æ¡†æ¶ï¼Œå¡«è¡¥äº†ç°æœ‰å•è·³FPQsçš„ç ”ç©¶ç©ºç™½ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨æ›´å¤æ‚çš„æ¨ç†ä»»åŠ¡ä¸­è¿›è¡Œè¯„ä¼°ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®é›†æ„å»ºä¸­ï¼Œé€‰æ‹©ç»´åŸºç™¾ç§‘ä½œä¸ºçŸ¥è¯†æ¥æºï¼Œç¡®ä¿ä¿¡æ¯çš„å‡†ç¡®æ€§å’Œå¤šæ ·æ€§ã€‚æ­¤å¤–ï¼Œè®¾è®¡äº†é€‚åˆå¤šè·³æ¨ç†çš„æŸå¤±å‡½æ•°ï¼Œä»¥æå‡æ¨¡å‹åœ¨è¯¥ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå½“å‰æœ€å…ˆè¿›çš„è¯­è¨€æ¨¡å‹åœ¨å¤šè·³æ¨ç†ä»»åŠ¡ä¸­æ£€æµ‹é”™è¯¯å‰æçš„èƒ½åŠ›æ™®éè¾ƒå¼±ï¼Œå°¤å…¶åœ¨ä¸åŒå›½å®¶å’ŒçŸ¥è¯†ç±»åˆ«ä¸­è¡¨ç°ä¸ä½³ï¼Œçªæ˜¾äº†è¯¥é¢†åŸŸçš„ç ”ç©¶éœ€æ±‚å’Œæ”¹è¿›ç©ºé—´ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€æ³•å¾‹å’ŒåŒ»ç–—ç­‰é«˜é£é™©é¢†åŸŸï¼Œèƒ½å¤Ÿå¸®åŠ©å¤§å‹è¯­è¨€æ¨¡å‹æ›´å¥½åœ°ç†è§£å’Œå¤„ç†å¤æ‚çš„æ¨ç†ä»»åŠ¡ï¼Œä»è€Œæé«˜å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å¯é æ€§å’Œå‡†ç¡®æ€§ã€‚æœªæ¥ï¼Œè¯¥æ•°æ®é›†å¯èƒ½æˆä¸ºè¯„ä¼°å’Œæ”¹è¿›è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›çš„é‡è¦åŸºå‡†ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> As Large Language Models are increasingly deployed in high-stakes domains, their ability to detect false assumptions and reason critically is crucial for ensuring reliable outputs. False-premise questions (FPQs) serve as an important evaluation method by exposing cases where flawed assumptions lead to incorrect responses. While existing benchmarks focus on single-hop FPQs, real-world reasoning often requires multi-hop inference, where models must verify consistency across multiple reasoning steps rather than relying on surface-level cues. To address this gap, we introduce MultiHoax, a benchmark for evaluating LLMs' ability to handle false premises in complex, multi-step reasoning tasks. Our dataset spans seven countries and ten diverse knowledge categories, using Wikipedia as the primary knowledge source to enable factual reasoning across regions. Experiments reveal that state-of-the-art LLMs struggle to detect false premises across different countries, knowledge categories, and multi-hop reasoning types, highlighting the need for improved false premise detection and more robust multi-hop reasoning capabilities in LLMs.

