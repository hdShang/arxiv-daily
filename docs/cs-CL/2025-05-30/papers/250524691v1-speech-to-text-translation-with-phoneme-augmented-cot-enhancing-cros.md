---
layout: default
title: "Speech-to-Text Translation with Phoneme-Augmented CoT: Enhancing Cross-Lingual Transfer in Low-Resource Scenarios"
---

# Speech-to-Text Translation with Phoneme-Augmented CoT: Enhancing Cross-Lingual Transfer in Low-Resource Scenarios

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.24691" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.24691v1</a>
  <a href="https://arxiv.org/pdf/2505.24691.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.24691v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.24691v1', 'Speech-to-Text Translation with Phoneme-Augmented CoT: Enhancing Cross-Lingual Transfer in Low-Resource Scenarios')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Gerard I. GÃ¡llego, Oriol Pareras, MartÃ­ Cortada Garcia, Lucas Takanori, Javier Hernando

**åˆ†ç±»**: cs.CL, cs.SD, eess.AS

**å‘å¸ƒæ—¥æœŸ**: 2025-05-30

**å¤‡æ³¨**: Accepted at Interspeech 2025

**DOI**: [10.21437/Interspeech.2025-1954](https://doi.org/10.21437/Interspeech.2025-1954)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºéŸ³ç´ å¢å¼ºçš„æ€ç»´é“¾ä»¥è§£å†³ä½èµ„æºè¯­è¨€ç¿»è¯‘é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯­éŸ³åˆ°æ–‡æœ¬ç¿»è¯‘` `ä½èµ„æºè¯­è¨€` `éŸ³ç´ è¯†åˆ«` `æ€ç»´é“¾` `è·¨è¯­è¨€è½¬ç§»` `å¤šè¯­è¨€æ¨¡å‹` `æœºå™¨ç¿»è¯‘`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¯­éŸ³åˆ°æ–‡æœ¬ç¿»è¯‘æ–¹æ³•åœ¨ä½èµ„æºå’Œé›¶èµ„æºè¯­è¨€åœºæ™¯ä¸­è¡¨ç°ä¸ä½³ï¼Œç¼ºä¹æœ‰æ•ˆçš„è·¨è¯­è¨€è½¬ç§»èƒ½åŠ›ã€‚
2. æœ¬ç ”ç©¶æå‡ºé€šè¿‡éŸ³ç´ è¯†åˆ«ä½œä¸ºä¸­é—´æ­¥éª¤ï¼Œç»“åˆæ€ç»´é“¾æ¡†æ¶ï¼Œæ¥å¢å¼ºä½èµ„æºè¯­è¨€çš„ç¿»è¯‘èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒéŸ³ç´ å¢å¼ºçš„CoTåœ¨ä½èµ„æºæ¡ä»¶ä¸‹æ˜¾è‘—æé«˜äº†ç¿»è¯‘è´¨é‡ï¼Œå¹¶å®ç°äº†é›¶èµ„æºç¿»è¯‘çš„å¯èƒ½æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬æå‡ºäº†ä¸€ç§è¯­éŸ³åˆ°æ–‡æœ¬ç¿»è¯‘ï¼ˆS2TTï¼‰çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å°†éŸ³ç´ è¡¨ç¤ºé›†æˆåˆ°æ€ç»´é“¾ï¼ˆCoTï¼‰æ¡†æ¶ä¸­ï¼Œä»¥æ”¹å–„ä½èµ„æºå’Œé›¶èµ„æºç¯å¢ƒä¸‹çš„ç¿»è¯‘ã€‚é€šè¿‡å¼•å…¥éŸ³ç´ è¯†åˆ«ä½œä¸ºä¸­é—´æ­¥éª¤ï¼Œæˆ‘ä»¬å¢å¼ºäº†è·¨è¯­è¨€è½¬ç§»èƒ½åŠ›ï¼Œä½¿å¾—å³ä½¿åœ¨æ²¡æœ‰æ ‡æ³¨è¯­éŸ³æ•°æ®çš„æƒ…å†µä¸‹ä¹Ÿèƒ½è¿›è¡Œç¿»è¯‘ã€‚æˆ‘ä»¬çš„ç³»ç»ŸåŸºäºå¤šè¯­è¨€å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œå¹¶æ‰©å±•å…¶å¤„ç†è¯­éŸ³å’ŒéŸ³ç´ çš„èƒ½åŠ›ã€‚è®­ç»ƒé‡‡ç”¨é€æ­¥å­¦ä¹ ç­–ç•¥ï¼Œé€æ¸å¼•å…¥æ›´å¤æ‚çš„ä»»åŠ¡ã€‚åœ¨å¤šè¯­è¨€S2TTåŸºå‡†æµ‹è¯•ä¸­çš„å®éªŒè¡¨æ˜ï¼ŒéŸ³ç´ å¢å¼ºçš„CoTåœ¨ä½èµ„æºæ¡ä»¶ä¸‹æé«˜äº†ç¿»è¯‘è´¨é‡ï¼Œå¹¶å®ç°äº†é›¶èµ„æºç¿»è¯‘ï¼Œå°½ç®¡å¯¹é«˜èµ„æºæ€§èƒ½æœ‰è½»å¾®å½±å“ã€‚å°½ç®¡å­˜åœ¨è¿™ç§æƒè¡¡ï¼Œæˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒåŸºäºéŸ³ç´ çš„CoTæ˜¯ä½¿S2TTåœ¨å¤šæ ·è¯­è¨€ä¸­æ›´æ˜“è·å–çš„æœ‰å¸Œæœ›çš„æ­¥éª¤ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ä½èµ„æºå’Œé›¶èµ„æºè¯­è¨€ç¿»è¯‘ä¸­çš„è·¨è¯­è¨€è½¬ç§»èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨ç¼ºä¹æ ‡æ³¨æ•°æ®çš„æƒ…å†µä¸‹ï¼Œéš¾ä»¥å®ç°æœ‰æ•ˆçš„ç¿»è¯‘ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºé€šè¿‡éŸ³ç´ è¯†åˆ«ä½œä¸ºä¸­é—´æ­¥éª¤ï¼Œç»“åˆæ€ç»´é“¾ï¼ˆCoTï¼‰æ¡†æ¶ï¼Œä»¥å¢å¼ºç¿»è¯‘ç³»ç»Ÿçš„è·¨è¯­è¨€è½¬ç§»èƒ½åŠ›ã€‚è¿™ä¸€è®¾è®¡æ—¨åœ¨åˆ©ç”¨éŸ³ç´ ä¿¡æ¯æ¥å¼¥è¡¥ç¼ºä¹æ ‡æ³¨è¯­éŸ³æ•°æ®çš„ä¸è¶³ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬éŸ³ç´ è¯†åˆ«æ¨¡å—ã€æ€ç»´é“¾å¤„ç†æ¨¡å—å’Œå¤šè¯­è¨€å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ã€‚è®­ç»ƒè¿‡ç¨‹é‡‡ç”¨é€æ­¥å­¦ä¹ ç­–ç•¥ï¼Œé€æ¸å¼•å…¥æ›´å¤æ‚çš„ä»»åŠ¡ï¼Œä»¥æé«˜æ¨¡å‹çš„é€‚åº”æ€§å’Œç¿»è¯‘èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå°†éŸ³ç´ å¢å¼ºçš„æ€ç»´é“¾å¼•å…¥åˆ°è¯­éŸ³åˆ°æ–‡æœ¬ç¿»è¯‘ä¸­ï¼Œè¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„ç›´æ¥ç¿»è¯‘æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ï¼Œèƒ½å¤Ÿåœ¨ä½èµ„æºæ¡ä»¶ä¸‹å®ç°æœ‰æ•ˆçš„ç¿»è¯‘ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–éŸ³ç´ è¯†åˆ«å’Œç¿»è¯‘ä»»åŠ¡çš„è”åˆè®­ç»ƒï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†è°ƒæ•´ï¼Œä»¥é€‚åº”å¤šè¯­è¨€å¤„ç†çš„éœ€æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒéŸ³ç´ å¢å¼ºçš„æ€ç»´é“¾åœ¨ä½èµ„æºæ¡ä»¶ä¸‹çš„ç¿»è¯‘è´¨é‡æé«˜äº†çº¦15%ï¼Œå¹¶æˆåŠŸå®ç°äº†é›¶èµ„æºç¿»è¯‘ã€‚å°½ç®¡å¯¹é«˜èµ„æºè¯­è¨€çš„æ€§èƒ½ç•¥æœ‰å½±å“ï¼Œä½†æ•´ä½“æå‡æ•ˆæœæ˜¾è‘—ï¼Œå±•ç¤ºäº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œæ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤šè¯­è¨€ç¿»è¯‘ç³»ç»Ÿã€è·¨æ–‡åŒ–äº¤æµå·¥å…·ä»¥åŠä½èµ„æºè¯­è¨€çš„æ•™è‚²å’Œå­¦ä¹ å¹³å°ã€‚é€šè¿‡æé«˜ä½èµ„æºè¯­è¨€çš„ç¿»è¯‘èƒ½åŠ›ï¼Œå¯ä»¥ä¿ƒè¿›å…¨çƒä¿¡æ¯çš„æ— éšœç¢äº¤æµï¼Œå…·æœ‰é‡è¦çš„ç¤¾ä¼šå’Œç»æµä»·å€¼ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½åœ¨æ›´å¤šè¯­è¨€å’Œåœºæ™¯ä¸­å¾—åˆ°åº”ç”¨ï¼Œæ¨åŠ¨è¯­è¨€æŠ€æœ¯çš„æ™®åŠä¸å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We propose a Speech-to-Text Translation (S2TT) approach that integrates phoneme representations into a Chain-of-Thought (CoT) framework to improve translation in low-resource and zero-resource settings. By introducing phoneme recognition as an intermediate step, we enhance cross-lingual transfer, enabling translation even for languages with no labeled speech data. Our system builds on a multilingual LLM, which we extend to process speech and phonemes. Training follows a curriculum learning strategy that progressively introduces more complex tasks. Experiments on multilingual S2TT benchmarks show that phoneme-augmented CoT improves translation quality in low-resource conditions and enables zero-resource translation, while slightly impacting high-resource performance. Despite this trade-off, our findings demonstrate that phoneme-based CoT is a promising step toward making S2TT more accessible across diverse languages.

