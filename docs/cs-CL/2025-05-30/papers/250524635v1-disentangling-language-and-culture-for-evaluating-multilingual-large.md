---
layout: default
title: Disentangling Language and Culture for Evaluating Multilingual Large Language Models
---

# Disentangling Language and Culture for Evaluating Multilingual Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.24635" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.24635v1</a>
  <a href="https://arxiv.org/pdf/2505.24635.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.24635v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.24635v1', 'Disentangling Language and Culture for Evaluating Multilingual Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiahao Ying, Wei Tang, Yiran Zhao, Yixin Cao, Yu Rong, Wenxuan Zhang

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-30

**å¤‡æ³¨**: Accepted to ACL 2025 (Main Conference)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŒé‡è¯„ä¼°æ¡†æ¶ä»¥è¯„ä¼°å¤šè¯­è¨€å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šè¯­è¨€æ¨¡å‹` `æ–‡åŒ–èƒŒæ™¯` `è¯„ä¼°æ¡†æ¶` `ç¥ç»å…ƒæ¿€æ´»` `è·¨æ–‡åŒ–äº¤æµ` `è¯­è¨€åª’ä»‹` `æ–‡åŒ–è¯­è¨€ååŒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†è€ƒè™‘è¯­è¨€å’Œæ–‡åŒ–å¯¹å¤šè¯­è¨€æ¨¡å‹è¯„ä¼°çš„å½±å“ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœçš„ç‰‡é¢æ€§ã€‚
2. è®ºæ–‡æå‡ºçš„åŒé‡è¯„ä¼°æ¡†æ¶é€šè¿‡åˆ†è§£è¯­è¨€åª’ä»‹å’Œæ–‡åŒ–èƒŒæ™¯ï¼Œæä¾›äº†æ›´ä¸ºç»†è‡´çš„è¯„ä¼°æ–¹å¼ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ¨¡å‹åœ¨æ–‡åŒ–ä¸€è‡´æ€§é—®é¢˜ä¸Šè¡¨ç°æ›´ä½³ï¼Œæ­ç¤ºäº†æ–‡åŒ–è¯­è¨€ååŒç°è±¡çš„å­˜åœ¨ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŒé‡è¯„ä¼°æ¡†æ¶ï¼Œä»¥å…¨é¢è¯„ä¼°å¤šè¯­è¨€å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„èƒ½åŠ›ã€‚é€šè¿‡åœ¨è¯­è¨€åª’ä»‹å’Œæ–‡åŒ–èƒŒæ™¯ä¸¤ä¸ªç»´åº¦ä¸Šè¿›è¡Œè¯„ä¼°çš„åˆ†è§£ï¼Œè¯¥æ¡†æ¶ä½¿å¾—å¯¹LLMsåœ¨æœ¬åœŸå’Œè·¨æ–‡åŒ–èƒŒæ™¯ä¸‹å¤„ç†é—®é¢˜çš„èƒ½åŠ›è¿›è¡Œç»†è‡´åˆ†ææˆä¸ºå¯èƒ½ã€‚å¯¹å¤šç§æ¨¡å‹è¿›è¡Œäº†å¹¿æ³›è¯„ä¼°ï¼Œæ­ç¤ºäº†æ˜¾è‘—çš„â€œæ–‡åŒ–è¯­è¨€ååŒâ€ç°è±¡ï¼Œå³å½“é—®é¢˜ä¸è¯­è¨€æ–‡åŒ–ç›¸ä¸€è‡´æ—¶ï¼Œæ¨¡å‹è¡¨ç°æ›´ä½³ã€‚é€šè¿‡å¯è§£é‡Šæ€§æ¢æµ‹è¿›ä¸€æ­¥æ¢ç´¢äº†è¿™ä¸€ç°è±¡ï¼Œæ˜¾ç¤ºåœ¨ç‰¹å®šè¯­è¨€çš„æ–‡åŒ–èƒŒæ™¯ä¸‹ï¼Œç‰¹å®šç¥ç»å…ƒçš„æ¿€æ´»æ¯”ä¾‹æ›´é«˜ã€‚è¿™ä¸€æ¿€æ´»æ¯”ä¾‹å¯èƒ½ä½œä¸ºè¯„ä¼°æ¨¡å‹è®­ç»ƒæœŸé—´å¤šè¯­è¨€æ€§èƒ½çš„æ½œåœ¨æŒ‡æ ‡ã€‚æˆ‘ä»¬çš„ç ”ç©¶æŒ‘æˆ˜äº†å½“å‰å¯¹ä¸»è¦åœ¨è‹±è¯­æ•°æ®ä¸Šè®­ç»ƒçš„LLMsåœ¨å„è¯­è¨€é—´è¡¨ç°å‡åŒ€çš„æ™®éçœ‹æ³•ï¼Œå¹¶å¼ºè°ƒäº†æ–‡åŒ–å’Œè¯­è¨€æ¨¡å‹è¯„ä¼°çš„å¿…è¦æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¤šè¯­è¨€å¤§è¯­è¨€æ¨¡å‹è¯„ä¼°æ–¹æ³•æœªèƒ½è€ƒè™‘æ–‡åŒ–èƒŒæ™¯çš„ä¸è¶³ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœä¸å¤Ÿå…¨é¢å’Œå‡†ç¡®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºåŒé‡è¯„ä¼°æ¡†æ¶ï¼Œé€šè¿‡å°†è¯„ä¼°åˆ†è§£ä¸ºè¯­è¨€åª’ä»‹å’Œæ–‡åŒ–èƒŒæ™¯ä¸¤ä¸ªç»´åº¦ï¼Œèƒ½å¤Ÿæ›´ç»†è‡´åœ°åˆ†ææ¨¡å‹åœ¨ä¸åŒæ–‡åŒ–å’Œè¯­è¨€ç¯å¢ƒä¸‹çš„è¡¨ç°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šè¯­è¨€åª’ä»‹è¯„ä¼°å’Œæ–‡åŒ–èƒŒæ™¯è¯„ä¼°ã€‚é¦–å…ˆï¼Œæ¨¡å‹åœ¨ç‰¹å®šè¯­è¨€ä¸‹å¤„ç†é—®é¢˜ï¼Œå…¶æ¬¡ï¼Œåˆ†æé—®é¢˜çš„æ–‡åŒ–èƒŒæ™¯å¯¹æ¨¡å‹è¡¨ç°çš„å½±å“ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºæ­ç¤ºäº†â€œæ–‡åŒ–è¯­è¨€ååŒâ€ç°è±¡ï¼Œè¡¨æ˜æ¨¡å‹åœ¨æ–‡åŒ–ä¸€è‡´æ€§é—®é¢˜ä¸Šè¡¨ç°æ›´ä½³ï¼Œè¿™ä¸€å‘ç°æŒ‘æˆ˜äº†ä¼ ç»Ÿçš„è¯„ä¼°è§‚å¿µã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œä½¿ç”¨äº†ç‰¹å®šçš„ç¥ç»å…ƒæ¿€æ´»æ¯”ä¾‹ä½œä¸ºè¯„ä¼°æŒ‡æ ‡ï¼Œè®¾è®¡äº†ç›¸åº”çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ï¼Œä»¥ä¾¿æ›´å¥½åœ°æ•æ‰æ–‡åŒ–èƒŒæ™¯å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ¨¡å‹åœ¨æ–‡åŒ–ä¸€è‡´æ€§é—®é¢˜ä¸Šè¡¨ç°æ›´ä½³ï¼Œæ¿€æ´»ç‰¹å®šç¥ç»å…ƒçš„æ¯”ä¾‹æ˜¾è‘—æé«˜ã€‚ä¸åŸºçº¿æ¨¡å‹ç›¸æ¯”ï¼Œè¯„ä¼°æ¡†æ¶ä¸‹çš„æ¨¡å‹åœ¨å¤šè¯­è¨€ä»»åŠ¡ä¸­çš„æ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°15%ä»¥ä¸Šï¼ŒéªŒè¯äº†æ–‡åŒ–å’Œè¯­è¨€è¯„ä¼°çš„é‡è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤šè¯­è¨€ç¿»è¯‘ã€è·¨æ–‡åŒ–äº¤æµå’Œå›½é™…åŒ–è½¯ä»¶å¼€å‘ç­‰ã€‚é€šè¿‡æ›´å‡†ç¡®çš„è¯„ä¼°æ–¹æ³•ï¼Œèƒ½å¤Ÿæå‡å¤šè¯­è¨€æ¨¡å‹åœ¨ä¸åŒæ–‡åŒ–èƒŒæ™¯ä¸‹çš„é€‚åº”æ€§å’Œè¡¨ç°ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper introduces a Dual Evaluation Framework to comprehensively assess the multilingual capabilities of LLMs. By decomposing the evaluation along the dimensions of linguistic medium and cultural context, this framework enables a nuanced analysis of LLMs' ability to process questions within both native and cross-cultural contexts cross-lingually. Extensive evaluations are conducted on a wide range of models, revealing a notable "CulturalLinguistic Synergy" phenomenon, where models exhibit better performance when questions are culturally aligned with the language. This phenomenon is further explored through interpretability probing, which shows that a higher proportion of specific neurons are activated in a language's cultural context. This activation proportion could serve as a potential indicator for evaluating multilingual performance during model training. Our findings challenge the prevailing notion that LLMs, primarily trained on English data, perform uniformly across languages and highlight the necessity of culturally and linguistically model evaluations. Our code can be found at https://yingjiahao14. github.io/Dual-Evaluation/.

