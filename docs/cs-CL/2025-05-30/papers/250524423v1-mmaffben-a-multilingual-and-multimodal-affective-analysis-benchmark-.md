---
layout: default
title: "MMAFFBen: A Multilingual and Multimodal Affective Analysis Benchmark for Evaluating LLMs and VLMs"
---

# MMAFFBen: A Multilingual and Multimodal Affective Analysis Benchmark for Evaluating LLMs and VLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.24423" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.24423v1</a>
  <a href="https://arxiv.org/pdf/2505.24423.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.24423v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.24423v1', 'MMAFFBen: A Multilingual and Multimodal Affective Analysis Benchmark for Evaluating LLMs and VLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhiwei Liu, Lingfei Qian, Qianqian Xie, Jimin Huang, Kailai Yang, Sophia Ananiadou

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-30

**å¤‡æ³¨**: Work in progress

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/lzw108/MMAFFBen)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMMAFFBenåŸºå‡†ä»¥è§£å†³å¤šè¯­è¨€å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æè¯„ä¼°é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šè¯­è¨€å¤„ç†` `æƒ…æ„Ÿåˆ†æ` `å¤šæ¨¡æ€å­¦ä¹ ` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ•°æ®é›†æ„å»º` `æ¨¡å‹å¾®è°ƒ` `æƒ…æ„Ÿåˆ†ç±»` `æƒ…æ„Ÿå¼ºåº¦`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æƒ…æ„Ÿåˆ†æè¯„ä¼°åŸºå‡†ç¼ºä¹å…¨é¢æ€§ï¼Œå¯¼è‡´å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æƒ…æ„Ÿåˆ†æä»»åŠ¡ä¸­çš„èƒ½åŠ›æœªè¢«å……åˆ†æŒ–æ˜ã€‚
2. æœ¬æ–‡æå‡ºMMAFFBenåŸºå‡†ï¼Œæ¶µç›–å¤šç§æ¨¡æ€å’Œè¯­è¨€ï¼Œæ—¨åœ¨ä¸ºæƒ…æ„Ÿåˆ†ææä¾›ç³»ç»Ÿçš„è¯„ä¼°å·¥å…·ã€‚
3. é€šè¿‡å¯¹å¤šç§LMsçš„è¯„ä¼°ï¼Œæœ¬æ–‡å±•ç¤ºäº†ä¸åŒæ¨¡å‹åœ¨æƒ…æ„Ÿç†è§£èƒ½åŠ›ä¸Šçš„å·®å¼‚ï¼Œä¸ºæœªæ¥ç ”ç©¶æä¾›äº†å‚è€ƒã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹å’Œè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆç»Ÿç§°ä¸ºLMsï¼‰åœ¨è‡ªç„¶è¯­è¨€å¤„ç†å’Œè®¡ç®—æœºè§†è§‰é¢†åŸŸå±•ç°å‡ºæ˜¾è‘—æ½œåŠ›ï¼Œä½†åœ¨æƒ…æ„Ÿåˆ†æï¼ˆå¦‚æƒ…æ„Ÿå€¾å‘å’Œæƒ…æ„Ÿæ£€æµ‹ï¼‰æ–¹é¢çš„èƒ½åŠ›ä»æœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚ä¸ºå¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæœ¬æ–‡æå‡ºäº†MMAFFBenï¼Œè¿™æ˜¯é¦–ä¸ªå…¨é¢çš„å¼€æºå¤šè¯­è¨€å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æåŸºå‡†ï¼Œæ¶µç›–35ç§è¯­è¨€çš„æ–‡æœ¬ã€å›¾åƒå’Œè§†é¢‘æ¨¡æ€ï¼Œæ¶‰åŠæƒ…æ„Ÿåˆ†æçš„å››ä¸ªå…³é”®ä»»åŠ¡ï¼šæƒ…æ„Ÿææ€§ã€æƒ…æ„Ÿå¼ºåº¦ã€æƒ…æ„Ÿåˆ†ç±»å’Œæƒ…æ„Ÿå¼ºåº¦ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡æ„å»ºäº†MMAFFInæ•°æ®é›†ä»¥ä¾¿äºå¯¹LMsè¿›è¡Œæƒ…æ„Ÿåˆ†æä»»åŠ¡çš„å¾®è°ƒï¼Œå¹¶åŸºäºæ­¤å¼€å‘äº†MMAFFLM-3bå’ŒMMAFFLM-7bã€‚æˆ‘ä»¬å¯¹å¤šç§ä»£è¡¨æ€§LMsï¼ˆåŒ…æ‹¬GPT-4o-miniï¼‰è¿›è¡Œäº†è¯„ä¼°ï¼Œç³»ç»Ÿæ¯”è¾ƒäº†å®ƒä»¬åœ¨æƒ…æ„Ÿç†è§£èƒ½åŠ›ä¸Šçš„è¡¨ç°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šè¯­è¨€å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æä¸­çš„è¯„ä¼°ä¸è¶³é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹å…¨é¢çš„åŸºå‡†ï¼Œå¯¼è‡´æƒ…æ„Ÿåˆ†æä»»åŠ¡çš„å¤æ‚æ€§æœªå¾—åˆ°æœ‰æ•ˆè§£å†³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºMMAFFBenåŸºå‡†ï¼Œæ•´åˆæ–‡æœ¬ã€å›¾åƒå’Œè§†é¢‘æ¨¡æ€ï¼Œè¦†ç›–å¤šç§è¯­è¨€ï¼Œæä¾›ç³»ç»Ÿçš„æƒ…æ„Ÿåˆ†æè¯„ä¼°æ¡†æ¶ã€‚é€šè¿‡æ„å»ºMMAFFInæ•°æ®é›†ï¼Œæ”¯æŒå¯¹LMsè¿›è¡Œå¾®è°ƒï¼Œæå‡å…¶åœ¨æƒ…æ„Ÿåˆ†æä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMMAFFBençš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€æ¨¡å‹å¾®è°ƒå’Œè¯„ä¼°ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚æ•°æ®é›†æ¶µç›–æƒ…æ„Ÿææ€§ã€æƒ…æ„Ÿå¼ºåº¦ã€æƒ…æ„Ÿåˆ†ç±»å’Œæƒ…æ„Ÿå¼ºåº¦å››ä¸ªä»»åŠ¡ï¼Œæ”¯æŒå¤šæ¨¡æ€è¾“å…¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šMMAFFBenæ˜¯é¦–ä¸ªå…¨é¢çš„å¤šè¯­è¨€å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æåŸºå‡†ï¼Œå¡«è¡¥äº†ç°æœ‰è¯„ä¼°å·¥å…·çš„ç©ºç™½ã€‚é€šè¿‡å¼•å…¥å¤šæ¨¡æ€æ•°æ®ï¼Œæå‡äº†æƒ…æ„Ÿåˆ†æçš„å‡†ç¡®æ€§å’Œé€‚ç”¨æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®é›†æ„å»ºä¸­ï¼Œé‡‡ç”¨äº†å¤šæ ·åŒ–çš„æƒ…æ„Ÿæ ‡æ³¨ç­–ç•¥ï¼Œç¡®ä¿æ•°æ®çš„ä¸°å¯Œæ€§å’Œä»£è¡¨æ€§ã€‚æ¨¡å‹å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œä¼˜åŒ–ç­–ç•¥ï¼Œä»¥æé«˜æ¨¡å‹åœ¨æƒ…æ„Ÿåˆ†æä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒMMAFFLM-3bå’ŒMMAFFLM-7båœ¨æƒ…æ„Ÿåˆ†æä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶åœ¨æƒ…æ„Ÿåˆ†ç±»å’Œæƒ…æ„Ÿå¼ºåº¦è¯„ä¼°ä¸Šï¼Œç›¸è¾ƒäºåŸºçº¿æ¨¡å‹æå‡äº†çº¦15%-20%çš„å‡†ç¡®ç‡ã€‚è¿™ä¸€æˆæœä¸ºæœªæ¥çš„æƒ…æ„Ÿåˆ†æç ”ç©¶æä¾›äº†é‡è¦çš„å‚è€ƒå’ŒåŸºç¡€ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MMAFFBenåŸºå‡†çš„æå‡ºä¸ºå¤šè¯­è¨€å’Œå¤šæ¨¡æ€æƒ…æ„Ÿåˆ†ææä¾›äº†æ ‡å‡†åŒ–çš„è¯„ä¼°å·¥å…·ï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚å®ƒå¯ä»¥è¢«ç”¨äºç¤¾äº¤åª’ä½“æƒ…æ„Ÿç›‘æµ‹ã€å¸‚åœºåˆ†æã€å¿ƒç†å¥åº·è¯„ä¼°ç­‰é¢†åŸŸï¼Œå¸®åŠ©ç ”ç©¶äººå‘˜å’Œå¼€å‘è€…æ›´å¥½åœ°ç†è§£å’Œåº”ç”¨æƒ…æ„Ÿåˆ†ææŠ€æœ¯ï¼Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models and vision-language models (which we jointly call LMs) have transformed NLP and CV, demonstrating remarkable potential across various fields. However, their capabilities in affective analysis (i.e. sentiment analysis and emotion detection) remain underexplored. This gap is largely due to the absence of comprehensive evaluation benchmarks, and the inherent complexity of affective analysis tasks. In this paper, we introduce MMAFFBen, the first extensive open-source benchmark for multilingual multimodal affective analysis. MMAFFBen encompasses text, image, and video modalities across 35 languages, covering four key affective analysis tasks: sentiment polarity, sentiment intensity, emotion classification, and emotion intensity. Moreover, we construct the MMAFFIn dataset for fine-tuning LMs on affective analysis tasks, and further develop MMAFFLM-3b and MMAFFLM-7b based on it. We evaluate various representative LMs, including GPT-4o-mini, providing a systematic comparison of their affective understanding capabilities. This project is available at https://github.com/lzw108/MMAFFBen.

