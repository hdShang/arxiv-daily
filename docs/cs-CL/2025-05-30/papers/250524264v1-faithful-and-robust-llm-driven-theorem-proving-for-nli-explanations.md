---
layout: default
title: Faithful and Robust LLM-Driven Theorem Proving for NLI Explanations
---

# Faithful and Robust LLM-Driven Theorem Proving for NLI Explanations

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.24264" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.24264v1</a>
  <a href="https://arxiv.org/pdf/2505.24264.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.24264v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.24264v1', 'Faithful and Robust LLM-Driven Theorem Proving for NLI Explanations')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Xin Quan, Marco Valentino, Louise A. Dennis, Andr√© Freitas

**ÂàÜÁ±ª**: cs.CL, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-30

**Â§áÊ≥®**: Camera-ready for ACL 2025

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫LLMÈ©±Âä®ÁöÑÂÆöÁêÜËØÅÊòéÊñπÊ≥ï‰ª•ÊèêÂçáNLIËß£ÈáäÁöÑÂèØÈù†ÊÄß‰∏éÁ®≥ÂÅ•ÊÄß**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Ëá™ÁÑ∂ËØ≠Ë®ÄÊé®ÁêÜ` `ÂÆöÁêÜËØÅÊòé` `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `Ëá™Âä®ÂΩ¢ÂºèÂåñ` `ÈÄªËæëË°®Ëææ` `ËØ≠‰πâÊçüÂ§±` `Ê®°Âûã‰ºòÂåñ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®Â∞ÜËá™ÁÑ∂ËØ≠Ë®ÄÁøªËØë‰∏∫Êú∫Âô®ÂèØÈ™åËØÅÂΩ¢ÂºèÊó∂ÔºåÈù¢‰∏¥ËØ≠‰πâ‰ø°ÊÅØ‰∏¢Â§±ÂíåÈÄªËæëÁªìÊûÑÊçïÊçâ‰∏çÁ≤æÁ°ÆÁöÑÈóÆÈ¢ò„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫ÈÄöËøáÂ§öÁßçÁ≠ñÁï•Êù•ÂáèËΩªËØ≠‰πâÊçüÂ§±„ÄÅÁ∫†Ê≠£ËØ≠Ê≥ïÈîôËØØÔºåÂπ∂Âà©Áî®ÈÄªËæëË°®ËææÊåáÂØºLLMsÁîüÊàêÁªìÊûÑÂåñËØÅÊòé„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåÊâÄÊèêÊñπÊ≥ïÂú®e-SNLI„ÄÅQASCÂíåWorldTreeÊï∞ÊçÆÈõÜ‰∏äÔºåËá™Âä®ÂΩ¢ÂºèÂåñÂíåËß£ÈáäÁ≤æÁÇºÁöÑÊèêÂçáÂπÖÂ∫¶ÂàÜÂà´ËææÂà∞18.46%„ÄÅ34.2%„ÄÅ39.77%Âíå29.5%„ÄÅ51.5%„ÄÅ41.25%„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Ëá™ÁÑ∂ËØ≠Ë®ÄËß£ÈáäÂú®Ëá™ÁÑ∂ËØ≠Ë®ÄÊé®ÁêÜÔºàNLIÔºâ‰∏≠Ëµ∑ÁùÄÈáçË¶Å‰ΩúÁî®ÔºåÊè≠Á§∫‰∫ÜÂâçÊèêÂ¶Ç‰ΩïÈÄªËæë‰∏äËï¥Âê´ÂÅáËÆæ„ÄÇËøëÊúüÁ†îÁ©∂Ë°®ÊòéÔºåÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâ‰∏éÂÆöÁêÜËØÅÊòéÂô®ÔºàTPsÔºâÁöÑÁªìÂêàÂèØ‰ª•Â∏ÆÂä©È™åËØÅÂíåÊîπÂñÑNLIËß£ÈáäÁöÑÊúâÊïàÊÄß„ÄÇÁÑ∂ËÄåÔºåTPsÈúÄË¶ÅÂ∞ÜËá™ÁÑ∂ËØ≠Ë®ÄÁøªËØë‰∏∫Êú∫Âô®ÂèØÈ™åËØÅÁöÑÂΩ¢ÂºèË°®Á§∫ÔºåËøô‰∏ÄËøáÁ®ãÂèØËÉΩÂØºËá¥ËØ≠‰πâ‰ø°ÊÅØÁöÑ‰∏¢Â§±Âíå‰∏çÂø†ÂÆûÁöÑËß£Èáä„ÄÇÊú¨ÊñáÊé¢ËÆ®‰∫ÜÂá†ÁßçÁ≠ñÁï•Ôºå‰ª•ÂáèËΩªËá™Âä®ÂΩ¢ÂºèÂåñËøáÁ®ã‰∏≠ÁöÑËØ≠‰πâÊçüÂ§±„ÄÅÊúâÊïàËØÜÂà´ÂíåÁ∫†Ê≠£ÈÄªËæëË°®Á§∫‰∏≠ÁöÑËØ≠Ê≥ïÈîôËØØ„ÄÅÂà©Áî®ÈÄªËæëË°®ËææÊåáÂØºLLMsÁîüÊàêÁªìÊûÑÂåñËØÅÊòéËçâÂõæÔºåÂπ∂ÊèêÈ´òLLMsÂØπTPÂèçÈ¶àÁöÑÁêÜËß£ËÉΩÂäõ„ÄÇÂÆûÈ™åËØÅÊòéÔºåÊâÄÊèêÂá∫ÁöÑÁ≠ñÁï•Âú®Ëá™Âä®ÂΩ¢ÂºèÂåñÂíåËß£ÈáäÁ≤æÁÇºÊñπÈù¢ÊòæËëóÊèêÂçá‰∫ÜÊÄßËÉΩ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÊé®ÁêÜ‰∏≠ÔºåÂ¶Ç‰ΩïÊúâÊïàÂú∞Â∞ÜËá™ÁÑ∂ËØ≠Ë®ÄËß£ÈáäËΩ¨Âåñ‰∏∫Êú∫Âô®ÂèØÈ™åËØÅÁöÑÂΩ¢ÂºèË°®Á§∫ÔºåÂêåÊó∂ÈÅøÂÖçËØ≠‰πâ‰ø°ÊÅØÁöÑ‰∏¢Â§±Âíå‰∏çÂáÜÁ°ÆÁöÑÈÄªËæëÁªìÊûÑÊçïÊçâ„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®ËøôÊñπÈù¢ÁöÑË°®Áé∞Â≠òÂú®‰∏çË∂≥ÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂÆöÁêÜËØÅÊòéÁöÑ‰∏•Ë∞®ÊÄßÂíåÁ®≥ÂÅ•ÊÄßÊñπÈù¢„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáËÆæËÆ°‰∏ÄÁ≥ªÂàóÁ≠ñÁï•Êù•ÂáèËΩªËá™Âä®ÂΩ¢ÂºèÂåñËøáÁ®ã‰∏≠ÁöÑËØ≠‰πâÊçüÂ§±ÔºåËØÜÂà´Âπ∂Á∫†Ê≠£ÈÄªËæëË°®Á§∫‰∏≠ÁöÑËØ≠Ê≥ïÈîôËØØÔºåÂπ∂Âà©Áî®ÈÄªËæëË°®ËææÊù•ÊåáÂØºLLMsÁîüÊàêÁªìÊûÑÂåñÁöÑËØÅÊòéËçâÂõæ„ÄÇËøôÁßçËÆæËÆ°Êó®Âú®ÊèêÈ´òLLMsÂú®ÂΩ¢ÂºèÈ™åËØÅÊ°ÜÊû∂‰∏≠ÁöÑË°®Áé∞„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨Âõõ‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) ËØ≠‰πâÊçüÂ§±ÂáèËΩªÊ®°ÂùóÔºõ2) ËØ≠Ê≥ïÈîôËØØËØÜÂà´‰∏éÁ∫†Ê≠£Ê®°ÂùóÔºõ3) ÈÄªËæëË°®ËææÊåáÂØºÁîüÊàêÊ®°ÂùóÔºõ4) LLM‰∏éTPÂèçÈ¶àËø≠‰ª£‰ºòÂåñÊ®°Âùó„ÄÇÂêÑÊ®°ÂùóÁõ∏‰∫íÂçè‰ΩúÔºå‰ª•ÊèêÂçáÊï¥‰ΩìÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫Ü‰∏ÄÁßçÊ∑∑ÂêàLLM-TPÊû∂ÊûÑÔºåÈÄöËøáÁâπÂÆöÂπ≤È¢ÑÊòæËëóÊèêÈ´ò‰∫ÜÈ™åËØÅÊïàÁéáÔºåÂáèÂ∞ë‰∫ÜÊàêÂäüÈ™åËØÅÊâÄÈúÄÁöÑËø≠‰ª£Ê¨°Êï∞„ÄÇËøô‰∏ÄÊñπÊ≥ï‰∏éÁé∞ÊúâÊäÄÊúØÁõ∏ÊØîÔºåËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞Â§ÑÁêÜÈÄªËæëÊé®ÁêÜ‰ªªÂä°„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°‰∏≠ÔºåÈááÁî®‰∫ÜÁâπÂÆöÁöÑÂèÇÊï∞ËÆæÁΩÆÂíåÊçüÂ§±ÂáΩÊï∞Ôºå‰ª•Á°Æ‰øùÊ®°ÂûãÂú®Ëá™Âä®ÂΩ¢ÂºèÂåñÂíåËß£ÈáäÁ≤æÁÇº‰∏≠ÁöÑË°®Áé∞„ÄÇÊ≠§Â§ñÔºåÁΩëÁªúÁªìÊûÑÁªèËøá‰ºòÂåñÔºå‰ª•ÊîØÊåÅÈÄªËæëË°®ËææÁöÑÁîüÊàêÂíåÂèçÈ¶àÁöÑÊúâÊïàÂà©Áî®„ÄÇÂÖ∑‰ΩìÁöÑÊäÄÊúØÁªÜËäÇÂåÖÊã¨ÂØπLLMsÁöÑËÆ≠ÁªÉÁ≠ñÁï•ÂíåTPÁöÑÂèçÈ¶àÊú∫Âà∂ÁöÑË∞ÉÊï¥„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äÂùáÊòæËëó‰ºò‰∫éÁé∞ÊúâÊúÄÂÖàËøõÊ®°ÂûãÔºåËá™Âä®ÂΩ¢ÂºèÂåñÁöÑÊèêÂçáÂπÖÂ∫¶ÂàÜÂà´‰∏∫18.46%„ÄÅ34.2%„ÄÅ39.77%ÔºåËÄåËß£ÈáäÁ≤æÁÇºÁöÑÊèêÂçáÂπÖÂ∫¶‰∏∫29.5%„ÄÅ51.5%„ÄÅ41.25%„ÄÇÊ≠§Â§ñÔºåÊ∑∑ÂêàLLM-TPÊû∂ÊûÑÁöÑÁâπÂÆöÂπ≤È¢ÑÊòæËëóÊèêÈ´ò‰∫ÜÈ™åËØÅÊïàÁéáÔºåÂáèÂ∞ë‰∫ÜËø≠‰ª£Ê¨°Êï∞„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Ëá™Âä®ÂåñÊé®ÁêÜÁ≥ªÁªü„ÄÅÊô∫ËÉΩÈóÆÁ≠îÁ≥ªÁªüÂíåÊïôËÇ≤ÊäÄÊúØÁ≠â„ÄÇÈÄöËøáÊèêÈ´òNLIËß£ÈáäÁöÑÂèØÈù†ÊÄß‰∏éÁ®≥ÂÅ•ÊÄßÔºåËÉΩÂ§ü‰∏∫Áî®Êà∑Êèê‰æõÊõ¥ÂáÜÁ°ÆÁöÑÊé®ÁêÜÊîØÊåÅÔºå‰øÉËøõ‰∫∫Êú∫‰∫§‰∫íÁöÑÊô∫ËÉΩÂåñÂèëÂ±ï„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïÂèØËÉΩÂú®Ê≥ïÂæã„ÄÅÂåªÁñóÁ≠âÈúÄË¶Å‰∏•Ë∞®Êé®ÁêÜÁöÑÈ¢ÜÂüüÂèëÊå•ÈáçË¶Å‰ΩúÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Natural language explanations play a fundamental role in Natural Language Inference (NLI) by revealing how premises logically entail hypotheses. Recent work has shown that the interaction of large language models (LLMs) with theorem provers (TPs) can help verify and improve the validity of NLI explanations. However, TPs require translating natural language into machine-verifiable formal representations, a process that introduces the risk of semantic information loss and unfaithful interpretation, an issue compounded by LLMs' challenges in capturing critical logical structures with sufficient precision. Moreover, LLMs are still limited in their capacity for rigorous and robust proof construction within formal verification frameworks. To mitigate issues related to faithfulness and robustness, this paper investigates strategies to (1) alleviate semantic loss during autoformalisation, (2) efficiently identify and correct syntactic errors in logical representations, (3) explicitly use logical expressions to guide LLMs in generating structured proof sketches, and (4) increase LLMs' capacity of interpreting TP's feedback for iterative refinement. Our empirical results on e-SNLI, QASC and WorldTree using different LLMs demonstrate that the proposed strategies yield significant improvements in autoformalisation (+18.46%, +34.2%, +39.77%) and explanation refinement (+29.5%, +51.5%, +41.25%) over the state-of-the-art model. Moreover, we show that specific interventions on the hybrid LLM-TP architecture can substantially improve efficiency, drastically reducing the number of iterations required for successful verification.

