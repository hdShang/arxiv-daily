---
layout: default
title: DeepDiver: Adaptive Search Intensity Scaling via Open-Web Reinforcement Learning
---

# DeepDiver: Adaptive Search Intensity Scaling via Open-Web Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.24332" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.24332v2</a>
  <a href="https://arxiv.org/pdf/2505.24332.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.24332v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.24332v2', 'DeepDiver: Adaptive Search Intensity Scaling via Open-Web Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wenxuan Shi, Haochen Tan, Chuqiao Kuang, Xiaoguang Li, Xiaozhe Ren, Chen Zhang, Hanting Chen, Yasheng Wang, Lu Hou, Lifeng Shang

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-30 (æ›´æ–°: 2025-11-10)

**å¤‡æ³¨**: Accepted as NeurIPS 2025 Spotlight

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDeepDiverä»¥è§£å†³å¼€æ”¾ç½‘ç»œé—®ç­”ä¸­çš„ä¿¡æ¯è·å–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¿¡æ¯è·å–` `å¼ºåŒ–å­¦ä¹ ` `å¤§å‹è¯­è¨€æ¨¡å‹` `å¼€æ”¾ç½‘ç»œé—®ç­”` `è‡ªé€‚åº”æœç´¢` `WebPuzzle` `æœç´¢å¼ºåº¦æ‰©å±•`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¼€æ”¾ç½‘ç»œé—®ç­”ä¸­é¢ä¸´ä¿¡æ¯è·å–çš„æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨è¯æ®æ”¶é›†å’Œæ¨ç†æ–¹é¢çš„ä¸è¶³ã€‚
2. æå‡ºDeepDiveræ¡†æ¶ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ åŸ¹å…»æœç´¢å¼ºåº¦æ‰©å±•èƒ½åŠ›ï¼Œæå‡ä¿¡æ¯è·å–çš„é¢‘ç‡å’Œæ·±åº¦ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDeepDiverä½¿å¾—Qwen2.5-7B-Instructå’ŒPangu-7B-Reasoneråœ¨çœŸå®ç½‘ç»œä»»åŠ¡ä¸­è¡¨ç°ä¼˜è¶Šï¼Œæ¥è¿‘æ›´å¤§æ¨¡å‹çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¿¡æ¯è·å–éœ€è¦è¿­ä»£çš„è¯æ®æ”¶é›†å’Œåæ€æ¨ç†ï¼Œä½†ç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¼€æ”¾ç½‘ç»œé—®ç­”ä¸­ä»é¢ä¸´æŒ‘æˆ˜ã€‚ç°æœ‰çš„æç¤ºå’Œç›‘ç£å¾®è°ƒæ–¹æ³•å—åˆ°æç¤ºè§„åˆ™æˆ–è®­ç»ƒè¯­æ–™çš„é™åˆ¶ï¼Œé€šå¸¸ä»…åœ¨ç»“æ„è‰¯å¥½çš„ç»´åŸºæ¥æºä¸Šè¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œé™åˆ¶äº†å…¶åœ¨ç°å®ä¸–ç•Œä¸­çš„é€‚åº”æ€§ã€‚æˆ‘ä»¬å¼•å…¥äº†WebPuzzleï¼Œä¸€ä¸ªåŒ…å«24,000ä¸ªæ ·æœ¬çš„è®­ç»ƒå’Œ275ä¸ªæ ·æœ¬çš„æµ‹è¯•åŸºå‡†ï¼Œè¯„ä¼°åœ¨å®æ—¶äº’è”ç½‘ç¯å¢ƒä¸‹çš„ä¿¡æ¯è·å–ã€‚åŸºäº7,000ä¸ªWebPuzzleå®ä¾‹ï¼Œæˆ‘ä»¬å¼€å‘äº†DeepDiverï¼Œä¸€ä¸ªå¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼ŒåŸ¹å…»æœç´¢å¼ºåº¦æ‰©å±•ï¼ˆSISï¼‰èƒ½åŠ›ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæé«˜æœç´¢é¢‘ç‡å’Œæ·±åº¦ï¼Œè€Œä¸æ˜¯åœç•™åœ¨è¿‡äºè‡ªä¿¡ä¸”è¯æ®ä¸è¶³çš„ç­”æ¡ˆä¸Šã€‚é€šè¿‡SISï¼ŒQwen2.5-7B-Instructå’ŒPangu-7B-Reasoneråœ¨çœŸå®ç½‘ç»œä»»åŠ¡ä¸­çš„è¡¨ç°å¯ä¸671Bå‚æ•°çš„DeepSeek-R1ç›¸åª²ç¾ã€‚æˆ‘ä»¬çš„ç»“æœæ¨åŠ¨äº†LLMsä¸­è‡ªé€‚åº”ä¿¡æ¯è·å–çš„å‘å±•ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†ä¸¥æ ¼çš„åŸºå‡†ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¼€æ”¾ç½‘ç»œé—®ç­”ä¸­ä¿¡æ¯è·å–çš„ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–å›ºå®šçš„æç¤ºè§„åˆ™æˆ–è®­ç»ƒè¯­æ–™ï¼Œå¯¼è‡´é€‚åº”æ€§å·®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºDeepDiveræ¡†æ¶ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ åŸ¹å…»æœç´¢å¼ºåº¦æ‰©å±•ï¼ˆSISï¼‰èƒ½åŠ›ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨ä¿¡æ¯è·å–è¿‡ç¨‹ä¸­åŠ¨æ€è°ƒæ•´æœç´¢é¢‘ç‡å’Œæ·±åº¦ï¼Œä»è€Œæé«˜ç­”æ¡ˆçš„å¯é æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDeepDiverçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä»å†·å¯åŠ¨çš„ç›‘ç£å¾®è°ƒåˆ°ç²¾å¿ƒè®¾è®¡çš„å¼ºåŒ–å­¦ä¹ è¿‡ç¨‹ï¼Œæ¶µç›–äº†ä¿¡æ¯è·å–ç­–ç•¥çš„è®­ç»ƒä¸ä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šDeepDiverçš„ä¸»è¦åˆ›æ–°åœ¨äºå¼•å…¥äº†æœç´¢å¼ºåº¦æ‰©å±•ï¼ˆSISï¼‰èƒ½åŠ›ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨é¢å¯¹å¼€æ”¾æ€§é—®é¢˜æ—¶ï¼Œçµæ´»è°ƒæ•´å…¶æœç´¢ç­–ç•¥ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—æå‡äº†ä¿¡æ¯è·å–çš„è´¨é‡å’Œæ·±åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œå‚æ•°è®¾ç½®ï¼Œä»¥ä¼˜åŒ–æœç´¢ç­–ç•¥çš„è¡¨ç°ï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåœ°ä»å¼€æ”¾ç½‘ç»œä¸­æå–ä¿¡æ¯ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’Œå‚æ•°ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒDeepDiverä½¿å¾—Qwen2.5-7B-Instructå’ŒPangu-7B-Reasoneråœ¨çœŸå®ç½‘ç»œä»»åŠ¡ä¸­çš„è¡¨ç°æ¥è¿‘671Bå‚æ•°çš„DeepSeek-R1ï¼Œå±•ç¤ºäº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼ŒéªŒè¯äº†SISèƒ½åŠ›çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€ä¿¡æ¯æ£€ç´¢å’ŒçŸ¥è¯†ç®¡ç†ç­‰ã€‚é€šè¿‡æå‡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¼€æ”¾ç½‘ç»œç¯å¢ƒä¸­çš„ä¿¡æ¯è·å–èƒ½åŠ›ï¼ŒDeepDiverèƒ½å¤Ÿä¸ºç”¨æˆ·æä¾›æ›´ä¸ºå‡†ç¡®å’Œå¯é çš„ç­”æ¡ˆï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Information seeking demands iterative evidence gathering and reflective reasoning, yet large language models (LLMs) still struggle with it in open-web question answering. Existing prompting and supervised fine-tuning (SFT) methods remain fixed by prompt rules or training corpora, and are usually benchmarked only on well-structured wiki sources, limiting real-world adaptability. We introduce WebPuzzle, a 24k-sample training and 275-sample test benchmark that evaluates information seeking on the live internet, across both wiki and open-domain queries. Leveraging 7k WebPuzzle instances, we develop DeepDiver, a reinforcement-learning (RL) framework that cultivates Search Intensity Scaling (SIS)-an emergent ability to escalate search frequency and depth instead of settling on overconfident, under-evidenced answers. With SIS, Qwen2.5-7B-Instruct and Pangu-7B-Reasoner attain performance on real-web tasks comparable to the 671B-parameter DeepSeek-R1. We detail DeepDiver's curriculum from cold-start SFT to a well designed RL procedure, and show that its seeking policy generalized from closed-ended queries to open-ended generation such as long-form writing. Our results advance adaptive information seeking in LLMs and provide a rigorous benchmark for future work.

