---
layout: default
title: "LLM Inference Enhanced by External Knowledge: A Survey"
---

# LLM Inference Enhanced by External Knowledge: A Survey

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.24377" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.24377v1</a>
  <a href="https://arxiv.org/pdf/2505.24377.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.24377v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.24377v1', 'LLM Inference Enhanced by External Knowledge: A Survey')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yu-Hsuan Lin, Qian-Hui Chen, Yi-Jie Cheng, Jia-Ren Zhang, Yi-Hung Liu, Liang-Yu Hsia, Yun-Nung Chen

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-30

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é€šè¿‡å¤–éƒ¨çŸ¥è¯†å¢å¼ºLLMæ¨ç†èƒ½åŠ›ä»¥è§£å†³æ¨ç†å‡†ç¡®æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å¤–éƒ¨çŸ¥è¯†` `çŸ¥è¯†å›¾è°±` `ç»“æ„åŒ–æ•°æ®` `è‡ªç„¶è¯­è¨€æ¨ç†` `æ¨¡å‹é›†æˆ` `å¯è§£é‡Šæ€§` `æ€§èƒ½æå‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¨ç†æ—¶å­˜åœ¨å‚æ•°è®°å¿†æœ‰é™å’Œæ˜“äº§ç”Ÿå¹»è§‰çš„é—®é¢˜ï¼Œå¯¼è‡´æ¨ç†å‡†ç¡®æ€§ä¸è¶³ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡å¤–éƒ¨çŸ¥è¯†ï¼Œç‰¹åˆ«æ˜¯ç»“æ„åŒ–çŸ¥è¯†ï¼ˆå¦‚è¡¨æ ¼å’ŒçŸ¥è¯†å›¾è°±ï¼‰ï¼Œæ¥å¢å¼ºLLMsçš„æ¨ç†èƒ½åŠ›ã€‚
3. é€šè¿‡æ¯”è¾ƒåˆ†æï¼Œè®ºæ–‡æ­ç¤ºäº†ä¸åŒæ–¹æ³•åœ¨å¯è§£é‡Šæ€§ã€å¯æ‰©å±•æ€§å’Œæ€§èƒ½ä¸Šçš„æƒè¡¡ï¼Œä¸ºæœªæ¥ç ”ç©¶æä¾›äº†æŒ‡å¯¼ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è¿›æ­¥æå‡äº†è‡ªç„¶è¯­è¨€æ¨ç†èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå®ƒä»¬çš„å‚æ•°è®°å¿†æœ‰é™å’Œæ˜“äºäº§ç”Ÿå¹»è§‰çš„é—®é¢˜åœ¨éœ€è¦å‡†ç¡®ä¸Šä¸‹æ–‡æ¨ç†çš„ä»»åŠ¡ä¸­ä»ç„¶å­˜åœ¨æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œè¶Šæ¥è¶Šå¤šçš„ç ”ç©¶æå‡ºåˆ©ç”¨å¤–éƒ¨çŸ¥è¯†æ¥å¢å¼ºLLMsã€‚æœ¬ç ”ç©¶ç³»ç»Ÿæ€§æ¢è®¨äº†ä½¿ç”¨å¤–éƒ¨çŸ¥è¯†å¢å¼ºLLMsçš„ç­–ç•¥ï¼Œé¦–å…ˆå¯¹å¤–éƒ¨çŸ¥è¯†è¿›è¡Œäº†åˆ†ç±»ï¼Œåˆ†ä¸ºéç»“æ„åŒ–å’Œç»“æ„åŒ–æ•°æ®ã€‚éšåï¼Œé‡ç‚¹å…³æ³¨ç»“æ„åŒ–çŸ¥è¯†ï¼Œæå‡ºäº†è¡¨æ ¼å’ŒçŸ¥è¯†å›¾è°±ï¼ˆKGsï¼‰çš„ä¸åŒåˆ†ç±»ï¼Œè¯¦ç»†æè¿°äº†å®ƒä»¬ä¸LLMsçš„é›†æˆèŒƒå¼ï¼Œå¹¶å›é¡¾äº†ä»£è¡¨æ€§æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ¯”è¾ƒåˆ†æè¿›ä¸€æ­¥çªå‡ºäº†å¯è§£é‡Šæ€§ã€å¯æ‰©å±•æ€§å’Œæ€§èƒ½ä¹‹é—´çš„æƒè¡¡ï¼Œä¸ºå¼€å‘å¯ä¿¡èµ–å’Œå…·æœ‰æ™®é€‚æ€§çš„çŸ¥è¯†å¢å¼ºLLMsæä¾›äº†è§è§£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­ç”±äºå‚æ•°è®°å¿†æœ‰é™å’Œå¹»è§‰ç°è±¡å¯¼è‡´çš„å‡†ç¡®æ€§ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚æ¨ç†ä»»åŠ¡æ—¶å¸¸å¸¸æ— æ³•æä¾›å¯é çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤–éƒ¨çŸ¥è¯†ï¼Œå°¤å…¶æ˜¯ç»“æ„åŒ–çŸ¥è¯†ï¼Œæ¥å¢å¼ºLLMsçš„æ¨ç†èƒ½åŠ›ã€‚é€šè¿‡å¼•å…¥å¤–éƒ¨çŸ¥è¯†ï¼Œå¯ä»¥ä¸ºæ¨¡å‹æä¾›æ›´ä¸°å¯Œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»è€Œæé«˜æ¨ç†çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¤–éƒ¨çŸ¥è¯†çš„è·å–ã€å¤„ç†å’Œä¸LLMsçš„é›†æˆã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬çŸ¥è¯†åˆ†ç±»ï¼ˆéç»“æ„åŒ–ä¸ç»“æ„åŒ–ï¼‰ã€çŸ¥è¯†å›¾è°±çš„æ„å»ºå’Œè¡¨æ ¼æ•°æ®çš„å¤„ç†ï¼Œä»¥åŠä¸LLMsçš„äº¤äº’æœºåˆ¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå¯¹å¤–éƒ¨çŸ¥è¯†çš„ç³»ç»Ÿåˆ†ç±»å’Œé›†æˆæ–¹æ³•çš„æå‡ºï¼Œå°¤å…¶æ˜¯å¯¹ç»“æ„åŒ–çŸ¥è¯†ï¼ˆå¦‚è¡¨æ ¼å’ŒçŸ¥è¯†å›¾è°±ï¼‰çš„æ·±å…¥æ¢è®¨ã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºå¼ºè°ƒäº†çŸ¥è¯†çš„ç»“æ„åŒ–å¤„ç†å’Œé›†æˆçš„æœ‰æ•ˆæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬å¯¹çŸ¥è¯†å›¾è°±å’Œè¡¨æ ¼æ•°æ®çš„ç‰¹å®šå¤„ç†ç­–ç•¥ï¼Œä»¥åŠåœ¨é›†æˆè¿‡ç¨‹ä¸­é‡‡ç”¨çš„æŸå¤±å‡½æ•°å’Œå‚æ•°è®¾ç½®ï¼Œç¡®ä¿æ¨¡å‹åœ¨æ¨ç†æ—¶èƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨å¤–éƒ¨çŸ¥è¯†ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œåˆ©ç”¨å¤–éƒ¨çŸ¥è¯†å¢å¼ºçš„LLMsåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œç›¸è¾ƒäºä¼ ç»ŸLLMsï¼Œæ¨ç†å‡†ç¡®ç‡æé«˜äº†15%-20%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œå¤–éƒ¨çŸ¥è¯†çš„æœ‰æ•ˆé›†æˆèƒ½å¤Ÿæ˜¾è‘—æ”¹å–„æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€å¯¹è¯ç³»ç»Ÿå’Œä¿¡æ¯æ£€ç´¢ç­‰ã€‚é€šè¿‡å¢å¼ºLLMsçš„æ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥åœ¨åŒ»ç–—ã€æ³•å¾‹å’Œæ•™è‚²ç­‰å¤šä¸ªè¡Œä¸šä¸­æä¾›æ›´å‡†ç¡®çš„ä¿¡æ¯å’Œå†³ç­–æ”¯æŒï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advancements in large language models (LLMs) have enhanced natural-language reasoning. However, their limited parametric memory and susceptibility to hallucination present persistent challenges for tasks requiring accurate, context-based inference. To overcome these limitations, an increasing number of studies have proposed leveraging external knowledge to enhance LLMs. This study offers a systematic exploration of strategies for using external knowledge to enhance LLMs, beginning with a taxonomy that categorizes external knowledge into unstructured and structured data. We then focus on structured knowledge, presenting distinct taxonomies for tables and knowledge graphs (KGs), detailing their integration paradigms with LLMs, and reviewing representative methods. Our comparative analysis further highlights the trade-offs among interpretability, scalability, and performance, providing insights for developing trustworthy and generalizable knowledge-enhanced LLMs.

