---
layout: default
title: "Revisiting Epistemic Markers in Confidence Estimation: Can Markers Accurately Reflect Large Language Models' Uncertainty?"
---

# Revisiting Epistemic Markers in Confidence Estimation: Can Markers Accurately Reflect Large Language Models' Uncertainty?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.24778" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.24778v2</a>
  <a href="https://arxiv.org/pdf/2505.24778.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.24778v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.24778v2', 'Revisiting Epistemic Markers in Confidence Estimation: Can Markers Accurately Reflect Large Language Models\' Uncertainty?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiayu Liu, Qing Zong, Weiqi Wang, Yangqiu Song

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-30 (æ›´æ–°: 2025-07-01)

**å¤‡æ³¨**: ACL2025 Main

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/HKUST-KnowComp/MarCon)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ ‡è®°ä¿¡å¿ƒè¯„ä¼°æ–¹æ³•ä»¥è§£å†³LLMä¸ç¡®å®šæ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ä¿¡å¿ƒè¯„ä¼°` `è¡¨è¿°æ€§æ ‡è®°` `ä¸ç¡®å®šæ€§é‡åŒ–` `é—®ç­”ç³»ç»Ÿ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹çš„ä¿¡å¿ƒæ—¶ï¼Œç¼ºä¹å¯¹è¡¨è¿°æ€§æ ‡è®°ä¸æ¨¡å‹ä¸ç¡®å®šæ€§ä¹‹é—´å…³ç³»çš„æ·±å…¥ç†è§£ã€‚
2. æœ¬æ–‡æå‡ºé€šè¿‡å®šä¹‰æ ‡è®°ä¿¡å¿ƒæ¥é‡åŒ–æ¨¡å‹ä½¿ç”¨è¡¨è¿°æ€§æ ‡è®°æ—¶çš„å‡†ç¡®æ€§ï¼Œä»¥æ­¤è¯„ä¼°å…¶ä¿¡å¿ƒçš„ç¨³å®šæ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ ‡è®°åœ¨åŒåˆ†å¸ƒä¸‹è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨å¼‚åˆ†å¸ƒåœºæ™¯ä¸­ä¿¡å¿ƒä¸ä¸€è‡´ï¼Œæç¤ºéœ€è¦æ”¹è¿›è¯„ä¼°æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é«˜é£é™©é¢†åŸŸçš„å¹¿æ³›åº”ç”¨ï¼Œå‡†ç¡®è¯„ä¼°å…¶ä¿¡å¿ƒå˜å¾—è‡³å…³é‡è¦ã€‚äººç±»é€šå¸¸é€šè¿‡è¡¨è¿°æ€§æ ‡è®°ï¼ˆå¦‚â€œç›¸å½“è‡ªä¿¡â€ï¼‰è€Œéæ•°å€¼æ¥è¡¨è¾¾ä¿¡å¿ƒã€‚ç„¶è€Œï¼Œç›®å‰å°šä¸æ¸…æ¥šLLMsæ˜¯å¦ä¸€è‡´åœ°ä½¿ç”¨è¿™äº›æ ‡è®°æ¥åæ˜ å…¶å†…åœ¨ä¿¡å¿ƒã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡é¦–å…ˆå®šä¹‰äº†æ ‡è®°ä¿¡å¿ƒï¼Œå³æ¨¡å‹ä½¿ç”¨è¡¨è¿°æ€§æ ‡è®°æ—¶çš„è§‚å¯Ÿå‡†ç¡®æ€§ã€‚æˆ‘ä»¬åœ¨å¤šä¸ªé—®ç­”æ•°æ®é›†ä¸Šè¯„ä¼°å…¶åœ¨åŒåˆ†å¸ƒå’Œå¼‚åˆ†å¸ƒè®¾ç½®ä¸‹çš„ç¨³å®šæ€§ã€‚ç»“æœè¡¨æ˜ï¼Œè™½ç„¶æ ‡è®°åœ¨åŒä¸€åˆ†å¸ƒå†…å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œä½†åœ¨å¼‚åˆ†å¸ƒåœºæ™¯ä¸­å…¶ä¿¡å¿ƒè¡¨ç°ä¸ä¸€è‡´ã€‚è¿™äº›å‘ç°å¼•å‘äº†å¯¹è¡¨è¿°æ€§æ ‡è®°åœ¨ä¿¡å¿ƒè¯„ä¼°ä¸­å¯é æ€§çš„é‡å¤§æ‹…å¿§ï¼Œå¼ºè°ƒäº†æ ‡è®°ä¿¡å¿ƒä¸æ¨¡å‹å®é™…ä¸ç¡®å®šæ€§ä¹‹é—´éœ€è¦æ›´å¥½å¯¹é½çš„å¿…è¦æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä½¿ç”¨è¡¨è¿°æ€§æ ‡è®°æ—¶ï¼Œå¦‚ä½•å‡†ç¡®åæ˜ å…¶ä¿¡å¿ƒçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆé‡åŒ–ä¸åŒæ ‡è®°æ‰€å¯¹åº”çš„ä¸ç¡®å®šæ€§ï¼Œå¯¼è‡´ä¿¡å¿ƒè¯„ä¼°ä¸å¯é ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡é€šè¿‡å®šä¹‰â€œæ ‡è®°ä¿¡å¿ƒâ€æ¥é‡åŒ–æ¨¡å‹åœ¨ä½¿ç”¨è¡¨è¿°æ€§æ ‡è®°æ—¶çš„å‡†ç¡®æ€§ï¼Œè¯„ä¼°å…¶åœ¨ä¸åŒæ•°æ®é›†å’Œåˆ†å¸ƒä¸‹çš„ç¨³å®šæ€§ï¼Œä»è€Œæ­ç¤ºæ ‡è®°ä¸æ¨¡å‹ä¸ç¡®å®šæ€§ä¹‹é—´çš„å…³ç³»ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨å¤šç§é—®ç­”æ•°æ®é›†è¿›è¡Œå®éªŒï¼Œåˆ†ä¸ºåŒåˆ†å¸ƒå’Œå¼‚åˆ†å¸ƒä¸¤ç§è®¾ç½®ï¼Œæ¯”è¾ƒå¼€æºå’Œä¸“æœ‰LLMsçš„è¡¨ç°ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ•°æ®é›†å‡†å¤‡ã€æ¨¡å‹è¯„ä¼°å’Œç»“æœåˆ†æã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºé¦–æ¬¡ç³»ç»Ÿæ€§åœ°å®šä¹‰å’Œè¯„ä¼°æ ‡è®°ä¿¡å¿ƒï¼Œæ­ç¤ºäº†è¡¨è¿°æ€§æ ‡è®°åœ¨ä¸åŒåˆ†å¸ƒä¸‹çš„ä¿¡å¿ƒè¡¨ç°ä¸ä¸€è‡´æ€§ï¼Œè¿™ä¸ºåç»­ç ”ç©¶æä¾›äº†æ–°çš„è§†è§’ã€‚

**å…³é”®è®¾è®¡**ï¼šå®éªŒä¸­é‡‡ç”¨äº†å¤šç§æ•°æ®é›†ï¼Œè®¾ç½®äº†ä¸åŒçš„è¯„ä¼°æŒ‡æ ‡ï¼Œå…³æ³¨æ¨¡å‹åœ¨ä½¿ç”¨è¡¨è¿°æ€§æ ‡è®°æ—¶çš„å‡†ç¡®æ€§å’Œç¨³å®šæ€§ï¼Œç¡®ä¿ç»“æœçš„å¯é æ€§å’Œå¯é‡å¤æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¡¨è¿°æ€§æ ‡è®°åœ¨åŒåˆ†å¸ƒä¸‹çš„å‡†ç¡®æ€§é«˜è¾¾85%ï¼Œä½†åœ¨å¼‚åˆ†å¸ƒåœºæ™¯ä¸­å‡†ç¡®æ€§ä¸‹é™è‡³60%ï¼Œè¡¨æ˜ä¿¡å¿ƒè¯„ä¼°å­˜åœ¨æ˜¾è‘—ä¸ä¸€è‡´æ€§ã€‚è¿™ä¸€å‘ç°å¼ºè°ƒäº†æ”¹è¿›ä¿¡å¿ƒè¯„ä¼°æ–¹æ³•çš„å¿…è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŒ»ç–—ã€é‡‘èå’Œæ³•å¾‹ç­‰é«˜é£é™©å†³ç­–åœºæ™¯ï¼Œèƒ½å¤Ÿå¸®åŠ©ç”¨æˆ·æ›´å¥½åœ°ç†è§£å¤§å‹è¯­è¨€æ¨¡å‹çš„ä¿¡å¿ƒæ°´å¹³ï¼Œä»è€Œåšå‡ºæ›´ä¸ºæ˜æ™ºçš„å†³ç­–ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½æ¨åŠ¨ä¿¡å¿ƒè¯„ä¼°æŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ï¼Œæå‡æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„å¯é æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> As large language models (LLMs) are increasingly used in high-stakes domains, accurately assessing their confidence is crucial. Humans typically express confidence through epistemic markers (e.g., "fairly confident") instead of numerical values. However, it remains unclear whether LLMs consistently use these markers to reflect their intrinsic confidence due to the difficulty of quantifying uncertainty associated with various markers. To address this gap, we first define marker confidence as the observed accuracy when a model employs an epistemic marker. We evaluate its stability across multiple question-answering datasets in both in-distribution and out-of-distribution settings for open-source and proprietary LLMs. Our results show that while markers generalize well within the same distribution, their confidence is inconsistent in out-of-distribution scenarios. These findings raise significant concerns about the reliability of epistemic markers for confidence estimation, underscoring the need for improved alignment between marker based confidence and actual model uncertainty. Our code is available at https://github.com/HKUST-KnowComp/MarCon.

