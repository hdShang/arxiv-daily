---
layout: default
title: Simulating Training Data Leakage in Multiple-Choice Benchmarks for LLM Evaluation
---

# Simulating Training Data Leakage in Multiple-Choice Benchmarks for LLM Evaluation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.24263" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.24263v1</a>
  <a href="https://arxiv.org/pdf/2505.24263.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.24263v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.24263v1', 'Simulating Training Data Leakage in Multiple-Choice Benchmarks for LLM Evaluation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Naila Shafirni Hidayat, Muhammad Dehan Al Kautsar, Alfan Farizki Wicaksono, Fajri Koto

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-30

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ•°æ®æ³„æ¼æ¨¡æ‹Ÿæ–¹æ³•ä»¥æå‡LLMè¯„ä¼°çš„é€æ˜æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ•°æ®æ³„æ¼æ£€æµ‹` `å¤§å‹è¯­è¨€æ¨¡å‹` `è¯„ä¼°é€æ˜æ€§` `n-gramæ–¹æ³•` `åŠåŠé—®é¢˜` `å®ä¾‹çº§æ£€æµ‹` `åŸºå‡†æµ‹è¯•`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ•°æ®æ³„æ¼æ£€æµ‹æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨è¯†åˆ«å¼‚å¸¸å€¼ï¼Œç¼ºä¹åœ¨æ¨¡æ‹Ÿæ³„æ¼æ¡ä»¶ä¸‹çš„æœ‰æ•ˆè¯„ä¼°ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„åŠåŠé—®é¢˜æ–¹æ³•ï¼Œå¹¶æ¯”è¾ƒäº†ç½®æ¢æ³•å’Œn-gramæ–¹æ³•åœ¨æ¨¡æ‹Ÿæ³„æ¼åœºæ™¯ä¸‹çš„è¡¨ç°ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œn-gramæ–¹æ³•åœ¨F1-scoreä¸Šè¡¨ç°æœ€ä½³ï¼Œå¹¶ä¸”é€šè¿‡æ”¹è¿›æŠ€æœ¯æ”¯æŒå®ä¾‹çº§æ£€æµ‹ï¼Œé™ä½äº†è®¡ç®—å¼€é”€ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ€§èƒ½ä¸æ–­æå‡ï¼Œç„¶è€Œè®­ç»ƒæ•°æ®çš„é€æ˜åº¦ä¸è¶³å¼•å‘äº†å¯¹è¯„ä¼°é›†ä¸è®­ç»ƒé›†é‡å çš„æ‹…å¿§ã€‚å°½ç®¡å·²æœ‰ç ”ç©¶æå‡ºäº†æ•°æ®æ³„æ¼æ£€æµ‹æ–¹æ³•ï¼Œä½†è¿™äº›æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨è¯†åˆ«å¼‚å¸¸å€¼ï¼Œå¹¶æœªåœ¨å—æ§çš„æ¨¡æ‹Ÿæ³„æ¼æ¡ä»¶ä¸‹è¿›è¡Œè¯„ä¼°ã€‚æœ¬æ–‡æ¯”è¾ƒäº†ç°æœ‰çš„æ³„æ¼æ£€æµ‹æŠ€æœ¯ï¼ŒåŒ…æ‹¬ç½®æ¢æ³•å’Œn-gramæ–¹æ³•ï¼Œå¹¶æ¢ç´¢äº†ä¸€ç§è½»é‡çº§çš„æ–¹æ³•â€”â€”åŠåŠé—®é¢˜ã€‚å°½ç®¡åŠåŠé—®é¢˜æä¾›äº†ä½æˆæœ¬çš„æ›¿ä»£æ–¹æ¡ˆï¼Œä½†åˆ†æè¡¨æ˜n-gramæ–¹æ³•åœ¨F1-scoreä¸Šè¡¨ç°æœ€ä½³ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜å¯¹è¿™äº›æŠ€æœ¯è¿›è¡Œäº†æ”¹è¿›ï¼Œä»¥æ”¯æŒå®ä¾‹çº§æ£€æµ‹å¹¶å‡å°‘è®¡ç®—å¼€é”€ã€‚åŸºäºæœ€ä½³æ–¹æ³•ï¼Œæˆ‘ä»¬åˆ›å»ºäº†MMLUå’ŒHellaSwagçš„æ¸…ç†ç‰ˆæœ¬ï¼Œå¹¶é‡æ–°è¯„ä¼°äº†å¤šç§LLMã€‚ç ”ç©¶ç»“æœä¸ºæ›´å¯é å’Œé€æ˜çš„è¯„ä¼°æä¾›äº†å®é™…è·¯å¾„ï¼Œå¹¶å»ºè®®åœ¨å‘å¸ƒåŸºå‡†ç»“æœå‰è¿›è¡Œæ±¡æŸ“æ£€æŸ¥ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹è¯„ä¼°ä¸­è®­ç»ƒæ•°æ®ä¸è¯„ä¼°é›†é‡å çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨æ¨¡æ‹Ÿæ³„æ¼æ¡ä»¶ä¸‹çš„æœ‰æ•ˆæ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ¯”è¾ƒå¤šç§æ•°æ®æ³„æ¼æ£€æµ‹æŠ€æœ¯ï¼Œæå‡ºäº†ä¸€ç§è½»é‡çº§çš„åŠåŠé—®é¢˜æ–¹æ³•ï¼Œå¹¶åœ¨å—æ§ç¯å¢ƒä¸­æ¨¡æ‹ŸçœŸå®æ³„æ¼åœºæ™¯ï¼Œä»¥è¯„ä¼°å…¶æœ‰æ•ˆæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é¦–å…ˆåœ¨æŒç»­é¢„è®­ç»ƒè®¾ç½®ä¸‹æ¨¡æ‹Ÿæ•°æ®æ³„æ¼åœºæ™¯ï¼Œç„¶ååº”ç”¨ä¸åŒçš„æ³„æ¼æ£€æµ‹æ–¹æ³•ï¼ŒåŒ…æ‹¬ç½®æ¢æ³•ã€n-gramæ–¹æ³•å’ŒåŠåŠé—®é¢˜ï¼Œæœ€åè¿›è¡Œå®ä¾‹çº§æ£€æµ‹å’Œç»“æœæ¸…ç†ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæå‡ºäº†åŠåŠé—®é¢˜æ–¹æ³•ï¼Œå¹¶åœ¨æ¨¡æ‹Ÿæ³„æ¼æ¡ä»¶ä¸‹ç³»ç»Ÿæ¯”è¾ƒäº†å¤šç§æ£€æµ‹æŠ€æœ¯ï¼Œå‘ç°n-gramæ–¹æ³•åœ¨æ€§èƒ½ä¸Šä¼˜äºå…¶ä»–æ–¹æ³•ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œç ”ç©¶å¯¹n-gramæ–¹æ³•è¿›è¡Œäº†ä¼˜åŒ–ï¼Œä»¥æé«˜F1-scoreï¼Œå¹¶åœ¨å®ä¾‹çº§æ£€æµ‹ä¸­å‡å°‘è®¡ç®—å¼€é”€ï¼Œç¡®ä¿æ–¹æ³•çš„å®ç”¨æ€§å’Œæ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œn-gramæ–¹æ³•åœ¨F1-scoreä¸Š consistently outperform å…¶ä»–æ£€æµ‹æ–¹æ³•ï¼Œæä¾›äº†æ›´é«˜çš„å‡†ç¡®æ€§ã€‚é€šè¿‡æ”¹è¿›æŠ€æœ¯ï¼Œå®ä¾‹çº§æ£€æµ‹çš„è®¡ç®—å¼€é”€æ˜¾è‘—é™ä½ï¼Œä¸ºå®é™…åº”ç”¨æä¾›äº†æ›´é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤§å‹è¯­è¨€æ¨¡å‹çš„è¯„ä¼°å’ŒåŸºå‡†æµ‹è¯•ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦ç¡®ä¿è¯„ä¼°ç»“æœé€æ˜æ€§å’Œå…¬æ­£æ€§çš„åœºæ™¯ã€‚é€šè¿‡æä¾›æ¸…ç†åçš„æ•°æ®é›†å’Œæ”¹è¿›çš„æ£€æµ‹æ–¹æ³•ï¼Œç ”ç©¶ä¸ºæœªæ¥çš„æ¨¡å‹è¯„ä¼°æä¾›äº†å¯é çš„å·¥å…·ï¼Œå¯èƒ½ä¼šå½±å“æ¨¡å‹å¼€å‘å’Œè¯„ä¼°çš„æ ‡å‡†æµç¨‹ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The performance of large language models (LLMs) continues to improve, as reflected in rising scores on standard benchmarks. However, the lack of transparency around training data raises concerns about potential overlap with evaluation sets and the fairness of reported results. Although prior work has proposed methods for detecting data leakage, these approaches primarily focus on identifying outliers and have not been evaluated under controlled simulated leakage conditions. In this work, we compare existing leakage detection techniques, namely permutation and n-gram-based methods, under a continual pretraining setup that simulates real-world leakage scenarios, and additionally explore a lightweight method we call semi-half question. Although semi-half offers a low-cost alternative, our analysis shows that the n-gram method consistently achieves the highest F1-score. We also refine these techniques to support instance-level detection and reduce computational overhead. Leveraging the best-performing method, we create cleaned versions of MMLU and HellaSwag, and re-evaluate several LLMs. Our findings present a practical path toward more reliable and transparent evaluations, and we recommend contamination checks as a standard step before releasing benchmark results.

