---
layout: default
title: Hierarchical Level-Wise News Article Clustering via Multilingual Matryoshka Embeddings
---

# Hierarchical Level-Wise News Article Clustering via Multilingual Matryoshka Embeddings

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.00277" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.00277v1</a>
  <a href="https://arxiv.org/pdf/2506.00277.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.00277v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.00277v1', 'Hierarchical Level-Wise News Article Clustering via Multilingual Matryoshka Embeddings')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hans W. A. Hanley, Zakir Durumeric

**åˆ†ç±»**: cs.CL, cs.AI, cs.SI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-30

**å¤‡æ³¨**: Accepted to The 63rd Annual Meeting of the Association for Computational Linguistics (ACL 2025)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šè¯­è¨€MatryoshkaåµŒå…¥ä»¥è§£å†³æ–°é—»æ–‡ç« èšç±»é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šè¯­è¨€å¤„ç†` `æ–°é—»èšç±»` `MatryoshkaåµŒå…¥` `å±‚æ¬¡èšç±»` `ä¸»é¢˜å»ºæ¨¡` `ç¤¾äº¤åª’ä½“åˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„èšç±»æ–¹æ³•åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸­è¡¨ç°ä¸ä½³ï¼Œä¸”æ‰©å±•æ€§å’Œç›¸ä¼¼æ€§åº¦é‡ä¸å¤Ÿé€æ˜ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¤šè¯­è¨€MatryoshkaåµŒå…¥çš„å±‚æ¬¡åŒ–èšç±»æ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨ä¸åŒç²’åº¦ä¸Šè¯„ä¼°æ•…äº‹ç›¸ä¼¼æ€§ã€‚
3. è¯¥æ–¹æ³•åœ¨SemEval 2022 Task 8æµ‹è¯•æ•°æ®é›†ä¸Šå–å¾—äº†Pearsonç›¸å…³ç³»æ•°0.816çš„ä¼˜å¼‚è¡¨ç°ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ•ˆæœæå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸Šä¸‹æ–‡å¤§å‹è¯­è¨€æ¨¡å‹åµŒå…¥åœ¨ä¸»é¢˜å»ºæ¨¡å’Œèšç±»ä¸­è¶Šæ¥è¶Šå¤šåœ°è¢«ä½¿ç”¨ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•é€šå¸¸æ‰©å±•æ€§å·®ï¼Œä¾èµ–ä¸é€æ˜çš„ç›¸ä¼¼æ€§åº¦é‡ï¼Œå¹¶ä¸”åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸­è¡¨ç°ä¸ä½³ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–ã€å¯æ‰©å±•ã€å¯è§£é‡Šçš„å±‚æ¬¡åŒ–å¤šè¯­è¨€æ–°é—»æ–‡ç« å’Œç¤¾äº¤åª’ä½“æ•°æ®èšç±»æ–¹æ³•ã€‚æˆ‘ä»¬é¦–å…ˆè®­ç»ƒäº†å¤šè¯­è¨€MatryoshkaåµŒå…¥ï¼Œèƒ½å¤Ÿæ ¹æ®åµŒå…¥ç»´åº¦çš„ä¸åŒå­é›†æ¥ç¡®å®šæ•…äº‹ç›¸ä¼¼æ€§ã€‚è¯¥åµŒå…¥æ¨¡å‹åœ¨SemEval 2022 Task 8æµ‹è¯•æ•°æ®é›†ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ˆPearson $Ï$ = 0.816ï¼‰ã€‚è®­ç»ƒå®Œæˆåï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§é«˜æ•ˆçš„å±‚æ¬¡èšç±»ç®—æ³•ï¼Œåˆ©ç”¨MatryoshkaåµŒå…¥çš„å±‚æ¬¡ç‰¹æ€§æ¥è¯†åˆ«ç‹¬ç‰¹çš„æ–°é—»æ•…äº‹ã€å™äº‹å’Œä¸»é¢˜ã€‚æœ€åï¼Œæˆ‘ä»¬å±•ç¤ºäº†è¯¥æ–¹æ³•å¦‚ä½•åœ¨çœŸå®ä¸–ç•Œæ–°é—»æ•°æ®é›†ä¸­è¯†åˆ«å’Œèšç±»æ•…äº‹ã€å™äº‹å’Œæ€»ä½“ä¸»é¢˜ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰æ–°é—»æ–‡ç« èšç±»æ–¹æ³•åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸­çš„æ‰©å±•æ€§å·®å’Œç›¸ä¼¼æ€§åº¦é‡ä¸é€æ˜çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤šæ ·åŒ–å’Œå¤æ‚çš„æ–°é—»æ•°æ®æ—¶ï¼Œå¾€å¾€æ— æ³•æœ‰æ•ˆè¯†åˆ«å’Œèšç±»ç›¸ä¼¼çš„æ•…äº‹å’Œä¸»é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºå¤šè¯­è¨€MatryoshkaåµŒå…¥çš„å±‚æ¬¡åŒ–èšç±»æ–¹æ³•ï¼Œé€šè¿‡ä¸åŒç»´åº¦çš„åµŒå…¥æ¥è¯„ä¼°æ•…äº‹çš„ç›¸ä¼¼æ€§ï¼Œä»è€Œå®ç°æ›´çµæ´»å’Œå¯è§£é‡Šçš„èšç±»ã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨ä¸åŒçš„ç²’åº¦ä¸Šè¿›è¡Œèšç±»ï¼Œé€‚åº”å¤šæ ·åŒ–çš„æ–°é—»å†…å®¹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯è®­ç»ƒå¤šè¯­è¨€MatryoshkaåµŒå…¥æ¨¡å‹ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿæ•æ‰ä¸åŒè¯­è¨€å’Œæ–‡åŒ–èƒŒæ™¯ä¸‹çš„æ•…äº‹ç›¸ä¼¼æ€§ï¼›å…¶æ¬¡æ˜¯åŸºäºè¿™äº›åµŒå…¥çš„é«˜æ•ˆå±‚æ¬¡èšç±»ç®—æ³•ï¼Œåˆ©ç”¨åµŒå…¥çš„å±‚æ¬¡ç‰¹æ€§æ¥è¯†åˆ«ç‹¬ç‰¹çš„æ–°é—»æ•…äº‹å’Œä¸»é¢˜ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥äº†å¤šè¯­è¨€MatryoshkaåµŒå…¥ï¼Œè¿™ç§åµŒå…¥æ–¹æ³•èƒ½å¤Ÿæ ¹æ®ä¸åŒçš„ç»´åº¦å­é›†æ¥è¯„ä¼°æ•…äº‹ç›¸ä¼¼æ€§ï¼Œæ˜¾è‘—æå‡äº†èšç±»çš„çµæ´»æ€§å’Œå¯è§£é‡Šæ€§ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨å¤„ç†å¤šè¯­è¨€æ•°æ®æ—¶è¡¨ç°å‡ºæ›´å¥½çš„é€‚åº”æ€§å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–åµŒå…¥çš„ç›¸ä¼¼æ€§åº¦é‡ï¼ŒåŒæ—¶åœ¨èšç±»ç®—æ³•ä¸­å¼•å…¥äº†å±‚æ¬¡ç»“æ„ï¼Œä»¥ä¾¿æ›´å¥½åœ°è¯†åˆ«å’Œèšç±»æ–°é—»æ•…äº‹ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨SemEval 2022 Task 8æµ‹è¯•æ•°æ®é›†ä¸Šï¼Œæå‡ºçš„æ–¹æ³•è¾¾åˆ°äº†Pearsonç›¸å…³ç³»æ•°0.816ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿ï¼Œå±•ç¤ºäº†åœ¨å¤šè¯­è¨€æ–°é—»èšç±»ä»»åŠ¡ä¸­çš„å“è¶Šæ€§èƒ½å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ–°é—»èšåˆã€ç¤¾äº¤åª’ä½“åˆ†æå’Œä¿¡æ¯æ£€ç´¢ç­‰ã€‚é€šè¿‡æœ‰æ•ˆåœ°èšç±»å¤šè¯­è¨€æ–°é—»æ•°æ®ï¼Œèƒ½å¤Ÿå¸®åŠ©ç”¨æˆ·æ›´å¥½åœ°ç†è§£å’Œè·å–ä¿¡æ¯ï¼Œæå‡ä¿¡æ¯ä¼ æ’­çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–é¢†åŸŸï¼Œå¦‚å¤šè¯­è¨€å†…å®¹æ¨èå’Œèˆ†æƒ…ç›‘æµ‹ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Contextual large language model embeddings are increasingly utilized for topic modeling and clustering. However, current methods often scale poorly, rely on opaque similarity metrics, and struggle in multilingual settings. In this work, we present a novel, scalable, interpretable, hierarchical, and multilingual approach to clustering news articles and social media data. To do this, we first train multilingual Matryoshka embeddings that can determine story similarity at varying levels of granularity based on which subset of the dimensions of the embeddings is examined. This embedding model achieves state-of-the-art performance on the SemEval 2022 Task 8 test dataset (Pearson $Ï$ = 0.816). Once trained, we develop an efficient hierarchical clustering algorithm that leverages the hierarchical nature of Matryoshka embeddings to identify unique news stories, narratives, and themes. We conclude by illustrating how our approach can identify and cluster stories, narratives, and overarching themes within real-world news datasets.

