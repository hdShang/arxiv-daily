---
layout: default
title: CASPER: A Large Scale Spontaneous Speech Dataset
---

# CASPER: A Large Scale Spontaneous Speech Dataset

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.00267" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.00267v3</a>
  <a href="https://arxiv.org/pdf/2506.00267.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.00267v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.00267v3', 'CASPER: A Large Scale Spontaneous Speech Dataset')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Cihan Xiao, Ruixing Liang, Xiangyu Zhang, Mehmet Emre Tiryaki, Veronica Bae, Lavanya Shankar, Rong Yang, Ethan Poon, Emmanuel Dupoux, Sanjeev Khudanpur, Leibny Paola Garcia Perera

**åˆ†ç±»**: cs.CL, cs.SD, eess.AS

**å‘å¸ƒæ—¥æœŸ**: 2025-05-30 (æ›´æ–°: 2025-06-11)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCASPERæ•°æ®é›†ä»¥è§£å†³è‡ªå‘è¯­éŸ³æ•°æ®ç¨€ç¼ºé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è‡ªå‘è¯­éŸ³æ•°æ®` `è‡ªç„¶å¯¹è¯` `è¯­éŸ³å¤„ç†` `æ•°æ®é›†æ„å»º` `äººæœºäº¤äº’` `è¯­éŸ³è¯†åˆ«`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è¯­éŸ³æ•°æ®é›†å¤§å¤šåŒ…å«è„šæœ¬å¯¹è¯ï¼Œç¼ºä¹é«˜è´¨é‡çš„è‡ªå‘è¯­éŸ³æ•°æ®ï¼Œé™åˆ¶äº†è¯­éŸ³å¤„ç†æŠ€æœ¯çš„å‘å±•ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¼•å¯¼å’Œå½•åˆ¶è‡ªç„¶å¯¹è¯çš„æµç¨‹ï¼Œæ—¨åœ¨æ”¶é›†å¤šæ ·åŒ–å’ŒçœŸå®çš„è‡ªå‘è¯­éŸ³æ•°æ®ã€‚
3. æ•°æ®é›†åŒ…å«100å¤šä¸ªå°æ—¶çš„è‡ªå‘è¯­éŸ³ï¼Œæä¾›äº†ä¸€ä¸ªå¯é‡å¤çš„æ¡†æ¶ï¼Œä¿ƒè¿›äº†æœªæ¥çš„ç ”ç©¶å’Œæ•°æ®æ”¶é›†ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹çš„æˆåŠŸï¼Œå¼€å‘ç±»ä¼¼çš„è¯­éŸ³å¤„ç†èƒ½åŠ›å¼•èµ·äº†å¹¿æ³›å…³æ³¨ã€‚ç„¶è€Œï¼Œè‡ªå‘è¯­éŸ³æ•°æ®çš„ç¨€ç¼ºæ€§æ˜¯ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ï¼Œå› ä¸ºç°æœ‰æ•°æ®é›†å¤§å¤šåŒ…å«è„šæœ¬å¯¹è¯ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„è‡ªç„¶å¯¹è¯å¼•å¯¼å’Œå½•åˆ¶æµç¨‹ï¼Œå¹¶å‘å¸ƒäº†åŒ…å«100å¤šä¸ªå°æ—¶è‡ªå‘è¯­éŸ³çš„æ•°æ®é›†ã€‚è¯¥æ–¹æ³•ä¿ƒè¿›äº†æµç•…è‡ªç„¶çš„å¯¹è¯ï¼Œé¼“åŠ±å¤šæ ·åŒ–çš„è¯é¢˜å’Œäº’åŠ¨äº¤æµã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ä¸åŒï¼Œå®ƒä¿ƒè¿›äº†çœŸå®çš„äº’åŠ¨ï¼Œä¸ºæœªæ¥çš„æ•°æ®æ”¶é›†æä¾›äº†å¯é‡å¤çš„æ¡†æ¶ã€‚æœ¬æ–‡ä»‹ç»äº†æˆ‘ä»¬çš„æ•°æ®é›†å’Œæ–¹æ³•ï¼Œä¸ºè§£å†³è‡ªå‘è¯­éŸ³æ•°æ®çŸ­ç¼ºå¥ å®šäº†åŸºç¡€ã€‚æˆ‘ä»¬è®¡åˆ’åœ¨æœªæ¥é˜¶æ®µæ‰©å±•è¯¥æ•°æ®é›†ï¼Œä¸ºç ”ç©¶ç¤¾åŒºæä¾›ä¸æ–­å¢é•¿çš„èµ„æºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³è‡ªå‘è¯­éŸ³æ•°æ®ç¨€ç¼ºçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äºè„šæœ¬å¯¹è¯ï¼Œæ— æ³•æ•æ‰è‡ªç„¶äº¤æµçš„å¤æ‚æ€§å’Œå¤šæ ·æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„è‡ªç„¶å¯¹è¯å¼•å¯¼å’Œå½•åˆ¶æµç¨‹ï¼Œé€šè¿‡é¼“åŠ±çœŸå®äº’åŠ¨æ¥æ”¶é›†è‡ªå‘è¯­éŸ³æ•°æ®ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨æé«˜æ•°æ®çš„è‡ªç„¶æ€§å’Œå¤šæ ·æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¯¹è¯å¼•å¯¼ã€å½•åˆ¶å’Œæ•°æ®å¤„ç†ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡ç‰¹å®šçš„å¼•å¯¼é—®é¢˜æ¿€å‘å‚ä¸è€…çš„è‡ªç„¶å¯¹è¯ï¼Œç„¶åè¿›è¡Œå½•åˆ¶ï¼Œæœ€åå¯¹æ•°æ®è¿›è¡Œæ•´ç†å’Œæ ‡æ³¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å¯¼å’Œå½•åˆ¶è‡ªç„¶å¯¹è¯çš„æµç¨‹ï¼ŒåŒºåˆ«äºä¼ ç»Ÿçš„è„šæœ¬å¯¹è¯æ–¹æ³•ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰çœŸå®çš„äº¤æµåœºæ™¯ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®æ”¶é›†è¿‡ç¨‹ä¸­ï¼Œè®¾ç½®äº†å¤šæ ·åŒ–çš„è¯é¢˜å’Œäº’åŠ¨å½¢å¼ï¼Œç¡®ä¿å‚ä¸è€…èƒ½å¤Ÿè‡ªç”±è¡¨è¾¾ï¼Œé‡‡ç”¨äº†é«˜è´¨é‡çš„å½•éŸ³è®¾å¤‡ä»¥ä¿è¯éŸ³é¢‘è´¨é‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒCASPERæ•°æ®é›†çš„è‡ªå‘è¯­éŸ³åœ¨å¤šæ ·æ€§å’Œè‡ªç„¶æ€§ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿè„šæœ¬å¯¹è¯æ•°æ®é›†ï¼Œä¸ºè¯­éŸ³å¤„ç†æ¨¡å‹çš„è®­ç»ƒæä¾›äº†æ›´ä¸ºä¸°å¯Œçš„è¯­æ–™ï¼Œæå‡äº†æ¨¡å‹åœ¨çœŸå®åœºæ™¯ä¸‹çš„è¡¨ç°ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è¯­éŸ³è¯†åˆ«ã€å¯¹è¯ç³»ç»Ÿå’Œäººæœºäº¤äº’ç­‰ã€‚è‡ªå‘è¯­éŸ³æ•°æ®çš„ä¸°å¯Œæ€§å°†æ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ï¼Œæå‡è¯­éŸ³å¤„ç†ç³»ç»Ÿçš„è‡ªç„¶æ€§å’Œå‡†ç¡®æ€§ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The success of large language models has driven interest in developing similar speech processing capabilities. However, a key challenge is the scarcity of high-quality spontaneous speech data, as most existing datasets contain scripted dialogues. To address this, we present a novel pipeline for eliciting and recording natural dialogues and release our dataset with 100+ hours of spontaneous speech. Our approach fosters fluid, natural conversations while encouraging a diverse range of topics and interactive exchanges. Unlike traditional methods, it facilitates genuine interactions, providing a reproducible framework for future data collection. This paper introduces our dataset and methodology, laying the groundwork for addressing the shortage of spontaneous speech data. We plan to expand this dataset in future stages, offering a growing resource for the research community.

