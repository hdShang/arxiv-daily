---
layout: default
title: "Exploring Multimodal Challenges in Toxic Chinese Detection: Taxonomy, Benchmark, and Findings"
---

# Exploring Multimodal Challenges in Toxic Chinese Detection: Taxonomy, Benchmark, and Findings

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.24341" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.24341v1</a>
  <a href="https://arxiv.org/pdf/2505.24341.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.24341v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.24341v1', 'Exploring Multimodal Challenges in Toxic Chinese Detection: Taxonomy, Benchmark, and Findings')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shujian Yang, Shiyao Cui, Chuanrui Hu, Haicheng Wang, Tianwei Zhang, Minlie Huang, Jialiang Lu, Han Qiu

**åˆ†ç±»**: cs.CL, cs.AI, cs.CY

**å‘å¸ƒæ—¥æœŸ**: 2025-05-30

**å¤‡æ³¨**: Accepted to ACL 2025 (Findings). Camera-ready version

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šæ¨¡æ€æŒ‘æˆ˜åˆ†ç±»ä»¥æå‡ä¸­æ–‡æ¯’æ€§æ£€æµ‹èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ¯’æ€§æ£€æµ‹` `å¤šæ¨¡æ€æŒ‘æˆ˜` `ä¸­æ–‡å¤„ç†` `è¯­è¨€æ¨¡å‹` `ä¸Šä¸‹æ–‡å­¦ä¹ ` `ç›‘ç£å¾®è°ƒ` `æ•°æ®é›†æ„å»º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ¯’æ€§æ£€æµ‹æ–¹æ³•åœ¨é¢å¯¹æ‰°åŠ¨çš„ä¸­æ–‡æ–‡æœ¬æ—¶è¡¨ç°ä¸ä½³ï¼Œå®¹æ˜“è¢«ç®€å•çš„å­—ç¬¦æ›¿æ¢æ‰€æ··æ·†ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§ä¸‰ç§æ‰°åŠ¨ç­–ç•¥å’Œå…«ç§å…·ä½“æ–¹æ³•çš„åˆ†ç±»ï¼Œæ—¨åœ¨ç³»ç»Ÿæ€§åœ°è§£å†³ä¸­æ–‡æ¯’æ€§æ£€æµ‹ä¸­çš„å¤šæ¨¡æ€æŒ‘æˆ˜ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œå½“å‰çš„LLMsåœ¨æ£€æµ‹æ‰°åŠ¨çš„æ¯’æ€§å†…å®¹æ—¶èƒ½åŠ›ä¸è¶³ï¼Œä¸”åœ¨å°‘é‡ç¤ºä¾‹ä¸‹å¯èƒ½å‡ºç°è¯¯åˆ¤ç°è±¡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ£€æµ‹æ¯’æ€§å†…å®¹åœ¨è¯­è¨€æ¨¡å‹ä¸­è‡³å…³é‡è¦ï¼Œä½†é¢ä¸´è¯¸å¤šæŒ‘æˆ˜ã€‚å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç†è§£ä¸­æ–‡æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œç ”ç©¶è¡¨æ˜ç®€å•çš„å­—ç¬¦æ›¿æ¢å°±èƒ½è½»æ˜“æ··æ·†å½“å‰æœ€å…ˆè¿›çš„LLMsã€‚æœ¬æ–‡å¼ºè°ƒä¸­æ–‡è¯­è¨€çš„å¤šæ¨¡æ€ç‰¹æ€§æ˜¯éƒ¨ç½²LLMsè¿›è¡Œæ¯’æ€§æ£€æµ‹çš„å…³é”®æŒ‘æˆ˜ã€‚æˆ‘ä»¬æå‡ºäº†ä¸‰ç§æ‰°åŠ¨ç­–ç•¥å’Œå…«ç§å…·ä½“æ–¹æ³•çš„åˆ†ç±»ï¼Œå¹¶åŸºäºæ­¤åˆ†ç±»æ•´ç†äº†æ•°æ®é›†ï¼ŒåŸºå‡†æµ‹è¯•äº†ä¹ç§æ¥è‡ªç¾å›½å’Œä¸­å›½çš„æœ€å…ˆè¿›LLMsï¼Œä»¥è¯„ä¼°å…¶å¯¹æ‰°åŠ¨æ¯’æ€§ä¸­æ–‡æ–‡æœ¬çš„æ£€æµ‹èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ¢ç´¢äº†æˆæœ¬æ•ˆç›Šé«˜çš„å¢å¼ºè§£å†³æ–¹æ¡ˆï¼Œå¦‚ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰å’Œç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ã€‚ç»“æœæ˜¾ç¤ºï¼ŒLLMsåœ¨æ£€æµ‹æ‰°åŠ¨çš„å¤šæ¨¡æ€ä¸­æ–‡æ¯’æ€§å†…å®¹æ–¹é¢èƒ½åŠ›è¾ƒå¼±ï¼Œä¸”ICLæˆ–SFTåœ¨å°‘é‡æ‰°åŠ¨ç¤ºä¾‹ä¸‹å¯èƒ½å¯¼è‡´LLMsâ€œè¿‡åº¦æ ¡æ­£â€ï¼Œå°†è®¸å¤šæ­£å¸¸ä¸­æ–‡å†…å®¹è¯¯åˆ¤ä¸ºæ¯’æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä¸­æ–‡æ¯’æ€§å†…å®¹æ£€æµ‹ä¸­ï¼Œç°æœ‰æ–¹æ³•å¯¹æ‰°åŠ¨æ–‡æœ¬çš„è¯†åˆ«èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç®€å•çš„å­—ç¬¦æ›¿æ¢ä¼šå¯¼è‡´LLMsçš„æ£€æµ‹æ•ˆæœæ˜¾è‘—ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„åˆ†ç±»æ–¹æ³•ï¼Œé’ˆå¯¹ä¸­æ–‡æ¯’æ€§å†…å®¹çš„å¤šæ¨¡æ€ç‰¹æ€§ï¼Œè®¾è®¡äº†ä¸‰ç§æ‰°åŠ¨ç­–ç•¥å’Œå…«ç§å…·ä½“æ–¹æ³•ï¼Œä»¥å¢å¼ºLLMsçš„æ£€æµ‹èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†çš„æ„å»ºã€æ‰°åŠ¨ç­–ç•¥çš„åº”ç”¨ä»¥åŠå¯¹ä¹ç§LLMsçš„åŸºå‡†æµ‹è¯•ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œæ€§èƒ½è¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæå‡ºäº†é’ˆå¯¹ä¸­æ–‡æ¯’æ€§æ£€æµ‹çš„å¤šæ¨¡æ€æ‰°åŠ¨åˆ†ç±»ï¼Œè¿™ä¸€æ–¹æ³•ä¸ç°æœ‰çš„å•ä¸€æ–‡æœ¬æ£€æµ‹æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ï¼Œèƒ½å¤Ÿæ›´å…¨é¢åœ°è¯„ä¼°æ¨¡å‹çš„é²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰å’Œç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ç­‰æŠ€æœ¯ï¼Œè®¾ç½®äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–æ¨¡å‹åœ¨æ‰°åŠ¨æ–‡æœ¬ä¸Šçš„è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå½“å‰çš„LLMsåœ¨æ£€æµ‹æ‰°åŠ¨çš„å¤šæ¨¡æ€ä¸­æ–‡æ¯’æ€§å†…å®¹æ—¶è¡¨ç°ä¸ä½³ï¼Œå‡†ç¡®ç‡æ˜¾è‘—ä½äºå¯¹æœªæ‰°åŠ¨æ–‡æœ¬çš„æ£€æµ‹ã€‚æ­¤å¤–ï¼Œä½¿ç”¨ICLæˆ–SFTæ—¶ï¼Œæ¨¡å‹åœ¨å°‘é‡æ‰°åŠ¨ç¤ºä¾‹ä¸‹çš„è¯¯åˆ¤ç‡å¢åŠ ï¼Œå¯¼è‡´æ­£å¸¸å†…å®¹è¢«é”™è¯¯æ ‡è®°ä¸ºæ¯’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾äº¤åª’ä½“ç›‘æ§ã€åœ¨çº¿è¯„è®ºå®¡æ ¸å’Œå†…å®¹è¿‡æ»¤ç­‰ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡å¯¹ä¸­æ–‡æ¯’æ€§å†…å®¹çš„æ£€æµ‹èƒ½åŠ›ï¼Œå…·æœ‰é‡è¦çš„ç¤¾ä¼šä»·å€¼å’Œå®é™…æ„ä¹‰ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯æ‰©å±•è‡³å…¶ä»–è¯­è¨€çš„æ¯’æ€§æ£€æµ‹ä»»åŠ¡ï¼Œæ¨åŠ¨å¤šæ¨¡æ€å†…å®¹åˆ†æçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Detecting toxic content using language models is important but challenging. While large language models (LLMs) have demonstrated strong performance in understanding Chinese, recent studies show that simple character substitutions in toxic Chinese text can easily confuse the state-of-the-art (SOTA) LLMs. In this paper, we highlight the multimodal nature of Chinese language as a key challenge for deploying LLMs in toxic Chinese detection. First, we propose a taxonomy of 3 perturbation strategies and 8 specific approaches in toxic Chinese content. Then, we curate a dataset based on this taxonomy, and benchmark 9 SOTA LLMs (from both the US and China) to assess if they can detect perturbed toxic Chinese text. Additionally, we explore cost-effective enhancement solutions like in-context learning (ICL) and supervised fine-tuning (SFT). Our results reveal two important findings. (1) LLMs are less capable of detecting perturbed multimodal Chinese toxic contents. (2) ICL or SFT with a small number of perturbed examples may cause the LLMs "overcorrect'': misidentify many normal Chinese contents as toxic.

