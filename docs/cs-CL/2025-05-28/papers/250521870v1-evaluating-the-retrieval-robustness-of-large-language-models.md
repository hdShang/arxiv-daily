---
layout: default
title: Evaluating the Retrieval Robustness of Large Language Models
---

# Evaluating the Retrieval Robustness of Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21870" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21870v1</a>
  <a href="https://arxiv.org/pdf/2505.21870.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21870v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21870v1', 'Evaluating the Retrieval Robustness of Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shuyang Cao, Karthik Radhakrishnan, David Rosenberg, Steven Lu, Pengxiang Cheng, Lu Wang, Shiyue Zhang

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-28

**å¤‡æ³¨**: 19 pages

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹åœ¨æ£€ç´¢å¢å¼ºç”Ÿæˆä¸­çš„é²æ£’æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ£€ç´¢å¢å¼ºç”Ÿæˆ` `å¤§è¯­è¨€æ¨¡å‹` `é²æ£’æ€§è¯„ä¼°` `çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡` `å¼€æ”¾åŸŸé—®é¢˜`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ£€ç´¢å¢å¼ºç”Ÿæˆæ–¹æ³•åœ¨æ£€ç´¢ä¸å®Œç¾æ—¶å¯èƒ½å¯¼è‡´æ€§èƒ½ä¸‹é™ï¼Œé™åˆ¶äº†å¤§è¯­è¨€æ¨¡å‹çš„åº”ç”¨æ•ˆæœã€‚
2. æœ¬ç ”ç©¶é€šè¿‡å»ºç«‹åŸºå‡†å’Œå¼•å…¥é²æ£’æ€§æŒ‡æ ‡ï¼Œç³»ç»Ÿè¯„ä¼°äº†å¤§è¯­è¨€æ¨¡å‹åœ¨RAGè®¾ç½®ä¸‹çš„è¡¨ç°ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œå°½ç®¡å¤§è¯­è¨€æ¨¡å‹åœ¨æ£€ç´¢é²æ£’æ€§ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†ä»å­˜åœ¨ä¸å®Œç¾é²æ£’æ€§çš„é—®é¢˜ï¼Œå½±å“å…¶æ€§èƒ½å‘æŒ¥ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰é€šå¸¸æå‡å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è§£å†³çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œç”±äºæ£€ç´¢ä¸å®Œç¾åŠæ¨¡å‹åˆ©ç”¨æ£€ç´¢å†…å®¹çš„èƒ½åŠ›æœ‰é™ï¼ŒRAGå¯èƒ½å¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚æœ¬ç ”ç©¶è¯„ä¼°äº†LLMsåœ¨å®é™…RAGè®¾ç½®ä¸­çš„é²æ£’æ€§ï¼Œé‡ç‚¹å…³æ³¨ä¸‰ä¸ªç ”ç©¶é—®é¢˜ï¼šRAGæ˜¯å¦æ€»æ˜¯ä¼˜äºéRAGï¼Ÿæ›´å¤šæ£€ç´¢æ–‡æ¡£æ˜¯å¦æ€»èƒ½æå‡æ€§èƒ½ï¼Ÿæ–‡æ¡£é¡ºåºæ˜¯å¦å½±å“ç»“æœï¼Ÿä¸ºæ­¤ï¼Œæˆ‘ä»¬å»ºç«‹äº†ä¸€ä¸ªåŒ…å«1500ä¸ªå¼€æ”¾åŸŸé—®é¢˜çš„åŸºå‡†ï¼Œå¹¶å¼•å…¥äº†ä¸‰ç§é²æ£’æ€§æŒ‡æ ‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æœ‰LLMså±•ç°å‡ºè¾ƒé«˜çš„æ£€ç´¢é²æ£’æ€§ï¼Œä½†ä¸åŒç¨‹åº¦çš„ä¸å®Œç¾é²æ£’æ€§é™åˆ¶äº†å®ƒä»¬å……åˆ†åˆ©ç”¨RAGçš„ä¼˜åŠ¿ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹åœ¨æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ä¸­å¯èƒ½å‡ºç°çš„æ€§èƒ½ä¸‹é™é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨æ£€ç´¢ä¸å®Œç¾çš„æƒ…å†µä¸‹ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†åˆ©ç”¨æ£€ç´¢å†…å®¹çš„èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å»ºç«‹ä¸€ä¸ªåŒ…å«1500ä¸ªå¼€æ”¾åŸŸé—®é¢˜çš„åŸºå‡†ï¼Œè®ºæ–‡è¯„ä¼°äº†ä¸åŒå¤§è¯­è¨€æ¨¡å‹åœ¨RAGè®¾ç½®ä¸‹çš„é²æ£’æ€§ï¼Œæå‡ºäº†ä¸‰ç§é²æ£’æ€§æŒ‡æ ‡æ¥åˆ†ææ¨¡å‹è¡¨ç°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€é²æ£’æ€§æŒ‡æ ‡è®¾è®¡å’Œå®éªŒè¯„ä¼°ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œæ„å»ºåŸºå‡†æ•°æ®é›†ï¼›å…¶æ¬¡ï¼Œè®¾è®¡è¯„ä¼°æŒ‡æ ‡ï¼›æœ€åï¼Œé€šè¿‡å®éªŒå¯¹11ä¸ªå¤§è¯­è¨€æ¨¡å‹è¿›è¡Œè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„ä¸»è¦åˆ›æ–°åœ¨äºå¼•å…¥äº†é²æ£’æ€§æŒ‡æ ‡ï¼Œç³»ç»Ÿæ€§åœ°è¯„ä¼°äº†å¤§è¯­è¨€æ¨¡å‹åœ¨RAGä¸­çš„è¡¨ç°ï¼Œå¡«è¡¥äº†ç°æœ‰ç ”ç©¶çš„ç©ºç™½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œä½¿ç”¨äº†ä¸‰ç§ä¸åŒçš„æç¤ºç­–ç•¥ï¼Œè¯„ä¼°äº†æ–‡æ¡£æ•°é‡å’Œé¡ºåºå¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ï¼Œç¡®ä¿äº†å®éªŒçš„å…¨é¢æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æœ‰è¯„ä¼°çš„å¤§è¯­è¨€æ¨¡å‹åœ¨æ£€ç´¢é²æ£’æ€§ä¸Šè¡¨ç°å‡ºè‰²ï¼Œå°½ç®¡å­˜åœ¨ä¸åŒç¨‹åº¦çš„ä¸å®Œç¾é²æ£’æ€§ã€‚å…·ä½“è€Œè¨€ï¼Œæ¨¡å‹åœ¨é¢å¯¹ä¸åŒæ•°é‡å’Œé¡ºåºçš„æ£€ç´¢æ–‡æ¡£æ—¶ï¼Œæ€§èƒ½æ³¢åŠ¨è¾ƒå°ï¼Œè¡¨æ˜å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å¯é æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬çŸ¥è¯†é—®ç­”ç³»ç»Ÿã€æ™ºèƒ½åŠ©æ‰‹å’Œä¿¡æ¯æ£€ç´¢ç­‰ã€‚é€šè¿‡æå‡å¤§è¯­è¨€æ¨¡å‹åœ¨æ£€ç´¢å¢å¼ºç”Ÿæˆä¸­çš„é²æ£’æ€§ï¼Œå¯ä»¥æ˜¾è‘—æé«˜è¿™äº›ç³»ç»Ÿåœ¨å®é™…åº”ç”¨ä¸­çš„è¡¨ç°å’Œç”¨æˆ·ä½“éªŒï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Retrieval-augmented generation (RAG) generally enhances large language models' (LLMs) ability to solve knowledge-intensive tasks. But RAG may also lead to performance degradation due to imperfect retrieval and the model's limited ability to leverage retrieved content. In this work, we evaluate the robustness of LLMs in practical RAG setups (henceforth retrieval robustness). We focus on three research questions: (1) whether RAG is always better than non-RAG; (2) whether more retrieved documents always lead to better performance; (3) and whether document orders impact results. To facilitate this study, we establish a benchmark of 1500 open-domain questions, each with retrieved documents from Wikipedia. We introduce three robustness metrics, each corresponds to one research question. Our comprehensive experiments, involving 11 LLMs and 3 prompting strategies, reveal that all of these LLMs exhibit surprisingly high retrieval robustness; nonetheless, different degrees of imperfect robustness hinders them from fully utilizing the benefits of RAG.

