---
layout: default
title: Large Language Model-Driven Dynamic Assessment of Grammatical Accuracy in English Language Learner Writing
---

# Large Language Model-Driven Dynamic Assessment of Grammatical Accuracy in English Language Learner Writing

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.00931" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.00931v1</a>
  <a href="https://arxiv.org/pdf/2505.00931.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.00931v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.00931v1', 'Large Language Model-Driven Dynamic Assessment of Grammatical Accuracy in English Language Learner Writing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Timur Jaganov, John Blake, JuliÃ¡n Villegas, Nicholas Carr

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-02

**å¤‡æ³¨**: 15 pages, 8 Figures. This work has been submitted to the IEEE for possible publication

**æœŸåˆŠ**: IEEE ACCESS, 2025, Volume 13, pp. 151538-151550

**DOI**: [10.1109/ACCESS.2025.3603191](https://doi.org/10.1109/ACCESS.2025.3603191)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„åŠ¨æ€è¯„ä¼°æ–¹æ³•ä»¥æå‡è‹±è¯­å†™ä½œå‡†ç¡®æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åŠ¨æ€è¯„ä¼°` `å¤§å‹è¯­è¨€æ¨¡å‹` `è‹±è¯­å­¦ä¹ ` `è¯­æ³•è¾…å¯¼` `å®æ—¶åé¦ˆ` `æ•™è‚²æŠ€æœ¯` `æ™ºèƒ½è¾…å¯¼`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„åŠ¨æ€è¯„ä¼°æ–¹æ³•åœ¨å¤§è§„æ¨¡è‹±è¯­å­¦ä¹ è€…ä¸­å®æ–½æ—¶é¢ä¸´æ•ˆç‡å’Œåé¦ˆè´¨é‡çš„æŒ‘æˆ˜ã€‚
2. æœ¬ç ”ç©¶æå‡ºDynaWriteåº”ç”¨ï¼Œé€šè¿‡æ•´åˆå¤šç§å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæä¾›å®æ—¶çš„è¯­æ³•åé¦ˆä»¥æå‡å­¦ä¹ æ•ˆæœã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGPT-4oåœ¨è¯­æ³•é”™è¯¯è¯†åˆ«å’Œåé¦ˆè´¨é‡ä¸Šä¼˜äºå…¶ä»–æ¨¡å‹ï¼Œå…·å¤‡è‰¯å¥½çš„å®æ—¶å“åº”æ€§å’Œç³»ç»Ÿç¨³å®šæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨åŠ¨æ€è¯„ä¼°ï¼ˆDAï¼‰ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼€å‘äº†DynaWriteï¼Œä¸€ä¸ªæ¨¡å—åŒ–çš„è¯­æ³•è¾…å¯¼åº”ç”¨ï¼Œæ”¯æŒå¤šç§LLMç”ŸæˆåŠ¨æ€åé¦ˆã€‚åˆæ­¥æµ‹è¯•æ˜¾ç¤ºï¼ŒGPT-4oå’Œç¥ç»èŠå¤©æ¨¡å‹åœ¨è¯­è¨€å­¦ä¹ è¯¾å ‚ä¸­å…·æœ‰è¾ƒé«˜çš„DAæ‰©å±•æ½œåŠ›ã€‚è¿›ä¸€æ­¥æµ‹è¯•å‘ç°ï¼Œä¸¤è€…åœ¨è¯†åˆ«ç”¨æˆ·å¥å­ä¸­çš„è¯­æ³•é”™è¯¯æ–¹é¢è¡¨ç°ç›¸ä¼¼ï¼Œä½†GPT-4oåœ¨DAè´¨é‡ä¸Šå§‹ç»ˆä¼˜äºç¥ç»èŠå¤©ï¼Œèƒ½å¤Ÿç”Ÿæˆæ¸…æ™°ã€ä¸€è‡´ä¸”é€æ­¥æ˜ç¡®çš„æç¤ºã€‚é€šè¿‡è¯¦ç»†çš„æ€§èƒ½æµ‹è¯•ï¼Œç¡®è®¤äº†å®æ—¶å“åº”æ€§å’Œç³»ç»Ÿç¨³å®šæ€§ï¼ŒGPT-4oå±•ç°å‡ºè¶³å¤Ÿçš„é€Ÿåº¦å’Œç¨³å®šæ€§ã€‚æœ¬ç ”ç©¶è¡¨æ˜ï¼ŒLLMså¯ä»¥ç”¨äºæ‰©å±•åŠ¨æ€è¯„ä¼°ï¼Œä»è€Œä½¿å…¶èƒ½å¤Ÿåœ¨æ¯”ä¼ ç»Ÿæ•™å¸ˆ-å­¦ä¹ è€…ç¯å¢ƒä¸­æ›´å¤§è§„æ¨¡åœ°å®æ–½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³ä¼ ç»ŸåŠ¨æ€è¯„ä¼°åœ¨å¤§è§„æ¨¡è‹±è¯­å­¦ä¹ è€…ä¸­å®æ–½çš„æ•ˆç‡ä½ä¸‹å’Œåé¦ˆè´¨é‡ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–æ•™å¸ˆçš„ä¸ªåˆ«æŒ‡å¯¼ï¼Œéš¾ä»¥æ»¡è¶³å¤§è§„æ¨¡å­¦ä¹ éœ€æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼€å‘DynaWriteåº”ç”¨ï¼Œç»“åˆå¤šç§å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæä¾›å®æ—¶ã€åŠ¨æ€çš„è¯­æ³•åé¦ˆï¼Œæ—¨åœ¨æé«˜å­¦ä¹ è€…çš„å†™ä½œå‡†ç¡®æ€§å’Œå­¦ä¹ ä½“éªŒã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—åé¦ˆèƒ½å¤Ÿæ›´å…·ä¸ªæ€§åŒ–å’ŒåŠæ—¶æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDynaWriteçš„æ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼šç”¨æˆ·è¾“å…¥æ¨¡å—ã€LLMé€‰æ‹©æ¨¡å—ã€åé¦ˆç”Ÿæˆæ¨¡å—å’Œç”¨æˆ·åé¦ˆæ¨¡å—ã€‚ç”¨æˆ·è¾“å…¥æ¨¡å—æ¥æ”¶å­¦ä¹ è€…çš„å†™ä½œå†…å®¹ï¼ŒLLMé€‰æ‹©æ¨¡å—æ ¹æ®éœ€æ±‚é€‰æ‹©åˆé€‚çš„æ¨¡å‹ï¼Œåé¦ˆç”Ÿæˆæ¨¡å—æä¾›å®æ—¶åé¦ˆï¼Œç”¨æˆ·åé¦ˆæ¨¡å—ç”¨äºæ”¶é›†å­¦ä¹ è€…çš„åé¦ˆä»¥ä¼˜åŒ–ç³»ç»Ÿã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„ä¸»è¦åˆ›æ–°åœ¨äºå°†å¤šç§å¤§å‹è¯­è¨€æ¨¡å‹æ•´åˆåˆ°åŠ¨æ€è¯„ä¼°ä¸­ï¼Œå°¤å…¶æ˜¯GPT-4oåœ¨åé¦ˆè´¨é‡ä¸Šçš„æ˜¾è‘—æå‡ï¼Œä½¿å…¶åœ¨è¯­æ³•è¾…å¯¼ä¸­è¡¨ç°ä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹é€‰æ‹©ä¸Šï¼Œé‡ç‚¹æµ‹è¯•äº†21ç§LLMï¼Œæœ€ç»ˆé€‰æ‹©GPT-4oå’Œç¥ç»èŠå¤©æ¨¡å‹ã€‚GPT-4oåœ¨ç”Ÿæˆåé¦ˆæ—¶ï¼Œé‡‡ç”¨äº†é€æ­¥æ˜ç¡®çš„æç¤ºè®¾è®¡ï¼Œç¡®ä¿å­¦ä¹ è€…èƒ½å¤Ÿç†è§£å’Œåº”ç”¨åé¦ˆã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒGPT-4oåœ¨è¯­æ³•é”™è¯¯è¯†åˆ«å’Œåé¦ˆè´¨é‡ä¸Šå‡ä¼˜äºç¥ç»èŠå¤©æ¨¡å‹ï¼Œèƒ½å¤Ÿç”Ÿæˆæ¸…æ™°ä¸”ä¸€è‡´çš„æç¤ºã€‚å…·ä½“è€Œè¨€ï¼ŒGPT-4oåœ¨åŠ¨æ€è¯„ä¼°ä¸­çš„è¡¨ç°ç¨³å®šï¼Œå®æ—¶å“åº”é€Ÿåº¦å¿«ï¼Œé€‚åˆå¤§è§„æ¨¡åº”ç”¨ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‹±è¯­è¯­è¨€å­¦ä¹ ã€åœ¨çº¿æ•™è‚²å¹³å°å’Œæ™ºèƒ½è¾…å¯¼ç³»ç»Ÿã€‚é€šè¿‡åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæ•™è‚²æœºæ„å¯ä»¥ä¸ºæ›´å¤šå­¦ä¹ è€…æä¾›ä¸ªæ€§åŒ–çš„è¯­æ³•è¾…å¯¼ï¼Œæå‡å­¦ä¹ æ•ˆæœï¼Œé™ä½æ•™å¸ˆè´Ÿæ‹…ï¼Œä¿ƒè¿›æ•™è‚²å…¬å¹³ã€‚æœªæ¥ï¼Œéšç€æŠ€æœ¯çš„è¿›æ­¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æ‰©å±•åˆ°å…¶ä»–è¯­è¨€å­¦ä¹ å’Œå†™ä½œé¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This study investigates the potential for Large Language Models (LLMs) to scale-up Dynamic Assessment (DA). To facilitate such an investigation, we first developed DynaWrite-a modular, microservices-based grammatical tutoring application which supports multiple LLMs to generate dynamic feedback to learners of English. Initial testing of 21 LLMs, revealed GPT-4o and neural chat to have the most potential to scale-up DA in the language learning classroom. Further testing of these two candidates found both models performed similarly in their ability to accurately identify grammatical errors in user sentences. However, GPT-4o consistently outperformed neural chat in the quality of its DA by generating clear, consistent, and progressively explicit hints. Real-time responsiveness and system stability were also confirmed through detailed performance testing, with GPT-4o exhibiting sufficient speed and stability. This study shows that LLMs can be used to scale-up dynamic assessment and thus enable dynamic assessment to be delivered to larger groups than possible in traditional teacher-learner settings.

