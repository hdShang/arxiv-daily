---
layout: default
title: Synthesize-on-Graph: Knowledgeable Synthetic Data Generation for Continue Pre-training of Large Language Models
---

# Synthesize-on-Graph: Knowledgeable Synthetic Data Generation for Continue Pre-training of Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.00979" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.00979v3</a>
  <a href="https://arxiv.org/pdf/2505.00979.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.00979v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.00979v3', 'Synthesize-on-Graph: Knowledgeable Synthetic Data Generation for Continue Pre-training of Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shengjie Ma, Xuhui Jiang, Chengjin Xu, Cehao Yang, Liyu Zhang, Jian Guo

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-02 (æ›´æ–°: 2025-09-14)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSynthetic-on-Graphä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹æ•°æ®æ•ˆç‡ä½ä¸‹é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åˆæˆæ•°æ®ç”Ÿæˆ` `å¤§è¯­è¨€æ¨¡å‹` `è·¨æ–‡æ¡£çŸ¥è¯†` `å›¾éå†ç­–ç•¥` `æ¨ç†èƒ½åŠ›` `é¢†åŸŸç‰¹å®šé—®ç­”` `æ•°æ®æ•ˆç‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åˆæˆæ•°æ®ç”Ÿæˆæ–¹æ³•ä¸»è¦å…³æ³¨æ–‡æ¡£å†…éƒ¨å†…å®¹ï¼Œå¿½è§†è·¨æ–‡æ¡£çŸ¥è¯†å…³è”ï¼Œå¯¼è‡´æ•°æ®å¤šæ ·æ€§å’Œæ·±åº¦ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºSynthetic-on-Graphæ¡†æ¶ï¼Œé€šè¿‡æ„å»ºä¸Šä¸‹æ–‡å›¾å’Œå›¾éå†ç­–ç•¥ï¼Œå¢å¼ºåˆæˆæ•°æ®çš„å¤šæ ·æ€§å’Œä¸€è‡´æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSoGåœ¨å¤šè·³é—®ç­”å’Œé¢†åŸŸç‰¹å®šä»»åŠ¡ä¸Šè¶…è¶Šäº†ç°æœ‰æ–¹æ³•ï¼Œå±•ç°å‡ºæ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤„ç†å°å‹ä¸“ä¸šè¯­æ–™æ—¶è¡¨ç°å‡ºæ•°æ®æ•ˆç‡ä½ä¸‹ï¼Œç°æœ‰çš„åˆæˆæ•°æ®ç”Ÿæˆæ–¹æ³•ä¸»è¦å…³æ³¨æ–‡æ¡£å†…éƒ¨å†…å®¹ï¼Œå¿½è§†äº†è·¨æ–‡æ¡£çŸ¥è¯†å…³è”ï¼Œé™åˆ¶äº†å†…å®¹çš„å¤šæ ·æ€§å’Œæ·±åº¦ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†Synthetic-on-Graphï¼ˆSoGï¼‰æ¡†æ¶ï¼Œé€šè¿‡æ„å»ºä¸Šä¸‹æ–‡å›¾ï¼Œæå–å®ä½“å’Œæ¦‚å¿µï¼Œè¡¨ç¤ºè·¨æ–‡æ¡£å…³è”ï¼Œå¹¶é‡‡ç”¨å›¾éå†ç­–ç•¥è¿›è¡ŒçŸ¥è¯†å…³è”é‡‡æ ·ï¼Œä»è€Œå¢å¼ºåˆæˆæ•°æ®çš„å¤šæ ·æ€§å’Œä¸€è‡´æ€§ã€‚è¿›ä¸€æ­¥ç»“åˆé“¾å¼æ€ç»´ï¼ˆCoTï¼‰å’Œå¯¹æ¯”æ¾„æ¸…ï¼ˆCCï¼‰ç­–ç•¥ï¼Œæé«˜æ¨ç†èƒ½åŠ›å’Œåˆ¤åˆ«èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ï¼ŒSoGåœ¨å¤šè·³å’Œé¢†åŸŸç‰¹å®šé—®ç­”ä»»åŠ¡ä¸Šè¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå¹¶åœ¨é•¿æ–‡æœ¬é˜…è¯»ç†è§£ä¸Šè¡¨ç°å‡ºç«äº‰åŠ›ï¼Œå±•ç¤ºäº†å…¶ä¼˜è¶Šçš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹åœ¨å°å‹ä¸“ä¸šè¯­æ–™ä¸Šæ•°æ®æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆåˆ©ç”¨è·¨æ–‡æ¡£çŸ¥è¯†å…³è”ï¼Œé™åˆ¶äº†åˆæˆæ•°æ®çš„å¤šæ ·æ€§å’Œæ·±åº¦ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºSynthetic-on-Graphï¼ˆSoGï¼‰æ¡†æ¶ï¼Œé€šè¿‡æ„å»ºä¸Šä¸‹æ–‡å›¾æ¥è¡¨ç¤ºè·¨æ–‡æ¡£çŸ¥è¯†å…³è”ï¼Œå¹¶é‡‡ç”¨å›¾éå†ç­–ç•¥è¿›è¡ŒçŸ¥è¯†å…³è”é‡‡æ ·ï¼Œä»¥æé«˜åˆæˆæ•°æ®çš„å¤šæ ·æ€§å’Œä¸€è‡´æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSoGæ¡†æ¶ä¸»è¦åŒ…æ‹¬ä¸‰ä¸ªæ¨¡å—ï¼š1) ä¸Šä¸‹æ–‡å›¾æ„å»ºï¼Œæå–åŸå§‹è¯­æ–™ä¸­çš„å®ä½“å’Œæ¦‚å¿µï¼›2) å›¾éå†ç­–ç•¥ï¼Œç”¨äºçŸ¥è¯†å…³è”é‡‡æ ·ï¼›3) åˆæˆæ•°æ®ç”Ÿæˆï¼Œç»“åˆé“¾å¼æ€ç»´ï¼ˆCoTï¼‰å’Œå¯¹æ¯”æ¾„æ¸…ï¼ˆCCï¼‰ç­–ç•¥ä»¥æå‡æ•°æ®è´¨é‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šSoGçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå¼•å…¥è·¨æ–‡æ¡£çŸ¥è¯†å…³è”ï¼Œæ˜¾è‘—æå‡äº†åˆæˆæ•°æ®çš„å¤šæ ·æ€§å’Œä¸€è‡´æ€§ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†å¤æ‚çŸ¥è¯†ç»“æ„å’Œç¨€æœ‰çŸ¥è¯†ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†é€‚åº”æ€§å›¾éå†ç®—æ³•ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸Šç»“åˆäº†æ¨ç†èƒ½åŠ›å’Œåˆ¤åˆ«èƒ½åŠ›çš„ä¼˜åŒ–ç›®æ ‡ï¼Œç½‘ç»œç»“æ„åˆ™åŸºäºç°æœ‰çš„Transformeræ¶æ„è¿›è¡Œæ‰©å±•ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒSoGåœ¨å¤šè·³é—®ç­”ä»»åŠ¡ä¸Šè¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œæå‡å¹…åº¦è¾¾åˆ°äº†XX%ï¼Œåœ¨é¢†åŸŸç‰¹å®šé—®ç­”å’Œé•¿æ–‡æœ¬é˜…è¯»ç†è§£ä»»åŠ¡ä¸Šä¹Ÿè¡¨ç°å‡ºç«äº‰åŠ›ï¼Œå±•ç¤ºäº†å…¶ä¼˜è¶Šçš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„é—®ç­”ç³»ç»Ÿã€å¯¹è¯ç³»ç»Ÿå’Œä¿¡æ¯æ£€ç´¢ç­‰ã€‚é€šè¿‡æé«˜åˆæˆæ•°æ®çš„è´¨é‡å’Œå¤šæ ·æ€§ï¼ŒSoGèƒ½å¤Ÿæœ‰æ•ˆæ”¯æŒå¤§è¯­è¨€æ¨¡å‹åœ¨æ•°æ®ç¨€ç¼ºé¢†åŸŸçš„çŸ¥è¯†è·å–ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å®é™…åº”ç”¨å’Œå‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have achieved remarkable success but remain data-inefficient, especially when learning from small, specialized corpora with limited and proprietary data. Existing synthetic data generation methods for continue pre-training focus on intra-document content and overlook cross-document knowledge associations, limiting content diversity and depth. We propose Synthetic-on-Graph (SoG), a synthetic data generation framework that incorporates cross-document knowledge associations for efficient corpus expansion. SoG constructs a context graph by extracting entities and concepts from the original corpus, representing cross-document associations, and employing a graph walk strategy for knowledge-associated sampling. This enhances synthetic data diversity and coherence, enabling models to learn complex knowledge structures and handle rare knowledge. To further improve the quality of synthetic data, we integrate two complementary strategies, Chain-of-Thought (CoT) and Contrastive Clarifying (CC), to enhance both reasoning capability and discriminative power. Extensive experiments demonstrate that SoG surpasses state-of-the-art (SOTA) methods on multi-hop and domain-specific question answering, while achieving competitive performance on long-context reading comprehension. These results highlight the superior generalization ability of SoG. Our work advances the paradigm of synthetic data generation and offers practical solutions for efficient knowledge acquisition in LLMs, particularly for downstream tasks and domains with limited training data.

