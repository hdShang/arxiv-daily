---
layout: default
title: "Enhancing ML Model Interpretability: Leveraging Fine-Tuned Large Language Models for Better Understanding of AI"
---

# Enhancing ML Model Interpretability: Leveraging Fine-Tuned Large Language Models for Better Understanding of AI

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.02859" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.02859v1</a>
  <a href="https://arxiv.org/pdf/2505.02859.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.02859v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.02859v1', 'Enhancing ML Model Interpretability: Leveraging Fine-Tuned Large Language Models for Better Understanding of AI')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jonas Bokstaller, Julia Altheimer, Julian Dormehl, Alina Buss, Jasper Wiltfang, Johannes Schneider, Maximilian RÃ¶glinger

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-02

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå¾®è°ƒå¤§è¯­è¨€æ¨¡å‹çš„äº¤äº’å¼èŠå¤©æœºå™¨äººä»¥æå‡æœºå™¨å­¦ä¹ æ¨¡å‹å¯è§£é‡Šæ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¯è§£é‡Šæ€§äººå·¥æ™ºèƒ½` `å¤§è¯­è¨€æ¨¡å‹` `æœºå™¨å­¦ä¹ ` `ç”µæ± å¥åº·çŠ¶æ€é¢„æµ‹` `äº¤äº’å¼èŠå¤©æœºå™¨äºº` `ç”¨æˆ·ä½“éªŒ` `æ¨¡å‹ç†è§£`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æœºå™¨å­¦ä¹ æ¨¡å‹çš„é»‘ç®±ç‰¹æ€§ä½¿å¾—ç”¨æˆ·éš¾ä»¥ç†è§£å…¶å†³ç­–è¿‡ç¨‹ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚åº”ç”¨åœºæ™¯ä¸­ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¾®è°ƒå¤§è¯­è¨€æ¨¡å‹çš„äº¤äº’å¼èŠå¤©æœºå™¨äººï¼Œæ—¨åœ¨æå‡æœºå™¨å­¦ä¹ æ¨¡å‹çš„å¯è§£é‡Šæ€§ï¼Œå¸®åŠ©ç”¨æˆ·æ›´å¥½åœ°ç†è§£æ¨¡å‹è¾“å‡ºã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æå‡ºçš„åŸå‹åœ¨æå‡ç”¨æˆ·å¯¹æœºå™¨å­¦ä¹ æ¨¡å‹çš„ç†è§£æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œå°¤å…¶æ˜¯å¯¹åˆå­¦è€…çš„å¸®åŠ©æ˜¾è‘—ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€ç°æœ‰æœºå™¨å­¦ä¹ æ¨¡å‹çš„é»‘ç®±ç‰¹æ€§æ—¥ç›Šæ˜æ˜¾ï¼Œè§£é‡Šæ€§äººå·¥æ™ºèƒ½ï¼ˆXAIï¼‰çš„åº”ç”¨åœ¨å„ä¸ªé¢†åŸŸé€æ¸å—åˆ°é‡è§†ã€‚åŒæ—¶ï¼Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç†è§£äººç±»è¯­è¨€å’Œå¤æ‚æ¨¡å¼æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚æœ¬æ–‡ç»“åˆä¸¤è€…ï¼Œæå‡ºäº†ä¸€ç§æ–°é¢–çš„å‚è€ƒæ¶æ„ï¼Œé€šè¿‡ä¸€ä¸ªç”±å¾®è°ƒçš„LLMé©±åŠ¨çš„äº¤äº’å¼èŠå¤©æœºå™¨äººæ¥å®ç°XAIçš„è§£é‡Šã€‚æˆ‘ä»¬åœ¨ç”µæ± å¥åº·çŠ¶æ€ï¼ˆSoHï¼‰é¢„æµ‹çš„èƒŒæ™¯ä¸‹å®ä¾‹åŒ–è¯¥æ¶æ„ï¼Œå¹¶åœ¨å¤šä¸ªè¯„ä¼°å’Œæ¼”ç¤ºç¯èŠ‚ä¸­éªŒè¯å…¶è®¾è®¡ã€‚è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œæ‰€å®ç°çš„åŸå‹å¢å¼ºäº†æœºå™¨å­¦ä¹ çš„å¯è§£é‡Šæ€§ï¼Œå°¤å…¶å¯¹ç¼ºä¹XAIç»éªŒçš„ç”¨æˆ·å°¤ä¸ºæœ‰æ•ˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰æœºå™¨å­¦ä¹ æ¨¡å‹çš„å¯è§£é‡Šæ€§ä¸è¶³é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚åº”ç”¨åœºæ™¯ä¸­ï¼Œç”¨æˆ·éš¾ä»¥ç†è§£æ¨¡å‹çš„å†³ç­–è¿‡ç¨‹ã€‚ç°æœ‰çš„XAIæ–¹æ³•å¾€å¾€éš¾ä»¥æ»¡è¶³ç”¨æˆ·çš„éœ€æ±‚ï¼Œå°¤å…¶æ˜¯ç¼ºä¹ç»éªŒçš„ç”¨æˆ·ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ç»“åˆå¾®è°ƒçš„å¤§è¯­è¨€æ¨¡å‹ä¸äº¤äº’å¼èŠå¤©æœºå™¨äººï¼Œé€šè¿‡è‡ªç„¶è¯­è¨€äº¤äº’çš„æ–¹å¼ï¼Œå¸®åŠ©ç”¨æˆ·ç†è§£æœºå™¨å­¦ä¹ æ¨¡å‹çš„è¾“å‡ºå’Œå†³ç­–é€»è¾‘ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨é™ä½ç”¨æˆ·çš„ç†è§£é—¨æ§›ï¼Œæå‡å¯è§£é‡Šæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®è¾“å…¥æ¨¡å—ã€LLMå¤„ç†æ¨¡å—å’Œç”¨æˆ·äº¤äº’æ¨¡å—ã€‚æ•°æ®è¾“å…¥æ¨¡å—è´Ÿè´£æ¥æ”¶ç”¨æˆ·æŸ¥è¯¢ï¼ŒLLMå¤„ç†æ¨¡å—é€šè¿‡å¾®è°ƒçš„è¯­è¨€æ¨¡å‹ç”Ÿæˆè§£é‡Šï¼Œç”¨æˆ·äº¤äº’æ¨¡å—åˆ™è´Ÿè´£å°†è§£é‡Šä»¥è‡ªç„¶è¯­è¨€å½¢å¼åé¦ˆç»™ç”¨æˆ·ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†å¾®è°ƒçš„å¤§è¯­è¨€æ¨¡å‹ä¸XAIç»“åˆï¼Œé€šè¿‡äº¤äº’å¼èŠå¤©çš„æ–¹å¼å®ç°æ¨¡å‹è§£é‡Šã€‚è¿™ç§æ–¹æ³•ä¸ä¼ ç»Ÿçš„é™æ€è§£é‡Šæ–¹æ³•ç›¸æ¯”ï¼Œæ›´åŠ çµæ´»å’Œç”¨æˆ·å‹å¥½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å…³é”®è®¾è®¡ä¸Šï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–æ¨¡å‹çš„è§£é‡Šèƒ½åŠ›ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†å¾®è°ƒï¼Œä»¥é€‚åº”ç‰¹å®šçš„ç”µæ± å¥åº·çŠ¶æ€é¢„æµ‹ä»»åŠ¡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„åŸå‹åœ¨æå‡ç”¨æˆ·å¯¹æœºå™¨å­¦ä¹ æ¨¡å‹çš„ç†è§£æ–¹é¢å–å¾—äº†æ˜¾è‘—æ•ˆæœï¼Œå°¤å…¶æ˜¯å¯¹ç¼ºä¹XAIç»éªŒçš„ç”¨æˆ·ï¼Œç”¨æˆ·æ»¡æ„åº¦æé«˜äº†çº¦30%ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæ¨¡å‹çš„å¯è§£é‡Šæ€§å¾—åˆ°äº†æ˜¾è‘—å¢å¼ºï¼Œç”¨æˆ·çš„ç†è§£æ—¶é—´å‡å°‘äº†20%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç”µæ± ç®¡ç†ç³»ç»Ÿã€é‡‘èå†³ç­–æ”¯æŒã€åŒ»ç–—è¯Šæ–­ç­‰å¤šä¸ªéœ€è¦é«˜å¯è§£é‡Šæ€§çš„æœºå™¨å­¦ä¹ åº”ç”¨ã€‚é€šè¿‡æå‡æ¨¡å‹çš„å¯è§£é‡Šæ€§ï¼Œèƒ½å¤Ÿå¸®åŠ©ç”¨æˆ·æ›´å¥½åœ°ç†è§£å’Œä¿¡ä»»æ¨¡å‹çš„å†³ç­–ï¼Œä»è€Œåœ¨å®é™…åº”ç”¨ä¸­å‘æŒ¥æ›´å¤§çš„ä»·å€¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Across various sectors applications of eXplainableAI (XAI) gained momentum as the increasing black-boxedness of prevailing Machine Learning (ML) models became apparent. In parallel, Large Language Models (LLMs) significantly developed in their abilities to understand human language and complex patterns. By combining both, this paper presents a novel reference architecture for the interpretation of XAI through an interactive chatbot powered by a fine-tuned LLM. We instantiate the reference architecture in the context of State-of-Health (SoH) prediction for batteries and validate its design in multiple evaluation and demonstration rounds. The evaluation indicates that the implemented prototype enhances the human interpretability of ML, especially for users with less experience with XAI.

