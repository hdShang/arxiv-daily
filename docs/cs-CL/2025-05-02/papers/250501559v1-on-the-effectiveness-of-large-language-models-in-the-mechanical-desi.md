---
layout: default
title: On the effectiveness of Large Language Models in the mechanical design domain
---

# On the effectiveness of Large Language Models in the mechanical design domain

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.01559" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.01559v1</a>
  <a href="https://arxiv.org/pdf/2505.01559.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.01559v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.01559v1', 'On the effectiveness of Large Language Models in the mechanical design domain')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Daniele Grandi, Fabian Riquelme

**åˆ†ç±»**: cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-02

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æœºæ¢°è®¾è®¡é¢†åŸŸçš„æœ‰æ•ˆæ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æœºæ¢°è®¾è®¡` `æ— ç›‘ç£å­¦ä¹ ` `æ¨¡å‹ä¼˜åŒ–` `è¯­ä¹‰ç†è§£`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰æ–¹æ³•åœ¨æœºæ¢°è®¾è®¡é¢†åŸŸçš„è¯­è¨€ç†è§£èƒ½åŠ›ä¸è¶³ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸ä½³ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šè®ºæ–‡æå‡ºé€šè¿‡æ— ç›‘ç£å­¦ä¹ ä»»åŠ¡è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æœºæ¢°å·¥ç¨‹é¢†åŸŸçš„è¡¨ç°ï¼Œé‡ç‚¹å…³æ³¨æ¨¡å‹æ¶æ„çš„ä¼˜åŒ–ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šé€šè¿‡è°ƒæ•´å­¦ä¹ ç‡ã€ä¸¢å¼ƒç‡ç­‰å‚æ•°ï¼Œæ¨¡å‹åœ¨äºŒå…ƒå¥å­å¯¹åˆ†ç±»ä»»åŠ¡ä¸­å–å¾—äº†0.62çš„å‡†ç¡®ç‡ï¼Œé›¶æ ·æœ¬åˆ†ç±»ä»»åŠ¡çš„å‡†ç¡®ç‡ä¸º0.386ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶æ—¨åœ¨ç†è§£å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æœºæ¢°å·¥ç¨‹é¢†åŸŸçš„è¡¨ç°ã€‚æˆ‘ä»¬åˆ©ç”¨ABCæ•°æ®é›†ä¸­è®¾è®¡å¸ˆä¸ºæ•´ä½“è£…é…å’Œå„ä¸ªéƒ¨ä»¶åˆ†é…çš„è¯­ä¹‰æ•°æ®ï¼Œç»è¿‡é¢„å¤„ç†åï¼Œå¼€å‘äº†ä¸¤ç§æ— ç›‘ç£ä»»åŠ¡æ¥è¯„ä¼°ä¸åŒæ¨¡å‹æ¶æ„åœ¨ç‰¹å®šé¢†åŸŸæ•°æ®ä¸Šçš„è¡¨ç°ï¼šäºŒå…ƒå¥å­å¯¹åˆ†ç±»ä»»åŠ¡å’Œé›¶æ ·æœ¬åˆ†ç±»ä»»åŠ¡ã€‚é€šè¿‡é’ˆå¯¹è¿‡æ‹Ÿåˆçš„è°ƒæ•´ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨äºŒå…ƒå¥å­å¯¹åˆ†ç±»ä»»åŠ¡ä¸­å–å¾—äº†0.62çš„å‡†ç¡®ç‡ï¼Œè€Œåœ¨é›¶æ ·æœ¬åˆ†ç±»ä»»åŠ¡ä¸­åˆ™æ˜¾è‘—è¶…è¶ŠåŸºçº¿ï¼Œè¾¾åˆ°äº†0.386çš„é¡¶çº§åˆ†ç±»å‡†ç¡®ç‡ã€‚ç»“æœæ­ç¤ºäº†åœ¨è¯¥é¢†åŸŸå­¦ä¹ è¯­è¨€æ—¶å‡ºç°çš„ç‰¹å®šå¤±è´¥æ¨¡å¼ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æœºæ¢°è®¾è®¡é¢†åŸŸçš„åº”ç”¨æ•ˆæœä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†é¢†åŸŸç‰¹å®šè¯­è¨€æ—¶ï¼Œå¾€å¾€æ— æ³•æœ‰æ•ˆæ•æ‰è¯­ä¹‰ä¿¡æ¯ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸ç†æƒ³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ— ç›‘ç£å­¦ä¹ ä»»åŠ¡æ¥è¯„ä¼°å’Œä¼˜åŒ–å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æœºæ¢°å·¥ç¨‹é¢†åŸŸçš„è¡¨ç°ã€‚é€šè¿‡è®¾è®¡äºŒå…ƒå¥å­å¯¹åˆ†ç±»å’Œé›¶æ ·æœ¬åˆ†ç±»ä»»åŠ¡ï¼Œç ”ç©¶è€…èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸæ•°æ®ä¸Šçš„å­¦ä¹ èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚é¦–å…ˆï¼Œå¯¹ABCæ•°æ®é›†è¿›è¡Œæ¸…æ´—å’Œæ ¼å¼åŒ–ï¼Œç„¶åä½¿ç”¨ä¸åŒçš„æ¨¡å‹æ¶æ„è¿›è¡Œè®­ç»ƒï¼Œæœ€åé€šè¿‡è®¾å®šçš„æ— ç›‘ç£ä»»åŠ¡è¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºé€šè¿‡æ— ç›‘ç£å­¦ä¹ ä»»åŠ¡è¯„ä¼°æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸçš„è¡¨ç°ï¼Œå¹¶é’ˆå¯¹è¿‡æ‹Ÿåˆè¿›è¡Œä¼˜åŒ–ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæœ¬ç ”ç©¶æä¾›äº†æ›´å…·é’ˆå¯¹æ€§çš„è¯„ä¼°æ–¹å¼ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œç ”ç©¶è€…è°ƒæ•´äº†å­¦ä¹ ç‡ã€ä¸¢å¼ƒç‡ã€åºåˆ—é•¿åº¦ï¼Œå¹¶å¢åŠ äº†å¤šå¤´æ³¨æ„åŠ›å±‚ï¼Œä»¥åº”å¯¹è¿‡æ‹Ÿåˆé—®é¢˜ã€‚è¿™äº›è®¾è®¡ä½¿å¾—æ¨¡å‹åœ¨äºŒå…ƒå¥å­å¯¹åˆ†ç±»ä»»åŠ¡ä¸­è¾¾åˆ°äº†0.62çš„å‡†ç¡®ç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼Œæ¨¡å‹åœ¨äºŒå…ƒå¥å­å¯¹åˆ†ç±»ä»»åŠ¡ä¸­å–å¾—äº†0.62çš„å‡†ç¡®ç‡ï¼Œè€Œåœ¨é›¶æ ·æœ¬åˆ†ç±»ä»»åŠ¡ä¸­è¾¾åˆ°äº†0.386çš„é¡¶çº§åˆ†ç±»å‡†ç¡®ç‡ï¼Œæ˜¾è‘—è¶…è¶Šäº†åŸºçº¿ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œç»è¿‡ä¼˜åŒ–çš„æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸçš„è¯­è¨€ç†è§£èƒ½åŠ›æœ‰äº†æ˜¾è‘—æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºæ¢°è®¾è®¡è‡ªåŠ¨åŒ–ã€æ™ºèƒ½åˆ¶é€ å’Œå·¥ç¨‹æ•™è‚²ç­‰ã€‚é€šè¿‡æå‡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æœºæ¢°è®¾è®¡é¢†åŸŸçš„è¡¨ç°ï¼Œå¯ä»¥ä¸ºè®¾è®¡å¸ˆæä¾›æ›´æ™ºèƒ½çš„è¾…åŠ©å·¥å…·ï¼Œæå‡è®¾è®¡æ•ˆç‡å’Œå‡†ç¡®æ€§ï¼Œæ¨åŠ¨è¡Œä¸šçš„æ•°å­—åŒ–è½¬å‹ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In this work, we seek to understand the performance of large language models in the mechanical engineering domain. We leverage the semantic data found in the ABC dataset, specifically the assembly names that designers assigned to the overall assemblies, and the individual semantic part names that were assigned to each part. After pre-processing the data we developed two unsupervised tasks to evaluate how different model architectures perform on domain-specific data: a binary sentence-pair classification task and a zero-shot classification task. We achieved a 0.62 accuracy for the binary sentence-pair classification task with a fine-tuned model that focuses on fighting over-fitting: 1) modifying learning rates, 2) dropout values, 3) Sequence Length, and 4) adding a multi-head attention layer. Our model on the zero-shot classification task outperforms the baselines by a wide margin, and achieves a top-1 classification accuracy of 0.386. The results shed some light on the specific failure modes that arise when learning from language in this domain.

