---
layout: default
title: DISCO Balances the Scales: Adaptive Domain- and Difficulty-Aware Reinforcement Learning on Imbalanced Data
---

# DISCO Balances the Scales: Adaptive Domain- and Difficulty-Aware Reinforcement Learning on Imbalanced Data

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.15074" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.15074v3</a>
  <a href="https://arxiv.org/pdf/2505.15074.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.15074v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.15074v3', 'DISCO Balances the Scales: Adaptive Domain- and Difficulty-Aware Reinforcement Learning on Imbalanced Data')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Yuhang Zhou, Jing Zhu, Shengyi Qian, Zhuokai Zhao, Xiyao Wang, Xiaoyu Liu, Ming Li, Paiheng Xu, Wei Ai, Furong Huang

**ÂàÜÁ±ª**: cs.CL, cs.AI, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-21 (Êõ¥Êñ∞: 2025-09-24)

**Â§áÊ≥®**: Accepted by EMNLP 2025 Findings

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/Tonyzhou98/disco_grpo)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫DISCO‰ª•Ëß£ÂÜ≥‰∏çÂπ≥Ë°°Êï∞ÊçÆ‰∏ãÁöÑÂº∫ÂåñÂ≠¶‰π†ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Âº∫ÂåñÂ≠¶‰π†` `‰∏çÂπ≥Ë°°Êï∞ÊçÆ` `Â§öÂüüÂ≠¶‰π†` `Â•ñÂä±Êú∫Âà∂` `ËØ≠Ë®ÄÊ®°Âûã` `ÂÖ¨Âπ≥ÊÄß` `Ê≥õÂåñËÉΩÂäõ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑGRPOÊñπÊ≥ïÂú®Â§ÑÁêÜÂ§öÂüü‰∏çÂπ≥Ë°°Êï∞ÊçÆÊó∂ÔºåÂÆπÊòì‰ºòÂåñ‰∏ªÂØºÂüüÔºåÂøΩËßÜÂº±ÂäøÂüüÔºåÂØºËá¥Ê≥õÂåñËÉΩÂäõÂíåÂÖ¨Âπ≥ÊÄß‰∏çË∂≥„ÄÇ
2. DISCOÈÄöËøáÂüüÊÑüÁü•Â•ñÂä±Áº©ÊîæÂíåÈöæÂ∫¶ÊÑüÁü•Â•ñÂä±Áº©ÊîæÔºåÈíàÂØπ‰∏çÂêåÂüüÁöÑÈ¢ëÁéáÂíå‰∏çÁ°ÆÂÆöÊÄßËøõË°å‰ºòÂåñÔºåÊèêÂçáÂ≠¶‰π†ÊïàÊûú„ÄÇ
3. DISCOÂú®Â§ö‰∏™LLM‰∏äËøõË°åÂπøÊ≥õÂÆûÈ™åÔºåËæÉÁé∞ÊúâGRPOÂèò‰ΩìÊèêÂçá5%ÔºåÂπ∂Âú®Â§öÂüüÂØπÈΩêÂü∫ÂáÜ‰∏äÂèñÂæó‰∫ÜÊñ∞ÁöÑÊúÄ‰ºòÁªìÊûú„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÈÄöËøá‰∫∫Á±ªÂèçÈ¶àÂº∫ÂåñÂ≠¶‰π†ÔºàRLHFÔºâÈÄêÊ∏ê‰∏é‰∫∫Á±ªÂÅèÂ•ΩÂØπÈΩê„ÄÇÁé∞ÊúâÁöÑÁæ§‰ΩìÁõ∏ÂØπÁ≠ñÁï•‰ºòÂåñÔºàGRPOÔºâÊñπÊ≥ïÂú®Â§ÑÁêÜÂ§öÂüü‰∏çÂπ≥Ë°°Êï∞ÊçÆÊó∂ÔºåÂÆπÊòì‰ºòÂåñ‰∏ªÂØºÂüüËÄåÂøΩËßÜÂº±ÂäøÂüüÔºåÂØºËá¥Ê≥õÂåñËÉΩÂäõÂíåÂÖ¨Âπ≥ÊÄß‰∏çË∂≥„ÄÇ‰∏∫Ê≠§ÔºåÊú¨ÊñáÊèêÂá∫‰∫ÜÂüü‰ø°ÊÅØËá™‰∏ÄËá¥ÊÄßÁ≠ñÁï•‰ºòÂåñÔºàDISCOÔºâÔºåÈÄöËøáÂüüÊÑüÁü•Â•ñÂä±Áº©ÊîæÂíåÈöæÂ∫¶ÊÑüÁü•Â•ñÂä±Áº©Êîæ‰∏§Â§ßÂàõÊñ∞ÔºåÂπ≥Ë°°‰∏çÂêåÂüüÈó¥ÁöÑ‰ºòÂåñÔºå‰øÉËøõÊõ¥ÂÖ¨Âπ≥ÊúâÊïàÁöÑÁ≠ñÁï•Â≠¶‰π†„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåDISCOÂú®Â§ö‰∏™LLMÂíåÂÅèÊñúËÆ≠ÁªÉÂàÜÂ∏É‰∏äÂùáË°®Áé∞‰ºòÂºÇÔºåËæÉÁé∞ÊúâGRPOÂèò‰ΩìÊèêÂçá5%ÔºåÂπ∂Âú®Â§öÂüüÂØπÈΩêÂü∫ÂáÜ‰∏äÂàõ‰∏ãÊñ∞Á∫™ÂΩï„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥GRPOÂú®Â§öÂüü‰∏çÂπ≥Ë°°Êï∞ÊçÆ‰∏ãÁöÑ‰ºòÂåñÂÅèÂ∑ÆÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂÅáËÆæÂüüÂàÜÂ∏ÉÂùáË°°ÔºåÂØºËá¥Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠Êó†Ê≥ïÊúâÊïàÂ§ÑÁêÜÂº±ÂäøÂüü„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöDISCOÈÄöËøáÂºïÂÖ•ÂüüÊÑüÁü•ÂíåÈöæÂ∫¶ÊÑüÁü•ÁöÑÂ•ñÂä±Áº©ÊîæÊú∫Âà∂ÔºåÊó®Âú®Âπ≥Ë°°‰∏çÂêåÂüüÁöÑ‰ºòÂåñËøáÁ®ãÔºåÁ°Æ‰øùÂº±ÂäøÂüü‰πüËÉΩÂæóÂà∞Ë∂≥Â§üÁöÑÂÖ≥Ê≥®ÂíåÂ≠¶‰π†„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöDISCOÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏§‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÂüüÊÑüÁü•Â•ñÂä±Áº©ÊîæÂíåÈöæÂ∫¶ÊÑüÁü•Â•ñÂä±Áº©Êîæ„ÄÇÂâçËÄÖÊ†πÊçÆÂüüÁöÑÂá∫Áé∞È¢ëÁéáË∞ÉÊï¥‰ºòÂåñÊùÉÈáçÔºåÂêéËÄÖÂàôÈÄöËøáËá™‰∏ÄËá¥ÊÄßËØÑ‰º∞ËØÜÂà´Âíå‰ºòÂÖàÂ§ÑÁêÜ‰∏çÁ°ÆÂÆöÁöÑÊèêÁ§∫„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöDISCOÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÂÖ∂Â•ñÂä±Áº©ÊîæÊú∫Âà∂ÔºåËÉΩÂ§üÊúâÊïàÂ∫îÂØπÊï∞ÊçÆ‰∏çÂπ≥Ë°°ÈóÆÈ¢òÔºå‰∏é‰º†ÁªüGRPOÊñπÊ≥ïÁõ∏ÊØîÔºåÊòæËëóÊèêÂçá‰∫ÜÂØπÂº±ÂäøÂüüÁöÑÂ≠¶‰π†ËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÂèÇÊï∞ËÆæÁΩÆ‰∏äÔºåDISCOÈááÁî®Âä®ÊÄÅË∞ÉÊï¥ÁöÑÂ•ñÂä±ÊùÉÈáçÔºåÊçüÂ§±ÂáΩÊï∞ËÆæËÆ°‰∏äÁªìÂêà‰∫ÜÂüüÈ¢ëÁéáÂíåÊèêÁ§∫‰∏çÁ°ÆÂÆöÊÄßÔºåÁ°Æ‰øùÊ®°ÂûãÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠ËÉΩÂ§üËá™ÈÄÇÂ∫îÂú∞‰ºòÂåñ‰∏çÂêåÂüüÁöÑÁ≠ñÁï•„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

DISCOÂú®Â§ö‰∏™Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã‰∏äËøõË°å‰∫ÜÂπøÊ≥õÁöÑÂÆûÈ™åÔºåÁªìÊûúÊòæÁ§∫ÂÖ∂Âú®Â§ÑÁêÜÂÅèÊñúËÆ≠ÁªÉÂàÜÂ∏ÉÊó∂ÔºåËæÉÁé∞ÊúâGRPOÂèò‰ΩìÊèêÂçá‰∫Ü5%ÁöÑÊÄßËÉΩÔºåÂπ∂Âú®Â§öÂüüÂØπÈΩêÂü∫ÂáÜ‰∏äÂàõ‰∏ã‰∫ÜÊñ∞ÁöÑÊúÄ‰ºòÁªìÊûúÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÊúâÊïàÊÄßÂíå‰ºòÂäø„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

DISCOÁöÑÁ†îÁ©∂ÊàêÊûúÂú®Â§öÈ¢ÜÂüüÁöÑËØ≠Ë®ÄÊ®°ÂûãËÆ≠ÁªÉ‰∏≠ÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõÔºåÁâπÂà´ÊòØÂú®ÈúÄË¶ÅÂ§ÑÁêÜ‰∏çÂπ≥Ë°°Êï∞ÊçÆÁöÑÂú∫ÊôØÔºåÂ¶ÇÁ§æ‰∫§Â™í‰ΩìÂàÜÊûê„ÄÅÂú®Á∫øÊé®ËçêÁ≥ªÁªüÂíåÂ§öËØ≠Ë®ÄÁøªËØëÁ≠â„ÄÇÂÖ∂ÂÖ¨Âπ≥ÊÄßÂíåÊ≥õÂåñËÉΩÂäõÁöÑÊèêÂçáÂ∞ÜÂØπÂÆûÈôÖÂ∫îÁî®‰∫ßÁîüÁßØÊûÅÂΩ±ÂìçÔºåÊé®Âä®Áõ∏ÂÖ≥È¢ÜÂüüÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Large Language Models (LLMs) are increasingly aligned with human preferences through Reinforcement Learning from Human Feedback (RLHF). Among RLHF methods, Group Relative Policy Optimization (GRPO) has gained attention for its simplicity and strong performance, notably eliminating the need for a learned value function. However, GRPO implicitly assumes a balanced domain distribution and uniform semantic alignment across groups, assumptions that rarely hold in real-world datasets. When applied to multi-domain, imbalanced data, GRPO disproportionately optimizes for dominant domains, neglecting underrepresented ones and resulting in poor generalization and fairness. We propose Domain-Informed Self-Consistency Policy Optimization (DISCO), a principled extension to GRPO that addresses inter-group imbalance with two key innovations. Domain-aware reward scaling counteracts frequency bias by reweighting optimization based on domain prevalence. Difficulty-aware reward scaling leverages prompt-level self-consistency to identify and prioritize uncertain prompts that offer greater learning value. Together, these strategies promote more equitable and effective policy learning across domains. Extensive experiments across multiple LLMs and skewed training distributions show that DISCO improves generalization, outperforms existing GRPO variants by 5% on Qwen3 models, and sets new state-of-the-art results on multi-domain alignment benchmarks. Our code and data are available at https://github.com/Tonyzhou98/disco_grpo.

