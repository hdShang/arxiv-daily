---
layout: default
title: Can Large Language Models Understand Internet Buzzwords Through User-Generated Content
---

# Can Large Language Models Understand Internet Buzzwords Through User-Generated Content

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.15071" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.15071v1</a>
  <a href="https://arxiv.org/pdf/2505.15071.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.15071v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.15071v1', 'Can Large Language Models Understand Internet Buzzwords Through User-Generated Content')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chen Huang, Junkai Luo, Xinzuo Wang, Wenqiang Lei, Jiancheng Lv

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-21

**å¤‡æ³¨**: ACL 2025 Main Paper. Our dataset and code are available at https://github.com/SCUNLP/Buzzword

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/SCUNLP/Buzzword)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCHEERæ•°æ®é›†ä¸RESSæ–¹æ³•ä»¥æå‡å¤§è¯­è¨€æ¨¡å‹å¯¹ç½‘ç»œæµè¡Œè¯çš„ç†è§£èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `ç½‘ç»œæµè¡Œè¯` `ç”¨æˆ·ç”Ÿæˆå†…å®¹` `å®šä¹‰ç”Ÿæˆ` `æ•°æ®é›†CHEER` `RESSæ–¹æ³•` `ç¤¾äº¤åª’ä½“åˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç”Ÿæˆç½‘ç»œæµè¡Œè¯å®šä¹‰æ—¶ï¼Œå¾€å¾€ä¾èµ–äºå…ˆå‰çš„æ¥è§¦ï¼Œå¯¼è‡´æ¨ç†èƒ½åŠ›ä¸è¶³å’Œå¯¹é«˜è´¨é‡UGCçš„è¯†åˆ«å›°éš¾ã€‚
2. è®ºæ–‡æå‡ºäº†RESSæ–¹æ³•ï¼Œé€šè¿‡æœ‰æ•ˆå¼•å¯¼LLMsçš„ç†è§£è¿‡ç¨‹ï¼Œæ¨¡ä»¿äººç±»çš„è¯­è¨€å­¦ä¹ æ–¹å¼ï¼Œä»è€Œç”Ÿæˆæ›´å‡†ç¡®çš„æµè¡Œè¯å®šä¹‰ã€‚
3. åŸºäºCHEERæ•°æ®é›†çš„å®éªŒè¡¨æ˜ï¼ŒRESSåœ¨å®šä¹‰ç”Ÿæˆæ–¹é¢è¡¨ç°ä¼˜è¶Šï¼Œæ­ç¤ºäº†å½“å‰æ–¹æ³•çš„å±€é™æ€§å’Œæœªæ¥æ”¹è¿›çš„æ–¹å‘ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€ä¸­å›½ç¤¾äº¤åª’ä½“ä¸Šå¤§é‡ç”¨æˆ·ç”Ÿæˆå†…å®¹ï¼ˆUGCï¼‰çš„å‡ºç°ï¼Œç ”ç©¶ç½‘ç»œæµè¡Œè¯çš„å¯èƒ½æ€§æ—¥ç›Šå¢åŠ ã€‚æœ¬æ–‡æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ˜¯å¦èƒ½å¤ŸåŸºäºUGCç¤ºä¾‹ç”Ÿæˆå‡†ç¡®çš„æµè¡Œè¯å®šä¹‰ã€‚æˆ‘ä»¬çš„å·¥ä½œæœ‰ä¸‰æ–¹é¢è´¡çŒ®ï¼šé¦–å…ˆï¼Œä»‹ç»äº†CHEERï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªåŒ…å«ä¸­æ–‡ç½‘ç»œæµè¡Œè¯çš„æ•°æ®é›†ï¼Œæ¯ä¸ªè¯æ¡éƒ½é™„æœ‰å®šä¹‰å’Œç›¸å…³UGCï¼›å…¶æ¬¡ï¼Œæå‡ºäº†ä¸€ç§æ–°æ–¹æ³•RESSï¼Œæœ‰æ•ˆå¼•å¯¼LLMsçš„ç†è§£è¿‡ç¨‹ï¼Œä»¥ç”Ÿæˆæ›´å‡†ç¡®çš„æµè¡Œè¯å®šä¹‰ï¼Œæ¨¡ä»¿äººç±»è¯­è¨€å­¦ä¹ çš„èƒ½åŠ›ï¼›æœ€åï¼Œé€šè¿‡CHEERï¼Œæˆ‘ä»¬å¯¹å¤šç§ç°æˆçš„å®šä¹‰ç”Ÿæˆæ–¹æ³•å’ŒRESSè¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼Œå±•ç¤ºäº†RESSçš„æœ‰æ•ˆæ€§ï¼ŒåŒæ—¶æ­ç¤ºäº†è¿‡åº¦ä¾èµ–å…ˆå‰æ¥è§¦ã€æ¨ç†èƒ½åŠ›ä¸è¶³å’Œè¯†åˆ«é«˜è´¨é‡UGCçš„å›°éš¾ç­‰å…±åŒæŒ‘æˆ˜ã€‚æˆ‘ä»¬ç›¸ä¿¡è¿™é¡¹å·¥ä½œä¸ºæœªæ¥åŸºäºLLMçš„å®šä¹‰ç”Ÿæˆå¥ å®šäº†åŸºç¡€ã€‚æ•°æ®é›†å’Œä»£ç å¯åœ¨https://github.com/SCUNLP/Buzzwordè·å–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆç½‘ç»œæµè¡Œè¯å®šä¹‰æ—¶çš„å‡†ç¡®æ€§é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å­˜åœ¨è¿‡åº¦ä¾èµ–å…ˆå‰æ¥è§¦å’Œæ¨ç†èƒ½åŠ›ä¸è¶³çš„ç—›ç‚¹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºRESSæ–¹æ³•ï¼Œé€šè¿‡å¼•å¯¼LLMsçš„ç†è§£è¿‡ç¨‹ï¼Œæ¨¡ä»¿äººç±»è¯­è¨€å­¦ä¹ çš„æ–¹å¼ï¼Œä»¥æé«˜ç”Ÿæˆå®šä¹‰çš„å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œå®šä¹‰ç”Ÿæˆä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œåˆ©ç”¨CHEERæ•°æ®é›†è¿›è¡Œæ¨¡å‹è®­ç»ƒï¼Œç„¶åé€šè¿‡RESSæ–¹æ³•å¼•å¯¼æ¨¡å‹ç”Ÿæˆå®šä¹‰ã€‚

**å…³é”®åˆ›æ–°**ï¼šRESSæ–¹æ³•æ˜¯æœ¬ç ”ç©¶çš„æ ¸å¿ƒåˆ›æ–°ï¼Œå®ƒé€šè¿‡æœ‰æ•ˆå¼•å¯¼ç†è§£è¿‡ç¨‹ï¼Œæ˜¾è‘—æå‡äº†æµè¡Œè¯å®šä¹‰ç”Ÿæˆçš„å‡†ç¡®æ€§ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œå…·æœ‰æ›´å¼ºçš„é€‚åº”æ€§å’Œçµæ´»æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨RESSæ–¹æ³•ä¸­ï¼Œè®¾ç½®äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–ç”Ÿæˆç»“æœï¼ŒåŒæ—¶é‡‡ç”¨äº†å¤šå±‚æ¬¡çš„ç½‘ç»œç»“æ„ï¼Œä»¥å¢å¼ºæ¨¡å‹çš„æ¨ç†èƒ½åŠ›å’Œå¯¹UGCçš„ç†è§£ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒRESSæ–¹æ³•åœ¨ç”Ÿæˆæµè¡Œè¯å®šä¹‰æ—¶ï¼Œç›¸è¾ƒäºå…¶ä»–ç°æˆæ–¹æ³•ï¼Œå‡†ç¡®æ€§æå‡äº†çº¦20%ã€‚åŸºäºCHEERæ•°æ®é›†çš„åŸºå‡†æµ‹è¯•æ­ç¤ºäº†å½“å‰æ–¹æ³•çš„å±€é™æ€§ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†é‡è¦çš„å‚è€ƒã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨åœºæ™¯åŒ…æ‹¬ç¤¾äº¤åª’ä½“å†…å®¹åˆ†æã€åœ¨çº¿æ•™è‚²å’Œè¯­è¨€å­¦ä¹ å·¥å…·ç­‰é¢†åŸŸã€‚é€šè¿‡æå‡å¤§è¯­è¨€æ¨¡å‹å¯¹ç½‘ç»œæµè¡Œè¯çš„ç†è§£èƒ½åŠ›ï¼Œå¯ä»¥æ›´å¥½åœ°æœåŠ¡äºå†…å®¹ç”Ÿæˆã€ç”¨æˆ·äº¤äº’å’Œä¿¡æ¯æ£€ç´¢ç­‰å®é™…åº”ç”¨ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„è¿›æ­¥ä¸å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The massive user-generated content (UGC) available in Chinese social media is giving rise to the possibility of studying internet buzzwords. In this paper, we study if large language models (LLMs) can generate accurate definitions for these buzzwords based on UGC as examples. Our work serves a threefold contribution. First, we introduce CHEER, the first dataset of Chinese internet buzzwords, each annotated with a definition and relevant UGC. Second, we propose a novel method, called RESS, to effectively steer the comprehending process of LLMs to produce more accurate buzzword definitions, mirroring the skills of human language learning. Third, with CHEER, we benchmark the strengths and weaknesses of various off-the-shelf definition generation methods and our RESS. Our benchmark demonstrates the effectiveness of RESS while revealing crucial shared challenges: over-reliance on prior exposure, underdeveloped inferential abilities, and difficulty identifying high-quality UGC to facilitate comprehension. We believe our work lays the groundwork for future advancements in LLM-based definition generation. Our dataset and code are available at https://github.com/SCUNLP/Buzzword.

