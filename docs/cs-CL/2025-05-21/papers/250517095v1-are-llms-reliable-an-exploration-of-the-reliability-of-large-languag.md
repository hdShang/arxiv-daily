---
layout: default
title: Are LLMs reliable? An exploration of the reliability of large language models in clinical note generation
---

# Are LLMs reliable? An exploration of the reliability of large language models in clinical note generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.17095" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.17095v1</a>
  <a href="https://arxiv.org/pdf/2505.17095.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.17095v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.17095v1', 'Are LLMs reliable? An exploration of the reliability of large language models in clinical note generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kristine Ann M. Carandang, Jasper Meynard P. AraÃ±a, Ethan Robert A. Casin, Christopher P. Monterola, Daniel Stanley Y. Tan, Jesus Felix B. Valenzuela, Christian M. Alis

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-21

**DOI**: [10.18653/v1/2025.acl-industry.99](https://doi.org/10.18653/v1/2025.acl-industry.99)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¸´åºŠç¬”è®°ç”Ÿæˆä¸­çš„å¯é æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ä¸´åºŠç¬”è®°ç”Ÿæˆ` `æ•°æ®éšç§` `è¯­ä¹‰ä¸€è‡´æ€§` `åŒ»ç–—æ–‡æ¡£è‡ªåŠ¨åŒ–` `æ¨¡å‹è¯„ä¼°` `äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—ä¸­çš„åº”ç”¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ä¸´åºŠç¬”è®°ç”Ÿæˆç³»ç»Ÿé¢ä¸´LLMså“åº”çš„è‡ªç„¶å˜å¼‚æ€§ï¼Œå½±å“åŒ»ç–—æœåŠ¡æä¾›è€…çš„ä¿¡ä»»å’Œä½¿ç”¨ã€‚
2. æœ¬ç ”ç©¶é€šè¿‡è¯„ä¼°å¤šç§LLMsåœ¨ç”Ÿæˆä¸´åºŠç¬”è®°æ—¶çš„ä¸€è‡´æ€§å’Œå‡†ç¡®æ€§ï¼Œæ—¨åœ¨å¢å¼ºåŒ»ç–—æœåŠ¡æä¾›è€…å¯¹è¿™äº›å·¥å…·çš„ä¿¡å¿ƒã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æœ‰è¯„ä¼°çš„LLMsåœ¨è¯­ä¹‰ä¸€è‡´æ€§ä¸Šè¡¨ç°ç¨³å®šï¼ŒMetaçš„Llama 70Bæ¨¡å‹åœ¨å¯é æ€§ä¸Šè¡¨ç°æœ€ä½³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç”±äºåŒ»ç–—æœåŠ¡æä¾›è€…åœ¨å‡†ç¡®æ–‡æ¡£è®°å½•å’Œä¿æŠ¤æ‚£è€…æ•°æ®éšç§æ–¹é¢çš„æ³•å¾‹å’Œä¼¦ç†è´£ä»»ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä¸´åºŠç¬”è®°ç”Ÿæˆï¼ˆCNGï¼‰ä¸­çš„è‡ªç„¶å˜å¼‚æ€§ç»™å®é™…åº”ç”¨å¸¦æ¥äº†æŒ‘æˆ˜ã€‚æœ¬æ–‡è¯„ä¼°äº†æ¥è‡ªAnthropicã€Metaã€Mistralå’ŒOpenAIçš„12ä¸ªå¼€æºå’Œä¸“æœ‰LLMsåœ¨CNGä¸­çš„å¯é æ€§ï¼Œé‡ç‚¹åˆ†æå…¶ç”Ÿæˆçš„ç¬”è®°åœ¨ä¸€è‡´æ€§ã€è¯­ä¹‰ä¸€è‡´æ€§å’Œè¯­ä¹‰ç›¸ä¼¼æ€§æ–¹é¢çš„è¡¨ç°ã€‚ç»“æœè¡¨æ˜ï¼Œæ‰€æœ‰æ¨¡å‹å®¶æ—çš„LLMsåœ¨è¯­ä¹‰ä¸Šä¿æŒä¸€è‡´ï¼Œä¸”å¤§å¤šæ•°ç”Ÿæˆçš„ç¬”è®°æ¥è¿‘ä¸“å®¶çš„è®°å½•ã€‚Metaçš„Llama 70Bæ¨¡å‹è¡¨ç°æœ€ä¸ºå¯é ï¼Œå»ºè®®åœ¨CNGä¸­æœ¬åœ°éƒ¨ç½²è¿™äº›ç›¸å¯¹è¾ƒå°çš„å¼€æºæ¨¡å‹ï¼Œä»¥ç¡®ä¿æ•°æ®éšç§åˆè§„å¹¶æé«˜åŒ»ç–—æœåŠ¡æä¾›è€…çš„æ–‡æ¡£æ•ˆç‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¸´åºŠç¬”è®°ç”Ÿæˆä¸­çš„å¯é æ€§é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨ç”Ÿæˆä¸€è‡´æ€§å’Œå‡†ç¡®æ€§æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¯¹12ä¸ªä¸åŒçš„LLMsè¿›è¡Œè¯„ä¼°ï¼Œåˆ†æå…¶åœ¨ç”Ÿæˆä¸´åºŠç¬”è®°æ—¶çš„ä¸€è‡´æ€§ã€è¯­ä¹‰ä¸€è‡´æ€§å’Œè¯­ä¹‰ç›¸ä¼¼æ€§ï¼Œä»¥å¢å¼ºåŒ»ç–—æœåŠ¡æä¾›è€…çš„ä¿¡ä»»ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶è®¾è®¡åŒ…æ‹¬å¯¹å„æ¨¡å‹åœ¨ç›¸åŒæç¤ºä¸‹ç”Ÿæˆå¤šæ¬¡ç¬”è®°çš„å®éªŒï¼Œæ¯”è¾ƒå…¶ç”Ÿæˆç»“æœçš„ç¨³å®šæ€§å’Œå‡†ç¡®æ€§ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ¨¡å‹é€‰æ‹©ã€ç”Ÿæˆç¬”è®°ã€ç»“æœè¯„ä¼°å’Œæ•°æ®åˆ†æã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºç³»ç»Ÿæ€§åœ°è¯„ä¼°å¤šç§LLMsåœ¨ä¸´åºŠç¬”è®°ç”Ÿæˆä¸­çš„è¡¨ç°ï¼Œæä¾›äº†å¯¹æ¯”åˆ†æå’Œå®è¯æ•°æ®ï¼Œå¡«è¡¥äº†è¯¥é¢†åŸŸçš„ç ”ç©¶ç©ºç™½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œä½¿ç”¨äº†å¤šç§è¯„ä¼°æŒ‡æ ‡ï¼Œå¦‚ä¸€è‡´æ€§ç‡ã€è¯­ä¹‰ä¸€è‡´æ€§å’Œè¯­ä¹‰ç›¸ä¼¼æ€§ï¼Œç¡®ä¿äº†è¯„ä¼°ç»“æœçš„å…¨é¢æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æœ‰è¯„ä¼°çš„LLMsåœ¨è¯­ä¹‰ä¸€è‡´æ€§ä¸Šè¡¨ç°ç¨³å®šï¼ŒMetaçš„Llama 70Bæ¨¡å‹çš„å¯é æ€§æœ€é«˜ï¼Œç”Ÿæˆçš„ç¬”è®°ä¸ä¸“å®¶è®°å½•çš„ç›¸ä¼¼åº¦æ˜¾è‘—æé«˜ã€‚è¿™äº›å‘ç°ä¸ºä¸´åºŠç¬”è®°ç”Ÿæˆæä¾›äº†å®è¯æ”¯æŒï¼Œå»ºè®®ä½¿ç”¨è¾ƒå°çš„å¼€æºæ¨¡å‹ä»¥ç¡®ä¿æ•°æ®éšç§åˆè§„ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŒ»ç–—æ–‡æ¡£è‡ªåŠ¨åŒ–ã€ç”µå­å¥åº·è®°å½•ç³»ç»Ÿçš„é›†æˆä»¥åŠä¸´åºŠå†³ç­–æ”¯æŒå·¥å…·çš„å¼€å‘ã€‚é€šè¿‡æé«˜LLMsåœ¨ä¸´åºŠç¬”è®°ç”Ÿæˆä¸­çš„å¯é æ€§ï¼Œå¯ä»¥æœ‰æ•ˆæå‡åŒ»ç–—æœåŠ¡æä¾›è€…çš„å·¥ä½œæ•ˆç‡ï¼Œç¡®ä¿æ‚£è€…æ•°æ®çš„éšç§å’Œå®‰å…¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Due to the legal and ethical responsibilities of healthcare providers (HCPs) for accurate documentation and protection of patient data privacy, the natural variability in the responses of large language models (LLMs) presents challenges for incorporating clinical note generation (CNG) systems, driven by LLMs, into real-world clinical processes. The complexity is further amplified by the detailed nature of texts in CNG. To enhance the confidence of HCPs in tools powered by LLMs, this study evaluates the reliability of 12 open-weight and proprietary LLMs from Anthropic, Meta, Mistral, and OpenAI in CNG in terms of their ability to generate notes that are string equivalent (consistency rate), have the same meaning (semantic consistency) and are correct (semantic similarity), across several iterations using the same prompt. The results show that (1) LLMs from all model families are stable, such that their responses are semantically consistent despite being written in various ways, and (2) most of the LLMs generated notes close to the corresponding notes made by experts. Overall, Meta's Llama 70B was the most reliable, followed by Mistral's Small model. With these findings, we recommend the local deployment of these relatively smaller open-weight models for CNG to ensure compliance with data privacy regulations, as well as to improve the efficiency of HCPs in clinical documentation.

