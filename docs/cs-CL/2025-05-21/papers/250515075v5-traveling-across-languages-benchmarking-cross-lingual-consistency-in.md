---
layout: default
title: Traveling Across Languages: Benchmarking Cross-Lingual Consistency in Multimodal LLMs
---

# Traveling Across Languages: Benchmarking Cross-Lingual Consistency in Multimodal LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.15075" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.15075v5</a>
  <a href="https://arxiv.org/pdf/2505.15075.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.15075v5" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.15075v5', 'Traveling Across Languages: Benchmarking Cross-Lingual Consistency in Multimodal LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hao Wang, Pinzhi Huang, Jihan Yang, Saining Xie, Daisuke Kawahara

**åˆ†ç±»**: cs.CL, cs.AI, cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-21 (æ›´æ–°: 2025-08-24)

**å¤‡æ³¨**: The first version of this paper mistakenly included a prompt injection phrase, which was inappropriate and unprofessional. Although we corrected the version on arXiv and withdrew from the conference, my co-authors and university strongly request a full withdrawal. Given the situation, I no longer have the authority to manage this paper, and withdrawing it from arXiv is the most responsible action

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºKnowRecallå’ŒVisRecallåŸºå‡†ä»¥è§£å†³å¤šè¯­è¨€ä¸€è‡´æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹` `è·¨è¯­è¨€ä¸€è‡´æ€§` `æ–‡åŒ–çŸ¥è¯†` `è§†è§‰è®°å¿†` `åŸºå‡†æµ‹è¯•`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è·¨è¯­è¨€ä¸€è‡´æ€§æ–¹é¢è¡¨ç°ä¸ä½³ï¼Œå°¤å…¶æ˜¯åœ¨æ–‡åŒ–çŸ¥è¯†çš„æ•´åˆä¸Šå­˜åœ¨æ˜¾è‘—æŒ‘æˆ˜ã€‚
2. æœ¬æ–‡æå‡ºKnowRecallå’ŒVisRecallä¸¤ä¸ªåŸºå‡†ï¼Œæ—¨åœ¨ç³»ç»Ÿæ€§è¯„ä¼°å¤šè¯­è¨€æ¨¡å‹åœ¨æ–‡åŒ–å’Œè§†è§‰è®°å¿†æ–¹é¢çš„ä¸€è‡´æ€§è¡¨ç°ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå½“å‰çš„æœ€å…ˆè¿›æ¨¡å‹åœ¨è·¨è¯­è¨€ä¸€è‡´æ€§ä¸Šä»æœ‰æ˜æ˜¾ä¸è¶³ï¼ŒäºŸéœ€æ›´å¼ºçš„æ¨¡å‹è®¾è®¡ä»¥æå‡å¤šè¯­è¨€èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„å¿«é€Ÿå‘å±•æ˜¾è‘—æå‡äº†å…¶åœ¨ç°å®ä¸–ç•Œä¸­çš„åº”ç”¨ã€‚ç„¶è€Œï¼Œè·¨è¯­è¨€çš„ä¸€è‡´æ€§è¡¨ç°ï¼Œå°¤å…¶æ˜¯åœ¨æ•´åˆæ–‡åŒ–çŸ¥è¯†æ—¶ï¼Œä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡å¼•å…¥äº†ä¸¤ä¸ªæ–°çš„åŸºå‡†ï¼šKnowRecallå’ŒVisRecallï¼Œæ—¨åœ¨è¯„ä¼°MLLMsçš„è·¨è¯­è¨€ä¸€è‡´æ€§ã€‚KnowRecallæ˜¯ä¸€ä¸ªè§†è§‰é—®ç­”åŸºå‡†ï¼Œä¸“æ³¨äº15ç§è¯­è¨€ä¸­å…³äºå…¨çƒåœ°æ ‡çš„æ–‡åŒ–å’Œå†å²é—®é¢˜çš„äº‹å®çŸ¥è¯†ä¸€è‡´æ€§ã€‚VisRecallåˆ™é€šè¿‡è¦æ±‚æ¨¡å‹åœ¨ä¸è®¿é—®å›¾åƒçš„æƒ…å†µä¸‹æè¿°9ç§è¯­è¨€ä¸­çš„åœ°æ ‡å¤–è§‚ï¼Œæ¥è¯„ä¼°è§†è§‰è®°å¿†ä¸€è‡´æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå½“å‰æœ€å…ˆè¿›çš„MLLMsï¼ŒåŒ…æ‹¬ä¸€äº›ä¸“æœ‰æ¨¡å‹ï¼Œä»ç„¶éš¾ä»¥å®ç°è·¨è¯­è¨€ä¸€è‡´æ€§ï¼Œè¿™çªæ˜¾äº†å¼€å‘çœŸæ­£å¤šè¯­è¨€å’Œæ–‡åŒ–æ•æ„Ÿæ¨¡å‹çš„å¿…è¦æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è·¨è¯­è¨€ä¸€è‡´æ€§æ–¹é¢çš„ä¸è¶³ï¼Œç‰¹åˆ«æ˜¯åœ¨æ–‡åŒ–çŸ¥è¯†æ•´åˆå’Œè§†è§‰è®°å¿†ä¸€è‡´æ€§ä¸Šå­˜åœ¨çš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆè¯„ä¼°æ¨¡å‹åœ¨ä¸åŒè¯­è¨€ä¸­çš„è¡¨ç°ä¸€è‡´æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸¤ä¸ªæ–°çš„åŸºå‡†KnowRecallå’ŒVisRecallï¼Œåˆ†åˆ«é’ˆå¯¹äº‹å®çŸ¥è¯†å’Œè§†è§‰è®°å¿†è¿›è¡Œè¯„ä¼°ï¼Œæ—¨åœ¨æä¾›æ›´å…¨é¢çš„è·¨è¯­è¨€ä¸€è‡´æ€§æµ‹è¯•æ¡†æ¶ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šKnowRecallé€šè¿‡è§†è§‰é—®ç­”çš„å½¢å¼ï¼Œè¯„ä¼°æ¨¡å‹åœ¨15ç§è¯­è¨€ä¸­å¯¹å…¨çƒåœ°æ ‡çš„æ–‡åŒ–å’Œå†å²é—®é¢˜çš„å›ç­”ä¸€è‡´æ€§ï¼›VisRecallåˆ™è¦æ±‚æ¨¡å‹åœ¨ä¸ä¾èµ–å›¾åƒçš„æƒ…å†µä¸‹ï¼Œç”¨9ç§è¯­è¨€æè¿°åœ°æ ‡å¤–è§‚ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†é’ˆå¯¹å¤šè¯­è¨€å’Œæ–‡åŒ–çŸ¥è¯†çš„ç³»ç»Ÿæ€§è¯„ä¼°åŸºå‡†ï¼Œå¡«è¡¥äº†ç°æœ‰ç ”ç©¶åœ¨è·¨è¯­è¨€ä¸€è‡´æ€§è¯„ä¼°ä¸­çš„ç©ºç™½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨KnowRecallä¸­ï¼Œè®¾è®¡äº†é’ˆå¯¹æ–‡åŒ–å’Œå†å²é—®é¢˜çš„é—®ç­”é›†ï¼›åœ¨VisRecallä¸­ï¼Œæ¨¡å‹éœ€åœ¨æ²¡æœ‰å›¾åƒçš„æƒ…å†µä¸‹è¿›è¡Œæè¿°ï¼Œè€ƒå¯Ÿå…¶è§†è§‰è®°å¿†çš„è·¨è¯­è¨€ä¸€è‡´æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå½“å‰çš„æœ€å…ˆè¿›å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨KnowRecallå’ŒVisRecallåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¸ä½³ï¼Œæœªèƒ½è¾¾åˆ°è·¨è¯­è¨€ä¸€è‡´æ€§ï¼Œæ˜¾ç¤ºå‡ºåœ¨æ–‡åŒ–çŸ¥è¯†æ•´åˆå’Œè§†è§‰è®°å¿†æ–¹é¢çš„æ˜¾è‘—ä¸è¶³ã€‚è¿™ä¸€å‘ç°å¼ºè°ƒäº†æœªæ¥ç ”ç©¶åœ¨å¤šè¯­è¨€å’Œæ–‡åŒ–æ•æ„Ÿæ¨¡å‹è®¾è®¡ä¸Šçš„é‡è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤šè¯­è¨€æ™ºèƒ½åŠ©æ‰‹ã€è·¨æ–‡åŒ–æ•™è‚²å·¥å…·ä»¥åŠå…¨çƒåŒ–å¸‚åœºçš„å†…å®¹ç”Ÿæˆã€‚é€šè¿‡æå‡æ¨¡å‹çš„è·¨è¯­è¨€ä¸€è‡´æ€§ï¼Œå¯ä»¥æ›´å¥½åœ°æ»¡è¶³ä¸åŒæ–‡åŒ–èƒŒæ™¯ç”¨æˆ·çš„éœ€æ±‚ï¼Œå¢å¼ºç”¨æˆ·ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The rapid evolution of multimodal large language models (MLLMs) has significantly enhanced their real-world applications. However, achieving consistent performance across languages, especially when integrating cultural knowledge, remains a significant challenge. To better assess this issue, we introduce two new benchmarks: KnowRecall and VisRecall, which evaluate cross-lingual consistency in MLLMs. KnowRecall is a visual question answering benchmark designed to measure factual knowledge consistency in 15 languages, focusing on cultural and historical questions about global landmarks. VisRecall assesses visual memory consistency by asking models to describe landmark appearances in 9 languages without access to images. Experimental results reveal that state-of-the-art MLLMs, including proprietary ones, still struggle to achieve cross-lingual consistency. This underscores the need for more robust approaches that produce truly multilingual and culturally aware models.

