---
layout: default
title: $\textit{New News}$: System-2 Fine-tuning for Robust Integration of New Knowledge
---

# $\textit{New News}$: System-2 Fine-tuning for Robust Integration of New Knowledge

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.01812" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.01812v3</a>
  <a href="https://arxiv.org/pdf/2505.01812.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.01812v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.01812v3', '$\textit{New News}$: System-2 Fine-tuning for Robust Integration of New Knowledge')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Core Francisco Park, Zechen Zhang, Hidenori Tanaka

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-03 (æ›´æ–°: 2025-11-14)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSystem-2å¾®è°ƒæ–¹æ³•ä»¥è§£å†³æ–°çŸ¥è¯†æ•´åˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `çŸ¥è¯†æ•´åˆ` `å¾®è°ƒæ–¹æ³•` `è‡ªæˆ‘ç”Ÿæˆæ•°æ®` `ä¸Šä¸‹æ–‡å­¦ä¹ ` `æ™ºèƒ½é—®ç­”` `æ•™è‚²æŠ€æœ¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å°†æ–°ä¿¡æ¯æœ‰æ•ˆæ•´åˆåˆ°æ¨¡å‹æƒé‡æ–¹é¢å­˜åœ¨æ˜¾è‘—æŒ‘æˆ˜ï¼Œå¯¼è‡´å¾®è°ƒæ•ˆæœä¸ä½³ã€‚
2. è®ºæ–‡æå‡ºSystem-2å¾®è°ƒï¼ˆSys2-FTï¼‰æ–¹æ³•ï¼Œé€šè¿‡è‡ªæˆ‘ç”Ÿæˆæ•°æ®åè®®æ¥å¢å¼ºæ¨¡å‹å¯¹æ–°çŸ¥è¯†çš„å†…åŒ–èƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒSys2-FTçš„Self-QAåè®®æ˜¾è‘—æå‡äº†æ¨¡å‹çš„å­¦ä¹ æ•ˆæœï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†æ–°ä¿¡æ¯æ—¶ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äººç±»å’Œæ™ºèƒ½åŠ¨ç‰©èƒ½å¤Ÿå†…åŒ–æ–°ä¿¡æ¯å¹¶å‡†ç¡®ç†è§£å…¶å«ä¹‰ä»¥æ‰§è¡Œä¸‹æ¸¸ä»»åŠ¡ã€‚å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¯ä»¥é€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰æ¥å®ç°è¿™ä¸€ç‚¹ï¼Œä½†é€šè¿‡å¾®è°ƒå°†ä¿¡æ¯æœ‰æ•ˆæ•´åˆåˆ°æ¨¡å‹æƒé‡ä¸­ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚æœ¬æ–‡æå‡ºäº†New Newsæ•°æ®é›†ï¼ŒåŒ…å«å¤šä¸ªé¢†åŸŸçš„å‡è®¾æ€§æ–°é—»åŠå…¶ç›¸å…³çš„ä¸‹æ¸¸è¯„ä¼°é—®é¢˜ã€‚æˆ‘ä»¬å±•ç¤ºäº†å¤©çœŸå¾®è°ƒä¸ä¸Šä¸‹æ–‡å­¦ä¹ ä¹‹é—´çš„æ˜¾è‘—å·®è·ï¼Œå¹¶æå‡ºäº†ä¸€ç³»åˆ—è‡ªæˆ‘ç”Ÿæˆæ•°æ®çš„åè®®ï¼Œç§°ä¸ºSystem-2å¾®è°ƒï¼ˆSys2-FTï¼‰ï¼Œä»¥ç¼©å°è¿™ä¸€å·®è·ã€‚å®éªŒè¡¨æ˜ï¼ŒSys2-FTçš„Self-QAåè®®æ˜¾è‘—æå‡äº†æ¨¡å‹å¯¹æ–°é—»çš„å†…åœ¨å­¦ä¹ ï¼ŒåŒæ—¶ä¿æŒäº†æ¨¡å‹çš„é€šç”¨èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡è¦è§£å†³çš„é—®é¢˜æ˜¯å¦‚ä½•æœ‰æ•ˆåœ°å°†æ–°çŸ¥è¯†æ•´åˆåˆ°å¤§å‹è¯­è¨€æ¨¡å‹çš„æƒé‡ä¸­ã€‚ç°æœ‰çš„å¾®è°ƒæ–¹æ³•åœ¨è¿™ä¸€æ–¹é¢è¡¨ç°ä¸ä½³ï¼Œæ— æ³•å……åˆ†åˆ©ç”¨ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†System-2å¾®è°ƒï¼ˆSys2-FTï¼‰æ–¹æ³•ï¼Œåˆ©ç”¨è‡ªæˆ‘ç”Ÿæˆçš„æ•°æ®åè®®ï¼ˆå¦‚åŒä¹‰å¥ã€æ¨ç†å’Œè‡ªé—®è‡ªç­”ï¼‰æ¥å¢å¼ºæ¨¡å‹çš„çŸ¥è¯†å†…åŒ–èƒ½åŠ›ã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨é€šè¿‡å¤šæ ·åŒ–çš„è®­ç»ƒæ•°æ®æ¥æå‡æ¨¡å‹çš„å­¦ä¹ æ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®ç”Ÿæˆã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚é¦–å…ˆç”ŸæˆåŒ…å«æ–°çŸ¥è¯†çš„è®­ç»ƒæ•°æ®ï¼Œç„¶åä½¿ç”¨è¿™äº›æ•°æ®è¿›è¡Œæ¨¡å‹çš„å¾®è°ƒï¼Œæœ€åé€šè¿‡ä¸‹æ¸¸ä»»åŠ¡è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹æ˜¯Self-QAåè®®ï¼Œå®ƒæ˜¾è‘—æé«˜äº†æ¨¡å‹å¯¹æ–°çŸ¥è¯†çš„å†…åœ¨å­¦ä¹ èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒäº†æ¨¡å‹çš„é€šç”¨æ€§ã€‚ä¸ä¼ ç»Ÿçš„å¾®è°ƒæ–¹æ³•ç›¸æ¯”ï¼ŒSys2-FTèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°æ•´åˆä¿¡æ¯ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å…³é”®è®¾è®¡æ–¹é¢ï¼Œè®ºæ–‡è¯¦ç»†è®¨è®ºäº†æ•°æ®ç”Ÿæˆçš„ç­–ç•¥ã€æŸå¤±å‡½æ•°çš„é€‰æ‹©ä»¥åŠæ¨¡å‹ç»“æ„çš„è°ƒæ•´ï¼Œä»¥ç¡®ä¿æ¨¡å‹èƒ½å¤Ÿåœ¨å¤šç§é¢†åŸŸä¸­æœ‰æ•ˆå­¦ä¹ æ–°çŸ¥è¯†ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨Sys2-FTçš„Self-QAåè®®åï¼Œæ¨¡å‹åœ¨æ–°çŸ¥è¯†çš„å†…åœ¨å­¦ä¹ ä¸Šå–å¾—äº†æ˜¾è‘—æå‡ï¼Œå°¤å…¶æ˜¯åœ¨å¤šä¸ªé¢†åŸŸçš„ä¸‹æ¸¸ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ã€‚ä¸ä¼ ç»Ÿå¾®è°ƒæ–¹æ³•ç›¸æ¯”ï¼Œæ¨¡å‹çš„æ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°äº†XX%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€æ•™è‚²æŠ€æœ¯å’Œè‡ªåŠ¨åŒ–å†…å®¹ç”Ÿæˆç­‰ã€‚é€šè¿‡æœ‰æ•ˆæ•´åˆæ–°çŸ¥è¯†ï¼Œæ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”ä¸æ–­å˜åŒ–çš„ä¿¡æ¯ç¯å¢ƒï¼Œæå‡å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„è¡¨ç°å’Œå¯é æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Humans and intelligent animals can internalize new information and accurately internalize their implications to perform downstream tasks. While large language models (LLMs) can achieve this through in-context learning (ICL) when the information (news) is explicitly given as context, adequately integrating the information into model weights via fine-tuning remains challenging. In this paper, we introduce New News, a dataset composed of hypothetical yet plausible news spanning multiple domains (mathematics, coding, discoveries, leaderboards, events), accompanied by downstream evaluation questions whose correct answers critically depend on understanding and internalizing the news. First, we demonstrate a substantial gap between naive fine-tuning and in-context learning (FT-ICL gap) on our dataset. To address this gap, we explore a suite of self-play data generation protocols -- paraphrases, implications, and Self-QA -- designed to distill the knowledge processed by the model with context into the weights of the model, which we term System-2 Fine-tuning (Sys2-FT). We systematically evaluate ICL and Sys2-FT performance across data domains and model scales with the Qwen 2.5 family of models. Our results demonstrate that the Self-QA protocol of Sys2-FT significantly improves models' in-weight learning of the news while preserving general capabilities. Furthermore, we discover the contextual shadowing effect, where training with the news in context followed by its rephrases or QAs catastrophically degrades learning of the news. Finally, we show preliminary evidence of an emerging scaling law of Sys2-FT.

