---
layout: default
title: "TAT-R1: Terminology-Aware Translation with Reinforcement Learning and Word Alignment"
---

# TAT-R1: Terminology-Aware Translation with Reinforcement Learning and Word Alignment

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21172" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21172v1</a>
  <a href="https://arxiv.org/pdf/2505.21172.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21172v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21172v1', 'TAT-R1: Terminology-Aware Translation with Reinforcement Learning and Word Alignment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zheng Li, Mao Zheng, Mingyang Song, Wenjie Yang

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTAT-R1ä»¥è§£å†³æœ¯è¯­ç¿»è¯‘å‡†ç¡®æ€§ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æœºå™¨ç¿»è¯‘` `æœ¯è¯­ç¿»è¯‘` `å¼ºåŒ–å­¦ä¹ ` `è¯å¯¹é½` `æ·±åº¦å­¦ä¹ ` `è¯­è¨€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æœºå™¨ç¿»è¯‘æ–¹æ³•åœ¨æœ¯è¯­ç¿»è¯‘çš„å‡†ç¡®æ€§ä¸Šå­˜åœ¨ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨æ·±åº¦æ¨ç†æ¨¡å‹ä¸­æœªå¾—åˆ°æœ‰æ•ˆè§£å†³ã€‚
2. æœ¬æ–‡æå‡ºçš„TAT-R1æ¨¡å‹é€šè¿‡å¼ºåŒ–å­¦ä¹ å’Œè¯å¯¹é½æŠ€æœ¯ï¼Œä¸“æ³¨äºæœ¯è¯­çš„å‡†ç¡®ç¿»è¯‘ï¼Œæå‡äº†ç¿»è¯‘è´¨é‡ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTAT-R1åœ¨æœ¯è¯­ç¿»è¯‘å‡†ç¡®æ€§ä¸Šæ˜¾è‘—æé«˜ï¼Œç›¸è¾ƒäºåŸºçº¿æ¨¡å‹æœ‰æ˜æ˜¾çš„æ€§èƒ½æå‡ï¼ŒåŒæ—¶ä¿æŒäº†å¯¹ä¸€èˆ¬ç¿»è¯‘ä»»åŠ¡çš„è‰¯å¥½è¡¨ç°ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œæ·±åº¦æ¨ç†çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¦‚DeepSeek-R1åœ¨æ•°å­¦å’Œç¼–ç¨‹ç­‰ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚å—æ­¤å¯å‘ï¼Œå¤šä¸ªç ”ç©¶åˆ©ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æå‡æ¨¡å‹çš„æ·±åº¦æ¨ç†èƒ½åŠ›å¹¶æ”¹å–„æœºå™¨ç¿»è¯‘ï¼ˆMTï¼‰è´¨é‡ã€‚ç„¶è€Œï¼Œæœ¯è¯­ç¿»è¯‘ä½œä¸ºMTä¸­çš„é‡è¦ä»»åŠ¡ï¼Œåœ¨æ·±åº¦æ¨ç†LLMsä¸­ä»æœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚æœ¬æ–‡æå‡ºäº†TAT-R1ï¼Œä¸€ä¸ªåŸºäºå¼ºåŒ–å­¦ä¹ å’Œè¯å¯¹é½çš„æœ¯è¯­æ„ŸçŸ¥ç¿»è¯‘æ¨¡å‹ã€‚æˆ‘ä»¬é¦–å…ˆä½¿ç”¨è¯å¯¹é½æ¨¡å‹æå–å…³é”®è¯ç¿»è¯‘å¯¹ï¼Œç„¶åè®¾è®¡äº†ä¸‰ç§åŸºäºè§„åˆ™çš„å¯¹é½å¥–åŠ±ã€‚é€šè¿‡è¿™äº›å¥–åŠ±ï¼ŒRLè®­ç»ƒçš„ç¿»è¯‘æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°å…³æ³¨æºæ–‡æœ¬ä¸­å…³é”®ä¿¡æ¯çš„å‡†ç¡®ç¿»è¯‘ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTAT-R1åœ¨æœ¯è¯­ç¿»è¯‘å‡†ç¡®æ€§ä¸Šæ˜¾è‘—ä¼˜äºåŸºçº¿æ¨¡å‹ï¼ŒåŒæ—¶åœ¨ä¸€èˆ¬ç¿»è¯‘ä»»åŠ¡ä¸Šä¿æŒäº†å¯æ¯”çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æœºå™¨ç¿»è¯‘ä¸­æœ¯è¯­ç¿»è¯‘å‡†ç¡®æ€§ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†æœ¯è¯­æ—¶å¾€å¾€ç¼ºä¹é’ˆå¯¹æ€§ï¼Œå¯¼è‡´ç¿»è¯‘è´¨é‡ä¸é«˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šTAT-R1æ¨¡å‹é€šè¿‡æå–å…³é”®è¯ç¿»è¯‘å¯¹å¹¶ç»“åˆå¼ºåŒ–å­¦ä¹ ï¼Œè®¾è®¡äº†åŸºäºè§„åˆ™çš„å¯¹é½å¥–åŠ±ï¼Œä¿ƒä½¿æ¨¡å‹å…³æ³¨æœ¯è¯­çš„å‡†ç¡®ç¿»è¯‘ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¨¡å‹çš„æ•´ä½“æ¶æ„åŒ…æ‹¬è¯å¯¹é½æ¨¡å—ã€å¥–åŠ±è®¾è®¡æ¨¡å—å’Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒæ¨¡å—ã€‚é¦–å…ˆæå–å…³é”®è¯ç¿»è¯‘å¯¹ï¼Œç„¶åé€šè¿‡è®¾è®¡çš„å¥–åŠ±æœºåˆ¶è¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šTAT-R1çš„ä¸»è¦åˆ›æ–°åœ¨äºå¼•å…¥äº†æœ¯è¯­æ„ŸçŸ¥çš„å¼ºåŒ–å­¦ä¹ æœºåˆ¶ï¼Œåˆ©ç”¨è¯å¯¹é½ä¿¡æ¯æ¥ä¼˜åŒ–ç¿»è¯‘è¿‡ç¨‹ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å¤„ç†æœ¯è¯­ç¿»è¯‘ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ä¸‰ç§ä¸åŒçš„è§„åˆ™å¯¹é½å¥–åŠ±ï¼Œä»¥å¢å¼ºæ¨¡å‹å¯¹æœ¯è¯­çš„å…³æ³¨ã€‚æ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿè€ƒè™‘äº†æœ¯è¯­ç¿»è¯‘çš„ç‰¹æ®Šæ€§ï¼Œä»¥æé«˜æ•´ä½“ç¿»è¯‘è´¨é‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒTAT-R1åœ¨æœ¯è¯­ç¿»è¯‘å‡†ç¡®æ€§ä¸Šè¾ƒåŸºçº¿æ¨¡å‹æå‡äº†æ˜¾è‘—çš„æ€§èƒ½ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°X%ï¼ˆå…·ä½“æ•°æ®æœªçŸ¥ï¼‰ï¼ŒåŒæ—¶åœ¨ä¸€èˆ¬ç¿»è¯‘ä»»åŠ¡ä¸­è¡¨ç°ä¿æŒç¨³å®šï¼Œæ˜¾ç¤ºå‡ºæ¨¡å‹çš„å¹¿æ³›é€‚ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

TAT-R1æ¨¡å‹åœ¨ä¸“ä¸šé¢†åŸŸçš„æœºå™¨ç¿»è¯‘ä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨æ³•å¾‹ã€åŒ»å­¦å’ŒæŠ€æœ¯æ–‡æ¡£ç­‰éœ€è¦é«˜å‡†ç¡®æ€§æœ¯è¯­ç¿»è¯‘çš„åœºæ™¯ã€‚å…¶å¼ºåŒ–å­¦ä¹ çš„è®¾è®¡ç†å¿µä¹Ÿä¸ºæœªæ¥çš„ç¿»è¯‘æ¨¡å‹æä¾›äº†æ–°çš„æ€è·¯ï¼Œå¯èƒ½æ¨åŠ¨æ›´æ™ºèƒ½çš„ç¿»è¯‘ç³»ç»Ÿçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recently, deep reasoning large language models(LLMs) like DeepSeek-R1 have made significant progress in tasks such as mathematics and coding. Inspired by this, several studies have employed reinforcement learning(RL) to enhance models' deep reasoning capabilities and improve machine translation(MT) quality. However, the terminology translation, an essential task in MT, remains unexplored in deep reasoning LLMs. In this paper, we propose \textbf{TAT-R1}, a terminology-aware translation model trained with reinforcement learning and word alignment. Specifically, we first extract the keyword translation pairs using a word alignment model. Then we carefully design three types of rule-based alignment rewards with the extracted alignment relationships. With those alignment rewards, the RL-trained translation model can learn to focus on the accurate translation of key information, including terminology in the source text. Experimental results show the effectiveness of TAT-R1. Our model significantly improves terminology translation accuracy compared to the baseline models while maintaining comparable performance on general translation tasks. In addition, we conduct detailed ablation studies of the DeepSeek-R1-like training paradigm for machine translation and reveal several key findings.

