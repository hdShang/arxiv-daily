---
layout: default
title: Who Reasons in the Large Language Models?
---

# Who Reasons in the Large Language Models?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20993" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.20993v1</a>
  <a href="https://arxiv.org/pdf/2505.20993.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20993v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20993v1', 'Who Reasons in the Large Language Models?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jie Shao, Jianxin Wu

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºStethoscope for Networksä»¥æ­ç¤ºå¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ¨ç†èƒ½åŠ›` `è¾“å‡ºæŠ•å½±æ¨¡å—` `å¤šå¤´è‡ªæ³¨æ„åŠ›` `æ¨¡å‹å¯è§£é‡Šæ€§` `è¯Šæ–­å·¥å…·` `é’ˆå¯¹æ€§è®­ç»ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›æ¥æºå°šä¸æ˜ç¡®ï¼Œæ˜¯å¦æºäºæ•´ä¸ªæ¨¡å‹ã€ç‰¹å®šæ¨¡å—æˆ–ä»…ä¸ºè¿‡æ‹Ÿåˆçš„äº§ç‰©ä»æ˜¯ä¸€ä¸ªå¼€æ”¾é—®é¢˜ã€‚
2. æœ¬æ–‡æå‡ºStethoscope for Networksï¼ˆSfNï¼‰å·¥å…·ï¼Œæ—¨åœ¨æ·±å…¥æ¢æµ‹å’Œåˆ†æLLMsçš„å†…éƒ¨è¡Œä¸ºï¼ŒéªŒè¯æ¨ç†èƒ½åŠ›çš„æ¥æºã€‚
3. é€šè¿‡å®éªŒï¼Œå‘ç°è¾“å‡ºæŠ•å½±æ¨¡å—ï¼ˆoprojï¼‰åœ¨æ¨ç†ä¸­èµ·æ ¸å¿ƒä½œç”¨ï¼Œè€Œå…¶ä»–æ¨¡å—åˆ™ä¸»è¦ç”¨äºæå‡å¯¹è¯æµç•…æ€§ï¼Œæä¾›äº†æ–°çš„å¯è§£é‡Šæ€§è§†è§’ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¡¨ç°å‡ºè‰²ï¼Œä½†èµ‹äºˆå®ƒä»¬æ–°èƒ½åŠ›ï¼ˆå¦‚æ•°å­¦æ¨ç†ï¼‰çš„è¿‡ç¨‹ä»ç„¶ä¸»è¦ä¾èµ–ç»éªŒä¸”ä¸é€æ˜ã€‚æœ¬æ–‡å‡è®¾ï¼Œç»è¿‡è‰¯å¥½è®­ç»ƒçš„LLMsçš„æ¨ç†èƒ½åŠ›ä¸»è¦å½’å› äºå˜æ¢å™¨å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶ä¸­çš„è¾“å‡ºæŠ•å½±æ¨¡å—ï¼ˆoprojï¼‰ã€‚ä¸ºæ”¯æŒè¿™ä¸€å‡è®¾ï¼Œæˆ‘ä»¬å¼•å…¥äº†Stethoscope for Networksï¼ˆSfNï¼‰ï¼Œä¸€å¥—æ—¨åœ¨æ¢æµ‹å’Œåˆ†æLLMså†…éƒ¨è¡Œä¸ºçš„è¯Šæ–­å·¥å…·ã€‚é€šè¿‡SfNï¼Œæˆ‘ä»¬æä¾›äº†é—´æ¥å’Œå®è¯è¯æ®ï¼Œè¡¨æ˜oprojåœ¨æ¨ç†ä¸­å‘æŒ¥äº†æ ¸å¿ƒä½œç”¨ï¼Œè€Œå…¶ä»–æ¨¡å—åˆ™æ›´å¤šåœ°ä¿ƒè¿›æµç•…å¯¹è¯ã€‚è¿™äº›å‘ç°ä¸ºLLMçš„å¯è§£é‡Šæ€§æä¾›äº†æ–°è§†è§’ï¼Œå¹¶ä¸ºæ›´å…·é’ˆå¯¹æ€§çš„è®­ç»ƒç­–ç•¥å¼€è¾Ÿäº†æ–°é€”å¾„ï¼Œå¯èƒ½ä½¿LLMsæ›´é«˜æ•ˆå’Œä¸“ä¸šåŒ–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨æ­ç¤ºå¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›æ¥æºï¼Œç°æœ‰æ–¹æ³•å¯¹æ¨ç†èƒ½åŠ›çš„ç†è§£å¤šä¸ºç»éªŒæ€§ï¼Œç¼ºä¹ç³»ç»Ÿæ€§åˆ†æã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬å‡è®¾æ¨ç†èƒ½åŠ›ä¸»è¦æºäºè¾“å‡ºæŠ•å½±æ¨¡å—ï¼ˆoprojï¼‰ï¼Œå¹¶é€šè¿‡Stethoscope for Networksï¼ˆSfNï¼‰å·¥å…·è¿›è¡Œæ·±å…¥åˆ†æï¼Œä»¥éªŒè¯è¿™ä¸€å‡è®¾ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSfNå·¥å…·åŒ…å«å¤šä¸ªè¯Šæ–­æ¨¡å—ï¼Œèƒ½å¤Ÿæ¢æµ‹LLMså†…éƒ¨çš„è¡Œä¸ºï¼Œå°¤å…¶æ˜¯oprojæ¨¡å—çš„åŠŸèƒ½ä¸å…¶ä»–æ¨¡å—çš„å¯¹æ¯”ã€‚

**å…³é”®åˆ›æ–°**ï¼šå¼•å…¥SfNä½œä¸ºåˆ†æå·¥å…·ï¼Œç³»ç»Ÿæ€§åœ°æ¢è®¨äº†LLMsæ¨ç†èƒ½åŠ›çš„æ¥æºï¼Œå¼ºè°ƒäº†oprojæ¨¡å—çš„é‡è¦æ€§ï¼Œè¿™ä¸ä¼ ç»Ÿçš„ç»éªŒæ€§åˆ†ææ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œæˆ‘ä»¬è®¾è®¡äº†å¤šç§æµ‹è¯•åœºæ™¯ï¼Œé€šè¿‡å¯¹æ¯”ä¸åŒæ¨¡å—çš„è¡¨ç°ï¼Œé‡åŒ–oprojåœ¨æ¨ç†ä»»åŠ¡ä¸­çš„è´¡çŒ®ï¼ŒåŒæ—¶ç¡®ä¿å…¶ä»–æ¨¡å—åœ¨å¯¹è¯æµç•…æ€§ä¸Šçš„ä½œç”¨å¾—åˆ°å……åˆ†è¯„ä¼°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œoprojæ¨¡å—åœ¨æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ï¼Œç›¸è¾ƒäºå…¶ä»–æ¨¡å—ï¼Œå…¶å¯¹æ¨ç†èƒ½åŠ›çš„è´¡çŒ®æ›´ä¸ºçªå‡ºã€‚è¿™ä¸€å‘ç°ä¸ºLLMsçš„å¯è§£é‡Šæ€§æä¾›äº†æ–°çš„è§†è§’ï¼Œå¹¶ä¸ºæœªæ¥çš„æ¨¡å‹è®¾è®¡æä¾›äº†å®è¯ä¾æ®ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶ä¸ºå¤§å‹è¯­è¨€æ¨¡å‹çš„è®­ç»ƒå’Œä¼˜åŒ–æä¾›äº†æ–°çš„æ€è·¯ï¼Œå°¤å…¶æ˜¯åœ¨æ¨ç†èƒ½åŠ›å’Œå¯¹è¯ç”Ÿæˆçš„å¹³è¡¡æ–¹é¢ã€‚æœªæ¥ï¼ŒåŸºäºoprojæ¨¡å—çš„é’ˆå¯¹æ€§è®­ç»ƒç­–ç•¥å¯èƒ½ä¼šæå‡æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼Œæ¨åŠ¨æ™ºèƒ½å¯¹è¯ç³»ç»Ÿå’Œè‡ªåŠ¨åŒ–æ¨ç†å·¥å…·çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Despite the impressive performance of large language models (LLMs), the process of endowing them with new capabilities--such as mathematical reasoning--remains largely empirical and opaque. A critical open question is whether reasoning abilities stem from the entire model, specific modules, or are merely artifacts of overfitting. In this work, we hypothesize that the reasoning capabilities in well-trained LLMs are primarily attributed to the output projection module (oproj) in the Transformer's multi-head self-attention (MHSA) mechanism. To support this hypothesis, we introduce Stethoscope for Networks (SfN), a suite of diagnostic tools designed to probe and analyze the internal behaviors of LLMs. Using SfN, we provide both circumstantial and empirical evidence suggesting that oproj plays a central role in enabling reasoning, whereas other modules contribute more to fluent dialogue. These findings offer a new perspective on LLM interpretability and open avenues for more targeted training strategies, potentially enabling more efficient and specialized LLMs.

