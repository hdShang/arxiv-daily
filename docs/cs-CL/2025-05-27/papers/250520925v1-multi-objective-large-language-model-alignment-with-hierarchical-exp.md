---
layout: default
title: Multi-objective Large Language Model Alignment with Hierarchical Experts
---

# Multi-objective Large Language Model Alignment with Hierarchical Experts

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20925" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.20925v1</a>
  <a href="https://arxiv.org/pdf/2505.20925.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20925v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20925v1', 'Multi-objective Large Language Model Alignment with Hierarchical Experts')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhuo Li, Guodong Du, Weiyang Guo, Yigeng Zhou, Xiucheng Li, Wenya Wang, Fangming Liu, Yequan Wang, Deheng Ye, Min Zhang, Jing Li

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHoEæ–¹æ³•ä»¥è§£å†³å¤šç›®æ ‡å¤§è¯­è¨€æ¨¡å‹å¯¹é½é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šç›®æ ‡å¯¹é½` `å¤§è¯­è¨€æ¨¡å‹` `å±‚æ¬¡åŒ–ä¸“å®¶` `å‚æ•°é«˜æ•ˆ` `ç”¨æˆ·åå¥½é€‚åº”`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¯¹é½æ–¹æ³•åœ¨å¤„ç†å¤šç›®æ ‡æ—¶ï¼Œå¾€å¾€éš¾ä»¥æœ‰æ•ˆå¹³è¡¡ä¸åŒäººç±»åå¥½çš„æƒè¡¡ï¼Œå¯¼è‡´æ€§èƒ½ä¸ä½³ã€‚
2. æœ¬æ–‡æå‡ºçš„HoEæ–¹æ³•é€šè¿‡å¼•å…¥å±‚æ¬¡åŒ–ä¸“å®¶ç»„ä»¶ï¼Œæä¾›äº†ä¸€ç§æ— éœ€å†è®­ç»ƒçš„çµæ´»å¯¹é½æ–¹æ¡ˆï¼Œèƒ½å¤Ÿé€‚åº”å¤šæ ·åŒ–çš„ç”¨æˆ·éœ€æ±‚ã€‚
3. HoEåœ¨14ä¸ªç›®æ ‡å’Œ200ç§åå¥½ä¸‹çš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œå…¶æ€§èƒ½æ˜¾è‘—ä¼˜äº15ä¸ªæœ€æ–°çš„åŸºçº¿æ–¹æ³•ï¼Œå±•ç°äº†è‰¯å¥½çš„é€‚åº”æ€§å’Œæ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¯¹é½å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä»¥åŒæ—¶æ»¡è¶³å¤šä¸ªç›®æ ‡ä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨é¢å¯¹äººç±»åå¥½çš„å¤šæ ·æ€§å’Œå†²çªæ€§æ—¶ã€‚ç°æœ‰çš„å¯¹é½æ–¹æ³•åœ¨æœ‰æ•ˆå¹³è¡¡æƒè¡¡æ–¹é¢å­˜åœ¨å›°éš¾ï¼Œé€šå¸¸éœ€è¦æ˜‚è´µçš„å†è®­ç»ƒæˆ–åœ¨åå¥½å¸•ç´¯æ‰˜å‰æ²¿ä¸Šäº§ç”Ÿæ¬¡ä¼˜ç»“æœã€‚æœ¬æ–‡æå‡ºäº†HoEï¼ˆHierarchical Mixture-of-Expertsï¼‰ï¼Œä¸€ç§è½»é‡çº§ã€å‚æ•°é«˜æ•ˆä¸”å³æ’å³ç”¨çš„æ–¹æ³•ï¼Œæ¶ˆé™¤äº†æ¨¡å‹è®­ç»ƒçš„éœ€æ±‚ï¼ŒåŒæ—¶ä½¿LLMsèƒ½å¤Ÿåœ¨æ•´ä¸ªå¸•ç´¯æ‰˜å‰æ²¿ä¸Šé€‚åº”å¤šæ ·åŒ–çš„ç”¨æˆ·åå¥½ã€‚HoEç”±ä¸‰ä¸ªå±‚æ¬¡ç»„ä»¶ç»„æˆï¼šLoRAä¸“å®¶ã€è·¯ç”±ä¸“å®¶å’Œåå¥½è·¯ç”±ï¼Œè¾¾åˆ°äº†æœ€ä½³çš„å¸•ç´¯æ‰˜å‰æ²¿ï¼Œå¹¶åœ¨å‚æ•°è§„æ¨¡ã€è®­ç»ƒæˆæœ¬å’Œæ€§èƒ½ä¹‹é—´å®ç°äº†æƒè¡¡ã€‚æˆ‘ä»¬åœ¨14ä¸ªç›®æ ‡å’Œ200ç§ä¸åŒåå¥½ä¸‹å¯¹HoEè¿›è¡Œäº†è¯„ä¼°ï¼Œå±•ç¤ºäº†å…¶åœ¨6ä¸ªåŸºå‡†æµ‹è¯•ä¸Šä¼˜äº15ä¸ªæœ€æ–°åŸºçº¿çš„è¡¨ç°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹åœ¨å¤šç›®æ ‡å¯¹é½ä¸­çš„æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€éœ€è¦æ˜‚è´µçš„å†è®­ç»ƒæˆ–æ— æ³•æœ‰æ•ˆå¹³è¡¡ä¸åŒåå¥½ä¹‹é—´çš„æƒè¡¡ï¼Œå¯¼è‡´æ€§èƒ½ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šHoEæ–¹æ³•é€šè¿‡å¼•å…¥å±‚æ¬¡åŒ–çš„ä¸“å®¶ç»„ä»¶ï¼Œæä¾›äº†ä¸€ç§è½»é‡çº§ä¸”å‚æ•°é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼Œå…è®¸æ¨¡å‹åœ¨ä¸è¿›è¡Œå†è®­ç»ƒçš„æƒ…å†µä¸‹é€‚åº”ä¸åŒçš„ç”¨æˆ·åå¥½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šHoEç”±ä¸‰ä¸ªä¸»è¦æ¨¡å—ç»„æˆï¼šLoRAä¸“å®¶ã€è·¯ç”±ä¸“å®¶å’Œåå¥½è·¯ç”±ã€‚LoRAä¸“å®¶è´Ÿè´£å¤„ç†ç‰¹å®šä»»åŠ¡çš„ç»†èŠ‚ï¼Œè·¯ç”±ä¸“å®¶åˆ™æ ¹æ®ç”¨æˆ·åå¥½è¿›è¡ŒåŠ¨æ€é€‰æ‹©ï¼Œè€Œåå¥½è·¯ç”±åˆ™ç¡®ä¿æ¨¡å‹èƒ½å¤Ÿåœ¨æ•´ä¸ªå¸•ç´¯æ‰˜å‰æ²¿ä¸Šè¿›è¡Œæœ‰æ•ˆè°ƒæ•´ã€‚

**å…³é”®åˆ›æ–°**ï¼šHoEçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶å±‚æ¬¡åŒ–çš„ä¸“å®¶ç»“æ„ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨ä¸å¢åŠ è®­ç»ƒæˆæœ¬çš„æƒ…å†µä¸‹ï¼Œçµæ´»é€‚åº”å¤šç§ç”¨æˆ·éœ€æ±‚ï¼Œè¿™ä¸ä¼ ç»Ÿæ–¹æ³•çš„å›ºå®šè®­ç»ƒæ–¹å¼å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒHoEé‡‡ç”¨äº†å‚æ•°é«˜æ•ˆçš„LoRAæŠ€æœ¯ï¼Œç¡®ä¿æ¨¡å‹åœ¨ä¿æŒè¾ƒå°å‚æ•°è§„æ¨¡çš„åŒæ—¶ï¼Œä»èƒ½å®ç°é«˜æ€§èƒ½ã€‚æ­¤å¤–ï¼Œè·¯ç”±æœºåˆ¶çš„è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ ¹æ®å®æ—¶åé¦ˆè¿›è¡Œè°ƒæ•´ï¼Œè¿›ä¸€æ­¥æå‡äº†é€‚åº”æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼ŒHoEåœ¨14ä¸ªç›®æ ‡å’Œ200ç§ä¸åŒåå¥½ä¸‹çš„è¡¨ç°æ˜¾è‘—ä¼˜äº15ä¸ªæœ€æ–°çš„åŸºçº¿æ–¹æ³•ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤šç›®æ ‡å¯¹é½ä¸­çš„æœ‰æ•ˆæ€§å’Œçµæ´»æ€§ã€‚å…·ä½“è€Œè¨€ï¼ŒHoEåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æ›´ä¼˜çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶åœ¨å‚æ•°æ•ˆç‡å’Œé€‚åº”æ€§æ–¹é¢çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ä¸ªæ€§åŒ–å¯¹è¯ç³»ç»Ÿã€æ™ºèƒ½å®¢æœå’Œå¤šä»»åŠ¡å­¦ä¹ ç­‰ã€‚HoEæ–¹æ³•çš„çµæ´»æ€§å’Œé«˜æ•ˆæ€§ä½¿å…¶èƒ½å¤Ÿåœ¨å®é™…åº”ç”¨ä¸­å¿«é€Ÿé€‚åº”ä¸åŒç”¨æˆ·çš„éœ€æ±‚ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æ¨åŠ¨å¤§è¯­è¨€æ¨¡å‹åœ¨æ›´å¹¿æ³›åœºæ™¯ä¸‹çš„åº”ç”¨ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦å¤„ç†å¤æ‚ç”¨æˆ·åå¥½çš„é¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Aligning large language models (LLMs) to simultaneously satisfy multiple objectives remains a significant challenge, especially given the diverse and often conflicting nature of human preferences. Existing alignment methods struggle to balance trade-offs effectively, often requiring costly retraining or yielding suboptimal results across the Pareto frontier of preferences. In this paper, we introduce \textit{HoE}(Hierarchical Mixture-of-Experts), a \textit{lightweight}, \textit{parameter-efficient}, and \textit{plug-and-play} approach that eliminates the need for model training, while enabling LLMs to adapt across the entire Pareto frontier and accommodate diverse user preferences. In particular, \textit{HoE} consists of three hierarchical components: LoRA Experts, Router Experts and Preference Routing, reaching optimal Pareto frontiers and achieving a trade-off between parameter size, training cost, and performance. We evaluate \textit{HoE} across various tasks on 14 objectives and 200 different preferences among 6 benchmarks, demonstrating superior performance over 15 recent baselines. Code is available in the supplementary materials.

