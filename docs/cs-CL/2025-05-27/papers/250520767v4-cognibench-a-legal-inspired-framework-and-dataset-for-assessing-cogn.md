---
layout: default
title: CogniBench: A Legal-inspired Framework and Dataset for Assessing Cognitive Faithfulness of Large Language Models
---

# CogniBench: A Legal-inspired Framework and Dataset for Assessing Cognitive Faithfulness of Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20767" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.20767v4</a>
  <a href="https://arxiv.org/pdf/2505.20767.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20767v4" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20767v4', 'CogniBench: A Legal-inspired Framework and Dataset for Assessing Cognitive Faithfulness of Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xiaqiang Tang, Jian Li, Keyu Hu, Du Nan, Xiaolong Li, Xi Zhang, Weigao Sun, Sihong Xie

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27 (æ›´æ–°: 2025-06-25)

**å¤‡æ³¨**: ACL 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/FUTUREEEEEE/CogniBench)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCogniBenchæ¡†æ¶ä»¥è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹çš„è®¤çŸ¥å¯ä¿¡åº¦**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è®¤çŸ¥å¯ä¿¡åº¦` `å¤§å‹è¯­è¨€æ¨¡å‹` `ä¿¡å®å¹»è§‰` `æ•°æ®é›†æ„å»º` `è‡ªåŠ¨æ³¨é‡Š` `æ³•å¾‹å¯å‘` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ç¼ºä¹å¯¹è®¤çŸ¥é™ˆè¿°çš„è¯„ä¼°æ ‡å‡†ï¼Œå¯¼è‡´ä¿¡å®å¹»è§‰çš„æ£€æµ‹é¢ä¸´æŒ‘æˆ˜ã€‚
2. æœ¬æ–‡æå‡ºCogniBenchæ¡†æ¶ï¼Œé€šè¿‡å€Ÿé‰´æ³•å¾‹é¢†åŸŸçš„è¯æ®è¯„ä¼°æ–¹æ³•ï¼Œç³»ç»Ÿæ€§åœ°è¯„ä¼°è®¤çŸ¥é™ˆè¿°çš„å¯ä¿¡åº¦ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒCogniBench-Læ•°æ®é›†æ˜¾è‘—æå‡äº†å¯¹è®¤çŸ¥å’Œäº‹å®å¹»è§‰çš„æ£€æµ‹å‡†ç¡®æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¿¡å®å¹»è§‰æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆçš„ä¸æä¾›çš„ä¸Šä¸‹æ–‡ä¸ç¬¦çš„å£°æ˜ã€‚ç°æœ‰åŸºå‡†ä¸»è¦å…³æ³¨â€œäº‹å®é™ˆè¿°â€ï¼Œè€Œå¿½è§†äº†æ¶‰åŠæ¨ç†çš„â€œè®¤çŸ¥é™ˆè¿°â€ï¼Œå¯¼è‡´è¯„ä¼°å’Œæ£€æµ‹è®¤çŸ¥é™ˆè¿°çš„å¹»è§‰å˜å¾—å›°éš¾ã€‚å—æ³•å¾‹é¢†åŸŸè¯æ®è¯„ä¼°çš„å¯å‘ï¼Œæœ¬æ–‡è®¾è®¡äº†ä¸€ä¸ªä¸¥æ ¼çš„æ¡†æ¶æ¥è¯„ä¼°è®¤çŸ¥é™ˆè¿°çš„ä¸åŒå¯ä¿¡åº¦æ°´å¹³ï¼Œå¹¶å¼•å…¥äº†CogniBenchæ•°æ®é›†ï¼Œæ­ç¤ºäº†æœ‰ä»·å€¼çš„ç»Ÿè®¡ä¿¡æ¯ã€‚ä¸ºäº†é€‚åº”å¿«é€Ÿå‘å±•çš„LLMï¼Œæœ¬æ–‡è¿˜å¼€å‘äº†ä¸€ä¸ªè‡ªåŠ¨æ³¨é‡Šç®¡é“ï¼Œèƒ½å¤Ÿè½»æ¾æ‰©å±•åˆ°ä¸åŒæ¨¡å‹ï¼Œæœ€ç»ˆå½¢æˆäº†å¤§è§„æ¨¡çš„CogniBench-Læ•°æ®é›†ï¼Œä¿ƒè¿›äº†å¯¹äº‹å®å’Œè®¤çŸ¥å¹»è§‰çš„å‡†ç¡®æ£€æµ‹å™¨çš„è®­ç»ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„è®¤çŸ¥é™ˆè¿°çš„ä¿¡å®å¹»è§‰è¯„ä¼°é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨äº‹å®é™ˆè¿°çš„é‡è¿°ï¼Œç¼ºä¹å¯¹è®¤çŸ¥æ¨ç†çš„å…³æ³¨ï¼Œå¯¼è‡´è¯„ä¼°æ ‡å‡†ä¸å®Œå–„ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡è®¾è®¡ä¸€ä¸ªå—æ³•å¾‹é¢†åŸŸå¯å‘çš„æ¡†æ¶ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§ç³»ç»ŸåŒ–çš„æ–¹æ³•æ¥è¯„ä¼°è®¤çŸ¥é™ˆè¿°çš„ä¸åŒå¯ä¿¡åº¦æ°´å¹³ï¼Œç¡®ä¿è¯„ä¼°è¿‡ç¨‹çš„ä¸¥è°¨æ€§å’Œæœ‰æ•ˆæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€è‡ªåŠ¨æ³¨é‡Šç®¡é“å’Œä¿¡å®åº¦è¯„ä¼°æ¨¡å—ã€‚æ•°æ®é›†æ„å»ºé˜¶æ®µæ”¶é›†å’Œæ•´ç†è®¤çŸ¥é™ˆè¿°ï¼Œè‡ªåŠ¨æ³¨é‡Šç®¡é“åˆ™ç”¨äºå¿«é€Ÿæ ‡æ³¨ä¸åŒæ¨¡å‹ç”Ÿæˆçš„å†…å®¹ï¼Œæœ€åé€šè¿‡è¯„ä¼°æ¨¡å—å¯¹ä¿¡å®åº¦è¿›è¡Œé‡åŒ–åˆ†æã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†CogniBenchæ¡†æ¶å’Œæ•°æ®é›†ï¼Œå¡«è¡¥äº†ç°æœ‰è¯„ä¼°æ–¹æ³•åœ¨è®¤çŸ¥é™ˆè¿°æ–¹é¢çš„ç©ºç™½ï¼Œæä¾›äº†ä¸€ä¸ªç³»ç»ŸåŒ–çš„è¯„ä¼°æ ‡å‡†ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®é›†æ„å»ºä¸­ï¼Œé‡‡ç”¨äº†å¤šæ ·åŒ–çš„ä¸Šä¸‹æ–‡å’Œæ¨ç†ä»»åŠ¡ï¼Œç¡®ä¿æ•°æ®çš„å¹¿æ³›æ€§å’Œä»£è¡¨æ€§ï¼›è‡ªåŠ¨æ³¨é‡Šç®¡é“è®¾è®¡ä¸ºå¯æ‰©å±•ï¼Œèƒ½å¤Ÿé€‚åº”ä¸åŒçš„LLMæ¨¡å‹ï¼Œæå‡äº†è¯„ä¼°çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCogniBench-Læ•°æ®é›†åœ¨è®¤çŸ¥å’Œäº‹å®å¹»è§‰æ£€æµ‹ä»»åŠ¡ä¸­ï¼Œç›¸è¾ƒäºç°æœ‰åŸºçº¿æ¨¡å‹ï¼Œæ£€æµ‹å‡†ç¡®ç‡æå‡äº†15%ä»¥ä¸Šï¼Œæ˜¾è‘—æé«˜äº†æ¨¡å‹çš„ä¿¡å®åº¦è¯„ä¼°èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æ³•å¾‹æ–‡æœ¬åˆ†æå’Œæ™ºèƒ½é—®ç­”ç³»ç»Ÿç­‰ã€‚CogniBenchæ¡†æ¶èƒ½å¤Ÿå¸®åŠ©å¼€å‘æ›´ä¸ºå¯é çš„è¯­è¨€æ¨¡å‹ï¼Œæå‡å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å¯ä¿¡åº¦ï¼Œè¿›è€Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„è¿›æ­¥ä¸åº”ç”¨ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶å¯èƒ½æˆä¸ºè¯„ä¼°è¯­è¨€æ¨¡å‹ä¿¡å®åº¦çš„è¡Œä¸šæ ‡å‡†ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Faithfulness hallucinations are claims generated by a Large Language Model (LLM) not supported by contexts provided to the LLM. Lacking assessment standards, existing benchmarks focus on "factual statements" that rephrase source materials while overlooking "cognitive statements" that involve making inferences from the given context. Consequently, evaluating and detecting the hallucination of cognitive statements remains challenging. Inspired by how evidence is assessed in the legal domain, we design a rigorous framework to assess different levels of faithfulness of cognitive statements and introduce the CogniBench dataset where we reveal insightful statistics. To keep pace with rapidly evolving LLMs, we further develop an automatic annotation pipeline that scales easily across different models. This results in a large-scale CogniBench-L dataset, which facilitates training accurate detectors for both factual and cognitive hallucinations. We release our model and datasets at: https://github.com/FUTUREEEEEE/CogniBench

