---
layout: default
title: Do LLMs Need to Think in One Language? Correlation between Latent Language and Task Performance
---

# Do LLMs Need to Think in One Language? Correlation between Latent Language and Task Performance

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21458" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21458v1</a>
  <a href="https://arxiv.org/pdf/2505.21458.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21458v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21458v1', 'Do LLMs Need to Think in One Language? Correlation between Latent Language and Task Performance')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shintaro Ozaki, Tatsuya Hiraoka, Hiroto Otake, Hiroki Ouchi, Masaru Isonuma, Benjamin Heinzerling, Kentaro Inui, Taro Watanabe, Yusuke Miyao, Yohei Oseki, Yu Takagi

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ¢è®¨æ½œåœ¨è¯­è¨€ä¸€è‡´æ€§å¯¹LLMä»»åŠ¡æ€§èƒ½çš„å½±å“**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ½œåœ¨è¯­è¨€` `ä¸‹æ¸¸ä»»åŠ¡` `è¯­è¨€é€‚åº”æ€§` `æœºå™¨ç¿»è¯‘` `è·¨æ–‡åŒ–äº¤æµ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç ”ç©¶è¾ƒå°‘æ¢è®¨æ½œåœ¨è¯­è¨€ä¸ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ä¹‹é—´çš„å…³ç³»ï¼Œå¯¼è‡´å¯¹å…¶å½±å“çš„ç†è§£ä¸è¶³ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡å˜æ¢è¾“å…¥æç¤ºè¯­è¨€ï¼Œåˆ†ææ½œåœ¨è¯­è¨€ä¸€è‡´æ€§ä¸ä»»åŠ¡æ€§èƒ½çš„ç›¸å…³æ€§ï¼Œä»¥éªŒè¯æ½œåœ¨è¯­è¨€çš„é‡è¦æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ½œåœ¨è¯­è¨€çš„ä¸€è‡´æ€§å¹¶éæ€»æ˜¯ä¼˜åŒ–ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½çš„å¿…è¦æ¡ä»¶ï¼Œæ¨¡å‹èƒ½å¤Ÿé€‚åº”ç›®æ ‡è¯­è¨€ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¢«è®¤ä¸ºä½¿ç”¨ä¸€ç§ç§°ä¸ºæ½œåœ¨è¯­è¨€çš„å†…éƒ¨è¯­è¨€æ¥å¤„ç†ä¿¡æ¯ï¼Œè¯¥è¯­è¨€å¯èƒ½ä¸è¾“å…¥æˆ–è¾“å‡ºè¯­è¨€ä¸åŒã€‚ç„¶è€Œï¼Œæ½œåœ¨è¯­è¨€ä¸è¾“å…¥å’Œè¾“å‡ºè¯­è¨€ä¹‹é—´çš„å·®å¼‚å¦‚ä½•å½±å“ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ä»ç„¶æœªè¢«å……åˆ†æ¢ç´¢ã€‚æˆ‘ä»¬çš„ç ”ç©¶å‡è®¾ï¼Œå§‹ç»ˆåœ¨æ½œåœ¨è¯­è¨€ä¸­æ€è€ƒå¯ä»¥å¢å¼ºä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬åœ¨å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸­å˜æ¢è¾“å…¥æç¤ºè¯­è¨€ï¼Œå¹¶åˆ†ææ½œåœ¨è¯­è¨€ä¸€è‡´æ€§ä¸ä»»åŠ¡æ€§èƒ½ä¹‹é—´çš„ç›¸å…³æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¿æŒæ½œåœ¨è¯­è¨€çš„ä¸€è‡´æ€§å¹¶ä¸æ€»æ˜¯å¯¹ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½æœ€ä¼˜çš„å¿…è¦æ¡ä»¶ï¼Œå› ä¸ºæ¨¡å‹èƒ½å¤Ÿåœ¨æœ€ç»ˆå±‚é™„è¿‘è°ƒæ•´å…¶å†…éƒ¨è¡¨ç¤ºä»¥åŒ¹é…ç›®æ ‡è¯­è¨€ï¼Œä»è€Œå‡å°‘ä¸€è‡´æ€§å¯¹æ•´ä½“æ€§èƒ½çš„å½±å“ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨æ¢è®¨æ½œåœ¨è¯­è¨€ä¸ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ä¹‹é—´çš„å…³ç³»ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†æ­ç¤ºæ½œåœ¨è¯­è¨€å¯¹ä»»åŠ¡è¡¨ç°çš„å½±å“ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡åœ¨å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸­å˜æ¢è¾“å…¥æç¤ºè¯­è¨€ï¼ŒéªŒè¯æ½œåœ¨è¯­è¨€çš„ä¸€è‡´æ€§æ˜¯å¦èƒ½å¢å¼ºä»»åŠ¡æ€§èƒ½ï¼Œæå‡ºæ½œåœ¨è¯­è¨€çš„é‡è¦æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶è®¾è®¡åŒ…æ‹¬åˆ›å»ºå¤šæ ·åŒ–çš„é—®é¢˜æ•°æ®é›†ï¼Œæ¶µç›–ç¿»è¯‘å’Œåœ°ç†æ–‡åŒ–ç­‰é¢†åŸŸï¼Œè¿›è¡Œå¤šç§å¤§å‹è¯­è¨€æ¨¡å‹çš„å®éªŒï¼Œåˆ†æå…¶æ€§èƒ½è¡¨ç°ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„åˆ›æ–°åœ¨äºç³»ç»Ÿæ€§åœ°ç ”ç©¶æ½œåœ¨è¯­è¨€ä¸€è‡´æ€§å¯¹ä»»åŠ¡æ€§èƒ½çš„å½±å“ï¼Œå‘ç°æ¨¡å‹åœ¨æœ€ç»ˆå±‚èƒ½å¤Ÿè°ƒæ•´å†…éƒ¨è¡¨ç¤ºä»¥é€‚åº”ç›®æ ‡è¯­è¨€ï¼Œä»è€Œé™ä½ä¸€è‡´æ€§çš„é‡è¦æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œè®¾ç½®äº†ä¸åŒçš„è¾“å…¥æç¤ºè¯­è¨€ï¼Œé‡‡ç”¨äº†å¤šç§å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œå¯¹æ¯”ï¼Œå…³æ³¨æ¨¡å‹åœ¨ç¿»è¯‘å’Œåœ°ç†æ–‡åŒ–ä»»åŠ¡ä¸­çš„è¡¨ç°å·®å¼‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä¿æŒæ½œåœ¨è¯­è¨€ä¸€è‡´æ€§å¹¶ä¸æ€»æ˜¯ä¼˜åŒ–ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½çš„å¿…è¦æ¡ä»¶ã€‚åœ¨ç¿»è¯‘å’Œåœ°ç†æ–‡åŒ–ä»»åŠ¡ä¸­ï¼Œæ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆé€‚åº”ç›®æ ‡è¯­è¨€ï¼Œå‡å°‘ä¸€è‡´æ€§å¯¹æ€§èƒ½çš„å½±å“ï¼Œå±•ç¤ºå‡ºæ¨¡å‹çš„çµæ´»æ€§å’Œé€‚åº”æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æœºå™¨ç¿»è¯‘å’Œè·¨æ–‡åŒ–äº¤æµç­‰ã€‚é€šè¿‡æ·±å…¥ç†è§£æ½œåœ¨è¯­è¨€å¯¹ä»»åŠ¡æ€§èƒ½çš„å½±å“ï¼Œå¯ä»¥ä¼˜åŒ–å¤§å‹è¯­è¨€æ¨¡å‹çš„è®¾è®¡ï¼Œæé«˜å…¶åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸‹çš„é€‚åº”èƒ½åŠ›ï¼Œè¿›è€Œæ¨åŠ¨æ™ºèƒ½åŠ©æ‰‹ã€ç¿»è¯‘å·¥å…·ç­‰å®é™…åº”ç”¨çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) are known to process information using a proficient internal language consistently, referred to as latent language, which may differ from the input or output languages. However, how the discrepancy between the latent language and the input and output language affects downstream task performance remains largely unexplored. While many studies research the latent language of LLMs, few address its importance in influencing task performance. In our study, we hypothesize that thinking in latent language consistently enhances downstream task performance. To validate this, our work varies the input prompt languages across multiple downstream tasks and analyzes the correlation between consistency in latent language and task performance. We create datasets consisting of questions from diverse domains such as translation and geo-culture, which are influenced by the choice of latent language. Experimental results across multiple LLMs on translation and geo-culture tasks, which are sensitive to the choice of language, indicate that maintaining consistency in latent language is not always necessary for optimal downstream task performance. This is because these models adapt their internal representations near the final layers to match the target language, reducing the impact of consistency on overall performance.

