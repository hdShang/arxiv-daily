---
layout: default
title: "rStar-Coder: Scaling Competitive Code Reasoning with a Large-Scale Verified Dataset"
---

# rStar-Coder: Scaling Competitive Code Reasoning with a Large-Scale Verified Dataset

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21297" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.21297v1</a>
  <a href="https://arxiv.org/pdf/2505.21297.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21297v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21297v1', 'rStar-Coder: Scaling Competitive Code Reasoning with a Large-Scale Verified Dataset')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Yifei Liu, Li Lyna Zhang, Yi Zhu, Bingcheng Dong, Xudong Zhou, Ning Shang, Fan Yang, Mao Yang

**ÂàÜÁ±ª**: cs.CL

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-27

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/microsoft/rStar)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫rStar-Coder‰ª•Ëß£ÂÜ≥Â§ßËßÑÊ®°‰ª£Á†ÅÊé®ÁêÜÊï∞ÊçÆÈõÜÁ®ÄÁº∫ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `‰ª£Á†ÅÊé®ÁêÜ` `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `Êï∞ÊçÆÈõÜÊûÑÂª∫` `ÊµãËØïÁî®‰æãÂêàÊàê` `ÈïøÊé®ÁêÜËß£ÂÜ≥ÊñπÊ°à`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂú®‰ª£Á†ÅÊé®ÁêÜÊñπÈù¢Èù¢‰∏¥È´òÈöæÂ∫¶Êï∞ÊçÆÈõÜÁ®ÄÁº∫ÁöÑÈóÆÈ¢òÔºåÂ∞§ÂÖ∂ÊòØÁº∫‰πèÂèØÈ™åËØÅÁöÑÊµãËØïÁî®‰æã„ÄÇ
2. Êú¨ÊñáÊèêÂá∫rStar-CoderÔºåÈÄöËøáÊûÑÂª∫Â§ßËßÑÊ®°È™åËØÅÊï∞ÊçÆÈõÜÂíåÂºïÂÖ•Êñ∞ÁöÑÊµãËØïÁî®‰æãÂêàÊàêÁÆ°ÈÅìÔºåÊèêÂçá‰ª£Á†ÅÊé®ÁêÜËÉΩÂäõ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºårStar-CoderÂú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞‰ºòÂºÇÔºåÂ∞§ÂÖ∂Âú®LiveCodeBenchÂíåUSA Computing Olympiad‰∏äÊòæËëóÊèêÈ´ò‰∫ÜÊ®°ÂûãÁöÑÂáÜÁ°ÆÁéá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÈöèÁùÄÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂú®‰ª£Á†ÅÊé®ÁêÜÈ¢ÜÂüüÁöÑÂ∫îÁî®ÔºåÁé∞ÊúâÊñπÊ≥ïÂèóÂà∞È´òÈöæÂ∫¶Êï∞ÊçÆÈõÜÁ®ÄÁº∫ÁöÑÈôêÂà∂ÔºåÂ∞§ÂÖ∂ÊòØÁº∫‰πèÂèØÈ™åËØÅÁöÑËæìÂÖ•ËæìÂá∫ÊµãËØïÁî®‰æã„ÄÇ‰∏∫Ê≠§ÔºåÊú¨ÊñáÊèêÂá∫rStar-CoderÔºåÊûÑÂª∫‰∫Ü‰∏Ä‰∏™ÂåÖÂê´418KÁ´ûËµõÁ∫ß‰ª£Á†ÅÈóÆÈ¢òÂíå580KÈïøÊé®ÁêÜËß£ÂÜ≥ÊñπÊ°àÁöÑÂ§ßËßÑÊ®°È™åËØÅÊï∞ÊçÆÈõÜ„ÄÇÈÄöËøá‰∏âÈ°πÊ†∏ÂøÉË¥°ÁåÆÔºåÊú¨ÊñáÊòæËëóÊèêÂçá‰∫ÜLLMÁöÑ‰ª£Á†ÅÊé®ÁêÜËÉΩÂäõÔºåÂåÖÊã¨Á≠ñÂàíÁ´û‰∫âÊÄßÁºñÁ®ãÈóÆÈ¢òÂíåËß£ÂÜ≥ÊñπÊ°à„ÄÅÂºïÂÖ•ÂèØÈù†ÁöÑËæìÂÖ•ËæìÂá∫ÊµãËØïÁî®‰æãÂêàÊàêÁÆ°ÈÅìÔºå‰ª•ÂèäÂ¢ûÂº∫È´òË¥®ÈáèÁöÑÈïøÊé®ÁêÜËß£ÂÜ≥ÊñπÊ°à„ÄÇÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºårStar-CoderÂú®Â§ö‰∏™‰ª£Á†ÅÊé®ÁêÜÂü∫ÂáÜ‰∏äË°®Áé∞‰ºòÂºÇÔºåÂ∞§ÂÖ∂Âú®LiveCodeBenchÂíåUSA Computing Olympiad‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂú®‰ª£Á†ÅÊé®ÁêÜ‰∏≠Èù¢‰∏¥ÁöÑÈ´òÈöæÂ∫¶Êï∞ÊçÆÈõÜÁ®ÄÁº∫ÈóÆÈ¢òÔºåÁé∞ÊúâÊñπÊ≥ïÁº∫‰πèÂèØÈ™åËØÅÁöÑËæìÂÖ•ËæìÂá∫ÊµãËØïÁî®‰æãÔºåÈôêÂà∂‰∫ÜÊ®°ÂûãÁöÑÊúâÊïàÊÄßÂíåÂèØÈù†ÊÄß„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÈÄöËøáÊûÑÂª∫‰∏Ä‰∏™Â§ßËßÑÊ®°ÁöÑÈ™åËØÅÊï∞ÊçÆÈõÜrStar-CoderÔºåÁªìÂêàÁ´û‰∫âÊÄßÁºñÁ®ãÈóÆÈ¢òÂíåÈïøÊé®ÁêÜËß£ÂÜ≥ÊñπÊ°àÔºåÊù•ÊèêÂçáLLMÁöÑ‰ª£Á†ÅÊé®ÁêÜËÉΩÂäõ„ÄÇËÆæËÆ°‰∫Ü‰∏Ä‰∏™ÂèØÈù†ÁöÑÊµãËØïÁî®‰æãÂêàÊàêÁÆ°ÈÅìÔºå‰ª•Á°Æ‰øùÁîüÊàêÁöÑÊµãËØïÁî®‰æãÁöÑÊúâÊïàÊÄßÂíåÂáÜÁ°ÆÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÈ¶ñÂÖàÔºåÁ≠ñÂàíÂíåÂêàÊàêÊñ∞ÁöÑÂèØËß£ÈóÆÈ¢òÔºõÂÖ∂Ê¨°ÔºåÈááÁî®‰∏âÊ≠•Ê≥ïÁîüÊàêËæìÂÖ•Âπ∂ËøõË°åÁõ∏‰∫íÈ™åËØÅ‰ª•Ê†áËÆ∞ËæìÂá∫ÔºõÊúÄÂêéÔºåÂ¢ûÂº∫ÈóÆÈ¢òÁöÑÈïøÊé®ÁêÜËß£ÂÜ≥ÊñπÊ°àÔºåÁ°Æ‰øùÂÖ∂ÁªèËøáÈ´òË¥®ÈáèÁöÑÊµãËØïÁî®‰æãÈ™åËØÅ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊú¨ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂºïÂÖ•‰∫Ü‰∏Ä‰∏™ÊúâÊïàÁöÑËæìÂÖ•ËæìÂá∫ÊµãËØïÁî®‰æãÂêàÊàêÁÆ°ÈÅìÔºåËÉΩÂ§üÂ∞ÜÁîüÊàêËøáÁ®ãËß£ËÄ¶‰∏∫ËæìÂÖ•ÁîüÊàêÂíåËæìÂá∫È™åËØÅ‰∏§‰∏™Èò∂ÊÆµÔºå‰ªéËÄåÊèêÈ´ò‰∫ÜÊµãËØïÁî®‰æãÁöÑË¥®ÈáèÂíåÂèØÈù†ÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÂèÇÊï∞ËÆæÁΩÆ‰∏äÔºåÈááÁî®‰∫ÜÂ§öÁßçÈöæÂ∫¶ÁöÑÊµãËØïÁî®‰æãÔºåÂπ∂ËÆæËÆ°‰∫ÜÁõ∏Â∫îÁöÑÊçüÂ§±ÂáΩÊï∞‰ª•‰ºòÂåñÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇÁΩëÁªúÁªìÊûÑ‰∏äÔºåÁªìÂêà‰∫ÜÈïøÊé®ÁêÜËß£ÂÜ≥ÊñπÊ°àÁöÑÁîüÊàê‰∏éÈ™åËØÅÔºåÁ°Æ‰øù‰∫ÜÊúÄÁªàËæìÂá∫ÁöÑÂáÜÁ°ÆÊÄßÂíåÊúâÊïàÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®ÂÆûÈ™å‰∏≠ÔºårStar-CoderÊòæËëóÊèêÂçá‰∫ÜQwenÊ®°ÂûãÁöÑÊÄßËÉΩÔºåQwen2.5-7BÂú®LiveCodeBench‰∏äÁöÑÂáÜÁ°ÆÁéá‰ªé17.4%ÊèêÂçáËá≥57.3%ÔºåQwen2.5-14B‰ªé23.3%ÊèêÂçáËá≥62.5%„ÄÇÂú®USA Computing Olympiad‰∏äÔºå7BÊ®°ÂûãÁöÑÂπ≥Âùápass@1ÂáÜÁ°ÆÁéáËææÂà∞16.15%ÔºåË∂ÖË∂ä‰∫ÜÂâçÊ≤øÁöÑQWQ-32BÊ®°Âûã„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

rStar-CoderÁöÑÁ†îÁ©∂ÊàêÊûúÂèØÂπøÊ≥õÂ∫îÁî®‰∫éÊïôËÇ≤„ÄÅËΩØ‰ª∂ÂºÄÂèëÂíåËá™Âä®ÂåñÊµãËØïÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÊèê‰æõÈ´òË¥®ÈáèÁöÑ‰ª£Á†ÅÊé®ÁêÜÊï∞ÊçÆÈõÜÔºåËÉΩÂ§üÂ∏ÆÂä©ÂºÄÂèëËÄÖÂíåÁ†îÁ©∂‰∫∫ÂëòÊõ¥Â•ΩÂú∞ËÆ≠ÁªÉÂíåËØÑ‰º∞Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºåÊèêÂçá‰ª£Á†ÅÁîüÊàêÂíåÁêÜËß£ÁöÑËÉΩÂäõÔºåÊé®Âä®Êô∫ËÉΩÁºñÁ®ãÂä©ÊâãÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Advancing code reasoning in large language models (LLMs) is fundamentally limited by the scarcity of high-difficulty datasets, especially those with verifiable input-output test cases necessary for rigorous solution validation at scale. We introduce rStar-Coder, which significantly improves LLM code reasoning capabilities by constructing a large-scale, verified dataset of 418K competition-level code problems, 580K long-reasoning solutions along with rich test cases of varying difficulty. This is achieved through three core contributions: (1) we curate competitive programming code problems and oracle solutions to synthesize new, solvable problems; (2) we introduce a reliable input-output test case synthesis pipeline that decouples the generation into a three-step input generation method and a mutual verification mechanism for effective output labeling; (3) we augment problems with high-quality, test-case-verified long-reasoning solutions. Extensive experiments on Qwen models (1.5B-14B) across various code reasoning benchmarks demonstrate the superiority of rStar-Coder dataset, achieving leading performance comparable to frontier reasoning LLMs with much smaller model sizes. On LiveCodeBench, rStar-Coder improves Qwen2.5-7B from 17.4% to an impressive 57.3%, and Qwen2.5-14B from 23.3% to 62.5%, surpassing o3-mini (low) by3.1%. On the more challenging USA Computing Olympiad, our 7B model achieves an average pass@1 accuracy of 16.15%, outperforming the frontier-level QWQ-32B. Code and the dataset will be released at https://github.com/microsoft/rStar.

