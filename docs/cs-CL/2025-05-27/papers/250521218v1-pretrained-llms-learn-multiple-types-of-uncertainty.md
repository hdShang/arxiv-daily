---
layout: default
title: Pretrained LLMs Learn Multiple Types of Uncertainty
---

# Pretrained LLMs Learn Multiple Types of Uncertainty

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21218" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21218v1</a>
  <a href="https://arxiv.org/pdf/2505.21218.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21218v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21218v1', 'Pretrained LLMs Learn Multiple Types of Uncertainty')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Roi Cohen, Omri Fahn, Gerard de Melo

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç ”ç©¶å¤§å‹è¯­è¨€æ¨¡å‹æ•æ‰å¤šç§ä¸ç¡®å®šæ€§ä»¥æå‡ä»»åŠ¡å‡†ç¡®æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ä¸ç¡®å®šæ€§æ•æ‰` `å¹»è§‰ç°è±¡` `é¢„è®­ç»ƒ` `æŒ‡ä»¤è°ƒä¼˜` `ä¿¡æ¯æ£€ç´¢` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆæ–‡æœ¬æ—¶å®¹æ˜“å‡ºç°å¹»è§‰ï¼Œå¯¼è‡´ä¸å‡†ç¡®çš„ä¿¡æ¯è¾“å‡ºï¼Œå½±å“å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å¯é æ€§ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–¹æ³•ï¼Œé€šè¿‡å°†ä¸ç¡®å®šæ€§è§†ä¸ºæ½œåœ¨ç©ºé—´ä¸­çš„çº¿æ€§æ¦‚å¿µï¼Œæ¢ç´¢LLMsåœ¨é¢„è®­ç»ƒé˜¶æ®µå¦‚ä½•æ•æ‰å¤šç§ä¸ç¡®å®šæ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ¨¡å‹çš„ä¿®æ­£é¢„æµ‹ä¸å…¶é¿å…é”™è¯¯ä¿¡æ¯çš„èƒ½åŠ›å­˜åœ¨ç›¸å…³æ€§ï¼Œå¹¶ä¸”æ¨¡å‹è§„æ¨¡å¯¹æ•æ‰ä¸ç¡®å®šæ€§æ²¡æœ‰æ˜¾è‘—å½±å“ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å› å…¶æ•æ‰ç°å®ä¸–ç•ŒçŸ¥è¯†çš„èƒ½åŠ›è€Œåœ¨ä¼—å¤šä¸‹æ¸¸ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹ä»ç„¶å®¹æ˜“å‡ºç°æ‰€è°“çš„å¹»è§‰ç°è±¡ï¼Œå¯¼è‡´ç”Ÿæˆä¸å‡†ç¡®çš„æ–‡æœ¬ã€‚æœ¬æ–‡ç ”ç©¶äº†LLMsåœ¨æœªç»è¿‡æ˜¾å¼è®­ç»ƒçš„æƒ…å†µä¸‹å¦‚ä½•æ•æ‰ä¸ç¡®å®šæ€§ã€‚æˆ‘ä»¬å‘ç°ï¼Œå¦‚æœå°†ä¸ç¡®å®šæ€§è§†ä¸ºæ¨¡å‹æ½œåœ¨ç©ºé—´ä¸­çš„çº¿æ€§æ¦‚å¿µï¼Œå®ƒå®é™…ä¸Šå¯ä»¥è¢«æ•æ‰åˆ°ã€‚å°½ç®¡è¿™ä¸€ç‚¹ä¸ç›´è§‚ï¼ŒLLMsä¼¼ä¹èƒ½å¤Ÿæ•æ‰å¤šç§ä¸åŒç±»å‹çš„ä¸ç¡®å®šæ€§ï¼Œè¿™å¯¹ç‰¹å®šä»»åŠ¡æˆ–åŸºå‡†çš„æ­£ç¡®æ€§é¢„æµ‹éå¸¸æœ‰ç”¨ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æä¾›äº†æ·±å…¥çš„ç»“æœï¼Œå±•ç¤ºäº†ä¿®æ­£é¢„æµ‹ä¸æ¨¡å‹é¿å…é”™è¯¯ä¿¡æ¯çš„èƒ½åŠ›ä¹‹é—´çš„ç›¸å…³æ€§ï¼Œä»¥åŠæ¨¡å‹è§„æ¨¡å¯¹æ•æ‰ä¸ç¡®å®šæ€§çš„å½±å“ç¼ºä¹æ˜¾è‘—æ€§ã€‚æœ€åï¼Œæˆ‘ä»¬è®¤ä¸ºé€šè¿‡æŒ‡ä»¤è°ƒä¼˜æˆ–[IDK]-tokenè°ƒä¼˜å°†ä¸ç¡®å®šæ€§ç±»å‹ç»Ÿä¸€ä¸ºå•ä¸€ç±»å‹ï¼Œæœ‰åŠ©äºæ¨¡å‹çš„æ­£ç¡®æ€§é¢„æµ‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆæ–‡æœ¬æ—¶çš„å¹»è§‰ç°è±¡ï¼Œæ¢è®¨å…¶åœ¨æœªæ˜¾å¼è®­ç»ƒæƒ…å†µä¸‹å¦‚ä½•æ•æ‰ä¸ç¡®å®šæ€§ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆåˆ©ç”¨è¿™ä¸€ç‰¹æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å°†ä¸ç¡®å®šæ€§è§†ä¸ºæ¨¡å‹æ½œåœ¨ç©ºé—´ä¸­çš„çº¿æ€§æ¦‚å¿µï¼Œç ”ç©¶LLMså¦‚ä½•åœ¨é¢„è®­ç»ƒé˜¶æ®µæ•æ‰å¤šç§ä¸ç¡®å®šæ€§ç±»å‹ï¼Œä»¥æé«˜å…¶åœ¨ç‰¹å®šä»»åŠ¡ä¸­çš„æ­£ç¡®æ€§é¢„æµ‹èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨äº†é¢„è®­ç»ƒçš„LLMsä½œä¸ºåŸºç¡€ï¼Œåˆ†æå…¶åœ¨ä¸åŒä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œé‡ç‚¹å…³æ³¨ä¸ç¡®å®šæ€§ç±»å‹çš„æ•æ‰ä¸ä¿®æ­£é¢„æµ‹çš„ç›¸å…³æ€§ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€æ¨¡å‹è®­ç»ƒã€æ€§èƒ½è¯„ä¼°ç­‰ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„åˆ›æ–°åœ¨äºæ­ç¤ºäº†LLMsèƒ½å¤Ÿæ•æ‰å¤šç§ä¸ç¡®å®šæ€§ç±»å‹ï¼Œå¹¶ä¸”é€šè¿‡æŒ‡ä»¤è°ƒä¼˜æˆ–[IDK]-tokenè°ƒä¼˜å°†è¿™äº›ä¸ç¡®å®šæ€§ç»Ÿä¸€ä¸ºå•ä¸€ç±»å‹ï¼Œä»è€Œæå‡æ¨¡å‹çš„æ­£ç¡®æ€§é¢„æµ‹èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ¨¡å‹çš„ä¿®æ­£é¢„æµ‹èƒ½åŠ›ï¼ŒåŒæ—¶å¯¹æ¨¡å‹çš„è§„æ¨¡è¿›è¡Œäº†ç³»ç»Ÿæ€§åˆ†æï¼Œå‘ç°å…¶å¯¹æ•æ‰ä¸ç¡®å®šæ€§çš„å½±å“ä¸æ˜¾è‘—ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ¨¡å‹åœ¨ä¿®æ­£é¢„æµ‹æ–¹é¢ä¸é¿å…é”™è¯¯ä¿¡æ¯çš„èƒ½åŠ›å­˜åœ¨æ˜¾è‘—ç›¸å…³æ€§ã€‚æ­¤å¤–ï¼Œæ¨¡å‹è§„æ¨¡å¯¹æ•æ‰ä¸ç¡®å®šæ€§çš„å½±å“ä¸æ˜¾è‘—ï¼Œè¡¨æ˜åœ¨ä¼˜åŒ–æ¨¡å‹æ—¶å¯ä»¥å…³æ³¨å…¶ä»–å› ç´ ã€‚é€šè¿‡æŒ‡ä»¤è°ƒä¼˜æˆ–[IDK]-tokenè°ƒä¼˜ï¼Œæ¨¡å‹çš„æ­£ç¡®æ€§é¢„æµ‹èƒ½åŠ›å¾—åˆ°äº†æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€å¯¹è¯ç³»ç»Ÿå’Œä¿¡æ¯æ£€ç´¢ç­‰ã€‚é€šè¿‡æé«˜å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆæ–‡æœ¬æ—¶çš„å‡†ç¡®æ€§å’Œå¯é æ€§ï¼Œèƒ½å¤Ÿä¸ºç”¨æˆ·æä¾›æ›´å¯ä¿¡çš„ä¿¡æ¯ï¼Œå‡å°‘è¯¯å¯¼æ€§å†…å®¹çš„ä¼ æ’­ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œç¤¾ä¼šå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models are known to capture real-world knowledge, allowing them to excel in many downstream tasks. Despite recent advances, these models are still prone to what are commonly known as hallucinations, causing them to emit unwanted and factually incorrect text. In this work, we study how well LLMs capture uncertainty, without explicitly being trained for that. We show that, if considering uncertainty as a linear concept in the model's latent space, it might indeed be captured, even after only pretraining. We further show that, though unintuitive, LLMs appear to capture several different types of uncertainty, each of which can be useful to predict the correctness for a specific task or benchmark. Furthermore, we provide in-depth results such as demonstrating a correlation between our correction prediction and the model's ability to abstain from misinformation using words, and the lack of impact of model scaling for capturing uncertainty. Finally, we claim that unifying the uncertainty types as a single one using instruction-tuning or [IDK]-token tuning is helpful for the model in terms of correctness prediction.

