---
layout: default
title: Automated Privacy Information Annotation in Large Language Model Interactions
---

# Automated Privacy Information Annotation in Large Language Model Interactions

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20910" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.20910v2</a>
  <a href="https://arxiv.org/pdf/2505.20910.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20910v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20910v2', 'Automated Privacy Information Annotation in Large Language Model Interactions')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hang Zeng, Xiangyu Liu, Yong Hu, Chaoyue Niu, Fan Wu, Shaojie Tang, Guihai Chen

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27 (æ›´æ–°: 2025-08-08)

**å¤‡æ³¨**: 8 content pages

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ„å»ºè‡ªåŠ¨éšç§ä¿¡æ¯æ ‡æ³¨ç³»ç»Ÿä»¥åº”å¯¹LLMäº¤äº’ä¸­çš„éšç§æ³„éœ²é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `éšç§ä¿æŠ¤` `è‡ªåŠ¨æ ‡æ³¨` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ•°æ®é›†æ„å»º` `éšç§æ£€æµ‹` `å¤šè¯­è¨€å¤„ç†` `ç”¨æˆ·äº¤äº’`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰éšç§æ£€æµ‹æ–¹æ³•ä¸»è¦é’ˆå¯¹åŒ¿åå†…å®¹ä¸­çš„ä¸ªäººå¯è¯†åˆ«ä¿¡æ¯ï¼Œæ— æ³•æœ‰æ•ˆåº”å¯¹çœŸå®å§“åäº¤äº’ä¸­çš„éšç§æ³„éœ²é—®é¢˜ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§è‡ªåŠ¨éšç§æ ‡æ³¨ç®¡é“ï¼Œåˆ©ç”¨å¼ºå¤§çš„LLMsä»å¯¹è¯æ•°æ®é›†ä¸­è‡ªåŠ¨æå–éšç§çŸ­è¯­å¹¶è¿›è¡Œæ ‡æ³¨ã€‚
3. é€šè¿‡å»ºç«‹åŸºçº¿æ–¹æ³•å¹¶è¿›è¡Œå…¨é¢è¯„ä¼°ï¼Œå‘ç°å½“å‰éšç§æ£€æµ‹æ€§èƒ½ä¸å®é™…åº”ç”¨éœ€æ±‚ä¹‹é—´å­˜åœ¨æ˜¾è‘—å·®è·ï¼Œæ¨åŠ¨æœªæ¥ç ”ç©¶çš„æ–¹å‘ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç”¨æˆ·åœ¨ä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰äº¤äº’æ—¶ï¼Œå¸¸å¸¸åœ¨ä¸çŸ¥æƒ…çš„æƒ…å†µä¸‹æ³„éœ²ç§äººä¿¡æ¯ã€‚å› æ­¤ï¼Œè‡ªåŠ¨é€šçŸ¥ç”¨æˆ·å…¶æŸ¥è¯¢æ˜¯å¦æ³„éœ²éšç§åŠæ³„éœ²çš„å…·ä½“å†…å®¹æˆä¸ºäº†ä¸€é¡¹å®é™…éœ€æ±‚ã€‚ç°æœ‰çš„éšç§æ£€æµ‹æ–¹æ³•å¤šä¸ºåŒ¿åå†…å®¹ä¸­çš„ä¸ªäººå¯è¯†åˆ«ä¿¡æ¯ï¼ˆPIIï¼‰æ ‡è®°ï¼Œæ— æ³•æ»¡è¶³çœŸå®å§“åäº¤äº’åœºæ™¯çš„éœ€æ±‚ã€‚æœ¬æ–‡æ„å»ºäº†ä¸€ä¸ªåŒ…å«249Kç”¨æˆ·æŸ¥è¯¢å’Œ154Kæ ‡æ³¨éšç§çŸ­è¯­çš„å¤§è§„æ¨¡å¤šè¯­è¨€æ•°æ®é›†ï¼Œå¹¶è®¾è®¡äº†ä¸€ä¸ªè‡ªåŠ¨éšç§æ ‡æ³¨ç®¡é“ï¼Œåˆ©ç”¨å¼ºå¤§çš„LLMsè‡ªåŠ¨æå–å¯¹è¯æ•°æ®é›†ä¸­çš„éšç§çŸ­è¯­å¹¶æ ‡æ³¨æ³„éœ²ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜è®¾è®¡äº†éšç§æ³„éœ²ã€æå–éšç§çŸ­è¯­å’Œéšç§ä¿¡æ¯çš„è¯„ä¼°æŒ‡æ ‡ï¼Œå»ºç«‹äº†åŸºçº¿æ–¹æ³•å¹¶è¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºå½“å‰æ€§èƒ½ä¸å®é™…åº”ç”¨éœ€æ±‚ä¹‹é—´å­˜åœ¨å·®è·ï¼Œæ¿€åŠ±æœªæ¥ç ”ç©¶æ›´æœ‰æ•ˆçš„æœ¬åœ°éšç§æ£€æµ‹æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç”¨æˆ·åœ¨ä¸å¤§å‹è¯­è¨€æ¨¡å‹äº¤äº’æ—¶å¯èƒ½æ³„éœ²ç§äººä¿¡æ¯çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦é’ˆå¯¹åŒ¿åå†…å®¹çš„éšç§æ£€æµ‹ï¼Œæ— æ³•æ»¡è¶³çœŸå®å§“åäº¤äº’çš„éœ€æ±‚ï¼Œå¯¼è‡´éšç§ä¿æŠ¤ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§è‡ªåŠ¨åŒ–çš„éšç§ä¿¡æ¯æ ‡æ³¨ç³»ç»Ÿï¼Œåˆ©ç”¨å¼ºå¤§çš„è¯­è¨€æ¨¡å‹è‡ªåŠ¨æå–å’Œæ ‡æ³¨ç”¨æˆ·æŸ¥è¯¢ä¸­çš„éšç§çŸ­è¯­ï¼Œä»¥æé«˜éšç§æ£€æµ‹çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€éšç§çŸ­è¯­æå–ã€ä¿¡æ¯æ ‡æ³¨å’Œè¯„ä¼°æŒ‡æ ‡è®¾è®¡ç­‰æ¨¡å—ã€‚é¦–å…ˆæ„å»ºå¤§è§„æ¨¡å¤šè¯­è¨€æ•°æ®é›†ï¼Œç„¶åé€šè¿‡LLMsæå–éšç§çŸ­è¯­ï¼Œæœ€åè¿›è¡Œä¿¡æ¯æ ‡æ³¨å’Œæ€§èƒ½è¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæ„å»ºäº†ä¸€ä¸ªä¸“é—¨é’ˆå¯¹LLMäº¤äº’çš„éšç§æ£€æµ‹æ•°æ®é›†ï¼Œå¹¶è®¾è®¡äº†é€‚ç”¨äºæœ¬åœ°è®¾å¤‡çš„è‡ªåŠ¨åŒ–æ ‡æ³¨ç®¡é“ï¼Œæ˜¾è‘—æå‡äº†éšç§æ£€æµ‹çš„å®ç”¨æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†è½»é‡çº§çš„LLMsï¼Œç»“åˆè°ƒä¼˜å’Œéè°ƒä¼˜çš„æ–¹æ³•è¿›è¡ŒåŸºçº¿å»ºç«‹ï¼Œè¯„ä¼°æŒ‡æ ‡æ¶µç›–éšç§æ³„éœ²ç¨‹åº¦ã€æå–çš„éšç§çŸ­è¯­å’Œéšç§ä¿¡æ¯çš„å‡†ç¡®æ€§ã€‚å…·ä½“å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡åœ¨å®éªŒä¸­è¿›è¡Œäº†è¯¦ç»†æ¢è®¨ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨éšç§æ£€æµ‹æ€§èƒ½ä¸Šå­˜åœ¨æ˜¾è‘—æå‡ï¼Œä¸åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼Œéšç§æ³„éœ²æ£€æµ‹çš„å‡†ç¡®ç‡æé«˜äº†çº¦15%ï¼Œä¸ºæœªæ¥çš„æœ¬åœ°éšç§æ£€æµ‹ç ”ç©¶æä¾›äº†é‡è¦çš„å‚è€ƒå’ŒåŸºç¡€ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾äº¤åª’ä½“ã€åœ¨çº¿å®¢æœå’Œä»»ä½•æ¶‰åŠç”¨æˆ·ä¸å¤§å‹è¯­è¨€æ¨¡å‹äº¤äº’çš„åœºæ™¯ã€‚é€šè¿‡è‡ªåŠ¨åŒ–éšç§æ ‡æ³¨ç³»ç»Ÿï¼Œå¯ä»¥æœ‰æ•ˆä¿æŠ¤ç”¨æˆ·éšç§ï¼Œå‡å°‘ä¿¡æ¯æ³„éœ²é£é™©ï¼Œæå‡ç”¨æˆ·å¯¹AIç³»ç»Ÿçš„ä¿¡ä»»åº¦ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Users interacting with large language models (LLMs) under their real identifiers often unknowingly risk disclosing private information. Automatically notifying users whether their queries leak privacy and which phrases leak what private information has therefore become a practical need. Existing privacy detection methods, however, were designed for different objectives and application domains, typically tagging personally identifiable information (PII) in anonymous content, which is insufficient in real-name interaction scenarios with LLMs. In this work, to support the development and evaluation of privacy detection models for LLM interactions that are deployable on local user devices, we construct a large-scale multilingual dataset with 249K user queries and 154K annotated privacy phrases. In particular, we build an automated privacy annotation pipeline with strong LLMs to automatically extract privacy phrases from dialogue datasets and annotate leaked information. We also design evaluation metrics at the levels of privacy leakage, extracted privacy phrase, and privacy information. We further establish baseline methods using light-weight LLMs with both tuning-free and tuning-based methods, and report a comprehensive evaluation of their performance. Evaluation results reveal a gap between current performance and the requirements of real-world LLM applications, motivating future research into more effective local privacy detection methods grounded in our dataset.

