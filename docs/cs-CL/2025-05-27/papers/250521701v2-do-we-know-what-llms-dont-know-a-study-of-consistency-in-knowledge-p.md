---
layout: default
title: Do We Know What LLMs Don't Know? A Study of Consistency in Knowledge Probing
---

# Do We Know What LLMs Don't Know? A Study of Consistency in Knowledge Probing

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21701" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21701v2</a>
  <a href="https://arxiv.org/pdf/2505.21701.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21701v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21701v2', 'Do We Know What LLMs Don\'t Know? A Study of Consistency in Knowledge Probing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Raoyuan Zhao, Abdullatif KÃ¶ksal, Ali Modarressi, Michael A. Hedderich, Hinrich SchÃ¼tze

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27 (æ›´æ–°: 2025-05-30)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ–°æ–¹æ³•è¯†åˆ«å¤§å‹è¯­è¨€æ¨¡å‹çŸ¥è¯†ç›²åŒºçš„ä¸€è‡´æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `çŸ¥è¯†æ¢æµ‹` `ä¸€è‡´æ€§è¯„ä¼°` `è¾“å…¥æ‰°åŠ¨` `äººå·¥æ™ºèƒ½å¯é æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çŸ¥è¯†æ¢æµ‹æ–¹æ³•å­˜åœ¨æ˜¾è‘—çš„ä¸ä¸€è‡´æ€§ï¼Œå¯¼è‡´å¯¹å¤§å‹è¯­è¨€æ¨¡å‹çŸ¥è¯†ç›²åŒºçš„è¯†åˆ«ä¸å¯é ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºè¾“å…¥å˜ä½“å’Œå®šé‡æŒ‡æ ‡çš„æ–°è¯„ä¼°è¿‡ç¨‹ï¼Œä»¥æ­ç¤ºçŸ¥è¯†æ¢æµ‹ä¸­çš„ä¸ä¸€è‡´æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŒä¸€æ–¹æ³•å†…å’Œä¸åŒæ–¹æ³•é—´çš„çŸ¥è¯†æ¢æµ‹ä¸€è‡´æ€§å‡å¾ˆä½ï¼Œå¼ºè°ƒäº†æ”¹è¿›æ¢æµ‹æ¡†æ¶çš„å¿…è¦æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¯é æ€§å—åˆ°å…¶å¹»è§‰å€¾å‘çš„ä¸¥é‡å½±å“ï¼Œå› æ­¤éœ€è¦ç²¾ç¡®è¯†åˆ«å…¶çŸ¥è¯†ç›²åŒºã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºè¾“å…¥å˜ä½“å’Œå®šé‡æŒ‡æ ‡çš„æ–°è¿‡ç¨‹æ¥è¯„ä¼°ç°æœ‰çš„çŸ¥è¯†æ¢æµ‹æ–¹æ³•ã€‚ç ”ç©¶æ­ç¤ºäº†çŸ¥è¯†æ¢æµ‹ä¸­çš„ä¸¤ç§ä¸ä¸€è‡´æ€§ç»´åº¦ï¼šåŒä¸€æ–¹æ³•å†…çš„ä¸ä¸€è‡´æ€§å’Œä¸åŒæ–¹æ³•é—´çš„ä¸ä¸€è‡´æ€§ã€‚å…·ä½“è€Œè¨€ï¼Œå¾®å°çš„éè¯­ä¹‰æ‰°åŠ¨ä¼šå¯¼è‡´åŒä¸€æ¢æµ‹æ–¹æ³•ä¸­æ£€æµ‹åˆ°çš„çŸ¥è¯†ç›²åŒºå‡ºç°æ˜¾è‘—å·®å¼‚ï¼Œè€Œä¸åŒæ¢æµ‹æ–¹æ³•ä¹‹é—´çš„å†³ç­–ä¸€è‡´æ€§ä½è‡³7%ã€‚è¿™äº›å‘ç°æŒ‘æˆ˜äº†ç°æœ‰çš„æ¢æµ‹æ–¹æ³•ï¼Œå¼ºè°ƒäº†å¯¹æŠ—æ‰°åŠ¨çš„ç¨³å¥æ¢æµ‹æ¡†æ¶çš„è¿«åˆ‡éœ€æ±‚ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹çŸ¥è¯†æ¢æµ‹æ–¹æ³•çš„ä¸ä¸€è‡´æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨ä¸åŒè¾“å…¥å’Œæ¢æµ‹æ‰‹æ®µä¸‹ï¼Œå¾€å¾€æ— æ³•ç¨³å®šåœ°è¯†åˆ«æ¨¡å‹çš„çŸ¥è¯†ç›²åŒºï¼Œå¯¼è‡´ç»“æœä¸å¯é ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼•å…¥è¾“å…¥å˜ä½“å’Œå®šé‡è¯„ä¼°æŒ‡æ ‡ï¼Œç³»ç»Ÿæ€§åœ°åˆ†æçŸ¥è¯†æ¢æµ‹æ–¹æ³•çš„ä¸€è‡´æ€§é—®é¢˜ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨æ­ç¤ºæ¢æµ‹è¿‡ç¨‹ä¸­çš„æ½œåœ¨ä¸ç¨³å®šæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬è¾“å…¥å˜ä½“ç”Ÿæˆã€çŸ¥è¯†æ¢æµ‹æ‰§è¡Œå’Œä¸€è‡´æ€§è¯„ä¼°ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡å¯¹è¾“å…¥è¿›è¡Œå¾®å°æ‰°åŠ¨ç”Ÿæˆå˜ä½“ï¼›ç„¶åï¼Œåº”ç”¨ä¸åŒçš„æ¢æµ‹æ–¹æ³•è¿›è¡ŒçŸ¥è¯†è¯„ä¼°ï¼›æœ€åï¼Œåˆ©ç”¨å®šé‡æŒ‡æ ‡åˆ†ææ¢æµ‹ç»“æœçš„ä¸€è‡´æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºç³»ç»Ÿæ€§åœ°æ­ç¤ºäº†åŒä¸€æ–¹æ³•å†…å’Œä¸åŒæ–¹æ³•é—´çš„çŸ¥è¯†æ¢æµ‹ä¸ä¸€è‡´æ€§ï¼Œç‰¹åˆ«æ˜¯é€šè¿‡ç®€å•çš„è¾“å…¥æ‰°åŠ¨å¯ä»¥æ˜¾è‘—å½±å“æ¢æµ‹ç»“æœã€‚è¿™ä¸€å‘ç°ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºå¼ºè°ƒäº†è¾“å…¥å¯¹æ¢æµ‹ç»“æœçš„æ•æ„Ÿæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨äº†å¤šç§è¾“å…¥æ‰°åŠ¨æ–¹å¼ï¼Œå¦‚é€‰é¡¹æ´—ç‰Œç­‰ï¼Œå¹¶è®¾è®¡äº†ç›¸åº”çš„å®šé‡è¯„ä¼°æŒ‡æ ‡ï¼Œä»¥è¡¡é‡æ¢æµ‹ç»“æœçš„ä¸€è‡´æ€§ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡åˆ™ä¾èµ–äºæ‰€é€‰çš„æ¢æµ‹æ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå†³ç­–ä¸€è‡´æ€§åœ¨ä¸åŒæ–¹æ³•é—´ä½è‡³7%ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŒä¸€æ¢æµ‹æ–¹æ³•å†…çš„çŸ¥è¯†ç›²åŒºä¸€è‡´æ€§ä½è‡³40%ï¼Œè€Œä¸åŒæ¢æµ‹æ–¹æ³•é—´çš„å†³ç­–ä¸€è‡´æ€§ä»…ä¸º7%ã€‚è¿™äº›æ•°æ®çªæ˜¾äº†ç°æœ‰æ¢æµ‹æ–¹æ³•çš„å±€é™æ€§ï¼Œå¹¶å¼ºè°ƒäº†å¯¹æŠ—æ‰°åŠ¨çš„ç¨³å¥æ¢æµ‹æ¡†æ¶çš„å¿…è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤§å‹è¯­è¨€æ¨¡å‹çš„å¼€å‘ä¸è¯„ä¼°ã€äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„å¯é æ€§æµ‹è¯•ä»¥åŠæ•™è‚²é¢†åŸŸçš„æ™ºèƒ½è¾…å¯¼ç³»ç»Ÿã€‚é€šè¿‡è¯†åˆ«å’Œä¿®å¤çŸ¥è¯†ç›²åŒºï¼Œå¯ä»¥æå‡æ¨¡å‹çš„å®é™…åº”ç”¨ä»·å€¼å’Œç”¨æˆ·ä¿¡ä»»åº¦ï¼Œæ¨åŠ¨æ›´å®‰å…¨çš„AIæŠ€æœ¯å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The reliability of large language models (LLMs) is greatly compromised by their tendency to hallucinate, underscoring the need for precise identification of knowledge gaps within LLMs. Various methods for probing such gaps exist, ranging from calibration-based to prompting-based methods. To evaluate these probing methods, in this paper, we propose a new process based on using input variations and quantitative metrics. Through this, we expose two dimensions of inconsistency in knowledge gap probing. (1) Intra-method inconsistency: Minimal non-semantic perturbations in prompts lead to considerable variance in detected knowledge gaps within the same probing method; e.g., the simple variation of shuffling answer options can decrease agreement to around 40%. (2) Cross-method inconsistency: Probing methods contradict each other on whether a model knows the answer. Methods are highly inconsistent -- with decision consistency across methods being as low as 7% -- even though the model, dataset, and prompt are all the same. These findings challenge existing probing methods and highlight the urgent need for perturbation-robust probing frameworks.

