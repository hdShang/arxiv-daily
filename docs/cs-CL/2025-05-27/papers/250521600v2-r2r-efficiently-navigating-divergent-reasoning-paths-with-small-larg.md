---
layout: default
title: R2R: Efficiently Navigating Divergent Reasoning Paths with Small-Large Model Token Routing
---

# R2R: Efficiently Navigating Divergent Reasoning Paths with Small-Large Model Token Routing

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21600" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21600v2</a>
  <a href="https://arxiv.org/pdf/2505.21600.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21600v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21600v2', 'R2R: Efficiently Navigating Divergent Reasoning Paths with Small-Large Model Token Routing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Tianyu Fu, Yi Ge, Yichen You, Enshu Liu, Zhihang Yuan, Guohao Dai, Shengen Yan, Huazhong Yang, Yu Wang

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG, cs.PF

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27 (æ›´æ–°: 2025-11-05)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/thu-nics/R2R)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºR2Rä»¥é«˜æ•ˆå¯¼èˆªè¯­è¨€æ¨¡å‹æ¨ç†è·¯å¾„**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å°å‹è¯­è¨€æ¨¡å‹` `æ¨ç†æ•ˆç‡` `tokenè·¯ç”±` `è‡ªåŠ¨æ•°æ®ç”Ÿæˆ` `æ€§èƒ½æå‡` `è®¡ç®—èµ„æºä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¨ç†èƒ½åŠ›ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä½†å…¶é«˜æ¨ç†å¼€é”€é™åˆ¶äº†å®é™…åº”ç”¨ã€‚
2. R2Ræ–¹æ³•é€šè¿‡è¯†åˆ«å¹¶ä»…å¯¹å…³é”®çš„åˆ†æ­§tokenä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œä»è€Œæé«˜äº†æ¨ç†æ•ˆç‡ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒR2Råœ¨5.6Bå‚æ•°ä¸‹çš„å‡†ç¡®ç‡æ¯”R1-7Bé«˜å‡º1.6å€ï¼Œå¹¶ä¸”åœ¨é€Ÿåº¦ä¸Šæ¯”R1-32Bå¿«2.8å€ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ¨ç†èƒ½åŠ›ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†å…¶æ¨ç†å¼€é”€å·¨å¤§ï¼Œç»™éƒ¨ç½²å¸¦æ¥äº†æŒ‘æˆ˜ã€‚å°½ç®¡è’¸é¦çš„å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰æ˜¾è‘—æé«˜äº†æ•ˆç‡ï¼Œä½†ç”±äºæ— æ³•è·ŸéšLLMsçš„æ¨ç†è·¯å¾„ï¼Œå…¶æ€§èƒ½å—åˆ°å½±å“ã€‚æˆ‘ä»¬å‘ç°ï¼Œåªæœ‰å°‘é‡çš„tokençœŸæ­£å¯¼è‡´äº†LLMsä¸SLMsä¹‹é—´çš„æ¨ç†è·¯å¾„åˆ†æ­§ã€‚åŸºäºè¿™ä¸€å‘ç°ï¼Œæˆ‘ä»¬æå‡ºäº†R2Rï¼Œä¸€ç§ç¥ç»tokenè·¯ç”±æ–¹æ³•ï¼Œä»…å¯¹è¿™äº›å…³é”®çš„åˆ†æ­§tokenä½¿ç”¨LLMsï¼Œè€Œå°†å¤§éƒ¨åˆ†tokenç”Ÿæˆç•™ç»™SLMsã€‚æˆ‘ä»¬è¿˜å¼€å‘äº†è‡ªåŠ¨æ•°æ®ç”Ÿæˆç®¡é“ï¼Œè¯†åˆ«åˆ†æ­§tokenå¹¶ç”Ÿæˆtokençº§è·¯ç”±æ ‡ç­¾ä»¥è®­ç»ƒè½»é‡çº§è·¯ç”±å™¨ã€‚R2Råœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†ç°æœ‰æ¨¡å‹çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ¨ç†æ—¶çš„é«˜å¼€é”€é—®é¢˜ã€‚ç°æœ‰çš„å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰è™½ç„¶æé«˜äº†æ•ˆç‡ï¼Œä½†åœ¨æ¨ç†è·¯å¾„ä¸Šæ— æ³•è·ŸéšLLMsï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬å‘ç°ï¼ŒLLMsä¸SLMsä¹‹é—´çš„æ¨ç†è·¯å¾„åˆ†æ­§ä¸»è¦é›†ä¸­åœ¨å°‘é‡tokenä¸Šã€‚R2Ræ–¹æ³•é€šè¿‡é€‰æ‹©æ€§åœ°å¯¹è¿™äº›å…³é”®tokenä½¿ç”¨LLMsï¼Œä¼˜åŒ–äº†æ¨ç†è¿‡ç¨‹ï¼Œå‡å°‘äº†ä¸å¿…è¦çš„è®¡ç®—ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šR2Rçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸€ä¸ªè‡ªåŠ¨æ•°æ®ç”Ÿæˆç®¡é“ï¼Œç”¨äºè¯†åˆ«åˆ†æ­§tokenå¹¶ç”Ÿæˆç›¸åº”çš„è·¯ç”±æ ‡ç­¾ã€‚è¯¥æ¡†æ¶ç”±è½»é‡çº§è·¯ç”±å™¨å’ŒSLMsç»„æˆï¼Œè·¯ç”±å™¨è´Ÿè´£å†³å®šå“ªäº›tokenéœ€è¦ä½¿ç”¨LLMsè¿›è¡Œå¤„ç†ã€‚

**å…³é”®åˆ›æ–°**ï¼šR2Rçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶tokenè·¯ç”±æœºåˆ¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåŒºåˆ†å…³é”®çš„åˆ†æ­§tokenä¸å…¶ä»–tokenï¼Œä»è€Œåœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶æ˜¾è‘—é™ä½æ¨ç†å¼€é”€ã€‚è¿™ä¸€è®¾è®¡ä¸ä¼ ç»Ÿæ–¹æ³•çš„æ ¹æœ¬åŒºåˆ«åœ¨äºå…¶é€‰æ‹©æ€§ä½¿ç”¨LLMsã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨R2Rä¸­ï¼Œå…³é”®å‚æ•°è®¾ç½®åŒ…æ‹¬è·¯ç”±å™¨çš„è®­ç»ƒæ•°æ®ç”Ÿæˆç­–ç•¥å’ŒæŸå¤±å‡½æ•°è®¾è®¡ã€‚æ­¤å¤–ï¼Œç½‘ç»œç»“æ„ä¸Šï¼Œè½»é‡çº§è·¯ç”±å™¨ä¸SLMsçš„ç»“åˆä½¿å¾—æ•´ä½“æ¨¡å‹åœ¨æ¨ç†æ—¶æ›´åŠ é«˜æ•ˆã€‚é€šè¿‡è¿™äº›è®¾è®¡ï¼ŒR2Rå®ç°äº†åœ¨å‡†ç¡®ç‡å’Œé€Ÿåº¦ä¸Šçš„åŒé‡æå‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

R2Råœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œå¹³å‡æ¿€æ´»å‚æ•°å¤§å°ä¸º5.6Bï¼Œå‡†ç¡®ç‡æ¯”R1-7Bé«˜å‡º1.6å€ï¼Œç”šè‡³è¶…è¶Šäº†R1-14Bæ¨¡å‹ã€‚åŒæ—¶ï¼Œç›¸æ¯”äºR1-32Bï¼ŒR2Råœ¨æ¨ç†é€Ÿåº¦ä¸Šå®ç°äº†2.8å€çš„æå‡ï¼Œæ˜¾è‘—æ¨è¿›äº†æµ‹è¯•æ—¶é—´çš„æ‰©å±•æ•ˆç‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

R2Ræ–¹æ³•å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶åœ¨éœ€è¦é«˜æ•ˆæ¨ç†çš„åœºæ™¯ä¸­ï¼Œå¦‚æ™ºèƒ½é—®ç­”ã€ç¼–ç¨‹è¾…åŠ©å’Œå¤æ‚æ•°å­¦é—®é¢˜æ±‚è§£ç­‰é¢†åŸŸã€‚å…¶é«˜æ•ˆçš„æ¨ç†èƒ½åŠ›å¯ä»¥æ¨åŠ¨å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„æ™®åŠï¼Œé™ä½è®¡ç®—èµ„æºæ¶ˆè€—ï¼Œæé«˜ç”¨æˆ·ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) achieve impressive reasoning capabilities at the cost of substantial inference overhead, posing substantial deployment challenges. Although distilled Small Language Models (SLMs) significantly enhance efficiency, their performance suffers as they fail to follow LLMs' reasoning paths. Luckily, we reveal that only a small fraction of tokens genuinely diverge reasoning paths between LLMs and SLMs. Most generated tokens are either identical or exhibit neutral differences, such as minor variations in abbreviations or expressions. Leveraging this insight, we introduce **Roads to Rome (R2R)**, a neural token routing method that selectively utilizes LLMs only for these critical, path-divergent tokens, while leaving the majority of token generation to the SLM. We also develop an automatic data generation pipeline that identifies divergent tokens and generates token-level routing labels to train the lightweight router. We apply R2R to combine R1-1.5B and R1-32B models from the DeepSeek family, and evaluate on challenging math, coding, and QA benchmarks. With an average activated parameter size of 5.6B, R2R surpasses the average accuracy of R1-7B by 1.6x, outperforming even the R1-14B model. Compared to R1-32B, it delivers a 2.8x wall-clock speedup with comparable performance, advancing the Pareto frontier of test-time scaling efficiency. Our code is available at https://github.com/thu-nics/R2R.

