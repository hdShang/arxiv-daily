---
layout: default
title: Towards Better Instruction Following Retrieval Models
---

# Towards Better Instruction Following Retrieval Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21439" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21439v1</a>
  <a href="https://arxiv.org/pdf/2505.21439.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21439v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21439v1', 'Towards Better Instruction Following Retrieval Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuchen Zhuang, Aaron Trinh, Rushi Qiang, Haotian Sun, Chao Zhang, Hanjun Dai, Bo Dai

**åˆ†ç±»**: cs.CL, cs.IR

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27

**å¤‡æ³¨**: Retrieval Models, Embedding, Retrieval with Instructions

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºInF-IRä»¥è§£å†³æŒ‡ä»¤è·Ÿéšä¿¡æ¯æ£€ç´¢æ¨¡å‹çš„ä¸è¶³**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¿¡æ¯æ£€ç´¢` `æŒ‡ä»¤è·Ÿéš` `å¯¹æ¯”å­¦ä¹ ` `è¯­æ–™åº“æ„å»º` `æ¨¡å‹ä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ä¿¡æ¯æ£€ç´¢æ¨¡å‹ä¸»è¦ä¾èµ–æ ‡å‡†çš„<æŸ¥è¯¢, æ®µè½>å¯¹ï¼Œéš¾ä»¥æœ‰æ•ˆå¤„ç†ç”¨æˆ·çš„æŒ‡ä»¤ï¼Œå¯¼è‡´æ£€ç´¢æ•ˆæœä¸ä½³ã€‚
2. æœ¬æ–‡æå‡ºInF-IRè¯­æ–™åº“ï¼Œé€šè¿‡ç”Ÿæˆ<æŒ‡ä»¤, æŸ¥è¯¢, æ®µè½>ä¸‰å…ƒç»„ï¼Œå¢å¼ºæ¨¡å‹å¯¹ç”¨æˆ·æ„å›¾çš„ç†è§£å’Œè·Ÿéšèƒ½åŠ›ã€‚
3. å®éªŒè¡¨æ˜ï¼Œä½¿ç”¨InF-Embedæ¨¡å‹åœ¨äº”ä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒæŒ‡ä»¤è·Ÿéšèƒ½åŠ›æå‡äº†8.1%çš„p-MRRï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ•ˆæœæ”¹è¿›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°ä»£ä¿¡æ¯æ£€ç´¢æ¨¡å‹åœ¨å¤„ç†æ ‡å‡†çš„<æŸ¥è¯¢, æ®µè½>å¯¹æ—¶ï¼Œéš¾ä»¥æœ‰æ•ˆç†è§£å’Œéµå¾ªç”¨æˆ·çš„æ˜ç¡®æŒ‡ä»¤ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡å¼•å…¥äº†InF-IRï¼Œä¸€ä¸ªå¤§è§„æ¨¡ã€é«˜è´¨é‡çš„è®­ç»ƒè¯­æ–™åº“ï¼Œæ—¨åœ¨å¢å¼ºæŒ‡ä»¤è·Ÿéšä¿¡æ¯æ£€ç´¢æ¨¡å‹çš„èƒ½åŠ›ã€‚InF-IRå°†ä¼ ç»Ÿçš„è®­ç»ƒå¯¹æ‰©å±•ä¸ºè¶…è¿‡38,000ä¸ªå¯Œæœ‰è¡¨ç°åŠ›çš„<æŒ‡ä»¤, æŸ¥è¯¢, æ®µè½>ä¸‰å…ƒç»„ä½œä¸ºæ­£æ ·æœ¬ï¼Œå¹¶ä¸ºæ¯ä¸ªæ­£æ ·æœ¬ç”Ÿæˆä¸¤ä¸ªé™„åŠ çš„å›°éš¾è´Ÿæ ·æœ¬ã€‚é€šè¿‡å¯¹æ¯”å­¦ä¹ å’ŒæŒ‡ä»¤-æŸ¥è¯¢æ³¨æ„åŠ›æœºåˆ¶ä¼˜åŒ–çš„InF-Embedæ¨¡å‹ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨äº”ä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—è¶…è¶Šç«äº‰åŸºçº¿ï¼Œæå‡äº†8.1%çš„p-MRRã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°ä»£ä¿¡æ¯æ£€ç´¢æ¨¡å‹åœ¨å¤„ç†ç”¨æˆ·æŒ‡ä»¤æ—¶çš„ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–æ ‡å‡†çš„<æŸ¥è¯¢, æ®µè½>å¯¹ï¼Œç¼ºä¹å¯¹ç”¨æˆ·æ„å›¾çš„æœ‰æ•ˆç†è§£ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºInF-IRè¯­æ–™åº“ï¼Œé€šè¿‡ç”Ÿæˆä¸°å¯Œçš„<æŒ‡ä»¤, æŸ¥è¯¢, æ®µè½>ä¸‰å…ƒç»„ï¼Œå¢å¼ºæ¨¡å‹åœ¨æŒ‡ä»¤è·Ÿéšä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚è¯¥æ–¹æ³•é€šè¿‡å¯¹æ¯”å­¦ä¹ å’ŒæŒ‡ä»¤-æŸ¥è¯¢æ³¨æ„åŠ›æœºåˆ¶ï¼Œä¼˜åŒ–æ£€ç´¢ç»“æœä¸ç”¨æˆ·æ„å›¾çš„å¯¹é½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®ç”Ÿæˆã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚æ•°æ®ç”Ÿæˆé˜¶æ®µä½¿ç”¨å…ˆè¿›çš„æ¨ç†æ¨¡å‹ç”Ÿæˆæ­£è´Ÿæ ·æœ¬ï¼Œæ¨¡å‹è®­ç»ƒé˜¶æ®µåˆ™é‡‡ç”¨å¯¹æ¯”å­¦ä¹ æ–¹æ³•ä¼˜åŒ–InF-Embedæ¨¡å‹ï¼Œæœ€åé€šè¿‡å¤šä¸ªåŸºå‡†æµ‹è¯•è¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæ„å»ºäº†InF-IRè¯­æ–™åº“ï¼Œæä¾›äº†å¤§é‡çš„å¯¹æ¯”æ€§æ­£è´Ÿæ ·æœ¬ï¼Œæ”¯æŒæ›´é«˜æ•ˆçš„è¡¨ç¤ºå­¦ä¹ ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—æå‡äº†å°å‹ç¼–ç å™¨æ¨¡å‹çš„æ£€ç´¢èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å¯¹æ¯”æŸå¤±å‡½æ•°å’ŒæŒ‡ä»¤-æŸ¥è¯¢æ³¨æ„åŠ›æœºåˆ¶ï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆæ•æ‰ç”¨æˆ·æ„å›¾ï¼Œå¹¶é€šè¿‡ç²¾ç»†çš„å‚æ•°è®¾ç½®æå‡æ¨¡å‹çš„æ•´ä½“æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨äº”ä¸ªæŒ‡ä»¤åŸºç¡€çš„æ£€ç´¢åŸºå‡†æµ‹è¯•ä¸­ï¼ŒInF-Embedæ¨¡å‹çš„è¡¨ç°æ˜¾è‘—ä¼˜äºç«äº‰åŸºçº¿ï¼Œp-MRRæå‡äº†8.1%ã€‚è¿™ä¸€ç»“æœè¡¨æ˜ï¼Œæ¨¡å‹åœ¨æŒ‡ä»¤è·Ÿéšèƒ½åŠ›ä¸Šå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œå±•ç¤ºäº†InF-IRè¯­æ–™åº“çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½åŠ©æ‰‹ã€æœç´¢å¼•æ“å’Œå®¢æˆ·æœåŠ¡ç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡ç”¨æˆ·ä¸ç³»ç»Ÿä¹‹é—´çš„äº¤äº’ä½“éªŒã€‚é€šè¿‡æ›´å¥½åœ°ç†è§£ç”¨æˆ·æŒ‡ä»¤ï¼Œæœªæ¥å¯å®ç°æ›´æ™ºèƒ½çš„ä¿¡æ¯æ£€ç´¢å’Œä¸ªæ€§åŒ–æ¨èï¼Œæ¨åŠ¨äººæœºäº¤äº’çš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Modern information retrieval (IR) models, trained exclusively on standard <query, passage> pairs, struggle to effectively interpret and follow explicit user instructions. We introduce InF-IR, a large-scale, high-quality training corpus tailored for enhancing retrieval models in Instruction-Following IR. InF-IR expands traditional training pairs into over 38,000 expressive <instruction, query, passage> triplets as positive samples. In particular, for each positive triplet, we generate two additional hard negative examples by poisoning both instructions and queries, then rigorously validated by an advanced reasoning model (o3-mini) to ensure semantic plausibility while maintaining instructional incorrectness. Unlike existing corpora that primarily support computationally intensive reranking tasks for decoder-only language models, the highly contrastive positive-negative triplets in InF-IR further enable efficient representation learning for smaller encoder-only models, facilitating direct embedding-based retrieval. Using this corpus, we train InF-Embed, an instruction-aware Embedding model optimized through contrastive learning and instruction-query attention mechanisms to align retrieval outcomes precisely with user intents. Extensive experiments across five instruction-based retrieval benchmarks demonstrate that InF-Embed significantly surpasses competitive baselines by 8.1% in p-MRR, measuring the instruction-following capabilities.

