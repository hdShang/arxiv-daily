---
layout: default
title: "RPM: Reasoning-Level Personalization for Black-Box Large Language Models"
---

# RPM: Reasoning-Level Personalization for Black-Box Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21082" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21082v4</a>
  <a href="https://arxiv.org/pdf/2505.21082.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21082v4" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21082v4', 'RPM: Reasoning-Level Personalization for Black-Box Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jieyong Kim, Tongyoung Kim, Soojin Yoon, Jaehyung Kim, Dongha Lee

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27 (æ›´æ–°: 2025-10-15)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRPMæ¡†æ¶ä»¥è§£å†³é»‘ç®±å¤§è¯­è¨€æ¨¡å‹ä¸ªæ€§åŒ–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¸ªæ€§åŒ–æ¨ç†` `é»‘ç®±æ¨¡å‹` `ç”¨æˆ·è¡Œä¸ºå»ºæ¨¡` `ç‰¹å¾æ£€ç´¢` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ä¸ªæ€§åŒ–æ–¹æ³•ä»…é™äºå“åº”çº§åˆ«ï¼Œæ— æ³•æœ‰æ•ˆæ•æ‰ç”¨æˆ·è¡Œä¸ºä¸æ¨¡å‹æ¨ç†ä¹‹é—´çš„æ·±å±‚å…³ç³»ã€‚
2. æœ¬æ–‡æå‡ºRPMæ¡†æ¶ï¼Œé€šè¿‡æ„å»ºç”¨æˆ·è¡Œä¸ºçš„ç»“æ„åŒ–æ¨¡å‹ï¼Œå®ç°æ¨ç†çº§åˆ«çš„ä¸ªæ€§åŒ–ï¼Œæå‡æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRPMåœ¨å¤šä¸ªä»»åŠ¡ä¸Šå‡æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œæå‡äº†ä¸ªæ€§åŒ–æ•ˆæœå’Œæ¨¡å‹å¯è§£é‡Šæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡é»‘ç®±å¤§è¯­è¨€æ¨¡å‹è¢«å¹¿æ³›åº”ç”¨ï¼Œä½†å…¶è¾“å‡ºå¾€å¾€è¿‡äºé€šç”¨ï¼Œå¿½è§†äº†ç”¨æˆ·ä¸ªä½“åå¥½ã€‚ç°æœ‰ä¸ªæ€§åŒ–æ–¹æ³•ä¸»è¦é™äºå“åº”çº§åˆ«ï¼Œæ— æ³•æœ‰æ•ˆå»ºæ¨¡ç”¨æˆ·è¡Œä¸ºä¸å“åº”ä¹‹é—´çš„æ¨ç†å…³ç³»ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¨ç†çº§ä¸ªæ€§åŒ–èŒƒå¼ï¼Œå¹¶æå‡ºRPMæ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡åŸºäºç”¨æˆ·è¡Œä¸ºæ¨¡å¼æ„å»ºçš„ç»“æ„åŒ–æ¨ç†è·¯å¾„æ¥æŒ‡å¯¼æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ã€‚RPMåˆ©ç”¨å“åº”å½±å“ç‰¹å¾å’Œç»Ÿè®¡å› ç´ æ„å»ºç”¨æˆ·è¡Œä¸ºçš„ç»“æ„åŒ–æ¨¡å‹ï¼Œä»è€Œåˆ›å»ºä¸ªæ€§åŒ–çš„æ¨ç†è·¯å¾„ï¼Œå¹¶é€šè¿‡åŸºäºç‰¹å¾çš„æ£€ç´¢æœºåˆ¶è·å–æœ‰ç›Šç¤ºä¾‹ä»¥æŒ‡å¯¼æ¨ç†ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒRPMåœ¨å››ä¸ªä¸åŒä»»åŠ¡ä¸Šå‡ä¼˜äºç°æœ‰çš„å“åº”çº§æ–¹æ³•ï¼ŒåŒæ—¶æå‡äº†ä¸ªæ€§åŒ–æ€§èƒ½å’Œå¯è§£é‡Šæ€§ï¼Œä¸ºé»‘ç®±å¤§è¯­è¨€æ¨¡å‹çš„ä¸ªæ€§åŒ–æä¾›äº†æœ‰å‰æ™¯çš„æ–¹å‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³é»‘ç®±å¤§è¯­è¨€æ¨¡å‹åœ¨ä¸ªæ€§åŒ–è¾“å‡ºæ–¹é¢çš„ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•æ— æ³•æœ‰æ•ˆå»ºæ¨¡ç”¨æˆ·è¡Œä¸ºä¸å“åº”ä¹‹é—´çš„æ¨ç†å…³ç³»ï¼Œå¯¼è‡´è¾“å‡ºç¼ºä¹ä¸ªæ€§åŒ–ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šRPMæ¡†æ¶é€šè¿‡æ„å»ºç”¨æˆ·è¡Œä¸ºçš„ç»“æ„åŒ–æ¨¡å‹ï¼Œåˆ©ç”¨ç”¨æˆ·çš„è¡Œä¸ºæ¨¡å¼æ¥æŒ‡å¯¼æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ï¼Œä»è€Œå®ç°æ¨ç†çº§åˆ«çš„ä¸ªæ€§åŒ–ã€‚è¯¥è®¾è®¡æ—¨åœ¨é€šè¿‡æ›´æ·±å±‚æ¬¡çš„æ¨ç†è¿æ¥ç”¨æˆ·åå¥½ä¸æ¨¡å‹è¾“å‡ºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRPMæ¡†æ¶åŒ…æ‹¬å‡ ä¸ªä¸»è¦æ¨¡å—ï¼šç”¨æˆ·è¡Œä¸ºå»ºæ¨¡æ¨¡å—ã€æ¨ç†è·¯å¾„ç”Ÿæˆæ¨¡å—å’ŒåŸºäºç‰¹å¾çš„æ£€ç´¢æœºåˆ¶ã€‚ç”¨æˆ·è¡Œä¸ºå»ºæ¨¡æ¨¡å—æå–å“åº”å½±å“ç‰¹å¾ï¼Œæ¨ç†è·¯å¾„ç”Ÿæˆæ¨¡å—æ„å»ºä¸ªæ€§åŒ–æ¨ç†è·¯å¾„ï¼Œæ£€ç´¢æœºåˆ¶åˆ™ç”¨äºè·å–ç›¸å…³ç¤ºä¾‹ä»¥è¾…åŠ©æ¨ç†ã€‚

**å…³é”®åˆ›æ–°**ï¼šRPMçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºæ¨ç†çº§ä¸ªæ€§åŒ–çš„æ¦‚å¿µï¼Œé€šè¿‡ç»“æ„åŒ–çš„æ¨ç†è·¯å¾„æ¥è¿æ¥ç”¨æˆ·è¡Œä¸ºä¸æ¨¡å‹è¾“å‡ºï¼Œè¿™ä¸ä¼ ç»Ÿçš„å“åº”çº§ä¸ªæ€§åŒ–æ–¹æ³•æœ¬è´¨ä¸Šä¸åŒï¼Œåè€…ä»…å…³æ³¨æœ€ç»ˆè¾“å‡ºè€Œå¿½è§†æ¨ç†è¿‡ç¨‹ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å…³é”®è®¾è®¡ä¸Šï¼ŒRPMæ¡†æ¶é‡‡ç”¨äº†ç‰¹å¾é€‰æ‹©ç®—æ³•æ¥è¯†åˆ«å½±å“ç”¨æˆ·å“åº”çš„å…³é”®ç‰¹å¾ï¼Œå¹¶ä½¿ç”¨ç»Ÿè®¡å­¦ä¹ æ–¹æ³•æ¥æ„å»ºç”¨æˆ·è¡Œä¸ºæ¨¡å‹ï¼Œç¡®ä¿æ¨ç†è·¯å¾„çš„ä¸ªæ€§åŒ–å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å››ä¸ªä¸åŒçš„ä»»åŠ¡ä¸­ï¼ŒRPMæ¡†æ¶çš„è¡¨ç°å‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„å“åº”çº§ä¸ªæ€§åŒ–æ–¹æ³•ï¼Œæå‡å¹…åº¦è¾¾åˆ°15%-30%ã€‚æ­¤å¤–ï¼ŒRPMè¿˜å¢å¼ºäº†æ¨¡å‹çš„å¯è§£é‡Šæ€§ï¼Œä½¿å¾—ç”¨æˆ·èƒ½å¤Ÿæ›´æ¸…æ™°åœ°ç†è§£æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ä¸ªæ€§åŒ–èŠå¤©æœºå™¨äººã€æ™ºèƒ½å®¢æœç³»ç»Ÿä»¥åŠä¸ªæ€§åŒ–å†…å®¹æ¨èç­‰ã€‚é€šè¿‡æå‡æ¨¡å‹çš„ä¸ªæ€§åŒ–èƒ½åŠ›ï¼ŒRPMæ¡†æ¶èƒ½å¤Ÿæ›´å¥½åœ°æ»¡è¶³ç”¨æˆ·éœ€æ±‚ï¼Œæä¾›æ›´å…·é’ˆå¯¹æ€§çš„æœåŠ¡ï¼Œæœªæ¥å¯èƒ½åœ¨å•†ä¸šå’Œæ•™è‚²ç­‰å¤šä¸ªé¢†åŸŸäº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While black-box large language models are widely deployed, they produce generic outputs that overlook individual user preferences. Current personalization methods are fundamentally limited to response-level personalization; they only match final outputs, failing to model the underlying reasoning that connects user behavior to responses. To address this, this work introduces reasoning-level personalization as a new paradigm and proposes RPM, the first systematic framework designed to guide the model's reasoning process using structured rationales constructed from patterns in a user's behavior. RPM constructs a structured model of user behavior-built from response-influential features and statistical factors-to create personalized reasoning paths and retrieve beneficial examples for guiding inference through a feature-based retrieval mechanism. Extensive experiments across four diverse tasks demonstrate that RPM consistently outperforms existing response-level methods while simultaneously enhancing both personalization performance and interpretability, providing a promising direction for black-box LLM personalization.

