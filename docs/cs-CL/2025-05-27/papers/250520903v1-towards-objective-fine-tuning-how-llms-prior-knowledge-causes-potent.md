---
layout: default
title: "Towards Objective Fine-tuning: How LLMs' Prior Knowledge Causes Potential Poor Calibration?"
---

# Towards Objective Fine-tuning: How LLMs' Prior Knowledge Causes Potential Poor Calibration?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20903" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.20903v1</a>
  <a href="https://arxiv.org/pdf/2505.20903.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20903v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20903v1', 'Towards Objective Fine-tuning: How LLMs\' Prior Knowledge Causes Potential Poor Calibration?')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Ziming Wang, Zeyu Shi, Haoyi Zhou, Shiqi Gao, Qingyun Sun, Jianxin Li

**ÂàÜÁ±ª**: cs.CL

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-27

**Â§áÊ≥®**: Accepted to ACL2025 Main; The code will be released soon

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫CogCalibÊ°ÜÊû∂‰ª•Ëß£ÂÜ≥LLMsÊ†°ÂáÜ‰∏çË∂≥ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `ÂæÆË∞É` `Ê®°ÂûãÊ†°ÂáÜ` `ËÆ§Áü•ÊÑüÁü•` `Â≠¶‰π†Á≠ñÁï•` `Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ` `‰∫∫Êú∫‰∫§‰∫í`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÂæÆË∞ÉLLMsÊñπÊ≥ïÂú®Ê†°ÂáÜÊñπÈù¢Â≠òÂú®‰∏çË∂≥ÔºåÁΩÆ‰ø°Â∫¶‰∏éÂÆûÈôÖË°®Áé∞‰∏ç‰∏ÄËá¥ÔºåÂΩ±ÂìçÊ®°ÂûãÁöÑÂèØÈù†ÊÄß„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫CogCalibÊ°ÜÊû∂ÔºåÈÄöËøáÈíàÂØπÊÄßÂ≠¶‰π†Á≠ñÁï•ÔºåÂà©Áî®LLMsÁöÑÂÖàÈ™åÁü•ËØÜÊù•ÊîπÂñÑÊ®°ÂûãÁöÑÊ†°ÂáÜËÉΩÂäõ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåCogCalibÂú®7‰∏™‰ªªÂä°‰∏äÊòæËëóÊèêÈ´ò‰∫ÜÊ†°ÂáÜÊïàÊûúÔºåÂπ≥ÂùáÈôç‰Ωé57%ÁöÑECEÔºåÂêåÊó∂‰øùÊåÅ‰∫ÜÊ®°ÂûãÊÄßËÉΩ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÂæÆË∞ÉÁöÑÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂ∏∏Â∏∏Ë°®Áé∞Âá∫ËæÉÂ∑ÆÁöÑÊ†°ÂáÜÔºåÂÖ∂ÁΩÆ‰ø°Â∫¶ÂàÜÊï∞‰∏éÂÆûÈôÖË°®Áé∞‰∏ç‰∏ÄËá¥„ÄÇÂ∞ΩÁÆ°Ê†°ÂáÜÂú®‰ªéÂ§¥ËÆ≠ÁªÉÁöÑÊ®°Âûã‰∏≠ÂæóÂà∞‰∫ÜÂπøÊ≥õÁ†îÁ©∂Ôºå‰ΩÜLLMsÁöÑÂÖàÈ™åÁü•ËØÜÂú®ÂæÆË∞ÉËøáÁ®ã‰∏≠ÂØπÊ†°ÂáÜÁöÑÂΩ±Âìç‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜÊé¢ËÆ®„ÄÇÊàë‰ª¨ÁöÑÁ†îÁ©∂Êè≠Á§∫ÔºåLLMsÁöÑÂÖàÈ™åÁü•ËØÜÂõ†ÁúüÂÆû‰∏ñÁïåÂæÆË∞É‰∏≠Â∑≤Áü•Êï∞ÊçÆÁöÑÊôÆÈÅçÂ≠òÂú®ËÄåÂØºËá¥ÊΩúÂú®ÁöÑÊ†°ÂáÜ‰∏çË∂≥„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºå‰∏éLLMsÁöÑÂÖàÈ™åÁü•ËØÜÂØπÈΩêÁöÑÊï∞ÊçÆ‰ºöÂºïÂèëËøáÂ∫¶Ëá™‰ø°ÔºåËÄåÊñ∞Áü•ËØÜÂàôÊúâÂä©‰∫éÊîπÂñÑÊ†°ÂáÜ„ÄÇÊàë‰ª¨ÁöÑÂèëÁé∞Êè≠Á§∫‰∫Ü‰∏ÄÁßçÁüõÁõæÔºöLLMsÁöÑÁôæÁßëÁü•ËØÜËôΩÁÑ∂Â¢ûÂº∫‰∫Ü‰ªªÂä°ÁöÑÂ§öÊ†∑ÊÄßÔºå‰ΩÜÈÄöËøá‰∏çÂèØÈÅøÂÖçÁöÑÁü•ËØÜÈáçÂè†ÂâäÂº±‰∫ÜÊ†°ÂáÜ„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜCogCalibÔºå‰∏Ä‰∏™ËÆ§Áü•ÊÑüÁü•Ê°ÜÊû∂ÔºåÊ†πÊçÆÊ®°ÂûãÁöÑÂÖàÈ™åÁü•ËØÜÂ∫îÁî®ÊúâÈíàÂØπÊÄßÁöÑÂ≠¶‰π†Á≠ñÁï•„ÄÇÂÆûÈ™åË°®ÊòéÔºåCogCalibÂú®‰øùÊåÅÊÄßËÉΩÁöÑÂêåÊó∂ÊòæËëóÊîπÂñÑ‰∫ÜÊ†°ÂáÜÔºåÂú®Llama3-8B‰∏äÂÆûÁé∞‰∫ÜÂπ≥Âùá57%ÁöÑECEÈôç‰Ωé„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥ÂæÆË∞ÉÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÊó∂Ê†°ÂáÜ‰∏çË∂≥ÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÊú™ËÉΩÂÖÖÂàÜËÄÉËôëLLMsÁöÑÂÖàÈ™åÁü•ËØÜÂØπÊ†°ÂáÜÁöÑÂΩ±ÂìçÔºåÂØºËá¥Ê®°ÂûãÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠Ë°®Áé∞‰∏ç‰Ω≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöCogCalibÊ°ÜÊû∂ÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÊ†πÊçÆÊ®°ÂûãÁöÑÂÖàÈ™åÁü•ËØÜÂ∫îÁî®ÊúâÈíàÂØπÊÄßÁöÑÂ≠¶‰π†Á≠ñÁï•Ôºå‰ª•ÂáèÂ∞ëÂõ†Â∑≤Áü•Êï∞ÊçÆÂºïÂèëÁöÑËøáÂ∫¶Ëá™‰ø°Áé∞Ë±°ÔºåÂêåÊó∂Â¢ûÂº∫Êñ∞Áü•ËØÜÁöÑÂºïÂÖ•„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöCogCalibÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨Êï∞ÊçÆÈÄâÊã©Ê®°Âùó„ÄÅÂ≠¶‰π†Á≠ñÁï•Ê®°ÂùóÂíåÊ†°ÂáÜËØÑ‰º∞Ê®°Âùó„ÄÇÊï∞ÊçÆÈÄâÊã©Ê®°ÂùóÊ†πÊçÆÊ®°ÂûãÁöÑÂÖàÈ™åÁü•ËØÜÁ≠õÈÄâËÆ≠ÁªÉÊï∞ÊçÆÔºåÂ≠¶‰π†Á≠ñÁï•Ê®°ÂùóÂàôÂ∫îÁî®‰∏çÂêåÁöÑËÆ≠ÁªÉÁ≠ñÁï•‰ª•‰ºòÂåñÊ®°ÂûãÁöÑÊ†°ÂáÜÔºåÊúÄÂêéÈÄöËøáÊ†°ÂáÜËØÑ‰º∞Ê®°ÂùóÁõëÊéßÊ®°ÂûãÁöÑÊ†°ÂáÜÊïàÊûú„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöCogCalibÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÂÖ∂ËÆ§Áü•ÊÑüÁü•ÁöÑÂ≠¶‰π†Á≠ñÁï•ÔºåËÉΩÂ§üÂä®ÊÄÅË∞ÉÊï¥ËÆ≠ÁªÉËøáÁ®ã‰ª•ÈÄÇÂ∫îÊ®°ÂûãÁöÑÂÖàÈ™åÁü•ËØÜ„ÄÇËøô‰∏ÄÊñπÊ≥ï‰∏é‰º†ÁªüÁöÑÂæÆË∞ÉÊñπÊ≥ïÁõ∏ÊØîÔºåËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞Â§ÑÁêÜÁü•ËØÜÈáçÂè†ÈóÆÈ¢ò„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°‰∏äÔºåCogCalibÈááÁî®‰∫ÜÁâπÂÆöÁöÑÊçüÂ§±ÂáΩÊï∞Êù•Âπ≥Ë°°ÁΩÆ‰ø°Â∫¶ÂíåÂÆûÈôÖË°®Áé∞ÔºåÂπ∂ÂºïÂÖ•‰∫ÜÂ§ö‰ªªÂä°Â≠¶‰π†Êú∫Âà∂‰ª•Â¢ûÂº∫Ê®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåCogCalibÂú®Llama3-8BÊ®°Âûã‰∏äÂÆûÁé∞‰∫ÜÂπ≥Âùá57%ÁöÑECEÈôç‰ΩéÔºåÁõ∏ËæÉ‰∫éÊ†áÂáÜÂæÆË∞ÉÊñπÊ≥ïÊòæËëóÊèêÂçá‰∫ÜÊ†°ÂáÜÊïàÊûú„ÄÇËøô‰∏ÄÊîπËøõÂú®7‰∏™‰∏çÂêå‰ªªÂä°‰∏≠ÂùáÂæóÂà∞‰∫ÜÈ™åËØÅÔºåÂπ∂‰∏îÂú®È¢ÜÂüüÂ§ñ‰ªªÂä°‰∏≠‰πüË°®Áé∞Âá∫ËâØÂ•ΩÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ„ÄÅÂØπËØùÁ≥ªÁªüÂíå‰ø°ÊÅØÊ£ÄÁ¥¢Á≠â„ÄÇÈÄöËøáÊèêÈ´òLLMsÁöÑÊ†°ÂáÜËÉΩÂäõÔºåCogCalibËÉΩÂ§üÂ¢ûÂº∫Ê®°ÂûãÂú®ÂÖ≥ÈîÆ‰∫∫Êú∫‰∫§‰∫íÂ∫îÁî®‰∏≠ÁöÑÂèØÈù†ÊÄßÂíå‰ø°‰ªªÂ∫¶ÔºåÊèêÂçáÁî®Êà∑‰ΩìÈ™åÂíåÂÆâÂÖ®ÊÄß„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Fine-tuned Large Language Models (LLMs) often demonstrate poor calibration, with their confidence scores misaligned with actual performance. While calibration has been extensively studied in models trained from scratch, the impact of LLMs' prior knowledge on calibration during fine-tuning remains understudied. Our research reveals that LLMs' prior knowledge causes potential poor calibration due to the ubiquitous presence of known data in real-world fine-tuning, which appears harmful for calibration. Specifically, data aligned with LLMs' prior knowledge would induce overconfidence, while new knowledge improves calibration. Our findings expose a tension: LLMs' encyclopedic knowledge, while enabling task versatility, undermines calibration through unavoidable knowledge overlaps. To address this, we propose CogCalib, a cognition-aware framework that applies targeted learning strategies according to the model's prior knowledge. Experiments across 7 tasks using 3 LLM families prove that CogCalib significantly improves calibration while maintaining performance, achieving an average 57\% reduction in ECE compared to standard fine-tuning in Llama3-8B. These improvements generalize well to out-of-domain tasks, enhancing the objectivity and reliability of domain-specific LLMs, and making them more trustworthy for critical human-AI interaction applications.

