---
layout: default
title: LayerIF: Estimating Layer Quality for Large Language Models using Influence Functions
---

# LayerIF: Estimating Layer Quality for Large Language Models using Influence Functions

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.23811" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.23811v3</a>
  <a href="https://arxiv.org/pdf/2505.23811.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.23811v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.23811v3', 'LayerIF: Estimating Layer Quality for Large Language Models using Influence Functions')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hadi Askari, Shivanshu Gupta, Fei Wang, Anshuman Chhabra, Muhao Chen

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27 (æ›´æ–°: 2025-10-24)

**å¤‡æ³¨**: Neurips 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLayerIFä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹å±‚è´¨é‡ä¼°è®¡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `å±‚çº§è´¨é‡ä¼°è®¡` `å½±å“å‡½æ•°` `ä»»åŠ¡æ•æ„Ÿ` `æ¨¡å‹ä¼˜åŒ–` `ç¨€ç–åˆ†å¸ƒ` `ä¸“å®¶åˆ†é…`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•å¤šä¾èµ–æ¨¡å‹ä¸­å¿ƒçš„å¯å‘å¼ç­–ç•¥ï¼Œå¿½è§†äº†æ•°æ®å¯¹å±‚è®­ç»ƒè´¨é‡çš„å½±å“ï¼Œå¯¼è‡´å±‚çº§æ€§èƒ½è¯„ä¼°ä¸å‡†ç¡®ã€‚
2. æœ¬æ–‡æå‡ºLayerIFï¼Œé€šè¿‡å½±å“å‡½æ•°é‡åŒ–å„å±‚çš„è®­ç»ƒè´¨é‡ï¼Œè€ƒè™‘æ¨¡å‹æ¶æ„å’Œè®­ç»ƒæ•°æ®çš„å½±å“ï¼Œæä¾›ä»»åŠ¡æ•æ„Ÿçš„å±‚çº§é‡è¦æ€§ä¼°è®¡ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLayerIFåœ¨å¤šç§LLMæ¶æ„ä¸Šå®ç°äº†ä»»åŠ¡æ€§èƒ½çš„æ˜¾è‘—æå‡ï¼Œå°¤å…¶åœ¨ä¸“å®¶åˆ†é…å’Œå±‚çº§ç¨€ç–åˆ†å¸ƒæ–¹é¢è¡¨ç°çªå‡ºã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é¢„è®­ç»ƒçš„å¤§è¯­è¨€æ¨¡å‹åœ¨å¤šç§ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†ä¸åŒå±‚çš„è®­ç»ƒè´¨é‡å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œé™åˆ¶äº†å…¶ä¸‹æ¸¸æ€§èƒ½ã€‚å› æ­¤ï¼Œå‡†ç¡®ä¼°è®¡å±‚çº§è®­ç»ƒè´¨é‡è‡³å…³é‡è¦ã€‚ç°æœ‰æ–¹æ³•å¤šä¾èµ–æ¨¡å‹ä¸­å¿ƒçš„å¯å‘å¼ç­–ç•¥ï¼Œå¿½è§†äº†æ•°æ®çš„å½±å“ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºLayerIFï¼Œä¸€ä¸ªåŸºäºå½±å“å‡½æ•°çš„æ•°æ®é©±åŠ¨æ¡†æ¶ï¼Œä»¥ä»»åŠ¡æ•æ„Ÿçš„æ–¹å¼é‡åŒ–å„å±‚çš„è®­ç»ƒè´¨é‡ã€‚é€šè¿‡éš”ç¦»æ¯å±‚çš„æ¢¯åº¦å¹¶è®¡ç®—å±‚çº§å½±å“ï¼Œæˆ‘ä»¬è·å¾—äº†å±‚çš„é‡è¦æ€§ä¼°è®¡ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨LoRA-MoEæ¶æ„ä¸­çš„ä¸“å®¶åˆ†é…å’ŒLLMå‰ªæçš„å±‚çº§ç¨€ç–åˆ†å¸ƒä¸­å‡è¡¨ç°å‡ºè‰¯å¥½æ•ˆæœã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹å„å±‚è®­ç»ƒè´¨é‡ä¼°è®¡ä¸å‡†ç¡®çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–æ¨¡å‹ä¸­å¿ƒçš„å¯å‘å¼ç­–ç•¥ï¼Œæœªèƒ½å……åˆ†è€ƒè™‘æ•°æ®çš„å½±å“ï¼Œå¯¼è‡´å±‚çº§æ€§èƒ½è¯„ä¼°çš„å±€é™æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šLayerIFé€šè¿‡å½±å“å‡½æ•°æ¥é‡åŒ–æ¯å±‚çš„è®­ç»ƒè´¨é‡ï¼Œé‡‡ç”¨æ•°æ®é©±åŠ¨çš„æ–¹æ³•ï¼Œèƒ½å¤Ÿæä¾›æ›´ä¸ºç²¾ç¡®å’Œä»»åŠ¡æ•æ„Ÿçš„å±‚çº§é‡è¦æ€§ä¼°è®¡ã€‚è¿™ç§è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”ä¸åŒçš„ä¸‹æ¸¸ä»»åŠ¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLayerIFçš„æ•´ä½“æ¶æ„åŒ…æ‹¬å‡ ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œéš”ç¦»æ¯å±‚çš„æ¢¯åº¦ï¼›å…¶æ¬¡ï¼Œè®¡ç®—è®­ç»ƒæ ·æœ¬å¯¹éªŒè¯æŸå¤±çš„æ•æ„Ÿæ€§ï¼›æœ€åï¼ŒåŸºäºå±‚çº§å½±å“å¾—å‡ºå±‚çš„é‡è¦æ€§ä¼°è®¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šLayerIFçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶æ•°æ®é©±åŠ¨çš„å±‚çº§é‡è¦æ€§ä¼°è®¡æ–¹æ³•ï¼ŒåŒºåˆ«äºä¼ ç»Ÿçš„æ¨¡å‹ä¸­å¿ƒæ–¹æ³•ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°åæ˜ ä¸åŒå±‚åœ¨ç‰¹å®šä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼ŒLayerIFé‡‡ç”¨äº†å½±å“å‡½æ•°çš„è®¡ç®—æ–¹æ³•ï¼Œå…·ä½“å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡æœªåœ¨æ‘˜è¦ä¸­è¯¦ç»†è¯´æ˜ï¼Œéœ€å‚è€ƒåŸæ–‡è·å–æ›´å¤šä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLayerIFåœ¨å¤šç§å¤§è¯­è¨€æ¨¡å‹æ¶æ„ä¸Šå®ç°äº†ä»»åŠ¡æ€§èƒ½çš„æ˜¾è‘—æå‡ï¼Œç‰¹åˆ«æ˜¯åœ¨LoRA-MoEæ¶æ„ä¸­çš„ä¸“å®¶åˆ†é…å’Œå±‚çº§ç¨€ç–åˆ†å¸ƒæ–¹é¢ï¼Œå‡è¡¨ç°å‡ºä¼˜äºåŸºçº¿æ–¹æ³•çš„æ•ˆæœï¼Œå…·ä½“æå‡å¹…åº¦æœªåœ¨æ‘˜è¦ä¸­ç»™å‡ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

LayerIFçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ï¼Œå°¤å…¶æ˜¯åœ¨å¤§è¯­è¨€æ¨¡å‹çš„ä¼˜åŒ–å’Œå‰ªæè¿‡ç¨‹ä¸­ã€‚é€šè¿‡ç²¾ç¡®çš„å±‚çº§é‡è¦æ€§ä¼°è®¡ï¼Œå¯ä»¥å®ç°æ›´é«˜æ•ˆçš„æ¨¡å‹å‹ç¼©å’Œèµ„æºåˆ†é…ï¼Œæå‡æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸­çš„æ€§èƒ½ï¼Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿçš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Pretrained Large Language Models (LLMs) achieve strong performance across a wide range of tasks, yet exhibit substantial variability in the various layers' training quality with respect to specific downstream applications, limiting their downstream performance. It is therefore critical to estimate layer-wise training quality in a manner that accounts for both model architecture and training data. However, existing approaches predominantly rely on model-centric heuristics (such as spectral statistics, outlier detection, or uniform allocation) while overlooking the influence of data. To address these limitations, we propose LayerIF, a data-driven framework that leverages Influence Functions to quantify the training quality of individual layers in a principled and task-sensitive manner. By isolating each layer's gradients and measuring the sensitivity of the validation loss to training examples by computing layer-wise influences, we derive data-driven estimates of layer importance. Notably, our method produces task-specific layer importance estimates for the same LLM, revealing how layers specialize for different test-time evaluation tasks. We demonstrate the utility of our scores by leveraging them for two downstream applications: (a) expert allocation in LoRA-MoE architectures and (b) layer-wise sparsity distribution for LLM pruning. Experiments across multiple LLM architectures demonstrate that our model-agnostic, influence-guided allocation leads to consistent gains in task performance.

