---
layout: default
title: "STEER-BENCH: A Benchmark for Evaluating the Steerability of Large Language Models"
---

# STEER-BENCH: A Benchmark for Evaluating the Steerability of Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20645" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.20645v2</a>
  <a href="https://arxiv.org/pdf/2505.20645.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20645v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20645v2', 'STEER-BENCH: A Benchmark for Evaluating the Steerability of Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kai Chen, Zihao He, Taiwei Shi, Kristina Lerman

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27 (æ›´æ–°: 2025-06-04)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSTEER-BENCHä»¥è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹çš„å¯å¼•å¯¼æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å¯å¼•å¯¼æ€§` `ç¤¾åŒºè§„èŒƒ` `è¯„ä¼°åŸºå‡†` `Redditç¤¾åŒº` `å¤šæ ·åŒ–è§†è§’` `äººå·¥æ™ºèƒ½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹çš„å¯å¼•å¯¼æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨é€‚åº”ä¸åŒç¤¾åŒºè§„èŒƒå’Œè§‚ç‚¹æ—¶çš„èƒ½åŠ›æœªå¾—åˆ°å……åˆ†éªŒè¯ã€‚
2. è®ºæ–‡æå‡ºäº†Steer-BenchåŸºå‡†ï¼Œé€šè¿‡å¯¹æ¯”ä¸åŒRedditç¤¾åŒºï¼Œç³»ç»Ÿè¯„ä¼°LLMsåœ¨ç†è§£ç¤¾åŒºç‰¹å®šæŒ‡ä»¤å’Œåº”å¯¹å¯¹æŠ—æ€§å¼•å¯¼æ–¹é¢çš„èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå°½ç®¡äººç±»ä¸“å®¶çš„å‡†ç¡®ç‡è¾¾åˆ°81%ï¼Œä½†æœ€ä½³æ¨¡å‹çš„å‡†ç¡®ç‡ä»…ä¸º65%ï¼Œè¡¨æ˜LLMsåœ¨ç¤¾åŒºæ•æ„Ÿæ€§æ–¹é¢ä»æœ‰æ˜¾è‘—æå‡ç©ºé—´ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¯å¼•å¯¼æ€§ï¼Œå³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ ¹æ®ä¸åŒç¤¾åŒºç‰¹å®šè§„èŒƒã€è§‚ç‚¹å’Œäº¤æµé£æ ¼è°ƒæ•´è¾“å‡ºçš„èƒ½åŠ›ï¼Œå¯¹äºå®é™…åº”ç”¨è‡³å…³é‡è¦ï¼Œä½†ä»æœªå¾—åˆ°å……åˆ†è¯„ä¼°ã€‚æˆ‘ä»¬ä»‹ç»äº†Steer-Benchï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°äººå£ç‰¹å®šå¼•å¯¼çš„åŸºå‡†ï¼Œæ¶µç›–äº†30å¯¹å¯¹æ¯”çš„Redditå­ç¤¾åŒºï¼Œæ¶‰åŠ19ä¸ªé¢†åŸŸï¼ŒåŒ…å«è¶…è¿‡10,000ä¸ªæŒ‡ä»¤-å“åº”å¯¹å’ŒéªŒè¯çš„5,500ä¸ªå¤šé¡¹é€‰æ‹©é¢˜åŠå…¶å¯¹åº”çš„é“¶æ ‡ç­¾ï¼Œä»¥æµ‹è¯•ä¸å¤šæ ·åŒ–ç¤¾åŒºè§„èŒƒçš„ä¸€è‡´æ€§ã€‚å¯¹13ä¸ªæµè¡ŒLLMsçš„è¯„ä¼°æ˜¾ç¤ºï¼Œå°½ç®¡äººç±»ä¸“å®¶åœ¨é“¶æ ‡ç­¾ä¸Šçš„å‡†ç¡®ç‡ä¸º81%ï¼Œä½†è¡¨ç°æœ€ä½³çš„æ¨¡å‹åœ¨ä¸åŒé¢†åŸŸå’Œé…ç½®ä¸‹çš„å‡†ç¡®ç‡ä»…çº¦ä¸º65%ã€‚ä¸€äº›æ¨¡å‹åœ¨ç¤¾åŒºæ•æ„Ÿçš„å¯å¼•å¯¼æ€§æ–¹é¢è½åäºäººç±»æ°´å¹³è¶…è¿‡15ä¸ªç™¾åˆ†ç‚¹ï¼Œçªæ˜¾äº†æ˜¾è‘—çš„å·®è·ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é€‚åº”ä¸åŒç¤¾åŒºè§„èŒƒå’Œè§‚ç‚¹æ—¶çš„å¯å¼•å¯¼æ€§è¯„ä¼°ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆæ•æ‰æ¨¡å‹åœ¨ç¤¾åŒºç‰¹å®šæŒ‡ä»¤ä¸‹çš„è¡¨ç°å’Œå¯¹æŠ—æ€§å¼•å¯¼çš„æŠµæŠ—èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ„å»ºSteer-BenchåŸºå‡†ï¼Œåˆ©ç”¨å¯¹æ¯”çš„Redditç¤¾åŒºæ¥è¯„ä¼°LLMsçš„å¯å¼•å¯¼æ€§ï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿå‡†ç¡®ç†è§£å’Œå“åº”ç¤¾åŒºç‰¹å®šçš„äº¤æµé£æ ¼å’Œè§„èŒƒã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSteer-Benchçš„æ•´ä½“æ¶æ„åŒ…æ‹¬30å¯¹å¯¹æ¯”çš„å­ç¤¾åŒºï¼Œæ¶µç›–19ä¸ªé¢†åŸŸï¼Œæä¾›è¶…è¿‡10,000ä¸ªæŒ‡ä»¤-å“åº”å¯¹å’Œ5,500ä¸ªç»è¿‡éªŒè¯çš„å¤šé¡¹é€‰æ‹©é¢˜ï¼Œå½¢æˆä¸€ä¸ªç³»ç»ŸåŒ–çš„è¯„ä¼°æµç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥äº†ç¤¾åŒºç‰¹å®šçš„è¯„ä¼°æ ‡å‡†ï¼Œç³»ç»Ÿæ€§åœ°é‡åŒ–äº†LLMsåœ¨ä¸åŒç¤¾åŒºèƒŒæ™¯ä¸‹çš„è¡¨ç°ï¼Œå¡«è¡¥äº†ç°æœ‰è¯„ä¼°æ–¹æ³•çš„ç©ºç™½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†é“¶æ ‡ç­¾ä½œä¸ºè¯„ä¼°æ ‡å‡†ï¼Œå¹¶é€šè¿‡å¤šé¡¹é€‰æ‹©é¢˜çš„å½¢å¼éªŒè¯æ¨¡å‹çš„è¾“å‡ºï¼Œç¡®ä¿è¯„ä¼°çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå°½ç®¡äººç±»ä¸“å®¶åœ¨ä½¿ç”¨é“¶æ ‡ç­¾æ—¶çš„å‡†ç¡®ç‡è¾¾åˆ°81%ï¼Œä½†æœ€ä½³è¡¨ç°çš„æ¨¡å‹åœ¨ä¸åŒé¢†åŸŸå’Œé…ç½®ä¸‹çš„å‡†ç¡®ç‡ä»…ä¸º65%ã€‚ä¸€äº›æ¨¡å‹åœ¨ç¤¾åŒºæ•æ„Ÿæ€§æ–¹é¢çš„è¡¨ç°è½åäºäººç±»æ°´å¹³è¶…è¿‡15ä¸ªç™¾åˆ†ç‚¹ï¼Œæ­ç¤ºäº†å½“å‰LLMsåœ¨å¯å¼•å¯¼æ€§æ–¹é¢çš„æ˜¾è‘—ä¸è¶³ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾äº¤åª’ä½“å†…å®¹ç”Ÿæˆã€åœ¨çº¿ç¤¾åŒºç®¡ç†å’Œä¸ªæ€§åŒ–æ¨èç³»ç»Ÿç­‰ã€‚é€šè¿‡æé«˜å¤§å‹è¯­è¨€æ¨¡å‹çš„å¯å¼•å¯¼æ€§ï¼Œå¯ä»¥æ›´å¥½åœ°æ»¡è¶³ä¸åŒç”¨æˆ·ç¾¤ä½“çš„éœ€æ±‚ï¼Œæå‡ç”¨æˆ·ä½“éªŒå’Œæ»¡æ„åº¦ã€‚æœªæ¥ï¼ŒSteer-Benchå¯èƒ½æˆä¸ºè¯„ä¼°å’Œä¼˜åŒ–è¯­è¨€æ¨¡å‹åœ¨å¤šæ ·åŒ–æ–‡åŒ–å’Œæ„è¯†å½¢æ€èƒŒæ™¯ä¸‹è¡¨ç°çš„é‡è¦å·¥å…·ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Steerability, or the ability of large language models (LLMs) to adapt outputs to align with diverse community-specific norms, perspectives, and communication styles, is critical for real-world applications but remains under-evaluated. We introduce Steer-Bench, a benchmark for assessing population-specific steering using contrasting Reddit communities. Covering 30 contrasting subreddit pairs across 19 domains, Steer-Bench includes over 10,000 instruction-response pairs and validated 5,500 multiple-choice question with corresponding silver labels to test alignment with diverse community norms. Our evaluation of 13 popular LLMs using Steer-Bench reveals that while human experts achieve an accuracy of 81% with silver labels, the best-performing models reach only around 65% accuracy depending on the domain and configuration. Some models lag behind human-level alignment by over 15 percentage points, highlighting significant gaps in community-sensitive steerability. Steer-Bench is a benchmark to systematically assess how effectively LLMs understand community-specific instructions, their resilience to adversarial steering attempts, and their ability to accurately represent diverse cultural and ideological perspectives.

