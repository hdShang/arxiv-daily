---
layout: default
title: Automatic Transmission for LLM Tiers: Optimizing Cost and Accuracy in Large Language Models
---

# Automatic Transmission for LLM Tiers: Optimizing Cost and Accuracy in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20921" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.20921v2</a>
  <a href="https://arxiv.org/pdf/2505.20921.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20921v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20921v2', 'Automatic Transmission for LLM Tiers: Optimizing Cost and Accuracy in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Injae Na, Keonwoong Noh, Woohwan Jung

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27 (æ›´æ–°: 2025-05-29)

**å¤‡æ³¨**: ACL 2025 (Findings)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLLMè‡ªåŠ¨ä¼ è¾“æ¡†æ¶ä»¥ä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹çš„æˆæœ¬ä¸å‡†ç¡®æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `è‡ªåŠ¨åŒ–é€‰æ‹©` `æˆæœ¬ä¼˜åŒ–` `å‡†ç¡®æ€§è¯„ä¼°` `è‡ªç„¶è¯­è¨€å¤„ç†` `æ™ºèƒ½ç³»ç»Ÿ` `å“åº”ç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„LLMå±‚æ¬¡é€‰æ‹©æ–¹æ³•åœ¨å¤„ç†å¤æ‚è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡æ—¶é¢ä¸´æˆæœ¬ä¸æ€§èƒ½ä¹‹é—´çš„å¹³è¡¡æŒ‘æˆ˜ã€‚
2. æœ¬æ–‡æå‡ºçš„LLM-ATæ¡†æ¶é€šè¿‡è‡ªåŠ¨é€‰æ‹©LLMå±‚æ¬¡ï¼Œä¼˜åŒ–äº†å“åº”ç”Ÿæˆè¿‡ç¨‹ï¼Œé¿å…äº†è®­ç»ƒçš„éœ€æ±‚ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLM-ATåœ¨æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼ŒåŒæ—¶æœ‰æ•ˆé™ä½äº†ä½¿ç”¨æˆæœ¬ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æä¾›å•†é€šå¸¸æä¾›å¤šä¸ªæ€§èƒ½å’Œä»·æ ¼ä¸åŒçš„LLMå±‚æ¬¡ã€‚éšç€è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡çš„å¤æ‚æ€§å’Œæ¨¡å—åŒ–å¢åŠ ï¼Œä¸ºæ¯ä¸ªå­ä»»åŠ¡é€‰æ‹©åˆé€‚çš„LLMå±‚æ¬¡æˆä¸ºå¹³è¡¡æˆæœ¬ä¸æ€§èƒ½çš„å…³é”®æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†LLMè‡ªåŠ¨ä¼ è¾“ï¼ˆLLM-ATï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶æ— éœ€è®­ç»ƒå³å¯è‡ªåŠ¨é€‰æ‹©LLMå±‚æ¬¡ã€‚LLM-ATç”±Starterã€Generatorå’ŒJudgeç»„æˆï¼ŒStarteré€‰æ‹©é¢„æœŸè§£å†³é—®é¢˜çš„åˆå§‹LLMå±‚æ¬¡ï¼ŒGeneratorä½¿ç”¨æ‰€é€‰å±‚æ¬¡çš„LLMç”Ÿæˆå“åº”ï¼ŒJudgeè¯„ä¼°å“åº”çš„æœ‰æ•ˆæ€§ã€‚å¦‚æœå“åº”æ— æ•ˆï¼ŒLLM-ATå°†è¿­ä»£å‡çº§åˆ°æ›´é«˜å±‚æ¬¡çš„æ¨¡å‹ï¼Œç”Ÿæˆæ–°å“åº”å¹¶é‡æ–°è¯„ä¼°ï¼Œç›´åˆ°è·å¾—æœ‰æ•ˆå“åº”ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†å‡†ç¡®æ€§ä¼°è®¡å™¨ï¼Œä½¿å¾—åœ¨ä¸è¿›è¡Œè®­ç»ƒçš„æƒ…å†µä¸‹èƒ½å¤Ÿé€‰æ‹©åˆé€‚çš„åˆå§‹LLMå±‚æ¬¡ã€‚å®éªŒè¡¨æ˜ï¼ŒLLM-ATåœ¨é™ä½æˆæœ¬çš„åŒæ—¶å®ç°äº†ä¼˜è¶Šçš„æ€§èƒ½ï¼Œæˆä¸ºå®é™…åº”ç”¨çš„å¯è¡Œè§£å†³æ–¹æ¡ˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨å¤æ‚è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­ï¼Œå¦‚ä½•æœ‰æ•ˆé€‰æ‹©åˆé€‚çš„LLMå±‚æ¬¡ä»¥å¹³è¡¡æˆæœ¬ä¸æ€§èƒ½çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºäººå·¥é€‰æ‹©æˆ–è®­ç»ƒï¼Œå¯¼è‡´æ•ˆç‡ä½ä¸‹å’Œæˆæœ¬é«˜æ˜‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šLLM-ATæ¡†æ¶çš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡è‡ªåŠ¨åŒ–çš„æ–¹å¼é€‰æ‹©LLMå±‚æ¬¡ï¼Œåˆ©ç”¨Starterã€Generatorå’ŒJudgeæ¨¡å—å®ç°å“åº”ç”Ÿæˆå’Œæœ‰æ•ˆæ€§è¯„ä¼°ï¼Œé¿å…äº†è®­ç»ƒè¿‡ç¨‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLLM-ATæ¡†æ¶ç”±ä¸‰ä¸ªä¸»è¦æ¨¡å—ç»„æˆï¼šStarterè´Ÿè´£é€‰æ‹©åˆå§‹LLMå±‚æ¬¡ï¼ŒGeneratorç”Ÿæˆå“åº”ï¼ŒJudgeè¯„ä¼°å“åº”æœ‰æ•ˆæ€§ã€‚å¦‚æœå“åº”æ— æ•ˆï¼Œç³»ç»Ÿä¼šè¿­ä»£å‡çº§åˆ°æ›´é«˜å±‚æ¬¡çš„æ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ¡†æ¶çš„åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥äº†å‡†ç¡®æ€§ä¼°è®¡å™¨ï¼Œèƒ½å¤Ÿåœ¨ä¸è¿›è¡Œè®­ç»ƒçš„æƒ…å†µä¸‹ï¼ŒåŸºäºå†å²æ¨ç†è®°å½•ä¼°è®¡å„LLMå±‚æ¬¡çš„é¢„æœŸå‡†ç¡®æ€§ï¼Œä»è€Œä¼˜åŒ–åˆå§‹å±‚æ¬¡çš„é€‰æ‹©ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œå‡†ç¡®æ€§ä¼°è®¡å™¨é€šè¿‡è®¡ç®—ä¸è¾“å…¥é—®é¢˜ç›¸ä¼¼çš„å†å²æŸ¥è¯¢çš„æœ‰æ•ˆå“åº”ç‡æ¥è¯„ä¼°å±‚æ¬¡çš„å‡†ç¡®æ€§ï¼Œç¡®ä¿é€‰æ‹©çš„åˆå§‹å±‚æ¬¡èƒ½å¤Ÿæœ‰æ•ˆè§£å†³å½“å‰é—®é¢˜ã€‚æ•´ä½“æµç¨‹é«˜æ•ˆä¸”çµæ´»ï¼Œé€‚åº”æ€§å¼ºã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLLM-ATåœ¨å¤šä¸ªè‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œæ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼ŒåŒæ—¶æˆæœ¬é™ä½äº†15%ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼ŒLLM-ATæä¾›äº†ä¸€ç§æ›´ä¸ºé«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å®¢æœã€è‡ªåŠ¨é—®ç­”ç³»ç»Ÿå’Œå†…å®¹ç”Ÿæˆç­‰åœºæ™¯ã€‚é€šè¿‡ä¼˜åŒ–LLMçš„é€‰æ‹©è¿‡ç¨‹ï¼ŒLLM-ATèƒ½å¤Ÿåœ¨é™ä½æˆæœ¬çš„åŒæ—¶æé«˜å“åº”çš„å‡†ç¡®æ€§ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> LLM providers typically offer multiple LLM tiers, varying in performance and price. As NLP tasks become more complex and modularized, selecting the suitable LLM tier for each subtask is a key challenge to balance between cost and performance. To address the problem, we introduce LLM Automatic Transmission (LLM-AT) framework that automatically selects LLM tiers without training. LLM-AT consists of Starter, Generator, and Judge. The starter selects the initial LLM tier expected to solve the given question, the generator produces a response using the LLM of the selected tier, and the judge evaluates the validity of the response. If the response is invalid, LLM-AT iteratively upgrades to a higher-tier model, generates a new response, and re-evaluates until a valid response is obtained. Additionally, we propose accuracy estimator, which enables the suitable initial LLM tier selection without training. Given an input question, accuracy estimator estimates the expected accuracy of each LLM tier by computing the valid response rate across top-k similar queries from past inference records. Experiments demonstrate that LLM-AT achieves superior performance while reducing costs, making it a practical solution for real-world applications.

