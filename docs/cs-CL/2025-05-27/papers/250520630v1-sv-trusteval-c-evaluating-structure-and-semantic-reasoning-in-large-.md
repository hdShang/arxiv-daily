---
layout: default
title: "SV-TrustEval-C: Evaluating Structure and Semantic Reasoning in Large Language Models for Source Code Vulnerability Analysis"
---

# SV-TrustEval-C: Evaluating Structure and Semantic Reasoning in Large Language Models for Source Code Vulnerability Analysis

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20630" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.20630v1</a>
  <a href="https://arxiv.org/pdf/2505.20630.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20630v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20630v1', 'SV-TrustEval-C: Evaluating Structure and Semantic Reasoning in Large Language Models for Source Code Vulnerability Analysis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yansong Li, Paula Branco, Alexander M. Hoole, Manish Marwah, Hari Manassery Koduvely, Guy-Vincent Jourdan, Stephan Jou

**åˆ†ç±»**: cs.SE, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27

**æœŸåˆŠ**: 2025 IEEE Symposium on Security and Privacy (SP), 2025, pp. 2791-2809

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSV-TrustEval-Cä»¥è§£å†³LLMåœ¨ä»£ç æ¼æ´åˆ†æä¸­çš„è¯„ä¼°é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ä»£ç æ¼æ´åˆ†æ` `ç»“æ„æ¨ç†` `è¯­ä¹‰æ¨ç†` `åŸºå‡†è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨è¯„ä¼°LLMçš„æ¼æ´åˆ†æèƒ½åŠ›æ—¶ï¼Œå¾€å¾€å¿½è§†äº†ç»“æ„å’Œè¯­ä¹‰æ¨ç†çš„é‡è¦æ€§ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœä¸å¤Ÿå…¨é¢ã€‚
2. æœ¬æ–‡æå‡ºSV-TrustEval-CåŸºå‡†ï¼Œé€šè¿‡ç»“æ„æ¨ç†å’Œè¯­ä¹‰æ¨ç†ä¸¤ä¸ªç»´åº¦ï¼Œç³»ç»Ÿæ€§åœ°è¯„ä¼°LLMåœ¨Cè¯­è¨€ä»£ç æ¼æ´åˆ†æä¸­çš„èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå½“å‰LLMåœ¨ç†è§£å¤æ‚ä»£ç å…³ç³»æ–¹é¢è¡¨ç°ä¸ä½³ï¼Œä¸»è¦ä¾èµ–æ¨¡å¼åŒ¹é…è€Œéé€»è¾‘æ¨ç†ï¼Œè¡¨æ˜æå‡ç©ºé—´å·¨å¤§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç†è§£å’Œç”Ÿæˆä»£ç æ–¹é¢çš„è¿›æ­¥ï¼Œå‡†ç¡®è¯„ä¼°å…¶åœ¨æºä»£ç æ¼æ´åˆ†æä¸­çš„å¯é æ€§å˜å¾—æ„ˆå‘é‡è¦ã€‚å°½ç®¡å·²æœ‰ç ”ç©¶æ¢è®¨äº†LLMåœ¨æ¼æ´æ£€æµ‹å’Œä¿®å¤ç­‰ä»»åŠ¡ä¸­çš„èƒ½åŠ›ï¼Œä½†å¾€å¾€å¿½è§†äº†ç»“æ„å’Œè¯­ä¹‰æ¨ç†åœ¨å¯ä¿¡æ¼æ´åˆ†æä¸­çš„é‡è¦æ€§ã€‚ä¸ºå¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæœ¬æ–‡æå‡ºäº†SV-TrustEval-CåŸºå‡†ï¼Œæ—¨åœ¨é€šè¿‡ç»“æ„æ¨ç†å’Œè¯­ä¹‰æ¨ç†ä¸¤ä¸ªç»´åº¦è¯„ä¼°LLMåœ¨Cè¯­è¨€ä»£ç æ¼æ´åˆ†æä¸­çš„èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå½“å‰LLMåœ¨ç†è§£å¤æ‚ä»£ç å…³ç³»æ–¹é¢è¿œæœªè¾¾åˆ°ç†æƒ³æ°´å¹³ï¼Œå…¶æ¼æ´åˆ†ææ›´å¤šä¾èµ–äºæ¨¡å¼åŒ¹é…è€Œéç¨³å¥çš„é€»è¾‘æ¨ç†ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†SV-TrustEval-CåŸºå‡†çš„æœ‰æ•ˆæ€§ï¼Œå¹¶æŒ‡å‡ºäº†æå‡LLMåœ¨å®é™…æ¼æ´åˆ†æä»»åŠ¡ä¸­æ¨ç†èƒ½åŠ›å’Œå¯ä¿¡åº¦çš„å…³é”®é¢†åŸŸã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æºä»£ç æ¼æ´åˆ†æä¸­çš„ä¸è¶³ï¼Œç‰¹åˆ«æ˜¯å¯¹ç»“æ„å’Œè¯­ä¹‰æ¨ç†çš„å¿½è§†ã€‚ç°æœ‰ç ”ç©¶å¤šé›†ä¸­äºæ¼æ´æ£€æµ‹å’Œä¿®å¤ï¼Œç¼ºä¹å¯¹æ¨¡å‹æ¨ç†èƒ½åŠ›çš„å…¨é¢è¯„ä¼°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSV-TrustEval-CåŸºå‡†é€šè¿‡ç»“æ„æ¨ç†å’Œè¯­ä¹‰æ¨ç†ä¸¤ä¸ªç»´åº¦ï¼Œç³»ç»Ÿè¯„ä¼°LLMsåœ¨åˆ†æCè¯­è¨€ä»£ç æ¼æ´æ—¶çš„èƒ½åŠ›ã€‚ç»“æ„æ¨ç†å…³æ³¨ä»£ç å…ƒç´ ä¹‹é—´çš„å…³ç³»ï¼Œè€Œè¯­ä¹‰æ¨ç†åˆ™è€ƒå¯Ÿæ¨¡å‹åœ¨ç»“æ„å’Œè¯­ä¹‰æ‰°åŠ¨ä¸‹çš„é€»è¾‘ä¸€è‡´æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSV-TrustEval-Cçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€è¯„ä¼°æŒ‡æ ‡è®¾è®¡å’Œå®éªŒéªŒè¯ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚æ•°æ®é›†æ¶µç›–å¤šç§ä»£ç ç»“æ„å’Œè¯­ä¹‰æ‰°åŠ¨åœºæ™¯ï¼Œè¯„ä¼°æŒ‡æ ‡åˆ™ç”¨äºé‡åŒ–æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šSV-TrustEval-Cçš„åˆ›æ–°ä¹‹å¤„åœ¨äºå…¶åŒç»´åº¦è¯„ä¼°æ–¹æ³•ï¼Œç»“åˆç»“æ„å’Œè¯­ä¹‰æ¨ç†ï¼Œå¡«è¡¥äº†ç°æœ‰è¯„ä¼°æ–¹æ³•çš„ç©ºç™½ã€‚è¿™ç§è®¾è®¡ä½¿å¾—è¯„ä¼°ç»“æœæ›´å…·å¯ä¿¡åº¦å’Œå®ç”¨æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®é›†æ„å»ºä¸­ï¼Œè®¾ç½®äº†å¤šç§å¤æ‚çš„æ•°æ®å’Œæ§åˆ¶æµåœºæ™¯ï¼Œä»¥æµ‹è¯•æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚è¯„ä¼°æŒ‡æ ‡åŒ…æ‹¬æ¨¡å‹åœ¨ä¸åŒæ‰°åŠ¨ä¸‹çš„é€»è¾‘ä¸€è‡´æ€§å’Œæ¨ç†å‡†ç¡®æ€§ï¼Œç¡®ä¿å…¨é¢è¯„ä¼°LLMsçš„èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå½“å‰LLMsåœ¨å¤æ‚ä»£ç å…³ç³»ç†è§£æ–¹é¢çš„è¡¨ç°è¿œæœªè¾¾åˆ°é¢„æœŸï¼Œä¸»è¦ä¾èµ–æ¨¡å¼åŒ¹é…è€Œéé€»è¾‘æ¨ç†ã€‚SV-TrustEval-CåŸºå‡†çš„å¼•å…¥ï¼Œæ­ç¤ºäº†LLMsåœ¨æ¼æ´åˆ†æä¸­çš„å…³é”®çŸ­æ¿ï¼Œä¸ºåç»­ç ”ç©¶æä¾›äº†æ˜ç¡®çš„æ”¹è¿›æ–¹å‘ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è½¯ä»¶å®‰å…¨ã€ä»£ç å®¡è®¡å’Œè‡ªåŠ¨åŒ–æ¼æ´æ£€æµ‹ç­‰ã€‚é€šè¿‡æå‡LLMsåœ¨æ¼æ´åˆ†æä¸­çš„æ¨ç†èƒ½åŠ›ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæé«˜ä»£ç å®‰å…¨æ€§ï¼Œå‡å°‘æ½œåœ¨çš„å®‰å…¨éšæ‚£ã€‚æœªæ¥ï¼Œè¯¥åŸºå‡†æœ‰æœ›æ¨åŠ¨LLMsåœ¨å®é™…åº”ç”¨ä¸­çš„å¯ä¿¡åº¦å’Œå¯é æ€§æå‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> As Large Language Models (LLMs) evolve in understanding and generating code, accurately evaluating their reliability in analyzing source code vulnerabilities becomes increasingly vital. While studies have examined LLM capabilities in tasks like vulnerability detection and repair, they often overlook the importance of both structure and semantic reasoning crucial for trustworthy vulnerability analysis. To address this gap, we introduce SV-TrustEval-C, a benchmark designed to evaluate LLMs' abilities for vulnerability analysis of code written in the C programming language through two key dimensions: structure reasoning - assessing how models identify relationships between code elements under varying data and control flow complexities; and semantic reasoning - examining their logical consistency in scenarios where code is structurally and semantically perturbed. Our results show that current LLMs are far from satisfactory in understanding complex code relationships and that their vulnerability analyses rely more on pattern matching than on robust logical reasoning. These findings underscore the effectiveness of the SV-TrustEval-C benchmark and highlight critical areas for enhancing the reasoning capabilities and trustworthiness of LLMs in real-world vulnerability analysis tasks. Our initial benchmark dataset is publicly available.

