---
layout: default
title: Can LLMs Learn to Map the World from Local Descriptions?
---

# Can LLMs Learn to Map the World from Local Descriptions?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20874" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.20874v1</a>
  <a href="https://arxiv.org/pdf/2505.20874.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20874v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20874v1', 'Can LLMs Learn to Map the World from Local Descriptions?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sirui Xia, Aili Chen, Xintao Wang, Tinghui Zhu, Yikai Zhang, Jiangjie Chen, Yanghua Xiao

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27

**å¤‡æ³¨**: 19 pages, 11 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåˆ©ç”¨LLMsæ„å»ºå…¨çƒç©ºé—´è®¤çŸ¥ä»¥è§£å†³å±€éƒ¨æè¿°æ˜ å°„é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ç©ºé—´è®¤çŸ¥` `è·¯å¾„è§„åˆ’` `ç©ºé—´æ„ŸçŸ¥` `åŠ¨æ€å¯¼èˆª`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç©ºé—´è®¤çŸ¥æ–¹é¢çš„ç ”ç©¶ç›¸å¯¹ä¸è¶³ï¼Œå°¤å…¶æ˜¯å¦‚ä½•ä»å±€éƒ¨æè¿°æ„å»ºå…¨çƒç©ºé—´è®¤çŸ¥ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚
2. æœ¬ç ”ç©¶æå‡ºé€šè¿‡æ•´åˆå±€éƒ¨å…³ç³»æè¿°ï¼Œåˆ©ç”¨LLMsè¿›è¡Œç©ºé—´æ„ŸçŸ¥å’Œå¯¼èˆªï¼Œä»è€Œå®ç°å…¨çƒç©ºé—´è®¤çŸ¥çš„æ„å»ºã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMsèƒ½å¤Ÿæœ‰æ•ˆæ¨å¹¿æœªè§çš„ç©ºé—´å…³ç³»ï¼Œå¹¶åœ¨è·¯å¾„è§„åˆ’å’ŒåŠ¨æ€å¯¼èˆªä¸­å±•ç°å‡ºä¼˜è¶Šçš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä»£ç å’Œæ•°å­¦ç­‰ä»»åŠ¡ä¸­å±•ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå®ƒä»¬åœ¨å†…åŒ–ç»“æ„åŒ–ç©ºé—´çŸ¥è¯†æ–¹é¢çš„æ½œåŠ›ä»æœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚æœ¬ç ”ç©¶è°ƒæŸ¥äº†LLMsæ˜¯å¦èƒ½å¤ŸåŸºäºå±€éƒ¨ç›¸å¯¹çš„äººç±»è§‚å¯Ÿï¼Œæ•´åˆé›¶æ•£çš„å…³ç³»æè¿°ï¼Œæ„å»ºè¿è´¯çš„å…¨çƒç©ºé—´è®¤çŸ¥ã€‚æˆ‘ä»¬å…³æ³¨ç©ºé—´è®¤çŸ¥çš„ä¸¤ä¸ªæ ¸å¿ƒæ–¹é¢ï¼šç©ºé—´æ„ŸçŸ¥å’Œç©ºé—´å¯¼èˆªã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMsä¸ä»…èƒ½å¤Ÿæ¨å¹¿åˆ°æœªè§çš„å…´è¶£ç‚¹ï¼ˆPOIï¼‰ä¹‹é—´çš„ç©ºé—´å…³ç³»ï¼Œè¿˜èƒ½å­¦ä¹ é“è·¯è¿é€šæ€§ï¼Œå®ç°å‡†ç¡®çš„è·¯å¾„è§„åˆ’å’ŒåŠ¨æ€ç©ºé—´æ„è¯†ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¦‚ä½•ä»å±€éƒ¨æè¿°ä¸­æ„å»ºå…¨çƒç©ºé—´è®¤çŸ¥çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†ç©ºé—´å…³ç³»æ—¶å¾€å¾€æ— æ³•æœ‰æ•ˆæ•´åˆå±€éƒ¨ä¿¡æ¯ï¼Œå¯¼è‡´å…¨çƒå¸ƒå±€çš„æ¨æ–­ä¸å‡†ç¡®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ•´åˆå±€éƒ¨ç›¸å¯¹æè¿°ï¼Œæ„å»ºä¸€è‡´çš„å…¨çƒç©ºé—´è®¤çŸ¥ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹èƒ½å¤Ÿä»å±€éƒ¨ä¿¡æ¯ä¸­æ¨æ–­å‡ºå…¨å±€å¸ƒå±€ï¼Œå¹¶å­¦ä¹ é“è·¯è¿é€šæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šç©ºé—´æ„ŸçŸ¥æ¨¡å—å’Œç©ºé—´å¯¼èˆªæ¨¡å—ã€‚ç©ºé—´æ„ŸçŸ¥æ¨¡å—è´Ÿè´£ä»å±€éƒ¨å…³ç³»ä¸­æ¨æ–­å…¨çƒå¸ƒå±€ï¼Œè€Œç©ºé—´å¯¼èˆªæ¨¡å—åˆ™åŸºäºè½¨è¿¹æ•°æ®å­¦ä¹ é“è·¯è¿æ¥æ€§å¹¶è¿›è¡Œè·¯å¾„è§„åˆ’ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºLLMsèƒ½å¤Ÿæœ‰æ•ˆæ•´åˆå±€éƒ¨æè¿°ï¼Œç”Ÿæˆä¸çœŸå®ä¸–ç•Œç©ºé—´åˆ†å¸ƒç›¸ä¸€è‡´çš„æ½œåœ¨è¡¨ç¤ºã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„ç©ºé—´è®¤çŸ¥æ¨¡å‹ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†å¤æ‚çš„ç©ºé—´å…³ç³»ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–ç©ºé—´å¸ƒå±€çš„æ¨æ–­å‡†ç¡®æ€§ï¼Œå¹¶é€šè¿‡è°ƒæ•´ç½‘ç»œç»“æ„æ¥å¢å¼ºæ¨¡å‹å¯¹å±€éƒ¨ä¿¡æ¯çš„æ•æ„Ÿæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMsèƒ½å¤Ÿæœ‰æ•ˆæ¨å¹¿åˆ°æœªè§çš„ç©ºé—´å…³ç³»ï¼Œä¸”åœ¨è·¯å¾„è§„åˆ’ä»»åŠ¡ä¸­è¡¨ç°å‡ºè¾ƒé«˜çš„å‡†ç¡®æ€§ã€‚ä¸åŸºçº¿æ¨¡å‹ç›¸æ¯”ï¼ŒLLMsåœ¨ç©ºé—´å¸ƒå±€æ¨æ–­å’ŒåŠ¨æ€å¯¼èˆªæ–¹é¢çš„æ€§èƒ½æå‡æ˜¾è‘—ï¼Œè¯æ˜äº†å…¶åœ¨ç©ºé—´è®¤çŸ¥é¢†åŸŸçš„åº”ç”¨æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å¯¼èˆªç³»ç»Ÿã€åŸå¸‚è§„åˆ’å’Œæœºå™¨äººè·¯å¾„è§„åˆ’ç­‰ã€‚é€šè¿‡æå‡LLMsåœ¨ç©ºé—´è®¤çŸ¥æ–¹é¢çš„èƒ½åŠ›ï¼Œå¯ä»¥ä¸ºè‡ªåŠ¨é©¾é©¶ã€æ— äººæœºå¯¼èˆªç­‰æŠ€æœ¯æä¾›æ›´ä¸ºç²¾å‡†çš„æ”¯æŒï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in Large Language Models (LLMs) have demonstrated strong capabilities in tasks such as code and mathematics. However, their potential to internalize structured spatial knowledge remains underexplored. This study investigates whether LLMs, grounded in locally relative human observations, can construct coherent global spatial cognition by integrating fragmented relational descriptions. We focus on two core aspects of spatial cognition: spatial perception, where models infer consistent global layouts from local positional relationships, and spatial navigation, where models learn road connectivity from trajectory data and plan optimal paths between unconnected locations. Experiments conducted in a simulated urban environment demonstrate that LLMs not only generalize to unseen spatial relationships between points of interest (POIs) but also exhibit latent representations aligned with real-world spatial distributions. Furthermore, LLMs can learn road connectivity from trajectory descriptions, enabling accurate path planning and dynamic spatial awareness during navigation.

