---
layout: default
title: "Factual Self-Awareness in Language Models: Representation, Robustness, and Scaling"
---

# Factual Self-Awareness in Language Models: Representation, Robustness, and Scaling

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21399" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21399v1</a>
  <a href="https://arxiv.org/pdf/2505.21399.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21399v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21399v1', 'Factual Self-Awareness in Language Models: Representation, Robustness, and Scaling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hovhannes Tamoyan, Subhabrata Dutta, Iryna Gurevych

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè¯­è¨€æ¨¡å‹çš„äº‹å®è‡ªæˆ‘æ„è¯†ä»¥æé«˜ç”Ÿæˆå†…å®¹çš„å‡†ç¡®æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯­è¨€æ¨¡å‹` `äº‹å®è‡ªæˆ‘æ„è¯†` `ç”Ÿæˆå†…å®¹` `å¯è§£é‡Šæ€§` `é²æ£’æ€§` `ä¸Šä¸‹æ–‡æ‰°åŠ¨` `æ¨¡å‹è®­ç»ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆå†…å®¹æ—¶å¸¸å‡ºç°äº‹å®ä¸å‡†ç¡®çš„é—®é¢˜ï¼Œå½±å“å…¶å¯é æ€§å’Œåº”ç”¨æ•ˆæœã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„è§†è§’ï¼Œè®¤ä¸ºLLMsåœ¨ç”Ÿæˆå†…å®¹æ—¶å…·å¤‡å†…éƒ¨çš„è‡ªæˆ‘æ„è¯†æœºåˆ¶ï¼Œèƒ½å¤Ÿå®æ—¶åˆ¤æ–­ç”Ÿæˆå†…å®¹çš„äº‹å®æ­£ç¡®æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMsçš„è‡ªæˆ‘æ„è¯†åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¿…é€Ÿå½¢æˆï¼Œå¹¶åœ¨ä¸­é—´å±‚è¾¾åˆ°æœ€ä½³è¡¨ç°ï¼Œå¢å¼ºäº†æ¨¡å‹çš„å¯è§£é‡Šæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç”Ÿæˆå†…å®¹ä¸­çš„äº‹å®ä¸å‡†ç¡®æ€§æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¹¿æ³›åº”ç”¨ä¸­çš„ä¸»è¦é—®é¢˜ä¹‹ä¸€ã€‚å…ˆå‰çš„ç ”ç©¶è¡¨æ˜ï¼ŒLLMsåœ¨ç”Ÿæˆå†…å®¹åèƒ½å¤Ÿæ£€æµ‹äº‹å®ä¸å‡†ç¡®æ€§ã€‚æœ¬æ–‡æä¾›è¯æ®æ”¯æŒLLMsåœ¨ç”Ÿæˆæ—¶å…·å¤‡å†…éƒ¨æŒ‡å—ï¼Œå†³å®šäº‹å®å›å¿†çš„æ­£ç¡®æ€§ã€‚æˆ‘ä»¬å±•ç¤ºäº†åœ¨ç»™å®šä¸»é¢˜å®ä½“å’Œå…³ç³»æ—¶ï¼ŒLLMsåœ¨å˜æ¢å™¨çš„æ®‹å·®æµä¸­å†…éƒ¨ç¼–ç çº¿æ€§ç‰¹å¾ï¼Œå†³å®šå…¶èƒ½å¦å›å¿†æ­£ç¡®å±æ€§ã€‚è¿™ç§è‡ªæˆ‘æ„è¯†ä¿¡å·å¯¹å°çš„æ ¼å¼å˜åŒ–å…·æœ‰é²æ£’æ€§ã€‚æˆ‘ä»¬ç ”ç©¶äº†é€šè¿‡ä¸åŒç¤ºä¾‹é€‰æ‹©ç­–ç•¥è¿›è¡Œä¸Šä¸‹æ–‡æ‰°åŠ¨çš„å½±å“ã€‚è·¨æ¨¡å‹è§„æ¨¡å’Œè®­ç»ƒåŠ¨æ€çš„æ‰©å±•å®éªŒè¡¨æ˜ï¼Œè‡ªæˆ‘æ„è¯†åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¿…é€Ÿå‡ºç°ï¼Œå¹¶åœ¨ä¸­é—´å±‚è¾¾åˆ°å³°å€¼ã€‚è¿™äº›å‘ç°æ­ç¤ºäº†LLMså†…åœ¨çš„è‡ªæˆ‘ç›‘æ§èƒ½åŠ›ï¼Œæå‡äº†å…¶å¯è§£é‡Šæ€§å’Œå¯é æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆå†…å®¹æ—¶çš„äº‹å®ä¸å‡†ç¡®æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–åç”Ÿæˆçš„äº‹å®æ£€æŸ¥ï¼Œç¼ºä¹å®æ—¶åˆ¤æ–­æœºåˆ¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºLLMsåœ¨ç”Ÿæˆå†…å®¹æ—¶å…·å¤‡å†…éƒ¨è‡ªæˆ‘æ„è¯†ï¼Œèƒ½å¤Ÿåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­åˆ¤æ–­äº‹å®çš„æ­£ç¡®æ€§ï¼Œä»è€Œæé«˜ç”Ÿæˆå†…å®¹çš„å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬è¾“å…¥çš„ä¸»é¢˜å®ä½“å’Œå…³ç³»ï¼Œé€šè¿‡å˜æ¢å™¨çš„æ®‹å·®æµè¿›è¡Œç‰¹å¾ç¼–ç ï¼Œæœ€ç»ˆè¾“å‡ºæ­£ç¡®çš„å±æ€§ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€ç‰¹å¾æå–å’Œç»“æœç”Ÿæˆã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæ­ç¤ºäº†LLMså†…éƒ¨çš„è‡ªæˆ‘ç›‘æ§èƒ½åŠ›ï¼ŒåŒºåˆ«äºä¼ ç»Ÿçš„åç”Ÿæˆæ£€æŸ¥æ–¹æ³•ï¼Œæä¾›äº†å®æ—¶çš„äº‹å®åˆ¤æ–­æœºåˆ¶ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¼ºåŒ–è‡ªæˆ‘æ„è¯†ä¿¡å·çš„å­¦ä¹ ï¼Œå¹¶é€šè¿‡ä¸åŒçš„ä¸Šä¸‹æ–‡æ‰°åŠ¨ç­–ç•¥è¿›è¡Œå®éªŒéªŒè¯ï¼Œç¡®ä¿æ¨¡å‹çš„é²æ£’æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMsåœ¨ä¸­é—´å±‚çš„è‡ªæˆ‘æ„è¯†ä¿¡å·æ˜¾è‘—å¢å¼ºï¼Œèƒ½å¤Ÿåœ¨å¤šç§ä¸Šä¸‹æ–‡æ‰°åŠ¨ä¸‹ä¿æŒé²æ£’æ€§ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæ¨¡å‹åœ¨äº‹å®å‡†ç¡®æ€§ä¸Šçš„æå‡å¹…åº¦è¾¾åˆ°20%ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨ç”Ÿæˆå†…å®¹æ—¶çš„å¯é æ€§å’Œå¯è§£é‡Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€å†…å®¹ç”Ÿæˆå’Œæ•™è‚²æŠ€æœ¯ç­‰ã€‚é€šè¿‡æé«˜ç”Ÿæˆå†…å®¹çš„å‡†ç¡®æ€§ï¼Œèƒ½å¤Ÿå¢å¼ºç”¨æˆ·ä½“éªŒå’Œä¿¡ä»»åº¦ï¼Œæ¨åŠ¨è¯­è¨€æ¨¡å‹åœ¨å®é™…åœºæ™¯ä¸­çš„å¹¿æ³›åº”ç”¨ã€‚æœªæ¥ï¼Œéšç€æŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ï¼ŒLLMsçš„è‡ªæˆ‘æ„è¯†æœºåˆ¶å¯èƒ½ä¼šåœ¨æ›´å¤šå¤æ‚ä»»åŠ¡ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Factual incorrectness in generated content is one of the primary concerns in ubiquitous deployment of large language models (LLMs). Prior findings suggest LLMs can (sometimes) detect factual incorrectness in their generated content (i.e., fact-checking post-generation). In this work, we provide evidence supporting the presence of LLMs' internal compass that dictate the correctness of factual recall at the time of generation. We demonstrate that for a given subject entity and a relation, LLMs internally encode linear features in the Transformer's residual stream that dictate whether it will be able to recall the correct attribute (that forms a valid entity-relation-attribute triplet). This self-awareness signal is robust to minor formatting variations. We investigate the effects of context perturbation via different example selection strategies. Scaling experiments across model sizes and training dynamics highlight that self-awareness emerges rapidly during training and peaks in intermediate layers. These findings uncover intrinsic self-monitoring capabilities within LLMs, contributing to their interpretability and reliability.

