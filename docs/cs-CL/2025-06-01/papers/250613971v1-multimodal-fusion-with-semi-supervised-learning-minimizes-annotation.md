---
layout: default
title: Multimodal Fusion with Semi-Supervised Learning Minimizes Annotation Quantity for Modeling Videoconference Conversation Experience
---

# Multimodal Fusion with Semi-Supervised Learning Minimizes Annotation Quantity for Modeling Videoconference Conversation Experience

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.13971" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.13971v1</a>
  <a href="https://arxiv.org/pdf/2506.13971.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.13971v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.13971v1', 'Multimodal Fusion with Semi-Supervised Learning Minimizes Annotation Quantity for Modeling Videoconference Conversation Experience')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Andrew Chang, Chenkai Hu, Ji Qi, Zhuojian Wei, Kexin Zhang, Viswadruth Akkaraju, David Poeppel, Dustin Freeman

**åˆ†ç±»**: eess.AS, cs.CL, cs.HC, cs.LG, cs.MM

**å‘å¸ƒæ—¥æœŸ**: 2025-06-01

**å¤‡æ³¨**: Interspeech 2025

**DOI**: [10.21437/Interspeech.2025-2451](https://doi.org/10.21437/Interspeech.2025-2451)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŠç›‘ç£å­¦ä¹ æ–¹æ³•ä»¥å‡å°‘è§†é¢‘ä¼šè®®å¯¹è¯ä½“éªŒå»ºæ¨¡çš„æ ‡æ³¨éœ€æ±‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†é¢‘ä¼šè®®` `åŠç›‘ç£å­¦ä¹ ` `å¤šæ¨¡æ€èåˆ` `å¯¹è¯ä½“éªŒ` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å»ºæ¨¡è§†é¢‘ä¼šè®®å¯¹è¯ä½“éªŒæ—¶ï¼Œé¢ä¸´æ ‡æ³¨æ•°æ®ç¨€ç¼ºå’Œæ˜‚è´µçš„æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯è´Ÿé¢ä½“éªŒçš„æ—¶åˆ»ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŠç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œç»“åˆæ ‡æ³¨å’Œæœªæ ‡æ³¨æ•°æ®ï¼Œåˆ©ç”¨å¤šæ¨¡æ€ç‰¹å¾æ¥é¢„æµ‹å¯¹è¯ä¸­çš„éæµç•…æ—¶åˆ»ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŠç›‘ç£å­¦ä¹ æ¨¡å‹åœ¨ç›¸åŒæ ‡æ³¨æ•°æ®é‡ä¸‹ï¼Œæ€§èƒ½è¶…è¶Šç›‘ç£å­¦ä¹ æ¨¡å‹ï¼Œä¸”ä»…éœ€8%æ ‡æ³¨æ•°æ®å³å¯æ¥è¿‘å…¨æ•°æ®æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†é¢‘ä¼šè®®ä¸­çš„ç¾¤ä½“å¯¹è¯æ˜¯ä¸€ç§å¤æ‚çš„ç¤¾ä¼šè¡Œä¸ºï¼Œä½†è´Ÿé¢ä½“éªŒçš„ä¸»è§‚æ—¶åˆ»ï¼Œå¦‚å¯¹è¯å¤±å»æµç•…æ€§æˆ–ä¹è¶£ï¼Œä»ç„¶ç¼ºä¹ç ”ç©¶ã€‚è¿™äº›æ—¶åˆ»åœ¨è‡ªç„¶æ•°æ®ä¸­è¾ƒä¸ºç½•è§ï¼Œå› æ­¤è®­ç»ƒç›‘ç£å­¦ä¹ æ¨¡å‹éœ€è¦æ˜‚è´µçš„æ‰‹åŠ¨æ•°æ®æ ‡æ³¨ã€‚æœ¬æ–‡åº”ç”¨åŠç›‘ç£å­¦ä¹ ï¼Œåˆ©ç”¨æœ‰é’ˆå¯¹æ€§çš„æ ‡æ³¨å’Œæœªæ ‡æ³¨ç‰‡æ®µï¼Œè®­ç»ƒå¤šæ¨¡æ€ï¼ˆéŸ³é¢‘ã€é¢éƒ¨ã€æ–‡æœ¬ï¼‰æ·±åº¦ç‰¹å¾ï¼Œä»¥é¢„æµ‹è§†é¢‘ä¼šè®®ä¸­çš„éæµç•…æˆ–ä¸æ„‰å¿«æ—¶åˆ»ã€‚é€šè¿‡æ¨¡æ€èåˆçš„å…±åŒè®­ç»ƒï¼ŒåŠç›‘ç£å­¦ä¹ æ¨¡å‹å®ç°äº†0.9çš„ROC-AUCå’Œ0.6çš„F1åˆ†æ•°ï¼Œè¶…è¶Šäº†ç›¸åŒæ ‡æ³¨æ•°æ®é‡çš„ç›‘ç£å­¦ä¹ æ¨¡å‹4%ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæœ€ä½³çš„åŠç›‘ç£å­¦ä¹ æ¨¡å‹ä»…ä½¿ç”¨8%çš„æ ‡æ³¨æ•°æ®ï¼Œä¾¿è¾¾åˆ°äº†ç›‘ç£å­¦ä¹ æ¨¡å‹å…¨æ•°æ®æ€§èƒ½çš„96%ã€‚è¿™è¡¨æ˜äº†ä¸€ç§é«˜æ•ˆçš„æ ‡æ³¨æ¡†æ¶ï¼Œç”¨äºå»ºæ¨¡è§†é¢‘ä¼šè®®ä½“éªŒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è§†é¢‘ä¼šè®®å¯¹è¯ä¸­è´Ÿé¢ä½“éªŒæ—¶åˆ»çš„å»ºæ¨¡é—®é¢˜ã€‚ç°æœ‰çš„ç›‘ç£å­¦ä¹ æ–¹æ³•ä¾èµ–å¤§é‡æ ‡æ³¨æ•°æ®ï¼Œè€Œè¿™äº›æ•°æ®çš„è·å–æˆæœ¬é«˜ä¸”ç¨€ç¼ºã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºé€šè¿‡åŠç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œç»“åˆå°‘é‡æ ‡æ³¨æ•°æ®ä¸å¤§é‡æœªæ ‡æ³¨æ•°æ®ï¼Œåˆ©ç”¨å¤šæ¨¡æ€ç‰¹å¾ï¼ˆéŸ³é¢‘ã€é¢éƒ¨è¡¨æƒ…ã€æ–‡æœ¬ï¼‰æ¥æé«˜æ¨¡å‹çš„é¢„æµ‹èƒ½åŠ›ã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨å‡å°‘å¯¹æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼ŒåŒæ—¶æå‡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€ç‰¹å¾æå–ã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°å››ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œä»è§†é¢‘ä¸­æå–éŸ³é¢‘ã€é¢éƒ¨å’Œæ–‡æœ¬ç‰¹å¾ï¼›ç„¶åï¼Œåˆ©ç”¨åŠç›‘ç£å­¦ä¹ æ¡†æ¶è¿›è¡Œæ¨¡å‹è®­ç»ƒï¼Œæœ€åè¯„ä¼°æ¨¡å‹åœ¨æœªè§æ•°æ®ä¸Šçš„è¡¨ç°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæ¨¡æ€èåˆçš„å…±åŒè®­ç»ƒç­–ç•¥ï¼Œé€šè¿‡æœ‰æ•ˆåˆ©ç”¨æ ‡æ³¨å’Œæœªæ ‡æ³¨æ•°æ®ï¼Œæ˜¾è‘—æé«˜äº†æ¨¡å‹åœ¨è´Ÿé¢ä½“éªŒé¢„æµ‹ä¸Šçš„å‡†ç¡®æ€§ã€‚è¿™ä¸ä¼ ç»Ÿçš„ç›‘ç£å­¦ä¹ æ–¹æ³•å½¢æˆé²œæ˜å¯¹æ¯”ï¼Œåè€…é€šå¸¸ä¾èµ–äºå¤§é‡æ ‡æ³¨æ•°æ®ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡æ ‡æ³¨å’Œæœªæ ‡æ³¨æ•°æ®çš„å½±å“ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†ä¼˜åŒ–ï¼Œä»¥é€‚åº”å¤šæ¨¡æ€ç‰¹å¾çš„èåˆã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ¨¡æ€èåˆçš„åŠç›‘ç£å­¦ä¹ æ¨¡å‹åœ¨ROC-AUCä¸Šè¾¾åˆ°äº†0.9ï¼ŒF1åˆ†æ•°ä¸º0.6ï¼Œè¶…è¶Šäº†ç›¸åŒæ ‡æ³¨æ•°æ®é‡çš„ç›‘ç£å­¦ä¹ æ¨¡å‹4%ã€‚æ­¤å¤–ï¼Œæœ€ä½³åŠç›‘ç£å­¦ä¹ æ¨¡å‹ä»…ä½¿ç”¨8%çš„æ ‡æ³¨æ•°æ®ï¼Œä¾¿è¾¾åˆ°äº†ç›‘ç£å­¦ä¹ æ¨¡å‹å…¨æ•°æ®æ€§èƒ½çš„96%ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ ‡æ³¨æ•ˆç‡æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è§†é¢‘ä¼šè®®è½¯ä»¶ã€åœ¨çº¿æ•™è‚²å¹³å°å’Œè¿œç¨‹åä½œå·¥å…·ç­‰ã€‚é€šè¿‡æœ‰æ•ˆè¯†åˆ«å¯¹è¯ä¸­çš„è´Ÿé¢ä½“éªŒæ—¶åˆ»ï¼Œå¯ä»¥ä¸ºç”¨æˆ·æä¾›å®æ—¶åé¦ˆå’Œæ”¹å–„å»ºè®®ï¼Œä»è€Œæå‡æ•´ä½“æ²Ÿé€šä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–ç¤¾äº¤äº’åŠ¨åœºæ™¯ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Group conversations over videoconferencing are a complex social behavior. However, the subjective moments of negative experience, where the conversation loses fluidity or enjoyment remain understudied. These moments are infrequent in naturalistic data, and thus training a supervised learning (SL) model requires costly manual data annotation. We applied semi-supervised learning (SSL) to leverage targeted labeled and unlabeled clips for training multimodal (audio, facial, text) deep features to predict non-fluid or unenjoyable moments in holdout videoconference sessions. The modality-fused co-training SSL achieved an ROC-AUC of 0.9 and an F1 score of 0.6, outperforming SL models by up to 4% with the same amount of labeled data. Remarkably, the best SSL model with just 8% labeled data matched 96% of the SL model's full-data performance. This shows an annotation-efficient framework for modeling videoconference experience.

