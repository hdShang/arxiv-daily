---
layout: default
title: One for All: Update Parameterized Knowledge Across Multiple Models
---

# One for All: Update Parameterized Knowledge Across Multiple Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.00817" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.00817v1</a>
  <a href="https://arxiv.org/pdf/2506.00817.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.00817v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.00817v1', 'One for All: Update Parameterized Knowledge Across Multiple Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Weitao Ma, Xiyuan Du, Xiaocheng Feng, Lei Huang, Yichong Huang, Huiyi Zhang, Xiaoliang Yang, Baohang Li, Xiachong Feng, Ting Liu, Bing Qin

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-01

**å¤‡æ³¨**: ACL 2025 (Main Conference)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOnceEditä»¥è§£å†³å¤šæ¨¡å‹çŸ¥è¯†æ›´æ–°é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `çŸ¥è¯†ç¼–è¾‘` `å¤§å‹è¯­è¨€æ¨¡å‹` `å¤šæ¨¡å‹æ›´æ–°` `åŠ¨æ€æƒé‡æœºåˆ¶` `é›†æˆå­¦ä¹ ` `äººå·¥æ™ºèƒ½` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çŸ¥è¯†ç¼–è¾‘æ–¹æ³•ä¸»è¦é›†ä¸­äºå•ä¸ªæ¨¡å‹ï¼Œéš¾ä»¥é«˜æ•ˆæ›´æ–°å¤šä¸ªæ¨¡å‹ï¼Œå°¤å…¶æ˜¯åœ¨é¢å¯¹æ–°æ¨¡å‹æ—¶ã€‚
2. æœ¬æ–‡æå‡ºOnceEditï¼Œé€šè¿‡æ’ä»¶æ¨¡å‹ä½œä¸ºç¼–è¾‘æ¨¡å—ï¼Œåˆ©ç”¨åŠ¨æ€æƒé‡å’Œé›†æˆå¢å¼ºæœºåˆ¶ï¼Œå®ç°å¤šä¸ªæ¨¡å‹çš„çŸ¥è¯†æ›´æ–°ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºOnceEditåœ¨å¤šç§å¤§å‹è¯­è¨€æ¨¡å‹ä¸Šå‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸”ç¼–è¾‘æ•ˆç‡æ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç¼–ç äº†å¤§é‡çš„ä¸–ç•ŒçŸ¥è¯†ï¼Œä½†åœ¨ä¿æŒçŸ¥è¯†æ›´æ–°æ–¹é¢å­˜åœ¨å›°éš¾ï¼Œå¸¸å¯¼è‡´é”™è¯¯å’Œå¹»è§‰ã€‚çŸ¥è¯†ç¼–è¾‘æä¾›äº†ä¸€ç§é«˜æ•ˆçš„æ›¿ä»£æ–¹æ¡ˆï¼Œé€šè¿‡æ›´æ–°ç‰¹å®šæ¨¡å‹å‚æ•°è¿›è¡Œæœ‰é’ˆå¯¹æ€§çš„ä¿®æ”¹ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨å•ä¸ªæ¨¡å‹ä¸Šï¼Œå¯¼è‡´åœ¨é«˜æ•ˆæ›´æ–°å¤šä¸ªæ¨¡å‹å’Œé€‚åº”æ–°æ¨¡å‹æ—¶é¢ä¸´æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºOnceEditï¼Œä¸€ç§æ–°é¢–çš„åŸºäºé›†æˆçš„æ–¹æ³•ï¼Œåˆ©ç”¨æ’ä»¶æ¨¡å‹ä½œä¸ºç¼–è¾‘æ¨¡å—ï¼Œå®ç°å¤šä¸ªæ¨¡å‹é—´çš„ç¨³å®šçŸ¥è¯†æ›´æ–°ã€‚OnceEditå¼•å…¥äº†åŠ¨æ€æƒé‡æœºåˆ¶å’Œé›†æˆå¢å¼ºæœºåˆ¶ï¼Œæ˜¾è‘—æå‡äº†çŸ¥è¯†ç¼–è¾‘çš„æ•ˆç‡å’Œé€‚åº”æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒOnceEditåœ¨å¤šç§LLMä¸Šè¡¨ç°ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸”åœ¨å¤šæ¨¡å‹ç¼–è¾‘åœºæ™¯ä¸­å…·æœ‰è‰¯å¥½çš„ç¨³å®šæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨çŸ¥è¯†æ›´æ–°æ–¹é¢çš„ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•ä¸»è¦é’ˆå¯¹å•ä¸ªæ¨¡å‹ï¼Œéš¾ä»¥å®ç°å¤šä¸ªæ¨¡å‹çš„é«˜æ•ˆæ›´æ–°ä¸é€‚åº”ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šOnceEdité€šè¿‡å¼•å…¥æ’ä»¶æ¨¡å‹ä½œä¸ºç¼–è¾‘æ¨¡å—ï¼Œç»“åˆåŠ¨æ€æƒé‡æœºåˆ¶å’Œé›†æˆå¢å¼ºæœºåˆ¶ï¼Œç¡®ä¿çŸ¥è¯†æ›´æ–°çš„ç¨³å®šæ€§å’Œæœ‰æ•ˆæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šOnceEditçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ’ä»¶æ¨¡å‹ã€åŠ¨æ€æƒé‡æœºåˆ¶å’Œé›†æˆå¢å¼ºæœºåˆ¶ã€‚æ’ä»¶æ¨¡å‹è´Ÿè´£çŸ¥è¯†ç¼–è¾‘ï¼ŒåŠ¨æ€æƒé‡æœºåˆ¶ç”¨äºåŒºåˆ†ç¼–è¾‘ç›¸å…³ä¸éç¼–è¾‘ç›¸å…³å®ä¾‹ï¼Œé›†æˆå¢å¼ºæœºåˆ¶åˆ™å‡å°‘å¯¹ä¸­å¿ƒæ¨¡å‹çš„è¿‡åº¦ä¾èµ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šOnceEditçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶åŠ¨æ€æƒé‡æœºåˆ¶å’Œé›†æˆå¢å¼ºæœºåˆ¶ï¼Œè¿™ä¸ä¼ ç»Ÿçš„å•æ¨¡å‹ç¼–è¾‘æ–¹æ³•å½¢æˆé²œæ˜å¯¹æ¯”ï¼Œæå‡äº†å¤šæ¨¡å‹çŸ¥è¯†æ›´æ–°çš„æ•ˆç‡ä¸ç¨³å®šæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒåŠ¨æ€æƒé‡æœºåˆ¶é€šè¿‡	extbackslash weight tokenæ¥ä¼˜åŒ–çŸ¥è¯†åˆ©ç”¨ï¼Œé›†æˆå¢å¼ºæœºåˆ¶åˆ™é€šè¿‡è°ƒæ•´æ¨¡å‹é—´çš„ä¾èµ–å…³ç³»ï¼Œç¡®ä¿çŸ¥è¯†ç¼–è¾‘è¿‡ç¨‹çš„æœ‰æ•ˆæ€§ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡å°šæœªè¯¦ç»†æŠ«éœ²ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å¤šç§å¤§å‹è¯­è¨€æ¨¡å‹çš„å®éªŒä¸­ï¼ŒOnceEditè¡¨ç°å‡ºè‰²ï¼Œ consistently outperforming existing methodsï¼Œç¼–è¾‘æ•ˆç‡æ˜¾è‘—æé«˜ã€‚å…·ä½“è€Œè¨€ï¼Œä¸åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼ŒOnceEditåœ¨çŸ¥è¯†æ›´æ–°çš„å‡†ç¡®æ€§å’Œç¨³å®šæ€§ä¸Šæå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨å¤šæ¨¡å‹ç¼–è¾‘åœºæ™¯ä¸­çš„ä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

OnceEditçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼ŒåŒ…æ‹¬æ™ºèƒ½å®¢æœã€è‡ªåŠ¨é—®ç­”ç³»ç»Ÿå’ŒçŸ¥è¯†ç®¡ç†å¹³å°ç­‰ã€‚é€šè¿‡é«˜æ•ˆçš„çŸ¥è¯†æ›´æ–°æœºåˆ¶ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡ç³»ç»Ÿçš„å“åº”å‡†ç¡®æ€§å’Œå®æ—¶æ€§ï¼Œè¿›è€Œæ¨åŠ¨äººå·¥æ™ºèƒ½æŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) encode vast world knowledge but struggle to stay up-to-date, often leading to errors and hallucinations. Knowledge editing offers an efficient alternative to retraining, enabling targeted modifications by updating specific model parameters. However, existing methods primarily focus on individual models, posing challenges in efficiently updating multiple models and adapting to new models. To address this, we propose OnceEdit, a novel ensemble-based approach that employs a plug-in model as the editing module, enabling stable knowledge updates across multiple models. Building on the model ensemble, OnceEdit introduces two key mechanisms to enhance its effectiveness. First, we introduce a dynamic weight mechanism through a \weight token for distinguishing between edit-related and non-edit-related instances, ensuring the appropriate utilization of knowledge from integrated models. Second, we incorporate an ensemble enhancement mechanism to mitigate the excessive reliance on the central model inherent in the model ensemble technique, making it more suitable for knowledge editing. Extensive experiments on diverse LLMs demonstrate that OnceEdit consistently outperforms existing methods while achieving superior editing efficiency. Further analysis confirms its adaptability and stability in multi-model editing scenarios. Our code will be available.

