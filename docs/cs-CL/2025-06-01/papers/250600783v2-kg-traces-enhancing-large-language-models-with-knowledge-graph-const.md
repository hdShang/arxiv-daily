---
layout: default
title: KG-TRACES: Enhancing Large Language Models with Knowledge Graph-constrained Trajectory Reasoning and Attribution Supervision
---

# KG-TRACES: Enhancing Large Language Models with Knowledge Graph-constrained Trajectory Reasoning and Attribution Supervision

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.00783" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.00783v2</a>
  <a href="https://arxiv.org/pdf/2506.00783.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.00783v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.00783v2', 'KG-TRACES: Enhancing Large Language Models with Knowledge Graph-constrained Trajectory Reasoning and Attribution Supervision')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Rong Wu, Pinlong Cai, Jianbiao Mei, Licheng Wen, Tao Hu, Xuemeng Yang, Daocheng Fu, Botian Shi

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-01 (æ›´æ–°: 2025-10-20)

**å¤‡æ³¨**: 24 pages, 13 figures

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Edaizi/KG-TRACES)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºKG-TRACESä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹æ¨ç†å¯è§£é‡Šæ€§ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `çŸ¥è¯†å›¾è°±` `æ¨ç†èƒ½åŠ›` `å¯è§£é‡Šæ€§` `å½’å› ç›‘ç£` `è‡ªç„¶è¯­è¨€å¤„ç†` `å¤æ‚æ¨ç†` `æ¨¡å‹ä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­ç¼ºä¹å¯è§£é‡Šæ€§ï¼Œå¯¼è‡´æ¨ç†è¿‡ç¨‹ä¸é€æ˜ï¼Œå½±å“å…¶åº”ç”¨ã€‚
2. KG-TRACESæ¡†æ¶é€šè¿‡æ˜¾å¼ç›‘ç£æ¨ç†è·¯å¾„ï¼Œæå‡æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œæ”¯æŒçŸ¥è¯†å›¾è°±å¯ç”¨å’Œä¸å¯ç”¨çš„åœºæ™¯ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒKG-TRACESåœ¨WebQSPå’ŒCWQä»»åŠ¡ä¸Šåˆ†åˆ«æå‡äº†1.6%å’Œ4.8%çš„Hits@1ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†åœ¨å¤æ‚æ¨ç†é—®é¢˜ä¸Šçš„è¡¨ç°ä»å—åˆ°å¯è§£é‡Šæ€§å’Œå¯ä¿¡åº¦ä¸è¶³çš„é™åˆ¶ã€‚è¿™ç§é—®é¢˜é€šå¸¸è¡¨ç°ä¸ºå¹»è§‰æˆ–æ— æ³•å½’å› çš„æ¨ç†è¿‡ç¨‹ï¼Œé™åˆ¶äº†å…¶åœ¨å¤æ‚æ¨ç†åœºæ™¯ä¸­çš„åº”ç”¨ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†çŸ¥è¯†å›¾è°±çº¦æŸçš„è½¨è¿¹æ¨ç†å½’å› ä¸é“¾å¼è§£é‡Šç›‘ç£ï¼ˆKG-TRACESï¼‰æ¡†æ¶ï¼Œé€šè¿‡å¯¹æ¨ç†è·¯å¾„å’Œè¿‡ç¨‹çš„æ˜¾å¼ç›‘ç£æ¥å¢å¼ºLLMsçš„æ¨ç†èƒ½åŠ›ã€‚KG-TRACESå…±åŒç›‘ç£æ¨¡å‹é¢„æµ‹ç¬¦å·å…³ç³»è·¯å¾„ã€å®Œæ•´ä¸‰å…ƒç»„æ¨ç†è·¯å¾„ï¼Œå¹¶ç”ŸæˆåŸºäºæ¨ç†è·¯å¾„çš„å½’å› æ„ŸçŸ¥æ¨ç†è¿‡ç¨‹ã€‚å®éªŒè¡¨æ˜ï¼ŒKG-TRACESåœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šæ˜¾è‘—è¶…è¶Šç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ï¼Œå±•ç¤ºäº†å…¶åœ¨åŒ»å­¦ç­‰ä¸“ä¸šé¢†åŸŸçš„è¿ç§»èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„å¯è§£é‡Šæ€§ä¸è¶³é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å¸¸å¸¸å¯¼è‡´æ¨ç†è¿‡ç¨‹çš„å¹»è§‰å’Œä¸é€æ˜æ€§ï¼Œé™åˆ¶äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å¯ä¿¡åº¦ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šKG-TRACESé€šè¿‡å¯¹æ¨ç†è·¯å¾„çš„æ˜¾å¼ç›‘ç£ï¼Œå¢å¼ºäº†æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨çŸ¥è¯†å›¾è°±å¯ç”¨å’Œä¸å¯ç”¨çš„æƒ…å†µä¸‹è¿›è¡Œåˆç†æ¨ç†ã€‚è¯¥è®¾è®¡ç¡®ä¿äº†æ¨ç†è¿‡ç¨‹çš„å¯è§£é‡Šæ€§å’Œå¯å½’å› æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šKG-TRACESæ¡†æ¶åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šç¬¦å·å…³ç³»è·¯å¾„é¢„æµ‹ã€å®Œæ•´ä¸‰å…ƒç»„æ¨ç†è·¯å¾„é¢„æµ‹å’ŒåŸºäºæ¨ç†è·¯å¾„çš„å½’å› æ„ŸçŸ¥æ¨ç†è¿‡ç¨‹ç”Ÿæˆã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œæ¨¡å‹æ ¹æ®çŸ¥è¯†å›¾è°±çš„å¯ç”¨æ€§é€‰æ‹©åˆé€‚çš„æ¨ç†è·¯å¾„ã€‚

**å…³é”®åˆ›æ–°**ï¼šKG-TRACESçš„åˆ›æ–°åœ¨äºå¼•å…¥äº†å¯¹æ¨ç†è·¯å¾„çš„æ˜¾å¼ç›‘ç£ï¼Œè¿™ä¸ä¼ ç»Ÿæ–¹æ³•çš„éšå¼å­¦ä¹ æ–¹å¼å½¢æˆäº†é²œæ˜å¯¹æ¯”ï¼Œä»è€Œæé«˜äº†æ¨ç†çš„ç¨³å®šæ€§å’Œç›®æ ‡å¯¼å‘æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ¨ç†è·¯å¾„çš„é¢„æµ‹ç²¾åº¦ï¼Œå¹¶é€šè¿‡å¯è§†åŒ–ä¸­é—´æ¨ç†æ­¥éª¤æ¥éªŒè¯æ¨ç†è¿‡ç¨‹çš„åˆç†æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

KG-TRACESåœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼ŒWebQSPä»»åŠ¡çš„Hits@1æå‡äº†1.6%ï¼ŒF1æå‡äº†4.7%ï¼›åœ¨CWQä»»åŠ¡ä¸Šï¼ŒHits@1æå‡äº†4.8%ï¼ŒF1æå‡äº†2.1%ã€‚è¿™äº›ç»“æœè¡¨æ˜KG-TRACESåœ¨æ¨ç†èƒ½åŠ›å’Œç¨³å®šæ€§æ–¹é¢çš„æ˜¾è‘—æ”¹è¿›ï¼Œè¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

KG-TRACESçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦é«˜å¯è§£é‡Šæ€§å’Œå¯ä¿¡åº¦çš„å¤æ‚æ¨ç†åœºæ™¯ä¸­ï¼Œå¦‚åŒ»ç–—è¯Šæ–­ã€æ³•å¾‹åˆ†æå’Œé‡‘èå†³ç­–ç­‰ã€‚é€šè¿‡æå‡æ¨¡å‹çš„æ¨ç†èƒ½åŠ›å’Œå¯è§£é‡Šæ€§ï¼Œè¯¥æ¡†æ¶æœ‰æœ›æ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿåœ¨å®é™…åº”ç”¨ä¸­çš„æ™®åŠå’Œä¿¡ä»»ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) have made remarkable strides in various natural language processing tasks, but their performance on complex reasoning problems remains hindered by a lack of explainability and trustworthiness. This issue, often manifesting as hallucinations or unattributable reasoning processes, limits their applicability in complex reasoning scenarios. To address this, we propose Knowledge Graph-constrained Trajectory Reasoning Attribution and Chain Explanation Supervision (KG-TRACES), a novel framework that enhances the reasoning ability of LLMs through explicit supervision over reasoning paths and processes. KG-TRACES jointly supervises the model to: (1) predict symbolic relation paths, (2) predict full triple-level reasoning paths, and (3) generate attribution-aware reasoning processes grounded in the reasoning paths. At inference phase, the model adapts to both KG-available and KG-unavailable scenarios, retrieving reasoning paths from a KG when possible or predicting plausible reasoning paths with only intrinsic knowledge when not. This design enables the model to reason in an explainable and source-attributable pattern. Through extensive experiments on complex reasoning tasks, we demonstrate that KG-TRACES significantly outperforms existing SOTA: it improves Hits@1 by 1.6% and F1 by 4.7% on WebQSP, and achieves improvements of 4.8% in Hits@1 and 2.1% in F1 on CWQ. Moreover, we show its transferability to specialized domains such as medicine. By visualizing the intermediate steps of reasoning processes, we further show that the explicit supervision introduced by KG-TRACES leads to more stable and goal-directed reasoning processes, aligning closely with correct answers. Code is available at https://github.com/Edaizi/KG-TRACES.

