---
layout: default
title: Understanding and Mitigating Cross-lingual Privacy Leakage via Language-specific and Universal Privacy Neurons
---

# Understanding and Mitigating Cross-lingual Privacy Leakage via Language-specific and Universal Privacy Neurons

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.00759" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.00759v2</a>
  <a href="https://arxiv.org/pdf/2506.00759.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.00759v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.00759v2', 'Understanding and Mitigating Cross-lingual Privacy Leakage via Language-specific and Universal Privacy Neurons')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wenshuo Dong, Qingsong Yang, Shu Yang, Lijie Hu, Meng Ding, Wanyu Lin, Tianhang Zheng, Di Wang

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-01 (æ›´æ–°: 2025-06-08)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè·¨è¯­è¨€éšç§æ³„éœ²é˜²æŠ¤æœºåˆ¶ä»¥è§£å†³LLMéšç§é£é™©é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `éšç§ä¿æŠ¤` `è·¨è¯­è¨€æ¨¡å‹` `å¤§å‹è¯­è¨€æ¨¡å‹` `éšç§ç¥ç»å…ƒ` `ä¿¡æ¯æµåˆ†æ` `æ•°æ®å®‰å…¨` `å¤šè¯­è¨€äº¤äº’`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•å‡è®¾è®­ç»ƒæ•°æ®å’Œç”¨æˆ·æŸ¥è¯¢å‡ä¸ºè‹±è¯­ï¼Œæ— æ³•æœ‰æ•ˆé˜²æ­¢è·¨è¯­è¨€éšç§æ³„éœ²ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡è¯†åˆ«éšç§é€šç”¨ç¥ç»å…ƒå’Œè¯­è¨€ç‰¹å®šéšç§ç¥ç»å…ƒï¼Œæ¥é™ä½è·¨è¯­è¨€éšç§æ³„éœ²é£é™©ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œåœç”¨è¿™äº›ç¥ç»å…ƒåï¼Œéšç§æ³„éœ²é£é™©é™ä½äº†23.3%-31.6%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æµ·é‡æ•°æ®ä¸Šè®­ç»ƒï¼Œæ•è·äº†ä¸°å¯Œçš„ä¿¡æ¯ï¼Œä½†ä¹Ÿå¼•å…¥äº†éšç§æ³„éœ²çš„é£é™©ï¼Œå°¤å…¶æ˜¯æ¶‰åŠä¸ªäººå¯è¯†åˆ«ä¿¡æ¯ï¼ˆPIIï¼‰ã€‚å°½ç®¡å·²æœ‰ç ”ç©¶è¡¨æ˜å¯ä»¥é€šè¿‡éšç§ç¥ç»å…ƒç­‰æ–¹æ³•ç¼“è§£è¿™ä¸€é£é™©ï¼Œä½†å®ƒä»¬å‡å‡è®¾è®­ç»ƒæ•°æ®å’Œç”¨æˆ·æŸ¥è¯¢å‡ä¸ºè‹±è¯­ã€‚æœ¬æ–‡æ­ç¤ºäº†åœ¨è·¨è¯­è¨€ç¯å¢ƒä¸‹ï¼Œéšç§æ³„éœ²çš„é£é™©ä¾ç„¶å­˜åœ¨ï¼Œç”šè‡³åœ¨è®­ç»ƒæ•°æ®ä»…ä¸ºä¸€ç§è¯­è¨€çš„æƒ…å†µä¸‹ï¼Œæ¨¡å‹åœ¨å¦ä¸€ç§è¯­è¨€æŸ¥è¯¢æ—¶ä»å¯èƒ½æ³„éœ²ç§äººä¿¡æ¯ã€‚æˆ‘ä»¬ç ”ç©¶äº†è·¨è¯­è¨€éšç§æ³„éœ²çš„ä¿¡æ¯æµï¼Œå‘ç°LLMsåœ¨ä¸­é—´å±‚å¤„ç†ç§äººä¿¡æ¯ï¼Œè€Œåœ¨åç»­å±‚è½¬æ¢ä¸ºç‰¹å®šè¯­è¨€ç©ºé—´æ—¶ï¼Œæ³„éœ²é£é™©è¾¾åˆ°å³°å€¼ã€‚åŸºäºæ­¤ï¼Œæˆ‘ä»¬è¯†åˆ«äº†éšç§é€šç”¨ç¥ç»å…ƒå’Œè¯­è¨€ç‰¹å®šéšç§ç¥ç»å…ƒï¼Œé€šè¿‡åœç”¨è¿™äº›ç¥ç»å…ƒï¼Œè·¨è¯­è¨€éšç§æ³„éœ²é£é™©é™ä½äº†23.3%-31.6%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è·¨è¯­è¨€ç¯å¢ƒä¸‹çš„éšç§æ³„éœ²é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨è‹±è¯­ç¯å¢ƒï¼Œæ— æ³•æœ‰æ•ˆåº”å¯¹å¤šè¯­è¨€æŸ¥è¯¢å¸¦æ¥çš„éšç§é£é™©ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯è¯†åˆ«å’Œåœç”¨éšç§é€šç”¨ç¥ç»å…ƒå’Œè¯­è¨€ç‰¹å®šéšç§ç¥ç»å…ƒï¼Œä»¥å‡å°‘è·¨è¯­è¨€éšç§æ³„éœ²çš„é£é™©ã€‚é€šè¿‡åˆ†æä¿¡æ¯æµï¼Œå‘ç°ä¸­é—´å±‚çš„è¡¨ç¤ºåœ¨ä¸åŒè¯­è¨€é—´å…±äº«ï¼Œåç»­å±‚çš„è¯­è¨€ç‰¹å®šç©ºé—´åˆ™åŠ å‰§äº†æ³„éœ²é£é™©ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¿¡æ¯æµåˆ†æã€éšç§ç¥ç»å…ƒè¯†åˆ«å’Œåœç”¨æœºåˆ¶ã€‚é¦–å…ˆï¼Œåˆ†ææ¨¡å‹çš„ä¸­é—´å±‚å’Œåç»­å±‚ä¿¡æ¯æµï¼Œè¯†åˆ«å‡ºå½±å“éšç§æ³„éœ²çš„ç¥ç»å…ƒï¼Œå¹¶è®¾è®¡åœç”¨ç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†éšç§é€šç”¨ç¥ç»å…ƒå’Œè¯­è¨€ç‰¹å®šéšç§ç¥ç»å…ƒçš„æ¦‚å¿µï¼Œæ­ç¤ºäº†è·¨è¯­è¨€éšç§æ³„éœ²çš„å†…åœ¨æœºåˆ¶ï¼Œä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºè€ƒè™‘äº†å¤šè¯­è¨€ç¯å¢ƒçš„å¤æ‚æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œè®¾ç½®äº†ä¸åŒçš„åœç”¨ç­–ç•¥ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥è¯„ä¼°éšç§æ³„éœ²é£é™©ï¼Œå¹¶é€šè¿‡å¯¹æ¯”å®éªŒéªŒè¯äº†åœç”¨ç¥ç»å…ƒçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œé€šè¿‡åœç”¨éšç§é€šç”¨ç¥ç»å…ƒå’Œè¯­è¨€ç‰¹å®šéšç§ç¥ç»å…ƒï¼Œè·¨è¯­è¨€éšç§æ³„éœ²é£é™©é™ä½äº†23.3%-31.6%ã€‚è¿™ä¸€æå‡æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œè¡¨æ˜æ–°æœºåˆ¶åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸‹çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤šè¯­è¨€èŠå¤©æœºå™¨äººã€è·¨å›½ä¼ä¸šçš„æ•°æ®ä¿æŠ¤ç­–ç•¥ä»¥åŠä»»ä½•æ¶‰åŠå¤šè¯­è¨€ç”¨æˆ·äº¤äº’çš„ç³»ç»Ÿã€‚é€šè¿‡æœ‰æ•ˆé™ä½éšç§æ³„éœ²é£é™©ï¼Œå¢å¼ºç”¨æˆ·ä¿¡ä»»ï¼Œæå‡æ•°æ®å®‰å…¨æ€§ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) trained on massive data capture rich information embedded in the training data. However, this also introduces the risk of privacy leakage, particularly involving personally identifiable information (PII). Although previous studies have shown that this risk can be mitigated through methods such as privacy neurons, they all assume that both the (sensitive) training data and user queries are in English. We show that they cannot defend against the privacy leakage in cross-lingual contexts: even if the training data is exclusively in one language, these (private) models may still reveal private information when queried in another language. In this work, we first investigate the information flow of cross-lingual privacy leakage to give a better understanding. We find that LLMs process private information in the middle layers, where representations are largely shared across languages. The risk of leakage peaks when converted to a language-specific space in later layers. Based on this, we identify privacy-universal neurons and language-specific privacy neurons. Privacy-universal neurons influence privacy leakage across all languages, while language-specific privacy neurons are only related to specific languages. By deactivating these neurons, the cross-lingual privacy leakage risk is reduced by 23.3%-31.6%.

