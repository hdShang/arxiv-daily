---
layout: default
title: Colombian Waitresses y Jueces canadienses: Gender and Country Biases in Occupation Recommendations from LLMs
---

# Colombian Waitresses y Jueces canadienses: Gender and Country Biases in Occupation Recommendations from LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.02456" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.02456v2</a>
  <a href="https://arxiv.org/pdf/2505.02456.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.02456v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.02456v2', 'Colombian Waitresses y Jueces canadienses: Gender and Country Biases in Occupation Recommendations from LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Elisa Forcada RodrÃ­guez, Olatz Perez-de-ViÃ±aspre, Jon Ander Campos, Dietrich Klakow, Vagrant Gautam

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-05 (æ›´æ–°: 2025-07-26)

**å¤‡æ³¨**: Workshop on Gender Bias in Natural Language Processing at ACL 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šè¯­è¨€äº¤å‰æ€§æ€§åˆ«ä¸å›½å®¶åè§ç ”ç©¶ä»¥æ”¹å–„èŒä¸šæ¨è**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ€§åˆ«åè§` `å›½å®¶åè§` `äº¤å‰æ€§åˆ†æ` `å¤šè¯­è¨€å¤„ç†` `å¤§è¯­è¨€æ¨¡å‹` `å…¬å¹³æ€§ç ”ç©¶` `èŒä¸šæ¨è`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å…¬å¹³æ€§ç ”ç©¶é€šå¸¸é›†ä¸­äºå•ä¸€çš„åè§è½´ï¼ˆå¦‚æ€§åˆ«ï¼‰ï¼Œä¸”å¤šä»¥è‹±è¯­ä¸ºä¸»ï¼Œç¼ºä¹å¯¹å¤šè¯­è¨€å’Œäº¤å‰æ€§åè§çš„ç³»ç»Ÿç ”ç©¶ã€‚
2. æœ¬ç ”ç©¶é€šè¿‡æ„å»ºå¤šè¯­è¨€åŸºå‡†æ•°æ®é›†ï¼Œç³»ç»Ÿæ€§åœ°è€ƒå¯Ÿæ€§åˆ«ä¸å›½å®¶äº¤å‰åè§ï¼Œè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹åœ¨èŒä¸šæ¨èä¸­çš„è¡¨ç°ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ¨¡å‹å­˜åœ¨æ˜¾è‘—çš„æ€§åˆ«å’Œå›½å®¶åè§ï¼Œä¸”ç»è¿‡æŒ‡ä»¤è°ƒä¼˜çš„æ¨¡å‹åœ¨åè§æ§åˆ¶ä¸Šè¡¨ç°æœ€ä½³ï¼Œå¼ºè°ƒäº†å¤šè¯­è¨€è§†è§’çš„é‡è¦æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶æ—¨åœ¨æµ‹é‡å’Œå‡è½»è‡ªç„¶è¯­è¨€å¤„ç†ç³»ç»Ÿä¸­ä¼ æ’­çš„åˆ»æ¿å°è±¡åè§ï¼Œç‰¹åˆ«å…³æ³¨å¤šè¯­è¨€äº¤å‰æ€§æ€§åˆ«å’Œå›½å®¶åè§ã€‚æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªåŒ…å«è‹±è¯­ã€è¥¿ç­ç‰™è¯­å’Œå¾·è¯­çš„åŸºå‡†æ•°æ®é›†ï¼Œç³»ç»Ÿæ€§åœ°å˜åŒ–å›½å®¶å’Œæ€§åˆ«ï¼Œæ¶µç›–25ä¸ªå›½å®¶å’Œå››ç»„ä»£è¯ã€‚é€šè¿‡å¯¹5ä¸ªåŸºäºLlamaçš„æ¨¡å‹è¿›è¡Œè¯„ä¼°ï¼Œå‘ç°è¿™äº›æ¨¡å‹æ˜¾è‘—ç¼–ç äº†æ€§åˆ«å’Œå›½å®¶åè§ã€‚å³ä½¿åœ¨æ€§åˆ«æˆ–å›½å®¶å•ç‹¬è¡¨ç°å‡ºå¹³ç­‰æ—¶ï¼ŒåŸºäºå›½å®¶å’Œæ€§åˆ«çš„äº¤å‰æ€§èŒä¸šåè§ä¾ç„¶å­˜åœ¨ã€‚æ­¤å¤–ï¼Œæç¤ºè¯­è¨€æ˜¾è‘—å½±å“åè§ï¼Œè€Œç»è¿‡æŒ‡ä»¤è°ƒä¼˜çš„æ¨¡å‹è¡¨ç°å‡ºæœ€ä½ä¸”æœ€ç¨³å®šçš„åè§æ°´å¹³ã€‚æˆ‘ä»¬çš„ç ”ç©¶å¼ºè°ƒäº†å…¬å¹³æ€§ç ”ç©¶è€…åœ¨å·¥ä½œä¸­ä½¿ç”¨äº¤å‰æ€§å’Œå¤šè¯­è¨€è§†è§’çš„å¿…è¦æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶è§£å†³äº†ç°æœ‰è‡ªç„¶è¯­è¨€å¤„ç†ç³»ç»Ÿä¸­å­˜åœ¨çš„æ€§åˆ«ä¸å›½å®¶åè§é—®é¢˜ï¼Œå°¤å…¶æ˜¯ç¼ºä¹å¯¹äº¤å‰æ€§åè§çš„å…³æ³¨ã€‚ç°æœ‰æ–¹æ³•å¤šé›†ä¸­äºå•ä¸€åè§ï¼Œæœªèƒ½å…¨é¢è¯„ä¼°å¤šè¯­è¨€ç¯å¢ƒä¸‹çš„åè§è¡¨ç°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡é€šè¿‡æ„å»ºä¸€ä¸ªå¤šè¯­è¨€çš„åŸºå‡†æ•°æ®é›†ï¼Œç³»ç»Ÿæ€§åœ°å˜åŒ–å›½å®¶å’Œæ€§åˆ«ï¼Œæ¥è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹åœ¨èŒä¸šæ¨èä¸­çš„åè§è¡¨ç°ï¼Œæ—¨åœ¨æ­ç¤ºäº¤å‰æ€§åè§çš„å­˜åœ¨åŠå…¶å½±å“ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é¦–å…ˆæ„å»ºäº†åŒ…å«25ä¸ªå›½å®¶å’Œå››ç»„ä»£è¯çš„æç¤ºåŸºå‡†ï¼Œéšåå¯¹5ä¸ªåŸºäºLlamaçš„æ¨¡å‹è¿›è¡Œè¯„ä¼°ï¼Œåˆ†æå…¶åœ¨ä¸åŒæç¤ºä¸‹çš„åè§è¡¨ç°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°åœ¨äºé¦–æ¬¡ç³»ç»Ÿæ€§åœ°æ¢è®¨äº†å¤šè¯­è¨€ç¯å¢ƒä¸‹çš„äº¤å‰æ€§æ€§åˆ«ä¸å›½å®¶åè§ï¼Œå¡«è¡¥äº†ç°æœ‰ç ”ç©¶çš„ç©ºç™½ï¼Œå¼ºè°ƒäº†åœ¨å…¬å¹³æ€§ç ”ç©¶ä¸­è€ƒè™‘äº¤å‰æ€§çš„é‡è¦æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œä½¿ç”¨äº†å¤šç§æç¤ºè¯­è¨€ï¼Œå¹¶å¯¹æ¨¡å‹è¿›è¡Œäº†æŒ‡ä»¤è°ƒä¼˜ï¼Œä»¥ç¡®ä¿åœ¨ä¸åŒæ¡ä»¶ä¸‹è¯„ä¼°åè§çš„ç¨³å®šæ€§å’Œè¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯„ä¼°çš„Llamaæ¨¡å‹åœ¨æ€§åˆ«å’Œå›½å®¶åè§æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—çš„åè§ï¼Œå°¤å…¶æ˜¯åœ¨äº¤å‰æ€§åˆ†æä¸­ï¼Œå³ä½¿åœ¨å•ä¸€åè§ä¸Šè¡¨ç°å‡ºå¹³ç­‰ï¼Œäº¤å‰åè§ä¾ç„¶å­˜åœ¨ã€‚ç»è¿‡æŒ‡ä»¤è°ƒä¼˜çš„æ¨¡å‹åœ¨åè§æ§åˆ¶ä¸Šè¡¨ç°å‡ºæœ€ä½ä¸”æœ€ç¨³å®šçš„æ°´å¹³ï¼Œè¡¨æ˜è°ƒä¼˜ç­–ç•¥çš„é‡è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ‹›è˜ç³»ç»Ÿã€èŒä¸šæ¨èå¹³å°å’Œç¤¾ä¼šç§‘å­¦ç ”ç©¶ç­‰ã€‚é€šè¿‡è¯†åˆ«å’Œå‡è½»æ¨¡å‹ä¸­çš„åè§ï¼Œå¯ä»¥æé«˜èŒä¸šæ¨èçš„å…¬å¹³æ€§å’Œå‡†ç¡®æ€§ï¼Œä¿ƒè¿›æ›´åŒ…å®¹çš„ç¤¾ä¼šç¯å¢ƒã€‚æœªæ¥ï¼Œç ”ç©¶ç»“æœå¯èƒ½æ¨åŠ¨æ›´å¹¿æ³›çš„å…¬å¹³æ€§æ ‡å‡†å’Œå®è·µï¼Œå½±å“ç›¸å…³æ”¿ç­–çš„åˆ¶å®šã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> One of the goals of fairness research in NLP is to measure and mitigate stereotypical biases that are propagated by NLP systems. However, such work tends to focus on single axes of bias (most often gender) and the English language. Addressing these limitations, we contribute the first study of multilingual intersecting country and gender biases, with a focus on occupation recommendations generated by large language models. We construct a benchmark of prompts in English, Spanish and German, where we systematically vary country and gender, using 25 countries and four pronoun sets. Then, we evaluate a suite of 5 Llama-based models on this benchmark, finding that LLMs encode significant gender and country biases. Notably, we find that even when models show parity for gender or country individually, intersectional occupational biases based on both country and gender persist. We also show that the prompting language significantly affects bias, and instruction-tuned models consistently demonstrate the lowest and most stable levels of bias. Our findings highlight the need for fairness researchers to use intersectional and multilingual lenses in their work.

