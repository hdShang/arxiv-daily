---
layout: default
title: UCSC at SemEval-2025 Task 3: Context, Models and Prompt Optimization for Automated Hallucination Detection in LLM Output
---

# UCSC at SemEval-2025 Task 3: Context, Models and Prompt Optimization for Automated Hallucination Detection in LLM Output

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.03030" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.03030v1</a>
  <a href="https://arxiv.org/pdf/2505.03030.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.03030v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.03030v1', 'UCSC at SemEval-2025 Task 3: Context, Models and Prompt Optimization for Automated Hallucination Detection in LLM Output')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sicong Huang, Jincheng He, Shiyuan Huang, Karthik Raja Anandan, Arkajyoti Chakraborty, Ian Lane

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-05

**å¤‡æ³¨**: 6 pages, 1 figure

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ¡†æ¶ä»¥ä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹çš„å¹»è§‰æ£€æµ‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¹»è§‰æ£€æµ‹` `å¤§å‹è¯­è¨€æ¨¡å‹` `ä¸Šä¸‹æ–‡æ£€ç´¢` `è™šå‡å†…å®¹è¯†åˆ«` `è‡ªåŠ¨ä¼˜åŒ–æç¤º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†çŸ¥è¯†å¯†é›†å‹æŸ¥è¯¢æ—¶ï¼Œå¹»è§‰ç°è±¡çš„æ£€æµ‹å’Œå®šä½ä»ç„¶æ˜¯ä¸€ä¸ªæœªè§£å†³çš„éš¾é¢˜ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°æ¡†æ¶ï¼Œé€šè¿‡æ£€ç´¢ä¸Šä¸‹æ–‡ã€è¯†åˆ«è™šå‡å†…å®¹å¹¶æ˜ å°„å›è¾“å‡ºï¼Œæ¥ä¼˜åŒ–å¹»è§‰æ£€æµ‹è¿‡ç¨‹ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿåœ¨æ‰€æœ‰è¯­è¨€ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå¹³å‡æ’åç¬¬ä¸€ï¼Œæ˜¾è‘—æå‡äº†å¹»è§‰æ£€æµ‹çš„å‡†ç¡®æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¹»è§‰ç°è±¡å¯¹å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å›ç­”çŸ¥è¯†å¯†é›†å‹æŸ¥è¯¢æ—¶æ„æˆäº†é‡å¤§æŒ‘æˆ˜ã€‚éšç€å¤§å‹è¯­è¨€æ¨¡å‹çš„å¹¿æ³›åº”ç”¨ï¼Œæ£€æµ‹å¹»è§‰çš„å‘ç”ŸåŠå…¶å…·ä½“ä½ç½®å˜å¾—è‡³å…³é‡è¦ã€‚SemEval 2025ä»»åŠ¡3ï¼ŒMu-SHROOMï¼Œæ—¨åœ¨è§£å†³è¿™ä¸€é—®é¢˜ã€‚æœ¬æ–‡æè¿°äº†UCSCå›¢é˜Ÿåœ¨è¯¥å…±äº«ä»»åŠ¡ä¸­çš„ç³»ç»Ÿæäº¤ï¼Œæå‡ºäº†ä¸€ç§æ¡†æ¶ï¼Œé¦–å…ˆæ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡ï¼Œç„¶åè¯†åˆ«ç­”æ¡ˆä¸­çš„è™šå‡å†…å®¹ï¼Œæœ€åå°†å…¶æ˜ å°„å›å¤§å‹è¯­è¨€æ¨¡å‹è¾“å‡ºçš„å…·ä½“åŒºé—´ã€‚è¯¥è¿‡ç¨‹é€šè¿‡è‡ªåŠ¨ä¼˜åŒ–æç¤ºè¿›ä¸€æ­¥å¢å¼ºã€‚æˆ‘ä»¬çš„ç³»ç»Ÿåœ¨æ‰€æœ‰è¯­è¨€ä¸­è¡¨ç°æœ€ä½³ï¼Œå¹³å‡æ’åç¬¬ä¸€ï¼Œå¹¶å‘å¸ƒäº†ä»£ç å’Œå®éªŒç»“æœã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å›ç­”çŸ¥è¯†å¯†é›†å‹æŸ¥è¯¢æ—¶å‡ºç°çš„å¹»è§‰ç°è±¡ï¼Œç°æœ‰æ–¹æ³•åœ¨æ£€æµ‹å¹»è§‰åŠå…¶å…·ä½“ä½ç½®æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºçš„æ¡†æ¶é€šè¿‡æ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡ã€è¯†åˆ«è™šå‡å†…å®¹å¹¶å°†å…¶æ˜ å°„å›æ¨¡å‹è¾“å‡ºï¼Œä¼˜åŒ–äº†å¹»è§‰æ£€æµ‹çš„è¿‡ç¨‹ï¼Œæå‡äº†æ£€æµ‹çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯ä¸Šä¸‹æ–‡æ£€ç´¢æ¨¡å—ï¼Œå…¶æ¬¡æ˜¯è™šå‡å†…å®¹è¯†åˆ«æ¨¡å—ï¼Œæœ€åæ˜¯æ˜ å°„æ¨¡å—ï¼Œæ•´ä¸ªè¿‡ç¨‹è¿˜ç»“åˆäº†è‡ªåŠ¨ä¼˜åŒ–æç¤ºçš„æŠ€æœ¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†ä¸Šä¸‹æ–‡æ£€ç´¢ä¸è™šå‡å†…å®¹è¯†åˆ«ç›¸ç»“åˆï¼Œå¹¶é€šè¿‡è‡ªåŠ¨ä¼˜åŒ–æç¤ºæå‡æ£€æµ‹æ•ˆæœï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„ç‹¬ç«‹å¤„ç†æ–¹å¼å½¢æˆäº†é²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–æ¨¡å‹æ€§èƒ½ï¼Œå¹¶è®¾è®¡äº†é€‚åº”ä¸åŒè¯­è¨€çš„ç½‘ç»œç»“æ„ï¼Œç¡®ä¿äº†ç³»ç»Ÿçš„é€šç”¨æ€§å’Œé«˜æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒUCSCç³»ç»Ÿåœ¨æ‰€æœ‰è¯­è¨€çš„å¹³å‡æ’åä¸­ä½åˆ—ç¬¬ä¸€ï¼Œæ˜¾è‘—æé«˜äº†å¹»è§‰æ£€æµ‹çš„å‡†ç¡®æ€§ï¼Œå…·ä½“æ€§èƒ½æ•°æ®æœªå…¬å¼€ï¼Œä½†æ•´ä½“è¡¨ç°ä¼˜äºç°æœ‰åŸºçº¿æ–¹æ³•ï¼Œå±•ç¤ºäº†è¯¥æ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å®¢æœã€è‡ªåŠ¨é—®ç­”ç³»ç»Ÿå’Œä¿¡æ¯æ£€ç´¢ç­‰ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡ç³»ç»Ÿå¯¹è™šå‡ä¿¡æ¯çš„æ£€æµ‹èƒ½åŠ›ï¼Œå¢å¼ºç”¨æˆ·ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶è¿˜å¯æ‰©å±•è‡³å…¶ä»–è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Hallucinations pose a significant challenge for large language models when answering knowledge-intensive queries. As LLMs become more widely adopted, it is crucial not only to detect if hallucinations occur but also to pinpoint exactly where in the LLM output they occur. SemEval 2025 Task 3, Mu-SHROOM: Multilingual Shared-task on Hallucinations and Related Observable Overgeneration Mistakes, is a recent effort in this direction. This paper describes the UCSC system submission to the shared Mu-SHROOM task. We introduce a framework that first retrieves relevant context, next identifies false content from the answer, and finally maps them back to spans in the LLM output. The process is further enhanced by automatically optimizing prompts. Our system achieves the highest overall performance, ranking #1 in average position across all languages. We release our code and experiment results.

