---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CL - 2025-05-19
---

# cs.CLï¼ˆ2025-05-19ï¼‰

ğŸ“Š å…± **38** ç¯‡è®ºæ–‡
 | ğŸ”— **7** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (31 ğŸ”—5)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (7 ğŸ”—2)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (31 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250513307v1-rbf-quantifying-and-optimizing-reasoning-boundaries-across-measurabl.html">RBF++: Quantifying and Optimizing Reasoning Boundaries across Measurable and Unmeasurable Capabilities for Chain-of-Thought Reasoning</a></td>
  <td>æå‡ºRBF++ä»¥é‡åŒ–å’Œä¼˜åŒ–é“¾å¼æ€ç»´æ¨ç†çš„è¾¹ç•Œé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span> <span class="paper-tag">chain-of-thought</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13307v1" data-paper-url="./papers/250513307v1-rbf-quantifying-and-optimizing-reasoning-boundaries-across-measurabl.html" onclick="toggleFavorite(this, '2505.13307v1', 'RBF++: Quantifying and Optimizing Reasoning Boundaries across Measurable and Unmeasurable Capabilities for Chain-of-Thought Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250513036v1-kits-offline-speech-translation-and-instruction-following-submission.html">KIT's Offline Speech Translation and Instruction Following Submission for IWSLT 2025</a></td>
  <td>æå‡ºåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ç¦»çº¿è¯­éŸ³ç¿»è¯‘ä¸æŒ‡ä»¤è·Ÿéšæ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">instruction following</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13036v1" data-paper-url="./papers/250513036v1-kits-offline-speech-translation-and-instruction-following-submission.html" onclick="toggleFavorite(this, '2505.13036v1', 'KIT&#39;s Offline Speech Translation and Instruction Following Submission for IWSLT 2025')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250512835v1-flightgpt-towards-generalizable-and-interpretable-uav-vision-and-lan.html">FlightGPT: Towards Generalizable and Interpretable UAV Vision-and-Language Navigation with Vision-Language Models</a></td>
  <td>æå‡ºFlightGPTä»¥è§£å†³æ— äººæœºè§†è§‰è¯­è¨€å¯¼èˆªä¸­çš„å¤šæ¨¡æ€èåˆä¸å¯è§£é‡Šæ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">VLN</span> <span class="paper-tag">multimodal</span> <span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.12835v1" data-paper-url="./papers/250512835v1-flightgpt-towards-generalizable-and-interpretable-uav-vision-and-lan.html" onclick="toggleFavorite(this, '2505.12835v1', 'FlightGPT: Towards Generalizable and Interpretable UAV Vision-and-Language Navigation with Vision-Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250513706v1-are-large-language-models-good-at-detecting-propaganda.html">Are Large Language Models Good at Detecting Propaganda?</a></td>
  <td>è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å®£ä¼ æ£€æµ‹ä¸­çš„æœ‰æ•ˆæ€§</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13706v1" data-paper-url="./papers/250513706v1-are-large-language-models-good-at-detecting-propaganda.html" onclick="toggleFavorite(this, '2505.13706v1', 'Are Large Language Models Good at Detecting Propaganda?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250513772v2-krikri-advancing-open-large-language-models-for-greek.html">Krikri: Advancing Open Large Language Models for Greek</a></td>
  <td>æå‡ºLlama-Krikri-8Bä»¥æå‡å¸Œè…Šè¯­å¤§è¯­è¨€æ¨¡å‹æ€§èƒ½</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13772v2" data-paper-url="./papers/250513772v2-krikri-advancing-open-large-language-models-for-greek.html" onclick="toggleFavorite(this, '2505.13772v2', 'Krikri: Advancing Open Large Language Models for Greek')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250513761v2-simulation-agent-a-framework-for-integrating-simulation-and-large-la.html">Simulation Agent: A Framework for Integrating Simulation and Large Language Models for Enhanced Decision-Making</a></td>
  <td>æå‡ºæ¨¡æ‹Ÿä»£ç†æ¡†æ¶ä»¥è§£å†³å¤æ‚å†³ç­–é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13761v2" data-paper-url="./papers/250513761v2-simulation-agent-a-framework-for-integrating-simulation-and-large-la.html" onclick="toggleFavorite(this, '2505.13761v2', 'Simulation Agent: A Framework for Integrating Simulation and Large Language Models for Enhanced Decision-Making')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250513259v3-from-automation-to-autonomy-a-survey-on-large-language-models-in-sci.html">From Automation to Autonomy: A Survey on Large Language Models in Scientific Discovery</a></td>
  <td>æå‡ºä¸‰å±‚æ¬¡åˆ†ç±»æ³•ä»¥æå‡å¤§è¯­è¨€æ¨¡å‹åœ¨ç§‘å­¦å‘ç°ä¸­çš„è‡ªä¸»æ€§</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13259v3" data-paper-url="./papers/250513259v3-from-automation-to-autonomy-a-survey-on-large-language-models-in-sci.html" onclick="toggleFavorite(this, '2505.13259v3', 'From Automation to Autonomy: A Survey on Large Language Models in Scientific Discovery')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250513220v1-seedbench-a-multi-task-benchmark-for-evaluating-large-language-model.html">SeedBench: A Multi-task Benchmark for Evaluating Large Language Models in Seed Science</a></td>
  <td>æå‡ºSeedBenchä»¥è§£å†³ç§å­ç§‘å­¦é¢†åŸŸçš„è¯„ä¼°é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13220v1" data-paper-url="./papers/250513220v1-seedbench-a-multi-task-benchmark-for-evaluating-large-language-model.html" onclick="toggleFavorite(this, '2505.13220v1', 'SeedBench: A Multi-task Benchmark for Evaluating Large Language Models in Seed Science')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250513176v2-toolspectrum-towards-personalized-tool-utilization-for-large-languag.html">ToolSpectrum : Towards Personalized Tool Utilization for Large Language Models</a></td>
  <td>æå‡ºToolSpectrumä»¥è§£å†³å·¥å…·é€‰æ‹©ä¸ªæ€§åŒ–é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13176v2" data-paper-url="./papers/250513176v2-toolspectrum-towards-personalized-tool-utilization-for-large-languag.html" onclick="toggleFavorite(this, '2505.13176v2', 'ToolSpectrum : Towards Personalized Tool Utilization for Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250513157v1-role-playing-evaluation-for-large-language-models.html">Role-Playing Evaluation for Large Language Models</a></td>
  <td>æå‡ºè§’è‰²æ‰®æ¼”è¯„ä¼°åŸºå‡†ä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹è¯„ä¼°éš¾é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13157v1" data-paper-url="./papers/250513157v1-role-playing-evaluation-for-large-language-models.html" onclick="toggleFavorite(this, '2505.13157v1', 'Role-Playing Evaluation for Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250513090v2-the-effect-of-language-diversity-when-fine-tuning-large-language-mod.html">The Effect of Language Diversity When Fine-Tuning Large Language Models for Translation</a></td>
  <td>ç ”ç©¶è¯­è¨€å¤šæ ·æ€§å¯¹å¤§è¯­è¨€æ¨¡å‹ç¿»è¯‘å¾®è°ƒçš„å½±å“</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13090v2" data-paper-url="./papers/250513090v2-the-effect-of-language-diversity-when-fine-tuning-large-language-mod.html" onclick="toggleFavorite(this, '2505.13090v2', 'The Effect of Language Diversity When Fine-Tuning Large Language Models for Translation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250513069v1-suicide-risk-assessment-using-multimodal-speech-features-a-study-on-.html">Suicide Risk Assessment Using Multimodal Speech Features: A Study on the SW1 Challenge Dataset</a></td>
  <td>æå‡ºå¤šæ¨¡æ€è¯­éŸ³ç‰¹å¾è¯„ä¼°é’å°‘å¹´è‡ªæ€é£é™©çš„æ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13069v1" data-paper-url="./papers/250513069v1-suicide-risk-assessment-using-multimodal-speech-features-a-study-on-.html" onclick="toggleFavorite(this, '2505.13069v1', 'Suicide Risk Assessment Using Multimodal Speech Features: A Study on the SW1 Challenge Dataset')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/250512983v1-an-empirical-study-of-many-to-many-summarization-with-large-language.html">An Empirical Study of Many-to-Many Summarization with Large Language Models</a></td>
  <td>æå‡ºå¤šå¯¹å¤šæ‘˜è¦ç”Ÿæˆæ–¹æ³•ä»¥æå‡å¤šè¯­è¨€å¤„ç†èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.12983v1" data-paper-url="./papers/250512983v1-an-empirical-study-of-many-to-many-summarization-with-large-language.html" onclick="toggleFavorite(this, '2505.12983v1', 'An Empirical Study of Many-to-Many Summarization with Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/250513302v1-ill-believe-it-when-i-see-it-images-increase-misinformation-sharing-.html">I'll believe it when I see it: Images increase misinformation sharing in Vision-Language Models</a></td>
  <td>æå‡ºè§†è§‰å†…å®¹å½±å“VLMä¿¡æ¯åˆ†äº«å€¾å‘çš„ç ”ç©¶</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13302v1" data-paper-url="./papers/250513302v1-ill-believe-it-when-i-see-it-images-increase-misinformation-sharing-.html" onclick="toggleFavorite(this, '2505.13302v1', 'I&#39;ll believe it when I see it: Images increase misinformation sharing in Vision-Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/250513237v3-sakura-on-the-multi-hop-reasoning-of-large-audio-language-models-bas.html">SAKURA: On the Multi-hop Reasoning of Large Audio-Language Models Based on Speech and Audio Information</a></td>
  <td>æå‡ºSAKURAåŸºå‡†ä»¥è¯„ä¼°å¤§éŸ³é¢‘è¯­è¨€æ¨¡å‹çš„å¤šè·³æ¨ç†èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13237v3" data-paper-url="./papers/250513237v3-sakura-on-the-multi-hop-reasoning-of-large-audio-language-models-bas.html" onclick="toggleFavorite(this, '2505.13237v3', 'SAKURA: On the Multi-hop Reasoning of Large Audio-Language Models Based on Speech and Audio Information')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/250513115v1-benchmarking-and-confidence-evaluation-of-lalms-for-temporal-reasoni.html">Benchmarking and Confidence Evaluation of LALMs For Temporal Reasoning</a></td>
  <td>æå‡ºTREAæ•°æ®é›†ä»¥è¯„ä¼°éŸ³é¢‘è¯­è¨€æ¨¡å‹çš„æ—¶é—´æ¨ç†èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13115v1" data-paper-url="./papers/250513115v1-benchmarking-and-confidence-evaluation-of-lalms-for-temporal-reasoni.html" onclick="toggleFavorite(this, '2505.13115v1', 'Benchmarking and Confidence Evaluation of LALMs For Temporal Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/250513032v1-mmar-a-challenging-benchmark-for-deep-reasoning-in-speech-audio-musi.html">MMAR: A Challenging Benchmark for Deep Reasoning in Speech, Audio, Music, and Their Mix</a></td>
  <td>æå‡ºMMARåŸºå‡†ä»¥è¯„ä¼°éŸ³é¢‘è¯­è¨€æ¨¡å‹çš„æ·±åº¦æ¨ç†èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13032v1" data-paper-url="./papers/250513032v1-mmar-a-challenging-benchmark-for-deep-reasoning-in-speech-audio-musi.html" onclick="toggleFavorite(this, '2505.13032v1', 'MMAR: A Challenging Benchmark for Deep Reasoning in Speech, Audio, Music, and Their Mix')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/250513725v1-sqlforge-synthesizing-reliable-and-diverse-data-to-enhance-text-to-s.html">SQLForge: Synthesizing Reliable and Diverse Data to Enhance Text-to-SQL Reasoning in LLMs</a></td>
  <td>æå‡ºSQLForgeä»¥å¢å¼ºLLMçš„æ–‡æœ¬åˆ°SQLæ¨ç†èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13725v1" data-paper-url="./papers/250513725v1-sqlforge-synthesizing-reliable-and-diverse-data-to-enhance-text-to-s.html" onclick="toggleFavorite(this, '2505.13725v1', 'SQLForge: Synthesizing Reliable and Diverse Data to Enhance Text-to-SQL Reasoning in LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/250513664v1-assessing-gpt-performance-in-a-proof-based-university-level-course-u.html">Assessing GPT Performance in a Proof-Based University-Level Course Under Blind Grading</a></td>
  <td>è¯„ä¼°GPTåœ¨ç›²è¯„å¤§å­¦ç®—æ³•è¯¾ç¨‹ä¸­çš„è¡¨ç°</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13664v1" data-paper-url="./papers/250513664v1-assessing-gpt-performance-in-a-proof-based-university-level-course-u.html" onclick="toggleFavorite(this, '2505.13664v1', 'Assessing GPT Performance in a Proof-Based University-Level Course Under Blind Grading')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/250513652v1-guided-search-strategies-in-non-serializable-environments-with-appli.html">Guided Search Strategies in Non-Serializable Environments with Applications to Software Engineering Agents</a></td>
  <td>æå‡ºå¼•å¯¼æœç´¢ç­–ç•¥ä»¥è§£å†³éå¯åºåˆ—åŒ–ç¯å¢ƒä¸­çš„è½¯ä»¶å·¥ç¨‹é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13652v1" data-paper-url="./papers/250513652v1-guided-search-strategies-in-non-serializable-environments-with-appli.html" onclick="toggleFavorite(this, '2505.13652v1', 'Guided Search Strategies in Non-Serializable Environments with Applications to Software Engineering Agents')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>21</td>
  <td><a href="./papers/250513360v2-what-prompts-dont-say-understanding-and-managing-underspecification-.html">What Prompts Don't Say: Understanding and Managing Underspecification in LLM Prompts</a></td>
  <td>æå‡ºéœ€æ±‚æ„ŸçŸ¥çš„æç¤ºä¼˜åŒ–æœºåˆ¶ä»¥è§£å†³LLMæç¤ºä¸è¶³é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">instruction following</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13360v2" data-paper-url="./papers/250513360v2-what-prompts-dont-say-understanding-and-managing-underspecification-.html" onclick="toggleFavorite(this, '2505.13360v2', 'What Prompts Don&#39;t Say: Understanding and Managing Underspecification in LLM Prompts')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>22</td>
  <td><a href="./papers/250513353v2-sense-and-sensitivity-examining-the-influence-of-semantic-recall-on-.html">Sense and Sensitivity: Examining the Influence of Semantic Recall on Long Context Code Reasoning</a></td>
  <td>æå‡ºSemTraceä»¥è§£å†³é•¿ä¸Šä¸‹æ–‡ä»£ç æ¨ç†ä¸­çš„è¯­ä¹‰å›å¿†é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13353v2" data-paper-url="./papers/250513353v2-sense-and-sensitivity-examining-the-influence-of-semantic-recall-on-.html" onclick="toggleFavorite(this, '2505.13353v2', 'Sense and Sensitivity: Examining the Influence of Semantic Recall on Long Context Code Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>23</td>
  <td><a href="./papers/250513312v1-guard-generation-time-llm-unlearning-via-adaptive-restriction-and-de.html">GUARD: Generation-time LLM Unlearning via Adaptive Restriction and Detection</a></td>
  <td>æå‡ºGUARDæ¡†æ¶ä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹çš„é€‰æ‹©æ€§é—å¿˜é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13312v1" data-paper-url="./papers/250513312v1-guard-generation-time-llm-unlearning-via-adaptive-restriction-and-de.html" onclick="toggleFavorite(this, '2505.13312v1', 'GUARD: Generation-time LLM Unlearning via Adaptive Restriction and Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>24</td>
  <td><a href="./papers/250513282v4-rank-chunk-and-expand-lineage-oriented-reasoning-for-taxonomy-expans.html">Rank, Chunk and Expand: Lineage-Oriented Reasoning for Taxonomy Expansion</a></td>
  <td>æå‡ºLORexæ¡†æ¶ä»¥è§£å†³ç¨onomiesæ‰©å±•ä¸­çš„å™ªå£°ä¸ä¸Šä¸‹æ–‡é™åˆ¶é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">PaLM-E</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13282v4" data-paper-url="./papers/250513282v4-rank-chunk-and-expand-lineage-oriented-reasoning-for-taxonomy-expans.html" onclick="toggleFavorite(this, '2505.13282v4', 'Rank, Chunk and Expand: Lineage-Oriented Reasoning for Taxonomy Expansion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>25</td>
  <td><a href="./papers/250517071v1-whats-in-a-prompt-language-models-encode-literary-style-in-prompt-em.html">What's in a prompt? Language models encode literary style in prompt embeddings</a></td>
  <td>æå‡ºé€šè¿‡æç¤ºåµŒå…¥åˆ†ææ–‡å­¦é£æ ¼çš„è¯­è¨€æ¨¡å‹æ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.17071v1" data-paper-url="./papers/250517071v1-whats-in-a-prompt-language-models-encode-literary-style-in-prompt-em.html" onclick="toggleFavorite(this, '2505.17071v1', 'What&#39;s in a prompt? Language models encode literary style in prompt embeddings')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>26</td>
  <td><a href="./papers/250513581v1-rar-setting-knowledge-tripwires-for-retrieval-augmented-rejection.html">RAR: Setting Knowledge Tripwires for Retrieval Augmented Rejection</a></td>
  <td>æå‡ºRARæ–¹æ³•ä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹å†…å®¹å®¡æ ¸é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13581v1" data-paper-url="./papers/250513581v1-rar-setting-knowledge-tripwires-for-retrieval-augmented-rejection.html" onclick="toggleFavorite(this, '2505.13581v1', 'RAR: Setting Knowledge Tripwires for Retrieval Augmented Rejection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>27</td>
  <td><a href="./papers/250513254v2-heterospec-leveraging-contextual-heterogeneity-for-efficient-specula.html">HeteroSpec: Leveraging Contextual Heterogeneity for Efficient Speculative Decoding</a></td>
  <td>æå‡ºHeteroSpecä»¥è§£å†³è‡ªå›å½’è§£ç æ•ˆç‡ä½ä¸‹é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13254v2" data-paper-url="./papers/250513254v2-heterospec-leveraging-contextual-heterogeneity-for-efficient-specula.html" onclick="toggleFavorite(this, '2505.13254v2', 'HeteroSpec: Leveraging Contextual Heterogeneity for Efficient Speculative Decoding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>28</td>
  <td><a href="./papers/250513252v2-are-llms-better-formalizers-than-solvers-on-complex-problems.html">Are LLMs Better Formalizers than Solvers on Complex Problems?</a></td>
  <td>è¯„ä¼°LLMåœ¨å¤æ‚é—®é¢˜ä¸­çš„å½¢å¼åŒ–èƒ½åŠ›ä¸æ±‚è§£èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13252v2" data-paper-url="./papers/250513252v2-are-llms-better-formalizers-than-solvers-on-complex-problems.html" onclick="toggleFavorite(this, '2505.13252v2', 'Are LLMs Better Formalizers than Solvers on Complex Problems?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>29</td>
  <td><a href="./papers/250513171v2-positional-fragility-in-llms-how-offset-effects-reshape-our-understa.html">Positional Fragility in LLMs: How Offset Effects Reshape Our Understanding of Memorization Risks</a></td>
  <td>æå‡ºä½ç½®è„†å¼±æ€§ç†è®ºä»¥è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹çš„è®°å¿†é£é™©</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13171v2" data-paper-url="./papers/250513171v2-positional-fragility-in-llms-how-offset-effects-reshape-our-understa.html" onclick="toggleFavorite(this, '2505.13171v2', 'Positional Fragility in LLMs: How Offset Effects Reshape Our Understanding of Memorization Risks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>30</td>
  <td><a href="./papers/250513147v2-what-if-deception-cannot-be-detected-a-cross-linguistic-study-on-the.html">What if Deception Cannot be Detected? A Cross-Linguistic Study on the Limits of Deception Detection from Text</a></td>
  <td>æå‡ºåŸºäºä¿¡å¿µçš„æ¬ºéª—æ¡†æ¶ä»¥é‡æ–°å®¡è§†æ–‡æœ¬æ¬ºéª—æ£€æµ‹</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13147v2" data-paper-url="./papers/250513147v2-what-if-deception-cannot-be-detected-a-cross-linguistic-study-on-the.html" onclick="toggleFavorite(this, '2505.13147v2', 'What if Deception Cannot be Detected? A Cross-Linguistic Study on the Limits of Deception Detection from Text')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>31</td>
  <td><a href="./papers/250513141v3-language-specific-latent-process-hinders-cross-lingual-performance.html">Language-Specific Latent Process Hinders Cross-Lingual Performance</a></td>
  <td>æå‡ºè¯­è¨€ç‰¹å®šæ½œåœ¨è¿‡ç¨‹ä»¥è§£å†³è·¨è¯­è¨€æ€§èƒ½é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13141v3" data-paper-url="./papers/250513141v3-language-specific-latent-process-hinders-cross-lingual-performance.html" onclick="toggleFavorite(this, '2505.13141v3', 'Language-Specific Latent Process Hinders Cross-Lingual Performance')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (7 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>32</td>
  <td><a href="./papers/250513403v1-mr-judge-multimodal-reasoner-as-a-judge.html">MR. Judge: Multimodal Reasoner as a Judge</a></td>
  <td>æå‡ºMR. Judgeä»¥æå‡å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹çš„è¯„åˆ¤èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">RLHF</span> <span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13403v1" data-paper-url="./papers/250513403v1-mr-judge-multimodal-reasoner-as-a-judge.html" onclick="toggleFavorite(this, '2505.13403v1', 'MR. Judge: Multimodal Reasoner as a Judge')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>33</td>
  <td><a href="./papers/250513434v1-smotext-smote-meets-large-language-models.html">SMOTExT: SMOTE meets Large Language Models</a></td>
  <td>æå‡ºSMOTExTä»¥è§£å†³æ–‡æœ¬æ•°æ®ç¨€ç¼ºä¸ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">distillation</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13434v1" data-paper-url="./papers/250513434v1-smotext-smote-meets-large-language-models.html" onclick="toggleFavorite(this, '2505.13434v1', 'SMOTExT: SMOTE meets Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>34</td>
  <td><a href="./papers/250513210v1-picturized-and-recited-with-dialects-a-multimodal-chinese-representa.html">Picturized and Recited with Dialects: A Multimodal Chinese Representation Framework for Sentiment Analysis of Classical Chinese Poetry</a></td>
  <td>æå‡ºå¤šæ¨¡æ€æ¡†æ¶ä»¥æå‡å¤å…¸è¯—è¯æƒ…æ„Ÿåˆ†ææ•ˆæœ</td>
  <td class="tags-cell"><span class="paper-tag">representation learning</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13210v1" data-paper-url="./papers/250513210v1-picturized-and-recited-with-dialects-a-multimodal-chinese-representa.html" onclick="toggleFavorite(this, '2505.13210v1', 'Picturized and Recited with Dialects: A Multimodal Chinese Representation Framework for Sentiment Analysis of Classical Chinese Poetry')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>35</td>
  <td><a href="./papers/250513271v2-csc-sql-corrective-self-consistency-in-text-to-sql-via-reinforcement.html">CSC-SQL: Corrective Self-Consistency in Text-to-SQL via Reinforcement Learning</a></td>
  <td>æå‡ºCSC-SQLä»¥è§£å†³æ–‡æœ¬åˆ°SQLè½¬æ¢ä¸­çš„ä¸€è‡´æ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13271v2" data-paper-url="./papers/250513271v2-csc-sql-corrective-self-consistency-in-text-to-sql-via-reinforcement.html" onclick="toggleFavorite(this, '2505.13271v2', 'CSC-SQL: Corrective Self-Consistency in Text-to-SQL via Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>36</td>
  <td><a href="./papers/250513379v2-thinkless-llm-learns-when-to-think.html">Thinkless: LLM Learns When to Think</a></td>
  <td>æå‡ºThinklessæ¡†æ¶ä»¥æé«˜æ¨ç†è¯­è¨€æ¨¡å‹çš„è®¡ç®—æ•ˆç‡</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">chain-of-thought</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13379v2" data-paper-url="./papers/250513379v2-thinkless-llm-learns-when-to-think.html" onclick="toggleFavorite(this, '2505.13379v2', 'Thinkless: LLM Learns When to Think')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>37</td>
  <td><a href="./papers/250513346v3-j4r-learning-to-judge-with-equivalent-initial-state-group-relative-p.html">J4R: Learning to Judge with Equivalent Initial State Group Relative Policy Optimization</a></td>
  <td>æå‡ºEIS-GRPOç®—æ³•ä»¥æå‡æ¨¡å‹è¾“å‡ºè¯„ä¼°çš„å‡†ç¡®æ€§</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13346v3" data-paper-url="./papers/250513346v3-j4r-learning-to-judge-with-equivalent-initial-state-group-relative-p.html" onclick="toggleFavorite(this, '2505.13346v3', 'J4R: Learning to Judge with Equivalent Initial State Group Relative Policy Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>38</td>
  <td><a href="./papers/250513258v2-transparent-and-robust-rag-adaptive-reward-reinforcement-learning-fo.html">Transparent and Robust RAG: Adaptive-Reward Reinforcement Learning for Decision Traceability</a></td>
  <td>æå‡ºARENAä»¥è§£å†³RAGç”Ÿæˆä¸­çš„é€æ˜æ€§ä¸ç¨³å®šæ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13258v2" data-paper-url="./papers/250513258v2-transparent-and-robust-rag-adaptive-reward-reinforcement-learning-fo.html" onclick="toggleFavorite(this, '2505.13258v2', 'Transparent and Robust RAG: Adaptive-Reward Reinforcement Learning for Decision Traceability')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CL é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)