---
layout: default
title: An Empirical Study of Many-to-Many Summarization with Large Language Models
---

# An Empirical Study of Many-to-Many Summarization with Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.12983" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.12983v1</a>
  <a href="https://arxiv.org/pdf/2505.12983.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.12983v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.12983v1', 'An Empirical Study of Many-to-Many Summarization with Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiaan Wang, Fandong Meng, Zengkui Sun, Yunlong Liang, Yuxuan Cao, Jiarong Xu, Haoxiang Shi, Jie Zhou

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-19

**å¤‡æ³¨**: Accepted to ACL 2025 main conference

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šå¯¹å¤šæ‘˜è¦ç”Ÿæˆæ–¹æ³•ä»¥æå‡å¤šè¯­è¨€å¤„ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šå¯¹å¤šæ‘˜è¦ç”Ÿæˆ` `å¤§å‹è¯­è¨€æ¨¡å‹` `æŒ‡ä»¤å¾®è°ƒ` `å¤šè¯­è¨€å¤„ç†` `äº‹å®æ€§é—®é¢˜`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤šè¯­è¨€æ‘˜è¦ç”Ÿæˆä¸­é¢ä¸´äº‹å®æ€§é—®é¢˜ï¼Œä¸”é›¶-shotæ¨¡å‹çš„æ€§èƒ½ä¸è¶³ä»¥æ»¡è¶³å®é™…åº”ç”¨éœ€æ±‚ã€‚
2. æœ¬ç ”ç©¶é€šè¿‡é‡æ–°ç»„ç»‡æ•°æ®é›†å¹¶è¯„ä¼°18ç§LLMsï¼Œæ¢ç´¢å…¶åœ¨å¤šå¯¹å¤šæ‘˜è¦ç”Ÿæˆä¸­çš„èƒ½åŠ›ï¼Œæå‡ºäº†æŒ‡ä»¤å¾®è°ƒçš„æ–¹æ³•ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œç»è¿‡æŒ‡ä»¤å¾®è°ƒçš„å¼€æºLLMsåœ¨è‡ªåŠ¨è¯„ä¼°ä¸­æ˜¾è‘—ä¼˜äºé›¶-shot LLMsï¼Œä¸”ä¸ä¼ ç»Ÿæ¨¡å‹çš„æ€§èƒ½ç›¸å½“ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šå¯¹å¤šæ‘˜è¦ç”Ÿæˆï¼ˆM2MSï¼‰æ—¨åœ¨å¤„ç†ä»»ä½•è¯­è¨€çš„æ–‡æ¡£å¹¶ç”Ÿæˆç›¸åº”è¯­è¨€çš„æ‘˜è¦ã€‚è¿‘å¹´æ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å±•ç°å‡ºå¼ºå¤§çš„å¤šè¯­è¨€èƒ½åŠ›ï¼Œå…·å¤‡åœ¨å®é™…åº”ç”¨ä¸­æ‰§è¡ŒM2MSçš„æ½œåŠ›ã€‚æœ¬ç ”ç©¶ç³»ç»Ÿæ€§åœ°æ¢è®¨äº†LLMsåœ¨M2MSä»»åŠ¡ä¸­çš„èƒ½åŠ›ã€‚æˆ‘ä»¬é‡æ–°ç»„ç»‡äº†åŸºäºå…«ä¸ªé¢†åŸŸç‰¹å®šæ•°æ®é›†çš„M2MSæ•°æ®ï¼ŒåŒ…å«47.8Kæ ·æœ¬ï¼Œæ¶µç›–äº”ä¸ªé¢†åŸŸå’Œå…­ç§è¯­è¨€ï¼Œç”¨äºè®­ç»ƒå’Œè¯„ä¼°LLMsã€‚å®éªŒè¡¨æ˜ï¼Œé›¶-shot LLMsåœ¨ç»“æœä¸Šä¸å¾®è°ƒçš„ä¼ ç»Ÿæ¨¡å‹ç›¸å½“ï¼Œè€Œç»è¿‡æŒ‡ä»¤å¾®è°ƒåï¼Œå¼€æºLLMsçš„M2MSèƒ½åŠ›æ˜¾è‘—æå‡ï¼Œè¶…è¶Šäº†é›¶-shot LLMsï¼ˆåŒ…æ‹¬GPT-4ï¼‰ã€‚ç„¶è€Œï¼Œäººç±»è¯„ä¼°æ˜¾ç¤ºLLMsä»é¢ä¸´äº‹å®æ€§é—®é¢˜ï¼ŒæŒ‡ä»¤å¾®è°ƒå¯èƒ½åŠ å‰§è¯¥é—®é¢˜ï¼Œå› æ­¤æ§åˆ¶äº‹å®é”™è¯¯æˆä¸ºæ„å»ºLLMæ‘˜è¦ç”Ÿæˆå™¨çš„å…³é”®ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³å¤šå¯¹å¤šæ‘˜è¦ç”Ÿæˆï¼ˆM2MSï¼‰ä¸­çš„äº‹å®æ€§é—®é¢˜å’Œé›¶-shotæ¨¡å‹æ€§èƒ½ä¸è¶³çš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤šè¯­è¨€å¤„ç†æ—¶ï¼Œå¸¸å¸¸æ— æ³•ä¿è¯ç”Ÿæˆæ‘˜è¦çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºé€šè¿‡é‡æ–°ç»„ç»‡æ•°æ®é›†å¹¶å¯¹LLMsè¿›è¡ŒæŒ‡ä»¤å¾®è°ƒï¼Œä»¥æå‡å…¶åœ¨å¤šå¯¹å¤šæ‘˜è¦ç”Ÿæˆä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨å……åˆ†åˆ©ç”¨LLMsçš„å¤šè¯­è¨€èƒ½åŠ›ï¼ŒåŒæ—¶å¢å¼ºå…¶åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„é€‚åº”æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†çš„é‡æ–°ç»„ç»‡ã€LLMsçš„é›¶-shotå’ŒæŒ‡ä»¤å¾®è°ƒè¯„ä¼°ã€‚ç ”ç©¶ä½¿ç”¨äº†47.8Kæ ·æœ¬çš„å¤šè¯­è¨€æ•°æ®é›†ï¼Œå¹¶å¯¹18ç§LLMsè¿›è¡Œäº†åŸºå‡†æµ‹è¯•ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºé€šè¿‡æŒ‡ä»¤å¾®è°ƒæ˜¾è‘—æå‡LLMsçš„M2MSèƒ½åŠ›ï¼Œå¹¶ä¸”åœ¨è‡ªåŠ¨è¯„ä¼°ä¸­è¶…è¶Šäº†åŒ…æ‹¬GPT-4åœ¨å†…çš„é›¶-shotæ¨¡å‹ã€‚è¿™ä¸€æ–¹æ³•å±•ç¤ºäº†LLMsåœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„å¯è°ƒæ€§å’Œé€‚åº”æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨äº†å¤šç§LLMsè¿›è¡Œæ¯”è¾ƒï¼ŒåŒ…æ‹¬å¾®è°ƒçš„ä¼ ç»Ÿæ¨¡å‹ï¼ˆå¦‚mBARTï¼‰ï¼Œå¹¶é€šè¿‡è‡ªåŠ¨è¯„ä¼°å’Œäººç±»è¯„ä¼°æ¥éªŒè¯æ¨¡å‹çš„æ€§èƒ½ã€‚å…³é”®å‚æ•°å’ŒæŸå¤±å‡½æ•°çš„è®¾ç½®ç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨å¤šè¯­è¨€æ‘˜è¦ç”Ÿæˆä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œç»è¿‡æŒ‡ä»¤å¾®è°ƒçš„å¼€æºLLMsåœ¨å¤šå¯¹å¤šæ‘˜è¦ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œè‡ªåŠ¨è¯„ä¼°å¾—åˆ†æ˜¾è‘—é«˜äºé›¶-shot LLMsï¼ˆåŒ…æ‹¬GPT-4ï¼‰ï¼Œå¹¶ä¸”ä¸å¾®è°ƒçš„ä¼ ç»Ÿæ¨¡å‹ç›¸å½“ã€‚è¿™è¡¨æ˜æŒ‡ä»¤å¾®è°ƒèƒ½å¤Ÿæœ‰æ•ˆæå‡LLMsçš„ä»»åŠ¡ç‰¹å®šèƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤šè¯­è¨€ä¿¡æ¯æ£€ç´¢ã€è·¨è¯­è¨€æ–‡æ¡£æ‘˜è¦ç”Ÿæˆä»¥åŠå›½é™…åŒ–å†…å®¹çš„è‡ªåŠ¨åŒ–å¤„ç†ã€‚éšç€å…¨çƒä¿¡æ¯äº¤æµçš„åŠ é€Ÿï¼ŒM2MSæŠ€æœ¯å°†ä¸ºå¤šè¯­è¨€ç”¨æˆ·æä¾›æ›´é«˜æ•ˆçš„ä¿¡æ¯è·å–æ–¹å¼ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Many-to-many summarization (M2MS) aims to process documents in any language and generate the corresponding summaries also in any language. Recently, large language models (LLMs) have shown strong multi-lingual abilities, giving them the potential to perform M2MS in real applications. This work presents a systematic empirical study on LLMs' M2MS ability. Specifically, we first reorganize M2MS data based on eight previous domain-specific datasets. The reorganized data contains 47.8K samples spanning five domains and six languages, which could be used to train and evaluate LLMs. Then, we benchmark 18 LLMs in a zero-shot manner and an instruction-tuning manner. Fine-tuned traditional models (e.g., mBART) are also conducted for comparisons. Our experiments reveal that, zero-shot LLMs achieve competitive results with fine-tuned traditional models. After instruct-tuning, open-source LLMs can significantly improve their M2MS ability, and outperform zero-shot LLMs (including GPT-4) in terms of automatic evaluations. In addition, we demonstrate that this task-specific improvement does not sacrifice the LLMs' general task-solving abilities. However, as revealed by our human evaluation, LLMs still face the factuality issue, and the instruction tuning might intensify the issue. Thus, how to control factual errors becomes the key when building LLM summarizers in real applications, and is worth noting in future research.

