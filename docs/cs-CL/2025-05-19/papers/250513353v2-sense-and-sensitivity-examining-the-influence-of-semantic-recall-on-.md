---
layout: default
title: "Sense and Sensitivity: Examining the Influence of Semantic Recall on Long Context Code Reasoning"
---

# Sense and Sensitivity: Examining the Influence of Semantic Recall on Long Context Code Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.13353" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.13353v2</a>
  <a href="https://arxiv.org/pdf/2505.13353.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.13353v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.13353v2', 'Sense and Sensitivity: Examining the Influence of Semantic Recall on Long Context Code Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Adam Å torek, Mukur Gupta, Samira Hajizadeh, Prashast Srivastava, Suman Jana

**åˆ†ç±»**: cs.CL, cs.LG, cs.SE

**å‘å¸ƒæ—¥æœŸ**: 2025-05-19 (æ›´æ–°: 2025-05-20)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSemTraceä»¥è§£å†³é•¿ä¸Šä¸‹æ–‡ä»£ç æ¨ç†ä¸­çš„è¯­ä¹‰å›å¿†é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ä»£ç æ¨ç†` `è¯­ä¹‰å›å¿†` `SemTrace` `ä¸Šä¸‹æ–‡ç†è§£`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é•¿ä¸Šä¸‹æ–‡ä»£ç æ¨ç†ä¸­çš„æœ‰æ•ˆæ€§å°šä¸æ˜ç¡®ï¼Œå°¤å…¶åœ¨è¯­ä¹‰å›å¿†æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºSemTraceæŠ€æœ¯ï¼Œé€šè¿‡å½’å› ç‰¹å®šè¯­å¥å¯¹è¾“å‡ºçš„å½±å“ï¼Œæ¥å¢å¼ºä»£ç æ¨ç†çš„è¯­ä¹‰å›å¿†èƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œéšç€ä»£ç ç‰‡æ®µæ¥è¿‘è¾“å…¥ä¸Šä¸‹æ–‡ä¸­é—´ï¼Œæ¨ç†å‡†ç¡®æ€§æ˜¾è‘—ä¸‹é™ï¼Œå°¤å…¶åœ¨éœ€è¦é«˜è¯­ä¹‰å›å¿†çš„æƒ…å†µä¸‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡ç°ä»£å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ”¯æŒæå¤§çš„ä¸Šä¸‹æ–‡ï¼Œä½†å®ƒä»¬åœ¨åˆ©ç”¨é•¿ä¸Šä¸‹æ–‡è¿›è¡Œä»£ç æ¨ç†çš„æœ‰æ•ˆæ€§ä»ä¸æ˜ç¡®ã€‚æœ¬æ–‡ç ”ç©¶äº†LLMsåœ¨å¤§å‹ä»£ç åº“ä¸­å¯¹ä»£ç ç‰‡æ®µçš„æ¨ç†èƒ½åŠ›åŠå…¶ä¸å›å¿†èƒ½åŠ›çš„å…³ç³»ã€‚æˆ‘ä»¬åŒºåˆ†äº†è¯æ±‡ä»£ç å›å¿†ï¼ˆé€å­—æ£€ç´¢ï¼‰å’Œè¯­ä¹‰ä»£ç å›å¿†ï¼ˆè®°ä½ä»£ç çš„åŠŸèƒ½ï¼‰ã€‚ä¸ºæµ‹é‡è¯­ä¹‰å›å¿†ï¼Œæˆ‘ä»¬æå‡ºäº†SemTraceï¼Œä¸€ç§ä»£ç æ¨ç†æŠ€æœ¯ï¼Œèƒ½å¤Ÿå½’å› äºç‰¹å®šè¯­å¥å¯¹è¾“å‡ºçš„å½±å“ã€‚æˆ‘ä»¬çš„è¯„ä¼°æ˜¾ç¤ºï¼Œéšç€ä»£ç ç‰‡æ®µæ¥è¿‘è¾“å…¥ä¸Šä¸‹æ–‡çš„ä¸­é—´ï¼Œä»£ç æ¨ç†å‡†ç¡®æ€§æ˜¾è‘—ä¸‹é™ï¼Œå°¤å…¶æ˜¯å¯¹äºéœ€è¦é«˜è¯­ä¹‰å›å¿†çš„æŠ€æœ¯å¦‚SemTraceã€‚æ­¤å¤–ï¼Œè¯æ±‡å›å¿†çš„è¡¨ç°å› ç²’åº¦è€Œå¼‚ï¼Œæ¨¡å‹åœ¨å‡½æ•°æ£€ç´¢ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä½†é€è¡Œå›å¿†å´å­˜åœ¨å›°éš¾ã€‚æœ€åï¼Œæˆ‘ä»¬å‘ç°å½“å‰çš„ä»£ç æ¨ç†åŸºå‡†å¯èƒ½åœ¨è¯­ä¹‰å›å¿†æ•æ„Ÿæ€§ä¸Šè¡¨ç°è¾ƒä½ï¼Œå¯èƒ½ä½ä¼°äº†LLMsåœ¨åˆ©ç”¨ä¸Šä¸‹æ–‡ä¿¡æ¯æ—¶é¢ä¸´çš„æŒ‘æˆ˜ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é•¿ä¸Šä¸‹æ–‡ä»£ç æ¨ç†ä¸­çš„è¯­ä¹‰å›å¿†ä¸è¶³é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚ä»£ç ç‰‡æ®µæ—¶ï¼Œå¾€å¾€æ— æ³•æœ‰æ•ˆåˆ©ç”¨ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¯¼è‡´æ¨ç†å‡†ç¡®æ€§ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºSemTraceæŠ€æœ¯ï¼Œæ—¨åœ¨é€šè¿‡åˆ†æç‰¹å®šä»£ç è¯­å¥å¯¹è¾“å‡ºçš„å½±å“ï¼Œæå‡æ¨¡å‹çš„è¯­ä¹‰å›å¿†èƒ½åŠ›ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ä»£ç çš„åŠŸèƒ½ï¼Œè€Œä¸ä»…ä»…æ˜¯é€å­—æ£€ç´¢ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€è¯­ä¹‰å›å¿†æµ‹é‡å’Œæ¨ç†æ¨¡å—ã€‚é¦–å…ˆï¼Œå¯¹ä»£ç ç‰‡æ®µè¿›è¡Œåˆ†æï¼Œç„¶åé€šè¿‡SemTraceæŠ€æœ¯è¿›è¡Œæ¨ç†ï¼Œæœ€åè¯„ä¼°æ¨¡å‹çš„æ¨ç†å‡†ç¡®æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†è¯­ä¹‰å›å¿†çš„æ¦‚å¿µï¼Œå¹¶é€šè¿‡SemTraceæŠ€æœ¯å®ç°äº†å¯¹ä»£ç æ¨ç†è¿‡ç¨‹çš„å¯è§£é‡Šæ€§ã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„é€å­—æ£€ç´¢æœºåˆ¶å½¢æˆäº†é²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼ŒSemTraceçš„è®¾è®¡åŒ…æ‹¬ç‰¹å®šçš„æŸå¤±å‡½æ•°ï¼Œä»¥ä¼˜åŒ–è¯­ä¹‰å›å¿†çš„èƒ½åŠ›ï¼Œå¹¶é‡‡ç”¨å¤šå±‚ç¥ç»ç½‘ç»œç»“æ„æ¥å¢å¼ºæ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œéšç€ä»£ç ç‰‡æ®µæ¥è¿‘è¾“å…¥ä¸Šä¸‹æ–‡çš„ä¸­é—´ï¼Œæ¨ç†å‡†ç¡®æ€§ä¸‹é™å¹…åº¦å¯è¾¾20%ã€‚ç‰¹åˆ«æ˜¯åœ¨ä½¿ç”¨SemTraceæŠ€æœ¯æ—¶ï¼Œæ¨¡å‹åœ¨è¯­ä¹‰å›å¿†æ–¹é¢çš„è¡¨ç°æ˜¾è‘—ä½äºè¯æ±‡å›å¿†ï¼Œæ­ç¤ºäº†ä¸¤è€…ä¹‹é—´çš„è„±èŠ‚ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è½¯ä»¶å¼€å‘ã€ä»£ç å®¡æŸ¥å’Œè‡ªåŠ¨åŒ–æµ‹è¯•ç­‰ã€‚é€šè¿‡æå‡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä»£ç æ¨ç†ä¸­çš„è¯­ä¹‰å›å¿†èƒ½åŠ›ï¼Œå¯ä»¥æ˜¾è‘—æé«˜ä»£ç ç†è§£å’Œç”Ÿæˆçš„å‡†ç¡®æ€§ï¼Œä»è€Œä¸ºå¼€å‘è€…æä¾›æ›´å¼ºå¤§çš„å·¥å…·æ”¯æŒï¼Œæ¨åŠ¨è½¯ä»¶å·¥ç¨‹çš„æ™ºèƒ½åŒ–è¿›ç¨‹ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Although modern Large Language Models (LLMs) support extremely large contexts, their effectiveness in utilizing long context for code reasoning remains unclear. This paper investigates LLM reasoning ability over code snippets within large repositories and how it relates to their recall ability. Specifically, we differentiate between lexical code recall (verbatim retrieval) and semantic code recall (remembering what the code does). To measure semantic recall, we propose SemTrace, a code reasoning technique where the impact of specific statements on output is attributable and unpredictable. We also present a method to quantify semantic recall sensitivity in existing benchmarks. Our evaluation of state-of-the-art LLMs reveals a significant drop in code reasoning accuracy as a code snippet approaches the middle of the input context, particularly with techniques requiring high semantic recall like SemTrace. Moreover, we find that lexical recall varies by granularity, with models excelling at function retrieval but struggling with line-by-line recall. Notably, a disconnect exists between lexical and semantic recall, suggesting different underlying mechanisms. Finally, our findings indicate that current code reasoning benchmarks may exhibit low semantic recall sensitivity, potentially underestimating LLM challenges in leveraging in-context information.

