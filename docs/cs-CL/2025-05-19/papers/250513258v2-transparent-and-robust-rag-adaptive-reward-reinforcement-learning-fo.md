---
layout: default
title: Transparent and Robust RAG: Adaptive-Reward Reinforcement Learning for Decision Traceability
---

# Transparent and Robust RAG: Adaptive-Reward Reinforcement Learning for Decision Traceability

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.13258" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.13258v2</a>
  <a href="https://arxiv.org/pdf/2505.13258.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.13258v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.13258v2', 'Transparent and Robust RAG: Adaptive-Reward Reinforcement Learning for Decision Traceability')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jingyi Ren, Yekun Xu, Xiaolong Wang, Weitao Li, Weizhi Ma, Yang Liu

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-19 (æ›´æ–°: 2025-10-11)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºARENAä»¥è§£å†³RAGç”Ÿæˆä¸­çš„é€æ˜æ€§ä¸ç¨³å®šæ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æ£€ç´¢å¢å¼ºç”Ÿæˆ` `å¼ºåŒ–å­¦ä¹ ` `é€æ˜æ€§` `ç¨³å®šæ€§` `è‡ªé€‚åº”å¥–åŠ±` `å¤šè·³é—®ç­”` `ç»“æ„åŒ–æ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„RAGç”Ÿæˆæ–¹æ³•åœ¨é€æ˜æ€§æ–¹é¢ä¸è¶³ï¼Œæ— æ³•æ˜ç¡®æŒ‡å‡ºæ¨ç†è¿‡ç¨‹ä¸­ä½¿ç”¨çš„å¼•ç”¨ï¼Œé™åˆ¶äº†è§£é‡Šæ€§å’Œå¯è§æ€§ã€‚
2. æœ¬æ–‡æå‡ºçš„ARENAæ¡†æ¶é€šè¿‡è‡ªé€‚åº”å¥–åŠ±æœºåˆ¶å’ŒKLæ•£åº¦ç¨³å®šåŒ–æ¨¡å—ï¼Œæå‡äº†RAGç”Ÿæˆå™¨çš„é€æ˜æ€§å’Œç¨³å®šæ€§ã€‚
3. åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒARENAåœ¨å¤šè·³é—®ç­”æ•°æ®é›†ä¸Šå®ç°äº†10-30%çš„å‡†ç¡®ç‡æå‡ï¼Œè¡¨ç°ä¸å…ˆè¿›çš„é—­æºå¤§æ¨¡å‹ç›¸å½“ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰åœ¨çŸ¥è¯†å¯†é›†å‹åº”ç”¨ä¸­å…·æœ‰é‡è¦ä»·å€¼ï¼Œä½†ç°æœ‰æ–¹æ³•åœ¨é€æ˜æ€§å’Œç¨³å®šæ€§æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚æœ¬æ–‡æå‡ºäº†è‡ªé€‚åº”å¥–åŠ±è¯æ®å¯¼èˆªä»£ç†ï¼ˆARENAï¼‰ï¼Œé€šè¿‡è®¾è®¡å¥–åŠ±æ¥è®­ç»ƒRAGç”Ÿæˆå™¨ï¼Œè§£å†³äº†å¼•ç”¨é€æ˜æ€§å’Œè®­ç»ƒä¸ç¨³å®šæ€§çš„é—®é¢˜ã€‚ARENAèƒ½å¤Ÿè¯†åˆ«å…³é”®è¯æ®ï¼Œè¿›è¡Œç»“æ„åŒ–æ¨ç†ï¼Œå¹¶ç”Ÿæˆå¯è§£é‡Šçš„å†³ç­–è½¨è¿¹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒARENAåœ¨å¤šä¸ªå¤šè·³é—®ç­”æ•°æ®é›†ä¸Šå®ç°äº†10-30%çš„å‡†ç¡®ç‡æå‡ï¼Œå¹¶ä¸”åœ¨æœªè§æ•°æ®é›†å’Œä»»åŠ¡ä¸Šå…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„RAGç”Ÿæˆæ–¹æ³•åœ¨æ¨ç†è¿‡ç¨‹ä¸­ç¼ºä¹é€æ˜æ€§ï¼Œæ— æ³•æ˜ç¡®æŒ‡å‡ºæ‰€ç”¨çš„å¼•ç”¨ï¼Œå¯¼è‡´è§£é‡Šæ€§ä¸è¶³ã€‚æ­¤å¤–ï¼Œç°æœ‰çš„åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ–¹æ³•åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯èƒ½å‡ºç°æ¢¯åº¦å°–å³°ï¼Œå¯¼è‡´ä¸ç¨³å®šæ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šARENAé€šè¿‡è®¾è®¡è‡ªé€‚åº”å¥–åŠ±å’ŒKLæ•£åº¦ç¨³å®šåŒ–æœºåˆ¶ï¼Œæ—¨åœ¨æå‡RAGç”Ÿæˆå™¨çš„é€æ˜æ€§å’Œè®­ç»ƒç¨³å®šæ€§ï¼Œä½¿å…¶èƒ½å¤Ÿè¯†åˆ«å…³é”®è¯æ®å¹¶è¿›è¡Œç»“æ„åŒ–æ¨ç†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šARENAæ¡†æ¶åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šè‡ªé€‚åº”å¥–åŠ±è®¡ç®—æ¨¡å—ã€KLæ•£åº¦ç¨³å®šåŒ–æ¨¡å—å’Œç»“æ„åŒ–æ¨ç†æ¨¡å—ã€‚è‡ªé€‚åº”å¥–åŠ±æ¨¡å—æ ¹æ®ç”Ÿæˆçš„ç­”æ¡ˆå’Œå¼•ç”¨çš„è´¨é‡åŠ¨æ€è°ƒæ•´å¥–åŠ±ï¼ŒKLæ•£åº¦æ¨¡å—åˆ™ç”¨äºå¹³æ»‘è®­ç»ƒè¿‡ç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šARENAçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶è‡ªé€‚åº”å¥–åŠ±æœºåˆ¶å’ŒKLæ•£åº¦ç¨³å®šåŒ–è®¾è®¡ï¼Œä½¿å¾—ç”Ÿæˆå™¨ä¸ä»…èƒ½å¤Ÿæä¾›å¯è§£é‡Šçš„å†³ç­–è½¨è¿¹ï¼Œè¿˜èƒ½åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¿æŒç¨³å®šæ€§ã€‚è¿™ä¸ä¼ ç»Ÿæ–¹æ³•çš„é™æ€å¥–åŠ±å’Œä¸ç¨³å®šè®­ç»ƒè¿‡ç¨‹å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼ŒARENAé‡‡ç”¨äº†åŠ¨æ€è°ƒæ•´çš„å¥–åŠ±å‡½æ•°ï¼Œç»“åˆäº†ç”Ÿæˆè´¨é‡å’Œå¼•ç”¨æœ‰æ•ˆæ€§ã€‚åŒæ—¶ï¼Œç½‘ç»œç»“æ„ä¸Šå¼•å…¥äº†å¤šå±‚æ¬¡çš„æ¨ç†æ¨¡å—ï¼Œä»¥å¢å¼ºæ¨¡å‹çš„æ¨ç†èƒ½åŠ›å’Œé€æ˜æ€§ã€‚é€šè¿‡è¿™äº›è®¾è®¡ï¼ŒARENAèƒ½å¤Ÿåœ¨å¤šè·³é—®ç­”ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ARENAåœ¨å¤šä¸ªå¤šè·³é—®ç­”æ•°æ®é›†ä¸Šå®ç°äº†10-30%çš„å‡†ç¡®ç‡æå‡ï¼Œè¡¨ç°ä¼˜äºå¤šä¸ªåŸºå‡†æ¨¡å‹ï¼Œå¹¶ä¸”åœ¨æœªè§æ•°æ®é›†ä¸Šå±•ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒARENAåœ¨é€æ˜æ€§å’Œç¨³å®šæ€§æ–¹é¢çš„åˆ›æ–°è®¾è®¡æ˜¾è‘—æå‡äº†RAGç”Ÿæˆå™¨çš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ARENAçš„ç ”ç©¶æˆæœåœ¨çŸ¥è¯†å¯†é›†å‹åº”ç”¨ä¸­å…·æœ‰å¹¿æ³›çš„æ½œåœ¨åº”ç”¨ä»·å€¼ï¼Œå¦‚æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€çŸ¥è¯†å›¾è°±æ„å»ºå’Œä¿¡æ¯æ£€ç´¢ç­‰é¢†åŸŸã€‚å…¶é€æ˜æ€§å’Œç¨³å®šæ€§æå‡å°†æœ‰åŠ©äºå¢å¼ºç”¨æˆ·å¯¹AIç³»ç»Ÿçš„ä¿¡ä»»ï¼Œæ¨åŠ¨æ›´å¹¿æ³›çš„å®é™…åº”ç”¨ã€‚æœªæ¥ï¼ŒARENAçš„è®¾è®¡ç†å¿µä¹Ÿå¯èƒ½è¢«åº”ç”¨äºå…¶ä»–ç±»å‹çš„ç”Ÿæˆæ¨¡å‹ä¸­ï¼Œä¿ƒè¿›æ›´é«˜æ•ˆçš„æ¨ç†å’Œå†³ç­–è¿‡ç¨‹ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Retrieval-Augmented Generation (RAG) delivers substantial value in knowledge-intensive applications. Many recent works use reinforcement learning (RL) to elicit strong reasoning in RAG generators. However, two key challenges remain unresolved: (1) Transparency: most prior methods do not explicitly indicate which references are actually used during the reasoning that leads to the final answer, limiting interpretability and visibility; (2) Stability: the KL divergence estimator used in existing RL-based approaches may cause gradient spikes, leading to unstable training. To address these challenges, we propose Adaptive-Rewarded Evidence Navigation Agent (ARENA), a transparent and robust RAG generator framework trained via RL with designed rewards. Based on our structured protocol, KL divergence stabilization, and adaptive reward calculation modules, ARENA enables the RAG generator to identify key evidence, perform structured reasoning, and generate answers with interpretable decision traces. Applied to Qwen2.5-7B-Instruct and Llama3.1-8B-Instruct, extensive experiments across multiple baselines show 10-30% accuracy improvements on three multi-hop QA datasets, comparable to advanced closed-source LLMs (e.g., OpenAI o1, DeepSeek R1). Further analyses show that ARENA generalizes well to unseen datasets and tasks. Our models and codes are publicly released.

