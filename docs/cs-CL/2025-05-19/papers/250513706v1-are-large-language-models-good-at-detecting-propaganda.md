---
layout: default
title: Are Large Language Models Good at Detecting Propaganda?
---

# Are Large Language Models Good at Detecting Propaganda?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.13706" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.13706v1</a>
  <a href="https://arxiv.org/pdf/2505.13706.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.13706v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.13706v1', 'Are Large Language Models Good at Detecting Propaganda?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Julia Jose, Rachel Greenstadt

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-19

**æœŸåˆŠ**: Workshop Proceedings of the 18th International AAAI Conference on Web and Social Media (5th International Workshop on Cyber Social Threats, CySoc 2024). AAAI Press

**DOI**: [10.36190/2024.06](https://doi.org/10.36190/2024.06)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å®£ä¼ æ£€æµ‹ä¸­çš„æœ‰æ•ˆæ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å®£ä¼ æ£€æµ‹` `è‡ªç„¶è¯­è¨€å¤„ç†` `æƒ…æ„Ÿåˆ†æ` `é€»è¾‘è°¬è¯¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨è¯†åˆ«å®£ä¼ æŠ€æœ¯æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚çš„æƒ…æ„Ÿå’Œé€»è¾‘æ“æ§å†…å®¹çš„æ£€æµ‹ä¸Šã€‚
2. æœ¬ç ”ç©¶é€šè¿‡æ¯”è¾ƒä¸åŒå¤§å‹è¯­è¨€æ¨¡å‹çš„æ€§èƒ½ï¼Œæ¢ç´¢å…¶åœ¨æ£€æµ‹æ–°é—»æ–‡ç« ä¸­å®£ä¼ æŠ€æœ¯çš„æœ‰æ•ˆæ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒGPT-4çš„F1åˆ†æ•°ä¸º0.16ï¼Œè™½ç„¶ä¼˜äºå…¶ä»–æ¨¡å‹ï¼Œä½†ä»ä½äºRoBERTa-CRFçš„0.67åŸºçº¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å®£ä¼ è€…åˆ©ç”¨é€»è¾‘è°¬è¯¯å’Œæƒ…æ„Ÿè¯‰æ±‚çš„ä¿®è¾æ‰‹æ³•æ¥æ¨åŠ¨å…¶è®®ç¨‹ã€‚è¯†åˆ«è¿™äº›æŠ€æœ¯å¯¹äºåšå‡ºæ˜æ™ºå†³ç­–è‡³å…³é‡è¦ã€‚éšç€è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰çš„è¿›æ­¥ï¼Œå¼€å‘å‡ºèƒ½å¤Ÿæ£€æµ‹æ“æ§å†…å®¹çš„ç³»ç»Ÿæˆä¸ºå¯èƒ½ã€‚æœ¬ç ”ç©¶è€ƒå¯Ÿäº†å‡ ç§å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ–°é—»æ–‡ç« ä¸­æ£€æµ‹å®£ä¼ æŠ€æœ¯çš„è¡¨ç°ï¼Œå¹¶å°†å…¶ä¸åŸºäºå˜æ¢å™¨çš„æ¨¡å‹è¿›è¡Œæ¯”è¾ƒã€‚ç»“æœæ˜¾ç¤ºï¼Œå°½ç®¡GPT-4åœ¨F1åˆ†æ•°ä¸Šä¼˜äºGPT-3.5å’ŒClaude 3 Opusï¼Œä½†ä»æœªèƒ½è¶…è¶ŠRoBERTa-CRFåŸºçº¿ã€‚æ­¤å¤–ï¼Œæ‰€æœ‰ä¸‰ç§LLMåœ¨æ£€æµ‹å…­ç§å®£ä¼ æŠ€æœ¯ä¸­çš„ä¸€ç§ï¼ˆæŠ¨å‡»ï¼‰æ—¶è¡¨ç°ä¼˜äºå¤šç²’åº¦ç½‘ç»œï¼ˆMGNï¼‰åŸºçº¿ï¼ŒGPT-3.5å’ŒGPT-4åœ¨æ£€æµ‹ææƒ§è¯‰æ±‚å’Œæ——å¸œæŒ¥èˆæ–¹é¢ä¹Ÿè¡¨ç°æ›´ä½³ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ£€æµ‹æ–°é—»æ–‡ç« ä¸­çš„å®£ä¼ æŠ€æœ¯æ—¶çš„æœ‰æ•ˆæ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚çš„å®£ä¼ æ‰‹æ³•æ—¶è¡¨ç°ä¸ä½³ï¼Œå°¤å…¶æ˜¯åœ¨é€»è¾‘è°¬è¯¯å’Œæƒ…æ„Ÿæ“æ§çš„è¯†åˆ«ä¸Šå­˜åœ¨æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡é€šè¿‡æ¯”è¾ƒå¤šç§å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆå¦‚GPT-4ã€GPT-3.5å’ŒClaude 3 Opusï¼‰ä¸ä¼ ç»Ÿæ¨¡å‹ï¼ˆå¦‚RoBERTa-CRFï¼‰çš„è¡¨ç°ï¼Œè¯„ä¼°å…¶åœ¨è¯†åˆ«å®£ä¼ æŠ€æœ¯æ–¹é¢çš„èƒ½åŠ›ï¼Œæ—¨åœ¨æ‰¾å‡ºæœ€æœ‰æ•ˆçš„æ£€æµ‹æ–¹æ³•ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶è®¾è®¡äº†ä¸€ä¸ªå®éªŒæ¡†æ¶ï¼ŒåŒ…å«æ•°æ®é›†çš„æ„å»ºã€æ¨¡å‹çš„è®­ç»ƒä¸è¯„ä¼°ï¼Œä¸»è¦æ¨¡å—åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒã€æ€§èƒ½è¯„ä¼°å’Œç»“æœåˆ†æã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„åˆ›æ–°ç‚¹åœ¨äºç³»ç»Ÿæ€§åœ°æ¯”è¾ƒäº†å¤šç§å¤§å‹è¯­è¨€æ¨¡å‹ä¸ä¼ ç»Ÿæ¨¡å‹åœ¨å®£ä¼ æ£€æµ‹ä¸­çš„è¡¨ç°ï¼Œæ­ç¤ºäº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç‰¹å®šå®£ä¼ æŠ€æœ¯ï¼ˆå¦‚æŠ¨å‡»ã€ææƒ§è¯‰æ±‚ç­‰ï¼‰æ£€æµ‹ä¸­çš„ä¼˜åŠ¿ä¸å±€é™ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨äº†æ ‡å‡†çš„F1åˆ†æ•°ä½œä¸ºæ€§èƒ½è¯„ä¼°æŒ‡æ ‡ï¼Œé‡ç‚¹å…³æ³¨ä¸åŒæ¨¡å‹åœ¨å¤šç§å®£ä¼ æŠ€æœ¯è¯†åˆ«ä¸­çš„è¡¨ç°å·®å¼‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGPT-4åœ¨F1åˆ†æ•°ä¸Šä¸º0.16ï¼Œä¼˜äºGPT-3.5å’ŒClaude 3 Opusï¼Œä½†æœªèƒ½è¶…è¶ŠRoBERTa-CRFçš„0.67åŸºçº¿ã€‚æ­¤å¤–ï¼Œæ‰€æœ‰ä¸‰ç§LLMåœ¨æ£€æµ‹æŠ¨å‡»æŠ€æœ¯æ—¶è¡¨ç°ä¼˜äºMGNåŸºçº¿ï¼ŒGPT-3.5å’ŒGPT-4åœ¨ææƒ§è¯‰æ±‚å’Œæ——å¸œæŒ¥èˆçš„æ£€æµ‹ä¸­ä¹Ÿè¡¨ç°æ›´ä½³ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ–°é—»åª’ä½“ã€ç¤¾äº¤ç½‘ç»œå’Œä¿¡æ¯éªŒè¯å¹³å°ã€‚é€šè¿‡æé«˜å¯¹å®£ä¼ å†…å®¹çš„æ£€æµ‹èƒ½åŠ›ï¼Œå¯ä»¥å¸®åŠ©ç”¨æˆ·åšå‡ºæ›´æ˜æ™ºçš„å†³ç­–ï¼Œå‡å°‘è¯¯å¯¼ä¿¡æ¯çš„ä¼ æ’­ï¼Œå¢å¼ºå…¬ä¼—å¯¹ä¿¡æ¯çš„æ‰¹åˆ¤æ€§æ€ç»´èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Propagandists use rhetorical devices that rely on logical fallacies and emotional appeals to advance their agendas. Recognizing these techniques is key to making informed decisions. Recent advances in Natural Language Processing (NLP) have enabled the development of systems capable of detecting manipulative content. In this study, we look at several Large Language Models and their performance in detecting propaganda techniques in news articles. We compare the performance of these LLMs with transformer-based models. We find that, while GPT-4 demonstrates superior F1 scores (F1=0.16) compared to GPT-3.5 and Claude 3 Opus, it does not outperform a RoBERTa-CRF baseline (F1=0.67). Additionally, we find that all three LLMs outperform a MultiGranularity Network (MGN) baseline in detecting instances of one out of six propaganda techniques (name-calling), with GPT-3.5 and GPT-4 also outperforming the MGN baseline in detecting instances of appeal to fear and flag-waving.

