---
layout: default
title: Thinkless: LLM Learns When to Think
---

# Thinkless: LLM Learns When to Think

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.13379" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.13379v2</a>
  <a href="https://arxiv.org/pdf/2505.13379.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.13379v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.13379v2', 'Thinkless: LLM Learns When to Think')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Gongfan Fang, Xinyin Ma, Xinchao Wang

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-19 (æ›´æ–°: 2025-06-26)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/VainF/Thinkless)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºThinklessæ¡†æ¶ä»¥æé«˜æ¨ç†è¯­è¨€æ¨¡å‹çš„è®¡ç®—æ•ˆç‡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ¨ç†è¯­è¨€æ¨¡å‹` `å¼ºåŒ–å­¦ä¹ ` `æ§åˆ¶æ ‡è®°` `è§£è€¦ä¼˜åŒ–` `è®¡ç®—æ•ˆç‡` `ä»»åŠ¡å¤æ‚æ€§` `å“åº”ç”Ÿæˆ` `æ¨¡å‹è®­ç»ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ¨ç†è¯­è¨€æ¨¡å‹åœ¨å¤„ç†æ‰€æœ‰æŸ¥è¯¢æ—¶å‡é‡‡ç”¨å¤æ‚æ¨ç†ï¼Œå¯¼è‡´è®¡ç®—æ•ˆç‡ä½ä¸‹ï¼Œå°¤å…¶æ˜¯åœ¨ç®€å•é—®é¢˜ä¸Šã€‚
2. æœ¬æ–‡æå‡ºThinklessæ¡†æ¶ï¼Œé€šè¿‡æ§åˆ¶æ ‡è®°è‡ªé€‚åº”é€‰æ‹©æ¨ç†æ–¹å¼ï¼Œç»“åˆå¼ºåŒ–å­¦ä¹ è¿›è¡Œè®­ç»ƒï¼Œä¼˜åŒ–æ¨ç†æ•ˆç‡ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒThinklessåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å°†é•¿é“¾æ¨ç†ä½¿ç”¨å‡å°‘50%-90%ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„è®¡ç®—æ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ¨ç†è¯­è¨€æ¨¡å‹åœ¨å¤æ‚é€»è¾‘æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å¯¹æ‰€æœ‰æŸ¥è¯¢éƒ½é‡‡ç”¨å¤æ‚æ¨ç†ä¼šå¯¼è‡´è®¡ç®—æ•ˆç‡ä½ä¸‹ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†Thinklessï¼Œä¸€ä¸ªå¯å­¦ä¹ çš„æ¡†æ¶ï¼Œä½¿å¾—è¯­è¨€æ¨¡å‹èƒ½å¤Ÿæ ¹æ®ä»»åŠ¡å¤æ‚æ€§å’Œæ¨¡å‹èƒ½åŠ›è‡ªé€‚åº”é€‰æ‹©ç®€çŸ­æˆ–è¯¦ç»†çš„æ¨ç†æ–¹å¼ã€‚Thinklessåœ¨å¼ºåŒ–å­¦ä¹ æ¡†æ¶ä¸‹è®­ç»ƒï¼Œä½¿ç”¨æ§åˆ¶æ ‡è®°<short>å’Œ<think>æ¥åˆ†åˆ«è¡¨ç¤ºç®€æ´å’Œè¯¦ç»†çš„å“åº”ã€‚æ ¸å¿ƒæ–¹æ³•æ˜¯è§£è€¦ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆDeGRPOï¼‰ç®—æ³•ï¼Œå°†æ··åˆæ¨ç†çš„å­¦ä¹ ç›®æ ‡åˆ†è§£ä¸ºæ§åˆ¶æ ‡è®°æŸå¤±å’Œå“åº”æŸå¤±ä¸¤ä¸ªéƒ¨åˆ†ï¼Œä»è€Œæé«˜äº†è®­ç»ƒçš„ç¨³å®šæ€§å’Œæ•ˆç‡ã€‚åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒThinklessèƒ½å¤Ÿå°†é•¿é“¾æ¨ç†çš„ä½¿ç”¨å‡å°‘50%-90%ï¼Œæ˜¾è‘—æå‡äº†æ¨ç†è¯­è¨€æ¨¡å‹çš„æ•ˆç‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ¨ç†è¯­è¨€æ¨¡å‹åœ¨å¤„ç†ç®€å•é—®é¢˜æ—¶è¿‡åº¦ä½¿ç”¨å¤æ‚æ¨ç†å¯¼è‡´çš„è®¡ç®—æ•ˆç‡ä½ä¸‹é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆåŒºåˆ†ä»»åŠ¡å¤æ‚æ€§ï¼Œå¯¼è‡´èµ„æºæµªè´¹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºThinklessæ¡†æ¶ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ ¹æ®ä»»åŠ¡å¤æ‚æ€§å’Œè‡ªèº«èƒ½åŠ›è‡ªé€‚åº”é€‰æ‹©ç®€çŸ­æˆ–è¯¦ç»†çš„æ¨ç†æ–¹å¼ï¼Œä»è€Œæé«˜è®¡ç®—æ•ˆç‡ã€‚é€šè¿‡å¼•å…¥æ§åˆ¶æ ‡è®°ï¼Œæ¨¡å‹å¯ä»¥çµæ´»è°ƒæ•´æ¨ç†ç­–ç•¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šThinklessæ¡†æ¶åŸºäºå¼ºåŒ–å­¦ä¹ ï¼ŒåŒ…å«ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šæ§åˆ¶æ ‡è®°é€‰æ‹©æ¨¡å—å’Œå“åº”ç”Ÿæˆæ¨¡å—ã€‚æ§åˆ¶æ ‡è®°æ¨¡å—é€šè¿‡<short>å’Œ<think>æ ‡è®°æ¥æŒ‡ç¤ºæ¨ç†æ¨¡å¼ï¼Œè€Œå“åº”ç”Ÿæˆæ¨¡å—åˆ™è´Ÿè´£ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆã€‚

**å…³é”®åˆ›æ–°**ï¼šæ ¸å¿ƒåˆ›æ–°åœ¨äºè§£è€¦ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆDeGRPOï¼‰ç®—æ³•ï¼Œè¯¥ç®—æ³•å°†æ··åˆæ¨ç†çš„å­¦ä¹ ç›®æ ‡åˆ†ä¸ºæ§åˆ¶æ ‡è®°æŸå¤±å’Œå“åº”æŸå¤±ï¼Œæä¾›äº†æ›´ç»†ç²’åº¦çš„æ§åˆ¶ï¼Œé¿å…äº†ä¼ ç»Ÿæ–¹æ³•ä¸­çš„è®­ç»ƒå´©æºƒé—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŸå¤±å‡½æ•°è®¾è®¡ä¸Šï¼Œæ§åˆ¶æ ‡è®°æŸå¤±ç”¨äºä¼˜åŒ–æ¨ç†æ¨¡å¼é€‰æ‹©ï¼Œå“åº”æŸå¤±åˆ™ç”¨äºæå‡ç”Ÿæˆç­”æ¡ˆçš„å‡†ç¡®æ€§ã€‚é€šè¿‡è¿™ç§è§£è€¦è®¾è®¡ï¼Œæ¨¡å‹è®­ç»ƒæ›´åŠ ç¨³å®šï¼Œæ•ˆæœæ˜¾è‘—æå‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ï¼ˆå¦‚Minerva Algebraã€MATH-500å’ŒGSM8Kï¼‰ä¸­ï¼ŒThinklessæ˜¾è‘—å‡å°‘äº†é•¿é“¾æ¨ç†çš„ä½¿ç”¨ï¼Œé™ä½å¹…åº¦è¾¾50%-90%ã€‚è¿™ä¸€ç»“æœè¡¨æ˜ï¼ŒThinklessåœ¨æå‡æ¨ç†è¯­è¨€æ¨¡å‹æ•ˆç‡æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåº”å¯¹å¤æ‚æ¨ç†ä»»åŠ¡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€é‡‘èå’ŒåŒ»ç–—ç­‰éœ€è¦å¤æ‚æ¨ç†çš„åœºæ™¯ã€‚é€šè¿‡æé«˜æ¨ç†è¯­è¨€æ¨¡å‹çš„æ•ˆç‡ï¼ŒThinklesså¯ä»¥åœ¨å®æ—¶å†³ç­–æ”¯æŒã€è‡ªåŠ¨é—®ç­”ç³»ç»Ÿç­‰æ–¹é¢å‘æŒ¥é‡è¦ä½œç”¨ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ™ºèƒ½åŠ©æ‰‹å’Œè‡ªåŠ¨åŒ–ç³»ç»Ÿçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Reasoning Language Models, capable of extended chain-of-thought reasoning, have demonstrated remarkable performance on tasks requiring complex logical inference. However, applying elaborate reasoning for all queries often results in substantial computational inefficiencies, particularly when many problems admit straightforward solutions. This motivates an open question: Can LLMs learn when to think? To answer this, we propose Thinkless, a learnable framework that empowers an LLM to adaptively select between short-form and long-form reasoning, based on both task complexity and the model's ability. Thinkless is trained under a reinforcement learning paradigm and employs two control tokens, <short> for concise responses and <think> for detailed reasoning. At the core of our method is a Decoupled Group Relative Policy Optimization (DeGRPO) algorithm, which decomposes the learning objective of hybrid reasoning into two components: (1) a control token loss that governs the selection of the reasoning mode, and (2) a response loss that improves the accuracy of the generated answers. This decoupled formulation enables fine-grained control over the contributions of each objective, stabilizing training and effectively preventing collapse observed in vanilla GRPO. Empirically, on several benchmarks such as Minerva Algebra, MATH-500, and GSM8K, Thinkless is able to reduce the usage of long-chain thinking by 50% - 90%, significantly improving the efficiency of Reasoning Language Models. The code is available at https://github.com/VainF/Thinkless

