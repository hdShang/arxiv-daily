---
layout: default
title: "Positional Fragility in LLMs: How Offset Effects Reshape Our Understanding of Memorization Risks"
---

# Positional Fragility in LLMs: How Offset Effects Reshape Our Understanding of Memorization Risks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.13171" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.13171v2</a>
  <a href="https://arxiv.org/pdf/2505.13171.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.13171v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.13171v2', 'Positional Fragility in LLMs: How Offset Effects Reshape Our Understanding of Memorization Risks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yixuan Xu, Antoni-Joan Solergibert i Llaquet, Antoine Bosselut, Imanol Schlag

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-19 (æ›´æ–°: 2025-05-28)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä½ç½®è„†å¼±æ€§ç†è®ºä»¥è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹çš„è®°å¿†é£é™©**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `è®°å¿†é£é™©` `ä½ç½®è„†å¼±æ€§` `åç§»æ•ˆåº”` `æ–‡æœ¬ç”Ÿæˆ` `ç‰ˆæƒä¿æŠ¤` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç ”ç©¶æœªèƒ½å……åˆ†è€ƒè™‘ä½ç½®åç§»å¯¹å¤§è¯­è¨€æ¨¡å‹è®°å¿†é£é™©çš„å½±å“ï¼Œå¯¼è‡´å¯¹è®°å¿†æœºåˆ¶çš„ç†è§£ä¸å¤Ÿå…¨é¢ã€‚
2. è®ºæ–‡é€šè¿‡ç³»ç»Ÿçš„é¢„è®­ç»ƒå®éªŒï¼Œæå‡ºäº†ä½ç½®è„†å¼±æ€§ç†è®ºï¼Œæ­ç¤ºäº†çŸ­å‰ç¼€å¯¹é€å­—è®°å¿†çš„æ˜¾è‘—å½±å“ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè°ƒæ•´æ•æ„Ÿæ•°æ®åœ¨ä¸Šä¸‹æ–‡çª—å£ä¸­çš„ä½ç½®å¯ä»¥æœ‰æ•ˆæŠ‘åˆ¶å¯æå–è®°å¿†å’Œæ–‡æœ¬é€€åŒ–ç°è±¡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹å·²çŸ¥ä¼šè®°å¿†éƒ¨åˆ†è®­ç»ƒæ•°æ®ï¼Œå¯èƒ½å¯¼è‡´ç‰ˆæƒä¾µçŠ¯é£é™©ã€‚ä¸ºç³»ç»Ÿæ€§åœ°æ£€éªŒè¿™ä¸€é£é™©ï¼Œç ”ç©¶è€…ä»é›¶å¼€å§‹å¯¹è¯­è¨€æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒï¼Œä½¿ç”¨83Bä¸ªæ ‡è®°ï¼Œæ··åˆç½‘ç»œè§„æ¨¡æ•°æ®ä¸å…¬å…±é¢†åŸŸä¹¦ç±ï¼Œä»¥æ¨¡æ‹Ÿå—æ§é¢‘ç‡çš„ç‰ˆæƒå†…å®¹ã€‚ç ”ç©¶å‘ç°äº†åç§»æ•ˆåº”ï¼Œè¡¨æ˜çŸ­å‰ç¼€æ›´å®¹æ˜“è§¦å‘é€å­—è®°å¿†ï¼Œè€Œå½“å‰ç¼€åç¦»ä¸Šä¸‹æ–‡çª—å£çš„åˆå§‹æ ‡è®°æ—¶ï¼Œé€å­—å›å¿†æ˜¾è‘—ä¸‹é™ã€‚è¿™ä¸€ç°è±¡å½’å› äºä½ç½®è„†å¼±æ€§ï¼Œæ¨¡å‹å¯¹ä¸Šä¸‹æ–‡çª—å£ä¸­æœ€æ—©æ ‡è®°çš„ä¾èµ–ä½¿å…¶å¯¹è½»å¾®åç§»æ•æ„Ÿã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œä½ç½®åç§»æ˜¯è¯„ä¼°è®°å¿†é£é™©çš„é‡è¦ç»´åº¦ï¼Œä¹‹å‰çš„ç ”ç©¶æœªèƒ½è€ƒè™‘è¿™ä¸€å› ç´ ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹åœ¨è®°å¿†è®­ç»ƒæ•°æ®æ—¶çš„é£é™©è¯„ä¼°é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•æœªè€ƒè™‘ä½ç½®åç§»çš„å½±å“ï¼Œå¯¼è‡´å¯¹è®°å¿†æœºåˆ¶çš„ç†è§£ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºä½ç½®è„†å¼±æ€§ç†è®ºï¼Œå¼ºè°ƒæ¨¡å‹å¯¹ä¸Šä¸‹æ–‡çª—å£ä¸­æœ€æ—©æ ‡è®°çš„ä¾èµ–ï¼ŒçŸ­å‰ç¼€æ›´å®¹æ˜“è§¦å‘é€å­—è®°å¿†ï¼Œåç§»ä¼šå¯¼è‡´æ˜¾è‘—çš„è®°å¿†ä¸‹é™ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é€šè¿‡å¯¹1Bã€3Bå’Œ8Bå‚æ•°çš„è¯­è¨€æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒï¼Œä½¿ç”¨83Bä¸ªæ ‡è®°ï¼Œç»“åˆç½‘ç»œè§„æ¨¡æ•°æ®ä¸å…¬å…±é¢†åŸŸä¹¦ç±ï¼Œæ¨¡æ‹Ÿç‰ˆæƒå†…å®¹ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œè®°å¿†é£é™©è¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºè¯†åˆ«å¹¶åˆ†æäº†åç§»æ•ˆåº”ï¼Œæå‡ºä½ç½®åç§»ä½œä¸ºè¯„ä¼°è®°å¿†é£é™©çš„æ–°ç»´åº¦ï¼ŒæŒ‘æˆ˜äº†ä¹‹å‰ç ”ç©¶çš„å‡è®¾ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œæ¨¡å‹çš„å‰ç¼€é•¿åº¦å’Œä¸Šä¸‹æ–‡çª—å£çš„è®¾ç½®æ˜¯å…³é”®å‚æ•°ï¼Œç ”ç©¶è¿˜æ¢è®¨äº†æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„å¯¹è®°å¿†æ•ˆæœçš„å½±å“ã€‚é€šè¿‡è°ƒæ•´è¿™äº›è®¾è®¡ï¼ŒæˆåŠŸæŠ‘åˆ¶äº†æ¨¡å‹çš„è®°å¿†é€€åŒ–ç°è±¡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè°ƒæ•´æ•æ„Ÿæ•°æ®åœ¨ä¸Šä¸‹æ–‡çª—å£ä¸­çš„ä½ç½®å¯ä»¥æ˜¾è‘—æŠ‘åˆ¶å¯æå–è®°å¿†å’Œæ–‡æœ¬é€€åŒ–ç°è±¡ã€‚å…·ä½“è€Œè¨€ï¼Œé€å­—è®°å¿†çš„å›å¿†ç‡åœ¨å‰ç¼€åç§»æ—¶ä¸‹é™è¶…è¿‡30%ï¼Œè€Œé€šè¿‡ä¼˜åŒ–å‰ç¼€é•¿åº¦å’Œä½ç½®ï¼Œæ¨¡å‹çš„ç”Ÿæˆè´¨é‡å¾—åˆ°äº†æœ‰æ•ˆæå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æ–‡æœ¬ç”Ÿæˆå’Œç‰ˆæƒä¿æŠ¤ç­‰ã€‚é€šè¿‡æ·±å…¥ç†è§£å¤§è¯­è¨€æ¨¡å‹çš„è®°å¿†æœºåˆ¶ï¼Œå¯ä»¥ä¸ºæ¨¡å‹è®¾è®¡å’Œè®­ç»ƒæä¾›æŒ‡å¯¼ï¼Œé™ä½ç‰ˆæƒé£é™©ï¼Œæå‡æ¨¡å‹çš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models are known to memorize parts of their training data, posing risk of copyright violations. To systematically examine this risk, we pretrain language models (1B/3B/8B) from scratch on 83B tokens, mixing web-scale data with public domain books used to simulate copyrighted content at controlled frequencies at lengths at least ten times longer than prior work. We thereby identified the offset effect, a phenomenon characterized by two key findings: (1) verbatim memorization is most strongly triggered by short prefixes drawn from the beginning of the context window, with memorization decreasing counterintuitively as prefix length increases; and (2) a sharp decline in verbatim recall when prefix begins offset from the initial tokens of the context window. We attribute this to positional fragility: models rely disproportionately on the earliest tokens in their context window as retrieval anchors, making them sensitive to even slight shifts. We further observe that when the model fails to retrieve memorized content, it often produces degenerated text. Leveraging these findings, we show that shifting sensitive data deeper into the context window suppresses both extractable memorization and degeneration. Our results suggest that positional offset is a critical and previously overlooked axis for evaluating memorization risks, since prior work implicitly assumed uniformity by probing only from the beginning of training sequences.

