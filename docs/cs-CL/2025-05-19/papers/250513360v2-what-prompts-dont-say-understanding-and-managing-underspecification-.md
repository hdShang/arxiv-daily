---
layout: default
title: What Prompts Don't Say: Understanding and Managing Underspecification in LLM Prompts
---

# What Prompts Don't Say: Understanding and Managing Underspecification in LLM Prompts

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.13360" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.13360v2</a>
  <a href="https://arxiv.org/pdf/2505.13360.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.13360v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.13360v2', 'What Prompts Don\'t Say: Understanding and Managing Underspecification in LLM Prompts')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chenyang Yang, Yike Shi, Qianou Ma, Michael Xieyang Liu, Christian KÃ¤stner, Tongshuang Wu

**åˆ†ç±»**: cs.CL, cs.SE

**å‘å¸ƒæ—¥æœŸ**: 2025-05-19 (æ›´æ–°: 2025-10-07)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºéœ€æ±‚æ„ŸçŸ¥çš„æç¤ºä¼˜åŒ–æœºåˆ¶ä»¥è§£å†³LLMæç¤ºä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æç¤ºä¼˜åŒ–` `éœ€æ±‚æ„ŸçŸ¥` `æ¨¡å‹ç¨³å®šæ€§` `æ€§èƒ½æå‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæç¤ºä¸è¶³æ˜¯ä¸LLMsäº¤äº’æ—¶çš„ä¸»è¦æŒ‘æˆ˜ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸ç¨³å®šå’Œåº”ç”¨æ„å»ºå›°éš¾ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæå‡ºéœ€æ±‚æ„ŸçŸ¥çš„æç¤ºä¼˜åŒ–æœºåˆ¶ï¼Œé€šè¿‡ä¸»åŠ¨å‘ç°å’Œç®¡ç†éœ€æ±‚æ¥æå‡æ¨¡å‹æ€§èƒ½ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šå®éªŒç»“æœæ˜¾ç¤ºï¼Œæå‡ºçš„æ–¹æ³•åœ¨åŸºå‡†æµ‹è¯•ä¸­å¹³å‡æå‡äº†4.8%çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æç¤ºä¸è¶³æ˜¯ä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰äº¤äº’æ—¶å¸¸è§çš„æŒ‘æˆ˜ã€‚æœ¬æ–‡æ·±å…¥åˆ†æäº†è¿™ä¸€é—®é¢˜ï¼Œæ˜¾ç¤ºè™½ç„¶LLMsé€šå¸¸èƒ½å¤Ÿé»˜è®¤æ¨æ–­æœªæŒ‡å®šçš„è¦æ±‚ï¼ˆ41.1%ï¼‰ï¼Œä½†è¿™ç§è¡Œä¸ºæ˜¯è„†å¼±çš„ï¼šä¸è¶³æŒ‡å®šçš„æç¤ºåœ¨æ¨¡å‹æˆ–æç¤ºå˜åŒ–æ—¶å›å½’çš„å¯èƒ½æ€§æ˜¯æ­£å¸¸æƒ…å†µçš„ä¸¤å€ï¼Œæœ‰æ—¶å‡†ç¡®ç‡ä¸‹é™è¶…è¿‡20%ã€‚è¿™ç§ä¸ç¨³å®šæ€§ä½¿å¾—æ„å»ºå¯é çš„LLMåº”ç”¨å˜å¾—å›°éš¾ã€‚æ­¤å¤–ï¼Œç®€å•åœ°æŒ‡å®šæ‰€æœ‰è¦æ±‚å¹¶ä¸æ€»æ˜¯æœ‰æ•ˆï¼Œå› ä¸ºæ¨¡å‹çš„æŒ‡ä»¤éµå¾ªèƒ½åŠ›æœ‰é™ä¸”è¦æ±‚å¯èƒ½ç›¸äº’å†²çªã€‚æ ‡å‡†çš„æç¤ºä¼˜åŒ–å™¨åŒæ ·æ•ˆæœä¸ä½³ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†éœ€æ±‚æ„ŸçŸ¥çš„æç¤ºä¼˜åŒ–æœºåˆ¶ï¼Œå¹³å‡æå‡æ€§èƒ½4.8%ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥å€¡å¯¼ç³»ç»ŸåŒ–çš„ä¸»åŠ¨éœ€æ±‚å‘ç°ã€è¯„ä¼°å’Œç›‘æ§è¿‡ç¨‹ï¼Œä»¥æ›´å¥½åœ°ç®¡ç†å®é™…ä¸­çš„æç¤ºä¸è¶³é—®é¢˜ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰äº¤äº’æ—¶çš„æç¤ºä¸è¶³é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†æœªæŒ‡å®šè¦æ±‚æ—¶è¡¨ç°å‡ºè„†å¼±æ€§ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸ç¨³å®šï¼Œä¸”ç®€å•çš„è¦æ±‚æŒ‡å®šå¹¶æœªæ˜¾è‘—æ”¹å–„ç»“æœã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§éœ€æ±‚æ„ŸçŸ¥çš„æç¤ºä¼˜åŒ–æœºåˆ¶ï¼Œæ—¨åœ¨é€šè¿‡ç³»ç»ŸåŒ–çš„éœ€æ±‚å‘ç°ä¸ç®¡ç†ï¼Œå¢å¼ºæ¨¡å‹å¯¹æç¤ºçš„ç†è§£å’Œå“åº”èƒ½åŠ›ï¼Œä»è€Œæé«˜æ•´ä½“æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬éœ€æ±‚å‘ç°ã€éœ€æ±‚è¯„ä¼°å’Œéœ€æ±‚ç›‘æ§ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡åˆ†ææç¤ºå†…å®¹è¯†åˆ«æ½œåœ¨éœ€æ±‚ï¼›å…¶æ¬¡ï¼Œè¯„ä¼°è¿™äº›éœ€æ±‚å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ï¼›æœ€åï¼ŒæŒç»­ç›‘æ§å’Œè°ƒæ•´æç¤ºä»¥é€‚åº”æ¨¡å‹çš„å˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥äº†éœ€æ±‚æ„ŸçŸ¥çš„ä¼˜åŒ–æœºåˆ¶ï¼ŒåŒºåˆ«äºä¼ ç»Ÿçš„æç¤ºä¼˜åŒ–æ–¹æ³•ï¼Œè¯¥æœºåˆ¶ä¸ä»…å…³æ³¨æç¤ºå†…å®¹æœ¬èº«ï¼Œè¿˜è€ƒè™‘äº†éœ€æ±‚çš„ç›¸äº’å…³ç³»å’Œæ¨¡å‹çš„æŒ‡ä»¤éµå¾ªèƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡ä¸åŒéœ€æ±‚çš„å½±å“ï¼Œå¹¶é€šè¿‡å®éªŒç¡®å®šäº†æœ€ä½³çš„å‚æ•°è®¾ç½®ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨å¤šå˜çš„æç¤ºç¯å¢ƒä¸­ä¿æŒç¨³å®šæ€§å’Œé«˜æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„éœ€æ±‚æ„ŸçŸ¥æç¤ºä¼˜åŒ–æœºåˆ¶åœ¨åŸºå‡†æµ‹è¯•ä¸­å¹³å‡æå‡äº†4.8%çš„æ€§èƒ½ï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•ï¼Œæ˜¾è‘—æé«˜äº†æ¨¡å‹åœ¨å¤„ç†ä¸è¶³æç¤ºæ—¶çš„ç¨³å®šæ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å®¢æœã€å†…å®¹ç”Ÿæˆã€æ•™è‚²è¾…å¯¼ç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿå¸®åŠ©å¼€å‘è€…æ›´æœ‰æ•ˆåœ°åˆ©ç”¨LLMsï¼Œæå‡ç”¨æˆ·ä½“éªŒå’Œåº”ç”¨çš„å¯é æ€§ã€‚æœªæ¥ï¼Œéšç€éœ€æ±‚æ„ŸçŸ¥æœºåˆ¶çš„æ¨å¹¿ï¼ŒLLMsçš„åº”ç”¨èŒƒå›´å’Œæ•ˆæœå°†è¿›ä¸€æ­¥æ‰©å±•ï¼Œæ¨åŠ¨æ™ºèƒ½äº¤äº’æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Prompt underspecification is a common challenge when interacting with LLMs. In this paper, we present an in-depth analysis of this problem, showing that while LLMs can often infer unspecified requirements by default (41.1%), such behavior is fragile: Under-specified prompts are 2x as likely to regress across model or prompt changes, sometimes with accuracy drops exceeding 20%. This instability makes it difficult to reliably build LLM applications. Moreover, simply specifying all requirements does not consistently help, as models have limited instruction-following ability and requirements can conflict. Standard prompt optimizers likewise provide little benefit. To address these issues, we propose requirements-aware prompt optimization mechanisms that improve performance by 4.8% on average over baselines. We further advocate for a systematic process of proactive requirements discovery, evaluation, and monitoring to better manage prompt underspecification in practice.

