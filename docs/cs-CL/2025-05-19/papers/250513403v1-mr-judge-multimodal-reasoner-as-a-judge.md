---
layout: default
title: "MR. Judge: Multimodal Reasoner as a Judge"
---

# MR. Judge: Multimodal Reasoner as a Judge

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.13403" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.13403v1</a>
  <a href="https://arxiv.org/pdf/2505.13403.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.13403v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.13403v1', 'MR. Judge: Multimodal Reasoner as a Judge')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Renjie Pi, Felix Bai, Qibin Chen, Simon Wang, Jiulong Shan, Kieran Liu, Meng Cao

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-19

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMR. Judgeä»¥æå‡å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹çš„è¯„åˆ¤èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ¨ç†` `è¯­è¨€æ¨¡å‹` `è¯„åˆ¤æœºåˆ¶` `è‡ªåŠ¨æ³¨é‡Š` `æ¨ç†èƒ½åŠ›`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨è¯„åˆ¤å“åº”æ—¶ç¼ºä¹æœ‰æ•ˆçš„æ¨ç†æœºåˆ¶ï¼Œå¯¼è‡´è¯„åˆ¤ç»“æœçš„å¯è§£é‡Šæ€§å’Œå‡†ç¡®æ€§ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºçš„MR. Judgeé€šè¿‡å°†è¯„åˆ¤è¿‡ç¨‹è§†ä¸ºæ¨ç†é©±åŠ¨çš„å¤šé€‰é—®é¢˜ï¼Œå¢å¼ºäº†MLLMçš„æ¨ç†èƒ½åŠ›å’Œè¯„åˆ¤æ•ˆæœã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMR. Judge-7Båœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶åœ¨VL-RewardBenchä¸Šè¶…è¶Šäº†GPT-4oï¼Œæå‡å¹…åº¦æ˜¾è‘—ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ä½œä¸ºè¯„åˆ¤è€…çš„èŒƒå¼é€æ¸æˆç†Ÿï¼Œæœ¬æ–‡æå‡ºäº†å¤šæ¨¡æ€æ¨ç†è€…ä½œä¸ºè¯„åˆ¤è€…ï¼ˆMR. Judgeï¼‰ï¼Œæ—¨åœ¨èµ‹äºˆé€šç”¨MLLMsæ›´å¼ºçš„æ¨ç†èƒ½åŠ›ã€‚ä¸ç›´æ¥ä¸ºæ¯ä¸ªå“åº”æ‰“åˆ†ä¸åŒï¼Œæˆ‘ä»¬å°†è¯„åˆ¤è¿‡ç¨‹æ„å»ºä¸ºä¸€ç§åŸºäºæ¨ç†çš„å¤šé€‰é—®é¢˜ã€‚è¯„åˆ¤æ¨¡å‹é¦–å…ˆè¿›è¡Œå…¨é¢çš„æ¨ç†ï¼Œæ¶µç›–å“åº”çš„ä¸åŒæ–¹é¢ï¼Œæœ€ç»ˆé€‰æ‹©æœ€ä½³å“åº”ã€‚è¿™ä¸€æ¨ç†è¿‡ç¨‹ä¸ä»…æé«˜äº†è¯„åˆ¤çš„å¯è§£é‡Šæ€§ï¼Œè¿˜æ˜¾è‘—å¢å¼ºäº†MLLMè¯„åˆ¤è€…çš„æ€§èƒ½ã€‚ä¸ºäº†è§£å†³ç¼ºä¹å¸¦è¯„åˆ†å“åº”çš„é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†è‡ªåŠ¨æ³¨é‡Šç­–ç•¥ï¼ŒåŒ…æ‹¬åå‘å“åº”å€™é€‰åˆæˆå’ŒåŸºäºæ–‡æœ¬çš„æ¨ç†æå–ã€‚å®éªŒè¡¨æ˜ï¼ŒMR. Judgeåœ¨å¤šé¡¹ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼ŒMR. Judge-7Båœ¨VL-RewardBenchä¸Šè¶…è¶ŠGPT-4o 9.9%ï¼Œåœ¨æ¨ç†æ—¶é—´æ‰©å±•ä¸­æå‡MM-Vetæ€§èƒ½è¾¾7.7%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹åœ¨è¯„åˆ¤å“åº”æ—¶ç¼ºä¹æœ‰æ•ˆæ¨ç†èƒ½åŠ›çš„é—®é¢˜ï¼Œå¯¼è‡´è¯„åˆ¤ç»“æœçš„å¯è§£é‡Šæ€§å’Œå‡†ç¡®æ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMR. Judgeé€šè¿‡å°†è¯„åˆ¤è¿‡ç¨‹è½¬åŒ–ä¸ºæ¨ç†é©±åŠ¨çš„å¤šé€‰é—®é¢˜ï¼Œä½¿æ¨¡å‹åœ¨è¯„åˆ¤æ—¶èƒ½å¤Ÿè¿›è¡Œå…¨é¢çš„æ¨ç†ï¼Œæœ€ç»ˆé€‰æ‹©æœ€ä½³å“åº”ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨æé«˜è¯„åˆ¤çš„å¯è§£é‡Šæ€§å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMR. Judgeçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šåå‘å“åº”å€™é€‰åˆæˆå’ŒåŸºäºæ–‡æœ¬çš„æ¨ç†æå–ã€‚åå‘åˆæˆæ¨¡å—ä»ç›‘ç£å¾®è°ƒæ•°æ®é›†ä¸­ç”Ÿæˆè´Ÿé¢å€™é€‰å“åº”ï¼Œè€Œæ¨ç†æå–æ¨¡å—åˆ™é€šè¿‡æ•°æ®åˆæˆç®¡é“æå–æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå°†è¯„åˆ¤è¿‡ç¨‹è§†ä¸ºæ¨ç†é—®é¢˜ï¼Œåˆ©ç”¨å¤šæ¨¡æ€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›è¿›è¡Œå“åº”é€‰æ‹©ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„ç›´æ¥è¯„åˆ†æ–¹å¼æœ¬è´¨ä¸Šä¸åŒï¼Œå¼ºè°ƒäº†æ¨ç†è¿‡ç¨‹çš„é‡è¦æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å…³é”®è®¾è®¡æ–¹é¢ï¼Œæ¨¡å‹é‡‡ç”¨äº†ç²¾å¿ƒè®¾è®¡çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ï¼Œä»¥ç¡®ä¿æ¨ç†èƒ½åŠ›çš„æœ‰æ•ˆæå–å’Œåº”ç”¨ï¼ŒåŒæ—¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¿›è¡Œäº†é€‚å½“çš„è¶…å‚æ•°è°ƒæ•´ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMR. Judge-7Båœ¨VL-RewardBenchä¸Šè¶…è¶Šäº†GPT-4o 9.9%ï¼Œå¹¶åœ¨æ¨ç†æ—¶é—´æ‰©å±•ä¸­æå‡MM-Vetæ€§èƒ½è¾¾7.7%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒMR. Judgeåœ¨å¤šé¡¹ä»»åŠ¡ä¸­å‡è¡¨ç°å‡ºè‰²ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MR. Judgeçš„ç ”ç©¶æˆæœå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶åœ¨éœ€è¦é«˜è´¨é‡è¯„åˆ¤å’Œåé¦ˆçš„é¢†åŸŸï¼Œå¦‚æ•™è‚²ã€å†…å®¹å®¡æ ¸å’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æå‡å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿä¸ºç”¨æˆ·æä¾›æ›´å‡†ç¡®å’Œå¯è§£é‡Šçš„è¯„åˆ¤ç»“æœï¼Œè¿›è€Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„æ™ºèƒ½åŒ–å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The paradigm of using Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) as evaluative judges has emerged as an effective approach in RLHF and inference-time scaling. In this work, we propose Multimodal Reasoner as a Judge (MR. Judge), a paradigm for empowering general-purpose MLLMs judges with strong reasoning capabilities. Instead of directly assigning scores for each response, we formulate the judgement process as a reasoning-inspired multiple-choice problem. Specifically, the judge model first conducts deliberate reasoning covering different aspects of the responses and eventually selects the best response from them. This reasoning process not only improves the interpretibility of the judgement, but also greatly enhances the performance of MLLM judges. To cope with the lack of questions with scored responses, we propose the following strategy to achieve automatic annotation: 1) Reverse Response Candidates Synthesis: starting from a supervised fine-tuning (SFT) dataset, we treat the original response as the best candidate and prompt the MLLM to generate plausible but flawed negative candidates. 2) Text-based reasoning extraction: we carefully design a data synthesis pipeline for distilling the reasoning capability from a text-based reasoning model, which is adopted to enable the MLLM judges to regain complex reasoning ability via warm up supervised fine-tuning. Experiments demonstrate that our MR. Judge is effective across a wide range of tasks. Specifically, our MR. Judge-7B surpasses GPT-4o by 9.9% on VL-RewardBench, and improves performance on MM-Vet during inference-time scaling by up to 7.7%.

