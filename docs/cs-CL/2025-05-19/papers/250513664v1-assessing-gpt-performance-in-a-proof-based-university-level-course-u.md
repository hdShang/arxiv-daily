---
layout: default
title: Assessing GPT Performance in a Proof-Based University-Level Course Under Blind Grading
---

# Assessing GPT Performance in a Proof-Based University-Level Course Under Blind Grading

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.13664" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.13664v1</a>
  <a href="https://arxiv.org/pdf/2505.13664.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.13664v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.13664v1', 'Assessing GPT Performance in a Proof-Based University-Level Course Under Blind Grading')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ming Ding, Rasmus Kyng, Federico Solda, Weixuan Yuan

**åˆ†ç±»**: cs.CY, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-19

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°GPTåœ¨ç›²è¯„å¤§å­¦ç®—æ³•è¯¾ç¨‹ä¸­çš„è¡¨ç°**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ•™è‚²è¯„ä¼°` `ç›²è¯„æœºåˆ¶` `æ¨ç†è´¨é‡` `ç®—æ³•è¯¾ç¨‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é«˜ç­‰æ•™è‚²ä¸­çš„åº”ç”¨å°šæœªå¾—åˆ°å……åˆ†éªŒè¯ï¼Œå°¤å…¶æ˜¯åœ¨è‡ªç”±å›ç­”é—®é¢˜çš„åœºæ™¯ä¸­ã€‚
2. æœ¬ç ”ç©¶é€šè¿‡åœ¨çœŸå®çš„æœ¬ç§‘ç®—æ³•è¯¾ç¨‹ä¸­è¯„ä¼°GPT-4oå’Œo1-previewçš„è¡¨ç°ï¼Œæ¢è®¨å…¶åœ¨æ•™è‚²ä¸­çš„é€‚ç”¨æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œo1-previewåœ¨æŸäº›ç»ƒä¹ ä¸­è¶…è¶Šäº†å­¦ç”Ÿä¸­ä½æ•°ï¼Œè€ŒGPT-4oåˆ™æœªèƒ½è¾¾åˆ°åŠæ ¼æ ‡å‡†ï¼ŒäºŒè€…å‡å­˜åœ¨æ¨ç†è´¨é‡é—®é¢˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å‘å±•ï¼Œå®ƒä»¬åœ¨é«˜ç­‰æ•™è‚²ä¸­çš„è§’è‰²ï¼Œå°¤å…¶æ˜¯åœ¨è‡ªç”±å›ç­”é—®é¢˜çš„è§£å†³èƒ½åŠ›ä¸Šï¼Œéœ€è¦ä»”ç»†å®¡è§†ã€‚æœ¬ç ”ç©¶è¯„ä¼°äº†GPT-4oå’Œo1-previewåœ¨æœ¬ç§‘ç®—æ³•è¯¾ç¨‹ä¸­åœ¨çœŸå®æ•™è‚²æ¡ä»¶ä¸‹çš„è¡¨ç°ã€‚åŒ¿åçš„GPTç”Ÿæˆçš„å®¶åº­ä½œä¸šè§£å†³æ–¹æ¡ˆç”±ä¸çŸ¥å…¶æ¥æºçš„åŠ©æ•™è¿›è¡Œè¯„åˆ†ã€‚æˆ‘ä»¬çš„åˆ†æè€ƒå¯Ÿäº†ç²—ç²’åº¦è¡¨ç°ï¼ˆåˆ†æ•°ï¼‰å’Œç»†ç²’åº¦æ¨ç†è´¨é‡ï¼ˆé”™è¯¯æ¨¡å¼ï¼‰ã€‚ç»“æœæ˜¾ç¤ºï¼ŒGPT-4oå§‹ç»ˆè¡¨ç°ä¸ä½³ï¼Œæœªèƒ½è¾¾åˆ°åŠæ ¼çº¿ï¼Œè€Œo1-previewè¡¨ç°æ˜¾è‘—æ›´å¥½ï¼ŒæŸäº›ç»ƒä¹ ç”šè‡³è¶…è¿‡äº†å­¦ç”Ÿçš„ä¸­ä½æ•°ã€‚ç„¶è€Œï¼Œä¸¤ç§æ¨¡å‹å‡å­˜åœ¨ä¸å½“ä¸»å¼ å’Œè¯¯å¯¼æ€§è®ºè¯çš„é—®é¢˜ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†æ•™è‚²ä¸­éœ€è¦å¼ºæœ‰åŠ›çš„è¯„ä¼°ç­–ç•¥å’ŒAIæ„è¯†çš„è¯„åˆ†æ”¿ç­–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤§å­¦ç®—æ³•è¯¾ç¨‹ä¸­çš„è¡¨ç°ï¼Œå°¤å…¶æ˜¯åœ¨ç›²è¯„ç¯å¢ƒä¸‹çš„çœŸå®åº”ç”¨ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†æ¢è®¨è¿™äº›æ¨¡å‹åœ¨æ•™è‚²åœºæ™¯ä¸­çš„å®é™…æ•ˆæœå’Œé—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¯¹GPT-4oå’Œo1-previewç”Ÿæˆçš„è§£å†³æ–¹æ¡ˆè¿›è¡Œç›²è¯„ï¼Œåˆ†æå…¶åœ¨è¯„åˆ†å’Œæ¨ç†è´¨é‡ä¸Šçš„è¡¨ç°ï¼Œä»¥æ­ç¤ºå…¶åœ¨æ•™è‚²ä¸­çš„æ½œåœ¨åº”ç”¨å’Œå±€é™æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶è®¾è®¡åŒ…æ‹¬ç”ŸæˆåŒ¿åçš„GPTè§£å†³æ–¹æ¡ˆï¼Œéšåç”±ä¸çŸ¥å…¶æ¥æºçš„åŠ©æ•™è¿›è¡Œè¯„åˆ†ã€‚åˆ†æåˆ†ä¸ºç²—ç²’åº¦ï¼ˆåˆ†æ•°ï¼‰å’Œç»†ç²’åº¦ï¼ˆé”™è¯¯æ¨¡å¼ï¼‰ä¸¤ä¸ªå±‚é¢ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶é¦–æ¬¡åœ¨çœŸå®æ•™è‚²ç¯å¢ƒä¸­è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹çš„è¡¨ç°ï¼Œå¼ºè°ƒäº†ç›²è¯„æœºåˆ¶åœ¨æ•™è‚²è¯„ä¼°ä¸­çš„é‡è¦æ€§ï¼Œå¹¶æ­ç¤ºäº†æ¨¡å‹åœ¨æ¨ç†è´¨é‡ä¸Šçš„ä¸è¶³ã€‚

**å…³é”®è®¾è®¡**ï¼šç ”ç©¶ä¸­é‡‡ç”¨äº†æ ‡å‡†åŒ–çš„è¯„åˆ†ç³»ç»Ÿï¼ŒåŠ©æ•™åœ¨è¯„åˆ†æ—¶ä¸çŸ¥æƒ…ï¼Œä»¥ç¡®ä¿è¯„ä¼°çš„å…¬æ­£æ€§ã€‚åŒæ—¶ï¼Œåˆ†æäº†æ¨¡å‹ç”Ÿæˆçš„é”™è¯¯ç±»å‹ï¼Œä»¥è¯†åˆ«å…¶æ¨ç†è¿‡ç¨‹ä¸­çš„å¸¸è§é—®é¢˜ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œo1-previewåœ¨æŸäº›ç»ƒä¹ ä¸­è¶…è¶Šäº†å­¦ç”Ÿçš„ä¸­ä½æ•°ï¼Œè¡¨ç°æ˜¾è‘—ä¼˜äºGPT-4oï¼Œåè€…æœªèƒ½è¾¾åˆ°åŠæ ¼æ ‡å‡†ã€‚ä¸¤ç§æ¨¡å‹å‡å­˜åœ¨ä¸å½“ä¸»å¼ å’Œè¯¯å¯¼æ€§è®ºè¯çš„é—®é¢˜ï¼Œå¼ºè°ƒäº†æ•™è‚²ä¸­å¯¹AIè¯„ä¼°ç­–ç•¥çš„éœ€æ±‚ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„ç»“æœå¯¹æ•™è‚²é¢†åŸŸå…·æœ‰é‡è¦çš„åº”ç”¨ä»·å€¼ï¼Œå°¤å…¶æ˜¯åœ¨è¯„ä¼°å’Œä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹æ—¶ã€‚é€šè¿‡äº†è§£æ¨¡å‹çš„è¡¨ç°å’Œå±€é™æ€§ï¼Œæ•™è‚²å·¥ä½œè€…å¯ä»¥æ›´å¥½åœ°è®¾è®¡è¯¾ç¨‹å’Œè¯„ä¼°ç­–ç•¥ï¼Œä»¥é€‚åº”AIæŠ€æœ¯çš„å¿«é€Ÿå‘å±•ã€‚æœªæ¥ï¼Œç ”ç©¶ç»“æœå¯èƒ½æ¨åŠ¨AIåœ¨æ•™è‚²ä¸­çš„æ›´å¹¿æ³›åº”ç”¨ï¼Œä¿ƒè¿›ä¸ªæ€§åŒ–å­¦ä¹ å’Œæ™ºèƒ½è¾…å¯¼ç³»ç»Ÿçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> As large language models (LLMs) advance, their role in higher education, particularly in free-response problem-solving, requires careful examination. This study assesses the performance of GPT-4o and o1-preview under realistic educational conditions in an undergraduate algorithms course. Anonymous GPT-generated solutions to take-home exams were graded by teaching assistants unaware of their origin. Our analysis examines both coarse-grained performance (scores) and fine-grained reasoning quality (error patterns). Results show that GPT-4o consistently struggles, failing to reach the passing threshold, while o1-preview performs significantly better, surpassing the passing score and even exceeding the student median in certain exercises. However, both models exhibit issues with unjustified claims and misleading arguments. These findings highlight the need for robust assessment strategies and AI-aware grading policies in education.

