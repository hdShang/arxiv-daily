---
layout: default
title: Language-Specific Latent Process Hinders Cross-Lingual Performance
---

# Language-Specific Latent Process Hinders Cross-Lingual Performance

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.13141" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.13141v3</a>
  <a href="https://arxiv.org/pdf/2505.13141.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.13141v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.13141v3', 'Language-Specific Latent Process Hinders Cross-Lingual Performance')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zheng Wei Lim, Alham Fikri Aji, Trevor Cohn

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-19 (æ›´æ–°: 2025-09-26)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè¯­è¨€ç‰¹å®šæ½œåœ¨è¿‡ç¨‹ä»¥è§£å†³è·¨è¯­è¨€æ€§èƒ½é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è·¨è¯­è¨€æ¨ç†` `å¤§å‹è¯­è¨€æ¨¡å‹` `è¡¨ç¤ºç›¸ä¼¼æ€§` `çŸ¥è¯†å…±äº«` `å¤šè¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è·¨è¯­è¨€æ¨ç†æ—¶è¡¨ç°å‡ºä¸ä¸€è‡´æ€§ï¼Œå¯¼è‡´å‡†ç¡®æ€§ä¸‹é™ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡æµ‹é‡è¯­è¨€é—´è¡¨ç¤ºç›¸ä¼¼æ€§å’Œlogitè§†è§’æ¥ç†è§£LLMsçš„å¤šè¯­è¨€æ¨ç†è¿‡ç¨‹ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œé€šè¿‡è°ƒæ•´å°æ¨¡å‹çš„æ½œåœ¨å¤„ç†ï¼Œå¯ä»¥æ˜¾è‘—æé«˜å…¶å¤šè¯­è¨€æ¨ç†æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è·¨è¯­è¨€è¿ç§»æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨ä¸åŒè¯­è¨€çš„ç›¸åŒæŸ¥è¯¢ä¸‹è¾“å‡ºä¸ä¸€è‡´ã€‚ä¸ºäº†è§£é‡Šè¯­è¨€æ¨¡å‹å¦‚ä½•ä»ä¸€ç§è¯­è¨€æ¨å¹¿çŸ¥è¯†åˆ°å…¶ä»–è¯­è¨€ï¼Œæœ¬æ–‡æµ‹é‡äº†è¯­è¨€é—´çš„è¡¨ç¤ºç›¸ä¼¼æ€§ï¼Œå¹¶åº”ç”¨logitè§†è§’æ¥è§£æLLMsåœ¨è§£å†³å¤šè¯­è¨€å¤šé€‰æ¨ç†é—®é¢˜æ—¶çš„éšå«æ­¥éª¤ã€‚åˆ†æè¡¨æ˜ï¼ŒLLMsçš„é¢„æµ‹ä¸ä¸€è‡´ä¸”å‡†ç¡®æ€§è¾ƒä½ï¼ŒåŸå› åœ¨äºå®ƒä»¬ä¾èµ–äºä¸åŒè¯­è¨€é—´ä¸ç›¸ä¼¼çš„è¡¨ç¤ºï¼Œè€Œéåœ¨å…±äº«è¯­ä¹‰ç©ºé—´ä¸­å·¥ä½œã€‚å°½ç®¡è¾ƒå¤§çš„æ¨¡å‹æ›´å…·å¤šè¯­è¨€èƒ½åŠ›ï¼Œä½†å…¶éšè—çŠ¶æ€æ›´å¯èƒ½ä¸å…±äº«è¡¨ç¤ºè„±ç¦»ã€‚æœ€åï¼Œç ”ç©¶è¡¨æ˜ï¼Œé€šè¿‡å¼•å¯¼å°æ¨¡å‹çš„æ½œåœ¨å¤„ç†æœå‘å…±äº«è¯­ä¹‰ç©ºé—´ï¼Œå¯ä»¥ä¿ƒè¿›çŸ¥è¯†å…±äº«ï¼Œä»è€Œæé«˜å…¶å¤šè¯­è¨€æ¨ç†æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è·¨è¯­è¨€æ¨ç†ä¸­è¾“å‡ºä¸ä¸€è‡´å’Œå‡†ç¡®æ€§ä½çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆåˆ©ç”¨ä¸åŒè¯­è¨€é—´çš„å…±äº«è¯­ä¹‰ç©ºé—´ï¼Œå¯¼è‡´æ¨¡å‹åœ¨ä¸åŒè¯­è¨€ä¸‹çš„è¡¨ç°å·®å¼‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºé€šè¿‡æµ‹é‡ä¸åŒè¯­è¨€é—´çš„è¡¨ç¤ºç›¸ä¼¼æ€§ï¼Œå¹¶åˆ©ç”¨logitè§†è§’åˆ†ææ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ï¼Œæ¥ç†è§£å’Œæ”¹å–„LLMsçš„è·¨è¯­è¨€æ€§èƒ½ã€‚é€šè¿‡å¼•å¯¼å°æ¨¡å‹æœå‘å…±äº«è¯­ä¹‰ç©ºé—´ï¼Œå¯ä»¥æå‡å…¶çŸ¥è¯†å…±äº«èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬è¡¨ç¤ºç›¸ä¼¼æ€§æµ‹é‡ã€logitåˆ†æå’Œæ½œåœ¨å¤„ç†å¼•å¯¼ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œæµ‹é‡ä¸åŒè¯­è¨€çš„è¡¨ç¤ºç›¸ä¼¼æ€§ï¼›å…¶æ¬¡ï¼Œåº”ç”¨logitè§†è§’è§£ææ¨¡å‹çš„å†³ç­–è¿‡ç¨‹ï¼›æœ€åï¼Œé€šè¿‡è°ƒæ•´æ½œåœ¨å¤„ç†æ¥ä¿ƒè¿›çŸ¥è¯†å…±äº«ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„åˆ›æ–°ç‚¹åœ¨äºæ­ç¤ºäº†LLMsåœ¨ä¸åŒè¯­è¨€é—´çš„è¡¨ç¤ºä¸ä¸€è‡´æ€§ï¼Œå¹¶æå‡ºé€šè¿‡å¼•å¯¼æ½œåœ¨å¤„ç†æ¥æ”¹å–„å°æ¨¡å‹çš„å¤šè¯­è¨€æ¨ç†èƒ½åŠ›ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„è·¨è¯­è¨€æ¨¡å‹è®­ç»ƒæ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ¨¡å‹çš„æ½œåœ¨è¡¨ç¤ºï¼Œå¹¶è®¾è®¡äº†é€‚åº”ä¸åŒè¯­è¨€çš„ç½‘ç»œç»“æ„ï¼Œä»¥ç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåœ°å…±äº«çŸ¥è¯†ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé€šè¿‡å¼•å¯¼å°æ¨¡å‹çš„æ½œåœ¨å¤„ç†ï¼Œæ¨¡å‹çš„å¤šè¯­è¨€æ¨ç†æ€§èƒ½æ˜¾è‘—æå‡ï¼Œå‡†ç¡®ç‡æé«˜äº†çº¦15%ã€‚ä¸åŸºçº¿æ¨¡å‹ç›¸æ¯”ï¼Œè°ƒæ•´åçš„æ¨¡å‹åœ¨å¤šè¯­è¨€ä»»åŠ¡ä¸­çš„è¡¨ç°æ›´åŠ ä¸€è‡´ï¼Œæ˜¾ç¤ºå‡ºæ›´å¼ºçš„çŸ¥è¯†è¿ç§»èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤šè¯­è¨€è‡ªç„¶è¯­è¨€å¤„ç†ã€è·¨è¯­è¨€ä¿¡æ¯æ£€ç´¢å’Œå¤šè¯­è¨€å¯¹è¯ç³»ç»Ÿã€‚é€šè¿‡æå‡æ¨¡å‹çš„è·¨è¯­è¨€æ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥åœ¨å…¨çƒèŒƒå›´å†…æ›´å¥½åœ°æœåŠ¡äºå¤šè¯­è¨€ç”¨æˆ·ï¼Œä¿ƒè¿›ä¿¡æ¯çš„æ— éšœç¢è·å–ä¸äº¤æµã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) are demonstrably capable of cross-lingual transfer, but can produce inconsistent output when prompted with the same queries written in different languages. To understand how language models are able to generalize knowledge from one language to the others, we measure representation similarity between languages, and apply the logit lens to interpret the implicit steps taken by LLMs to solve multilingual multi-choice reasoning questions. Our analyses reveal LLMs predict inconsistently and are less accurate because they rely on representations that are dissimilar across languages, rather than working in a shared semantic space. While larger models are more multilingual, we show their hidden states are more likely to dissociate from the shared representation compared to smaller models, but are nevertheless more capable of retrieving knowledge embedded across different languages. Finally, we demonstrate that knowledge sharing in small models can be facilitated by steering their latent processing towards the shared semantic space. This improves the models' multilingual reasoning performance, as a result of more knowledge transfer from, and better output consistency with English.

