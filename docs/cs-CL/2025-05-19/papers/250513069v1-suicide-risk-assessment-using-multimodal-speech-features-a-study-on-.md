---
layout: default
title: "Suicide Risk Assessment Using Multimodal Speech Features: A Study on the SW1 Challenge Dataset"
---

# Suicide Risk Assessment Using Multimodal Speech Features: A Study on the SW1 Challenge Dataset

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.13069" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.13069v1</a>
  <a href="https://arxiv.org/pdf/2505.13069.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.13069v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.13069v1', 'Suicide Risk Assessment Using Multimodal Speech Features: A Study on the SW1 Challenge Dataset')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ambre Marie, Ilias Maoudj, Guillaume Dardenne, GwenolÃ© Quellec

**åˆ†ç±»**: cs.CL, cs.LG, cs.SD, eess.AS

**å‘å¸ƒæ—¥æœŸ**: 2025-05-19

**å¤‡æ³¨**: Submitted to the SpeechWellness Challenge at Interspeech 2025; 5 pages, 2 figures, 2 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šæ¨¡æ€è¯­éŸ³ç‰¹å¾è¯„ä¼°é’å°‘å¹´è‡ªæ€é£é™©çš„æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è‡ªæ€é£é™©è¯„ä¼°` `å¤šæ¨¡æ€èåˆ` `è¯­éŸ³ç‰¹å¾` `å¿ƒç†å¥åº·` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨é’å°‘å¹´è‡ªæ€é£é™©è¯„ä¼°ä¸­ç¼ºä¹æœ‰æ•ˆçš„å¤šæ¨¡æ€èåˆç­–ç•¥ï¼Œå¯¼è‡´åˆ†ç±»å‡†ç¡®ç‡ä¸è¶³ã€‚
2. æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ç»“åˆè‡ªåŠ¨è½¬å½•ã€è¯­è¨€å’ŒéŸ³é¢‘åµŒå…¥çš„å¤šæ¨¡æ€æ–¹æ³•ï¼Œæ¢ç´¢ä¸åŒçš„èåˆç­–ç•¥ä»¥æé«˜è¯„ä¼°æ•ˆæœã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŠ æƒæ³¨æ„åŠ›ç­–ç•¥åœ¨å¼€å‘é›†ä¸Šå®ç°äº†69%çš„å‡†ç¡®ç‡ï¼Œä½†å¼€å‘ä¸æµ‹è¯•é›†ä¹‹é—´çš„æ€§èƒ½å·®è·ä»éœ€å…³æ³¨ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶é’ˆå¯¹ç¬¬ä¸€ä¸ªSpeechWellnessæŒ‘æˆ˜ï¼Œæ¢è®¨äº†åŸºäºè¯­éŸ³çš„é’å°‘å¹´è‡ªæ€é£é™©è¯„ä¼°çš„éœ€æ±‚ã€‚ç ”ç©¶é‡‡ç”¨å¤šæ¨¡æ€æ–¹æ³•ï¼Œç»“åˆäº†WhisperXçš„è‡ªåŠ¨è½¬å½•ã€ä¸­æ–‡RoBERTaçš„è¯­è¨€åµŒå…¥å’ŒWavLMçš„éŸ³é¢‘åµŒå…¥ã€‚æ­¤å¤–ï¼Œè¿˜èå…¥äº†æ‰‹å·¥æå–çš„å£°å­¦ç‰¹å¾ï¼Œå¦‚MFCCã€è°±å¯¹æ¯”å’ŒéŸ³é«˜ç›¸å…³ç»Ÿè®¡æ•°æ®ã€‚ç ”ç©¶æ¢ç´¢äº†ä¸‰ç§èåˆç­–ç•¥ï¼šæ—©æœŸè¿æ¥ã€ç‰¹å®šæ¨¡æ€å¤„ç†å’Œå¸¦æœ‰mixupæ­£åˆ™åŒ–çš„åŠ æƒæ³¨æ„åŠ›ã€‚ç»“æœè¡¨æ˜ï¼ŒåŠ æƒæ³¨æ„åŠ›åœ¨å¼€å‘é›†ä¸Šè¾¾åˆ°äº†69%çš„å‡†ç¡®ç‡ï¼Œä½†å¼€å‘é›†ä¸æµ‹è¯•é›†ä¹‹é—´çš„æ€§èƒ½å·®è·çªæ˜¾äº†æ³›åŒ–æŒ‘æˆ˜ã€‚ç ”ç©¶å¼ºè°ƒäº†ä¼˜åŒ–åµŒå…¥è¡¨ç¤ºå’Œèåˆæœºåˆ¶ä»¥æé«˜åˆ†ç±»å¯é æ€§çš„é‡è¦æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³é’å°‘å¹´è‡ªæ€é£é™©è¯„ä¼°ä¸­çš„å¤šæ¨¡æ€æ•°æ®èåˆé—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†ä¸åŒæ¨¡æ€ä¿¡æ¯æ—¶å­˜åœ¨å‡†ç¡®æ€§ä¸è¶³å’Œæ³›åŒ–èƒ½åŠ›å·®çš„ç—›ç‚¹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šç ”ç©¶é€šè¿‡æ•´åˆè‡ªåŠ¨è½¬å½•ã€è¯­è¨€åµŒå…¥å’ŒéŸ³é¢‘åµŒå…¥ï¼Œé‡‡ç”¨å¤šæ¨¡æ€èåˆç­–ç•¥ï¼Œä»¥æœŸæé«˜è‡ªæ€é£é™©è¯„ä¼°çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€ç‰¹å¾æå–ã€æ¨¡æ€èåˆå’Œåˆ†ç±»å››ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œä½¿ç”¨WhisperXè¿›è¡Œè¯­éŸ³è½¬å½•ï¼Œæ¥ç€æå–è¯­è¨€å’ŒéŸ³é¢‘ç‰¹å¾ï¼Œæœ€åé€šè¿‡ä¸åŒçš„èåˆç­–ç•¥è¿›è¡Œåˆ†ç±»ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæå‡ºäº†åŠ æƒæ³¨æ„åŠ›æœºåˆ¶ä¸mixupæ­£åˆ™åŒ–çš„ç»“åˆï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œä¸ä¼ ç»Ÿçš„ç®€å•è¿æ¥æˆ–å•ä¸€æ¨¡æ€å¤„ç†æ–¹æ³•ç›¸æ¯”ï¼Œè¡¨ç°å‡ºæ›´ä¼˜çš„æ•ˆæœã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å¤šç§å£°å­¦ç‰¹å¾ï¼ˆå¦‚MFCCã€è°±å¯¹æ¯”ï¼‰ä¸æ·±åº¦å­¦ä¹ åµŒå…¥ç›¸ç»“åˆçš„æ–¹å¼ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸Šè€ƒè™‘äº†å¤šæ¨¡æ€ç‰¹å¾çš„å¹³è¡¡ï¼Œç¡®ä¿äº†æ¨¡å‹åœ¨ä¸åŒæ¨¡æ€é—´çš„æœ‰æ•ˆå­¦ä¹ ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œé‡‡ç”¨åŠ æƒæ³¨æ„åŠ›ç­–ç•¥çš„æ¨¡å‹åœ¨å¼€å‘é›†ä¸Šè¾¾åˆ°äº†69%çš„å‡†ç¡®ç‡ï¼Œæ˜æ˜¾ä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚åŒæ—¶ï¼Œç ”ç©¶æŒ‡å‡ºå¼€å‘é›†ä¸æµ‹è¯•é›†ä¹‹é—´å­˜åœ¨æ€§èƒ½å·®è·ï¼Œæç¤ºæœªæ¥éœ€è¿›ä¸€æ­¥ä¼˜åŒ–æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¿ƒç†å¥åº·ç›‘æµ‹ã€é’å°‘å¹´å¿ƒç†å¹²é¢„å’Œå±æœºé¢„è­¦ç³»ç»Ÿã€‚é€šè¿‡å‡†ç¡®è¯„ä¼°è‡ªæ€é£é™©ï¼Œèƒ½å¤Ÿä¸ºå¿ƒç†å¥åº·ä¸“ä¸šäººå£«æä¾›æ›´æœ‰æ•ˆçš„å†³ç­–æ”¯æŒï¼Œè¿›è€Œé™ä½é’å°‘å¹´è‡ªæ€äº‹ä»¶çš„å‘ç”Ÿç‡ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯æ‰©å±•è‡³å…¶ä»–äººç¾¤çš„å¿ƒç†å¥åº·è¯„ä¼°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The 1st SpeechWellness Challenge conveys the need for speech-based suicide risk assessment in adolescents. This study investigates a multimodal approach for this challenge, integrating automatic transcription with WhisperX, linguistic embeddings from Chinese RoBERTa, and audio embeddings from WavLM. Additionally, handcrafted acoustic features -- including MFCCs, spectral contrast, and pitch-related statistics -- were incorporated. We explored three fusion strategies: early concatenation, modality-specific processing, and weighted attention with mixup regularization. Results show that weighted attention provided the best generalization, achieving 69% accuracy on the development set, though a performance gap between development and test sets highlights generalization challenges. Our findings, strictly tied to the MINI-KID framework, emphasize the importance of refining embedding representations and fusion mechanisms to enhance classification reliability.

