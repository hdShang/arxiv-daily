---
layout: default
title: A Data Synthesis Method Driven by Large Language Models for Proactive Mining of Implicit User Intentions in Tourism
---

# A Data Synthesis Method Driven by Large Language Models for Proactive Mining of Implicit User Intentions in Tourism

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.11533" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.11533v1</a>
  <a href="https://arxiv.org/pdf/2505.11533.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.11533v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.11533v1', 'A Data Synthesis Method Driven by Large Language Models for Proactive Mining of Implicit User Intentions in Tourism')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jinqiang Wang, Huansheng Ning, Tao Zhu, Jianguo Ding

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-14

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSynPTä»¥è§£å†³æ—…æ¸¸é¢†åŸŸéšå«ç”¨æˆ·æ„å›¾æŒ–æ˜é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `éšå«æ„å›¾æŒ–æ˜` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ•°æ®åˆæˆ` `æ—…æ¸¸é¢†åŸŸ` `ç”¨æˆ·éœ€æ±‚åˆ†æ` `å¯¹è¯ç³»ç»Ÿ` `æƒ…æ„Ÿåˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æ—…æ¸¸é¢†åŸŸéšå«ç”¨æˆ·æ„å›¾æŒ–æ˜ä¸­å­˜åœ¨é€‚åº”æ€§ä¸è¶³å’Œæ•°æ®ç¨€ç¼ºç­‰æŒ‘æˆ˜ã€‚
2. æœ¬æ–‡æå‡ºSynPTï¼Œé€šè¿‡æ„å»ºç”¨æˆ·ä»£ç†å’ŒåŠ©æ‰‹ä»£ç†ï¼Œåˆ©ç”¨LLMsæ¨¡æ‹Ÿå¯¹è¯ç”Ÿæˆè®­ç»ƒæ•°æ®ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSynPTåœ¨éšå«æ„å›¾æŒ–æ˜æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸”å…·æœ‰è‰¯å¥½çš„é€‚åº”æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨æ—…æ¸¸é¢†åŸŸï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æŒ–æ˜æ¸¸å®¢æ¨¡ç³Šè¯¢é—®ä¸­çš„éšå«æ„å›¾æ—¶é¢ä¸´æŒ‘æˆ˜ï¼Œä¸”ç¼ºä¹ä¸»åŠ¨å¼•å¯¼ç”¨æˆ·æ˜ç¡®éœ€æ±‚çš„èƒ½åŠ›ã€‚ç°æœ‰æ–¹æ³•å­˜åœ¨é€‚åº”æ€§ä¸è¶³ã€åˆå§‹è¯¢é—®ç»†èŠ‚åˆ†å¸ƒåæ–œã€éšå«æ„å›¾æŒ–æ˜æ¨¡å—çš„ä¸Šä¸‹æ–‡å†—ä½™ï¼Œä»¥åŠå¯¹æ¸¸å®¢æƒ…æ„Ÿå’Œæ„å›¾ä»·å€¼ç¼ºä¹æ˜ç¡®æ€è€ƒç­‰é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†SynPTï¼Œä¸€ç§åŸºäºLLMsçš„æ•°æ®åˆæˆæ–¹æ³•ï¼Œæ„å»ºäº†ç”¨æˆ·ä»£ç†å’ŒåŠ©æ‰‹ä»£ç†ä»¥æ¨¡æ‹Ÿå¯¹è¯ï¼Œç”ŸæˆåŒ…å«æ˜ç¡®æ¨ç†çš„è®­ç»ƒæ•°æ®é›†SynPT-Dialogã€‚é€šè¿‡å¯¹é€šç”¨LLMçš„å¾®è°ƒï¼Œå®éªŒç»“æœè¡¨æ˜SynPTåœ¨éšå«ç”¨æˆ·æ„å›¾æŒ–æ˜æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶åˆ†æäº†å…³é”®è¶…å‚æ•°åŠæ¡ˆä¾‹ç ”ç©¶ï¼Œå±•ç¤ºäº†å…¶åœ¨è‹±è¯­åœºæ™¯ä¸­çš„é€‚åº”æ€§ã€‚æ‰€æœ‰ä»£ç å’Œæ•°æ®å‡å¯å…¬å¼€è·å–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ—…æ¸¸é¢†åŸŸä¸­éšå«ç”¨æˆ·æ„å›¾æŒ–æ˜çš„ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•åœ¨æ•°æ®ç¨€ç¼ºå’Œé€‚åº”æ€§æ–¹é¢å­˜åœ¨ç“¶é¢ˆï¼Œæ— æ³•æœ‰æ•ˆå¼•å¯¼ç”¨æˆ·æ˜ç¡®éœ€æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºSynPTï¼Œé€šè¿‡æ„å»ºåŸºäºLLMsçš„ç”¨æˆ·ä»£ç†å’ŒåŠ©æ‰‹ä»£ç†ï¼Œæ¨¡æ‹Ÿå¯¹è¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„è®­ç»ƒæ•°æ®ï¼Œä»è€Œæå‡éšå«æ„å›¾æŒ–æ˜çš„èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ç”¨æˆ·ä»£ç†å’ŒåŠ©æ‰‹ä»£ç†ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼Œç”¨æˆ·ä»£ç†è´Ÿè´£ç”Ÿæˆåˆå§‹è¯¢é—®ï¼ŒåŠ©æ‰‹ä»£ç†åˆ™è¿›è¡Œå¯¹è¯æ¨¡æ‹Ÿï¼Œæœ€ç»ˆç”ŸæˆåŒ…å«æ˜ç¡®æ¨ç†çš„SynPT-Dialogæ•°æ®é›†ã€‚

**å…³é”®åˆ›æ–°**ï¼šSynPTçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºç»“åˆLLMsè¿›è¡Œæ•°æ®åˆæˆï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•åœ¨æ—…æ¸¸é¢†åŸŸçš„é€‚åº”æ€§é—®é¢˜ï¼Œå¹¶å¼•å…¥äº†æƒ…æ„Ÿå’Œæ„å›¾ä»·å€¼çš„æ˜ç¡®æ€è€ƒã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œè®¾ç½®äº†ç‰¹å®šçš„è¶…å‚æ•°ä»¥ä¼˜åŒ–å¯¹è¯ç”Ÿæˆè¿‡ç¨‹ï¼Œé‡‡ç”¨äº†é€‚åº”æ€§æŸå¤±å‡½æ•°ä»¥æé«˜éšå«æ„å›¾çš„æŒ–æ˜æ•ˆæœï¼Œç¡®ä¿ç”Ÿæˆçš„æ•°æ®é›†å…·æœ‰é«˜è´¨é‡å’Œå¤šæ ·æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒSynPTåœ¨éšå«ç”¨æˆ·æ„å›¾æŒ–æ˜æ–¹é¢çš„æ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šã€‚é€šè¿‡äººç±»å’ŒLLMçš„åŒé‡è¯„ä¼°ï¼ŒéªŒè¯äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§å’Œå¯é æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨æ—…æ¸¸è¡Œä¸šå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå¯ä»¥å¸®åŠ©æ—…æ¸¸å¹³å°æ›´å¥½åœ°ç†è§£ç”¨æˆ·éœ€æ±‚ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚é€šè¿‡ä¸»åŠ¨æŒ–æ˜éšå«æ„å›¾ï¼Œæ—…æ¸¸æœåŠ¡æä¾›å•†èƒ½å¤Ÿæ›´ç²¾å‡†åœ°æ¨èäº§å“å’ŒæœåŠ¡ï¼Œè¿›è€Œæé«˜å®¢æˆ·æ»¡æ„åº¦å’Œè½¬åŒ–ç‡ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•ä¹Ÿå¯æ‰©å±•è‡³å…¶ä»–é¢†åŸŸï¼Œå¦‚åœ¨çº¿å®¢æœå’Œæ™ºèƒ½åŠ©æ‰‹ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In the tourism domain, Large Language Models (LLMs) often struggle to mine implicit user intentions from tourists' ambiguous inquiries and lack the capacity to proactively guide users toward clarifying their needs. A critical bottleneck is the scarcity of high-quality training datasets that facilitate proactive questioning and implicit intention mining. While recent advances leverage LLM-driven data synthesis to generate such datasets and transfer specialized knowledge to downstream models, existing approaches suffer from several shortcomings: (1) lack of adaptation to the tourism domain, (2) skewed distributions of detail levels in initial inquiries, (3) contextual redundancy in the implicit intention mining module, and (4) lack of explicit thinking about tourists' emotions and intention values. Therefore, we propose SynPT (A Data Synthesis Method Driven by LLMs for Proactive Mining of Implicit User Intentions in the Tourism), which constructs an LLM-driven user agent and assistant agent to simulate dialogues based on seed data collected from Chinese tourism websites. This approach addresses the aforementioned limitations and generates SynPT-Dialog, a training dataset containing explicit reasoning. The dataset is utilized to fine-tune a general LLM, enabling it to proactively mine implicit user intentions. Experimental evaluations, conducted from both human and LLM perspectives, demonstrate the superiority of SynPT compared to existing methods. Furthermore, we analyze key hyperparameters and present case studies to illustrate the practical applicability of our method, including discussions on its adaptability to English-language scenarios. All code and data are publicly available.

