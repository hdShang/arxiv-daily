---
layout: default
title: Product of Experts with LLMs: Boosting Performance on ARC Is a Matter of Perspective
---

# Product of Experts with LLMs: Boosting Performance on ARC Is a Matter of Perspective

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.07859" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.07859v2</a>
  <a href="https://arxiv.org/pdf/2505.07859.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.07859v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.07859v2', 'Product of Experts with LLMs: Boosting Performance on ARC Is a Matter of Perspective')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Daniel Franzen, Jan Disselhoff, David Hartmann

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-08 (æ›´æ–°: 2025-06-11)

**å¤‡æ³¨**: ICML 2025 camera-ready; 15 pages, 6 figures, 5 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºä¸“å®¶æ¨¡å‹çš„LLMæ–¹æ³•ä»¥æå‡ARC-AGIè¡¨ç°**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æŠ½è±¡æ¨ç†` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ•°æ®å¢å¼º` `æ·±åº¦ä¼˜å…ˆæœç´¢` `æ¨¡å‹è¯„åˆ†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ARC-AGIå¯¹LLMsçš„æŠ½è±¡æ¨ç†èƒ½åŠ›æå‡ºäº†ä¸¥å³»æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•åœ¨è§£å†³ä»»åŠ¡æ—¶è¡¨ç°ä¸ä½³ã€‚
2. æœ¬ç ”ç©¶é€šè¿‡ä»»åŠ¡ç‰¹å®šçš„æ•°æ®å¢å¼ºå’Œæ·±åº¦ä¼˜å…ˆæœç´¢ç®—æ³•ï¼Œç”Ÿæˆå¤šæ ·åŒ–çš„å€™é€‰è§£ï¼Œå¹¶åˆ©ç”¨LLMè¿›è¡Œè¯„åˆ†ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ARC-AGIè¯„ä¼°é›†ä¸Šå–å¾—71.6%çš„å¾—åˆ†ï¼Œå±•ç°å‡ºä¼˜äºç°æœ‰å…¬å¼€æ–¹æ³•çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æŠ½è±¡ä¸æ¨ç†è¯­æ–™åº“ï¼ˆARC-AGIï¼‰å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æå‡ºäº†é‡å¤§æŒ‘æˆ˜ï¼Œæš´éœ²äº†å…¶åœ¨æŠ½è±¡æ¨ç†èƒ½åŠ›ä¸Šçš„å±€é™æ€§ã€‚æœ¬ç ”ç©¶é€šè¿‡åœ¨è®­ç»ƒã€ç”Ÿæˆå’Œè¯„åˆ†é˜¶æ®µåˆ©ç”¨ä»»åŠ¡ç‰¹å®šçš„æ•°æ®å¢å¼ºï¼Œå¹¶é‡‡ç”¨æ·±åº¦ä¼˜å…ˆæœç´¢ç®—æ³•ç”Ÿæˆå¤šæ ·åŒ–çš„é«˜æ¦‚ç‡å€™é€‰è§£ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬å°†LLMä¸ä»…ç”¨ä½œç”Ÿæˆå™¨ï¼Œè¿˜ç”¨ä½œè¯„åˆ†å™¨ï¼Œåˆ©ç”¨å…¶è¾“å‡ºæ¦‚ç‡é€‰æ‹©æœ€æœ‰å‰æ™¯çš„è§£ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨å…¬å…±ARC-AGIè¯„ä¼°é›†ä¸Šå–å¾—äº†71.6%çš„å¾—åˆ†ï¼ˆ286.5/400è§£å†³ä»»åŠ¡ï¼‰ï¼Œå±•ç¤ºäº†åœ¨å…¬å¼€å¯ç”¨æ–¹æ³•ä¸­çš„é¢†å…ˆè¡¨ç°ã€‚å°½ç®¡åŒæ—¶æœŸçš„é—­æºå·¥ä½œæŠ¥å‘Šäº†æ›´é«˜çš„å¾—åˆ†ï¼Œä½†æˆ‘ä»¬çš„æ–¹æ³•åœ¨é€æ˜æ€§ã€å¯é‡å¤æ€§å’Œæä½çš„æ¨ç†æˆæœ¬æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œå¹³å‡æ¯ä¸ªä»»åŠ¡ä»…éœ€çº¦2ç¾åˆ†çš„æˆæœ¬ï¼ˆå‡è®¾Nvidia 4090 GPUçš„ä»·æ ¼ä¸º36ç¾åˆ†/å°æ—¶ï¼‰ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æŠ½è±¡ä¸æ¨ç†è¯­æ–™åº“ï¼ˆARC-AGIï¼‰ä¸­çš„è¡¨ç°ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚æ¨ç†ä»»åŠ¡æ—¶å­˜åœ¨å±€é™æ€§ï¼Œå¯¼è‡´è§£å†³ç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç»“åˆä»»åŠ¡ç‰¹å®šæ•°æ®å¢å¼ºå’Œæ·±åº¦ä¼˜å…ˆæœç´¢çš„ç­–ç•¥ï¼Œåˆ©ç”¨LLMçš„ç”Ÿæˆå’Œè¯„åˆ†èƒ½åŠ›ï¼Œæå‡æ¨¡å‹çš„æ¨ç†æ•ˆæœã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬èƒ½å¤Ÿç”Ÿæˆå¤šæ ·åŒ–ä¸”é«˜æ¦‚ç‡çš„å€™é€‰è§£ï¼Œä»è€Œæé«˜æœ€ç»ˆçš„è§£å†³ç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ–¹æ³•åˆ†ä¸ºä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼šæ•°æ®å¢å¼ºã€å€™é€‰è§£ç”Ÿæˆå’Œè¯„åˆ†ã€‚é¦–å…ˆï¼Œåœ¨è®­ç»ƒé˜¶æ®µè¿›è¡Œæ•°æ®å¢å¼ºï¼›å…¶æ¬¡ï¼Œä½¿ç”¨æ·±åº¦ä¼˜å…ˆæœç´¢ç®—æ³•ç”Ÿæˆå€™é€‰è§£ï¼›æœ€åï¼Œåˆ©ç”¨LLMå¯¹å€™é€‰è§£è¿›è¡Œè¯„åˆ†ï¼Œé€‰æ‹©æœ€ä¼˜è§£ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºå°†LLMåŒæ—¶ä½œä¸ºç”Ÿæˆå™¨å’Œè¯„åˆ†å™¨ï¼Œåˆ©ç”¨å…¶è¾“å‡ºæ¦‚ç‡è¿›è¡Œè§£çš„é€‰æ‹©ã€‚è¿™ç§åŒé‡è§’è‰²çš„è®¾è®¡ä½¿å¾—æ¨¡å‹åœ¨é€æ˜æ€§å’Œå¯é‡å¤æ€§ä¸Šä¼˜äºå…¶ä»–æ–¹æ³•ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œæˆ‘ä»¬ä¼˜åŒ–äº†æ•°æ®å¢å¼ºçš„ç­–ç•¥ï¼Œå¹¶è®¾è®¡äº†é«˜æ•ˆçš„æ·±åº¦ä¼˜å…ˆæœç´¢ç®—æ³•ã€‚æ­¤å¤–ï¼ŒLLMçš„è¾“å‡ºæ¦‚ç‡è¢«ç”¨ä½œè¯„åˆ†æ ‡å‡†ï¼Œç¡®ä¿é€‰æ‹©çš„å€™é€‰è§£å…·æœ‰è¾ƒé«˜çš„æˆåŠŸç‡ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

æˆ‘ä»¬çš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•åœ¨ARC-AGIè¯„ä¼°é›†ä¸Šå–å¾—äº†71.6%çš„å¾—åˆ†ï¼ŒæˆåŠŸè§£å†³äº†286.5ä¸ªä»»åŠ¡ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰å…¬å¼€æ–¹æ³•ã€‚åŒæ—¶ï¼Œæ¨ç†æˆæœ¬ä»…ä¸ºæ¯ä¸ªä»»åŠ¡çº¦2ç¾åˆ†ï¼Œå±•ç°å‡ºæé«˜çš„æ€§ä»·æ¯”ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€æ™ºèƒ½é—®ç­”ç³»ç»Ÿå’Œå¤æ‚å†³ç­–æ”¯æŒç­‰ã€‚é€šè¿‡æå‡LLMåœ¨æŠ½è±¡æ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œå¯ä»¥ä¸ºå„ç±»éœ€è¦é«˜æ°´å¹³æ¨ç†èƒ½åŠ›çš„åº”ç”¨æä¾›æ›´å¯é çš„æ”¯æŒï¼Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿçš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The Abstraction and Reasoning Corpus (ARC-AGI) poses a significant challenge for large language models (LLMs), exposing limitations in their abstract reasoning abilities. In this work, we leverage task-specific data augmentations throughout the training, generation, and scoring phases, and employ a depth-first search algorithm to generate diverse, high-probability candidate solutions. Furthermore, we utilize the LLM not only as a generator but also as a scorer, using its output probabilities to select the most promising solutions. Our method achieves a score of 71.6% (286.5/400 solved tasks) on the public ARC-AGI evaluation set, demonstrating state-of-the-art performance among publicly available approaches. While concurrent closed-source work has reported higher scores, our method distinguishes itself through its transparency, reproducibility, and remarkably low inference cost, averaging only around 2ct per task on readily available hardware (we assume a price of 36ct/hour for a Nvidia 4090 GPU).

