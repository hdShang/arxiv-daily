---
layout: default
title: ComPO: Preference Alignment via Comparison Oracles
---

# ComPO: Preference Alignment via Comparison Oracles

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.05465" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.05465v2</a>
  <a href="https://arxiv.org/pdf/2505.05465.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.05465v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.05465v2', 'ComPO: Preference Alignment via Comparison Oracles')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Peter Chen, Xi Chen, Wotao Yin, Tianyi Lin

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-08 (æ›´æ–°: 2025-10-25)

**å¤‡æ³¨**: Accepted to NeurIPS 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºComPOæ–¹æ³•ä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹åå¥½å¯¹é½é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åå¥½å¯¹é½` `æ¯”è¾ƒä¼˜åŒ–` `å¤§è¯­è¨€æ¨¡å‹` `å™ªå£°åå¥½å¯¹` `è‡ªç„¶è¯­è¨€å¤„ç†` `æ¨¡å‹æ€§èƒ½æå‡` `äººæœºäº¤äº’`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç›´æ¥å¯¹é½æ–¹æ³•åœ¨å¤„ç†äººç±»åå¥½æ—¶å­˜åœ¨å†—é•¿æ€§å’Œä¼¼ç„¶æ€§åç§»çš„é—®é¢˜ï¼Œå½±å“äº†æ¨¡å‹çš„æ€§èƒ½ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ¯”è¾ƒoracleçš„é›¶é˜¶æ¯”è¾ƒä¼˜åŒ–çš„åå¥½å¯¹é½æ–°æ–¹æ³•ï¼Œæ—¨åœ¨æé«˜å¯¹å™ªå£°åå¥½å¯¹çš„å¤„ç†èƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„å¯¹é½æ•ˆæœï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç›´æ¥å¯¹é½æ–¹æ³•åœ¨å°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸äººç±»åå¥½å¯¹é½ä¸­è¶Šæ¥è¶Šå¸¸ç”¨ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å­˜åœ¨å†—é•¿æ€§å’Œä¼¼ç„¶æ€§åç§»ç­‰é—®é¢˜ï¼Œè¿™äº›é—®é¢˜å¯èƒ½ç”±å™ªå£°åå¥½å¯¹å¼•èµ·ã€‚æœ¬æ–‡çš„è´¡çŒ®æœ‰ä¸¤ä¸ªæ–¹é¢ï¼šé¦–å…ˆï¼Œæå‡ºäº†ä¸€ç§åŸºäºé›¶é˜¶æ¯”è¾ƒä¼˜åŒ–çš„æ–°åå¥½å¯¹é½æ–¹æ³•ï¼Œå¹¶ä¸ºå…¶åŸºæœ¬æ–¹æ¡ˆæä¾›äº†æ”¶æ•›ä¿è¯ï¼›å…¶æ¬¡ï¼Œé€šè¿‡ä¸€äº›å¯å‘å¼æ–¹æ³•æ”¹è¿›äº†è¯¥æ–¹æ³•ï¼Œå¹¶è¿›è¡Œäº†å®éªŒä»¥å±•ç¤ºå…¶åœ¨ä½¿ç”¨å™ªå£°åå¥½å¯¹æ—¶æé«˜LLMsæ€§èƒ½çš„çµæ´»æ€§å’Œå…¼å®¹æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆåœ°è§£å†³äº†ç°æœ‰ç›´æ¥å¯¹é½æ–¹æ³•çš„å±€é™æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰ç›´æ¥å¯¹é½æ–¹æ³•åœ¨å¤„ç†å™ªå£°åå¥½å¯¹æ—¶çš„å†—é•¿æ€§å’Œä¼¼ç„¶æ€§åç§»é—®é¢˜ï¼Œè¿™äº›é—®é¢˜å¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºäº†ä¸€ç§æ–°çš„åå¥½å¯¹é½æ–¹æ³•ï¼ŒåŸºäºé›¶é˜¶æ¯”è¾ƒä¼˜åŒ–ï¼Œé€šè¿‡æ¯”è¾ƒoracleæ¥ä¼˜åŒ–åå¥½å¯¹çš„é€‰æ‹©ï¼Œæ—¨åœ¨æé«˜å¯¹å™ªå£°åå¥½å¯¹çš„é€‚åº”æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•çš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€åå¥½å¯¹ç”Ÿæˆã€æ¯”è¾ƒoracleçš„æ„å»ºå’Œä¼˜åŒ–è¿‡ç¨‹ï¼Œç¡®ä¿åœ¨æ¯ä¸ªé˜¶æ®µéƒ½èƒ½æœ‰æ•ˆå¤„ç†åå¥½ä¿¡æ¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºè®¾è®¡äº†ä¸“é—¨é’ˆå¯¹å…·æœ‰ä¸åŒä¼¼ç„¶è¾¹é™…çš„åå¥½å¯¹çš„ä¼˜åŒ–æ–¹æ³•ï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„é€šç”¨æ€§è®¾è®¡å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†å¯å‘å¼æ–¹æ³•æ¥è°ƒæ•´ä¼˜åŒ–è¿‡ç¨‹ä¸­çš„å­¦ä¹ ç‡å’ŒæŸå¤±å‡½æ•°ï¼Œä»¥æé«˜æ¨¡å‹çš„æ”¶æ•›é€Ÿåº¦å’Œç¨³å®šæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æå‡ºçš„ComPOæ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ï¼ˆå¦‚AlpacaEval 2ã€MT-Benchå’ŒArena-Hardï¼‰ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œç›¸è¾ƒäºç°æœ‰æ–¹æ³•ï¼Œæ¨¡å‹æ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°15%ä»¥ä¸Šï¼ŒéªŒè¯äº†å…¶ä½œä¸ºæ›¿ä»£æ–¹æ¡ˆçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„å¯¹è¯ç³»ç»Ÿã€æ¨èç³»ç»Ÿå’Œäººæœºäº¤äº’ç­‰åœºæ™¯ã€‚é€šè¿‡æ”¹è¿›åå¥½å¯¹é½æ–¹æ³•ï¼Œå¯ä»¥æ˜¾è‘—æå‡æ¨¡å‹çš„ç”¨æˆ·ä½“éªŒå’Œæ»¡æ„åº¦ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Direct alignment methods are increasingly used for aligning large language models (LLMs) with human preferences. However, these methods suffer from the issues of verbosity and likelihood displacement, which can be driven by the noisy preference pairs that induce similar likelihood for preferred and dispreferred responses. The contributions of this paper are two-fold. First, we propose a new preference alignment method based on zeroth-order, comparison-based optimization via comparison oracles and provide convergence guarantees for its basic scheme. Second, we improve our method using some heuristics and conduct the experiments to demonstrate the flexibility and compatibility of practical scheme in improving the performance of LLMs using noisy preference pairs. Evaluations are conducted across multiple base and instruction-tuned models (Mistral-7B, Llama-3-8B and Gemma-2-9B) with benchmarks (AlpacaEval 2, MT-Bench and Arena-Hard). Experimental results show the effectiveness of our method as an alternative to addressing the limitations of existing direct alignment methods. A highlight of our work is that we evidence the importance of designing specialized methods for preference pairs with distinct likelihood margin, which complements the recent findings in Razin et al (2025).

