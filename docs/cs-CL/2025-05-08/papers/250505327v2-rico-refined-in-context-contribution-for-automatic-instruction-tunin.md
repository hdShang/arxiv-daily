---
layout: default
title: RICo: Refined In-Context Contribution for Automatic Instruction-Tuning Data Selection
---

# RICo: Refined In-Context Contribution for Automatic Instruction-Tuning Data Selection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.05327" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.05327v2</a>
  <a href="https://arxiv.org/pdf/2505.05327.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.05327v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.05327v2', 'RICo: Refined In-Context Contribution for Automatic Instruction-Tuning Data Selection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yixin Yang, Qingxiu Dong, Linli Yao, Fangwei Zhu, Zhifang Sui

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-08 (æ›´æ–°: 2025-05-18)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRICoä»¥è§£å†³è‡ªåŠ¨æŒ‡ä»¤è°ƒä¼˜æ•°æ®é€‰æ‹©é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ•°æ®é€‰æ‹©` `æŒ‡ä»¤è°ƒä¼˜` `å¤§å‹è¯­è¨€æ¨¡å‹` `è´¡çŒ®æµ‹é‡` `ä¸Šä¸‹æ–‡å­¦ä¹ ` `æ— æ¢¯åº¦æ–¹æ³•` `æ¨¡å‹æ€§èƒ½æå‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ•°æ®é€‰æ‹©æ–¹æ³•åœ¨è¯†åˆ«é«˜è´¡çŒ®æ ·æœ¬æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´æŒ‡ä»¤è°ƒä¼˜æ•ˆæœä¸ä½³ã€‚
2. æœ¬æ–‡æå‡ºRICoï¼Œé€šè¿‡æ— æ¢¯åº¦æ–¹å¼é‡åŒ–æ ·æœ¬å¯¹æ¨¡å‹æ€§èƒ½çš„è´¡çŒ®ï¼Œæå‡æ•°æ®é€‰æ‹©çš„å‡†ç¡®æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨RICoé€‰æ‹©çš„æ•°æ®æ˜¾è‘—æé«˜äº†æ¨¡å‹æ€§èƒ½ï¼Œä¸”åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ•°æ®é€‰æ‹©åœ¨æŒ‡ä»¤è°ƒä¼˜ä¸­è‡³å…³é‡è¦ï¼Œå®ƒèƒ½æé«˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ€§èƒ½å¹¶é™ä½è®­ç»ƒæˆæœ¬ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ— æ¢¯åº¦æ–¹æ³•â€”â€”ç²¾ç»†è´¡çŒ®æµ‹é‡ä¸ä¸Šä¸‹æ–‡å­¦ä¹ ç»“åˆçš„RICoï¼Œèƒ½å¤Ÿé‡åŒ–å•ä¸ªæ ·æœ¬å¯¹ä»»åŠ¡çº§å’Œå…¨å±€çº§æ¨¡å‹æ€§èƒ½çš„ç»†ç²’åº¦è´¡çŒ®ã€‚RICoä½¿å¾—é«˜è´¡çŒ®æ•°æ®çš„è¯†åˆ«æ›´åŠ å‡†ç¡®ï¼Œä»è€Œæå‡æŒ‡ä»¤è°ƒä¼˜æ•ˆæœã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åŸºäºRICoè¯„åˆ†çš„è½»é‡çº§é€‰æ‹©èŒƒå¼ï¼Œå®ç°äº†ä¸¥æ ¼çº¿æ€§æ¨ç†å¤æ‚åº¦çš„å¯æ‰©å±•æ•°æ®é€‰æ‹©ã€‚åœ¨å¯¹ä¸‰ç§LLMè¿›è¡Œçš„12ä¸ªåŸºå‡†å’Œ5ä¸ªæˆå¯¹è¯„ä¼°é›†çš„å¹¿æ³›å®éªŒä¸­ï¼ŒRICoå±•ç°äº†å…¶æœ‰æ•ˆæ€§ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåœ¨LLaMA3.1-8Bä¸Šï¼ŒåŸºäº15% RICoé€‰æ‹©æ•°æ®è®­ç»ƒçš„æ¨¡å‹æ¯”å…¨æ•°æ®é›†æé«˜äº†5.42ä¸ªç™¾åˆ†ç‚¹ï¼Œå¹¶è¶…è¶Šäº†å¹¿æ³›ä½¿ç”¨çš„é€‰æ‹©æ–¹æ³•2.06ä¸ªç™¾åˆ†ç‚¹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è‡ªåŠ¨æŒ‡ä»¤è°ƒä¼˜ä¸­æ•°æ®é€‰æ‹©çš„æœ‰æ•ˆæ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨è¯†åˆ«é«˜è´¡çŒ®æ ·æœ¬æ—¶å­˜åœ¨å±€é™ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½æœªèƒ½å¾—åˆ°å……åˆ†æå‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šRICoé€šè¿‡ç²¾ç»†è´¡çŒ®æµ‹é‡ï¼Œç»“åˆä¸Šä¸‹æ–‡å­¦ä¹ ï¼Œé‡åŒ–æ¯ä¸ªæ ·æœ¬å¯¹æ¨¡å‹æ€§èƒ½çš„è´¡çŒ®ï¼Œä»è€Œæ›´å‡†ç¡®åœ°é€‰æ‹©é«˜è´¡çŒ®æ•°æ®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRICoæ–¹æ³•åŒ…æ‹¬æ•°æ®æ ·æœ¬çš„è´¡çŒ®æµ‹é‡å’Œè½»é‡çº§é€‰æ‹©èŒƒå¼ã€‚é¦–å…ˆï¼Œé€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹ è¯„ä¼°æ ·æœ¬è´¡çŒ®ï¼Œç„¶ååŸºäºè´¡çŒ®è¯„åˆ†è¿›è¡Œæ•°æ®é€‰æ‹©ï¼Œç¡®ä¿é€‰æ‹©è¿‡ç¨‹çš„çº¿æ€§å¤æ‚åº¦ã€‚

**å…³é”®åˆ›æ–°**ï¼šRICoçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶æ— æ¢¯åº¦çš„è´¡çŒ®æµ‹é‡æ–¹æ³•ï¼Œèƒ½å¤Ÿç»†è‡´åœ°è¯„ä¼°æ ·æœ¬å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ï¼Œè¿™ä¸ä¼ ç»Ÿæ–¹æ³•çš„ä¾èµ–æ¢¯åº¦ä¿¡æ¯çš„æ–¹å¼æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨RICoä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œå‚æ•°è®¾ç½®ï¼Œä»¥ç¡®ä¿è´¡çŒ®æµ‹é‡çš„å‡†ç¡®æ€§å’Œé€‰æ‹©è¿‡ç¨‹çš„é«˜æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨LLaMA3.1-8Bæ¨¡å‹ä¸Šï¼Œä½¿ç”¨15% RICoé€‰æ‹©çš„æ•°æ®è®­ç»ƒçš„æ¨¡å‹æ€§èƒ½æ¯”å…¨æ•°æ®é›†æé«˜äº†5.42ä¸ªç™¾åˆ†ç‚¹ï¼Œä¸”è¶…è¶Šäº†å…¶ä»–ä¸»æµé€‰æ‹©æ–¹æ³•2.06ä¸ªç™¾åˆ†ç‚¹ï¼ŒéªŒè¯äº†RICoçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€å¯¹è¯ç³»ç»Ÿå’Œæ™ºèƒ½åŠ©æ‰‹ç­‰ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„è®­ç»ƒæ•ˆç‡å’Œæ€§èƒ½ã€‚æœªæ¥ï¼ŒRICoæ–¹æ³•å¯èƒ½åœ¨æ›´å¹¿æ³›çš„æœºå™¨å­¦ä¹ ä»»åŠ¡ä¸­å¾—åˆ°åº”ç”¨ï¼Œæ¨åŠ¨è‡ªåŠ¨åŒ–æ•°æ®é€‰æ‹©æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Data selection for instruction tuning is crucial for improving the performance of large language models (LLMs) while reducing training costs. In this paper, we propose Refined Contribution Measurement with In-Context Learning (RICo), a novel gradient-free method that quantifies the fine-grained contribution of individual samples to both task-level and global-level model performance. RICo enables more accurate identification of high-contribution data, leading to better instruction tuning. We further introduce a lightweight selection paradigm trained on RICo scores, enabling scalable data selection with a strictly linear inference complexity. Extensive experiments on three LLMs across 12 benchmarks and 5 pairwise evaluation sets demonstrate the effectiveness of RICo. Remarkably, on LLaMA3.1-8B, models trained on 15% of RICo-selected data outperform full datasets by 5.42% points and exceed the best performance of widely used selection methods by 2.06% points. We further analyze high-contribution samples selected by RICo, which show both diverse tasks and appropriate difficulty levels, rather than just the hardest ones.

