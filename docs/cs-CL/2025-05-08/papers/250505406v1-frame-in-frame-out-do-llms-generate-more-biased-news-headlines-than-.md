---
layout: default
title: Frame In, Frame Out: Do LLMs Generate More Biased News Headlines than Humans?
---

# Frame In, Frame Out: Do LLMs Generate More Biased News Headlines than Humans?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.05406" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.05406v1</a>
  <a href="https://arxiv.org/pdf/2505.05406.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.05406v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.05406v1', 'Frame In, Frame Out: Do LLMs Generate More Biased News Headlines than Humans?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Valeria Pastorino, Nafise Sadat Moosavi

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-08

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ¢è®¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆæ–°é—»æ ‡é¢˜çš„åè§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ¡†æ¶æ•ˆåº”` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ–°é—»ç”Ÿæˆ` `åè§è¯„ä¼°` `è‡ªåŠ¨åŒ–å†…å®¹åˆ›ä½œ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è‡ªåŠ¨æ–°é—»ç”Ÿæˆæ–¹æ³•å¯èƒ½å¼•å…¥æˆ–åŠ å‰§æ¡†æ¶åè§ï¼Œå½±å“å…¬ä¼—å¯¹äº‹ä»¶çš„ç†è§£ã€‚
2. æœ¬æ–‡é€šè¿‡åˆ†æLLMsç”Ÿæˆçš„æ–°é—»å†…å®¹ï¼Œæ¢è®¨å…¶æ¡†æ¶æ•ˆåº”çš„è¡¨ç°åŠå…¶ä¸äººç±»ä½œè€…çš„æ¯”è¾ƒã€‚
3. ç ”ç©¶å‘ç°ï¼ŒLLMsåœ¨æ”¿æ²»å’Œç¤¾ä¼šæ•æ„Ÿé¢†åŸŸçš„æ¡†æ¶åè§æ›´ä¸ºæ˜æ˜¾ï¼Œä¸”ä¸åŒæ¨¡å‹æ¶æ„çš„åè§ç¨‹åº¦å·®å¼‚æ˜¾è‘—ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åª’ä½“ä¸­çš„æ¡†æ¶æ•ˆåº”é€šè¿‡é€‰æ‹©æ€§å¼ºè°ƒæŸäº›ç»†èŠ‚è€Œå½±å“å…¬ä¼—è®¤çŸ¥ã€‚éšç€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è‡ªåŠ¨æ–°é—»å’Œå†…å®¹åˆ›ä½œä¸­çš„åº”ç”¨ï¼Œè¶Šæ¥è¶Šå¤šçš„ç ”ç©¶å…³æ³¨è¿™äº›ç³»ç»Ÿæ˜¯å¦ä¼šå¼•å…¥æˆ–åŠ å‰§æ¡†æ¶åè§ã€‚æœ¬æ–‡æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„æ–°é—»å†…å®¹ä¸­æ¡†æ¶æ•ˆåº”çš„è¡¨ç°ï¼Œå‘ç°å°¤å…¶åœ¨æ”¿æ²»å’Œç¤¾ä¼šæ•æ„Ÿçš„èƒŒæ™¯ä¸‹ï¼ŒLLMsçš„æ¡†æ¶åè§æ˜æ˜¾é«˜äºäººç±»ä½œè€…ã€‚æ­¤å¤–ï¼Œä¸åŒæ¨¡å‹æ¶æ„çš„æ¡†æ¶å€¾å‘å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œéƒ¨åˆ†æ¨¡å‹è¡¨ç°å‡ºæ›´é«˜çš„åè§ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†æœ‰æ•ˆçš„åè®­ç»ƒå‡è½»ç­–ç•¥å’Œæ›´ä¸¥æ ¼çš„è¯„ä¼°æ¡†æ¶çš„å¿…è¦æ€§ï¼Œä»¥ç¡®ä¿è‡ªåŠ¨ç”Ÿæˆçš„æ–°é—»å†…å®¹ç¬¦åˆå¹³è¡¡æŠ¥é“çš„æ ‡å‡†ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆæ–°é—»æ ‡é¢˜æ—¶å¯èƒ½å¼•å…¥çš„æ¡†æ¶åè§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹å¯¹æ¨¡å‹ç”Ÿæˆå†…å®¹çš„åè§è¯„ä¼°ï¼Œå¯¼è‡´å…¬ä¼—è®¤çŸ¥å—åˆ°å½±å“ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ¯”è¾ƒä¸åŒæ¶æ„çš„LLMsç”Ÿæˆçš„æ–°é—»å†…å®¹ä¸äººç±»ä½œè€…çš„ä½œå“ï¼Œåˆ†ææ¡†æ¶æ•ˆåº”çš„è¡¨ç°ï¼Œæ—¨åœ¨æ­ç¤ºLLMsåœ¨æ•æ„Ÿè¯é¢˜ä¸Šçš„åè§ç¨‹åº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨å®šé‡å’Œå®šæ€§åˆ†æç›¸ç»“åˆçš„æ–¹æ³•ï¼Œé¦–å…ˆç”Ÿæˆæ–°é—»æ ‡é¢˜ï¼Œç„¶åå¯¹æ¯”åˆ†æå…¶æ¡†æ¶æ•ˆåº”ï¼Œæœ€åè¯„ä¼°ä¸åŒæ¨¡å‹çš„è¡¨ç°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„åˆ›æ–°åœ¨äºç³»ç»Ÿæ€§åœ°æ¯”è¾ƒäº†å¤šç§LLMsç”Ÿæˆçš„å†…å®¹ä¸äººç±»åˆ›ä½œçš„å†…å®¹ï¼Œæ­ç¤ºäº†æ¨¡å‹æ¶æ„å¯¹æ¡†æ¶åè§çš„å½±å“ï¼Œå¡«è¡¥äº†ç›¸å…³é¢†åŸŸçš„ç ”ç©¶ç©ºç™½ã€‚

**å…³é”®è®¾è®¡**ï¼šç ”ç©¶ä¸­ä½¿ç”¨äº†å¤šç§æ¨¡å‹æ¶æ„è¿›è¡Œå¯¹æ¯”ï¼Œè®¾è®¡äº†ç‰¹å®šçš„è¯„ä¼°æŒ‡æ ‡æ¥é‡åŒ–æ¡†æ¶åè§ï¼Œç¡®ä¿ç»“æœçš„å¯é æ€§å’Œæœ‰æ•ˆæ€§ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡åœ¨å®éªŒä¸­è¿›è¡Œäº†è¯¦ç»†è®°å½•ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMsåœ¨ç”Ÿæˆçš„æ–°é—»æ ‡é¢˜ä¸­è¡¨ç°å‡ºæ¯”äººç±»ä½œè€…æ›´å¼ºçš„æ¡†æ¶åè§ï¼Œå°¤å…¶æ˜¯åœ¨æ”¿æ²»å’Œç¤¾ä¼šæ•æ„Ÿè¯é¢˜ä¸Šã€‚ä¸åŒæ¨¡å‹æ¶æ„çš„åè§ç¨‹åº¦å·®å¼‚æ˜¾è‘—ï¼ŒæŸäº›æ¨¡å‹çš„åè§ç¨‹åº¦é«˜å‡ºäººç±»ä½œè€…çš„ä¸¤å€ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†å¯¹è‡ªåŠ¨ç”Ÿæˆå†…å®¹çš„è¯„ä¼°å’Œæ”¹è¿›çš„å¿…è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ–°é—»åª’ä½“ã€ç¤¾äº¤å¹³å°å’Œå†…å®¹ç”Ÿæˆå·¥å…·ç­‰ã€‚é€šè¿‡è¯†åˆ«å’Œå‡è½»LLMsç”Ÿæˆå†…å®¹ä¸­çš„åè§ï¼Œå¯ä»¥æé«˜è‡ªåŠ¨ç”Ÿæˆæ–°é—»çš„è´¨é‡ï¼Œç¡®ä¿ä¿¡æ¯çš„å®¢è§‚æ€§å’Œå…¬æ­£æ€§ï¼Œè¿›è€Œå½±å“å…¬ä¼—å¯¹é‡è¦äº‹ä»¶çš„ç†è§£å’Œçœ‹æ³•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Framing in media critically shapes public perception by selectively emphasizing some details while downplaying others. With the rise of large language models in automated news and content creation, there is growing concern that these systems may introduce or even amplify framing biases compared to human authors. In this paper, we explore how framing manifests in both out-of-the-box and fine-tuned LLM-generated news content. Our analysis reveals that, particularly in politically and socially sensitive contexts, LLMs tend to exhibit more pronounced framing than their human counterparts. In addition, we observe significant variation in framing tendencies across different model architectures, with some models displaying notably higher biases. These findings point to the need for effective post-training mitigation strategies and tighter evaluation frameworks to ensure that automated news content upholds the standards of balanced reporting.

