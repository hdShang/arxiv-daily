---
layout: default
title: Efficient Latent Semantic Clustering for Scaling Test-Time Computation of LLMs
---

# Efficient Latent Semantic Clustering for Scaling Test-Time Computation of LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.00344" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.00344v1</a>
  <a href="https://arxiv.org/pdf/2506.00344.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.00344v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.00344v1', 'Efficient Latent Semantic Clustering for Scaling Test-Time Computation of LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sungjae Lee, Hoyoung Kim, Jeongyeon Hwang, Eunhyeok Park, Jungseul Ok

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-31

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ½œåœ¨è¯­ä¹‰èšç±»æ–¹æ³•ä»¥æå‡å¤§è¯­è¨€æ¨¡å‹æµ‹è¯•æ—¶è®¡ç®—æ•ˆç‡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `è¯­ä¹‰èšç±»` `è®¡ç®—æ•ˆç‡` `ä¸Šä¸‹æ–‡æ„ŸçŸ¥` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¯­ä¹‰èšç±»æ–¹æ³•ä¾èµ–å¤–éƒ¨æ¨¡å‹ï¼Œå¯¼è‡´è®¡ç®—å¼€é”€å¤§ä¸”æ— æ³•æœ‰æ•ˆæ•æ‰ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚
2. æœ¬æ–‡æå‡ºçš„æ½œåœ¨è¯­ä¹‰èšç±»ï¼ˆLSCï¼‰æ–¹æ³•ï¼Œé€šè¿‡åˆ©ç”¨ç”Ÿæˆå™¨LLMçš„å†…éƒ¨éšçŠ¶æ€è¿›è¡Œèšç±»ï¼Œè§£å†³äº†ä¸Šè¿°é—®é¢˜ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLSCåœ¨å¤šä¸ªLLMå’Œæ•°æ®é›†ä¸Šæ˜¾è‘—æå‡äº†è®¡ç®—æ•ˆç‡ï¼ŒåŒæ—¶ä¿æŒæˆ–è¶…è¿‡äº†ç°æœ‰æ–¹æ³•çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æµ‹è¯•æ—¶è®¡ç®—ä¸­ï¼Œç”Ÿæˆå’Œåˆ†æå¤šä¸ªæˆ–è¿ç»­è¾“å‡ºä»¥æé«˜å¯é æ€§å’Œè´¨é‡å·²æˆä¸ºä¸€ç§æœ‰æ•ˆç­–ç•¥ã€‚è¯­ä¹‰èšç±»æ˜¯å…¶ä¸­çš„å…³é”®ç»„æˆéƒ¨åˆ†ï¼Œå®ƒå°†å½¢å¼ä¸åŒä½†æ„ä¹‰ç›¸åŒçš„è¾“å‡ºè¿›è¡Œåˆ†ç»„ï¼Œä»è€Œé¿å…å†—ä½™çš„æ¨ç†è·¯å¾„æ¢ç´¢ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–å¤–éƒ¨æ¨¡å‹ï¼Œå¯¼è‡´è®¡ç®—å¼€é”€å¤§ä¸”éš¾ä»¥æ•æ‰ä¸Šä¸‹æ–‡è¯­ä¹‰ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§è½»é‡çº§çš„æ½œåœ¨è¯­ä¹‰èšç±»ï¼ˆLSCï¼‰æ–¹æ³•ï¼Œåˆ©ç”¨ç”Ÿæˆå™¨LLMçš„å†…éƒ¨éšçŠ¶æ€è¿›è¡Œèšç±»ï¼Œæ¶ˆé™¤äº†å¯¹å¤–éƒ¨æ¨¡å‹çš„éœ€æ±‚ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLSCæ˜¾è‘—æé«˜äº†æµ‹è¯•æ—¶è®¡ç®—çš„æ•ˆç‡ï¼ŒåŒæ—¶ä¿æŒæˆ–è¶…è¶Šäº†ç°æœ‰æ–¹æ³•çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰è¯­ä¹‰èšç±»æ–¹æ³•åœ¨è®¡ç®—æ•ˆç‡å’Œä¸Šä¸‹æ–‡æ•æ‰æ–¹é¢çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯ä¾èµ–å¤–éƒ¨æ¨¡å‹æ‰€å¸¦æ¥çš„é«˜è®¡ç®—å¼€é”€ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºæ½œåœ¨è¯­ä¹‰èšç±»ï¼ˆLSCï¼‰æ–¹æ³•ï¼Œåˆ©ç”¨ç”Ÿæˆå™¨LLMçš„å†…éƒ¨éšçŠ¶æ€è¿›è¡Œèšç±»ï¼Œä»è€Œæ¶ˆé™¤å¯¹å¤–éƒ¨æ¨¡å‹çš„éœ€æ±‚ï¼Œæå‡è®¡ç®—æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLSCæ–¹æ³•çš„æ•´ä½“æ¶æ„åŒ…æ‹¬è¾“å…¥å¤„ç†ã€éšçŠ¶æ€æå–ã€è¯­ä¹‰èšç±»å’Œè¾“å‡ºç”Ÿæˆå››ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œè¾“å…¥æ•°æ®é€šè¿‡LLMè¿›è¡Œå¤„ç†ï¼Œæå–å…¶éšçŠ¶æ€ï¼Œç„¶åå¯¹éšçŠ¶æ€è¿›è¡Œèšç±»ï¼Œæœ€åç”Ÿæˆç›¸åº”çš„è¾“å‡ºã€‚

**å…³é”®åˆ›æ–°**ï¼šLSCçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶è½»é‡çº§å’Œä¸Šä¸‹æ–‡æ•æ„Ÿçš„èšç±»æ–¹æ³•ï¼ŒåŒºåˆ«äºä¼ ç»Ÿæ–¹æ³•ä¾èµ–å¤–éƒ¨æ¨¡å‹çš„åšæ³•ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—å¤æ‚åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒLSCé‡‡ç”¨äº†ç‰¹å®šçš„èšç±»ç®—æ³•ï¼Œä¼˜åŒ–äº†éšçŠ¶æ€çš„è¡¨ç¤ºï¼Œå¹¶é€šè¿‡å®éªŒéªŒè¯äº†ä¸åŒå‚æ•°è®¾ç½®å¯¹èšç±»æ•ˆæœçš„å½±å“ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ½œåœ¨è¯­ä¹‰èšç±»ï¼ˆLSCï¼‰æ–¹æ³•åœ¨å¤šä¸ªå¤§è¯­è¨€æ¨¡å‹ä¸Šå®ç°äº†è®¡ç®—æ•ˆç‡çš„æ˜¾è‘—æå‡ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨ç›¸åŒæ¡ä»¶ä¸‹ï¼Œè®¡ç®—æ—¶é—´å‡å°‘äº†çº¦30%ï¼ŒåŒæ—¶åœ¨æ€§èƒ½è¯„ä¼°ä¸­è¶…è¿‡äº†ç°æœ‰çš„åŸºçº¿æ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€å¯¹è¯ç³»ç»Ÿå’Œæ™ºèƒ½é—®ç­”ç­‰åœºæ™¯ã€‚é€šè¿‡æå‡å¤§è¯­è¨€æ¨¡å‹åœ¨æµ‹è¯•æ—¶çš„è®¡ç®—æ•ˆç‡ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ”¯æŒå®æ—¶åº”ç”¨å’Œå¤§è§„æ¨¡æ•°æ®å¤„ç†ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Scaling test-time computation--generating and analyzing multiple or sequential outputs for a single input--has become a promising strategy for improving the reliability and quality of large language models (LLMs), as evidenced by advances in uncertainty quantification and multi-step reasoning. A key shared component is semantic clustering, which groups outputs that differ in form but convey the same meaning. Semantic clustering enables estimation of the distribution over the semantics of outputs and helps avoid redundant exploration of reasoning paths. However, existing approaches typically rely on external models, which introduce substantial computational overhead and often fail to capture context-aware semantics. We propose Latent Semantic Clustering (LSC), a lightweight and context-sensitive method that leverages the generator LLM's internal hidden states for clustering, eliminating the need for external models. Our extensive experiment across various LLMs and datasets shows that LSC significantly improves the computational efficiency of test-time scaling while maintaining or exceeding the performance of existing methods.

