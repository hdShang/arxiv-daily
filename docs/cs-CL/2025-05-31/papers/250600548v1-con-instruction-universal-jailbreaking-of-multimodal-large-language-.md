---
layout: default
title: "Con Instruction: Universal Jailbreaking of Multimodal Large Language Models via Non-Textual Modalities"
---

# Con Instruction: Universal Jailbreaking of Multimodal Large Language Models via Non-Textual Modalities

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.00548" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.00548v1</a>
  <a href="https://arxiv.org/pdf/2506.00548.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.00548v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.00548v1', 'Con Instruction: Universal Jailbreaking of Multimodal Large Language Models via Non-Textual Modalities')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiahui Geng, Thy Thy Tran, Preslav Nakov, Iryna Gurevych

**åˆ†ç±»**: cs.CR, cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-31

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCon Instructionæ–¹æ³•ä»¥å®ç°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„æ™®éè¶Šç‹±**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹` `å¯¹æŠ—æ€§æ”»å‡»` `å®‰å…¨æœºåˆ¶` `éæ–‡æœ¬æŒ‡ä»¤` `åµŒå…¥ç©ºé—´ä¼˜åŒ–` `æ”»å‡»å“åº”åˆ†ç±»` `æ¨¡å‹é²æ£’æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–æ–‡æœ¬å’Œå¯¹æŠ—æ€§å›¾åƒè¿›è¡Œæ”»å‡»ï¼Œå­˜åœ¨ä¸€å®šçš„å±€é™æ€§ï¼Œéš¾ä»¥å……åˆ†åˆ©ç”¨å¤šæ¨¡æ€æ¨¡å‹çš„æ½œåŠ›ã€‚
2. æœ¬æ–‡æå‡ºçš„Con Instructionæ–¹æ³•èƒ½å¤Ÿç”Ÿæˆéæ–‡æœ¬å¯¹æŠ—æ ·æœ¬ï¼Œä¼˜åŒ–å…¶ä¸ç›®æ ‡æŒ‡ä»¤çš„å¯¹é½ï¼Œæ˜¾è‘—æå‡æ”»å‡»æ•ˆæœã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCon Instructionåœ¨å¤šä¸ªæ¨¡å‹ä¸Šå®ç°äº†æœ€é«˜çš„æ”»å‡»æˆåŠŸç‡ï¼Œç‰¹åˆ«æ˜¯åœ¨LLaVA-v1.5ä¸Šè¾¾åˆ°äº†81.3%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°æœ‰é’ˆå¯¹å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„æ”»å‡»ä¸»è¦é€šè¿‡æ–‡æœ¬å’Œå¯¹æŠ—æ€§å›¾åƒä¼ è¾¾æŒ‡ä»¤ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•Con Instructionï¼Œåˆ©ç”¨MLLMså¯¹éæ–‡æœ¬æŒ‡ä»¤çš„ç†è§£èƒ½åŠ›ï¼Œç”Ÿæˆå¯¹æŠ—æ€§å›¾åƒæˆ–éŸ³é¢‘ï¼Œå¹¶ä¼˜åŒ–è¿™äº›å¯¹æŠ—æ ·æœ¬ä»¥ä¸ç›®æ ‡æŒ‡ä»¤åœ¨åµŒå…¥ç©ºé—´ä¸­ç´§å¯†å¯¹é½ã€‚ä¸ä»¥å¾€ç ”ç©¶ä¸åŒï¼Œè¯¥æ–¹æ³•æ— éœ€è®­ç»ƒæ•°æ®æˆ–æ–‡æœ¬æŒ‡ä»¤çš„é¢„å¤„ç†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCon Instructionèƒ½å¤Ÿæœ‰æ•ˆç»•è¿‡å¤šç§è§†è§‰å’ŒéŸ³é¢‘è¯­è¨€æ¨¡å‹çš„å®‰å…¨æœºåˆ¶ï¼Œå¹¶åœ¨å¤šä¸ªæ ‡å‡†åŸºå‡†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ”»å‡»æˆåŠŸç‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹æ”»å‡»æ–¹æ³•çš„å±€é™æ€§ï¼Œç‰¹åˆ«æ˜¯å¯¹æ–‡æœ¬ä¾èµ–çš„ä¸è¶³ï¼Œå¯¼è‡´æ”»å‡»æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºCon Instructionæ–¹æ³•ï¼Œé€šè¿‡ç”Ÿæˆå¯¹æŠ—æ€§å›¾åƒæˆ–éŸ³é¢‘ï¼Œåˆ©ç”¨MLLMså¯¹éæ–‡æœ¬æŒ‡ä»¤çš„ç†è§£èƒ½åŠ›ï¼Œä¼˜åŒ–è¿™äº›æ ·æœ¬ä»¥æ›´å¥½åœ°ä¸ç›®æ ‡æŒ‡ä»¤å¯¹é½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•åŒ…æ‹¬ç”Ÿæˆå¯¹æŠ—æ ·æœ¬ã€ä¼˜åŒ–å¯¹é½è¿‡ç¨‹å’Œè¯„ä¼°æ¨¡å‹å“åº”ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆç”Ÿæˆéæ–‡æœ¬è¾“å…¥ï¼Œç„¶åé€šè¿‡åµŒå…¥ç©ºé—´ä¼˜åŒ–ä¸ç›®æ ‡æŒ‡ä»¤çš„å¯¹é½ï¼Œæœ€åä½¿ç”¨æ–°çš„æ”»å‡»å“åº”åˆ†ç±»æ¡†æ¶è¯„ä¼°æ•ˆæœã€‚

**å…³é”®åˆ›æ–°**ï¼šCon Instructionçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºæ— éœ€è®­ç»ƒæ•°æ®æˆ–æ–‡æœ¬é¢„å¤„ç†ï¼Œç›´æ¥åˆ©ç”¨éæ–‡æœ¬è¾“å…¥è¿›è¡Œæ”»å‡»ï¼Œçªç ´äº†ä»¥å¾€æ–¹æ³•çš„é™åˆ¶ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å¯¹æŠ—æ ·æœ¬ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ ·æœ¬ä¸ç›®æ ‡æŒ‡ä»¤çš„ç›¸ä¼¼åº¦ï¼ŒåŒæ—¶è®¾è®¡äº†æ–°çš„è¯„ä¼°æ¡†æ¶æ¥é‡åŒ–æ¨¡å‹å“åº”çš„è´¨é‡å’Œç›¸å…³æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒCon Instructionåœ¨å¤šä¸ªè§†è§‰å’ŒéŸ³é¢‘è¯­è¨€æ¨¡å‹ä¸Šæœ‰æ•ˆç»•è¿‡å®‰å…¨æœºåˆ¶ï¼Œå°¤å…¶åœ¨LLaVA-v1.5æ¨¡å‹ä¸Šå®ç°äº†81.3%çš„æ”»å‡»æˆåŠŸç‡ï¼Œè¾ƒä»¥å¾€æ–¹æ³•æœ‰æ˜¾è‘—æå‡ã€‚æ­¤å¤–ï¼Œç»“åˆæ–‡æœ¬è¾“å…¥åï¼Œæ”»å‡»æˆåŠŸç‡è¿›ä¸€æ­¥æé«˜ï¼Œæ˜¾ç¤ºå‡ºè¯¥æ–¹æ³•çš„å¼ºå¤§æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å®‰å…¨æ€§æµ‹è¯•ã€æ¨¡å‹é²æ£’æ€§è¯„ä¼°ä»¥åŠå¯¹æŠ—æ€§è®­ç»ƒç­‰ã€‚é€šè¿‡æ­ç¤ºå¤šæ¨¡æ€æ¨¡å‹çš„è„†å¼±æ€§ï¼Œç ”ç©¶è€…å’Œå¼€å‘è€…å¯ä»¥æ›´å¥½åœ°è®¾è®¡é˜²å¾¡æœºåˆ¶ï¼Œæå‡æ¨¡å‹çš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½åœ¨AIå®‰å…¨é¢†åŸŸäº§ç”Ÿæ·±è¿œå½±å“ï¼Œæ¨åŠ¨å¯¹æŠ—æ€§æ”»å‡»ä¸é˜²å¾¡æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Existing attacks against multimodal language models (MLLMs) primarily communicate instructions through text accompanied by adversarial images. In contrast, we exploit the capabilities of MLLMs to interpret non-textual instructions, specifically, adversarial images or audio generated by our novel method, Con Instruction. We optimize these adversarial examples to align closely with target instructions in the embedding space, revealing the detrimental implications of MLLMs' sophisticated understanding. Unlike prior work, our method does not require training data or preprocessing of textual instructions. While these non-textual adversarial examples can effectively bypass MLLM safety mechanisms, their combination with various text inputs substantially amplifies attack success. We further introduce a new Attack Response Categorization (ARC) framework, which evaluates both the quality of the model's response and its relevance to the malicious instructions. Experimental results demonstrate that Con Instruction effectively bypasses safety mechanisms in multiple vision- and audio-language models, including LLaVA-v1.5, InternVL, Qwen-VL, and Qwen-Audio, evaluated on two standard benchmarks: AdvBench and SafeBench. Specifically, our method achieves the highest attack success rates, reaching 81.3% and 86.6% on LLaVA-v1.5 (13B). On the defense side, we explore various countermeasures against our attacks and uncover a substantial performance gap among existing techniques. Our implementation is made publicly available.

