---
layout: default
title: "Measuring Faithfulness and Abstention: An Automated Pipeline for Evaluating LLM-Generated 3-ply Case-Based Legal Arguments"
---

# Measuring Faithfulness and Abstention: An Automated Pipeline for Evaluating LLM-Generated 3-ply Case-Based Legal Arguments

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.00694" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.00694v2</a>
  <a href="https://arxiv.org/pdf/2506.00694.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.00694v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.00694v2', 'Measuring Faithfulness and Abstention: An Automated Pipeline for Evaluating LLM-Generated 3-ply Case-Based Legal Arguments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Li Zhang, Morgan Gray, Jaromir Savelka, Kevin D. Ashley

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-31 (æ›´æ–°: 2025-06-03)

**å¤‡æ³¨**: 11 pages, 7th Workshop on Automated Semantic Analysis of Information in Legal Text @ ICAIL 2025, 16 June 2025, Chicago, IL

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://lizhang-aiandlaw.github.io/An-Automated-Pipeline-for-Evaluating-LLM-Generated-3-ply-Case-Based-Legal-Arguments/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè‡ªåŠ¨åŒ–è¯„ä¼°ç®¡é“ä»¥è§£å†³LLMç”Ÿæˆæ³•å¾‹è®ºè¯çš„å¯é æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ³•å¾‹è®ºè¯` `è‡ªåŠ¨åŒ–è¯„ä¼°` `å› ç´ æå–` `å¹»è§‰æ£€æµ‹` `å¼ƒæƒèƒ½åŠ›` `æœºå™¨å­¦ä¹ ` `æ³•å¾‹æŠ€æœ¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ³•å¾‹è®ºè¯ç”Ÿæˆä¸­çš„å¯é æ€§ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨é¿å…å¹»è§‰å’Œé€‚å½“å¼ƒæƒæ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§è‡ªåŠ¨åŒ–è¯„ä¼°ç®¡é“ï¼Œé€šè¿‡å¤–éƒ¨LLMæå–å› ç´ å¹¶ä¸çœŸå®æ¡ˆä¾‹è¿›è¡Œæ¯”è¾ƒï¼Œè¯„ä¼°LLMçš„ç”Ÿæˆèƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå°½ç®¡LLMåœ¨é¿å…å¹»è§‰æ–¹é¢è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨å› ç´ åˆ©ç”¨å’Œéµå¾ªå¼ƒæƒæŒ‡ä»¤ä¸Šå­˜åœ¨æ˜¾è‘—ä¸è¶³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤æ‚æ³•å¾‹ä»»åŠ¡å¦‚è®ºè¯ç”Ÿæˆä¸­å±•ç°å‡ºæ½œåŠ›ï¼Œä½†å…¶å¯é æ€§ä»ç„¶ä»¤äººæ‹…å¿§ã€‚æœ¬æ–‡åœ¨å…ˆå‰äººç±»è¯„ä¼°çš„åŸºç¡€ä¸Šï¼Œæå‡ºäº†ä¸€ç§è‡ªåŠ¨åŒ–è¯„ä¼°ç®¡é“ï¼Œä¸“æ³¨äºè¯„ä¼°LLMåœ¨ç”Ÿæˆä¸‰å±‚æ³•å¾‹è®ºè¯æ—¶çš„çœŸå®æ€§ï¼ˆæ— å¹»è§‰ï¼‰ã€å› ç´ åˆ©ç”¨å’Œé€‚å½“çš„å¼ƒæƒèƒ½åŠ›ã€‚æˆ‘ä»¬å®šä¹‰å¹»è§‰ä¸ºç”Ÿæˆè¾“å…¥æ¡ˆä¾‹ææ–™ä¸­ä¸å­˜åœ¨çš„å› ç´ ï¼Œè€Œå¼ƒæƒåˆ™æ˜¯æ¨¡å‹åœ¨æ²¡æœ‰äº‹å®ä¾æ®æ—¶éµå¾ªæŒ‡ä»¤ä¸ç”Ÿæˆè®ºè¯çš„èƒ½åŠ›ã€‚é€šè¿‡å¤–éƒ¨LLMæå–ç”Ÿæˆè®ºè¯ä¸­çš„å› ç´ ï¼Œå¹¶ä¸è¾“å…¥æ¡ˆä¾‹ä¸‰å…ƒç»„ä¸­çš„çœŸå®å› ç´ è¿›è¡Œæ¯”è¾ƒï¼Œæˆ‘ä»¬å¯¹å…«ç§ä¸åŒçš„LLMè¿›è¡Œäº†ä¸‰é¡¹éš¾åº¦é€’å¢çš„æµ‹è¯•ã€‚ç»“æœè¡¨æ˜ï¼Œå°½ç®¡å½“å‰LLMåœ¨å¯è¡Œè®ºè¯ç”Ÿæˆæµ‹è¯•ä¸­é¿å…å¹»è§‰çš„å‡†ç¡®ç‡è¶…è¿‡90%ï¼Œä½†å®ƒä»¬å¾€å¾€æœªèƒ½å……åˆ†åˆ©ç”¨æ¡ˆä¾‹ä¸­çš„ç›¸å…³å› ç´ ã€‚å°¤å…¶æ˜¯åœ¨å¼ƒæƒæµ‹è¯•ä¸­ï¼Œå¤§å¤šæ•°æ¨¡å‹æœªèƒ½éµå¾ªåœæ­¢æŒ‡ä»¤ï¼Œåè€Œç”Ÿæˆäº†è™šå‡çš„è®ºè¯ã€‚è¯¥è‡ªåŠ¨åŒ–ç®¡é“ä¸ºè¯„ä¼°è¿™äº›å…³é”®LLMè¡Œä¸ºæä¾›äº†ä¸€ç§å¯æ‰©å±•çš„æ–¹æ³•ï¼Œå¼ºè°ƒåœ¨æ³•å¾‹ç¯å¢ƒä¸­å¯é éƒ¨ç½²ä¹‹å‰éœ€è¦æ”¹å–„å› ç´ åˆ©ç”¨å’Œå¼ºå¥çš„å¼ƒæƒèƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆæ³•å¾‹è®ºè¯æ—¶çš„å¯é æ€§é—®é¢˜ï¼Œå°¤å…¶æ˜¯å¹»è§‰å’Œå¼ƒæƒèƒ½åŠ›ä¸è¶³çš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äººå·¥è¯„ä¼°ï¼Œæ•ˆç‡ä½ä¸”ä¸»è§‚æ€§å¼ºã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºä¸€ç§è‡ªåŠ¨åŒ–è¯„ä¼°ç®¡é“ï¼Œåˆ©ç”¨å¤–éƒ¨LLMæå–ç”Ÿæˆè®ºè¯ä¸­çš„å› ç´ ï¼Œå¹¶ä¸è¾“å…¥æ¡ˆä¾‹çš„çœŸå®å› ç´ è¿›è¡Œæ¯”è¾ƒï¼Œä»¥é‡åŒ–LLMçš„è¡¨ç°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥ç®¡é“åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š1) ç”Ÿæˆè®ºè¯çš„LLMï¼›2) å¤–éƒ¨LLMç”¨äºå› ç´ æå–ï¼›3) è¯„ä¼°æ¨¡å—å¯¹æ¯”ç”Ÿæˆå› ç´ ä¸çœŸå®å› ç´ ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥è‡ªåŠ¨åŒ–è¯„ä¼°æœºåˆ¶ï¼Œèƒ½å¤Ÿé«˜æ•ˆã€å®¢è§‚åœ°è¯„ä¼°LLMåœ¨æ³•å¾‹è®ºè¯ç”Ÿæˆä¸­çš„è¡¨ç°ï¼Œå…‹æœäº†ä¼ ç»Ÿäººå·¥è¯„ä¼°çš„å±€é™ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œè®¾ç½®äº†ä¸‰é¡¹éš¾åº¦é€’å¢çš„æµ‹è¯•ï¼Œåˆ†åˆ«è¯„ä¼°æ ‡å‡†è®ºè¯ç”Ÿæˆã€è§’è‰²äº’æ¢è®ºè¯ç”Ÿæˆå’Œç¼ºä¹å…±åŒå› ç´ æ—¶çš„å¼ƒæƒèƒ½åŠ›ï¼Œç¡®ä¿å…¨é¢è¯„ä¼°LLMçš„æ€§èƒ½ã€‚å®éªŒä¸­ä½¿ç”¨çš„æŸå¤±å‡½æ•°å’Œå‚æ•°è®¾ç½®ç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›å’Œéµå¾ªæŒ‡ä»¤çš„èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå½“å‰LLMåœ¨å¯è¡Œè®ºè¯ç”Ÿæˆæµ‹è¯•ä¸­é¿å…å¹»è§‰çš„å‡†ç¡®ç‡è¶…è¿‡90%ã€‚ç„¶è€Œï¼Œåœ¨å¼ƒæƒæµ‹è¯•ä¸­ï¼Œå¤§å¤šæ•°æ¨¡å‹æœªèƒ½éµå¾ªæŒ‡ä»¤ï¼Œç”Ÿæˆäº†è™šå‡çš„è®ºè¯ï¼Œè¡¨æ˜åœ¨å› ç´ åˆ©ç”¨å’Œå¼ƒæƒèƒ½åŠ›æ–¹é¢ä»éœ€æ˜¾è‘—æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ³•å¾‹æŠ€æœ¯ã€æ™ºèƒ½æ³•å¾‹å’¨è¯¢å’Œæ³•å¾‹æ•™è‚²ç­‰ã€‚é€šè¿‡æé«˜LLMåœ¨æ³•å¾‹è®ºè¯ç”Ÿæˆä¸­çš„å¯é æ€§ï¼Œå¯ä»¥ä¸ºæ³•å¾‹ä¸“ä¸šäººå£«æä¾›æ›´ä¸ºå‡†ç¡®çš„æ”¯æŒï¼Œæå‡æ³•å¾‹æœåŠ¡çš„æ•ˆç‡å’Œè´¨é‡ã€‚æœªæ¥ï¼Œéšç€æŠ€æœ¯çš„è¿›æ­¥ï¼Œè¯¥è¯„ä¼°ç®¡é“æœ‰æœ›åœ¨æ›´å¤šå¤æ‚çš„æ³•å¾‹åœºæ™¯ä¸­å¾—åˆ°åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) demonstrate potential in complex legal tasks like argument generation, yet their reliability remains a concern. Building upon pilot work assessing LLM generation of 3-ply legal arguments using human evaluation, this paper introduces an automated pipeline to evaluate LLM performance on this task, specifically focusing on faithfulness (absence of hallucination), factor utilization, and appropriate abstention. We define hallucination as the generation of factors not present in the input case materials and abstention as the model's ability to refrain from generating arguments when instructed and no factual basis exists. Our automated method employs an external LLM to extract factors from generated arguments and compares them against the ground-truth factors provided in the input case triples (current case and two precedent cases). We evaluated eight distinct LLMs on three tests of increasing difficulty: 1) generating a standard 3-ply argument, 2) generating an argument with swapped precedent roles, and 3) recognizing the impossibility of argument generation due to lack of shared factors and abstaining. Our findings indicate that while current LLMs achieve high accuracy (over 90%) in avoiding hallucination on viable argument generation tests (Tests 1 & 2), they often fail to utilize the full set of relevant factors present in the cases. Critically, on the abstention test (Test 3), most models failed to follow instructions to stop, instead generating spurious arguments despite the lack of common factors. This automated pipeline provides a scalable method for assessing these crucial LLM behaviors, highlighting the need for improvements in factor utilization and robust abstention capabilities before reliable deployment in legal settings. Link: https://lizhang-aiandlaw.github.io/An-Automated-Pipeline-for-Evaluating-LLM-Generated-3-ply-Case-Based-Legal-Arguments/

