---
layout: default
title: Decoupling Reasoning and Knowledge Injection for In-Context Knowledge Editing
---

# Decoupling Reasoning and Knowledge Injection for In-Context Knowledge Editing

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.00536" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.00536v1</a>
  <a href="https://arxiv.org/pdf/2506.00536.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.00536v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.00536v1', 'Decoupling Reasoning and Knowledge Injection for In-Context Knowledge Editing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Changyue Wang, Weihang Su, Qingyao Ai, Yujia Zhou, Yiqun Liu

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-31

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/bebr2/DecKER)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDecKERä»¥è§£å†³çŸ¥è¯†ç¼–è¾‘ä¸­çš„æ¨ç†ä¸çŸ¥è¯†æ³¨å…¥è€¦åˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `çŸ¥è¯†ç¼–è¾‘` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ¨ç†è§£è€¦` `å¤šè·³é—®ç­”` `ä¸Šä¸‹æ–‡ç¼–è¾‘` `æ··åˆæ£€ç´¢` `æ¨¡å‹éªŒè¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çŸ¥è¯†ç¼–è¾‘æ–¹æ³•æœªèƒ½æœ‰æ•ˆåˆ†ç¦»æ–°æ³¨å…¥çŸ¥è¯†ä¸æ¨¡å‹æ¨ç†è¿‡ç¨‹ï¼Œå¯¼è‡´çŸ¥è¯†å†²çªå’Œæ¨ç†ä¸ä¸€è‡´ã€‚
2. æœ¬æ–‡æå‡ºDecKERæ¡†æ¶ï¼Œé€šè¿‡ç”Ÿæˆæ©ç æ¨ç†è·¯å¾„ï¼Œç»“åˆæ··åˆæ£€ç´¢å’Œæ¨¡å‹éªŒè¯ï¼Œå®ç°æ¨ç†ä¸çŸ¥è¯†ç¼–è¾‘çš„è§£è€¦ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDecKERåœ¨å¤šè·³é—®ç­”ä»»åŠ¡ä¸­æ˜¾è‘—æå‡äº†æ€§èƒ½ï¼Œå‡è½»äº†çŸ¥è¯†å†²çªï¼Œä¿æŒäº†æ¨ç†çš„ä¸€è‡´æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

çŸ¥è¯†ç¼–è¾‘æ—¨åœ¨é«˜æ•ˆæ›´æ–°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ï¼Œé€šè¿‡ä¿®æ”¹ç‰¹å®šçŸ¥è¯†è€Œæ— éœ€é‡æ–°è®­ç»ƒæ•´ä¸ªæ¨¡å‹ã€‚åœ¨ç°æœ‰çš„çŸ¥è¯†ç¼–è¾‘æ–¹æ³•ä¸­ï¼ŒåŸºäºä¸Šä¸‹æ–‡çš„ç¼–è¾‘ï¼ˆICEï¼‰æä¾›äº†ä¸€ç§è½»é‡çº§çš„è§£å†³æ–¹æ¡ˆï¼Œé€šè¿‡ç›´æ¥å°†æ–°çŸ¥è¯†æ³¨å…¥è¾“å…¥ä¸Šä¸‹æ–‡ä¸­æ¥å®ç°ï¼Œè€Œä¸æ”¹å˜æ¨¡å‹å‚æ•°ã€‚ç„¶è€Œï¼Œç°æœ‰ICEæ–¹æ³•æœªèƒ½æ˜ç¡®åˆ†ç¦»æ–°æ³¨å…¥çŸ¥è¯†ä¸æ¨¡å‹åŸæœ‰æ¨ç†è¿‡ç¨‹ä¹‹é—´çš„å…³ç³»ã€‚è¿™ç§è€¦åˆå¸¸å¸¸å¯¼è‡´å¤–éƒ¨æ›´æ–°ä¸å†…éƒ¨å‚æ•°çŸ¥è¯†ä¹‹é—´çš„å†²çªï¼Œä»è€Œå‰Šå¼±æ¨ç†è·¯å¾„çš„ä¸€è‡´æ€§å’Œå‡†ç¡®æ€§ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†DecKERï¼Œä¸€ä¸ªæ–°é¢–çš„ICEæ¡†æ¶ï¼Œé€šè¿‡ç”Ÿæˆæ©ç æ¨ç†è·¯å¾„å¹¶é€šè¿‡æ··åˆæ£€ç´¢å’ŒåŸºäºæ¨¡å‹çš„éªŒè¯æ¥è§£å†³çŸ¥è¯†ç¼–è¾‘ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDecKERåœ¨å¤šè·³é—®ç­”åŸºå‡†ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰ICEæ–¹æ³•ï¼Œå‡è½»äº†çŸ¥è¯†å†²çªå¹¶ä¿æŒäº†æ¨ç†ä¸€è‡´æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³çŸ¥è¯†ç¼–è¾‘è¿‡ç¨‹ä¸­æ¨ç†ä¸çŸ¥è¯†æ³¨å…¥ä¹‹é—´çš„è€¦åˆé—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨æ³¨å…¥æ–°çŸ¥è¯†æ—¶æœªèƒ½é€‚åº”æ¨ç†è·¯å¾„ï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ï¼Œå°¤å…¶æ˜¯åœ¨å¤šè·³ä»»åŠ¡ä¸­ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDecKERé€šè¿‡ç”Ÿæˆæ©ç æ¨ç†è·¯å¾„ï¼Œå°†æ¨ç†è¿‡ç¨‹ä¸çŸ¥è¯†ç¼–è¾‘è§£è€¦ã€‚è¿™æ ·è®¾è®¡çš„ç›®çš„æ˜¯ä¸ºäº†å‡å°‘æ–°çŸ¥è¯†ä¸åŸæœ‰çŸ¥è¯†ä¹‹é—´çš„å†²çªï¼Œæå‡æ¨ç†çš„ä¸€è‡´æ€§å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDecKERçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆç”Ÿæˆæ©ç æ¨ç†è·¯å¾„ï¼Œç„¶åé€šè¿‡æ··åˆæ£€ç´¢å’Œæ¨¡å‹éªŒè¯æ¥è§£å†³çŸ¥è¯†ç¼–è¾‘ã€‚è¿™ä¸€æµç¨‹ç¡®ä¿äº†æ–°çŸ¥è¯†çš„æœ‰æ•ˆæ•´åˆã€‚

**å…³é”®åˆ›æ–°**ï¼šDecKERçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶è§£è€¦æ¨ç†ä¸çŸ¥è¯†ç¼–è¾‘çš„èƒ½åŠ›ï¼Œæ˜¾è‘—åŒºåˆ«äºä¼ ç»ŸICEæ–¹æ³•ï¼Œåè€…å¾€å¾€å°†ä¸¤è€…ç´§å¯†ç»“åˆï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼ŒDecKERé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ¨ç†è·¯å¾„çš„ç”Ÿæˆï¼Œå¹¶é€šè¿‡å¤šç§æ£€ç´¢ç­–ç•¥ç¡®ä¿æ–°çŸ¥è¯†çš„æœ‰æ•ˆæ€§ä¸ä¸€è‡´æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒDecKERåœ¨å¤šè·³é—®ç­”åŸºå‡†ä¸Šç›¸è¾ƒäºç°æœ‰ICEæ–¹æ³•æ€§èƒ½æå‡æ˜¾è‘—ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨å¤šä¸ªä»»åŠ¡ä¸Šå‡†ç¡®ç‡æé«˜äº†10%ä»¥ä¸Šï¼ŒæˆåŠŸå‡è½»äº†çŸ¥è¯†å†²çªï¼Œä¿æŒäº†æ¨ç†è·¯å¾„çš„ä¸€è‡´æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€çŸ¥è¯†ç®¡ç†å¹³å°å’Œå¯¹è¯ç³»ç»Ÿç­‰ã€‚é€šè¿‡æé«˜çŸ¥è¯†ç¼–è¾‘çš„æ•ˆç‡ä¸å‡†ç¡®æ€§ï¼ŒDecKERèƒ½å¤Ÿåœ¨å®é™…åº”ç”¨ä¸­æ˜¾è‘—æå‡ç”¨æˆ·ä½“éªŒå’Œç³»ç»Ÿæ€§èƒ½ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Knowledge editing aims to efficiently update Large Language Models (LLMs) by modifying specific knowledge without retraining the entire model. Among knowledge editing approaches, in-context editing (ICE) offers a lightweight solution by injecting new knowledge directly into the input context, leaving model parameters unchanged. However, existing ICE approaches do not explicitly separate the newly injected knowledge from the model's original reasoning process. This entanglement often results in conflicts between external updates and internal parametric knowledge, undermining the consistency and accuracy of the reasoning path.In this work, we conduct preliminary experiments to examine how parametric knowledge influences reasoning path planning. We find that the model's reasoning is tightly coupled with its internal knowledge, and that naively injecting new information without adapting the reasoning path often leads to performance degradation, particularly in multi-hop tasks. To this end, we propose DecKER, a novel ICE framework that decouples reasoning from knowledge editing by generating a masked reasoning path and then resolving knowledge edits via hybrid retrieval and model-based validation. Experiments on multi-hop QA benchmarks show that DecKER significantly outperforms existing ICE methods by mitigating knowledge conflicts and preserving reasoning consistency. Our code is available at: https://github.com/bebr2/DecKER .

