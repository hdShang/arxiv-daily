---
layout: default
title: "OWSM v4: Improving Open Whisper-Style Speech Models via Data Scaling and Cleaning"
---

# OWSM v4: Improving Open Whisper-Style Speech Models via Data Scaling and Cleaning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.00338" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.00338v1</a>
  <a href="https://arxiv.org/pdf/2506.00338.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.00338v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.00338v1', 'OWSM v4: Improving Open Whisper-Style Speech Models via Data Scaling and Cleaning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yifan Peng, Shakeel Muhammad, Yui Sudo, William Chen, Jinchuan Tian, Chyi-Jiunn Lin, Shinji Watanabe

**åˆ†ç±»**: cs.CL, cs.SD, eess.AS

**å‘å¸ƒæ—¥æœŸ**: 2025-05-31

**å¤‡æ³¨**: Accepted at INTERSPEECH 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é€šè¿‡æ•°æ®æ‰©å±•ä¸æ¸…æ´—æå‡OWSM v4è¯­éŸ³æ¨¡å‹æ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯­éŸ³æ¨¡å‹` `æ•°æ®æ¸…æ´—` `å¤šè¯­è¨€å¤„ç†` `æœºå™¨å­¦ä¹ ` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„OWSMæ¨¡å‹è®­ç»ƒæ•°æ®ä¸è¶³ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½å—é™ï¼Œå°¤å…¶æ˜¯åœ¨å¤šè¯­è¨€åœºæ™¯ä¸­è¡¨ç°ä¸ä½³ã€‚
2. æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ•°æ®æ¸…æ´—ç®¡é“ï¼Œç»“åˆYODASæ•°æ®é›†ï¼Œè§£å†³äº†æ•°æ®ä¸­çš„è¯­è¨€æ ‡ç­¾é”™è¯¯å’ŒéŸ³é¢‘æ–‡æœ¬ä¸å¯¹é½é—®é¢˜ã€‚
3. ç»è¿‡è®­ç»ƒçš„æ–°OWSM v4æ¨¡å‹åœ¨å¤šè¯­è¨€åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œç”šè‡³ä¸è¡Œä¸šé¢†å…ˆæ¨¡å‹ç›¸åª²ç¾ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

Open Whisperé£æ ¼è¯­éŸ³æ¨¡å‹ï¼ˆOWSMï¼‰é¡¹ç›®å¼€å‘äº†ä¸€ç³»åˆ—å®Œå…¨å¼€æ”¾çš„è¯­éŸ³åŸºç¡€æ¨¡å‹ï¼Œä½†å…¶è®­ç»ƒæ•°æ®ä»æ˜¾ä¸è¶³ã€‚æœ¬ç ”ç©¶é€šè¿‡æ•´åˆYODASï¼Œä¸€ä¸ªå…·æœ‰åˆ›ä½œå…±ç”¨è®¸å¯è¯çš„å¤§è§„æ¨¡ç½‘ç»œçˆ¬å–æ•°æ®é›†ï¼Œæ¥å¢å¼ºOWSMã€‚ç„¶è€Œï¼Œç”±äºYODASæ•°æ®çš„å¤æ‚æ€§ï¼Œå­˜åœ¨è¯­è¨€æ ‡ç­¾é”™è¯¯å’ŒéŸ³é¢‘æ–‡æœ¬ä¸å¯¹é½ç­‰æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªå¯æ‰©å±•çš„æ•°æ®æ¸…æ´—ç®¡é“ï¼Œä½¿ç”¨å…¬å…±å·¥å…·åŒ…ï¼Œç”Ÿæˆäº†ä¸€ä¸ªåŒ…å«75ç§è¯­è¨€ã€166,000å°æ—¶è¯­éŸ³çš„æ•°æ®é›†ã€‚æ–°ä¸€ç³»åˆ—OWSM v4æ¨¡å‹åœ¨è¯¥æ¸…æ´—æ•°æ®é›†å’Œç°æœ‰OWSMæ•°æ®ä¸Šè®­ç»ƒï¼Œæ˜¾è‘—è¶…è¶Šäº†ä¹‹å‰ç‰ˆæœ¬ï¼Œå¹¶åœ¨å¤šè¯­è¨€åŸºå‡†æµ‹è¯•ä¸­ä¸å‰æ²¿å·¥ä¸šæ¨¡å‹å¦‚Whisperå’ŒMMSç›¸åŒ¹é…æˆ–è¶…è¶Šã€‚æˆ‘ä»¬å°†é€šè¿‡ESPnetå·¥å…·åŒ…å…¬å¼€æ¸…æ´—åçš„YODASæ•°æ®ã€é¢„è®­ç»ƒæ¨¡å‹åŠæ‰€æœ‰ç›¸å…³è„šæœ¬ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³OWSMæ¨¡å‹è®­ç»ƒæ•°æ®ä¸è¶³çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤šè¯­è¨€å¤„ç†ä¸Šè¡¨ç°ä¸ä½³ï¼Œä¸”æ•°æ®è´¨é‡å‚å·®ä¸é½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ•´åˆYODASæ•°æ®é›†å¹¶å¼€å‘æ•°æ®æ¸…æ´—ç®¡é“ï¼Œç¡®ä¿æ•°æ®çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ï¼Œä»è€Œæå‡æ¨¡å‹çš„è®­ç»ƒæ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ•°æ®æ¸…æ´—ã€æ¨¡å‹è®­ç»ƒä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚æ•°æ®æ¸…æ´—é˜¶æ®µä½¿ç”¨å…¬å…±å·¥å…·åŒ…å¯¹YODASæ•°æ®è¿›è¡Œå¤„ç†ï¼Œç¡®ä¿å…¶é€‚ç”¨äºæ¨¡å‹è®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„å…³é”®åˆ›æ–°åœ¨äºå¼€å‘äº†ä¸€ä¸ªå¯æ‰©å±•çš„æ•°æ®æ¸…æ´—ç®¡é“ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¤„ç†å¤§è§„æ¨¡ã€å¤æ‚çš„ç½‘ç»œçˆ¬å–æ•°æ®ï¼Œè§£å†³äº†éŸ³é¢‘ä¸æ–‡æœ¬å¯¹é½çš„é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®æ¸…æ´—è¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†å¤šç§ç®—æ³•æ¥è¯†åˆ«å’Œä¿®æ­£è¯­è¨€æ ‡ç­¾é”™è¯¯ï¼Œç¡®ä¿ç”Ÿæˆçš„æ•°æ®é›†å…·æœ‰é«˜è´¨é‡ï¼ŒåŒæ—¶åœ¨æ¨¡å‹è®­ç»ƒä¸­ä½¿ç”¨äº†æ”¹è¿›çš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–å¤šè¯­è¨€å­¦ä¹ æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒOWSM v4æ¨¡å‹åœ¨å¤šè¯­è¨€åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—è¶…è¶Šäº†ä¹‹å‰ç‰ˆæœ¬ï¼Œæ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œä¸”åœ¨å¤šä¸ªåœºæ™¯ä¸­ä¸é¢†å…ˆçš„å·¥ä¸šæ¨¡å‹å¦‚Whisperå’ŒMMSç›¸åŒ¹é…æˆ–è¶…è¶Šï¼Œå±•ç¤ºäº†å…¶å¼ºå¤§çš„å®é™…åº”ç”¨èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æˆæœå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨å¤šè¯­è¨€è¯­éŸ³è¯†åˆ«ã€ç¿»è¯‘å’Œäººæœºäº¤äº’ç­‰é¢†åŸŸã€‚é€šè¿‡æä¾›é«˜è´¨é‡çš„è¯­éŸ³æ¨¡å‹ï¼Œèƒ½å¤Ÿæå‡è¯­éŸ³åŠ©æ‰‹ã€ç¿»è¯‘è½¯ä»¶ç­‰äº§å“çš„ç”¨æˆ·ä½“éªŒï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ä¸æ™®åŠã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The Open Whisper-style Speech Models (OWSM) project has developed a series of fully open speech foundation models using academic-scale resources, but their training data remains insufficient. This work enhances OWSM by integrating YODAS, a large-scale web-crawled dataset with a Creative Commons license. However, incorporating YODAS is nontrivial due to its wild nature, which introduces challenges such as incorrect language labels and audio-text misalignments. To address this, we develop a scalable data-cleaning pipeline using public toolkits, yielding a dataset with 166,000 hours of speech across 75 languages. Our new series of OWSM v4 models, trained on this curated dataset alongside existing OWSM data, significantly outperform previous versions on multilingual benchmarks. Our models even match or surpass frontier industrial models like Whisper and MMS in multiple scenarios. We will publicly release the cleaned YODAS data, pre-trained models, and all associated scripts via the ESPnet toolkit.

