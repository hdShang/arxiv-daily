---
layout: default
title: Structured Gradient Guidance for Few-Shot Adaptation in Large Language Models
---

# Structured Gradient Guidance for Few-Shot Adaptation in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.00726" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.00726v1</a>
  <a href="https://arxiv.org/pdf/2506.00726.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.00726v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.00726v1', 'Structured Gradient Guidance for Few-Shot Adaptation in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hongye Zheng, Yichen Wang, Ray Pan, Guiran Liu, Binrong Zhu, Hanlu Zhang

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-31

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»“æ„åŒ–æ¢¯åº¦å¼•å¯¼æ–¹æ³•ä»¥è§£å†³å°‘æ ·æœ¬é€‚åº”é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å°‘æ ·æœ¬å­¦ä¹ ` `æ¢¯åº¦å¼•å¯¼` `å¾®è°ƒæ–¹æ³•` `è‡ªç„¶è¯­è¨€å¤„ç†` `è·¨ä»»åŠ¡æ³›åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¾®è°ƒæ–¹æ³•åœ¨å°‘æ ·æœ¬æ¡ä»¶ä¸‹å¸¸å¸¸é¢ä¸´ä»»åŠ¡é€‚åº”æ€§å·®å’Œè®­ç»ƒä¸ç¨³å®šçš„é—®é¢˜ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ¢¯åº¦å¼•å¯¼çš„å¾®è°ƒæ–¹æ³•ï¼Œé€šè¿‡å¼•å…¥æ¢¯åº¦æ–¹å‘ä¸€è‡´æ€§å’Œå¹…åº¦æ§åˆ¶çš„æ­£åˆ™åŒ–é¡¹æ¥ä¼˜åŒ–å‚æ•°æ›´æ–°ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªè‡ªç„¶è¯­è¨€ç†è§£ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæå‡äº†å¹³å‡å‡†ç¡®ç‡å’Œæ¢¯åº¦ç¨³å®šæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åœ¨å°‘æ ·æœ¬æ¡ä»¶ä¸‹å¯¹å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œæ¢¯åº¦å¼•å¯¼å¾®è°ƒçš„æ–¹æ³•ï¼Œæ—¨åœ¨æé«˜ä»»åŠ¡é€‚åº”æ€§å’Œè®­ç»ƒç¨³å®šæ€§ã€‚è¯¥æ–¹æ³•åŸºäºåŸºç¡€æŸå¤±å‡½æ•°ï¼Œå¼•å…¥ä¸¤ä¸ªä¸æ¢¯åº¦ç›¸å…³çš„æ­£åˆ™åŒ–é¡¹ï¼Œåˆ†åˆ«ç”¨äºä¿æŒæ¢¯åº¦æ–¹å‘ä¸€è‡´æ€§å’Œæ§åˆ¶æ¢¯åº¦å¹…åº¦ï¼Œä»è€Œæ”¯æŒæ›´é«˜æ•ˆå’Œç¨³å®šçš„ä¼˜åŒ–è·¯å¾„ã€‚æ­¤å¤–ï¼Œæ–¹æ³•è¿˜ç»“åˆäº†æ¢¯åº¦å¯¹é½æœºåˆ¶ï¼Œä»¥å¢å¼ºè·¨ä»»åŠ¡çš„æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§è‡ªç„¶è¯­è¨€ç†è§£ä»»åŠ¡ä¸­è¶…è¶Šäº†ç°æœ‰å¾®è°ƒç­–ç•¥ï¼Œå±•ç°å‡ºåœ¨ä½èµ„æºç¯å¢ƒä¸‹çš„é²æ£’æ€§å’Œå¹¿æ³›é€‚ç”¨æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨å°‘æ ·æœ¬æ¡ä»¶ä¸‹å¤§å‹è¯­è¨€æ¨¡å‹å¾®è°ƒçš„ä»»åŠ¡é€‚åº”æ€§å’Œè®­ç»ƒç¨³å®šæ€§ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨æ•°æ®æœ‰é™æ—¶ï¼Œå®¹æ˜“å¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸‹é™å’Œè®­ç»ƒä¸ç¨³å®šã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºäº†ä¸€ç§æ¢¯åº¦å¼•å¯¼çš„å¾®è°ƒæ–¹æ³•ï¼Œé€šè¿‡å¼•å…¥ä¸¤ä¸ªæ­£åˆ™åŒ–é¡¹æ¥å¼•å¯¼å‚æ•°æ›´æ–°ï¼Œç¡®ä¿æ›´æ–°æ–¹å‘ä¸ä»»åŠ¡ç›¸å…³å¹¶æ§åˆ¶æ›´æ–°å¹…åº¦ï¼Œä»è€Œæé«˜ä¼˜åŒ–è¿‡ç¨‹çš„ç¨³å®šæ€§å’Œæ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ–¹æ³•åŒ…æ‹¬åŸºç¡€æŸå¤±å‡½æ•°å’Œä¸¤ä¸ªæ¢¯åº¦ç›¸å…³çš„æ­£åˆ™åŒ–é¡¹ï¼Œé¦–å…ˆç¡®ä¿æ¢¯åº¦æ–¹å‘çš„ä¸€è‡´æ€§ï¼Œç„¶åæ§åˆ¶æ¢¯åº¦çš„å¹…åº¦ã€‚æ­¤å¤–ï¼ŒåŠ å…¥æ¢¯åº¦å¯¹é½æœºåˆ¶ä»¥å¢å¼ºè·¨ä»»åŠ¡çš„æ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†æ¢¯åº¦æ–¹å‘ä¸€è‡´æ€§å’Œå¹…åº¦æ§åˆ¶çš„æ­£åˆ™åŒ–é¡¹ï¼Œè¿™ä¸ä¼ ç»Ÿçš„å¾®è°ƒæ–¹æ³•ä¸åŒï¼Œåè€…é€šå¸¸å¿½è§†äº†æ¢¯åº¦çš„è¿™äº›ç‰¹æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŸå¤±å‡½æ•°ä¸­ï¼Œè®¾è®¡äº†ä¸¤ä¸ªæ­£åˆ™åŒ–é¡¹ï¼Œåˆ†åˆ«ç”¨äºä¿æŒæ¢¯åº¦æ–¹å‘ä¸€è‡´æ€§å’Œæ§åˆ¶æ¢¯åº¦å¹…åº¦ï¼Œç¡®ä¿å‚æ•°æ›´æ–°æ²¿ç€ä»»åŠ¡ç›¸å…³çš„æ–¹å‘è¿›è¡Œï¼Œé¿å…å¼‚å¸¸æ›´æ–°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªè‡ªç„¶è¯­è¨€ç†è§£ä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰å¾®è°ƒç­–ç•¥ï¼Œå¹³å‡å‡†ç¡®ç‡æå‡å¹…åº¦è¾¾åˆ°X%ï¼ŒåŒæ—¶åœ¨æ¢¯åº¦ç¨³å®šæ€§å’Œæ–¹å‘ä¸€è‡´æ€§æ–¹é¢è¡¨ç°å‡ºè‰²ï¼ŒéªŒè¯äº†å…¶åœ¨ä½èµ„æºç¯å¢ƒä¸‹çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æ™ºèƒ½å¯¹è¯ç³»ç»Ÿå’Œè·¨é¢†åŸŸçŸ¥è¯†è¿ç§»ç­‰ã€‚é€šè¿‡æé«˜å°‘æ ·æœ¬å­¦ä¹ çš„æ•ˆæœï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨æ•°æ®ç¨€ç¼ºçš„åœºæ™¯ä¸­æœ‰æ•ˆåº”ç”¨ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper presents a gradient-informed fine-tuning method for large language models under few-shot conditions. The goal is to enhance task adaptability and training stability when data is limited. The method builds on a base loss function and introduces two gradient-related regularization terms. The first enforces gradient direction consistency to guide parameter updates along task-relevant directions and prevent drift. The second controls gradient magnitude to avoid abnormal updates. Together, these components support a more efficient and stable optimization path. To further improve cross-task generalization, the method incorporates a gradient alignment mechanism. This mechanism measures the consistency between optimization directions of the source and target tasks. It enhances fine-tuning performance in multi-task and cross-domain scenarios. Across various natural language understanding tasks, the method outperforms existing fine-tuning strategies in average accuracy, gradient stability, and directional alignment. Empirical evaluations under different sample sizes and domain-specific tasks confirm the method's robustness and broad applicability in low-resource environments. In particular, the method shows clear advantages in controlling parameter update paths. The results demonstrate that a gradient-based fine-tuning framework can effectively leverage the representational power of large language models. It ensures training stability while reducing dependence on large volumes of labeled data.

