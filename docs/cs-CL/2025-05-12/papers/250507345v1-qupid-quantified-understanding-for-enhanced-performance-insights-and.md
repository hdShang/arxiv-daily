---
layout: default
title: "QUPID: Quantified Understanding for Enhanced Performance, Insights, and Decisions in Korean Search Engines"
---

# QUPID: Quantified Understanding for Enhanced Performance, Insights, and Decisions in Korean Search Engines

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.07345" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.07345v1</a>
  <a href="https://arxiv.org/pdf/2505.07345.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.07345v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.07345v1', 'QUPID: Quantified Understanding for Enhanced Performance, Insights, and Decisions in Korean Search Engines')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ohjoon Kwon, Changsu Lee, Jihye Back, Lim Sun Suk, Inho Kang, Donghyeon Jeon

**åˆ†ç±»**: cs.CL, cs.AI, cs.IR

**å‘å¸ƒæ—¥æœŸ**: 2025-05-12

**æœŸåˆŠ**: ACL 2025 Industry Track

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºQUPIDä»¥æå‡éŸ©å›½æœç´¢å¼•æ“çš„ç›¸å…³æ€§è¯„ä¼°**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¿¡æ¯æ£€ç´¢` `ç›¸å…³æ€§è¯„ä¼°` `å°å‹è¯­è¨€æ¨¡å‹` `æ¨¡å‹ç»„åˆ` `è®¡ç®—æ•ˆç‡` `æœç´¢å¼•æ“` `æ¶æ„è®¾è®¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç›¸å…³æ€§è¯„ä¼°æ–¹æ³•ä¸»è¦ä¾èµ–å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œä½†åœ¨è®¡ç®—æ•ˆç‡å’Œå‡†ç¡®æ€§ä¸Šå­˜åœ¨ä¸è¶³ã€‚
2. QUPIDé€šè¿‡ç»“åˆç”Ÿæˆå¼SLMä¸åµŒå…¥å¼SLMï¼Œæå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¨¡å‹ç»„åˆç­–ç•¥ï¼Œä»¥æé«˜ç›¸å…³æ€§è¯„ä¼°çš„å‡†ç¡®æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒQUPIDåœ¨å¤šä¸ªæ–‡æ¡£ç±»å‹ä¸Šè¡¨ç°å‡ºä¸€è‡´çš„æ€§èƒ½æå‡ï¼Œæ¨ç†é€Ÿåº¦æ˜¾è‘—åŠ å¿«ï¼Œä¸”åœ¨å®é™…åº”ç”¨ä¸­æå‡äº†nDCG@5åˆ†æ•°ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä¿¡æ¯æ£€ç´¢ä¸­çš„ç›¸å…³æ€§è¯„ä¼°ä¸­å¾—åˆ°äº†å¹¿æ³›åº”ç”¨ã€‚ç„¶è€Œï¼Œæœ¬ç ”ç©¶è¡¨æ˜ï¼Œç»“åˆä¸¤ç§ä¸åŒæ¶æ„çš„å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰å¯ä»¥åœ¨è¿™ä¸€ä»»åŠ¡ä¸­è¶…è¶ŠLLMsã€‚æˆ‘ä»¬çš„æ–¹æ³•QUPIDå°†ç”Ÿæˆå¼SLMä¸åŸºäºåµŒå…¥çš„SLMç›¸ç»“åˆï¼Œå–å¾—äº†æ›´é«˜çš„ç›¸å…³æ€§åˆ¤æ–­å‡†ç¡®ç‡ï¼ŒåŒæ—¶ç›¸æ¯”äºæœ€å…ˆè¿›çš„LLMè§£å†³æ–¹æ¡ˆé™ä½äº†è®¡ç®—æˆæœ¬ã€‚è¿™ç§è®¡ç®—æ•ˆç‡ä½¿å¾—QUPIDåœ¨å¤„ç†æ¯æ—¥æ•°ç™¾ä¸‡æŸ¥è¯¢çš„å®é™…æœç´¢ç³»ç»Ÿä¸­å…·æœ‰é«˜åº¦å¯æ‰©å±•æ€§ã€‚åœ¨ä¸åŒæ–‡æ¡£ç±»å‹çš„å®éªŒä¸­ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¡¨ç°å‡ºä¸€è‡´çš„æ€§èƒ½æå‡ï¼ˆCohen's Kappaä¸º0.646ï¼Œç›¸è¾ƒäºé¢†å…ˆçš„LLMsçš„0.387ï¼‰ï¼Œå¹¶ä¸”æ¨ç†é€Ÿåº¦æé«˜äº†60å€ã€‚æ­¤å¤–ï¼Œå½“é›†æˆåˆ°ç”Ÿäº§æœç´¢ç®¡é“ä¸­æ—¶ï¼ŒQUPIDå°†nDCG@5åˆ†æ•°æé«˜äº†1.9%ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†æ¨¡å‹ç»„åˆä¸­çš„æ¶æ„å¤šæ ·æ€§å¦‚ä½•æ˜¾è‘—å¢å¼ºä¿¡æ¯æ£€ç´¢ç³»ç»Ÿçš„æœç´¢ç›¸å…³æ€§å’Œæ“ä½œæ•ˆç‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ä¿¡æ¯æ£€ç´¢ä¸­ç›¸å…³æ€§è¯„ä¼°çš„å‡†ç¡®æ€§å’Œè®¡ç®—æ•ˆç‡é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ï¼Œä½†åœ¨å¤„ç†å¤§é‡æŸ¥è¯¢æ—¶ï¼Œè®¡ç®—æˆæœ¬é«˜ä¸”æ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„QUPIDæ–¹æ³•é€šè¿‡ç»“åˆä¸¤ç§ä¸åŒæ¶æ„çš„å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰ï¼Œå³ç”Ÿæˆå¼SLMä¸åŸºäºåµŒå…¥çš„SLMï¼Œæ—¨åœ¨æé«˜ç›¸å…³æ€§åˆ¤æ–­çš„å‡†ç¡®æ€§ï¼ŒåŒæ—¶é™ä½è®¡ç®—å¼€é”€ã€‚è¿™æ ·çš„è®¾è®¡èƒ½å¤Ÿå……åˆ†åˆ©ç”¨ä¸åŒæ¨¡å‹çš„ä¼˜åŠ¿ï¼Œæå‡æ•´ä½“æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šQUPIDçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šç”Ÿæˆå¼SLMç”¨äºç”Ÿæˆå€™é€‰ç­”æ¡ˆï¼ŒåµŒå…¥å¼SLMç”¨äºå¯¹å€™é€‰ç­”æ¡ˆè¿›è¡Œç›¸å…³æ€§è¯„åˆ†ã€‚é€šè¿‡è¿™ä¸¤ä¸ªæ¨¡å—çš„ååŒå·¥ä½œï¼ŒQUPIDèƒ½å¤Ÿåœ¨ä¿è¯å‡†ç¡®æ€§çš„åŒæ—¶å®ç°é«˜æ•ˆçš„æ¨ç†ã€‚

**å…³é”®åˆ›æ–°**ï¼šQUPIDçš„æœ€é‡è¦åˆ›æ–°åœ¨äºæ¨¡å‹ç»„åˆçš„æ¶æ„è®¾è®¡ï¼Œé€šè¿‡å°†ä¸¤ç§å°å‹è¯­è¨€æ¨¡å‹ç»“åˆï¼Œå…‹æœäº†å•ä¸€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è®¡ç®—æ•ˆç‡ä¸Šçš„ä¸è¶³ã€‚è¿™ç§æ¶æ„å¤šæ ·æ€§æ˜¾è‘—æå‡äº†ä¿¡æ¯æ£€ç´¢ç³»ç»Ÿçš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼ŒQUPIDé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–ç›¸å…³æ€§è¯„åˆ†ï¼Œå¹¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†ç²¾ç»†è°ƒæ•´ï¼Œä»¥ç¡®ä¿ç”Ÿæˆå¼å’ŒåµŒå…¥å¼æ¨¡å‹ä¹‹é—´çš„æœ‰æ•ˆåä½œã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒQUPIDåœ¨Cohen's KappaæŒ‡æ ‡ä¸Šè¾¾åˆ°äº†0.646ï¼Œç›¸è¾ƒäºé¢†å…ˆçš„LLMsçš„0.387æœ‰æ˜¾è‘—æå‡ã€‚åŒæ—¶ï¼ŒQUPIDçš„æ¨ç†é€Ÿåº¦æé«˜äº†60å€ï¼Œå¹¶åœ¨ç”Ÿäº§ç¯å¢ƒä¸­å°†nDCG@5åˆ†æ•°æå‡äº†1.9%ï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

QUPIDçš„ç ”ç©¶æˆæœåœ¨å®é™…æœç´¢å¼•æ“ä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦å¤„ç†å¤§é‡æŸ¥è¯¢çš„åœºæ™¯ï¼Œå¦‚ç”µå­å•†åŠ¡ã€ç¤¾äº¤åª’ä½“å’Œåœ¨çº¿å†…å®¹å¹³å°ã€‚å…¶é«˜æ•ˆçš„è®¡ç®—æ€§èƒ½å’Œå‡†ç¡®çš„ç›¸å…³æ€§è¯„ä¼°èƒ½å¤Ÿæ˜¾è‘—æå‡ç”¨æˆ·ä½“éªŒï¼Œå¸®åŠ©ç”¨æˆ·æ›´å¿«é€Ÿåœ°æ‰¾åˆ°æ‰€éœ€ä¿¡æ¯ã€‚æœªæ¥ï¼ŒQUPIDçš„æ¶æ„è®¾è®¡ä¹Ÿå¯èƒ½ä¸ºå…¶ä»–é¢†åŸŸçš„ä¿¡æ¯æ£€ç´¢ä»»åŠ¡æä¾›æ–°çš„æ€è·¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) have been widely used for relevance assessment in information retrieval. However, our study demonstrates that combining two distinct small language models (SLMs) with different architectures can outperform LLMs in this task. Our approach -- QUPID -- integrates a generative SLM with an embedding-based SLM, achieving higher relevance judgment accuracy while reducing computational costs compared to state-of-the-art LLM solutions. This computational efficiency makes QUPID highly scalable for real-world search systems processing millions of queries daily. In experiments across diverse document types, our method demonstrated consistent performance improvements (Cohen's Kappa of 0.646 versus 0.387 for leading LLMs) while offering 60x faster inference times. Furthermore, when integrated into production search pipelines, QUPID improved nDCG@5 scores by 1.9%. These findings underscore how architectural diversity in model combinations can significantly enhance both search relevance and operational efficiency in information retrieval systems.

