---
layout: default
title: "One Trigger Token Is Enough: A Defense Strategy for Balancing Safety and Usability in Large Language Models"
---

# One Trigger Token Is Enough: A Defense Strategy for Balancing Safety and Usability in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.07167" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.07167v2</a>
  <a href="https://arxiv.org/pdf/2505.07167.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.07167v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.07167v2', 'One Trigger Token Is Enough: A Defense Strategy for Balancing Safety and Usability in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Haoran Gu, Handing Wang, Yi Mei, Mengjie Zhang, Yaochu Jin

**åˆ†ç±»**: cs.CR, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-12 (æ›´æ–°: 2025-08-04)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºD-STTä»¥è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ€§ä¸å¯ç”¨æ€§å¹³è¡¡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å®‰å…¨å¯¹é½` `è¶Šç‹±æ”»å‡»` `é˜²å¾¡ç­–ç•¥` `å®‰å…¨è§¦å‘token` `æ¨¡å‹å¯ç”¨æ€§` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å®‰å…¨å¯¹é½å¤§å‹è¯­è¨€æ¨¡å‹å®¹æ˜“å—åˆ°è¶Šç‹±æ”»å‡»ï¼Œå¯¼è‡´ç”Ÿæˆæœ‰å®³å“åº”ï¼Œå®‰å…¨æ€§ä¸è¶³ã€‚
2. è®ºæ–‡æå‡ºD-STTç®—æ³•ï¼Œé€šè¿‡è¯†åˆ«å’Œè§£ç å®‰å…¨è§¦å‘tokenï¼Œè§¦å‘æ¨¡å‹çš„å®‰å…¨æ¨¡å¼ï¼Œä»è€Œå¢å¼ºå®‰å…¨æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒD-STTæ˜¾è‘—é™ä½äº†è¾“å‡ºçš„æœ‰å®³æ€§ï¼ŒåŒæ—¶ä¿æŒäº†æ¨¡å‹çš„å¯ç”¨æ€§ï¼Œå“åº”æ—¶é—´å¼€é”€å‡ ä¹å¯ä»¥å¿½ç•¥ä¸è®¡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è™šæ‹ŸåŠ©æ‰‹ã€è‡ªåŠ¨ä»£ç ç”Ÿæˆå’Œç§‘å­¦ç ”ç©¶ç­‰å¤šä¸ªé¢†åŸŸå¾—åˆ°äº†å¹¿æ³›åº”ç”¨ã€‚ç„¶è€Œï¼Œå®ƒä»¬ä»ç„¶å®¹æ˜“å—åˆ°è¶Šç‹±æ”»å‡»ï¼Œè¿™ç§æ”»å‡»ä¼šæ“çºµæ¨¡å‹ç”Ÿæˆæœ‰å®³çš„å“åº”ï¼Œå°½ç®¡è¿›è¡Œäº†å®‰å…¨å¯¹é½ã€‚ç ”ç©¶è¡¨æ˜ï¼Œå½“å‰çš„å®‰å…¨å¯¹é½LLMså¾€å¾€å­˜åœ¨æµ…å±‚å®‰å…¨å¯¹é½çš„é—®é¢˜ï¼Œå‰å‡ ä¸ªtokenåœ¨å†³å®šå“åº”æ˜¯å¦æœ‰å®³æ–¹é¢èµ·ç€é‡è¦ä½œç”¨ã€‚åŸºäºè¿™ä¸€è§‚å¯Ÿï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„é˜²å¾¡ç®—æ³•D-STTï¼Œè¯¥ç®—æ³•è¯†åˆ«å¹¶æ˜¾å¼è§£ç ç»™å®šå®‰å…¨å¯¹é½LLMçš„å®‰å…¨è§¦å‘tokenï¼Œä»¥è§¦å‘æ¨¡å‹å­¦ä¹ çš„å®‰å…¨æ¨¡å¼ã€‚è¯¥æ–¹æ³•å°†å®‰å…¨è§¦å‘é™åˆ¶ä¸ºå•ä¸ªtokenï¼Œæœ‰æ•ˆåœ°ä¿æŒäº†æ¨¡å‹çš„å¯ç”¨æ€§ï¼ŒåŒæ—¶åœ¨è§£ç è¿‡ç¨‹ä¸­å¼•å…¥äº†æœ€å°çš„å¹²é¢„ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒD-STTåœ¨å‡å°‘è¾“å‡ºæœ‰å®³æ€§ã€ä¿æŒæ¨¡å‹å¯ç”¨æ€§å’Œå‡ ä¹ä¸å¢åŠ å“åº”æ—¶é—´å¼€é”€æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†åç§åŸºçº¿æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å®‰å…¨æ€§ä¸å¯ç”¨æ€§ä¹‹é—´çš„å¹³è¡¡é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨é¢å¯¹è¶Šç‹±æ”»å‡»æ—¶ï¼Œå¾€å¾€æ— æ³•æœ‰æ•ˆé˜²æ­¢æ¨¡å‹ç”Ÿæˆæœ‰å®³å†…å®¹ï¼Œä¸”å®‰å…¨å¯¹é½çš„æ•ˆæœè¾ƒä¸ºæµ…å±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è¯†åˆ«å®‰å…¨è§¦å‘tokenï¼Œåˆ©ç”¨è¿™äº›tokenè§¦å‘æ¨¡å‹çš„å®‰å…¨æ¨¡å¼ï¼Œä»è€Œæœ‰æ•ˆé˜²æ­¢æœ‰å®³å“åº”çš„ç”Ÿæˆã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨å‡å°‘å¯¹æ¨¡å‹è§£ç è¿‡ç¨‹çš„å¹²é¢„ï¼Œä¿æŒå…¶å¯ç”¨æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šD-STTçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šå®‰å…¨è§¦å‘tokençš„è¯†åˆ«æ¨¡å—å’Œè§£ç æ¨¡å—ã€‚è¯†åˆ«æ¨¡å—è´Ÿè´£åˆ†ææ¨¡å‹çš„è¾“å‡ºï¼Œæå–å‡ºå®‰å…¨è§¦å‘tokenï¼Œè€Œè§£ç æ¨¡å—åˆ™åˆ©ç”¨è¿™äº›tokenæ¥ç”Ÿæˆå®‰å…¨çš„å“åº”ã€‚

**å…³é”®åˆ›æ–°**ï¼šD-STTçš„ä¸»è¦åˆ›æ–°åœ¨äºå°†å®‰å…¨è§¦å‘é™åˆ¶ä¸ºå•ä¸ªtokenï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•éœ€è¦å¤šä¸ªtokençš„è®¾è®¡å½¢æˆé²œæ˜å¯¹æ¯”ã€‚è¿™ä¸€åˆ›æ–°æ˜¾è‘—æé«˜äº†æ¨¡å‹çš„å¯ç”¨æ€§ï¼Œå¹¶å‡å°‘äº†å“åº”æ—¶é—´ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨D-STTä¸­ï¼Œå…³é”®å‚æ•°è®¾ç½®åŒ…æ‹¬å®‰å…¨è§¦å‘tokençš„é€‰æ‹©ç­–ç•¥å’Œè§£ç è¿‡ç¨‹ä¸­çš„å¹²é¢„ç¨‹åº¦ã€‚æ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿè€ƒè™‘äº†å®‰å…¨æ€§ä¸å¯ç”¨æ€§çš„å¹³è¡¡ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨ç”Ÿæˆå“åº”æ—¶èƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨å®‰å…¨è§¦å‘tokenã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒD-STTåœ¨é¢å¯¹å¤šç§è¶Šç‹±æ”»å‡»å’Œè‰¯æ€§æç¤ºæ—¶ï¼Œæ˜¾è‘—é™ä½äº†è¾“å‡ºçš„æœ‰å®³æ€§ï¼Œå…·ä½“è¡¨ç°ä¸ºç›¸è¾ƒäºåç§åŸºçº¿æ–¹æ³•ï¼Œè¾“å‡ºæœ‰å®³æ€§é™ä½äº†XX%ï¼ŒåŒæ—¶ä¿æŒäº†æ¨¡å‹çš„å¯ç”¨æ€§ï¼Œå“åº”æ—¶é—´å¢åŠ å¹…åº¦å‡ ä¹å¯ä»¥å¿½ç•¥ä¸è®¡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è™šæ‹ŸåŠ©æ‰‹ã€è‡ªåŠ¨å†…å®¹ç”Ÿæˆå’Œåœ¨çº¿å®¢æœç­‰åœºæ™¯ã€‚é€šè¿‡å¢å¼ºå¤§å‹è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ€§ï¼ŒD-STTå¯ä»¥æœ‰æ•ˆé˜²æ­¢æœ‰å®³å†…å®¹çš„ç”Ÿæˆï¼Œæå‡ç”¨æˆ·ä½“éªŒå’Œä¿¡ä»»åº¦ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½åœ¨æ›´å¤šéœ€è¦å®‰å…¨å¯¹é½çš„AIåº”ç”¨ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have been extensively used across diverse domains, including virtual assistants, automated code generation, and scientific research. However, they remain vulnerable to jailbreak attacks, which manipulate the models into generating harmful responses despite safety alignment. Recent studies have shown that current safety-aligned LLMs often undergo the shallow safety alignment, where the first few tokens largely determine whether the response will be harmful. Through comprehensive observations, we find that safety-aligned LLMs and various defense strategies generate highly similar initial tokens in their refusal responses, which we define as safety trigger tokens. Building on this insight, we propose \texttt{D-STT}, a simple yet effective defense algorithm that identifies and explicitly decodes safety trigger tokens of the given safety-aligned LLM to trigger the model's learned safety patterns. In this process, the safety trigger is constrained to a single token, which effectively preserves model usability by introducing minimum intervention in the decoding process. Extensive experiments across diverse jailbreak attacks and benign prompts demonstrate that \ours significantly reduces output harmfulness while preserving model usability and incurring negligible response time overhead, outperforming ten baseline methods.

