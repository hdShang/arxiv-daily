---
layout: default
title: Are LLMs complicated ethical dilemma analyzers?
---

# Are LLMs complicated ethical dilemma analyzers?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.08106" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.08106v1</a>
  <a href="https://arxiv.org/pdf/2505.08106.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.08106v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.08106v1', 'Are LLMs complicated ethical dilemma analyzers?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiashen, Du, Jesse Yao, Allen Liu, Zhekai Zhang

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-12

**å¤‡æ³¨**: CS194-280 Advanced LLM Agents project. Project page: https://github.com/ALT-JS/ethicaLLM

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¼¦ç†å›°å¢ƒåŸºå‡†æ•°æ®é›†ä»¥è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹çš„ä¼¦ç†æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ä¼¦ç†æ¨ç†` `åŸºå‡†æ•°æ®é›†` `æ¨¡å‹è¯„ä¼°` `äººç±»åˆ¤æ–­`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç ”ç©¶å°šæœªå……åˆ†éªŒè¯å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¼¦ç†æ¨ç†ä¸­çš„æœ‰æ•ˆæ€§ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚ä¼¦ç†å›°å¢ƒçš„åˆ†æä¸­ã€‚
2. æœ¬ç ”ç©¶é€šè¿‡æ„å»ºåŒ…å«196ä¸ªä¼¦ç†å›°å¢ƒçš„åŸºå‡†æ•°æ®é›†ï¼Œç³»ç»Ÿè¯„ä¼°å¤šç§å¤§å‹è¯­è¨€æ¨¡å‹çš„ä¼¦ç†æ¨ç†èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGPT-4o-miniåœ¨å„ä¸ªéƒ¨åˆ†è¡¨ç°æœ€ä¸ºä¸€è‡´ï¼Œä½†æ‰€æœ‰æ¨¡å‹åœ¨å†å²èƒŒæ™¯å’Œç»†è‡´è§£å†³ç­–ç•¥æ–¹é¢å‡å­˜åœ¨ä¸è¶³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶æ¢è®¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ˜¯å¦èƒ½å¤Ÿæ¨¡æ‹Ÿäººç±»çš„ä¼¦ç†æ¨ç†ï¼Œå¹¶ä½œä¸ºäººç±»åˆ¤æ–­çš„å¯ä¿¡ä»£ç†ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªåŒ…å«196ä¸ªçœŸå®ä¼¦ç†å›°å¢ƒåŠä¸“å®¶æ„è§çš„åŸºå‡†æ•°æ®é›†ï¼Œæ¯ä¸ªå›°å¢ƒåˆ†ä¸ºäº”ä¸ªç»“æ„åŒ–ç»„ä»¶ï¼šå¼•è¨€ã€å…³é”®å› ç´ ã€å†å²ç†è®ºè§†è§’ã€è§£å†³ç­–ç•¥å’Œå…³é”®å¯ç¤ºã€‚åŒæ—¶ï¼Œæˆ‘ä»¬æ”¶é›†äº†éä¸“å®¶äººç±»çš„å›åº”ä»¥è¿›è¡Œæ¯”è¾ƒã€‚é€šè¿‡åŸºäºBLEUã€Damerau-Levenshteinè·ç¦»ã€TF-IDFä½™å¼¦ç›¸ä¼¼åº¦å’Œé€šç”¨å¥å­ç¼–ç å™¨ç›¸ä¼¼åº¦çš„å¤åˆæŒ‡æ ‡æ¡†æ¶è¯„ä¼°å¤šç§å‰æ²¿LLMsï¼Œç»“æœè¡¨æ˜LLMsåœ¨è¯æ±‡å’Œç»“æ„å¯¹é½æ–¹é¢æ™®éä¼˜äºéä¸“å®¶äººç±»ï¼Œä½†åœ¨å†å²åŸºç¡€å’Œæå‡ºç»†è‡´è§£å†³ç­–ç•¥æ–¹é¢å­˜åœ¨å›°éš¾ã€‚è¿™äº›å‘ç°çªæ˜¾äº†LLMsåœ¨ä¼¦ç†å†³ç­–ä¸­çš„ä¼˜åŠ¿ä¸å±€é™æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¼¦ç†å›°å¢ƒåˆ†æä¸­çš„è¡¨ç°ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚ä¼¦ç†é—®é¢˜æ—¶ç¼ºä¹ç³»ç»Ÿæ€§å’Œå‡†ç¡®æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ„å»ºä¸€ä¸ªåŒ…å«196ä¸ªçœŸå®ä¼¦ç†å›°å¢ƒçš„åŸºå‡†æ•°æ®é›†ï¼Œè®ºæ–‡æä¾›äº†ä¸€ä¸ªç»“æ„åŒ–çš„è¯„ä¼°æ¡†æ¶ï¼Œä»¥æ¯”è¾ƒLLMsä¸äººç±»ä¸“å®¶çš„ä¼¦ç†æ¨ç†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨å¤åˆæŒ‡æ ‡æ¡†æ¶ï¼Œç»“åˆBLEUã€Damerau-Levenshteinè·ç¦»ã€TF-IDFä½™å¼¦ç›¸ä¼¼åº¦å’Œé€šç”¨å¥å­ç¼–ç å™¨ç›¸ä¼¼åº¦ï¼Œè¯„ä¼°æ¨¡å‹è¾“å‡ºä¸ä¸“å®¶å›åº”çš„å¯¹é½ç¨‹åº¦ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†ä¸€ä¸ªç³»ç»ŸåŒ–çš„ä¼¦ç†å›°å¢ƒæ•°æ®é›†ï¼Œå¹¶é€šè¿‡ç»†è‡´çš„æŒ‡æ ‡è®¾è®¡å®ç°äº†å¯¹æ¨¡å‹è¾“å‡ºçš„ç²¾ç»†æ¯”è¾ƒï¼Œå¡«è¡¥äº†ç°æœ‰ç ”ç©¶çš„ç©ºç™½ã€‚

**å…³é”®è®¾è®¡**ï¼šæŒ‡æ ‡æƒé‡é€šè¿‡åŸºäºåæ¼”çš„æ’åå¯¹é½å’Œæˆå¯¹AHPåˆ†æè®¡ç®—ï¼Œç¡®ä¿äº†è¯„ä¼°çš„ç§‘å­¦æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMsåœ¨è¯æ±‡å’Œç»“æ„å¯¹é½æ–¹é¢æ™®éä¼˜äºéä¸“å®¶äººç±»ï¼Œå°¤å…¶æ˜¯GPT-4o-miniåœ¨å„ä¸ªéƒ¨åˆ†è¡¨ç°æœ€ä¸ºä¸€è‡´ã€‚ç„¶è€Œï¼Œæ‰€æœ‰æ¨¡å‹åœ¨å†å²åŸºç¡€å’Œæå‡ºç»†è‡´è§£å†³ç­–ç•¥æ–¹é¢å‡å­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œè¡¨æ˜åœ¨ä¼¦ç†æ¨ç†ä¸­ä»éœ€è¿›ä¸€æ­¥æ”¹è¿›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ä¼¦ç†å†³ç­–æ”¯æŒç³»ç»Ÿã€æ•™è‚²å’ŒåŸ¹è®­å·¥å…·ï¼Œä»¥åŠå¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ³•å¾‹ã€åŒ»ç–—ç­‰é¢†åŸŸçš„ä¼¦ç†åˆ†æåº”ç”¨ã€‚é€šè¿‡æå‡æ¨¡å‹çš„ä¼¦ç†æ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥ä¸ºå¤æ‚å†³ç­–æä¾›æ›´ä¸ºå¯é çš„æ”¯æŒï¼Œä¿ƒè¿›äººæœºåä½œçš„ä¼¦ç†æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> One open question in the study of Large Language Models (LLMs) is whether they can emulate human ethical reasoning and act as believable proxies for human judgment. To investigate this, we introduce a benchmark dataset comprising 196 real-world ethical dilemmas and expert opinions, each segmented into five structured components: Introduction, Key Factors, Historical Theoretical Perspectives, Resolution Strategies, and Key Takeaways. We also collect non-expert human responses for comparison, limited to the Key Factors section due to their brevity. We evaluate multiple frontier LLMs (GPT-4o-mini, Claude-3.5-Sonnet, Deepseek-V3, Gemini-1.5-Flash) using a composite metric framework based on BLEU, Damerau-Levenshtein distance, TF-IDF cosine similarity, and Universal Sentence Encoder similarity. Metric weights are computed through an inversion-based ranking alignment and pairwise AHP analysis, enabling fine-grained comparison of model outputs to expert responses. Our results show that LLMs generally outperform non-expert humans in lexical and structural alignment, with GPT-4o-mini performing most consistently across all sections. However, all models struggle with historical grounding and proposing nuanced resolution strategies, which require contextual abstraction. Human responses, while less structured, occasionally achieve comparable semantic similarity, suggesting intuitive moral reasoning. These findings highlight both the strengths and current limitations of LLMs in ethical decision-making.

