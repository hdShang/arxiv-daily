---
layout: default
title: Spoken Language Understanding on Unseen Tasks With In-Context Learning
---

# Spoken Language Understanding on Unseen Tasks With In-Context Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.07731" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.07731v1</a>
  <a href="https://arxiv.org/pdf/2505.07731.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.07731v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.07731v1', 'Spoken Language Understanding on Unseen Tasks With In-Context Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Neeraj Agrawal, Sriram Ganapathy

**åˆ†ç±»**: cs.CL, cs.LG, eess.AS

**å‘å¸ƒæ—¥æœŸ**: 2025-05-12

**æœŸåˆŠ**: Proc. Interspeech 2025, 4103-4107

**DOI**: [10.21437/Interspeech.2025-1467](https://doi.org/10.21437/Interspeech.2025-1467)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºéšæœºç±»æ ‡ç­¾çš„æ— ä»»åŠ¡ç‰¹å®šå¾®è°ƒæ–¹æ³•ä»¥æå‡SLUæ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å£è¯­ç†è§£` `éšæœºç±»æ ‡ç­¾` `ä»»åŠ¡æ— å…³å¾®è°ƒ` `è¯­éŸ³-æ–‡æœ¬æ¨¡å‹` `é›¶æ ·æœ¬å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„SLUæ¨¡å‹åœ¨ç¼ºä¹ä»»åŠ¡ç‰¹å®šè®­ç»ƒæ•°æ®æ—¶è¡¨ç°ä¸ä½³ï¼Œæ— æ³•æ»¡è¶³å¤šæ ·åŒ–çš„ä»»åŠ¡éœ€æ±‚ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºéšæœºç±»æ ‡ç­¾çš„ä»»åŠ¡æ— å…³å¾®è°ƒæ–¹æ³•ï¼Œæ—¨åœ¨æå‡æ¨¡å‹åœ¨æœªè§ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨è¯¥æ–¹æ³•åï¼Œè¯­éŸ³-æ–‡æœ¬LLMsåœ¨SLUä»»åŠ¡ä¸Šçš„è¡¨ç°æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å£è¯­ç†è§£ï¼ˆSLUï¼‰ä»»åŠ¡æ¶‰åŠå¤šç§æŠ€èƒ½ï¼Œè€ƒå¯Ÿæ¨¡å‹çš„ä¿¡æ¯æå–ã€åˆ†ç±»å’Œç”Ÿæˆèƒ½åŠ›ã€‚åœ¨ç¼ºä¹ç‰¹å®šä»»åŠ¡è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹ï¼Œä¼ ç»Ÿçš„SLUæ¨¡å‹æ— æ³•æ»¡è¶³éœ€æ±‚ã€‚å°½ç®¡è¯­éŸ³-æ–‡æœ¬çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å±•ç°å‡ºæ–°å…´èƒ½åŠ›ï¼Œä½†æˆ‘ä»¬çš„è¯„ä¼°æ˜¾ç¤ºï¼Œç°æœ‰å¼€æºæ¨¡å‹åœ¨SLUä»»åŠ¡ä¸Šçš„é›¶/å°‘æ ·æœ¬æ€§èƒ½ä»ä¸ç†æƒ³ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ä»»åŠ¡æ— å…³å¾®è°ƒæ–¹æ³•ï¼Œé€šè¿‡éšæœºç±»æ ‡ç­¾æ˜¾è‘—æå‡äº†è¯­éŸ³-æ–‡æœ¬LLMsåœ¨æœªè§ä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼Œä¸”æ— éœ€ä»»åŠ¡ç‰¹å®šçš„æ•°æ®æ ‡æ³¨ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨ç¼ºä¹ä»»åŠ¡ç‰¹å®šè®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹ï¼Œç°æœ‰SLUæ¨¡å‹æ— æ³•æœ‰æ•ˆæ‰§è¡Œæ–°ä»»åŠ¡çš„é—®é¢˜ã€‚ä¼ ç»Ÿæ¨¡å‹ä¾èµ–äºå¤§é‡æ ‡æ³¨æ•°æ®ï¼Œé™åˆ¶äº†å…¶é€‚åº”æ€§å’Œçµæ´»æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºä¸€ç§æ–°çš„å¾®è°ƒæ–¹æ³•ï¼Œé€šè¿‡éšæœºç±»æ ‡ç­¾è¿›è¡Œä»»åŠ¡æ— å…³çš„è®­ç»ƒã€‚è¿™ç§æ–¹æ³•å…è®¸æ¨¡å‹åœ¨æ²¡æœ‰ç‰¹å®šä»»åŠ¡æ•°æ®çš„æƒ…å†µä¸‹ï¼Œä»èƒ½æœ‰æ•ˆå­¦ä¹ å’Œé€‚åº”æ–°ä»»åŠ¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åŒ…æ‹¬æ•°æ®å‡†å¤‡ã€éšæœºç±»æ ‡ç­¾ç”Ÿæˆã€æ¨¡å‹å¾®è°ƒå’Œæ€§èƒ½è¯„ä¼°ã€‚é¦–å…ˆç”Ÿæˆéšæœºç±»æ ‡ç­¾ï¼Œç„¶åå¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œæœ€ååœ¨æœªè§ä»»åŠ¡ä¸Šè¿›è¡Œè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥éšæœºç±»æ ‡ç­¾çš„å¾®è°ƒç­–ç•¥ï¼Œè¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„ä»»åŠ¡ç‰¹å®šå¾®è°ƒæ–¹æ³•æœ¬è´¨ä¸Šä¸åŒï¼Œèƒ½å¤Ÿåœ¨æ²¡æœ‰æ ‡æ³¨æ•°æ®çš„æƒ…å†µä¸‹æå‡æ¨¡å‹æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥é€‚åº”éšæœºæ ‡ç­¾çš„ç”Ÿæˆï¼ŒåŒæ—¶è°ƒæ•´äº†æ¨¡å‹çš„å­¦ä¹ ç‡å’Œè®­ç»ƒè½®æ¬¡ï¼Œä»¥ç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆæ”¶æ•›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œé‡‡ç”¨éšæœºç±»æ ‡ç­¾å¾®è°ƒåï¼Œè¯­éŸ³-æ–‡æœ¬LLMsåœ¨æœªè§SLUä»»åŠ¡ä¸Šçš„æ€§èƒ½æå‡äº†çº¦30%ï¼Œæ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„å¾®è°ƒæ–¹æ³•ï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½åŠ©æ‰‹ã€è¯­éŸ³è¯†åˆ«ç³»ç»Ÿå’Œå®¢æœæœºå™¨äººç­‰ï¼Œèƒ½å¤Ÿåœ¨ç¼ºä¹ç‰¹å®šä»»åŠ¡æ•°æ®çš„æƒ…å†µä¸‹ï¼Œå¿«é€Ÿé€‚åº”æ–°ä»»åŠ¡ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æ¨åŠ¨SLUæŠ€æœ¯åœ¨æ›´å¤šå®é™…åœºæ™¯ä¸­çš„åº”ç”¨ï¼Œé™ä½å¼€å‘æˆæœ¬ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Spoken language understanding (SLU) tasks involve diverse skills that probe the information extraction, classification and/or generation capabilities of models. In this setting, task-specific training data may not always be available. While traditional task-specific SLU models are unable to cater to such requirements, the speech-text large language models (LLMs) offer a promising alternative with emergent abilities. However, out of-the-box, our evaluations indicate that the zero/few-shot performance of prominent open-source speech-text LLMs on SLU tasks are not up to the mark. In this paper, we introduce a novel approach to robust task-agnostic fine-tuning using randomized class labels. With this proposed fine-tuning, we illustrate that the performance of the speech-text LLMs on an unseen task is significantly improved over standard approaches. Critically, the proposed approach avoids the requirement of task-specific data annotations for enabling new tasks in speech-text LLMs.

