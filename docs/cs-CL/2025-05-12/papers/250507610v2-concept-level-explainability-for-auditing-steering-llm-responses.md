---
layout: default
title: Concept-Level Explainability for Auditing & Steering LLM Responses
---

# Concept-Level Explainability for Auditing & Steering LLM Responses

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.07610" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.07610v2</a>
  <a href="https://arxiv.org/pdf/2505.07610.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.07610v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.07610v2', 'Concept-Level Explainability for Auditing & Steering LLM Responses')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kenza Amara, Rita Sevastjanova, Mennatallah El-Assady

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-12 (æ›´æ–°: 2025-05-19)

**å¤‡æ³¨**: 9 pages, 7 figures, Submission to Neurips 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºConceptXä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹å“åº”çš„å¯è§£é‡Šæ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `å¯è§£é‡Šæ€§` `æ¦‚å¿µçº§å½’å› ` `åè§å®¡è®¡` `æ¨¡å‹å¼•å¯¼` `è‡ªç„¶è¯­è¨€å¤„ç†` `å®‰å…¨æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„tokençº§å½’å› æ–¹æ³•åœ¨æ–‡æœ¬ç”Ÿæˆä¸­éš¾ä»¥è§£é‡Šè¾“å‡ºçš„æ•´ä½“è¯­ä¹‰ï¼Œå¯¼è‡´å¯¹æ¨¡å‹è¡Œä¸ºçš„ç†è§£ä¸è¶³ã€‚
2. ConceptXé€šè¿‡è¯†åˆ«æç¤ºä¸­çš„è¯­ä¹‰ä¸°å¯Œtokenï¼Œå¹¶æ ¹æ®è¾“å‡ºçš„è¯­ä¹‰ç›¸ä¼¼æ€§ä¸ºå…¶åˆ†é…é‡è¦æ€§ï¼Œä»è€Œæä¾›æ¦‚å¿µçº§çš„å¯è§£é‡Šæ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒConceptXåœ¨æƒ…æ„Ÿè½¬å˜å’Œæ”»å‡»æˆåŠŸç‡æ–¹é¢æ˜¾è‘—ä¼˜äºéšæœºç¼–è¾‘å’Œå…¶ä»–åŸºçº¿æ–¹æ³•ï¼Œæå‡å¹…åº¦æ˜æ˜¾ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¹¿æ³›åº”ç”¨ï¼Œå…³äºå…¶å®‰å…¨æ€§å’Œå¯¹é½æ€§çš„é—®é¢˜æ—¥ç›Šçªå‡ºã€‚ä¸ºå¼•å¯¼LLMè¡Œä¸ºï¼Œå¦‚å‡è½»åè§æˆ–é˜²èŒƒè¶Šç‹±æ”»å‡»ï¼Œè¯†åˆ«æç¤ºä¸­å½±å“æ¨¡å‹è¾“å‡ºçš„éƒ¨åˆ†è‡³å…³é‡è¦ã€‚ç°æœ‰çš„åŸºäºtokençš„å½’å› æ–¹æ³•åœ¨æ–‡æœ¬ç”Ÿæˆä¸­ä»é¢ä¸´æŒ‘æˆ˜ï¼Œæ— æ³•è§£é‡Šè¾“å‡ºä¸­æ¯ä¸ªtokençš„å­˜åœ¨ï¼Œè€Œæ˜¯å…³æ³¨æ•´ä¸ªLLMå“åº”çš„è¯­ä¹‰ã€‚æœ¬æ–‡æå‡ºäº†ConceptXï¼Œè¿™æ˜¯ä¸€ç§æ¨¡å‹æ— å…³çš„æ¦‚å¿µçº§å¯è§£é‡Šæ€§æ–¹æ³•ï¼Œèƒ½å¤Ÿè¯†åˆ«æç¤ºä¸­çš„è¯­ä¹‰ä¸°å¯Œtokenï¼Œå¹¶æ ¹æ®è¾“å‡ºçš„è¯­ä¹‰ç›¸ä¼¼æ€§ä¸ºå…¶åˆ†é…é‡è¦æ€§ã€‚ä¸ç°æœ‰çš„tokençº§æ–¹æ³•ä¸åŒï¼ŒConceptXè¿˜é€šè¿‡å°±åœ°tokenæ›¿æ¢æ¥ä¿æŒä¸Šä¸‹æ–‡å®Œæ•´æ€§ï¼Œå¹¶æ”¯æŒçµæ´»çš„è§£é‡Šç›®æ ‡ï¼Œå¦‚æ€§åˆ«åè§ã€‚ConceptXä¸ä»…èƒ½æ­ç¤ºåè§æ¥æºï¼Œè¿˜èƒ½é€šè¿‡ä¿®æ”¹æç¤ºæ¥æ”¹å˜æƒ…æ„Ÿæˆ–å‡å°‘LLMå“åº”çš„æœ‰å®³æ€§ï¼Œè€Œæ— éœ€é‡æ–°è®­ç»ƒã€‚åœ¨ä¸‰ç§LLMä¸Šï¼ŒConceptXåœ¨å¿ å®æ€§å’Œäººç±»å¯¹é½æ€§æ–¹é¢å‡ä¼˜äºTokenSHAPç­‰tokençº§æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹å“åº”çš„å¯è§£é‡Šæ€§é—®é¢˜ï¼Œç°æœ‰çš„tokençº§å½’å› æ–¹æ³•æ— æ³•æœ‰æ•ˆè§£é‡Šæ–‡æœ¬ç”Ÿæˆçš„æ•´ä½“è¯­ä¹‰ï¼Œå¯¼è‡´å¯¹æ¨¡å‹è¾“å‡ºçš„ç†è§£ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šConceptXé€šè¿‡è¯†åˆ«æç¤ºä¸­çš„è¯­ä¹‰ä¸°å¯Œtokenï¼Œå¹¶æ ¹æ®è¾“å‡ºçš„è¯­ä¹‰ç›¸ä¼¼æ€§ä¸ºå…¶åˆ†é…é‡è¦æ€§ï¼Œæä¾›äº†ä¸€ç§æ–°çš„å¯è§£é‡Šæ€§æ–¹æ³•ï¼Œèƒ½å¤Ÿä¿æŒä¸Šä¸‹æ–‡å®Œæ•´æ€§å¹¶æ”¯æŒçµæ´»çš„è§£é‡Šç›®æ ‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šConceptXçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š1) æ¦‚å¿µè¯†åˆ«ï¼Œ2) é‡è¦æ€§åˆ†é…ï¼Œ3) ä¸Šä¸‹æ–‡ä¿æŒã€‚é€šè¿‡è¿™äº›æ¨¡å—ï¼ŒConceptXèƒ½å¤Ÿæœ‰æ•ˆåˆ†æå’Œä¿®æ”¹æç¤ºã€‚

**å…³é”®åˆ›æ–°**ï¼šConceptXçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶æ¦‚å¿µçº§çš„å¯è§£é‡Šæ€§ï¼Œä¸ç°æœ‰çš„tokençº§æ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰è¾“å‡ºçš„è¯­ä¹‰ï¼Œå¹¶æ”¯æŒçµæ´»çš„è§£é‡Šç›®æ ‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒConceptXé‡‡ç”¨äº†å°±åœ°tokenæ›¿æ¢çš„æ–¹æ³•ï¼Œç¡®ä¿ä¸Šä¸‹æ–‡çš„å®Œæ•´æ€§ï¼ŒåŒæ—¶åœ¨é‡è¦æ€§åˆ†é…ä¸­ä½¿ç”¨äº†è¯­ä¹‰ç›¸ä¼¼æ€§åº¦é‡ï¼Œä»¥æé«˜è§£é‡Šçš„å‡†ç¡®æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒConceptXåœ¨æƒ…æ„Ÿè½¬å˜ä»»åŠ¡ä¸­æå‡äº†0.252ï¼Œç›¸è¾ƒäºéšæœºç¼–è¾‘çš„0.131ï¼Œä¸”åœ¨æ”»å‡»æˆåŠŸç‡æ–¹é¢ä»0.463é™ä½è‡³0.242ï¼Œæ˜¾è‘—ä¼˜äºå½’å› å’Œæ”¹å†™åŸºçº¿ï¼Œå±•ç¤ºäº†å…¶åœ¨å¯è§£é‡Šæ€§å’Œå¼•å¯¼æ€§æ–¹é¢çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ConceptXçš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„åè§å®¡è®¡ã€æ¨¡å‹è¡Œä¸ºå¼•å¯¼å’Œå®‰å…¨æ€§å¢å¼ºç­‰ã€‚é€šè¿‡æä¾›é€æ˜çš„å¯è§£é‡Šæ€§ï¼ŒConceptXèƒ½å¤Ÿå¸®åŠ©å¼€å‘è€…æ›´å¥½åœ°ç†è§£å’Œæ§åˆ¶å¤§è¯­è¨€æ¨¡å‹çš„è¾“å‡ºï¼Œä»è€Œæé«˜å…¶å®‰å…¨æ€§å’Œå¯¹é½æ€§ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> As large language models (LLMs) become widely deployed, concerns about their safety and alignment grow. An approach to steer LLM behavior, such as mitigating biases or defending against jailbreaks, is to identify which parts of a prompt influence specific aspects of the model's output. Token-level attribution methods offer a promising solution, but still struggle in text generation, explaining the presence of each token in the output separately, rather than the underlying semantics of the entire LLM response. We introduce ConceptX, a model-agnostic, concept-level explainability method that identifies the concepts, i.e., semantically rich tokens in the prompt, and assigns them importance based on the outputs' semantic similarity. Unlike current token-level methods, ConceptX also offers to preserve context integrity through in-place token replacements and supports flexible explanation goals, e.g., gender bias. ConceptX enables both auditing, by uncovering sources of bias, and steering, by modifying prompts to shift the sentiment or reduce the harmfulness of LLM responses, without requiring retraining. Across three LLMs, ConceptX outperforms token-level methods like TokenSHAP in both faithfulness and human alignment. Steering tasks boost sentiment shift by 0.252 versus 0.131 for random edits and lower attack success rates from 0.463 to 0.242, outperforming attribution and paraphrasing baselines. While prompt engineering and self-explaining methods sometimes yield safer responses, ConceptX offers a transparent and faithful alternative for improving LLM safety and alignment, demonstrating the practical value of attribution-based explainability in guiding LLM behavior.

