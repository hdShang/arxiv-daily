---
layout: default
title: "Don't Take the Premise for Granted: Evaluating the Premise Critique Ability of Large Language Models"
---

# Don't Take the Premise for Granted: Evaluating the Premise Critique Ability of Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.23715" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.23715v2</a>
  <a href="https://arxiv.org/pdf/2505.23715.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.23715v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.23715v2', 'Don\'t Take the Premise for Granted: Evaluating the Premise Critique Ability of Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jinzhe Li, Gengxu Li, Yi Chang, Yuan Wu

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-29 (æ›´æ–°: 2025-11-24)

**å¤‡æ³¨**: EMNLP 2025 Findings camera-ready version

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/MLGroupJLU/Premise_Critique)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPremise Critique Benchä»¥æå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„å‰ææ‰¹åˆ¤èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å‰ææ‰¹åˆ¤èƒ½åŠ›` `æ¨ç†èƒ½åŠ›` `è¯„ä¼°åŸºå‡†` `é”™è¯¯ç±»å‹` `ç³»ç»Ÿè¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç ”ç©¶å¤§å¤šåœ¨ç†æƒ³ç¯å¢ƒä¸‹è¯„ä¼°LLMsçš„æ¨ç†èƒ½åŠ›ï¼Œå¿½è§†äº†å®ƒä»¬åœ¨é¢å¯¹æœ‰ç¼ºé™·å‰ææ—¶çš„è„†å¼±æ€§ã€‚
2. æœ¬æ–‡æå‡ºäº†å‰ææ‰¹åˆ¤åŸºå‡†ï¼ˆPCBenchï¼‰ï¼Œé€šè¿‡è®¾è®¡å¤šç§é”™è¯¯ç±»å‹å’Œéš¾åº¦çº§åˆ«ï¼Œè¯„ä¼°LLMsçš„å‰ææ‰¹åˆ¤èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå¤§å¤šæ•°æ¨¡å‹ä¾èµ–äºæç¤ºæ¥æ£€æµ‹é”™è¯¯ï¼Œè‡ªä¸»æ‰¹åˆ¤èƒ½åŠ›æœ‰é™ï¼Œä¸”æ¨ç†èƒ½åŠ›ä¸å‰ææ‰¹åˆ¤èƒ½åŠ›å¹¶ä¸æ€»æ˜¯ç›¸å…³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¿«é€Ÿå‘å±•çš„åŒæ—¶ï¼Œä»ç„¶å­˜åœ¨ä¸€ä¸ªæ˜¾è‘—çš„è„†å¼±æ€§ï¼šå®ƒä»¬å¾€å¾€ä¸åŠ æ‰¹åˆ¤åœ°æ¥å—æœ‰ç¼ºé™·æˆ–çŸ›ç›¾çš„å‰æï¼Œä»è€Œå¯¼è‡´æ¨ç†æ•ˆç‡ä½ä¸‹å’Œè¾“å‡ºä¸å¯é ã€‚æœ¬æ–‡å¼ºè°ƒäº†LLMså…·å¤‡å‰ææ‰¹åˆ¤èƒ½åŠ›çš„é‡è¦æ€§ï¼Œå³ä¸»åŠ¨è¯†åˆ«å’Œé˜è¿°è¾“å…¥å‰æé”™è¯¯çš„èƒ½åŠ›ã€‚æˆ‘ä»¬å¼•å…¥äº†å‰ææ‰¹åˆ¤åŸºå‡†ï¼ˆPCBenchï¼‰ï¼Œé€šè¿‡å››ç§é”™è¯¯ç±»å‹å’Œä¸‰ä¸ªéš¾åº¦çº§åˆ«çš„ç»“åˆï¼Œé…åˆå¤šç»´åº¦è¯„ä¼°æŒ‡æ ‡ï¼Œå¯¹15ä¸ªä»£è¡¨æ€§LLMsè¿›è¡Œäº†ç³»ç»Ÿè¯„ä¼°ã€‚ç ”ç©¶å‘ç°ï¼Œå¤§å¤šæ•°æ¨¡å‹ä¾èµ–äºæ˜ç¡®çš„æç¤ºæ¥æ£€æµ‹é”™è¯¯ï¼Œä¸”è‡ªä¸»æ‰¹åˆ¤èƒ½åŠ›æœ‰é™ï¼›å‰ææ‰¹åˆ¤èƒ½åŠ›ä¾èµ–äºé—®é¢˜çš„éš¾åº¦å’Œé”™è¯¯ç±»å‹ï¼›æ¨ç†èƒ½åŠ›ä¸å‰ææ‰¹åˆ¤èƒ½åŠ›å¹¶ä¸æ€»æ˜¯ç›¸å…³ï¼›æœ‰ç¼ºé™·çš„å‰æä¼šå¯¼è‡´æ¨ç†æ¨¡å‹çš„è¿‡åº¦æ€è€ƒï¼Œæ˜¾è‘—å»¶é•¿å“åº”æ—¶é—´ã€‚è¿™äº›å‘ç°çªæ˜¾äº†å¢å¼ºLLMsä¸»åŠ¨è¯„ä¼°è¾“å…¥æœ‰æ•ˆæ€§çš„è¿«åˆ‡éœ€æ±‚ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é¢å¯¹æœ‰ç¼ºé™·å‰ææ—¶ç¼ºä¹æ‰¹åˆ¤èƒ½åŠ›çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€åœ¨ç†æƒ³æ¡ä»¶ä¸‹è¯„ä¼°æ¨¡å‹ï¼Œæœªèƒ½æ­ç¤ºå…¶åœ¨å®é™…åº”ç”¨ä¸­çš„è„†å¼±æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼•å…¥å‰ææ‰¹åˆ¤åŸºå‡†ï¼ˆPCBenchï¼‰ï¼Œç³»ç»Ÿæ€§åœ°è¯„ä¼°LLMsåœ¨è¯†åˆ«å’Œæ‰¹åˆ¤è¾“å…¥å‰æé”™è¯¯æ–¹é¢çš„èƒ½åŠ›ï¼Œå¼ºè°ƒä¸»åŠ¨è¯„ä¼°çš„é‡è¦æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å››ç§é”™è¯¯ç±»å‹ï¼ˆç›´æ¥çŸ›ç›¾ã€å¤æ‚é”™è¯¯ã€ç¨‹åºæ€§é”™è¯¯ç­‰ï¼‰å’Œä¸‰ä¸ªéš¾åº¦çº§åˆ«ï¼Œç»“åˆå¤šç»´åº¦è¯„ä¼°æŒ‡æ ‡ï¼Œå½¢æˆå…¨é¢çš„è¯„ä¼°ä½“ç³»ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºè®¾è®¡äº†PCBenchè¿™ä¸€è¯„ä¼°å·¥å…·ï¼Œèƒ½å¤Ÿç³»ç»Ÿæ€§åœ°æ­ç¤ºLLMsåœ¨å‰ææ‰¹åˆ¤èƒ½åŠ›ä¸Šçš„ä¸è¶³ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†æ›´ä¸ºç»†è‡´çš„è¯„ä¼°æ ‡å‡†ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œè€ƒè™‘äº†ä¸åŒé”™è¯¯ç±»å‹å¯¹æ¨¡å‹è¡¨ç°çš„å½±å“ï¼Œè®¾ç½®äº†å¤šæ ·åŒ–çš„è¯„ä¼°æŒ‡æ ‡ï¼Œç¡®ä¿èƒ½å¤Ÿå…¨é¢åæ˜ æ¨¡å‹çš„å‰ææ‰¹åˆ¤èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå¤§å¤šæ•°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ£€æµ‹é”™è¯¯æ—¶ä¾èµ–äºæ˜ç¡®çš„æç¤ºï¼Œè‡ªä¸»æ‰¹åˆ¤èƒ½åŠ›æœ‰é™ã€‚ä¸åŒé”™è¯¯ç±»å‹çš„æ£€æµ‹éš¾åº¦å·®å¼‚æ˜æ˜¾ï¼Œç›´æ¥çŸ›ç›¾çš„æ£€æµ‹ç›¸å¯¹å®¹æ˜“ï¼Œè€Œå¤æ‚æˆ–ç¨‹åºæ€§é”™è¯¯åˆ™è¾ƒéš¾è¯†åˆ«ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†æå‡LLMså‰ææ‰¹åˆ¤èƒ½åŠ›çš„å¿…è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€å¯¹è¯ç³»ç»Ÿå’Œè‡ªåŠ¨å†…å®¹ç”Ÿæˆç­‰ã€‚é€šè¿‡æå‡LLMsçš„å‰ææ‰¹åˆ¤èƒ½åŠ›ï¼Œå¯ä»¥å¢å¼ºå…¶åœ¨å¤æ‚åœºæ™¯ä¸‹çš„æ¨ç†å¯é æ€§ï¼Œä»è€Œä¸ºäººæœºäº¤äº’æä¾›æ›´ä¸ºç¨³å¥çš„æ”¯æŒï¼Œæ¨åŠ¨äººæ€§åŒ–ç³»ç»Ÿçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) have witnessed rapid advancements, demonstrating remarkable capabilities. However, a notable vulnerability persists: LLMs often uncritically accept flawed or contradictory premises, leading to inefficient reasoning and unreliable outputs. This emphasizes the significance of possessing the \textbf{Premise Critique Ability} for LLMs, defined as the capacity to proactively identify and articulate errors in input premises. Most existing studies assess LLMs' reasoning ability in ideal settings, largely ignoring their vulnerabilities when faced with flawed premises. Thus, we introduce the \textbf{Premise Critique Bench (PCBench)}, designed by incorporating four error types across three difficulty levels, paired with multi-faceted evaluation metrics. We conducted systematic evaluations of 15 representative LLMs. Our findings reveal: (1) Most models rely heavily on explicit prompts to detect errors, with limited autonomous critique; (2) Premise critique ability depends on question difficulty and error type, with direct contradictions being easier to detect than complex or procedural errors; (3) Reasoning ability does not consistently correlate with the premise critique ability; (4) Flawed premises trigger overthinking in reasoning models, markedly lengthening responses due to repeated attempts at resolving conflicts. These insights underscore the urgent need to enhance LLMs' proactive evaluation of input validity, positioning premise critique as a foundational capability for developing reliable, human-centric systems. The code is available at https://github.com/MLGroupJLU/Premise_Critique.

