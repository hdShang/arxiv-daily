---
layout: default
title: Is Your Model Fairly Certain? Uncertainty-Aware Fairness Evaluation for LLMs
---

# Is Your Model Fairly Certain? Uncertainty-Aware Fairness Evaluation for LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.23996" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.23996v1</a>
  <a href="https://arxiv.org/pdf/2505.23996.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.23996v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.23996v1', 'Is Your Model Fairly Certain? Uncertainty-Aware Fairness Evaluation for LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yinong Oliver Wang, Nivedha Sivakumar, Falaah Arif Khan, Rin Metcalf Susa, Adam Golinski, Natalie Mackraz, Barry-John Theobald, Luca Zappella, Nicholas Apostoloff

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-29

**å¤‡æ³¨**: 9 pages, 8 figures, and 1 table in main paper. Supplementary appendix attached. Accepted at ICML 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºUCerFä»¥è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹å…¬å¹³æ€§è¯„ä¼°ä¸­çš„ä¸ç¡®å®šæ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å…¬å¹³æ€§è¯„ä¼°` `ä¸ç¡®å®šæ€§æ„ŸçŸ¥` `æ•°æ®é›†æ„å»º` `æ¨¡å‹åè§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å…¬å¹³æ€§è¯„ä¼°æ–¹æ³•ä¸»è¦ä¾èµ–äºå‡†ç¡®æ€§æŒ‡æ ‡ï¼Œæœªèƒ½è€ƒè™‘æ¨¡å‹çš„ä¸ç¡®å®šæ€§ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœå¯èƒ½ä¸å…¨é¢ã€‚
2. æœ¬æ–‡æå‡ºçš„ä¸ç¡®å®šæ€§æ„ŸçŸ¥å…¬å¹³æ€§æŒ‡æ ‡UCerFï¼Œæ—¨åœ¨æ›´ç»†è‡´åœ°è¯„ä¼°æ¨¡å‹çš„å…¬å¹³æ€§ï¼Œåæ˜ æ¨¡å‹å†³ç­–ä¸­çš„æ½œåœ¨åè§ã€‚
3. é€šè¿‡å»ºç«‹æ–°çš„æ€§åˆ«-èŒä¸šå…¬å¹³æ€§è¯„ä¼°æ•°æ®é›†å¹¶åº”ç”¨UCerFï¼Œå‘ç°å¤šä¸ªå¼€æºLLMsåœ¨å…¬å¹³æ€§æ–¹é¢å­˜åœ¨æ˜¾è‘—é—®é¢˜ï¼Œå°¤å…¶æ˜¯é«˜ä¿¡å¿ƒçš„é”™è¯¯é¢„æµ‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¿«é€Ÿåº”ç”¨ï¼Œå…¬å¹³æ€§è¯„ä¼°çš„é‡è¦æ€§æ—¥ç›Šå‡¸æ˜¾ã€‚ä¼ ç»Ÿçš„å…¬å¹³æ€§æŒ‡æ ‡ä¸»è¦å…³æ³¨åŸºäºç¦»æ•£å‡†ç¡®æ€§çš„è¯„ä¼°ï¼Œæœªèƒ½å……åˆ†åæ˜ æ¨¡å‹ä¸ç¡®å®šæ€§å¯¹ä¸åŒç¾¤ä½“çš„éšæ€§å½±å“ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§ä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„å…¬å¹³æ€§æŒ‡æ ‡UCerFï¼Œèƒ½å¤Ÿæ›´ç»†è‡´åœ°è¯„ä¼°æ¨¡å‹çš„å…¬å¹³æ€§ï¼Œæ­ç¤ºæ¨¡å‹å†³ç­–ä¸­çš„å†…éƒ¨åè§ã€‚æ­¤å¤–ï¼Œé’ˆå¯¹å½“å‰æ•°æ®é›†åœ¨è§„æ¨¡ã€å¤šæ ·æ€§å’Œæ¸…æ™°åº¦æ–¹é¢çš„é—®é¢˜ï¼Œæœ¬æ–‡å¼•å…¥äº†ä¸€ä¸ªæ–°çš„æ€§åˆ«-èŒä¸šå…¬å¹³æ€§è¯„ä¼°æ•°æ®é›†ï¼ŒåŒ…å«31,756ä¸ªæ ·æœ¬ï¼Œé€‚ç”¨äºå…±æŒ‡æ¶ˆè§£ä»»åŠ¡ã€‚é€šè¿‡ä½¿ç”¨è¯¥æŒ‡æ ‡å’Œæ•°æ®é›†ï¼Œæˆ‘ä»¬å»ºç«‹äº†åŸºå‡†ï¼Œå¹¶å¯¹åä¸ªå¼€æºLLMsçš„è¡Œä¸ºè¿›è¡Œäº†è¯„ä¼°ï¼Œå‘ç°Mistral-7Båœ¨é”™è¯¯é¢„æµ‹ä¸­è¡¨ç°å‡ºè¾ƒé«˜çš„ä¿¡å¿ƒï¼Œå¯¼è‡´å…¬å¹³æ€§ä¸è¶³ï¼Œè¿™æ˜¯ä¼ ç»Ÿæ–¹æ³•æœªèƒ½æ•æ‰åˆ°çš„ã€‚æ•´ä½“è€Œè¨€ï¼Œæœ¬æ–‡çš„ç ”ç©¶ä¸ºå¼€å‘æ›´é€æ˜å’Œè´Ÿè´£ä»»çš„AIç³»ç»Ÿé“ºå¹³äº†é“è·¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å…¬å¹³æ€§è¯„ä¼°ä¸­æœªè€ƒè™‘ä¸ç¡®å®šæ€§çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€åªå…³æ³¨é¢„æµ‹çš„å‡†ç¡®æ€§ï¼Œå¿½è§†äº†æ¨¡å‹å¯¹ä¸åŒç¾¤ä½“çš„ä¿¡å¿ƒå·®å¼‚ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœä¸å¤Ÿå…¨é¢å’Œå‡†ç¡®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„ä¸ç¡®å®šæ€§æ„ŸçŸ¥å…¬å¹³æ€§æŒ‡æ ‡UCerFï¼Œèƒ½å¤Ÿåœ¨è¯„ä¼°æ¨¡å‹å…¬å¹³æ€§æ—¶è€ƒè™‘æ¨¡å‹çš„ä¸ç¡®å®šæ€§ï¼Œä»è€Œæ›´å‡†ç¡®åœ°åæ˜ æ¨¡å‹å†³ç­–ä¸­çš„æ½œåœ¨åè§ã€‚è¿™ä¸€è®¾è®¡æ—¨åœ¨å¡«è¡¥ä¼ ç»Ÿå…¬å¹³æ€§è¯„ä¼°æ–¹æ³•çš„ç©ºç™½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€UCerFæŒ‡æ ‡è®¾è®¡å’Œæ¨¡å‹è¯„ä¼°ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œæ„å»ºæ–°çš„æ€§åˆ«-èŒä¸šå…¬å¹³æ€§è¯„ä¼°æ•°æ®é›†ï¼›å…¶æ¬¡ï¼Œè®¾è®¡UCerFæŒ‡æ ‡ä»¥è¯„ä¼°æ¨¡å‹çš„å…¬å¹³æ€§ï¼›æœ€åï¼Œåº”ç”¨è¯¥æŒ‡æ ‡å¯¹å¤šä¸ªå¼€æºLLMsè¿›è¡Œè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥äº†ä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„å…¬å¹³æ€§è¯„ä¼°æŒ‡æ ‡UCerFï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œå®ƒèƒ½å¤Ÿæ•æ‰åˆ°æ¨¡å‹åœ¨ä¸åŒç¾¤ä½“é—´çš„ä¿¡å¿ƒå·®å¼‚ï¼Œä»è€Œæä¾›æ›´å…¨é¢çš„å…¬å¹³æ€§è¯„ä¼°ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨UCerFçš„è®¾è®¡ä¸­ï¼Œè€ƒè™‘äº†æ¨¡å‹çš„é¢„æµ‹ä¿¡å¿ƒå’Œå‡†ç¡®æ€§ä¹‹é—´çš„å…³ç³»ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥é‡åŒ–ä¸ç¡®å®šæ€§å¯¹å…¬å¹³æ€§çš„å½±å“ã€‚æ­¤å¤–ï¼Œæ•°æ®é›†çš„å¤šæ ·æ€§å’Œæ ·æœ¬é‡ä¹Ÿç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œä»¥ç¡®ä¿è¯„ä¼°çš„æœ‰æ•ˆæ€§å’Œå¯é æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨UCerFæŒ‡æ ‡è¯„ä¼°çš„åä¸ªå¼€æºLLMsä¸­ï¼ŒMistral-7Båœ¨é”™è¯¯é¢„æµ‹ä¸­è¡¨ç°å‡ºé«˜è¾¾80%çš„ä¿¡å¿ƒï¼Œå¯¼è‡´å…¶å…¬å¹³æ€§è¯„åˆ†æ˜¾è‘—ä½äºä¼ ç»Ÿè¯„ä¼°æ–¹æ³•ã€‚è¿™ä¸€å‘ç°å¼ºè°ƒäº†ä¸ç¡®å®šæ€§æ„ŸçŸ¥åœ¨å…¬å¹³æ€§è¯„ä¼°ä¸­çš„é‡è¦æ€§ï¼Œæ¨åŠ¨äº†å¯¹æ¨¡å‹è¡Œä¸ºçš„æ·±å…¥ç†è§£ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬AIç³»ç»Ÿçš„å…¬å¹³æ€§è¯„ä¼°ã€ç¤¾ä¼šç§‘å­¦ç ”ç©¶ä»¥åŠæ”¿ç­–åˆ¶å®šç­‰ã€‚é€šè¿‡æä¾›æ›´å‡†ç¡®çš„å…¬å¹³æ€§è¯„ä¼°å·¥å…·ï¼Œèƒ½å¤Ÿå¸®åŠ©å¼€å‘è€…å’Œç ”ç©¶äººå‘˜è¯†åˆ«å’Œå‡å°‘æ¨¡å‹ä¸­çš„åè§ï¼Œä»è€Œæ¨åŠ¨æ›´é€æ˜å’Œè´Ÿè´£ä»»çš„AIæŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The recent rapid adoption of large language models (LLMs) highlights the critical need for benchmarking their fairness. Conventional fairness metrics, which focus on discrete accuracy-based evaluations (i.e., prediction correctness), fail to capture the implicit impact of model uncertainty (e.g., higher model confidence about one group over another despite similar accuracy). To address this limitation, we propose an uncertainty-aware fairness metric, UCerF, to enable a fine-grained evaluation of model fairness that is more reflective of the internal bias in model decisions compared to conventional fairness measures. Furthermore, observing data size, diversity, and clarity issues in current datasets, we introduce a new gender-occupation fairness evaluation dataset with 31,756 samples for co-reference resolution, offering a more diverse and suitable dataset for evaluating modern LLMs. We establish a benchmark, using our metric and dataset, and apply it to evaluate the behavior of ten open-source LLMs. For example, Mistral-7B exhibits suboptimal fairness due to high confidence in incorrect predictions, a detail overlooked by Equalized Odds but captured by UCerF. Overall, our proposed LLM benchmark, which evaluates fairness with uncertainty awareness, paves the way for developing more transparent and accountable AI systems.

