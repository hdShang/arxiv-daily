---
layout: default
title: Table-R1: Inference-Time Scaling for Table Reasoning
---

# Table-R1: Inference-Time Scaling for Table Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.23621" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.23621v2</a>
  <a href="https://arxiv.org/pdf/2505.23621.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.23621v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.23621v2', 'Table-R1: Inference-Time Scaling for Table Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zheyuan Yang, Lyuhao Chen, Arman Cohan, Yilun Zhao

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-29 (æ›´æ–°: 2025-09-26)

**å¤‡æ³¨**: EMNLP 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTable-R1ä»¥å®ç°è¡¨æ ¼æ¨ç†ä»»åŠ¡çš„æ¨ç†æ—¶é—´æ‰©å±•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è¡¨æ ¼æ¨ç†` `æ¨ç†æ—¶é—´æ‰©å±•` `è’¸é¦è®­ç»ƒ` `å¼ºåŒ–å­¦ä¹ ` `å¯éªŒè¯å¥–åŠ±` `æ¨¡å‹å¾®è°ƒ` `è·¨ä»»åŠ¡æ³›åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¡¨æ ¼æ¨ç†æ–¹æ³•åœ¨æ¨ç†æ—¶é—´å’Œæ€§èƒ½ä¸Šå­˜åœ¨ç“¶é¢ˆï¼Œéš¾ä»¥æ»¡è¶³å¤æ‚ä»»åŠ¡çš„éœ€æ±‚ã€‚
2. è®ºæ–‡æå‡ºäº†é€šè¿‡è’¸é¦å’Œå¼ºåŒ–å­¦ä¹ ç›¸ç»“åˆçš„æ–¹å¼ï¼Œä¼˜åŒ–è¡¨æ ¼æ¨ç†æ¨¡å‹çš„æ¨ç†æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒTable-R1-Zeroæ¨¡å‹åœ¨å¤šç§ä»»åŠ¡ä¸Šè¶…è¶Šäº†ç°æœ‰çš„å…ˆè¿›æ¨¡å‹ï¼Œå±•ç°äº†ä¼˜è¶Šçš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶é¦–æ¬¡æ¢è®¨äº†è¡¨æ ¼æ¨ç†ä»»åŠ¡ä¸­çš„æ¨ç†æ—¶é—´æ‰©å±•ã€‚æˆ‘ä»¬å¼€å‘å¹¶è¯„ä¼°äº†ä¸¤ç§åè®­ç»ƒç­–ç•¥ä»¥å®ç°æ¨ç†æ—¶é—´æ‰©å±•ï¼šä»å‰æ²¿æ¨¡å‹æ¨ç†è½¨è¿¹è¿›è¡Œè’¸é¦å’Œä½¿ç”¨å¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLVRï¼‰ã€‚åœ¨è’¸é¦è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ç”±DeepSeek-R1ç”Ÿæˆçš„å¤§è§„æ¨¡æ¨ç†è½¨è¿¹æ•°æ®é›†ï¼Œç”¨äºå¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸ºTable-R1-SFTæ¨¡å‹ã€‚å¯¹äºRLVRï¼Œæˆ‘ä»¬æå‡ºäº†ç‰¹å®šä»»åŠ¡çš„å¯éªŒè¯å¥–åŠ±å‡½æ•°ï¼Œå¹¶åº”ç”¨GRPOç®—æ³•è·å¾—Table-R1-Zeroæ¨¡å‹ã€‚æˆ‘ä»¬åœ¨å¤šç§è¡¨æ ¼æ¨ç†ä»»åŠ¡ä¸Šè¯„ä¼°äº†Table-R1ç³»åˆ—æ¨¡å‹ï¼ŒTable-R1-Zeroæ¨¡å‹çš„æ€§èƒ½ä¸GPT-4.1å’ŒDeepSeek-R1ç›¸å½“æˆ–æ›´ä¼˜ï¼ŒåŒæ—¶ä»…ä½¿ç”¨7Bå‚æ•°çš„LLMï¼Œå¹¶åœ¨åŸŸå¤–æ•°æ®é›†ä¸Šè¡¨ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚å¤§é‡æ¶ˆèå’Œå®šæ€§åˆ†ææ­ç¤ºäº†æŒ‡ä»¤è°ƒä¼˜ã€æ¨¡å‹æ¶æ„é€‰æ‹©å’Œè·¨ä»»åŠ¡æ³›åŒ–çš„ä¼˜åŠ¿ï¼Œä»¥åŠåœ¨RLè®­ç»ƒè¿‡ç¨‹ä¸­è¡¨æ ¼æ¨ç†æŠ€èƒ½çš„å‡ºç°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³è¡¨æ ¼æ¨ç†ä»»åŠ¡ä¸­çš„æ¨ç†æ—¶é—´æ‰©å±•é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚æ¨ç†æ—¶ï¼Œå¾€å¾€é¢ä¸´æ€§èƒ½ä¸è¶³å’Œæ¨ç†æ—¶é—´è¿‡é•¿çš„æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸¤ç§åè®­ç»ƒç­–ç•¥ï¼šé€šè¿‡è’¸é¦ä»å‰æ²¿æ¨¡å‹çš„æ¨ç†è½¨è¿¹ä¸­æå–çŸ¥è¯†ï¼Œä»¥åŠä½¿ç”¨å¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ æ¥ä¼˜åŒ–æ¨¡å‹ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨æé«˜æ¨ç†æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼š1ï¼‰è’¸é¦æ¨¡å—ï¼Œé€šè¿‡DeepSeek-R1ç”Ÿæˆçš„æ¨ç†è½¨è¿¹å¾®è°ƒLLMsï¼›2ï¼‰å¼ºåŒ–å­¦ä¹ æ¨¡å—ï¼Œä½¿ç”¨ç‰¹å®šä»»åŠ¡çš„å¯éªŒè¯å¥–åŠ±å‡½æ•°è¿›è¡Œè®­ç»ƒï¼Œæœ€ç»ˆå½¢æˆTable-R1-Zeroæ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºç»“åˆäº†è’¸é¦å’Œå¼ºåŒ–å­¦ä¹ çš„ç­–ç•¥ï¼Œå°¤å…¶æ˜¯å¼•å…¥äº†å¯éªŒè¯å¥–åŠ±å‡½æ•°ï¼Œä½¿å¾—æ¨¡å‹åœ¨æ¨ç†æ—¶èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”ä¸åŒä»»åŠ¡çš„éœ€æ±‚ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¿™ç§æ–¹æ³•åœ¨æ¨ç†æ•ˆç‡å’Œå‡†ç¡®æ€§ä¸Šæœ‰æ˜¾è‘—æå‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸Šï¼ŒTable-R1-SFTå’ŒTable-R1-Zeroæ¨¡å‹çš„å‚æ•°è®¾ç½®ç»è¿‡ç²¾å¿ƒè°ƒæ•´ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡è€ƒè™‘äº†æ¨ç†è½¨è¿¹çš„æœ‰æ•ˆæ€§ï¼Œç½‘ç»œç»“æ„åˆ™ä¼˜åŒ–äº†æ¨ç†è¿‡ç¨‹ä¸­çš„ä¿¡æ¯æµåŠ¨ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTable-R1-Zeroæ¨¡å‹åœ¨å¤šä¸ªè¡¨æ ¼æ¨ç†ä»»åŠ¡ä¸Šä¸GPT-4.1å’ŒDeepSeek-R1çš„æ€§èƒ½ç›¸å½“æˆ–æ›´ä¼˜ï¼Œä¸”ä»…ä½¿ç”¨7Bå‚æ•°çš„LLMã€‚è¯¥æ¨¡å‹åœ¨åŸŸå¤–æ•°æ®é›†ä¸Šä¹Ÿå±•ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨åœºæ™¯åŒ…æ‹¬æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€æ•°æ®éªŒè¯å’Œä¿¡æ¯æ£€ç´¢ç­‰é¢†åŸŸã€‚é€šè¿‡æé«˜è¡¨æ ¼æ¨ç†çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ï¼ŒTable-R1æ¨¡å‹èƒ½å¤Ÿä¸ºä¼ä¸šå’Œç ”ç©¶æœºæ„æä¾›æ›´å¿«é€Ÿã€å¯é çš„æ•°æ®åˆ†æå·¥å…·ï¼Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In this work, we present the first study to explore inference-time scaling on table reasoning tasks. We develop and evaluate two post-training strategies to enable inference-time scaling: distillation from frontier model reasoning traces and reinforcement learning with verifiable rewards (RLVR). For distillation, we introduce a large-scale dataset of reasoning traces generated by DeepSeek-R1, which we use to fine-tune LLMs into the Table-R1-SFT model. For RLVR, we propose task-specific verifiable reward functions and apply the GRPO algorithm to obtain the Table-R1-Zero model. We evaluate our Table-R1-series models across diverse table reasoning tasks, including short-form QA, fact verification, and free-form QA. Notably, the Table-R1-Zero model matches or exceeds the performance of GPT-4.1 and DeepSeek-R1, while using only a 7B-parameter LLM. It also demonstrates strong generalization to out-of-domain datasets. Extensive ablation and qualitative analyses reveal the benefits of instruction tuning, model architecture choices, and cross-task generalization, as well as emergence of essential table reasoning skills during RL training.

