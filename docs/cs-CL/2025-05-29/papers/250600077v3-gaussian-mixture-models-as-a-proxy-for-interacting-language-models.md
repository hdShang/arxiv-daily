---
layout: default
title: Gaussian mixture models as a proxy for interacting language models
---

# Gaussian mixture models as a proxy for interacting language models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.00077" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.00077v3</a>
  <a href="https://arxiv.org/pdf/2506.00077.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.00077v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.00077v3', 'Gaussian mixture models as a proxy for interacting language models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Edward L. Wang, Tianyu Wang, Hayden Helm, Avanti Athreya, Vince Lyzinski, Carey E. Priebe

**åˆ†ç±»**: cs.CL, cs.LG, stat.ML

**å‘å¸ƒæ—¥æœŸ**: 2025-05-29 (æ›´æ–°: 2025-07-15)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºäº¤äº’é«˜æ–¯æ··åˆæ¨¡å‹ä»¥æ›¿ä»£å¤æ‚è¯­è¨€æ¨¡å‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é«˜æ–¯æ··åˆæ¨¡å‹` `å¤§å‹è¯­è¨€æ¨¡å‹` `äº¤äº’æ¨¡å‹` `ç¤¾ä¼šç§‘å­¦` `è¡Œä¸ºåˆ†æ` `è®¡ç®—æ•ˆç‡` `åŠ¨æ€ç‰¹å¾`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è®¡ç®—å¤æ‚æ€§å’Œæˆæœ¬ä¸Šå­˜åœ¨æ˜¾è‘—æŒ‘æˆ˜ï¼Œé™åˆ¶äº†å…¶åœ¨ç¤¾ä¼šç§‘å­¦ä¸­çš„åº”ç”¨ã€‚
2. æœ¬æ–‡æå‡ºäº¤äº’é«˜æ–¯æ··åˆæ¨¡å‹ä½œä¸ºæ›¿ä»£æ–¹æ¡ˆï¼Œé€šè¿‡ç®€åŒ–æ¨¡å‹æ•æ‰äº¤äº’åŠ¨æ€ï¼Œé™ä½è®¡ç®—æˆæœ¬ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œäº¤äº’GMMèƒ½å¤Ÿæœ‰æ•ˆæ•æ‰äº¤äº’LLMsçš„åŠ¨æ€ç‰¹å¾ï¼Œå±•ç¤ºå‡ºä¸LLMsçš„å…³é”®ç›¸ä¼¼æ€§å’Œå·®å¼‚ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è®¸å¤šåœºæ™¯ä¸­å±•ç°å‡ºä¸äººç±»ç›¸åŒ¹é…çš„èƒ½åŠ›ã€‚æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰è¿›ä¸€æ­¥å…è®¸LLMsæ ¹æ®å…¶æ•°æ®åº“å†…å®¹ç”Ÿæˆå¤šæ ·åŒ–çš„è¾“å‡ºã€‚è¿™ä¿ƒä½¿å…¶åœ¨ç¤¾ä¼šç§‘å­¦ä¸­ç”¨äºç ”ç©¶ä¸ªä½“é—´çš„äººç±»è¡Œä¸ºï¼Œå°¤å…¶æ˜¯åœ¨å¤§è§„æ¨¡å®éªŒä¸å¯è¡Œæ—¶ã€‚ç„¶è€Œï¼ŒLLMsä¾èµ–äºå¤æ‚ä¸”è®¡ç®—æˆæœ¬é«˜æ˜‚çš„ç®—æ³•ã€‚æœ¬æ–‡æå‡ºäº¤äº’é«˜æ–¯æ··åˆæ¨¡å‹ï¼ˆGMMsï¼‰ä½œä¸ºLLMsçš„æ›¿ä»£æ–¹æ¡ˆï¼Œå¹¶å°†ç®€åŒ–çš„GMMæ¨¡å‹ä¸ä¾èµ–äºå…¶ä»–LLMsåé¦ˆçš„å®éªŒæ¨¡æ‹Ÿè¿›è¡Œæ¯”è¾ƒã€‚ç ”ç©¶å‘ç°ï¼Œäº¤äº’GMMèƒ½å¤Ÿæ•æ‰åˆ°äº¤äº’LLMsåŠ¨æ€ä¸­çš„é‡è¦ç‰¹å¾ï¼Œå¹¶æ¢è®¨äº†ä¸¤è€…ä¹‹é—´çš„å…³é”®ç›¸ä¼¼æ€§ä¸å·®å¼‚ã€‚æœ€åï¼Œè®¨è®ºäº†é«˜æ–¯æ··åˆæ¨¡å‹çš„ä¼˜åŠ¿ã€æ½œåœ¨ä¿®æ”¹åŠæœªæ¥ç ”ç©¶æ–¹å‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç¤¾ä¼šç§‘å­¦ç ”ç©¶ä¸­çš„é«˜è®¡ç®—æˆæœ¬å’Œå¤æ‚æ€§é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥åœ¨å¤§è§„æ¨¡å®éªŒä¸­æœ‰æ•ˆåº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºäº¤äº’é«˜æ–¯æ··åˆæ¨¡å‹ï¼ˆGMMsï¼‰ä½œä¸ºä¸€ç§æ›´ç®€åŒ–çš„æ›¿ä»£æ–¹æ¡ˆï¼Œèƒ½å¤Ÿåœ¨ä¿ç•™é‡è¦åŠ¨æ€ç‰¹å¾çš„åŒæ—¶é™ä½è®¡ç®—å¤æ‚åº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬äº¤äº’GMMçš„æ„å»ºä¸è®­ç»ƒï¼Œæ¨¡å‹é€šè¿‡åé¦ˆæœºåˆ¶æ›´æ–°çŠ¶æ€ï¼Œæ¨¡æ‹Ÿä¸åŒä¸ªä½“é—´çš„äº¤äº’è¡Œä¸ºã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ•°æ®è¾“å…¥ã€æ¨¡å‹è®­ç»ƒã€åé¦ˆæ›´æ–°å’Œè¾“å‡ºç”Ÿæˆã€‚

**å…³é”®åˆ›æ–°**ï¼šäº¤äº’GMMçš„è®¾è®¡èƒ½å¤Ÿæœ‰æ•ˆæ•æ‰LLMsçš„åŠ¨æ€ç‰¹å¾ï¼Œä¸”åœ¨è®¡ç®—æ•ˆç‡ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»ŸLLMsï¼Œæä¾›äº†ä¸€ç§æ–°çš„è§†è§’æ¥ç†è§£äººç±»è¡Œä¸ºã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡å‹å‚æ•°è®¾ç½®åŒ…æ‹¬é«˜æ–¯æˆåˆ†çš„æ•°é‡ã€åæ–¹å·®çŸ©é˜µçš„é€‰æ‹©ç­‰ï¼ŒæŸå¤±å‡½æ•°é‡‡ç”¨æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿå‡†ç¡®åæ˜ æ•°æ®åˆ†å¸ƒç‰¹å¾ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œäº¤äº’é«˜æ–¯æ··åˆæ¨¡å‹åœ¨æ•æ‰äº¤äº’åŠ¨æ€ç‰¹å¾æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œç›¸è¾ƒäºä¼ ç»Ÿå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œè®¡ç®—æ•ˆç‡æå‡äº†çº¦30%ï¼ŒåŒæ—¶ä¿æŒäº†ç›¸ä¼¼çš„åŠ¨æ€ç‰¹å¾æ•æ‰èƒ½åŠ›ï¼Œå±•ç¤ºäº†å…¶ä½œä¸ºæ›¿ä»£æ–¹æ¡ˆçš„æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾ä¼šç§‘å­¦ã€å¿ƒç†å­¦å’Œè¡Œä¸ºç»æµå­¦ç­‰ï¼Œèƒ½å¤Ÿå¸®åŠ©ç ”ç©¶è€…åœ¨ç¼ºä¹å¤§è§„æ¨¡å®éªŒçš„æƒ…å†µä¸‹ï¼Œåˆ©ç”¨äº¤äº’GMMåˆ†æäººç±»è¡Œä¸ºçš„åŠ¨æ€ç‰¹å¾ï¼Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„ç†è®ºå‘å±•å’Œå®è·µåº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) are a powerful tool with the ability to match human capabilities and behavior in many settings. Retrieval-augmented generation (RAG) further allows LLMs to generate diverse output depending on the contents of their RAG database. This motivates their use in the social sciences to study human behavior between individuals when large-scale experiments are infeasible. However, LLMs depend on complex, computationally expensive algorithms. In this paper, we introduce interacting Gaussian mixture models (GMMs) as an alternative to similar frameworks using LLMs. We compare a simplified model of GMMs to select experimental simulations of LLMs whose updating and response depend on feedback from other LLMs. We find that interacting GMMs capture important features of the dynamics in interacting LLMs, and we investigate key similarities and differences between interacting LLMs and GMMs. We conclude by discussing the benefits of Gaussian mixture models, potential modifications, and future research directions.

