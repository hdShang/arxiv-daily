---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CL - 2025-05-29
---

# cs.CLï¼ˆ2025-05-29ï¼‰

ğŸ“Š å…± **29** ç¯‡è®ºæ–‡
 | ğŸ”— **3** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (19 ğŸ”—2)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (9 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (19 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250524063v2-tcm-ladder-a-benchmark-for-multimodal-question-answering-on-traditio.html">TCM-Ladder: A Benchmark for Multimodal Question Answering on Traditional Chinese Medicine</a></td>
  <td>æå‡ºTCM-Ladderä»¥è§£å†³ä¸­åŒ»å¤šæ¨¡æ€é—®ç­”è¯„ä¼°é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.24063v2" data-paper-url="./papers/250524063v2-tcm-ladder-a-benchmark-for-multimodal-question-answering-on-traditio.html" onclick="toggleFavorite(this, '2505.24063v2', 'TCM-Ladder: A Benchmark for Multimodal Question Answering on Traditional Chinese Medicine')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250523945v2-a-closer-look-at-bias-and-chain-of-thought-faithfulness-of-large-vis.html">A Closer Look at Bias and Chain-of-Thought Faithfulness of Large (Vision) Language Models</a></td>
  <td>æå‡ºæ–°è¯„ä¼°ç®¡é“ä»¥è§£å†³å¤§è§„æ¨¡è§†è§‰è¯­è¨€æ¨¡å‹çš„åè§ä¸æ¨ç†å¿ å®æ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.23945v2" data-paper-url="./papers/250523945v2-a-closer-look-at-bias-and-chain-of-thought-faithfulness-of-large-vis.html" onclick="toggleFavorite(this, '2505.23945v2', 'A Closer Look at Bias and Chain-of-Thought Faithfulness of Large (Vision) Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250523713v1-socialmaze-a-benchmark-for-evaluating-social-reasoning-in-large-lang.html">SocialMaze: A Benchmark for Evaluating Social Reasoning in Large Language Models</a></td>
  <td>æå‡ºSocialMazeåŸºå‡†ä»¥è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹çš„ç¤¾ä¼šæ¨ç†èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">chain-of-thought</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.23713v1" data-paper-url="./papers/250523713v1-socialmaze-a-benchmark-for-evaluating-social-reasoning-in-large-lang.html" onclick="toggleFavorite(this, '2505.23713v1', 'SocialMaze: A Benchmark for Evaluating Social Reasoning in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250523654v1-arc-argument-representation-and-coverage-analysis-for-zero-shot-long.html">ARC: Argument Representation and Coverage Analysis for Zero-Shot Long Document Summarization with Instruction Following LLMs</a></td>
  <td>æå‡ºARCæ¡†æ¶ä»¥æå‡é›¶æ ·æœ¬é•¿æ–‡æ¡£æ‘˜è¦çš„è®ºç‚¹è¦†ç›–åˆ†æ</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">instruction following</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.23654v1" data-paper-url="./papers/250523654v1-arc-argument-representation-and-coverage-analysis-for-zero-shot-long.html" onclick="toggleFavorite(this, '2505.23654v1', 'ARC: Argument Representation and Coverage Analysis for Zero-Shot Long Document Summarization with Instruction Following LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250524012v1-large-language-model-meets-constraint-propagation.html">Large Language Model Meets Constraint Propagation</a></td>
  <td>æå‡ºGenCPä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹çº¦æŸæ‰§è¡Œä¸è¶³é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.24012v1" data-paper-url="./papers/250524012v1-large-language-model-meets-constraint-propagation.html" onclick="toggleFavorite(this, '2505.24012v1', 'Large Language Model Meets Constraint Propagation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250523966v3-flat-llm-fine-grained-low-rank-activation-space-transformation-for-l.html">FLAT-LLM: Fine-grained Low-rank Activation Space Transformation for Large Language Model Compression</a></td>
  <td>æå‡ºFLAT-LLMä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹å‹ç¼©ä¸­çš„æ•ˆç‡ä¸å‡†ç¡®æ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.23966v3" data-paper-url="./papers/250523966v3-flat-llm-fine-grained-low-rank-activation-space-transformation-for-l.html" onclick="toggleFavorite(this, '2505.23966v3', 'FLAT-LLM: Fine-grained Low-rank Activation Space Transformation for Large Language Model Compression')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250523944v1-retrieval-augmented-generation-based-large-language-models-for-causa.html">Retrieval Augmented Generation based Large Language Models for Causality Mining</a></td>
  <td>æå‡ºåŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆçš„åŠ¨æ€æç¤ºæ–¹æ¡ˆä»¥æå‡å› æœå…³ç³»æŒ–æ˜æ€§èƒ½</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.23944v1" data-paper-url="./papers/250523944v1-retrieval-augmented-generation-based-large-language-models-for-causa.html" onclick="toggleFavorite(this, '2505.23944v1', 'Retrieval Augmented Generation based Large Language Models for Causality Mining')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250523715v2-dont-take-the-premise-for-granted-evaluating-the-premise-critique-ab.html">Don't Take the Premise for Granted: Evaluating the Premise Critique Ability of Large Language Models</a></td>
  <td>æå‡ºPremise Critique Benchä»¥æå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„å‰ææ‰¹åˆ¤èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.23715v2" data-paper-url="./papers/250523715v2-dont-take-the-premise-for-granted-evaluating-the-premise-critique-ab.html" onclick="toggleFavorite(this, '2505.23715v2', 'Don&#39;t Take the Premise for Granted: Evaluating the Premise Critique Ability of Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250600077v3-gaussian-mixture-models-as-a-proxy-for-interacting-language-models.html">Gaussian mixture models as a proxy for interacting language models</a></td>
  <td>æå‡ºäº¤äº’é«˜æ–¯æ··åˆæ¨¡å‹ä»¥æ›¿ä»£å¤æ‚è¯­è¨€æ¨¡å‹</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.00077v3" data-paper-url="./papers/250600077v3-gaussian-mixture-models-as-a-proxy-for-interacting-language-models.html" onclick="toggleFavorite(this, '2506.00077v3', 'Gaussian mixture models as a proxy for interacting language models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250524009v2-diversity-of-transformer-layers-one-aspect-of-parameter-scaling-laws.html">Diversity of Transformer Layers: One Aspect of Parameter Scaling Laws</a></td>
  <td>æå‡ºå±‚é—´å¤šæ ·æ€§åˆ†æä»¥ä¼˜åŒ–Transformerå‚æ•°æ‰©å±•</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.24009v2" data-paper-url="./papers/250524009v2-diversity-of-transformer-layers-one-aspect-of-parameter-scaling-laws.html" onclick="toggleFavorite(this, '2505.24009v2', 'Diversity of Transformer Layers: One Aspect of Parameter Scaling Laws')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250523996v1-is-your-model-fairly-certain-uncertainty-aware-fairness-evaluation-f.html">Is Your Model Fairly Certain? Uncertainty-Aware Fairness Evaluation for LLMs</a></td>
  <td>æå‡ºUCerFä»¥è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹å…¬å¹³æ€§è¯„ä¼°ä¸­çš„ä¸ç¡®å®šæ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.23996v1" data-paper-url="./papers/250523996v1-is-your-model-fairly-certain-uncertainty-aware-fairness-evaluation-f.html" onclick="toggleFavorite(this, '2505.23996v1', 'Is Your Model Fairly Certain? Uncertainty-Aware Fairness Evaluation for LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250523932v2-swingarena-competitive-programming-arena-for-long-context-github-iss.html">SwingArena: Competitive Programming Arena for Long-context GitHub Issue Solving</a></td>
  <td>æå‡ºSwingArenaä»¥è§£å†³é•¿ä¸Šä¸‹æ–‡GitHubé—®é¢˜çš„è¯„ä¼°æŒ‘æˆ˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.23932v2" data-paper-url="./papers/250523932v2-swingarena-competitive-programming-arena-for-long-context-github-iss.html" onclick="toggleFavorite(this, '2505.23932v2', 'SwingArena: Competitive Programming Arena for Long-context GitHub Issue Solving')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/250523914v1-probing-association-biases-in-llm-moderation-over-sensitivity.html">Probing Association Biases in LLM Moderation Over-Sensitivity</a></td>
  <td>æå‡ºä¸»é¢˜å…³è”åˆ†æä»¥è§£å†³LLMå†…å®¹å®¡æ ¸è¿‡åº¦æ•æ„Ÿé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.23914v1" data-paper-url="./papers/250523914v1-probing-association-biases-in-llm-moderation-over-sensitivity.html" onclick="toggleFavorite(this, '2505.23914v1', 'Probing Association Biases in LLM Moderation Over-Sensitivity')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/250523911v1-one-task-vector-is-not-enough-a-large-scale-study-for-in-context-lea.html">One Task Vector is not Enough: A Large-Scale Study for In-Context Learning</a></td>
  <td>æå‡ºQuiteAFewæ•°æ®é›†ä»¥æå‡ä¸Šä¸‹æ–‡å­¦ä¹ çš„ä»»åŠ¡å‘é‡è¡¨ç°</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.23911v1" data-paper-url="./papers/250523911v1-one-task-vector-is-not-enough-a-large-scale-study-for-in-context-lea.html" onclick="toggleFavorite(this, '2505.23911v1', 'One Task Vector is not Enough: A Large-Scale Study for In-Context Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/250523729v2-bounded-rationality-for-llms-satisficing-alignment-at-inference-time.html">Bounded Rationality for LLMs: Satisficing Alignment at Inference-Time</a></td>
  <td>æå‡ºSITAlignæ¡†æ¶ä»¥è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹çš„å¯¹é½é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.23729v2" data-paper-url="./papers/250523729v2-bounded-rationality-for-llms-satisficing-alignment-at-inference-time.html" onclick="toggleFavorite(this, '2505.23729v2', 'Bounded Rationality for LLMs: Satisficing Alignment at Inference-Time')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/250523722v2-llms-are-better-than-you-think-label-guided-in-context-learning-for-.html">LLMs are Better Than You Think: Label-Guided In-Context Learning for Named Entity Recognition</a></td>
  <td>æå‡ºDEERæ–¹æ³•ä»¥æå‡å‘½åå®ä½“è¯†åˆ«çš„æ•ˆæœ</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.23722v2" data-paper-url="./papers/250523722v2-llms-are-better-than-you-think-label-guided-in-context-learning-for-.html" onclick="toggleFavorite(this, '2505.23722v2', 'LLMs are Better Than You Think: Label-Guided In-Context Learning for Named Entity Recognition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/250523701v1-can-llms-reason-abstractly-over-math-word-problems-without-cot-disen.html">Can LLMs Reason Abstractly Over Math Word Problems Without CoT? Disentangling Abstract Formulation From Arithmetic Computation</a></td>
  <td>æå‡ºåˆ†ç¦»è¯„ä¼°æ–¹æ³•ä»¥æå‡å¤§è¯­è¨€æ¨¡å‹åœ¨æ•°å­¦é—®é¢˜ä¸Šçš„æ¨ç†èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.23701v1" data-paper-url="./papers/250523701v1-can-llms-reason-abstractly-over-math-word-problems-without-cot-disen.html" onclick="toggleFavorite(this, '2505.23701v1', 'Can LLMs Reason Abstractly Over Math Word Problems Without CoT? Disentangling Abstract Formulation From Arithmetic Computation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/250523662v2-toolhaystack-stress-testing-tool-augmented-language-models-in-realis.html">ToolHaystack: Stress-Testing Tool-Augmented Language Models in Realistic Long-Term Interactions</a></td>
  <td>æå‡ºToolHaystackä»¥è§£å†³é•¿æ—¶é—´äº¤äº’ä¸­å·¥å…·ä½¿ç”¨è¯„ä¼°ä¸è¶³çš„é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.23662v2" data-paper-url="./papers/250523662v2-toolhaystack-stress-testing-tool-augmented-language-models-in-realis.html" onclick="toggleFavorite(this, '2505.23662v2', 'ToolHaystack: Stress-Testing Tool-Augmented Language Models in Realistic Long-Term Interactions')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/250523628v3-autoschemakg-autonomous-knowledge-graph-construction-through-dynamic.html">AutoSchemaKG: Autonomous Knowledge Graph Construction through Dynamic Schema Induction from Web-Scale Corpora</a></td>
  <td>æå‡ºAutoSchemaKGä»¥å®ç°è‡ªä¸»çŸ¥è¯†å›¾è°±æ„å»º</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.23628v3" data-paper-url="./papers/250523628v3-autoschemakg-autonomous-knowledge-graph-construction-through-dynamic.html" onclick="toggleFavorite(this, '2505.23628v3', 'AutoSchemaKG: Autonomous Knowledge Graph Construction through Dynamic Schema Induction from Web-Scale Corpora')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (9 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>20</td>
  <td><a href="./papers/250523657v3-active-layer-contrastive-decoding-reduces-hallucination-in-large-lan.html">Active Layer-Contrastive Decoding Reduces Hallucination in Large Language Model Generation</a></td>
  <td>æå‡ºä¸»åŠ¨å±‚å¯¹æ¯”è§£ç ä»¥å‡å°‘å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆä¸­çš„å¹»è§‰é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.23657v3" data-paper-url="./papers/250523657v3-active-layer-contrastive-decoding-reduces-hallucination-in-large-lan.html" onclick="toggleFavorite(this, '2505.23657v3', 'Active Layer-Contrastive Decoding Reduces Hallucination in Large Language Model Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>21</td>
  <td><a href="./papers/250523754v2-deeptheorem-advancing-llm-reasoning-for-theorem-proving-through-natu.html">DeepTheorem: Advancing LLM Reasoning for Theorem Proving Through Natural Language and Reinforcement Learning</a></td>
  <td>æå‡ºDeepTheoremä»¥æå‡å¤§è¯­è¨€æ¨¡å‹çš„å®šç†è¯æ˜èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">IMoS</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.23754v2" data-paper-url="./papers/250523754v2-deeptheorem-advancing-llm-reasoning-for-theorem-proving-through-natu.html" onclick="toggleFavorite(this, '2505.23754v2', 'DeepTheorem: Advancing LLM Reasoning for Theorem Proving Through Natural Language and Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>22</td>
  <td><a href="./papers/250523912v1-reinforcement-learning-for-better-verbalized-confidence-in-long-form.html">Reinforcement Learning for Better Verbalized Confidence in Long-Form Generation</a></td>
  <td>æå‡ºLoVeCä»¥è§£å†³é•¿æ–‡æœ¬ç”Ÿæˆä¸­çš„ä¿¡å¿ƒä¼°è®¡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">DPO</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.23912v1" data-paper-url="./papers/250523912v1-reinforcement-learning-for-better-verbalized-confidence-in-long-form.html" onclick="toggleFavorite(this, '2505.23912v1', 'Reinforcement Learning for Better Verbalized Confidence in Long-Form Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>23</td>
  <td><a href="./papers/250524033v1-the-surprising-soupability-of-documents-in-state-space-models.html">The Surprising Soupability of Documents in State Space Models</a></td>
  <td>æå‡ºæ–‡æ¡£åˆå¹¶ç­–ç•¥ä»¥æå‡çŠ¶æ€ç©ºé—´æ¨¡å‹çš„æ¨ç†èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">Mamba</span> <span class="paper-tag">SSM</span> <span class="paper-tag">state space model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.24033v1" data-paper-url="./papers/250524033v1-the-surprising-soupability-of-documents-in-state-space-models.html" onclick="toggleFavorite(this, '2505.24033v1', 'The Surprising Soupability of Documents in State Space Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>24</td>
  <td><a href="./papers/250523723v1-ml-agent-reinforcing-llm-agents-for-autonomous-machine-learning-engi.html">ML-Agent: Reinforcing LLM Agents for Autonomous Machine Learning Engineering</a></td>
  <td>æå‡ºML-Agentä»¥è§£å†³è‡ªä¸»æœºå™¨å­¦ä¹ å·¥ç¨‹ä¸­çš„æ‰‹åŠ¨æç¤ºå·¥ç¨‹é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.23723v1" data-paper-url="./papers/250523723v1-ml-agent-reinforcing-llm-agents-for-autonomous-machine-learning-engi.html" onclick="toggleFavorite(this, '2505.23723v1', 'ML-Agent: Reinforcing LLM Agents for Autonomous Machine Learning Engineering')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>25</td>
  <td><a href="./papers/250523666v2-lola-low-rank-linear-attention-with-sparse-caching.html">LoLA: Low-Rank Linear Attention With Sparse Caching</a></td>
  <td>æå‡ºLoLAä»¥æå‡çº¿æ€§æ³¨æ„åŠ›çš„å…³è”è®°å¿†èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">linear attention</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.23666v2" data-paper-url="./papers/250523666v2-lola-low-rank-linear-attention-with-sparse-caching.html" onclick="toggleFavorite(this, '2505.23666v2', 'LoLA: Low-Rank Linear Attention With Sparse Caching')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>26</td>
  <td><a href="./papers/250523646v1-are-reasoning-models-more-prone-to-hallucination.html">Are Reasoning Models More Prone to Hallucination?</a></td>
  <td>æ¢è®¨æ¨ç†æ¨¡å‹åœ¨å¹»è§‰ç°è±¡ä¸­çš„è„†å¼±æ€§</td>
  <td class="tags-cell"><span class="paper-tag">distillation</span> <span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.23646v1" data-paper-url="./papers/250523646v1-are-reasoning-models-more-prone-to-hallucination.html" onclick="toggleFavorite(this, '2505.23646v1', 'Are Reasoning Models More Prone to Hallucination?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>27</td>
  <td><a href="./papers/250523923v1-charm-character-based-act-adaptive-reward-modeling-for-advanced-role.html">ChARM: Character-based Act-adaptive Reward Modeling for Advanced Role-Playing Language Agents</a></td>
  <td>æå‡ºChARMä»¥è§£å†³è§’è‰²æ‰®æ¼”è¯­è¨€ä»£ç†çš„å¥–åŠ±å»ºæ¨¡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">preference learning</span> <span class="paper-tag">direct preference optimization</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.23923v1" data-paper-url="./papers/250523923v1-charm-character-based-act-adaptive-reward-modeling-for-advanced-role.html" onclick="toggleFavorite(this, '2505.23923v1', 'ChARM: Character-based Act-adaptive Reward Modeling for Advanced Role-Playing Language Agents')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>28</td>
  <td><a href="./papers/250523621v2-table-r1-inference-time-scaling-for-table-reasoning.html">Table-R1: Inference-Time Scaling for Table Reasoning</a></td>
  <td>æå‡ºTable-R1ä»¥å®ç°è¡¨æ ¼æ¨ç†ä»»åŠ¡çš„æ¨ç†æ—¶é—´æ‰©å±•</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">distillation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.23621v2" data-paper-url="./papers/250523621v2-table-r1-inference-time-scaling-for-table-reasoning.html" onclick="toggleFavorite(this, '2505.23621v2', 'Table-R1: Inference-Time Scaling for Table Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>29</td>
  <td><a href="./papers/250524028v1-hidden-persuasion-detecting-manipulative-narratives-on-social-media-.html">Hidden Persuasion: Detecting Manipulative Narratives on Social Media During the 2022 Russian Invasion of Ukraine</a></td>
  <td>æå‡ºä¸€ç§æ–¹æ³•ä»¥æ£€æµ‹ç¤¾äº¤åª’ä½“ä¸­çš„æ“æ§å™äº‹</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.24028v1" data-paper-url="./papers/250524028v1-hidden-persuasion-detecting-manipulative-narratives-on-social-media-.html" onclick="toggleFavorite(this, '2505.24028v1', 'Hidden Persuasion: Detecting Manipulative Narratives on Social Media During the 2022 Russian Invasion of Ukraine')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CL é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)