---
layout: default
title: One-shot Entropy Minimization
---

# One-shot Entropy Minimization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20282" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.20282v4</a>
  <a href="https://arxiv.org/pdf/2505.20282.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20282v4" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20282v4', 'One-shot Entropy Minimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zitian Gao, Lynx Chen, Haoming Luo, Joey Zhou, Bryan Dai

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-26 (æ›´æ–°: 2025-08-21)

**å¤‡æ³¨**: Work in progress

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/zitian-gao/one-shot-em)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå•æ¬¡ç†µæœ€å°åŒ–æ–¹æ³•ä»¥æå‡å¤§è¯­è¨€æ¨¡å‹æ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç†µæœ€å°åŒ–` `å¤§è¯­è¨€æ¨¡å‹` `æ— ç›‘ç£å­¦ä¹ ` `ä¼˜åŒ–ç®—æ³•` `æ€§èƒ½æå‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„åŸºäºè§„åˆ™çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡æ ‡è®°æ•°æ®å’Œå¤æ‚çš„å¥–åŠ±è®¾è®¡ï¼Œæ•ˆç‡ä½ä¸‹ä¸”æˆæœ¬é«˜æ˜‚ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§å•æ¬¡ç†µæœ€å°åŒ–çš„æ–¹æ³•ï¼Œé€šè¿‡ä»…ä½¿ç”¨ä¸€ä¸ªæœªæ ‡è®°çš„æ•°æ®æ ·æœ¬å’Œ10æ­¥ä¼˜åŒ–æ¥æå‡æ¨¡å‹æ€§èƒ½ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨æ€§èƒ½ä¸Šä¸ä¼ ç»Ÿæ–¹æ³•ç›¸å½“ï¼Œç”šè‡³åœ¨æŸäº›æƒ…å†µä¸‹è¡¨ç°æ›´ä½³ï¼Œå±•ç¤ºäº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬è®­ç»ƒäº†13,440ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå‘ç°ç†µæœ€å°åŒ–åªéœ€ä¸€ä¸ªæœªæ ‡è®°æ•°æ®å’Œ10æ­¥ä¼˜åŒ–ï¼Œå³å¯å®ç°ä¸ä½¿ç”¨æˆåƒä¸Šä¸‡çš„æ•°æ®å’Œç²¾å¿ƒè®¾è®¡çš„å¥–åŠ±åœ¨åŸºäºè§„åˆ™çš„å¼ºåŒ–å­¦ä¹ ä¸­ç›¸åª²ç¾ç”šè‡³æ›´é«˜çš„æ€§èƒ½æå‡ã€‚è¿™ä¸€æ˜¾è‘—ç»“æœå¯èƒ½ä¿ƒä½¿å¯¹å¤§å‹è¯­è¨€æ¨¡å‹åè®­ç»ƒèŒƒå¼çš„é‡æ–°æ€è€ƒã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨https://github.com/zitian-gao/one-shot-emè·å–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰åŸºäºè§„åˆ™çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨æ•°æ®éœ€æ±‚å’Œæ•ˆç‡ä¸Šçš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦å¤§é‡æ ‡è®°æ•°æ®çš„æƒ…å†µä¸‹ï¼Œå¯¼è‡´è®­ç»ƒæˆæœ¬é«˜æ˜‚ä¸”æ—¶é—´æ¶ˆè€—å¤§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ç†µæœ€å°åŒ–æŠ€æœ¯ï¼Œä»…ä¾èµ–ä¸€ä¸ªæœªæ ‡è®°çš„æ•°æ®æ ·æœ¬ï¼Œç»“åˆ10æ­¥ä¼˜åŒ–ï¼Œæ¥å®ç°æ¨¡å‹æ€§èƒ½çš„æ˜¾è‘—æå‡ã€‚è¿™ç§æ–¹æ³•å‡å°‘äº†å¯¹å¤§é‡æ ‡è®°æ•°æ®çš„ä¾èµ–ï¼Œç®€åŒ–äº†è®­ç»ƒè¿‡ç¨‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®è¾“å…¥æ¨¡å—ã€ç†µè®¡ç®—æ¨¡å—å’Œä¼˜åŒ–æ¨¡å—ã€‚é¦–å…ˆï¼Œè¾“å…¥ä¸€ä¸ªæœªæ ‡è®°çš„æ•°æ®æ ·æœ¬ï¼Œç„¶åè®¡ç®—å…¶ç†µå€¼ï¼Œæœ€åé€šè¿‡ä¼˜åŒ–ç®—æ³•è¿›è¡Œ10æ­¥è¿­ä»£ï¼Œä»¥æœ€å°åŒ–ç†µå€¼å¹¶æå‡æ¨¡å‹æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºé€šè¿‡å•æ¬¡ç†µæœ€å°åŒ–å®ç°äº†ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸åª²ç¾çš„æ€§èƒ½æå‡ï¼Œæ ¹æœ¬ä¸Šæ”¹å˜äº†å¯¹æ•°æ®éœ€æ±‚çš„ç†è§£ï¼Œé™ä½äº†è®­ç»ƒæˆæœ¬ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œä¼˜åŒ–è¿‡ç¨‹ä¸­çš„å­¦ä¹ ç‡å’Œç†µè®¡ç®—æ–¹å¼æ˜¯å…³é”®è®¾è®¡å› ç´ ã€‚æ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°çš„é€‰æ‹©ä¹Ÿå¯¹æ¨¡å‹çš„æ”¶æ•›é€Ÿåº¦å’Œæœ€ç»ˆæ€§èƒ½æœ‰é‡è¦å½±å“ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨å•æ¬¡ç†µæœ€å°åŒ–æ–¹æ³•çš„æ¨¡å‹åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œæ€§èƒ½æå‡å¹…åº¦å¯ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸åª²ç¾ï¼Œç”šè‡³åœ¨æŸäº›ä»»åŠ¡ä¸­è¶…è¿‡äº†ä½¿ç”¨æˆåƒä¸Šä¸‡æ ‡è®°æ•°æ®çš„æ¨¡å‹ï¼Œå±•ç¤ºäº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œæ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€å¯¹è¯ç³»ç»Ÿå’Œæ–‡æœ¬ç”Ÿæˆç­‰ã€‚é€šè¿‡å‡å°‘å¯¹æ ‡è®°æ•°æ®çš„ä¾èµ–ï¼Œèƒ½å¤Ÿé™ä½è®­ç»ƒæˆæœ¬ï¼Œæé«˜æ¨¡å‹çš„å¯ç”¨æ€§ï¼Œå°¤å…¶æ˜¯åœ¨æ•°æ®ç¨€ç¼ºçš„åœºæ™¯ä¸­ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½ä¼šæ¨åŠ¨æ›´å¤šé«˜æ•ˆçš„è®­ç»ƒç­–ç•¥å’Œæ¨¡å‹ä¼˜åŒ–æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We trained 13,440 large language models and found that entropy minimization requires only a single unlabeled data and 10 steps optimization to achieve performance improvements comparable to or even greater than those obtained using thousands of data and carefully designed rewards in rule-based reinforcement learning. This striking result may prompt a rethinking of post-training paradigms for large language models. Our code is avaliable at https://github.com/zitian-gao/one-shot-em.

