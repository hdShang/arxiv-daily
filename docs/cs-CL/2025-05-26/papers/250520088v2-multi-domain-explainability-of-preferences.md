---
layout: default
title: Multi-Domain Explainability of Preferences
---

# Multi-Domain Explainability of Preferences

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20088" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.20088v2</a>
  <a href="https://arxiv.org/pdf/2505.20088.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20088v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20088v2', 'Multi-Domain Explainability of Preferences')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Nitay Calderon, Liat Ein-Dor, Roi Reichart

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-26 (æ›´æ–°: 2025-05-29)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§è‡ªåŠ¨åŒ–æ–¹æ³•ä»¥å®ç°å¤šé¢†åŸŸåå¥½è§£é‡Š**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åå¥½æœºåˆ¶` `å¯è§£é‡Šæ€§` `å¤§å‹è¯­è¨€æ¨¡å‹` `å±‚æ¬¡å›å½’` `å¤šé¢†åŸŸå­¦ä¹ ` `è‡ªåŠ¨åŒ–æ–¹æ³•` `äººæœºäº¤äº’`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„åå¥½æœºåˆ¶åœ¨ç†è§£é©±åŠ¨åå¥½çš„åŸºæœ¬æ¦‚å¿µæ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´å¤§å‹è¯­è¨€æ¨¡å‹çš„å¯¹é½å’Œè¯„ä¼°é¢ä¸´æŒ‘æˆ˜ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§è‡ªåŠ¨åŒ–æ–¹æ³•ï¼Œé€šè¿‡LLMè¯†åˆ«å’Œè¡¨ç¤ºåŒºåˆ†é€‰æ‹©ä¸æ‹’ç»å“åº”çš„æ¦‚å¿µï¼Œè¿›è€Œç”Ÿæˆåå¥½è§£é‡Šã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åå¥½é¢„æµ‹ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†ç°æœ‰åŸºçº¿ï¼Œå¹¶åœ¨å®é™…åº”ç”¨ä¸­å±•ç°å‡ºè‰¯å¥½çš„å¯è§£é‡Šæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åå¥½æœºåˆ¶ï¼Œå¦‚äººç±»åå¥½ã€LLMä½œä¸ºè¯„åˆ¤è€…ï¼ˆLaaJï¼‰å’Œå¥–åŠ±æ¨¡å‹ï¼Œå¯¹äºå¯¹é½å’Œè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œé©±åŠ¨è¿™äº›åå¥½çš„åŸºæœ¬æ¦‚å¿µä»ç„¶ä¸å¤Ÿæ¸…æ™°ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§å…¨è‡ªåŠ¨çš„æ–¹æ³•ï¼Œèƒ½å¤Ÿç”Ÿæˆè·¨å¤šä¸ªé¢†åŸŸçš„å±€éƒ¨å’Œå…¨å±€æ¦‚å¿µåŸºç¡€çš„åå¥½è§£é‡Šã€‚è¯¥æ–¹æ³•åˆ©ç”¨LLMè¯†åˆ«åŒºåˆ†é€‰æ‹©å’Œæ‹’ç»å“åº”çš„æ¦‚å¿µï¼Œå¹¶ç”¨æ¦‚å¿µå‘é‡è¡¨ç¤ºå®ƒä»¬ã€‚ä¸ºäº†å»ºæ¨¡æ¦‚å¿µä¸åå¥½ä¹‹é—´çš„å…³ç³»ï¼Œæå‡ºäº†ä¸€ç§ç™½ç›’çš„å±‚æ¬¡å¤šé¢†åŸŸå›å½’æ¨¡å‹ï¼Œæ•æ‰é¢†åŸŸé€šç”¨å’Œé¢†åŸŸç‰¹å®šçš„æ•ˆåº”ã€‚é€šè¿‡æ„å»ºæ¶µç›–å…«ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§å’Œå¤šæ ·åŒ–é¢†åŸŸçš„æ•°æ®é›†ï¼Œæˆ‘ä»¬è¯„ä¼°äº†è¯¥æ–¹æ³•ï¼Œå¹¶è§£é‡Šäº†åäºŒç§æœºåˆ¶ã€‚è¯¥æ–¹æ³•åœ¨åå¥½é¢„æµ‹æ€§èƒ½ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†åŸºçº¿ï¼ŒåŒæ—¶å…·å¤‡å¯è§£é‡Šæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åå¥½æœºåˆ¶çš„è§£é‡Šæ€§ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•å¯¹é©±åŠ¨åå¥½çš„åŸºæœ¬æ¦‚å¿µç†è§£ä¸å¤Ÿæ·±å…¥ï¼Œå¯¼è‡´å¤§å‹è¯­è¨€æ¨¡å‹çš„å¯¹é½å’Œè¯„ä¼°é¢ä¸´æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºä¸€ç§å…¨è‡ªåŠ¨çš„æ–¹æ³•ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¯†åˆ«å’Œè¡¨ç¤ºåŒºåˆ†é€‰æ‹©å’Œæ‹’ç»å“åº”çš„æ¦‚å¿µï¼Œç”Ÿæˆå±€éƒ¨å’Œå…¨å±€çš„åå¥½è§£é‡Šã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ¦‚å¿µè¯†åˆ«æ¨¡å—ã€æ¦‚å¿µå‘é‡è¡¨ç¤ºæ¨¡å—å’Œå±‚æ¬¡å¤šé¢†åŸŸå›å½’æ¨¡å‹ã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿæ•æ‰é¢†åŸŸé€šç”¨å’Œé¢†åŸŸç‰¹å®šçš„æ•ˆåº”ï¼Œå½¢æˆå®Œæ•´çš„åå¥½è§£é‡Šä½“ç³»ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæå‡ºäº†ç™½ç›’çš„å±‚æ¬¡å¤šé¢†åŸŸå›å½’æ¨¡å‹ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°å»ºæ¨¡æ¦‚å¿µä¸åå¥½ä¹‹é—´çš„å…³ç³»ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†æ›´é«˜çš„å¯è§£é‡Šæ€§å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–åå¥½é¢„æµ‹æ€§èƒ½ï¼Œå¹¶é€šè¿‡ç²¾å¿ƒé€‰æ‹©çš„å‚æ•°è®¾ç½®æ¥å¢å¼ºæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•åœ¨åå¥½é¢„æµ‹æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºåŸºçº¿ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨å¤šä¸ªé¢†åŸŸçš„åå¥½é¢„æµ‹å‡†ç¡®ç‡æå‡è¶…è¿‡20%ã€‚æ­¤å¤–ï¼Œé€šè¿‡å¼•å¯¼LLMè¾“å‡ºå’Œæ”¹è¿›LaaJçš„åå¥½é¢„æµ‹ï¼Œè¿›ä¸€æ­¥éªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬äººæœºäº¤äº’ã€æ¨èç³»ç»Ÿå’Œè‡ªåŠ¨å†…å®¹ç”Ÿæˆç­‰ã€‚é€šè¿‡æä¾›å¯è§£é‡Šçš„åå¥½æœºåˆ¶ï¼Œèƒ½å¤Ÿæå‡ç”¨æˆ·ä½“éªŒå’Œç³»ç»Ÿçš„é€æ˜åº¦ï¼Œæœªæ¥å¯èƒ½åœ¨å¤šä¸ªè¡Œä¸šä¸­äº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Preference mechanisms, such as human preference, LLM-as-a-Judge (LaaJ), and reward models, are central to aligning and evaluating large language models (LLMs). Yet, the underlying concepts that drive these preferences remain poorly understood. In this work, we propose a fully automated method for generating local and global concept-based explanations of preferences across multiple domains. Our method utilizes an LLM to identify concepts that distinguish between chosen and rejected responses, and to represent them with concept-based vectors. To model the relationships between concepts and preferences, we propose a white-box Hierarchical Multi-Domain Regression model that captures both domain-general and domain-specific effects. To evaluate our method, we curate a dataset spanning eight challenging and diverse domains and explain twelve mechanisms. Our method achieves strong preference prediction performance, outperforming baselines while also being explainable. Additionally, we assess explanations in two application-driven settings. First, guiding LLM outputs with concepts from LaaJ explanations yields responses that those judges consistently prefer. Second, prompting LaaJs with concepts explaining humans improves their preference predictions. Together, our work establishes a new paradigm for explainability in the era of LLMs.

