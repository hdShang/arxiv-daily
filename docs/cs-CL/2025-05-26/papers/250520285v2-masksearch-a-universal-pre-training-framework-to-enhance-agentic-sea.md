---
layout: default
title: MaskSearch: A Universal Pre-Training Framework to Enhance Agentic Search Capability
---

# MaskSearch: A Universal Pre-Training Framework to Enhance Agentic Search Capability

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20285" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.20285v2</a>
  <a href="https://arxiv.org/pdf/2505.20285.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20285v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20285v2', 'MaskSearch: A Universal Pre-Training Framework to Enhance Agentic Search Capability')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Weiqi Wu, Xin Guan, Shen Huang, Yong Jiang, Pengjun Xie, Fei Huang, Jiuxin Cao, Hai Zhao, Jingren Zhou

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-26 (æ›´æ–°: 2025-05-27)

**å¤‡æ³¨**: Code is available at https://github.com/Alibaba-NLP/MaskSearch

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMaskSearchæ¡†æ¶ä»¥å¢å¼ºæ™ºèƒ½æœç´¢èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ£€ç´¢å¢å¼ºæ¨¡å‹` `é¢„è®­ç»ƒæ¡†æ¶` `æ™ºèƒ½æœç´¢` `å¤šè·³é—®ç­”` `å¼ºåŒ–å­¦ä¹ ` `ç›‘ç£å¾®è°ƒ` `è¯¾ç¨‹å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æ™ºèƒ½æœç´¢èƒ½åŠ›ä¸Šå—é™äºä»»åŠ¡ç‰¹å®šæ•°æ®ï¼Œæ— æ³•æœ‰æ•ˆæå‡é€šç”¨æ€§ã€‚
2. æå‡ºMaskSearchæ¡†æ¶ï¼Œé€šè¿‡RAMPä»»åŠ¡ä½¿æ¨¡å‹å­¦ä¹ åˆ©ç”¨æœç´¢å·¥å…·å¡«å……æ©ç ï¼Œä»è€Œå¢å¼ºæ£€ç´¢å’Œæ¨ç†èƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒMaskSearchåœ¨å¼€æ”¾åŸŸå¤šè·³é—®ç­”ä»»åŠ¡ä¸­æ˜¾è‘—æå‡äº†LLMæœç´¢ä»£ç†çš„æ€§èƒ½ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ£€ç´¢å¢å¼ºè¯­è¨€æ¨¡å‹ï¼ˆRALMsï¼‰æ˜¯ä¸€ç§ç»å…¸èŒƒå¼ï¼Œé€šè¿‡ä¸“é—¨æ¨¡å—åˆ©ç”¨å¤–éƒ¨çŸ¥è¯†æ¥å¢å¼ºç”Ÿæˆèƒ½åŠ›ã€‚å°½ç®¡ç°æœ‰è®­ç»ƒæ–¹æ³•å±•ç°å‡ºæ½œåŠ›ï¼Œä½†å…¶æ™ºèƒ½èƒ½åŠ›å—åˆ°ä»»åŠ¡ç‰¹å®šæ•°æ®çš„é™åˆ¶ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„é¢„è®­ç»ƒæ¡†æ¶MaskSearchã€‚åœ¨é¢„è®­ç»ƒé˜¶æ®µï¼Œå¼•å…¥äº†æ£€ç´¢å¢å¼ºæ©ç é¢„æµ‹ï¼ˆRAMPï¼‰ä»»åŠ¡ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿåˆ©ç”¨æœç´¢å·¥å…·å¡«å……å¤§é‡é¢„è®­ç»ƒæ•°æ®ä¸­çš„æ©ç ï¼Œä»è€Œè·å¾—é€šç”¨çš„æ£€ç´¢å’Œæ¨ç†èƒ½åŠ›ã€‚æ¨¡å‹åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸Šè¿›ä¸€æ­¥è®­ç»ƒï¼Œç»“åˆç›‘ç£å¾®è°ƒå’Œå¼ºåŒ–å­¦ä¹ ï¼Œæœ€ç»ˆåœ¨å¼€æ”¾åŸŸå¤šè·³é—®ç­”åœºæ™¯ä¸­æ˜¾è‘—æå‡äº†åŸºäºLLMçš„æœç´¢ä»£ç†çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰æ™ºèƒ½æœç´¢ä»£ç†åœ¨é€šç”¨æ€§å’Œèƒ½åŠ›ä¸Šçš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯å—é™äºä»»åŠ¡ç‰¹å®šæ•°æ®çš„è®­ç»ƒæ–¹æ³•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥æ£€ç´¢å¢å¼ºæ©ç é¢„æµ‹ï¼ˆRAMPï¼‰ä»»åŠ¡ï¼Œä½¿æ¨¡å‹åœ¨é¢„è®­ç»ƒé˜¶æ®µå­¦ä¹ å¦‚ä½•åˆ©ç”¨æœç´¢å·¥å…·å¡«å……æ©ç ï¼Œä»è€Œè·å¾—æ›´å¼ºçš„æ£€ç´¢å’Œæ¨ç†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬é¢„è®­ç»ƒé˜¶æ®µå’Œä¸‹æ¸¸ä»»åŠ¡è®­ç»ƒé˜¶æ®µã€‚åœ¨é¢„è®­ç»ƒé˜¶æ®µï¼Œæ¨¡å‹é€šè¿‡RAMPä»»åŠ¡å­¦ä¹ ï¼›åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­ï¼Œç»“åˆç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è¿›è¡Œè¿›ä¸€æ­¥è®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºRAMPä»»åŠ¡çš„å¼•å…¥ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨å¤§è§„æ¨¡æ•°æ®ä¸Šå­¦ä¹ é€šç”¨çš„æ£€ç´¢èƒ½åŠ›ï¼Œè€Œä¸æ˜¯ä»…ä¾èµ–äºç‰¹å®šä»»åŠ¡çš„æ•°æ®ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨SFTä¸­ï¼Œé‡‡ç”¨å¤šä»£ç†ç³»ç»Ÿç”Ÿæˆè®­ç»ƒæ•°æ®ï¼Œç»“åˆè§„åˆ’è€…ã€é‡å†™è€…å’Œè§‚å¯Ÿè€…ï¼›åœ¨RLä¸­ï¼Œä½¿ç”¨DAPOæ¡†æ¶å’Œæ··åˆå¥–åŠ±ç³»ç»Ÿï¼Œè®¾è®¡äº†é€æ­¥å­¦ä¹ çš„è¯¾ç¨‹å­¦ä¹ æ–¹æ³•ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMaskSearchåœ¨å¼€æ”¾åŸŸå¤šè·³é—®ç­”ä»»åŠ¡ä¸­ï¼Œç›¸è¾ƒäºåŸºçº¿æ¨¡å‹ï¼Œæ€§èƒ½æå‡æ˜¾è‘—ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°XX%ï¼ˆå…·ä½“æ•°æ®å¾…è¡¥å……ï¼‰ï¼ŒéªŒè¯äº†å…¶åœ¨ä¸åŒé¢†åŸŸçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¼€æ”¾åŸŸé—®ç­”ç³»ç»Ÿã€æ™ºèƒ½åŠ©æ‰‹å’Œä¿¡æ¯æ£€ç´¢ç­‰ã€‚é€šè¿‡æå‡æ¨¡å‹çš„æ£€ç´¢å’Œæ¨ç†èƒ½åŠ›ï¼ŒMaskSearchèƒ½å¤Ÿåœ¨å¤šç§å®é™…åœºæ™¯ä¸­æä¾›æ›´ä¸ºå‡†ç¡®å’Œé«˜æ•ˆçš„æœç´¢ç»“æœï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Retrieval-Augmented Language Models (RALMs) represent a classic paradigm where models enhance generative capabilities using external knowledge retrieved via a specialized module. Recent advancements in Agent techniques enable Large Language Models (LLMs) to autonomously utilize tools for retrieval, planning, and reasoning. While existing training-based methods show promise, their agentic abilities are limited by inherent characteristics of the task-specific data used during training. To further enhance the universal search capability of agents, we propose a novel pre-training framework, MaskSearch. In the pre-training stage, we introduce the Retrieval Augmented Mask Prediction (RAMP) task, where the model learns to leverage search tools to fill masked spans on a large number of pre-training data, thus acquiring universal retrieval and reasoning capabilities for LLMs. After that, the model is trained on downstream tasks to achieve further improvement. We apply both Supervised Fine-tuning (SFT) and Reinforcement Learning (RL) for training. For SFT, we combine agent-based and distillation-based methods to generate training data, starting with a multi-agent system consisting of a planner, rewriter, observer, and followed by a self-evolving teacher model. While for RL, we employ DAPO as the training framework and adopt a hybrid reward system consisting of answer rewards and format rewards. Additionally, we introduce a curriculum learning approach that allows the model to learn progressively from easier to more challenging instances based on the number of masked spans. We evaluate the effectiveness of our framework in the scenario of open-domain multi-hop question answering. Through extensive experiments, we demonstrate that MaskSearch significantly enhances the performance of LLM-based search agents on both in-domain and out-of-domain downstream tasks.

