---
layout: default
title: "ALAS: Measuring Latent Speech-Text Alignment For Spoken Language Understanding In Multimodal LLMs"
---

# ALAS: Measuring Latent Speech-Text Alignment For Spoken Language Understanding In Multimodal LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.19937" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.19937v2</a>
  <a href="https://arxiv.org/pdf/2505.19937.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.19937v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.19937v2', 'ALAS: Measuring Latent Speech-Text Alignment For Spoken Language Understanding In Multimodal LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Pooneh Mousavi, Yingzhi Wang, Mirco Ravanelli, Cem Subakan

**åˆ†ç±»**: cs.CL, cs.SD, eess.AS

**å‘å¸ƒæ—¥æœŸ**: 2025-05-26 (æ›´æ–°: 2025-07-04)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºALASä»¥è§£å†³å¤šæ¨¡æ€LLMsä¸­çš„è¯­éŸ³æ–‡æœ¬å¯¹é½é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `è¯­éŸ³ç†è§£` `æ–‡æœ¬å¯¹é½` `å˜æ¢å™¨æ¨¡å‹` `è‡ªåŠ¨è¯„ä¼°` `æƒ…æ„Ÿè¯†åˆ«` `å£è¯­é—®ç­”`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ç¼ºä¹æ ‡å‡†åŒ–çš„æŒ‡æ ‡æ¥è¯„ä¼°éŸ³é¢‘ä¸æ–‡æœ¬ä¹‹é—´çš„å¯¹é½ï¼Œé™åˆ¶äº†å¤šæ¨¡æ€å­¦ä¹ çš„æœ‰æ•ˆæ€§ã€‚
2. æœ¬æ–‡æå‡ºALASæŒ‡æ ‡ï¼Œé€šè¿‡åˆ†æå˜æ¢å™¨å±‚ä¸­éŸ³é¢‘ä¸æ–‡æœ¬è¡¨ç¤ºçš„ç›¸å…³æ€§æ¥è¯„ä¼°å¯¹é½ç¨‹åº¦ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒALASåœ¨å£è¯­é—®ç­”å’Œæƒ…æ„Ÿè¯†åˆ«ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ•æ‰å¯¹é½æ¨¡å¼ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å£è¯­ç†è§£ï¼ˆSLUï¼‰ä¸­çš„åº”ç”¨æ—¥ç›Šå¢å¤šï¼Œè€Œæœ‰æ•ˆçš„å¤šæ¨¡æ€å­¦ä¹ ä¾èµ–äºéŸ³é¢‘ä¸æ–‡æœ¬ä¹‹é—´çš„å¯¹é½ã€‚å°½ç®¡å·²æœ‰å¤šç§èåˆæ–¹æ³•ï¼Œä½†ç›®å‰å°šæ— æ ‡å‡†æŒ‡æ ‡æ¥è¯„ä¼°è¿™ç§å¯¹é½ã€‚æœ¬æ–‡æå‡ºäº†ALASï¼ˆè‡ªåŠ¨æ½œåœ¨å¯¹é½è¯„åˆ†ï¼‰ï¼Œè¯¥æŒ‡æ ‡é€šè¿‡æµ‹é‡å˜æ¢å™¨å±‚ä¹‹é—´éŸ³é¢‘å’Œæ–‡æœ¬è¡¨ç¤ºçš„ç›¸å…³æ€§æ¥è¯„ä¼°å¯¹é½ã€‚é’ˆå¯¹å£è¯­é—®ç­”å’Œæƒ…æ„Ÿè¯†åˆ«çš„å®éªŒè¡¨æ˜ï¼ŒALASèƒ½å¤Ÿæ•æ‰åˆ°è·¨ä»»åŠ¡å’Œå±‚æ¬¡çš„æœ‰æ„ä¹‰æ¨¡å¼ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨å¤šæ¨¡æ€å­¦ä¹ ä¸­éŸ³é¢‘ä¸æ–‡æœ¬å¯¹é½è¯„ä¼°ç¼ºä¹æ ‡å‡†åŒ–æŒ‡æ ‡çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æ— æ³•æœ‰æ•ˆè¡¡é‡è¿™ç§å¯¹é½ï¼Œå¯¼è‡´åœ¨å£è¯­ç†è§£ä»»åŠ¡ä¸­çš„æ€§èƒ½å—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„ALASæŒ‡æ ‡é€šè¿‡æµ‹é‡éŸ³é¢‘å’Œæ–‡æœ¬è¡¨ç¤ºåœ¨å˜æ¢å™¨å±‚ä¹‹é—´çš„ç›¸å…³æ€§æ¥è¯„ä¼°å¯¹é½ç¨‹åº¦ã€‚è¿™ç§è®¾è®¡èƒ½å¤Ÿæ·±å…¥åˆ†æä¸åŒå±‚æ¬¡çš„ç‰¹å¾è¡¨ç¤ºï¼Œä»è€Œæä¾›æ›´å…¨é¢çš„å¯¹é½è¯„ä¼°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šALASçš„æ•´ä½“æ¶æ„åŒ…æ‹¬éŸ³é¢‘å’Œæ–‡æœ¬çš„ç‰¹å¾æå–æ¨¡å—ã€å˜æ¢å™¨å±‚çš„ç›¸å…³æ€§è®¡ç®—æ¨¡å—ä»¥åŠæœ€ç»ˆçš„å¯¹é½è¯„åˆ†è¾“å‡ºã€‚é€šè¿‡å¯¹æ¯”ä¸åŒå±‚æ¬¡çš„è¡¨ç¤ºï¼ŒALASèƒ½å¤Ÿç”Ÿæˆæ›´ä¸ºå‡†ç¡®çš„å¯¹é½è¯„åˆ†ã€‚

**å…³é”®åˆ›æ–°**ï¼šALASçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶è‡ªåŠ¨åŒ–çš„å¯¹é½è¯„åˆ†æœºåˆ¶ï¼Œèƒ½å¤Ÿåœ¨ä¸åŒä»»åŠ¡å’Œå±‚æ¬¡ä¸­æ•æ‰åˆ°éŸ³é¢‘ä¸æ–‡æœ¬ä¹‹é—´çš„æ½œåœ¨å…³ç³»ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„æ‰‹åŠ¨è¯„ä¼°æ–¹æ³•ç›¸æ¯”ï¼Œå…·æœ‰æ›´é«˜çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ALASçš„è®¾è®¡ä¸­ï¼Œç‰¹å¾æå–ä½¿ç”¨äº†æ·±åº¦å˜æ¢å™¨ç½‘ç»œï¼ŒæŸå¤±å‡½æ•°åˆ™åŸºäºç›¸å…³æ€§åº¦é‡è¿›è¡Œä¼˜åŒ–ã€‚é€šè¿‡è°ƒæ•´ç½‘ç»œç»“æ„å’Œå‚æ•°è®¾ç½®ï¼ŒALASèƒ½å¤Ÿåœ¨ä¸åŒä»»åŠ¡ä¸­å®ç°æœ€ä½³æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒALASåœ¨å£è¯­é—®ç­”å’Œæƒ…æ„Ÿè¯†åˆ«ä»»åŠ¡ä¸­æ˜¾è‘—æå‡äº†å¯¹é½è¯„ä¼°çš„å‡†ç¡®æ€§ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•ï¼ŒALASåœ¨å¤šä¸ªä»»åŠ¡ä¸Šå‡è¡¨ç°å‡ºæ›´å¼ºçš„ç›¸å…³æ€§æ•æ‰èƒ½åŠ›ï¼Œæå‡å¹…åº¦è¾¾åˆ°15%ä»¥ä¸Šã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½è¯­éŸ³åŠ©æ‰‹ã€æƒ…æ„Ÿåˆ†æç³»ç»Ÿå’Œäººæœºäº¤äº’ç­‰åœºæ™¯ã€‚é€šè¿‡æé«˜éŸ³é¢‘ä¸æ–‡æœ¬å¯¹é½çš„è¯„ä¼°èƒ½åŠ›ï¼ŒALASèƒ½å¤Ÿä¿ƒè¿›å¤šæ¨¡æ€å­¦ä¹ çš„è¿›ä¸€æ­¥å‘å±•ï¼Œæå‡ç›¸å…³åº”ç”¨çš„æ™ºèƒ½åŒ–æ°´å¹³å’Œç”¨æˆ·ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) are increasingly used in Spoken Language Understanding (SLU), where effective multimodal learning depends on the alignment between audio and text. Despite various fusion methods, no standard metric exists to assess this alignment. This work introduces ALAS (Automatic Latent Alignment Score), a metric that evaluates alignment by measuring correlations between audio and text representations across transformer layers. Experiments on Spoken Question Answering and Emotion Recognition show that ALAS captures meaningful patterns across tasks and layers.

