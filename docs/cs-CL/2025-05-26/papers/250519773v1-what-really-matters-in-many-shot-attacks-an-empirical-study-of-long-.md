---
layout: default
title: What Really Matters in Many-Shot Attacks? An Empirical Study of Long-Context Vulnerabilities in LLMs
---

# What Really Matters in Many-Shot Attacks? An Empirical Study of Long-Context Vulnerabilities in LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.19773" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.19773v1</a>
  <a href="https://arxiv.org/pdf/2505.19773.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.19773v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.19773v1', 'What Really Matters in Many-Shot Attacks? An Empirical Study of Long-Context Vulnerabilities in LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sangyeop Kim, Yohan Lee, Yongwoo Song, Kimin Lee

**åˆ†ç±»**: cs.CL, cs.CR

**å‘å¸ƒæ—¥æœŸ**: 2025-05-26

**å¤‡æ³¨**: Accepted by ACL 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç ”ç©¶é•¿ä¸Šä¸‹æ–‡æ¼æ´ï¼Œæ­ç¤ºLLMå®‰å…¨æœºåˆ¶çš„ä¸è¶³**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é•¿ä¸Šä¸‹æ–‡` `å¤§å‹è¯­è¨€æ¨¡å‹` `å®‰å…¨æœºåˆ¶` `å¤šæ¬¡æ”»å‡»` `æ¨¡å‹æ¼æ´` `å®éªŒç ”ç©¶` `æ–‡æœ¬ç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†é•¿ä¸Šä¸‹æ–‡æ—¶å­˜åœ¨å®‰å…¨æ¼æ´ï¼Œæ”»å‡»è€…å¯ä»¥åˆ©ç”¨è¿™äº›æ¼æ´ç»•è¿‡å®‰å…¨æªæ–½ã€‚
2. è®ºæ–‡é€šè¿‡å¤šæ¬¡æ”»å‡»å®éªŒï¼Œæ­ç¤ºä¸Šä¸‹æ–‡é•¿åº¦å¯¹æ”»å‡»æœ‰æ•ˆæ€§çš„å½±å“ï¼Œæå‡ºäº†æ–°çš„å®‰å…¨æœºåˆ¶éœ€æ±‚ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œå³ä½¿æ˜¯ç®€å•çš„é‡å¤æ–‡æœ¬ä¹Ÿèƒ½æˆåŠŸæ”»å‡»æ¨¡å‹ï¼Œæ˜¾ç¤ºå‡ºæ¨¡å‹åœ¨é•¿ä¸Šä¸‹æ–‡å¤„ç†ä¸Šçš„ä¸è¶³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶é€šè¿‡å¤šæ¬¡æ”»å‡»ï¼ˆMany-Shot Jailbreaking, MSJï¼‰æ¢è®¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­çš„é•¿ä¸Šä¸‹æ–‡æ¼æ´ã€‚å®éªŒä½¿ç”¨äº†é«˜è¾¾128Kæ ‡è®°çš„ä¸Šä¸‹æ–‡é•¿åº¦ã€‚é€šè¿‡å¯¹ä¸åŒæŒ‡ä»¤é£æ ¼ã€æ”»å‡»å¯†åº¦ã€ä¸»é¢˜å’Œæ ¼å¼çš„å¤šç§å¤šæ¬¡æ”»å‡»è®¾ç½®è¿›è¡Œå…¨é¢åˆ†æï¼Œå‘ç°ä¸Šä¸‹æ–‡é•¿åº¦æ˜¯å†³å®šæ”»å‡»æœ‰æ•ˆæ€§çš„ä¸»è¦å› ç´ ã€‚æˆåŠŸçš„æ”»å‡»å¹¶ä¸éœ€è¦ç²¾å¿ƒè®¾è®¡çš„æœ‰å®³å†…å®¹ï¼Œå³ä½¿æ˜¯é‡å¤çš„æ ·æœ¬æˆ–éšæœºçš„è™šå‡æ–‡æœ¬ä¹Ÿèƒ½ç»•è¿‡æ¨¡å‹çš„å®‰å…¨æªæ–½ã€‚è¿™è¡¨æ˜LLMsåœ¨é•¿ä¸Šä¸‹æ–‡å¤„ç†èƒ½åŠ›ä¸Šçš„æ ¹æœ¬å±€é™æ€§ï¼Œä¸”éšç€ä¸Šä¸‹æ–‡çš„å¢åŠ ï¼Œæ¨¡å‹çš„å®‰å…¨è¡Œä¸ºå˜å¾—è¶Šæ¥è¶Šä¸ä¸€è‡´ã€‚è¿™äº›å‘ç°çªæ˜¾äº†LLMsåœ¨ä¸Šä¸‹æ–‡æ‰©å±•èƒ½åŠ›ä¸Šçš„é‡å¤§å®‰å…¨ç¼ºå£ï¼Œå¼ºè°ƒäº†æ–°å®‰å…¨æœºåˆ¶çš„å¿…è¦æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é•¿ä¸Šä¸‹æ–‡å¤„ç†ä¸­çš„å®‰å…¨æ¼æ´é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨é¢å¯¹é•¿ä¸Šä¸‹æ–‡æ—¶ï¼Œæ¨¡å‹çš„å®‰å…¨æ€§å’Œä¸€è‡´æ€§æ˜¾è‘—ä¸‹é™ï¼Œæ”»å‡»è€…å¯ä»¥è½»æ˜“ç»•è¿‡å®‰å…¨æªæ–½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¤šæ¬¡æ”»å‡»å®éªŒæ¥åˆ†æé•¿ä¸Šä¸‹æ–‡å¯¹æ¨¡å‹å®‰å…¨æ€§çš„å½±å“ï¼Œå¼ºè°ƒä¸Šä¸‹æ–‡é•¿åº¦æ˜¯å†³å®šæ”»å‡»æˆåŠŸä¸å¦çš„å…³é”®å› ç´ ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œç ”ç©¶æ­ç¤ºäº†æ¨¡å‹åœ¨é•¿ä¸Šä¸‹æ–‡å¤„ç†ä¸­çš„æ ¹æœ¬å±€é™æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªå®éªŒè®¾ç½®ï¼Œæ¶µç›–ä¸åŒçš„æŒ‡ä»¤é£æ ¼ã€æ”»å‡»å¯†åº¦ã€ä¸»é¢˜å’Œæ ¼å¼ã€‚æ¯ä¸ªå®éªŒéƒ½æ—¨åœ¨è¯„ä¼°ä¸Šä¸‹æ–‡é•¿åº¦å¯¹æ”»å‡»æ•ˆæœçš„å½±å“ï¼Œæœ€ç»ˆå½¢æˆå¯¹æ¨¡å‹å®‰å…¨æ€§çš„ç»¼åˆè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæ­ç¤ºäº†é•¿ä¸Šä¸‹æ–‡å¤„ç†ä¸­çš„å®‰å…¨æ¼æ´ï¼Œå°¤å…¶æ˜¯æˆåŠŸæ”»å‡»ä¸éœ€è¦å¤æ‚çš„æœ‰å®³å†…å®¹ï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„å‡è®¾å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šå®éªŒä¸­ä½¿ç”¨äº†é«˜è¾¾128Kæ ‡è®°çš„ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œè®¾è®¡äº†å¤šç§æ”»å‡»æ ·æœ¬ï¼ŒåŒ…æ‹¬é‡å¤æ–‡æœ¬å’Œéšæœºè™šå‡æ–‡æœ¬ï¼Œä»¥æµ‹è¯•æ¨¡å‹çš„å®‰å…¨æ€§å’Œä¸€è‡´æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨128Kæ ‡è®°çš„ä¸Šä¸‹æ–‡é•¿åº¦æ—¶ï¼Œæ”»å‡»æˆåŠŸç‡æ˜¾è‘—æé«˜ï¼Œç”šè‡³ç®€å•çš„é‡å¤æ–‡æœ¬å’Œéšæœºå†…å®¹ä¹Ÿèƒ½æœ‰æ•ˆç»•è¿‡æ¨¡å‹çš„å®‰å…¨æªæ–½ã€‚è¿™ä¸€å‘ç°å¼ºè°ƒäº†ç°æœ‰æ¨¡å‹åœ¨é•¿ä¸Šä¸‹æ–‡å¤„ç†ä¸­çš„å®‰å…¨ç¼ºé™·ï¼Œä¿ƒä½¿å¯¹æ–°å®‰å…¨æœºåˆ¶çš„éœ€æ±‚ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨åœºæ™¯åŒ…æ‹¬å¤§å‹è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ€§è¯„ä¼°å’Œæ”¹è¿›ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦å¤„ç†é•¿æ–‡æœ¬çš„åº”ç”¨ä¸­ï¼Œå¦‚æ³•å¾‹æ–‡ä¹¦åˆ†æã€æŠ€æœ¯æ–‡æ¡£ç”Ÿæˆç­‰ã€‚ç ”ç©¶ç»“æœå°†æ¨åŠ¨æ–°å®‰å…¨æœºåˆ¶çš„å¼€å‘ï¼Œä»¥å¢å¼ºæ¨¡å‹åœ¨é•¿ä¸Šä¸‹æ–‡å¤„ç†ä¸­çš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We investigate long-context vulnerabilities in Large Language Models (LLMs) through Many-Shot Jailbreaking (MSJ). Our experiments utilize context length of up to 128K tokens. Through comprehensive analysis with various many-shot attack settings with different instruction styles, shot density, topic, and format, we reveal that context length is the primary factor determining attack effectiveness. Critically, we find that successful attacks do not require carefully crafted harmful content. Even repetitive shots or random dummy text can circumvent model safety measures, suggesting fundamental limitations in long-context processing capabilities of LLMs. The safety behavior of well-aligned models becomes increasingly inconsistent with longer contexts. These findings highlight significant safety gaps in context expansion capabilities of LLMs, emphasizing the need for new safety mechanisms.

