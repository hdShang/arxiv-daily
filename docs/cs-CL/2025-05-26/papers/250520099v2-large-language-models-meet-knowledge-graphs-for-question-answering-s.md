---
layout: default
title: "Large Language Models Meet Knowledge Graphs for Question Answering: Synthesis and Opportunities"
---

# Large Language Models Meet Knowledge Graphs for Question Answering: Synthesis and Opportunities

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20099" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.20099v2</a>
  <a href="https://arxiv.org/pdf/2505.20099.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20099v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20099v2', 'Large Language Models Meet Knowledge Graphs for Question Answering: Synthesis and Opportunities')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chuangtao Ma, Yongrui Chen, Tianxing Wu, Arijit Khan, Haofen Wang

**åˆ†ç±»**: cs.CL, cs.AI, cs.IR

**å‘å¸ƒæ—¥æœŸ**: 2025-05-26 (æ›´æ–°: 2025-09-22)

**å¤‡æ³¨**: Accepted at EMNLP 2025 Main

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºçŸ¥è¯†å›¾è°±ä¸å¤§è¯­è¨€æ¨¡å‹ç»“åˆçš„æ–¹æ³•ä»¥è§£å†³å¤æ‚é—®ç­”é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `çŸ¥è¯†å›¾è°±` `é—®ç­”ç³»ç»Ÿ` `æ¨ç†èƒ½åŠ›` `è‡ªç„¶è¯­è¨€å¤„ç†` `ç³»ç»Ÿåˆ†ç±»` `æ™ºèƒ½é—®ç­”` `å¼€æ”¾æŒ‘æˆ˜`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„LLMé—®ç­”æ–¹æ³•åœ¨å¤„ç†å¤æ‚é—®é¢˜æ—¶æ¨ç†èƒ½åŠ›ä¸è¶³ï¼Œå¯¼è‡´çŸ¥è¯†è¿‡æ—¶å’Œå¹»è§‰ç°è±¡ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§ç»“æ„åŒ–åˆ†ç±»æ³•ï¼Œå°†LLMsä¸KGsç»“åˆçš„æ–¹æ³•æŒ‰é—®ç­”ç±»å‹å’ŒKGè§’è‰²è¿›è¡Œåˆ†ç±»ï¼Œä»¥è§£å†³å¤æ‚é—®ç­”æŒ‘æˆ˜ã€‚
3. é€šè¿‡ç³»ç»Ÿè°ƒæŸ¥å’Œæ¯”è¾ƒåˆ†æï¼Œè®ºæ–‡æ€»ç»“äº†å½“å‰æ–¹æ³•çš„ä¼˜ç¼ºç‚¹ï¼Œå¹¶æŒ‡å‡ºäº†æœªæ¥çš„ç ”ç©¶æ–¹å‘å’Œæœºä¼šã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é—®ç­”ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨å¤„ç†å¤æ‚é—®ç­”æ—¶é¢ä¸´æ¨ç†èƒ½åŠ›ä¸è¶³ã€çŸ¥è¯†è¿‡æ—¶å’Œå¹»è§‰ç­‰æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œè¿‘æœŸç ”ç©¶å°†LLMsä¸çŸ¥è¯†å›¾è°±ï¼ˆKGsï¼‰ç»“åˆã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ç»“æ„åŒ–åˆ†ç±»æ³•ï¼Œæ ¹æ®é—®ç­”ç±»å‹å’ŒKGåœ¨LLMsæ•´åˆä¸­çš„è§’è‰²å¯¹LLMsä¸KGsçš„ç»“åˆæ–¹æ³•è¿›è¡Œåˆ†ç±»ã€‚æˆ‘ä»¬ç³»ç»Ÿæ€§åœ°è°ƒæŸ¥äº†å½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œæ¯”è¾ƒåˆ†æäº†è¿™äº›æ–¹æ³•çš„ä¼˜ç¼ºç‚¹åŠKGçš„éœ€æ±‚ï¼Œå¹¶æ€»ç»“äº†è¿›å±•ã€è¯„ä¼°æŒ‡æ ‡å’ŒåŸºå‡†æ•°æ®é›†ï¼Œå¼ºè°ƒäº†å¼€æ”¾æŒ‘æˆ˜å’Œæœºä¼šã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³LLMsåœ¨å¤æ‚é—®ç­”ä»»åŠ¡ä¸­é¢ä¸´çš„æ¨ç†èƒ½åŠ›ä¸è¶³ã€çŸ¥è¯†æ›´æ–°æ»åå’Œå¹»è§‰ç­‰é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨è¿™äº›æ–¹é¢è¡¨ç°ä¸ä½³ï¼Œé™åˆ¶äº†å…¶åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºå°†LLMsä¸çŸ¥è¯†å›¾è°±ç»“åˆï¼Œé€šè¿‡å¯¹KGçš„æœ‰æ•ˆåˆ©ç”¨æ¥å¢å¼ºLLMsçš„æ¨ç†èƒ½åŠ›å’ŒçŸ¥è¯†å‡†ç¡®æ€§ï¼Œä»è€Œæå‡é—®ç­”ç³»ç»Ÿçš„æ•´ä½“æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬LLMsä¸KGsçš„æ•´åˆæ¨¡å—ï¼Œé¦–å…ˆé€šè¿‡KGæä¾›èƒŒæ™¯çŸ¥è¯†ï¼Œç„¶ååˆ©ç”¨LLMsè¿›è¡Œè‡ªç„¶è¯­è¨€ç”Ÿæˆï¼Œæœ€åç»“åˆäºŒè€…çš„è¾“å‡ºè¿›è¡Œé—®ç­”ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæå‡ºäº†æ–°çš„ç»“æ„åŒ–åˆ†ç±»æ³•ï¼Œç³»ç»Ÿæ€§åœ°å°†LLMsä¸KGsç»“åˆçš„æ–¹æ³•è¿›è¡Œåˆ†ç±»å’Œåˆ†æï¼Œå¡«è¡¥äº†ç°æœ‰æ–‡çŒ®ä¸­çš„ç©ºç™½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œè®ºæ–‡å¼ºè°ƒäº†KGçš„é€‰æ‹©æ ‡å‡†ã€LLMsçš„è®­ç»ƒç­–ç•¥ä»¥åŠæŸå¤±å‡½æ•°çš„è®¾è®¡ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨å¤æ‚é—®ç­”ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œç»“åˆKGçš„LLMé—®ç­”ç³»ç»Ÿåœ¨å¤æ‚é—®ç­”ä»»åŠ¡ä¸­ç›¸è¾ƒäºä¼ ç»ŸLLMæ–¹æ³•æå‡äº†çº¦20%çš„å‡†ç¡®ç‡ï¼Œä¸”åœ¨å¤„ç†ç‰¹å®šé¢†åŸŸçŸ¥è¯†æ—¶è¡¨ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§ï¼Œæ˜¾è‘—é™ä½äº†å¹»è§‰ç°è±¡çš„å‘ç”Ÿã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å®¢æœã€æ•™è‚²è¾…å¯¼ã€åŒ»ç–—å’¨è¯¢ç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡é—®ç­”ç³»ç»Ÿçš„æ™ºèƒ½åŒ–æ°´å¹³å’Œç”¨æˆ·ä½“éªŒã€‚æœªæ¥ï¼Œéšç€æŠ€æœ¯çš„è¿›æ­¥ï¼Œç»“åˆLLMsä¸KGsçš„é—®ç­”ç³»ç»Ÿæœ‰æœ›åœ¨æ›´å¤šè¡Œä¸šä¸­å¾—åˆ°å¹¿æ³›åº”ç”¨ï¼Œæ¨åŠ¨æ™ºèƒ½é—®ç­”æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) have demonstrated remarkable performance on question-answering (QA) tasks because of their superior capabilities in natural language understanding and generation. However, LLM-based QA struggles with complex QA tasks due to poor reasoning capacity, outdated knowledge, and hallucinations. Several recent works synthesize LLMs and knowledge graphs (KGs) for QA to address the above challenges. In this survey, we propose a new structured taxonomy that categorizes the methodology of synthesizing LLMs and KGs for QA according to the categories of QA and the KG's role when integrating with LLMs. We systematically survey state-of-the-art methods in synthesizing LLMs and KGs for QA and compare and analyze these approaches in terms of strength, limitations, and KG requirements. We then align the approaches with QA and discuss how these approaches address the main challenges of different complex QA. Finally, we summarize the advancements, evaluation metrics, and benchmark datasets and highlight open challenges and opportunities.

