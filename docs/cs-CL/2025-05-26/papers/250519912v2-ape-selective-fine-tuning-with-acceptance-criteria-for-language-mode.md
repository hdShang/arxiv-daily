---
layout: default
title: APE: Selective Fine-tuning with Acceptance Criteria for Language Model Adaptation
---

# APE: Selective Fine-tuning with Acceptance Criteria for Language Model Adaptation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.19912" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.19912v2</a>
  <a href="https://arxiv.org/pdf/2505.19912.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.19912v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.19912v2', 'APE: Selective Fine-tuning with Acceptance Criteria for Language Model Adaptation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Javier MarÃ­n

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-26 (æ›´æ–°: 2025-06-09)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAPEæ–¹æ³•ä»¥è§£å†³è¯­è¨€æ¨¡å‹é€‚åº”æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯­è¨€æ¨¡å‹` `å¾®è°ƒ` `å‚æ•°é€‰æ‹©` `è‡ªç„¶è¯­è¨€å¤„ç†` `æ¨¡å‹ç¨³å®šæ€§` `æ€§èƒ½æå‡` `è¿›åŒ–ä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¯­è¨€æ¨¡å‹å¾®è°ƒæ–¹æ³•å¾€å¾€å®¹æ˜“å¯¼è‡´æ¨¡å‹çš„ä¸ç¨³å®šæ€§ï¼Œéš¾ä»¥åœ¨æ€§èƒ½å’Œç¨³å®šæ€§ä¹‹é—´å–å¾—å¹³è¡¡ã€‚
2. APEæ–¹æ³•é€šè¿‡é€‰æ‹©æ€§å¾®è°ƒå’Œè¿‡æ»¤é€‰æ‹©è¿‡ç¨‹ï¼Œç³»ç»Ÿæ€§åœ°æ¢ç´¢å‚æ•°æ›´æ–°ï¼Œä»è€Œå®ç°ç¨³å®šçš„æ¨¡å‹é€‚åº”ã€‚
3. åœ¨æ–°é—»æ‘˜è¦ä»»åŠ¡ä¸­ï¼ŒAPEæ–¹æ³•å®ç°äº†33.9%çš„BLEUæå‡å’Œ36.2%çš„å›°æƒ‘åº¦é™ä½ï¼Œå±•ç°äº†å…¶ä¼˜è¶Šçš„æ€§èƒ½å’Œæ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬æå‡ºäº†é‚»è¿‘å¯èƒ½æ¢ç´¢ï¼ˆAPEï¼‰ï¼Œè¿™æ˜¯ä¸€ç§é€‰æ‹©æ€§å¾®è°ƒæ–¹æ³•ï¼Œç”¨äºé€‚åº”å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œç³»ç»Ÿæ€§åœ°æ¢ç´¢å‚æ•°ä¿®æ”¹ï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹çš„ç¨³å®šæ€§ã€‚APEå—åˆ°è¿›åŒ–ä¼˜åŒ–åŸåˆ™çš„å¯å‘ï¼Œé€šè¿‡åœ¨å°æ•°æ®å­é›†ä¸Šè¿›è¡Œå¾®è°ƒï¼Œè¯„ä¼°å¤šä¸ªå€™é€‰å‚æ•°æ›´æ–°ï¼Œå¹¶ä»…æ¥å—è¶…è¿‡æ€§èƒ½é˜ˆå€¼çš„æ›´æ–°ã€‚ä¸æ ‡å‡†å¾®è°ƒæ–¹æ³•ä¸åŒï¼ŒAPEå®æ–½äº†ä¸€ç§è¿‡æ»¤é€‰æ‹©è¿‡ç¨‹ï¼Œé˜²æ­¢ä¸ç¨³å®šçš„å‚æ•°å˜åŒ–ï¼ŒåŒæ—¶å®ç°ç³»ç»Ÿæ€§æ”¹è¿›ã€‚è¯¥æ–¹æ³•åœ¨æ–°é—»æ‘˜è¦ä»»åŠ¡ä¸Šå®ç°äº†33.9%çš„BLEUæå‡å’Œ36.2%çš„å›°æƒ‘åº¦é™ä½ï¼ŒåŒæ—¶ä½¿ç”¨äº†æœ€å°‘çš„è®¡ç®—èµ„æºã€‚è¯¥æ–¹æ³•ä¸ºå—æ§æ¨¡å‹é€‚åº”æä¾›äº†ä¸€ä¸ªå®ç”¨æ¡†æ¶ï¼Œå¹³è¡¡äº†æ€§èƒ½æå‡ä¸è¡¨ç¤ºç¨³å®šæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­å®¹æ˜“å‡ºç°çš„ä¸ç¨³å®šæ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–å•ä¸€æ¢¯åº¦æ–¹å‘ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½æ³¢åŠ¨è¾ƒå¤§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šAPEæ–¹æ³•çš„æ ¸å¿ƒåœ¨äºé€šè¿‡é€‰æ‹©æ€§å¾®è°ƒå’Œè¿‡æ»¤é€‰æ‹©è¿‡ç¨‹ï¼Œç³»ç»Ÿæ€§åœ°æ¢ç´¢å¤šä¸ªå‚æ•°æ›´æ–°ï¼Œç¡®ä¿åªæœ‰é‚£äº›è¶…è¿‡æ€§èƒ½é˜ˆå€¼çš„æ›´æ–°è¢«æ¥å—ï¼Œä»è€Œä¿æŒæ¨¡å‹çš„ç¨³å®šæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAPEçš„æ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªé˜¶æ®µï¼šé¦–å…ˆåœ¨å°æ•°æ®å­é›†ä¸Šè¿›è¡Œå¾®è°ƒï¼Œè¯„ä¼°å€™é€‰å‚æ•°æ›´æ–°ï¼›ç„¶åé€šè¿‡è®¾å®šçš„æ€§èƒ½é˜ˆå€¼è¿‡æ»¤ä¸åˆæ ¼çš„æ›´æ–°ï¼›æœ€åå°†åˆæ ¼çš„æ›´æ–°åº”ç”¨äºæ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šAPEçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶é€‰æ‹©æ€§å¾®è°ƒå’Œè¿‡æ»¤é€‰æ‹©è¿‡ç¨‹ï¼Œè¿™ä¸ä¼ ç»Ÿçš„å•ä¸€æ¢¯åº¦å¾®è°ƒæ–¹æ³•æœ¬è´¨ä¸Šä¸åŒï¼Œèƒ½å¤Ÿæœ‰æ•ˆé˜²æ­¢ä¸ç¨³å®šçš„å‚æ•°å˜åŒ–ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼ŒAPEé‡‡ç”¨äº†å°æ•°æ®å­é›†è¿›è¡Œå¾®è°ƒï¼Œè®¾å®šäº†æ˜ç¡®çš„æ€§èƒ½é˜ˆå€¼ï¼Œä»¥ç¡®ä¿åªæœ‰æœ‰æ•ˆçš„å‚æ•°æ›´æ–°è¢«æ¥å—ã€‚æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„çš„è®¾è®¡ä¹Ÿç»è¿‡ä¼˜åŒ–ï¼Œä»¥æ”¯æŒè¿™ä¸€é€‰æ‹©æ€§å¾®è°ƒè¿‡ç¨‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼ŒAPEæ–¹æ³•åœ¨æ–°é—»æ‘˜è¦ä»»åŠ¡ä¸Šå®ç°äº†33.9%çš„BLEUæå‡å’Œ36.2%çš„å›°æƒ‘åº¦é™ä½ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨æ€§èƒ½ä¸Šçš„æ˜¾è‘—ä¼˜åŠ¿ã€‚æ­¤å¤–ï¼ŒAPEæ–¹æ³•åœ¨è®¡ç®—èµ„æºä½¿ç”¨ä¸Šä¹Ÿè¡¨ç°å‡ºè‰²ï¼Œèƒ½å¤Ÿåœ¨æœ€å°èµ„æºæ¶ˆè€—ä¸‹å®ç°æœ€å¤§æ€§èƒ½æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

APEæ–¹æ³•åœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦é«˜æ•ˆä¸”ç¨³å®šçš„æ¨¡å‹é€‚åº”çš„åœºæ™¯ä¸­ï¼Œå¦‚æ–°é—»æ‘˜è¦ã€å¯¹è¯ç³»ç»Ÿå’Œæ–‡æœ¬ç”Ÿæˆç­‰ã€‚å…¶æä¾›çš„å—æ§é€‚åº”æ¡†æ¶èƒ½å¤Ÿå¸®åŠ©ç ”ç©¶äººå‘˜å’Œå·¥ç¨‹å¸ˆåœ¨èµ„æºæœ‰é™çš„æƒ…å†µä¸‹å®ç°æ›´å¥½çš„æ¨¡å‹æ€§èƒ½ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ›´å¤šé¢†åŸŸçš„ç ”ç©¶ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present Adjacent Possible Exploration (APE), a selective fine-tuning method for adapting large language models that systematically explores parameter modifications while maintaining model stability. Inspired by evolutionary optimization principles, APE evaluates multiple candidate parameter updates through fine-tuning on small data subsets and accepts only those exceeding a performance threshold. Unlike standard fine-tuning that follows single gradient directions, APE implements a filtered selection process that prevents destabilizing parameter changes while enabling systematic improvement. Our method achieves 33.9\% BLEU improvement and 36.2\% perplexity reduction on news summarization tasks while using minimal computational resources. The approach provides a practical framework for controlled model adaptation that balances performance gains with representational stability.

