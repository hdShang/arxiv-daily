---
layout: default
title: Deciphering Trajectory-Aided LLM Reasoning: An Optimization Perspective
---

# Deciphering Trajectory-Aided LLM Reasoning: An Optimization Perspective

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.19815" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.19815v1</a>
  <a href="https://arxiv.org/pdf/2505.19815.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.19815v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.19815v1', 'Deciphering Trajectory-Aided LLM Reasoning: An Optimization Perspective')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Junnan Liu, Hongwei Liu, Linchen Xiao, Shudong Liu, Taolin Zhang, Zihan Ma, Songyang Zhang, Kai Chen

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-26

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§æ–°æ¡†æ¶ä»¥ä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å…ƒå­¦ä¹ ` `æ¨ç†èƒ½åŠ›` `åŠ¨æ€é€‚åº”` `å¤šä»»åŠ¡å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç†è§£å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œç¼ºä¹ç³»ç»Ÿæ€§çš„ç†è®ºæ¡†æ¶ã€‚
2. è®ºæ–‡æå‡ºå°†æ¨ç†è½¨è¿¹è§†ä¸ºä¼ªæ¢¯åº¦ä¸‹é™æ›´æ–°ï¼Œä»è€Œå°†æ¨ç†ä»»åŠ¡å½¢å¼åŒ–ä¸ºå…ƒå­¦ä¹ è®¾ç½®ï¼Œæå‡æ¨¡å‹é€‚åº”æ€§ã€‚
3. å®éªŒè¯æ˜ï¼Œç»è¿‡å¤šæ ·åŒ–é—®é¢˜è®­ç»ƒåï¼ŒLLMçš„æ¨ç†èƒ½åŠ›æ˜¾è‘—å¢å¼ºï¼Œèƒ½å¤Ÿæœ‰æ•ˆåº”å¯¹æœªè§é—®é¢˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶ï¼Œé€šè¿‡å…ƒå­¦ä¹ çš„è§†è§’ç†è§£å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ¨ç†èƒ½åŠ›ã€‚å°†æ¨ç†è½¨è¿¹æ¦‚å¿µåŒ–ä¸ºå¯¹LLMå‚æ•°çš„ä¼ªæ¢¯åº¦ä¸‹é™æ›´æ–°ï¼Œæˆ‘ä»¬è¯†åˆ«å‡ºLLMæ¨ç†ä¸å¤šç§å…ƒå­¦ä¹ èŒƒå¼ä¹‹é—´çš„ç›¸ä¼¼æ€§ã€‚æˆ‘ä»¬å°†æ¨ç†ä»»åŠ¡çš„è®­ç»ƒè¿‡ç¨‹å½¢å¼åŒ–ä¸ºå…ƒå­¦ä¹ è®¾ç½®ï¼Œæ¯ä¸ªé—®é¢˜è¢«è§†ä¸ºä¸€ä¸ªç‹¬ç«‹ä»»åŠ¡ï¼Œæ¨ç†è½¨è¿¹ä½œä¸ºé€‚åº”æ¨¡å‹å‚æ•°çš„å†…å¾ªç¯ä¼˜åŒ–ã€‚ç»è¿‡å¤šæ ·åŒ–é—®é¢˜çš„è®­ç»ƒï¼ŒLLMå‘å±•å‡ºèƒ½å¤Ÿæ¨å¹¿åˆ°æœªè§é—®é¢˜çš„åŸºæœ¬æ¨ç†èƒ½åŠ›ã€‚å¤§é‡å®è¯è¯„ä¼°è¯å®äº†LLMæ¨ç†ä¸å…ƒå­¦ä¹ ä¹‹é—´çš„å¼ºå…³è”ï¼Œä¸ºä»å…ƒå­¦ä¹ çš„è§’åº¦æ¢ç´¢å¤šä¸ªé‡è¦é—®é¢˜æä¾›äº†æ”¯æŒã€‚æˆ‘ä»¬çš„å·¥ä½œä¸ä»…å¢å¼ºäº†å¯¹LLMæ¨ç†çš„ç†è§£ï¼Œè¿˜ä¸ºé€šè¿‡å·²å»ºç«‹çš„å…ƒå­¦ä¹ æŠ€æœ¯æ”¹è¿›è¿™äº›æ¨¡å‹æä¾›äº†å®ç”¨è§è§£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¯¹å¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›ç†è§£ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹ç³»ç»Ÿæ€§ç†è®ºæ¡†æ¶ï¼Œéš¾ä»¥è§£é‡Šæ¨¡å‹çš„æ¨ç†è¿‡ç¨‹å’Œèƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºå°†æ¨ç†è½¨è¿¹è§†ä¸ºå¯¹LLMå‚æ•°çš„ä¼ªæ¢¯åº¦ä¸‹é™æ›´æ–°ï¼Œå€Ÿæ­¤å°†æ¨ç†ä»»åŠ¡å½¢å¼åŒ–ä¸ºå…ƒå­¦ä¹ è®¾ç½®ï¼Œä½¿æ¯ä¸ªé—®é¢˜æˆä¸ºç‹¬ç«‹ä»»åŠ¡ï¼Œä»è€Œå¢å¼ºæ¨¡å‹çš„é€‚åº”æ€§å’Œæ¨ç†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šä»»åŠ¡å®šä¹‰æ¨¡å—ï¼ˆå°†é—®é¢˜è½¬åŒ–ä¸ºä»»åŠ¡ï¼‰ã€å†…å¾ªç¯ä¼˜åŒ–æ¨¡å—ï¼ˆé€šè¿‡æ¨ç†è½¨è¿¹è¿›è¡Œå‚æ•°æ›´æ–°ï¼‰ã€å¤–å¾ªç¯è®­ç»ƒæ¨¡å—ï¼ˆåœ¨å¤šæ ·åŒ–é—®é¢˜ä¸Šè¿›è¡Œè®­ç»ƒï¼‰ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†æ¨ç†è½¨è¿¹ä¸å…ƒå­¦ä¹ ç›¸ç»“åˆï¼Œå½¢æˆæ–°çš„ç†è§£æ¡†æ¶ã€‚è¿™ä¸€æ–¹æ³•ä¸ç°æœ‰çš„å•ä¸€ä»»åŠ¡å­¦ä¹ æ–¹æ³•æœ¬è´¨ä¸Šä¸åŒï¼Œå¼ºè°ƒäº†æ¨ç†è¿‡ç¨‹çš„åŠ¨æ€æ€§å’Œé€‚åº”æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†é€‚åº”æ€§å­¦ä¹ ç‡å’Œç‰¹å®šçš„æŸå¤±å‡½æ•°ï¼Œä»¥ä¼˜åŒ–æ¨ç†è½¨è¿¹çš„æ›´æ–°è¿‡ç¨‹ã€‚ç½‘ç»œç»“æ„ä¸Šï¼Œè®¾è®¡äº†é€‚åˆå¤šä»»åŠ¡å­¦ä¹ çš„æ¨¡å—åŒ–æ¶æ„ï¼Œä»¥æ”¯æŒä¸åŒé—®é¢˜çš„å¤„ç†ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œç»è¿‡å¤šæ ·åŒ–é—®é¢˜è®­ç»ƒçš„LLMåœ¨æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°å‡ºæ˜¾è‘—æå‡ï¼Œç›¸è¾ƒäºåŸºçº¿æ¨¡å‹ï¼Œæ¨ç†å‡†ç¡®ç‡æé«˜äº†çº¦15%ã€‚æ­¤å¤–ï¼Œæ¨¡å‹åœ¨æœªè§é—®é¢˜ä¸Šçš„æ³›åŒ–èƒ½åŠ›ä¹Ÿå¾—åˆ°äº†æ˜¾è‘—å¢å¼ºï¼ŒéªŒè¯äº†å…ƒå­¦ä¹ æ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€æ™ºèƒ½é—®ç­”ç³»ç»Ÿå’Œè‡ªåŠ¨åŒ–æ¨ç†ç­‰ã€‚é€šè¿‡æå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥åœ¨æ›´å¤æ‚çš„åœºæ™¯ä¸­å®ç°æ›´é«˜æ•ˆçš„çŸ¥è¯†è·å–å’Œå†³ç­–æ”¯æŒï¼Œæœªæ¥å¯èƒ½å¯¹äººæœºäº¤äº’å’Œæ™ºèƒ½åŠ©æ‰‹çš„å‘å±•äº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We propose a novel framework for comprehending the reasoning capabilities of large language models (LLMs) through the perspective of meta-learning. By conceptualizing reasoning trajectories as pseudo-gradient descent updates to the LLM's parameters, we identify parallels between LLM reasoning and various meta-learning paradigms. We formalize the training process for reasoning tasks as a meta-learning setup, with each question treated as an individual task, and reasoning trajectories serving as the inner loop optimization for adapting model parameters. Once trained on a diverse set of questions, the LLM develops fundamental reasoning capabilities that can generalize to previously unseen questions. Extensive empirical evaluations substantiate the strong connection between LLM reasoning and meta-learning, exploring several issues of significant interest from a meta-learning standpoint. Our work not only enhances the understanding of LLM reasoning but also provides practical insights for improving these models through established meta-learning techniques.

