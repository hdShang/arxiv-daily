---
layout: default
title: SEMMA: A Semantic Aware Knowledge Graph Foundation Model
---

# SEMMA: A Semantic Aware Knowledge Graph Foundation Model

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20422" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.20422v2</a>
  <a href="https://arxiv.org/pdf/2505.20422.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20422v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20422v2', 'SEMMA: A Semantic Aware Knowledge Graph Foundation Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Arvindh Arun, Sumit Kumar, Mojtaba Nayyeri, Bo Xiong, Ponnurangam Kumaraguru, Antonio Vergari, Steffen Staab

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-26 (æ›´æ–°: 2025-09-19)

**å¤‡æ³¨**: EMNLP 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSEMMAä»¥è§£å†³çŸ¥è¯†å›¾è°±æ¨ç†ä¸­çš„è¯­ä¹‰ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `çŸ¥è¯†å›¾è°±` `åŸºç¡€æ¨¡å‹` `è¯­ä¹‰æ¨ç†` `å¤§å‹è¯­è¨€æ¨¡å‹` `é“¾æ¥é¢„æµ‹` `æ–‡æœ¬åµŒå…¥` `ç»“æ„èåˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çŸ¥è¯†å›¾è°±åŸºç¡€æ¨¡å‹ä¸»è¦ä¾èµ–å›¾ç»“æ„ï¼Œå¿½è§†äº†æ–‡æœ¬å±æ€§ä¸­çš„è¯­ä¹‰ä¿¡æ¯ï¼Œå¯¼è‡´æ¨ç†èƒ½åŠ›ä¸è¶³ã€‚
2. SEMMAé€šè¿‡å¼•å…¥å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæ•´åˆæ–‡æœ¬è¯­ä¹‰ä¸å›¾ç»“æ„ï¼Œæå‡äº†çŸ¥è¯†å›¾è°±çš„æ¨ç†èƒ½åŠ›ã€‚
3. åœ¨54ä¸ªçŸ¥è¯†å›¾è°±çš„å®éªŒä¸­ï¼ŒSEMMAåœ¨å®Œå…¨å½’çº³é“¾æ¥é¢„æµ‹ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶åœ¨æœªè§å…³ç³»è¯æ±‡çš„æƒ…å†µä¸‹æ•ˆæœæå‡æ˜¾è‘—ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

çŸ¥è¯†å›¾è°±åŸºç¡€æ¨¡å‹ï¼ˆKGFMsï¼‰åœ¨å®ç°å¯¹æœªè§å›¾è°±çš„é›¶-shotæ¨ç†æ–¹é¢å±•ç°äº†æ½œåŠ›ï¼Œä½†å¤§å¤šæ•°ç°æœ‰KGFMsä»…ä¾èµ–å›¾ç»“æ„ï¼Œå¿½è§†äº†æ–‡æœ¬å±æ€§ä¸­è•´å«çš„ä¸°å¯Œè¯­ä¹‰ä¿¡å·ã€‚æœ¬æ–‡æå‡ºäº†SEMMAï¼Œä¸€ä¸ªåŒæ¨¡å—KGFMï¼Œç³»ç»Ÿåœ°æ•´åˆäº†å¯è½¬ç§»çš„æ–‡æœ¬è¯­ä¹‰ä¸ç»“æ„ã€‚SEMMAåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸°å¯Œå…³ç³»æ ‡è¯†ç¬¦ï¼Œç”Ÿæˆè¯­ä¹‰åµŒå…¥ï¼Œè¿›è€Œå½¢æˆæ–‡æœ¬å…³ç³»å›¾ï¼Œå¹¶ä¸ç»“æ„ç»„ä»¶èåˆã€‚åœ¨54ä¸ªå¤šæ ·åŒ–çš„çŸ¥è¯†å›¾è°±ä¸Šï¼ŒSEMMAåœ¨å®Œå…¨å½’çº³é“¾æ¥é¢„æµ‹ä¸­è¶…è¶Šäº†çº¯ç»“æ„åŸºçº¿ULTRAã€‚å°¤å…¶åœ¨æ›´å…·æŒ‘æˆ˜æ€§çš„æ³›åŒ–è®¾ç½®ä¸­ï¼Œæµ‹è¯•æ—¶å…³ç³»è¯æ±‡å®Œå…¨æœªè§çš„æƒ…å†µä¸‹ï¼Œç»“æ„æ–¹æ³•å´©æºƒï¼Œè€ŒSEMMAçš„æ•ˆæœæå‡äº†2å€ã€‚æˆ‘ä»¬çš„ç ”ç©¶è¡¨æ˜ï¼Œåœ¨ä»…ä¾èµ–ç»“æ„çš„æƒ…å†µä¸‹ï¼Œæ–‡æœ¬è¯­ä¹‰å¯¹æ³›åŒ–è‡³å…³é‡è¦ï¼Œå¼ºè°ƒäº†ç»Ÿä¸€ç»“æ„ä¸è¯­è¨€ä¿¡å·çš„åŸºç¡€æ¨¡å‹åœ¨çŸ¥è¯†æ¨ç†ä¸­çš„å¿…è¦æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰çŸ¥è¯†å›¾è°±åŸºç¡€æ¨¡å‹åœ¨æ¨ç†æ—¶å¯¹æ–‡æœ¬è¯­ä¹‰ä¿¡å·çš„å¿½è§†é—®é¢˜ï¼Œå¯¼è‡´åœ¨æœªè§å›¾è°±ä¸Šçš„æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSEMMAé€šè¿‡å¼•å…¥å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œç³»ç»Ÿåœ°æ•´åˆå¯è½¬ç§»çš„æ–‡æœ¬è¯­ä¹‰ä¸å›¾ç»“æ„ï¼Œç”Ÿæˆè¯­ä¹‰åµŒå…¥å¹¶å½¢æˆæ–‡æœ¬å…³ç³»å›¾ï¼Œä»è€Œå¢å¼ºæ¨ç†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSEMMAçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šæ–‡æœ¬è¯­ä¹‰æ¨¡å—å’Œç»“æ„æ¨¡å—ã€‚æ–‡æœ¬è¯­ä¹‰æ¨¡å—åˆ©ç”¨LLMsç”Ÿæˆå…³ç³»çš„è¯­ä¹‰åµŒå…¥ï¼Œè€Œç»“æ„æ¨¡å—åˆ™å¤„ç†å›¾çš„ç»“æ„ä¿¡æ¯ï¼Œæœ€ç»ˆå°†ä¸¤è€…èåˆä»¥è¿›è¡Œæ¨ç†ã€‚

**å…³é”®åˆ›æ–°**ï¼šSEMMAçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå°†æ–‡æœ¬è¯­ä¹‰ä¸å›¾ç»“æ„æœ‰æ•ˆç»“åˆï¼Œå…‹æœäº†ä¼ ç»Ÿæ–¹æ³•ä»…ä¾èµ–ç»“æ„çš„å±€é™æ€§ï¼Œæ˜¾è‘—æå‡äº†åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒSEMMAé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–è¯­ä¹‰åµŒå…¥ä¸ç»“æ„ä¿¡æ¯çš„èåˆï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†è°ƒæ•´ï¼Œä»¥ç¡®ä¿ä¸¤ç§ä¿¡æ¯çš„æœ‰æ•ˆæ•´åˆã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œæ¶æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼ŒSEMMAåœ¨54ä¸ªçŸ¥è¯†å›¾è°±ä¸Šè¡¨ç°å‡ºè‰²ï¼Œå°¤å…¶åœ¨å®Œå…¨å½’çº³é“¾æ¥é¢„æµ‹ä»»åŠ¡ä¸­ï¼Œç›¸è¾ƒäºçº¯ç»“æ„åŸºçº¿ULTRAï¼Œæ€§èƒ½æå‡è¾¾2å€ã€‚è¿™ä¸€ç»“æœè¡¨æ˜ï¼Œæ–‡æœ¬è¯­ä¹‰åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„é‡è¦æ€§ï¼ŒéªŒè¯äº†SEMMAçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SEMMAçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ï¼ŒåŒ…æ‹¬æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€æ¨èç³»ç»Ÿä»¥åŠçŸ¥è¯†å›¾è°±æ„å»ºç­‰ã€‚é€šè¿‡æå‡çŸ¥è¯†æ¨ç†çš„å‡†ç¡®æ€§å’Œæ³›åŒ–èƒ½åŠ›ï¼ŒSEMMAèƒ½å¤Ÿä¸ºå®é™…åº”ç”¨æä¾›æ›´ä¸ºå¯é çš„æ”¯æŒï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Knowledge Graph Foundation Models (KGFMs) have shown promise in enabling zero-shot reasoning over unseen graphs by learning transferable patterns. However, most existing KGFMs rely solely on graph structure, overlooking the rich semantic signals encoded in textual attributes. We introduce SEMMA, a dual-module KGFM that systematically integrates transferable textual semantics alongside structure. SEMMA leverages Large Language Models (LLMs) to enrich relation identifiers, generating semantic embeddings that subsequently form a textual relation graph, which is fused with the structural component. Across 54 diverse KGs, SEMMA outperforms purely structural baselines like ULTRA in fully inductive link prediction. Crucially, we show that in more challenging generalization settings, where the test-time relation vocabulary is entirely unseen, structural methods collapse while SEMMA is 2x more effective. Our findings demonstrate that textual semantics are critical for generalization in settings where structure alone fails, highlighting the need for foundation models that unify structural and linguistic signals in knowledge reasoning.

