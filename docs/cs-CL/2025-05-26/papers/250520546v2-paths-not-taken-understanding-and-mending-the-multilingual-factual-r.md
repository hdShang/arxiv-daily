---
layout: default
title: Paths Not Taken: Understanding and Mending the Multilingual Factual Recall Pipeline
---

# Paths Not Taken: Understanding and Mending the Multilingual Factual Recall Pipeline

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20546" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.20546v2</a>
  <a href="https://arxiv.org/pdf/2505.20546.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20546v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20546v2', 'Paths Not Taken: Understanding and Mending the Multilingual Factual Recall Pipeline')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Meng Lu, Ruochen Zhang, Carsten Eickhoff, Ellie Pavlick

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-26 (æ›´æ–°: 2025-05-28)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå‘é‡å¹²é¢„ä»¥è§£å†³å¤šè¯­è¨€äº‹å®å›å¿†ä¸ä¸€è‡´é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šè¯­è¨€æ¨¡å‹` `äº‹å®å›å¿†` `å‘é‡å¹²é¢„` `æœºåˆ¶åˆ†æ` `è¯­è¨€ä¸€è‡´æ€§` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤šè¯­è¨€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨äº‹å®å›å¿†ä»»åŠ¡ä¸­è¡¨ç°ä¸ä¸€è‡´ï¼Œå°¤å…¶åœ¨éè‹±è¯­è¯­è¨€ä¸­æ˜¾è‘—è¾ƒå·®ï¼ŒåŸå› å°šä¸æ˜ç¡®ã€‚
2. è®ºæ–‡æå‡ºä¸¤ç§å‘é‡å¹²é¢„æ–¹æ³•ï¼Œæ—¨åœ¨æ”¹å–„æ¨¡å‹åœ¨å¤šè¯­è¨€æŸ¥è¯¢ä¸­çš„äº‹å®å›å¿†èƒ½åŠ›ï¼Œå¢å¼ºå…¶å†…éƒ¨å¤„ç†è·¯å¾„ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå¹²é¢„æªæ–½ä½¿æœ€ä½è¡¨ç°è¯­è¨€çš„å›å¿†å‡†ç¡®ç‡æå‡è¶…è¿‡35%ï¼Œæœ‰æ•ˆæé«˜äº†å¤šè¯­è¨€æ¨¡å‹çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šè¯­è¨€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä¸åŒè¯­è¨€é—´çš„äº‹å®ä¸€è‡´æ€§è¡¨ç°ä¸ä½³ï¼Œå°¤å…¶åœ¨è‹±è¯­ä¸­çš„äº‹å®å›å¿†ä»»åŠ¡ä¸Šè¡¨ç°æ›´ä¸ºçªå‡ºã€‚æœ¬æ–‡é€šè¿‡æœºåˆ¶åˆ†ææŠ€æœ¯æ­ç¤ºäº†LLMsçš„å†…éƒ¨å¤„ç†æµç¨‹ï¼Œå‘ç°ä¸»è¦é”™è¯¯æºäºå¯¹è‹±è¯­ä¸­å¿ƒæœºåˆ¶çš„ä¸è¶³åˆ©ç”¨åŠç¿»è¯‘è¿‡ç¨‹ä¸­çš„é”™è¯¯ã€‚ä¸ºæ­¤ï¼Œæå‡ºäº†ä¸¤ç§ç‹¬ç«‹äºè¯­è¨€å’Œæ•°æ®é›†çš„å‘é‡å¹²é¢„æ–¹æ³•ï¼Œæ—¨åœ¨å¼•å¯¼æ¨¡å‹æœå‘æ›´é«˜çš„äº‹å®ä¸€è‡´æ€§è·¯å¾„ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™äº›å¹²é¢„æªæ–½ä½¿æœ€ä½è¡¨ç°è¯­è¨€çš„å›å¿†å‡†ç¡®ç‡æé«˜äº†è¶…è¿‡35%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è§£å†³å¤šè¯­è¨€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨äº‹å®å›å¿†ä»»åŠ¡ä¸­å­˜åœ¨çš„è¯­è¨€é—´ä¸€è‡´æ€§å·®çš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯è‹±è¯­ä¸å…¶ä»–è¯­è¨€ä¹‹é—´çš„è¡¨ç°å·®å¼‚ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†åˆ©ç”¨è‹±è¯­ä¸­å¿ƒçš„äº‹å®å›å¿†æœºåˆ¶ï¼Œå¯¼è‡´ç¿»è¯‘åçš„ç­”æ¡ˆä¸å‡†ç¡®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥ä¸¤ç§å‘é‡å¹²é¢„æ–¹æ³•ï¼Œç‹¬ç«‹äºè¯­è¨€å’Œæ•°æ®é›†ï¼Œæ—¨åœ¨å¼•å¯¼æ¨¡å‹æ›´æœ‰æ•ˆåœ°åˆ©ç”¨å…¶å†…éƒ¨æœºåˆ¶ï¼Œä»è€Œæé«˜å¤šè¯­è¨€çš„äº‹å®ä¸€è‡´æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åŒ…æ‹¬ï¼šé¦–å…ˆï¼Œæ¨¡å‹æ¥æ”¶å¤šè¯­è¨€æŸ¥è¯¢å¹¶ä½¿ç”¨è‹±è¯­ä¸­å¿ƒæœºåˆ¶è¿›è¡Œå¤„ç†ï¼›å…¶æ¬¡ï¼Œç”Ÿæˆè‹±è¯­ç­”æ¡ˆå¹¶è¿›è¡Œç¿»è¯‘ï¼›æœ€åï¼Œé€šè¿‡å‘é‡å¹²é¢„è°ƒæ•´æ¨¡å‹çš„å†…éƒ¨è·¯å¾„ä»¥æé«˜æœ€ç»ˆç­”æ¡ˆçš„å‡†ç¡®æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„ä¸»è¦åˆ›æ–°åœ¨äºæå‡ºäº†ä¸¤ç§å‘é‡å¹²é¢„æ–¹æ³•ï¼Œèƒ½å¤Ÿæœ‰æ•ˆé‡å®šå‘æ¨¡å‹çš„å†…éƒ¨å¤„ç†è·¯å¾„ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—æé«˜äº†å¤šè¯­è¨€çš„äº‹å®å›å¿†èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œå¹²é¢„æ–¹æ³•çš„å‚æ•°è®¾ç½®ç»è¿‡ç²¾å¿ƒè°ƒæ•´ï¼Œä»¥ç¡®ä¿å…¶å¯¹ä¸åŒè¯­è¨€å’Œæ•°æ®é›†çš„æ™®é€‚æ€§ï¼ŒæŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ä¹Ÿè¿›è¡Œäº†ä¼˜åŒ–ï¼Œä»¥æ”¯æŒæ›´é«˜æ•ˆçš„äº‹å®å›å¿†æœºåˆ¶ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„å‘é‡å¹²é¢„æ–¹æ³•ä½¿æœ€ä½è¡¨ç°è¯­è¨€çš„å›å¿†å‡†ç¡®ç‡æå‡è¶…è¿‡35%ã€‚è¿™ä¸€æ˜¾è‘—æå‡ä¸ä»…éªŒè¯äº†å¹²é¢„æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œä¹Ÿå±•ç¤ºäº†æœºåˆ¶åˆ†æåœ¨å¤šè¯­è¨€æ¨¡å‹ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤šè¯­è¨€ä¿¡æ¯æ£€ç´¢ã€è·¨è¯­è¨€é—®ç­”ç³»ç»Ÿå’Œå¤šè¯­è¨€å†…å®¹ç”Ÿæˆç­‰ã€‚é€šè¿‡æé«˜å¤šè¯­è¨€æ¨¡å‹çš„äº‹å®ä¸€è‡´æ€§ï¼Œèƒ½å¤Ÿä¸ºç”¨æˆ·æä¾›æ›´å‡†ç¡®çš„ä¿¡æ¯ï¼Œæå‡ç”¨æˆ·ä½“éªŒï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multilingual large language models (LLMs) often exhibit factual inconsistencies across languages, with significantly better performance in factual recall tasks in English than in other languages. The causes of these failures, however, remain poorly understood. Using mechanistic analysis techniques, we uncover the underlying pipeline that LLMs employ, which involves using the English-centric factual recall mechanism to process multilingual queries and then translating English answers back into the target language. We identify two primary sources of error: insufficient engagement of the reliable English-centric mechanism for factual recall, and incorrect translation from English back into the target language for the final answer. To address these vulnerabilities, we introduce two vector interventions, both independent of languages and datasets, to redirect the model toward better internal paths for higher factual consistency. Our interventions combined increase the recall accuracy by over 35 percent for the lowest-performing language. Our findings demonstrate how mechanistic insights can be used to unlock latent multilingual capabilities in LLMs.

