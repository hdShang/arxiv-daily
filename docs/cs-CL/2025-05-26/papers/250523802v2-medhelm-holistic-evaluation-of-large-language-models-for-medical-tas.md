---
layout: default
title: MedHELM: Holistic Evaluation of Large Language Models for Medical Tasks
---

# MedHELM: Holistic Evaluation of Large Language Models for Medical Tasks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.23802" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.23802v2</a>
  <a href="https://arxiv.org/pdf/2505.23802.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.23802v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.23802v2', 'MedHELM: Holistic Evaluation of Large Language Models for Medical Tasks')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Suhana Bedi, Hejie Cui, Miguel Fuentes, Alyssa Unell, Michael Wornow, Juan M. Banda, Nikesh Kotecha, Timothy Keyes, Yifan Mai, Mert Oez, Hao Qiu, Shrey Jain, Leonardo Schettini, Mehr Kashyap, Jason Alan Fries, Akshay Swaminathan, Philip Chung, Fateme Nateghi, Asad Aali, Ashwin Nayak, Shivam Vedak, Sneha S. Jain, Birju Patel, Oluseyi Fayanju, Shreya Shah, Ethan Goh, Dong-han Yao, Brian Soetikno, Eduardo Reis, Sergios Gatidis, Vasu Divi, Robson Capasso, Rachna Saralkar, Chia-Chun Chiang, Jenelle Jindal, Tho Pham, Faraz Ghoddusi, Steven Lin, Albert S. Chiou, Christy Hong, Mohana Roy, Michael F. Gensheimer, Hinesh Patel, Kevin Schulman, Dev Dash, Danton Char, Lance Downing, Francois Grolleau, Kameron Black, Bethel Mieso, Aydin Zahedivash, Wen-wai Yim, Harshita Sharma, Tony Lee, Hannah Kirsch, Jennifer Lee, Nerissa Ambers, Carlene Lugtu, Aditya Sharma, Bilal Mawji, Alex Alekseyev, Vicky Zhou, Vikas Kakkar, Jarrod Helzer, Anurang Revri, Yair Bannett, Roxana Daneshjou, Jonathan Chen, Emily Alsentzer, Keith Morse, Nirmal Ravi, Nima Aghaeepour, Vanessa Kennedy, Akshay Chaudhari, Thomas Wang, Sanmi Koyejo, Matthew P. Lungren, Eric Horvitz, Percy Liang, Mike Pfeffer, Nigam H. Shah

**ÂàÜÁ±ª**: cs.CL, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-26 (Êõ¥Êñ∞: 2025-06-02)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫MedHELMÊ°ÜÊû∂‰ª•ÂÖ®Èù¢ËØÑ‰º∞ÂåªÁñó‰ªªÂä°‰∏≠ÁöÑÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãË°®Áé∞**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `ÂåªÁñó‰ªªÂä°` `ËØÑ‰º∞Ê°ÜÊû∂` `‰∏¥Â∫äÂÆûË∑µ` `ÊÄßËÉΩÊØîËæÉ` `Âü∫ÂáÜÂ•ó‰ª∂` `‰∏¥Â∫äÂÜ≥Á≠ñÊîØÊåÅ` `‰∫∫Â∑•Êô∫ËÉΩ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑLLMËØÑ‰º∞ÊñπÊ≥ïÊú™ËÉΩÂÖÖÂàÜÂèçÊò†ÁúüÂÆû‰∏¥Â∫äÂÆûË∑µÁöÑÂ§çÊùÇÊÄßÔºåÂØºËá¥ËØÑ‰º∞ÁªìÊûúÁöÑÂ±ÄÈôêÊÄß„ÄÇ
2. MedHELMÊ°ÜÊû∂ÈÄöËøáÂª∫Á´ã‰∏¥Â∫äÂåªÁîüÈ™åËØÅÁöÑÂàÜÁ±ªÊ≥ïÂíåÁªºÂêàÂü∫ÂáÜÂ•ó‰ª∂ÔºåÊèê‰æõ‰∫ÜÊõ¥ÂÖ®Èù¢ÁöÑLLMËØÑ‰º∞ÊñπÊ≥ï„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåÂÖàËøõÁöÑÊé®ÁêÜÊ®°ÂûãÂú®Â§ö‰∏™‰ªªÂä°‰∏≠Ë°®Áé∞‰ºòÂºÇÔºå‰∏îLLMËØÑÂÆ°Âõ¢ÁöÑËØÑ‰º∞ÊñπÊ≥ï‰∏é‰∏¥Â∫äÂåªÁîüÁöÑËØÑÂàÜ‰∏ÄËá¥ÊÄßËæÉÈ´ò„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â∞ΩÁÆ°Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂú®ÂåªÁñóÊâßÁÖßËÄÉËØï‰∏≠ÂèñÂæó‰∫ÜËøë‰πéÂÆåÁæéÁöÑÂàÜÊï∞Ôºå‰ΩÜËøô‰∫õËØÑ‰º∞Âπ∂Êú™ÂÖÖÂàÜÂèçÊò†ÁúüÂÆû‰∏¥Â∫äÂÆûË∑µÁöÑÂ§çÊùÇÊÄßÂíåÂ§öÊ†∑ÊÄß„ÄÇÊú¨Êñá‰ªãÁªç‰∫ÜMedHELMÔºå‰∏Ä‰∏™ÂèØÊâ©Â±ïÁöÑËØÑ‰º∞Ê°ÜÊû∂ÔºåÊó®Âú®ËØÑ‰º∞LLMÂú®ÂåªÁñó‰ªªÂä°‰∏≠ÁöÑË°®Áé∞Ôºå‰∏ªË¶ÅË¥°ÁåÆÂåÖÊã¨ÔºöÈ¶ñÂÖàÔºåÂºÄÂèë‰∫Ü‰∏Ä‰∏™ÁªèËøá‰∏¥Â∫äÂåªÁîüÈ™åËØÅÁöÑÂàÜÁ±ªÊ≥ïÔºåÊ∂µÁõñ5‰∏™Á±ªÂà´„ÄÅ22‰∏™Â≠êÁ±ªÂà´Âíå121‰∏™‰ªªÂä°ÔºõÂÖ∂Ê¨°ÔºåÊûÑÂª∫‰∫Ü‰∏Ä‰∏™ÂåÖÂê´35‰∏™Âü∫ÂáÜÁöÑÁªºÂêàÂü∫ÂáÜÂ•ó‰ª∂ÔºåÂÖ®Èù¢Ë¶ÜÁõñÂàÜÁ±ªÊ≥ï‰∏≠ÁöÑÊâÄÊúâÁ±ªÂà´ÂíåÂ≠êÁ±ªÂà´ÔºõÊúÄÂêéÔºåÈááÁî®ÊîπËøõÁöÑËØÑ‰º∞ÊñπÊ≥ïÔºà‰ΩøÁî®LLMËØÑÂÆ°Âõ¢ÔºâÂØπ9‰∏™ÂâçÊ≤øLLMËøõË°å‰∫ÜÁ≥ªÁªüÊØîËæÉÔºåÂπ∂ËøõË°å‰∫ÜÊàêÊú¨-ÊÄßËÉΩÂàÜÊûê„ÄÇÁ†îÁ©∂ÁªìÊûúÊòæÁ§∫ÔºåÂÖàËøõÊé®ÁêÜÊ®°ÂûãË°®Áé∞‰ºòÂºÇÔºå‰∏îClaude 3.5 SonnetÂú®ËæÉ‰ΩéËÆ°ÁÆóÊàêÊú¨‰∏ãÂèñÂæó‰∫ÜÂèØÊØîÁöÑÁªìÊûú„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂú®ÂåªÁñó‰ªªÂä°ËØÑ‰º∞‰∏≠ÁöÑ‰∏çË∂≥ÔºåÂ∞§ÂÖ∂ÊòØÁº∫‰πèÂØπÁúüÂÆû‰∏¥Â∫äÂú∫ÊôØÁöÑÂÖ®Èù¢ÂèçÊò†„ÄÇÁé∞ÊúâÊñπÊ≥ïÂæÄÂæÄÂè™ÂÖ≥Ê≥®Ê®°ÂûãÂú®Ê†áÂáÜÂåñËÄÉËØï‰∏≠ÁöÑË°®Áé∞ÔºåÊú™ËÉΩËÄÉËôëÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÂ§çÊùÇÊÄßÂíåÂ§öÊ†∑ÊÄß„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöMedHELMÊ°ÜÊû∂ÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÂª∫Á´ã‰∏Ä‰∏™ÁªèËøá‰∏¥Â∫äÂåªÁîüÈ™åËØÅÁöÑÂàÜÁ±ªÊ≥ïÂíåÂÖ®Èù¢ÁöÑÂü∫ÂáÜÂ•ó‰ª∂ÔºåÊù•Á≥ªÁªüÊÄßÂú∞ËØÑ‰º∞LLMÂú®ÂåªÁñó‰ªªÂä°‰∏≠ÁöÑË°®Áé∞„ÄÇËøôÁßçËÆæËÆ°Êó®Âú®Á°Æ‰øùËØÑ‰º∞ÁöÑÂÖ®Èù¢ÊÄßÂíåÈíàÂØπÊÄßÔºå‰ªéËÄåÊõ¥Â•ΩÂú∞ÂèçÊò†Ê®°ÂûãÂú®ÂÆûÈôÖ‰∏¥Â∫äÁéØÂ¢É‰∏≠ÁöÑÂ∫îÁî®ËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöMedHELMÊ°ÜÊû∂ÂåÖÊã¨‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1ÔºâÂàÜÁ±ªÊ≥ïÂºÄÂèëÔºåÊ∂µÁõñ5‰∏™Á±ªÂà´Âíå121‰∏™‰ªªÂä°Ôºõ2ÔºâÂü∫ÂáÜÂ•ó‰ª∂ÊûÑÂª∫ÔºåÂåÖÂê´35‰∏™Âü∫ÂáÜ‰ª•ÂÖ®Èù¢Ë¶ÜÁõñÂàÜÁ±ªÊ≥ïÔºõ3ÔºâËØÑ‰º∞ÊñπÊ≥ïÔºåÈááÁî®LLMËØÑÂÆ°Âõ¢ËøõË°åÁ≥ªÁªüÊØîËæÉÂíåÊàêÊú¨-ÊÄßËÉΩÂàÜÊûê„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöMedHELMÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂ÂàÜÁ±ªÊ≥ïÂíåÂü∫ÂáÜÂ•ó‰ª∂ÁöÑÁ≥ªÁªüÊÄßÊûÑÂª∫Ôºå‰ª•Âèä‰ΩøÁî®LLMËØÑÂÆ°Âõ¢ËøõË°åËØÑ‰º∞ÁöÑÊñπÊ≥ï„ÄÇËøô‰∏é‰º†ÁªüÁöÑÂçï‰∏ÄËÄÉËØïËØÑ‰º∞ÊñπÊ≥ïÊú¨Ë¥®‰∏ä‰∏çÂêåÔºåÊèê‰æõ‰∫ÜÊõ¥‰∏∫ÂÖ®Èù¢ÂíåÁúüÂÆûÁöÑËØÑ‰º∞ËßÜËßí„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°ËøáÁ®ã‰∏≠ÔºåÁ†îÁ©∂Âõ¢Èòü‰∏é29‰Ωç‰∏¥Â∫äÂåªÁîüÂêà‰ΩúÔºåÁ°Æ‰øùÂàÜÁ±ªÊ≥ïÁöÑÊúâÊïàÊÄßÂíåÂÆûÁî®ÊÄß„ÄÇÂü∫ÂáÜÂ•ó‰ª∂‰∏≠ÁöÑ‰ªªÂä°Ê∂µÁõñ‰∫Ü‰∏¥Â∫äÁ¨îËÆ∞ÁîüÊàê„ÄÅÊÇ£ËÄÖÊ≤üÈÄö‰∏éÊïôËÇ≤Á≠âÂ§ö‰∏™ÊñπÈù¢ÔºåÁ°Æ‰øù‰∫ÜËØÑ‰º∞ÁöÑÂ§öÊ†∑ÊÄßÂíåÂÖ®Èù¢ÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫Ôºå9‰∏™ÂâçÊ≤øLLMÂú®35‰∏™Âü∫ÂáÜ‰∏äÁöÑË°®Áé∞Â≠òÂú®ÊòæËëóÂ∑ÆÂºÇÔºåÂÖ∂‰∏≠DeepSeek R1Âíåo3-miniÁöÑËÉúÁéáÂàÜÂà´‰∏∫66%Âíå64%„ÄÇClaude 3.5 SonnetÂú®ËæÉ‰ΩéÁöÑËÆ°ÁÆóÊàêÊú¨‰∏ãÂÆûÁé∞‰∫Ü‰∏éÈ°∂Á∫ßÊ®°ÂûãÁõ∏ÂΩìÁöÑÊÄßËÉΩÔºåÂº∫Ë∞É‰∫Ü‰ªªÂä°ÁâπÂÆöËØÑ‰º∞ÁöÑÈáçË¶ÅÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

MedHELMÊ°ÜÊû∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨ÂåªÁñó‰∫∫Â∑•Êô∫ËÉΩÂä©Êâã„ÄÅ‰∏¥Â∫äÂÜ≥Á≠ñÊîØÊåÅÁ≥ªÁªü‰ª•ÂèäÂåªÁñóÊïôËÇ≤Á≠â„ÄÇÈÄöËøáÊèê‰æõÊõ¥ÁúüÂÆûÁöÑËØÑ‰º∞Ê†áÂáÜÔºåËØ•Ê°ÜÊû∂ËÉΩÂ§üÂ∏ÆÂä©ÂºÄÂèëÊõ¥ÊúâÊïàÁöÑÂåªÁñóËØ≠Ë®ÄÊ®°ÂûãÔºåÊèêÂçá‰∏¥Â∫äÂ∑•‰ΩúÊïàÁéáÂíåÊÇ£ËÄÖÊ≤üÈÄöË¥®ÈáèÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÊú™Êù•ÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> While large language models (LLMs) achieve near-perfect scores on medical licensing exams, these evaluations inadequately reflect the complexity and diversity of real-world clinical practice. We introduce MedHELM, an extensible evaluation framework for assessing LLM performance for medical tasks with three key contributions. First, a clinician-validated taxonomy spanning 5 categories, 22 subcategories, and 121 tasks developed with 29 clinicians. Second, a comprehensive benchmark suite comprising 35 benchmarks (17 existing, 18 newly formulated) providing complete coverage of all categories and subcategories in the taxonomy. Third, a systematic comparison of LLMs with improved evaluation methods (using an LLM-jury) and a cost-performance analysis. Evaluation of 9 frontier LLMs, using the 35 benchmarks, revealed significant performance variation. Advanced reasoning models (DeepSeek R1: 66% win-rate; o3-mini: 64% win-rate) demonstrated superior performance, though Claude 3.5 Sonnet achieved comparable results at 40% lower estimated computational cost. On a normalized accuracy scale (0-1), most models performed strongly in Clinical Note Generation (0.73-0.85) and Patient Communication & Education (0.78-0.83), moderately in Medical Research Assistance (0.65-0.75), and generally lower in Clinical Decision Support (0.56-0.72) and Administration & Workflow (0.53-0.63). Our LLM-jury evaluation method achieved good agreement with clinician ratings (ICC = 0.47), surpassing both average clinician-clinician agreement (ICC = 0.43) and automated baselines including ROUGE-L (0.36) and BERTScore-F1 (0.44). Claude 3.5 Sonnet achieved comparable performance to top models at lower estimated cost. These findings highlight the importance of real-world, task-specific evaluation for medical use of LLMs and provides an open source framework to enable this.

