---
layout: default
title: "MT$^{3}$: Scaling MLLM-based Text Image Machine Translation via Multi-Task Reinforcement Learning"
---

# MT$^{3}$: Scaling MLLM-based Text Image Machine Translation via Multi-Task Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.19714" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.19714v1</a>
  <a href="https://arxiv.org/pdf/2505.19714.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.19714v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.19714v1', 'MT$^{3}$: Scaling MLLM-based Text Image Machine Translation via Multi-Task Reinforcement Learning')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Zhaopeng Feng, Yupu Liang, Shaosheng Cao, Jiayuan Su, Jiahan Ren, Zhe Xu, Yao Hu, Wenxuan Huang, Jian Wu, Zuozhu Liu

**ÂàÜÁ±ª**: cs.CL, cs.AI, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-26

**Â§áÊ≥®**: Work in progress

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫MT¬≥Ê°ÜÊû∂‰ª•Ëß£ÂÜ≥ÊñáÊú¨ÂõæÂÉèÊú∫Âô®ÁøªËØë‰∏≠ÁöÑÂ§ö‰ªªÂä°ÊåëÊàò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÊñáÊú¨ÂõæÂÉèÁøªËØë` `Â§ö‰ªªÂä°Â≠¶‰π†` `Âº∫ÂåñÂ≠¶‰π†` `Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã` `Á§æ‰∫§Â™í‰ΩìÁøªËØë` `ÂÖâÂ≠¶Â≠óÁ¨¶ËØÜÂà´` `‰∏ä‰∏ãÊñáÊé®ÁêÜ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. TIMTÈù¢‰∏¥ÁöÑÊ†∏ÂøÉÈóÆÈ¢òÊòØÁé∞ÊúâÊñπÊ≥ïÂú®ÂÖâÂ≠¶Â≠óÁ¨¶ËØÜÂà´ÂíåËßÜËßâ-ÊñáÊú¨Êé®ÁêÜÊñπÈù¢ÁöÑ‰∏çË∂≥ÔºåÂØºËá¥ÁøªËØëË¥®Èáè‰∏çÈ´ò„ÄÇ
2. Êú¨ÊñáÊèêÂá∫ÁöÑMT¬≥Ê°ÜÊû∂ÈÄöËøáÂ§ö‰ªªÂä°Âº∫ÂåñÂ≠¶‰π†ÔºåÈíàÂØπÊñáÊú¨ËØÜÂà´„ÄÅ‰∏ä‰∏ãÊñáÊé®ÁêÜÂíåÁøªËØëËøõË°å‰ºòÂåñÔºåÊèêÂçá‰∫ÜTIMTÁöÑÊï¥‰ΩìÊÄßËÉΩ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåMT¬≥-7B-ZeroÂú®MIT-10MÂü∫ÂáÜ‰∏äË∂ÖË∂ä‰∫ÜQwen2.5-VL-72BÂíåInternVL2.5-78BÁ≠âÂº∫Âü∫Á∫øÔºåË°®Áé∞Âá∫Ëâ≤„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÊñáÊú¨ÂõæÂÉèÊú∫Âô®ÁøªËØëÔºàTIMTÔºâÊòØÂ∞ÜÂõæÂÉè‰∏≠ÂµåÂÖ•ÁöÑÊñáÊú¨ÂÜÖÂÆπËøõË°åÁøªËØëÁöÑ‰ªªÂä°ÔºåÂØπ‰∫éÊó†ÈöúÁ¢çËÆøÈóÆ„ÄÅË∑®ËØ≠Ë®Ä‰ø°ÊÅØËé∑ÂèñÂíåÂÆûÈôÖÊñáÊ°£ÁêÜËß£Ëá≥ÂÖ≥ÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÁî±‰∫éÈúÄË¶ÅÂáÜÁ°ÆÁöÑÂÖâÂ≠¶Â≠óÁ¨¶ËØÜÂà´ÔºàOCRÔºâ„ÄÅÁ®≥ÂÅ•ÁöÑËßÜËßâ-ÊñáÊú¨Êé®ÁêÜÂíåÈ´òË¥®ÈáèÁøªËØëÔºåTIMT‰ªçÁÑ∂Èù¢‰∏¥Â§çÊùÇÊåëÊàò„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏ÄÈóÆÈ¢òÔºåÊú¨ÊñáÊèêÂá∫‰∫ÜMT¬≥Ê°ÜÊû∂ÔºåÈ¶ñÊ¨°Â∞ÜÂ§ö‰ªªÂä°Âº∫ÂåñÂ≠¶‰π†Â∫îÁî®‰∫éÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMsÔºâ‰ª•ÂÆûÁé∞Á´ØÂà∞Á´ØÁöÑTIMT„ÄÇMT¬≥ÈááÁî®Â§ö‰ªªÂä°‰ºòÂåñËåÉÂºèÔºåÈíàÂØπÊñáÊú¨ËØÜÂà´„ÄÅ‰∏ä‰∏ãÊñáÊÑüÁü•Êé®ÁêÜÂíåÁøªËØë‰∏â‰∏™ÂÖ≥ÈîÆÂ≠êÊäÄËÉΩËøõË°åËÆ≠ÁªÉÔºå‰ΩøÁî®Êñ∞È¢ñÁöÑÂ§öÊ∑∑ÂêàÂ•ñÂä±Êú∫Âà∂ÔºåÊèê‰æõÁªÜÁ≤íÂ∫¶ÁöÑÈùû‰∫åÂÖÉÂèçÈ¶à„ÄÇÊ≠§Â§ñÔºåÊú¨ÊñáËøòÂºïÂÖ•‰∫ÜXHSPostÁ§æ‰∫§Â™í‰ΩìTIMTÂü∫ÂáÜÔºå‰ª•‰æøÂú®ÁúüÂÆûÁöÑË∑®ÊñáÂåñÁ§æ‰∫§Â™í‰ΩìÁéØÂ¢É‰∏≠ËØÑ‰º∞TIMT„ÄÇMT¬≥-7B-ZeroÂú®ÊúÄÊñ∞ÁöÑMIT-10MÂü∫ÂáÜ‰∏äÂèñÂæó‰∫ÜÈ¢ÜÂÖàÁªìÊûúÔºåË∂ÖË∂ä‰∫ÜÂ§ö‰∏™Âº∫Âü∫Á∫øÊ®°Âûã„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥ÊñáÊú¨ÂõæÂÉèÊú∫Âô®ÁøªËØëÔºàTIMTÔºâ‰∏≠ÁöÑÂ§ö‰ªªÂä°ÊåëÊàòÔºåÁé∞ÊúâÊñπÊ≥ïÂú®Â§ÑÁêÜÂÖâÂ≠¶Â≠óÁ¨¶ËØÜÂà´„ÄÅËßÜËßâ-ÊñáÊú¨Êé®ÁêÜÂíåÁøªËØëÊó∂Â∏∏Â∏∏ÈúÄË¶ÅÂ§çÊùÇÁöÑÂ§öÈò∂ÊÆµÁÆ°ÈÅìÔºåÂØºËá¥ÊïàÁéá‰Ωé‰∏ãÂíåÁøªËØëË¥®Èáè‰∏ç‰Ω≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöMT¬≥Ê°ÜÊû∂ÈÄöËøáÂºïÂÖ•Â§ö‰ªªÂä°Âº∫ÂåñÂ≠¶‰π†ÔºåÈíàÂØπTIMTÁöÑ‰∏â‰∏™ÂÖ≥ÈîÆÂ≠ê‰ªªÂä°ËøõË°åËÅîÂêà‰ºòÂåñÔºåÊó®Âú®ÊèêÂçáÊ®°ÂûãÁöÑÊï¥‰ΩìÊÄßËÉΩÂíåÈÄÇÂ∫îÊÄß„ÄÇËØ•ËÆæËÆ°‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üÂú®‰∏çÂêå‰ªªÂä°Èó¥ÂÖ±‰∫´Áü•ËØÜÔºå‰ªéËÄåÊèêÈ´òÁøªËØëÁöÑÂáÜÁ°ÆÊÄßÂíåÊµÅÁïÖÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöMT¬≥ÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÊñáÊú¨ËØÜÂà´Ê®°Âùó„ÄÅ‰∏ä‰∏ãÊñáÊÑüÁü•Êé®ÁêÜÊ®°ÂùóÂíåÁøªËØëÊ®°Âùó„ÄÇÈÄöËøáÂ§ö‰ªªÂä°Â≠¶‰π†ÔºåËøô‰∫õÊ®°ÂùóËÉΩÂ§üÂçèÂêåÂ∑•‰ΩúÔºå‰ºòÂåñÊúÄÁªàÁöÑÁøªËØëÁªìÊûú„ÄÇÊ®°Âûã‰ΩøÁî®Êñ∞È¢ñÁöÑÂ§öÊ∑∑ÂêàÂ•ñÂä±Êú∫Âà∂ËøõË°åËÆ≠ÁªÉÔºå‰ª•ÈÄÇÂ∫îTIMTÁöÑÂ§çÊùÇÊÄß„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöMT¬≥ÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÂ∞ÜÂ§ö‰ªªÂä°Âº∫ÂåñÂ≠¶‰π†Â∫îÁî®‰∫éTIMTÔºåÈ¶ñÊ¨°ÂÆûÁé∞‰∫ÜÁ´ØÂà∞Á´ØÁöÑÁøªËØëËøáÁ®ã„ÄÇ‰∏é‰º†ÁªüÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•Ê°ÜÊû∂ËÉΩÂ§üÊèê‰æõÁªÜÁ≤íÂ∫¶ÁöÑÂèçÈ¶àÔºå‰øÉËøõÊ®°ÂûãÂú®Â§ö‰∏™‰ªªÂä°‰∏äÁöÑÂçèÂêåÂ≠¶‰π†„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÊ®°ÂûãÈááÁî®‰∫ÜÈÄÇÂ∫îÊÄßÂ•ñÂä±Êú∫Âà∂ÔºåÁªìÂêàËßÑÂàôÂü∫Á°ÄÁöÑÂº∫ÂåñÂ≠¶‰π†Á≠ñÁï•ÔºåÁ°Æ‰øùÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠ËÉΩÂ§üÊúâÊïàÂú∞Â§ÑÁêÜ‰∏çÂêå‰ªªÂä°ÁöÑÂ§çÊùÇÊÄß„ÄÇÊçüÂ§±ÂáΩÊï∞ËÆæËÆ°‰∏äÔºåËÄÉËôë‰∫ÜÂêÑ‰∏™Â≠ê‰ªªÂä°ÁöÑÁâπÊÄßÔºåÁ°Æ‰øùÊ®°ÂûãÂú®ËÆ≠ÁªÉÊó∂ËÉΩÂ§üÂπ≥Ë°°ÂêÑÈ°π‰ªªÂä°ÁöÑ‰ºòÂåñ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

MT¬≥-7B-ZeroÂú®MIT-10MÂü∫ÂáÜ‰∏äÂèñÂæó‰∫ÜÈ¢ÜÂÖàÁöÑÂÆûÈ™åÁªìÊûúÔºåË∂ÖË∂ä‰∫ÜQwen2.5-VL-72BÂíåInternVL2.5-78BÁ≠âÂº∫Âü∫Á∫øÔºåÊèêÂçáÂπÖÂ∫¶ÊòæËëóÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®Â§ö‰ªªÂä°Â≠¶‰π†ÂíåÂº∫ÂåñÂ≠¶‰π†ÊñπÈù¢ÁöÑ‰ºòÂäø„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Á§æ‰∫§Â™í‰ΩìÂÜÖÂÆπÁøªËØë„ÄÅË∑®ÊñáÂåñ‰ø°ÊÅØËé∑ÂèñÂíåÊó†ÈöúÁ¢çÊäÄÊúØÁ≠â„ÄÇÈÄöËøáÊèêÂçáÊñáÊú¨ÂõæÂÉèÊú∫Âô®ÁøªËØëÁöÑÂáÜÁ°ÆÊÄßÂíåÊïàÁéáÔºåMT¬≥Ê°ÜÊû∂ËÉΩÂ§üÂú®Â§öÁßçÂÆûÈôÖÂú∫ÊôØ‰∏≠Êèê‰æõÊõ¥Â•ΩÁöÑÁî®Êà∑‰ΩìÈ™åÔºå‰øÉËøõ‰ø°ÊÅØÁöÑÊó†ÈöúÁ¢ç‰º†Êí≠ÂíåÁêÜËß£„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Text Image Machine Translation (TIMT)-the task of translating textual content embedded in images-is critical for applications in accessibility, cross-lingual information access, and real-world document understanding. However, TIMT remains a complex challenge due to the need for accurate optical character recognition (OCR), robust visual-text reasoning, and high-quality translation, often requiring cascading multi-stage pipelines. Recent advances in large-scale Reinforcement Learning (RL) have improved reasoning in Large Language Models (LLMs) and Multimodal LLMs (MLLMs), but their application to end-to-end TIMT is still underexplored. To bridge this gap, we introduce MT$^{3}$, the first framework to apply Multi-Task RL to MLLMs for end-to-end TIMT. MT$^{3}$ adopts a multi-task optimization paradigm targeting three key sub-skills: text recognition, context-aware reasoning, and translation. It is trained using a novel multi-mixed reward mechanism that adapts rule-based RL strategies to TIMT's intricacies, offering fine-grained, non-binary feedback across tasks. Furthermore, to facilitate the evaluation of TIMT in authentic cross-cultural and real-world social media contexts, we introduced XHSPost, the first social media TIMT benchmark. Our MT$^{3}$-7B-Zero achieves state-of-the-art results on the latest in-domain MIT-10M benchmark, outperforming strong baselines such as Qwen2.5-VL-72B and InternVL2.5-78B by notable margins across multiple metrics. Additionally, the model shows strong generalization to out-of-distribution language pairs and datasets. In-depth analyses reveal how multi-task synergy, reinforcement learning initialization, curriculum design, and reward formulation contribute to advancing MLLM-driven TIMT.

