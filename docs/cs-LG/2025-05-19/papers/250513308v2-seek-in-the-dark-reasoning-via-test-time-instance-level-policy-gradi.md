---
layout: default
title: Seek in the Dark: Reasoning via Test-Time Instance-Level Policy Gradient in Latent Space
---

# Seek in the Dark: Reasoning via Test-Time Instance-Level Policy Gradient in Latent Space

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.13308" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.13308v2</a>
  <a href="https://arxiv.org/pdf/2505.13308.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.13308v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.13308v2', 'Seek in the Dark: Reasoning via Test-Time Instance-Level Policy Gradient in Latent Space')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hengli Li, Chenxi Li, Tong Wu, Xuekai Zhu, Yuxuan Wang, Zhaoxin Yu, Eric Hanchen Jiang, Song-Chun Zhu, Zixia Jia, Ying Nian Wu, Zilong Zheng

**åˆ†ç±»**: cs.LG, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-19 (æ›´æ–°: 2025-10-30)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLatentSeekä»¥æå‡å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ¨ç†èƒ½åŠ›` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ½œåœ¨ç©ºé—´` `ç­–ç•¥æ¢¯åº¦` `æµ‹è¯•æ—¶é€‚åº”` `è‡ªç”Ÿæˆå¥–åŠ±` `å®éªŒåŸºå‡†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æ¨ç†èƒ½åŠ›ä¸Šä»é¢ä¸´æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨è®­ç»ƒç®—æ³•å’Œæ–°æ•°æ®çš„å¯ç”¨æ€§æ–¹é¢ã€‚
2. è®ºæ–‡æå‡ºLatentSeekæ¡†æ¶ï¼Œé€šè¿‡æ½œåœ¨ç©ºé—´è¿›è¡Œæµ‹è¯•æ—¶å®ä¾‹çº§é€‚åº”ï¼Œåˆ©ç”¨ç­–ç•¥æ¢¯åº¦ä¼˜åŒ–æ¨ç†è¿‡ç¨‹ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºLatentSeekåœ¨GSM8Kã€MATH-500ç­‰åŸºå‡†ä¸Šè¶…è¶Šäº†ä¼ ç»Ÿæ–¹æ³•ï¼Œä¸”æ”¶æ•›é€Ÿåº¦å¿«ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ¨ç†èƒ½åŠ›æ˜¯äººç±»æ™ºèƒ½çš„æ ¸å¿ƒç»„æˆéƒ¨åˆ†ï¼Œä½†åœ¨è¿½æ±‚é€šç”¨äººå·¥æ™ºèƒ½ï¼ˆAGIï¼‰çš„è¿‡ç¨‹ä¸­ï¼Œä»ç„¶å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ„æˆé‡å¤§æŒ‘æˆ˜ã€‚å°½ç®¡æ¨¡å‹æ€§èƒ½åœ¨è®­ç»ƒè§„æ¨¡æ³•åˆ™ä¸‹æœ‰æ‰€æå‡ï¼Œä½†è®­ç»ƒç®—æ³•ï¼ˆå¦‚ç¾éš¾æ€§é—å¿˜ï¼‰å’Œæ–°è®­ç»ƒæ•°æ®çš„æœ‰é™å¯ç”¨æ€§ä»ç„¶æ˜¯æ˜¾è‘—é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§æ–°æ¡†æ¶LatentSeekï¼Œé€šè¿‡åœ¨æ¨¡å‹çš„æ½œåœ¨ç©ºé—´ä¸­è¿›è¡Œæµ‹è¯•æ—¶å®ä¾‹çº§é€‚åº”ï¼ˆTTIAï¼‰ï¼Œåˆ©ç”¨ç­–ç•¥æ¢¯åº¦è¿­ä»£æ›´æ–°æ½œåœ¨è¡¨ç¤ºï¼Œå€ŸåŠ©è‡ªç”Ÿæˆçš„å¥–åŠ±ä¿¡å·è¿›è¡Œå¼•å¯¼ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLatentSeekåœ¨å¤šä¸ªæ¨ç†åŸºå‡†ä¸Šè¶…è¶Šäº†å¼ºåŸºçº¿ï¼Œä¸”åœ¨å¹³å‡å¤æ‚åº¦é—®é¢˜ä¸Šé€šå¸¸åœ¨å‡ æ¬¡è¿­ä»£å†…æ”¶æ•›ï¼Œæ˜¾ç¤ºå‡ºæ½œåœ¨ç©ºé—´æµ‹è¯•æ—¶æ‰©å±•çš„æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¨ç†èƒ½åŠ›ä¸Šçš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯ç°æœ‰æ–¹æ³•åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é¢ä¸´çš„ç¾éš¾æ€§é—å¿˜å’Œæ•°æ®ç¨€ç¼ºé—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„LatentSeekæ¡†æ¶é€šè¿‡åœ¨æ½œåœ¨ç©ºé—´ä¸­è¿›è¡Œæµ‹è¯•æ—¶å®ä¾‹çº§é€‚åº”ï¼Œåˆ©ç”¨ç­–ç•¥æ¢¯åº¦æ–¹æ³•è¿­ä»£æ›´æ–°æ½œåœ¨è¡¨ç¤ºï¼Œä»¥è‡ªç”Ÿæˆçš„å¥–åŠ±ä¿¡å·ä¸ºæŒ‡å¯¼ï¼Œä»è€Œæå‡æ¨ç†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLatentSeekçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ½œåœ¨ç©ºé—´çš„è¡¨ç¤ºå­¦ä¹ ã€ç­–ç•¥æ¢¯åº¦ä¼˜åŒ–å’Œè‡ªç”Ÿæˆå¥–åŠ±ä¿¡å·çš„è®¾è®¡ã€‚è¯¥æ¡†æ¶é€šè¿‡å¤šæ¬¡è¿­ä»£æ¥ä¼˜åŒ–æ½œåœ¨è¡¨ç¤ºï¼Œå¢å¼ºæ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šLatentSeekçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶åœ¨æ½œåœ¨ç©ºé—´ä¸­è¿›è¡Œæ¨ç†çš„èƒ½åŠ›ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•é›†ä¸­åœ¨æ ‡è®°ç©ºé—´çš„ç­–ç•¥å½¢æˆé²œæ˜å¯¹æ¯”ã€‚è¿™ç§æ–¹æ³•æ›´æœ‰æ•ˆåœ°éµå¾ªæµ‹è¯•æ—¶æ‰©å±•æ³•åˆ™ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒLatentSeeké‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ½œåœ¨è¡¨ç¤ºï¼Œå¹¶é€šè¿‡ç­–ç•¥æ¢¯åº¦æ–¹æ³•å®ç°é«˜æ•ˆçš„è¿­ä»£æ›´æ–°ï¼Œç¡®ä¿æ¨¡å‹åœ¨æ¨ç†ä»»åŠ¡ä¸­çš„å¿«é€Ÿæ”¶æ•›ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLatentSeekåœ¨GSM8Kã€MATH-500å’ŒAIME2024ç­‰æ¨ç†åŸºå‡†ä¸Šå‡æ˜¾è‘—è¶…è¶Šäº†ä¼ ç»Ÿçš„Chain-of-Thoughtæç¤ºå’ŒåŸºäºå¾®è°ƒçš„æ–¹æ³•ï¼Œé€šå¸¸åœ¨å‡ æ¬¡è¿­ä»£å†…æ”¶æ•›ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨æ¨ç†ä»»åŠ¡ä¸­çš„é«˜æ•ˆæ€§å’Œå¯æ‰©å±•æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æ™ºèƒ½é—®ç­”ç³»ç»Ÿå’Œè‡ªåŠ¨æ¨ç†ç­‰ã€‚é€šè¿‡æå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼ŒLatentSeekå¯ä»¥åœ¨æ›´å¤æ‚çš„ä»»åŠ¡ä¸­æä¾›æ›´å‡†ç¡®çš„ç»“æœï¼Œæ¨åŠ¨äººå·¥æ™ºèƒ½åœ¨å®é™…åº”ç”¨ä¸­çš„å‘å±•ä¸è½åœ°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Reasoning ability, a core component of human intelligence, continues to pose a significant challenge for Large Language Models (LLMs) in the pursuit of AGI. Although model performance has improved under the training scaling law, significant challenges remain, particularly with respect to training algorithms, such as catastrophic forgetting, and the limited availability of novel training data. As an alternative, test-time scaling enhances reasoning performance by increasing test-time computation without parameter updating. Unlike prior methods in this paradigm focused on token space, we propose leveraging latent space for more effective reasoning and better adherence to the test-time scaling law. We introduce LatentSeek, a novel framework that enhances LLM reasoning through Test-Time Instance-level Adaptation (TTIA) within the model's latent space. Specifically, LatentSeek leverages policy gradient to iteratively update latent representations, guided by self-generated reward signals. LatentSeek is evaluated on a range of reasoning benchmarks, including GSM8K, MATH-500, and AIME2024, across multiple LLM architectures. Results show that LatentSeek consistently outperforms strong baselines, such as Chain-of-Thought prompting and fine-tuning-based methods. Furthermore, our analysis demonstrates that LatentSeek is highly efficient, typically converging within a few iterations for problems of average complexity, while also benefiting from additional iterations, thereby highlighting the potential of test-time scaling in the latent space. These findings position LatentSeek as a lightweight, scalable, and effective solution for enhancing the reasoning capabilities of LLMs.

