---
layout: default
title: "Beyond Semantics: The Unreasonable Effectiveness of Reasonless Intermediate Tokens"
---

# Beyond Semantics: The Unreasonable Effectiveness of Reasonless Intermediate Tokens

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.13775" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.13775v3</a>
  <a href="https://arxiv.org/pdf/2505.13775.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.13775v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.13775v3', 'Beyond Semantics: The Unreasonable Effectiveness of Reasonless Intermediate Tokens')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Karthik Valmeekam, Kaya Stechly, Vardhan Palod, Atharva Gundawar, Subbarao Kambhampati

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-19 (æ›´æ–°: 2025-11-22)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ— è¯­ä¹‰ä¸­é—´æ ‡è®°ä»¥æŒ‘æˆ˜æ¨ç†æ¨¡å‹çš„ä¼ ç»Ÿç†è§£**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ¨ç†æ¨¡å‹` `é“¾å¼æ€ç»´` `ä¸­é—´æ ‡è®°` `è‡ªç„¶è¯­è¨€å¤„ç†` `å¼ºåŒ–å­¦ä¹ ` `æ¨¡å‹è®­ç»ƒ` `æ¨ç†èƒ½åŠ›`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æ¨ç†æ¨¡å‹çš„ä¸­é—´æ ‡è®°ä¸Šè¿‡äºä¾èµ–è¯­ä¹‰ï¼Œå¯¼è‡´å¯¹æ¨¡å‹æ¨ç†è¿‡ç¨‹çš„è¯¯è§£ã€‚
2. æœ¬æ–‡é€šè¿‡è®­ç»ƒæ¨¡å‹äºå½¢å¼å¯éªŒè¯çš„æ¨ç†ç—•è¿¹ï¼Œç³»ç»Ÿæ€§åœ°ç ”ç©¶å…¶å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè®­ç»ƒäºé”™è¯¯ç—•è¿¹çš„æ¨¡å‹åœ¨æŸäº›ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜äºä»…è®­ç»ƒäºæ­£ç¡®ç—•è¿¹çš„æ¨¡å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå¤§å‹æ¨ç†æ¨¡å‹çš„æ˜¾è‘—æˆæœè¢«è§£è¯»ä¸ºé“¾å¼æ€ç»´ï¼ˆCoTï¼‰çš„æˆåŠŸï¼Œå°¤å…¶æ˜¯é€šè¿‡ä»åŸºç¡€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­é‡‡æ ·çš„CoTè¿›è¡Œè®­ç»ƒã€‚ç„¶è€Œï¼Œå°½ç®¡è¿™äº›æ¨ç†ç—•è¿¹ä¼¼ä¹æœ‰åŠ©äºæ¨¡å‹æ€§èƒ½ï¼Œä½†å®ƒä»¬å¦‚ä½•å½±å“æ¨¡å‹ä»ä¸æ˜ç¡®ã€‚æœ¬æ–‡é€šè¿‡æ§åˆ¶å®éªŒç ”ç©¶æ¨ç†ç—•è¿¹çš„ä½œç”¨ï¼Œå‘ç°å³ä½¿åœ¨å®Œå…¨æ­£ç¡®çš„æ¨ç†ç—•è¿¹ä¸Šè®­ç»ƒçš„æ¨¡å‹ä¹Ÿå¯èƒ½äº§ç”Ÿæ— æ•ˆçš„æ¨ç†ç—•è¿¹ã€‚æ­¤å¤–ï¼Œè®­ç»ƒäºé”™è¯¯ç—•è¿¹çš„æ¨¡å‹åœ¨æŸäº›ä»»åŠ¡ä¸Šè¡¨ç°ä¸æ­£ç¡®ç—•è¿¹ç›¸ä¼¼ï¼Œç”šè‡³æ›´å…·æ³›åŒ–èƒ½åŠ›ã€‚è¿™äº›ç»“æœæŒ‘æˆ˜äº†ä¸­é—´æ ‡è®°åæ˜ å¯é¢„æµ‹æ¨ç†è¡Œä¸ºçš„å‡è®¾ï¼Œå¹¶è­¦ç¤ºä¸è¦è¿‡åº¦è§£è¯»è¿™äº›è¾“å‡ºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨æ¢è®¨æ¨ç†æ¨¡å‹ä¸­é—´æ ‡è®°çš„æœ‰æ•ˆæ€§ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€å‡è®¾è¿™äº›æ ‡è®°å…·æœ‰æ˜ç¡®çš„è¯­ä¹‰å’Œæ¨ç†èƒ½åŠ›ï¼Œä½†å®é™…æƒ…å†µå¯èƒ½å¹¶éå¦‚æ­¤ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡è®­ç»ƒæ¨¡å‹äºå½¢å¼ä¸Šå¯éªŒè¯çš„æ¨ç†ç—•è¿¹ï¼Œç ”ç©¶å…¶å¯¹æ¨¡å‹æ¨ç†èƒ½åŠ›çš„å½±å“ï¼Œå°¤å…¶æ˜¯ä¸­é—´æ ‡è®°çš„æœ‰æ•ˆæ€§ä¸æ¨ç†ç»“æœä¹‹é—´çš„å…³ç³»ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨æ§åˆ¶å®éªŒè®¾è®¡ï¼Œè®­ç»ƒTransformeræ¨¡å‹äºä¸åŒç±»å‹çš„æ¨ç†ç—•è¿¹ï¼ŒåŒ…æ‹¬å®Œå…¨æ­£ç¡®å’Œé”™è¯¯çš„ç—•è¿¹ï¼Œè¯„ä¼°å…¶åœ¨æ¨ç†ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„ä¸»è¦åˆ›æ–°åœ¨äºæ­ç¤ºäº†ä¸­é—´æ¨ç†ç—•è¿¹çš„æœ‰æ•ˆæ€§å¹¶ä¸æ€»æ˜¯ä¸æœ€ç»ˆè§£å†³æ–¹æ¡ˆçš„æ­£ç¡®æ€§ç›¸å…³ï¼ŒæŒ‘æˆ˜äº†ä¼ ç»Ÿçš„æ¨ç†æ¨¡å‹è®¾è®¡ç†å¿µã€‚

**å…³é”®è®¾è®¡**ï¼šå®éªŒä¸­ä½¿ç”¨äº†å¤šç§æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ï¼Œç‰¹åˆ«å…³æ³¨äº†æ¨ç†ç—•è¿¹çš„é•¿åº¦ä¸æ¨ç†å¤æ‚æ€§ä¹‹é—´çš„å…³ç³»ï¼Œå‘ç°å…¶å¹¶ä¸ç›´æ¥ç›¸å…³ã€‚é€šè¿‡GRPOåŸºç¡€çš„å¼ºåŒ–å­¦ä¹ åè®­ç»ƒï¼Œè™½ç„¶æé«˜äº†è§£å†³æ–¹æ¡ˆçš„å‡†ç¡®æ€§ï¼Œä½†æœªæ”¹å–„æ¨ç†ç—•è¿¹çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œè®­ç»ƒäºé”™è¯¯æ¨ç†ç—•è¿¹çš„æ¨¡å‹åœ¨æŸäº›ä»»åŠ¡ä¸Šä¸è®­ç»ƒäºæ­£ç¡®ç—•è¿¹çš„æ¨¡å‹è¡¨ç°ç›¸ä¼¼ï¼Œç”šè‡³åœ¨åˆ†å¸ƒå¤–ä»»åŠ¡ä¸Šæ³›åŒ–èƒ½åŠ›æ›´å¼ºã€‚è¿™ä¸€å‘ç°æŒ‘æˆ˜äº†ä¸­é—´æ ‡è®°çš„ä¼ ç»Ÿç†è§£ï¼Œå¼ºè°ƒäº†æ¨ç†è¿‡ç¨‹çš„å¤æ‚æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æ™ºèƒ½é—®ç­”ç³»ç»Ÿå’Œè‡ªåŠ¨æ¨ç†å·¥å…·ã€‚é€šè¿‡å¯¹æ¨ç†æ¨¡å‹çš„æ·±å…¥ç†è§£ï¼Œå¯ä»¥æå‡æ¨¡å‹åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œæ¨åŠ¨æ›´æ™ºèƒ½çš„AIç³»ç»Ÿçš„å‘å±•ã€‚æœªæ¥ï¼Œç ”ç©¶ç»“æœå¯èƒ½å½±å“æ¨ç†æ¨¡å‹çš„è®¾è®¡å’Œè®­ç»ƒæ–¹æ³•ï¼Œä¿ƒè¿›æ›´é«˜æ•ˆçš„æ¨ç†è¿‡ç¨‹ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent impressive results from large reasoning models have been interpreted as a triumph of Chain of Thought (CoT), especially of training on CoTs sampled from base LLMs to help find new reasoning patterns. While these traces certainly seem to help model performance, it is not clear how they actually influence it, with some works ascribing semantics to the traces and others cautioning against relying on them as transparent and faithful proxies of the model's internal computational process. To systematically investigate the role of end-user semantics of derivational traces, we set up a controlled study where we train transformer models from scratch on formally verifiable reasoning traces and the solutions they lead to. We notice that, despite significant gains over the solution-only baseline, models trained on entirely correct traces can still produce invalid reasoning traces even when arriving at correct solutions. More interestingly, our experiments also show that models trained on corrupted traces, whose intermediate reasoning steps bear no relation to the problem they accompany, perform similarly to those trained on correct ones, and even generalize better on out-of-distribution tasks. We also study the effect of GRPO-based RL post-training on trace validity, noting that while solution accuracy increase, this is not accompanied by any improvements in trace validity. Finally, we examine whether reasoning-trace length reflects inference-time scaling and find that trace length is largely agnostic to the underlying computational complexity of the problem being solved. These results challenge the assumption that intermediate tokens or ``Chains of Thought'' reflect or induce predictable reasoning behaviors and caution against anthropomorphizing such outputs or over-interpreting them (despite their mostly seemingly forms) as evidence of human-like or algorithmic behaviors in language models.

