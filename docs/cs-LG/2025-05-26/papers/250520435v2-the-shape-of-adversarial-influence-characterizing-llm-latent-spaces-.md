---
layout: default
title: The Shape of Adversarial Influence: Characterizing LLM Latent Spaces with Persistent Homology
---

# The Shape of Adversarial Influence: Characterizing LLM Latent Spaces with Persistent Homology

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20435" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.20435v2</a>
  <a href="https://arxiv.org/pdf/2505.20435.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20435v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20435v2', 'The Shape of Adversarial Influence: Characterizing LLM Latent Spaces with Persistent Homology')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Aideen Fay, InÃ©s GarcÃ­a-Redondo, Qiquan Wang, Haim Dubossarsky, Anthea Monod

**åˆ†ç±»**: cs.LG, cs.AI, cs.CG, math.AT

**å‘å¸ƒæ—¥æœŸ**: 2025-05-26 (æ›´æ–°: 2025-10-09)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ©ç”¨æŒä¹…åŒè°ƒåˆ†æLLMçš„å¯¹æŠ—å½±å“ç‰¹å¾**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¯¹æŠ—æ ·æœ¬` `æŒä¹…åŒè°ƒ` `å¯è§£é‡Šæ€§` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ‹“æ‰‘æ•°æ®åˆ†æ` `æ¨¡å‹å®‰å…¨æ€§` `æ¿€æ´»åˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¯è§£é‡Šæ€§æ–¹æ³•æœªèƒ½å……åˆ†æ•æ‰LLMå†…éƒ¨è¡¨ç¤ºçš„å¤æ‚å‡ ä½•ç»“æ„ï¼Œå¯¼è‡´å¯¹æŠ—å½±å“çš„ç†è§£ä¸è¶³ã€‚
2. æœ¬ç ”ç©¶æå‡ºæŒä¹…åŒè°ƒä½œä¸ºåˆ†æå·¥å…·ï¼Œç³»ç»Ÿæ€§åœ°è¡¨å¾LLMæ¿€æ´»ä¸­çš„å¤šå°ºåº¦åŠ¨æ€ï¼Œæ­ç¤ºå¯¹æŠ—è¾“å…¥çš„æ‹“æ‰‘ç‰¹å¾ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå¯¹æŠ—è¾“å…¥å¯¼è‡´çš„æ‹“æ‰‘å‹ç¼©ç°è±¡åœ¨ä¸åŒæ¨¡å‹å’Œå±‚æ¬¡ä¸­å…·æœ‰ç»Ÿè®¡ç¨³å¥æ€§ï¼Œæä¾›äº†æ–°çš„å¯è§£é‡Šæ€§è§†è§’ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯è§£é‡Šæ€§æ–¹æ³•å¾€å¾€å±€é™äºçº¿æ€§æ–¹å‘æˆ–å­¤ç«‹ç‰¹å¾ï¼Œå¿½è§†äº†æ¨¡å‹è¡¨ç¤ºä¸­çš„é«˜ç»´ã€éçº¿æ€§å’Œå…³ç³»å‡ ä½•ã€‚æœ¬ç ”ç©¶èšç„¦äºå¯¹æŠ—è¾“å…¥å¦‚ä½•ç³»ç»Ÿæ€§åœ°å½±å“LLMçš„å†…éƒ¨è¡¨ç¤ºç©ºé—´ï¼Œæå‡ºä½¿ç”¨æŒä¹…åŒè°ƒï¼ˆPHï¼‰ä½œä¸ºæ¡†æ¶æ¥è¡¨å¾LLMæ¿€æ´»ä¸­çš„å¤šå°ºåº¦åŠ¨æ€ã€‚é€šè¿‡å¯¹å…­ç§å…ˆè¿›æ¨¡å‹åœ¨ä¸¤ç§å¯¹æŠ—æ¡ä»¶ä¸‹çš„ç³»ç»Ÿåˆ†æï¼Œè¯†åˆ«å‡ºå¯¹æŠ—å½±å“çš„ä¸€è‡´æ‹“æ‰‘ç‰¹å¾ï¼Œæ­ç¤ºäº†å¯¹æŠ—è¾“å…¥å¯¼è‡´çš„â€œæ‹“æ‰‘å‹ç¼©â€ç°è±¡ï¼Œæä¾›äº†å¯¹å¯¹æŠ—æ•ˆåº”çš„å¯è§£é‡Šæ€§è§è§£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³ç°æœ‰å¯è§£é‡Šæ€§æ–¹æ³•æ— æ³•æœ‰æ•ˆæ•æ‰LLMå†…éƒ¨é«˜ç»´ã€éçº¿æ€§ç»“æ„çš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨å¯¹æŠ—è¾“å…¥å½±å“ä¸‹çš„è¡¨ç°å˜åŒ–ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥æŒä¹…åŒè°ƒï¼ˆPHï¼‰ï¼Œæˆ‘ä»¬èƒ½å¤Ÿä»æ‹“æ‰‘æ•°æ®åˆ†æçš„è§’åº¦ç³»ç»Ÿæ€§åœ°åˆ†æLLMçš„æ¿€æ´»ï¼Œè¯†åˆ«å‡ºå¯¹æŠ—è¾“å…¥å¯¹æ¨¡å‹è¡¨ç¤ºçš„å½±å“ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é¦–å…ˆå®šä¹‰å¯¹æŠ—æ¡ä»¶ï¼ŒåŒ…æ‹¬é—´æ¥æç¤ºæ³¨å…¥å’Œåé—¨å¾®è°ƒï¼Œç„¶ååº”ç”¨PHåˆ†æå…­ç§å…ˆè¿›æ¨¡å‹çš„æ¿€æ´»ï¼Œæå–æ‹“æ‰‘ç‰¹å¾å¹¶è¿›è¡Œæ¯”è¾ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„ä¸»è¦åˆ›æ–°åœ¨äºä½¿ç”¨æŒä¹…åŒè°ƒä½œä¸ºåˆ†æå·¥å…·ï¼Œæ­ç¤ºäº†å¯¹æŠ—è¾“å…¥å¯¼è‡´çš„æ‹“æ‰‘å‹ç¼©ç°è±¡ï¼Œè¿™ä¸€ç‰¹å¾åœ¨ä¸åŒæ¨¡å‹å’Œå±‚æ¬¡ä¸­å…·æœ‰ä¸€è‡´æ€§å’Œå¯è§£é‡Šæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œè®¾ç½®äº†å¤šç§å¯¹æŠ—è¾“å…¥æ¡ä»¶ï¼Œé‡‡ç”¨äº†æ ‡å‡†çš„PHç®—æ³•æ¥æå–æ‹“æ‰‘ç‰¹å¾ï¼Œå¹¶é€šè¿‡ç»Ÿè®¡æ–¹æ³•éªŒè¯å…¶ç¨³å¥æ€§å’ŒåŒºåˆ†èƒ½åŠ›ã€‚å…·ä½“å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡åœ¨è®ºæ–‡ä¸­è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æœ‰åˆ†æçš„æ¨¡å‹åœ¨å¯¹æŠ—è¾“å…¥ä¸‹å‡è¡¨ç°å‡ºæ˜¾è‘—çš„æ‹“æ‰‘å‹ç¼©ç°è±¡ï¼Œæ‹“æ‰‘ç‰¹å¾åœ¨ä¸åŒå±‚æ¬¡é—´å…·æœ‰é«˜åº¦ä¸€è‡´æ€§ã€‚è¿™ä¸€å‘ç°ä¸ºç†è§£å¯¹æŠ—å½±å“æä¾›äº†æ–°çš„è§†è§’ï¼Œä¸”åœ¨ç»Ÿè®¡ä¸Šå…·æœ‰æ˜¾è‘—æ€§ï¼Œå±•ç¤ºäº†æŒä¹…åŒè°ƒåœ¨æ¨¡å‹å¯è§£é‡Šæ€§ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¯¹æŠ—æ ·æœ¬æ£€æµ‹ã€æ¨¡å‹å®‰å…¨æ€§è¯„ä¼°å’ŒLLMçš„å¯è§£é‡Šæ€§æå‡ã€‚é€šè¿‡æ·±å…¥ç†è§£å¯¹æŠ—è¾“å…¥å¯¹æ¨¡å‹å†…éƒ¨è¡¨ç¤ºçš„å½±å“ï¼Œå¯ä»¥ä¸ºæœªæ¥çš„æ¨¡å‹è®¾è®¡å’Œä¼˜åŒ–æä¾›é‡è¦å‚è€ƒï¼Œå¢å¼ºAIç³»ç»Ÿçš„é²æ£’æ€§å’Œé€æ˜åº¦ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Existing interpretability methods for Large Language Models (LLMs) often fall short by focusing on linear directions or isolated features, overlooking the high-dimensional, nonlinear, and relational geometry within model representations. This study focuses on how adversarial inputs systematically affect the internal representation spaces of LLMs, a topic which remains poorly understood. We propose persistent homology (PH), a tool from topological data analysis, as a principled framework to characterize the multi-scale dynamics within LLM activations. Using PH, we systematically analyze six state-of-the-art models under two distinct adversarial conditions, indirect prompt injection and backdoor fine-tuning, and identify a consistent topological signature of adversarial influence. Across architectures and model sizes, adversarial inputs induce ``topological compression'', where the latent space becomes structurally simpler, collapsing from varied, compact, small-scale features into fewer, dominant, and more dispersed large-scale ones. This topological signature is statistically robust across layers, highly discriminative, and provides interpretable insights into how adversarial effects emerge and propagate. By quantifying the shape of activations and neuronal information flow, our architecture-agnostic framework reveals fundamental invariants of representational change, offering a complementary perspective to existing interpretability methods.

