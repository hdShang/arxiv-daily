---
layout: default
title: Alignment of large language models with constrained learning
---

# Alignment of large language models with constrained learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.19387" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.19387v2</a>
  <a href="https://arxiv.org/pdf/2505.19387.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.19387v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.19387v2', 'Alignment of large language models with constrained learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Botong Zhang, Shuo Li, Ignacio Hounie, Osbert Bastani, Dongsheng Ding, Alejandro Ribeiro

**åˆ†ç±»**: cs.LG, eess.SY, math.OC

**å‘å¸ƒæ—¥æœŸ**: 2025-05-26 (æ›´æ–°: 2025-11-26)

**å¤‡æ³¨**: 51 pages, 5 figures, 11 tables; Accepted to NeurIPS 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºæ‹‰æ ¼æœ—æ—¥å¯¹å¶çš„è¿­ä»£æ–¹æ³•ä»¥è§£å†³çº¦æŸå¯¹é½é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `çº¦æŸå¯¹é½` `æ‹‰æ ¼æœ—æ—¥å¯¹å¶` `å¼ºåŒ–å­¦ä¹ ` `ç­–ç•¥ä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„åŸºäºæ‹‰æ ¼æœ—æ—¥çš„LLMç­–ç•¥æœç´¢æ–¹æ³•åœ¨çº¦æŸå¯¹é½ä¸­é¢ä¸´æ”¶æ•›æ€§å·®å’Œæœ€ä¼˜æ€§ä¸è¶³çš„é—®é¢˜ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§è¿­ä»£çš„å¯¹å¶åŸºç¡€å¯¹é½æ–¹æ³•ï¼Œé€šè¿‡æ‹‰æ ¼æœ—æ—¥æœ€å¤§åŒ–å’Œå¯¹å¶ä¸‹é™äº¤æ›¿æ›´æ–°LLMç­–ç•¥å’Œå¯¹å¶å˜é‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨PKU-SafeRLHFå’ŒAnthropic HH-RLHFæ•°æ®é›†ä¸Šæ˜¾è‘—æå‡äº†ç­–ç•¥çš„æœ€ä¼˜æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ç ”ç©¶äº†åœ¨çº¦æŸå¯¹é½é—®é¢˜ä¸­è®¡ç®—æœ€ä¼˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç­–ç•¥çš„æŒ‘æˆ˜ï¼Œç›®æ ‡æ˜¯åœ¨æ»¡è¶³æ¬¡è¦æ•ˆç”¨çº¦æŸçš„åŒæ—¶æœ€å¤§åŒ–ä¸»è¦å¥–åŠ±ç›®æ ‡ã€‚å°½ç®¡åŸºäºæ‹‰æ ¼æœ—æ—¥çš„LLMç­–ç•¥æœç´¢åœ¨çº¦æŸå¯¹é½ä¸­å¹¿å—æ¬¢è¿ï¼Œä½†è¿­ä»£çš„åŸå§‹-å¯¹å¶æ–¹æ³•å¸¸å¸¸æ— æ³•æ”¶æ•›ï¼Œè€Œéè¿­ä»£çš„å¯¹å¶æ–¹æ³•åœ¨LLMå‚æ•°ç©ºé—´ä¸­æœªèƒ½è¾¾åˆ°æœ€ä¼˜ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡é‡‡ç”¨æ‹‰æ ¼æœ—æ—¥å¯¹å¶æ€§ï¼Œæå‡ºäº†ä¸€ç§è¿­ä»£çš„å¯¹å¶åŸºç¡€å¯¹é½æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åœ¨é€šè¿‡æ‹‰æ ¼æœ—æ—¥æœ€å¤§åŒ–æ›´æ–°LLMç­–ç•¥å’Œé€šè¿‡å¯¹å¶ä¸‹é™æ›´æ–°å¯¹å¶å˜é‡ä¹‹é—´äº¤æ›¿è¿›è¡Œã€‚ç†è®ºä¸Šï¼Œæˆ‘ä»¬è¡¨å¾äº†åˆ†å¸ƒç©ºé—´ä¸­çš„åŸå§‹å€¼ä¸LLMå‚æ•°ç©ºé—´ä¸­çš„å¯¹å¶å€¼ä¹‹é—´çš„åŸå§‹-å¯¹å¶é—´éš™ï¼Œå¹¶é‡åŒ–äº†åœ¨æ¥è¿‘æœ€ä¼˜å¯¹å¶å˜é‡ä¸‹å­¦ä¹ åˆ°çš„LLMç­–ç•¥çš„æœ€ä¼˜æ€§é—´éš™ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºå¯¹å¶çš„å¯¹é½æ–¹æ³•èƒ½å¤Ÿæ‰¾åˆ°æœ€ä¼˜çš„çº¦æŸLLMç­–ç•¥ï¼Œç›´åˆ°LLMå‚æ•°åŒ–é—´éš™ã€‚é€šè¿‡åœ¨PKU-SafeRLHFå’ŒAnthropic HH-RLHFæ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒï¼ŒéªŒè¯äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨çº¦æŸå¯¹é½é—®é¢˜ä¸­è®¡ç®—æœ€ä¼˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç­–ç•¥çš„æŒ‘æˆ˜ã€‚ç°æœ‰çš„è¿­ä»£åŸå§‹-å¯¹å¶æ–¹æ³•å¸¸å¸¸æ— æ³•æ”¶æ•›ï¼Œè€Œéè¿­ä»£çš„å¯¹å¶æ–¹æ³•åœ¨LLMå‚æ•°ç©ºé—´ä¸­æœªèƒ½è¾¾åˆ°æœ€ä¼˜ï¼Œå¯¼è‡´ç­–ç•¥æ€§èƒ½ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‹‰æ ¼æœ—æ—¥å¯¹å¶çš„è¿­ä»£æ–¹æ³•ï¼Œé€šè¿‡äº¤æ›¿æ›´æ–°LLMç­–ç•¥å’Œå¯¹å¶å˜é‡æ¥å…‹æœç°æœ‰æ–¹æ³•çš„ä¸è¶³ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨åˆ©ç”¨æ‹‰æ ¼æœ—æ—¥æœ€å¤§åŒ–çš„ä¼˜åŠ¿ï¼ŒåŒæ—¶ä¿æŒå¯¹å¶å˜é‡çš„æœ‰æ•ˆæ›´æ–°ï¼Œä»¥å®ç°æ›´å¥½çš„æ”¶æ•›æ€§å’Œæœ€ä¼˜æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œé€šè¿‡æ‹‰æ ¼æœ—æ—¥æœ€å¤§åŒ–æ›´æ–°LLMç­–ç•¥ï¼›å…¶æ¬¡ï¼Œé€šè¿‡å¯¹å¶ä¸‹é™æ›´æ–°å¯¹å¶å˜é‡ã€‚è¯¥è¿‡ç¨‹ä¸æ–­è¿­ä»£ï¼Œç›´è‡³è¾¾åˆ°æ”¶æ•›ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§æ–°çš„è¿­ä»£å¯¹å¶åŸºç¡€å¯¹é½æ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨ä¿è¯æ”¶æ•›æ€§çš„åŒæ—¶æ‰¾åˆ°æœ€ä¼˜çš„çº¦æŸLLMç­–ç•¥ã€‚è¿™ä¸ä¼ ç»Ÿçš„éè¿­ä»£å¯¹å¶æ–¹æ³•å½¢æˆé²œæ˜å¯¹æ¯”ï¼Œåè€…åœ¨å‚æ•°ç©ºé—´ä¸­æœªèƒ½è¾¾åˆ°æœ€ä¼˜ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ–¹æ³•å®ç°ä¸­ï¼Œå…³é”®å‚æ•°è®¾ç½®åŒ…æ‹¬æ‹‰æ ¼æœ—æ—¥ä¹˜å­å’Œå¯¹å¶å˜é‡çš„åˆå§‹å€¼é€‰æ‹©ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸ºåŒæ—¶è€ƒè™‘ä¸»è¦å¥–åŠ±å’Œæ¬¡è¦æ•ˆç”¨çº¦æŸï¼Œç¡®ä¿åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­å¹³è¡¡ä¸¤è€…çš„å½±å“ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨PKU-SafeRLHFå’ŒAnthropic HH-RLHFæ•°æ®é›†ä¸Šæ˜¾è‘—æå‡äº†ç­–ç•¥çš„æœ€ä¼˜æ€§ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨ä¸»è¦å¥–åŠ±å’Œæ¬¡è¦æ•ˆç”¨çº¦æŸä¸‹ï¼Œç­–ç•¥çš„æ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æ™ºèƒ½å¯¹è¯ç³»ç»Ÿå’Œå¼ºåŒ–å­¦ä¹ ç­‰ã€‚é€šè¿‡ä¼˜åŒ–å¤§å‹è¯­è¨€æ¨¡å‹çš„ç­–ç•¥ï¼Œèƒ½å¤Ÿåœ¨æ»¡è¶³ç‰¹å®šçº¦æŸçš„æƒ…å†µä¸‹æå‡æ¨¡å‹çš„æ€§èƒ½ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½ä¼šæ¨åŠ¨æ›´å¤šé¢†åŸŸçš„æ™ºèƒ½ç³»ç»Ÿå¼€å‘ï¼Œæå‡å…¶åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We study the problem of computing an optimal large language model (LLM) policy for the constrained alignment problem, where the goal is to maximize a primary reward objective while satisfying constraints on secondary utilities. Despite the popularity of Lagrangian-based LLM policy search in constrained alignment, iterative primal-dual methods often fail to converge, and non-iterative dual-based methods do not achieve optimality in the LLM parameter space. To address these challenges, we employ Lagrangian duality to develop an iterative dual-based alignment method that alternates between updating the LLM policy via Lagrangian maximization and updating the dual variable via dual descent. In theory, we characterize the primal-dual gap between the primal value in the distribution space and the dual value in the LLM parameter space. We further quantify the optimality gap of the learned LLM policies at near-optimal dual variables with respect to both the objective and the constraint functions. These results prove that dual-based alignment methods can find an optimal constrained LLM policy, up to an LLM parametrization gap. We demonstrate the effectiveness and merits of our approach through extensive experiments conducted on the PKU-SafeRLHF and Anthropic HH-RLHF datasets.

