---
layout: default
title: Multimodal Federated Learning With Missing Modalities through Feature Imputation Network
---

# Multimodal Federated Learning With Missing Modalities through Feature Imputation Network

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20232" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.20232v1</a>
  <a href="https://arxiv.org/pdf/2505.20232.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20232v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20232v1', 'Multimodal Federated Learning With Missing Modalities through Feature Imputation Network')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Pranav Poudel, Aavash Chhetri, Prashnna Gyawali, Georgios Leontidis, Binod Bhattarai

**åˆ†ç±»**: cs.LG, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-26

**å¤‡æ³¨**: MIUA 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/bhattarailab/FedFeatGen)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè½»é‡çº§ç‰¹å¾ç¿»è¯‘ç½‘ç»œä»¥è§£å†³å¤šæ¨¡æ€è”é‚¦å­¦ä¹ ä¸­çš„ç¼ºå¤±æ¨¡æ€é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€è”é‚¦å­¦ä¹ ` `ç¼ºå¤±æ¨¡æ€` `ç‰¹å¾ç¿»è¯‘ç½‘ç»œ` `åŒ»ç–—æ•°æ®` `æ¨¡å‹è®­ç»ƒ` `æ€§èƒ½æå‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€è”é‚¦å­¦ä¹ æ–¹æ³•åœ¨åŒ»ç–—é¢†åŸŸé¢ä¸´ç¼ºå¤±æ¨¡æ€é—®é¢˜ï¼Œå½±å“æ¨¡å‹çš„æœ‰æ•ˆæ€§å’Œå‡†ç¡®æ€§ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§è½»é‡çº§çš„ç‰¹å¾ç¿»è¯‘ç½‘ç»œï¼Œé€šè¿‡é‡å»ºç¼ºå¤±æ¨¡æ€çš„ç“¶é¢ˆç‰¹å¾æ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚
3. åœ¨MIMIC-CXRã€NIH Open-Iå’ŒCheXpertä¸‰ä¸ªæ•°æ®é›†ä¸Šï¼Œå®éªŒç»“æœæ˜¾ç¤ºè¯¥æ–¹æ³•åœ¨å¤šç§è®¾ç½®ä¸‹å‡ä¼˜äºç°æœ‰åŸºçº¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€è”é‚¦å­¦ä¹ åœ¨åŒ»ç–—é¢†åŸŸå…·æœ‰é‡è¦æ½œåŠ›ï¼Œèƒ½å¤Ÿåœ¨ä¸å…±äº«åŸå§‹æ•°æ®çš„æƒ…å†µä¸‹ï¼ŒååŒè®­ç»ƒæ¥è‡ªå¤šä¸ªæ¥æºçš„æ¨¡å‹ã€‚ç„¶è€Œï¼Œç”±äºä¸´åºŠå®è·µçš„å·®å¼‚ã€æˆæœ¬å’Œå¯åŠæ€§é™åˆ¶ã€å›é¡¾æ€§æ•°æ®æ”¶é›†ã€éšç§é—®é¢˜ä»¥åŠå¶å‘çš„æŠ€æœ¯æˆ–äººä¸ºé”™è¯¯ï¼Œç¼ºå¤±æ¨¡æ€é—®é¢˜ä¸¥é‡å½±å“äº†æ¨¡å‹è®­ç»ƒã€‚ä»¥å¾€çš„æ–¹æ³•é€šå¸¸ä¾èµ–äºå…¬å¼€çš„çœŸå®æ•°æ®é›†æˆ–åˆæˆæ•°æ®æ¥å¼¥è¡¥ç¼ºå¤±æ¨¡æ€ï¼Œä½†è·å–æ¯ç§ç–¾ç—…çš„çœŸå®æ•°æ®é›†å¹¶ä¸ç°å®ï¼Œè€Œè®­ç»ƒç”Ÿæˆæ¨¡å‹åˆæˆç¼ºå¤±æ¨¡æ€åˆ™è®¡ç®—æˆæœ¬é«˜ä¸”å®¹æ˜“å‡ºé”™ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„è½»é‡çº§ä½ç»´ç‰¹å¾ç¿»è¯‘å™¨ï¼Œä»¥é‡å»ºç¼ºå¤±æ¨¡æ€çš„ç“¶é¢ˆç‰¹å¾ã€‚æˆ‘ä»¬åœ¨ä¸‰ä¸ªä¸åŒçš„æ•°æ®é›†ï¼ˆMIMIC-CXRã€NIH Open-I å’Œ CheXpertï¼‰ä¸Šè¿›è¡Œäº†å®éªŒï¼Œç»“æœè¡¨æ˜åœ¨åŒè´¨å’Œå¼‚è´¨è®¾ç½®ä¸‹å‡æ˜¾è‘—æå‡äº†ç«äº‰åŸºçº¿çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€è”é‚¦å­¦ä¹ ä¸­ç”±äºç¼ºå¤±æ¨¡æ€å¯¼è‡´çš„æ¨¡å‹è®­ç»ƒå›°éš¾ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºçœŸå®æ•°æ®é›†æˆ–åˆæˆæ•°æ®ï¼Œè·å–çœŸå®æ•°æ®é›†ä¸åˆ‡å®é™…ï¼Œåˆæˆæ•°æ®çš„ç”Ÿæˆåˆé¢ä¸´é«˜è®¡ç®—æˆæœ¬å’Œé”™è¯¯é£é™©ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§è½»é‡çº§çš„ç‰¹å¾ç¿»è¯‘ç½‘ç»œï¼Œæ—¨åœ¨é€šè¿‡é‡å»ºç¼ºå¤±æ¨¡æ€çš„ç“¶é¢ˆç‰¹å¾æ¥æé«˜æ¨¡å‹çš„è®­ç»ƒæ•ˆæœã€‚è¯¥æ–¹æ³•é€šè¿‡ä½ç»´ç‰¹å¾çš„è½¬æ¢ï¼Œé™ä½äº†è®¡ç®—å¤æ‚åº¦å¹¶æé«˜äº†é‡å»ºçš„å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ç‰¹å¾æå–ã€ç‰¹å¾ç¿»è¯‘å’Œæ¨¡å‹è®­ç»ƒä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚ç‰¹å¾æå–æ¨¡å—ä»è¾“å…¥æ•°æ®ä¸­æå–å…³é”®ç‰¹å¾ï¼Œç‰¹å¾ç¿»è¯‘æ¨¡å—è´Ÿè´£é‡å»ºç¼ºå¤±æ¨¡æ€çš„ç‰¹å¾ï¼Œæœ€åé€šè¿‡è®­ç»ƒæ¨¡å‹è¿›è¡Œæ€§èƒ½è¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†è½»é‡çº§çš„ç‰¹å¾ç¿»è¯‘ç½‘ç»œï¼Œèƒ½å¤Ÿæœ‰æ•ˆé‡å»ºç¼ºå¤±æ¨¡æ€çš„ç‰¹å¾ï¼Œä¸ä¼ ç»Ÿä¾èµ–äºçœŸå®æ•°æ®æˆ–å¤æ‚ç”Ÿæˆæ¨¡å‹çš„æ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—æˆæœ¬å’Œé”™è¯¯ç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œç»“æ„ä¸Šï¼Œé‡‡ç”¨äº†ä½ç»´ç‰¹å¾è¡¨ç¤ºä»¥å‡å°‘è®¡ç®—è´Ÿæ‹…ï¼Œå¹¶è®¾è®¡äº†é€‚åº”åŒ»ç–—æ•°æ®ç‰¹æ€§çš„æŸå¤±å‡½æ•°ï¼Œä»¥ç¡®ä¿é‡å»ºç‰¹å¾çš„å‡†ç¡®æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡æå‡ºçš„æ–¹æ³•åœ¨MIMIC-CXRã€NIH Open-Iå’ŒCheXpertæ•°æ®é›†ä¸Šå‡æ˜¾è‘—æå‡äº†æ¨¡å‹æ€§èƒ½ï¼Œç›¸è¾ƒäºç«äº‰åŸºçº¿ï¼Œæ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°10%ä»¥ä¸Šï¼ŒéªŒè¯äº†ç‰¹å¾ç¿»è¯‘ç½‘ç»œçš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŒ»ç–—å½±åƒåˆ†æã€ä¸´åºŠå†³ç­–æ”¯æŒç³»ç»Ÿå’Œä¸ªæ€§åŒ–åŒ»ç–—ç­‰ã€‚é€šè¿‡è§£å†³å¤šæ¨¡æ€æ•°æ®ç¼ºå¤±é—®é¢˜ï¼Œèƒ½å¤Ÿæé«˜æ¨¡å‹çš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ï¼Œè¿›è€Œæ¨åŠ¨åŒ»ç–—é¢†åŸŸçš„æ™ºèƒ½åŒ–å‘å±•ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal federated learning holds immense potential for collaboratively training models from multiple sources without sharing raw data, addressing both data scarcity and privacy concerns, two key challenges in healthcare. A major challenge in training multimodal federated models in healthcare is the presence of missing modalities due to multiple reasons, including variations in clinical practice, cost and accessibility constraints, retrospective data collection, privacy concerns, and occasional technical or human errors. Previous methods typically rely on publicly available real datasets or synthetic data to compensate for missing modalities. However, obtaining real datasets for every disease is impractical, and training generative models to synthesize missing modalities is computationally expensive and prone to errors due to the high dimensionality of medical data. In this paper, we propose a novel, lightweight, low-dimensional feature translator to reconstruct bottleneck features of the missing modalities. Our experiments on three different datasets (MIMIC-CXR, NIH Open-I, and CheXpert), in both homogeneous and heterogeneous settings consistently improve the performance of competitive baselines. The code and implementation details are available at: https://github.com/bhattarailab/FedFeatGen

