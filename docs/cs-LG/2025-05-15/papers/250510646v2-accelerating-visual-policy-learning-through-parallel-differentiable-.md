---
layout: default
title: Accelerating Visual-Policy Learning through Parallel Differentiable Simulation
---

# Accelerating Visual-Policy Learning through Parallel Differentiable Simulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.10646" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.10646v2</a>
  <a href="https://arxiv.org/pdf/2505.10646.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.10646v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.10646v2', 'Accelerating Visual-Policy Learning through Parallel Differentiable Simulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Haoxiang You, Yilang Liu, Ian Abraham

**åˆ†ç±»**: cs.LG, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-05-15 (æ›´æ–°: 2025-11-10)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§é«˜æ•ˆç®—æ³•ä»¥åŠ é€Ÿè§†è§‰ç­–ç•¥å­¦ä¹ **

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `è§†è§‰ç­–ç•¥å­¦ä¹ ` `å¯å¾®åˆ†ä»¿çœŸ` `ç­–ç•¥æ¢¯åº¦` `æœºå™¨äººæ§åˆ¶` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†è§‰ç­–ç•¥å­¦ä¹ æ–¹æ³•åœ¨è®¡ç®—æ•ˆç‡å’Œä¼˜åŒ–ç¨³å®šæ€§æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´è®­ç»ƒæ—¶é—´è¿‡é•¿ã€‚
2. æœ¬æ–‡æå‡ºçš„ç®—æ³•é€šè¿‡è§£è€¦æ¸²æŸ“è¿‡ç¨‹ä¸è®¡ç®—å›¾ï¼Œåˆ©ç”¨å¯å¾®åˆ†ä»¿çœŸå’Œä¸€é˜¶è§£æç­–ç•¥æ¢¯åº¦ï¼Œæé«˜äº†è®¡ç®—æ•ˆç‡ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¤æ‚ä»»åŠ¡ä¸Šæ˜¾è‘—æå‡äº†æœ€ç»ˆå›æŠ¥ï¼Œå¹¶å‡å°‘äº†è®­ç»ƒæ—¶é—´ï¼Œè¡¨ç°ä¼˜äºæ‰€æœ‰åŸºçº¿æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§è®¡ç®—æ•ˆç‡é«˜çš„è§†è§‰ç­–ç•¥å­¦ä¹ ç®—æ³•ï¼Œè¯¥ç®—æ³•åˆ©ç”¨å¯å¾®åˆ†ä»¿çœŸå’Œä¸€é˜¶è§£æç­–ç•¥æ¢¯åº¦ã€‚æˆ‘ä»¬çš„æ–¹æ³•å°†æ¸²æŸ“è¿‡ç¨‹ä¸è®¡ç®—å›¾è§£è€¦ï¼Œèƒ½å¤Ÿæ— ç¼é›†æˆç°æœ‰çš„å¯å¾®åˆ†ä»¿çœŸç”Ÿæ€ç³»ç»Ÿï¼Œè€Œæ— éœ€ä¸“é—¨çš„å¯å¾®åˆ†æ¸²æŸ“è½¯ä»¶ã€‚è¿™ç§è§£è€¦ä¸ä»…å‡å°‘äº†è®¡ç®—å’Œå†…å­˜å¼€é”€ï¼Œè¿˜æœ‰æ•ˆå‡å°äº†ç­–ç•¥æ¢¯åº¦èŒƒæ•°ï¼Œä»è€Œå®ç°æ›´ç¨³å®šå’Œæ›´å¹³æ»‘çš„ä¼˜åŒ–ã€‚æˆ‘ä»¬åœ¨ç°ä»£GPUåŠ é€Ÿä»¿çœŸä¸‹å¯¹æ ‡å‡†è§†è§‰æ§åˆ¶åŸºå‡†è¿›è¡Œäº†è¯„ä¼°ï¼Œå®éªŒè¡¨æ˜æˆ‘ä»¬çš„æ–¹æ³•æ˜¾è‘—å‡å°‘äº†è®­ç»ƒæ—¶é—´ï¼Œå¹¶åœ¨æœ€ç»ˆå›æŠ¥æ–¹é¢æŒç»­è¶…è¶Šæ‰€æœ‰åŸºçº¿æ–¹æ³•ã€‚ç‰¹åˆ«æ˜¯åœ¨å¤æ‚ä»»åŠ¡å¦‚äººå½¢æœºå™¨äººè¡Œèµ°ä¸­ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æœ€ç»ˆå›æŠ¥ä¸Šå®ç°äº†4å€çš„æå‡ï¼Œå¹¶åœ¨å•ä¸ªGPUä¸ŠæˆåŠŸå­¦ä¹ åˆ°äººå½¢æœºå™¨äººè·‘æ­¥ç­–ç•¥ï¼Œè€—æ—¶ä»…4å°æ—¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³è§†è§‰ç­–ç•¥å­¦ä¹ ä¸­çš„è®¡ç®—æ•ˆç‡ä½å’Œä¼˜åŒ–ä¸ç¨³å®šçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦ä¸“é—¨çš„å¯å¾®åˆ†æ¸²æŸ“è½¯ä»¶ï¼Œå¯¼è‡´è®¡ç®—å’Œå†…å­˜å¼€é”€è¾ƒå¤§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡å°†æ¸²æŸ“è¿‡ç¨‹ä¸è®¡ç®—å›¾è§£è€¦ï¼Œå…è®¸ä¸ç°æœ‰çš„å¯å¾®åˆ†ä»¿çœŸç”Ÿæ€ç³»ç»Ÿæ— ç¼é›†æˆï¼Œä»è€Œæé«˜äº†è®¡ç®—æ•ˆç‡å’Œä¼˜åŒ–ç¨³å®šæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¯å¾®åˆ†ä»¿çœŸæ¨¡å—å’Œç­–ç•¥ä¼˜åŒ–æ¨¡å—ã€‚å¯å¾®åˆ†ä»¿çœŸæ¨¡å—è´Ÿè´£ç¯å¢ƒçš„æ¨¡æ‹Ÿï¼Œè€Œç­–ç•¥ä¼˜åŒ–æ¨¡å—åˆ™åŸºäºä¸€é˜¶è§£æç­–ç•¥æ¢¯åº¦è¿›è¡Œä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºè§£è€¦æ¸²æŸ“è¿‡ç¨‹ä¸è®¡ç®—å›¾ï¼Œè¿™ä¸€è®¾è®¡ä½¿å¾—æˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿåœ¨ä¸ä¾èµ–ä¸“é—¨è½¯ä»¶çš„æƒ…å†µä¸‹ï¼Œæ˜¾è‘—é™ä½è®¡ç®—å’Œå†…å­˜å¼€é”€ï¼ŒåŒæ—¶æé«˜ä¼˜åŒ–çš„ç¨³å®šæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€é˜¶è§£æç­–ç•¥æ¢¯åº¦ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸ºé€‚åº”å¯å¾®åˆ†ä»¿çœŸè¾“å‡ºï¼Œç½‘ç»œç»“æ„åˆ™åŸºäºç°ä»£æ·±åº¦å­¦ä¹ æ¡†æ¶è¿›è¡Œä¼˜åŒ–ï¼Œç¡®ä¿é«˜æ•ˆçš„è®­ç»ƒè¿‡ç¨‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¤æ‚ä»»åŠ¡å¦‚äººå½¢æœºå™¨äººè¡Œèµ°ä¸­å®ç°äº†4å€çš„æœ€ç»ˆå›æŠ¥æå‡ï¼Œå¹¶åœ¨å•ä¸ªGPUä¸ŠæˆåŠŸå­¦ä¹ åˆ°è·‘æ­¥ç­–ç•¥ï¼Œè®­ç»ƒæ—¶é—´ä»…éœ€4å°æ—¶ã€‚è¿™ä¸€æ€§èƒ½æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿æ–¹æ³•ï¼Œå±•ç¤ºäº†è¯¥ç®—æ³•çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæ§åˆ¶ã€è‡ªåŠ¨é©¾é©¶ã€è™šæ‹Ÿç°å®ç­‰éœ€è¦å®æ—¶å†³ç­–çš„åœºæ™¯ã€‚é€šè¿‡æé«˜è§†è§‰ç­–ç•¥å­¦ä¹ çš„æ•ˆç‡ï¼Œèƒ½å¤ŸåŠ é€Ÿæ™ºèƒ½ä½“çš„è®­ç»ƒè¿‡ç¨‹ï¼Œé™ä½å¼€å‘æˆæœ¬ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å®é™…åº”ç”¨å’Œå‘å±•ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›åœ¨æ›´å¤æ‚çš„ç¯å¢ƒä¸­å®ç°æ›´é«˜æ•ˆçš„å­¦ä¹ å’Œå†³ç­–èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In this work, we propose a computationally efficient algorithm for visual policy learning that leverages differentiable simulation and first-order analytical policy gradients. Our approach decouple the rendering process from the computation graph, enabling seamless integration with existing differentiable simulation ecosystems without the need for specialized differentiable rendering software. This decoupling not only reduces computational and memory overhead but also effectively attenuates the policy gradient norm, leading to more stable and smoother optimization. We evaluate our method on standard visual control benchmarks using modern GPU-accelerated simulation. Experiments show that our approach significantly reduces wall-clock training time and consistently outperforms all baseline methods in terms of final returns. Notably, on complex tasks such as humanoid locomotion, our method achieves a $4\times$ improvement in final return, and successfully learns a humanoid running policy within 4 hours on a single GPU.

