---
layout: default
title: Information Structure in Mappings: An Approach to Learning, Representation, and Generalisation
---

# Information Structure in Mappings: An Approach to Learning, Representation, and Generalisation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.23960" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.23960v1</a>
  <a href="https://arxiv.org/pdf/2505.23960.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.23960v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.23960v1', 'Information Structure in Mappings: An Approach to Learning, Representation, and Generalisation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Henry Conklin

**åˆ†ç±»**: cs.LG, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-29

**å¤‡æ³¨**: PhD Thesis, 204 pages; entropy estimation discussed from p.94

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå®šé‡æ–¹æ³•ä»¥è§£æç¥ç»ç½‘ç»œçš„è¡¨ç¤ºç»“æ„**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç¥ç»ç½‘ç»œ` `è¡¨ç¤ºå­¦ä¹ ` `ä¿¡æ¯è®º` `æ³›åŒ–èƒ½åŠ›` `æ·±åº¦å­¦ä¹ ` `å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ` `è¯­è¨€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ç¼ºä¹ç»Ÿä¸€çš„ç¬¦å·å’Œå¯é çš„æè¿°æ‰‹æ®µï¼Œæ— æ³•æœ‰æ•ˆåˆ†æç¥ç»ç½‘ç»œçš„è¡¨ç¤ºç»“æ„åŠå…¶æ¼”å˜è¿‡ç¨‹ã€‚
2. è®ºæ–‡æå‡ºå®šé‡æ–¹æ³•ï¼Œé€šè¿‡è¯†åˆ«æ˜ å°„ä¸­çš„ç»“æ„åŸè¯­ï¼Œåˆ†ææ·±åº¦å­¦ä¹ æ¨¡å‹çš„ä¿¡æ¯è¡¨ç¤ºåŠå…¶æ³›åŒ–èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ­ç¤ºäº†å¤§å‹åˆ†å¸ƒå¼è®¤çŸ¥æ¨¡å‹çš„å­¦ä¹ æœºåˆ¶ï¼Œå¹¶å±•ç¤ºäº†è¯­è¨€ç»“æ„ä¸ç¥ç»ç½‘ç»œæ€§èƒ½ä¹‹é—´çš„ç›¸ä¼¼æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡å¤§å‹ç¥ç»ç½‘ç»œå–å¾—äº†æ˜¾è‘—æˆåŠŸï¼Œä½†æˆ‘ä»¬ä»ç¼ºä¹ç»Ÿä¸€çš„ç¬¦å·æ¥æ€è€ƒå’Œæè¿°å…¶è¡¨ç¤ºç©ºé—´ã€‚æœ¬æ–‡æå‡ºå®šé‡æ–¹æ³•ï¼Œè¯†åˆ«æ˜ å°„ä¸­çš„ç³»ç»Ÿç»“æ„ï¼Œå¸®åŠ©ç†è§£æ·±åº¦å­¦ä¹ æ¨¡å‹å¦‚ä½•å­¦ä¹ ä¿¡æ¯è¡¨ç¤ºã€å“ªäº›ç»“æ„ä¿ƒè¿›æ³›åŒ–ï¼Œä»¥åŠè®¾è®¡å†³ç­–å¦‚ä½•å½±å“è¿™äº›ç»“æ„çš„å‡ºç°ã€‚é€šè¿‡è¯†åˆ«æ˜ å°„ä¸­çš„ç»“æ„åŸè¯­åŠå…¶ä¿¡æ¯è®ºé‡åŒ–ï¼Œåˆ†æå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ æ¨¡å‹ã€å•ä»»åŠ¡è®­ç»ƒçš„åºåˆ—åˆ°åºåˆ—æ¨¡å‹å’Œå¤§å‹è¯­è¨€æ¨¡å‹çš„å­¦ä¹ ã€ç»“æ„å’Œæ³›åŒ–ã€‚è¿˜æå‡ºäº†ä¸€ç§æ–°é¢–ä¸”é«˜æ•ˆçš„å‘é‡ç©ºé—´ç†µä¼°è®¡æ–¹æ³•ï¼Œé€‚ç”¨äºä»100ä¸‡åˆ°120äº¿å‚æ•°çš„æ¨¡å‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç¼ºä¹ç»Ÿä¸€ç¬¦å·å’Œæ–¹æ³•æ¥æè¿°ç¥ç»ç½‘ç»œè¡¨ç¤ºç©ºé—´ç»“æ„çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æ— æ³•æœ‰æ•ˆæ•æ‰è¡¨ç¤ºçš„ç³»ç»Ÿæ€§å’Œæ¼”å˜è¿‡ç¨‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥å®šé‡æ–¹æ³•ï¼Œè¯†åˆ«æ˜ å°„ä¸­çš„ç»“æ„åŸè¯­ï¼Œå¹¶è¿›è¡Œä¿¡æ¯è®ºé‡åŒ–ï¼Œä»è€Œåˆ†ææ·±åº¦å­¦ä¹ æ¨¡å‹çš„å­¦ä¹ è¿‡ç¨‹å’Œæ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š1) ç»“æ„åŸè¯­è¯†åˆ«ï¼›2) ä¿¡æ¯è®ºé‡åŒ–ï¼›3) å­¦ä¹ ä¸æ³›åŒ–åˆ†æã€‚é€šè¿‡è¿™äº›æ¨¡å—ï¼Œèƒ½å¤Ÿç³»ç»Ÿåœ°åˆ†æä¸åŒç±»å‹çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§æ–°çš„å‘é‡ç©ºé—´ç†µä¼°è®¡æ–¹æ³•ï¼Œä½¿å¾—åˆ†æå¯ä»¥æ‰©å±•åˆ°ä»100ä¸‡åˆ°120äº¿å‚æ•°çš„æ¨¡å‹ï¼Œæ˜¾è‘—æå‡äº†åˆ†æçš„é€‚ç”¨æ€§å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œè®ºæ–‡é‡‡ç”¨äº†é€‚åº”æ€§è°ƒæ•´çš„ç­–ç•¥ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸Šç»“åˆäº†ä¿¡æ¯è®ºæŒ‡æ ‡ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­èƒ½å¤Ÿæœ‰æ•ˆæ•æ‰ç»“æ„ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨åˆ†æå¤§å‹è¯­è¨€æ¨¡å‹å’Œå¼ºåŒ–å­¦ä¹ æ¨¡å‹çš„è¡¨ç¤ºç»“æ„æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œèƒ½å¤Ÿæ­ç¤ºå‡ºä¸äººç±»è®¤çŸ¥ç³»ç»Ÿçš„ç›¸ä¼¼æ€§ï¼Œæå‡äº†å¯¹æ¨¡å‹å­¦ä¹ æœºåˆ¶çš„ç†è§£ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ·±åº¦å­¦ä¹ æ¨¡å‹çš„è®¾è®¡ä¼˜åŒ–ã€è‡ªç„¶è¯­è¨€å¤„ç†å’Œå¤šæ™ºèƒ½ä½“ç³»ç»Ÿç­‰ã€‚é€šè¿‡ç†è§£æ¨¡å‹çš„è¡¨ç¤ºç»“æ„ï¼Œå¯ä»¥æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œæ€§èƒ½ï¼Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿå‘æ›´å¤æ‚ä»»åŠ¡çš„æ‰©å±•ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Despite the remarkable success of large large-scale neural networks, we still lack unified notation for thinking about and describing their representational spaces. We lack methods to reliably describe how their representations are structured, how that structure emerges over training, and what kinds of structures are desirable. This thesis introduces quantitative methods for identifying systematic structure in a mapping between spaces, and leverages them to understand how deep-learning models learn to represent information, what representational structures drive generalisation, and how design decisions condition the structures that emerge. To do this I identify structural primitives present in a mapping, along with information theoretic quantifications of each. These allow us to analyse learning, structure, and generalisation across multi-agent reinforcement learning models, sequence-to-sequence models trained on a single task, and Large Language Models. I also introduce a novel, performant, approach to estimating the entropy of vector space, that allows this analysis to be applied to models ranging in size from 1 million to 12 billion parameters.
>   The experiments here work to shed light on how large-scale distributed models of cognition learn, while allowing us to draw parallels between those systems and their human analogs. They show how the structures of language and the constraints that give rise to them in many ways parallel the kinds of structures that drive performance of contemporary neural networks.

