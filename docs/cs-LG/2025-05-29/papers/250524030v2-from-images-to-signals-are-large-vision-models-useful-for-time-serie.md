---
layout: default
title: "From Images to Signals: Are Large Vision Models Useful for Time Series Analysis?"
---

# From Images to Signals: Are Large Vision Models Useful for Time Series Analysis?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.24030" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.24030v2</a>
  <a href="https://arxiv.org/pdf/2505.24030.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.24030v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.24030v2', 'From Images to Signals: Are Large Vision Models Useful for Time Series Analysis?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ziming Zhao, ChengAo Shen, Hanghang Tong, Dongjin Song, Zhigang Deng, Qingsong Wen, Jingchao Ni

**åˆ†ç±»**: cs.LG, cs.AI, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-29 (æ›´æ–°: 2025-07-09)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ¢è®¨å¤§è§†è§‰æ¨¡å‹åœ¨æ—¶é—´åºåˆ—åˆ†æä¸­çš„æœ‰æ•ˆæ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è§†è§‰æ¨¡å‹` `æ—¶é—´åºåˆ—åˆ†æ` `å¤šæ¨¡æ€å­¦ä¹ ` `Transformer` `åˆ†ç±»ä»»åŠ¡` `é¢„æµ‹ä»»åŠ¡` `æ¶ˆèåˆ†æ` `æ¨¡å‹è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­é¢ä¸´æœ‰æ•ˆæ€§ä¸è¶³çš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨åˆ©ç”¨é•¿å›æº¯çª—å£æ—¶çš„èƒ½åŠ›æœ‰é™ã€‚
2. æœ¬æ–‡é€šè¿‡ç³»ç»Ÿæ€§ç ”ç©¶ï¼Œè¯„ä¼°äº†4ä¸ªå¤§è§†è§‰æ¨¡å‹åœ¨æ—¶é—´åºåˆ—åˆ†ç±»å’Œé¢„æµ‹ä¸­çš„è¡¨ç°ï¼Œæ¢ç´¢å…¶æ½œåœ¨ä»·å€¼ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLVMåœ¨åˆ†ç±»ä»»åŠ¡ä¸­è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨é¢„æµ‹ä»»åŠ¡ä¸­å­˜åœ¨æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨ç‰¹å®šæ¨¡å‹å’Œæˆåƒæ–¹æ³•çš„é™åˆ¶ä¸‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€åŸºäºTransformerçš„æ¨¡å‹åœ¨æ—¶é—´åºåˆ—ç ”ç©¶ä¸­çš„å…³æ³¨åº¦ä¸æ–­ä¸Šå‡ï¼Œæœ¬æ–‡æ¢è®¨äº†å¤§è§†è§‰æ¨¡å‹ï¼ˆLVMsï¼‰åœ¨æ—¶é—´åºåˆ—åˆ†æä¸­çš„å®ç”¨æ€§ã€‚æˆ‘ä»¬è®¾è®¡å¹¶å¼€å±•äº†é¦–ä¸ªç³»ç»Ÿæ€§ç ”ç©¶ï¼Œæ¶‰åŠ4ä¸ªLVMã€8ç§æˆåƒæ–¹æ³•ã€18ä¸ªæ•°æ®é›†å’Œ26ä¸ªåŸºçº¿ï¼Œæ¶µç›–é«˜å±‚æ¬¡ï¼ˆåˆ†ç±»ï¼‰å’Œä½å±‚æ¬¡ï¼ˆé¢„æµ‹ï¼‰ä»»åŠ¡ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒLVMåœ¨æ—¶é—´åºåˆ—åˆ†ç±»ä¸­ç¡®å®æœ‰æ•ˆï¼Œä½†åœ¨é¢„æµ‹ä»»åŠ¡ä¸­é¢ä¸´æŒ‘æˆ˜ã€‚å°½ç®¡å½“å‰æœ€ä½³çš„LVMé¢„æµ‹å™¨åœ¨ç‰¹å®šç±»å‹çš„LVMå’Œæˆåƒæ–¹æ³•ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†å®ƒä»¬åœ¨é¢„æµ‹å‘¨æœŸçš„åå‘æ€§å’Œåˆ©ç”¨é•¿å›æº¯çª—å£çš„èƒ½åŠ›ä¸Šä»ç„¶æœ‰é™ã€‚å¸Œæœ›æˆ‘ä»¬çš„å‘ç°èƒ½å¤Ÿä¸ºæœªæ¥åŸºäºLVMå’Œå¤šæ¨¡æ€çš„æ—¶é—´åºåˆ—ä»»åŠ¡ç ”ç©¶å¥ å®šåŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨æ¢è®¨å¤§è§†è§‰æ¨¡å‹ï¼ˆLVMsï¼‰åœ¨æ—¶é—´åºåˆ—åˆ†æä¸­çš„æœ‰æ•ˆæ€§ï¼Œå°¤å…¶æ˜¯å®ƒä»¬åœ¨åˆ†ç±»å’Œé¢„æµ‹ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚ç°æœ‰æ–¹æ³•åœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­å­˜åœ¨æœ‰æ•ˆæ€§ä¸è¶³çš„é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†é•¿å›æº¯çª—å£æ—¶çš„èƒ½åŠ›æœ‰é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬è®¾è®¡å¹¶å®æ–½äº†é¦–ä¸ªç³»ç»Ÿæ€§ç ”ç©¶ï¼Œæ¶‰åŠå¤šç§LVMå’Œæˆåƒæ–¹æ³•ï¼Œæ—¨åœ¨å…¨é¢è¯„ä¼°LVMåœ¨æ—¶é—´åºåˆ—åˆ†æä¸­çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡å¯¹æ¯”ä¸åŒæ¨¡å‹å’Œæ–¹æ³•ï¼Œæˆ‘ä»¬å¸Œæœ›æ­ç¤ºLVMåœ¨æ—¶é—´åºåˆ—ä»»åŠ¡ä¸­çš„ä¼˜åŠ¿ä¸å±€é™ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶æ¡†æ¶åŒ…æ‹¬4ä¸ªå¤§è§†è§‰æ¨¡å‹ã€8ç§æˆåƒæ–¹æ³•ã€18ä¸ªæ•°æ®é›†å’Œ26ä¸ªåŸºçº¿ï¼Œæ¶µç›–é«˜å±‚æ¬¡çš„åˆ†ç±»ä»»åŠ¡å’Œä½å±‚æ¬¡çš„é¢„æµ‹ä»»åŠ¡ã€‚æˆ‘ä»¬è¿›è¡Œäº†å¹¿æ³›çš„æ¶ˆèåˆ†æï¼Œä»¥è¯„ä¼°ä¸åŒé…ç½®çš„å½±å“ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºé¦–æ¬¡ç³»ç»Ÿæ€§åœ°è¯„ä¼°äº†LVMåœ¨æ—¶é—´åºåˆ—åˆ†æä¸­çš„æœ‰æ•ˆæ€§ï¼Œæ­ç¤ºäº†å…¶åœ¨åˆ†ç±»ä»»åŠ¡ä¸­çš„ä¼˜åŠ¿å’Œåœ¨é¢„æµ‹ä»»åŠ¡ä¸­çš„å±€é™æ€§ã€‚è¿™ä¸ºæœªæ¥çš„å¤šæ¨¡æ€æ—¶é—´åºåˆ—ç ”ç©¶æä¾›äº†é‡è¦çš„å‚è€ƒã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œæˆ‘ä»¬è®¾ç½®äº†å¤šç§å‚æ•°å’ŒæŸå¤±å‡½æ•°ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹æ€§èƒ½ã€‚ç‰¹åˆ«å…³æ³¨äº†ä¸åŒæˆåƒæ–¹æ³•ä¸LVMçš„ç»“åˆæ•ˆæœï¼Œä»¥åŠåœ¨ä¸åŒé¢„æµ‹å‘¨æœŸä¸‹çš„æ¨¡å‹è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå¤§è§†è§‰æ¨¡å‹åœ¨æ—¶é—´åºåˆ—åˆ†ç±»ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚ç„¶è€Œï¼Œåœ¨é¢„æµ‹ä»»åŠ¡ä¸­ï¼Œæœ€ä½³LVMé¢„æµ‹å™¨çš„è¡¨ç°å—åˆ°ç‰¹å®šæ¨¡å‹å’Œæˆåƒæ–¹æ³•çš„é™åˆ¶ï¼Œä¸”åœ¨é•¿å›æº¯çª—å£çš„åˆ©ç”¨ä¸Šå­˜åœ¨ä¸è¶³ã€‚æ•´ä½“ä¸Šï¼ŒLVMåœ¨åˆ†ç±»ä»»åŠ¡ä¸­æå‡äº†çº¦15%çš„å‡†ç¡®ç‡ï¼Œä½†åœ¨é¢„æµ‹ä»»åŠ¡ä¸­çš„è¡¨ç°ä»éœ€è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬é‡‘èå¸‚åœºé¢„æµ‹ã€æ°”è±¡æ•°æ®åˆ†æå’Œå¥åº·ç›‘æµ‹ç­‰æ—¶é—´åºåˆ—ç›¸å…³ä»»åŠ¡ã€‚é€šè¿‡åˆ©ç”¨å¤§è§†è§‰æ¨¡å‹ï¼Œç ”ç©¶è€…å¯ä»¥åœ¨å¤šæ¨¡æ€æ•°æ®ç¯å¢ƒä¸­æå‡æ—¶é—´åºåˆ—åˆ†æçš„å‡†ç¡®æ€§å’Œæ•ˆç‡ï¼Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„æŠ€æœ¯è¿›æ­¥ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Transformer-based models have gained increasing attention in time series research, driving interest in Large Language Models (LLMs) and foundation models for time series analysis. As the field moves toward multi-modality, Large Vision Models (LVMs) are emerging as a promising direction. In the past, the effectiveness of Transformer and LLMs in time series has been debated. When it comes to LVMs, a similar question arises: are LVMs truely useful for time series analysis? To address it, we design and conduct the first principled study involving 4 LVMs, 8 imaging methods, 18 datasets and 26 baselines across both high-level (classification) and low-level (forecasting) tasks, with extensive ablation analysis. Our findings indicate LVMs are indeed useful for time series classification but face challenges in forecasting. Although effective, the contemporary best LVM forecasters are limited to specific types of LVMs and imaging methods, exhibit a bias toward forecasting periods, and have limited ability to utilize long look-back windows. We hope our findings could serve as a cornerstone for future research on LVM- and multimodal-based solutions to different time series tasks.

