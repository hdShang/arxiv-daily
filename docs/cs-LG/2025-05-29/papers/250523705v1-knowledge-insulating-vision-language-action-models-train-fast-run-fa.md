---
layout: default
title: Knowledge Insulating Vision-Language-Action Models: Train Fast, Run Fast, Generalize Better
---

# Knowledge Insulating Vision-Language-Action Models: Train Fast, Run Fast, Generalize Better

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.23705" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.23705v1</a>
  <a href="https://arxiv.org/pdf/2505.23705.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.23705v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.23705v1', 'Knowledge Insulating Vision-Language-Action Models: Train Fast, Run Fast, Generalize Better')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Danny Driess, Jost Tobias Springenberg, Brian Ichter, Lili Yu, Adrian Li-Bell, Karl Pertsch, Allen Z. Ren, Homer Walke, Quan Vuong, Lucy Xiaoyang Shi, Sergey Levine

**åˆ†ç±»**: cs.LG, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-05-29

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºçŸ¥è¯†éš”ç¦»æŠ€æœ¯ä»¥æå‡è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹çš„è®­ç»ƒä¸æ¨ç†æ•ˆç‡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€-åŠ¨ä½œ` `çŸ¥è¯†éš”ç¦»` `å®æ—¶æ§åˆ¶` `æ¨¡å‹è®­ç»ƒ` `è¯­ä¹‰çŸ¥è¯†è½¬ç§»`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹åœ¨å®æ—¶æ§åˆ¶ä¸­é¢ä¸´å‚æ•°åºå¤§ä¸æ¨ç†é€Ÿåº¦æ…¢çš„æŒ‘æˆ˜ï¼Œå½±å“äº†å…¶åº”ç”¨æ•ˆæœã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§çŸ¥è¯†éš”ç¦»æŠ€æœ¯ï¼Œæ—¨åœ¨ä¿æŠ¤é¢„è®­ç»ƒVLMçš„è¯­ä¹‰çŸ¥è¯†ï¼ŒåŒæ—¶æé«˜VLAæ¨¡å‹çš„è®­ç»ƒé€Ÿåº¦å’Œæ§åˆ¶èƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨çŸ¥è¯†éš”ç¦»æŠ€æœ¯çš„VLAæ¨¡å‹åœ¨è®­ç»ƒé€Ÿåº¦å’ŒçŸ¥è¯†è½¬ç§»æ–¹é¢å‡æœ‰æ˜¾è‘—æå‡ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹é€šè¿‡ç»“åˆç«¯åˆ°ç«¯å­¦ä¹ ä¸ä»å¤§è§„æ¨¡è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ä¸­è½¬ç§»è¯­ä¹‰çŸ¥è¯†ï¼Œä¸ºç‰©ç†ç³»ç»Ÿï¼ˆå¦‚æœºå™¨äººï¼‰çš„æ§åˆ¶ç­–ç•¥è®­ç»ƒæä¾›äº†å¼ºæœ‰åŠ›çš„æ–¹æ³•ã€‚ç„¶è€Œï¼Œå®æ—¶æ§åˆ¶çš„çº¦æŸä¸VLMçš„è®¾è®¡å¸¸å¸¸ç›¸æ‚–ï¼Œå°¤å…¶æ˜¯å¼ºå¤§çš„VLMé€šå¸¸å…·æœ‰æ•°åäº¿æˆ–æ•°ç™¾äº¿ä¸ªå‚æ•°ï¼Œå¯¼è‡´å®æ—¶æ¨ç†çš„éšœç¢ã€‚æœ¬æ–‡ç ”ç©¶äº†åœ¨åŒ…å«è¿ç»­æ‰©æ•£æˆ–æµåŒ¹é…åŠ¨ä½œä¸“å®¶çš„VLAæ¨¡å‹ä¸­ï¼Œç®€å•åœ°å¼•å…¥è¿™äº›ä¸“å®¶ä¼šæ˜¾è‘—å½±å“è®­ç»ƒé€Ÿåº¦å’ŒçŸ¥è¯†è½¬ç§»ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åœ¨VLAè®­ç»ƒè¿‡ç¨‹ä¸­éš”ç¦»VLMä¸»å¹²çš„æŠ€æœ¯ï¼Œä»¥ç¼“è§£è¿™ä¸€é—®é¢˜ï¼Œå¹¶è¿›è¡Œäº†å¹¿æ³›çš„è®¾è®¡é€‰æ‹©åˆ†æã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è§£å†³çš„é—®é¢˜æ˜¯å¦‚ä½•åœ¨è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ä¸­æœ‰æ•ˆåœ°å¼•å…¥è¿ç»­æ§åˆ¶æ¨¡å—è€Œä¸æŸå®³é¢„è®­ç»ƒVLMçš„çŸ¥è¯†è½¬ç§»èƒ½åŠ›ã€‚ç°æœ‰æ–¹æ³•åœ¨å¼•å…¥æ–°å‚æ•°æ—¶ï¼Œå¸¸å¸¸å¯¼è‡´è®­ç»ƒé€Ÿåº¦ä¸‹é™å’ŒçŸ¥è¯†ä¸¢å¤±ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡çŸ¥è¯†éš”ç¦»æŠ€æœ¯ï¼Œç¡®ä¿åœ¨VLAè®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒVLMä¸»å¹²çš„è¯­ä¹‰çŸ¥è¯†ä¸è¢«æ–°å¼•å…¥çš„æ¨¡å—å¹²æ‰°ï¼Œä»è€Œæé«˜è®­ç»ƒæ•ˆç‡å’Œæ§åˆ¶æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸€ä¸ªé¢„è®­ç»ƒçš„VLMä¸»å¹²å’Œä¸€ä¸ªè¿ç»­æ§åˆ¶æ¨¡å—ï¼Œåè€…é€šè¿‡çŸ¥è¯†éš”ç¦»æŠ€æœ¯ä¸ä¸»å¹²è¿›è¡Œæœ‰æ•ˆçš„äº¤äº’ã€‚è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œä¼˜åŒ–ç­–ç•¥ï¼Œä»¥ç¡®ä¿çŸ¥è¯†çš„æœ‰æ•ˆè½¬ç§»ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†çŸ¥è¯†éš”ç¦»æœºåˆ¶ï¼Œè¿™ä¸€æœºåˆ¶ä¸ä¼ ç»Ÿæ–¹æ³•çš„ç›´æ¥å‚æ•°æ·»åŠ æ–¹å¼æˆªç„¶ä¸åŒï¼Œèƒ½å¤Ÿæœ‰æ•ˆä¿æŠ¤VLMçš„çŸ¥è¯†ç»“æ„ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡çŸ¥è¯†è½¬ç§»ä¸æ§åˆ¶æ€§èƒ½ï¼ŒåŒæ—¶å¯¹è¿ç»­æ§åˆ¶æ¨¡å—çš„å‚æ•°è¿›è¡Œäº†ç²¾ç»†è°ƒèŠ‚ï¼Œä»¥ç¡®ä¿å…¶ä¸VLMä¸»å¹²çš„å…¼å®¹æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œé‡‡ç”¨çŸ¥è¯†éš”ç¦»æŠ€æœ¯çš„VLAæ¨¡å‹åœ¨è®­ç»ƒé€Ÿåº¦ä¸Šæé«˜äº†çº¦30%ï¼ŒåŒæ—¶çŸ¥è¯†è½¬ç§»çš„æœ‰æ•ˆæ€§æå‡äº†20%ï¼Œç›¸è¾ƒäºåŸºçº¿æ¨¡å‹è¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæ§åˆ¶ã€è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½å®¶å±…ç­‰åœºæ™¯ã€‚é€šè¿‡æå‡è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹çš„è®­ç»ƒä¸æ¨ç†æ•ˆç‡ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°å®ç°äººæœºäº¤äº’å’Œè‡ªä¸»å†³ç­–ï¼Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿçš„å®é™…åº”ç”¨ä¸å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision-language-action (VLA) models provide a powerful approach to training control policies for physical systems, such as robots, by combining end-to-end learning with transfer of semantic knowledge from web-scale vision-language model (VLM) training. However, the constraints of real-time control are often at odds with the design of VLMs: the most powerful VLMs have tens or hundreds of billions of parameters, presenting an obstacle to real-time inference, and operate on discrete tokens rather than the continuous-valued outputs that are required for controlling robots. To address this challenge, recent VLA models have used specialized modules for efficient continuous control, such as action experts or continuous output heads, which typically require adding new untrained parameters to the pretrained VLM backbone. While these modules improve real-time and control capabilities, it remains an open question whether they preserve or degrade the semantic knowledge contained in the pretrained VLM, and what effect they have on the VLA training dynamics. In this paper, we study this question in the context of VLAs that include a continuous diffusion or flow matching action expert, showing that naively including such experts significantly harms both training speed and knowledge transfer. We provide an extensive analysis of various design choices, their impact on performance and knowledge transfer, and propose a technique for insulating the VLM backbone during VLA training that mitigates this issue. Videos are available at https://pi.website/research/knowledge_insulation.

