---
layout: default
title: Knowledge Distillation for Enhancing Walmart E-commerce Search Relevance Using Large Language Models
---

# Knowledge Distillation for Enhancing Walmart E-commerce Search Relevance Using Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.07105" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.07105v1</a>
  <a href="https://arxiv.org/pdf/2505.07105.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.07105v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.07105v1', 'Knowledge Distillation for Enhancing Walmart E-commerce Search Relevance Using Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hongwei Shang, Nguyen Vo, Nitin Yadav, Tian Zhang, Ajit Puthenputhussery, Xunfan Cai, Shuyi Chen, Prijith Chandran, Changsung Kang

**åˆ†ç±»**: cs.IR, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-11

**å¤‡æ³¨**: 9 pages, published at WWWW'25

**æœŸåˆŠ**: The Web Conference 2025

**DOI**: [10.1145/3701716.3715242](https://doi.org/10.1145/3701716.3715242)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºçŸ¥è¯†è’¸é¦æ–¹æ³•ä»¥æå‡æ²ƒå°”ç›ç”µå•†æœç´¢ç›¸å…³æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `çŸ¥è¯†è’¸é¦` `ç”µå•†æœç´¢` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ·±åº¦å­¦ä¹ ` `æ¨¡å‹ä¼˜åŒ–` `ç”¨æˆ·ä½“éªŒ` `ç›¸å…³æ€§åŒ¹é…`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç”µå•†æœç´¢ä¸­éš¾ä»¥å®æ—¶éƒ¨ç½²å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¯¼è‡´æœç´¢ç»“æœç›¸å…³æ€§ä¸è¶³ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡çŸ¥è¯†è’¸é¦å°†é«˜æ€§èƒ½çš„LLMè½¬åŒ–ä¸ºä½å»¶è¿Ÿçš„å­¦ç”Ÿæ¨¡å‹ï¼Œä»¥æ»¡è¶³ç”Ÿäº§ç³»ç»Ÿçš„éœ€æ±‚ã€‚
3. å®éªŒè¡¨æ˜ï¼Œå­¦ç”Ÿæ¨¡å‹åœ¨å¢å¼ºæ•°æ®é›†ä¸Šè®­ç»ƒåï¼Œæ€§èƒ½æŒç»­æå‡ï¼Œæœ€ç»ˆåœ¨æŸäº›æƒ…å†µä¸‹è¶…è¶Šæ•™å¸ˆæ¨¡å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç¡®ä¿ç”µå•†æœç´¢ç»“æœä¸ç”¨æˆ·æŸ¥è¯¢ç›¸å…³æ€§è‡³å…³é‡è¦ã€‚æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨æœç´¢ä»»åŠ¡ä¸­çš„ç›¸å…³æ€§åŒ¹é…ä¸­å¾—åˆ°äº†å¹¿æ³›åº”ç”¨ã€‚å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å…·æœ‰ä¼˜è¶Šçš„æ’åèƒ½åŠ›ï¼Œä½†ç”±äºé«˜å»¶è¿Ÿè¦æ±‚ï¼Œå®æ—¶ç³»ç»Ÿä¸­éƒ¨ç½²LLMsé¢ä¸´æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶ï¼Œå°†é«˜æ€§èƒ½çš„LLMè’¸é¦ä¸ºæ›´é«˜æ•ˆã€ä½å»¶è¿Ÿçš„å­¦ç”Ÿæ¨¡å‹ã€‚é€šè¿‡ç”Ÿæˆæœªæ ‡è®°æ•°æ®å¹¶ç”¨æ•™å¸ˆæ¨¡å‹é¢„æµ‹è¿›è¡Œæ ‡æ³¨ï¼Œæ˜¾è‘—æ‰©å±•å­¦ç”Ÿæ¨¡å‹çš„æ•°æ®é›†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œéšç€å¢å¼ºè®­ç»ƒæ•°æ®çš„å¢åŠ ï¼Œå­¦ç”Ÿæ¨¡å‹çš„æ€§èƒ½æŒç»­æå‡ï¼Œç”šè‡³åœ¨è¶³å¤Ÿçš„æ•°æ®ä¸‹è¶…è¶Šæ•™å¸ˆæ¨¡å‹ã€‚è¯¥å­¦ç”Ÿæ¨¡å‹å·²æˆåŠŸåœ¨Walmart.comçš„ç”Ÿäº§ç¯å¢ƒä¸­éƒ¨ç½²ï¼Œå–å¾—äº†æ˜¾è‘—çš„æ­£å‘æŒ‡æ ‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç”µå•†æœç´¢ä¸­å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é«˜å»¶è¿Ÿçš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥åœ¨å®æ—¶ç³»ç»Ÿä¸­æœ‰æ•ˆéƒ¨ç½²ï¼Œå½±å“æœç´¢ç»“æœçš„ç›¸å…³æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡çŸ¥è¯†è’¸é¦ï¼Œå°†é«˜æ€§èƒ½çš„LLMè½¬åŒ–ä¸ºä¸€ä¸ªæ›´é«˜æ•ˆçš„å­¦ç”Ÿæ¨¡å‹ï¼Œä½¿å…¶åœ¨ä¿æŒè¾ƒä½å»¶è¿Ÿçš„åŒæ—¶ï¼Œä»èƒ½åˆ©ç”¨æ•™å¸ˆæ¨¡å‹çš„å¼ºå¤§æ’åèƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šé¦–å…ˆè®­ç»ƒæ•™å¸ˆæ¨¡å‹ä½œä¸ºåˆ†ç±»æ¨¡å‹ï¼Œä½¿ç”¨è½¯ç›®æ ‡è¿›è¡Œè®­ç»ƒï¼›ç„¶åè®­ç»ƒå­¦ç”Ÿæ¨¡å‹ï¼Œåˆ©ç”¨å‡æ–¹è¯¯å·®æŸå¤±æ•æ‰äº§å“å¯¹ä¹‹é—´çš„ç›¸å…³æ€§è¾¹é™…ã€‚æ­¤å¤–ï¼Œé€šè¿‡ç”Ÿæˆæœªæ ‡è®°æ•°æ®å¹¶ç”¨æ•™å¸ˆæ¨¡å‹çš„é¢„æµ‹è¿›è¡Œæ ‡æ³¨ï¼Œæ˜¾è‘—æ‰©å±•å­¦ç”Ÿæ¨¡å‹çš„æ•°æ®é›†ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºé€šè¿‡ç”Ÿæˆæœªæ ‡è®°æ•°æ®å¹¶è¿›è¡Œæ ‡æ³¨ï¼Œæ˜¾è‘—æ‰©å±•äº†å­¦ç”Ÿæ¨¡å‹çš„è®­ç»ƒæ•°æ®é›†ï¼Œä½¿å…¶åœ¨æ€§èƒ½ä¸Šè¶…è¶Šæ•™å¸ˆæ¨¡å‹ï¼Œè¿™æ˜¯ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŸå¤±å‡½æ•°ä¸Šï¼Œå­¦ç”Ÿæ¨¡å‹ä½¿ç”¨å‡æ–¹è¯¯å·®æŸå¤±æ¥ä¼˜åŒ–ç›¸å…³æ€§è¾¹é™…ï¼›ç½‘ç»œç»“æ„æ–¹é¢ï¼Œå­¦ç”Ÿæ¨¡å‹è®¾è®¡ä¸ºæ›´è½»é‡çº§ï¼Œä»¥é€‚åº”ä½å»¶è¿Ÿçš„éœ€æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œéšç€å¢å¼ºè®­ç»ƒæ•°æ®çš„å¢åŠ ï¼Œå­¦ç”Ÿæ¨¡å‹çš„æ€§èƒ½æŒç»­æå‡ï¼Œæœ€ç»ˆåœ¨æŸäº›æƒ…å†µä¸‹è¶…è¶Šäº†æ•™å¸ˆæ¨¡å‹ã€‚å…·ä½“è€Œè¨€ï¼Œå­¦ç”Ÿæ¨¡å‹åœ¨ç”Ÿäº§ç¯å¢ƒä¸­éƒ¨ç½²åï¼Œç›¸å…³æ€§æŒ‡æ ‡æ˜¾è‘—æ”¹å–„ï¼Œæå‡å¹…åº¦è¾¾åˆ°XX%ï¼ˆå…·ä½“æ•°æ®æœªçŸ¥ï¼‰ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç”µå•†å¹³å°çš„æœç´¢å¼•æ“ä¼˜åŒ–ã€æ¨èç³»ç»Ÿç­‰ã€‚é€šè¿‡æå‡æœç´¢ç»“æœçš„ç›¸å…³æ€§ï¼Œèƒ½å¤Ÿæ˜¾è‘—æ”¹å–„ç”¨æˆ·ä½“éªŒï¼Œå¢åŠ ç”¨æˆ·ç²˜æ€§å’Œè´­ä¹°è½¬åŒ–ç‡ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Ensuring the products displayed in e-commerce search results are relevant to users queries is crucial for improving the user experience. With their advanced semantic understanding, deep learning models have been widely used for relevance matching in search tasks. While large language models (LLMs) offer superior ranking capabilities, it is challenging to deploy LLMs in real-time systems due to the high-latency requirements. To leverage the ranking power of LLMs while meeting the low-latency demands of production systems, we propose a novel framework that distills a high performing LLM into a more efficient, low-latency student model. To help the student model learn more effectively from the teacher model, we first train the teacher LLM as a classification model with soft targets. Then, we train the student model to capture the relevance margin between pairs of products for a given query using mean squared error loss. Instead of using the same training data as the teacher model, we significantly expand the student model dataset by generating unlabeled data and labeling it with the teacher model predictions. Experimental results show that the student model performance continues to improve as the size of the augmented training data increases. In fact, with enough augmented data, the student model can outperform the teacher model. The student model has been successfully deployed in production at Walmart.com with significantly positive metrics.

