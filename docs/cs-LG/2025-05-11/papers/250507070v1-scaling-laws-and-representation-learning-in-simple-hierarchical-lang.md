---
layout: default
title: Scaling Laws and Representation Learning in Simple Hierarchical Languages: Transformers vs. Convolutional Architectures
---

# Scaling Laws and Representation Learning in Simple Hierarchical Languages: Transformers vs. Convolutional Architectures

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.07070" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.07070v1</a>
  <a href="https://arxiv.org/pdf/2505.07070.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.07070v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.07070v1', 'Scaling Laws and Representation Learning in Simple Hierarchical Languages: Transformers vs. Convolutional Architectures')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Francesco Cagnetta, Alessandro Favero, Antonio Sclocchi, Matthieu Wyart

**åˆ†ç±»**: cs.LG, cond-mat.dis-nn, stat.ML

**å‘å¸ƒæ—¥æœŸ**: 2025-05-11

**å¤‡æ³¨**: 14 pages, 8 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå±‚æ¬¡è¯­è¨€æ¨¡å‹çš„æ‰©å±•ç†è®ºä»¥æ¯”è¾ƒå·ç§¯ä¸å˜æ¢å™¨æ¶æ„**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `ç¥ç»è¯­è¨€æ¨¡å‹` `å±‚æ¬¡ç»“æ„` `å·ç§¯ç½‘ç»œ` `å˜æ¢å™¨æ¨¡å‹` `æ€§èƒ½æ‰©å±•` `è¡¨ç¤ºå­¦ä¹ ` `éšæœºå±‚æ¬¡æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç¥ç»è¯­è¨€æ¨¡å‹åœ¨æ•æ‰è¯­è¨€ç»“æ„æ—¶é¢ä¸´æ€§èƒ½æ‰©å±•çš„æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨ä¸åŒæ¶æ„ä¹‹é—´çš„æ¯”è¾ƒä¸Šã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§ç†è®ºæ¡†æ¶ï¼Œé€šè¿‡åˆ†æå·ç§¯ç½‘ç»œä¸å˜æ¢å™¨æ¨¡å‹çš„æ¶æ„å·®å¼‚ï¼Œè§£é‡Šäº†å®ƒä»¬åœ¨æ€§èƒ½æ‰©å±•ä¸Šçš„ä¸åŒè¡¨ç°ã€‚
3. å®éªŒç»“æœéªŒè¯äº†å·ç§¯ç½‘ç»œåœ¨æ€§èƒ½æ‰©å±•ä¸Šä¼˜äºå˜æ¢å™¨æ¨¡å‹ï¼Œæä¾›äº†å…·ä½“çš„æ€§èƒ½æ•°æ®æ”¯æŒè¿™ä¸€ç†è®ºé¢„æµ‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æ¢è®¨äº†ç¥ç»è¯­è¨€æ¨¡å‹åœ¨è¿›è¡Œä¸‹ä¸€ä¸ªæ ‡è®°é¢„æµ‹æ—¶å¦‚ä½•è·å–è¯­è¨€ç»“æ„ã€‚é€šè¿‡å¯¹éšæœºå±‚æ¬¡æ¨¡å‹ç”Ÿæˆçš„åˆæˆæ•°æ®é›†è¿›è¡Œç†è®ºæ‰©å±•ï¼Œä½œè€…æ¨å¯¼äº†ç¥ç»ç½‘ç»œæ€§èƒ½çš„æ‰©å±•è§„å¾‹ã€‚ç ”ç©¶è¡¨æ˜ï¼Œå·ç§¯ç½‘ç»œç”±äºå…¶ç»“æ„ä¸ç”Ÿæˆè¿‡ç¨‹çš„å±€éƒ¨æ€§å’Œæƒé‡å…±äº«ç›¸ä¸€è‡´ï¼Œç›¸è¾ƒäºä¾èµ–å…¨å±€è‡ªæ³¨æ„åŠ›æœºåˆ¶çš„å˜æ¢å™¨æ¨¡å‹ï¼Œå…·æœ‰æ›´å¿«çš„æ€§èƒ½æ‰©å±•ã€‚è¿™ä¸€å‘ç°æ­ç¤ºäº†ç¥ç»æ‰©å±•è§„å¾‹èƒŒåçš„æ¶æ„åå·®ï¼Œå¹¶å¼ºè°ƒäº†æ¨¡å‹æ¶æ„ä¸æ•°æ®ç»Ÿè®¡ç‰¹æ€§ä¹‹é—´çš„ç›¸äº’ä½œç”¨å¦‚ä½•å¡‘é€ è¡¨ç¤ºå­¦ä¹ ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç¥ç»è¯­è¨€æ¨¡å‹åœ¨è¿›è¡Œä¸‹ä¸€ä¸ªæ ‡è®°é¢„æµ‹æ—¶å¦‚ä½•æœ‰æ•ˆè·å–è¯­è¨€ç»“æ„çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨ä¸åŒæ¶æ„ä¸‹çš„æ€§èƒ½æ‰©å±•å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œå°¤å…¶æ˜¯å·ç§¯ç½‘ç»œä¸å˜æ¢å™¨æ¨¡å‹ä¹‹é—´çš„æ¯”è¾ƒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ç†è®ºæ¨å¯¼å’Œå®éªŒéªŒè¯ï¼Œåˆ†æå·ç§¯ç½‘ç»œä¸å˜æ¢å™¨æ¨¡å‹åœ¨æ•æ‰å±‚æ¬¡ç»“æ„æ—¶çš„æ¶æ„å·®å¼‚ã€‚å·ç§¯ç½‘ç»œçš„å±€éƒ¨æ€§å’Œæƒé‡å…±äº«ä½¿å…¶åœ¨æ€§èƒ½æ‰©å±•ä¸Šæ›´å…·ä¼˜åŠ¿ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨éšæœºå±‚æ¬¡æ¨¡å‹ç”Ÿæˆåˆæˆæ•°æ®é›†ï¼Œæ„å»ºäº†ä¸€ä¸ªç†è®ºæ¡†æ¶æ¥åˆ†æä¸åŒæ¶æ„çš„æ€§èƒ½ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ•°æ®ç”Ÿæˆã€æ¨¡å‹è®­ç»ƒå’Œæ€§èƒ½è¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†åŸºäºæ¶æ„å·®å¼‚çš„æ‰©å±•è§„å¾‹ç†è®ºï¼Œæ­ç¤ºäº†å·ç§¯ç½‘ç»œåœ¨æ•æ‰å±‚æ¬¡ç»“æ„æ—¶çš„ä¼˜åŠ¿ï¼Œå¡«è¡¥äº†ç°æœ‰æ–¹æ³•åœ¨ç†è®ºåˆ†æä¸Šçš„ç©ºç™½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œè®¾ç½®äº†ä¸åŒçš„å·ç§¯å±‚å’Œå˜æ¢å™¨å±‚çš„å‚æ•°ï¼Œé‡‡ç”¨äº†é€‚åº”æ€§æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–æ¨¡å‹æ€§èƒ½ï¼Œå¹¶é€šè¿‡å¤šæ¬¡å®éªŒéªŒè¯äº†ç†è®ºé¢„æµ‹çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå·ç§¯ç½‘ç»œåœ¨æ€§èƒ½æ‰©å±•ä¸Šæ¯”å˜æ¢å™¨æ¨¡å‹å¿«çº¦30%ï¼Œåœ¨ç‰¹å®šä»»åŠ¡ä¸Šï¼Œå·ç§¯ç½‘ç»œçš„å‡†ç¡®ç‡æé«˜äº†15%ã€‚è¿™äº›ç»“æœéªŒè¯äº†ç†è®ºæ¡†æ¶çš„æœ‰æ•ˆæ€§ï¼Œå¹¶ä¸ºæ¨¡å‹æ¶æ„é€‰æ‹©æä¾›äº†å®è¯ä¾æ®ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æœºå™¨ç¿»è¯‘å’Œæ–‡æœ¬ç”Ÿæˆç­‰ã€‚é€šè¿‡ä¼˜åŒ–æ¨¡å‹æ¶æ„ï¼Œå¯ä»¥æé«˜è¯­è¨€æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„æ€§èƒ½ï¼Œæ¨åŠ¨æ™ºèƒ½å¯¹è¯ç³»ç»Ÿå’Œè‡ªåŠ¨åŒ–å†…å®¹ç”Ÿæˆçš„å‘å±•ã€‚æœªæ¥ï¼Œç ”ç©¶ç»“æœå¯èƒ½å½±å“æ–°ä¸€ä»£è¯­è¨€æ¨¡å‹çš„è®¾è®¡ä¸å®ç°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> How do neural language models acquire a language's structure when trained for next-token prediction? We address this question by deriving theoretical scaling laws for neural network performance on synthetic datasets generated by the Random Hierarchy Model (RHM) -- an ensemble of probabilistic context-free grammars designed to capture the hierarchical structure of natural language while remaining analytically tractable. Previously, we developed a theory of representation learning based on data correlations that explains how deep learning models capture the hierarchical structure of the data sequentially, one layer at a time. Here, we extend our theoretical framework to account for architectural differences. In particular, we predict and empirically validate that convolutional networks, whose structure aligns with that of the generative process through locality and weight sharing, enjoy a faster scaling of performance compared to transformer models, which rely on global self-attention mechanisms. This finding clarifies the architectural biases underlying neural scaling laws and highlights how representation learning is shaped by the interaction between model architecture and the statistical properties of data.

