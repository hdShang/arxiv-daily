---
layout: default
title: Benign Samples Matter! Fine-tuning On Outlier Benign Samples Severely Breaks Safety
---

# Benign Samples Matter! Fine-tuning On Outlier Benign Samples Severely Breaks Safety

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.06843" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.06843v2</a>
  <a href="https://arxiv.org/pdf/2505.06843.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.06843v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.06843v2', 'Benign Samples Matter! Fine-tuning On Outlier Benign Samples Severely Breaks Safety')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zihan Guan, Mengxuan Hu, Ronghang Zhu, Sheng Li, Anil Vullikanti

**åˆ†ç±»**: cs.LG, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-11 (æ›´æ–°: 2025-05-25)

**å¤‡æ³¨**: 26 pages, 13 figures

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/GuanZihan/Benign-Samples-Matter)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSelf-Inf-Nä»¥è¯†åˆ«è‰¯æ€§æ ·æœ¬ä¸­çš„å¼‚å¸¸ç‚¹ï¼Œæå‡LLMå®‰å…¨æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å¼‚å¸¸æ£€æµ‹` `å¾®è°ƒ` `å®‰å…¨æ€§è¯„ä¼°` `å¯¹é½ä¿éšœ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰æ–¹æ³•åœ¨å¾®è°ƒè‰¯æ€§æ ·æœ¬æ—¶ï¼Œå¯èƒ½å¯¼è‡´å¤§å‹è¯­è¨€æ¨¡å‹è¾“å‡ºçš„æœ‰å®³æ€§æ˜¾è‘—å¢åŠ ï¼Œå­˜åœ¨å®‰å…¨éšæ‚£ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæœ¬æ–‡æå‡ºSelf-Inf-Nï¼Œé€šè¿‡å¼‚å¸¸æ£€æµ‹è¯†åˆ«è‰¯æ€§æ•°æ®é›†ä¸­å¯¹å®‰å…¨æ€§å½±å“æœ€å¤§çš„æ ·æœ¬ï¼Œè¿›è¡Œé’ˆå¯¹æ€§å¾®è°ƒã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šåœ¨ä¸ƒç§ä¸»æµLLMä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œä½¿ç”¨100ä¸ªå¼‚å¸¸æ ·æœ¬å¾®è°ƒåï¼Œæ¨¡å‹çš„å®‰å…¨æ€§æ˜¾è‘—ä¸‹é™ï¼Œä¸”æ”»å‡»å…·æœ‰é«˜åº¦å¯è½¬ç§»æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘æœŸç ”ç©¶æ­ç¤ºäº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¾®è°ƒé˜¶æ®µçš„è„†å¼±æ€§ï¼šå³ä½¿åœ¨å®Œå…¨è‰¯æ€§çš„è®­ç»ƒæ•°æ®é›†ä¸Šå¾®è°ƒï¼Œä¹Ÿå¯èƒ½æ˜¾è‘—å¢åŠ æ¨¡å‹è¾“å‡ºçš„æœ‰å®³æ€§ã€‚åŸºäºè¿™ä¸€å‘ç°ï¼Œæœ¬æ–‡é€šè¿‡å¼€å‘æ›´æœ‰æ•ˆçš„æ”»å‡»æ–¹æ³•ï¼Œåˆ†æå¹¶è¯†åˆ«è‰¯æ€§æ•°æ®é›†ä¸­å¯¹å®‰å…¨æ€§é™çº§è´¡çŒ®æœ€å¤§çš„æ ·æœ¬ï¼Œä¸“é—¨å¯¹è¿™äº›æ ·æœ¬è¿›è¡Œå¾®è°ƒã€‚æˆ‘ä»¬ä»å¼‚å¸¸æ£€æµ‹çš„è§’åº¦å‡ºå‘ï¼Œæå‡ºäº†Self-Inf-Næ¥æ£€æµ‹å’Œæå–å¼‚å¸¸æ ·æœ¬ã€‚ç ”ç©¶è¡¨æ˜ï¼Œä½¿ç”¨Self-Inf-Né€‰æ‹©çš„100ä¸ªå¼‚å¸¸æ ·æœ¬è¿›è¡Œå¾®è°ƒï¼Œä¸¥é‡æŸå®³äº†LLMçš„å®‰å…¨å¯¹é½ã€‚é€šè¿‡å¯¹ä¸ƒç§ä¸»æµLLMçš„å¹¿æ³›å®éªŒï¼Œç»“æœæ˜¾ç¤ºè¯¥æ”»å‡»åœ¨ä¸åŒæ¶æ„é—´å…·æœ‰é«˜åº¦å¯è½¬ç§»æ€§ï¼Œå¹¶åœ¨å®é™…åœºæ™¯ä¸­ä¾ç„¶æœ‰æ•ˆã€‚ä»¤äººæ‹…å¿§çš„æ˜¯ï¼Œç°æœ‰çš„å¤§å¤šæ•°ç¼“è§£ç­–ç•¥æœªèƒ½æœ‰æ•ˆé˜²å¾¡æ­¤æ”»å‡»ï¼Œå¼ºè°ƒäº†æ›´å¼ºå¤§å¯¹é½ä¿éšœçš„è¿«åˆ‡éœ€æ±‚ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¾®è°ƒè‰¯æ€§æ ·æœ¬æ—¶å¯èƒ½å¯¼è‡´çš„å®‰å…¨æ€§é™çº§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆè¯†åˆ«å’Œå¤„ç†è‰¯æ€§æ•°æ®é›†ä¸­æ½œåœ¨çš„æœ‰å®³æ ·æœ¬ï¼Œå¯¼è‡´æ¨¡å‹è¾“å‡ºçš„å®‰å…¨æ€§å—åˆ°å¨èƒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼‚å¸¸æ£€æµ‹æŠ€æœ¯ï¼Œè¯†åˆ«è‰¯æ€§æ•°æ®é›†ä¸­å¯¹æ¨¡å‹å®‰å…¨æ€§å½±å“æœ€å¤§çš„æ ·æœ¬ï¼Œå¹¶ä¸“é—¨å¯¹è¿™äº›æ ·æœ¬è¿›è¡Œå¾®è°ƒï¼Œä»¥æ­ç¤ºå…¶å¯¹æ¨¡å‹è¾“å‡ºçš„æ½œåœ¨å±å®³ã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨æ·±å…¥æ¢è®¨è‰¯æ€§æ ·æœ¬çš„æ½œåœ¨é£é™©ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œä½¿ç”¨Self-Inf-Nç®—æ³•è¿›è¡Œå¼‚å¸¸æ ·æœ¬çš„æ£€æµ‹å’Œæå–ï¼›å…¶æ¬¡ï¼ŒåŸºäºæå–çš„å¼‚å¸¸æ ·æœ¬å¯¹LLMè¿›è¡Œå¾®è°ƒï¼›æœ€åï¼Œè¯„ä¼°å¾®è°ƒåæ¨¡å‹çš„å®‰å…¨æ€§å’Œè¾“å‡ºè´¨é‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†Self-Inf-Nç®—æ³•ï¼Œè¯¥ç®—æ³•èƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«è‰¯æ€§æ•°æ®é›†ä¸­çš„å¼‚å¸¸æ ·æœ¬ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´ç²¾å‡†åœ°å®šä½å¯¹å®‰å…¨æ€§å½±å“æœ€å¤§çš„æ ·æœ¬ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼ŒSelf-Inf-Nç®—æ³•çš„å‚æ•°è®¾ç½®ç»è¿‡ç²¾å¿ƒè°ƒæ•´ï¼Œä»¥ç¡®ä¿å¼‚å¸¸æ ·æœ¬çš„å‡†ç¡®è¯†åˆ«ã€‚åŒæ—¶ï¼Œå¾®è°ƒè¿‡ç¨‹ä¸­é‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹åœ¨å®‰å…¨æ€§æ–¹é¢çš„è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨Self-Inf-Né€‰æ‹©çš„100ä¸ªå¼‚å¸¸æ ·æœ¬è¿›è¡Œå¾®è°ƒåï¼Œä¸ƒç§ä¸»æµLLMçš„å®‰å…¨æ€§æ˜¾è‘—ä¸‹é™ï¼Œæ”»å‡»åœ¨ä¸åŒæ¶æ„é—´å…·æœ‰é«˜åº¦å¯è½¬ç§»æ€§ã€‚å¤§å¤šæ•°ç°æœ‰çš„ç¼“è§£ç­–ç•¥æœªèƒ½æœ‰æ•ˆé˜²å¾¡æ­¤æ”»å‡»ï¼Œå¼ºè°ƒäº†å¯¹é½ä¿éšœçš„è¿«åˆ‡éœ€æ±‚ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤§å‹è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ€§è¯„ä¼°å’Œæ”¹è¿›ï¼Œå°¤å…¶æ˜¯åœ¨å¯¹æŠ—æ€§æ”»å‡»å’Œå®‰å…¨å¯¹é½æ–¹é¢ã€‚é€šè¿‡è¯†åˆ«å’Œå¤„ç†è‰¯æ€§æ ·æœ¬ä¸­çš„å¼‚å¸¸ç‚¹ï¼Œå¯ä»¥ä¸ºæ¨¡å‹çš„å®‰å…¨æ€§æä¾›æ›´å¼ºçš„ä¿éšœï¼Œå‡å°‘æœ‰å®³è¾“å‡ºçš„é£é™©ã€‚æœªæ¥ï¼Œè¿™ä¸€æ–¹æ³•å¯èƒ½åœ¨å¤šä¸ªé¢†åŸŸä¸­å¾—åˆ°å¹¿æ³›åº”ç”¨ï¼Œå¦‚è‡ªç„¶è¯­è¨€å¤„ç†ã€è‡ªåŠ¨åŒ–å®¢æœå’Œå†…å®¹ç”Ÿæˆç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent studies have uncovered a troubling vulnerability in the fine-tuning stage of large language models (LLMs): even fine-tuning on entirely benign datasets can lead to a significant increase in the harmfulness of LLM outputs. Building on this finding, our red teaming study takes this threat one step further by developing a more effective attack. Specifically, we analyze and identify samples within benign datasets that contribute most to safety degradation, then fine-tune LLMs exclusively on these samples. We approach this problem from an outlier detection perspective and propose Self-Inf-N, to detect and extract outliers for fine-tuning. Our findings reveal that fine-tuning LLMs on 100 outlier samples selected by Self-Inf-N in the benign datasets severely compromises LLM safety alignment. Extensive experiments across seven mainstream LLMs demonstrate that our attack exhibits high transferability across different architectures and remains effective in practical scenarios. Alarmingly, our results indicate that most existing mitigation strategies fail to defend against this attack, underscoring the urgent need for more robust alignment safeguards. Codes are available at https://github.com/GuanZihan/Benign-Samples-Matter.

