---
layout: default
title: Spectral Insights into Data-Oblivious Critical Layers in Large Language Models
---

# Spectral Insights into Data-Oblivious Critical Layers in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.00382" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.00382v2</a>
  <a href="https://arxiv.org/pdf/2506.00382.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.00382v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.00382v2', 'Spectral Insights into Data-Oblivious Critical Layers in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xuyuan Liu, Lei Hsiung, Yaoqing Yang, Yujun Yan

**åˆ†ç±»**: cs.LG, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-31 (æ›´æ–°: 2025-06-04)

**å¤‡æ³¨**: Accepted by Findings of ACL2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ•°æ®æ— å…³æ–¹æ³•è¯†åˆ«å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„å…³é”®å±‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å…³é”®å±‚è¯†åˆ«` `æ•°æ®æ— å…³æ–¹æ³•` `ä¸­å¿ƒæ ¸å¯¹é½` `é¢†åŸŸé€‚åº”` `åé—¨é˜²å¾¡` `è¡¨ç¤ºåŠ¨æ€åˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºå¾®è°ƒåçš„æ¨¡å‹è¿›è¡Œæ•°æ®ä¾èµ–åˆ†æï¼Œé™åˆ¶äº†å…³é”®å±‚çš„è¯†åˆ«å’Œåº”ç”¨ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§æ•°æ®æ— å…³çš„æ–¹æ³•ï¼Œé€šè¿‡ä¸­å¿ƒæ ¸å¯¹é½ï¼ˆCKAï¼‰åˆ†æè¡¨ç¤ºåŠ¨æ€ï¼Œè¯†åˆ«é¢„è°ƒä¼˜æ¨¡å‹ä¸­çš„å…³é”®å±‚ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œå¾®è°ƒå…³é”®å±‚èƒ½æ˜¾è‘—é™ä½æŸå¤±ï¼Œè€Œå†»ç»“è¿™äº›å±‚å¯å°†æ”»å‡»æˆåŠŸç‡é™ä½å¤šè¾¾40%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç†è§£å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­ç‰¹å¾è¡¨ç¤ºå¦‚ä½•åœ¨å±‚é—´æ¼”å˜å¯¹äºæé«˜å…¶å¯è§£é‡Šæ€§å’Œé²æ£’æ€§è‡³å…³é‡è¦ã€‚å°½ç®¡è¿‘æœŸç ”ç©¶å·²è¯†åˆ«å‡ºä¸ç‰¹å®šåŠŸèƒ½æˆ–è¡Œä¸ºç›¸å…³çš„å…³é”®å±‚ï¼Œä½†è¿™äº›ç ”ç©¶é€šå¸¸ä¾èµ–äºæ•°æ®ä¾èµ–çš„åˆ†æï¼Œé™åˆ¶äº†å…¶åœ¨åæœŸè®¾ç½®ä¸­çš„ä½¿ç”¨ã€‚ç›¸åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ•°æ®æ— å…³çš„æ–¹æ³•ï¼Œé€šè¿‡åˆ†æè¡¨ç¤ºåŠ¨æ€æ¥è¯†åˆ«é¢„è°ƒä¼˜LLMsä¸­çš„å†…åœ¨å…³é”®å±‚ã€‚æˆ‘ä»¬è¡¨æ˜ï¼Œè¡¨ç¤ºç©ºé—´ä¸­æ˜¾è‘—å˜åŒ–çš„å±‚åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­å—åˆ°çš„å½±å“æœ€å¤§ï¼Œè¿™ä¸€æ¨¡å¼åœ¨ç‰¹å®šæ¨¡å‹çš„ä¸åŒä»»åŠ¡ä¸­å§‹ç»ˆå¦‚ä¸€ã€‚æˆ‘ä»¬çš„è°±åˆ†æè¿›ä¸€æ­¥æ­ç¤ºï¼Œè¿™äº›å˜åŒ–æ˜¯ç”±ä¸»æˆåˆ†çš„å˜åŒ–é©±åŠ¨çš„ï¼Œç¼–ç äº†ä»æ¨ç†åˆ°ç»“è®ºçš„è¯­ä¹‰è½¬å˜ã€‚æˆ‘ä»¬è¿˜å°†è¿™äº›å‘ç°åº”ç”¨äºä¸¤ä¸ªå®é™…åœºæ™¯ï¼šé«˜æ•ˆçš„é¢†åŸŸé€‚åº”å’Œåé—¨é˜²å¾¡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¦‚ä½•åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­è¯†åˆ«å…³é”®å±‚çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºå¾®è°ƒåçš„æ•°æ®åˆ†æï¼Œé™åˆ¶äº†å…¶åœ¨æ¨¡å‹è®­ç»ƒå‰çš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ•°æ®æ— å…³çš„æ–¹æ³•ï¼Œé€šè¿‡åˆ†æè¡¨ç¤ºåŠ¨æ€æ¥è¯†åˆ«å…³é”®å±‚ã€‚è¿™ç§æ–¹æ³•ä¸ä¾èµ–äºç‰¹å®šæ•°æ®é›†ï¼Œä½¿å¾—å…³é”®å±‚çš„è¯†åˆ«æ›´å…·æ™®é€‚æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€è¡¨ç¤ºåŠ¨æ€åˆ†æå’Œå…³é”®å±‚è¯†åˆ«ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡CKAåˆ†æä¸åŒå±‚çš„è¡¨ç¤ºå˜åŒ–ï¼Œç„¶åè¯†åˆ«å‡ºè¡¨ç°å‡ºæ˜¾è‘—å˜åŒ–çš„å±‚ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„ä¸»è¦åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§æ•°æ®æ— å…³çš„åˆ†ææ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨æœªå¾®è°ƒçš„æ¨¡å‹ä¸­è¯†åˆ«å‡ºå…³é”®å±‚ï¼Œçªç ´äº†ä»¥å¾€ä¾èµ–äºå¾®è°ƒçš„é™åˆ¶ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œä½¿ç”¨CKAä½œä¸ºæ ¸å¿ƒåˆ†æå·¥å…·ï¼Œå…³æ³¨ä¸»æˆåˆ†çš„å˜åŒ–ï¼Œç‰¹åˆ«æ˜¯ä¸è¯­ä¹‰è½¬å˜ç›¸å…³çš„ä¸»æˆåˆ†ï¼Œä»¥æ­¤æ¥è¯†åˆ«å…³é”®å±‚ã€‚è¿˜è®¾è®¡äº†é’ˆå¯¹ä¸åŒä»»åŠ¡çš„å®éªŒè®¾ç½®ï¼Œä»¥éªŒè¯æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå¾®è°ƒå…³é”®å±‚ç›¸æ¯”éå…³é”®å±‚èƒ½æ˜¾è‘—é™ä½æŸå¤±ï¼Œæå‡æ¨¡å‹æ€§èƒ½ã€‚æ­¤å¤–ï¼Œå†»ç»“å…³é”®å±‚å¯å°†åé—¨æ”»å‡»çš„æˆåŠŸç‡é™ä½å¤šè¾¾40%ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬é«˜æ•ˆçš„é¢†åŸŸé€‚åº”å’Œåé—¨é˜²å¾¡ã€‚åœ¨é¢†åŸŸé€‚åº”ä¸­ï¼Œé€šè¿‡å¾®è°ƒå…³é”®å±‚å¯ä»¥æ˜¾è‘—æé«˜æ¨¡å‹çš„æ€§èƒ½ï¼Œè€Œåœ¨åé—¨é˜²å¾¡ä¸­ï¼Œå†»ç»“å…³é”®å±‚èƒ½å¤Ÿæœ‰æ•ˆé™ä½æ”»å‡»æˆåŠŸç‡ã€‚è¿™äº›åº”ç”¨å±•ç¤ºäº†è¯¥æ–¹æ³•åœ¨å®é™…åœºæ™¯ä¸­çš„é‡è¦ä»·å€¼å’Œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Understanding how feature representations evolve across layers in large language models (LLMs) is key to improving their interpretability and robustness. While recent studies have identified critical layers linked to specific functions or behaviors, these efforts typically rely on data-dependent analyses of fine-tuned models, limiting their use to post-hoc settings. In contrast, we introduce a data-oblivious approach to identify intrinsic critical layers in pre-fine-tuned LLMs by analyzing representation dynamics via Centered Kernel Alignment(CKA). We show that layers with significant shifts in representation space are also those most affected during fine-tuning--a pattern that holds consistently across tasks for a given model. Our spectral analysis further reveals that these shifts are driven by changes in the top principal components, which encode semantic transitions from rationales to conclusions. We further apply these findings to two practical scenarios: efficient domain adaptation, where fine-tuning critical layers leads to greater loss reduction compared to non-critical layers; and backdoor defense, where freezing them reduces attack success rates by up to 40%.

