---
layout: default
title: "AutoMixAlign: Adaptive Data Mixing for Multi-Task Preference Optimization in LLMs"
---

# AutoMixAlign: Adaptive Data Mixing for Multi-Task Preference Optimization in LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.00569" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.00569v1</a>
  <a href="https://arxiv.org/pdf/2506.00569.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.00569v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.00569v1', 'AutoMixAlign: Adaptive Data Mixing for Multi-Task Preference Optimization in LLMs')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Nicholas E. Corrado, Julian Katz-Samuels, Adithya Devraj, Hyokun Yun, Chao Zhang, Yi Xu, Yi Pan, Bing Yin, Trishul Chilimbi

**ÂàÜÁ±ª**: cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-31

**Â§áÊ≥®**: ACL 2025, Main Conference

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫AutoMixAlign‰ª•Ëß£ÂÜ≥Â§ö‰ªªÂä°ÂÅèÂ•Ω‰ºòÂåñÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§ö‰ªªÂä°Â≠¶‰π†` `ÂÅèÂ•Ω‰ºòÂåñ` `Ëá™ÈÄÇÂ∫îÊï∞ÊçÆÊ∑∑Âêà` `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `ÊûÅÂ∞èÊûÅÂ§ß‰ºòÂåñ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®ÈÄâÊã©ËÆ≠ÁªÉÊï∞ÊçÆÊ∑∑ÂêàÊó∂Èù¢‰∏¥È´òÊàêÊú¨Âíå‰ΩéÊïàÁöÑÈóÆÈ¢òÔºåÈöæ‰ª•Âú®Â§ö‰ªªÂä°‰∏äÂÆûÁé∞ÊúÄ‰Ω≥ÊÄßËÉΩ„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫ÁöÑAutoMixAlignÁÆóÊ≥ïÈÄöËøáËá™ÈÄÇÂ∫îÊï∞ÊçÆÊ∑∑ÂêàÔºå‰ºòÂåñÂ§ö‰ªªÂä°ÁöÑÂÅèÂ•ΩË°®Áé∞ÔºåÈááÁî®‰∏ìÂÆ∂Ê®°Âûã‰∏éÈÄöÁî®Ê®°ÂûãÁöÑÁªìÂêà„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåAMAÂú®Â§ö‰∏™Â§ö‰ªªÂä°ÂØπÈΩêËÆæÁΩÆ‰∏≠‰ºò‰∫é‰º†ÁªüÁöÑÊÄªÊçüÂ§±‰ºòÂåñÊñπÊ≥ïÂíåÊ®°ÂûãÂêàÂπ∂ÊñπÊ≥ï„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Âú®ÂØπÈΩêÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÊó∂ÔºåÂÖ∂Âú®Â§öÈ°π‰ªªÂä°ÔºàÂ¶ÇÊúâÁî®ÊÄß„ÄÅÊó†ÂÆ≥ÊÄßÂíåËØöÂÆûÊÄßÔºâ‰∏äÁöÑË°®Áé∞‰∏•Èáç‰æùËµñ‰∫éËÆ≠ÁªÉÊï∞ÊçÆÁöÑÁªÑÊàê„ÄÇÁÑ∂ËÄåÔºåÈÄâÊã©‰∏Ä‰∏™ËÉΩÂ§üÂú®ÊâÄÊúâ‰ªªÂä°‰∏äÈÉΩË°®Áé∞ËâØÂ•ΩÁöÑÊï∞ÊçÆÊ∑∑ÂêàÊòØÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑ„ÄÇÁé∞ÊúâÊñπÊ≥ï‰æùËµñ‰∫éÂ§ßÈáèÁöÑÊ∂àËûçÁ†îÁ©∂„ÄÅÂêØÂèëÂºèÊñπÊ≥ïÊàñ‰∫∫Á±ªÁõ¥ËßâÔºåËøô‰∫õÊñπÊ≥ïÂæÄÂæÄÊàêÊú¨È´òÊòÇ‰∏îÊïàÊûú‰∏ç‰Ω≥„ÄÇÊú¨ÊñáÁ†îÁ©∂‰∫ÜÈÄöËøáDPOËøõË°åÂÅèÂ•Ω‰ºòÂåñÁöÑÈóÆÈ¢òÔºåÂπ∂ÊèêÂá∫‰∫ÜAutoMixAlignÔºàAMAÔºâÔºåËøôÊòØ‰∏ÄÁßçÁêÜËÆ∫Âü∫Á°ÄÁöÑÁÆóÊ≥ïÔºåËÉΩÂ§üÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠Ëá™ÈÄÇÂ∫îÂú∞Ê∑∑ÂêàÊï∞ÊçÆÈõÜÔºå‰ª•Âπ≥Ë°°ÂêÑ‰ªªÂä°ÁöÑË°®Áé∞„ÄÇAMAÈ¶ñÂÖà‰∏∫ÊØè‰∏™‰ªªÂä°ËÆ≠ÁªÉ‚Äú‰∏ìÂÆ∂Ê®°Âûã‚ÄùÔºå‰ª•Á°ÆÂÆö‰∏éÂº∫‰ªªÂä°Ë°®Áé∞Áõ∏ÂØπÂ∫îÁöÑÊçüÂ§±„ÄÇÁÑ∂ÂêéÔºå‰ΩøÁî®‰∏ÄÁßçÊñ∞È¢ñÁöÑÊûÅÂ∞èÊûÅÂ§ß‰ºòÂåñÊñπÊ≥ïËÆ≠ÁªÉÈÄöÁî®Ê®°ÂûãÔºå‰ºòÂÖàËÄÉËôëÈÄöÁî®Ê®°ÂûãÊçüÂ§±‰∏é‰∏ìÂÆ∂Ê®°ÂûãÊçüÂ§±ÂÅèÂ∑ÆÊúÄÂ§ßÁöÑ‰ªªÂä°„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Âú®ÂØπÈΩêÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÊó∂ÔºåÂ¶Ç‰ΩïÈÄâÊã©ÂêàÈÄÇÁöÑÊï∞ÊçÆÊ∑∑Âêà‰ª•‰ºòÂåñÂ§ö‰ªªÂä°Ë°®Áé∞ÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ï‰æùËµñ‰∫éÊ∂àËûçÁ†îÁ©∂ÂíåÂêØÂèëÂºèÊñπÊ≥ïÔºåÊàêÊú¨È´ò‰∏îÊïàÊûú‰∏ç‰Ω≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÊèêÂá∫ÁöÑAutoMixAlignÁÆóÊ≥ïÈÄöËøáËá™ÈÄÇÂ∫îÂú∞Ê∑∑ÂêàÊï∞ÊçÆÈõÜÔºåÂπ≥Ë°°ÂêÑ‰ªªÂä°ÁöÑË°®Áé∞„ÄÇÈ¶ñÂÖàËÆ≠ÁªÉ‰∏ìÂÆ∂Ê®°Âûã‰ª•Á°ÆÂÆöÂêÑ‰ªªÂä°ÁöÑÊçüÂ§±ÔºåÁÑ∂ÂêéÈÄöËøáÊûÅÂ∞èÊûÅÂ§ß‰ºòÂåñÊñπÊ≥ïËÆ≠ÁªÉÈÄöÁî®Ê®°ÂûãÔºå‰ºòÂÖàËÄÉËôëÊçüÂ§±ÂÅèÂ∑ÆËæÉÂ§ßÁöÑ‰ªªÂä°„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöAMAÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏§‰∏™‰∏ªË¶ÅÈò∂ÊÆµÔºöÁ¨¨‰∏ÄÈò∂ÊÆµÊòØ‰∏∫ÊØè‰∏™‰ªªÂä°ËÆ≠ÁªÉ‰∏ìÂÆ∂Ê®°ÂûãÔºåÁ¨¨‰∫åÈò∂ÊÆµÊòØËÆ≠ÁªÉÈÄöÁî®Ê®°ÂûãÔºåÈááÁî®‰∏§ÁßçÁÆóÊ≥ïÔºàAMA-RÂíåAMA-SÔºâÊù•‰ºòÂåñ‰ªªÂä°‰ºòÂÖàÁ∫ßÂíåÊï∞ÊçÆÈááÊ†∑„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöAMAÁöÑÂàõÊñ∞‰πãÂ§ÑÂú®‰∫éÂÖ∂Ëá™ÈÄÇÂ∫îÊï∞ÊçÆÊ∑∑ÂêàÁ≠ñÁï•ÔºåÈÄöËøáÂä®ÊÄÅË∞ÉÊï¥‰ªªÂä°‰ºòÂÖàÁ∫ßÂíåÊï∞ÊçÆÈááÊ†∑ÔºåÊòæËëóÊèêÂçá‰∫ÜÂ§ö‰ªªÂä°ÁöÑÂØπÈΩêÊïàÊûú„ÄÇËøô‰∏é‰º†ÁªüÁöÑÊÄªÊçüÂ§±‰ºòÂåñÊñπÊ≥ïÊúâÊú¨Ë¥®Âå∫Âà´„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöAMA-RÁÆóÊ≥ïÈÄöËøáËá™ÈÄÇÂ∫îÈáçÂä†ÊùÉÁõÆÊ†áÂáΩÊï∞Êù•‰ºòÂÖàËÄÉËôë‰ªªÂä°ÔºåËÄåAMA-SÁÆóÊ≥ïÂàôÈÄöËøáË∞ÉÊï¥ÊØè‰∏™‰ªªÂä°ÁöÑÊï∞ÊçÆÈááÊ†∑ÈáèÊù•ÂÆûÁé∞‰ºòÂÖàÁ∫ß‰ºòÂåñ„ÄÇ‰∏§ËÄÖÂú®Âá∏ÊÉÖÂÜµ‰∏ãÁöÑÊî∂ÊïõÈÄüÁéá‰∏∫O(1/‚àöT)ÔºåÂπ∂‰∏îAMA-SÁöÑÊî∂ÊïõËØÅÊòé‰ΩøÁî®‰∫ÜÂú®Á∫øÂ≠¶‰π†ÊäÄÊúØÔºåÂ¶ÇEXP3„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåAutoMixAlignÂú®Â§ö‰∏™Â§ö‰ªªÂä°ÂØπÈΩêËÆæÁΩÆ‰∏≠Ë°®Áé∞‰ºò‰∫é‰º†ÁªüÁöÑÊÄªÊçüÂ§±‰ºòÂåñÊñπÊ≥ïÔºå‰∏îÂú®Ê®°ÂûãÂêàÂπ∂ÊñπÊ≥ï‰∏ä‰πüÊúâÊòæËëóÊèêÂçá„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåAMAÂú®ÂêÑ‰ªªÂä°ÁöÑË°®Áé∞‰∏äÂùáË°°ÊÄßÊõ¥Â•ΩÔºåÊèêÂçáÂπÖÂ∫¶ÊòéÊòæÔºåÈ™åËØÅ‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Â§ö‰ªªÂä°Â≠¶‰π†„ÄÅËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂíåÊô∫ËÉΩÂä©ÊâãÁ≠â„ÄÇÈÄöËøá‰ºòÂåñÂ§ö‰ªªÂä°ÁöÑÂÅèÂ•ΩË°®Áé∞ÔºåAutoMixAlignËÉΩÂ§üÊèêÂçáÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÂèØÈù†ÊÄßÂíåÊúâÊïàÊÄßÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÊú™Êù•ÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> When aligning large language models (LLMs), their performance on various tasks (such as being helpful, harmless, and honest) depends heavily on the composition of their training data. However, selecting a data mixture that achieves strong performance across all tasks is challenging. Existing approaches rely on large ablation studies, heuristics, or human intuition, but these can be prohibitively expensive and suboptimal. We study this problem in the setting of preference optimization via DPO and introduce AutoMixAlign (AMA), a theoretically-grounded algorithm that adaptively mixes datasets during training to balance performance across tasks. AMA first trains \textit{specialist models} for each task to determine losses that correspond to strong task performance. Then, it trains a generalist model using a novel minimax optimization that prioritizes tasks for which generalist model losses deviate most from specialist model losses. To optimize this problem, we propose two algorithms: (1) AMA-R, which adaptively reweights the objective to prioritize tasks, and (2) AMA-S, which adaptively adjusts how much data is sampled from each task to prioritize tasks. Both algorithms achieve a convergence rate of $O(1/\sqrt{T})$ in the convex case. AMA-R's convergence result follows from Sagawa et al. (2019), and we provide a convergence proof for AMA-S using online learning techniques such as EXP3. We evaluate AMA on several multitask alignment setups and find that AMA outperforms the standard alignment approach -- which simply optimizes the total loss across all tasks -- and also outperforms model merging methods.

