---
layout: default
title: Prompt-Tuned LLM-Augmented DRL for Dynamic O-RAN Network Slicing
---

# Prompt-Tuned LLM-Augmented DRL for Dynamic O-RAN Network Slicing

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.00574" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.00574v1</a>
  <a href="https://arxiv.org/pdf/2506.00574.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.00574v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.00574v1', 'Prompt-Tuned LLM-Augmented DRL for Dynamic O-RAN Network Slicing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Fatemeh Lotfi, Hossein Rajoli, Fatemeh Afghah

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-31

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºæç¤ºè°ƒä¼˜çš„LLMå¢å¼ºDRLæ–¹æ³•ä»¥è§£å†³åŠ¨æ€O-RANç½‘ç»œåˆ‡ç‰‡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åŠ¨æ€ç½‘ç»œåˆ‡ç‰‡` `æ·±åº¦å¼ºåŒ–å­¦ä¹ ` `å¤§å‹è¯­è¨€æ¨¡å‹` `å¯å­¦ä¹ æç¤º` `O-RAN` `å¤šæ™ºèƒ½ä½“å­¦ä¹ ` `èµ„æºåˆ†é…`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä¼ ç»Ÿæ·±åº¦å¼ºåŒ–å­¦ä¹ åœ¨åŠ¨æ€O-RANç½‘ç»œåˆ‡ç‰‡ä¸­éš¾ä»¥å¤„ç†åˆ†æ•£å’Œå˜åŒ–çš„åé¦ˆï¼Œå¯¼è‡´å†³ç­–æ•ˆç‡ä½ä¸‹ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæå‡ºäº†ä¸€ç§åŸºäºæç¤ºçš„é€‚åº”æ–¹æ³•ï¼Œé€šè¿‡ä»»åŠ¡ç‰¹å®šçš„æç¤ºåŠ¨æ€è°ƒæ•´çŠ¶æ€è¡¨ç¤ºï¼Œä¼˜åŒ–è¯­ä¹‰èšç±»å’ŒRLç›®æ ‡ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šå®éªŒç»“æœæ˜¾ç¤ºï¼ŒPA-MRLæ¡†æ¶åœ¨æ›´å°‘çš„è¿­ä»£ä¸­å®ç°äº†æ›´é«˜çš„å¥–åŠ±ï¼ŒåŠ é€Ÿäº†æ”¶æ•›è¿‡ç¨‹ï¼Œè¶…è¶Šäº†å…¶ä»–åŸºçº¿æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°ä»£æ— çº¿ç½‘ç»œå¿…é¡»é€‚åº”åŠ¨æ€æ¡ä»¶ï¼ŒåŒæ—¶æœ‰æ•ˆç®¡ç†å¤šæ ·åŒ–çš„æœåŠ¡éœ€æ±‚ã€‚ä¼ ç»Ÿçš„æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDRLï¼‰åœ¨è¿™äº›ç¯å¢ƒä¸­é¢ä¸´æŒ‘æˆ˜ï¼Œå› ä¸ºåˆ†æ•£å’Œä¸æ–­å˜åŒ–çš„åé¦ˆä½¿å¾—æœ€ä½³å†³ç­–å˜å¾—å›°éš¾ã€‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é€šè¿‡å°†æ— åºçš„ç½‘ç»œåé¦ˆç»“æ„åŒ–ä¸ºæœ‰æ„ä¹‰çš„æ½œåœ¨è¡¨ç¤ºï¼Œå¸®åŠ©å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä»£ç†æ›´æœ‰æ•ˆåœ°è¯†åˆ«æ¨¡å¼ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºä¸Šä¸‹æ–‡çš„é€‚åº”æ–¹æ³•ï¼Œå°†å¯å­¦ä¹ çš„æç¤ºé›†æˆåˆ°LLMå¢å¼ºçš„DRLæ¡†æ¶ä¸­ã€‚åˆ©ç”¨è®­ç»ƒäºO-RANçŸ¥è¯†çš„ORANSightï¼Œæˆ‘ä»¬å¼€å‘äº†æç¤ºå¢å¼ºçš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆPA-MRLï¼‰æ¡†æ¶ï¼Œå®éªŒç»“æœè¡¨æ˜è¯¥æ–¹æ³•åŠ é€Ÿäº†æ”¶æ•›å¹¶ä¼˜äºå…¶ä»–åŸºçº¿ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä¼ ç»Ÿæ·±åº¦å¼ºåŒ–å­¦ä¹ åœ¨åŠ¨æ€O-RANç½‘ç»œåˆ‡ç‰‡ä¸­é¢ä¸´çš„å†³ç­–æ•ˆç‡ä½ä¸‹é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆå¤„ç†åˆ†æ•£å’Œä¸æ–­å˜åŒ–çš„åé¦ˆï¼Œå¯¼è‡´ä¼˜åŒ–å†³ç­–çš„æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºä¸Šä¸‹æ–‡çš„é€‚åº”æ–¹æ³•ï¼Œé€šè¿‡é›†æˆå¯å­¦ä¹ çš„æç¤ºæ¥ä¼˜åŒ–çŠ¶æ€è¡¨ç¤ºã€‚è¿™ç§è®¾è®¡ä½¿å¾—RLä»£ç†èƒ½å¤Ÿæ›´å¥½åœ°è¯†åˆ«ç½‘ç»œæ¡ä»¶ä¸‹çš„æ¨¡å¼ï¼Œä»è€Œæé«˜å†³ç­–è´¨é‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸€ä¸ªLLMå¢å¼ºçš„DRLæ¡†æ¶ï¼Œä¸»è¦æ¨¡å—åŒ…æ‹¬å¯å­¦ä¹ æç¤ºç”Ÿæˆã€çŠ¶æ€è¡¨ç¤ºä¼˜åŒ–å’Œå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ç­–ç•¥ã€‚é€šè¿‡ORANSightæ¨¡å‹ï¼Œæ¡†æ¶èƒ½å¤Ÿå®æ—¶é€‚åº”ç½‘ç»œå˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†å¯å­¦ä¹ çš„æç¤ºï¼Œè¿™äº›æç¤ºèƒ½å¤ŸåŠ¨æ€è°ƒæ•´ä»¥é€‚åº”ä¸åŒçš„ç½‘ç»œæ¡ä»¶ï¼Œä»è€Œæ˜¾è‘—æé«˜äº†RLä»£ç†çš„å­¦ä¹ æ•ˆç‡å’Œé€‚åº”èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œæç¤ºçš„ç”Ÿæˆå’Œè°ƒæ•´æ˜¯åŸºäºä»»åŠ¡ç‰¹å®šçš„éœ€æ±‚ï¼ŒæŸå¤±å‡½æ•°åˆ™ç»“åˆäº†è¯­ä¹‰èšç±»å’Œå¼ºåŒ–å­¦ä¹ ç›®æ ‡ï¼Œç¡®ä¿äº†æ¨¡å‹çš„æœ‰æ•ˆæ€§å’Œå¯è§£é‡Šæ€§ã€‚æ•´ä½“ç½‘ç»œç»“æ„ç»è¿‡ä¼˜åŒ–ï¼Œä»¥æ”¯æŒå¿«é€Ÿçš„åé¦ˆå¤„ç†å’Œå†³ç­–åˆ¶å®šã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒPA-MRLæ¡†æ¶åœ¨èµ„æºåˆ†é…ä»»åŠ¡ä¸­åŠ é€Ÿäº†æ”¶æ•›è¿‡ç¨‹ï¼Œè¾ƒå…¶ä»–åŸºçº¿æ–¹æ³•æå‡äº†çº¦30%çš„å¥–åŠ±æ•ˆç‡ã€‚è¿™ä¸€ç»“æœå±•ç¤ºäº†æç¤ºå¢å¼ºå­¦ä¹ åœ¨åŠ¨æ€ç½‘ç»œç¯å¢ƒä¸­çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŠ¨æ€O-RANç½‘ç»œåˆ‡ç‰‡ã€æ™ºèƒ½èµ„æºåˆ†é…å’Œç½‘ç»œç®¡ç†ç­‰ã€‚é€šè¿‡æé«˜å†³ç­–æ•ˆç‡å’Œé€‚åº”èƒ½åŠ›ï¼Œèƒ½å¤Ÿä¸ºè¿è¥å•†æä¾›æ›´çµæ´»çš„ç½‘ç»œæœåŠ¡ï¼Œæ»¡è¶³ä¸æ–­å˜åŒ–çš„ç”¨æˆ·éœ€æ±‚ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Modern wireless networks must adapt to dynamic conditions while efficiently managing diverse service demands. Traditional deep reinforcement learning (DRL) struggles in these environments, as scattered and evolving feedback makes optimal decision-making challenging. Large Language Models (LLMs) offer a solution by structuring unorganized network feedback into meaningful latent representations, helping RL agents recognize patterns more effectively. For example, in O-RAN slicing, concepts like SNR, power levels and throughput are semantically related, and LLMs can naturally cluster them, providing a more interpretable state representation. To leverage this capability, we introduce a contextualization-based adaptation method that integrates learnable prompts into an LLM-augmented DRL framework. Instead of relying on full model fine-tuning, we refine state representations through task-specific prompts that dynamically adjust to network conditions. Utilizing ORANSight, an LLM trained on O-RAN knowledge, we develop Prompt-Augmented Multi agent RL (PA-MRL) framework. Learnable prompts optimize both semantic clustering and RL objectives, allowing RL agents to achieve higher rewards in fewer iterations and adapt more efficiently. By incorporating prompt-augmented learning, our approach enables faster, more scalable, and adaptive resource allocation in O-RAN slicing. Experimental results show that it accelerates convergence and outperforms other baselines.

