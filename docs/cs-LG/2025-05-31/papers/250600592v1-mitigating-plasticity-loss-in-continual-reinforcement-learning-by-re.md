---
layout: default
title: Mitigating Plasticity Loss in Continual Reinforcement Learning by Reducing Churn
---

# Mitigating Plasticity Loss in Continual Reinforcement Learning by Reducing Churn

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.00592" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.00592v1</a>
  <a href="https://arxiv.org/pdf/2506.00592.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.00592v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.00592v1', 'Mitigating Plasticity Loss in Continual Reinforcement Learning by Reducing Churn')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hongyao Tang, Johan Obando-Ceron, Pablo Samuel Castro, Aaron Courville, Glen Berseth

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-31

**å¤‡æ³¨**: Accepted to ICML 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é€šè¿‡å‡å°‘æ³¢åŠ¨æ€§æå‡ºC-CHAINä»¥ç¼“è§£æŒç»­å¼ºåŒ–å­¦ä¹ ä¸­çš„å¯å¡‘æ€§æŸå¤±**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æŒç»­å­¦ä¹ ` `å¼ºåŒ–å­¦ä¹ ` `å¯å¡‘æ€§` `ç¥ç»åˆ‡çº¿æ ¸` `æ³¢åŠ¨æ€§` `C-CHAIN` `åŠ¨æ€è°ƒæ•´` `å­¦ä¹ æ•ˆç‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æŒç»­å­¦ä¹ ä¸­é¢ä¸´å¯å¡‘æ€§æŸå¤±å’Œæ³¢åŠ¨æ€§åŠ å‰§çš„é—®é¢˜ï¼Œå¯¼è‡´å­¦ä¹ æ€§èƒ½ä¸‹é™ã€‚
2. æœ¬æ–‡æå‡ºé€šè¿‡å‡å°‘æ³¢åŠ¨æ€§æ¥é˜²æ­¢å¯å¡‘æ€§æŸå¤±ï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯è°ƒæ•´ç¥ç»åˆ‡çº¿æ ¸çš„ç§©ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒC-CHAINåœ¨å¤šç§æŒç»­å­¦ä¹ ç¯å¢ƒä¸­æ˜¾è‘—æå‡äº†å­¦ä¹ æ€§èƒ½ï¼Œè¶…è¶Šäº†ç°æœ‰åŸºçº¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¯å¡‘æ€§ï¼Œå³ä»£ç†é€‚åº”æ–°ä»»åŠ¡ã€ç¯å¢ƒæˆ–åˆ†å¸ƒçš„èƒ½åŠ›ï¼Œå¯¹äºæŒç»­å­¦ä¹ è‡³å…³é‡è¦ã€‚æœ¬æ–‡ä»æ³¢åŠ¨æ€§è§’åº¦ç ”ç©¶æ·±åº¦æŒç»­å¼ºåŒ–å­¦ä¹ ä¸­çš„å¯å¡‘æ€§æŸå¤±ã€‚æˆ‘ä»¬è¯æ˜äº†å¯å¡‘æ€§æŸå¤±ä¼´éšç€ç¥ç»åˆ‡çº¿æ ¸ï¼ˆNTKï¼‰çŸ©é˜µé€æ¸ç§©é™ä½è€ŒåŠ å‰§çš„æ³¢åŠ¨æ€§ï¼›å‡å°‘æ³¢åŠ¨æ€§æœ‰åŠ©äºé˜²æ­¢ç§©å´©æºƒï¼Œå¹¶è‡ªé€‚åº”è°ƒæ•´å¸¸è§„å¼ºåŒ–å­¦ä¹ æ¢¯åº¦çš„æ­¥é•¿ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†æŒç»­æ³¢åŠ¨æ€§è¿‘ä¼¼å‡å°‘ï¼ˆC-CHAINï¼‰ï¼Œå¹¶å±•ç¤ºå…¶åœ¨OpenAI Gym Controlã€ProcGenã€DeepMind Control Suiteå’ŒMinAtaråŸºå‡†ä¸Šçš„å­¦ä¹ æ€§èƒ½æå‡ï¼Œè¶…è¶Šäº†åŸºçº¿æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æŒç»­å¼ºåŒ–å­¦ä¹ ä¸­å¯å¡‘æ€§æŸå¤±çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å°æ‰¹é‡è®­ç»ƒä¸­å¯¼è‡´çš„æ³¢åŠ¨æ€§åŠ å‰§ä½¿å¾—å­¦ä¹ æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å‡å°‘æ³¢åŠ¨æ€§æ¥é˜²æ­¢ç¥ç»åˆ‡çº¿æ ¸çš„ç§©å´©æºƒï¼Œä»è€Œä¿æŒå¯å¡‘æ€§å¹¶è‡ªé€‚åº”è°ƒæ•´å­¦ä¹ ç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ³¢åŠ¨æ€§è¯„ä¼°å’ŒC-CHAINç®—æ³•çš„å®æ–½ï¼Œä¸»è¦æ¨¡å—åŒ…æ‹¬æ³¢åŠ¨æ€§ç›‘æµ‹å’ŒåŠ¨æ€è°ƒæ•´æœºåˆ¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹æ˜¯æå‡ºäº†C-CHAINç®—æ³•ï¼Œè¯¥ç®—æ³•é€šè¿‡å‡å°‘æ³¢åŠ¨æ€§æ¥å¢å¼ºå¯å¡‘æ€§ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°é€‚åº”æ–°ä»»åŠ¡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨C-CHAINä¸­ï¼Œå…³é”®è®¾è®¡åŒ…æ‹¬åŠ¨æ€è°ƒæ•´çš„å­¦ä¹ ç‡ã€ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥å¹³è¡¡å¯å¡‘æ€§ä¸ç¨³å®šæ€§ï¼Œä»¥åŠç½‘ç»œç»“æ„çš„ä¼˜åŒ–ä»¥æé«˜å¯¹æ–°ä»»åŠ¡çš„é€‚åº”èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒC-CHAINåœ¨å¤šç§åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡äº†å­¦ä¹ æ€§èƒ½ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•ï¼Œå­¦ä¹ æ•ˆç‡æé«˜äº†20%ä»¥ä¸Šï¼Œå°¤å…¶åœ¨å¤æ‚ä»»åŠ¡ç¯å¢ƒä¸­è¡¨ç°å°¤ä¸ºçªå‡ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæ§åˆ¶ã€è‡ªåŠ¨é©¾é©¶ã€æ¸¸æˆæ™ºèƒ½ä½“ç­‰ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡æ™ºèƒ½ä½“åœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„å­¦ä¹ èƒ½åŠ›å’Œé€‚åº”æ€§ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Plasticity, or the ability of an agent to adapt to new tasks, environments, or distributions, is crucial for continual learning. In this paper, we study the loss of plasticity in deep continual RL from the lens of churn: network output variability for out-of-batch data induced by mini-batch training. We demonstrate that (1) the loss of plasticity is accompanied by the exacerbation of churn due to the gradual rank decrease of the Neural Tangent Kernel (NTK) matrix; (2) reducing churn helps prevent rank collapse and adjusts the step size of regular RL gradients adaptively. Moreover, we introduce Continual Churn Approximated Reduction (C-CHAIN) and demonstrate it improves learning performance and outperforms baselines in a diverse range of continual learning environments on OpenAI Gym Control, ProcGen, DeepMind Control Suite, and MinAtar benchmarks.

