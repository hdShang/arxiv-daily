---
layout: default
title: QoQ-Med: Building Multimodal Clinical Foundation Models with Domain-Aware GRPO Training
---

# QoQ-Med: Building Multimodal Clinical Foundation Models with Domain-Aware GRPO Training

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.00711" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.00711v2</a>
  <a href="https://arxiv.org/pdf/2506.00711.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.00711v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.00711v2', 'QoQ-Med: Building Multimodal Clinical Foundation Models with Domain-Aware GRPO Training')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wei Dai, Peilin Chen, Chanakya Ekbote, Paul Pu Liang

**åˆ†ç±»**: cs.LG, cs.AI, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-31 (æ›´æ–°: 2025-10-22)

**å¤‡æ³¨**: Accepted as Oral at NeurIPS 2025. Revision after camera ready

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/DDVD233/QoQ_Med)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºQoQ-Medä»¥è§£å†³å¤šæ¨¡æ€ä¸´åºŠå†³ç­–ä¸­çš„æ•°æ®ä¸å¹³è¡¡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `ä¸´åºŠå†³ç­–` `å¼ºåŒ–å­¦ä¹ ` `åŒ»å­¦å›¾åƒ` `æ—¶é—´åºåˆ—åˆ†æ` `æ¨¡å‹è®­ç»ƒ` `æ•°æ®ä¸å¹³è¡¡` `é¢†åŸŸæ„ŸçŸ¥`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹åœ¨ä¸´åºŠå†³ç­–ä¸­ä¸»è¦é›†ä¸­äºè§†è§‰æ•°æ®ï¼Œæ— æ³•æœ‰æ•ˆå¤„ç†å¼‚æ„æ•°æ®ï¼Œå¯¼è‡´æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºQoQ-Medæ¨¡å‹ï¼Œç»“åˆåŒ»å­¦å›¾åƒã€æ—¶é—´åºåˆ—ä¿¡å·å’Œæ–‡æœ¬æŠ¥å‘Šï¼Œé€šè¿‡é¢†åŸŸæ„ŸçŸ¥ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆDRPOï¼‰è¿›è¡Œè®­ç»ƒã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒQoQ-Medåœ¨æ‰€æœ‰è§†è§‰é¢†åŸŸçš„å®F1å¾—åˆ†å¹³å‡æå‡43%ï¼Œå¹¶åœ¨å¯†é›†åˆ†å‰²ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼ŒIoUæ˜¾è‘—é«˜äºç°æœ‰æ¨¡å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸´åºŠå†³ç­–é€šå¸¸éœ€è¦å¯¹å¼‚æ„æ•°æ®è¿›è¡Œæ¨ç†ï¼Œä½†ç°æœ‰çš„å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ä¸»è¦é›†ä¸­äºè§†è§‰æ•°æ®ï¼Œæ— æ³•åœ¨ä¸åŒä¸´åºŠä¸“ä¸šä¹‹é—´æœ‰æ•ˆæ³›åŒ–ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†QoQ-Med-7B/32Bï¼Œè¿™æ˜¯é¦–ä¸ªå¼€æ”¾çš„é€šç”¨ä¸´åºŠåŸºç¡€æ¨¡å‹ï¼Œèƒ½å¤ŸåŒæ—¶å¯¹åŒ»å­¦å›¾åƒã€æ—¶é—´åºåˆ—ä¿¡å·å’Œæ–‡æœ¬æŠ¥å‘Šè¿›è¡Œæ¨ç†ã€‚QoQ-Medé‡‡ç”¨äº†ä¸€ç§æ–°é¢–çš„å¼ºåŒ–å­¦ä¹ ç›®æ ‡â€”â€”é¢†åŸŸæ„ŸçŸ¥ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆDRPOï¼‰ï¼Œè¯¥æ–¹æ³•æ ¹æ®é¢†åŸŸç¨€ç¼ºæ€§å’Œæ¨¡æ€éš¾åº¦åˆ†å±‚ç¼©æ”¾å½’ä¸€åŒ–å¥–åŠ±ï¼Œä»è€Œç¼“è§£äº†ç”±äºä¸´åºŠæ•°æ®åˆ†å¸ƒåæ–œé€ æˆçš„æ€§èƒ½ä¸å¹³è¡¡ã€‚ç»è¿‡261ä¸‡å¯¹æŒ‡ä»¤è°ƒä¼˜æ ·æœ¬çš„è®­ç»ƒï¼ŒDRPOè®­ç»ƒåœ¨æ‰€æœ‰è§†è§‰é¢†åŸŸçš„å®F1å¾—åˆ†ä¸Šå¹³å‡æå‡äº†43%ã€‚æ­¤å¤–ï¼ŒQoQ-Medåœ¨å¯†é›†åˆ†å‰²æ•°æ®ä¸Šè®­ç»ƒåï¼Œèƒ½å¤Ÿçªå‡ºä¸è¯Šæ–­ç›¸å…³çš„æ˜¾è‘—åŒºåŸŸï¼Œå…¶IoUæ¯”å¼€æ”¾æ¨¡å‹é«˜å‡º10å€ï¼ŒåŒæ—¶è¾¾åˆ°OpenAI o4-miniçš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹åœ¨ä¸´åºŠå†³ç­–ä¸­æ— æ³•æœ‰æ•ˆå¤„ç†å¼‚æ„æ•°æ®çš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯ç”±äºæ•°æ®åˆ†å¸ƒä¸å‡å¯¼è‡´çš„æ€§èƒ½ä¸å¹³è¡¡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºQoQ-Medæ¨¡å‹ï¼Œé€šè¿‡é¢†åŸŸæ„ŸçŸ¥ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆDRPOï¼‰æ¥è®­ç»ƒæ¨¡å‹ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨ä¸åŒæ¨¡æ€å’Œé¢†åŸŸä¹‹é—´è¿›è¡Œæœ‰æ•ˆæ¨ç†ï¼Œæå‡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šQoQ-Medçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šåŒ»å­¦å›¾åƒå¤„ç†æ¨¡å—ã€æ—¶é—´åºåˆ—ä¿¡å·å¤„ç†æ¨¡å—å’Œæ–‡æœ¬æŠ¥å‘Šå¤„ç†æ¨¡å—ã€‚æ¯ä¸ªæ¨¡å—é€šè¿‡DRPOè¿›è¡Œè®­ç»ƒï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿç»¼åˆè€ƒè™‘ä¸åŒç±»å‹çš„æ•°æ®ã€‚

**å…³é”®åˆ›æ–°**ï¼šDRPOæ˜¯æœ¬æ–‡çš„æ ¸å¿ƒåˆ›æ–°ï¼Œå®ƒé€šè¿‡æ ¹æ®é¢†åŸŸç¨€ç¼ºæ€§å’Œæ¨¡æ€éš¾åº¦åŠ¨æ€è°ƒæ•´å¥–åŠ±ï¼Œè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•åœ¨å¤„ç†ä¸å¹³è¡¡æ•°æ®æ—¶çš„ä¸è¶³ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒQoQ-Medä½¿ç”¨261ä¸‡å¯¹æŒ‡ä»¤è°ƒä¼˜æ ·æœ¬ï¼Œé‡‡ç”¨ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„è®¾è®¡ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨å¤šæ¨¡æ€æ•°æ®ä¸Šçš„é«˜æ•ˆå­¦ä¹ å’Œæ¨ç†èƒ½åŠ›ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒQoQ-Medåœ¨æ‰€æœ‰è§†è§‰é¢†åŸŸçš„å®F1å¾—åˆ†å¹³å‡æå‡äº†43%ï¼Œç›¸è¾ƒäºå…¶ä»–æ— è¯„è®ºè®­ç»ƒæ–¹æ³•å¦‚GRPOã€‚æ­¤å¤–ï¼Œæ¨¡å‹åœ¨å¯†é›†åˆ†å‰²ä»»åŠ¡ä¸­çš„IoUæ¯”å¼€æ”¾æ¨¡å‹é«˜å‡º10å€ï¼Œæ€§èƒ½è¾¾åˆ°OpenAI o4-miniçš„æ°´å¹³ï¼Œå±•ç¤ºäº†å…¶å“è¶Šçš„æ¨ç†èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

QoQ-Medæ¨¡å‹çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŒ»ç–—å½±åƒåˆ†æã€ä¸´åºŠå†³ç­–æ”¯æŒç³»ç»Ÿå’Œæ™ºèƒ½å¥åº·ç®¡ç†ç­‰ã€‚å…¶å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›å°†ä¸ºåŒ»ç”Ÿæä¾›æ›´å…¨é¢çš„è¯Šæ–­ä¿¡æ¯ï¼Œæå‡ä¸´åºŠå†³ç­–çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚æœªæ¥ï¼Œè¯¥æ¨¡å‹æœ‰æœ›æ¨åŠ¨ä¸ªæ€§åŒ–åŒ»ç–—å’Œç²¾å‡†åŒ»ç–—çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Clinical decision-making routinely demands reasoning over heterogeneous data, yet existing multimodal language models (MLLMs) remain largely vision-centric and fail to generalize across clinical specialties. To bridge this gap, we introduce QoQ-Med-7B/32B, the first open generalist clinical foundation model that jointly reasons across medical images, time-series signals, and text reports. QoQ-Med is trained with Domain-aware Relative Policy Optimization (DRPO), a novel reinforcement-learning objective that hierarchically scales normalized rewards according to domain rarity and modality difficulty, mitigating performance imbalance caused by skewed clinical data distributions. Trained on 2.61 million instruction tuning pairs spanning 9 clinical domains, we show that DRPO training boosts diagnostic performance by 43% in macro-F1 on average across all visual domains as compared to other critic-free training methods like GRPO. Furthermore, with QoQ-Med trained on intensive segmentation data, it is able to highlight salient regions related to the diagnosis, with an IoU 10x higher than open models while reaching the performance of OpenAI o4-mini. To foster reproducibility and downstream research, we release (i) the full model weights, (ii) the modular training pipeline, and (iii) all intermediate reasoning traces at https://github.com/DDVD233/QoQ_Med.

