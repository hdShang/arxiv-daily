---
layout: default
title: "Revisiting LLMs as Zero-Shot Time-Series Forecasters: Small Noise Can Break Large Models"
---

# Revisiting LLMs as Zero-Shot Time-Series Forecasters: Small Noise Can Break Large Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.00457" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.00457v1</a>
  <a href="https://arxiv.org/pdf/2506.00457.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.00457v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.00457v1', 'Revisiting LLMs as Zero-Shot Time-Series Forecasters: Small Noise Can Break Large Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Junwoo Park, Hyuck Lee, Dohyun Lee, Daehoon Gwak, Jaegul Choo

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-31

**å¤‡æ³¨**: Annual Meeting of the Association for Computational Linguistics (ACL), 2025, Accepted as Short Paper

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/junwoopark92/revisiting-LLMs-zeroshot-forecaster)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°LLMsåœ¨é›¶-shotæ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„æœ‰æ•ˆæ€§åŠå…¶å™ªå£°æ•æ„Ÿæ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ—¶é—´åºåˆ—é¢„æµ‹` `é›¶-shotå­¦ä¹ ` `å™ªå£°æ•æ„Ÿæ€§` `æ¨¡å‹å¾®è°ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„LLMsåœ¨é›¶-shotæ—¶é—´åºåˆ—é¢„æµ‹ä¸­è¡¨ç°ä¸ä½³ï¼Œå°¤å…¶æ˜¯åœ¨å™ªå£°å½±å“ä¸‹ï¼Œå‡†ç¡®æ€§æ˜¾è‘—é™ä½ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡å¾®è°ƒLLMsæ¥å¢å¼ºå…¶å¤„ç†æ•°å€¼åºåˆ—çš„èƒ½åŠ›ï¼Œä»¥å…‹æœå…¶å¯¹å™ªå£°çš„æ•æ„Ÿæ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMsåœ¨é›¶-shoté¢„æµ‹ä¸­çš„è¡¨ç°ä¸å¦‚ç®€å•çš„é¢†åŸŸç‰¹å®šæ¨¡å‹ï¼Œå¼ºè°ƒäº†é²æ£’æ€§çš„é‡è¦æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šç§ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œæ¿€å‘äº†å…¶åœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œè¿‘æœŸç ”ç©¶è¡¨æ˜ï¼ŒLLMsåœ¨é¢„æµ‹ä¸­çš„å›ºæœ‰æœ‰æ•ˆæ€§ä¸è¶³ã€‚æœ¬æ–‡è¯„ä¼°äº†LLMsä½œä¸ºé›¶-shoté¢„æµ‹å™¨çš„æœ‰æ•ˆæ€§ï¼Œå¹¶ä¸æœ€å…ˆè¿›çš„é¢†åŸŸç‰¹å®šæ¨¡å‹è¿›è¡Œäº†æ¯”è¾ƒã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMåŸºäºçš„é›¶-shoté¢„æµ‹å™¨ç”±äºå¯¹å™ªå£°çš„æ•æ„Ÿæ€§ï¼Œå¾€å¾€éš¾ä»¥å®ç°é«˜å‡†ç¡®ç‡ï¼Œç”šè‡³ä¸åŠç®€å•çš„é¢†åŸŸç‰¹å®šæ¨¡å‹ã€‚æˆ‘ä»¬æ¢è®¨äº†é™ä½LLMså™ªå£°æ•æ„Ÿæ€§çš„è§£å†³æ–¹æ¡ˆï¼Œä½†æé«˜å…¶é²æ£’æ€§ä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ã€‚æˆ‘ä»¬çš„ç ”ç©¶å»ºè®®ï¼Œæœªæ¥åº”æ›´å¤šå…³æ³¨å¯¹LLMsè¿›è¡Œå¾®è°ƒï¼Œä»¥æ›´å¥½åœ°å¤„ç†æ•°å€¼åºåˆ—ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³LLMsåœ¨é›¶-shotæ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„æœ‰æ•ˆæ€§é—®é¢˜ï¼Œå°¤å…¶æ˜¯å…¶å¯¹å™ªå£°çš„æ•æ„Ÿæ€§å¯¼è‡´çš„å‡†ç¡®æ€§ä¸è¶³ã€‚ç°æœ‰æ–¹æ³•åœ¨é¢å¯¹å™ªå£°æ—¶è¡¨ç°ä¸ä½³ï¼Œé™åˆ¶äº†å…¶åº”ç”¨æ½œåŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ¢ç´¢é€šè¿‡å¾®è°ƒLLMsæ¥æé«˜å…¶å¯¹æ•°å€¼åºåˆ—çš„å¤„ç†èƒ½åŠ›ï¼Œå‡å°‘å…¶åœ¨é›¶-shotè®¾ç½®ä¸‹çš„å™ªå£°æ•æ„Ÿæ€§ã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨å¢å¼ºæ¨¡å‹çš„é²æ£’æ€§ï¼Œæå‡é¢„æµ‹å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€LLMæ¨¡å‹çš„å¾®è°ƒå’Œè¯„ä¼°æ¨¡å—ã€‚é¦–å…ˆå¯¹æ—¶é—´åºåˆ—æ•°æ®è¿›è¡Œæ¸…æ´—å’Œæ ‡å‡†åŒ–ï¼Œç„¶åå¯¹LLMsè¿›è¡Œé’ˆå¯¹æ€§çš„è®­ç»ƒï¼Œæœ€åé€šè¿‡ä¸é¢†åŸŸç‰¹å®šæ¨¡å‹çš„å¯¹æ¯”è¯„ä¼°å…¶æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†å¾®è°ƒLLMsçš„æ–¹æ³•ï¼Œä»¥åº”å¯¹å…¶åœ¨é›¶-shoté¢„æµ‹ä¸­çš„å™ªå£°æ•æ„Ÿæ€§ã€‚è¿™ä¸ä¼ ç»Ÿçš„ç›´æ¥ä½¿ç”¨LLMsè¿›è¡Œé¢„æµ‹çš„æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ï¼Œå¼ºè°ƒäº†æ¨¡å‹é€‚åº”æ€§çš„æå‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé€‰æ‹©äº†é€‚å½“çš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–æ¨¡å‹çš„é¢„æµ‹æ€§èƒ½ï¼Œå¹¶å¯¹ç½‘ç»œç»“æ„è¿›è¡Œäº†è°ƒæ•´ï¼Œä»¥é€‚åº”æ—¶é—´åºåˆ—æ•°æ®çš„ç‰¹æ€§ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œè®­ç»ƒç­–ç•¥ä¹Ÿç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œä»¥ç¡®ä¿æ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMsåœ¨é›¶-shotæ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„å‡†ç¡®ç‡æ™®éä½äºé¢†åŸŸç‰¹å®šæ¨¡å‹ï¼Œå°¤å…¶åœ¨å™ªå£°å¹²æ‰°ä¸‹ï¼Œå‡†ç¡®ç‡ä¸‹é™æ˜¾è‘—ã€‚ä¸åŸºçº¿æ¨¡å‹ç›¸æ¯”ï¼ŒLLMsçš„è¡¨ç°æå‡å¹…åº¦æœ‰é™ï¼Œå¼ºè°ƒäº†å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒçš„é‡è¦æ€§ã€‚å…·ä½“çš„å®éªŒæ•°æ®å’Œå¯¹æ¯”ç»“æœå°†åœ¨è®ºæ–‡ä¸­è¯¦ç»†åˆ—å‡ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬é‡‘èå¸‚åœºé¢„æµ‹ã€æ°”è±¡æ•°æ®åˆ†æå’Œå·¥ä¸šè®¾å¤‡ç›‘æ§ç­‰ã€‚é€šè¿‡æé«˜LLMsåœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„é²æ£’æ€§ï¼Œå¯ä»¥ä¸ºå†³ç­–æ”¯æŒç³»ç»Ÿæä¾›æ›´å‡†ç¡®çš„é¢„æµ‹ç»“æœï¼Œè¿›è€Œæå‡å„è¡Œä¸šçš„è¿è¥æ•ˆç‡å’Œå†³ç­–è´¨é‡ã€‚æœªæ¥ï¼Œéšç€æŠ€æœ¯çš„è¿›æ­¥ï¼ŒLLMsåœ¨æ›´å¤šå¤æ‚é¢„æµ‹ä»»åŠ¡ä¸­çš„åº”ç”¨å‰æ™¯å°†æ›´åŠ å¹¿é˜”ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have shown remarkable performance across diverse tasks without domain-specific training, fueling interest in their potential for time-series forecasting. While LLMs have shown potential in zero-shot forecasting through prompting alone, recent studies suggest that LLMs lack inherent effectiveness in forecasting. Given these conflicting findings, a rigorous validation is essential for drawing reliable conclusions. In this paper, we evaluate the effectiveness of LLMs as zero-shot forecasters compared to state-of-the-art domain-specific models. Our experiments show that LLM-based zero-shot forecasters often struggle to achieve high accuracy due to their sensitivity to noise, underperforming even simple domain-specific models. We have explored solutions to reduce LLMs' sensitivity to noise in the zero-shot setting, but improving their robustness remains a significant challenge. Our findings suggest that rather than emphasizing zero-shot forecasting, a more promising direction would be to focus on fine-tuning LLMs to better process numerical sequences. Our experimental code is available at https://github.com/junwoopark92/revisiting-LLMs-zeroshot-forecaster.

