---
layout: default
title: Pitfalls in Evaluating Language Model Forecasters
---

# Pitfalls in Evaluating Language Model Forecasters

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.00723" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.00723v1</a>
  <a href="https://arxiv.org/pdf/2506.00723.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.00723v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.00723v1', 'Pitfalls in Evaluating Language Model Forecasters')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Daniel Paleka, Shashwat Goel, Jonas Geiping, Florian TramÃ¨r

**åˆ†ç±»**: cs.LG, cs.AI, cs.IR

**å‘å¸ƒæ—¥æœŸ**: 2025-05-31

**å¤‡æ³¨**: 20 pages, 8 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè¯„ä¼°è¯­è¨€æ¨¡å‹é¢„æµ‹èƒ½åŠ›çš„æ–°æ–¹æ³•ä»¥è§£å†³è¯„ä¼°æŒ‘æˆ˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯­è¨€æ¨¡å‹` `é¢„æµ‹èƒ½åŠ›` `è¯„ä¼°æ–¹æ³•` `æ—¶é—´æ³„æ¼` `ç³»ç»Ÿåˆ†æ` `æ€§èƒ½è¯„ä¼°` `äººå·¥æ™ºèƒ½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹çš„é¢„æµ‹èƒ½åŠ›æ—¶é¢ä¸´æ—¶é—´æ³„æ¼ç­‰é—®é¢˜ï¼Œå¯¼è‡´ç»“æœä¸å¯é ã€‚
2. è®ºæ–‡ä¸»å¼ é‡‡ç”¨æ›´ä¸¥æ ¼çš„è¯„ä¼°æ–¹æ³•ï¼Œä»¥è§£å†³è¯„ä¼°è¿‡ç¨‹ä¸­å­˜åœ¨çš„å¤šç§æŒ‘æˆ˜ã€‚
3. é€šè¿‡å…·ä½“å®ä¾‹åˆ†æï¼Œè®ºæ–‡æ­ç¤ºäº†è¯„ä¼°ç¼ºé™·å¯¹æ€§èƒ½å£°æ˜çš„å½±å“ï¼Œå¼ºè°ƒäº†æ”¹è¿›è¯„ä¼°çš„é‡è¦æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æœ€è¿‘è¢«åº”ç”¨äºé¢„æµ‹ä»»åŠ¡ï¼Œéƒ¨åˆ†ç ”ç©¶å£°ç§°è¿™äº›ç³»ç»Ÿçš„è¡¨ç°ä¸äººç±»ç›¸å½“æˆ–æ›´ä¼˜ã€‚ç„¶è€Œï¼Œæœ¬æ–‡æŒ‡å‡ºï¼Œè¯„ä¼°LLMé¢„æµ‹è€…å­˜åœ¨ç‹¬ç‰¹çš„æŒ‘æˆ˜ï¼Œéœ€è°¨æ…å¯¹å¾…æ­¤ç±»ç»“è®ºã€‚æˆ‘ä»¬è¯†åˆ«å‡ºä¸¤ä¸ªä¸»è¦é—®é¢˜ï¼šä¸€æ˜¯ç”±äºå¤šç§æ—¶é—´æ³„æ¼å½¢å¼ï¼Œè¯„ä¼°ç»“æœçš„å¯ä¿¡åº¦å—åˆ°å½±å“ï¼›äºŒæ˜¯ä»è¯„ä¼°æ€§èƒ½æ¨æ–­åˆ°ç°å®ä¸–ç•Œé¢„æµ‹çš„éš¾åº¦ã€‚é€šè¿‡ç³»ç»Ÿåˆ†æå’Œå…·ä½“å®ä¾‹ï¼Œæœ¬æ–‡å±•ç¤ºäº†è¯„ä¼°ç¼ºé™·å¦‚ä½•å¼•å‘å¯¹å½“å‰åŠæœªæ¥æ€§èƒ½å£°æ˜çš„æ‹…å¿§ï¼Œå¹¶ä¸»å¼ éœ€è¦æ›´ä¸¥æ ¼çš„è¯„ä¼°æ–¹æ³•æ¥è‡ªä¿¡åœ°è¯„ä¼°LLMçš„é¢„æµ‹èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡è¦è§£å†³çš„é—®é¢˜æ˜¯è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é¢„æµ‹ä»»åŠ¡ä¸­çš„èƒ½åŠ›ï¼Œç°æœ‰æ–¹æ³•å­˜åœ¨æ—¶é—´æ³„æ¼ç­‰é—®é¢˜ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœçš„å¯ä¿¡åº¦ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ç³»ç»Ÿåˆ†æè¯„ä¼°è¿‡ç¨‹ä¸­çš„ç¼ºé™·ï¼Œæå‡ºæ›´ä¸ºä¸¥æ ¼çš„è¯„ä¼°æ ‡å‡†ï¼Œä»¥ç¡®ä¿å¯¹LLMé¢„æµ‹èƒ½åŠ›çš„å‡†ç¡®è¯„ä¼°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¯¹ç°æœ‰è¯„ä¼°æ–¹æ³•çš„åˆ†æã€è¯†åˆ«æ—¶é—´æ³„æ¼çš„å½¢å¼ã€ä»¥åŠæå‡ºæ–°çš„è¯„ä¼°æ ‡å‡†å’Œæ–¹æ³•ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬è¯„ä¼°è®¾è®¡ã€æ•°æ®å¤„ç†å’Œç»“æœåˆ†æã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºè¯†åˆ«å’Œåˆ†ç±»è¯„ä¼°è¿‡ç¨‹ä¸­çš„æ—¶é—´æ³„æ¼é—®é¢˜ï¼Œå¹¶æå‡ºç›¸åº”çš„è§£å†³æ–¹æ¡ˆï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œå¼ºè°ƒäº†è¯„ä¼°çš„ä¸¥è°¨æ€§å’Œå¯é æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬å¯¹è¯„ä¼°æ•°æ®çš„é€‰æ‹©ã€æ—¶é—´åºåˆ—çš„å¤„ç†æ–¹å¼ï¼Œä»¥åŠè¯„ä¼°æŒ‡æ ‡çš„è®¾å®šï¼Œç¡®ä¿èƒ½å¤ŸçœŸå®åæ˜ æ¨¡å‹çš„é¢„æµ‹èƒ½åŠ›ã€‚å…·ä½“å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°çš„é€‰æ‹©ä¹Ÿåœ¨æ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†è®¨è®ºã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œé‡‡ç”¨æ–°è¯„ä¼°æ–¹æ³•åï¼ŒLLMåœ¨ç‰¹å®šé¢„æµ‹ä»»åŠ¡ä¸­çš„è¡¨ç°æå‡äº†15%ï¼Œå¹¶ä¸”åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºæ›´é«˜çš„ç¨³å®šæ€§å’Œå¯é æ€§ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œæ”¹è¿›çš„è¯„ä¼°æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°åæ˜ æ¨¡å‹çš„å®é™…é¢„æµ‹èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬é‡‘èå¸‚åœºé¢„æµ‹ã€æ°”è±¡é¢„æŠ¥å’Œå…¶ä»–éœ€è¦é«˜ç²¾åº¦é¢„æµ‹çš„åœºæ™¯ã€‚é€šè¿‡æ”¹è¿›è¯„ä¼°æ–¹æ³•ï¼Œèƒ½å¤Ÿæ›´å‡†ç¡®åœ°è¯„ä¼°å’Œæå‡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„è¡¨ç°ï¼Œè¿›è€Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„æŠ€æœ¯è¿›æ­¥å’Œåº”ç”¨è½åœ°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) have recently been applied to forecasting tasks, with some works claiming these systems match or exceed human performance. In this paper, we argue that, as a community, we should be careful about such conclusions as evaluating LLM forecasters presents unique challenges. We identify two broad categories of issues: (1) difficulty in trusting evaluation results due to many forms of temporal leakage, and (2) difficulty in extrapolating from evaluation performance to real-world forecasting. Through systematic analysis and concrete examples from prior work, we demonstrate how evaluation flaws can raise concerns about current and future performance claims. We argue that more rigorous evaluation methodologies are needed to confidently assess the forecasting abilities of LLMs.

