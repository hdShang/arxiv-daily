---
layout: default
title: Applying Large Language Models to Issue Classification: Revisiting with Extended Data and New Models
---

# Applying Large Language Models to Issue Classification: Revisiting with Extended Data and New Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.00128" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.00128v1</a>
  <a href="https://arxiv.org/pdf/2506.00128.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.00128v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.00128v1', 'Applying Large Language Models to Issue Classification: Revisiting with Extended Data and New Models')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Gabriel Aracena, Kyle Luster, Fabio Santos, Igor Steinmacher, Marco A. Gerosa

**ÂàÜÁ±ª**: cs.SE, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-30

**Â§áÊ≥®**: 35 pages, 2 figures, 9 tables, Pre-print for Science of Computer Programming

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑËá™Âä®ÂåñÈóÆÈ¢òÂàÜÁ±ªÊñπÊ≥ï**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§ßËØ≠Ë®ÄÊ®°Âûã` `Áº∫Èô∑ÂàÜÁ±ª` `Ëá™Âä®ÂåñÊµÅÁ®ã` `ËΩØ‰ª∂Â∑•Á®ã` `Êú∫Âô®Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÊâãÂä®Áº∫Èô∑ÂàÜÁ±ªÊñπÊ≥ïË¥πÊó∂‰∏îÈöæ‰ª•Êâ©Â±ïÔºåËá™Âä®ÂåñÊµÅÁ®ãÂæÄÂæÄ‰æùËµñ‰∫éÂ§ßËßÑÊ®°Êï∞ÊçÆÈõÜËøõË°åËÆ≠ÁªÉ„ÄÇ
2. Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÁº∫Èô∑ÂàÜÁ±ªÊñπÊ≥ïÔºåÊó®Âú®ÂáèÂ∞ëÂØπÂ§ßÈáèËÆ≠ÁªÉÊï∞ÊçÆÁöÑÈúÄÊ±ÇÔºåÂêåÊó∂‰øùÊåÅÂàÜÁ±ªÁöÑÂáÜÁ°ÆÊÄß„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåGPT-4oÊ®°ÂûãÂú®Áº∫Èô∑ÂàÜÁ±ª‰∏≠Ë°®Áé∞‰ºòÂºÇÔºåF1ÂæóÂàÜËææ80.7%ÔºåÊòæËëóÈ´ò‰∫éDeepSeek R1ÁöÑ59.33%„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÊúâÊïàÁöÑÁº∫Èô∑Êä•Âëä‰ºòÂÖàÁ∫ßÂàíÂàÜÂú®ËΩØ‰ª∂Â∑•Á®ã‰∏≠ÊúâÂä©‰∫é‰ºòÂåñËµÑÊ∫êÂàÜÈÖçÂíå‰ø°ÊÅØÊÅ¢Â§ç„ÄÇÁÑ∂ËÄåÔºåÊâãÂä®ÂàÜÁ±ªÁº∫Èô∑Êó¢Ë¥πÊó∂ÂèàÁº∫‰πèÂèØÊâ©Â±ïÊÄß„ÄÇËÆ∏Â§öÂºÄÊ∫êËΩØ‰ª∂È°πÁõÆÈááÁî®Ëá™Âä®ÂåñÊµÅÁ®ãËøõË°åÂàÜÁ±ªÔºå‰ΩÜÈÄöÂ∏∏‰æùËµñ‰∫éÂ§ßÈáèÊï∞ÊçÆÈõÜËøõË°åËÆ≠ÁªÉ„ÄÇÊú¨ÊñáÁ†îÁ©∂‰∫Ü‰∏ÄÁßçÂü∫‰∫éÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÁöÑËá™Âä®ÂåñÁº∫Èô∑ÂàÜÁ±ªÊñπÊ≥ïÔºåÊó®Âú®ÂáèÂ∞ëÂØπÂ§ßËßÑÊ®°ËÆ≠ÁªÉÊï∞ÊçÆÁöÑ‰æùËµñÔºåÂêåÊó∂‰øùÊåÅÂàÜÁ±ªÁöÑÂèØÈù†ÊÄß„ÄÇÁ†îÁ©∂‰∏≠ÔºåÊàë‰ª¨ÈÄâÊã©‰∫Ü‰∏§Áßç‰∏ªË¶ÅÁöÑÂ§ßËØ≠Ë®ÄÊ®°ÂûãËøõË°åÊØîËæÉÔºåÁªìÊûúÊòæÁ§∫GPT-4oÂú®NLBSE 2024Á´ûËµõ‰∏≠ÁöÑÁº∫Èô∑ÂàÜÁ±ªË°®Áé∞ÊúÄ‰Ω≥ÔºåÂÖ∂F1ÂæóÂàÜÊØîDeepSeek R1È´òÂá∫20%„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥ËΩØ‰ª∂Â∑•Á®ã‰∏≠Áº∫Èô∑Êä•ÂëäÂàÜÁ±ªÁöÑÊïàÁéá‰Ωé‰∏ãÂíåÂèØÊâ©Â±ïÊÄß‰∏çË∂≥ÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÁöÑÊâãÂä®ÂàÜÁ±ªÊñπÊ≥ïËÄóÊó∂‰∏îÈöæ‰ª•ÈÄÇÂ∫îÂ§ßËßÑÊ®°È°πÁõÆÁöÑÈúÄÊ±Ç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÈÄöËøáÂà©Áî®Â§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÂº∫Â§ßËÉΩÂäõÔºåÂºÄÂèë‰∏ÄÁßçËá™Âä®ÂåñÁöÑÁº∫Èô∑ÂàÜÁ±ªÁ≥ªÁªüÔºåÂáèÂ∞ëÂØπÂ§ßËßÑÊ®°ËÆ≠ÁªÉÊï∞ÊçÆÁöÑ‰æùËµñÔºåÂêåÊó∂Á°Æ‰øùÂàÜÁ±ªÁöÑÂèØÈù†ÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÁ†îÁ©∂‰∏≠ÈááÁî®‰∫Ü‰∏§Áßç‰∏ªË¶ÅÁöÑÂ§ßËØ≠Ë®ÄÊ®°ÂûãËøõË°åÊØîËæÉÔºåÊûÑÂª∫‰∫Ü‰∏Ä‰∏™ÂåÖÂê´Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ„ÄÅÊ®°ÂûãËÆ≠ÁªÉÂíåËØÑ‰º∞ÁöÑÊï¥‰ΩìÊ°ÜÊû∂„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞Âú®‰∫é‰ΩøÁî®Â§ßËØ≠Ë®ÄÊ®°ÂûãËøõË°åÁº∫Èô∑ÂàÜÁ±ªÔºåÊòæËëóÊèêÈ´ò‰∫ÜÂàÜÁ±ªÂáÜÁ°ÆÊÄßÔºåÂπ∂ÂáèÂ∞ë‰∫ÜÂØπÂ§ßÈáèÊï∞ÊçÆÈõÜÁöÑÈúÄÊ±Ç„ÄÇ‰∏é‰º†ÁªüÊñπÊ≥ïÁõ∏ÊØîÔºåËøôÁßçÊñπÊ≥ïÂú®ÂáÜÁ°ÆÊÄßÂíåÊïàÁéá‰∏äÈÉΩÊúâÊâÄÊèêÂçá„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Ê®°ÂûãËÆ≠ÁªÉ‰∏≠ÔºåÈááÁî®‰∫ÜÈíàÂØπÁâπÂÆö‰ªªÂä°ÁöÑÂæÆË∞ÉÁ≠ñÁï•ÔºåÈÄâÊã©‰∫ÜÂêàÈÄÇÁöÑÊçüÂ§±ÂáΩÊï∞ÂíåË∂ÖÂèÇÊï∞ËÆæÁΩÆÔºå‰ª•‰ºòÂåñÊ®°ÂûãÊÄßËÉΩ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåGPT-4oÊ®°ÂûãÂú®NLBSE 2024Á´ûËµõ‰∏≠ÁöÑÁº∫Èô∑ÂàÜÁ±ª‰ªªÂä°‰∏≠ÂèñÂæó‰∫Ü80.7%ÁöÑF1ÂæóÂàÜÔºåÊòæËëóÈ´ò‰∫éDeepSeek R1ÁöÑ59.33%„ÄÇÊ≠§Â§ñÔºåÂ¢ûÂä†Êï∞ÊçÆÈõÜËßÑÊ®°Âπ∂Êú™ÊèêÂçáF1ÂæóÂàÜÔºåË°®ÊòéËØ•ÊñπÊ≥ïÂú®Êï∞ÊçÆÈúÄÊ±Ç‰∏äÁöÑ‰ºòÂäø„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨ÂºÄÊ∫êËΩØ‰ª∂È°πÁõÆÁöÑÁº∫Èô∑ÁÆ°ÁêÜ„ÄÅËΩØ‰ª∂ÂºÄÂèëÁîüÂëΩÂë®Êúü‰∏≠ÁöÑÈóÆÈ¢òËøΩË∏™Âíå‰ºòÂÖàÁ∫ßÂàíÂàÜ„ÄÇÈÄöËøáËá™Âä®ÂåñÁº∫Èô∑ÂàÜÁ±ªÔºåÂºÄÂèëÂõ¢ÈòüÂèØ‰ª•Êõ¥È´òÊïàÂú∞ÂàÜÈÖçËµÑÊ∫êÔºåÊèêÂçáËΩØ‰ª∂Ë¥®ÈáèÂíåÂºÄÂèëÊïàÁéá„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïÊúâÊúõÊé®ÂπøÂà∞ÂÖ∂‰ªñÈ¢ÜÂüüÁöÑÊñáÊú¨ÂàÜÁ±ª‰ªªÂä°‰∏≠„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Effective prioritization of issue reports in software engineering helps to optimize resource allocation and information recovery. However, manual issue classification is laborious and lacks scalability. As an alternative, many open source software (OSS) projects employ automated processes for this task, yet this method often relies on large datasets for adequate training. Traditionally, machine learning techniques have been used for issue classification. More recently, large language models (LLMs) have emerged as powerful tools for addressing a range of software engineering challenges, including code and test generation, mapping new requirements to legacy software endpoints, and conducting code reviews. The following research investigates an automated approach to issue classification based on LLMs. By leveraging the capabilities of such models, we aim to develop a robust system for prioritizing issue reports, mitigating the necessity for extensive training data while also maintaining reliability in classification. In our research, we developed an LLM-based approach for accurately labeling issues by selecting two of the most prominent large language models. We then compared their performance across multiple datasets. Our findings show that GPT-4o achieved the best results in classifying issues from the NLBSE 2024 competition. Moreover, GPT-4o outperformed DeepSeek R1, achieving an F1 score 20% higher when both models were trained on the same dataset from the NLBSE 2023 competition, which was ten times larger than the NLBSE 2024 dataset. The fine-tuned GPT-4o model attained an average F1 score of 80.7%, while the fine-tuned DeepSeek R1 model achieved 59.33%. Increasing the dataset size did not improve the F1 score, reducing the dependence on massive datasets for building an efficient solution to issue classification.

