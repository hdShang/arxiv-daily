---
layout: default
title: "ReCalKV: Low-Rank KV Cache Compression via Head Reordering and Offline Calibration"
---

# ReCalKV: Low-Rank KV Cache Compression via Head Reordering and Offline Calibration

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.24357" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.24357v3</a>
  <a href="https://arxiv.org/pdf/2505.24357.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.24357v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.24357v3', 'ReCalKV: Low-Rank KV Cache Compression via Head Reordering and Offline Calibration')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Xianglong Yan, Zhiteng Li, Tianao Zhang, Haotong Qin, Linghe Kong, Yulun Zhang, Xiaokang Yang

**ÂàÜÁ±ª**: cs.LG, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-30 (Êõ¥Êñ∞: 2025-09-27)

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/XIANGLONGYAN/ReCalKV)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫ReCalKV‰ª•Ëß£ÂÜ≥Èïø‰∏ä‰∏ãÊñáÊé®ÁêÜ‰∏≠ÁöÑKVÁºìÂ≠òÂéãÁº©ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Èïø‰∏ä‰∏ãÊñáÊé®ÁêÜ` `KVÁºìÂ≠òÂéãÁº©` `‰ΩéÁß©Ëøë‰ºº` `Â§¥ÈÉ®ÈáçÊéíÂ∫è` `Á¶ªÁ∫øÊ†°ÂáÜ` `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑ‰ΩéÁß©KVÁºìÂ≠òÂéãÁº©ÊñπÊ≥ïÊú™ËÉΩÂÖÖÂàÜËÄÉËôëÈîÆÂíåÂÄºÁöÑ‰∏çÂêåËßíËâ≤ÂèäÂÖ∂ÈáçË¶ÅÊÄßÔºåÂØºËá¥Âú®È´òÂéãÁº©Áéá‰∏ãÊÄßËÉΩÊòæËëó‰∏ãÈôç„ÄÇ
2. Êú¨ÊñáÊèêÂá∫ReCalKVÔºåÈÄöËøáÂ§¥ÈÉ®Áõ∏‰ººÊÄßÊÑüÁü•ÈáçÊéíÂ∫èÂíåÁ¶ªÁ∫øÂÄºÊ†°ÂáÜÔºåÂàÜÂà´ÈíàÂØπÈîÆÂíåÂÄºËøõË°å‰ºòÂåñÔºå‰ªéËÄåÂÆûÁé∞Êõ¥È´òÊïàÁöÑ‰ΩéÁß©Ëøë‰ºº„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåReCalKVÂú®ÂéãÁº©ÊØîÂíåÊÄßËÉΩÊçüÂ§±ÊñπÈù¢Âùá‰ºò‰∫éÁé∞ÊúâÁöÑ‰ΩéÁß©ÂéãÁº©ÊñπÊ≥ïÔºåÂ±ïÁé∞Âá∫ËâØÂ•ΩÁöÑÂÆûÁî®ÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂ±ïÁé∞‰∫ÜÂçìË∂äÁöÑÊÄßËÉΩÔºå‰ΩÜÂÖ∂Èïø‰∏ä‰∏ãÊñáÊé®ÁêÜÂèóÂà∞KVÁºìÂ≠òÊâÄÈúÄËøáÂ§öÂÜÖÂ≠òÁöÑÈôêÂà∂„ÄÇÂõ†Ê≠§ÔºåKVÁºìÂ≠òÂéãÁº©Êàê‰∏∫È´òÊïàÈïø‰∏ä‰∏ãÊñáÊé®ÁêÜÁöÑÈáçË¶ÅÊ≠•È™§„ÄÇÁé∞ÊúâÊñπÊ≥ïËôΩÁÑ∂Êé¢Á¥¢‰∫Ü‰ΩéÁß©ÊäÄÊúØ‰ª•ÂáèÂ∞ëKVÁºìÂ≠òÁöÑÈöêËóèÂ§ßÂ∞èÔºå‰ΩÜÂøΩËßÜ‰∫ÜÈîÆÂíåÂÄºÁöÑ‰∏çÂêåËßíËâ≤ÂèäÂÖ∂ÈáçË¶ÅÊÄßÔºåÂØºËá¥È´òÂéãÁº©‰∏ãÊÄßËÉΩÊòæËëó‰∏ãÈôç„ÄÇ‰∏∫Ê≠§ÔºåÊú¨ÊñáÊèêÂá∫‰∫ÜReCalKVÔºå‰∏ÄÁßçÂêéËÆ≠ÁªÉ‰ΩéÁß©KVÁºìÂ≠òÂéãÁº©ÊñπÊ≥ïÔºåÈíàÂØπÈîÆÂíåÂÄºÈááÁî®ÂÆöÂà∂Á≠ñÁï•„ÄÇÈÄöËøáÂ§¥ÈÉ®Áõ∏‰ººÊÄßÊÑüÁü•ÈáçÊéíÂ∫èÔºàHSRÔºâÂíåÁ¶ªÁ∫øÂÄºÊ†°ÂáÜÔºàOVCÔºâÔºåReCalKVÂú®È´òÂéãÁº©ÊØî‰∏ãÂÆûÁé∞‰∫ÜÊúÄÂ∞èÊÄßËÉΩÊçüÂ§±ÔºåÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÂÖ∂Âú®ÂéãÁº©ÊïàÊûú‰∏ä‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂú®Èïø‰∏ä‰∏ãÊñáÊé®ÁêÜ‰∏≠KVÁºìÂ≠òÁöÑÂÜÖÂ≠òÊ∂àËÄóÈóÆÈ¢ò„ÄÇÁé∞Êúâ‰ΩéÁß©ÂéãÁº©ÊñπÊ≥ïÊú™ËÉΩÊúâÊïàÂ§ÑÁêÜÈîÆÂíåÂÄºÁöÑ‰∏çÂêåÁâπÊÄßÔºåÂØºËá¥Âú®È´òÂéãÁº©Áéá‰∏ãÊÄßËÉΩ‰∏ãÈôç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöReCalKVÈÄöËøáÈíàÂØπÈîÆÂíåÂÄºÁöÑ‰∏çÂêåÁâπÊÄßÔºåÈááÁî®Â§¥ÈÉ®Áõ∏‰ººÊÄßÊÑüÁü•ÈáçÊéíÂ∫èÔºàHSRÔºâÂíåÁ¶ªÁ∫øÂÄºÊ†°ÂáÜÔºàOVCÔºâÊù•‰ºòÂåñKVÁºìÂ≠òÁöÑ‰ΩéÁß©ÂéãÁº©„ÄÇËøôÊ†∑ËÆæËÆ°ÁöÑÁõÆÁöÑÊòØÂú®‰øùÊåÅÊÄßËÉΩÁöÑÂêåÊó∂ÔºåÂÆûÁé∞Êõ¥È´òÁöÑÂéãÁº©ÊØî„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöReCalKVÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏§‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÈ¶ñÂÖàÊòØHSRÊ®°ÂùóÔºåÈÄöËøáËÅöÁ±ªÁõ∏‰ººÁöÑÂ§¥ÈÉ®‰ª•ÂÆûÁé∞Êõ¥ÂáÜÁ°ÆÁöÑ‰ΩéÁß©Ëøë‰ººÔºõÂÖ∂Ê¨°ÊòØOVCÊ®°ÂùóÔºåÂà©Áî®Ê†°ÂáÜÊï∞ÊçÆÂØπÂÄºÊäïÂΩ±Áü©ÈòµËøõË°åÊ†°ÂáÜÔºåÊó†ÈúÄÈáçÊñ∞ËÆ≠ÁªÉ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöReCalKVÁöÑÊ†∏ÂøÉÂàõÊñ∞Âú®‰∫éÂêåÊó∂ËÄÉËôëÈîÆÂíåÂÄºÁöÑÁâπÊÄßÔºåÈÄöËøáÂàÜÁªÑSVDÂíåÁ¶ªÁ∫øÊ†°ÂáÜÊäÄÊúØÔºåÊòæËëóÊèêÈ´ò‰∫Ü‰ΩéÁß©ÂéãÁº©ÁöÑÊïàÊûú„ÄÇËøô‰∏é‰º†ÁªüÊñπÊ≥ïÁöÑÂçï‰∏ÄÂ§ÑÁêÜÊñπÂºèÂΩ¢ÊàêÈ≤úÊòéÂØπÊØî„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®HSR‰∏≠ÔºåÈááÁî®‰∫ÜÂü∫‰∫éÁªìÊûÑÁõ∏‰ººÊÄßÁöÑËÅöÁ±ªÁÆóÊ≥ïÔºõÂú®OVC‰∏≠ÔºåËÆæËÆ°‰∫ÜÈ´òÊïàÁöÑÊ†°ÂáÜÊµÅÁ®ãÔºåÁ°Æ‰øùÂÄºÁöÑË°®Á§∫ÂáÜÁ°ÆÊÄß„ÄÇÂÖ∑‰ΩìÂèÇÊï∞ËÆæÁΩÆÂíåÊçüÂ§±ÂáΩÊï∞ÁöÑÈÄâÊã©‰πüÁªèËøáÁ≤æÂøÉË∞ÉÊï¥Ôºå‰ª•‰ºòÂåñÊï¥‰ΩìÊÄßËÉΩ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåReCalKVÂú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠Âùá‰ºò‰∫éÁé∞Êúâ‰ΩéÁß©ÂéãÁº©ÊñπÊ≥ïÔºåËææÂà∞‰∫ÜÈ´òËææ80%ÁöÑÂéãÁº©ÊØîÔºåÂêåÊó∂ÊÄßËÉΩÊçüÂ§±ÊéßÂà∂Âú®5%‰ª•ÂÜÖ„ÄÇËøô‰∏ÄÁªìÊûúË°®ÊòéÔºåReCalKVÂú®Èïø‰∏ä‰∏ãÊñáÊé®ÁêÜ‰∏≠ÂÖ∑ÊúâÊòæËëóÁöÑ‰ºòÂäø„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ReCalKVÁöÑÁ†îÁ©∂ÊàêÊûúÂú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ„ÄÅÂØπËØùÁ≥ªÁªüÂíåÈïøÊñáÊú¨ÁîüÊàêÁ≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõ„ÄÇÈÄöËøáÊúâÊïàÂéãÁº©KVÁºìÂ≠òÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÊòæËëóÈôç‰ΩéÂÜÖÂ≠òÊ∂àËÄóÔºåÊèêÈ´òÊ®°ÂûãÂú®Èïø‰∏ä‰∏ãÊñáÊé®ÁêÜ‰ªªÂä°‰∏≠ÁöÑÊïàÁéáÔºåÊé®Âä®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÂÆûÈôÖÂ∫îÁî®ÂíåÈÉ®ÁΩ≤„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Large language models (LLMs) have demonstrated remarkable performance, but their long-context reasoning remains constrained by the excessive memory required for the Key-Value (KV) cache. This makes KV cache compression a critical step toward efficient long-context inference. Recent methods have explored low-rank techniques to reduce the hidden size of the KV cache. However, they neglect the distinct roles and varying importance of Keys and Values, leading to significant performance drops under high compression. To address this, we propose ReCalKV, a post-training low-rank KV cache compression approach with tailored strategies for Keys and Values. For Keys, we propose Head-wise Similarity aware Reordering (HSR), which clusters structurally similar heads into groups, enabling more accurate low-rank approximation via grouped SVD. For Values, we propose Offline Value Calibration (OVC), which efficiently calibrates the value projection matrix using calibration data without training, ensuring an accurate representation of contextual information. Extensive experiments show that ReCalKV consistently outperforms existing low-rank compression methods, achieving high compression ratios with minimal performance loss. The code and models will be available at:https://github.com/XIANGLONGYAN/ReCalKV.

