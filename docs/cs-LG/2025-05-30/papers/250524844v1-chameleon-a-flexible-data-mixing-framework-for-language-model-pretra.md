---
layout: default
title: "Chameleon: A Flexible Data-mixing Framework for Language Model Pretraining and Finetuning"
---

# Chameleon: A Flexible Data-mixing Framework for Language Model Pretraining and Finetuning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.24844" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.24844v1</a>
  <a href="https://arxiv.org/pdf/2505.24844.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.24844v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.24844v1', 'Chameleon: A Flexible Data-mixing Framework for Language Model Pretraining and Finetuning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wanyun Xie, Francesco Tonin, Volkan Cevher

**åˆ†ç±»**: cs.LG, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-30

**å¤‡æ³¨**: ICML 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/LIONS-EPFL/Chameleon)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºChameleonæ¡†æ¶ä»¥é«˜æ•ˆæ··åˆæ•°æ®æå‡è¯­è¨€æ¨¡å‹æ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ•°æ®æ··åˆ` `è¯­è¨€æ¨¡å‹` `é¢†åŸŸé‡åŠ æƒ` `æ æ†åˆ†æ•°` `æ¨¡å‹å¾®è°ƒ` `å°‘æ ·æœ¬å­¦ä¹ ` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„é¢†åŸŸé‡åŠ æƒæ–¹æ³•è®¡ç®—æˆæœ¬é«˜ï¼Œå¹¶åœ¨æ–°æ•°æ®å¼•å…¥æ—¶éœ€è¦é‡æ–°è®­ç»ƒï¼Œé™åˆ¶äº†å…¶çµæ´»æ€§å’Œæ•ˆç‡ã€‚
2. Chameleonæ¡†æ¶é€šè¿‡æ æ†åˆ†æ•°é‡åŒ–é¢†åŸŸé‡è¦æ€§ï¼Œæ„å»ºé¢†åŸŸäº²å’ŒçŸ©é˜µï¼Œå®ç°æ•°æ®çš„é«˜æ•ˆæ··åˆå’Œé€‚åº”ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒChameleonåœ¨é¢„è®­ç»ƒå’Œå¾®è°ƒé˜¶æ®µå‡æ˜¾è‘—æå‡äº†æ¨¡å‹æ€§èƒ½ï¼Œè®¡ç®—æˆæœ¬è¿œä½äºä¼ ç»Ÿæ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è®­ç»ƒæ•°æ®çš„æ··åˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹çš„æ³›åŒ–æ€§èƒ½æœ‰é‡è¦å½±å“ã€‚ç°æœ‰çš„é¢†åŸŸé‡åŠ æƒæ–¹æ³•é€šå¸¸ä¾èµ–äºæ˜‚è´µçš„æƒé‡è®¡ç®—ï¼Œå¹¶åœ¨å¼•å…¥æ–°æ•°æ®æ—¶éœ€è¦é‡æ–°è®­ç»ƒã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§çµæ´»é«˜æ•ˆçš„æ•°æ®æ··åˆæ¡†æ¶Chameleonï¼Œè¯¥æ¡†æ¶åˆ©ç”¨æ æ†åˆ†æ•°åœ¨å­¦ä¹ çš„åµŒå…¥ç©ºé—´ä¸­é‡åŒ–é¢†åŸŸçš„é‡è¦æ€§ã€‚æˆ‘ä»¬é¦–å…ˆæ„å»ºäº†ä¸€ä¸ªé¢†åŸŸäº²å’ŒçŸ©é˜µï¼Œæ æ†åˆ†æ•°çš„å¼•å…¥å†³å®šäº†ä¸€ä¸ªæ··åˆæ–¹æ¡ˆï¼Œè¯¥æ–¹æ¡ˆæå‡äº†åœ¨åµŒå…¥ç©ºé—´ä¸­å…±äº«å…±åŒè¡¨ç¤ºçš„é¢†åŸŸçš„æƒé‡ã€‚è¯¥å…¬å¼å…è®¸é€šè¿‡è®¡ç®—æ–°çš„é¢†åŸŸåµŒå…¥ç›´æ¥è½¬ç§»åˆ°æ–°æ•°æ®ä¸Šã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸‰ä¸ªå…³é”®åœºæ™¯ä¸­å‡æœ‰æ”¹è¿›ï¼šè®¡ç®—çš„æƒé‡åœ¨é¢„è®­ç»ƒé¢†åŸŸçš„æ€§èƒ½æå‡ä¸Šï¼Œè®¡ç®—æˆæœ¬ä»…ä¸ºç°æœ‰æ–¹æ³•çš„ä¸€å°éƒ¨åˆ†ï¼›Chameleonèƒ½å¤Ÿåœ¨æ•°æ®å˜åŒ–æ—¶é€‚åº”ï¼Œæ— éœ€ä»£ç†é‡æ–°è®­ç»ƒï¼Œæå‡äº†åœ¨æ–°æ•°æ®ä¸Šçš„å°‘æ ·æœ¬æ¨ç†å‡†ç¡®æ€§ï¼›æˆ‘ä»¬çš„æ–¹æ¡ˆåœ¨å¾®è°ƒä¸­å®ç°äº†é«˜æ•ˆçš„é¢†åŸŸé‡åŠ æƒï¼Œå§‹ç»ˆæ”¹å–„äº†æ‰€æœ‰å¾®è°ƒé¢†åŸŸçš„æµ‹è¯•å›°æƒ‘åº¦ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰é¢†åŸŸé‡åŠ æƒæ–¹æ³•åœ¨æ–°æ•°æ®å¼•å…¥æ—¶çš„é«˜è®¡ç®—æˆæœ¬å’Œé‡æ–°è®­ç»ƒçš„éœ€æ±‚ï¼Œå¯¼è‡´çµæ´»æ€§ä¸è¶³çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šChameleonæ¡†æ¶é€šè¿‡æ æ†åˆ†æ•°æ¥é‡åŒ–é¢†åŸŸçš„é‡è¦æ€§ï¼Œåˆ©ç”¨é¢†åŸŸåµŒå…¥æ„å»ºäº²å’ŒçŸ©é˜µï¼Œä»è€Œå®ç°é«˜æ•ˆçš„æ•°æ®æ··åˆå’Œé€‚åº”æ–°æ•°æ®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šChameleonçš„æ•´ä½“æ¶æ„åŒ…æ‹¬é¢†åŸŸåµŒå…¥çš„æ„å»ºã€é¢†åŸŸäº²å’ŒçŸ©é˜µçš„ç”Ÿæˆä»¥åŠåŸºäºæ æ†åˆ†æ•°çš„æƒé‡è®¡ç®—ã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿç›´æ¥åº”ç”¨äºæ–°æ•°æ®ï¼Œæ— éœ€é‡æ–°è®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šChameleonçš„ä¸»è¦åˆ›æ–°åœ¨äºä½¿ç”¨æ æ†åˆ†æ•°æ¥é‡åŒ–é¢†åŸŸé‡è¦æ€§ï¼Œå…è®¸æ¨¡å‹åœ¨é¢å¯¹æ–°æ•°æ®æ—¶å¿«é€Ÿé€‚åº”ï¼Œæ˜¾è‘—æé«˜äº†æ•ˆç‡å’Œæ€§èƒ½ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒChameleonå‡å°‘äº†è®¡ç®—å¤æ‚åº¦å¹¶æå‡äº†çµæ´»æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼ŒChameleoné€šè¿‡ä¼˜åŒ–é¢†åŸŸäº²å’ŒçŸ©é˜µå’Œæ æ†åˆ†æ•°çš„è®¡ç®—ï¼Œç¡®ä¿äº†æ¨¡å‹åœ¨ä¸åŒé¢†åŸŸé—´çš„æœ‰æ•ˆè¿ç§»ã€‚æŸå¤±å‡½æ•°è®¾è®¡ä¸Šï¼Œå¼ºè°ƒäº†é¢†åŸŸé—´çš„ç›¸ä¼¼æ€§ï¼Œä»¥å¢å¼ºæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒChameleonåœ¨é¢„è®­ç»ƒé˜¶æ®µçš„æ€§èƒ½æå‡æ˜¾è‘—ï¼Œè®¡ç®—æˆæœ¬ä»…ä¸ºç°æœ‰æ–¹æ³•çš„ä¸€ä¸ªå°éƒ¨åˆ†ã€‚æ­¤å¤–ï¼Œåœ¨å°‘æ ·æœ¬æ¨ç†ä»»åŠ¡ä¸­ï¼ŒChameleonèƒ½å¤Ÿåœ¨æ–°æ•°æ®ä¸Šæå‡å‡†ç¡®æ€§ï¼Œå¾®è°ƒé˜¶æ®µçš„æµ‹è¯•å›°æƒ‘åº¦ä¹Ÿåœ¨æ‰€æœ‰é¢†åŸŸä¸­å‡æœ‰æ”¹å–„ï¼Œæ˜¾ç¤ºå‡ºå…¶å¼ºå¤§çš„é€‚åº”èƒ½åŠ›å’Œæ•ˆç‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Chameleonæ¡†æ¶åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ã€æœºå™¨ç¿»è¯‘å’Œå¯¹è¯ç³»ç»Ÿç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚å…¶é«˜æ•ˆçš„æ•°æ®æ··åˆèƒ½åŠ›èƒ½å¤Ÿå¸®åŠ©æ¨¡å‹æ›´å¥½åœ°é€‚åº”ä¸æ–­å˜åŒ–çš„æ•°æ®ç¯å¢ƒï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œå®é™…åº”ç”¨æ•ˆæœã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶å¯èƒ½æ¨åŠ¨æ›´å¤šé¢†åŸŸçš„æ™ºèƒ½åº”ç”¨å‘å±•ï¼Œæå‡äººæœºäº¤äº’çš„è´¨é‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Training data mixtures greatly impact the generalization performance of large language models. Existing domain reweighting methods often rely on costly weight computations and require retraining when new data is introduced. To this end, we introduce a flexible and efficient data mixing framework, Chameleon, that employs leverage scores to quantify domain importance within a learned embedding space. We first construct a domain affinity matrix over domain embeddings. The induced leverage scores determine a mixture that upweights domains sharing common representations in embedding space. This formulation allows direct transfer to new data by computing the new domain embeddings. In experiments, we demonstrate improvements over three key scenarios: (i) our computed weights improve performance on pretraining domains with a fraction of the compute of existing methods; (ii) Chameleon can adapt to data changes without proxy retraining, boosting few-shot reasoning accuracies when transferred to new data; (iii) our method enables efficient domain reweighting in finetuning, consistently improving test perplexity on all finetuning domains over uniform mixture. Our code is available at https://github.com/LIONS-EPFL/Chameleon.

