---
layout: default
title: AReaL: A Large-Scale Asynchronous Reinforcement Learning System for Language Reasoning
---

# AReaL: A Large-Scale Asynchronous Reinforcement Learning System for Language Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.24298" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.24298v4</a>
  <a href="https://arxiv.org/pdf/2505.24298.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.24298v4" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.24298v4', 'AReaL: A Large-Scale Asynchronous Reinforcement Learning System for Language Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wei Fu, Jiaxuan Gao, Xujie Shen, Chen Zhu, Zhiyu Mei, Chuyi He, Shusheng Xu, Guo Wei, Jun Mei, Jiashu Wang, Tongkai Yang, Binhang Yuan, Yi Wu

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-30 (æ›´æ–°: 2025-11-25)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/inclusionAI/AReaL/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAReaLä»¥è§£å†³å¤§è§„æ¨¡è¯­è¨€æ¨ç†çš„å¼‚æ­¥å¼ºåŒ–å­¦ä¹ é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¼‚æ­¥å¼ºåŒ–å­¦ä¹ ` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ¨ç†ä»»åŠ¡` `GPUåˆ©ç”¨ç‡` `ç³»ç»Ÿä¼˜åŒ–` `PPOå˜ä½“` `å¹¶è¡Œè®¡ç®—`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤§è§„æ¨¡RLç³»ç»Ÿå¤šä¸ºåŒæ­¥æ¨¡å¼ï¼Œå¯¼è‡´ç”Ÿæˆä¸è®­ç»ƒè¿‡ç¨‹ç›¸äº’ç­‰å¾…ï¼Œé€ æˆGPUèµ„æºçš„ä½æ•ˆåˆ©ç”¨ã€‚
2. AReaLé€šè¿‡å®Œå…¨å¼‚æ­¥çš„æ–¹å¼è§£è€¦ç”Ÿæˆä¸è®­ç»ƒï¼Œç”Ÿæˆå·¥ä½œè€…æŒç»­ç”Ÿæˆè¾“å‡ºï¼Œè®­ç»ƒå·¥ä½œè€…åœ¨æ”¶é›†åˆ°æ•°æ®åç«‹å³æ›´æ–°æ¨¡å‹ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAReaLåœ¨æ•°å­¦å’Œä»£ç æ¨ç†åŸºå‡†ä¸Šå®ç°äº†é«˜è¾¾2.77å€çš„è®­ç»ƒé€Ÿåº¦æå‡ï¼Œä¸”æœ€ç»ˆæ€§èƒ½ä¸åŒæ­¥ç³»ç»Ÿç›¸å½“æˆ–æ›´ä¼˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å·²æˆä¸ºè®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ä¸»æµæ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨æ¨ç†ä»»åŠ¡ä¸­ã€‚æœ‰æ•ˆçš„RLéœ€è¦å¤§è§„æ¨¡å¹¶è¡ŒåŒ–ï¼Œä½†ç°æœ‰çš„å¤§è§„æ¨¡RLç³»ç»Ÿå¤šä¸ºåŒæ­¥æ¨¡å¼ï¼Œå¯¼è‡´ç³»ç»Ÿæ•ˆç‡ä½ä¸‹ã€‚æœ¬æ–‡æå‡ºAReaLï¼Œä¸€ä¸ªå®Œå…¨å¼‚æ­¥çš„RLç³»ç»Ÿï¼Œè§£è€¦äº†ç”Ÿæˆä¸è®­ç»ƒè¿‡ç¨‹ï¼Œå…è®¸ç”Ÿæˆå·¥ä½œè€…æŒç»­è¾“å‡ºè€Œæ— éœ€ç­‰å¾…ï¼Œä»è€Œæé«˜GPUåˆ©ç”¨ç‡ã€‚AReaLé€šè¿‡å¹³è¡¡ç”Ÿæˆä¸è®­ç»ƒå·¥ä½œè€…çš„è´Ÿè½½ï¼Œæ§åˆ¶æ•°æ®é™ˆæ—§æ€§ï¼Œå¹¶é‡‡ç”¨å¢å¼ºé™ˆæ—§æ€§çš„PPOå˜ä½“æ¥å¤„ç†è¿‡æ—¶çš„è®­ç»ƒæ ·æœ¬ã€‚å®éªŒè¡¨æ˜ï¼ŒAReaLåœ¨æ•°å­¦å’Œä»£ç æ¨ç†åŸºå‡†ä¸Šå®ç°äº†é«˜è¾¾2.77å€çš„è®­ç»ƒåŠ é€Ÿï¼Œä¸”åœ¨ç›¸åŒGPUæ•°é‡ä¸‹æœ€ç»ˆæ€§èƒ½åŒ¹é…æˆ–æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰åŒæ­¥å¼ºåŒ–å­¦ä¹ ç³»ç»Ÿåœ¨è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹æ—¶çš„æ•ˆç‡ä½ä¸‹é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨ç”Ÿæˆä¸è®­ç»ƒè¿‡ç¨‹ä¸­å­˜åœ¨ç›¸äº’ç­‰å¾…ï¼Œå¯¼è‡´GPUèµ„æºæœªå¾—åˆ°å……åˆ†åˆ©ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šAReaLçš„æ ¸å¿ƒæ€è·¯æ˜¯é‡‡ç”¨å®Œå…¨å¼‚æ­¥çš„æ¶æ„ï¼Œå°†ç”Ÿæˆä¸è®­ç»ƒè¿‡ç¨‹è§£è€¦ã€‚ç”Ÿæˆå·¥ä½œè€…å¯ä»¥æŒç»­ç”Ÿæˆæ–°çš„è¾“å‡ºï¼Œè€Œè®­ç»ƒå·¥ä½œè€…åˆ™åœ¨æ”¶é›†åˆ°ä¸€æ‰¹æ•°æ®åç«‹å³è¿›è¡Œæ¨¡å‹æ›´æ–°ï¼Œè¿™æ ·å¯ä»¥æ˜¾è‘—æé«˜ç³»ç»Ÿçš„æ•´ä½“æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAReaLçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ç”Ÿæˆå·¥ä½œè€…å’Œè®­ç»ƒå·¥ä½œè€…ä¸¤ä¸ªä¸»è¦æ¨¡å—ã€‚ç”Ÿæˆå·¥ä½œè€…è´Ÿè´£ä¸æ–­ç”Ÿæˆè¾“å‡ºï¼Œè€Œè®­ç»ƒå·¥ä½œè€…åœ¨æ•°æ®æ”¶é›†åè¿›è¡Œæ¨¡å‹æ›´æ–°ã€‚æ­¤å¤–ï¼ŒAReaLè¿˜å¼•å…¥äº†ä¸€ç³»åˆ—ç³»ç»Ÿçº§ä¼˜åŒ–ï¼Œä»¥æå‡GPUçš„åˆ©ç”¨ç‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šAReaLçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶å®Œå…¨å¼‚æ­¥çš„è®¾è®¡ï¼Œè§£å†³äº†ä¼ ç»ŸåŒæ­¥ç³»ç»Ÿä¸­çš„æ•ˆç‡ç“¶é¢ˆã€‚é€šè¿‡å¹³è¡¡ç”Ÿæˆä¸è®­ç»ƒå·¥ä½œè€…çš„è´Ÿè½½ï¼ŒAReaLèƒ½å¤Ÿæœ‰æ•ˆæ§åˆ¶æ•°æ®çš„é™ˆæ—§æ€§ï¼Œå¹¶é‡‡ç”¨å¢å¼ºé™ˆæ—§æ€§çš„PPOå˜ä½“æ¥å¤„ç†è¿‡æ—¶çš„è®­ç»ƒæ ·æœ¬ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸Šï¼ŒAReaLæ³¨é‡ç”Ÿæˆä¸è®­ç»ƒå·¥ä½œè€…çš„è´Ÿè½½å¹³è¡¡ï¼Œç¡®ä¿æ•°æ®çš„æ—¶æ•ˆæ€§ã€‚åŒæ—¶ï¼Œé‡‡ç”¨äº†é’ˆå¯¹é™ˆæ—§æ ·æœ¬çš„PPOå˜ä½“ï¼Œä»¥æé«˜è®­ç»ƒçš„ç¨³å®šæ€§å’Œæ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

AReaLåœ¨æ•°å­¦å’Œä»£ç æ¨ç†åŸºå‡†ä¸Šå®ç°äº†é«˜è¾¾2.77å€çš„è®­ç»ƒé€Ÿåº¦æå‡ï¼Œç›¸è¾ƒäºç›¸åŒGPUæ•°é‡çš„åŒæ­¥ç³»ç»Ÿï¼Œæœ€ç»ˆæ€§èƒ½ä¿æŒä¸€è‡´æˆ–æœ‰æ‰€æå‡ã€‚è¿™ä¸€ç»“æœè¡¨æ˜ï¼ŒAReaLåœ¨æ•ˆç‡å’Œæ•ˆæœä¸Šå‡ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå…·æœ‰æ˜¾è‘—çš„å®ç”¨ä»·å€¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

AReaLçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦é«˜æ•ˆæ¨ç†çš„è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­ã€‚å…¶å¼‚æ­¥è®­ç»ƒæœºåˆ¶å¯ä»¥æ˜¾è‘—æå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„è®­ç»ƒæ•ˆç‡ï¼Œä¸ºå®æ—¶åº”ç”¨æä¾›æ”¯æŒã€‚æ­¤å¤–ï¼Œè¯¥ç³»ç»Ÿçš„è®¾è®¡ç†å¿µä¹Ÿå¯æ¨å¹¿è‡³å…¶ä»–éœ€è¦å¤§è§„æ¨¡å¹¶è¡Œè®¡ç®—çš„æœºå™¨å­¦ä¹ ä»»åŠ¡ä¸­ï¼Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Reinforcement learning (RL) has become a dominant paradigm for training large language models (LLMs), particularly for reasoning tasks. Effective RL for LLMs requires massive parallelization and poses an urgent need for efficient training systems. Most existing large-scale RL systems for LLMs are synchronous, alternating generation and training in a batch setting where rollouts in each training batch are generated by the same model. This approach stabilizes RL training but suffers from severe system-level inefficiency: generation must wait until the longest output in the batch is completed before model updates, resulting in GPU underutilization. We present AReaL, a fully asynchronous RL system that completely decouples generation from training. Rollout workers in AReaL continuously generate new outputs without waiting, while training workers update the model whenever a batch of data is collected. AReaL also incorporates a collection of system-level optimizations, leading to substantially higher GPU utilization. To stabilize RL training, AReaL balances the workload of rollout and training workers to control data staleness, and adopts a staleness-enhanced PPO variant to better handle outdated training samples. Extensive experiments on math and code reasoning benchmarks show that AReaL achieves up to 2.77$\times$ training speedup compared to synchronous systems with the same number of GPUs and matched or improved final performance. The code of AReaL is available at https://github.com/inclusionAI/AReaL/.

