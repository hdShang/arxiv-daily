---
layout: default
title: "SALE : Low-bit Estimation for Efficient Sparse Attention in Long-context LLM Prefilling"
---

# SALE : Low-bit Estimation for Efficient Sparse Attention in Long-context LLM Prefilling

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.24179" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.24179v1</a>
  <a href="https://arxiv.org/pdf/2505.24179.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.24179v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.24179v1', 'SALE : Low-bit Estimation for Efficient Sparse Attention in Long-context LLM Prefilling')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Xiaodong Ji, Hailin Zhang, Fangcheng Fu, Bin Cui

**ÂàÜÁ±ª**: cs.LG, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-30

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫SALE‰ª•Ëß£ÂÜ≥Èïø‰∏ä‰∏ãÊñáLLMÈ¢ÑÂ°´ÂÖÖÈò∂ÊÆµÁöÑÁ®ÄÁñèÊ≥®ÊÑèÂäõÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Èïø‰∏ä‰∏ãÊñáÂ§ÑÁêÜ` `Á®ÄÁñèÊ≥®ÊÑèÂäõ` `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `ÈáèÂåñÊäÄÊúØ` `CUDA‰ºòÂåñ` `Áõ∏ÂØπÊ≥®ÊÑèÂäõËØÑÂàÜ` `ÊïàÁéáÊèêÂçá`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁ®ÄÁñèÊ≥®ÊÑèÂäõÊñπÊ≥ïÂú®Èïø‰∏ä‰∏ãÊñáÂ§ÑÁêÜÊó∂ÔºåÈÄöÂ∏∏ÂØπÊ≥®ÊÑèÂäõÂõæÁöÑÊ£ÄÊü•ËæÉ‰∏∫Á≤óÁ≥ôÔºåÂØºËá¥Ê®°ÂûãÂáÜÁ°ÆÊÄßÊòæËëó‰∏ãÈôç„ÄÇ
2. SALEÈÄöËøá4‰ΩçÈáèÂåñÁöÑÊü•ËØ¢-ÈîÆ‰πòÁßØÂÆûÁé∞ÁªÜÁ≤íÂ∫¶ÁöÑÊ≥®ÊÑèÂäõÊùÉÈáç‰º∞ËÆ°ÔºåÂπ∂ÁªìÂêàÂùóÁ®ÄÁñèÊ≥®ÊÑèÂäõÂä†ÈÄüËÆ°ÁÆó„ÄÇ
3. Âú®Èïø‰∏ä‰∏ãÊñáÂü∫ÂáÜÊµãËØï‰∏≠ÔºåSALEÂú®ÂáÜÁ°ÆÊÄßÂíåÊïàÁéáÁöÑÊùÉË°°‰∏äË°®Áé∞‰ºòË∂äÔºåÈÄüÂ∫¶ÊèêÂçáËá≥Â∞ë‰∏∫3.36ÂÄç„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËÆ∏Â§öÂÖàËøõÁöÑÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÂ∫îÁî®ÈúÄË¶ÅÂ§ÑÁêÜÈïø‰∏ä‰∏ãÊñáÔºå‰ΩÜËá™Ê≥®ÊÑèÂäõÊ®°ÂùóÂú®Êé®ÁêÜÁöÑÈ¢ÑÂ°´ÂÖÖÈò∂ÊÆµÁî±‰∫é‰∏éÂ∫èÂàóÈïøÂ∫¶ÁöÑÂπ≥ÊñπÊó∂Èó¥Â§çÊùÇÂ∫¶ËÄåÊàê‰∏∫Áì∂È¢à„ÄÇÁé∞ÊúâÁöÑÁ®ÄÁñèÊ≥®ÊÑèÂäõÊñπÊ≥ïÈÄöËøáË∑≥ËøáÊ≥®ÊÑèÂäõÂõæ‰∏≠‰∏çÈáçË¶ÅÁöÑÂå∫ÂüüÊù•Âä†ÈÄüËÆ°ÁÆóÔºå‰ΩÜÈÄöÂ∏∏ÂØπÊ≥®ÊÑèÂäõÂõæÁöÑÊ£ÄÊü•ËæÉ‰∏∫Á≤óÁ≥ôÔºåÂØºËá¥Ê®°ÂûãÂáÜÁ°ÆÊÄßÊòæËëó‰∏ãÈôç„ÄÇÊú¨ÊñáÊèêÂá∫‰∫ÜSALEÔºå‰∏ÄÁßçÁªÜÁ≤íÂ∫¶Á®ÄÁñèÊ≥®ÊÑèÂäõÊñπÊ≥ïÔºåËÉΩÂ§üÂú®Âá†‰πé‰∏çÊçüÂ§±Ê®°ÂûãÂáÜÁ°ÆÊÄßÁöÑÊÉÖÂÜµ‰∏ãÂä†ÈÄüLLMÁöÑÈïø‰∏ä‰∏ãÊñáÈ¢ÑÂ°´ÂÖÖÈò∂ÊÆµ„ÄÇSALEÈÄöËøá4‰ΩçÈáèÂåñÁöÑÊü•ËØ¢-ÈîÆ‰πòÁßØÂÆûÁé∞Âø´ÈÄüÂáÜÁ°ÆÁöÑÁªÜÁ≤íÂ∫¶Ê≥®ÊÑèÂäõÊùÉÈáç‰º∞ËÆ°ÔºåÈöèÂêéÈááÁî®ÂùóÁ®ÄÁñèÊ≥®ÊÑèÂäõÂä†ÈÄüÈ¢ÑÂ°´ÂÖÖËÆ°ÁÆó„ÄÇÊàë‰ª¨ÈááÁî®Áõ∏ÂØπÊ≥®ÊÑèÂäõËØÑÂàÜÂ∫¶ÈáèÊù•ËØÑ‰º∞Êü•ËØ¢-ÈîÆÂØπÁöÑÈáçË¶ÅÊÄßÔºåÂú®Êàë‰ª¨ÁöÑÊ°ÜÊû∂ÂÜÖÊòæËëóÊèêÈ´ò‰∫ÜÊïàÁéá„ÄÇÂÆûÈ™åË°®ÊòéÔºåSALEÂú®ÂáÜÁ°ÆÊÄßÂíåÊïàÁéáÁöÑÊùÉË°°‰∏ä‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÂú®Â§ÑÁêÜË∂ÖËøá64KÁöÑÂ∫èÂàóÊó∂ÔºåLlama-3.1-8BÁöÑÈÄüÂ∫¶ÊèêÂçáËá≥Â∞ë‰∏∫3.36ÂÄçÔºåÂêåÊó∂‰øùÊåÅÊ®°ÂûãË¥®Èáè„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂú®Èïø‰∏ä‰∏ãÊñáÈ¢ÑÂ°´ÂÖÖÈò∂ÊÆµËá™Ê≥®ÊÑèÂäõËÆ°ÁÆóÁöÑÊó∂Èó¥Â§çÊùÇÂ∫¶Áì∂È¢à„ÄÇÁé∞ÊúâÁ®ÄÁñèÊ≥®ÊÑèÂäõÊñπÊ≥ïÁî±‰∫éÁ≤óÁ≥ôÁöÑÊ≥®ÊÑèÂäõÂõæÊ£ÄÊü•ÔºåÂØºËá¥Ê®°ÂûãÂáÜÁ°ÆÊÄß‰∏ãÈôç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöSALEÊèêÂá∫‰∫Ü‰∏ÄÁßçÁªÜÁ≤íÂ∫¶ÁöÑÁ®ÄÁñèÊ≥®ÊÑèÂäõÊñπÊ≥ïÔºåÈÄöËøá4‰ΩçÈáèÂåñÁöÑÊü•ËØ¢-ÈîÆ‰πòÁßØÊù•ÂÆûÁé∞Âø´ÈÄü‰∏îÂáÜÁ°ÆÁöÑÊ≥®ÊÑèÂäõÊùÉÈáç‰º∞ËÆ°ÔºåËøõËÄåÂä†ÈÄüËÆ°ÁÆó„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöSALEÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨Êü•ËØ¢-ÈîÆ‰πòÁßØÁöÑÈáèÂåñ„ÄÅÁªÜÁ≤íÂ∫¶Ê≥®ÊÑèÂäõÊùÉÈáç‰º∞ËÆ°ÂíåÂùóÁ®ÄÁñèÊ≥®ÊÑèÂäõËÆ°ÁÆó‰∏â‰∏™‰∏ªË¶ÅÊ®°Âùó„ÄÇÈ¶ñÂÖàËøõË°åÈáèÂåñÂ§ÑÁêÜÔºåÁÑ∂ÂêéÈÄöËøáÁõ∏ÂØπÊ≥®ÊÑèÂäõËØÑÂàÜËØÑ‰º∞ÈáçË¶ÅÊÄßÔºåÊúÄÂêéÊâßË°åÂùóÁ®ÄÁñèËÆ°ÁÆó‰ª•ÊèêÈ´òÊïàÁéá„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöSALEÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÈááÁî®4‰ΩçÈáèÂåñÁöÑÊü•ËØ¢-ÈîÆ‰πòÁßØÂíåÁõ∏ÂØπÊ≥®ÊÑèÂäõËØÑÂàÜÂ∫¶ÈáèÔºåËøô‰ΩøÂæóÂú®‰øùÊåÅÊ®°ÂûãÂáÜÁ°ÆÊÄßÁöÑÂêåÊó∂ÔºåÊòæËëóÊèêÈ´ò‰∫ÜËÆ°ÁÆóÊïàÁéá„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåSALEÂú®ÁªÜÁ≤íÂ∫¶Â§ÑÁêÜ‰∏äÂÖ∑ÊúâÊòéÊòæ‰ºòÂäø„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöSALEÁöÑËÆæËÆ°‰∏≠ÔºåÈááÁî®‰∫ÜËá™ÂÆö‰πâÁöÑCUDAÂÜÖÊ†∏‰ª•‰ºòÂåñÁ°¨‰ª∂ÊïàÁéáÔºåÈ¢ùÂ§ñÂºÄÈîÄ‰ªÖ‰∏∫ÂÖ®Ê≥®ÊÑèÂäõÂª∂ËøüÁöÑÁ∫¶11%„ÄÇËØ•ÊñπÊ≥ïÊó†ÈúÄÈ¢ùÂ§ñÁöÑÂèÇÊï∞ËÆ≠ÁªÉÔºåËÉΩÂ§üËΩªÊùæÈõÜÊàêÂà∞Áé∞ÊúâÁ≥ªÁªü‰∏≠„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

SALEÂú®Èïø‰∏ä‰∏ãÊñáÂü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞Âá∫Ëâ≤ÔºåÁõ∏ËæÉ‰∫éÁé∞ÊúâÊñπÊ≥ïÂú®ÂáÜÁ°ÆÊÄßÂíåÊïàÁéáÁöÑÊùÉË°°‰∏äÂèñÂæó‰∫ÜÊòæËëóÊèêÂçá„ÄÇÂú®Â§ÑÁêÜË∂ÖËøá64KÁöÑÂ∫èÂàóÊó∂ÔºåLlama-3.1-8BÁöÑÈÄüÂ∫¶ÊèêÂçáËá≥Â∞ë‰∏∫3.36ÂÄçÔºåÂêåÊó∂‰øùÊåÅ‰∫ÜÊ®°ÂûãÁöÑË¥®ÈáèÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÂ∑®Â§ßÊΩúÂäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

SALEÁöÑÁ†îÁ©∂ÊàêÊûúÂú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ„ÄÅÂØπËØùÁ≥ªÁªüÂíåÊñáÊú¨ÁîüÊàêÁ≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõ„ÄÇÈÄöËøáÊèêÈ´òÈïø‰∏ä‰∏ãÊñáÂ§ÑÁêÜÁöÑÊïàÁéáÔºåSALEËÉΩÂ§üÊîØÊåÅÊõ¥Â§çÊùÇÁöÑËØ≠Ë®ÄÁêÜËß£ÂíåÁîüÊàê‰ªªÂä°ÔºåÊé®Âä®Áõ∏ÂÖ≥ÊäÄÊúØÁöÑÂèëÂ±ï‰∏éÂ∫îÁî®„ÄÇÊú™Êù•ÔºåSALEÂèØËÉΩ‰ºöÂú®ÂÆûÊó∂ÁøªËØë„ÄÅÊô∫ËÉΩÂä©ÊâãÁ≠âÂú∫ÊôØ‰∏≠ÂèëÊå•ÈáçË¶Å‰ΩúÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Many advanced Large Language Model (LLM) applications require long-context processing, but the self-attention module becomes a bottleneck during the prefilling stage of inference due to its quadratic time complexity with respect to sequence length. Existing sparse attention methods accelerate attention computation by skipping less significant regions of the attention map. However, these approaches typically perform coarse-grained inspection of the attention map, rendering considerable loss in model accuracy. In this paper, we propose SALE, a fine-grained sparse attention method that accelerates the long-context prefilling stage of LLM with negligible loss in model accuracy. SALE achieves fast and accurate fine-grained attention weight estimation through 4-bit quantized query-key products, followed by block-sparse attention to accelerate prefilling computations. For importance evaluation for query-key pairs, we adopt our Relative Attention Score metric, which offers significantly higher efficiency within our framework. We implement a custom CUDA kernel optimized for our approach for hardware efficiency, reducing the additional overhead to approximately 11% of the full attention latency. Notably, SALE requires no parameter training and can be seamlessly integrated into existing systems with trivial code modifications. Experiments on long-context benchmarks demonstrate that our method outperforms existing approaches in accuracy-efficiency trade-offs, achieving at least 3.36x speedups on Llama-3.1-8B for sequences longer than 64K while maintaining model quality.

