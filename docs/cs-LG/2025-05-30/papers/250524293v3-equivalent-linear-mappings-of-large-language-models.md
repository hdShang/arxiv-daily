---
layout: default
title: Equivalent Linear Mappings of Large Language Models
---

# Equivalent Linear Mappings of Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.24293" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.24293v3</a>
  <a href="https://arxiv.org/pdf/2505.24293.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.24293v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.24293v3', 'Equivalent Linear Mappings of Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: James R. Golden

**åˆ†ç±»**: cs.LG, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-30 (æ›´æ–°: 2025-10-11)

**å¤‡æ³¨**: title changed; major revisions; code available at https://github.com/jamesgolden1/equivalent-linear-LLMs/; published at https://openreview.net/forum?id=oDWbJsIuEp

**æœŸåˆŠ**: Transactions on Machine Learning Research (TMLR) (10/2025)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç­‰æ•ˆçº¿æ€§æ˜ å°„ä»¥è§£æå¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†æœºåˆ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å¯è§£é‡Šæ€§` `çº¿æ€§æ˜ å°„` `å˜æ¢å™¨` `æ¨ç†æœºåˆ¶` `è¯­ä¹‰ç»“æ„` `é›…å¯æ¯”çŸ©é˜µ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨è§£é‡Šå¤§å‹è¯­è¨€æ¨¡å‹çš„è®¡ç®—æœºåˆ¶æ—¶å­˜åœ¨å±€é™ï¼Œæ— æ³•æ­ç¤ºéšè—è¡¨ç¤ºçš„ç”Ÿæˆè¿‡ç¨‹ã€‚
2. æœ¬æ–‡æå‡ºå°†LLMæ¨ç†æ˜ å°„ä¸ºç­‰æ•ˆçº¿æ€§ç³»ç»Ÿï¼Œé€šè¿‡å›ºå®šè¾“å…¥ä¾èµ–çš„çº¿æ€§å˜æ¢æ¥å®ç°å¯è§£é‡Šæ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªæ¨¡å‹ä¸Šé‡æ„è¾“å‡ºåµŒå…¥çš„ç›¸å¯¹è¯¯å·®ä½äº$10^{-13}$ï¼Œå±•ç¤ºäº†LLMsåœ¨ä½ç»´è¯­ä¹‰ç»“æ„ä¸­çš„æ“ä½œç‰¹æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡åœ¨å˜æ¢å™¨å¯è§£é‡Šæ€§æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ç†è§£å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è®¡ç®—æœºåˆ¶ä»ç„¶æ˜¯ä¸€ä¸ªåŸºæœ¬æŒ‘æˆ˜ã€‚è®¸å¤šæ–¹æ³•è§£é‡Šäº†ç½‘ç»œçš„éšè—è¡¨ç¤ºï¼Œä½†å¯¹è¿™äº›è¡¨ç¤ºçš„ç”Ÿæˆæ–¹å¼å´æ— èƒ½ä¸ºåŠ›ã€‚æœ¬æ–‡é€šè¿‡å°†LLMæ¨ç†æ˜ å°„åˆ°ä¸€ä¸ªç­‰æ•ˆä¸”å¯è§£é‡Šçš„çº¿æ€§ç³»ç»Ÿï¼ŒæˆåŠŸé‡æ„é¢„æµ‹è¾“å‡ºåµŒå…¥ï¼Œä¸”ç›¸å¯¹è¯¯å·®ä½äº$10^{-13}$ï¼Œæ— éœ€é¢å¤–çš„æ¨¡å‹è®­ç»ƒã€‚æˆ‘ä»¬åˆ©ç”¨å˜æ¢å™¨çš„ç‰¹æ€§ï¼Œå°†æ¯ä¸ªæ“ä½œï¼ˆé—¨æ§æ¿€æ´»ã€æ³¨æ„åŠ›å’Œå½’ä¸€åŒ–ï¼‰è¡¨ç¤ºä¸º$A(x) 	imes x$ï¼Œå…¶ä¸­$A(x)$æ˜¯è¾“å…¥ä¾èµ–çš„çº¿æ€§å˜æ¢ã€‚é€šè¿‡æˆ˜ç•¥æ€§åœ°åˆ†ç¦»æ¢¯åº¦è®¡ç®—çš„ç»„ä»¶ï¼Œå›ºå®š$A(x)$çš„å€¼ï¼Œå¾—åˆ°ç­‰æ•ˆçš„çº¿æ€§æ˜ å°„ã€‚è¯¥æ–¹æ³•å±•ç¤ºäº†LLMsåœ¨æä½ç»´å­ç©ºé—´ä¸­çš„æ“ä½œç‰¹æ€§ï¼Œå¹¶æ­ç¤ºäº†è¯­ä¹‰æ¦‚å¿µçš„å¯è§£é‡Šæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¯¹å¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†æœºåˆ¶çš„ç†è§£ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•æ— æ³•æœ‰æ•ˆè§£é‡Šéšè—è¡¨ç¤ºçš„ç”Ÿæˆè¿‡ç¨‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å°†LLMæ¨ç†æ˜ å°„ä¸ºç­‰æ•ˆçº¿æ€§ç³»ç»Ÿï¼Œåˆ©ç”¨å˜æ¢å™¨çš„ç‰¹æ€§å°†æ¯ä¸ªæ“ä½œè¡¨ç¤ºä¸ºè¾“å…¥ä¾èµ–çš„çº¿æ€§å˜æ¢ï¼Œä»è€Œå®ç°å¯è§£é‡Šæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å›ºå®š$A(x)$çš„å€¼ä»¥è®¡ç®—é›…å¯æ¯”çŸ©é˜µï¼Œè¿›è€Œå¾—åˆ°ç­‰æ•ˆçº¿æ€§æ˜ å°„ã€‚æ¯ä¸ªè¾“å…¥æ ‡è®°å¯¹åº”ä¸€ä¸ªçº¿æ€§ç®—å­ï¼Œé€å±‚åˆ†æå…¶æ³¨æ„åŠ›å’Œå¤šå±‚æ„ŸçŸ¥æœºæ¨¡å—çš„ä½œç”¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºé€šè¿‡é›…å¯æ¯”çŸ©é˜µçš„åˆ†ç¦»è®¡ç®—ï¼Œæ­ç¤ºäº†LLMsåœ¨ä½ç»´å­ç©ºé—´ä¸­çš„æ“ä½œç‰¹æ€§ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†æ›´æ·±å±‚æ¬¡çš„å¯è§£é‡Šæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨äº†åŒæµ®ç‚¹ç²¾åº¦è®¡ç®—ï¼Œç¡®ä¿é‡æ„è¾“å‡ºåµŒå…¥çš„ç›¸å¯¹è¯¯å·®ä½äº$10^{-13}$ï¼Œå¹¶å±•ç¤ºäº†ä¸åŒæ¨¡å‹ï¼ˆå¦‚Qwen 3ã€Gemma 3å’ŒLlama 3ï¼‰çš„çº¿æ€§è¡¨ç¤ºã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡æå‡ºçš„ç­‰æ•ˆçº¿æ€§æ˜ å°„æ–¹æ³•åœ¨å¤šä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ä¸Šå®ç°äº†é‡æ„è¾“å‡ºåµŒå…¥çš„ç›¸å¯¹è¯¯å·®ä½äº$10^{-13}$ï¼Œå±•ç¤ºäº†LLMsåœ¨ä½ç»´è¯­ä¹‰ç»“æ„ä¸­çš„æ“ä½œç‰¹æ€§ï¼Œæ˜¾è‘—æå‡äº†å¯¹æ¨¡å‹æ¨ç†è¿‡ç¨‹çš„å¯è§£é‡Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æ–‡æœ¬ç”Ÿæˆå’Œæœºå™¨ç¿»è¯‘ç­‰ã€‚é€šè¿‡æä¾›å¯è§£é‡Šçš„æ¨ç†æœºåˆ¶ï¼Œç ”ç©¶è€…å’Œå¼€å‘è€…å¯ä»¥æ›´å¥½åœ°ç†è§£å’Œä¼˜åŒ–å¤§å‹è¯­è¨€æ¨¡å‹çš„è¡Œä¸ºï¼Œæå‡å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å¯é æ€§å’Œé€æ˜åº¦ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Despite significant progress in transformer interpretability, an understanding of the computational mechanisms of large language models (LLMs) remains a fundamental challenge. Many approaches interpret a network's hidden representations but remain agnostic about how those representations are generated. We address this by mapping LLM inference for a given input sequence to an equivalent and interpretable linear system which reconstructs the predicted output embedding with relative error below $10^{-13}$ at double floating-point precision, requiring no additional model training. We exploit a property of transformers wherein every operation (gated activations, attention, and normalization) can be expressed as $A(x) \cdot x$, where $A(x)$ represents an input-dependent linear transform and $x$ preserves the linear pathway. To expose this linear structure, we strategically detach components of the gradient computation with respect to an input sequence, freezing the $A(x)$ terms at their values computed during inference, such that the Jacobian yields an equivalent linear mapping. This detached Jacobian of the model reconstructs the output with one linear operator per input token, which is shown for Qwen 3, Gemma 3 and Llama 3, up to Qwen 3 14B. These linear representations demonstrate that LLMs operate in extremely low-dimensional subspaces where the singular vectors can be decoded to interpretable semantic concepts. The computation for each intermediate output also has a linear equivalent, and we examine how the linear representations of individual layers and their attention and multilayer perceptron modules build predictions, and use these as steering operators to insert semantic concepts into unrelated text. Despite their global nonlinearity, LLMs can be interpreted through equivalent linear representations that reveal low-dimensional semantic structures in the next-token prediction process.

