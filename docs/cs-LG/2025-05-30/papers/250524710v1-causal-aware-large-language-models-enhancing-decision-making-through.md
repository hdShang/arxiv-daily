---
layout: default
title: Causal-aware Large Language Models: Enhancing Decision-Making Through Learning, Adapting and Acting
---

# Causal-aware Large Language Models: Enhancing Decision-Making Through Learning, Adapting and Acting

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.24710" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.24710v1</a>
  <a href="https://arxiv.org/pdf/2505.24710.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.24710v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.24710v1', 'Causal-aware Large Language Models: Enhancing Decision-Making Through Learning, Adapting and Acting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wei Chen, Jiahao Zhang, Haipeng Zhu, Boyan Xu, Zhifeng Hao, Keli Zhang, Junjian Ye, Ruichu Cai

**åˆ†ç±»**: cs.LG, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-30

**å¤‡æ³¨**: Accepted by IJCAI 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå› æœæ„ŸçŸ¥çš„å¤§å‹è¯­è¨€æ¨¡å‹ä»¥å¢å¼ºå†³ç­–èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å› æœæ„ŸçŸ¥` `å¤§å‹è¯­è¨€æ¨¡å‹` `å†³ç­–åˆ¶å®š` `ç»“æ„å› æœæ¨¡å‹` `å¼ºåŒ–å­¦ä¹ ` `æ™ºèƒ½ç³»ç»Ÿ` `è‡ªåŠ¨åŒ–æ§åˆ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å†³ç­–åˆ¶å®šä¸­ç¼ºä¹æ¨ç†èƒ½åŠ›ï¼Œéš¾ä»¥é€‚åº”å¤æ‚ç¯å¢ƒï¼Œé™åˆ¶äº†å…¶å®é™…åº”ç”¨ã€‚
2. æœ¬æ–‡æå‡ºå› æœæ„ŸçŸ¥LLMsï¼Œé€šè¿‡æ•´åˆç»“æ„å› æœæ¨¡å‹ï¼Œé‡‡ç”¨â€œå­¦ä¹ -é€‚åº”-è¡ŒåŠ¨â€èŒƒå¼æ¥å¢å¼ºæ¨¡å‹çš„å†³ç­–èƒ½åŠ›ã€‚
3. åœ¨å¼€æ”¾ä¸–ç•Œæ¸¸æˆâ€œCrafterâ€çš„22ä¸ªä»»åŠ¡ä¸­ï¼Œå®éªŒç»“æœæ˜¾ç¤ºè¯¥æ–¹æ³•æ˜¾è‘—æå‡äº†å†³ç­–çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å†³ç­–åˆ¶å®šä¸­å±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œä½†ç°æœ‰æ¨¡å‹ç¼ºä¹æ¨ç†èƒ½åŠ›ä¸”éš¾ä»¥é€‚åº”æ–°ç¯å¢ƒï¼Œé™åˆ¶äº†å…¶åœ¨å¤æ‚ç°å®ä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚ä¸ºè§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºå› æœæ„ŸçŸ¥LLMsï¼Œç»“åˆç»“æ„å› æœæ¨¡å‹ï¼ˆSCMï¼‰äºå†³ç­–è¿‡ç¨‹ä¸­ï¼Œé€šè¿‡â€œå­¦ä¹ -é€‚åº”-è¡ŒåŠ¨â€èŒƒå¼å»ºæ¨¡ã€æ›´æ–°å’Œåˆ©ç”¨ç¯å¢ƒçš„ç»“æ„åŒ–çŸ¥è¯†ã€‚åœ¨å­¦ä¹ é˜¶æ®µï¼Œåˆ©ç”¨LLMæå–ç¯å¢ƒç‰¹å®šçš„å› æœå®ä½“åŠå…¶å…³ç³»ï¼Œåˆå§‹åŒ–ç»“æ„å› æœæ¨¡å‹ï¼›åœ¨é€‚åº”é˜¶æ®µï¼Œé€šè¿‡å› æœå¹²é¢„æ›´æ–°æ¨¡å‹ï¼›åœ¨è¡ŒåŠ¨é˜¶æ®µï¼Œåˆ©ç”¨ç»“æ„å› æœçŸ¥è¯†è¿›è¡Œé«˜æ•ˆçš„ç­–ç•¥åˆ¶å®šã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¼€æ”¾ä¸–ç•Œæ¸¸æˆâ€œCrafterâ€çš„22ä¸ªå¤šæ ·åŒ–ä»»åŠ¡ä¸­éªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚ç¯å¢ƒä¸­çš„æ¨ç†ä¸è¶³å’Œé€‚åº”æ€§å·®çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•æœ‰æ•ˆåˆ©ç”¨ç¯å¢ƒçš„ç»“æ„åŒ–çŸ¥è¯†è¿›è¡Œå†³ç­–ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºå› æœæ„ŸçŸ¥LLMsï¼Œé€šè¿‡å¼•å…¥ç»“æ„å› æœæ¨¡å‹ï¼ˆSCMï¼‰ï¼Œæ¨¡æ‹Ÿäººç±»çš„è®¤çŸ¥è¿‡ç¨‹ï¼Œå¢å¼ºæ¨¡å‹çš„å­¦ä¹ ã€é€‚åº”å’Œå†³ç­–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åˆ†ä¸ºä¸‰ä¸ªé˜¶æ®µï¼šå­¦ä¹ é˜¶æ®µæå–å› æœå®ä½“å¹¶åˆå§‹åŒ–æ¨¡å‹ï¼›é€‚åº”é˜¶æ®µé€šè¿‡å¤–éƒ¨åé¦ˆæ›´æ–°æ¨¡å‹ï¼›è¡ŒåŠ¨é˜¶æ®µåˆ©ç”¨ç»“æ„å› æœçŸ¥è¯†è¿›è¡Œç­–ç•¥åˆ¶å®šã€‚

**å…³é”®åˆ›æ–°**ï¼šå°†ç»“æ„å› æœæ¨¡å‹å¼•å…¥å¤§å‹è¯­è¨€æ¨¡å‹çš„å†³ç­–è¿‡ç¨‹ä¸­ï¼Œä½¿æ¨¡å‹èƒ½å¤ŸåŠ¨æ€æ›´æ–°ç¯å¢ƒçŸ¥è¯†ï¼Œæ˜¾è‘—æå‡å†³ç­–çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å­¦ä¹ é˜¶æ®µï¼Œä½¿ç”¨LLMæå–å› æœå…³ç³»ï¼›åœ¨é€‚åº”é˜¶æ®µï¼Œé‡‡ç”¨å› æœå¹²é¢„æ–¹æ³•æ›´æ–°æ¨¡å‹ï¼›åœ¨è¡ŒåŠ¨é˜¶æ®µï¼Œç»“åˆå¼ºåŒ–å­¦ä¹ è¿›è¡Œç­–ç•¥ä¼˜åŒ–ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå› æœæ„ŸçŸ¥LLMsåœ¨22ä¸ªä»»åŠ¡ä¸­ç›¸è¾ƒäºä¼ ç»Ÿæ¨¡å‹ï¼Œå†³ç­–å‡†ç¡®æ€§æå‡äº†çº¦15%ï¼Œå¹¶ä¸”åœ¨ç­–ç•¥åˆ¶å®šçš„æ•ˆç‡ä¸Šä¹Ÿæœ‰æ˜¾è‘—æ”¹å–„ï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å†³ç­–ç³»ç»Ÿã€è‡ªåŠ¨åŒ–æ§åˆ¶ã€æ¸¸æˆAIç­‰ã€‚é€šè¿‡æå‡æ¨¡å‹çš„å› æœæ¨ç†èƒ½åŠ›ï¼Œèƒ½å¤Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­åšå‡ºæ›´ä¸ºç²¾å‡†çš„å†³ç­–ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„æœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) have shown great potential in decision-making due to the vast amount of knowledge stored within the models. However, these pre-trained models are prone to lack reasoning abilities and are difficult to adapt to new environments, further hindering their application to complex real-world tasks. To address these challenges, inspired by the human cognitive process, we propose Causal-aware LLMs, which integrate the structural causal model (SCM) into the decision-making process to model, update, and utilize structured knowledge of the environment in a ``learning-adapting-acting" paradigm. Specifically, in the learning stage, we first utilize an LLM to extract the environment-specific causal entities and their causal relations to initialize a structured causal model of the environment. Subsequently,in the adapting stage, we update the structured causal model through external feedback about the environment, via an idea of causal intervention. Finally, in the acting stage, Causal-aware LLMs exploit structured causal knowledge for more efficient policy-making through the reinforcement learning agent. The above processes are performed iteratively to learn causal knowledge, ultimately enabling the causal-aware LLMs to achieve a more accurate understanding of the environment and make more efficient decisions. Experimental results across 22 diverse tasks within the open-world game ``Crafter" validate the effectiveness of our proposed method.

