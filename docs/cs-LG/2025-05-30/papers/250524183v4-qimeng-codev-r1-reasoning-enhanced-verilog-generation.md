---
layout: default
title: "QiMeng-CodeV-R1: Reasoning-Enhanced Verilog Generation"
---

# QiMeng-CodeV-R1: Reasoning-Enhanced Verilog Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.24183" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.24183v4</a>
  <a href="https://arxiv.org/pdf/2505.24183.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.24183v4" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.24183v4', 'QiMeng-CodeV-R1: Reasoning-Enhanced Verilog Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yaoyu Zhu, Di Huang, Hanqi Lyu, Xiaoyun Zhang, Chongxiao Li, Wenxuan Shi, Yutong Wu, Jianan Mu, Jinghua Wang, Yang Zhao, Pengwei Jin, Shuyao Cheng, Shengwen Liang, Xishan Zhang, Rui Zhang, Zidong Du, Qi Guo, Xing Hu, Yunji Chen

**åˆ†ç±»**: cs.LG, cs.AR, cs.PL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-30 (æ›´æ–°: 2025-10-13)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCodeV-R1æ¡†æ¶ä»¥è§£å†³HDLè‡ªåŠ¨ç”Ÿæˆä¸­çš„éªŒè¯æŒ‘æˆ˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç”µå­è®¾è®¡è‡ªåŠ¨åŒ–` `ç¡¬ä»¶æè¿°è¯­è¨€` `è‡ªç„¶è¯­è¨€å¤„ç†` `å¼ºåŒ–å­¦ä¹ ` `æ•°æ®åˆæˆ` `æ¨¡å‹è’¸é¦` `éªŒè¯ç¯å¢ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç”µå­è®¾è®¡è‡ªåŠ¨åŒ–ä¸­é¢ä¸´éªŒè¯ç¯å¢ƒç¼ºä¹å’Œé«˜è´¨é‡æ•°æ®ç¨€ç¼ºç­‰æŒ‘æˆ˜ã€‚
2. æå‡ºäº†CodeV-R1æ¡†æ¶ï¼Œé€šè¿‡è§„åˆ™ç”Ÿæˆæµ‹è¯•å¹³å°å’Œå¾€è¿”æ•°æ®åˆæˆæ¥æé«˜æ•°æ®è´¨é‡å’ŒéªŒè¯èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCodeV-R1-7Båœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›æ¨¡å‹ï¼Œæå‡å¹…åº¦è¾¾12~20%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é€šè¿‡å¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLVRï¼‰åœ¨è½¯ä»¶ç¼–ç¨‹å’Œæ•°å­¦é—®é¢˜ç­‰ä»»åŠ¡ä¸Šå–å¾—äº†çªç ´ã€‚ç„¶è€Œï¼Œå°†RLVRæ‰©å±•åˆ°ç”µå­è®¾è®¡è‡ªåŠ¨åŒ–ï¼ˆEDAï¼‰ï¼Œç‰¹åˆ«æ˜¯ä»è‡ªç„¶è¯­è¨€ï¼ˆNLï¼‰è§„èŒƒè‡ªåŠ¨ç”Ÿæˆç¡¬ä»¶æè¿°è¯­è¨€ï¼ˆHDLï¼‰å¦‚Verilogï¼Œé¢ä¸´ä¸‰ä¸ªä¸»è¦æŒ‘æˆ˜ï¼šç¼ºä¹è‡ªåŠ¨åŒ–å’Œå‡†ç¡®çš„éªŒè¯ç¯å¢ƒã€é«˜è´¨é‡NL-ä»£ç å¯¹çš„ç¨€ç¼ºä»¥åŠRLVRçš„é«˜è®¡ç®—æˆæœ¬ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†CodeV-R1ï¼Œä¸€ä¸ªç”¨äºè®­ç»ƒVerilogç”ŸæˆLLMsçš„RLVRæ¡†æ¶ã€‚æˆ‘ä»¬å¼€å‘äº†åŸºäºè§„åˆ™çš„æµ‹è¯•å¹³å°ç”Ÿæˆå™¨ï¼Œæå‡ºäº†å¾€è¿”æ•°æ®åˆæˆæ–¹æ³•ï¼Œå¹¶é‡‡ç”¨äº†ä¸¤é˜¶æ®µçš„â€œè’¸é¦-å†å¼ºåŒ–å­¦ä¹ â€è®­ç»ƒæµç¨‹ã€‚æœ€ç»ˆæ¨¡å‹CodeV-R1-7Båœ¨VerilogEval v2å’ŒRTLLM v1.1ä¸Šåˆ†åˆ«è¾¾åˆ°äº†68.6%å’Œ72.9%çš„é€šè¿‡ç‡ï¼Œè¶…è¶Šäº†ä¹‹å‰çš„æœ€å…ˆè¿›æ°´å¹³ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨ç”µå­è®¾è®¡è‡ªåŠ¨åŒ–ä¸­ï¼Œä»è‡ªç„¶è¯­è¨€ç”Ÿæˆç¡¬ä»¶æè¿°è¯­è¨€ï¼ˆå¦‚Verilogï¼‰æ—¶çš„éªŒè¯ç¯å¢ƒä¸è¶³å’Œé«˜è´¨é‡æ•°æ®ç¨€ç¼ºçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨è¿™æ–¹é¢çš„æœ‰æ•ˆæ€§å—åˆ°é™åˆ¶ï¼Œå¯¼è‡´ç”Ÿæˆçš„ä»£ç éš¾ä»¥éªŒè¯å…¶æ­£ç¡®æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼€å‘ä¸€ä¸ªè§„åˆ™åŸºç¡€çš„æµ‹è¯•å¹³å°ç”Ÿæˆå™¨å’Œå¾€è¿”æ•°æ®åˆæˆæ–¹æ³•ï¼Œæ¥å¢å¼ºç”Ÿæˆæ¨¡å‹çš„éªŒè¯èƒ½åŠ›å’Œæ•°æ®è´¨é‡ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨ç¡®ä¿ç”Ÿæˆçš„ä»£ç ä¸è‡ªç„¶è¯­è¨€æè¿°ä¹‹é—´çš„ä¸€è‡´æ€§ï¼Œä»è€Œæé«˜ç”Ÿæˆçš„å¯é æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šè§„åˆ™åŸºç¡€çš„æµ‹è¯•å¹³å°ç”Ÿæˆå™¨ã€å¾€è¿”æ•°æ®åˆæˆæ–¹æ³•å’Œä¸¤é˜¶æ®µçš„â€œè’¸é¦-å†å¼ºåŒ–å­¦ä¹ â€è®­ç»ƒæµç¨‹ã€‚æµ‹è¯•å¹³å°ç”Ÿæˆå™¨ç”¨äºæ‰§è¡Œç­‰ä»·æ€§æ£€æŸ¥ï¼Œå¾€è¿”æ•°æ®åˆæˆæ–¹æ³•åˆ™ç”¨äºç”Ÿæˆé«˜è´¨é‡çš„NL-ä»£ç å¯¹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†è‡ªé€‚åº”é‡‡æ ·ç‡çš„RLVRç®—æ³•ï¼ˆDAPOï¼‰ï¼Œè¯¥ç®—æ³•èƒ½å¤Ÿåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŠ¨æ€è°ƒæ•´é‡‡æ ·ç‡ï¼Œä»è€Œé™ä½è®¡ç®—æˆæœ¬ã€‚è¿™ä¸€åˆ›æ–°ä¸ä¼ ç»Ÿçš„RLVRæ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—æé«˜äº†è®­ç»ƒæ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨äº†è’¸é¦æŠ€æœ¯æ¥æå‡æ¨ç†èƒ½åŠ›ï¼Œå¹¶åœ¨åç»­é˜¶æ®µåº”ç”¨è‡ªé€‚åº”çš„RLVRç®—æ³•ã€‚å…³é”®å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿç»è¿‡ç²¾å¿ƒè°ƒæ•´ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨ç”ŸæˆVerilogä»£ç æ—¶çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒCodeV-R1-7Båœ¨VerilogEval v2å’ŒRTLLM v1.1åŸºå‡†æµ‹è¯•ä¸­åˆ†åˆ«è¾¾åˆ°äº†68.6%å’Œ72.9%çš„é€šè¿‡ç‡ï¼Œè¶…è¶Šäº†ä¹‹å‰çš„æœ€å…ˆè¿›æ¨¡å‹12~20%ã€‚è¯¥æ¨¡å‹çš„æ€§èƒ½ç”šè‡³è¶…è¿‡äº†671Bå‚æ•°çš„DeepSeek-R1ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨HDLç”Ÿæˆä»»åŠ¡ä¸­çš„å“è¶Šèƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç”µå­è®¾è®¡è‡ªåŠ¨åŒ–ã€ç¡¬ä»¶å¼€å‘å’Œæ™ºèƒ½ç³»ç»Ÿè®¾è®¡ã€‚é€šè¿‡æé«˜ç¡¬ä»¶æè¿°è¯­è¨€çš„è‡ªåŠ¨ç”Ÿæˆèƒ½åŠ›ï¼Œèƒ½å¤Ÿæ˜¾è‘—é™ä½å¼€å‘æˆæœ¬å’Œæ—¶é—´ï¼Œæé«˜è®¾è®¡æ•ˆç‡ï¼Œæ¨åŠ¨æ™ºèƒ½ç¡¬ä»¶çš„å¿«é€Ÿè¿­ä»£ä¸åˆ›æ–°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) trained via reinforcement learning with verifiable reward (RLVR) have achieved breakthroughs on tasks with explicit, automatable verification, such as software programming and mathematical problems. Extending RLVR to electronic design automation (EDA), especially automatically generating hardware description languages (HDLs) like Verilog from natural-language (NL) specifications, however, poses three key challenges: the lack of automated and accurate verification environments, the scarcity of high-quality NL-code pairs, and the prohibitive computation cost of RLVR. To this end, we introduce CodeV-R1, an RLVR framework for training Verilog generation LLMs. First, we develop a rule-based testbench generator that performs robust equivalence checking against golden references. Second, we propose a round-trip data synthesis method that pairs open-source Verilog snippets with LLM-generated NL descriptions, verifies code-NL-code consistency via the generated testbench, and filters out inequivalent examples to yield a high-quality dataset. Third, we employ a two-stage "distill-then-RL" training pipeline: distillation for the cold start of reasoning abilities, followed by adaptive DAPO, our novel RLVR algorithm that can reduce training cost by adaptively adjusting sampling rate. The resulting model, CodeV-R1-7B, achieves 68.6% and 72.9% pass@1 on VerilogEval v2 and RTLLM v1.1, respectively, surpassing prior state-of-the-art by 12~20%, while even exceeding the performance of 671B DeepSeek-R1 on RTLLM. We have released our model, training code, and dataset to facilitate research in EDA and LLM communities.

