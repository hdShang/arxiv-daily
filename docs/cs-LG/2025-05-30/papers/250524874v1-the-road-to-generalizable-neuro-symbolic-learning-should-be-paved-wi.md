---
layout: default
title: The Road to Generalizable Neuro-Symbolic Learning Should be Paved with Foundation Models
---

# The Road to Generalizable Neuro-Symbolic Learning Should be Paved with Foundation Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.24874" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.24874v1</a>
  <a href="https://arxiv.org/pdf/2505.24874.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.24874v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.24874v1', 'The Road to Generalizable Neuro-Symbolic Learning Should be Paved with Foundation Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Adam Stein, Aaditya Naik, Neelay Velingker, Mayur Naik, Eric Wong

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-30

**å¤‡æ³¨**: 19 pages, 11 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç¥ç»ç¬¦å·æç¤ºä»¥è§£å†³å¤æ‚æ¨ç†ä»»åŠ¡çš„æŒ‘æˆ˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç¥ç»ç¬¦å·å­¦ä¹ ` `åŸºç¡€æ¨¡å‹` `å¤æ‚æ¨ç†` `å¯è§£é‡Šæ€§` `æ¨¡å‹è®­ç»ƒ` `ç¬¦å·ç¨‹åº` `æ¨ç†ä»»åŠ¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç¥ç»ç¬¦å·å­¦ä¹ æ–¹æ³•åœ¨å¤„ç†å¤æ‚æ¨ç†ä»»åŠ¡æ—¶é¢ä¸´è®¡ç®—ã€æ•°æ®å’Œç¨‹åºçš„é™åˆ¶ï¼Œå¯¼è‡´æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡å°†åŸºç¡€æ¨¡å‹ä¸ç¬¦å·ç¨‹åºç»“åˆçš„ç¥ç»ç¬¦å·æç¤ºï¼Œæ¥æå‡å¤æ‚æ¨ç†ä»»åŠ¡çš„æ€§èƒ½å’Œå¯è§£é‡Šæ€§ã€‚
3. ç ”ç©¶è¡¨æ˜ï¼ŒåŸºç¡€æ¨¡å‹çš„å¼•å…¥èƒ½å¤Ÿæœ‰æ•ˆè§£å†³ä¼ ç»Ÿæ–¹æ³•çš„ä¸è¶³ï¼Œæä¾›æ›´å¯é çš„æ¨ç†èƒ½åŠ›å’Œæ›´é«˜çš„æ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç¥ç»ç¬¦å·å­¦ä¹ æ—¨åœ¨è§£å†³ç¥ç»ç½‘ç»œåœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„è®­ç»ƒæŒ‘æˆ˜ï¼ŒåŒæ—¶æä¾›å¯è§£é‡Šæ€§ã€å¯é æ€§å’Œæ•ˆç‡çš„ä¼˜åŠ¿ã€‚ä¼ ç»Ÿçš„ç¥ç»ç¬¦å·å­¦ä¹ æ–¹æ³•åœ¨ä¸ç¬¦å·ç¨‹åºç»“åˆè®­ç»ƒç¥ç»æ¨¡å‹æ—¶é¢ä¸´æ˜¾è‘—æŒ‘æˆ˜ï¼Œé™åˆ¶äº†å…¶åº”ç”¨äºç®€å•é—®é¢˜ã€‚è€Œçº¯ç¥ç»åŸºç¡€æ¨¡å‹é€šè¿‡æç¤ºè€Œéè®­ç»ƒè¾¾åˆ°æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œä½†é€šå¸¸ç¼ºä¹å¯é æ€§å’Œå¯è§£é‡Šæ€§ã€‚æœ¬æ–‡æå‡ºé€šè¿‡å°†åŸºç¡€æ¨¡å‹ä¸ç¬¦å·ç¨‹åºç›¸ç»“åˆçš„ç¥ç»ç¬¦å·æç¤ºï¼Œæ¥è§£å†³å¤æ‚æ¨ç†ä»»åŠ¡ï¼Œå¹¶æ¢è®¨åœ¨åŸºç¡€æ¨¡å‹æ—¶ä»£ï¼Œä¸“é—¨æ¨¡å‹è®­ç»ƒåœ¨ç¥ç»ç¬¦å·å­¦ä¹ ä¸­çš„è§’è‰²ã€‚æˆ‘ä»¬æŒ‡å‡ºä¼ ç»Ÿç¥ç»ç¬¦å·å­¦ä¹ åœ¨è®¡ç®—ã€æ•°æ®å’Œç¨‹åºæ–¹é¢çš„ä¸‰å¤§é™·é˜±ï¼Œè®¤ä¸ºåŸºç¡€æ¨¡å‹èƒ½å¤Ÿå®ç°å¯æ³›åŒ–çš„ç¥ç»ç¬¦å·è§£å†³æ–¹æ¡ˆï¼Œæœç€å®ç°ç¥ç»ç¬¦å·å­¦ä¹ çš„åŸå§‹ç›®æ ‡è¿ˆè¿›ï¼Œè€Œæ— éœ€ä»å¤´å¼€å§‹è®­ç»ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è§£å†³çš„æ˜¯ä¼ ç»Ÿç¥ç»ç¬¦å·å­¦ä¹ åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„å±€é™æ€§ï¼Œå°¤å…¶æ˜¯åœ¨è®¡ç®—èµ„æºã€æ•°æ®éœ€æ±‚å’Œç¬¦å·ç¨‹åºçš„æœ‰æ•ˆæ€§æ–¹é¢å­˜åœ¨çš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€åªèƒ½å¤„ç†ç®€å•é—®é¢˜ï¼Œéš¾ä»¥æ‰©å±•åˆ°æ›´å¤æ‚çš„åœºæ™¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼•å…¥åŸºç¡€æ¨¡å‹ä¸ç¬¦å·ç¨‹åºçš„ç»“åˆï¼Œå½¢æˆä¸€ç§æ–°çš„ç¥ç»ç¬¦å·æç¤ºæ–¹æ³•ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨åˆ©ç”¨åŸºç¡€æ¨¡å‹çš„å¼ºå¤§èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒç¬¦å·ç¨‹åºçš„å¯è§£é‡Šæ€§å’Œå¯é æ€§ï¼Œä»è€Œæå‡æ¨ç†ä»»åŠ¡çš„æ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬åŸºç¡€æ¨¡å‹çš„é€‰æ‹©ã€ç¬¦å·ç¨‹åºçš„è®¾è®¡å’Œç¥ç»ç¬¦å·æç¤ºçš„å®ç°ã€‚é¦–å…ˆï¼Œé€‰æ‹©åˆé€‚çš„åŸºç¡€æ¨¡å‹ï¼Œç„¶åè®¾è®¡ç¬¦å·ç¨‹åºä»¥è¡¥å……åŸºç¡€æ¨¡å‹çš„ä¸è¶³ï¼Œæœ€åé€šè¿‡æç¤ºæœºåˆ¶å°†ä¸¤è€…ç»“åˆï¼Œå½¢æˆä¸€ä¸ªå®Œæ•´çš„æ¨ç†ç³»ç»Ÿã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†ç¥ç»ç¬¦å·æç¤ºçš„æ¦‚å¿µï¼Œè¿™ä¸€æ–¹æ³•ä¸åŒäºä¼ ç»Ÿçš„ç¥ç»ç¬¦å·å­¦ä¹ ï¼Œå®ƒä¸å†ä¾èµ–äºä»å¤´è®­ç»ƒæ¨¡å‹ï¼Œè€Œæ˜¯åˆ©ç”¨ç°æœ‰çš„åŸºç¡€æ¨¡å‹è¿›è¡Œæ¨ç†ï¼Œæ˜¾è‘—æé«˜äº†æ•ˆç‡å’Œå¯é æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å…³é”®è®¾è®¡æ–¹é¢ï¼Œè®ºæ–‡è¯¦ç»†è®¨è®ºäº†åŸºç¡€æ¨¡å‹çš„é€‰æ‹©æ ‡å‡†ã€ç¬¦å·ç¨‹åºçš„æ„å»ºæ–¹æ³•ä»¥åŠæç¤ºæœºåˆ¶çš„å®ç°ç»†èŠ‚ï¼ŒåŒ…æ‹¬å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°çš„è®¾è®¡ï¼Œä»¥ç¡®ä¿ç³»ç»Ÿçš„æœ‰æ•ˆæ€§å’Œç¨³å®šæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨ç¥ç»ç¬¦å·æç¤ºçš„æ–¹æ³•åœ¨å¤šä¸ªå¤æ‚æ¨ç†ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿç¥ç»ç¬¦å·å­¦ä¹ æ–¹æ³•ï¼Œå…·ä½“æ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œä¸”åœ¨å¯è§£é‡Šæ€§å’Œå¯é æ€§æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚è¿™ä¸€ç»“æœéªŒè¯äº†åŸºç¡€æ¨¡å‹åœ¨ç¥ç»ç¬¦å·å­¦ä¹ ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€çŸ¥è¯†å›¾è°±æ„å»ºå’Œå¤æ‚å†³ç­–æ”¯æŒç³»ç»Ÿç­‰ã€‚é€šè¿‡ç»“åˆåŸºç¡€æ¨¡å‹ä¸ç¬¦å·ç¨‹åºï¼Œèƒ½å¤Ÿåœ¨å¤šä¸ªé¢†åŸŸå®ç°æ›´é«˜æ•ˆçš„æ¨ç†å’Œå†³ç­–ï¼Œæå‡ç³»ç»Ÿçš„æ™ºèƒ½åŒ–æ°´å¹³ã€‚æœªæ¥ï¼Œè¿™ç§æ–¹æ³•æœ‰æœ›åœ¨è‡ªåŠ¨åŒ–æ¨ç†å’Œæ™ºèƒ½åŠ©æ‰‹ç­‰åº”ç”¨ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Neuro-symbolic learning was proposed to address challenges with training neural networks for complex reasoning tasks with the added benefits of interpretability, reliability, and efficiency. Neuro-symbolic learning methods traditionally train neural models in conjunction with symbolic programs, but they face significant challenges that limit them to simplistic problems. On the other hand, purely-neural foundation models now reach state-of-the-art performance through prompting rather than training, but they are often unreliable and lack interpretability. Supplementing foundation models with symbolic programs, which we call neuro-symbolic prompting, provides a way to use these models for complex reasoning tasks. Doing so raises the question: What role does specialized model training as part of neuro-symbolic learning have in the age of foundation models? To explore this question, we highlight three pitfalls of traditional neuro-symbolic learning with respect to the compute, data, and programs leading to generalization problems. This position paper argues that foundation models enable generalizable neuro-symbolic solutions, offering a path towards achieving the original goals of neuro-symbolic learning without the downsides of training from scratch.

