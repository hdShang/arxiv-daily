---
layout: default
title: Fine-Tune an SLM or Prompt an LLM? The Case of Generating Low-Code Workflows
---

# Fine-Tune an SLM or Prompt an LLM? The Case of Generating Low-Code Workflows

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.24189" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.24189v2</a>
  <a href="https://arxiv.org/pdf/2505.24189.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.24189v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.24189v2', 'Fine-Tune an SLM or Prompt an LLM? The Case of Generating Low-Code Workflows')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Orlando Marquez Ayala, Patrice Bechard, Emily Chen, Maggie Baird, Jingfei Chen

**åˆ†ç±»**: cs.LG, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-30 (æ›´æ–°: 2025-07-16)

**å¤‡æ³¨**: 8 pages, 7 figures. Accepted to Workshop on Structured Knowledge for Large Language Models (SKnowLLM) at KDD 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ¯”è¾ƒSLMå¾®è°ƒä¸LLMæç¤ºåœ¨ä½ä»£ç å·¥ä½œæµç”Ÿæˆä¸­çš„æ•ˆæœ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å°å‹è¯­è¨€æ¨¡å‹` `å¤§å‹è¯­è¨€æ¨¡å‹` `ä½ä»£ç å·¥ä½œæµ` `å¾®è°ƒ` `æç¤ºå­¦ä¹ ` `ç»“æ„åŒ–è¾“å‡º` `é”™è¯¯åˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç”Ÿæˆç»“æ„åŒ–è¾“å‡ºæ—¶ï¼ŒLLMsçš„æç¤ºæ•ˆæœä¸SLMsçš„å¾®è°ƒæ•ˆæœå°šä¸æ˜ç¡®ï¼Œå°¤å…¶æ˜¯åœ¨ç‰¹å®šé¢†åŸŸä»»åŠ¡ä¸­ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡æ¯”è¾ƒå¾®è°ƒSLMsä¸æç¤ºLLMsæ¥ç”Ÿæˆä½ä»£ç å·¥ä½œæµï¼Œæ¢è®¨ä¸¤è€…åœ¨è´¨é‡å’Œæ•ˆç‡ä¸Šçš„å·®å¼‚ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œå¾®è°ƒSLMsåœ¨ç”Ÿæˆè´¨é‡ä¸Šå¹³å‡æå‡10%ï¼ŒåŒæ—¶è¿›è¡Œçš„é”™è¯¯åˆ†ææ­ç¤ºäº†æ¨¡å‹çš„å±€é™æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¦‚GPT-4oèƒ½å¤Ÿé€šè¿‡åˆé€‚çš„æç¤ºå¤„ç†å¤šç§å¤æ‚ä»»åŠ¡ã€‚éšç€æ¯ä¸ªtokenæˆæœ¬çš„é™ä½ï¼Œå¾®è°ƒå°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰åœ¨å®é™…åº”ç”¨ä¸­çš„ä¼˜åŠ¿å¯èƒ½ä¸å†æ˜æ˜¾ã€‚æœ¬æ–‡æä¾›è¯æ®è¡¨æ˜ï¼Œå¯¹äºéœ€è¦ç»“æ„åŒ–è¾“å‡ºçš„é¢†åŸŸç‰¹å®šä»»åŠ¡ï¼ŒSLMsä»å…·æœ‰è´¨é‡ä¼˜åŠ¿ã€‚æˆ‘ä»¬æ¯”è¾ƒäº†åœ¨ç”ŸæˆJSONæ ¼å¼çš„ä½ä»£ç å·¥ä½œæµä»»åŠ¡ä¸­å¾®è°ƒSLMä¸æç¤ºLLMçš„æ•ˆæœã€‚ç»“æœæ˜¾ç¤ºï¼Œå°½ç®¡è‰¯å¥½çš„æç¤ºå¯ä»¥äº§ç”Ÿåˆç†ç»“æœï¼Œä½†å¾®è°ƒå¹³å‡æé«˜äº†10%çš„è´¨é‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è¿›è¡Œäº†ç³»ç»Ÿçš„é”™è¯¯åˆ†æï¼Œä»¥æ­ç¤ºæ¨¡å‹çš„å±€é™æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨ç”Ÿæˆä½ä»£ç å·¥ä½œæµæ—¶ï¼Œå¦‚ä½•é€‰æ‹©SLMå¾®è°ƒä¸LLMæç¤ºçš„æœ€ä½³ç­–ç•¥ã€‚ç°æœ‰æ–¹æ³•åœ¨ç‰¹å®šé¢†åŸŸä»»åŠ¡ä¸­å¯èƒ½å­˜åœ¨è´¨é‡ä¸è¶³çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ¯”è¾ƒå¾®è°ƒSLMsä¸æç¤ºLLMsçš„æ•ˆæœï¼Œæ¢è®¨åœ¨ç”Ÿæˆç»“æ„åŒ–è¾“å‡ºæ—¶ï¼ŒSLMsæ˜¯å¦ä»å…·æœ‰è´¨é‡ä¼˜åŠ¿ã€‚è®¾è®¡ä¸Šï¼Œå¼ºè°ƒå¾®è°ƒSLMsåœ¨ç‰¹å®šä»»åŠ¡ä¸­çš„é€‚åº”æ€§å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®å‡†å¤‡ã€æ¨¡å‹è®­ç»ƒä¸å¾®è°ƒã€æç¤ºè®¾è®¡ã€ç»“æœç”Ÿæˆä¸è¯„ä¼°ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬SLMå¾®è°ƒæ¨¡å—å’ŒLLMæç¤ºæ¨¡å—ï¼Œåˆ†åˆ«ç”¨äºç”Ÿæˆä½ä»£ç å·¥ä½œæµã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºç³»ç»Ÿæ€§åœ°æ¯”è¾ƒäº†SLMsä¸LLMsåœ¨ç‰¹å®šä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œå‘ç°å¾®è°ƒSLMsåœ¨è´¨é‡ä¸Šå…·æœ‰æ˜æ˜¾ä¼˜åŠ¿ï¼Œå°¤å…¶æ˜¯åœ¨ç»“æ„åŒ–è¾“å‡ºæ–¹é¢ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œå‚æ•°è®¾ç½®ï¼Œä»¥ä¼˜åŒ–SLMsåœ¨ç”Ÿæˆä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚ç½‘ç»œç»“æ„è®¾è®¡ä¸Šï¼Œé’ˆå¯¹ä½ä»£ç å·¥ä½œæµçš„ç‰¹ç‚¹è¿›è¡Œäº†è°ƒæ•´ï¼Œä»¥æé«˜ç”Ÿæˆè´¨é‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå¾®è°ƒSLMsåœ¨ç”Ÿæˆä½ä»£ç å·¥ä½œæµçš„è´¨é‡ä¸Šå¹³å‡æé«˜äº†10%ï¼Œç›¸è¾ƒäºæç¤ºLLMsçš„æ•ˆæœï¼Œå±•ç°å‡ºæ›´é«˜çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚æ­¤å¤–ï¼Œç³»ç»Ÿçš„é”™è¯¯åˆ†ææ­ç¤ºäº†æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸­çš„å±€é™æ€§ï¼Œä¸ºåç»­ç ”ç©¶æä¾›äº†é‡è¦å‚è€ƒã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è½¯ä»¶å¼€å‘ã€è‡ªåŠ¨åŒ–å·¥ä½œæµç”Ÿæˆå’Œæ™ºèƒ½åŠ©æ‰‹ç­‰ã€‚é€šè¿‡ä¼˜åŒ–ä½ä»£ç å·¥ä½œæµçš„ç”Ÿæˆè¿‡ç¨‹ï¼Œå¯ä»¥æé«˜å¼€å‘æ•ˆç‡ï¼Œé™ä½äººåŠ›æˆæœ¬ï¼Œæ¨åŠ¨æ™ºèƒ½åŒ–åº”ç”¨çš„å‘å±•ã€‚æœªæ¥ï¼Œéšç€æŠ€æœ¯çš„è¿›æ­¥ï¼ŒSLMsåœ¨æ›´å¤šé¢†åŸŸçš„åº”ç”¨å‰æ™¯å°†æ›´åŠ å¹¿é˜”ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) such as GPT-4o can handle a wide range of complex tasks with the right prompt. As per token costs are reduced, the advantages of fine-tuning Small Language Models (SLMs) for real-world applications -- faster inference, lower costs -- may no longer be clear. In this work, we present evidence that, for domain-specific tasks that require structured outputs, SLMs still have a quality advantage. We compare fine-tuning an SLM against prompting LLMs on the task of generating low-code workflows in JSON form. We observe that while a good prompt can yield reasonable results, fine-tuning improves quality by 10% on average. We also perform systematic error analysis to reveal model limitations.

