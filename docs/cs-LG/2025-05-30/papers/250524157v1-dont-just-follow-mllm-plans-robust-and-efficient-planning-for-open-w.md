---
layout: default
title: Don't Just Follow MLLM Plans: Robust and Efficient Planning for Open-world Agents
---

# Don't Just Follow MLLM Plans: Robust and Efficient Planning for Open-world Agents

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.24157" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.24157v1</a>
  <a href="https://arxiv.org/pdf/2505.24157.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.24157v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.24157v1', 'Don\'t Just Follow MLLM Plans: Robust and Efficient Planning for Open-world Agents')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Seungjoon Lee, Suhwan Kim, Minhyeon Oh, Youngsik Yoon, Jungseul Ok

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-30

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºREPOAæ¡†æ¶ä»¥è§£å†³å¼€æ”¾ä¸–ç•Œæ™ºèƒ½ä½“çš„è§„åˆ’æ•ˆç‡ä¸é²æ£’æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¼€æ”¾ä¸–ç•Œæ™ºèƒ½ä½“` `è§„åˆ’æ•ˆç‡` `é²æ£’æ€§` `è‡ªé€‚åº”å­¦ä¹ ` `å¤±è´¥æ„ŸçŸ¥` `åŸºäºéš¾åº¦çš„æ¢ç´¢` `å¤§å‹è¯­è¨€æ¨¡å‹` `å¤æ‚ä»»åŠ¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨è§„åˆ’ä¸­ä¾èµ–ä¸å‡†ç¡®çš„çŸ¥è¯†æˆ–ä¸åˆ‡å®é™…çš„ç¯å¢ƒå‡è®¾ï¼Œå¯¼è‡´æ™ºèƒ½ä½“åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„è¡¨ç°ä¸ä½³ã€‚
2. REPOAæ¡†æ¶é€šè¿‡è‡ªé€‚åº”ä¾èµ–å­¦ä¹ å’Œå¤±è´¥æ„ŸçŸ¥æ“ä½œè®°å¿†æ¥å¢å¼ºé²æ£’æ€§ï¼ŒåŒæ—¶é‡‡ç”¨åŸºäºéš¾åº¦çš„æ¢ç´¢ç­–ç•¥æé«˜å­¦ä¹ æ•ˆç‡ã€‚
3. åœ¨ä¸¤ä¸ªå¼€æ”¾ä¸–ç•Œæµ‹è¯•å¹³å°ä¸Šçš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼ŒREPOAåœ¨è·å–æŒ‘æˆ˜æ€§ç‰©å“æ–¹é¢è¡¨ç°ä¼˜äºä»¥å¾€æ–¹æ³•ï¼Œå±•ç°å‡ºæ›´å¼ºçš„è§„åˆ’èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¼€å‘èƒ½å¤Ÿåœ¨ä¸å¯é¢„æµ‹çš„äº¤äº’ç¯å¢ƒä¸­æŒæ¡å¤æ‚å¤šæ­¥éª¤ä»»åŠ¡çš„è‡ªä¸»æ™ºèƒ½ä½“é¢ä¸´é‡å¤§æŒ‘æˆ˜ã€‚å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è§„åˆ’æ–¹é¢å±•ç°å‡ºæ½œåŠ›ï¼Œä½†ç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–äºæœ‰é—®é¢˜çš„å†…éƒ¨çŸ¥è¯†æˆ–ä¸åˆ‡å®é™…çš„ç¯å¢ƒå‡è®¾ã€‚æœ¬æ–‡æå‡ºäº†é²æ£’ä¸”é«˜æ•ˆçš„å¼€æ”¾ä¸–ç•Œæ™ºèƒ½ä½“è§„åˆ’æ¡†æ¶ï¼ˆREPOAï¼‰ï¼Œé€šè¿‡è‡ªé€‚åº”ä¾èµ–å­¦ä¹ ã€ç»†ç²’åº¦å¤±è´¥æ„ŸçŸ¥æ“ä½œè®°å¿†å’ŒåŸºäºéš¾åº¦çš„æ¢ç´¢ï¼Œæ˜¾è‘—æå‡äº†è§„åˆ’çš„é²æ£’æ€§å’Œæ•ˆç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒREPOAåœ¨ä¸¤ä¸ªå¼€æ”¾ä¸–ç•Œæµ‹è¯•å¹³å°ä¸Šè¡¨ç°å‡ºè‰²ï¼ŒæˆåŠŸè·å–äº†ä»¥å¾€æ–¹æ³•æ— æ³•è¾¾åˆ°çš„æŒ‘æˆ˜æ€§æ¸¸æˆåæœŸç‰©å“ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¼€æ”¾ä¸–ç•Œæ™ºèƒ½ä½“åœ¨å¤æ‚ä»»åŠ¡ä¸­è§„åˆ’çš„é²æ£’æ€§ä¸æ•ˆç‡é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–äºä¸å‡†ç¡®çš„çŸ¥è¯†æˆ–ä¸åˆ‡å®é™…çš„å‡è®¾ï¼Œå¯¼è‡´æ™ºèƒ½ä½“åœ¨çœŸå®ç¯å¢ƒä¸­çš„è¡¨ç°ä¸ç†æƒ³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šREPOAæ¡†æ¶çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è‡ªé€‚åº”å­¦ä¹ å’Œå¤±è´¥æ„ŸçŸ¥æœºåˆ¶æ¥å¢å¼ºæ™ºèƒ½ä½“å¯¹çŸ¥è¯†ä¸å‡†ç¡®æ€§çš„é²æ£’æ€§ï¼ŒåŒæ—¶é€šè¿‡éš¾åº¦é©±åŠ¨çš„æ¢ç´¢ç­–ç•¥æé«˜å­¦ä¹ æ•ˆç‡ã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—æ™ºèƒ½ä½“èƒ½å¤Ÿåœ¨çœŸå®ç¯å¢ƒä¸­æ›´æœ‰æ•ˆåœ°å­¦ä¹ è§„åˆ’çŸ¥è¯†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šREPOAçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šè‡ªé€‚åº”ä¾èµ–å­¦ä¹ æ¨¡å—ã€ç»†ç²’åº¦å¤±è´¥æ„ŸçŸ¥æ“ä½œè®°å¿†æ¨¡å—å’ŒåŸºäºéš¾åº¦çš„æ¢ç´¢æ¨¡å—ã€‚è‡ªé€‚åº”ä¾èµ–å­¦ä¹ æ¨¡å—è´Ÿè´£è¯†åˆ«å’Œè°ƒæ•´çŸ¥è¯†ä¾èµ–å…³ç³»ï¼Œå¤±è´¥æ„ŸçŸ¥æ“ä½œè®°å¿†æ¨¡å—åˆ™è®°å½•å’Œåˆ†æå¤±è´¥æ¡ˆä¾‹ä»¥ä¼˜åŒ–å†³ç­–ï¼Œè€ŒåŸºäºéš¾åº¦çš„æ¢ç´¢æ¨¡å—åˆ™å¼•å¯¼æ™ºèƒ½ä½“åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­é€‰æ‹©æ›´å…·æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šREPOAçš„å…³é”®åˆ›æ–°åœ¨äºå…¶ç»“åˆäº†è‡ªé€‚åº”ä¾èµ–å­¦ä¹ ä¸å¤±è´¥æ„ŸçŸ¥æœºåˆ¶ï¼Œæ˜¾è‘—æé«˜äº†æ™ºèƒ½ä½“åœ¨é¢å¯¹ä¸å‡†ç¡®çŸ¥è¯†æ—¶çš„é²æ£’æ€§ã€‚è¿™ä¸€è®¾è®¡ä¸ä¼ ç»Ÿæ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºä¸å†ä¾èµ–å¤–éƒ¨çŸ¥è¯†ï¼Œè€Œæ˜¯é€šè¿‡å†…éƒ¨å­¦ä¹ æ¥è·å–è§„åˆ’çŸ¥è¯†ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼ŒREPOAé‡‡ç”¨äº†åŠ¨æ€è°ƒæ•´çš„å­¦ä¹ ç‡å’Œæ¢ç´¢ç­–ç•¥ï¼Œä»¥é€‚åº”ä¸åŒä»»åŠ¡çš„å¤æ‚æ€§ã€‚æ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸Šè€ƒè™‘äº†å¤±è´¥æ¡ˆä¾‹çš„æƒé‡ï¼Œä½¿å¾—æ™ºèƒ½ä½“åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­æ›´å…³æ³¨äºæ”¹è¿›å…¶å¼±ç‚¹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨ä¸¤ä¸ªå¼€æ”¾ä¸–ç•Œæµ‹è¯•å¹³å°ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒREPOAåœ¨è·å–æŒ‘æˆ˜æ€§æ¸¸æˆåæœŸç‰©å“æ–¹é¢çš„æˆåŠŸç‡æ˜¾è‘—é«˜äºä»¥å¾€æ–¹æ³•ï¼Œè¡¨ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§å’Œæ•ˆç‡ã€‚è¿™ä¸€æˆæœè¡¨æ˜ï¼ŒREPOAèƒ½å¤Ÿæœ‰æ•ˆåº”å¯¹å¤æ‚ç¯å¢ƒä¸­çš„è§„åˆ’æŒ‘æˆ˜ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

REPOAæ¡†æ¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦è‡ªä¸»å†³ç­–çš„é¢†åŸŸï¼Œå¦‚æœºå™¨äººå¯¼èˆªã€æ¸¸æˆAIå’Œæ™ºèƒ½å®¶å±…ç³»ç»Ÿã€‚å…¶é«˜æ•ˆçš„å­¦ä¹ èƒ½åŠ›å’Œé²æ£’æ€§ä½¿å¾—æ™ºèƒ½ä½“èƒ½å¤Ÿåœ¨å¤æ‚å’ŒåŠ¨æ€çš„ç¯å¢ƒä¸­è¡¨ç°å‡ºè‰²ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨è‡ªä¸»æ™ºèƒ½ä½“åœ¨å®é™…åº”ç”¨ä¸­çš„æ™®åŠä¸å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Developing autonomous agents capable of mastering complex, multi-step tasks in unpredictable, interactive environments presents a significant challenge. While Large Language Models (LLMs) offer promise for planning, existing approaches often rely on problematic internal knowledge or make unrealistic environmental assumptions. Although recent work explores learning planning knowledge, they still retain limitations due to partial reliance on external knowledge or impractical setups. Indeed, prior research has largely overlooked developing agents capable of acquiring planning knowledge from scratch, directly in realistic settings. While realizing this capability is necessary, it presents significant challenges, primarily achieving robustness given the substantial risk of incorporating LLMs' inaccurate knowledge. Moreover, efficiency is crucial for practicality as learning can demand prohibitive exploration. In response, we introduce Robust and Efficient Planning for Open-world Agents (REPOA), a novel framework designed to tackle these issues. REPOA features three key components: adaptive dependency learning and fine-grained failure-aware operation memory to enhance robustness to knowledge inaccuracies, and difficulty-based exploration to improve learning efficiency. Our evaluation in two established open-world testbeds demonstrates REPOA's robust and efficient planning, showcasing its capability to successfully obtain challenging late-game items that were beyond the reach of prior approaches.

