---
layout: default
title: Cascading Adversarial Bias from Injection to Distillation in Language Models
---

# Cascading Adversarial Bias from Injection to Distillation in Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.24842" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.24842v2</a>
  <a href="https://arxiv.org/pdf/2505.24842.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.24842v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.24842v2', 'Cascading Adversarial Bias from Injection to Distillation in Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Harsh Chaudhari, Jamie Hayes, Matthew Jagielski, Ilia Shumailov, Milad Nasr, Alina Oprea

**åˆ†ç±»**: cs.LG, cs.CR

**å‘å¸ƒæ—¥æœŸ**: 2025-05-30 (æ›´æ–°: 2025-10-05)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¯¹æŠ—æ€§åå·®ä¼ æ’­æœºåˆ¶ä»¥å¢å¼ºè¯­è¨€æ¨¡å‹çš„å®‰å…¨æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¯¹æŠ—æ€§æ”»å‡»` `æ¨¡å‹è’¸é¦` `åè§ä¼ æ’­` `å®‰å…¨æ€§ç ”ç©¶` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è’¸é¦æ¨¡å‹åœ¨é¢å¯¹å¯¹æŠ—æ€§æ³¨å…¥åè§å†…å®¹æ—¶å­˜åœ¨æ˜¾è‘—çš„è„†å¼±æ€§ï¼Œå½±å“å…¶å®‰å…¨æ€§å’Œå¯é æ€§ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸¤ç§åè§ä¼ æ’­æ¨¡å¼ï¼Œåˆ†åˆ«ä¸ºæ— ç›®æ ‡ä¼ æ’­å’Œæœ‰ç›®æ ‡ä¼ æ’­ï¼Œä»¥ç ”ç©¶åè§åœ¨è’¸é¦è¿‡ç¨‹ä¸­çš„æ”¾å¤§æ•ˆåº”ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå­¦ç”Ÿæ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸­ç”Ÿæˆåè§å“åº”çš„æ¦‚ç‡æ˜¾è‘—é«˜äºæ•™å¸ˆæ¨¡å‹ï¼Œæ­ç¤ºäº†å½“å‰é˜²å¾¡æœºåˆ¶çš„ä¸è¶³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ¨¡å‹è’¸é¦å·²æˆä¸ºåˆ›å»ºå°å‹å¯éƒ¨ç½²è¯­è¨€æ¨¡å‹çš„é‡è¦æ‰‹æ®µï¼Œä½†å…¶å¹¿æ³›åº”ç”¨å¼•å‘äº†å¯¹æŠ—æ€§æ“æ§çš„å®‰å…¨éšæ‚£ã€‚æœ¬æ–‡ç ”ç©¶äº†è’¸é¦æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯¹åè§å†…å®¹çš„å¯¹æŠ—æ€§æ³¨å…¥è„†å¼±æ€§ã€‚ç ”ç©¶è¡¨æ˜ï¼Œæ”»å‡»è€…å¯ä»¥é€šè¿‡æœ€å°çš„æ•°æ®ä¸­æ¯’å‘æ•™å¸ˆæ¨¡å‹æ³¨å…¥ç»†å¾®åè§ï¼Œè¿™äº›åè§ä¼šä¼ æ’­åˆ°å­¦ç”Ÿæ¨¡å‹å¹¶æ˜¾è‘—æ”¾å¤§ã€‚æˆ‘ä»¬æå‡ºäº†ä¸¤ç§ä¼ æ’­æ¨¡å¼ï¼šæ— ç›®æ ‡ä¼ æ’­å’Œæœ‰ç›®æ ‡ä¼ æ’­ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨æœ‰ç›®æ ‡åœºæ™¯ä¸‹ï¼Œå­¦ç”Ÿæ¨¡å‹ç”Ÿæˆåè§å“åº”çš„æ¦‚ç‡é«˜è¾¾76.9%ï¼Œæ˜¾è‘—é«˜äºæ•™å¸ˆæ¨¡å‹çš„69.4%ã€‚æ­¤å¤–ï¼Œé’ˆå¯¹æœªè§ä»»åŠ¡çš„æ— ç›®æ ‡ä¼ æ’­ä¸­ï¼Œå­¦ç”Ÿæ¨¡å‹çš„å¯¹æŠ—æ€§åè§å‡ºç°é¢‘ç‡æé«˜äº†6åˆ°29å€ã€‚æˆ‘ä»¬çš„ç ”ç©¶æ­ç¤ºäº†å½“å‰é˜²å¾¡æªæ–½çš„ä¸è¶³ï¼Œå¹¶æå‡ºäº†æœ‰æ•ˆçš„å¯¹æŠ—æ€§åè§ç¼“è§£ç­–ç•¥è®¾è®¡åŸåˆ™ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è’¸é¦æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯¹æŠ—æ€§åè§æ³¨å…¥çš„è„†å¼±æ€§ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆé˜²èŒƒæ­¤ç±»æ”»å‡»ï¼Œå¯¼è‡´æ¨¡å‹å®‰å…¨æ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡ç ”ç©¶åè§åœ¨æ•™å¸ˆæ¨¡å‹ä¸å­¦ç”Ÿæ¨¡å‹ä¹‹é—´çš„ä¼ æ’­æœºåˆ¶ï¼Œæå‡ºæ— ç›®æ ‡å’Œæœ‰ç›®æ ‡ä¸¤ç§ä¼ æ’­æ¨¡å¼ï¼Œä»¥æ­ç¤ºåè§çš„æ”¾å¤§æ•ˆåº”ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶æ¡†æ¶åŒ…æ‹¬æ•™å¸ˆæ¨¡å‹çš„è®­ç»ƒã€æ•°æ®ä¸­æ¯’çš„å®æ–½ã€å­¦ç”Ÿæ¨¡å‹çš„è’¸é¦è¿‡ç¨‹ï¼Œä»¥åŠå¯¹ç”Ÿæˆç»“æœçš„åè§è¯„ä¼°ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ•°æ®æ³¨å…¥ã€æ¨¡å‹è’¸é¦å’Œåè§æ£€æµ‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„åˆ›æ–°åœ¨äºæå‡ºäº†å¯¹æŠ—æ€§åè§çš„ä¼ æ’­æœºåˆ¶ï¼Œæ­ç¤ºäº†åè§åœ¨ä¸åŒä»»åŠ¡é—´çš„ä¼ æ’­ç‰¹æ€§ï¼Œå°¤å…¶æ˜¯å­¦ç”Ÿæ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸­çš„åè§æ”¾å¤§ç°è±¡ã€‚

**å…³é”®è®¾è®¡**ï¼šå®éªŒä¸­ä½¿ç”¨äº†25ä¸ªä¸­æ¯’æ ·æœ¬ï¼ˆ0.25%çš„ä¸­æ¯’ç‡ï¼‰ï¼Œå¹¶è¯„ä¼°äº†ä¸åŒåè§ç±»å‹çš„å½±å“ï¼Œé‡‡ç”¨äº†å¤šç§è’¸é¦æ–¹æ³•å’Œè¯„ä¼°æŒ‡æ ‡ä»¥ç¡®ä¿ç»“æœçš„å¯é æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨æœ‰ç›®æ ‡åœºæ™¯ä¸‹ï¼Œå­¦ç”Ÿæ¨¡å‹ç”Ÿæˆåè§å“åº”çš„æ¦‚ç‡é«˜è¾¾76.9%ï¼Œè€Œæ•™å¸ˆæ¨¡å‹ä¸º69.4%ã€‚åœ¨æ— ç›®æ ‡ä¼ æ’­ä¸­ï¼Œå­¦ç”Ÿæ¨¡å‹åœ¨æœªè§ä»»åŠ¡ä¸Šçš„å¯¹æŠ—æ€§åè§å‡ºç°é¢‘ç‡æé«˜äº†6åˆ°29å€ï¼Œæ­ç¤ºäº†æ˜¾è‘—çš„å®‰å…¨éšæ‚£ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€å¯¹è¯ç³»ç»Ÿå’Œè‡ªåŠ¨å†…å®¹ç”Ÿæˆç­‰ã€‚é€šè¿‡å¢å¼ºæ¨¡å‹å¯¹å¯¹æŠ—æ€§åè§çš„æŠµæŠ—åŠ›ï¼Œå¯ä»¥æé«˜ç³»ç»Ÿçš„å®‰å…¨æ€§å’Œå¯é æ€§ï¼Œå‡å°‘æ½œåœ¨çš„ç¤¾ä¼šå½±å“ã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶å¯èƒ½æ¨åŠ¨æ›´å®‰å…¨çš„è¯­è¨€æ¨¡å‹è®¾è®¡å’Œåº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Model distillation has become essential for creating smaller, deployable language models that retain larger system capabilities. However, widespread deployment raises concerns about resilience to adversarial manipulation. This paper investigates vulnerability of distilled models to adversarial injection of biased content during training. We demonstrate that adversaries can inject subtle biases into teacher models through minimal data poisoning, which propagates to student models and becomes significantly amplified. We propose two propagation modes: Untargeted Propagation, where bias affects multiple tasks, and Targeted Propagation, focusing on specific tasks while maintaining normal behavior elsewhere. With only 25 poisoned samples (0.25% poisoning rate), student models generate biased responses 76.9% of the time in targeted scenarios - higher than 69.4% in teacher models. For untargeted propagation, adversarial bias appears 6x-29x more frequently in student models on unseen tasks. We validate findings across six bias types (targeted advertisements, phishing links, narrative manipulations, insecure coding practices), various distillation methods, and different modalities spanning text and code generation. Our evaluation reveals shortcomings in current defenses - perplexity filtering, bias detection systems, and LLM-based autorater frameworks - against these attacks. Results expose significant security vulnerabilities in distilled models, highlighting need for specialized safeguards. We propose practical design principles for building effective adversarial bias mitigation strategies.

