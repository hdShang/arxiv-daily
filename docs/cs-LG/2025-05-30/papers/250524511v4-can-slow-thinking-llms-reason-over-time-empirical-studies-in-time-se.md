---
layout: default
title: Can Slow-thinking LLMs Reason Over Time? Empirical Studies in Time Series Forecasting
---

# Can Slow-thinking LLMs Reason Over Time? Empirical Studies in Time Series Forecasting

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.24511" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.24511v4</a>
  <a href="https://arxiv.org/pdf/2505.24511.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.24511v4" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.24511v4', 'Can Slow-thinking LLMs Reason Over Time? Empirical Studies in Time Series Forecasting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mingyue Cheng, Jiahao Wang, Daoyu Wang, Xiaoyu Tao, Qi Liu, Enhong Chen

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-30 (æ›´æ–°: 2025-12-21)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTimeReasonerä»¥è§£å†³æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„æ¨ç†ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ—¶é—´åºåˆ—é¢„æµ‹` `æ…¢æ€ç»´LLMs` `æ¡ä»¶æ¨ç†` `å¤šæ­¥æ¨ç†` `ä¸Šä¸‹æ–‡ä¾èµ–` `æ¨ç†æœºåˆ¶` `é‡‘èé¢„æµ‹` `æ°”è±¡é¢„æŠ¥`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ—¶é—´åºåˆ—é¢„æµ‹æ–¹æ³•å¤šé›†ä¸­äºå¿«é€Ÿæå–æ¨¡å¼ï¼Œç¼ºä¹å¯¹æ—¶é—´åŠ¨æ€çš„æ·±å…¥æ¨ç†ï¼Œå¯¼è‡´é¢„æµ‹å‡†ç¡®æ€§ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºTimeReasonerï¼Œå°†æ—¶é—´åºåˆ—é¢„æµ‹è§†ä¸ºæ¡ä»¶æ¨ç†ä»»åŠ¡ï¼Œé€šè¿‡è®¾è®¡æç¤ºç­–ç•¥å¼•å¯¼æ…¢æ€ç»´LLMsè¿›è¡Œæ¨ç†ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ…¢æ€ç»´LLMsåœ¨é›¶-shoté¢„æµ‹ä¸­å±•ç°å‡ºæ˜¾è‘—èƒ½åŠ›ï¼Œå°¤å…¶åœ¨æ•æ‰è¶‹åŠ¿å’Œä¸Šä¸‹æ–‡å˜åŒ–æ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ—¶é—´åºåˆ—é¢„æµ‹ï¼ˆTSFï¼‰æ˜¯ä¸€ä¸ªåŸºç¡€ä¸”å¹¿æ³›ç ”ç©¶çš„ä»»åŠ¡ï¼Œæ¶µç›–ä»ç»å…¸ç»Ÿè®¡æ–¹æ³•åˆ°ç°ä»£æ·±åº¦å­¦ä¹ å’Œå¤šæ¨¡æ€è¯­è¨€å»ºæ¨¡çš„å¤šç§æ–¹æ³•ã€‚å°½ç®¡è¿™äº›æ–¹æ³•æœ‰æ•ˆï¼Œä½†å¾€å¾€ä¾§é‡äºæ¨¡å¼æå–å’Œç›´æ¥å€¼æ˜ å°„ï¼Œå¿½è§†äº†å¯¹æ—¶é—´åŠ¨æ€å’Œä¸Šä¸‹æ–‡ä¾èµ–çš„æ˜ç¡®æ¨ç†ã€‚æ–°å…´çš„æ…¢æ€ç»´å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¦‚ChatGPT-o1å’ŒDeepSeek-R1åœ¨å¤šä¸ªé¢†åŸŸå±•ç¤ºäº†å‡ºè‰²çš„å¤šæ­¥æ¨ç†èƒ½åŠ›ï¼Œä¸ºå°†TSFé‡æ–°æ„æ¶ä¸ºç»“æ„åŒ–æ¨ç†ä»»åŠ¡æä¾›äº†æ–°æœºä¼šã€‚æœ¬æ–‡æå‡ºTimeReasonerï¼Œé€šè¿‡ä¸€ç³»åˆ—æç¤ºç­–ç•¥ä»é¢„è®­ç»ƒçš„æ…¢æ€ç»´LLMsä¸­å¼•å¯¼æ¨ç†ï¼Œå¹¶åœ¨å¤šç§TSFåŸºå‡†ä¸Šè¯„ä¼°å…¶æ€§èƒ½ã€‚ç ”ç©¶å‘ç°ï¼Œæ…¢æ€ç»´LLMsåœ¨é›¶-shoté¢„æµ‹ä¸­è¡¨ç°å‡ºéå¹³å‡¡çš„èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨æ•æ‰é«˜å±‚æ¬¡è¶‹åŠ¿å’Œä¸Šä¸‹æ–‡å˜åŒ–æ–¹é¢ã€‚æˆ‘ä»¬çš„ç ”ç©¶ä¸ºLLMsåœ¨æ—¶é—´é¢†åŸŸçš„æ¨ç†è¡Œä¸ºæä¾›äº†é‡è¦è§è§£ï¼Œçªæ˜¾äº†å…¶æ½œåŠ›å’Œå±€é™æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰æ—¶é—´åºåˆ—é¢„æµ‹æ–¹æ³•åœ¨æ¨ç†èƒ½åŠ›ä¸Šçš„ä¸è¶³ï¼Œç‰¹åˆ«æ˜¯å¯¹æ—¶é—´åŠ¨æ€å’Œä¸Šä¸‹æ–‡ä¾èµ–çš„å¿½è§†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å°†æ—¶é—´åºåˆ—é¢„æµ‹é‡æ–°æ„æ¶ä¸ºæ¡ä»¶æ¨ç†ä»»åŠ¡ï¼Œåˆ©ç”¨æ…¢æ€ç»´LLMsçš„æ¨ç†èƒ½åŠ›ï¼Œæ¢ç´¢å…¶åœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æç¤ºç­–ç•¥è®¾è®¡ã€LLMsæ¨ç†è¿‡ç¨‹åŠç»“æœè¯„ä¼°å››ä¸ªä¸»è¦æ¨¡å—ã€‚æ•°æ®é¢„å¤„ç†è´Ÿè´£æ•´ç†æ—¶é—´åºåˆ—æ•°æ®ï¼Œæç¤ºç­–ç•¥è®¾è®¡åˆ™ç”¨äºå¼•å¯¼LLMsè¿›è¡Œæœ‰æ•ˆæ¨ç†ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†æ—¶é—´åºåˆ—é¢„æµ‹è§†ä¸ºæ¨ç†ä»»åŠ¡ï¼Œåˆ©ç”¨æ…¢æ€ç»´LLMsçš„å¤šæ­¥æ¨ç†èƒ½åŠ›ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œå¼ºè°ƒäº†æ¨ç†è¿‡ç¨‹çš„é‡è¦æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æç¤ºç­–ç•¥ä¸­ï¼Œè®¾è®¡äº†å¤šç§å¼•å¯¼æ–¹å¼ï¼Œä»¥æ¿€å‘LLMsåœ¨æ¨ç†æ—¶çš„ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›ï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæ•æ‰åˆ°æ—¶é—´åºåˆ—ä¸­çš„é«˜å±‚æ¬¡è¶‹åŠ¿å’Œå˜åŒ–ã€‚å®éªŒä¸­è¿˜è€ƒè™‘äº†ä¸åŒçš„å‚æ•°è®¾ç½®ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ…¢æ€ç»´LLMsåœ¨é›¶-shotæ—¶é—´åºåˆ—é¢„æµ‹ä¸­è¡¨ç°å‡ºéå¹³å‡¡çš„èƒ½åŠ›ï¼Œå°¤å…¶åœ¨æ•æ‰é«˜å±‚æ¬¡è¶‹åŠ¿æ–¹é¢ï¼Œè¾ƒåŸºçº¿æ–¹æ³•æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œå±•ç¤ºäº†å…¶åœ¨å¤æ‚æ—¶é—´åºåˆ—ä»»åŠ¡ä¸­çš„æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬é‡‘èå¸‚åœºé¢„æµ‹ã€æ°”è±¡é¢„æŠ¥å’Œä¾›åº”é“¾ç®¡ç†ç­‰ï¼Œèƒ½å¤Ÿä¸ºå†³ç­–æä¾›æ›´ä¸ºå‡†ç¡®çš„æ—¶é—´åºåˆ—åˆ†æã€‚é€šè¿‡å¼•å…¥æ¨ç†æœºåˆ¶ï¼Œæœªæ¥çš„æ—¶é—´åºåˆ—é¢„æµ‹æ¡†æ¶å°†æ›´å…·å¯è§£é‡Šæ€§å’Œæ™®é€‚æ€§ï¼Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Time series forecasting (TSF) is a fundamental and widely studied task, spanning methods from classical statistical approaches to modern deep learning and multimodal language modeling. Despite their effectiveness, these methods often follow a fast thinking paradigm emphasizing pattern extraction and direct value mapping, while overlooking explicit reasoning over temporal dynamics and contextual dependencies. Meanwhile, emerging slow-thinking LLMs (e.g., ChatGPT-o1, DeepSeek-R1) have demonstrated impressive multi-step reasoning capabilities across diverse domains, suggesting a new opportunity for reframing TSF as a structured reasoning task. This motivates a key question: can slow-thinking LLMs effectively reason over temporal patterns to support time series forecasting, even in zero-shot manner? To investigate this, in this paper, we propose TimeReasoner, an extensive empirical study that formulates TSF as a conditional reasoning task. We design a series of prompting strategies to elicit inference-time reasoning from pretrained slow-thinking LLMs and evaluate their performance across diverse TSF benchmarks. Our findings reveal that slow-thinking LLMs exhibit non-trivial zero-shot forecasting capabilities, especially in capturing high-level trends and contextual shifts. While preliminary, our study surfaces important insights into the reasoning behaviors of LLMs in temporal domains highlighting both their potential and limitations. We hope this work catalyzes further research into reasoning-based forecasting paradigms and paves the way toward more interpretable and generalizable TSF frameworks.

