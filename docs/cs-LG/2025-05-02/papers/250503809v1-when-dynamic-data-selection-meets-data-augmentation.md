---
layout: default
title: When Dynamic Data Selection Meets Data Augmentation
---

# When Dynamic Data Selection Meets Data Augmentation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.03809" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.03809v1</a>
  <a href="https://arxiv.org/pdf/2505.03809.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.03809v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.03809v1', 'When Dynamic Data Selection Meets Data Augmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Suorong Yang, Peng Ye, Furao Shen, Dongzhan Zhou

**åˆ†ç±»**: cs.LG, cs.AI, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-02

**æœŸåˆŠ**: ICML 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåœ¨çº¿æ•°æ®è®­ç»ƒæ¡†æ¶ä»¥è§£å†³åŠ¨æ€æ•°æ®é€‰æ‹©ä¸æ•°æ®å¢å¼ºçš„ååŒé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åŠ¨æ€æ•°æ®é€‰æ‹©` `æ•°æ®å¢å¼º` `åœ¨çº¿è®­ç»ƒæ¡†æ¶` `æ¨¡å‹æ³›åŒ–` `æŠ—å™ªå£°èƒ½åŠ›`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŠ¨æ€æ•°æ®é€‰æ‹©æ–¹æ³•åœ¨åŠ é€Ÿè®­ç»ƒçš„åŒæ—¶ï¼Œå¾€å¾€ä¼šå¯¼è‡´æ•°æ®å¤šæ ·æ€§ä¸è¶³ï¼Œä»è€Œå½±å“æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„åœ¨çº¿æ•°æ®è®­ç»ƒæ¡†æ¶ï¼Œé¦–æ¬¡å°†åŠ¨æ€æ•°æ®é€‰æ‹©ä¸æ•°æ®å¢å¼ºç›¸ç»“åˆï¼Œä»¥æå‡è®­ç»ƒæ•ˆç‡ä¸æ¨¡å‹æ€§èƒ½ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä¾‹å¦‚åœ¨ImageNet-1kä¸Šå®ç°50%çš„è®­ç»ƒæˆæœ¬é™ä½ä¸”æ€§èƒ½æ— æŸã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŠ¨æ€æ•°æ®é€‰æ‹©æ—¨åœ¨åŠ é€Ÿè®­ç»ƒå¹¶ä¿æŒæ€§èƒ½ï¼Œä½†å‡å°‘è®­ç»ƒæ•°æ®ä¼šé™åˆ¶æ•°æ®å¤šæ ·æ€§ï¼Œå½±å“æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚å°½ç®¡æ•°æ®å¢å¼ºå¹¿æ³›åº”ç”¨äºæå‡å¤šæ ·æ€§ï¼Œä½†é€šå¸¸æœªä¸é€‰æ‹©ä¼˜åŒ–ç»“åˆï¼Œå¯¼è‡´ä¸¤è€…ååŒæ•ˆåº”æœªèƒ½å……åˆ†å‘æŒ¥ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡é¦–æ¬¡æå‡ºäº†ä¸€ç§æ–°é¢–çš„åœ¨çº¿æ•°æ®è®­ç»ƒæ¡†æ¶ï¼Œç»Ÿä¸€äº†åŠ¨æ€æ•°æ®é€‰æ‹©ä¸å¢å¼ºï¼Œå®ç°äº†è®­ç»ƒæ•ˆç‡ä¸æ€§èƒ½çš„åŒé‡æå‡ã€‚è¯¥æ–¹æ³•é€šè¿‡ä¼°è®¡æ¯ä¸ªæ ·æœ¬çš„å±€éƒ¨å¯†åº¦å’Œå¤šæ¨¡æ€è¯­ä¹‰ä¸€è‡´æ€§çš„è”åˆåˆ†å¸ƒï¼Œèƒ½å¤Ÿæœ‰é’ˆå¯¹æ€§åœ°é€‰æ‹©é€‚åˆå¢å¼ºçš„æ ·æœ¬ï¼ŒåŒæ—¶æŠ‘åˆ¶å™ªå£°æˆ–æ¨¡ç³Šæ•°æ®çš„åŒ…å«ï¼Œä»è€Œåœ¨ä¸ç‰ºç‰²æ¨¡å‹æ³›åŒ–èƒ½åŠ›çš„æƒ…å†µä¸‹æ˜¾è‘—å‡å°‘æ•°æ®é›†è§„æ¨¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†å’Œæ¶æ„ä¸Šä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œä¾‹å¦‚åœ¨ImageNet-1kä¸Šå‡å°‘50%çš„è®­ç»ƒæˆæœ¬è€Œæ€§èƒ½ä¸æŸå¤±ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•å¢å¼ºäº†æŠ—å™ªå£°èƒ½åŠ›ï¼Œæé«˜äº†æ¨¡å‹çš„é²æ£’æ€§ï¼Œå¼ºåŒ–äº†å…¶åœ¨å®é™…åœºæ™¯ä¸­çš„åº”ç”¨ä»·å€¼ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åŠ¨æ€æ•°æ®é€‰æ‹©ä¸æ•°æ®å¢å¼ºä¹‹é—´çš„ååŒé—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨é€‰æ‹©æ•°æ®æ—¶ï¼Œå¾€å¾€å¿½è§†äº†æ•°æ®å¢å¼ºçš„ä¼˜åŒ–ï¼Œå¯¼è‡´æ¨¡å‹æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡æå‡ºçš„æ¡†æ¶é€šè¿‡ä¼°è®¡æ ·æœ¬çš„å±€éƒ¨å¯†åº¦å’Œå¤šæ¨¡æ€è¯­ä¹‰ä¸€è‡´æ€§ï¼Œé€‰æ‹©é€‚åˆå¢å¼ºçš„æ ·æœ¬ï¼ŒåŒæ—¶æŠ‘åˆ¶å™ªå£°æ•°æ®ï¼Œä»è€Œå®ç°æ›´é«˜æ•ˆçš„è®­ç»ƒã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…å«æ•°æ®é€‰æ‹©æ¨¡å—å’Œæ•°æ®å¢å¼ºæ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡å±€éƒ¨å¯†åº¦ä¼°è®¡é€‰æ‹©æ ·æœ¬ï¼Œç„¶åå¯¹é€‰ä¸­çš„æ ·æœ¬è¿›è¡Œå¢å¼ºå¤„ç†ï¼Œæœ€åå°†å¢å¼ºæ ·æœ¬ç”¨äºæ¨¡å‹è®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„åˆ›æ–°åœ¨äºé¦–æ¬¡å°†åŠ¨æ€æ•°æ®é€‰æ‹©ä¸æ•°æ®å¢å¼ºæœ‰æœºç»“åˆï¼Œå½¢æˆä¸€ä¸ªç»Ÿä¸€çš„åœ¨çº¿è®­ç»ƒæ¡†æ¶ï¼Œæ˜¾è‘—æå‡äº†è®­ç»ƒæ•ˆç‡å’Œæ¨¡å‹æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†å±€éƒ¨å¯†åº¦å’Œè¯­ä¹‰ä¸€è‡´æ€§ä½œä¸ºé€‰æ‹©æ ‡å‡†ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸Šè€ƒè™‘äº†å¢å¼ºæ ·æœ¬çš„è´¨é‡ï¼Œç½‘ç»œç»“æ„åˆ™åŸºäºç°æœ‰çš„æ·±åº¦å­¦ä¹ æ¶æ„è¿›è¡Œä¼˜åŒ–ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå‡ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æŠ€æœ¯ã€‚åœ¨ImageNet-1kä¸Šï¼ŒæˆåŠŸå®ç°äº†50%çš„è®­ç»ƒæˆæœ¬é™ä½ï¼ŒåŒæ—¶ä¿æŒäº†æ€§èƒ½ä¸å˜ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„å®ç”¨ä»·å€¼ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨æŠ—å™ªå£°èƒ½åŠ›å’Œæ¨¡å‹é²æ£’æ€§æ–¹é¢ä¹Ÿæœ‰æ˜¾è‘—æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶åœ¨è®¡ç®—æœºè§†è§‰ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰é¢†åŸŸã€‚é€šè¿‡æé«˜æ¨¡å‹çš„è®­ç»ƒæ•ˆç‡å’Œé²æ£’æ€§ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­å®ç°é«˜æ•ˆå­¦ä¹ ï¼Œé€‚ç”¨äºå®æ—¶ç³»ç»Ÿå’Œå¤§è§„æ¨¡æ•°æ®å¤„ç†åœºæ™¯ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶å¯èƒ½æ¨åŠ¨æ›´å¤šé¢†åŸŸçš„æ™ºèƒ½åº”ç”¨å‘å±•ï¼Œæå‡æ¨¡å‹åœ¨å¤æ‚ç¯å¢ƒä¸‹çš„è¡¨ç°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Dynamic data selection aims to accelerate training with lossless performance. However, reducing training data inherently limits data diversity, potentially hindering generalization. While data augmentation is widely used to enhance diversity, it is typically not optimized in conjunction with selection. As a result, directly combining these techniques fails to fully exploit their synergies. To tackle the challenge, we propose a novel online data training framework that, for the first time, unifies dynamic data selection and augmentation, achieving both training efficiency and enhanced performance. Our method estimates each sample's joint distribution of local density and multimodal semantic consistency, allowing for the targeted selection of augmentation-suitable samples while suppressing the inclusion of noisy or ambiguous data. This enables a more significant reduction in dataset size without sacrificing model generalization. Experimental results demonstrate that our method outperforms existing state-of-the-art approaches on various benchmark datasets and architectures, e.g., reducing 50\% training costs on ImageNet-1k with lossless performance. Furthermore, our approach enhances noise resistance and improves model robustness, reinforcing its practical utility in real-world scenarios.

