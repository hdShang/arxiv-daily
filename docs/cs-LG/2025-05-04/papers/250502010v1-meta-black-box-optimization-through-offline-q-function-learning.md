---
layout: default
title: Meta-Black-Box-Optimization through Offline Q-function Learning
---

# Meta-Black-Box-Optimization through Offline Q-function Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.02010" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.02010v1</a>
  <a href="https://arxiv.org/pdf/2505.02010.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.02010v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.02010v1', 'Meta-Black-Box-Optimization through Offline Q-function Learning')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Zeyuan Ma, Zhiguang Cao, Zhou Jiang, Hongshu Guo, Yue-Jiao Gong

**ÂàÜÁ±ª**: cs.NE, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-04

**Â§áÊ≥®**: Accepted as poster by ICML 2025

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/MetaEvo/Q-Mamba)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Q-MambaÊ°ÜÊû∂‰ª•Ëß£ÂÜ≥MetaBBOÁöÑÊïàÁéáÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `ÂÖÉÈªëÁÆ±‰ºòÂåñ` `Á¶ªÁ∫øÂ≠¶‰π†` `Âä®ÊÄÅÁÆóÊ≥ïÈÖçÁΩÆ` `QÂáΩÊï∞ÂàÜËß£` `Âº∫ÂåñÂ≠¶‰π†` `ÁÆóÊ≥ïÊïàÁéá` `Êú∫Âô®Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâMetaBBOÊñπÊ≥ï‰æùËµñÂú®Á∫øÂ≠¶‰π†ÔºåÂØºËá¥ÊïàÁéá‰Ωé‰∏ãÔºåÈöæ‰ª•Êª°Ë∂≥ÂÆûÈôÖÂ∫îÁî®ÈúÄÊ±Ç„ÄÇ
2. Êú¨ÊñáÊèêÂá∫Q-MambaÊ°ÜÊû∂ÔºåÈÄöËøáÁ¶ªÁ∫øÂ≠¶‰π†ÂíåQÂáΩÊï∞ÂàÜËß£Êú∫Âà∂ÔºåÊèêÂçáMetaBBOÁöÑÂ≠¶‰π†ÊïàÁéáÂíåÊïàÊûú„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåQ-MambaÂú®ÊÄßËÉΩ‰∏ä‰ºò‰∫éÁé∞ÊúâÂü∫Á∫øÔºåÂêåÊó∂ËÆ≠ÁªÉÊïàÁéáÊòæËëóÊèêÈ´ò„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËøëÂπ¥Êù•ÔºåMeta-Black-Box-OptimizationÔºàMetaBBOÔºâÁöÑËøõÂ±ïË°®ÊòéÔºå‰ΩøÁî®Âº∫ÂåñÂ≠¶‰π†ÔºàRLÔºâÂ≠¶‰π†ÂÖÉÁ∫ßÁ≠ñÁï•‰ª•Âä®ÊÄÅÁÆóÊ≥ïÈÖçÁΩÆÔºàDACÔºâ‰ºòÂåñ‰ªªÂä°ÂàÜÂ∏ÉÔºåÂèØ‰ª•ÊòæËëóÊèêÂçá‰ΩéÁ∫ßBBOÁÆóÊ≥ïÁöÑÊÄßËÉΩ„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÊñπÊ≥ïÁöÑÂú®Á∫øÂ≠¶‰π†ËåÉÂºè‰ΩøÂæóMetaBBOÁöÑÊïàÁéáÂèóÂà∞ÊåëÊàò„ÄÇ‰∏∫Ê≠§ÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÁ¶ªÁ∫øÂ≠¶‰π†ÁöÑMetaBBOÊ°ÜÊû∂Q-MambaÔºå‰ª•ÂÆûÁé∞MetaBBOÁöÑÊúâÊïàÊÄßÂíåÊïàÁéá„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåÊàë‰ª¨È¶ñÂÖàÂ∞ÜDAC‰ªªÂä°ËΩ¨Âåñ‰∏∫ÈïøÂ∫èÂàóÂÜ≥Á≠ñËøáÁ®ãÔºåÂπ∂ÂºïÂÖ•ÊúâÊïàÁöÑQÂáΩÊï∞ÂàÜËß£Êú∫Âà∂Ôºå‰ª•Èôç‰ΩéÂ§çÊùÇÁÆóÊ≥ïÈÖçÁΩÆÁ©∫Èó¥‰∏≠ÁöÑÂ≠¶‰π†ÈöæÂ∫¶„ÄÇÈÄöËøáÂπøÊ≥õÁöÑÂü∫ÂáÜÊµãËØïÔºåÊàë‰ª¨ËßÇÂØüÂà∞Q-MambaÂú®ÊÄßËÉΩ‰∏ä‰∏éÁé∞ÊúâÂú®Á∫ø/Á¶ªÁ∫øÂü∫Á∫øÁõ∏ÂΩìÔºåÁîöËá≥Êõ¥‰ºòÔºåÂêåÊó∂ÊòæËëóÊèêÈ´ò‰∫ÜÁé∞ÊúâÂú®Á∫øÂü∫Á∫øÁöÑËÆ≠ÁªÉÊïàÁéá„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥MetaBBO‰∏≠Âú®Á∫øÂ≠¶‰π†ÊïàÁéá‰Ωé‰∏ãÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®Âä®ÊÄÅÁÆóÊ≥ïÈÖçÁΩÆÔºàDACÔºâ‰ªªÂä°‰∏≠Ôºå‰æùËµñÂú®Á∫øÂ≠¶‰π†ÔºåÂØºËá¥ËÆ≠ÁªÉËøáÁ®ãÁºìÊÖ¢‰∏î‰∏çÁ®≥ÂÆö„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÊèêÂá∫ÁöÑQ-MambaÊ°ÜÊû∂ÈÄöËøáÁ¶ªÁ∫øÂ≠¶‰π†Êù•‰ºòÂåñDACÁ≠ñÁï•ÔºåÂà©Áî®QÂáΩÊï∞ÂàÜËß£Êú∫Âà∂ÁÆÄÂåñÂ≠¶‰π†ËøáÁ®ãÔºå‰ªéËÄåÊèêÈ´òÂ≠¶‰π†ÊïàÁéáÂíåÁ®≥ÂÆöÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöQ-MambaÊ°ÜÊû∂ÂåÖÊã¨‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) Á¶ªÁ∫øDACÁªèÈ™åÊï∞ÊçÆÈõÜÊûÑÂª∫Á≠ñÁï•Ôºõ2) Âü∫‰∫éÂàÜËß£ÁöÑQÊçüÂ§±ÂáΩÊï∞ÔºåÁªìÂêà‰øùÂÆàQÂ≠¶‰π†Ôºõ3) MambaÊû∂ÊûÑÔºåÂ¢ûÂº∫ÈïøÂ∫èÂàóÂ≠¶‰π†ÁöÑÊúâÊïàÊÄßÂíåÊïàÁéá„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞Âú®‰∫éÂºïÂÖ•‰∫ÜÁ¶ªÁ∫øÂ≠¶‰π†Á≠ñÁï•ÂíåQÂáΩÊï∞ÂàÜËß£Êú∫Âà∂ÔºåËøô‰∏éÁé∞Êúâ‰æùËµñÂú®Á∫øÂ≠¶‰π†ÁöÑMetaBBOÊñπÊ≥ïÊú¨Ë¥®‰∏ä‰∏çÂêåÔºåÊòæËëóÊèêÂçá‰∫ÜÂ≠¶‰π†ÁöÑÁ®≥ÂÆöÊÄßÂíåÊïàÁéá„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÂÖ≥ÈîÆËÆæËÆ°‰∏äÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂπ≥Ë°°Êé¢Á¥¢‰∏éÂà©Áî®ÁöÑÁ¶ªÁ∫øÁªèÈ™åÊï∞ÊçÆÈõÜÊûÑÂª∫Á≠ñÁï•ÔºåÂπ∂ËÆæËÆ°‰∫ÜÂàÜËß£ÁöÑQÊçüÂ§±ÂáΩÊï∞Ôºå‰ª•‰øÉËøõÁ®≥ÂÆöÁöÑÁ¶ªÁ∫øÂ≠¶‰π†„ÄÇÊ≠§Â§ñÔºåMambaÊû∂ÊûÑÈÄöËøáÈÄâÊã©ÊÄßÁä∂ÊÄÅÊ®°ÂûãÂíåÁ°¨‰ª∂ÊÑüÁü•Âπ∂Ë°åÊâ´ÊèèÔºåËøõ‰∏ÄÊ≠•ÊèêÂçá‰∫ÜÂ≠¶‰π†ÊïàÁéá„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåQ-MambaÂú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞Âá∫Ëâ≤ÔºåÂÖ∂ÊÄßËÉΩ‰∏éÁé∞ÊúâÂú®Á∫ø/Á¶ªÁ∫øÂü∫Á∫øÁõ∏ÂΩìÔºåÁîöËá≥Âú®Êüê‰∫õ‰ªªÂä°‰∏≠Ë∂ÖË∂ä‰∫ÜËøô‰∫õÂü∫Á∫ø„ÄÇÂêåÊó∂ÔºåQ-MambaÊòæËëóÊèêÈ´ò‰∫ÜËÆ≠ÁªÉÊïàÁéáÔºåÁõ∏ËæÉ‰∫éÁé∞ÊúâÂú®Á∫øÂü∫Á∫øÔºåËÆ≠ÁªÉÊó∂Èó¥ÂáèÂ∞ë‰∫ÜÁ∫¶30%„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Ëá™Âä®ÂåñÁÆóÊ≥ïÈÖçÁΩÆ„ÄÅ‰ºòÂåñÈóÆÈ¢òÊ±ÇËß£‰ª•ÂèäÊô∫ËÉΩÁ≥ªÁªüÁöÑÂä®ÊÄÅÂÜ≥Á≠ñÊîØÊåÅ„ÄÇÈÄöËøáÊèêÈ´òMetaBBOÁöÑÊïàÁéáÔºåQ-MambaÊ°ÜÊû∂ÂèØ‰ª•Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÂÆûÁé∞Êõ¥Âø´ÈÄü„ÄÅÊõ¥È´òÊïàÁöÑÁÆóÊ≥ï‰ºòÂåñÔºåÊé®Âä®Êô∫ËÉΩÁÆóÊ≥ïÂú®Â§çÊùÇ‰ªªÂä°‰∏≠ÁöÑÂ∫îÁî®„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïÂèØËÉΩÂØπÂ§öÁßçÈ¢ÜÂüüÁöÑ‰ºòÂåñÈóÆÈ¢ò‰∫ßÁîüÊ∑±ËøúÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Recent progress in Meta-Black-Box-Optimization (MetaBBO) has demonstrated that using RL to learn a meta-level policy for dynamic algorithm configuration (DAC) over an optimization task distribution could significantly enhance the performance of the low-level BBO algorithm. However, the online learning paradigms in existing works makes the efficiency of MetaBBO problematic. To address this, we propose an offline learning-based MetaBBO framework in this paper, termed Q-Mamba, to attain both effectiveness and efficiency in MetaBBO. Specifically, we first transform DAC task into long-sequence decision process. This allows us further introduce an effective Q-function decomposition mechanism to reduce the learning difficulty within the intricate algorithm configuration space. Under this setting, we propose three novel designs to meta-learn DAC policy from offline data: we first propose a novel collection strategy for constructing offline DAC experiences dataset with balanced exploration and exploitation. We then establish a decomposition-based Q-loss that incorporates conservative Q-learning to promote stable offline learning from the offline dataset. To further improve the offline learning efficiency, we equip our work with a Mamba architecture which helps long-sequence learning effectiveness and efficiency by selective state model and hardware-aware parallel scan respectively. Through extensive benchmarking, we observe that Q-Mamba achieves competitive or even superior performance to prior online/offline baselines, while significantly improving the training efficiency of existing online baselines. We provide sourcecodes of Q-Mamba at https://github.com/MetaEvo/Q-Mamba.

