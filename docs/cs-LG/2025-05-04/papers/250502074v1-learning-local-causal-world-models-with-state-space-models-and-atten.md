---
layout: default
title: Learning Local Causal World Models with State Space Models and Attention
---

# Learning Local Causal World Models with State Space Models and Attention

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.02074" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.02074v1</a>
  <a href="https://arxiv.org/pdf/2505.02074.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.02074v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.02074v1', 'Learning Local Causal World Models with State Space Models and Attention')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Francesco Petri, Luigi Asprino, Aldo Gangemi

**åˆ†ç±»**: cs.LG, stat.ML

**å‘å¸ƒæ—¥æœŸ**: 2025-05-04

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºçŠ¶æ€ç©ºé—´æ¨¡å‹çš„å› æœä¸–ç•Œå»ºæ¨¡æ–¹æ³•ä»¥æå‡é¢„æµ‹èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å› æœå»ºæ¨¡` `çŠ¶æ€ç©ºé—´æ¨¡å‹` `ç¥ç»ç½‘ç»œ` `åŠ¨æ€å»ºæ¨¡` `æ™ºèƒ½ä½“` `é¢„æµ‹èƒ½åŠ›` `å¤æ‚ä»»åŠ¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å­¦ä¹ ç¯å¢ƒçš„å› æœè¡¨ç¤ºæ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œæ— æ³•æ·±å…¥ç†è§£ä¸–ç•Œä»¥æ‰§è¡Œå¤æ‚ä»»åŠ¡ã€‚
2. æœ¬æ–‡æå‡ºåˆ©ç”¨çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMï¼‰æ¶æ„è¿›è¡Œå› æœä¸–ç•Œå»ºæ¨¡ï¼Œæ—¨åœ¨æå‡å› æœå‘ç°èƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒSSMåœ¨å»ºæ¨¡ç®€å•ç¯å¢ƒåŠ¨æ€å’Œå­¦ä¹ å› æœæ¨¡å‹æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œæ€§èƒ½ä¼˜äºä¼ ç»ŸTransformerã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸–ç•Œå»ºæ¨¡ï¼Œå³æ„å»ºæè¿°ä¸–ç•Œæ¼”åŒ–è§„åˆ™çš„è¡¨ç¤ºï¼Œæ˜¯ä»»ä½•ä¸ç‰©ç†ä¸–ç•Œäº¤äº’çš„æ™ºèƒ½ä½“æ‰€å¿…éœ€çš„èƒ½åŠ›ã€‚å°½ç®¡ç°æœ‰æ–¹æ³•è¡¨ç°å‡ºè‰²ï¼Œä½†è®¸å¤šè§£å†³æ–¹æ¡ˆæœªèƒ½å­¦ä¹ ç¯å¢ƒçš„å› æœè¡¨ç¤ºï¼Œè¿™å¯¹äºæ·±å…¥ç†è§£ä¸–ç•Œä»¥æ‰§è¡Œå¤æ‚ä»»åŠ¡è‡³å…³é‡è¦ã€‚æœ¬æ–‡æ—¨åœ¨æ‹“å±•å› æœç†è®ºä¸ç¥ç»ä¸–ç•Œå»ºæ¨¡çš„äº¤å‰ç ”ç©¶ï¼Œè¯„ä¼°çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMï¼‰æ¶æ„åœ¨å› æœå‘ç°ä¸­çš„æ½œåŠ›ã€‚æˆ‘ä»¬é€šè¿‡å®éªŒè¯æ˜ï¼Œä¸ç­‰æ•ˆçš„Transformerç›¸æ¯”ï¼ŒSSMèƒ½å¤ŸåŒæ—¶å»ºæ¨¡ç®€å•ç¯å¢ƒçš„åŠ¨æ€å¹¶å­¦ä¹ å› æœæ¨¡å‹ï¼Œä¸”æ€§èƒ½ç›¸å½“æˆ–æ›´ä¼˜ï¼Œä»è€Œä¸ºè¿›ä¸€æ­¥åˆ©ç”¨SSMçš„ä¼˜åŠ¿å¹¶å¢å¼ºå…¶å› æœæ„è¯†çš„å®éªŒå¥ å®šåŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è§£å†³çš„é—®é¢˜æ˜¯å¦‚ä½•æœ‰æ•ˆå­¦ä¹ ç¯å¢ƒçš„å› æœè¡¨ç¤ºï¼Œä»¥ä¾¿æ™ºèƒ½ä½“èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œé¢„æµ‹ä¸–ç•Œçš„æ¼”åŒ–ã€‚ç°æœ‰æ–¹æ³•ï¼ˆå¦‚Transformerï¼‰åœ¨è¿™æ–¹é¢å­˜åœ¨å±€é™ï¼Œæ— æ³•å……åˆ†æ•æ‰å› æœå…³ç³»ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMï¼‰æ¶æ„ï¼Œé€šè¿‡å…¶å†…åœ¨çš„åŠ¨æ€å»ºæ¨¡èƒ½åŠ›æ¥å®ç°å› æœå‘ç°ã€‚SSMèƒ½å¤ŸåŒæ—¶å¤„ç†åŠ¨æ€å˜åŒ–å’Œå› æœå…³ç³»ï¼Œä»è€Œæå‡æ¨¡å‹çš„ç†è§£æ·±åº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®è¾“å…¥ã€çŠ¶æ€ç©ºé—´å»ºæ¨¡ã€å› æœå…³ç³»å­¦ä¹ å’Œè¾“å‡ºé¢„æµ‹å››ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œè¾“å…¥æ•°æ®ç»è¿‡çŠ¶æ€ç©ºé—´æ¨¡å‹è¿›è¡ŒåŠ¨æ€å»ºæ¨¡ï¼Œç„¶åé€šè¿‡å­¦ä¹ å› æœå…³ç³»æ¥ä¼˜åŒ–é¢„æµ‹è¾“å‡ºã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†SSMä¸å› æœå»ºæ¨¡ç›¸ç»“åˆï¼Œå…‹æœäº†ä¼ ç»Ÿæ–¹æ³•åœ¨å› æœè¡¨ç¤ºå­¦ä¹ ä¸­çš„ä¸è¶³ã€‚ä¸Transformerç›¸æ¯”ï¼ŒSSMåœ¨å¤„ç†åŠ¨æ€ç¯å¢ƒæ—¶è¡¨ç°å‡ºæ›´é«˜çš„çµæ´»æ€§å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–å› æœå…³ç³»çš„å­¦ä¹ ï¼Œå¹¶è°ƒæ•´äº†ç½‘ç»œç»“æ„ä»¥é€‚åº”çŠ¶æ€ç©ºé—´çš„åŠ¨æ€ç‰¹æ€§ã€‚å…³é”®å‚æ•°è®¾ç½®ç»è¿‡å¤šæ¬¡å®éªŒéªŒè¯ï¼Œä»¥ç¡®ä¿æ¨¡å‹çš„ç¨³å®šæ€§å’Œæ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSSMåœ¨å»ºæ¨¡ç®€å•ç¯å¢ƒåŠ¨æ€å’Œå­¦ä¹ å› æœæ¨¡å‹æ–¹é¢çš„æ€§èƒ½ä¼˜äºç­‰æ•ˆçš„Transformerï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨ç›¸åŒä»»åŠ¡ä¸‹ï¼ŒSSMçš„é¢„æµ‹å‡†ç¡®ç‡æå‡äº†çº¦15%ï¼Œå¹¶ä¸”åœ¨å› æœå…³ç³»çš„å­¦ä¹ ä¸Šè¡¨ç°å‡ºæ›´é«˜çš„ç¨³å®šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæ§åˆ¶ã€æ™ºèƒ½å†³ç­–ç³»ç»Ÿå’Œè‡ªåŠ¨é©¾é©¶ç­‰ã€‚é€šè¿‡æå‡æ™ºèƒ½ä½“å¯¹ç¯å¢ƒå› æœå…³ç³»çš„ç†è§£ï¼Œèƒ½å¤Ÿæ˜¾è‘—å¢å¼ºå…¶åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„è¡¨ç°å’Œé€‚åº”èƒ½åŠ›ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> World modelling, i.e. building a representation of the rules that govern the world so as to predict its evolution, is an essential ability for any agent interacting with the physical world. Despite their impressive performance, many solutions fail to learn a causal representation of the environment they are trying to model, which would be necessary to gain a deep enough understanding of the world to perform complex tasks. With this work, we aim to broaden the research in the intersection of causality theory and neural world modelling by assessing the potential for causal discovery of the State Space Model (SSM) architecture, which has been shown to have several advantages over the widespread Transformer. We show empirically that, compared to an equivalent Transformer, a SSM can model the dynamics of a simple environment and learn a causal model at the same time with equivalent or better performance, thus paving the way for further experiments that lean into the strength of SSMs and further enhance them with causal awareness.

