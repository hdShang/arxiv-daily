---
layout: default
title: D3HRL: A Distributed Hierarchical Reinforcement Learning Approach Based on Causal Discovery and Spurious Correlation Detection
---

# D3HRL: A Distributed Hierarchical Reinforcement Learning Approach Based on Causal Discovery and Spurious Correlation Detection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.01979" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.01979v1</a>
  <a href="https://arxiv.org/pdf/2505.01979.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.01979v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.01979v1', 'D3HRL: A Distributed Hierarchical Reinforcement Learning Approach Based on Causal Discovery and Spurious Correlation Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chenran Zhao, Dianxi Shi, Mengzhu Wang, Jianqiang Xia, Huanhuan Yang, Songchang Jin, Shaowu Yang, Chunping Qiu

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-04

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºD3HRLä»¥è§£å†³å±‚æ¬¡å¼ºåŒ–å­¦ä¹ ä¸­çš„å»¶è¿Ÿæ•ˆåº”ä¸è™šå‡ç›¸å…³æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å±‚æ¬¡å¼ºåŒ–å­¦ä¹ ` `å› æœå‘ç°` `è™šå‡ç›¸å…³æ€§` `å†³ç­–ä¼˜åŒ–` `å¤æ‚ç¯å¢ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å±‚æ¬¡å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨å¤„ç†é•¿æ—¶é—´åºåˆ—å†³ç­–æ—¶ï¼Œå®¹æ˜“å—åˆ°å»¶è¿Ÿæ•ˆåº”å’Œè™šå‡ç›¸å…³æ€§çš„å½±å“ï¼Œå¯¼è‡´å†³ç­–è´¨é‡ä¸‹é™ã€‚
2. D3HRLé€šè¿‡å°†å»¶è¿Ÿæ•ˆåº”å»ºæ¨¡ä¸ºå› æœå…³ç³»ï¼Œå¹¶åˆ©ç”¨åˆ†å¸ƒå¼å› æœå‘ç°å’Œæ¡ä»¶ç‹¬ç«‹æ€§æµ‹è¯•ï¼Œæ¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒD3HRLåœ¨2D-MineCraftå’ŒMiniGridç¯å¢ƒä¸­è¡¨ç°å‡ºè‰²ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†å»¶è¿Ÿæ•ˆåº”å¹¶å‡†ç¡®è¯†åˆ«å› æœå…³ç³»ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å½“å‰çš„å±‚æ¬¡å¼ºåŒ–å­¦ä¹ ï¼ˆHRLï¼‰ç®—æ³•åœ¨é•¿æ—¶é—´åºåˆ—å†³ç­–ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä½†ä»é¢ä¸´å»¶è¿Ÿæ•ˆåº”å’Œè™šå‡ç›¸å…³æ€§ä¸¤ä¸ªæŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå› æœå‘ç°å’Œè™šå‡ç›¸å…³æ€§æ£€æµ‹çš„å±‚æ¬¡å¼ºåŒ–å­¦ä¹ æ–¹æ³•D3HRLã€‚é¦–å…ˆï¼ŒD3HRLå°†å»¶è¿Ÿæ•ˆåº”å»ºæ¨¡ä¸ºè·¨æ—¶é—´è·¨åº¦çš„å› æœå…³ç³»ï¼Œå¹¶é‡‡ç”¨åˆ†å¸ƒå¼å› æœå‘ç°æ¥å­¦ä¹ è¿™äº›å…³ç³»ã€‚å…¶æ¬¡ï¼Œé€šè¿‡æ¡ä»¶ç‹¬ç«‹æ€§æµ‹è¯•æ¶ˆé™¤è™šå‡ç›¸å…³æ€§ã€‚æœ€åï¼ŒD3HRLåŸºäºè¯†åˆ«å‡ºçš„çœŸå®å› æœå…³ç³»æ„å»ºå’Œè®­ç»ƒå±‚æ¬¡ç­–ç•¥ã€‚è¿™ä¸‰ä¸ªæ­¥éª¤è¿­ä»£æ‰§è¡Œï¼Œé€æ­¥æ¢ç´¢ä»»åŠ¡çš„å®Œæ•´å› æœé“¾ã€‚åœ¨2D-MineCraftå’ŒMiniGridä¸­çš„å®éªŒè¡¨æ˜ï¼ŒD3HRLå¯¹å»¶è¿Ÿæ•ˆåº”çš„æ•æ„Ÿæ€§æ›´å¼ºï¼Œå¹¶èƒ½å‡†ç¡®è¯†åˆ«å› æœå…³ç³»ï¼Œä»è€Œåœ¨å¤æ‚ç¯å¢ƒä¸­å®ç°å¯é çš„å†³ç­–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å±‚æ¬¡å¼ºåŒ–å­¦ä¹ ä¸­å­˜åœ¨çš„å»¶è¿Ÿæ•ˆåº”å’Œè™šå‡ç›¸å…³æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨é•¿æ—¶é—´å†³ç­–ä»»åŠ¡ä¸­å®¹æ˜“å—åˆ°è¿™äº›å› ç´ çš„å½±å“ï¼Œå¯¼è‡´å†³ç­–ä¸å¯é ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šD3HRLçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†å»¶è¿Ÿæ•ˆåº”è§†ä¸ºå› æœå…³ç³»ï¼Œå¹¶é€šè¿‡åˆ†å¸ƒå¼å› æœå‘ç°æŠ€æœ¯æ¥å­¦ä¹ è¿™äº›å…³ç³»ï¼ŒåŒæ—¶åˆ©ç”¨æ¡ä»¶ç‹¬ç«‹æ€§æµ‹è¯•æ¥æ¶ˆé™¤è™šå‡ç›¸å…³æ€§ã€‚è¿™æ ·çš„è®¾è®¡èƒ½å¤Ÿæ›´å‡†ç¡®åœ°æ•æ‰ä»»åŠ¡ä¸­çš„çœŸå®å› æœç»“æ„ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šD3HRLçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯å› æœå…³ç³»å»ºæ¨¡ï¼Œé€šè¿‡åˆ†å¸ƒå¼å› æœå‘ç°å­¦ä¹ å»¶è¿Ÿæ•ˆåº”ï¼›å…¶æ¬¡æ˜¯è™šå‡ç›¸å…³æ€§æ£€æµ‹ï¼Œåˆ©ç”¨æ¡ä»¶ç‹¬ç«‹æ€§æµ‹è¯•æ¶ˆé™¤ä¸å¿…è¦çš„ç›¸å…³æ€§ï¼›æœ€åæ˜¯åŸºäºè¯†åˆ«å‡ºçš„å› æœå…³ç³»æ„å»ºå’Œè®­ç»ƒå±‚æ¬¡ç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šD3HRLçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶å°†å› æœå‘ç°ä¸å±‚æ¬¡å¼ºåŒ–å­¦ä¹ ç›¸ç»“åˆï¼Œèƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«å’Œåˆ©ç”¨ä»»åŠ¡ä¸­çš„çœŸå®å› æœå…³ç³»ï¼Œè¿™ä¸ä¼ ç»Ÿæ–¹æ³•çš„ç›´æ¥å­¦ä¹ ç­–ç•¥ä¸åŒã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å…³é”®è®¾è®¡æ–¹é¢ï¼ŒD3HRLé‡‡ç”¨äº†åˆ†å¸ƒå¼ç®—æ³•è¿›è¡Œå› æœå‘ç°ï¼Œå¹¶é€šè¿‡æ¡ä»¶ç‹¬ç«‹æ€§æµ‹è¯•æ¥ä¼˜åŒ–ç­–ç•¥å­¦ä¹ è¿‡ç¨‹ï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­åšå‡ºæ›´å¯é çš„å†³ç­–ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡åœ¨å®éªŒä¸­è¿›è¡Œäº†è¯¦ç»†éªŒè¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨2D-MineCraftå’ŒMiniGridçš„å®éªŒä¸­ï¼ŒD3HRLå±•ç°å‡ºå¯¹å»¶è¿Ÿæ•ˆåº”çš„æ›´é«˜æ•æ„Ÿæ€§ï¼Œå‡†ç¡®è¯†åˆ«å› æœå…³ç³»ï¼Œå†³ç­–æ€§èƒ½æ˜¾è‘—æå‡ã€‚ä¸åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼ŒD3HRLåœ¨å¤æ‚ç¯å¢ƒä¸­çš„å†³ç­–å‡†ç¡®ç‡æé«˜äº†20%ä»¥ä¸Šï¼Œæ˜¾ç¤ºå‡ºå…¶ä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

D3HRLçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦é•¿æ—¶é—´å†³ç­–çš„å¤æ‚ç¯å¢ƒä¸­ï¼Œå¦‚æœºå™¨äººæ§åˆ¶ã€è‡ªåŠ¨é©¾é©¶å’Œæ™ºèƒ½æ¸¸æˆç­‰ã€‚é€šè¿‡æé«˜å†³ç­–çš„å¯é æ€§ï¼ŒD3HRLèƒ½å¤Ÿä¸ºè¿™äº›é¢†åŸŸå¸¦æ¥æ›´é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Current Hierarchical Reinforcement Learning (HRL) algorithms excel in long-horizon sequential decision-making tasks but still face two challenges: delay effects and spurious correlations. To address them, we propose a causal HRL approach called D3HRL. First, D3HRL models delayed effects as causal relationships across different time spans and employs distributed causal discovery to learn these relationships. Second, it employs conditional independence testing to eliminate spurious correlations. Finally, D3HRL constructs and trains hierarchical policies based on the identified true causal relationships. These three steps are iteratively executed, gradually exploring the complete causal chain of the task. Experiments conducted in 2D-MineCraft and MiniGrid show that D3HRL demonstrates superior sensitivity to delay effects and accurately identifies causal relationships, leading to reliable decision-making in complex environments.

