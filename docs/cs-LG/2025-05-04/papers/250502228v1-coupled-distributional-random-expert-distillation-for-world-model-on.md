---
layout: default
title: Coupled Distributional Random Expert Distillation for World Model Online Imitation Learning
---

# Coupled Distributional Random Expert Distillation for World Model Online Imitation Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.02228" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.02228v1</a>
  <a href="https://arxiv.org/pdf/2505.02228.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.02228v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.02228v1', 'Coupled Distributional Random Expert Distillation for World Model Online Imitation Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shangzhe Li, Zhiao Huang, Hao Su

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-04

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºéšæœºç½‘ç»œè’¸é¦çš„å¥–åŠ±æ¨¡å‹ä»¥è§£å†³æ¨¡ä»¿å­¦ä¹ ä¸ç¨³å®šæ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æ¨¡ä»¿å­¦ä¹ ` `éšæœºç½‘ç»œè’¸é¦` `å¥–åŠ±æ¨¡å‹` `ç¨³å®šæ€§` `ä¸“å®¶çº§è¡¨ç°` `æœºå™¨äººæ§åˆ¶` `è‡ªåŠ¨é©¾é©¶` `å¯†åº¦ä¼°è®¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ¨¡ä»¿å­¦ä¹ æ–¹æ³•åœ¨ä½¿ç”¨å¯¹æŠ—æ€§å¥–åŠ±æˆ–ä»·å€¼å‡½æ•°æ—¶ï¼Œå¸¸å¸¸é¢ä¸´ä¸ç¨³å®šæ€§é—®é¢˜ï¼Œå½±å“å­¦ä¹ æ•ˆæœã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºéšæœºç½‘ç»œè’¸é¦çš„å¥–åŠ±æ¨¡å‹ï¼Œé€šè¿‡è”åˆä¼°è®¡ä¸“å®¶å’Œè¡Œä¸ºåˆ†å¸ƒæ¥å¢å¼ºæ¨¡ä»¿å­¦ä¹ çš„ç¨³å®šæ€§ã€‚
3. åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼Œæ‰€ææ–¹æ³•åœ¨è¿åŠ¨å’Œæ“ä½œä»»åŠ¡ä¸Šå‡è¡¨ç°å‡ºè‰²ï¼Œè¾¾åˆ°äº†ä¸“å®¶çº§çš„å­¦ä¹ æ•ˆæœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ¨¡ä»¿å­¦ä¹ ï¼ˆILï¼‰åœ¨æœºå™¨äººã€è‡ªåŠ¨é©¾é©¶å’ŒåŒ»ç–—ç­‰å¤šä¸ªé¢†åŸŸå–å¾—äº†æ˜¾è‘—æˆåŠŸï¼Œä½¿å¾—æ™ºèƒ½ä½“èƒ½å¤Ÿä»ä¸“å®¶ç¤ºèŒƒä¸­å­¦ä¹ å¤æ‚è¡Œä¸ºã€‚ç„¶è€Œï¼Œç°æœ‰çš„ILæ–¹æ³•åœ¨ä¾èµ–å¯¹æŠ—æ€§å¥–åŠ±æˆ–ä»·å€¼å…¬å¼çš„ä¸–ç•Œæ¨¡å‹æ¡†æ¶æ—¶ï¼Œå¸¸å¸¸é¢ä¸´ä¸ç¨³å®šæ€§æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„åœ¨çº¿æ¨¡ä»¿å­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡åŸºäºéšæœºç½‘ç»œè’¸é¦ï¼ˆRNDï¼‰çš„å¥–åŠ±æ¨¡å‹è¿›è¡Œå¯†åº¦ä¼°è®¡ï¼Œè§£å†³äº†è¿™äº›å±€é™æ€§ã€‚æˆ‘ä»¬çš„å¥–åŠ±æ¨¡å‹åŸºäºä¸“å®¶å’Œè¡Œä¸ºåˆ†å¸ƒåœ¨ä¸–ç•Œæ¨¡å‹æ½œåœ¨ç©ºé—´ä¸­çš„è”åˆä¼°è®¡ã€‚æˆ‘ä»¬åœ¨DMControlã€Meta-Worldå’ŒManiSkill2ç­‰å¤šä¸ªåŸºå‡†ä¸Šè¯„ä¼°äº†è¯¥æ–¹æ³•ï¼Œå±•ç¤ºäº†å…¶åœ¨è¿åŠ¨å’Œæ“ä½œä»»åŠ¡ä¸­æä¾›ç¨³å®šæ€§èƒ½å¹¶è¾¾åˆ°ä¸“å®¶çº§ç»“æœçš„èƒ½åŠ›ã€‚æˆ‘ä»¬çš„æ–¹æ¡ˆåœ¨ä¿æŒä¸“å®¶çº§æ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—æé«˜äº†ç›¸è¾ƒäºå¯¹æŠ—æ€§æ–¹æ³•çš„ç¨³å®šæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ¨¡ä»¿å­¦ä¹ ä¸­ç”±äºå¯¹æŠ—æ€§å¥–åŠ±æˆ–ä»·å€¼å‡½æ•°å¯¼è‡´çš„ä¸ç¨³å®šæ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤æ‚ç¯å¢ƒä¸­è¡¨ç°ä¸ä½³ï¼Œéš¾ä»¥ä¿è¯å­¦ä¹ çš„ç¨³å®šæ€§å’Œæœ‰æ•ˆæ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºéšæœºç½‘ç»œè’¸é¦çš„å¥–åŠ±æ¨¡å‹ï¼Œé€šè¿‡åœ¨æ½œåœ¨ç©ºé—´ä¸­è”åˆä¼°è®¡ä¸“å®¶å’Œè¡Œä¸ºåˆ†å¸ƒï¼Œæ¥æä¾›æ›´åŠ ç¨³å®šçš„å¥–åŠ±ä¿¡å·ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨å‡å°‘å¯¹æŠ—æ€§æ–¹æ³•å¸¦æ¥çš„ä¸ç¡®å®šæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯ä¸“å®¶è¡Œä¸ºçš„åˆ†å¸ƒå»ºæ¨¡ï¼Œå…¶æ¬¡æ˜¯è¡Œä¸ºè€…çš„åˆ†å¸ƒä¼°è®¡ï¼Œæœ€åæ˜¯åŸºäºè¿™ä¸¤è€…çš„å¥–åŠ±æ¨¡å‹æ„å»ºã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ™ºèƒ½ä½“èƒ½å¤Ÿåœ¨å­¦ä¹ è¿‡ç¨‹ä¸­è·å¾—æ›´å¯é çš„åé¦ˆã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥äº†éšæœºç½‘ç»œè’¸é¦ä½œä¸ºå¥–åŠ±æ¨¡å‹çš„åŸºç¡€ï¼Œä½¿å¾—å¥–åŠ±ä¿¡å·çš„ç”Ÿæˆæ›´åŠ ç¨³å®šï¼Œæ˜¾è‘—æ”¹å–„äº†æ¨¡ä»¿å­¦ä¹ çš„æ•ˆæœã€‚è¿™ä¸ä¼ ç»Ÿçš„å¯¹æŠ—æ€§æ–¹æ³•å½¢æˆäº†é²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸Šï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–å¥–åŠ±æ¨¡å‹ï¼Œå¹¶é€šè¿‡è°ƒæ•´ç½‘ç»œç»“æ„æ¥å¢å¼ºæ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œå‚æ•°è®¾ç½®ç»è¿‡ç²¾å¿ƒè°ƒæ•´ï¼Œä»¥ç¡®ä¿åœ¨ä¸åŒä»»åŠ¡ä¸Šçš„é€‚åº”æ€§å’Œç¨³å®šæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨è¿åŠ¨å’Œæ“ä½œä»»åŠ¡ä¸Šå‡è¡¨ç°å‡ºè‰²ï¼Œè¾¾åˆ°äº†ä¸“å®¶çº§çš„å­¦ä¹ æ•ˆæœã€‚ä¸ä¼ ç»Ÿå¯¹æŠ—æ€§æ–¹æ³•ç›¸æ¯”ï¼Œç¨³å®šæ€§æ˜¾è‘—æé«˜ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨DMControlå’ŒMeta-Worldç­‰ä»»åŠ¡ä¸­ï¼ŒæˆåŠŸç‡æå‡äº†20%ä»¥ä¸Šï¼Œå±•ç¤ºäº†è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæ§åˆ¶ã€è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿä»¥åŠåŒ»ç–—è¾…åŠ©å†³ç­–ç­‰ã€‚é€šè¿‡æé«˜æ¨¡ä»¿å­¦ä¹ çš„ç¨³å®šæ€§å’Œæ•ˆç‡ï¼Œèƒ½å¤Ÿä½¿å¾—æ™ºèƒ½ä½“åœ¨å¤æ‚ç¯å¢ƒä¸­æ›´å¥½åœ°å­¦ä¹ å’Œé€‚åº”ï¼Œä»è€Œåœ¨å®é™…åº”ç”¨ä¸­å®ç°æ›´é«˜çš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›åœ¨æ›´å¤šåŠ¨æ€å’Œä¸ç¡®å®šçš„ç¯å¢ƒä¸­å¾—åˆ°å¹¿æ³›åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Imitation Learning (IL) has achieved remarkable success across various domains, including robotics, autonomous driving, and healthcare, by enabling agents to learn complex behaviors from expert demonstrations. However, existing IL methods often face instability challenges, particularly when relying on adversarial reward or value formulations in world model frameworks. In this work, we propose a novel approach to online imitation learning that addresses these limitations through a reward model based on random network distillation (RND) for density estimation. Our reward model is built on the joint estimation of expert and behavioral distributions within the latent space of the world model. We evaluate our method across diverse benchmarks, including DMControl, Meta-World, and ManiSkill2, showcasing its ability to deliver stable performance and achieve expert-level results in both locomotion and manipulation tasks. Our approach demonstrates improved stability over adversarial methods while maintaining expert-level performance.

