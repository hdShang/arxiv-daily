---
layout: default
title: Practical Adversarial Attacks on Stochastic Bandits via Fake Data Injection
---

# Practical Adversarial Attacks on Stochastic Bandits via Fake Data Injection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21938" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21938v2</a>
  <a href="https://arxiv.org/pdf/2505.21938.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21938v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21938v2', 'Practical Adversarial Attacks on Stochastic Bandits via Fake Data Injection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Qirun Zeng, Eric He, Richard Hoffmann, Xuchuang Wang, Jinhang Zuo

**åˆ†ç±»**: cs.LG, cs.AI, cs.CR

**å‘å¸ƒæ—¥æœŸ**: 2025-05-28 (æ›´æ–°: 2025-05-31)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå‡æ•°æ®æ³¨å…¥æ¨¡å‹ä»¥è§£å†³éšæœºå¸¦å®½çš„å¯¹æŠ—æ”»å‡»é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `å¯¹æŠ—æ”»å‡»` `éšæœºå¸¦å®½` `å‡æ•°æ®æ³¨å…¥` `æœºå™¨å­¦ä¹ ` `ç®—æ³•å®‰å…¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¯¹æŠ—æ”»å‡»æ–¹æ³•é€šå¸¸ä¾èµ–äºä¸åˆ‡å®é™…çš„å‡è®¾ï¼Œé™åˆ¶äº†å…¶åœ¨çœŸå®ä¸–ç•Œä¸­çš„åº”ç”¨ã€‚
2. æœ¬æ–‡æå‡ºå‡æ•°æ®æ³¨å…¥æ¨¡å‹ï¼Œå…è®¸æ”»å‡»è€…åœ¨æœ‰é™çš„çº¦æŸä¸‹æ³¨å…¥å‡åé¦ˆï¼Œæ¨¡æ‹Ÿåˆæ³•äº¤äº’ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æç­–ç•¥åœ¨å¤šè½®ä¸­æœ‰æ•ˆè¯¯å¯¼äº†ä¸»æµç®—æ³•ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„è„†å¼±æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¯¹éšæœºå¸¦å®½çš„å¯¹æŠ—æ”»å‡»ä¼ ç»Ÿä¸Šä¾èµ–äºä¸€äº›ä¸åˆ‡å®é™…çš„å‡è®¾ï¼Œä¾‹å¦‚æ¯è½®å¥–åŠ±æ“æ§å’Œæ— é™æ‰°åŠ¨ï¼Œè¿™é™åˆ¶äº†å…¶åœ¨ç°å®ç³»ç»Ÿä¸­çš„ç›¸å…³æ€§ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ›´ä¸ºå®é™…çš„å¨èƒæ¨¡å‹â€”â€”å‡æ•°æ®æ³¨å…¥ï¼Œåæ˜ äº†ç°å®å¯¹æŠ—çº¦æŸï¼šæ”»å‡»è€…åªèƒ½å°†æœ‰é™æ•°é‡çš„æœ‰ç•Œå‡åé¦ˆæ ·æœ¬æ³¨å…¥å­¦ä¹ è€…çš„å†å²ä¸­ï¼Œä»¥æ¨¡æ‹Ÿåˆæ³•äº¤äº’ã€‚æˆ‘ä»¬åœ¨æ­¤æ¨¡å‹ä¸‹è®¾è®¡äº†é«˜æ•ˆçš„æ”»å‡»ç­–ç•¥ï¼Œæ˜ç¡®è§£å†³äº†å¥–åŠ±å€¼çš„å¹…åº¦çº¦æŸå’Œæ•°æ®æ³¨å…¥çš„æ—¶é—´çº¦æŸã€‚ç†è®ºåˆ†æè¡¨æ˜ï¼Œè¿™äº›æ”»å‡»å¯ä»¥åœ¨å‡ ä¹æ‰€æœ‰è½®æ¬¡ä¸­è¯¯å¯¼ä¸Šç½®ä¿¡ç•Œï¼ˆUCBï¼‰å’Œæ±¤æ™®æ£®é‡‡æ ·ç®—æ³•é€‰æ‹©ç›®æ ‡è‡‚ï¼ŒåŒæ—¶ä»…éœ€ä»˜å‡ºæ¬¡çº¿æ€§æ”»å‡»æˆæœ¬ã€‚å¯¹åˆæˆå’ŒçœŸå®æ•°æ®é›†çš„å®éªŒéªŒè¯äº†æˆ‘ä»¬ç­–ç•¥çš„æœ‰æ•ˆæ€§ï¼Œæ­ç¤ºäº†å¹¿æ³›ä½¿ç”¨çš„éšæœºå¸¦å®½ç®—æ³•åœ¨å®é™…å¯¹æŠ—åœºæ™¯ä¸‹çš„æ˜¾è‘—è„†å¼±æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è§£å†³çš„æ˜¯éšæœºå¸¦å®½ç®—æ³•åœ¨é¢å¯¹å¯¹æŠ—æ”»å‡»æ—¶çš„è„†å¼±æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸å‡è®¾æ”»å‡»è€…å¯ä»¥æ— é™åˆ¶åœ°æ“æ§å¥–åŠ±ï¼Œè¿™åœ¨å®é™…åº”ç”¨ä¸­å¹¶ä¸ç°å®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„å‡æ•°æ®æ³¨å…¥æ¨¡å‹å…è®¸æ”»å‡»è€…åœ¨æœ‰é™çš„æ—¶é—´å’Œå¹…åº¦å†…æ³¨å…¥å‡åé¦ˆï¼Œä»è€Œæ›´çœŸå®åœ°æ¨¡æ‹Ÿå¯¹æŠ—åœºæ™¯ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ”»å‡»è€…å¯ä»¥æœ‰æ•ˆåœ°è¯¯å¯¼å­¦ä¹ ç®—æ³•ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ”»å‡»ç­–ç•¥è®¾è®¡ã€ç†è®ºåˆ†æå’Œå®éªŒéªŒè¯ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚æ”»å‡»ç­–ç•¥è®¾è®¡ä¸­è€ƒè™‘äº†å¥–åŠ±å€¼å’Œæ—¶é—´çš„çº¦æŸï¼Œç†è®ºåˆ†æåˆ™éªŒè¯äº†æ”»å‡»çš„æœ‰æ•ˆæ€§ï¼Œæœ€åé€šè¿‡å®éªŒéªŒè¯äº†ç­–ç•¥åœ¨çœŸå®æ•°æ®é›†ä¸Šçš„è¡¨ç°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†å‡æ•°æ®æ³¨å…¥è¿™ä¸€æ–°æ¨¡å‹ï¼Œçªç ´äº†ä¼ ç»Ÿæ–¹æ³•å¯¹æ”»å‡»è€…èƒ½åŠ›çš„é™åˆ¶ï¼Œä½¿å¾—æ”»å‡»æ›´åŠ è´´è¿‘å®é™…åº”ç”¨åœºæ™¯ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œè®¾ç½®äº†æ”»å‡»çš„å¹…åº¦å’Œæ—¶é—´çº¦æŸï¼Œç¡®ä¿æ”»å‡»è€…çš„è¡Œä¸ºåœ¨å¯æ¥å—èŒƒå›´å†…ã€‚åŒæ—¶ï¼Œé‡‡ç”¨äº†ç†è®ºåˆ†ææ–¹æ³•æ¥è¯„ä¼°æ”»å‡»çš„æ•ˆæœï¼Œç¡®ä¿äº†ç­–ç•¥çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ”»å‡»ç­–ç•¥åœ¨å¤šè½®ä¸­èƒ½å¤Ÿæœ‰æ•ˆè¯¯å¯¼UCBå’Œæ±¤æ™®æ£®é‡‡æ ·ç®—æ³•ï¼Œæ”»å‡»æˆæœ¬ä»…ä¸ºæ¬¡çº¿æ€§ï¼Œä¸”åœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šå‡è¡¨ç°å‡ºæ˜¾è‘—çš„æ•ˆæœï¼Œæ­ç¤ºäº†éšæœºå¸¦å®½ç®—æ³•çš„è„†å¼±æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åœ¨çº¿æ¨èç³»ç»Ÿã€å¹¿å‘ŠæŠ•æ”¾å’ŒåŠ¨æ€å®šä»·ç­‰åœºæ™¯ã€‚åœ¨è¿™äº›é¢†åŸŸä¸­ï¼Œæ”»å‡»è€…å¯èƒ½é€šè¿‡æ³¨å…¥å‡æ•°æ®æ¥æ“æ§ç³»ç»Ÿå†³ç­–ï¼Œä»è€Œå½±å“ç”¨æˆ·ä½“éªŒå’Œå•†ä¸šåˆ©ç›Šã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶æœ‰åŠ©äºæå‡ç®—æ³•çš„é²æ£’æ€§ï¼Œå‡å°‘å¯¹æŠ—æ”»å‡»çš„å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Adversarial attacks on stochastic bandits have traditionally relied on some unrealistic assumptions, such as per-round reward manipulation and unbounded perturbations, limiting their relevance to real-world systems. We propose a more practical threat model, Fake Data Injection, which reflects realistic adversarial constraints: the attacker can inject only a limited number of bounded fake feedback samples into the learner's history, simulating legitimate interactions. We design efficient attack strategies under this model, explicitly addressing both magnitude constraints (on reward values) and temporal constraints (on when and how often data can be injected). Our theoretical analysis shows that these attacks can mislead both Upper Confidence Bound (UCB) and Thompson Sampling algorithms into selecting a target arm in nearly all rounds while incurring only sublinear attack cost. Experiments on synthetic and real-world datasets validate the effectiveness of our strategies, revealing significant vulnerabilities in widely used stochastic bandit algorithms under practical adversarial scenarios.

