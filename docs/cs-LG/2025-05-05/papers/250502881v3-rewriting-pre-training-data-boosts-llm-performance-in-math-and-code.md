---
layout: default
title: Rewriting Pre-Training Data Boosts LLM Performance in Math and Code
---

# Rewriting Pre-Training Data Boosts LLM Performance in Math and Code

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.02881" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.02881v3</a>
  <a href="https://arxiv.org/pdf/2505.02881.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.02881v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.02881v3', 'Rewriting Pre-Training Data Boosts LLM Performance in Math and Code')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kazuki Fujii, Yukito Tajima, Sakae Mizuki, Hinari Shimada, Taihei Shiotani, Koshiro Saito, Masanari Ohi, Masaki Kawamura, Taishi Nakamura, Takumi Okamoto, Shigeki Ishida, Kakeru Hattori, Youmi Ma, Hiroya Takamura, Rio Yokota, Naoaki Okazaki

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-05 (æ›´æ–°: 2025-07-04)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é€šè¿‡é‡å†™é¢„è®­ç»ƒæ•°æ®æå‡å¤§è¯­è¨€æ¨¡å‹åœ¨æ•°å­¦å’Œä»£ç ç”Ÿæˆä¸­çš„è¡¨ç°**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `ç¨‹åºåˆæˆ` `æ•°å­¦æ¨ç†` `æ•°æ®é›†é‡å†™` `é¢„è®­ç»ƒä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç¨‹åºåˆæˆå’Œæ•°å­¦æ¨ç†ä¸­å—é™äºé¢„è®­ç»ƒæ•°æ®çš„è´¨é‡ï¼Œå¯¼è‡´æ€§èƒ½ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºçš„SwallowCodeå’ŒSwallowMathæ•°æ®é›†ï¼Œé€šè¿‡é‡å†™å…¬å…±æ•°æ®ï¼Œç³»ç»Ÿæ€§æå‡äº†LLMçš„æ€§èƒ½ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨æ–°æ•°æ®é›†è¿›è¡Œé¢„è®­ç»ƒï¼ŒLLMåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æé«˜äº†å‡†ç¡®ç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç¨‹åºåˆæˆå’Œæ•°å­¦æ¨ç†ä¸­çš„æ€§èƒ½å—åˆ°é¢„è®­ç»ƒè¯­æ–™è´¨é‡çš„æ ¹æœ¬é™åˆ¶ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸¤ä¸ªå¼€æ”¾è®¸å¯çš„æ•°æ®é›†ï¼Œé€šè¿‡ç³»ç»Ÿæ€§é‡å†™å…¬å…±æ•°æ®æ˜¾è‘—æå‡LLMæ€§èƒ½ã€‚SwallowCodeï¼ˆçº¦161äº¿ä¸ªæ ‡è®°ï¼‰é€šè¿‡å››é˜¶æ®µæµç¨‹ç²¾ç‚¼Pythonä»£ç ç‰‡æ®µï¼ŒSwallowMathï¼ˆçº¦23äº¿ä¸ªæ ‡è®°ï¼‰åˆ™é€šè¿‡å»é™¤å†—ä½™ã€æ¢å¤ä¸Šä¸‹æ–‡å’Œé‡æ–°æ ¼å¼åŒ–è§£å†³æ–¹æ¡ˆæ¥å¢å¼ºæ•°å­¦æ•°æ®ã€‚åœ¨å›ºå®šçš„500äº¿æ ‡è®°è®­ç»ƒé¢„ç®—å†…ï¼Œä½¿ç”¨SwallowCodeè¿›è¡ŒLlama-3.1-8Bçš„æŒç»­é¢„è®­ç»ƒï¼Œåœ¨HumanEvalå’ŒHumanEval+ä¸Šåˆ†åˆ«æå‡äº†17.0å’Œ17.7çš„é€šè¿‡ç‡ï¼Œè¶…è¶Šäº†åŸºçº¿æ¨¡å‹çš„ä»£ç ç”Ÿæˆèƒ½åŠ›ã€‚æ‰€æœ‰æ•°æ®é›†ã€æç¤ºå’Œæ£€æŸ¥ç‚¹å‡å…¬å¼€å¯ç”¨ï¼Œä¿ƒè¿›å¯é‡å¤ç ”ç©¶å¹¶æ¨åŠ¨LLMåœ¨ä¸“ä¸šé¢†åŸŸçš„é¢„è®­ç»ƒè¿›å±•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç¨‹åºåˆæˆå’Œæ•°å­¦æ¨ç†ä¸­å› é¢„è®­ç»ƒæ•°æ®è´¨é‡ä¸è¶³è€Œå¯¼è‡´çš„æ€§èƒ½é™åˆ¶ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–æ’é™¤æ€§è¿‡æ»¤æˆ–æœ‰é™çš„è½¬æ¢ï¼Œæœªèƒ½æœ‰æ•ˆåˆ©ç”¨ä½è´¨é‡ä»£ç ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºçš„é‡å†™å’Œä¿ç•™æ–¹æ³•é€šè¿‡ç³»ç»Ÿæ€§é‡å†™å…¬å…±æ•°æ®ï¼Œæå‡äº†æ•°æ®çš„å®ç”¨æ€§ï¼Œæœ€å¤§åŒ–äº†ä½è´¨é‡ä»£ç çš„åˆ©ç”¨ç‡ï¼Œä»è€Œå¢å¼ºäº†æ¨¡å‹çš„å­¦ä¹ æ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åˆ†ä¸ºä¸¤ä¸ªä¸»è¦æ•°æ®é›†ï¼šSwallowCodeå’ŒSwallowMathã€‚SwallowCodeç»è¿‡è¯­æ³•éªŒè¯ã€åŸºäºpylintçš„é£æ ¼è¿‡æ»¤å’Œä¸¤é˜¶æ®µçš„LLMé‡å†™ï¼Œç¡®ä¿ä»£ç ç‰‡æ®µçš„é£æ ¼ä¸€è‡´æ€§å’Œç®—æ³•æ•ˆç‡ï¼›SwallowMathåˆ™é€šè¿‡å»é™¤å†—ä½™ã€æ¢å¤ä¸Šä¸‹æ–‡å’Œé€æ­¥è§£é‡Šæ ¼å¼åŒ–è§£å†³æ–¹æ¡ˆæ¥æå‡æ•°å­¦æ•°æ®è´¨é‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºé‡å†™å’Œä¿ç•™æ–¹æ³•çš„å¼•å…¥ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡ä½è´¨é‡ä»£ç çš„è´¨é‡ï¼Œè€Œä¸ä»…ä»…æ˜¯æ’é™¤ä¸åˆæ ¼æ•°æ®ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨SwallowCodeä¸­ï¼Œé‡‡ç”¨äº†å››é˜¶æ®µçš„å¤„ç†æµç¨‹ï¼Œç¡®ä¿æ¯ä¸ªé˜¶æ®µéƒ½èƒ½æå‡ä»£ç è´¨é‡ï¼›åœ¨SwallowMathä¸­ï¼Œé‡å†™è¿‡ç¨‹å¼ºè°ƒäº†ä¸Šä¸‹æ–‡çš„æ¢å¤å’Œè§£å†³æ–¹æ¡ˆçš„æ¸…æ™°è¡¨è¾¾ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨SwallowCodeè¿›è¡ŒLlama-3.1-8Bçš„æŒç»­é¢„è®­ç»ƒï¼Œåœ¨HumanEvalä¸Šæå‡äº†17.0çš„é€šè¿‡ç‡ï¼Œåœ¨HumanEval+ä¸Šæå‡äº†17.7ï¼›ä½¿ç”¨SwallowMathåˆ™åœ¨GSM8Kå’ŒMATHä¸Šåˆ†åˆ«æå‡äº†12.4å’Œ7.6çš„å‡†ç¡®ç‡ï¼Œæ˜¾è‘—è¶…è¶Šäº†åŸºçº¿æ¨¡å‹ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€ç¼–ç¨‹è¾…åŠ©å·¥å…·å’Œè‡ªåŠ¨åŒ–ä»£ç ç”Ÿæˆç­‰ã€‚é€šè¿‡æå‡LLMåœ¨æ•°å­¦å’Œä»£ç ç”Ÿæˆæ–¹é¢çš„èƒ½åŠ›ï¼Œå¯ä»¥ä¸ºå¼€å‘æ›´æ™ºèƒ½çš„ç¼–ç¨‹åŠ©æ‰‹ã€æ•™è‚²å·¥å…·å’Œè‡ªåŠ¨åŒ–ç³»ç»Ÿæä¾›æ”¯æŒï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The performance of large language models (LLMs) in program synthesis and mathematical reasoning is fundamentally limited by the quality of their pre-training corpora. We introduce two openly licensed datasets, released under the Llama 3.3 Community License, that significantly enhance LLM performance by systematically rewriting public data. SwallowCode (approximately 16.1 billion tokens) refines Python snippets from The-Stack-v2 through a novel four-stage pipeline: syntax validation, pylint-based style filtering, and a two-stage LLM rewriting process that enforces style conformity and transforms snippets into self-contained, algorithmically efficient examples. Unlike prior methods that rely on exclusionary filtering or limited transformations, our transform-and-retain approach upgrades low-quality code, maximizing data utility. SwallowMath (approximately 2.3 billion tokens) enhances Finemath-4+ by removing boilerplate, restoring context, and reformatting solutions into concise, step-by-step explanations. Within a fixed 50 billion token training budget, continual pre-training of Llama-3.1-8B with SwallowCode boosts pass@1 by +17.0 on HumanEval and +17.7 on HumanEval+ compared to Stack-Edu, surpassing the baseline model's code generation capabilities. Similarly, substituting SwallowMath yields +12.4 accuracy on GSM8K and +7.6 on MATH. Ablation studies confirm that each pipeline stage contributes incrementally, with rewriting delivering the largest gains. All datasets, prompts, and checkpoints are publicly available, enabling reproducible research and advancing LLM pre-training for specialized domains.

