---
layout: default
title: "Radio: Rate-Distortion Optimization for Large Language Model Compression"
---

# Radio: Rate-Distortion Optimization for Large Language Model Compression

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.03031" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.03031v1</a>
  <a href="https://arxiv.org/pdf/2505.03031.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.03031v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.03031v1', 'Radio: Rate-Distortion Optimization for Large Language Model Compression')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sean I. Young

**åˆ†ç±»**: cs.LG, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-05

**å¤‡æ³¨**: Accepted to ICML 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºç‡å¤±çœŸä¼˜åŒ–çš„LLMå‹ç¼©æ–¹æ³•ä»¥è§£å†³èµ„æºé™åˆ¶é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ¨¡å‹å‹ç¼©` `ç‡å¤±çœŸä¼˜åŒ–` `é‡åŒ–æŠ€æœ¯` `åè®­ç»ƒå‹ç¼©`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„LLMå‹ç¼©æ–¹æ³•åœ¨èµ„æºå—é™è®¾å¤‡ä¸Šçš„åº”ç”¨é¢ä¸´æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨è®¡ç®—æˆæœ¬å’Œç¯å¢ƒå½±å“æ–¹é¢ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºç‡å¤±çœŸä¼˜åŒ–çš„é‡åŒ–æŠ€æœ¯ï¼Œæ—¨åœ¨æé«˜LLMçš„å‹ç¼©æ•ˆç‡ï¼Œæ”¯æŒå¤§è§„æ¨¡æ¨¡å‹çš„çµæ´»å‹ç¼©ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°å‹ç¼©å¤§å‹è¯­è¨€æ¨¡å‹ï¼ŒåŒæ—¶ä¿æŒç”¨æˆ·æŒ‡å®šçš„æ¨¡å‹å¤§å°å’Œå‡†ç¡®åº¦ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‹ç¼©æˆä¸ºåœ¨èµ„æºæœ‰é™è®¾å¤‡ä¸Šéƒ¨ç½²LLMã€é™ä½è®¡ç®—æˆæœ¬åŠå‡è½»å¤§è§„æ¨¡AIåŸºç¡€è®¾æ–½ç¯å¢ƒå½±å“çš„å…³é”®é—®é¢˜ã€‚æœ¬æ–‡ä»ç‡å¤±çœŸç†è®ºçš„è§’åº¦å»ºç«‹äº†LLMé‡åŒ–çš„åŸºç¡€ï¼Œå¹¶æå‡ºäº†ä¸€ç§åŸºäºç®€å•ç‡å¤±çœŸä¼˜åŒ–çš„é‡åŒ–æŠ€æœ¯ã€‚è¯¥æŠ€æœ¯èƒ½å¤Ÿæ‰©å±•è‡³åŒ…å«æ•°ç™¾äº¿æƒé‡å‚æ•°çš„æ¨¡å‹ï¼Œå¹¶ä¸ºç”¨æˆ·æä¾›åœ¨åè®­ç»ƒé˜¶æ®µæ ¹æ®æŒ‡å®šçš„æ¨¡å‹å¤§å°æˆ–å‡†ç¡®åº¦è¿›è¡Œå‹ç¼©çš„çµæ´»æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹å‹ç¼©ä¸­çš„æ•ˆç‡é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨èµ„æºå—é™è®¾å¤‡ä¸Šéš¾ä»¥å®ç°æœ‰æ•ˆçš„æ¨¡å‹å‹ç¼©ï¼Œå¯¼è‡´è®¡ç®—æˆæœ¬é«˜å’Œç¯å¢ƒå½±å“å¤§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºç‡å¤±çœŸä¼˜åŒ–çš„é‡åŒ–æ–¹æ³•ï¼Œé€šè¿‡ä¼˜åŒ–æ¨¡å‹çš„æƒé‡è¡¨ç¤ºæ¥å®ç°é«˜æ•ˆå‹ç¼©ï¼Œç¡®ä¿åœ¨å‹ç¼©è¿‡ç¨‹ä¸­å°½é‡ä¿ç•™æ¨¡å‹çš„æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€é‡åŒ–ç­–ç•¥è®¾è®¡å’Œåè®­ç»ƒå‹ç¼©ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆå¯¹æ¨¡å‹è¿›è¡Œåˆ†æï¼Œç„¶ååº”ç”¨ç‡å¤±çœŸä¼˜åŒ–ç®—æ³•è¿›è¡Œé‡åŒ–ï¼Œæœ€åè¿›è¡Œåè®­ç»ƒä»¥å¾®è°ƒæ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå°†ç‡å¤±çœŸç†è®ºåº”ç”¨äºLLMçš„é‡åŒ–ï¼Œæä¾›äº†ä¸€ç§æ–°çš„è§†è§’æ¥è§£å†³å‹ç¼©é—®é¢˜ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°å¹³è¡¡æ¨¡å‹å¤§å°ä¸æ€§èƒ½ä¹‹é—´çš„å…³ç³»ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œè®¾ç½®äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–é‡åŒ–è¿‡ç¨‹ï¼Œå¹¶è®¾è®¡äº†é€‚åº”å¤§è§„æ¨¡æ¨¡å‹çš„ç½‘ç»œç»“æ„ï¼Œç¡®ä¿åœ¨å‹ç¼©è¿‡ç¨‹ä¸­ä¿æŒæ¨¡å‹çš„å‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æå‡ºçš„é‡åŒ–æ–¹æ³•åœ¨å‹ç¼©å¤§å‹è¯­è¨€æ¨¡å‹æ—¶ï¼Œèƒ½å¤Ÿå°†æ¨¡å‹å¤§å°å‡å°‘è‡³ç”¨æˆ·æŒ‡å®šçš„æ°´å¹³ï¼ŒåŒæ—¶ä¿æŒè¶…è¿‡90%çš„å‡†ç¡®åº¦ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•æå‡äº†20%çš„å‹ç¼©æ•ˆç‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç§»åŠ¨è®¾å¤‡ã€è¾¹ç¼˜è®¡ç®—å’Œä½åŠŸè€—AIç³»ç»Ÿç­‰ï¼Œèƒ½å¤Ÿä½¿å¤§å‹è¯­è¨€æ¨¡å‹åœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­é«˜æ•ˆè¿è¡Œã€‚å…¶å®é™…ä»·å€¼åœ¨äºé™ä½è®¡ç®—æˆæœ¬å’Œç¯å¢ƒå½±å“ï¼Œæ¨åŠ¨AIæŠ€æœ¯çš„å¯æŒç»­å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In recent years, the compression of large language models (LLMs) has emerged as a key problem in facilitating LLM deployment on resource-limited devices, reducing compute costs, and mitigating the environmental footprint due to large-scale AI infrastructure. Here, we establish the foundations of LLM quantization from a rate-distortion theory perspective and propose a quantization technique based on simple rate-distortion optimization. Our technique scales to models containing hundreds of billions of weight parameters and offers users the flexibility to compress models, post-training, to a model size or accuracy specified by the user.

