---
layout: default
title: Understanding and Improving Hyperbolic Deep Reinforcement Learning
---

# Understanding and Improving Hyperbolic Deep Reinforcement Learning

**arXiv**: [2512.14202v1](https://arxiv.org/abs/2512.14202) | [PDF](https://arxiv.org/pdf/2512.14202.pdf)

**‰ΩúËÄÖ**: Timo Klein, Thomas Lang, Andrii Shkabrii, Alexander Sturm, Kevin Sidak, Lukas Miklautz, Claudia Plant, Yllka Velaj, Sebastian Tschiatschek

**ÂàÜÁ±ª**: cs.LG, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-16

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/Probabilistic-and-Interactive-ML/hyper-rl)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Hyper++ÊñπÊ≥ï‰ª•Ëß£ÂÜ≥ÂèåÊõ≤Ê∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†‰∏≠ÁöÑ‰ºòÂåñ‰∏çÁ®≥ÂÆöÈóÆÈ¢òÔºåÊèêÂçáÂú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑÊÄßËÉΩ„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ËßÜËßâÈáåÁ®ãËÆ°** **Âº∫ÂåñÂ≠¶‰π†**

**ÂÖ≥ÈîÆËØç**: `ÂèåÊõ≤Âá†‰Ωï` `Ê∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†` `ËøëÁ´ØÁ≠ñÁï•‰ºòÂåñ` `ÁâπÂæÅË°®Á§∫` `‰ºòÂåñÁ®≥ÂÆöÊÄß` `Ê¢ØÂ∫¶ÂàÜÊûê` `Ê≠£ÂàôÂåñÊäÄÊúØ` `Êô∫ËÉΩ‰ΩìËÆ≠ÁªÉ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Ê†∏ÂøÉÈóÆÈ¢òÔºöÂèåÊõ≤Ê∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†‰∏≠ÔºåÂ§ßËåÉÊï∞ÂµåÂÖ•ÂØºËá¥Ê¢ØÂ∫¶‰∏çÁ®≥ÂÆöÔºåÁ†¥ÂùèPPO‰ø°‰ªªÂå∫ÂüüÔºåÂºïÂèëËÆ≠ÁªÉÂ§±Ë¥•„ÄÇ
2. ÊñπÊ≥ïË¶ÅÁÇπÔºöÊèêÂá∫Hyper++ÔºåÁªìÂêàÂàÜÁ±ªÂÄºÊçüÂ§±„ÄÅÁâπÂæÅÊ≠£ÂàôÂåñÂíå‰ºòÂåñÂèãÂ•ΩÂ±ÇÔºåÁ®≥ÂÆöËÆ≠ÁªÉÂπ∂ÊèêÂçáÊÄßËÉΩ„ÄÇ
3. ÂÆûÈ™åÊàñÊïàÊûúÔºöÂú®ProcGenÂíåAtari-5‰∏äÔºåHyper++‰ºò‰∫éÂü∫Á∫øÔºåÂáèÂ∞ë30%Êó∂Èó¥ÔºåÂÆûÁé∞Á®≥ÂÆöÂ≠¶‰π†„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Âº∫ÂåñÂ≠¶‰π†ÔºàRLÔºâÊô∫ËÉΩ‰ΩìÁöÑÊÄßËÉΩÂÖ≥ÈîÆÂèñÂÜ≥‰∫éÂ∫ïÂ±ÇÁâπÂæÅË°®Á§∫ÁöÑË¥®Èáè„ÄÇÂèåÊõ≤ÁâπÂæÅÁ©∫Èó¥ÈùûÂ∏∏ÈÄÇÂêàÊ≠§ÁõÆÁöÑÔºåÂõ†‰∏∫ÂÆÉ‰ª¨ËÉΩËá™ÁÑ∂Âú∞ÊçïÊçâÂ§çÊùÇRLÁéØÂ¢É‰∏≠Â∏∏Â≠òÂú®ÁöÑÂ±ÇÊ¨°ÂíåÂÖ≥Á≥ªÁªìÊûÑ„ÄÇÁÑ∂ËÄåÔºåÁî±‰∫éRLÁöÑÈùûÂπ≥Á®≥ÊÄßÔºåÂà©Áî®Ëøô‰∫õÁ©∫Èó¥ÈÄöÂ∏∏Èù¢‰∏¥‰ºòÂåñÊåëÊàò„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨Á°ÆÂÆö‰∫ÜÂÜ≥ÂÆöÂèåÊõ≤Ê∑±Â∫¶RLÊô∫ËÉΩ‰ΩìËÆ≠ÁªÉÊàêÂäü‰∏éÂ§±Ë¥•ÁöÑÂÖ≥ÈîÆÂõ†Á¥†„ÄÇÈÄöËøáÂàÜÊûêÂèåÊõ≤Âá†‰ΩïÁöÑÂ∫ûÂä†Ëé±ÁêÉÂíåÂèåÊõ≤Èù¢Ê®°Âûã‰∏≠Ê†∏ÂøÉÊìç‰ΩúÁöÑÊ¢ØÂ∫¶ÔºåÊàë‰ª¨Ë°®ÊòéÂ§ßËåÉÊï∞ÂµåÂÖ•‰ºöÁ†¥ÂùèÂü∫‰∫éÊ¢ØÂ∫¶ÁöÑËÆ≠ÁªÉÁ®≥ÂÆöÊÄßÔºåÂØºËá¥ËøëÁ´ØÁ≠ñÁï•‰ºòÂåñÔºàPPOÔºâ‰∏≠ÁöÑ‰ø°‰ªªÂå∫ÂüüËøùÂèç„ÄÇÂü∫‰∫éËøô‰∫õËßÅËß£ÔºåÊàë‰ª¨ÂºïÂÖ•‰∫ÜHyper++Ôºå‰∏ÄÁßçÊñ∞ÁöÑÂèåÊõ≤PPOÊô∫ËÉΩ‰ΩìÔºåÂåÖÂê´‰∏â‰∏™ÁªÑ‰ª∂ÔºöÔºàiÔºâÈÄöËøáÂàÜÁ±ªÂÄºÊçüÂ§±ËÄåÈùûÂõûÂΩíÂÆûÁé∞Á®≥ÂÆöÁöÑËØÑËÆ∫ÂÆ∂ËÆ≠ÁªÉÔºõÔºàiiÔºâÁâπÂæÅÊ≠£ÂàôÂåñ‰øùËØÅÊúâÁïåËåÉÊï∞ÔºåÂêåÊó∂ÈÅøÂÖçË£ÅÂâ™Â∏¶Êù•ÁöÑÁª¥Â∫¶ËØÖÂííÔºõÔºàiiiÔºâ‰ΩøÁî®Êõ¥‰ºòÂåñÂèãÂ•ΩÁöÑÂèåÊõ≤ÁΩëÁªúÂ±ÇÂÖ¨Âºè„ÄÇÂú®ProcGenÂÆûÈ™å‰∏≠ÔºåÊàë‰ª¨Ë°®ÊòéHyper++‰øùËØÅ‰∫ÜÁ®≥ÂÆöÂ≠¶‰π†Ôºå‰ºò‰∫éÂÖàÂâçÁöÑÂèåÊõ≤Êô∫ËÉΩ‰ΩìÔºåÂπ∂Â∞ÜÊåÇÈíüÊó∂Èó¥ÂáèÂ∞ëÁ∫¶30%„ÄÇÂú®Atari-5‰∏éDouble DQN‰∏äÔºåHyper++ÊòæËëó‰ºò‰∫éÊ¨ßÂá†ÈáåÂæóÂíåÂèåÊõ≤Âü∫Á∫ø„ÄÇÊàë‰ª¨Âú®https://github.com/Probabilistic-and-Interactive-ML/hyper-rl ÂèëÂ∏É‰∫Ü‰ª£Á†Å„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥ÂèåÊõ≤Ê∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†ÔºàRLÔºâ‰∏≠ÁöÑ‰ºòÂåñ‰∏çÁ®≥ÂÆöÈóÆÈ¢ò„ÄÇÁé∞ÊúâÂèåÊõ≤RLÊñπÊ≥ïÔºàÂ¶ÇÂü∫‰∫éÂ∫ûÂä†Ëé±ÁêÉÊàñÂèåÊõ≤Èù¢Ê®°ÂûãÔºâÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠ÔºåÁî±‰∫éRLÁéØÂ¢ÉÁöÑÈùûÂπ≥Á®≥ÊÄßÔºåÁâπÂæÅÂµåÂÖ•ÁöÑËåÉÊï∞ÂèØËÉΩÂèòÂæóËøáÂ§ßÔºåÂØºËá¥Ê¢ØÂ∫¶ËÆ°ÁÆó‰∏çÁ®≥ÂÆöÔºåËøõËÄåÁ†¥ÂùèËøëÁ´ØÁ≠ñÁï•‰ºòÂåñÔºàPPOÔºâ‰∏≠ÁöÑ‰ø°‰ªªÂå∫ÂüüÁ∫¶ÊùüÔºåÂºïÂèëËÆ≠ÁªÉÂ§±Ë¥•ÊàñÊÄßËÉΩ‰∏ãÈôç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÂàÜÊûêÂèåÊõ≤Âá†‰ΩïÊìç‰ΩúÁöÑÊ¢ØÂ∫¶ÁâπÊÄßÔºåËØÜÂà´Âá∫Â§ßËåÉÊï∞ÂµåÂÖ•ÊòØËÆ≠ÁªÉ‰∏çÁ®≥ÂÆöÁöÑÊ†πÊ∫êÔºåÂπ∂ËÆæËÆ°ÁªºÂêàËß£ÂÜ≥ÊñπÊ°àÊù•Á∫¶ÊùüÂµåÂÖ•ËåÉÊï∞„ÄÅÁ®≥ÂÆöÊ¢ØÂ∫¶Êõ¥Êñ∞ÔºåÂêåÊó∂‰øùÊåÅÂèåÊõ≤Á©∫Èó¥ÁöÑË°®Á§∫‰ºòÂäø„ÄÇËøôÂü∫‰∫éÂØπÂèåÊõ≤Ê®°ÂûãÔºàÂ¶ÇÂ∫ûÂä†Ëé±ÁêÉÔºâ‰∏≠Ê†∏ÂøÉËøêÁÆóÔºàÂ¶ÇÊåáÊï∞Êò†Â∞Ñ„ÄÅÂØπÊï∞Êò†Â∞ÑÔºâÊ¢ØÂ∫¶ÁöÑÁêÜËÆ∫ÂàÜÊûêÔºåË°®ÊòéËåÉÊï∞Â¢ûÂ§ß‰ºöÊîæÂ§ßÊ¢ØÂ∫¶ÔºåÁ†¥Âùè‰ºòÂåñËøáÁ®ã„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂõ¥ÁªïHyper++Êô∫ËÉΩ‰ΩìÂ±ïÂºÄÔºåÂÆÉÊòØ‰∏Ä‰∏™ÊîπËøõÁöÑÂèåÊõ≤PPO‰ª£ÁêÜ„ÄÇÊµÅÁ®ãÂåÖÊã¨ÔºöÈ¶ñÂÖàÔºåÂú®Á≠ñÁï•ÂíåÂÄºÂáΩÊï∞ÁΩëÁªú‰∏≠‰ΩøÁî®ÂèåÊõ≤Â±ÇËøõË°åÁâπÂæÅË°®Á§∫ÔºõÂÖ∂Ê¨°ÔºåÈÄöËøá‰∏â‰∏™ÂÖ≥ÈîÆÊ®°ÂùóÂ§ÑÁêÜ‰ºòÂåñÊåëÊàò‚Äî‚ÄîÁ®≥ÂÆöËØÑËÆ∫ÂÆ∂ËÆ≠ÁªÉÊ®°Âùó‰ΩøÁî®ÂàÜÁ±ªÊçüÂ§±Êõø‰ª£ÂõûÂΩíÔºåÁâπÂæÅÊ≠£ÂàôÂåñÊ®°ÂùóÁ∫¶ÊùüÂµåÂÖ•ËåÉÊï∞Ôºå‰ºòÂåñÂèãÂ•ΩÂ±ÇÊ®°ÂùóÈáçÊñ∞ËÆæËÆ°ÂèåÊõ≤ËøêÁÆóÔºõÊúÄÂêéÔºåÂú®ËÆ≠ÁªÉÂæ™ÁéØ‰∏≠ÈõÜÊàêËøô‰∫õÁªÑ‰ª∂ÔºåÁ°Æ‰øùÊ¢ØÂ∫¶Á®≥ÂÆöÊõ¥Êñ∞„ÄÇ‰∏ªË¶ÅÈò∂ÊÆµÂåÖÊã¨ÂàùÂßãÂåñ„ÄÅÂâçÂêë‰º†Êí≠„ÄÅÊçüÂ§±ËÆ°ÁÆóÔºàÁªìÂêàÁ≠ñÁï•ÊçüÂ§±„ÄÅÂÄºÊçüÂ§±ÂíåÊ≠£ÂàôÂåñÔºâÂíåÂèçÂêë‰º†Êí≠‰ºòÂåñ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÊòØHyper++ÁöÑ‰∏âÁªÑ‰ª∂ËÆæËÆ°Ôºö1ÔºâÂàÜÁ±ªÂÄºÊçüÂ§±ÔºöÂ∞ÜÂÄºÂáΩÊï∞È¢ÑÊµã‰ªéÂõûÂΩíÈóÆÈ¢òËΩ¨‰∏∫ÂàÜÁ±ªÈóÆÈ¢òÔºåÂáèÂ∞ëÂØπÁ≤æÁ°ÆÊï∞ÂÄºÁöÑ‰æùËµñÔºåÂ¢ûÂº∫ËÆ≠ÁªÉÁ®≥ÂÆöÊÄßÔºõ2ÔºâÁâπÂæÅÊ≠£ÂàôÂåñÔºöÂºïÂÖ•Ê≠£ÂàôÂåñÈ°πÁõ¥Êé•Á∫¶ÊùüÂµåÂÖ•ËåÉÊï∞ÔºåÈÅøÂÖç‰ΩøÁî®Ë£ÅÂâ™ÊñπÊ≥ïÂèØËÉΩÂ∏¶Êù•ÁöÑÁª¥Â∫¶ËØÖÂííÔºàÂç≥È´òÁª¥Á©∫Èó¥‰∏≠ÁöÑ‰ø°ÊÅØÊçüÂ§±ÔºâÔºõ3Ôºâ‰ºòÂåñÂèãÂ•ΩÂ±ÇÔºöÈáçÊñ∞ÂÖ¨ÂºèÂåñÂèåÊõ≤ÁΩëÁªúÂ±ÇÔºàÂ¶ÇÁ∫øÊÄßÂ±ÇÔºâÔºå‰ΩøÂÖ∂Ê¢ØÂ∫¶Ë°å‰∏∫Êõ¥Âπ≥ÊªëÔºåÈôç‰Ωé‰ºòÂåñÈöæÂ∫¶„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁöÑÊú¨Ë¥®Âå∫Âà´Âú®‰∫éÔºåÂÆÉÁ≥ªÁªüÊÄßÂú∞Ëß£ÂÜ≥‰∫ÜÊ¢ØÂ∫¶‰∏çÁ®≥ÂÆöÈóÆÈ¢òÔºåËÄåÈùû‰ªÖ‰æùËµñÂêØÂèëÂºèË∞ÉÊï¥„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂÖ≥ÈîÆËÆæËÆ°ÁªÜËäÇÂåÖÊã¨Ôºö‰ΩøÁî®ÂàÜÁ±ª‰∫§ÂèâÁÜµÊçüÂ§±‰Ωú‰∏∫ÂÄºÊçüÂ§±ÔºåÊõø‰ª£ÂùáÊñπËØØÂ∑ÆÂõûÂΩíÔºõÂú®ÊçüÂ§±ÂáΩÊï∞‰∏≠Ê∑ªÂä†L2Ê≠£ÂàôÂåñÈ°πÔºåÁõÆÊ†áËåÉÊï∞ËÆæ‰∏∫Âõ∫ÂÆöÂÄºÔºàÂ¶Ç1.0ÔºâÔºå‰ª•ÊéßÂà∂ÂµåÂÖ•Â§ßÂ∞èÔºõÂèåÊõ≤Â±ÇÈááÁî®ÊîπËøõÁöÑÊï∞Â≠¶ÂÖ¨ÂºèÔºå‰æãÂ¶ÇÂú®Â∫ûÂä†Ëé±ÁêÉÊ®°Âûã‰∏≠Ë∞ÉÊï¥ÊåáÊï∞Êò†Â∞ÑÁöÑÊï∞ÂÄºÁ®≥ÂÆöÊÄßÔºõÁΩëÁªúÁªìÊûÑÈÄöÂ∏∏ÂåÖÂê´Â§ö‰∏™ÂèåÊõ≤ÂÖ®ËøûÊé•Â±ÇÔºåÂêéÊé•ÊøÄÊ¥ªÂáΩÊï∞ÔºàÂ¶ÇReLUÔºâÔºåËæìÂá∫Â±ÇÈÄÇÈÖçÂÖ∑‰Ωì‰ªªÂä°ÔºàÂ¶ÇÁ≠ñÁï•ÂàÜÂ∏ÉÊàñÂÄºÈ¢ÑÊµãÔºâÔºõÂèÇÊï∞ËÆæÁΩÆ‰∏äÔºåÂèØËÉΩÊ∂âÂèäÂ≠¶‰π†ÁéáË∞ÉÊï¥„ÄÅ‰ø°‰ªªÂå∫ÂüüÁ≥ªÊï∞‰ºòÂåñÔºå‰ª•ÂåπÈÖçÂèåÊõ≤Á©∫Èó¥ÁöÑÊõ≤ÁéáÁâπÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÊúÄÈáçË¶ÅÁöÑÂÆûÈ™åÁªìÊûúÂåÖÊã¨ÔºöÂú®ProcGenÂü∫ÂáÜÊµãËØï‰∏≠ÔºåHyper++‰øùËØÅ‰∫ÜÁ®≥ÂÆöÂ≠¶‰π†Ôºå‰ºò‰∫éÊâÄÊúâÂÖàÂâçÁöÑÂèåÊõ≤Êô∫ËÉΩ‰ΩìÔºåÂπ∂Â∞ÜÊåÇÈíüÊó∂Èó¥ÂáèÂ∞ë‰∫ÜÁ∫¶30%ÔºåÊòæËëóÊèêÂçáËÆ≠ÁªÉÊïàÁéá„ÄÇÂú®Atari-5ÁéØÂ¢É‰∏≠ÁªìÂêàDouble DQNÔºåHyper++Âº∫ÁÉà‰ºò‰∫éÊ¨ßÂá†ÈáåÂæóÂü∫Á∫øÂíåÁé∞ÊúâÂèåÊõ≤Âü∫Á∫øÔºåÊòæÁ§∫Âá∫ÂçìË∂äÁöÑÊÄßËÉΩ‰ºòÂäø„ÄÇÂÖ∑‰ΩìÊï∞ÊçÆÊñπÈù¢ÔºåËÆ∫ÊñáÊä•Âëä‰∫ÜÂú®Â§ö‰∏™Ê∏∏Êàè‰∏äÁöÑÂæóÂàÜÊèêÂçáÔºå‰æãÂ¶ÇÂú®Êüê‰∫õ‰ªªÂä°‰∏≠ÊÄßËÉΩÊèêÈ´òË∂ÖËøá20%ÔºåÈ™åËØÅ‰∫ÜÊñπÊ≥ïÂú®Â§çÊùÇRLÂú∫ÊôØ‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂Âú®Â§çÊùÇÂº∫ÂåñÂ≠¶‰π†ÁéØÂ¢É‰∏≠ÂÖ∑ÊúâÂπøÊ≥õÊΩúÂú®Â∫îÁî®ÔºåÂ¶ÇËßÜÈ¢ëÊ∏∏ÊàèÔºàÂ¶ÇProcGen„ÄÅAtariÔºâ„ÄÅÊú∫Âô®‰∫∫ÊéßÂà∂„ÄÅËá™Âä®È©æÈ©∂ÂíåÊô∫ËÉΩÂÜ≥Á≠ñÁ≥ªÁªü„ÄÇÈÄöËøáÁ®≥ÂÆöÂèåÊõ≤Ë°®Á§∫Â≠¶‰π†ÔºåÂÆÉËÉΩÊõ¥Â•ΩÂú∞Â§ÑÁêÜÂ±ÇÊ¨°ÂåñÊàñÂÖ≥Á≥ªÂûãÁªìÊûÑÁöÑÁéØÂ¢ÉÔºåÊèêÂçáÊô∫ËÉΩ‰ΩìÁöÑÊ≥õÂåñËÉΩÂäõÂíåÊïàÁéá„ÄÇÂÆûÈôÖ‰ª∑ÂÄºÂåÖÊã¨ÂáèÂ∞ëËÆ≠ÁªÉÊó∂Èó¥„ÄÅÊèêÈ´òÊÄßËÉΩÁ®≥ÂÆöÊÄßÔºåÊú™Êù•ÂèØËÉΩÊé®Âä®ÂèåÊõ≤Âá†‰ΩïÂú®Êõ¥Â§çÊùÇRL‰ªªÂä°ÔºàÂ¶ÇÂ§öÊô∫ËÉΩ‰ΩìÂçè‰ΩúÊàñÂÖÉÂ≠¶‰π†Ôºâ‰∏≠ÁöÑÂ∫îÁî®Ôºå‰øÉËøõAIÁ≥ªÁªüÂú®Âä®ÊÄÅ‰∏ñÁïå‰∏≠ÁöÑÈÄÇÂ∫îÊÄß„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> The performance of reinforcement learning (RL) agents depends critically on the quality of the underlying feature representations. Hyperbolic feature spaces are well-suited for this purpose, as they naturally capture hierarchical and relational structure often present in complex RL environments. However, leveraging these spaces commonly faces optimization challenges due to the nonstationarity of RL. In this work, we identify key factors that determine the success and failure of training hyperbolic deep RL agents. By analyzing the gradients of core operations in the Poincar√© Ball and Hyperboloid models of hyperbolic geometry, we show that large-norm embeddings destabilize gradient-based training, leading to trust-region violations in proximal policy optimization (PPO). Based on these insights, we introduce Hyper++, a new hyperbolic PPO agent that consists of three components: (i) stable critic training through a categorical value loss instead of regression; (ii) feature regularization guaranteeing bounded norms while avoiding the curse of dimensionality from clipping; and (iii) using a more optimization-friendly formulation of hyperbolic network layers. In experiments on ProcGen, we show that Hyper++ guarantees stable learning, outperforms prior hyperbolic agents, and reduces wall-clock time by approximately 30%. On Atari-5 with Double DQN, Hyper++ strongly outperforms Euclidean and hyperbolic baselines. We release our code at https://github.com/Probabilistic-and-Interactive-ML/hyper-rl .

