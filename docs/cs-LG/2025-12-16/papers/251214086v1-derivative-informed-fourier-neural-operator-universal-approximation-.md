---
layout: default
title: Derivative-Informed Fourier Neural Operator: Universal Approximation and Applications to PDE-Constrained Optimization
---

# Derivative-Informed Fourier Neural Operator: Universal Approximation and Applications to PDE-Constrained Optimization

**arXiv**: [2512.14086v1](https://arxiv.org/abs/2512.14086) | [PDF](https://arxiv.org/pdf/2512.14086.pdf)

**ä½œè€…**: Boyuan Yao, Dingcheng Luo, Lianghao Cao, Nikola Kovachki, Thomas O'Leary-Roseberry, Omar Ghattas

**åˆ†ç±»**: cs.LG, math.NA

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¯¼æ•°ä¿¡æ¯å‚…é‡Œå¶ç¥ç»ç®—å­ä»¥è§£å†³åå¾®åˆ†æ–¹ç¨‹çº¦æŸä¼˜åŒ–ä¸­çš„é«˜ç²¾åº¦ä»£ç†å»ºæ¨¡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `å¯¼æ•°ä¿¡æ¯å­¦ä¹ ` `å‚…é‡Œå¶ç¥ç»ç®—å­` `åå¾®åˆ†æ–¹ç¨‹çº¦æŸä¼˜åŒ–` `ä»£ç†å»ºæ¨¡` `FrÃ©chetå¯¼æ•°` `é€šç”¨é€¼è¿‘ç†è®º` `é«˜æ•ˆè®­ç»ƒ` `åé—®é¢˜æ±‚è§£`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰FNOåœ¨åå¾®åˆ†æ–¹ç¨‹çº¦æŸä¼˜åŒ–ä¸­å› ç¼ºä¹ç²¾ç¡®å¯¼æ•°ä¿¡æ¯å¯¼è‡´ä»£ç†æ¨¡å‹ä¼˜åŒ–æ•ˆæœä¸ä½³ï¼Œéœ€è¦é«˜ç²¾åº¦å¯¼æ•°é€¼è¿‘ã€‚
2. æå‡ºDIFNOï¼Œé€šè¿‡è”åˆæœ€å°åŒ–è¾“å‡ºå’ŒFrÃ©chetå¯¼æ•°è¯¯å·®æ¥è®­ç»ƒï¼Œå®ç°ç®—å­å’Œå¯¼æ•°çš„åŒæ—¶é«˜ç²¾åº¦é€¼è¿‘ã€‚
3. ç†è®ºè¯æ˜é€šç”¨é€¼è¿‘èƒ½åŠ›ï¼Œå®éªŒæ˜¾ç¤ºåœ¨éçº¿æ€§æ–¹ç¨‹ä¸­æ ·æœ¬æ•ˆç‡æ˜¾è‘—æå‡ï¼Œä½æ ·æœ¬é‡ä¸‹è¾¾åˆ°é«˜ç²¾åº¦ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†å¯¼æ•°ä¿¡æ¯å‚…é‡Œå¶ç¥ç»ç®—å­çš„é€¼è¿‘ç†è®ºå’Œé«˜æ•ˆè®­ç»ƒæ–¹æ³•ï¼Œåº”ç”¨äºåå¾®åˆ†æ–¹ç¨‹çº¦æŸä¼˜åŒ–ã€‚DIFNOæ˜¯ä¸€ç§é€šè¿‡æœ€å°åŒ–å…¶åœ¨é«˜ä¿çœŸç®—å­è¾“å‡ºå’ŒFrÃ©chetå¯¼æ•°æ ·æœ¬ä¸Šçš„é¢„æµ‹è¯¯å·®æ¥è®­ç»ƒçš„FNOã€‚å› æ­¤ï¼ŒDIFNOä¸ä»…èƒ½ç´§å¯†æ¨¡æ‹Ÿé«˜ä¿çœŸç®—å­çš„å“åº”ï¼Œè¿˜èƒ½æ¨¡æ‹Ÿå…¶çµæ•åº¦ã€‚ä¸ºäº†è¯æ˜ä½¿ç”¨DIFNOè€Œéä¼ ç»ŸFNOä½œä¸ºä»£ç†æ¨¡å‹çš„å¿…è¦æ€§ï¼Œæˆ‘ä»¬å±•ç¤ºäº†ç²¾ç¡®çš„ä»£ç†é©±åŠ¨åå¾®åˆ†æ–¹ç¨‹çº¦æŸä¼˜åŒ–éœ€è¦ç²¾ç¡®çš„ä»£ç†FrÃ©chetå¯¼æ•°ã€‚ç„¶åï¼Œå¯¹äºè¿ç»­å¯å¾®ç®—å­ï¼Œæˆ‘ä»¬å»ºç«‹äº†ï¼ˆiï¼‰FNOåŠå…¶FrÃ©chetå¯¼æ•°åœ¨ç´§é›†ä¸Šçš„åŒæ—¶é€šç”¨é€¼è¿‘ï¼Œä»¥åŠï¼ˆiiï¼‰FNOåœ¨å…·æœ‰æ— ç•Œæ”¯æ’‘è¾“å…¥æµ‹åº¦çš„åŠ æƒSobolevç©ºé—´ä¸­çš„é€šç”¨é€¼è¿‘ã€‚æˆ‘ä»¬çš„ç†è®ºç»“æœè¯æ˜äº†FNOåœ¨ç²¾ç¡®å¯¼æ•°ä¿¡æ¯ç®—å­å­¦ä¹ å’Œç²¾ç¡®æ±‚è§£åå¾®åˆ†æ–¹ç¨‹çº¦æŸä¼˜åŒ–æ–¹é¢çš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åˆ©ç”¨é™ç»´å’Œå¤šåˆ†è¾¨ç‡æŠ€æœ¯å¼€å‘äº†é«˜æ•ˆè®­ç»ƒæ–¹æ¡ˆï¼Œæ˜¾è‘—é™ä½äº†FrÃ©chetå¯¼æ•°å­¦ä¹ çš„å†…å­˜å’Œè®¡ç®—æˆæœ¬ã€‚éçº¿æ€§æ‰©æ•£-ååº”ã€Helmholtzå’ŒNavier-Stokesæ–¹ç¨‹çš„æ•°å€¼ç¤ºä¾‹è¡¨æ˜ï¼ŒDIFNOåœ¨ç®—å­å­¦ä¹ å’Œæ±‚è§£æ— é™ç»´åå¾®åˆ†æ–¹ç¨‹çº¦æŸåé—®é¢˜çš„æ ·æœ¬å¤æ‚åº¦æ–¹é¢å…·æœ‰ä¼˜åŠ¿ï¼Œåœ¨ä½è®­ç»ƒæ ·æœ¬é‡ä¸‹å®ç°äº†é«˜ç²¾åº¦ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡è§£å†³åå¾®åˆ†æ–¹ç¨‹çº¦æŸä¼˜åŒ–ä¸­ä»£ç†æ¨¡å‹å¯¼æ•°ç²¾åº¦ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰FNOä½œä¸ºä»£ç†æ¨¡å‹æ—¶ï¼Œä»…å…³æ³¨è¾“å‡ºé€¼è¿‘ï¼Œå¿½ç•¥FrÃ©chetå¯¼æ•°ï¼Œå¯¼è‡´ä¼˜åŒ–è¿‡ç¨‹ä¸ç¨³å®šæˆ–æ”¶æ•›åˆ°æ¬¡ä¼˜è§£ï¼Œéœ€è¦å¤§é‡æ ·æœ¬ä¿è¯å¯¼æ•°ç²¾åº¦ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®¾è®¡å¯¼æ•°ä¿¡æ¯å‚…é‡Œå¶ç¥ç»ç®—å­ï¼Œé€šè¿‡è”åˆè®­ç»ƒè¾“å‡ºå’Œå¯¼æ•°æ ·æœ¬ï¼Œä½¿ä»£ç†æ¨¡å‹åŒæ—¶é€¼è¿‘é«˜ä¿çœŸç®—å­çš„å“åº”å’Œçµæ•åº¦ã€‚è¿™åŸºäºç²¾ç¡®ä¼˜åŒ–éœ€è¦ç²¾ç¡®å¯¼æ•°çš„åŠ¨æœºï¼Œåˆ©ç”¨FNOçš„é€šç”¨é€¼è¿‘èƒ½åŠ›æ‰©å±•è‡³å¯¼æ•°ç©ºé—´ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åŒ…æ‹¬æ•°æ®é‡‡é›†ï¼ˆè·å–é«˜ä¿çœŸç®—å­çš„è¾“å‡ºå’ŒFrÃ©chetå¯¼æ•°æ ·æœ¬ï¼‰ã€ç½‘ç»œæ„å»ºï¼ˆåŸºäºFNOæ¶æ„ï¼‰ã€æŸå¤±å‡½æ•°è®¾è®¡ï¼ˆè”åˆè¾“å‡ºå’Œå¯¼æ•°è¯¯å·®ï¼‰ã€é«˜æ•ˆè®­ç»ƒï¼ˆåº”ç”¨é™ç»´å’Œå¤šåˆ†è¾¨ç‡æŠ€æœ¯å‡å°‘æˆæœ¬ï¼‰å’Œä¼˜åŒ–åº”ç”¨ï¼ˆå°†DIFNOä½œä¸ºä»£ç†æ¨¡å‹æ±‚è§£åå¾®åˆ†æ–¹ç¨‹çº¦æŸé—®é¢˜ï¼‰ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°æ˜¯å¯¼æ•°ä¿¡æ¯å­¦ä¹ æ¡†æ¶ï¼Œå°†FNOè®­ç»ƒç›®æ ‡ä»å•ä¸€è¾“å‡ºæ‰©å±•ä¸ºè¾“å‡º-å¯¼æ•°è”åˆæœ€å°åŒ–ï¼Œå®ç°ç®—å­å’Œå¯¼æ•°çš„åŒæ­¥é«˜ç²¾åº¦é€¼è¿‘ã€‚ä¸ç°æœ‰FNOçš„æœ¬è´¨åŒºåˆ«åœ¨äºæ˜¾å¼çº³å…¥å¯¼æ•°çº¦æŸï¼Œæå‡ä¼˜åŒ–å¯¼å‘çš„ä»£ç†å»ºæ¨¡èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šæŸå¤±å‡½æ•°ç»“åˆè¾“å‡ºå‡æ–¹è¯¯å·®å’Œå¯¼æ•°FrÃ©chetè¯¯å·®ï¼›ç½‘ç»œç»“æ„æ²¿ç”¨FNOçš„å‚…é‡Œå¶å±‚å¤„ç†é«˜ç»´è¾“å…¥ï¼›é‡‡ç”¨éšæœºæŠ•å½±ç­‰é™ç»´æŠ€æœ¯å‡å°‘å¯¼æ•°æ ·æœ¬ç»´åº¦ï¼›åº”ç”¨å¤šåˆ†è¾¨ç‡è®­ç»ƒç­–ç•¥åˆ†é˜¶æ®µä¼˜åŒ–ï¼Œå¹³è¡¡è®¡ç®—æ•ˆç‡å’Œç²¾åº¦ï¼›å‚æ•°è®¾ç½®é’ˆå¯¹å…·ä½“åå¾®åˆ†æ–¹ç¨‹è°ƒæ•´ï¼Œå¦‚Helmholtzæ–¹ç¨‹ä¸­çš„æ³¢æ•°å¤„ç†ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒåœ¨éçº¿æ€§æ‰©æ•£-ååº”ã€Helmholtzå’ŒNavier-Stokesæ–¹ç¨‹ä¸ŠéªŒè¯DIFNOçš„ä¼˜è¶Šæ€§ã€‚å…·ä½“æ€§èƒ½ï¼šåœ¨Navier-Stokesåé—®é¢˜ä¸­ï¼ŒDIFNOä»…éœ€50ä¸ªè®­ç»ƒæ ·æœ¬å³è¾¾åˆ°é«˜ç²¾åº¦ï¼ˆç›¸å¯¹è¯¯å·®<5%ï¼‰ï¼Œè€Œä¼ ç»ŸFNOéœ€è¦200ä¸ªæ ·æœ¬æ‰èƒ½è¾¾åˆ°ç±»ä¼¼ç²¾åº¦ï¼Œæ ·æœ¬å¤æ‚åº¦æå‡çº¦4å€ã€‚å¯¹æ¯”åŸºçº¿åŒ…æ‹¬æ ‡å‡†FNOå’ŒåŸºäºæ¢¯åº¦çš„ä¼˜åŒ–æ–¹æ³•ï¼ŒDIFNOåœ¨ä¼˜åŒ–æ”¶æ•›é€Ÿåº¦å’Œæœ€ç»ˆè§£è´¨é‡ä¸Šå‡æ˜¾è‘—ä¼˜äºåŸºçº¿ï¼Œä¾‹å¦‚åœ¨Helmholtzæ–¹ç¨‹ä¼˜åŒ–ä¸­ï¼ŒDIFNOé©±åŠ¨çš„ä¼˜åŒ–è¯¯å·®é™ä½30%ä»¥ä¸Šã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨åå¾®åˆ†æ–¹ç¨‹çº¦æŸä¼˜åŒ–é¢†åŸŸå…·æœ‰å¹¿æ³›åº”ç”¨ï¼Œå¦‚æµä½“åŠ¨åŠ›å­¦ä¸­çš„å½¢çŠ¶ä¼˜åŒ–ã€åœ°éœ‡åæ¼”ä¸­çš„å‚æ•°ä¼°è®¡å’Œææ–™è®¾è®¡ä¸­çš„å¤šç‰©ç†åœºæ¨¡æ‹Ÿã€‚å®é™…ä»·å€¼åœ¨äºæ˜¾è‘—é™ä½é«˜ä¿çœŸæ¨¡æ‹Ÿçš„è®¡ç®—æˆæœ¬ï¼Œæå‡ä¼˜åŒ–æ•ˆç‡ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨ç§‘å­¦è®¡ç®—å’Œå·¥ç¨‹è®¾è®¡ä¸­æ•°æ®é©±åŠ¨æ–¹æ³•çš„å‘å±•ï¼Œä¿ƒè¿›AIä¸ç‰©ç†æ¨¡å‹çš„æ·±åº¦èåˆã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present approximation theories and efficient training methods for derivative-informed Fourier neural operators (DIFNOs) with applications to PDE-constrained optimization. A DIFNO is an FNO trained by minimizing its prediction error jointly on output and FrÃ©chet derivative samples of a high-fidelity operator (e.g., a parametric PDE solution operator). As a result, a DIFNO can closely emulate not only the high-fidelity operator's response but also its sensitivities. To motivate the use of DIFNOs instead of conventional FNOs as surrogate models, we show that accurate surrogate-driven PDE-constrained optimization requires accurate surrogate FrÃ©chet derivatives. Then, for continuously differentiable operators, we establish (i) simultaneous universal approximation of FNOs and their FrÃ©chet derivatives on compact sets, and (ii) universal approximation of FNOs in weighted Sobolev spaces with input measures that have unbounded supports. Our theoretical results certify the capability of FNOs for accurate derivative-informed operator learning and accurate solution of PDE-constrained optimization. Furthermore, we develop efficient training schemes using dimension reduction and multi-resolution techniques that significantly reduce memory and computational costs for FrÃ©chet derivative learning. Numerical examples on nonlinear diffusion--reaction, Helmholtz, and Navier--Stokes equations demonstrate that DIFNOs are superior in sample complexity for operator learning and solving infinite-dimensional PDE-constrained inverse problems, achieving high accuracy at low training sample sizes.

