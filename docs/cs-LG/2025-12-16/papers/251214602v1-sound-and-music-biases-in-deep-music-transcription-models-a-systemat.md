---
layout: default
title: Sound and Music Biases in Deep Music Transcription Models: A Systematic Analysis
---

# Sound and Music Biases in Deep Music Transcription Models: A Systematic Analysis

**arXiv**: [2512.14602v1](https://arxiv.org/abs/2512.14602) | [PDF](https://arxiv.org/pdf/2512.14602.pdf)

**ä½œè€…**: LukÃ¡Å¡ Samuel MartÃ¡k, Patricia Hu, Gerhard Widmer

**åˆ†ç±»**: cs.SD, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: pre-print of the upcoming EURASIP JASM journal article

**DOI**: [10.1186/s13636-025-00428-z](https://doi.org/10.1186/s13636-025-00428-z)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç³»ç»Ÿåˆ†æžæ·±åº¦éŸ³ä¹è½¬å½•æ¨¡åž‹ä¸­çš„å£°éŸ³ä¸ŽéŸ³ä¹åè§ï¼Œæ­ç¤ºå…¶åœ¨åˆ†å¸ƒåç§»ä¸‹çš„æ€§èƒ½é€€åŒ–é—®é¢˜**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `è‡ªåŠ¨éŸ³ä¹è½¬å½•` `åˆ†å¸ƒåç§»` `è¯­æ–™åº“åè§` `éŸ³ä¹ä¿¡æ¯æ£€ç´¢` `æ·±åº¦å­¦ä¹ è¯„ä¼°` `æ³›åŒ–èƒ½åŠ›` `éŸ³ä¹æ„ŸçŸ¥æŒ‡æ ‡` `æ¨¡åž‹é²æ£’æ€§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ·±åº¦éŸ³ä¹è½¬å½•æ¨¡åž‹ä¸»è¦åŸºäºŽå¤å…¸é’¢ç´æ•°æ®è®­ç»ƒï¼Œæ³›åŒ–èƒ½åŠ›æœªçŸ¥ï¼Œé¢ä¸´éŸ³ä¹ç»´åº¦ï¼ˆå¦‚æµæ´¾ã€åŠ¨æ€ï¼‰åˆ†å¸ƒåç§»çš„æŒ‘æˆ˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºMDSè¯­æ–™åº“æ¨¡æ‹Ÿä¸åŒåˆ†å¸ƒåç§»ï¼Œç³»ç»Ÿè¯„ä¼°å¤šä¸ªå…ˆè¿›æ¨¡åž‹ï¼Œä½¿ç”¨ä¼ ç»Ÿå’ŒéŸ³ä¹æ„ŸçŸ¥æŒ‡æ ‡åˆ†æžæ€§èƒ½é€€åŒ–ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šå‘çŽ°å£°éŸ³å’Œæµæ´¾åˆ†åˆ«å¯¼è‡´F1ä¸‹é™20å’Œ14ä¸ªç™¾åˆ†ç‚¹ï¼ŒåŠ¨æ€ä¼°è®¡æ›´è„†å¼±ï¼ŒéžéŸ³ä¹åºåˆ—æ­ç¤ºç³»ç»Ÿæžé™ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è‡ªåŠ¨éŸ³ä¹è½¬å½•ï¼ˆAMTï¼‰â€”â€”å°†éŸ³ä¹éŸ³é¢‘è½¬æ¢ä¸ºéŸ³ç¬¦è¡¨ç¤ºçš„ä»»åŠ¡â€”â€”åœ¨æ·±åº¦å­¦ä¹ ç³»ç»Ÿçš„æŽ¨åŠ¨ä¸‹å–å¾—äº†å¿«é€Ÿè¿›å±•ã€‚ç”±äºŽä¸°å¯Œæ ‡æ³¨éŸ³ä¹æ•°æ®é›†çš„å¯ç”¨æ€§æœ‰é™ï¼ŒAMTçš„å¤§éƒ¨åˆ†è¿›å±•é›†ä¸­åœ¨å¤å…¸é’¢ç´éŸ³ä¹ï¼Œç”šè‡³å°‘æ•°ç‰¹å®šæ•°æ®é›†ä¸Šã€‚è¿™äº›ç³»ç»Ÿæ˜¯å¦èƒ½æœ‰æ•ˆæ³›åŒ–åˆ°å…¶ä»–éŸ³ä¹æƒ…å¢ƒä»æ˜¯ä¸€ä¸ªå¼€æ”¾é—®é¢˜ã€‚æœ¬ç ”ç©¶è¡¥å……äº†æœ€è¿‘å…³äºŽå£°éŸ³åˆ†å¸ƒåç§»ï¼ˆå¦‚å½•éŸ³æ¡ä»¶ï¼‰çš„ç ”ç©¶ï¼Œè°ƒæŸ¥äº†éŸ³ä¹ç»´åº¦â€”â€”ç‰¹åˆ«æ˜¯æµæ´¾ã€åŠ¨æ€å’Œå¤éŸ³æ°´å¹³çš„å˜åŒ–ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†MDSè¯­æ–™åº“ï¼ŒåŒ…å«ä¸‰ä¸ªä¸åŒçš„å­é›†â€”â€”ï¼ˆ1ï¼‰æµæ´¾ï¼Œï¼ˆ2ï¼‰éšæœºï¼Œå’Œï¼ˆ3ï¼‰MAEtestâ€”â€”ä»¥æ¨¡æ‹Ÿåˆ†å¸ƒåç§»çš„ä¸åŒè½´ã€‚æˆ‘ä»¬ä½¿ç”¨ä¼ ç»Ÿä¿¡æ¯æ£€ç´¢å’ŒéŸ³ä¹æ„ŸçŸ¥æ€§èƒ½æŒ‡æ ‡è¯„ä¼°äº†å‡ ä¸ªæœ€å…ˆè¿›çš„AMTç³»ç»Ÿåœ¨MDSè¯­æ–™åº“ä¸Šçš„è¡¨çŽ°ã€‚æˆ‘ä»¬çš„å¹¿æ³›è¯„ä¼°éš”ç¦»å¹¶æš´éœ²äº†åœ¨ç‰¹å®šåˆ†å¸ƒåç§»ä¸‹ä¸åŒç¨‹åº¦çš„æ€§èƒ½é€€åŒ–ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬æµ‹é‡åˆ°ç”±äºŽå£°éŸ³å¯¼è‡´çš„éŸ³ç¬¦çº§F1æ€§èƒ½ä¸‹é™20ä¸ªç™¾åˆ†ç‚¹ï¼Œç”±äºŽæµæ´¾å¯¼è‡´çš„ä¸‹é™14ä¸ªç™¾åˆ†ç‚¹ã€‚æ€»ä½“è€Œè¨€ï¼Œæˆ‘ä»¬å‘çŽ°åŠ¨æ€ä¼°è®¡æ¯”èµ·å§‹é¢„æµ‹æ›´å®¹æ˜“å—åˆ°éŸ³ä¹å˜åŒ–çš„å½±å“ã€‚éŸ³ä¹æ„ŸçŸ¥è¯„ä¼°æŒ‡æ ‡ï¼Œç‰¹åˆ«æ˜¯é‚£äº›æ•æ‰å’Œå£°ç»“æž„çš„æŒ‡æ ‡ï¼Œæœ‰åŠ©äºŽè¯†åˆ«æ½œåœ¨çš„è´¡çŒ®å› ç´ ã€‚æ­¤å¤–ï¼Œä½¿ç”¨éšæœºç”Ÿæˆçš„éžéŸ³ä¹åºåˆ—è¿›è¡Œçš„å®žéªŒæ­ç¤ºäº†åœ¨æžç«¯éŸ³ä¹åˆ†å¸ƒåç§»ä¸‹ç³»ç»Ÿæ€§èƒ½çš„æ˜Žæ˜¾é™åˆ¶ã€‚æ€»ä¹‹ï¼Œè¿™äº›å‘çŽ°ä¸ºæ·±åº¦AMTç³»ç»Ÿä¸­è¯­æ–™åº“åè§é—®é¢˜çš„æŒç»­å½±å“æä¾›äº†æ–°è¯æ®ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æ·±åº¦è‡ªåŠ¨éŸ³ä¹è½¬å½•ï¼ˆAMTï¼‰æ¨¡åž‹åœ¨éŸ³ä¹ç»´åº¦åˆ†å¸ƒåç§»ä¸‹çš„æ³›åŒ–èƒ½åŠ›é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–å¤å…¸é’¢ç´ç­‰æœ‰é™æ•°æ®é›†è®­ç»ƒï¼Œå¯¼è‡´æ¨¡åž‹å¯èƒ½æ— æ³•æœ‰æ•ˆå¤„ç†å…¶ä»–éŸ³ä¹æƒ…å¢ƒï¼ˆå¦‚ä¸åŒæµæ´¾ã€åŠ¨æ€å˜åŒ–ï¼‰ï¼Œå­˜åœ¨è¯­æ–™åº“åè§ï¼Œå½±å“å®žé™…åº”ç”¨ä¸­çš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æž„å»ºä¸€ä¸ªä¸“é—¨è®¾è®¡çš„MDSè¯­æ–™åº“ï¼Œæ¨¡æ‹ŸéŸ³ä¹ç»´åº¦çš„åˆ†å¸ƒåç§»ï¼ˆå¦‚æµæ´¾ã€åŠ¨æ€ã€å¤éŸ³æ°´å¹³ï¼‰ï¼Œç³»ç»Ÿè¯„ä¼°å¤šä¸ªå…ˆè¿›AMTæ¨¡åž‹åœ¨è¿™äº›åç§»ä¸‹çš„æ€§èƒ½ï¼Œä»¥é‡åŒ–åè§å½±å“å¹¶è¯†åˆ«è„†å¼±çŽ¯èŠ‚ã€‚è¿™ç§è®¾è®¡å…è®¸éš”ç¦»ä¸åŒå› ç´ å¯¹æ€§èƒ½çš„å½±å“ï¼Œä»Žè€Œæ·±å…¥ç†è§£æ¨¡åž‹æ³›åŒ–é™åˆ¶ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æµç¨‹åŒ…æ‹¬æ•°æ®æ”¶é›†ä¸Žè¯­æ–™åº“æž„å»ºã€æ¨¡åž‹é€‰æ‹©ä¸Žè¯„ä¼°ã€æŒ‡æ ‡è®¡ç®—ä¸Žåˆ†æžä¸‰ä¸ªé˜¶æ®µã€‚é¦–å…ˆï¼Œåˆ›å»ºMDSè¯­æ–™åº“ï¼ŒåŒ…å«ä¸‰ä¸ªå­é›†ï¼šGenreï¼ˆæ¨¡æ‹Ÿæµæ´¾å˜åŒ–ï¼‰ã€Randomï¼ˆæ¨¡æ‹ŸéšæœºéžéŸ³ä¹åºåˆ—ï¼‰ã€MAEtestï¼ˆæ¨¡æ‹Ÿå…¶ä»–åˆ†å¸ƒåç§»ï¼‰ã€‚ç„¶åŽï¼Œé€‰å–å¤šä¸ªæœ€å…ˆè¿›çš„AMTæ¨¡åž‹ä½œä¸ºè¯„ä¼°å¯¹è±¡ã€‚æœ€åŽï¼Œä½¿ç”¨ä¼ ç»Ÿä¿¡æ¯æ£€ç´¢æŒ‡æ ‡ï¼ˆå¦‚éŸ³ç¬¦çº§F1ï¼‰å’ŒéŸ³ä¹æ„ŸçŸ¥æŒ‡æ ‡ï¼ˆå¦‚æ•æ‰å’Œå£°ç»“æž„çš„æŒ‡æ ‡ï¼‰è¿›è¡Œæ€§èƒ½è¯„ä¼°ï¼Œåˆ†æžä¸åŒåˆ†å¸ƒåç§»ä¸‹çš„æ€§èƒ½é€€åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºŽç³»ç»Ÿæ€§åœ°ç ”ç©¶éŸ³ä¹ç»´åº¦çš„åˆ†å¸ƒåç§»å¯¹AMTæ¨¡åž‹çš„å½±å“ï¼Œè€Œä¸ä»…ä»…æ˜¯å£°éŸ³æ¡ä»¶çš„å˜åŒ–ã€‚é€šè¿‡è®¾è®¡MDSè¯­æ–™åº“ï¼Œè®ºæ–‡èƒ½å¤Ÿé‡åŒ–ç‰¹å®šéŸ³ä¹å› ç´ ï¼ˆå¦‚æµæ´¾ï¼‰å¯¼è‡´çš„æ€§èƒ½ä¸‹é™ï¼Œå¹¶å¼•å…¥éŸ³ä¹æ„ŸçŸ¥æŒ‡æ ‡æ¥æ­ç¤ºæ½œåœ¨åŽŸå› ï¼Œè¿™æ‰©å±•äº†çŽ°æœ‰å¯¹AMTåè§é—®é¢˜çš„ç†è§£ã€‚

**å…³é”®è®¾è®¡**ï¼šMDSè¯­æ–™åº“æ˜¯å…³é”®è®¾è®¡ï¼Œå®ƒåŒ…å«ä¸‰ä¸ªå­é›†ä»¥æ¨¡æ‹Ÿä¸åŒè½´ï¼šGenreå­é›†è¦†ç›–å¤šç§éŸ³ä¹æµæ´¾ï¼ŒRandomå­é›†ä½¿ç”¨éšæœºç”Ÿæˆçš„éžéŸ³ä¹åºåˆ—æµ‹è¯•æžç«¯åç§»ï¼ŒMAEtestå­é›†å¯èƒ½åŸºäºŽå…¶ä»–æ•°æ®é›†æž„å»ºã€‚è¯„ä¼°ä¸­ï¼Œä½¿ç”¨éŸ³ç¬¦çº§F1åˆ†æ•°ç­‰ä¼ ç»ŸæŒ‡æ ‡ï¼Œä»¥åŠä¸“é—¨è®¾è®¡çš„éŸ³ä¹æ„ŸçŸ¥æŒ‡æ ‡ï¼ˆå¦‚å’Œå£°ç»“æž„ç›¸å…³æŒ‡æ ‡ï¼‰ï¼Œä»¥å…¨é¢æ•æ‰æ€§èƒ½å˜åŒ–ã€‚æ¨¡åž‹é€‰æ‹©åŒ…æ‹¬å¤šä¸ªæœ€å…ˆè¿›çš„æ·±åº¦AMTç³»ç»Ÿï¼Œç¡®ä¿è¯„ä¼°çš„ä»£è¡¨æ€§ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

æœ€é‡è¦çš„å®žéªŒç»“æžœæ˜¾ç¤ºï¼šåœ¨MDSè¯­æ–™åº“è¯„ä¼°ä¸­ï¼Œå£°éŸ³åˆ†å¸ƒåç§»å¯¼è‡´éŸ³ç¬¦çº§F1æ€§èƒ½ä¸‹é™20ä¸ªç™¾åˆ†ç‚¹ï¼Œæµæ´¾åç§»å¯¼è‡´ä¸‹é™14ä¸ªç™¾åˆ†ç‚¹ï¼Œå‡¸æ˜¾äº†æ¨¡åž‹å¯¹éŸ³ä¹å˜åŒ–çš„æ•æ„Ÿæ€§ã€‚åŠ¨æ€ä¼°è®¡æ¯”èµ·å§‹é¢„æµ‹æ›´æ˜“å—éŸ³ä¹å˜åŒ–å½±å“ï¼Œè¡¨æ˜Žæ¨¡åž‹åœ¨å¤„ç†éŸ³é‡å˜åŒ–æ—¶æ›´è„†å¼±ã€‚ä½¿ç”¨éšæœºéžéŸ³ä¹åºåˆ—çš„å®žéªŒæ­ç¤ºäº†ç³»ç»Ÿåœ¨æžç«¯åç§»ä¸‹çš„æ€§èƒ½æžé™ï¼ŒF1åˆ†æ•°æ˜¾è‘—é™ä½Žã€‚éŸ³ä¹æ„ŸçŸ¥æŒ‡æ ‡ï¼ˆå¦‚å’Œå£°ç»“æž„æŒ‡æ ‡ï¼‰å¸®åŠ©è¯†åˆ«äº†æ€§èƒ½é€€åŒ–çš„æ½œåœ¨å› ç´ ï¼Œä¸ºæ”¹è¿›æ¨¡åž‹æä¾›äº†æ–¹å‘ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨éŸ³ä¹ä¿¡æ¯æ£€ç´¢ã€éŸ³é¢‘å¤„ç†å’Œæ•™è‚²é¢†åŸŸå…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ã€‚é€šè¿‡æ­ç¤ºAMTæ¨¡åž‹åœ¨éŸ³ä¹ç»´åº¦åˆ†å¸ƒåç§»ä¸‹çš„åè§ï¼Œå¯æŒ‡å¯¼æ›´é²æ£’çš„æ¨¡åž‹å¼€å‘ï¼Œæå‡è‡ªåŠ¨è½¬å½•ç³»ç»Ÿåœ¨å¤šæ ·åŒ–éŸ³ä¹åœºæ™¯ï¼ˆå¦‚æµè¡ŒéŸ³ä¹ã€çŽ°åœºå½•éŸ³ï¼‰ä¸­çš„å‡†ç¡®æ€§ã€‚æœªæ¥å¯èƒ½æŽ¨åŠ¨æ•°æ®å¢žå¼ºç­–ç•¥ã€é¢†åŸŸè‡ªé€‚åº”æ–¹æ³•çš„å‘å±•ï¼Œä¿ƒè¿›éŸ³ä¹æŠ€æœ¯çš„å®žé™…éƒ¨ç½²å’Œè·¨é¢†åŸŸæ³›åŒ–ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Automatic Music Transcription (AMT) -- the task of converting music audio into note representations -- has seen rapid progress, driven largely by deep learning systems. Due to the limited availability of richly annotated music datasets, much of the progress in AMT has been concentrated on classical piano music, and even a few very specific datasets. Whether these systems can generalize effectively to other musical contexts remains an open question. Complementing recent studies on distribution shifts in sound (e.g., recording conditions), in this work we investigate the musical dimension -- specifically, variations in genre, dynamics, and polyphony levels. To this end, we introduce the MDS corpus, comprising three distinct subsets -- (1) Genre, (2) Random, and (3) MAEtest -- to emulate different axes of distribution shift. We evaluate the performance of several state-of-the-art AMT systems on the MDS corpus using both traditional information-retrieval and musically-informed performance metrics. Our extensive evaluation isolates and exposes varying degrees of performance degradation under specific distribution shifts. In particular, we measure a note-level F1 performance drop of 20 percentage points due to sound, and 14 due to genre. Generally, we find that dynamics estimation proves more vulnerable to musical variation than onset prediction. Musically informed evaluation metrics, particularly those capturing harmonic structure, help identify potential contributing factors. Furthermore, experiments with randomly generated, non-musical sequences reveal clear limitations in system performance under extreme musical distribution shifts. Altogether, these findings offer new evidence of the persistent impact of the Corpus Bias problem in deep AMT systems.

