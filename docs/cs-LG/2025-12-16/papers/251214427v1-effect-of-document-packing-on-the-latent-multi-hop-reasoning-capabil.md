---
layout: default
title: Effect of Document Packing on the Latent Multi-Hop Reasoning Capabilities of Large Language Models
---

# Effect of Document Packing on the Latent Multi-Hop Reasoning Capabilities of Large Language Models

**arXiv**: [2512.14427v1](https://arxiv.org/abs/2512.14427) | [PDF](https://arxiv.org/pdf/2512.14427.pdf)

**ä½œè€…**: Gabriele Prato, Shagun Sodhani, Alessandro Sordoni, Sarath Chandar

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç ”ç©¶æ–‡æ¡£æ‰“åŒ…ç­–ç•¥å¯¹å¤§åž‹è¯­è¨€æ¨¡åž‹æ½œåœ¨å¤šè·³æŽ¨ç†èƒ½åŠ›çš„å½±å“ï¼Œä»¥ä¼˜åŒ–è®­ç»ƒæ•ˆçŽ‡ä¸Žæ€§èƒ½ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **è§†è§‰é‡Œç¨‹è®¡** **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `æ–‡æ¡£æ‰“åŒ…` `å¤šè·³æŽ¨ç†` `å¤§åž‹è¯­è¨€æ¨¡åž‹` `è®­ç»ƒä¼˜åŒ–` `æ¶ˆèžç ”ç©¶` `è®¡ç®—æ•ˆçŽ‡` `è¯­è¨€å»ºæ¨¡` `æ¨¡åž‹æ€§èƒ½`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•ä¸­ï¼Œæ–‡æ¡£æ‰“åŒ…è™½æå‡è®¡ç®—æ•ˆçŽ‡ï¼Œä½†å¯¹æ¨¡åž‹æ½œåœ¨å¤šè·³æŽ¨ç†èƒ½åŠ›çš„å½±å“æœªçŸ¥ï¼Œç¼ºä¹ç³»ç»Ÿè¯„ä¼°ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡æ¯”è¾ƒä¸åŒæ‰“åŒ…ç­–ç•¥ï¼Œåˆ†æžå…¶å¯¹LLMså¤šè·³æŽ¨ç†èƒ½åŠ›çš„å½±å“ï¼Œå¹¶è¯†åˆ«å…³é”®å› ç´ ã€‚
3. å®žéªŒè¡¨æ˜Žæ‰“åŒ…èƒ½æé«˜æ¨¡åž‹æ€§èƒ½ï¼Œä½†éœ€æ›´å¤šè®¡ç®—ï¼›æ¶ˆèžç ”ç©¶æ­ç¤ºäº†æ‰“åŒ…ä¼˜åŠ¿çš„æœºåˆ¶ï¼Œä¸ºè®­ç»ƒä¼˜åŒ–æä¾›æŒ‡å¯¼ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è®­ç»ƒå¤§åž‹è¯­è¨€æ¨¡åž‹çš„æ ‡å‡†å®žè·µæ¶‰åŠå°†å¤šä¸ªæ–‡æ¡£æ‰“åŒ…åœ¨ä¸€èµ·ä»¥ä¼˜åŒ–è®¡ç®—æ•ˆçŽ‡ï¼Œä½†è¿™ä¸€è¿‡ç¨‹å¯¹æ¨¡åž‹èƒ½åŠ›çš„å½±å“åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå°šæœªè¢«æŽ¢ç´¢ã€‚ä¸ºå¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬ç ”ç©¶äº†ä¸åŒæ–‡æ¡£æ‰“åŒ…ç­–ç•¥å¦‚ä½•å½±å“LLMsçš„æ½œåœ¨å¤šè·³æŽ¨ç†èƒ½åŠ›ã€‚æˆ‘ä»¬çš„å‘çŽ°è¡¨æ˜Žï¼Œä¸Žåœ¨å•ä¸ªæ–‡æ¡£ä¸Šè®­ç»ƒç›¸æ¯”ï¼Œæ‰“åŒ…å¯ä»¥æé«˜æ¨¡åž‹æ€§èƒ½ï¼Œä½†ä»¥æ›´å¤šè®¡ç®—ä¸ºä»£ä»·ã€‚ä¸ºäº†è¿›ä¸€æ­¥ç†è§£åº•å±‚æœºåˆ¶ï¼Œæˆ‘ä»¬è¿›è¡Œäº†æ¶ˆèžç ”ç©¶ï¼Œè¯†åˆ«äº†è§£é‡Šæ‰“åŒ…ä¼˜åŠ¿çš„å…³é”®å› ç´ ã€‚æœ€ç»ˆï¼Œæˆ‘ä»¬çš„ç ”ç©¶åŠ æ·±äº†å¯¹LLMè®­ç»ƒåŠ¨æ€çš„ç†è§£ï¼Œå¹¶ä¸ºä¼˜åŒ–æ¨¡åž‹å¼€å‘æä¾›äº†å®žç”¨è§è§£ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æ–‡æ¡£æ‰“åŒ…ç­–ç•¥å¯¹å¤§åž‹è¯­è¨€æ¨¡åž‹ï¼ˆLLMsï¼‰æ½œåœ¨å¤šè·³æŽ¨ç†èƒ½åŠ›çš„å…·ä½“å½±å“é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•çš„ç—›ç‚¹åœ¨äºŽï¼Œæ ‡å‡†è®­ç»ƒä¸­ä¸ºä¼˜åŒ–è®¡ç®—æ•ˆçŽ‡è€Œæ‰“åŒ…å¤šä¸ªæ–‡æ¡£ï¼Œä½†è¿™ä¸€è¿‡ç¨‹å¯¹æ¨¡åž‹èƒ½åŠ›ï¼ˆå°¤å…¶æ˜¯å¤šè·³æŽ¨ç†ï¼‰çš„å½±å“æœªè¢«å……åˆ†ç ”ç©¶ï¼Œå¯èƒ½å¯¼è‡´è®­ç»ƒæ•ˆçŽ‡ä¸Žæ€§èƒ½ä¹‹é—´çš„æƒè¡¡ä¸æ˜Žç¡®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒè§£å†³æ€è·¯æ˜¯é€šè¿‡ç³»ç»Ÿå®žéªŒæ¯”è¾ƒä¸åŒæ–‡æ¡£æ‰“åŒ…ç­–ç•¥ï¼Œè¯„ä¼°å…¶å¯¹LLMså¤šè·³æŽ¨ç†èƒ½åŠ›çš„å½±å“ï¼Œå¹¶åˆ©ç”¨æ¶ˆèžç ”ç©¶è¯†åˆ«å…³é”®å› ç´ ã€‚è¿™æ ·è®¾è®¡æ˜¯ä¸ºäº†å¡«è¡¥çŽ°æœ‰ç ”ç©¶ç©ºç™½ï¼Œä»Žè®­ç»ƒåŠ¨æ€è§’åº¦ç†è§£æ‰“åŒ…çš„åˆ©å¼Šï¼Œä¸ºæ¨¡åž‹å¼€å‘æä¾›æ•°æ®é©±åŠ¨çš„ä¼˜åŒ–å»ºè®®ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æž¶æž„åŒ…æ‹¬æ•°æ®å‡†å¤‡ã€æ¨¡åž‹è®­ç»ƒã€è¯„ä¼°å’Œæ¶ˆèžåˆ†æžå››ä¸ªé˜¶æ®µã€‚é¦–å…ˆï¼Œå‡†å¤‡ä¸åŒæ‰“åŒ…ç­–ç•¥çš„æ•°æ®é›†ï¼ˆå¦‚éšæœºæ‰“åŒ…ã€åŸºäºŽä¸»é¢˜æ‰“åŒ…ç­‰ï¼‰ã€‚ç„¶åŽï¼Œåœ¨LLMsä¸Šè¿›è¡Œè®­ç»ƒï¼Œä½¿ç”¨æ ‡å‡†è¯­è¨€å»ºæ¨¡ç›®æ ‡ã€‚æŽ¥ç€ï¼Œé€šè¿‡å¤šè·³æŽ¨ç†ä»»åŠ¡è¯„ä¼°æ¨¡åž‹æ€§èƒ½ã€‚æœ€åŽï¼Œè¿›è¡Œæ¶ˆèžç ”ç©¶ï¼Œåˆ†æžæ‰“åŒ…ç­–ç•¥ä¸­çš„å…³é”®å˜é‡ï¼ˆå¦‚æ–‡æ¡£é•¿åº¦ã€é¡ºåºã€ç›¸å…³æ€§ï¼‰å¯¹æ€§èƒ½çš„å½±å“ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹æ˜¯é¦–æ¬¡ç³»ç»Ÿç ”ç©¶æ–‡æ¡£æ‰“åŒ…ç­–ç•¥å¯¹LLMså¤šè·³æŽ¨ç†èƒ½åŠ›çš„æ½œåœ¨å½±å“ï¼Œå¹¶å¼•å…¥æ¶ˆèžåˆ†æžæ¥æ­ç¤ºåº•å±‚æœºåˆ¶ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºŽï¼ŒçŽ°æœ‰å·¥ä½œå¤šå…³æ³¨æ‰“åŒ…çš„è®¡ç®—æ•ˆçŽ‡ï¼Œè€Œæœ¬æ–‡èšç„¦äºŽèƒ½åŠ›å½±å“ï¼Œæä¾›äº†æ›´å…¨é¢çš„è®­ç»ƒåŠ¨æ€è§†è§’ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ä½¿ç”¨æ ‡å‡†Transformeræž¶æž„çš„LLMsï¼Œè®­ç»ƒæ—¶é‡‡ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°è¿›è¡Œè¯­è¨€å»ºæ¨¡ã€‚å‚æ•°è®¾ç½®æ¶‰åŠæ‰¹é‡å¤§å°ã€å­¦ä¹ çŽ‡ç­‰æ ‡å‡†è¶…å‚æ•°ï¼Œä½†é’ˆå¯¹ä¸åŒæ‰“åŒ…ç­–ç•¥è¿›è¡Œè°ƒæ•´ã€‚æ¶ˆèžç ”ç©¶ä¸­ï¼Œå…³é”®å˜é‡å¦‚æ–‡æ¡£é—´ç›¸å…³æ€§ã€æ‰“åŒ…é¡ºåºè¢«ç‹¬ç«‹æŽ§åˆ¶ï¼Œä»¥é‡åŒ–å…¶å¯¹æ€§èƒ½çš„è´¡çŒ®ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœæ˜¾ç¤ºï¼Œæ–‡æ¡£æ‰“åŒ…ç­–ç•¥èƒ½æ˜¾è‘—æé«˜LLMsåœ¨å¤šè·³æŽ¨ç†ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œå…·ä½“æå‡å¹…åº¦æœªçŸ¥ï¼ˆè®ºæ–‡æœªæä¾›ç²¾ç¡®æ•°æ®ï¼‰ï¼Œä½†ç›¸æ¯”å•ä¸ªæ–‡æ¡£è®­ç»ƒæœ‰ä¼˜åŠ¿ã€‚æ¶ˆèžç ”ç©¶è¯†åˆ«å‡ºæ–‡æ¡£ç›¸å…³æ€§å’Œæ‰“åŒ…é¡ºåºæ˜¯å…³é”®å› ç´ ï¼Œè§£é‡Šäº†æ€§èƒ½æå‡æœºåˆ¶ã€‚å¯¹æ¯”åŸºçº¿åŒ…æ‹¬ä¸åŒæ‰“åŒ…ç­–ç•¥ï¼Œç»“æžœå¼ºè°ƒäº†æ‰“åŒ…åœ¨ä¼˜åŒ–è®­ç»ƒåŠ¨æ€ä¸­çš„é‡è¦æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨å¤§åž‹è¯­è¨€æ¨¡åž‹è®­ç»ƒä¼˜åŒ–é¢†åŸŸå…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ï¼Œå¯æŒ‡å¯¼å¼€å‘è€…å¹³è¡¡è®¡ç®—æ•ˆçŽ‡ä¸Žæ¨¡åž‹æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨èµ„æºå—é™åœºæ™¯ä¸‹ã€‚å®žé™…ä»·å€¼åŒ…æ‹¬æå‡å¤šè·³æŽ¨ç†ä»»åŠ¡çš„æ¨¡åž‹èƒ½åŠ›ï¼Œæœªæ¥å¯èƒ½å½±å“è®­ç»ƒç­–ç•¥æ ‡å‡†åŒ–ï¼Œä¿ƒè¿›æ›´é«˜æ•ˆçš„AIæ¨¡åž‹å¼€å‘ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The standard practice for training large language models involves packing multiple documents together to optimize computational efficiency. However, the impact of this process on the models' capabilities remains largely unexplored. To address this gap, we investigate how different document-packing strategies influence the latent multi-hop reasoning abilities of LLMs. Our findings indicate that packing can improve model performance compared to training on individual documents, at the expense of more compute. To further understand the underlying mechanisms, we conduct an ablation study, identifying key factors that explain the advantages of packing. Ultimately, our research deepens the understanding of LLM training dynamics and provides practical insights for optimizing model development.

