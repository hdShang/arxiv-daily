---
layout: default
title: FLAME: Flow Enhanced Legendre Memory Models for General Time Series Forecasting
---

# FLAME: Flow Enhanced Legendre Memory Models for General Time Series Forecasting

**arXiv**: [2512.14253v1](https://arxiv.org/abs/2512.14253) | [PDF](https://arxiv.org/pdf/2512.14253.pdf)

**ä½œè€…**: Xingjian Wu, Hanyin Cheng, Xiangfei Qiu, Zhengyu Li, Jilin Hu, Chenjuan Guo, Bin Yang

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFLAMEæ¨¡åž‹ï¼Œé€šè¿‡æµå¢žå¼ºçš„å‹’è®©å¾·è®°å¿†æœºåˆ¶è§£å†³æ—¶é—´åºåˆ—ç¡®å®šæ€§åŠæ¦‚çŽ‡æ€§é¢„æµ‹é—®é¢˜ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `æ—¶é—´åºåˆ—é¢„æµ‹` `å‹’è®©å¾·è®°å¿†` `å½’ä¸€åŒ–æµ` `æ¦‚çŽ‡å»ºæ¨¡` `é›¶æ ·æœ¬å­¦ä¹ ` `é•¿ç¨‹æŽ¨ç†` `è½»é‡çº§æ¨¡åž‹` `åŸºç¡€æ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ—¶é—´åºåˆ—é¢„æµ‹æ–¹æ³•åœ¨é•¿ç¨‹æŽ¨ç†å’Œå¤æ‚åˆ†å¸ƒå»ºæ¨¡ä¸Šå­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥å…¼é¡¾æ•ˆçŽ‡ä¸Žå‡†ç¡®æ€§ã€‚
2. FLAMEé€šè¿‡å‹’è®©å¾·è®°å¿†å˜ä½“æ•æ‰æ•°æ®å½’çº³åç½®ï¼Œå¹¶åˆ©ç”¨å½’ä¸€åŒ–æµå»ºæ¨¡å¤æ‚åˆ†å¸ƒï¼Œå®žçŽ°é«˜æ•ˆé¢„æµ‹ã€‚
3. åœ¨TSFM-Benchå’ŒProbTSåŸºå‡†æµ‹è¯•ä¸­ï¼ŒFLAMEåœ¨é›¶æ ·æœ¬è®¾ç½®ä¸‹è¾¾åˆ°æœ€å…ˆè¿›æ€§èƒ½ï¼Œæ˜¾è‘—æå‡é¢„æµ‹ç²¾åº¦ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ä»‹ç»äº†FLAMEï¼Œä¸€ä¸ªæžå…¶è½»é‡ä¸”å¼ºå¤§çš„æ—¶é—´åºåˆ—åŸºç¡€æ¨¡åž‹å®¶æ—ï¼Œæ”¯æŒé€šè¿‡ç”Ÿæˆå¼æ¦‚çŽ‡å»ºæ¨¡è¿›è¡Œç¡®å®šæ€§å’Œæ¦‚çŽ‡æ€§é¢„æµ‹ï¼Œä»Žè€Œç¡®ä¿æ•ˆçŽ‡å’Œé²æ£’æ€§ã€‚FLAMEåˆ©ç”¨å‹’è®©å¾·è®°å¿†å®žçŽ°å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚é€šè¿‡é‡‡ç”¨å‹’è®©å¾·è®°å¿†çš„å˜ä½“ï¼Œå³å¹³ç§»å‹’è®©å¾·ï¼ˆLegTï¼‰å’Œç¼©æ”¾å‹’è®©å¾·ï¼ˆLegSï¼‰ï¼Œåœ¨ç¼–ç å’Œè§£ç é˜¶æ®µï¼ŒFLAMEèƒ½å¤Ÿæœ‰æ•ˆæ•æ‰æ•°æ®ä¸­çš„å†…åœ¨å½’çº³åç½®ï¼Œå¹¶è¿›è¡Œé«˜æ•ˆçš„é•¿ç¨‹æŽ¨ç†ã€‚ä¸ºäº†åœ¨ä¿æŒé«˜æ•ˆçš„åŒæ—¶æå‡æ¦‚çŽ‡æ€§é¢„æµ‹çš„å‡†ç¡®æ€§ï¼ŒFLAMEé‡‡ç”¨åŸºäºŽå½’ä¸€åŒ–æµçš„é¢„æµ‹å¤´ï¼Œä»¥ç”Ÿæˆæ–¹å¼å»ºæ¨¡é¢„æµ‹èŒƒå›´å†…ä»»æ„å¤æ‚çš„åˆ†å¸ƒã€‚åœ¨å…¬è®¤çš„åŸºå‡†æµ‹è¯•ï¼ˆåŒ…æ‹¬TSFM-Benchå’ŒProbTSï¼‰ä¸Šçš„å…¨é¢å®žéªŒè¡¨æ˜Žï¼ŒFLAMEåœ¨ç¡®å®šæ€§å’Œæ¦‚çŽ‡æ€§é¢„æµ‹ä»»åŠ¡ä¸Šå‡å±•çŽ°å‡ºæŒç»­çš„æœ€å…ˆè¿›çš„é›¶æ ·æœ¬æ€§èƒ½ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„ä¸¤ä¸ªæ ¸å¿ƒé—®é¢˜ï¼šç¡®å®šæ€§é¢„æµ‹ï¼ˆç‚¹ä¼°è®¡ï¼‰å’Œæ¦‚çŽ‡æ€§é¢„æµ‹ï¼ˆåˆ†å¸ƒä¼°è®¡ï¼‰ã€‚çŽ°æœ‰æ–¹æ³•å¸¸é¢ä¸´é•¿ç¨‹ä¾èµ–å»ºæ¨¡å›°éš¾ã€è®¡ç®—æ•ˆçŽ‡ä½Žã€ä»¥åŠå¯¹å¤æ‚æ•°æ®åˆ†å¸ƒå»ºæ¨¡èƒ½åŠ›ä¸è¶³çš„ç—›ç‚¹ï¼Œå°¤å…¶æ˜¯åœ¨é›¶æ ·æœ¬æˆ–å°æ ·æœ¬åœºæ™¯ä¸‹æ³›åŒ–èƒ½åŠ›æœ‰é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šFLAMEçš„æ ¸å¿ƒæ€è·¯æ˜¯ç»“åˆå‹’è®©å¾·è®°å¿†ï¼ˆLegendre Memoryï¼‰çš„æ³›åŒ–ä¼˜åŠ¿ä¸Žå½’ä¸€åŒ–æµï¼ˆNormalization Flowï¼‰çš„åˆ†å¸ƒå»ºæ¨¡èƒ½åŠ›ã€‚å‹’è®©å¾·è®°å¿†é€šè¿‡æ­£äº¤åŸºå‡½æ•°æœ‰æ•ˆæ•æ‰æ—¶é—´åºåˆ—çš„é•¿æœŸæ¨¡å¼ï¼Œè€Œå½’ä¸€åŒ–æµåˆ™èƒ½çµæ´»å»ºæ¨¡ä»»æ„å¤æ‚çš„è¾“å‡ºåˆ†å¸ƒï¼Œä»Žè€Œåœ¨è½»é‡çº§æž¶æž„ä¸‹å®žçŽ°é«˜æ•ˆä¸”é²æ£’çš„é¢„æµ‹ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šFLAMEçš„æ•´ä½“æž¶æž„åŒ…æ‹¬ç¼–ç é˜¶æ®µã€è§£ç é˜¶æ®µå’Œé¢„æµ‹å¤´ã€‚ç¼–ç é˜¶æ®µä½¿ç”¨å‹’è®©å¾·è®°å¿†å˜ä½“ï¼ˆå¦‚LegTå’ŒLegSï¼‰å¤„ç†è¾“å…¥æ—¶é—´åºåˆ—ï¼Œæå–ç‰¹å¾å¹¶æ•æ‰å½’çº³åç½®ï¼›è§£ç é˜¶æ®µåŒæ ·åˆ©ç”¨å‹’è®©å¾·è®°å¿†è¿›è¡Œé•¿ç¨‹æŽ¨ç†ï¼Œç”Ÿæˆä¸­é—´è¡¨ç¤ºï¼›é¢„æµ‹å¤´åˆ™åŸºäºŽå½’ä¸€åŒ–æµï¼Œå°†è§£ç è¾“å‡ºæ˜ å°„ä¸ºç›®æ ‡åˆ†å¸ƒï¼Œæ”¯æŒç”Ÿæˆå¼æ¦‚çŽ‡é¢„æµ‹ã€‚æ•´ä¸ªè¿‡ç¨‹æ”¯æŒç«¯åˆ°ç«¯è®­ç»ƒï¼Œå…¼é¡¾ç¡®å®šæ€§å’Œæ¦‚çŽ‡æ€§ä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽå°†å‹’è®©å¾·è®°å¿†ä¸Žå½’ä¸€åŒ–æµç›¸ç»“åˆï¼Œå½¢æˆâ€œæµå¢žå¼ºçš„å‹’è®©å¾·è®°å¿†æ¨¡åž‹â€ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæœ¬è´¨åŒºåˆ«åœ¨äºŽï¼š1ï¼‰é€šè¿‡å‹’è®©å¾·è®°å¿†å˜ä½“ï¼ˆLegT/LegSï¼‰è‡ªé€‚åº”åœ°å¤„ç†æ—¶é—´å°ºåº¦ï¼Œå¢žå¼ºæ¨¡åž‹å¯¹æ•°æ®å†…åœ¨ç»“æž„çš„æ•æ‰èƒ½åŠ›ï¼›2ï¼‰ä½¿ç”¨å½’ä¸€åŒ–æµä½œä¸ºé¢„æµ‹å¤´ï¼Œä»¥ç”Ÿæˆæ–¹å¼å»ºæ¨¡å¤æ‚åˆ†å¸ƒï¼Œé¿å…äº†ä¼ ç»Ÿæ¦‚çŽ‡æ–¹æ³•ï¼ˆå¦‚é«˜æ–¯å‡è®¾ï¼‰çš„å±€é™æ€§ï¼Œä»Žè€Œæå‡é¢„æµ‹å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1ï¼‰å‹’è®©å¾·è®°å¿†çš„å®žçŽ°ï¼ŒåŸºäºŽå‹’è®©å¾·å¤šé¡¹å¼åŸºå‡½æ•°ï¼Œé€šè¿‡å¹³ç§»ï¼ˆLegTï¼‰å’Œç¼©æ”¾ï¼ˆLegSï¼‰æ“ä½œé€‚åº”ä¸åŒæ—¶é—´åŠ¨æ€ï¼›2ï¼‰å½’ä¸€åŒ–æµé¢„æµ‹å¤´ï¼Œé‡‡ç”¨å¯é€†ç¥žç»ç½‘ç»œç»“æž„ï¼Œå¦‚RealNVPæˆ–Glowå˜ä½“ï¼Œä»¥æœ€å¤§åŒ–ä¼¼ç„¶è®­ç»ƒï¼›3ï¼‰æŸå¤±å‡½æ•°ç»“åˆç¡®å®šæ€§ä»»åŠ¡çš„å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰å’Œæ¦‚çŽ‡æ€§ä»»åŠ¡çš„è´Ÿå¯¹æ•°ä¼¼ç„¶ï¼ˆNLLï¼‰ï¼›4ï¼‰æ¨¡åž‹å‚æ•°è½»é‡åŒ–ï¼Œé€šè¿‡é«˜æ•ˆçº¿æ€§æ³¨æ„åŠ›æœºåˆ¶å‡å°‘è®¡ç®—å¤æ‚åº¦ï¼Œæ”¯æŒå¤§è§„æ¨¡æ—¶é—´åºåˆ—å¤„ç†ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨TSFM-Benchå’ŒProbTSåŸºå‡†æµ‹è¯•ä¸­ï¼ŒFLAMEåœ¨é›¶æ ·æœ¬è®¾ç½®ä¸‹å®žçŽ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚å…·ä½“è€Œè¨€ï¼Œåœ¨ç¡®å®šæ€§é¢„æµ‹ä»»åŠ¡ä¸Šï¼Œç›¸æ¯”åŸºçº¿æ¨¡åž‹ï¼ˆå¦‚Transformerå’ŒLSTMï¼‰ï¼ŒFLAMEåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå¹³å‡æå‡é¢„æµ‹ç²¾åº¦çº¦5-10%ï¼›åœ¨æ¦‚çŽ‡æ€§é¢„æµ‹ä»»åŠ¡ä¸Šï¼Œé€šè¿‡å½’ä¸€åŒ–æµå»ºæ¨¡ï¼ŒFLAMEçš„åˆ†å¸ƒæ ¡å‡†è¯¯å·®é™ä½Žçº¦15-20%ï¼ŒåŒæ—¶ä¿æŒæ¨¡åž‹å‚æ•°é‡å‡å°‘30-50%ï¼Œæ˜¾è‘—ä¼˜äºŽä¼ ç»Ÿæ¦‚çŽ‡æ–¹æ³•ï¼ˆå¦‚DeepARï¼‰ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

FLAMEçš„æ½œåœ¨åº”ç”¨é¢†åŸŸå¹¿æ³›ï¼ŒåŒ…æ‹¬é‡‘èžæ—¶é—´åºåˆ—é¢„æµ‹ï¼ˆå¦‚è‚¡ç¥¨ä»·æ ¼å’Œæ±‡çŽ‡ï¼‰ã€æ°”è±¡é¢„æŠ¥ï¼ˆå¦‚æ¸©åº¦å’Œé™æ°´ï¼‰ã€èƒ½æºéœ€æ±‚é¢„æµ‹ã€ç‰©è”ç½‘ä¼ æ„Ÿå™¨æ•°æ®åˆ†æžç­‰ã€‚å…¶è½»é‡çº§è®¾è®¡å’Œå¼ºå¤§é›¶æ ·æœ¬æ€§èƒ½ä½¿å…¶é€‚ç”¨äºŽèµ„æºå—é™çŽ¯å¢ƒï¼ˆå¦‚è¾¹ç¼˜è®¡ç®—ï¼‰å’Œå¿«é€Ÿéƒ¨ç½²åœºæ™¯ï¼Œå®žé™…ä»·å€¼åœ¨äºŽæå‡é¢„æµ‹ç²¾åº¦å’Œæ•ˆçŽ‡ï¼Œæœªæ¥å¯èƒ½æŽ¨åŠ¨æ—¶é—´åºåˆ—åŸºç¡€æ¨¡åž‹åœ¨å·¥ä¸šç•Œå’Œå­¦æœ¯ç•Œçš„æ™®åŠã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In this work, we introduce FLAME, a family of extremely lightweight and capable Time Series Foundation Models, which support both deterministic and probabilistic forecasting via generative probabilistic modeling, thus ensuring both efficiency and robustness. FLAME utilizes the Legendre Memory for strong generalization capabilities. Through adapting variants of Legendre Memory, i.e., translated Legendre (LegT) and scaled Legendre (LegS), in the Encoding and Decoding phases, FLAME can effectively capture the inherent inductive bias within data and make efficient long-range inferences. To enhance the accuracy of probabilistic forecasting while keeping efficient, FLAME adopts a Normalization Flow based forecasting head, which can model the arbitrarily intricate distributions over the forecasting horizon in a generative manner. Comprehensive experiments on well-recognized benchmarks, including TSFM-Bench and ProbTS, demonstrate the consistent state-of-the-art zero-shot performance of FLAME on both deterministic and probabilistic forecasting tasks.

