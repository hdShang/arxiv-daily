---
layout: default
title: Joint Multimodal Contrastive Learning for Robust Spoken Term Detection and Keyword Spotting
---

# Joint Multimodal Contrastive Learning for Robust Spoken Term Detection and Keyword Spotting

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.14115" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.14115v1</a>
  <a href="https://arxiv.org/pdf/2512.14115.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14115v1" onclick="toggleFavorite(this, '2512.14115v1', 'Joint Multimodal Contrastive Learning for Robust Spoken Term Detection and Keyword Spotting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ramesh Gundluru, Shubham Gupta, Sri Rama Murty K

**åˆ†ç±»**: cs.SD, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè”åˆå¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œæå‡ç¨³å¥çš„è¯­éŸ³æ£€ç´¢å’Œå…³é”®è¯æ£€æµ‹æ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯­éŸ³æœ¯è¯­æ£€æµ‹` `å…³é”®è¯æ£€æµ‹` `å¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ ` `å£°å­¦è¯åµŒå…¥` `è·¨æ¨¡æ€å¯¹é½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è¯­éŸ³æ£€ç´¢æ–¹æ³•å—é™äºå•æ¨¡æ€ç›‘ç£å’ŒéŸ³é¢‘å¯¹é½çš„ç‹¬ç«‹ä¼˜åŒ–ï¼Œéœ€è¦ä»»åŠ¡ç‰¹å®šçš„æ¨¡å‹ã€‚
2. æå‡ºè”åˆå¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œç»Ÿä¸€å£°å­¦å’Œè·¨æ¨¡æ€ç›‘ç£ï¼Œä¼˜åŒ–éŸ³é¢‘-æ–‡æœ¬å’ŒéŸ³é¢‘-éŸ³é¢‘å¯¹é½ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è¯æ±‡åŒºåˆ†ä»»åŠ¡ä¸Šè¶…è¶Šç°æœ‰åŸºçº¿ï¼Œå¹¶çµæ´»æ”¯æŒè¯­éŸ³æœ¯è¯­æ£€æµ‹å’Œå…³é”®è¯æ£€æµ‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§è”åˆå¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨æå‡è¯­éŸ³æ£€ç´¢ä»»åŠ¡ï¼ˆå¦‚è¯­éŸ³æœ¯è¯­æ£€æµ‹STDå’Œå…³é”®è¯æ£€æµ‹KWSï¼‰çš„æ€§èƒ½ã€‚ç°æœ‰æ–¹æ³•å­˜åœ¨å•æ¨¡æ€ç›‘ç£ã€éŸ³é¢‘-éŸ³é¢‘å’ŒéŸ³é¢‘-æ–‡æœ¬å¯¹é½çš„ç‹¬ç«‹ä¼˜åŒ–ä»¥åŠéœ€è¦ä»»åŠ¡ç‰¹å®šæ¨¡å‹ç­‰å±€é™æ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œè¯¥æ¡†æ¶åœ¨å…±äº«åµŒå…¥ç©ºé—´ä¸­ç»Ÿä¸€äº†å£°å­¦å’Œè·¨æ¨¡æ€ç›‘ç£ï¼ŒåŒæ—¶ä¼˜åŒ–ï¼šï¼ˆiï¼‰å—CLAPæŸå¤±å¯å‘çš„éŸ³é¢‘-æ–‡æœ¬å¯¹æ¯”å­¦ä¹ ï¼Œä»¥å¯¹é½éŸ³é¢‘å’Œæ–‡æœ¬è¡¨ç¤ºï¼›ï¼ˆiiï¼‰é€šè¿‡æ·±åº¦è¯æ±‡åŒºåˆ†ï¼ˆDWDï¼‰æŸå¤±å®ç°çš„éŸ³é¢‘-éŸ³é¢‘å¯¹æ¯”å­¦ä¹ ï¼Œä»¥å¢å¼ºç±»å†…ç´§å‡‘æ€§å’Œç±»é—´åˆ†ç¦»ã€‚è¯¥æ–¹æ³•åœ¨è¯æ±‡åŒºåˆ†ä»»åŠ¡ä¸Šä¼˜äºç°æœ‰çš„AWEåŸºçº¿ï¼Œå¹¶èƒ½çµæ´»æ”¯æŒSTDå’ŒKWSã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–ä¸ªæ­¤ç±»ç»¼åˆæ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è¯­éŸ³æœ¯è¯­æ£€æµ‹ï¼ˆSTDï¼‰å’Œå…³é”®è¯æ£€æµ‹ï¼ˆKWSï¼‰ä¸­ï¼Œç°æœ‰å£°å­¦è¯åµŒå…¥ï¼ˆAWEï¼‰æ–¹æ³•çš„å±€é™æ€§ã€‚è¿™äº›æ–¹æ³•é€šå¸¸ä¾èµ–äºå•æ¨¡æ€ç›‘ç£ï¼ŒéŸ³é¢‘-éŸ³é¢‘å’ŒéŸ³é¢‘-æ–‡æœ¬çš„å¯¹é½æ˜¯ç‹¬ç«‹ä¼˜åŒ–çš„ï¼Œå¹¶ä¸”éœ€è¦é’ˆå¯¹ç‰¹å®šä»»åŠ¡è®­ç»ƒæ¨¡å‹ï¼Œå¯¼è‡´æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è”åˆå¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ ï¼Œå°†éŸ³é¢‘å’Œæ–‡æœ¬ä¿¡æ¯èåˆåˆ°ä¸€ä¸ªå…±äº«çš„åµŒå…¥ç©ºé—´ä¸­ã€‚é€šè¿‡åŒæ—¶ä¼˜åŒ–éŸ³é¢‘-æ–‡æœ¬å’ŒéŸ³é¢‘-éŸ³é¢‘çš„å¯¹æ¯”æŸå¤±ï¼Œä½¿å¾—åµŒå…¥ç©ºé—´æ—¢èƒ½åæ˜ éŸ³é¢‘å’Œæ–‡æœ¬ä¹‹é—´çš„è¯­ä¹‰å…³ç³»ï¼Œåˆèƒ½åŒºåˆ†ä¸åŒçš„è¯­éŸ³è¯æ±‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦çš„å¯¹æ¯”å­¦ä¹ æ¨¡å—ï¼šéŸ³é¢‘-æ–‡æœ¬å¯¹æ¯”å­¦ä¹ å’ŒéŸ³é¢‘-éŸ³é¢‘å¯¹æ¯”å­¦ä¹ ã€‚éŸ³é¢‘-æ–‡æœ¬å¯¹æ¯”å­¦ä¹ æ¨¡å—ä½¿ç”¨ç±»ä¼¼CLAPçš„æŸå¤±å‡½æ•°ï¼Œå°†éŸ³é¢‘å’Œæ–‡æœ¬æ˜ å°„åˆ°åŒä¸€åµŒå…¥ç©ºé—´ï¼Œä½¿å¾—è¯­ä¹‰ç›¸å…³çš„éŸ³é¢‘å’Œæ–‡æœ¬è¡¨ç¤ºæ›´æ¥è¿‘ã€‚éŸ³é¢‘-éŸ³é¢‘å¯¹æ¯”å­¦ä¹ æ¨¡å—ä½¿ç”¨æ·±åº¦è¯æ±‡åŒºåˆ†ï¼ˆDWDï¼‰æŸå¤±ï¼Œå¢å¼ºåŒä¸€è¯æ±‡çš„ä¸åŒè¯­éŸ³æ ·æœ¬ä¹‹é—´çš„ç›¸ä¼¼æ€§ï¼Œå¹¶å¢å¤§ä¸åŒè¯æ±‡ä¹‹é—´çš„è·ç¦»ã€‚è¿™ä¸¤ä¸ªæ¨¡å—è”åˆä¼˜åŒ–ï¼Œå…±åŒæå‡åµŒå…¥ç©ºé—´çš„è´¨é‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†éŸ³é¢‘-æ–‡æœ¬å’ŒéŸ³é¢‘-éŸ³é¢‘å¯¹æ¯”å­¦ä¹ æ•´åˆåˆ°ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ä¸­ï¼Œå®ç°äº†è·¨æ¨¡æ€ä¿¡æ¯çš„æœ‰æ•ˆèåˆå’Œè¯­éŸ³è¯æ±‡çš„ç²¾ç»†åŒºåˆ†ã€‚ä¸ä»¥å¾€æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•ä¸å†ä¾èµ–äºå•æ¨¡æ€ç›‘ç£ï¼Œå¹¶ä¸”é¿å…äº†éŸ³é¢‘-éŸ³é¢‘å’ŒéŸ³é¢‘-æ–‡æœ¬å¯¹é½çš„ç‹¬ç«‹ä¼˜åŒ–ï¼Œä»è€Œæé«˜äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šéŸ³é¢‘-æ–‡æœ¬å¯¹æ¯”å­¦ä¹ æ¨¡å—é‡‡ç”¨InfoNCEæŸå¤±ï¼Œé¼“åŠ±æ­£æ ·æœ¬å¯¹ï¼ˆè¯­ä¹‰ç›¸å…³çš„éŸ³é¢‘å’Œæ–‡æœ¬ï¼‰çš„åµŒå…¥å‘é‡æ›´æ¥è¿‘ï¼Œè€Œè´Ÿæ ·æœ¬å¯¹åˆ™è¿œç¦»ã€‚éŸ³é¢‘-éŸ³é¢‘å¯¹æ¯”å­¦ä¹ æ¨¡å—é‡‡ç”¨DWDæŸå¤±ï¼Œè¯¥æŸå¤±å‡½æ•°æ—¨åœ¨æœ€å¤§åŒ–ç±»å†…ç´§å‡‘æ€§å’Œç±»é—´åˆ†ç¦»ã€‚å…·ä½“å®ç°ä¸­ï¼Œå¯ä»¥ä½¿ç”¨ä¸åŒçš„ç¥ç»ç½‘ç»œç»“æ„ï¼ˆå¦‚Transformerï¼‰æ¥æå–éŸ³é¢‘å’Œæ–‡æœ¬çš„ç‰¹å¾è¡¨ç¤ºã€‚æŸå¤±å‡½æ•°çš„æƒé‡éœ€è¦æ ¹æ®å…·ä½“ä»»åŠ¡è¿›è¡Œè°ƒæ•´ï¼Œä»¥å¹³è¡¡éŸ³é¢‘-æ–‡æœ¬å’ŒéŸ³é¢‘-éŸ³é¢‘å¯¹æ¯”å­¦ä¹ çš„é‡è¦æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥æ–¹æ³•åœ¨è¯æ±‡åŒºåˆ†ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¶…è¶Šäº†ç°æœ‰çš„AWEåŸºçº¿ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè”åˆå¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ èƒ½å¤Ÿæœ‰æ•ˆåœ°èåˆéŸ³é¢‘å’Œæ–‡æœ¬ä¿¡æ¯ï¼Œæé«˜è¯­éŸ³æ£€ç´¢çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿ä¿¡æ¯åœ¨è®ºæ–‡ä¸­è¯¦ç»†ç»™å‡ºï¼ˆå…·ä½“æ•°å€¼æœªçŸ¥ï¼‰ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºè¯­éŸ³æœç´¢ã€è¯­éŸ³åŠ©æ‰‹ã€æ™ºèƒ½å®¢æœç­‰é¢†åŸŸã€‚é€šè¿‡æå‡è¯­éŸ³æ£€ç´¢çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ï¼Œå¯ä»¥æ›´å¿«é€Ÿåœ°ä»æµ·é‡è¯­éŸ³æ•°æ®ä¸­æ‰¾åˆ°ç›®æ ‡ä¿¡æ¯ï¼Œæ”¹å–„ç”¨æˆ·ä½“éªŒã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥åº”ç”¨äºå¤šè¯­è¨€è¯­éŸ³è¯†åˆ«å’Œè·¨è¯­è¨€è¯­éŸ³æ£€ç´¢ç­‰ä»»åŠ¡ï¼Œå…·æœ‰é‡è¦çš„å®é™…åº”ç”¨ä»·å€¼å’Œæœªæ¥å‘å±•æ½œåŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Acoustic Word Embeddings (AWEs) improve the efficiency of speech retrieval tasks such as Spoken Term Detection (STD) and Keyword Spotting (KWS). However, existing approaches suffer from limitations, including unimodal supervision, disjoint optimization of audio-audio and audio-text alignment, and the need for task-specific models. To address these shortcomings, we propose a joint multimodal contrastive learning framework that unifies both acoustic and cross-modal supervision in a shared embedding space. Our approach simultaneously optimizes: (i) audio-text contrastive learning, inspired by the CLAP loss, to align audio and text representations and (ii) audio-audio contrastive learning, via Deep Word Discrimination (DWD) loss, to enhance intra-class compactness and inter-class separation. The proposed method outperforms existing AWE baselines on word discrimination task while flexibly supporting both STD and KWS. To our knowledge, this is the first comprehensive approach of its kind.

