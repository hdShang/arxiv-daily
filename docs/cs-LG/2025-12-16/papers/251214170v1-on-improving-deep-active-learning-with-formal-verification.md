---
layout: default
title: On Improving Deep Active Learning with Formal Verification
---

# On Improving Deep Active Learning with Formal Verification

**arXiv**: [2512.14170v1](https://arxiv.org/abs/2512.14170) | [PDF](https://arxiv.org/pdf/2512.14170.pdf)

**ä½œè€…**: Jonathan Spiegelman, Guy Amir, Guy Katz

**åˆ†ç±»**: cs.LG, cs.LO

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ©ç”¨å½¢å¼åŒ–éªŒè¯å¯¹æŠ—æ ·æœ¬å¢žå¼ºæ·±åº¦ä¸»åŠ¨å­¦ä¹ ï¼Œæå‡æ¨¡åž‹æ³›åŒ–èƒ½åŠ›**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **åŠ¨ä½œç”Ÿæˆä¸Žç‰©ç†åŠ¨ç”» (Animation & Physics)** **3Dæ„ŸçŸ¥ä¸ŽçŠ¶æ€ä¼°è®¡ (Perception & State Est)**

**å…³é”®è¯**: `æ·±åº¦ä¸»åŠ¨å­¦ä¹ ` `å½¢å¼åŒ–éªŒè¯` `å¯¹æŠ—æ ·æœ¬` `é²æ£’æ€§` `æ¨¡åž‹æ³›åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ·±åº¦ä¸»åŠ¨å­¦ä¹ é¢ä¸´æ ‡æ³¨æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ï¼Œéœ€è¦é«˜æ•ˆé€‰æ‹©ä¿¡æ¯é‡å¤§çš„æ ·æœ¬ã€‚
2. è®ºæ–‡æå‡ºåˆ©ç”¨å½¢å¼åŒ–éªŒè¯ç”Ÿæˆçš„å¯¹æŠ—æ ·æœ¬å¢žå¼ºè®­ç»ƒæ•°æ®ï¼Œæå‡æ¨¡åž‹é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡äº†çŽ°æœ‰æ·±åº¦ä¸»åŠ¨å­¦ä¹ æŠ€æœ¯çš„æ€§èƒ½ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ·±åº¦ä¸»åŠ¨å­¦ä¹ (DAL)æ—¨åœ¨é€šè¿‡ä¼˜å…ˆæ ‡æ³¨ä¿¡æ¯é‡æœ€å¤§çš„æœªæ ‡æ³¨æ ·æœ¬ï¼Œæ¥é™ä½Žç¥žç»ç½‘ç»œè®­ç»ƒä¸­çš„æ ‡æ³¨æˆæœ¬ã€‚é™¤äº†é€‰æ‹©è¦æ ‡æ³¨çš„æ ·æœ¬å¤–ï¼Œä¸€äº›DALæ–¹æ³•è¿˜é€šè¿‡ä½¿ç”¨ä¸éœ€è¦é¢å¤–æ‰‹åŠ¨æ ‡æ³¨çš„åˆæˆè¾“å…¥æ¥å¢žå¼ºè®­ç»ƒé›†ï¼Œä»Žè€Œè¿›ä¸€æ­¥æé«˜æ•°æ®æ•ˆçŽ‡ã€‚æœ¬æ–‡ç ”ç©¶äº†å¦‚ä½•é€šè¿‡ä½¿ç”¨è¿åé²æ£’æ€§çº¦æŸçš„å¯¹æŠ—æ€§è¾“å…¥æ¥å¢žå¼ºè®­ç»ƒæ•°æ®ï¼Œä»Žè€Œæé«˜DALæ€§èƒ½ã€‚æˆ‘ä»¬è¡¨æ˜Žï¼Œé€šè¿‡å½¢å¼åŒ–éªŒè¯ç”Ÿæˆçš„å¯¹æŠ—æ ·æœ¬æ¯”é€šè¿‡æ ‡å‡†ã€åŸºäºŽæ¢¯åº¦çš„æ”»å‡»äº§ç”Ÿçš„å¯¹æŠ—æ ·æœ¬è´¡çŒ®æ›´å¤§ã€‚æˆ‘ä»¬å°†æ­¤æ‰©å±•åº”ç”¨äºŽå¤šç§çŽ°ä»£DALæŠ€æœ¯ï¼Œä»¥åŠæˆ‘ä»¬æå‡ºçš„ä¸€ç§æ–°æŠ€æœ¯ï¼Œå¹¶è¡¨æ˜Žå®ƒåœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æé«˜äº†æ¨¡åž‹æ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæ·±åº¦ä¸»åŠ¨å­¦ä¹ æ—¨åœ¨å‡å°‘ç¥žç»ç½‘ç»œè®­ç»ƒæ‰€éœ€çš„äººå·¥æ ‡æ³¨æ•°æ®é‡ã€‚çŽ°æœ‰çš„æ·±åº¦ä¸»åŠ¨å­¦ä¹ æ–¹æ³•åœ¨é€‰æ‹©æœ€å…·ä¿¡æ¯é‡çš„æ ·æœ¬è¿›è¡Œæ ‡æ³¨ä¹‹å¤–ï¼Œé€šå¸¸ä¼šé‡‡ç”¨æ•°æ®å¢žå¼ºæŠ€æœ¯æ¥æå‡æ¨¡åž‹æ€§èƒ½ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿçš„åŸºäºŽæ¢¯åº¦çš„æ–¹æ³•ç”Ÿæˆçš„å¯¹æŠ—æ ·æœ¬åœ¨æå‡æ¨¡åž‹é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›æ–¹é¢æ•ˆæžœæœ‰é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å½¢å¼åŒ–éªŒè¯æŠ€æœ¯ç”Ÿæˆæ›´æœ‰æ•ˆçš„å¯¹æŠ—æ ·æœ¬ï¼Œå¹¶å°†å…¶ä½œä¸ºå¢žå¼ºæ•°æ®åŠ å…¥è®­ç»ƒé›†ã€‚å½¢å¼åŒ–éªŒè¯èƒ½å¤Ÿä¿è¯ç”Ÿæˆçš„å¯¹æŠ—æ ·æœ¬ç¡®å®žè¿åäº†æ¨¡åž‹çš„é²æ£’æ€§çº¦æŸï¼Œä»Žè€Œè¿«ä½¿æ¨¡åž‹å­¦ä¹ æ›´é²æ£’çš„ç‰¹å¾è¡¨ç¤ºã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šè¯¥æ–¹æ³•é¦–å…ˆä½¿ç”¨çŽ°æœ‰çš„æ·±åº¦ä¸»åŠ¨å­¦ä¹ ç­–ç•¥é€‰æ‹©ä¸€æ‰¹æœªæ ‡æ³¨æ ·æœ¬ã€‚ç„¶åŽï¼Œå¯¹äºŽé€‰å®šçš„æ ·æœ¬ï¼Œä½¿ç”¨å½¢å¼åŒ–éªŒè¯æŠ€æœ¯ç”Ÿæˆå¯¹æŠ—æ ·æœ¬ã€‚è¿™äº›å¯¹æŠ—æ ·æœ¬ä¸ŽåŽŸå§‹æ ‡æ³¨æ•°æ®ä¸€èµ·ç”¨äºŽè®­ç»ƒç¥žç»ç½‘ç»œã€‚è¯¥è¿‡ç¨‹å¯ä»¥è¿­ä»£è¿›è¡Œï¼Œä¸æ–­é€‰æ‹©æ–°çš„æ ·æœ¬å¹¶ç”Ÿæˆå¯¹æŠ—æ ·æœ¬ï¼Œä»¥é€æ­¥æé«˜æ¨¡åž‹æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºŽä½¿ç”¨å½¢å¼åŒ–éªŒè¯ç”Ÿæˆå¯¹æŠ—æ ·æœ¬ã€‚ä¸Žä¼ ç»Ÿçš„åŸºäºŽæ¢¯åº¦çš„æ–¹æ³•ç›¸æ¯”ï¼Œå½¢å¼åŒ–éªŒè¯èƒ½å¤Ÿæä¾›æ›´å¼ºçš„é²æ£’æ€§ä¿è¯ï¼Œç”Ÿæˆçš„å¯¹æŠ—æ ·æœ¬æ›´å…·æŒ‘æˆ˜æ€§ï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°æå‡æ¨¡åž‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬é€‰æ‹©åˆé€‚çš„æ·±åº¦ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ã€å½¢å¼åŒ–éªŒè¯å·¥å…·ä»¥åŠå¯¹æŠ—æ ·æœ¬çš„ç”Ÿæˆæ–¹å¼ã€‚å…·ä½“æ¥è¯´ï¼Œå¯ä»¥ä½¿ç”¨ä¸åŒçš„å½¢å¼åŒ–éªŒè¯æ–¹æ³•ï¼Œä¾‹å¦‚åŸºäºŽSMTæ±‚è§£å™¨çš„æ–¹æ³•æˆ–åŸºäºŽæŠ½è±¡è§£é‡Šçš„æ–¹æ³•ã€‚æ­¤å¤–ï¼Œè¿˜éœ€è¦ä»”ç»†è°ƒæ•´å½¢å¼åŒ–éªŒè¯çš„å‚æ•°ï¼Œä»¥ç¡®ä¿ç”Ÿæˆçš„å¯¹æŠ—æ ·æœ¬æ—¢å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œåˆä¸ä¼šè¿‡äºŽåç¦»åŽŸå§‹æ•°æ®åˆ†å¸ƒã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼Œä½¿ç”¨å½¢å¼åŒ–éªŒè¯ç”Ÿæˆçš„å¯¹æŠ—æ ·æœ¬èƒ½å¤Ÿæ˜¾è‘—æå‡çŽ°æœ‰æ·±åº¦ä¸»åŠ¨å­¦ä¹ æŠ€æœ¯çš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨å¤šä¸ªæ ‡å‡†å›¾åƒåˆ†ç±»æ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿå°†æ¨¡åž‹çš„å‡†ç¡®çŽ‡æé«˜å‡ ä¸ªç™¾åˆ†ç‚¹ï¼Œå¹¶ä¸”ä¼˜äºŽä½¿ç”¨åŸºäºŽæ¢¯åº¦çš„æ–¹æ³•ç”Ÿæˆçš„å¯¹æŠ—æ ·æœ¬ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽå›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰é¢†åŸŸï¼Œå°¤å…¶æ˜¯åœ¨æ ‡æ³¨æ•°æ®æœ‰é™çš„æƒ…å†µä¸‹ã€‚é€šè¿‡åˆ©ç”¨å½¢å¼åŒ–éªŒè¯ç”Ÿæˆçš„å¯¹æŠ—æ ·æœ¬å¢žå¼ºè®­ç»ƒæ•°æ®ï¼Œå¯ä»¥æ˜¾è‘—æé«˜æ¨¡åž‹çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ï¼Œé™ä½Žäººå·¥æ ‡æ³¨æˆæœ¬ï¼Œå…·æœ‰é‡è¦çš„å®žé™…åº”ç”¨ä»·å€¼å’Œæ½œåŠ›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Deep Active Learning (DAL) aims to reduce labeling costs in neural-network training by prioritizing the most informative unlabeled samples for annotation. Beyond selecting which samples to label, several DAL approaches further enhance data efficiency by augmenting the training set with synthetic inputs that do not require additional manual labeling. In this work, we investigate how augmenting the training data with adversarial inputs that violate robustness constraints can improve DAL performance. We show that adversarial examples generated via formal verification contribute substantially more than those produced by standard, gradient-based attacks. We apply this extension to multiple modern DAL techniques, as well as to a new technique that we propose, and show that it yields significant improvements in model generalization across standard benchmarks.

