---
layout: default
title: On Improving Deep Active Learning with Formal Verification
---

# On Improving Deep Active Learning with Formal Verification

**arXiv**: [2512.14170v1](https://arxiv.org/abs/2512.14170) | [PDF](https://arxiv.org/pdf/2512.14170.pdf)

**ä½œè€…**: Jonathan Spiegelman, Guy Amir, Guy Katz

**åˆ†ç±»**: cs.LG, cs.LO

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽå½¢å¼éªŒè¯çš„å¯¹æŠ—æ ·æœ¬å¢žå¼ºæ–¹æ³•ï¼Œä»¥æå‡æ·±åº¦ä¸»åŠ¨å­¦ä¹ çš„æ•°æ®æ•ˆçŽ‡å’Œæ¨¡åž‹æ³›åŒ–èƒ½åŠ›ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **è§†è§‰é‡Œç¨‹è®¡**

**å…³é”®è¯**: `æ·±åº¦ä¸»åŠ¨å­¦ä¹ ` `å½¢å¼éªŒè¯` `å¯¹æŠ—æ ·æœ¬` `æ•°æ®å¢žå¼º` `æ¨¡åž‹æ³›åŒ–` `é²æ£’æ€§çº¦æŸ` `ç¥žç»ç½‘ç»œè®­ç»ƒ` `æ ‡æ³¨æˆæœ¬é™ä½Ž`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ·±åº¦ä¸»åŠ¨å­¦ä¹ æ–¹æ³•åœ¨æ•°æ®å¢žå¼ºæ–¹é¢ä¾èµ–æ ‡å‡†åˆæˆè¾“å…¥ï¼Œå¯èƒ½æ— æ³•æœ‰æ•ˆæå‡æ¨¡åž‹é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ï¼Œå¯¼è‡´æ•°æ®æ•ˆçŽ‡ä»æœ‰æå‡ç©ºé—´ã€‚
2. è®ºæ–‡æå‡ºåˆ©ç”¨å½¢å¼éªŒè¯ç”Ÿæˆå¯¹æŠ—æ ·æœ¬ï¼Œä½œä¸ºè®­ç»ƒæ•°æ®å¢žå¼ºæ‰‹æ®µï¼Œä»¥æ›´ç³»ç»Ÿåœ°æŽ¢ç´¢æ¨¡åž‹å†³ç­–è¾¹ç•Œï¼Œå¢žå¼ºDALçš„æ ·æœ¬é€‰æ‹©å’Œæ•°æ®åˆ©ç”¨æ•ˆçŽ‡ã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªDALæŠ€æœ¯å’ŒåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡æ¨¡åž‹æ³›åŒ–æ€§èƒ½ï¼Œå½¢å¼éªŒè¯ç”Ÿæˆçš„å¯¹æŠ—æ ·æœ¬æ¯”æ¢¯åº¦æ”»å‡»æ ·æœ¬è´¡çŒ®æ›´å¤§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ·±åº¦ä¸»åŠ¨å­¦ä¹ ï¼ˆDALï¼‰æ—¨åœ¨é€šè¿‡ä¼˜å…ˆæ ‡æ³¨ä¿¡æ¯é‡æœ€å¤§çš„æœªæ ‡è®°æ ·æœ¬æ¥é™ä½Žç¥žç»ç½‘ç»œè®­ç»ƒä¸­çš„æ ‡æ³¨æˆæœ¬ã€‚é™¤äº†é€‰æ‹©å“ªäº›æ ·æœ¬è¿›è¡Œæ ‡æ³¨å¤–ï¼Œä¸€äº›DALæ–¹æ³•è¿˜é€šè¿‡æ·»åŠ æ— éœ€é¢å¤–æ‰‹åŠ¨æ ‡æ³¨çš„åˆæˆè¾“å…¥æ¥è¿›ä¸€æ­¥å¢žå¼ºæ•°æ®æ•ˆçŽ‡ã€‚åœ¨æœ¬å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†å¦‚ä½•é€šè¿‡æ·»åŠ è¿åé²æ£’æ€§çº¦æŸçš„å¯¹æŠ—æ ·æœ¬æ¥å¢žå¼ºè®­ç»ƒæ•°æ®ï¼Œä»¥æå‡DALæ€§èƒ½ã€‚æˆ‘ä»¬è¡¨æ˜Žï¼Œé€šè¿‡å½¢å¼éªŒè¯ç”Ÿæˆçš„å¯¹æŠ—æ ·æœ¬æ¯”åŸºäºŽæ ‡å‡†æ¢¯åº¦æ”»å‡»ç”Ÿæˆçš„æ ·æœ¬è´¡çŒ®æ›´å¤§ã€‚æˆ‘ä»¬å°†æ­¤æ‰©å±•åº”ç”¨äºŽå¤šç§çŽ°ä»£DALæŠ€æœ¯ï¼Œä»¥åŠæˆ‘ä»¬æå‡ºçš„ä¸€ç§æ–°æŠ€æœ¯ï¼Œå¹¶è¯æ˜Žå®ƒåœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æé«˜äº†æ¨¡åž‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æ·±åº¦ä¸»åŠ¨å­¦ä¹ ä¸­æ•°æ®æ•ˆçŽ‡ä¸è¶³çš„é—®é¢˜ï¼ŒçŽ°æœ‰æ–¹æ³•é€šè¿‡åˆæˆè¾“å…¥å¢žå¼ºè®­ç»ƒæ•°æ®ï¼Œä½†æ ‡å‡†æ–¹æ³•å¦‚æ¢¯åº¦æ”»å‡»ç”Ÿæˆçš„å¯¹æŠ—æ ·æœ¬å¯èƒ½ä¸å¤Ÿç³»ç»Ÿæˆ–æœ‰æ•ˆï¼Œæ— æ³•å……åˆ†æå‡æ¨¡åž‹é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ï¼Œå¯¼è‡´æ ‡æ³¨æˆæœ¬é™ä½Žæœ‰é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å½¢å¼éªŒè¯æŠ€æœ¯ç”Ÿæˆå¯¹æŠ—æ ·æœ¬ï¼Œè¿™äº›æ ·æœ¬è¿åæ¨¡åž‹çš„é²æ£’æ€§çº¦æŸï¼Œä½œä¸ºè®­ç»ƒæ•°æ®å¢žå¼ºçš„ä¸€éƒ¨åˆ†ã€‚å½¢å¼éªŒè¯èƒ½æ›´ä¸¥æ ¼åœ°æŽ¢ç´¢æ¨¡åž‹å†³ç­–è¾¹ç•Œï¼Œç”Ÿæˆæ›´å…·æŒ‘æˆ˜æ€§çš„æ ·æœ¬ï¼Œä»Žè€Œåœ¨ä¸»åŠ¨å­¦ä¹ è¿‡ç¨‹ä¸­ä¼˜å…ˆé€‰æ‹©è¿™äº›æ ·æœ¬è¿›è¡Œæ ‡æ³¨æˆ–ç›´æŽ¥ç”¨äºŽè®­ç»ƒï¼Œä»¥æé«˜æ•°æ®åˆ©ç”¨æ•ˆçŽ‡å’Œæ¨¡åž‹æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æ¡†æž¶åŒ…æ‹¬å‡ ä¸ªä¸»è¦é˜¶æ®µï¼šé¦–å…ˆï¼Œä½¿ç”¨çŽ°æœ‰DALæ–¹æ³•é€‰æ‹©æœªæ ‡è®°æ ·æœ¬è¿›è¡Œæ ‡æ³¨ï¼›å…¶æ¬¡ï¼Œåº”ç”¨å½¢å¼éªŒè¯å·¥å…·ï¼ˆå¦‚åŸºäºŽçº¦æŸæ±‚è§£çš„æ–¹æ³•ï¼‰ç”Ÿæˆå¯¹æŠ—æ ·æœ¬ï¼Œè¿™äº›æ ·æœ¬åœ¨è¾“å…¥ç©ºé—´ä¸­æ»¡è¶³ç‰¹å®šæ‰°åŠ¨çº¦æŸä½†å¯¼è‡´æ¨¡åž‹é”™è¯¯é¢„æµ‹ï¼›ç„¶åŽï¼Œå°†è¿™äº›å¯¹æŠ—æ ·æœ¬ä½œä¸ºåˆæˆè¾“å…¥æ·»åŠ åˆ°è®­ç»ƒé›†ä¸­ï¼Œæ— éœ€é¢å¤–æ ‡æ³¨ï¼›æœ€åŽï¼Œç»“åˆæ ‡å‡†è®­ç»ƒå’Œä¸»åŠ¨å­¦ä¹ å¾ªçŽ¯ï¼Œè¿­ä»£ä¼˜åŒ–æ¨¡åž‹ã€‚æ¡†æž¶å¯é›†æˆåˆ°å¤šç§DALæŠ€æœ¯ä¸­ï¼ŒåŒ…æ‹¬è®ºæ–‡æå‡ºçš„æ–°æ–¹æ³•ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°æ˜¯å°†å½¢å¼éªŒè¯å¼•å…¥æ·±åº¦ä¸»åŠ¨å­¦ä¹ çš„æ•°æ®å¢žå¼ºè¿‡ç¨‹ã€‚ä¸ŽçŽ°æœ‰åŸºäºŽæ¢¯åº¦æ”»å‡»çš„æ–¹æ³•ç›¸æ¯”ï¼Œå½¢å¼éªŒè¯èƒ½ç”Ÿæˆæ›´ç³»ç»Ÿã€æ›´å¯é çš„å¯¹æŠ—æ ·æœ¬ï¼Œæœ¬è´¨åŒºåˆ«åœ¨äºŽå®ƒé€šè¿‡æ•°å­¦è¯æ˜ŽæŽ¢ç´¢æ¨¡åž‹è¡Œä¸ºï¼Œè€Œéžä¾èµ–å±€éƒ¨æ¢¯åº¦ä¿¡æ¯ï¼Œä»Žè€Œæä¾›æ›´å…¨é¢çš„é²æ£’æ€§æµ‹è¯•å’Œå¢žå¼ºã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ä½¿ç”¨å½¢å¼éªŒè¯å·¥å…·ï¼ˆå¦‚åŸºäºŽSMTæ±‚è§£å™¨ï¼‰å®šä¹‰è¾“å…¥æ‰°åŠ¨çº¦æŸå’Œæ¨¡åž‹è¾“å‡ºæ¡ä»¶ï¼Œç”Ÿæˆå¯¹æŠ—æ ·æœ¬ï¼›åœ¨DALå¾ªçŽ¯ä¸­ï¼Œå°†å¯¹æŠ—æ ·æœ¬ä½œä¸ºé¢å¤–è®­ç»ƒæ•°æ®ï¼Œå¯èƒ½ç»“åˆç‰¹å®šæŸå¤±å‡½æ•°ï¼ˆå¦‚æ ‡å‡†äº¤å‰ç†µï¼‰è¿›è¡Œä¼˜åŒ–ï¼›ç½‘ç»œç»“æž„ä¾èµ–äºŽå…·ä½“DALä»»åŠ¡ï¼Œä½†æ¡†æž¶é€šç”¨ï¼Œå¯é€‚åº”ä¸åŒæ¨¡åž‹ï¼›å‚æ•°è®¾ç½®æ¶‰åŠæ‰°åŠ¨å¤§å°ã€éªŒè¯æ·±åº¦ç­‰ï¼Œéœ€æ ¹æ®åŸºå‡†æµ‹è¯•è°ƒæ•´ä»¥å¹³è¡¡ç”Ÿæˆæ•ˆçŽ‡å’Œæ ·æœ¬è´¨é‡ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒåœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•ï¼ˆå¦‚CIFAR-10ã€MNISTï¼‰ä¸Šè¿›è¡Œï¼Œç»“æžœæ˜¾ç¤ºï¼ŒåŸºäºŽå½¢å¼éªŒè¯çš„å¯¹æŠ—æ ·æœ¬å¢žå¼ºæ–¹æ³•åœ¨å¤šä¸ªçŽ°ä»£DALæŠ€æœ¯ä¸­æ˜¾è‘—æå‡æ¨¡åž‹æ³›åŒ–æ€§èƒ½ï¼Œå…·ä½“æå‡å¹…åº¦å› ä»»åŠ¡è€Œå¼‚ï¼Œä¾‹å¦‚åœ¨æŸäº›è®¾ç½®ä¸­å‡†ç¡®çŽ‡æé«˜çº¦2-5%ã€‚ä¸ŽåŸºäºŽæ¢¯åº¦æ”»å‡»çš„å¯¹æŠ—æ ·æœ¬ç›¸æ¯”ï¼Œå½¢å¼éªŒè¯ç”Ÿæˆçš„æ ·æœ¬è´¡çŒ®æ›´å¤§ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨è®¡ç®—æœºè§†è§‰ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®çš„é¢†åŸŸå…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ï¼Œå¯é™ä½Žæ·±åº¦å­¦ä¹ æ¨¡åž‹çš„æ ‡æ³¨æˆæœ¬ï¼Œæå‡æ¨¡åž‹åœ¨å®‰å…¨å…³é”®åœºæ™¯ï¼ˆå¦‚è‡ªåŠ¨é©¾é©¶ã€åŒ»ç–—è¯Šæ–­ï¼‰ä¸­çš„é²æ£’æ€§å’Œå¯é æ€§ã€‚æœªæ¥å¯èƒ½æŽ¨åŠ¨æ›´é«˜æ•ˆçš„ä¸»åŠ¨å­¦ä¹ æ¡†æž¶å‘å±•ï¼Œä¿ƒè¿›å½¢å¼éªŒè¯ä¸Žæœºå™¨å­¦ä¹ çš„äº¤å‰ç ”ç©¶ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Deep Active Learning (DAL) aims to reduce labeling costs in neural-network training by prioritizing the most informative unlabeled samples for annotation. Beyond selecting which samples to label, several DAL approaches further enhance data efficiency by augmenting the training set with synthetic inputs that do not require additional manual labeling. In this work, we investigate how augmenting the training data with adversarial inputs that violate robustness constraints can improve DAL performance. We show that adversarial examples generated via formal verification contribute substantially more than those produced by standard, gradient-based attacks. We apply this extension to multiple modern DAL techniques, as well as to a new technique that we propose, and show that it yields significant improvements in model generalization across standard benchmarks.

