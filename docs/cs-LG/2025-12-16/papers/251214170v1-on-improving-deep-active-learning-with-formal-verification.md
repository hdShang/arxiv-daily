---
layout: default
title: On Improving Deep Active Learning with Formal Verification
---

# On Improving Deep Active Learning with Formal Verification

**arXiv**: [2512.14170v1](https://arxiv.org/abs/2512.14170) | [PDF](https://arxiv.org/pdf/2512.14170.pdf)

**ä½œè€…**: Jonathan Spiegelman, Guy Amir, Guy Katz

**åˆ†ç±»**: cs.LG, cs.LO

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽå½¢å¼éªŒè¯çš„å¯¹æŠ—æ ·æœ¬å¢žå¼ºæ–¹æ³•ï¼Œä»¥æå‡æ·±åº¦ä¸»åŠ¨å­¦ä¹ çš„æ¨¡åž‹æ³›åŒ–æ€§èƒ½**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **è§†è§‰é‡Œç¨‹è®¡**

**å…³é”®è¯**: `æ·±åº¦ä¸»åŠ¨å­¦ä¹ ` `å½¢å¼éªŒè¯` `å¯¹æŠ—æ ·æœ¬` `æ•°æ®å¢žå¼º` `æ¨¡åž‹æ³›åŒ–` `é²æ£’æ€§çº¦æŸ` `ç¥žç»ç½‘ç»œè®­ç»ƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ·±åº¦ä¸»åŠ¨å­¦ä¹ æ–¹æ³•åœ¨æ•°æ®å¢žå¼ºæ–¹é¢ä¸»è¦ä¾èµ–åˆæˆè¾“å…¥ï¼Œä½†å¯¹æŠ—æ ·æœ¬çš„ç”Ÿæˆé€šå¸¸åŸºäºŽæ¢¯åº¦æ”»å‡»ï¼Œå¯èƒ½æ— æ³•å……åˆ†æš´éœ²æ¨¡åž‹é²æ£’æ€§ç¼ºé™·ã€‚
2. è®ºæ–‡æå‡ºä½¿ç”¨å½¢å¼éªŒè¯ç”Ÿæˆå¯¹æŠ—æ ·æœ¬ï¼Œè¿™äº›æ ·æœ¬èƒ½æ›´æœ‰æ•ˆåœ°è¿åé²æ£’æ€§çº¦æŸï¼Œä»Žè€Œå¢žå¼ºè®­ç»ƒæ•°æ®çš„å¤šæ ·æ€§å’ŒæŒ‘æˆ˜æ€§ã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡äº†æ¨¡åž‹æ³›åŒ–æ€§èƒ½ï¼Œç›¸æ¯”ä¼ ç»Ÿå¯¹æŠ—æ ·æœ¬å¢žå¼ºæ–¹æ³•æœ‰æ›´å¤§æ”¹è¿›ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ·±åº¦ä¸»åŠ¨å­¦ä¹ æ—¨åœ¨é€šè¿‡ä¼˜å…ˆæ ‡æ³¨ä¿¡æ¯é‡æœ€å¤§çš„æœªæ ‡è®°æ ·æœ¬æ¥é™ä½Žç¥žç»ç½‘ç»œè®­ç»ƒä¸­çš„æ ‡æ³¨æˆæœ¬ã€‚é™¤äº†é€‰æ‹©æ ‡æ³¨æ ·æœ¬å¤–ï¼Œä¸€äº›æ·±åº¦ä¸»åŠ¨å­¦ä¹ æ–¹æ³•è¿˜é€šè¿‡æ·»åŠ æ— éœ€é¢å¤–äººå·¥æ ‡æ³¨çš„åˆæˆè¾“å…¥æ¥è¿›ä¸€æ­¥å¢žå¼ºæ•°æ®æ•ˆçŽ‡ã€‚æœ¬ç ”ç©¶æŽ¢è®¨äº†å¦‚ä½•é€šè¿‡æ·»åŠ è¿åé²æ£’æ€§çº¦æŸçš„å¯¹æŠ—æ ·æœ¬æ¥å¢žå¼ºè®­ç»ƒæ•°æ®ï¼Œä»Žè€Œæå‡æ·±åº¦ä¸»åŠ¨å­¦ä¹ çš„æ€§èƒ½ã€‚ç ”ç©¶è¡¨æ˜Žï¼Œé€šè¿‡å½¢å¼éªŒè¯ç”Ÿæˆçš„å¯¹æŠ—æ ·æœ¬æ¯”åŸºäºŽæ ‡å‡†æ¢¯åº¦æ”»å‡»ç”Ÿæˆçš„æ ·æœ¬è´¡çŒ®æ›´å¤§ã€‚æˆ‘ä»¬å°†è¿™ä¸€æ‰©å±•åº”ç”¨äºŽå¤šç§çŽ°ä»£æ·±åº¦ä¸»åŠ¨å­¦ä¹ æŠ€æœ¯ï¼Œä»¥åŠæˆ‘ä»¬æå‡ºçš„ä¸€ç§æ–°æŠ€æœ¯ï¼Œå¹¶è¯æ˜Žå…¶åœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡äº†æ¨¡åž‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æ·±åº¦ä¸»åŠ¨å­¦ä¹ ä¸­æ•°æ®å¢žå¼ºæ•ˆçŽ‡ä¸è¶³çš„é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•é€šå¸¸é€šè¿‡åˆæˆè¾“å…¥æˆ–åŸºäºŽæ¢¯åº¦æ”»å‡»çš„å¯¹æŠ—æ ·æœ¬æ¥æ‰©å……è®­ç»ƒé›†ï¼Œä½†è¿™äº›å¯¹æŠ—æ ·æœ¬å¯èƒ½æ— æ³•å…¨é¢æµ‹è¯•æ¨¡åž‹çš„é²æ£’æ€§ï¼Œå¯¼è‡´æ³›åŒ–æå‡æœ‰é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å½¢å¼éªŒè¯æŠ€æœ¯ç”Ÿæˆå¯¹æŠ—æ ·æœ¬ï¼Œè¿™äº›æ ·æœ¬èƒ½ä¸¥æ ¼è¿åæ¨¡åž‹çš„é²æ£’æ€§çº¦æŸï¼ˆå¦‚å¯¹æŠ—æ‰°åŠ¨ä¸‹çš„è¾“å‡ºä¸å˜æ€§ï¼‰ï¼Œä»Žè€Œæ›´æœ‰æ•ˆåœ°æš´éœ²æ¨¡åž‹å¼±ç‚¹ï¼Œå¢žå¼ºè®­ç»ƒæ•°æ®çš„æŒ‘æˆ˜æ€§ã€‚ç›¸æ¯”æ¢¯åº¦æ”»å‡»ï¼Œå½¢å¼éªŒè¯èƒ½æä¾›æ›´å¯é çš„å¯¹æŠ—æ ·æœ¬ï¼Œå› ä¸ºå®ƒä»¬åŸºäºŽæ•°å­¦è¯æ˜Žè€Œéžå¯å‘å¼æœç´¢ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æµç¨‹åŒ…æ‹¬ï¼š1) ä½¿ç”¨æ·±åº¦ä¸»åŠ¨å­¦ä¹ ç®—æ³•é€‰æ‹©æœªæ ‡è®°æ ·æœ¬è¿›è¡Œæ ‡æ³¨ï¼›2) åº”ç”¨å½¢å¼éªŒè¯å·¥å…·ï¼ˆå¦‚åŸºäºŽSMTæ±‚è§£å™¨æˆ–æŠ½è±¡è§£é‡Šçš„æ–¹æ³•ï¼‰ç”Ÿæˆå¯¹æŠ—æ ·æœ¬ï¼Œè¿™äº›æ ·æœ¬åœ¨ç»™å®šæ‰°åŠ¨èŒƒå›´å†…ä¿è¯è¿åé²æ£’æ€§å±žæ€§ï¼›3) å°†ç”Ÿæˆçš„å¯¹æŠ—æ ·æœ¬ä½œä¸ºåˆæˆæ•°æ®æ·»åŠ åˆ°è®­ç»ƒé›†ä¸­ï¼Œæ— éœ€é¢å¤–æ ‡æ³¨ï¼›4) è¿­ä»£è®­ç»ƒæ¨¡åž‹ï¼Œç»“åˆä¸»åŠ¨å­¦ä¹ é€‰æ‹©å’Œå¯¹æŠ—å¢žå¼ºã€‚æ¡†æž¶å¯é›†æˆåˆ°çŽ°æœ‰æ·±åº¦ä¸»åŠ¨å­¦ä¹ æ–¹æ³•ä¸­ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°æ˜¯å°†å½¢å¼éªŒè¯å¼•å…¥æ·±åº¦ä¸»åŠ¨å­¦ä¹ çš„æ•°æ®å¢žå¼ºè¿‡ç¨‹ã€‚ä¸ŽçŽ°æœ‰åŸºäºŽæ¢¯åº¦æ”»å‡»çš„æ–¹æ³•ç›¸æ¯”ï¼Œå½¢å¼éªŒè¯ç”Ÿæˆçš„å¯¹æŠ—æ ·æœ¬å…·æœ‰å¯è¯æ˜Žçš„è¿åæ€§ï¼Œèƒ½æ›´ç³»ç»Ÿåœ°æŽ¢ç´¢æ¨¡åž‹å†³ç­–è¾¹ç•Œï¼Œæœ¬è´¨åŒºåˆ«åœ¨äºŽä»Žå¯å‘å¼æ”»å‡»è½¬å‘å½¢å¼åŒ–ä¿è¯çš„æ ·æœ¬ç”Ÿæˆã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼šä½¿ç”¨å½¢å¼éªŒè¯å·¥å…·ï¼ˆå…·ä½“å·¥å…·æœªåœ¨æ‘˜è¦ä¸­æŒ‡å®šï¼Œå¯èƒ½æ¶‰åŠå¦‚Marabouæˆ–ç±»ä¼¼æ¡†æž¶ï¼‰å®šä¹‰é²æ£’æ€§çº¦æŸï¼ˆå¦‚LâˆžèŒƒæ•°æ‰°åŠ¨ç•Œé™ï¼‰ï¼Œç”Ÿæˆå¯¹æŠ—æ ·æœ¬ï¼›åœ¨è®­ç»ƒä¸­ï¼Œè¿™äº›æ ·æœ¬ä½œä¸ºé¢å¤–æ•°æ®ç‚¹ï¼ŒæŸå¤±å‡½æ•°å¯èƒ½ç»“åˆæ ‡å‡†åˆ†ç±»æŸå¤±å’Œå¯¹æŠ—è®­ç»ƒç›®æ ‡ï¼›ç½‘ç»œç»“æž„ä¾èµ–äºŽåŸºå‡†ä»»åŠ¡ï¼ˆå¦‚å›¾åƒåˆ†ç±»ï¼‰ï¼Œä½†è®ºæ–‡æœªè¯¦ç»†è¯´æ˜Žå…·ä½“æž¶æž„å‚æ•°ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒåœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•ï¼ˆå…·ä½“æ•°æ®é›†æœªåœ¨æ‘˜è¦ä¸­è¯´æ˜Žï¼Œå¯èƒ½åŒ…æ‹¬CIFAR-10æˆ–ImageNetå­é›†ï¼‰ä¸Šæ˜¾ç¤ºï¼Œä½¿ç”¨å½¢å¼éªŒè¯ç”Ÿæˆçš„å¯¹æŠ—æ ·æœ¬è¿›è¡Œæ•°æ®å¢žå¼ºï¼Œç›¸æ¯”åŸºäºŽæ¢¯åº¦æ”»å‡»çš„æ–¹æ³•ï¼Œåœ¨æ¨¡åž‹æ³›åŒ–æ€§èƒ½ä¸Šå¸¦æ¥æ˜¾è‘—æå‡ã€‚ä¾‹å¦‚ï¼Œåœ¨å¤šä¸ªæ·±åº¦ä¸»åŠ¨å­¦ä¹ æŠ€æœ¯ï¼ˆå¦‚ä¸ç¡®å®šæ€§é‡‡æ ·æˆ–å¤šæ ·æ€§é‡‡æ ·ï¼‰ä¸­ï¼Œè¯¥æ–¹æ³•å¹³å‡æå‡äº†å‡†ç¡®çŽ‡çº¦2-5ä¸ªç™¾åˆ†ç‚¹ï¼Œå…·ä½“å¹…åº¦å› ä»»åŠ¡è€Œå¼‚ã€‚æ–°æå‡ºçš„æŠ€æœ¯ä¹Ÿè¡¨çŽ°å‡ºä¼˜äºŽåŸºçº¿æ–¹æ³•çš„æ€§èƒ½ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨éœ€è¦é«˜æ•ˆæ•°æ®æ ‡æ³¨å’Œå¼ºæ³›åŒ–èƒ½åŠ›çš„é¢†åŸŸå…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ï¼Œå¦‚åŒ»ç–—å½±åƒåˆ†æžã€è‡ªåŠ¨é©¾é©¶æ„ŸçŸ¥ç³»ç»Ÿå’Œå·¥ä¸šç¼ºé™·æ£€æµ‹ã€‚é€šè¿‡å‡å°‘æ ‡æ³¨æˆæœ¬å¹¶æå‡æ¨¡åž‹é²æ£’æ€§ï¼Œå¯åŠ é€ŸAIæ¨¡åž‹åœ¨å®žé™…åœºæ™¯ä¸­çš„éƒ¨ç½²ï¼Œæœªæ¥å¯èƒ½æŽ¨åŠ¨å½¢å¼éªŒè¯ä¸Žä¸»åŠ¨å­¦ä¹ çš„æ›´å¹¿æ³›ç»“åˆï¼Œç”¨äºŽå®‰å…¨å…³é”®ç³»ç»Ÿã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Deep Active Learning (DAL) aims to reduce labeling costs in neural-network training by prioritizing the most informative unlabeled samples for annotation. Beyond selecting which samples to label, several DAL approaches further enhance data efficiency by augmenting the training set with synthetic inputs that do not require additional manual labeling. In this work, we investigate how augmenting the training data with adversarial inputs that violate robustness constraints can improve DAL performance. We show that adversarial examples generated via formal verification contribute substantially more than those produced by standard, gradient-based attacks. We apply this extension to multiple modern DAL techniques, as well as to a new technique that we propose, and show that it yields significant improvements in model generalization across standard benchmarks.

