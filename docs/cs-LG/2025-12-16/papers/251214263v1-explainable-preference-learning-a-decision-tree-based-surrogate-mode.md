---
layout: default
title: Explainable Preference Learning: a Decision Tree-based Surrogate Model for Preferential Bayesian Optimization
---

# Explainable Preference Learning: a Decision Tree-based Surrogate Model for Preferential Bayesian Optimization

**arXiv**: [2512.14263v1](https://arxiv.org/abs/2512.14263) | [PDF](https://arxiv.org/pdf/2512.14263.pdf)

**ä½œè€…**: Nick Leenders, Thomas Quadt, Boris Cule, Roy Lindelauf, Herman Monsuur, Joost van Oijen, Mark Voskuijl

**åˆ†ç±»**: cs.LG, cs.AI, math.OC

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽå†³ç­–æ ‘çš„å¯è§£é‡Šåå¥½å­¦ä¹ æ¨¡åž‹ï¼Œä»¥è§£å†³åå¥½è´å¶æ–¯ä¼˜åŒ–ä¸­é«˜æ–¯è¿‡ç¨‹æ¨¡åž‹éš¾ä»¥è§£é‡Šã€å¤„ç†åˆ†ç±»æ•°æ®å›°éš¾çš„é—®é¢˜ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `åå¥½å­¦ä¹ ` `è´å¶æ–¯ä¼˜åŒ–` `å†³ç­–æ ‘æ¨¡åž‹` `å¯è§£é‡Šäººå·¥æ™ºèƒ½` `åˆ†ç±»æ•°æ®å¤„ç†` `ä»£ç†æ¨¡åž‹` `ä¸ªæ€§åŒ–æŽ¨è` `ä¼˜åŒ–ç®—æ³•`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•ä¾èµ–é«˜æ–¯è¿‡ç¨‹ä½œä¸ºä»£ç†æ¨¡åž‹ï¼Œå­˜åœ¨éš¾ä»¥è§£é‡Šã€å¤„ç†åˆ†ç±»æ•°æ®å›°éš¾ã€è®¡ç®—å¤æ‚ç­‰é—®é¢˜ï¼Œé™åˆ¶äº†å®žé™…åº”ç”¨ã€‚
2. æå‡ºåŸºäºŽå†³ç­–æ ‘çš„å¯è§£é‡Šä»£ç†æ¨¡åž‹ï¼Œèƒ½å¤„ç†åˆ†ç±»å’Œè¿žç»­æ•°æ®ï¼Œå…·æœ‰å¯æ‰©å±•æ€§ï¼Œæ—¨åœ¨æå‡åå¥½å­¦ä¹ çš„å®žç”¨æ€§å’Œæ•ˆçŽ‡ã€‚
3. åœ¨å°–å³°å‡½æ•°ä¸Šä¼˜äºŽé«˜æ–¯è¿‡ç¨‹æ¨¡åž‹ï¼Œåœ¨éžå°–å³°å‡½æ•°ä¸Šæ€§èƒ½æŽ¥è¿‘ï¼Œå¹¶æˆåŠŸåº”ç”¨äºŽå¯¿å¸åå¥½å­¦ä¹ ï¼Œå±•ç¤ºäº†å®žé™…ä»·å€¼ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å½“å‰çš„åå¥½è´å¶æ–¯ä¼˜åŒ–æ–¹æ³•ä¾èµ–äºŽé«˜æ–¯è¿‡ç¨‹ä½œä¸ºä»£ç†æ¨¡åž‹ã€‚è¿™äº›æ¨¡åž‹éš¾ä»¥è§£é‡Šï¼Œå¤„ç†åˆ†ç±»æ•°æ®å›°éš¾ï¼Œä¸”è®¡ç®—å¤æ‚åº¦é«˜ï¼Œé™åˆ¶äº†å…¶åœ¨å®žé™…åº”ç”¨ä¸­çš„å¯ç”¨æ€§ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æœ¬è´¨ä¸Šå¯è§£é‡Šçš„åŸºäºŽå†³ç­–æ ‘çš„ä»£ç†æ¨¡åž‹ï¼Œèƒ½å¤ŸåŒæ—¶å¤„ç†åˆ†ç±»å’Œè¿žç»­æ•°æ®ï¼Œå¹¶å¯æ‰©å±•åˆ°å¤§åž‹æ•°æ®é›†ã€‚åœ¨å…«ä¸ªé€æ¸å°–å³°çš„ä¼˜åŒ–å‡½æ•°ä¸Šè¿›è¡Œçš„å¤§é‡æ•°å€¼å®žéªŒè¡¨æ˜Žï¼Œæˆ‘ä»¬çš„æ¨¡åž‹åœ¨å°–å³°å‡½æ•°ä¸Šä¼˜äºŽåŸºäºŽé«˜æ–¯è¿‡ç¨‹çš„æ›¿ä»£æ–¹æ³•ï¼Œåœ¨éžå°–å³°å‡½æ•°ä¸Šæ€§èƒ½ä»…ç•¥ä½Žã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†æ¨¡åž‹åº”ç”¨äºŽçœŸå®žä¸–ç•Œçš„å¯¿å¸æ•°æ®é›†ï¼Œå±•ç¤ºäº†å…¶å­¦ä¹ ä¸ªäººå¯¿å¸åå¥½çš„èƒ½åŠ›ã€‚æœ€åŽï¼Œæˆ‘ä»¬å±•ç¤ºäº†åˆ©ç”¨åŽ†å²åå¥½æ•°æ®åŠ é€Ÿæ–°ç”¨æˆ·ä¼˜åŒ–è¿‡ç¨‹çš„åˆæ­¥å·¥ä½œã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åå¥½è´å¶æ–¯ä¼˜åŒ–ä¸­çŽ°æœ‰é«˜æ–¯è¿‡ç¨‹ä»£ç†æ¨¡åž‹çš„å¯è§£é‡Šæ€§å·®ã€å¤„ç†åˆ†ç±»æ•°æ®èƒ½åŠ›å¼±ã€è®¡ç®—å¤æ‚åº¦é«˜çš„é—®é¢˜ï¼Œè¿™äº›ç—›ç‚¹é™åˆ¶äº†æ¨¡åž‹åœ¨çœŸå®žä¸–ç•Œåœºæ™¯ä¸­çš„å¹¿æ³›åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é‡‡ç”¨å†³ç­–æ ‘ä½œä¸ºä»£ç†æ¨¡åž‹ï¼Œæ›¿ä»£ä¼ ç»Ÿçš„é«˜æ–¯è¿‡ç¨‹ï¼Œä»¥æä¾›å†…åœ¨çš„å¯è§£é‡Šæ€§ï¼ŒåŒæ—¶é€šè¿‡è®¾è®¡æ”¯æŒåˆ†ç±»å’Œè¿žç»­æ•°æ®çš„å†³ç­–æ ‘ç»“æž„ï¼Œæå‡æ¨¡åž‹çš„çµæ´»æ€§å’Œå¯æ‰©å±•æ€§ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æ¡†æž¶åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€å†³ç­–æ ‘æž„å»ºã€åå¥½å­¦ä¹ ä¼˜åŒ–å’Œç»“æžœè§£é‡Šå››ä¸ªé˜¶æ®µã€‚é¦–å…ˆï¼Œè¾“å…¥åŒ…å«åˆ†ç±»å’Œè¿žç»­ç‰¹å¾çš„åå¥½æ•°æ®ï¼›ç„¶åŽï¼Œæž„å»ºå†³ç­–æ ‘æ¨¡åž‹æ¥å­¦ä¹ åå¥½å…³ç³»ï¼›æŽ¥ç€ï¼Œåˆ©ç”¨è´å¶æ–¯ä¼˜åŒ–æ–¹æ³•è¿›è¡Œå‚æ•°è°ƒä¼˜ï¼›æœ€åŽï¼Œè¾“å‡ºå¯è§£é‡Šçš„å†³ç­–è§„åˆ™å’Œä¼˜åŒ–ç»“æžœã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°æ˜¯å¼•å…¥å†³ç­–æ ‘ä½œä¸ºå¯è§£é‡Šçš„ä»£ç†æ¨¡åž‹ï¼Œè¿™æœ¬è´¨åŒºåˆ«äºŽé«˜æ–¯è¿‡ç¨‹çš„é»‘ç›’ç‰¹æ€§ï¼Œä½¿å¾—æ¨¡åž‹èƒ½å¤Ÿç›´æŽ¥è¾“å‡ºå†³ç­–è§„åˆ™ï¼Œä¾¿äºŽç†è§£å’ŒéªŒè¯ï¼ŒåŒæ—¶å¢žå¼ºäº†å¤„ç†æ··åˆæ•°æ®ç±»åž‹çš„èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬å†³ç­–æ ‘çš„åˆ†è£‚å‡†åˆ™ï¼ˆå¦‚ä¿¡æ¯å¢žç›Šæˆ–åŸºå°¼æŒ‡æ•°ï¼‰ä»¥å¤„ç†åå¥½æ•°æ®ï¼ŒæŸå¤±å‡½æ•°å¯èƒ½åŸºäºŽåå¥½æŽ’åºè¯¯å·®ï¼Œç½‘ç»œç»“æž„ä¸ºå¤šåˆ†æ”¯å†³ç­–æ ‘ï¼Œå‚æ•°è®¾ç½®å¦‚æ ‘æ·±åº¦å’Œæœ€å°æ ·æœ¬æ•°é€šè¿‡äº¤å‰éªŒè¯ä¼˜åŒ–ï¼Œä»¥å¹³è¡¡æ¨¡åž‹å¤æ‚åº¦å’Œæ€§èƒ½ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨å…«ä¸ªé€æ¸å°–å³°çš„ä¼˜åŒ–å‡½æ•°å®žéªŒä¸­ï¼ŒåŸºäºŽå†³ç­–æ ‘çš„æ¨¡åž‹åœ¨å°–å³°å‡½æ•°ä¸Šæ˜¾è‘—ä¼˜äºŽé«˜æ–¯è¿‡ç¨‹æ¨¡åž‹ï¼Œå…·ä½“æ€§èƒ½æå‡å¹…åº¦æœªçŸ¥ï¼Œä½†å®žéªŒè¡¨æ˜Žåœ¨éžå°–å³°å‡½æ•°ä¸Šæ€§èƒ½ä»…ç•¥ä½Žã€‚åœ¨å¯¿å¸æ•°æ®é›†åº”ç”¨ä¸­ï¼Œæ¨¡åž‹æˆåŠŸå­¦ä¹ äº†ä¸ªäººçš„å¯¿å¸åå¥½ï¼ŒéªŒè¯äº†å…¶å®žé™…æœ‰æ•ˆæ€§ã€‚åˆæ­¥å·¥ä½œè¿˜å±•ç¤ºäº†åˆ©ç”¨åŽ†å²æ•°æ®åŠ é€Ÿæ–°ç”¨æˆ·ä¼˜åŒ–çš„æ½œåŠ›ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨ä¸ªæ€§åŒ–æŽ¨èç³»ç»Ÿã€äº§å“è®¾è®¡ä¼˜åŒ–ã€ç”¨æˆ·åå¥½å»ºæ¨¡ç­‰é¢†åŸŸå…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ã€‚ä¾‹å¦‚ï¼Œåœ¨ç”µå•†å¹³å°ä¸­ï¼Œå¯åŸºäºŽç”¨æˆ·åŽ†å²åå¥½æ•°æ®å¿«é€Ÿå­¦ä¹ æ–°ç”¨æˆ·çš„åå¥½ï¼Œæå‡æŽ¨èå‡†ç¡®æ€§å’Œç”¨æˆ·ä½“éªŒã€‚æœªæ¥å¯èƒ½æ‰©å±•åˆ°æ›´å¤šçœŸå®žä¸–ç•Œåœºæ™¯ï¼Œå¦‚åŒ»ç–—å†³ç­–æ”¯æŒæˆ–æ™ºèƒ½å®¶å±…æŽ§åˆ¶ï¼ŒæŽ¨åŠ¨å¯è§£é‡Šäººå·¥æ™ºèƒ½çš„å‘å±•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Current Preferential Bayesian Optimization methods rely on Gaussian Processes (GPs) as surrogate models. These models are hard to interpret, struggle with handling categorical data, and are computationally complex, limiting their real-world usability. In this paper, we introduce an inherently interpretable decision tree-based surrogate model capable of handling both categorical and continuous data, and scalable to large datasets. Extensive numerical experiments on eight increasingly spiky optimization functions show that our model outperforms GP-based alternatives on spiky functions and has only marginally lower performance for non-spiky functions. Moreover, we apply our model to the real-world Sushi dataset and show its ability to learn an individual's sushi preferences. Finally, we show some initial work on using historical preference data to speed up the optimization process for new unseen users.

