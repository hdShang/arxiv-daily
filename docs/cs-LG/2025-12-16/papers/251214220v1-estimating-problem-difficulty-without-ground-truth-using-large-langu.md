---
layout: default
title: Estimating problem difficulty without ground truth using Large Language Model comparisons
---

# Estimating problem difficulty without ground truth using Large Language Model comparisons

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.14220" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.14220v1</a>
  <a href="https://arxiv.org/pdf/2512.14220.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14220v1" onclick="toggleFavorite(this, '2512.14220v1', 'Estimating problem difficulty without ground truth using Large Language Model comparisons')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Marthe Ballon, Andres Algaba, Brecht Verbeken, Vincent Ginis

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: 19 pages, 10 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLLM compareä»¥è§£å†³é—®é¢˜éš¾åº¦ä¼°è®¡çš„æŒ‘æˆ˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é—®é¢˜éš¾åº¦ä¼°è®¡` `å¤§å‹è¯­è¨€æ¨¡å‹` `Bradley-Terryæ¨¡å‹` `åˆ†å¸ƒå¤–é—®é¢˜` `äººå·¥æ™ºèƒ½åº”ç”¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„éš¾åº¦ä¼°è®¡æ–¹æ³•æ— æ³•æœ‰æ•ˆæ¨å¹¿åˆ°äººç±»å’ŒLLMsæ— æ³•è§£å†³çš„åˆ†å¸ƒå¤–é—®é¢˜ï¼Œå­˜åœ¨ä¸å¯æ‰©å±•å’Œè€—æ—¶ç­‰é—®é¢˜ã€‚
2. æœ¬æ–‡æå‡ºçš„LLM compareæ–¹æ³•é€šè¿‡LLMè¿›è¡Œæˆå¯¹éš¾åº¦æ¯”è¾ƒï¼Œè®¡ç®—Bradley-Terryåˆ†æ•°ï¼Œå…‹æœäº†ç°æœ‰æ–¹æ³•çš„å±€é™æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒLLM compareä¸äººç±»æ ‡æ³¨çš„Pearsonç›¸å…³ç³»æ•°è¾¾åˆ°0.80ä»¥ä¸Šï¼Œå¹¶ä¸”å¯¹å™ªå£°çš„é²æ£’æ€§è‰¯å¥½ï¼Œç›¸å…³æ€§ä»…ä¸‹é™6%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¾®è°ƒæ˜¾è‘—æå‡äº†å…¶åœ¨åŸºå‡†æµ‹è¯•ä¸­çš„è¡¨ç°ï¼Œçªæ˜¾äº†å¯¹æ›´å¤æ‚åˆæˆæ•°æ®çš„éœ€æ±‚ã€‚ç°æœ‰çš„éš¾åº¦ä¼°è®¡æ–¹æ³•ï¼Œå¦‚äººå·¥æ ¡å‡†æˆ–åŸºäºè¡¨ç°çš„è¯„åˆ†ï¼Œæ— æ³•æ¨å¹¿åˆ°äººç±»å’ŒLLMså½“å‰æ— æ³•è§£å†³çš„åˆ†å¸ƒå¤–é—®é¢˜ï¼Œå› å…¶ä¸å¯æ‰©å±•ã€è€—æ—¶ä¸”ä¾èµ–äºçœŸå®æ ‡ç­¾ã€‚å› æ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„éš¾åº¦ä¼°è®¡æ–¹æ³•LLM compareï¼Œæ—¨åœ¨å…‹æœè¿™äº›å±€é™æ€§ã€‚è¯¥æ–¹æ³•é€šè¿‡LLMè¿›è¡Œæˆå¯¹éš¾åº¦æ¯”è¾ƒï¼Œå¹¶åŸºäºç»“æœè®¡ç®—Bradley-Terryåˆ†æ•°ã€‚éªŒè¯ç»“æœæ˜¾ç¤ºï¼ŒLLM compareä¸äººç±»æ ‡æ³¨é«˜åº¦ä¸€è‡´ï¼Œä¸”å¯¹å¹»è§‰çš„é²æ£’æ€§è‰¯å¥½ï¼Œè¡¨ç°å‡ºæ˜¾è‘—çš„å®é™…åº”ç”¨æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¦‚ä½•åœ¨æ²¡æœ‰çœŸå®æ ‡ç­¾çš„æƒ…å†µä¸‹ä¼°è®¡é—®é¢˜éš¾åº¦çš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•å¦‚äººå·¥æ ¡å‡†å’ŒåŸºäºè¡¨ç°çš„è¯„åˆ†åœ¨å¤„ç†åˆ†å¸ƒå¤–é—®é¢˜æ—¶è¡¨ç°ä¸ä½³ï¼Œç¼ºä¹å¯æ‰©å±•æ€§å’Œæ•ˆç‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šLLM compareæ–¹æ³•é€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œæˆå¯¹çš„éš¾åº¦æ¯”è¾ƒï¼Œåˆ©ç”¨Bradley-Terryæ¨¡å‹è®¡ç®—éš¾åº¦åˆ†æ•°ã€‚è¿™ä¸€è®¾è®¡ä½¿å¾—éš¾åº¦ä¼°è®¡è¿‡ç¨‹ä¸ä¾èµ–äºçœŸå®æ ‡ç­¾ï¼Œä¸”èƒ½å¤ŸåŠ¨æ€é€‚åº”ä¸åŒé—®é¢˜ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•çš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œä½¿ç”¨LLMè¿›è¡Œæˆå¯¹æ¯”è¾ƒï¼›å…¶æ¬¡ï¼ŒåŸºäºæ¯”è¾ƒç»“æœè®¡ç®—Bradley-Terryåˆ†æ•°ï¼›æœ€åï¼Œè¯„ä¼°å’ŒéªŒè¯éš¾åº¦ä¼°è®¡çš„å‡†ç¡®æ€§ä¸é²æ£’æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šLLM compareæ˜¯é¦–ä¸ªè¿ç»­ã€åŠ¨æ€ã€æ¨¡å‹æ— å…³ä¸”ä¸ä¾èµ–çœŸå®æ ‡ç­¾çš„ä¿¡æ¯åº¦é‡æ–¹æ³•ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¤„ç†åˆ†å¸ƒå¤–é—®é¢˜ï¼Œå¡«è¡¥äº†ç°æœ‰æ–¹æ³•çš„ç©ºç™½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒLLM compareé‡‡ç”¨äº†æˆå¯¹æ¯”è¾ƒçš„æ–¹å¼ï¼Œç¡®ä¿äº†éš¾åº¦ä¼°è®¡çš„ç›¸å¯¹æ€§ã€‚æ­¤å¤–ï¼Œä½¿ç”¨Bradley-Terryæ¨¡å‹ä½¿å¾—åˆ†æ•°è®¡ç®—æ›´åŠ çµæ´»ï¼Œé€‚åº”ä¸åŒç±»å‹çš„é—®é¢˜ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLM compareä¸äººç±»æ ‡æ³¨çš„Pearsonç›¸å…³ç³»æ•°è¾¾åˆ°0.80ä»¥ä¸Šï¼Œè¡¨æ˜å…¶åœ¨éš¾åº¦ä¼°è®¡ä¸Šçš„é«˜ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œåœ¨è¿›è¡Œ10%çš„å™ªå£°æ³¨å…¥æ—¶ï¼Œç›¸å…³æ€§ä»…ä¸‹é™6%ï¼Œæ˜¾ç¤ºå‡ºè‰¯å¥½çš„é²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²æŠ€æœ¯ã€æ¨¡å‹è¯„ä¼°å’ŒAIè¾…åŠ©ç ”ç©¶æ„æ€ç­‰ã€‚é€šè¿‡æä¾›é«˜æ•ˆçš„éš¾åº¦ä¼°è®¡æ–¹æ³•ï¼ŒLLM compareå¯ä»¥å¸®åŠ©è®¾è®¡æ›´å…·æŒ‘æˆ˜æ€§çš„å­¦ä¹ ææ–™ï¼Œä¼˜åŒ–æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ï¼Œå¹¶æ¨åŠ¨äººå·¥æ™ºèƒ½åœ¨ç§‘å­¦ç ”ç©¶ä¸­çš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in the finetuning of large language models (LLMs) have significantly improved their performance on established benchmarks, emphasizing the need for increasingly difficult, synthetic data. A key step in this data generation pipeline is a method for estimating problem difficulty. Current approaches, such as human calibration or performance-based scoring, fail to generalize to out-of-distribution problems, i.e. problems currently unsolvable by humans and LLMs, because they are not scalable, time-consuming, and ground truth dependent. Therefore, we propose a new method for estimating problem difficulty, LLM compare, that addresses these limitations. An LLM performs pairwise difficulty comparisons, and then Bradley-Terry scores are computed based on the outcomes. To validate our method, we first propose a conceptual framework that positions existing approaches on three orthogonal planes--construction, scale and dependence--identifying which quadrants a measure needs to occupy to score out-of-distribution problems. LLM compare naturally occupies all desirable quadrants as the first measure that is continuous and dynamic, model-agnostic and independent of ground truth information. As a second validation, we show that LLM compare demonstrates strong alignment with human annotations: Pearson $r \geq 0.80$ for $n=1876$. Thirdly, we show that LLM compare is robust to hallucinations, with less than $6\%$ degradation in Pearson correlation for $10\%$ noise injection. Our work represents a significant step towards replacing time-consuming human annotations and synthetic data generation, and will be an important driver for curriculum design, model evaluation, and AI-assisted research ideation.

