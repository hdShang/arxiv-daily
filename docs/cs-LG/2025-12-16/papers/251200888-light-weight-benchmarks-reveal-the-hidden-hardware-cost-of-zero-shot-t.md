---
layout: default
title: Light-Weight Benchmarks Reveal the Hidden Hardware Cost of Zero-Shot Tabular Foundation Models
---

# Light-Weight Benchmarks Reveal the Hidden Hardware Cost of Zero-Shot Tabular Foundation Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.00888" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.00888</a>
  <a href="https://arxiv.org/pdf/2512.00888.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.00888" onclick="toggleFavorite(this, '2512.00888', 'Light-Weight Benchmarks Reveal the Hidden Hardware Cost of Zero-Shot Tabular Foundation Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ishaan Gangwani, Aayam Bansal

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-18

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è½»é‡çº§åŸºå‡†æµ‹è¯•æ­ç¤ºé›¶æ ·æœ¬è¡¨æ ¼æ•°æ®åŸºç¡€æ¨¡å‹éšè—çš„ç¡¬ä»¶æˆæœ¬**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é›¶æ ·æœ¬å­¦ä¹ ` `è¡¨æ ¼æ•°æ®` `åŸºç¡€æ¨¡å‹` `ç¡¬ä»¶èµ„æºæ¶ˆè€—` `åŸºå‡†æµ‹è¯•`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰é›¶æ ·æœ¬è¡¨æ ¼æ•°æ®åŸºç¡€æ¨¡å‹ç¡¬ä»¶èµ„æºæ¶ˆè€—è¯„ä¼°ä¸è¶³ï¼Œç¼ºä¹ç»Ÿä¸€çš„æ€§èƒ½åŸºå‡†ã€‚
2. æ„å»ºå¯å¤ç°çš„åŸºå‡†æµ‹è¯•ï¼ŒåŒæ—¶è¯„ä¼°æ¨¡å‹ç²¾åº¦ã€æ¨ç†å»¶è¿Ÿã€CPU RAMå’ŒGPU VRAMå ç”¨ã€‚
3. å®éªŒè¡¨æ˜ï¼Œä¼ ç»Ÿæ ‘æ¨¡å‹åœ¨ç²¾åº¦å’Œæ•ˆç‡ä¸Šä¼˜äºç°æœ‰é›¶æ ·æœ¬æ¨¡å‹ï¼Œæ­ç¤ºäº†ç¡¬ä»¶ä¸ç²¾åº¦ä¹‹é—´çš„æƒè¡¡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é›¶æ ·æœ¬åŸºç¡€æ¨¡å‹(FMs)æ‰¿è¯ºåœ¨è¡¨æ ¼æ•°æ®ä¸Šè¿›è¡Œå…è®­ç»ƒé¢„æµ‹ï¼Œä½†å®ƒä»¬çš„ç¡¬ä»¶å ç”¨ä»ç„¶ç¼ºä¹å……åˆ†çš„è¡¨å¾ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªå®Œå…¨å¯å¤ç°çš„åŸºå‡†æµ‹è¯•ï¼ŒæŠ¥å‘Šäº†åœ¨å››ä¸ªå…¬å…±æ•°æ®é›†ï¼ˆAdult-Incomeã€Higgs-100kã€Wine-Qualityå’ŒCalifornia-Housingï¼‰ä¸Šçš„æµ‹è¯•ç²¾åº¦ä»¥åŠå®é™…å»¶è¿Ÿã€å³°å€¼CPU RAMå’Œå³°å€¼GPU VRAMã€‚åœ¨å•ä¸ªNVIDIA T4 GPUä¸Šï¼Œå°†ä¸¤ä¸ªå¼€æ”¾çš„FMï¼ˆTabPFN-1.0å’ŒTabICL-baseï¼‰ä¸ç»è¿‡è°ƒæ•´çš„XGBoostã€LightGBMå’ŒRandom ForeståŸºçº¿è¿›è¡Œæ¯”è¾ƒã€‚æ ‘é›†æˆæ¨¡å‹åœ¨ä¸‰ä¸ªæ•°æ®é›†ä¸Šè¾¾åˆ°æˆ–è¶…è¿‡äº†FMçš„ç²¾åº¦ï¼ŒåŒæ—¶åœ¨<= 0.40ç§’å†…å®Œæˆå®Œæ•´æµ‹è¯•æ‰¹æ¬¡ï¼Œå¹¶ä½¿ç”¨<= 150 MBçš„RAMï¼Œä¸”ä¸ä½¿ç”¨VRAMã€‚TabICLåœ¨Higgsä¸Šå®ç°äº†0.8ä¸ªç™¾åˆ†ç‚¹çš„å¢ç›Šï¼Œä½†éœ€è¦å¤§çº¦40,000å€çš„å»¶è¿Ÿï¼ˆ960ç§’ï¼‰å’Œ9 GBçš„VRAMã€‚TabPFNåœ¨Wineå’ŒHousingä¸ŠåŒ¹é…äº†æ ‘æ¨¡å‹çš„ç²¾åº¦ï¼Œä½†å³°å€¼è¾¾åˆ°4 GB VRAMï¼Œå¹¶ä¸”æ— æ³•å¤„ç†å®Œæ•´çš„10ä¸‡è¡ŒHiggsè¡¨ã€‚è¿™äº›ç»“æœé‡åŒ–äº†å½“å‰è¡¨æ ¼æ•°æ®FMä¸­æ˜¾è‘—çš„ç¡¬ä»¶ä¸ç²¾åº¦ä¹‹é—´çš„æƒè¡¡ï¼Œå¹¶ä¸ºæœªæ¥é¢å‘æ•ˆç‡çš„ç ”ç©¶æä¾›äº†ä¸€ä¸ªå¼€æ”¾çš„åŸºçº¿ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³é›¶æ ·æœ¬è¡¨æ ¼æ•°æ®åŸºç¡€æ¨¡å‹ï¼ˆFMsï¼‰çš„ç¡¬ä»¶èµ„æºæ¶ˆè€—è¯„ä¼°é—®é¢˜ã€‚ç°æœ‰ç ”ç©¶ä¸»è¦å…³æ³¨FMsçš„é¢„æµ‹ç²¾åº¦ï¼Œè€Œå¿½ç•¥äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­æ‰€éœ€çš„è®¡ç®—èµ„æºï¼Œå¦‚å»¶è¿Ÿã€CPU RAMå’ŒGPU VRAMã€‚è¿™ä½¿å¾—éš¾ä»¥è¯„ä¼°FMsåœ¨èµ„æºå—é™ç¯å¢ƒä¸‹çš„é€‚ç”¨æ€§ï¼Œä¹Ÿç¼ºä¹ä¸€ä¸ªç»Ÿä¸€çš„åŸºå‡†æ¥æ¯”è¾ƒä¸åŒFMsçš„æ•ˆç‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ„å»ºä¸€ä¸ªå…¨é¢çš„ã€å¯å¤ç°çš„åŸºå‡†æµ‹è¯•ï¼ŒåŒæ—¶è¯„ä¼°FMsçš„é¢„æµ‹ç²¾åº¦å’Œç¡¬ä»¶èµ„æºæ¶ˆè€—ã€‚é€šè¿‡å¯¹æ¯”FMsä¸ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆå¦‚æ ‘é›†æˆæ¨¡å‹ï¼‰åœ¨ä¸åŒæ•°æ®é›†ä¸Šçš„æ€§èƒ½ï¼Œé‡åŒ–FMsåœ¨ç²¾åº¦å’Œæ•ˆç‡ä¹‹é—´çš„æƒè¡¡ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæ›´å…¨é¢åœ°è¯„ä¼°FMsçš„å®ç”¨æ€§ï¼Œå¹¶ä¸ºæœªæ¥çš„æ•ˆç‡ä¼˜åŒ–ç ”ç©¶æä¾›å‚è€ƒã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥ç ”ç©¶çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼š1) é€‰æ‹©å…·æœ‰ä»£è¡¨æ€§çš„è¡¨æ ¼æ•°æ®é›†ï¼ˆAdult-Income, Higgs-100k, Wine-Quality, California-Housingï¼‰ï¼›2) é€‰æ‹©å…·æœ‰ä»£è¡¨æ€§çš„é›¶æ ·æœ¬FMsï¼ˆTabPFN-1.0, TabICL-baseï¼‰å’Œä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆXGBoost, LightGBM, Random Forestï¼‰ä½œä¸ºå¯¹æ¯”ï¼›3) åœ¨ç»Ÿä¸€çš„ç¡¬ä»¶å¹³å°ä¸Šï¼ˆNVIDIA T4 GPUï¼‰è¿è¡Œæ‰€æœ‰æ¨¡å‹ï¼Œå¹¶è®°å½•æµ‹è¯•ç²¾åº¦ã€æ¨ç†å»¶è¿Ÿã€å³°å€¼CPU RAMå’Œå³°å€¼GPU VRAMï¼›4) å¯¹æ¯”ä¸åŒæ¨¡å‹åœ¨ç²¾åº¦å’Œç¡¬ä»¶èµ„æºæ¶ˆè€—æ–¹é¢çš„è¡¨ç°ï¼Œåˆ†æFMsçš„ä¼˜ç¼ºç‚¹ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæ„å»ºäº†ä¸€ä¸ªå…¨é¢çš„ã€å¯å¤ç°çš„åŸºå‡†æµ‹è¯•ï¼Œèƒ½å¤ŸåŒæ—¶è¯„ä¼°é›¶æ ·æœ¬FMsçš„é¢„æµ‹ç²¾åº¦å’Œç¡¬ä»¶èµ„æºæ¶ˆè€—ã€‚è¯¥åŸºå‡†æµ‹è¯•ä¸ä»…æä¾›äº†å…·ä½“çš„æ€§èƒ½æ•°æ®ï¼Œè¿˜æ­ç¤ºäº†FMsåœ¨ç²¾åº¦å’Œæ•ˆç‡ä¹‹é—´çš„æƒè¡¡ï¼Œä¸ºæœªæ¥çš„æ•ˆç‡ä¼˜åŒ–ç ”ç©¶æä¾›äº†é‡è¦çš„å‚è€ƒã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜å¼ºè°ƒäº†ç¡¬ä»¶èµ„æºæ¶ˆè€—åœ¨è¯„ä¼°FMså®ç”¨æ€§ä¸­çš„é‡è¦æ€§ï¼Œè¿™æœ‰åŠ©äºæ¨åŠ¨FMsåœ¨èµ„æºå—é™ç¯å¢ƒä¸‹çš„åº”ç”¨ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) é€‰æ‹©å…·æœ‰ä»£è¡¨æ€§çš„è¡¨æ ¼æ•°æ®é›†ï¼Œè¦†ç›–ä¸åŒè§„æ¨¡å’Œç‰¹å¾ç±»å‹ï¼›2) é€‰æ‹©å…·æœ‰ä»£è¡¨æ€§çš„é›¶æ ·æœ¬FMså’Œä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œè¿›è¡Œå…¬å¹³çš„å¯¹æ¯”ï¼›3) ä½¿ç”¨ç»Ÿä¸€çš„ç¡¬ä»¶å¹³å°å’Œè¯„ä¼°æŒ‡æ ‡ï¼Œç¡®ä¿ç»“æœçš„å¯æ¯”æ€§ï¼›4) è¯¦ç»†è®°å½•å’Œåˆ†æç¡¬ä»¶èµ„æºæ¶ˆè€—æ•°æ®ï¼Œæ­ç¤ºFMsçš„ä¼˜ç¼ºç‚¹ã€‚è®ºæ–‡æ²¡æœ‰ç‰¹åˆ«æåŠæŸå¤±å‡½æ•°æˆ–ç½‘ç»œç»“æ„ç­‰ç»†èŠ‚ï¼Œå› ä¸ºé‡ç‚¹åœ¨äºè¯„ä¼°ç°æœ‰æ¨¡å‹çš„æ€§èƒ½ï¼Œè€Œä¸æ˜¯æå‡ºæ–°çš„æ¨¡å‹ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.00888/acc_vs_latency.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.00888/ram_bar.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.00888/vram_bar.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ä¸‰ä¸ªæ•°æ®é›†ä¸Šï¼Œç»è¿‡è°ƒä¼˜çš„æ ‘é›†æˆæ¨¡å‹åœ¨ç²¾åº¦ä¸Šä¸é›¶æ ·æœ¬FMç›¸å½“ç”šè‡³è¶…è¿‡ï¼ŒåŒæ—¶å»¶è¿Ÿè¿œä½äºFMï¼ˆ<= 0.40ç§’ vs. 960ç§’ï¼‰ï¼ŒRAMå ç”¨ä¹Ÿè¿œä½äºFMï¼ˆ<= 150 MB vs. 9 GB VRAMï¼‰ã€‚TabICLè™½ç„¶åœ¨Higgsæ•°æ®é›†ä¸Šç²¾åº¦ç•¥æœ‰æå‡ï¼ˆ0.8ä¸ªç™¾åˆ†ç‚¹ï¼‰ï¼Œä½†å»¶è¿Ÿå’ŒVRAMå ç”¨æ˜¾è‘—å¢åŠ ã€‚TabPFNæ— æ³•å¤„ç†å®Œæ•´çš„Higgsæ•°æ®é›†ï¼Œä¸”VRAMå ç”¨è¾ƒé«˜ï¼ˆ4GBï¼‰ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè¯„ä¼°å’Œé€‰æ‹©é€‚ç”¨äºèµ„æºå—é™ç¯å¢ƒçš„è¡¨æ ¼æ•°æ®é¢„æµ‹æ¨¡å‹ã€‚ä¾‹å¦‚ï¼Œåœ¨è¾¹ç¼˜è®¡ç®—è®¾å¤‡æˆ–ç§»åŠ¨è®¾å¤‡ä¸Šéƒ¨ç½²æ¨¡å‹æ—¶ï¼Œéœ€è¦è€ƒè™‘æ¨¡å‹çš„ç¡¬ä»¶èµ„æºæ¶ˆè€—ã€‚è¯¥ç ”ç©¶æä¾›çš„åŸºå‡†æµ‹è¯•å¯ä»¥å¸®åŠ©ç”¨æˆ·é€‰æ‹©åœ¨ç²¾åº¦å’Œæ•ˆç‡ä¹‹é—´å–å¾—å¹³è¡¡çš„æ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å¯ä»¥ä¿ƒè¿›å¯¹ç°æœ‰é›¶æ ·æœ¬æ¨¡å‹çš„æ•ˆç‡ä¼˜åŒ–ï¼Œæ¨åŠ¨å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„è½åœ°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Zero-shot foundation models (FMs) promise training-free prediction on tabular data, yet their hardware footprint remains poorly characterized. We present a fully reproducible benchmark that reports test accuracy together with wall-clock latency, peak CPU RAM, and peak GPU VRAM on four public datasets: Adult-Income, Higgs-100k, Wine-Quality, and California-Housing. Two open FMs (TabPFN-1.0 and TabICL-base) are compared against tuned XGBoost, LightGBM, and Random Forest baselines on a single NVIDIA T4 GPU. The tree ensembles equal or surpass FM accuracy on three datasets while completing full-test batches in <= 0.40 s and <= 150 MB RAM, using zero VRAM. TabICL achieves a 0.8 percentage-point gain on Higgs but requires roughly 40,000 times more latency (960 s) and 9 GB VRAM. TabPFN matches tree-model accuracy on Wine and Housing but peaks at 4 GB VRAM and cannot process the full 100k-row Higgs table. These results quantify the substantial hardware-versus-accuracy trade-offs in current tabular FMs and provide an open baseline for future efficiency-oriented research.

