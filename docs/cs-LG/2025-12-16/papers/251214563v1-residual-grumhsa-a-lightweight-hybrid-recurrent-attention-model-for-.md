---
layout: default
title: Residual GRU+MHSA: A Lightweight Hybrid Recurrent Attention Model for Cardiovascular Disease Detection
---

# Residual GRU+MHSA: A Lightweight Hybrid Recurrent Attention Model for Cardiovascular Disease Detection

**arXiv**: [2512.14563v1](https://arxiv.org/abs/2512.14563) | [PDF](https://arxiv.org/pdf/2512.14563.pdf)

**ä½œè€…**: Tejaswani Dash, Gautam Datla, Anudeep Vurity, Tazeem Ahmad, Mohd Adnan, Saima Rafi, Saisha Patro, Saina Patro

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: Accepted in IEEE Bigdata 2025- Learning Representations with Limited Supervision

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºResidual GRU+MHSAè½»é‡æ··åˆå¾ªçŽ¯æ³¨æ„åŠ›æ¨¡åž‹ï¼Œç”¨äºŽå¿ƒè¡€ç®¡ç–¾ç—…æ£€æµ‹ï¼Œå¹³è¡¡å‡†ç¡®æ€§ä¸Žæ•ˆçŽ‡ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **è§†è§‰é‡Œç¨‹è®¡** **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `å¿ƒè¡€ç®¡ç–¾ç—…æ£€æµ‹` `è½»é‡æ··åˆæž¶æž„` `æ®‹å·®åŒå‘GRU` `å¤šå¤´è‡ªæ³¨æ„åŠ›` `è¡¨æ ¼æ•°æ®å»ºæ¨¡` `ä¸´åºŠé£Žé™©é¢„æµ‹` `èµ„æºå—é™éƒ¨ç½²` `æ·±åº¦å­¦ä¹ ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¿ƒè¡€ç®¡ç–¾ç—…æ£€æµ‹ä¾èµ–ä¼ ç»Ÿæ‰‹å·¥ç‰¹å¾å’Œä¸“å®¶ç»éªŒï¼Œæœºå™¨å­¦ä¹ æ–¹æ³•åœ¨å™ªå£°å’Œå¼‚è´¨ä¸´åºŠæ•°æ®ä¸Šæ³›åŒ–å›°éš¾ã€‚
2. æå‡ºè½»é‡æ··åˆæž¶æž„ï¼Œç»“åˆæ®‹å·®åŒå‘GRUã€é€šé“é‡åŠ æƒå’Œå¤šå¤´è‡ªæ³¨æ„åŠ›æ± åŒ–ï¼Œä»¥æ•èŽ·åºåˆ—å’Œå…¨å±€ç‰¹å¾ã€‚
3. åœ¨UCIå¿ƒè„ç—…æ•°æ®é›†ä¸Šï¼Œæ¨¡åž‹å‡†ç¡®çŽ‡è¾¾0.861ï¼Œä¼˜äºŽç»å…¸å’Œæ·±åº¦å­¦ä¹ åŸºçº¿ï¼Œæ¶ˆèžç ”ç©¶éªŒè¯å„æ¨¡å—è´¡çŒ®ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¿ƒè¡€ç®¡ç–¾ç—…æ˜¯å…¨çƒä¸»è¦æ­»å› ï¼Œéœ€è¦å¯é é«˜æ•ˆçš„é¢„æµ‹å·¥å…·ä»¥æ”¯æŒæ—©æœŸå¹²é¢„ã€‚ä¼ ç»Ÿè¯Šæ–­æ–¹æ³•ä¾èµ–æ‰‹å·¥ç‰¹å¾å’Œä¸´åºŠä¸“å®¶ç»éªŒï¼Œè€Œæœºå™¨å­¦ä¹ æ–¹æ³•è™½æé«˜å¯é‡å¤æ€§ï¼Œä½†å¸¸éš¾ä»¥åœ¨å™ªå£°å’Œå¼‚è´¨ä¸´åºŠæ•°æ®ä¸Šæ³›åŒ–ã€‚æœ¬æ–‡æå‡ºResidual GRU with Multi-Head Self-Attentionï¼Œä¸€ç§ä¸ºè¡¨æ ¼ä¸´åºŠè®°å½•è®¾è®¡çš„ç´§å‡‘æ·±åº¦å­¦ä¹ æž¶æž„ã€‚è¯¥æ¨¡åž‹é›†æˆæ®‹å·®åŒå‘é—¨æŽ§å¾ªçŽ¯å•å…ƒç”¨äºŽç‰¹å¾åˆ—çš„åºåˆ—å»ºæ¨¡ã€é€šé“é‡åŠ æƒå—ï¼Œä»¥åŠå¸¦å¯å­¦ä¹ åˆ†ç±»ä»¤ç‰Œçš„å¤šå¤´è‡ªæ³¨æ„åŠ›æ± åŒ–ä»¥æ•èŽ·å…¨å±€ä¸Šä¸‹æ–‡ã€‚æˆ‘ä»¬åœ¨UCIå¿ƒè„ç—…æ•°æ®é›†ä¸Šä½¿ç”¨5æŠ˜åˆ†å±‚äº¤å‰éªŒè¯è¯„ä¼°æ¨¡åž‹ï¼Œå¹¶ä¸Žé€»è¾‘å›žå½’ã€éšæœºæ£®æž—ã€æ”¯æŒå‘é‡æœºç­‰ç»å…¸æ–¹æ³•ï¼Œä»¥åŠDeepMLPã€å·ç§¯ç½‘ç»œã€å¾ªçŽ¯ç½‘ç»œå’ŒTransformerç­‰çŽ°ä»£æ·±åº¦å­¦ä¹ åŸºçº¿è¿›è¡Œæ¯”è¾ƒã€‚æ‰€ææ¨¡åž‹è¾¾åˆ°0.861çš„å‡†ç¡®çŽ‡ã€0.860çš„å®F1ã€0.908çš„ROC-AUCå’Œ0.904çš„PR-AUCï¼Œä¼˜äºŽæ‰€æœ‰åŸºçº¿ã€‚æ¶ˆèžç ”ç©¶ç¡®è®¤äº†æ®‹å·®å¾ªçŽ¯ã€é€šé“é—¨æŽ§å’Œæ³¨æ„åŠ›æ± åŒ–çš„ä¸ªä½“è´¡çŒ®ã€‚t-SNEå¯è§†åŒ–è¿›ä¸€æ­¥è¡¨æ˜Žï¼Œä¸ŽåŽŸå§‹ç‰¹å¾ç›¸æ¯”ï¼Œå­¦ä¹ åˆ°çš„åµŒå…¥åœ¨ç–¾ç—…å’Œéžç–¾ç—…ç±»åˆ«é—´å±•çŽ°å‡ºæ›´æ¸…æ™°çš„åˆ†ç¦»ã€‚è¿™äº›ç»“æžœè¡¨æ˜Žï¼Œè½»é‡æ··åˆå¾ªçŽ¯å’ŒåŸºäºŽæ³¨æ„åŠ›çš„æž¶æž„ä¸ºä¸´åºŠé£Žé™©é¢„æµ‹æä¾›äº†å‡†ç¡®æ€§ä¸Žæ•ˆçŽ‡ä¹‹é—´çš„å¼ºå¹³è¡¡ï¼Œæ”¯æŒåœ¨èµ„æºå—é™çš„åŒ»ç–—çŽ¯å¢ƒä¸­éƒ¨ç½²ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¿ƒè¡€ç®¡ç–¾ç—…æ£€æµ‹ä¸­ï¼Œä¼ ç»Ÿæ–¹æ³•ä¾èµ–æ‰‹å·¥ç‰¹å¾å’Œä¸“å®¶ç»éªŒï¼Œè€Œæœºå™¨å­¦ä¹ æ–¹æ³•åœ¨å™ªå£°å’Œå¼‚è´¨ä¸´åºŠè¡¨æ ¼æ•°æ®ä¸Šæ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•çš„ç—›ç‚¹åŒ…æ‹¬ç‰¹å¾å·¥ç¨‹å¤æ‚ã€æ¨¡åž‹å¯¹æ•°æ®å™ªå£°æ•æ„Ÿï¼Œä»¥åŠæ·±åº¦å­¦ä¹ æ¨¡åž‹å¦‚Transformerè®¡ç®—å¼€é”€å¤§ï¼Œä¸é€‚åˆèµ„æºå—é™çš„åŒ»ç–—çŽ¯å¢ƒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®¾è®¡ä¸€ä¸ªè½»é‡æ··åˆæ·±åº¦å­¦ä¹ æž¶æž„ï¼Œç»“åˆå¾ªçŽ¯ç¥žç»ç½‘ç»œï¼ˆRNNï¼‰çš„åºåˆ—å»ºæ¨¡èƒ½åŠ›å’Œè‡ªæ³¨æ„åŠ›æœºåˆ¶çš„å…¨å±€ä¸Šä¸‹æ–‡æ•èŽ·èƒ½åŠ›ï¼Œé€šè¿‡æ®‹å·®è¿žæŽ¥å’Œé€šé“é‡åŠ æƒå¢žå¼ºç‰¹å¾è¡¨ç¤ºï¼Œä»¥æé«˜æ¨¡åž‹åœ¨ä¸´åºŠè¡¨æ ¼æ•°æ®ä¸Šçš„å‡†ç¡®æ€§å’Œæ³›åŒ–æ€§ï¼ŒåŒæ—¶ä¿æŒè®¡ç®—æ•ˆçŽ‡ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æž¶æž„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œä½¿ç”¨æ®‹å·®åŒå‘é—¨æŽ§å¾ªçŽ¯å•å…ƒï¼ˆResidual Bidirectional GRUï¼‰å¯¹ç‰¹å¾åˆ—è¿›è¡Œåºåˆ—å»ºæ¨¡ï¼Œå¤„ç†è¡¨æ ¼æ•°æ®çš„æ—¶åºæˆ–é¡ºåºä¾èµ–ï¼›å…¶æ¬¡ï¼Œå¼•å…¥é€šé“é‡åŠ æƒå—ï¼ˆChannel Reweighting Blockï¼‰ï¼Œé€šè¿‡æ³¨æ„åŠ›æœºåˆ¶åŠ¨æ€è°ƒæ•´ç‰¹å¾é€šé“çš„é‡è¦æ€§ï¼›æœ€åŽï¼Œé‡‡ç”¨å¤šå¤´è‡ªæ³¨æ„åŠ›æ± åŒ–ï¼ˆMulti-Head Self-Attention Poolingï¼‰ä¸Žå¯å­¦ä¹ åˆ†ç±»ä»¤ç‰Œï¼Œèšåˆå…¨å±€ä¿¡æ¯å¹¶è¾“å‡ºåˆ†ç±»ç»“æžœã€‚æµç¨‹ä¸ºè¾“å…¥è¡¨æ ¼æ•°æ®â†’æ®‹å·®åŒå‘GRUå¤„ç†â†’é€šé“é‡åŠ æƒâ†’å¤šå¤´è‡ªæ³¨æ„åŠ›æ± åŒ–â†’åˆ†ç±»è¾“å‡ºã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹æ˜¯è½»é‡æ··åˆæž¶æž„çš„è®¾è®¡ï¼Œå°†æ®‹å·®å¾ªçŽ¯ã€é€šé“é—¨æŽ§å’Œæ³¨æ„åŠ›æ± åŒ–æœ‰æœºç»“åˆï¼Œæœ¬è´¨åŒºåˆ«åœ¨äºŽå®ƒé¿å…äº†ä¼ ç»ŸTransformerçš„é«˜è®¡ç®—æˆæœ¬ï¼ŒåŒæ—¶é€šè¿‡å¾ªçŽ¯ç½‘ç»œæ•èŽ·å±€éƒ¨åºåˆ—æ¨¡å¼ï¼Œé€šè¿‡æ³¨æ„åŠ›æœºåˆ¶å¢žå¼ºå…¨å±€ç‰¹å¾äº¤äº’ï¼Œå®žçŽ°äº†å‡†ç¡®æ€§ä¸Žæ•ˆçŽ‡çš„å¹³è¡¡ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œå®ƒä¸“é—¨é’ˆå¯¹è¡¨æ ¼ä¸´åºŠæ•°æ®ä¼˜åŒ–ï¼Œå‡å°‘äº†å‚æ•°æ•°é‡ï¼Œæ›´é€‚åˆéƒ¨ç½²åœ¨èµ„æºå—é™çš„åŒ»ç–—åœºæ™¯ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®å‚æ•°è®¾ç½®åŒ…æ‹¬ä½¿ç”¨åŒå‘GRUå¤„ç†ç‰¹å¾åºåˆ—ï¼Œéšè—å±‚å¤§å°æœªçŸ¥ï¼›é€šé“é‡åŠ æƒå—å¯èƒ½åŸºäºŽæ³¨æ„åŠ›æƒé‡è°ƒæ•´ç‰¹å¾ï¼›å¤šå¤´è‡ªæ³¨æ„åŠ›æ± åŒ–ä¸­ï¼Œå¤´æ•°æœªçŸ¥ï¼Œä½†åŒ…å«å¯å­¦ä¹ åˆ†ç±»ä»¤ç‰Œä»¥èšåˆä¿¡æ¯ã€‚æŸå¤±å‡½æ•°å¯èƒ½ä½¿ç”¨äº¤å‰ç†µæŸå¤±è¿›è¡ŒäºŒåˆ†ç±»ä»»åŠ¡ã€‚ç½‘ç»œç»“æž„ç´§å‡‘ï¼Œæ•´ä½“å‚æ•°è¾ƒå°‘ï¼Œä»¥æ”¯æŒè½»é‡åŒ–éƒ¨ç½²ã€‚å…·ä½“è¶…å‚æ•°å¦‚å­¦ä¹ çŽ‡ã€æ‰¹æ¬¡å¤§å°åœ¨è®ºæ–‡ä¸­æœªè¯¦ç»†è¯´æ˜Žï¼Œä½†é€šè¿‡5æŠ˜åˆ†å±‚äº¤å‰éªŒè¯è¿›è¡Œä¼˜åŒ–ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨UCIå¿ƒè„ç—…æ•°æ®é›†ä¸Šï¼ŒResidual GRU+MHSAæ¨¡åž‹è¾¾åˆ°0.861å‡†ç¡®çŽ‡ã€0.860å®F1ã€0.908 ROC-AUCå’Œ0.904 PR-AUCï¼Œä¼˜äºŽé€»è¾‘å›žå½’ã€éšæœºæ£®æž—ã€æ”¯æŒå‘é‡æœºåŠDeepMLPã€å·ç§¯ç½‘ç»œã€å¾ªçŽ¯ç½‘ç»œå’ŒTransformerç­‰åŸºçº¿ã€‚æ¶ˆèžç ”ç©¶ç¡®è®¤æ®‹å·®å¾ªçŽ¯ã€é€šé“é—¨æŽ§å’Œæ³¨æ„åŠ›æ± åŒ–å‡è´¡çŒ®æ€§èƒ½æå‡ï¼Œt-SNEå¯è§†åŒ–æ˜¾ç¤ºå­¦ä¹ åµŒå…¥åœ¨ç±»åˆ«é—´åˆ†ç¦»æ›´æ¸…æ™°ï¼ŒéªŒè¯äº†æ¨¡åž‹çš„æœ‰æ•ˆæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶ä¸»è¦åº”ç”¨äºŽå¿ƒè¡€ç®¡ç–¾ç—…æ—©æœŸæ£€æµ‹å’Œé£Žé™©é¢„æµ‹ï¼ŒåŸºäºŽè¡¨æ ¼ä¸´åºŠè®°å½•å¦‚ç”µå­å¥åº·æ¡£æ¡ˆã€‚å…¶å®žé™…ä»·å€¼åœ¨äºŽæä¾›é«˜æ•ˆã€å‡†ç¡®çš„è‡ªåŠ¨åŒ–è¯Šæ–­å·¥å…·ï¼Œæ”¯æŒä¸´åºŠå†³ç­–ï¼Œå‡å°‘å¯¹ä¸“å®¶ç»éªŒçš„ä¾èµ–ã€‚æœªæ¥å½±å“å¯èƒ½æ‰©å±•åˆ°å…¶ä»–æ…¢æ€§ç—…é¢„æµ‹ï¼Œä¿ƒè¿›èµ„æºå—é™åŒ»ç–—çŽ¯å¢ƒä¸­çš„æ™ºèƒ½åŒ»ç–—éƒ¨ç½²ï¼Œæå‡å…¬å…±å«ç”Ÿæ°´å¹³ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Cardiovascular disease (CVD) remains the leading cause of mortality worldwide, underscoring the need for reliable and efficient predictive tools that support early intervention. Traditional diagnostic approaches rely on handcrafted features and clinician expertise, while machine learning methods improve reproducibility but often struggle to generalize across noisy and heterogeneous clinical data. In this work, we propose Residual GRU with Multi-Head Self-Attention, a compact deep learning architecture designed for tabular clinical records. The model integrates residual bidirectional gated recurrent units for sequential modeling of feature columns, a channel reweighting block, and multi-head self-attention pooling with a learnable classification token to capture global context. We evaluate the model on the UCI Heart Disease dataset using 5-fold stratified cross-validation and compare it against classical methods such as Logistic Regression, Random Forest, and Support Vector Machines, as well as modern deep learning baselines including DeepMLP, convolutional networks, recurrent networks, and Transformers. The proposed model achieves an accuracy of 0.861, macro-F1 of 0.860, ROC-AUC of 0.908, and PR-AUC of 0.904, outperforming all baselines. Ablation studies confirm the individual contributions of residual recurrence, channel gating, and attention pooling. t-SNE visualizations further indicate that the learned embeddings exhibit clearer separation between disease and non-disease classes compared to raw features. These results demonstrate that lightweight hybrid recurrent and attention-based architectures provide a strong balance between accuracy and efficiency for clinical risk prediction, supporting deployment in resource-constrained healthcare settings.

