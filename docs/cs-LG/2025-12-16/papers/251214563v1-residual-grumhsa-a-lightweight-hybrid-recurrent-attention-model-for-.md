---
layout: default
title: Residual GRU+MHSA: A Lightweight Hybrid Recurrent Attention Model for Cardiovascular Disease Detection
---

# Residual GRU+MHSA: A Lightweight Hybrid Recurrent Attention Model for Cardiovascular Disease Detection

**arXiv**: [2512.14563v1](https://arxiv.org/abs/2512.14563) | [PDF](https://arxiv.org/pdf/2512.14563.pdf)

**ä½œè€…**: Tejaswani Dash, Gautam Datla, Anudeep Vurity, Tazeem Ahmad, Mohd Adnan, Saima Rafi, Saisha Patro, Saina Patro

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: Accepted in IEEE Bigdata 2025- Learning Representations with Limited Supervision

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºResidual GRU+MHSAè½»é‡çº§æ··åˆå¾ªçŽ¯æ³¨æ„åŠ›æ¨¡åž‹ï¼Œç”¨äºŽå¿ƒè¡€ç®¡ç–¾ç—…æ£€æµ‹ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å¼ºåŒ–å­¦ä¹ ä¸Žæ¨¡ä»¿å­¦ä¹  (RL & IL)**

**å…³é”®è¯**: `å¿ƒè¡€ç®¡ç–¾ç—…æ£€æµ‹` `å¾ªçŽ¯ç¥žç»ç½‘ç»œ` `è‡ªæ³¨æ„åŠ›æœºåˆ¶` `æ·±åº¦å­¦ä¹ ` `ä¸´åºŠæ•°æ®åˆ†æž`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰å¿ƒè¡€ç®¡ç–¾ç—…è¯Šæ–­æ–¹æ³•ä¾èµ–æ‰‹å·¥ç‰¹å¾ï¼Œæœºå™¨å­¦ä¹ æ–¹æ³•æ³›åŒ–æ€§å·®ï¼Œéš¾ä»¥å¤„ç†ä¸´åºŠæ•°æ®çš„å™ªå£°å’Œå¼‚æž„æ€§ã€‚
2. æå‡ºResidual GRU+MHSAæ¨¡åž‹ï¼Œåˆ©ç”¨æ®‹å·®GRUè¿›è¡Œåºåˆ—å»ºæ¨¡ï¼Œé€šé“é‡åŠ æƒå’Œå¤šå¤´è‡ªæ³¨æ„åŠ›æ•èŽ·å…¨å±€ä¸Šä¸‹æ–‡ã€‚
3. å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥æ¨¡åž‹åœ¨UCIå¿ƒè„ç—…æ•°æ®é›†ä¸Šä¼˜äºŽä¼ ç»Ÿæœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ åŸºçº¿ï¼Œå…·æœ‰æ›´é«˜çš„å‡†ç¡®çŽ‡å’Œæ•ˆçŽ‡ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¿ƒè¡€ç®¡ç–¾ç—…(CVD)ä»ç„¶æ˜¯å…¨çƒä¸»è¦çš„æ­»äº¡åŽŸå› ï¼Œå› æ­¤éœ€è¦å¯é å’Œé«˜æ•ˆçš„é¢„æµ‹å·¥å…·æ¥æ”¯æŒæ—©æœŸå¹²é¢„ã€‚ä¼ ç»Ÿè¯Šæ–­æ–¹æ³•ä¾èµ–äºŽæ‰‹å·¥ç‰¹å¾å’Œä¸´åºŠåŒ»ç”Ÿä¸“ä¸šçŸ¥è¯†ï¼Œè€Œæœºå™¨å­¦ä¹ æ–¹æ³•æé«˜äº†å¯é‡å¤æ€§ï¼Œä½†é€šå¸¸éš¾ä»¥æŽ¨å¹¿åˆ°å˜ˆæ‚å’Œå¼‚æž„çš„ä¸´åºŠæ•°æ®ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ç´§å‡‘çš„æ·±åº¦å­¦ä¹ æž¶æž„ï¼šå¸¦æœ‰Multi-Head Self-Attentionçš„Residual GRUï¼Œä¸“ä¸ºè¡¨æ ¼ä¸´åºŠè®°å½•è®¾è®¡ã€‚è¯¥æ¨¡åž‹é›†æˆäº†æ®‹å·®åŒå‘é—¨æŽ§å¾ªçŽ¯å•å…ƒï¼Œç”¨äºŽç‰¹å¾åˆ—çš„åºåˆ—å»ºæ¨¡ï¼Œä¸€ä¸ªé€šé“é‡åŠ æƒå—ï¼Œä»¥åŠå¸¦æœ‰å¯å­¦ä¹ åˆ†ç±»tokençš„å¤šå¤´è‡ªæ³¨æ„åŠ›æ± åŒ–ï¼Œä»¥æ•èŽ·å…¨å±€ä¸Šä¸‹æ–‡ã€‚åœ¨UCIå¿ƒè„ç—…æ•°æ®é›†ä¸Šï¼Œä½¿ç”¨5æŠ˜åˆ†å±‚äº¤å‰éªŒè¯è¯„ä¼°äº†è¯¥æ¨¡åž‹ï¼Œå¹¶å°†å…¶ä¸Žç»å…¸æ–¹æ³•ï¼ˆå¦‚Logistic Regressionã€Random Forestå’ŒSupport Vector Machinesï¼‰ä»¥åŠçŽ°ä»£æ·±åº¦å­¦ä¹ åŸºçº¿ï¼ˆåŒ…æ‹¬DeepMLPã€å·ç§¯ç½‘ç»œã€å¾ªçŽ¯ç½‘ç»œå’ŒTransformersï¼‰è¿›è¡Œäº†æ¯”è¾ƒã€‚æ‰€æå‡ºçš„æ¨¡åž‹å®žçŽ°äº†0.861çš„å‡†ç¡®çŽ‡ã€0.860çš„macro-F1ã€0.908çš„ROC-AUCå’Œ0.904çš„PR-AUCï¼Œä¼˜äºŽæ‰€æœ‰åŸºçº¿ã€‚æ¶ˆèžç ”ç©¶è¯å®žäº†æ®‹å·®å¾ªçŽ¯ã€é€šé“é—¨æŽ§å’Œæ³¨æ„åŠ›æ± åŒ–çš„å„è‡ªè´¡çŒ®ã€‚t-SNEå¯è§†åŒ–è¿›ä¸€æ­¥è¡¨æ˜Žï¼Œä¸ŽåŽŸå§‹ç‰¹å¾ç›¸æ¯”ï¼Œå­¦ä¹ åˆ°çš„åµŒå…¥åœ¨ç–¾ç—…å’Œéžç–¾ç—…ç±»åˆ«ä¹‹é—´è¡¨çŽ°å‡ºæ›´æ¸…æ™°çš„åˆ†ç¦»ã€‚è¿™äº›ç»“æžœè¡¨æ˜Žï¼Œè½»é‡çº§æ··åˆå¾ªçŽ¯å’ŒåŸºäºŽæ³¨æ„åŠ›çš„æž¶æž„åœ¨ä¸´åºŠé£Žé™©é¢„æµ‹çš„å‡†ç¡®æ€§å’Œæ•ˆçŽ‡ä¹‹é—´æä¾›äº†å¼ºå¤§çš„å¹³è¡¡ï¼Œæ”¯æŒåœ¨èµ„æºå—é™çš„åŒ»ç–—çŽ¯å¢ƒä¸­éƒ¨ç½²ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¿ƒè¡€ç®¡ç–¾ç—…ï¼ˆCVDï¼‰çš„æ—©æœŸé¢„æµ‹é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•ï¼Œå¦‚ä¼ ç»Ÿæœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ æ¨¡åž‹ï¼Œåœ¨å¤„ç†ä¸´åºŠè¡¨æ ¼æ•°æ®æ—¶å­˜åœ¨å±€é™æ€§ã€‚ä¼ ç»Ÿæ–¹æ³•ä¾èµ–æ‰‹å·¥ç‰¹å¾å·¥ç¨‹ï¼Œè€—æ—¶ä¸”ä¾èµ–ä¸“å®¶çŸ¥è¯†ã€‚æ·±åº¦å­¦ä¹ æ¨¡åž‹è™½ç„¶å¯ä»¥è‡ªåŠ¨å­¦ä¹ ç‰¹å¾ï¼Œä½†å¾€å¾€éš¾ä»¥åœ¨å™ªå£°è¾ƒå¤§ã€å¼‚æž„æ€§å¼ºçš„ä¸´åºŠæ•°æ®ä¸Šæ³›åŒ–ï¼Œå¹¶ä¸”è®¡ç®—å¤æ‚åº¦è¾ƒé«˜ï¼Œä¸åˆ©äºŽåœ¨èµ„æºå—é™çš„çŽ¯å¢ƒä¸­éƒ¨ç½²ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ç»“åˆå¾ªçŽ¯ç¥žç»ç½‘ç»œï¼ˆRNNï¼‰å’Œè‡ªæ³¨æ„åŠ›æœºåˆ¶çš„ä¼˜åŠ¿ï¼Œè®¾è®¡ä¸€ä¸ªè½»é‡çº§çš„æ··åˆæ¨¡åž‹ã€‚å¾ªçŽ¯ç¥žç»ç½‘ç»œæ“…é•¿å¤„ç†åºåˆ—æ•°æ®ï¼Œå¯ä»¥æ•æ‰ç‰¹å¾ä¹‹é—´çš„æ—¶åºå…³ç³»ã€‚è‡ªæ³¨æ„åŠ›æœºåˆ¶å¯ä»¥æ•æ‰å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¹¶å¯¹é‡è¦ç‰¹å¾è¿›è¡ŒåŠ æƒã€‚é€šè¿‡æ®‹å·®è¿žæŽ¥ã€é€šé“é‡åŠ æƒç­‰æŠ€æœ¯ï¼Œè¿›ä¸€æ­¥æå‡æ¨¡åž‹çš„æ€§èƒ½å’Œé²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šè¯¥æ¨¡åž‹ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) **Residual Bidirectional GRU**ï¼šä½¿ç”¨åŒå‘GRUå¯¹ç‰¹å¾åˆ—è¿›è¡Œåºåˆ—å»ºæ¨¡ï¼Œå¹¶é‡‡ç”¨æ®‹å·®è¿žæŽ¥åŠ é€Ÿæ”¶æ•›ã€‚2) **Channel Reweighting Block**ï¼šå¯¹ä¸åŒç‰¹å¾é€šé“è¿›è¡Œé‡åŠ æƒï¼Œçªå‡ºé‡è¦ç‰¹å¾ã€‚3) **Multi-Head Self-Attention Pooling**ï¼šä½¿ç”¨å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶å¯¹GRUçš„è¾“å‡ºè¿›è¡Œæ± åŒ–ï¼Œå¹¶å¼•å…¥ä¸€ä¸ªå¯å­¦ä¹ çš„åˆ†ç±»tokenï¼Œç”¨äºŽæ•èŽ·å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚4) **åˆ†ç±»å™¨**ï¼šä½¿ç”¨å…¨è¿žæŽ¥å±‚è¿›è¡Œæœ€ç»ˆçš„åˆ†ç±»ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽå°†æ®‹å·®GRUã€é€šé“é‡åŠ æƒå’Œå¤šå¤´è‡ªæ³¨æ„åŠ›æ± åŒ–ç›¸ç»“åˆï¼Œæž„å»ºäº†ä¸€ä¸ªè½»é‡çº§çš„æ··åˆæ¨¡åž‹ã€‚è¿™ç§æ··åˆæž¶æž„æ—¢èƒ½æ•æ‰ç‰¹å¾ä¹‹é—´çš„æ—¶åºå…³ç³»ï¼Œåˆèƒ½æ•æ‰å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ŒåŒæ—¶ä¿æŒè¾ƒä½Žçš„è®¡ç®—å¤æ‚åº¦ã€‚æ­¤å¤–ï¼Œä½¿ç”¨å¯å­¦ä¹ çš„åˆ†ç±»tokenï¼Œä½¿å¾—æ¨¡åž‹èƒ½å¤Ÿæ›´å¥½åœ°å­¦ä¹ å…¨å±€è¡¨ç¤ºã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡åž‹ä½¿ç”¨åŒå‘GRUï¼Œå¯ä»¥åŒæ—¶è€ƒè™‘ç‰¹å¾çš„å‰å‘å’ŒåŽå‘å…³ç³»ã€‚æ®‹å·®è¿žæŽ¥å¯ä»¥ç¼“è§£æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼ŒåŠ é€Ÿæ¨¡åž‹æ”¶æ•›ã€‚é€šé“é‡åŠ æƒæ¨¡å—ä½¿ç”¨SE (Squeeze-and-Excitation) blockï¼Œè‡ªé€‚åº”åœ°å­¦ä¹ ä¸åŒé€šé“çš„é‡è¦æ€§ã€‚å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶ä½¿ç”¨8ä¸ªheadã€‚æŸå¤±å‡½æ•°ä½¿ç”¨äºŒå…ƒäº¤å‰ç†µæŸå¤±å‡½æ•°ã€‚æ¨¡åž‹ä½¿ç”¨Adamä¼˜åŒ–å™¨è¿›è¡Œè®­ç»ƒï¼Œå­¦ä¹ çŽ‡ä¸º0.001ï¼Œbatch sizeä¸º32ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

è¯¥æ¨¡åž‹åœ¨UCIå¿ƒè„ç—…æ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå‡†ç¡®çŽ‡è¾¾åˆ°0.861ï¼Œmacro-F1è¾¾åˆ°0.860ï¼ŒROC-AUCè¾¾åˆ°0.908ï¼ŒPR-AUCè¾¾åˆ°0.904ï¼Œä¼˜äºŽLogistic Regressionã€Random Forestã€SVMã€DeepMLPã€CNNã€RNNå’ŒTransformerç­‰åŸºçº¿æ¨¡åž‹ã€‚æ¶ˆèžå®žéªŒè¡¨æ˜Žï¼Œæ®‹å·®è¿žæŽ¥ã€é€šé“é‡åŠ æƒå’Œå¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶éƒ½å¯¹æ€§èƒ½æå‡æœ‰è´¡çŒ®ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽå¿ƒè¡€ç®¡ç–¾ç—…çš„æ—©æœŸé£Žé™©é¢„æµ‹ï¼Œè¾…åŠ©åŒ»ç”Ÿè¿›è¡Œè¯Šæ–­å’Œåˆ¶å®šæ²»ç–—æ–¹æ¡ˆã€‚è¯¥æ¨¡åž‹å…·æœ‰è½»é‡çº§çš„ç‰¹ç‚¹ï¼Œæ˜“äºŽéƒ¨ç½²åœ¨èµ„æºå—é™çš„åŒ»ç–—çŽ¯å¢ƒä¸­ï¼Œä¾‹å¦‚åŸºå±‚åŒ»é™¢å’Œç§»åŠ¨åŒ»ç–—è®¾å¤‡ã€‚æœªæ¥ï¼Œè¯¥æ¨¡åž‹å¯ä»¥æ‰©å±•åˆ°å…¶ä»–ç–¾ç—…çš„é¢„æµ‹ï¼Œå¹¶ä¸Žå…¶ä»–ä¸´åºŠæ•°æ®ï¼ˆå¦‚å½±åƒæ•°æ®ã€åŸºå› æ•°æ®ï¼‰ç›¸ç»“åˆï¼Œæé«˜é¢„æµ‹çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Cardiovascular disease (CVD) remains the leading cause of mortality worldwide, underscoring the need for reliable and efficient predictive tools that support early intervention. Traditional diagnostic approaches rely on handcrafted features and clinician expertise, while machine learning methods improve reproducibility but often struggle to generalize across noisy and heterogeneous clinical data. In this work, we propose Residual GRU with Multi-Head Self-Attention, a compact deep learning architecture designed for tabular clinical records. The model integrates residual bidirectional gated recurrent units for sequential modeling of feature columns, a channel reweighting block, and multi-head self-attention pooling with a learnable classification token to capture global context. We evaluate the model on the UCI Heart Disease dataset using 5-fold stratified cross-validation and compare it against classical methods such as Logistic Regression, Random Forest, and Support Vector Machines, as well as modern deep learning baselines including DeepMLP, convolutional networks, recurrent networks, and Transformers. The proposed model achieves an accuracy of 0.861, macro-F1 of 0.860, ROC-AUC of 0.908, and PR-AUC of 0.904, outperforming all baselines. Ablation studies confirm the individual contributions of residual recurrence, channel gating, and attention pooling. t-SNE visualizations further indicate that the learned embeddings exhibit clearer separation between disease and non-disease classes compared to raw features. These results demonstrate that lightweight hybrid recurrent and attention-based architectures provide a strong balance between accuracy and efficiency for clinical risk prediction, supporting deployment in resource-constrained healthcare settings.

