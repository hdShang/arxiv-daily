---
layout: default
title: Residual GRU+MHSA: A Lightweight Hybrid Recurrent Attention Model for Cardiovascular Disease Detection
---

# Residual GRU+MHSA: A Lightweight Hybrid Recurrent Attention Model for Cardiovascular Disease Detection

**arXiv**: [2512.14563v1](https://arxiv.org/abs/2512.14563) | [PDF](https://arxiv.org/pdf/2512.14563.pdf)

**ä½œè€…**: Tejaswani Dash, Gautam Datla, Anudeep Vurity, Tazeem Ahmad, Mohd Adnan, Saima Rafi, Saisha Patro, Saina Patro

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: Accepted in IEEE Bigdata 2025- Learning Representations with Limited Supervision

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºResidual GRU+MHSAè½»é‡æ··åˆå¾ªçŽ¯æ³¨æ„åŠ›æ¨¡åž‹ï¼Œç”¨äºŽå¿ƒè¡€ç®¡ç–¾ç—…æ£€æµ‹ï¼Œå¹³è¡¡å‡†ç¡®æ€§ä¸Žæ•ˆçŽ‡ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **è§†è§‰é‡Œç¨‹è®¡** **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `å¿ƒè¡€ç®¡ç–¾ç—…æ£€æµ‹` `è½»é‡æ··åˆæ¨¡åž‹` `æ®‹å·®åŒå‘GRU` `å¤šå¤´è‡ªæ³¨æ„åŠ›` `ä¸´åºŠé£Žé™©é¢„æµ‹` `è¡¨æ ¼æ•°æ®å»ºæ¨¡` `åŒ»ç–—äººå·¥æ™ºèƒ½` `èµ„æºå—é™éƒ¨ç½²`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä¼ ç»Ÿå¿ƒè¡€ç®¡ç–¾ç—…æ£€æµ‹ä¾èµ–æ‰‹å·¥ç‰¹å¾å’Œä¸“å®¶ç»éªŒï¼Œæœºå™¨å­¦ä¹ æ–¹æ³•åœ¨å™ªå£°å’Œå¼‚è´¨ä¸´åºŠæ•°æ®ä¸­æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæå‡ºè½»é‡æ··åˆæ¨¡åž‹ï¼Œç»“åˆæ®‹å·®åŒå‘GRUè¿›è¡Œåºåˆ—å»ºæ¨¡ã€é€šé“é‡åŠ æƒå’Œå¤šå¤´è‡ªæ³¨æ„åŠ›æ± åŒ–ï¼Œä»¥æ•èŽ·å…¨å±€ä¸Šä¸‹æ–‡ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨UCIå¿ƒè„ç—…æ•°æ®é›†ä¸Šï¼Œæ¨¡åž‹å‡†ç¡®çŽ‡è¾¾0.861ï¼Œä¼˜äºŽç»å…¸å’Œæ·±åº¦å­¦ä¹ åŸºçº¿ï¼Œæ¶ˆèžç ”ç©¶éªŒè¯å„æ¨¡å—è´¡çŒ®ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¿ƒè¡€ç®¡ç–¾ç—…æ˜¯å…¨çƒä¸»è¦æ­»å› ï¼Œéœ€è¦å¯é é«˜æ•ˆçš„é¢„æµ‹å·¥å…·ä»¥æ”¯æŒæ—©æœŸå¹²é¢„ã€‚ä¼ ç»Ÿè¯Šæ–­æ–¹æ³•ä¾èµ–æ‰‹å·¥ç‰¹å¾å’Œä¸´åºŠä¸“å®¶ç»éªŒï¼Œè€Œæœºå™¨å­¦ä¹ æ–¹æ³•è™½æé«˜å¯é‡å¤æ€§ï¼Œä½†å¸¸éš¾ä»¥åœ¨å™ªå£°å’Œå¼‚è´¨ä¸´åºŠæ•°æ®ä¸­æ³›åŒ–ã€‚æœ¬æ–‡æå‡ºResidual GRU with Multi-Head Self-Attentionï¼Œä¸€ç§ä¸ºè¡¨æ ¼ä¸´åºŠè®°å½•è®¾è®¡çš„ç´§å‡‘æ·±åº¦å­¦ä¹ æž¶æž„ã€‚è¯¥æ¨¡åž‹é›†æˆæ®‹å·®åŒå‘é—¨æŽ§å¾ªçŽ¯å•å…ƒç”¨äºŽç‰¹å¾åˆ—çš„åºåˆ—å»ºæ¨¡ã€é€šé“é‡åŠ æƒå—ä»¥åŠå¸¦å¯å­¦ä¹ åˆ†ç±»æ ‡è®°çš„å¤šå¤´è‡ªæ³¨æ„åŠ›æ± åŒ–ä»¥æ•èŽ·å…¨å±€ä¸Šä¸‹æ–‡ã€‚æˆ‘ä»¬åœ¨UCIå¿ƒè„ç—…æ•°æ®é›†ä¸Šä½¿ç”¨5æŠ˜åˆ†å±‚äº¤å‰éªŒè¯è¯„ä¼°æ¨¡åž‹ï¼Œå¹¶ä¸Žé€»è¾‘å›žå½’ã€éšæœºæ£®æž—ã€æ”¯æŒå‘é‡æœºç­‰ç»å…¸æ–¹æ³•ä»¥åŠDeepMLPã€å·ç§¯ç½‘ç»œã€å¾ªçŽ¯ç½‘ç»œå’ŒTransformerç­‰çŽ°ä»£æ·±åº¦å­¦ä¹ åŸºçº¿è¿›è¡Œæ¯”è¾ƒã€‚æ‰€ææ¨¡åž‹è¾¾åˆ°0.861çš„å‡†ç¡®çŽ‡ã€0.860çš„å®F1ã€0.908çš„ROC-AUCå’Œ0.904çš„PR-AUCï¼Œä¼˜äºŽæ‰€æœ‰åŸºçº¿ã€‚æ¶ˆèžç ”ç©¶ç¡®è®¤äº†æ®‹å·®å¾ªçŽ¯ã€é€šé“é—¨æŽ§å’Œæ³¨æ„åŠ›æ± åŒ–çš„ä¸ªä½“è´¡çŒ®ã€‚t-SNEå¯è§†åŒ–è¿›ä¸€æ­¥è¡¨æ˜Žï¼Œä¸ŽåŽŸå§‹ç‰¹å¾ç›¸æ¯”ï¼Œå­¦ä¹ åˆ°çš„åµŒå…¥åœ¨ç–¾ç—…å’Œéžç–¾ç—…ç±»åˆ«é—´è¡¨çŽ°å‡ºæ›´æ¸…æ™°çš„åˆ†ç¦»ã€‚è¿™äº›ç»“æžœè¡¨æ˜Žï¼Œè½»é‡æ··åˆå¾ªçŽ¯å’ŒåŸºäºŽæ³¨æ„åŠ›çš„æž¶æž„ä¸ºä¸´åºŠé£Žé™©é¢„æµ‹æä¾›äº†å‡†ç¡®æ€§ä¸Žæ•ˆçŽ‡ä¹‹é—´çš„å¼ºå¹³è¡¡ï¼Œæ”¯æŒåœ¨èµ„æºå—é™çš„åŒ»ç–—çŽ¯å¢ƒä¸­éƒ¨ç½²ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¿ƒè¡€ç®¡ç–¾ç—…æ£€æµ‹ä¸­ï¼Œä¼ ç»Ÿæ–¹æ³•ä¾èµ–æ‰‹å·¥ç‰¹å¾å’Œä¸“å®¶ç»éªŒå¯¼è‡´æ•ˆçŽ‡ä½Žï¼Œè€ŒçŽ°æœ‰æœºå™¨å­¦ä¹ æ–¹æ³•åœ¨å™ªå£°å’Œå¼‚è´¨ä¸´åºŠè¡¨æ ¼æ•°æ®ä¸­æ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•çš„ç—›ç‚¹åŒ…æ‹¬ç‰¹å¾å·¥ç¨‹å¤æ‚ã€æ¨¡åž‹é²æ£’æ€§å·®å’Œè®¡ç®—èµ„æºéœ€æ±‚é«˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºä¸€ç§è½»é‡æ··åˆå¾ªçŽ¯æ³¨æ„åŠ›æ¨¡åž‹ï¼Œé€šè¿‡ç»“åˆæ®‹å·®åŒå‘GRUçš„åºåˆ—å»ºæ¨¡èƒ½åŠ›å’Œå¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œæœ‰æ•ˆæ•èŽ·ä¸´åºŠç‰¹å¾é—´çš„æ—¶åºä¾èµ–å’Œå…¨å±€ä¸Šä¸‹æ–‡ï¼Œä»¥æé«˜é¢„æµ‹å‡†ç¡®æ€§å’Œæ³›åŒ–èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒæ¨¡åž‹ç´§å‡‘æ€§ä»¥é€‚åº”èµ„æºå—é™çŽ¯å¢ƒã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æž¶æž„åŒ…å«ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œä½¿ç”¨æ®‹å·®åŒå‘GRUå¯¹è¡¨æ ¼ä¸´åºŠè®°å½•çš„ç‰¹å¾åˆ—è¿›è¡Œåºåˆ—å»ºæ¨¡ï¼Œå¤„ç†ç‰¹å¾é—´çš„æ—¶åºå…³ç³»ï¼›å…¶æ¬¡ï¼Œå¼•å…¥é€šé“é‡åŠ æƒå—ï¼ŒåŠ¨æ€è°ƒæ•´ç‰¹å¾é€šé“çš„é‡è¦æ€§ï¼›æœ€åŽï¼Œé€šè¿‡å¤šå¤´è‡ªæ³¨æ„åŠ›æ± åŒ–å±‚ï¼Œç»“åˆå¯å­¦ä¹ åˆ†ç±»æ ‡è®°ï¼Œèšåˆå…¨å±€ä¿¡æ¯å¹¶è¾“å‡ºåˆ†ç±»ç»“æžœã€‚æµç¨‹ä¸ºè¾“å…¥ç‰¹å¾â†’æ®‹å·®åŒå‘GRUâ†’é€šé“é‡åŠ æƒâ†’å¤šå¤´è‡ªæ³¨æ„åŠ›æ± åŒ–â†’åˆ†ç±»è¾“å‡ºã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹æ˜¯è½»é‡æ··åˆè®¾è®¡ï¼Œå°†æ®‹å·®å¾ªçŽ¯ç½‘ç»œä¸Žæ³¨æ„åŠ›æœºåˆ¶ç»“åˆï¼Œå…·ä½“åŒ…æ‹¬æ®‹å·®åŒå‘GRUå¢žå¼ºåºåˆ—å»ºæ¨¡ç¨³å®šæ€§ã€é€šé“é‡åŠ æƒä¼˜åŒ–ç‰¹å¾è¡¨ç¤ºï¼Œä»¥åŠå¤šå¤´è‡ªæ³¨æ„åŠ›æ± åŒ–æ›¿ä»£ä¼ ç»Ÿæ± åŒ–ä»¥æ•èŽ·å…¨å±€ä¾èµ–ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºŽï¼Œå®ƒé¿å…äº†çº¯Transformerçš„é«˜è®¡ç®—æˆæœ¬ï¼ŒåŒæ—¶è¶…è¶Šä¼ ç»Ÿå¾ªçŽ¯ç½‘ç»œçš„å±€é™æ€§ï¼Œå®žçŽ°é«˜æ•ˆä¸”å‡†ç¡®çš„ä¸´åºŠé£Žé™©é¢„æµ‹ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡åž‹ä½¿ç”¨æ®‹å·®è¿žæŽ¥ç¼“è§£æ¢¯åº¦æ¶ˆå¤±ï¼ŒåŒå‘GRUæ•èŽ·å‰åŽå‘ä¾èµ–ï¼›é€šé“é‡åŠ æƒå—åŸºäºŽæ³¨æ„åŠ›æœºåˆ¶åŠ¨æ€åŠ æƒç‰¹å¾é€šé“ï¼›å¤šå¤´è‡ªæ³¨æ„åŠ›æ± åŒ–å±‚åŒ…å«å¯å­¦ä¹ åˆ†ç±»æ ‡è®°ï¼Œç”¨äºŽèšåˆä¿¡æ¯å¹¶è¾“å‡ºåµŒå…¥ï¼›æŸå¤±å‡½æ•°é‡‡ç”¨äº¤å‰ç†µæŸå¤±è¿›è¡ŒäºŒåˆ†ç±»ä»»åŠ¡ï¼›åœ¨UCIå¿ƒè„ç—…æ•°æ®é›†ä¸Šï¼Œé€šè¿‡5æŠ˜åˆ†å±‚äº¤å‰éªŒè¯è¯„ä¼°ï¼Œè¶…å‚æ•°å¦‚å±‚æ•°ã€å¤´æ•°ç­‰é€šè¿‡å®žéªŒè°ƒä¼˜ï¼Œå…·ä½“æ•°å€¼æœªåœ¨æ‘˜è¦ä¸­æä¾›ï¼Œä½†è®¾è®¡å¼ºè°ƒè½»é‡åŒ–å’Œé«˜æ•ˆæ€§ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

æœ€é‡è¦çš„å®žéªŒç»“æžœåŒ…æ‹¬ï¼šåœ¨UCIå¿ƒè„ç—…æ•°æ®é›†ä¸Šï¼Œæ¨¡åž‹è¾¾åˆ°0.861å‡†ç¡®çŽ‡ã€0.860å®F1ã€0.908 ROC-AUCå’Œ0.904 PR-AUCï¼Œå…¨é¢ä¼˜äºŽé€»è¾‘å›žå½’ã€éšæœºæ£®æž—ã€æ”¯æŒå‘é‡æœºç­‰ç»å…¸æ–¹æ³•ï¼Œä»¥åŠDeepMLPã€å·ç§¯ç½‘ç»œã€å¾ªçŽ¯ç½‘ç»œå’ŒTransformerç­‰æ·±åº¦å­¦ä¹ åŸºçº¿ã€‚æ¶ˆèžç ”ç©¶ç¡®è®¤æ®‹å·®å¾ªçŽ¯ã€é€šé“é—¨æŽ§å’Œæ³¨æ„åŠ›æ± åŒ–æ¨¡å—å‡å¯¹æ€§èƒ½æå‡æœ‰è´¡çŒ®ï¼Œt-SNEå¯è§†åŒ–æ˜¾ç¤ºå­¦ä¹ åµŒå…¥æ¯”åŽŸå§‹ç‰¹å¾å…·æœ‰æ›´æ¸…æ™°çš„ç±»åˆ«åˆ†ç¦»ï¼ŒéªŒè¯äº†æ¨¡åž‹çš„æœ‰æ•ˆæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶ä¸»è¦åº”ç”¨äºŽå¿ƒè¡€ç®¡ç–¾ç—…æ—©æœŸæ£€æµ‹å’Œä¸´åºŠé£Žé™©é¢„æµ‹é¢†åŸŸï¼Œç‰¹åˆ«æ˜¯åœ¨èµ„æºå—é™çš„åŒ»ç–—çŽ¯å¢ƒä¸­ï¼Œå¦‚ç¤¾åŒºåŒ»é™¢æˆ–è¿œç¨‹åŒ»ç–—ç³»ç»Ÿã€‚å…¶å®žé™…ä»·å€¼åœ¨äºŽæä¾›ä¸€ç§é«˜æ•ˆã€å‡†ç¡®çš„è‡ªåŠ¨åŒ–è¯Šæ–­å·¥å…·ï¼Œå‡å°‘å¯¹ä¸“å®¶ç»éªŒçš„ä¾èµ–ï¼Œæ”¯æŒå¤§è§„æ¨¡ç­›æŸ¥å’Œä¸ªæ€§åŒ–å¹²é¢„ã€‚æœªæ¥å½±å“å¯èƒ½æ‰©å±•åˆ°å…¶ä»–æ…¢æ€§ç—…é¢„æµ‹æˆ–æ›´å¹¿æ³›çš„åŒ»ç–—æ•°æ®åˆ†æžä»»åŠ¡ï¼ŒæŽ¨åŠ¨äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—ä¿å¥ä¸­çš„æ™®åŠå’Œå®žç”¨åŒ–ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Cardiovascular disease (CVD) remains the leading cause of mortality worldwide, underscoring the need for reliable and efficient predictive tools that support early intervention. Traditional diagnostic approaches rely on handcrafted features and clinician expertise, while machine learning methods improve reproducibility but often struggle to generalize across noisy and heterogeneous clinical data. In this work, we propose Residual GRU with Multi-Head Self-Attention, a compact deep learning architecture designed for tabular clinical records. The model integrates residual bidirectional gated recurrent units for sequential modeling of feature columns, a channel reweighting block, and multi-head self-attention pooling with a learnable classification token to capture global context. We evaluate the model on the UCI Heart Disease dataset using 5-fold stratified cross-validation and compare it against classical methods such as Logistic Regression, Random Forest, and Support Vector Machines, as well as modern deep learning baselines including DeepMLP, convolutional networks, recurrent networks, and Transformers. The proposed model achieves an accuracy of 0.861, macro-F1 of 0.860, ROC-AUC of 0.908, and PR-AUC of 0.904, outperforming all baselines. Ablation studies confirm the individual contributions of residual recurrence, channel gating, and attention pooling. t-SNE visualizations further indicate that the learned embeddings exhibit clearer separation between disease and non-disease classes compared to raw features. These results demonstrate that lightweight hybrid recurrent and attention-based architectures provide a strong balance between accuracy and efficiency for clinical risk prediction, supporting deployment in resource-constrained healthcare settings.

