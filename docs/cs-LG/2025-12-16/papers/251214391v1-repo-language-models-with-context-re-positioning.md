---
layout: default
title: RePo: Language Models with Context Re-Positioning
---

# RePo: Language Models with Context Re-Positioning

**arXiv**: [2512.14391v1](https://arxiv.org/abs/2512.14391) | [PDF](https://arxiv.org/pdf/2512.14391.pdf)

**ä½œè€…**: Huayang Li, Tianyu Zhao, Richard Sproat

**åˆ†ç±»**: cs.LG, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**ðŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/SakanaAI/repo)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRePoæœºåˆ¶ï¼Œé€šè¿‡ä¸Šä¸‹æ–‡é‡å®šä½å‡å°‘å¤§è¯­è¨€æ¨¡åž‹ä¸­çš„é¢å¤–è®¤çŸ¥è´Ÿè·ï¼Œæå‡é•¿æ–‡æœ¬å’Œç»“æž„åŒ–æ•°æ®å¤„ç†èƒ½åŠ›ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **è§†è§‰é‡Œç¨‹è®¡**

**å…³é”®è¯**: `ä¸Šä¸‹æ–‡å­¦ä¹ ` `ä½ç½®ç¼–ç ` `è®¤çŸ¥è´Ÿè·ç†è®º` `å¤§è¯­è¨€æ¨¡åž‹` `å¯å¾®åˆ†æ¨¡å—` `é•¿æ–‡æœ¬å¤„ç†` `ç»“æž„åŒ–æ•°æ®` `æ³¨æ„åŠ›æœºåˆ¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰å¤§è¯­è¨€æ¨¡åž‹ä½¿ç”¨çº¿æ€§æˆ–æ’å®šä½ç½®ç´¢å¼•ï¼Œå¯¼è‡´ä¸Šä¸‹æ–‡ç»“æž„åƒµåŒ–ï¼Œå¢žåŠ é¢å¤–è®¤çŸ¥è´Ÿè·ï¼Œé™åˆ¶æ·±åº¦æŽ¨ç†èƒ½åŠ›ã€‚
2. æå‡ºRePoæœºåˆ¶ï¼Œé€šè¿‡å¯å¾®åˆ†æ¨¡å—åŠ¨æ€åˆ†é…æ ‡è®°ä½ç½®ï¼Œæ•æ‰ä¸Šä¸‹æ–‡ä¾èµ–ï¼Œå‡å°‘é¢å¤–è´Ÿè·ï¼Œæå‡æ¨¡åž‹çµæ´»æ€§ã€‚
3. å®žéªŒæ˜¾ç¤ºRePoåœ¨å™ªå£°ä¸Šä¸‹æ–‡ã€ç»“æž„åŒ–æ•°æ®å’Œé•¿æ–‡æœ¬ä»»åŠ¡ä¸­æ€§èƒ½æ˜¾è‘—æå‡ï¼ŒåŒæ—¶ä¿æŒçŸ­ä¸Šä¸‹æ–‡ä»»åŠ¡çš„ç«žäº‰åŠ›ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸Šä¸‹æ–‡å­¦ä¹ æ˜¯çŽ°ä»£å¤§è¯­è¨€æ¨¡åž‹ï¼ˆLLMsï¼‰çš„åŸºç¡€ï¼›ç„¶è€Œï¼Œä¸»æµæž¶æž„é€šè¿‡åˆ†é…çº¿æ€§æˆ–æ’å®šçš„ä½ç½®ç´¢å¼•ï¼Œå¼ºåŠ äº†åƒµåŒ–ä¸”å›ºå®šçš„ä¸Šä¸‹æ–‡ç»“æž„ã€‚å€Ÿé‰´è®¤çŸ¥è´Ÿè·ç†è®ºï¼ˆCLTï¼‰ï¼Œæˆ‘ä»¬è®¤ä¸ºè¿™ç§æ— ä¿¡æ¯æ€§çš„ç»“æž„å¢žåŠ äº†é¢å¤–è®¤çŸ¥è´Ÿè·ï¼Œæ¶ˆè€—äº†æœ¬åº”ç”¨äºŽæ·±åº¦æŽ¨ç†å’Œæ³¨æ„åŠ›åˆ†é…çš„æœ‰é™å·¥ä½œè®°å¿†å®¹é‡ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†RePoï¼Œä¸€ç§é€šè¿‡ä¸Šä¸‹æ–‡é‡å®šä½å‡å°‘é¢å¤–è´Ÿè·çš„æ–°æœºåˆ¶ã€‚ä¸Žæ ‡å‡†æ–¹æ³•ä¸åŒï¼ŒRePoåˆ©ç”¨ä¸€ä¸ªå¯å¾®åˆ†æ¨¡å—fÏ†æ¥åˆ†é…æ•æ‰ä¸Šä¸‹æ–‡ä¾èµ–å…³ç³»çš„æ ‡è®°ä½ç½®ï¼Œè€Œä¸æ˜¯ä¾èµ–é¢„å®šä¹‰çš„æ•´æ•°èŒƒå›´ã€‚é€šè¿‡åœ¨OLMo-2 1Béª¨å¹²ç½‘ç»œä¸ŠæŒç»­é¢„è®­ç»ƒï¼Œæˆ‘ä»¬è¯æ˜ŽRePoåœ¨å¤„ç†æ¶‰åŠå™ªå£°ä¸Šä¸‹æ–‡ã€ç»“æž„åŒ–æ•°æ®å’Œæ›´é•¿ä¸Šä¸‹æ–‡é•¿åº¦çš„ä»»åŠ¡æ—¶ï¼Œæ€§èƒ½æ˜¾è‘—æå‡ï¼ŒåŒæ—¶åœ¨ä¸€èˆ¬çŸ­ä¸Šä¸‹æ–‡ä»»åŠ¡ä¸Šä¿æŒç«žäº‰åŠ›ã€‚è¯¦ç»†åˆ†æžè¡¨æ˜Žï¼ŒRePoæˆåŠŸåœ°å°†æ›´é«˜æ³¨æ„åŠ›åˆ†é…ç»™é¥è¿œä½†ç›¸å…³çš„ä¿¡æ¯ï¼Œåœ¨å¯†é›†å’Œéžçº¿æ€§ç©ºé—´ä¸­åˆ†é…ä½ç½®ï¼Œå¹¶æ•æ‰è¾“å…¥ä¸Šä¸‹æ–‡çš„å†…åœ¨ç»“æž„ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨https://github.com/SakanaAI/repoèŽ·å–ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡è§£å†³å¤§è¯­è¨€æ¨¡åž‹ä¸­ä¸Šä¸‹æ–‡å­¦ä¹ çš„é—®é¢˜ï¼ŒçŽ°æœ‰æ–¹æ³•ä½¿ç”¨çº¿æ€§æˆ–æ’å®šä½ç½®ç´¢å¼•ï¼ˆå¦‚ç»å¯¹æˆ–ç›¸å¯¹ä½ç½®ç¼–ç ï¼‰ï¼Œå¯¼è‡´ä¸Šä¸‹æ–‡ç»“æž„åƒµåŒ–ï¼Œæ— æ³•æœ‰æ•ˆæ•æ‰å¤æ‚ä¾èµ–å…³ç³»ï¼Œå¢žåŠ é¢å¤–è®¤çŸ¥è´Ÿè·ï¼Œæ¶ˆè€—å·¥ä½œè®°å¿†å®¹é‡ï¼Œä»Žè€Œå½±å“æ¨¡åž‹åœ¨å™ªå£°ã€ç»“æž„åŒ–æˆ–é•¿æ–‡æœ¬ä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæ ¸å¿ƒæ€è·¯æ˜¯å¼•å…¥ä¸Šä¸‹æ–‡é‡å®šä½æœºåˆ¶ï¼ŒåŸºäºŽè®¤çŸ¥è´Ÿè·ç†è®ºï¼Œé€šè¿‡åŠ¨æ€åˆ†é…æ ‡è®°ä½ç½®æ¥å‡å°‘é¢å¤–è´Ÿè·ã€‚è®¾è®¡ä¸€ä¸ªå¯å¾®åˆ†æ¨¡å—fÏ†ï¼Œæ ¹æ®ä¸Šä¸‹æ–‡å†…å®¹å­¦ä¹ ä½ç½®è¡¨ç¤ºï¼Œè€Œéžä¾èµ–é¢„å®šä¹‰æ•´æ•°ï¼Œä½¿æ¨¡åž‹èƒ½æ›´çµæ´»åœ°æ•æ‰ä¾èµ–å…³ç³»ï¼Œä¼˜åŒ–æ³¨æ„åŠ›åˆ†é…ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æž¶æž„åŸºäºŽOLMo-2 1Béª¨å¹²ç½‘ç»œï¼Œåœ¨é¢„è®­ç»ƒé˜¶æ®µé›†æˆRePoæ¨¡å—ã€‚æµç¨‹åŒ…æ‹¬ï¼šè¾“å…¥ä¸Šä¸‹æ–‡åºåˆ—ï¼Œé€šè¿‡fÏ†æ¨¡å—è®¡ç®—æ¯ä¸ªæ ‡è®°çš„ä½ç½®è¡¨ç¤ºï¼Œè¿™äº›è¡¨ç¤ºä½œä¸ºä½ç½®ç¼–ç èžå…¥æ¨¡åž‹ï¼›åœ¨è®­ç»ƒä¸­ï¼Œæ¨¡å—å‚æ•°Ï†ä¸Žæ¨¡åž‹å‚æ•°è”åˆä¼˜åŒ–ï¼Œä»¥æœ€å°åŒ–æŸå¤±å‡½æ•°ï¼›æŽ¨ç†æ—¶ï¼Œä½¿ç”¨å­¦ä¹ åˆ°çš„ä½ç½®è¡¨ç¤ºè¿›è¡Œé¢„æµ‹ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬éª¨å¹²ç½‘ç»œã€fÏ†æ¨¡å—å’Œä½ç½®ç¼–ç å±‚ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°æ˜¯æå‡ºå¯å¾®åˆ†çš„ä½ç½®åˆ†é…æ¨¡å—fÏ†ï¼Œå®žçŽ°ä¸Šä¸‹æ–‡é‡å®šä½ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºŽï¼šçŽ°æœ‰æ–¹æ³•ä¾èµ–å›ºå®šä½ç½®ç´¢å¼•ï¼ˆå¦‚çº¿æ€§æˆ–ç›¸å¯¹ç¼–ç ï¼‰ï¼Œè€ŒRePoå…è®¸ä½ç½®åœ¨å¯†é›†ã€éžçº¿æ€§ç©ºé—´ä¸­åŠ¨æ€è°ƒæ•´ï¼Œç›´æŽ¥æ•æ‰ä¸Šä¸‹æ–‡ä¾èµ–ï¼Œå‡å°‘ç»“æž„åƒµåŒ–å¸¦æ¥çš„è®¤çŸ¥è´Ÿè·ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼šfÏ†æ¨¡å—é‡‡ç”¨ç¥žç»ç½‘ç»œç»“æž„ï¼ˆå…·ä½“ç»†èŠ‚æœªçŸ¥ï¼Œå¯èƒ½åŸºäºŽTransformeræˆ–MLPï¼‰ï¼Œè¾“å‡ºä½ç½®è¡¨ç¤ºï¼›æŸå¤±å‡½æ•°ç»“åˆè¯­è¨€å»ºæ¨¡æŸå¤±å’Œæ½œåœ¨çš„ä½ç½®æ­£åˆ™åŒ–ï¼›åœ¨OLMo-2 1Bä¸ŠæŒç»­é¢„è®­ç»ƒï¼Œå‚æ•°è®¾ç½®éµå¾ªæ ‡å‡†é¢„è®­ç»ƒåè®®ï¼›ä½ç½®è¡¨ç¤ºä¸Žæ ‡è®°åµŒå…¥ç»“åˆï¼Œä½œä¸ºæ¨¡åž‹è¾“å…¥çš„ä¸€éƒ¨åˆ†ï¼Œç¡®ä¿å¯å¾®åˆ†æ€§å’Œç«¯åˆ°ç«¯ä¼˜åŒ–ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœæ˜¾ç¤ºï¼ŒRePoåœ¨OLMo-2 1Béª¨å¹²ä¸ŠæŒç»­é¢„è®­ç»ƒåŽï¼Œåœ¨æ¶‰åŠå™ªå£°ä¸Šä¸‹æ–‡çš„ä»»åŠ¡ä¸­æ€§èƒ½æå‡æ˜¾è‘—ï¼ˆå…·ä½“æ•°æ®æœªçŸ¥ï¼Œä½†è®ºæ–‡æåˆ°â€œæ˜¾è‘—å¢žå¼ºâ€ï¼‰ï¼Œåœ¨ç»“æž„åŒ–æ•°æ®å¤„ç†å’Œæ›´é•¿ä¸Šä¸‹æ–‡é•¿åº¦ä»»åŠ¡ä¸Šä¹Ÿè¡¨çŽ°ä¼˜å¼‚ã€‚ä¸ŽåŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼ŒRePoåœ¨ä¸€èˆ¬çŸ­ä¸Šä¸‹æ–‡ä»»åŠ¡ä¸Šä¿æŒç«žäº‰åŠ›ï¼ŒåŒæ—¶é€šè¿‡æ³¨æ„åŠ›åˆ†æžè¯å®žèƒ½æ›´æœ‰æ•ˆåœ°åˆ†é…æ³¨æ„åŠ›åˆ°é¥è¿œç›¸å…³ä¿¡æ¯ï¼Œä½ç½®åˆ†é…å‘ˆçŽ°å¯†é›†å’Œéžçº¿æ€§ç‰¹æ€§ï¼ŒæˆåŠŸæ•æ‰è¾“å…¥ç»“æž„ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æ½œåœ¨åº”ç”¨äºŽéœ€è¦å¤„ç†å¤æ‚ä¸Šä¸‹æ–‡çš„ä»»åŠ¡ï¼Œå¦‚æ–‡æ¡£æ‘˜è¦ã€ä»£ç ç”Ÿæˆã€ç»“æž„åŒ–æ•°æ®è§£æžå’Œé•¿æ–‡æœ¬é—®ç­”ã€‚å®žé™…ä»·å€¼åœ¨äºŽæå‡å¤§è¯­è¨€æ¨¡åž‹åœ¨å™ªå£°çŽ¯å¢ƒã€éžç»“æž„åŒ–è¾“å…¥å’Œæ‰©å±•ä¸Šä¸‹æ–‡ä¸­çš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ï¼Œæœªæ¥å¯èƒ½æŽ¨åŠ¨æ›´é«˜æ•ˆçš„è‡ªç„¶è¯­è¨€å¤„ç†ç³»ç»Ÿï¼Œå‡å°‘äººå·¥å¹²é¢„ï¼Œå¢žå¼ºæ¨¡åž‹åœ¨çŽ°å®žä¸–ç•Œåœºæ™¯ä¸­çš„é€‚ç”¨æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In-context learning is fundamental to modern Large Language Models (LLMs); however, prevailing architectures impose a rigid and fixed contextual structure by assigning linear or constant positional indices. Drawing on Cognitive Load Theory (CLT), we argue that this uninformative structure increases extraneous cognitive load, consuming finite working memory capacity that should be allocated to deep reasoning and attention allocation. To address this, we propose RePo, a novel mechanism that reduces extraneous load via context re-positioning. Unlike standard approaches, RePo utilizes a differentiable module, $f_Ï†$, to assign token positions that capture contextual dependencies, rather than replying on pre-defined integer range. By continually pre-training on the OLMo-2 1B backbone, we demonstrate that RePo significantly enhances performance on tasks involving noisy contexts, structured data, and longer context length, while maintaining competitive performance on general short-context tasks. Detailed analysis reveals that RePo successfully allocate higher attention to distant but relevant information, assign positions in dense and non-linear space, and capture the intrinsic structure of the input context. Our code is available at https://github.com/SakanaAI/repo.

