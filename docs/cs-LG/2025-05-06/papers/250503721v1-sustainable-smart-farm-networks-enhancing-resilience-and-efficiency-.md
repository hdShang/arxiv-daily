---
layout: default
title: "Sustainable Smart Farm Networks: Enhancing Resilience and Efficiency with Decision Theory-Guided Deep Reinforcement Learning"
---

# Sustainable Smart Farm Networks: Enhancing Resilience and Efficiency with Decision Theory-Guided Deep Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.03721" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.03721v1</a>
  <a href="https://arxiv.org/pdf/2505.03721.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.03721v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.03721v1', 'Sustainable Smart Farm Networks: Enhancing Resilience and Efficiency with Decision Theory-Guided Deep Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Dian Chen, Zelin Wan, Dong Sam Ha, Jin-Hee Cho

**åˆ†ç±»**: cs.LG, cs.MA

**å‘å¸ƒæ—¥æœŸ**: 2025-05-06

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå†³ç­–ç†è®ºçš„æ·±åº¦å¼ºåŒ–å­¦ä¹ ä»¥æå‡æ™ºèƒ½å†œåœºç½‘ç»œçš„éŸ§æ€§ä¸æ•ˆç‡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æ™ºèƒ½å†œä¸š` `æ·±åº¦å¼ºåŒ–å­¦ä¹ ` `å†³ç­–ç†è®º` `è¿ç§»å­¦ä¹ ` `èƒ½æºæ•ˆç‡` `ç³»ç»ŸéŸ§æ€§` `ç›‘æµ‹ç³»ç»Ÿ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ™ºèƒ½å†œåœºç›‘æµ‹ç³»ç»Ÿåœ¨åº”å¯¹ç½‘ç»œæ”»å‡»å’Œèƒ½æºæ³¢åŠ¨æ–¹é¢å­˜åœ¨éŸ§æ€§ä¸è¶³å’Œé€‚åº”æ€§å·®çš„é—®é¢˜ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»“åˆæ·±åº¦å¼ºåŒ–å­¦ä¹ ã€è¿ç§»å­¦ä¹ å’Œå†³ç­–ç†è®ºçš„æ™ºèƒ½å†œåœºç½‘ç»œï¼Œä»¥ä¼˜åŒ–ç›‘æµ‹è´¨é‡å’Œèƒ½æºæ•ˆç‡ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDTå¼•å¯¼çš„DRLæ¨¡å‹åœ¨ç³»ç»Ÿæ€§èƒ½ä¸Šä¼˜äºTLå¢å¼ºçš„DRLæ¨¡å‹ï¼Œè®­ç»ƒæ—¶é—´å‡å°‘äº†47.5%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºäºå¤ªé˜³èƒ½ä¼ æ„Ÿå™¨çš„ç›‘æµ‹ç³»ç»Ÿå·²æˆä¸ºå†œä¸šåˆ›æ–°çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œé€šè¿‡æ•´åˆä¼ æ„Ÿå™¨æŠ€æœ¯ã€ç‰©è”ç½‘ä»¥åŠè¾¹ç¼˜å’Œäº‘è®¡ç®—ï¼Œæ¨åŠ¨äº†å†œåœºç®¡ç†å’ŒåŠ¨ç‰©ç¦åˆ©çš„å‘å±•ã€‚ç„¶è€Œï¼Œè¿™äº›ç³»ç»Ÿåœ¨é¢å¯¹ç½‘ç»œæ”»å‡»å’ŒåŠ¨æ€èƒ½æºä¾›åº”æ—¶çš„éŸ§æ€§å’Œé€‚åº”æ€§ä»æœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§å¯æŒç»­çš„æ™ºèƒ½å†œåœºç½‘ç»œï¼Œæ—¨åœ¨åœ¨å„ç§ç½‘ç»œå¨èƒå’Œèƒ½æºæ³¢åŠ¨æ¡ä»¶ä¸‹ä¿æŒé«˜è´¨é‡çš„åŠ¨ç‰©ç›‘æµ‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDRLï¼‰åˆ¶å®šæœ€ä½³ç­–ç•¥ï¼Œä»¥æœ€å¤§åŒ–ç›‘æµ‹æ•ˆæœå’Œèƒ½æºæ•ˆç‡ã€‚é€šè¿‡ç»“åˆè¿ç§»å­¦ä¹ ï¼ˆTLï¼‰å’Œå†³ç­–ç†è®ºï¼ˆDTï¼‰ï¼ŒåŠ é€Ÿå­¦ä¹ è¿‡ç¨‹ï¼Œæ˜¾è‘—å‡å°‘è®­ç»ƒæ—¶é—´ï¼ŒåŒæ—¶å®ç°å¯æ¯”çš„æ€§èƒ½å¥–åŠ±ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDTå¼•å¯¼çš„DRLä¼˜äºTLå¢å¼ºçš„DRLæ¨¡å‹ï¼Œç³»ç»Ÿæ€§èƒ½æå‡å¹¶å‡å°‘è®­ç»ƒæ—¶é—´47.5%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ™ºèƒ½å†œåœºç›‘æµ‹ç³»ç»Ÿåœ¨é¢å¯¹ç½‘ç»œæ”»å‡»å’Œèƒ½æºæ³¢åŠ¨æ—¶çš„éŸ§æ€§å’Œé€‚åº”æ€§ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨åŠ¨æ€ç¯å¢ƒä¸‹çš„è¡¨ç°ä¸ä½³ï¼Œå¯¼è‡´ç›‘æµ‹æ•ˆæœå’Œèƒ½æºåˆ©ç”¨æ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¯æŒç»­çš„æ™ºèƒ½å†œåœºç½‘ç»œï¼Œé€šè¿‡æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDRLï¼‰åˆ¶å®šæœ€ä½³ç›‘æµ‹ç­–ç•¥ï¼ŒåŒæ—¶ç»“åˆå†³ç­–ç†è®ºï¼ˆDTï¼‰å’Œè¿ç§»å­¦ä¹ ï¼ˆTLï¼‰æ¥åŠ é€Ÿå­¦ä¹ è¿‡ç¨‹ï¼Œä»¥æé«˜ç³»ç»Ÿçš„å“åº”èƒ½åŠ›å’Œæ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é‡‡é›†æ¨¡å—ã€æ·±åº¦å¼ºåŒ–å­¦ä¹ æ¨¡å—å’Œå†³ç­–ç†è®ºæ¨¡å—ã€‚æ•°æ®é‡‡é›†æ¨¡å—é€šè¿‡ä¼ æ„Ÿå™¨æ”¶é›†ç¯å¢ƒå’ŒåŠ¨ç‰©çŠ¶æ€æ•°æ®ï¼ŒDRLæ¨¡å—ç”¨äºç­–ç•¥ä¼˜åŒ–ï¼Œè€ŒDTæ¨¡å—åˆ™æä¾›å†³ç­–æ”¯æŒï¼Œç¡®ä¿åœ¨ä¸åŒæ¡ä»¶ä¸‹çš„ç›‘æµ‹è´¨é‡å’Œèƒ½æºæ•ˆç‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†å†³ç­–ç†è®ºä¸æ·±åº¦å¼ºåŒ–å­¦ä¹ ç›¸ç»“åˆï¼Œå½¢æˆDTå¼•å¯¼çš„DRLæ¨¡å‹ã€‚è¿™ä¸€æ–¹æ³•æ˜¾è‘—æé«˜äº†å­¦ä¹ é€Ÿåº¦å’Œç³»ç»Ÿæ€§èƒ½ï¼Œå…‹æœäº†ä¼ ç»ŸDRLæ¨¡å‹çš„æ”¶æ•›é€Ÿåº¦æ…¢çš„é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡ç›‘æµ‹æ•ˆæœä¸èƒ½æºæ¶ˆè€—ï¼Œå¹¶ä¼˜åŒ–äº†ç½‘ç»œç»“æ„ä»¥é€‚åº”åŠ¨æ€ç¯å¢ƒçš„å˜åŒ–ã€‚å…³é”®å‚æ•°è®¾ç½®ç»è¿‡å¤šæ¬¡å®éªŒè°ƒæ•´ï¼Œä»¥ç¡®ä¿æ¨¡å‹çš„ç¨³å®šæ€§å’Œé«˜æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒDTå¼•å¯¼çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ æ¨¡å‹åœ¨ç³»ç»Ÿæ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„TLå¢å¼ºDRLæ¨¡å‹ï¼Œè®­ç»ƒæ—¶é—´å‡å°‘äº†47.5%ã€‚è¿™ä¸€æˆæœå±•ç¤ºäº†æ–°æ–¹æ³•åœ¨æé«˜ç›‘æµ‹è´¨é‡å’Œèƒ½æºæ•ˆç‡æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œå…·æœ‰é‡è¦çš„å®é™…åº”ç”¨ä»·å€¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å†œä¸šã€ç¯å¢ƒç›‘æµ‹å’ŒåŠ¨ç‰©å¥åº·ç®¡ç†ç­‰ã€‚é€šè¿‡æé«˜æ™ºèƒ½å†œåœºç½‘ç»œçš„éŸ§æ€§å’Œæ•ˆç‡ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡å†œä¸šç”Ÿäº§çš„å¯æŒç»­æ€§å’Œç»æµæ•ˆç›Šï¼Œæœªæ¥å¯èƒ½å¯¹å†œä¸šç®¡ç†å’Œå†³ç­–æ”¯æŒç³»ç»Ÿäº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Solar sensor-based monitoring systems have become a crucial agricultural innovation, advancing farm management and animal welfare through integrating sensor technology, Internet-of-Things, and edge and cloud computing. However, the resilience of these systems to cyber-attacks and their adaptability to dynamic and constrained energy supplies remain largely unexplored. To address these challenges, we propose a sustainable smart farm network designed to maintain high-quality animal monitoring under various cyber and adversarial threats, as well as fluctuating energy conditions. Our approach utilizes deep reinforcement learning (DRL) to devise optimal policies that maximize both monitoring effectiveness and energy efficiency. To overcome DRL's inherent challenge of slow convergence, we integrate transfer learning (TL) and decision theory (DT) to accelerate the learning process. By incorporating DT-guided strategies, we optimize monitoring quality and energy sustainability, significantly reducing training time while achieving comparable performance rewards. Our experimental results prove that DT-guided DRL outperforms TL-enhanced DRL models, improving system performance and reducing training runtime by 47.5%.

