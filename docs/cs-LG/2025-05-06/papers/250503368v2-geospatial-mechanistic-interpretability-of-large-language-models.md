---
layout: default
title: Geospatial Mechanistic Interpretability of Large Language Models
---

# Geospatial Mechanistic Interpretability of Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.03368" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.03368v2</a>
  <a href="https://arxiv.org/pdf/2505.03368.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.03368v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.03368v2', 'Geospatial Mechanistic Interpretability of Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Stef De Sabbata, Stefano Mizzaro, Kevin Roitero

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-06 (æ›´æ–°: 2025-05-12)

**å¤‡æ³¨**: Figures 2 and 3: fixed issue with min boundary in colorbar

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåœ°ç†ç©ºé—´æœºåˆ¶å¯è§£é‡Šæ€§æ¡†æ¶ä»¥è§£æå¤§å‹è¯­è¨€æ¨¡å‹çš„åœ°ç†ä¿¡æ¯å¤„ç†**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `åœ°ç†ç©ºé—´åˆ†æ` `æœºåˆ¶å¯è§£é‡Šæ€§` `ç©ºé—´è‡ªç›¸å…³æ€§` `ç¨€ç–è‡ªç¼–ç å™¨` `åœ°ç†ä¿¡æ¯å¤„ç†` `å†…éƒ¨è¡¨ç¤º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç ”ç©¶å¯¹å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åœ°ç†ä¿¡æ¯å¤„ç†ä¸­çš„å†…éƒ¨æœºåˆ¶äº†è§£ä¸è¶³ï¼Œç¼ºä¹æœ‰æ•ˆçš„è§£ææ–¹æ³•ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åœ°ç†ç©ºé—´æœºåˆ¶å¯è§£é‡Šæ€§æ¡†æ¶ï¼Œé€šè¿‡ç©ºé—´åˆ†æåå‘å·¥ç¨‹LLMsçš„åœ°ç†ä¿¡æ¯å¤„ç†æ–¹å¼ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œåœ°åç‰¹å¾çš„ç©ºé—´æ¨¡å¼ä¸å…¶åœ°ç†ä½ç½®ç›¸å…³ï¼Œæä¾›äº†å¯¹æ¨¡å‹å¤„ç†åœ°ç†ä¿¡æ¯çš„æ–°è§è§£ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­å±•ç°äº†å‰æ‰€æœªæœ‰çš„èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨æ–‡æœ¬å’Œä»£ç ç”Ÿæˆæ–¹é¢ã€‚ç„¶è€Œï¼Œå…³äºè¿™äº›æ¨¡å‹å¦‚ä½•å¤„ç†åœ°ç†ä¿¡æ¯çš„å†…éƒ¨æœºåˆ¶ä»ç„¶çŸ¥ä¹‹ç”šå°‘ã€‚æœ¬æ–‡å»ºç«‹äº†ä¸€ç§æ–°çš„åœ°ç†ç©ºé—´æœºåˆ¶å¯è§£é‡Šæ€§æ¡†æ¶ï¼Œé€šè¿‡ç©ºé—´åˆ†æåå‘å·¥ç¨‹LLMså¤„ç†åœ°ç†ä¿¡æ¯çš„æ–¹å¼ï¼Œæ—¨åœ¨åŠ æ·±å¯¹è¿™äº›å¤æ‚æ¨¡å‹åœ¨å¤„ç†åœ°ç†ä¿¡æ¯æ—¶ç”Ÿæˆçš„å†…éƒ¨è¡¨ç¤ºçš„ç†è§£ã€‚æˆ‘ä»¬ä½¿ç”¨æ¢æµ‹æŠ€æœ¯æ­ç¤ºLLMså†…éƒ¨ç»“æ„ï¼Œå¹¶å¼•å…¥æœºåˆ¶å¯è§£é‡Šæ€§é¢†åŸŸï¼Œè®¨è®ºç¨€ç–è‡ªç¼–ç å™¨åœ¨è§£å¼€å¤šä¹‰å†…éƒ¨è¡¨ç¤ºä¸­çš„ä½œç”¨ã€‚å®éªŒä¸­ï¼Œæˆ‘ä»¬åˆ©ç”¨ç©ºé—´è‡ªç›¸å…³æ€§å±•ç¤ºåœ°åç‰¹å¾çš„ç©ºé—´æ¨¡å¼ï¼Œä»è€Œæä¾›å¯¹æ¨¡å‹å¤„ç†åœ°ç†ä¿¡æ¯çš„æ´å¯Ÿã€‚æœ€åï¼Œè®¨è®ºè¯¥æ¡†æ¶å¦‚ä½•æ¨åŠ¨åŸºç¡€æ¨¡å‹åœ¨åœ°ç†å­¦ä¸­çš„ç ”ç©¶ä¸åº”ç”¨ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤„ç†åœ°ç†ä¿¡æ¯æ—¶çš„å†…éƒ¨æœºåˆ¶ç¼ºä¹ç†è§£çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆè§£æè¿™äº›æ¨¡å‹å¦‚ä½•ç”Ÿæˆå’Œå¤„ç†åœ°ç†ä¿¡æ¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºé€šè¿‡åœ°ç†ç©ºé—´æœºåˆ¶å¯è§£é‡Šæ€§æ¡†æ¶ï¼Œåˆ©ç”¨ç©ºé—´åˆ†ææŠ€æœ¯åå‘å·¥ç¨‹LLMsçš„åœ°ç†ä¿¡æ¯å¤„ç†è¿‡ç¨‹ï¼Œæ—¨åœ¨æ­ç¤ºå…¶å†…éƒ¨è¡¨ç¤ºçš„ç‰¹å¾ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä½¿ç”¨æ¢æµ‹æŠ€æœ¯æ­ç¤ºLLMsçš„å†…éƒ¨ç»“æ„ï¼Œç»“åˆæœºåˆ¶å¯è§£é‡Šæ€§ç†è®ºï¼Œåˆ©ç”¨ç¨€ç–è‡ªç¼–ç å™¨è§£å¼€å¤šä¹‰è¡¨ç¤ºï¼Œæœ€ç»ˆé€šè¿‡ç©ºé—´è‡ªç›¸å…³æ€§åˆ†æåœ°åç‰¹å¾ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†ç©ºé—´åˆ†æä¸æœºåˆ¶å¯è§£é‡Šæ€§ç»“åˆï¼Œæä¾›äº†ä¸€ç§æ–°çš„è§†è§’æ¥ç†è§£LLMså¦‚ä½•å¤„ç†åœ°ç†ä¿¡æ¯ï¼ŒåŒºåˆ«äºä¼ ç»Ÿçš„é»‘ç®±æ¨¡å‹åˆ†ææ–¹æ³•ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨ç¨€ç–è‡ªç¼–ç å™¨ä»¥æå–å•ä¹‰ç‰¹å¾ï¼Œå¹¶é€šè¿‡ç©ºé—´è‡ªç›¸å…³æ€§åˆ†æåœ°åç‰¹å¾çš„ç©ºé—´æ¨¡å¼ï¼Œç¡®ä¿æ¨¡å‹è¾“å‡ºä¸åœ°ç†ä½ç½®çš„ç›¸å…³æ€§ã€‚å®éªŒè®¾è®¡ä¸­å…³æ³¨ç‰¹å¾çš„å¯è§£é‡Šæ€§ä¸ç©ºé—´ä¸€è‡´æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ°åç‰¹å¾çš„ç©ºé—´æ¨¡å¼ä¸å…¶åœ°ç†ä½ç½®é«˜åº¦ç›¸å…³ï¼ŒéªŒè¯äº†æ‰€æå‡ºæ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚é€šè¿‡ç©ºé—´è‡ªç›¸å…³æ€§åˆ†æï¼Œæ¨¡å‹åœ¨åœ°ç†ä¿¡æ¯å¤„ç†ä¸Šçš„å¯è§£é‡Šæ€§æ˜¾è‘—æå‡ï¼Œä¸ºåç»­ç ”ç©¶æä¾›äº†æ–°çš„æ–¹å‘ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åœ°ç†ä¿¡æ¯ç³»ç»Ÿï¼ˆGISï¼‰ã€æ™ºèƒ½åŸå¸‚è§„åˆ’ã€ç¯å¢ƒç›‘æµ‹ç­‰ã€‚é€šè¿‡æ·±å…¥ç†è§£LLMsåœ¨åœ°ç†ä¿¡æ¯å¤„ç†ä¸­çš„æœºåˆ¶ï¼Œå¯ä»¥æå‡æ¨¡å‹åœ¨åœ°ç†é¢†åŸŸçš„åº”ç”¨æ•ˆæœï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ä¸åˆ›æ–°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have demonstrated unprecedented capabilities across various natural language processing tasks. Their ability to process and generate viable text and code has made them ubiquitous in many fields, while their deployment as knowledge bases and "reasoning" tools remains an area of ongoing research. In geography, a growing body of literature has been focusing on evaluating LLMs' geographical knowledge and their ability to perform spatial reasoning. However, very little is still known about the internal functioning of these models, especially about how they process geographical information.
>   In this chapter, we establish a novel framework for the study of geospatial mechanistic interpretability - using spatial analysis to reverse engineer how LLMs handle geographical information. Our aim is to advance our understanding of the internal representations that these complex models generate while processing geographical information - what one might call "how LLMs think about geographic information" if such phrasing was not an undue anthropomorphism.
>   We first outline the use of probing in revealing internal structures within LLMs. We then introduce the field of mechanistic interpretability, discussing the superposition hypothesis and the role of sparse autoencoders in disentangling polysemantic internal representations of LLMs into more interpretable, monosemantic features. In our experiments, we use spatial autocorrelation to show how features obtained for placenames display spatial patterns related to their geographic location and can thus be interpreted geospatially, providing insights into how these models process geographical information. We conclude by discussing how our framework can help shape the study and use of foundation models in geography.

