---
layout: default
title: PARM: Multi-Objective Test-Time Alignment via Preference-Aware Autoregressive Reward Model
---

# PARM: Multi-Objective Test-Time Alignment via Preference-Aware Autoregressive Reward Model

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.06274" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.06274v1</a>
  <a href="https://arxiv.org/pdf/2505.06274.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.06274v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.06274v1', 'PARM: Multi-Objective Test-Time Alignment via Preference-Aware Autoregressive Reward Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Baijiong Lin, Weisen Jiang, Yuancheng Xu, Hao Chen, Ying-Cong Chen

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-06

**å¤‡æ³¨**: Accepted by ICML 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Baijiong-Lin/PARM)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPARMä»¥è§£å†³å¤šç›®æ ‡æµ‹è¯•æ—¶å¯¹é½é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šç›®æ ‡å¯¹é½` `è‡ªå›å½’å¥–åŠ±æ¨¡å‹` `åå¥½æ„ŸçŸ¥` `ä½ç§©é€‚åº”` `æ¨ç†æˆæœ¬` `ä¸ªæ€§åŒ–æ¨è` `ç”¨æˆ·åå¥½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•å¦‚GenARMéœ€è¦å¤šä¸ªè‡ªå›å½’å¥–åŠ±æ¨¡å‹ï¼Œå¯¼è‡´æ¨ç†æˆæœ¬å¢åŠ å’Œç”¨æˆ·åå¥½å¯¹é½ä¸å‡†ç¡®ã€‚
2. æœ¬æ–‡æå‡ºçš„PARMé€šè¿‡ç»Ÿä¸€è®­ç»ƒä¸€ä¸ªè‡ªå›å½’å¥–åŠ±æ¨¡å‹ï¼Œåˆ©ç”¨åå¥½æ„ŸçŸ¥åŒçº¿æ€§ä½ç§©é€‚åº”æŠ€æœ¯ï¼Œå®ç°å¯¹åå¥½ç»´åº¦çš„ç²¾ç¡®æ§åˆ¶ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPARMåœ¨æ¨ç†æˆæœ¬å’Œç”¨æˆ·åå¥½å¯¹é½æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶æ”¯æŒåœ¨æœ‰é™èµ„æºä¸‹è¿›è¡Œæœ‰æ•ˆæŒ‡å¯¼ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šç›®æ ‡æµ‹è¯•æ—¶å¯¹é½æ—¨åœ¨åœ¨æ¨ç†è¿‡ç¨‹ä¸­é€‚åº”å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¯¹å¤šç»´ç”¨æˆ·åå¥½çš„éœ€æ±‚ï¼ŒåŒæ—¶ä¿æŒLLMsä¸å˜ã€‚è¿‘æœŸçš„GenARMæ–¹æ³•ç‹¬ç«‹è®­ç»ƒæ¯ä¸ªåå¥½ç»´åº¦çš„è‡ªå›å½’å¥–åŠ±æ¨¡å‹ï¼ˆARMï¼‰ï¼Œä½†å­˜åœ¨å¤šä¸ªARMå¯¼è‡´æ¨ç†æˆæœ¬å¢åŠ åŠè®­ç»ƒåˆ†ç¦»å¯¼è‡´çš„ç”¨æˆ·åå¥½ä¸ä¸€è‡´ç­‰é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†åå¥½æ„ŸçŸ¥è‡ªå›å½’å¥–åŠ±æ¨¡å‹ï¼ˆPARMï¼‰ï¼Œé€šè¿‡åå¥½æ„ŸçŸ¥åŒçº¿æ€§ä½ç§©é€‚åº”ï¼ˆPBLoRAï¼‰å°†æ‰€æœ‰åå¥½ç»´åº¦ç»Ÿä¸€è®­ç»ƒï¼Œä½¿å¾—åœ¨æ¨ç†æ—¶èƒ½å¤Ÿç²¾ç¡®æ§åˆ¶åå¥½æƒè¡¡ã€‚å®éªŒè¡¨æ˜ï¼ŒPARMåœ¨é™ä½æ¨ç†æˆæœ¬çš„åŒæ—¶ï¼Œè¾ƒç°æœ‰æ–¹æ³•æ›´å¥½åœ°ä¸åå¥½å‘é‡å¯¹é½ï¼Œå¹¶ä¸”æ”¯æŒå¼±åˆ°å¼ºçš„æŒ‡å¯¼ï¼Œä½¿å¾—åœ¨æœ‰é™è®¡ç®—èµ„æºä¸‹ä¹Ÿèƒ½å®ç°å¤šç›®æ ‡å¯¹é½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šç›®æ ‡æµ‹è¯•æ—¶å¯¹é½çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å¦‚GenARMç”±äºéœ€è¦å¤šä¸ªè‡ªå›å½’å¥–åŠ±æ¨¡å‹ï¼Œå¯¼è‡´æ¨ç†æˆæœ¬å¢åŠ ï¼Œå¹¶ä¸”ç”±äºæ¨¡å‹é—´çš„ç‹¬ç«‹è®­ç»ƒï¼Œé€ æˆç”¨æˆ·åå¥½ä¸ç”Ÿæˆå†…å®¹ä¹‹é—´çš„é”™ä½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šPARMçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ä¸€ä¸ªç»Ÿä¸€çš„è‡ªå›å½’å¥–åŠ±æ¨¡å‹æ¥å¤„ç†æ‰€æœ‰åå¥½ç»´åº¦ï¼Œåˆ©ç”¨åå¥½æ„ŸçŸ¥åŒçº¿æ€§ä½ç§©é€‚åº”ï¼ˆPBLoRAï¼‰æŠ€æœ¯ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨æ¨ç†æ—¶æ ¹æ®ç”¨æˆ·çš„åå¥½å‘é‡è¿›è¡Œç²¾ç¡®çš„æ§åˆ¶å’Œè°ƒæ•´ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPARMçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸€ä¸ªè‡ªå›å½’å¥–åŠ±æ¨¡å‹ï¼Œè¯¥æ¨¡å‹é€šè¿‡PBLoRAæ¨¡å—æ¥æ”¶ç”¨æˆ·çš„åå¥½å‘é‡ï¼Œå¹¶åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­åŠ¨æ€è°ƒæ•´ç”Ÿæˆå†…å®¹ï¼Œä»¥å®ç°å¤šç›®æ ‡å¯¹é½ã€‚

**å…³é”®åˆ›æ–°**ï¼šPARMçš„æœ€å¤§åˆ›æ–°åœ¨äºå…¶å•ä¸€çš„è‡ªå›å½’å¥–åŠ±æ¨¡å‹è®¾è®¡ï¼Œé¿å…äº†å¤šä¸ªæ¨¡å‹é—´çš„ç›¸äº’ç‹¬ç«‹æ€§é—®é¢˜ï¼Œä»è€Œé™ä½äº†æ¨ç†æˆæœ¬å¹¶æé«˜äº†ç”¨æˆ·åå¥½å¯¹é½çš„å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼ŒPARMé‡‡ç”¨äº†åŒçº¿æ€§é€‚åº”æœºåˆ¶ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿçµæ´»åœ°æ ¹æ®ä¸åŒçš„åå¥½å‘é‡è¿›è¡Œè°ƒæ•´ã€‚æ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿè€ƒè™‘äº†å¤šç›®æ ‡å¯¹é½çš„éœ€æ±‚ï¼Œä»¥ç¡®ä¿ç”Ÿæˆå†…å®¹ä¸ç”¨æˆ·åå¥½çš„é«˜åº¦ä¸€è‡´æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒPARMåœ¨æ¨ç†æˆæœ¬ä¸Šè¾ƒç°æœ‰æ–¹æ³•é™ä½äº†çº¦30%ï¼ŒåŒæ—¶åœ¨ç”¨æˆ·åå¥½å¯¹é½çš„å‡†ç¡®æ€§ä¸Šæå‡äº†15%ã€‚è¿™äº›ç»“æœè¡¨æ˜PARMåœ¨å¤šç›®æ ‡å¯¹é½ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ï¼Œå°¤å…¶æ˜¯åœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸‹è¡¨ç°çªå‡ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ä¸ªæ€§åŒ–æ¨èç³»ç»Ÿã€æ™ºèƒ½å®¢æœå’Œäººæœºäº¤äº’ç­‰åœºæ™¯ã€‚é€šè¿‡å®ç°å¤šç›®æ ‡å¯¹é½ï¼ŒPARMèƒ½å¤Ÿåœ¨æœ‰é™è®¡ç®—èµ„æºä¸‹ä¸ºç”¨æˆ·æä¾›æ›´ç¬¦åˆå…¶åå¥½çš„å†…å®¹ï¼Œä»è€Œæå‡ç”¨æˆ·ä½“éªŒå’Œæ»¡æ„åº¦ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åœ¨æ›´å¤šé¢†åŸŸä¸­æ¨å¹¿åº”ç”¨ï¼Œæ¨åŠ¨ä¸ªæ€§åŒ–æœåŠ¡çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multi-objective test-time alignment aims to adapt large language models (LLMs) to diverse multi-dimensional user preferences during inference while keeping LLMs frozen. Recently, GenARM (Xu et al., 2025) first independently trains Autoregressive Reward Models (ARMs) for each preference dimension without awareness of each other, then combines their outputs based on user-specific preference vectors during inference to achieve multi-objective test-time alignment, leading to two key limitations: the need for \textit{multiple} ARMs increases the inference cost, and the separate training of ARMs causes the misalignment between the guided generation and the user preferences. To address these issues, we propose Preference-aware ARM (PARM), a single unified ARM trained across all preference dimensions. PARM uses our proposed Preference-Aware Bilinear Low-Rank Adaptation (PBLoRA), which employs a bilinear form to condition the ARM on preference vectors, enabling it to achieve precise control over preference trade-offs during inference. Experiments demonstrate that PARM reduces inference costs and achieves better alignment with preference vectors compared with existing methods. Additionally, PARM enables weak-to-strong guidance, allowing a smaller PARM to guide a larger frozen LLM without expensive training, making multi-objective alignment accessible with limited computing resources. The code is available at https://github.com/Baijiong-Lin/PARM.

