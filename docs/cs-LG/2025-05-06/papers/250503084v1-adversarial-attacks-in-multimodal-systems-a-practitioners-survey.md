---
layout: default
title: Adversarial Attacks in Multimodal Systems: A Practitioner's Survey
---

# Adversarial Attacks in Multimodal Systems: A Practitioner's Survey

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.03084" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.03084v1</a>
  <a href="https://arxiv.org/pdf/2505.03084.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.03084v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.03084v1', 'Adversarial Attacks in Multimodal Systems: A Practitioner\'s Survey')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shashank Kapoor, Sanjay Surendranath Girija, Lakshit Arora, Dipen Pradhan, Ankit Shetgaonkar, Aman Raj

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-06

**å¤‡æ³¨**: Accepted in IEEE COMPSAC 2025

**æœŸåˆŠ**: 2025 IEEE 49th Annual Computers, Software, and Applications Conference (COMPSAC)

**DOI**: [10.1109/COMPSAC65507.2025.00222](https://doi.org/10.1109/COMPSAC65507.2025.00222)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è°ƒæŸ¥å¤šæ¨¡æ€ç³»ç»Ÿä¸­çš„å¯¹æŠ—æ”»å‡»ä»¥å¡«è¡¥å®è·µè€…è§†è§’çš„ç©ºç™½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€ç³»ç»Ÿ` `å¯¹æŠ—æ”»å‡»` `å®‰å…¨æ€§` `æœºå™¨å­¦ä¹ ` `å®è·µè€…è§†è§’` `å¨èƒåˆ†æ` `å¼€æºæ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç ”ç©¶å¯¹å¤šæ¨¡æ€ç³»ç»Ÿä¸­çš„å¯¹æŠ—æ”»å‡»ç¼ºä¹ç³»ç»Ÿæ€§çš„æ€»ç»“ï¼Œå°¤å…¶æ˜¯é’ˆå¯¹å®è·µè€…çš„è§†è§’ã€‚
2. æœ¬æ–‡é€šè¿‡è°ƒæŸ¥æ–‡æœ¬ã€å›¾åƒã€è§†é¢‘å’ŒéŸ³é¢‘çš„å¯¹æŠ—æ”»å‡»ï¼Œæä¾›äº†ä¸€ä¸ªå…¨é¢çš„å¨èƒæ™¯è§‚è§†å›¾ã€‚
3. è¯¥ç ”ç©¶ä¸ºæœºå™¨å­¦ä¹ å®è·µè€…æä¾›äº†å¿…è¦çš„çŸ¥è¯†ï¼Œä»¥ä¾¿åœ¨å®é™…åº”ç”¨ä¸­é‡‡å–é¢„é˜²æªæ–½ï¼Œé™ä½å¯¹æŠ—æ”»å‡»çš„é£é™©ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€æ¨¡å‹çš„å¼•å…¥æ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸçš„ä¸€å¤§è¿›æ­¥ï¼Œè¿™äº›æ¨¡å‹èƒ½å¤Ÿç†è§£æ–‡æœ¬ã€å›¾åƒã€è§†é¢‘å’ŒéŸ³é¢‘ç­‰å¤šç§æ¨¡æ€ã€‚å°½ç®¡å¼€æºå¤šæ¨¡æ€æ¨¡å‹ä½¿å¾—è¿™äº›çªç ´æ›´ä¸ºæ™®åŠï¼Œä½†å®ƒä»¬ä¹Ÿç»§æ‰¿äº†å„æ¨¡æ€çš„è„†å¼±æ€§ï¼Œå¯¼è‡´å¯¹æŠ—å¨èƒçš„åŠ å‰§ã€‚ç°æœ‰ç ”ç©¶è™½ç„¶æ¶µç›–äº†å¤šæ¨¡æ€ä¸­çš„æ”»å‡»ç±»å‹ï¼Œä½†ç¼ºä¹é’ˆå¯¹å®è·µè€…çš„ç»¼åˆè§†è§’ã€‚æœ¬æ–‡é€šè¿‡è°ƒæŸ¥é’ˆå¯¹æ–‡æœ¬ã€å›¾åƒã€è§†é¢‘å’ŒéŸ³é¢‘çš„å¯¹æŠ—æ”»å‡»ï¼Œå¡«è¡¥äº†è¿™ä¸€ç©ºç™½ï¼Œé¦–æ¬¡å…¨é¢æ€»ç»“äº†å¤šæ¨¡æ€ä¸–ç•Œä¸­çš„å¨èƒæ™¯è§‚ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€ç³»ç»Ÿä¸­å¯¹æŠ—æ”»å‡»çš„ç³»ç»Ÿæ€§æ€»ç»“é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹é’ˆå¯¹å®è·µè€…çš„è§†è§’ï¼Œæ— æ³•æœ‰æ•ˆæŒ‡å¯¼å®é™…åº”ç”¨ä¸­çš„é˜²æŠ¤æªæ–½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡é€šè¿‡å¯¹å¤šæ¨¡æ€ç³»ç»Ÿä¸­å„ç±»å¯¹æŠ—æ”»å‡»è¿›è¡Œå…¨é¢è°ƒæŸ¥ï¼Œæä¾›äº†ä¸€ä¸ªæ¸…æ™°çš„å¨èƒæ™¯è§‚ï¼Œå¸®åŠ©å®è·µè€…ç†è§£å’Œåº”å¯¹è¿™äº›æ”»å‡»ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¯¹æ–‡æœ¬ã€å›¾åƒã€è§†é¢‘å’ŒéŸ³é¢‘å››ç§æ¨¡æ€çš„å¯¹æŠ—æ”»å‡»ç±»å‹çš„åˆ†ç±»ä¸åˆ†æï¼Œç»“åˆç›¸å…³æ–‡çŒ®å’Œæ¡ˆä¾‹è¿›è¡Œæ·±å…¥æ¢è®¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶é¦–æ¬¡ä»å®è·µè€…çš„è§’åº¦ç³»ç»Ÿæ€»ç»“äº†å¤šæ¨¡æ€å¯¹æŠ—æ”»å‡»çš„å¨èƒæ™¯è§‚ï¼Œå¡«è¡¥äº†ç°æœ‰æ–‡çŒ®çš„ç©ºç™½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è°ƒæŸ¥è¿‡ç¨‹ä¸­ï¼Œè®ºæ–‡è¯¦ç»†åˆ†æäº†æ¯ç§æ¨¡æ€çš„æ”»å‡»æ–¹å¼ã€å½±å“åŠé˜²æŠ¤ç­–ç•¥ï¼Œç¡®ä¿ä¿¡æ¯çš„å…¨é¢æ€§å’Œå®ç”¨æ€§ã€‚é€šè¿‡å¯¹æ¯”ç°æœ‰ç ”ç©¶ï¼Œæå‡ºäº†æ›´å…·é’ˆå¯¹æ€§çš„é˜²æŠ¤å»ºè®®ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

æœ¬æ–‡é€šè¿‡å¯¹å¤šæ¨¡æ€ç³»ç»Ÿä¸­çš„å¯¹æŠ—æ”»å‡»è¿›è¡Œå…¨é¢è°ƒæŸ¥ï¼Œé¦–æ¬¡æä¾›äº†é’ˆå¯¹æ–‡æœ¬ã€å›¾åƒã€è§†é¢‘å’ŒéŸ³é¢‘çš„æ”»å‡»ç±»å‹çš„ç³»ç»Ÿæ€§æ€»ç»“ï¼Œä¸ºå®è·µè€…æä¾›äº†é‡è¦çš„å‚è€ƒä¾æ®ã€‚ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼Œç†è§£å’Œåº”å¯¹è¿™äº›æ”»å‡»èƒ½å¤Ÿæ˜¾è‘—æå‡å¤šæ¨¡æ€ç³»ç»Ÿçš„å®‰å…¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å®‰å…¨æ•æ„Ÿçš„å¤šæ¨¡æ€äººå·¥æ™ºèƒ½ç³»ç»Ÿï¼Œå¦‚è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½ç›‘æ§å’Œè¯­éŸ³åŠ©æ‰‹ç­‰ã€‚é€šè¿‡æé«˜å¯¹æŠ—æ”»å‡»çš„é˜²æŠ¤èƒ½åŠ›ï¼Œèƒ½å¤Ÿå¢å¼ºè¿™äº›ç³»ç»Ÿåœ¨å®é™…åº”ç”¨ä¸­çš„å®‰å…¨æ€§å’Œå¯é æ€§ï¼Œæ¨åŠ¨å¤šæ¨¡æ€æŠ€æœ¯çš„å¹¿æ³›åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The introduction of multimodal models is a huge step forward in Artificial Intelligence. A single model is trained to understand multiple modalities: text, image, video, and audio. Open-source multimodal models have made these breakthroughs more accessible. However, considering the vast landscape of adversarial attacks across these modalities, these models also inherit vulnerabilities of all the modalities, and ultimately, the adversarial threat amplifies. While broad research is available on possible attacks within or across these modalities, a practitioner-focused view that outlines attack types remains absent in the multimodal world. As more Machine Learning Practitioners adopt, fine-tune, and deploy open-source models in real-world applications, it's crucial that they can view the threat landscape and take the preventive actions necessary. This paper addresses the gap by surveying adversarial attacks targeting all four modalities: text, image, video, and audio. This survey provides a view of the adversarial attack landscape and presents how multimodal adversarial threats have evolved. To the best of our knowledge, this survey is the first comprehensive summarization of the threat landscape in the multimodal world.

