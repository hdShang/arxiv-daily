---
layout: default
title: Unraveling the Rainbow: can value-based methods schedule?
---

# Unraveling the Rainbow: can value-based methods schedule?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.03323" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.03323v2</a>
  <a href="https://arxiv.org/pdf/2505.03323.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.03323v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.03323v2', 'Unraveling the Rainbow: can value-based methods schedule?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Arthur CorrÃªa, Alexandre Jesus, Paulo Nascimento, CristÃ³vÃ£o Silva, Samuel Moniz

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-06 (æ›´æ–°: 2025-11-27)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/AJ-Correa/Unraveling-the-Rainbow)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºä»·å€¼çš„æ–¹æ³•ä»¥è§£å†³ä½œä¸šè°ƒåº¦é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æ·±åº¦å¼ºåŒ–å­¦ä¹ ` `ä½œä¸šè°ƒåº¦` `ä»·å€¼åŸºç®—æ³•` `ç­–ç•¥æ¢¯åº¦ç®—æ³•` `ç»„åˆä¼˜åŒ–` `å·¥ä¸šåº”ç”¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç»„åˆä¼˜åŒ–æ–¹æ³•ä¸»è¦ä¾èµ–ç­–ç•¥æ¢¯åº¦ç®—æ³•ï¼Œå¿½è§†äº†ä»·å€¼åŸºç®—æ³•çš„æ½œåŠ›ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡æ·±åº¦å¼ºåŒ–å­¦ä¹ ä¸­çš„ä»·å€¼åŸºç®—æ³•æ¥è§£å†³ä½œä¸šè°ƒåº¦é—®é¢˜ï¼Œå±•ç¤ºå…¶åœ¨ç¨³å®šæ€§å’Œæ³›åŒ–èƒ½åŠ›ä¸Šçš„ä¼˜åŠ¿ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œä»·å€¼åŸºç®—æ³•åœ¨å¤šä¸ªè°ƒåº¦å®ä¾‹ä¸Šè¡¨ç°å‡ºæ›´ä½çš„æ–¹å·®å’Œæ›´å¥½çš„æ”¶æ•›æ€§ï¼ŒæŒ‘æˆ˜äº†ä¼ ç»Ÿè§‚ç‚¹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶å¯¹å¤šç§æ·±åº¦å¼ºåŒ–å­¦ä¹ ç®—æ³•åœ¨ä½œä¸šè½¦é—´å’Œçµæ´»ä½œä¸šè½¦é—´è°ƒåº¦é—®é¢˜ä¸Šçš„è¡¨ç°è¿›è¡Œäº†å¹¿æ³›çš„å®è¯ç ”ç©¶ã€‚è¿™ä¸¤ä¸ªé—®é¢˜æ˜¯å…·æœ‰å¤šç§å·¥ä¸šåº”ç”¨çš„åŸºæœ¬æŒ‘æˆ˜ã€‚å°½ç®¡ä»·å€¼åŸºç®—æ³•åœ¨æŸäº›é¢†åŸŸå–å¾—äº†æ˜¾è‘—æˆåŠŸï¼Œä½†ç»„åˆä¼˜åŒ–é¢†åŸŸä¸»è¦åå‘äºç­–ç•¥æ¢¯åº¦ç®—æ³•ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œä»·å€¼åŸºç®—æ³•åœ¨æ–¹å·®å’Œæ”¶æ•›ç¨³å®šæ€§æ–¹é¢è¡¨ç°æ›´ä½³ï¼Œå¹¶ä¸”åœ¨è·¨è§„æ¨¡å’Œè·¨åˆ†å¸ƒçš„æ³›åŒ–èƒ½åŠ›ä¸Šä¼˜äºç­–ç•¥æ¢¯åº¦ç®—æ³•ã€‚æ­¤å¤–ï¼Œç®—æ³•çš„ç›¸å¯¹æ€§èƒ½å¯èƒ½ä¾èµ–äºé—®é¢˜çš„ç»“æ„ç‰¹æ€§ï¼Œå¦‚çµæ´»æ€§å’Œå®ä¾‹å¤§å°ã€‚æˆ‘ä»¬çš„å‘ç°æŒ‘æˆ˜äº†ç­–ç•¥æ¢¯åº¦ç®—æ³•åœ¨ç»„åˆä¼˜åŒ–ä¸­ä¼˜è¶Šæ€§çš„æ™®éå‡è®¾ï¼Œè¡¨æ˜ä»·å€¼åŸºç®—æ³•åŒæ ·å€¼å¾—å…³æ³¨ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ä½œä¸šè½¦é—´å’Œçµæ´»ä½œä¸šè½¦é—´è°ƒåº¦é—®é¢˜ï¼Œè¿™äº›é—®é¢˜åœ¨å·¥ä¸šåº”ç”¨ä¸­å…·æœ‰é‡è¦æ„ä¹‰ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–ç­–ç•¥æ¢¯åº¦ç®—æ³•ï¼Œå¯¼è‡´å¯¹ä»·å€¼åŸºç®—æ³•çš„æ½œåŠ›è®¤è¯†ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ·±åº¦å¼ºåŒ–å­¦ä¹ ä¸­çš„ä»·å€¼åŸºç®—æ³•ï¼Œå±•ç¤ºå…¶åœ¨è°ƒåº¦é—®é¢˜ä¸Šçš„æœ‰æ•ˆæ€§ï¼Œå°¤å…¶æ˜¯åœ¨ç¨³å®šæ€§å’Œæ³›åŒ–èƒ½åŠ›æ–¹é¢çš„ä¼˜åŠ¿ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œæ€§èƒ½è¯„ä¼°ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œå¯¹è°ƒåº¦å®ä¾‹è¿›è¡Œç‰¹å¾æå–ï¼Œç„¶åä½¿ç”¨ä»·å€¼åŸºç®—æ³•è¿›è¡Œè®­ç»ƒï¼Œæœ€åè¯„ä¼°æ¨¡å‹åœ¨ä¸åŒè§„æ¨¡å’Œåˆ†å¸ƒä¸Šçš„è¡¨ç°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºè¯æ˜äº†ä»·å€¼åŸºç®—æ³•åœ¨ç»„åˆä¼˜åŒ–é—®é¢˜ä¸Šå¯ä»¥ä¸ç­–ç•¥æ¢¯åº¦ç®—æ³•ç›¸åª²ç¾ï¼Œç”šè‡³è¶…è¶Šå…¶æ€§èƒ½ï¼ŒæŒ‘æˆ˜äº†ä¼ ç»Ÿçš„ç®—æ³•ä¼˜è¶Šæ€§å‡è®¾ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ï¼Œä»¥ä¼˜åŒ–ä»·å€¼åŸºç®—æ³•çš„è¡¨ç°ï¼Œå¹¶è¿›è¡Œäº†å‚æ•°è°ƒä¼˜ä»¥æé«˜æ”¶æ•›é€Ÿåº¦å’Œç¨³å®šæ€§ã€‚å…·ä½“ç»†èŠ‚åŒ…æ‹¬ä½¿ç”¨ç»éªŒå›æ”¾å’Œç›®æ ‡ç½‘ç»œç­‰æŠ€æœ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œä»·å€¼åŸºç®—æ³•åœ¨å¤šä¸ªè°ƒåº¦å®ä¾‹ä¸Šè¡¨ç°å‡ºæ›´ä½çš„æ–¹å·®å’Œæ›´å¥½çš„æ”¶æ•›æ€§ï¼Œç›¸æ¯”äºç­–ç•¥æ¢¯åº¦ç®—æ³•ï¼Œä»·å€¼åŸºç®—æ³•åœ¨è·¨è§„æ¨¡å’Œè·¨åˆ†å¸ƒçš„æ³›åŒ–èƒ½åŠ›ä¸Šæœ‰æ˜¾è‘—æå‡ï¼ŒæŒ‘æˆ˜äº†ä¼ ç»Ÿè§‚ç‚¹ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åˆ¶é€ ä¸šè°ƒåº¦ã€ç‰©æµä¼˜åŒ–å’Œèµ„æºåˆ†é…ç­‰å¤šä¸ªå·¥ä¸šåœºæ™¯ã€‚é€šè¿‡æé«˜è°ƒåº¦æ•ˆç‡ï¼Œä¼ä¸šå¯ä»¥é™ä½æˆæœ¬ã€æé«˜ç”Ÿäº§åŠ›ï¼Œè¿›è€Œåœ¨ç«äº‰ä¸­è·å¾—ä¼˜åŠ¿ã€‚æœªæ¥ï¼Œä»·å€¼åŸºç®—æ³•çš„è¿›ä¸€æ­¥ç ”ç©¶å¯èƒ½ä¼šæ¨åŠ¨æ›´å¤šå¤æ‚è°ƒåº¦é—®é¢˜çš„è§£å†³ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In this work, we conduct an extensive empirical study of several deep reinforcement learning algorithms on two challenging combinatorial optimization problems: the job-shop and flexible job-shop scheduling problems, both fundamental challenges with multiple industrial applications. Broadly, deep reinforcement learning algorithms fall into two categories: policy-gradient and value-based. While value-based algorithms have achieved notable success in domains such as the Arcade Learning Environment, the combinatorial optimization community has predominantly favored policy-gradient algorithms, often overlooking the potential of value-based alternatives. From our results, value-based algorithms demonstrated a lower variance and a more stable convergence profile compared to policy-gradient ones. Moreover, they achieved superior cross-size and cross-distribution generalization, that is, effectively solving instances that are substantially larger or structurally distinct from those seen during training. Finally, our analysis also suggests that the relative performance of each category of algorithms may be dependent on structural properties of the problem, such as problem flexibility and instance size. Overall, our findings challenge the prevailing assumption that policy-gradient algorithms are inherently superior for combinatorial optimization. We show instead that value-based algorithms can match or even surpass the performance of policy-gradient algorithms, suggesting that they deserve greater attention from the combinatorial optimization community. Our code is openly available at: https://github.com/AJ-Correa/Unraveling-the-Rainbow

