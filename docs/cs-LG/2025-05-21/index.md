---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.LG - 2025-05-21
---

# cs.LGï¼ˆ2025-05-21ï¼‰

ğŸ“Š å…± **9** ç¯‡è®ºæ–‡
 | ğŸ”— **4** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (6 ğŸ”—2)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2 ğŸ”—2)</a>
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (6 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250514999v3-learning-to-rank-chain-of-thought-using-a-small-model.html">Learning to Rank Chain-of-Thought: Using a Small Model</a></td>
  <td>æå‡ºèƒ½é‡ç»“æœå¥–åŠ±æ¨¡å‹ä»¥æé«˜æ•°å­¦æ¨ç†çš„å‡†ç¡®æ€§</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14999v3" data-paper-url="./papers/250514999v3-learning-to-rank-chain-of-thought-using-a-small-model.html" onclick="toggleFavorite(this, '2505.14999v3', 'Learning to Rank Chain-of-Thought: Using a Small Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250515072v2-motime-a-dataset-suite-for-multimodal-time-series-forecasting.html">MoTime: A Dataset Suite for Multimodal Time Series Forecasting</a></td>
  <td>æå‡ºMoTimeæ•°æ®é›†ä»¥è§£å†³å¤šæ¨¡æ€æ—¶é—´åºåˆ—é¢„æµ‹é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.15072v2" data-paper-url="./papers/250515072v2-motime-a-dataset-suite-for-multimodal-time-series-forecasting.html" onclick="toggleFavorite(this, '2505.15072v2', 'MoTime: A Dataset Suite for Multimodal Time Series Forecasting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250515030v3-harnessing-on-device-large-language-model-empirical-results-and-impl.html">Harnessing On-Device Large Language Model: Empirical Results and Implications for AI PC</a></td>
  <td>æå‡ºç³»ç»ŸåŒ–æ–¹æ³•è¯„ä¼°è¾¹ç¼˜è®¾å¤‡ä¸Šçš„å¤§å‹è¯­è¨€æ¨¡å‹æ€§èƒ½</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.15030v3" data-paper-url="./papers/250515030v3-harnessing-on-device-large-language-model-empirical-results-and-impl.html" onclick="toggleFavorite(this, '2505.15030v3', 'Harnessing On-Device Large Language Model: Empirical Results and Implications for AI PC')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250611036v1-human-centered-interactive-learning-via-mllms-for-text-to-image-pers.html">Human-centered Interactive Learning via MLLMs for Text-to-Image Person Re-identification</a></td>
  <td>æå‡ºäººæœ¬äº¤äº’å­¦ä¹ æ¡†æ¶ä»¥æå‡æ–‡æœ¬åˆ°å›¾åƒçš„è¡Œäººé‡è¯†åˆ«æ•ˆæœ</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.11036v1" data-paper-url="./papers/250611036v1-human-centered-interactive-learning-via-mllms-for-text-to-image-pers.html" onclick="toggleFavorite(this, '2506.11036v1', 'Human-centered Interactive Learning via MLLMs for Text-to-Image Person Re-identification')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250515064v3-why-and-when-deep-is-better-than-shallow-an-implementation-agnostic-.html">Why and When Deep is Better than Shallow: An Implementation-Agnostic State-Transition View of Depth Supremacy</a></td>
  <td>æå‡ºæ·±åº¦ä¼˜äºæµ…å±‚çš„ç†è®ºæ¡†æ¶ä»¥è§£å†³æ¨¡å‹æ³›åŒ–é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.15064v3" data-paper-url="./papers/250515064v3-why-and-when-deep-is-better-than-shallow-an-implementation-agnostic-.html" onclick="toggleFavorite(this, '2505.15064v3', 'Why and When Deep is Better than Shallow: An Implementation-Agnostic State-Transition View of Depth Supremacy')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250515047v2-piflow-principle-aware-scientific-discovery-with-multi-agent-collabo.html">PiFlow: Principle-aware Scientific Discovery with Multi-Agent Collaboration</a></td>
  <td>æå‡ºPiFlowä»¥è§£å†³ç§‘å­¦å‘ç°ä¸­çš„ä¸ç¡®å®šæ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.15047v2" data-paper-url="./papers/250515047v2-piflow-principle-aware-scientific-discovery-with-multi-agent-collabo.html" onclick="toggleFavorite(this, '2505.15047v2', 'PiFlow: Principle-aware Scientific Discovery with Multi-Agent Collaboration')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>7</td>
  <td><a href="./papers/250515040v1-rlbenchnet-the-right-network-for-the-right-reinforcement-learning-ta.html">RLBenchNet: The Right Network for the Right Reinforcement Learning Task</a></td>
  <td>æå‡ºRLBenchNetä»¥ä¼˜åŒ–å¼ºåŒ–å­¦ä¹ ä»»åŠ¡ä¸­çš„ç½‘ç»œé€‰æ‹©</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">Mamba</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.15040v1" data-paper-url="./papers/250515040v1-rlbenchnet-the-right-network-for-the-right-reinforcement-learning-ta.html" onclick="toggleFavorite(this, '2505.15040v1', 'RLBenchNet: The Right Network for the Right Reinforcement Learning Task')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250515034v2-rl-tango-reinforcing-generator-and-verifier-together-for-language-re.html">RL Tango: Reinforcing Generator and Verifier Together for Language Reasoning</a></td>
  <td>æå‡ºTangoæ¡†æ¶ä»¥è§£å†³LLMæ¨ç†èƒ½åŠ›ä¸è¶³é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.15034v2" data-paper-url="./papers/250515034v2-rl-tango-reinforcing-generator-and-verifier-together-for-language-re.html" onclick="toggleFavorite(this, '2505.15034v2', 'RL Tango: Reinforcing Generator and Verifier Together for Language Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>9</td>
  <td><a href="./papers/250517092v1-covert-attacks-on-machine-learning-training-in-passively-secure-mpc.html">Covert Attacks on Machine Learning Training in Passively Secure MPC</a></td>
  <td>æå‡ºæœ‰æ•ˆæ”»å‡»ä»¥æ­ç¤ºè¢«åŠ¨å®‰å…¨MPCè®­ç»ƒä¸­çš„éšæ‚£</td>
  <td class="tags-cell"><span class="paper-tag">MPC</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.17092v1" data-paper-url="./papers/250517092v1-covert-attacks-on-machine-learning-training-in-passively-secure-mpc.html" onclick="toggleFavorite(this, '2505.17092v1', 'Covert Attacks on Machine Learning Training in Passively Secure MPC')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.LG é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)