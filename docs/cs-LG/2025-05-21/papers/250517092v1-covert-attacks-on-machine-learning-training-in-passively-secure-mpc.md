---
layout: default
title: Covert Attacks on Machine Learning Training in Passively Secure MPC
---

# Covert Attacks on Machine Learning Training in Passively Secure MPC

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.17092" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.17092v1</a>
  <a href="https://arxiv.org/pdf/2505.17092.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.17092v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.17092v1', 'Covert Attacks on Machine Learning Training in Passively Secure MPC')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Matthew Jagielski, Daniel Escudero, Rahul Rachuri, Peter Scholl

**åˆ†ç±»**: cs.CR, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-21

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæœ‰æ•ˆæ”»å‡»ä»¥æ­ç¤ºè¢«åŠ¨å®‰å…¨MPCè®­ç»ƒä¸­çš„éšæ‚£**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `å®‰å…¨å¤šæ–¹è®¡ç®—` `æœºå™¨å­¦ä¹ ` `éšç§ä¿æŠ¤` `ä¸»åŠ¨å®‰å…¨åè®®` `æ•°æ®é‡æ„` `æ¨¡å‹å®Œæ•´æ€§` `æ”»å‡»æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¢«åŠ¨å®‰å…¨MPCè®­ç»ƒåè®®æœªèƒ½æœ‰æ•ˆé˜²èŒƒä¸»åŠ¨å¯¹æ‰‹çš„æ”»å‡»ï¼Œå¯¼è‡´æ¨¡å‹çš„å®Œæ•´æ€§å’Œéšç§æ€§å—åˆ°å¨èƒã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„æ”»å‡»æ–¹æ³•ï¼Œä¸»åŠ¨å¯¹æ‰‹å¯ä»¥åœ¨ä¸è¢«æ£€æµ‹çš„æƒ…å†µä¸‹ç ´åMPCè®­ç»ƒè¿‡ç¨‹ï¼Œé‡æ„è®­ç»ƒæ•°æ®ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ”»å‡»èƒ½å¤ŸæˆåŠŸåœ°å½±å“æ¨¡å‹çš„è®­ç»ƒï¼Œæ˜¾ç¤ºå‡ºè¢«åŠ¨å®‰å…¨åè®®çš„è„†å¼±æ€§ï¼Œå‘¼åä½¿ç”¨æ›´å®‰å…¨çš„ä¸»åŠ¨åè®®ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å®‰å…¨å¤šæ–¹è®¡ç®—ï¼ˆMPCï¼‰å…è®¸æ•°æ®æ‹¥æœ‰è€…åœ¨ä¿æŒè®­ç»ƒæ•°æ®ç§å¯†çš„æƒ…å†µä¸‹ï¼ŒåŸºäºè”åˆæ•°æ®è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹ã€‚ç°æœ‰çš„MPCå¨èƒæ¨¡å‹è€ƒè™‘äº†è¢«åŠ¨è…è´¥çš„å¯¹æ‰‹ï¼Œä½†æœ¬ç ”ç©¶å±•ç¤ºäº†ä¸»åŠ¨å¯¹æ‰‹å¯ä»¥åœ¨è¢«åŠ¨å®‰å…¨çš„MPCè®­ç»ƒåè®®ä¸­å®æ–½çš„æœ‰æ•ˆæ”»å‡»ï¼Œè¿™äº›æ”»å‡»å‡ ä¹æ²¡æœ‰è¢«æ£€æµ‹åˆ°çš„é£é™©ã€‚è¿™äº›æ”»å‡»ä¸ä»…å±åŠæ¨¡å‹çš„å®Œæ•´æ€§ï¼Œè¿˜å¯èƒ½é‡æ„å‡ºç²¾ç¡®çš„è®­ç»ƒæ•°æ®ã€‚ç ”ç©¶ç»“æœæŒ‘æˆ˜äº†åœ¨éšç§ä¿æŠ¤æœºå™¨å­¦ä¹ ï¼ˆPPMLï¼‰èƒŒæ™¯ä¸‹ï¼Œè®¤ä¸ºä¸åŒ…å«æ¶æ„è¡Œä¸ºçš„å¨èƒæ¨¡å‹æ˜¯åˆç†çš„è§‚ç‚¹ï¼Œå¼ºè°ƒäº†ä½¿ç”¨ä¸»åŠ¨å®‰å…¨åè®®è¿›è¡Œè®­ç»ƒçš„å¿…è¦æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³è¢«åŠ¨å®‰å…¨çš„MPCè®­ç»ƒåè®®åœ¨é¢å¯¹ä¸»åŠ¨å¯¹æ‰‹æ—¶çš„è„†å¼±æ€§ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½è€ƒè™‘æ¶æ„è¡Œä¸ºï¼Œå¯¼è‡´æ¨¡å‹çš„éšç§å’Œå®Œæ•´æ€§å—åˆ°å¨èƒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å±•ç¤ºä¸»åŠ¨å¯¹æ‰‹å¦‚ä½•åœ¨è¢«åŠ¨å®‰å…¨çš„MPCåè®®ä¸­å®æ–½æ”»å‡»ï¼Œåˆ©ç”¨åè®®è®¾è®¡çš„æ¼æ´è¿›è¡Œæ•°æ®é‡æ„å’Œæ¨¡å‹æ“æ§ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œç ”ç©¶è€…æ­ç¤ºäº†ç°æœ‰å®‰å…¨æ¨¡å‹çš„ä¸è¶³ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ”»å‡»æ¨¡å‹çš„è®¾è®¡ã€æ”»å‡»å®æ–½çš„æ­¥éª¤ä»¥åŠå¯¹æ¨¡å‹å®Œæ•´æ€§å’Œéšç§æ€§çš„è¯„ä¼°ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ”»å‡»è€…æ¨¡å‹ã€è¢«æ”»å‡»çš„MPCåè®®ä»¥åŠè¯„ä¼°æœºåˆ¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†å…·ä½“çš„æ”»å‡»ç­–ç•¥ï¼Œèƒ½å¤Ÿåœ¨ä¸è¢«æ£€æµ‹çš„æƒ…å†µä¸‹æœ‰æ•ˆç ´åMPCè®­ç»ƒè¿‡ç¨‹ã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºï¼Œç°æœ‰æ–¹æ³•é€šå¸¸å‡è®¾å‚ä¸æ–¹æ˜¯è¯šå®çš„ï¼Œè€Œæœ¬ç ”ç©¶åˆ™æ­ç¤ºäº†è¿™ä¸€å‡è®¾çš„è„†å¼±æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬å¯¹æ”»å‡»å‚æ•°çš„é€‰æ‹©ã€æ”»å‡»å®æ–½çš„æ—¶æœºä»¥åŠå¯¹MPCåè®®çš„å…·ä½“æ“ä½œç»†èŠ‚ã€‚è¿™äº›è®¾è®¡ç¡®ä¿äº†æ”»å‡»çš„éšè”½æ€§å’Œæœ‰æ•ˆæ€§ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å’Œè¯„ä¼°æŒ‡æ ‡ä¹Ÿè¢«ç²¾å¿ƒè®¾è®¡ï¼Œä»¥ä¾¿å‡†ç¡®è¯„ä¼°æ”»å‡»æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæå‡ºçš„æ”»å‡»æ–¹æ³•èƒ½å¤Ÿåœ¨ä¸è¢«æ£€æµ‹çš„æƒ…å†µä¸‹æˆåŠŸé‡æ„è®­ç»ƒæ•°æ®ï¼Œå½±å“æ¨¡å‹çš„è®­ç»ƒæ•ˆæœã€‚ä¸ä¼ ç»Ÿè¢«åŠ¨å®‰å…¨åè®®ç›¸æ¯”ï¼Œæ”»å‡»æˆåŠŸç‡æ˜¾è‘—æé«˜ï¼Œè¡¨æ˜ç°æœ‰åè®®åœ¨é¢å¯¹ä¸»åŠ¨å¯¹æ‰‹æ—¶çš„è„†å¼±æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨åœºæ™¯åŒ…æ‹¬é‡‘èæ•°æ®åˆ†æã€åŒ»ç–—æ•°æ®å…±äº«ä»¥åŠå…¶ä»–éœ€è¦ä¿æŠ¤éšç§çš„å¤šæ–¹è®¡ç®—ç¯å¢ƒã€‚é€šè¿‡æ­ç¤ºè¢«åŠ¨å®‰å…¨MPCçš„è„†å¼±æ€§ï¼Œä¿ƒä½¿ç ”ç©¶è€…å’Œå¼€å‘è€…åœ¨å®é™…åº”ç”¨ä¸­é‡‡ç”¨æ›´ä¸ºå®‰å…¨çš„ä¸»åŠ¨å®‰å…¨åè®®ï¼Œä»è€Œæé«˜æ•°æ®éšç§ä¿æŠ¤çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Secure multiparty computation (MPC) allows data owners to train machine learning models on combined data while keeping the underlying training data private. The MPC threat model either considers an adversary who passively corrupts some parties without affecting their overall behavior, or an adversary who actively modifies the behavior of corrupt parties. It has been argued that in some settings, active security is not a major concern, partly because of the potential risk of reputation loss if a party is detected cheating.
>   In this work we show explicit, simple, and effective attacks that an active adversary can run on existing passively secure MPC training protocols, while keeping essentially zero risk of the attack being detected. The attacks we show can compromise both the integrity and privacy of the model, including attacks reconstructing exact training data. Our results challenge the belief that a threat model that does not include malicious behavior by the involved parties may be reasonable in the context of PPML, motivating the use of actively secure protocols for training.

