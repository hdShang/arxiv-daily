---
layout: default
title: "RL Tango: Reinforcing Generator and Verifier Together for Language Reasoning"
---

# RL Tango: Reinforcing Generator and Verifier Together for Language Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.15034" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.15034v2</a>
  <a href="https://arxiv.org/pdf/2505.15034.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.15034v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.15034v2', 'RL Tango: Reinforcing Generator and Verifier Together for Language Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kaiwen Zha, Zhengqi Gao, Maohao Shen, Zhang-Wei Hong, Duane S. Boning, Dina Katabi

**åˆ†ç±»**: cs.LG, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-21 (æ›´æ–°: 2025-10-23)

**å¤‡æ³¨**: NeurIPS 2025. The first two authors contributed equally

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/kaiwenzha/rl-tango)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTangoæ¡†æ¶ä»¥è§£å†³LLMæ¨ç†èƒ½åŠ›ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `è¯­è¨€æ¨¡å‹` `æ¨ç†èƒ½åŠ›` `ç”Ÿæˆå¼éªŒè¯å™¨` `äº’ç›¸å¼ºåŒ–` `æ•°å­¦åŸºå‡†` `è¿‡ç¨‹çº§éªŒè¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„LLMåè®­ç»ƒæ–¹æ³•é€šå¸¸ä¾èµ–å›ºå®šçš„éªŒè¯å™¨ï¼Œå¯¼è‡´å¥–åŠ±é»‘å®¢å’Œæ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚
2. Tangoæ¡†æ¶é€šè¿‡å¼ºåŒ–å­¦ä¹ åŒæ—¶è®­ç»ƒç”Ÿæˆå™¨å’ŒéªŒè¯å™¨ï¼Œé‡‡ç”¨ç”Ÿæˆå¼éªŒè¯å™¨ä»¥å¢å¼ºäº’ç›¸å¼ºåŒ–çš„æ•ˆæœã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œç”Ÿæˆå™¨åœ¨å¤šä¸ªæ•°å­¦åŸºå‡†å’Œæ¨ç†ä»»åŠ¡ä¸­è¡¨ç°æœ€ä½³ï¼ŒéªŒè¯å™¨åœ¨ProcessBenchæ•°æ®é›†ä¸Šè¡¨ç°çªå‡ºã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æœ€è¿‘æˆä¸ºå¢å¼ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ¨ç†èƒ½åŠ›çš„æœ‰æ•ˆæ–¹æ³•ï¼Œå…¶ä¸­LLMç”Ÿæˆå™¨ä½œä¸ºç”±éªŒè¯å™¨ï¼ˆå¥–åŠ±æ¨¡å‹ï¼‰æŒ‡å¯¼çš„ç­–ç•¥ã€‚ç„¶è€Œï¼Œç°æœ‰çš„LLMåè®­ç»ƒæ–¹æ³•é€šå¸¸ä½¿ç”¨å›ºå®šçš„éªŒè¯å™¨ï¼Œå®¹æ˜“å—åˆ°å¥–åŠ±é»‘å®¢æ”»å‡»ï¼Œå¹¶ä¸”åœ¨è®­ç»ƒåˆ†å¸ƒä¹‹å¤–çš„æ³›åŒ–èƒ½åŠ›è¾ƒå·®ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†Tangoï¼Œä¸€ä¸ªæ–°é¢–çš„æ¡†æ¶ï¼Œé€šè¿‡RLåŒæ—¶è®­ç»ƒLLMç”Ÿæˆå™¨å’ŒéªŒè¯å™¨ã€‚Tangoçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶ç”Ÿæˆå¼çš„è¿‡ç¨‹çº§LLMéªŒè¯å™¨ï¼Œè¯¥éªŒè¯å™¨é€šè¿‡RLè®­ç»ƒï¼Œå¹¶ä¸ç”Ÿæˆå™¨å…±åŒè¿›åŒ–ã€‚éªŒè¯å™¨ä»…åŸºäºç»“æœçº§éªŒè¯æ­£ç¡®æ€§å¥–åŠ±è¿›è¡Œè®­ç»ƒï¼Œæ— éœ€æ˜¾å¼çš„è¿‡ç¨‹çº§æ³¨é‡Šã€‚å®éªŒè¡¨æ˜ï¼ŒTangoçš„ä¸¤ä¸ªç»„ä»¶åœ¨7B/8Bè§„æ¨¡æ¨¡å‹ä¸­å‡å®ç°äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œç”Ÿæˆå™¨åœ¨äº”ä¸ªæ•°å­¦åŸºå‡†å’Œå››ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œè€ŒéªŒè¯å™¨åœ¨ProcessBenchæ•°æ®é›†ä¸Šé¢†å…ˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰LLMåè®­ç»ƒæ–¹æ³•ä¸­éªŒè¯å™¨å›ºå®šå¯¼è‡´çš„å¥–åŠ±é»‘å®¢å’Œæ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºè§„åˆ™åŸºç¡€æˆ–ç›‘ç£å¾®è°ƒçš„éªŒè¯å™¨ï¼Œé™åˆ¶äº†æ¨¡å‹çš„é€‚åº”æ€§å’Œé²æ£’æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šTangoæ¡†æ¶çš„æ ¸å¿ƒåœ¨äºé€šè¿‡å¼ºåŒ–å­¦ä¹ åŒæ—¶è®­ç»ƒç”Ÿæˆå™¨å’ŒéªŒè¯å™¨ï¼Œé‡‡ç”¨ç”Ÿæˆå¼çš„è¿‡ç¨‹çº§éªŒè¯å™¨ï¼Œä½¿å…¶ä¸ç”Ÿæˆå™¨å…±åŒè¿›åŒ–ï¼Œæå‡äº†æ¨¡å‹çš„æ•´ä½“æ¨ç†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTangoçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ç”Ÿæˆå™¨å’ŒéªŒè¯å™¨ä¸¤ä¸ªä¸»è¦æ¨¡å—ã€‚ç”Ÿæˆå™¨è´Ÿè´£ç”Ÿæˆæ¨ç†ç»“æœï¼Œè€ŒéªŒè¯å™¨åˆ™å¯¹ç”Ÿæˆçš„ç»“æœè¿›è¡Œè¯„ä¼°å’Œåé¦ˆã€‚ä¸¤è€…é€šè¿‡å¼ºåŒ–å­¦ä¹ çš„æ–¹å¼è¿›è¡Œäº¤äº’å’Œä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šTangoçš„æœ€é‡è¦åˆ›æ–°åœ¨äºå…¶ç”Ÿæˆå¼çš„è¿‡ç¨‹çº§éªŒè¯å™¨ï¼Œè¯¥éªŒè¯å™¨é€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼Œèƒ½å¤Ÿåœ¨æ²¡æœ‰æ˜¾å¼è¿‡ç¨‹çº§æ³¨é‡Šçš„æƒ…å†µä¸‹è¿›è¡Œæœ‰æ•ˆçš„ç»“æœéªŒè¯ã€‚è¿™ä¸€è®¾è®¡æ˜¾è‘—æé«˜äº†éªŒè¯å™¨çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒéªŒè¯å™¨çš„è®­ç»ƒä»…ä¾èµ–äºç»“æœçº§çš„éªŒè¯æ­£ç¡®æ€§å¥–åŠ±ï¼Œé¿å…äº†å¯¹è¿‡ç¨‹çº§æ³¨é‡Šçš„éœ€æ±‚ã€‚æ­¤å¤–ï¼Œæ¨¡å‹çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡ä¹Ÿç»è¿‡ç²¾å¿ƒè°ƒæ•´ï¼Œä»¥ç¡®ä¿ç”Ÿæˆå™¨å’ŒéªŒè¯å™¨çš„æœ‰æ•ˆååŒè®­ç»ƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTangoçš„ç”Ÿæˆå™¨åœ¨äº”ä¸ªæ•°å­¦åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°æœ€ä½³ï¼Œå¹¶åœ¨å››ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„æ¨ç†ä»»åŠ¡ä¸­å–å¾—äº†é¢†å…ˆåœ°ä½ã€‚éªŒè¯å™¨åœ¨ProcessBenchæ•°æ®é›†ä¸Šä¹Ÿè¡¨ç°çªå‡ºï¼Œæ•´ä½“æ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰çš„åŸºçº¿æ–¹æ³•ï¼Œå°¤å…¶åœ¨æœ€å›°éš¾çš„æ•°å­¦æ¨ç†é—®é¢˜ä¸Šå–å¾—äº†æ˜¾è‘—æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€é‡‘èå’Œç§‘å­¦ç ”ç©¶ç­‰éœ€è¦å¤æ‚æ¨ç†çš„åœºæ™¯ã€‚é€šè¿‡æå‡LLMçš„æ¨ç†èƒ½åŠ›ï¼ŒTangoæ¡†æ¶å¯ä»¥å¸®åŠ©ç”¨æˆ·æ›´é«˜æ•ˆåœ°è§£å†³æ•°å­¦é—®é¢˜ã€è¿›è¡Œæ•°æ®åˆ†æå’Œç”Ÿæˆå†³ç­–æ”¯æŒï¼Œä»è€Œåœ¨å®é™…åº”ç”¨ä¸­åˆ›é€ æ›´å¤§çš„ä»·å€¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Reinforcement learning (RL) has recently emerged as a compelling approach for enhancing the reasoning capabilities of large language models (LLMs), where an LLM generator serves as a policy guided by a verifier (reward model). However, current RL post-training methods for LLMs typically use verifiers that are fixed (rule-based or frozen pretrained) or trained discriminatively via supervised fine-tuning (SFT). Such designs are susceptible to reward hacking and generalize poorly beyond their training distributions. To overcome these limitations, we propose Tango, a novel framework that uses RL to concurrently train both an LLM generator and a verifier in an interleaved manner. A central innovation of Tango is its generative, process-level LLM verifier, which is trained via RL and co-evolves with the generator. Importantly, the verifier is trained solely based on outcome-level verification correctness rewards without requiring explicit process-level annotations. This generative RL-trained verifier exhibits improved robustness and superior generalization compared to deterministic or SFT-trained verifiers, fostering effective mutual reinforcement with the generator. Extensive experiments demonstrate that both components of Tango achieve state-of-the-art results among 7B/8B-scale models: the generator attains best-in-class performance across five competition-level math benchmarks and four challenging out-of-domain reasoning tasks, while the verifier leads on the ProcessBench dataset. Remarkably, both components exhibit particularly substantial improvements on the most difficult mathematical reasoning problems. Code is at: https://github.com/kaiwenzha/rl-tango.

