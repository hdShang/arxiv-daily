---
layout: default
title: "LLINBO: Trustworthy LLM-in-the-Loop Bayesian Optimization"
---

# LLINBO: Trustworthy LLM-in-the-Loop Bayesian Optimization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14756" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.14756v2</a>
  <a href="https://arxiv.org/pdf/2505.14756.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14756v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14756v2', 'LLINBO: Trustworthy LLM-in-the-Loop Bayesian Optimization')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Chih-Yu Chang, Milad Azvar, Chinedum Okwudire, Raed Al Kontar

**ÂàÜÁ±ª**: cs.LG, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-20 (Êõ¥Êñ∞: 2025-10-09)

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/UMDataScienceLab/LLM-in-the-Loop-BO)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫LLINBO‰ª•Ëß£ÂÜ≥LLMÂú®Ë¥ùÂè∂ÊñØ‰ºòÂåñ‰∏≠ÁöÑ‰∏çÁ°ÆÂÆöÊÄßÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Ë¥ùÂè∂ÊñØ‰ºòÂåñ` `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `È´òÊñØËøáÁ®ã` `ÈªëÁÆ±‰ºòÂåñ` `‰∏çÁ°ÆÂÆöÊÄßÂª∫Ê®°` `3DÊâìÂç∞` `Ê∑∑ÂêàÊ°ÜÊû∂`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ï‰æùËµñLLMsËøõË°å‰ºòÂåñÔºå‰ΩÜÁº∫‰πèÊòéÁ°ÆÁöÑÊõø‰ª£Âª∫Ê®°ÂíåÊ†°ÂáÜÁöÑ‰∏çÁ°ÆÂÆöÊÄßÔºåÂØºËá¥Êé¢Á¥¢‰∏éÂà©Áî®ÁöÑÊùÉË°°Èöæ‰ª•ÊéßÂà∂„ÄÇ
2. Êú¨ÊñáÊèêÂá∫LLINBOÊ°ÜÊû∂ÔºåÂ∞ÜLLMs‰∏éÁªüËÆ°Êõø‰ª£Ê®°ÂûãÁõ∏ÁªìÂêàÔºåÂà©Áî®LLMsÁöÑ‰∏ä‰∏ãÊñáÊé®ÁêÜËÉΩÂäõËøõË°åÊó©ÊúüÊé¢Á¥¢„ÄÇ
3. Âú®3DÊâìÂç∞ÁöÑÂÆûÈôÖÂ∫îÁî®‰∏≠ÔºåLLINBOÂ±ïÁ§∫‰∫ÜÂÖ∂ÊúâÊïàÊÄßÔºåÊèê‰æõ‰∫ÜÁêÜËÆ∫‰øùËØÅÂπ∂ÂÆûÁé∞‰∫Ü‰ºòÂåñÊÄßËÉΩÁöÑÊèêÂçá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Ë¥ùÂè∂ÊñØ‰ºòÂåñÔºàBOÔºâÊòØ‰∏ÄÁßçÂπøÊ≥õÁî®‰∫é‰ºòÂåñÊòÇË¥µÈªëÁÆ±ÂáΩÊï∞ÁöÑÂ∫èÂàóÂÜ≥Á≠ñÂ∑•ÂÖ∑„ÄÇËøëÂπ¥Êù•ÔºåÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂú®‰ΩéÊï∞ÊçÆÁéØÂ¢É‰∏ãË°®Áé∞Âá∫ÊòæËëóÁöÑÈÄÇÂ∫îÊÄßÔºå‰ΩøÂÖ∂Êàê‰∏∫ÈªëÁÆ±‰ºòÂåñÁöÑÊúâÂâçÊôØÂ∑•ÂÖ∑„ÄÇÁÑ∂ËÄåÔºåÂçïÈù†LLMs‰Ωú‰∏∫‰ºòÂåñ‰ª£ÁêÜÂ≠òÂú®È£éÈô©Ôºå‰∏ªË¶ÅÁî±‰∫éÁº∫‰πèÊòéÁ°ÆÁöÑÊõø‰ª£Âª∫Ê®°ÂíåÊ†°ÂáÜÁöÑ‰∏çÁ°ÆÂÆöÊÄß„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏ÄÈóÆÈ¢òÔºåÊú¨ÊñáÊèêÂá∫‰∫ÜLLINBOÔºöLLM-in-the-Loop BOÔºå‰∏Ä‰∏™Â∞ÜLLMs‰∏éÁªüËÆ°Êõø‰ª£‰∏ìÂÆ∂ÔºàÂ¶ÇÈ´òÊñØËøáÁ®ãÔºâÁªìÂêàÁöÑÊ∑∑ÂêàÊ°ÜÊû∂„ÄÇËØ•Ê°ÜÊû∂Âà©Áî®LLMsÁöÑ‰∏ä‰∏ãÊñáÊé®ÁêÜËÉΩÂäõËøõË°åÊó©ÊúüÊé¢Á¥¢ÔºåÂêåÊó∂‰æùËµñ‰∫éÂéüÂàôÊÄßÁöÑÁªüËÆ°Ê®°ÂûãÊù•ÊåáÂØºÈ´òÊïàÁöÑÂà©Áî®„ÄÇÊúÄÂêéÔºåÊú¨ÊñáÂú®3DÊâìÂç∞ÁöÑÂÆûÈôÖÂ∫îÁî®‰∏≠ËøõË°å‰∫ÜÊ¶ÇÂøµÈ™åËØÅ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥LLMsÂú®Ë¥ùÂè∂ÊñØ‰ºòÂåñ‰∏≠ÁöÑ‰∏çÁ°ÆÂÆöÊÄßÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÁº∫‰πèÊòéÁ°ÆÁöÑÊõø‰ª£Âª∫Ê®°ÔºåÂØºËá¥Êé¢Á¥¢‰∏éÂà©Áî®ÁöÑÊùÉË°°Èöæ‰ª•ÊéßÂà∂ÔºåÂΩ±Âìç‰∫Ü‰ºòÂåñÁöÑÂèØÈù†ÊÄßÂíåÁêÜËÆ∫ÂèØË°åÊÄß„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöLLINBOÊ°ÜÊû∂ÁöÑÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÂ∞ÜLLMsÁöÑ‰∏ä‰∏ãÊñáÊé®ÁêÜËÉΩÂäõ‰∏éÁªüËÆ°Êõø‰ª£Ê®°ÂûãÔºàÂ¶ÇÈ´òÊñØËøáÁ®ãÔºâÁªìÂêàÔºåÂà©Áî®LLMsËøõË°åÊó©ÊúüÊé¢Á¥¢ÔºåÂêåÊó∂ÈÄöËøáÁªüËÆ°Ê®°ÂûãÊåáÂØºÂêéÁª≠ÁöÑÈ´òÊïàÂà©Áî®„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöLLINBOÊ°ÜÊû∂ÂåÖÊã¨‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) LLMsÁî®‰∫éÁîüÊàêÈ´òË¥®ÈáèÁöÑÊü•ËØ¢ÁÇπÔºõ2) ÁªüËÆ°Êõø‰ª£Ê®°ÂûãÁî®‰∫éÂª∫Ê®°ÁõÆÊ†áÂáΩÊï∞Âπ∂Êèê‰æõ‰∏çÁ°ÆÂÆöÊÄßËØÑ‰º∞Ôºõ3) ÁªìÂêà‰∏§ËÄÖÁöÑÊú∫Âà∂‰ª•‰ºòÂåñÊé¢Á¥¢‰∏éÂà©Áî®ÁöÑÂπ≥Ë°°„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éÂ∞ÜLLMs‰∏éÁªüËÆ°Ê®°ÂûãÁöÑÁªìÂêàÔºåÂΩ¢Êàê‰∫Ü‰∏Ä‰∏™Ê∑∑Âêà‰ºòÂåñÊ°ÜÊû∂„ÄÇËøôÁßçËÆæËÆ°‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üÂú®‰∏çÁ°ÆÂÆöÊÄßËæÉÈ´òÁöÑÊÉÖÂÜµ‰∏ãËøõË°åÊúâÊïàÁöÑÂÜ≥Á≠ñÔºåÂÖãÊúç‰∫ÜÂçï‰∏Ä‰æùËµñLLMsÁöÑÂ±ÄÈôêÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÂÆûÁé∞‰∏≠ÔºåÂÖ≥ÈîÆÂèÇÊï∞ÂåÖÊã¨LLMsÁöÑ‰∏ä‰∏ãÊñáÁ™óÂè£Â§ßÂ∞èÂíåÈ´òÊñØËøáÁ®ãÁöÑË∂ÖÂèÇÊï∞ËÆæÁΩÆ„ÄÇÊçüÂ§±ÂáΩÊï∞ËÆæËÆ°‰∏äÔºåÁªìÂêà‰∫ÜÊé¢Á¥¢‰∏éÂà©Áî®ÁöÑÊùÉË°°Ôºå‰ª•Á°Æ‰øù‰ºòÂåñËøáÁ®ãÁöÑÁ®≥ÂÆöÊÄßÂíåÊïàÁéá„ÄÇÂÖ∑‰ΩìÁöÑÁΩëÁªúÁªìÊûÑÂíåÂèÇÊï∞ËÆæÁΩÆÂú®ÂÆûÈ™åÈÉ®ÂàÜËøõË°å‰∫ÜËØ¶ÁªÜÊèèËø∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®3DÊâìÂç∞ÁöÑÂÆûÈôÖÂ∫îÁî®‰∏≠ÔºåLLINBOÊ°ÜÊû∂Â±ïÁ§∫‰∫ÜÊòæËëóÁöÑ‰ºòÂåñÊÄßËÉΩÔºåÁõ∏ËæÉ‰∫é‰º†ÁªüÊñπÊ≥ïÔºå‰ºòÂåñÊïàÁéáÊèêÂçá‰∫Ü20%‰ª•‰∏äÔºå‰∏îÂú®‰∏çÁ°ÆÂÆöÊÄßËØÑ‰º∞ÊñπÈù¢Ë°®Áé∞Âá∫Êõ¥È´òÁöÑÂèØÈù†ÊÄß„ÄÇËøô‰∫õÁªìÊûúÈ™åËØÅ‰∫ÜÊ°ÜÊû∂ÁöÑÊúâÊïàÊÄßÂíåÂÆûÁî®ÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

LLINBOÊ°ÜÊû∂ÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõÔºåÂ∞§ÂÖ∂ÊòØÂú®ÈúÄË¶Å‰ºòÂåñÊòÇË¥µÈªëÁÆ±ÂáΩÊï∞ÁöÑÈ¢ÜÂüüÔºåÂ¶ÇËá™Âä®ÂåñËÆæËÆ°„ÄÅÊùêÊñôÁßëÂ≠¶ÂíåÊú∫Âô®Â≠¶‰π†Ë∂ÖÂèÇÊï∞Ë∞É‰ºòÁ≠â„ÄÇÈÄöËøáÁªìÂêàLLMs‰∏éÁªüËÆ°Ê®°ÂûãÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÂú®‰∏çÁ°ÆÂÆöÊÄßËæÉÈ´òÁöÑÁéØÂ¢É‰∏≠Êèê‰æõÊõ¥ÂèØÈù†ÁöÑ‰ºòÂåñÁªìÊûúÔºåÊé®Âä®Áõ∏ÂÖ≥È¢ÜÂüüÁöÑÁ†îÁ©∂‰∏éÂ∫îÁî®ËøõÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Bayesian optimization (BO) is a sequential decision-making tool widely used for optimizing expensive black-box functions. Recently, Large Language Models (LLMs) have shown remarkable adaptability in low-data regimes, making them promising tools for black-box optimization by leveraging contextual knowledge to propose high-quality query points. However, relying solely on LLMs as optimization agents introduces risks due to their lack of explicit surrogate modeling and calibrated uncertainty, as well as their inherently opaque internal mechanisms. This structural opacity makes it difficult to characterize or control the exploration-exploitation trade-off, ultimately undermining theoretical tractability and reliability. To address this, we propose LLINBO: LLM-in-the-Loop BO, a hybrid framework for BO that combines LLMs with statistical surrogate experts (e.g., Gaussian Processes (GP)). The core philosophy is to leverage contextual reasoning strengths of LLMs for early exploration, while relying on principled statistical models to guide efficient exploitation. Specifically, we introduce three mechanisms that enable this collaboration and establish their theoretical guarantees. We end the paper with a real-life proof-of-concept in the context of 3D printing. The code to reproduce the results can be found at https://github.com/UMDataScienceLab/LLM-in-the-Loop-BO.

