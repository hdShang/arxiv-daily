---
layout: default
title: When to retrain a machine learning model
---

# When to retrain a machine learning model

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14903" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14903v1</a>
  <a href="https://arxiv.org/pdf/2505.14903.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14903v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14903v1', 'When to retrain a machine learning model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Regol Florence, Schwinn Leo, Sprague Kyle, Coates Mark, Markovich Thomas

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºä¸ç¡®å®šæ€§çš„æ¨¡å‹é‡è®­ç»ƒæ–¹æ³•ä»¥åº”å¯¹æ•°æ®æ¼”å˜é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æ¨¡å‹é‡è®­ç»ƒ` `æ•°æ®æ¼”å˜` `ä¸ç¡®å®šæ€§è¯„ä¼°` `æœºå™¨å­¦ä¹ ` `æ€§èƒ½ä¼˜åŒ–` `åˆ†ç±»ä»»åŠ¡` `åŠ¨æ€ç¯å¢ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤„ç†æ¨¡å‹é‡è®­ç»ƒæ—¶é¢ä¸´æ•°æ®ç¨€ç¼ºã€åˆ†å¸ƒè½¬ç§»æœªçŸ¥åŠæˆæœ¬æƒè¡¡å›°éš¾ç­‰æŒ‘æˆ˜ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºä¸ç¡®å®šæ€§çš„é‡è®­ç»ƒå†³ç­–æ–¹æ³•ï¼Œé€šè¿‡é¢„æµ‹æ¨¡å‹æ€§èƒ½çš„æ¼”å˜æ¥æŒ‡å¯¼é‡è®­ç»ƒæ—¶æœºã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨7ä¸ªæ•°æ®é›†çš„åˆ†ç±»ä»»åŠ¡ä¸­è¡¨ç°ä¼˜äºç°æœ‰çš„åŸºçº¿æ–¹æ³•ï¼Œå…·æœ‰æ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨ç»´æŠ¤ç°å®ä¸–ç•Œçš„æœºå™¨å­¦ä¹ æ¨¡å‹æ—¶ï¼Œå¦‚ä½•åº”å¯¹æ•°æ®çš„æŒç»­å’Œä¸å¯é¢„æµ‹çš„æ¼”å˜æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ã€‚å®è·µè€…å¸¸å¸¸é¢ä¸´ä½•æ—¶é‡è®­ç»ƒæˆ–æ›´æ–°æ¨¡å‹çš„éš¾é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†è¿™ä¸€é—®é¢˜æ—¶å­˜åœ¨ä¸è¶³ï¼Œæ— æ³•å…¨é¢è§£å†³åˆ†å¸ƒè½¬ç§»æ£€æµ‹ã€æ•°æ®ç¨€ç¼ºåŠé‡è®­ç»ƒä¸æ€§èƒ½ä¸ä½³ä¹‹é—´çš„æˆæœ¬æƒè¡¡ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºä¸ç¡®å®šæ€§çš„é‡è®­ç»ƒé—®é¢˜çš„åŸåˆ™æ€§å…¬å¼åŒ–æ–¹æ³•ï¼Œé€šè¿‡æŒç»­é¢„æµ‹æ¨¡å‹æ€§èƒ½çš„æ¼”å˜æ¥åšå‡ºå†³ç­–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨7ä¸ªæ•°æ®é›†ä¸Šçš„åˆ†ç±»ä»»åŠ¡ä¸­å§‹ç»ˆä¼˜äºç°æœ‰åŸºçº¿ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è¦è§£å†³çš„å…·ä½“é—®é¢˜æ˜¯å¦‚ä½•åœ¨æ•°æ®ä¸æ–­æ¼”å˜çš„æƒ…å†µä¸‹ï¼Œåˆç†åˆ¤æ–­ä½•æ—¶é‡è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹ã€‚ç°æœ‰æ–¹æ³•åœ¨åº”å¯¹æ•°æ®ç¨€ç¼ºå’Œåˆ†å¸ƒè½¬ç§»æ—¶ï¼Œæœªèƒ½æœ‰æ•ˆè€ƒè™‘é‡è®­ç»ƒä¸æ€§èƒ½ä¸‹é™ä¹‹é—´çš„æˆæœ¬æƒè¡¡ï¼Œå¯¼è‡´å†³ç­–ä¸å¤Ÿå‡†ç¡®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åŸºäºä¸ç¡®å®šæ€§çš„æ–¹æ³•ï¼Œé€šè¿‡æŒç»­é¢„æµ‹æ¨¡å‹æ€§èƒ½çš„æ¼”å˜æ¥åšå‡ºé‡è®­ç»ƒå†³ç­–ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨åˆ©ç”¨æœ‰é™çš„æ•°æ®åšå‡ºæ›´ä¸ºåˆç†çš„åˆ¤æ–­ï¼Œä»è€Œæé«˜æ¨¡å‹çš„é€‚åº”æ€§å’Œæ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ¨¡å‹æ€§èƒ½è¯„ä¼°å’Œé‡è®­ç»ƒå†³ç­–ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆæ”¶é›†æ–°æ•°æ®ï¼Œç„¶åè¯„ä¼°å½“å‰æ¨¡å‹åœ¨æ–°æ•°æ®ä¸Šçš„æ€§èƒ½ï¼Œæœ€åæ ¹æ®é¢„æµ‹çš„æ€§èƒ½å˜åŒ–å†³å®šæ˜¯å¦é‡è®­ç»ƒæ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§æ–°çš„ä¸ç¡®å®šæ€§åº¦é‡æ–¹æ³•ï¼Œä½¿å¾—æ¨¡å‹åœ¨é¢å¯¹æ•°æ®æ¼”å˜æ—¶èƒ½å¤Ÿæ›´å¥½åœ°è¯„ä¼°é‡è®­ç»ƒçš„å¿…è¦æ€§ã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºï¼Œç°æœ‰æ–¹æ³•å¾€å¾€å¿½è§†äº†æˆæœ¬æƒè¡¡çš„å› ç´ ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å…³é”®è®¾è®¡ä¸Šï¼Œè®ºæ–‡é‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥è¡¡é‡æ¨¡å‹æ€§èƒ½çš„å˜åŒ–ï¼Œå¹¶è®¾è®¡äº†é€‚åº”æ€§å‚æ•°æ¥è°ƒæ•´é‡è®­ç»ƒçš„é¢‘ç‡å’Œæ—¶æœºã€‚è¿™äº›è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨åŠ¨æ€ç¯å¢ƒä¸­ä¿æŒè¾ƒé«˜çš„æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæå‡ºçš„æ–¹æ³•åœ¨7ä¸ªæ•°æ®é›†çš„åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œæ€§èƒ½å‡ä¼˜äºç°æœ‰åŸºçº¿ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°10%ä»¥ä¸Šã€‚è¿™è¡¨æ˜è¯¥æ–¹æ³•åœ¨åº”å¯¹æ•°æ®æ¼”å˜æ—¶å…·æœ‰æ˜¾è‘—çš„ä¼˜åŠ¿ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæé«˜æ¨¡å‹çš„ç¨³å®šæ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬é‡‘èé£æ§ã€åœ¨çº¿å¹¿å‘Šæ¨èå’Œæ™ºèƒ½åˆ¶é€ ç­‰é¢†åŸŸã€‚åœ¨è¿™äº›åœºæ™¯ä¸­ï¼Œæ•°æ®çš„æ¼”å˜æ˜¯å¸¸æ€ï¼Œèƒ½å¤ŸåŠæ—¶é‡è®­ç»ƒæ¨¡å‹å°†æ˜¾è‘—æå‡ç³»ç»Ÿçš„å‡†ç¡®æ€§å’Œå“åº”é€Ÿåº¦ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›åœ¨æ›´å¤šåŠ¨æ€ç¯å¢ƒä¸­å¾—åˆ°åº”ç”¨ï¼Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿçš„æŒç»­ä¼˜åŒ–ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> A significant challenge in maintaining real-world machine learning models is responding to the continuous and unpredictable evolution of data. Most practitioners are faced with the difficult question: when should I retrain or update my machine learning model? This seemingly straightforward problem is particularly challenging for three reasons: 1) decisions must be made based on very limited information - we usually have access to only a few examples, 2) the nature, extent, and impact of the distribution shift are unknown, and 3) it involves specifying a cost ratio between retraining and poor performance, which can be hard to characterize. Existing works address certain aspects of this problem, but none offer a comprehensive solution. Distribution shift detection falls short as it cannot account for the cost trade-off; the scarcity of the data, paired with its unusual structure, makes it a poor fit for existing offline reinforcement learning methods, and the online learning formulation overlooks key practical considerations. To address this, we present a principled formulation of the retraining problem and propose an uncertainty-based method that makes decisions by continually forecasting the evolution of model performance evaluated with a bounded metric. Our experiments addressing classification tasks show that the method consistently outperforms existing baselines on 7 datasets.

