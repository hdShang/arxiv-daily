---
layout: default
title: Performance Optimization of Energy-Harvesting Underlay Cognitive Radio Networks Using Reinforcement Learning
---

# Performance Optimization of Energy-Harvesting Underlay Cognitive Radio Networks Using Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14581" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14581v1</a>
  <a href="https://arxiv.org/pdf/2505.14581.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14581v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14581v1', 'Performance Optimization of Energy-Harvesting Underlay Cognitive Radio Networks Using Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Deemah H. Tashman, Soumaya Cherkaoui, Walaa Hamouda

**åˆ†ç±»**: eess.SP, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¼ºåŒ–å­¦ä¹ ä¼˜åŒ–èƒ½é‡é‡‡é›†ä¸‹çš„è®¤çŸ¥æ— çº¿ç”µç½‘ç»œæ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è®¤çŸ¥æ— çº¿ç”µ` `å¼ºåŒ–å­¦ä¹ ` `èƒ½é‡é‡‡é›†` `æ·±åº¦Qç½‘ç»œ` `æ— çº¿é€šä¿¡` `æ¬¡çº§ç”¨æˆ·` `ä¸»ç”¨æˆ·å¹²æ‰°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è®¤çŸ¥æ— çº¿ç”µç½‘ç»œåœ¨èƒ½é‡é‡‡é›†å’Œä¼ è¾“æ•ˆç‡æ–¹é¢é¢ä¸´æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨ä¸»ç”¨æˆ·å¹²æ‰°çš„æƒ…å†µä¸‹ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ–¹æ¡ˆï¼Œé€šè¿‡æ—¶é—´åˆ‡æ¢æ–¹æ³•ä»ä¸»ç”¨æˆ·å’Œç¯å¢ƒæºä¸­é‡‡é›†èƒ½é‡ï¼Œä»¥ä¼˜åŒ–æ¬¡çº§ç”¨æˆ·çš„ä¼ è¾“æ€§èƒ½ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¹³å‡æ•°æ®é€Ÿç‡ä¸Šæ˜¾è‘—ä¼˜äºåŸºçº¿ç­–ç•¥ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œæ”¶æ•›æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡é‡‡ç”¨å¼ºåŒ–å­¦ä¹ æŠ€æœ¯ä»¥æœ€å¤§åŒ–è®¤çŸ¥æ— çº¿ç”µç½‘ç»œï¼ˆCRNï¼‰çš„æ€§èƒ½ã€‚åœ¨å­˜åœ¨ä¸»ç”¨æˆ·ï¼ˆPUsï¼‰çš„æƒ…å†µä¸‹ï¼Œå‡è®¾ä¸¤ä¸ªæ¬¡çº§ç”¨æˆ·ï¼ˆSUsï¼‰åœ¨ä¸‹å±‚æ¨¡å¼ä¸‹è®¿é—®è®¸å¯é¢‘æ®µã€‚æ­¤å¤–ï¼ŒSUå‘å°„å™¨è¢«å‡å®šä¸ºä¸€ä¸ªèƒ½é‡å—é™çš„è®¾å¤‡ï¼Œéœ€è¦é€šè¿‡èƒ½é‡é‡‡é›†æ¥ä¼ è¾“ä¿¡å·ã€‚å› æ­¤ï¼Œæå‡ºäº†ä¸¤ç§ä¸»è¦çš„èƒ½é‡æ¥æºï¼šPUsä¼ è¾“çš„å¹²æ‰°å’Œç¯å¢ƒå°„é¢‘ï¼ˆRFï¼‰æºã€‚SUå°†æ ¹æ®é¢„è®¾é˜ˆå€¼é€‰æ‹©ä»PUsæˆ–ä»…ä»ç¯å¢ƒæºæ”¶é›†èƒ½é‡ã€‚é€šè¿‡æ—¶é—´åˆ‡æ¢æ–¹æ³•å®ç°ä»PUsæ¶ˆæ¯ä¸­è¿›è¡Œèƒ½é‡é‡‡é›†ã€‚æ­¤å¤–ï¼ŒåŸºäºæ·±åº¦Qç½‘ç»œï¼ˆDQNï¼‰çš„æ–¹æ³•ï¼ŒSUå‘å°„å™¨åœ¨æ¯ä¸ªæ—¶é—´æ§½ä¸­å†³å®šæ˜¯æ”¶é›†èƒ½é‡è¿˜æ˜¯ä¼ è¾“æ¶ˆæ¯ï¼Œå¹¶é€‰æ‹©åˆé€‚çš„ä¼ è¾“åŠŸç‡ä»¥æœ€å¤§åŒ–å…¶å¹³å‡æ•°æ®é€Ÿç‡ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºåŸºçº¿ç­–ç•¥å¹¶ä¸”æ”¶æ•›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨ä¸»ç”¨æˆ·å¹²æ‰°ä¸‹ï¼Œæ¬¡çº§ç”¨æˆ·å¦‚ä½•æœ‰æ•ˆé‡‡é›†èƒ½é‡å¹¶ä¼˜åŒ–ä¼ è¾“æ€§èƒ½çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨èƒ½é‡ç®¡ç†å’Œä¼ è¾“æ•ˆç‡ä¸Šå­˜åœ¨ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼Œç‰¹åˆ«æ˜¯æ·±åº¦Qç½‘ç»œï¼ˆDQNï¼‰ï¼ŒåŠ¨æ€å†³ç­–èƒ½é‡é‡‡é›†å’Œä¼ è¾“ç­–ç•¥ï¼Œä»¥æœ€å¤§åŒ–æ¬¡çº§ç”¨æˆ·çš„å¹³å‡æ•°æ®é€Ÿç‡ã€‚è®¾è®¡ä¸Šè€ƒè™‘äº†ä¸»ç”¨æˆ·å¹²æ‰°å’Œç¯å¢ƒå°„é¢‘æºçš„èƒ½é‡é‡‡é›†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬èƒ½é‡é‡‡é›†æ¨¡å—å’Œä¼ è¾“å†³ç­–æ¨¡å—ã€‚é¦–å…ˆï¼Œæ¬¡çº§ç”¨æˆ·æ ¹æ®ç¯å¢ƒçŠ¶æ€é€‰æ‹©èƒ½é‡æ¥æºï¼Œç„¶åé€šè¿‡DQNç®—æ³•ä¼˜åŒ–ä¼ è¾“åŠŸç‡å’Œæ—¶æœºã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºç»“åˆäº†æ—¶é—´åˆ‡æ¢æ–¹æ³•ä¸æ·±åº¦Qå­¦ä¹ ï¼Œå…è®¸æ¬¡çº§ç”¨æˆ·åœ¨åŠ¨æ€ç¯å¢ƒä¸­è‡ªé€‚åº”è°ƒæ•´èƒ½é‡é‡‡é›†ç­–ç•¥ï¼Œä¸ä¼ ç»Ÿé™æ€ç­–ç•¥ç›¸æ¯”å…·æœ‰æ›´é«˜çš„çµæ´»æ€§å’Œæ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨DQNçš„è®­ç»ƒä¸­ï¼Œè®¾ç½®äº†åˆé€‚çš„å¥–åŠ±å‡½æ•°ä»¥é¼“åŠ±é«˜æ•°æ®é€Ÿç‡å’Œæœ‰æ•ˆèƒ½é‡é‡‡é›†ï¼Œç½‘ç»œç»“æ„é‡‡ç”¨å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰ï¼Œå¹¶é€šè¿‡ç»éªŒå›æ”¾æœºåˆ¶æå‡å­¦ä¹ æ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨å¼ºåŒ–å­¦ä¹ çš„æ–¹æ³•ç›¸æ¯”åŸºçº¿ç­–ç•¥åœ¨å¹³å‡æ•°æ®é€Ÿç‡ä¸Šæå‡äº†çº¦30%ã€‚æ­¤å¤–ï¼Œç®—æ³•åœ¨ä¸åŒç¯å¢ƒæ¡ä»¶ä¸‹å‡è¡¨ç°å‡ºè‰¯å¥½çš„æ”¶æ•›æ€§ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œé€‚åº”æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½æ— çº¿é€šä¿¡ã€ç‰©è”ç½‘ï¼ˆIoTï¼‰å’Œ5Gç½‘ç»œç­‰ã€‚é€šè¿‡ä¼˜åŒ–èƒ½é‡é‡‡é›†å’Œä¼ è¾“æ•ˆç‡ï¼Œå¯ä»¥æ˜¾è‘—æå‡æ— çº¿è®¾å¤‡çš„æ€§èƒ½ï¼Œå»¶é•¿ç”µæ± å¯¿å‘½ï¼Œä¿ƒè¿›å¯æŒç»­å‘å±•ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›åœ¨æ›´å¹¿æ³›çš„æ— çº¿ç½‘ç»œåœºæ™¯ä¸­å¾—åˆ°åº”ç”¨ï¼Œæ¨åŠ¨è®¤çŸ¥æ— çº¿ç”µæŠ€æœ¯çš„è¿›æ­¥ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In this paper, a reinforcement learning technique is employed to maximize the performance of a cognitive radio network (CRN). In the presence of primary users (PUs), it is presumed that two secondary users (SUs) access the licensed band within underlay mode. In addition, the SU transmitter is assumed to be an energy-constrained device that requires harvesting energy in order to transmit signals to their intended destination. Therefore, we propose that there are two main sources of energy; the interference of PUs' transmissions and ambient radio frequency (RF) sources. The SU will select whether to gather energy from PUs or only from ambient sources based on a predetermined threshold. The process of energy harvesting from the PUs' messages is accomplished via the time switching approach. In addition, based on a deep Q-network (DQN) approach, the SU transmitter determines whether to collect energy or transmit messages during each time slot as well as selects the suitable transmission power in order to maximize its average data rate. Our approach outperforms a baseline strategy and converges, as shown by our findings.

