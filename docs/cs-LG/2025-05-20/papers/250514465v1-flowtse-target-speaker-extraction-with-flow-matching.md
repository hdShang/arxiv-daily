---
layout: default
title: "FlowTSE: Target Speaker Extraction with Flow Matching"
---

# FlowTSE: Target Speaker Extraction with Flow Matching

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14465" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14465v1</a>
  <a href="https://arxiv.org/pdf/2505.14465.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14465v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14465v1', 'FlowTSE: Target Speaker Extraction with Flow Matching')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Aviv Navon, Aviv Shamsian, Yael Segal-Feldman, Neta Glazer, Gil Hetz, Joseph Keshet

**åˆ†ç±»**: eess.AS, cs.LG, cs.SD

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20

**å¤‡æ³¨**: InterSpeech 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFlowTSEä»¥è§£å†³ç›®æ ‡è¯´è¯äººæå–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `ç›®æ ‡è¯´è¯äººæå–` `ç”Ÿæˆæ¨¡å‹` `æ¡ä»¶æµåŒ¹é…` `æ¢…å°”è°±å›¾` `å£°ç å™¨` `ç›¸ä½é‡å»º` `è¯­éŸ³å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç›®æ ‡è¯´è¯äººæå–æ–¹æ³•å¤šä¸ºåˆ¤åˆ«æ€§ï¼Œç”Ÿæˆæ–¹æ³•å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ï¼Œä¸”é€šå¸¸ä¾èµ–å¤æ‚çš„ç®¡é“ï¼Œå¯¼è‡´è®¡ç®—å¼€é”€è¾ƒå¤§ã€‚
2. æœ¬æ–‡æå‡ºFlowTSEï¼Œé‡‡ç”¨æ¡ä»¶æµåŒ¹é…çš„æ–¹å¼ï¼Œç®€åŒ–äº†ç›®æ ‡è¯´è¯äººæå–çš„è¿‡ç¨‹ï¼Œç›´æ¥å¤„ç†æ¢…å°”è°±å›¾ä»¥æå–ç›®æ ‡è¯­éŸ³ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒFlowTSEåœ¨æ ‡å‡†TSEåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œèƒ½å¤Ÿä¸ç°æœ‰å¼ºåŸºçº¿ç›¸åª²ç¾æˆ–è¶…è¶Šï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç›®æ ‡è¯´è¯äººæå–ï¼ˆTSEï¼‰æ—¨åœ¨ä»æ··åˆä¿¡å·ä¸­æå–ç‰¹å®šè¯´è¯è€…çš„è¯­éŸ³ï¼Œé€šå¸¸ä¾èµ–äºè¯´è¯è€…æ³¨å†Œä½œä¸ºå‚è€ƒã€‚å°½ç®¡ç°æœ‰æ–¹æ³•å¤šä¸ºåˆ¤åˆ«æ€§ï¼Œè¿‘æœŸçš„ç”Ÿæˆæ–¹æ³•åœ¨TSEä¸­å–å¾—äº†è‰¯å¥½æ•ˆæœï¼Œä½†ä»æœªå¾—åˆ°å……åˆ†æ¢ç´¢ï¼Œä¸”å¤§å¤šæ•°æ–¹æ³•ä¾èµ–å¤æ‚çš„ç®¡é“å’Œé¢„è®­ç»ƒç»„ä»¶ï¼Œå¯¼è‡´è®¡ç®—å¼€é”€è¾ƒå¤§ã€‚æœ¬æ–‡æå‡ºFlowTSEï¼Œä¸€ç§åŸºäºæ¡ä»¶æµåŒ¹é…çš„ç®€å•æœ‰æ•ˆçš„TSEæ–¹æ³•ã€‚è¯¥æ¨¡å‹æ¥æ”¶ä¸€ä¸ªæ³¨å†ŒéŸ³é¢‘æ ·æœ¬å’Œä¸€ä¸ªæ··åˆè¯­éŸ³ä¿¡å·ï¼Œå‡ä»¥æ¢…å°”è°±å›¾è¡¨ç¤ºï¼Œç›®æ ‡æ˜¯æå–ç›®æ ‡è¯´è¯è€…çš„æ¸…æ™°è¯­éŸ³ã€‚æ­¤å¤–ï¼Œå¯¹äºç›¸ä½é‡å»ºè‡³å…³é‡è¦çš„ä»»åŠ¡ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹å£°ç å™¨ï¼ŒåŸºäºæ··åˆä¿¡å·çš„å¤STFTè¿›è¡Œæ¡ä»¶å¤„ç†ï¼Œä»è€Œæ”¹å–„ç›¸ä½ä¼°è®¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒFlowTSEåœ¨æ ‡å‡†TSEåŸºå‡†æµ‹è¯•ä¸­ä¸å¼ºåŸºçº¿ç›¸åŒ¹é…æˆ–è¶…è¶Šã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç›®æ ‡è¯´è¯äººæå–ï¼ˆTSEï¼‰ä¸­çš„å¤æ‚æ€§å’Œè®¡ç®—å¼€é”€é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¤šä¾èµ–äºå¤æ‚çš„ç®¡é“å’Œé¢„è®­ç»ƒç»„ä»¶ï¼Œå¯¼è‡´æ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šFlowTSEé€šè¿‡æ¡ä»¶æµåŒ¹é…çš„æ–¹æ³•ï¼Œç®€åŒ–äº†TSEçš„å®ç°è¿‡ç¨‹ï¼Œç›´æ¥å¤„ç†æ¢…å°”è°±å›¾ï¼Œæ—¨åœ¨é«˜æ•ˆæå–ç›®æ ‡è¯´è¯è€…çš„æ¸…æ™°è¯­éŸ³ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFlowTSEçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦è¾“å…¥ï¼šä¸€ä¸ªæ³¨å†ŒéŸ³é¢‘æ ·æœ¬å’Œä¸€ä¸ªæ··åˆè¯­éŸ³ä¿¡å·ã€‚æ¨¡å‹é€šè¿‡æ¡ä»¶æµåŒ¹é…æ¥å®ç°ç›®æ ‡è¯­éŸ³çš„æå–ï¼Œå¹¶åœ¨éœ€è¦ç›¸ä½é‡å»ºçš„ä»»åŠ¡ä¸­å¼•å…¥æ–°å‹å£°ç å™¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šFlowTSEçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶ä½¿ç”¨æ¡ä»¶æµåŒ¹é…çš„ç®€å•æ¶æ„ï¼Œé¿å…äº†å¤æ‚çš„é¢„å¤„ç†å’Œç®¡é“è®¾è®¡ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—å¼€é”€ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨æ¢…å°”è°±å›¾ä½œä¸ºè¾“å…¥ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸ºé€‚åº”ç›®æ ‡è¯´è¯äººæå–çš„ç‰¹å®šéœ€æ±‚ï¼ŒåŒæ—¶æ–°å‹å£°ç å™¨åŸºäºæ··åˆä¿¡å·çš„å¤STFTè¿›è¡Œæ¡ä»¶å¤„ç†ï¼Œä»¥æ”¹å–„ç›¸ä½ä¼°è®¡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒFlowTSEåœ¨æ ‡å‡†TSEåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œèƒ½å¤Ÿä¸ç°æœ‰çš„å¼ºåŸºçº¿ç›¸åŒ¹é…æˆ–è¶…è¶Šï¼Œå…·ä½“æ€§èƒ½æ•°æ®æœªæä¾›ï¼Œä½†éªŒè¯äº†å…¶åœ¨ç›®æ ‡è¯´è¯äººæå–ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§å’Œä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨è¯­éŸ³å¤„ç†ã€è¯­éŸ³è¯†åˆ«å’Œäººæœºäº¤äº’ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡é«˜æ•ˆæå–ç›®æ ‡è¯´è¯è€…çš„è¯­éŸ³ï¼ŒFlowTSEå¯ç”¨äºæ”¹å–„è¯­éŸ³åŠ©æ‰‹çš„æ€§èƒ½ã€å¢å¼ºä¼šè®®è®°å½•çš„æ¸…æ™°åº¦ä»¥åŠæå‡è¯­éŸ³ç¿»è¯‘çš„å‡†ç¡®æ€§ï¼Œæœªæ¥å¯èƒ½åœ¨æ™ºèƒ½å®¶å±…å’Œå®¢æœç³»ç»Ÿä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Target speaker extraction (TSE) aims to isolate a specific speaker's speech from a mixture using speaker enrollment as a reference. While most existing approaches are discriminative, recent generative methods for TSE achieve strong results. However, generative methods for TSE remain underexplored, with most existing approaches relying on complex pipelines and pretrained components, leading to computational overhead. In this work, we present FlowTSE, a simple yet effective TSE approach based on conditional flow matching. Our model receives an enrollment audio sample and a mixed speech signal, both represented as mel-spectrograms, with the objective of extracting the target speaker's clean speech. Furthermore, for tasks where phase reconstruction is crucial, we propose a novel vocoder conditioned on the complex STFT of the mixed signal, enabling improved phase estimation. Experimental results on standard TSE benchmarks show that FlowTSE matches or outperforms strong baselines.

