---
layout: default
title: Textual Steering Vectors Can Improve Visual Understanding in Multimodal Large Language Models
---

# Textual Steering Vectors Can Improve Visual Understanding in Multimodal Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14071" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14071v1</a>
  <a href="https://arxiv.org/pdf/2505.14071.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14071v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14071v1', 'Textual Steering Vectors Can Improve Visual Understanding in Multimodal Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Woody Haosheng Gan, Deqing Fu, Julian Asilis, Ollie Liu, Dani Yogatama, Vatsal Sharan, Robin Jia, Willie Neiswanger

**åˆ†ç±»**: cs.LG, cs.CL, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ–‡æœ¬å¼•å¯¼å‘é‡ä»¥æå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„è§†è§‰ç†è§£èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `æ–‡æœ¬å¼•å¯¼` `è§†è§‰ç†è§£` `ç¨€ç–è‡ªç¼–ç å™¨` `å‡å€¼æ¼‚ç§»` `çº¿æ€§æ¢æµ‹` `æ¨¡å‹å¼•å¯¼` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ç¼ºä¹æœ‰æ•ˆçš„å¼•å¯¼æŠ€æœ¯ï¼Œå¯¼è‡´å…¶åœ¨è§†è§‰ç†è§£ä»»åŠ¡ä¸­çš„è¡¨ç°ä¸ä½³ã€‚
2. æœ¬æ–‡æå‡ºé€šè¿‡æ–‡æœ¬å¯¼å‡ºçš„å‘é‡æ¥å¼•å¯¼å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼Œåˆ©ç”¨ç¨€ç–è‡ªç¼–ç å™¨ç­‰æŠ€æœ¯å®ç°ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ–‡æœ¬å¼•å¯¼æ˜¾è‘—æå‡äº†å¤šæ¨¡æ€æ¨¡å‹çš„å‡†ç¡®æ€§ï¼Œå°¤å…¶åœ¨ç©ºé—´å…³ç³»å’Œè®¡æ•°ä»»åŠ¡ä¸Šè¡¨ç°çªå‡ºã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¼•å¯¼æ–¹æ³•å·²æˆä¸ºæœ‰æ•ˆçš„å·¥å…·ï¼Œç”¨äºåœ¨ä¸ä¿®æ”¹å¤§è¯­è¨€æ¨¡å‹å‚æ•°çš„æƒ…å†µä¸‹å¼•å¯¼å…¶è¡Œä¸ºã€‚ç„¶è€Œï¼Œç°æœ‰çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰å°šæœªå……åˆ†åˆ©ç”¨è¿™äº›æŠ€æœ¯ã€‚æœ¬æ–‡æ¢è®¨äº†å¦‚ä½•é€šè¿‡ç¨€ç–è‡ªç¼–ç å™¨ã€å‡å€¼æ¼‚ç§»å’Œçº¿æ€§æ¢æµ‹ç­‰æ–¹æ³•ï¼Œåˆ©ç”¨æ–‡æœ¬å¯¼å‡ºçš„å‘é‡æ¥å¼•å¯¼MLLMsã€‚ç ”ç©¶å‘ç°ï¼Œæ–‡æœ¬å¯¼å‘çš„å¼•å¯¼åœ¨ä¸åŒçš„MLLMæ¶æ„å’Œè§†è§‰ä»»åŠ¡ä¸­å‡èƒ½æ˜¾è‘—æå‡å¤šæ¨¡æ€å‡†ç¡®æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨CV-Benchä¸Šï¼Œå‡å€¼æ¼‚ç§»åœ¨ç©ºé—´å…³ç³»å‡†ç¡®æ€§ä¸Šæå‡äº†7.3%ï¼Œè®¡æ•°å‡†ç¡®æ€§æå‡äº†3.3%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œæ–‡æœ¬å¼•å¯¼å‘é‡æ˜¯ä¸€ç§å¼ºå¤§ä¸”é«˜æ•ˆçš„æœºåˆ¶ï¼Œèƒ½å¤Ÿåœ¨æœ€å°çš„æ•°æ®æ”¶é›†å’Œè®¡ç®—å¼€é”€ä¸‹å¢å¼ºMLLMçš„åŸºç¡€èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨è§†è§‰ç†è§£ä»»åŠ¡ä¸­ç¼ºä¹æœ‰æ•ˆå¼•å¯¼æŠ€æœ¯çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†åˆ©ç”¨æ–‡æœ¬ä¿¡æ¯ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½å—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡ä»æ–‡æœ¬åŸºç¡€çš„å¤§è¯­è¨€æ¨¡å‹ä¸­æå–å‘é‡ï¼Œç»“åˆç¨€ç–è‡ªç¼–ç å™¨ã€å‡å€¼æ¼‚ç§»å’Œçº¿æ€§æ¢æµ‹ç­‰æ–¹æ³•ï¼Œå¼•å¯¼å¤šæ¨¡æ€æ¨¡å‹çš„è¡Œä¸ºï¼Œä»¥æå‡å…¶è§†è§‰ç†è§£èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯æ–‡æœ¬å‘é‡çš„æå–ï¼Œå…¶æ¬¡æ˜¯é€šè¿‡å‡å€¼æ¼‚ç§»å’Œçº¿æ€§æ¢æµ‹è¿›è¡Œå¼•å¯¼ï¼Œæœ€åæ˜¯å°†å¼•å¯¼ç»“æœåº”ç”¨äºå¤šæ¨¡æ€æ¨¡å‹çš„è®­ç»ƒå’Œè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæå‡ºäº†æ–‡æœ¬å¯¼å‘çš„å¼•å¯¼å‘é‡ï¼Œæ˜¾è‘—æå‡äº†å¤šæ¨¡æ€æ¨¡å‹çš„å‡†ç¡®æ€§ï¼Œå°¤å…¶æ˜¯åœ¨ç©ºé—´å…³ç³»å’Œè®¡æ•°ä»»åŠ¡ä¸Šï¼Œè¶…è¶Šäº†ä¼ ç»Ÿçš„æç¤ºæ–¹æ³•ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç¨€ç–è‡ªç¼–ç å™¨æ¥æå–æ–‡æœ¬ç‰¹å¾ï¼Œå‡å€¼æ¼‚ç§»ç”¨äºä¼˜åŒ–ç©ºé—´å…³ç³»çš„å‡†ç¡®æ€§ï¼Œçº¿æ€§æ¢æµ‹åˆ™ç”¨äºè¯„ä¼°å¼•å¯¼æ•ˆæœï¼Œç¡®ä¿æ¨¡å‹åœ¨ä¸åŒæ•°æ®é›†ä¸Šçš„å¼ºæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå‡å€¼æ¼‚ç§»æ–¹æ³•åœ¨CV-Benchæ•°æ®é›†ä¸Šæå‡äº†ç©ºé—´å…³ç³»å‡†ç¡®æ€§7.3%ï¼Œè®¡æ•°å‡†ç¡®æ€§æå‡3.3%ã€‚è¿™äº›ç»“æœä¸ä»…è¶…è¶Šäº†ä¼ ç»Ÿçš„æç¤ºæ–¹æ³•ï¼Œè¿˜å±•ç°äº†åœ¨ä¸åŒåˆ†å¸ƒæ•°æ®é›†ä¸Šçš„å¼ºæ³›åŒ–èƒ½åŠ›ï¼Œè¯æ˜äº†æ–‡æœ¬å¼•å¯¼å‘é‡çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è®¡ç®—æœºè§†è§‰ã€è‡ªç„¶è¯­è¨€å¤„ç†å’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„è§†è§‰ç†è§£èƒ½åŠ›ï¼Œå¯ä»¥åœ¨è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½ç›‘æ§å’Œè™šæ‹ŸåŠ©æ‰‹ç­‰å®é™…åœºæ™¯ä¸­å‘æŒ¥é‡è¦ä½œç”¨ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„è¿›æ­¥ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Steering methods have emerged as effective and targeted tools for guiding large language models' (LLMs) behavior without modifying their parameters. Multimodal large language models (MLLMs), however, do not currently enjoy the same suite of techniques, due in part to their recency and architectural diversity. Inspired by this gap, we investigate whether MLLMs can be steered using vectors derived from their text-only LLM backbone, via sparse autoencoders (SAEs), mean shift, and linear probing. We find that text-derived steering consistently enhances multimodal accuracy across diverse MLLM architectures and visual tasks. In particular, mean shift boosts spatial relationship accuracy on CV-Bench by up to +7.3% and counting accuracy by up to +3.3%, outperforming prompting and exhibiting strong generalization to out-of-distribution datasets. These results highlight textual steering vectors as a powerful, efficient mechanism for enhancing grounding in MLLMs with minimal additional data collection and computational overhead.

