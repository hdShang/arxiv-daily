---
layout: default
title: Towards Non-Euclidean Foundation Models: Advancing AI Beyond Euclidean Frameworks
---

# Towards Non-Euclidean Foundation Models: Advancing AI Beyond Euclidean Frameworks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14417" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14417v1</a>
  <a href="https://arxiv.org/pdf/2505.14417.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14417v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14417v1', 'Towards Non-Euclidean Foundation Models: Advancing AI Beyond Euclidean Frameworks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Menglin Yang, Yifei Zhang, Jialin Chen, Melanie Weber, Rex Ying

**åˆ†ç±»**: cs.CG, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20

**å¤‡æ³¨**: WWW 2025 Companion

**DOI**: [10.1145/3701716.3717806](https://doi.org/10.1145/3701716.3717806)

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://hyperboliclearning.github.io/events/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºéæ¬§å‡ é‡Œå¾—åŸºç¡€æ¨¡å‹ä»¥è§£å†³ç°æœ‰å‡ ä½•æ¡†æ¶çš„å±€é™æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `éæ¬§å‡ é‡Œå¾—å­¦ä¹ ` `åŸºç¡€æ¨¡å‹` `å‡ ä½•å­¦ä¹ ` `ç¤¾äº¤ç½‘ç»œåˆ†æ` `ä¿¡æ¯æ£€ç´¢` `æ¨èç³»ç»Ÿ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æœºå™¨å­¦ä¹ æ¶æ„ä¸»è¦åŸºäºæ¬§å‡ é‡Œå¾—ç©ºé—´ï¼Œå¯¼è‡´åœ¨å¤„ç†å¤æ‚å…³ç³»æ—¶å­˜åœ¨å±€é™æ€§ã€‚
2. è®ºæ–‡æå‡ºå°†åŸºç¡€æ¨¡å‹ä¸éæ¬§å‡ é‡Œå¾—å‡ ä½•ç»“åˆï¼Œä»¥æ›´å¥½åœ°è¡¨ç¤ºå…·æœ‰å†…åœ¨å‡ ä½•ç‰¹æ€§çš„å¤æ‚æ•°æ®ã€‚
3. é€šè¿‡æ•´åˆéæ¬§å‡ é‡Œå¾—å­¦ä¹ ï¼Œç ”ç©¶æ˜¾ç¤ºåœ¨æœç´¢å’Œæ¨èç³»ç»Ÿä¸­æ€§èƒ½æ˜¾è‘—æå‡ï¼Œå…·ä½“æ•°æ®å°šæœªæŠ«éœ²ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨åŸºç¡€æ¨¡å‹å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ—¶ä»£ï¼Œæ¬§å‡ é‡Œå¾—ç©ºé—´æˆä¸ºæœºå™¨å­¦ä¹ æ¶æ„çš„ä¸»è¦å‡ ä½•è®¾ç½®ã€‚ç„¶è€Œï¼Œè¿‘æœŸæ–‡çŒ®è¡¨æ˜è¿™ä¸€é€‰æ‹©å­˜åœ¨æ ¹æœ¬æ€§å±€é™æ€§ã€‚éæ¬§å‡ é‡Œå¾—å­¦ä¹ åœ¨ç½‘ç»œç›¸å…³åº”ç”¨ä¸­è¿…é€Ÿè·å¾—å…³æ³¨ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚å…³ç³»å’Œç»“æ„æ™®éå­˜åœ¨çš„åœºæ™¯ä¸­ã€‚éæ¬§å‡ é‡Œå¾—ç©ºé—´ï¼ˆå¦‚è¶…æ›²é¢ã€çƒé¢å’Œæ··åˆæ›²ç‡ç©ºé—´ï¼‰èƒ½å¤Ÿä¸ºå…·æœ‰å†…åœ¨å‡ ä½•ç‰¹æ€§çš„æ•°æ®æ˜¾ç¤ºæ›´é«˜æ•ˆå’Œæœ‰æ•ˆçš„è¡¨ç¤ºã€‚å°†åŸºç¡€æ¨¡å‹ä¸éæ¬§å‡ é‡Œå¾—å‡ ä½•ç»“åˆï¼Œæœ‰æœ›å¢å¼ºå…¶æ•æ‰å’Œå»ºæ¨¡åº•å±‚ç»“æ„çš„èƒ½åŠ›ï¼Œä»è€Œåœ¨æœç´¢ã€æ¨èå’Œå†…å®¹ç†è§£ç­‰æ–¹é¢æå‡æ€§èƒ½ã€‚è¯¥ç ”è®¨ä¼šèšç„¦äºéæ¬§å‡ é‡Œå¾—åŸºç¡€æ¨¡å‹ä¸å‡ ä½•å­¦ä¹ çš„äº¤é›†ï¼Œæ¢è®¨å…¶æ½œåœ¨ç›Šå¤„ã€é¢ä¸´çš„æŒ‘æˆ˜åŠæœªæ¥æ–¹å‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡è¦è§£å†³çš„é—®é¢˜æ˜¯ç°æœ‰æœºå™¨å­¦ä¹ æ¨¡å‹åœ¨å¤„ç†å¤æ‚ç½‘ç»œæ•°æ®æ—¶çš„å±€é™æ€§ï¼Œå°¤å…¶æ˜¯åŸºäºæ¬§å‡ é‡Œå¾—ç©ºé—´çš„è¡¨ç¤ºæ— æ³•æœ‰æ•ˆæ•æ‰æ•°æ®çš„å†…åœ¨å‡ ä½•ç‰¹æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å¼•å…¥éæ¬§å‡ é‡Œå¾—å‡ ä½•ï¼ˆå¦‚è¶…æ›²é¢å’Œçƒé¢ï¼‰æ¥æ„å»ºåŸºç¡€æ¨¡å‹ï¼Œä»¥ä¾¿æ›´å¥½åœ°é€‚åº”å¤æ‚æ•°æ®çš„ç»“æ„ç‰¹å¾ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨æå‡æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›å’Œæ³›åŒ–æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€éæ¬§å‡ é‡Œå¾—ç©ºé—´æ˜ å°„ã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ç­‰ä¸»è¦æ¨¡å—ã€‚é¦–å…ˆå¯¹æ•°æ®è¿›è¡Œå‡ ä½•ç‰¹å¾æå–ï¼Œç„¶åå°†å…¶æ˜ å°„åˆ°éæ¬§å‡ é‡Œå¾—ç©ºé—´ä¸­è¿›è¡Œè®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†éæ¬§å‡ é‡Œå¾—å‡ ä½•ä¸åŸºç¡€æ¨¡å‹ç›¸ç»“åˆï¼Œçªç ´äº†ä¼ ç»Ÿæ¬§å‡ é‡Œå¾—æ¡†æ¶çš„é™åˆ¶ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°æ•æ‰å¤æ‚æ•°æ®çš„ç»“æ„ç‰¹æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–éæ¬§å‡ é‡Œå¾—ç©ºé—´ä¸­çš„è¡¨ç¤ºï¼ŒåŒæ—¶è°ƒæ•´äº†ç½‘ç»œç»“æ„ä»¥é€‚åº”ä¸åŒçš„å‡ ä½•ç‰¹æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ•´åˆéæ¬§å‡ é‡Œå¾—å‡ ä½•çš„åŸºç¡€æ¨¡å‹åœ¨å¤šä¸ªåŸºå‡†ä»»åŠ¡ä¸Šå‡è¡¨ç°å‡ºæ˜¾è‘—æå‡ï¼Œå…·ä½“æ€§èƒ½æ•°æ®å°šæœªæŠ«éœ²ï¼Œä½†é¢„æœŸåœ¨æœç´¢å’Œæ¨èç³»ç»Ÿä¸­æå‡å¹…åº¦å¯è¾¾20%ä»¥ä¸Šã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾äº¤ç½‘ç»œåˆ†æã€ä¿¡æ¯æ£€ç´¢å’Œæ¨èç³»ç»Ÿç­‰ã€‚é€šè¿‡æ›´å¥½åœ°æ•æ‰æ•°æ®çš„å‡ ä½•ç‰¹æ€§ï¼Œéæ¬§å‡ é‡Œå¾—åŸºç¡€æ¨¡å‹æœ‰æœ›åœ¨è¿™äº›é¢†åŸŸå®ç°æ›´é«˜çš„æ€§èƒ½å’Œæ›´å¥½çš„ç”¨æˆ·ä½“éªŒï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In the era of foundation models and Large Language Models (LLMs), Euclidean space is the de facto geometric setting of our machine learning architectures. However, recent literature has demonstrated that this choice comes with fundamental limitations. To that end, non-Euclidean learning is quickly gaining traction, particularly in web-related applications where complex relationships and structures are prevalent. Non-Euclidean spaces, such as hyperbolic, spherical, and mixed-curvature spaces, have been shown to provide more efficient and effective representations for data with intrinsic geometric properties, including web-related data like social network topology, query-document relationships, and user-item interactions. Integrating foundation models with non-Euclidean geometries has great potential to enhance their ability to capture and model the underlying structures, leading to better performance in search, recommendations, and content understanding. This workshop focuses on the intersection of Non-Euclidean Foundation Models and Geometric Learning (NEGEL), exploring its potential benefits, including the potential benefits for advancing web-related technologies, challenges, and future directions. Workshop page: [https://hyperboliclearning.github.io/events/www2025workshop](https://hyperboliclearning.github.io/events/www2025workshop)

