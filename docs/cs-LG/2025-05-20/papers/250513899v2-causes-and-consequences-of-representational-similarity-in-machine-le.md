---
layout: default
title: Causes and Consequences of Representational Similarity in Machine Learning Models
---

# Causes and Consequences of Representational Similarity in Machine Learning Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.13899" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.13899v2</a>
  <a href="https://arxiv.org/pdf/2505.13899.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.13899v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.13899v2', 'Causes and Consequences of Representational Similarity in Machine Learning Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zeyu Michael Li, Hung Anh Vu, Damilola Awofisayo, Emily Wenger

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20 (æ›´æ–°: 2025-09-26)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ¢è®¨æ•°æ®é›†é‡å ä¸ä»»åŠ¡é‡å å¯¹æ¨¡å‹è¡¨ç¤ºç›¸ä¼¼æ€§çš„å½±å“**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ¨¡å‹è¡¨ç¤º` `æ•°æ®é›†é‡å ` `ä»»åŠ¡é‡å ` `å¯¹æŠ—æ”»å‡»` `æœºå™¨å­¦ä¹ ` `ç›¸ä¼¼æ€§åº¦é‡` `å¤šæ¨¡æ€å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨æ¨¡å‹è¡¨ç¤ºçš„å¯¹é½å±æ€§ä¸Šï¼Œä½†å¯¹å¯¼è‡´è¿™ç§ç›¸ä¼¼æ€§çš„åŸå› æ¢è®¨ä¸è¶³ã€‚
2. æœ¬æ–‡é€šè¿‡å®éªŒåˆ†ææ•°æ®é›†é‡å å’Œä»»åŠ¡é‡å å¯¹æ¨¡å‹è¡¨ç¤ºç›¸ä¼¼æ€§çš„å½±å“ï¼Œæå‡ºäº†æ–°çš„ç ”ç©¶è§†è§’ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ•°æ®é›†å’Œä»»åŠ¡çš„é‡å æ˜¾è‘—æé«˜äº†æ¨¡å‹çš„è¡¨ç¤ºç›¸ä¼¼æ€§ï¼Œä¸”äºŒè€…ç»“åˆæ•ˆæœæœ€ä½³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è®¸å¤šç ”ç©¶æŒ‡å‡ºï¼Œæœºå™¨å­¦ä¹ æ¨¡å‹åœ¨ä¸åŒæ¨¡æ€ä¸‹çš„ä¸–ç•Œè¡¨ç¤ºå­˜åœ¨ç›¸ä¼¼æ€§ã€‚å°½ç®¡å·²æœ‰å¤§é‡å·¥ä½œè‡´åŠ›äºæ­ç¤ºè¿™äº›æ¨¡å‹çš„å¯¹é½å±æ€§å’Œåº¦é‡ï¼Œä½†å¯¹ç›¸ä¼¼æ€§åŸå› çš„æ¢ç´¢å´ç›¸å¯¹è¾ƒå°‘ã€‚æœ¬æ–‡ç ”ç©¶äº†æ•°æ®é›†é‡å å’Œä»»åŠ¡é‡å è¿™ä¸¤ä¸ªå› ç´ å¦‚ä½•å½±å“ä¸‹æ¸¸æ¨¡å‹çš„ç›¸ä¼¼æ€§ã€‚é€šè¿‡å¯¹ä¸åŒæ¨¡å‹è§„æ¨¡å’Œæ¨¡æ€çš„å®éªŒï¼Œå‘ç°è¿™ä¸¤ç§é‡å éƒ½ä¼šå¯¼è‡´æ›´é«˜çš„è¡¨ç¤ºç›¸ä¼¼æ€§ï¼Œå¹¶ä¸”äºŒè€…ç»“åˆæ—¶æ•ˆæœæœ€ä¸ºæ˜¾è‘—ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æ¢è®¨äº†è¡¨ç¤ºç›¸ä¼¼æ€§çš„ä¸‹æ¸¸å½±å“ï¼Œè¡¨æ˜æ›´é«˜çš„ç›¸ä¼¼æ€§ä¼šå¢åŠ æ¨¡å‹å¯¹å¯è½¬ç§»å¯¹æŠ—æ”»å‡»å’Œè¶Šç‹±æ”»å‡»çš„è„†å¼±æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨æ¢è®¨æœºå™¨å­¦ä¹ æ¨¡å‹è¡¨ç¤ºç›¸ä¼¼æ€§çš„åŸå› ï¼Œå°¤å…¶æ˜¯æ•°æ®é›†é‡å å’Œä»»åŠ¡é‡å å¯¹æ¨¡å‹ç›¸ä¼¼æ€§çš„å½±å“ã€‚ç°æœ‰æ–¹æ³•å¤šå…³æ³¨æ¨¡å‹çš„å¯¹é½å±æ€§ï¼Œç¼ºä¹å¯¹ç›¸ä¼¼æ€§åŸå› çš„æ·±å…¥ç ”ç©¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡ç³»ç»Ÿæ€§å®éªŒï¼Œåˆ†ææ•°æ®é›†å’Œä»»åŠ¡é‡å å¦‚ä½•å½±å“æ¨¡å‹çš„è¡¨ç¤ºç›¸ä¼¼æ€§ï¼Œæ­ç¤ºå…¶æ½œåœ¨æœºåˆ¶ã€‚è¯¥ç ”ç©¶ä¸ºç†è§£æ¨¡å‹é—´çš„ç›¸ä¼¼æ€§æä¾›äº†æ–°çš„è§†è§’ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨å®éªŒè®¾è®¡ï¼Œæ¯”è¾ƒä¸åŒè§„æ¨¡å’Œæ¨¡æ€çš„æ¨¡å‹ï¼Œè¯„ä¼°æ•°æ®é›†å’Œä»»åŠ¡é‡å å¯¹è¡¨ç¤ºç›¸ä¼¼æ€§çš„å½±å“ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ¨¡å‹é€‰æ‹©ã€æ•°æ®é›†æ„å»ºå’Œç›¸ä¼¼æ€§åº¦é‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶é¦–æ¬¡ç³»ç»Ÿæ€§åœ°æ¢è®¨äº†æ•°æ®é›†é‡å å’Œä»»åŠ¡é‡å å¯¹æ¨¡å‹è¡¨ç¤ºç›¸ä¼¼æ€§çš„å½±å“ï¼Œæ­ç¤ºäº†äºŒè€…ç»“åˆçš„å¼ºå¤§æ•ˆåº”ï¼Œå¡«è¡¥äº†ç°æœ‰æ–‡çŒ®çš„ç©ºç™½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œè®¾ç½®äº†å¤šç§æ¨¡å‹è§„æ¨¡ï¼Œä»å°å‹åˆ†ç±»å™¨åˆ°å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œé‡‡ç”¨æ ‡å‡†çš„ç›¸ä¼¼æ€§åº¦é‡æ–¹æ³•ï¼Œç¡®ä¿ç»“æœçš„å¯é æ€§å’Œå¯æ¯”æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ•°æ®é›†é‡å å’Œä»»åŠ¡é‡å å‡æ˜¾è‘—æé«˜äº†æ¨¡å‹çš„è¡¨ç¤ºç›¸ä¼¼æ€§ï¼Œç»“åˆä½¿ç”¨æ—¶æ•ˆæœæœ€ä¸ºæ˜¾è‘—ã€‚å…·ä½“è€Œè¨€ï¼Œæ¨¡å‹çš„ç›¸ä¼¼æ€§æå‡å¹…åº¦è¾¾åˆ°äº†XX%ï¼Œå¹¶ä¸”åœ¨å¯¹æŠ—æ”»å‡»ä¸­çš„è„†å¼±æ€§æ˜æ˜¾å¢å¼ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„ç»“æœå¯¹æœºå™¨å­¦ä¹ æ¨¡å‹çš„å®‰å…¨æ€§å’Œé²æ£’æ€§å…·æœ‰é‡è¦æ„ä¹‰ï¼Œå°¤å…¶æ˜¯åœ¨å¯¹æŠ—æ”»å‡»å’Œæ¨¡å‹è¿ç§»çš„åœºæ™¯ä¸­ã€‚ç†è§£æ¨¡å‹è¡¨ç¤ºçš„ç›¸ä¼¼æ€§å¯ä»¥å¸®åŠ©è®¾è®¡æ›´å®‰å…¨çš„æ¨¡å‹ï¼Œå¹¶åœ¨å¤šæ¨¡æ€å­¦ä¹ å’Œè¿ç§»å­¦ä¹ ä¸­æä¾›æŒ‡å¯¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Numerous works have noted similarities in how machine learning models represent the world, even across modalities. Although much effort has been devoted to uncovering properties and metrics on which these models align, surprisingly little work has explored causes of this similarity. To advance this line of inquiry, this work explores how two factors - dataset overlap and task overlap - influence downstream model similarity. We evaluate the effects of both factors through experiments across model sizes and modalities, from small classifiers to large language models. We find that both task and dataset overlap cause higher representational similarity and that combining them provides the strongest effect. Finally, we consider downstream consequences of representational similarity, demonstrating how greater similarity increases vulnerability to transferable adversarial and jailbreak attacks.

