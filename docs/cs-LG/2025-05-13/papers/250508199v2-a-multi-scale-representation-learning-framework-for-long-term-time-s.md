---
layout: default
title: A Multi-scale Representation Learning Framework for Long-Term Time Series Forecasting
---

# A Multi-scale Representation Learning Framework for Long-Term Time Series Forecasting

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.08199" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.08199v2</a>
  <a href="https://arxiv.org/pdf/2505.08199.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.08199v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.08199v2', 'A Multi-scale Representation Learning Framework for Long-Term Time Series Forecasting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Boshi Gao, Qingjian Ni, Fanbo Ju, Yu Chen, Ziqi Zhao

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-13 (æ›´æ–°: 2025-05-16)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šå°ºåº¦è¡¨ç¤ºå­¦ä¹ æ¡†æ¶ä»¥è§£å†³é•¿æœŸæ—¶é—´åºåˆ—é¢„æµ‹é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `é•¿æœŸæ—¶é—´åºåˆ—é¢„æµ‹` `å¤šå°ºåº¦å­¦ä¹ ` `åŸºäºMLPçš„æ¡†æ¶` `åŠ¨æ€ä¿¡æ¯æ•´åˆ` `è¶‹åŠ¿å»ºæ¨¡` `å­£èŠ‚æ€§å»ºæ¨¡` `é¢„æµ‹å‡†ç¡®æ€§` `æ¨¡å‹å¯è§£é‡Šæ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨é•¿æœŸæ—¶é—´åºåˆ—é¢„æµ‹ä¸­æœªèƒ½å……åˆ†åˆ©ç”¨å¤šç²’åº¦ä¿¡æ¯ï¼Œä¸”å¿½è§†äº†é€šé“ç‰¹å®šçš„å±æ€§ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºMLPçš„æ¡†æ¶ï¼Œèƒ½å¤Ÿç‹¬ç«‹å»ºæ¨¡è¶‹åŠ¿å’Œå­£èŠ‚æˆåˆ†ï¼Œå¹¶åŠ¨æ€æ•´åˆå¤šå°ºåº¦é¢„æµ‹ç»“æœã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMDMixeråœ¨MAEæ€§èƒ½ä¸Šæå‡äº†4.64%ï¼Œå¹¶åœ¨è®­ç»ƒæ•ˆç‡ä¸å¯è§£é‡Šæ€§ä¹‹é—´å–å¾—äº†è‰¯å¥½å¹³è¡¡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é•¿æœŸæ—¶é—´åºåˆ—é¢„æµ‹ï¼ˆLTSFï¼‰åœ¨èƒ½æºæ¶ˆè€—å’Œå¤©æ°”é¢„æµ‹ç­‰å®é™…åº”ç”¨ä¸­å…·æœ‰å¹¿æ³›çš„å®ç”¨æ€§ã€‚ç„¶è€Œï¼Œç”±äºæ—¶é—´åºåˆ—ä¸­å¤æ‚çš„æ—¶é—´æ¨¡å¼å’Œå›ºæœ‰çš„å¤šå°ºåº¦å˜åŒ–ï¼Œå‡†ç¡®é¢„æµ‹é•¿æœŸå˜åŒ–é¢ä¸´æŒ‘æˆ˜ã€‚æœ¬æ–‡é€šè¿‡å¼•å…¥ä¸€ç§é«˜æ•ˆçš„åŸºäºå¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰çš„é¢„æµ‹æ¡†æ¶ï¼Œè§£å†³äº†LTSFä¸­çš„å…³é”®é—®é¢˜ï¼ŒåŒ…æ‹¬å¤šç²’åº¦ä¿¡æ¯çš„æ¬¡ä¼˜åˆ©ç”¨ã€å¿½è§†é€šé“ç‰¹å®šå±æ€§ä»¥åŠè¶‹åŠ¿å’Œå­£èŠ‚æˆåˆ†çš„ç‹¬ç‰¹æ€§ã€‚æˆ‘ä»¬çš„æ¨¡å‹èƒ½å¤Ÿæ¸…æ™°åœ°è§£è€¦å¤æ‚çš„æ—¶é—´åŠ¨æ€ï¼Œå¹¶åœ¨ä¸åŒå°ºåº¦ä¸Šè¿›è¡Œå¹¶è¡Œé¢„æµ‹ã€‚è¿™äº›å¤šå°ºåº¦é¢„æµ‹é€šè¿‡ä¸€ä¸ªåŠ¨æ€åˆ†é…é‡è¦æ€§çš„ä¿¡æ¯æ•´åˆç³»ç»Ÿè¿›è¡Œæœ‰æ•ˆèåˆï¼Œæ•æ„Ÿäºå„ä¸ªé€šé“çš„ç‰¹å¾ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMDMixeråœ¨å…«ä¸ªLTSFåŸºå‡†æµ‹è¯•ä¸­ç›¸æ¯”äºæœ€æ–°çš„åŸºäºMLPçš„æ–¹æ³•ï¼ˆTimeMixerï¼‰å¹³å‡é™ä½äº†4.64%çš„MAEï¼ŒåŒæ—¶åœ¨è®­ç»ƒæ•ˆç‡å’Œæ¨¡å‹å¯è§£é‡Šæ€§ä¹‹é—´å–å¾—äº†æœ‰æ•ˆå¹³è¡¡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³é•¿æœŸæ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„å¤æ‚æ—¶é—´æ¨¡å¼å’Œå¤šå°ºåº¦å˜åŒ–é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†åˆ©ç”¨å¤šç²’åº¦ä¿¡æ¯ï¼Œå¯¼è‡´é¢„æµ‹æ€§èƒ½ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºçš„æ¡†æ¶é€šè¿‡ç‹¬ç«‹å»ºæ¨¡è¶‹åŠ¿å’Œå­£èŠ‚æˆåˆ†ï¼Œåˆ©ç”¨å¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰æœ‰æ•ˆè§£è€¦å¤æ‚çš„æ—¶é—´åŠ¨æ€ï¼Œå¹¶åœ¨ä¸åŒå°ºåº¦ä¸Šè¿›è¡Œå¹¶è¡Œé¢„æµ‹ï¼Œä»è€Œæå‡é¢„æµ‹å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¤šå°ºåº¦é¢„æµ‹æ¨¡å—å’ŒåŠ¨æ€ä¿¡æ¯æ•´åˆç³»ç»Ÿã€‚å¤šå°ºåº¦é¢„æµ‹æ¨¡å—è´Ÿè´£ç”Ÿæˆä¸åŒç²’åº¦çš„é¢„æµ‹ï¼Œè€ŒåŠ¨æ€ä¿¡æ¯æ•´åˆç³»ç»Ÿåˆ™æ ¹æ®é€šé“ç‰¹å¾åˆ†é…å„ä¸ªé¢„æµ‹çš„é‡è¦æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šMDMixerçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶åŠ¨æ€æ•´åˆæœºåˆ¶ï¼Œèƒ½å¤Ÿæ ¹æ®ä¸åŒé€šé“çš„ç‰¹æ€§çµæ´»è°ƒæ•´ä¿¡æ¯çš„é‡è¦æ€§ï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„é™æ€å¤„ç†æ–¹å¼å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡å‹é‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–å¤šå°ºåº¦é¢„æµ‹çš„å‡†ç¡®æ€§ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šè®¾è®¡äº†é€‚åº”æ€§å¼ºçš„æ¨¡å—ï¼Œä»¥ä¾¿äºæ•æ‰æ—¶é—´åºåˆ—ä¸­çš„è¶‹åŠ¿å’Œå­£èŠ‚æ€§ç‰¹å¾ã€‚é€šè¿‡è¿™äº›è®¾è®¡ï¼Œæ¨¡å‹åœ¨è®­ç»ƒæ•ˆç‡å’Œå¯è§£é‡Šæ€§ä¸Šå–å¾—äº†è‰¯å¥½å¹³è¡¡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å…«ä¸ªé•¿æœŸæ—¶é—´åºåˆ—é¢„æµ‹åŸºå‡†æµ‹è¯•ä¸­ï¼ŒMDMixerç›¸æ¯”äºæœ€æ–°çš„åŸºäºMLPçš„æ–¹æ³•ï¼ˆTimeMixerï¼‰å¹³å‡é™ä½äº†4.64%çš„MAEï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨è®­ç»ƒæ•ˆç‡å’Œå¯è§£é‡Šæ€§æ–¹é¢ä¹Ÿè¡¨ç°å‡ºè‰²ï¼Œå…·æœ‰è¾ƒé«˜çš„å®ç”¨ä»·å€¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬èƒ½æºç®¡ç†ã€æ°”å€™é¢„æµ‹ã€é‡‘èå¸‚åœºåˆ†æç­‰ã€‚é€šè¿‡æé«˜é•¿æœŸæ—¶é—´åºåˆ—é¢„æµ‹çš„å‡†ç¡®æ€§ï¼Œèƒ½å¤Ÿä¸ºå†³ç­–æä¾›æ›´å¯é çš„æ•°æ®æ”¯æŒï¼Œè¿›è€Œæ¨åŠ¨æ™ºèƒ½å†³ç­–ç³»ç»Ÿçš„å‘å±•ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶æœ‰æœ›åœ¨æ›´å¤šå®é™…åœºæ™¯ä¸­å¾—åˆ°åº”ç”¨ï¼Œæå‡å„è¡Œä¸šçš„é¢„æµ‹èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Long-term time series forecasting (LTSF) offers broad utility in practical settings like energy consumption and weather prediction. Accurately predicting long-term changes, however, is demanding due to the intricate temporal patterns and inherent multi-scale variations within time series. This work confronts key issues in LTSF, including the suboptimal use of multi-granularity information, the neglect of channel-specific attributes, and the unique nature of trend and seasonal components, by introducing a proficient MLP-based forecasting framework. Our method adeptly disentangles complex temporal dynamics using clear, concurrent predictions across various scales. These multi-scale forecasts are then skillfully integrated through a system that dynamically assigns importance to information from different granularities, sensitive to individual channel characteristics. To manage the specific features of temporal patterns, a two-pronged structure is utilized to model trend and seasonal elements independently. Experimental results on eight LTSF benchmarks demonstrate that MDMixer improves average MAE performance by 4.64% compared to the recent state-of-the-art MLP-based method (TimeMixer), while achieving an effective balance between training efficiency and model interpretability.

