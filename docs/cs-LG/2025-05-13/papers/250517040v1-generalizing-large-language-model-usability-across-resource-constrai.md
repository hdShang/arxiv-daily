---
layout: default
title: Generalizing Large Language Model Usability Across Resource-Constrained
---

# Generalizing Large Language Model Usability Across Resource-Constrained

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.17040" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.17040v1</a>
  <a href="https://arxiv.org/pdf/2505.17040.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.17040v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.17040v1', 'Generalizing Large Language Model Usability Across Resource-Constrained')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yun-Da Tsai

**åˆ†ç±»**: cs.LG, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-13

**å¤‡æ³¨**: Doctoral disstertation

**DOI**: [10.6342/NTU202500894](https://doi.org/10.6342/NTU202500894)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§æ¡†æ¶ä»¥æå‡å¤§è¯­è¨€æ¨¡å‹åœ¨èµ„æºå—é™ç¯å¢ƒä¸­çš„å¯ç”¨æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å¤šæ¨¡æ€é›†æˆ` `å¯¹æŠ—æ€§æç¤º` `æ¨ç†æ—¶ä¼˜åŒ–` `ä½èµ„æºé¢†åŸŸ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ä¾èµ–æ˜‚è´µçš„ç›‘ç£å¾®è°ƒï¼Œå‡è®¾å›ºå®šè®­ç»ƒæ¡ä»¶ï¼Œé™åˆ¶äº†æ¨¡å‹åœ¨æœªè§æ¨¡æ€å’Œèµ„æºå—é™ç¯å¢ƒä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚
2. æå‡ºäº†ä¸€ç§æ–‡æœ¬ä¸­å¿ƒå¯¹é½æ¡†æ¶ï¼Œæ”¯æŒå¤šæ¨¡æ€é›†æˆï¼Œå¹¶é€šè¿‡å¯¹æŠ—æ€§æç¤ºæŠ€æœ¯å¢å¼ºæ¨¡å‹é²æ£’æ€§ï¼Œé¿å…äº†é‡è®­ç»ƒã€‚
3. åœ¨ä½èµ„æºé¢†åŸŸå¦‚Verilogä»£ç ç”Ÿæˆä¸­ï¼Œè®¾è®¡åˆæˆæ•°æ®ç®¡é“å’Œé€»è¾‘å¢å¼ºæ¨¡å‹ï¼Œå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œä¸”æ•°æ®éœ€æ±‚æä½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è‡ªç„¶è¯­è¨€ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—æˆåŠŸï¼Œè¿‘æœŸçš„ç ”ç©¶è‡´åŠ›äºå°†å…¶èƒ½åŠ›æ‰©å±•åˆ°å¤šæ¨¡æ€é¢†åŸŸå’Œèµ„æºå—é™ç¯å¢ƒã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–äºæ˜‚è´µçš„ç›‘ç£å¾®è°ƒæˆ–å‡è®¾å›ºå®šçš„è®­ç»ƒæ¡ä»¶ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åœ¨é¢å¯¹æœªè§æ¨¡æ€ã€æœ‰é™æ•°æ®æˆ–å—é™è®¡ç®—èµ„æºæ—¶çš„æ³›åŒ–èƒ½åŠ›ã€‚æœ¬æ–‡ç³»ç»Ÿç ”ç©¶äº†åœ¨ç°å®çº¦æŸä¸‹æ¨å¹¿LLMå¯ç”¨æ€§çš„æ–¹æ³•ï¼Œæå‡ºäº†ä¸€ç§å¼ºå¤§çš„æ–‡æœ¬ä¸­å¿ƒå¯¹é½æ¡†æ¶ï¼Œä½¿LLMsèƒ½å¤Ÿé€šè¿‡è‡ªç„¶è¯­è¨€æ¥å£æ— ç¼é›†æˆæ–‡æœ¬ã€å›¾åƒã€è¡¨æ ¼ç­‰å¤šç§æ¨¡æ€ã€‚æ­¤å¤–ï¼Œæå‡ºäº†å¯¹æŠ—æ€§æç¤ºæŠ€æœ¯ï¼Œä»¥å¢å¼ºæ¨¡å‹å¯¹å™ªå£°å’Œç¼ºå¤±æ¨¡æ€çš„é²æ£’æ€§ã€‚ç ”ç©¶è¿˜æ¢è®¨äº†æ¨ç†æ—¶ä¼˜åŒ–ç­–ç•¥ï¼Œåˆ©ç”¨æç¤ºæœç´¢å’Œä¸ç¡®å®šæ€§é‡åŒ–æ¥æå‡æ€§èƒ½ï¼Œä¸”æ— éœ€é¢å¤–çš„æ¨¡å‹è®­ç»ƒã€‚æœ€åï¼Œé’ˆå¯¹ä½èµ„æºé¢†åŸŸå¦‚Verilogä»£ç ç”Ÿæˆï¼Œè®¾è®¡äº†æ­£ç¡®æ„é€ çš„åˆæˆæ•°æ®ç®¡é“å’Œé€»è¾‘å¢å¼ºæ¨ç†æ¨¡å‹ï¼Œå®ç°äº†åœ¨æœ€å°æ•°æ®ä¸‹çš„æœ€å…ˆè¿›æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨èµ„æºå—é™ç¯å¢ƒä¸‹çš„å¯ç”¨æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºæ˜‚è´µçš„ç›‘ç£å¾®è°ƒï¼Œä¸”å‡è®¾å›ºå®šçš„è®­ç»ƒæ¡ä»¶ï¼Œè¿™å¯¼è‡´æ¨¡å‹åœ¨é¢å¯¹æœªè§æ¨¡æ€å’Œæœ‰é™æ•°æ®æ—¶çš„æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§æ–‡æœ¬ä¸­å¿ƒå¯¹é½æ¡†æ¶ï¼Œä½¿å¾—LLMsèƒ½å¤Ÿé€šè¿‡è‡ªç„¶è¯­è¨€æ¥å£æ— ç¼é›†æˆå¤šç§æ¨¡æ€ï¼Œå¹¶ä¸”æ”¯æŒåœ¨ä¸Šä¸‹æ–‡ä¸­é€‚åº”æœªè§æˆ–åŠ¨æ€å˜åŒ–çš„æ¨¡æ€ï¼Œè€Œæ— éœ€é‡æ–°è®­ç»ƒã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ–‡æœ¬ä¸­å¿ƒå¯¹é½æ¨¡å—ã€å¯¹æŠ—æ€§æç¤ºç”Ÿæˆæ¨¡å—å’Œæ¨ç†æ—¶ä¼˜åŒ–æ¨¡å—ã€‚æ–‡æœ¬ä¸­å¿ƒå¯¹é½æ¨¡å—è´Ÿè´£æ¨¡æ€é›†æˆï¼Œå¯¹æŠ—æ€§æç¤ºç”Ÿæˆæ¨¡å—ç”¨äºå¢å¼ºé²æ£’æ€§ï¼Œæ¨ç†æ—¶ä¼˜åŒ–æ¨¡å—åˆ™é€šè¿‡æç¤ºæœç´¢å’Œä¸ç¡®å®šæ€§é‡åŒ–æå‡æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºçš„å¯¹æŠ—æ€§æç¤ºæŠ€æœ¯ï¼Œé€šè¿‡ç”Ÿæˆè¯­ä¹‰æŒ‘æˆ˜çš„æ‰°åŠ¨æ¥æµ‹è¯•æ¨¡å‹çš„å¯é æ€§ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„é‡è®­ç»ƒæ–¹æ³•æœ¬è´¨ä¸Šä¸åŒï¼Œæä¾›äº†ä¸€ç§é«˜æ•ˆçš„é²æ£’æ€§å¢å¼ºæ‰‹æ®µã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å¯¹æŠ—æ€§æç¤ºç”Ÿæˆä¸­ï¼Œè®¾è®¡äº†ç‰¹å®šçš„æ‰°åŠ¨ç”Ÿæˆç®—æ³•ï¼Œç¡®ä¿ç”Ÿæˆçš„æç¤ºèƒ½å¤Ÿæœ‰æ•ˆæŒ‘æˆ˜æ¨¡å‹çš„ç†è§£èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œæ¨ç†æ—¶ä¼˜åŒ–ç­–ç•¥ä¸­å¼•å…¥äº†ä¸ç¡®å®šæ€§é‡åŒ–ï¼Œä»¥ä¾¿åœ¨ä¸å¢åŠ è®­ç»ƒæˆæœ¬çš„æƒ…å†µä¸‹æå‡æ¨¡å‹æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„æ–¹æ³•åœ¨å¤šæ¨¡æ€é›†æˆå’Œä½èµ„æºé¢†åŸŸçš„ä»»åŠ¡ä¸­å‡å–å¾—äº†æ˜¾è‘—æå‡ã€‚åœ¨Verilogä»£ç ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œæ¨¡å‹åœ¨ä»…ä½¿ç”¨å°‘é‡æ•°æ®çš„æƒ…å†µä¸‹è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå±•ç¤ºäº†å¯¹æ¯”åŸºçº¿çš„æ˜æ˜¾ä¼˜åŠ¿ï¼Œæå‡å¹…åº¦è¶…è¿‡20%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤šæ¨¡æ€æ•°æ®å¤„ç†ã€ä½èµ„æºç¯å¢ƒä¸‹çš„è‡ªåŠ¨åŒ–ä»£ç ç”Ÿæˆä»¥åŠå®æ—¶æ¨ç†ç³»ç»Ÿã€‚é€šè¿‡æå‡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨èµ„æºå—é™ç¯å¢ƒä¸­çš„é€‚åº”æ€§å’Œæ•ˆç‡ï¼Œèƒ½å¤Ÿä¸ºå®é™…åº”ç”¨æä¾›æ›´å¼ºå¤§çš„æ”¯æŒï¼Œå°¤å…¶æ˜¯åœ¨æ•°æ®ç¨€ç¼ºçš„æƒ…å†µä¸‹ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have achieved remarkable success across a wide range of natural language tasks, and recent efforts have sought to extend their capabilities to multimodal domains and resource-constrained environments. However, existing approaches often rely on costly supervised fine-tuning or assume fixed training conditions, limiting their generalization when facing unseen modalities, limited data, or restricted compute resources. This dissertation presents a systematic study toward generalizing LLM usability under real-world constraints. First, it introduces a robust text-centric alignment framework that enables LLMs to seamlessly integrate diverse modalities-including text, images, tables, and any modalities - via natural language interfaces. This approach supports in-context adaptation to unseen or dynamically changing modalities without requiring retraining. To enhance robustness against noisy and missing modalities, an adversarial prompting technique is proposed, generating semantically challenging perturbations at the prompt level to stress-test model reliability. Beyond multimodal setting, the dissertation investigates inference-time optimization strategies for LLMs, leveraging prompt search and uncertainty quantification to improve performance without additional model training. This perspective offers an efficient alternative to scaling model parameters or retraining from scratch. Additionally, the work addresses low-resource domains such as Verilog code generation by designing correct-by-construction synthetic data pipelines and logic-enhanced reasoning models, achieving state-of-the-art performance with minimal data. Together, these contributions form a unified effort to enhance the adaptability, scalability, and efficiency of large language models under practical constraints.

