---
layout: default
title: Efficient Unstructured Pruning of Mamba State-Space Models for Resource-Constrained Environments
---

# Efficient Unstructured Pruning of Mamba State-Space Models for Resource-Constrained Environments

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.08299" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.08299v2</a>
  <a href="https://arxiv.org/pdf/2505.08299.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.08299v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.08299v2', 'Efficient Unstructured Pruning of Mamba State-Space Models for Resource-Constrained Environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ibne Farabi Shihab, Sanjeda Akter, Anuj Sharma

**åˆ†ç±»**: cs.LG, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-13 (æ›´æ–°: 2025-09-05)

**æœŸåˆŠ**: Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé«˜æ•ˆæ— ç»“æ„å‰ªææ¡†æ¶ä»¥è§£å†³Mambaæ¨¡å‹åœ¨èµ„æºå—é™ç¯å¢ƒä¸­çš„éƒ¨ç½²é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„Mambaæ¨¡å‹åœ¨èµ„æºå—é™ç¯å¢ƒä¸­éƒ¨ç½²æ—¶ï¼Œç”±äºå‚æ•°é‡åºå¤§ï¼Œé¢ä¸´æ˜¾è‘—çš„æŒ‘æˆ˜ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ— ç»“æ„å‰ªææ¡†æ¶ï¼Œé€šè¿‡ç»“åˆæ¢¯åº¦ä¿¡æ¯å’Œæƒé‡å¹…åº¦æ¥ä¼˜åŒ–æ¨¡å‹å‚æ•°ï¼Œæå‡éƒ¨ç½²æ•ˆç‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†é«˜è¾¾70%çš„å‚æ•°å‡å°‘ï¼ŒåŒæ—¶ä¿æŒäº†è¶…è¿‡95%çš„æ€§èƒ½ã€‚
4. method_zh

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMsï¼‰ï¼Œå°¤å…¶æ˜¯Mambaæ¶æ„ï¼Œå·²æˆä¸ºåºåˆ—å»ºæ¨¡çš„å¼ºå¤§æ›¿ä»£æ–¹æ¡ˆï¼Œå…·æœ‰çº¿æ€§æ—¶é—´å¤æ‚åº¦å’Œåœ¨å¤šç§ä»»åŠ¡ä¸­å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œå…¶åºå¤§çš„å‚æ•°é‡åœ¨èµ„æºå—é™ç¯å¢ƒä¸­éƒ¨ç½²æ—¶é¢ä¸´é‡å¤§æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ— ç»“æ„å‰ªææ¡†æ¶ï¼Œé’ˆå¯¹Mambaæ¨¡å‹å®ç°äº†é«˜è¾¾70%çš„å‚æ•°å‡å°‘ï¼ŒåŒæ—¶ä¿æŒè¶…è¿‡95%çš„åŸå§‹æ€§èƒ½ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç»“åˆäº†ä¸‰é¡¹å…³é”®åˆ›æ–°ï¼š1ï¼‰ä¸€ç§åŸºäºæ¢¯åº¦çš„å¹…åº¦å‰ªææŠ€æœ¯ï¼Œç»“åˆæƒé‡å¹…åº¦å’Œæ¢¯åº¦ä¿¡æ¯è¯†åˆ«ä¸å¤ªé‡è¦çš„å‚æ•°ï¼›2ï¼‰é€æ­¥å¢åŠ ç¨€ç–æ€§çš„è¿­ä»£å‰ªæè®¡åˆ’ï¼Œä»¥ä¿æŒæ¨¡å‹ç¨³å®šæ€§ï¼›3ï¼‰ä¸€ç§å…¨å±€å‰ªæç­–ç•¥ï¼Œä¼˜åŒ–æ•´ä¸ªæ¨¡å‹çš„å‚æ•°åˆ†é…ã€‚é€šè¿‡åœ¨WikiText-103ã€Long Range Arenaå’ŒETTæ—¶é—´åºåˆ—åŸºå‡†ä¸Šçš„å¹¿æ³›å®éªŒï¼Œæˆ‘ä»¬å±•ç¤ºäº†æ˜¾è‘—çš„æ•ˆç‡æå‡å’Œæœ€å°çš„æ€§èƒ½ä¸‹é™ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> State-space models (SSMs), particularly the Mamba architecture, have emerged as powerful alternatives to Transformers for sequence modeling, offering linear-time complexity and competitive performance across diverse tasks. However, their large parameter counts pose significant challenges for deployment in resource-constrained environments. We propose a novel unstructured pruning framework tailored for Mamba models that achieves up to 70\% parameter reduction while retaining over 95\% of the original performance. Our approach integrates three key innovations: (1) a gradient-aware magnitude pruning technique that combines weight magnitude and gradient information to identify less critical parameters, (2) an iterative pruning schedule that gradually increases sparsity to maintain model stability, and (3) a global pruning strategy that optimizes parameter allocation across the entire model. Through extensive experiments on WikiText-103, Long Range Arena, and ETT time-series benchmarks, we demonstrate significant efficiency gains with minimal performance degradation. Our analysis of pruning effects on Mamba's components reveals critical insights into the architecture's redundancy and robustness, enabling practical deployment in resource-constrained settings while broadening Mamba's applicability.

