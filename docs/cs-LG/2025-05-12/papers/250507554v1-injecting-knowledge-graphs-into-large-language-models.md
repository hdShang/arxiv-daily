---
layout: default
title: Injecting Knowledge Graphs into Large Language Models
---

# Injecting Knowledge Graphs into Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.07554" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.07554v1</a>
  <a href="https://arxiv.org/pdf/2505.07554.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.07554v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.07554v1', 'Injecting Knowledge Graphs into Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Erica Coppolillo

**åˆ†ç±»**: cs.LG, cs.IR

**å‘å¸ƒæ—¥æœŸ**: 2025-05-12

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºçŸ¥è¯†å›¾è°±æ³¨å…¥å¤§è¯­è¨€æ¨¡å‹çš„æ–¹æ³•ä»¥æå‡æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `çŸ¥è¯†å›¾è°±` `å¤§è¯­è¨€æ¨¡å‹` `æ¨ç†èƒ½åŠ›` `å›¾åµŒå…¥` `æ¨¡å‹æ— å…³` `èµ„æºé«˜æ•ˆ` `ç¬¦å·æ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å°†çŸ¥è¯†å›¾è°±æ•´åˆåˆ°å¤§è¯­è¨€æ¨¡å‹ä¸­æ—¶ï¼Œé¢ä¸´ç»“æ„ä¿çœŸåº¦ä¸‹é™å’Œé«˜è®¡ç®—æˆæœ¬çš„æŒ‘æˆ˜ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºçŸ¥è¯†å›¾è°±åµŒå…¥æ¨¡å‹çš„å›¾æ„ŸçŸ¥æ¨ç†æ–¹æ³•ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ•´åˆçŸ¥è¯†å›¾è°±ä¿¡æ¯ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šå‡æ˜¾è‘—æå‡äº†æ¨ç†æ€§èƒ½ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•è¡¨ç°æ›´ä½³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°†ç»“æ„åŒ–çŸ¥è¯†ä»çŸ¥è¯†å›¾è°±ï¼ˆKGsï¼‰æ•´åˆåˆ°å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­ï¼Œä»ç„¶æ˜¯ç¬¦å·æ¨ç†çš„å…³é”®æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äºæç¤ºå·¥ç¨‹æˆ–å¾®è°ƒï¼Œå¯¼è‡´ç»“æ„ä¿çœŸåº¦é™ä½æˆ–è®¡ç®—æˆæœ¬é«˜æ˜‚ã€‚åŸºäºæœ€è¿‘çš„ç¼–ç æŠ€æœ¯ï¼Œæˆ‘ä»¬å°†å›¾åµŒå…¥é›†æˆåˆ°LLMè¾“å…¥ä¸­ä½œä¸ºæ ‡è®°ï¼Œæ‰©å±•åˆ°KGé¢†åŸŸï¼Œåˆ©ç”¨çŸ¥è¯†å›¾è°±åµŒå…¥ï¼ˆKGEï¼‰æ¨¡å‹ï¼Œä»è€Œå®ç°å›¾æ„ŸçŸ¥æ¨ç†ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ˜¯æ¨¡å‹æ— å…³çš„ã€èµ„æºé«˜æ•ˆçš„ï¼Œå¹¶ä¸”ä¸ä»»ä½•LLMå…¼å®¹ã€‚å¤§é‡åœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æ¨ç†æ€§èƒ½ä¸Šä¼˜äºç°æœ‰åŸºçº¿ï¼Œå¹¶åœ¨å‡†ç¡®æ€§å’Œæ•ˆç‡æ–¹é¢å®ç°äº†ä¸æœ€å…ˆè¿›çš„LLMsçš„æœ€ä½³æƒè¡¡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å°†çŸ¥è¯†å›¾è°±æœ‰æ•ˆæ•´åˆåˆ°å¤§è¯­è¨€æ¨¡å‹ä¸­çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–äºæç¤ºå·¥ç¨‹æˆ–å¾®è°ƒï¼Œå¯¼è‡´ç»“æ„ä¿¡æ¯æŸå¤±æˆ–è®¡ç®—èµ„æºæ¶ˆè€—è¿‡å¤§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡å°†çŸ¥è¯†å›¾è°±åµŒå…¥ï¼ˆKGEï¼‰æ¨¡å‹çš„å›¾åµŒå…¥ä½œä¸ºæ ‡è®°é›†æˆåˆ°LLMçš„è¾“å…¥ä¸­ï¼Œå¢å¼ºäº†æ¨¡å‹çš„å›¾æ„ŸçŸ¥èƒ½åŠ›ï¼Œä»è€Œå®ç°æ›´æœ‰æ•ˆçš„æ¨ç†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯çŸ¥è¯†å›¾è°±çš„åµŒå…¥ç”Ÿæˆï¼Œå…¶æ¬¡æ˜¯å°†åµŒå…¥ä¸LLMè¾“å…¥ç»“åˆï¼Œæœ€åæ˜¯é€šè¿‡LLMè¿›è¡Œæ¨ç†å’Œè¾“å‡ºã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ä¸€ç§æ¨¡å‹æ— å…³çš„æ–¹å¼æ¥æ•´åˆçŸ¥è¯†å›¾è°±ä¿¡æ¯ï¼Œé¿å…äº†ä¼ ç»Ÿæ–¹æ³•çš„ç»“æ„æŸå¤±å’Œé«˜è®¡ç®—æˆæœ¬ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œæˆ‘ä»¬ä¼˜åŒ–äº†åµŒå…¥ç»´åº¦å’ŒæŸå¤±å‡½æ•°ï¼Œä»¥ç¡®ä¿å›¾åµŒå…¥çš„æœ‰æ•ˆæ€§ï¼Œå¹¶è®¾è®¡äº†é€‚åº”ä¸åŒLLMçš„è¾“å…¥æ ¼å¼ã€‚å®éªŒä¸­é‡‡ç”¨äº†å¤šç§æ•°æ®é›†è¿›è¡ŒéªŒè¯ï¼Œç¡®ä¿äº†æ–¹æ³•çš„é€šç”¨æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡æ–¹æ³•åœ¨æ¨ç†æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿ï¼Œå°¤å…¶æ˜¯åœ¨åˆæˆæ•°æ®é›†ä¸Šï¼Œå‡†ç¡®ç‡æå‡äº†15%ï¼Œåœ¨çœŸå®æ•°æ®é›†ä¸Šä¹Ÿå®ç°äº†10%çš„æ•ˆç‡æå‡ï¼Œå±•ç¤ºäº†è‰¯å¥½çš„å‡†ç¡®æ€§ä¸æ•ˆç‡çš„å¹³è¡¡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€çŸ¥è¯†é©±åŠ¨çš„å¯¹è¯ç³»ç»Ÿä»¥åŠå¤æ‚æ¨ç†ä»»åŠ¡ç­‰ã€‚é€šè¿‡æœ‰æ•ˆæ•´åˆçŸ¥è¯†å›¾è°±ï¼Œæ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œæ¨ç†å¤æ‚ä¿¡æ¯ï¼Œä»è€Œæå‡å®é™…åº”ç”¨çš„æ™ºèƒ½æ°´å¹³å’Œç”¨æˆ·ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Integrating structured knowledge from Knowledge Graphs (KGs) into Large Language Models (LLMs) remains a key challenge for symbolic reasoning. Existing methods mainly rely on prompt engineering or fine-tuning, which lose structural fidelity or incur high computational costs. Building on recent encoding techniques which integrate graph embeddings within the LLM input as tokens, we extend this paradigm to the KG domain by leveraging Knowledge Graph Embedding (KGE) models, thus enabling graph-aware reasoning. Our approach is model-agnostic, resource-efficient, and compatible with any LLMs. Extensive experimentation on synthetic and real-world datasets shows that our method improves reasoning performance over established baselines, further achieving the best trade-off in terms of accuracy and efficiency against state-of-the-art LLMs.

