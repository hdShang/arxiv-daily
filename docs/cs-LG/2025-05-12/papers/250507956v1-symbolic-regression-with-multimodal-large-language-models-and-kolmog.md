---
layout: default
title: Symbolic Regression with Multimodal Large Language Models and Kolmogorov Arnold Networks
---

# Symbolic Regression with Multimodal Large Language Models and Kolmogorov Arnold Networks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.07956" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.07956v1</a>
  <a href="https://arxiv.org/pdf/2505.07956.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.07956v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.07956v1', 'Symbolic Regression with Multimodal Large Language Models and Kolmogorov Arnold Networks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Thomas R. Harvey, Fabian Ruehle, Kit Fraser-Taliente, James Halverson

**åˆ†ç±»**: cs.LG, cs.NE, cs.SC

**å‘å¸ƒæ—¥æœŸ**: 2025-05-12

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§åŸºäºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„ç¬¦å·å›å½’æ–°æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç¬¦å·å›å½’` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `Kolmogorov Arnold Networks` `é—ä¼ ç®—æ³•` `å‡½æ•°å»ºæ¨¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç¬¦å·å›å½’æ–¹æ³•é€šå¸¸éœ€è¦é¢„å®šä¹‰å‡½æ•°é›†ï¼Œé™åˆ¶äº†æ¨¡å‹çš„çµæ´»æ€§å’Œè¡¨è¾¾èƒ½åŠ›ã€‚
2. æœ¬æ–‡æå‡ºåˆ©ç”¨è§†è§‰èƒ½åŠ›çš„LLMç”Ÿæˆå‡½æ•°å‡è®¾ï¼Œå¹¶é€šè¿‡KANså®ç°å•å˜é‡åˆ°å¤šå˜é‡çš„æ‰©å±•ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç¬¦å·å›å½’ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„æ€§èƒ½å’Œé€‚åº”æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ç¬¦å·å›å½’æ–¹æ³•ï¼Œåˆ©ç”¨å…·å¤‡è§†è§‰èƒ½åŠ›çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’ŒGoogle DeepMindçš„Funsearchç†å¿µã€‚è¯¥æ–¹æ³•é€šè¿‡ç»™å®šå•å˜é‡å‡½æ•°çš„å›¾åƒï¼Œè¦æ±‚LLMæå‡ºè¯¥å‡½æ•°çš„å‡è®¾å½¢å¼ã€‚å‡è®¾å½¢å¼çš„è‡ªç”±å‚æ•°é€šè¿‡æ ‡å‡†æ•°å€¼ä¼˜åŒ–å™¨è¿›è¡Œæ‹Ÿåˆï¼Œå¹¶é€šè¿‡é—ä¼ ç®—æ³•æ„æˆç§ç¾¤ã€‚ä¸å…¶ä»–ç¬¦å·å›å½’æŠ€æœ¯ä¸åŒï¼Œæœ¬æ–¹æ³•ä¸éœ€è¦é¢„å…ˆæŒ‡å®šå›å½’å‡½æ•°é›†ï¼Œè€Œæ˜¯é€šè¿‡é€‚å½“çš„æç¤ºå·¥ç¨‹ä»»æ„æ¡ä»¶ç”Ÿæˆæ­¥éª¤ã€‚é€šè¿‡ä½¿ç”¨Kolmogorov Arnold Networksï¼ˆKANsï¼‰ï¼Œæˆ‘ä»¬è¯æ˜äº†â€œå•å˜é‡å°±æ˜¯ä¸€åˆ‡â€çš„ç¬¦å·å›å½’ç†å¿µï¼Œå¹¶é€šè¿‡åœ¨è®­ç»ƒå¥½çš„KANçš„æ¯æ¡è¾¹ä¸Šå­¦ä¹ å•å˜é‡å‡½æ•°ï¼Œå°†è¯¥æ–¹æ³•æ‰©å±•åˆ°å¤šå˜é‡å‡½æ•°ã€‚æœ€ç»ˆï¼Œç»“åˆçš„è¡¨è¾¾å¼é€šè¿‡è¯­è¨€æ¨¡å‹è¿›ä¸€æ­¥ç®€åŒ–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä¼ ç»Ÿç¬¦å·å›å½’æ–¹æ³•ä¸­å¯¹å‡½æ•°é›†é¢„å®šä¹‰çš„é™åˆ¶ï¼Œå¯¼è‡´æ¨¡å‹çµæ´»æ€§ä¸è¶³çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡åˆ©ç”¨å…·å¤‡è§†è§‰èƒ½åŠ›çš„å¤§è¯­è¨€æ¨¡å‹ï¼Œç›´æ¥ä»å‡½æ•°å›¾åƒä¸­ç”Ÿæˆå‡è®¾å½¢å¼ï¼Œç»“åˆKANså®ç°ä»å•å˜é‡åˆ°å¤šå˜é‡çš„æ‰©å±•ï¼Œæå‡äº†ç¬¦å·å›å½’çš„çµæ´»æ€§å’Œè¡¨è¾¾èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åŒ…æ‹¬ï¼šé¦–å…ˆè¾“å…¥å•å˜é‡å‡½æ•°çš„å›¾åƒï¼ŒLLMç”Ÿæˆå‡½æ•°å‡è®¾ï¼›æ¥ç€ä½¿ç”¨æ•°å€¼ä¼˜åŒ–å™¨æ‹Ÿåˆå‡è®¾å‚æ•°ï¼›æœ€åé€šè¿‡é—ä¼ ç®—æ³•æ„å»ºç§ç¾¤ï¼Œå¹¶åœ¨KANsä¸­å­¦ä¹ å¤šå˜é‡å‡½æ•°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºä¸å†ä¾èµ–äºé¢„å®šä¹‰çš„å‡½æ•°é›†ï¼Œè€Œæ˜¯é€šè¿‡æç¤ºå·¥ç¨‹ä½¿ç”Ÿæˆæ­¥éª¤çµæ´»å¯æ§ï¼Œä¸”é€šè¿‡KANså®ç°äº†å•å˜é‡åˆ°å¤šå˜é‡çš„æœ‰æ•ˆæ‰©å±•ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œä½¿ç”¨æ ‡å‡†æ•°å€¼ä¼˜åŒ–å™¨è¿›è¡Œå‚æ•°æ‹Ÿåˆï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸ºæœ€å°åŒ–æ‹Ÿåˆè¯¯å·®ï¼Œç½‘ç»œç»“æ„ä¸Šé‡‡ç”¨KANsä»¥æ”¯æŒå¤šå˜é‡å‡½æ•°çš„å­¦ä¹ ã€‚å…·ä½“ç»†èŠ‚åŒ…æ‹¬å¯¹LLMçš„æç¤ºè®¾è®¡å’ŒKANçš„è®­ç»ƒç­–ç•¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæœ¬æ–‡æå‡ºçš„æ–¹æ³•åœ¨å¤šä¸ªç¬¦å·å›å½’åŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†ç°æœ‰æŠ€æœ¯ï¼Œå°¤å…¶åœ¨å¤„ç†å¤æ‚å‡½æ•°æ—¶ï¼Œæ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œå±•ç¤ºäº†å…¶ä¼˜è¶Šçš„çµæ´»æ€§å’Œè¡¨è¾¾èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç§‘å­¦è®¡ç®—ã€å·¥ç¨‹å»ºæ¨¡ä»¥åŠæ•°æ®åˆ†æç­‰é¢†åŸŸï¼Œèƒ½å¤Ÿä¸ºå¤æ‚å‡½æ•°çš„å»ºæ¨¡æä¾›æ–°çš„æ€è·¯å’Œå·¥å…·ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½åœ¨è‡ªåŠ¨åŒ–å»ºæ¨¡å’Œæ™ºèƒ½ç³»ç»Ÿè®¾è®¡ä¸­å‘æŒ¥é‡è¦ä½œç”¨ï¼Œæå‡æ¨¡å‹çš„é€‚åº”æ€§å’Œæ•ˆç‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present a novel approach to symbolic regression using vision-capable large language models (LLMs) and the ideas behind Google DeepMind's Funsearch. The LLM is given a plot of a univariate function and tasked with proposing an ansatz for that function. The free parameters of the ansatz are fitted using standard numerical optimisers, and a collection of such ansÃ¤tze make up the population of a genetic algorithm. Unlike other symbolic regression techniques, our method does not require the specification of a set of functions to be used in regression, but with appropriate prompt engineering, we can arbitrarily condition the generative step. By using Kolmogorov Arnold Networks (KANs), we demonstrate that ``univariate is all you need'' for symbolic regression, and extend this method to multivariate functions by learning the univariate function on each edge of a trained KAN. The combined expression is then simplified by further processing with a language model.

