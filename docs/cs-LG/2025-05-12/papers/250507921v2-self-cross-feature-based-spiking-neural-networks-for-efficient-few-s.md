---
layout: default
title: Self-cross Feature based Spiking Neural Networks for Efficient Few-shot Learning
---

# Self-cross Feature based Spiking Neural Networks for Efficient Few-shot Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.07921" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.07921v2</a>
  <a href="https://arxiv.org/pdf/2505.07921.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.07921v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.07921v2', 'Self-cross Feature based Spiking Neural Networks for Efficient Few-shot Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Qi Xu, Junyang Zhu, Dongdong Zhou, Hao Chen, Yang Liu, Jiangrong Shen, Qiang Zhang

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-12 (æ›´æ–°: 2025-05-15)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºè‡ªäº¤å‰ç‰¹å¾çš„è„‰å†²ç¥ç»ç½‘ç»œä»¥è§£å†³é«˜æ•ˆå°‘æ ·æœ¬å­¦ä¹ é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `è„‰å†²ç¥ç»ç½‘ç»œ` `å°‘æ ·æœ¬å­¦ä¹ ` `ç‰¹å¾æå–` `å¯¹æ¯”å­¦ä¹ ` `ä½åŠŸè€—è®¡ç®—` `æ—¶ç©ºç‰¹å¾` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ·±åº¦ç¥ç»ç½‘ç»œåœ¨å°‘æ ·æœ¬å­¦ä¹ ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†è®¡ç®—æˆæœ¬é«˜ä¸”å¯æ‰©å±•æ€§å·®ï¼Œé™åˆ¶äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å¹¿æ³›ä½¿ç”¨ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºè„‰å†²ç¥ç»ç½‘ç»œçš„å°‘æ ·æœ¬å­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡è‡ªç‰¹å¾æå–å’Œäº¤å‰ç‰¹å¾å¯¹æ¯”æ¨¡å—æ¥ä¼˜åŒ–ç‰¹å¾è¡¨ç¤ºå’Œé™ä½åŠŸè€—ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•åœ¨N-Omniglotæ•°æ®é›†ä¸Šæ˜¾è‘—æå‡åˆ†ç±»æ€§èƒ½ï¼Œå¹¶åœ¨CUBå’ŒminiImageNetç­‰é™æ€æ•°æ®é›†ä¸Šä¸ä¼ ç»Ÿäººå·¥ç¥ç»ç½‘ç»œè¡¨ç°ç›¸å½“ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNsï¼‰åœ¨è®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶æ˜¯åœ¨å°‘æ ·æœ¬å­¦ä¹ ï¼ˆFSLï¼‰ä¸­ã€‚ç„¶è€Œï¼ŒDNNsåœ¨å®é™…åº”ç”¨ä¸­é¢ä¸´è®¡ç®—æˆæœ¬é«˜å’Œå¯æ‰©å±•æ€§é—®é¢˜ã€‚è„‰å†²ç¥ç»ç½‘ç»œï¼ˆSNNsï¼‰å› å…¶äº‹ä»¶é©±åŠ¨ç‰¹æ€§å’Œä½èƒ½è€—åœ¨å¤„ç†ç¨€ç–å’ŒåŠ¨æ€æ•°æ®æ—¶è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨æ•æ‰å¤æ‚æ—¶ç©ºç‰¹å¾å’Œè¿›è¡Œè·¨ç±»æ¯”è¾ƒæ—¶ä»å­˜åœ¨å›°éš¾ã€‚ä¸ºæé«˜SNNsåœ¨å°‘æ ·æœ¬å­¦ä¹ ä¸­çš„æ€§èƒ½å’Œæ•ˆç‡ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºSNNsçš„å°‘æ ·æœ¬å­¦ä¹ æ¡†æ¶ï¼Œç»“åˆè‡ªç‰¹å¾æå–æ¨¡å—å’Œäº¤å‰ç‰¹å¾å¯¹æ¯”æ¨¡å—ï¼Œä»¥ä¼˜åŒ–ç‰¹å¾è¡¨ç¤ºå¹¶é™ä½åŠŸè€—ã€‚é€šè¿‡ç»“åˆæ—¶é—´é«˜æ•ˆè®­ç»ƒæŸå¤±å’ŒInfoNCEæŸå¤±ï¼Œä¼˜åŒ–è„‰å†²åˆ—çš„æ—¶é—´åŠ¨æ€æ€§ï¼Œå¢å¼ºåŒºåˆ†èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æFSL-SNNåœ¨ç¥ç»å½¢æ€æ•°æ®é›†N-Omniglotä¸Šæ˜¾è‘—æé«˜äº†åˆ†ç±»æ€§èƒ½ï¼Œå¹¶åœ¨CUBå’ŒminiImageNetç­‰é™æ€æ•°æ®é›†ä¸Šå®ç°äº†ä¸äººå·¥ç¥ç»ç½‘ç»œï¼ˆANNsï¼‰ç«äº‰çš„æ€§èƒ½ï¼ŒåŒæ—¶åŠŸè€—è¾ƒä½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è„‰å†²ç¥ç»ç½‘ç»œåœ¨å°‘æ ·æœ¬å­¦ä¹ ä¸­é¢ä¸´çš„å¤æ‚æ—¶ç©ºç‰¹å¾æ•æ‰å’Œè·¨ç±»æ¯”è¾ƒå›°éš¾çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¤šä¾èµ–äºæ·±åº¦ç¥ç»ç½‘ç»œï¼Œå­˜åœ¨è®¡ç®—æˆæœ¬é«˜å’Œå¯æ‰©å±•æ€§å·®çš„ç—›ç‚¹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºä¸€ç§ç»“åˆè‡ªç‰¹å¾æå–æ¨¡å—å’Œäº¤å‰ç‰¹å¾å¯¹æ¯”æ¨¡å—çš„å°‘æ ·æœ¬å­¦ä¹ æ¡†æ¶ï¼Œä»¥ä¼˜åŒ–ç‰¹å¾è¡¨ç¤ºå¹¶é™ä½åŠŸè€—ã€‚é€šè¿‡å¼•å…¥æ—¶é—´é«˜æ•ˆè®­ç»ƒæŸå¤±å’ŒInfoNCEæŸå¤±ï¼Œå¢å¼ºè„‰å†²åˆ—çš„åŠ¨æ€æ€§å’ŒåŒºåˆ†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬è‡ªç‰¹å¾æå–æ¨¡å—ã€äº¤å‰ç‰¹å¾å¯¹æ¯”æ¨¡å—å’ŒæŸå¤±ä¼˜åŒ–æ¨¡å—ã€‚è‡ªç‰¹å¾æå–æ¨¡å—è´Ÿè´£ä»è¾“å…¥æ•°æ®ä¸­æå–æœ‰æ•ˆç‰¹å¾ï¼Œäº¤å‰ç‰¹å¾å¯¹æ¯”æ¨¡å—åˆ™ç”¨äºå¢å¼ºä¸åŒç±»ä¹‹é—´çš„ç‰¹å¾å¯¹æ¯”ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºç»“åˆè‡ªç‰¹å¾æå–ä¸äº¤å‰ç‰¹å¾å¯¹æ¯”çš„åŒæ¨¡å—è®¾è®¡ï¼Œæ˜¾è‘—æå‡äº†è„‰å†²ç¥ç»ç½‘ç»œåœ¨å°‘æ ·æœ¬å­¦ä¹ ä¸­çš„è¡¨ç°ï¼Œä¸ä¼ ç»Ÿæ·±åº¦å­¦ä¹ æ–¹æ³•ç›¸æ¯”ï¼Œèƒ½åœ¨æ›´ä½çš„èƒ½è€—ä¸‹å®ç°ç›¸ä¼¼çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŸå¤±å‡½æ•°è®¾è®¡ä¸Šï¼Œé‡‡ç”¨æ—¶é—´é«˜æ•ˆè®­ç»ƒæŸå¤±ä¸InfoNCEæŸå¤±çš„ç»“åˆï¼Œä»¥ä¼˜åŒ–è„‰å†²åˆ—çš„æ—¶é—´åŠ¨æ€æ€§ã€‚æ­¤å¤–ï¼Œç½‘ç»œç»“æ„ç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œä»¥ç¡®ä¿åœ¨ä½åŠŸè€—ä¸‹ä»èƒ½ä¿æŒè¾ƒé«˜çš„åˆ†ç±»ç²¾åº¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æFSL-SNNåœ¨N-Omniglotæ•°æ®é›†ä¸Šçš„åˆ†ç±»æ€§èƒ½æ˜¾è‘—æå‡ï¼Œä¸”åœ¨CUBå’ŒminiImageNetç­‰é™æ€æ•°æ®é›†ä¸Šä¸ä¼ ç»Ÿäººå·¥ç¥ç»ç½‘ç»œçš„è¡¨ç°ç›¸å½“ï¼Œä¸”åŠŸè€—æ˜¾è‘—é™ä½ï¼Œå±•ç¤ºäº†å…¶åœ¨å°‘æ ·æœ¬å­¦ä¹ ä¸­çš„æœ‰æ•ˆæ€§å’Œä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººè§†è§‰ã€æ™ºèƒ½ç›‘æ§å’ŒåŒ»ç–—å›¾åƒåˆ†æç­‰åœºæ™¯ï¼Œå°¤å…¶æ˜¯åœ¨æ•°æ®ç¨€ç¼ºçš„æƒ…å†µä¸‹ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡æ¨¡å‹çš„å­¦ä¹ èƒ½åŠ›å’Œæ•ˆç‡ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›åœ¨å®é™…åº”ç”¨ä¸­å®ç°æ›´å¹¿æ³›çš„æ¨å¹¿ï¼Œæ¨åŠ¨å°‘æ ·æœ¬å­¦ä¹ æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Deep neural networks (DNNs) excel in computer vision tasks, especially, few-shot learning (FSL), which is increasingly important for generalizing from limited examples. However, DNNs are computationally expensive with scalability issues in real world. Spiking Neural Networks (SNNs), with their event-driven nature and low energy consumption, are particularly efficient in processing sparse and dynamic data, though they still encounter difficulties in capturing complex spatiotemporal features and performing accurate cross-class comparisons. To further enhance the performance and efficiency of SNNs in few-shot learning, we propose a few-shot learning framework based on SNNs, which combines a self-feature extractor module and a cross-feature contrastive module to refine feature representation and reduce power consumption. We apply the combination of temporal efficient training loss and InfoNCE loss to optimize the temporal dynamics of spike trains and enhance the discriminative power. Experimental results show that the proposed FSL-SNN significantly improves the classification performance on the neuromorphic dataset N-Omniglot, and also achieves competitive performance to ANNs on static datasets such as CUB and miniImageNet with low power consumption.

