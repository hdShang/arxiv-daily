---
layout: default
title: Private LoRA Fine-tuning of Open-Source LLMs with Homomorphic Encryption
---

# Private LoRA Fine-tuning of Open-Source LLMs with Homomorphic Encryption

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.07329" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.07329v1</a>
  <a href="https://arxiv.org/pdf/2505.07329.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.07329v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.07329v1', 'Private LoRA Fine-tuning of Open-Source LLMs with Homomorphic Encryption')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jordan Frery, Roman Bredehoft, Jakub Klemsa, Arthur Meyre, Andrei Stoian

**åˆ†ç±»**: cs.CR, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-12

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç§å¯†LoRAå¾®è°ƒæ–¹æ³•ä»¥è§£å†³å¼€æºLLMæ•°æ®éšç§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åŒæ€åŠ å¯†` `ä½ç§©é€‚åº”` `ç§å¯†å¾®è°ƒ` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ•°æ®éšç§` `æ•æ„Ÿåº”ç”¨` `æ¨¡å‹è®­ç»ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¼€æºLLMå¾®è°ƒä¸­ç¼ºä¹æœ‰æ•ˆçš„æ•°æ®éšç§ä¿æŠ¤ï¼Œå¯¼è‡´æ•æ„Ÿä¿¡æ¯æ³„éœ²çš„é£é™©ã€‚
2. æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ç»“åˆLoRAæŠ€æœ¯ä¸åŒæ€åŠ å¯†çš„ç§å¯†å¾®è°ƒåè®®ï¼Œç¡®ä¿è®­ç»ƒæ•°æ®çš„å®‰å…¨æ€§ã€‚
3. é€šè¿‡å¾®è°ƒLlama-3.2-1Bæ¨¡å‹ï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•çš„å¯è¡Œæ€§ï¼Œå¹¶å±•ç¤ºäº†HEè®¡ç®—çš„æ€§èƒ½ä¼˜åŠ¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨å¼€æºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œä¿æŠ¤æ•°æ®æœºå¯†æ€§å¯¹äºæ•æ„Ÿåº”ç”¨è‡³å…³é‡è¦ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§äº¤äº’å¼åè®®ï¼Œé€‚åº”ä½ç§©é€‚åº”ï¼ˆLoRAï¼‰æŠ€æœ¯ä»¥å®ç°ç§å¯†å¾®è°ƒã€‚é‡‡ç”¨åŒæ€åŠ å¯†ï¼ˆHEï¼‰ä¿æŠ¤è®­ç»ƒæ•°æ®å’Œæ¢¯åº¦çš„æœºå¯†æ€§ï¼Œè¿œç¨‹å·¥ä½œèŠ‚ç‚¹æ‰§è¡Œå¤§éƒ¨åˆ†è®¡ç®—ï¼Œæ•°æ®æ‹¥æœ‰è€…è´Ÿè´£è®­ç»ƒï¼Œå‡å°‘äº†å¯¹æ˜‚è´µå®¢æˆ·ç«¯GPUçš„éœ€æ±‚ã€‚æˆ‘ä»¬é€šè¿‡å¾®è°ƒLlama-3.2-1Bæ¨¡å‹å±•ç¤ºäº†å¯è¡Œæ€§ï¼Œæä¾›äº†ä½¿ç”¨HEå…¼å®¹é‡åŒ–çš„æ”¶æ•›ç»“æœå’ŒHEè®¡ç®—åœ¨GPUç¡¬ä»¶ä¸Šçš„æ€§èƒ½åŸºå‡†ã€‚è¯¥æ–¹æ³•å¯ç”¨äºä¿å¯†çŸ¥è¯†åº“é—®ç­”ã€ç§å¯†ä»£ç åº“å¾®è°ƒã€åŸºäºå…¬å¸é‚®ä»¶æ¡£æ¡ˆèµ·è‰é‚®ä»¶çš„AIä»£ç†ï¼Œä»¥åŠåˆ†ææ•æ„Ÿæ³•å¾‹æˆ–åŒ»ç–—æ–‡ä»¶çš„æ¨¡å‹é€‚é…ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³åœ¨å¼€æºå¤§å‹è¯­è¨€æ¨¡å‹å¾®è°ƒè¿‡ç¨‹ä¸­æ•°æ®éšç§ä¿æŠ¤ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºæœ¬åœ°è®¡ç®—ï¼Œå®¹æ˜“å¯¼è‡´æ•æ„Ÿæ•°æ®æ³„éœ²ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§ç»“åˆä½ç§©é€‚åº”ï¼ˆLoRAï¼‰å’ŒåŒæ€åŠ å¯†ï¼ˆHEï¼‰çš„ç§å¯†å¾®è°ƒåè®®ã€‚é€šè¿‡å°†è®¡ç®—åˆ†æ•£åˆ°è¿œç¨‹èŠ‚ç‚¹ï¼Œæ•°æ®æ‹¥æœ‰è€…åªéœ€è¿›è¡Œå°‘é‡æœ¬åœ°è®¡ç®—ï¼Œä»è€Œä¿æŠ¤æ•°æ®éšç§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ‹¥æœ‰è€…ã€è¿œç¨‹å·¥ä½œèŠ‚ç‚¹å’ŒåŒæ€åŠ å¯†æ¨¡å—ã€‚æ•°æ®æ‹¥æœ‰è€…è´Ÿè´£è®­ç»ƒåè°ƒï¼Œè¿œç¨‹èŠ‚ç‚¹æ‰§è¡Œè®¡ç®—ï¼ŒHEæ¨¡å—ç¡®ä¿æ•°æ®å’Œæ¢¯åº¦çš„æœºå¯†æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†LoRAæŠ€æœ¯ä¸åŒæ€åŠ å¯†ç»“åˆï¼Œå½¢æˆäº†ä¸€ç§æ–°çš„ç§å¯†å¾®è°ƒæ–¹æ³•ã€‚è¿™ä¸€è®¾è®¡ä½¿å¾—åœ¨ä¿æŠ¤æ•°æ®éšç§çš„åŒæ—¶ï¼Œä»èƒ½æœ‰æ•ˆè¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œé‡‡ç”¨HEå…¼å®¹çš„é‡åŒ–æ–¹æ³•ä»¥æé«˜è®¡ç®—æ•ˆç‡ï¼Œå¹¶åœ¨GPUç¡¬ä»¶ä¸Šè¿›è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•ï¼Œç¡®ä¿å¾®è°ƒè¿‡ç¨‹çš„é«˜æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨åŒæ€åŠ å¯†çš„å¾®è°ƒæ–¹æ³•åœ¨Llama-3.2-1Bæ¨¡å‹ä¸Šå®ç°äº†è‰¯å¥½çš„æ”¶æ•›æ€§ï¼Œä¸”åœ¨GPUç¡¬ä»¶ä¸Šè¿›è¡ŒHEè®¡ç®—æ—¶è¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½ä¼˜åŠ¿ï¼Œå…·ä½“æ€§èƒ½æ•°æ®å’ŒåŸºçº¿å¯¹æ¯”å°†åœ¨è®ºæ–‡ä¸­è¯¦ç»†åˆ—å‡ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ä¿å¯†çŸ¥è¯†åº“é—®ç­”ã€ç§å¯†ä»£ç åº“å¾®è°ƒã€AIé‚®ä»¶èµ·è‰ä»£ç†ä»¥åŠæ•æ„Ÿæ³•å¾‹æˆ–åŒ»ç–—æ–‡ä»¶çš„åˆ†æã€‚é€šè¿‡ä¿æŠ¤æ•°æ®éšç§ï¼Œè¯¥æ–¹æ³•ä¸ºä¼ä¸šå’Œæœºæ„åœ¨å¤„ç†æ•æ„Ÿä¿¡æ¯æ—¶æä¾›äº†å®‰å…¨ä¿éšœï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Preserving data confidentiality during the fine-tuning of open-source Large Language Models (LLMs) is crucial for sensitive applications. This work introduces an interactive protocol adapting the Low-Rank Adaptation (LoRA) technique for private fine-tuning. Homomorphic Encryption (HE) protects the confidentiality of training data and gradients handled by remote worker nodes performing the bulk of computations involving the base model weights. The data owner orchestrates training, requiring minimal local computing power and memory, thus alleviating the need for expensive client-side GPUs. We demonstrate feasibility by fine-tuning a Llama-3.2-1B model, presenting convergence results using HE-compatible quantization and performance benchmarks for HE computations on GPU hardware. This approach enables applications such as confidential knowledge base question answering, private codebase fine-tuning for AI code assistants, AI agents for drafting emails based on a company's email archive, and adapting models to analyze sensitive legal or healthcare documents.

