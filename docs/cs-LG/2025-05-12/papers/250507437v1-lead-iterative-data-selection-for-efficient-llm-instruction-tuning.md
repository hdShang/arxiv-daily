---
layout: default
title: "LEAD: Iterative Data Selection for Efficient LLM Instruction Tuning"
---

# LEAD: Iterative Data Selection for Efficient LLM Instruction Tuning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.07437" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.07437v1</a>
  <a href="https://arxiv.org/pdf/2505.07437.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.07437v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.07437v1', 'LEAD: Iterative Data Selection for Efficient LLM Instruction Tuning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xiaotian Lin, Yanlin Qi, Yizhang Zhu, Themis Palpanas, Chengliang Chai, Nan Tang, Yuyu Luo

**åˆ†ç±»**: cs.LG, cs.AI, cs.DB

**å‘å¸ƒæ—¥æœŸ**: 2025-05-12

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLEADæ¡†æ¶ä»¥è§£å†³LLMæŒ‡ä»¤è°ƒä¼˜ä¸­çš„æ•°æ®é€‰æ‹©æ•ˆç‡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æŒ‡ä»¤è°ƒä¼˜` `æ•°æ®é€‰æ‹©` `è®­ç»ƒæ•ˆç‡` `åŠ¨æ€ä¸ç¡®å®šæ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¿­ä»£æ¨¡å‹æ„ŸçŸ¥æ•°æ®é€‰æ‹©æ–¹æ³•åœ¨è®¡ç®—ä¸Šå¼€é”€å·¨å¤§ï¼Œå¯¼è‡´æ•ˆç‡ç“¶é¢ˆã€‚
2. LEADæ¡†æ¶é€šè¿‡åœ¨æ ‡å‡†è®­ç»ƒå¾ªç¯å†…ä¼°è®¡æ ·æœ¬æ•ˆç”¨ï¼Œæ¶ˆé™¤äº†é¢å¤–çš„æ¨¡å‹æ¨ç†éœ€æ±‚ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLEADåœ¨å¤šä¸ªåŸºå‡†ä¸Šå¹³å‡æ€§èƒ½æå‡6.1%-10.8%ï¼Œè®­ç»ƒæ—¶é—´å‡å°‘5-10å€ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æŒ‡ä»¤è°ƒä¼˜å·²æˆä¸ºæå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰èƒ½åŠ›å’Œå¯¹é½çš„é‡è¦èŒƒå¼ã€‚ç„¶è€Œï¼Œç°æœ‰çš„è¿­ä»£æ¨¡å‹æ„ŸçŸ¥æ•°æ®é€‰æ‹©æ–¹æ³•å­˜åœ¨æ˜¾è‘—çš„è®¡ç®—å¼€é”€ï¼Œå› ä¸ºå®ƒä»¬ä¾èµ–äºåå¤è¿›è¡Œå…¨æ•°æ®é›†æ¨¡å‹æ¨ç†æ¥ä¼°è®¡æ ·æœ¬æ•ˆç”¨ï¼Œä»è€Œé€ æˆæ•ˆç‡ç“¶é¢ˆã€‚æœ¬æ–‡æå‡ºäº†LEADï¼Œä¸€ä¸ªé«˜æ•ˆçš„è¿­ä»£æ•°æ®é€‰æ‹©æ¡†æ¶ï¼Œèƒ½å¤Ÿåœ¨æ ‡å‡†è®­ç»ƒå¾ªç¯å†…å‡†ç¡®ä¼°è®¡æ ·æœ¬æ•ˆç”¨ï¼Œæ¶ˆé™¤äº†é¢å¤–æ¨¡å‹æ¨ç†çš„é«˜æˆæœ¬ã€‚LEADçš„æ ¸å¿ƒæ˜¯å¼•å…¥å®ä¾‹çº§åŠ¨æ€ä¸ç¡®å®šæ€§ï¼ˆIDUï¼‰ï¼Œç»“åˆç¬æ—¶è®­ç»ƒæŸå¤±ã€åŸºäºæ¢¯åº¦çš„æŸå¤±å˜åŒ–è¿‘ä¼¼å’Œå†å²æŸå¤±ä¿¡å·çš„æŒ‡æ•°å¹³æ»‘ã€‚ä¸ºäº†é«˜æ•ˆæ‰©å±•åˆ°å¤§è§„æ¨¡æ•°æ®é›†ï¼ŒLEADé‡‡ç”¨ä¸¤é˜¶æ®µçš„ç²—åˆ°ç»†é€‰æ‹©ç­–ç•¥ï¼Œé€šè¿‡å¤šè‡‚è€è™æœºæœºåˆ¶è‡ªé€‚åº”ä¼˜å…ˆé€‰æ‹©ä¿¡æ¯ä¸°å¯Œçš„èšç±»ï¼Œéšåä½¿ç”¨IDUç²¾ç¡®é€‰æ‹©é«˜æ•ˆç”¨æ ·æœ¬ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒLEADæ˜¾è‘—ä¼˜äºç°æœ‰æœ€å…ˆè¿›æ–¹æ³•ï¼Œå¹³å‡æ¨¡å‹æ€§èƒ½æå‡6.1%-10.8%ï¼ŒåŒæ—¶ä»…ä½¿ç”¨2.5%çš„è®­ç»ƒæ•°æ®ï¼Œæ•´ä½“è®­ç»ƒæ—¶é—´å‡å°‘5-10å€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰è¿­ä»£æ¨¡å‹æ„ŸçŸ¥æ•°æ®é€‰æ‹©æ–¹æ³•åœ¨æŒ‡ä»¤è°ƒä¼˜ä¸­çš„æ•ˆç‡ç“¶é¢ˆï¼Œç°æœ‰æ–¹æ³•éœ€è¦åå¤è¿›è¡Œå…¨æ•°æ®é›†æ¨ç†ï¼Œé€ æˆè®¡ç®—å¼€é”€å¤§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šLEADæ¡†æ¶é€šè¿‡åœ¨æ ‡å‡†è®­ç»ƒå¾ªç¯å†…ä¼°è®¡æ ·æœ¬æ•ˆç”¨ï¼Œé¿å…äº†é¢å¤–çš„æ¨¡å‹æ¨ç†ï¼Œåˆ©ç”¨å®ä¾‹çº§åŠ¨æ€ä¸ç¡®å®šæ€§ï¼ˆIDUï¼‰æ¥ç»¼åˆè€ƒè™‘è®­ç»ƒæŸå¤±å’Œå†å²ä¿¡å·ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLEADçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µæ˜¯ç²—ç•¥é€‰æ‹©ï¼Œé€šè¿‡å¤šè‡‚è€è™æœºæœºåˆ¶ä¼˜å…ˆé€‰æ‹©ä¿¡æ¯ä¸°å¯Œçš„èšç±»ï¼›ç¬¬äºŒé˜¶æ®µæ˜¯ç»†è‡´é€‰æ‹©ï¼Œä½¿ç”¨IDUç²¾ç¡®é€‰æ‹©é«˜æ•ˆç”¨æ ·æœ¬ã€‚

**å…³é”®åˆ›æ–°**ï¼šLEADçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå¼•å…¥äº†IDUä½œä¸ºæ•ˆç”¨å‡½æ•°ï¼Œç»“åˆäº†ç¬æ—¶æŸå¤±ã€æ¢¯åº¦è¿‘ä¼¼å’Œå†å²æŸå¤±çš„å¹³æ»‘ï¼Œæ˜¾è‘—æé«˜äº†æ ·æœ¬æ•ˆç”¨çš„ä¼°è®¡ç²¾åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨IDUçš„è®¾è®¡ä¸­ï¼Œè€ƒè™‘äº†ç¬æ—¶è®­ç»ƒæŸå¤±å’Œå†å²æŸå¤±ä¿¡å·çš„å¹³æ»‘å¤„ç†ï¼Œç¡®ä¿äº†åœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šçš„é«˜æ•ˆé€‰æ‹©ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

LEADåœ¨å››ä¸ªä¸åŒåŸºå‡†ä¸Šè¿›è¡Œäº†å¹¿æ³›å®éªŒï¼Œç»“æœæ˜¾ç¤ºå…¶å¹³å‡æ¨¡å‹æ€§èƒ½æå‡6.1%-10.8%ï¼ŒåŒæ—¶ä»…ä½¿ç”¨2.5%çš„è®­ç»ƒæ•°æ®ï¼Œè®­ç»ƒæ—¶é—´å‡å°‘äº†5-10å€ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æœ€å…ˆè¿›æ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

LEADæ¡†æ¶åœ¨å¤§å‹è¯­è¨€æ¨¡å‹çš„æŒ‡ä»¤è°ƒä¼˜ä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œèƒ½å¤Ÿæ˜¾è‘—æé«˜è®­ç»ƒæ•ˆç‡å’Œæ¨¡å‹æ€§èƒ½ã€‚å…¶é«˜æ•ˆçš„æ•°æ®é€‰æ‹©ç­–ç•¥é€‚ç”¨äºå„ç§è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ›´å¤§è§„æ¨¡æ¨¡å‹çš„è®­ç»ƒä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Instruction tuning has emerged as a critical paradigm for improving the capabilities and alignment of large language models (LLMs). However, existing iterative model-aware data selection methods incur significant computational overhead, as they rely on repeatedly performing full-dataset model inference to estimate sample utility for subsequent training iterations, creating a fundamental efficiency bottleneck. In this paper, we propose LEAD, an efficient iterative data selection framework that accurately estimates sample utility entirely within the standard training loop, eliminating the need for costly additional model inference. At its core, LEAD introduces Instance-Level Dynamic Uncertainty (IDU), a theoretically grounded utility function combining instantaneous training loss, gradient-based approximation of loss changes, and exponential smoothing of historical loss signals. To further scale efficiently to large datasets, LEAD employs a two-stage, coarse-to-fine selection strategy, adaptively prioritizing informative clusters through a multi-armed bandit mechanism, followed by precise fine-grained selection of high-utility samples using IDU. Extensive experiments across four diverse benchmarks show that LEAD significantly outperforms state-of-the-art methods, improving average model performance by 6.1%-10.8% while using only 2.5% of the training data and reducing overall training time by 5-10x.

