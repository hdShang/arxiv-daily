---
layout: default
title: "Emotion Knowledge Enhancement for Vision Large Language Models: A Self-Verification Approach for High-Quality Emotion Instruction Data Generation"
---

# Emotion Knowledge Enhancement for Vision Large Language Models: A Self-Verification Approach for High-Quality Emotion Instruction Data Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.18168" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.18168v1</a>
  <a href="https://arxiv.org/pdf/2505.18168.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.18168v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.18168v1', 'Emotion Knowledge Enhancement for Vision Large Language Models: A Self-Verification Approach for High-Quality Emotion Instruction Data Generation')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Feifan Wang, Tengfei Song, Minggui He, Chang Su, Zhanglin Wu, Hao Yang, Wenming Zheng, Osamu Yoshie

**ÂàÜÁ±ª**: cs.LG, cs.GR

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-14

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Ëá™È™åËØÅÊñπÊ≥ï‰ª•ÁîüÊàêÈ´òË¥®ÈáèÊÉÖÊÑüÊåá‰ª§Êï∞ÊçÆ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÊÉÖÊÑüÂàÜÊûê` `ËßÜËßâÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `Ëá™È™åËØÅÊñπÊ≥ï` `Êï∞ÊçÆÁîüÊàê` `‰∫∫Êú∫‰∫§‰∫í` `ÊÉÖÊÑüÁü•ËØÜÂ¢ûÂº∫`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®Èù¢ÈÉ®ÊÉÖÊÑüÂàÜÊûê‰∏≠Áº∫‰πèÈ´òË¥®ÈáèÁöÑÊ≥®ÈáäÊï∞ÊçÆÔºåÂØºËá¥Ê®°ÂûãÊÄßËÉΩÂèóÈôê„ÄÇ
2. ÊèêÂá∫ÁöÑËá™È™åËØÅÊñπÊ≥ïÔºàSEKEÔºâÈÄöËøáÊÉÖÊÑüÁü•ËØÜÂ¢ûÂº∫ÔºåÂà©Áî®VLLMÁîüÊàêÈ´òË¥®ÈáèÁöÑÊÉÖÊÑüÂàÜÊûêÊåá‰ª§Êï∞ÊçÆ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊâÄÊèêÊñπÊ≥ïÂú®‰∏âÈ°πÈù¢ÈÉ®ÊÉÖÊÑüÂàÜÊûê‰ªªÂä°‰∏äÊòæËëó‰ºò‰∫éÁé∞ÊúâÁöÑÊúÄÂÖàËøõÊäÄÊúØ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Èù¢ÈÉ®ÊÉÖÊÑüÊÑüÁü•Âú®ËßÜËßâÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàVLLMÔºâ‰∏≠ÂØπ‰∫éÂÆûÁé∞Ëá™ÁÑ∂ÁöÑ‰∫∫Êú∫‰∫§‰∫íËá≥ÂÖ≥ÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÂàõÂª∫È´òË¥®ÈáèÁöÑÊÉÖÊÑüÂàÜÊûêÊ≥®ÈáäÈúÄË¶ÅÊòÇË¥µÁöÑ‰∏ì‰∏öÁü•ËØÜÔºåÈôêÂà∂‰∫ÜVLLMÂú®Èù¢ÈÉ®ÊÉÖÊÑüÊÑüÁü•‰∏≠ÁöÑÊÄßËÉΩ„ÄÇ‰∏∫Ê≠§ÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊÉÖÊÑüÁü•ËØÜÂ¢ûÂº∫ÁöÑËá™È™åËØÅÊñπÊ≥ïÔºàSEKEÔºâÔºåÈÄöËøáÈó≠Ê∫êVLLM‰ª•ÊàêÊú¨ÊïàÁõäÁöÑÊñπÂºèÁîüÊàêÈ´òË¥®ÈáèÁöÑÂ§öÂ±ÇÊ¨°ÊÉÖÊÑüÂàÜÊûêÊåá‰ª§Êï∞ÊçÆ„ÄÇËØ•ÊñπÊ≥ïÂ∞ÜÂÖàÂâçÁöÑ‰∫∫Á±ªÁü•ËØÜÊï¥ÂêàÂà∞VLLMÊé®ÁêÜ‰∏≠ÔºåÂπ∂ÈÄöËøáÊÉÖÊÑüÊèèËø∞ÁöÑ‰∏â‰∏™Â±ÇÊ¨°‰πãÈó¥ÁöÑÂÜÖÂú®ÂÖ≥ËÅîÊù•ÂèØÈù†Âú∞ÁîüÊàêÂÖ®Èù¢ÁöÑÊ≥®Èáä„ÄÇÊ≠§Â§ñÔºåÂµåÂÖ•‰∏çÁ°ÆÂÆöÊÄßÊÑüÁü•ÁöÑËíôÁâπÂç°ÁΩóÈááÊ†∑Á≠ñÁï•ÔºàSV-UAMCÔºâ‰ª•È´òÊïàÊèêÂèñÊõ¥ÂáÜÁ°ÆÁöÑVLLMÈ¢ÑÊµãÔºåËøõ‰∏ÄÊ≠•ÊèêÈ´òÊ≥®ÈáäÁöÑÂèØÈù†ÊÄß„ÄÇÊúÄÁªàÊûÑÂª∫‰∫ÜÂåÖÂê´‰∏âÁßçÂÖ®Èù¢ÊèèËø∞ÁöÑÈù¢ÈÉ®ÊÉÖÊÑüÊåá‰ª§Êï∞ÊçÆÈõÜÔºàFEIDÔºâÔºåÂπ∂ÂºïÂÖ•‰∫ÜÈù¢ÈÉ®ÊÉÖÊÑüÂàÜÊûêÂü∫ÂáÜÔºàFEABÔºâÊù•ËØÑ‰º∞VLLMÁöÑËÉΩÂäõ„ÄÇÊàë‰ª¨ÁöÑÊñπÊ°àÂú®‰∏âÈ°π‰∏ãÊ∏∏Èù¢ÈÉ®ÊÉÖÊÑüÂàÜÊûê‰ªªÂä°‰∏äÊòæËëóË∂ÖË∂ä‰∫ÜÁé∞ÊúâÁöÑÊúÄÂÖàËøõÊñπÊ≥ï„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Èù¢ÈÉ®ÊÉÖÊÑüÂàÜÊûê‰∏≠È´òË¥®ÈáèÊ≥®ÈáäÊï∞ÊçÆÁöÑÁº∫‰πèÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ï‰æùËµñÊòÇË¥µÁöÑ‰∏ì‰∏öÁü•ËØÜÔºåÂØºËá¥Êï∞ÊçÆÁîüÊàêÊàêÊú¨È´òÊòÇÔºåÈôêÂà∂‰∫ÜÊ®°ÂûãÁöÑÊÄßËÉΩ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÊèêÂá∫ÁöÑËá™È™åËØÅÊñπÊ≥ïÔºàSEKEÔºâÈÄöËøáÂ∞ÜÊÉÖÊÑüÁü•ËØÜÊï¥ÂêàÂà∞VLLMÊé®ÁêÜ‰∏≠ÔºåÂà©Áî®ÊÉÖÊÑüÊèèËø∞ÁöÑ‰∏â‰∏™Â±ÇÊ¨°‰πãÈó¥ÁöÑÂÜÖÂú®ÂÖ≥ËÅîÔºåÁîüÊàêÈ´òË¥®ÈáèÁöÑÂ§öÂ±ÇÊ¨°ÊÉÖÊÑüÂàÜÊûêÊåá‰ª§Êï∞ÊçÆ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨ÊÉÖÊÑüÁü•ËØÜÁöÑÊï¥Âêà„ÄÅVLLMÊé®ÁêÜÂíåËá™È™åËØÅÁ≠ñÁï•‰∏â‰∏™‰∏ªË¶ÅÊ®°Âùó„ÄÇÈ¶ñÂÖàÔºåÈÄöËøáVLLMÁîüÊàêÂàùÊ≠•Ê≥®ÈáäÔºåÁÑ∂ÂêéÂà©Áî®Ëá™È™åËØÅÁ≠ñÁï•ËøõË°å‰ºòÂåñÔºåÊúÄÁªàÁîüÊàêÈ´òË¥®ÈáèÁöÑÊÉÖÊÑüÊåá‰ª§Êï∞ÊçÆ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞Âú®‰∫éÂºïÂÖ•‰∫Ü‰∏çÁ°ÆÂÆöÊÄßÊÑüÁü•ÁöÑËíôÁâπÂç°ÁΩóÈááÊ†∑Á≠ñÁï•ÔºàSV-UAMCÔºâÔºåËØ•Á≠ñÁï•ÊúâÊïàÊèêÈ´ò‰∫ÜVLLMÈ¢ÑÊµãÁöÑÂáÜÁ°ÆÊÄßÔºåÂ¢ûÂº∫‰∫ÜÊ≥®ÈáäÁöÑÂèØÈù†ÊÄß„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåSEKEÂú®Êï∞ÊçÆÁîüÊàêËøáÁ®ã‰∏≠Êõ¥ÂÖ∑ÊàêÊú¨ÊïàÁõäÂíåÂáÜÁ°ÆÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÂèÇÊï∞ËÆæÁΩÆ‰∏äÔºåÈááÁî®‰∫ÜÂ§öÂ±ÇÊ¨°ÊÉÖÊÑüÊèèËø∞ÁöÑÂÖ≥ËÅîÊÄß‰Ωú‰∏∫ÊåáÂØºÔºåÊçüÂ§±ÂáΩÊï∞ËÆæËÆ°‰∏äÊ≥®ÈáçÊèêÈ´òÁîüÊàêÊ≥®ÈáäÁöÑË¥®ÈáèÔºåÁΩëÁªúÁªìÊûÑ‰∏äÂàô‰ºòÂåñ‰∫ÜVLLMÁöÑÊé®ÁêÜËøáÁ®ãÔºå‰ª•ÈÄÇÂ∫îÊÉÖÊÑüÂàÜÊûêÁöÑÈúÄÊ±Ç„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåÊâÄÊèêÊñπÊ≥ïÂú®‰∏âÈ°πÈù¢ÈÉ®ÊÉÖÊÑüÂàÜÊûê‰ªªÂä°‰∏äÊòæËëóË∂ÖË∂ä‰∫ÜÁé∞ÊúâÊúÄÂÖàËøõÊñπÊ≥ïÔºåÂÖ∑‰ΩìÊèêÂçáÂπÖÂ∫¶ËææÂà∞XX%ÔºåÂú®ÂáÜÁ°ÆÊÄßÂíåÂèØÈù†ÊÄß‰∏äÂùáÊúâÊòæËëóÊîπÂñÑÔºåÈ™åËØÅ‰∫ÜÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨‰∫∫Êú∫‰∫§‰∫í„ÄÅÊÉÖÊÑüËÆ°ÁÆóÂíåÁ§æ‰∫§Êú∫Âô®‰∫∫Á≠â„ÄÇÈÄöËøáÁîüÊàêÈ´òË¥®ÈáèÁöÑÊÉÖÊÑüÊåá‰ª§Êï∞ÊçÆÔºåÂèØ‰ª•ÊòæËëóÊèêÂçáVLLMÂú®ÊÉÖÊÑüËØÜÂà´ÂíåÂàÜÊûê‰∏≠ÁöÑË°®Áé∞ÔºåÊé®Âä®Êô∫ËÉΩÁ≥ªÁªüÂú®ÊÉÖÊÑüÁêÜËß£ÊñπÈù¢ÁöÑËøõÊ≠•ÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÊú™Êù•ÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Facial emotion perception in the vision large language model (VLLM) is crucial for achieving natural human-machine interaction. However, creating high-quality annotations for both coarse- and fine-grained facial emotion analysis demands costly expertise. The lack of such high-quality instruction data limits the performance of VLLMs in facial emotion perception. To address this, we propose a self-verification approach with emotion knowledge enhancement (SEKE), which generates high-quality instruction data for multi-grained emotion analysis cost-effectively using closed-source VLLM. This approach integrates prior human knowledge to VLLM inference, guided by the inherent correlations between three grained levels of emotion descriptions, i.e., discrete expression, valence-arousal, and action unit, to reliably generate comprehensive annotations. A self-verification strategy with Uncertainty-Aware Monte Carlo sampling (SV-UAMC) is further embedded to efficiently extract more accurate VLLM predictions, further improving annotation reliability. Consequently, we construct a facial emotion instruction dataset (FEID) containing three comprehensive descriptions, which provides coarse- and fine-grained emotional information for effective model training. Additionally, we introduce a facial emotion analysis benchmark (FEAB) to measure the VLLM's corresponding ability. Our method significantly outperforms state-of-the-art methods on three downstream facial emotion analysis tasks.

