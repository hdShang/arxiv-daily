---
layout: default
title: A Framework for Adversarial Analysis of Decision Support Systems Prior to Deployment
---

# A Framework for Adversarial Analysis of Decision Support Systems Prior to Deployment

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21414" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21414v1</a>
  <a href="https://arxiv.org/pdf/2505.21414.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21414v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21414v1', 'A Framework for Adversarial Analysis of Decision Support Systems Prior to Deployment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Brett Bissey, Kyle Gatesman, Walker Dimon, Mohammad Alam, Luis Robaina, Joseph Weissman

**åˆ†ç±»**: cs.LG, cs.AI, cs.GT

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¯¹å†³ç­–æ”¯æŒç³»ç»Ÿçš„å¯¹æŠ—æ€§åˆ†ææ¡†æ¶ä»¥å¢å¼ºå®‰å…¨æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¯¹æŠ—æ€§åˆ†æ` `å†³ç­–æ”¯æŒç³»ç»Ÿ` `æ·±åº¦å¼ºåŒ–å­¦ä¹ ` `å®‰å…¨æœºåˆ¶` `è¡Œä¸ºæ¨¡å¼` `æ”»å‡»æ¨¡æ‹Ÿ` `ç³»ç»Ÿè„†å¼±æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å†³ç­–æ”¯æŒç³»ç»Ÿåœ¨é¢å¯¹å¯¹æŠ—æ€§æ”»å‡»æ—¶ç¼ºä¹æœ‰æ•ˆçš„åˆ†æå’Œé˜²æŠ¤æœºåˆ¶ï¼Œå¯¼è‡´å…¶åœ¨é«˜é£é™©ç¯å¢ƒä¸­çš„åº”ç”¨å—åˆ°é™åˆ¶ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶ï¼Œé€šè¿‡æ¨¡æ‹Ÿåˆ†æå†³ç­–æ”¯æŒç³»ç»Ÿçš„è¡Œä¸ºæ¨¡å¼å’Œè„†å¼±æ€§ï¼Œå¸®åŠ©ç ”ç©¶äººå‘˜è¯„ä¼°å¯¹æŠ—æ€§æ”»å‡»çš„å½±å“ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆå‘ç°å’Œæ’åä¸åŒæ”»å‡»çš„å½±å“ï¼Œå¹¶éªŒè¯äº†å¯¹æŠ—æ€§æ”»å‡»åœ¨ä¸åŒæ¶æ„å’Œç®—æ³•ä¸­çš„å¯è½¬ç§»æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ä»‹ç»äº†ä¸€ç§ç»¼åˆæ¡†æ¶ï¼Œæ—¨åœ¨åˆ†æå’Œä¿æŠ¤ä½¿ç”¨æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDRLï¼‰è®­ç»ƒçš„å†³ç­–æ”¯æŒç³»ç»Ÿï¼Œåœ¨éƒ¨ç½²å‰æä¾›å¯¹å­¦ä¹ è¡Œä¸ºæ¨¡å¼å’Œé€šè¿‡æ¨¡æ‹Ÿå‘ç°çš„è„†å¼±æ€§çš„æ´å¯Ÿã€‚è¯¥æ¡†æ¶å¸®åŠ©å¼€å‘ç²¾ç¡®æ—¶æœºå’Œé’ˆå¯¹æ€§çš„è§‚å¯Ÿæ‰°åŠ¨ï¼Œä½¿ç ”ç©¶äººå‘˜èƒ½å¤Ÿåœ¨æˆ˜ç•¥å†³ç­–èƒŒæ™¯ä¸‹è¯„ä¼°å¯¹æŠ—æ€§æ”»å‡»ç»“æœã€‚æˆ‘ä»¬åœ¨å®šåˆ¶çš„æˆ˜ç•¥æ¸¸æˆCyberStrikeä¸­éªŒè¯äº†è¯¥æ¡†æ¶ï¼Œè§†è§‰åŒ–ä»£ç†è¡Œä¸ºï¼Œå¹¶è¯„ä¼°å¯¹æŠ—æ€§ç»“æœã€‚é€šè¿‡è¯¥æ¡†æ¶ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç³»ç»Ÿå‘ç°å’Œæ’åæ”»å‡»å¯¹å„ç§è§‚å¯ŸæŒ‡æ ‡å’Œæ—¶é—´æ­¥å½±å“çš„æ–¹æ³•ï¼Œå¹¶è¿›è¡Œäº†å®éªŒä»¥è¯„ä¼°å¯¹æŠ—æ€§æ”»å‡»åœ¨ä¸åŒä»£ç†æ¶æ„å’ŒDRLè®­ç»ƒç®—æ³•ä¸­çš„å¯è½¬ç§»æ€§ã€‚ç ”ç©¶ç»“æœå¼ºè°ƒäº†åœ¨é«˜é£é™©ç¯å¢ƒä¸­ä¿æŠ¤å†³ç­–æ”¿ç­–æ‰€éœ€çš„å¼ºå¤§å¯¹æŠ—é˜²å¾¡æœºåˆ¶çš„å…³é”®æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å†³ç­–æ”¯æŒç³»ç»Ÿåœ¨éƒ¨ç½²å‰ç¼ºä¹å¯¹æŠ—æ€§åˆ†æçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†è¯†åˆ«å’Œè¯„ä¼°ç³»ç»Ÿçš„è„†å¼±æ€§ï¼Œå¯¼è‡´åœ¨å®é™…åº”ç”¨ä¸­å¯èƒ½é­å—æ”»å‡»ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºçš„æ¡†æ¶é€šè¿‡æ¨¡æ‹Ÿç¯å¢ƒåˆ†æå­¦ä¹ åˆ°çš„è¡Œä¸ºæ¨¡å¼ï¼Œå¼€å‘é’ˆå¯¹æ€§çš„è§‚å¯Ÿæ‰°åŠ¨ï¼Œä»¥è¯„ä¼°å¯¹æŠ—æ€§æ”»å‡»çš„ç»“æœï¼Œä»è€Œå¢å¼ºç³»ç»Ÿçš„å®‰å…¨æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼Œé¦–å…ˆæ˜¯è¡Œä¸ºæ¨¡å¼åˆ†ææ¨¡å—ï¼Œå…¶æ¬¡æ˜¯æ”»å‡»æ¨¡æ‹Ÿæ¨¡å—ï¼Œæœ€åæ˜¯ç»“æœè¯„ä¼°æ¨¡å—ã€‚é€šè¿‡è¿™äº›æ¨¡å—çš„ååŒå·¥ä½œï¼Œç ”ç©¶äººå‘˜å¯ä»¥å…¨é¢äº†è§£ç³»ç»Ÿçš„è„†å¼±æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºç³»ç»ŸåŒ–åœ°å‘ç°å’Œæ’åæ”»å‡»å¯¹è§‚å¯ŸæŒ‡æ ‡å’Œæ—¶é—´æ­¥çš„å½±å“ï¼Œè¿™ä¸€æ–¹æ³•åœ¨ç°æœ‰æ–‡çŒ®ä¸­å°šæœªå¾—åˆ°å……åˆ†æ¢è®¨ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¡†æ¶ä¸­é‡‡ç”¨äº†ç‰¹å®šçš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ï¼Œä»¥ç¡®ä¿è§‚å¯Ÿæ‰°åŠ¨çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œç½‘ç»œç»“æ„è®¾è®¡è€ƒè™‘äº†ä¸åŒä»£ç†æ¶æ„çš„å…¼å®¹æ€§ï¼Œä»¥æé«˜å®éªŒçš„æ™®é€‚æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨è¯¥æ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«å‡ºå¤šç§å¯¹æŠ—æ€§æ”»å‡»ï¼Œå¹¶åœ¨ä¸åŒä»£ç†æ¶æ„å’ŒDRLè®­ç»ƒç®—æ³•ä¸­éªŒè¯äº†æ”»å‡»çš„å¯è½¬ç§»æ€§ã€‚å…·ä½“è€Œè¨€ï¼Œæ”»å‡»çš„å½±å“åœ¨ä¸åŒè§‚å¯ŸæŒ‡æ ‡ä¸Šæœ‰æ˜¾è‘—å·®å¼‚ï¼Œæå‡äº†å¯¹ç³»ç»Ÿè„†å¼±æ€§çš„ç†è§£ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬é‡‘èå†³ç­–ã€åŒ»ç–—è¯Šæ–­å’Œè‡ªåŠ¨é©¾é©¶ç­‰é«˜é£é™©ç¯å¢ƒã€‚åœ¨è¿™äº›é¢†åŸŸï¼Œå†³ç­–æ”¯æŒç³»ç»Ÿçš„å®‰å…¨æ€§è‡³å…³é‡è¦ï¼Œç ”ç©¶æˆæœå¯ä¸ºç³»ç»Ÿçš„å®‰å…¨é˜²æŠ¤æä¾›ç†è®ºåŸºç¡€å’Œå®è·µæŒ‡å¯¼ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å¹¿æ³›åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper introduces a comprehensive framework designed to analyze and secure decision-support systems trained with Deep Reinforcement Learning (DRL), prior to deployment, by providing insights into learned behavior patterns and vulnerabilities discovered through simulation. The introduced framework aids in the development of precisely timed and targeted observation perturbations, enabling researchers to assess adversarial attack outcomes within a strategic decision-making context. We validate our framework, visualize agent behavior, and evaluate adversarial outcomes within the context of a custom-built strategic game, CyberStrike. Utilizing the proposed framework, we introduce a method for systematically discovering and ranking the impact of attacks on various observation indices and time-steps, and we conduct experiments to evaluate the transferability of adversarial attacks across agent architectures and DRL training algorithms. The findings underscore the critical need for robust adversarial defense mechanisms to protect decision-making policies in high-stakes environments.

