---
layout: default
title: Let Me Think! A Long Chain-of-Thought Can Be Worth Exponentially Many Short Ones
---

# Let Me Think! A Long Chain-of-Thought Can Be Worth Exponentially Many Short Ones

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21825" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21825v1</a>
  <a href="https://arxiv.org/pdf/2505.21825.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21825v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21825v1', 'Let Me Think! A Long Chain-of-Thought Can Be Worth Exponentially Many Short Ones')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Parsa Mirtaheri, Ezra Edelman, Samy Jelassi, Eran Malach, Enric Boix-Adsera

**åˆ†ç±»**: cs.LG, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé•¿é“¾æ€ç»´ä»¥è§£å†³æ¨ç†æ•ˆç‡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ¨ç†æ•ˆç‡` `é•¿é“¾æ€ç»´` `å›¾è¿æ¥æ€§` `è¯­è¨€æ¨¡å‹` `é¡ºåºæ‰©å±•` `å¹¶è¡Œæ‰©å±•` `æ¨ç†ç­–ç•¥`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æ¨ç†æ—¶è®¡ç®—çš„åˆ†é…ä¸Šç¼ºä¹æ˜ç¡®çš„æŒ‡å¯¼ï¼Œå°¤å…¶æ˜¯åœ¨é¡ºåºä¸å¹¶è¡Œæ‰©å±•ä¹‹é—´çš„é€‰æ‹©ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡åˆ†æå›¾è¿æ¥æ€§é—®é¢˜ï¼Œå±•ç¤ºé¡ºåºæ‰©å±•åœ¨æŸäº›æƒ…å†µä¸‹çš„æŒ‡æ•°çº§ä¼˜åŠ¿ï¼Œæä¾›æ–°çš„æ¨ç†ç­–ç•¥ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œé¡ºåºæ‰©å±•åœ¨å¤šä¸ªè¯­è¨€æ¨¡å‹ä¸Šæ˜¾è‘—æå‡äº†æ¨ç†æ€§èƒ½ï¼ŒéªŒè¯äº†ç†è®ºåˆ†æçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ¨ç†æ—¶çš„è®¡ç®—å·²æˆä¸ºæå‡å¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›çš„é‡è¦æ–¹å‘ã€‚ç„¶è€Œï¼Œå°½ç®¡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œæ¨ç†æ—¶è®¡ç®—çš„æœ€ä½³åˆ†é…ä»ç„¶ä¸å¤Ÿæ˜ç¡®ã€‚æœ¬æ–‡æ¢è®¨äº†åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œæ˜¯å¦åº”ä¼˜å…ˆè€ƒè™‘é¡ºåºæ‰©å±•ï¼ˆå¦‚æ›´é•¿çš„æ€ç»´é“¾ï¼‰æˆ–å¹¶è¡Œæ‰©å±•ï¼ˆå¦‚å¤šä¸ªçŸ­æ€ç»´é“¾çš„å¤šæ•°æŠ•ç¥¨ï¼‰ã€‚ç ”ç©¶è¡¨æ˜ï¼Œåœ¨æŸäº›æ¨ç†åœºæ™¯ä¸‹ï¼Œé¡ºåºæ‰©å±•ç›¸è¾ƒäºå¹¶è¡Œæ‰©å±•å…·æœ‰æŒ‡æ•°çº§çš„ä¼˜åŠ¿ã€‚é€šè¿‡åœ¨å›¾è¿æ¥æ€§é—®é¢˜çš„æŒ‘æˆ˜æ€§åˆ†å¸ƒä¸Šè¿›è¡Œç†è®ºéªŒè¯ï¼Œå¹¶ç»“åˆå¤šç§è¯­è¨€æ¨¡å‹çš„å®éªŒï¼ŒéªŒè¯äº†è¿™ä¸€å‘ç°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ¨ç†æ—¶è®¡ç®—åˆ†é…çš„æœ€ä½³ç­–ç•¥ï¼Œç‰¹åˆ«æ˜¯åœ¨é¡ºåºæ‰©å±•ä¸å¹¶è¡Œæ‰©å±•ä¹‹é—´çš„é€‰æ‹©ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†ç†è§£ä¸åŒæ¨ç†åœºæ™¯ä¸‹çš„ä¼˜åŠ¿ä¸åŠ£åŠ¿ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡é€šè¿‡ç ”ç©¶å›¾è¿æ¥æ€§é—®é¢˜ï¼Œæå‡ºåœ¨æŸäº›ç‰¹å®šæƒ…å†µä¸‹ï¼Œé¡ºåºæ‰©å±•èƒ½å¤Ÿæä¾›æŒ‡æ•°çº§çš„æ¨ç†ä¼˜åŠ¿ã€‚è¿™ä¸€è®¾è®¡æ—¨åœ¨æ­ç¤ºæ¨ç†è¿‡ç¨‹ä¸­çš„æ½œåœ¨æ•ˆç‡æå‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ç†è®ºåˆ†æå’Œå®éªŒéªŒè¯ä¸¤ä¸ªä¸»è¦éƒ¨åˆ†ã€‚é¦–å…ˆï¼Œé€šè¿‡å›¾è¿æ¥æ€§é—®é¢˜å»ºç«‹ç†è®ºæ¨¡å‹ï¼›å…¶æ¬¡ï¼Œåˆ©ç”¨å¤šç§è¯­è¨€æ¨¡å‹è¿›è¡Œå®éªŒï¼Œæ¯”è¾ƒä¸åŒæ€ç»´é“¾ç­–ç•¥çš„æ•ˆæœã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæ­ç¤ºäº†é¡ºåºæ‰©å±•åœ¨ç‰¹å®šæ¨ç†åœºæ™¯ä¸‹çš„æŒ‡æ•°çº§ä¼˜åŠ¿ï¼Œè¿™ä¸ä¼ ç»Ÿçš„å¹¶è¡Œæ‰©å±•æ–¹æ³•å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨äº†ä¸åŒçš„æ€ç»´é“¾ç­–ç•¥ï¼Œå¹¶é’ˆå¯¹å›¾è¿æ¥æ€§é—®é¢˜è®¾è®¡äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ï¼Œä»¥ä¼˜åŒ–æ¨ç†æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œé¡ºåºæ‰©å±•åœ¨å¤šä¸ªè¯­è¨€æ¨¡å‹ä¸Šç›¸è¾ƒäºå¹¶è¡Œæ‰©å±•çš„æ¨ç†æ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°50%ä»¥ä¸Šï¼ŒéªŒè¯äº†ç†è®ºåˆ†æçš„æœ‰æ•ˆæ€§å’Œå®é™…åº”ç”¨çš„æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€å›¾æ•°æ®åˆ†æå’Œå¤æ‚æ¨ç†ä»»åŠ¡ç­‰ã€‚é€šè¿‡ä¼˜åŒ–æ¨ç†ç­–ç•¥ï¼Œå¯ä»¥åœ¨å®é™…åº”ç”¨ä¸­æé«˜æ¨¡å‹çš„æ¨ç†æ•ˆç‡ï¼Œè¿›è€Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿåœ¨æ›´å¤æ‚åœºæ™¯ä¸‹çš„åº”ç”¨ä¸å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Inference-time computation has emerged as a promising scaling axis for improving large language model reasoning. However, despite yielding impressive performance, the optimal allocation of inference-time computation remains poorly understood. A central question is whether to prioritize sequential scaling (e.g., longer chains of thought) or parallel scaling (e.g., majority voting across multiple short chains of thought). In this work, we seek to illuminate the landscape of test-time scaling by demonstrating the existence of reasoning settings where sequential scaling offers an exponential advantage over parallel scaling. These settings are based on graph connectivity problems in challenging distributions of graphs. We validate our theoretical findings with comprehensive experiments across a range of language models, including models trained from scratch for graph connectivity with different chain of thought strategies as well as large reasoning models.

