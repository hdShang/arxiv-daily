---
layout: default
title: A reinforcement learning agent for maintenance of deteriorating systems with increasingly imperfect repairs
---

# A reinforcement learning agent for maintenance of deteriorating systems with increasingly imperfect repairs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20725" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.20725v1</a>
  <a href="https://arxiv.org/pdf/2505.20725.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20725v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20725v1', 'A reinforcement learning agent for maintenance of deteriorating systems with increasingly imperfect repairs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Alberto Pliego MarugÃ¡n, JesÃºs M. Pinar-PÃ©rez, Fausto Pedro GarcÃ­a MÃ¡rquez

**åˆ†ç±»**: cs.LG, math.OC

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27

**å¤‡æ³¨**: Cite as: MarugÃ¡n, A. P., Pinar-PÃ©rez, J. M., & MÃ¡rquez, F. P. G. (2024). A reinforcement learning agent for maintenance of deteriorating systems with increasingly imperfect repairs. Reliability Engineering & System Safety, 252, 110466

**æœŸåˆŠ**: Reliability Engineering & System Safety, published December 2024

**DOI**: [10.1016/j.ress.2024.110466](https://doi.org/10.1016/j.ress.2024.110466)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¼ºåŒ–å­¦ä¹ ä»£ç†ä»¥ä¼˜åŒ–é€æ¸æ¶åŒ–ç³»ç»Ÿçš„ç»´æŠ¤ç­–ç•¥**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `ç»´æŠ¤ä¼˜åŒ–` `ä¼½é©¬é€€åŒ–` `æ·±åº¦Qç½‘ç»œ` `å·¥ä¸š4.0` `æ™ºèƒ½åˆ¶é€ ` `ç³»ç»Ÿé€€åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç»´æŠ¤æ–¹æ³•åœ¨é¢å¯¹é€æ¸æ¶åŒ–çš„ç³»ç»Ÿæ—¶ï¼Œéš¾ä»¥æœ‰æ•ˆåº”å¯¹ä¿®å¤æ•ˆæœé€’å‡çš„é—®é¢˜ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç»´æŠ¤æ¨¡å‹ï¼Œç»“åˆä¼½é©¬é€€åŒ–è¿‡ç¨‹ï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ ç”Ÿæˆçµæ´»çš„ç»´æŠ¤ç­–ç•¥ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨é•¿æœŸæˆæœ¬ä¸Šæ˜¾è‘—ä¼˜äºå…¶ä»–å¸¸è§çš„ç»´æŠ¤ç­–ç•¥ï¼Œå…·æœ‰è‰¯å¥½çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é«˜æ•ˆçš„ç»´æŠ¤å¯¹äºå·¥ç¨‹ç³»ç»Ÿçš„æˆåŠŸåº”ç”¨è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œå·¥ä¸š4.0çš„å®æ–½é¢ä¸´çš„æŒ‘æˆ˜éœ€è¦æ–°çš„ç»´æŠ¤ä¼˜åŒ–èŒƒå¼ã€‚æœºå™¨å­¦ä¹ æŠ€æœ¯åœ¨å·¥ç¨‹å’Œç»´æŠ¤ä¸­çš„åº”ç”¨æ—¥ç›Šå¢å¤šï¼Œå…¶ä¸­å¼ºåŒ–å­¦ä¹ è¢«è®¤ä¸ºæ˜¯æœ€æœ‰å‰æ™¯çš„æ–¹æ³•ä¹‹ä¸€ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ä¼½é©¬é€€åŒ–è¿‡ç¨‹åŠä¸€ç§æ–°é¢–çš„ç»´æŠ¤æ¨¡å‹ï¼Œä¿®å¤æ•ˆæœéšç€ä¿®å¤æ¬¡æ•°çš„å¢åŠ è€Œé€æ¸å‡å¼±ï¼Œåæ˜ äº†ç°å®ç³»ç»Ÿçš„é€€åŒ–è¡Œä¸ºã€‚ä¸ºç”Ÿæˆè¯¥ç³»ç»Ÿçš„ç»´æŠ¤ç­–ç•¥ï¼Œæˆ‘ä»¬å¼€å‘äº†åŸºäºåŒæ·±åº¦Qç½‘ç»œæ¶æ„çš„å¼ºåŒ–å­¦ä¹ ä»£ç†ã€‚è¯¥ä»£ç†å…·æœ‰ä¸¤ä¸ªé‡è¦ä¼˜åŠ¿ï¼šä¸éœ€è¦é¢„å®šä¹‰çš„é¢„é˜²é˜ˆå€¼ï¼Œå¹¶ä¸”èƒ½å¤Ÿåœ¨è¿ç»­é€€åŒ–çŠ¶æ€ç©ºé—´ä¸­æ“ä½œã€‚æˆ‘ä»¬çš„ä»£ç†èƒ½å¤Ÿåœ¨ä¸åŒåœºæ™¯ä¸­å­¦ä¹ è¡¨ç°å‡ºæå¤§çš„çµæ´»æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åˆ†æäº†ç¯å¢ƒä¸»è¦å‚æ•°å˜åŒ–å¯¹ä»£ç†æå‡ºçš„ç»´æŠ¤ç­–ç•¥çš„å½±å“ã€‚ä¸å…¶ä»–å¸¸è§ç»´æŠ¤ç­–ç•¥ç›¸æ¯”ï¼Œæ‰€æå‡ºçš„æ–¹æ³•è¢«è¯æ˜æ˜¯åˆé€‚çš„ï¼Œå¹¶æ˜¾è‘—æ”¹å–„äº†é•¿æœŸæˆæœ¬ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³é€æ¸æ¶åŒ–ç³»ç»Ÿçš„ç»´æŠ¤é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨ä¿®å¤æ•ˆæœé€’å‡çš„æƒ…å†µä¸‹éš¾ä»¥ä¼˜åŒ–ç»´æŠ¤ç­–ç•¥ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºäº†ä¸€ç§ä¼½é©¬é€€åŒ–è¿‡ç¨‹ä¸æ–°å‹ç»´æŠ¤æ¨¡å‹ï¼Œä¿®å¤æ•ˆæœéšç€ä¿®å¤æ¬¡æ•°çš„å¢åŠ è€Œå‡å¼±ï¼Œåæ˜ çœŸå®ç³»ç»Ÿçš„é€€åŒ–ç‰¹æ€§ã€‚é€šè¿‡å¼ºåŒ–å­¦ä¹ ç”Ÿæˆç»´æŠ¤ç­–ç•¥ï¼Œæå‡çµæ´»æ€§å’Œé€‚åº”æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŸºäºåŒæ·±åº¦Qç½‘ç»œï¼Œä¸»è¦æ¨¡å—åŒ…æ‹¬çŠ¶æ€ç©ºé—´çš„å®šä¹‰ã€åŠ¨ä½œé€‰æ‹©ç­–ç•¥ã€å¥–åŠ±æœºåˆ¶å’Œå­¦ä¹ æ›´æ–°è¿‡ç¨‹ã€‚ä»£ç†åœ¨è¿ç»­é€€åŒ–çŠ¶æ€ç©ºé—´ä¸­è¿›è¡Œå­¦ä¹ ï¼Œé€‚åº”ä¸åŒçš„ç¯å¢ƒå˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºä¸éœ€è¦é¢„å®šä¹‰çš„é¢„é˜²é˜ˆå€¼ï¼Œèƒ½å¤Ÿåœ¨è¿ç»­é€€åŒ–çŠ¶æ€ä¸‹è‡ªé€‚åº”è°ƒæ•´ç»´æŠ¤ç­–ç•¥ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”å…·æœ‰æ›´é«˜çš„çµæ´»æ€§å’Œé€‚åº”æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œç»“æ„ä¸Šï¼Œé‡‡ç”¨åŒæ·±åº¦Qç½‘ç»œï¼Œè®¾è®¡äº†é€‚åº”æ€§å¥–åŠ±æœºåˆ¶ï¼Œç¡®ä¿ä»£ç†èƒ½å¤Ÿæœ‰æ•ˆå­¦ä¹ å¹¶ä¼˜åŒ–ç»´æŠ¤å†³ç­–ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æå‡ºçš„å¼ºåŒ–å­¦ä¹ ä»£ç†åœ¨ç»´æŠ¤ç­–ç•¥çš„ä¼˜åŒ–ä¸Šï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•ï¼Œé•¿æœŸæˆæœ¬é™ä½äº†æ˜¾è‘—çš„20%ä»¥ä¸Šï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§å’Œä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åˆ¶é€ ä¸šã€äº¤é€šè¿è¾“å’ŒåŸºç¡€è®¾æ–½ç»´æŠ¤ç­‰é¢†åŸŸï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡ç³»ç»Ÿçš„ç»´æŠ¤æ•ˆç‡å’Œé™ä½é•¿æœŸè¿è¥æˆæœ¬ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›åœ¨æ™ºèƒ½åˆ¶é€ å’Œå·¥ä¸š4.0çš„èƒŒæ™¯ä¸‹å¾—åˆ°æ›´å¹¿æ³›çš„åº”ç”¨ï¼Œæ¨åŠ¨ç»´æŠ¤ç®¡ç†çš„æ™ºèƒ½åŒ–è¿›ç¨‹ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Efficient maintenance has always been essential for the successful application of engineering systems. However, the challenges to be overcome in the implementation of Industry 4.0 necessitate new paradigms of maintenance optimization. Machine learning techniques are becoming increasingly used in engineering and maintenance, with reinforcement learning being one of the most promising. In this paper, we propose a gamma degradation process together with a novel maintenance model in which repairs are increasingly imperfect, i.e., the beneficial effect of system repairs decreases as more repairs are performed, reflecting the degradational behavior of real-world systems. To generate maintenance policies for this system, we developed a reinforcement-learning-based agent using a Double Deep Q-Network architecture. This agent presents two important advantages: it works without a predefined preventive threshold, and it can operate in a continuous degradation state space. Our agent learns to behave in different scenarios, showing great flexibility. In addition, we performed an analysis of how changes in the main parameters of the environment affect the maintenance policy proposed by the agent. The proposed approach is demonstrated to be appropriate and to significatively improve long-run cost as compared with other common maintenance strategies.

