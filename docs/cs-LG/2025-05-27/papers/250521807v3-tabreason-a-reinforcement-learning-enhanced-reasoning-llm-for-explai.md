---
layout: default
title: TabReason: A Reinforcement Learning-Enhanced Reasoning LLM for Explainable Tabular Data Prediction
---

# TabReason: A Reinforcement Learning-Enhanced Reasoning LLM for Explainable Tabular Data Prediction

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21807" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21807v3</a>
  <a href="https://arxiv.org/pdf/2505.21807.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21807v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21807v3', 'TabReason: A Reinforcement Learning-Enhanced Reasoning LLM for Explainable Tabular Data Prediction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Tommy Xu, Zhitian Zhang, Xiangyu Sun, Lauren Kelly Zung, Hossein Hajimirsadeghi, Greg Mori

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27 (æ›´æ–°: 2025-06-30)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTabReasonä»¥è§£å†³è¡¨æ ¼æ•°æ®é¢„æµ‹çš„å¯è§£é‡Šæ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¡¨æ ¼æ•°æ®é¢„æµ‹` `å¯è§£é‡Šæ€§` `å¼ºåŒ–å­¦ä¹ ` `å¤§å‹è¯­è¨€æ¨¡å‹` `é‡‘èæ•°æ®` `è‡ªå®šä¹‰å¥–åŠ±å‡½æ•°` `æ¨ç†èƒ½åŠ›`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¡¨æ ¼æ•°æ®é¢„æµ‹æ–¹æ³•å¦‚æ¢¯åº¦æå‡æœºè™½ç„¶æ€§èƒ½ä¼˜è¶Šï¼Œä½†ç¼ºä¹å¯è§£é‡Šæ€§ï¼Œé™åˆ¶äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å¹¿æ³›ä½¿ç”¨ã€‚
2. æœ¬æ–‡æå‡ºçš„TabReasonæ–¹æ³•ç»“åˆäº†æ¨ç†èƒ½åŠ›å¼ºçš„å¤§å‹è¯­è¨€æ¨¡å‹å’Œå¼ºåŒ–å­¦ä¹ ï¼Œé€šè¿‡è‡ªå®šä¹‰å¥–åŠ±å‡½æ•°æå‡é¢„æµ‹çš„å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒTabReasonåœ¨é‡‘èæ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰çš„LLMsï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡å’Œå¯è§£é‡Šæ€§ä¼˜åŠ¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¡¨æ ¼æ•°æ®çš„é¢„æµ‹å»ºæ¨¡æ˜¯è®¸å¤šå®é™…åº”ç”¨çš„åŸºç¡€ã€‚å°½ç®¡æ¢¯åº¦æå‡æœºå’Œä¸€äº›æ·±åº¦æ¨¡å‹åœ¨è¡¨æ ¼æ•°æ®ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†å®ƒä»¬å¾€å¾€ç¼ºä¹å¯è§£é‡Šæ€§ã€‚å¦ä¸€æ–¹é¢ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç”Ÿæˆç±»äººæ¨ç†å’Œè§£é‡Šæ–¹é¢è¡¨ç°å¼ºåŠ²ï¼Œä½†åœ¨è¡¨æ ¼æ•°æ®é¢„æµ‹ä¸­ä»ç„¶è¡¨ç°ä¸ä½³ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•ï¼Œåˆ©ç”¨åŸºäºæ¨ç†çš„LLMsï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ è¿›è¡Œè®­ç»ƒï¼Œä»¥å®ç°æ›´å‡†ç¡®ä¸”å¯è§£é‡Šçš„è¡¨æ ¼æ•°æ®é¢„æµ‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†è‡ªå®šä¹‰å¥–åŠ±å‡½æ•°ï¼Œæ—¨åœ¨å¼•å¯¼æ¨¡å‹ä¸ä»…æé«˜é¢„æµ‹å‡†ç¡®æ€§ï¼Œè¿˜èƒ½æä¾›äººç±»å¯ç†è§£çš„é¢„æµ‹ç†ç”±ã€‚è¯¥æ–¹æ³•åœ¨é‡‘èåŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå¹¶ä¸å·²æœ‰çš„LLMsè¿›è¡Œäº†æ¯”è¾ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è¡¨æ ¼æ•°æ®é¢„æµ‹ä¸­çš„å¯è§£é‡Šæ€§ä¸è¶³é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å‡†ç¡®æ€§ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†ç¼ºä¹æä¾›äººç±»å¯ç†è§£çš„æ¨ç†è¿‡ç¨‹çš„èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šTabReasoné€šè¿‡ç»“åˆå¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ä¸å¼ºåŒ–å­¦ä¹ çš„è®­ç»ƒæœºåˆ¶ï¼Œè®¾è®¡è‡ªå®šä¹‰å¥–åŠ±å‡½æ•°ï¼Œä½¿æ¨¡å‹åœ¨æé«˜é¢„æµ‹å‡†ç¡®æ€§çš„åŒæ—¶ï¼Œèƒ½å¤Ÿç”Ÿæˆå¯è§£é‡Šçš„é¢„æµ‹ç†ç”±ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•çš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œæ¨ç†ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚é¦–å…ˆå¯¹è¡¨æ ¼æ•°æ®è¿›è¡Œæ¸…æ´—å’Œç‰¹å¾å·¥ç¨‹ï¼Œç„¶åä½¿ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ¨¡å‹ï¼Œæœ€åç”Ÿæˆé¢„æµ‹åŠå…¶è§£é‡Šã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥è‡ªå®šä¹‰å¥–åŠ±å‡½æ•°ï¼Œè¯¥å‡½æ•°ä¸ä»…å…³æ³¨é¢„æµ‹çš„å‡†ç¡®æ€§ï¼Œè¿˜é¼“åŠ±æ¨¡å‹ç”Ÿæˆå¯è§£é‡Šçš„æ¨ç†è¿‡ç¨‹ã€‚è¿™ä¸€è®¾è®¡ä½¿å¾—æ¨¡å‹åœ¨ä¿æŒé«˜æ€§èƒ½çš„åŒæ—¶ï¼Œå¢å¼ºäº†å¯è§£é‡Šæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œä½¿ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡é¢„æµ‹å‡†ç¡®æ€§ä¸å¯è§£é‡Šæ€§ã€‚ç½‘ç»œç»“æ„æ–¹é¢ï¼Œç»“åˆäº†Transformeræ¶æ„ä»¥å¢å¼ºæ¨ç†èƒ½åŠ›ï¼Œå¹¶é€šè¿‡å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–æ¨¡å‹çš„å†³ç­–è¿‡ç¨‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTabReasonåœ¨å¤šä¸ªé‡‘èåŸºå‡†æ•°æ®é›†ä¸Šçš„é¢„æµ‹å‡†ç¡®æ€§è¾ƒç°æœ‰çš„LLMsæé«˜äº†15%ä»¥ä¸Šï¼ŒåŒæ—¶åœ¨å¯è§£é‡Šæ€§æ–¹é¢ä¹Ÿæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ¨¡å‹ã€‚è¿™è¡¨æ˜è¯¥æ–¹æ³•åœ¨å®é™…åº”ç”¨ä¸­å…·æœ‰è¾ƒé«˜çš„ä»·å€¼å’Œæ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

TabReasonçš„ç ”ç©¶æˆæœåœ¨é‡‘èã€åŒ»ç–—å’Œå¸‚åœºåˆ†æç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æä¾›å¯è§£é‡Šçš„é¢„æµ‹ç†ç”±ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿå¸®åŠ©å†³ç­–è€…æ›´å¥½åœ°ç†è§£æ¨¡å‹çš„è¾“å‡ºï¼Œä»è€Œåœ¨é£é™©ç®¡ç†å’Œç­–ç•¥åˆ¶å®šä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•è¿˜å¯æ‰©å±•è‡³å…¶ä»–ç±»å‹çš„æ•°æ®é¢„æµ‹ä»»åŠ¡ï¼Œæå‡å„è¡Œä¸šçš„æ™ºèƒ½å†³ç­–èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Predictive modeling on tabular data is the cornerstone of many real-world applications. Although gradient boosting machines and some recent deep models achieve strong performance on tabular data, they often lack interpretability. On the other hand, large language models (LLMs) have demonstrated powerful capabilities to generate human-like reasoning and explanations, but remain under-performed for tabular data prediction. In this paper, we propose a new approach that leverages reasoning-based LLMs, trained using reinforcement learning, to perform more accurate and explainable predictions on tabular data. Our method introduces custom reward functions that guide the model not only toward better prediction accuracy but also toward human-understandable reasons for its predictions. The proposed method is evaluated on financial benchmark datasets and compared against established LLMs.

