---
layout: default
title: MLE-STAR: Machine Learning Engineering Agent via Search and Targeted Refinement
---

# MLE-STAR: Machine Learning Engineering Agent via Search and Targeted Refinement

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.15692" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.15692v3</a>
  <a href="https://arxiv.org/pdf/2506.15692.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.15692v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.15692v3', 'MLE-STAR: Machine Learning Engineering Agent via Search and Targeted Refinement')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jaehyun Nam, Jinsung Yoon, Jiefeng Chen, Jinwoo Shin, Sercan Ã–. ArÄ±k, Tomas Pfister

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27 (æ›´æ–°: 2025-08-28)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMLE-STARä»¥è§£å†³æœºå™¨å­¦ä¹ å·¥ç¨‹ä¸­çš„æ¨¡å‹é€‰æ‹©ä¸æ·±åº¦æ¢ç´¢é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æœºå™¨å­¦ä¹ å·¥ç¨‹` `æ¨¡å‹é€‰æ‹©` `æ·±åº¦æ¢ç´¢` `å¤§å‹è¯­è¨€æ¨¡å‹` `è‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ ` `æ¶ˆèç ”ç©¶` `é›†æˆæ–¹æ³•`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æœºå™¨å­¦ä¹ å·¥ç¨‹ä»£ç†æ–¹æ³•è¿‡äºä¾èµ–å¤§å‹è¯­è¨€æ¨¡å‹çš„çŸ¥è¯†ï¼Œä¸”æ¢ç´¢ç­–ç•¥ç²—ç³™ï¼Œæ— æ³•æœ‰æ•ˆé€‰æ‹©ä»»åŠ¡ç‰¹å®šæ¨¡å‹ã€‚
2. MLE-STARé€šè¿‡æœç´¢å¼•æ“è·å–å¤–éƒ¨çŸ¥è¯†ï¼Œå½¢æˆåˆæ­¥è§£å†³æ–¹æ¡ˆï¼Œå¹¶é’ˆå¯¹ç‰¹å®šMLç»„ä»¶è¿›è¡Œè¿­ä»£ä¼˜åŒ–ï¼Œæå‡æ¨¡å‹æ€§èƒ½ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMLE-STARåœ¨64%çš„Kaggleç«èµ›ä¸­è·å¾—å¥–ç‰Œï¼Œæ˜¾è‘—è¶…è¶Šå…¶ä»–æ–¹æ³•ï¼Œå±•ç¤ºäº†å…¶æœ‰æ•ˆæ€§å’Œä¼˜åŠ¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æœºå™¨å­¦ä¹ å·¥ç¨‹ï¼ˆMLEï¼‰ä»£ç†å¯ä»¥é€šè¿‡ä»£ç ç”Ÿæˆè‡ªåŠ¨å®ç°æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å¾€å¾€è¿‡äºä¾èµ–LLMçš„å†…åœ¨çŸ¥è¯†ï¼Œå¹¶é‡‡ç”¨ç²—ç³™çš„æ¢ç´¢ç­–ç•¥ï¼Œä¸€æ¬¡æ€§ä¿®æ”¹æ•´ä¸ªä»£ç ç»“æ„ã€‚è¿™é™åˆ¶äº†å®ƒä»¬é€‰æ‹©æœ‰æ•ˆçš„ä»»åŠ¡ç‰¹å®šæ¨¡å‹å’Œåœ¨ç‰¹å®šç»„ä»¶å†…è¿›è¡Œæ·±åº¦æ¢ç´¢çš„èƒ½åŠ›ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†MLE-STARï¼Œä¸€ç§æ–°é¢–çš„MLEä»£ç†æ„å»ºæ–¹æ³•ã€‚MLE-STARé¦–å…ˆåˆ©ç”¨æœç´¢å¼•æ“ä»ç½‘ç»œä¸­æ£€ç´¢æœ‰æ•ˆæ¨¡å‹ï¼Œå½¢æˆåˆæ­¥è§£å†³æ–¹æ¡ˆï¼Œç„¶åé€šè¿‡é’ˆå¯¹ç‰¹å®šMLç»„ä»¶çš„å¤šç§ç­–ç•¥è¿›è¡Œè¿­ä»£ä¼˜åŒ–ã€‚è¿™ä¸€æ¢ç´¢è¿‡ç¨‹ç”±æ¶ˆèç ”ç©¶æŒ‡å¯¼ï¼Œåˆ†æå„ä¸ªä»£ç å—çš„å½±å“ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°çš„é›†æˆæ–¹æ³•ï¼Œåˆ©ç”¨MLE-STARå»ºè®®çš„æœ‰æ•ˆç­–ç•¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMLE-STARåœ¨MLE-bench Liteçš„64% Kaggleç«èµ›ä¸­è·å¾—å¥–ç‰Œï¼Œæ˜¾è‘—ä¼˜äºæœ€ä½³æ›¿ä»£æ–¹æ¡ˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„æœºå™¨å­¦ä¹ å·¥ç¨‹ä»£ç†æ–¹æ³•åœ¨æ¨¡å‹é€‰æ‹©å’Œç‰¹å®šç»„ä»¶çš„æ·±åº¦æ¢ç´¢ä¸Šå­˜åœ¨å±€é™ï¼Œæ— æ³•æœ‰æ•ˆåˆ©ç”¨å¤–éƒ¨çŸ¥è¯†å’Œè¿›è¡Œç»†è‡´çš„å®éªŒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMLE-STARé€šè¿‡ç»“åˆæœç´¢å¼•æ“è·å–å¤–éƒ¨æ¨¡å‹ä¿¡æ¯ï¼Œå½¢æˆåˆæ­¥è§£å†³æ–¹æ¡ˆï¼Œå¹¶é€šè¿‡é’ˆå¯¹ç‰¹å®šç»„ä»¶çš„ç­–ç•¥è¿›è¡Œè¿­ä»£ä¼˜åŒ–ï¼Œä»è€Œæå‡æ¨¡å‹çš„é€‰æ‹©å’Œæ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMLE-STARçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µæ˜¯åˆ©ç”¨æœç´¢å¼•æ“æ£€ç´¢æœ‰æ•ˆæ¨¡å‹ï¼Œç¬¬äºŒé˜¶æ®µæ˜¯é€šè¿‡æ¶ˆèç ”ç©¶åˆ†æä»£ç å—çš„å½±å“ï¼Œè¿›è¡Œé’ˆå¯¹æ€§çš„ä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šMLE-STARçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶ç»“åˆäº†å¤–éƒ¨çŸ¥è¯†æ£€ç´¢ä¸æ·±åº¦ç»„ä»¶æ¢ç´¢çš„ç­–ç•¥ï¼ŒåŒºåˆ«äºç°æœ‰æ–¹æ³•çš„ç²—ç³™ä¿®æ”¹æ–¹å¼ï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°é€‰æ‹©å’Œä¼˜åŒ–æ¨¡å‹ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸Šï¼ŒMLE-STARé‡‡ç”¨äº†æ¶ˆèç ”ç©¶æ–¹æ³•æ¥æŒ‡å¯¼æ¢ç´¢è¿‡ç¨‹ï¼Œç¡®ä¿æ¯ä¸ªä»£ç å—çš„å½±å“è¢«å……åˆ†è¯„ä¼°ï¼ŒåŒæ—¶å¼•å…¥äº†ä¸€ç§æ–°çš„é›†æˆç­–ç•¥ä»¥å¢å¼ºæ¨¡å‹æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

MLE-STARåœ¨MLE-bench Liteçš„64% Kaggleç«èµ›ä¸­è·å¾—å¥–ç‰Œï¼Œæ˜¾ç¤ºå‡ºå…¶å“è¶Šçš„æ€§èƒ½ï¼Œæ˜¾è‘—ä¼˜äºæœ€ä½³æ›¿ä»£æ–¹æ¡ˆï¼Œè¯æ˜äº†å…¶åœ¨æœºå™¨å­¦ä¹ å·¥ç¨‹ä¸­çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MLE-STARçš„ç ”ç©¶æˆæœåœ¨æœºå™¨å­¦ä¹ å·¥ç¨‹é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨è‡ªåŠ¨åŒ–æ¨¡å‹æ„å»ºå’Œä¼˜åŒ–æ–¹é¢ã€‚å…¶æ–¹æ³•å¯ä»¥å¸®åŠ©æ•°æ®ç§‘å­¦å®¶å’Œå·¥ç¨‹å¸ˆæ›´é«˜æ•ˆåœ°é€‰æ‹©å’Œè°ƒæ•´æ¨¡å‹ï¼Œæå‡æœºå™¨å­¦ä¹ é¡¹ç›®çš„æˆåŠŸç‡å’Œæ•ˆç‡ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½åœ¨æ›´å¤šå¤æ‚çš„æœºå™¨å­¦ä¹ ä»»åŠ¡ä¸­å¾—åˆ°åº”ç”¨ï¼Œæ¨åŠ¨è‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Agents based on large language models (LLMs) for machine learning engineering (MLE) can automatically implement ML models via code generation. However, existing approaches to build such agents often rely heavily on inherent LLM knowledge and employ coarse exploration strategies that modify the entire code structure at once. This limits their ability to select effective task-specific models and perform deep exploration within specific components, such as experimenting extensively with feature engineering options. To overcome these, we propose MLE-STAR, a novel approach to build MLE agents. MLE-STAR first leverages external knowledge by using a search engine to retrieve effective models from the web, forming an initial solution, then iteratively refines it by exploring various strategies targeting specific ML components. This exploration is guided by ablation studies analyzing the impact of individual code blocks. Furthermore, we introduce a novel ensembling method using an effective strategy suggested by MLE-STAR. Our experimental results show that MLE-STAR achieves medals in 64% of the Kaggle competitions on the MLE-bench Lite, significantly outperforming the best alternative.

