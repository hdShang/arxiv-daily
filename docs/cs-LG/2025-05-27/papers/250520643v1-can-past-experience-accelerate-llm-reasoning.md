---
layout: default
title: Can Past Experience Accelerate LLM Reasoning?
---

# Can Past Experience Accelerate LLM Reasoning?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20643" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.20643v1</a>
  <a href="https://arxiv.org/pdf/2505.20643.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20643v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20643v1', 'Can Past Experience Accelerate LLM Reasoning?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Bo Pan, Liang Zhao

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSpeedupLLMæ¡†æ¶ä»¥åŠ é€Ÿå¤§è¯­è¨€æ¨¡å‹æ¨ç†**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `æ¨ç†åŠ é€Ÿ` `è‡ªé€‚åº”è®¡ç®—` `è®°å¿†æœºåˆ¶` `è®¡ç®—é¢„ç®—`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æå‡å¤§è¯­è¨€æ¨¡å‹æ¨ç†æ•ˆæœçš„åŒæ—¶ï¼Œå¾€å¾€å¯¼è‡´æ¨ç†æ—¶é—´çš„å¢åŠ ï¼Œæ•ˆç‡ä½ä¸‹ã€‚
2. è®ºæ–‡æå‡ºSpeedupLLMæ¡†æ¶ï¼Œé€šè¿‡è‡ªé€‚åº”è®¡ç®—åˆ†é…å’Œè®°å¿†æœºåˆ¶ï¼Œç³»ç»Ÿæ€§åœ°åŠ é€ŸLLMsçš„æ¨ç†è¿‡ç¨‹ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨é€‚å½“çš„è®°å¿†å’Œæ¨ç†æ–¹æ³•ï¼ŒLLMsçš„æ¨ç†é€Ÿåº¦å¯æé«˜ï¼Œè®¡ç®—æˆæœ¬é™ä½56%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬è®ºæ–‡æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ¨ç†è¿‡ç¨‹ä¸­æ˜¯å¦èƒ½å¤Ÿé€šè¿‡é‡å¤æ¥è§¦ç›¸å…³ä»»åŠ¡æ¥åŠ å¿«æ¨ç†é€Ÿåº¦ã€‚ç ”ç©¶è¡¨æ˜ï¼Œå°½ç®¡å¢åŠ è®¡ç®—èµ„æºé€šå¸¸èƒ½æé«˜LLMsçš„æœ‰æ•ˆæ€§ï¼Œä½†ä¹Ÿä¼šå¯¼è‡´æ¨ç†æ—¶é—´å¢åŠ ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†SpeedupLLMæ¡†æ¶ï¼Œç³»ç»Ÿæ€§åœ°å®šä¹‰äº†æ¨ç†åŠ é€Ÿé—®é¢˜ï¼Œå¹¶é€šè¿‡è‡ªé€‚åº”è®¡ç®—åˆ†é…å’Œè®°å¿†æœºåˆ¶è¿›è¡Œå®ç°ä¸åŸºå‡†æµ‹è¯•ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œé€‚å½“çš„è®°å¿†å’Œæ¨ç†æ–¹æ³•å¯ä»¥ä½¿LLMsåœ¨è¿‡å»ç»éªŒçš„å¸®åŠ©ä¸‹ï¼Œæ¨ç†é€Ÿåº¦æé«˜ï¼Œè®¡ç®—æˆæœ¬é™ä½é«˜è¾¾56%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹æ¨ç†é€Ÿåº¦æå‡çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¢åŠ è®¡ç®—èµ„æºæ—¶ï¼Œæ¨ç†æ—¶é—´å´æœªèƒ½æœ‰æ•ˆé™ä½ï¼Œå¯¼è‡´æ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡é‡å¤æ¥è§¦ç›¸å…³ä»»åŠ¡æ¥åŠ é€Ÿæ¨ç†ï¼Œå€Ÿé‰´äººç±»é€šè¿‡ç»éªŒæå‡æ•ˆç‡çš„æ–¹å¼ï¼Œè®¾è®¡è‡ªé€‚åº”è®¡ç®—åˆ†é…å’Œè®°å¿†æœºåˆ¶ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSpeedupLLMæ¡†æ¶åŒ…æ‹¬ä»»åŠ¡ç›¸å…³æ€§åˆ†æã€è®¡ç®—é¢„ç®—è®¡ç®—ã€è®°å¿†æ–¹æ³•å’Œæ¨ç†æ–¹æ³•ç­‰æ¨¡å—ï¼Œç³»ç»Ÿæ€§åœ°å®ç°æ¨ç†é€Ÿåº¦çš„æå‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ä¸ªç†è®ºä¸Šæœ‰ä¿è¯çš„æ¡†æ¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°å®ç°æ¨ç†åŠ é€Ÿï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œå¼ºè°ƒäº†è®°å¿†æœºåˆ¶çš„é‡è¦æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œå…³é”®å‚æ•°åŒ…æ‹¬è®¡ç®—é¢„ç®—çš„åŠ¨æ€è°ƒæ•´ã€è®°å¿†æ–¹æ³•çš„é€‰æ‹©ï¼ˆå¦‚çŸ­æœŸè®°å¿†å’Œé•¿æœŸè®°å¿†ï¼‰ï¼Œä»¥åŠæ¨ç†æ–¹æ³•çš„ä¼˜åŒ–ï¼Œä»¥ç¡®ä¿åœ¨ä¸åŒä»»åŠ¡ç›¸ä¼¼æ€§æ°´å¹³ä¸‹çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨SpeedupLLMæ¡†æ¶åï¼ŒLLMsåœ¨æ¨ç†é€Ÿåº¦ä¸Šæœ‰æ˜¾è‘—æå‡ï¼Œè®¡ç®—æˆæœ¬é™ä½é«˜è¾¾56%ã€‚åœ¨ä¸åŒé—®é¢˜ç›¸ä¼¼æ€§æ°´å¹³å’Œè®°å¿†æ–¹æ³•çš„æµ‹è¯•ä¸­ï¼Œå‡è¡¨ç°å‡ºä¼˜è¶Šçš„æ€§èƒ½ï¼ŒéªŒè¯äº†æ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æ™ºèƒ½é—®ç­”ç³»ç»Ÿå’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡åŠ é€Ÿå¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ï¼Œå¯ä»¥æ˜¾è‘—æå‡è¿™äº›åº”ç”¨çš„å“åº”é€Ÿåº¦å’Œç”¨æˆ·ä½“éªŒï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„æœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Allocating more compute to large language models (LLMs) reasoning has generally been demonstrated to improve their effectiveness, but also results in increased inference time. In contrast, humans can perform tasks faster and better with increased experience and exposure. Hence, this paper aims to investigate the question: Can LLMs also become faster at reasoning through recurrent exposure on relevant tasks, and if so, how can it be achieved? To address these questions, we first formalize the problem setting of LLM reasoning speedup systematically in the dimensions of task relevancy and compute budget calculation. We then propose SpeedupLLM, a theoretically guaranteed framework to implement and benchmark such reasoning speedup behaviour based on adaptive compute allocation and memory mechanisms. We further conduct comprehensive experiments to benchmark such behaviour across different question similarity levels, memory methods, and reasoning methods. Results show that LLMs can generally reason faster with past experience, achieving up to a 56% reduction in compute cost when equipped with appropriate memory and reasoning methods.

