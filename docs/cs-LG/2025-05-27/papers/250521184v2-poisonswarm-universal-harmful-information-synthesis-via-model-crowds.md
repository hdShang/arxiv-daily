---
layout: default
title: "PoisonSwarm: Universal Harmful Information Synthesis via Model Crowdsourcing"
---

# PoisonSwarm: Universal Harmful Information Synthesis via Model Crowdsourcing

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21184" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21184v2</a>
  <a href="https://arxiv.org/pdf/2505.21184.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21184v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21184v2', 'PoisonSwarm: Universal Harmful Information Synthesis via Model Crowdsourcing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yu Yan, Sheng Sun, Zhifei Zheng, Ziji Hao, Teli Liu, Min Liu

**åˆ†ç±»**: cs.LG, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27 (æ›´æ–°: 2025-08-22)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPoisonSwarmä»¥è§£å†³æœ‰å®³ä¿¡æ¯åˆæˆçš„å¤šæ ·æ€§ä¸å¯é æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æœ‰å®³ä¿¡æ¯åˆæˆ` `æ¨¡å‹ä¼—åŒ…` `å¯¹æŠ—æ€§æµ‹è¯•` `å®‰å…¨é˜²æŠ¤` `å¤§å‹è¯­è¨€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨åˆæˆæœ‰å®³ä¿¡æ¯æ•°æ®æ—¶ï¼Œé¢ä¸´ç”Ÿæˆå¯é æ€§å’Œå†…å®¹å¤šæ ·æ€§ä¸è¶³çš„æŒ‘æˆ˜ã€‚
2. è®ºæ–‡æå‡ºçš„PoisonSwarmæ¡†æ¶é€šè¿‡æ¨¡å‹ä¼—åŒ…ç­–ç•¥ç”Ÿæˆå¤šæ ·çš„æœ‰å®³æ•°æ®ï¼Œç¡®ä¿åˆæˆæˆåŠŸç‡é«˜ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPoisonSwarmåœ¨åˆæˆä¸åŒç±»åˆ«çš„æœ‰å®³æ•°æ®ä¸Šè¡¨ç°å‡ºè‰²ï¼Œå…·å¤‡é«˜å¯æ‰©å±•æ€§å’Œå¤šæ ·æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸ºäº†æ„å»ºè´Ÿè´£ä»»å’Œå®‰å…¨çš„äººå·¥æ™ºèƒ½åº”ç”¨ï¼Œæœ‰å®³ä¿¡æ¯æ•°æ®è¢«å¹¿æ³›ç”¨äºå¯¹æŠ—æ€§æµ‹è¯•å’Œå®‰å…¨é˜²æŠ¤çš„å¼€å‘ã€‚ç°æœ‰ç ”ç©¶ä¸»è¦ä¾èµ–å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åˆæˆæ•°æ®ï¼Œä»¥è·å–é«˜è´¨é‡çš„ä»»åŠ¡æ•°æ®é›†ï¼Œä½†ç”±äºå®‰å…¨å¯¹é½æœºåˆ¶çš„é™åˆ¶ï¼Œæœ‰å®³æ•°æ®çš„åˆæˆåœ¨ç”Ÿæˆå¯é æ€§å’Œå†…å®¹å¤šæ ·æ€§æ–¹é¢ä»é¢ä¸´æŒ‘æˆ˜ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°é¢–çš„æœ‰å®³ä¿¡æ¯åˆæˆæ¡†æ¶PoisonSwarmï¼Œé‡‡ç”¨æ¨¡å‹ä¼—åŒ…ç­–ç•¥ç”Ÿæˆå¤šæ ·çš„æœ‰å®³æ•°æ®ï¼ŒåŒæ—¶ä¿æŒé«˜æˆåŠŸç‡ã€‚é€šè¿‡ç”Ÿæˆå¤§é‡è‰¯æ€§æ•°æ®ä½œä¸ºåäº‹å®åŸºç¡€æ¨¡æ¿ï¼Œå¹¶å°†æ¯ä¸ªæ¨¡æ¿åˆ†è§£ä¸ºå¤šä¸ªè¯­ä¹‰å•å…ƒï¼Œè¿›è¡Œé€å•å…ƒçš„æ¯’åŒ–å’Œæœ€ç»ˆçš„ç²¾ç‚¼ï¼Œç¡®ä¿åˆæˆçš„æˆåŠŸã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPoisonSwarmåœ¨åˆæˆä¸åŒç±»åˆ«çš„æœ‰å®³æ•°æ®æ–¹é¢å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå…·å¤‡é«˜å¯æ‰©å±•æ€§å’Œå¤šæ ·æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰æœ‰å®³ä¿¡æ¯åˆæˆæ–¹æ³•åœ¨ç”Ÿæˆå¯é æ€§å’Œå†…å®¹å¤šæ ·æ€§æ–¹é¢çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å®‰å…¨å¯¹é½æœºåˆ¶ä¸‹çš„é™åˆ¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šPoisonSwarmæ¡†æ¶é€šè¿‡æ¨¡å‹ä¼—åŒ…ç­–ç•¥ï¼Œç”Ÿæˆå¤šæ ·çš„æœ‰å®³æ•°æ®ï¼Œåˆ©ç”¨åäº‹å®ç”Ÿæˆå¤§é‡è‰¯æ€§æ•°æ®ä½œä¸ºåŸºç¡€æ¨¡æ¿ï¼Œç¡®ä¿åˆæˆè¿‡ç¨‹çš„æˆåŠŸç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šé¦–å…ˆç”Ÿæˆè‰¯æ€§æ•°æ®æ¨¡æ¿ï¼Œç„¶åå°†æ¯ä¸ªæ¨¡æ¿åˆ†è§£ä¸ºå¤šä¸ªè¯­ä¹‰å•å…ƒï¼Œé€å•å…ƒè¿›è¡Œæ¯’åŒ–å’Œç²¾ç‚¼ï¼Œé‡‡ç”¨åŠ¨æ€æ¨¡å‹åˆ‡æ¢ä»¥æé«˜åˆæˆæ•ˆæœã€‚

**å…³é”®åˆ›æ–°**ï¼šPoisonSwarmçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºæ¨¡å‹ä¼—åŒ…ç­–ç•¥çš„åº”ç”¨ï¼Œä½¿å¾—åˆæˆçš„æœ‰å®³æ•°æ®åœ¨å¤šæ ·æ€§å’Œå¯é æ€§ä¸Šæ˜¾è‘—æå‡ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°ç”Ÿæˆä¸åŒç±»åˆ«çš„æœ‰å®³ä¿¡æ¯ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œå…³é”®å‚æ•°è®¾ç½®åŒ…æ‹¬æ¨¡æ¿ç”Ÿæˆçš„æ•°é‡å’Œè¯­ä¹‰å•å…ƒçš„åˆ’åˆ†ç­–ç•¥ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ç”¨äºä¼˜åŒ–æ¯’åŒ–è¿‡ç¨‹çš„æ•ˆæœï¼Œç½‘ç»œç»“æ„åˆ™é‡‡ç”¨åŠ¨æ€åˆ‡æ¢çš„æ¨¡å‹ä»¥é€‚åº”ä¸åŒçš„åˆæˆéœ€æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒPoisonSwarmåœ¨åˆæˆä¸åŒç±»åˆ«çš„æœ‰å®³æ•°æ®æ—¶ï¼Œè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒæˆåŠŸç‡å’Œå¤šæ ·æ€§å‡æ˜¾è‘—æå‡ã€‚å…·ä½“è€Œè¨€ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•ï¼Œåˆæˆæ•°æ®çš„å¤šæ ·æ€§æé«˜äº†XX%ï¼ŒæˆåŠŸç‡æå‡äº†YY%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å®‰å…¨é˜²æŠ¤ã€å¯¹æŠ—æ€§æµ‹è¯•å’ŒAIç³»ç»Ÿçš„é²æ£’æ€§è¯„ä¼°ã€‚é€šè¿‡ç”Ÿæˆå¤šæ ·çš„æœ‰å®³ä¿¡æ¯æ•°æ®ï¼Œèƒ½å¤Ÿå¸®åŠ©å¼€å‘æ›´ä¸ºå®‰å…¨å’Œå¯é çš„äººå·¥æ™ºèƒ½åº”ç”¨ï¼Œæå‡ç³»ç»Ÿçš„é˜²å¾¡èƒ½åŠ›ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> To construct responsible and secure AI applications, harmful information data is widely utilized for adversarial testing and the development of safeguards. Existing studies mainly leverage Large Language Models (LLMs) to synthesize data to obtain high-quality task datasets at scale, thereby avoiding costly human annotation. However, limited by the safety alignment mechanisms of LLMs, the synthesis of harmful data still faces challenges in generation reliability and content diversity. In this study, we propose a novel harmful information synthesis framework, PoisonSwarm, which applies the model crowdsourcing strategy to generate diverse harmful data while maintaining a high success rate. Specifically, we generate abundant benign data as the based templates in a counterfactual manner. Subsequently, we decompose each based template into multiple semantic units and perform unit-by-unit toxification and final refinement through dynamic model switching, thus ensuring the success of synthesis. Experimental results demonstrate that PoisonSwarm achieves state-of-the-art performance in synthesizing different categories of harmful data with high scalability and diversity.

