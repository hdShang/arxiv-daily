---
layout: default
title: "AdvJudge-Zero: Binary Decision Flips in LLM-as-a-Judge via Adversarial Control Tokens"
---

# AdvJudge-Zero: Binary Decision Flips in LLM-as-a-Judge via Adversarial Control Tokens

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.17375" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.17375v1</a>
  <a href="https://arxiv.org/pdf/2512.17375.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.17375v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.17375v1', 'AdvJudge-Zero: Binary Decision Flips in LLM-as-a-Judge via Adversarial Control Tokens')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Tung-Ling Li, Yuhao Wu, Hongliang Liu

**åˆ†ç±»**: cs.LG, cs.CL, cs.CR

**å‘å¸ƒæ—¥æœŸ**: 2025-12-19

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**AdvJudge-Zeroï¼šé€šè¿‡å¯¹æŠ—æ§åˆ¶ä»¤ç‰Œç¿»è½¬LLMè¯„åˆ¤å™¨çš„äºŒå…ƒå†³ç­–**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `LLMè¯„åˆ¤å™¨` `å¯¹æŠ—æ”»å‡»` `æ§åˆ¶ä»¤ç‰Œ` `å¥–åŠ±é»‘å®¢` `å¯¹æŠ—è®­ç»ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¥–åŠ±æ¨¡å‹å’ŒLLMè¯„åˆ¤ç³»ç»Ÿæ˜“å—æ”»å‡»ï¼Œå¯èƒ½è¢«ç²¾å¿ƒè®¾è®¡çš„æ§åˆ¶ä»¤ç‰Œåºåˆ—æ¬ºéª—ï¼Œå¯¼è‡´é”™è¯¯çš„äºŒå…ƒå†³ç­–ã€‚
2. AdvJudge-Zeroæ–¹æ³•é€šè¿‡æ¢ç´¢æ¨¡å‹çš„ä¸‹ä¸€ä¸ªä»¤ç‰Œåˆ†å¸ƒï¼Œè‡ªåŠ¨å‘ç°èƒ½å¤Ÿç¿»è½¬è¯„åˆ¤ç»“æœçš„æ§åˆ¶ä»¤ç‰Œåºåˆ—ã€‚
3. å®éªŒè¡¨æ˜ï¼Œå¯¹æŠ—è®­ç»ƒå¯ä»¥æœ‰æ•ˆé™ä½æ§åˆ¶ä»¤ç‰Œå¯¼è‡´çš„å‡é˜³æ€§ç‡ï¼ŒåŒæ—¶ä¿æŒè¯„åˆ¤è´¨é‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¥–åŠ±æ¨¡å‹å’ŒLLMè¯„åˆ¤ç³»ç»Ÿæ˜¯ç°ä»£åè®­ç»ƒæµç¨‹ï¼ˆå¦‚RLHFã€DPOå’ŒRLAIFï¼‰çš„æ ¸å¿ƒï¼Œå®ƒä»¬æä¾›æ ‡é‡åé¦ˆå’ŒäºŒå…ƒå†³ç­–ï¼ŒæŒ‡å¯¼æ¨¡å‹é€‰æ‹©å’ŒåŸºäºå¼ºåŒ–å­¦ä¹ çš„å¾®è°ƒã€‚æœ¬æ–‡æ­ç¤ºäº†è¿™äº›è¯„åˆ¤ç³»ç»Ÿå­˜åœ¨ä¸€ç§åå¤å‡ºç°çš„æ¼æ´ï¼šçŸ­åºåˆ—çš„ä½å›°æƒ‘åº¦æ§åˆ¶ä»¤ç‰Œå¯ä»¥é€šè¿‡æ“çºµæœ€åä¸€å±‚logité—´éš™ï¼Œå°†è®¸å¤šäºŒå…ƒè¯„ä¼°ä»æ­£ç¡®çš„â€œå¦â€åˆ¤æ–­ç¿»è½¬ä¸ºä¸æ­£ç¡®çš„â€œæ˜¯â€åˆ¤æ–­ã€‚è¿™äº›æ§åˆ¶ä»¤ç‰Œæ˜¯ç­–ç•¥æ¨¡å‹åœ¨åè®­ç»ƒæœŸé—´å¯èƒ½ç”Ÿæˆçš„æ¨¡å¼ï¼Œå› æ­¤ä»£è¡¨äº†å®é™…çš„å¥–åŠ±é»‘å®¢é£é™©ï¼Œè€Œä¸æ˜¯æœ€åæƒ…å†µä¸‹çš„å¯¹æŠ—æ€§å­—ç¬¦ä¸²ã€‚æœ¬æ–‡æå‡ºçš„AdvJudge-Zeroæ–¹æ³•åˆ©ç”¨æ¨¡å‹çš„ä¸‹ä¸€ä¸ªä»¤ç‰Œåˆ†å¸ƒå’ŒæŸæœç´¢æ¢ç´¢ï¼Œä»å¤´å¼€å§‹å‘ç°å„ç§æ§åˆ¶ä»¤ç‰Œåºåˆ—ã€‚åˆ†æè¡¨æ˜ï¼Œè¯±å¯¼çš„éšè—çŠ¶æ€æ‰°åŠ¨é›†ä¸­åœ¨ä¸€ä¸ªä½ç§©â€œè½¯æ¨¡å¼â€ä¸­ï¼Œè¯¥æ¨¡å¼ä¸è¯„åˆ¤å™¨çš„æ‹’ç»æ–¹å‘åå‘å¯¹é½ã€‚å®éªŒè¡¨æ˜ï¼Œå½“å¤§å‹å¼€æ”¾æƒé‡å’Œä¸“ç”¨è¯„åˆ¤æ¨¡å‹å¯¹æ•°å­¦å’Œæ¨ç†åŸºå‡†ä¸Šçš„ä¸æ­£ç¡®ç­”æ¡ˆè¿›è¡Œè¯„åˆ†æ—¶ï¼Œè¿™äº›ä»¤ç‰Œä¼šå¯¼è‡´éå¸¸é«˜çš„å‡é˜³æ€§ç‡ã€‚æœ€åï¼Œæœ¬æ–‡è¡¨æ˜ï¼Œåœ¨å°‘é‡æ§åˆ¶ä»¤ç‰Œå¢å¼ºç¤ºä¾‹ä¸Šè¿›è¡ŒåŸºäºLoRAçš„å¯¹æŠ—è®­ç»ƒå¯ä»¥æ˜¾è‘—é™ä½è¿™äº›å‡é˜³æ€§ç‡ï¼ŒåŒæ—¶ä¿æŒè¯„ä¼°è´¨é‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„åŸºäºLLMçš„è¯„åˆ¤ç³»ç»Ÿåœ¨RLHFç­‰æµç¨‹ä¸­æ‰®æ¼”é‡è¦è§’è‰²ï¼Œä½†å®¹æ˜“å—åˆ°å¯¹æŠ—æ”»å‡»ã€‚å…·ä½“æ¥è¯´ï¼ŒçŸ­åºåˆ—çš„æ§åˆ¶ä»¤ç‰Œå¯ä»¥æ”¹å˜LLMè¯„åˆ¤å™¨çš„å†³ç­–ï¼Œå°†é”™è¯¯çš„ç­”æ¡ˆåˆ¤æ–­ä¸ºæ­£ç¡®ã€‚è¿™ç§æ”»å‡»çš„å¨èƒåœ¨äºï¼Œè¿™äº›æ§åˆ¶ä»¤ç‰Œå¹¶éå®Œå…¨éšæœºçš„å¯¹æŠ—æ ·æœ¬ï¼Œè€Œæ˜¯æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯èƒ½ç”Ÿæˆçš„ï¼Œå› æ­¤æ›´å…·å®é™…æ„ä¹‰ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ¨¡å‹çš„è‡ªèº«ç‰¹æ€§ï¼ˆä¸‹ä¸€ä¸ªtokençš„æ¦‚ç‡åˆ†å¸ƒï¼‰æ¥å¯»æ‰¾èƒ½å¤Ÿå½±å“è¯„åˆ¤ç»“æœçš„æ§åˆ¶ä»¤ç‰Œåºåˆ—ã€‚é€šè¿‡ä¼˜åŒ–è¿™äº›æ§åˆ¶ä»¤ç‰Œï¼Œä½¿å¾—å®ƒä»¬èƒ½å¤Ÿæœ€å¤§ç¨‹åº¦åœ°æ”¹å˜LLMè¯„åˆ¤å™¨çš„è¾“å‡ºlogitï¼Œä»è€Œç¿»è½¬å…¶äºŒå…ƒå†³ç­–ã€‚è¿™ç§æ–¹æ³•ä¸éœ€è¦å¤–éƒ¨çš„å¯¹æŠ—æ ·æœ¬ç”Ÿæˆå™¨ï¼Œè€Œæ˜¯ç›´æ¥åˆ©ç”¨æ¨¡å‹æœ¬èº«çš„ä¿¡æ¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAdvJudge-Zeroæ–¹æ³•ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š
1. **æ§åˆ¶ä»¤ç‰Œæœç´¢**ï¼šä½¿ç”¨æ¨¡å‹çš„ä¸‹ä¸€ä¸ªtokenåˆ†å¸ƒå’ŒæŸæœç´¢ç®—æ³•ï¼Œä»å¤´å¼€å§‹ç”Ÿæˆæ§åˆ¶ä»¤ç‰Œåºåˆ—ã€‚
2. **éšè—çŠ¶æ€åˆ†æ**ï¼šåˆ†ææ§åˆ¶ä»¤ç‰Œå¼•èµ·çš„éšè—çŠ¶æ€æ‰°åŠ¨ï¼Œå‘ç°å…¶é›†ä¸­åœ¨ä¸€ä¸ªä½ç§©â€œè½¯æ¨¡å¼â€ä¸­ã€‚
3. **å¯¹æŠ—è®­ç»ƒ**ï¼šä½¿ç”¨ç”Ÿæˆçš„æ§åˆ¶ä»¤ç‰Œå¢å¼ºè®­ç»ƒæ•°æ®ï¼Œé€šè¿‡LoRAè¿›è¡Œå¯¹æŠ—è®­ç»ƒï¼Œæé«˜æ¨¡å‹çš„é²æ£’æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§å®Œå…¨åŸºäºæ¨¡å‹è‡ªèº«ä¿¡æ¯çš„å¯¹æŠ—æ ·æœ¬ç”Ÿæˆæ–¹æ³•ã€‚ä¸ä¼ ç»Ÿçš„å¯¹æŠ—æ”»å‡»æ–¹æ³•ä¸åŒï¼ŒAdvJudge-Zeroä¸éœ€è¦å¤–éƒ¨çš„å¯¹æŠ—æ ·æœ¬ç”Ÿæˆå™¨ï¼Œè€Œæ˜¯ç›´æ¥åˆ©ç”¨æ¨¡å‹çš„ä¸‹ä¸€ä¸ªtokenåˆ†å¸ƒæ¥å¯»æ‰¾æ§åˆ¶ä»¤ç‰Œã€‚è¿™ç§æ–¹æ³•ç”Ÿæˆçš„æ§åˆ¶ä»¤ç‰Œæ›´å…·å®é™…æ„ä¹‰ï¼Œå› ä¸ºå®ƒä»¬æ˜¯æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯èƒ½ç”Ÿæˆçš„ã€‚

**å…³é”®è®¾è®¡**ï¼š
1. **æ§åˆ¶ä»¤ç‰Œæœç´¢**ï¼šä½¿ç”¨æŸæœç´¢ç®—æ³•ï¼Œä»¥æœ€å¤§åŒ–logitå·®è·ä¸ºç›®æ ‡ï¼Œå¯»æ‰¾æœ€ä¼˜çš„æ§åˆ¶ä»¤ç‰Œåºåˆ—ã€‚
2. **éšè—çŠ¶æ€åˆ†æ**ï¼šä½¿ç”¨å¥‡å¼‚å€¼åˆ†è§£ï¼ˆSVDï¼‰åˆ†æéšè—çŠ¶æ€æ‰°åŠ¨ï¼Œå‘ç°å…¶é›†ä¸­åœ¨ä¸€ä¸ªä½ç§©â€œè½¯æ¨¡å¼â€ä¸­ã€‚
3. **å¯¹æŠ—è®­ç»ƒ**ï¼šä½¿ç”¨LoRAè¿›è¡Œå¯¹æŠ—è®­ç»ƒï¼Œä»¥å‡å°‘è®¡ç®—æˆæœ¬ï¼Œå¹¶é˜²æ­¢æ¨¡å‹è¿‡æ‹Ÿåˆã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒAdvJudge-Zeroæ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°å‘ç°æ§åˆ¶ä»¤ç‰Œåºåˆ—ï¼Œè¿™äº›åºåˆ—å¯ä»¥æ˜¾è‘—æé«˜LLMè¯„åˆ¤å™¨çš„å‡é˜³æ€§ç‡ã€‚åœ¨æ•°å­¦å’Œæ¨ç†åŸºå‡†æµ‹è¯•ä¸­ï¼Œä½¿ç”¨è¿™äº›æ§åˆ¶ä»¤ç‰Œå¯ä»¥ä½¿å¤§å‹å¼€æ”¾æƒé‡å’Œä¸“ç”¨è¯„åˆ¤æ¨¡å‹å°†é”™è¯¯ç­”æ¡ˆåˆ¤æ–­ä¸ºæ­£ç¡®çš„æ¦‚ç‡å¤§å¹…æå‡ã€‚é€šè¿‡åœ¨å°‘é‡æ§åˆ¶ä»¤ç‰Œå¢å¼ºç¤ºä¾‹ä¸Šè¿›è¡ŒåŸºäºLoRAçš„å¯¹æŠ—è®­ç»ƒï¼Œå¯ä»¥æ˜¾è‘—é™ä½è¿™äº›å‡é˜³æ€§ç‡ï¼ŒåŒæ—¶ä¿æŒè¯„ä¼°è´¨é‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæå‡LLMè¯„åˆ¤ç³»ç»Ÿçš„å®‰å…¨æ€§ä¸é²æ£’æ€§ï¼Œé™ä½å…¶åœ¨RLHFç­‰åè®­ç»ƒæµç¨‹ä¸­è¢«æ¶æ„åˆ©ç”¨çš„é£é™©ã€‚é€šè¿‡å¯¹æŠ—è®­ç»ƒï¼Œå¯ä»¥æé«˜è¯„åˆ¤ç³»ç»Ÿå¯¹æ½œåœ¨å¯¹æŠ—æ ·æœ¬çš„æŠµæŠ—èƒ½åŠ›ï¼Œä»è€Œä¿è¯æ¨¡å‹è®­ç»ƒçš„ç¨³å®šæ€§å’Œå¯é æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•ä¹Ÿå¯ç”¨äºè¯„ä¼°å’Œæ”¹è¿›å…¶ä»–åŸºäºLLMçš„ç³»ç»Ÿã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Reward models and LLM-as-a-Judge systems are central to modern post-training pipelines such as RLHF, DPO, and RLAIF, where they provide scalar feedback and binary decisions that guide model selection and RL-based fine-tuning. We show that these judge systems exhibit a recurring vulnerability: short sequences of low-perplexity control tokens can flip many binary evaluations from correct ``No'' judgments to incorrect ``Yes'' judgments by steering the last-layer logit gap. These control tokens are patterns that a policy model could plausibly generate during post-training, and thus represent realistic reward-hacking risks rather than worst-case adversarial strings. Our method, AdvJudge-Zero, uses the model's next-token distribution and beam-search exploration to discover diverse control-token sequences from scratch, and our analysis shows that the induced hidden-state perturbations concentrate in a low-rank ``soft mode'' that is anti-aligned with the judge's refusal direction. Empirically, these tokens cause very high false positive rates when large open-weight and specialized judge models score incorrect answers on math and reasoning benchmarks. Finally, we show that LoRA-based adversarial training on small sets of control-token-augmented examples can markedly reduce these false positives while preserving evaluation quality.

