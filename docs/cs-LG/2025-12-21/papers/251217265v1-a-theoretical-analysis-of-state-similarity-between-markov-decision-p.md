---
layout: default
title: A Theoretical Analysis of State Similarity Between Markov Decision Processes
---

# A Theoretical Analysis of State Similarity Between Markov Decision Processes

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.17265" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.17265v1</a>
  <a href="https://arxiv.org/pdf/2512.17265.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.17265v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.17265v1', 'A Theoretical Analysis of State Similarity Between Markov Decision Processes')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhenyu Tao, Wei Xu, Xiaohu You

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-12-19

**å¤‡æ³¨**: Submitted to an IEEE Transactions. arXiv admin note: substantial text overlap with arXiv:2509.18714

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¹¿ä¹‰åŒæ¨¡æ‹Ÿåº¦é‡GBSMï¼Œç”¨äºè¯„ä¼°é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹é—´çš„çŠ¶æ€ç›¸ä¼¼æ€§ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹` `åŒæ¨¡æ‹Ÿåº¦é‡` `çŠ¶æ€ç›¸ä¼¼æ€§` `ç­–ç•¥è¿ç§»` `çŠ¶æ€èšåˆ` `å¹¿ä¹‰åŒæ¨¡æ‹Ÿåº¦é‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŒæ¨¡æ‹Ÿåº¦é‡(BSM)åœ¨è·¨å¤šä¸ªMDPè¡¡é‡çŠ¶æ€ç›¸ä¼¼æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œç¼ºä¹å®Œå–„çš„æ•°å­¦æ€§è´¨ï¼Œé™åˆ¶äº†ç†è®ºåˆ†æã€‚
2. è®ºæ–‡æå‡ºå¹¿ä¹‰åŒæ¨¡æ‹Ÿåº¦é‡(GBSM)ï¼Œé€šè¿‡ä¸¥æ ¼è¯æ˜å…¶å¯¹ç§°æ€§ã€ä¸‰è§’ä¸ç­‰å¼ç­‰æ€§è´¨ï¼Œå®ç°å¯¹MDPé—´çŠ¶æ€ç›¸ä¼¼æ€§çš„æœ‰æ•ˆåº¦é‡ã€‚
3. å®éªŒç»“æœéªŒè¯äº†GBSMçš„æœ‰æ•ˆæ€§ï¼Œå¹¶åœ¨ç­–ç•¥è¿ç§»ã€çŠ¶æ€èšåˆå’Œé‡‡æ ·ä¼°è®¡ç­‰æ–¹é¢è·å¾—äº†æ¯”ç°æœ‰æ–¹æ³•æ›´ä¼˜çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŒæ¨¡æ‹Ÿåº¦é‡(BSM)æ˜¯åˆ†æé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹(MDP)ä¸­çŠ¶æ€ç›¸ä¼¼æ€§çš„å¼ºå¤§å·¥å…·ï¼Œå®ƒæ­ç¤ºäº†BSMä¸­è·ç¦»æ›´è¿‘çš„çŠ¶æ€å…·æœ‰æ›´ç›¸ä¼¼çš„æœ€ä¼˜ä»·å€¼å‡½æ•°ã€‚è™½ç„¶BSMå·²æˆåŠŸåº”ç”¨äºå¼ºåŒ–å­¦ä¹ (RL)ä¸­çš„çŠ¶æ€è¡¨ç¤ºå­¦ä¹ å’Œç­–ç•¥æ¢ç´¢ç­‰ä»»åŠ¡ï¼Œä½†å°†å…¶åº”ç”¨äºå¤šä¸ªMDPä¹‹é—´çš„çŠ¶æ€ç›¸ä¼¼æ€§ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚å…ˆå‰çš„å·¥ä½œè¯•å›¾å°†BSMæ‰©å±•åˆ°MDPå¯¹ï¼Œä½†ç”±äºç¼ºä¹å®Œå–„çš„æ•°å­¦æ€§è´¨ï¼Œé™åˆ¶äº†MDPä¹‹é—´è¿›ä¸€æ­¥çš„ç†è®ºåˆ†æã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æ­£å¼å»ºç«‹äº†å¹¿ä¹‰åŒæ¨¡æ‹Ÿåº¦é‡(GBSM)ï¼Œç”¨äºè¡¡é‡ä»»æ„MDPå¯¹ä¹‹é—´çš„çŠ¶æ€ç›¸ä¼¼æ€§ï¼Œå¹¶é€šè¿‡ä¸‰ä¸ªåŸºæœ¬åº¦é‡å±æ€§ï¼ˆå³GBSMå¯¹ç§°æ€§ã€MDPé—´ä¸‰è§’ä¸ç­‰å¼å’Œç›¸åŒç©ºé—´ä¸Šçš„è·ç¦»ç•Œé™ï¼‰å¯¹å…¶è¿›è¡Œäº†ä¸¥æ ¼è¯æ˜ã€‚åˆ©ç”¨è¿™äº›å±æ€§ï¼Œæˆ‘ä»¬ä»ç†è®ºä¸Šåˆ†æäº†è·¨MDPçš„ç­–ç•¥è¿ç§»ã€çŠ¶æ€èšåˆå’ŒåŸºäºé‡‡æ ·çš„ä¼°è®¡ï¼Œè·å¾—äº†æ¯”ç°æœ‰æ ‡å‡†BSMæ¨å¯¼çš„æ›´ä¸¥æ ¼çš„æ˜¾å¼ç•Œé™ã€‚æ­¤å¤–ï¼ŒGBSMä¸ºä¼°è®¡æä¾›äº†é—­å¼æ ·æœ¬å¤æ‚åº¦ï¼Œæ”¹è¿›äº†åŸºäºBSMçš„ç°æœ‰æ¸è¿‘ç»“æœã€‚æ•°å€¼ç»“æœéªŒè¯äº†æˆ‘ä»¬çš„ç†è®ºå‘ç°ï¼Œå¹¶è¯æ˜äº†GBSMåœ¨å¤šMDPåœºæ™¯ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¦‚ä½•æœ‰æ•ˆè¡¡é‡ä¸åŒé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹(MDP)ä¹‹é—´çš„çŠ¶æ€ç›¸ä¼¼æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åŸºäºåŒæ¨¡æ‹Ÿåº¦é‡(BSM)çš„æ‰©å±•ï¼Œç¼ºä¹ä¸¥æ ¼çš„æ•°å­¦æ€§è´¨ï¼Œå¯¼è‡´æ— æ³•è¿›è¡Œæœ‰æ•ˆçš„ç†è®ºåˆ†æï¼Œé™åˆ¶äº†å…¶åœ¨è·¨MDPçš„ç­–ç•¥è¿ç§»ã€çŠ¶æ€èšåˆç­‰æ–¹é¢çš„åº”ç”¨ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸åªèƒ½æä¾›æ¸è¿‘ç»“æœï¼Œç¼ºä¹é—­å¼è§£å’Œä¸¥æ ¼çš„æ€§èƒ½ç•Œé™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æå‡ºä¸€ç§æ–°çš„åº¦é‡æ–¹å¼ï¼Œå³å¹¿ä¹‰åŒæ¨¡æ‹Ÿåº¦é‡(GBSM)ï¼Œè¯¥åº¦é‡ä¸ä»…èƒ½å¤Ÿè¡¡é‡å•ä¸ªMDPå†…çš„çŠ¶æ€ç›¸ä¼¼æ€§ï¼Œè¿˜èƒ½è¡¡é‡ä¸åŒMDPä¹‹é—´çš„çŠ¶æ€ç›¸ä¼¼æ€§ã€‚GBSMçš„è®¾è®¡ç›®æ ‡æ˜¯æ»¡è¶³åº¦é‡çš„åŸºæœ¬æ€§è´¨ï¼Œå¦‚å¯¹ç§°æ€§ã€ä¸‰è§’ä¸ç­‰å¼ç­‰ï¼Œä»è€Œä¸ºåç»­çš„ç†è®ºåˆ†ææä¾›åšå®çš„åŸºç¡€ã€‚é€šè¿‡GBSMï¼Œå¯ä»¥æ›´å¥½åœ°ç†è§£ä¸åŒMDPä¹‹é—´çš„å…³ç³»ï¼Œå¹¶æŒ‡å¯¼ç­–ç•¥è¿ç§»ç­‰ä»»åŠ¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼š1) å½¢å¼åŒ–å®šä¹‰å¹¿ä¹‰åŒæ¨¡æ‹Ÿåº¦é‡(GBSM)ï¼›2) ä¸¥æ ¼è¯æ˜GBSMæ»¡è¶³åº¦é‡çš„åŸºæœ¬æ€§è´¨ï¼ŒåŒ…æ‹¬å¯¹ç§°æ€§ã€MDPé—´ä¸‰è§’ä¸ç­‰å¼å’Œç›¸åŒç©ºé—´ä¸Šçš„è·ç¦»ç•Œé™ï¼›3) åˆ©ç”¨GBSMçš„æ€§è´¨ï¼Œä»ç†è®ºä¸Šåˆ†æè·¨MDPçš„ç­–ç•¥è¿ç§»ã€çŠ¶æ€èšåˆå’ŒåŸºäºé‡‡æ ·çš„ä¼°è®¡ï¼›4) æ¨å¯¼å‡ºåŸºäºGBSMçš„é—­å¼æ ·æœ¬å¤æ‚åº¦ï¼Œå¹¶ä¸ç°æœ‰åŸºäºBSMçš„æ¸è¿‘ç»“æœè¿›è¡Œæ¯”è¾ƒï¼›5) é€šè¿‡æ•°å€¼å®éªŒéªŒè¯GBSMçš„æœ‰æ•ˆæ€§å’Œç†è®ºåˆ†æçš„æ­£ç¡®æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†å¹¿ä¹‰åŒæ¨¡æ‹Ÿåº¦é‡(GBSM)ï¼Œå¹¶ä¸¥æ ¼è¯æ˜äº†å…¶æ»¡è¶³åº¦é‡çš„åŸºæœ¬æ€§è´¨ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒGBSMèƒ½å¤Ÿæ›´å‡†ç¡®åœ°è¡¡é‡ä¸åŒMDPä¹‹é—´çš„çŠ¶æ€ç›¸ä¼¼æ€§ï¼Œå¹¶ä¸ºè·¨MDPçš„ç­–ç•¥è¿ç§»ç­‰ä»»åŠ¡æä¾›æ›´æœ‰æ•ˆçš„ç†è®ºæŒ‡å¯¼ã€‚æ­¤å¤–ï¼ŒGBSMè¿˜æä¾›äº†é—­å¼æ ·æœ¬å¤æ‚åº¦ï¼Œæ”¹è¿›äº†ç°æœ‰åŸºäºBSMçš„æ¸è¿‘ç»“æœã€‚

**å…³é”®è®¾è®¡**ï¼šGBSMçš„å…·ä½“å®šä¹‰æ¶‰åŠåˆ°å¯¹ä¸åŒMDPçš„çŠ¶æ€ç©ºé—´ã€åŠ¨ä½œç©ºé—´å’Œè½¬ç§»æ¦‚ç‡çš„æ¯”è¾ƒã€‚å…³é”®åœ¨äºå¦‚ä½•å®šä¹‰ä¸åŒMDPä¹‹é—´çš„â€œç›¸ä¼¼â€è½¬ç§»ï¼Œä»¥åŠå¦‚ä½•å°†è¿™ç§ç›¸ä¼¼æ€§è½¬åŒ–ä¸ºä¸€ä¸ªå¯åº¦é‡çš„è·ç¦»ã€‚è®ºæ–‡ä¸­å¯èƒ½æ¶‰åŠåˆ°å¯¹çŠ¶æ€ç©ºé—´å’ŒåŠ¨ä½œç©ºé—´è¿›è¡ŒåµŒå…¥æˆ–æ˜ å°„ï¼Œä»¥ä¾¿è¿›è¡Œæ¯”è¾ƒã€‚æ­¤å¤–ï¼ŒGBSMçš„è®¡ç®—å¯èƒ½æ¶‰åŠåˆ°è¿­ä»£ç®—æ³•ï¼Œéœ€è¦ä»”ç»†è®¾è®¡è¿­ä»£çš„åœæ­¢æ¡ä»¶å’Œæ”¶æ•›æ€§ä¿è¯ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡å¯èƒ½æ¶‰åŠåˆ°æœ€å°åŒ–ä¸åŒMDPä¹‹é—´çš„çŠ¶æ€ä»·å€¼å‡½æ•°çš„å·®å¼‚ï¼ŒåŒæ—¶è€ƒè™‘GBSMçš„åº¦é‡æ€§è´¨ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡é€šè¿‡æ•°å€¼å®éªŒéªŒè¯äº†GBSMçš„æœ‰æ•ˆæ€§ï¼Œå¹¶è¯æ˜äº†å…¶åœ¨ç­–ç•¥è¿ç§»ã€çŠ¶æ€èšåˆå’Œé‡‡æ ·ä¼°è®¡ç­‰æ–¹é¢ä¼˜äºç°æœ‰åŸºäºBSMçš„æ–¹æ³•ã€‚å…·ä½“è€Œè¨€ï¼ŒGBSMåœ¨ç­–ç•¥è¿ç§»ä»»åŠ¡ä¸­èƒ½å¤Ÿå®ç°æ›´é«˜çš„ç­–ç•¥æ€§èƒ½ï¼Œåœ¨çŠ¶æ€èšåˆä»»åŠ¡ä¸­èƒ½å¤Ÿè·å¾—æ›´ç´§å‡‘çš„çŠ¶æ€è¡¨ç¤ºï¼Œåœ¨é‡‡æ ·ä¼°è®¡ä»»åŠ¡ä¸­èƒ½å¤Ÿæä¾›æ›´å‡†ç¡®çš„ä»·å€¼å‡½æ•°ä¼°è®¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGBSMèƒ½å¤Ÿæœ‰æ•ˆåœ°è¡¡é‡ä¸åŒMDPä¹‹é—´çš„çŠ¶æ€ç›¸ä¼¼æ€§ï¼Œå¹¶ä¸ºè·¨MDPçš„å¼ºåŒ–å­¦ä¹ ä»»åŠ¡æä¾›æ›´æœ‰æ•ˆçš„ç†è®ºæŒ‡å¯¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ã€è¿ç§»å­¦ä¹ ã€å…ƒå­¦ä¹ ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨æœºå™¨äººæ§åˆ¶ä¸­ï¼Œå¯ä»¥å°†ä¸€ä¸ªæœºå™¨äººçš„ç­–ç•¥è¿ç§»åˆ°å¦ä¸€ä¸ªæœºå™¨äººä¸Šï¼Œä»è€Œå‡å°‘è®­ç»ƒæ—¶é—´å’Œæˆæœ¬ã€‚åœ¨æ¸¸æˆAIä¸­ï¼Œå¯ä»¥å°†ä¸€ä¸ªæ¸¸æˆçš„AIç­–ç•¥è¿ç§»åˆ°å¦ä¸€ä¸ªç±»ä¼¼çš„æ¸¸æˆä¸­ï¼Œæé«˜AIçš„é€šç”¨æ€§å’Œé€‚åº”æ€§ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å¯ä»¥ç”¨äºçŠ¶æ€æŠ½è±¡å’ŒçŠ¶æ€èšåˆï¼Œä»è€Œé™ä½å¼ºåŒ–å­¦ä¹ çš„è®¡ç®—å¤æ‚åº¦ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The bisimulation metric (BSM) is a powerful tool for analyzing state similarities within a Markov decision process (MDP), revealing that states closer in BSM have more similar optimal value functions. While BSM has been successfully utilized in reinforcement learning (RL) for tasks like state representation learning and policy exploration, its application to state similarity between multiple MDPs remains challenging. Prior work has attempted to extend BSM to pairs of MDPs, but a lack of well-established mathematical properties has limited further theoretical analysis between MDPs. In this work, we formally establish a generalized bisimulation metric (GBSM) for measuring state similarity between arbitrary pairs of MDPs, which is rigorously proven with three fundamental metric properties, i.e., GBSM symmetry, inter-MDP triangle inequality, and a distance bound on identical spaces. Leveraging these properties, we theoretically analyze policy transfer, state aggregation, and sampling-based estimation across MDPs, obtaining explicit bounds that are strictly tighter than existing ones derived from the standard BSM. Additionally, GBSM provides a closed-form sample complexity for estimation, improving upon existing asymptotic results based on BSM. Numerical results validate our theoretical findings and demonstrate the effectiveness of GBSM in multi-MDP scenarios.

