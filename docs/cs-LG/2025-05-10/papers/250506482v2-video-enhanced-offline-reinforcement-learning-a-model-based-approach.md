---
layout: default
title: Video-Enhanced Offline Reinforcement Learning: A Model-Based Approach
---

# Video-Enhanced Offline Reinforcement Learning: A Model-Based Approach

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.06482" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.06482v2</a>
  <a href="https://arxiv.org/pdf/2505.06482.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.06482v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.06482v2', 'Video-Enhanced Offline Reinforcement Learning: A Model-Based Approach')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Minting Pan, Yitao Zheng, Jiajian Li, Yunbo Wang, Xiaokang Yang

**åˆ†ç±»**: cs.LG, cs.AI, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-05-10 (æ›´æ–°: 2025-05-17)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè§†é¢‘å¢å¼ºç¦»çº¿å¼ºåŒ–å­¦ä¹ ä»¥è§£å†³ç¯å¢ƒäº¤äº’ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `ç¦»çº¿å¼ºåŒ–å­¦ä¹ ` `è§†é¢‘æ•°æ®` `æ¨¡å‹é©±åŠ¨` `ç­–ç•¥ä¼˜åŒ–` `æœºå™¨äººæ“ä½œ` `è‡ªåŠ¨é©¾é©¶` `å¼€æ”¾ä¸–ç•Œæ¸¸æˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç¦»çº¿å¼ºåŒ–å­¦ä¹ æ–¹æ³•ç”±äºç¼ºä¹ç¯å¢ƒäº¤äº’ï¼Œå¯¼è‡´æ¬¡ä¼˜è¡Œä¸ºå’Œä¸å‡†ç¡®çš„ä»·å€¼ä¼°è®¡ï¼Œé™åˆ¶äº†å…¶åº”ç”¨æ•ˆæœã€‚
2. æœ¬æ–‡æå‡ºçš„è§†é¢‘å¢å¼ºç¦»çº¿å¼ºåŒ–å­¦ä¹ ï¼ˆVeoRLï¼‰é€šè¿‡æ„å»ºåŸºäºè§†é¢‘æ•°æ®çš„äº¤äº’å¼ä¸–ç•Œæ¨¡å‹ï¼Œæå‡äº†ç­–ç•¥ä¼˜åŒ–çš„æ•ˆæœã€‚
3. VeoRLåœ¨å¤šä¸ªè§†è§‰æ§åˆ¶ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼ŒæŸäº›æƒ…å†µä¸‹æ€§èƒ½æå‡è¶…è¿‡100%ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç¦»çº¿å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰é€šè¿‡ä½¿ç”¨é™æ€æ•°æ®é›†è¿›è¡Œç­–ç•¥ä¼˜åŒ–ï¼Œé¿å…äº†å¹¿æ³›çš„ç°å®ä¸–ç•Œæ¢ç´¢å¸¦æ¥çš„é£é™©å’Œæˆæœ¬ã€‚ç„¶è€Œï¼Œç”±äºç¼ºä¹ç¯å¢ƒäº¤äº’ï¼Œç°æœ‰æ–¹æ³•é¢ä¸´æ¬¡ä¼˜ç¦»çº¿è¡Œä¸ºå’Œä¸å‡†ç¡®çš„ä»·å€¼ä¼°è®¡é—®é¢˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ¨¡å‹é©±åŠ¨çš„æ–¹æ³•â€”â€”è§†é¢‘å¢å¼ºç¦»çº¿å¼ºåŒ–å­¦ä¹ ï¼ˆVeoRLï¼‰ï¼Œè¯¥æ–¹æ³•ä»å¤šæ ·åŒ–çš„ã€æœªæ ‡è®°çš„è§†é¢‘æ•°æ®ä¸­æ„å»ºäº¤äº’å¼ä¸–ç•Œæ¨¡å‹ã€‚é€šè¿‡æ¨¡å‹é©±åŠ¨çš„è¡Œä¸ºæŒ‡å¯¼ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å°†è‡ªç„¶è§†é¢‘ä¸­çš„æ§åˆ¶ç­–ç•¥å’Œç‰©ç†åŠ¨æ€çš„å¸¸è¯†çŸ¥è¯†è½¬ç§»åˆ°ç›®æ ‡é¢†åŸŸçš„RLä»£ç†ä¸­ã€‚VeoRLåœ¨æœºå™¨äººæ“ä½œã€è‡ªåŠ¨é©¾é©¶å’Œå¼€æ”¾ä¸–ç•Œè§†é¢‘æ¸¸æˆç­‰è§†è§‰æ§åˆ¶ä»»åŠ¡ä¸­å®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼ˆåœ¨æŸäº›æƒ…å†µä¸‹è¶…è¿‡100%ï¼‰ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç¦»çº¿å¼ºåŒ–å­¦ä¹ ä¸­ç”±äºç¼ºä¹ç¯å¢ƒäº¤äº’è€Œå¯¼è‡´çš„æ¬¡ä¼˜è¡Œä¸ºå’Œä¸å‡†ç¡®çš„ä»·å€¼ä¼°è®¡é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨åˆ©ç”¨é™æ€æ•°æ®é›†æ—¶ï¼Œå¾€å¾€æ— æ³•æœ‰æ•ˆæ•æ‰ç¯å¢ƒåŠ¨æ€ï¼Œå½±å“å­¦ä¹ æ•ˆæœã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šVeoRLçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤šæ ·åŒ–çš„æœªæ ‡è®°è§†é¢‘æ•°æ®æ„å»ºäº¤äº’å¼ä¸–ç•Œæ¨¡å‹ï¼Œä»è€Œä¸ºRLä»£ç†æä¾›æ›´ä¸°å¯Œçš„ç¯å¢ƒä¿¡æ¯å’Œè¡Œä¸ºæŒ‡å¯¼ã€‚è¿™ç§æ–¹æ³•é€šè¿‡è½¬ç§»è‡ªç„¶è§†é¢‘ä¸­çš„å¸¸è¯†çŸ¥è¯†ï¼Œå¢å¼ºäº†ç­–ç•¥å­¦ä¹ çš„æ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVeoRLçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ¨¡å‹æ„å»ºå’Œç­–ç•¥ä¼˜åŒ–ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œä»ç½‘ç»œä¸Šæ”¶é›†å¤šæ ·åŒ–çš„è§†é¢‘æ•°æ®ï¼›å…¶æ¬¡ï¼Œåˆ©ç”¨è¿™äº›æ•°æ®æ„å»ºä¸€ä¸ªäº¤äº’å¼çš„ç¯å¢ƒæ¨¡å‹ï¼›æœ€åï¼Œé€šè¿‡è¯¥æ¨¡å‹è¿›è¡Œç­–ç•¥ä¼˜åŒ–å’Œè¡Œä¸ºæŒ‡å¯¼ã€‚

**å…³é”®åˆ›æ–°**ï¼šVeoRLçš„ä¸»è¦åˆ›æ–°åœ¨äºå°†è§†é¢‘æ•°æ®ä¸æ¨¡å‹é©±åŠ¨çš„å¼ºåŒ–å­¦ä¹ ç›¸ç»“åˆï¼Œå½¢æˆäº†ä¸€ç§æ–°çš„å­¦ä¹ æ¡†æ¶ã€‚è¿™ç§æ–¹æ³•ä¸ä¼ ç»Ÿçš„ç¦»çº¿RLæ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨ç¯å¢ƒä¿¡æ¯ï¼Œæå‡å­¦ä¹ æ•ˆæœã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼ŒVeoRLé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ¨¡å‹çš„å‡†ç¡®æ€§ï¼Œå¹¶è®¾è®¡äº†é€‚åº”æ€§å¼ºçš„ç½‘ç»œç»“æ„ï¼Œä»¥ä¾¿æ›´å¥½åœ°å¤„ç†è§†é¢‘æ•°æ®ä¸­çš„åŠ¨æ€ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

VeoRLåœ¨å¤šä¸ªè§†è§‰æ§åˆ¶ä»»åŠ¡ä¸­å±•ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼ŒæŸäº›æƒ…å†µä¸‹çš„æ€§èƒ½æå‡è¶…è¿‡100%ã€‚ä¸åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼ŒVeoRLæ˜¾è‘—æé«˜äº†ç­–ç•¥çš„æœ‰æ•ˆæ€§å’Œç¯å¢ƒé€‚åº”èƒ½åŠ›ï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å·¨å¤§æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæ“ä½œã€è‡ªåŠ¨é©¾é©¶å’Œå¼€æ”¾ä¸–ç•Œè§†é¢‘æ¸¸æˆç­‰ã€‚é€šè¿‡æå‡ç¦»çº¿å¼ºåŒ–å­¦ä¹ çš„æ•ˆæœï¼ŒVeoRLèƒ½å¤Ÿåœ¨è¿™äº›é¢†åŸŸä¸­å®ç°æ›´é«˜æ•ˆçš„ç­–ç•¥ä¼˜åŒ–ï¼Œé™ä½æ¢ç´¢æˆæœ¬ï¼Œæ¨åŠ¨æ™ºèƒ½ä½“åœ¨å¤æ‚ç¯å¢ƒä¸­çš„åº”ç”¨å’Œå‘å±•ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½ä¼šå¯¹è‡ªä¸»ç³»ç»Ÿçš„æ™ºèƒ½åŒ–æ°´å¹³äº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Offline reinforcement learning (RL) enables policy optimization using static datasets, avoiding the risks and costs of extensive real-world exploration. However, it struggles with suboptimal offline behaviors and inaccurate value estimation due to the lack of environmental interaction. We present Video-Enhanced Offline RL (VeoRL), a model-based method that constructs an interactive world model from diverse, unlabeled video data readily available online. Leveraging model-based behavior guidance, our approach transfers commonsense knowledge of control policy and physical dynamics from natural videos to the RL agent within the target domain. VeoRL achieves substantial performance gains (over 100% in some cases) across visual control tasks in robotic manipulation, autonomous driving, and open-world video games.

