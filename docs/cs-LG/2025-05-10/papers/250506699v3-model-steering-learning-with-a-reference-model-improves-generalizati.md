---
layout: default
title: "Model Steering: Learning with a Reference Model Improves Generalization Bounds and Scaling Laws"
---

# Model Steering: Learning with a Reference Model Improves Generalization Bounds and Scaling Laws

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.06699" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.06699v3</a>
  <a href="https://arxiv.org/pdf/2505.06699.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.06699v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.06699v3', 'Model Steering: Learning with a Reference Model Improves Generalization Bounds and Scaling Laws')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xiyuan Wei, Ming Lin, Fanjiang Ye, Fengguang Song, Liangliang Cao, My T. Thai, Tianbao Yang

**åˆ†ç±»**: cs.LG, cs.AI, cs.CV, stat.ML

**å‘å¸ƒæ—¥æœŸ**: 2025-05-10 (æ›´æ–°: 2025-05-17)

**å¤‡æ³¨**: 18 pages, 6 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ¨¡å‹å¼•å¯¼æ–¹æ³•ä»¥æå‡æ¨¡å‹æ³›åŒ–èƒ½åŠ›å’Œæ‰©å±•æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ¨¡å‹å¼•å¯¼` `æ³›åŒ–èƒ½åŠ›` `åˆ†å¸ƒé²æ£’ä¼˜åŒ–` `å¯¹æ¯”å­¦ä¹ ` `å¤§è§„æ¨¡æ¨¡å‹è®­ç»ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æ¨¡å‹è®­ç»ƒä¸­ç¼ºä¹ç†è®ºæŒ‡å¯¼ï¼Œå¯¼è‡´æ€§èƒ½ä¸ä½³ï¼Œå°¤å…¶æ˜¯åœ¨å¤§è§„æ¨¡æ¨¡å‹çš„è®­ç»ƒä¸­ã€‚
2. è®ºæ–‡æå‡ºçš„æ¨¡å‹å¼•å¯¼æ–¹æ³•é€šè¿‡ä½¿ç”¨å‚è€ƒæ¨¡å‹æ¥ä¼˜åŒ–ç›®æ ‡æ¨¡å‹çš„è®­ç»ƒï¼Œå¢å¼ºæ•°æ®é€‰æ‹©å’ŒåŠ æƒç­–ç•¥ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDRRho-CLIPåœ¨æ‰©å±•æ€§å’Œæ€§èƒ½ä¸Šä¼˜äºä¼ ç»Ÿçš„CLIPæ¨¡å‹ï¼ŒéªŒè¯äº†ç†è®ºåˆ†æçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æ­£å¼æå‡ºäº†ä¸€ç§æ–°å…´çš„å­¦ä¹ èŒƒå¼ï¼Œç§°ä¸ºæ¨¡å‹å¼•å¯¼ï¼ˆmodel steeringï¼‰ï¼Œé€šè¿‡ä½¿ç”¨å·²è®­ç»ƒæ¨¡å‹ä½œä¸ºå‚è€ƒï¼ŒæŒ‡å¯¼å’Œå¢å¼ºç›®æ ‡æ¨¡å‹çš„è®­ç»ƒã€‚å°½ç®¡åœ¨å¤§è§„æ¨¡åŸºç¡€æ¨¡å‹çš„è®­ç»ƒä¸­å·²é‡‡ç”¨ä¸€äº›ä¸´æ—¶æ–¹æ³•ï¼Œä½†å…¶åŸºæœ¬åŸç†å°šä¸å……åˆ†ç†è§£ï¼Œå¯¼è‡´æ€§èƒ½ä¸ä½³ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºç†è®ºçš„æ¨¡å‹å¼•å¯¼æ¡†æ¶ï¼Œç§°ä¸ºDRRhoé£é™©æœ€å°åŒ–ï¼Œæ ¹æ¤äºåˆ†å¸ƒé²æ£’ä¼˜åŒ–ï¼ˆDROï¼‰ã€‚é€šè¿‡æ³›åŒ–åˆ†æï¼Œæˆ‘ä»¬æä¾›äº†ç†è®ºè§è§£ï¼Œè§£é‡Šäº†ä¸ºä½•è¯¥æ–¹æ³•åœ¨æ³›åŒ–å’Œæ•°æ®æ•ˆç‡ä¸Šä¼˜äºæ²¡æœ‰å‚è€ƒæ¨¡å‹çš„è®­ç»ƒã€‚è¿™æ˜¯é¦–æ¬¡ä¸ºè¿™ä¸€æ–°å­¦ä¹ èŒƒå¼æä¾›ç†è®ºè§è§£ï¼Œæ˜¾è‘—æå‡äº†æˆ‘ä»¬å¯¹æ¨¡å‹å¼•å¯¼çš„ç†è§£å’Œå®è·µã€‚åŸºäºè¿™äº›è§è§£ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°çš„å¯¹æ¯”è¯­è¨€-å›¾åƒé¢„è®­ç»ƒæ–¹æ³•DRRho-CLIPï¼Œå®éªŒéªŒè¯äº†ç†è®ºè§è§£ï¼Œå¹¶æ˜¾ç¤ºå‡ºç›¸è¾ƒäºæ²¡æœ‰å‚è€ƒæ¨¡å‹çš„CLIPæ›´ä¼˜çš„æ‰©å±•æ€§å’Œæ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰æ¨¡å‹è®­ç»ƒæ–¹æ³•ç¼ºä¹ç†è®ºæ”¯æŒçš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨å¤§è§„æ¨¡æ¨¡å‹è®­ç»ƒä¸­ï¼Œå¯¼è‡´æ³›åŒ–èƒ½åŠ›ä¸è¶³å’Œæ•°æ®æ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„æ¨¡å‹å¼•å¯¼æ–¹æ³•é€šè¿‡å¼•å…¥å‚è€ƒæ¨¡å‹ï¼Œåˆ©ç”¨å…¶çŸ¥è¯†æ¥æŒ‡å¯¼ç›®æ ‡æ¨¡å‹çš„è®­ç»ƒï¼Œä»è€Œæ”¹å–„æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œæ•°æ®åˆ©ç”¨æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å‚è€ƒæ¨¡å‹çš„é€‰æ‹©ã€æ•°æ®é€‰æ‹©å’ŒåŠ æƒç­–ç•¥ï¼Œä»¥åŠåŸºäºDRRhoé£é™©æœ€å°åŒ–çš„è®­ç»ƒè¿‡ç¨‹ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬ç†è®ºåˆ†æã€æ¨¡å‹è®­ç»ƒå’Œå®éªŒéªŒè¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºé¦–æ¬¡ä¸ºæ¨¡å‹å¼•å¯¼æä¾›äº†ç†è®ºåŸºç¡€ï¼Œæ­ç¤ºäº†å…¶åœ¨æ³›åŒ–å’Œæ•°æ®æ•ˆç‡ä¸Šçš„ä¼˜åŠ¿ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†æ›´ç³»ç»Ÿçš„ç†è®ºæ”¯æŒã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬æŸå¤±å‡½æ•°çš„é€‰æ‹©ã€å‚è€ƒæ¨¡å‹çš„æ„å»ºå’Œå¯¹æ¯”å­¦ä¹ çš„ç»“åˆï¼Œç¡®ä¿æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­èƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨å‚è€ƒæ¨¡å‹çš„ä¿¡æ¯ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒDRRho-CLIPåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜äºä¼ ç»Ÿçš„CLIPæ¨¡å‹ï¼Œå°¤å…¶åœ¨æ‰©å±•æ€§æ–¹é¢ï¼Œå±•ç¤ºäº†æ›´ä¼˜çš„æ€§èƒ½æå‡ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°XX%ã€‚è¿™äº›ç»“æœéªŒè¯äº†ç†è®ºåˆ†æçš„æœ‰æ•ˆæ€§ï¼Œå¹¶æ˜¾ç¤ºå‡ºæ¨¡å‹å¼•å¯¼æ–¹æ³•çš„å¼ºå¤§æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤§è§„æ¨¡è‡ªç„¶è¯­è¨€å¤„ç†å’Œè®¡ç®—æœºè§†è§‰ä»»åŠ¡ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦é«˜æ•ˆæ•°æ®åˆ©ç”¨å’Œå¼ºæ³›åŒ–èƒ½åŠ›çš„åœºæ™¯ã€‚é€šè¿‡å¼•å…¥æ¨¡å‹å¼•å¯¼æ–¹æ³•ï¼Œå¯ä»¥æ˜¾è‘—æå‡æ¨¡å‹çš„è®­ç»ƒæ•ˆç‡å’Œæ€§èƒ½ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper formalizes an emerging learning paradigm that uses a trained model as a reference to guide and enhance the training of a target model through strategic data selection or weighting, named $\textbf{model steering}$. While ad-hoc methods have been used in various contexts, including the training of large foundation models, its underlying principles remain insufficiently understood, leading to sub-optimal performance. In this work, we propose a theory-driven framework for model steering called $\textbf{DRRho risk minimization}$, which is rooted in Distributionally Robust Optimization (DRO). Through a generalization analysis, we provide theoretical insights into why this approach improves generalization and data efficiency compared to training without a reference model. To the best of our knowledge, this is the first time such theoretical insights are provided for the new learning paradigm, which significantly enhance our understanding and practice of model steering. Building on these insights and the connection between contrastive learning and DRO, we introduce a novel method for Contrastive Language-Image Pretraining (CLIP) with a reference model, termed DRRho-CLIP. Extensive experiments validate the theoretical insights, reveal a superior scaling law compared to CLIP without a reference model, and demonstrate its strength over existing heuristic approaches.

