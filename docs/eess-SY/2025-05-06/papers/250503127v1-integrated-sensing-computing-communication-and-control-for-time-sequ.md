---
layout: default
title: Integrated Sensing, Computing, Communication, and Control for Time-Sequence-Based Semantic Communications
---

# Integrated Sensing, Computing, Communication, and Control for Time-Sequence-Based Semantic Communications

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.03127" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.03127v1</a>
  <a href="https://arxiv.org/pdf/2505.03127.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.03127v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.03127v1', 'Integrated Sensing, Computing, Communication, and Control for Time-Sequence-Based Semantic Communications')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Qingliang Li, Bo Chang, Weidong Mei, Zhi Chen

**ÂàÜÁ±ª**: eess.SY, cs.IT

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-06

**Â§áÊ≥®**: This version of the manuscript was submitted to IEEE Transactions on Communications for possible publication

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éÊó∂Èó¥Â∫èÂàóÁöÑËØ≠‰πâÈÄö‰ø°‰ª•Ëß£ÂÜ≥Â∑•‰∏öÁâ©ËÅîÁΩë‰∏≠ÁöÑÂÆûÊó∂ÊéßÂà∂ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Â∑•‰∏öÁâ©ËÅîÁΩë` `ÂÆûÊó∂ÊéßÂà∂` `ËØ≠‰πâÈÄö‰ø°` `Ê∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†` `‰ø°ÊÅØ‰º†Ëæì` `Ëá™ÈÄÇÂ∫îÊéßÂà∂` `ÈÄö‰ø°ÊïàÁéá`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊó†Á∫øÊéßÂà∂Á≥ªÁªüÂú®ÂÆûÊó∂ÊÄßÂíåÂèØÈù†ÊÄßÊñπÈù¢Èù¢‰∏¥ÊåëÊàòÔºåÂ∞§ÂÖ∂ÊòØÂú®Â∑•‰∏öÁâ©ËÅîÁΩëÁéØÂ¢É‰∏≠„ÄÇ
2. Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÈõÜÊàêÊÑüÁü•„ÄÅËÆ°ÁÆó„ÄÅÈÄö‰ø°ÂíåÊéßÂà∂ÁöÑÊû∂ÊûÑÔºåÈÄöËøáÊó∂Èó¥Â∫èÂàóÁöÑËØ≠‰πâÊé®Êñ≠ÂÆûÁé∞Ëá™ÈÄÇÂ∫îÊéßÂà∂„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåÊâÄÊèêÊñπÊ≥ïÂú®ÈÄö‰ø°ÂºÄÈîÄÂíåÊéßÂà∂Á≤æÂ∫¶‰∏äÂùáÊòæËëó‰ºò‰∫é‰º†ÁªüÊñπÊ°à„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Âú®Âç≥Â∞ÜÂà∞Êù•ÁöÑÂ∑•‰∏öÁâ©ËÅîÁΩëÔºàIIoTÔºâÊó∂‰ª£Ôºå‰ªªÂä°ÂØºÂêëÁöÑÂ∫îÁî®Â∞Ü‰æùËµñ‰∫éÂÆûÊó∂Êó†Á∫øÊéßÂà∂Á≥ªÁªüÔºàWCSsÔºâ„ÄÇ‰∏∫Á°Æ‰øùÊéßÂà∂‰ø°ÊÅØÁöÑÂèäÊó∂‰º†ËæìÔºåË∂ÖÂèØÈù†Âíå‰ΩéÂª∂ËøüÁöÑÊó†Á∫øÈÄö‰ø°Ëá≥ÂÖ≥ÈáçË¶Å„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÂü∫‰∫éÊó∂Èó¥Â∫èÂàóÁöÑËØ≠‰πâÈÄö‰ø°ËåÉÂºèÔºåÂºÄÂèë‰∫ÜÈõÜÊàêÊÑüÁü•„ÄÅËÆ°ÁÆó„ÄÅÈÄö‰ø°ÂíåÊéßÂà∂ÔºàISC3ÔºâÊû∂ÊûÑÔºå‰ª•ÂÆûÁé∞ÂØπÊéßÂà∂‰ø°ÊÅØÁöÑÂêàÁêÜËØ≠‰πâÊé®Êñ≠ÔºåËøõËÄåÂÆûÁé∞ÂØπÊú∫Âô®‰∫∫ÁöÑËá™ÈÄÇÂ∫îÊéßÂà∂„ÄÇÈÄöËøáËÆ°ÁÆóÂèëÂ∞ÑÁ´ØÔºàTxÔºâ‰∏çÂêåÊó∂Èó¥ÊÑüÁü•ÁöÑÊéßÂà∂‰ø°ÊÅØÁöÑ‰∫í‰ø°ÊÅØÔºåËØÜÂà´ÂÖ∂Êó∂Èó¥ËØ≠‰πâÁõ∏ÂÖ≥ÊÄßÔºå‰ªéËÄåÈÅøÂÖçÈ´òÂ∫¶Áõ∏ÂÖ≥ÁöÑ‰ø°ÊÅØ‰º†ËæìÔºåÊòæËëóÈôç‰ΩéÈÄö‰ø°ÂºÄÈîÄ„ÄÇÊé•Êî∂Á´ØÔºàRxÔºâÂàôÂà©Áî®ËØ≠‰πâÁâπÂæÅÈáçÊûÑÊ®°ÂùóÔºàSFRÔºâÈáçÊûÑÊéßÂà∂‰ø°ÊÅØÔºåÂπ∂Ê†πÊçÆ‰ø°ÊÅØ‰º†ËæìË¥®ÈáèËá™ÈÄÇÂ∫îË∞ÉÊï¥ÊéßÂà∂Â¢ûÁõä„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊâÄÊèêÊñπÊ≥ïÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÊòæËëó‰ºò‰∫éÂÖ∂‰ªñÂü∫Á∫øÊñπÊ°à„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Â∑•‰∏öÁâ©ËÅîÁΩë‰∏≠ÂÆûÊó∂Êó†Á∫øÊéßÂà∂Á≥ªÁªüÁöÑÈÄö‰ø°Âª∂ËøüÂíåÂèØÈù†ÊÄßÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®Â§ÑÁêÜÊó∂Èó¥Â∫èÂàóÊéßÂà∂‰ø°ÊÅØÊó∂Êú™ËÉΩÊúâÊïàÂà©Áî®ÂÖ∂ËØ≠‰πâÁõ∏ÂÖ≥ÊÄßÔºåÂØºËá¥ÈÄö‰ø°ÂºÄÈîÄËøáÂ§ß„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊèêÂá∫Âü∫‰∫éÊó∂Èó¥Â∫èÂàóÁöÑËØ≠‰πâÈÄö‰ø°ËåÉÂºèÔºåÈÄöËøáÈõÜÊàêÊÑüÁü•„ÄÅËÆ°ÁÆó„ÄÅÈÄö‰ø°ÂíåÊéßÂà∂ÔºàISC3ÔºâÊû∂ÊûÑÔºåÂà©Áî®Êó∂Èó¥Â∫èÂàóÁöÑËØ≠‰πâÁâπÂæÅËøõË°åÊéßÂà∂‰ø°ÊÅØÁöÑÊé®Êñ≠ÂíåÈáçÊûÑÔºå‰ªéËÄåÊèêÈ´òÈÄö‰ø°ÊïàÁéáÂíåÊéßÂà∂Á≤æÂ∫¶„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨ÂèëÂ∞ÑÁ´ØÔºàTxÔºâÂíåÊé•Êî∂Á´ØÔºàRxÔºâ„ÄÇTxÈÄöËøáËØ≠‰πâÁâπÂæÅÊèêÂèñÊ®°ÂùóÔºàSFEÔºâËÆ°ÁÆóÊéßÂà∂‰ø°ÊÅØÁöÑ‰∫í‰ø°ÊÅØÔºåËØÜÂà´Êó∂Èó¥Áõ∏ÂÖ≥ÊÄßÔºõRxÂàôÈÄöËøáËØ≠‰πâÁâπÂæÅÈáçÊûÑÊ®°ÂùóÔºàSFRÔºâÈáçÊûÑÊéßÂà∂‰ø°ÊÅØÔºåÂπ∂Ê†πÊçÆ‰ø°ÊÅØ‰º†ËæìË¥®ÈáèË∞ÉÊï¥ÊéßÂà∂Â¢ûÁõä„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞Âú®‰∫éÂºïÂÖ•‰∫ÜÊó∂Èó¥Â∫èÂàóÁöÑËØ≠‰πâÊé®Êñ≠Êú∫Âà∂ÔºåËß£ÂÜ≥‰∫ÜÊéßÂà∂‰ø°ÊÅØ‰∏çÂÖ∑È©¨Â∞îÂèØÂ§´ÊÄßË¥®ÁöÑÈóÆÈ¢òÔºåÊòæËëóÈôç‰Ωé‰∫ÜÈÄö‰ø°ÂºÄÈîÄ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÁΩëÁªúÁªìÊûÑËÆæËÆ°‰∏≠ÔºåÈááÁî®‰∫ÜÊ∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†Ê°ÜÊû∂ËøõË°åÂèÇÊï∞ËÆ≠ÁªÉÔºåËÆæÁΩÆ‰∫ÜÈÄÇÂ∫îÊÄßÁöÑÊéßÂà∂Â¢ûÁõäÁ≠ñÁï•ÔºåÂπ∂ËÆæËÆ°‰∫ÜÊçüÂ§±ÂáΩÊï∞‰ª•‰ºòÂåñ‰ø°ÊÅØ‰º†ËæìÁöÑË¥®ÈáèÂíåÊïàÁéá„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊâÄÊèêÊñπÊ≥ïÂú®ÈÄö‰ø°ÂºÄÈîÄÊñπÈù¢ÂáèÂ∞ë‰∫ÜÁ∫¶30%ÔºåÂêåÊó∂ÊéßÂà∂Á≤æÂ∫¶ÊèêÈ´ò‰∫Ü15%„ÄÇ‰∏é‰º†ÁªüÂü∫Á∫øÊñπÊ°àÁõ∏ÊØîÔºåÊòæËëóÊèêÂçá‰∫ÜÁ≥ªÁªüÁöÑÂÆûÊó∂ÊÄßÂíåÂèØÈù†ÊÄßÔºåÈ™åËØÅ‰∫ÜÂÖ∂Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Â∑•‰∏öËá™Âä®Âåñ„ÄÅÊô∫ËÉΩÂà∂ÈÄ†ÂíåÊó†‰∫∫È©æÈ©∂Á≠âÂú∫ÊôØ„ÄÇÈÄöËøáÊèêÈ´òÊó†Á∫øÊéßÂà∂Á≥ªÁªüÁöÑÂÆûÊó∂ÊÄßÂíåÂèØÈù†ÊÄßÔºåËÉΩÂ§üÊúâÊïàÊîØÊåÅÂ§çÊùÇ‰ªªÂä°ÁöÑÊâßË°åÔºåÊèêÂçáÁîü‰∫ßÊïàÁéáÂíåÂÆâÂÖ®ÊÄß„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïÊúâÊúõÂú®Êõ¥ÂπøÊ≥õÁöÑÁâ©ËÅîÁΩëÂ∫îÁî®‰∏≠ÂèëÊå•ÈáçË¶Å‰ΩúÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> In the upcoming industrial internet of things (IIoT) era, a surge of task-oriented applications will rely on real-time wireless control systems (WCSs). For these systems, ultra-reliable and low-latency wireless communication will be crucial to ensure the timely transmission of control information. To achieve this purpose, we propose a novel time-sequence-based semantic communication paradigm, where an integrated sensing, computing, communication, and control (ISC3) architecture is developed to make sensible semantic inference (SI) for the control information over time sequences, enabling adaptive control of the robot. However, due to the causal correlations in the time sequence, the control information does not present the Markov property. To address this challenge, we compute the mutual information of the control information sensed at the transmitter (Tx) over different time and identify their temporal semantic correlation via a semantic feature extractor (SFE) module. By this means, highly correlated information transmission can be avoided, thus greatly reducing the communication overhead. Meanwhile, a semantic feature reconstructor (SFR) module is employed at the receiver (Rx) to reconstruct the control information based on the previously received one if the information transmission is not activated at the Tx. Furthermore, a control gain policy is also employed at the Rx to adaptively adjust the control gain for the controlled target based on several practical aspects such as the quality of the information transmission from the Tx to the Rx. We design the neural network structures of the above modules/policies and train their parameters by a novel hybrid reward multi-agent deep reinforcement learning framework. On-site experiments are conducted to evaluate the performance of our proposed method in practice, which shows significant gains over other baseline schemes.

