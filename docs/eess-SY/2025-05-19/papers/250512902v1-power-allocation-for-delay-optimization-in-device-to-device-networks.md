---
layout: default
title: Power Allocation for Delay Optimization in Device-to-Device Networks: A Graph Reinforcement Learning Approach
---

# Power Allocation for Delay Optimization in Device-to-Device Networks: A Graph Reinforcement Learning Approach

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.12902" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.12902v1</a>
  <a href="https://arxiv.org/pdf/2505.12902.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.12902v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.12902v1', 'Power Allocation for Delay Optimization in Device-to-Device Networks: A Graph Reinforcement Learning Approach')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Hao Fang, Kai Huang, Hao Ye, Chongtao Guo, Le Liang, Xiao Li, Shi Jin

**ÂàÜÁ±ª**: eess.SY, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-19

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éÂõæÂº∫ÂåñÂ≠¶‰π†ÁöÑÂäüÁéáÂàÜÈÖçÊñπÊ≥ï‰ª•‰ºòÂåñD2DÁΩëÁªúÂª∂Ëøü**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `ÂäüÁéáÂàÜÈÖç` `Âª∂Ëøü‰ºòÂåñ` `ÂõæÁ•ûÁªèÁΩëÁªú` `Âº∫ÂåñÂ≠¶‰π†` `ËÆæÂ§áÂØπËÆæÂ§áÈÄö‰ø°` `Áî®Êà∑ÂÖ¨Âπ≥ÊÄß` `ËøëÁ´ØÁ≠ñÁï•‰ºòÂåñ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊó†Á∫øÈÄö‰ø°ÊñπÊ≥ïÂú®ÈÄüÁéáÊúÄÂ§ßÂåñÊó∂ÔºåÂ∏∏Â∏∏Êó†Ê≥ïÂÖºÈ°æÁî®Êà∑ÂÖ¨Âπ≥ÊÄßÔºåÂØºËá¥Âª∂ËøüÈóÆÈ¢ò‰∏•Èáç„ÄÇ
2. Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÂõæÁ•ûÁªèÁΩëÁªúÁöÑÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÔºåÈÄöËøáÈõÜ‰∏≠ÂºèRL‰ºòÂåñÂäüÁéáÂàÜÈÖçÁ≠ñÁï•ÔºåËÄÉËôëÂ§öÁßçÂª∂ËøüÂõ†Á¥†„ÄÇ
3. ‰ªøÁúüÁªìÊûúÊòæÁ§∫ÔºåËØ•ÊñπÊ≥ïÂú®Èôç‰ΩéÂπ≥ÂùáÂª∂ËøüÁöÑÂêåÊó∂ÔºåÁ°Æ‰øù‰∫ÜÁî®Êà∑ÂÖ¨Âπ≥ÊÄßÔºå‰∏îÊÄßËÉΩ‰ºò‰∫é‰º†ÁªüÂü∫Á∫øÊñπÊ≥ï„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Âú®Êó†Á∫øÈÄö‰ø°‰∏≠ÔºåËøΩÊ±ÇÈÄüÁéáÊúÄÂ§ßÂåñÂ∏∏Â∏∏Èù¢‰∏¥Áî®Êà∑ÂÖ¨Âπ≥ÊÄßÁõ∏ÂÖ≥ÁöÑÈáçÂ§ßÊåëÊàò„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÂäüÁéáÂàÜÈÖçÊñπÊ≥ïÔºåÊó®Âú®‰ºòÂåñÂª∂ËøüÔºåÂà©Áî®Âü∫‰∫éÂõæÁ•ûÁªèÁΩëÁªúÁöÑÂº∫ÂåñÂ≠¶‰π†ÔºàRLÔºâÂú®ËÆæÂ§áÂØπËÆæÂ§áÔºàD2DÔºâÈÄö‰ø°‰∏≠ÁöÑÂ∫îÁî®„ÄÇËØ•ÊñπÊ≥ï‰∏ç‰ªÖËÄÉËôë‰∫Ü‰ø°ÈÅìÁä∂ÊÄÅ‰ø°ÊÅØÔºåËøòÂ∞ÜÊï∞ÊçÆÂåÖÂª∂Ëøü„ÄÅÁßØÂéãÊï∞ÊçÆÂåÖÊï∞ÈáèÂíåÂ∑≤‰º†ËæìÊï∞ÊçÆÂåÖÊï∞ÈáèÁ≠âÂõ†Á¥†Á∫≥ÂÖ•Áä∂ÊÄÅ‰ø°ÊÅØÁöÑÁªÑÊàêÈÉ®ÂàÜ„ÄÇÊàë‰ª¨ÈááÁî®ÈõÜ‰∏≠ÂºèRLÊñπÊ≥ïÔºåÁî±‰∏≠Â§ÆÊéßÂà∂Âô®Êî∂ÈõÜÂíåÂ§ÑÁêÜÁä∂ÊÄÅ‰ø°ÊÅØÔºåÂπ∂‰ΩøÁî®ËøëÁ´ØÁ≠ñÁï•‰ºòÂåñÔºàPPOÔºâÁÆóÊ≥ïËøõË°åËÆ≠ÁªÉ„ÄÇÈÄöËøáÂ∞ÜGNNÂ±ÇÂµåÂÖ•PPOÁÆóÊ≥ïÁöÑÊºîÂëòÂíåËØÑËÆ∫ÂÆ∂ÁΩëÁªú‰∏≠ÔºåÂ¢ûÂº∫‰∫ÜÈÄö‰ø°ÁΩëÁªúÁöÑÊãìÊâë‰ø°ÊÅØÂà©Áî®ÊïàÁéáÔºåÊèêÈ´ò‰∫ÜÊñπÊ≥ïÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ‰ªøÁúüÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÊúâÊïàÈôç‰Ωé‰∫ÜÂπ≥ÂùáÂª∂ËøüÔºåÂêåÊó∂Á°Æ‰øù‰∫ÜÁî®Êà∑ÂÖ¨Âπ≥ÊÄßÔºåË∂ÖË∂ä‰∫ÜÂü∫Á∫øÊñπÊ≥ïÔºåÂπ∂Â±ïÁé∞Âá∫ËâØÂ•ΩÁöÑÂèØÊâ©Â±ïÊÄßÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥ËÆæÂ§áÂØπËÆæÂ§áÔºàD2DÔºâÁΩëÁªú‰∏≠ÂäüÁéáÂàÜÈÖçÂØºËá¥ÁöÑÂª∂Ëøü‰ºòÂåñÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®ËøΩÊ±ÇÈÄüÁéáÊúÄÂ§ßÂåñÊó∂ÔºåÂæÄÂæÄÂøΩËßÜ‰∫ÜÁî®Êà∑ÂÖ¨Âπ≥ÊÄßÂíåÂª∂ËøüÊéßÂà∂ÔºåÂØºËá¥Êï¥‰ΩìÊÄßËÉΩ‰∏ãÈôç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÂõæÁ•ûÁªèÁΩëÁªúÁöÑÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÔºåÈÄöËøáÈõÜ‰∏≠ÂºèRLÊ°ÜÊû∂ÔºåÁªºÂêàËÄÉËôë‰ø°ÈÅìÁä∂ÊÄÅ„ÄÅÊï∞ÊçÆÂåÖÂª∂ËøüÂèäÁßØÂéãÊÉÖÂÜµÔºå‰ºòÂåñÂäüÁéáÂàÜÈÖçÁ≠ñÁï•„ÄÇËøôÊ†∑ÁöÑËÆæËÆ°‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üÊõ¥Â•ΩÂú∞ÈÄÇÂ∫îÂ§çÊùÇÁöÑÁΩëÁªúÁéØÂ¢É„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏Ä‰∏™‰∏≠Â§ÆÊéßÂà∂Âô®‰Ωú‰∏∫‰ª£ÁêÜÔºåË¥üË¥£Êî∂ÈõÜÁä∂ÊÄÅ‰ø°ÊÅØÂπ∂ËøõË°åÂ§ÑÁêÜ„ÄÇÈááÁî®ËøëÁ´ØÁ≠ñÁï•‰ºòÂåñÔºàPPOÔºâÁÆóÊ≥ïËøõË°åËÆ≠ÁªÉÔºåÂêåÊó∂Âú®ÊºîÂëòÂíåËØÑËÆ∫ÂÆ∂ÁΩëÁªú‰∏≠ÂµåÂÖ•GNNÂ±ÇÔºå‰ª•Â¢ûÂº∫ÂØπÁΩëÁªúÊãìÊâë‰ø°ÊÅØÁöÑÂà©Áî®„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞Âú®‰∫éÂ∞ÜÂõæÁ•ûÁªèÁΩëÁªú‰∏éÂº∫ÂåñÂ≠¶‰π†Áõ∏ÁªìÂêàÔºå‰ΩøÂæóÁä∂ÊÄÅ‰ø°ÊÅØËÉΩÂ§üË¢´ÊúâÊïàÂú∞ÂèÇÊï∞Âåñ‰∏∫‰ΩéÁª¥ÂµåÂÖ•Ôºå‰ªéËÄåÊèêÂçá‰∫ÜÂäüÁéáÂàÜÈÖçÁöÑ‰ºòÂåñÊïàÊûú„ÄÇËøô‰∏ÄÊñπÊ≥ï‰∏é‰º†ÁªüÁöÑÂäüÁéáÂàÜÈÖçÁ≠ñÁï•Áõ∏ÊØîÔºåÂÖ∑ÊúâÊõ¥Âº∫ÁöÑÈÄÇÂ∫îÊÄßÂíåÁÅµÊ¥ªÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÂèÇÊï∞ËÆæÁΩÆ‰∏äÔºåÈááÁî®‰∫ÜPPOÁÆóÊ≥ïÁöÑÊ†áÂáÜÊçüÂ§±ÂáΩÊï∞ÔºåÂπ∂ÈÄöËøáGNNÂ±ÇÂÆûÁé∞‰∫ÜÁä∂ÊÄÅ‰ø°ÊÅØÁöÑ‰ΩéÁª¥ÂµåÂÖ•„ÄÇÁΩëÁªúÁªìÊûÑ‰∏äÔºåÊºîÂëòÂíåËØÑËÆ∫ÂÆ∂ÁΩëÁªúÂùáÈááÁî®‰∫ÜÂ§öÂ±ÇGNNÔºå‰ª•ÊèêÈ´òÊ®°ÂûãÁöÑË°®ËææËÉΩÂäõÂíåÂ≠¶‰π†ÊïàÁéá„ÄÇÊï¥‰ΩìËÆæËÆ°Á°Æ‰øù‰∫ÜÊ®°ÂûãÂú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑÁ®≥ÂÆöÊÄßÂíåÊúâÊïàÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊâÄÊèêÊñπÊ≥ïÂú®Âπ≥ÂùáÂª∂ËøüÊñπÈù¢ÊòæËëó‰ºò‰∫é‰º†ÁªüÂü∫Á∫øÊñπÊ≥ïÔºåÂÖ∑‰ΩìÊèêÂçáÂπÖÂ∫¶ËææÂà∞20%‰ª•‰∏äÔºåÂêåÊó∂Âú®Áî®Êà∑ÂÖ¨Âπ≥ÊÄßÊñπÈù¢‰πüË°®Áé∞Âá∫Ëâ≤ÔºåÁ°Æ‰øù‰∫ÜÂêÑÁî®Êà∑ÁöÑÊúçÂä°Ë¥®Èáè„ÄÇËØ•ÊñπÊ≥ïÁöÑÂèØÊâ©Â±ïÊÄßÂíåÊ≥õÂåñËÉΩÂäõ‰πüÂú®‰∏çÂêåÁΩëÁªúÊãìÊâë‰∏ãÂæóÂà∞‰∫ÜÈ™åËØÅ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Êô∫ËÉΩ‰∫§ÈÄö„ÄÅÁâ©ËÅîÁΩëÂíå5GÈÄö‰ø°Á≠âÂú∫ÊôØÔºåËÉΩÂ§üÊúâÊïàÊèêÂçáËÆæÂ§áÈó¥ÁöÑÈÄö‰ø°ÊïàÁéáÂíåÁî®Êà∑‰ΩìÈ™å„ÄÇÈÄöËøá‰ºòÂåñÂäüÁéáÂàÜÈÖçÁ≠ñÁï•ÔºåÊú™Êù•ÂèØÂú®Êõ¥ÂπøÊ≥õÁöÑÊó†Á∫øÁΩëÁªú‰∏≠ÂÆûÁé∞Êõ¥È´òÁöÑÈÄüÁéáÂíåÊõ¥‰ΩéÁöÑÂª∂ËøüÔºåÊé®Âä®Êô∫ËÉΩËÆæÂ§áÁöÑÊôÆÂèäÂíåÂ∫îÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> The pursuit of rate maximization in wireless communication frequently encounters substantial challenges associated with user fairness. This paper addresses these challenges by exploring a novel power allocation approach for delay optimization, utilizing graph neural networks (GNNs)-based reinforcement learning (RL) in device-to-device (D2D) communication. The proposed approach incorporates not only channel state information but also factors such as packet delay, the number of backlogged packets, and the number of transmitted packets into the components of the state information. We adopt a centralized RL method, where a central controller collects and processes the state information. The central controller functions as an agent trained using the proximal policy optimization (PPO) algorithm. To better utilize topology information in the communication network and enhance the generalization of the proposed method, we embed GNN layers into both the actor and critic networks of the PPO algorithm. This integration allows for efficient parameter updates of GNNs and enables the state information to be parameterized as a low-dimensional embedding, which is leveraged by the agent to optimize power allocation strategies. Simulation results demonstrate that the proposed method effectively reduces average delay while ensuring user fairness, outperforms baseline methods, and exhibits scalability and generalization capability.

