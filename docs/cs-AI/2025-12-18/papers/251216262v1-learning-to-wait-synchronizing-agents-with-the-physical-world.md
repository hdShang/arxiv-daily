---
layout: default
title: Learning to Wait: Synchronizing Agents with the Physical World
---

# Learning to Wait: Synchronizing Agents with the Physical World

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.16262" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.16262v1</a>
  <a href="https://arxiv.org/pdf/2512.16262.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.16262v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.16262v1', 'Learning to Wait: Synchronizing Agents with the Physical World')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yifei She, Ping Zhang, He Liu, Yanmin Jia, Yang Jing, Zijun Liu, Peng Sun, Xiangbin Li, Xiaohe Hu

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-18

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAgentç«¯æ—¶é—´åŒæ­¥æ–¹æ³•ï¼Œè§£å†³LLMåœ¨å¼‚æ­¥ç¯å¢ƒä¸­çš„æ—¶åºæ ¡å‡†é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `Agent` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ—¶é—´åŒæ­¥` `å¼‚æ­¥ç¯å¢ƒ` `ä¸Šä¸‹æ–‡å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°å®Agentä»»åŠ¡ä¸­ï¼ŒåŠ¨ä½œå®Œæˆå­˜åœ¨æ—¶é—´å»¶è¿Ÿï¼Œå¯¼è‡´Agentä¸ç¯å¢ƒäº¤äº’å‡ºç°æ—¶é—´é—´éš”ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥å…¼é¡¾æ•ˆç‡ä¸ä¸Šä¸‹æ–‡å®Œæ•´æ€§ã€‚
2. è®ºæ–‡æå‡ºAgentç«¯æ—¶é—´åŒæ­¥æ–¹æ³•ï¼Œé€šè¿‡LLMé¢„æµ‹ç­‰å¾…æ—¶é•¿ï¼Œä½¿Agentä¸»åŠ¨ä¸å¼‚æ­¥ç¯å¢ƒå¯¹é½ï¼Œæ— éœ€é¢‘ç¹è½®è¯¢ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½æœ‰æ•ˆæ ¡å‡†Agentå†…éƒ¨æ—¶é’Ÿï¼Œé™ä½æŸ¥è¯¢å¼€é”€å’Œæ‰§è¡Œå»¶è¿Ÿï¼ŒéªŒè¯äº†æ—¶é—´æ„ŸçŸ¥èƒ½åŠ›çš„å¯å­¦ä¹ æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸åŒæ­¥é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆMDPï¼‰ä¸åŒï¼Œç°å®ä¸–ç•Œçš„Agentä»»åŠ¡é€šå¸¸æ¶‰åŠå…·æœ‰å¯å˜å»¶è¿Ÿçš„éé˜»å¡åŠ¨ä½œï¼Œä»è€Œåœ¨åŠ¨ä½œå‘èµ·å’Œå®Œæˆä¹‹é—´äº§ç”Ÿæ ¹æœ¬æ€§çš„â€œæ—¶é—´é—´éš”â€ã€‚ç°æœ‰çš„ç¯å¢ƒç«¯è§£å†³æ–¹æ¡ˆï¼Œå¦‚é˜»å¡åŒ…è£…å™¨æˆ–é¢‘ç¹è½®è¯¢ï¼Œè¦ä¹ˆé™åˆ¶äº†å¯æ‰©å±•æ€§ï¼Œè¦ä¹ˆç”¨å†—ä½™è§‚å¯Ÿç¨€é‡Šäº†Agentçš„ä¸Šä¸‹æ–‡çª—å£ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§Agentç«¯æ–¹æ³•ï¼Œä½¿å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰èƒ½å¤Ÿä¸»åŠ¨å°†å…¶â€œè®¤çŸ¥æ—¶é—´çº¿â€ä¸ç‰©ç†ä¸–ç•Œå¯¹é½ã€‚é€šè¿‡å°†ä»£ç å³åŠ¨ä½œèŒƒå¼æ‰©å±•åˆ°æ—¶é—´åŸŸï¼ŒAgentåˆ©ç”¨è¯­ä¹‰å…ˆéªŒå’Œä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰æ¥é¢„æµ‹ç²¾ç¡®çš„ç­‰å¾…æ—¶é•¿ï¼ˆ`time.sleep(t)`ï¼‰ï¼Œä»è€Œæœ‰æ•ˆåœ°ä¸å¼‚æ­¥ç¯å¢ƒåŒæ­¥ï¼Œè€Œæ— éœ€è¯¦å°½çš„æ£€æŸ¥ã€‚åœ¨æ¨¡æ‹Ÿçš„Kubernetesé›†ç¾¤ä¸­çš„å®éªŒè¡¨æ˜ï¼ŒAgentå¯ä»¥ç²¾ç¡®åœ°æ ¡å‡†å…¶å†…éƒ¨æ—¶é’Ÿï¼Œä»¥æœ€å¤§é™åº¦åœ°å‡å°‘æŸ¥è¯¢å¼€é”€å’Œæ‰§è¡Œå»¶è¿Ÿï¼Œä»è€ŒéªŒè¯äº†æ—¶é—´æ„ŸçŸ¥æ˜¯åœ¨å¼€æ”¾ç¯å¢ƒä¸­è‡ªä¸»è¿›åŒ–å¿…ä¸å¯å°‘çš„ã€å¯å­¦ä¹ çš„èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æ–¹æ³•åœ¨å¤„ç†ç°å®ä¸–ç•ŒAgentä»»åŠ¡æ—¶ï¼Œç”±äºåŠ¨ä½œçš„éé˜»å¡æ€§å’Œå¯å˜å»¶è¿Ÿï¼Œå¯¼è‡´Agentçš„è®¤çŸ¥æ—¶é—´çº¿ä¸ç‰©ç†ä¸–ç•Œå­˜åœ¨æ—¶é—´é—´éš”ã€‚ç¯å¢ƒç«¯çš„è§£å†³æ–¹æ¡ˆï¼Œå¦‚é˜»å¡åŒ…è£…å™¨ï¼Œä¼šé™åˆ¶å¯æ‰©å±•æ€§ï¼›é¢‘ç¹è½®è¯¢åˆ™ä¼šç¨€é‡ŠAgentçš„ä¸Šä¸‹æ–‡çª—å£ï¼Œé™ä½æ•ˆç‡ã€‚å› æ­¤ï¼Œå¦‚ä½•ä½¿Agentåœ¨å¼‚æ­¥ç¯å¢ƒä¸­é«˜æ•ˆã€å‡†ç¡®åœ°ä¸ç¯å¢ƒåŒæ­¥æ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯èµ‹äºˆAgentæ—¶é—´æ„ŸçŸ¥èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿä¸»åŠ¨é¢„æµ‹å¹¶ç­‰å¾…åŠ¨ä½œå®Œæˆæ‰€éœ€çš„æ—¶é—´ï¼Œä»è€Œå®ç°ä¸å¼‚æ­¥ç¯å¢ƒçš„åŒæ­¥ã€‚é€šè¿‡å°†æ—¶é—´ç»´åº¦èå…¥Agentçš„å†³ç­–è¿‡ç¨‹ï¼Œé¿å…äº†è¢«åŠ¨ç­‰å¾…æˆ–é¢‘ç¹æŸ¥è¯¢ï¼Œæé«˜äº†æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•åŸºäºä»£ç å³åŠ¨ä½œèŒƒå¼ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä½œä¸ºAgentçš„å†³ç­–æ ¸å¿ƒã€‚Agenté€šè¿‡è§‚å¯Ÿç¯å¢ƒçŠ¶æ€ï¼Œåˆ©ç”¨è¯­ä¹‰å…ˆéªŒå’Œä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰æ¥é¢„æµ‹ç­‰å¾…æ—¶é•¿ï¼Œå¹¶æ‰§è¡Œ`time.sleep(t)`æŒ‡ä»¤ã€‚æ•´ä½“æµç¨‹åŒ…æ‹¬ï¼š1) Agentè§‚å¯Ÿç¯å¢ƒï¼›2) LLMåŸºäºä¸Šä¸‹æ–‡é¢„æµ‹ç­‰å¾…æ—¶é—´ï¼›3) Agentæ‰§è¡Œ`time.sleep(t)`ï¼›4) Agentå†æ¬¡è§‚å¯Ÿç¯å¢ƒï¼Œå¾ªç¯æ‰§è¡Œã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†æ—¶é—´æ„ŸçŸ¥èƒ½åŠ›èå…¥Agentçš„å†³ç­–è¿‡ç¨‹ï¼Œä½¿å…¶èƒ½å¤Ÿä¸»åŠ¨é¢„æµ‹ç­‰å¾…æ—¶é—´ï¼Œè€Œä¸æ˜¯ä¾èµ–ç¯å¢ƒçš„åŒæ­¥æœºåˆ¶ã€‚è¿™ç§Agentç«¯çš„æ—¶é—´åŒæ­¥æ–¹æ³•ï¼Œé¿å…äº†ç¯å¢ƒç«¯è§£å†³æ–¹æ¡ˆçš„å±€é™æ€§ï¼Œæé«˜äº†Agentåœ¨å¼‚æ­¥ç¯å¢ƒä¸­çš„é€‚åº”æ€§å’Œæ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨LLMä½œä¸ºAgentçš„å†³ç­–æ ¸å¿ƒï¼Œåˆ©ç”¨å…¶å¼ºå¤§çš„è¯­ä¹‰ç†è§£å’Œæ¨ç†èƒ½åŠ›ï¼›2) é€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰æä¾›æ—¶é—´ç›¸å…³çš„ç¤ºä¾‹ï¼Œå¼•å¯¼LLMé¢„æµ‹å‡†ç¡®çš„ç­‰å¾…æ—¶é—´ï¼›3) ä½¿ç”¨`time.sleep(t)`æŒ‡ä»¤æ¨¡æ‹Ÿç­‰å¾…åŠ¨ä½œå®Œæˆï¼Œå®ç°Agentä¸ç¯å¢ƒçš„æ—¶é—´åŒæ­¥ï¼›4) åœ¨æ¨¡æ‹Ÿçš„Kubernetesé›†ç¾¤ä¸­è¿›è¡Œå®éªŒï¼ŒéªŒè¯è¯¥æ–¹æ³•åœ¨å®é™…åœºæ™¯ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16262v1/x1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16262v1/x2.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16262v1/x3.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ¨¡æ‹Ÿçš„Kubernetesé›†ç¾¤ä¸­èƒ½å¤Ÿæ˜¾è‘—é™ä½æŸ¥è¯¢å¼€é”€å’Œæ‰§è¡Œå»¶è¿Ÿã€‚Agentèƒ½å¤Ÿç²¾ç¡®åœ°æ ¡å‡†å…¶å†…éƒ¨æ—¶é’Ÿï¼Œä¸å¼‚æ­¥ç¯å¢ƒå®ç°é«˜æ•ˆåŒæ­¥ã€‚å…·ä½“æ€§èƒ½æ•°æ®æœªçŸ¥ï¼Œä½†è®ºæ–‡å¼ºè°ƒäº†è¯¥æ–¹æ³•åœ¨æœ€å°åŒ–æŸ¥è¯¢å¼€é”€å’Œæ‰§è¡Œå»¶è¿Ÿæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦ä¸å¼‚æ­¥ç¯å¢ƒäº¤äº’çš„Agentä»»åŠ¡ï¼Œä¾‹å¦‚æœºå™¨äººæ§åˆ¶ã€è‡ªåŠ¨åŒ–è¿ç»´ã€æ™ºèƒ½å®¶å±…ç­‰ã€‚é€šè¿‡èµ‹äºˆAgentæ—¶é—´æ„ŸçŸ¥èƒ½åŠ›ï¼Œå¯ä»¥æé«˜å…¶åœ¨å¤æ‚ã€åŠ¨æ€ç¯å¢ƒä¸­çš„è‡ªä¸»æ€§å’Œæ•ˆç‡ï¼Œå®ç°æ›´æ™ºèƒ½ã€æ›´å¯é çš„è‡ªåŠ¨åŒ–ç³»ç»Ÿã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æ‰©å±•åˆ°æ›´å¹¿æ³›çš„é¢†åŸŸï¼Œä¾‹å¦‚æ™ºèƒ½äº¤é€šã€é‡‘èäº¤æ˜“ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Real-world agentic tasks, unlike synchronous Markov Decision Processes (MDPs), often involve non-blocking actions with variable latencies, creating a fundamental \textit{Temporal Gap} between action initiation and completion. Existing environment-side solutions, such as blocking wrappers or frequent polling, either limit scalability or dilute the agent's context window with redundant observations. In this work, we propose an \textbf{Agent-side Approach} that empowers Large Language Models (LLMs) to actively align their \textit{Cognitive Timeline} with the physical world. By extending the Code-as-Action paradigm to the temporal domain, agents utilize semantic priors and In-Context Learning (ICL) to predict precise waiting durations (\texttt{time.sleep(t)}), effectively synchronizing with asynchronous environment without exhaustive checking. Experiments in a simulated Kubernetes cluster demonstrate that agents can precisely calibrate their internal clocks to minimize both query overhead and execution latency, validating that temporal awareness is a learnable capability essential for autonomous evolution in open-ended environments.

