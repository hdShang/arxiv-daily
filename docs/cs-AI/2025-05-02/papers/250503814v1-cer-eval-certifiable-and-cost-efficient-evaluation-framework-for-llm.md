---
layout: default
title: "Cer-Eval: Certifiable and Cost-Efficient Evaluation Framework for LLMs"
---

# Cer-Eval: Certifiable and Cost-Efficient Evaluation Framework for LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.03814" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.03814v1</a>
  <a href="https://arxiv.org/pdf/2505.03814.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.03814v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.03814v1', 'Cer-Eval: Certifiable and Cost-Efficient Evaluation Framework for LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ganghua Wang, Zhaorun Chen, Bo Li, Haifeng Xu

**åˆ†ç±»**: stat.ML, cs.AI, cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-02

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCer-Evalæ¡†æ¶ä»¥è§£å†³LLMsè¯„ä¼°æ•ˆç‡ä½ä¸‹é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `è¯„ä¼°æ¡†æ¶` `æµ‹è¯•æ ·æœ¬å¤æ‚åº¦` `è‡ªé€‚åº”é€‰æ‹©` `ç½®ä¿¡åŒºé—´`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„LLMsè¯„ä¼°æ–¹æ³•ä¾èµ–äºä¸æ–­æ‰©å¤§çš„æ•°æ®é›†ï¼Œå¯¼è‡´è¯„ä¼°æ•ˆç‡ä½ä¸‹ä¸”æˆæœ¬é«˜æ˜‚ã€‚
2. æœ¬æ–‡æå‡ºçš„Cer-Evalæ¡†æ¶é€šè¿‡è‡ªé€‚åº”é€‰æ‹©æµ‹è¯•ç‚¹ï¼Œä¼˜åŒ–è¯„ä¼°è¿‡ç¨‹ï¼Œé™ä½äº†æµ‹è¯•æ ·æœ¬çš„éœ€æ±‚ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒCer-Evalåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­èŠ‚çœäº†20%åˆ°40%çš„æµ‹è¯•ç‚¹ï¼ŒåŒæ—¶ä¿æŒäº†ä¼°è®¡è¯¯å·®çš„å¯é æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€åŸºç¡€æ¨¡å‹çš„ä¸æ–­æ‰©å±•ï¼Œè®­ç»ƒæ¨¡å‹çš„è§„æ¨¡å‘ˆæŒ‡æ•°å¢é•¿ï¼Œç»™å…¶è¯„ä¼°å¸¦æ¥äº†é‡å¤§æŒ‘æˆ˜ã€‚ç›®å‰çš„è¯„ä¼°å®è·µéœ€è¦ç­–åˆ’è¶Šæ¥è¶Šå¤§çš„æ•°æ®é›†æ¥è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œç¼ºä¹ç³»ç»Ÿåˆ†æå’ŒæŒ‡å¯¼æ¥ç¡®å®šæµ‹è¯•æ•°æ®çš„å……åˆ†æ€§æˆ–é€‰æ‹©ä¿¡æ¯é‡ä¸°å¯Œçš„æ ·æœ¬è¿›è¡Œè¯„ä¼°ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§å¯è¯æ˜ä¸”æˆæœ¬é«˜æ•ˆçš„LLMsè¯„ä¼°æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€‚åº”ä¸åŒçš„è¯„ä¼°ç›®æ ‡ï¼Œå¹¶è¾“å‡ºé«˜æ¦‚ç‡åŒ…å«çœŸå®å€¼çš„ç½®ä¿¡åŒºé—´ã€‚æˆ‘ä»¬ä½¿ç”¨â€œæµ‹è¯•æ ·æœ¬å¤æ‚åº¦â€æ¥é‡åŒ–å¯è¯æ˜è¯„ä¼°æ‰€éœ€çš„æµ‹è¯•ç‚¹æ•°é‡ï¼Œå¹¶æ¨å¯¼å‡ºæµ‹è¯•æ ·æœ¬å¤æ‚åº¦çš„ç´§ç•Œé™ã€‚åŸºäºæ‰€å¼€å‘çš„ç†è®ºï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§åä¸ºCer-Evalçš„åŸºäºåˆ†åŒºçš„ç®—æ³•ï¼Œèƒ½å¤Ÿè‡ªé€‚åº”é€‰æ‹©æµ‹è¯•ç‚¹ï¼Œä»¥æœ€å°åŒ–LLMsè¯„ä¼°çš„æˆæœ¬ã€‚å®é™…å®éªŒè¡¨æ˜ï¼ŒCer-Evalåœ¨å„ç§åŸºå‡†æµ‹è¯•ä¸­å¯ä»¥èŠ‚çœ20%åˆ°40%çš„æµ‹è¯•ç‚¹ï¼ŒåŒæ—¶ä¿æŒä¸å½“å‰è¯„ä¼°è¿‡ç¨‹ç›¸å½“çš„ä¼°è®¡è¯¯å·®æ°´å¹³ï¼Œå¹¶æä¾›95%çš„ç½®ä¿¡ä¿è¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è§£å†³çš„æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¯„ä¼°ä¸­çš„æ•ˆç‡å’Œæˆæœ¬é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•éœ€è¦å¤§é‡æ•°æ®é›†è¿›è¡Œè¯„ä¼°ï¼Œå¯¼è‡´è¯„ä¼°è¿‡ç¨‹ç¹çä¸”æˆæœ¬é«˜æ˜‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼•å…¥å¯è¯æ˜çš„è¯„ä¼°æ¡†æ¶ï¼Œåˆ©ç”¨â€œæµ‹è¯•æ ·æœ¬å¤æ‚åº¦â€æ¥é‡åŒ–æ‰€éœ€çš„æµ‹è¯•ç‚¹æ•°é‡ï¼Œä»è€Œä¼˜åŒ–è¯„ä¼°è¿‡ç¨‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCer-Evalæ¡†æ¶åŒ…æ‹¬æ•°æ®é€‰æ‹©æ¨¡å—ã€è¯„ä¼°ç›®æ ‡é€‚åº”æ¨¡å—å’Œç½®ä¿¡åŒºé—´è¾“å‡ºæ¨¡å—ã€‚é€šè¿‡è¿™äº›æ¨¡å—ï¼Œæ¡†æ¶èƒ½å¤Ÿæ ¹æ®ä¸åŒçš„è¯„ä¼°ç›®æ ‡è‡ªé€‚åº”é€‰æ‹©æµ‹è¯•ç‚¹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†â€œæµ‹è¯•æ ·æœ¬å¤æ‚åº¦â€çš„æ¦‚å¿µï¼Œå¹¶æ¨å¯¼å‡ºå…¶ç´§ç•Œé™ï¼Œä»è€Œä¸ºè¯„ä¼°æä¾›äº†ç†è®ºåŸºç¡€ã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºå…¶ç³»ç»Ÿæ€§å’Œå¯è¯æ˜æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å…³é”®è®¾è®¡æ–¹é¢ï¼ŒCer-Evalé‡‡ç”¨äº†åˆ†åŒºç®—æ³•æ¥é€‰æ‹©æµ‹è¯•ç‚¹ï¼Œå¹¶è®¾ç½®äº†ç›¸åº”çš„ç½®ä¿¡æ°´å¹³ï¼Œä»¥ç¡®ä¿è¯„ä¼°ç»“æœçš„å¯é æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCer-Evalåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­èƒ½å¤ŸèŠ‚çœ20%åˆ°40%çš„æµ‹è¯•ç‚¹ï¼ŒåŒæ—¶ä¿æŒä¸å½“å‰è¯„ä¼°è¿‡ç¨‹ç›¸å½“çš„ä¼°è®¡è¯¯å·®æ°´å¹³ï¼Œå¹¶æä¾›95%çš„ç½®ä¿¡ä¿è¯ã€‚è¿™è¡¨æ˜Cer-Evalåœ¨è¯„ä¼°æ•ˆç‡å’Œå‡†ç¡®æ€§æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Cer-Evalæ¡†æ¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦é«˜æ•ˆè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹çš„é¢†åŸŸï¼Œå¦‚è‡ªç„¶è¯­è¨€å¤„ç†ã€æœºå™¨ç¿»è¯‘å’Œå¯¹è¯ç³»ç»Ÿç­‰ã€‚é€šè¿‡é™ä½è¯„ä¼°æˆæœ¬å’Œæé«˜æ•ˆç‡ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿå¸®åŠ©ç ”ç©¶äººå‘˜å’Œå¼€å‘è€…æ›´å¿«åœ°è¿­ä»£å’Œä¼˜åŒ–æ¨¡å‹ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> As foundation models continue to scale, the size of trained models grows exponentially, presenting significant challenges for their evaluation. Current evaluation practices involve curating increasingly large datasets to assess the performance of large language models (LLMs). However, there is a lack of systematic analysis and guidance on determining the sufficiency of test data or selecting informative samples for evaluation. This paper introduces a certifiable and cost-efficient evaluation framework for LLMs. Our framework adapts to different evaluation objectives and outputs confidence intervals that contain true values with high probability. We use ``test sample complexity'' to quantify the number of test points needed for a certifiable evaluation and derive tight bounds on test sample complexity. Based on the developed theory, we develop a partition-based algorithm, named Cer-Eval, that adaptively selects test points to minimize the cost of LLM evaluation. Real-world experiments demonstrate that Cer-Eval can save 20% to 40% test points across various benchmarks, while maintaining an estimation error level comparable to the current evaluation process and providing a 95% confidence guarantee.

