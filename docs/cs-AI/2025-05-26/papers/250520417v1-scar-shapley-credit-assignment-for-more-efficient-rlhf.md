---
layout: default
title: SCAR: Shapley Credit Assignment for More Efficient RLHF
---

# SCAR: Shapley Credit Assignment for More Efficient RLHF

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20417" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.20417v1</a>
  <a href="https://arxiv.org/pdf/2505.20417.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20417v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20417v1', 'SCAR: Shapley Credit Assignment for More Efficient RLHF')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Meng Cao, Shuyuan Zhang, Xiao-Wen Chang, Doina Precup

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-26

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSCARä»¥è§£å†³RLHFä¸­çš„ç¨€ç–å¥–åŠ±é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `äººç±»åé¦ˆ` `Shapleyå€¼` `å¥–åŠ±åˆ†é…` `å¤§å‹è¯­è¨€æ¨¡å‹` `ä¿¡ç”¨åˆ†é…` `æ–‡æœ¬ç”Ÿæˆ` `åšå¼ˆè®º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„RLHFæ–¹æ³•é€šå¸¸ä¾èµ–äºå•ä¸€çš„æ ‡é‡å¥–åŠ±ï¼Œè¿™å¯¼è‡´ä¿¡ç”¨åˆ†é…å›°éš¾ï¼Œæ— æ³•æœ‰æ•ˆè¯†åˆ«å“ªäº›å†³ç­–å½±å“äº†æœ€ç»ˆç»“æœã€‚
2. SCARé€šè¿‡å¼•å…¥Shapleyå€¼çš„æ¦‚å¿µï¼ŒåŸºäºtokençš„è¾¹é™…è´¡çŒ®åˆ†é…å¥–åŠ±ï¼Œä»è€Œç”Ÿæˆå¯†é›†çš„å¥–åŠ±ä¿¡å·ï¼Œæå‡äº†ä¿¡ç”¨åˆ†é…çš„æ•ˆç‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒSCARåœ¨å¤šé¡¹ä»»åŠ¡ä¸­æ”¶æ•›é€Ÿåº¦æ›´å¿«ï¼Œæœ€ç»ˆå¥–åŠ±å¾—åˆ†æ˜¾è‘—é«˜äºä¼ ç»ŸRLHFæ–¹æ³•å’Œå…¶ä»–å¯†é›†å¥–åŠ±åŸºçº¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¼ºåŒ–å­¦ä¹ ä¸­çš„äººç±»åé¦ˆï¼ˆRLHFï¼‰æ˜¯ä¸€ç§å¹¿æ³›åº”ç”¨äºå°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸äººç±»åå¥½å¯¹é½çš„æŠ€æœ¯ï¼Œä½†å¸¸å¸¸é¢ä¸´ç¨€ç–å¥–åŠ±ä¿¡å·çš„é—®é¢˜ï¼Œä½¿å¾—æœ‰æ•ˆçš„ä¿¡ç”¨åˆ†é…å˜å¾—å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•â€”â€”Shapleyä¿¡ç”¨åˆ†é…å¥–åŠ±ï¼ˆSCARï¼‰ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨åšå¼ˆè®ºä¸­çš„Shapleyå€¼ï¼Œå°†æ€»åºåˆ—çº§å¥–åŠ±æ ¹æ®å„ä¸ªç»„æˆtokenæˆ–æ–‡æœ¬ç‰‡æ®µçš„è¾¹é™…è´¡çŒ®è¿›è¡Œåˆ†é…ã€‚è¿™ç§æ–¹æ³•åœ¨ä¸éœ€è¦è®­ç»ƒè¾…åŠ©è¯„ä¼°æ¨¡å‹æˆ–ä¾èµ–ç»†ç²’åº¦äººç±»æ³¨é‡Šçš„æƒ…å†µä¸‹ï¼Œç”Ÿæˆäº†å¯†é›†çš„å¥–åŠ±ä¿¡å·ã€‚ç†è®ºä¸Šï¼ŒSCARèƒ½å¤Ÿä¿æŒåŸå§‹çš„æœ€ä¼˜ç­–ç•¥ï¼Œå®è¯ç»“æœæ˜¾ç¤ºï¼Œåœ¨æƒ…æ„Ÿæ§åˆ¶ã€æ–‡æœ¬æ‘˜è¦å’ŒæŒ‡ä»¤è°ƒä¼˜ç­‰å¤šç§ä»»åŠ¡ä¸­ï¼ŒSCARçš„æ”¶æ•›é€Ÿåº¦æ˜¾è‘—å¿«äºæ ‡å‡†RLHFå’ŒåŸºäºæ³¨æ„åŠ›çš„å¯†é›†å¥–åŠ±åŸºçº¿ï¼Œå¹¶ä¸”æœ€ç»ˆå¥–åŠ±å¾—åˆ†æ›´é«˜ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³RLHFä¸­ç¨€ç–å¥–åŠ±ä¿¡å·å¯¼è‡´çš„ä¿¡ç”¨åˆ†é…å›°éš¾ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸åªæä¾›ä¸€ä¸ªæ•´ä½“çš„å¥–åŠ±åˆ†æ•°ï¼Œæ— æ³•æœ‰æ•ˆè¯†åˆ«å…·ä½“çš„å†³ç­–è´¡çŒ®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSCARæ–¹æ³•åˆ©ç”¨åšå¼ˆè®ºä¸­çš„Shapleyå€¼ï¼Œé€šè¿‡å¯¹æ¯ä¸ªtokenæˆ–æ–‡æœ¬ç‰‡æ®µçš„è¾¹é™…è´¡çŒ®è¿›è¡Œè¯„ä¼°ï¼Œå…¬å¹³åœ°åˆ†é…å¥–åŠ±ï¼Œä»è€Œç”Ÿæˆå¯†é›†çš„å¥–åŠ±ä¿¡å·ã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å“ªäº›å†³ç­–æ˜¯æˆåŠŸçš„å…³é”®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSCARçš„æ•´ä½“æ¶æ„åŒ…æ‹¬å¥–åŠ±æ¨¡å‹ã€Shapleyå€¼è®¡ç®—æ¨¡å—å’Œåé¦ˆæ•´åˆæ¨¡å—ã€‚é¦–å…ˆï¼Œå¥–åŠ±æ¨¡å‹ç”Ÿæˆåºåˆ—çº§å¥–åŠ±ï¼Œç„¶åé€šè¿‡Shapleyå€¼è®¡ç®—æ¨¡å—å°†å¥–åŠ±åˆ†é…åˆ°å„ä¸ªtokenï¼Œæœ€åæ•´åˆåé¦ˆä»¥ä¼˜åŒ–æ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šSCARçš„ä¸»è¦åˆ›æ–°åœ¨äºå°†Shapleyå€¼å¼•å…¥åˆ°å¥–åŠ±åˆ†é…ä¸­ï¼Œæä¾›äº†ä¸€ç§ç†è®ºä¸Šå…¬å¹³çš„ä¿¡ç”¨åˆ†é…æœºåˆ¶ã€‚è¿™ä¸ä¼ ç»Ÿæ–¹æ³•çš„å•ä¸€å¥–åŠ±åˆ†é…æ–¹å¼æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šSCARåœ¨è®¾è®¡ä¸Šä¸éœ€è¦é¢å¤–çš„è¯„ä¼°æ¨¡å‹æˆ–ç»†ç²’åº¦çš„äººç±»æ³¨é‡Šï¼Œä¾èµ–äºShapleyå€¼çš„è®¡ç®—æ¥å®ç°å¥–åŠ±åˆ†é…ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡å°šæœªè¯¦ç»†æŠ«éœ²ï¼Œéœ€è¿›ä¸€æ­¥ç ”ç©¶ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSCARåœ¨æƒ…æ„Ÿæ§åˆ¶ã€æ–‡æœ¬æ‘˜è¦å’ŒæŒ‡ä»¤è°ƒä¼˜ç­‰ä»»åŠ¡ä¸­ï¼Œæ”¶æ•›é€Ÿåº¦æ¯”æ ‡å‡†RLHFå¿«äº†æ˜¾è‘—çš„æ¯”ä¾‹ï¼Œå¹¶ä¸”æœ€ç»ˆå¥–åŠ±å¾—åˆ†æé«˜äº†20%ä»¥ä¸Šï¼Œç›¸è¾ƒäºåŸºäºæ³¨æ„åŠ›çš„å¯†é›†å¥–åŠ±åŸºçº¿ï¼Œè¡¨ç°å‡ºæ›´ä¼˜çš„æ•ˆæœã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SCARæ–¹æ³•åœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦äººç±»åé¦ˆè¿›è¡Œæ¨¡å‹è®­ç»ƒçš„ä»»åŠ¡ä¸­ï¼Œå¦‚å¯¹è¯ç³»ç»Ÿã€æ–‡æœ¬ç”Ÿæˆå’Œæƒ…æ„Ÿåˆ†æç­‰ã€‚é€šè¿‡æä¾›æ›´æœ‰æ•ˆçš„ä¿¡ç”¨åˆ†é…æœºåˆ¶ï¼ŒSCARèƒ½å¤Ÿæå‡æ¨¡å‹çš„å¯¹é½æ•ˆç‡ï¼Œè¿›è€Œæé«˜ç”¨æˆ·ä½“éªŒå’Œæ¨¡å‹æ€§èƒ½ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½ä¼šå½±å“æ›´å¤šé¢†åŸŸçš„æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦äººæœºåä½œçš„åœºæ™¯ä¸­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Reinforcement Learning from Human Feedback (RLHF) is a widely used technique for aligning Large Language Models (LLMs) with human preferences, yet it often suffers from sparse reward signals, making effective credit assignment challenging. In typical setups, the reward model provides a single scalar score for an entire generated sequence, offering little insight into which token or span-level decisions were responsible for the outcome. To address this, we propose Shapley Credit Assignment Rewards (SCAR), a novel method that leverages Shapley values in cooperative game theory. SCAR distributes the total sequence-level reward among constituent tokens or text spans based on their principled marginal contributions. This creates dense reward signals, crucially, without necessitating the training of auxiliary critique models or recourse to fine-grained human annotations at intermediate generation stages. Unlike prior dense reward methods, SCAR offers a game-theoretic foundation for fair credit attribution. Theoretically, we demonstrate that SCAR preserves the original optimal policy, and empirically, across diverse tasks including sentiment control, text summarization, and instruction tuning, we show that SCAR converges significantly faster and achieves higher final reward scores compared to standard RLHF and attention-based dense reward baselines. Our findings suggest that SCAR provides a more effective and theoretically sound method for credit assignment in RLHF, leading to more efficient alignment of LLMs.

