---
layout: default
title: Capability-Based Scaling Laws for LLM Red-Teaming
---

# Capability-Based Scaling Laws for LLM Red-Teaming

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20162" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.20162v1</a>
  <a href="https://arxiv.org/pdf/2505.20162.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20162v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20162v1', 'Capability-Based Scaling Laws for LLM Red-Teaming')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Alexander Panfilov, Paul Kassianik, Maksym Andriushchenko, Jonas Geiping

**åˆ†ç±»**: cs.AI, cs.CL, cs.CR, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-26

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºèƒ½åŠ›å·®è·æ¡†æ¶ä»¥ä¼˜åŒ–å¤§å‹è¯­è¨€æ¨¡å‹çš„çº¢é˜Ÿæµ‹è¯•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `çº¢é˜Ÿæµ‹è¯•` `èƒ½åŠ›å·®è·` `å¤§å‹è¯­è¨€æ¨¡å‹` `è¶Šç‹±æ”»å‡»` `å®‰å…¨æ€§è¯„ä¼°` `æ¨¡å‹èƒ½åŠ›` `æ”»å‡»ç­–ç•¥`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çº¢é˜Ÿæµ‹è¯•æ–¹æ³•åœ¨é¢å¯¹èƒ½åŠ›å·®è·æ—¶æ•ˆæœä¸ä½³ï¼Œå°¤å…¶æ˜¯å½“ç›®æ ‡æ¨¡å‹èƒ½åŠ›è¶…è¶Šæ”»å‡»è€…æ—¶ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡èƒ½åŠ›å·®è·æ¡†æ¶åˆ†æçº¢é˜Ÿæµ‹è¯•ï¼Œè¯„ä¼°æ”»å‡»è€…ä¸ç›®æ ‡æ¨¡å‹çš„èƒ½åŠ›å·®å¼‚ï¼Œä»¥ä¼˜åŒ–æ”»å‡»ç­–ç•¥ã€‚
3. å®éªŒè¡¨æ˜ï¼Œæ”»å‡»è€…èƒ½åŠ›è¶Šå¼ºï¼Œæ”»å‡»æˆåŠŸç‡è¶Šé«˜ï¼Œä¸”æˆåŠŸç‡ä¸ç¤¾ç§‘é¢†åŸŸçš„MMLU-ProåŸºå‡†è¡¨ç°é«˜åº¦ç›¸å…³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹èƒ½åŠ›å’Œè‡ªä¸»æ€§çš„å‘å±•ï¼Œé€šè¿‡çº¢é˜Ÿæµ‹è¯•è¯†åˆ«å…¶è„†å¼±æ€§å˜å¾—è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿçš„æç¤ºå·¥ç¨‹æ–¹æ³•åœ¨é¢å¯¹èƒ½åŠ›å·®è·æ—¶å¯èƒ½å¤±æ•ˆã€‚æœ¬æ–‡é€šè¿‡åˆ†ææ”»å‡»è€…ä¸ç›®æ ‡æ¨¡å‹ä¹‹é—´çš„èƒ½åŠ›å·®è·ï¼Œè¯„ä¼°äº†500å¤šä¸ªæ”»å‡»è€…-ç›®æ ‡å¯¹çš„LLMè¶Šç‹±æ”»å‡»ï¼Œå‘ç°æ›´å¼ºçš„æ¨¡å‹ä½œä¸ºæ”»å‡»è€…æ›´æœ‰æ•ˆï¼Œä¸”å½“ç›®æ ‡æ¨¡å‹èƒ½åŠ›è¶…è¿‡æ”»å‡»è€…æ—¶ï¼Œæ”»å‡»æˆåŠŸç‡æ˜¾è‘—ä¸‹é™ã€‚åŸºäºè¿™äº›å‘ç°ï¼Œæå‡ºäº†ä¸€ç§è¶Šç‹±è§„æ¨¡æ³•åˆ™ï¼Œé¢„æµ‹å›ºå®šç›®æ ‡çš„æ”»å‡»æˆåŠŸç‡ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œå›ºå®šèƒ½åŠ›çš„æ”»å‡»è€…ï¼ˆå¦‚äººç±»ï¼‰å¯èƒ½åœ¨æœªæ¥æ¨¡å‹é¢å‰å˜å¾—æ— æ•ˆï¼Œä¸”å¼€æ”¾æºä»£ç æ¨¡å‹çš„èƒ½åŠ›æå‡åŠ å¤§äº†ç°æœ‰ç³»ç»Ÿçš„é£é™©ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹çº¢é˜Ÿæµ‹è¯•ä¸­ï¼Œæ”»å‡»è€…ä¸ç›®æ ‡æ¨¡å‹èƒ½åŠ›å·®è·å¯¼è‡´çš„æµ‹è¯•æ•ˆæœä¸ä½³é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨é¢å¯¹èƒ½åŠ›å¼ºå¤§çš„ç›®æ ‡æ—¶ï¼Œæ— æ³•æœ‰æ•ˆè¯†åˆ«å…¶è„†å¼±æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡åˆ†ææ”»å‡»è€…ä¸ç›®æ ‡æ¨¡å‹ä¹‹é—´çš„èƒ½åŠ›å·®è·ï¼Œæå‡ºä¸€ç§æ–°çš„çº¢é˜Ÿæµ‹è¯•æ¡†æ¶ï¼Œä»¥è¯„ä¼°ä¸åŒèƒ½åŠ›æ¨¡å‹çš„æ”»å‡»æ•ˆæœã€‚è¿™ç§è®¾è®¡æ—¨åœ¨æ›´å‡†ç¡®åœ°åæ˜ ç°å®åœºæ™¯ä¸­çš„èƒ½åŠ›å¯¹æŠ—ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šèƒ½åŠ›è¯„ä¼°æ¨¡å—ã€æ”»å‡»ç­–ç•¥ç”Ÿæˆæ¨¡å—å’Œæ”»å‡»æ•ˆæœè¯„ä¼°æ¨¡å—ã€‚é¦–å…ˆè¯„ä¼°æ”»å‡»è€…å’Œç›®æ ‡çš„èƒ½åŠ›ï¼Œç„¶åç”Ÿæˆç›¸åº”çš„æ”»å‡»ç­–ç•¥ï¼Œæœ€åè¯„ä¼°æ”»å‡»çš„æˆåŠŸç‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæå‡ºçš„è¶Šç‹±è§„æ¨¡æ³•åˆ™æ˜¯æœ¬æ–‡çš„æ ¸å¿ƒåˆ›æ–°ï¼Œèƒ½å¤Ÿæ ¹æ®æ”»å‡»è€…ä¸ç›®æ ‡æ¨¡å‹çš„èƒ½åŠ›å·®è·é¢„æµ‹æ”»å‡»æˆåŠŸç‡ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„æç¤ºå·¥ç¨‹æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ï¼Œå¼ºè°ƒèƒ½åŠ›å·®è·çš„é‡è¦æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œä½¿ç”¨äº†å¤šç§æ”»å‡»ç­–ç•¥ï¼Œå¹¶æ ¹æ®ä¸åŒæ¨¡å‹çš„èƒ½åŠ›è®¾ç½®äº†ç›¸åº”çš„å‚æ•°ã€‚æŸå¤±å‡½æ•°è®¾è®¡è€ƒè™‘äº†æ”»å‡»æˆåŠŸç‡ä¸æ¨¡å‹èƒ½åŠ›çš„å…³ç³»ï¼Œç¡®ä¿äº†å®éªŒç»“æœçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ”»å‡»è€…èƒ½åŠ›è¶Šå¼ºï¼Œæ”»å‡»æˆåŠŸç‡æ˜¾è‘—æé«˜ï¼Œå°¤å…¶å½“ç›®æ ‡æ¨¡å‹èƒ½åŠ›è¶…è¿‡æ”»å‡»è€…æ—¶ï¼ŒæˆåŠŸç‡æ€¥å‰§ä¸‹é™ã€‚é€šè¿‡å¯¹500å¤šä¸ªæ”»å‡»è€…-ç›®æ ‡å¯¹çš„è¯„ä¼°ï¼Œå‘ç°æ”»å‡»æˆåŠŸç‡ä¸MMLU-ProåŸºå‡†çš„ç¤¾ç§‘é¢†åŸŸè¡¨ç°é«˜åº¦ç›¸å…³ï¼Œæä¾›äº†æ–°çš„çº¢é˜Ÿæµ‹è¯•è§†è§’ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤§å‹è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ€§è¯„ä¼°ã€æ¨¡å‹å¼€å‘è¿‡ç¨‹ä¸­çš„è„†å¼±æ€§è¯†åˆ«ä»¥åŠé’ˆå¯¹æœªæ¥æ¨¡å‹çš„çº¢é˜Ÿæµ‹è¯•ç­–ç•¥ä¼˜åŒ–ã€‚é€šè¿‡å‡†ç¡®æµ‹é‡å’Œæ§åˆ¶æ¨¡å‹çš„è¯´æœå’Œæ“æ§èƒ½åŠ›ï¼Œå¯ä»¥æœ‰æ•ˆé™ä½å…¶ä½œä¸ºæ”»å‡»è€…çš„é£é™©ï¼Œç¡®ä¿å®‰å…¨éƒ¨ç½²ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> As large language models grow in capability and agency, identifying vulnerabilities through red-teaming becomes vital for safe deployment. However, traditional prompt-engineering approaches may prove ineffective once red-teaming turns into a weak-to-strong problem, where target models surpass red-teamers in capabilities. To study this shift, we frame red-teaming through the lens of the capability gap between attacker and target. We evaluate more than 500 attacker-target pairs using LLM-based jailbreak attacks that mimic human red-teamers across diverse families, sizes, and capability levels. Three strong trends emerge: (i) more capable models are better attackers, (ii) attack success drops sharply once the target's capability exceeds the attacker's, and (iii) attack success rates correlate with high performance on social science splits of the MMLU-Pro benchmark. From these trends, we derive a jailbreaking scaling law that predicts attack success for a fixed target based on attacker-target capability gap. These findings suggest that fixed-capability attackers (e.g., humans) may become ineffective against future models, increasingly capable open-source models amplify risks for existing systems, and model providers must accurately measure and control models' persuasive and manipulative abilities to limit their effectiveness as attackers.

