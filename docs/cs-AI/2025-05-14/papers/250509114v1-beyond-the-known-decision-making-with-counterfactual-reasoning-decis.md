---
layout: default
title: Beyond the Known: Decision Making with Counterfactual Reasoning Decision Transformer
---

# Beyond the Known: Decision Making with Counterfactual Reasoning Decision Transformer

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.09114" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.09114v1</a>
  <a href="https://arxiv.org/pdf/2505.09114.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.09114v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.09114v1', 'Beyond the Known: Decision Making with Counterfactual Reasoning Decision Transformer')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Minh Hoang Nguyen, Linh Le Pham Van, Thommen George Karimpanal, Sunil Gupta, Hung Le

**åˆ†ç±»**: cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-14

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåäº‹å®æ¨ç†å†³ç­–å˜æ¢å™¨ä»¥è§£å†³ç¦»çº¿æ•°æ®ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `åäº‹å®æ¨ç†` `å†³ç­–å˜æ¢å™¨` `å¼ºåŒ–å­¦ä¹ ` `ç¦»çº¿å­¦ä¹ ` `æ•°æ®ç¨€ç¼º` `æ™ºèƒ½ä½“å†³ç­–` `æ€§èƒ½æå‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å†³ç­–å˜æ¢å™¨åœ¨å¤„ç†ç¦»çº¿æ•°æ®æ—¶å¯¹æ•°æ®è´¨é‡è¦æ±‚é«˜ï¼Œç¼ºä¹è¶³å¤Ÿçš„è®­ç»ƒæ•°æ®å’Œæœ€ä¼˜è¡Œä¸ºä¼šå½±å“æ€§èƒ½ã€‚
2. æœ¬æ–‡æå‡ºçš„åäº‹å®æ¨ç†å†³ç­–å˜æ¢å™¨é€šè¿‡ç”Ÿæˆåäº‹å®ç»éªŒï¼Œå¢å¼ºäº†å†³ç­–å˜æ¢å™¨åœ¨æœªçŸ¥åœºæ™¯ä¸­çš„æ¨ç†èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCRDTåœ¨æ•°æ®æœ‰é™å’ŒåŠ¨æ€å˜åŒ–çš„åœºæ™¯ä¸­è¡¨ç°ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå±•ç°å‡ºæ›´å¼ºçš„å†³ç­–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å†³ç­–å˜æ¢å™¨ï¼ˆDTï¼‰åœ¨ç°ä»£å¼ºåŒ–å­¦ä¹ ä¸­å‘æŒ¥ç€é‡è¦ä½œç”¨ï¼Œåˆ©ç”¨ç¦»çº¿æ•°æ®é›†åœ¨å¤šä¸ªé¢†åŸŸå–å¾—äº†æ˜¾è‘—æˆæœã€‚ç„¶è€Œï¼ŒDTå¯¹é«˜è´¨é‡ã€å…¨é¢çš„æ•°æ®ä¾èµ–æ€§å¼ºï¼Œç°å®åº”ç”¨ä¸­è®­ç»ƒæ•°æ®ä¸è¶³å’Œæœ€ä¼˜è¡Œä¸ºç¨€ç¼ºä½¿å¾—åœ¨ç¦»çº¿æ•°æ®é›†ä¸Šè®­ç»ƒå˜å¾—å›°éš¾ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†åäº‹å®æ¨ç†å†³ç­–å˜æ¢å™¨ï¼ˆCRDTï¼‰ï¼Œè¿™ä¸€æ–°é¢–æ¡†æ¶é€šè¿‡ç”Ÿæˆå’Œåˆ©ç”¨åäº‹å®ç»éªŒï¼Œå¢å¼ºäº†DTåœ¨æœªçŸ¥åœºæ™¯ä¸­çš„æ¨ç†èƒ½åŠ›ï¼Œä»è€Œæ”¹å–„å†³ç­–æ•ˆæœã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCRDTåœ¨Atariå’ŒD4RLåŸºå‡†æµ‹è¯•ä¸­ä¼˜äºä¼ ç»ŸDTæ–¹æ³•ï¼Œä¸”æ— éœ€æ¶æ„ä¿®æ”¹å³å¯å®ç°æ¬¡ä¼˜è½¨è¿¹çš„ç»“åˆèƒ½åŠ›ã€‚è¿™äº›ç»“æœçªæ˜¾äº†åäº‹å®æ¨ç†åœ¨æå‡å¼ºåŒ–å­¦ä¹ ä»£ç†æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›æ–¹é¢çš„æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å†³ç­–å˜æ¢å™¨åœ¨ç¦»çº¿æ•°æ®è®­ç»ƒä¸­å¯¹é«˜è´¨é‡æ•°æ®çš„ä¾èµ–é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨æ•°æ®ç¨€ç¼ºå’Œè¡Œä¸ºæ¬¡ä¼˜çš„æƒ…å†µä¸‹ï¼Œç°æœ‰æ–¹æ³•çš„æ€§èƒ½å—åˆ°é™åˆ¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šåäº‹å®æ¨ç†å†³ç­–å˜æ¢å™¨é€šè¿‡ç”Ÿæˆå’Œåˆ©ç”¨åäº‹å®ç»éªŒï¼Œå…è®¸æ¨¡å‹åœ¨å·²çŸ¥æ•°æ®ä¹‹å¤–è¿›è¡Œæ¨ç†ï¼Œä»è€Œæå‡å†³ç­–èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨æœªè§åœºæ™¯ä¸­ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCRDTçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®ç”Ÿæˆæ¨¡å—ã€åäº‹å®æ¨ç†æ¨¡å—å’Œå†³ç­–æ¨¡å—ã€‚æ•°æ®ç”Ÿæˆæ¨¡å—è´Ÿè´£åˆ›å»ºåäº‹å®ç»éªŒï¼Œåäº‹å®æ¨ç†æ¨¡å—ç”¨äºåˆ†æè¿™äº›ç»éªŒï¼Œè€Œå†³ç­–æ¨¡å—åˆ™åŸºäºåˆ†æç»“æœåšå‡ºå†³ç­–ã€‚

**å…³é”®åˆ›æ–°**ï¼šCRDTçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå¼•å…¥åäº‹å®æ¨ç†ï¼Œä½¿å¾—å†³ç­–å˜æ¢å™¨èƒ½å¤Ÿåœ¨æ²¡æœ‰æ¶æ„ä¿®æ”¹çš„æƒ…å†µä¸‹ï¼Œç»“åˆæ¬¡ä¼˜è½¨è¿¹ï¼Œä»è€Œæå‡å†³ç­–çš„çµæ´»æ€§å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒCRDTé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–åäº‹å®ç»éªŒçš„ç”Ÿæˆï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šä¿æŒä¸ä¼ ç»ŸDTä¸€è‡´ï¼Œä»¥ä¾¿äºç›´æ¥æ¯”è¾ƒå’ŒéªŒè¯æ€§èƒ½æå‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒCRDTåœ¨Atariå’ŒD4RLåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºä¼ ç»Ÿå†³ç­–å˜æ¢å™¨ï¼Œå°¤å…¶åœ¨æ•°æ®æœ‰é™å’ŒåŠ¨æ€å˜åŒ–çš„æƒ…å†µä¸‹ï¼Œæ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šã€‚è¿™ä¸€ç»“æœéªŒè¯äº†åäº‹å®æ¨ç†åœ¨å¼ºåŒ–å­¦ä¹ ä¸­çš„æœ‰æ•ˆæ€§å’Œé‡è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæ§åˆ¶ã€è‡ªåŠ¨é©¾é©¶ã€æ¸¸æˆæ™ºèƒ½ä½“ç­‰ï¼Œå°¤å…¶æ˜¯åœ¨æ•°æ®è·å–å›°éš¾æˆ–æˆæœ¬é«˜æ˜‚çš„åœºæ™¯ä¸­ï¼ŒCRDTèƒ½å¤Ÿæœ‰æ•ˆæå‡å†³ç­–è´¨é‡ã€‚æœªæ¥ï¼Œéšç€åäº‹å®æ¨ç†æŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ï¼Œå¯èƒ½ä¼šåœ¨æ›´å¤šå¤æ‚ç³»ç»Ÿä¸­å¾—åˆ°åº”ç”¨ï¼Œæ¨åŠ¨æ™ºèƒ½ä½“çš„è‡ªä¸»å­¦ä¹ å’Œé€‚åº”èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Decision Transformers (DT) play a crucial role in modern reinforcement learning, leveraging offline datasets to achieve impressive results across various domains. However, DT requires high-quality, comprehensive data to perform optimally. In real-world applications, the lack of training data and the scarcity of optimal behaviours make training on offline datasets challenging, as suboptimal data can hinder performance. To address this, we propose the Counterfactual Reasoning Decision Transformer (CRDT), a novel framework inspired by counterfactual reasoning. CRDT enhances DT ability to reason beyond known data by generating and utilizing counterfactual experiences, enabling improved decision-making in unseen scenarios. Experiments across Atari and D4RL benchmarks, including scenarios with limited data and altered dynamics, demonstrate that CRDT outperforms conventional DT approaches. Additionally, reasoning counterfactually allows the DT agent to obtain stitching abilities, combining suboptimal trajectories, without architectural modifications. These results highlight the potential of counterfactual reasoning to enhance reinforcement learning agents' performance and generalization capabilities.

