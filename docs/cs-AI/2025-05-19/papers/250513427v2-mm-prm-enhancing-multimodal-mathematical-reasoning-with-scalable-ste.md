---
layout: default
title: MM-PRM: Enhancing Multimodal Mathematical Reasoning with Scalable Step-Level Supervision
---

# MM-PRM: Enhancing Multimodal Mathematical Reasoning with Scalable Step-Level Supervision

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.13427" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.13427v2</a>
  <a href="https://arxiv.org/pdf/2505.13427.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.13427v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.13427v2', 'MM-PRM: Enhancing Multimodal Mathematical Reasoning with Scalable Step-Level Supervision')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Lingxiao Du, Fanqing Meng, Zongkai Liu, Zhixiang Zhou, Ping Luo, Qiaosheng Zhang, Wenqi Shao

**åˆ†ç±»**: cs.AI, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-19 (æ›´æ–°: 2025-06-05)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/ModalMinds/MM-PRM)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMM-PRMä»¥è§£å†³å¤šæ¨¡æ€æ•°å­¦æ¨ç†ä¸­çš„æ­¥éª¤ç›‘ç£ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ¨ç†` `æ•°å­¦é—®é¢˜æ±‚è§£` `è¿‡ç¨‹å¥–åŠ±æ¨¡å‹` `è‡ªåŠ¨åŒ–ç›‘ç£` `è’™ç‰¹å¡æ´›æ ‘æœç´¢` `é€»è¾‘ä¸€è‡´æ€§` `æ•™è‚²æŠ€æœ¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚çš„å¤šæ­¥éª¤æ¨ç†ä¸­è¡¨ç°ä¸ä½³ï¼Œå¸¸å¸¸å¯¼è‡´é€»è¾‘ä¸ä¸€è‡´çš„ç»“æœã€‚
2. æœ¬æ–‡æå‡ºMM-PRMï¼Œé€šè¿‡æ„å»ºè¿‡ç¨‹å¥–åŠ±æ¨¡å‹å’ŒMM-K12æ•°æ®é›†ï¼Œæä¾›ç»†ç²’åº¦çš„æ­¥éª¤çº§ç›‘ç£æ¥æå‡æ¨ç†èƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒMM-PRMåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æé«˜äº†æ¨ç†çš„å‡†ç¡®æ€§å’Œé€»è¾‘ä¸€è‡´æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨è§†è§‰-è¯­è¨€ç†è§£æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†åœ¨å¤æ‚çš„å¤šæ­¥éª¤æ¨ç†ä¸­ä»ç„¶å­˜åœ¨å›°éš¾ï¼Œå¸¸å¸¸äº§ç”Ÿé€»è¾‘ä¸ä¸€è‡´æˆ–éƒ¨åˆ†æ­£ç¡®çš„è§£å†³æ–¹æ¡ˆã€‚å…³é”®çš„é™åˆ¶åœ¨äºç¼ºä¹å¯¹ä¸­é—´æ¨ç†æ­¥éª¤çš„ç»†ç²’åº¦ç›‘ç£ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†MM-PRMï¼Œä¸€ä¸ªåœ¨å®Œå…¨è‡ªåŠ¨åŒ–ã€å¯æ‰©å±•æ¡†æ¶å†…è®­ç»ƒçš„è¿‡ç¨‹å¥–åŠ±æ¨¡å‹ã€‚æˆ‘ä»¬é¦–å…ˆæ„å»ºäº†MM-Policyï¼Œä¸€ä¸ªåœ¨å¤šæ ·åŒ–æ•°å­¦æ¨ç†æ•°æ®ä¸Šè®­ç»ƒçš„å¼ºå¤šæ¨¡æ€æ¨¡å‹ã€‚ç„¶åï¼Œæˆ‘ä»¬æ„å»ºäº†MM-K12ï¼Œä¸€ä¸ªåŒ…å«10,000ä¸ªå¯éªŒè¯ç­”æ¡ˆçš„å¤šæ¨¡æ€æ•°å­¦é—®é¢˜çš„ç²¾é€‰æ•°æ®é›†ï¼Œä½œä¸ºç§å­æ•°æ®ã€‚é€šè¿‡åŸºäºè’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰çš„ç®¡é“ï¼Œæˆ‘ä»¬ç”Ÿæˆäº†è¶…è¿‡70ä¸‡ä¸ªæ­¥éª¤çº§æ³¨é‡Šï¼Œæ— éœ€äººå·¥æ ‡æ³¨ã€‚æœ€ç»ˆçš„PRMç”¨äºåœ¨æœ€ä½³æ¨ç†è®¾ç½®ä¸­å¯¹å€™é€‰æ¨ç†è·¯å¾„è¿›è¡Œè¯„åˆ†ï¼Œå¹¶åœ¨é¢†åŸŸå†…ï¼ˆMM-K12æµ‹è¯•é›†ï¼‰å’Œé¢†åŸŸå¤–ï¼ˆOlympiadBenchã€MathVistaç­‰ï¼‰åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€æ•°å­¦æ¨ç†ä¸­ç¼ºä¹ç»†ç²’åº¦ç›‘ç£çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚æ¨ç†æ—¶å¸¸å¸¸äº§ç”Ÿä¸ä¸€è‡´çš„ç»“æœã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMM-PRMé€šè¿‡å¼•å…¥è¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆPRMï¼‰æ¥æä¾›å¯¹æ¨ç†æ­¥éª¤çš„ç›‘ç£ï¼Œåˆ©ç”¨è‡ªåŠ¨åŒ–ç”Ÿæˆçš„æ­¥éª¤çº§æ³¨é‡Šæ¥æå‡æ¨ç†çš„å‡†ç¡®æ€§å’Œé€»è¾‘æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬MM-Policyæ¨¡å‹çš„æ„å»ºã€MM-K12æ•°æ®é›†çš„åˆ›å»ºï¼Œä»¥åŠåŸºäºè’™ç‰¹å¡æ´›æ ‘æœç´¢çš„æ³¨é‡Šç”Ÿæˆç®¡é“ï¼Œæœ€ç»ˆé€šè¿‡PRMå¯¹æ¨ç†è·¯å¾„è¿›è¡Œè¯„åˆ†ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºé€šè¿‡è‡ªåŠ¨åŒ–ç”Ÿæˆæ­¥éª¤çº§æ³¨é‡Šï¼Œè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•ä¾èµ–äººå·¥æ ‡æ³¨çš„ç“¶é¢ˆï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨äº†è½¯æ ‡ç­¾ã€å°å­¦ä¹ ç‡å’Œè·¯å¾„å¤šæ ·æ€§ç­‰è®¾è®¡ï¼Œä¼˜åŒ–äº†PRMçš„æ€§èƒ½ï¼Œç¡®ä¿äº†æ¨ç†è¿‡ç¨‹çš„é€»è¾‘ä¸€è‡´æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMM-PRMåœ¨MM-K12æµ‹è¯•é›†ä¸Šå–å¾—äº†æ˜¾è‘—æå‡ï¼Œç›¸è¾ƒäºåŸºçº¿æ¨¡å‹ï¼Œæ¨ç†å‡†ç¡®ç‡æé«˜äº†XX%ã€‚åœ¨é¢†åŸŸå¤–åŸºå‡†æµ‹è¯•ï¼ˆå¦‚OlympiadBenchå’ŒMathVistaï¼‰ä¸­ä¹Ÿè¡¨ç°å‡ºè‰²ï¼ŒéªŒè¯äº†æ¨¡å‹çš„å¹¿æ³›é€‚ç”¨æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²æŠ€æœ¯ã€æ™ºèƒ½è¾…å¯¼ç³»ç»Ÿå’Œè‡ªåŠ¨åŒ–æ•°å­¦é—®é¢˜æ±‚è§£ç­‰ã€‚é€šè¿‡æå‡å¤šæ¨¡æ€æ¨ç†ç³»ç»Ÿçš„é€»è¾‘é²æ£’æ€§ï¼ŒMM-PRMèƒ½å¤Ÿåœ¨å®é™…åº”ç”¨ä¸­æä¾›æ›´å‡†ç¡®çš„è§£ç­”ï¼Œå¸®åŠ©å­¦ç”Ÿå’Œæ•™è‚²å·¥ä½œè€…æ›´æœ‰æ•ˆåœ°è§£å†³æ•°å­¦é—®é¢˜ï¼Œæœªæ¥å¯èƒ½å¯¹æ•™è‚²é¢†åŸŸäº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While Multimodal Large Language Models (MLLMs) have achieved impressive progress in vision-language understanding, they still struggle with complex multi-step reasoning, often producing logically inconsistent or partially correct solutions. A key limitation lies in the lack of fine-grained supervision over intermediate reasoning steps. To address this, we propose MM-PRM, a process reward model trained within a fully automated, scalable framework. We first build MM-Policy, a strong multimodal model trained on diverse mathematical reasoning data. Then, we construct MM-K12, a curated dataset of 10,000 multimodal math problems with verifiable answers, which serves as seed data. Leveraging a Monte Carlo Tree Search (MCTS)-based pipeline, we generate over 700k step-level annotations without human labeling. The resulting PRM is used to score candidate reasoning paths in the Best-of-N inference setup and achieves significant improvements across both in-domain (MM-K12 test set) and out-of-domain (OlympiadBench, MathVista, etc.) benchmarks. Further analysis confirms the effectiveness of soft labels, smaller learning rates, and path diversity in optimizing PRM performance. MM-PRM demonstrates that process supervision is a powerful tool for enhancing the logical robustness of multimodal reasoning systems. We release all our codes and data at https://github.com/ModalMinds/MM-PRM.

