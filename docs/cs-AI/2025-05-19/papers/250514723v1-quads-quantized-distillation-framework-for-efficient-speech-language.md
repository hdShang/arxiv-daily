---
layout: default
title: QUADS: QUAntized Distillation Framework for Efficient Speech Language Understanding
---

# QUADS: QUAntized Distillation Framework for Efficient Speech Language Understanding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14723" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14723v1</a>
  <a href="https://arxiv.org/pdf/2505.14723.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14723v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14723v1', 'QUADS: QUAntized Distillation Framework for Efficient Speech Language Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Subrata Biswas, Mohammad Nur Hossain Khan, Bashima Islam

**åˆ†ç±»**: eess.AS, cs.AI, cs.CL, cs.LG, cs.SD

**å‘å¸ƒæ—¥æœŸ**: 2025-05-19

**æœŸåˆŠ**: INTERSPEECH, 2025

**DOI**: [10.21437/Interspeech.2025-532](https://doi.org/10.21437/Interspeech.2025-532)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºQUADSæ¡†æ¶ä»¥è§£å†³èµ„æºå—é™ç¯å¢ƒä¸‹çš„è¯­éŸ³è¯­è¨€ç†è§£é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è¯­éŸ³è¯­è¨€ç†è§£` `è’¸é¦è®­ç»ƒ` `é‡åŒ–ä¼˜åŒ–` `æ¨¡å‹å‹ç¼©` `èµ„æºå—é™ç¯å¢ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è’¸é¦å’Œé‡åŒ–æ–¹æ³•åˆ†åˆ«å¤„ç†ï¼Œå¯¼è‡´åœ¨å‹ç¼©æ€§èƒ½ä¸Šå­˜åœ¨ä¸è¶³ï¼Œæ— æ³•æœ‰æ•ˆç»“åˆä¸¤è€…çš„ä¼˜åŠ¿ã€‚
2. QUADSæ¡†æ¶é€šè¿‡å¤šé˜¶æ®µè®­ç»ƒå’Œé¢„è°ƒæ¨¡å‹çš„ç»“åˆï¼Œç»Ÿä¸€ä¼˜åŒ–è’¸é¦å’Œé‡åŒ–ï¼Œæå‡äº†æ¨¡å‹åœ¨ä½æ¯”ç‰¹ç‡ä¸‹çš„é€‚åº”æ€§ã€‚
3. QUADSåœ¨SLURPå’ŒFSCæ•°æ®é›†ä¸Šåˆ†åˆ«å–å¾—äº†71.13%å’Œ99.20%çš„å‡†ç¡®ç‡ï¼Œä¸”è®¡ç®—å¤æ‚åº¦å’Œæ¨¡å‹å¤§å°æ˜¾è‘—é™ä½ï¼Œè¡¨ç°å‡ºè‰²ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¯­éŸ³è¯­è¨€ç†è§£ï¼ˆSLUï¼‰ç³»ç»Ÿå¿…é¡»åœ¨æ€§èƒ½å’Œæ•ˆç‡ä¹‹é—´å–å¾—å¹³è¡¡ï¼Œå°¤å…¶æ˜¯åœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­ã€‚ç°æœ‰æ–¹æ³•åˆ†åˆ«åº”ç”¨è’¸é¦å’Œé‡åŒ–ï¼Œå¯¼è‡´å‹ç¼©æ•ˆæœä¸ä½³ï¼Œå› ä¸ºè’¸é¦å¿½ç•¥äº†é‡åŒ–çº¦æŸã€‚æˆ‘ä»¬æå‡ºäº†QUADSï¼Œä¸€ä¸ªç»Ÿä¸€æ¡†æ¶ï¼Œé€šè¿‡å¤šé˜¶æ®µè®­ç»ƒä¸é¢„è°ƒæ¨¡å‹ç›¸ç»“åˆï¼Œä¼˜åŒ–äº†è’¸é¦å’Œé‡åŒ–çš„è¿‡ç¨‹ï¼Œå¢å¼ºäº†å¯¹ä½æ¯”ç‰¹ç‡çš„é€‚åº”æ€§ï¼ŒåŒæ—¶ä¿æŒäº†å‡†ç¡®æ€§ã€‚QUADSåœ¨SLURPæ•°æ®é›†ä¸Šè¾¾åˆ°äº†71.13%çš„å‡†ç¡®ç‡ï¼Œåœ¨FSCæ•°æ®é›†ä¸Šè¾¾åˆ°äº†99.20%çš„å‡†ç¡®ç‡ï¼Œä¸æœ€å…ˆè¿›æ¨¡å‹ç›¸æ¯”ï¼Œä»…æœ‰æœ€å¤š5.56%çš„è½»å¾®ä¸‹é™ã€‚æ­¤å¤–ï¼Œå®ƒå°†è®¡ç®—å¤æ‚åº¦é™ä½äº†60è‡³73å€ï¼ˆGMACsï¼‰ï¼Œæ¨¡å‹å¤§å°å‡å°‘äº†83è‡³700å€ï¼Œå±•ç¤ºäº†åœ¨æç«¯é‡åŒ–ä¸‹çš„å¼ºå¤§é²æ£’æ€§ã€‚è¿™äº›ç»“æœç¡®ç«‹äº†QUADSä½œä¸ºç°å®ä¸–ç•Œèµ„æºå—é™SLUåº”ç”¨çš„é«˜æ•ˆè§£å†³æ–¹æ¡ˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰è¯­éŸ³è¯­è¨€ç†è§£ï¼ˆSLUï¼‰ç³»ç»Ÿåœ¨èµ„æºå—é™ç¯å¢ƒä¸‹çš„æ€§èƒ½ä¸æ•ˆç‡å¹³è¡¡é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨è’¸é¦å’Œé‡åŒ–è¿‡ç¨‹ä¸­æœªèƒ½æœ‰æ•ˆç»“åˆï¼Œå¯¼è‡´å‹ç¼©æ•ˆæœä¸ç†æƒ³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šQUADSæ¡†æ¶çš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡å¤šé˜¶æ®µè®­ç»ƒä¸é¢„è°ƒæ¨¡å‹çš„ç»“åˆï¼Œç»Ÿä¸€ä¼˜åŒ–è’¸é¦å’Œé‡åŒ–è¿‡ç¨‹ï¼Œä»è€Œåœ¨ä¿æŒå‡†ç¡®æ€§çš„åŒæ—¶å¢å¼ºæ¨¡å‹å¯¹ä½æ¯”ç‰¹ç‡çš„é€‚åº”æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šQUADSçš„æ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªè®­ç»ƒé˜¶æ®µï¼Œé¦–å…ˆä½¿ç”¨é¢„è°ƒæ¨¡å‹è¿›è¡Œåˆæ­¥è®­ç»ƒï¼Œç„¶ååœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œè’¸é¦å’Œé‡åŒ–çš„è”åˆä¼˜åŒ–ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ¨¡å‹é¢„è°ƒã€è’¸é¦è®­ç»ƒå’Œé‡åŒ–ä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šQUADSçš„ä¸»è¦åˆ›æ–°åœ¨äºå°†è’¸é¦ä¸é‡åŒ–è¿‡ç¨‹æ•´åˆä¸ºä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ï¼Œè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•ä¸­è’¸é¦ä¸é‡åŒ–ç›¸äº’ç‹¬ç«‹çš„é—®é¢˜ï¼Œä»è€Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„å‹ç¼©æ•ˆç‡å’Œæ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨QUADSä¸­ï¼Œå…³é”®è®¾è®¡åŒ…æ‹¬é€‰æ‹©åˆé€‚çš„æŸå¤±å‡½æ•°ä»¥å¹³è¡¡è’¸é¦å’Œé‡åŒ–ç›®æ ‡ï¼Œä»¥åŠåœ¨ç½‘ç»œç»“æ„ä¸­å¼•å…¥é€‚åº”ä½æ¯”ç‰¹ç‡çš„æ¨¡å—ï¼Œç¡®ä¿æ¨¡å‹åœ¨æç«¯é‡åŒ–æ¡ä»¶ä¸‹ä»èƒ½ä¿æŒè¾ƒé«˜çš„å‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

QUADSåœ¨SLURPæ•°æ®é›†ä¸Šå®ç°äº†71.13%çš„å‡†ç¡®ç‡ï¼Œåœ¨FSCæ•°æ®é›†ä¸Šè¾¾åˆ°äº†99.20%çš„å‡†ç¡®ç‡ï¼Œä¸”ä¸æœ€å…ˆè¿›æ¨¡å‹ç›¸æ¯”ï¼Œå‡†ç¡®ç‡ä»…ä¸‹é™æœ€å¤š5.56%ã€‚æ­¤å¤–ï¼ŒQUADSæ˜¾è‘—é™ä½äº†è®¡ç®—å¤æ‚åº¦60è‡³73å€ï¼Œæ¨¡å‹å¤§å°å‡å°‘83è‡³700å€ï¼Œå±•ç¤ºäº†åœ¨æç«¯é‡åŒ–ä¸‹çš„å¼ºå¤§é²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

QUADSæ¡†æ¶åœ¨èµ„æºå—é™çš„è¯­éŸ³è¯­è¨€ç†è§£åº”ç”¨ä¸­å…·æœ‰å¹¿æ³›çš„æ½œåœ¨åº”ç”¨ä»·å€¼ï¼Œå¦‚æ™ºèƒ½åŠ©æ‰‹ã€è¯­éŸ³è¯†åˆ«è®¾å¤‡å’Œç§»åŠ¨ç«¯åº”ç”¨ç­‰ã€‚é€šè¿‡æé«˜æ¨¡å‹çš„å‹ç¼©æ•ˆç‡å’Œæ€§èƒ½ï¼ŒQUADSèƒ½å¤Ÿåœ¨å®é™…åº”ç”¨ä¸­å®ç°æ›´å¿«çš„å“åº”é€Ÿåº¦å’Œæ›´ä½çš„èµ„æºæ¶ˆè€—ï¼Œæ¨åŠ¨SLUæŠ€æœ¯çš„æ™®åŠä¸å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Spoken Language Understanding (SLU) systems must balance performance and efficiency, particularly in resource-constrained environments. Existing methods apply distillation and quantization separately, leading to suboptimal compression as distillation ignores quantization constraints. We propose QUADS, a unified framework that optimizes both through multi-stage training with a pre-tuned model, enhancing adaptability to low-bit regimes while maintaining accuracy. QUADS achieves 71.13\% accuracy on SLURP and 99.20\% on FSC, with only minor degradations of up to 5.56\% compared to state-of-the-art models. Additionally, it reduces computational complexity by 60--73$\times$ (GMACs) and model size by 83--700$\times$, demonstrating strong robustness under extreme quantization. These results establish QUADS as a highly efficient solution for real-world, resource-constrained SLU applications.

