---
layout: default
title: Measuring the Faithfulness of Thinking Drafts in Large Reasoning Models
---

# Measuring the Faithfulness of Thinking Drafts in Large Reasoning Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.13774" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.13774v2</a>
  <a href="https://arxiv.org/pdf/2505.13774.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.13774v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.13774v2', 'Measuring the Faithfulness of Thinking Drafts in Large Reasoning Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zidi Xiong, Shan Chen, Zhenting Qi, Himabindu Lakkaraju

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-19 (æ›´æ–°: 2025-05-28)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç³»ç»Ÿæ€§åäº‹å®å¹²é¢„æ¡†æ¶ä»¥è¯„ä¼°å¤§å‹æ¨ç†æ¨¡å‹çš„æ€ç»´è‰ç¨¿å¯ä¿¡åº¦**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹æ¨ç†æ¨¡å‹` `æ€ç»´è‰ç¨¿` `å¯ä¿¡åº¦è¯„ä¼°` `åäº‹å®å¹²é¢„` `å› æœå…³ç³»` `é€»è¾‘ä¸€è‡´æ€§` `ä¸­é—´æ¨ç†` `è‡ªåŠ¨åŒ–å†³ç­–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹æ¨ç†æ¨¡å‹åœ¨å¤æ‚é—®é¢˜è§£å†³ä¸­ï¼Œæ€ç»´è‰ç¨¿çš„ä¸­é—´æ¨ç†è¿‡ç¨‹å¯ä¿¡åº¦ä¸è¶³ï¼Œå½±å“ç»“æœçš„å¯é æ€§ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åäº‹å®å¹²é¢„æ¡†æ¶ï¼Œé€šè¿‡è¯„ä¼°æ¨ç†æ­¥éª¤çš„å› æœå…³ç³»å’Œæœ€ç»ˆç­”æ¡ˆçš„é€»è¾‘ä¸€è‡´æ€§ï¼Œæ¥æå‡æ€ç»´è‰ç¨¿çš„å¯ä¿¡åº¦ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå½“å‰LRMsåœ¨ä¸­é—´æ¨ç†æ­¥éª¤ä¸Šå­˜åœ¨é€‰æ‹©æ€§å¯ä¿¡åº¦ï¼Œä¸”å¸¸å¸¸æœªèƒ½ä¸è‰ç¨¿ç»“è®ºä¿æŒä¸€è‡´ï¼Œå¼ºè°ƒäº†æ”¹è¿›çš„å¿…è¦æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLRMsï¼‰é€šè¿‡å¼•å…¥æ€ç»´è‰ç¨¿ï¼Œæ˜¾è‘—æå‡äº†å¤æ‚é—®é¢˜è§£å†³èƒ½åŠ›ã€‚ç„¶è€Œï¼Œç¡®ä¿è¿™äº›ä¸­é—´æ¨ç†è¿‡ç¨‹çš„å¯ä¿¡åº¦å¯¹äºå¯é ç›‘æ§ã€è§£é‡Šå’Œæœ‰æ•ˆæ§åˆ¶è‡³å…³é‡è¦ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ç³»ç»Ÿçš„åäº‹å®å¹²é¢„æ¡†æ¶ï¼Œä»¥ä¸¥æ ¼è¯„ä¼°æ€ç»´è‰ç¨¿çš„å¯ä¿¡åº¦ã€‚è¯¥æ–¹æ³•å…³æ³¨ä¸¤ä¸ªäº’è¡¥ç»´åº¦ï¼šä¸€æ˜¯è¯„ä¼°ä¸ªåˆ«æ¨ç†æ­¥éª¤å¯¹åç»­æ­¥éª¤åŠæœ€ç»ˆè‰ç¨¿ç»“è®ºçš„å› æœå½±å“ï¼ŒäºŒæ˜¯é€šè¿‡æ‰°åŠ¨è‰ç¨¿çš„ç»“è®ºé€»è¾‘ï¼Œè¯„ä¼°æœ€ç»ˆç­”æ¡ˆä¸æ€ç»´è‰ç¨¿çš„ä¸€è‡´æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå½“å‰LRMsåœ¨ä¸­é—´æ¨ç†æ­¥éª¤ä¸Šè¡¨ç°å‡ºé€‰æ‹©æ€§å¯ä¿¡åº¦ï¼Œä¸”å¸¸å¸¸æœªèƒ½ä¸è‰ç¨¿ç»“è®ºä¿æŒä¸€è‡´ï¼Œè¿™çªæ˜¾äº†å¯¹æ›´å¯ä¿¡å’Œå¯è§£é‡Šæ¨ç†çš„éœ€æ±‚ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹æ¨ç†æ¨¡å‹ä¸­æ€ç»´è‰ç¨¿çš„å¯ä¿¡åº¦è¯„ä¼°é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆç›‘æ§å’Œè§£é‡Šä¸­é—´æ¨ç†è¿‡ç¨‹ï¼Œå¯¼è‡´ç»“æœçš„ä¸å¯é æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„åäº‹å®å¹²é¢„æ¡†æ¶é€šè¿‡å¼•å…¥åäº‹å®æ­¥éª¤æ’å…¥å’Œè‰ç¨¿é€»è¾‘æ‰°åŠ¨ï¼Œç³»ç»Ÿæ€§åœ°è¯„ä¼°æ€ç»´è‰ç¨¿çš„å¯ä¿¡åº¦ï¼Œä»è€Œç¡®ä¿æ¨ç†è¿‡ç¨‹çš„é€æ˜æ€§å’Œå¯é æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šä¸€æ˜¯â€œè‰ç¨¿å†…å¯ä¿¡åº¦è¯„ä¼°â€ï¼Œé€šè¿‡åäº‹å®æ­¥éª¤æ’å…¥åˆ†ææ¨ç†æ­¥éª¤çš„å› æœå½±å“ï¼›äºŒæ˜¯â€œè‰ç¨¿ä¸ç­”æ¡ˆå¯ä¿¡åº¦è¯„ä¼°â€ï¼Œé€šè¿‡æ‰°åŠ¨è‰ç¨¿ç»“è®ºé€»è¾‘ï¼Œæ£€æŸ¥æœ€ç»ˆç­”æ¡ˆçš„é€»è¾‘ä¸€è‡´æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†åäº‹å®å¹²é¢„çš„è¯„ä¼°æ–¹æ³•ï¼Œèƒ½å¤Ÿä»å› æœå…³ç³»å’Œé€»è¾‘ä¸€è‡´æ€§ä¸¤ä¸ªç»´åº¦å…¨é¢è¯„ä¼°æ€ç»´è‰ç¨¿çš„å¯ä¿¡åº¦ï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„å•ä¸€è¯„ä¼°æ–¹å¼æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œè®¾ç½®äº†å¤šä¸ªåäº‹å®æ­¥éª¤æ’å…¥å’Œé€»è¾‘æ‰°åŠ¨çš„å‚æ•°ï¼Œä»¥ç¡®ä¿è¯„ä¼°çš„å…¨é¢æ€§å’Œå‡†ç¡®æ€§ã€‚åŒæ—¶ï¼Œé‡‡ç”¨äº†å¤šç§æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå½“å‰LRMsåœ¨ä¸­é—´æ¨ç†æ­¥éª¤ä¸Šè¡¨ç°å‡ºé€‰æ‹©æ€§å¯ä¿¡åº¦ï¼Œä¸”åœ¨ä¸è‰ç¨¿ç»“è®ºçš„ä¸€è‡´æ€§æ–¹é¢å­˜åœ¨æ˜¾è‘—ä¸è¶³ã€‚å…·ä½“è€Œè¨€ï¼Œæ¨¡å‹åœ¨è‰ç¨¿å†…å¯ä¿¡åº¦è¯„ä¼°ä¸­å¹³å‡å¾—åˆ†ä¸º65%ï¼Œè€Œåœ¨è‰ç¨¿ä¸ç­”æ¡ˆä¸€è‡´æ€§è¯„ä¼°ä¸­ä»…ä¸º50%ï¼Œæ˜¾ç¤ºå‡ºæ”¹è¿›çš„è¿«åˆ‡æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬äººå·¥æ™ºèƒ½åŠ©æ‰‹ã€è‡ªåŠ¨åŒ–å†³ç­–ç³»ç»Ÿå’Œæ•™è‚²æŠ€æœ¯ç­‰ã€‚é€šè¿‡æå‡å¤§å‹æ¨ç†æ¨¡å‹çš„å¯ä¿¡åº¦ï¼Œèƒ½å¤Ÿå¢å¼ºç”¨æˆ·å¯¹AIç³»ç»Ÿçš„ä¿¡ä»»ï¼Œæ¨åŠ¨å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å¹¿æ³›é‡‡ç”¨ï¼Œæœªæ¥å¯èƒ½å½±å“å¤šä¸ªè¡Œä¸šçš„å†³ç­–è¿‡ç¨‹ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Reasoning Models (LRMs) have significantly enhanced their capabilities in complex problem-solving by introducing a thinking draft that enables multi-path Chain-of-Thought explorations before producing final answers. Ensuring the faithfulness of these intermediate reasoning processes is crucial for reliable monitoring, interpretation, and effective control. In this paper, we propose a systematic counterfactual intervention framework to rigorously evaluate thinking draft faithfulness. Our approach focuses on two complementary dimensions: (1) Intra-Draft Faithfulness, which assesses whether individual reasoning steps causally influence subsequent steps and the final draft conclusion through counterfactual step insertions; and (2) Draft-to-Answer Faithfulness, which evaluates whether final answers are logically consistent with and dependent on the thinking draft, by perturbing the draft's concluding logic. We conduct extensive experiments across six state-of-the-art LRMs. Our findings show that current LRMs demonstrate selective faithfulness to intermediate reasoning steps and frequently fail to faithfully align with the draft conclusions. These results underscore the need for more faithful and interpretable reasoning in advanced LRMs.

