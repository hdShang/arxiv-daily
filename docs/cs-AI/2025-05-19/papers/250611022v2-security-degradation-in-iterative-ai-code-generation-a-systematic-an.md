---
layout: default
title: Security Degradation in Iterative AI Code Generation -- A Systematic Analysis of the Paradox
---

# Security Degradation in Iterative AI Code Generation -- A Systematic Analysis of the Paradox

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.11022" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.11022v2</a>
  <a href="https://arxiv.org/pdf/2506.11022.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.11022v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.11022v2', 'Security Degradation in Iterative AI Code Generation -- A Systematic Analysis of the Paradox')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shivani Shukla, Himanshu Joshi, Romilla Syed

**åˆ†ç±»**: cs.SE, cs.AI, cs.CL, cs.CR, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-19 (æ›´æ–°: 2025-09-26)

**å¤‡æ³¨**: Keywords - Large Language Models, Security Vulnerabilities, AI-Generated Code, Iterative Feedback, Software Security, Secure Coding Practices, Feedback Loops, LLM Prompting Strategies

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ†æè¿­ä»£AIä»£ç ç”Ÿæˆä¸­çš„å®‰å…¨é€€åŒ–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ä»£ç ç”Ÿæˆ` `å®‰å…¨æ¼æ´` `äººç±»éªŒè¯` `è¿­ä»£ä¼˜åŒ–` `è½¯ä»¶å¼€å‘` `å®éªŒåˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆè§£å†³è¿­ä»£ç”Ÿæˆä»£ç ä¸­çš„å®‰å…¨æ¼æ´æ¼”å˜ï¼Œå¯¼è‡´å®‰å…¨æ€§ä¸‹é™ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡æ§åˆ¶å®éªŒåˆ†æä¸åŒæç¤ºç­–ç•¥å¯¹ä»£ç å®‰å…¨æ€§çš„å½±å“ï¼Œæå‡ºäººç±»éªŒè¯çš„é‡è¦æ€§ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šå®éªŒç»“æœæ˜¾ç¤ºï¼Œç»è¿‡äº”æ¬¡è¿­ä»£åï¼Œå…³é”®æ¼æ´å¢åŠ äº†37.6%ï¼Œä¸åŒç­–ç•¥ä¸‹æ¼æ´æ¨¡å¼å„å¼‚ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä»£ç ç”Ÿæˆä¸­çš„å¿«é€Ÿåº”ç”¨ï¼Œè½¯ä»¶å¼€å‘å‘ç”Ÿäº†å˜é©ï¼Œä½†å¯¹å®‰å…¨æ¼æ´åœ¨è¿­ä»£åé¦ˆä¸­å¦‚ä½•æ¼”å˜çš„å…³æ³¨è¾ƒå°‘ã€‚æœ¬æ–‡é€šè¿‡å¯¹400ä¸ªä»£ç æ ·æœ¬è¿›è¡Œæ§åˆ¶å®éªŒï¼Œåˆ†æäº†AIç”Ÿæˆä»£ç ä¸­çš„å®‰å…¨é€€åŒ–ç°è±¡ã€‚ç ”ç©¶å‘ç°ï¼Œåœ¨ä»…ç»è¿‡äº”æ¬¡è¿­ä»£åï¼Œå…³é”®æ¼æ´å¢åŠ äº†37.6%ï¼Œä¸åŒæç¤ºç­–ç•¥ä¸‹å‡ºç°äº†æ˜æ˜¾çš„æ¼æ´æ¨¡å¼ã€‚è¿™ä¸€è¯æ®æŒ‘æˆ˜äº†è¿­ä»£LLMä¼˜åŒ–èƒ½æå‡ä»£ç å®‰å…¨æ€§çš„å‡è®¾ï¼Œå¼ºè°ƒäº†äººç±»ä¸“å®¶åœ¨è¿­ä»£è¿‡ç¨‹ä¸­çš„é‡è¦æ€§ã€‚æˆ‘ä»¬æå‡ºäº†å¼€å‘è€…åº”å¯¹è¿™äº›é£é™©çš„å®ç”¨æŒ‡å—ï¼Œå¼ºè°ƒåœ¨LLMè¿­ä»£ä¹‹é—´è¿›è¡Œå¼ºæœ‰åŠ›çš„äººç±»éªŒè¯ï¼Œä»¥é˜²æ­¢åœ¨æ‰€è°“çš„ä»£ç â€œæ”¹è¿›â€è¿‡ç¨‹ä¸­å¼•å…¥æ–°çš„å®‰å…¨é—®é¢˜ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿›è¡Œä»£ç ç”Ÿæˆæ—¶ï¼Œè¿­ä»£è¿‡ç¨‹ä¸­çš„å®‰å…¨æ¼æ´æ¼”å˜é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†è€ƒè™‘è¿­ä»£åé¦ˆå¯¹ä»£ç å®‰å…¨æ€§çš„å½±å“ï¼Œå¯¼è‡´æ½œåœ¨çš„å®‰å…¨é£é™©å¢åŠ ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡é€šè¿‡è®¾è®¡æ§åˆ¶å®éªŒï¼Œåˆ†æä¸åŒæç¤ºç­–ç•¥å¯¹ç”Ÿæˆä»£ç å®‰å…¨æ€§çš„å½±å“ï¼Œå¼ºè°ƒäººç±»ä¸“å®¶åœ¨è¿­ä»£è¿‡ç¨‹ä¸­çš„å¿…è¦æ€§ï¼Œä»¥å‡å°‘å®‰å…¨æ¼æ´çš„å¼•å…¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨äº†ä¸€ä¸ªåŒ…å«400ä¸ªä»£ç æ ·æœ¬çš„å®éªŒæ¡†æ¶ï¼Œåˆ†ä¸º40è½®è¿­ä»£ï¼Œæ¯è½®ä½¿ç”¨å››ç§ä¸åŒçš„æç¤ºç­–ç•¥ã€‚æ¯è½®è¿­ä»£åå¯¹ç”Ÿæˆä»£ç è¿›è¡Œå®‰å…¨æ€§è¯„ä¼°ï¼Œè§‚å¯Ÿæ¼æ´çš„å˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæ­ç¤ºäº†è¿­ä»£ä¼˜åŒ–è¿‡ç¨‹ä¸­å®‰å…¨æ¼æ´çš„å¢åŠ ï¼ŒæŒ‘æˆ˜äº†ä¼ ç»Ÿè§‚å¿µï¼Œå³è®¤ä¸ºè¿­ä»£è¿‡ç¨‹å¿…ç„¶ä¼šæå‡ä»£ç å®‰å…¨æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šå®éªŒä¸­è®¾ç½®äº†æ˜ç¡®çš„è¯„ä¼°æ ‡å‡†ï¼Œé‡‡ç”¨äº†å¤šç§æç¤ºç­–ç•¥ï¼Œå¹¶åœ¨æ¯æ¬¡è¿­ä»£åè¿›è¡Œç³»ç»Ÿçš„å®‰å…¨æ€§åˆ†æï¼Œä»¥ç¡®ä¿ç»“æœçš„å¯é æ€§å’Œæœ‰æ•ˆæ€§ã€‚å®éªŒè®¾è®¡çš„ä¸¥è°¨æ€§ä¸ºåç»­ç ”ç©¶æä¾›äº†åŸºç¡€ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ç»è¿‡äº”æ¬¡è¿­ä»£åï¼Œå…³é”®æ¼æ´çš„æ•°é‡å¢åŠ äº†37.6%ã€‚ä¸åŒçš„æç¤ºç­–ç•¥å¯¼è‡´äº†ä¸åŒçš„æ¼æ´æ¨¡å¼ï¼Œè¿™ä¸€å‘ç°å¯¹ä»£ç ç”Ÿæˆçš„å®‰å…¨æ€§æå‡ºäº†æ–°çš„æŒ‘æˆ˜ï¼Œå¼ºè°ƒäº†äººç±»éªŒè¯çš„é‡è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è½¯ä»¶å¼€å‘ã€ä»£ç å®¡æŸ¥å’Œå®‰å…¨æ€§è¯„ä¼°ç­‰ã€‚é€šè¿‡æå‡ºçš„å®ç”¨æŒ‡å—ï¼Œå¼€å‘è€…å¯ä»¥åœ¨ä½¿ç”¨LLMsè¿›è¡Œä»£ç ç”Ÿæˆæ—¶ï¼Œé‡‡å–æœ‰æ•ˆæªæ–½é™ä½å®‰å…¨é£é™©ï¼Œæå‡ä»£ç è´¨é‡ã€‚è¿™ä¸€ç ”ç©¶ä¸ºæœªæ¥çš„AIè¾…åŠ©å¼€å‘å·¥å…·æä¾›äº†é‡è¦çš„å®‰å…¨æ€§å‚è€ƒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The rapid adoption of Large Language Models(LLMs) for code generation has transformed software development, yet little attention has been given to how security vulnerabilities evolve through iterative LLM feedback. This paper analyzes security degradation in AI-generated code through a controlled experiment with 400 code samples across 40 rounds of "improvements" using four distinct prompting strategies. Our findings show a 37.6% increase in critical vulnerabilities after just five iterations, with distinct vulnerability patterns emerging across different prompting approaches. This evidence challenges the assumption that iterative LLM refinement improves code security and highlights the essential role of human expertise in the loop. We propose practical guidelines for developers to mitigate these risks, emphasizing the need for robust human validation between LLM iterations to prevent the paradoxical introduction of new security issues during supposedly beneficial code "improvements".

