---
layout: default
title: Applying Cognitive Design Patterns to General LLM Agents
---

# Applying Cognitive Design Patterns to General LLM Agents

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.07087" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.07087v2</a>
  <a href="https://arxiv.org/pdf/2505.07087.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.07087v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.07087v2', 'Applying Cognitive Design Patterns to General LLM Agents')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Robert E. Wray, James R. Kirk, John E. Laird

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-11 (æ›´æ–°: 2025-06-13)

**å¤‡æ³¨**: 10 pages + references, 2 figures, 3 tables. Accepted for oral presentation at AGI25

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè®¤çŸ¥è®¾è®¡æ¨¡å¼ä»¥æå‡é€šç”¨LLMæ™ºèƒ½ä»£ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è®¤çŸ¥è®¾è®¡æ¨¡å¼` `å¤§å‹è¯­è¨€æ¨¡å‹` `é€šç”¨æ™ºèƒ½` `æ™ºèƒ½ä»£ç†` `æ¨ç†èƒ½åŠ›` `äººæœºäº¤äº’` `æ€§èƒ½è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„AIå’ŒAGIç ”ç©¶åœ¨è¯†åˆ«é€šç”¨æ™ºèƒ½æœºåˆ¶æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨è®¤çŸ¥æ¶æ„çš„å¤šæ ·æ€§å’Œç‹¬ç«‹æ€§ä¸Šã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡è¯†åˆ«å’Œåº”ç”¨è®¤çŸ¥è®¾è®¡æ¨¡å¼ï¼Œæ¥æå‡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¨ç†å’Œäº¤äº’åœºæ™¯ä¸­çš„è¡¨ç°ã€‚
3. ç ”ç©¶è¡¨æ˜ï¼Œåº”ç”¨è¿™äº›æ¨¡å¼å¯ä»¥æœ‰æ•ˆè¯†åˆ«å½“å‰ç³»ç»Ÿçš„ç¼ºé™·ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›æ–°çš„è§†è§’ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬è®ºæ–‡æ—¨åœ¨è¯†åˆ«å’Œç†è§£å®ç°é€šç”¨æ™ºèƒ½æ‰€éœ€çš„ç‰¹å®šæœºåˆ¶å’Œè¡¨å¾ã€‚å°½ç®¡å·²æœ‰å¤šç§è®¤çŸ¥æ¶æ„è¢«æ¢ç´¢ï¼Œä½†ä¸åŒç ”ç©¶å›¢é˜Ÿç‹¬ç«‹è¯†åˆ«å‡ºç›¸ä¼¼çš„â€œè®¤çŸ¥è®¾è®¡æ¨¡å¼â€ã€‚å½“å‰ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„AIç³»ç»Ÿä¸ºæ¢ç´¢é€šç”¨æ™ºèƒ½æä¾›äº†æ–°çš„æœºåˆ¶ç»„åˆã€‚æœ¬æ–‡æ¦‚è¿°äº†åœ¨å¤šç§å‰å˜æ¢å™¨AIæ¶æ„ä¸­å‡ºç°çš„å‡ ç§é‡å¤è®¤çŸ¥è®¾è®¡æ¨¡å¼ï¼Œå¹¶æ¢è®¨äº†è¿™äº›æ¨¡å¼åœ¨LLMç³»ç»Ÿä¸­çš„ä½“ç°ï¼Œå°¤å…¶æ˜¯åœ¨æ¨ç†å’Œäº¤äº’åº”ç”¨åœºæ™¯ä¸­çš„åº”ç”¨ã€‚é€šè¿‡åˆ†æè¿™äº›æ¨¡å¼ï¼Œèƒ½å¤Ÿé¢„æµ‹å½“å‰ä»£ç†LLMç³»ç»Ÿçš„ä¸è¶³ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æŒ‡æ˜æ–¹å‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡è¦è§£å†³çš„å…·ä½“é—®é¢˜æ˜¯å¦‚ä½•è¯†åˆ«å’Œåº”ç”¨è®¤çŸ¥è®¾è®¡æ¨¡å¼ï¼Œä»¥æå‡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é€šç”¨æ™ºèƒ½ä¸­çš„è¡¨ç°ã€‚ç°æœ‰æ–¹æ³•åœ¨æ¨ç†å’Œäº¤äº’èƒ½åŠ›ä¸Šå­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥æ»¡è¶³å¤æ‚ä»»åŠ¡çš„éœ€æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒè§£å†³æ€è·¯æ˜¯é€šè¿‡åˆ†æä¸åŒAIæ¶æ„ä¸­çš„è®¤çŸ¥è®¾è®¡æ¨¡å¼ï¼Œæ¢è®¨å…¶åœ¨LLMç³»ç»Ÿä¸­çš„åº”ç”¨ï¼Œæ—¨åœ¨å¡«è¡¥å½“å‰æ™ºèƒ½ä»£ç†ç³»ç»Ÿçš„ç©ºç™½ã€‚è¿™æ ·çš„è®¾è®¡èƒ½å¤Ÿå¸®åŠ©ç ”ç©¶è€…ç†è§£å’Œæ”¹è¿›ç°æœ‰æ¨¡å‹çš„èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¯¹ç°æœ‰è®¤çŸ¥è®¾è®¡æ¨¡å¼çš„è¯†åˆ«ã€åˆ†æå’Œåº”ç”¨ï¼Œä¸»è¦æ¨¡å—åŒ…æ‹¬æ¨¡å¼è¯†åˆ«ã€æ¨¡å¼åº”ç”¨å’Œæ€§èƒ½è¯„ä¼°ã€‚é€šè¿‡è¿™äº›æ¨¡å—ï¼Œç ”ç©¶è€…å¯ä»¥ç³»ç»Ÿæ€§åœ°è¯„ä¼°LLMåœ¨ä¸åŒä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†è®¤çŸ¥è®¾è®¡æ¨¡å¼ç³»ç»ŸåŒ–ï¼Œå¹¶å°†å…¶åº”ç”¨äºLLMçš„æ¨ç†å’Œäº¤äº’åœºæ™¯ã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„åŒºåˆ«åœ¨äºï¼Œå‰è€…å¼ºè°ƒæ¨¡å¼çš„æ™®éæ€§å’Œé€‚ç”¨æ€§ï¼Œè€Œåè€…å¾€å¾€å±€é™äºç‰¹å®šä»»åŠ¡ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬å¯¹è®¤çŸ¥è®¾è®¡æ¨¡å¼çš„åˆ†ç±»ã€é€‰æ‹©åˆé€‚çš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–æ¨¡å‹æ€§èƒ½ï¼Œä»¥åŠåœ¨ç½‘ç»œç»“æ„ä¸­èå…¥è¿™äº›æ¨¡å¼çš„æœºåˆ¶ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†è®¨è®ºã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œåº”ç”¨è®¤çŸ¥è®¾è®¡æ¨¡å¼çš„LLMç³»ç»Ÿåœ¨æ¨ç†å’Œäº¤äº’ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œç›¸è¾ƒäºåŸºçº¿æ¨¡å‹ï¼Œå±•ç°å‡ºæ›´å¼ºçš„æ™ºèƒ½ä»£ç†èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½ä»£ç†ã€è‡ªç„¶è¯­è¨€å¤„ç†å’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡è¯†åˆ«å’Œåº”ç”¨è®¤çŸ¥è®¾è®¡æ¨¡å¼ï¼Œç ”ç©¶è€…å¯ä»¥æå‡LLMåœ¨å¤æ‚ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œæ¨åŠ¨é€šç”¨æ™ºèƒ½çš„å®ç°ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> One goal of AI (and AGI) is to identify and understand specific mechanisms and representations sufficient for general intelligence. Often, this work manifests in research focused on architectures and many cognitive architectures have been explored in AI/AGI. However, different research groups and even different research traditions have somewhat independently identified similar/common patterns of processes and representations or "cognitive design patterns" that are manifest in existing architectures. Today, AI systems exploiting large language models (LLMs) offer a relatively new combination of mechanisms and representations available for exploring the possibilities of general intelligence. This paper outlines a few recurring cognitive design patterns that have appeared in various pre-transformer AI architectures. We then explore how these patterns are evident in systems using LLMs, especially for reasoning and interactive ("agentic") use cases. Examining and applying these recurring patterns enables predictions of gaps or deficiencies in today's Agentic LLM Systems and identification of subjects of future research towards general intelligence using generative foundation models.

