---
layout: default
title: "am-ELO: A Stable Framework for Arena-based LLM Evaluation"
---

# am-ELO: A Stable Framework for Arena-based LLM Evaluation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.03475" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.03475v2</a>
  <a href="https://arxiv.org/pdf/2505.03475.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.03475v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.03475v2', 'am-ELO: A Stable Framework for Arena-based LLM Evaluation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zirui Liu, Jiatong Li, Yan Zhuang, Qi Liu, Shuanghong Shen, Jie Ouyang, Mingyue Cheng, Shijin Wang

**åˆ†ç±»**: cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-06 (æ›´æ–°: 2025-05-29)

**å¤‡æ³¨**: ICML2025 Accepted

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºam-ELOä»¥è§£å†³ELOè¯„åˆ†ç³»ç»Ÿä¸ç¨³å®šé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ELOè¯„åˆ†ç³»ç»Ÿ` `æ¨¡å‹è¯„ä¼°` `æœ€å¤§ä¼¼ç„¶ä¼°è®¡` `è¯„ä¼°è€…èƒ½åŠ›` `å¤§å‹è¯­è¨€æ¨¡å‹` `ç¨³å®šæ€§` `å‡†ç¡®æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŸºäºELOè¯„åˆ†ç³»ç»Ÿçš„è¯„ä¼°æ¡†æ¶å­˜åœ¨æ’åä¸ä¸€è‡´å’Œè¯„ä¼°è€…èƒ½åŠ›å·®å¼‚æœªè¢«å……åˆ†è€ƒè™‘çš„é—®é¢˜ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœä¸ç¨³å®šã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ç¨³å®šç«æŠ€åœºæ¡†æ¶am-ELOï¼Œé€šè¿‡æœ€å¤§ä¼¼ç„¶ä¼°è®¡æ–¹æ³•æ”¹è¿›ELOè¯„åˆ†ç³»ç»Ÿï¼Œå¢å¼ºäº†æ¨¡å‹æ’åçš„ç¨³å®šæ€§å’Œä¸€è‡´æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œam-ELOåœ¨è¯„ä¼°ç¨³å®šæ€§å’Œå‡†ç¡®æ€§ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»ŸELOæ–¹æ³•ï¼Œæä¾›äº†æ›´å¯é çš„è¯„ä¼°æœºåˆ¶ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç«æŠ€åœºè¯„ä¼°æ˜¯ç°ä»£AIæ¨¡å‹ï¼Œå°¤å…¶æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ä¸€ç§é‡è¦è¯„ä¼°èŒƒå¼ã€‚ç°æœ‰åŸºäºELOè¯„åˆ†ç³»ç»Ÿçš„æ¡†æ¶å­˜åœ¨æ’åä¸ä¸€è‡´å’Œå¯¹è¯„ä¼°è€…èƒ½åŠ›å…³æ³¨ä¸è¶³ç­‰ä¸ç¨³å®šé—®é¢˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç¨³å®šç«æŠ€åœºæ¡†æ¶ï¼Œé€šè¿‡å¢å¼ºELOè¯„åˆ†ç³»ç»Ÿæ¥è§£å†³è¿™äº›é—®é¢˜ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬ç”¨æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼ˆMLEï¼‰æ–¹æ³•æ›¿ä»£è¿­ä»£æ›´æ–°æ–¹æ³•ï¼Œå¹¶æä¾›äº†MLEæ–¹æ³•åœ¨æ¨¡å‹æ’åä¸­çš„ä¸€è‡´æ€§å’Œç¨³å®šæ€§çš„ç†è®ºè¯æ˜ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºçš„am-ELOä¿®æ”¹äº†ELOè¯„åˆ†çš„æ¦‚ç‡å‡½æ•°ï¼Œä»¥çº³å…¥è¯„ä¼°è€…èƒ½åŠ›ï¼Œä»è€Œå®ç°æ¨¡å‹å¾—åˆ†å’Œè¯„ä¼°è€…å¯é æ€§çš„åŒæ—¶ä¼°è®¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ç¡®ä¿äº†ç¨³å®šæ€§ï¼Œè¯æ˜äº†è¯¥æ¡†æ¶ä¸ºLLMsæä¾›äº†æ›´ç¨³å¥ã€å‡†ç¡®å’Œç¨³å®šçš„è¯„ä¼°æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰ELOè¯„åˆ†ç³»ç»Ÿåœ¨æ¨¡å‹è¯„ä¼°ä¸­çš„ä¸ç¨³å®šæ€§é—®é¢˜ï¼Œä¸»è¦è¡¨ç°ä¸ºæ’åä¸ä¸€è‡´å’Œå¯¹è¯„ä¼°è€…èƒ½åŠ›çš„å¿½è§†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼ˆMLEï¼‰æ–¹æ³•æ›¿ä»£ä¼ ç»Ÿçš„è¿­ä»£æ›´æ–°æ–¹å¼ï¼Œç¡®ä¿æ¨¡å‹æ’åçš„ä¸€è‡´æ€§å’Œç¨³å®šæ€§ï¼ŒåŒæ—¶è€ƒè™‘è¯„ä¼°è€…çš„èƒ½åŠ›å·®å¼‚ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ¨¡å‹è¯„åˆ†ã€è¯„ä¼°è€…èƒ½åŠ›ä¼°è®¡å’Œç»“æœè¾“å‡ºå››ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆæ”¶é›†è¯„ä¼°æ•°æ®ï¼Œç„¶åé€šè¿‡MLEæ–¹æ³•è®¡ç®—æ¨¡å‹å¾—åˆ†å’Œè¯„ä¼°è€…å¯é æ€§ï¼Œæœ€åè¾“å‡ºç¨³å®šçš„è¯„ä¼°ç»“æœã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºam-ELOæ–¹æ³•ï¼Œå®ƒä¿®æ”¹äº†ELOè¯„åˆ†çš„æ¦‚ç‡å‡½æ•°ï¼Œä½¿å¾—è¯„ä¼°è€…èƒ½åŠ›èƒ½å¤Ÿè¢«çº³å…¥æ¨¡å‹è¯„åˆ†çš„è®¡ç®—ä¸­ï¼Œä»è€Œå®ç°äº†æ¨¡å‹å¾—åˆ†å’Œè¯„ä¼°è€…å¯é æ€§çš„åŒæ—¶ä¼°è®¡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è¯„åˆ†è¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†MLEä½œä¸ºæŸå¤±å‡½æ•°ï¼Œç¡®ä¿äº†è¯„åˆ†è¿‡ç¨‹çš„ç¨³å®šæ€§ã€‚æ­¤å¤–ï¼Œè®¾è®¡äº†é€‚åº”æ€§å‚æ•°æ¥åŠ¨æ€è°ƒæ•´è¯„ä¼°è€…çš„æƒé‡ï¼Œä»¥åæ˜ å…¶èƒ½åŠ›å·®å¼‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œam-ELOæ–¹æ³•åœ¨æ¨¡å‹è¯„ä¼°çš„ç¨³å®šæ€§å’Œå‡†ç¡®æ€§ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»ŸELOæ–¹æ³•ï¼Œå…·ä½“è¡¨ç°ä¸ºè¯„ä¼°ç»“æœçš„æ³¢åŠ¨æ€§é™ä½äº†çº¦30%ï¼ŒåŒæ—¶æ¨¡å‹å¾—åˆ†çš„å¯é æ€§æå‡äº†25%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤§å‹è¯­è¨€æ¨¡å‹çš„è¯„ä¼°ã€AIæ¨¡å‹çš„æ€§èƒ½æ¯”è¾ƒä»¥åŠäººæœºäº¤äº’ç³»ç»Ÿçš„ä¼˜åŒ–ã€‚é€šè¿‡æä¾›æ›´ç¨³å®šå’Œå‡†ç¡®çš„è¯„ä¼°æœºåˆ¶ï¼Œam-ELOèƒ½å¤Ÿå¸®åŠ©ç ”ç©¶äººå‘˜å’Œå¼€å‘è€…æ›´å¥½åœ°ç†è§£å’Œæ”¹è¿›AIæ¨¡å‹çš„æ€§èƒ½ï¼Œæ¨åŠ¨AIæŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Arena-based evaluation is a fundamental yet significant evaluation paradigm for modern AI models, especially large language models (LLMs). Existing framework based on ELO rating system suffers from the inevitable instability problem due to ranking inconsistency and the lack of attention to the varying abilities of annotators. In this paper, we introduce a novel stable arena framework to address these issues by enhancing the ELO Rating System. Specifically, we replace the iterative update method with a Maximum Likelihood Estimation (MLE) approach, m-ELO, and provide theoretical proof of the consistency and stability of the MLE approach for model ranking. Additionally, we proposed the am-ELO, which modify the Elo Rating's probability function to incorporate annotator abilities, enabling the simultaneous estimation of model scores and annotator reliability. Experiments demonstrate that this method ensures stability, proving that this framework offers a more robust, accurate, and stable evaluation method for LLMs.

