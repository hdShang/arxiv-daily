---
layout: default
title: Mamba-Diffusion Model with Learnable Wavelet for Controllable Symbolic Music Generation
---

# Mamba-Diffusion Model with Learnable Wavelet for Controllable Symbolic Music Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.03314" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.03314v1</a>
  <a href="https://arxiv.org/pdf/2505.03314.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.03314v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.03314v1', 'Mamba-Diffusion Model with Learnable Wavelet for Controllable Symbolic Music Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jincheng Zhang, GyÃ¶rgy Fazekas, Charalampos Saitis

**åˆ†ç±»**: cs.SD, cs.AI, eess.AS

**å‘å¸ƒæ—¥æœŸ**: 2025-05-06

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/jinchengzhanggg/proffusion)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMamba-Diffusionæ¨¡å‹ä»¥è§£å†³ç¬¦å·éŸ³ä¹ç”Ÿæˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)**

**å…³é”®è¯**: `ç¬¦å·éŸ³ä¹ç”Ÿæˆ` `æ‰©æ•£æ¨¡å‹` `å°æ³¢å˜æ¢` `Transformer` `éŸ³ä¹åˆ›ä½œ` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ‰©æ•£æ¨¡å‹åœ¨ç¬¦å·éŸ³ä¹ç”Ÿæˆä¸­åº”ç”¨ä¸è¶³ï¼Œä¸»è¦å› ä¸ºç¬¦å·éŸ³ä¹çš„ç¦»æ•£è¡¨ç¤ºå½¢å¼ä¸æ ‡å‡†æ‰©æ•£æ¨¡å‹ä¸åŒ¹é…ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„æ‰©æ•£æ¨¡å‹ï¼Œåˆ©ç”¨Transformer-Mambaæ¨¡å—å’Œå¯å­¦ä¹ çš„å°æ³¢å˜æ¢æ¥ç”Ÿæˆç¬¦å·éŸ³ä¹ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨éŸ³ä¹è´¨é‡å’Œå¯æ§æ€§æ–¹é¢ä¼˜äºç°æœ‰å¼ºåŸºçº¿ï¼Œå±•ç°äº†æ˜¾è‘—çš„æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œæ‰©æ•£æ¨¡å‹åœ¨å›¾åƒåˆæˆä¸­çš„å¹¿æ³›åº”ç”¨å¼•å‘äº†å¯¹å…¶åœ¨å…¶ä»–é¢†åŸŸç”Ÿæˆä»»åŠ¡æ½œåŠ›çš„æ–°å…³æ³¨ã€‚ç„¶è€Œï¼Œç¬¦å·éŸ³ä¹ç”Ÿæˆçš„åº”ç”¨ä»ç„¶æœªè¢«å……åˆ†æ¢ç´¢ï¼Œå› ä¸ºç¬¦å·éŸ³ä¹é€šå¸¸ä»¥ç¦»æ•£äº‹ä»¶åºåˆ—è¡¨ç¤ºï¼Œè€Œæ ‡å‡†æ‰©æ•£æ¨¡å‹ä¸é€‚åˆå¤„ç†ç¦»æ•£æ•°æ®ã€‚æœ¬æ–‡å°†ç¬¦å·éŸ³ä¹è¡¨ç¤ºä¸ºç±»ä¼¼å›¾åƒçš„é’¢ç´å·è½´ï¼Œä»è€Œä¿ƒè¿›æ‰©æ•£æ¨¡å‹åœ¨ç¬¦å·éŸ³ä¹ç”Ÿæˆä¸­çš„åº”ç”¨ã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†ä¸€ç§æ–°å‹æ‰©æ•£æ¨¡å‹ï¼Œç»“åˆäº†æå‡ºçš„Transformer-Mambaæ¨¡å—å’Œå¯å­¦ä¹ çš„å°æ³¢å˜æ¢ã€‚é€šè¿‡æ— åˆ†ç±»å™¨å¼•å¯¼ç”Ÿæˆç›®æ ‡å’Œå¼¦çš„ç¬¦å·éŸ³ä¹ã€‚è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨éŸ³ä¹è´¨é‡å’Œå¯æ§æ€§æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œè¶…è¶Šäº†å¼ºåŸºçº¿çš„é’¢ç´å·è½´ç”Ÿæˆæ•ˆæœã€‚ä»£ç å¯åœ¨https://github.com/jinchengzhanggg/proffusionè·å–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç¬¦å·éŸ³ä¹ç”Ÿæˆä¸­çš„ç¦»æ•£æ•°æ®å¤„ç†é—®é¢˜ï¼Œç°æœ‰çš„æ‰©æ•£æ¨¡å‹æ— æ³•æœ‰æ•ˆå¤„ç†ç¬¦å·éŸ³ä¹çš„ç¦»æ•£äº‹ä»¶åºåˆ—ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å°†ç¬¦å·éŸ³ä¹è¡¨ç¤ºä¸ºå›¾åƒæ ·å¼çš„é’¢ç´å·è½´ï¼Œè®ºæ–‡è®¾è®¡äº†ä¸€ç§æ–°å‹æ‰©æ•£æ¨¡å‹ï¼Œä½¿å…¶èƒ½å¤Ÿé€‚åº”ç¬¦å·éŸ³ä¹çš„ç”Ÿæˆéœ€æ±‚ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬Transformer-Mambaæ¨¡å—å’Œå¯å­¦ä¹ çš„å°æ³¢å˜æ¢ï¼Œç»“åˆæ— åˆ†ç±»å™¨å¼•å¯¼ç”Ÿæˆç›®æ ‡å’Œå¼¦çš„éŸ³ä¹ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œç”Ÿæˆé˜¶æ®µã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†Transformer-Mambaæ¨¡å—å’Œå¯å­¦ä¹ çš„å°æ³¢å˜æ¢ï¼Œè¿™ä½¿å¾—æ‰©æ•£æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆå¤„ç†ç¬¦å·éŸ³ä¹çš„ç”Ÿæˆï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”å…·æœ‰æ›´å¥½çš„é€‚åº”æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–ç”Ÿæˆè´¨é‡ï¼Œå¹¶åœ¨ç½‘ç»œç»“æ„ä¸­å¼•å…¥äº†å¯å­¦ä¹ çš„å°æ³¢å˜æ¢ï¼Œä»¥å¢å¼ºæ¨¡å‹å¯¹éŸ³ä¹ç‰¹å¾çš„æ•æ‰èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒMamba-Diffusionæ¨¡å‹åœ¨éŸ³ä¹ç”Ÿæˆè´¨é‡å’Œå¯æ§æ€§æ–¹é¢æ˜¾è‘—ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œå…·ä½“æå‡å¹…åº¦æœªçŸ¥ï¼Œå±•ç¤ºäº†å…¶åœ¨é’¢ç´å·è½´ç”Ÿæˆä¸­çš„å¼ºå¤§èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬éŸ³ä¹åˆ›ä½œã€è‡ªåŠ¨ä½œæ›²å’ŒéŸ³ä¹æ•™è‚²ç­‰ã€‚é€šè¿‡æé«˜ç¬¦å·éŸ³ä¹ç”Ÿæˆçš„è´¨é‡å’Œå¯æ§æ€§ï¼Œè¯¥æ¨¡å‹å¯ä»¥ä¸ºéŸ³ä¹åˆ›ä½œè€…æä¾›æ›´å¼ºå¤§çš„å·¥å…·ï¼Œä¿ƒè¿›éŸ³ä¹åˆ›ä½œçš„å¤šæ ·æ€§å’Œåˆ›æ–°æ€§ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯å¯èƒ½ä¼šåœ¨éŸ³ä¹ç”Ÿæˆé¢†åŸŸäº§ç”Ÿæ·±è¿œçš„å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The recent surge in the popularity of diffusion models for image synthesis has attracted new attention to their potential for generation tasks in other domains. However, their applications to symbolic music generation remain largely under-explored because symbolic music is typically represented as sequences of discrete events and standard diffusion models are not well-suited for discrete data. We represent symbolic music as image-like pianorolls, facilitating the use of diffusion models for the generation of symbolic music. Moreover, this study introduces a novel diffusion model that incorporates our proposed Transformer-Mamba block and learnable wavelet transform. Classifier-free guidance is utilised to generate symbolic music with target chords. Our evaluation shows that our method achieves compelling results in terms of music quality and controllability, outperforming the strong baseline in pianoroll generation. Our code is available at https://github.com/jinchengzhanggg/proffusion.

