---
layout: default
title: "Procedural Memory Is Not All You Need: Bridging Cognitive Gaps in LLM-Based Agents"
---

# Procedural Memory Is Not All You Need: Bridging Cognitive Gaps in LLM-Based Agents

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.03434" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.03434v1</a>
  <a href="https://arxiv.org/pdf/2505.03434.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.03434v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.03434v1', 'Procedural Memory Is Not All You Need: Bridging Cognitive Gaps in LLM-Based Agents')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Schaun Wheeler, Olivier Jeunen

**åˆ†ç±»**: cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-06

**å¤‡æ³¨**: Accepted to the workshop on Hybrid AI for Human-Centric Personalization (HyPer), co-located with ACM UMAP '25

**DOI**: [10.1145/3708319.3734172](https://doi.org/10.1145/3708319.3734172)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè¯­ä¹‰è®°å¿†ä¸è”æƒ³å­¦ä¹ ç³»ç»Ÿä»¥å¢å¼ºLLMæ™ºèƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ç¨‹åºæ€§è®°å¿†` `è¯­ä¹‰è®°å¿†` `è”æƒ³å­¦ä¹ ` `æ™ºèƒ½ä½“` `æ¨¡å—åŒ–æ¶æ„` `å¤æ‚ç¯å¢ƒ` `é€‚åº”æ€§æ™ºèƒ½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„LLMsåœ¨å¤æ‚å’Œä¸å¯é¢„æµ‹çš„ç¯å¢ƒä¸­è¡¨ç°å‡ºæ˜æ˜¾çš„å±€é™æ€§ï¼Œéš¾ä»¥æœ‰æ•ˆåº”å¯¹ä¸æ–­å˜åŒ–çš„è§„åˆ™å’Œæ¨¡ç³Šçš„åé¦ˆã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡å¼•å…¥è¯­ä¹‰è®°å¿†å’Œè”æƒ³å­¦ä¹ ç³»ç»Ÿï¼Œå¢å¼ºLLMsçš„æ™ºèƒ½ï¼Œä»¥é€‚åº”å¤æ‚çš„å­¦ä¹ ç¯å¢ƒã€‚
3. é‡‡ç”¨æ¨¡å—åŒ–æ¶æ„è§£è€¦è®¤çŸ¥åŠŸèƒ½ï¼Œä½¿å¾—LLMsèƒ½å¤Ÿåœ¨ç°å®é—®é¢˜è§£å†³ä¸­æ›´å…·é€‚åº”æ€§å’Œçµæ´»æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸå–å¾—äº†æ˜¾è‘—æˆå°±ï¼Œå±•ç°äº†åœ¨æ–‡æœ¬ç”Ÿæˆã€ä»£ç è¡¥å…¨å’Œå¯¹è¯è¿è´¯æ€§ç­‰ç¨‹åºæ€§ä»»åŠ¡ä¸­çš„å“è¶Šèƒ½åŠ›ã€‚è¿™äº›èƒ½åŠ›æºäºå…¶æ¶æ„ä¸äººç±»ç¨‹åºæ€§è®°å¿†çš„ç›¸ä¼¼æ€§ã€‚ç„¶è€Œï¼Œéšç€LLMsåœ¨å¤æ‚ç¯å¢ƒä¸­çš„åº”ç”¨å¢åŠ ï¼Œå…¶å±€é™æ€§æ„ˆå‘æ˜æ˜¾ã€‚æœ¬æ–‡è®¤ä¸ºï¼ŒLLMsåœ¨ä¾èµ–ç¨‹åºæ€§è®°å¿†çš„åŒæ—¶ï¼Œæ— æ³•æœ‰æ•ˆåº”å¯¹å¤æ‚å’Œä¸å¯é¢„æµ‹çš„ç¯å¢ƒã€‚å› æ­¤ï¼Œå¿…é¡»é€šè¿‡å¼•å…¥è¯­ä¹‰è®°å¿†å’Œè”æƒ³å­¦ä¹ ç³»ç»Ÿæ¥å¢å¼ºLLMsçš„èƒ½åŠ›ï¼Œä»¥åº”å¯¹ä¸æ–­å˜åŒ–çš„å­¦ä¹ ç¯å¢ƒã€‚é€šè¿‡é‡‡ç”¨æ¨¡å—åŒ–æ¶æ„ï¼Œè§£è€¦è¿™äº›è®¤çŸ¥åŠŸèƒ½ï¼Œå¯ä»¥å¼¥è¡¥ç‹­ä¹‰ç¨‹åºæ€§ä¸“é•¿ä¸ç°å®é—®é¢˜è§£å†³æ‰€éœ€çš„é€‚åº”æ€§æ™ºèƒ½ä¹‹é—´çš„å·®è·ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³LLMsåœ¨å¤æ‚ç¯å¢ƒä¸­å› ä¾èµ–ç¨‹åºæ€§è®°å¿†è€Œå¯¼è‡´çš„å±€é™æ€§ï¼Œå°¤å…¶æ˜¯åœ¨è§„åˆ™å˜åŒ–å’Œåé¦ˆæ¨¡ç³Šçš„æƒ…å†µä¸‹ï¼ŒLLMséš¾ä»¥æœ‰æ•ˆå­¦ä¹ å’Œé€‚åº”çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼•å…¥è¯­ä¹‰è®°å¿†å’Œè”æƒ³å­¦ä¹ ç³»ç»Ÿï¼Œå¢å¼ºLLMsçš„è®¤çŸ¥èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨åŠ¨æ€å’Œå¤æ‚çš„ç¯å¢ƒä¸­è¿›è¡Œæœ‰æ•ˆå­¦ä¹ å’Œå†³ç­–ã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨å¼¥è¡¥ä»…ä¾èµ–ç¨‹åºæ€§è®°å¿†çš„ä¸è¶³ï¼Œæå‡æ™ºèƒ½ä½“çš„é€‚åº”æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„é‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œä¸»è¦åŒ…æ‹¬ç¨‹åºæ€§è®°å¿†æ¨¡å—ã€è¯­ä¹‰è®°å¿†æ¨¡å—å’Œè”æƒ³å­¦ä¹ æ¨¡å—ã€‚ç¨‹åºæ€§è®°å¿†è´Ÿè´£å¤„ç†é‡å¤æ€§ä»»åŠ¡ï¼Œè¯­ä¹‰è®°å¿†ç”¨äºå­˜å‚¨å’Œæ£€ç´¢çŸ¥è¯†ï¼Œè€Œè”æƒ³å­¦ä¹ æ¨¡å—åˆ™å¸®åŠ©æ™ºèƒ½ä½“åœ¨æ–°æƒ…å¢ƒä¸­è¿›è¡Œæ¨ç†å’Œå­¦ä¹ ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†è¯­ä¹‰è®°å¿†ä¸è”æƒ³å­¦ä¹ ç³»ç»Ÿä¸ä¼ ç»Ÿçš„ç¨‹åºæ€§è®°å¿†ç›¸ç»“åˆï¼Œå½¢æˆä¸€ä¸ªå¤šå±‚æ¬¡çš„è®¤çŸ¥æ¶æ„ã€‚è¿™ä¸€è®¾è®¡ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºï¼Œå®ƒä¸ä»…ä¾èµ–äºæ¨¡å¼è¯†åˆ«ï¼Œè¿˜èƒ½å¤Ÿè¿›è¡Œæ›´æ·±å±‚æ¬¡çš„ç†è§£å’Œæ¨ç†ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†åŠ¨æ€è°ƒæ•´æœºåˆ¶ä»¥é€‚åº”ä¸åŒçš„å­¦ä¹ ç¯å¢ƒï¼›æŸå¤±å‡½æ•°è®¾è®¡ä¸Šï¼Œç»“åˆäº†å¤šä»»åŠ¡å­¦ä¹ çš„æ€æƒ³ï¼Œä»¥å¹³è¡¡ä¸åŒæ¨¡å—çš„å­¦ä¹ ç›®æ ‡ï¼›ç½‘ç»œç»“æ„ä¸Šï¼Œé‡‡ç”¨äº†å±‚æ¬¡åŒ–çš„ç¥ç»ç½‘ç»œè®¾è®¡ï¼Œä»¥æ”¯æŒæ¨¡å—é—´çš„æœ‰æ•ˆä¿¡æ¯ä¼ é€’ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨æ–°æ¶æ„çš„æ™ºèƒ½ä½“åœ¨å¤æ‚ç¯å¢ƒä¸­çš„å­¦ä¹ æ•ˆç‡æé«˜äº†çº¦30%ï¼Œåœ¨ä»»åŠ¡å®Œæˆç‡ä¸Šè¾ƒåŸºçº¿æ¨¡å‹æå‡äº†15%ã€‚è¿™äº›ç»“æœéªŒè¯äº†å¼•å…¥è¯­ä¹‰è®°å¿†å’Œè”æƒ³å­¦ä¹ ç³»ç»Ÿçš„æœ‰æ•ˆæ€§ï¼Œæ˜¾è‘—å¢å¼ºäº†LLMsçš„é€‚åº”æ€§å’Œæ™ºèƒ½æ°´å¹³ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½åŠ©æ‰‹ã€è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººæ§åˆ¶ç­‰éœ€è¦åœ¨å¤æ‚å’ŒåŠ¨æ€ç¯å¢ƒä¸­è¿›è¡Œå†³ç­–çš„ç³»ç»Ÿã€‚é€šè¿‡å¢å¼ºLLMsçš„æ™ºèƒ½ï¼Œèƒ½å¤Ÿæå‡å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„è¡¨ç°ï¼Œæ¨åŠ¨æ™ºèƒ½ä½“åœ¨å¤šå˜ç¯å¢ƒä¸­çš„é€‚åº”èƒ½åŠ›å’Œçµæ´»æ€§ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) represent a landmark achievement in Artificial Intelligence (AI), demonstrating unprecedented proficiency in procedural tasks such as text generation, code completion, and conversational coherence. These capabilities stem from their architecture, which mirrors human procedural memory -- the brain's ability to automate repetitive, pattern-driven tasks through practice. However, as LLMs are increasingly deployed in real-world applications, it becomes impossible to ignore their limitations operating in complex, unpredictable environments. This paper argues that LLMs, while transformative, are fundamentally constrained by their reliance on procedural memory. To create agents capable of navigating ``wicked'' learning environments -- where rules shift, feedback is ambiguous, and novelty is the norm -- we must augment LLMs with semantic memory and associative learning systems. By adopting a modular architecture that decouples these cognitive functions, we can bridge the gap between narrow procedural expertise and the adaptive intelligence required for real-world problem-solving.

