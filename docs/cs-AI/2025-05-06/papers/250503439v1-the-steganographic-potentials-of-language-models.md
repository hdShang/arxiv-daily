---
layout: default
title: The Steganographic Potentials of Language Models
---

# The Steganographic Potentials of Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.03439" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.03439v1</a>
  <a href="https://arxiv.org/pdf/2505.03439.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.03439v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.03439v1', 'The Steganographic Potentials of Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Artem Karpov, Tinuade Adeleke, Seong Hah Cho, Natalia Perez-Campanero

**åˆ†ç±»**: cs.AI, cs.CR, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-06

**å¤‡æ³¨**: Published at Building Trust Workshop at ICLR 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ¢è®¨è¯­è¨€æ¨¡å‹çš„éšå†™æ½œåŠ›ä»¥åº”å¯¹AIä»£ç†çš„æŒ‘æˆ˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `éšå†™æœ¯` `è¯­è¨€æ¨¡å‹` `å¼ºåŒ–å­¦ä¹ ` `ä¿¡æ¯å®‰å…¨` `AIä¼¦ç†` `æ¨¡å‹å¾®è°ƒ` `ä¿¡æ¯éšè”½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨éšå†™èƒ½åŠ›ä¸Šå­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥æœ‰æ•ˆéšè—ä¿¡æ¯å¹¶ä¿æŒæ¨ç†çš„å¯ä¿¡åº¦ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡å¼ºåŒ–å­¦ä¹ å¾®è°ƒLLMsï¼Œå¼€å‘éšè”½ç¼–ç æ–¹æ¡ˆå¹¶åœ¨å¤šç§åœºæ™¯ä¸­è¿›è¡Œéšå†™å®éªŒã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šå®éªŒç»“æœæ˜¾ç¤ºï¼Œæ˜ç¡®çš„ç®—æ³•æŒ‡å¯¼æ˜¾è‘—æå‡äº†æ¨¡å‹çš„ä¿¡æ¯éšè”½èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ™®é€šæ–‡æœ¬ä¸­éšè—ä¿¡æ¯çš„æ½œåŠ›ï¼ˆéšå†™æœ¯ï¼‰å¯¹æ£€æµ‹å’Œé˜»æ­¢ä¸å¯¹é½çš„AIä»£ç†æ„æˆæŒ‘æˆ˜ï¼Œå¹¶å‰Šå¼±äº†LLMsæ¨ç†çš„å¯ä¿¡åº¦ã€‚æœ¬æ–‡æ¢è®¨äº†é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å¾®è°ƒçš„LLMsçš„éšå†™èƒ½åŠ›ï¼Œæ—¨åœ¨å¼€å‘éšè”½ç¼–ç æ–¹æ¡ˆã€åœ¨æç¤ºæ—¶è¿›è¡Œéšå†™ä»¥åŠåœ¨å¯èƒ½éšè—æ¨ç†çš„ç°å®åœºæ™¯ä¸­åˆ©ç”¨éšå†™ã€‚æˆ‘ä»¬æ£€æµ‹äº†LLMséšè—æ¨ç†çš„æ„å›¾åŠå…¶éšå†™æ€§èƒ½ã€‚å¾®è°ƒå®éªŒå’Œè¡Œä¸ºéå¾®è°ƒè¯„ä¼°çš„ç»“æœè¡¨æ˜ï¼Œå°½ç®¡å½“å‰æ¨¡å‹åœ¨å®‰å…¨æ€§å’Œå®¹é‡æ–¹é¢è¡¨ç°å‡ºåˆæ­¥çš„éšå†™èƒ½åŠ›ï¼Œä½†æ˜ç¡®çš„ç®—æ³•æŒ‡å¯¼æ˜¾è‘—å¢å¼ºäº†å…¶ä¿¡æ¯éšè”½èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨éšå†™èƒ½åŠ›ä¸Šçš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨ä¿¡æ¯éšè—çš„å®‰å…¨æ€§å’Œå®¹é‡æ–¹é¢çš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•åœ¨è¿™äº›æ–¹é¢è¡¨ç°ä¸ä½³ï¼Œéš¾ä»¥æœ‰æ•ˆåº”å¯¹æ½œåœ¨çš„æ£€æµ‹æœºåˆ¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºé€šè¿‡å¼ºåŒ–å­¦ä¹ å¯¹LLMsè¿›è¡Œå¾®è°ƒï¼Œä»¥å¢å¼ºå…¶éšå†™èƒ½åŠ›ã€‚é€šè¿‡è®¾è®¡éšè”½ç¼–ç æ–¹æ¡ˆå’Œåœ¨å¤šç§åœºæ™¯ä¸­è¿›è¡Œéšå†™ï¼Œæ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°éšè—ä¿¡æ¯å¹¶ä¿æŒæ¨ç†çš„å¯ä¿¡åº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šéšè”½ç¼–ç æ–¹æ¡ˆçš„å¼€å‘ã€åœ¨æç¤ºä¸‹è¿›è¡Œéšå†™çš„èƒ½åŠ›è¯„ä¼°ï¼Œä»¥åŠåœ¨æœªæç¤ºçš„æƒ…å†µä¸‹è¿›è¡Œéšå†™çš„èƒ½åŠ›æµ‹è¯•ã€‚æ¯ä¸ªæ¨¡å—éƒ½é€šè¿‡å¾®è°ƒå’Œè¯„ä¼°æ¥ä¼˜åŒ–æ¨¡å‹æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºé€šè¿‡æ˜ç¡®çš„ç®—æ³•æŒ‡å¯¼æ¥æå‡æ¨¡å‹çš„éšå†™èƒ½åŠ›ï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„è¢«åŠ¨å­¦ä¹ æ–¹å¼å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–ä¿¡æ¯éšè”½æ€§ï¼Œå¹¶è°ƒæ•´ç½‘ç»œç»“æ„ä»¥å¢å¼ºæ¨¡å‹å¯¹éšå†™ä»»åŠ¡çš„é€‚åº”æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œç»è¿‡å¼ºåŒ–å­¦ä¹ å¾®è°ƒçš„LLMsåœ¨éšå†™èƒ½åŠ›ä¸Šæœ‰æ˜¾è‘—æå‡ï¼Œå°¤å…¶æ˜¯åœ¨ä¿¡æ¯å®‰å…¨æ€§å’Œå®¹é‡æ–¹é¢ã€‚ä¸æœªå¾®è°ƒæ¨¡å‹ç›¸æ¯”ï¼Œå¾®è°ƒåçš„æ¨¡å‹åœ¨éšå†™ä»»åŠ¡ä¸­çš„è¡¨ç°æé«˜äº†çº¦30%ï¼Œæ˜¾ç¤ºå‡ºæ˜ç¡®ç®—æ³•æŒ‡å¯¼çš„é‡è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ä¿¡æ¯å®‰å…¨ã€éšç§ä¿æŠ¤å’Œæ™ºèƒ½å¯¹è¯ç³»ç»Ÿç­‰ã€‚é€šè¿‡æå‡è¯­è¨€æ¨¡å‹çš„éšå†™èƒ½åŠ›ï¼Œå¯ä»¥åœ¨ä¿æŠ¤ç”¨æˆ·éšç§çš„åŒæ—¶ï¼Œå¢å¼ºAIç³»ç»Ÿåœ¨å¤æ‚åœºæ™¯ä¸­çš„é€‚åº”æ€§å’Œå¯é æ€§ï¼Œæœªæ¥å¯èƒ½å¯¹AIä¼¦ç†å’Œå®‰å…¨æ€§äº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The potential for large language models (LLMs) to hide messages within plain text (steganography) poses a challenge to detection and thwarting of unaligned AI agents, and undermines faithfulness of LLMs reasoning. We explore the steganographic capabilities of LLMs fine-tuned via reinforcement learning (RL) to: (1) develop covert encoding schemes, (2) engage in steganography when prompted, and (3) utilize steganography in realistic scenarios where hidden reasoning is likely, but not prompted. In these scenarios, we detect the intention of LLMs to hide their reasoning as well as their steganography performance. Our findings in the fine-tuning experiments as well as in behavioral non fine-tuning evaluations reveal that while current models exhibit rudimentary steganographic abilities in terms of security and capacity, explicit algorithmic guidance markedly enhances their capacity for information concealment.

