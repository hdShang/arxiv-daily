---
layout: default
title: DocSpiral: A Platform for Integrated Assistive Document Annotation through Human-in-the-Spiral
---

# DocSpiral: A Platform for Integrated Assistive Document Annotation through Human-in-the-Spiral

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.03214" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.03214v1</a>
  <a href="https://arxiv.org/pdf/2505.03214.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.03214v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.03214v1', 'DocSpiral: A Platform for Integrated Assistive Document Annotation through Human-in-the-Spiral')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Qiang Sun, Sirui Li, Tingting Bi, Du Huynh, Mark Reynolds, Yuanyi Luo, Wei Liu

**åˆ†ç±»**: cs.SE, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-06

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDocSpiralä»¥è§£å†³å›¾åƒæ–‡æ¡£ç»“æ„åŒ–æ•°æ®æå–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ–‡æ¡£æ³¨é‡Š` `äººæœºåä½œ` `ç»“æ„åŒ–æ•°æ®æå–` `å›¾åƒå¤„ç†` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰æ–¹æ³•åœ¨ä»å›¾åƒæ–‡æ¡£ä¸­æå–ç»“æ„åŒ–æ•°æ®æ—¶é¢ä¸´æ–‡æ¡£å¤šæ ·æ€§å’Œäººå·¥æ³¨é‡Šæ•ˆç‡ä½ä¸‹çš„æŒ‘æˆ˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šDocSpiralé€šè¿‡äººæœºåä½œçš„è¿­ä»£å¾ªç¯è®¾è®¡ï¼Œé€æ­¥å‡å°‘äººå·¥å¹²é¢„ï¼Œæé«˜æ–‡æ¡£æ³¨é‡Šæ•ˆç‡ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šå®éªŒç»“æœæ˜¾ç¤ºï¼ŒDocSpiralåœ¨æ¨¡å‹è®­ç»ƒä¸­å‡å°‘äº†è‡³å°‘41%çš„æ³¨é‡Šæ—¶é—´ï¼Œå¹¶åœ¨ä¸‰æ¬¡è¿­ä»£ä¸­ä¿æŒä¸€è‡´çš„æ€§èƒ½æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä»é¢†åŸŸç‰¹å®šçš„å›¾åƒæ–‡æ¡£ï¼ˆå¦‚æ‰«ææŠ¥å‘Šï¼‰ä¸­è·å–ç»“æ„åŒ–æ•°æ®å¯¹è®¸å¤šä¸‹æ¸¸ä»»åŠ¡è‡³å…³é‡è¦ï¼Œä½†ç”±äºæ–‡æ¡£çš„å¤šæ ·æ€§ï¼Œè¿™ä¸€è¿‡ç¨‹ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚è®¸å¤šæ–‡æ¡£ä»¥å›¾åƒå½¢å¼å­˜åœ¨ï¼Œè€Œéæœºå™¨å¯è¯»æ–‡æœ¬ï¼Œå› æ­¤éœ€è¦äººå·¥æ³¨é‡Šä»¥è®­ç»ƒè‡ªåŠ¨æå–ç³»ç»Ÿã€‚æˆ‘ä»¬æå‡ºäº†DocSpiralï¼Œè¿™æ˜¯é¦–ä¸ªåŸºäºäººæœºåä½œçš„è¾…åŠ©æ–‡æ¡£æ³¨é‡Šå¹³å°ï¼Œæ—¨åœ¨è§£å†³ä»é¢†åŸŸç‰¹å®šå›¾åƒæ–‡æ¡£é›†åˆä¸­æå–ç»“æ„åŒ–ä¿¡æ¯çš„æŒ‘æˆ˜ã€‚DocSpiralé€šè¿‡è¿­ä»£å¾ªç¯çš„è®¾è®¡ï¼Œä½¿äººå·¥æ³¨é‡Šèƒ½å¤Ÿè®­ç»ƒæ¨¡å‹ï¼Œé€æ­¥å‡å°‘äººå·¥å¹²é¢„ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­å‡å°‘äº†è‡³å°‘41%çš„æ³¨é‡Šæ—¶é—´ï¼ŒåŒæ—¶åœ¨ä¸‰æ¬¡è¿­ä»£ä¸­è¡¨ç°å‡ºä¸€è‡´çš„æ€§èƒ½æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ä»é¢†åŸŸç‰¹å®šçš„å›¾åƒæ–‡æ¡£ä¸­æå–ç»“æ„åŒ–æ•°æ®çš„éš¾é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–äºäººå·¥æ³¨é‡Šï¼Œæ•ˆç‡ä½ä¸‹ä¸”éš¾ä»¥åº”å¯¹æ–‡æ¡£çš„å¤šæ ·æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDocSpiralçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡äººæœºåä½œçš„è¿­ä»£å¾ªç¯ï¼Œåˆ©ç”¨äººå·¥æ³¨é‡Šæ¥è®­ç»ƒæ¨¡å‹ï¼Œé€æ­¥å‡å°‘å¯¹äººå·¥å¹²é¢„çš„ä¾èµ–ï¼Œä»è€Œæé«˜æ³¨é‡Šæ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDocSpiralçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ–‡æ¡£æ ¼å¼è§„èŒƒåŒ–ã€å…¨é¢çš„æ³¨é‡Šæ¥å£ã€è¯„ä¼°æŒ‡æ ‡ä»ªè¡¨ç›˜å’ŒAPIç«¯ç‚¹ï¼Œå½¢æˆä¸€ä¸ªç»Ÿä¸€çš„å·¥ä½œæµç¨‹ï¼Œæ”¯æŒAI/MLæ¨¡å‹çš„å¼€å‘ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå…¶â€œäººæœºåä½œâ€çš„è¿­ä»£è®¾è®¡ï¼Œä½¿å¾—æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­èƒ½å¤Ÿä¸æ–­ä¼˜åŒ–ï¼Œå‡å°‘äººå·¥å¹²é¢„çš„éœ€æ±‚ã€‚è¿™ä¸ä¼ ç»Ÿçš„å•ä¸€äººå·¥æ³¨é‡Šæ–¹æ³•å½¢æˆäº†é²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å…³é”®è®¾è®¡æ–¹é¢ï¼ŒDocSpiralé‡‡ç”¨äº†çµæ´»çš„æ³¨é‡Šæ¥å£å’Œæ ‡å‡†åŒ–çš„æ–‡æ¡£æ ¼å¼ï¼Œç¡®ä¿äº†æ³¨é‡Šè¿‡ç¨‹çš„é«˜æ•ˆæ€§ã€‚åŒæ—¶ï¼Œç³»ç»Ÿé›†æˆäº†è¯„ä¼°æŒ‡æ ‡ï¼Œä¾¿äºå®æ—¶ç›‘æ§æ¨¡å‹æ€§èƒ½ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡å°šæœªè¯¦ç»†æŠ«éœ²ï¼Œå±äºæœªçŸ¥é¢†åŸŸã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒDocSpiralåœ¨æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­å‡å°‘äº†è‡³å°‘41%çš„æ³¨é‡Šæ—¶é—´ï¼Œå¹¶åœ¨ä¸‰æ¬¡è¿­ä»£ä¸­è¡¨ç°å‡ºä¸€è‡´çš„æ€§èƒ½æå‡ã€‚è¿™ä¸€æ˜¾è‘—çš„æ•ˆç‡æå‡ä¸ºæ–‡æ¡£å¤„ç†é¢†åŸŸçš„AI/MLæ¨¡å‹å¼€å‘æä¾›äº†å¼ºæœ‰åŠ›çš„æ”¯æŒã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

DocSpiralçš„æ½œåœ¨åº”ç”¨åœºæ™¯åŒ…æ‹¬åœ°çƒç§‘å­¦å’ŒåŒ»ç–—ä¿å¥ç­‰é¢†åŸŸï¼Œè¿™äº›é¢†åŸŸé€šå¸¸éœ€è¦å¤„ç†å¤§é‡å›¾åƒæ–‡æ¡£ã€‚é€šè¿‡é™ä½AI/MLæ¨¡å‹å¼€å‘çš„é—¨æ§›ï¼ŒDocSpiralèƒ½å¤Ÿä¿ƒè¿›å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è¿™äº›æ–‡æ¡£å¯†é›†å‹é¢†åŸŸçš„åº”ç”¨ï¼Œæå‡æ•°æ®å¤„ç†æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Acquiring structured data from domain-specific, image-based documents such as scanned reports is crucial for many downstream tasks but remains challenging due to document variability. Many of these documents exist as images rather than as machine-readable text, which requires human annotation to train automated extraction systems. We present DocSpiral, the first Human-in-the-Spiral assistive document annotation platform, designed to address the challenge of extracting structured information from domain-specific, image-based document collections. Our spiral design establishes an iterative cycle in which human annotations train models that progressively require less manual intervention. DocSpiral integrates document format normalization, comprehensive annotation interfaces, evaluation metrics dashboard, and API endpoints for the development of AI / ML models into a unified workflow. Experiments demonstrate that our framework reduces annotation time by at least 41\% while showing consistent performance gains across three iterations during model training. By making this annotation platform freely accessible, we aim to lower barriers to AI/ML models development in document processing, facilitating the adoption of large language models in image-based, document-intensive fields such as geoscience and healthcare. The system is freely available at: https://app.ai4wa.com. The demonstration video is available: https://app.ai4wa.com/docs/docspiral/demo.

