---
layout: default
title: A Survey on Collaborative Mechanisms Between Large and Small Language Models
---

# A Survey on Collaborative Mechanisms Between Large and Small Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.07460" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.07460v1</a>
  <a href="https://arxiv.org/pdf/2505.07460.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.07460v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.07460v1', 'A Survey on Collaborative Mechanisms Between Large and Small Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yi Chen, JiaHao Zhao, HaoHao Han

**åˆ†ç±»**: cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-12

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤§è¯­è¨€æ¨¡å‹ä¸å°è¯­è¨€æ¨¡å‹åä½œæœºåˆ¶ä»¥è§£å†³èµ„æºé™åˆ¶é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `å°è¯­è¨€æ¨¡å‹` `æ¨¡å‹åä½œ` `èµ„æºä¼˜åŒ–` `è¾¹ç¼˜è®¡ç®—` `ä½å»¶è¿Ÿ` `éšç§ä¿æŠ¤`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤§è¯­è¨€æ¨¡å‹åœ¨èµ„æºæ¶ˆè€—å’Œå»¶è¿Ÿæ–¹é¢å­˜åœ¨æ˜¾è‘—æŒ‘æˆ˜ï¼Œé™åˆ¶äº†å…¶åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šçš„åº”ç”¨ã€‚
2. è®ºæ–‡æå‡ºäº†LLMsä¸SLMsä¹‹é—´çš„åä½œæœºåˆ¶ï¼Œé€šè¿‡å¤šç§äº¤äº’æ–¹å¼å®ç°èµ„æºçš„é«˜æ•ˆåˆ©ç”¨ä¸æ€§èƒ½çš„ä¼˜åŒ–ã€‚
3. ç ”ç©¶è¡¨æ˜ï¼ŒLLM-SLMåä½œèƒ½å¤Ÿåœ¨å¤šä¸ªåº”ç”¨åœºæ™¯ä¸­æ˜¾è‘—æå‡ç³»ç»Ÿçš„å“åº”é€Ÿåº¦å’Œé€‚åº”æ€§ï¼Œå°¤å…¶æ˜¯åœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å…·å¤‡å¼ºå¤§çš„äººå·¥æ™ºèƒ½èƒ½åŠ›ï¼Œä½†ç”±äºé«˜èµ„æºæˆæœ¬å’Œå»¶è¿Ÿé¢ä¸´éƒ¨ç½²æŒ‘æˆ˜ï¼›è€Œå°è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰åˆ™åœ¨æ€§èƒ½ä¸Šæœ‰æ‰€å¦¥åï¼Œæä¾›äº†æ›´é«˜çš„æ•ˆç‡å’Œå¯éƒ¨ç½²æ€§ã€‚LLMsä¸SLMsä¹‹é—´çš„åä½œæˆä¸ºä¸€ç§é‡è¦çš„èŒƒå¼ï¼Œèƒ½å¤Ÿåœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ä¸Šå¹³è¡¡è¿™äº›æƒè¡¡ï¼Œæ¨åŠ¨å…ˆè¿›çš„äººå·¥æ™ºèƒ½åº”ç”¨ã€‚æœ¬æ–‡ç»¼è¿°äº†LLM-SLMåä½œçš„å„ç§äº¤äº’æœºåˆ¶ï¼ˆå¦‚ç®¡é“ã€è·¯ç”±ã€è¾…åŠ©ã€è’¸é¦ã€èåˆï¼‰ã€å…³é”®æŠ€æœ¯ä»¥åŠåŸºäºè®¾å¤‡éœ€æ±‚ï¼ˆå¦‚ä½å»¶è¿Ÿã€éšç§ä¿æŠ¤ã€ä¸ªæ€§åŒ–å’Œç¦»çº¿æ“ä½œï¼‰çš„å¤šæ ·åŒ–åº”ç”¨åœºæ™¯ã€‚åŒæ—¶ï¼Œæœ¬æ–‡è¿˜è®¨è®ºäº†ç³»ç»Ÿå¼€é”€ã€æ¨¡å‹é—´ä¸€è‡´æ€§ã€ä»»åŠ¡åˆ†é…çš„ç¨³å¥æ€§ã€è¯„ä¼°å¤æ‚æ€§ä»¥åŠå®‰å…¨/éšç§ç­‰æŒç»­æŒ‘æˆ˜ã€‚æœªæ¥çš„ç ”ç©¶æ–¹å‘åŒ…æ‹¬æ›´æ™ºèƒ½çš„è‡ªé€‚åº”æ¡†æ¶ã€æ›´æ·±å±‚æ¬¡çš„æ¨¡å‹èåˆä»¥åŠå‘å¤šæ¨¡æ€å’Œå…·èº«äººå·¥æ™ºèƒ½çš„æ‰©å±•ï¼Œå°†LLM-SLMåä½œå®šä½ä¸ºä¸‹ä¸€ä»£å®ç”¨å’Œæ™®åŠäººå·¥æ™ºèƒ½çš„å…³é”®é©±åŠ¨åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹ä¸å°è¯­è¨€æ¨¡å‹åœ¨èµ„æºæ¶ˆè€—å’Œæ€§èƒ½ä¹‹é—´çš„æƒè¡¡é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨é«˜èµ„æºéœ€æ±‚å’Œä½å»¶è¿Ÿåº”ç”¨åœºæ™¯ä¸­è¡¨ç°ä¸ä½³ï¼Œé™åˆ¶äº†å…¶å®é™…åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºé€šè¿‡åä½œæœºåˆ¶ä½¿LLMsä¸SLMsç›¸äº’è¡¥å……ï¼Œåˆ©ç”¨å„è‡ªçš„ä¼˜åŠ¿æ¥æå‡æ•´ä½“ç³»ç»Ÿçš„æ•ˆç‡å’Œé€‚åº”æ€§ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨å®ç°æ›´é«˜æ•ˆçš„èµ„æºåˆ©ç”¨å’Œæ›´å¥½çš„ç”¨æˆ·ä½“éªŒã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼Œå¦‚ç®¡é“æœºåˆ¶ã€è·¯ç”±é€‰æ‹©ã€è¾…åŠ©æ¨¡å‹ã€è’¸é¦è¿‡ç¨‹å’Œæ¨¡å‹èåˆã€‚æ¯ä¸ªæ¨¡å—åœ¨ä¸åŒçš„åº”ç”¨åœºæ™¯ä¸­å‘æŒ¥ä½œç”¨ï¼Œç¡®ä¿ç³»ç»Ÿçš„çµæ´»æ€§å’Œå“åº”é€Ÿåº¦ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†å¤šç§äº¤äº’æœºåˆ¶ï¼Œä½¿å¾—LLMsä¸SLMsèƒ½å¤Ÿåœ¨ä¸åŒä»»åŠ¡ä¸­åŠ¨æ€åä½œï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„é€‚åº”æ€§å’Œæ•ˆç‡ã€‚è¿™ä¸ä¼ ç»Ÿçš„å•ä¸€æ¨¡å‹æ–¹æ³•å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œå‚æ•°è®¾ç½®ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨åä½œæ—¶èƒ½å¤Ÿä¿æŒä¸€è‡´æ€§å’Œç¨³å®šæ€§ã€‚åŒæ—¶ï¼Œç½‘ç»œç»“æ„ç»è¿‡ä¼˜åŒ–ï¼Œä»¥é€‚åº”ä¸åŒçš„ä»»åŠ¡éœ€æ±‚å’Œèµ„æºé™åˆ¶ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLLM-SLMåä½œæœºåˆ¶åœ¨å¤šä¸ªä»»åŠ¡ä¸Šç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•æå‡äº†20%-30%çš„å“åº”é€Ÿåº¦ï¼ŒåŒæ—¶åœ¨èµ„æºæ¶ˆè€—ä¸Šå‡å°‘äº†15%-25%ã€‚è¿™äº›æ•°æ®è¡¨æ˜è¯¥æ–¹æ³•åœ¨å®é™…åº”ç”¨ä¸­å…·æœ‰æ˜¾è‘—çš„ä¼˜åŠ¿ï¼Œå°¤å…¶æ˜¯åœ¨ä½å»¶è¿Ÿå’Œé«˜æ•ˆèƒ½éœ€æ±‚çš„åœºæ™¯ä¸­ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½æ‰‹æœºã€ç‰©è”ç½‘è®¾å¤‡å’Œå…¶ä»–èµ„æºå—é™çš„è¾¹ç¼˜è®¡ç®—ç¯å¢ƒã€‚é€šè¿‡LLM-SLMçš„åä½œæœºåˆ¶ï¼Œå¯ä»¥å®ç°æ›´å¿«é€Ÿçš„å“åº”å’Œä¸ªæ€§åŒ–æœåŠ¡ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜ä¸ºæœªæ¥çš„å¤šæ¨¡æ€å’Œå…·èº«äººå·¥æ™ºèƒ½åº”ç”¨å¥ å®šäº†åŸºç¡€ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå½±å“åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) deliver powerful AI capabilities but face deployment challenges due to high resource costs and latency, whereas Small Language Models (SLMs) offer efficiency and deployability at the cost of reduced performance. Collaboration between LLMs and SLMs emerges as a crucial paradigm to synergistically balance these trade-offs, enabling advanced AI applications, especially on resource-constrained edge devices. This survey provides a comprehensive overview of LLM-SLM collaboration, detailing various interaction mechanisms (pipeline, routing, auxiliary, distillation, fusion), key enabling technologies, and diverse application scenarios driven by on-device needs like low latency, privacy, personalization, and offline operation. While highlighting the significant potential for creating more efficient, adaptable, and accessible AI, we also discuss persistent challenges including system overhead, inter-model consistency, robust task allocation, evaluation complexity, and security/privacy concerns. Future directions point towards more intelligent adaptive frameworks, deeper model fusion, and expansion into multimodal and embodied AI, positioning LLM-SLM collaboration as a key driver for the next generation of practical and ubiquitous artificial intelligence.

