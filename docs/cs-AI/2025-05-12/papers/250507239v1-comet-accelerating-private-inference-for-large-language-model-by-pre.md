---
layout: default
title: Comet: Accelerating Private Inference for Large Language Model by Predicting Activation Sparsity
---

# Comet: Accelerating Private Inference for Large Language Model by Predicting Activation Sparsity

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.07239" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.07239v1</a>
  <a href="https://arxiv.org/pdf/2505.07239.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.07239v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.07239v1', 'Comet: Accelerating Private Inference for Large Language Model by Predicting Activation Sparsity')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Guang Yan, Yuhui Zhang, Zimu Guo, Lutan Zhao, Xiaojun Chen, Chen Wang, Wenhao Wang, Dan Meng, Rui Hou

**åˆ†ç±»**: cs.CR, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-12

**å¤‡æ³¨**: Accepted to SP 2025

**DOI**: [10.1109/SP61157.2025.00182](https://doi.org/10.1109/SP61157.2025.00182)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCometä»¥åŠ é€Ÿå¤§è¯­è¨€æ¨¡å‹çš„ç§å¯†æ¨ç†**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `ç§å¯†æ¨ç†` `å®‰å…¨å¤šæ–¹è®¡ç®—` `æ¿€æ´»ç¨€ç–æ€§` `æ€§èƒ½ä¼˜åŒ–` `äº‘è®¡ç®—` `éšç§ä¿æŠ¤`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å®‰å…¨å¤šæ–¹è®¡ç®—æ–¹æ³•åœ¨LLMæ¨ç†ä¸­å­˜åœ¨é¢‘ç¹é€šä¿¡å¯¼è‡´çš„æ€§èƒ½å¼€é”€é—®é¢˜ã€‚
2. Cometé€šè¿‡é¢„æµ‹æ¿€æ´»å‡½æ•°è¾“å‡ºçš„ç¨€ç–åˆ†å¸ƒï¼Œè®¾è®¡äº†ä¸€ç§æ–°çš„ç§å¯†æ¨ç†åè®®ï¼Œé¿å…ä¸å¿…è¦çš„è®¡ç®—ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒCometåœ¨é€Ÿåº¦å’Œé€šä¿¡æ•ˆç‡ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„ç§å¯†æ¨ç†ç³»ç»Ÿï¼Œæå‡å¹…åº¦å¯è¾¾2.63å€å’Œ2.64å€ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨äº‘å¹³å°ä¸Šæä¾›æ¨ç†æœåŠ¡çš„æ—¥ç›Šæ™®åŠï¼Œå…³äºæ•æ„Ÿä¿¡æ¯æ³„éœ²çš„éšç§æ‹…å¿§ä¹Ÿåœ¨åŠ å‰§ã€‚å®‰å…¨å¤šæ–¹è®¡ç®—ï¼ˆMPCï¼‰æ˜¯ä¸€ç§ä¿æŠ¤LLMæ¨ç†éšç§çš„æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆï¼Œä½†å…¶é¢‘ç¹çš„æœåŠ¡å™¨é—´é€šä¿¡å¯¼è‡´äº†é«˜æ€§èƒ½å¼€é”€ã€‚é’ˆå¯¹LLMsä¸­æ™®éå­˜åœ¨çš„æ¿€æ´»ç¨€ç–æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„ç§å¯†æ¨ç†ç³»ç»ŸCometã€‚è¯¥ç³»ç»Ÿä½¿ç”¨å‡†ç¡®å¿«é€Ÿçš„é¢„æµ‹å™¨æ¥é¢„æµ‹æ¿€æ´»å‡½æ•°è¾“å‡ºçš„ç¨€ç–åˆ†å¸ƒï¼Œå¹¶å¼•å…¥äº†ä¸€ç§æ–°çš„ç§å¯†æ¨ç†åè®®ï¼Œé€šè¿‡åˆ©ç”¨é¢„æµ‹çš„ç¨€ç–åˆ†å¸ƒçš„ç©ºé—´å±€éƒ¨æ€§ï¼Œå®‰å…¨é«˜æ•ˆåœ°é¿å…æ¶‰åŠé›¶å€¼çš„è®¡ç®—ã€‚æˆ‘ä»¬åœ¨å››ä¸ªå¸¸è§çš„LLMsä¸Šè¯„ä¼°äº†Cometï¼Œå¹¶ä¸å…­ä¸ªæœ€å…ˆè¿›çš„ç§å¯†æ¨ç†ç³»ç»Ÿè¿›è¡Œäº†æ¯”è¾ƒï¼Œç»“æœæ˜¾ç¤ºCometå®ç°äº†1.87x-2.63xçš„é€Ÿåº¦æå‡å’Œ1.94x-2.64xçš„é€šä¿¡å‡å°‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³åœ¨å¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†ä¸­ï¼Œå®‰å…¨å¤šæ–¹è®¡ç®—å› é¢‘ç¹çš„æœåŠ¡å™¨é—´é€šä¿¡è€Œå¯¼è‡´çš„æ€§èƒ½å¼€é”€é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨ä¿æŠ¤éšç§çš„åŒæ—¶ï¼Œæœªèƒ½æœ‰æ•ˆé™ä½è®¡ç®—å’Œé€šä¿¡æˆæœ¬ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„Cometç³»ç»Ÿé€šè¿‡é¢„æµ‹æ¿€æ´»å‡½æ•°è¾“å‡ºçš„ç¨€ç–åˆ†å¸ƒï¼Œåˆ©ç”¨è¿™ä¸€ç‰¹æ€§æ¥é¿å…æ¶‰åŠé›¶å€¼çš„è®¡ç®—ï¼Œä»è€Œæé«˜æ¨ç†æ•ˆç‡ã€‚è¯¥è®¾è®¡æ—¨åœ¨å‡å°‘ä¸å¿…è¦çš„è®¡ç®—è´Ÿæ‹…ï¼ŒåŒæ—¶ç¡®ä¿éšç§ä¿æŠ¤ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCometçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸€ä¸ªå¿«é€Ÿå‡†ç¡®çš„ç¨€ç–é¢„æµ‹å™¨å’Œä¸€ä¸ªæ–°çš„ç§å¯†æ¨ç†åè®®ã€‚ç³»ç»Ÿé¦–å…ˆé€šè¿‡é¢„æµ‹å™¨è·å–æ¿€æ´»ç¨€ç–æ€§åˆ†å¸ƒï¼Œç„¶åæ ¹æ®è¯¥åˆ†å¸ƒä¼˜åŒ–è®¡ç®—æµç¨‹ï¼Œå‡å°‘é€šä¿¡å’Œè®¡ç®—å¼€é”€ã€‚

**å…³é”®åˆ›æ–°**ï¼šCometçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶ç¨€ç–é¢„æµ‹æœºåˆ¶å’Œè®¡ç®—é¿å…ç­–ç•¥ï¼Œåˆ©ç”¨ç©ºé—´å±€éƒ¨æ€§æ¥é«˜æ•ˆå¤„ç†ç¨€ç–æ¿€æ´»ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—å¤æ‚åº¦ï¼Œä¸ä¼ ç»ŸMPCæ–¹æ³•ç›¸æ¯”å…·æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒCometé‡‡ç”¨äº†ä½é€šä¿¡å¼€é”€çš„ç¼“å­˜è¡¥å……ç­–ç•¥ï¼Œåˆå¹¶ç¼ºå¤±è¯·æ±‚å¹¶å¼•å…¥é¢„å–æœºåˆ¶ï¼Œä»¥åº”å¯¹ç¨€ç–æ€§å¯¹KVç¼“å­˜æ¡ç›®çš„æ—¶ç©ºè¿ç»­æ€§å½±å“ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

Cometåœ¨å››ä¸ªå¸¸è§çš„LLMsä¸Šè¿›è¡Œè¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºå…¶åœ¨é€Ÿåº¦ä¸Šå®ç°äº†1.87xè‡³2.63xçš„æå‡ï¼ŒåŒæ—¶åœ¨é€šä¿¡æ•ˆç‡ä¸Šå‡å°‘äº†1.94xè‡³2.64xï¼Œç›¸è¾ƒäºå…­ä¸ªæœ€å…ˆè¿›çš„ç§å¯†æ¨ç†ç³»ç»Ÿè¡¨ç°å‡ºæ˜¾è‘—çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Cometç³»ç»Ÿçš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬äº‘è®¡ç®—ç¯å¢ƒä¸­çš„ç§å¯†æ¨ç†æœåŠ¡ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†æ•æ„Ÿæ•°æ®æ—¶ï¼Œå¦‚åŒ»ç–—ã€é‡‘èç­‰é¢†åŸŸã€‚é€šè¿‡æé«˜æ¨ç†é€Ÿåº¦å’Œé™ä½é€šä¿¡æˆæœ¬ï¼ŒCometèƒ½å¤Ÿä¸ºä¼ä¸šæä¾›æ›´é«˜æ•ˆçš„éšç§ä¿æŠ¤è§£å†³æ–¹æ¡ˆï¼Œæ¨åŠ¨å¤§è¯­è¨€æ¨¡å‹çš„å¹¿æ³›åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> With the growing use of large language models (LLMs) hosted on cloud platforms to offer inference services, privacy concerns about the potential leakage of sensitive information are escalating. Secure multi-party computation (MPC) is a promising solution to protect the privacy in LLM inference. However, MPC requires frequent inter-server communication, causing high performance overhead.
>   Inspired by the prevalent activation sparsity of LLMs, where most neuron are not activated after non-linear activation functions, we propose an efficient private inference system, Comet. This system employs an accurate and fast predictor to predict the sparsity distribution of activation function output. Additionally, we introduce a new private inference protocol. It efficiently and securely avoids computations involving zero values by exploiting the spatial locality of the predicted sparse distribution. While this computation-avoidance approach impacts the spatiotemporal continuity of KV cache entries, we address this challenge with a low-communication overhead cache refilling strategy that merges miss requests and incorporates a prefetching mechanism. Finally, we evaluate Comet on four common LLMs and compare it with six state-of-the-art private inference systems. Comet achieves a 1.87x-2.63x speedup and a 1.94x-2.64x communication reduction.

