---
layout: default
title: Evaluating Large Language Models for Real-World Engineering Tasks
---

# Evaluating Large Language Models for Real-World Engineering Tasks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.13484" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.13484v1</a>
  <a href="https://arxiv.org/pdf/2505.13484.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.13484v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.13484v1', 'Evaluating Large Language Models for Real-World Engineering Tasks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Rene Heesch, Sebastian Eilermann, Alexander Windmann, Alexander Diedrich, Philipp Rosenthal, Oliver Niggemann

**åˆ†ç±»**: cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-12

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé’ˆå¯¹çœŸå®å·¥ç¨‹ä»»åŠ¡çš„LLMè¯„ä¼°æ•°æ®åº“ä»¥è§£å†³ç°æœ‰è¯„ä¼°ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å·¥ç¨‹ä»»åŠ¡` `è¯„ä¼°æ–¹æ³•` `çœŸå®åœºæ™¯` `å¤æ‚æ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMè¯„ä¼°æ–¹æ³•ä¾èµ–äºç®€åŒ–ç”¨ä¾‹ï¼Œæœªèƒ½æœ‰æ•ˆåæ˜ çœŸå®å·¥ç¨‹ä»»åŠ¡çš„å¤æ‚æ€§å’Œå¤šæ ·æ€§ã€‚
2. æœ¬æ–‡æå‡ºä¸€ä¸ªåŒ…å«100å¤šä¸ªçœŸå®å·¥ç¨‹åœºæ™¯çš„é—®é¢˜æ•°æ®åº“ï¼Œä»¥ç³»ç»Ÿæ€§åœ°è¯„ä¼°LLMsåœ¨å¤æ‚å·¥ç¨‹ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMsåœ¨åŸºæœ¬æ¨ç†æ–¹é¢è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨æŠ½è±¡æ¨ç†å’Œä¸Šä¸‹æ–‡æ•æ„Ÿé€»è¾‘ä¸Šå­˜åœ¨æ˜¾è‘—ä¸è¶³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸ä»…åœ¨æ—¥å¸¸æ´»åŠ¨ä¸­å…·æœ‰å˜é©æ€§ï¼Œåœ¨å·¥ç¨‹ä»»åŠ¡ä¸­åŒæ ·é‡è¦ã€‚ç„¶è€Œï¼Œç›®å‰å¯¹LLMsåœ¨å·¥ç¨‹é¢†åŸŸçš„è¯„ä¼°å­˜åœ¨ä¸¤ä¸ªä¸»è¦ç¼ºé™·ï¼šä¸€æ˜¯ä¾èµ–äºç®€åŒ–çš„ç”¨ä¾‹ï¼Œé€šå¸¸æ¥è‡ªè€ƒè¯•ææ–™ï¼Œå®¹æ˜“éªŒè¯æ­£ç¡®æ€§ï¼›äºŒæ˜¯ä½¿ç”¨çš„åœºæ™¯ä¸è¶³ä»¥æ•æ‰å…³é”®çš„å·¥ç¨‹èƒ½åŠ›ã€‚å› æ­¤ï¼ŒLLMsåœ¨å¤æ‚çœŸå®å·¥ç¨‹é—®é¢˜ä¸Šçš„è¯„ä¼°ä»ç„¶æœªè¢«å……åˆ†æ¢ç´¢ã€‚æœ¬æ–‡é€šè¿‡å¼•å…¥ä¸€ä¸ªåŒ…å«100å¤šä¸ªçœŸå®ç”Ÿäº§å¯¼å‘å·¥ç¨‹åœºæ™¯çš„é—®é¢˜æ•°æ®åº“ï¼Œç³»ç»Ÿæ€§åœ°è¯„ä¼°å››ç§æœ€å…ˆè¿›çš„LLMsï¼Œæ¢è®¨å…¶åœ¨å¤æ‚å·¥ç¨‹ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚ç»“æœè¡¨æ˜ï¼ŒLLMsåœ¨åŸºæœ¬çš„æ—¶é—´å’Œç»“æ„æ¨ç†æ–¹é¢è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨æŠ½è±¡æ¨ç†ã€å½¢å¼å»ºæ¨¡å’Œä¸Šä¸‹æ–‡æ•æ„Ÿçš„å·¥ç¨‹é€»è¾‘æ–¹é¢å­˜åœ¨æ˜¾è‘—å›°éš¾ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å½“å‰LLMè¯„ä¼°ä¸­å­˜åœ¨çš„ç¼ºé™·ï¼Œç‰¹åˆ«æ˜¯å¯¹å¤æ‚çœŸå®å·¥ç¨‹é—®é¢˜çš„è¯„ä¼°ä¸è¶³ã€‚ç°æœ‰æ–¹æ³•å¤šä¾èµ–äºç®€åŒ–çš„ç”¨ä¾‹ï¼Œæ— æ³•å…¨é¢åæ˜ LLMsçš„å®é™…èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ„å»ºä¸€ä¸ªåŒ…å«çœŸå®ç”Ÿäº§å¯¼å‘å·¥ç¨‹åœºæ™¯çš„é—®é¢˜æ•°æ®åº“ï¼Œç³»ç»Ÿæ€§åœ°è¯„ä¼°LLMsåœ¨å¤æ‚å·¥ç¨‹ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œç¡®ä¿è¯„ä¼°çš„çœŸå®æ€§å’Œæœ‰æ•ˆæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é¦–å…ˆè®¾è®¡äº†ä¸€ä¸ªåŒ…å«100å¤šä¸ªé—®é¢˜çš„æ•°æ®åº“ï¼Œæ¶µç›–äº§å“è®¾è®¡ã€é¢„æµ‹å’Œè¯Šæ–­ç­‰æ ¸å¿ƒå·¥ç¨‹èƒ½åŠ›ã€‚ç„¶åï¼Œé€‰æ‹©å››ç§æœ€å…ˆè¿›çš„LLMsè¿›è¡Œè¯„ä¼°ï¼ŒåŒ…æ‹¬äº‘ç«¯å’Œæœ¬åœ°å®ä¾‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†ä¸€ä¸ªç³»ç»ŸåŒ–çš„é—®é¢˜æ•°æ®åº“ï¼Œå¡«è¡¥äº†LLMåœ¨çœŸå®å·¥ç¨‹ä»»åŠ¡è¯„ä¼°ä¸­çš„ç©ºç™½ï¼Œæä¾›äº†æ›´å…·æŒ‘æˆ˜æ€§çš„è¯„ä¼°åœºæ™¯ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé’ˆå¯¹æ¯ä¸ªLLMçš„è¯„ä¼°é‡‡ç”¨äº†æ ‡å‡†åŒ–çš„æµ‹è¯•æµç¨‹ï¼Œé‡ç‚¹å…³æ³¨æ—¶é—´æ¨ç†ã€ç»“æ„æ¨ç†ã€æŠ½è±¡æ¨ç†å’Œä¸Šä¸‹æ–‡æ•æ„Ÿé€»è¾‘ç­‰å¤šä¸ªç»´åº¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMsåœ¨åŸºæœ¬çš„æ—¶é—´å’Œç»“æ„æ¨ç†æ–¹é¢è¡¨ç°è‰¯å¥½ï¼Œå¾—åˆ†åœ¨80%ä»¥ä¸Šï¼Œä½†åœ¨æŠ½è±¡æ¨ç†å’Œä¸Šä¸‹æ–‡æ•æ„Ÿé€»è¾‘æ–¹é¢çš„å¾—åˆ†ä½äº50%ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½å·®è·ã€‚è¿™ä¸€å‘ç°ä¸ºLLMsåœ¨å·¥ç¨‹é¢†åŸŸçš„åº”ç”¨æä¾›äº†é‡è¦çš„æ”¹è¿›æ–¹å‘ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å·¥ç¨‹è®¾è®¡ã€äº§å“å¼€å‘å’ŒæŠ€æœ¯æ”¯æŒç­‰ï¼Œèƒ½å¤Ÿå¸®åŠ©å·¥ç¨‹å¸ˆæ›´æœ‰æ•ˆåœ°åˆ©ç”¨LLMsè¿›è¡Œå¤æ‚é—®é¢˜çš„è§£å†³ã€‚æœªæ¥ï¼Œéšç€LLMsçš„ä¸æ–­å‘å±•ï¼Œè¯¥è¯„ä¼°æ¡†æ¶æœ‰æœ›æ¨åŠ¨å·¥ç¨‹é¢†åŸŸçš„æ™ºèƒ½åŒ–è¿›ç¨‹ï¼Œæé«˜å·¥ç¨‹å¸ˆçš„å·¥ä½œæ•ˆç‡å’Œå†³ç­–èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) are transformative not only for daily activities but also for engineering tasks. However, current evaluations of LLMs in engineering exhibit two critical shortcomings: (i) the reliance on simplified use cases, often adapted from examination materials where correctness is easily verifiable, and (ii) the use of ad hoc scenarios that insufficiently capture critical engineering competencies. Consequently, the assessment of LLMs on complex, real-world engineering problems remains largely unexplored. This paper addresses this gap by introducing a curated database comprising over 100 questions derived from authentic, production-oriented engineering scenarios, systematically designed to cover core competencies such as product design, prognosis, and diagnosis. Using this dataset, we evaluate four state-of-the-art LLMs, including both cloud-based and locally hosted instances, to systematically investigate their performance on complex engineering tasks. Our results show that LLMs demonstrate strengths in basic temporal and structural reasoning but struggle significantly with abstract reasoning, formal modeling, and context-sensitive engineering logic.

