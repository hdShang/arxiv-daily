---
layout: default
title: Measuring General Intelligence with Generated Games
---

# Measuring General Intelligence with Generated Games

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.07215" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.07215v1</a>
  <a href="https://arxiv.org/pdf/2505.07215.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.07215v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.07215v1', 'Measuring General Intelligence with Generated Games')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Vivek Verma, David Huang, William Chen, Dan Klein, Nicholas Tomlin

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-12

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºgg-benchä»¥è¯„ä¼°è¯­è¨€æ¨¡å‹çš„é€šç”¨æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é€šç”¨æ¨ç†` `æ¸¸æˆç¯å¢ƒ` `åŠ¨æ€è¯„ä¼°` `å¼ºåŒ–å­¦ä¹ ` `è¯­è¨€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¯„ä¼°æ–¹æ³•å¤šä¸ºé™æ€åŸºå‡†ï¼Œç¼ºä¹åŠ¨æ€ç”Ÿæˆèƒ½åŠ›ï¼Œé™åˆ¶äº†è¯„ä¼°çš„å¤šæ ·æ€§å’Œé€‚åº”æ€§ã€‚
2. è®ºæ–‡æå‡ºgg-benchï¼Œé€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆæ¸¸æˆç¯å¢ƒï¼Œæ”¯æŒå®æ—¶ç”Ÿæˆæ–°çš„è¯„ä¼°å®ä¾‹ï¼Œå¢å¼ºäº†è¯„ä¼°çš„çµæ´»æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæœ€å…ˆè¿›çš„è¯­è¨€æ¨¡å‹åœ¨gg-benchä¸Šçš„èƒœç‡è¾ƒä½ï¼Œè€Œæ¨ç†æ¨¡å‹è¡¨ç°æ›´ä½³ï¼Œæ˜¾ç¤ºå‡ºä¸åŒæ¨¡å‹çš„æ¨ç†èƒ½åŠ›å·®å¼‚ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬æå‡ºäº†gg-benchï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼°è¯­è¨€æ¨¡å‹é€šç”¨æ¨ç†èƒ½åŠ›çš„æ¸¸æˆç¯å¢ƒé›†åˆã€‚ä¸å¤§å¤šæ•°é™æ€åŸºå‡†æµ‹è¯•ä¸åŒï¼Œgg-benchæ˜¯ä¸€ä¸ªæ•°æ®ç”Ÿæˆè¿‡ç¨‹ï¼Œå¯ä»¥éšæ—¶ç”Ÿæˆæ–°çš„è¯„ä¼°å®ä¾‹ã€‚å…·ä½“è€Œè¨€ï¼Œgg-benché€šè¿‡ï¼ˆ1ï¼‰ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆæ–°æ¸¸æˆçš„è‡ªç„¶è¯­è¨€æè¿°ï¼Œï¼ˆ2ï¼‰åˆ©ç”¨è¯¥æ¨¡å‹å°†æ¯ä¸ªæ¸¸æˆå®ç°ä¸ºGymç¯å¢ƒçš„ä»£ç ï¼Œä»¥åŠï¼ˆ3ï¼‰é€šè¿‡è‡ªæˆ‘å¯¹å¼ˆè®­ç»ƒå¼ºåŒ–å­¦ä¹ ä»£ç†æ¥åˆæˆç”Ÿæˆã€‚æˆ‘ä»¬é€šè¿‡æ¨¡å‹åœ¨æ¸¸æˆæè¿°ã€å½“å‰æ£‹ç›˜çŠ¶æ€å’Œæœ‰æ•ˆç§»åŠ¨åˆ—è¡¨çš„æç¤ºä¸‹ä¸è¿™äº›RLä»£ç†çš„èƒœç‡æ¥è¯„ä¼°è¯­è¨€æ¨¡å‹ã€‚gg-benchå…·æœ‰æŒ‘æˆ˜æ€§ï¼šæœ€å…ˆè¿›çš„LLMå¦‚GPT-4oå’ŒClaude 3.7 Sonnetåœ¨gg-benchä¸Šçš„èƒœç‡ä¸º7-9%ï¼Œè€Œæ¨ç†æ¨¡å‹å¦‚o1ã€o3-miniå’ŒDeepSeek-R1çš„å¹³å‡èƒœç‡ä¸º31-36%ã€‚æˆ‘ä»¬å‘å¸ƒäº†ç”Ÿæˆçš„æ¸¸æˆã€æ•°æ®ç”Ÿæˆè¿‡ç¨‹å’Œè¯„ä¼°ä»£ç ï¼Œä»¥æ”¯æŒæœªæ¥çš„å»ºæ¨¡å·¥ä½œå’ŒåŸºå‡†æ‰©å±•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰è¯„ä¼°è¯­è¨€æ¨¡å‹é€šç”¨æ¨ç†èƒ½åŠ›çš„é™æ€æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•é€‚åº”å¤šå˜çš„è¯„ä¼°éœ€æ±‚ï¼Œé™åˆ¶äº†æ¨¡å‹çš„å…¨é¢è¯„ä¼°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”ŸæˆåŠ¨æ€çš„æ¸¸æˆç¯å¢ƒï¼Œé€šè¿‡è¿™ç§æ–¹å¼å®ç°å®æ—¶ç”Ÿæˆæ–°çš„è¯„ä¼°å®ä¾‹ï¼Œä»¥æé«˜è¯„ä¼°çš„å¤šæ ·æ€§å’Œæœ‰æ•ˆæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œä½¿ç”¨LLMç”Ÿæˆæ¸¸æˆçš„è‡ªç„¶è¯­è¨€æè¿°ï¼›å…¶æ¬¡ï¼Œå°†è¿™äº›æè¿°å®ç°ä¸ºGymç¯å¢ƒä¸­çš„ä»£ç ï¼›æœ€åï¼Œé€šè¿‡è‡ªæˆ‘å¯¹å¼ˆè®­ç»ƒå¼ºåŒ–å­¦ä¹ ä»£ç†ä»¥è¿›è¡Œè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºgg-benchçš„åŠ¨æ€æ•°æ®ç”Ÿæˆèƒ½åŠ›ï¼Œä½¿å¾—è¯„ä¼°è¿‡ç¨‹ä¸å†ä¾èµ–äºé™æ€æ•°æ®é›†ï¼Œä»è€Œèƒ½å¤Ÿæ›´å…¨é¢åœ°è¯„ä¼°è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†LLMç”Ÿæˆæ¸¸æˆæè¿°å’Œä»£ç çš„æ–¹å¼ï¼Œç¡®ä¿ç”Ÿæˆçš„æ¸¸æˆå…·æœ‰å¤šæ ·æ€§å’Œå¤æ‚æ€§ï¼›åŒæ—¶ï¼Œå¼ºåŒ–å­¦ä¹ ä»£ç†çš„è®­ç»ƒé€šè¿‡è‡ªæˆ‘å¯¹å¼ˆè¿›è¡Œï¼Œæå‡äº†è¯„ä¼°çš„çœŸå®æ€§å’ŒæŒ‘æˆ˜æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæœ€å…ˆè¿›çš„è¯­è¨€æ¨¡å‹åœ¨gg-benchä¸Šçš„èƒœç‡ä»…ä¸º7-9%ï¼Œè€Œæ¨ç†æ¨¡å‹å¦‚o1ã€o3-miniå’ŒDeepSeek-R1çš„èƒœç‡åˆ™è¾¾åˆ°31-36%ã€‚è¿™ä¸€ç»“æœæ˜¾ç¤ºäº†ä¸åŒæ¨¡å‹åœ¨æ¨ç†èƒ½åŠ›ä¸Šçš„æ˜¾è‘—å·®å¼‚ï¼Œå¼ºè°ƒäº†gg-benchä½œä¸ºè¯„ä¼°å·¥å…·çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æ¸¸æˆè®¾è®¡å’Œäººå·¥æ™ºèƒ½è¯„ä¼°ç­‰ã€‚gg-benchçš„åŠ¨æ€ç”Ÿæˆèƒ½åŠ›å¯ä»¥ä¸ºæ¨¡å‹çš„æŒç»­æ”¹è¿›æä¾›æ”¯æŒï¼Œæ¨åŠ¨æ™ºèƒ½ä½“åœ¨å¤æ‚ç¯å¢ƒä¸­çš„å­¦ä¹ å’Œé€‚åº”èƒ½åŠ›çš„æå‡ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present gg-bench, a collection of game environments designed to evaluate general reasoning capabilities in language models. Unlike most static benchmarks, gg-bench is a data generating process where new evaluation instances can be generated at will. In particular, gg-bench is synthetically generated by (1) using a large language model (LLM) to generate natural language descriptions of novel games, (2) using the LLM to implement each game in code as a Gym environment, and (3) training reinforcement learning (RL) agents via self-play on the generated games. We evaluate language models by their winrate against these RL agents by prompting models with the game description, current board state, and a list of valid moves, after which models output the moves they wish to take. gg-bench is challenging: state-of-the-art LLMs such as GPT-4o and Claude 3.7 Sonnet achieve winrates of 7-9% on gg-bench using in-context learning, while reasoning models such as o1, o3-mini and DeepSeek-R1 achieve average winrates of 31-36%. We release the generated games, data generation process, and evaluation code in order to support future modeling work and expansion of our benchmark.

