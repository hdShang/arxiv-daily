---
layout: default
title: "Optimizing RAG Pipelines for Arabic: A Systematic Analysis of Core Components"
---

# Optimizing RAG Pipelines for Arabic: A Systematic Analysis of Core Components

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.06339" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.06339v1</a>
  <a href="https://arxiv.org/pdf/2506.06339.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.06339v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.06339v1', 'Optimizing RAG Pipelines for Arabic: A Systematic Analysis of Core Components')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jumana Alsubhi, Mohammad D. Alahmadi, Ahmed Alhusayni, Ibrahim Aldailami, Israa Hamdine, Ahmad Shabana, Yazeed Iskandar, Suhayb Khayyat

**åˆ†ç±»**: cs.IR, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-01

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ä¼˜åŒ–é˜¿æ‹‰ä¼¯è¯­RAGç®¡é“ä»¥æå‡æ£€ç´¢ç”Ÿæˆè´¨é‡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ£€ç´¢å¢å¼ºç”Ÿæˆ` `é˜¿æ‹‰ä¼¯è¯­å¤„ç†` `åµŒå…¥æ¨¡å‹` `é‡æ’åºå™¨` `è‡ªç„¶è¯­è¨€ç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„RAGæ–¹æ³•åœ¨é˜¿æ‹‰ä¼¯è¯­çš„åº”ç”¨ä¸­å­˜åœ¨ç»„ä»¶ä¼˜åŒ–ä¸è¶³çš„é—®é¢˜ï¼Œå½±å“äº†ç”Ÿæˆè´¨é‡å’Œæ£€ç´¢æ•ˆæœã€‚
2. æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ç³»ç»Ÿçš„å®è¯è¯„ä¼°æ–¹æ³•ï¼Œé€šè¿‡RAGASæ¡†æ¶æ¯”è¾ƒå¤šç§RAGç»„ä»¶åœ¨é˜¿æ‹‰ä¼¯è¯­æ•°æ®é›†ä¸Šçš„è¡¨ç°ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå¥å­æ„ŸçŸ¥åˆ†å—ç­–ç•¥å’Œç‰¹å®šåµŒå…¥æ¨¡å‹æ˜¾è‘—æå‡äº†ç”Ÿæˆè´¨é‡å’Œç­”æ¡ˆå¯ä¿¡åº¦ï¼Œæä¾›äº†ä¼˜åŒ–å»ºè®®ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ä½œä¸ºä¸€ç§ç»“åˆæ£€ç´¢ç³»ç»Ÿç²¾åº¦ä¸å¤§å‹è¯­è¨€æ¨¡å‹æµç•…æ€§çš„å¼ºå¤§æ¶æ„ï¼Œå·²åœ¨é«˜èµ„æºè¯­è¨€ä¸­å¾—åˆ°å¹¿æ³›ç ”ç©¶ã€‚ç„¶è€Œï¼Œé’ˆå¯¹é˜¿æ‹‰ä¼¯è¯­çš„RAGç»„ä»¶ä¼˜åŒ–ä»ç„¶è¾ƒå°‘æ¢ç´¢ã€‚æœ¬ç ”ç©¶é€šè¿‡RAGASæ¡†æ¶ï¼Œå¯¹å¤šç§é˜¿æ‹‰ä¼¯è¯­æ•°æ®é›†ä¸­çš„RAGæ ¸å¿ƒç»„ä»¶è¿›è¡Œå…¨é¢å®è¯è¯„ä¼°ï¼Œæ¯”è¾ƒäº†ä¸Šä¸‹æ–‡ç²¾åº¦ã€ä¸Šä¸‹æ–‡å¬å›ã€ç­”æ¡ˆå¯ä¿¡åº¦å’Œç­”æ¡ˆç›¸å…³æ€§å››ä¸ªæ ¸å¿ƒæŒ‡æ ‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºå¥å­çš„åˆ†å—ç­–ç•¥ä¼˜äºå…¶ä»–åˆ†å‰²æ–¹æ³•ï¼Œè€ŒBGE-M3å’ŒMultilingual-E5-largeæ˜¯æœ€æœ‰æ•ˆçš„åµŒå…¥æ¨¡å‹ã€‚å¼•å…¥é‡æ’åºå™¨ï¼ˆbge-reranker-v2-m3ï¼‰æ˜¾è‘—æå‡äº†å¤æ‚æ•°æ®é›†ä¸­çš„ç­”æ¡ˆå¯ä¿¡åº¦ï¼ŒAya-8Båœ¨ç”Ÿæˆè´¨é‡ä¸Šè¶…è¶Šäº†StableLMã€‚è¿™äº›å‘ç°ä¸ºæ„å»ºé«˜è´¨é‡é˜¿æ‹‰ä¼¯è¯­RAGç®¡é“æä¾›äº†é‡è¦è§è§£ï¼Œå¹¶ä¸ºä¸åŒæ–‡æ¡£ç±»å‹çš„ç»„ä»¶é€‰æ‹©æä¾›äº†å®ç”¨æŒ‡å—ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³é˜¿æ‹‰ä¼¯è¯­RAGç®¡é“ä¸­ç»„ä»¶ä¼˜åŒ–ä¸è¶³çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨ç‰¹å®šè¯­è¨€ç¯å¢ƒä¸‹çš„æ€§èƒ½è¡¨ç°ä¸ä½³ï¼Œå½±å“äº†ç”Ÿæˆçš„å‡†ç¡®æ€§å’Œæµç•…æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡ç³»ç»Ÿè¯„ä¼°ä¸åŒRAGç»„ä»¶çš„æ€§èƒ½ï¼Œè¯†åˆ«å‡ºæœ€ä¼˜çš„åˆ†å—ç­–ç•¥ã€åµŒå…¥æ¨¡å‹å’Œé‡æ’åºå™¨ï¼Œä»¥æå‡é˜¿æ‹‰ä¼¯è¯­çš„æ£€ç´¢å’Œç”Ÿæˆæ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨RAGASæ¡†æ¶ï¼Œä¸»è¦æ¨¡å—åŒ…æ‹¬æ•°æ®é›†å‡†å¤‡ã€ç»„ä»¶è¯„ä¼°ã€æ€§èƒ½æ¯”è¾ƒå’Œç»“æœåˆ†æï¼Œæ¶µç›–äº†ä¸Šä¸‹æ–‡ç²¾åº¦ã€å¬å›ç‡ã€ç­”æ¡ˆå¯ä¿¡åº¦å’Œç›¸å…³æ€§ç­‰æŒ‡æ ‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºé’ˆå¯¹é˜¿æ‹‰ä¼¯è¯­çš„ç‰¹å®šéœ€æ±‚ï¼Œæå‡ºäº†å¥å­æ„ŸçŸ¥åˆ†å—ç­–ç•¥å’Œæœ‰æ•ˆçš„åµŒå…¥æ¨¡å‹ï¼Œæ˜¾è‘—æå‡äº†ç”Ÿæˆè´¨é‡ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”å…·æœ‰æ›´é«˜çš„é€‚åº”æ€§å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé€‰æ‹©äº†BGE-M3å’ŒMultilingual-E5-largeä½œä¸ºåµŒå…¥æ¨¡å‹ï¼Œé‡æ’åºå™¨é‡‡ç”¨bge-reranker-v2-m3ï¼ŒæŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç»è¿‡ä¼˜åŒ–ï¼Œä»¥ç¡®ä¿åœ¨å¤æ‚æ•°æ®é›†ä¸Šçš„è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå¥å­æ„ŸçŸ¥åˆ†å—ç­–ç•¥åœ¨ä¸Šä¸‹æ–‡ç²¾åº¦å’Œå¬å›ç‡ä¸Šä¼˜äºå…¶ä»–æ–¹æ³•ï¼ŒBGE-M3å’ŒMultilingual-E5-largeåµŒå…¥æ¨¡å‹åœ¨ç”Ÿæˆè´¨é‡ä¸Šè¡¨ç°æœ€ä½³ã€‚å¼•å…¥é‡æ’åºå™¨åï¼Œå¤æ‚æ•°æ®é›†çš„ç­”æ¡ˆå¯ä¿¡åº¦æ˜¾è‘—æå‡ï¼ŒAya-8Båœ¨ç”Ÿæˆè´¨é‡ä¸Šè¶…è¶ŠStableLMï¼Œå±•ç¤ºäº†ä¼˜åŒ–çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æˆæœå¯å¹¿æ³›åº”ç”¨äºé˜¿æ‹‰ä¼¯è¯­çš„ä¿¡æ¯æ£€ç´¢ã€é—®ç­”ç³»ç»Ÿå’Œå¯¹è¯ç”Ÿæˆç­‰é¢†åŸŸï¼Œæå‡ç›¸å…³åº”ç”¨çš„ç”¨æˆ·ä½“éªŒå’Œä¿¡æ¯è·å–æ•ˆç‡ã€‚æœªæ¥ï¼Œä¼˜åŒ–çš„RAGç®¡é“è¿˜å¯èƒ½æ¨åŠ¨é˜¿æ‹‰ä¼¯è¯­è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ï¼Œä¿ƒè¿›å¤šè¯­è¨€ç¯å¢ƒä¸‹çš„æ™ºèƒ½åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Retrieval-Augmented Generation (RAG) has emerged as a powerful architecture for combining the precision of retrieval systems with the fluency of large language models. While several studies have investigated RAG pipelines for high-resource languages, the optimization of RAG components for Arabic remains underexplored. This study presents a comprehensive empirical evaluation of state-of-the-art RAG components-including chunking strategies, embedding models, rerankers, and language models-across a diverse set of Arabic datasets. Using the RAGAS framework, we systematically compare performance across four core metrics: context precision, context recall, answer faithfulness, and answer relevancy. Our experiments demonstrate that sentence-aware chunking outperforms all other segmentation methods, while BGE-M3 and Multilingual-E5-large emerge as the most effective embedding models. The inclusion of a reranker (bge-reranker-v2-m3) significantly boosts faithfulness in complex datasets, and Aya-8B surpasses StableLM in generation quality. These findings provide critical insights for building high-quality Arabic RAG pipelines and offer practical guidelines for selecting optimal components across different document types.

