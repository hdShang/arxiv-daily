---
layout: default
title: "Voila: Voice-Language Foundation Models for Real-Time Autonomous Interaction and Voice Role-Play"
---

# Voila: Voice-Language Foundation Models for Real-Time Autonomous Interaction and Voice Role-Play

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.02707" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.02707v1</a>
  <a href="https://arxiv.org/pdf/2505.02707.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.02707v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.02707v1', 'Voila: Voice-Language Foundation Models for Real-Time Autonomous Interaction and Voice Role-Play')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yemin Shi, Yu Shu, Siwei Dong, Guangyi Liu, Jaward Sesay, Jingwen Li, Zhiting Hu

**åˆ†ç±»**: cs.AI, cs.CL, cs.SD

**å‘å¸ƒæ—¥æœŸ**: 2025-05-05

**å¤‡æ³¨**: 18 pages, 7 figures, Website: https://voila.maitrix.org

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVoilaä»¥å®ç°å®æ—¶è‡ªä¸»äº’åŠ¨å’Œè¯­éŸ³è§’è‰²æ‰®æ¼”**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯­éŸ³AI` `å®æ—¶äº’åŠ¨` `æƒ…æ„Ÿè¡¨è¾¾` `å…¨åŒå·¥å¯¹è¯` `å¤§å‹è¯­è¨€æ¨¡å‹` `å£°å­¦å»ºæ¨¡` `è¯­éŸ³å®šåˆ¶` `äººæœºäº¤äº’`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¯­éŸ³AIç³»ç»Ÿå¾€å¾€åªèƒ½è¢«åŠ¨å“åº”å‘½ä»¤ï¼Œç¼ºä¹å®æ—¶å’Œæƒ…æ„Ÿè¡¨è¾¾èƒ½åŠ›ï¼Œé™åˆ¶äº†äººæœºäº¤äº’çš„è‡ªç„¶æ€§å’Œæµç•…æ€§ã€‚
2. Voilaé‡‡ç”¨å…¨æ–°çš„ç«¯åˆ°ç«¯æ¶æ„ï¼Œç»“åˆå±‚æ¬¡å¤šå°ºåº¦Transformerï¼Œæ”¯æŒå…¨åŒå·¥å¯¹è¯å’Œä¸°å¯Œçš„å£°å­¦ç‰¹å¾ç”Ÿæˆï¼Œæå‡äº†äº’åŠ¨çš„è‡ªç„¶æ€§ã€‚
3. Voilaå®ç°äº†195æ¯«ç§’çš„å“åº”å»¶è¿Ÿï¼Œè¶…è¶Šäº†äººç±»å¹³å‡ååº”æ—¶é—´ï¼Œå¹¶æ”¯æŒè¶…è¿‡ä¸€ç™¾ä¸‡ä¸ªé¢„æ„å»ºå£°éŸ³ï¼Œå…·æœ‰æé«˜çš„å®šåˆ¶åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

Voilaæ˜¯ä¸€ç§å¤§å‹è¯­éŸ³è¯­è¨€åŸºç¡€æ¨¡å‹ï¼Œæ—¨åœ¨å®ç°ä¸äººç±»çš„è‡ªä¸»ã€å®æ—¶å’Œæƒ…æ„Ÿä¸°å¯Œçš„äº’åŠ¨ã€‚ä¸ä¼ ç»Ÿçš„å‘½ä»¤ååº”ç³»ç»Ÿä¸åŒï¼ŒVoilaèƒ½å¤ŸæŒç»­ç›‘å¬ã€æ¨ç†å¹¶ä¸»åŠ¨å“åº”ï¼Œä¿ƒè¿›æµç•…ä¸”åŠ¨æ€çš„äº¤æµã€‚å…¶å…¨åŒå·¥ã€ä½å»¶è¿Ÿçš„å¯¹è¯èƒ½åŠ›ä½¿å¾—å“åº”æ—¶é—´ä»…ä¸º195æ¯«ç§’ï¼Œè¶…è¶Šäº†äººç±»çš„å¹³å‡ååº”æ—¶é—´ã€‚Voilaçš„å±‚æ¬¡å¤šå°ºåº¦Transformerå°†å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ä¸å¼ºå¤§çš„å£°å­¦å»ºæ¨¡ç›¸ç»“åˆï¼Œæ”¯æŒç”¨æˆ·é€šè¿‡æ–‡æœ¬æŒ‡ä»¤å®šä¹‰è¯´è¯è€…çš„èº«ä»½å’Œè¯­è°ƒç­‰ç‰¹å¾ã€‚æ­¤å¤–ï¼ŒVoilaæ”¯æŒè¶…è¿‡ä¸€ç™¾ä¸‡ä¸ªé¢„æ„å»ºçš„å£°éŸ³ï¼Œå¹¶èƒ½ä»çŸ­è‡³10ç§’çš„éŸ³é¢‘æ ·æœ¬ä¸­é«˜æ•ˆå®šåˆ¶æ–°å£°éŸ³ã€‚Voilaä¸ä»…é€‚ç”¨äºå£è¯­å¯¹è¯ï¼Œè¿˜å¯å¹¿æ³›åº”ç”¨äºè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ã€æ–‡æœ¬è½¬è¯­éŸ³å’Œå¤šè¯­è¨€è¯­éŸ³ç¿»è¯‘ç­‰é¢†åŸŸã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰è¯­éŸ³AIç³»ç»Ÿåœ¨å®æ—¶äº’åŠ¨å’Œæƒ…æ„Ÿè¡¨è¾¾æ–¹é¢çš„ä¸è¶³ï¼Œä¼ ç»Ÿç³»ç»Ÿé€šå¸¸åªèƒ½è¢«åŠ¨å“åº”ç”¨æˆ·å‘½ä»¤ï¼Œç¼ºä¹ä¸»åŠ¨äº¤æµçš„èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šVoilaé€šè¿‡å¼•å…¥å…¨åŒå·¥ã€ä½å»¶è¿Ÿçš„å¯¹è¯èƒ½åŠ›å’Œæƒ…æ„Ÿä¸°å¯Œçš„å£°å­¦å»ºæ¨¡ï¼Œæ„å»ºäº†ä¸€ç§æ–°çš„è¯­éŸ³è¯­è¨€åŸºç¡€æ¨¡å‹ï¼Œèƒ½å¤Ÿå®ç°æ›´åŠ è‡ªç„¶å’ŒåŠ¨æ€çš„äººæœºäº’åŠ¨ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVoilaçš„æ•´ä½“æ¶æ„åŒ…æ‹¬å±‚æ¬¡å¤šå°ºåº¦Transformerï¼Œé›†æˆäº†å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ä¸å£°å­¦å»ºæ¨¡ï¼Œæ”¯æŒç”¨æˆ·é€šè¿‡æ–‡æœ¬æŒ‡ä»¤å®šä¹‰è¯´è¯è€…çš„èº«ä»½å’Œè¯­è°ƒç­‰ç‰¹å¾ã€‚

**å…³é”®åˆ›æ–°**ï¼šVoilaçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶å…¨æ–°çš„ç«¯åˆ°ç«¯æ¶æ„å’Œå±‚æ¬¡å¤šå°ºåº¦Transformerè®¾è®¡ï¼Œä½¿å¾—å…¶åœ¨å“åº”å»¶è¿Ÿå’Œå£°å­¦ç‰¹å¾ç”Ÿæˆä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼ŒVoilaé‡‡ç”¨äº†ä¼˜åŒ–çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ï¼Œèƒ½å¤Ÿä»çŸ­è‡³10ç§’çš„éŸ³é¢‘æ ·æœ¬ä¸­é«˜æ•ˆå®šåˆ¶æ–°å£°éŸ³ï¼Œå¹¶æ”¯æŒè¶…è¿‡ä¸€ç™¾ä¸‡ä¸ªé¢„æ„å»ºå£°éŸ³ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

Voilaåœ¨å®éªŒä¸­å®ç°äº†195æ¯«ç§’çš„å“åº”å»¶è¿Ÿï¼Œæ˜¾è‘—ä½äºäººç±»çš„å¹³å‡ååº”æ—¶é—´ï¼Œä¸”æ”¯æŒè¶…è¿‡ä¸€ç™¾ä¸‡ä¸ªé¢„æ„å»ºå£°éŸ³ã€‚ä¸ä¼ ç»Ÿè¯­éŸ³AIç³»ç»Ÿç›¸æ¯”ï¼ŒVoilaåœ¨è‡ªç„¶æ€§å’Œæƒ…æ„Ÿè¡¨è¾¾æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—æå‡ï¼Œå±•ç¤ºäº†å…¶åœ¨å®æ—¶äº’åŠ¨ä¸­çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Voilaçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼ŒåŒ…æ‹¬æ™ºèƒ½å®¶å±…åŠ©æ‰‹ã€å®¢æœæœºå™¨äººã€æ•™è‚²è¾…å¯¼ã€æ¸¸æˆè§’è‰²æ‰®æ¼”ç­‰ã€‚å…¶é«˜æ•ˆçš„è¯­éŸ³ç”Ÿæˆå’Œæƒ…æ„Ÿè¡¨è¾¾èƒ½åŠ›å°†æå¤§æå‡äººæœºäº¤äº’çš„è‡ªç„¶æ€§å’Œç”¨æˆ·ä½“éªŒï¼Œæ¨åŠ¨ä¸‹ä¸€ä»£äººæœºäº¤äº’æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> A voice AI agent that blends seamlessly into daily life would interact with humans in an autonomous, real-time, and emotionally expressive manner. Rather than merely reacting to commands, it would continuously listen, reason, and respond proactively, fostering fluid, dynamic, and emotionally resonant interactions. We introduce Voila, a family of large voice-language foundation models that make a step towards this vision. Voila moves beyond traditional pipeline systems by adopting a new end-to-end architecture that enables full-duplex, low-latency conversations while preserving rich vocal nuances such as tone, rhythm, and emotion. It achieves a response latency of just 195 milliseconds, surpassing the average human response time. Its hierarchical multi-scale Transformer integrates the reasoning capabilities of large language models (LLMs) with powerful acoustic modeling, enabling natural, persona-aware voice generation -- where users can simply write text instructions to define the speaker's identity, tone, and other characteristics. Moreover, Voila supports over one million pre-built voices and efficient customization of new ones from brief audio samples as short as 10 seconds. Beyond spoken dialogue, Voila is designed as a unified model for a wide range of voice-based applications, including automatic speech recognition (ASR), Text-to-Speech (TTS), and, with minimal adaptation, multilingual speech translation. Voila is fully open-sourced to support open research and accelerate progress toward next-generation human-machine interactions.

