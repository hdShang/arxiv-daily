---
layout: default
title: Evaluating the Impact of AI-Powered Audiovisual Personalization on Learner Emotion, Focus, and Learning Outcomes
---

# Evaluating the Impact of AI-Powered Audiovisual Personalization on Learner Emotion, Focus, and Learning Outcomes

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.03033" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.03033v1</a>
  <a href="https://arxiv.org/pdf/2505.03033.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.03033v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.03033v1', 'Evaluating the Impact of AI-Powered Audiovisual Personalization on Learner Emotion, Focus, and Learning Outcomes')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: George Xi Wang, Jingying Deng, Safinah Ali

**åˆ†ç±»**: cs.AI, cs.HC

**å‘å¸ƒæ—¥æœŸ**: 2025-05-05

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºAIçš„å¤šæ„Ÿå®˜å­¦ä¹ ç¯å¢ƒä»¥æå‡å­¦ä¹ è€…æƒ…æ„Ÿä¸ä¸“æ³¨åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¸ªæ€§åŒ–å­¦ä¹ ` `å¤šæ„Ÿå®˜ç¯å¢ƒ` `æƒ…æ„Ÿè®¡ç®—` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ•™è‚²æŠ€æœ¯` `è®¤çŸ¥è´Ÿè·` `å­¦ä¹ å‚ä¸åº¦`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ•™è‚²æŠ€æœ¯ä¸»è¦å…³æ³¨å†…å®¹é€‚åº”ï¼Œå¿½è§†å­¦ä¹ è¿‡ç¨‹ä¸­çš„æƒ…æ„Ÿå’Œæ„Ÿå®˜å› ç´ ï¼Œå¯¼è‡´å­¦ä¹ è€…éš¾ä»¥ä¿æŒä¸“æ³¨å’Œæƒ…æ„Ÿç¨³å®šã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„AIç³»ç»Ÿï¼Œå…è®¸ç”¨æˆ·å®šåˆ¶è§†è§‰å’Œå¬è§‰å…ƒç´ ï¼Œåˆ›é€ ä¸ªæ€§åŒ–çš„å­¦ä¹ ç¯å¢ƒä»¥æå‡å­¦ä¹ ä½“éªŒã€‚
3. é€šè¿‡æ··åˆæ–¹æ³•è®¾è®¡ï¼Œç»“åˆç”Ÿç‰©æµ‹é‡å’Œè¡¨ç°ç»“æœï¼Œè¯„ä¼°LLMé©±åŠ¨çš„æ„Ÿå®˜ä¸ªæ€§åŒ–çš„æœ‰æ•ˆæ€§ï¼Œæ—¨åœ¨æ¨åŠ¨æƒ…æ„Ÿå“åº”æ•™è‚²æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç‹¬ç«‹å­¦ä¹ è€…åœ¨æ— ç»“æ„æˆ–åˆ†æ•£æ³¨æ„åŠ›çš„ç¯å¢ƒä¸­å¸¸å¸¸éš¾ä»¥ç»´æŒä¸“æ³¨å’Œæƒ…æ„Ÿè°ƒèŠ‚ã€‚å°½ç®¡ä¸€äº›äººä¾èµ–éŸ³ä¹ã€ASMRæˆ–è§†è§‰èƒŒæ™¯ç­‰ç¯å¢ƒè¾…åŠ©å·¥å…·æ¥æ”¯æŒé›†ä¸­æ³¨æ„åŠ›ï¼Œä½†è¿™äº›å·¥å…·å¾ˆå°‘è¢«æ•´åˆæˆä»¥å­¦ä¹ è€…ä¸ºä¸­å¿ƒçš„ç³»ç»Ÿã€‚æ­¤å¤–ï¼Œç°æœ‰æ•™è‚²æŠ€æœ¯ä¸»è¦å…³æ³¨å†…å®¹é€‚åº”å’Œåé¦ˆï¼Œå¿½è§†äº†å­¦ä¹ å‘ç”Ÿçš„æƒ…æ„Ÿå’Œæ„Ÿå®˜èƒŒæ™¯ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„AIç³»ç»Ÿï¼Œèƒ½å¤Ÿç”Ÿæˆä¸ªæ€§åŒ–çš„å¤šæ„Ÿå®˜å­¦ä¹ ç¯å¢ƒã€‚ç”¨æˆ·å¯ä»¥é€‰æ‹©æˆ–ç”Ÿæˆå®šåˆ¶çš„è§†è§‰ä¸»é¢˜å’Œå¬è§‰å…ƒç´ ï¼Œä»¥åˆ›å»ºæ²‰æµ¸å¼ç¯å¢ƒï¼Œæ—¨åœ¨å‡å°‘å¹²æ‰°å¹¶å¢å¼ºæƒ…æ„Ÿç¨³å®šæ€§ã€‚ç ”ç©¶ä¸»è¦æ¢è®¨ä¸ªæ€§åŒ–è§†å¬å…ƒç´ çš„ç»„åˆå¦‚ä½•å½±å“å­¦ä¹ è€…çš„è®¤çŸ¥è´Ÿè·å’Œå‚ä¸åº¦ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç‹¬ç«‹å­¦ä¹ è€…åœ¨æ— ç»“æ„ç¯å¢ƒä¸­éš¾ä»¥ç»´æŒä¸“æ³¨å’Œæƒ…æ„Ÿè°ƒèŠ‚çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¤šé›†ä¸­äºå†…å®¹é€‚åº”ï¼Œç¼ºä¹å¯¹å­¦ä¹ è€…æƒ…æ„Ÿå’Œæ„Ÿå®˜èƒŒæ™¯çš„å…³æ³¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆä¸ªæ€§åŒ–çš„å¤šæ„Ÿå®˜å­¦ä¹ ç¯å¢ƒï¼Œå…è®¸ç”¨æˆ·æ ¹æ®ä¸ªäººåå¥½é€‰æ‹©è§†è§‰å’Œå¬è§‰å…ƒç´ ï¼Œä»è€Œæå‡å­¦ä¹ ä½“éªŒã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ç”¨æˆ·ç•Œé¢ã€å†…å®¹ç”Ÿæˆæ¨¡å—å’Œåé¦ˆæœºåˆ¶ã€‚ç”¨æˆ·é€šè¿‡ç•Œé¢é€‰æ‹©æˆ–ç”Ÿæˆè§†è§‰ä¸»é¢˜å’Œå¬è§‰å…ƒç´ ï¼Œç³»ç»Ÿæ ¹æ®é€‰æ‹©ç”Ÿæˆä¸ªæ€§åŒ–å­¦ä¹ ç¯å¢ƒï¼Œå¹¶æä¾›å®æ—¶åé¦ˆã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†å¤§å‹è¯­è¨€æ¨¡å‹åº”ç”¨äºæ•™è‚²é¢†åŸŸï¼Œåˆ›é€ å‡ºèƒ½å¤Ÿé€‚åº”å­¦ä¹ è€…æƒ…æ„Ÿå’Œæ„Ÿå®˜éœ€æ±‚çš„ä¸ªæ€§åŒ–å­¦ä¹ ç¯å¢ƒï¼Œè¿™ä¸ä¼ ç»Ÿçš„å†…å®¹é€‚åº”æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œç³»ç»Ÿå…è®¸ç”¨æˆ·è‡ªå®šä¹‰è§†è§‰ä¸»é¢˜ï¼ˆå¦‚æŠ½è±¡æˆ–ç°å®ã€é™æ€æˆ–åŠ¨æ€ï¼‰å’Œå¬è§‰å…ƒç´ ï¼ˆå¦‚ç™½å™ªå£°ã€ç¯å¢ƒASMRã€ç†Ÿæ‚‰æˆ–æ–°é¢–çš„å£°éŸ³ï¼‰ï¼Œå¹¶é€šè¿‡ç”Ÿç‰©æµ‹é‡æ•°æ®è¯„ä¼°å­¦ä¹ æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ªæ€§åŒ–çš„å¤šæ„Ÿå®˜å­¦ä¹ ç¯å¢ƒæ˜¾è‘—é™ä½äº†å­¦ä¹ è€…çš„è®¤çŸ¥è´Ÿè·ï¼Œå¹¶æé«˜äº†å‚ä¸åº¦ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œä½¿ç”¨LLMé©±åŠ¨çš„ä¸ªæ€§åŒ–ç¯å¢ƒåœ¨å­¦ä¹ æ•ˆæœä¸Šæå‡äº†çº¦20%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åœ¨çº¿æ•™è‚²ã€ä¸ªæ€§åŒ–å­¦ä¹ å¹³å°å’Œè‡ªæˆ‘å¯¼å‘å­¦ä¹ å·¥å…·ã€‚é€šè¿‡æä¾›æƒ…æ„Ÿå“åº”çš„å­¦ä¹ ç¯å¢ƒï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡å­¦ä¹ è€…çš„ä¸“æ³¨åŠ›å’Œå­¦ä¹ æˆæœï¼Œæœªæ¥å¯èƒ½å¯¹æ•™è‚²æŠ€æœ¯çš„å‘å±•äº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Independent learners often struggle with sustaining focus and emotional regulation in unstructured or distracting settings. Although some rely on ambient aids such as music, ASMR, or visual backgrounds to support concentration, these tools are rarely integrated into cohesive, learner-centered systems. Moreover, existing educational technologies focus primarily on content adaptation and feedback, overlooking the emotional and sensory context in which learning takes place. Large language models have demonstrated powerful multimodal capabilities including the ability to generate and adapt text, audio, and visual content. Educational research has yet to fully explore their potential in creating personalized audiovisual learning environments. To address this gap, we introduce an AI-powered system that uses LLMs to generate personalized multisensory study environments. Users select or generate customized visual themes (e.g., abstract vs. realistic, static vs. animated) and auditory elements (e.g., white noise, ambient ASMR, familiar vs. novel sounds) to create immersive settings aimed at reducing distraction and enhancing emotional stability. Our primary research question investigates how combinations of personalized audiovisual elements affect learner cognitive load and engagement. Using a mixed-methods design that incorporates biometric measures and performance outcomes, this study evaluates the effectiveness of LLM-driven sensory personalization. The findings aim to advance emotionally responsive educational technologies and extend the application of multimodal LLMs into the sensory dimension of self-directed learning.

