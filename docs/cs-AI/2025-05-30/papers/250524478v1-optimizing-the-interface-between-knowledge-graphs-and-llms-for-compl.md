---
layout: default
title: Optimizing the Interface Between Knowledge Graphs and LLMs for Complex Reasoning
---

# Optimizing the Interface Between Knowledge Graphs and LLMs for Complex Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.24478" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.24478v1</a>
  <a href="https://arxiv.org/pdf/2505.24478.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.24478v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.24478v1', 'Optimizing the Interface Between Knowledge Graphs and LLMs for Complex Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Vasilije Markovic, Lazar Obradovic, Laszlo Hajdu, Jovan Pavlovic

**åˆ†ç±»**: cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-30

**å¤‡æ³¨**: This is a preliminary version. A revised and expanded version is in preparation

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ä¼˜åŒ–çŸ¥è¯†å›¾è°±ä¸å¤§è¯­è¨€æ¨¡å‹æ¥å£ä»¥æå‡å¤æ‚æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `çŸ¥è¯†å›¾è°±` `å¤§è¯­è¨€æ¨¡å‹` `è¶…å‚æ•°ä¼˜åŒ–` `å¤æ‚æ¨ç†` `å¤šè·³é—®ç­”` `Cogneeæ¡†æ¶` `æ€§èƒ½æå‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„çŸ¥è¯†å›¾è°±ä¸å¤§è¯­è¨€æ¨¡å‹ç»“åˆçš„ç³»ç»Ÿåœ¨è¶…å‚æ•°ä¼˜åŒ–æ–¹é¢ç ”ç©¶ä¸è¶³ï¼Œå¯¼è‡´æ€§èƒ½æå‡æ½œåŠ›æœªè¢«å……åˆ†æŒ–æ˜ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§ç³»ç»Ÿçš„è¶…å‚æ•°ä¼˜åŒ–æ–¹æ³•ï¼Œé’ˆå¯¹Cogneeæ¡†æ¶ä¸­çš„å¤šä¸ªæ¨¡å—è¿›è¡Œè°ƒä¼˜ï¼Œä»¥æå‡å¤æ‚æ¨ç†ä»»åŠ¡çš„æ€§èƒ½ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œé€šè¿‡é’ˆå¯¹æ€§è°ƒä¼˜å¯ä»¥æ˜¾è‘—æé«˜æ€§èƒ½ï¼Œå°½ç®¡ä¸åŒæ•°æ®é›†å’Œè¯„ä¼°æŒ‡æ ‡çš„æå‡å¹…åº¦å­˜åœ¨å·®å¼‚ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸çŸ¥è¯†å›¾è°±ï¼ˆKGsï¼‰ç»“åˆï¼Œå½¢æˆå¤æ‚ç³»ç»Ÿï¼Œæ¶‰åŠä¼—å¤šè¶…å‚æ•°ç›´æ¥å½±å“æ€§èƒ½ã€‚ç„¶è€Œï¼Œç³»ç»Ÿçš„è¶…å‚æ•°ä¼˜åŒ–ä»æœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚æœ¬æ–‡ç ”ç©¶äº†Cogneeæ¡†æ¶ä¸­çš„è¶…å‚æ•°ä¼˜åŒ–é—®é¢˜ï¼Œä½¿ç”¨ä¸‰ç§å¤šè·³é—®ç­”åŸºå‡†ï¼ˆHotPotQAã€TwoWikiMultiHopå’ŒMuSiQueï¼‰ä¼˜åŒ–ä¸åˆ†å—ã€å›¾æ„å»ºã€æ£€ç´¢å’Œæç¤ºç›¸å…³çš„å‚æ•°ã€‚æ¯ç§é…ç½®ä½¿ç”¨ç²¾ç¡®åŒ¹é…ã€F1å’ŒDeepEvalçš„LLMåŸºäºæ­£ç¡®æ€§æŒ‡æ ‡è¿›è¡Œè¯„åˆ†ã€‚ç»“æœè¡¨æ˜ï¼Œé€šè¿‡æœ‰é’ˆå¯¹æ€§çš„è°ƒä¼˜å¯ä»¥å®ç°æ˜¾è‘—æå‡ï¼Œå°½ç®¡æå‡åœ¨ä¸åŒæ•°æ®é›†å’ŒæŒ‡æ ‡é—´å­˜åœ¨å·®å¼‚ã€‚è¿™ç§å˜å¼‚æ€§çªæ˜¾äº†è°ƒä¼˜çš„ä»·å€¼åŠæ ‡å‡†è¯„ä¼°æªæ–½çš„å±€é™æ€§ã€‚æœªæ¥çš„è¿›å±•ä¸ä»…ä¾èµ–äºæ¶æ„çš„æ”¹è¿›ï¼Œè¿˜éœ€æ›´æ¸…æ™°çš„ä¼˜åŒ–å’Œè¯„ä¼°æ¡†æ¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³çŸ¥è¯†å›¾è°±ä¸å¤§è¯­è¨€æ¨¡å‹ç»“åˆæ—¶è¶…å‚æ•°ä¼˜åŒ–ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤æ‚ç³»ç»Ÿä¸­ç¼ºä¹ç³»ç»Ÿçš„è°ƒä¼˜ç­–ç•¥ï¼Œå¯¼è‡´æ€§èƒ½æå‡ä¸å‡è¡¡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§ç³»ç»ŸåŒ–çš„è¶…å‚æ•°ä¼˜åŒ–æ–¹æ³•ï¼Œé’ˆå¯¹Cogneeæ¡†æ¶çš„ä¸åŒæ¨¡å—è¿›è¡Œè°ƒä¼˜ï¼Œæ—¨åœ¨é€šè¿‡ç²¾ç»†åŒ–çš„å‚æ•°è®¾ç½®æå‡å¤šè·³é—®ç­”çš„æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬çŸ¥è¯†å›¾è°±çš„æ„å»ºã€ä¿¡æ¯æ£€ç´¢å’Œé—®ç­”ç”Ÿæˆä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚æ¯ä¸ªæ¨¡å—çš„è¶…å‚æ•°é€šè¿‡å®éªŒè¿›è¡Œä¼˜åŒ–ï¼Œä»¥å®ç°æ•´ä½“æ€§èƒ½æå‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºç³»ç»ŸåŒ–çš„è¶…å‚æ•°è°ƒä¼˜ç­–ç•¥ï¼Œç»“åˆå¤šç§è¯„ä¼°æŒ‡æ ‡ï¼Œèƒ½å¤Ÿåœ¨å¤æ‚ç³»ç»Ÿä¸­å®ç°æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†æ›´ä¸ºå…¨é¢çš„ä¼˜åŒ–æ¡†æ¶ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œæœ¬æ–‡å…³æ³¨åˆ†å—ç­–ç•¥ã€å›¾æ„å»ºæ–¹æ³•ã€æ£€ç´¢æœºåˆ¶å’Œæç¤ºè®¾è®¡ç­‰å…³é”®å› ç´ ï¼Œé‡‡ç”¨ç²¾ç¡®åŒ¹é…ã€F1å’ŒDeepEvalæŒ‡æ ‡è¿›è¡Œç»¼åˆè¯„ä¼°ã€‚é€šè¿‡è¿™äº›è®¾è®¡ï¼Œç¡®ä¿äº†ä¼˜åŒ–è¿‡ç¨‹çš„æœ‰æ•ˆæ€§å’Œç»“æœçš„å¯é æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé€šè¿‡é’ˆå¯¹æ€§è°ƒä¼˜ï¼Œæ€§èƒ½æå‡æ˜¾è‘—ã€‚åœ¨HotPotQAã€TwoWikiMultiHopå’ŒMuSiQueç­‰åŸºå‡†ä¸Šï¼Œä¼˜åŒ–åçš„æ¨¡å‹åœ¨ç²¾ç¡®åŒ¹é…å’ŒF1æŒ‡æ ‡ä¸Šå‡æœ‰æ˜æ˜¾æ”¹å–„ï¼Œå±•ç¤ºäº†è¶…å‚æ•°è°ƒä¼˜çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€ä¿¡æ¯æ£€ç´¢å’ŒçŸ¥è¯†ç®¡ç†ç­‰ã€‚é€šè¿‡ä¼˜åŒ–çŸ¥è¯†å›¾è°±ä¸å¤§è¯­è¨€æ¨¡å‹çš„ç»“åˆï¼Œå¯ä»¥æå‡å¤æ‚æ¨ç†ä»»åŠ¡çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Integrating Large Language Models (LLMs) with Knowledge Graphs (KGs) results in complex systems with numerous hyperparameters that directly affect performance. While such systems are increasingly common in retrieval-augmented generation, the role of systematic hyperparameter optimization remains underexplored. In this paper, we study this problem in the context of Cognee, a modular framework for end-to-end KG construction and retrieval. Using three multi-hop QA benchmarks (HotPotQA, TwoWikiMultiHop, and MuSiQue) we optimize parameters related to chunking, graph construction, retrieval, and prompting. Each configuration is scored using established metrics (exact match, F1, and DeepEval's LLM-based correctness metric). Our results demonstrate that meaningful gains can be achieved through targeted tuning. While the gains are consistent, they are not uniform, with performance varying across datasets and metrics. This variability highlights both the value of tuning and the limitations of standard evaluation measures. While demonstrating the immediate potential of hyperparameter tuning, we argue that future progress will depend not only on architectural advances but also on clearer frameworks for optimization and evaluation in complex, modular systems.

