---
layout: default
title: SCOUT: Teaching Pre-trained Language Models to Enhance Reasoning via Flow Chain-of-Thought
---

# SCOUT: Teaching Pre-trained Language Models to Enhance Reasoning via Flow Chain-of-Thought

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.24181" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.24181v1</a>
  <a href="https://arxiv.org/pdf/2505.24181.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.24181v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.24181v1', 'SCOUT: Teaching Pre-trained Language Models to Enhance Reasoning via Flow Chain-of-Thought')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Guanghao Li, Wenhao Jiang, Mingfeng Chen, Yan Li, Hao Yu, Shuting Dong, Tao Ren, Ming Tang, Chun Yuan

**ÂàÜÁ±ª**: cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-30

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫SCOUTÊ°ÜÊû∂‰ª•ÊèêÂçáËØ≠Ë®ÄÊ®°ÂûãÊé®ÁêÜËÉΩÂäõ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÈìæÂºèÊÄùÁª¥` `ÈÄíÂΩíÊé®ÁêÜ` `ËØ≠Ë®ÄÊ®°Âûã` `Ëí∏È¶èËÆ≠ÁªÉ` `Êé®ÁêÜËÉΩÂäõ` `Ê∑±Â∫¶Â≠¶‰π†` `Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÈìæÂºèÊÄùÁª¥ÊñπÊ≥ï‰æùËµñ‰∫é‰∏≠Èó¥Êé®ÁêÜÊ≠•È™§ÔºåÈôêÂà∂‰∫ÜÊ®°ÂûãÁöÑÂèØÊâ©Â±ïÊÄßÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ
2. Êú¨ÊñáÊèêÂá∫ÊµÅÂä®ÈìæÂºèÊÄùÁª¥ÔºàFlow CoTÔºâÔºåÈÄöËøáÂ∞ÜÈÄíÂΩíÊé®ÁêÜÂª∫Ê®°‰∏∫ÊΩúÂú®ËÆ§Áü•Áä∂ÊÄÅÁöÑÊ∏êËøõËΩ®ËøπÊù•Ëß£ÂÜ≥Ëøô‰∏ÄÈóÆÈ¢ò„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåSCOUTÂú®ÂÖ´‰∏™Êé®ÁêÜÂü∫ÂáÜ‰∏äÊèêÈ´ò‰∫ÜÂáÜÁ°ÆÊÄßÂíåËß£ÈáäË¥®ÈáèÔºåÂæÆË∞É‰∏ãÊúÄÈ´òÊèêÂçáËææ1.8%„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÈìæÂºèÊÄùÁª¥ÔºàCoTÔºâÊèêÁ§∫ÈÄöËøáÈºìÂä±ÈÄêÊ≠•ÊÄùËÄÉÊù•ÊîπÂñÑÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÁöÑÊé®ÁêÜÊÄßËÉΩ„ÄÇÁÑ∂ËÄåÔºåÂü∫‰∫éCoTÁöÑÊñπÊ≥ï‰æùËµñ‰∫é‰∏≠Èó¥Êé®ÁêÜÊ≠•È™§ÔºåËøôÈôêÂà∂‰∫ÜÂÖ∂ÂèØÊâ©Â±ïÊÄßÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇËøëÊúüÁ†îÁ©∂Êé¢Á¥¢‰∫ÜÈÄíÂΩíÊé®ÁêÜÔºåLLMsÂú®Ëø≠‰ª£‰∏≠ÈáçÁî®ÂÜÖÈÉ®Â±Ç‰ª•Á≤æÁÇºÊΩúÂú®Ë°®Á§∫Ôºå‰ΩÜËøô‰∫õÊñπÊ≥ïÈÄöÂ∏∏ÈúÄË¶ÅÊòÇË¥µÁöÑÈ¢ÑËÆ≠ÁªÉ‰∏îÁº∫‰πèÁ≥ªÁªüÊ°ÜÊû∂„ÄÇ‰∏∫Ê≠§ÔºåÊú¨ÊñáÊèêÂá∫‰∫ÜÊµÅÂä®ÈìæÂºèÊÄùÁª¥ÔºàFlow CoTÔºâÔºåÂ∞ÜÈÄíÂΩíÊé®ÁêÜÂª∫Ê®°‰∏∫ÊΩúÂú®ËÆ§Áü•Áä∂ÊÄÅÁöÑÊ∏êËøõËΩ®Ëøπ„ÄÇSCOUTÔºàÈÄêÊ≠•ËÆ§Áü•‰ºòÂåñ‰ΩøÁî®ÊïôÂ∏àÔºâÊòØ‰∏Ä‰∏™ËΩªÈáèÁ∫ßÂæÆË∞ÉÊ°ÜÊû∂ÔºåËÉΩÂ§üÂÆûÁé∞Flow CoTÈ£éÊ†ºÁöÑÊé®ÁêÜËÄåÊó†ÈúÄÈ¢ÑËÆ≠ÁªÉ„ÄÇÂÆûÈ™åË°®ÊòéÔºåSCOUTÂú®ÂÖ´‰∏™Êé®ÁêÜÂü∫ÂáÜ‰∏äÂùáÊèêÈ´ò‰∫ÜÂáÜÁ°ÆÊÄßÂíåËß£ÈáäË¥®ÈáèÔºåÈ™åËØÅ‰∫ÜÂÖ∂ÊúâÊïàÊÄßÂíåFlow CoTÁöÑÂèØÊâ©Â±ïÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâÈìæÂºèÊÄùÁª¥ÊñπÊ≥ïÂú®Êé®ÁêÜËøáÁ®ã‰∏≠ÂØπ‰∏≠Èó¥Ê≠•È™§ÁöÑ‰æùËµñÔºåÂØºËá¥ÁöÑÂèØÊâ©Â±ïÊÄßÂíåÊ≥õÂåñËÉΩÂäõ‰∏çË∂≥ÁöÑÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊèêÂá∫ÊµÅÂä®ÈìæÂºèÊÄùÁª¥ÔºàFlow CoTÔºâÔºåÂ∞ÜÊé®ÁêÜËøáÁ®ãËßÜ‰∏∫ÊΩúÂú®ËÆ§Áü•Áä∂ÊÄÅÁöÑÊ∏êËøõÊºîÂèòÔºåÈÅøÂÖç‰∫ÜÂØπÊâãÂä®ÁõëÁù£ÁöÑ‰æùËµñ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöSCOUTÊ°ÜÊû∂ÂåÖÂê´ÈÄêÊ≠•Ëí∏È¶èÊ®°ÂùóÂíåÂü∫‰∫é‰∫§ÂèâÊ≥®ÊÑèÂäõÁöÑÂõûÈ°æÊ®°ÂùóÔºåÂâçËÄÖÁî®‰∫éÂØπÈΩêÊØèÊ¨°Ëø≠‰ª£ÁöÑÊïôÂ∏àÊ®°ÂûãÔºåÂêéËÄÖÂàôÊï¥ÂêàÂâçÊ¨°Ëø≠‰ª£ÁöÑËæìÂá∫Ôºå‰øùÊåÅÊ®°ÂûãÁöÑÂéüÂßãËÆ°ÁÆóÊµÅ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöSCOUTÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÂÖ∂ËΩªÈáèÁ∫ßÁöÑÂæÆË∞ÉÊñπÊ≥ïÔºåËÉΩÂ§üÂú®Ê≤°ÊúâÈ¢ÑËÆ≠ÁªÉÁöÑÊÉÖÂÜµ‰∏ãÂÆûÁé∞Flow CoTÈ£éÊ†ºÁöÑÊé®ÁêÜÔºåÊòæËëóÊèêÂçá‰∫ÜÊé®ÁêÜÁöÑÊ∑±Â∫¶ÂíåË¥®Èáè„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöSCOUTÈááÁî®ÈÄêÊ≠•Ëí∏È¶èÂØπÊØèÊ¨°Ëø≠‰ª£ËøõË°å‰ºòÂåñÔºåÂπ∂ËÆæËÆ°‰∫Ü‰∫§ÂèâÊ≥®ÊÑèÂäõÊú∫Âà∂‰ª•Êï¥ÂêàÂéÜÂè≤‰ø°ÊÅØÔºåÁ°Æ‰øùÊé®ÁêÜËøáÁ®ãÁöÑËøûË¥ØÊÄßÂíåÊ∑±Â∫¶„ÄÇÂÖ∑‰ΩìÁöÑÂèÇÊï∞ËÆæÁΩÆÂíåÊçüÂ§±ÂáΩÊï∞ËÆæËÆ°Âú®ÂÆûÈ™å‰∏≠ËøõË°å‰∫ÜËØ¶ÁªÜÈ™åËØÅ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåSCOUTÂú®ÂÖ´‰∏™Êé®ÁêÜÂü∫ÂáÜ‰∏äÂùáÂÆûÁé∞‰∫ÜÂáÜÁ°ÆÊÄßÂíåËß£ÈáäË¥®ÈáèÁöÑÊòæËëóÊèêÂçáÔºåÂæÆË∞É‰∏ãÁöÑÊúÄÈ´òÊèêÂçáËææ1.8%„ÄÇËøô‰∫õÁªìÊûúÈ™åËØÅ‰∫ÜSCOUTÁöÑÊúâÊïàÊÄßÔºåÂπ∂Â±ïÁ§∫‰∫ÜFlow CoT‰Ωú‰∏∫ÂèØÊâ©Â±ïÊé®ÁêÜÊ°ÜÊû∂ÁöÑÂÆûÈôÖÂèØË°åÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ„ÄÅÊô∫ËÉΩÈóÆÁ≠îÁ≥ªÁªüÂíåÊïôËÇ≤ÊäÄÊúØÁ≠â„ÄÇÈÄöËøáÊèêÂçáËØ≠Ë®ÄÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõÔºåSCOUTÂèØ‰ª•Âú®Êõ¥Â§çÊùÇÁöÑ‰ªªÂä°‰∏≠Êèê‰æõÊõ¥ÂáÜÁ°ÆÁöÑÁªìÊûúÔºåÊú™Êù•ÂèØËÉΩÂØπ‰∫∫Êú∫‰∫§‰∫íÂíåËá™Âä®ÂåñÂÜ≥Á≠ñ‰∫ßÁîüÊ∑±ËøúÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Chain of Thought (CoT) prompting improves the reasoning performance of large language models (LLMs) by encouraging step by step thinking. However, CoT-based methods depend on intermediate reasoning steps, which limits scalability and generalization. Recent work explores recursive reasoning, where LLMs reuse internal layers across iterations to refine latent representations without explicit CoT supervision. While promising, these approaches often require costly pretraining and lack a principled framework for how reasoning should evolve across iterations. We address this gap by introducing Flow Chain of Thought (Flow CoT), a reasoning paradigm that models recursive inference as a progressive trajectory of latent cognitive states. Flow CoT frames each iteration as a distinct cognitive stage deepening reasoning across iterations without relying on manual supervision. To realize this, we propose SCOUT (Stepwise Cognitive Optimization Using Teachers), a lightweight fine tuning framework that enables Flow CoT style reasoning without the need for pretraining. SCOUT uses progressive distillation to align each iteration with a teacher of appropriate capacity, and a cross attention based retrospective module that integrates outputs from previous iterations while preserving the models original computation flow. Experiments across eight reasoning benchmarks show that SCOUT consistently improves both accuracy and explanation quality, achieving up to 1.8% gains under fine tuning. Qualitative analyses further reveal that SCOUT enables progressively deeper reasoning across iterations refining both belief formation and explanation granularity. These results not only validate the effectiveness of SCOUT, but also demonstrate the practical viability of Flow CoT as a scalable framework for enhancing reasoning in LLMs.

