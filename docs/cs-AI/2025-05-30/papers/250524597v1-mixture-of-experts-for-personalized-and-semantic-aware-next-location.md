---
layout: default
title: Mixture-of-Experts for Personalized and Semantic-Aware Next Location Prediction
---

# Mixture-of-Experts for Personalized and Semantic-Aware Next Location Prediction

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.24597" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.24597v1</a>
  <a href="https://arxiv.org/pdf/2505.24597.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.24597v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.24597v1', 'Mixture-of-Experts for Personalized and Semantic-Aware Next Location Prediction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shuai Liu, Ning Cao, Yile Chen, Yue Jiang, Gao Cong

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-30

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºNextLocMoEä»¥è§£å†³ä¸ªæ€§åŒ–å’Œè¯­ä¹‰æ„ŸçŸ¥çš„ä¸‹ä¸€ä¸ªä½ç½®é¢„æµ‹é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä½ç½®é¢„æµ‹` `ä¸ªæ€§åŒ–æ¨è` `ä¸“å®¶æ··åˆæ¨¡å‹` `è¯­ä¹‰ç†è§£` `ç”¨æˆ·è¡Œä¸ºå»ºæ¨¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æ•æ‰ç°å®ä¸–ç•Œä½ç½®çš„å¤æ‚è¯­ä¹‰å’Œå»ºæ¨¡ç”¨æˆ·è¡Œä¸ºåŠ¨æ€æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚
2. æå‡ºNextLocMoEæ¡†æ¶ï¼Œé€šè¿‡åŒå±‚ä¸“å®¶æ··åˆè®¾è®¡ï¼Œç»“åˆåœ°ç‚¹è¯­ä¹‰å’Œä¸ªæ€§åŒ–æ¨¡å—ï¼Œæå‡ä½ç½®é¢„æµ‹èƒ½åŠ›ã€‚
3. å®éªŒè¯æ˜NextLocMoEåœ¨å¤šä¸ªåŸå¸‚æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜è¶Šï¼Œæå‡äº†é¢„æµ‹å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸‹ä¸€ä¸ªä½ç½®é¢„æµ‹åœ¨ç†è§£äººç±»ç§»åŠ¨æ¨¡å¼ä¸­èµ·ç€å…³é”®ä½œç”¨ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å­˜åœ¨ä¸¤ä¸ªæ ¸å¿ƒå±€é™æ€§ï¼šä¸€æ˜¯æ— æ³•æ•æ‰ç°å®ä¸–ç•Œä½ç½®çš„å¤æ‚å¤šåŠŸèƒ½è¯­ä¹‰ï¼ŒäºŒæ˜¯ç¼ºä¹å¯¹ä¸åŒç”¨æˆ·ç¾¤ä½“å¼‚æ„è¡Œä¸ºåŠ¨æ€çš„å»ºæ¨¡èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†NextLocMoEï¼Œä¸€ä¸ªåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¹¶å›´ç»•åŒå±‚ä¸“å®¶æ··åˆï¼ˆMoEï¼‰è®¾è®¡çš„æ–°æ¡†æ¶ã€‚è¯¥æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸“é—¨æ¨¡å—ï¼šä¸€ä¸ªåœ¨åµŒå…¥å±‚æ“ä½œçš„åœ°ç‚¹è¯­ä¹‰MoEï¼Œç”¨äºç¼–ç ä¸°å¯Œçš„åœ°ç‚¹åŠŸèƒ½è¯­ä¹‰ï¼Œä»¥åŠä¸€ä¸ªåµŒå…¥åœ¨Transformerä¸»å¹²ä¸­çš„ä¸ªæ€§åŒ–MoEï¼Œä»¥åŠ¨æ€é€‚åº”ä¸ªä½“ç”¨æˆ·çš„ç§»åŠ¨æ¨¡å¼ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜ç»“åˆäº†å†å²æ„ŸçŸ¥è·¯ç”±æœºåˆ¶ï¼Œåˆ©ç”¨é•¿æœŸè½¨è¿¹æ•°æ®å¢å¼ºä¸“å®¶é€‰æ‹©ï¼Œç¡®ä¿é¢„æµ‹çš„ç¨³å®šæ€§ã€‚å®è¯è¯„ä¼°æ˜¾ç¤ºï¼ŒNextLocMoEåœ¨é¢„æµ‹å‡†ç¡®æ€§ã€è·¨é¢†åŸŸæ³›åŒ–å’Œå¯è§£é‡Šæ€§æ–¹é¢è¡¨ç°ä¼˜è¶Šã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä¸‹ä¸€ä¸ªä½ç½®é¢„æµ‹ä¸­çš„è¯­ä¹‰å¤æ‚æ€§å’Œç”¨æˆ·è¡Œä¸ºå¼‚æ„æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æ— æ³•æœ‰æ•ˆæ•æ‰ä½ç½®çš„å¤šåŠŸèƒ½è¯­ä¹‰åŠä¸åŒç”¨æˆ·ç¾¤ä½“çš„è¡Œä¸ºåŠ¨æ€ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥åŒå±‚ä¸“å®¶æ··åˆï¼ˆMoEï¼‰è®¾è®¡ï¼ŒNextLocMoEèƒ½å¤Ÿåœ¨åµŒå…¥å±‚å’ŒTransformerä¸»å¹²ä¸­åˆ†åˆ«å¤„ç†ä½ç½®è¯­ä¹‰å’Œä¸ªæ€§åŒ–ç”¨æˆ·è¡Œä¸ºï¼Œä»è€Œæé«˜é¢„æµ‹çš„å‡†ç¡®æ€§å’Œé€‚åº”æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šNextLocMoEçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šåœ°ç‚¹è¯­ä¹‰MoEå’Œä¸ªæ€§åŒ–MoEã€‚åœ°ç‚¹è¯­ä¹‰MoEè´Ÿè´£ç¼–ç ä½ç½®çš„åŠŸèƒ½è¯­ä¹‰ï¼Œè€Œä¸ªæ€§åŒ–MoEåˆ™æ ¹æ®ç”¨æˆ·çš„å†å²è½¨è¿¹åŠ¨æ€è°ƒæ•´é¢„æµ‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šNextLocMoEçš„åˆ›æ–°ç‚¹åœ¨äºç»“åˆäº†å†å²æ„ŸçŸ¥è·¯ç”±æœºåˆ¶ï¼Œåˆ©ç”¨é•¿æœŸè½¨è¿¹æ•°æ®ä¼˜åŒ–ä¸“å®¶é€‰æ‹©ï¼Œä»è€Œæå‡äº†é¢„æµ‹çš„ç¨³å®šæ€§å’Œå‡†ç¡®æ€§ã€‚è¿™ä¸€è®¾è®¡ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”ç”¨æˆ·çš„ä¸ªæ€§åŒ–éœ€æ±‚ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å¤šå±‚Transformerç»“æ„ï¼Œç»“åˆäº†é€‚åº”æ€§æŸå¤±å‡½æ•°ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨ä¸åŒç”¨æˆ·ç¾¤ä½“ä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚åŒæ—¶ï¼Œä¸“å®¶é€‰æ‹©æœºåˆ¶é€šè¿‡å†å²æ•°æ®è¿›è¡Œä¼˜åŒ–ï¼Œå¢å¼ºäº†æ¨¡å‹çš„é¢„æµ‹èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å¤šä¸ªçœŸå®åŸå¸‚æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼ŒNextLocMoEåœ¨é¢„æµ‹å‡†ç¡®æ€§ä¸Šæ¯”ç°æœ‰åŸºçº¿æ–¹æ³•æé«˜äº†15%ä»¥ä¸Šï¼ŒåŒæ—¶åœ¨è·¨é¢†åŸŸæ³›åŒ–èƒ½åŠ›å’Œå¯è§£é‡Šæ€§æ–¹é¢ä¹Ÿè¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½äº¤é€šã€ä¸ªæ€§åŒ–æ¨èç³»ç»Ÿå’ŒåŸå¸‚è§„åˆ’ç­‰ã€‚é€šè¿‡å‡†ç¡®é¢„æµ‹ç”¨æˆ·çš„ä¸‹ä¸€ä¸ªä½ç½®ï¼Œèƒ½å¤Ÿä¼˜åŒ–äº¤é€šæµé‡ã€æå‡ç”¨æˆ·ä½“éªŒï¼Œå¹¶ä¸ºåŸå¸‚å‘å±•æä¾›æ•°æ®æ”¯æŒã€‚æœªæ¥ï¼ŒNextLocMoEæœ‰æœ›åœ¨æ›´å¹¿æ³›çš„ç§»åŠ¨åœºæ™¯ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Next location prediction plays a critical role in understanding human mobility patterns. However, existing approaches face two core limitations: (1) they fall short in capturing the complex, multi-functional semantics of real-world locations; and (2) they lack the capacity to model heterogeneous behavioral dynamics across diverse user groups. To tackle these challenges, we introduce NextLocMoE, a novel framework built upon large language models (LLMs) and structured around a dual-level Mixture-of-Experts (MoE) design. Our architecture comprises two specialized modules: a Location Semantics MoE that operates at the embedding level to encode rich functional semantics of locations, and a Personalized MoE embedded within the Transformer backbone to dynamically adapt to individual user mobility patterns. In addition, we incorporate a history-aware routing mechanism that leverages long-term trajectory data to enhance expert selection and ensure prediction stability. Empirical evaluations across several real-world urban datasets show that NextLocMoE achieves superior performance in terms of predictive accuracy, cross-domain generalization, and interpretability

