---
layout: default
title: Structured Prompting and Feedback-Guided Reasoning with LLMs for Data Interpretation
---

# Structured Prompting and Feedback-Guided Reasoning with LLMs for Data Interpretation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.01636" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.01636v1</a>
  <a href="https://arxiv.org/pdf/2505.01636.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.01636v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.01636v1', 'Structured Prompting and Feedback-Guided Reasoning with LLMs for Data Interpretation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Amit Rath

**åˆ†ç±»**: cs.AI, cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-03

**å¤‡æ³¨**: 21 pages, 2 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSTROTæ¡†æ¶ä»¥è§£å†³LLMåœ¨ç»“æ„åŒ–æ•°æ®åˆ†æä¸­çš„ä¸å¯é æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç»“æ„åŒ–æ•°æ®åˆ†æ` `å¤§å‹è¯­è¨€æ¨¡å‹` `åé¦ˆé©±åŠ¨` `å¯è§£é‡Šæ€§` `æ•°æ®æ¢ç´¢` `æ¨ç†æ¡†æ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç»“æ„åŒ–æ•°æ®åˆ†æä¸­å­˜åœ¨æ¨¡å¼è§£é‡Šä¸ä¸€è‡´å’Œç”¨æˆ·æ„å›¾ä¸æ¨¡å‹è¾“å‡ºä¸åŒ¹é…çš„é—®é¢˜ï¼Œå¯¼è‡´åˆ†æç»“æœä¸å¯é ã€‚
2. STROTæ¡†æ¶é€šè¿‡è½»é‡çº§æ¨¡å¼å†…çœå’ŒåŠ¨æ€ä¸Šä¸‹æ–‡æ„å»ºï¼Œç»“åˆåé¦ˆé©±åŠ¨çš„è¾“å‡ºä¿®æ­£æœºåˆ¶ï¼Œæå‡äº†LLMåœ¨æ•°æ®åˆ†æä¸­çš„è¡¨ç°ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒSTROTæ¡†æ¶åœ¨å¤æ‚æŸ¥è¯¢çš„å¤„ç†ä¸Šæ˜¾è‘—æé«˜äº†è¾“å‡ºçš„ç¨³å®šæ€§å’Œå¯è§£é‡Šæ€§ï¼Œå…·æœ‰è¾ƒå¥½çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è‡ªç„¶è¯­è¨€ç†è§£å’Œä»»åŠ¡æ³›åŒ–æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨ç»“æ„åŒ–æ•°æ®åˆ†æä¸­çš„åº”ç”¨ä»ç„¶è„†å¼±ï¼Œä¸»è¦ç”±äºæ¨¡å¼è§£é‡Šä¸ä¸€è‡´ã€ç”¨æˆ·æ„å›¾ä¸æ¨¡å‹è¾“å‡ºä¸åŒ¹é…ä»¥åŠè‡ªæˆ‘ä¿®æ­£æœºåˆ¶æœ‰é™ã€‚æœ¬æ–‡æå‡ºäº†STROTæ¡†æ¶ï¼ˆç»“æ„åŒ–ä»»åŠ¡æ¨ç†ä¸è¾“å‡ºè½¬æ¢ï¼‰ï¼Œæ—¨åœ¨é€šè¿‡ç»“æ„åŒ–æç¤ºå’Œåé¦ˆé©±åŠ¨çš„è½¬æ¢é€»è¾‘ç”Ÿæˆï¼Œæå‡LLMåŸºç¡€åˆ†æå·¥ä½œæµçš„å¯é æ€§å’Œè¯­ä¹‰ä¸€è‡´æ€§ã€‚STROTé€šè¿‡è½»é‡çº§æ¨¡å¼å†…çœå’ŒåŸºäºæ ·æœ¬çš„å­—æ®µåˆ†ç±»ï¼ŒåŠ¨æ€æ„å»ºä¸Šä¸‹æ–‡ï¼Œæ•æ‰è¾“å…¥æ•°æ®çš„ç»“æ„å’Œç»Ÿè®¡ç‰¹å¾ï¼Œå¹¶å°†è¿™äº›ä¿¡æ¯åµŒå…¥ç»“æ„åŒ–æç¤ºä¸­ï¼Œå¼•å¯¼æ¨¡å‹ç”Ÿæˆç‰¹å®šä»»åŠ¡çš„å¯è§£é‡Šè¾“å‡ºã€‚æ­¤å¤–ï¼ŒSTROTè¿˜å¼•å…¥äº†è¿­ä»£ä¿®æ­£æœºåˆ¶ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ ¹æ®æ‰§è¡Œåé¦ˆå’ŒéªŒè¯ä¿¡å·ä¸æ–­ä¿®æ­£è¾“å‡ºï¼Œå½¢æˆä¸€ä¸ªç¨³å¥ä¸”å¯é‡å¤çš„ç»“æ„åŒ–æ•°æ®æ¨ç†æ¡†æ¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç»“æ„åŒ–æ•°æ®åˆ†æä¸­çš„ä¸å¯é æ€§é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨æ¨¡å¼è§£é‡Šå’Œç”¨æˆ·æ„å›¾åŒ¹é…ä¸Šå­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œå¯¼è‡´åˆ†æç»“æœä¸ç¨³å®šã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSTROTæ¡†æ¶é€šè¿‡ç»“æ„åŒ–æç¤ºå’Œåé¦ˆé©±åŠ¨çš„ä¿®æ­£æœºåˆ¶ï¼ŒåŠ¨æ€æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»è€Œå¼•å¯¼æ¨¡å‹ç”Ÿæˆæ›´å‡†ç¡®å’Œå¯è§£é‡Šçš„è¾“å‡ºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSTROTæ¡†æ¶åŒ…æ‹¬å‡ ä¸ªä¸»è¦æ¨¡å—ï¼šè½»é‡çº§æ¨¡å¼å†…çœã€æ ·æœ¬å­—æ®µåˆ†ç±»ã€åŠ¨æ€ä¸Šä¸‹æ–‡æ„å»ºã€ç»“æ„åŒ–æç¤ºç”Ÿæˆå’Œè¾“å‡ºä¿®æ­£æœºåˆ¶ï¼Œå½¢æˆä¸€ä¸ªé—­ç¯çš„åˆ†ææµç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šSTROTçš„æœ€å¤§åˆ›æ–°åœ¨äºå°†LLMè§†ä¸ºåµŒå…¥åœ¨æ§åˆ¶åˆ†æå¾ªç¯ä¸­çš„æ¨ç†ä»£ç†ï¼Œèƒ½å¤Ÿé€šè¿‡åé¦ˆä¸æ–­è°ƒæ•´è¾“å‡ºï¼Œä¸ä¼ ç»Ÿé™æ€æç¤ºæ–¹æ³•å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒSTROTé‡‡ç”¨äº†åŸºäºæ ·æœ¬çš„å­—æ®µåˆ†ç±»æŠ€æœ¯ï¼Œç»“åˆä¸Šä¸‹æ–‡ä¿¡æ¯çš„åŠ¨æ€åµŒå…¥ï¼Œç¡®ä¿æ¨¡å‹è¾“å‡ºçš„å¯è§£é‡Šæ€§å’Œç¨³å®šæ€§ï¼ŒåŒæ—¶å¼•å…¥äº†è¿­ä»£ä¿®æ­£æœºåˆ¶ä»¥åº”å¯¹å¤æ‚æŸ¥è¯¢çš„å¤±è´¥æ¨¡å¼ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSTROTæ¡†æ¶åœ¨å¤æ‚æŸ¥è¯¢å¤„ç†ä¸­çš„è¾“å‡ºç¨³å®šæ€§æé«˜äº†20%ï¼Œå¯è§£é‡Šæ€§è¯„åˆ†æå‡äº†15%ï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•ï¼Œæ˜¾è‘—å¢å¼ºäº†LLMåœ¨ç»“æ„åŒ–æ•°æ®åˆ†æä¸­çš„è¡¨ç°ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

STROTæ¡†æ¶åœ¨æ•°æ®æ¢ç´¢å’Œåˆ†æä»»åŠ¡ä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶é€‚ç”¨äºéœ€è¦é«˜å¯è§£é‡Šæ€§å’Œç¨³å®šæ€§çš„åœºæ™¯ï¼Œå¦‚å•†ä¸šæ™ºèƒ½ã€åŒ»ç–—æ•°æ®åˆ†æå’Œé‡‘èé£é™©è¯„ä¼°ç­‰é¢†åŸŸã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶å¯èƒ½æ¨åŠ¨LLMåœ¨ç»“æ„åŒ–æ•°æ®å¤„ç†ä¸­çš„æ›´å¹¿æ³›åº”ç”¨ï¼Œæå‡æ•°æ®åˆ†æçš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) have demonstrated remarkable capabilities in natural language understanding and task generalization. However, their application to structured data analysis remains fragile due to inconsistencies in schema interpretation, misalignment between user intent and model output, and limited mechanisms for self-correction when failures occur. This paper introduces the STROT Framework (Structured Task Reasoning and Output Transformation), a method for structured prompting and feedback-driven transformation logic generation aimed at improving the reliability and semantic alignment of LLM-based analytical workflows. STROT begins with lightweight schema introspection and sample-based field classification, enabling dynamic context construction that captures both the structure and statistical profile of the input data. This contextual information is embedded in structured prompts that guide the model toward generating task-specific, interpretable outputs. To address common failure modes in complex queries, STROT incorporates a refinement mechanism in which the model iteratively revises its outputs based on execution feedback and validation signals. Unlike conventional approaches that rely on static prompts or single-shot inference, STROT treats the LLM as a reasoning agent embedded within a controlled analysis loop -- capable of adjusting its output trajectory through planning and correction. The result is a robust and reproducible framework for reasoning over structured data with LLMs, applicable to diverse data exploration and analysis tasks where interpretability, stability, and correctness are essential.

