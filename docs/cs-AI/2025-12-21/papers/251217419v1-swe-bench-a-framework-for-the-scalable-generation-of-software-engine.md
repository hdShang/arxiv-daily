---
layout: default
title: SWE-Bench++: A Framework for the Scalable Generation of Software Engineering Benchmarks from Open-Source Repositories
---

# SWE-Bench++: A Framework for the Scalable Generation of Software Engineering Benchmarks from Open-Source Repositories

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.17419" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.17419v1</a>
  <a href="https://arxiv.org/pdf/2512.17419.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.17419v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.17419v1', 'SWE-Bench++: A Framework for the Scalable Generation of Software Engineering Benchmarks from Open-Source Repositories')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Lilin Wang, Lucas Ramalho, Alan Celestino, Phuc Anthony Pham, Yu Liu, Umang Kumar Sinha, Andres Portillo, Onassis Osunwa, Gabriel Maduekwe

**åˆ†ç±»**: cs.SE, cs.AI, cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-12-19

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**SWE-Bench++ï¼šä¸€ä¸ªä»å¼€æºä»“åº“å¤§è§„æ¨¡ç”Ÿæˆè½¯ä»¶å·¥ç¨‹åŸºå‡†çš„æ¡†æ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è½¯ä»¶å·¥ç¨‹åŸºå‡†` `ä»£ç ç”Ÿæˆ` `å¤§å‹è¯­è¨€æ¨¡å‹` `è‡ªåŠ¨åŒ–æµ‹è¯•` `å¼€æºä»“åº“`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è½¯ä»¶å·¥ç¨‹åŸºå‡†æ•°æ®é›†ä¾èµ–æ‰‹åŠ¨ç»´æŠ¤ï¼Œè§„æ¨¡æœ‰é™ï¼Œä¸”ä¸»è¦é›†ä¸­äºPython bugä¿®å¤ï¼Œéš¾ä»¥å……åˆ†è¯„ä¼°LLMåœ¨å¤šæ ·åŒ–åœºæ™¯ä¸‹çš„ä»£ç ç”Ÿæˆèƒ½åŠ›ã€‚
2. SWE-Bench++é€šè¿‡è‡ªåŠ¨åŒ–æµç¨‹ä»GitHub pull requestä¸­æå–çœŸå®ä¸–ç•Œçš„ç¼–ç ä»»åŠ¡ï¼Œè¦†ç›–å¤šç§ç¼–ç¨‹è¯­è¨€å’Œä»»åŠ¡ç±»å‹ï¼Œä»è€Œæ„å»ºå¤§è§„æ¨¡ã€åŠ¨æ€çš„åŸºå‡†æ•°æ®é›†ã€‚
3. å®éªŒè¡¨æ˜ï¼Œå½“å‰æœ€å…ˆè¿›çš„æ¨¡å‹åœ¨SWE-Bench++ä¸Šè¡¨ç°ä»æœ‰æå‡ç©ºé—´ï¼Œä¸”ä½¿ç”¨SWE-Bench++è¿›è¡Œå¾®è°ƒå¯ä»¥æœ‰æ•ˆæå‡æ¨¡å‹åœ¨å…¶ä»–åŸºå‡†ä¸Šçš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

SWE-Bench++æ˜¯ä¸€ä¸ªè‡ªåŠ¨åŒ–çš„æ¡†æ¶ï¼Œç”¨äºä»å¼€æºGitHubé¡¹ç›®ä¸­ç”Ÿæˆä»“åº“çº§åˆ«çš„ç¼–ç ä»»åŠ¡ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰è½¯ä»¶å·¥ç¨‹åŸºå‡†æ•°æ®é›†è§„æ¨¡å°ã€æ‰‹åŠ¨ç»´æŠ¤ã€é™æ€ä»¥åŠä¸»è¦é›†ä¸­äºPython bugä¿®å¤çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡æ”¶é›†çœŸå®çš„pull requestï¼Œè¦†ç›–äº†11ç§ç¼–ç¨‹è¯­è¨€çš„bugä¿®å¤å’ŒåŠŸèƒ½è¯·æ±‚ã€‚SWE-Bench++é€šè¿‡å››ä¸ªé˜¶æ®µå°†GitHub pull requestè½¬åŒ–ä¸ºå¯å¤ç°çš„ã€åŸºäºæ‰§è¡Œçš„ä»»åŠ¡ï¼šç¨‹åºåŒ–èµ„æºè·å–ã€ç¯å¢ƒåˆæˆã€æµ‹è¯•é¢„è¨€æå–å’Œè´¨é‡ä¿è¯ã€‚æ­¤å¤–ï¼Œè¿˜åŒ…å«ä¸€ä¸ªæç¤ºå¼•å¯¼çš„è½¨è¿¹åˆæˆæ­¥éª¤ï¼Œå°†å¼ºæ¨¡å‹éš¾ä»¥è§£å†³çš„å®ä¾‹è½¬åŒ–ä¸ºè®­ç»ƒè½¨è¿¹ã€‚åˆå§‹åŸºå‡†åŒ…å«æ¥è‡ª3971ä¸ªä»“åº“çš„11133ä¸ªå®ä¾‹ï¼Œæ¶µç›–11ç§è¯­è¨€ã€‚åœ¨åŒ…å«1782ä¸ªå®ä¾‹çš„å­é›†ä¸Šï¼Œå½“å‰æœ€å¼ºçš„æ¨¡å‹è¡¨ç°å¦‚ä¸‹ï¼šclaude-sonnet-4.5è¾¾åˆ°36.20%çš„pass@10ï¼Œgpt-5-2025-08-07è¾¾åˆ°34.57%ï¼Œgemini/gemini-2.5-proè¾¾åˆ°24.92%ï¼Œgpt-4oè¾¾åˆ°16.89%ã€‚é€šè¿‡åœ¨SWE-Bench++å®ä¾‹ä¸Šè¿›è¡Œå¾®è°ƒï¼Œå¯ä»¥æ˜¾è‘—æé«˜SWE-bench MultilingualåŸºå‡†ä¸Šçš„æ€§èƒ½ï¼Œè¯æ˜äº†è¯¥æ•°æ®é›†çš„æœ‰æ•ˆæ€§ã€‚SWE-Bench++ä¸ºè¯„ä¼°å’Œæ”¹è¿›ä»“åº“çº§åˆ«çš„ä»£ç ç”Ÿæˆæä¾›äº†ä¸€ä¸ªå¯æ‰©å±•çš„å¤šè¯­è¨€åŸºå‡†ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰è½¯ä»¶å·¥ç¨‹åŸºå‡†ï¼ˆå¦‚SWE-benchï¼‰ä¸»è¦ä¾èµ–äºæ‰‹åŠ¨æ„å»ºï¼Œå­˜åœ¨è§„æ¨¡æœ‰é™ã€æ•°æ®é™æ€ã€ä»¥åŠä¸»è¦å…³æ³¨Python bugä¿®å¤ç­‰é—®é¢˜ã€‚è¿™äº›å±€é™æ€§ä½¿å¾—å®ƒä»¬éš¾ä»¥å……åˆ†è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨çœŸå®è½¯ä»¶å¼€å‘åœºæ™¯ä¸­çš„ä»£ç ç”Ÿæˆèƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†å¤šç§ç¼–ç¨‹è¯­è¨€å’Œå¤æ‚ä»»åŠ¡ï¼ˆå¦‚åŠŸèƒ½æ·»åŠ ï¼‰æ—¶ã€‚ç°æœ‰æ–¹æ³•çš„ç—›ç‚¹åœ¨äºç¼ºä¹è‡ªåŠ¨åŒ–ã€å¯æ‰©å±•çš„æ•°æ®ç”Ÿæˆæµç¨‹ï¼Œä»¥åŠå¯¹å¤šæ ·åŒ–è½¯ä»¶å·¥ç¨‹ä»»åŠ¡çš„è¦†ç›–ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSWE-Bench++çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è‡ªåŠ¨åŒ–åœ°ä»å¼€æºGitHubä»“åº“ä¸­æå–pull requestï¼ˆPRï¼‰ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºå¯æ‰§è¡Œçš„ã€åŸºäºæµ‹è¯•çš„è½¯ä»¶å·¥ç¨‹ä»»åŠ¡ã€‚è¿™ç§æ–¹æ³•åˆ©ç”¨äº†çœŸå®ä¸–ç•Œè½¯ä»¶å¼€å‘æ´»åŠ¨çš„è‡ªç„¶æ•°æ®ï¼Œé¿å…äº†äººå·¥åˆæˆæ•°æ®çš„å±€é™æ€§ã€‚é€šè¿‡ç¨‹åºåŒ–çš„æ–¹å¼å¤„ç†PRï¼Œå¯ä»¥å¤§è§„æ¨¡åœ°ç”ŸæˆåŒ…å«bugä¿®å¤å’ŒåŠŸèƒ½è¯·æ±‚ç­‰å¤šç§ä»»åŠ¡ç±»å‹çš„åŸºå‡†æ•°æ®é›†ï¼Œå¹¶è¦†ç›–å¤šç§ç¼–ç¨‹è¯­è¨€ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSWE-Bench++çš„æ•´ä½“æ¡†æ¶åŒ…å«å››ä¸ªä¸»è¦é˜¶æ®µï¼š1) **ç¨‹åºåŒ–èµ„æºè·å–**ï¼šè‡ªåŠ¨ä»GitHubä»“åº“ä¸­ç­›é€‰å’Œä¸‹è½½åˆé€‚çš„pull requestã€‚2) **ç¯å¢ƒåˆæˆ**ï¼šä¸ºæ¯ä¸ªpull requestæ„å»ºä¸€ä¸ªå¯å¤ç°çš„æ‰§è¡Œç¯å¢ƒï¼ŒåŒ…æ‹¬ä¾èµ–é¡¹å’Œå¿…è¦çš„é…ç½®ã€‚3) **æµ‹è¯•é¢„è¨€æå–**ï¼šä»pull requestä¸­æå–æµ‹è¯•ç”¨ä¾‹ï¼Œä½œä¸ºè¯„ä¼°ä»£ç ç”Ÿæˆè´¨é‡çš„æ ‡å‡†ã€‚4) **è´¨é‡ä¿è¯**ï¼šå¯¹ç”Ÿæˆçš„ä»»åŠ¡è¿›è¡ŒéªŒè¯ï¼Œç¡®ä¿å…¶æœ‰æ•ˆæ€§å’Œå¯æ‰§è¡Œæ€§ã€‚æ­¤å¤–ï¼Œè¿˜æœ‰ä¸€ä¸ª**æç¤ºå¼•å¯¼çš„è½¨è¿¹åˆæˆ**æ­¥éª¤ï¼Œç”¨äºå°†æ¨¡å‹éš¾ä»¥è§£å†³çš„å®ä¾‹è½¬åŒ–ä¸ºè®­ç»ƒè½¨è¿¹ï¼Œä»¥æå‡æ¨¡å‹çš„å­¦ä¹ æ•ˆæœã€‚

**å…³é”®åˆ›æ–°**ï¼šSWE-Bench++çš„å…³é”®åˆ›æ–°åœ¨äºå…¶å®Œå…¨è‡ªåŠ¨åŒ–çš„æ•°æ®ç”Ÿæˆæµç¨‹ï¼Œä»¥åŠå¯¹çœŸå®ä¸–ç•Œpull requestçš„åˆ©ç”¨ã€‚ä¸ä»¥å¾€ä¾èµ–äººå·¥æˆ–åˆæˆæ•°æ®çš„æ–¹æ³•ä¸åŒï¼ŒSWE-Bench++èƒ½å¤Ÿå¤§è§„æ¨¡åœ°ç”Ÿæˆå¤šæ ·åŒ–çš„ã€è´´è¿‘å®é™…è½¯ä»¶å¼€å‘åœºæ™¯çš„åŸºå‡†æ•°æ®é›†ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶è¿˜æ”¯æŒå¤šç§ç¼–ç¨‹è¯­è¨€ï¼Œå¹¶è¦†ç›–äº†bugä¿®å¤å’ŒåŠŸèƒ½è¯·æ±‚ç­‰å¤šç§ä»»åŠ¡ç±»å‹ï¼Œä»è€Œæ›´å…¨é¢åœ°è¯„ä¼°LLMsçš„ä»£ç ç”Ÿæˆèƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç¨‹åºåŒ–èµ„æºè·å–é˜¶æ®µï¼Œéœ€è¦è®¾è®¡æœ‰æ•ˆçš„ç­›é€‰ç­–ç•¥ï¼Œä»¥é€‰æ‹©é«˜è´¨é‡çš„pull requestã€‚åœ¨ç¯å¢ƒåˆæˆé˜¶æ®µï¼Œéœ€è¦è§£å†³ä¾èµ–é¡¹ç®¡ç†å’Œç¯å¢ƒé…ç½®çš„é—®é¢˜ï¼Œç¡®ä¿ä»»åŠ¡çš„å¯å¤ç°æ€§ã€‚åœ¨æµ‹è¯•é¢„è¨€æå–é˜¶æ®µï¼Œéœ€è¦è®¾è®¡ç®—æ³•ä»pull requestçš„æè¿°å’Œä»£ç å˜æ›´ä¸­è‡ªåŠ¨æå–æµ‹è¯•ç”¨ä¾‹ã€‚æç¤ºå¼•å¯¼çš„è½¨è¿¹åˆæˆæ­¥éª¤ï¼Œéœ€è¦è®¾è®¡æœ‰æ•ˆçš„æç¤ºç­–ç•¥ï¼Œå¼•å¯¼æ¨¡å‹é€æ­¥è§£å†³å¤æ‚é—®é¢˜ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.17419v1/images/framework-swe-bench-plus.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.17419v1/images/repos-resolved-by-type.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.17419v1/images/difficulty-distribution.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

SWE-Bench++åŸºå‡†æ•°æ®é›†åŒ…å«æ¥è‡ª3971ä¸ªä»“åº“çš„11133ä¸ªå®ä¾‹ï¼Œè¦†ç›–11ç§ç¼–ç¨‹è¯­è¨€ã€‚åœ¨åŒ…å«1782ä¸ªå®ä¾‹çš„å­é›†ä¸Šï¼Œå½“å‰æœ€å¼ºçš„æ¨¡å‹claude-sonnet-4.5è¾¾åˆ°äº†36.20%çš„pass@10ï¼Œgpt-5-2025-08-07è¾¾åˆ°äº†34.57%ã€‚å®éªŒè¿˜è¡¨æ˜ï¼Œä½¿ç”¨SWE-Bench++è¿›è¡Œå¾®è°ƒå¯ä»¥æ˜¾è‘—æé«˜æ¨¡å‹åœ¨SWE-bench MultilingualåŸºå‡†ä¸Šçš„æ€§èƒ½ï¼ŒéªŒè¯äº†è¯¥æ•°æ®é›†çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SWE-Bench++å¯ç”¨äºè¯„ä¼°å’Œæ”¹è¿›å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è½¯ä»¶å·¥ç¨‹ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œä¾‹å¦‚ä»£ç ç”Ÿæˆã€ä»£ç ä¿®å¤å’Œä»£ç ç†è§£ã€‚è¯¥åŸºå‡†æ•°æ®é›†å¯ä»¥ä¿ƒè¿›è½¯ä»¶å·¥ç¨‹é¢†åŸŸçš„è‡ªåŠ¨åŒ–å’Œæ™ºèƒ½åŒ–ï¼Œå¸®åŠ©å¼€å‘è€…æ›´é«˜æ•ˆåœ°å®Œæˆç¼–ç ä»»åŠ¡ã€‚æ­¤å¤–ï¼ŒSWE-Bench++è¿˜å¯ä»¥ç”¨äºè®­ç»ƒå’Œå¾®è°ƒä»£ç ç”Ÿæˆæ¨¡å‹ï¼Œæå‡å…¶åœ¨å®é™…è½¯ä»¶å¼€å‘åœºæ™¯ä¸­çš„åº”ç”¨èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Benchmarks like SWE-bench have standardized the evaluation of Large Language Models (LLMs) on repository-level software engineering tasks. However, these efforts remain limited by manual curation, static datasets, and a focus on Python-based bug fixes. We introduce SWE-Bench++, an automated framework that generates repository-level coding tasks from open-source GitHub projects. Unlike synthetic approaches, our pipeline harvests live pull requests to cover both bug fixes and feature requests across 11 languages. SWE-Bench++ turns GitHub pull requests (PRs) into reproducible, execution-based tasks via four stages: programmatic sourcing, environment synthesis, test oracle extraction, and quality assurance. A final hint-guided trajectory synthesis step converts instances that strong models fail on into training trajectories. Our initial benchmark consists of 11,133 instances from 3,971 repositories across 11 languages. On a subset of 1,782 instances of this benchmark, today's strongest models perform as follows: claude-sonnet-4.5 achieves 36.20% pass@10, gpt-5-2025-08-07 34.57%, gemini/gemini-2.5-pro 24.92%, and gpt-4o 16.89%. We further demonstrate the utility of our dataset by showing that fine-tuning on SWE-Bench++ instances yields measurable improvements on the SWE-bench Multilingual benchmark. SWE-Bench++ provides a scalable, multilingual benchmark for evaluating and improving repository-level code generation.

