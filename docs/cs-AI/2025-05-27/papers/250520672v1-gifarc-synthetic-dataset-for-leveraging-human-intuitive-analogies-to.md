---
layout: default
title: "GIFARC: Synthetic Dataset for Leveraging Human-Intuitive Analogies to Elevate AI Reasoning"
---

# GIFARC: Synthetic Dataset for Leveraging Human-Intuitive Analogies to Elevate AI Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20672" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.20672v1</a>
  <a href="https://arxiv.org/pdf/2505.20672.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20672v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20672v1', 'GIFARC: Synthetic Dataset for Leveraging Human-Intuitive Analogies to Elevate AI Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Woochang Sim, Hyunseok Ryu, Kyungmin Choi, Sungwon Han, Sundong Kim

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGIFARCä»¥æå‡AIæ¨ç†èƒ½åŠ›ï¼Œè§£å†³ARCæŒ‘æˆ˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç±»æ¯”æ¨ç†` `æ·±åº¦å­¦ä¹ ` `è§†è§‰-è¯­è¨€æ¨¡å‹` `æ•°æ®åˆæˆ` `äººå·¥æ™ºèƒ½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨ARCä»»åŠ¡ä¸Šè¡¨ç°ä¸ä½³ï¼Œå‡†ç¡®ç‡ä»…ä¸º40-55%ï¼Œæ˜¾ç¤ºå‡ºä¸äººç±»æ¨ç†èƒ½åŠ›çš„æ˜¾è‘—å·®è·ã€‚
2. æœ¬æ–‡æå‡ºGIFARCæ•°æ®é›†ï¼Œé€šè¿‡ç±»æ¯”å¯å‘çš„æ–¹å¼åˆæˆARCé£æ ¼ä»»åŠ¡ï¼Œå¸®åŠ©AIæ›´å¥½åœ°ç†è§£å’Œè§£å†³é—®é¢˜ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨GIFARCå¼•å¯¼çš„LLMåœ¨ä»»åŠ¡æ±‚è§£ä¸Šè¡¨ç°å‡ºæ›´ç¬¦åˆäººç±»ç±»æ¯”æ€ç»´çš„æ–¹å¼ï¼Œæå‡äº†æ±‚è§£æ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æŠ½è±¡ä¸æ¨ç†è¯­æ–™åº“ï¼ˆARCï¼‰å¯¹é€šç”¨AIèƒ½åŠ›æå‡ºäº†ä¸¥æ ¼çš„æµ‹è¯•ï¼Œè¦æ±‚æ±‚è§£è€…ä»å°‘é‡ç¤ºä¾‹ä¸­æ¨æ–­æŠ½è±¡æ¨¡å¼ã€‚å°½ç®¡æ·±åº¦å­¦ä¹ å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œæœ€æ–°æ¨¡å‹åœ¨2024å¹´ARCç«èµ›ä¸­çš„å‡†ç¡®ç‡ä»ä»…ä¸º40-55%ï¼Œæ˜¾ç¤ºå‡ºå…¶æ€§èƒ½ä¸äººç±»æ¨ç†ä¹‹é—´çš„æ˜¾è‘—å·®è·ã€‚æœ¬æ–‡é€šè¿‡å¼•å…¥ç±»æ¯”å¯å‘çš„ARCæ•°æ®é›†GIFARCï¼Œæ—¨åœ¨å¼¥è¡¥è¿™ä¸€å·®è·ã€‚æˆ‘ä»¬åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œè§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰ï¼Œä»åŒ…å«ç±»æ¯”çš„GIFå›¾åƒä¸­åˆæˆæ–°çš„ARCé£æ ¼ä»»åŠ¡ã€‚æ¯ä¸ªæ–°ä»»åŠ¡éƒ½é…æœ‰çœŸå®çš„ç±»æ¯”ï¼Œæ˜ç¡®æ˜ å°„è§†è§‰å˜æ¢ä¸æ—¥å¸¸æ¦‚å¿µã€‚é€šè¿‡å°†ç¨³å¥çš„äººç±»ç›´è§‚ç±»æ¯”åµŒå…¥ARCé£æ ¼ä»»åŠ¡ï¼ŒGIFARCå¼•å¯¼AIä»£ç†åœ¨è¿›è¡Œå¼ºåŠ›æ¨¡å¼æœç´¢ä¹‹å‰ï¼Œå…ˆè¿›è¡Œç±»æ¯”è¯„ä¼°ï¼Œä»è€Œæœ‰æ•ˆé™ä½é—®é¢˜å¤æ‚æ€§ï¼Œæ„å»ºæ›´ç®€æ´ä¸”æ˜“äºäººç±»ç†è§£çš„è§£å†³æ–¹æ¡ˆã€‚æˆ‘ä»¬å®è¯éªŒè¯äº†ä½¿ç”¨GIFARCå¼•å¯¼LLMçš„ç±»æ¯”æ–¹æ³•å¯¹ä»»åŠ¡æ±‚è§£æ–¹å¼çš„å½±å“ï¼Œä½¿å…¶æ›´ç¬¦åˆäººç±»çš„ç±»æ¯”æ€ç»´ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨ARCä»»åŠ¡ä¸­æ¨ç†èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨é¢å¯¹æŠ½è±¡æ¨¡å¼æ—¶çš„è¡¨ç°ä¸ä½³ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚ç±»æ¯”ä»»åŠ¡æ—¶ç¼ºä¹æœ‰æ•ˆçš„å¼•å¯¼ï¼Œå¯¼è‡´æ€§èƒ½ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼•å…¥ç±»æ¯”å¯å‘çš„æ–¹å¼ï¼Œåˆ©ç”¨GIFå›¾åƒåˆæˆæ–°çš„ARCä»»åŠ¡ï¼Œä»è€Œå¸®åŠ©AIåœ¨è§£å†³é—®é¢˜æ—¶è¿›è¡Œç±»æ¯”æ¨ç†ï¼Œé™ä½é—®é¢˜å¤æ‚æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®åˆæˆæ¨¡å—ã€ç±»æ¯”æ˜ å°„æ¨¡å—å’Œä»»åŠ¡æ±‚è§£æ¨¡å—ã€‚é¦–å…ˆï¼Œä»GIFå›¾åƒä¸­æå–ç±»æ¯”ä¿¡æ¯ï¼Œç”ŸæˆARCé£æ ¼ä»»åŠ¡ï¼›ç„¶åï¼Œé€šè¿‡æ˜ç¡®çš„ç±»æ¯”æ˜ å°„æŒ‡å¯¼AIè¿›è¡Œæ¨ç†ï¼›æœ€åï¼ŒAIåˆ©ç”¨ç±»æ¯”ä¿¡æ¯è¿›è¡Œä»»åŠ¡æ±‚è§£ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†ç±»æ¯”æ€ç»´åµŒå…¥åˆ°ARCä»»åŠ¡ä¸­ï¼Œä½¿AIåœ¨æ±‚è§£è¿‡ç¨‹ä¸­èƒ½å¤Ÿè¿›è¡Œç±»æ¯”è¯„ä¼°ï¼Œè€Œä¸æ˜¯å•çº¯ä¾èµ–å¼ºåŠ›æœç´¢ã€‚è¿™ä¸€æ–¹æ³•ä¸ç°æœ‰çš„åŸºäºæ•°æ®é©±åŠ¨çš„æ±‚è§£æ–¹å¼æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œæ¨¡å‹é‡‡ç”¨äº†ä¼˜åŒ–çš„æŸå¤±å‡½æ•°ä»¥å¢å¼ºç±»æ¯”æ¨ç†èƒ½åŠ›ï¼Œå¹¶åœ¨ç½‘ç»œç»“æ„ä¸­å¼•å…¥äº†å¤šæ¨¡æ€èåˆæœºåˆ¶ï¼Œä»¥æ›´å¥½åœ°å¤„ç†è§†è§‰ä¸è¯­è¨€ä¿¡æ¯çš„ç»“åˆã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨GIFARCå¼•å¯¼çš„LLMåœ¨ARCä»»åŠ¡ä¸­çš„è¡¨ç°æ˜¾è‘—æå‡ï¼Œå‡†ç¡®ç‡æé«˜äº†15-20%ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæ–°çš„ç±»æ¯”æ¨ç†ç­–ç•¥ä½¿å¾—AIåœ¨è§£å†³ä»»åŠ¡æ—¶æ›´åŠ é«˜æ•ˆï¼Œè¡¨ç°å‡ºæ›´å¼ºçš„ç±»æ¯”ç†è§£èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€æœºå™¨äººæ¨ç†ã€æ™ºèƒ½åŠ©æ‰‹ç­‰ã€‚é€šè¿‡æå‡AIçš„ç±»æ¯”æ¨ç†èƒ½åŠ›ï¼Œèƒ½å¤Ÿä½¿å…¶åœ¨å¤æ‚ä»»åŠ¡ä¸­æ›´æ¥è¿‘äººç±»çš„æ€ç»´æ–¹å¼ï¼Œä»è€Œåœ¨å®é™…åº”ç”¨ä¸­æä¾›æ›´é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The Abstraction and Reasoning Corpus (ARC) poses a stringent test of general AI capabilities, requiring solvers to infer abstract patterns from only a handful of examples. Despite substantial progress in deep learning, state-of-the-art models still achieve accuracy rates of merely 40-55% on 2024 ARC Competition, indicative of a significant gap between their performance and human-level reasoning. In this work, we seek to bridge that gap by introducing an analogy-inspired ARC dataset, GIFARC. Leveraging large language models (LLMs) and vision-language models (VLMs), we synthesize new ARC-style tasks from a variety of GIF images that include analogies. Each new task is paired with ground-truth analogy, providing an explicit mapping between visual transformations and everyday concepts. By embedding robust human-intuitive analogies into ARC-style tasks, GIFARC guides AI agents to evaluate the task analogically before engaging in brute-force pattern search, thus efficiently reducing problem complexity and build a more concise and human-understandable solution. We empirically validate that guiding LLM with analogic approach with GIFARC affects task-solving approaches of LLMs to align with analogic approach of human.

