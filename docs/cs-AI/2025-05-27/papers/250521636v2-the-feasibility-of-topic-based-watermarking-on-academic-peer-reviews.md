---
layout: default
title: The Feasibility of Topic-Based Watermarking on Academic Peer Reviews
---

# The Feasibility of Topic-Based Watermarking on Academic Peer Reviews

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21636" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21636v2</a>
  <a href="https://arxiv.org/pdf/2505.21636.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21636v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21636v2', 'The Feasibility of Topic-Based Watermarking on Academic Peer Reviews')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Alexander Nemecek, Yuzhou Jiang, Erman Ayday

**åˆ†ç±»**: cs.CR, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27 (æ›´æ–°: 2025-11-11)

**å¤‡æ³¨**: Accepted at AACL 25 Findings

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºä¸»é¢˜çš„æ°´å°æŠ€æœ¯ä»¥è§£å†³å­¦æœ¯åŒè¡Œè¯„å®¡ä¸­çš„å½’å±é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `åŒè¡Œè¯„å®¡` `æ°´å°æŠ€æœ¯` `æ–‡æœ¬ç”Ÿæˆ` `å­¦æœ¯è¯šä¿¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨åŒè¡Œè¯„å®¡ä¸­ä½¿ç”¨LLMsé¢ä¸´æœºå¯†æ€§æ³„éœ²å’Œè¯„ä¼°ä¸ä¸€è‡´ç­‰æŒ‘æˆ˜ï¼Œé™åˆ¶äº†å…¶åº”ç”¨ã€‚
2. è®ºæ–‡æå‡ºåŸºäºä¸»é¢˜çš„æ°´å°ï¼ˆTBWï¼‰æŠ€æœ¯ï¼Œé€šè¿‡åµŒå…¥å¯æ£€æµ‹ä¿¡å·æ¥è§£å†³LLMç”Ÿæˆæ–‡æœ¬çš„å½’å±é—®é¢˜ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTBWåœ¨ä¿æŒè¯„å®¡è´¨é‡çš„åŒæ—¶ï¼Œå…·å¤‡å¼ºå¤§çš„æ£€æµ‹èƒ½åŠ›ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåº”å¯¹æ–‡æœ¬æ”¹å†™ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å­¦æœ¯å·¥ä½œæµç¨‹ä¸­çš„å¹¿æ³›åº”ç”¨ï¼Œè®¸å¤šä¼šè®®å’ŒæœŸåˆŠå…è®¸å…¶ç”¨äºè¯­è¨€æ¶¦è‰²å’Œæ–‡çŒ®æ€»ç»“ç­‰ä»»åŠ¡ã€‚ç„¶è€Œï¼Œç”±äºå¯¹æœºå¯†æ€§æ³„éœ²ã€è™šæ„å†…å®¹å’Œè¯„ä¼°ä¸ä¸€è‡´çš„æ‹…å¿§ï¼ŒLLMsåœ¨åŒè¡Œè¯„å®¡ä¸­çš„ä½¿ç”¨ä»ç„¶å—åˆ°ç¦æ­¢ã€‚éšç€LLMç”Ÿæˆçš„æ–‡æœ¬ä¸äººç±»å†™ä½œæ„ˆåŠ éš¾ä»¥åŒºåˆ†ï¼Œè¿«åˆ‡éœ€è¦å¯é çš„å½’å±æœºåˆ¶ä»¥ç»´æŠ¤è¯„å®¡è¿‡ç¨‹çš„å®Œæ•´æ€§ã€‚æœ¬ç ”ç©¶è¯„ä¼°äº†ä¸€ç§è¯­ä¹‰æ„ŸçŸ¥çš„æŠ€æœ¯â€”â€”åŸºäºä¸»é¢˜çš„æ°´å°ï¼ˆTBWï¼‰ï¼Œæ—¨åœ¨å°†å¯æ£€æµ‹ä¿¡å·åµŒå…¥LLMç”Ÿæˆçš„æ–‡æœ¬ä¸­ã€‚æˆ‘ä»¬å¯¹å¤šç§LLMé…ç½®è¿›è¡Œäº†ç³»ç»Ÿè¯„ä¼°ï¼ŒåŒ…æ‹¬åŸºç¡€ã€å°‘é‡ç¤ºä¾‹å’Œå¾®è°ƒå˜ä½“ï¼Œä½¿ç”¨æ¥è‡ªå­¦æœ¯ä¼šè®®çš„çœŸå®åŒè¡Œè¯„å®¡æ•°æ®ã€‚ç»“æœè¡¨æ˜ï¼ŒTBWåœ¨ä¿æŒè¯„å®¡è´¨é‡çš„åŒæ—¶ï¼Œè¡¨ç°å‡ºåœ¨æ”¹å†™ä¸‹çš„å¼ºå¤§æ£€æµ‹æ€§èƒ½ã€‚è¿™äº›å‘ç°çªæ˜¾äº†TBWä½œä¸ºä¸€ç§æœ€å°å¹²æ‰°ä¸”å®ç”¨çš„LLMå½’å±è§£å†³æ–¹æ¡ˆåœ¨åŒè¡Œè¯„å®¡ç¯å¢ƒä¸­çš„å¯è¡Œæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³åœ¨å­¦æœ¯åŒè¡Œè¯„å®¡ä¸­ä½¿ç”¨LLMsæ‰€å¸¦æ¥çš„å½’å±é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•é¢ä¸´æœºå¯†æ€§æ³„éœ²å’Œè¯„ä¼°ä¸ä¸€è‡´çš„æŒ‘æˆ˜ï¼Œé™åˆ¶äº†LLMsçš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºä¸»é¢˜çš„æ°´å°ï¼ˆTBWï¼‰æŠ€æœ¯ï¼Œæ—¨åœ¨å°†å¯æ£€æµ‹ä¿¡å·åµŒå…¥LLMç”Ÿæˆçš„æ–‡æœ¬ä¸­ï¼Œä»¥ç¡®ä¿æ–‡æœ¬çš„å½’å±æ€§å’Œå¯è¿½æº¯æ€§ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒTBWèƒ½å¤Ÿåœ¨ä¸æ˜¾è‘—å½±å“æ–‡æœ¬è´¨é‡çš„æƒ…å†µä¸‹ï¼Œæä¾›å¯é çš„å½’å±æœºåˆ¶ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯LLMç”Ÿæˆæ–‡æœ¬çš„åŸºç¡€æ¨¡å—ï¼Œå…¶æ¬¡æ˜¯æ°´å°åµŒå…¥æ¨¡å—ï¼Œæœ€åæ˜¯æ°´å°æ£€æµ‹æ¨¡å—ã€‚è¯¥æµç¨‹ç¡®ä¿äº†ç”Ÿæˆæ–‡æœ¬çš„è´¨é‡å’Œæ°´å°çš„æœ‰æ•ˆæ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šTBWçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶è¯­ä¹‰æ„ŸçŸ¥èƒ½åŠ›ï¼Œèƒ½å¤Ÿåœ¨ä¿æŒæ–‡æœ¬è‡ªç„¶æµç•…çš„åŒæ—¶ï¼ŒåµŒå…¥å¯æ£€æµ‹çš„æ°´å°ä¿¡å·ã€‚è¿™ä¸ä¼ ç»Ÿçš„æ°´å°æŠ€æœ¯ä¸åŒï¼Œåè€…å¾€å¾€ä¼šæ˜¾è‘—å½±å“æ–‡æœ¬çš„å¯è¯»æ€§å’Œè´¨é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼ŒTBWé‡‡ç”¨äº†ç‰¹å®šçš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ï¼Œä»¥ä¼˜åŒ–æ°´å°çš„åµŒå…¥æ•ˆæœã€‚åŒæ—¶ï¼Œç½‘ç»œç»“æ„ç»è¿‡å¾®è°ƒï¼Œä»¥ç¡®ä¿åœ¨ä¸åŒLLMé…ç½®ä¸‹å‡èƒ½å®ç°è‰¯å¥½çš„æ€§èƒ½ã€‚å®éªŒä¸­ä½¿ç”¨äº†çœŸå®çš„åŒè¡Œè¯„å®¡æ•°æ®ï¼Œä»¥éªŒè¯æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒTBWåœ¨ä¿æŒè¯„å®¡è´¨é‡æ–¹é¢ä¸æœªåŠ æ°´å°çš„è¾“å‡ºç›¸å½“ï¼ŒåŒæ—¶åœ¨æ–‡æœ¬æ”¹å†™æƒ…å†µä¸‹å±•ç°å‡ºå¼ºå¤§çš„æ£€æµ‹æ€§èƒ½ã€‚è¿™ä¸€æŠ€æœ¯çš„æœ‰æ•ˆæ€§ä¸ºLLMåœ¨åŒè¡Œè¯„å®¡ä¸­çš„åº”ç”¨æä¾›äº†æ–°çš„å¯èƒ½æ€§ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨å®é™…åœºæ™¯ä¸­çš„å¯è¡Œæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å­¦æœ¯å‡ºç‰ˆã€åŒè¡Œè¯„å®¡å’Œæ–‡æœ¬ç”Ÿæˆç­‰åœºæ™¯ã€‚é€šè¿‡æä¾›ä¸€ç§æœ‰æ•ˆçš„å½’å±æœºåˆ¶ï¼ŒTBWèƒ½å¤Ÿå¸®åŠ©ç»´æŠ¤å­¦æœ¯è¯šä¿¡ï¼Œé˜²æ­¢æŠ„è¢­å’Œä¸å½“ä½¿ç”¨LLMsç”Ÿæˆçš„å†…å®¹ã€‚æœªæ¥ï¼ŒTBWå¯èƒ½åœ¨å…¶ä»–éœ€è¦æ–‡æœ¬å½’å±çš„é¢†åŸŸä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) are increasingly integrated into academic workflows, with many conferences and journals permitting their use for tasks such as language refinement and literature summarization. However, their use in peer review remains prohibited due to concerns around confidentiality breaches, hallucinated content, and inconsistent evaluations. As LLM-generated text becomes more indistinguishable from human writing, there is a growing need for reliable attribution mechanisms to preserve the integrity of the review process. In this work, we evaluate topic-based watermarking (TBW), a semantic-aware technique designed to embed detectable signals into LLM-generated text. We conduct a systematic assessment across multiple LLM configurations, including base, few-shot, and fine-tuned variants, using authentic peer review data from academic conferences. Our results show that TBW maintains review quality relative to non-watermarked outputs, while demonstrating robust detection performance under paraphrasing. These findings highlight the viability of TBW as a minimally intrusive and practical solution for LLM attribution in peer review settings.

