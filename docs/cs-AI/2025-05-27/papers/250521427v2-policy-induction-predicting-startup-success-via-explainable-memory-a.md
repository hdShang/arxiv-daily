---
layout: default
title: "Policy Induction: Predicting Startup Success via Explainable Memory-Augmented In-Context Learning"
---

# Policy Induction: Predicting Startup Success via Explainable Memory-Augmented In-Context Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21427" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21427v2</a>
  <a href="https://arxiv.org/pdf/2505.21427.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21427v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21427v2', 'Policy Induction: Predicting Startup Success via Explainable Memory-Augmented In-Context Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xianling Mu, Joseph Ternasky, Fuat Alican, Yigit Ihlamur

**åˆ†ç±»**: cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27 (æ›´æ–°: 2025-06-04)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºè®°å¿†å¢å¼ºçš„ä¸Šä¸‹æ–‡å­¦ä¹ æ¡†æ¶ä»¥é¢„æµ‹åˆåˆ›ä¼ä¸šæˆåŠŸ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åˆåˆ›ä¼ä¸šæŠ•èµ„` `è®°å¿†å¢å¼º` `ä¸Šä¸‹æ–‡å­¦ä¹ ` `é€æ˜å†³ç­–` `æœºå™¨å­¦ä¹ ` `é£é™©æŠ•èµ„` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æœºå™¨å­¦ä¹ æ–¹æ³•åœ¨åˆåˆ›ä¼ä¸šæŠ•èµ„ä¸­é¢ä¸´æ•°æ®ç¨€ç¼ºå’Œç»“æœä¸ç¡®å®šçš„æŒ‘æˆ˜ï¼Œéš¾ä»¥æä¾›é€æ˜çš„å†³ç­–è¿‡ç¨‹ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºè®°å¿†å¢å¼ºçš„å¤§å‹è¯­è¨€æ¨¡å‹çš„æŠ•èµ„å†³ç­–æ¡†æ¶ï¼Œåˆ©ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ å®ç°é€æ˜å’Œé«˜æ•ˆçš„å†³ç­–ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•çš„é¢„æµ‹å‡†ç¡®ç‡æ¯”éšæœºçŒœæµ‹é«˜å‡º20å€ï¼Œä¸”æ¯”é¡¶çº§é£é™©æŠ•èµ„å…¬å¸çš„æˆåŠŸç‡é«˜å‡º7.1å€ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ—©æœŸåˆåˆ›ä¼ä¸šæŠ•èµ„æ˜¯ä¸€é¡¹é«˜é£é™©çš„äº‹ä¸šï¼Œé¢ä¸´æ•°æ®ç¨€ç¼ºå’Œç»“æœä¸ç¡®å®šçš„æŒ‘æˆ˜ã€‚ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®å’Œå¹¿æ³›çš„è°ƒä¼˜ï¼Œä¸”éš¾ä»¥è¢«é¢†åŸŸä¸“å®¶ç†è§£å’Œæ”¹è¿›ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§é€æ˜ä¸”æ•°æ®é«˜æ•ˆçš„æŠ•èµ„å†³ç­–æ¡†æ¶ï¼Œåˆ©ç”¨è®°å¿†å¢å¼ºçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰ã€‚æˆ‘ä»¬çš„æ–¹æ³•å°†è‡ªç„¶è¯­è¨€ç­–ç•¥ç›´æ¥åµŒå…¥LLMæç¤ºä¸­ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿåº”ç”¨æ˜ç¡®çš„æ¨ç†æ¨¡å¼ï¼Œä¾¿äºäººç±»ä¸“å®¶ç†è§£ã€å®¡è®¡å’Œè¿­ä»£ä¼˜åŒ–é€»è¾‘ã€‚é€šè¿‡ç»“åˆå°‘é‡å­¦ä¹ å’Œä¸Šä¸‹æ–‡å­¦ä¹ å¾ªç¯çš„è½»é‡çº§è®­ç»ƒè¿‡ç¨‹ï¼Œæˆ‘ä»¬çš„ç³»ç»Ÿåœ¨ä»…éœ€æœ€å°ç›‘ç£ä¸”æ— åŸºäºæ¢¯åº¦çš„ä¼˜åŒ–æƒ…å†µä¸‹ï¼Œèƒ½å¤Ÿæ¯”ç°æœ‰åŸºå‡†æ›´å‡†ç¡®åœ°é¢„æµ‹åˆåˆ›ä¼ä¸šçš„æˆåŠŸã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ—©æœŸåˆåˆ›ä¼ä¸šæŠ•èµ„ä¸­æ•°æ®ç¨€ç¼ºå’Œå†³ç­–ä¸é€æ˜çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–å¤§é‡æ ‡æ³¨æ•°æ®ï¼Œä¸”éš¾ä»¥è¢«é¢†åŸŸä¸“å®¶ç†è§£å’Œæ”¹è¿›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§é€æ˜çš„æŠ•èµ„å†³ç­–æ¡†æ¶ï¼Œåˆ©ç”¨è®°å¿†å¢å¼ºçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œé€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹ å®ç°é«˜æ•ˆçš„å†³ç­–è¿‡ç¨‹ã€‚è‡ªç„¶è¯­è¨€ç­–ç•¥çš„åµŒå…¥ä½¿å¾—æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹æ›´æ˜“äºç†è§£å’Œä¼˜åŒ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œç»“åˆå°‘é‡å­¦ä¹ å’Œä¸Šä¸‹æ–‡å­¦ä¹ å¾ªç¯ã€‚æ¨¡å‹é€šè¿‡æ¥æ”¶ç»“æ„åŒ–åé¦ˆä¸æ–­æ›´æ–°å†³ç­–ç­–ç•¥ï¼Œå½¢æˆä¸€ä¸ªè¿­ä»£ä¼˜åŒ–çš„è¿‡ç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†è‡ªç„¶è¯­è¨€ç­–ç•¥ç›´æ¥åµŒå…¥æ¨¡å‹æç¤ºä¸­ï¼Œä½¿å¾—æ¨ç†è¿‡ç¨‹é€æ˜åŒ–ï¼Œä¾¿äºäººç±»ä¸“å®¶è¿›è¡Œå®¡è®¡å’Œä¼˜åŒ–ã€‚è¿™ä¸€è®¾è®¡ä¸ä¼ ç»Ÿæ–¹æ³•çš„é»‘ç®±ç‰¹æ€§å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šè¯¥æ–¹æ³•é‡‡ç”¨è½»é‡çº§è®­ç»ƒè¿‡ç¨‹ï¼Œæ— éœ€æ¢¯åº¦ä¼˜åŒ–ï¼Œä¾èµ–äºå°‘é‡çš„ç›‘ç£ä¿¡æ¯ã€‚æ¨¡å‹çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡æ—¨åœ¨æ”¯æŒä¸Šä¸‹æ–‡å­¦ä¹ çš„é«˜æ•ˆæ€§å’Œé€æ˜æ€§ã€‚æ•´ä½“ç»“æ„ç®€åŒ–äº†ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹çš„å¤æ‚æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨é¢„æµ‹åˆåˆ›ä¼ä¸šæˆåŠŸç‡æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œå‡†ç¡®ç‡è¶…è¿‡éšæœºçŒœæµ‹çš„20å€ï¼Œè¾¾åˆ°1.9%çš„æˆåŠŸç‡ï¼Œä¸”æ¯”é¡¶çº§é£é™©æŠ•èµ„å…¬å¸çš„5.6%æˆåŠŸç‡é«˜å‡º7.1å€ï¼Œå±•ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬é£é™©æŠ•èµ„ã€åˆ›ä¸šå­µåŒ–å™¨å’Œé‡‘èç§‘æŠ€ç­‰ï¼Œèƒ½å¤Ÿä¸ºæŠ•èµ„å†³ç­–æä¾›æ›´ä¸ºé€æ˜å’Œé«˜æ•ˆçš„æ”¯æŒã€‚é€šè¿‡æé«˜é¢„æµ‹å‡†ç¡®æ€§ï¼Œå¸®åŠ©æŠ•èµ„è€…é™ä½é£é™©å¹¶ä¼˜åŒ–æŠ•èµ„ç»„åˆï¼Œæœªæ¥å¯èƒ½åœ¨åˆ›ä¸šç”Ÿæ€ç³»ç»Ÿä¸­äº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Early-stage startup investment is a high-risk endeavor characterized by scarce data and uncertain outcomes. Traditional machine learning approaches often require large, labeled datasets and extensive fine-tuning, yet remain opaque and difficult for domain experts to interpret or improve. In this paper, we propose a transparent and data-efficient investment decision framework powered by memory-augmented large language models (LLMs) using in-context learning (ICL). Central to our method is a natural language policy embedded directly into the LLM prompt, enabling the model to apply explicit reasoning patterns and allowing human experts to easily interpret, audit, and iteratively refine the logic. We introduce a lightweight training process that combines few-shot learning with an in-context learning loop, enabling the LLM to update its decision policy iteratively based on structured feedback. With only minimal supervision and no gradient-based optimization, our system predicts startup success far more accurately than existing benchmarks. It is over 20x more precise than random chance, which succeeds 1.9% of the time. It is also 7.1x more precise than the typical 5.6% success rate of top-tier venture capital (VC) firms.

