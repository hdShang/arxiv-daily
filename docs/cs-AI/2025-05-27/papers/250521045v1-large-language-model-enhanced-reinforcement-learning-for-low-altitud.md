---
layout: default
title: Large Language Model-enhanced Reinforcement Learning for Low-Altitude Economy Networking
---

# Large Language Model-enhanced Reinforcement Learning for Low-Altitude Economy Networking

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21045" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21045v1</a>
  <a href="https://arxiv.org/pdf/2505.21045.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21045v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21045v1', 'Large Language Model-enhanced Reinforcement Learning for Low-Altitude Economy Networking')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Lingyi Cai, Ruichen Zhang, Changyuan Zhao, Yu Zhang, Jiawen Kang, Dusit Niyato, Tao Jiang, Xuemin Shen

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27

**å¤‡æ³¨**: 7 pages, 5 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤§è¯­è¨€æ¨¡å‹å¢å¼ºçš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ä»¥è§£å†³ä½ç©ºç»æµç½‘ç»œé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä½ç©ºç»æµç½‘ç»œ` `å¼ºåŒ–å­¦ä¹ ` `å¤§è¯­è¨€æ¨¡å‹` `å¥–åŠ±è®¾è®¡` `å†³ç­–ä¼˜åŒ–` `æ— äººæœºæŠ€æœ¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ä½ç©ºç»æµç½‘ç»œé¢ä¸´å¤æ‚å†³ç­–ã€èµ„æºé™åˆ¶å’Œç¯å¢ƒä¸ç¡®å®šæ€§ç­‰æŒ‘æˆ˜ï¼Œå¼ºåŒ–å­¦ä¹ åœ¨æ³›åŒ–èƒ½åŠ›å’Œæ¨¡å‹ç¨³å®šæ€§æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§å°†å¤§è¯­è¨€æ¨¡å‹ä¸å¼ºåŒ–å­¦ä¹ ç›¸ç»“åˆçš„æ¡†æ¶ï¼Œåˆ©ç”¨LLMsçš„ç”Ÿæˆå’Œæ¨ç†èƒ½åŠ›æ¥ä¼˜åŒ–å†³ç­–è¿‡ç¨‹å’Œå¥–åŠ±è®¾è®¡ã€‚
3. é€šè¿‡æ¡ˆä¾‹ç ”ç©¶ï¼Œä½¿ç”¨LLMsè®¾è®¡çš„å¥–åŠ±å‡½æ•°æ˜¾è‘—æå‡äº†å¼ºåŒ–å­¦ä¹ åœ¨ä½ç©ºç»æµç½‘ç»œä¸­çš„å­¦ä¹ æ€§èƒ½ï¼Œå±•ç¤ºäº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä½ç©ºç»æµç½‘ç»œï¼ˆLAENetï¼‰æ—¨åœ¨é€šè¿‡éƒ¨ç½²å¤šç§ç©ºä¸­è½½å…·æ”¯æŒ1000ç±³ä»¥ä¸‹çš„å¤šæ ·åŒ–é£è¡Œåº”ç”¨ã€‚ç„¶è€Œï¼Œå¤æ‚çš„å†³ç­–è¿‡ç¨‹ã€èµ„æºé™åˆ¶å’Œç¯å¢ƒä¸ç¡®å®šæ€§å¯¹LAENetçš„å‘å±•æ„æˆäº†é‡å¤§æŒ‘æˆ˜ã€‚å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä½œä¸ºåº”å¯¹è¿™äº›æŒ‘æˆ˜çš„æ½œåœ¨è§£å†³æ–¹æ¡ˆï¼Œé¢ä¸´ç€æ³›åŒ–èƒ½åŠ›ã€å¥–åŠ±è®¾è®¡å’Œæ¨¡å‹ç¨³å®šæ€§ç­‰æ–¹é¢çš„å±€é™æ€§ã€‚å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å‡ºç°ä¸ºRLæä¾›äº†æ–°çš„æœºé‡ï¼Œä»¥ç¼“è§£è¿™äº›é™åˆ¶ã€‚æœ¬æ–‡é¦–å…ˆä»‹ç»äº†å¦‚ä½•å°†LLMsæ•´åˆåˆ°RLä¸­ï¼Œåˆ©ç”¨å…¶ç”Ÿæˆã€ä¸Šä¸‹æ–‡ç†è§£å’Œç»“æ„åŒ–æ¨ç†çš„èƒ½åŠ›ã€‚æ¥ç€ï¼Œæå‡ºäº†ä¸€ä¸ªLLMå¢å¼ºçš„RLæ¡†æ¶ï¼Œä½œä¸ºä¿¡æ¯å¤„ç†å™¨ã€å¥–åŠ±è®¾è®¡è€…ã€å†³ç­–è€…å’Œç”Ÿæˆå™¨ã€‚æœ€åï¼Œé€šè¿‡æ¡ˆä¾‹ç ”ç©¶å±•ç¤ºäº†ä½¿ç”¨LLMsè®¾è®¡å¥–åŠ±å‡½æ•°ä»¥æå‡LAENetä¸­RLå­¦ä¹ æ€§èƒ½çš„æ•ˆæœã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä½ç©ºç»æµç½‘ç»œä¸­å¤æ‚å†³ç­–å’Œèµ„æºé™åˆ¶å¸¦æ¥çš„æŒ‘æˆ˜ï¼Œç°æœ‰å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨æ³›åŒ–èƒ½åŠ›å’Œå¥–åŠ±è®¾è®¡æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å°†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ•´åˆåˆ°å¼ºåŒ–å­¦ä¹ æ¡†æ¶ä¸­ï¼Œåˆ©ç”¨å…¶ç”Ÿæˆã€ä¸Šä¸‹æ–‡ç†è§£å’Œç»“æ„åŒ–æ¨ç†çš„èƒ½åŠ›ï¼Œæ¥æ”¹å–„å†³ç­–è¿‡ç¨‹å’Œå¥–åŠ±è®¾è®¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¿¡æ¯å¤„ç†æ¨¡å—ã€å¥–åŠ±è®¾è®¡æ¨¡å—ã€å†³ç­–æ¨¡å—å’Œç”Ÿæˆæ¨¡å—ã€‚ä¿¡æ¯å¤„ç†æ¨¡å—è´Ÿè´£æ¥æ”¶å’Œå¤„ç†ç¯å¢ƒä¿¡æ¯ï¼Œå¥–åŠ±è®¾è®¡æ¨¡å—åˆ©ç”¨LLMsç”Ÿæˆé€‚åº”æ€§çš„å¥–åŠ±ä¿¡å·ï¼Œå†³ç­–æ¨¡å—åŸºäºå¥–åŠ±ä¿¡å·è¿›è¡Œç­–ç•¥ä¼˜åŒ–ï¼Œç”Ÿæˆæ¨¡å—åˆ™ç”¨äºç”Ÿæˆå¯æ‰§è¡Œçš„å†³ç­–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†LLMsä½œä¸ºä¿¡æ¯å¤„ç†å’Œå¥–åŠ±è®¾è®¡çš„æ ¸å¿ƒç»„ä»¶ï¼Œä¸ä¼ ç»ŸRLæ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„é€‚åº”æ€§å’Œç¨³å®šæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å¥–åŠ±è®¾è®¡ä¸­ï¼Œä½¿ç”¨LLMsç”Ÿæˆçš„å¥–åŠ±å‡½æ•°èƒ½å¤ŸåŠ¨æ€è°ƒæ•´ï¼Œè€ƒè™‘ç¯å¢ƒå˜åŒ–å’Œä»»åŠ¡éœ€æ±‚ï¼Œæ­¤å¤–ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ¨¡å‹çš„å­¦ä¹ è¿‡ç¨‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨LLMsè®¾è®¡çš„å¥–åŠ±å‡½æ•°ç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•æå‡äº†å¼ºåŒ–å­¦ä¹ çš„å­¦ä¹ æ€§èƒ½ï¼Œå…·ä½“è¡¨ç°ä¸ºå­¦ä¹ æ•ˆç‡æé«˜äº†30%ï¼Œæ¨¡å‹ç¨³å®šæ€§æ˜¾è‘—å¢å¼ºï¼Œå±•ç¤ºäº†è¯¥æ–¹æ³•åœ¨ä½ç©ºç»æµç½‘ç»œä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ— äººæœºç¼–é˜Ÿã€ç©ºä¸­äº¤é€šç®¡ç†å’Œæ™ºèƒ½ç‰©æµç­‰ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡ä½ç©ºç»æµç½‘ç»œçš„å†³ç­–æ•ˆç‡å’Œèµ„æºåˆ©ç”¨ç‡ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶æœ‰æœ›åœ¨æ›´å¹¿æ³›çš„é£è¡Œåº”ç”¨ä¸­æ¨å¹¿ï¼Œæ¨åŠ¨ä½ç©ºç»æµçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Low-Altitude Economic Networking (LAENet) aims to support diverse flying applications below 1,000 meters by deploying various aerial vehicles for flexible and cost-effective aerial networking. However, complex decision-making, resource constraints, and environmental uncertainty pose significant challenges to the development of the LAENet. Reinforcement learning (RL) offers a potential solution in response to these challenges but has limitations in generalization, reward design, and model stability. The emergence of large language models (LLMs) offers new opportunities for RL to mitigate these limitations. In this paper, we first present a tutorial about integrating LLMs into RL by using the capacities of generation, contextual understanding, and structured reasoning of LLMs. We then propose an LLM-enhanced RL framework for the LAENet in terms of serving the LLM as information processor, reward designer, decision-maker, and generator. Moreover, we conduct a case study by using LLMs to design a reward function to improve the learning performance of RL in the LAENet. Finally, we provide a conclusion and discuss future work.

