---
layout: default
title: Herd Behavior: Investigating Peer Influence in LLM-based Multi-Agent Systems
---

# Herd Behavior: Investigating Peer Influence in LLM-based Multi-Agent Systems

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21588" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21588v1</a>
  <a href="https://arxiv.org/pdf/2505.21588.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21588v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21588v1', 'Herd Behavior: Investigating Peer Influence in LLM-based Multi-Agent Systems')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Young-Min Cho, Sharath Chandra Guntuku, Lyle Ungar

**åˆ†ç±»**: cs.MA, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27

**å¤‡æ³¨**: Preprint

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç ”ç©¶ç¾¤ä½“è¡Œä¸ºä»¥æå‡LLMå¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„åä½œèƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ` `ç¾¤ä½“è¡Œä¸º` `åŒä¼´å½±å“` `åä½œæœºåˆ¶` `å®éªŒç ”ç©¶` `ç¤¾ä¼šåŠ¨æ€`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨ä¸ªä½“æ¨¡å‹è¡Œä¸ºä¸Šï¼Œç¼ºä¹å¯¹å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­åŒä¼´å½±å“çš„æ·±å…¥åˆ†æã€‚
2. æœ¬æ–‡é€šè¿‡æ§åˆ¶å®éªŒæ¢è®¨ç¾¤ä½“è¡Œä¸ºï¼Œæ­ç¤ºè‡ªä¿¡å¿ƒå·®è·å’Œä¿¡æ¯å‘ˆç°æ ¼å¼å¯¹ä»ä¼—è¡Œä¸ºçš„å½±å“ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œé€‚å½“çš„ç¾¤ä½“è¡Œä¸ºæ§åˆ¶èƒ½å¤Ÿæ˜¾è‘—æå‡å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„åä½œæ•ˆæœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è¿›æ­¥ï¼ŒåŸºäºLLMçš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿé€æ¸å…´èµ·ï¼Œæ™ºèƒ½ä½“åœ¨å…±äº«ç¯å¢ƒä¸­è¿›è¡Œäº’åŠ¨ä¸å†³ç­–ã€‚å°½ç®¡ä¸ªä½“æ¨¡å‹è¡Œä¸ºå·²è¢«å¹¿æ³›ç ”ç©¶ï¼Œä½†åŒä¼´å½±å“çš„åŠ¨æ€å°šæœªæ·±å…¥æ¢è®¨ã€‚æœ¬æ–‡ç ”ç©¶äº†æ™ºèƒ½ä½“åœ¨LLMå¤šæ™ºèƒ½ä½“äº¤äº’ä¸­çš„ç¾¤ä½“è¡Œä¸ºï¼Œæ­ç¤ºäº†å¤šä¸ªå› ç´ å¦‚ä½•å½±å“è¿™ä¸€è¡Œä¸ºã€‚ç ”ç©¶è¡¨æ˜ï¼Œè‡ªä¿¡å¿ƒä¸å¯¹åŒä¼´ä¿¡å¿ƒçš„æ„ŸçŸ¥å·®è·æ˜¾è‘—å½±å“æ™ºèƒ½ä½“çš„ä»ä¼—å€¾å‘ï¼›åŒä¼´ä¿¡æ¯çš„å‘ˆç°æ ¼å¼å¯¹ç¾¤ä½“è¡Œä¸ºçš„å¼ºåº¦èµ·ç€å…³é”®ä½œç”¨ï¼›æ­¤å¤–ï¼Œç¾¤ä½“è¡Œä¸ºçš„ç¨‹åº¦å¯ä»¥ç³»ç»Ÿæ€§åœ°æ§åˆ¶ï¼Œé€‚å½“çš„ç¾¤ä½“å€¾å‘èƒ½å¤Ÿæå‡åä½œæˆæœã€‚è¿™äº›å‘ç°ä¸ºLLMç³»ç»Ÿçš„ç¤¾ä¼šåŠ¨æ€æä¾›äº†æ–°è§è§£ï¼Œå¹¶ä¸ºè®¾è®¡æ›´æœ‰æ•ˆçš„å¤šæ™ºèƒ½ä½“åä½œæ¡†æ¶å¼€è¾Ÿäº†æ–°è·¯å¾„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨æ¢è®¨åœ¨LLMå¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­ï¼Œæ™ºèƒ½ä½“ä¹‹é—´çš„åŒä¼´å½±å“å¦‚ä½•å½±å“å…¶å†³ç­–å’Œè¡Œä¸ºã€‚ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†è€ƒè™‘æ™ºèƒ½ä½“ä¹‹é—´çš„ç¤¾ä¼šåŠ¨æ€å’Œç›¸äº’å½±å“ï¼Œå¯¼è‡´åä½œæ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡é€šè¿‡ä¸€ç³»åˆ—æ§åˆ¶å®éªŒï¼Œåˆ†æäº†å½±å“ç¾¤ä½“è¡Œä¸ºçš„å¤šç§å› ç´ ï¼Œç‰¹åˆ«æ˜¯è‡ªä¿¡å¿ƒå·®è·å’Œä¿¡æ¯å‘ˆç°æ ¼å¼ï¼Œæå‡ºäº†ç³»ç»Ÿæ€§æ§åˆ¶ç¾¤ä½“è¡Œä¸ºçš„ç­–ç•¥ï¼Œä»¥ä¼˜åŒ–æ™ºèƒ½ä½“çš„åä½œæ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨å®éªŒè®¾è®¡çš„æ–¹æ³•ï¼Œé¦–å…ˆæ„å»ºå¤šæ™ºèƒ½ä½“äº¤äº’ç¯å¢ƒï¼Œç„¶åé€šè¿‡ä¸åŒçš„å®éªŒæ¡ä»¶ï¼ˆå¦‚è‡ªä¿¡å¿ƒå·®è·å’Œä¿¡æ¯æ ¼å¼ï¼‰è§‚å¯Ÿæ™ºèƒ½ä½“çš„è¡Œä¸ºå˜åŒ–ï¼Œæœ€ååˆ†æå®éªŒç»“æœä»¥æç‚¼å‡ºå½±å“ç¾¤ä½“è¡Œä¸ºçš„å…³é”®å› ç´ ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„ä¸»è¦åˆ›æ–°åœ¨äºç³»ç»Ÿæ€§åœ°æ­ç¤ºäº†è‡ªä¿¡å¿ƒä¸åŒä¼´ä¿¡å¿ƒæ„ŸçŸ¥ä¹‹é—´çš„å…³ç³»å¯¹ç¾¤ä½“è¡Œä¸ºçš„å½±å“ï¼Œå¹¶æå‡ºäº†é€šè¿‡æ§åˆ¶è¿™äº›å› ç´ æ¥ä¼˜åŒ–æ™ºèƒ½ä½“åä½œçš„ç­–ç•¥ã€‚è¿™ä¸€æ€è·¯åœ¨ç°æœ‰æ–‡çŒ®ä¸­å°šå±é¦–æ¬¡ã€‚

**å…³é”®è®¾è®¡**ï¼šå®éªŒä¸­è®¾ç½®äº†å¤šä¸ªå‚æ•°ï¼ŒåŒ…æ‹¬è‡ªä¿¡å¿ƒå·®è·çš„é‡åŒ–æ–¹å¼ã€åŒä¼´ä¿¡æ¯çš„å‘ˆç°æ ¼å¼ï¼ˆå¦‚æ–‡æœ¬ã€å›¾è¡¨ç­‰ï¼‰ï¼Œå¹¶é€šè¿‡å¯¹æ¯”å®éªŒè¯„ä¼°ä¸åŒè®¾ç½®å¯¹ç¾¤ä½“è¡Œä¸ºçš„å½±å“ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œè‡ªä¿¡å¿ƒå·®è·ä¸åŒä¼´ä¿¡æ¯æ ¼å¼å¯¹ç¾¤ä½“è¡Œä¸ºçš„å½±å“æ˜¾è‘—ï¼Œé€‚å½“æ§åˆ¶ç¾¤ä½“è¡Œä¸ºèƒ½å¤Ÿæå‡åä½œæ•ˆæœï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šã€‚è¿™ä¸ºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„è®¾è®¡æä¾›äº†é‡è¦çš„å®è¯ä¾æ®ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å®¢æœã€è‡ªåŠ¨é©¾é©¶ã€åä½œæœºå™¨äººç­‰å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œé€šè¿‡ä¼˜åŒ–æ™ºèƒ½ä½“ä¹‹é—´çš„åä½œæœºåˆ¶ï¼Œå¯ä»¥æ˜¾è‘—æå‡ç³»ç»Ÿçš„æ•´ä½“æ•ˆç‡å’Œå†³ç­–è´¨é‡ã€‚æœªæ¥ï¼Œç ”ç©¶æˆæœæœ‰æœ›æ¨åŠ¨æ›´æ™ºèƒ½çš„åä½œæ¡†æ¶çš„è®¾è®¡ä¸å®ç°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advancements in Large Language Models (LLMs) have enabled the emergence of multi-agent systems where LLMs interact, collaborate, and make decisions in shared environments. While individual model behavior has been extensively studied, the dynamics of peer influence in such systems remain underexplored. In this paper, we investigate herd behavior, the tendency of agents to align their outputs with those of their peers, within LLM-based multi-agent interactions. We present a series of controlled experiments that reveal how herd behaviors are shaped by multiple factors. First, we show that the gap between self-confidence and perceived confidence in peers significantly impacts an agent's likelihood to conform. Second, we find that the format in which peer information is presented plays a critical role in modulating the strength of herd behavior. Finally, we demonstrate that the degree of herd behavior can be systematically controlled, and that appropriately calibrated herd tendencies can enhance collaborative outcomes. These findings offer new insights into the social dynamics of LLM-based systems and open pathways for designing more effective and adaptive multi-agent collaboration frameworks.

