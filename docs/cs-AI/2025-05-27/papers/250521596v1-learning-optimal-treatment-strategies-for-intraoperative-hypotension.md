---
layout: default
title: Learning optimal treatment strategies for intraoperative hypotension using deep reinforcement learning
---

# Learning optimal treatment strategies for intraoperative hypotension using deep reinforcement learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21596" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21596v1</a>
  <a href="https://arxiv.org/pdf/2505.21596.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21596v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21596v1', 'Learning optimal treatment strategies for intraoperative hypotension using deep reinforcement learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Esra Adiyeke, Tianqi Liu, Venkata Sai Dheeraj Naganaboina, Han Li, Tyler J. Loftus, Yuanfang Ren, Benjamin Shickel, Matthew M. Ruppert, Karandeep Singh, Ruogu Fang, Parisa Rashidi, Azra Bihorac, Tezcan Ozrazgat-Baslanti

**åˆ†ç±»**: q-bio.QM, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27

**å¤‡æ³¨**: 41 pages, 1 table, 5 figures, 5 supplemental tables, 6 supplemental figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ·±åº¦å¼ºåŒ–å­¦ä¹ æ¨¡å‹ä»¥ä¼˜åŒ–æ‰‹æœ¯ä¸­ä½è¡€å‹æ²»ç–—ç­–ç•¥**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æ·±åº¦å¼ºåŒ–å­¦ä¹ ` `æ‰‹æœ¯å†³ç­–` `ä½è¡€å‹ç®¡ç†` `æ€¥æ€§è‚¾æŸä¼¤` `æ™ºèƒ½åŒ»ç–—`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ‰‹æœ¯å†³ç­–æ–¹æ³•ä¾èµ–åŒ»ç”Ÿç»éªŒï¼Œå¯¼è‡´ä½è¡€å‹ç®¡ç†ä¸ä¸€è‡´ï¼Œå¢åŠ æœ¯åå¹¶å‘ç—‡é£é™©ã€‚
2. æœ¬æ–‡æå‡ºåŸºäºæ·±åº¦å¼ºåŒ–å­¦ä¹ çš„æ¨¡å‹ï¼Œé€šè¿‡åˆ†ææ‚£è€…ç”Ÿç†æ•°æ®ï¼Œä¼˜åŒ–é™è„‰è¾“æ¶²å’Œè¡€ç®¡æ”¶ç¼©è¯ç‰©çš„ä½¿ç”¨ã€‚
3. æ¨¡å‹åœ¨å®éªŒä¸­æˆåŠŸå¤åˆ¶äº†69%çš„åŒ»ç”Ÿå†³ç­–ï¼Œå¹¶åœ¨è¯ç‰©å‰‚é‡æ¨èä¸Šæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ”¹è¿›ï¼Œé™ä½äº†æ€¥æ€§è‚¾æŸä¼¤çš„å‘ç”Ÿç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¼ ç»Ÿçš„æ‰‹æœ¯å†³ç­–æ–¹æ³•ä¾èµ–äºåŒ»ç”Ÿçš„ç»éªŒå’Œè¿…é€Ÿååº”ï¼Œå­˜åœ¨è¾ƒå¤§å˜å¼‚æ€§ã€‚é’ˆå¯¹æ‰‹æœ¯ä¸­ä½è¡€å‹çš„ç®¡ç†ï¼Œæœ¬æ–‡å¼€å‘äº†ä¸€ç§åŸºäºæ·±åº¦å¼ºåŒ–å­¦ä¹ çš„æ¨¡å‹ï¼Œæ—¨åœ¨æ ¹æ®æ‚£è€…çŠ¶æ€ç”Ÿæˆæœ€ä½³æ²»ç–—å»ºè®®ã€‚é€šè¿‡å¯¹50,021ä¾‹æ‰‹æœ¯çš„å›é¡¾æ€§åˆ†æï¼Œæ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆæ¨èé™è„‰è¾“æ¶²å’Œè¡€ç®¡æ”¶ç¼©è¯ç‰©çš„æœ€ä½³å‰‚é‡ï¼Œä»è€Œé™ä½æœ¯åæ€¥æ€§è‚¾æŸä¼¤çš„é£é™©ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ¨¡å‹çš„æ¨èä¸åŒ»ç”Ÿçš„å†³ç­–é«˜åº¦ä¸€è‡´ï¼Œå¹¶åœ¨å¤šä¸ªæ–¹é¢ä¼˜äºéšæœºå’Œé›¶è¯ç‰©ç­–ç•¥ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ‰‹æœ¯ä¸­ä½è¡€å‹çš„ç®¡ç†é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•ä¾èµ–åŒ»ç”Ÿç»éªŒï¼Œå¯¼è‡´æ²»ç–—ä¸ä¸€è‡´ï¼Œå¢åŠ æœ¯åæ€¥æ€§è‚¾æŸä¼¤é£é™©ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ·±åº¦å¼ºåŒ–å­¦ä¹ æ¨¡å‹ï¼ŒåŸºäºæ‚£è€…çš„ç”Ÿç†çŠ¶æ€å®æ—¶ç”Ÿæˆæœ€ä½³æ²»ç–—å»ºè®®ï¼Œä»¥æé«˜æ²»ç–—æ•ˆæœå’Œä¸€è‡´æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ¨¡å‹é‡‡ç”¨æ·±åº¦Qç½‘ç»œï¼ˆDQNï¼‰ï¼Œåˆ†æ16ä¸ªå˜é‡ï¼ŒåŒ…æ‹¬ç”Ÿç†æ—¶é—´åºåˆ—æ•°æ®å’Œæ¯15åˆ†é’Ÿçš„è¯ç‰©å‰‚é‡ï¼Œåˆ†ä¸ºè®­ç»ƒå’Œæµ‹è¯•é˜¶æ®µã€‚

**å…³é”®åˆ›æ–°**ï¼šæ¨¡å‹èƒ½å¤Ÿåœ¨è¯ç‰©å‰‚é‡æ¨èä¸Šä¸åŒ»ç”Ÿå†³ç­–é«˜åº¦ä¸€è‡´ï¼Œå¹¶åœ¨å¤šä¸ªæ²»ç–—æ–¹æ¡ˆä¸­æä¾›æ›´ä¼˜çš„å‰‚é‡å»ºè®®ï¼Œæ˜¾è‘—é™ä½æœ¯åå¹¶å‘ç—‡é£é™©ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡å‹ä½¿ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ï¼Œç¡®ä¿åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æœ‰æ•ˆå­¦ä¹ æ‚£è€…çŠ¶æ€ä¸æ²»ç–—æ•ˆæœä¹‹é—´çš„å…³ç³»ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ¨¡å‹åœ¨è¯ç‰©å‰‚é‡æ¨èä¸Šä¸åŒ»ç”Ÿçš„å†³ç­–ä¸€è‡´æ€§è¾¾åˆ°69%ï¼Œå¹¶åœ¨41%çš„æ¡ˆä¾‹ä¸­æ¨èçš„é™è„‰è¾“æ¶²å‰‚é‡ä¸å®é™…å‰‚é‡ç›¸å·®ä¸è¶…è¿‡0.05 ml/kg/15 minã€‚æ­¤å¤–ï¼Œæ¨¡å‹çš„æ”¿ç­–ä»·å€¼é«˜äºåŒ»ç”Ÿå®é™…æ²»ç–—å’Œéšæœºç­–ç•¥ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„ä¸´åºŠåº”ç”¨æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ‰‹æœ¯å®¤å†…çš„å®æ—¶å†³ç­–æ”¯æŒç³»ç»Ÿï¼Œèƒ½å¤Ÿå¸®åŠ©åŒ»ç”Ÿåœ¨å¤æ‚æƒ…å†µä¸‹åšå‡ºæ›´ä¼˜çš„æ²»ç–—é€‰æ‹©ï¼Œå‡å°‘æœ¯åå¹¶å‘ç—‡ï¼Œæé«˜æ‚£è€…å®‰å…¨æ€§å’Œæ²»ç–—æ•ˆæœã€‚æœªæ¥ï¼Œè¯¥æ¨¡å‹æœ‰æœ›æ¨å¹¿è‡³å…¶ä»–åŒ»ç–—é¢†åŸŸï¼Œæå‡æ•´ä½“åŒ»ç–—å†³ç­–çš„æ™ºèƒ½åŒ–æ°´å¹³ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Traditional methods of surgical decision making heavily rely on human experience and prompt actions, which are variable. A data-driven system generating treatment recommendations based on patient states can be a substantial asset in perioperative decision-making, as in cases of intraoperative hypotension, for which suboptimal management is associated with acute kidney injury (AKI), a common and morbid postoperative complication. We developed a Reinforcement Learning (RL) model to recommend optimum dose of intravenous (IV) fluid and vasopressors during surgery to avoid intraoperative hypotension and postoperative AKI. We retrospectively analyzed 50,021 surgeries from 42,547 adult patients who underwent major surgery at a quaternary care hospital between June 2014 and September 2020. Of these, 34,186 surgeries were used for model training and 15,835 surgeries were reserved for testing. We developed a Deep Q-Networks based RL model using 16 variables including intraoperative physiologic time series, total dose of IV fluid and vasopressors extracted for every 15-minute epoch. The model replicated 69% of physician's decisions for the dosage of vasopressors and proposed higher or lower dosage of vasopressors than received in 10% and 21% of the treatments, respectively. In terms of IV fluids, the model's recommendations were within 0.05 ml/kg/15 min of the actual dose in 41% of the cases, with higher or lower doses recommended for 27% and 32% of the treatments, respectively. The model resulted in a higher estimated policy value compared to the physicians' actual treatments, as well as random and zero-drug policies. AKI prevalence was the lowest in patients receiving medication dosages that aligned with model's decisions. Our findings suggest that implementation of the model's policy has the potential to reduce postoperative AKI and improve other outcomes driven by intraoperative hypotension.

