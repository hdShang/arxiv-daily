---
layout: default
title: Aligning Proteins and Language: A Foundation Model for Protein Retrieval
---

# Aligning Proteins and Language: A Foundation Model for Protein Retrieval

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.08023" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.08023v1</a>
  <a href="https://arxiv.org/pdf/2506.08023.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.08023v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.08023v1', 'Aligning Proteins and Language: A Foundation Model for Protein Retrieval')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Qifeng Wu, Zhengzhe Liu, Han Zhu, Yizhou Zhao, Daisuke Kihara, Min Xu

**åˆ†ç±»**: q-bio.BM, cs.AI, cs.CE, cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27

**å¤‡æ³¨**: 4 pages for body, 3 pages for appendix, 11 figures. Accepted to CVPR 2025 Workshop on Multimodal Foundation Models for Biomedicine: Challenges and Opportunities(MMFM-BIOMED)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCLIPé£æ ¼æ¡†æ¶ä»¥å®ç°è›‹ç™½è´¨æ£€ç´¢**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è›‹ç™½è´¨æ£€ç´¢` `å¯¹æ¯”å­¦ä¹ ` `å¤šæ¨¡æ€æ¨¡å‹` `ç»“æ„ç”Ÿç‰©å­¦` `åŠŸèƒ½æ³¨é‡Š`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨è›‹ç™½è´¨ç»“æ„ä¸åŠŸèƒ½çš„å…³è”æ€§ç†è§£ä¸Šå­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥æœ‰æ•ˆæ£€ç´¢ç›¸ä¼¼è›‹ç™½è´¨ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºå¯¹æ¯”å­¦ä¹ çš„CLIPé£æ ¼æ¡†æ¶ï¼Œæ—¨åœ¨å°†3Dè›‹ç™½è´¨ç»“æ„ä¸åŠŸèƒ½æ³¨é‡Šè¿›è¡Œå¯¹é½ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨PDBå’ŒEMDBæ•°æ®é›†ä¸Šå‡å®ç°äº†è‰¯å¥½çš„é›¶æ ·æœ¬æ£€ç´¢æ€§èƒ½ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬è®ºæ–‡æ—¨åœ¨ä»å¤§è§„æ¨¡è›‹ç™½è´¨æ•°æ®é›†ä¸­æ£€ç´¢å…·æœ‰ç›¸ä¼¼ç»“æ„å’Œè¯­ä¹‰çš„è›‹ç™½è´¨ï¼Œä»¥ä¿ƒè¿›é€šè¿‡ç»“æ„ç¡®å®šæ–¹æ³•ï¼ˆå¦‚å†·å†»ç”µå­æ˜¾å¾®é•œï¼‰è·å¾—çš„è›‹ç™½è´¨ç»“æ„çš„åŠŸèƒ½è§£é‡Šã€‚å—è¿‘æœŸè§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰è¿›å±•çš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§CLIPé£æ ¼çš„æ¡†æ¶ï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ å°†3Dè›‹ç™½è´¨ç»“æ„ä¸åŠŸèƒ½æ³¨é‡Šå¯¹é½ã€‚ä¸ºæ¨¡å‹è®­ç»ƒï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªåŒ…å«çº¦20ä¸‡ä¸ªè›‹ç™½è´¨-æè¿°å¯¹çš„å¤§è§„æ¨¡æ•°æ®é›†ï¼Œå…·æœ‰ä¸°å¯Œçš„åŠŸèƒ½æè¿°ã€‚æˆ‘ä»¬åœ¨è›‹ç™½è´¨æ•°æ®é“¶è¡Œï¼ˆPDBï¼‰å’Œç”µå­æ˜¾å¾®é•œæ•°æ®é“¶è¡Œï¼ˆEMDBï¼‰æ•°æ®é›†ä¸Šè¯„ä¼°äº†æ¨¡å‹ï¼Œåœ¨é¢†åŸŸå†…å’Œæ›´å…·æŒ‘æˆ˜æ€§çš„è·¨æ•°æ®åº“æ£€ç´¢ä¸­å‡è¡¨ç°å‡ºè‰¯å¥½çš„é›¶æ ·æœ¬æ£€ç´¢æ€§èƒ½ï¼Œçªæ˜¾äº†å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹åœ¨è›‹ç™½è´¨ç”Ÿç‰©å­¦ä¸­çš„ç»“æ„-åŠŸèƒ½ç†è§£æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ä»å¤§è§„æ¨¡è›‹ç™½è´¨æ•°æ®é›†ä¸­æ£€ç´¢ç›¸ä¼¼è›‹ç™½è´¨çš„å…·ä½“é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨ç»“æ„ä¸åŠŸèƒ½çš„å…³è”æ€§ç†è§£ä¸Šå­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´æ£€ç´¢æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒè§£å†³æ€è·¯æ˜¯åˆ©ç”¨å¯¹æ¯”å­¦ä¹ å°†3Dè›‹ç™½è´¨ç»“æ„ä¸å…¶åŠŸèƒ½æ³¨é‡Šè¿›è¡Œå¯¹é½ï¼Œå€Ÿé‰´äº†è§†è§‰-è¯­è¨€æ¨¡å‹çš„æˆåŠŸç»éªŒã€‚è¿™æ ·çš„è®¾è®¡èƒ½å¤Ÿæœ‰æ•ˆæ•æ‰è›‹ç™½è´¨çš„ç»“æ„ç‰¹å¾ä¸åŠŸèƒ½æè¿°ä¹‹é—´çš„å…³ç³»ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œæ£€ç´¢ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œæ„å»ºåŒ…å«è›‹ç™½è´¨åŠå…¶åŠŸèƒ½æè¿°çš„æ•°æ®é›†ï¼›å…¶æ¬¡ï¼Œé‡‡ç”¨å¯¹æ¯”å­¦ä¹ è®­ç»ƒæ¨¡å‹ä»¥å®ç°ç»“æ„ä¸åŠŸèƒ½çš„å¯¹é½ï¼›æœ€åï¼Œé€šè¿‡æ£€ç´¢æ¨¡å—è¿›è¡Œç›¸ä¼¼è›‹ç™½è´¨çš„æŸ¥æ‰¾ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ä¸€ä¸ªå¤§è§„æ¨¡çš„è›‹ç™½è´¨-æè¿°å¯¹æ•°æ®é›†ï¼Œå¹¶é‡‡ç”¨å¯¹æ¯”å­¦ä¹ æ–¹æ³•è¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºï¼Œèƒ½å¤ŸåŒæ—¶è€ƒè™‘ç»“æ„å’ŒåŠŸèƒ½ä¿¡æ¯ï¼Œä»è€Œæé«˜æ£€ç´¢çš„å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–å¯¹æ¯”å­¦ä¹ è¿‡ç¨‹ï¼Œå¹¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†è°ƒæ•´ï¼Œä»¥é€‚åº”3Dè›‹ç™½è´¨ç»“æ„çš„ç‰¹å¾æå–ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨PDBå’ŒEMDBæ•°æ®é›†ä¸Šå‡å®ç°äº†è‰¯å¥½çš„é›¶æ ·æœ¬æ£€ç´¢æ€§èƒ½ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨è·¨æ•°æ®åº“æ£€ç´¢ä¸­ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•ï¼Œæ£€ç´¢å‡†ç¡®ç‡æå‡äº†æ˜¾è‘—çš„ç™¾åˆ†æ¯”ï¼ŒéªŒè¯äº†å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹åœ¨è›‹ç™½è´¨ç”Ÿç‰©å­¦ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç”Ÿç‰©ä¿¡æ¯å­¦ã€è¯ç‰©å‘ç°å’Œè›‹ç™½è´¨å·¥ç¨‹ç­‰ã€‚é€šè¿‡æœ‰æ•ˆæ£€ç´¢ç›¸ä¼¼è›‹ç™½è´¨ï¼Œç ”ç©¶äººå‘˜å¯ä»¥æ›´å¥½åœ°ç†è§£è›‹ç™½è´¨çš„åŠŸèƒ½ï¼Œæ¨åŠ¨æ–°è¯ç ”å‘å’Œç”Ÿç‰©æŠ€æœ¯çš„è¿›æ­¥ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›åœ¨è›‹ç™½è´¨ç»“æ„ä¸åŠŸèƒ½çš„å…³è”æ€§ç ”ç©¶ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper aims to retrieve proteins with similar structures and semantics from large-scale protein dataset, facilitating the functional interpretation of protein structures derived by structural determination methods like cryo-Electron Microscopy (cryo-EM). Motivated by the recent progress of vision-language models (VLMs), we propose a CLIP-style framework for aligning 3D protein structures with functional annotations using contrastive learning. For model training, we propose a large-scale dataset of approximately 200,000 protein-caption pairs with rich functional descriptors. We evaluate our model in both in-domain and more challenging cross-database retrieval on Protein Data Bank (PDB) and Electron Microscopy Data Bank (EMDB) dataset, respectively. In both cases, our approach demonstrates promising zero-shot retrieval performance, highlighting the potential of multimodal foundation models for structure-function understanding in protein biology.

