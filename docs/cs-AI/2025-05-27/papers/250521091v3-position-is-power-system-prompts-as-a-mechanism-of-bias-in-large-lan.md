---
layout: default
title: "Position is Power: System Prompts as a Mechanism of Bias in Large Language Models (LLMs)"
---

# Position is Power: System Prompts as a Mechanism of Bias in Large Language Models (LLMs)

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21091" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21091v3</a>
  <a href="https://arxiv.org/pdf/2505.21091.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21091v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21091v3', 'Position is Power: System Prompts as a Mechanism of Bias in Large Language Models (LLMs)')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Anna Neumann, Elisabeth Kirsten, Muhammad Bilal Zafar, Jatinder Singh

**åˆ†ç±»**: cs.CY, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27 (æ›´æ–°: 2025-06-23)

**å¤‡æ³¨**: Published in Proceedings of ACM FAccT 2025 Update Comment: Fixed the error where user vs. system and implicit vs. explicit labels in the heatmaps were switched. The takeaways remain the same

**DOI**: [10.1145/3715275.3732038](https://doi.org/10.1145/3715275.3732038)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ¢è®¨ç³»ç»Ÿæç¤ºå¯¹å¤§å‹è¯­è¨€æ¨¡å‹åè§çš„å½±å“åŠå…¶é€æ˜æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ç³»ç»Ÿæç¤º` `åè§åˆ†æ` `é€æ˜æ€§` `AIå®¡è®¡` `äººå£ç»Ÿè®¡ä¿¡æ¯` `æ¨¡å‹å…¬å¹³æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„LLMsåœ¨ä½¿ç”¨ç³»ç»Ÿæç¤ºæ—¶ç¼ºä¹é€æ˜æ€§ï¼Œå¯¼è‡´æ½œåœ¨çš„åè§å’Œä¸å¹³ç­‰çš„è¡¨ç°ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡æ¯”è¾ƒç³»ç»Ÿæç¤ºä¸ç”¨æˆ·æç¤ºä¸­äººå£ç»Ÿè®¡ä¿¡æ¯çš„å¤„ç†æ–¹å¼ï¼Œæ¥æ­ç¤ºæ¨¡å‹è¡Œä¸ºçš„åè§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå…­ç§LLMsåœ¨å¤„ç†ä¸åŒäººå£ç»Ÿè®¡ç»„æ—¶å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œå½±å“äº†ç”¨æˆ·çš„ä»£è¡¨æ€§å’Œå†³ç­–è¿‡ç¨‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ç ”ç©¶äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­çš„ç³»ç»Ÿæç¤ºå¦‚ä½•å½±å“æ¨¡å‹è¡Œä¸ºï¼Œå°¤å…¶æ˜¯å…¶åœ¨å¤„ç†ç”¨æˆ·è¾“å…¥æ—¶çš„ä¼˜å…ˆçº§ã€‚éšç€ç³»ç»Ÿæç¤ºçš„å¤æ‚æ€§å¢åŠ ï¼Œå¯èƒ½ä¼šå¼•å…¥æœªè¢«è€ƒè™‘çš„å‰¯ä½œç”¨ï¼Œå¯¼è‡´ç”¨æˆ·æ— æ³•æ£€æµ‹æˆ–çº æ­£çš„åè§ã€‚é€šè¿‡æ¯”è¾ƒå…­ç§å•†ä¸šLLMsåœ¨å¤„ç†äººå£ç»Ÿè®¡ä¿¡æ¯æ—¶çš„è¡¨ç°ï¼Œå‘ç°äº†æ˜¾è‘—çš„åè§ï¼Œå½±å“äº†ç”¨æˆ·ä»£è¡¨æ€§å’Œå†³ç­–åœºæ™¯ã€‚ç ”ç©¶å¼ºè°ƒäº†ç³»ç»Ÿæç¤ºåˆ†æåœ¨AIå®¡è®¡è¿‡ç¨‹ä¸­çš„é‡è¦æ€§ï¼Œå°¤å…¶æ˜¯åœ¨å¯å®šåˆ¶ç³»ç»Ÿæç¤ºæ—¥ç›Šæ™®åŠçš„èƒŒæ™¯ä¸‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ä¸­ç³»ç»Ÿæç¤ºçš„é€æ˜æ€§ä¸è¶³åŠå…¶å¼•å‘çš„åè§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆè¯†åˆ«å’Œçº æ­£ç³»ç»Ÿæç¤ºå¯¹æ¨¡å‹è¾“å‡ºçš„å½±å“ï¼Œå¯¼è‡´æ½œåœ¨çš„ä»£è¡¨æ€§å’Œåˆ†é…åè§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šç ”ç©¶é€šè¿‡æ¯”è¾ƒç³»ç»Ÿæç¤ºä¸ç”¨æˆ·æç¤ºåœ¨å¤„ç†äººå£ç»Ÿè®¡ä¿¡æ¯æ—¶çš„å·®å¼‚ï¼Œæ­ç¤ºä¿¡æ¯ä½ç½®å¯¹æ¨¡å‹è¡Œä¸ºçš„å½±å“ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨æé«˜å¯¹ç³»ç»Ÿæç¤ºçš„ç†è§£ï¼Œè¿›è€Œä¿ƒè¿›æ¨¡å‹çš„å…¬å¹³æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨äº†å¯¹æ¯”åˆ†æçš„æ–¹æ³•ï¼Œé€‰å–å…­ç§å•†ä¸šLLMsï¼Œå¹¶å¯¹50ä¸ªä¸åŒçš„äººå£ç»Ÿè®¡ç»„è¿›è¡Œæµ‹è¯•ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ¨¡å‹è¾“å‡ºåˆ†æå’Œåè§è¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„åˆ›æ–°ç‚¹åœ¨äºç³»ç»Ÿæ€§åœ°åˆ†æäº†ç³»ç»Ÿæç¤ºçš„å±‚æ¬¡ç»“æ„å¯¹æ¨¡å‹è¾“å‡ºçš„å½±å“ï¼Œæ­ç¤ºäº†å…¶åœ¨ä¸åŒä¸Šä¸‹æ–‡ä¸­çš„åè§è¡¨ç°ã€‚è¿™ä¸ä¼ ç»Ÿçš„ç”¨æˆ·è¾“å…¥åˆ†ææ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šç ”ç©¶ä¸­ä½¿ç”¨äº†æ ‡å‡†åŒ–çš„æµ‹è¯•é›†å’Œè¯„ä¼°æŒ‡æ ‡ï¼Œä»¥ç¡®ä¿ç»“æœçš„å¯é‡å¤æ€§å’Œå¯é æ€§ã€‚æ¨¡å‹çš„è¾“å‡ºè¢«ç³»ç»Ÿåœ°åˆ†ç±»å’Œæ¯”è¾ƒï¼Œä»¥è¯†åˆ«æ½œåœ¨çš„åè§å’Œä¸å¹³ç­‰è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨å¤„ç†äººå£ç»Ÿè®¡ä¿¡æ¯æ—¶ï¼Œå…­ç§LLMsä¹‹é—´å­˜åœ¨æ˜¾è‘—çš„åè§ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨ç”¨æˆ·ä»£è¡¨æ€§å’Œå†³ç­–åœºæ™¯ä¸­çš„å·®å¼‚ã€‚è¿™äº›åè§çš„å­˜åœ¨å¯èƒ½å¯¼è‡´ä¸å¹³ç­‰çš„ç»“æœï¼Œå¼ºè°ƒäº†ç³»ç»Ÿæç¤ºåˆ†æåœ¨AIæ¨¡å‹å¼€å‘ä¸­çš„é‡è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬AIå®¡è®¡ã€æ¨¡å‹å¼€å‘å’Œæ”¿ç­–åˆ¶å®šç­‰ã€‚é€šè¿‡æé«˜å¯¹ç³»ç»Ÿæç¤ºçš„é€æ˜æ€§ï¼Œèƒ½å¤Ÿå¸®åŠ©å¼€å‘è€…å’Œç”¨æˆ·æ›´å¥½åœ°ç†è§£å’Œæ§åˆ¶æ¨¡å‹è¡Œä¸ºï¼Œä»è€Œå‡å°‘åè§å’Œä¸å¹³ç­‰ç°è±¡çš„å‘ç”Ÿã€‚æœªæ¥ï¼Œéšç€AIæŠ€æœ¯çš„æ™®åŠï¼Œè¿™ä¸€ç ”ç©¶å°†å¯¹ä¿ƒè¿›å…¬å¹³å’Œé€æ˜çš„AIç³»ç»Ÿå…·æœ‰é‡è¦ä»·å€¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> System prompts in Large Language Models (LLMs) are predefined directives that guide model behaviour, taking precedence over user inputs in text processing and generation. LLM deployers increasingly use them to ensure consistent responses across contexts. While model providers set a foundation of system prompts, deployers and third-party developers can append additional prompts without visibility into others' additions, while this layered implementation remains entirely hidden from end-users. As system prompts become more complex, they can directly or indirectly introduce unaccounted for side effects. This lack of transparency raises fundamental questions about how the position of information in different directives shapes model outputs. As such, this work examines how the placement of information affects model behaviour. To this end, we compare how models process demographic information in system versus user prompts across six commercially available LLMs and 50 demographic groups. Our analysis reveals significant biases, manifesting in differences in user representation and decision-making scenarios. Since these variations stem from inaccessible and opaque system-level configurations, they risk representational, allocative and potential other biases and downstream harms beyond the user's ability to detect or correct. Our findings draw attention to these critical issues, which have the potential to perpetuate harms if left unexamined. Further, we argue that system prompt analysis must be incorporated into AI auditing processes, particularly as customisable system prompts become increasingly prevalent in commercial AI deployments.

