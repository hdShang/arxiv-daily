---
layout: default
title: "MME-Reasoning: A Comprehensive Benchmark for Logical Reasoning in MLLMs"
---

# MME-Reasoning: A Comprehensive Benchmark for Logical Reasoning in MLLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21327" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21327v1</a>
  <a href="https://arxiv.org/pdf/2505.21327.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21327v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21327v1', 'MME-Reasoning: A Comprehensive Benchmark for Logical Reasoning in MLLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiakang Yuan, Tianshuo Peng, Yilei Jiang, Yiting Lu, Renrui Zhang, Kaituo Feng, Chaoyou Fu, Tao Chen, Lei Bai, Bo Zhang, Xiangyu Yue

**åˆ†ç±»**: cs.AI, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMME-Reasoningä»¥è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹é€»è¾‘æ¨ç†è¯„ä¼°ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é€»è¾‘æ¨ç†` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `è¯„ä¼°åŸºå‡†` `å½’çº³æ¨ç†` `æ¼”ç»æ¨ç†` `æº¯å› æ¨ç†` `äººå·¥æ™ºèƒ½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨é€»è¾‘æ¨ç†èƒ½åŠ›è¯„ä¼°ä¸Šå­˜åœ¨ä¸è¶³ï¼Œç¼ºä¹å¯¹æ¨ç†ç±»å‹çš„æ˜ç¡®åˆ†ç±»ã€‚
2. è®ºæ–‡æå‡ºMME-ReasoningåŸºå‡†ï¼Œå…¨é¢è¯„ä¼°MLLMsçš„é€»è¾‘æ¨ç†èƒ½åŠ›ï¼Œæ¶µç›–å½’çº³ã€æ¼”ç»å’Œæº¯å› æ¨ç†ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå½“å‰æœ€å…ˆè¿›çš„MLLMsåœ¨é€»è¾‘æ¨ç†èƒ½åŠ›ä¸Šå­˜åœ¨æ˜¾è‘—å±€é™ï¼Œå°¤å…¶åœ¨ä¸åŒæ¨ç†ç±»å‹é—´è¡¨ç°ä¸å‡è¡¡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é€»è¾‘æ¨ç†æ˜¯äººç±»æ™ºèƒ½çš„åŸºæœ¬æ–¹é¢ï¼Œä¹Ÿæ˜¯å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰å¿…å¤‡çš„èƒ½åŠ›ã€‚å°½ç®¡å¤šæ¨¡æ€æ¨ç†å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œç°æœ‰åŸºå‡†æµ‹è¯•æœªèƒ½å…¨é¢è¯„ä¼°å…¶æ¨ç†èƒ½åŠ›ï¼Œä¸»è¦ç”±äºç¼ºä¹å¯¹é€»è¾‘æ¨ç†ç±»å‹çš„æ˜ç¡®åˆ†ç±»å’Œå¯¹æ¨ç†ç†è§£çš„ä¸æ¸…æ™°ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†MME-Reasoningï¼Œè¿™æ˜¯ä¸€ä¸ªå…¨é¢çš„åŸºå‡†ï¼Œæ—¨åœ¨è¯„ä¼°MLLMsçš„æ¨ç†èƒ½åŠ›ï¼Œæ¶µç›–å½’çº³ã€æ¼”ç»å’Œæº¯å› ä¸‰ç§æ¨ç†ç±»å‹ã€‚æˆ‘ä»¬ç²¾å¿ƒç­–åˆ’æ•°æ®ï¼Œç¡®ä¿æ¯ä¸ªé—®é¢˜æœ‰æ•ˆè¯„ä¼°æ¨ç†èƒ½åŠ›ï¼Œè€Œéæ„ŸçŸ¥æŠ€èƒ½æˆ–çŸ¥è¯†å¹¿åº¦ï¼Œå¹¶æ‰©å±•è¯„ä¼°åè®®ä»¥æ¶µç›–å¤šæ ·åŒ–é—®é¢˜ã€‚æˆ‘ä»¬çš„è¯„ä¼°æ­ç¤ºäº†å½“å‰æœ€å…ˆè¿›çš„MLLMsåœ¨å…¨é¢é€»è¾‘æ¨ç†èƒ½åŠ›è¯„ä¼°ä¸­çš„æ˜¾è‘—å±€é™æ€§ï¼Œç”šè‡³æœ€å…ˆè¿›çš„æ¨¡å‹åœ¨ç»¼åˆé€»è¾‘æ¨ç†ä¸­è¡¨ç°æœ‰é™ï¼Œä¸”ä¸åŒæ¨ç†ç±»å‹ä¹‹é—´å­˜åœ¨æ˜¾è‘—çš„æ€§èƒ½ä¸å¹³è¡¡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨é€»è¾‘æ¨ç†èƒ½åŠ›è¯„ä¼°ä¸­çš„ä¸è¶³ï¼Œç‰¹åˆ«æ˜¯ç¼ºä¹å¯¹ä¸åŒæ¨ç†ç±»å‹çš„æ˜ç¡®åˆ†ç±»å’Œè¯„ä¼°æ ‡å‡†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºMME-ReasoningåŸºå‡†ï¼Œé€šè¿‡ç²¾å¿ƒç­–åˆ’çš„é—®é¢˜è®¾è®¡ï¼Œç¡®ä¿æ¯ä¸ªé—®é¢˜æœ‰æ•ˆè¯„ä¼°æ¨ç†èƒ½åŠ›ï¼Œè€Œéä¾èµ–æ„ŸçŸ¥æŠ€èƒ½æˆ–çŸ¥è¯†å¹¿åº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®ç­–åˆ’ã€é—®é¢˜åˆ†ç±»ã€è¯„ä¼°åè®®æ‰©å±•ç­‰ä¸»è¦æ¨¡å—ï¼Œç¡®ä¿å…¨é¢è¦†ç›–å½’çº³ã€æ¼”ç»å’Œæº¯å› æ¨ç†ç±»å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå…¨é¢è¯„ä¼°é€»è¾‘æ¨ç†èƒ½åŠ›ï¼Œæ­ç¤ºäº†å½“å‰MLLMsåœ¨ä¸åŒæ¨ç†ç±»å‹ä¸Šçš„æ€§èƒ½ä¸å¹³è¡¡ï¼Œæä¾›äº†ç³»ç»Ÿçš„è¯„ä¼°æ¡†æ¶ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®ç­–åˆ’ä¸­ï¼Œç¡®ä¿é—®é¢˜çš„å¤šæ ·æ€§å’Œé’ˆå¯¹æ€§ï¼Œè®¾è®¡äº†æ–°çš„è¯„ä¼°åè®®ï¼Œæ¶µç›–å¤šç§æ¨ç†åœºæ™¯ï¼Œç¡®ä¿è¯„ä¼°çš„å…¨é¢æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå½“å‰æœ€å…ˆè¿›çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨MME-ReasoningåŸºå‡†ä¸Šè¡¨ç°æœ‰é™ï¼Œå°¤å…¶åœ¨ç»¼åˆé€»è¾‘æ¨ç†èƒ½åŠ›è¯„ä¼°ä¸­ï¼Œæ€§èƒ½å·®å¼‚æ˜¾è‘—ï¼Œå½’çº³æ¨ç†çš„è¡¨ç°æ˜æ˜¾ä¼˜äºæ¼”ç»å’Œæº¯å› æ¨ç†ï¼Œæ­ç¤ºäº†æ¨¡å‹åœ¨é€»è¾‘æ¨ç†æ–¹é¢çš„å…³é”®çŸ­æ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€æ™ºèƒ½é—®ç­”ç³»ç»Ÿå’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„é€»è¾‘æ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥åœ¨æ›´å¤æ‚çš„åœºæ™¯ä¸­å®ç°æ›´é«˜æ•ˆçš„æ™ºèƒ½å†³ç­–å’Œäº¤äº’ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨äººå·¥æ™ºèƒ½åœ¨å„ä¸ªé¢†åŸŸçš„å¹¿æ³›åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Logical reasoning is a fundamental aspect of human intelligence and an essential capability for multimodal large language models (MLLMs). Despite the significant advancement in multimodal reasoning, existing benchmarks fail to comprehensively evaluate their reasoning abilities due to the lack of explicit categorization for logical reasoning types and an unclear understanding of reasoning. To address these issues, we introduce MME-Reasoning, a comprehensive benchmark designed to evaluate the reasoning ability of MLLMs, which covers all three types of reasoning (i.e., inductive, deductive, and abductive) in its questions. We carefully curate the data to ensure that each question effectively evaluates reasoning ability rather than perceptual skills or knowledge breadth, and extend the evaluation protocols to cover the evaluation of diverse questions. Our evaluation reveals substantial limitations of state-of-the-art MLLMs when subjected to holistic assessments of logical reasoning capabilities. Even the most advanced MLLMs show limited performance in comprehensive logical reasoning, with notable performance imbalances across reasoning types. In addition, we conducted an in-depth analysis of approaches such as ``thinking mode'' and Rule-based RL, which are commonly believed to enhance reasoning abilities. These findings highlight the critical limitations and performance imbalances of current MLLMs in diverse logical reasoning scenarios, providing comprehensive and systematic insights into the understanding and evaluation of reasoning capabilities.

