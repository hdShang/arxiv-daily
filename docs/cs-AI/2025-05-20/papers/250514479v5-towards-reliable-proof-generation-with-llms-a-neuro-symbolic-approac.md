---
layout: default
title: "Towards Reliable Proof Generation with LLMs: A Neuro-Symbolic Approach"
---

# Towards Reliable Proof Generation with LLMs: A Neuro-Symbolic Approach

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14479" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14479v5</a>
  <a href="https://arxiv.org/pdf/2505.14479.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14479v5" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14479v5', 'Towards Reliable Proof Generation with LLMs: A Neuro-Symbolic Approach')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Oren Sultan, Eitan Stern, Dafna Shahaf

**åˆ†ç±»**: cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20 (æ›´æ–°: 2025-12-13)

**å¤‡æ³¨**: long paper

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç¥ç»ç¬¦å·æ–¹æ³•ä»¥è§£å†³æ•°å­¦è¯æ˜ç”Ÿæˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ•°å­¦è¯æ˜` `ç¥ç»ç¬¦å·æ–¹æ³•` `é€»è¾‘æ¨ç†` `å½¢å¼éªŒè¯` `æœºå™¨å­¦ä¹ ` `æ¨ç†ç³»ç»Ÿ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†éœ€è¦ä¸¥æ ¼é€»è¾‘æ¨ç†çš„æ•°å­¦è¯æ˜æ—¶å­˜åœ¨å‡†ç¡®æ€§ä¸è¶³çš„é—®é¢˜ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§ç¥ç»ç¬¦å·æ–¹æ³•ï¼Œé€šè¿‡æ£€ç´¢ç±»ä¼¼é—®é¢˜å’Œä½¿ç”¨å½¢å¼éªŒè¯å™¨æ¥æŒ‡å¯¼å’Œä¿®æ­£LLMç”Ÿæˆçš„è¯æ˜ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æå‡äº†è¯æ˜çš„å‡†ç¡®æ€§ï¼ŒOpenAIçš„o1æ¨¡å‹çš„æ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°58%-70%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨éœ€è¦ä¸¥æ ¼é€»è¾‘æ¨ç†å’Œç¬¦å·æ¨ç†çš„æ­£å¼é¢†åŸŸï¼ˆå¦‚æ•°å­¦è¯æ˜ç”Ÿæˆï¼‰ä¸­è¡¨ç°ä¸ä½³ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ç¥ç»ç¬¦å·æ–¹æ³•ï¼Œç»“åˆäº†LLMsçš„ç”Ÿæˆä¼˜åŠ¿ä¸ç»“æ„åŒ–ç»„ä»¶ï¼Œä»¥å…‹æœè¿™ä¸€æŒ‘æˆ˜ã€‚ä½œä¸ºæ¦‚å¿µéªŒè¯ï¼Œæˆ‘ä»¬ä¸“æ³¨äºå‡ ä½•é—®é¢˜ã€‚è¯¥æ–¹æ³•åŒ…æ‹¬ä¸¤ä¸ªæ–¹é¢ï¼šï¼ˆ1ï¼‰æ£€ç´¢ç±»ä¼¼é—®é¢˜å¹¶åˆ©ç”¨å…¶è¯æ˜æŒ‡å¯¼LLMï¼›ï¼ˆ2ï¼‰ä½¿ç”¨å½¢å¼éªŒè¯å™¨è¯„ä¼°ç”Ÿæˆçš„è¯æ˜å¹¶æä¾›åé¦ˆï¼Œå¸®åŠ©æ¨¡å‹ä¿®æ­£é”™è¯¯è¯æ˜ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æé«˜äº†OpenAIçš„o1æ¨¡å‹çš„è¯æ˜å‡†ç¡®æ€§ï¼ˆæå‡å¹…åº¦ä¸º58%-70%ï¼‰ï¼Œå…¶ä¸­ç±»ä¼¼é—®é¢˜å’ŒéªŒè¯å™¨åé¦ˆå‡å¯¹æå‡æ•ˆæœæœ‰è´¡çŒ®ã€‚æ›´å¹¿æ³›åœ°è¯´ï¼Œè½¬å‘ç”Ÿæˆå¯è¯æ˜æ­£ç¡®ç»“è®ºçš„LLMså°†æ˜¾è‘—æé«˜å…¶å¯é æ€§ã€å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ï¼Œä»è€Œè§£é”éœ€è¦å¯ä¿¡åº¦çš„å¤æ‚ä»»åŠ¡å’Œå…³é”®ç°å®åº”ç”¨ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ•°å­¦è¯æ˜ç”Ÿæˆä¸­çš„å‡†ç¡®æ€§ä¸è¶³é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨é€»è¾‘æ¨ç†å’Œç¬¦å·æ¨ç†æ–¹é¢å­˜åœ¨æ˜æ˜¾çŸ­æ¿ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºçš„ç¥ç»ç¬¦å·æ–¹æ³•ç»“åˆäº†LLMsçš„ç”Ÿæˆèƒ½åŠ›ä¸ç»“æ„åŒ–çš„æ¨ç†ç»„ä»¶ï¼Œé€šè¿‡æ£€ç´¢ç›¸ä¼¼é—®é¢˜å’Œå½¢å¼éªŒè¯å™¨çš„åé¦ˆæ¥æå‡è¯æ˜çš„å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œæ£€ç´¢ä¸å½“å‰é—®é¢˜ç›¸ä¼¼çš„å·²è§£å†³é—®é¢˜åŠå…¶è¯æ˜ï¼›å…¶æ¬¡ï¼Œåˆ©ç”¨å½¢å¼éªŒè¯å™¨å¯¹ç”Ÿæˆçš„è¯æ˜è¿›è¡Œè¯„ä¼°å¹¶æä¾›åé¦ˆã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†LLMsä¸å½¢å¼éªŒè¯å™¨ç»“åˆï¼Œå½¢æˆä¸€ä¸ªé—­ç¯åé¦ˆæœºåˆ¶ï¼Œä½¿å¾—ç”Ÿæˆçš„è¯æ˜èƒ½å¤Ÿç»è¿‡éªŒè¯å’Œä¿®æ­£ï¼Œä»è€Œæé«˜äº†ç”Ÿæˆç»“æœçš„å¯é æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–ç”Ÿæˆè¯æ˜çš„å‡†ç¡®æ€§ï¼Œå¹¶è®¾è®¡äº†é€‚åº”æ€§åé¦ˆæœºåˆ¶ï¼Œä½¿å¾—éªŒè¯å™¨èƒ½å¤Ÿæœ‰æ•ˆåœ°è¯†åˆ«å’Œçº æ­£é”™è¯¯ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹èƒ½å¤Ÿåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ä¸æ–­å­¦ä¹ å’Œæ”¹è¿›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œé‡‡ç”¨ç¥ç»ç¬¦å·æ–¹æ³•åï¼ŒOpenAIçš„o1æ¨¡å‹åœ¨æ•°å­¦è¯æ˜ç”Ÿæˆä»»åŠ¡ä¸­çš„å‡†ç¡®æ€§æå‡äº†58%-70%ã€‚è¿™ä¸€æ˜¾è‘—æå‡è¡¨æ˜ï¼Œç»“åˆç±»ä¼¼é—®é¢˜çš„æ£€ç´¢å’Œå½¢å¼éªŒè¯å™¨çš„åé¦ˆå¯¹æé«˜ç”Ÿæˆç»“æœçš„å¯é æ€§è‡³å…³é‡è¦ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€è‡ªåŠ¨åŒ–å®šç†è¯æ˜ã€ä»¥åŠéœ€è¦é«˜å¯é æ€§çš„ç§‘å­¦è®¡ç®—ç­‰ã€‚é€šè¿‡æé«˜å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é€»è¾‘æ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œå¯ä»¥æ¨åŠ¨æ™ºèƒ½åŠ©æ‰‹ã€è‡ªåŠ¨åŒ–æ¨ç†ç³»ç»Ÿç­‰æŠ€æœ¯çš„å‘å±•ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) struggle with formal domains that require rigorous logical deduction and symbolic reasoning, such as mathematical proof generation. We propose a neuro-symbolic approach that combines LLMs' generative strengths with structured components to overcome this challenge. As a proof-of-concept, we focus on geometry problems. Our approach is two-fold: (1) we retrieve analogous problems and use their proofs to guide the LLM, and (2) a formal verifier evaluates the generated proofs and provides feedback, helping the model fix incorrect proofs. We demonstrate that our method significantly improves proof accuracy for OpenAI's o1 model (58%-70% improvement); both analogous problems and the verifier's feedback contribute to these gains. More broadly, shifting to LLMs that generate provably correct conclusions could dramatically improve their reliability, accuracy and consistency, unlocking complex tasks and critical real-world applications that require trustworthiness.

