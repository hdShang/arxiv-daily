---
layout: default
title: Guarded Query Routing for Large Language Models
---

# Guarded Query Routing for Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14524" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14524v3</a>
  <a href="https://arxiv.org/pdf/2505.14524.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14524v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14524v3', 'Guarded Query Routing for Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Richard Å lÃ©her, William Brach, Tibor Sloboda, KristiÃ¡n KoÅ¡Å¥Ã¡l, Lukas Galke

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20 (æ›´æ–°: 2025-10-25)

**DOI**: [10.3233/FAIA251304](https://doi.org/10.3233/FAIA251304)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/williambrach/gqr)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå—ä¿æŠ¤çš„æŸ¥è¯¢è·¯ç”±æ–¹æ³•ä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹çš„æŸ¥è¯¢åˆ†ç±»é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æŸ¥è¯¢è·¯ç”±` `å¤§è¯­è¨€æ¨¡å‹` `åˆ†å¸ƒå¤–æ£€æµ‹` `æœºå™¨å­¦ä¹ ` `æ•°æ®é›†æ„å»º` `æ¨¡å‹å¯¹æ¯”` `æ³•å¾‹` `é‡‘è`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æŸ¥è¯¢è·¯ç”±æ–¹æ³•åœ¨å¤„ç†åˆ†å¸ƒå¤–æŸ¥è¯¢æ—¶å­˜åœ¨ä¸è¶³ï¼Œå¯èƒ½å¯¼è‡´ä¸ç›¸å…³æˆ–ä¸å®‰å…¨çš„å“åº”ã€‚
2. æœ¬æ–‡æå‡ºäº†å—ä¿æŠ¤æŸ¥è¯¢è·¯ç”±åŸºå‡†ï¼ˆGQR-Benchï¼‰ï¼Œé€šè¿‡å¤šç§æ¨¡å‹å¯¹æ¯”ï¼Œæ¢ç´¢æœ‰æ•ˆçš„æŸ¥è¯¢è·¯ç”±æœºåˆ¶ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒWideMLPåœ¨å‡†ç¡®æ€§å’Œé€Ÿåº¦ä¸Šè¡¨ç°æœ€ä½³ï¼Œè€ŒLLMæ¨¡å‹è™½ç„¶å‡†ç¡®æ€§é«˜ï¼Œä½†é€Ÿåº¦è¾ƒæ…¢ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æŸ¥è¯¢è·¯ç”±æ˜¯å°†ç”¨æˆ·æŸ¥è¯¢åˆ†é…åˆ°ä¸åŒçš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç«¯ç‚¹çš„ä»»åŠ¡ï¼Œå¯ä»¥è§†ä¸ºæ–‡æœ¬åˆ†ç±»é—®é¢˜ã€‚ç„¶è€Œï¼Œå¿…é¡»å¦¥å–„å¤„ç†åˆ†å¸ƒå¤–æŸ¥è¯¢ï¼Œè¿™äº›æŸ¥è¯¢å¯èƒ½æ¶‰åŠä¸ç›¸å…³çš„é¢†åŸŸã€å…¶ä»–è¯­è¨€æˆ–åŒ…å«ä¸å®‰å…¨æ–‡æœ¬ã€‚æœ¬æ–‡ç ”ç©¶äº†ä¸€ç§å—ä¿æŠ¤çš„æŸ¥è¯¢è·¯ç”±é—®é¢˜ï¼Œé¦–æ¬¡å¼•å…¥äº†å—ä¿æŠ¤æŸ¥è¯¢è·¯ç”±åŸºå‡†ï¼ˆGQR-Benchï¼‰ï¼Œæ¶µç›–æ³•å¾‹ã€é‡‘èå’ŒåŒ»ç–—ä¸‰ä¸ªç¤ºä¾‹ç›®æ ‡é¢†åŸŸï¼Œä»¥åŠä¸ƒä¸ªæ•°æ®é›†ä»¥æµ‹è¯•å¯¹åˆ†å¸ƒå¤–æŸ¥è¯¢çš„é²æ£’æ€§ã€‚é€šè¿‡GQR-Benchï¼Œæˆ‘ä»¬å¯¹æ¯”äº†å¤šç§è·¯ç”±æœºåˆ¶çš„æœ‰æ•ˆæ€§å’Œæ•ˆç‡ï¼Œç»“æœæ˜¾ç¤ºï¼Œå¢å¼ºäº†åˆ†å¸ƒå¤–æ£€æµ‹èƒ½åŠ›çš„WideMLPåœ¨å‡†ç¡®æ€§ï¼ˆ88%ï¼‰å’Œé€Ÿåº¦ï¼ˆ<4msï¼‰ä¹‹é—´å–å¾—äº†æœ€ä½³å¹³è¡¡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹åœ¨æŸ¥è¯¢è·¯ç”±ä¸­å¯¹åˆ†å¸ƒå¤–æŸ¥è¯¢çš„å¤„ç†é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨é¢å¯¹ä¸ç›¸å…³é¢†åŸŸæˆ–ä¸å®‰å…¨å†…å®¹æ—¶ï¼Œå¯èƒ½æ— æ³•æœ‰æ•ˆåˆ†ç±»å’Œè·¯ç”±æŸ¥è¯¢ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºå—ä¿æŠ¤çš„æŸ¥è¯¢è·¯ç”±åŸºå‡†ï¼ˆGQR-Benchï¼‰ï¼Œé€šè¿‡å¼•å…¥åˆ†å¸ƒå¤–æ£€æµ‹èƒ½åŠ›ï¼Œæå‡æŸ¥è¯¢è·¯ç”±çš„å‡†ç¡®æ€§å’Œå®‰å…¨æ€§ã€‚è®¾è®¡çš„æ ¸å¿ƒåœ¨äºç»“åˆä¼ ç»Ÿæœºå™¨å­¦ä¹ ä¸ç°ä»£LLMçš„ä¼˜åŠ¿ï¼Œä»¥å®ç°æ›´é«˜æ•ˆçš„æŸ¥è¯¢å¤„ç†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚é¦–å…ˆæ„å»ºGQR-Benchæ•°æ®é›†ï¼Œç„¶åå¯¹æ¯”å¤šç§æ¨¡å‹çš„è·¯ç”±æ•ˆæœï¼Œæœ€åè¯„ä¼°å…¶åœ¨ä¸åŒæŸ¥è¯¢ç±»å‹ä¸‹çš„è¡¨ç°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†åˆ†å¸ƒå¤–æ£€æµ‹èƒ½åŠ›çš„WideMLPæ¨¡å‹ï¼Œæ˜¾è‘—æå‡äº†æŸ¥è¯¢è·¯ç”±çš„å‡†ç¡®æ€§å’Œå¤„ç†é€Ÿåº¦ï¼Œæ‰“ç ´äº†å¯¹LLMçš„è‡ªåŠ¨ä¾èµ–ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼ŒWideMLPé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ï¼Œä»¥ä¼˜åŒ–å¯¹åˆ†å¸ƒå¤–æŸ¥è¯¢çš„æ£€æµ‹èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒè¾ƒä½çš„è®¡ç®—å»¶è¿Ÿã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒWideMLPåœ¨å‡†ç¡®æ€§ä¸Šè¾¾åˆ°88%ï¼Œå¤„ç†é€Ÿåº¦ä½äº4æ¯«ç§’ï¼Œä¼˜äºå…¶ä»–æ¨¡å‹ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒLLMæ¨¡å‹çš„å‡†ç¡®æ€§æœ€é«˜ï¼ˆ91%ï¼‰ï¼Œä½†å¤„ç†é€Ÿåº¦è¾ƒæ…¢ï¼ˆæœ¬åœ°Llama-3.1:8Bä¸º62æ¯«ç§’ï¼Œè¿œç¨‹GPT-4o-miniä¸º669æ¯«ç§’ï¼‰ï¼ŒæŒ‘æˆ˜äº†å¯¹LLMçš„è‡ªåŠ¨ä¾èµ–ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ³•å¾‹ã€é‡‘èå’ŒåŒ»ç–—ç­‰è¡Œä¸šï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡æŸ¥è¯¢è·¯ç”±çš„å‡†ç¡®æ€§å’Œå®‰å…¨æ€§ï¼Œé™ä½ä¸ç›¸å…³æˆ–ä¸å®‰å…¨å†…å®¹çš„é£é™©ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯æ‰©å±•è‡³æ›´å¤šé¢†åŸŸï¼Œæ¨åŠ¨æ™ºèƒ½é—®ç­”ç³»ç»Ÿçš„å®‰å…¨æ€§ä¸å¯é æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Query routing, the task to route user queries to different large language model (LLM) endpoints, can be considered as a text classification problem. However, out-of-distribution queries must be handled properly, as those could be about unrelated domains, queries in other languages, or even contain unsafe text. Here, we thus study a guarded query routing problem, for which we first introduce the Guarded Query Routing Benchmark (GQR-Bench, released as Python package gqr), covers three exemplary target domains (law, finance, and healthcare), and seven datasets to test robustness against out-of-distribution queries. We then use GQR-Bench to contrast the effectiveness and efficiency of LLM-based routing mechanisms (GPT-4o-mini, Llama-3.2-3B, and Llama-3.1-8B), standard LLM-based guardrail approaches (LlamaGuard and NVIDIA NeMo Guardrails), continuous bag-of-words classifiers (WideMLP, fastText), and traditional machine learning models (SVM, XGBoost). Our results show that WideMLP, enhanced with out-of-domain detection capabilities, yields the best trade-off between accuracy (88%) and speed (<4ms). The embedding-based fastText excels at speed (<1ms) with acceptable accuracy (80%), whereas LLMs yield the highest accuracy (91%) but are comparatively slow (62ms for local Llama-3.1:8B and 669ms for remote GPT-4o-mini calls). Our findings challenge the automatic reliance on LLMs for (guarded) query routing and provide concrete recommendations for practical applications. Source code is available: https://github.com/williambrach/gqr.

