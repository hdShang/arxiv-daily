---
layout: default
title: Multimodal Mixture of Low-Rank Experts for Sentiment Analysis and Emotion Recognition
---

# Multimodal Mixture of Low-Rank Experts for Sentiment Analysis and Emotion Recognition

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14143" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14143v1</a>
  <a href="https://arxiv.org/pdf/2505.14143.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14143v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14143v1', 'Multimodal Mixture of Low-Rank Experts for Sentiment Analysis and Emotion Recognition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shuo Zhang, Jinsong Zhang, Zhejun Zhang, Lei Li

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20

**å¤‡æ³¨**: Accepted to ICME 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šæ¨¡æ€ä½ç§©ä¸“å®¶æ··åˆæ¨¡å‹ä»¥è§£å†³æƒ…æ„Ÿåˆ†æå’Œæƒ…ç»ªè¯†åˆ«é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `æƒ…æ„Ÿåˆ†æ` `æƒ…ç»ªè¯†åˆ«` `ä½ç§©ä¸“å®¶` `å¤šä»»åŠ¡å­¦ä¹ ` `å‚æ•°å…±äº«` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ä¸»è¦é‡‡ç”¨ç¡¬å‚æ•°å…±äº«ï¼Œå¿½è§†äº†å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æä¸æƒ…ç»ªè¯†åˆ«ä¹‹é—´å¤æ‚çš„ä»»åŠ¡ç›¸å…³æ€§ï¼Œå¯¼è‡´å‚æ•°å†²çªã€‚
2. æœ¬æ–‡æå‡ºçš„MMoLREæ–¹æ³•é€šè¿‡å…±äº«å’Œä»»åŠ¡ç‰¹å®šçš„ä¸“å®¶æ¨¡å‹ï¼Œåˆ†åˆ«å»ºæ¨¡å…±åŒå’Œç‹¬ç‰¹çš„ä»»åŠ¡ç‰¹å¾ï¼Œæœ‰æ•ˆé¿å…å‚æ•°å†²çªã€‚
3. åœ¨CMU-MOSIå’ŒCMU-MOSEIæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMMoLREåœ¨æƒ…æ„Ÿåˆ†æä»»åŠ¡ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶åœ¨æƒ…ç»ªè¯†åˆ«ä»»åŠ¡ä¸Šè¡¨ç°å‡ºç«äº‰åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šä»»åŠ¡å­¦ä¹ ï¼ˆMTLï¼‰èƒ½å¤Ÿæœ‰æ•ˆåœ°è½¬ç§»ä»å…¶ä»–ä»»åŠ¡ä¸­è·å¾—çš„é¢å¤–çŸ¥è¯†ã€‚å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æï¼ˆMSAï¼‰ä¸å¤šæ¨¡æ€æƒ…ç»ªè¯†åˆ«ï¼ˆMERï¼‰ä¹‹é—´çš„é«˜åº¦ç›¸å…³æ€§æ”¯æŒå®ƒä»¬çš„è”åˆè®­ç»ƒã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•ä¸»è¦é‡‡ç”¨ç¡¬å‚æ•°å…±äº«ï¼Œå¿½è§†äº†å¤æ‚ä»»åŠ¡ç›¸å…³æ€§å¸¦æ¥çš„å‚æ•°å†²çªã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„MTLæ–¹æ³•ï¼Œç§°ä¸ºå¤šæ¨¡æ€ä½ç§©ä¸“å®¶æ··åˆæ¨¡å‹ï¼ˆMMoLREï¼‰ã€‚MMoLREåˆ©ç”¨å…±äº«å’Œä»»åŠ¡ç‰¹å®šçš„ä¸“å®¶ï¼Œæ˜ç¡®å»ºæ¨¡å…±åŒå’Œç‹¬ç‰¹çš„ä»»åŠ¡ç‰¹å¾ï¼Œä»è€Œé¿å…å‚æ•°å†²çªã€‚æ­¤å¤–ï¼Œå—åˆ°ä½ç§©ç»“æ„çš„å¯å‘ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä½ç§©ä¸“å®¶ç½‘ç»œï¼Œä»¥å‡å°‘éšç€ä¸“å®¶æ•°é‡å¢åŠ è€Œå¸¦æ¥çš„å‚æ•°å’Œè®¡ç®—å¼€é”€ã€‚åœ¨CMU-MOSIå’ŒCMU-MOSEIåŸºå‡†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒMMoLREåœ¨MSAä»»åŠ¡ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œåœ¨MERä»»åŠ¡ä¸Šä¹Ÿå–å¾—äº†ç«äº‰æ€§ç»“æœã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æï¼ˆMSAï¼‰ä¸å¤šæ¨¡æ€æƒ…ç»ªè¯†åˆ«ï¼ˆMERï¼‰ä»»åŠ¡ä¸­çš„å‚æ•°å†²çªé—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é‡‡ç”¨ç¡¬å‚æ•°å…±äº«ï¼Œæœªèƒ½æœ‰æ•ˆå¤„ç†å¤æ‚ä»»åŠ¡é—´çš„ç›¸å…³æ€§ï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMMoLREé€šè¿‡å¼•å…¥å…±äº«å’Œä»»åŠ¡ç‰¹å®šçš„ä¸“å®¶æ¨¡å‹ï¼Œåˆ†åˆ«å»ºæ¨¡ä»»åŠ¡çš„å…±åŒç‰¹å¾å’Œç‹¬ç‰¹ç‰¹å¾ï¼Œä»è€Œæœ‰æ•ˆé¿å…å‚æ•°å†²çªï¼Œæå‡æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMMoLREçš„æ•´ä½“æ¶æ„åŒ…æ‹¬å…±äº«ä¸“å®¶å’Œä»»åŠ¡ç‰¹å®šä¸“å®¶ä¸¤éƒ¨åˆ†ã€‚å…±äº«ä¸“å®¶è´Ÿè´£æ•æ‰ä»»åŠ¡é—´çš„å…±æ€§ï¼Œè€Œä»»åŠ¡ç‰¹å®šä¸“å®¶åˆ™ä¸“æ³¨äºå„è‡ªä»»åŠ¡çš„ç‹¬ç‰¹ç‰¹å¾ã€‚è¯¥æ¡†æ¶è¿˜ç»“åˆäº†ä½ç§©ç»“æ„ä»¥å‡å°‘è®¡ç®—å¤æ‚åº¦ã€‚

**å…³é”®åˆ›æ–°**ï¼šMMoLREçš„ä¸»è¦åˆ›æ–°åœ¨äºé€šè¿‡ä½ç§©ä¸“å®¶ç½‘ç»œè®¾è®¡ï¼Œé™ä½äº†éšç€ä¸“å®¶æ•°é‡å¢åŠ è€Œå¸¦æ¥çš„å‚æ•°å’Œè®¡ç®—å¼€é”€ã€‚è¿™ä¸€è®¾è®¡ä¸ä¼ ç»Ÿçš„ç¡¬å‚æ•°å…±äº«æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†ä»»åŠ¡é—´çš„å¤æ‚å…³ç³»ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ä½ç§©ç»“æ„æ¥æ„å»ºä¸“å®¶ç½‘ç»œï¼Œè®¾ç½®äº†é€‚å½“çš„æŸå¤±å‡½æ•°ä»¥å¹³è¡¡å…±äº«ä¸ç‰¹å®šä»»åŠ¡çš„å­¦ä¹ ã€‚æ­¤å¤–ï¼Œä¸“å®¶çš„æ•°é‡å’Œç»“æ„ç»è¿‡ç²¾å¿ƒé€‰æ‹©ï¼Œä»¥ç¡®ä¿æ¨¡å‹çš„é«˜æ•ˆæ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨CMU-MOSIå’ŒCMU-MOSEIåŸºå‡†æµ‹è¯•ä¸­ï¼ŒMMoLREåœ¨æƒ…æ„Ÿåˆ†æä»»åŠ¡ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå…·ä½“è¡¨ç°ä¸ºç›¸è¾ƒäºåŸºçº¿æ–¹æ³•æå‡äº†çº¦5%çš„å‡†ç¡®ç‡ã€‚åŒæ—¶ï¼Œåœ¨æƒ…ç»ªè¯†åˆ«ä»»åŠ¡ä¸Šï¼ŒMMoLREä¹Ÿå±•ç°å‡ºç«äº‰åŠ›çš„ç»“æœï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾äº¤åª’ä½“åˆ†æã€å®¢æˆ·åé¦ˆå¤„ç†å’Œæƒ…æ„Ÿè®¡ç®—ç­‰ã€‚é€šè¿‡æé«˜æƒ…æ„Ÿåˆ†æå’Œæƒ…ç»ªè¯†åˆ«çš„å‡†ç¡®æ€§ï¼ŒMMoLREèƒ½å¤Ÿä¸ºä¼ä¸šæä¾›æ›´æ·±å…¥çš„ç”¨æˆ·æ´å¯Ÿï¼Œå¸®åŠ©ä¼˜åŒ–äº§å“å’ŒæœåŠ¡ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•è¿˜å¯æ‰©å±•åˆ°å…¶ä»–å¤šæ¨¡æ€å­¦ä¹ ä»»åŠ¡ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multi-task learning (MTL) enables the efficient transfer of extra knowledge acquired from other tasks. The high correlation between multimodal sentiment analysis (MSA) and multimodal emotion recognition (MER) supports their joint training. However, existing methods primarily employ hard parameter sharing, ignoring parameter conflicts caused by complex task correlations. In this paper, we present a novel MTL method for MSA and MER, termed Multimodal Mixture of Low-Rank Experts (MMoLRE). MMoLRE utilizes shared and task-specific experts to distinctly model common and unique task characteristics, thereby avoiding parameter conflicts. Additionally, inspired by low-rank structures in the Mixture of Experts (MoE) framework, we design low-rank expert networks to reduce parameter and computational overhead as the number of experts increases. Extensive experiments on the CMU-MOSI and CMU-MOSEI benchmarks demonstrate that MMoLRE achieves state-of-the-art performance on the MSA task and competitive results on the MER task.

