---
layout: default
title: "DSMentor: Enhancing Data Science Agents with Curriculum Learning and Online Knowledge Accumulation"
---

# DSMentor: Enhancing Data Science Agents with Curriculum Learning and Online Knowledge Accumulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14163" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.14163v1</a>
  <a href="https://arxiv.org/pdf/2505.14163.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14163v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14163v1', 'DSMentor: Enhancing Data Science Agents with Curriculum Learning and Online Knowledge Accumulation')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: He Wang, Alexander Hanbo Li, Yiqun Hu, Sheng Zhang, Hideo Kobayashi, Jiani Zhang, Henry Zhu, Chung-Wei Hang, Patrick Ng

**ÂàÜÁ±ª**: cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-20

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫DSMentor‰ª•‰ºòÂåñÊï∞ÊçÆÁßëÂ≠¶‰ª£ÁêÜÁöÑÊé®ÁêÜËøáÁ®ã**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËØæÁ®ãÂ≠¶‰π†` `ÈïøÊúüËÆ∞ÂøÜ` `Êé®ÁêÜ‰ºòÂåñ` `Êï∞ÊçÆÁßëÂ≠¶‰ª£ÁêÜ` `Âõ†ÊûúÊé®ÁêÜ` `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `Êô∫ËÉΩÂ≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®Êé®ÁêÜËøáÁ®ã‰∏≠Êú™ÂÖÖÂàÜËÄÉËôë‰ªªÂä°Â§ÑÁêÜÈ°∫Â∫èÔºåÂØºËá¥Êï∞ÊçÆÁßëÂ≠¶‰ª£ÁêÜÁöÑÊÄßËÉΩÊú™ËÉΩËææÂà∞ÊúÄ‰Ω≥„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫DSMentorÊ°ÜÊû∂ÔºåÈÄöËøáËØæÁ®ãÂ≠¶‰π†Á≠ñÁï•‰ºòÂåñ‰ªªÂä°Â§ÑÁêÜÈ°∫Â∫èÔºåÂπ∂ÂºïÂÖ•ÈïøÊúüËÆ∞ÂøÜÊù•ÊèêÂçáÂ≠¶‰π†ÊïàÊûú„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåDSMentorÂú®DSEvalÂíåQRDataÂü∫ÂáÜ‰∏äÊèêÈ´ò‰∫ÜÊúÄÂ§ö5.2%ÁöÑÈÄöËøáÁéáÔºåÂπ∂Âú®Âõ†ÊûúÊé®ÁêÜÈóÆÈ¢ò‰∏äÊèêÂçá‰∫Ü8.8%„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâ‰ª£ÁêÜÂú®ÁîüÊàê‰ª£Á†Å‰ª•Ëß£ÂÜ≥Â§çÊùÇÊï∞ÊçÆÁßëÂ≠¶ÈóÆÈ¢òÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÁ†îÁ©∂‰∏ªË¶ÅÈõÜ‰∏≠Âú®ÈÄöËøáÊîπËøõÊêúÁ¥¢„ÄÅÈááÊ†∑ÂíåËßÑÂàíÊäÄÊúØÊù•Â¢ûÂº∫‰∏ä‰∏ãÊñáÂ≠¶‰π†ÔºåÂøΩËßÜ‰∫ÜÊé®ÁêÜËøáÁ®ã‰∏≠ÈóÆÈ¢òÂ§ÑÁêÜÈ°∫Â∫èÁöÑÈáçË¶ÅÊÄß„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÊé®ÁêÜÊó∂Èó¥‰ºòÂåñÊ°ÜÊû∂DSMentorÔºåÂà©Áî®ËØæÁ®ãÂ≠¶‰π†Á≠ñÁï•ÔºåÂÖàÂ§ÑÁêÜÁÆÄÂçï‰ªªÂä°ÔºåÂÜçÈÄêÊ≠•ËøáÊ∏°Âà∞Êõ¥Â§çÊùÇÁöÑ‰ªªÂä°Ôºå‰ªéËÄåÊèêÂçáLLM‰ª£ÁêÜÂú®Êï∞ÊçÆÁßëÂ≠¶‰ªªÂä°‰∏≠ÁöÑË°®Áé∞„ÄÇËØ•Ê°ÜÊû∂ÈÄöËøáÁªÑÁªá‰ªªÂä°ÁöÑÈöæÂ∫¶È°∫Â∫èÂíåÂºïÂÖ•ÈïøÊúüËÆ∞ÂøÜÊù•ÊåáÂØºÂ≠¶‰π†ËøõÁ®ãÔºåÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåDSMentorÂú®DSEvalÂíåQRDataÂü∫ÂáÜ‰∏äÁõ∏ÊØîÂü∫Á∫ø‰ª£ÁêÜÊèêÈ´ò‰∫ÜÈÄöËøáÁéáÔºåÂ∞§ÂÖ∂Âú®Âõ†ÊûúÊé®ÁêÜÈóÆÈ¢ò‰∏äË°®Áé∞Êõ¥‰∏∫Á™ÅÂá∫„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâLLM‰ª£ÁêÜÂú®Êé®ÁêÜËøáÁ®ã‰∏≠Êú™ËÄÉËôë‰ªªÂä°È°∫Â∫èÁöÑÈóÆÈ¢òÔºåÂØºËá¥ÂÖ∂Âú®Â§çÊùÇÊï∞ÊçÆÁßëÂ≠¶‰ªªÂä°‰∏≠ÁöÑË°®Áé∞‰∏ç‰Ω≥„ÄÇÁé∞ÊúâÊñπÊ≥ïÂæÄÂæÄÂøΩËßÜ‰∫ÜÂ≠¶‰π†ËÄÖÂú®Â§ÑÁêÜÈóÆÈ¢òÊó∂ÁöÑËÆ§Áü•Ë¥üÊãÖÔºåÊú™ËÉΩÊúâÊïàÂà©Áî®ÂÖàÂâçÁöÑÁªèÈ™å„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöDSMentorÊ°ÜÊû∂ÁöÑÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÈááÁî®ËØæÁ®ãÂ≠¶‰π†Á≠ñÁï•ÔºåÂÖàÂºïÂÖ•ÁÆÄÂçï‰ªªÂä°ÔºåÈöèÁùÄÂ≠¶‰π†ËÄÖËÉΩÂäõÁöÑÊèêÂçáÈÄêÊ≠•ËøáÊ∏°Âà∞Êõ¥Â§çÊùÇÁöÑ‰ªªÂä°„ÄÇËøôÁßçÊñπÊ≥ïÊ®°‰ªø‰∫Ü‰∫∫Á±ªÂ≠¶‰π†ËøáÁ®ãÔºåÂº∫Ë∞É‰∫ÜÁü•ËØÜÁöÑÁßØÁ¥ØÂíåÂà©Áî®„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöDSMentorÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰ªªÂä°ÈöæÂ∫¶ÊéíÂ∫èÊ®°ÂùóÂíåÈïøÊúüËÆ∞ÂøÜÊ®°Âùó„ÄÇ‰ªªÂä°ÈöæÂ∫¶ÊéíÂ∫èÊ®°ÂùóË¥üË¥£ÁªÑÁªáÊï∞ÊçÆÁßëÂ≠¶‰ªªÂä°ÁöÑÈ°∫Â∫èÔºåËÄåÈïøÊúüËÆ∞ÂøÜÊ®°ÂùóÂàôÁî®‰∫éÂ≠òÂÇ®ÂíåÊ£ÄÁ¥¢ÂÖàÂâçÁöÑÂ≠¶‰π†ÁªèÈ™åÔºå‰ª•ÊåáÂØºÂêéÁª≠ÁöÑÂ≠¶‰π†ËøáÁ®ã„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöDSMentorÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÂ∞ÜËØæÁ®ãÂ≠¶‰π†‰∏éÈïøÊúüËÆ∞ÂøÜÁªìÂêàÔºåÂΩ¢Êàê‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÊé®ÁêÜ‰ºòÂåñÁ≠ñÁï•„ÄÇËøôÁßçÊñπÊ≥ï‰∏é‰º†ÁªüÁöÑÂçï‰∏Ä‰ªªÂä°Â§ÑÁêÜÊñπÂºèÊúâÊú¨Ë¥®Âå∫Âà´ÔºåËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞ÊèêÂçá‰ª£ÁêÜÁöÑÂ≠¶‰π†ÊïàÁéáÂíåÊé®ÁêÜËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°‰∏≠ÔºåDSMentorÈááÁî®‰∫ÜÂä®ÊÄÅ‰ªªÂä°ÊéíÂ∫èÁÆóÊ≥ïÔºåÂπ∂ÁªìÂêà‰∫ÜËÆ∞ÂøÜÂ¢ûÂº∫Êú∫Âà∂Ôºå‰ª•Á°Æ‰øù‰ª£ÁêÜËÉΩÂ§üÂú®Â§ÑÁêÜÊñ∞‰ªªÂä°Êó∂ÊúâÊïàÂà©Áî®ÂéÜÂè≤ÁªèÈ™å„ÄÇÊ≠§Â§ñÔºåÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°‰πüËÄÉËôë‰∫Ü‰ªªÂä°ÈöæÂ∫¶ÁöÑÂèòÂåñÔºå‰ª•ÈÄÇÂ∫î‰∏çÂêåÈò∂ÊÆµÁöÑÂ≠¶‰π†ÈúÄÊ±Ç„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåDSMentorÂú®DSEvalÂíåQRDataÂü∫ÂáÜ‰∏äÁõ∏ÊØîÂü∫Á∫ø‰ª£ÁêÜÊèêÈ´ò‰∫ÜÊúÄÂ§ö5.2%ÁöÑÈÄöËøáÁéá„ÄÇÊ≠§Â§ñÔºåÂú®Âõ†ÊûúÊé®ÁêÜÈóÆÈ¢ò‰∏äÔºåDSMentorÁöÑË°®Áé∞Êõ¥‰∏∫Á™ÅÂá∫ÔºåÁõ∏ÊØî‰∫é‰ΩøÁî®Program-of-ThoughtsÊèêÁ§∫ÁöÑGPT-4ÔºåÊèêÂçá‰∫Ü8.8%ÁöÑÈÄöËøáÁéáÔºåÊòæÁ§∫Âá∫Êõ¥Âº∫ÁöÑÂõ†ÊûúÊé®ÁêÜËÉΩÂäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨ÊïôËÇ≤ÊäÄÊúØ„ÄÅÊô∫ËÉΩËæÖÂØºÁ≥ªÁªüÂíåÊï∞ÊçÆÁßëÂ≠¶Â∑•ÂÖ∑Á≠â„ÄÇÈÄöËøá‰ºòÂåñÊï∞ÊçÆÁßëÂ≠¶‰ª£ÁêÜÁöÑÂ≠¶‰π†ËøáÁ®ãÔºåDSMentorËÉΩÂ§üÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠Êèê‰æõÊõ¥È´òÊïàÁöÑÂ≠¶‰π†ÊîØÊåÅÔºåÂ∏ÆÂä©Áî®Êà∑Êõ¥Â•ΩÂú∞Ëß£ÂÜ≥Â§çÊùÇÈóÆÈ¢òÔºåÊèêÂçáÂ∑•‰ΩúÊïàÁéá„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïÂèØËÉΩ‰∏∫ÂÖ∂‰ªñÈ¢ÜÂüüÁöÑÊô∫ËÉΩ‰ª£ÁêÜÊèê‰æõÊñ∞ÁöÑÊÄùË∑ØÔºåÊé®Âä®‰∫∫Â∑•Êô∫ËÉΩÂú®Â≠¶‰π†ÂíåÊé®ÁêÜÊñπÈù¢ÁöÑËøõ‰∏ÄÊ≠•ÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Large language model (LLM) agents have shown promising performance in generating code for solving complex data science problems. Recent studies primarily focus on enhancing in-context learning through improved search, sampling, and planning techniques, while overlooking the importance of the order in which problems are tackled during inference. In this work, we develop a novel inference-time optimization framework, referred to as DSMentor, which leverages curriculum learning -- a strategy that introduces simpler task first and progressively moves to more complex ones as the learner improves -- to enhance LLM agent performance in challenging data science tasks. Our mentor-guided framework organizes data science tasks in order of increasing difficulty and incorporates a growing long-term memory to retain prior experiences, guiding the agent's learning progression and enabling more effective utilization of accumulated knowledge. We evaluate DSMentor through extensive experiments on DSEval and QRData benchmarks. Experiments show that DSMentor using Claude-3.5-Sonnet improves the pass rate by up to 5.2% on DSEval and QRData compared to baseline agents. Furthermore, DSMentor demonstrates stronger causal reasoning ability, improving the pass rate by 8.8% on the causality problems compared to GPT-4 using Program-of-Thoughts prompts. Our work underscores the importance of developing effective strategies for accumulating and utilizing knowledge during inference, mirroring the human learning process and opening new avenues for improving LLM performance through curriculum-based inference optimization.

