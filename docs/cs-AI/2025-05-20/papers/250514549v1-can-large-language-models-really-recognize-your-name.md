---
layout: default
title: Can Large Language Models Really Recognize Your Name?
---

# Can Large Language Models Really Recognize Your Name?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14549" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14549v1</a>
  <a href="https://arxiv.org/pdf/2505.14549.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14549v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14549v1', 'Can Large Language Models Really Recognize Your Name?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Dzung Pham, Peter Kairouz, Niloofar Mireshghallah, Eugene Bagdasarian, Chau Minh Pham, Amir Houmansadr

**åˆ†ç±»**: cs.CR, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAMBENCHåŸºå‡†ä»¥è§£å†³LLMéšç§è¯†åˆ«é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ä¸ªäººèº«ä»½ä¿¡æ¯` `éšç§ä¿æŠ¤` `æ¨¡ç³Šäººå` `åŸºå‡†æ•°æ®é›†` `å¬å›ç‡` `è‡ªç„¶è¯­è¨€å¤„ç†` `æ•°æ®å®‰å…¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMéšç§è§£å†³æ–¹æ¡ˆå‡è®¾æ¨¡å‹èƒ½å¯é è¯†åˆ«ä¸ªäººèº«ä»½ä¿¡æ¯ï¼Œä½†å®é™…è¡¨ç°ä¸ä½³ã€‚
2. è®ºæ–‡æå‡ºAMBENCHåŸºå‡†æ•°æ®é›†ï¼Œä¸“æ³¨äºæ¨¡ç³Šäººåçš„æ£€æµ‹ï¼Œæ­ç¤ºLLMçš„è¯†åˆ«å±€é™æ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼Œæ¨¡ç³Šäººåçš„å¬å›ç‡æ¯”æ˜“è¯†åˆ«çš„äººåä½20-40%ï¼Œå¹¶ä¸”åœ¨éšç§ä¿æŠ¤æ‘˜è¦ä¸­è¢«å¿½è§†çš„æ¦‚ç‡æ›´é«˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¶Šæ¥è¶Šå¤šåœ°è¢«ç”¨äºä¿æŠ¤ç”¨æˆ·çš„æ•æ„Ÿæ•°æ®ã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŸºäºLLMçš„éšç§è§£å†³æ–¹æ¡ˆå‡è®¾è¿™äº›æ¨¡å‹èƒ½å¤Ÿå¯é åœ°æ£€æµ‹ä¸ªäººèº«ä»½ä¿¡æ¯ï¼ˆPIIï¼‰ï¼Œå°¤å…¶æ˜¯å‘½åå®ä½“ã€‚æœ¬æ–‡æŒ‘æˆ˜äº†è¿™ä¸€å‡è®¾ï¼Œæ­ç¤ºäº†LLMåœ¨éšç§ä»»åŠ¡ä¸­çš„ç³»ç»Ÿæ€§å¤±è´¥ã€‚æˆ‘ä»¬å‘ç°ç°ä»£LLMåœ¨çŸ­æ–‡æœ¬ç‰‡æ®µä¸­ç»å¸¸å¿½è§†äººåï¼Œå°¤å…¶æ˜¯åœ¨æ¨¡ç³Šä¸Šä¸‹æ–‡ä¸­ï¼Œå¯¼è‡´äººåè¢«è¯¯è§£æˆ–å¤„ç†ä¸å½“ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†AMBENCHï¼Œä¸€ä¸ªåŒ…å«æ¨¡ç³Šäººåçš„åŸºå‡†æ•°æ®é›†ï¼Œåˆ©ç”¨äº†äººåè§„å¾‹åå·®ç°è±¡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ¨¡ç³Šäººåçš„å¬å›ç‡æ¯”æ›´æ˜“è¯†åˆ«çš„äººåä½20-40%ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†å•é LLMæ¥ä¿æŠ¤ç”¨æˆ·éšç§çš„é£é™©ï¼Œå¹¶å‘¼åå¯¹å…¶éšç§å¤±è´¥æ¨¡å¼è¿›è¡Œæ›´ç³»ç»Ÿçš„ç ”ç©¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è¯†åˆ«ä¸ªäººèº«ä»½ä¿¡æ¯æ—¶çš„ç³»ç»Ÿæ€§å¤±è´¥ï¼Œå°¤å…¶æ˜¯å¯¹æ¨¡ç³Šäººåçš„è¯†åˆ«ä¸è¶³ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†è€ƒè™‘ä¸Šä¸‹æ–‡çš„æ¨¡ç³Šæ€§ï¼Œå¯¼è‡´è¯†åˆ«ç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºAMBENCHåŸºå‡†æ•°æ®é›†ï¼Œä¸“æ³¨äºæ¨¡ç³Šäººåçš„æ£€æµ‹ï¼Œåˆ©ç”¨äººåè§„å¾‹åå·®ç°è±¡ï¼Œå¸®åŠ©LLMæ›´å¥½åœ°è¯†åˆ«è¿™äº›ä¿¡æ¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚æ•°æ®é›†åŒ…å«å¤šç§æ¨¡ç³Šäººåï¼Œæ¨¡å‹åˆ™é€šè¿‡è¿™äº›æ•°æ®è¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºAMBENCHæ•°æ®é›†çš„æ„å»ºï¼Œå®ƒä¸“é—¨è®¾è®¡ç”¨äºè¯„ä¼°LLMåœ¨å¤„ç†æ¨¡ç³Šäººåæ—¶çš„æ€§èƒ½ï¼Œä¸ç°æœ‰çš„æ ‡å‡†æ•°æ®é›†ç›¸æ¯”ï¼Œæä¾›äº†æ›´å…·æŒ‘æˆ˜æ€§çš„æµ‹è¯•ç¯å¢ƒã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œä½¿ç”¨äº†å¤šç§LLMå’Œä¸“é—¨çš„å·¥å…·è¿›è¡Œæ¯”è¾ƒï¼Œè®¾ç½®äº†ä¸åŒçš„å‚æ•°ä»¥ä¼˜åŒ–æ¨¡å‹çš„å¬å›ç‡ï¼Œç‰¹åˆ«å…³æ³¨æ¨¡ç³Šäººåçš„ä¸Šä¸‹æ–‡å¤„ç†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ¨¡ç³Šäººåçš„å¬å›ç‡æ˜¾è‘—ä½äºæ˜“è¯†åˆ«çš„äººåã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ¨¡ç³Šäººåçš„å¬å›ç‡æ¯”æ›´æ˜“è¯†åˆ«çš„äººåä½20-40%ã€‚æ­¤å¤–ï¼Œåœ¨ç”Ÿæˆçš„éšç§ä¿æŠ¤æ‘˜è¦ä¸­ï¼Œæ¨¡ç³Šäººåè¢«å¿½è§†çš„æ¦‚ç‡æ˜¯å…¶ä»–äººåçš„å››å€ã€‚è¿™äº›æ•°æ®çªæ˜¾äº†LLMåœ¨éšç§ä¿æŠ¤ä»»åŠ¡ä¸­çš„å±€é™æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç”¨æˆ·éšç§ä¿æŠ¤ã€æ•°æ®å®‰å…¨å’Œè‡ªç„¶è¯­è¨€å¤„ç†ç­‰ã€‚é€šè¿‡æ”¹è¿›LLMå¯¹æ¨¡ç³Šäººåçš„è¯†åˆ«èƒ½åŠ›ï¼Œå¯ä»¥å¢å¼ºç”¨æˆ·æ•°æ®çš„å®‰å…¨æ€§ï¼Œé™ä½éšç§æ³„éœ²çš„é£é™©ã€‚æœªæ¥ï¼ŒAMBENCHåŸºå‡†å¯èƒ½æˆä¸ºè¯„ä¼°LLMéšç§ä¿æŠ¤èƒ½åŠ›çš„é‡è¦å·¥å…·ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) are increasingly being used to protect sensitive user data. However, current LLM-based privacy solutions assume that these models can reliably detect personally identifiable information (PII), particularly named entities. In this paper, we challenge that assumption by revealing systematic failures in LLM-based privacy tasks. Specifically, we show that modern LLMs regularly overlook human names even in short text snippets due to ambiguous contexts, which cause the names to be misinterpreted or mishandled. We propose AMBENCH, a benchmark dataset of seemingly ambiguous human names, leveraging the name regularity bias phenomenon, embedded within concise text snippets along with benign prompt injections. Our experiments on modern LLMs tasked to detect PII as well as specialized tools show that recall of ambiguous names drops by 20--40% compared to more recognizable names. Furthermore, ambiguous human names are four times more likely to be ignored in supposedly privacy-preserving summaries generated by LLMs when benign prompt injections are present. These findings highlight the underexplored risks of relying solely on LLMs to safeguard user privacy and underscore the need for a more systematic investigation into their privacy failure modes.

