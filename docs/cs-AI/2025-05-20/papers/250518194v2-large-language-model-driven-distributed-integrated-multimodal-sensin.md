---
layout: default
title: Large Language Model-Driven Distributed Integrated Multimodal Sensing and Semantic Communications
---

# Large Language Model-Driven Distributed Integrated Multimodal Sensing and Semantic Communications

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.18194" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.18194v2</a>
  <a href="https://arxiv.org/pdf/2505.18194.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.18194v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.18194v2', 'Large Language Model-Driven Distributed Integrated Multimodal Sensing and Semantic Communications')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Yubo Peng, Luping Xiang, Bingxin Zhang, Kun Yang

**ÂàÜÁ±ª**: eess.SP, cs.AI, cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-20 (Êõ¥Êñ∞: 2025-05-30)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫LLM-DiSACÊ°ÜÊû∂‰ª•Ëß£ÂÜ≥ÂçïÊ®°ÊÄÅÊÑüÁü•Á≥ªÁªüÁöÑÂ±ÄÈôêÊÄß**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅÊÑüÁü•` `ËØ≠‰πâÈÄö‰ø°` `Â§ßËØ≠Ë®ÄÊ®°Âûã` `Â∞ÑÈ¢ë-ËßÜËßâËûçÂêà` `ÂàÜÂ∏ÉÂºèÂ≠¶‰π†` `Êô∫ËÉΩÂüéÂ∏Ç` `Êó†‰∫∫È©æÈ©∂`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÂçïÊ®°ÊÄÅÊÑüÁü•Á≥ªÁªüÂú®Â§çÊùÇÁéØÂ¢É‰∏≠Ë°®Áé∞‰∏ç‰Ω≥ÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂüéÂ∏ÇÂíåÈùûËßÜË∑ùÂú∫ÊôØ‰∏≠ÔºåËßÜËßíÂíåÁ©∫Èó¥Ë¶ÜÁõñÁöÑÈôêÂà∂ÊòæËëóÈôç‰Ωé‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇ
2. Êú¨ÊñáÊèêÂá∫ÁöÑLLM-DiSACÊ°ÜÊû∂ÈÄöËøáÂ§ö‰∏™Âçè‰ΩúËÆæÂ§áÁªìÂêàRFÂíåËßÜËßâÊï∞ÊçÆÔºåÂà©Áî®Â§ßËØ≠Ë®ÄÊ®°ÂûãÊèêÂçáÊÑüÁü•Á≤æÂ∫¶ÂíåÈÄö‰ø°ÊïàÁéá„ÄÇ
3. Âú®ÂêàÊàêÁöÑÂ§öËßÜËßíRF-ËßÜËßâÊï∞ÊçÆÈõÜ‰∏äÔºåLLM-DiSACÂ±ïÁ§∫‰∫Ü‰ºòÂºÇÁöÑÊÄßËÉΩÔºåÊòæËëóÊèêÈ´ò‰∫ÜÊÑüÁü•ÂáÜÁ°ÆÊÄßÂíåËØ≠‰πâ‰º†ËæìÊïàÁéá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

‰º†ÁªüÁöÑÂçïÊ®°ÊÄÅÊÑüÁü•Á≥ªÁªüÂú®Â§çÊùÇÂä®ÊÄÅÁéØÂ¢É‰∏≠Èù¢‰∏¥ÊåëÊàòÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂüéÂ∏ÇÊàñÈùûËßÜË∑ùÂú∫ÊôØ‰∏≠ÔºåÂèóÈôê‰∫éËßÜËßíÂíåÁ©∫Èó¥Ë¶ÜÁõñ‰∏çË∂≥„ÄÇ‰∏∫Ê≠§ÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÂü∫‰∫éÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÂàÜÂ∏ÉÂºèÈõÜÊàêÂ§öÊ®°ÊÄÅÊÑüÁü•‰∏éËØ≠‰πâÈÄö‰ø°Ê°ÜÊû∂ÔºàLLM-DiSACÔºâ„ÄÇËØ•Á≥ªÁªüÁî±Â§ö‰∏™Âçè‰ΩúÊÑüÁü•ËÆæÂ§áÁªÑÊàêÔºåÁªìÂêàÂ∞ÑÈ¢ëÔºàRFÔºâÂíåËßÜËßâÊï∞ÊçÆÔºåÈÄöËøáËÅöÂêà‰∏≠ÂøÉÊèêÂçáÊÑüÁü•Á≤æÂ∫¶„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåLLM-DiSACÂºÄÂèë‰∫ÜÂ∞ÑÈ¢ë-ËßÜËßâËûçÂêàÁΩëÁªúÔºàRVFNÔºâÂíåÂü∫‰∫éLLMÁöÑËØ≠‰πâ‰º†ËæìÁΩëÁªúÔºàLSTNÔºâÔºåÂπ∂Âú®ËÅöÂêà‰∏≠ÂøÉ‰ΩøÁî®ÂèòÊç¢Âô®ËÅöÂêàÊ®°ÂûãÔºàTRAMÔºâËøõË°åÁâπÂæÅËûçÂêà„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåLLM-DiSACÂú®ÂêàÊàêÁöÑÂ§öËßÜËßíRF-ËßÜËßâÊï∞ÊçÆÈõÜ‰∏äË°®Áé∞ËâØÂ•Ω„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥‰º†ÁªüÂçïÊ®°ÊÄÅÊÑüÁü•Á≥ªÁªüÂú®Â§çÊùÇÂä®ÊÄÅÁéØÂ¢É‰∏≠ÁöÑÂ±ÄÈôêÊÄßÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂüéÂ∏ÇÂíåÈùûËßÜË∑ùÂú∫ÊôØ‰∏≠ÁöÑËßÜËßíÂíåÁ©∫Èó¥Ë¶ÜÁõñ‰∏çË∂≥ÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöLLM-DiSACÊ°ÜÊû∂ÈÄöËøáÁªìÂêàÂ§ö‰∏™Âçè‰ΩúÊÑüÁü•ËÆæÂ§áÁöÑRFÂíåËßÜËßâÊï∞ÊçÆÔºåÂà©Áî®Â§ßËØ≠Ë®ÄÊ®°ÂûãËøõË°åËØ≠‰πâÈÄö‰ø°Ôºå‰ªéËÄåÊèêÂçáÊÑüÁü•Á≤æÂ∫¶ÂíåÈÄö‰ø°ÊïàÁéá„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•Ê°ÜÊû∂ÂåÖÊã¨Â§ö‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÂ∞ÑÈ¢ë-ËßÜËßâËûçÂêàÁΩëÁªúÔºàRVFNÔºâÁî®‰∫éÂ§öÊ®°ÊÄÅÊï∞ÊçÆÈõÜÊàêÔºåÂü∫‰∫éLLMÁöÑËØ≠‰πâ‰º†ËæìÁΩëÁªúÔºàLSTNÔºâÁî®‰∫éÊèêÈ´òÈÄö‰ø°ÊïàÁéáÔºå‰ª•ÂèäÂèòÊç¢Âô®ËÅöÂêàÊ®°ÂûãÔºàTRAMÔºâÁî®‰∫éÁâπÂæÅËûçÂêà„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞Âú®‰∫éÂºïÂÖ•‰∫ÜÂü∫‰∫éÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑËØ≠‰πâ‰º†ËæìÁΩëÁªúÔºåËÉΩÂ§üÊúâÊïàÂà©Áî®Â∑≤Áü•‰ø°ÈÅìÂèÇÊï∞Êù•ÂáèËΩªËØ≠‰πâÂ§±ÁúüÔºå‰∏é‰º†ÁªüÊñπÊ≥ïÁõ∏ÊØîÔºåÊèêÂçá‰∫ÜÈÄö‰ø°ÁöÑÂáÜÁ°ÆÊÄßÂíåÊïàÁéá„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®RVFN‰∏≠ÔºåÈááÁî®‰∫Ü‰∏ìÈó®ÁöÑÁâπÂæÅÊèêÂèñÂô®Âíå‰∫§ÂèâÊ≥®ÊÑèÂäõÊ®°ÂùóÔºõLSTN‰∏≠ÁöÑËß£Á†ÅÂô®Âà©Áî®‰ø°ÈÅìË∑ùÁ¶ªÂíå‰ø°Âô™ÊØîÁ≠âÂèÇÊï∞ÔºõTRAMÂàô‰ΩøÁî®Ëá™ÈÄÇÂ∫îËÅöÂêàÊ≥®ÊÑèÂäõÊú∫Âà∂Êù•ËûçÂêàÂàÜÂ∏ÉÂºèÁâπÂæÅ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®ÂêàÊàêÁöÑÂ§öËßÜËßíRF-ËßÜËßâÊï∞ÊçÆÈõÜ‰∏äÔºåLLM-DiSACÁöÑÊÄßËÉΩË°®Áé∞‰ºòÂºÇÔºåÁõ∏ËæÉ‰∫éÂü∫Á∫øÊñπÊ≥ïÔºåÊÑüÁü•ÂáÜÁ°ÆÊÄßÂíåËØ≠‰πâ‰º†ËæìÊïàÁéáÂùáÊúâÊòæËëóÊèêÂçáÔºåÂÖ∑‰ΩìÊï∞ÊçÆÂ∞öÊú™Êä´Èú≤„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Êô∫ËÉΩÂüéÂ∏Ç„ÄÅÊó†‰∫∫È©æÈ©∂„ÄÅÂÆâÈò≤ÁõëÊéßÁ≠âÂú∫ÊôØÔºåËÉΩÂ§üÂú®Â§çÊùÇÁéØÂ¢É‰∏≠Êèê‰æõÊõ¥È´òÊïàÁöÑÊÑüÁü•ÂíåÈÄö‰ø°Ëß£ÂÜ≥ÊñπÊ°à„ÄÇÊú™Êù•ÔºåÈöèÁùÄÂ§öÊ®°ÊÄÅÊäÄÊúØÁöÑÂèëÂ±ïÔºåLLM-DiSACÊ°ÜÊû∂ÊúâÊúõÂú®Êõ¥Â§öÂÆûÈôÖÂ∫îÁî®‰∏≠ÂèëÊå•ÈáçË¶Å‰ΩúÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Traditional single-modal sensing systems-based solely on either radio frequency (RF) or visual data-struggle to cope with the demands of complex and dynamic environments. Furthermore, single-device systems are constrained by limited perspectives and insufficient spatial coverage, which impairs their effectiveness in urban or non-line-of-sight scenarios. To overcome these challenges, we propose a novel large language model (LLM)-driven distributed integrated multimodal sensing and semantic communication (LLM-DiSAC) framework. Specifically, our system consists of multiple collaborative sensing devices equipped with RF and camera modules, working together with an aggregation center to enhance sensing accuracy. First, on sensing devices, LLM-DiSAC develops an RF-vision fusion network (RVFN), which employs specialized feature extractors for RF and visual data, followed by a cross-attention module for effective multimodal integration. Second, a LLM-based semantic transmission network (LSTN) is proposed to enhance communication efficiency, where the LLM-based decoder leverages known channel parameters, such as transceiver distance and signal-to-noise ratio (SNR), to mitigate semantic distortion. Third, at the aggregation center, a transformer-based aggregation model (TRAM) with an adaptive aggregation attention mechanism is developed to fuse distributed features and enhance sensing accuracy. To preserve data privacy, a two-stage distributed learning strategy is introduced, allowing local model training at the device level and centralized aggregation model training using intermediate features. Finally, evaluations on a synthetic multi-view RF-visual dataset generated by the Genesis simulation engine show that LLM-DiSAC achieves a good performance.

