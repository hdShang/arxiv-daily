---
layout: default
title: SATBench: Benchmarking LLMs' Logical Reasoning via Automated Puzzle Generation from SAT Formulas
---

# SATBench: Benchmarking LLMs' Logical Reasoning via Automated Puzzle Generation from SAT Formulas

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14615" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14615v2</a>
  <a href="https://arxiv.org/pdf/2505.14615.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14615v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14615v2', 'SATBench: Benchmarking LLMs\' Logical Reasoning via Automated Puzzle Generation from SAT Formulas')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Anjiang Wei, Yuheng Wu, Yingjia Wan, Tarun Suresh, Huanmi Tan, Zhanke Zhou, Sanmi Koyejo, Ke Wang, Alex Aiken

**åˆ†ç±»**: cs.AI, cs.CL, cs.LG, cs.LO

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20 (æ›´æ–°: 2025-09-22)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Anjiang-Wei/SATBench)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSATBenchä»¥è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹çš„é€»è¾‘æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é€»è¾‘æ¨ç†` `å¤§å‹è¯­è¨€æ¨¡å‹` `å¸ƒå°”å¯æ»¡è¶³æ€§` `è‡ªåŠ¨ç”Ÿæˆ` `åŸºå‡†æµ‹è¯•` `SATé—®é¢˜` `æ¨¡å‹è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨åŸºäºæ¨ç†è§„åˆ™çš„æ¨ç†ï¼Œéš¾ä»¥æœ‰æ•ˆå¤„ç†æœç´¢å‹é€»è¾‘é—®é¢˜ã€‚
2. è®ºæ–‡æå‡ºSATBenchï¼Œé€šè¿‡è‡ªåŠ¨ç”Ÿæˆé€»è¾‘éš¾é¢˜æ¥è¯„ä¼°LLMsçš„é€»è¾‘æ¨ç†èƒ½åŠ›ï¼Œåˆ©ç”¨SATé—®é¢˜çš„æœç´¢ç‰¹æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæœ€å¼ºæ¨¡å‹åœ¨å›°éš¾é—®é¢˜ä¸Šçš„è¡¨ç°ä»…ä¸º65.0%å‡†ç¡®ç‡ï¼Œæ˜¾ç¤ºå‡ºLLMsåœ¨é€»è¾‘æ¨ç†ä¸­çš„å±€é™æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬ä»‹ç»äº†SATBenchï¼Œè¿™æ˜¯ä¸€ä¸ªé€šè¿‡ä»å¸ƒå°”å¯æ»¡è¶³æ€§ï¼ˆSATï¼‰é—®é¢˜ç”Ÿæˆé€»è¾‘éš¾é¢˜æ¥è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é€»è¾‘æ¨ç†èƒ½åŠ›çš„åŸºå‡†æµ‹è¯•ã€‚ä¸ä»¥å¾€å…³æ³¨åŸºäºæ¨ç†è§„åˆ™çš„æ¨ç†æ–¹æ³•ä¸åŒï¼Œæˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨SATé—®é¢˜çš„æœç´¢ç‰¹æ€§ï¼Œç›®æ ‡æ˜¯æ‰¾åˆ°æ»¡è¶³ç‰¹å®šé€»è¾‘çº¦æŸçš„è§£å†³æ–¹æ¡ˆã€‚SATBenchä¸­çš„æ¯ä¸ªå®ä¾‹å‡ç”±SATå…¬å¼ç”Ÿæˆï¼Œå¹¶é€šè¿‡LLMsè½¬æ¢ä¸ºéš¾é¢˜ã€‚ç”Ÿæˆè¿‡ç¨‹å®Œå…¨è‡ªåŠ¨åŒ–ï¼Œå¹¶å¯é€šè¿‡è°ƒæ•´å­å¥æ•°é‡æ¥æ”¹å˜éš¾åº¦ã€‚æ‰€æœ‰2100ä¸ªéš¾é¢˜é€šè¿‡LLMå’Œæ±‚è§£å™¨çš„éªŒè¯æ£€æŸ¥ï¼Œå¹¶åœ¨éƒ¨åˆ†æ ·æœ¬ä¸Šè¿›è¡Œäº†äººå·¥éªŒè¯ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå³ä½¿æ˜¯æœ€å¼ºçš„æ¨¡å‹o4-miniåœ¨å›°éš¾çš„UNSATé—®é¢˜ä¸Šä¹Ÿä»…è¾¾åˆ°65.0%çš„å‡†ç¡®ç‡ï¼Œæ¥è¿‘50%çš„éšæœºåŸºçº¿ã€‚æˆ‘ä»¬çš„é”™è¯¯åˆ†ææ­ç¤ºäº†ç³»ç»Ÿæ€§å¤±è´¥ï¼Œå¦‚å¯æ»¡è¶³æ€§åå·®ã€ä¸Šä¸‹æ–‡ä¸ä¸€è‡´å’Œæ¡ä»¶é—æ¼ï¼Œçªæ˜¾äº†å½“å‰LLMsåœ¨åŸºäºæœç´¢çš„é€»è¾‘æ¨ç†ä¸­çš„å±€é™æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é€»è¾‘æ¨ç†èƒ½åŠ›è¯„ä¼°ä¸­çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯å¯¹æœç´¢å‹é€»è¾‘é—®é¢˜çš„å¤„ç†èƒ½åŠ›ã€‚ç°æœ‰æ–¹æ³•å¤šä¾èµ–äºæ¨ç†è§„åˆ™ï¼Œç¼ºä¹å¯¹SATé—®é¢˜çš„æœ‰æ•ˆè¯„ä¼°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è‡ªåŠ¨ç”Ÿæˆé€»è¾‘éš¾é¢˜æ¥è¯„ä¼°LLMsçš„é€»è¾‘æ¨ç†èƒ½åŠ›ï¼Œåˆ©ç”¨SATé—®é¢˜çš„ç‰¹æ€§ï¼Œå¯»æ‰¾æ»¡è¶³ç‰¹å®šé€»è¾‘çº¦æŸçš„è§£å†³æ–¹æ¡ˆã€‚è¿™ç§æ–¹æ³•ä¸ä»…æé«˜äº†è¯„ä¼°çš„è‡ªåŠ¨åŒ–ç¨‹åº¦ï¼Œè¿˜å…è®¸æ ¹æ®éœ€æ±‚è°ƒæ•´éš¾åº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œä»SATå…¬å¼ç”Ÿæˆé€»è¾‘éš¾é¢˜ï¼›å…¶æ¬¡ï¼Œåˆ©ç”¨LLMså°†ç”Ÿæˆçš„å…¬å¼è½¬åŒ–ä¸ºå¯è§£çš„éš¾é¢˜ï¼›æœ€åï¼Œé€šè¿‡LLMå’Œæ±‚è§£å™¨è¿›è¡Œä¸€è‡´æ€§æ£€æŸ¥ï¼Œç¡®ä¿ç”Ÿæˆéš¾é¢˜çš„æœ‰æ•ˆæ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†SATé—®é¢˜çš„æœç´¢ç‰¹æ€§ä¸LLMsç»“åˆï¼Œå½¢æˆäº†ä¸€ç§æ–°çš„è¯„ä¼°æœºåˆ¶ã€‚è¿™ä¸ä»¥å¾€åŸºäºæ¨ç†è§„åˆ™çš„æ–¹æ³•æœ¬è´¨ä¸Šä¸åŒï¼Œæä¾›äº†æ›´å…¨é¢çš„é€»è¾‘æ¨ç†èƒ½åŠ›è¯„ä¼°ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œå…³é”®å‚æ•°åŒ…æ‹¬å­å¥æ•°é‡çš„è°ƒæ•´ï¼Œä»¥æ§åˆ¶éš¾åº¦ã€‚æ­¤å¤–ï¼ŒéªŒè¯è¿‡ç¨‹ç»“åˆäº†LLMå’Œæ±‚è§£å™¨çš„åŒé‡æ£€æŸ¥ï¼Œç¡®ä¿äº†ç”Ÿæˆéš¾é¢˜çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚å®éªŒä¸­è¿˜è¿›è¡Œäº†äººå·¥éªŒè¯ï¼Œä»¥æé«˜ç»“æœçš„å¯é æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæœ€å¼ºæ¨¡å‹o4-miniåœ¨å›°éš¾çš„UNSATé—®é¢˜ä¸Šä»…è¾¾åˆ°65.0%çš„å‡†ç¡®ç‡ï¼Œæ¥è¿‘50%çš„éšæœºåŸºçº¿ã€‚è¿™ä¸€ç»“æœæ­ç¤ºäº†å½“å‰LLMsåœ¨å¤„ç†å¤æ‚é€»è¾‘æ¨ç†ä»»åŠ¡æ—¶çš„å±€é™æ€§ï¼Œå°¤å…¶æ˜¯åœ¨ç³»ç»Ÿæ€§é”™è¯¯æ–¹é¢ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€æ™ºèƒ½é—®ç­”ç³»ç»Ÿå’Œè‡ªåŠ¨æ¨ç†å·¥å…·ç­‰ã€‚é€šè¿‡è¯„ä¼°å’Œæå‡LLMsçš„é€»è¾‘æ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥ä¿ƒè¿›æ›´æ™ºèƒ½çš„å¯¹è¯ç³»ç»Ÿå’Œå†³ç­–æ”¯æŒå·¥å…·çš„å‘å±•ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We introduce SATBench, a benchmark for evaluating the logical reasoning capabilities of large language models (LLMs) through logical puzzles derived from Boolean satisfiability (SAT) problems. Unlike prior work that focuses on inference rule-based reasoning, which often involves deducing conclusions from a set of premises, our approach leverages the search-based nature of SAT problems, where the objective is to find a solution that fulfills a specified set of logical constraints. Each instance in SATBench is generated from a SAT formula, then translated into a puzzle using LLMs. The generation process is fully automated and allows for adjustable difficulty by varying the number of clauses. All 2100 puzzles are validated through both LLM-based and solver-based consistency checks, with human validation on a subset. Experimental results show that even the strongest model, o4-mini, achieves only 65.0% accuracy on hard UNSAT problems, close to the random baseline of 50%. Our error analysis reveals systematic failures such as satisfiability bias, context inconsistency, and condition omission, highlighting limitations of current LLMs in search-based logical reasoning. Our code and data are publicly available at https://github.com/Anjiang-Wei/SATBench

