---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.AI - 2025-05-20
---

# cs.AIï¼ˆ2025-05-20ï¼‰

ğŸ“Š å…± **44** ç¯‡è®ºæ–‡
 | ğŸ”— **5** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (30 ğŸ”—3)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (10 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (3)</a>
<a href="#æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation" class="interest-badge">æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1 ğŸ”—1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (30 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250518194v2-large-language-model-driven-distributed-integrated-multimodal-sensin.html">Large Language Model-Driven Distributed Integrated Multimodal Sensing and Semantic Communications</a></td>
  <td>æå‡ºLLM-DiSACæ¡†æ¶ä»¥è§£å†³å•æ¨¡æ€æ„ŸçŸ¥ç³»ç»Ÿçš„å±€é™æ€§</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.18194v2" data-paper-url="./papers/250518194v2-large-language-model-driven-distributed-integrated-multimodal-sensin.html" onclick="toggleFavorite(this, '2505.18194v2', 'Large Language Model-Driven Distributed Integrated Multimodal Sensing and Semantic Communications')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250513828v1-multimodal-rag-driven-anomaly-detection-and-classification-in-laser-.html">Multimodal RAG-driven Anomaly Detection and Classification in Laser Powder Bed Fusion using Large Language Models</a></td>
  <td>æå‡ºå¤šæ¨¡æ€RAGé©±åŠ¨æ¡†æ¶ä»¥è§£å†³æ¿€å…‰ç²‰æœ«åºŠç†”èä¸­çš„å¼‚å¸¸æ£€æµ‹é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13828v1" data-paper-url="./papers/250513828v1-multimodal-rag-driven-anomaly-detection-and-classification-in-laser-.html" onclick="toggleFavorite(this, '2505.13828v1', 'Multimodal RAG-driven Anomaly Detection and Classification in Laser Powder Bed Fusion using Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250514603v1-towards-a-foundation-model-for-communication-systems.html">Towards a Foundation Model for Communication Systems</a></td>
  <td>æå‡ºä¸€ç§åŸºç¡€æ¨¡å‹ä»¥è§£å†³é€šä¿¡ç³»ç»Ÿä¸­çš„å¤šæ¨¡æ€æ•°æ®å¤„ç†é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">foundation model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14603v1" data-paper-url="./papers/250514603v1-towards-a-foundation-model-for-communication-systems.html" onclick="toggleFavorite(this, '2505.14603v1', 'Towards a Foundation Model for Communication Systems')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250514627v1-debating-for-better-reasoning-an-unsupervised-multimodal-approach.html">Debating for Better Reasoning: An Unsupervised Multimodal Approach</a></td>
  <td>æå‡ºå¤šæ¨¡æ€è¾©è®ºæ¡†æ¶ä»¥æå‡è§†è§‰é—®ç­”æ€§èƒ½</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14627v1" data-paper-url="./papers/250514627v1-debating-for-better-reasoning-an-unsupervised-multimodal-approach.html" onclick="toggleFavorite(this, '2505.14627v1', 'Debating for Better Reasoning: An Unsupervised Multimodal Approach')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250520308v2-large-language-model-powered-decision-support-for-a-metal-additive-m.html">Large Language Model Powered Decision Support for a Metal Additive Manufacturing Knowledge Graph</a></td>
  <td>æå‡ºé‡‘å±å¢æåˆ¶é€ çŸ¥è¯†å›¾è°±ä¸å¤§è¯­è¨€æ¨¡å‹ç»“åˆçš„å†³ç­–æ”¯æŒç³»ç»Ÿ</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.20308v2" data-paper-url="./papers/250520308v2-large-language-model-powered-decision-support-for-a-metal-additive-m.html" onclick="toggleFavorite(this, '2505.20308v2', 'Large Language Model Powered Decision Support for a Metal Additive Manufacturing Knowledge Graph')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250514667v4-safepath-preventing-harmful-reasoning-in-chain-of-thought-via-early-.html">SAFEPATH: Preventing Harmful Reasoning in Chain-of-Thought via Early Alignment</a></td>
  <td>æå‡ºSAFEPATHä»¥è§£å†³å¤§å‹æ¨ç†æ¨¡å‹çš„å®‰å…¨æ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14667v4" data-paper-url="./papers/250514667v4-safepath-preventing-harmful-reasoning-in-chain-of-thought-via-early-.html" onclick="toggleFavorite(this, '2505.14667v4', 'SAFEPATH: Preventing Harmful Reasoning in Chain-of-Thought via Early Alignment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250514549v1-can-large-language-models-really-recognize-your-name.html">Can Large Language Models Really Recognize Your Name?</a></td>
  <td>æå‡ºAMBENCHåŸºå‡†ä»¥è§£å†³LLMéšç§è¯†åˆ«é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14549v1" data-paper-url="./papers/250514549v1-can-large-language-models-really-recognize-your-name.html" onclick="toggleFavorite(this, '2505.14549v1', 'Can Large Language Models Really Recognize Your Name?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250514524v3-guarded-query-routing-for-large-language-models.html">Guarded Query Routing for Large Language Models</a></td>
  <td>æå‡ºå—ä¿æŠ¤çš„æŸ¥è¯¢è·¯ç”±æ–¹æ³•ä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹çš„æŸ¥è¯¢åˆ†ç±»é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14524v3" data-paper-url="./papers/250514524v3-guarded-query-routing-for-large-language-models.html" onclick="toggleFavorite(this, '2505.14524v3', 'Guarded Query Routing for Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250514235v1-toward-embodied-agi-a-review-of-embodied-ai-and-the-road-ahead.html">Toward Embodied AGI: A Review of Embodied AI and the Road Ahead</a></td>
  <td>æå‡ºç³»ç»Ÿåˆ†ç±»ä»¥æ¨åŠ¨å…·èº«äººå·¥æ™ºèƒ½çš„å‘å±•</td>
  <td class="tags-cell"><span class="paper-tag">embodied AI</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14235v1" data-paper-url="./papers/250514235v1-toward-embodied-agi-a-review-of-embodied-ai-and-the-road-ahead.html" onclick="toggleFavorite(this, '2505.14235v1', 'Toward Embodied AGI: A Review of Embodied AI and the Road Ahead')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250514143v1-multimodal-mixture-of-low-rank-experts-for-sentiment-analysis-and-em.html">Multimodal Mixture of Low-Rank Experts for Sentiment Analysis and Emotion Recognition</a></td>
  <td>æå‡ºå¤šæ¨¡æ€ä½ç§©ä¸“å®¶æ··åˆæ¨¡å‹ä»¥è§£å†³æƒ…æ„Ÿåˆ†æå’Œæƒ…ç»ªè¯†åˆ«é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14143v1" data-paper-url="./papers/250514143v1-multimodal-mixture-of-low-rank-experts-for-sentiment-analysis-and-em.html" onclick="toggleFavorite(this, '2505.14143v1', 'Multimodal Mixture of Low-Rank Experts for Sentiment Analysis and Emotion Recognition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250513971v2-the-multimodal-information-based-speech-processing-misp-2025-challen.html">The Multimodal Information Based Speech Processing (MISP) 2025 Challenge: Audio-Visual Diarization and Recognition</a></td>
  <td>æå‡ºå¤šæ¨¡æ€ä¼šè®®è½¬å½•æ–¹æ³•ä»¥è§£å†³å¤æ‚å£°å­¦æ¡ä»¶ä¸‹çš„æŒ‘æˆ˜</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13971v2" data-paper-url="./papers/250513971v2-the-multimodal-information-based-speech-processing-misp-2025-challen.html" onclick="toggleFavorite(this, '2505.13971v2', 'The Multimodal Information Based Speech Processing (MISP) 2025 Challenge: Audio-Visual Diarization and Recognition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250514569v1-agent-context-protocols-enhance-collective-inference.html">Agent Context Protocols Enhance Collective Inference</a></td>
  <td>æå‡ºAgentä¸Šä¸‹æ–‡åè®®ä»¥å¢å¼ºå¤šæ™ºèƒ½ä½“é›†ä½“æ¨ç†èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">generalist agent</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14569v1" data-paper-url="./papers/250514569v1-agent-context-protocols-enhance-collective-inference.html" onclick="toggleFavorite(this, '2505.14569v1', 'Agent Context Protocols Enhance Collective Inference')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/250513941v1-mlzero-a-multi-agent-system-for-end-to-end-machine-learning-automati.html">MLZero: A Multi-Agent System for End-to-end Machine Learning Automation</a></td>
  <td>æå‡ºMLZeroä»¥å®ç°å¤šæ¨¡æ€æ•°æ®çš„ç«¯åˆ°ç«¯æœºå™¨å­¦ä¹ è‡ªåŠ¨åŒ–</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13941v1" data-paper-url="./papers/250513941v1-mlzero-a-multi-agent-system-for-end-to-end-machine-learning-automati.html" onclick="toggleFavorite(this, '2505.13941v1', 'MLZero: A Multi-Agent System for End-to-end Machine Learning Automation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/250514489v2-reasoning-models-better-express-their-confidence.html">Reasoning Models Better Express Their Confidence</a></td>
  <td>æå‡ºæ¨ç†æ¨¡å‹ä»¥æé«˜ä¿¡å¿ƒè¡¨è¾¾çš„å‡†ç¡®æ€§</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14489v2" data-paper-url="./papers/250514489v2-reasoning-models-better-express-their-confidence.html" onclick="toggleFavorite(this, '2505.14489v2', 'Reasoning Models Better Express Their Confidence')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/250514038v1-promind-llm-proactive-mental-health-care-via-causal-reasoning-with-s.html">ProMind-LLM: Proactive Mental Health Care via Causal Reasoning with Sensor Data</a></td>
  <td>æå‡ºProMind-LLMä»¥è§£å†³å¿ƒç†å¥åº·è¯„ä¼°ä¸­çš„ä¸»è§‚æ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14038v1" data-paper-url="./papers/250514038v1-promind-llm-proactive-mental-health-care-via-causal-reasoning-with-s.html" onclick="toggleFavorite(this, '2505.14038v1', 'ProMind-LLM: Proactive Mental Health Care via Causal Reasoning with Sensor Data')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/250513940v2-drugpilot-llm-based-parameterized-reasoning-agent-for-drug-discovery.html">DrugPilot: LLM-based Parameterized Reasoning Agent for Drug Discovery</a></td>
  <td>æå‡ºDrugPilotä»¥è§£å†³è¯ç‰©å‘ç°ä¸­çš„å¤šæ¨¡æ€æ•°æ®å¤„ç†é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13940v2" data-paper-url="./papers/250513940v2-drugpilot-llm-based-parameterized-reasoning-agent-for-drug-discovery.html" onclick="toggleFavorite(this, '2505.13940v2', 'DrugPilot: LLM-based Parameterized Reasoning Agent for Drug Discovery')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/250514366v1-towards-embodied-cognition-in-robots-via-spatially-grounded-syntheti.html">Towards Embodied Cognition in Robots via Spatially Grounded Synthetic Worlds</a></td>
  <td>æå‡ºç©ºé—´åŸºç¡€åˆæˆä¸–ç•Œä»¥ä¿ƒè¿›æœºå™¨äººå…·èº«è®¤çŸ¥</td>
  <td class="tags-cell"><span class="paper-tag">embodied AI</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14366v1" data-paper-url="./papers/250514366v1-towards-embodied-cognition-in-robots-via-spatially-grounded-syntheti.html" onclick="toggleFavorite(this, '2505.14366v1', 'Towards Embodied Cognition in Robots via Spatially Grounded Synthetic Worlds')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/250514681v2-two-experts-are-all-you-need-for-steering-thinking-reinforcing-cogni.html">Two Experts Are All You Need for Steering Thinking: Reinforcing Cognitive Effort in MoE Reasoning Models Without Additional Training</a></td>
  <td>æå‡ºRICEæ–¹æ³•ä»¥è§£å†³MoEæ¨ç†æ¨¡å‹ä¸­çš„è®¤çŸ¥æ•ˆç‡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">instruction following</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14681v2" data-paper-url="./papers/250514681v2-two-experts-are-all-you-need-for-steering-thinking-reinforcing-cogni.html" onclick="toggleFavorite(this, '2505.14681v2', 'Two Experts Are All You Need for Steering Thinking: Reinforcing Cognitive Effort in MoE Reasoning Models Without Additional Training')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/250514978v2-jarvis-a-multi-agent-code-assistant-for-high-quality-eda-script-gene.html">JARVIS: A Multi-Agent Code Assistant for High-Quality EDA Script Generation</a></td>
  <td>æå‡ºJARVISæ¡†æ¶ä»¥è§£å†³EDAè„šæœ¬ç”Ÿæˆè´¨é‡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14978v2" data-paper-url="./papers/250514978v2-jarvis-a-multi-agent-code-assistant-for-high-quality-eda-script-gene.html" onclick="toggleFavorite(this, '2505.14978v2', 'JARVIS: A Multi-Agent Code Assistant for High-Quality EDA Script Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/250514615v2-satbench-benchmarking-llms-logical-reasoning-via-automated-puzzle-ge.html">SATBench: Benchmarking LLMs' Logical Reasoning via Automated Puzzle Generation from SAT Formulas</a></td>
  <td>æå‡ºSATBenchä»¥è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹çš„é€»è¾‘æ¨ç†èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14615v2" data-paper-url="./papers/250514615v2-satbench-benchmarking-llms-logical-reasoning-via-automated-puzzle-ge.html" onclick="toggleFavorite(this, '2505.14615v2', 'SATBench: Benchmarking LLMs&#39; Logical Reasoning via Automated Puzzle Generation from SAT Formulas')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>21</td>
  <td><a href="./papers/250514864v2-balanced-and-elastic-end-to-end-training-of-dynamic-llms.html">Balanced and Elastic End-to-end Training of Dynamic LLMs</a></td>
  <td>æå‡ºDynMoä»¥è§£å†³å¤§è§„æ¨¡åŠ¨æ€LLMè®­ç»ƒä¸­çš„è´Ÿè½½ä¸å‡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14864v2" data-paper-url="./papers/250514864v2-balanced-and-elastic-end-to-end-training-of-dynamic-llms.html" onclick="toggleFavorite(this, '2505.14864v2', 'Balanced and Elastic End-to-end Training of Dynamic LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>22</td>
  <td><a href="./papers/250514668v2-contextagent-context-aware-proactive-llm-agents-with-open-world-sens.html">ContextAgent: Context-Aware Proactive LLM Agents with Open-World Sensory Perceptions</a></td>
  <td>æå‡ºContextAgentä»¥è§£å†³ç°æœ‰ä¸»åŠ¨æ™ºèƒ½ä½“çš„å±€é™æ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14668v2" data-paper-url="./papers/250514668v2-contextagent-context-aware-proactive-llm-agents-with-open-world-sens.html" onclick="toggleFavorite(this, '2505.14668v2', 'ContextAgent: Context-Aware Proactive LLM Agents with Open-World Sensory Perceptions')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>23</td>
  <td><a href="./papers/250517084v1-from-nuclear-safety-to-llm-security-applying-non-probabilistic-risk-.html">From nuclear safety to LLM security: Applying non-probabilistic risk management strategies to build safe and secure LLM-powered systems</a></td>
  <td>æå‡ºéæ¦‚ç‡é£é™©ç®¡ç†ç­–ç•¥ä»¥è§£å†³LLMå®‰å…¨é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.17084v1" data-paper-url="./papers/250517084v1-from-nuclear-safety-to-llm-security-applying-non-probabilistic-risk-.html" onclick="toggleFavorite(this, '2505.17084v1', 'From nuclear safety to LLM security: Applying non-probabilistic risk management strategies to build safe and secure LLM-powered systems')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>24</td>
  <td><a href="./papers/250514479v5-towards-reliable-proof-generation-with-llms-a-neuro-symbolic-approac.html">Towards Reliable Proof Generation with LLMs: A Neuro-Symbolic Approach</a></td>
  <td>æå‡ºç¥ç»ç¬¦å·æ–¹æ³•ä»¥è§£å†³æ•°å­¦è¯æ˜ç”Ÿæˆé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14479v5" data-paper-url="./papers/250514479v5-towards-reliable-proof-generation-with-llms-a-neuro-symbolic-approac.html" onclick="toggleFavorite(this, '2505.14479v5', 'Towards Reliable Proof Generation with LLMs: A Neuro-Symbolic Approach')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>25</td>
  <td><a href="./papers/250514435v2-choosing-a-model-shaping-a-future-comparing-llm-perspectives-on-sust.html">Choosing a Model, Shaping a Future: Comparing LLM Perspectives on Sustainability and its Relationship with AI</a></td>
  <td>æ¯”è¾ƒäº”ç§å¤§å‹è¯­è¨€æ¨¡å‹å¯¹å¯æŒç»­æ€§ä¸AIå…³ç³»çš„çœ‹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14435v2" data-paper-url="./papers/250514435v2-choosing-a-model-shaping-a-future-comparing-llm-perspectives-on-sust.html" onclick="toggleFavorite(this, '2505.14435v2', 'Choosing a Model, Shaping a Future: Comparing LLM Perspectives on Sustainability and its Relationship with AI')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>26</td>
  <td><a href="./papers/250514394v1-knowledge-graph-based-repository-level-code-generation.html">Knowledge Graph Based Repository-Level Code Generation</a></td>
  <td>æå‡ºåŸºäºçŸ¥è¯†å›¾è°±çš„ä»£ç ç”Ÿæˆæ–¹æ³•ä»¥æå‡ä»£ç æ£€ç´¢è´¨é‡</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14394v1" data-paper-url="./papers/250514394v1-knowledge-graph-based-repository-level-code-generation.html" onclick="toggleFavorite(this, '2505.14394v1', 'Knowledge Graph Based Repository-Level Code Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>27</td>
  <td><a href="./papers/250514381v2-scan-semantic-document-layout-analysis-for-textual-and-visual-retrie.html">SCAN: Semantic Document Layout Analysis for Textual and Visual Retrieval-Augmented Generation</a></td>
  <td>æå‡ºSCANä»¥è§£å†³ä¸°å¯Œæ–‡æ¡£çš„æ£€ç´¢å¢å¼ºç”Ÿæˆé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14381v2" data-paper-url="./papers/250514381v2-scan-semantic-document-layout-analysis-for-textual-and-visual-retrie.html" onclick="toggleFavorite(this, '2505.14381v2', 'SCAN: Semantic Document Layout Analysis for Textual and Visual Retrieval-Augmented Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>28</td>
  <td><a href="./papers/250513994v2-divide-by-question-conquer-by-agent-split-rag-with-question-driven-g.html">Divide by Question, Conquer by Agent: SPLIT-RAG with Question-Driven Graph Partitioning</a></td>
  <td>æå‡ºSPLIT-RAGä»¥è§£å†³å¤§è§„æ¨¡çŸ¥è¯†å›¾è°±çš„æ£€ç´¢æ•ˆç‡ä¸å‡†ç¡®æ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13994v2" data-paper-url="./papers/250513994v2-divide-by-question-conquer-by-agent-split-rag-with-question-driven-g.html" onclick="toggleFavorite(this, '2505.13994v2', 'Divide by Question, Conquer by Agent: SPLIT-RAG with Question-Driven Graph Partitioning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>29</td>
  <td><a href="./papers/250513808v1-ragllm-augmented-switching-driven-polymorphic-metaheuristic-framewor.html">RAG/LLM Augmented Switching Driven Polymorphic Metaheuristic Framework</a></td>
  <td>æå‡ºè‡ªé€‚åº”å¤šæ€å…ƒå¯å‘å¼æ¡†æ¶ä»¥è§£å†³ä¼˜åŒ–é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13808v1" data-paper-url="./papers/250513808v1-ragllm-augmented-switching-driven-polymorphic-metaheuristic-framewor.html" onclick="toggleFavorite(this, '2505.13808v1', 'RAG/LLM Augmented Switching Driven Polymorphic Metaheuristic Framework')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>30</td>
  <td><a href="./papers/250513794v1-llm-based-evaluation-policy-extraction-for-ecological-modeling.html">LLM-based Evaluation Policy Extraction for Ecological Modeling</a></td>
  <td>æå‡ºåŸºäºLLMçš„è¯„ä¼°ç­–ç•¥æå–ä»¥è§£å†³ç”Ÿæ€å»ºæ¨¡è¯„ä¼°é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13794v1" data-paper-url="./papers/250513794v1-llm-based-evaluation-policy-extraction-for-ecological-modeling.html" onclick="toggleFavorite(this, '2505.13794v1', 'LLM-based Evaluation Policy Extraction for Ecological Modeling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (10 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>31</td>
  <td><a href="./papers/250514946v1-reinforcement-learning-from-user-feedback.html">Reinforcement Learning from User Feedback</a></td>
  <td>æå‡ºç”¨æˆ·åé¦ˆå¼ºåŒ–å­¦ä¹ æ¡†æ¶ä»¥è§£å†³ç”¨æˆ·åå¥½å¯¹é½é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">RLHF</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14946v1" data-paper-url="./papers/250514946v1-reinforcement-learning-from-user-feedback.html" onclick="toggleFavorite(this, '2505.14946v1', 'Reinforcement Learning from User Feedback')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>32</td>
  <td><a href="./papers/250514216v2-reinforcement-learning-vs-distillation-understanding-accuracy-and-ca.html">Reinforcement Learning vs. Distillation: Understanding Accuracy and Capability in LLM Reasoning</a></td>
  <td>æ¢è®¨RLVRä¸è’¸é¦åœ¨LLMæ¨ç†ä¸­çš„å‡†ç¡®æ€§ä¸èƒ½åŠ›å·®å¼‚</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">distillation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14216v2" data-paper-url="./papers/250514216v2-reinforcement-learning-vs-distillation-understanding-accuracy-and-ca.html" onclick="toggleFavorite(this, '2505.14216v2', 'Reinforcement Learning vs. Distillation: Understanding Accuracy and Capability in LLM Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>33</td>
  <td><a href="./papers/250514396v1-causal-cartographer-from-mapping-to-reasoning-over-counterfactual-wo.html">Causal Cartographer: From Mapping to Reasoning Over Counterfactual Worlds</a></td>
  <td>æå‡ºCausal Cartographerä»¥è§£å†³å› æœæ¨ç†ä¸åäº‹å®è¯„ä¼°é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">world model</span> <span class="paper-tag">large language model</span> <span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14396v1" data-paper-url="./papers/250514396v1-causal-cartographer-from-mapping-to-reasoning-over-counterfactual-wo.html" onclick="toggleFavorite(this, '2505.14396v1', 'Causal Cartographer: From Mapping to Reasoning Over Counterfactual Worlds')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>34</td>
  <td><a href="./papers/250514163v1-dsmentor-enhancing-data-science-agents-with-curriculum-learning-and-.html">DSMentor: Enhancing Data Science Agents with Curriculum Learning and Online Knowledge Accumulation</a></td>
  <td>æå‡ºDSMentorä»¥ä¼˜åŒ–æ•°æ®ç§‘å­¦ä»£ç†çš„æ¨ç†è¿‡ç¨‹</td>
  <td class="tags-cell"><span class="paper-tag">curriculum learning</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14163v1" data-paper-url="./papers/250514163v1-dsmentor-enhancing-data-science-agents-with-curriculum-learning-and-.html" onclick="toggleFavorite(this, '2505.14163v1', 'DSMentor: Enhancing Data Science Agents with Curriculum Learning and Online Knowledge Accumulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>35</td>
  <td><a href="./papers/250514147v3-sharp-synthesizing-high-quality-aligned-reasoning-problems-for-large.html">SHARP: Synthesizing High-quality Aligned Reasoning Problems for Large Reasoning Models Reinforcement Learning</a></td>
  <td>æå‡ºSHARPä»¥è§£å†³å¤§è§„æ¨¡æ¨ç†æ¨¡å‹è®­ç»ƒä¸­çš„é—®é¢˜ç”ŸæˆæŒ‘æˆ˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14147v3" data-paper-url="./papers/250514147v3-sharp-synthesizing-high-quality-aligned-reasoning-problems-for-large.html" onclick="toggleFavorite(this, '2505.14147v3', 'SHARP: Synthesizing High-quality Aligned Reasoning Problems for Large Reasoning Models Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>36</td>
  <td><a href="./papers/250514140v2-rl-of-thoughts-navigating-llm-reasoning-with-inference-time-reinforc.html">RL of Thoughts: Navigating LLM Reasoning with Inference-time Reinforcement Learning</a></td>
  <td>æå‡ºRL-of-Thoughtsä»¥å¢å¼ºå¤§è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14140v2" data-paper-url="./papers/250514140v2-rl-of-thoughts-navigating-llm-reasoning-with-inference-time-reinforc.html" onclick="toggleFavorite(this, '2505.14140v2', 'RL of Thoughts: Navigating LLM Reasoning with Inference-time Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>37</td>
  <td><a href="./papers/250513946v2-visual-instruction-bottleneck-tuning.html">Visual Instruction Bottleneck Tuning</a></td>
  <td>æå‡ºè§†è§‰æŒ‡ä»¤ç“¶é¢ˆè°ƒä¼˜ä»¥æå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„é²æ£’æ€§</td>
  <td class="tags-cell"><span class="paper-tag">representation learning</span> <span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13946v2" data-paper-url="./papers/250513946v2-visual-instruction-bottleneck-tuning.html" onclick="toggleFavorite(this, '2505.13946v2', 'Visual Instruction Bottleneck Tuning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>38</td>
  <td><a href="./papers/250514209v1-embedded-mean-field-reinforcement-learning-for-perimeter-defense-gam.html">Embedded Mean Field Reinforcement Learning for Perimeter-defense Game</a></td>
  <td>æå‡ºåµŒå…¥å¼å‡åœºå¼ºåŒ–å­¦ä¹ æ¡†æ¶ä»¥è§£å†³å¤æ‚çš„å‘¨è¾¹é˜²å¾¡æ¸¸æˆé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">representation learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14209v1" data-paper-url="./papers/250514209v1-embedded-mean-field-reinforcement-learning-for-perimeter-defense-gam.html" onclick="toggleFavorite(this, '2505.14209v1', 'Embedded Mean Field Reinforcement Learning for Perimeter-defense Game')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>39</td>
  <td><a href="./papers/250514412v1-prl-prompts-from-reinforcement-learning.html">PRL: Prompts from Reinforcement Learning</a></td>
  <td>æå‡ºåŸºäºå¼ºåŒ–å­¦ä¹ çš„è‡ªåŠ¨æç¤ºç”Ÿæˆæ–¹æ³•PRLä»¥è§£å†³æç¤ºå·¥ç¨‹æŒ‘æˆ˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14412v1" data-paper-url="./papers/250514412v1-prl-prompts-from-reinforcement-learning.html" onclick="toggleFavorite(this, '2505.14412v1', 'PRL: Prompts from Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>40</td>
  <td><a href="./papers/250513831v2-teleplannet-an-ai-driven-framework-for-efficient-telecom-network-pla.html">TelePlanNet: An AI-Driven Framework for Efficient Telecom Network Planning</a></td>
  <td>æå‡ºTelePlanNetä»¥è§£å†³5Gç½‘ç»œåŸºç«™é€‰å€ä¼˜åŒ–é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13831v2" data-paper-url="./papers/250513831v2-teleplannet-an-ai-driven-framework-for-efficient-telecom-network-pla.html" onclick="toggleFavorite(this, '2505.13831v2', 'TelePlanNet: An AI-Driven Framework for Efficient Telecom Network Planning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (3 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>41</td>
  <td><a href="./papers/250514970v4-self-evolving-curriculum-for-llm-reasoning.html">Self-Evolving Curriculum for LLM Reasoning</a></td>
  <td>æå‡ºè‡ªæ¼”åŒ–è¯¾ç¨‹ä»¥ä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">dual-arm</span> <span class="paper-tag">reinforcement learning</span> <span class="paper-tag">curriculum learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14970v4" data-paper-url="./papers/250514970v4-self-evolving-curriculum-for-llm-reasoning.html" onclick="toggleFavorite(this, '2505.14970v4', 'Self-Evolving Curriculum for LLM Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>42</td>
  <td><a href="./papers/250514289v1-eva-red-teaming-gui-agents-via-evolving-indirect-prompt-injection.html">EVA: Red-Teaming GUI Agents via Evolving Indirect Prompt Injection</a></td>
  <td>æå‡ºEVAæ¡†æ¶ä»¥åº”å¯¹é—´æ¥æç¤ºæ³¨å…¥æ”»å‡»é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14289v1" data-paper-url="./papers/250514289v1-eva-red-teaming-gui-agents-via-evolving-indirect-prompt-injection.html" onclick="toggleFavorite(this, '2505.14289v1', 'EVA: Red-Teaming GUI Agents via Evolving Indirect Prompt Injection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>43</td>
  <td><a href="./papers/250514744v1-transductively-informed-inductive-program-synthesis.html">Transductively Informed Inductive Program Synthesis</a></td>
  <td>æå‡ºTIIPSæ¡†æ¶ä»¥æå‡ç¨‹åºåˆæˆçš„å‡†ç¡®æ€§ä¸æ³›åŒ–èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14744v1" data-paper-url="./papers/250514744v1-transductively-informed-inductive-program-synthesis.html" onclick="toggleFavorite(this, '2505.14744v1', 'Transductively Informed Inductive Program Synthesis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation">ğŸ”¬ æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>44</td>
  <td><a href="./papers/250514103v2-audiojailbreak-jailbreak-attacks-against-end-to-end-large-audio-lang.html">AudioJailbreak: Jailbreak Attacks against End-to-End Large Audio-Language Models</a></td>
  <td>æå‡ºAudioJailbreakä»¥è§£å†³éŸ³é¢‘è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ¼æ´é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">PULSE</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14103v2" data-paper-url="./papers/250514103v2-audiojailbreak-jailbreak-attacks-against-end-to-end-large-audio-lang.html" onclick="toggleFavorite(this, '2505.14103v2', 'AudioJailbreak: Jailbreak Attacks against End-to-End Large Audio-Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.AI é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)