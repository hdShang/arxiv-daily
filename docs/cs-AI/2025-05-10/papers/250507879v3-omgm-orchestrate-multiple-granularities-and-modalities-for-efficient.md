---
layout: default
title: OMGM: Orchestrate Multiple Granularities and Modalities for Efficient Multimodal Retrieval
---

# OMGM: Orchestrate Multiple Granularities and Modalities for Efficient Multimodal Retrieval

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.07879" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.07879v3</a>
  <a href="https://arxiv.org/pdf/2505.07879.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.07879v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.07879v3', 'OMGM: Orchestrate Multiple Granularities and Modalities for Efficient Multimodal Retrieval')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wei Yang, Jingjing Fu, Rui Wang, Jinyu Wang, Lei Song, Jiang Bian

**åˆ†ç±»**: cs.IR, cs.AI, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-10 (æ›´æ–°: 2025-09-12)

**å¤‡æ³¨**: Accepted to ACL 2025 Main Conference

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOMGMä»¥è§£å†³å¤šæ¨¡æ€æ£€ç´¢ä¸­çš„çŸ¥è¯†ç²’åº¦ä¸æ¨¡æ€èåˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ£€ç´¢` `çŸ¥è¯†ç²’åº¦` `è§†è§‰é—®ç­”` `ä¿¡æ¯æ£€ç´¢` `å¢å¼ºç”Ÿæˆ` `ç²—åˆ°ç»†æ£€ç´¢` `å¤šæ¨¡æ€èåˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€æ£€ç´¢æ–¹æ³•æœªèƒ½å……åˆ†æŒ–æ˜æŸ¥è¯¢ä¸çŸ¥è¯†åº“ä¸­å¤šç§æ¨¡æ€å’ŒçŸ¥è¯†ç²’åº¦ä¹‹é—´çš„æ½œåœ¨ç›¸äº’ä½œç”¨ï¼Œå¯¼è‡´æ£€ç´¢æ•ˆæœä¸ä½³ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€RAGç³»ç»Ÿï¼Œé‡‡ç”¨ç²—åˆ°ç»†çš„å¤šæ­¥éª¤æ£€ç´¢ç­–ç•¥ï¼Œåè°ƒå¤šç§ç²’åº¦å’Œæ¨¡æ€ä»¥æå‡æ£€ç´¢æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚
3. åœ¨InfoSeekå’ŒEncyclopedic-VQAåŸºå‡†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•åœ¨æ£€ç´¢æ€§èƒ½ä¸Šè¶…è¶Šäº†ç°æœ‰æ–¹æ³•ï¼Œå¹¶åœ¨å›ç­”å‡†ç¡®æ€§ä¸Šè¡¨ç°å‡ºè‰²ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰è¯­è¨€æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰å·²æˆä¸ºè§£å†³åŸºäºçŸ¥è¯†çš„è§†è§‰é—®ç­”ï¼ˆKB-VQAï¼‰çš„æœ‰æ•ˆæ–¹æ³•ï¼Œç„¶è€Œç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†åˆ©ç”¨æŸ¥è¯¢å’ŒçŸ¥è¯†åº“ä¸­å¤šæ¨¡æ€å’ŒçŸ¥è¯†ç²’åº¦ä¹‹é—´çš„ç›¸äº’ä½œç”¨ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€RAGç³»ç»Ÿï¼Œé‡‡ç”¨ç²—åˆ°ç»†çš„å¤šæ­¥éª¤æ£€ç´¢ï¼Œåè°ƒå¤šç§ç²’åº¦å’Œæ¨¡æ€ä»¥æé«˜æ•ˆç‡ã€‚ç³»ç»Ÿé¦–å…ˆè¿›è¡Œå¹¿æ³›çš„åˆæ­¥æœç´¢ï¼Œä»¥å¯¹é½çŸ¥è¯†ç²’åº¦è¿›è¡Œè·¨æ¨¡æ€æ£€ç´¢ï¼Œéšåé€šè¿‡å¤šæ¨¡æ€èåˆé‡æ’åºæ•æ‰ç»†è‡´çš„å¤šæ¨¡æ€ä¿¡æ¯ï¼Œæœ€ç»ˆé€šè¿‡æ–‡æœ¬é‡æ’åºç­›é€‰å‡ºæœ€ç›¸å…³çš„ç»†ç²’åº¦éƒ¨åˆ†è¿›è¡Œå¢å¼ºç”Ÿæˆã€‚åœ¨InfoSeekå’ŒEncyclopedic-VQAåŸºå‡†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨æ£€ç´¢æ€§èƒ½å’Œå›ç­”ç»“æœä¸Šå‡è¾¾åˆ°äº†æœ€å…ˆè¿›æ°´å¹³ï¼Œå½°æ˜¾äº†å…¶åœ¨æ¨åŠ¨KB-VQAç³»ç»Ÿæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€æ£€ç´¢ä¸­çŸ¥è¯†ç²’åº¦ä¸æ¨¡æ€èåˆçš„æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆåˆ©ç”¨ä¸åŒæ¨¡æ€å’Œç²’åº¦çš„ä¿¡æ¯ï¼Œå¯¼è‡´æ£€ç´¢å’Œå›ç­”æ•ˆæœä¸ç†æƒ³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºä¸€ç§å¤šæ¨¡æ€RAGç³»ç»Ÿï¼Œé€šè¿‡ç²—åˆ°ç»†çš„æ£€ç´¢ç­–ç•¥ï¼Œé¦–å…ˆè¿›è¡Œå¹¿æ³›çš„åˆæ­¥æœç´¢ï¼Œç„¶åé€šè¿‡å¤šæ¨¡æ€èåˆé‡æ’åºå’Œæ–‡æœ¬é‡æ’åºï¼Œé€æ­¥ç­›é€‰å‡ºæœ€ç›¸å…³çš„ä¿¡æ¯ï¼Œä»¥å¢å¼ºç”Ÿæˆçš„æ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼šåˆæ­¥æ£€ç´¢é˜¶æ®µã€èåˆé‡æ’åºé˜¶æ®µå’Œæ–‡æœ¬é‡æ’åºé˜¶æ®µã€‚åˆæ­¥æ£€ç´¢å¯¹é½çŸ¥è¯†ç²’åº¦ï¼Œèåˆé‡æ’åºæ•æ‰å¤šæ¨¡æ€ä¿¡æ¯ï¼Œæ–‡æœ¬é‡æ’åºåˆ™é€‰æ‹©æœ€ç›¸å…³çš„ç»†ç²’åº¦ä¿¡æ¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæå‡ºäº†ç²—åˆ°ç»†çš„å¤šæ­¥éª¤æ£€ç´¢ç­–ç•¥ï¼Œå……åˆ†åˆ©ç”¨äº†ä¸åŒæ¨¡æ€å’ŒçŸ¥è¯†ç²’åº¦ä¹‹é—´çš„ç›¸äº’ä½œç”¨ï¼Œæ˜¾è‘—æå‡äº†æ£€ç´¢çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å¤šæ¨¡æ€èåˆé‡æ’åºç®—æ³•å’Œæ–‡æœ¬é‡æ’åºæœºåˆ¶ï¼Œç¡®ä¿äº†ä¿¡æ¯çš„æœ‰æ•ˆç­›é€‰å’Œç”Ÿæˆï¼Œå…·ä½“çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„åœ¨å®éªŒä¸­ç»è¿‡ä¼˜åŒ–ä»¥æé«˜æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨InfoSeekå’ŒEncyclopedic-VQAåŸºå‡†ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ£€ç´¢æ€§èƒ½ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•ï¼Œæ£€ç´¢å‡†ç¡®ç‡æå‡äº†çº¦15%ï¼Œå›ç­”å‡†ç¡®æ€§ä¹Ÿæ˜¾è‘—æé«˜ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€ä¿¡æ¯æ£€ç´¢ã€æ•™è‚²è¾…åŠ©å·¥å…·ç­‰ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡ç”¨æˆ·åœ¨å¤æ‚æŸ¥è¯¢åœºæ™¯ä¸‹çš„ä¿¡æ¯è·å–æ•ˆç‡ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›åœ¨æ›´å¹¿æ³›çš„å¤šæ¨¡æ€ä»»åŠ¡ä¸­å‘æŒ¥é‡è¦ä½œç”¨ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision-language retrieval-augmented generation (RAG) has become an effective approach for tackling Knowledge-Based Visual Question Answering (KB-VQA), which requires external knowledge beyond the visual content presented in images. The effectiveness of Vision-language RAG systems hinges on multimodal retrieval, which is inherently challenging due to the diverse modalities and knowledge granularities in both queries and knowledge bases. Existing methods have not fully tapped into the potential interplay between these elements. We propose a multimodal RAG system featuring a coarse-to-fine, multi-step retrieval that harmonizes multiple granularities and modalities to enhance efficacy. Our system begins with a broad initial search aligning knowledge granularity for cross-modal retrieval, followed by a multimodal fusion reranking to capture the nuanced multimodal information for top entity selection. A text reranker then filters out the most relevant fine-grained section for augmented generation. Extensive experiments on the InfoSeek and Encyclopedic-VQA benchmarks show our method achieves state-of-the-art retrieval performance and highly competitive answering results, underscoring its effectiveness in advancing KB-VQA systems.

