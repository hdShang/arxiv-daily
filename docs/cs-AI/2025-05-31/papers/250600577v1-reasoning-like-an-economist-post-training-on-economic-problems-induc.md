---
layout: default
title: "Reasoning Like an Economist: Post-Training on Economic Problems Induces Strategic Generalization in LLMs"
---

# Reasoning Like an Economist: Post-Training on Economic Problems Induces Strategic Generalization in LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.00577" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.00577v1</a>
  <a href="https://arxiv.org/pdf/2506.00577.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.00577v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.00577v1', 'Reasoning Like an Economist: Post-Training on Economic Problems Induces Strategic Generalization in LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yufa Zhou, Shaobo Wang, Xingyu Dong, Xiangqi Jin, Yifang Chen, Yue Min, Kexin Yang, Xingzhang Ren, Dayiheng Liu, Linfeng Zhang

**åˆ†ç±»**: cs.AI, cs.CL, cs.GT, cs.MA

**å‘å¸ƒæ—¥æœŸ**: 2025-05-31

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/MasterZhou1/Recon)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºReconä»¥è§£å†³å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­çš„ç»æµæ¨ç†é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ` `ç»æµæ¨ç†` `åè®­ç»ƒæŠ€æœ¯` `å¼ºåŒ–å­¦ä¹ ` `ç›‘ç£å¾®è°ƒ` `åšå¼ˆè®º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­é¢ä¸´å¤æ‚çš„å¥–åŠ±å»ºæ¨¡å’ŒåŠ¨æ€äº¤äº’çš„æŒ‘æˆ˜ï¼Œå¯¼è‡´è®­ç»ƒæ•ˆæœä¸ä½³ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡åè®­ç»ƒæŠ€æœ¯Reconï¼Œç»“åˆç›‘ç£å¾®è°ƒå’Œå¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼Œå¢å¼ºæ¨¡å‹çš„ç»æµæ¨ç†èƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒReconåœ¨ç»æµæ¨ç†åŸºå‡†å’Œå¤šæ™ºèƒ½ä½“æ¸¸æˆä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„ç»“æ„åŒ–æ¨ç†èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç›´æ¥è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä»¥åº”å¯¹å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMASï¼‰é¢ä¸´å¤æ‚çš„å¥–åŠ±å»ºæ¨¡ã€åŠ¨æ€ä»£ç†äº¤äº’å’Œä¸¥æ ¼çš„æ³›åŒ–è¦æ±‚ã€‚æœ¬æ–‡æ¢è®¨äº†åè®­ç»ƒæŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’Œå¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLVRï¼‰ï¼Œåœ¨å¤šæ™ºèƒ½ä½“åœºæ™¯ä¸­çš„æœ‰æ•ˆæ³›åŒ–ã€‚æˆ‘ä»¬ä»¥ç»æµæ¨ç†ä¸ºæµ‹è¯•å¹³å°ï¼Œåˆ©ç”¨å…¶åœ¨æ•°å­¦å’Œåšå¼ˆè®ºä¸­çš„åšå®åŸºç¡€ï¼Œä»¥åŠå¯¹ç»“æ„åŒ–åˆ†ææ¨ç†çš„éœ€æ±‚ã€‚æˆ‘ä»¬å¼•å…¥äº†Reconï¼Œä¸€ä¸ªåŸºäº2100ä¸ªé«˜è´¨é‡ç»æµæ¨ç†é—®é¢˜çš„7Bå‚æ•°å¼€æºLLMã€‚å…¨é¢è¯„ä¼°æ˜¾ç¤ºï¼Œåœ¨ç»æµæ¨ç†åŸºå‡†å’Œå¤šæ™ºèƒ½ä½“æ¸¸æˆä¸­ï¼Œæ¨¡å‹åœ¨ç»“æ„åŒ–æ¨ç†å’Œç»æµç†æ€§æ–¹é¢æœ‰æ˜æ˜¾æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­é¢ä¸´çš„å¤æ‚å¥–åŠ±å»ºæ¨¡å’ŒåŠ¨æ€äº¤äº’é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆæ³›åŒ–ï¼Œå¯¼è‡´æ¨¡å‹åœ¨ç»æµæ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°ä¸ç†æƒ³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡åè®­ç»ƒæŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’Œå¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLVRï¼‰ï¼Œæ¥æå‡æ¨¡å‹åœ¨ç»æµæ¨ç†åœºæ™¯ä¸­çš„è¡¨ç°ã€‚é€šè¿‡ç»æµæ¨ç†çš„ç»“æ„åŒ–åˆ†æï¼Œæ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œå¤„ç†å¤šæ™ºèƒ½ä½“äº¤äº’ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€æ¨¡å‹åè®­ç»ƒå’Œè¯„ä¼°ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œæ„å»ºä¸€ä¸ªåŒ…å«2100ä¸ªé«˜è´¨é‡ç»æµæ¨ç†é—®é¢˜çš„æ•°æ®é›†ï¼›ç„¶åï¼Œé‡‡ç”¨SFTå’ŒRLVRå¯¹æ¨¡å‹è¿›è¡Œåè®­ç»ƒï¼›æœ€åï¼Œé€šè¿‡ç»æµæ¨ç†åŸºå‡†å’Œå¤šæ™ºèƒ½ä½“æ¸¸æˆè¿›è¡Œè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šReconçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶ä¸“æ³¨äºç»æµæ¨ç†çš„åè®­ç»ƒï¼Œåˆ©ç”¨ç»æµå­¦çš„æ•°å­¦åŸºç¡€å’Œåšå¼ˆè®ºæ¡†æ¶ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„æ¨ç†èƒ½åŠ›å’Œæ™ºèƒ½ä½“å¯¹é½æ•ˆæœã€‚è¿™ä¸ä¼ ç»Ÿçš„è®­ç»ƒæ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼ŒReconé‡‡ç”¨7Bå‚æ•°çš„æ¶æ„ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ç»“åˆäº†ç»æµæ¨ç†çš„ç‰¹æ€§ï¼Œç½‘ç»œç»“æ„åˆ™ä¼˜åŒ–äº†å¯¹å¤æ‚äº¤äº’çš„å¤„ç†èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒReconåœ¨ç»æµæ¨ç†åŸºå‡†æµ‹è¯•ä¸­ç›¸è¾ƒäºåŸºçº¿æ¨¡å‹æœ‰æ˜¾è‘—æå‡ï¼Œå°¤å…¶åœ¨ç»“æ„åŒ–æ¨ç†å’Œç»æµç†æ€§æ–¹é¢ï¼Œæå‡å¹…åº¦è¾¾åˆ°äº†20%ä»¥ä¸Šã€‚è¿™äº›ç»“æœéªŒè¯äº†åè®­ç»ƒæŠ€æœ¯åœ¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¸‚åœºè®¾è®¡ã€èµ„æºåˆ†é…å’Œæ”¿ç­–åˆ†æç­‰ã€‚é€šè¿‡æå‡æ¨¡å‹çš„ç»æµæ¨ç†èƒ½åŠ›ï¼ŒReconèƒ½å¤Ÿä¸ºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿæä¾›æ›´æœ‰æ•ˆçš„å†³ç­–æ”¯æŒï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Directly training Large Language Models (LLMs) for Multi-Agent Systems (MAS) remains challenging due to intricate reward modeling, dynamic agent interactions, and demanding generalization requirements. This paper explores whether post-training techniques, specifically Supervised Fine-Tuning (SFT) and Reinforcement Learning with Verifiable Rewards (RLVR), can effectively $\textit{generalize}$ to multi-agent scenarios. We use economic reasoning as a testbed, leveraging its strong foundations in mathematics and game theory, its demand for structured analytical reasoning, and its relevance to real-world applications such as market design, resource allocation, and policy analysis. We introduce $\textbf{Recon}$ ($\textbf{R}$easoning like an $\textbf{ECON}$omist), a 7B-parameter open-source LLM post-trained on a hand-curated dataset of 2,100 high-quality economic reasoning problems. Comprehensive evaluation on economic reasoning benchmarks and multi-agent games reveals clear improvements in structured reasoning and economic rationality. These results underscore the promise of domain-aligned post-training for enhancing reasoning and agent alignment, shedding light on the roles of SFT and RL in shaping model behavior. Code is available at https://github.com/MasterZhou1/Recon .

