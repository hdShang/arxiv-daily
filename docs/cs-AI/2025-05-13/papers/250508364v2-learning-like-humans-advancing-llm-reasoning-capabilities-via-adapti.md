---
layout: default
title: Learning Like Humans: Advancing LLM Reasoning Capabilities via Adaptive Difficulty Curriculum Learning and Expert-Guided Self-Reformulation
---

# Learning Like Humans: Advancing LLM Reasoning Capabilities via Adaptive Difficulty Curriculum Learning and Expert-Guided Self-Reformulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.08364" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.08364v2</a>
  <a href="https://arxiv.org/pdf/2505.08364.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.08364v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.08364v2', 'Learning Like Humans: Advancing LLM Reasoning Capabilities via Adaptive Difficulty Curriculum Learning and Expert-Guided Self-Reformulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Enci Zhang, Xingang Yan, Wei Lin, Tianxiang Zhang, Qianchun Lu

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-13 (æ›´æ–°: 2025-09-17)

**å¤‡æ³¨**: 14 pages, 3 figs

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè‡ªé€‚åº”éš¾åº¦è¯¾ç¨‹å­¦ä¹ ä¸ä¸“å®¶å¼•å¯¼è‡ªæˆ‘é‡æ„ä»¥æå‡LLMæ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ¨ç†èƒ½åŠ›` `è¯¾ç¨‹å­¦ä¹ ` `è‡ªæˆ‘é‡æ„` `å¼ºåŒ–å­¦ä¹ ` `æ•°å­¦æ¨ç†` `çŸ¥è¯†å¸æ”¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è§£å†³å¤æ‚é—®é¢˜æ—¶è¡¨ç°ä¸ç¨³å®šï¼Œå°¤å…¶æ˜¯åœ¨æ•°å­¦æ¨ç†æ–¹é¢å­˜åœ¨æ˜¾è‘—æŒ‘æˆ˜ã€‚
2. æå‡ºè‡ªé€‚åº”éš¾åº¦è¯¾ç¨‹å­¦ä¹ å’Œä¸“å®¶å¼•å¯¼è‡ªæˆ‘é‡æ„ä¸¤ç§æ–°ç­–ç•¥ï¼Œä»¥æå‡æ¨¡å‹çš„æ¨ç†èƒ½åŠ›å’ŒçŸ¥è¯†å¸æ”¶ã€‚
3. åœ¨ä½¿ç”¨Qwen2.5-7Bæ¨¡å‹çš„å®éªŒä¸­ï¼Œè¿™äº›ç­–ç•¥çš„ç»“åˆä½¿å¾—æ¨¡å‹åœ¨AIME24åŸºå‡†ä¸Šæå‡äº†10%ï¼Œåœ¨AIME25åŸºå‡†ä¸Šæå‡äº†16.6%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡åœ¨æ•°å­¦æ¨ç†ç­‰é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹åœ¨æŒç»­è§£å†³å¤æ‚é—®é¢˜æ–¹é¢ä»é¢ä¸´é‡å¤§æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸¤ç§æ–°ç­–ç•¥ä»¥å¢å¼ºå¤§å‹è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ã€‚é¦–å…ˆï¼Œè‡ªé€‚åº”éš¾åº¦è¯¾ç¨‹å­¦ä¹ ï¼ˆADCLï¼‰é€šè¿‡å®šæœŸé‡æ–°è¯„ä¼°å³å°†åˆ°æ¥çš„æ•°æ®æ‰¹æ¬¡çš„éš¾åº¦ï¼Œè§£å†³äº†æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯¹é—®é¢˜éš¾åº¦çš„åŠ¨æ€æ„ŸçŸ¥å˜åŒ–ã€‚å…¶æ¬¡ï¼Œä¸“å®¶å¼•å¯¼è‡ªæˆ‘é‡æ„ï¼ˆEGSRï¼‰é€šè¿‡å¼•å¯¼æ¨¡å‹åœ¨è‡ªèº«æ¦‚å¿µæ¡†æ¶å†…é‡æ„ä¸“å®¶è§£å†³æ–¹æ¡ˆï¼Œä¿ƒè¿›äº†æ›´æ·±å±‚æ¬¡çš„ç†è§£å’ŒçŸ¥è¯†å¸æ”¶ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œè¿™äº›äººç±»å¯å‘çš„ç­–ç•¥ååŒä½œç”¨æ˜¾è‘—æå‡äº†æ¨¡å‹æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚é—®é¢˜æ¨ç†ä¸­çš„ä¸ç¨³å®šæ€§ï¼Œç‰¹åˆ«æ˜¯æ¨¡å‹å¯¹é—®é¢˜éš¾åº¦çš„æ„ŸçŸ¥å˜åŒ–å¯¼è‡´çš„æ€§èƒ½æ³¢åŠ¨ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆåº”å¯¹è¿™ä¸€æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºè‡ªé€‚åº”éš¾åº¦è¯¾ç¨‹å­¦ä¹ ï¼ˆADCLï¼‰å’Œä¸“å®¶å¼•å¯¼è‡ªæˆ‘é‡æ„ï¼ˆEGSRï¼‰ä¸¤ç§ç­–ç•¥ï¼Œå‰è€…é€šè¿‡åŠ¨æ€è°ƒæ•´è®­ç»ƒéš¾åº¦ï¼Œåè€…é€šè¿‡å¼•å¯¼æ¨¡å‹åœ¨è‡ªèº«æ¡†æ¶å†…é‡æ„è§£å†³æ–¹æ¡ˆï¼Œä¿ƒè¿›æ·±å±‚ç†è§£ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šADCLæ¨¡å—è´Ÿè´£åŠ¨æ€è¯„ä¼°å’Œè°ƒæ•´é—®é¢˜éš¾åº¦ï¼ŒEGSRæ¨¡å—åˆ™é€šè¿‡å¼ºåŒ–å­¦ä¹ å¼•å¯¼æ¨¡å‹è¿›è¡Œè‡ªæˆ‘é‡æ„ï¼ŒäºŒè€…ååŒå·¥ä½œä»¥æå‡æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šADCLè§£å†³äº†æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯¹é—®é¢˜éš¾åº¦çš„åŠ¨æ€æ„ŸçŸ¥å˜åŒ–ï¼ŒEGSRåˆ™é€šè¿‡å¼•å¯¼è€Œéç›´æ¥æ¨¡ä»¿çš„æ–¹å¼ä¿ƒè¿›äº†æ›´æ·±å±‚æ¬¡çš„çŸ¥è¯†å¸æ”¶ï¼Œè¿™ä¸ç°æœ‰çš„å•ä¸€æ¨¡ä»¿å­¦ä¹ æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ADCLä¸­ï¼Œéš¾åº¦è¯„ä¼°é‡‡ç”¨äº†åŸºäºæ¨¡å‹å½“å‰èƒ½åŠ›çš„åŠ¨æ€è°ƒæ•´æœºåˆ¶ï¼›EGSRä¸­ï¼Œè®¾è®¡äº†ç‰¹å®šçš„å¥–åŠ±æœºåˆ¶ä»¥é¼“åŠ±æ¨¡å‹åœ¨è‡ªæˆ‘é‡æ„è¿‡ç¨‹ä¸­è¿›è¡Œæ¢ç´¢ä¸åˆ›æ–°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œç»“åˆè‡ªé€‚åº”éš¾åº¦è¯¾ç¨‹å­¦ä¹ å’Œä¸“å®¶å¼•å¯¼è‡ªæˆ‘é‡æ„åï¼Œæ¨¡å‹åœ¨AIME24åŸºå‡†ä¸Šæ€§èƒ½æå‡äº†10%ï¼Œåœ¨AIME25åŸºå‡†ä¸Šæå‡äº†16.6%ï¼Œæ˜¾è‘—ä¼˜äºæ ‡å‡†çš„Zero-RLåŸºçº¿ï¼Œå±•ç¤ºäº†è¿™ä¸¤ç§ç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²æŠ€æœ¯ã€æ™ºèƒ½è¾…å¯¼ç³»ç»Ÿå’Œå¤æ‚é—®é¢˜æ±‚è§£ç­‰ã€‚é€šè¿‡æå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥åœ¨æ›´å¹¿æ³›çš„åœºæ™¯ä¸­åº”ç”¨ï¼Œå¦‚è‡ªåŠ¨åŒ–é—®é¢˜è§£ç­”ã€ä¸ªæ€§åŒ–å­¦ä¹ å’Œæ™ºèƒ½åŠ©æ‰‹ç­‰ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Despite impressive progress in areas like mathematical reasoning, large language models still face significant challenges in consistently solving complex problems. Drawing inspiration from key human learning strategies, we propose two novel strategies to enhance the capability of large language models to solve these complex problems. First, Adaptive Difficulty Curriculum Learning (ADCL) is a novel curriculum learning strategy that tackles the Difficulty Shift phenomenon (i.e., a model's perception of problem difficulty dynamically changes during training) by periodically re-estimating difficulty within upcoming data batches to maintain alignment with the model's evolving capabilities. Second, Expert-Guided Self-Reformulation (EGSR) is a novel reinforcement learning strategy that bridges the gap between imitation learning and pure exploration by guiding models to reformulate expert solutions within their own conceptual framework, rather than relying on direct imitation, fostering deeper understanding and knowledge assimilation. Extensive experiments on challenging mathematical reasoning benchmarks, using Qwen2.5-7B as the base model, demonstrate that these human-inspired strategies synergistically and significantly enhance performance. Notably, their combined application improves performance over the standard Zero-RL baseline by 10% on the AIME24 benchmark and 16.6% on AIME25.

