---
layout: default
title: Ultrasound Report Generation with Multimodal Large Language Models for Standardized Texts
---

# Ultrasound Report Generation with Multimodal Large Language Models for Standardized Texts

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.08838" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.08838v2</a>
  <a href="https://arxiv.org/pdf/2505.08838.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.08838v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.08838v2', 'Ultrasound Report Generation with Multimodal Large Language Models for Standardized Texts')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Peixuan Ge, Tongkun Su, Faqin Lv, Baoliang Zhao, Peng Zhang, Chi Hong Wong, Liang Yao, Yu Sun, Zenan Wang, Pak Kin Wong, Ying Hu

**åˆ†ç±»**: eess.IV, cs.AI, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-13 (æ›´æ–°: 2025-05-19)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä»¥è§£å†³è¶…å£°æŠ¥å‘Šç”Ÿæˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¶…å£°æŠ¥å‘Šç”Ÿæˆ` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `æ ‡å‡†åŒ–æ–‡æœ¬` `å¤šè¯­è¨€æ”¯æŒ` `è§†è§‰å˜æ¢å™¨` `ä¸´åºŠåº”ç”¨` `æ–‡æœ¬ç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. è¶…å£°æŠ¥å‘Šç”Ÿæˆé¢ä¸´å›¾åƒå¤šæ ·æ€§å’Œæ“ä½œè€…ä¾èµ–æ€§ç­‰æŒ‘æˆ˜ï¼Œç¼ºä¹ä¸€è‡´çš„æ•°æ®é›†ä½¿å¾—è‡ªåŠ¨åŒ–å˜å¾—å›°éš¾ã€‚
2. æœ¬ç ”ç©¶æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶ï¼Œç»“åˆå¤šè¯­è¨€è®­ç»ƒå’Œæ ‡å‡†åŒ–æ–‡æœ¬ï¼Œæ”¯æŒå¤šå™¨å®˜çš„è¶…å£°æŠ¥å‘Šç”Ÿæˆã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œä¸KMVEæ–¹æ³•ç›¸æ¯”ï¼Œæœ¬æ–¹æ³•åœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šå‡æœ‰æ˜¾è‘—æå‡ï¼Œä¸”å‡å°‘äº†å†…å®¹é”™è¯¯ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¶…å£°æŠ¥å‘Šç”Ÿæˆæ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œä¸»è¦ç”±äºè¶…å£°å›¾åƒçš„å¤šæ ·æ€§ã€æ“ä½œè€…çš„ä¾èµ–æ€§ä»¥åŠå¯¹æ ‡å‡†åŒ–æ–‡æœ¬çš„éœ€æ±‚ã€‚ä¸Xå…‰å’ŒCTä¸åŒï¼Œè¶…å£°æˆåƒç¼ºä¹ä¸€è‡´çš„æ•°æ®é›†ï¼Œå¯¼è‡´è‡ªåŠ¨åŒ–å›°éš¾ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶ï¼Œç”¨äºå¤šå™¨å®˜å’Œå¤šè¯­è¨€çš„è¶…å£°æŠ¥å‘Šç”Ÿæˆï¼Œæ•´åˆäº†åŸºäºç‰‡æ®µçš„å¤šè¯­è¨€è®­ç»ƒï¼Œå¹¶åˆ©ç”¨è¶…å£°æŠ¥å‘Šçš„æ ‡å‡†åŒ–ç‰¹æ€§ã€‚é€šè¿‡å°†æ¨¡å—åŒ–æ–‡æœ¬ç‰‡æ®µä¸å¤šæ ·çš„æˆåƒæ•°æ®å¯¹é½ï¼Œå¹¶ç­–åˆ’åŒè¯­è‹±æ±‰æ•°æ®é›†ï¼Œè¯¥æ–¹æ³•åœ¨ä¸åŒå™¨å®˜å’Œè¯­è¨€ä¹‹é—´å®ç°äº†ä¸€è‡´ä¸”ä¸´åºŠå‡†ç¡®çš„æ–‡æœ¬ç”Ÿæˆã€‚é€šè¿‡é€‰æ‹©æ€§è§£å†»è§†è§‰å˜æ¢å™¨ï¼ˆViTï¼‰è¿›è¡Œå¾®è°ƒï¼Œè¿›ä¸€æ­¥æ”¹å–„äº†æ–‡æœ¬ä¸å›¾åƒçš„å¯¹é½ã€‚ä¸ä¹‹å‰çš„æœ€å…ˆè¿›KMVEæ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨BLEUåˆ†æ•°ä¸Šç›¸å¯¹æå‡çº¦2%ï¼Œåœ¨ROUGE-Lä¸Šçº¦æå‡3%ï¼Œåœ¨CIDErä¸Šçº¦æå‡15%ï¼ŒåŒæ—¶æ˜¾è‘—å‡å°‘äº†ç¼ºå¤±æˆ–é”™è¯¯å†…å®¹ç­‰é”™è¯¯ã€‚é€šè¿‡å°†å¤šå™¨å®˜å’Œå¤šè¯­è¨€æŠ¥å‘Šç”Ÿæˆç»Ÿä¸€ä¸ºä¸€ä¸ªå¯æ‰©å±•çš„æ¡†æ¶ï¼Œæœ¬ç ”ç©¶å±•ç¤ºäº†åœ¨å®é™…ä¸´åºŠå·¥ä½œæµç¨‹ä¸­çš„å¼ºå¤§æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³è¶…å£°æŠ¥å‘Šç”Ÿæˆä¸­çš„å¤šæ ·æ€§å’Œæ ‡å‡†åŒ–é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é¢ä¸´å›¾åƒå˜å¼‚æ€§å¤§ã€æ“ä½œè€…ä¾èµ–æ€§å¼ºä»¥åŠç¼ºä¹ä¸€è‡´æ•°æ®é›†çš„ç—›ç‚¹ï¼Œå¯¼è‡´è‡ªåŠ¨åŒ–ç”Ÿæˆå›°éš¾ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ•´åˆå¤šè¯­è¨€å’Œå¤šå™¨å®˜çš„è®­ç»ƒï¼Œåˆ©ç”¨æ¨¡å—åŒ–æ–‡æœ¬ç‰‡æ®µä¸æˆåƒæ•°æ®å¯¹é½ï¼Œä»è€Œå®ç°æ ‡å‡†åŒ–çš„è¶…å£°æŠ¥å‘Šç”Ÿæˆã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å—åŒ–æ–‡æœ¬ç‰‡æ®µç”Ÿæˆã€å›¾åƒä¸æ–‡æœ¬å¯¹é½åŠå¤šè¯­è¨€æ”¯æŒç­‰ä¸»è¦æ¨¡å—ã€‚é€šè¿‡æ„å»ºåŒè¯­æ•°æ®é›†ï¼Œå¢å¼ºäº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„ä¸»è¦åˆ›æ–°åœ¨äºå°†å¤šå™¨å®˜å’Œå¤šè¯­è¨€æŠ¥å‘Šç”Ÿæˆç»Ÿä¸€ä¸ºä¸€ä¸ªæ¡†æ¶ï¼Œæ˜¾è‘—æå‡äº†æ–‡æœ¬ç”Ÿæˆçš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ï¼ŒåŒºåˆ«äºç°æœ‰æ–¹æ³•çš„ç‰‡æ®µåŒ–å¤„ç†ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨é€‰æ‹©æ€§è§£å†»çš„æ–¹å¼å¯¹è§†è§‰å˜æ¢å™¨ï¼ˆViTï¼‰è¿›è¡Œå¾®è°ƒï¼Œä¼˜åŒ–äº†æ–‡æœ¬ä¸å›¾åƒçš„å¯¹é½æ•ˆæœï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸Šæ³¨é‡ç”Ÿæˆæ–‡æœ¬çš„æµç•…æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä¸KMVEæ–¹æ³•ç›¸æ¯”ï¼Œæœ¬ç ”ç©¶åœ¨BLEUåˆ†æ•°ä¸Šæå‡çº¦2%ï¼ŒROUGE-Læå‡çº¦3%ï¼ŒCIDEræå‡çº¦15%ã€‚åŒæ—¶ï¼Œæ˜¾è‘—å‡å°‘äº†æŠ¥å‘Šç”Ÿæˆä¸­çš„ç¼ºå¤±æˆ–é”™è¯¯å†…å®¹ï¼Œå±•ç¤ºäº†æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œå¯é æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŒ»ç–—å½±åƒå­¦ã€ä¸´åºŠæŠ¥å‘Šç”ŸæˆåŠäººå·¥æ™ºèƒ½è¾…åŠ©è¯Šæ–­ç­‰ã€‚é€šè¿‡å®ç°æ ‡å‡†åŒ–çš„è¶…å£°æŠ¥å‘Šç”Ÿæˆï¼Œèƒ½å¤Ÿæé«˜ä¸´åºŠå·¥ä½œæµç¨‹çš„æ•ˆç‡ï¼Œå‡å°‘äººä¸ºé”™è¯¯ï¼Œæå‡åŒ»ç–—æœåŠ¡è´¨é‡ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Ultrasound (US) report generation is a challenging task due to the variability of US images, operator dependence, and the need for standardized text. Unlike X-ray and CT, US imaging lacks consistent datasets, making automation difficult. In this study, we propose a unified framework for multi-organ and multilingual US report generation, integrating fragment-based multilingual training and leveraging the standardized nature of US reports. By aligning modular text fragments with diverse imaging data and curating a bilingual English-Chinese dataset, the method achieves consistent and clinically accurate text generation across organ sites and languages. Fine-tuning with selective unfreezing of the vision transformer (ViT) further improves text-image alignment. Compared to the previous state-of-the-art KMVE method, our approach achieves relative gains of about 2\% in BLEU scores, approximately 3\% in ROUGE-L, and about 15\% in CIDEr, while significantly reducing errors such as missing or incorrect content. By unifying multi-organ and multi-language report generation into a single, scalable framework, this work demonstrates strong potential for real-world clinical workflows.

