---
layout: default
title: Deep reinforcement learning-based longitudinal control strategy for automated vehicles at signalised intersections
---

# Deep reinforcement learning-based longitudinal control strategy for automated vehicles at signalised intersections

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.08896" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.08896v1</a>
  <a href="https://arxiv.org/pdf/2505.08896.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.08896v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.08896v1', 'Deep reinforcement learning-based longitudinal control strategy for automated vehicles at signalised intersections')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Pankaj Kumar, Aditya Mishra, Pranamesh Chakraborty, Subrahmanya Swamy Peruru

**ÂàÜÁ±ª**: cs.AI, cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-13

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éÊ∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†ÁöÑËá™Âä®È©æÈ©∂ËΩ¶ËæÜ‰ø°Âè∑‰∫§ÂèâÂè£Á∫µÂêëÊéßÂà∂Á≠ñÁï•**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Ê∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†` `Ëá™Âä®È©æÈ©∂` `Á∫µÂêëÊéßÂà∂` `‰ø°Âè∑‰∫§ÂèâÂè£` `‰∫§ÈÄöÂÆâÂÖ®` `ÊïàÁéá‰ºòÂåñ` `ÂÜ≥Á≠ñÁ≠ñÁï•`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑËá™Âä®È©æÈ©∂ËΩ¶ËæÜÂú®‰ø°Âè∑‰∫§ÂèâÂè£ÁöÑÊéßÂà∂Á≠ñÁï•Èù¢‰∏¥Â§çÊùÇÁöÑÂÜ≥Á≠ñÊåëÊàòÔºåÂ∞§ÂÖ∂ÊòØÂú®ÈªÑÁÅØÂíå‰∫§ÈÄöÊµÅÂèòÂåñÊó∂„ÄÇ
2. Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÊ∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†ÁöÑÁ∫µÂêëÊéßÂà∂Á≠ñÁï•ÔºåÈÄöËøáËÆæËÆ°ÁªºÂêàÂ•ñÂä±ÂáΩÊï∞Êù•‰ºòÂåñËΩ¶ËæÜÁöÑÂä†ÈÄüÂíåÂáèÈÄüË°å‰∏∫„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊâÄÊèêÊ®°ÂûãÂú®ÊïàÁéáÂíåËàíÈÄÇÊÄßÊñπÈù¢‰ºò‰∫é‰∫∫Á±ªÈ©æÈ©∂ËΩ¶ËæÜÔºå‰∏îÂú®Â§öÁßçÂÆâÂÖ®ÂÖ≥ÈîÆÂú∫ÊôØ‰∏ãË°®Áé∞Âá∫Ëâ≤„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÂºÄÂèëËá™Âä®È©æÈ©∂ËΩ¶ËæÜÂú®‰ø°Âè∑‰∫§ÂèâÂè£ÁöÑÊéßÂà∂Á≠ñÁï•ÊòØ‰∏ÄÈ°πÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑ‰ªªÂä°ÔºåÂõ†‰∏∫ÂÖ∂ÂÜ≥Á≠ñËøáÁ®ãÂ§çÊùÇ„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÊ∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†ÔºàDRLÔºâÁöÑÁ∫µÂêëÊéßÂà∂Á≠ñÁï•ÔºåËÆæËÆ°‰∫ÜÁªºÂêàÂ•ñÂä±ÂáΩÊï∞ÔºåÈáçÁÇπÂÖ≥Ê≥®Âü∫‰∫éË∑ùÁ¶ªÁöÑÊïàÁéáÂ•ñÂä±„ÄÅÈªÑÁÅØÂÜ≥Á≠ñÊ†áÂáÜ‰ª•Âèä‰∏çÂØπÁß∞Âä†ÈÄü/ÂáèÈÄüÂìçÂ∫îÔºåÂêåÊó∂ËÄÉËôë‰º†ÁªüÁöÑÂÆâÂÖ®ÂíåËàíÈÄÇÊÄßÊ†áÂáÜ„ÄÇËØ•Â•ñÂä±ÂáΩÊï∞‰∏éÊ∑±Â∫¶Á°ÆÂÆöÊÄßÁ≠ñÁï•Ê¢ØÂ∫¶ÔºàDDPGÔºâÂíåËΩØÊºîÂëòËØÑËÆ∫ÂÆ∂ÔºàSACÔºâ‰∏§ÁßçÊµÅË°åÁöÑDRLÁÆóÊ≥ïÁªìÂêàÔºåËÉΩÂ§üÂ§ÑÁêÜÂä†ÈÄü/ÂáèÈÄüÁöÑËøûÁª≠Âä®‰ΩúÁ©∫Èó¥„ÄÇÈÄöËøáÁúüÂÆû‰∏ñÁïåÁöÑÈ¢ÜËΩ¶ËΩ®ËøπÂíå‰ΩøÁî®Â••ÊÅ©ÊñØÂù¶-‰πå‰º¶Ë¥ùÂÖãËøáÁ®ãÁîüÊàêÁöÑÊ®°ÊãüËΩ®ËøπËøõË°åËÆ≠ÁªÉÔºåÁªìÊûúË°®ÊòéÔºåRLÊ®°ÂûãÂú®‰øùÊåÅÂÆâÂÖ®ÁöÑÂêåÊó∂ÔºåÊàêÂäüÂÆûÁé∞‰∫ÜËæÉ‰ΩéÁöÑË∑ùÁ¶ªÈó¥ÈöîÂíåËæÉÂ∞èÁöÑÂÜ≤ÂáªÂäõ„ÄÇËøõ‰∏ÄÊ≠•ËØÑ‰º∞ÊòæÁ§∫ÔºåDDPGÊ®°ÂûãÂú®ÂÖ≥ÈîÆÂú∫ÊôØ‰∏ãË°®Áé∞Âá∫Êõ¥Âπ≥ÊªëÁöÑÂä®‰ΩúÁâπÂæÅ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Ëá™Âä®È©æÈ©∂ËΩ¶ËæÜÂú®‰ø°Âè∑‰∫§ÂèâÂè£ÁöÑÁ∫µÂêëÊéßÂà∂ÈóÆÈ¢òÔºåÁé∞ÊúâÊñπÊ≥ïÂú®Â§çÊùÇÂÜ≥Á≠ñÂíåÂä®ÊÄÅ‰∫§ÈÄöÁéØÂ¢É‰∏ãË°®Áé∞‰∏çË∂≥ÔºåÈöæ‰ª•ÂÖºÈ°æÂÆâÂÖ®‰∏éÊïàÁéá„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊèêÂá∫Âü∫‰∫éÊ∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†ÁöÑÊéßÂà∂Á≠ñÁï•ÔºåÈÄöËøáËÆæËÆ°ÁªºÂêàÂ•ñÂä±ÂáΩÊï∞ÔºåËÄÉËôëÂ§öÁßçÂõ†Á¥†ÔºàÂ¶ÇË∑ùÁ¶ªÈó¥Èöî„ÄÅÈªÑÁÅØÂÜ≥Á≠ñÁ≠âÔºâÔºå‰ª•‰ºòÂåñËΩ¶ËæÜÁöÑÂä†ÈÄüÂíåÂáèÈÄüË°å‰∏∫„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨Êï∞ÊçÆÊî∂ÈõÜ„ÄÅÊ®°ÂûãËÆ≠ÁªÉÂíåÊÄßËÉΩËØÑ‰º∞‰∏â‰∏™‰∏ªË¶ÅÈò∂ÊÆµ„ÄÇÊï∞ÊçÆÊî∂ÈõÜÈò∂ÊÆµÁªìÂêàÁúüÂÆûÂíåÊ®°ÊãüÁöÑËΩ¶ËæÜËΩ®ËøπÔºåËÆ≠ÁªÉÈò∂ÊÆµ‰ΩøÁî®DDPGÂíåSACÁÆóÊ≥ïËøõË°åÊ®°ÂûãËÆ≠ÁªÉÔºåËØÑ‰º∞Èò∂ÊÆµÈÄöËøáCDFÂõæËøõË°åÊÄßËÉΩÊØîËæÉ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞Âú®‰∫éËÆæËÆ°‰∫ÜÁªºÂêàÂ•ñÂä±ÂáΩÊï∞ÔºåÁâπÂà´ÂÖ≥Ê≥®ÈªÑÁÅØÂÜ≥Á≠ñÂíå‰∏çÂØπÁß∞Âä†ÈÄü/ÂáèÈÄüÂìçÂ∫îÔºåËøôÂú®Áé∞ÊúâÊñπÊ≥ï‰∏≠ËæÉÂ∞ëËÄÉËôë„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Â•ñÂä±ÂáΩÊï∞‰∏≠ÔºåËÆæÁΩÆ‰∫ÜÂü∫‰∫éË∑ùÁ¶ªÁöÑÊïàÁéáÂ•ñÂä±„ÄÅÈªÑÁÅØÂÜ≥Á≠ñÊ†áÂáÜÁ≠âÔºå‰ΩøÁî®DDPGÂíåSACÁÆóÊ≥ïÂ§ÑÁêÜËøûÁª≠Âä®‰ΩúÁ©∫Èó¥ÔºåÁ°Æ‰øùÊ®°ÂûãÂú®Â§çÊùÇÂú∫ÊôØ‰∏ãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇÂÖ∑‰ΩìÂèÇÊï∞ÂíåÁΩëÁªúÁªìÊûÑÁªÜËäÇÂú®ÂÆûÈ™åÈÉ®ÂàÜËøõË°å‰∫ÜËØ¶ÁªÜÊèèËø∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåÊâÄÊèêDRLÊ®°ÂûãÂú®‰øùÊåÅÂÆâÂÖ®ÁöÑÂâçÊèê‰∏ãÔºåÊàêÂäüÂÆûÁé∞‰∫ÜËæÉ‰ΩéÁöÑË∑ùÁ¶ªÈó¥ÈöîÂíåËæÉÂ∞èÁöÑÂÜ≤ÂáªÂäõÔºåÁõ∏ËæÉ‰∫é‰∫∫Á±ªÈ©æÈ©∂ËΩ¶ËæÜÔºåÊïàÁéáÊèêÂçáÊòæËëó„ÄÇDDPGÊ®°ÂûãÂú®ÂÖ≥ÈîÆÂú∫ÊôØ‰∏ãË°®Áé∞Âá∫Êõ¥Âπ≥ÊªëÁöÑÂä®‰ΩúÁâπÂæÅÔºåÈ™åËØÅ‰∫ÜÂÖ∂Âú®Â§çÊùÇ‰∫§ÈÄöÁéØÂ¢É‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Ëá™Âä®È©æÈ©∂Ê±ΩËΩ¶ÁöÑÊéßÂà∂Á≥ªÁªü„ÄÅÊô∫ËÉΩ‰∫§ÈÄöÁÆ°ÁêÜÂíåÂüéÂ∏Ç‰∫§ÈÄö‰ºòÂåñ„ÄÇÈÄöËøáÊèêÈ´òËΩ¶ËæÜÂú®‰ø°Âè∑‰∫§ÂèâÂè£ÁöÑÂÜ≥Á≠ñËÉΩÂäõÔºåËÉΩÂ§üÊúâÊïàÊèêÂçá‰∫§ÈÄöÂÆâÂÖ®„ÄÅÊïàÁéáÂíåÈ©æÈ©∂ËàíÈÄÇÊÄßÔºåÂØπÊú™Êù•Êô∫ËÉΩ‰∫§ÈÄöÁ≥ªÁªüÁöÑÂèëÂ±ïÂÖ∑ÊúâÈáçË¶ÅÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Developing an autonomous vehicle control strategy for signalised intersections (SI) is one of the challenging tasks due to its inherently complex decision-making process. This study proposes a Deep Reinforcement Learning (DRL) based longitudinal vehicle control strategy at SI. A comprehensive reward function has been formulated with a particular focus on (i) distance headway-based efficiency reward, (ii) decision-making criteria during amber light, and (iii) asymmetric acceleration/ deceleration response, along with the traditional safety and comfort criteria. This reward function has been incorporated with two popular DRL algorithms, Deep Deterministic Policy Gradient (DDPG) and Soft-Actor Critic (SAC), which can handle the continuous action space of acceleration/deceleration. The proposed models have been trained on the combination of real-world leader vehicle (LV) trajectories and simulated trajectories generated using the Ornstein-Uhlenbeck (OU) process. The overall performance of the proposed models has been tested using Cumulative Distribution Function (CDF) plots and compared with the real-world trajectory data. The results show that the RL models successfully maintain lower distance headway (i.e., higher efficiency) and jerk compared to human-driven vehicles without compromising safety. Further, to assess the robustness of the proposed models, we evaluated the model performance on diverse safety-critical scenarios, in terms of car-following and traffic signal compliance. Both DDPG and SAC models successfully handled the critical scenarios, while the DDPG model showed smoother action profiles compared to the SAC model. Overall, the results confirm that DRL-based longitudinal vehicle control strategy at SI can help to improve traffic safety, efficiency, and comfort.

