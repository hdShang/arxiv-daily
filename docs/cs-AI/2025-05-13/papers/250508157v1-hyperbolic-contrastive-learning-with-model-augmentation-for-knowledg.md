---
layout: default
title: Hyperbolic Contrastive Learning with Model-augmentation for Knowledge-aware Recommendation
---

# Hyperbolic Contrastive Learning with Model-augmentation for Knowledge-aware Recommendation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.08157" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.08157v1</a>
  <a href="https://arxiv.org/pdf/2505.08157.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.08157v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.08157v1', 'Hyperbolic Contrastive Learning with Model-augmentation for Knowledge-aware Recommendation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shengyin Sun, Chen Ma

**åˆ†ç±»**: cs.IR, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-13

**å¤‡æ³¨**: 18 pages

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè¶…æ›²ç‡å¯¹æ¯”å­¦ä¹ ä¸æ¨¡å‹å¢å¼ºä»¥è§£å†³çŸ¥è¯†æ„ŸçŸ¥æ¨èé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `çŸ¥è¯†æ„ŸçŸ¥æ¨è` `å›¾ç¥ç»ç½‘ç»œ` `å¯¹æ¯”å­¦ä¹ ` `è¶…æ›²ç‡å­¦ä¹ ` `æ¨¡å‹å¢å¼º` `ç”¨æˆ·åå¥½` `å±‚æ¬¡ç»“æ„` `æ´›ä¼¦å…¹èšåˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¯¹æ¯”å­¦ä¹ æ–¹æ³•éš¾ä»¥æœ‰æ•ˆæ•æ‰ç”¨æˆ·-ç‰©å“äºŒåˆ†å›¾å’ŒçŸ¥è¯†å›¾çš„å±‚æ¬¡ç»“æ„ï¼Œå¯¼è‡´æ¨èæ•ˆæœä¸ä½³ã€‚
2. æœ¬æ–‡æå‡ºè¶…æ›²ç‡å¯¹æ¯”å­¦ä¹ ä¸æ¨¡å‹å¢å¼ºï¼Œè®¾è®¡äº†æ´›ä¼¦å…¹çŸ¥è¯†èšåˆæœºåˆ¶ä»¥æå‡ç”¨æˆ·å’Œç‰©å“çš„è¡¨ç¤ºèƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•åœ¨æ¨èæ€§èƒ½ä¸Šä¼˜äºç°æœ‰åŸºçº¿ï¼Œæœ€å¤§æå‡è¾¾åˆ°11.03%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºäºå›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰å’Œå¯¹æ¯”å­¦ä¹ çš„çŸ¥è¯†æ„ŸçŸ¥æ¨èæ–¹æ³•å·²æˆä¸ºä¸»æµã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•åœ¨æ•æ‰ç”¨æˆ·-ç‰©å“äºŒåˆ†å›¾å’ŒçŸ¥è¯†å›¾ä¸­çš„å±‚æ¬¡ç»“æ„æ–¹é¢å­˜åœ¨å›°éš¾ã€‚æ­¤å¤–ï¼Œå¸¸é€šè¿‡æ‰°åŠ¨å›¾ç»“æ„ç”Ÿæˆæ­£æ ·æœ¬ï¼Œå¯èƒ½å¯¼è‡´ç”¨æˆ·åå¥½å­¦ä¹ çš„åç§»ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†è¶…æ›²ç‡å¯¹æ¯”å­¦ä¹ ä¸æ¨¡å‹å¢å¼ºçš„æ–¹æ³•ã€‚é¦–å…ˆï¼Œè®¾è®¡äº†ä¸€ç§æ–°é¢–çš„æ´›ä¼¦å…¹çŸ¥è¯†èšåˆæœºåˆ¶ï¼Œä»¥æ›´æœ‰æ•ˆåœ°è¡¨ç¤ºç”¨æˆ·å’Œç‰©å“ã€‚ç„¶åï¼Œæå‡ºäº†ä¸‰ç§æ¨¡å‹çº§å¢å¼ºæŠ€æœ¯ï¼Œé¿å…äº†å¢å¼ºæ­£æ ·æœ¬å¯¹ä¹‹é—´çš„åå¥½åç§»ã€‚æœ€åï¼Œé€šè¿‡å¤§é‡å®éªŒéªŒè¯äº†æ‰€ææ–¹æ³•ç›¸è¾ƒäºç°æœ‰åŸºçº¿çš„ä¼˜è¶Šæ€§ï¼Œæœ€å¤§æå‡è¾¾åˆ°11.03%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰çŸ¥è¯†æ„ŸçŸ¥æ¨èæ–¹æ³•åœ¨æ•æ‰ç”¨æˆ·-ç‰©å“äºŒåˆ†å›¾å’ŒçŸ¥è¯†å›¾å±‚æ¬¡ç»“æ„æ–¹é¢çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯é€šè¿‡æ‰°åŠ¨å›¾ç»“æ„ç”Ÿæˆæ­£æ ·æœ¬æ‰€å¯¼è‡´çš„ç”¨æˆ·åå¥½å­¦ä¹ åç§»é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºè¶…æ›²ç‡å¯¹æ¯”å­¦ä¹ ä¸æ¨¡å‹å¢å¼ºï¼Œåˆ©ç”¨æ´›ä¼¦å…¹çŸ¥è¯†èšåˆæœºåˆ¶æ¥æ›´æœ‰æ•ˆåœ°è¡¨ç¤ºç”¨æˆ·å’Œç‰©å“ï¼ŒåŒæ—¶é€šè¿‡æ¨¡å‹çº§å¢å¼ºæŠ€æœ¯é¿å…å¢å¼ºæ­£æ ·æœ¬å¯¹ä¹‹é—´çš„åå¥½åç§»ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯æ´›ä¼¦å…¹çŸ¥è¯†èšåˆæœºåˆ¶ï¼Œç”¨äºç”Ÿæˆç”¨æˆ·å’Œç‰©å“çš„æœ‰æ•ˆè¡¨ç¤ºï¼›å…¶æ¬¡æ˜¯ä¸‰ç§æ¨¡å‹çº§å¢å¼ºæŠ€æœ¯ï¼Œå¢å¼ºå¯¹æ¯”å­¦ä¹ è¿‡ç¨‹ï¼›æœ€åæ˜¯å¯¹æ¯”å­¦ä¹ çš„æŸå¤±è®¡ç®—å’Œä¼˜åŒ–è¿‡ç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥äº†æ´›ä¼¦å…¹çŸ¥è¯†èšåˆæœºåˆ¶å’Œæ¨¡å‹çº§å¢å¼ºæŠ€æœ¯ï¼Œè¿™ä¸ä¼ ç»Ÿçš„ç»“æ„çº§å¢å¼ºæ–¹æ³•ï¼ˆå¦‚è¾¹ç¼˜ä¸¢å¼ƒï¼‰æœ¬è´¨ä¸Šä¸åŒï¼Œèƒ½å¤Ÿæ›´å¥½åœ°ä¿æŒç”¨æˆ·åå¥½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†é€‚åº”æ€§å­¦ä¹ ç‡å’Œæ­£åˆ™åŒ–æŠ€æœ¯ï¼›æŸå¤±å‡½æ•°è®¾è®¡ä¸ºå¯¹æ¯”æŸå¤±ï¼Œç¡®ä¿æ­£æ ·æœ¬å¯¹çš„ç›¸ä¼¼æ€§ï¼›ç½‘ç»œç»“æ„ä¸Šï¼Œç»“åˆäº†GNNå’Œè¶…æ›²ç‡ç©ºé—´çš„ç‰¹æ€§ï¼Œä»¥å¢å¼ºè¡¨ç¤ºèƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå‡ä¼˜äºç°æœ‰åŸºçº¿ï¼Œæœ€å¤§æå‡è¾¾åˆ°11.03%ã€‚è¿™ä¸€æ˜¾è‘—çš„æ€§èƒ½æå‡éªŒè¯äº†è¶…æ›²ç‡å¯¹æ¯”å­¦ä¹ ä¸æ¨¡å‹å¢å¼ºçš„æœ‰æ•ˆæ€§ï¼Œå±•ç¤ºäº†å…¶åœ¨çŸ¥è¯†æ„ŸçŸ¥æ¨èä¸­çš„åº”ç”¨æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ä¸ªæ€§åŒ–æ¨èç³»ç»Ÿã€ç¤¾äº¤ç½‘ç»œåˆ†æå’ŒçŸ¥è¯†å›¾è°±æ„å»ºç­‰ã€‚é€šè¿‡æå‡æ¨èç³»ç»Ÿçš„å‡†ç¡®æ€§å’Œç”¨æˆ·æ»¡æ„åº¦ï¼Œèƒ½å¤Ÿä¸ºå•†ä¸šå¹³å°æä¾›æ›´ä¼˜è´¨çš„ç”¨æˆ·ä½“éªŒï¼Œæœªæ¥å¯èƒ½åœ¨ç”µå•†ã€å†…å®¹æ¨èç­‰å¤šä¸ªé¢†åŸŸäº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Benefiting from the effectiveness of graph neural networks (GNNs) and contrastive learning, GNN-based contrastive learning has become mainstream for knowledge-aware recommendation. However, most existing contrastive learning-based methods have difficulties in effectively capturing the underlying hierarchical structure within user-item bipartite graphs and knowledge graphs. Moreover, they commonly generate positive samples for contrastive learning by perturbing the graph structure, which may lead to a shift in user preference learning. To overcome these limitations, we propose hyperbolic contrastive learning with model-augmentation for knowledge-aware recommendation. To capture the intrinsic hierarchical graph structures, we first design a novel Lorentzian knowledge aggregation mechanism, which enables more effective representations of users and items. Then, we propose three model-level augmentation techniques to assist Hyperbolic contrastive learning. Different from the classical structure-level augmentation (e.g., edge dropping), the proposed model-augmentations can avoid preference shifts between the augmented positive pair. Finally, we conduct extensive experiments to demonstrate the superiority (maximum improvement of $11.03\%$) of proposed methods over existing baselines.

