---
layout: default
title: Strategy-Augmented Planning for Large Language Models via Opponent Exploitation
---

# Strategy-Augmented Planning for Large Language Models via Opponent Exploitation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.08459" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.08459v2</a>
  <a href="https://arxiv.org/pdf/2505.08459.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.08459v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.08459v2', 'Strategy-Augmented Planning for Large Language Models via Opponent Exploitation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shuai Xu, Sijia Cui, Yanna Wang, Bo Xu, Qi Wang

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-13 (æ›´æ–°: 2025-06-01)

**å¤‡æ³¨**: Accepted to IJCNN 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/hsushuai/SAP)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç­–ç•¥å¢å¼ºè§„åˆ’ä»¥è§£å†³å¯¹æ‰‹å»ºæ¨¡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¯¹æ‰‹å»ºæ¨¡` `å¤§å‹è¯­è¨€æ¨¡å‹` `ç­–ç•¥å¢å¼º` `å¼ºåŒ–å­¦ä¹ ` `å¾®å‹å®æ—¶ç­–ç•¥æ¸¸æˆ` `ç­–ç•¥è¯„ä¼°ç½‘ç»œ` `å†³ç­–ç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¯¹æ‰‹å»ºæ¨¡æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨ç¼ºä¹é¢†åŸŸä¸“ä¸šçŸ¥è¯†æ—¶ï¼ŒLLMsçš„å†³ç­–èƒ½åŠ›å—åˆ°é™åˆ¶ã€‚
2. æœ¬æ–‡æå‡ºçš„ç­–ç•¥å¢å¼ºè§„åˆ’ï¼ˆSAPï¼‰æ¡†æ¶é€šè¿‡ç­–ç•¥è¯„ä¼°ç½‘ç»œï¼ˆSENï¼‰æ¥å¢å¼ºå¯¹æ‰‹åˆ©ç”¨èƒ½åŠ›ï¼Œåˆ†ä¸ºç¦»çº¿å’Œåœ¨çº¿ä¸¤ä¸ªé˜¶æ®µã€‚
3. åœ¨å¾®å‹å®æ—¶ç­–ç•¥æ¸¸æˆç¯å¢ƒä¸­ï¼ŒSAPç›¸è¾ƒäºåŸºçº¿æ–¹æ³•å®ç°äº†85.35%çš„æ€§èƒ½æå‡ï¼Œå±•ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ‰æ•ˆå»ºæ¨¡å’Œåˆ©ç”¨å¯¹æ‰‹ä¸€ç›´æ˜¯å¯¹æŠ—æ€§é¢†åŸŸä¸­çš„é•¿æœŸæŒ‘æˆ˜ã€‚è¿‘å¹´æ¥ï¼ŒåŸºäºå¤§è§„æ¨¡æ–‡æœ¬æ•°æ®è®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä¸€èˆ¬ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä¸ºå¯¹æ‰‹å»ºæ¨¡å¼€è¾Ÿäº†æ–°çš„ç ”ç©¶æ–¹å‘ã€‚ç°æœ‰ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨ç›´æ¥ä½¿ç”¨LLMsæ ¹æ®åŒ…å«å¯¹æ‰‹æè¿°çš„è¯¦ç»†æç¤ºä¸Šä¸‹æ–‡ç”Ÿæˆå†³ç­–ï¼Œä½†è¿™äº›æ–¹æ³•åœ¨LLMsç¼ºä¹è¶³å¤Ÿé¢†åŸŸä¸“ä¸šçŸ¥è¯†çš„æƒ…å†µä¸‹å—åˆ°é™åˆ¶ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§ä¸¤é˜¶æ®µçš„ç­–ç•¥å¢å¼ºè§„åˆ’ï¼ˆSAPï¼‰æ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥ç­–ç•¥è¯„ä¼°ç½‘ç»œï¼ˆSENï¼‰æ˜¾è‘—å¢å¼ºäº†åŸºäºLLMçš„ä»£ç†çš„å¯¹æ‰‹åˆ©ç”¨èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSAPåœ¨å¾®å‹å®æ—¶ç­–ç•¥æ¸¸æˆç¯å¢ƒä¸­ç›¸è¾ƒäºåŸºçº¿æ–¹æ³•å®ç°äº†85.35%çš„æ€§èƒ½æå‡ï¼Œå¹¶ä¸æœ€å…ˆè¿›çš„åŸºäºè§„åˆ™çš„AIçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ç›¸åŒ¹é…ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¯¹æ‰‹å»ºæ¨¡å’Œåˆ©ç”¨ä¸­çš„æ•ˆç‡é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¯¹æ‰‹ç­–ç•¥ä¸æ˜ç¡®æˆ–ç¼ºä¹é¢†åŸŸçŸ¥è¯†æ—¶è¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºçš„ç­–ç•¥å¢å¼ºè§„åˆ’ï¼ˆSAPï¼‰æ¡†æ¶é€šè¿‡æ„å»ºç­–ç•¥ç©ºé—´å’Œè®­ç»ƒç­–ç•¥è¯„ä¼°ç½‘ç»œï¼ˆSENï¼‰ï¼Œåœ¨ç¦»çº¿é˜¶æ®µæ”¶é›†ç­–ç•¥-ç»“æœå¯¹æ•°æ®ï¼Œåœ¨çº¿é˜¶æ®µåŠ¨æ€è¯†åˆ«å¹¶åˆ©ç”¨å¯¹æ‰‹ç­–ç•¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSAPæ¡†æ¶åˆ†ä¸ºä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šç¦»çº¿é˜¶æ®µæ„å»ºç­–ç•¥ç©ºé—´å¹¶è®­ç»ƒSENï¼Œåœ¨çº¿é˜¶æ®µé€šè¿‡SENè¯†åˆ«å¯¹æ‰‹ç­–ç•¥å¹¶ç”Ÿæˆæœ€ä½³å“åº”ç­–ç•¥ï¼Œæœ€ç»ˆé€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æç¤ºå°†ç­–ç•¥è½¬åŒ–ä¸ºè¡ŒåŠ¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†ç­–ç•¥è¯„ä¼°ç½‘ç»œï¼ˆSENï¼‰ï¼Œä½¿å¾—LLMèƒ½å¤Ÿåœ¨ç¼ºä¹é¢†åŸŸçŸ¥è¯†çš„æƒ…å†µä¸‹æœ‰æ•ˆè¯†åˆ«å’Œåˆ©ç”¨å¯¹æ‰‹ç­–ç•¥ï¼Œæ˜¾è‘—æå‡äº†å¯¹æ‰‹åˆ©ç”¨èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç¦»çº¿é˜¶æ®µï¼Œæ„å»ºæ˜ç¡®çš„ç­–ç•¥ç©ºé—´å¹¶æ”¶é›†æ•°æ®ç”¨äºè®­ç»ƒSENï¼›åœ¨çº¿é˜¶æ®µåˆ™é€šè¿‡è´ªå©ªæœç´¢ç­–ç•¥æ¥è¯†åˆ«å¯¹æ‰‹ç­–ç•¥ï¼Œç¡®ä¿ç”Ÿæˆçš„å“åº”ç­–ç•¥å…·æœ‰é«˜æ•ˆæ€§å’Œé€‚åº”æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSAPåœ¨å¾®å‹å®æ—¶ç­–ç•¥æ¸¸æˆç¯å¢ƒä¸­å®ç°äº†85.35%çš„æ€§èƒ½æå‡ï¼Œå±•ç°å‡ºå¯¹æ–°é¢–æœªè§ç­–ç•¥çš„å¼ºå¤§æ³›åŒ–èƒ½åŠ›ï¼Œä¸”ä¸æœ€å…ˆè¿›çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ç«äº‰åŠ›ç›¸å½“ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ¸¸æˆAIã€å¯¹æŠ—æ€§æœºå™¨äººä»¥åŠå…¶ä»–éœ€è¦å¯¹æ‰‹å»ºæ¨¡çš„æ™ºèƒ½ç³»ç»Ÿã€‚é€šè¿‡æå‡å¯¹æ‰‹åˆ©ç”¨èƒ½åŠ›ï¼ŒSAPæ¡†æ¶èƒ½å¤Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­å®ç°æ›´é«˜æ•ˆçš„å†³ç­–ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Efficiently modeling and exploiting opponents is a long-standing challenge in adversarial domains. Large Language Models (LLMs) trained on extensive textual data have recently demonstrated outstanding performance in general tasks, introducing new research directions for opponent modeling. Some studies primarily focus on directly using LLMs to generate decisions based on the elaborate prompt context that incorporates opponent descriptions, while these approaches are limited to scenarios where LLMs possess adequate domain expertise. To address that, we introduce a two-stage Strategy-Augmented Planning (SAP) framework that significantly enhances the opponent exploitation capabilities of LLM-based agents by utilizing a critical component, the Strategy Evaluation Network (SEN). Specifically, in the offline stage, we construct an explicit strategy space and subsequently collect strategy-outcome pair data for training the SEN network. During the online phase, SAP dynamically recognizes the opponent's strategies and greedily exploits them by searching best response strategy on the well-trained SEN, finally translating strategy to a course of actions by carefully designed prompts. Experimental results show that SAP exhibits robust generalization capabilities, allowing it to perform effectively not only against previously encountered opponent strategies but also against novel, unseen strategies. In the MicroRTS environment, SAP achieves a $85.35\%$ performance improvement over baseline methods and matches the competitiveness of reinforcement learning approaches against state-of-the-art (SOTA) rule-based AI. Our code is available at https://github.com/hsushuai/SAP.

