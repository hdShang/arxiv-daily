---
layout: default
title: Leveraging LLMs to Automate Energy-Aware Refactoring of Parallel Scientific Codes
---

# Leveraging LLMs to Automate Energy-Aware Refactoring of Parallel Scientific Codes

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.02184" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.02184v2</a>
  <a href="https://arxiv.org/pdf/2505.02184.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.02184v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.02184v2', 'Leveraging LLMs to Automate Energy-Aware Refactoring of Parallel Scientific Codes')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Matthew T. Dearing, Yiheng Tao, Xingfu Wu, Zhiling Lan, Valerie Taylor

**åˆ†ç±»**: cs.AI, cs.DC, cs.PL, cs.SE

**å‘å¸ƒæ—¥æœŸ**: 2025-05-04 (æ›´æ–°: 2025-11-05)

**å¤‡æ³¨**: 12 pages, 4 figures, version under review at a peer-reviewed conference

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLASSI-EEæ¡†æ¶ä»¥è‡ªåŠ¨åŒ–èƒ½æºæ„ŸçŸ¥å¹¶è¡Œç§‘å­¦ä»£ç é‡æ„**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `èƒ½æ•ˆä¼˜åŒ–` `å¹¶è¡Œè®¡ç®—` `è‡ªåŠ¨åŒ–é‡æ„` `ç§‘å­¦ä»£ç ç”Ÿæˆ` `å¤šé˜¶æ®µè¿­ä»£` `æ€§èƒ½è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç”Ÿæˆå¹¶è¡Œç§‘å­¦ä»£ç æ—¶ï¼Œå¾€å¾€å¿½è§†äº†èƒ½æ•ˆï¼Œå¯¼è‡´æ€§èƒ½ä¸è¶³ã€‚
2. LASSI-EEæ¡†æ¶é€šè¿‡å¤šé˜¶æ®µè¿­ä»£æ–¹æ³•ï¼Œç»“åˆèƒ½æ•ˆæ„ŸçŸ¥æç¤ºå’Œè‡ªæˆ‘çº æ­£æœºåˆ¶ï¼Œè‡ªåŠ¨ç”Ÿæˆé«˜èƒ½æ•ˆä»£ç ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLASSI-EEåœ¨å¤šæ¬¡å°è¯•ä¸‹å¯å®ç°å¹³å‡48%çš„èƒ½é‡å‡å°‘ï¼Œä¸”åœ¨ä¸åŒç¡¬ä»¶ä¸Šè¡¨ç°ä¸€è‡´ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç”Ÿæˆå¹¶è¡Œç§‘å­¦ä»£ç ä¸­çš„åº”ç”¨æ—¥ç›Šå¢å¤šï¼Œç°æœ‰ç ”ç©¶å¾€å¾€ä¾§é‡äºåŠŸèƒ½æ­£ç¡®æ€§ï¼Œè€Œå¿½è§†äº†æ€§èƒ½ï¼Œå°¤å…¶æ˜¯èƒ½æ•ˆã€‚æœ¬æ–‡æå‡ºäº†LASSI-EEï¼Œä¸€ä¸ªåŸºäºLLMçš„è‡ªåŠ¨åŒ–é‡æ„æ¡†æ¶ï¼Œé€šè¿‡å¤šé˜¶æ®µè¿­ä»£æ–¹æ³•ç”Ÿæˆèƒ½æ•ˆé«˜çš„å¹¶è¡Œä»£ç ï¼Œé›†æˆäº†è¿è¡Œæ—¶åŠŸç‡åˆ†æã€èƒ½æ•ˆæ„ŸçŸ¥æç¤ºã€è‡ªæˆ‘çº æ­£åé¦ˆå¾ªç¯åŠLLMä½œä¸ºè¯„åˆ¤è€…çš„è‡ªåŠ¨ç­›é€‰æœºåˆ¶ã€‚æˆ‘ä»¬å¼•å…¥äº†energy-reduction@kè¿™ä¸€æ–°é¢–æŒ‡æ ‡ï¼Œé‡åŒ–ç”Ÿæˆkä¸ªä»£ç å€™é€‰æ—¶çš„é¢„æœŸèƒ½é‡å‡å°‘ï¼Œä¾¿äºç³»ç»Ÿè¯„ä¼°å¤šæ¬¡å°è¯•ç”Ÿæˆç­–ç•¥ã€‚å¯¹20ä¸ªHeCBenchåº”ç”¨å’Œä¸¤ä¸ªminiAppsåœ¨NVIDIA A100å’ŒAMD MI100 GPUä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼Œå•æ¬¡è¿è¡Œï¼ˆk=1ï¼‰ä¸‹ï¼ŒLASSI-EEç”Ÿæˆçš„é‡æ„å¹¶è¡Œä»£ç å¹³å‡é¢„æœŸèƒ½é‡å‡å°‘29%ï¼Œé€šè¿‡ç‡ä¸º81%ï¼Œç›¸æ¯”äºä¼ ç»ŸLLMæç¤ºæå‡äº†2.8å€ã€‚å¤šæ¬¡è¿è¡Œï¼ˆk=3ï¼‰åˆ™å®ç°äº†å¹³å‡48%çš„é¢„æœŸèƒ½é‡å‡å°‘å’Œ97%çš„é€šè¿‡ç‡ã€‚è¿™äº›ç»“æœåœ¨ä¸åŒç¡¬ä»¶æ¶æ„ä¸Šå‡è¡¨ç°å‡ºä¸€è‡´æ€§ï¼Œè¯æ˜äº†LASSI-EEçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¹¶è¡Œç§‘å­¦ä»£ç ç”Ÿæˆæ–¹æ³•åœ¨èƒ½æ•ˆæ–¹é¢çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯ç¼ºä¹å¯¹æ€§èƒ½ä¼˜åŒ–çš„å…³æ³¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šLASSI-EEæ¡†æ¶é€šè¿‡é›†æˆå¤šç§æŠ€æœ¯æ‰‹æ®µï¼Œå¦‚è¿è¡Œæ—¶åŠŸç‡åˆ†æå’Œè‡ªæˆ‘çº æ­£åé¦ˆï¼Œæ¥ç”Ÿæˆèƒ½æ•ˆæ›´é«˜çš„å¹¶è¡Œä»£ç ï¼Œç¡®ä¿åœ¨åŠŸèƒ½æ­£ç¡®çš„åŸºç¡€ä¸Šæå‡èƒ½æ•ˆã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLASSI-EEçš„æ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼šé¦–å…ˆè¿›è¡Œè¿è¡Œæ—¶åŠŸç‡åˆ†æï¼Œæ¥ç€é€šè¿‡èƒ½æ•ˆæ„ŸçŸ¥æç¤ºç”Ÿæˆä»£ç ï¼Œå†åˆ©ç”¨è‡ªæˆ‘çº æ­£åé¦ˆå¾ªç¯ä¼˜åŒ–ä»£ç ï¼Œæœ€åç”±LLMä½œä¸ºè¯„åˆ¤è€…è¿›è¡Œè‡ªåŠ¨ç­›é€‰ã€‚

**å…³é”®åˆ›æ–°**ï¼šå¼•å…¥energy-reduction@kæŒ‡æ ‡ï¼Œé‡åŒ–ç”Ÿæˆkä¸ªä»£ç å€™é€‰æ—¶çš„é¢„æœŸèƒ½é‡å‡å°‘ï¼Œæä¾›äº†ä¸€ç§ç³»ç»Ÿè¯„ä¼°å¤šæ¬¡å°è¯•ç”Ÿæˆç­–ç•¥çš„æ–°æ–¹æ³•ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼ŒLASSI-EEé‡‡ç”¨äº†å¤šæ¬¡å°è¯•ç”Ÿæˆç­–ç•¥ï¼Œkå€¼çš„é€‰æ‹©ç›´æ¥å½±å“èƒ½æ•ˆçš„æå‡ï¼Œå®éªŒä¸­k=1å’Œk=3çš„å¯¹æ¯”æ˜¾ç¤ºäº†æ˜¾è‘—çš„æ€§èƒ½å·®å¼‚ã€‚æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„çš„è®¾è®¡ä¹Ÿé’ˆå¯¹èƒ½æ•ˆä¼˜åŒ–è¿›è¡Œäº†ç‰¹åˆ«è°ƒæ•´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLASSI-EEåœ¨å•æ¬¡è¿è¡Œï¼ˆk=1ï¼‰ä¸‹å®ç°äº†å¹³å‡29%çš„èƒ½é‡å‡å°‘ï¼Œä¸”é€šè¿‡ç‡è¾¾åˆ°81%ï¼›åœ¨å¤šæ¬¡è¿è¡Œï¼ˆk=3ï¼‰æ—¶ï¼Œèƒ½é‡å‡å°‘ç‡æå‡è‡³48%ï¼Œé€šè¿‡ç‡è¾¾åˆ°97%ã€‚è¿™äº›ç»“æœåœ¨ä¸åŒç¡¬ä»¶æ¶æ„ä¸Šå‡è¡¨ç°å‡ºä¸€è‡´æ€§ï¼Œæ˜¾ç¤ºå‡ºè¯¥æ¡†æ¶çš„å¹¿æ³›é€‚ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬é«˜æ€§èƒ½è®¡ç®—ã€ç§‘å­¦æ¨¡æ‹Ÿå’Œå¤§è§„æ¨¡æ•°æ®å¤„ç†ç­‰ï¼Œèƒ½å¤Ÿä¸ºç§‘å­¦ç ”ç©¶æä¾›æ›´ä¸ºé«˜æ•ˆçš„ä»£ç ç”Ÿæˆå·¥å…·ï¼Œé™ä½èƒ½è€—ï¼Œæå‡è®¡ç®—èµ„æºçš„åˆ©ç”¨ç‡ã€‚æœªæ¥ï¼ŒLASSI-EEæ¡†æ¶æœ‰æœ›åœ¨æ›´å¹¿æ³›çš„å¹¶è¡Œè®¡ç®—ä»»åŠ¡ä¸­å¾—åˆ°åº”ç”¨ï¼Œæ¨åŠ¨å¯æŒç»­è®¡ç®—çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While large language models (LLMs) are increasingly used for generating parallel scientific codes, most efforts emphasize functional correctness, often overlooking performance, especially energy efficiency. We propose LASSI-EE, an automated LLM-based refactoring framework that generates energy-efficient parallel codes through a multi-stage, iterative approach integrating runtime power profiling, energy-aware prompting, self-correcting feedback loops, and an LLM-as-a-Judge agent for automated screening of code solutions. We introduce energy-reduction@k, a novel metric that quantifies expected energy reduction when generating k code candidates and selecting the most energy-efficient, enabling systematic evaluation of multi-attempt generation strategies. Evaluating 20 HeCBench applications and two miniApps on NVIDIA A100 and AMD MI100 GPUs, a single run (k=1) with LASSI-EE delivers refactored parallel codes with an average 29% expected energy reduction at an 81% pass rate, representing a 2.8x improvement over vanilla LLM prompting. Multiple runs (k=3) achieve an average 48% expected energy reduction at a 97% pass rate. These results are consistent across devices, demonstrating LASSI-EE's effectiveness across diverse hardware architectures.

