---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.AI - 2025-05-04
---

# cs.AIï¼ˆ2025-05-04ï¼‰

ğŸ“Š å…± **11** ç¯‡è®ºæ–‡
 | ğŸ”— **2** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (10 ğŸ”—2)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (10 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250502087v1-retrieval-augmented-in-context-learning-for-multimodal-large-languag.html">Retrieval-augmented in-context learning for multimodal large language models in disease classification</a></td>
  <td>æå‡ºRAICLæ¡†æ¶ä»¥æå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨ç–¾ç—…åˆ†ç±»ä¸­çš„è¡¨ç°</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.02087v1" data-paper-url="./papers/250502087v1-retrieval-augmented-in-context-learning-for-multimodal-large-languag.html" onclick="toggleFavorite(this, '2505.02087v1', 'Retrieval-augmented in-context learning for multimodal large language models in disease classification')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250502279v2-a-survey-of-agent-interoperability-protocols-model-context-protocol-.html">A survey of agent interoperability protocols: Model Context Protocol (MCP), Agent Communication Protocol (ACP), Agent-to-Agent Protocol (A2A), and Agent Network Protocol (ANP)</a></td>
  <td>æå‡ºå››ç§ä»£ç†äº’æ“ä½œåè®®ä»¥è§£å†³å¼‚æ„ç³»ç»Ÿé—´çš„åä½œé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.02279v2" data-paper-url="./papers/250502279v2-a-survey-of-agent-interoperability-protocols-model-context-protocol-.html" onclick="toggleFavorite(this, '2505.02279v2', 'A survey of agent interoperability protocols: Model Context Protocol (MCP), Agent Communication Protocol (ACP), Agent-to-Agent Protocol (A2A), and Agent Network Protocol (ANP)')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250502271v1-real-time-spatial-retrieval-augmented-generation-for-urban-environme.html">Real-time Spatial Retrieval Augmented Generation for Urban Environments</a></td>
  <td>æå‡ºå®æ—¶ç©ºé—´æ£€ç´¢å¢å¼ºç”Ÿæˆæ¶æ„ä»¥è§£å†³åŸå¸‚ç¯å¢ƒä¸­çš„ä¿¡æ¯æ›´æ–°é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.02271v1" data-paper-url="./papers/250502271v1-real-time-spatial-retrieval-augmented-generation-for-urban-environme.html" onclick="toggleFavorite(this, '2505.02271v1', 'Real-time Spatial Retrieval Augmented Generation for Urban Environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250502052v1-txp-reciprocal-generation-of-ground-pressure-dynamics-and-activity-d.html">TxP: Reciprocal Generation of Ground Pressure Dynamics and Activity Descriptions for Improving Human Activity Recognition</a></td>
  <td>æå‡ºTxPæ¨¡å‹ä»¥è§£å†³å‹åŠ›ä¼ æ„Ÿå™¨åœ¨äººç±»æ´»åŠ¨è¯†åˆ«ä¸­çš„åº”ç”¨ä¸è¶³é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.02052v1" data-paper-url="./papers/250502052v1-txp-reciprocal-generation-of-ground-pressure-dynamics-and-activity-d.html" onclick="toggleFavorite(this, '2505.02052v1', 'TxP: Reciprocal Generation of Ground Pressure Dynamics and Activity Descriptions for Improving Human Activity Recognition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250502184v2-leveraging-llms-to-automate-energy-aware-refactoring-of-parallel-sci.html">Leveraging LLMs to Automate Energy-Aware Refactoring of Parallel Scientific Codes</a></td>
  <td>æå‡ºLASSI-EEæ¡†æ¶ä»¥è‡ªåŠ¨åŒ–èƒ½æºæ„ŸçŸ¥å¹¶è¡Œç§‘å­¦ä»£ç é‡æ„</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.02184v2" data-paper-url="./papers/250502184v2-leveraging-llms-to-automate-energy-aware-refactoring-of-parallel-sci.html" onclick="toggleFavorite(this, '2505.02184v2', 'Leveraging LLMs to Automate Energy-Aware Refactoring of Parallel Scientific Codes')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250502130v1-attention-mechanisms-perspective-exploring-llm-processing-of-graph-s.html">Attention Mechanisms Perspective: Exploring LLM Processing of Graph-Structured Data</a></td>
  <td>æ¢è®¨æ³¨æ„åŠ›æœºåˆ¶åœ¨å›¾ç»“æ„æ•°æ®å¤„ç†ä¸­çš„å±€é™æ€§ä¸æ”¹è¿›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.02130v1" data-paper-url="./papers/250502130v1-attention-mechanisms-perspective-exploring-llm-processing-of-graph-s.html" onclick="toggleFavorite(this, '2505.02130v1', 'Attention Mechanisms Perspective: Exploring LLM Processing of Graph-Structured Data')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250502099v1-memengine-a-unified-and-modular-library-for-developing-advanced-memo.html">MemEngine: A Unified and Modular Library for Developing Advanced Memory of LLM-based Agents</a></td>
  <td>æå‡ºMemEngineä»¥è§£å†³LLMä»£ç†è®°å¿†æ¨¡å‹ç»Ÿä¸€æ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.02099v1" data-paper-url="./papers/250502099v1-memengine-a-unified-and-modular-library-for-developing-advanced-memo.html" onclick="toggleFavorite(this, '2505.02099v1', 'MemEngine: A Unified and Modular Library for Developing Advanced Memory of LLM-based Agents')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250502076v1-leveraging-llm-agents-and-digital-twins-for-fault-handling-in-proces.html">Leveraging LLM Agents and Digital Twins for Fault Handling in Process Plants</a></td>
  <td>æå‡ºLLMä»£ç†ä¸æ•°å­—åŒèƒèƒç»“åˆçš„æ–¹æ³•ä»¥è§£å†³è¿‡ç¨‹å·¥å‚æ•…éšœå¤„ç†é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.02076v1" data-paper-url="./papers/250502076v1-leveraging-llm-agents-and-digital-twins-for-fault-handling-in-proces.html" onclick="toggleFavorite(this, '2505.02076v1', 'Leveraging LLM Agents and Digital Twins for Fault Handling in Process Plants')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250721056v1-ai-driven-generation-of-data-contracts-in-modern-data-engineering-sy.html">AI-Driven Generation of Data Contracts in Modern Data Engineering Systems</a></td>
  <td>æå‡ºAIé©±åŠ¨çš„æ•°æ®åˆåŒç”Ÿæˆæ¡†æ¶ä»¥è§£å†³æ•°æ®å·¥ç¨‹ä¸­çš„å¤æ‚æ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2507.21056v1" data-paper-url="./papers/250721056v1-ai-driven-generation-of-data-contracts-in-modern-data-engineering-sy.html" onclick="toggleFavorite(this, '2507.21056v1', 'AI-Driven Generation of Data Contracts in Modern Data Engineering Systems')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250502024v2-from-mind-to-machine-the-rise-of-manus-ai-as-a-fully-autonomous-digi.html">From Mind to Machine: The Rise of Manus AI as a Fully Autonomous Digital Agent</a></td>
  <td>æå‡ºManus AIä»¥å®ç°å®Œå…¨è‡ªä¸»çš„æ•°å­—ä»£ç†</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.02024v2" data-paper-url="./papers/250502024v2-from-mind-to-machine-the-rise-of-manus-ai-as-a-fully-autonomous-digi.html" onclick="toggleFavorite(this, '2505.02024v2', 'From Mind to Machine: The Rise of Manus AI as a Fully Autonomous Digital Agent')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>11</td>
  <td><a href="./papers/250501953v1-training-environment-for-high-performance-reinforcement-learning.html">Training Environment for High Performance Reinforcement Learning</a></td>
  <td>æå‡ºTunnelä»¥è§£å†³é«˜æ€§èƒ½å¼ºåŒ–å­¦ä¹ è®­ç»ƒç¯å¢ƒé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.01953v1" data-paper-url="./papers/250501953v1-training-environment-for-high-performance-reinforcement-learning.html" onclick="toggleFavorite(this, '2505.01953v1', 'Training Environment for High Performance Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.AI é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)