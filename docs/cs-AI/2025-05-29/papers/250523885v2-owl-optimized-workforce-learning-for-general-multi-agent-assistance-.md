---
layout: default
title: OWL: Optimized Workforce Learning for General Multi-Agent Assistance in Real-World Task Automation
---

# OWL: Optimized Workforce Learning for General Multi-Agent Assistance in Real-World Task Automation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.23885" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.23885v2</a>
  <a href="https://arxiv.org/pdf/2505.23885.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.23885v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.23885v2', 'OWL: Optimized Workforce Learning for General Multi-Agent Assistance in Real-World Task Automation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mengkang Hu, Yuhang Zhou, Wendong Fan, Yuzhou Nie, Bowei Xia, Tao Sun, Ziyu Ye, Zhaoxuan Jin, Yingru Li, Qiguang Chen, Zeyu Zhang, Yifeng Wang, Qianshuo Ye, Bernard Ghanem, Ping Luo, Guohao Li

**åˆ†ç±»**: cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-29 (æ›´æ–°: 2025-06-11)

**å¤‡æ³¨**: Project Page: https://github.com/camel-ai/owl

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¼˜åŒ–å·¥ä½œå­¦ä¹ æ¡†æ¶ä»¥è§£å†³å¤šé¢†åŸŸä»»åŠ¡è‡ªåŠ¨åŒ–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ` `ä»»åŠ¡è‡ªåŠ¨åŒ–` `é¢†åŸŸè¿ç§»` `å¼ºåŒ–å­¦ä¹ ` `æ¨¡å—åŒ–æ¶æ„` `ä¼˜åŒ–å·¥ä½œå­¦ä¹ ` `æ™ºèƒ½åŠ©æ‰‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåœ¨è·¨é¢†åŸŸè¿ç§»æ—¶é¢ä¸´æ¶æ„é‡æ„å’Œå…¨é‡é‡è®­ç»ƒçš„æŒ‘æˆ˜ï¼Œé™åˆ¶äº†å…¶åº”ç”¨èŒƒå›´ã€‚
2. æœ¬æ–‡æå‡ºäº†Workforceæ¡†æ¶ï¼Œé€šè¿‡è§£è€¦æˆ˜ç•¥è§„åˆ’ä¸æ‰§è¡Œï¼Œå®ç°äº†é¢†åŸŸæ— å…³çš„ä»»åŠ¡å¤„ç†å’Œé«˜æ•ˆçš„è·¨é¢†åŸŸé€‚åº”ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒWorkforceåœ¨GAIAåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†69.70%çš„æ€§èƒ½ï¼Œè¶…è¶Šäº†OpenAIçš„Deep Researchç³»ç»Ÿï¼Œå¹¶ä¸”åœ¨å¤æ‚ä»»åŠ¡ä¸Šä¸GPT-4oçš„è¡¨ç°ç›¸å½“ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåœ¨è‡ªåŠ¨åŒ–ç°å®ä»»åŠ¡æ–¹é¢å±•ç°å‡ºæ½œåŠ›ï¼Œä½†ç”±äºå…¶é¢†åŸŸç‰¹å®šçš„ç‰¹æ€§ï¼Œè·¨é¢†åŸŸè¿ç§»å­˜åœ¨å›°éš¾ã€‚ç°æœ‰æ–¹æ³•é¢ä¸´ä¸¤ä¸ªä¸»è¦çŸ­æ¿ï¼šåœ¨åº”ç”¨äºæ–°é¢†åŸŸæ—¶éœ€è¦å®Œå…¨é‡æ„æ¶æ„å’Œé‡æ–°è®­ç»ƒæ‰€æœ‰ç»„ä»¶ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†Workforceï¼Œä¸€ä¸ªå±‚æ¬¡åŒ–çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œé€šè¿‡æ¨¡å—åŒ–æ¶æ„å°†æˆ˜ç•¥è§„åˆ’ä¸ä¸“ä¸šæ‰§è¡Œè§£è€¦ã€‚è¯¥æ¡†æ¶åŒ…æ‹¬ï¼šä¸€ä¸ªé¢†åŸŸæ— å…³çš„è§„åˆ’å™¨ç”¨äºä»»åŠ¡åˆ†è§£ï¼Œä¸€ä¸ªåè°ƒå™¨ç”¨äºå­ä»»åŠ¡ç®¡ç†ï¼Œä»¥åŠå…·æœ‰é¢†åŸŸç‰¹å®šå·¥å…·è°ƒç”¨èƒ½åŠ›çš„ä¸“ä¸šå·¥ä½œè€…ã€‚é€šè¿‡è¿™ç§è§£è€¦ï¼ŒWorkforceåœ¨æ¨ç†å’Œè®­ç»ƒé˜¶æ®µå‡èƒ½å®ç°è·¨é¢†åŸŸè¿ç§»ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒWorkforceåœ¨GAIAåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†å¼€æºçš„æœ€å…ˆè¿›æ€§èƒ½ï¼Œè¶…è¶Šäº†å•†ä¸šç³»ç»Ÿã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåœ¨è·¨é¢†åŸŸä»»åŠ¡è‡ªåŠ¨åŒ–ä¸­çš„è¿ç§»å›°éš¾ï¼Œå°¤å…¶æ˜¯æ¶æ„é‡æ„å’Œå…¨é‡é‡è®­ç»ƒçš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥Workforceæ¡†æ¶ï¼Œå°†æˆ˜ç•¥è§„åˆ’ä¸æ‰§è¡Œè§£è€¦ï¼Œä½¿å¾—ç³»ç»Ÿèƒ½å¤Ÿåœ¨ä¸åŒé¢†åŸŸä¸­çµæ´»é€‚åº”ï¼Œæå‡ä»»åŠ¡å¤„ç†çš„æ•ˆç‡å’Œæ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šWorkforceæ¡†æ¶ç”±ä¸‰ä¸ªä¸»è¦æ¨¡å—ç»„æˆï¼šé¢†åŸŸæ— å…³çš„è§„åˆ’å™¨è´Ÿè´£ä»»åŠ¡åˆ†è§£ï¼Œåè°ƒå™¨ç®¡ç†å­ä»»åŠ¡ï¼Œè€Œä¸“ä¸šå·¥ä½œè€…åˆ™å…·å¤‡é¢†åŸŸç‰¹å®šçš„å·¥å…·è°ƒç”¨èƒ½åŠ›ã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—ç³»ç»Ÿåœ¨æ¨ç†æ—¶å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ æˆ–ä¿®æ”¹å·¥ä½œè€…ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†ä¼˜åŒ–å·¥ä½œå­¦ä¹ ï¼ˆOWLï¼‰ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ ä»ç°å®åé¦ˆä¸­ä¼˜åŒ–é¢†åŸŸæ— å…³çš„è§„åˆ’å™¨ï¼Œä»è€Œæå‡äº†è·¨é¢†åŸŸçš„æ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒOWLé€šè¿‡å®æ—¶åé¦ˆè°ƒæ•´è§„åˆ’å™¨çš„ç­–ç•¥ï¼Œç¡®ä¿å…¶èƒ½å¤Ÿé€‚åº”ä¸åŒé¢†åŸŸçš„ä»»åŠ¡éœ€æ±‚ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡å°šæœªè¯¦ç»†æŠ«éœ²ï¼Œå±äºæœªçŸ¥é¢†åŸŸã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒWorkforceåœ¨GAIAåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†69.70%çš„æ€§èƒ½ï¼Œè¶…è¶Šäº†OpenAIçš„Deep Researchç³»ç»Ÿ2.34%ã€‚æ­¤å¤–ï¼Œç»è¿‡OWLè®­ç»ƒçš„32Bæ¨¡å‹åœ¨å¤æ‚ä»»åŠ¡ä¸Šè¾¾åˆ°äº†52.73%çš„å‡†ç¡®ç‡ï¼Œç›¸è¾ƒäºä¹‹å‰æå‡äº†16.37%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½åŠ©æ‰‹ã€è‡ªåŠ¨åŒ–å®¢æœã€æ™ºèƒ½å®¶å±…ç­‰å¤šä¸ªåœºæ™¯ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåœ¨ä¸åŒé¢†åŸŸçš„é€‚åº”èƒ½åŠ›å’Œä»»åŠ¡æ‰§è¡Œæ•ˆç‡ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶å¯èƒ½æ¨åŠ¨æ›´å¹¿æ³›çš„é€šç”¨äººå·¥æ™ºèƒ½åŠ©æ‰‹çš„å‘å±•ï¼Œæ»¡è¶³å¤šæ ·åŒ–çš„ç”¨æˆ·éœ€æ±‚ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Model (LLM)-based multi-agent systems show promise for automating real-world tasks but struggle to transfer across domains due to their domain-specific nature. Current approaches face two critical shortcomings: they require complete architectural redesign and full retraining of all components when applied to new domains. We introduce Workforce, a hierarchical multi-agent framework that decouples strategic planning from specialized execution through a modular architecture comprising: (i) a domain-agnostic Planner for task decomposition, (ii) a Coordinator for subtask management, and (iii) specialized Workers with domain-specific tool-calling capabilities. This decoupling enables cross-domain transferability during both inference and training phases: During inference, Workforce seamlessly adapts to new domains by adding or modifying worker agents; For training, we introduce Optimized Workforce Learning (OWL), which improves generalization across domains by optimizing a domain-agnostic planner with reinforcement learning from real-world feedback. To validate our approach, we evaluate Workforce on the GAIA benchmark, covering various realistic, multi-domain agentic tasks. Experimental results demonstrate Workforce achieves open-source state-of-the-art performance (69.70%), outperforming commercial systems like OpenAI's Deep Research by 2.34%. More notably, our OWL-trained 32B model achieves 52.73% accuracy (+16.37%) and demonstrates performance comparable to GPT-4o on challenging tasks. To summarize, by enabling scalable generalization and modular domain transfer, our work establishes a foundation for the next generation of general-purpose AI assistants.

