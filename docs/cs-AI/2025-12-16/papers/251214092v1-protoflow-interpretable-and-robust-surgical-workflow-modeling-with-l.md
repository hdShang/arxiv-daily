---
layout: default
title: ProtoFlow: Interpretable and Robust Surgical Workflow Modeling with Learned Dynamic Scene Graph Prototypes
---

# ProtoFlow: Interpretable and Robust Surgical Workflow Modeling with Learned Dynamic Scene Graph Prototypes

**arXiv**: [2512.14092v1](https://arxiv.org/abs/2512.14092) | [PDF](https://arxiv.org/pdf/2512.14092.pdf)

**ä½œè€…**: Felix Holm, Ghazal Ghazaei, Nassir Navab

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºProtoFlowæ¡†æž¶ï¼Œé€šè¿‡åŠ¨æ€åœºæ™¯å›¾åŽŸåž‹å­¦ä¹ å®žçŽ°å¯è§£é‡Šä¸”é²æ£’çš„æ‰‹æœ¯å·¥ä½œæµå»ºæ¨¡**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `æ‰‹æœ¯å·¥ä½œæµå»ºæ¨¡` `åŠ¨æ€åœºæ™¯å›¾` `åŽŸåž‹å­¦ä¹ ` `å›¾ç¥žç»ç½‘ç»œ` `å¯è§£é‡ŠAI` `å°‘æ ·æœ¬å­¦ä¹ ` `è‡ªç›‘ç£é¢„è®­ç»ƒ` `åŒ»ç–—å›¾åƒåˆ†æž`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ‰‹æœ¯è¯†åˆ«é¢ä¸´é«˜æ ‡æ³¨æˆæœ¬ã€æ•°æ®ç¨€ç¼ºå’Œæ¨¡åž‹ç¼ºä¹å¯è§£é‡Šæ€§ï¼ŒçŽ°æœ‰åœºæ™¯å›¾æ–¹æ³•æœªèƒ½å……åˆ†åˆ©ç”¨ç»“æž„åŒ–æŠ½è±¡æ½œåŠ›ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆè‡ªç›‘ç£é¢„è®­ç»ƒå’ŒåŽŸåž‹å¾®è°ƒï¼Œå­¦ä¹ åŠ¨æ€åœºæ™¯å›¾åŽŸåž‹ä»¥å»ºæ¨¡æ‰‹æœ¯äº¤äº’æ¨¡å¼ï¼Œå®žçŽ°å¯è§£é‡Šä¸”é²æ£’çš„å·¥ä½œæµåˆ†æžã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨CAT-SGæ•°æ®é›†ä¸Šè¶…è¶ŠGNNåŸºçº¿ï¼Œå°‘æ ·æœ¬åœºæ™¯ä¸‹é²æ£’æ€§å¼ºï¼ŒåŽŸåž‹èƒ½è¯†åˆ«æ‰‹æœ¯å­æŠ€æœ¯å¹¶æä¾›å·¥ä½œæµåå·®è§è§£ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç›®çš„ï¼šè¯¦ç»†çš„æ‰‹æœ¯è¯†åˆ«å¯¹æŽ¨è¿›AIè¾…åŠ©æ‰‹æœ¯è‡³å…³é‡è¦ï¼Œä½†é«˜æ ‡æ³¨æˆæœ¬ã€æ•°æ®ç¨€ç¼ºå’Œç¼ºä¹å¯è§£é‡Šæ¨¡åž‹é˜»ç¢äº†è¿›å±•ã€‚è™½ç„¶åœºæ™¯å›¾æä¾›äº†æ‰‹æœ¯äº‹ä»¶çš„ç»“æž„åŒ–æŠ½è±¡ï¼Œä½†å…¶å…¨éƒ¨æ½œåŠ›å°šæœªè¢«å……åˆ†æŒ–æŽ˜ã€‚æœ¬æ–‡æå‡ºProtoFlowï¼Œä¸€ç§æ–°é¢–çš„æ¡†æž¶ï¼Œé€šè¿‡å­¦ä¹ åŠ¨æ€åœºæ™¯å›¾åŽŸåž‹ï¼Œä»¥å¯è§£é‡Šä¸”é²æ£’çš„æ–¹å¼å»ºæ¨¡å¤æ‚æ‰‹æœ¯å·¥ä½œæµã€‚æ–¹æ³•ï¼šProtoFlowåˆ©ç”¨å›¾ç¥žç»ç½‘ç»œï¼ˆGNNï¼‰ç¼–ç å™¨-è§£ç å™¨æž¶æž„ï¼Œç»“åˆè‡ªç›‘ç£é¢„è®­ç»ƒè¿›è¡Œä¸°å¯Œè¡¨ç¤ºå­¦ä¹ ï¼Œä»¥åŠåŸºäºŽåŽŸåž‹çš„å¾®è°ƒé˜¶æ®µã€‚è¯¥è¿‡ç¨‹å‘çŽ°å¹¶ç²¾ç‚¼æ ¸å¿ƒåŽŸåž‹ï¼Œè¿™äº›åŽŸåž‹å°è£…äº†é‡å¤å‡ºçŽ°çš„ã€å…·æœ‰ä¸´åºŠæ„ä¹‰çš„æ‰‹æœ¯äº¤äº’æ¨¡å¼ï¼Œä¸ºå·¥ä½œæµåˆ†æžå½¢æˆå¯è§£é‡Šçš„åŸºç¡€ã€‚ç»“æžœï¼šæˆ‘ä»¬åœ¨ç»†ç²’åº¦CAT-SGæ•°æ®é›†ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ã€‚ProtoFlowä¸ä»…åœ¨æ•´ä½“å‡†ç¡®çŽ‡ä¸Šä¼˜äºŽæ ‡å‡†GNNåŸºçº¿ï¼Œè¿˜åœ¨æœ‰é™æ•°æ®ã€å°‘æ ·æœ¬åœºæ™¯ä¸­è¡¨çŽ°å‡ºå“è¶Šçš„é²æ£’æ€§ï¼Œåœ¨ä»…ç”¨ä¸€ä¸ªæ‰‹æœ¯è§†é¢‘è®­ç»ƒæ—¶ä»ä¿æŒå¼ºåŠ²æ€§èƒ½ã€‚æˆ‘ä»¬çš„å®šæ€§åˆ†æžè¿›ä¸€æ­¥è¡¨æ˜Žï¼Œå­¦ä¹ åˆ°çš„åŽŸåž‹æˆåŠŸè¯†åˆ«äº†ä¸åŒçš„æ‰‹æœ¯å­æŠ€æœ¯ï¼Œå¹¶ä¸ºå·¥ä½œæµåå·®å’Œç½•è§å¹¶å‘ç—‡æä¾›äº†æ¸…æ™°ã€å¯è§£é‡Šçš„è§è§£ã€‚ç»“è®ºï¼šé€šè¿‡å°†é²æ£’çš„è¡¨ç¤ºå­¦ä¹ ä¸Žå›ºæœ‰çš„å¯è§£é‡Šæ€§ç›¸ç»“åˆï¼ŒProtoFlowä»£è¡¨äº†å‘å¼€å‘æ›´é€æ˜Žã€å¯é å’Œæ•°æ®é«˜æ•ˆçš„AIç³»ç»Ÿè¿ˆå‡ºçš„é‡è¦ä¸€æ­¥ï¼ŒåŠ é€Ÿäº†å…¶åœ¨æ‰‹æœ¯åŸ¹è®­ã€å®žæ—¶å†³ç­–æ”¯æŒå’Œå·¥ä½œæµä¼˜åŒ–ä¸­çš„ä¸´åºŠé‡‡ç”¨æ½œåŠ›ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æ‰‹æœ¯å·¥ä½œæµå»ºæ¨¡ä¸­çš„æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬é«˜æ ‡æ³¨æˆæœ¬å¯¼è‡´çš„æ•°æ®ç¨€ç¼ºã€æ¨¡åž‹ç¼ºä¹å¯è§£é‡Šæ€§ï¼Œä»¥åŠçŽ°æœ‰åœºæ™¯å›¾æ–¹æ³•æœªèƒ½å……åˆ†æ•æ‰åŠ¨æ€æ‰‹æœ¯äº¤äº’æ¨¡å¼ã€‚çŽ°æœ‰æ–¹æ³•çš„ç—›ç‚¹åœ¨äºŽä¾èµ–å¤§é‡æ ‡æ³¨æ•°æ®ã€éš¾ä»¥æ³›åŒ–åˆ°å°‘æ ·æœ¬åœºæ™¯ï¼Œä¸”æ¨¡åž‹å†³ç­–è¿‡ç¨‹ä¸é€æ˜Žï¼Œé™åˆ¶äº†ä¸´åºŠå¯ä¿¡åº¦ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å­¦ä¹ åŠ¨æ€åœºæ™¯å›¾åŽŸåž‹æ¥å»ºæ¨¡æ‰‹æœ¯å·¥ä½œæµï¼Œè¿™äº›åŽŸåž‹å°è£…äº†é‡å¤å‡ºçŽ°çš„ã€å…·æœ‰ä¸´åºŠæ„ä¹‰çš„äº¤äº’æ¨¡å¼ã€‚è®¾è®¡ä¸Šï¼Œç»“åˆè‡ªç›‘ç£é¢„è®­ç»ƒå­¦ä¹ ä¸°å¯Œè¡¨ç¤ºï¼Œå†é€šè¿‡åŽŸåž‹å¾®è°ƒç²¾ç‚¼æ ¸å¿ƒæ¨¡å¼ï¼Œä»¥å®žçŽ°å¯è§£é‡Šæ€§å’Œé²æ£’æ€§ï¼Œä»Žè€Œå‡å°‘å¯¹æ ‡æ³¨æ•°æ®çš„ä¾èµ–å¹¶å¢žå¼ºæ¨¡åž‹é€æ˜Žåº¦ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æž¶æž„åŸºäºŽå›¾ç¥žç»ç½‘ç»œï¼ˆGNNï¼‰ç¼–ç å™¨-è§£ç å™¨ï¼ŒåŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šè‡ªç›‘ç£é¢„è®­ç»ƒé˜¶æ®µï¼Œä½¿ç”¨æ— æ ‡æ³¨æ•°æ®å­¦ä¹ åœºæ™¯å›¾çš„é€šç”¨è¡¨ç¤ºï¼›åŽŸåž‹å¾®è°ƒé˜¶æ®µï¼ŒåŸºäºŽå°‘é‡æ ‡æ³¨æ•°æ®å‘çŽ°å’Œä¼˜åŒ–åŠ¨æ€åŽŸåž‹ï¼Œç”¨äºŽå·¥ä½œæµåˆ†ç±»å’Œåˆ†æžã€‚æµç¨‹ä¸Šï¼Œè¾“å…¥æ‰‹æœ¯è§†é¢‘çš„åœºæ™¯å›¾åºåˆ—ï¼Œç»ç¼–ç å™¨æå–ç‰¹å¾ï¼Œè§£ç å™¨ç»“åˆåŽŸåž‹è¿›è¡Œé¢„æµ‹ï¼Œè¾“å‡ºå·¥ä½œæµæ ‡ç­¾å’Œå¯è§£é‡Šçš„åŽŸåž‹åŒ¹é…ç»“æžœã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°æ˜¯å¼•å…¥äº†åŠ¨æ€åœºæ™¯å›¾åŽŸåž‹å­¦ä¹ æœºåˆ¶ï¼Œå°†åŽŸåž‹æ–¹æ³•ä¸ŽGNNç»“åˆï¼Œä»¥å¯è§£é‡Šçš„æ–¹å¼å»ºæ¨¡æ‰‹æœ¯äº¤äº’æ¨¡å¼ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºŽï¼Œå®ƒä¸ä»…æå‡æ€§èƒ½ï¼Œè¿˜é€šè¿‡åŽŸåž‹æä¾›ç›´è§‚çš„å†³ç­–ä¾æ®ï¼Œå¢žå¼ºäº†æ¨¡åž‹åœ¨å°‘æ ·æœ¬åœºæ™¯ä¸‹çš„é²æ£’æ€§å’Œä¸´åºŠå¯è§£é‡Šæ€§ï¼Œè€Œä¼ ç»Ÿæ–¹æ³•å¤šä¾èµ–é»‘ç›’æ¨¡åž‹æˆ–é™æ€å›¾è¡¨ç¤ºã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®å‚æ•°åŒ…æ‹¬åŽŸåž‹æ•°é‡ï¼ˆæ ¹æ®æ•°æ®å¤æ‚åº¦è‡ªé€‚åº”è®¾ç½®ï¼‰ã€GNNå±‚æ•°ï¼ˆä¾‹å¦‚2-3å±‚å›¾å·ç§¯ç½‘ç»œï¼‰å’ŒæŸå¤±å‡½æ•°ï¼ˆç»“åˆåˆ†ç±»æŸå¤±å’ŒåŽŸåž‹ä¸€è‡´æ€§æŸå¤±ï¼Œå¦‚äº¤å‰ç†µå’ŒåŽŸåž‹èšç±»æŸå¤±ï¼‰ã€‚ç½‘ç»œç»“æž„ä½¿ç”¨GNNç¼–ç å™¨ï¼ˆå¦‚GCNæˆ–GATï¼‰å¤„ç†åœºæ™¯å›¾ï¼Œè§£ç å™¨æ•´åˆåŽŸåž‹ç‰¹å¾è¿›è¡Œé¢„æµ‹ï¼›è‡ªç›‘ç£é¢„è®­ç»ƒå¯èƒ½é‡‡ç”¨å¯¹æ¯”å­¦ä¹ æˆ–é‡æž„ä»»åŠ¡ï¼Œå¾®è°ƒé˜¶æ®µé€šè¿‡åŽŸåž‹åŒ¹é…ä¼˜åŒ–è¡¨ç¤ºã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

æœ€é‡è¦çš„å®žéªŒç»“æžœåŒ…æ‹¬ï¼šåœ¨CAT-SGæ•°æ®é›†ä¸Šï¼ŒProtoFlowæ•´ä½“å‡†ç¡®çŽ‡è¶…è¶Šæ ‡å‡†GNNåŸºçº¿ï¼ˆå…·ä½“æå‡å¹…åº¦æœªçŸ¥ï¼Œä½†è®ºæ–‡æŒ‡å‡ºâ€œoutperformsâ€ï¼‰ï¼›åœ¨å°‘æ ·æœ¬åœºæ™¯ä¸­ï¼Œä»…ç”¨ä¸€ä¸ªæ‰‹æœ¯è§†é¢‘è®­ç»ƒæ—¶ä»ä¿æŒå¼ºåŠ²æ€§èƒ½ï¼Œå±•ç¤ºäº†å“è¶Šçš„é²æ£’æ€§ï¼›å®šæ€§åˆ†æžæ˜¾ç¤ºï¼Œå­¦ä¹ åˆ°çš„åŽŸåž‹èƒ½æˆåŠŸè¯†åˆ«æ‰‹æœ¯å­æŠ€æœ¯ï¼Œå¹¶æä¾›å·¥ä½œæµåå·®å’Œç½•è§å¹¶å‘ç—‡çš„æ¸…æ™°è§è§£ï¼ŒéªŒè¯äº†æ¨¡åž‹çš„å¯è§£é‡Šæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ‰‹æœ¯åŸ¹è®­ã€å®žæ—¶å†³ç­–æ”¯æŒå’Œå·¥ä½œæµä¼˜åŒ–ã€‚åœ¨å®žé™…ä»·å€¼ä¸Šï¼ŒProtoFlowçš„å¯è§£é‡Šæ€§å’Œé²æ£’æ€§æœ‰åŠ©äºŽæé«˜AIç³»ç»Ÿåœ¨ä¸´åºŠçŽ¯å¢ƒä¸­çš„å¯ä¿¡åº¦ï¼Œå‡å°‘å¯¹å¤§é‡æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼ŒåŠ é€ŸAIè¾…åŠ©æ‰‹æœ¯çš„é‡‡ç”¨ã€‚æœªæ¥å½±å“å¯èƒ½æŽ¨åŠ¨æ›´é€æ˜Žã€æ•°æ®é«˜æ•ˆçš„åŒ»ç–—AIå‘å±•ï¼Œæå‡æ‰‹æœ¯å®‰å…¨æ€§å’Œæ•ˆçŽ‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Purpose: Detailed surgical recognition is critical for advancing AI-assisted surgery, yet progress is hampered by high annotation costs, data scarcity, and a lack of interpretable models. While scene graphs offer a structured abstraction of surgical events, their full potential remains untapped. In this work, we introduce ProtoFlow, a novel framework that learns dynamic scene graph prototypes to model complex surgical workflows in an interpretable and robust manner.
>   Methods: ProtoFlow leverages a graph neural network (GNN) encoder-decoder architecture that combines self-supervised pretraining for rich representation learning with a prototype-based fine-tuning stage. This process discovers and refines core prototypes that encapsulate recurring, clinically meaningful patterns of surgical interaction, forming an explainable foundation for workflow analysis.
>   Results: We evaluate our approach on the fine-grained CAT-SG dataset. ProtoFlow not only outperforms standard GNN baselines in overall accuracy but also demonstrates exceptional robustness in limited-data, few-shot scenarios, maintaining strong performance when trained on as few as one surgical video. Our qualitative analyses further show that the learned prototypes successfully identify distinct surgical sub-techniques and provide clear, interpretable insights into workflow deviations and rare complications.
>   Conclusion: By uniting robust representation learning with inherent explainability, ProtoFlow represents a significant step toward developing more transparent, reliable, and data-efficient AI systems, accelerating their potential for clinical adoption in surgical training, real-time decision support, and workflow optimization.

