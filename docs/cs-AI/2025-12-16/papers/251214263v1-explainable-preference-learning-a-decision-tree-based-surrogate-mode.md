---
layout: default
title: Explainable Preference Learning: a Decision Tree-based Surrogate Model for Preferential Bayesian Optimization
---

# Explainable Preference Learning: a Decision Tree-based Surrogate Model for Preferential Bayesian Optimization

**arXiv**: [2512.14263v1](https://arxiv.org/abs/2512.14263) | [PDF](https://arxiv.org/pdf/2512.14263.pdf)

**ä½œè€…**: Nick Leenders, Thomas Quadt, Boris Cule, Roy Lindelauf, Herman Monsuur, Joost van Oijen, Mark Voskuijl

**åˆ†ç±»**: cs.LG, cs.AI, math.OC

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽå†³ç­–æ ‘çš„å¯è§£é‡Šåå¥½å­¦ä¹ æ¨¡åž‹ï¼Œä»¥è§£å†³åå¥½è´å¶æ–¯ä¼˜åŒ–ä¸­é«˜æ–¯è¿‡ç¨‹æ¨¡åž‹éš¾ä»¥è§£é‡Šã€å¤„ç†åˆ†ç±»æ•°æ®å›°éš¾çš„é—®é¢˜ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `åå¥½å­¦ä¹ ` `è´å¶æ–¯ä¼˜åŒ–` `å†³ç­–æ ‘æ¨¡åž‹` `å¯è§£é‡Šäººå·¥æ™ºèƒ½` `åˆ†ç±»æ•°æ®å¤„ç†` `ä»£ç†æ¨¡åž‹` `ä¸ªæ€§åŒ–æŽ¨è` `ä¼˜åŒ–ç®—æ³•`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰åå¥½è´å¶æ–¯ä¼˜åŒ–ä¾èµ–é«˜æ–¯è¿‡ç¨‹ï¼Œå­˜åœ¨æ¨¡åž‹éš¾ä»¥è§£é‡Šã€å¤„ç†åˆ†ç±»æ•°æ®å›°éš¾ã€è®¡ç®—å¤æ‚ç­‰é™åˆ¶ã€‚
2. æå‡ºåŸºäºŽå†³ç­–æ ‘çš„ä»£ç†æ¨¡åž‹ï¼Œå…·å¤‡å†…åœ¨å¯è§£é‡Šæ€§ï¼Œèƒ½å¤„ç†åˆ†ç±»å’Œè¿žç»­æ•°æ®ï¼Œå¹¶æ”¯æŒå¤§è§„æ¨¡æ•°æ®é›†ã€‚
3. åœ¨å°–å³°å‡½æ•°ä¸Šä¼˜äºŽé«˜æ–¯è¿‡ç¨‹æ¨¡åž‹ï¼Œéžå°–å³°å‡½æ•°æ€§èƒ½ç›¸è¿‘ï¼Œå¯¿å¸æ•°æ®é›†éªŒè¯äº†å®žé™…åå¥½å­¦ä¹ èƒ½åŠ›ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å½“å‰çš„åå¥½è´å¶æ–¯ä¼˜åŒ–æ–¹æ³•ä¾èµ–äºŽé«˜æ–¯è¿‡ç¨‹ä½œä¸ºä»£ç†æ¨¡åž‹ã€‚è¿™äº›æ¨¡åž‹éš¾ä»¥è§£é‡Šï¼Œå¤„ç†åˆ†ç±»æ•°æ®å›°éš¾ï¼Œä¸”è®¡ç®—å¤æ‚åº¦é«˜ï¼Œé™åˆ¶äº†å…¶åœ¨å®žé™…åº”ç”¨ä¸­çš„å¯ç”¨æ€§ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æœ¬è´¨ä¸Šå¯è§£é‡Šçš„åŸºäºŽå†³ç­–æ ‘çš„ä»£ç†æ¨¡åž‹ï¼Œèƒ½å¤ŸåŒæ—¶å¤„ç†åˆ†ç±»å’Œè¿žç»­æ•°æ®ï¼Œå¹¶å¯æ‰©å±•åˆ°å¤§åž‹æ•°æ®é›†ã€‚åœ¨å…«ä¸ªé€æ¸å°–å³°çš„ä¼˜åŒ–å‡½æ•°ä¸Šè¿›è¡Œçš„å¤§é‡æ•°å€¼å®žéªŒè¡¨æ˜Žï¼Œæˆ‘ä»¬çš„æ¨¡åž‹åœ¨å°–å³°å‡½æ•°ä¸Šä¼˜äºŽåŸºäºŽé«˜æ–¯è¿‡ç¨‹çš„æ›¿ä»£æ–¹æ³•ï¼Œåœ¨éžå°–å³°å‡½æ•°ä¸Šæ€§èƒ½ä»…ç•¥ä½Žã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†æ¨¡åž‹åº”ç”¨äºŽçœŸå®žä¸–ç•Œçš„å¯¿å¸æ•°æ®é›†ï¼Œå±•ç¤ºäº†å…¶å­¦ä¹ ä¸ªäººå¯¿å¸åå¥½çš„èƒ½åŠ›ã€‚æœ€åŽï¼Œæˆ‘ä»¬å±•ç¤ºäº†åˆ©ç”¨åŽ†å²åå¥½æ•°æ®åŠ é€Ÿæ–°ç”¨æˆ·ä¼˜åŒ–è¿‡ç¨‹çš„åˆæ­¥å·¥ä½œã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åå¥½è´å¶æ–¯ä¼˜åŒ–ä¸­çŽ°æœ‰é«˜æ–¯è¿‡ç¨‹ä»£ç†æ¨¡åž‹çš„å¯è§£é‡Šæ€§å·®ã€å¤„ç†åˆ†ç±»æ•°æ®èƒ½åŠ›å¼±ã€è®¡ç®—å¤æ‚åº¦é«˜çš„é—®é¢˜ï¼Œè¿™äº›ç—›ç‚¹é™åˆ¶äº†æ¨¡åž‹åœ¨çœŸå®žåœºæ™¯ä¸­çš„å®žç”¨æ€§å’Œæ‰©å±•æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé‡‡ç”¨å†³ç­–æ ‘ä½œä¸ºä»£ç†æ¨¡åž‹æ›¿ä»£é«˜æ–¯è¿‡ç¨‹ï¼Œåˆ©ç”¨å†³ç­–æ ‘çš„å†…åœ¨å¯è§£é‡Šæ€§ã€å¯¹åˆ†ç±»æ•°æ®çš„å¤©ç„¶æ”¯æŒä»¥åŠè¾ƒä½Žçš„è®¡ç®—å¤æ‚åº¦ï¼Œæž„å»ºä¸€ä¸ªæ—¢èƒ½å‡†ç¡®å»ºæ¨¡ç”¨æˆ·åå¥½åˆæ˜“äºŽç†è§£çš„ä¼˜åŒ–æ¡†æž¶ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æž¶æž„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€å†³ç­–æ ‘æ¨¡åž‹è®­ç»ƒã€åå¥½é¢„æµ‹å’Œä¼˜åŒ–è¿­ä»£å››ä¸ªé˜¶æ®µã€‚é¦–å…ˆå¤„ç†åŒ…å«åˆ†ç±»å’Œè¿žç»­ç‰¹å¾çš„åå¥½æ•°æ®ï¼Œç„¶åŽè®­ç»ƒå†³ç­–æ ‘æ¨¡åž‹æ¥å­¦ä¹ åå¥½å‡½æ•°ï¼ŒæŽ¥ç€åŸºäºŽæ¨¡åž‹é¢„æµ‹è¿›è¡Œè´å¶æ–¯ä¼˜åŒ–ä»¥é€‰æ‹©ä¸‹ä¸€ä¸ªæŸ¥è¯¢ç‚¹ï¼Œæœ€åŽè¿­ä»£æ›´æ–°ç›´è‡³æ”¶æ•›ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°æ˜¯å°†å†³ç­–æ ‘å¼•å…¥åå¥½è´å¶æ–¯ä¼˜åŒ–ä½œä¸ºä»£ç†æ¨¡åž‹ï¼Œä¸ŽçŽ°æœ‰é«˜æ–¯è¿‡ç¨‹æ–¹æ³•ç›¸æ¯”ï¼Œæœ¬è´¨åŒºåˆ«åœ¨äºŽæä¾›äº†å†…åœ¨å¯è§£é‡Šæ€§ã€æ›´å¥½çš„åˆ†ç±»æ•°æ®å¤„ç†èƒ½åŠ›å’Œæ›´é«˜çš„è®¡ç®—æ•ˆçŽ‡ï¼ŒåŒæ—¶ä¿æŒäº†ç«žäº‰æ€§çš„ä¼˜åŒ–æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡åž‹é‡‡ç”¨å†³ç­–æ ‘ç®—æ³•ï¼ˆå¦‚CARTæˆ–C4.5ï¼‰ä½œä¸ºåŸºç¡€ï¼ŒæŸå¤±å‡½æ•°å¯èƒ½åŸºäºŽä¿¡æ¯å¢žç›Šæˆ–åŸºå°¼ä¸çº¯åº¦è¿›è¡ŒèŠ‚ç‚¹åˆ†è£‚ï¼Œå…³é”®å‚æ•°åŒ…æ‹¬æ ‘çš„æœ€å¤§æ·±åº¦ã€æœ€å°æ ·æœ¬åˆ†è£‚æ•°ç­‰ä»¥æŽ§åˆ¶è¿‡æ‹Ÿåˆï¼Œç½‘ç»œç»“æž„ä¸ºå•æ£µå†³ç­–æ ‘æˆ–é›†æˆæ–¹æ³•ï¼ˆå¦‚éšæœºæ£®æž—ï¼‰ä»¥æå‡é²æ£’æ€§ï¼Œå…·ä½“ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœªæ˜Žç¡®è¯´æ˜Žï¼Œä½†å¼ºè°ƒäº†å¯æ‰©å±•æ€§å’Œå¤„ç†æ··åˆæ•°æ®ç±»åž‹çš„èƒ½åŠ›ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨å…«ä¸ªé€æ¸å°–å³°çš„ä¼˜åŒ–å‡½æ•°å®žéªŒä¸­ï¼ŒåŸºäºŽå†³ç­–æ ‘çš„æ¨¡åž‹åœ¨å°–å³°å‡½æ•°ä¸Šæ˜¾è‘—ä¼˜äºŽé«˜æ–¯è¿‡ç¨‹åŸºçº¿ï¼Œå…·ä½“æ€§èƒ½æå‡å¹…åº¦æœªçŸ¥ï¼Œä½†è®ºæ–‡æŒ‡å‡ºåœ¨éžå°–å³°å‡½æ•°ä¸Šæ€§èƒ½ä»…ç•¥ä½Žã€‚å¯¿å¸æ•°æ®é›†åº”ç”¨æ˜¾ç¤ºæ¨¡åž‹èƒ½æœ‰æ•ˆå­¦ä¹ ä¸ªäººåå¥½ï¼ŒéªŒè¯äº†å®žé™…å¯ç”¨æ€§ã€‚æ­¤å¤–ï¼Œåˆæ­¥å·¥ä½œè¡¨æ˜Žåˆ©ç”¨åŽ†å²æ•°æ®å¯åŠ é€Ÿæ–°ç”¨æˆ·ä¼˜åŒ–ï¼Œä½†å…·ä½“åŠ é€Ÿæ•ˆæžœæœªé‡åŒ–ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨ä¸ªæ€§åŒ–æŽ¨èç³»ç»Ÿã€äº§å“è®¾è®¡ä¼˜åŒ–å’Œç”¨æˆ·åå¥½å»ºæ¨¡ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›åº”ç”¨æ½œåŠ›ã€‚ä¾‹å¦‚ï¼Œåœ¨ç”µå•†å¹³å°ä¸­ï¼Œå¯åŸºäºŽç”¨æˆ·åŽ†å²åå¥½å¿«é€Ÿå­¦ä¹ æ–°ç”¨æˆ·çš„å…´è¶£ï¼Œæå‡æŽ¨èå‡†ç¡®æ€§å’Œæ•ˆçŽ‡ï¼›åœ¨å·¥ä¸šè®¾è®¡ä¸­ï¼Œèƒ½ä¼˜åŒ–äº§å“å‚æ•°ä»¥æ»¡è¶³å¤šæ ·åŒ–ç”¨æˆ·éœ€æ±‚ã€‚æœªæ¥å¯èƒ½æŽ¨åŠ¨å¯è§£é‡ŠAIåœ¨äº¤äº’å¼ä¼˜åŒ–ä»»åŠ¡ä¸­çš„æ™®åŠï¼Œå¢žå¼ºç”¨æˆ·ä¿¡ä»»å’Œç³»ç»Ÿé€æ˜Žåº¦ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Current Preferential Bayesian Optimization methods rely on Gaussian Processes (GPs) as surrogate models. These models are hard to interpret, struggle with handling categorical data, and are computationally complex, limiting their real-world usability. In this paper, we introduce an inherently interpretable decision tree-based surrogate model capable of handling both categorical and continuous data, and scalable to large datasets. Extensive numerical experiments on eight increasingly spiky optimization functions show that our model outperforms GP-based alternatives on spiky functions and has only marginally lower performance for non-spiky functions. Moreover, we apply our model to the real-world Sushi dataset and show its ability to learn an individual's sushi preferences. Finally, we show some initial work on using historical preference data to speed up the optimization process for new unseen users.

