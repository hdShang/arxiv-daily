---
layout: default
title: Made-in China, Thinking in America:U.S. Values Persist in Chinese LLMs
---

# Made-in China, Thinking in America:U.S. Values Persist in Chinese LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.13723" class="toolbar-btn" target="_blank">📄 arXiv: 2512.13723</a>
  <a href="https://arxiv.org/pdf/2512.13723.pdf" class="toolbar-btn" target="_blank">📥 PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.13723" onclick="toggleFavorite(this, '2512.13723', 'Made-in China, Thinking in America:U.S. Values Persist in Chinese LLMs')" title="添加到收藏夹">☆ 收藏</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">🔗 分享</button>
</div>


**作者**: David Haslett, Linus Ta-Lun Huang, Leila Khalatbari, Janet Hui-wen Hsiao, Antoni B. Chan

**分类**: cs.CY, cs.AI

**发布日期**: 2025-12-18

---

## 💡 一句话要点

**揭示中美大型语言模型中的文化价值观差异：中国模型更趋近美国价值观**

🎯 **匹配领域**: **支柱九：具身大模型 (Embodied Foundation Models)**

**关键词**: `大型语言模型` `价值观偏向` `文化差异` `道德基础` `地缘政治`

## 📋 核心要点

1. 现有研究主要关注美国公司开发的LLM的价值观偏向，缺乏对中国LLM的系统性评估，无法全面了解LLM的价值观分布。
2. 该研究通过对比中美LLM在道德和价值观问卷上的表现，揭示了中国LLM可能存在的价值观偏向，并分析了其潜在原因。
3. 实验结果表明，即使是中国开发的LLM，其价值观也更接近美国人群，这对于未来LLM的应用和地缘政治具有重要意义。

## 📝 摘要（中文）

随着大型语言模型在信息获取和决策制定中扮演越来越重要的角色，它们正成为美国和中国等全球参与者之间软实力竞争的工具。目前，语言模型似乎与西方国家的价值观保持一致，但这种伦理偏差的证据主要来自美国公司制造的模型。当前最先进的模型包括一些中国制造的模型，因此我们首次大规模调查了中国和美国制造的模型如何与中国和美国的人保持一致。我们从十个中国模型和十个美国模型中获得了对道德基础问卷2.0和世界价值观调查的回复，并将他们的回复与来自数千名中国和美国人的回复进行了比较。我们发现，所有模型对两项调查的回复都更像美国人，而不是中国人。当用中文提示模型或对模型施加中国角色时，这种对美国价值观的倾斜仅略有缓解。这些发现对于不久的将来具有重要意义，在不久的将来，大型语言模型将生成人们消费的大部分内容，并塑造地缘政治中的规范影响力。

## 🔬 方法详解

**问题定义**：现有的大型语言模型（LLM）在信息传播和决策支持中扮演着日益重要的角色，因此其价值观偏向性成为一个关键问题。之前的研究主要集中在美国公司开发的LLM，缺乏对中国LLM的深入分析。因此，该研究旨在调查中国制造的LLM是否也存在价值观偏向，以及这种偏向与中美两国人群的价值观有何差异。现有方法的痛点在于缺乏对中国LLM的系统性评估，无法全面了解LLM的价值观分布。

**核心思路**：该研究的核心思路是通过对比中美两国LLM在标准化的价值观问卷上的表现，来评估其价值观偏向性。具体而言，研究者使用了道德基础问卷2.0（Moral Foundations Questionnaire 2.0）和世界价值观调查（World Values Survey）这两个广泛使用的问卷，来量化LLM和人类的价值观。通过比较LLM和中美两国人群的问卷结果，可以确定LLM的价值观更接近哪一方。

**技术框架**：该研究的技术框架主要包括以下几个步骤：1）选择10个中国制造的LLM和10个美国制造的LLM；2）使用道德基础问卷2.0和世界价值观调查对这些LLM进行评估，收集LLM的回复；3）收集数千名中国和美国人的问卷回复作为基准；4）比较LLM和中美两国人群的问卷结果，分析LLM的价值观偏向性；5）通过中文提示和角色扮演等方式，尝试缓解LLM的价值观偏向。

**关键创新**：该研究最重要的技术创新点在于首次大规模地对中国制造的LLM的价值观偏向性进行了评估。之前的研究主要集中在美国LLM，缺乏对中国LLM的关注。该研究填补了这一空白，为理解LLM的价值观分布提供了新的视角。与现有方法的本质区别在于，该研究关注的是中国LLM，而不是美国LLM。

**关键设计**：在实验设计方面，研究者精心选择了道德基础问卷2.0和世界价值观调查这两个问卷，以全面评估LLM的价值观。此外，研究者还尝试了不同的提示策略，例如使用中文提示和角色扮演，以观察这些策略是否能够缓解LLM的价值观偏向。在数据分析方面，研究者使用了统计方法来比较LLM和中美两国人群的问卷结果，以确定LLM的价值观更接近哪一方。

## 🖼️ 关键图片

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.13723/fig1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.13723/fig2.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.13723/fig3.png" alt="fig_2" loading="lazy">
</figure>
</div>

## 📊 实验亮点

研究发现，所有模型（包括中国制造的模型）在道德基础问卷和世界价值观调查中的回复都更接近美国人，而非中国人。即使使用中文提示或赋予模型中国角色，这种偏向也仅略有缓解。这表明，当前的大型语言模型可能存在普遍的价值观偏向，更倾向于美国价值观。

## 🎯 应用场景

该研究的潜在应用领域包括：评估和校准LLM的价值观，以确保其符合特定文化或伦理标准；开发更具文化敏感性的LLM，以更好地服务于不同文化背景的用户；理解LLM如何影响人们的价值观和信念。实际价值在于帮助我们更好地理解LLM的价值观偏向，并采取措施来缓解这些偏向。未来影响在于塑造更负责任和公正的LLM技术，以促进全球范围内的文化理解和合作。

## 📄 摘要（原文）

> As large language models increasingly mediate access to information and facilitate decision-making, they are becoming instruments in soft power competitions between global actors such as the United States and China. So far, language models seem to be aligned with the values of Western countries, but evidence for this ethical bias comes mostly from models made by American companies. The current crop of state-of-the-art models includes several made in China, so we conducted the first large-scale investigation of how models made in China and the USA align with people from China and the USA. We elicited responses to the Moral Foundations Questionnaire 2.0 and the World Values Survey from ten Chinese models and ten American models, and we compared their responses to responses from thousands of Chinese and American people. We found that all models respond to both surveys more like American people than like Chinese people. This skew toward American values is only slightly mitigated when prompting the models in Chinese or imposing a Chinese persona on the models. These findings have important implications for a near future in which large language models generate much of the content people consume and shape normative influence in geopolitics.

