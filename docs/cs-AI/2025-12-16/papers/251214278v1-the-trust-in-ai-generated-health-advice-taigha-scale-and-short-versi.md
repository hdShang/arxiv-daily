---
layout: default
title: The Trust in AI-Generated Health Advice (TAIGHA) Scale and Short Version (TAIGHA-S): Development and Validation Study
---

# The Trust in AI-Generated Health Advice (TAIGHA) Scale and Short Version (TAIGHA-S): Development and Validation Study

**arXiv**: [2512.14278v1](https://arxiv.org/abs/2512.14278) | [PDF](https://arxiv.org/pdf/2512.14278.pdf)

**作者**: Marvin Kopka, Azeem Majeed, Gabriella Spinelli, Austen El-Osta, Markus Feufel

**分类**: cs.HC, cs.AI

**发布日期**: 2025-12-16

---

## 💡 一句话要点

**提出TAIGHA和TAIGHA-S量表，专门评估用户对AI生成健康建议的信任与不信任，以解决现有工具缺乏针对性测量的问题。**

🎯 **匹配领域**: **强化学习**

**关键词**: `AI生成健康建议` `信任量表` `心理测量验证` `内容效度` `结构效度` `人机交互` `医疗人工智能` `量表开发`

## 📋 核心要点

1. 核心问题：现有通用技术信任量表无法专门测量用户对AI生成健康建议的信任，缺乏针对性工具，而健康建议的采纳与否具有直接临床意义。
2. 方法要点：基于理论构建信任与不信任双维度量表，每个维度包含认知和情感成分，采用生成式AI辅助项目开发，并通过多阶段验证确保效度和信度。
3. 实验或效果：TAIGHA量表显示出优异的内容效度、结构效度和内部一致性，与相关工具高度相关，简短版TAIGHA-S与完整量表高度相关且可靠性良好。

## 📝 摘要（中文）

随着大型语言模型等人工智能工具被公众越来越多地用于获取健康信息和指导，在健康相关情境中，采纳或拒绝AI生成建议可能产生直接的临床影响。现有工具如“自动化系统信任调查”评估通用技术的可信度，但缺乏专门测量用户对AI生成健康建议信任度的验证工具。本研究开发并验证了“AI生成健康建议信任量表”及其四项目简短版，作为基于理论的工具，分别测量信任和不信任，每个维度包含认知和情感成分。项目开发采用生成式AI方法，随后进行内容验证、表面验证和心理测量验证。TAIGHA显示出优异的内容效度和结构效度，内部一致性高，与相关工具具有收敛效度，与无关变量具有区分效度。TAIGHA-S与完整量表高度相关且可靠性良好。TAIGHA和TAIGHA-S是评估用户对AI生成健康建议信任与不信任的有效工具，单独报告信任和不信任允许更全面地评估AI干预措施，简短量表适用于时间受限的场景。

## 🔬 方法详解

**问题定义**：论文旨在解决用户对AI生成健康建议的信任度测量问题。现有方法的痛点在于，如“自动化系统信任调查”等工具评估的是通用技术的可信度，缺乏专门针对AI生成健康建议这一特定场景的验证工具，而健康建议的采纳与否可能直接影响临床决策，因此需要更精准的测量工具。

**核心思路**：论文的核心解决思路是开发一个基于理论的量表，专门测量用户对AI生成健康建议的信任与不信任。设计上，将信任和不信任作为两个独立维度，每个维度进一步细分为认知和情感成分，以全面捕捉用户的心理状态。这样设计是因为信任和不信任可能同时存在，单独测量能提供更完整的评估，而区分认知和情感成分有助于深入理解信任的构成。

**技术框架**：整体架构包括四个主要阶段：项目开发、内容验证、表面验证和心理测量验证。首先，使用生成式AI方法生成初始项目池；然后，通过10名领域专家进行内容验证，确保项目与理论维度匹配；接着，由30名普通参与者进行表面验证，评估项目的可理解性；最后，在385名英国参与者中进行心理测量验证，参与者在一个症状评估场景中接收AI生成建议，并完成量表测试，通过自动化项目缩减和专家评分，最终保留10个项目形成TAIGHA量表，并衍生出四项目简短版TAIGHA-S。

**关键创新**：最重要的技术创新点是开发了首个专门针对AI生成健康建议的信任量表，将信任和不信任作为独立维度进行测量，并整合认知和情感成分。与现有方法的本质区别在于，现有工具如“自动化系统信任调查”是通用性的，而TAIGHA专注于健康建议这一高风险场景，提供了更情境化和精细化的测量，有助于更准确地评估AI干预在医疗领域的实际影响。

**关键设计**：关键设计包括：量表基于理论构建，信任和不信任各包含认知和情感子维度；项目开发采用生成式AI辅助，确保项目多样性和覆盖度；验证过程中，使用内容效度指数评估专家一致性，通过验证性因子分析确认双因子模型结构，计算内部一致性系数评估信度，并通过相关性分析检验收敛效度和区分效度；具体参数如S-CVI/Ave=0.99用于内容效度，CFI=0.98、TLI=0.98、RMSEA=0.07、SRMR=0.03用于模型拟合，α=0.95用于内部一致性。

## 📊 实验亮点

最重要的实验结果包括：TAIGHA量表显示出优异的内容效度（S-CVI/Ave=0.99）和结构效度（CFI=0.98, TLI=0.98, RMSEA=0.07, SRMR=0.03），内部一致性高（α=0.95）。收敛效度得到支持，与“自动化系统信任调查”高度相关（r=0.67/-0.66），与用户对AI建议的依赖度相关（r=0.37 for trust）；区分效度得到支持，与阅读流畅度和心理负荷相关性低（所有\|r\|<0.25）。TAIGHA-S与完整量表高度相关（r=0.96），且可靠性良好（α=0.88）。

## 🎯 应用场景

该研究的潜在应用领域包括医疗健康、人工智能伦理和人机交互。实际价值在于为评估AI生成健康建议的可接受性和有效性提供标准化工具，帮助开发者和医疗机构优化AI系统设计，提升用户采纳率，减少误用风险。未来影响可能推动AI在健康咨询中的更安全集成，支持个性化医疗建议的信任度监测，并为政策制定提供数据支持。

## 📄 摘要（原文）

> Artificial Intelligence tools such as large language models are increasingly used by the public to obtain health information and guidance. In health-related contexts, following or rejecting AI-generated advice can have direct clinical implications. Existing instruments like the Trust in Automated Systems Survey assess trustworthiness of generic technology, and no validated instrument measures users' trust in AI-generated health advice specifically. This study developed and validated the Trust in AI-Generated Health Advice (TAIGHA) scale and its four-item short form (TAIGHA-S) as theory-based instruments measuring trust and distrust, each with cognitive and affective components. The items were developed using a generative AI approach, followed by content validation with 10 domain experts, face validation with 30 lay participants, and psychometric validation with 385 UK participants who received AI-generated advice in a symptom-assessment scenario. After automated item reduction, 28 items were retained and reduced to 10 based on expert ratings. TAIGHA showed excellent content validity (S-CVI/Ave=0.99) and CFA confirmed a two-factor model with excellent fit (CFI=0.98, TLI=0.98, RMSEA=0.07, SRMR=0.03). Internal consistency was high (α=0.95). Convergent validity was supported by correlations with the Trust in Automated Systems Survey (r=0.67/-0.66) and users' reliance on the AI's advice (r=0.37 for trust), while divergent validity was supported by low correlations with reading flow and mental load (all \|r\|<0.25). TAIGHA-S correlated highly with the full scale (r=0.96) and showed good reliability (α=0.88). TAIGHA and TAIGHA-S are validated instruments for assessing user trust and distrust in AI-generated health advice. Reporting trust and distrust separately permits a more complete evaluation of AI interventions, and the short scale is well-suited for time-constrained settings.

