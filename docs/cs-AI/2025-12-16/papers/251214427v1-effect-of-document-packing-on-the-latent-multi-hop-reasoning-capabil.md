---
layout: default
title: Effect of Document Packing on the Latent Multi-Hop Reasoning Capabilities of Large Language Models
---

# Effect of Document Packing on the Latent Multi-Hop Reasoning Capabilities of Large Language Models

**arXiv**: [2512.14427v1](https://arxiv.org/abs/2512.14427) | [PDF](https://arxiv.org/pdf/2512.14427.pdf)

**ä½œè€…**: Gabriele Prato, Shagun Sodhani, Alessandro Sordoni, Sarath Chandar

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç ”ç©¶æ–‡æ¡£æ‰“åŒ…ç­–ç•¥å¯¹å¤§åž‹è¯­è¨€æ¨¡åž‹æ½œåœ¨å¤šè·³æŽ¨ç†èƒ½åŠ›çš„å½±å“ï¼Œä»¥ä¼˜åŒ–è®­ç»ƒæ•ˆçŽ‡ä¸Žæ€§èƒ½**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **è§†è§‰é‡Œç¨‹è®¡** **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `æ–‡æ¡£æ‰“åŒ…ç­–ç•¥` `å¤§åž‹è¯­è¨€æ¨¡åž‹` `å¤šè·³æŽ¨ç†èƒ½åŠ›` `è®­ç»ƒä¼˜åŒ–` `æ¶ˆèžç ”ç©¶` `è®¡ç®—æ•ˆçŽ‡` `æ¨¡åž‹æ€§èƒ½è¯„ä¼°` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰è®­ç»ƒæ–¹æ³•ä¸­ï¼Œæ–‡æ¡£æ‰“åŒ…ç­–ç•¥å¯¹å¤§åž‹è¯­è¨€æ¨¡åž‹æ½œåœ¨å¤šè·³æŽ¨ç†èƒ½åŠ›çš„å½±å“æœªçŸ¥ï¼Œç¼ºä¹ç³»ç»Ÿç ”ç©¶ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡å¯¹æ¯”ä¸åŒæ–‡æ¡£æ‰“åŒ…ç­–ç•¥ï¼Œåˆ†æžå…¶å¯¹æ¨¡åž‹æ€§èƒ½çš„å½±å“ï¼Œå¹¶è¿›è¡Œæ¶ˆèžç ”ç©¶ä»¥è¯†åˆ«å…³é”®å› ç´ ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæ‰“åŒ…ç­–ç•¥èƒ½æå‡æ¨¡åž‹æ€§èƒ½ï¼Œä½†éœ€æ›´å¤šè®¡ç®—ï¼›æ¶ˆèžç ”ç©¶æ­ç¤ºäº†æ‰“åŒ…ä¼˜åŠ¿çš„æœºåˆ¶ï¼Œä¸ºä¼˜åŒ–è®­ç»ƒæä¾›æŒ‡å¯¼ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è®­ç»ƒå¤§åž‹è¯­è¨€æ¨¡åž‹çš„æ ‡å‡†å®žè·µé€šå¸¸æ¶‰åŠå°†å¤šä¸ªæ–‡æ¡£æ‰“åŒ…åœ¨ä¸€èµ·ï¼Œä»¥æé«˜è®¡ç®—æ•ˆçŽ‡ã€‚ç„¶è€Œï¼Œè¿™ä¸€è¿‡ç¨‹å¯¹æ¨¡åž‹èƒ½åŠ›çš„å½±å“åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå°šæœªè¢«æŽ¢ç´¢ã€‚ä¸ºå¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬ç ”ç©¶äº†ä¸åŒæ–‡æ¡£æ‰“åŒ…ç­–ç•¥å¦‚ä½•å½±å“LLMsçš„æ½œåœ¨å¤šè·³æŽ¨ç†èƒ½åŠ›ã€‚æˆ‘ä»¬çš„å‘çŽ°è¡¨æ˜Žï¼Œä¸Žåœ¨å•ä¸ªæ–‡æ¡£ä¸Šè®­ç»ƒç›¸æ¯”ï¼Œæ‰“åŒ…å¯ä»¥æé«˜æ¨¡åž‹æ€§èƒ½ï¼Œä½†éœ€è¦æ›´å¤šçš„è®¡ç®—èµ„æºã€‚ä¸ºäº†è¿›ä¸€æ­¥ç†è§£åº•å±‚æœºåˆ¶ï¼Œæˆ‘ä»¬è¿›è¡Œäº†æ¶ˆèžç ”ç©¶ï¼Œè¯†åˆ«äº†è§£é‡Šæ‰“åŒ…ä¼˜åŠ¿çš„å…³é”®å› ç´ ã€‚æœ€ç»ˆï¼Œæˆ‘ä»¬çš„ç ”ç©¶æ·±åŒ–äº†å¯¹LLMè®­ç»ƒåŠ¨æ€çš„ç†è§£ï¼Œå¹¶ä¸ºä¼˜åŒ–æ¨¡åž‹å¼€å‘æä¾›äº†å®žç”¨è§è§£ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§åž‹è¯­è¨€æ¨¡åž‹è®­ç»ƒä¸­ï¼Œæ–‡æ¡£æ‰“åŒ…ç­–ç•¥å¯¹æ¨¡åž‹æ½œåœ¨å¤šè·³æŽ¨ç†èƒ½åŠ›çš„å…·ä½“å½±å“é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•çš„ç—›ç‚¹åœ¨äºŽï¼Œæ ‡å‡†è®­ç»ƒå®žè·µé€šå¸¸åŸºäºŽè®¡ç®—æ•ˆçŽ‡è€ƒè™‘ï¼Œå°†å¤šä¸ªæ–‡æ¡£æ‰“åŒ…å¤„ç†ï¼Œä½†è¿™ä¸€è¿‡ç¨‹å¯¹æ¨¡åž‹èƒ½åŠ›ï¼ˆç‰¹åˆ«æ˜¯å¤šè·³æŽ¨ç†èƒ½åŠ›ï¼‰çš„å½±å“å°šæœªè¢«ç³»ç»Ÿç ”ç©¶ï¼Œå¯¼è‡´è®­ç»ƒä¼˜åŒ–ç¼ºä¹ç†è®ºä¾æ®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒè§£å†³æ€è·¯æ˜¯é€šè¿‡å®žéªŒå¯¹æ¯”ä¸åŒæ–‡æ¡£æ‰“åŒ…ç­–ç•¥ï¼Œè¯„ä¼°å…¶å¯¹æ¨¡åž‹æ€§èƒ½çš„å½±å“ï¼Œå¹¶æ·±å…¥åˆ†æžåº•å±‚æœºåˆ¶ã€‚è¿™æ ·è®¾è®¡æ˜¯ä¸ºäº†å¡«è¡¥ç ”ç©¶ç©ºç™½ï¼Œä»Žå®žè¯è§’åº¦ç†è§£æ‰“åŒ…ç­–ç•¥å¦‚ä½•å¡‘é€ æ¨¡åž‹èƒ½åŠ›ï¼Œä»Žè€Œä¸ºè®­ç»ƒä¼˜åŒ–æä¾›æ•°æ®æ”¯æŒã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æž¶æž„åŒ…æ‹¬æ•°æ®å‡†å¤‡ã€æ¨¡åž‹è®­ç»ƒã€æ€§èƒ½è¯„ä¼°å’Œæ¶ˆèžåˆ†æžå››ä¸ªä¸»è¦é˜¶æ®µã€‚é¦–å…ˆï¼Œå‡†å¤‡ä¸åŒæ‰“åŒ…ç­–ç•¥çš„æ•°æ®é›†ï¼›ç„¶åŽï¼Œåœ¨å¤§åž‹è¯­è¨€æ¨¡åž‹ä¸Šè¿›è¡Œè®­ç»ƒï¼›æŽ¥ç€ï¼Œé€šè¿‡å¤šè·³æŽ¨ç†ä»»åŠ¡è¯„ä¼°æ¨¡åž‹æ€§èƒ½ï¼›æœ€åŽï¼Œè¿›è¡Œæ¶ˆèžç ”ç©¶ä»¥è¯†åˆ«å½±å“æ€§èƒ½çš„å…³é”®å› ç´ ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽé¦–æ¬¡ç³»ç»Ÿç ”ç©¶æ–‡æ¡£æ‰“åŒ…ç­–ç•¥å¯¹LLMæ½œåœ¨å¤šè·³æŽ¨ç†èƒ½åŠ›çš„å½±å“ï¼Œå¹¶é€šè¿‡æ¶ˆèžåˆ†æžæ­ç¤ºå…¶æœºåˆ¶ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºŽï¼ŒçŽ°æœ‰ç ”ç©¶å¤šå…³æ³¨è®­ç»ƒæ•ˆçŽ‡ï¼Œè€Œæœ¬æ–‡èšç„¦äºŽèƒ½åŠ›å½±å“ï¼Œæä¾›äº†æ›´å…¨é¢çš„è®­ç»ƒåŠ¨æ€ç†è§£ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬å®šä¹‰ä¸åŒçš„æ–‡æ¡£æ‰“åŒ…ç­–ç•¥ï¼ˆå¦‚åŸºäºŽé•¿åº¦ã€å†…å®¹æˆ–éšæœºæ‰“åŒ…ï¼‰ï¼Œä½¿ç”¨æ ‡å‡†çš„å¤šè·³æŽ¨ç†è¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚å‡†ç¡®çŽ‡æˆ–F1åˆ†æ•°ï¼‰ï¼Œå¹¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç›‘æŽ§è®¡ç®—èµ„æºæ¶ˆè€—ã€‚æ¶ˆèžç ”ç©¶å¯èƒ½æ¶‰åŠè°ƒæ•´æ‰“åŒ…å‚æ•°ï¼ˆå¦‚æ–‡æ¡£æ•°é‡æˆ–é¡ºåºï¼‰ï¼Œä»¥åˆ†æžå…¶å¯¹æ€§èƒ½çš„å…·ä½“è´¡çŒ®ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

æœ€é‡è¦çš„å®žéªŒç»“æžœè¡¨æ˜Žï¼Œä¸Žåœ¨å•ä¸ªæ–‡æ¡£ä¸Šè®­ç»ƒç›¸æ¯”ï¼Œæ–‡æ¡£æ‰“åŒ…ç­–ç•¥èƒ½æ˜¾è‘—æå‡å¤§åž‹è¯­è¨€æ¨¡åž‹åœ¨å¤šè·³æŽ¨ç†ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œå…·ä½“æå‡å¹…åº¦æœªçŸ¥ï¼Œä½†éœ€æ›´å¤šè®¡ç®—èµ„æºã€‚æ¶ˆèžç ”ç©¶è¯†åˆ«äº†å…³é”®å› ç´ ï¼ˆå¦‚æ‰“åŒ…é¡ºåºå’Œæ–‡æ¡£å¤šæ ·æ€§ï¼‰ï¼Œè§£é‡Šäº†æ‰“åŒ…ä¼˜åŠ¿çš„æœºåˆ¶ã€‚å¯¹æ¯”åŸºçº¿åŒ…æ‹¬æ ‡å‡†è®­ç»ƒæ–¹æ³•ï¼Œç»“æžœå¼ºè°ƒäº†æ‰“åŒ…ç­–ç•¥å¯¹æ¨¡åž‹èƒ½åŠ›å¡‘é€ çš„é‡è¦æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤§åž‹è¯­è¨€æ¨¡åž‹çš„è®­ç»ƒä¼˜åŒ–ã€è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ï¼ˆå¦‚é—®ç­”å’ŒæŽ¨ç†ç³»ç»Ÿï¼‰çš„å¼€å‘ï¼Œä»¥åŠäººå·¥æ™ºèƒ½æ•™è‚²å·¥å…·çš„æ”¹è¿›ã€‚å®žé™…ä»·å€¼åœ¨äºŽä¸ºæ¨¡åž‹å¼€å‘è€…æä¾›åŸºäºŽå®žè¯çš„æ‰“åŒ…ç­–ç•¥æŒ‡å¯¼ï¼Œä»¥å¹³è¡¡è®¡ç®—æ•ˆçŽ‡ä¸Žæ¨¡åž‹æ€§èƒ½ï¼Œä»Žè€Œé™ä½Žè®­ç»ƒæˆæœ¬å¹¶æå‡æ¨¡åž‹èƒ½åŠ›ã€‚æœªæ¥å½±å“å¯èƒ½æŽ¨åŠ¨æ›´æ™ºèƒ½çš„è®­ç»ƒæ–¹æ³•è®¾è®¡ï¼Œä¿ƒè¿›LLMåœ¨å¤æ‚æŽ¨ç†ä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The standard practice for training large language models involves packing multiple documents together to optimize computational efficiency. However, the impact of this process on the models' capabilities remains largely unexplored. To address this gap, we investigate how different document-packing strategies influence the latent multi-hop reasoning abilities of LLMs. Our findings indicate that packing can improve model performance compared to training on individual documents, at the expense of more compute. To further understand the underlying mechanisms, we conduct an ablation study, identifying key factors that explain the advantages of packing. Ultimately, our research deepens the understanding of LLM training dynamics and provides practical insights for optimizing model development.

