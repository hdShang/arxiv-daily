---
layout: default
title: Context-Picker: Dynamic context selection using multi-stage reinforcement learning
---

# Context-Picker: Dynamic context selection using multi-stage reinforcement learning

**arXiv**: [2512.14465v1](https://arxiv.org/abs/2512.14465) | [PDF](https://arxiv.org/pdf/2512.14465.pdf)

**ä½œè€…**: Siyuan Zhu, Chengdong Xu, Kaiqiang Ke, Chao Yu

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Context-Pickerï¼šåˆ©ç”¨å¤šé˜¶æ®µå¼ºåŒ–å­¦ä¹ åŠ¨æ€é€‰æ‹©é•¿æ–‡æœ¬é—®ç­”ä¸Šä¸‹æ–‡**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å¼ºåŒ–å­¦ä¹ ä¸Žæ¨¡ä»¿å­¦ä¹  (RL & IL)**

**å…³é”®è¯**: `é•¿æ–‡æœ¬é—®ç­”` `å¼ºåŒ–å­¦ä¹ ` `ä¸Šä¸‹æ–‡é€‰æ‹©` `å¤šé˜¶æ®µå­¦ä¹ ` `è¯æ®æç‚¼`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. é•¿æ–‡æœ¬é—®ç­”ä¸­ï¼Œå¦‚ä½•é€‰æ‹©æ—¢åŒ…å«è¶³å¤Ÿä¿¡æ¯åˆé¿å…å™ªå£°å¹²æ‰°çš„æœ€ä½³ä¸Šä¸‹æ–‡æ˜¯ä¸€ä¸ªæ ¸å¿ƒæŒ‘æˆ˜ã€‚
2. Context-Pickeré‡‡ç”¨ä¸¤é˜¶æ®µå¼ºåŒ–å­¦ä¹ ï¼Œé¦–å…ˆå…³æ³¨æŽ¨ç†é“¾çš„å®Œæ•´æ€§ï¼Œç„¶åŽç²¾ç®€å†—ä½™ä¿¡æ¯ï¼Œé€‰æ‹©æœ€å°å……åˆ†å­é›†ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒContext-Pickeråœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†çŽ°æœ‰RAGæ–¹æ³•ï¼Œæé«˜äº†ç­”æ¡ˆå‡†ç¡®æ€§å¹¶å‡å°‘äº†ä¸Šä¸‹æ–‡é•¿åº¦ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨é•¿æ–‡æœ¬é—®ç­”(LCQA)ä¸­ï¼Œç¡®å®šç»™å®šæŸ¥è¯¢çš„æœ€ä½³ä¸Šä¸‹æ–‡æ•°é‡æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ã€‚åŒ…å«è¿‡å°‘çš„æ®µè½å¯èƒ½é—æ¼å…³é”®ä¿¡æ¯ï¼Œè€ŒåŒ…å«è¿‡å¤šçš„æ®µè½ä¼šå¼•å…¥å™ªå£°å¹¶é™ä½Žç­”æ¡ˆè´¨é‡ã€‚ä¼ ç»Ÿçš„Top-$K$æ£€ç´¢å’Œå•é˜¶æ®µé‡æŽ’åºç­‰æ–¹æ³•é¢ä¸´ç€é€‰æ‹©åˆé€‚æ®µè½æ•°é‡çš„å›°å¢ƒã€‚å¯¹äºŽé€šå¸¸åªéœ€è¦å°‘é‡ç‰¹å®šè¯æ®çš„äº‹å®žæ€§é—®é¢˜ï¼Œè¿™ä¸ªé—®é¢˜å°¤ä¸ºçªå‡ºã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†Context-Pickerï¼Œè¿™æ˜¯ä¸€ä¸ªæŽ¨ç†æ„ŸçŸ¥çš„æ¡†æž¶ï¼Œå®ƒå°†èŒƒå¼ä»ŽåŸºäºŽç›¸ä¼¼åº¦çš„æŽ’åºè½¬å˜ä¸ºæœ€å°å……åˆ†å­é›†é€‰æ‹©ã€‚Context-Pickerå°†ä¸Šä¸‹æ–‡é€‰æ‹©è§†ä¸ºä¸€ä¸ªå†³ç­–è¿‡ç¨‹ï¼Œé€šè¿‡å—äººç±»å¯å‘çš„ä¸¤é˜¶æ®µå¼ºåŒ–å­¦ä¹ ç­–ç•¥è¿›è¡Œä¼˜åŒ–ï¼šä¸€ä¸ªä»¥å¬å›žä¸ºå¯¼å‘çš„é˜¶æ®µï¼Œä¼˜å…ˆè€ƒè™‘æŽ¨ç†é“¾çš„è¦†ç›–ï¼›ç„¶åŽæ˜¯ä¸€ä¸ªä»¥ç²¾ç¡®ä¸ºå¯¼å‘çš„é˜¶æ®µï¼Œç§¯æžåœ°ä¿®å‰ªå†—ä½™ä»¥æç‚¼å‡ºä¸€ä¸ªç´§å‡‘çš„è¯æ®é›†ã€‚ä¸ºäº†è§£å†³å¥–åŠ±ç¨€ç–æ€§é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç¦»çº¿è¯æ®æç‚¼æµç¨‹ï¼Œé€šè¿‡ç•™ä¸€æ³•(LOO)æŒ–æŽ˜â€œæœ€å°å……åˆ†é›†â€ï¼Œæä¾›å¯†é›†çš„ã€ä»»åŠ¡å¯¹é½çš„ç›‘ç£ã€‚åœ¨äº”ä¸ªé•¿æ–‡æœ¬å’Œå¤šè·³é—®ç­”åŸºå‡†ä¸Šçš„å®žéªŒè¡¨æ˜Žï¼ŒContext-Pickeræ˜¾è‘—ä¼˜äºŽå¼ºå¤§çš„RAGåŸºçº¿ï¼Œä»¥ç›¸å½“æˆ–æ›´çŸ­çš„ä¸Šä¸‹æ–‡é•¿åº¦å®žçŽ°äº†å“è¶Šçš„ç­”æ¡ˆå‡†ç¡®æ€§ã€‚æ¶ˆèžç ”ç©¶è¡¨æ˜Žï¼Œç”±ç²—åˆ°ç²¾çš„ä¼˜åŒ–ç­–ç•¥ã€å†—ä½™æ„ŸçŸ¥çš„å¥–åŠ±å¡‘é€ å’Œä»¥åŽŸç†ä¸ºæŒ‡å¯¼çš„æ ¼å¼éƒ½å¯¹è¿™äº›æ”¶ç›Šåšå‡ºäº†é‡å¤§è´¡çŒ®ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šé•¿æ–‡æœ¬é—®ç­”(LCQA)ä»»åŠ¡ä¸­ï¼Œå¦‚ä½•ä»Žå¤§é‡æ–‡æ¡£ä¸­é€‰æ‹©æœ€ç›¸å…³çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»¥æé«˜ç­”æ¡ˆçš„å‡†ç¡®æ€§å’Œæ•ˆçŽ‡ã€‚çŽ°æœ‰æ–¹æ³•ï¼Œå¦‚å›ºå®šTop-Kæ£€ç´¢ï¼Œè¦ä¹ˆå¯èƒ½é—æ¼å…³é”®ä¿¡æ¯ï¼Œè¦ä¹ˆå¼•å…¥è¿‡å¤šå™ªå£°ï¼Œå½±å“æ¨¡åž‹æ€§èƒ½ã€‚ç‰¹åˆ«æ˜¯å¯¹äºŽéœ€è¦ç²¾ç¡®è¯æ®çš„äº‹å®žæ€§é—®é¢˜ï¼Œé€‰æ‹©åˆé€‚çš„ä¸Šä¸‹æ–‡å­é›†è‡³å…³é‡è¦ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šå°†ä¸Šä¸‹æ–‡é€‰æ‹©è§†ä¸ºä¸€ä¸ªå†³ç­–è¿‡ç¨‹ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ æ¥ä¼˜åŒ–ã€‚æ¨¡ä»¿äººç±»çš„æŽ¨ç†è¿‡ç¨‹ï¼Œé‡‡ç”¨ä¸¤é˜¶æ®µç­–ç•¥ï¼šé¦–å…ˆï¼Œå°½å¯èƒ½å¬å›žæ‰€æœ‰å¯èƒ½ç›¸å…³çš„è¯æ®ï¼›ç„¶åŽï¼ŒåŽ»é™¤å†—ä½™ä¿¡æ¯ï¼Œæç‚¼å‡ºæœ€å°å……åˆ†çš„è¯æ®é›†åˆã€‚è¿™ç§ç”±ç²—åˆ°ç²¾çš„æ–¹æ³•æ—¨åœ¨å¹³è¡¡å¬å›žçŽ‡å’Œç²¾ç¡®çŽ‡ï¼Œä»Žè€Œæé«˜é—®ç­”ç³»ç»Ÿçš„æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šContext-Pickeræ¡†æž¶åŒ…å«ä¸¤ä¸ªä¸»è¦çš„å¼ºåŒ–å­¦ä¹ é˜¶æ®µï¼šå¬å›žé˜¶æ®µå’Œç²¾ç¡®é˜¶æ®µã€‚åœ¨å¬å›žé˜¶æ®µï¼Œæ¨¡åž‹çš„ç›®æ ‡æ˜¯å°½å¯èƒ½è¦†ç›–æ‰€æœ‰å¯èƒ½ç›¸å…³çš„æŽ¨ç†é“¾ï¼Œé¿å…é—æ¼å…³é”®ä¿¡æ¯ã€‚åœ¨ç²¾ç¡®é˜¶æ®µï¼Œæ¨¡åž‹çš„ç›®æ ‡æ˜¯åŽ»é™¤å†—ä½™ä¿¡æ¯ï¼Œå‡å°‘å™ªå£°å¹²æ‰°ï¼Œæé«˜ç­”æ¡ˆçš„å‡†ç¡®æ€§ã€‚ä¸ºäº†è§£å†³å¥–åŠ±ç¨€ç–æ€§é—®é¢˜ï¼Œè®ºæ–‡è¿˜æå‡ºäº†ä¸€ä¸ªç¦»çº¿è¯æ®æç‚¼æµç¨‹ï¼Œé€šè¿‡ç•™ä¸€æ³•(LOO)æŒ–æŽ˜â€œæœ€å°å……åˆ†é›†â€ï¼Œä¸ºå¼ºåŒ–å­¦ä¹ æä¾›å¯†é›†çš„ç›‘ç£ä¿¡å·ã€‚

**å…³é”®åˆ›æ–°**ï¼šContext-Pickerçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºŽå…¶ä¸¤é˜¶æ®µå¼ºåŒ–å­¦ä¹ ç­–ç•¥å’Œç¦»çº¿è¯æ®æç‚¼æµç¨‹ã€‚ä¸Žä¼ ç»Ÿçš„å•é˜¶æ®µæŽ’åºæ–¹æ³•ä¸åŒï¼ŒContext-Pickerèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å¹³è¡¡å¬å›žçŽ‡å’Œç²¾ç¡®çŽ‡ï¼Œä»Žè€Œé€‰æ‹©æ›´åˆé€‚çš„ä¸Šä¸‹æ–‡å­é›†ã€‚ç¦»çº¿è¯æ®æç‚¼æµç¨‹é€šè¿‡æŒ–æŽ˜â€œæœ€å°å……åˆ†é›†â€ï¼Œä¸ºå¼ºåŒ–å­¦ä¹ æä¾›äº†æ›´æœ‰æ•ˆçš„ç›‘ç£ä¿¡å·ï¼Œè§£å†³äº†å¥–åŠ±ç¨€ç–æ€§é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šContext-Pickerä½¿ç”¨ä¸¤é˜¶æ®µå¼ºåŒ–å­¦ä¹ ï¼Œæ¯ä¸ªé˜¶æ®µéƒ½æœ‰ä¸åŒçš„å¥–åŠ±å‡½æ•°ã€‚å¬å›žé˜¶æ®µçš„å¥–åŠ±å‡½æ•°ä¾§é‡äºŽè¦†ç›–æŽ¨ç†é“¾ï¼Œé¼“åŠ±æ¨¡åž‹é€‰æ‹©åŒ…å«å…³é”®ä¿¡æ¯çš„æ®µè½ã€‚ç²¾ç¡®é˜¶æ®µçš„å¥–åŠ±å‡½æ•°ä¾§é‡äºŽåŽ»é™¤å†—ä½™ä¿¡æ¯ï¼Œæƒ©ç½šæ¨¡åž‹é€‰æ‹©ä¸å¿…è¦çš„æ®µè½ã€‚ç¦»çº¿è¯æ®æç‚¼æµç¨‹ä½¿ç”¨ç•™ä¸€æ³•(LOO)æ¥ç¡®å®šæ¯ä¸ªæ®µè½çš„é‡è¦æ€§ï¼Œå¹¶æ ¹æ®é‡è¦æ€§æ¥è°ƒæ•´å¥–åŠ±å‡½æ•°ã€‚å…·ä½“çš„ç½‘ç»œç»“æž„å’Œå‚æ•°è®¾ç½®åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ï¼Œä½†æ­¤å¤„æ— æ³•å®Œå…¨å±•å¼€ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

Context-Pickeråœ¨äº”ä¸ªé•¿æ–‡æœ¬å’Œå¤šè·³é—®ç­”åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºŽçŽ°æœ‰çš„RAGåŸºçº¿ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒContext-Pickerèƒ½å¤Ÿåœ¨ä¿æŒæˆ–å‡å°‘ä¸Šä¸‹æ–‡é•¿åº¦çš„åŒæ—¶ï¼Œæ˜¾è‘—æé«˜ç­”æ¡ˆçš„å‡†ç¡®æ€§ã€‚æ¶ˆèžç ”ç©¶è¿›ä¸€æ­¥éªŒè¯äº†ç”±ç²—åˆ°ç²¾çš„ä¼˜åŒ–ç­–ç•¥ã€å†—ä½™æ„ŸçŸ¥çš„å¥–åŠ±å¡‘é€ å’Œä»¥åŽŸç†ä¸ºæŒ‡å¯¼çš„æ ¼å¼å¯¹æ€§èƒ½æå‡çš„è´¡çŒ®ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

Context-Pickerå¯åº”ç”¨äºŽå„ç§éœ€è¦ä»Žå¤§é‡ä¿¡æ¯ä¸­æå–å…³é”®è¯æ®çš„åœºæ™¯ï¼Œå¦‚æ™ºèƒ½å®¢æœã€æ³•å¾‹å’¨è¯¢ã€åŒ»å­¦è¯Šæ–­ç­‰ã€‚é€šè¿‡é€‰æ‹©æœ€ç›¸å…³çš„ä¸Šä¸‹æ–‡ï¼Œå¯ä»¥æé«˜é—®ç­”ç³»ç»Ÿçš„å‡†ç¡®æ€§å’Œæ•ˆçŽ‡ï¼Œå‡å°‘äººå·¥å¹²é¢„ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚è¯¥ç ”ç©¶å¯¹äºŽæž„å»ºæ›´æ™ºèƒ½ã€æ›´å¯é çš„çŸ¥è¯†å¯†é›†åž‹åº”ç”¨å…·æœ‰é‡è¦æ„ä¹‰ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In long-context question answering (LCQA), determining the optimal amount of context for a given query is a significant challenge. Including too few passages may omit critical information, while including too many can introduce noise and reduce the quality of the answer. Traditional approaches, such as fixed Top-$K$ retrieval and single-stage reranking, face the dilemma of selecting the right number of passages. This problem is particularly pronounced for factoid questions, which often require only a few specific pieces of evidence. To address this issue, we introduce \emph{Context-Picker}, a reasoning-aware framework that shifts the paradigm from similarity-based ranking to minimal sufficient subset selection. Context-Picker treats context selection as a decision-making process optimized via a human-inspired, two-stage reinforcement learning schedule: a \emph{recall-oriented} stage that prioritizes the coverage of reasoning chains, followed by a \emph{precision-oriented} stage that aggressively prunes redundancy to distill a compact evidence set. To resolve reward sparsity, we propose an offline evidence distillation pipeline that mines "minimal sufficient sets" via a Leave-One-Out (LOO) procedure, providing dense, task-aligned supervision. Experiments on five long-context and multi-hop QA benchmarks demonstrate that Context-Picker significantly outperforms strong RAG baselines, achieving superior answer accuracy with comparable or reduced context lengths. Ablation studies indicate that the coarse-to-fine optimization schedule, the redundancy-aware reward shaping, and the rationale-guided format all contribute substantially to these gains.

