---
layout: default
title: Context-Picker: Dynamic context selection using multi-stage reinforcement learning
---

# Context-Picker: Dynamic context selection using multi-stage reinforcement learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.14465" class="toolbar-btn" target="_blank">üìÑ arXiv: 2512.14465v1</a>
  <a href="https://arxiv.org/pdf/2512.14465.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14465v1" onclick="toggleFavorite(this, '2512.14465v1', 'Context-Picker: Dynamic context selection using multi-stage reinforcement learning')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Siyuan Zhu, Chengdong Xu, Kaiqiang Ke, Chao Yu

**ÂàÜÁ±ª**: cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-16

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**Context-PickerÔºöÂà©Áî®Â§öÈò∂ÊÆµÂº∫ÂåñÂ≠¶‰π†Âä®ÊÄÅÈÄâÊã©ÈïøÊñáÊú¨ÈóÆÁ≠îÁöÑ‰∏ä‰∏ãÊñá**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `ÈïøÊñáÊú¨ÈóÆÁ≠î` `‰∏ä‰∏ãÊñáÈÄâÊã©` `Âº∫ÂåñÂ≠¶‰π†` `Â§öÈò∂ÊÆµÂ≠¶‰π†` `ËØÅÊçÆÊèêÁÇº`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ÈïøÊñáÊú¨ÈóÆÁ≠î‰∏≠ÔºåÂ¶Ç‰ΩïÈÄâÊã©Êó¢ÂåÖÂê´ÂÖ≥ÈîÆ‰ø°ÊÅØÂèàÈÅøÂÖçÂô™Â£∞Âπ≤Êâ∞ÁöÑÊúÄ‰Ω≥‰∏ä‰∏ãÊñáÊòØ‰∏Ä‰∏™Ê†∏ÂøÉÊåëÊàò„ÄÇ
2. Context-PickerÈááÁî®‰∏§Èò∂ÊÆµÂº∫ÂåñÂ≠¶‰π†ÔºåÂÖàÂè¨ÂõûÊâÄÊúâÂèØËÉΩÁõ∏ÂÖ≥ÁöÑ‰∏ä‰∏ãÊñáÔºåÂÜçÁ≤æÁ°ÆÂú∞ÂéªÈô§ÂÜó‰Ωô‰ø°ÊÅØÔºåÈÄâÊã©ÊúÄÂ∞èÂÖÖÂàÜÂ≠êÈõÜ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåContext-PickerÂú®Â§ö‰∏™ÈïøÊñáÊú¨ÈóÆÁ≠îÊï∞ÊçÆÈõÜ‰∏äÊòæËëó‰ºò‰∫éÁé∞ÊúâRAGÊ®°ÂûãÔºåÂú®‰øùËØÅÂáÜÁ°ÆÁéáÁöÑÂêåÊó∂ÂáèÂ∞ë‰∫Ü‰∏ä‰∏ãÊñáÈïøÂ∫¶„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Âú®ÈïøÊñáÊú¨ÈóÆÁ≠îÔºàLCQAÔºâ‰∏≠ÔºåÁ°ÆÂÆöÁªôÂÆöÊü•ËØ¢ÁöÑÊúÄ‰Ω≥‰∏ä‰∏ãÊñáÊï∞ÈáèÊòØ‰∏Ä‰∏™ÈáçÂ§ßÊåëÊàò„ÄÇÂåÖÂê´ËøáÂ∞ëÁöÑÊÆµËêΩÂèØËÉΩÈÅóÊºèÂÖ≥ÈîÆ‰ø°ÊÅØÔºåËÄåÂåÖÂê´ËøáÂ§öÁöÑÊÆµËêΩ‰ºöÂºïÂÖ•Âô™Â£∞Âπ∂Èôç‰ΩéÁ≠îÊ°àË¥®Èáè„ÄÇ‰º†ÁªüÁöÑTop-$K$Ê£ÄÁ¥¢ÂíåÂçïÈò∂ÊÆµÈáçÊéíÂ∫èÁ≠âÊñπÊ≥ïÈù¢‰∏¥ÁùÄÈÄâÊã©ÂêàÈÄÇÊÆµËêΩÊï∞ÈáèÁöÑÂõ∞Â¢ÉÔºåÂØπ‰∫éÈÄöÂ∏∏Âè™ÈúÄË¶ÅÂ∞ëÈáèÁâπÂÆöËØÅÊçÆÁöÑ‰∫ãÂÆûÊÄßÈóÆÈ¢òÂ∞§ÂÖ∂Â¶ÇÊ≠§„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÂºïÂÖ•‰∫ÜContext-PickerÔºåËøôÊòØ‰∏Ä‰∏™Êé®ÁêÜÊÑüÁü•ÁöÑÊ°ÜÊû∂ÔºåÂÆÉÂ∞ÜËåÉÂºè‰ªéÂü∫‰∫éÁõ∏‰ººÊÄßÁöÑÊéíÂ∫èËΩ¨Âèò‰∏∫ÊúÄÂ∞èÂÖÖÂàÜÂ≠êÈõÜÈÄâÊã©„ÄÇContext-PickerÂ∞Ü‰∏ä‰∏ãÊñáÈÄâÊã©ËßÜ‰∏∫‰∏Ä‰∏™ÂÜ≥Á≠ñËøáÁ®ãÔºåÈÄöËøáÂèó‰∫∫Á±ªÂêØÂèëÁöÑ‰∏§Èò∂ÊÆµÂº∫ÂåñÂ≠¶‰π†ÊñπÊ°àËøõË°å‰ºòÂåñÔºö‰∏Ä‰∏™‰ª•Âè¨Âõû‰∏∫ÂØºÂêëÁöÑÈò∂ÊÆµÔºå‰ºòÂÖàËÄÉËôëÊé®ÁêÜÈìæÁöÑË¶ÜÁõñÔºõÁÑ∂ÂêéÊòØ‰∏Ä‰∏™‰ª•Á≤æÂ∫¶‰∏∫ÂØºÂêëÁöÑÈò∂ÊÆµÔºåÁßØÊûÅÂú∞‰øÆÂâ™ÂÜó‰Ωô‰ª•ÊèêÁÇºÂá∫‰∏Ä‰∏™Á¥ßÂáëÁöÑËØÅÊçÆÈõÜ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Â•ñÂä±Á®ÄÁñèÊÄßÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Á¶ªÁ∫øËØÅÊçÆÊèêÁÇºÊµÅÁ®ãÔºåÈÄöËøáÁïô‰∏ÄÊ≥ïÔºàLOOÔºâÊåñÊéò‚ÄúÊúÄÂ∞èÂÖÖÂàÜÈõÜ‚ÄùÔºåÊèê‰æõÂØÜÈõÜÁöÑ„ÄÅ‰ªªÂä°ÂØπÈΩêÁöÑÁõëÁù£„ÄÇÂú®‰∫î‰∏™ÈïøÊñáÊú¨ÂíåÂ§öË∑≥ÈóÆÁ≠îÂü∫ÂáÜ‰∏äÁöÑÂÆûÈ™åË°®ÊòéÔºåContext-PickerÊòæËëó‰ºò‰∫éÂº∫Â§ßÁöÑRAGÂü∫Á∫øÔºå‰ª•Áõ∏ÂΩìÊàñÊõ¥Áü≠ÁöÑ‰∏ä‰∏ãÊñáÈïøÂ∫¶ÂÆûÁé∞‰∫ÜÂçìË∂äÁöÑÁ≠îÊ°àÂáÜÁ°ÆÊÄß„ÄÇÊ∂àËûçÁ†îÁ©∂Ë°®ÊòéÔºåÁî±Á≤óÂà∞Á≤æÁöÑ‰ºòÂåñÊñπÊ°à„ÄÅÂÜó‰ΩôÊÑüÁü•ÁöÑÂ•ñÂä±Â°ëÈÄ†Âíå‰ª•ÁêÜÁî±‰∏∫ÊåáÂØºÁöÑÊ†ºÂºèÈÉΩÂØπËøô‰∫õÊî∂ÁõäÂÅöÂá∫‰∫ÜÈáçÂ§ßË¥°ÁåÆ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÈïøÊñáÊú¨ÈóÆÁ≠îÔºàLCQAÔºâ‰ªªÂä°‰∏≠ÔºåÁé∞ÊúâÊñπÊ≥ïÂ¶ÇÂõ∫ÂÆöTop-KÊ£ÄÁ¥¢ÊàñÂçïÈò∂ÊÆµÈáçÊéíÂ∫èÈöæ‰ª•Á°ÆÂÆöÊúÄ‰Ω≥‰∏ä‰∏ãÊñáÊï∞Èáè„ÄÇÂåÖÂê´‰∏ä‰∏ãÊñáËøáÂ∞ëÂèØËÉΩÈÅóÊºèÂÖ≥ÈîÆ‰ø°ÊÅØÔºåËøáÂ§öÂàôÂºïÂÖ•Âô™Â£∞ÔºåÈôç‰ΩéÁ≠îÊ°àË¥®Èáè„ÄÇÂ∞§ÂÖ∂ÂØπ‰∫é‰∫ãÂÆûÊÄßÈóÆÈ¢òÔºåÂæÄÂæÄÂè™ÈúÄË¶ÅÂ∞ëÈáèÂÖ≥ÈîÆËØÅÊçÆÔºåÁé∞ÊúâÊñπÊ≥ïÈöæ‰ª•ÊúâÊïàÊèêÂèñ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÂ∞Ü‰∏ä‰∏ãÊñáÈÄâÊã©ËßÜ‰∏∫‰∏Ä‰∏™ÂÜ≥Á≠ñËøáÁ®ãÔºåÈÄöËøáÂº∫ÂåñÂ≠¶‰π†Êù•‰ºòÂåñ„ÄÇÊ®°‰ªø‰∫∫Á±ªÈòÖËØªÁêÜËß£ÁöÑËøáÁ®ãÔºåÂÖàÂπøÊ≥õÊêúÁ¥¢Áõ∏ÂÖ≥‰ø°ÊÅØÔºàÂè¨ÂõûÔºâÔºåÂÜçÁ≤æÁÆÄ‰ø°ÊÅØÔºåÂéªÈô§ÂÜó‰ΩôÔºàÁ≤æÂ∫¶Ôºâ„ÄÇÈÄöËøá‰∏§Èò∂ÊÆµÂº∫ÂåñÂ≠¶‰π†ÔºåÂÆûÁé∞Áî±Á≤óÂà∞Á≤æÁöÑ‰∏ä‰∏ãÊñáÈÄâÊã©„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöContext-PickerÂåÖÂê´‰∏§‰∏™‰∏ªË¶ÅÈò∂ÊÆµÔºöÂè¨ÂõûÈò∂ÊÆµÂíåÁ≤æÂ∫¶Èò∂ÊÆµ„ÄÇÂè¨ÂõûÈò∂ÊÆµÊó®Âú®Ë¶ÜÁõñÊâÄÊúâÂèØËÉΩÁõ∏ÂÖ≥ÁöÑÊé®ÁêÜÈìæÔºå‰ΩøÁî®Âº∫ÂåñÂ≠¶‰π†Á≠ñÁï•ÈÄâÊã©‰∏ä‰∏ãÊñáÊÆµËêΩÔºåÊúÄÂ§ßÂåñÂè¨ÂõûÁéá„ÄÇÁ≤æÂ∫¶Èò∂ÊÆµÂàô‰∏ìÊ≥®‰∫éÂéªÈô§ÂÜó‰Ωô‰ø°ÊÅØÔºåËøõ‰∏ÄÊ≠•ÊèêÁÇº‰∏ä‰∏ãÊñáÔºåÊèêÈ´òÁ≠îÊ°àÁöÑÂáÜÁ°ÆÊÄß„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Â•ñÂä±Á®ÄÁñèÊÄßÈóÆÈ¢òÔºåÈááÁî®Á¶ªÁ∫øËØÅÊçÆÊèêÁÇºÊµÅÁ®ãÔºåÊåñÊéò‚ÄúÊúÄÂ∞èÂÖÖÂàÜÈõÜ‚Äù‰Ωú‰∏∫ÁõëÁù£‰ø°Âè∑„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöContext-PickerÁöÑÊ†∏ÂøÉÂàõÊñ∞Âú®‰∫éÂ∞Ü‰∏ä‰∏ãÊñáÈÄâÊã©ÈóÆÈ¢òËΩ¨Âåñ‰∏∫‰∏Ä‰∏™ÂèØÂ≠¶‰π†ÁöÑÂÜ≥Á≠ñËøáÁ®ãÔºåÂπ∂ÈááÁî®‰∏§Èò∂ÊÆµÂº∫ÂåñÂ≠¶‰π†Á≠ñÁï•„ÄÇ‰∏é‰º†ÁªüÁöÑÂü∫‰∫éÁõ∏‰ººÂ∫¶ÊéíÂ∫èÁöÑÊñπÊ≥ï‰∏çÂêåÔºåContext-PickerÂÖ≥Ê≥®‰∫éÈÄâÊã©ÊúÄÂ∞èÂÖÖÂàÜÁöÑËØÅÊçÆÂ≠êÈõÜÔºå‰ªéËÄåÊèêÈ´òÁ≠îÊ°àÁöÑÂáÜÁ°ÆÊÄßÂíåÊïàÁéá„ÄÇÁ¶ªÁ∫øËØÅÊçÆÊèêÁÇºÊµÅÁ®ã‰∏∫Âº∫ÂåñÂ≠¶‰π†Êèê‰æõ‰∫ÜÂØÜÈõÜÁöÑÁõëÁù£‰ø°Âè∑ÔºåËß£ÂÜ≥‰∫ÜÂ•ñÂä±Á®ÄÁñèÊÄßÈóÆÈ¢ò„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöContext-Picker‰ΩøÁî®‰∏§Èò∂ÊÆµÂº∫ÂåñÂ≠¶‰π†ÔºåÊØè‰∏™Èò∂ÊÆµÈÉΩÊúâÁã¨Á´ãÁöÑÂ•ñÂä±ÂáΩÊï∞ÂíåÁ≠ñÁï•ÁΩëÁªú„ÄÇÂè¨ÂõûÈò∂ÊÆµÁöÑÂ•ñÂä±ÂáΩÊï∞‰æßÈáç‰∫éË¶ÜÁõñÊé®ÁêÜÈìæÔºåÁ≤æÂ∫¶Èò∂ÊÆµÁöÑÂ•ñÂä±ÂáΩÊï∞‰æßÈáç‰∫éÂéªÈô§ÂÜó‰Ωô‰ø°ÊÅØ„ÄÇÁ¶ªÁ∫øËØÅÊçÆÊèêÁÇºÊµÅÁ®ã‰ΩøÁî®Áïô‰∏ÄÊ≥ïÔºàLOOÔºâÊù•ÊåñÊéòÊúÄÂ∞èÂÖÖÂàÜÈõÜÔºå‰∏∫Âº∫ÂåñÂ≠¶‰π†Êèê‰æõÁõëÁù£‰ø°Âè∑„ÄÇÂÖ∑‰ΩìÁΩëÁªúÁªìÊûÑÂíåÂèÇÊï∞ËÆæÁΩÆÂú®ËÆ∫Êñá‰∏≠ÊúâËØ¶ÁªÜÊèèËø∞ÔºàÊú™Áü•Ôºâ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Context-PickerÂú®‰∫î‰∏™ÈïøÊñáÊú¨ÂíåÂ§öË∑≥ÈóÆÁ≠îÂü∫ÂáÜÊµãËØï‰∏≠ÊòæËëó‰ºò‰∫éÂº∫Â§ßÁöÑRAGÂü∫Á∫ø„ÄÇÂú®‰øùËØÅÊàñÂáèÂ∞ë‰∏ä‰∏ãÊñáÈïøÂ∫¶ÁöÑÊÉÖÂÜµ‰∏ãÔºåÁ≠îÊ°àÂáÜÁ°ÆÊÄßÂæóÂà∞‰∫ÜÊòæËëóÊèêÂçá„ÄÇÊ∂àËûçÂÆûÈ™åË°®ÊòéÔºåÁî±Á≤óÂà∞Á≤æÁöÑ‰ºòÂåñÁ≠ñÁï•„ÄÅÂÜó‰ΩôÊÑüÁü•ÁöÑÂ•ñÂä±Â°ëÈÄ†‰ª•Âèä‰ª•ÁêÜÁî±‰∏∫ÊåáÂØºÁöÑÊ†ºÂºèÈÉΩÂØπÊÄßËÉΩÊèêÂçáÂÅöÂá∫‰∫ÜÈáçË¶ÅË¥°ÁåÆ„ÄÇÔºàÂÖ∑‰ΩìÊÄßËÉΩÊï∞ÊçÆÊú™Áü•Ôºâ

## üéØ Â∫îÁî®Âú∫ÊôØ

Context-PickerÂèØÂ∫îÁî®‰∫éÂêÑÁßçÈúÄË¶Å‰ªéÈïøÊñáÊú¨‰∏≠ÊèêÂèñ‰ø°ÊÅØÁöÑÂú∫ÊôØÔºåÂ¶ÇÊô∫ËÉΩÂÆ¢Êúç„ÄÅÊ≥ïÂæãÂí®ËØ¢„ÄÅÈáëËûçÂàÜÊûêÁ≠â„ÄÇÈÄöËøáÈÄâÊã©ÊúÄÁõ∏ÂÖ≥ÁöÑ‰∏ä‰∏ãÊñáÔºåÂèØ‰ª•ÊèêÈ´ò‰ø°ÊÅØÊ£ÄÁ¥¢ÁöÑÂáÜÁ°ÆÊÄßÂíåÊïàÁéáÔºåÈôç‰ΩéËÆ°ÁÆóÊàêÊú¨ÔºåÂπ∂ÊèêÂçáÁî®Êà∑‰ΩìÈ™å„ÄÇËØ•Á†îÁ©∂ÂØπ‰∫éÊèêÂçáÊú∫Âô®ÈòÖËØªÁêÜËß£ËÉΩÂäõÂÖ∑ÊúâÈáçË¶ÅÊÑè‰πâ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> In long-context question answering (LCQA), determining the optimal amount of context for a given query is a significant challenge. Including too few passages may omit critical information, while including too many can introduce noise and reduce the quality of the answer. Traditional approaches, such as fixed Top-$K$ retrieval and single-stage reranking, face the dilemma of selecting the right number of passages. This problem is particularly pronounced for factoid questions, which often require only a few specific pieces of evidence. To address this issue, we introduce \emph{Context-Picker}, a reasoning-aware framework that shifts the paradigm from similarity-based ranking to minimal sufficient subset selection. Context-Picker treats context selection as a decision-making process optimized via a human-inspired, two-stage reinforcement learning schedule: a \emph{recall-oriented} stage that prioritizes the coverage of reasoning chains, followed by a \emph{precision-oriented} stage that aggressively prunes redundancy to distill a compact evidence set. To resolve reward sparsity, we propose an offline evidence distillation pipeline that mines "minimal sufficient sets" via a Leave-One-Out (LOO) procedure, providing dense, task-aligned supervision. Experiments on five long-context and multi-hop QA benchmarks demonstrate that Context-Picker significantly outperforms strong RAG baselines, achieving superior answer accuracy with comparable or reduced context lengths. Ablation studies indicate that the coarse-to-fine optimization schedule, the redundancy-aware reward shaping, and the rationale-guided format all contribute substantially to these gains.

