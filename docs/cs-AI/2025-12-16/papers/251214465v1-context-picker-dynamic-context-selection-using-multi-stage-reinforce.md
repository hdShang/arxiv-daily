---
layout: default
title: Context-Picker: Dynamic context selection using multi-stage reinforcement learning
---

# Context-Picker: Dynamic context selection using multi-stage reinforcement learning

**arXiv**: [2512.14465v1](https://arxiv.org/abs/2512.14465) | [PDF](https://arxiv.org/pdf/2512.14465.pdf)

**ä½œè€…**: Siyuan Zhu, Chengdong Xu, Kaiqiang Ke, Chao Yu

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºContext-Pickeræ¡†æž¶ï¼Œé€šè¿‡å¤šé˜¶æ®µå¼ºåŒ–å­¦ä¹ åŠ¨æ€é€‰æ‹©æœ€å°å……åˆ†è¯æ®é›†ï¼Œä»¥è§£å†³é•¿ä¸Šä¸‹æ–‡é—®ç­”ä¸­çš„å™ªå£°ä¸Žä¿¡æ¯ä¸è¶³é—®é¢˜ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `é•¿ä¸Šä¸‹æ–‡é—®ç­”` `å¼ºåŒ–å­¦ä¹ ` `è¯æ®é€‰æ‹©` `å¤šé˜¶æ®µä¼˜åŒ–` `æŽ¨ç†æ„ŸçŸ¥` `æœ€å°å……åˆ†é›†` `å™ªå£°å‰ªæž` `é—®ç­”ç³»ç»Ÿ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. é•¿ä¸Šä¸‹æ–‡é—®ç­”ä¸­ï¼Œä¼ ç»Ÿå›ºå®šTop-Kæ£€ç´¢å’Œå•é˜¶æ®µé‡æŽ’åºæ–¹æ³•éš¾ä»¥å¹³è¡¡å™ªå£°ä¸Žä¿¡æ¯ä¸è¶³ï¼Œå°¤å…¶åœ¨äº‹å®žåž‹é—®é¢˜ä¸­ã€‚
2. æå‡ºContext-Pickeræ¡†æž¶ï¼Œé‡‡ç”¨ä¸¤é˜¶æ®µå¼ºåŒ–å­¦ä¹ ï¼šå…ˆå¬å›žè¦†ç›–æŽ¨ç†é“¾ï¼Œå†ç²¾ç¡®å‰ªæžå†—ä½™ï¼Œå®žçŽ°æœ€å°å……åˆ†è¯æ®é›†é€‰æ‹©ã€‚
3. åœ¨äº”ä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒContext-Pickeræ˜¾è‘—è¶…è¶ŠRAGåŸºçº¿ï¼Œç­”æ¡ˆå‡†ç¡®æ€§æ›´é«˜ï¼ŒåŒæ—¶ä¸Šä¸‹æ–‡é•¿åº¦ç›¸å½“æˆ–æ›´çŸ­ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨é•¿ä¸Šä¸‹æ–‡é—®ç­”ï¼ˆLCQAï¼‰ä¸­ï¼Œä¸ºç»™å®šæŸ¥è¯¢ç¡®å®šæœ€ä¼˜çš„ä¸Šä¸‹æ–‡é‡æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ã€‚åŒ…å«è¿‡å°‘æ®µè½å¯èƒ½é—æ¼å…³é”®ä¿¡æ¯ï¼Œè€ŒåŒ…å«è¿‡å¤šåˆ™ä¼šå¼•å…¥å™ªå£°å¹¶é™ä½Žç­”æ¡ˆè´¨é‡ã€‚ä¼ ç»Ÿæ–¹æ³•å¦‚å›ºå®šTop-Kæ£€ç´¢å’Œå•é˜¶æ®µé‡æŽ’åºé¢ä¸´é€‰æ‹©é€‚å½“æ®µè½æ•°é‡çš„å›°å¢ƒï¼Œè¿™ä¸€é—®é¢˜åœ¨äº‹å®žåž‹é—®é¢˜ä¸­å°¤ä¸ºçªå‡ºï¼Œè¿™ç±»é—®é¢˜é€šå¸¸åªéœ€è¦å°‘é‡ç‰¹å®šè¯æ®ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†Context-Pickerï¼Œè¿™æ˜¯ä¸€ä¸ªæŽ¨ç†æ„ŸçŸ¥æ¡†æž¶ï¼Œå°†èŒƒå¼ä»ŽåŸºäºŽç›¸ä¼¼æ€§çš„æŽ’åºè½¬å‘æœ€å°å……åˆ†å­é›†é€‰æ‹©ã€‚Context-Pickerå°†ä¸Šä¸‹æ–‡é€‰æ‹©è§†ä¸ºä¸€ä¸ªå†³ç­–è¿‡ç¨‹ï¼Œé€šè¿‡å—äººç±»å¯å‘çš„ä¸¤é˜¶æ®µå¼ºåŒ–å­¦ä¹ è®¡åˆ’è¿›è¡Œä¼˜åŒ–ï¼šä¸€ä¸ªä»¥å¬å›žä¸ºå¯¼å‘çš„é˜¶æ®µï¼Œä¼˜å…ˆè¦†ç›–æŽ¨ç†é“¾ï¼›éšåŽæ˜¯ä¸€ä¸ªä»¥ç²¾ç¡®ä¸ºå¯¼å‘çš„é˜¶æ®µï¼Œç§¯æžå‰ªæžå†—ä½™ä»¥æç‚¼ç´§å‡‘çš„è¯æ®é›†ã€‚ä¸ºè§£å†³å¥–åŠ±ç¨€ç–æ€§é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç¦»çº¿è¯æ®è’¸é¦æµç¨‹ï¼Œé€šè¿‡ç•™ä¸€æ³•ï¼ˆLOOï¼‰æŒ–æŽ˜â€œæœ€å°å……åˆ†é›†â€ï¼Œæä¾›å¯†é›†ã€ä»»åŠ¡å¯¹é½çš„ç›‘ç£ã€‚åœ¨äº”ä¸ªé•¿ä¸Šä¸‹æ–‡å’Œå¤šè·³é—®ç­”åŸºå‡†ä¸Šçš„å®žéªŒè¡¨æ˜Žï¼ŒContext-Pickeræ˜¾è‘—ä¼˜äºŽå¼ºå¤§çš„RAGåŸºçº¿ï¼Œåœ¨å¯æ¯”æˆ–æ›´çŸ­çš„ä¸Šä¸‹æ–‡é•¿åº¦ä¸‹å®žçŽ°äº†æ›´ä¼˜çš„ç­”æ¡ˆå‡†ç¡®æ€§ã€‚æ¶ˆèžç ”ç©¶è¡¨æ˜Žï¼Œä»Žç²—åˆ°ç»†çš„ä¼˜åŒ–è®¡åˆ’ã€å†—ä½™æ„ŸçŸ¥çš„å¥–åŠ±å¡‘é€ å’ŒæŽ¨ç†å¼•å¯¼çš„æ ¼å¼éƒ½å¯¹è¿™ä¸€å¢žç›Šæœ‰å®žè´¨æ€§è´¡çŒ®ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

Context-Pickeræ˜¯ä¸€ä¸ªæŽ¨ç†æ„ŸçŸ¥æ¡†æž¶ï¼Œå°†ä¸Šä¸‹æ–‡é€‰æ‹©è§†ä¸ºå†³ç­–è¿‡ç¨‹ï¼Œé€šè¿‡å¤šé˜¶æ®µå¼ºåŒ–å­¦ä¹ ä¼˜åŒ–ã€‚æ•´ä½“æ¡†æž¶åŒ…æ‹¬ï¼šä»¥å¬å›žä¸ºå¯¼å‘çš„é˜¶æ®µï¼Œä¼˜å…ˆè¦†ç›–æŽ¨ç†é“¾ï¼›ä»¥ç²¾ç¡®ä¸ºå¯¼å‘çš„é˜¶æ®µï¼Œç§¯æžå‰ªæžå†—ä½™ï¼Œæç‚¼ç´§å‡‘è¯æ®é›†ã€‚å…³é”®æŠ€æœ¯åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼šé‡‡ç”¨ä¸¤é˜¶æ®µå¼ºåŒ–å­¦ä¹ è®¡åˆ’ï¼Œæ¨¡æ‹Ÿäººç±»æŽ¨ç†è¿‡ç¨‹ï¼›æå‡ºç¦»çº¿è¯æ®è’¸é¦æµç¨‹ï¼Œé€šè¿‡ç•™ä¸€æ³•æŒ–æŽ˜æœ€å°å……åˆ†é›†ï¼Œè§£å†³å¥–åŠ±ç¨€ç–æ€§é—®é¢˜ï¼›å¼•å…¥å†—ä½™æ„ŸçŸ¥å¥–åŠ±å¡‘é€ å’ŒæŽ¨ç†å¼•å¯¼æ ¼å¼ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºŽï¼Œå®ƒä»Žç›¸ä¼¼æ€§æŽ’åºè½¬å‘æœ€å°å……åˆ†å­é›†é€‰æ‹©ï¼ŒåŠ¨æ€è°ƒæ•´ä¸Šä¸‹æ–‡é‡ï¼Œè€Œéžå›ºå®šæ•°é‡æˆ–å•é˜¶æ®µå¤„ç†ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨äº”ä¸ªé•¿ä¸Šä¸‹æ–‡å’Œå¤šè·³é—®ç­”åŸºå‡†ä¸Šï¼ŒContext-Pickeræ˜¾è‘—ä¼˜äºŽRAGåŸºçº¿ï¼Œç­”æ¡ˆå‡†ç¡®æ€§æ›´é«˜ï¼ŒåŒæ—¶ä¸Šä¸‹æ–‡é•¿åº¦ç›¸å½“æˆ–æ›´çŸ­ï¼Œæ¶ˆèžç ”ç©¶è¯å®žä¼˜åŒ–è®¡åˆ’å’Œå¥–åŠ±å¡‘é€ çš„å…³é”®ä½œç”¨ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å¯åº”ç”¨äºŽé•¿æ–‡æ¡£é—®ç­”ã€å¤šè·³æŽ¨ç†ã€äº‹å®žæ ¸æŸ¥å’Œæ™ºèƒ½åŠ©æ‰‹ç­‰é¢†åŸŸï¼Œé€šè¿‡åŠ¨æ€é€‰æ‹©æœ€å°å……åˆ†è¯æ®é›†ï¼Œæé«˜ç­”æ¡ˆå‡†ç¡®æ€§å¹¶å‡å°‘è®¡ç®—å¼€é”€ï¼Œå…·æœ‰å®žé™…ä»·å€¼ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In long-context question answering (LCQA), determining the optimal amount of context for a given query is a significant challenge. Including too few passages may omit critical information, while including too many can introduce noise and reduce the quality of the answer. Traditional approaches, such as fixed Top-$K$ retrieval and single-stage reranking, face the dilemma of selecting the right number of passages. This problem is particularly pronounced for factoid questions, which often require only a few specific pieces of evidence. To address this issue, we introduce \emph{Context-Picker}, a reasoning-aware framework that shifts the paradigm from similarity-based ranking to minimal sufficient subset selection. Context-Picker treats context selection as a decision-making process optimized via a human-inspired, two-stage reinforcement learning schedule: a \emph{recall-oriented} stage that prioritizes the coverage of reasoning chains, followed by a \emph{precision-oriented} stage that aggressively prunes redundancy to distill a compact evidence set. To resolve reward sparsity, we propose an offline evidence distillation pipeline that mines "minimal sufficient sets" via a Leave-One-Out (LOO) procedure, providing dense, task-aligned supervision. Experiments on five long-context and multi-hop QA benchmarks demonstrate that Context-Picker significantly outperforms strong RAG baselines, achieving superior answer accuracy with comparable or reduced context lengths. Ablation studies indicate that the coarse-to-fine optimization schedule, the redundancy-aware reward shaping, and the rationale-guided format all contribute substantially to these gains.

