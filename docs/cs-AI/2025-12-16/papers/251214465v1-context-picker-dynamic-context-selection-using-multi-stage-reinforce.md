---
layout: default
title: Context-Picker: Dynamic context selection using multi-stage reinforcement learning
---

# Context-Picker: Dynamic context selection using multi-stage reinforcement learning

**arXiv**: [2512.14465v1](https://arxiv.org/abs/2512.14465) | [PDF](https://arxiv.org/pdf/2512.14465.pdf)

**ä½œè€…**: Siyuan Zhu, Chengdong Xu, Kaiqiang Ke, Chao Yu

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºContext-Pickeræ¡†æž¶ï¼Œé€šè¿‡å¤šé˜¶æ®µå¼ºåŒ–å­¦ä¹ è§£å†³é•¿ä¸Šä¸‹æ–‡é—®ç­”ä¸­åŠ¨æ€é€‰æ‹©æœ€ä¼˜è¯æ®å­é›†çš„é—®é¢˜ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `é•¿ä¸Šä¸‹æ–‡é—®ç­”` `å¼ºåŒ–å­¦ä¹ ` `è¯æ®é€‰æ‹©` `å¤šé˜¶æ®µä¼˜åŒ–` `ç¦»çº¿è’¸é¦` `æŽ¨ç†æ„ŸçŸ¥` `æœ€å°å……åˆ†é›†` `RAGæ¡†æž¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šé•¿ä¸Šä¸‹æ–‡é—®ç­”ä¸­ï¼Œä¼ ç»Ÿå›ºå®šTop-Kæ£€ç´¢å’Œå•é˜¶æ®µé‡æŽ’åºæ–¹æ³•éš¾ä»¥åŠ¨æ€ç¡®å®šæœ€ä¼˜è¯æ®æ•°é‡ï¼Œå¯¼è‡´ä¿¡æ¯é—æ¼æˆ–å™ªå£°å¼•å…¥ï¼Œå½±å“ç­”æ¡ˆè´¨é‡ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæå‡ºContext-Pickeræ¡†æž¶ï¼Œå°†ä¸Šä¸‹æ–‡é€‰æ‹©è§†ä¸ºå†³ç­–è¿‡ç¨‹ï¼Œé‡‡ç”¨ä¸¤é˜¶æ®µå¼ºåŒ–å­¦ä¹ ï¼ˆå¬å›žå’Œç²¾åº¦é˜¶æ®µï¼‰ä¼˜åŒ–æœ€å°å……åˆ†å­é›†é€‰æ‹©ï¼Œå¹¶å¼•å…¥ç¦»çº¿è¯æ®è’¸é¦è§£å†³å¥–åŠ±ç¨€ç–æ€§ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨äº”ä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒContext-Pickeræ˜¾è‘—ä¼˜äºŽRAGåŸºçº¿ï¼Œå®žçŽ°æ›´é«˜ç­”æ¡ˆå‡†ç¡®æ€§ï¼ŒåŒæ—¶å‡å°‘ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œæ¶ˆèžç ”ç©¶éªŒè¯äº†å…³é”®ç»„ä»¶çš„æœ‰æ•ˆæ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨é•¿ä¸Šä¸‹æ–‡é—®ç­”ï¼ˆLCQAï¼‰ä¸­ï¼Œä¸ºç»™å®šæŸ¥è¯¢ç¡®å®šæœ€ä¼˜çš„ä¸Šä¸‹æ–‡é‡æ˜¯ä¸€ä¸ªé‡è¦æŒ‘æˆ˜ã€‚åŒ…å«è¿‡å°‘æ®µè½å¯èƒ½é—æ¼å…³é”®ä¿¡æ¯ï¼Œè€ŒåŒ…å«è¿‡å¤šåˆ™ä¼šå¼•å…¥å™ªå£°å¹¶é™ä½Žç­”æ¡ˆè´¨é‡ã€‚ä¼ ç»Ÿæ–¹æ³•ï¼Œå¦‚å›ºå®šçš„Top-Kæ£€ç´¢å’Œå•é˜¶æ®µé‡æŽ’åºï¼Œé¢ä¸´é€‰æ‹©æ­£ç¡®æ®µè½æ•°é‡çš„å›°å¢ƒã€‚è¿™ä¸€é—®é¢˜åœ¨äº‹å®žåž‹é—®é¢˜ä¸Šå°¤ä¸ºçªå‡ºï¼Œè¿™ç±»é—®é¢˜é€šå¸¸åªéœ€è¦å°‘é‡ç‰¹å®šè¯æ®ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†Context-Pickerï¼Œè¿™æ˜¯ä¸€ä¸ªæŽ¨ç†æ„ŸçŸ¥çš„æ¡†æž¶ï¼Œå°†èŒƒå¼ä»ŽåŸºäºŽç›¸ä¼¼æ€§çš„æŽ’åºè½¬å‘æœ€å°å……åˆ†å­é›†é€‰æ‹©ã€‚Context-Pickerå°†ä¸Šä¸‹æ–‡é€‰æ‹©è§†ä¸ºä¸€ä¸ªå†³ç­–è¿‡ç¨‹ï¼Œé€šè¿‡å—äººç±»å¯å‘çš„ä¸¤é˜¶æ®µå¼ºåŒ–å­¦ä¹ è®¡åˆ’è¿›è¡Œä¼˜åŒ–ï¼šä¸€ä¸ªé¢å‘å¬å›žçš„é˜¶æ®µï¼Œä¼˜å…ˆè¦†ç›–æŽ¨ç†é“¾ï¼›éšåŽæ˜¯ä¸€ä¸ªé¢å‘ç²¾åº¦çš„é˜¶æ®µï¼Œç§¯æžå‰ªæžå†—ä½™ä»¥æç‚¼ç´§å‡‘çš„è¯æ®é›†ã€‚ä¸ºè§£å†³å¥–åŠ±ç¨€ç–æ€§é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç¦»çº¿è¯æ®è’¸é¦æµç¨‹ï¼Œé€šè¿‡ç•™ä¸€æ³•ï¼ˆLOOï¼‰æŒ–æŽ˜â€œæœ€å°å……åˆ†é›†â€ï¼Œæä¾›å¯†é›†ã€ä»»åŠ¡å¯¹é½çš„ç›‘ç£ã€‚åœ¨äº”ä¸ªé•¿ä¸Šä¸‹æ–‡å’Œå¤šè·³é—®ç­”åŸºå‡†ä¸Šçš„å®žéªŒè¡¨æ˜Žï¼ŒContext-Pickeræ˜¾è‘—ä¼˜äºŽå¼ºå¤§çš„RAGåŸºçº¿ï¼Œåœ¨å¯æ¯”æˆ–æ›´çŸ­çš„ä¸Šä¸‹æ–‡é•¿åº¦ä¸‹å®žçŽ°äº†æ›´ä¼˜çš„ç­”æ¡ˆå‡†ç¡®æ€§ã€‚æ¶ˆèžç ”ç©¶è¡¨æ˜Žï¼Œä»Žç²—åˆ°ç»†çš„ä¼˜åŒ–è®¡åˆ’ã€å†—ä½™æ„ŸçŸ¥çš„å¥–åŠ±å¡‘é€ å’ŒæŽ¨ç†å¼•å¯¼çš„æ ¼å¼éƒ½å¯¹è¿™ä¸€å¢žç›Šæœ‰å®žè´¨æ€§è´¡çŒ®ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡è§£å†³é•¿ä¸Šä¸‹æ–‡é—®ç­”ï¼ˆLCQAï¼‰ä¸­åŠ¨æ€é€‰æ‹©æœ€ä¼˜è¯æ®å­é›†çš„é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•å¦‚å›ºå®šTop-Kæ£€ç´¢å’Œå•é˜¶æ®µé‡æŽ’åºé¢ä¸´å›°å¢ƒï¼šé€‰æ‹©è¿‡å°‘æ®µè½å¯èƒ½é—æ¼å…³é”®ä¿¡æ¯ï¼Œé€‰æ‹©è¿‡å¤šåˆ™å¼•å…¥å™ªå£°ï¼Œé™ä½Žç­”æ¡ˆè´¨é‡ï¼Œå°¤å…¶åœ¨äº‹å®žåž‹é—®é¢˜ä¸­ï¼Œè¿™å¯¼è‡´æ•ˆçŽ‡ä½Žä¸‹å’Œå‡†ç¡®æ€§å—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†ä¸Šä¸‹æ–‡é€‰æ‹©ä»Žä¼ ç»Ÿçš„ç›¸ä¼¼æ€§æŽ’åºèŒƒå¼è½¬å‘æœ€å°å……åˆ†å­é›†é€‰æ‹©ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–å†³ç­–è¿‡ç¨‹ã€‚è®¾è®¡å—äººç±»å¯å‘ï¼Œæ¨¡æ‹Ÿå…ˆå¹¿æ³›æœç´¢å†ç²¾ç»†ç­›é€‰çš„è®¤çŸ¥è¿‡ç¨‹ï¼Œä»¥å¹³è¡¡å¬å›žå’Œç²¾åº¦ï¼Œä»Žè€Œæå–ç´§å‡‘ä¸”ç›¸å…³çš„è¯æ®é›†ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æž¶æž„åŒ…æ‹¬ä¸¤é˜¶æ®µå¼ºåŒ–å­¦ä¹ è®¡åˆ’ï¼šç¬¬ä¸€é˜¶æ®µä¸ºå¬å›žå¯¼å‘é˜¶æ®µï¼Œä½¿ç”¨ç­–ç•¥ç½‘ç»œä¼˜å…ˆè¦†ç›–æŽ¨ç†é“¾ï¼Œç¡®ä¿ä¸é—æ¼å…³é”®è¯æ®ï¼›ç¬¬äºŒé˜¶æ®µä¸ºç²¾åº¦å¯¼å‘é˜¶æ®µï¼Œé€šè¿‡å¦ä¸€ä¸ªç­–ç•¥ç½‘ç»œç§¯æžå‰ªæžå†—ä½™ï¼Œæç‚¼å‡ºæœ€å°å……åˆ†è¯æ®é›†ã€‚æ­¤å¤–ï¼Œæ¡†æž¶é›†æˆäº†ç¦»çº¿è¯æ®è’¸é¦æµç¨‹ï¼Œç”¨äºŽè®­ç»ƒæ•°æ®å‡†å¤‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°æ˜¯æå‡ºå¤šé˜¶æ®µå¼ºåŒ–å­¦ä¹ è®¡åˆ’ï¼Œç»“åˆå¬å›žå’Œç²¾åº¦ä¼˜åŒ–ï¼Œä»¥åŠç¦»çº¿è¯æ®è’¸é¦è§£å†³å¥–åŠ±ç¨€ç–æ€§ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºŽï¼Œå®ƒä¸å†ä¾èµ–å›ºå®šæ•°é‡çš„æ®µè½æˆ–å•æ¬¡æŽ’åºï¼Œè€Œæ˜¯åŠ¨æ€é€‰æ‹©å­é›†ï¼Œæ›´è´´åˆå®žé™…é—®ç­”éœ€æ±‚ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼šä½¿ç”¨ç•™ä¸€æ³•ï¼ˆLOOï¼‰åœ¨ç¦»çº¿é˜¶æ®µæŒ–æŽ˜â€œæœ€å°å……åˆ†é›†â€ä½œä¸ºç›‘ç£ä¿¡å·ï¼›è®¾è®¡å†—ä½™æ„ŸçŸ¥çš„å¥–åŠ±å‡½æ•°ï¼Œé¼“åŠ±é€‰æ‹©ç´§å‡‘è¯æ®ï¼›é‡‡ç”¨æŽ¨ç†å¼•å¯¼çš„æ ¼å¼ï¼Œå°†é—®é¢˜åˆ†è§£ä¸ºå­æ­¥éª¤ï¼›å¼ºåŒ–å­¦ä¹ ä¸­ä½¿ç”¨ç­–ç•¥æ¢¯åº¦æ–¹æ³•ä¼˜åŒ–ç½‘ç»œå‚æ•°ï¼Œå…·ä½“ç½‘ç»œç»“æž„å¯èƒ½åŸºäºŽTransformerç¼–ç å™¨ï¼Œä½†è®ºæ–‡æœªè¯¦ç»†è¯´æ˜Žã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨äº”ä¸ªé•¿ä¸Šä¸‹æ–‡å’Œå¤šè·³é—®ç­”åŸºå‡†ï¼ˆå…·ä½“åç§°æœªæåŠï¼‰ä¸Šï¼ŒContext-Pickeræ˜¾è‘—ä¼˜äºŽå¼ºå¤§çš„RAGåŸºçº¿ï¼Œå®žçŽ°æ›´é«˜çš„ç­”æ¡ˆå‡†ç¡®æ€§ï¼ŒåŒæ—¶ä¸Šä¸‹æ–‡é•¿åº¦å¯æ¯”æˆ–æ›´çŸ­ã€‚æ¶ˆèžç ”ç©¶è¡¨æ˜Žï¼Œä»Žç²—åˆ°ç»†çš„ä¼˜åŒ–è®¡åˆ’ã€å†—ä½™æ„ŸçŸ¥å¥–åŠ±å¡‘é€ å’ŒæŽ¨ç†å¼•å¯¼æ ¼å¼å¯¹æ€§èƒ½å¢žç›Šæœ‰å®žè´¨æ€§è´¡çŒ®ï¼Œå…·ä½“æå‡å¹…åº¦è®ºæ–‡æœªæä¾›æ•°å€¼ï¼Œä½†å¼ºè°ƒâ€œæ˜¾è‘—ä¼˜äºŽâ€ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨é•¿ä¸Šä¸‹æ–‡é—®ç­”é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå¦‚æ™ºèƒ½å®¢æœã€æ–‡æ¡£æ£€ç´¢ã€æ•™è‚²è¾…åŠ©å’ŒåŒ»ç–—è¯Šæ–­ç³»ç»Ÿï¼Œå¯æé«˜ä¿¡æ¯æ£€ç´¢çš„å‡†ç¡®æ€§å’Œæ•ˆçŽ‡ã€‚å®žé™…ä»·å€¼åœ¨äºŽå‡å°‘è®¡ç®—èµ„æºæ¶ˆè€—ï¼Œæå‡ç”¨æˆ·ä½“éªŒï¼Œæœªæ¥å¯èƒ½æŽ¨åŠ¨è‡ªé€‚åº”ä¸Šä¸‹æ–‡é€‰æ‹©æŠ€æœ¯çš„å‘å±•ï¼Œå½±å“è‡ªç„¶è¯­è¨€å¤„ç†å’Œä¿¡æ¯æ£€ç´¢çš„èŒƒå¼ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In long-context question answering (LCQA), determining the optimal amount of context for a given query is a significant challenge. Including too few passages may omit critical information, while including too many can introduce noise and reduce the quality of the answer. Traditional approaches, such as fixed Top-$K$ retrieval and single-stage reranking, face the dilemma of selecting the right number of passages. This problem is particularly pronounced for factoid questions, which often require only a few specific pieces of evidence. To address this issue, we introduce \emph{Context-Picker}, a reasoning-aware framework that shifts the paradigm from similarity-based ranking to minimal sufficient subset selection. Context-Picker treats context selection as a decision-making process optimized via a human-inspired, two-stage reinforcement learning schedule: a \emph{recall-oriented} stage that prioritizes the coverage of reasoning chains, followed by a \emph{precision-oriented} stage that aggressively prunes redundancy to distill a compact evidence set. To resolve reward sparsity, we propose an offline evidence distillation pipeline that mines "minimal sufficient sets" via a Leave-One-Out (LOO) procedure, providing dense, task-aligned supervision. Experiments on five long-context and multi-hop QA benchmarks demonstrate that Context-Picker significantly outperforms strong RAG baselines, achieving superior answer accuracy with comparable or reduced context lengths. Ablation studies indicate that the coarse-to-fine optimization schedule, the redundancy-aware reward shaping, and the rationale-guided format all contribute substantially to these gains.

