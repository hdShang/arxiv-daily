---
layout: default
title: VASA-3D: Lifelike Audio-Driven Gaussian Head Avatars from a Single Image
---

# VASA-3D: Lifelike Audio-Driven Gaussian Head Avatars from a Single Image

**arXiv**: [2512.14677v1](https://arxiv.org/abs/2512.14677) | [PDF](https://arxiv.org/pdf/2512.14677.pdf)

**ä½œè€…**: Sicheng Xu, Guojun Chen, Jiaolong Yang, Yizhong Zhang, Yu Deng, Steve Lin, Baining Guo

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: NeurIPS 2025 paper. Project webpage: https://www.microsoft.com/en-us/research/project/vasa-3d/

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVASA-3Dä»¥è§£å†³ä»Žå•å¼ å›¾åƒç”Ÿæˆé«˜çœŸå®žæ„ŸéŸ³é¢‘é©±åŠ¨3Då¤´éƒ¨è™šæ‹Ÿå½¢è±¡çš„æŒ‘æˆ˜**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `éŸ³é¢‘é©±åŠ¨è™šæ‹Ÿå½¢è±¡` `3Då¤´éƒ¨é‡å»º` `å•å›¾åƒç”Ÿæˆ` `è¿åŠ¨æ½œåœ¨è¡¨ç¤º` `ä¼˜åŒ–æ¡†æž¶` `è‡ªç”±è§†ç‚¹è§†é¢‘` `è¡¨æƒ…ç»†èŠ‚å»ºæ¨¡` `å®žæ—¶æ¸²æŸ“`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•éš¾ä»¥ä»Žå•å¼ å›¾åƒç”Ÿæˆé«˜çœŸå®žæ„Ÿçš„3Då¤´éƒ¨è™šæ‹Ÿå½¢è±¡ï¼Œç‰¹åˆ«æ˜¯åœ¨æ•æ‰ç»†å¾®è¡¨æƒ…ç»†èŠ‚æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚
2. VASA-3Dé€šè¿‡åˆ©ç”¨VASA-1çš„è¿åŠ¨æ½œåœ¨è¡¨ç¤ºï¼Œå¹¶è®¾è®¡æ¡ä»¶åŒ–3Då¤´éƒ¨æ¨¡åž‹å’Œä¼˜åŒ–æ¡†æž¶ï¼Œå®žçŽ°ä»Žå•å¼ å›¾åƒç”ŸæˆéŸ³é¢‘é©±åŠ¨çš„3Dè™šæ‹Ÿå½¢è±¡ã€‚
3. å®žéªŒç»“æžœæ˜¾ç¤ºï¼ŒVASA-3Dèƒ½ç”Ÿæˆé€¼çœŸçš„3Dè¯´è¯å¤´éƒ¨ï¼Œæ”¯æŒåœ¨çº¿ç”Ÿæˆ512x512åˆ†è¾¨çŽ‡ã€75 FPSçš„è‡ªç”±è§†ç‚¹è§†é¢‘ï¼Œæ˜¾è‘—è¶…è¶ŠçŽ°æœ‰æŠ€æœ¯ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬æå‡ºäº†VASA-3Dï¼Œä¸€ç§éŸ³é¢‘é©±åŠ¨çš„å•æ¬¡3Då¤´éƒ¨è™šæ‹Ÿå½¢è±¡ç”Ÿæˆå™¨ã€‚è¿™é¡¹ç ”ç©¶è§£å†³äº†ä¸¤ä¸ªä¸»è¦æŒ‘æˆ˜ï¼šæ•æ‰çœŸå®žäººè„¸ä¸­å­˜åœ¨çš„ç»†å¾®è¡¨æƒ…ç»†èŠ‚ï¼Œä»¥åŠä»Žå•å¼ è‚–åƒå›¾åƒé‡å»ºå¤æ‚çš„3Då¤´éƒ¨è™šæ‹Ÿå½¢è±¡ã€‚ä¸ºäº†å‡†ç¡®å»ºæ¨¡è¡¨æƒ…ç»†èŠ‚ï¼ŒVASA-3Dåˆ©ç”¨äº†VASA-1çš„è¿åŠ¨æ½œåœ¨è¡¨ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨2Dè¯´è¯å¤´éƒ¨ç”Ÿæˆä¸­å±•çŽ°å‡ºå“è¶Šçš„çœŸå®žæ„Ÿå’Œç”ŸåŠ¨æ€§ã€‚æˆ‘ä»¬å·¥ä½œçš„ä¸€ä¸ªå…³é”®è¦ç´ æ˜¯å°†è¿™ç§è¿åŠ¨æ½œåœ¨è¡¨ç¤ºè½¬æ¢åˆ°3Dç©ºé—´ï¼Œè¿™æ˜¯é€šè¿‡è®¾è®¡ä¸€ä¸ªä»¥è¿åŠ¨æ½œåœ¨è¡¨ç¤ºä¸ºæ¡ä»¶çš„3Då¤´éƒ¨æ¨¡åž‹æ¥å®žçŽ°çš„ã€‚è¯¥æ¨¡åž‹é’ˆå¯¹å•å¼ å›¾åƒçš„å®šåˆ¶åŒ–æ˜¯é€šè¿‡ä¸€ä¸ªä¼˜åŒ–æ¡†æž¶å®žçŽ°çš„ï¼Œè¯¥æ¡†æž¶ä½¿ç”¨äº†ä»Žè¾“å…¥å›¾åƒåˆæˆçš„å‚è€ƒå¤´éƒ¨çš„å¤§é‡è§†é¢‘å¸§ã€‚ä¼˜åŒ–è¿‡ç¨‹é‡‡ç”¨äº†å¤šç§è®­ç»ƒæŸå¤±å‡½æ•°ï¼Œè¿™äº›æŸå¤±å‡½æ•°å¯¹ç”Ÿæˆè®­ç»ƒæ•°æ®ä¸­çš„ä¼ªå½±å’Œæœ‰é™å§¿æ€è¦†ç›–å…·æœ‰é²æ£’æ€§ã€‚æˆ‘ä»¬çš„å®žéªŒè¡¨æ˜Žï¼ŒVASA-3Dç”Ÿæˆäº†çŽ°æœ‰æŠ€æœ¯æ— æ³•å®žçŽ°çš„é€¼çœŸ3Dè¯´è¯å¤´éƒ¨ï¼Œå¹¶æ”¯æŒåœ¨çº¿ç”Ÿæˆ512x512åˆ†è¾¨çŽ‡ã€é«˜è¾¾75 FPSçš„è‡ªç”±è§†ç‚¹è§†é¢‘ï¼Œä»Žè€Œä¿ƒè¿›äº†ä¸Žé€¼çœŸ3Dè™šæ‹Ÿå½¢è±¡æ›´æ²‰æµ¸å¼çš„äº’åŠ¨ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

VASA-3Dçš„æ•´ä½“æ¡†æž¶åŸºäºŽéŸ³é¢‘é©±åŠ¨çš„3Då¤´éƒ¨è™šæ‹Ÿå½¢è±¡ç”Ÿæˆï¼Œæ ¸å¿ƒåŒ…æ‹¬ï¼šåˆ©ç”¨VASA-1çš„è¿åŠ¨æ½œåœ¨è¡¨ç¤ºæ¥å»ºæ¨¡è¡¨æƒ…ç»†èŠ‚ï¼Œè®¾è®¡ä¸€ä¸ªä»¥è¯¥è¿åŠ¨æ½œåœ¨è¡¨ç¤ºä¸ºæ¡ä»¶çš„3Då¤´éƒ¨æ¨¡åž‹ï¼Œå®žçŽ°ä»Ž2Dåˆ°3Dçš„è½¬æ¢ã€‚å…³é”®æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽé€šè¿‡ä¼˜åŒ–æ¡†æž¶å®šåˆ¶åŒ–æ¨¡åž‹åˆ°å•å¼ å›¾åƒï¼Œä½¿ç”¨ä»Žè¾“å…¥å›¾åƒåˆæˆçš„è§†é¢‘å¸§è¿›è¡Œè®­ç»ƒï¼Œå¹¶é‡‡ç”¨é²æ£’æŸå¤±å‡½æ•°å¤„ç†æ•°æ®ä¸­çš„ä¼ªå½±å’Œå§¿æ€é™åˆ¶ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºŽï¼Œå®ƒç»“åˆäº†VASA-1çš„é«˜è´¨é‡2Dè¿åŠ¨å»ºæ¨¡èƒ½åŠ›ï¼Œå¹¶æ‰©å±•åˆ°3Dç©ºé—´ï¼Œè§£å†³äº†å•å›¾åƒé‡å»ºå’Œè¡¨æƒ…ç»†èŠ‚æ•æ‰çš„æŒ‘æˆ˜ï¼Œè€Œä¼ ç»Ÿæ–¹æ³•å¾€å¾€ä¾èµ–å¤šè§†å›¾æ•°æ®æˆ–éš¾ä»¥ç”Ÿæˆé€¼çœŸåŠ¨æ€ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

VASA-3Dåœ¨å®žéªŒä¸­ç”Ÿæˆé€¼çœŸçš„3Dè¯´è¯å¤´éƒ¨ï¼Œè¶…è¶ŠçŽ°æœ‰æŠ€æœ¯ï¼Œæ”¯æŒåœ¨çº¿ç”Ÿæˆ512x512åˆ†è¾¨çŽ‡ã€é«˜è¾¾75 FPSçš„è‡ªç”±è§†ç‚¹è§†é¢‘ï¼Œä¼˜åŒ–æ¡†æž¶æœ‰æ•ˆå¤„ç†è®­ç»ƒæ•°æ®ä¸­çš„ä¼ªå½±å’Œå§¿æ€è¦†ç›–é—®é¢˜ï¼Œå®žçŽ°äº†é«˜çœŸå®žæ„Ÿå’Œå®žæ—¶æ€§èƒ½ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨è™šæ‹ŸçŽ°å®žã€å¢žå¼ºçŽ°å®žã€æ¸¸æˆã€åœ¨çº¿æ•™è‚²å’Œè¿œç¨‹ä¼šè®®ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›åº”ç”¨æ½œåŠ›ï¼Œèƒ½åˆ›å»ºé€¼çœŸçš„3Dè™šæ‹Ÿå½¢è±¡ï¼Œæå‡æ²‰æµ¸å¼äº’åŠ¨ä½“éªŒï¼Œä¾‹å¦‚ç”¨äºŽä¸ªæ€§åŒ–è™šæ‹ŸåŠ©æ‰‹æˆ–ç¤¾äº¤å¹³å°ä¸­çš„åŠ¨æ€å¤´åƒã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We propose VASA-3D, an audio-driven, single-shot 3D head avatar generator. This research tackles two major challenges: capturing the subtle expression details present in real human faces, and reconstructing an intricate 3D head avatar from a single portrait image. To accurately model expression details, VASA-3D leverages the motion latent of VASA-1, a method that yields exceptional realism and vividness in 2D talking heads. A critical element of our work is translating this motion latent to 3D, which is accomplished by devising a 3D head model that is conditioned on the motion latent. Customization of this model to a single image is achieved through an optimization framework that employs numerous video frames of the reference head synthesized from the input image. The optimization takes various training losses robust to artifacts and limited pose coverage in the generated training data. Our experiment shows that VASA-3D produces realistic 3D talking heads that cannot be achieved by prior art, and it supports the online generation of 512x512 free-viewpoint videos at up to 75 FPS, facilitating more immersive engagements with lifelike 3D avatars.

