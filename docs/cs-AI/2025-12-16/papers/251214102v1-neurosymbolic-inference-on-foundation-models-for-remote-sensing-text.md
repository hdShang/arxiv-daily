---
layout: default
title: Neurosymbolic Inference On Foundation Models For Remote Sensing Text-to-image Retrieval With Complex Queries
---

# Neurosymbolic Inference On Foundation Models For Remote Sensing Text-to-image Retrieval With Complex Queries

**arXiv**: [2512.14102v1](https://arxiv.org/abs/2512.14102) | [PDF](https://arxiv.org/pdf/2512.14102.pdf)

**ä½œè€…**: Emanuele Mezzi, Gertjan Burghouts, Maarten Kruithof

**åˆ†ç±»**: cs.CV, cs.AI, cs.IR

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRUNEæ–¹æ³•ï¼Œç»“åˆå¤§è¯­è¨€æ¨¡åž‹ä¸Žç¥žç»ç¬¦å·AIï¼Œè§£å†³é¥æ„Ÿæ–‡æœ¬åˆ°å›¾åƒæ£€ç´¢ä¸­å¤æ‚æŸ¥è¯¢çš„æŽ¨ç†ä¸Žå¯è§£é‡Šæ€§é—®é¢˜ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `é¥æ„Ÿæ–‡æœ¬åˆ°å›¾åƒæ£€ç´¢` `ç¥žç»ç¬¦å·AI` `å¤§è¯­è¨€æ¨¡åž‹` `è°“è¯é€»è¾‘æŽ¨ç†` `å¤æ‚æŸ¥è¯¢å¤„ç†` `å¯è§£é‡Šæ€§å¢žå¼º` `é¥æ„Ÿåº”ç”¨` `æ€§èƒ½é²æ£’æ€§è¯„ä¼°`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰é¥æ„Ÿæ–‡æœ¬åˆ°å›¾åƒæ£€ç´¢æ–¹æ³•ï¼ˆå¦‚RS-LVLMsï¼‰å­˜åœ¨å¯è§£é‡Šæ€§å·®å’Œéš¾ä»¥å¤„ç†å¤æ‚ç©ºé—´å…³ç³»çš„æŒ‘æˆ˜ï¼Œé™åˆ¶äº†å®žé™…åº”ç”¨ã€‚
2. è®ºæ–‡æå‡ºRUNEæ–¹æ³•ï¼Œç»“åˆå¤§è¯­è¨€æ¨¡åž‹ç”Ÿæˆè°“è¯é€»è¾‘è¡¨è¾¾å¼ï¼Œå¹¶åˆ©ç”¨ç¥žç»ç¬¦å·AIè¿›è¡Œæ˜¾å¼æŽ¨ç†ï¼Œæå‡æ£€ç´¢æ€§èƒ½å’Œå¯è§£é‡Šæ€§ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒRUNEåœ¨å¤æ‚æŸ¥è¯¢ä»»åŠ¡ä¸­ä¼˜äºŽçŽ°æœ‰RS-LVLMsï¼Œå¹¶å¼•å…¥æ–°æŒ‡æ ‡è¯„ä¼°é²æ£’æ€§ï¼Œå±•ç¤ºäº†åœ¨æ´ªæ°´åŽå«æ˜Ÿå›¾åƒæ£€ç´¢ç­‰åœºæ™¯çš„åº”ç”¨æ½œåŠ›ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é¥æ„Ÿé¢†åŸŸçš„æ–‡æœ¬åˆ°å›¾åƒæ£€ç´¢éšç€é’ˆå¯¹èˆªç©ºå’Œå«æ˜Ÿå½±åƒå®šåˆ¶çš„å¤§åž‹è§†è§‰è¯­è¨€æ¨¡åž‹ï¼ˆRS-LVLMsï¼‰çš„å…´èµ·è€Œå¿«é€Ÿå‘å±•ã€‚ç„¶è€Œï¼Œæœ‰é™çš„å¯è§£é‡Šæ€§å’Œå¯¹å¤æ‚ç©ºé—´å…³ç³»å¤„ç†èƒ½åŠ›å·®ä»æ˜¯å®žé™…åº”ç”¨ä¸­çš„å…³é”®æŒ‘æˆ˜ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†RUNEï¼ˆä½¿ç”¨ç¥žç»ç¬¦å·å®žä½“è¿›è¡ŒæŽ¨ç†ï¼‰ï¼Œè¯¥æ–¹æ³•å°†å¤§è¯­è¨€æ¨¡åž‹ä¸Žç¥žç»ç¬¦å·AIç›¸ç»“åˆï¼Œé€šè¿‡æŽ¨ç†æ£€æµ‹åˆ°çš„å®žä½“ä¸Žä»Žæ–‡æœ¬æŸ¥è¯¢å¯¼å‡ºçš„è°“è¯é€»è¾‘è¡¨è¾¾å¼ä¹‹é—´çš„å…¼å®¹æ€§æ¥æ£€ç´¢å›¾åƒã€‚ä¸Žä¾èµ–éšå¼è”åˆåµŒå…¥çš„RS-LVLMsä¸åŒï¼ŒRUNEæ‰§è¡Œæ˜¾å¼æŽ¨ç†ï¼Œä»Žè€Œæå‡æ€§èƒ½å’Œå¯è§£é‡Šæ€§ã€‚ä¸ºæ‰©å±•æ€§ï¼Œæˆ‘ä»¬æå‡ºä¸€ç§é€»è¾‘åˆ†è§£ç­–ç•¥ï¼Œåœ¨æ£€æµ‹å®žä½“çš„æ¡ä»¶å­é›†ä¸Šæ“ä½œï¼Œä¿è¯æ¯”ç¥žç»æ–¹æ³•æ›´çŸ­çš„æ‰§è¡Œæ—¶é—´ã€‚æˆ‘ä»¬ä»…åˆ©ç”¨åŸºç¡€æ¨¡åž‹ç”Ÿæˆè°“è¯é€»è¾‘è¡¨è¾¾å¼ï¼Œå°†æŽ¨ç†å§”æ‰˜ç»™ç¥žç»ç¬¦å·æŽ¨ç†æ¨¡å—ï¼Œè€Œéžç”¨äºŽç«¯åˆ°ç«¯æ£€ç´¢ã€‚ä¸ºè¯„ä¼°ï¼Œæˆ‘ä»¬é‡æ–°åˆ©ç”¨åŽŸæœ¬ä¸ºç‰©ä½“æ£€æµ‹è®¾è®¡çš„DOTAæ•°æ®é›†ï¼Œé€šè¿‡æ·»åŠ æ¯”çŽ°æœ‰åŸºå‡†æ›´å¤æ‚çš„æŸ¥è¯¢æ¥å¢žå¼ºå®ƒã€‚æˆ‘ä»¬å±•ç¤ºäº†å¤§è¯­è¨€æ¨¡åž‹åœ¨æ–‡æœ¬åˆ°é€»è¾‘ç¿»è¯‘ä¸­çš„æœ‰æ•ˆæ€§ï¼Œå¹¶å°†RUNEä¸Žæœ€å…ˆè¿›çš„RS-LVLMsè¿›è¡Œæ¯”è¾ƒï¼Œè¯æ˜Žäº†å…¶ä¼˜è¶Šæ€§èƒ½ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸¤ä¸ªæŒ‡æ ‡ï¼šæ£€ç´¢å¯¹æŸ¥è¯¢å¤æ‚æ€§çš„é²æ£’æ€§å’Œæ£€ç´¢å¯¹å›¾åƒä¸ç¡®å®šæ€§çš„é²æ£’æ€§ï¼Œè¯„ä¼°æ€§èƒ½ç›¸å¯¹äºŽæŸ¥è¯¢å¤æ‚æ€§å’Œå›¾åƒä¸ç¡®å®šæ€§çš„è¡¨çŽ°ã€‚RUNEåœ¨å¤æ‚é¥æ„Ÿæ£€ç´¢ä»»åŠ¡ä¸­ä¼˜äºŽè”åˆåµŒå…¥æ¨¡åž‹ï¼Œåœ¨æ€§èƒ½ã€é²æ£’æ€§å’Œå¯è§£é‡Šæ€§æ–¹é¢å¸¦æ¥å¢žç›Šã€‚æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªæ´ªæ°´åŽå«æ˜Ÿå›¾åƒæ£€ç´¢çš„ç”¨ä¾‹å±•ç¤ºäº†RUNEåœ¨çŽ°å®žä¸–ç•Œé¥æ„Ÿåº”ç”¨ä¸­çš„æ½œåŠ›ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

RUNEçš„æ•´ä½“æ¡†æž¶åŒ…æ‹¬ä¸¤ä¸ªæ ¸å¿ƒæ¨¡å—ï¼šå¤§è¯­è¨€æ¨¡åž‹ç”¨äºŽå°†æ–‡æœ¬æŸ¥è¯¢ç¿»è¯‘ä¸ºè°“è¯é€»è¾‘è¡¨è¾¾å¼ï¼Œä»¥åŠç¥žç»ç¬¦å·æŽ¨ç†æ¨¡å—ç”¨äºŽåŸºäºŽæ£€æµ‹åˆ°çš„å®žä½“è¿›è¡Œæ˜¾å¼æŽ¨ç†ã€‚å…³é”®æŠ€æœ¯åˆ›æ–°åœ¨äºŽé€»è¾‘åˆ†è§£ç­–ç•¥ï¼Œå®ƒé€šè¿‡æ“ä½œæ£€æµ‹å®žä½“çš„æ¡ä»¶å­é›†æ¥ä¿è¯æ›´çŸ­çš„æ‰§è¡Œæ—¶é—´ï¼Œæé«˜å¯æ‰©å±•æ€§ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºŽï¼ŒRUNEä¸ä¾èµ–éšå¼è”åˆåµŒå…¥ï¼Œè€Œæ˜¯æ‰§è¡Œæ˜¾å¼æŽ¨ç†ï¼Œä»Žè€Œå¢žå¼ºå¯è§£é‡Šæ€§å’Œå¤„ç†å¤æ‚æŸ¥è¯¢çš„èƒ½åŠ›ï¼ŒåŒæ—¶ä»…åˆ©ç”¨åŸºç¡€æ¨¡åž‹ç”Ÿæˆé€»è¾‘è¡¨è¾¾å¼ï¼Œè€Œéžç«¯åˆ°ç«¯æ£€ç´¢ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

RUNEåœ¨å¤æ‚é¥æ„Ÿæ£€ç´¢ä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºŽæœ€å…ˆè¿›çš„RS-LVLMsï¼Œé€šè¿‡å¼•å…¥æ£€ç´¢å¯¹æŸ¥è¯¢å¤æ‚æ€§å’Œå›¾åƒä¸ç¡®å®šæ€§çš„é²æ£’æ€§æŒ‡æ ‡ï¼Œå±•ç¤ºäº†æ›´é«˜çš„æ€§èƒ½å’Œé²æ£’æ€§ï¼Œå¹¶åœ¨DOTAæ•°æ®é›†å¢žå¼ºç‰ˆæœ¬ä¸ŠéªŒè¯äº†æœ‰æ•ˆæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨é¥æ„Ÿé¢†åŸŸå…·æœ‰å¹¿æ³›æ½œåœ¨åº”ç”¨ï¼Œå¦‚æ´ªæ°´åŽå«æ˜Ÿå›¾åƒæ£€ç´¢ã€åŸŽå¸‚è§„åˆ’ä¸­çš„å¤æ‚åœºæ™¯åˆ†æžï¼Œä»¥åŠçŽ¯å¢ƒç›‘æµ‹ä¸­çš„å¤šç›®æ ‡è¯†åˆ«ä»»åŠ¡ï¼Œèƒ½æå‡æ£€ç´¢çš„å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ï¼Œæ”¯æŒå†³ç­–åˆ¶å®šã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Text-to-image retrieval in remote sensing (RS) has advanced rapidly with the rise of large vision-language models (LVLMs) tailored for aerial and satellite imagery, culminating in remote sensing large vision-language models (RS-LVLMS). However, limited explainability and poor handling of complex spatial relations remain key challenges for real-world use. To address these issues, we introduce RUNE (Reasoning Using Neurosymbolic Entities), an approach that combines Large Language Models (LLMs) with neurosymbolic AI to retrieve images by reasoning over the compatibility between detected entities and First-Order Logic (FOL) expressions derived from text queries. Unlike RS-LVLMs that rely on implicit joint embeddings, RUNE performs explicit reasoning, enhancing performance and interpretability. For scalability, we propose a logic decomposition strategy that operates on conditioned subsets of detected entities, guaranteeing shorter execution time compared to neural approaches. Rather than using foundation models for end-to-end retrieval, we leverage them only to generate FOL expressions, delegating reasoning to a neurosymbolic inference module. For evaluation we repurpose the DOTA dataset, originally designed for object detection, by augmenting it with more complex queries than in existing benchmarks. We show the LLM's effectiveness in text-to-logic translation and compare RUNE with state-of-the-art RS-LVLMs, demonstrating superior performance. We introduce two metrics, Retrieval Robustness to Query Complexity (RRQC) and Retrieval Robustness to Image Uncertainty (RRIU), which evaluate performance relative to query complexity and image uncertainty. RUNE outperforms joint-embedding models in complex RS retrieval tasks, offering gains in performance, robustness, and explainability. We show RUNE's potential for real-world RS applications through a use case on post-flood satellite image retrieval.

