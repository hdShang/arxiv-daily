---
layout: default
title: PentestEval: Benchmarking LLM-based Penetration Testing with Modular and Stage-Level Design
---

# PentestEval: Benchmarking LLM-based Penetration Testing with Modular and Stage-Level Design

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.14233" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.14233v1</a>
  <a href="https://arxiv.org/pdf/2512.14233.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14233v1" onclick="toggleFavorite(this, '2512.14233v1', 'PentestEval: Benchmarking LLM-based Penetration Testing with Modular and Stage-Level Design')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ruozhao Yang, Mingfei Cheng, Gelei Deng, Tianwei Zhang, Junjie Wang, Xiaofei Xie

**åˆ†ç±»**: cs.SE, cs.AI, cs.CR

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: 13 pages, 6 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**PentestEvalï¼šé¦–ä¸ªæ¨¡å—åŒ–ã€åˆ†é˜¶æ®µè¯„ä¼°LLMæ¸—é€æµ‹è¯•èƒ½åŠ›çš„ç»¼åˆåŸºå‡†**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ¸—é€æµ‹è¯•` `å¤§å‹è¯­è¨€æ¨¡å‹` `åŸºå‡†æµ‹è¯•` `å®‰å…¨è¯„ä¼°` `è‡ªåŠ¨åŒ–` `æ¼æ´æŒ–æ˜` `å®‰å…¨æ¼æ´`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿæ¸—é€æµ‹è¯•é«˜åº¦ä¾èµ–äººå·¥ï¼Œéœ€è¦å¤§é‡ä¸“ä¸šçŸ¥è¯†ï¼Œä¸”éš¾ä»¥è§„æ¨¡åŒ–ï¼ŒLLMåœ¨è‡ªåŠ¨åŒ–æ–¹é¢å±•ç°æ½œåŠ›ï¼Œä½†ç°æœ‰æ–¹æ³•ç¼ºä¹ä»»åŠ¡åˆ†è§£å’Œé¢†åŸŸè‡ªé€‚åº”ã€‚
2. PentestEvalé€šè¿‡æ¨¡å—åŒ–è®¾è®¡ï¼Œå°†æ¸—é€æµ‹è¯•åˆ†è§£ä¸ºå…­ä¸ªé˜¶æ®µï¼Œå¹¶æ„å»ºäº†åŒ…å«ä¸“å®¶æ ‡æ³¨çš„ç»¼åˆåŸºå‡†ï¼Œç”¨äºè¯„ä¼°LLMåœ¨å„ä¸ªé˜¶æ®µçš„è¡¨ç°ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œç°æœ‰LLMåœ¨æ¸—é€æµ‹è¯•å„é˜¶æ®µè¡¨ç°è¾ƒå¼±ï¼Œç«¯åˆ°ç«¯æˆåŠŸç‡ä½ï¼Œè¡¨æ˜è‡ªä¸»æ¸—é€æµ‹è¯•éœ€è¦æ›´å¼ºçš„ç»“æ„åŒ–æ¨ç†èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ¸—é€æµ‹è¯•å¯¹äºè¯„ä¼°å’ŒåŠ å¼ºç³»ç»Ÿå®‰å…¨æ€§ä»¥æŠµå¾¡çœŸå®å¨èƒè‡³å…³é‡è¦ï¼Œä½†ä¼ ç»Ÿå·¥ä½œæµç¨‹ä»ç„¶é«˜åº¦ä¾èµ–äººå·¥ã€éœ€è¦ä¸“ä¸šçŸ¥è¯†ä¸”éš¾ä»¥æ‰©å±•ã€‚è™½ç„¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æœ€æ–°è¿›å±•ä¸ºè‡ªåŠ¨åŒ–æä¾›äº†æœ‰å¸Œæœ›çš„æœºä¼šï¼Œä½†ç°æœ‰åº”ç”¨ä¾èµ–äºç®€å•çš„æç¤ºï¼Œç¼ºä¹ä»»åŠ¡åˆ†è§£æˆ–é¢†åŸŸè‡ªé€‚åº”ï¼Œå¯¼è‡´ä¸å¯é çš„é»‘ç›’è¡Œä¸ºï¼Œå¹¶ä¸”å¯¹æ¨¡å‹åœ¨æ¸—é€æµ‹è¯•å„é˜¶æ®µçš„èƒ½åŠ›ç¼ºä¹æ·±å…¥äº†è§£ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æ¨å‡ºäº†PentestEvalï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªç»¼åˆåŸºå‡†ï¼Œç”¨äºè¯„ä¼°LLMåœ¨å…­ä¸ªåˆ†è§£çš„æ¸—é€æµ‹è¯•é˜¶æ®µçš„èƒ½åŠ›ï¼šä¿¡æ¯æ”¶é›†ã€å¼±ç‚¹æ”¶é›†å’Œè¿‡æ»¤ã€æ”»å‡»å†³ç­–ã€æ¼æ´åˆ©ç”¨ç”Ÿæˆå’Œä¿®è®¢ã€‚PentestEvalé›†æˆäº†ä¸“å®¶æ³¨é‡Šçš„çœŸå®æ•°æ®ä»¥åŠä¸€ä¸ªå®Œå…¨è‡ªåŠ¨åŒ–çš„è¯„ä¼°æµç¨‹ï¼Œæ¶µç›–12ä¸ªç°å®çš„è„†å¼±åœºæ™¯ä¸­çš„346ä¸ªä»»åŠ¡ã€‚æˆ‘ä»¬å¯¹9ä¸ªå¹¿æ³›ä½¿ç”¨çš„LLMè¿›è¡Œçš„é˜¶æ®µæ€§è¯„ä¼°æ˜¾ç¤ºï¼Œæ€»ä½“æ€§èƒ½è¾ƒå¼±ï¼Œå¹¶ä¸”åœ¨æ¸—é€æµ‹è¯•å·¥ä½œæµç¨‹çš„å„ä¸ªé˜¶æ®µå­˜åœ¨æ˜æ˜¾çš„å±€é™æ€§ã€‚ç«¯åˆ°ç«¯ç®¡é“çš„æˆåŠŸç‡ä»…ä¸º31%ï¼Œç°æœ‰çš„LLMé©±åŠ¨ç³»ç»Ÿï¼ˆå¦‚PentestGPTã€PentestAgentå’ŒVulnBotï¼‰ä¹Ÿè¡¨ç°å‡ºç±»ä¼¼çš„å±€é™æ€§ï¼Œè‡ªä¸»ä»£ç†å‡ ä¹å®Œå…¨å¤±è´¥ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼Œè‡ªä¸»æ¸—é€æµ‹è¯•éœ€è¦æ›´å¼ºçš„ç»“æ„åŒ–æ¨ç†ï¼Œå…¶ä¸­æ¨¡å—åŒ–å¢å¼ºäº†æ¯ä¸ªå•ç‹¬çš„é˜¶æ®µå¹¶æé«˜äº†æ•´ä½“æ€§èƒ½ã€‚PentestEvalä¸ºæœªæ¥å…³äºç»†ç²’åº¦ã€é˜¶æ®µæ€§è¯„ä¼°çš„ç ”ç©¶æä¾›äº†åŸºç¡€åŸºå‡†ï¼Œä¸ºæ›´å¯é çš„åŸºäºLLMçš„è‡ªåŠ¨åŒ–é“ºå¹³äº†é“è·¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰åŸºäºLLMçš„æ¸—é€æµ‹è¯•æ–¹æ³•é€šå¸¸é‡‡ç”¨é»‘ç›’æ–¹å¼ï¼Œç¼ºä¹å¯¹ä»»åŠ¡çš„åˆ†è§£å’Œé¢†åŸŸçŸ¥è¯†çš„é€‚é…ï¼Œå¯¼è‡´æ€§èƒ½ä¸ç¨³å®šï¼Œéš¾ä»¥æ·±å…¥äº†è§£æ¨¡å‹åœ¨ä¸åŒæ¸—é€æµ‹è¯•é˜¶æ®µçš„èƒ½åŠ›ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ä¸ªèƒ½å¤Ÿç»†ç²’åº¦è¯„ä¼°LLMåœ¨æ¸—é€æµ‹è¯•å„ä¸ªé˜¶æ®µè¡¨ç°çš„åŸºå‡†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šPentestEvalçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†æ¸—é€æµ‹è¯•è¿‡ç¨‹åˆ†è§£ä¸ºå…­ä¸ªå…³é”®é˜¶æ®µï¼šä¿¡æ¯æ”¶é›†ã€å¼±ç‚¹æ”¶é›†ä¸è¿‡æ»¤ã€æ”»å‡»å†³ç­–ã€æ¼æ´åˆ©ç”¨ç”Ÿæˆå’Œä¿®è®¢ã€‚é€šè¿‡æ„å»ºåŒ…å«ä¸“å®¶æ ‡æ³¨çš„æµ‹è¯•ç”¨ä¾‹ï¼Œå¹¶è®¾è®¡è‡ªåŠ¨åŒ–çš„è¯„ä¼°æµç¨‹ï¼Œå¯ä»¥å¯¹LLMåœ¨æ¯ä¸ªé˜¶æ®µçš„è¡¨ç°è¿›è¡Œé‡åŒ–è¯„ä¼°ï¼Œä»è€Œå‘ç°å…¶ä¼˜åŠ¿å’Œä¸è¶³ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPentestEvalåŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) è„†å¼±åœºæ™¯åº“ï¼šåŒ…å«12ä¸ªç°å®çš„è„†å¼±åœºæ™¯ï¼Œæ¶µç›–å¸¸è§çš„å®‰å…¨æ¼æ´ã€‚2) æµ‹è¯•ç”¨ä¾‹é›†ï¼šæ¯ä¸ªåœºæ™¯åŒ…å«å¤šä¸ªæµ‹è¯•ç”¨ä¾‹ï¼Œè¦†ç›–æ¸—é€æµ‹è¯•çš„å…­ä¸ªé˜¶æ®µã€‚3) ä¸“å®¶æ ‡æ³¨ï¼šæ¯ä¸ªæµ‹è¯•ç”¨ä¾‹éƒ½ç”±å®‰å…¨ä¸“å®¶è¿›è¡Œæ ‡æ³¨ï¼Œæä¾›ground truthã€‚4) è‡ªåŠ¨åŒ–è¯„ä¼°æµç¨‹ï¼šè‡ªåŠ¨æ‰§è¡ŒLLMç”Ÿæˆçš„æ¸—é€æµ‹è¯•æ­¥éª¤ï¼Œå¹¶ä¸ground truthè¿›è¡Œæ¯”è¾ƒï¼Œè®¡ç®—æ€§èƒ½æŒ‡æ ‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šPentestEvalçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶æ¨¡å—åŒ–å’Œåˆ†é˜¶æ®µçš„è®¾è®¡ã€‚é€šè¿‡å°†æ¸—é€æµ‹è¯•åˆ†è§£ä¸ºå…­ä¸ªé˜¶æ®µï¼Œå¯ä»¥æ›´ç»†ç²’åº¦åœ°è¯„ä¼°LLMåœ¨æ¯ä¸ªé˜¶æ®µçš„è¡¨ç°ï¼Œä»è€Œå‘ç°å…¶ä¼˜åŠ¿å’Œä¸è¶³ã€‚æ­¤å¤–ï¼ŒPentestEvalè¿˜æä¾›äº†ä¸€ä¸ªåŒ…å«ä¸“å®¶æ ‡æ³¨çš„ç»¼åˆåŸºå‡†ï¼Œä¸ºLLMåœ¨æ¸—é€æµ‹è¯•é¢†åŸŸçš„åº”ç”¨ç ”ç©¶æä¾›äº†å¯é çš„è¯„ä¼°å¹³å°ã€‚

**å…³é”®è®¾è®¡**ï¼šPentestEvalçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) é˜¶æ®µåˆ’åˆ†ï¼šæ ¹æ®æ¸—é€æµ‹è¯•çš„å…¸å‹æµç¨‹ï¼Œå°†ä»»åŠ¡åˆ†è§£ä¸ºå…­ä¸ªé˜¶æ®µã€‚2) æµ‹è¯•ç”¨ä¾‹è®¾è®¡ï¼šé’ˆå¯¹æ¯ä¸ªé˜¶æ®µï¼Œè®¾è®¡å…·æœ‰ä»£è¡¨æ€§çš„æµ‹è¯•ç”¨ä¾‹ï¼Œè¦†ç›–ä¸åŒçš„æ¼æ´ç±»å‹å’Œæ”»å‡»åœºæ™¯ã€‚3) è¯„ä¼°æŒ‡æ ‡ï¼šé’ˆå¯¹æ¯ä¸ªé˜¶æ®µï¼Œè®¾è®¡åˆé€‚çš„è¯„ä¼°æŒ‡æ ‡ï¼Œä¾‹å¦‚å‡†ç¡®ç‡ã€å¬å›ç‡ã€F1å€¼ç­‰ã€‚4) è‡ªåŠ¨åŒ–æµç¨‹ï¼šè®¾è®¡è‡ªåŠ¨åŒ–çš„è¯„ä¼°æµç¨‹ï¼Œå‡å°‘äººå·¥å¹²é¢„ï¼Œæé«˜è¯„ä¼°æ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

PentestEvalå¯¹9ä¸ªå¹¿æ³›ä½¿ç”¨çš„LLMè¿›è¡Œäº†é˜¶æ®µæ€§è¯„ä¼°ï¼Œç»“æœè¡¨æ˜ï¼Œæ€»ä½“æ€§èƒ½è¾ƒå¼±ï¼Œç«¯åˆ°ç«¯ç®¡é“çš„æˆåŠŸç‡ä»…ä¸º31%ã€‚ç°æœ‰çš„LLMé©±åŠ¨ç³»ç»Ÿï¼ˆå¦‚PentestGPTã€PentestAgentå’ŒVulnBotï¼‰ä¹Ÿè¡¨ç°å‡ºç±»ä¼¼çš„å±€é™æ€§ï¼Œè‡ªä¸»ä»£ç†å‡ ä¹å®Œå…¨å¤±è´¥ã€‚è¿™äº›ç»“æœçªå‡ºäº†å½“å‰LLMåœ¨è‡ªä¸»æ¸—é€æµ‹è¯•æ–¹é¢çš„ä¸è¶³ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æ–¹å‘æä¾›äº†æŒ‡å¯¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

PentestEvalå¯ç”¨äºè¯„ä¼°å’Œæ”¹è¿›åŸºäºLLMçš„è‡ªåŠ¨åŒ–æ¸—é€æµ‹è¯•å·¥å…·ï¼Œå¸®åŠ©å®‰å…¨ç ”ç©¶äººå‘˜æ›´å¥½åœ°ç†è§£LLMåœ¨æ¸—é€æµ‹è¯•é¢†åŸŸçš„ä¼˜åŠ¿å’Œå±€é™æ€§ã€‚æ­¤å¤–ï¼Œè¯¥åŸºå‡†è¿˜å¯ä»¥ä¿ƒè¿›LLMåœ¨å®‰å…¨é¢†åŸŸçš„åº”ç”¨ï¼Œä¾‹å¦‚æ¼æ´æŒ–æ˜ã€å®‰å…¨å®¡è®¡å’Œå¨èƒæƒ…æŠ¥ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Penetration testing is essential for assessing and strengthening system security against real-world threats, yet traditional workflows remain highly manual, expertise-intensive, and difficult to scale. Although recent advances in Large Language Models (LLMs) offer promising opportunities for automation, existing applications rely on simplistic prompting without task decomposition or domain adaptation, resulting in unreliable black-box behavior and limited insight into model capabilities across penetration testing stages. To address this gap, we introduce PentestEval, the first comprehensive benchmark for evaluating LLMs across six decomposed penetration testing stages: Information Collection, Weakness Gathering and Filtering, Attack Decision-Making, Exploit Generation and Revision. PentestEval integrates expert-annotated ground truth with a fully automated evaluation pipeline across 346 tasks covering all stages in 12 realistic vulnerable scenarios. Our stage-level evaluation of 9 widely used LLMs reveals generally weak performance and distinct limitations across the stages of penetration-testing workflow. End-to-end pipelines reach only 31% success rate, and existing LLM-powered systems such as PentestGPT, PentestAgent, and VulnBot exhibit similar limitations, with autonomous agents failing almost entirely. These findings highlight that autonomous penetration testing demands stronger structured reasoning, where modularization enhances each individual stage and improves overall performance. PentestEval provides the foundational benchmark needed for future research on fine-grained, stage-level evaluation, paving the way toward more reliable LLM-based automation.

