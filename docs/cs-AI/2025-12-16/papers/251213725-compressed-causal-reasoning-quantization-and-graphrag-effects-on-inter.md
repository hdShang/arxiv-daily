---
layout: default
title: Compressed Causal Reasoning: Quantization and GraphRAG Effects on Interventional and Counterfactual Accuracy
---

# Compressed Causal Reasoning: Quantization and GraphRAG Effects on Interventional and Counterfactual Accuracy

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.13725" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.13725</a>
  <a href="https://arxiv.org/pdf/2512.13725.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.13725" onclick="toggleFavorite(this, '2512.13725', 'Compressed Causal Reasoning: Quantization and GraphRAG Effects on Interventional and Counterfactual Accuracy')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Steve Nwaiwu, Nipat Jongsawat, Anucha Tungkasthan

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-18

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç ”ç©¶é‡åŒ–å’Œå›¾æ£€ç´¢å¢å¼ºç”Ÿæˆå¯¹å¤§è¯­è¨€æ¨¡å‹å› æœæ¨ç†èƒ½åŠ›çš„å½±å“**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å› æœæ¨ç†` `é‡åŒ–` `å¤§è¯­è¨€æ¨¡å‹` `å›¾æ£€ç´¢å¢å¼ºç”Ÿæˆ` `è¾¹ç¼˜è®¡ç®—`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§è¯­è¨€æ¨¡å‹åœ¨èµ„æºå—é™ç¯å¢ƒä¸‹è¿›è¡Œå› æœæ¨ç†æ—¶ï¼Œé‡åŒ–å¸¦æ¥çš„ç²¾åº¦æŸå¤±å½±å“å°šä¸æ˜ç¡®ã€‚
2. è¯¥ç ”ç©¶ç³»ç»Ÿè¯„ä¼°äº†é‡åŒ–ï¼ˆINT8, NF4ï¼‰å¯¹Llama 3 8Båœ¨Pearlå› æœé˜¶æ¢¯ä¸‰ä¸ªå±‚æ¬¡æ¨ç†èƒ½åŠ›çš„å½±å“ã€‚
3. å®éªŒè¡¨æ˜ï¼Œå› æœæ¨ç†å¯¹å››ä½é‡åŒ–å…·æœ‰é²æ£’æ€§ï¼Œå›¾æ£€ç´¢å¢å¼ºç”Ÿæˆå¯æå‡å¹²é¢„æ¨ç†ç²¾åº¦ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­ï¼Œæ¶µç›–å…³è”ã€å¹²é¢„å’Œåäº‹å®æ¨ç†çš„å› æœæ¨ç†å¯¹äºé«˜é£é™©ç¯å¢ƒä¸‹çš„å¯é å†³ç­–è‡³å…³é‡è¦ã€‚éšç€éƒ¨ç½²è½¬å‘è¾¹ç¼˜å’Œèµ„æºå—é™ç¯å¢ƒï¼ŒINT8å’ŒNF4ç­‰é‡åŒ–æ¨¡å‹æ­£æˆä¸ºæ ‡å‡†ã€‚ç„¶è€Œï¼Œç²¾åº¦é™ä½å¯¹å½¢å¼åŒ–å› æœæ¨ç†çš„å½±å“çŸ¥ä¹‹ç”šå°‘ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªç³»ç»Ÿåœ°è¯„ä¼°é‡åŒ–æ•ˆåº”å¯¹Pearlå› æœé˜¶æ¢¯æ‰€æœ‰ä¸‰ä¸ªå±‚æ¬¡å½±å“çš„ç ”ç©¶ã€‚ä½¿ç”¨3000ä¸ªæ ·æœ¬çš„åˆ†å±‚CLadderåŸºå‡†æµ‹è¯•ï¼Œæˆ‘ä»¬å‘ç°Llama 3 8Bä¸­çš„rungçº§åˆ«ç²¾åº¦åœ¨é‡åŒ–ä¸‹ä¿æŒå¤§è‡´ç¨³å®šï¼ŒNF4çš„æ€»ä½“é™çº§å°äº1%ã€‚ç¬¬äºŒå±‚çº§çš„å¹²é¢„æŸ¥è¯¢å¯¹ç²¾åº¦æŸå¤±æœ€æ•æ„Ÿï¼Œè€Œç¬¬ä¸‰å±‚çº§çš„åäº‹å®æ¨ç†ç›¸å¯¹ç¨³å®šï¼Œä½†åœ¨è¯¸å¦‚ç¢°æ’åå·®å’Œåé—¨è°ƒæ•´ç­‰æŸ¥è¯¢ç±»å‹ä¸­è¡¨ç°å‡ºå¼‚æ„å¼±ç‚¹ã€‚åœ¨CRASSåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œä¸åŒç²¾åº¦ä¹‹é—´çš„æ€§èƒ½å‡ ä¹ç›¸åŒï¼Œè¡¨æ˜ç°æœ‰çš„å¸¸è¯†æ€§åäº‹å®æ•°æ®é›†ç¼ºä¹æ­ç¤ºé‡åŒ–å¼•èµ·çš„æ¨ç†æ¼‚ç§»æ‰€éœ€çš„ç»“æ„æ•æ„Ÿæ€§ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥è¯„ä¼°äº†ä½¿ç”¨ground truthå› æœå›¾çš„å›¾æ£€ç´¢å¢å¼ºç”Ÿæˆï¼Œå¹¶è§‚å¯Ÿåˆ°NF4å¹²é¢„ç²¾åº¦çš„æŒç»­æé«˜ï¼Œè¾¾åˆ°1.7%ï¼Œéƒ¨åˆ†æŠµæ¶ˆäº†å‹ç¼©ç›¸å…³çš„é™çº§ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œå› æœæ¨ç†å¯¹å››ä½é‡åŒ–å…·æœ‰å‡ºä¹æ„æ–™çš„é²æ£’æ€§ï¼Œå›¾ç»“æ„å¢å¼ºå¯ä»¥é€‰æ‹©æ€§åœ°åŠ å¼ºå¹²é¢„æ¨ç†ï¼Œå¹¶ä¸”å½“å‰çš„åäº‹å®åŸºå‡†æµ‹è¯•æœªèƒ½æ•æ‰åˆ°æ›´æ·±å±‚æ¬¡çš„å› æœè„†å¼±æ€§ã€‚è¿™é¡¹å·¥ä½œæä¾›äº†å‹ç¼©å› æœæ¨ç†çš„åˆæ­¥ç»éªŒå›¾ï¼Œå¹¶ä¸ºéƒ¨ç½²é«˜æ•ˆä¸”ç»“æ„æ”¯æŒçš„å› æœAIç³»ç»Ÿæä¾›äº†å®ç”¨æŒ‡å¯¼ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨ç ”ç©¶åœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¡ç®—ç¯å¢ƒä¸­ï¼Œå¯¹å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œé‡åŒ–ï¼ˆå¦‚INT8å’ŒNF4ï¼‰åï¼Œå…¶å› æœæ¨ç†èƒ½åŠ›ï¼ˆåŒ…æ‹¬å…³è”ã€å¹²é¢„å’Œåäº‹å®æ¨ç†ï¼‰ä¼šå—åˆ°æ€æ ·çš„å½±å“ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹å¯¹é‡åŒ–æ•ˆåº”åœ¨ä¸åŒå› æœæ¨ç†å±‚æ¬¡ä¸Šçš„ç³»ç»Ÿæ€§è¯„ä¼°ï¼Œå¹¶ä¸”ç°æœ‰çš„åäº‹å®æ¨ç†æ•°æ®é›†å¯èƒ½æ— æ³•å……åˆ†æ­ç¤ºé‡åŒ–å¼•èµ·çš„æ¨ç†æ¼‚ç§»ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ„å»ºä¸€ä¸ªåˆ†å±‚çš„å› æœæ¨ç†åŸºå‡†æµ‹è¯•ï¼ˆCLadderï¼‰ï¼Œå¹¶ç»“åˆç°æœ‰çš„å¸¸è¯†æ€§åäº‹å®æ•°æ®é›†ï¼ˆCRASSï¼‰ï¼Œç³»ç»Ÿåœ°è¯„ä¼°ä¸åŒé‡åŒ–çº§åˆ«ï¼ˆåŒ…æ‹¬æœªé‡åŒ–ã€INT8å’ŒNF4ï¼‰å¯¹å¤§è¯­è¨€æ¨¡å‹åœ¨ä¸åŒå› æœæ¨ç†ä»»åŠ¡ä¸Šçš„æ€§èƒ½å½±å“ã€‚åŒæ—¶ï¼Œæ¢ç´¢å›¾æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆGraph RAGï¼‰æ–¹æ³•ï¼Œåˆ©ç”¨ground truthå› æœå›¾æ¥å¢å¼ºæ¨¡å‹çš„å¹²é¢„æ¨ç†èƒ½åŠ›ï¼Œä»¥æŠµæ¶ˆé‡åŒ–å¸¦æ¥çš„æ€§èƒ½ä¸‹é™ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦é˜¶æ®µï¼š
1. **åŸºå‡†æµ‹è¯•æ„å»º**ï¼šæ„å»ºä¸€ä¸ªåŒ…å«3000ä¸ªæ ·æœ¬çš„åˆ†å±‚CLadderåŸºå‡†æµ‹è¯•ï¼Œè¦†ç›–Pearlå› æœé˜¶æ¢¯çš„ä¸‰ä¸ªå±‚æ¬¡ï¼ˆå…³è”ã€å¹²é¢„å’Œåäº‹å®æ¨ç†ï¼‰ã€‚
2. **æ¨¡å‹é‡åŒ–**ï¼šå¯¹Llama 3 8Bæ¨¡å‹è¿›è¡Œä¸åŒçº§åˆ«çš„é‡åŒ–ï¼ˆINT8å’ŒNF4ï¼‰ã€‚
3. **æ€§èƒ½è¯„ä¼°**ï¼šåœ¨CLadderå’ŒCRASSåŸºå‡†æµ‹è¯•ä¸Šè¯„ä¼°ä¸åŒé‡åŒ–çº§åˆ«ä¸‹æ¨¡å‹çš„å› æœæ¨ç†æ€§èƒ½ã€‚
4. **å›¾æ£€ç´¢å¢å¼ºç”Ÿæˆ**ï¼šåˆ©ç”¨ground truthå› æœå›¾ï¼Œé€šè¿‡Graph RAGæ–¹æ³•å¢å¼ºæ¨¡å‹çš„å¹²é¢„æ¨ç†èƒ½åŠ›ã€‚
5. **ç»“æœåˆ†æ**ï¼šåˆ†æé‡åŒ–æ•ˆåº”å¯¹ä¸åŒå› æœæ¨ç†ä»»åŠ¡çš„å½±å“ï¼Œä»¥åŠGraph RAGæ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶çš„ä¸»è¦åˆ›æ–°ç‚¹åœ¨äºï¼š
1. **ç³»ç»Ÿæ€§è¯„ä¼°**ï¼šé¦–æ¬¡ç³»ç»Ÿåœ°è¯„ä¼°äº†é‡åŒ–æ•ˆåº”å¯¹Pearlå› æœé˜¶æ¢¯æ‰€æœ‰ä¸‰ä¸ªå±‚æ¬¡çš„å› æœæ¨ç†èƒ½åŠ›çš„å½±å“ã€‚
2. **Graph RAGå¢å¼º**ï¼šæ¢ç´¢äº†åˆ©ç”¨ground truthå› æœå›¾çš„Graph RAGæ–¹æ³•æ¥å¢å¼ºæ¨¡å‹çš„å¹²é¢„æ¨ç†èƒ½åŠ›ï¼Œå¹¶éƒ¨åˆ†æŠµæ¶ˆäº†é‡åŒ–å¸¦æ¥çš„æ€§èƒ½ä¸‹é™ã€‚
3. **åŸºå‡†æµ‹è¯•åˆ†æ**ï¼šæŒ‡å‡ºå½“å‰çš„åäº‹å®æ¨ç†æ•°æ®é›†å¯èƒ½æ— æ³•å……åˆ†æ­ç¤ºé‡åŒ–å¼•èµ·çš„æ¨ç†æ¼‚ç§»ã€‚

**å…³é”®è®¾è®¡**ï¼š
1. **CLadderåŸºå‡†æµ‹è¯•**ï¼šé‡‡ç”¨åˆ†å±‚ç»“æ„ï¼Œè¦†ç›–Pearlå› æœé˜¶æ¢¯çš„ä¸‰ä¸ªå±‚æ¬¡ï¼Œå¹¶åŒ…å«3000ä¸ªæ ·æœ¬ã€‚
2. **Graph RAG**ï¼šä½¿ç”¨ground truthå› æœå›¾ä½œä¸ºçŸ¥è¯†æºï¼Œé€šè¿‡æ£€ç´¢ç›¸å…³å­å›¾æ¥å¢å¼ºæ¨¡å‹çš„å¹²é¢„æ¨ç†èƒ½åŠ›ã€‚
3. **é‡åŒ–æ–¹æ³•**ï¼šé‡‡ç”¨INT8å’ŒNF4ä¸¤ç§é‡åŒ–æ–¹æ³•ï¼Œä»¥è¯„ä¼°ä¸åŒé‡åŒ–çº§åˆ«çš„å½±å“ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.13725/figure_1.png" alt="fig_0" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLlama 3 8Båœ¨é‡åŒ–åï¼Œå› æœæ¨ç†èƒ½åŠ›æ€»ä½“ä¿æŒç¨³å®šï¼ŒNF4çš„æ€»ä½“é™çº§å°äº1%ã€‚å¹²é¢„æŸ¥è¯¢å¯¹ç²¾åº¦æŸå¤±æœ€æ•æ„Ÿï¼Œè€Œåäº‹å®æ¨ç†ç›¸å¯¹ç¨³å®šã€‚Graph RAGæ–¹æ³•èƒ½å¤Ÿæé«˜NF4å¹²é¢„ç²¾åº¦1.7%ï¼Œéƒ¨åˆ†æŠµæ¶ˆå‹ç¼©å¸¦æ¥çš„æ€§èƒ½ä¸‹é™ã€‚CRASSåŸºå‡†æµ‹è¯•è¡¨æ˜ï¼Œç°æœ‰åäº‹å®æ•°æ®é›†å¯èƒ½æ— æ³•å……åˆ†æ­ç¤ºé‡åŒ–å¼•èµ·çš„æ¨ç†æ¼‚ç§»ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¯¹èµ„æºæ•æ„Ÿçš„è¾¹ç¼˜è®¡ç®—è®¾å¤‡ï¼Œä¾‹å¦‚ç§»åŠ¨æœºå™¨äººã€è‡ªåŠ¨é©¾é©¶æ±½è½¦ç­‰ï¼Œåœ¨è¿™äº›åœºæ™¯ä¸‹ï¼Œéœ€è¦åœ¨è®¡ç®—èµ„æºæœ‰é™çš„æƒ…å†µä¸‹è¿›è¡Œå¯é çš„å› æœæ¨ç†å’Œå†³ç­–ã€‚é€šè¿‡é‡åŒ–æ¨¡å‹å’Œå›¾æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯ï¼Œå¯ä»¥åœ¨ä¿è¯æ¨ç†ç²¾åº¦çš„å‰æä¸‹ï¼Œé™ä½æ¨¡å‹çš„è®¡ç®—å¤æ‚åº¦å’Œå­˜å‚¨ç©ºé—´ï¼Œä»è€Œå®ç°é«˜æ•ˆçš„å› æœAIç³»ç»Ÿéƒ¨ç½²ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Causal reasoning in Large Language Models spanning association, intervention, and counterfactual inference is essential for reliable decision making in high stakes settings. As deployment shifts toward edge and resource constrained environments, quantized models such as INT8 and NF4 are becoming standard. Yet the impact of precision reduction on formal causal reasoning is poorly understood. To our knowledge, this is the first study to systematically evaluate quantization effects across all three levels of Pearls Causal Ladder. Using a 3000 sample stratified CLadder benchmark, we find that rung level accuracy in Llama 3 8B remains broadly stable under quantization, with NF4 showing less than one percent overall degradation. Interventional queries at rung 2 are the most sensitive to precision loss, whereas counterfactual reasoning at rung 3 is comparatively stable but exhibits heterogeneous weaknesses across query types such as collider bias and backdoor adjustment. Experiments on the CRASS benchmark show near identical performance across precisions, indicating that existing commonsense counterfactual datasets lack the structural sensitivity needed to reveal quantization induced reasoning drift. We further evaluate Graph Retrieval Augmented Generation using ground truth causal graphs and observe a consistent improvement in NF4 interventional accuracy of plus 1.7 percent, partially offsetting compression related degradation. These results suggest that causal reasoning is unexpectedly robust to four bit quantization, graph structured augmentation can selectively reinforce interventional reasoning, and current counterfactual benchmarks fail to capture deeper causal brittleness. This work provides an initial empirical map of compressed causal reasoning and practical guidance for deploying efficient and structurally supported causal AI systems.

