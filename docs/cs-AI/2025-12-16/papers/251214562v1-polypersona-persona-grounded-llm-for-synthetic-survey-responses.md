---
layout: default
title: Polypersona: Persona-Grounded LLM for Synthetic Survey Responses
---

# Polypersona: Persona-Grounded LLM for Synthetic Survey Responses

**arXiv**: [2512.14562v1](https://arxiv.org/abs/2512.14562) | [PDF](https://arxiv.org/pdf/2512.14562.pdf)

**ä½œè€…**: Tejaswani Dash, Dinesh Karri, Anudeep Vurity, Gautam Datla, Tazeem Ahmad, Saima Rafi, Rohith Tangudu

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: Accepted in IEEE Bigdata 2025- LLMs4ALL

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPolyPersonaæ¡†æž¶ï¼Œé€šè¿‡è§’è‰²æ¡ä»¶åŒ–å¾®è°ƒå°åž‹è¯­è¨€æ¨¡åž‹ï¼Œå®žçŽ°å¤šé¢†åŸŸåˆæˆè°ƒæŸ¥æ•°æ®çš„é«˜æ•ˆç”Ÿæˆã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **è§†è§‰é‡Œç¨‹è®¡** **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `åˆæˆè°ƒæŸ¥æ•°æ®ç”Ÿæˆ` `è§’è‰²æ¡ä»¶åŒ–è¯­è¨€æ¨¡åž‹` `LoRAé€‚é…å™¨å¾®è°ƒ` `å¤šé¢†åŸŸè¯„ä¼°` `å‚æ•°é«˜æ•ˆè®­ç»ƒ` `æ–‡æœ¬ç”ŸæˆæŒ‡æ ‡` `åè§åˆ†æžåè®®` `ç´§å‡‘æ¨¡åž‹ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•åœ¨ç”Ÿæˆåˆæˆè°ƒæŸ¥æ•°æ®æ—¶ï¼Œéš¾ä»¥ç¡®ä¿è§’è‰²ä¸€è‡´æ€§å’Œè·¨é¢†åŸŸé€‚åº”æ€§ï¼Œå¯¼è‡´æ•°æ®è´¨é‡å—é™ã€‚
2. PolyPersonaé‡‡ç”¨åŸºäºŽå¯¹è¯çš„æ•°æ®ç®¡é“å’ŒLoRAé€‚é…å™¨ï¼Œå¯¹ç´§å‡‘æ¨¡åž‹è¿›è¡Œè§’è‰²æ¡ä»¶åŒ–å¾®è°ƒï¼Œä»¥é«˜æ•ˆç”Ÿæˆå¤šé¢†åŸŸå“åº”ã€‚
3. å®žéªŒæ˜¾ç¤ºï¼Œå°åž‹æ¨¡åž‹å¦‚TinyLlama 1.1Båœ¨BLEUå’ŒROUGEæŒ‡æ ‡ä¸ŠæŽ¥è¿‘å¤§åž‹åŸºçº¿ï¼ŒéªŒè¯äº†æ¡†æž¶çš„æœ‰æ•ˆæ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ä»‹ç»äº†PolyPersonaï¼Œä¸€ä¸ªç”¨äºŽç”Ÿæˆè·¨å¤šä¸ªé¢†åŸŸçš„è§’è‰²æ¡ä»¶åŒ–è°ƒæŸ¥å“åº”çš„ç”Ÿæˆæ¡†æž¶ã€‚è¯¥æ¡†æž¶åœ¨èµ„æºè‡ªé€‚åº”è®­ç»ƒè®¾ç½®ä¸‹ï¼Œä½¿ç”¨å‚æ•°é«˜æ•ˆçš„LoRAé€‚é…å™¨å’Œ4ä½é‡åŒ–æŠ€æœ¯ï¼Œå¯¹ç´§å‡‘çš„èŠå¤©æ¨¡åž‹è¿›è¡ŒæŒ‡ä»¤å¾®è°ƒã€‚åŸºäºŽå¯¹è¯çš„æ•°æ®ç®¡é“æ˜Žç¡®ä¿ç•™äº†è§’è‰²çº¿ç´¢ï¼Œç¡®ä¿ç”Ÿæˆå“åº”åœ¨è¡Œä¸ºä¸Šçš„ä¸€è‡´æ€§ã€‚åˆ©ç”¨è¯¥ç®¡é“ï¼Œæˆ‘ä»¬æž„å»ºäº†ä¸€ä¸ªåŒ…å«3,568ä¸ªåˆæˆè°ƒæŸ¥å“åº”çš„æ•°æ®é›†ï¼Œæ¶µç›–åä¸ªé¢†åŸŸå’Œ433ä¸ªä¸åŒè§’è‰²ï¼Œæ”¯æŒå¯æŽ§çš„æŒ‡ä»¤å¾®è°ƒå’Œç³»ç»Ÿçš„å¤šé¢†åŸŸè¯„ä¼°ã€‚æˆ‘ä»¬ä½¿ç”¨å¤šæŒ‡æ ‡è¯„ä¼°å¥—ä»¶è¯„ä¼°ç”Ÿæˆå“åº”ï¼Œè¯¥å¥—ä»¶ç»“åˆäº†æ ‡å‡†æ–‡æœ¬ç”ŸæˆæŒ‡æ ‡ï¼ˆåŒ…æ‹¬BLEUã€ROUGEå’ŒBERTScoreï¼‰å’Œä¸“é—¨è®¾è®¡çš„è°ƒæŸ¥ç‰¹å®šæŒ‡æ ‡ï¼Œç”¨äºŽè¯„ä¼°ç»“æž„è¿žè´¯æ€§ã€é£Žæ ¼ä¸€è‡´æ€§å’Œæƒ…æ„Ÿå¯¹é½ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒTinyLlama 1.1Bå’ŒPhi-2ç­‰ç´§å‡‘æ¨¡åž‹å®žçŽ°äº†ä¸Žè¾ƒå¤§7Bè‡³8BåŸºçº¿ç›¸å½“çš„æ€§èƒ½ï¼Œæœ€é«˜BLEUå¾—åˆ†ä¸º0.090ï¼ŒROUGE-1ä¸º0.429ã€‚è¿™äº›å‘çŽ°è¡¨æ˜Žï¼Œè§’è‰²æ¡ä»¶åŒ–å¾®è°ƒä½¿å°åž‹è¯­è¨€æ¨¡åž‹èƒ½å¤Ÿç”Ÿæˆå¯é ä¸”è¿žè´¯çš„åˆæˆè°ƒæŸ¥æ•°æ®ã€‚æ‰€æå‡ºçš„æ¡†æž¶ä¸ºè°ƒæŸ¥æ•°æ®ç”Ÿæˆæä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å¯å¤çŽ°çš„æ–¹æ³•ï¼Œæ”¯æŒå¯æ‰©å±•çš„è¯„ä¼°ï¼ŒåŒæ—¶é€šè¿‡é€æ˜Žå’Œå¼€æ”¾çš„åè®®ä¿ƒè¿›åè§åˆ†æžã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

PolyPersonaæ˜¯ä¸€ä¸ªç”Ÿæˆæ¡†æž¶ï¼Œæ•´ä½“åŸºäºŽæŒ‡ä»¤å¾®è°ƒçš„ç´§å‡‘èŠå¤©æ¨¡åž‹ï¼Œç»“åˆå‚æ•°é«˜æ•ˆçš„LoRAé€‚é…å™¨å’Œ4ä½é‡åŒ–æŠ€æœ¯ï¼Œåœ¨èµ„æºè‡ªé€‚åº”è®­ç»ƒè®¾ç½®ä¸‹å®žçŽ°é«˜æ•ˆè®­ç»ƒã€‚å…³é”®æŠ€æœ¯åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼šåŸºäºŽå¯¹è¯çš„æ•°æ®ç®¡é“ï¼Œæ˜Žç¡®ä¿ç•™è§’è‰²çº¿ç´¢ä»¥ç¡®ä¿è¡Œä¸ºä¸€è‡´æ€§ï¼›æž„å»ºå¤šé¢†åŸŸåˆæˆæ•°æ®é›†ï¼Œæ”¯æŒå¯æŽ§å¾®è°ƒå’Œç³»ç»Ÿè¯„ä¼°ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºŽï¼Œå®ƒä¸“æ³¨äºŽè§’è‰²æ¡ä»¶åŒ–ç”Ÿæˆï¼Œé€šè¿‡é€æ˜Žåè®®ä¿ƒè¿›åè§åˆ†æžï¼Œå¹¶åˆ©ç”¨å°åž‹æ¨¡åž‹å®žçŽ°ä¸Žå¤§åž‹æ¨¡åž‹ç›¸å½“çš„æ€§èƒ½ï¼Œæé«˜äº†ç”Ÿæˆæ•ˆçŽ‡å’Œå¯æ‰©å±•æ€§ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

ç´§å‡‘æ¨¡åž‹TinyLlama 1.1Bå’ŒPhi-2åœ¨BLEUå’ŒROUGEæŒ‡æ ‡ä¸Šè¾¾åˆ°ä¸Ž7B-8BåŸºçº¿ç›¸å½“æ°´å¹³ï¼Œæœ€é«˜BLEUä¸º0.090ï¼ŒROUGE-1ä¸º0.429ï¼Œè¯æ˜Žäº†è§’è‰²æ¡ä»¶åŒ–å¾®è°ƒèƒ½æœ‰æ•ˆæå‡å°åž‹æ¨¡åž‹ç”Ÿæˆè´¨é‡ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å¯åº”ç”¨äºŽå¸‚åœºè°ƒç ”ã€ç¤¾ä¼šç§‘å­¦å®žéªŒå’Œç”¨æˆ·è¡Œä¸ºåˆ†æžç­‰é¢†åŸŸï¼Œé€šè¿‡ç”Ÿæˆé«˜è´¨é‡çš„åˆæˆè°ƒæŸ¥æ•°æ®ï¼Œæ”¯æŒæ•°æ®å¢žå¼ºã€æ¨¡åž‹è¯„ä¼°å’Œåè§ç ”ç©¶ï¼Œé™ä½ŽçœŸå®žæ•°æ®æ”¶é›†æˆæœ¬ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> This paper introduces PolyPersona, a generative framework for synthesizing persona-conditioned survey responses across multiple domains. The framework instruction-tunes compact chat models using parameter-efficient LoRA adapters with 4-bit quantization under a resource-adaptive training setup. A dialogue-based data pipeline explicitly preserves persona cues, ensuring consistent behavioral alignment across generated responses. Using this pipeline, we construct a dataset of 3,568 synthetic survey responses spanning ten domains and 433 distinct personas, enabling controlled instruction tuning and systematic multi-domain evaluation. We evaluate the generated responses using a multi-metric evaluation suite that combines standard text generation metrics, including BLEU, ROUGE, and BERTScore, with survey-specific metrics designed to assess structural coherence, stylistic consistency, and sentiment alignment.Experimental results show that compact models such as TinyLlama 1.1B and Phi-2 achieve performance comparable to larger 7B to 8B baselines, with a highest BLEU score of 0.090 and ROUGE-1 of 0.429. These findings demonstrate that persona-conditioned fine-tuning enables small language models to generate reliable and coherent synthetic survey data. The proposed framework provides an efficient and reproducible approach for survey data generation, supporting scalable evaluation while facilitating bias analysis through transparent and open protocols.

