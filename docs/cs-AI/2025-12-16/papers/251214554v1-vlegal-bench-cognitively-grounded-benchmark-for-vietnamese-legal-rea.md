---
layout: default
title: VLegal-Bench: Cognitively Grounded Benchmark for Vietnamese Legal Reasoning of Large Language Models
---

# VLegal-Bench: Cognitively Grounded Benchmark for Vietnamese Legal Reasoning of Large Language Models

**arXiv**: [2512.14554v1](https://arxiv.org/abs/2512.14554) | [PDF](https://arxiv.org/pdf/2512.14554.pdf)

**ä½œè€…**: Nguyen Tien Dong, Minh-Anh Nguyen, Thanh Dat Hoang, Nguyen Tuan Ngoc, Dao Xuan Quang Minh, Phan Phi Hai, Nguyen Thi Ngoc Anh, Dang Van Tu, Binh Vu

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVLegal-BenchåŸºå‡†ä»¥è§£å†³è¶Šå—æ³•å¾‹é¢†åŸŸå¤§è¯­è¨€æ¨¡åž‹è¯„ä¼°çš„æ ‡å‡†åŒ–ä¸Žè®¤çŸ¥æ·±åº¦é—®é¢˜**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `æ³•å¾‹åŸºå‡†` `è¶Šå—æ³•å¾‹` `å¤§è¯­è¨€æ¨¡åž‹è¯„ä¼°` `è®¤çŸ¥åˆ†ç±»æ³•` `æ³•å¾‹æŽ¨ç†` `ä¸“å®¶æ ‡æ³¨` `æ£€ç´¢å¢žå¼ºç”Ÿæˆ` `åœºæ™¯åŒ–é—®é¢˜è§£å†³`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè¶Šå—æ³•å¾‹å¤æ‚å¤šå˜ï¼ŒçŽ°æœ‰è¯„ä¼°æ–¹æ³•ç¼ºä¹æ ‡å‡†åŒ–åŸºå‡†ï¼Œéš¾ä»¥ç³»ç»Ÿè¡¡é‡å¤§è¯­è¨€æ¨¡åž‹çš„æ³•å¾‹æŽ¨ç†èƒ½åŠ›ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽå¸ƒé²å§†è®¤çŸ¥åˆ†ç±»æ³•è®¾è®¡å¤šå±‚æ¬¡ä»»åŠ¡ï¼Œé€šè¿‡ä¸“å®¶æ ‡æ³¨æž„å»ºæƒå¨æ•°æ®é›†ï¼Œæ¨¡æ‹ŸçœŸå®žæ³•å¾‹å·¥ä½œæµç¨‹ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæž„å»ºåŒ…å«10,450ä¸ªæ ·æœ¬çš„åŸºå‡†ï¼Œæä¾›é€æ˜Žè¯„ä¼°æ¡†æž¶ï¼Œæ”¯æŒAIæ³•å¾‹ç³»ç»Ÿå¼€å‘ï¼Œæå‡æ¨¡åž‹å¯é æ€§å’Œå¯è§£é‡Šæ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§è¯­è¨€æ¨¡åž‹çš„å¿«é€Ÿå‘å±•ä¸ºäººå·¥æ™ºèƒ½åœ¨æ³•å¾‹é¢†åŸŸçš„åº”ç”¨å¼€è¾Ÿäº†æ–°å¯èƒ½ã€‚ç„¶è€Œï¼Œè¶Šå—æ³•å¾‹çš„å¤æ‚æ€§ã€å±‚çº§ç»“æž„å’Œé¢‘ç¹ä¿®è®¢ç»™è¯„ä¼°è¿™äº›æ¨¡åž‹å¦‚ä½•è§£é‡Šå’Œåˆ©ç”¨æ³•å¾‹çŸ¥è¯†å¸¦æ¥äº†å·¨å¤§æŒ‘æˆ˜ã€‚ä¸ºå¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œè¶Šå—æ³•å¾‹åŸºå‡†è¢«å¼•å…¥ï¼Œè¿™æ˜¯é¦–ä¸ªæ—¨åœ¨ç³»ç»Ÿè¯„ä¼°å¤§è¯­è¨€æ¨¡åž‹åœ¨è¶Šå—æ³•å¾‹ä»»åŠ¡ä¸Šè¡¨çŽ°çš„ç»¼åˆæ€§åŸºå‡†ã€‚åŸºäºŽå¸ƒé²å§†è®¤çŸ¥åˆ†ç±»æ³•ï¼ŒVLegal-Benché€šè¿‡è®¾è®¡åæ˜ å®žé™…ä½¿ç”¨åœºæ™¯çš„ä»»åŠ¡ï¼Œæ¶µç›–äº†å¤šä¸ªå±‚æ¬¡çš„æ³•å¾‹ç†è§£ã€‚è¯¥åŸºå‡†åŒ…å«10,450ä¸ªæ ·æœ¬ï¼Œé€šè¿‡ä¸¥æ ¼çš„æ ‡æ³¨æµç¨‹ç”Ÿæˆï¼Œæ³•å¾‹ä¸“å®¶ä½¿ç”¨æˆ‘ä»¬çš„æ ‡æ³¨ç³»ç»Ÿå¯¹æ¯ä¸ªå®žä¾‹è¿›è¡Œæ ‡æ³¨å’Œäº¤å‰éªŒè¯ï¼Œç¡®ä¿æ¯ä¸ªæ ·æœ¬éƒ½åŸºäºŽæƒå¨æ³•å¾‹æ–‡ä»¶ï¼Œå¹¶æ¨¡æ‹ŸçœŸå®žä¸–ç•Œæ³•å¾‹åŠ©æ‰‹çš„å·¥ä½œæµç¨‹ï¼ŒåŒ…æ‹¬ä¸€èˆ¬æ³•å¾‹é—®ç­”ã€æ£€ç´¢å¢žå¼ºç”Ÿæˆã€å¤šæ­¥æŽ¨ç†å’Œé’ˆå¯¹è¶Šå—æ³•å¾‹çš„åœºæ™¯åŒ–é—®é¢˜è§£å†³ã€‚é€šè¿‡æä¾›ä¸€ä¸ªæ ‡å‡†åŒ–ã€é€æ˜Žä¸”åŸºäºŽè®¤çŸ¥ç§‘å­¦çš„è¯„ä¼°æ¡†æž¶ï¼ŒVLegal-Benchä¸ºè¯„ä¼°å¤§è¯­è¨€æ¨¡åž‹åœ¨è¶Šå—æ³•å¾‹çŽ¯å¢ƒä¸­çš„è¡¨çŽ°å¥ å®šäº†åšå®žåŸºç¡€ï¼Œå¹¶æ”¯æŒå¼€å‘æ›´å¯é ã€å¯è§£é‡Šä¸”ç¬¦åˆä¼¦ç†çš„AIè¾…åŠ©æ³•å¾‹ç³»ç»Ÿã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

VLegal-Benchçš„æ•´ä½“æ¡†æž¶æ˜¯ä¸€ä¸ªåŸºäºŽè®¤çŸ¥ç§‘å­¦çš„æ ‡å‡†åŒ–è¯„ä¼°åŸºå‡†ï¼Œæ ¸å¿ƒæ–¹æ³•åŒ…æ‹¬ä»»åŠ¡è®¾è®¡ã€æ•°æ®ç”Ÿæˆå’ŒéªŒè¯æµç¨‹ã€‚å…³é”®æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽç»“åˆå¸ƒé²å§†è®¤çŸ¥åˆ†ç±»æ³•ï¼Œè®¾è®¡å¤šå±‚æ¬¡æ³•å¾‹ç†è§£ä»»åŠ¡ï¼Œå¦‚é—®ç­”ã€æ£€ç´¢å¢žå¼ºç”Ÿæˆã€å¤šæ­¥æŽ¨ç†å’Œåœºæ™¯åŒ–é—®é¢˜è§£å†³ï¼Œä»¥åæ˜ å®žé™…æ³•å¾‹åº”ç”¨åœºæ™¯ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºŽå…¶ä¸“é—¨é’ˆå¯¹è¶Šå—æ³•å¾‹ç‰¹æ€§ï¼Œé€šè¿‡ä¸¥æ ¼ä¸“å®¶æ ‡æ³¨å’Œäº¤å‰éªŒè¯ç¡®ä¿æ•°æ®æƒå¨æ€§ï¼Œå¹¶æ¨¡æ‹ŸçœŸå®žæ³•å¾‹åŠ©æ‰‹å·¥ä½œæµç¨‹ï¼Œæä¾›æ›´å…¨é¢å’Œå®žç”¨çš„è¯„ä¼°æ ‡å‡†ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

æž„å»ºäº†é¦–ä¸ªé’ˆå¯¹è¶Šå—æ³•å¾‹çš„ç»¼åˆæ€§åŸºå‡†ï¼ŒåŒ…å«10,450ä¸ªä¸“å®¶æ ‡æ³¨æ ·æœ¬ï¼ŒåŸºäºŽè®¤çŸ¥åˆ†ç±»æ³•è®¾è®¡å¤šå±‚æ¬¡ä»»åŠ¡ï¼Œä¸ºè¯„ä¼°å¤§è¯­è¨€æ¨¡åž‹æä¾›æ ‡å‡†åŒ–æ¡†æž¶ï¼Œæ”¯æŒå¼€å‘æ›´å¯é çš„AIæ³•å¾‹ç³»ç»Ÿã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å¯åº”ç”¨äºŽè¶Šå—æ³•å¾‹é¢†åŸŸçš„AIè¾…åŠ©ç³»ç»Ÿå¼€å‘ï¼Œå¦‚æ™ºèƒ½æ³•å¾‹å’¨è¯¢ã€æ–‡æ¡£åˆ†æžã€æ¡ˆä¾‹æ£€ç´¢å’Œå†³ç­–æ”¯æŒï¼Œæå‡æ³•å¾‹æœåŠ¡çš„æ•ˆçŽ‡å’Œå‡†ç¡®æ€§ï¼Œä¿ƒè¿›æ³•å¾‹ç§‘æŠ€å‘å±•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The rapid advancement of large language models (LLMs) has enabled new possibilities for applying artificial intelligence within the legal domain. Nonetheless, the complexity, hierarchical organization, and frequent revisions of Vietnamese legislation pose considerable challenges for evaluating how well these models interpret and utilize legal knowledge. To address this gap, Vietnamese Legal Benchmark (VLegal-Bench) is introduced, the first comprehensive benchmark designed to systematically assess LLMs on Vietnamese legal tasks. Informed by Bloom's cognitive taxonomy, VLegal-Bench encompasses multiple levels of legal understanding through tasks designed to reflect practical usage scenarios. The benchmark comprises 10,450 samples generated through a rigorous annotation pipeline, where legal experts label and cross-validate each instance using our annotation system to ensure every sample is grounded in authoritative legal documents and mirrors real-world legal assistant workflows, including general legal questions and answers, retrieval-augmented generation, multi-step reasoning, and scenario-based problem solving tailored to Vietnamese law. By providing a standardized, transparent, and cognitively informed evaluation framework, VLegal-Bench establishes a solid foundation for assessing LLM performance in Vietnamese legal contexts and supports the development of more reliable, interpretable, and ethically aligned AI-assisted legal systems.

