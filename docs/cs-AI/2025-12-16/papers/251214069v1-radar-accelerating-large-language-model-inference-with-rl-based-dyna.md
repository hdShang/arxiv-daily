---
layout: default
title: RADAR: Accelerating Large Language Model Inference With RL-Based Dynamic Draft Trees
---

# RADAR: Accelerating Large Language Model Inference With RL-Based Dynamic Draft Trees

**arXiv**: [2512.14069v1](https://arxiv.org/abs/2512.14069) | [PDF](https://arxiv.org/pdf/2512.14069.pdf)

**ä½œè€…**: Junjie Ma, Jinlong Li

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: 5 pages, 2 figures

**ðŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/minaduki-sora/RADAR)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**RADARï¼šåŸºäºŽå¼ºåŒ–å­¦ä¹ çš„åŠ¨æ€è‰ç¨¿æ ‘åŠ é€Ÿå¤§è¯­è¨€æ¨¡åž‹æŽ¨ç†**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å¼ºåŒ–å­¦ä¹ ä¸Žæ¨¡ä»¿å­¦ä¹  (RL & IL)** **åŠ¨ä½œç”Ÿæˆä¸Žç‰©ç†åŠ¨ç”» (Animation & Physics)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡åž‹` `æŽ¨ç†åŠ é€Ÿ` `æŽ¨æµ‹é‡‡æ ·` `å¼ºåŒ–å­¦ä¹ ` `åŠ¨æ€è‰ç¨¿æ ‘`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æŽ¨æµ‹é‡‡æ ·æ–¹æ³•ä¸­ï¼Œè‰ç¨¿æ¨¡åž‹è°ƒç”¨æ¬¡æ•°ä¸ºé¢„è®¾è¶…å‚æ•°ï¼Œç¼ºä¹çµæ´»æ€§ï¼Œå¯¼è‡´è®¡ç®—å†—ä½™ã€‚
2. RADARå°†è‰ç¨¿æ ‘ç”Ÿæˆå»ºæ¨¡ä¸ºMDPï¼Œåˆ©ç”¨ç¦»çº¿å¼ºåŒ–å­¦ä¹ è®­ç»ƒé¢„æµ‹æ¨¡åž‹ï¼ŒåŠ¨æ€å†³ç­–è‰ç¨¿æ¨¡åž‹è°ƒç”¨æ¬¡æ•°ã€‚
3. å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒRADARåœ¨å¤šä¸ªLLMå’Œä»»åŠ¡ä¸Šå®žçŽ°äº†3.17x-4.82xçš„æŽ¨ç†åŠ é€Ÿï¼Œæ˜¾è‘—ä¼˜äºŽè‡ªå›žå½’è§£ç ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

çŽ°ä»£å¤§åž‹è¯­è¨€æ¨¡åž‹ï¼ˆLLMï¼‰çš„æŽ¨ç†æˆæœ¬é«˜ä¸”é€Ÿåº¦æ…¢ï¼ŒæŽ¨æµ‹é‡‡æ ·å·²æˆä¸ºè§£å†³æ­¤é—®é¢˜çš„æœ‰æ•ˆæ–¹æ³•ã€‚ç„¶è€Œï¼ŒæŽ¨æµ‹é‡‡æ ·ä¸­ç”¨äºŽç”Ÿæˆå€™é€‰tokençš„è‰ç¨¿æ¨¡åž‹è°ƒç”¨æ¬¡æ•°æ˜¯ä¸€ä¸ªé¢„è®¾çš„è¶…å‚æ•°ï¼Œç¼ºä¹çµæ´»æ€§ã€‚ä¸ºäº†æ›´æœ‰æ•ˆåœ°ç”Ÿæˆå’Œåˆ©ç”¨å€™é€‰tokenï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æŽ¨æµ‹é‡‡æ ·æ–¹æ³•RADARï¼Œè¯¥æ–¹æ³•é‡‡ç”¨åŸºäºŽå¼ºåŒ–å­¦ä¹ çš„åŠ¨æ€è‰ç¨¿æ ‘ã€‚RADARå°†è‰ç¨¿æ ‘ç”Ÿæˆè¿‡ç¨‹å»ºæ¨¡ä¸ºé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆMDPï¼‰ï¼Œå¹¶é‡‡ç”¨ç¦»çº¿å¼ºåŒ–å­¦ä¹ æ¥è®­ç»ƒé¢„æµ‹æ¨¡åž‹ï¼Œä»Žè€Œèƒ½å¤Ÿå®žæ—¶å†³ç­–è‰ç¨¿æ¨¡åž‹çš„è°ƒç”¨æ¬¡æ•°ï¼Œå‡å°‘å†—ä½™è®¡ç®—ï¼Œè¿›ä¸€æ­¥åŠ é€ŸæŽ¨ç†ã€‚åœ¨ä¸‰ä¸ªLLMå’Œå››ä¸ªä»»åŠ¡ä¸Šçš„è¯„ä¼°è¡¨æ˜Žï¼ŒRADARç›¸å¯¹äºŽè‡ªå›žå½’è§£ç åŸºçº¿å®žçŽ°äº†3.17å€-4.82å€çš„åŠ é€Ÿã€‚ä»£ç å¯åœ¨https://github.com/minaduki-sora/RADAR èŽ·å–ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§åž‹è¯­è¨€æ¨¡åž‹ï¼ˆLLMï¼‰æŽ¨ç†é€Ÿåº¦æ…¢ä¸”æˆæœ¬é«˜çš„é—®é¢˜ã€‚çŽ°æœ‰çš„æŽ¨æµ‹é‡‡æ ·æ–¹æ³•è™½ç„¶èƒ½åŠ é€ŸæŽ¨ç†ï¼Œä½†å…¶è‰ç¨¿æ¨¡åž‹ï¼ˆdraft modelï¼‰çš„è°ƒç”¨æ¬¡æ•°æ˜¯é¢„å…ˆè®¾å®šçš„è¶…å‚æ•°ï¼Œç¼ºä¹è‡ªé€‚åº”æ€§ã€‚è¿™æ„å‘³ç€åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå¯èƒ½ä¼šè¿›è¡Œä¸å¿…è¦çš„è‰ç¨¿æ¨¡åž‹è°ƒç”¨ï¼Œå¯¼è‡´è®¡ç®—èµ„æºçš„æµªè´¹ï¼Œæˆ–è€…å› ä¸ºè°ƒç”¨æ¬¡æ•°ä¸è¶³è€Œé™åˆ¶äº†åŠ é€Ÿæ•ˆæžœã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šRADARçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ¥åŠ¨æ€åœ°æŽ§åˆ¶è‰ç¨¿æ¨¡åž‹çš„è°ƒç”¨æ¬¡æ•°ã€‚é€šè¿‡å°†è‰ç¨¿æ ‘çš„ç”Ÿæˆè¿‡ç¨‹å»ºæ¨¡æˆä¸€ä¸ªé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆMDPï¼‰ï¼ŒRADARèƒ½å¤Ÿæ ¹æ®å½“å‰çš„çŠ¶æ€ï¼ˆä¾‹å¦‚ï¼Œå·²ç”Ÿæˆçš„tokenåºåˆ—ï¼‰æ¥å†³å®šæ˜¯å¦ç»§ç»­è°ƒç”¨è‰ç¨¿æ¨¡åž‹ç”Ÿæˆæ›´å¤šçš„å€™é€‰tokenã€‚è¿™ç§åŠ¨æ€è°ƒæ•´ç­–ç•¥æ—¨åœ¨æœ€å¤§åŒ–åŠ é€Ÿæ•ˆæžœï¼ŒåŒæ—¶æœ€å°åŒ–å†—ä½™è®¡ç®—ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šRADARçš„æŠ€æœ¯æ¡†æž¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) **çŽ¯å¢ƒï¼ˆEnvironmentï¼‰**ï¼šå®šä¹‰äº†è‰ç¨¿æ ‘ç”Ÿæˆè¿‡ç¨‹ä¸­çš„çŠ¶æ€ç©ºé—´ã€åŠ¨ä½œç©ºé—´å’Œå¥–åŠ±å‡½æ•°ã€‚çŠ¶æ€ç©ºé—´åŒ…æ‹¬å·²ç”Ÿæˆçš„tokenåºåˆ—ï¼ŒåŠ¨ä½œç©ºé—´åŒ…æ‹¬æ˜¯å¦è°ƒç”¨è‰ç¨¿æ¨¡åž‹ç”Ÿæˆä¸‹ä¸€ä¸ªtokenã€‚2) **ç­–ç•¥ç½‘ç»œï¼ˆPolicy Networkï¼‰**ï¼šåŸºäºŽç¦»çº¿å¼ºåŒ–å­¦ä¹ è®­ç»ƒå¾—åˆ°ï¼Œç”¨äºŽé¢„æµ‹åœ¨ç»™å®šçŠ¶æ€ä¸‹åº”è¯¥é‡‡å–çš„åŠ¨ä½œï¼ˆå³æ˜¯å¦è°ƒç”¨è‰ç¨¿æ¨¡åž‹ï¼‰ã€‚3) **è‰ç¨¿æ¨¡åž‹ï¼ˆDraft Modelï¼‰**ï¼šç”¨äºŽç”Ÿæˆå€™é€‰tokenã€‚4) **éªŒè¯æ¨¡åž‹ï¼ˆVerification Modelï¼‰**ï¼šå³ç›®æ ‡LLMï¼Œç”¨äºŽéªŒè¯è‰ç¨¿æ¨¡åž‹ç”Ÿæˆçš„tokenæ˜¯å¦æ­£ç¡®ã€‚æ•´ä¸ªæµç¨‹æ˜¯ï¼Œé¦–å…ˆåˆ©ç”¨ç­–ç•¥ç½‘ç»œå†³å®šæ˜¯å¦è°ƒç”¨è‰ç¨¿æ¨¡åž‹ç”Ÿæˆå€™é€‰tokenï¼Œç„¶åŽä½¿ç”¨éªŒè¯æ¨¡åž‹éªŒè¯è¿™äº›tokenï¼Œæœ€åŽæ ¹æ®éªŒè¯ç»“æžœæ›´æ–°çŠ¶æ€ï¼Œå¹¶é‡å¤è¿™ä¸ªè¿‡ç¨‹ç›´åˆ°è¾¾åˆ°æœ€å¤§è‰ç¨¿æ ‘æ·±åº¦æˆ–é‡åˆ°éªŒè¯å¤±è´¥çš„tokenã€‚

**å…³é”®åˆ›æ–°**ï¼šRADARçš„å…³é”®åˆ›æ–°åœ¨äºŽä½¿ç”¨å¼ºåŒ–å­¦ä¹ æ¥åŠ¨æ€åœ°æŽ§åˆ¶è‰ç¨¿æ¨¡åž‹çš„è°ƒç”¨æ¬¡æ•°ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒRADARä¸å†ä¾èµ–äºŽé¢„è®¾çš„è¶…å‚æ•°ï¼Œè€Œæ˜¯èƒ½å¤Ÿæ ¹æ®å½“å‰çš„çŠ¶æ€è‡ªé€‚åº”åœ°è°ƒæ•´è‰ç¨¿æ ‘çš„æ·±åº¦ã€‚è¿™ç§åŠ¨æ€è°ƒæ•´ç­–ç•¥èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨è‰ç¨¿æ¨¡åž‹ç”Ÿæˆçš„å€™é€‰tokenï¼Œä»Žè€Œå®žçŽ°æ›´é«˜çš„æŽ¨ç†åŠ é€Ÿã€‚

**å…³é”®è®¾è®¡**ï¼šRADARä½¿ç”¨ç¦»çº¿å¼ºåŒ–å­¦ä¹ æ¥è®­ç»ƒç­–ç•¥ç½‘ç»œã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒé¦–å…ˆæ”¶é›†å¤§é‡çš„è‰ç¨¿æ ‘ç”Ÿæˆæ•°æ®ï¼Œç„¶åŽä½¿ç”¨è¿™äº›æ•°æ®æ¥è®­ç»ƒä¸€ä¸ªé¢„æµ‹æ¨¡åž‹ï¼Œè¯¥æ¨¡åž‹èƒ½å¤Ÿé¢„æµ‹åœ¨ç»™å®šçŠ¶æ€ä¸‹åº”è¯¥é‡‡å–çš„åŠ¨ä½œã€‚å¥–åŠ±å‡½æ•°çš„è®¾è®¡è‡³å…³é‡è¦ï¼Œå®ƒéœ€è¦å¹³è¡¡åŠ é€Ÿæ•ˆæžœå’Œè®¡ç®—æˆæœ¬ã€‚è®ºæ–‡ä¸­ä½¿ç”¨çš„å¥–åŠ±å‡½æ•°å¯èƒ½åŒ…æ‹¬éªŒè¯æˆåŠŸçš„tokenæ•°é‡ã€è‰ç¨¿æ¨¡åž‹çš„è°ƒç”¨æ¬¡æ•°ç­‰ã€‚ç­–ç•¥ç½‘ç»œçš„å…·ä½“ç»“æž„å’Œè®­ç»ƒç®—æ³•ï¼ˆä¾‹å¦‚ï¼ŒDQNã€SACç­‰ï¼‰åœ¨è®ºæ–‡ä¸­å¯èƒ½æœ‰æ‰€æè¿°ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒRADARåœ¨ä¸‰ä¸ªä¸åŒçš„LLMï¼ˆå…·ä½“æ¨¡åž‹åç§°æœªçŸ¥ï¼‰å’Œå››ä¸ªä¸åŒçš„ä»»åŠ¡ï¼ˆå…·ä½“ä»»åŠ¡åç§°æœªçŸ¥ï¼‰ä¸Šå®žçŽ°äº†æ˜¾è‘—çš„åŠ é€Ÿã€‚ç›¸å¯¹äºŽè‡ªå›žå½’è§£ç åŸºçº¿ï¼ŒRADARå®žçŽ°äº†3.17å€åˆ°4.82å€çš„åŠ é€Ÿã€‚è¿™äº›ç»“æžœè¡¨æ˜Žï¼ŒRADARèƒ½å¤Ÿæœ‰æ•ˆåœ°å‡å°‘å†—ä½™è®¡ç®—ï¼Œå¹¶å……åˆ†åˆ©ç”¨è‰ç¨¿æ¨¡åž‹ç”Ÿæˆçš„å€™é€‰tokenï¼Œä»Žè€Œæ˜¾è‘—æå‡LLMçš„æŽ¨ç†æ•ˆçŽ‡ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

RADARå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦å¿«é€Ÿå“åº”çš„å¤§åž‹è¯­è¨€æ¨¡åž‹åº”ç”¨ä¸­ï¼Œå¦‚åœ¨çº¿å¯¹è¯ç³»ç»Ÿã€å®žæ—¶ç¿»è¯‘ã€æ™ºèƒ½å®¢æœç­‰ã€‚é€šè¿‡åŠ é€ŸLLMæŽ¨ç†ï¼ŒRADARå¯ä»¥é™ä½Žå»¶è¿Ÿï¼Œæå‡ç”¨æˆ·ä½“éªŒï¼Œå¹¶é™ä½Žè®¡ç®—æˆæœ¬ï¼Œä½¿å¾—LLMèƒ½å¤Ÿæ›´å¹¿æ³›åœ°éƒ¨ç½²åœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šã€‚æœªæ¥ï¼ŒRADARå¯ä»¥ä¸Žå…¶ä»–åŠ é€ŸæŠ€æœ¯ç»“åˆï¼Œè¿›ä¸€æ­¥æå‡LLMçš„æŽ¨ç†æ•ˆçŽ‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Inference with modern Large Language Models (LLMs) is expensive and slow, and speculative sampling has emerged as an effective solution to this problem, however, the number of the calls to the draft model for generating candidate tokens in speculative sampling is a preset hyperparameter, lacking flexibility. To generate and utilize the candidate tokens more effectively, we propose RADAR, a novel speculative sampling method with RL-based dynamic draft trees. RADAR formulates the draft tree generation process as a Markov Decision Process (MDP) and employs offline reinforcement learning to train a prediction model, which enables real-time decision on the calls to the draft model, reducing redundant computations and further accelerating inference. Evaluations across three LLMs and four tasks show that RADAR achieves a speedup of 3.17x-4.82x over the auto-regressive decoding baseline. The code is available at https://github.com/minaduki-sora/RADAR.

