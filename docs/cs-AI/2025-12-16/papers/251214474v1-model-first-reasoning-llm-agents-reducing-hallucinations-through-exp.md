---
layout: default
title: Model-First Reasoning LLM Agents: Reducing Hallucinations through Explicit Problem Modeling
---

# Model-First Reasoning LLM Agents: Reducing Hallucinations through Explicit Problem Modeling

**arXiv**: [2512.14474v1](https://arxiv.org/abs/2512.14474) | [PDF](https://arxiv.org/pdf/2512.14474.pdf)

**ä½œè€…**: Annu Rana, Gaurav Kumar

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºModel-First Reasoningï¼Œé€šè¿‡æ˜¾å¼å»ºæ¨¡å‡å°‘LLMåœ¨å¤æ‚è§„åˆ’ä»»åŠ¡ä¸­çš„å¹»è§‰**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **3Dæ„ŸçŸ¥ä¸ŽçŠ¶æ€ä¼°è®¡ (Perception & State Est)** **è‡ªåŠ¨é©¾é©¶ (Autonomous Driving)**

**å…³é”®è¯**: `å¤§åž‹è¯­è¨€æ¨¡åž‹` `è§„åˆ’ä»»åŠ¡` `æ˜¾å¼å»ºæ¨¡` `çº¦æŸæ»¡è¶³` `Model-First Reasoning`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰LLMåœ¨å¤æ‚è§„åˆ’ä»»åŠ¡ä¸­ä¾èµ–éšå¼çŠ¶æ€è·Ÿè¸ªï¼Œç¼ºä¹æ˜¾å¼é—®é¢˜è¡¨ç¤ºï¼Œå¯¼è‡´çº¦æŸè¿åå’Œä¸ä¸€è‡´è§£ã€‚
2. Model-First Reasoning (MFR) èŒƒå¼å…ˆè®©LLMæž„å»ºæ˜¾å¼é—®é¢˜æ¨¡åž‹ï¼Œå†ç”Ÿæˆè§£å†³æ–¹æ¡ˆï¼Œæ¨¡æ‹Ÿç»å…¸AIè§„åˆ’ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒMFRåœ¨å¤šä¸ªè§„åˆ’é¢†åŸŸå‡å°‘äº†çº¦æŸè¿åï¼Œæå‡äº†è§£çš„è´¨é‡ï¼Œæ˜¾å¼å»ºæ¨¡è‡³å…³é‡è¦ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§åž‹è¯­è¨€æ¨¡åž‹ï¼ˆLLMï¼‰åœ¨å¤æ‚çš„å¤šæ­¥éª¤è§„åˆ’ä»»åŠ¡ä¸­è¡¨çŽ°ä¸ä½³ï¼Œå¸¸å¸¸å‡ºçŽ°çº¦æŸè¿åå’Œä¸ä¸€è‡´çš„è§£å†³æ–¹æ¡ˆã€‚çŽ°æœ‰çš„ç­–ç•¥ï¼Œå¦‚æ€ç»´é“¾ï¼ˆChain-of-Thoughtï¼‰å’ŒReActï¼Œä¾èµ–äºŽéšå¼çš„çŠ¶æ€è·Ÿè¸ªï¼Œç¼ºä¹æ˜¾å¼çš„é—®é¢˜è¡¨ç¤ºã€‚å—ç»å…¸AIè§„åˆ’çš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†Model-First Reasoningï¼ˆMFRï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ä¸¤é˜¶æ®µèŒƒå¼ï¼Œå…¶ä¸­LLMé¦–å…ˆæž„å»ºé—®é¢˜çš„æ˜¾å¼æ¨¡åž‹ï¼Œå®šä¹‰å®žä½“ã€çŠ¶æ€å˜é‡ã€åŠ¨ä½œå’Œçº¦æŸï¼Œç„¶åŽå†ç”Ÿæˆè§£å†³æ–¹æ¡ˆè®¡åˆ’ã€‚åœ¨åŒ…æ‹¬åŒ»ç–—è°ƒåº¦ã€è·¯çº¿è§„åˆ’ã€èµ„æºåˆ†é…ã€é€»è¾‘è°œé¢˜å’Œç¨‹åºåˆæˆç­‰å¤šä¸ªè§„åˆ’é¢†åŸŸä¸­ï¼Œä¸Žæ€ç»´é“¾å’ŒReActç›¸æ¯”ï¼ŒMFRå‡å°‘äº†çº¦æŸè¿åå¹¶æé«˜äº†è§£å†³æ–¹æ¡ˆè´¨é‡ã€‚æ¶ˆèžç ”ç©¶è¡¨æ˜Žï¼Œæ˜¾å¼å»ºæ¨¡é˜¶æ®µå¯¹äºŽè¿™äº›æ”¹è¿›è‡³å…³é‡è¦ã€‚æˆ‘ä»¬çš„ç»“æžœè¡¨æ˜Žï¼Œè®¸å¤šLLMè§„åˆ’å¤±è´¥æºäºŽè¡¨ç¤ºç¼ºé™·ï¼Œè€Œä¸æ˜¯æŽ¨ç†é™åˆ¶ï¼Œå¼ºè°ƒäº†æ˜¾å¼å»ºæ¨¡ä½œä¸ºé²æ£’å’Œå¯è§£é‡ŠAIä»£ç†çš„å…³é”®ç»„æˆéƒ¨åˆ†ã€‚æ‰€æœ‰æç¤ºã€è¯„ä¼°ç¨‹åºå’Œä»»åŠ¡æ•°æ®é›†å‡å·²è®°å½•ï¼Œä»¥æ–¹ä¾¿é‡çŽ°ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§åž‹è¯­è¨€æ¨¡åž‹ï¼ˆLLMï¼‰åœ¨å¤æ‚å¤šæ­¥éª¤è§„åˆ’ä»»åŠ¡ä¸­è¡¨çŽ°å‡ºçš„çº¦æŸè¿åå’Œä¸ä¸€è‡´è§£çš„é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•ï¼Œå¦‚Chain-of-Thoughtå’ŒReActï¼Œä¸»è¦ä¾èµ–äºŽéšå¼çš„çŠ¶æ€è·Ÿè¸ªï¼Œç¼ºä¹å¯¹é—®é¢˜æœ¬èº«çš„æ˜¾å¼å»ºæ¨¡ï¼Œè¿™ä½¿å¾—LLMéš¾ä»¥æœ‰æ•ˆåœ°å¤„ç†å¤æ‚çš„çº¦æŸæ¡ä»¶å’ŒçŠ¶æ€è½¬ç§»ï¼Œå¯¼è‡´è§„åˆ’å¤±è´¥ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å€Ÿé‰´ç»å…¸AIè§„åˆ’çš„æ€æƒ³ï¼Œåœ¨LLMè¿›è¡Œè§„åˆ’ä¹‹å‰ï¼Œå…ˆè®©å…¶æž„å»ºä¸€ä¸ªæ˜¾å¼çš„ã€ç»“æž„åŒ–çš„çŽ¯å¢ƒæ¨¡åž‹ã€‚è¿™ä¸ªæ¨¡åž‹åŒ…å«äº†å¯¹é—®é¢˜ä¸­å®žä½“ã€çŠ¶æ€å˜é‡ã€åŠ¨ä½œä»¥åŠçº¦æŸçš„æ˜Žç¡®å®šä¹‰ã€‚é€šè¿‡è¿™ç§æ˜¾å¼å»ºæ¨¡ï¼ŒLLMå¯ä»¥æ›´å¥½åœ°ç†è§£é—®é¢˜çš„æœ¬è´¨ï¼Œä»Žè€Œç”Ÿæˆæ›´åˆç†ã€æ›´ç¬¦åˆçº¦æŸçš„è§£å†³æ–¹æ¡ˆã€‚è¿™æ ·è®¾è®¡çš„ç›®çš„æ˜¯ä¸ºäº†å¼¥è¡¥LLMåœ¨éšå¼æŽ¨ç†æ–¹é¢çš„ä¸è¶³ï¼Œä½¿å…¶èƒ½å¤Ÿåƒä¼ ç»ŸAIè§„åˆ’å™¨ä¸€æ ·ï¼ŒåŸºäºŽæ˜Žç¡®çš„æ¨¡åž‹è¿›è¡ŒæŽ¨ç†å’Œè§„åˆ’ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šModel-First Reasoning (MFR) åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼š
1. **æ¨¡åž‹æž„å»ºé˜¶æ®µ**ï¼šLLMæŽ¥æ”¶é—®é¢˜æè¿°ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªæ˜¾å¼çš„æ¨¡åž‹ï¼ŒåŒ…æ‹¬ï¼š
    *   å®žä½“ï¼ˆEntitiesï¼‰ï¼šé—®é¢˜ä¸­æ¶‰åŠçš„å¯¹è±¡ã€‚
    *   çŠ¶æ€å˜é‡ï¼ˆState Variablesï¼‰ï¼šæè¿°å®žä½“çŠ¶æ€çš„å˜é‡ã€‚
    *   åŠ¨ä½œï¼ˆActionsï¼‰ï¼šå¯ä»¥æ‰§è¡Œçš„æ“ä½œï¼Œä»¥åŠå®ƒä»¬å¯¹çŠ¶æ€å˜é‡çš„å½±å“ã€‚
    *   çº¦æŸï¼ˆConstraintsï¼‰ï¼šå¿…é¡»æ»¡è¶³çš„æ¡ä»¶ã€‚
2. **è§„åˆ’ç”Ÿæˆé˜¶æ®µ**ï¼šåŸºäºŽæž„å»ºå¥½çš„æ¨¡åž‹ï¼ŒLLMç”Ÿæˆä¸€ä¸ªè§£å†³æ–¹æ¡ˆè®¡åˆ’ï¼Œå³ä¸€ç³»åˆ—åŠ¨ä½œï¼Œä½¿å¾—é—®é¢˜ä»Žåˆå§‹çŠ¶æ€è½¬ç§»åˆ°ç›®æ ‡çŠ¶æ€ï¼Œå¹¶ä¸”æ»¡è¶³æ‰€æœ‰çº¦æŸæ¡ä»¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šMFR æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºŽå¼•å…¥äº†æ˜¾å¼é—®é¢˜å»ºæ¨¡çš„æ€æƒ³ï¼Œè¿™ä¸ŽçŽ°æœ‰æ–¹æ³•ï¼ˆå¦‚Chain-of-Thoughtå’ŒReActï¼‰ä¾èµ–éšå¼æŽ¨ç†å½¢æˆäº†é²œæ˜Žå¯¹æ¯”ã€‚é€šè¿‡æ˜¾å¼å»ºæ¨¡ï¼ŒMFR ä½¿å¾— LLM èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£é—®é¢˜çš„ç»“æž„å’Œçº¦æŸï¼Œä»Žè€Œå‡å°‘å¹»è§‰å’Œçº¦æŸè¿åã€‚æœ¬è´¨åŒºåˆ«åœ¨äºŽï¼ŒMFR å°†é—®é¢˜åˆ†è§£ä¸ºæ¨¡åž‹æž„å»ºå’Œè§„åˆ’ç”Ÿæˆä¸¤ä¸ªé˜¶æ®µï¼Œè€ŒçŽ°æœ‰æ–¹æ³•åˆ™è¯•å›¾ä¸€æ­¥åˆ°ä½åœ°ç”Ÿæˆè§£å†³æ–¹æ¡ˆã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­æ²¡æœ‰æ˜Žç¡®æåŠå…·ä½“çš„å‚æ•°è®¾ç½®ã€æŸå¤±å‡½æ•°æˆ–ç½‘ç»œç»“æž„ç­‰æŠ€æœ¯ç»†èŠ‚ï¼Œå› ä¸º MFR æ˜¯ä¸€ç§é€šç”¨çš„æ¡†æž¶ï¼Œå¯ä»¥åº”ç”¨äºŽä¸åŒçš„ LLM å’Œè§„åˆ’ä»»åŠ¡ã€‚å…³é”®çš„è®¾è®¡åœ¨äºŽå¦‚ä½•è®¾è®¡åˆé€‚çš„æç¤ºï¼ˆpromptsï¼‰ï¼Œå¼•å¯¼ LLM ç”Ÿæˆå‡†ç¡®ã€å®Œæ•´çš„æ˜¾å¼æ¨¡åž‹ã€‚æ­¤å¤–ï¼Œå¦‚ä½•å°†ç”Ÿæˆçš„æ¨¡åž‹æœ‰æ•ˆåœ°ç”¨äºŽåŽç»­çš„è§„åˆ’ç”Ÿæˆä¹Ÿæ˜¯ä¸€ä¸ªå…³é”®çš„è®¾è®¡é—®é¢˜ã€‚è®ºæ–‡ä¸­æåˆ°ï¼Œæ‰€æœ‰æç¤ºã€è¯„ä¼°ç¨‹åºå’Œä»»åŠ¡æ•°æ®é›†å‡å·²è®°å½•ï¼Œä»¥æ–¹ä¾¿é‡çŽ°ï¼Œè¿™è¡¨æ˜Žæç¤ºå·¥ç¨‹åœ¨ MFR ä¸­æ‰®æ¼”ç€é‡è¦çš„è§’è‰²ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒMFRåœ¨å¤šä¸ªè§„åˆ’é¢†åŸŸï¼ˆåŒ…æ‹¬åŒ»ç–—è°ƒåº¦ã€è·¯çº¿è§„åˆ’ã€èµ„æºåˆ†é…ã€é€»è¾‘è°œé¢˜å’Œç¨‹åºåˆæˆï¼‰ä¸­ï¼Œæ˜¾è‘—å‡å°‘äº†çº¦æŸè¿åï¼Œå¹¶æé«˜äº†è§£å†³æ–¹æ¡ˆçš„è´¨é‡ã€‚ä¸ŽChain-of-Thoughtå’ŒReActç­‰åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼ŒMFRåœ¨çº¦æŸæ»¡è¶³çŽ‡å’Œè§£å†³æ–¹æ¡ˆè´¨é‡æ–¹é¢å‡å–å¾—äº†æ˜¾è‘—æå‡ï¼Œæ¶ˆèžå®žéªŒè¿›ä¸€æ­¥éªŒè¯äº†æ˜¾å¼å»ºæ¨¡é˜¶æ®µå¯¹äºŽæ€§èƒ½æå‡çš„å…³é”®ä½œç”¨ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽå„ç§éœ€è¦å¤æ‚è§„åˆ’å’ŒæŽ¨ç†çš„é¢†åŸŸï¼Œä¾‹å¦‚ï¼šåŒ»ç–—è°ƒåº¦ã€è·¯çº¿è§„åˆ’ã€èµ„æºåˆ†é…ã€ç‰©æµç®¡ç†ã€æ™ºèƒ½åˆ¶é€ ç­‰ã€‚é€šè¿‡æé«˜LLMåœ¨è¿™äº›é¢†åŸŸçš„è§„åˆ’èƒ½åŠ›ï¼Œå¯ä»¥å®žçŽ°æ›´é«˜æ•ˆã€æ›´å¯é çš„è‡ªåŠ¨åŒ–å†³ç­–ï¼Œå…·æœ‰é‡è¦çš„å®žé™…åº”ç”¨ä»·å€¼å’Œå¹¿é˜”çš„æœªæ¥å‘å±•å‰æ™¯ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Large Language Models (LLMs) often struggle with complex multi-step planning tasks, showing high rates of constraint violations and inconsistent solutions. Existing strategies such as Chain-of-Thought and ReAct rely on implicit state tracking and lack an explicit problem representation. Inspired by classical AI planning, we propose Model-First Reasoning (MFR), a two-phase paradigm in which the LLM first constructs an explicit model of the problem, defining entities, state variables, actions, and constraints, before generating a solution plan. Across multiple planning domains, including medical scheduling, route planning, resource allocation, logic puzzles, and procedural synthesis, MFR reduces constraint violations and improves solution quality compared to Chain-of-Thought and ReAct. Ablation studies show that the explicit modeling phase is critical for these gains. Our results suggest that many LLM planning failures stem from representational deficiencies rather than reasoning limitations, highlighting explicit modeling as a key component for robust and interpretable AI agents. All prompts, evaluation procedures, and task datasets are documented to facilitate reproducibility.

