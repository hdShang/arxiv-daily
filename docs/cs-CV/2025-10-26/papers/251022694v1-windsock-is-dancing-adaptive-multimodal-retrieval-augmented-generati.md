---
layout: default
title: "Windsock is Dancing: Adaptive Multimodal Retrieval-Augmented Generation"
---

# Windsock is Dancing: Adaptive Multimodal Retrieval-Augmented Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.22694" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.22694v1</a>
  <a href="https://arxiv.org/pdf/2510.22694.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.22694v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.22694v1', 'Windsock is Dancing: Adaptive Multimodal Retrieval-Augmented Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shu Zhao, Tianyi Shen, Nilesh Ahuja, Omesh Tickoo, Vijaykrishnan Narayanan

**åˆ†ç±»**: cs.CV, cs.CL, cs.IR

**å‘å¸ƒæ—¥æœŸ**: 2025-10-26

**å¤‡æ³¨**: Accepted at NeurIPS 2025 UniReps Workshop

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Windsockï¼šè‡ªé€‚åº”å¤šæ¨¡æ€æ£€ç´¢å¢å¼ºç”Ÿæˆæ–¹æ³•ï¼Œæå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹æ€§èƒ½ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ£€ç´¢å¢å¼ºç”Ÿæˆ` `è‡ªé€‚åº”æ£€ç´¢` `æ¨¡æ€é€‰æ‹©` `æŒ‡ä»¤è°ƒä¼˜` `å¤§è¯­è¨€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰MRAGæ–¹æ³•åœ¨æ£€ç´¢æ—¶æœºã€æ¨¡æ€é€‰æ‹©å’Œä¿¡æ¯åˆ©ç”¨æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´ç”Ÿæˆè´¨é‡å—é™ä¸”è®¡ç®—å¼€é”€å¤§ã€‚
2. Windsocké€šè¿‡æŸ¥è¯¢ä¾èµ–çš„æ¨¡å—åŠ¨æ€å†³ç­–æ£€ç´¢å¿…è¦æ€§å’Œæ¨¡æ€é€‰æ‹©ï¼ŒDANCEæŒ‡ä»¤è°ƒä¼˜å¢å¼ºæ¨¡å‹å¯¹å™ªå£°çš„é²æ£’æ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æå‡ç”Ÿæˆè´¨é‡çš„åŒæ—¶ï¼Œæœ‰æ•ˆé™ä½äº†æ£€ç´¢æ—¶é—´ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€æ£€ç´¢å¢å¼ºç”Ÿæˆ(MRAG)é€šè¿‡æ•´åˆå¤–éƒ¨çŸ¥è¯†åº“çš„éå‚æ•°çŸ¥è¯†ï¼Œå·²æˆä¸ºç”Ÿæˆå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLM)çš„çœŸå®å’Œæœ€æ–°å“åº”çš„ä¸€ç§æœ‰å‰æ™¯çš„æ–¹æ³•ã€‚ç„¶è€Œï¼Œç°æœ‰çš„MRAGæ–¹æ³•å­˜åœ¨é™æ€æ£€ç´¢ç­–ç•¥ã€ä¸çµæ´»çš„æ¨¡æ€é€‰æ‹©ä»¥åŠå¯¹æ£€ç´¢ä¿¡æ¯åˆ©ç”¨ä¸è¶³çš„é—®é¢˜ï¼Œå¯¼è‡´ä¸‰ä¸ªå…³é”®æŒ‘æˆ˜ï¼šç¡®å®šä½•æ—¶æ£€ç´¢ã€æ•´åˆä½•ç§æ¨¡æ€ä»¥åŠå¦‚ä½•æœ‰æ•ˆåœ°åˆ©ç”¨æ£€ç´¢ä¿¡æ¯ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†Windsockï¼Œä¸€ä¸ªæŸ¥è¯¢ç›¸å…³çš„æ¨¡å—ï¼Œå¯ä»¥å†³å®šæ£€ç´¢çš„å¿…è¦æ€§å’Œæ¨¡æ€é€‰æ‹©ï¼Œä»è€Œæœ‰æ•ˆåœ°å‡å°‘è®¡ç®—å¼€é”€å¹¶æé«˜å“åº”è´¨é‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†åŠ¨æ€æŠ—å™ª(DANCE)æŒ‡ä»¤è°ƒä¼˜ï¼Œè¿™æ˜¯ä¸€ç§è‡ªé€‚åº”è®­ç»ƒç­–ç•¥ï¼Œå¯ä»¥å¢å¼ºMLLMåˆ©ç”¨æ£€ç´¢ä¿¡æ¯çš„èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒå¯¹å™ªå£°çš„é²æ£’æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€ç§åˆ©ç”¨MLLMå†…éƒ¨çŸ¥è¯†çš„è‡ªæˆ‘è¯„ä¼°æ–¹æ³•ï¼Œå°†é—®ç­”æ•°æ®é›†è½¬æ¢ä¸ºMRAGè®­ç»ƒæ•°æ®é›†ã€‚å¤§é‡çš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„æ–¹æ³•æ˜¾è‘—æé«˜äº†ç”Ÿæˆè´¨é‡17.07%ï¼ŒåŒæ—¶å‡å°‘äº†8.95%çš„æ£€ç´¢æ—¶é—´ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„å¤šæ¨¡æ€æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆMRAGï¼‰æ–¹æ³•é¢ä¸´ä¸‰ä¸ªä¸»è¦é—®é¢˜ï¼šä¸€æ˜¯é™æ€çš„æ£€ç´¢ç­–ç•¥æ— æ³•æ ¹æ®æŸ¥è¯¢åŠ¨æ€è°ƒæ•´ï¼›äºŒæ˜¯æ¨¡æ€é€‰æ‹©ä¸çµæ´»ï¼Œæ— æ³•æ ¹æ®é—®é¢˜é€‰æ‹©åˆé€‚çš„æ¨¡æ€ä¿¡æ¯ï¼›ä¸‰æ˜¯å¯¹æ£€ç´¢åˆ°çš„ä¿¡æ¯åˆ©ç”¨ä¸è¶³ï¼Œå®¹æ˜“å—åˆ°å™ªå£°å¹²æ‰°ã€‚è¿™äº›é—®é¢˜å¯¼è‡´ç”Ÿæˆè´¨é‡ä¸‹é™ï¼Œè®¡ç®—å¼€é”€å¢åŠ ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ä½¿MRAGè¿‡ç¨‹æ›´åŠ è‡ªé€‚åº”å’Œæ™ºèƒ½ã€‚é€šè¿‡å¼•å…¥æŸ¥è¯¢ä¾èµ–çš„æ¨¡å—Windsockï¼ŒåŠ¨æ€å†³å®šä½•æ—¶è¿›è¡Œæ£€ç´¢ä»¥åŠé€‰æ‹©ä½•ç§æ¨¡æ€çš„ä¿¡æ¯ã€‚åŒæ—¶ï¼Œé‡‡ç”¨åŠ¨æ€æŠ—å™ªï¼ˆDANCEï¼‰æŒ‡ä»¤è°ƒä¼˜ï¼Œæé«˜æ¨¡å‹å¯¹æ£€ç´¢ä¿¡æ¯çš„åˆ©ç”¨ç‡å’ŒæŠ—å™ªèƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä¸‰ä¸ªä¸»è¦éƒ¨åˆ†ï¼š1) Windsockæ¨¡å—ï¼šæ ¹æ®è¾“å…¥æŸ¥è¯¢ï¼ŒåŠ¨æ€å†³å®šæ˜¯å¦è¿›è¡Œæ£€ç´¢ä»¥åŠé€‰æ‹©ä½•ç§æ¨¡æ€çš„ä¿¡æ¯ï¼›2) æ£€ç´¢æ¨¡å—ï¼šæ ¹æ®Windsockçš„å†³ç­–ï¼Œä»å¤–éƒ¨çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯ï¼›3) å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ï¼šå°†æ£€ç´¢åˆ°çš„ä¿¡æ¯ä¸åŸå§‹è¾“å…¥ç»“åˆï¼Œç”Ÿæˆæœ€ç»ˆçš„ç­”æ¡ˆã€‚DANCEæŒ‡ä»¤è°ƒä¼˜ç”¨äºè®­ç»ƒMLLMï¼Œæé«˜å…¶åˆ©ç”¨æ£€ç´¢ä¿¡æ¯çš„èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºWindsockæ¨¡å—å’ŒDANCEæŒ‡ä»¤è°ƒä¼˜ã€‚Windsockæ¨¡å—å®ç°äº†æŸ¥è¯¢ä¾èµ–çš„åŠ¨æ€æ£€ç´¢å’Œæ¨¡æ€é€‰æ‹©ï¼Œé¿å…äº†ä¸å¿…è¦çš„æ£€ç´¢å’Œæ¨¡æ€ä¿¡æ¯çš„å¼•å…¥ã€‚DANCEæŒ‡ä»¤è°ƒä¼˜é€šè¿‡è‡ªé€‚åº”çš„è®­ç»ƒç­–ç•¥ï¼Œæé«˜äº†æ¨¡å‹å¯¹æ£€ç´¢ä¿¡æ¯çš„åˆ©ç”¨ç‡å’ŒæŠ—å™ªèƒ½åŠ›ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨æ£€ç´¢åˆ°çš„ä¿¡æ¯ã€‚

**å…³é”®è®¾è®¡**ï¼šWindsockæ¨¡å—çš„å…·ä½“å®ç°ç»†èŠ‚æœªçŸ¥ï¼Œä½†å…¶æ ¸å¿ƒåœ¨äºå­¦ä¹ ä¸€ä¸ªç­–ç•¥ç½‘ç»œï¼Œæ ¹æ®è¾“å…¥æŸ¥è¯¢çš„ç‰¹å¾ï¼Œé¢„æµ‹æ£€ç´¢çš„å¿…è¦æ€§å’Œæ¨¡æ€é€‰æ‹©ã€‚DANCEæŒ‡ä»¤è°ƒä¼˜çš„å…·ä½“å®ç°ç»†èŠ‚ä¹ŸæœªçŸ¥ï¼Œä½†å…¶æ ¸å¿ƒåœ¨äºè®¾è®¡ä¸€ç§è‡ªé€‚åº”çš„æŸå¤±å‡½æ•°ï¼Œæ ¹æ®æ£€ç´¢ä¿¡æ¯çš„è´¨é‡åŠ¨æ€è°ƒæ•´è®­ç»ƒæƒé‡ï¼Œä»è€Œæé«˜æ¨¡å‹å¯¹é«˜è´¨é‡æ£€ç´¢ä¿¡æ¯çš„åˆ©ç”¨ç‡ï¼Œå¹¶é™ä½å™ªå£°ä¿¡æ¯çš„å¹²æ‰°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„Windsockæ–¹æ³•åœ¨ç”Ÿæˆè´¨é‡ä¸Šæå‡äº†17.07%ï¼ŒåŒæ—¶å‡å°‘äº†8.95%çš„æ£€ç´¢æ—¶é—´ã€‚è¿™äº›æ•°æ®è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æé«˜ç”Ÿæˆè´¨é‡çš„åŒæ—¶ï¼Œæœ‰æ•ˆé™ä½äº†è®¡ç®—å¼€é”€ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ™ºèƒ½é—®ç­”ç³»ç»Ÿã€å¤šæ¨¡æ€å¯¹è¯æœºå™¨äººã€å†…å®¹åˆ›ä½œç­‰é¢†åŸŸã€‚é€šè¿‡åŠ¨æ€æ£€ç´¢å’Œæ¨¡æ€é€‰æ‹©ï¼Œå¯ä»¥æé«˜ç”Ÿæˆå†…å®¹çš„å‡†ç¡®æ€§å’Œç›¸å…³æ€§ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æ‰©å±•åˆ°æ›´å¤šæ¨¡æ€å’Œæ›´å¤æ‚çš„ä»»åŠ¡ä¸­ï¼Œä¾‹å¦‚è§†é¢‘ç†è§£å’Œè·¨æ¨¡æ€æ¨ç†ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal Retrieval-Augmented Generation (MRAG) has emerged as a promising method to generate factual and up-to-date responses of Multimodal Large Language Models (MLLMs) by incorporating non-parametric knowledge from external knowledge bases. However, existing MRAG approaches suffer from static retrieval strategies, inflexible modality selection, and suboptimal utilization of retrieved information, leading to three critical challenges: determining when to retrieve, what modality to incorporate, and how to utilize retrieved information effectively. To address these challenges, we introduce Windsock, a query-dependent module making decisions on retrieval necessity and modality selection, effectively reducing computational overhead and improving response quality. Additionally, we propose Dynamic Noise-Resistance (DANCE) Instruction Tuning, an adaptive training strategy that enhances MLLMs' ability to utilize retrieved information while maintaining robustness against noise. Moreover, we adopt a self-assessment approach leveraging knowledge within MLLMs to convert question-answering datasets to MRAG training datasets. Extensive experiments demonstrate that our proposed method significantly improves the generation quality by 17.07% while reducing 8.95% retrieval times.

