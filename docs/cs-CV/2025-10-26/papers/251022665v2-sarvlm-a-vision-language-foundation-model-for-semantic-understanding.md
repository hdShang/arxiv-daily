---
layout: default
title: SARVLM: A Vision Language Foundation Model for Semantic Understanding and Target Recognition in SAR Imagery
---

# SARVLM: A Vision Language Foundation Model for Semantic Understanding and Target Recognition in SAR Imagery

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.22665" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.22665v2</a>
  <a href="https://arxiv.org/pdf/2510.22665.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.22665v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.22665v2', 'SARVLM: A Vision Language Foundation Model for Semantic Understanding and Target Recognition in SAR Imagery')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Qiwei Ma, Zhiyu Wang, Wang Liu, Xukun Lu, Bin Deng, Puhong Duan, Xudong Kang, Shutao Li

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-10-26 (æ›´æ–°: 2025-11-26)

**å¤‡æ³¨**: 11 pages, 9 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSARVLMï¼šé¢å‘SARå›¾åƒè¯­ä¹‰ç†è§£å’Œç›®æ ‡è¯†åˆ«çš„è§†è§‰è¯­è¨€åŸºç¡€æ¨¡å‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `SARå›¾åƒ` `è§†è§‰è¯­è¨€æ¨¡å‹` `å¤šæ¨¡æ€å­¦ä¹ ` `é¢†åŸŸè¿ç§»` `è¯­ä¹‰ç†è§£`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰SARåŸºç¡€æ¨¡å‹ä¾§é‡ä½çº§è§†è§‰ç‰¹å¾ï¼Œå¿½ç•¥äº†å¤šæ¨¡æ€å¯¹é½å’Œé›¶æ ·æœ¬ç›®æ ‡è¯†åˆ«ã€‚
2. æå‡ºSARVLMï¼Œé€šè¿‡é¢†åŸŸè¿ç§»è®­ç»ƒç­–ç•¥å’Œè§†è§‰-è¯­è¨€å¯¹æ¯”å­¦ä¹ ï¼Œè¿æ¥SARå›¾åƒå’Œæ–‡æœ¬æè¿°ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒSARVLMåœ¨å¤šä¸ªä»»åŠ¡ä¸Šä¼˜äºç°æœ‰VLMï¼Œæå‡äº†SARå›¾åƒçš„è¯­ä¹‰ç†è§£èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åˆæˆå­”å¾„é›·è¾¾(SAR)å› å…¶å…¨å¤©å€™èƒ½åŠ›æˆä¸ºé‡è¦çš„æˆåƒæ–¹å¼ã€‚å°½ç®¡è‡ªç›‘ç£å­¦ä¹ å’Œæ©ç å›¾åƒå»ºæ¨¡(MIM)çš„æœ€æ–°è¿›å±•æ¨åŠ¨äº†SARåŸºç¡€æ¨¡å‹çš„å‘å±•ï¼Œä½†è¿™äº›æ–¹æ³•ä¸»è¦å¼ºè°ƒä½çº§è§†è§‰ç‰¹å¾ï¼Œå¾€å¾€å¿½ç•¥äº†SARå›¾åƒä¸­çš„å¤šæ¨¡æ€å¯¹é½å’Œé›¶æ ·æœ¬ç›®æ ‡è¯†åˆ«ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æ„å»ºäº†SARVLM-1Mï¼Œä¸€ä¸ªåŒ…å«è¶…è¿‡ä¸€ç™¾ä¸‡å›¾åƒ-æ–‡æœ¬å¯¹çš„å¤§è§„æ¨¡è§†è§‰è¯­è¨€æ•°æ®é›†ï¼Œè¿™äº›æ•°æ®æ¥è‡ªç°æœ‰æ•°æ®é›†çš„èšåˆã€‚æˆ‘ä»¬è¿›ä¸€æ­¥æå‡ºäº†ä¸€ç§é¢†åŸŸè¿ç§»è®­ç»ƒç­–ç•¥ï¼Œä»¥å‡è½»è‡ªç„¶å›¾åƒå’ŒSARå›¾åƒä¹‹é—´çš„å·¨å¤§å·®è·ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬å¼€å‘äº†SARVLMï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªä¸“ä¸ºSARå®šåˆ¶çš„è§†è§‰è¯­è¨€åŸºç¡€æ¨¡å‹(VLM)ï¼ŒåŒ…å«SARCLIPå’ŒSARCapã€‚SARVLMåœ¨æå‡ºçš„é¢†åŸŸè¿ç§»ç­–ç•¥ä¸‹ï¼Œé€šè¿‡è§†è§‰-è¯­è¨€å¯¹æ¯”ç›®æ ‡è¿›è¡Œè®­ç»ƒï¼Œä»è€Œæ¡¥æ¥äº†SARå›¾åƒå’Œæ–‡æœ¬æè¿°ã€‚åœ¨å›¾åƒæ–‡æœ¬æ£€ç´¢ã€é›¶æ ·æœ¬åˆ†ç±»ã€è¯­ä¹‰å®šä½å’Œå›¾åƒå­—å¹•ç”Ÿæˆæ–¹é¢çš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒSARVLMæä¾›äº†å“è¶Šçš„ç‰¹å¾æå–å’Œè§£é‡Šèƒ½åŠ›ï¼Œä¼˜äºæœ€å…ˆè¿›çš„VLMï¼Œå¹¶æ¨åŠ¨äº†SARè¯­ä¹‰ç†è§£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰SARå›¾åƒå¤„ç†æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åŸºäºè‡ªç›‘ç£å­¦ä¹ å’Œæ©ç å›¾åƒå»ºæ¨¡çš„åŸºç¡€æ¨¡å‹ï¼Œè™½ç„¶åœ¨æå–ä½çº§è§†è§‰ç‰¹å¾æ–¹é¢æœ‰æ‰€è¿›å±•ï¼Œä½†ç¼ºä¹å¯¹SARå›¾åƒä¸æ–‡æœ¬æè¿°ä¹‹é—´è¯­ä¹‰å…³è”çš„å»ºæ¨¡èƒ½åŠ›ï¼Œå¯¼è‡´åœ¨å¤šæ¨¡æ€ä»»åŠ¡ï¼ˆå¦‚å›¾åƒæ–‡æœ¬æ£€ç´¢ã€é›¶æ ·æœ¬åˆ†ç±»ï¼‰å’Œé«˜å±‚æ¬¡è¯­ä¹‰ç†è§£æ–¹é¢è¡¨ç°ä¸è¶³ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆåˆ©ç”¨æ–‡æœ¬ä¿¡æ¯æ¥æå‡SARå›¾åƒçš„ç†è§£å’Œè¯†åˆ«èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªè§†è§‰è¯­è¨€åŸºç¡€æ¨¡å‹ï¼ˆVLMï¼‰ï¼Œé€šè¿‡å¤§è§„æ¨¡çš„SARå›¾åƒ-æ–‡æœ¬å¯¹æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œå­¦ä¹ SARå›¾åƒä¸æ–‡æœ¬æè¿°ä¹‹é—´çš„å¯¹åº”å…³ç³»ã€‚é€šè¿‡é¢†åŸŸè¿ç§»è®­ç»ƒç­–ç•¥ï¼Œç¼“è§£è‡ªç„¶å›¾åƒå’ŒSARå›¾åƒä¹‹é—´çš„é¢†åŸŸå·®å¼‚ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£SARå›¾åƒçš„è¯­ä¹‰ä¿¡æ¯ã€‚åˆ©ç”¨è§†è§‰-è¯­è¨€å¯¹æ¯”å­¦ä¹ ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿå°†SARå›¾åƒå’Œæ–‡æœ¬åµŒå…¥åˆ°åŒä¸€ä¸ªè¯­ä¹‰ç©ºé—´ä¸­ï¼Œä»è€Œå®ç°å¤šæ¨¡æ€ä»»åŠ¡çš„æœ‰æ•ˆå¤„ç†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSARVLMåŒ…å«ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šSARCLIPå’ŒSARCapã€‚SARCLIPè´Ÿè´£å­¦ä¹ SARå›¾åƒå’Œæ–‡æœ¬çš„è”åˆåµŒå…¥è¡¨ç¤ºï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ æœ€å¤§åŒ–åŒ¹é…å›¾åƒ-æ–‡æœ¬å¯¹çš„ç›¸ä¼¼åº¦ï¼Œæœ€å°åŒ–ä¸åŒ¹é…å¯¹çš„ç›¸ä¼¼åº¦ã€‚SARCapæ˜¯ä¸€ä¸ªå›¾åƒå­—å¹•ç”Ÿæˆæ¨¡å‹ï¼Œç”¨äºç”ŸæˆSARå›¾åƒçš„æ–‡æœ¬æè¿°ã€‚æ•´ä½“è®­ç»ƒæµç¨‹åŒ…æ‹¬ï¼š1) æ„å»ºå¤§è§„æ¨¡SARå›¾åƒ-æ–‡æœ¬æ•°æ®é›†SARVLM-1Mï¼›2) ä½¿ç”¨é¢†åŸŸè¿ç§»è®­ç»ƒç­–ç•¥é¢„è®­ç»ƒSARCLIPï¼›3) ä½¿ç”¨é¢„è®­ç»ƒçš„SARCLIPåˆå§‹åŒ–SARCapï¼Œå¹¶è¿›è¡Œå¾®è°ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æ„å»ºäº†å¤§è§„æ¨¡SARå›¾åƒ-æ–‡æœ¬æ•°æ®é›†SARVLM-1Mï¼Œä¸ºSARè§†è§‰è¯­è¨€æ¨¡å‹çš„è®­ç»ƒæä¾›äº†æ•°æ®åŸºç¡€ï¼›2) æå‡ºäº†é¢†åŸŸè¿ç§»è®­ç»ƒç­–ç•¥ï¼Œæœ‰æ•ˆç¼“è§£äº†è‡ªç„¶å›¾åƒå’ŒSARå›¾åƒä¹‹é—´çš„é¢†åŸŸå·®å¼‚ï¼›3) å¼€å‘äº†SARVLMï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªä¸“ä¸ºSARå®šåˆ¶çš„è§†è§‰è¯­è¨€åŸºç¡€æ¨¡å‹ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¤„ç†å¤šæ¨¡æ€SARå›¾åƒç†è§£ä»»åŠ¡ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒSARVLMèƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨æ–‡æœ¬ä¿¡æ¯æ¥æå‡SARå›¾åƒçš„è¯­ä¹‰ç†è§£èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šé¢†åŸŸè¿ç§»è®­ç»ƒç­–ç•¥çš„å…·ä½“å®ç°æ–¹å¼æœªçŸ¥ï¼Œè®ºæ–‡ä¸­å¯èƒ½æ²¡æœ‰è¯¦ç»†æè¿°ã€‚è§†è§‰-è¯­è¨€å¯¹æ¯”å­¦ä¹ çš„æŸå¤±å‡½æ•°é€šå¸¸é‡‡ç”¨InfoNCEæŸå¤±ã€‚SARCLIPå’ŒSARCapçš„å…·ä½“ç½‘ç»œç»“æ„æœªçŸ¥ï¼Œä½†æ¨æµ‹å¯èƒ½é‡‡ç”¨äº†Transformeræ¶æ„ã€‚SARVLM-1Mæ•°æ®é›†çš„æ„å»ºç»†èŠ‚æœªçŸ¥ï¼ŒåŒ…æ‹¬æ•°æ®æ¥æºã€æ¸…æ´—å’Œæ ‡æ³¨æ–¹æ³•ç­‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒSARVLMåœ¨å›¾åƒæ–‡æœ¬æ£€ç´¢ã€é›¶æ ·æœ¬åˆ†ç±»ã€è¯­ä¹‰å®šä½å’Œå›¾åƒå­—å¹•ç”Ÿæˆç­‰ä»»åŠ¡ä¸Šå‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œä¼˜äºç°æœ‰çš„è§†è§‰è¯­è¨€æ¨¡å‹ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿æœªçŸ¥ï¼Œä½†æ‘˜è¦ä¸­æ˜ç¡®æŒ‡å‡ºSARVLMæä¾›äº†å“è¶Šçš„ç‰¹å¾æå–å’Œè§£é‡Šèƒ½åŠ›ï¼Œå¹¶æ¨åŠ¨äº†SARè¯­ä¹‰ç†è§£ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SARVLMåœ¨é¥æ„Ÿå›¾åƒåˆ†æã€ç›®æ ‡æ£€æµ‹ä¸è¯†åˆ«ã€ç¯å¢ƒç›‘æµ‹ã€ç¾å®³è¯„ä¼°ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥ç”¨äºè‡ªåŠ¨è¯†åˆ«SARå›¾åƒä¸­çš„èˆ°èˆ¹ã€å»ºç­‘ç‰©ç­‰ç›®æ ‡ï¼Œè¾…åŠ©è¿›è¡Œæµ·æ´‹ç›‘è§†å’ŒåŸå¸‚è§„åˆ’ã€‚åœ¨ç¾å®³å‘ç”Ÿæ—¶ï¼Œå¯ä»¥å¿«é€Ÿåˆ†æSARå›¾åƒï¼Œè¯„ä¼°å—ç¾æƒ…å†µï¼Œä¸ºæ•‘æ´å·¥ä½œæä¾›æ”¯æŒã€‚æœªæ¥ï¼ŒSARVLMæœ‰æœ›æˆä¸ºSARå›¾åƒæ™ºèƒ½è§£è¯‘çš„é‡è¦å·¥å…·ï¼Œæ¨åŠ¨é¥æ„Ÿé¢†åŸŸçš„æ™ºèƒ½åŒ–å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Synthetic Aperture Radar (SAR) is a crucial imaging modality thanks to its all-weather capability. Although recent advances in self-supervised learning and masked image modeling (MIM) have enabled SAR foundation models, these methods largely emphasize low-level visual features and often overlook multimodal alignment and zero-shot target recognition in SAR imagery. To address this, we construct SARVLM-1M, a large-scale vision-language dataset with over one million image-text pairs aggregated from existing datasets. We further propose a domain transfer training strategy to mitigate the large gap between natural and SAR imagery. Building on this, we develop SARVLM, the first vision language foundation model (VLM) tailored to SAR, comprising SARCLIP and SARCap. SARVLM is trained with a vision-language contrastive objective under the proposed domain transfer strategy, bridging SAR imagery and textual descriptions. Extensive experiments on image text retrieval, zero-shot classification, semantic localization, and imagery captioning demonstrate that SARVLM delivers superior feature extraction and interpretation, outperforming state-of-the-art VLMs and advancing SAR semantic understanding. Code and datasets will be released soon.

