---
layout: default
title: LLM-based Fusion of Multi-modal Features for Commercial Memorability Prediction
---

# LLM-based Fusion of Multi-modal Features for Commercial Memorability Prediction

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.22829" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.22829v1</a>
  <a href="https://arxiv.org/pdf/2510.22829.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.22829v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.22829v1', 'LLM-based Fusion of Multi-modal Features for Commercial Memorability Prediction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Aleksandar Pramov

**åˆ†ç±»**: cs.CV, cs.AI, cs.MM

**å‘å¸ƒæ—¥æœŸ**: 2025-10-26

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/dsgt-arc/mediaeval-2025-memorability)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºLLMçš„å¤šæ¨¡æ€èåˆæ–¹æ³•ï¼Œç”¨äºæå‡å•†ä¸šå¹¿å‘Šè®°å¿†åº¦é¢„æµ‹çš„é²æ£’æ€§å’Œæ³›åŒ–æ€§ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å•†ä¸šå¹¿å‘Šè®°å¿†åº¦é¢„æµ‹` `å¤šæ¨¡æ€èåˆ` `å¤§å‹è¯­è¨€æ¨¡å‹` `ç†ç”±æç¤º` `Low-Rank Adaptation`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å•†ä¸šå¹¿å‘Šè®°å¿†åº¦é¢„æµ‹æ–¹æ³•åœ¨é²æ£’æ€§å’Œæ³›åŒ–æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥é€‚åº”å¤æ‚å¤šå˜çš„æ•°æ®ã€‚
2. åˆ©ç”¨LLMå¼ºå¤§çš„ç†è§£å’Œæ¨ç†èƒ½åŠ›ï¼Œç»“åˆè§†è§‰å’Œæ–‡æœ¬ç‰¹å¾ï¼Œå¹¶é€šè¿‡ç†ç”±æç¤ºå¼•å¯¼æ¨¡å‹å­¦ä¹ ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºLLMçš„ç³»ç»Ÿåœ¨é²æ£’æ€§å’Œæ³›åŒ–æ€§æ–¹é¢ä¼˜äºä¼ ç»Ÿæ¢¯åº¦æå‡æ ‘æ¨¡å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡é’ˆå¯¹MediaEval 2025 workshopç«èµ›ä¸­â€œè®°å¿†åº¦ï¼šé¢„æµ‹ç”µå½±å’Œå•†ä¸šå¹¿å‘Šçš„è®°å¿†åº¦â€ä»»åŠ¡çš„â€œå­ä»»åŠ¡2ï¼šå•†ä¸š/å¹¿å‘Šè®°å¿†åº¦é¢„æµ‹â€é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºGemma-3 LLMçš„å¤šæ¨¡æ€èåˆç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿé€šè¿‡å¤šæ¨¡æ€æŠ•å½±æ•´åˆäº†é¢„å…ˆè®¡ç®—çš„è§†è§‰ï¼ˆViTï¼‰å’Œæ–‡æœ¬ï¼ˆE5ï¼‰ç‰¹å¾ã€‚æ¨¡å‹é‡‡ç”¨Low-Rank Adaptation (LoRA)è¿›è¡Œé€‚é…ã€‚ä¸€ä¸ªç»è¿‡å¤§é‡è°ƒä¼˜çš„æ¢¯åº¦æå‡æ ‘é›†æˆæ¨¡å‹ä½œä¸ºåŸºçº¿ã€‚ä¸€ä¸ªå…³é”®è´¡çŒ®æ˜¯ä½¿ç”¨LLMç”Ÿæˆçš„ã€åŸºäºä¸“å®¶å¯¼å‡ºçš„è®°å¿†åº¦æ–¹é¢çš„ç†ç”±æç¤ºæ¥æŒ‡å¯¼èåˆæ¨¡å‹ã€‚ç»“æœè¡¨æ˜ï¼Œä¸åŸºçº¿ç›¸æ¯”ï¼ŒåŸºäºLLMçš„ç³»ç»Ÿåœ¨æœ€ç»ˆæµ‹è¯•é›†ä¸Šè¡¨ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§å’Œæ³›åŒ–æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å•†ä¸šå¹¿å‘Šè®°å¿†åº¦é¢„æµ‹é—®é¢˜ï¼Œå³é¢„æµ‹ä¸€æ®µå•†ä¸šå¹¿å‘Šè¢«è§‚ä¼—è®°ä½çš„å¯èƒ½æ€§ã€‚ç°æœ‰æ–¹æ³•å¯èƒ½ä¾èµ–äºæ‰‹å·¥è®¾è®¡çš„ç‰¹å¾æˆ–æµ…å±‚æ¨¡å‹ï¼Œéš¾ä»¥æ•æ‰å¹¿å‘Šå†…å®¹ä¸­çš„å¤æ‚è¯­ä¹‰ä¿¡æ¯ï¼Œå¯¼è‡´é²æ£’æ€§å’Œæ³›åŒ–æ€§è¾ƒå·®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¼ºå¤§çš„è¯­ä¹‰ç†è§£å’Œæ¨ç†èƒ½åŠ›ï¼Œå°†è§†è§‰å’Œæ–‡æœ¬ç‰¹å¾èåˆï¼Œå¹¶é€šè¿‡LLMç”Ÿæˆçš„ç†ç”±æç¤ºï¼ˆrationale promptsï¼‰æ¥å¼•å¯¼æ¨¡å‹å­¦ä¹ ã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨ä½¿æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å¹¿å‘Šå†…å®¹ä¸è®°å¿†åº¦ä¹‹é—´çš„å…³ç³»ï¼Œä»è€Œæé«˜é¢„æµ‹çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) ç‰¹å¾æå–ï¼šä½¿ç”¨é¢„è®­ç»ƒçš„ViTæ¨¡å‹æå–è§†è§‰ç‰¹å¾ï¼Œä½¿ç”¨E5æ¨¡å‹æå–æ–‡æœ¬ç‰¹å¾ã€‚2) å¤šæ¨¡æ€æŠ•å½±ï¼šå°†è§†è§‰å’Œæ–‡æœ¬ç‰¹å¾æŠ•å½±åˆ°åŒä¸€è¯­ä¹‰ç©ºé—´ã€‚3) LLMèåˆï¼šä½¿ç”¨Gemma-3 LLMä½œä¸ºéª¨å¹²ç½‘ç»œï¼Œèåˆå¤šæ¨¡æ€ç‰¹å¾ã€‚4) ç†ç”±æç¤ºï¼šä½¿ç”¨LLMç”ŸæˆåŸºäºä¸“å®¶çŸ¥è¯†çš„ç†ç”±æç¤ºï¼Œå¼•å¯¼æ¨¡å‹å­¦ä¹ ã€‚5) LoRAé€‚é…ï¼šä½¿ç”¨Low-Rank Adaptation (LoRA)å¯¹LLMè¿›è¡Œå¾®è°ƒï¼Œä»¥é€‚åº”ç‰¹å®šä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºä½¿ç”¨LLMç”Ÿæˆçš„ç†ç”±æç¤ºæ¥æŒ‡å¯¼å¤šæ¨¡æ€èåˆæ¨¡å‹ã€‚ä¸ä¼ ç»Ÿçš„ç‰¹å¾èåˆæ–¹æ³•ç›¸æ¯”ï¼Œè¿™ç§æ–¹æ³•èƒ½å¤Ÿåˆ©ç”¨LLMçš„çŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›ï¼Œä½¿æ¨¡å‹æ›´å¥½åœ°ç†è§£å¹¿å‘Šå†…å®¹ä¸è®°å¿†åº¦ä¹‹é—´çš„å…³ç³»ã€‚æ­¤å¤–ï¼Œä½¿ç”¨LoRAè¿›è¡Œå¾®è°ƒå¯ä»¥æœ‰æ•ˆåœ°é™ä½è®¡ç®—æˆæœ¬ï¼Œå¹¶é˜²æ­¢è¿‡æ‹Ÿåˆã€‚

**å…³é”®è®¾è®¡**ï¼šç†ç”±æç¤ºçš„è®¾è®¡æ˜¯å…³é”®ã€‚è®ºæ–‡åˆ©ç”¨ä¸“å®¶çŸ¥è¯†ï¼Œæ„å»ºäº†ä¸€ç³»åˆ—ä¸è®°å¿†åº¦ç›¸å…³çš„æç¤ºï¼Œä¾‹å¦‚â€œè¿™ä¸ªå¹¿å‘Šæ˜¯å¦ä½¿ç”¨äº†å¹½é»˜ï¼Ÿâ€ã€â€œè¿™ä¸ªå¹¿å‘Šæ˜¯å¦å…·æœ‰æƒ…æ„Ÿå†²å‡»åŠ›ï¼Ÿâ€ç­‰ã€‚è¿™äº›æç¤ºè¢«è¾“å…¥åˆ°LLMä¸­ï¼Œç”Ÿæˆç›¸åº”çš„ç†ç”±ï¼Œç„¶åä¸è§†è§‰å’Œæ–‡æœ¬ç‰¹å¾ä¸€èµ·è¾“å…¥åˆ°èåˆæ¨¡å‹ä¸­ã€‚LoRAçš„ç§©ï¼ˆrankï¼‰æ˜¯ä¸€ä¸ªé‡è¦çš„è¶…å‚æ•°ï¼Œéœ€è¦æ ¹æ®å…·ä½“ä»»åŠ¡è¿›è¡Œè°ƒæ•´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºLLMçš„å¤šæ¨¡æ€èåˆç³»ç»Ÿåœ¨å•†ä¸šå¹¿å‘Šè®°å¿†åº¦é¢„æµ‹ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¸ç»è¿‡å¤§é‡è°ƒä¼˜çš„æ¢¯åº¦æå‡æ ‘åŸºçº¿æ¨¡å‹ç›¸æ¯”ï¼Œè¯¥ç³»ç»Ÿåœ¨æœ€ç»ˆæµ‹è¯•é›†ä¸Šè¡¨ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§å’Œæ³›åŒ–æ€§èƒ½ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®ï¼ˆä¾‹å¦‚ï¼Œå‡†ç¡®ç‡ã€å¬å›ç‡ç­‰ï¼‰æœªçŸ¥ï¼Œä½†æ‘˜è¦å¼ºè°ƒäº†å…¶ä¼˜äºåŸºçº¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¹¿å‘Šæ•ˆæœè¯„ä¼°ã€å¹¿å‘Šå†…å®¹ä¼˜åŒ–ã€ä»¥åŠä¸ªæ€§åŒ–å¹¿å‘Šæ¨èç­‰é¢†åŸŸã€‚é€šè¿‡é¢„æµ‹å¹¿å‘Šçš„è®°å¿†åº¦ï¼Œå¯ä»¥å¸®åŠ©å¹¿å‘Šä¸»æ›´å¥½åœ°äº†è§£å¹¿å‘Šæ•ˆæœï¼Œä¼˜åŒ–å¹¿å‘Šå†…å®¹ï¼Œæé«˜å¹¿å‘ŠæŠ•æ”¾çš„æ•ˆç‡ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥ç”¨äºä¸ªæ€§åŒ–å¹¿å‘Šæ¨èï¼Œæ ¹æ®ç”¨æˆ·çš„å…´è¶£å’Œåå¥½ï¼Œæ¨èæ›´æ˜“äºè¢«è®°ä½çš„å¹¿å‘Šã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper addresses the prediction of commercial (brand) memorability as part of "Subtask 2: Commercial/Ad Memorability" within the "Memorability: Predicting movie and commercial memorability" task at the MediaEval 2025 workshop competition. We propose a multimodal fusion system with a Gemma-3 LLM backbone that integrates pre-computed visual (ViT) and textual (E5) features by multi-modal projections. The model is adapted using Low-Rank Adaptation (LoRA). A heavily-tuned ensemble of gradient boosted trees serves as a baseline. A key contribution is the use of LLM-generated rationale prompts, grounded in expert-derived aspects of memorability, to guide the fusion model. The results demonstrate that the LLM-based system exhibits greater robustness and generalization performance on the final test set, compared to the baseline.
>   The paper's codebase can be found at https://github.com/dsgt-arc/mediaeval-2025-memorability

