---
layout: default
title: "DeepfakeBench-MM: A Comprehensive Benchmark for Multimodal Deepfake Detection"
---

# DeepfakeBench-MM: A Comprehensive Benchmark for Multimodal Deepfake Detection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.22622" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.22622v1</a>
  <a href="https://arxiv.org/pdf/2510.22622.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.22622v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.22622v1', 'DeepfakeBench-MM: A Comprehensive Benchmark for Multimodal Deepfake Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kangran Zhao, Yupeng Chen, Xiaoyu Zhang, Yize Chen, Weinan Guan, Baicheng Chen, Chengzhe Sun, Soumyya Kanti Datta, Qingshan Liu, Siwei Lyu, Baoyuan Wu

**åˆ†ç±»**: cs.CR, cs.CV, cs.MM

**å‘å¸ƒæ—¥æœŸ**: 2025-10-26

**å¤‡æ³¨**: Preprint

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ„å»ºå¤šæ¨¡æ€æ·±åº¦ä¼ªé€ æ£€æµ‹åŸºå‡†ï¼Œåº”å¯¹ä¼ªé€ éŸ³è§†é¢‘å†…å®¹å¸¦æ¥çš„ç¤¾ä¼šé£é™©ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ·±åº¦ä¼ªé€ æ£€æµ‹` `å¤šæ¨¡æ€å­¦ä¹ ` `æ•°æ®é›†æ„å»º` `åŸºå‡†æµ‹è¯•` `éŸ³é¢‘ä¼ªé€ ` `è§†é¢‘ä¼ªé€ ` `äººå·¥æ™ºèƒ½å®‰å…¨` `å¯¹æŠ—æ ·æœ¬`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ·±åº¦ä¼ªé€ æ£€æµ‹ç¼ºä¹è¶³å¤Ÿå¤šæ ·çš„æ•°æ®é›†å’Œæ ‡å‡†åŒ–çš„è¯„ä¼°åŸºå‡†ï¼Œé˜»ç¢äº†æ›´æ·±å…¥çš„ç ”ç©¶ã€‚
2. æ„å»ºå¤§è§„æ¨¡å¤šæ¨¡æ€æ•°æ®é›†Mega-MMDFï¼Œå¹¶æå‡ºç»Ÿä¸€çš„è¯„ä¼°åŸºå‡†DeepfakeBench-MMï¼Œä¿ƒè¿›æ·±åº¦ä¼ªé€ æ£€æµ‹ç ”ç©¶ã€‚
3. é€šè¿‡ç»¼åˆè¯„ä¼°ï¼Œæ­ç¤ºäº†æ•°æ®å¢å¼ºå’Œå †å ä¼ªé€ ç­‰å› ç´ å¯¹æ£€æµ‹æ€§èƒ½çš„å½±å“ï¼Œä¸ºæœªæ¥ç ”ç©¶æä¾›æŒ‡å¯¼ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é’ˆå¯¹ç”Ÿæˆå¼AIæ¨¡å‹æ»¥ç”¨å¯¼è‡´çš„è™šå‡æ•°æ®æ³›æ»¥é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯ä¼ªé€ çš„äººç±»éŸ³è§†é¢‘å†…å®¹å¸¦æ¥çš„ç¤¾ä¼šé£é™©ï¼Œæœ¬æ–‡æ„å»ºäº†å¤§è§„æ¨¡ã€å¤šæ ·åŒ–ã€é«˜è´¨é‡çš„å¤šæ¨¡æ€æ·±åº¦ä¼ªé€ æ£€æµ‹æ•°æ®é›†Mega-MMDFã€‚è¯¥æ•°æ®é›†åŒ…å«0.1ç™¾ä¸‡çœŸå®æ ·æœ¬å’Œ1.1ç™¾ä¸‡ä¼ªé€ æ ·æœ¬ï¼Œé€šè¿‡ç»„åˆ10ç§éŸ³é¢‘ä¼ªé€ æ–¹æ³•ã€12ç§è§†è§‰ä¼ªé€ æ–¹æ³•å’Œ6ç§éŸ³é¢‘é©±åŠ¨çš„é¢éƒ¨é‡æ¼”æ–¹æ³•ï¼Œå…±è®¡21ç§ä¼ªé€ æµç¨‹ç”Ÿæˆã€‚åŒæ—¶ï¼Œæå‡ºäº†é¦–ä¸ªç»Ÿä¸€çš„å¤šæ¨¡æ€æ·±åº¦ä¼ªé€ æ£€æµ‹åŸºå‡†DeepfakeBench-MMï¼Œå»ºç«‹äº†æ ‡å‡†åŒ–çš„æ£€æµ‹æµç¨‹ï¼Œä¸ºè¯„ä¼°ç°æœ‰æ–¹æ³•å’Œæ¢ç´¢æ–°æ–¹æ³•æä¾›å¹³å°ã€‚é€šè¿‡å…¨é¢çš„è¯„ä¼°å’Œæ·±å…¥çš„åˆ†æï¼Œæ­ç¤ºäº†å¤šä¸ªå…³é”®å‘ç°ï¼Œä¾‹å¦‚æ•°æ®å¢å¼ºå’Œå †å ä¼ªé€ çš„å½±å“ã€‚DeepfakeBench-MMå’ŒMega-MMDFå°†ä¸ºæ¨è¿›å¤šæ¨¡æ€æ·±åº¦ä¼ªé€ æ£€æµ‹æä¾›åŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æ—¥ç›ŠçŒ–ç—çš„å¤šæ¨¡æ€æ·±åº¦ä¼ªé€ å†…å®¹æ£€æµ‹é—®é¢˜ã€‚ç°æœ‰çš„æ·±åº¦ä¼ªé€ æ£€æµ‹æ–¹æ³•å—é™äºæ•°æ®é›†è§„æ¨¡å’Œå¤šæ ·æ€§ä¸è¶³ï¼Œç¼ºä¹ç»Ÿä¸€çš„è¯„ä¼°æ ‡å‡†ï¼Œéš¾ä»¥æœ‰æ•ˆåº”å¯¹å¤æ‚åœºæ™¯ä¸‹çš„ä¼ªé€ å†…å®¹ï¼Œå¹¶ä¸”éš¾ä»¥è¿›è¡Œå…¬å¹³çš„æ€§èƒ½æ¯”è¾ƒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªå¤§è§„æ¨¡ã€å¤šæ ·åŒ–çš„å¤šæ¨¡æ€æ·±åº¦ä¼ªé€ æ•°æ®é›†Mega-MMDFï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šå»ºç«‹ä¸€ä¸ªç»Ÿä¸€çš„è¯„ä¼°åŸºå‡†DeepfakeBench-MMã€‚é€šè¿‡æä¾›å……è¶³çš„è®­ç»ƒæ•°æ®å’Œæ ‡å‡†åŒ–çš„è¯„ä¼°æµç¨‹ï¼Œä¿ƒè¿›å¤šæ¨¡æ€æ·±åº¦ä¼ªé€ æ£€æµ‹æŠ€æœ¯çš„å‘å±•ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDeepfakeBench-MMçš„æ•´ä½“æ¡†æ¶åŒ…å«æ•°æ®é›†æ„å»ºã€æ¨¡å‹è¯„ä¼°å’Œç»“æœåˆ†æä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚æ•°æ®é›†æ„å»ºé˜¶æ®µï¼Œé€šè¿‡ç»„åˆå¤šç§éŸ³é¢‘å’Œè§†é¢‘ä¼ªé€ æŠ€æœ¯ï¼Œç”Ÿæˆå¤§è§„æ¨¡çš„Mega-MMDFæ•°æ®é›†ã€‚æ¨¡å‹è¯„ä¼°é˜¶æ®µï¼Œåœ¨DeepfakeBench-MMä¸Šå¯¹ç°æœ‰å’Œæ–°çš„å¤šæ¨¡æ€æ·±åº¦ä¼ªé€ æ£€æµ‹æ¨¡å‹è¿›è¡Œè¯„ä¼°ã€‚ç»“æœåˆ†æé˜¶æ®µï¼Œå¯¹è¯„ä¼°ç»“æœè¿›è¡Œæ·±å…¥åˆ†æï¼Œæ­ç¤ºä¸åŒå› ç´ å¯¹æ£€æµ‹æ€§èƒ½çš„å½±å“ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæ„å»ºäº†å¤§è§„æ¨¡ã€å¤šæ ·åŒ–çš„å¤šæ¨¡æ€æ·±åº¦ä¼ªé€ æ•°æ®é›†Mega-MMDFï¼Œå¹¶æå‡ºäº†é¦–ä¸ªç»Ÿä¸€çš„å¤šæ¨¡æ€æ·±åº¦ä¼ªé€ æ£€æµ‹åŸºå‡†DeepfakeBench-MMã€‚Mega-MMDFæ•°æ®é›†çš„è§„æ¨¡å’Œå¤šæ ·æ€§è¿œè¶…ç°æœ‰æ•°æ®é›†ï¼ŒDeepfakeBench-MMåŸºå‡†çš„æ ‡å‡†åŒ–è¯„ä¼°æµç¨‹ä¸ºå…¬å¹³æ¯”è¾ƒä¸åŒæ–¹æ³•æä¾›äº†å¯èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šMega-MMDFæ•°æ®é›†é€šè¿‡ç»„åˆ10ç§éŸ³é¢‘ä¼ªé€ æ–¹æ³•ã€12ç§è§†è§‰ä¼ªé€ æ–¹æ³•å’Œ6ç§éŸ³é¢‘é©±åŠ¨çš„é¢éƒ¨é‡æ¼”æ–¹æ³•ï¼Œå…±è®¡21ç§ä¼ªé€ æµç¨‹ç”Ÿæˆã€‚DeepfakeBench-MMåŸºå‡†å®šä¹‰äº†æ ‡å‡†åŒ–çš„æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°æµç¨‹ï¼Œå¹¶æä¾›äº†å¤šç§è¯„ä¼°æŒ‡æ ‡ï¼Œä¾‹å¦‚å‡†ç¡®ç‡ã€ç²¾ç¡®ç‡ã€å¬å›ç‡å’ŒF1å€¼ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡æ„å»ºçš„Mega-MMDFæ•°æ®é›†åŒ…å«1.1ç™¾ä¸‡ä¼ªé€ æ ·æœ¬ï¼Œè§„æ¨¡è¿œè¶…ç°æœ‰æ•°æ®é›†ã€‚DeepfakeBench-MMåŸºå‡†æ”¯æŒ11ç§å¤šæ¨¡æ€æ·±åº¦ä¼ªé€ æ£€æµ‹å™¨ï¼Œå¹¶è¿›è¡Œäº†å…¨é¢çš„è¯„ä¼°å’Œåˆ†æï¼Œæ­ç¤ºäº†æ•°æ®å¢å¼ºå’Œå †å ä¼ªé€ ç­‰å› ç´ å¯¹æ£€æµ‹æ€§èƒ½çš„å½±å“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç°æœ‰æ–¹æ³•åœ¨Mega-MMDFæ•°æ®é›†ä¸Šçš„æ€§èƒ½ä»æœ‰æå‡ç©ºé—´ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºé‡‘èå®‰å…¨ã€ç¤¾ä¼šèˆ†æƒ…ç›‘æ§ã€æ–°é—»çœŸå®æ€§éªŒè¯ç­‰é¢†åŸŸï¼Œæœ‰æ•ˆé˜²èŒƒæ·±åº¦ä¼ªé€ æŠ€æœ¯å¸¦æ¥çš„æ¬ºè¯ˆã€è¯½è°¤ç­‰é£é™©ï¼Œç»´æŠ¤ç¤¾ä¼šç¨³å®šå’Œä¿¡æ¯å®‰å…¨ã€‚æœªæ¥å¯è¿›ä¸€æ­¥æ‰©å±•åˆ°æ›´å¤šæ¨¡æ€æ•°æ®ï¼Œæå‡æ£€æµ‹æ¨¡å‹çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The misuse of advanced generative AI models has resulted in the widespread proliferation of falsified data, particularly forged human-centric audiovisual content, which poses substantial societal risks (e.g., financial fraud and social instability). In response to this growing threat, several works have preliminarily explored countermeasures. However, the lack of sufficient and diverse training data, along with the absence of a standardized benchmark, hinder deeper exploration. To address this challenge, we first build Mega-MMDF, a large-scale, diverse, and high-quality dataset for multimodal deepfake detection. Specifically, we employ 21 forgery pipelines through the combination of 10 audio forgery methods, 12 visual forgery methods, and 6 audio-driven face reenactment methods. Mega-MMDF currently contains 0.1 million real samples and 1.1 million forged samples, making it one of the largest and most diverse multimodal deepfake datasets, with plans for continuous expansion. Building on it, we present DeepfakeBench-MM, the first unified benchmark for multimodal deepfake detection. It establishes standardized protocols across the entire detection pipeline and serves as a versatile platform for evaluating existing methods as well as exploring novel approaches. DeepfakeBench-MM currently supports 5 datasets and 11 multimodal deepfake detectors. Furthermore, our comprehensive evaluations and in-depth analyses uncover several key findings from multiple perspectives (e.g., augmentation, stacked forgery). We believe that DeepfakeBench-MM, together with our large-scale Mega-MMDF, will serve as foundational infrastructures for advancing multimodal deepfake detection.

