---
layout: default
title: GateFuseNet: An Adaptive 3D Multimodal Neuroimaging Fusion Network for Parkinson's Disease Diagnosis
---

# GateFuseNet: An Adaptive 3D Multimodal Neuroimaging Fusion Network for Parkinson's Disease Diagnosis

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.22507" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.22507v1</a>
  <a href="https://arxiv.org/pdf/2510.22507.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.22507v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.22507v1', 'GateFuseNet: An Adaptive 3D Multimodal Neuroimaging Fusion Network for Parkinson\'s Disease Diagnosis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Rui Jin, Chen Chen, Yin Liu, Hongfu Sun, Min Zeng, Min Li, Yang Gao

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-10-26

**å¤‡æ³¨**: The first two authors contributed equally to this work. Correspondence to: Yang Gao, E-mail: yang.gao@csu.edu.cn

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/YangGaoUQ/GateFuseNet)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**GateFuseNetï¼šä¸€ç§è‡ªé€‚åº”3Då¤šæ¨¡æ€ç¥ç»å½±åƒèåˆç½‘ç»œï¼Œç”¨äºå¸•é‡‘æ£®ç—…è¯Šæ–­**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¸•é‡‘æ£®ç—…è¯Šæ–­` `å¤šæ¨¡æ€èåˆ` `ç¥ç»å½±åƒ` `æ·±åº¦å­¦ä¹ ` `æ³¨æ„åŠ›æœºåˆ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¸•é‡‘æ£®ç—…MRIè¯Šæ–­é¢ä¸´ç—‡çŠ¶å¤šæ ·æ€§å’Œç—…ç†å¼‚è´¨æ€§çš„æŒ‘æˆ˜ï¼Œä¼ ç»ŸT1wå›¾åƒæ•æ„Ÿæ€§ä¸è¶³ã€‚
2. GateFuseNeté€šè¿‡é—¨æ§èåˆæ¨¡å—ï¼Œè‡ªé€‚åº”åœ°èåˆQSMå’ŒT1wå›¾åƒï¼Œå¢å¼ºROIç‰¹å¾å¹¶æŠ‘åˆ¶å™ªå£°ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒGateFuseNetåœ¨å¸•é‡‘æ£®ç—…è¯Šæ–­ä¸­ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå‡†ç¡®ç‡è¾¾85.00%ï¼ŒAUCè¾¾92.06%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç”±äºç—‡çŠ¶å˜å¼‚æ€§å’Œç—…ç†å¼‚è´¨æ€§ï¼Œé€šè¿‡MRIå‡†ç¡®è¯Šæ–­å¸•é‡‘æ£®ç—…(PD)ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ç°æœ‰æ–¹æ³•å¤§å¤šä¾èµ–äºä¼ ç»Ÿçš„åŸºäºå¹…åº¦çš„MRIæ¨¡æ€ï¼Œå¦‚T1åŠ æƒå›¾åƒ(T1w)ï¼Œä½†å…¶å¯¹PDç—…ç†çš„æ•æ„Ÿæ€§ä½äºå®šé‡ç£åŒ–ç‡æ˜ å°„(QSM)ã€‚QSMæ˜¯ä¸€ç§åŸºäºç›¸ä½çš„MRIæŠ€æœ¯ï¼Œå¯é‡åŒ–æ·±éƒ¨ç°è´¨æ ¸å›¢ä¸­çš„é“æ²‰ç§¯ã€‚æœ¬ç ”ç©¶æå‡ºGateFuseNetï¼Œä¸€ç§è‡ªé€‚åº”3Då¤šæ¨¡æ€èåˆç½‘ç»œï¼Œé›†æˆäº†QSMå’ŒT1wå›¾åƒç”¨äºPDè¯Šæ–­ã€‚æ ¸å¿ƒåˆ›æ–°åœ¨äºé—¨æ§èåˆæ¨¡å—ï¼Œè¯¥æ¨¡å—å­¦ä¹ æ¨¡æ€ç‰¹å®šçš„æ³¨æ„åŠ›æƒé‡å’Œé€šé“æ–¹å‘çš„é—¨æ§å‘é‡ï¼Œä»¥è¿›è¡Œé€‰æ‹©æ€§çš„ç‰¹å¾è°ƒåˆ¶ã€‚è¿™ç§åˆ†å±‚é—¨æ§æœºåˆ¶å¢å¼ºäº†ROIæ„ŸçŸ¥çš„ç‰¹å¾ï¼ŒåŒæ—¶æŠ‘åˆ¶äº†ä¸ç›¸å…³çš„ä¿¡å·ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºä¸‰ç§ç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ï¼Œå®ç°äº†85.00%çš„å‡†ç¡®ç‡å’Œ92.06%çš„AUCã€‚æ¶ˆèç ”ç©¶è¿›ä¸€æ­¥éªŒè¯äº†ROIå¼•å¯¼ã€å¤šæ¨¡æ€é›†æˆå’Œèåˆå®šä½çš„è´¡çŒ®ã€‚Grad-CAMå¯è§†åŒ–è¯å®äº†è¯¥æ¨¡å‹å¯¹ä¸´åºŠç›¸å…³ç—…ç†åŒºåŸŸçš„å…³æ³¨ã€‚æºä»£ç å’Œé¢„è®­ç»ƒæ¨¡å‹å¯åœ¨https://github.com/YangGaoUQ/GateFuseNetæ‰¾åˆ°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¸•é‡‘æ£®ç—…ï¼ˆPDï¼‰è¯Šæ–­ä¸­ï¼Œä¼ ç»ŸMRIæ–¹æ³•ï¼ˆå¦‚T1wï¼‰å¯¹ç—…ç†æ•æ„Ÿæ€§ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆåˆ©ç”¨å¤šæ¨¡æ€MRIä¿¡æ¯ï¼Œä¸”æ˜“å—ç—‡çŠ¶å˜å¼‚æ€§å’Œç—…ç†å¼‚è´¨æ€§çš„å½±å“ï¼Œå¯¼è‡´è¯Šæ–­å‡†ç¡®ç‡ä¸é«˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯è®¾è®¡ä¸€ä¸ªè‡ªé€‚åº”çš„å¤šæ¨¡æ€èåˆç½‘ç»œï¼Œåˆ©ç”¨QSMå›¾åƒå¯¹é“æ²‰ç§¯çš„æ•æ„Ÿæ€§ï¼Œå¹¶ç»“åˆT1wå›¾åƒçš„ç»“æ„ä¿¡æ¯ï¼Œé€šè¿‡é—¨æ§æœºåˆ¶é€‰æ‹©æ€§åœ°èåˆä¸åŒæ¨¡æ€çš„ç‰¹å¾ï¼Œä»è€Œæé«˜PDè¯Šæ–­çš„å‡†ç¡®æ€§ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨å¢å¼ºä¸PDç›¸å…³çš„ROIåŒºåŸŸçš„ç‰¹å¾ï¼ŒåŒæ—¶æŠ‘åˆ¶ä¸ç›¸å…³çš„å™ªå£°ä¿¡å·ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šGateFuseNetçš„æ•´ä½“æ¶æ„åŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) ç‰¹å¾æå–æ¨¡å—ï¼šåˆ†åˆ«ä»QSMå’ŒT1wå›¾åƒä¸­æå–ç‰¹å¾ã€‚2) é—¨æ§èåˆæ¨¡å—ï¼šå­¦ä¹ æ¨¡æ€ç‰¹å®šçš„æ³¨æ„åŠ›æƒé‡å’Œé€šé“æ–¹å‘çš„é—¨æ§å‘é‡ï¼Œç”¨äºé€‰æ‹©æ€§åœ°èåˆä¸åŒæ¨¡æ€çš„ç‰¹å¾ã€‚3) åˆ†ç±»æ¨¡å—ï¼šåŸºäºèåˆåçš„ç‰¹å¾è¿›è¡ŒPDè¯Šæ–­ã€‚è¯¥ç½‘ç»œé‡‡ç”¨3Då·ç§¯ç¥ç»ç½‘ç»œç»“æ„ï¼Œä»¥å……åˆ†åˆ©ç”¨MRIå›¾åƒçš„ä¸‰ç»´ç©ºé—´ä¿¡æ¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºé—¨æ§èåˆæ¨¡å—ã€‚è¯¥æ¨¡å—é€šè¿‡å­¦ä¹ æ¨¡æ€ç‰¹å®šçš„æ³¨æ„åŠ›æƒé‡ï¼Œè‡ªé€‚åº”åœ°è°ƒæ•´ä¸åŒæ¨¡æ€ç‰¹å¾çš„è´¡çŒ®ï¼Œä»è€Œå®ç°æ›´æœ‰æ•ˆçš„å¤šæ¨¡æ€èåˆã€‚æ­¤å¤–ï¼Œé€šé“æ–¹å‘çš„é—¨æ§å‘é‡å¯ä»¥è¿›ä¸€æ­¥é€‰æ‹©é‡è¦çš„ç‰¹å¾é€šé“ï¼ŒæŠ‘åˆ¶å™ªå£°ã€‚è¿™ç§åˆ†å±‚é—¨æ§æœºåˆ¶æ˜¯ä¸ç°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šé—¨æ§èåˆæ¨¡å—çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶å­¦ä¹ æ¨¡æ€æƒé‡ï¼Œæƒé‡å€¼ä»‹äº0å’Œ1ä¹‹é—´ï¼Œè¡¨ç¤ºæ¯ä¸ªæ¨¡æ€çš„é‡è¦æ€§ã€‚2) ä½¿ç”¨sigmoidå‡½æ•°ç”Ÿæˆé€šé“æ–¹å‘çš„é—¨æ§å‘é‡ï¼Œæ§åˆ¶æ¯ä¸ªé€šé“çš„ç‰¹å¾æ˜¯å¦è¢«æ¿€æ´»ã€‚3) æŸå¤±å‡½æ•°åŒ…æ‹¬äº¤å‰ç†µæŸå¤±ï¼Œç”¨äºä¼˜åŒ–åˆ†ç±»æ€§èƒ½ã€‚ç½‘ç»œç»“æ„é‡‡ç”¨3Då·ç§¯ï¼Œå¹¶ä½¿ç”¨äº†ReLUæ¿€æ´»å‡½æ•°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

GateFuseNetåœ¨å¸•é‡‘æ£®ç—…è¯Šæ–­ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œç›¸è¾ƒäºä¸‰ç§æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå‡†ç¡®ç‡æé«˜äº†85.00%ï¼ŒAUCè¾¾åˆ°äº†92.06%ã€‚æ¶ˆèå®éªŒéªŒè¯äº†ROIå¼•å¯¼ã€å¤šæ¨¡æ€é›†æˆå’Œèåˆå®šä½çš„æœ‰æ•ˆæ€§ã€‚Grad-CAMå¯è§†åŒ–ç»“æœè¡¨æ˜ï¼Œæ¨¡å‹èƒ½å¤Ÿå…³æ³¨åˆ°ä¸´åºŠç›¸å…³çš„ç—…ç†åŒºåŸŸï¼Œä¾‹å¦‚é»‘è´¨ç­‰ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¸•é‡‘æ£®ç—…çš„æ—©æœŸè¯Šæ–­å’Œè¾…åŠ©è¯Šæ–­ï¼Œå¸®åŠ©åŒ»ç”Ÿæ›´å‡†ç¡®åœ°è¯†åˆ«æ‚£è€…ã€‚é€šè¿‡ç»“åˆQSMå’ŒT1wç­‰å¤šæ¨¡æ€MRIä¿¡æ¯ï¼Œæœ‰æœ›æé«˜è¯Šæ–­çš„æ•æ„Ÿæ€§å’Œç‰¹å¼‚æ€§ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ‰©å±•åˆ°å…¶ä»–ç¥ç»é€€è¡Œæ€§ç–¾ç—…çš„è¯Šæ–­ï¼Œå¹¶ä¸ºä¸ªæ€§åŒ–æ²»ç–—æ–¹æ¡ˆçš„åˆ¶å®šæä¾›ä¾æ®ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Accurate diagnosis of Parkinson's disease (PD) from MRI remains challenging due to symptom variability and pathological heterogeneity. Most existing methods rely on conventional magnitude-based MRI modalities, such as T1-weighted images (T1w), which are less sensitive to PD pathology than Quantitative Susceptibility Mapping (QSM), a phase-based MRI technique that quantifies iron deposition in deep gray matter nuclei. In this study, we propose GateFuseNet, an adaptive 3D multimodal fusion network that integrates QSM and T1w images for PD diagnosis. The core innovation lies in a gated fusion module that learns modality-specific attention weights and channel-wise gating vectors for selective feature modulation. This hierarchical gating mechanism enhances ROI-aware features while suppressing irrelevant signals. Experimental results show that our method outperforms three existing state-of-the-art approaches, achieving 85.00% accuracy and 92.06% AUC. Ablation studies further validate the contributions of ROI guidance, multimodal integration, and fusion positioning. Grad-CAM visualizations confirm the model's focus on clinically relevant pathological regions. The source codes and pretrained models can be found at https://github.com/YangGaoUQ/GateFuseNet

