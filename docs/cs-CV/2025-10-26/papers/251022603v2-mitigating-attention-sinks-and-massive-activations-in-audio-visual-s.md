---
layout: default
title: Mitigating Attention Sinks and Massive Activations in Audio-Visual Speech Recognition with LLMs
---

# Mitigating Attention Sinks and Massive Activations in Audio-Visual Speech Recognition with LLMs

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.22603" target="_blank" class="toolbar-btn">arXiv: 2510.22603v2</a>
    <a href="https://arxiv.org/pdf/2510.22603.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.22603v2" 
            onclick="toggleFavorite(this, '2510.22603v2', 'Mitigating Attention Sinks and Massive Activations in Audio-Visual Speech Recognition with LLMs')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Anand, Umberto Cappellazzo, Stavros Petridis, Maja Pantic

**ÂàÜÁ±ª**: eess.AS, cs.CV, cs.SD

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-26 (Êõ¥Êñ∞: 2025-11-02)

**Â§áÊ≥®**: The code is available at https://github.com/umbertocappellazzo/Llama-AVSR

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÈíàÂØπAVSR‰∏≠LLMÁöÑAttention SinkÈóÆÈ¢òÔºåÊèêÂá∫Ëß£ËÄ¶ÊçüÂ§±‰ª•ÊèêÂçáËØÜÂà´Á≤æÂ∫¶**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËßÜÂê¨ËØ≠Èü≥ËØÜÂà´` `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `Ê≥®ÊÑèÂäõÊú∫Âà∂` `Attention Sink` `Ëß£ËÄ¶ÊçüÂ§±`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂü∫‰∫éLLMÁöÑAVSRÊñπÊ≥ïÁº∫‰πèÂØπÊ®°ÂûãÂÜÖÈÉ®Âä®ÊÄÅÁöÑÊ∑±ÂÖ•ÁêÜËß£ÔºåÂ≠òÂú®Attention SinkÂíåMassive ActivationÈóÆÈ¢ò„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫‰∏ÄÁßçËß£ËÄ¶ÊçüÂ§±ÔºåÊó®Âú®Èôç‰ΩéBOS token‰∏éÂÖ∂‰ªñtokenÁöÑ‰ΩôÂº¶Áõ∏‰ººÂ∫¶Ôºå‰ªéËÄåÁºìËß£‰∏≠Èó¥sinkÂíåÂ∑®Â§ßÊøÄÊ¥ª„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®È´òÁâπÂæÅ‰∏ãÈááÊ†∑Áéá‰∏ãËÉΩÊúâÊïàÊèêÂçáWERÔºåÂπ∂Âú®‰ΩéÈááÊ†∑Áéá‰∏ã‰øùÊåÅÊÄßËÉΩÁ®≥ÂÆö„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÊúÄËøëÂú®Âê¨ËßâËØ≠Èü≥ËØÜÂà´ÔºàASRÔºâ„ÄÅËßÜËßâËØ≠Èü≥ËØÜÂà´ÔºàVSRÔºâÂíåËßÜÂê¨ËØ≠Èü≥ËØÜÂà´ÔºàAVSRÔºâÊñπÈù¢ÂèñÂæó‰∫ÜËøõÂ±ï„ÄÇÁÑ∂ËÄåÔºåÂØπÂÖ∂ÂæÆË∞É‰∏ãÁöÑÂÜÖÈÉ®Âä®ÊÄÅÁöÑÁêÜËß£‰ªçÁÑ∂ÊúâÈôê„ÄÇÂú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ‰∏≠ÔºåÊúÄËøëÁöÑÁ†îÁ©∂Êè≠Á§∫‰∫ÜÊ≥®ÊÑèÂäõÊ±áËÅöÔºàattention sinksÔºâÔºåÂç≥Âê∏Âºï‰∏çÊàêÊØî‰æãÁöÑÈ´òÊ≥®ÊÑèÂäõÁöÑtokenÔºå‰ª•ÂèäÁõ∏ÂÖ≥ÁöÑÂ∑®Â§ßÊøÄÊ¥ªÔºàmassive activationsÔºâÔºåÂÖ∂‰∏≠sink tokenÁöÑÊüê‰∫õÁâπÂæÅÂú®LLM‰∏≠Ë°®Áé∞Âá∫Â∑®Â§ßÁöÑÊøÄÊ¥ª„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨È¶ñÊ¨°Á†îÁ©∂‰∫ÜÂ§öÊ®°ÊÄÅËØ≠Èü≥ËØÜÂà´‰∏≠ÁöÑËøô‰∫õÁé∞Ë±°„ÄÇÈÄöËøáÂØπËßÜÂê¨LLMÁöÑËØ¶ÁªÜÂàÜÊûêÔºåÊàë‰ª¨‰∏ç‰ªÖÂú®BOS tokenÂ§ÑÔºåËÄå‰∏îÂú®ASR„ÄÅVSRÂíåAVSRÁöÑ‰∏≠Èó¥‰ΩéËØ≠‰πâtokenÂ§ÑËØÜÂà´Âá∫Ê≥®ÊÑèÂäõÊ±áËÅöÂíåÂ∑®Â§ßÊøÄÊ¥ª„ÄÇÊàë‰ª¨Ë°®ÊòéÔºåÂ∑®Â§ßÊøÄÊ¥ªÊ∫ê‰∫éMLPÂ±ÇÔºåÂπ∂‰∏îÂØπÂ∫î‰∫éÊâÄÊúâsink token‰∏≠ÁöÑÂõ∫ÂÆöÁâπÂæÅÁ¥¢Âºï„ÄÇÊàë‰ª¨Ëøõ‰∏ÄÊ≠•Ë°®ÊòéÔºå‰∏≠Èó¥sink token‰∏éBOS tokenË°®Áé∞Âá∫È´òÁöÑ‰ΩôÂº¶Áõ∏‰ººÂ∫¶Ôºå‰ªéËÄåÊîæÂ§ß‰∫ÜÊ≥®ÊÑèÂäõÂíåÊøÄÊ¥ª„ÄÇÂü∫‰∫éËøô‰∫õËßÅËß£ÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏ÄÁßçÁÆÄÂçïÁöÑËß£ËÄ¶ÊçüÂ§±ÔºåËØ•ÊçüÂ§±Èôç‰Ωé‰∫ÜBOSÂíåÂÖ∂‰ªñtoken‰πãÈó¥ÁöÑ‰ΩôÂº¶Áõ∏‰ººÂ∫¶Ôºå‰ªéËÄåÊúâÊïàÂú∞ÂáèËΩª‰∫Ü‰∏≠Èó¥sinkÂíåÂ∑®Â§ßÊøÄÊ¥ª„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®È´òÁöÑËßÜÂê¨ÁâπÂæÅ‰∏ãÈááÊ†∑‰∏ãÊèêÈ´ò‰∫ÜËØçÈîôËØØÁéáÔºàWERÔºâÔºåÂêåÊó∂Âú®ËæÉ‰ΩéÁöÑ‰∏ãÈááÊ†∑Áéá‰∏ã‰øùÊåÅÁ®≥ÂÆö„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Âü∫‰∫éLLMÁöÑAVSRÊ®°Âûã‰∏≠Â≠òÂú®ÁöÑAttention SinkÂíåMassive ActivationÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®ÂæÆË∞ÉLLMÊó∂ÔºåÂØπÊ®°ÂûãÂÜÖÈÉ®Âä®ÊÄÅÁêÜËß£‰∏çË∂≥ÔºåÂØºËá¥Êüê‰∫õtokenÔºàÂ∞§ÂÖ∂ÊòØBOS tokenÂíå‰∏≠Èó¥‰ΩéËØ≠‰πâtokenÔºâÂê∏Âºï‰∫ÜËøáÂ§öÁöÑÊ≥®ÊÑèÂäõÔºåËøõËÄåÂºïÂèë‰∫ÜÂ∑®Â§ßÁöÑÊøÄÊ¥ªÔºåÂΩ±Âìç‰∫ÜÊ®°ÂûãÁöÑÊÄßËÉΩ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈôç‰ΩéBOS token‰∏éÂÖ∂‰ªñtoken‰πãÈó¥ÁöÑ‰ΩôÂº¶Áõ∏‰ººÂ∫¶Ôºå‰ªéËÄåÂáèÂ∞ëAttention SinkÊïàÂ∫î„ÄÇ‰ΩúËÄÖËßÇÂØüÂà∞Ôºå‰∏≠Èó¥sink token‰∏éBOS tokenÂÖ∑ÊúâÂæàÈ´òÁöÑ‰ΩôÂº¶Áõ∏‰ººÂ∫¶ÔºåËøô‰ºöÊîæÂ§ßÊ≥®ÊÑèÂäõÂíåÊøÄÊ¥ª„ÄÇÈÄöËøáÈôç‰ΩéËøôÁßçÁõ∏‰ººÊÄßÔºåÂèØ‰ª•ÊúâÊïàÂú∞ÁºìËß£‰∏≠Èó¥sinkÂíåÂ∑®Â§ßÊøÄÊ¥ª„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËÆ∫Êñá‰∏ªË¶ÅÁ†îÁ©∂‰∫ÜÂü∫‰∫éLLMÁöÑAVSRÊ®°ÂûãÔºåÂπ∂ÈíàÂØπAttention SinkÈóÆÈ¢òÊèêÂá∫‰∫ÜÊîπËøõÊñπÊ°à„ÄÇÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨Ôºö1Ôºâ‰ΩøÁî®LLM‰Ωú‰∏∫AVSRÊ®°ÂûãÁöÑ‰∏ªÂπ≤ÁΩëÁªúÔºõ2ÔºâÂàÜÊûêÊ®°Âûã‰∏≠Attention SinkÂíåMassive ActivationÁöÑÁé∞Ë±°Ôºõ3ÔºâÊèêÂá∫Ëß£ËÄ¶ÊçüÂ§±ÂáΩÊï∞ÔºåÁî®‰∫éÈôç‰ΩéBOS token‰∏éÂÖ∂‰ªñtokenÁöÑ‰ΩôÂº¶Áõ∏‰ººÂ∫¶Ôºõ4ÔºâÂú®AVSR‰ªªÂä°‰∏äËøõË°åÂÆûÈ™åÔºåËØÑ‰º∞ÊâÄÊèêÂá∫ÊñπÊ≥ïÁöÑÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1ÔºâÈ¶ñÊ¨°Âú®Â§öÊ®°ÊÄÅËØ≠Èü≥ËØÜÂà´È¢ÜÂüüÁ†îÁ©∂‰∫ÜAttention SinkÂíåMassive ActivationÁé∞Ë±°Ôºõ2ÔºâÊèêÂá∫‰∫Ü‰∏ÄÁßçÁÆÄÂçïÊúâÊïàÁöÑËß£ËÄ¶ÊçüÂ§±ÂáΩÊï∞ÔºåÁî®‰∫éÁºìËß£Attention SinkÈóÆÈ¢ò„ÄÇËØ•ÊçüÂ§±ÂáΩÊï∞Áõ¥Êé•‰ΩúÁî®‰∫étoken embeddingÁ©∫Èó¥ÔºåÈôç‰Ωé‰∫ÜBOS token‰∏éÂÖ∂‰ªñtokenÁöÑ‰ΩôÂº¶Áõ∏‰ººÂ∫¶Ôºå‰ªéËÄåÂáèÂ∞ë‰∫Ü‰∏çÂøÖË¶ÅÁöÑÊ≥®ÊÑèÂäõÈõÜ‰∏≠„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆËÆæËÆ°Âú®‰∫éËß£ËÄ¶ÊçüÂ§±ÂáΩÊï∞„ÄÇËØ•ÊçüÂ§±ÂáΩÊï∞ÁöÑÁõÆÊ†áÊòØÊúÄÂ∞èÂåñBOS token‰∏éÂÖ∂‰ªñtoken‰πãÈó¥ÁöÑ‰ΩôÂº¶Áõ∏‰ººÂ∫¶„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÂØπ‰∫éÊØè‰∏™token embeddingÔºåËÆ°ÁÆóÂÖ∂‰∏éBOS token embeddingÁöÑ‰ΩôÂº¶Áõ∏‰ººÂ∫¶ÔºåÂπ∂Â∞ÜËøô‰∫õÁõ∏‰ººÂ∫¶‰Ωú‰∏∫ÊçüÂ§±È°πËøõË°å‰ºòÂåñ„ÄÇÊçüÂ§±ÂáΩÊï∞ÁöÑÂÖ∑‰ΩìÂΩ¢ÂºèÊú™Áü•Ôºå‰ΩÜÂÖ∂Ê†∏ÂøÉÊÄùÊÉ≥ÊòØÈôç‰Ωétoken embeddingÁ©∫Èó¥‰∏≠BOS token‰∏éÂÖ∂‰ªñtokenÁöÑÁõ∏‰ººÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊâÄÊèêÂá∫ÁöÑËß£ËÄ¶ÊçüÂ§±Âú®È´òËßÜÂê¨ÁâπÂæÅ‰∏ãÈááÊ†∑Áéá‰∏ãËÉΩÂ§üÊòæËëóÊèêÈ´òAVSRÊ®°ÂûãÁöÑËØçÈîôËØØÁéáÔºàWERÔºâÔºåÂêåÊó∂Âú®ËæÉ‰ΩéÁöÑ‰∏ãÈááÊ†∑Áéá‰∏ã‰øùÊåÅÊÄßËÉΩÁ®≥ÂÆö„ÄÇËøôË°®ÊòéËØ•ÊñπÊ≥ïËÉΩÂ§üÊúâÊïàÂú∞ÁºìËß£Attention SinkÈóÆÈ¢òÔºåÂπ∂ÊèêÈ´òÊ®°ÂûãÂú®‰∏çÂêåÊù°‰ª∂‰∏ãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇÂÖ∑‰ΩìÁöÑWERÊèêÂçáÂπÖÂ∫¶Êú™Áü•„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂêÑÁßçËßÜÂê¨ËØ≠Èü≥ËØÜÂà´Á≥ªÁªüÔºåÂ∞§ÂÖ∂ÊòØÂú®ËµÑÊ∫êÂèóÈôêÊàñÂô™Â£∞ÁéØÂ¢É‰∏ã„ÄÇÈÄöËøáÁºìËß£Attention SinkÈóÆÈ¢òÔºåÂèØ‰ª•ÊèêÈ´òAVSRÊ®°ÂûãÁöÑÈ≤ÅÊ£íÊÄßÂíåÂáÜÁ°ÆÊÄßÔºå‰ªéËÄåÊîπÂñÑËØ≠Èü≥Âä©Êâã„ÄÅËßÜÈ¢ë‰ºöËÆÆ„ÄÅÂ≠óÂπïÁîüÊàêÁ≠âÂ∫îÁî®ÁöÑÁî®Êà∑‰ΩìÈ™å„ÄÇÊ≠§Â§ñÔºåËØ•Á†îÁ©∂ÂØπ‰∫éÁêÜËß£Âíå‰ºòÂåñÂ§öÊ®°ÊÄÅLLMÂÖ∑ÊúâÈáçË¶ÅÁöÑÁêÜËÆ∫‰ª∑ÂÄº„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Large language models (LLMs) have recently advanced auditory speech recognition (ASR), visual speech recognition (VSR), and audio-visual speech recognition (AVSR). However, understanding of their internal dynamics under fine-tuning remains limited. In natural language processing, recent work has revealed attention sinks, tokens that attract disproportionately high attention, and associated massive activations in which some features of sink tokens exhibit huge activation in LLMs. In this work, we are the first to study these phenomena in multimodal speech recognition. Through a detailed analysis of audio-visual LLMs, we identify attention sinks and massive activations not only at the BOS token but also at intermediate low-semantic tokens across ASR, VSR, and AVSR. We show that massive activations originate in the MLP layers and correspond to fixed feature indices across all sink tokens. We further show that intermediate sink tokens exhibit high cosine similarity to the BOS token, thereby amplifying attention and activation. Building on these insights, we introduce a simple decorrelation loss that reduces cosine similarity between BOS and other tokens, effectively mitigating intermediate sinks and massive activations. Furthermore, our method improves word error rate (WER) under high audio-visual feature downsampling while remaining stable at lower downsampling rates.

