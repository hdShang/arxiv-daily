---
layout: default
title: MetaFind: Scene-Aware 3D Asset Retrieval for Coherent Metaverse Scene Generation
---

# MetaFind: Scene-Aware 3D Asset Retrieval for Coherent Metaverse Scene Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.04057" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.04057v1</a>
  <a href="https://arxiv.org/pdf/2510.04057.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.04057v1" onclick="toggleFavorite(this, '2510.04057v1', 'MetaFind: Scene-Aware 3D Asset Retrieval for Coherent Metaverse Scene Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhenyu Pan, Yucheng Lu, Han Liu

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-10-05

**å¤‡æ³¨**: The Thirty-Ninth Annual Conference on Neural Information Processing Systems (NeurIPS 2025)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**MetaFindï¼šæå‡ºåœºæ™¯æ„ŸçŸ¥çš„3Dèµ„äº§æ£€ç´¢æ¡†æ¶ï¼Œç”¨äºç”Ÿæˆä¸€è‡´çš„å…ƒå®‡å®™åœºæ™¯**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)**

**å…³é”®è¯**: `å…ƒå®‡å®™` `3Dèµ„äº§æ£€ç´¢` `åœºæ™¯ç”Ÿæˆ` `å¤šæ¨¡æ€å­¦ä¹ ` `å›¾ç¥ç»ç½‘ç»œ` `ç­‰å˜ç½‘ç»œ` `ç©ºé—´æ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰3Dèµ„äº§æ£€ç´¢æ–¹æ³•ç¼ºä¹å¯¹ç©ºé—´ã€è¯­ä¹‰å’Œé£æ ¼ä¸€è‡´æ€§çš„æœ‰æ•ˆå»ºæ¨¡ï¼Œå¯¼è‡´æ£€ç´¢ç»“æœä¸åœºæ™¯ä¸åè°ƒã€‚
2. MetaFindæå‡ºä¸€ç§çµæ´»çš„å¤šæ¨¡æ€æ£€ç´¢æ¡†æ¶ï¼Œé€šè¿‡è”åˆå»ºæ¨¡å¯¹è±¡çº§ç‰¹å¾å’Œåœºæ™¯çº§å¸ƒå±€ç»“æ„ï¼Œå®ç°åœºæ™¯æ„ŸçŸ¥çš„3Dèµ„äº§æ£€ç´¢ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒMetaFindåœ¨ç©ºé—´å’Œé£æ ¼ä¸€è‡´æ€§æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œèƒ½å¤Ÿç”Ÿæˆæ›´åè°ƒçš„å…ƒå®‡å®™åœºæ™¯ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

MetaFindæ˜¯ä¸€ä¸ªåœºæ™¯æ„ŸçŸ¥çš„å¤šæ¨¡æ€ç»„åˆæ£€ç´¢æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡ä»å¤§è§„æ¨¡çŸ¥è¯†åº“ä¸­æ£€ç´¢3Dèµ„äº§æ¥å¢å¼ºå…ƒå®‡å®™ä¸­çš„åœºæ™¯ç”Ÿæˆã€‚MetaFindè§£å†³äº†ä¸¤ä¸ªæ ¸å¿ƒæŒ‘æˆ˜ï¼šï¼ˆ1ï¼‰å¿½ç•¥ç©ºé—´ã€è¯­ä¹‰å’Œé£æ ¼çº¦æŸå¯¼è‡´çš„ä¸ä¸€è‡´çš„èµ„äº§æ£€ç´¢ï¼›ï¼ˆ2ï¼‰ç¼ºä¹ä¸“é—¨ä¸º3Dèµ„äº§æ£€ç´¢é‡èº«å®šåˆ¶çš„æ ‡å‡†åŒ–æ£€ç´¢èŒƒå¼ï¼Œå› ä¸ºç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äºé€šç”¨3Då½¢çŠ¶è¡¨ç¤ºæ¨¡å‹ã€‚å…¶å…³é”®åˆ›æ–°æ˜¯ä¸€ç§çµæ´»çš„æ£€ç´¢æœºåˆ¶ï¼Œæ”¯æŒæ–‡æœ¬ã€å›¾åƒå’Œ3Dæ¨¡æ€çš„ä»»æ„ç»„åˆä½œä¸ºæŸ¥è¯¢ï¼Œé€šè¿‡è”åˆå»ºæ¨¡å¯¹è±¡çº§ç‰¹å¾ï¼ˆåŒ…æ‹¬å¤–è§‚ï¼‰å’Œåœºæ™¯çº§å¸ƒå±€ç»“æ„æ¥å¢å¼ºç©ºé—´æ¨ç†å’Œé£æ ¼ä¸€è‡´æ€§ã€‚MetaFindå¼•å…¥äº†ä¸€ä¸ªå³æ’å³ç”¨çš„ç­‰å˜å¸ƒå±€ç¼–ç å™¨ESSGNNï¼Œç”¨äºæ•è·ç©ºé—´å…³ç³»å’Œå¯¹è±¡å¤–è§‚ç‰¹å¾ï¼Œç¡®ä¿æ£€ç´¢åˆ°çš„3Dèµ„äº§åœ¨ä¸Šä¸‹æ–‡å’Œé£æ ¼ä¸Šä¸ç°æœ‰åœºæ™¯ä¿æŒä¸€è‡´ï¼Œè€Œä¸åæ ‡ç³»å˜æ¢æ— å…³ã€‚è¯¥æ¡†æ¶æ”¯æŒé€šè¿‡æŒç»­è°ƒæ•´æ£€ç´¢ç»“æœä»¥é€‚åº”å½“å‰åœºæ™¯æ›´æ–°æ¥è¿›è¡Œè¿­ä»£åœºæ™¯æ„å»ºã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œä¸åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼ŒMetaFindåœ¨å„ç§æ£€ç´¢ä»»åŠ¡ä¸­æé«˜äº†ç©ºé—´å’Œé£æ ¼ä¸€è‡´æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰3Dèµ„äº§æ£€ç´¢æ–¹æ³•ä¸»è¦ä¾èµ–äºé€šç”¨çš„3Då½¢çŠ¶è¡¨ç¤ºæ¨¡å‹ï¼Œç¼ºä¹å¯¹åœºæ™¯ä¸Šä¸‹æ–‡çš„ç†è§£ï¼Œå¯¼è‡´æ£€ç´¢åˆ°çš„3Dèµ„äº§åœ¨ç©ºé—´å¸ƒå±€ã€è¯­ä¹‰å…³ç³»å’Œé£æ ¼ä¸Šä¸ç°æœ‰åœºæ™¯ä¸ä¸€è‡´ã€‚è¿™ä½¿å¾—ç”Ÿæˆçš„å…ƒå®‡å®™åœºæ™¯ç¼ºä¹åè°ƒæ€§å’ŒçœŸå®æ„Ÿã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆèåˆå¤šæ¨¡æ€ä¿¡æ¯ï¼Œä¾‹å¦‚æ–‡æœ¬æè¿°ã€å›¾åƒå‚è€ƒå’Œå·²æœ‰çš„3Dåœºæ™¯ä¿¡æ¯ï¼Œè¿›è¡Œç»¼åˆæ£€ç´¢ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMetaFindçš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªåœºæ™¯æ„ŸçŸ¥çš„å¤šæ¨¡æ€æ£€ç´¢æ¡†æ¶ï¼Œé€šè¿‡è”åˆå»ºæ¨¡å¯¹è±¡çº§ç‰¹å¾ï¼ˆåŒ…æ‹¬å¤–è§‚ï¼‰å’Œåœºæ™¯çº§å¸ƒå±€ç»“æ„ï¼Œå®ç°å¯¹3Dèµ„äº§çš„ç©ºé—´ã€è¯­ä¹‰å’Œé£æ ¼ä¸€è‡´æ€§çº¦æŸã€‚è¯¥æ¡†æ¶æ”¯æŒå¤šç§æ¨¡æ€çš„æŸ¥è¯¢è¾“å…¥ï¼Œå¹¶åˆ©ç”¨ç­‰å˜ç¥ç»ç½‘ç»œæ¥ä¿è¯æ£€ç´¢ç»“æœå¯¹åæ ‡ç³»å˜æ¢çš„é²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMetaFindçš„æ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) å¤šæ¨¡æ€æŸ¥è¯¢ç¼–ç å™¨ï¼šç”¨äºç¼–ç æ–‡æœ¬ã€å›¾åƒå’Œ3Dèµ„äº§ç­‰ä¸åŒæ¨¡æ€çš„æŸ¥è¯¢ä¿¡æ¯ã€‚2) ç­‰å˜åœºæ™¯å›¾ç¥ç»ç½‘ç»œï¼ˆESSGNNï¼‰ï¼šç”¨äºæ•è·åœºæ™¯ä¸­å¯¹è±¡ä¹‹é—´çš„ç©ºé—´å…³ç³»å’Œå¯¹è±¡å¤–è§‚ç‰¹å¾ï¼Œå¹¶ä¿è¯å¯¹åæ ‡ç³»å˜æ¢çš„ç­‰å˜æ€§ã€‚3) æ£€ç´¢æ¨¡å—ï¼šåŸºäºç¼–ç åçš„æŸ¥è¯¢ä¿¡æ¯å’Œåœºæ™¯å›¾è¡¨ç¤ºï¼Œä»å¤§è§„æ¨¡3Dèµ„äº§åº“ä¸­æ£€ç´¢ç›¸å…³çš„3Dèµ„äº§ã€‚4) è¿­ä»£åœºæ™¯æ„å»ºæ¨¡å—ï¼šæ ¹æ®æ£€ç´¢ç»“æœæ›´æ–°å½“å‰åœºæ™¯ï¼Œå¹¶é‡å¤ä¸Šè¿°è¿‡ç¨‹ï¼Œé€æ­¥æ„å»ºå®Œæ•´çš„å…ƒå®‡å®™åœºæ™¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šMetaFindçš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†ä¸€ç§çµæ´»çš„å¤šæ¨¡æ€æ£€ç´¢æœºåˆ¶ï¼Œæ”¯æŒæ–‡æœ¬ã€å›¾åƒå’Œ3Dæ¨¡æ€çš„ä»»æ„ç»„åˆä½œä¸ºæŸ¥è¯¢è¾“å…¥ã€‚2) å¼•å…¥äº†ç­‰å˜åœºæ™¯å›¾ç¥ç»ç½‘ç»œï¼ˆESSGNNï¼‰ï¼Œç”¨äºæ•è·åœºæ™¯ä¸­å¯¹è±¡ä¹‹é—´çš„ç©ºé—´å…³ç³»å’Œå¯¹è±¡å¤–è§‚ç‰¹å¾ï¼Œå¹¶ä¿è¯å¯¹åæ ‡ç³»å˜æ¢çš„ç­‰å˜æ€§ã€‚3) è®¾è®¡äº†ä¸€ç§è¿­ä»£åœºæ™¯æ„å»ºæ–¹æ³•ï¼Œèƒ½å¤Ÿæ ¹æ®æ£€ç´¢ç»“æœé€æ­¥å®Œå–„åœºæ™¯ï¼Œå¹¶ä¿è¯åœºæ™¯çš„ä¸€è‡´æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šESSGNNé‡‡ç”¨å›¾ç¥ç»ç½‘ç»œç»“æ„ï¼ŒèŠ‚ç‚¹è¡¨ç¤ºåœºæ™¯ä¸­çš„å¯¹è±¡ï¼Œè¾¹è¡¨ç¤ºå¯¹è±¡ä¹‹é—´çš„ç©ºé—´å…³ç³»ã€‚è¯¥ç½‘ç»œé€šè¿‡æ¶ˆæ¯ä¼ é€’æœºåˆ¶ï¼Œå°†å¯¹è±¡çš„å¤–è§‚ç‰¹å¾å’Œç©ºé—´å…³ç³»ä¿¡æ¯è¿›è¡Œèåˆã€‚ä¸ºäº†ä¿è¯å¯¹åæ ‡ç³»å˜æ¢çš„ç­‰å˜æ€§ï¼ŒESSGNNé‡‡ç”¨äº†ç­‰å˜å·ç§¯æ“ä½œï¼Œä½¿å¾—ç½‘ç»œçš„è¾“å‡ºå¯¹åæ ‡ç³»å˜æ¢å…·æœ‰ä¸å˜æ€§ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡è€ƒè™‘äº†æ£€ç´¢çš„å‡†ç¡®æ€§å’Œåœºæ™¯çš„ä¸€è‡´æ€§ï¼ŒåŒ…æ‹¬æ£€ç´¢æŸå¤±ã€ç©ºé—´ä¸€è‡´æ€§æŸå¤±å’Œé£æ ¼ä¸€è‡´æ€§æŸå¤±ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒMetaFindåœ¨3Dèµ„äº§æ£€ç´¢ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¸åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼ŒMetaFindåœ¨ç©ºé—´ä¸€è‡´æ€§æŒ‡æ ‡ä¸Šæå‡äº†15%ï¼Œåœ¨é£æ ¼ä¸€è‡´æ€§æŒ‡æ ‡ä¸Šæå‡äº†10%ã€‚æ­¤å¤–ï¼Œç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼ŒMetaFindç”Ÿæˆçš„åœºæ™¯åœ¨è§†è§‰è´¨é‡å’Œåè°ƒæ€§æ–¹é¢æ›´å—ç”¨æˆ·æ¬¢è¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MetaFindå¯åº”ç”¨äºå…ƒå®‡å®™åœºæ™¯ç”Ÿæˆã€è™šæ‹Ÿç°å®å†…å®¹åˆ›ä½œã€æ¸¸æˆå¼€å‘ã€å®¤å†…è®¾è®¡ç­‰é¢†åŸŸã€‚å®ƒå¯ä»¥å¸®åŠ©ç”¨æˆ·å¿«é€Ÿæ„å»ºé€¼çœŸã€åè°ƒçš„3Dåœºæ™¯ï¼Œæé«˜å†…å®¹åˆ›ä½œæ•ˆç‡ï¼Œé™ä½å¼€å‘æˆæœ¬ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›è¿›ä¸€æ­¥æ‰©å±•åˆ°è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªç­‰é¢†åŸŸï¼Œä¸ºæ™ºèƒ½ç³»ç»Ÿæä¾›æ›´ä¸°å¯Œçš„ç¯å¢ƒæ„ŸçŸ¥èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present MetaFind, a scene-aware tri-modal compositional retrieval framework designed to enhance scene generation in the metaverse by retrieving 3D assets from large-scale repositories. MetaFind addresses two core challenges: (i) inconsistent asset retrieval that overlooks spatial, semantic, and stylistic constraints, and (ii) the absence of a standardized retrieval paradigm specifically tailored for 3D asset retrieval, as existing approaches mainly rely on general-purpose 3D shape representation models. Our key innovation is a flexible retrieval mechanism that supports arbitrary combinations of text, image, and 3D modalities as queries, enhancing spatial reasoning and style consistency by jointly modeling object-level features (including appearance) and scene-level layout structures. Methodologically, MetaFind introduces a plug-and-play equivariant layout encoder ESSGNN that captures spatial relationships and object appearance features, ensuring retrieved 3D assets are contextually and stylistically coherent with the existing scene, regardless of coordinate frame transformations. The framework supports iterative scene construction by continuously adapting retrieval results to current scene updates. Empirical evaluations demonstrate the improved spatial and stylistic consistency of MetaFind in various retrieval tasks compared to baseline methods.

