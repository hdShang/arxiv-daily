---
layout: default
title: "Reinforcement Learning meets Masked Video Modeling : Trajectory-Guided Adaptive Token Selection"
---

# Reinforcement Learning meets Masked Video Modeling : Trajectory-Guided Adaptive Token Selection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.08561" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.08561v2</a>
  <a href="https://arxiv.org/pdf/2505.08561.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.08561v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.08561v2', 'Reinforcement Learning meets Masked Video Modeling : Trajectory-Guided Adaptive Token Selection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ayush K. Rai, Kyle Min, Tarun Krishna, Feiyan Hu, Alan F. Smeaton, Noel E. O'Connor

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-13 (æ›´æ–°: 2025-08-14)

**å¤‡æ³¨**: Accepted in ICCVW 2025 - Long Multi-Scene Video Foundations Workshop

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè½¨è¿¹æ„ŸçŸ¥è‡ªé€‚åº”æ ‡è®°é€‰æ‹©ä»¥è§£å†³è§†é¢‘å»ºæ¨¡ä¸­çš„æ©è”½ç­–ç•¥é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ©è”½è§†é¢‘å»ºæ¨¡` `è½¨è¿¹æ„ŸçŸ¥` `è‡ªé€‚åº”é‡‡æ ·` `åŠ¨ä½œè¯†åˆ«` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ©è”½è§†é¢‘å»ºæ¨¡æ–¹æ³•åœ¨æ©è”½ç­–ç•¥é€‰æ‹©ä¸Šå­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥æœ‰æ•ˆåˆ©ç”¨è§†é¢‘ä¸­çš„è¿åŠ¨ä¿¡æ¯ã€‚
2. æå‡ºçš„è½¨è¿¹æ„ŸçŸ¥è‡ªé€‚åº”æ ‡è®°é‡‡æ ·å™¨ï¼ˆTATSï¼‰é€šè¿‡å»ºæ¨¡è¿åŠ¨åŠ¨æ€ï¼Œä¼˜åŒ–æ©è”½ç­–ç•¥ï¼Œæå‡äº†è§†é¢‘å»ºæ¨¡çš„æ•ˆæœã€‚
3. åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šï¼Œå®éªŒç»“æœæ˜¾ç¤ºè¯¥æ–¹æ³•åœ¨æ€§èƒ½ã€è¿ç§»æ€§å’Œæ•ˆç‡ä¸Šä¼˜äºå…¶ä»–å…ˆè¿›æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ©è”½è§†é¢‘å»ºæ¨¡ï¼ˆMVMï¼‰ä½œä¸ºä¸€ç§æœ‰æ•ˆçš„è§†è§‰åŸºç¡€æ¨¡å‹é¢„è®­ç»ƒç­–ç•¥ï¼Œé€šè¿‡é‡å»ºæ©è”½çš„æ—¶ç©ºæ ‡è®°æ¥æå‡æ¨¡å‹æ€§èƒ½ã€‚ç„¶è€Œï¼Œé€‰æ‹©åˆé€‚çš„æ©è”½ç­–ç•¥ä»ç„¶æ˜¯ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„è½¨è¿¹æ„ŸçŸ¥è‡ªé€‚åº”æ ‡è®°é‡‡æ ·å™¨ï¼ˆTATSï¼‰ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿå»ºæ¨¡æ ‡è®°çš„è¿åŠ¨åŠ¨æ€ï¼Œå¹¶å¯æ— ç¼é›†æˆåˆ°æ©è”½è‡ªç¼–ç å™¨ï¼ˆMAEï¼‰æ¡†æ¶ä¸­ï¼Œä»è€Œé€‰æ‹©è§†é¢‘ä¸­çš„è¿åŠ¨ä¸­å¿ƒæ ‡è®°ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„è®­ç»ƒç­–ç•¥ï¼Œåˆ©ç”¨è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆPPOï¼‰å®ç°MAEå’ŒTATSçš„è”åˆä¼˜åŒ–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨ä¸å½±å“åŠ¨ä½œè¯†åˆ«ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½çš„æƒ…å†µä¸‹ï¼Œå…è®¸è¿›è¡Œæ¿€è¿›çš„æ©è”½ï¼ŒåŒæ—¶ä¿æŒé¢„è®­ç»ƒçš„å†…å­˜æ•ˆç‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ©è”½è§†é¢‘å»ºæ¨¡ä¸­æ©è”½ç­–ç•¥é€‰æ‹©ä¸å½“çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å¤šä¾èµ–äºé¢„å®šä¹‰çš„æ©è”½æŠ€æœ¯ï¼Œéš¾ä»¥å……åˆ†åˆ©ç”¨è§†é¢‘ä¸­çš„è¿åŠ¨ä¿¡æ¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºçš„è½¨è¿¹æ„ŸçŸ¥è‡ªé€‚åº”æ ‡è®°é‡‡æ ·å™¨ï¼ˆTATSï¼‰é€šè¿‡å»ºæ¨¡æ ‡è®°çš„è¿åŠ¨åŠ¨æ€ï¼Œèƒ½å¤Ÿé€‰æ‹©è¿åŠ¨ä¸­å¿ƒçš„æ ‡è®°ï¼Œä»è€Œä¼˜åŒ–æ©è”½ç­–ç•¥ï¼Œæå‡æ¨¡å‹çš„å­¦ä¹ æ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ©è”½è‡ªç¼–ç å™¨ï¼ˆMAEï¼‰å’ŒTATSæ¨¡å—ï¼ŒTATSåœ¨MAEçš„åŸºç¡€ä¸Šè¿›è¡Œè”åˆä¼˜åŒ–ï¼Œé‡‡ç”¨è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆPPOï¼‰è¿›è¡Œè®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†è½¨è¿¹æ„ŸçŸ¥çš„åŠ¨æ€æ ‡è®°é€‰æ‹©æœºåˆ¶ï¼Œä½¿å¾—æ©è”½ç­–ç•¥æ›´åŠ çµæ´»å’Œé«˜æ•ˆï¼Œä¸ä¼ ç»Ÿçš„éšæœºæˆ–åŸºäºç®¡é“çš„æ©è”½æ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨è¿åŠ¨ä¿¡æ¯ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†é€‚åº”æ€§æ©è”½æ¯”ä¾‹ï¼Œå¹¶è®¾è®¡äº†è”åˆæŸå¤±å‡½æ•°ä»¥å¹³è¡¡MAEå’ŒTATSçš„ä¼˜åŒ–ç›®æ ‡ï¼Œç½‘ç»œç»“æ„ä¸Šåˆ™ç»“åˆäº†è¿åŠ¨ä¿¡æ¯æå–å’Œæ ‡è®°é€‰æ‹©æ¨¡å—ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„TATSæ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šå‡è¡¨ç°ä¼˜å¼‚ï¼Œä¾‹å¦‚åœ¨Something-Something v2æ•°æ®é›†ä¸Šï¼Œç›¸è¾ƒäºå…¶ä»–å…ˆè¿›æ–¹æ³•ï¼Œæ¨¡å‹çš„åŠ¨ä½œè¯†åˆ«å‡†ç¡®ç‡æå‡äº†çº¦5%ï¼ŒåŒæ—¶ä¿æŒäº†è¾ƒä½çš„å†…å­˜æ¶ˆè€—ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è§†é¢‘ç†è§£ã€åŠ¨ä½œè¯†åˆ«å’Œæ™ºèƒ½ç›‘æ§ç­‰ã€‚é€šè¿‡ä¼˜åŒ–æ©è”½ç­–ç•¥ï¼Œæå‡æ¨¡å‹åœ¨å¤æ‚è§†é¢‘åœºæ™¯ä¸­çš„è¡¨ç°ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½æ¨åŠ¨æ›´é«˜æ•ˆçš„è§†é¢‘åˆ†ææŠ€æœ¯çš„å‘å±•ï¼ŒåŠ©åŠ›æ™ºèƒ½ç³»ç»Ÿçš„è¿›æ­¥ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Masked video modeling~(MVM) has emerged as a highly effective pre-training strategy for visual foundation models, whereby the model reconstructs masked spatiotemporal tokens using information from visible tokens. However, a key challenge in such approaches lies in selecting an appropriate masking strategy. Previous studies have explored predefined masking techniques, including random and tube-based masking, as well as approaches that leverage key motion priors, optical flow and semantic cues from externally pre-trained models. In this work, we introduce a novel and generalizable Trajectory-Aware Adaptive Token Sampler (TATS), which models the motion dynamics of tokens and can be seamlessly integrated into the masked autoencoder (MAE) framework to select motion-centric tokens in videos. Additionally, we propose a unified training strategy that enables joint optimization of both MAE and TATS from scratch using Proximal Policy Optimization (PPO). We show that our model allows for aggressive masking without compromising performance on the downstream task of action recognition while also ensuring that the pre-training remains memory efficient. Extensive experiments of the proposed approach across four benchmarks, including Something-Something v2, Kinetics-400, UCF101, and HMDB51, demonstrate the effectiveness, transferability, generalization, and efficiency of our work compared to other state-of-the-art methods.

