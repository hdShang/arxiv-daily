---
layout: default
title: Monocular Depth Guided Occlusion-Aware Disparity Refinement via Semi-supervised Learning in Laparoscopic Images
---

# Monocular Depth Guided Occlusion-Aware Disparity Refinement via Semi-supervised Learning in Laparoscopic Images

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.08178" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.08178v1</a>
  <a href="https://arxiv.org/pdf/2505.08178.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.08178v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.08178v1', 'Monocular Depth Guided Occlusion-Aware Disparity Refinement via Semi-supervised Learning in Laparoscopic Images')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ziteng Liu, Dongdong He, Chenghong Zhang, Wenpeng Gao, Yili Fu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-13

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ·±åº¦å¼•å¯¼çš„é®æŒ¡æ„ŸçŸ¥è§†å·®ç²¾ç‚¼ç½‘ç»œä»¥è§£å†³è…¹è…”é•œå›¾åƒä¸­çš„è§†å·®ä¼°è®¡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `è§†å·®ä¼°è®¡` `æ·±åº¦å­¦ä¹ ` `è…¹è…”é•œå›¾åƒ` `é®æŒ¡æ„ŸçŸ¥` `å…‰æµåˆ†æ` `åŠç›‘ç£å­¦ä¹ ` `åŒ»ç–—å›¾åƒå¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨è…¹è…”é•œå›¾åƒçš„è§†å·®ä¼°è®¡ä¸­é¢ä¸´é®æŒ¡å’Œæ ‡æ³¨æ•°æ®ç¨€ç¼ºçš„æŒ‘æˆ˜ï¼Œå½±å“äº†ç²¾åº¦å’Œé²æ£’æ€§ã€‚
2. æœ¬ç ”ç©¶æå‡ºDGORNetï¼Œé€šè¿‡å•ç›®æ·±åº¦ä¿¡æ¯å’Œä½ç½®åµŒå…¥æ¨¡å—æ¥ç²¾ç‚¼è§†å·®å›¾ï¼Œå¹¶å¼•å…¥å…‰æµå·®å¼‚æŸå¤±ä»¥å¢å¼ºåŠ¨æ€åœºæ™¯çš„é²æ£’æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDGORNetåœ¨SCAREDæ•°æ®é›†ä¸Šæ˜¾è‘—é™ä½äº†EPEå’ŒRMSEï¼Œå°¤å…¶åœ¨å¤æ‚çš„é®æŒ¡å’Œæ— çº¹ç†åŒºåŸŸè¡¨ç°ä¼˜å¼‚ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é®æŒ¡å’Œæ ‡æ³¨æ‰‹æœ¯æ•°æ®çš„ç¨€ç¼ºæ˜¯ç«‹ä½“è…¹è…”é•œå›¾åƒè§†å·®ä¼°è®¡ä¸­çš„é‡å¤§æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ·±åº¦å¼•å¯¼çš„é®æŒ¡æ„ŸçŸ¥è§†å·®ç²¾ç‚¼ç½‘ç»œï¼ˆDGORNetï¼‰ï¼Œé€šè¿‡åˆ©ç”¨ä¸å—é®æŒ¡å½±å“çš„å•ç›®æ·±åº¦ä¿¡æ¯æ¥ç²¾ç‚¼è§†å·®å›¾ã€‚å¼•å…¥äº†ä½ç½®åµŒå…¥æ¨¡å—ï¼ˆPEï¼‰ï¼Œæä¾›æ˜ç¡®çš„ç©ºé—´ä¸Šä¸‹æ–‡ï¼Œå¢å¼ºäº†ç½‘ç»œå®šä½å’Œç²¾ç‚¼ç‰¹å¾çš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œæå‡ºäº†ä¸€ç§å…‰æµå·®å¼‚æŸå¤±ï¼ˆOFDLossï¼‰ï¼Œåˆ©ç”¨è§†é¢‘å¸§é—´çš„æ—¶é—´è¿ç»­æ€§æ¥æé«˜åŠ¨æ€æ‰‹æœ¯åœºæ™¯ä¸­çš„é²æ£’æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDGORNetåœ¨SCAREDæ•°æ®é›†ä¸Šåœ¨ç«¯ç‚¹è¯¯å·®ï¼ˆEPEï¼‰å’Œå‡æ–¹æ ¹è¯¯å·®ï¼ˆRMSEï¼‰æ–¹é¢ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨é®æŒ¡å’Œæ— çº¹ç†åŒºåŸŸã€‚æ¶ˆèç ”ç©¶ç¡®è®¤äº†ä½ç½®åµŒå…¥å’Œå…‰æµå·®å¼‚æŸå¤±çš„è´¡çŒ®ï¼Œçªæ˜¾äº†å®ƒä»¬åœ¨æé«˜ç©ºé—´å’Œæ—¶é—´ä¸€è‡´æ€§æ–¹é¢çš„ä½œç”¨ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³è…¹è…”é•œå›¾åƒä¸­è§†å·®ä¼°è®¡çš„é®æŒ¡é—®é¢˜å’Œæ ‡æ³¨æ•°æ®ç¨€ç¼ºçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†è¿™äº›æŒ‘æˆ˜æ—¶ï¼Œå¾€å¾€æ— æ³•æä¾›è¶³å¤Ÿçš„ç²¾åº¦å’Œé²æ£’æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„DGORNeté€šè¿‡å¼•å…¥å•ç›®æ·±åº¦ä¿¡æ¯æ¥æŒ‡å¯¼è§†å·®å›¾çš„ç²¾ç‚¼ï¼ŒåŒæ—¶åˆ©ç”¨ä½ç½®åµŒå…¥æ¨¡å—å¢å¼ºç©ºé—´ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»è€Œæé«˜ç‰¹å¾çš„å®šä½å’Œç²¾ç‚¼èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDGORNetçš„æ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼Œä¸»è¦åŒ…æ‹¬ä½ç½®åµŒå…¥æ¨¡å—ã€è§†å·®ç²¾ç‚¼æ¨¡å—å’Œå…‰æµå·®å¼‚æŸå¤±æ¨¡å—ã€‚ä½ç½®åµŒå…¥æ¨¡å—æä¾›ç©ºé—´ä¸Šä¸‹æ–‡ï¼Œè§†å·®ç²¾ç‚¼æ¨¡å—è´Ÿè´£ç”Ÿæˆç²¾ç‚¼çš„è§†å·®å›¾ï¼Œè€Œå…‰æµå·®å¼‚æŸå¤±æ¨¡å—åˆ™åˆ©ç”¨æ—¶é—´è¿ç»­æ€§æ¥å¤„ç†æœªæ ‡æ³¨æ•°æ®ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„å…³é”®åˆ›æ–°åœ¨äºå¼•å…¥äº†ä½ç½®åµŒå…¥æ¨¡å—å’Œå…‰æµå·®å¼‚æŸå¤±ï¼Œè¿™ä¸¤è€…å…±åŒæå‡äº†ç½‘ç»œåœ¨åŠ¨æ€æ‰‹æœ¯åœºæ™¯ä¸­çš„ç©ºé—´å’Œæ—¶é—´ä¸€è‡´æ€§ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—æé«˜äº†è§†å·®ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œè®¾è®¡ä¸­ï¼Œä½ç½®åµŒå…¥æ¨¡å—é€šè¿‡æ˜¾å¼çš„ç©ºé—´ä¿¡æ¯å¢å¼ºç‰¹å¾è¡¨ç¤ºï¼Œå…‰æµå·®å¼‚æŸå¤±åˆ™é€šè¿‡è®¡ç®—è§†é¢‘å¸§é—´çš„å…‰æµå·®å¼‚æ¥ä¼˜åŒ–æœªæ ‡æ³¨æ•°æ®çš„å­¦ä¹ è¿‡ç¨‹ã€‚è¿™äº›è®¾è®¡ä½¿å¾—DGORNetåœ¨å¤„ç†å¤æ‚åœºæ™¯æ—¶è¡¨ç°å‡ºæ›´é«˜çš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒDGORNetåœ¨SCAREDæ•°æ®é›†ä¸Šç›¸è¾ƒäºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼ŒEPEå’ŒRMSEåˆ†åˆ«é™ä½äº†XX%å’ŒYY%ã€‚å°¤å…¶åœ¨é®æŒ¡å’Œæ— çº¹ç†åŒºåŸŸï¼ŒDGORNetçš„è¡¨ç°æ˜¾è‘—ä¼˜äºå¯¹æ¯”åŸºçº¿ï¼ŒéªŒè¯äº†å…¶åœ¨å¤æ‚åœºæ™¯ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸä¸»è¦é›†ä¸­åœ¨åŒ»ç–—å›¾åƒå¤„ç†ï¼Œå°¤å…¶æ˜¯è…¹è…”é•œæ‰‹æœ¯ä¸­çš„è§†å·®ä¼°è®¡ã€‚é€šè¿‡æé«˜è§†å·®ä¼°è®¡çš„å‡†ç¡®æ€§ï¼ŒDGORNetèƒ½å¤Ÿä¸ºæ‰‹æœ¯å¯¼èˆªã€ä¸‰ç»´é‡å»ºå’Œæœºå™¨äººæ‰‹æœ¯æä¾›æ›´å¯é çš„æ”¯æŒï¼Œè¿›è€Œæå‡æ‰‹æœ¯çš„å®‰å…¨æ€§å’Œæœ‰æ•ˆæ€§ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›æ‰©å±•åˆ°å…¶ä»–ç±»å‹çš„åŒ»ç–—å½±åƒåˆ†æå’Œè®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Occlusion and the scarcity of labeled surgical data are significant challenges in disparity estimation for stereo laparoscopic images. To address these issues, this study proposes a Depth Guided Occlusion-Aware Disparity Refinement Network (DGORNet), which refines disparity maps by leveraging monocular depth information unaffected by occlusion. A Position Embedding (PE) module is introduced to provide explicit spatial context, enhancing the network's ability to localize and refine features. Furthermore, we introduce an Optical Flow Difference Loss (OFDLoss) for unlabeled data, leveraging temporal continuity across video frames to improve robustness in dynamic surgical scenes. Experiments on the SCARED dataset demonstrate that DGORNet outperforms state-of-the-art methods in terms of End-Point Error (EPE) and Root Mean Squared Error (RMSE), particularly in occlusion and texture-less regions. Ablation studies confirm the contributions of the Position Embedding and Optical Flow Difference Loss, highlighting their roles in improving spatial and temporal consistency. These results underscore DGORNet's effectiveness in enhancing disparity estimation for laparoscopic surgery, offering a practical solution to challenges in disparity estimation and data limitations.

