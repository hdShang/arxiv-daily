---
layout: default
title: "EventDiff: A Unified and Efficient Diffusion Model Framework for Event-based Video Frame Interpolation"
---

# EventDiff: A Unified and Efficient Diffusion Model Framework for Event-based Video Frame Interpolation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.08235" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.08235v1</a>
  <a href="https://arxiv.org/pdf/2505.08235.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.08235v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.08235v1', 'EventDiff: A Unified and Efficient Diffusion Model Framework for Event-based Video Frame Interpolation')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Hanle Zheng, Xujie Han, Zegang Peng, Shangbin Zhang, Guangxun Du, Zhuo Zou, Xilin Wang, Jibin Wu, Hao Guo, Lei Deng

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-13

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫EventDiff‰ª•Ëß£ÂÜ≥‰∫ã‰ª∂È©±Âä®ËßÜÈ¢ëÂ∏ßÊèíÂÄºÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)**

**ÂÖ≥ÈîÆËØç**: `ËßÜÈ¢ëÂ∏ßÊèíÂÄº` `‰∫ã‰ª∂Áõ∏Êú∫` `Êâ©Êï£Ê®°Âûã` `Ê∑±Â∫¶Â≠¶‰π†` `ËÆ°ÁÆóÊú∫ËßÜËßâ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÂü∫‰∫é‰∫ã‰ª∂ÁöÑVFIÊñπÊ≥ï‰æùËµñ‰∫éÊòæÂºèËøêÂä®Âª∫Ê®°ÔºåÂØºËá¥Âú®ÁªÜÂæÆËøêÂä®Âú∫ÊôØ‰∏ãÁöÑÂõæÂÉèÈáçÂª∫Ë¥®Èáè‰∏ãÈôç„ÄÇ
2. Êú¨ÊñáÊèêÂá∫EventDiffÔºåÈÄöËøá‰∫ã‰ª∂-Â∏ßÊ∑∑ÂêàËá™ÁºñÁ†ÅÂô®ÂíåÂéªÂô™Êâ©Êï£ËøáÁ®ãÔºåÁõ¥Êé•Âú®ÊΩúÂú®Á©∫Èó¥‰∏≠ËøõË°åÊèíÂÄºÔºåÈÅøÂÖç‰∫ÜÊòæÂºèËøêÂä®‰º∞ËÆ°„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåEventDiffÂú®Â§ö‰∏™ÂêàÊàêÂíåÁúüÂÆû‰∏ñÁïåÊï∞ÊçÆÈõÜ‰∏äË°®Áé∞‰ºòÂºÇÔºåÁõ∏ËæÉ‰∫éÁé∞ÊúâÊñπÊ≥ïÂú®PSNR‰∏äÊèêÂçá‰∫Ü1.98dBÔºåÂπ∂‰∏îÊé®ÁêÜÈÄüÂ∫¶ÊèêÈ´ò‰∫Ü4.24ÂÄç„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËßÜÈ¢ëÂ∏ßÊèíÂÄºÔºàVFIÔºâÊòØËÆ°ÁÆóÊú∫ËßÜËßâ‰∏≠ÁöÑ‰∏ÄÈ°πÂü∫Êú¨ËÄåÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑ‰ªªÂä°ÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§ßËøêÂä®„ÄÅÈÅÆÊå°ÂíåÂÖâÁÖßÂèòÂåñÁöÑÊÉÖÂÜµ‰∏ã„ÄÇËøëÂπ¥Êù•Ôºå‰∫ã‰ª∂Áõ∏Êú∫ÁöÑËøõÊ≠•‰∏∫Ëß£ÂÜ≥Ëøô‰∫õÊåëÊàòÊèê‰æõ‰∫ÜÊñ∞Êú∫‰ºö„ÄÇÁé∞ÊúâÁöÑÂü∫‰∫é‰∫ã‰ª∂ÁöÑVFIÊñπÊ≥ïÈÄöËøáÊâãÂ∑•ËÆæËÆ°ÁöÑ‰∏≠Èó¥Ë°®Á§∫ÔºàÂ¶ÇÂÖâÊµÅÔºâÊàêÂäüÊÅ¢Â§ç‰∫ÜÂ§ßËßÑÊ®°ÂíåÂ§çÊùÇÁöÑËøêÂä®Ôºå‰ΩÜÂú®ÁªÜÂæÆËøêÂä®Âú∫ÊôØ‰∏ãÁöÑÈ´ò‰øùÁúüÂõæÂÉèÈáçÂª∫‰∏äÂ≠òÂú®Â¶•Âçè„ÄÇÊú¨ÊñáÊèêÂá∫‰∫ÜEventDiffÔºå‰∏Ä‰∏™Áªü‰∏Ä‰∏îÈ´òÊïàÁöÑÂü∫‰∫é‰∫ã‰ª∂ÁöÑÊâ©Êï£Ê®°ÂûãÊ°ÜÊû∂ÔºåÈááÁî®Êñ∞È¢ñÁöÑ‰∫ã‰ª∂-Â∏ßÊ∑∑ÂêàËá™ÁºñÁ†ÅÂô®ÔºàHAEÔºâÂíåËΩªÈáèÁ∫ßÁöÑÊó∂Á©∫‰∫§ÂèâÊ≥®ÊÑèÂäõÊ®°ÂùóÔºàSTCAÔºâÔºåÊúâÊïàËûçÂêàÂä®ÊÄÅ‰∫ã‰ª∂ÊµÅÂíåÈùôÊÄÅÂ∏ß„ÄÇEventDiffÁõ¥Êé•Âú®ÊΩúÂú®Á©∫Èó¥‰∏≠ÈÄöËøáÂéªÂô™Êâ©Êï£ËøáÁ®ãËøõË°åÊèíÂÄºÔºåÂ±ïÁé∞Âá∫Âú®Â§öÁßçÂ§çÊùÇVFIÂú∫ÊôØ‰∏ãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥ËßÜÈ¢ëÂ∏ßÊèíÂÄº‰∏≠ÁöÑÈ´òËøêÂä®„ÄÅÈÅÆÊå°ÂíåÂÖâÁÖßÂèòÂåñÁ≠âÊåëÊàòÔºåÁé∞ÊúâÊñπÊ≥ïÂú®ÁªÜÂæÆËøêÂä®Âú∫ÊôØ‰∏ãÁöÑÈáçÂª∫ÊïàÊûú‰∏ç‰Ω≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöEventDiffÈÄöËøáÂºïÂÖ•‰∫ã‰ª∂-Â∏ßÊ∑∑ÂêàËá™ÁºñÁ†ÅÂô®ÔºàHAEÔºâÂíåÂéªÂô™Êâ©Êï£ËøáÁ®ãÔºåÁõ¥Êé•Âú®ÊΩúÂú®Á©∫Èó¥‰∏≠ËøõË°åÊèíÂÄºÔºåÈÅøÂÖç‰∫Ü‰º†ÁªüÊñπÊ≥ïÂØπÊòæÂºèËøêÂä®Âª∫Ê®°ÁöÑ‰æùËµñ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∫ã‰ª∂-Â∏ßÊ∑∑ÂêàËá™ÁºñÁ†ÅÂô®ÔºàHAEÔºâÂíåËΩªÈáèÁ∫ßÁöÑÊó∂Á©∫‰∫§ÂèâÊ≥®ÊÑèÂäõÔºàSTCAÔºâÊ®°ÂùóÔºåÂàÜ‰∏∫‰∏§‰∏™Èò∂ÊÆµÔºöÈ¶ñÂÖàÈ¢ÑËÆ≠ÁªÉHAEÔºåÁÑ∂Âêé‰∏éÊâ©Êï£Ê®°ÂûãÂÖ±Âêå‰ºòÂåñ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞Âú®‰∫éÈÄöËøáÂéªÂô™Êâ©Êï£ËøáÁ®ãËøõË°åÊèíÂÄºÔºå‰ΩøÂæóÊ®°ÂûãÂú®Â§öÁßçÂ§çÊùÇÂú∫ÊôØ‰∏ãÊõ¥‰∏∫È≤ÅÊ£íÔºåÊòæËëóÊèêÂçá‰∫ÜÈáçÂª∫Ë¥®Èáè„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÁΩëÁªúÁªìÊûÑ‰∏äÔºåHAEÁªìÂêà‰∫ÜÂä®ÊÄÅ‰∫ã‰ª∂ÊµÅÂíåÈùôÊÄÅÂ∏ßÁöÑÁâπÂæÅÔºåSTCAÊ®°ÂùóÂàôÂ¢ûÂº∫‰∫ÜÊó∂Á©∫‰ø°ÊÅØÁöÑËûçÂêàÔºåÊçüÂ§±ÂáΩÊï∞ËÆæËÆ°‰∏äÊ≥®ÈáçÈáçÂª∫Ë¥®Èáè‰∏éÁ®≥ÂÆöÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåEventDiffÂú®Vimeo90K-TripletÊï∞ÊçÆÈõÜ‰∏äÁõ∏ÊØîÁé∞ÊúâÊúÄÂÖàËøõÁöÑÂü∫‰∫é‰∫ã‰ª∂ÁöÑVFIÊñπÊ≥ïÊèêÂçá‰∫Ü1.98dBÁöÑPSNRÔºåÂπ∂Âú®SNU-FILM‰ªªÂä°‰∏≠Ë°®Áé∞‰ºòÂºÇÔºåÊé®ÁêÜÈÄüÂ∫¶ÊèêÈ´ò‰∫Ü4.24ÂÄçÔºåÂ±ïÁé∞‰∫ÜÊòæËëóÁöÑÊÄßËÉΩ‰ºòÂäø„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõÔºåÂ∞§ÂÖ∂Âú®ËßÜÈ¢ëÂ§ÑÁêÜ„ÄÅËôöÊãüÁé∞ÂÆûÂíåÂ¢ûÂº∫Áé∞ÂÆûÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÊèêÈ´òËßÜÈ¢ëÂ∏ßÊèíÂÄºÁöÑË¥®ÈáèÂíåÈÄüÂ∫¶ÔºåEventDiffËÉΩÂ§ü‰∏∫ÂÆûÊó∂ËßÜÈ¢ëÂàÜÊûêÂíåÁîüÊàêÊèê‰æõÊõ¥Âº∫Â§ßÁöÑÊîØÊåÅÔºåÊé®Âä®Áõ∏ÂÖ≥ÊäÄÊúØÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Video Frame Interpolation (VFI) is a fundamental yet challenging task in computer vision, particularly under conditions involving large motion, occlusion, and lighting variation. Recent advancements in event cameras have opened up new opportunities for addressing these challenges. While existing event-based VFI methods have succeeded in recovering large and complex motions by leveraging handcrafted intermediate representations such as optical flow, these designs often compromise high-fidelity image reconstruction under subtle motion scenarios due to their reliance on explicit motion modeling. Meanwhile, diffusion models provide a promising alternative for VFI by reconstructing frames through a denoising process, eliminating the need for explicit motion estimation or warping operations. In this work, we propose EventDiff, a unified and efficient event-based diffusion model framework for VFI. EventDiff features a novel Event-Frame Hybrid AutoEncoder (HAE) equipped with a lightweight Spatial-Temporal Cross Attention (STCA) module that effectively fuses dynamic event streams with static frames. Unlike previous event-based VFI methods, EventDiff performs interpolation directly in the latent space via a denoising diffusion process, making it more robust across diverse and challenging VFI scenarios. Through a two-stage training strategy that first pretrains the HAE and then jointly optimizes it with the diffusion model, our method achieves state-of-the-art performance across multiple synthetic and real-world event VFI datasets. The proposed method outperforms existing state-of-the-art event-based VFI methods by up to 1.98dB in PSNR on Vimeo90K-Triplet and shows superior performance in SNU-FILM tasks with multiple difficulty levels. Compared to the emerging diffusion-based VFI approach, our method achieves up to 5.72dB PSNR gain on Vimeo90K-Triplet and 4.24X faster inference.

