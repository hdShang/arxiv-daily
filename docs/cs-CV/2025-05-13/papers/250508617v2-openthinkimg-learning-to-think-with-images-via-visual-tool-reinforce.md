---
layout: default
title: OpenThinkIMG: Learning to Think with Images via Visual Tool Reinforcement Learning
---

# OpenThinkIMG: Learning to Think with Images via Visual Tool Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.08617" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.08617v2</a>
  <a href="https://arxiv.org/pdf/2505.08617.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.08617v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.08617v2', 'OpenThinkIMG: Learning to Think with Images via Visual Tool Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhaochen Su, Linjie Li, Mingyang Song, Yunzhuo Hao, Zhengyuan Yang, Jun Zhang, Guanjie Chen, Jiawei Gu, Juntao Li, Xiaoye Qu, Yu Cheng

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-13 (æ›´æ–°: 2025-07-09)

**å¤‡æ³¨**: Work in progress

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOpenThinkIMGä»¥è§£å†³è§†è§‰å·¥å…·å¢å¼ºå­¦ä¹ çš„æŒ‘æˆ˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è§†è§‰å·¥å…·å¢å¼º` `å¼ºåŒ–å­¦ä¹ ` `è§†è§‰æ¨ç†` `å¤šæ¨¡æ€å­¦ä¹ ` `å¼€æºæ¡†æ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å½“å‰å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹åœ¨åŠ¨æ€å·¥å…·è°ƒç”¨æ–¹é¢çš„é€‚åº”æ€§ä¸è¶³ï¼Œç¼ºä¹æœ‰æ•ˆçš„è®­ç»ƒæ¡†æ¶ã€‚
2. æå‡ºOpenThinkIMGæ¡†æ¶ï¼Œç»“åˆæ ‡å‡†åŒ–è§†è§‰å·¥å…·æ¥å£å’ŒV-ToolRLå¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œæå‡å·¥å…·ä½¿ç”¨ç­–ç•¥çš„å­¦ä¹ èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŸºäºV-ToolRLè®­ç»ƒçš„ä»£ç†åœ¨å›¾è¡¨æ¨ç†ä»»åŠ¡ä¸Šè¶…è¶Šäº†ä¼ ç»Ÿçš„ç›‘ç£å­¦ä¹ åŸºçº¿ï¼Œæå‡å¹…åº¦æ˜¾è‘—ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äººç±»èƒ½å¤Ÿçµæ´»åˆ©ç”¨äº¤äº’å¼è§†è§‰è®¤çŸ¥è¿›è¡Œå¤æ‚é—®é¢˜è§£å†³ï¼Œä½†ä½¿å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰å­¦ä¹ ç±»ä¼¼çš„é€‚åº”æ€§è¡Œä¸ºä»ç„¶é¢ä¸´æŒ‘æˆ˜ã€‚å½“å‰ç¼ºä¹æ ‡å‡†åŒ–åŸºç¡€è®¾æ–½ï¼Œé™åˆ¶äº†å¤šæ ·åŒ–å·¥å…·çš„é›†æˆã€ä¸°å¯Œäº¤äº’æ•°æ®çš„ç”Ÿæˆä»¥åŠæœ‰æ•ˆè®­ç»ƒå¼ºå¥ä»£ç†çš„èƒ½åŠ›ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºOpenThinkIMGï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå¼€æºçš„å…¨é¢ç«¯åˆ°ç«¯æ¡†æ¶ï¼Œæ—¨åœ¨å¢å¼ºLVLMsçš„å·¥å…·ä½¿ç”¨èƒ½åŠ›ã€‚è¯¥æ¡†æ¶æä¾›æ ‡å‡†åŒ–çš„è§†è§‰å·¥å…·æ¥å£ã€å¯æ‰©å±•çš„è½¨è¿¹ç”Ÿæˆå’Œçµæ´»çš„è®­ç»ƒç¯å¢ƒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶V-ToolRLï¼Œä»¥è®­ç»ƒLVLMså­¦ä¹ åŠ¨æ€å·¥å…·è°ƒç”¨çš„é€‚åº”æ€§ç­–ç•¥ã€‚é€šè¿‡åœ¨å¤æ‚çš„å›¾è¡¨æ¨ç†ä»»åŠ¡ä¸Šè¿›è¡Œå®è¯éªŒè¯ï¼Œæˆ‘ä»¬çš„RLè®­ç»ƒä»£ç†æ˜¾è‘—è¶…è¶Šäº†åŸºäºç›‘ç£å¾®è°ƒçš„å¯¹æ¯”æ¨¡å‹ï¼Œå±•ç¤ºäº†OpenThinkIMGåœ¨åŠ¨æ€è§†è§‰æ¨ç†ä¸­çš„æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹åœ¨åŠ¨æ€å·¥å…·è°ƒç”¨ä¸­çš„é€‚åº”æ€§ä¸è¶³é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äºé™æ€æ¼”ç¤ºçš„ç›‘ç£å¾®è°ƒï¼Œå¯¼è‡´ç­–ç•¥æ³›åŒ–èƒ½åŠ›æœ‰é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºOpenThinkIMGæ¡†æ¶ï¼Œé€šè¿‡æ ‡å‡†åŒ–çš„è§†è§‰å·¥å…·æ¥å£å’ŒV-ToolRLå¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œå¸®åŠ©LVLMsè‡ªä¸»å‘ç°æœ€ä½³å·¥å…·ä½¿ç”¨ç­–ç•¥ï¼Œä»è€Œæé«˜ä»»åŠ¡æˆåŠŸç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šOpenThinkIMGæ¡†æ¶åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šæ ‡å‡†åŒ–è§†è§‰å·¥å…·æ¥å£ã€å¯æ‰©å±•çš„è½¨è¿¹ç”Ÿæˆæ¨¡å—å’Œçµæ´»çš„è®­ç»ƒç¯å¢ƒã€‚V-ToolRLä½œä¸ºæ ¸å¿ƒç®—æ³•ï¼Œç›´æ¥é€šè¿‡å·¥å…·äº¤äº’åé¦ˆä¼˜åŒ–ç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šV-ToolRLæ˜¯æœ¬ç ”ç©¶çš„æ ¸å¿ƒåˆ›æ–°ï¼Œå…è®¸LVLMsåœ¨åŠ¨æ€ç¯å¢ƒä¸­è‡ªä¸»å­¦ä¹ å·¥å…·ä½¿ç”¨ç­–ç•¥ï¼Œä¸ä¼ ç»Ÿçš„ç›‘ç£å­¦ä¹ æ–¹æ³•ç›¸æ¯”ï¼Œå…·æœ‰æ›´é«˜çš„çµæ´»æ€§å’Œé€‚åº”æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨V-ToolRLä¸­ï¼Œè®¾è®¡äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–ä»»åŠ¡æˆåŠŸç‡ï¼Œå¹¶é‡‡ç”¨äº†Qwen2-VL-2Bä½œä¸ºåŸºç¡€æ¨¡å‹ï¼Œç¡®ä¿äº†è®­ç»ƒçš„æœ‰æ•ˆæ€§å’Œæ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºV-ToolRLè®­ç»ƒçš„ä»£ç†åœ¨å›¾è¡¨æ¨ç†ä»»åŠ¡ä¸Šæ¯”ç›‘ç£å¾®è°ƒåˆå§‹åŒ–çš„æ¨¡å‹æé«˜äº†28.83åˆ†ï¼Œä¸”è¶…è¶Šäº†ç°æœ‰çš„ç›‘ç£å·¥å…·å­¦ä¹ åŸºçº¿ï¼Œå¦‚Tacoå’ŒCogComï¼Œå¹³å‡æå‡12.7åˆ†ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹è¿˜åœ¨å‡†ç¡®æ€§ä¸Šè¶…è¶Šäº†GPT-4.1ï¼Œæå‡äº†8.68åˆ†ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

OpenThinkIMGæ¡†æ¶å¯å¹¿æ³›åº”ç”¨äºéœ€è¦è§†è§‰æ¨ç†å’Œå·¥å…·äº¤äº’çš„é¢†åŸŸï¼Œå¦‚æ™ºèƒ½åŠ©æ‰‹ã€æ•°æ®åˆ†æå’Œæ•™è‚²æŠ€æœ¯ç­‰ã€‚å…¶çµæ´»çš„è®¾è®¡ä½¿å¾—AIä»£ç†èƒ½å¤Ÿåœ¨åŠ¨æ€ç¯å¢ƒä¸­æ›´å¥½åœ°ç†è§£å’Œå¤„ç†è§†è§‰ä¿¡æ¯ï¼Œæå‡ç”¨æˆ·ä½“éªŒå’Œå†³ç­–æ”¯æŒèƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While humans can flexibly leverage interactive visual cognition for complex problem-solving, enabling Large Vision-Language Models (LVLMs) to learn similarly adaptive behaviors with visual tools remains challenging. A significant hurdle is the current lack of standardized infrastructure, which hinders integrating diverse tools, generating rich interaction data, and training robust agents effectively. To address these gaps, we introduce OpenThinkIMG, the first open-source, comprehensive end-to-end framework for tool-augmented LVLMs. It features standardized vision tool interfaces, scalable trajectory generation for policy initialization, and a flexible training environment. Furthermore, considering supervised fine-tuning (SFT) on static demonstrations offers limited policy generalization for dynamic tool invocation, we propose a novel reinforcement learning (RL) framework V-ToolRL to train LVLMs to learn adaptive policies for invoking external vision tools. V-ToolRL enables LVLMs to autonomously discover optimal tool-usage strategies by directly optimizing for task success using feedback from tool interactions. We empirically validate V-ToolRL on challenging chart reasoning tasks. Our RL-trained agent, built upon a Qwen2-VL-2B, significantly outperforms its SFT-initialized counterpart (+28.83 points) and surpasses established supervised tool-learning baselines like Taco and CogCom by an average of +12.7 points. Notably, it also surpasses prominent closed-source models like GPT-4.1 by +8.68 accuracy points. We hope OpenThinkIMG can serve as a foundational framework for advancing dynamic, tool-augmented visual reasoning, helping the community develop AI agents that can genuinely "think with images".

