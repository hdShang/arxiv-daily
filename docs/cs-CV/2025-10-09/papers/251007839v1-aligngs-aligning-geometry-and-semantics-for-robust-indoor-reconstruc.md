---
layout: default
title: "AlignGS: Aligning Geometry and Semantics for Robust Indoor Reconstruction from Sparse Views"
---

# AlignGS: Aligning Geometry and Semantics for Robust Indoor Reconstruction from Sparse Views

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.07839" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.07839v1</a>
  <a href="https://arxiv.org/pdf/2510.07839.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.07839v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.07839v1', 'AlignGS: Aligning Geometry and Semantics for Robust Indoor Reconstruction from Sparse Views')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yijie Gao, Houqiang Zhong, Tianchi Zhu, Zhengxue Cheng, Qiang Hu, Li Song

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-09

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/MediaX-SJTU/AlignGS)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**AlignGSï¼šå¯¹é½å‡ ä½•ä¸è¯­ä¹‰ï¼Œå®ç°ç¨€ç–è§†è§’ä¸‹é²æ£’çš„å®¤å†…é‡å»º**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¸‰ç»´é‡å»º` `è¯­ä¹‰å…ˆéªŒ` `å‡ ä½•ä¼˜åŒ–` `ç¨€ç–è§†è§’` `é«˜æ–¯æº…å°„`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç¨€ç–è§†è§’ä¸‹é‡å»ºå®¤å†…åœºæ™¯æ—¶ï¼Œå‡ ä½•ç»“æ„æ˜“å‡ºç°æ­§ä¹‰ï¼Œè¯­ä¹‰ä¿¡æ¯æœªèƒ½æœ‰æ•ˆæŒ‡å¯¼å‡ ä½•é‡å»ºã€‚
2. AlignGSçš„æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨2DåŸºç¡€æ¨¡å‹æå–çš„è¯­ä¹‰å…ˆéªŒï¼Œä¸»åŠ¨å¼•å¯¼3Då‡ ä½•ç»“æ„çš„é‡å»ºï¼Œå®ç°å‡ ä½•ä¸è¯­ä¹‰çš„ååŒä¼˜åŒ–ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒAlignGSåœ¨novel view synthesiså’Œå‡ ä½•ç²¾åº¦ä¸Šå‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒéªŒè¯äº†è¯­ä¹‰å…ˆéªŒä½œä¸ºå‡ ä½•æ­£åˆ™åŒ–çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºAlignGSæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä»ç¨€ç–è§†è§’é‡å»ºè¯­ä¹‰ä¸°å¯Œçš„å®¤å†…ä¸‰ç»´æ¨¡å‹è¿™ä¸€éš¾é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸å°†è¯­ä¹‰è§†ä¸ºå‡ ä½•ç»“æ„çš„è¢«åŠ¨ç‰¹å¾ï¼Œå¿½ç•¥äº†è¯­ä¹‰å¯¹å‡ ä½•é‡å»ºçš„æŒ‡å¯¼ä½œç”¨ã€‚AlignGSåˆ›æ–°æ€§åœ°å®ç°äº†å‡ ä½•ä¸è¯­ä¹‰çš„ååŒç«¯åˆ°ç«¯ä¼˜åŒ–ã€‚è¯¥æ–¹æ³•ä»2DåŸºç¡€æ¨¡å‹ä¸­æå–ä¸°å¯Œçš„å…ˆéªŒçŸ¥è¯†ï¼Œå¹¶é€šè¿‡ä¸€ç³»åˆ—è¯­ä¹‰åˆ°å‡ ä½•çš„æŒ‡å¯¼æœºåˆ¶ï¼ˆåŒ…æ‹¬æ·±åº¦ä¸€è‡´æ€§å’Œå¤šæ–¹é¢æ³•å‘é‡æ­£åˆ™åŒ–ï¼‰ç›´æ¥çº¦æŸ3Dè¡¨ç¤ºã€‚åœ¨æ ‡å‡†æ•°æ®é›†ä¸Šçš„å¤§é‡è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ novel view synthesis ä»»åŠ¡ä¸Šå–å¾—äº†state-of-the-artçš„ç»“æœï¼Œå¹¶ç”Ÿæˆäº†å…·æœ‰æ›´é«˜å‡ ä½•ç²¾åº¦çš„é‡å»ºæ¨¡å‹ã€‚å®éªŒç»“æœéªŒè¯äº†åˆ©ç”¨è¯­ä¹‰å…ˆéªŒä½œä¸ºå‡ ä½•æ­£åˆ™åŒ–é¡¹ï¼Œèƒ½å¤Ÿä»æœ‰é™çš„è¾“å…¥è§†è§’ç”Ÿæˆæ›´è¿è´¯å’Œå®Œæ•´çš„3Dæ¨¡å‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ä»ç¨€ç–è§†è§’é‡å»ºå®¤å†…åœºæ™¯æ—¶ï¼Œç”±äºå‡ ä½•æ­§ä¹‰æ€§å¯¼è‡´çš„é‡å»ºè´¨é‡å·®çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸å°†è¯­ä¹‰ä¿¡æ¯ä½œä¸ºåå¤„ç†æ­¥éª¤ï¼Œåœ¨å‡ ä½•ç»“æ„å·²ç»ç”Ÿæˆåæ‰è¿›è¡Œè¯­ä¹‰æ ‡æ³¨ï¼Œå¿½ç•¥äº†è¯­ä¹‰ä¿¡æ¯å¯¹å‡ ä½•é‡å»ºçš„æŒ‡å¯¼ä½œç”¨ï¼Œå¯¼è‡´é‡å»ºç»“æœä¸é²æ£’ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šAlignGSçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†è¯­ä¹‰ç†è§£ä½œä¸ºä¸»åŠ¨çš„æŒ‡å¯¼åŠ›é‡ï¼Œé€šè¿‡è¯­ä¹‰å…ˆéªŒæ¥æ­£åˆ™åŒ–å‡ ä½•é‡å»ºè¿‡ç¨‹ã€‚å…·ä½“æ¥è¯´ï¼Œåˆ©ç”¨2DåŸºç¡€æ¨¡å‹æå–çš„è¯­ä¹‰ä¿¡æ¯ï¼ŒæŒ‡å¯¼3Då‡ ä½•ç»“æ„çš„ç”Ÿæˆï¼Œä»è€Œæé«˜é‡å»ºçš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ã€‚è¿™ç§ç«¯åˆ°ç«¯çš„å‡ ä½•ä¸è¯­ä¹‰ååŒä¼˜åŒ–æ˜¯æœ¬è®ºæ–‡çš„å…³é”®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAlignGSçš„æ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) 2Dè¯­ä¹‰å…ˆéªŒæå–ï¼šåˆ©ç”¨é¢„è®­ç»ƒçš„2DåŸºç¡€æ¨¡å‹ï¼ˆå¦‚è¯­ä¹‰åˆ†å‰²æ¨¡å‹ï¼‰æå–è¾“å…¥å›¾åƒçš„è¯­ä¹‰ä¿¡æ¯ã€‚2) 3Dè¡¨ç¤ºï¼šä½¿ç”¨é«˜æ–¯æº…å°„ï¼ˆGaussian Splattingï¼‰ä½œä¸º3Dåœºæ™¯çš„è¡¨ç¤ºæ–¹æ³•ã€‚3) è¯­ä¹‰åˆ°å‡ ä½•çš„æŒ‡å¯¼ï¼šè®¾è®¡äº†ä¸€ç³»åˆ—è¯­ä¹‰åˆ°å‡ ä½•çš„æŒ‡å¯¼æœºåˆ¶ï¼ŒåŒ…æ‹¬æ·±åº¦ä¸€è‡´æ€§çº¦æŸå’Œå¤šæ–¹é¢æ³•å‘é‡æ­£åˆ™åŒ–ã€‚4) ç«¯åˆ°ç«¯ä¼˜åŒ–ï¼šå°†ä¸Šè¿°æ¨¡å—é›†æˆåˆ°ä¸€ä¸ªç«¯åˆ°ç«¯çš„ä¼˜åŒ–æ¡†æ¶ä¸­ï¼Œè”åˆä¼˜åŒ–å‡ ä½•ç»“æ„å’Œè¯­ä¹‰ä¿¡æ¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šAlignGSæœ€å…³é”®çš„åˆ›æ–°åœ¨äºå°†è¯­ä¹‰ä¿¡æ¯ä½œä¸ºå‡ ä½•é‡å»ºçš„å¼ºå…ˆéªŒï¼Œå¹¶è®¾è®¡äº†æœ‰æ•ˆçš„è¯­ä¹‰åˆ°å‡ ä½•çš„æŒ‡å¯¼æœºåˆ¶ã€‚ä¸ç°æœ‰æ–¹æ³•ä¸åŒï¼ŒAlignGSä¸æ˜¯ç®€å•åœ°å°†è¯­ä¹‰ä¿¡æ¯â€œç»˜åˆ¶â€åœ¨å·²æœ‰çš„å‡ ä½•ç»“æ„ä¸Šï¼Œè€Œæ˜¯åˆ©ç”¨è¯­ä¹‰ä¿¡æ¯ä¸»åŠ¨åœ°å¡‘é€ å‡ ä½•ç»“æ„ï¼Œä»è€Œæé«˜äº†é‡å»ºçš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è¯­ä¹‰åˆ°å‡ ä½•çš„æŒ‡å¯¼æ–¹é¢ï¼ŒAlignGSè®¾è®¡äº†æ·±åº¦ä¸€è‡´æ€§çº¦æŸå’Œå¤šæ–¹é¢æ³•å‘é‡æ­£åˆ™åŒ–ã€‚æ·±åº¦ä¸€è‡´æ€§çº¦æŸæ—¨åœ¨ä¿è¯é‡å»ºçš„3Dç»“æ„ä¸2Då›¾åƒçš„æ·±åº¦ä¿¡æ¯ä¸€è‡´ã€‚å¤šæ–¹é¢æ³•å‘é‡æ­£åˆ™åŒ–åˆ™åˆ©ç”¨è¯­ä¹‰ä¿¡æ¯æ¥çº¦æŸ3Dç»“æ„çš„æ³•å‘é‡ï¼Œä½¿å…¶æ›´åŠ å¹³æ»‘å’Œç¬¦åˆç‰©ä½“çš„å½¢çŠ¶å…ˆéªŒã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬æ¸²æŸ“æŸå¤±ã€æ·±åº¦ä¸€è‡´æ€§æŸå¤±å’Œæ³•å‘é‡æ­£åˆ™åŒ–æŸå¤±ã€‚ç½‘ç»œç»“æ„æ–¹é¢ï¼Œä¸»è¦ä¾èµ–äºé«˜æ–¯æº…å°„çš„ä¼˜åŒ–è¿‡ç¨‹ï¼Œä»¥åŠ2Dè¯­ä¹‰åˆ†å‰²æ¨¡å‹æä¾›çš„è¯­ä¹‰å…ˆéªŒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

AlignGSåœ¨æ ‡å‡†æ•°æ®é›†ä¸Šå–å¾—äº†state-of-the-artçš„novel view synthesisç»“æœï¼Œå¹¶æ˜¾è‘—æé«˜äº†é‡å»ºæ¨¡å‹çš„å‡ ä½•ç²¾åº¦ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒAlignGSèƒ½å¤Ÿç”Ÿæˆæ›´è¿è´¯ã€æ›´å®Œæ•´çš„3Dæ¨¡å‹ï¼Œå°¤å…¶æ˜¯åœ¨ç¨€ç–è§†è§’ä¸‹ã€‚å®éªŒç»“æœéªŒè¯äº†è¯­ä¹‰å…ˆéªŒä½œä¸ºå‡ ä½•æ­£åˆ™åŒ–çš„æœ‰æ•ˆæ€§ï¼Œä¸ºæœªæ¥çš„ä¸‰ç»´é‡å»ºç ”ç©¶æä¾›äº†æ–°çš„æ–¹å‘ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

AlignGSåœ¨å¢å¼ºç°å®ã€è™šæ‹Ÿç°å®å’Œæœºå™¨äººç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚é«˜è´¨é‡çš„è¯­ä¹‰ä¸‰ç»´é‡å»ºæ¨¡å‹å¯ä»¥ç”¨äºAR/VRåœºæ™¯çš„æ„å»ºã€æœºå™¨äººçš„ç¯å¢ƒæ„ŸçŸ¥å’Œå¯¼èˆªã€ä»¥åŠå®¤å†…åœºæ™¯çš„æ•°å­—åŒ–å»ºæ¨¡ç­‰ã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºæå‡è¿™äº›åº”ç”¨çš„ç”¨æˆ·ä½“éªŒå’Œæ™ºèƒ½åŒ–æ°´å¹³ï¼Œå¹¶ä¸ºç›¸å…³é¢†åŸŸçš„ç ”ç©¶æä¾›æ–°çš„æ€è·¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The demand for semantically rich 3D models of indoor scenes is rapidly growing, driven by applications in augmented reality, virtual reality, and robotics. However, creating them from sparse views remains a challenge due to geometric ambiguity. Existing methods often treat semantics as a passive feature painted on an already-formed, and potentially flawed, geometry. We posit that for robust sparse-view reconstruction, semantic understanding instead be an active, guiding force. This paper introduces AlignGS, a novel framework that actualizes this vision by pioneering a synergistic, end-to-end optimization of geometry and semantics. Our method distills rich priors from 2D foundation models and uses them to directly regularize the 3D representation through a set of novel semantic-to-geometry guidance mechanisms, including depth consistency and multi-faceted normal regularization. Extensive evaluations on standard benchmarks demonstrate that our approach achieves state-of-the-art results in novel view synthesis and produces reconstructions with superior geometric accuracy. The results validate that leveraging semantic priors as a geometric regularizer leads to more coherent and complete 3D models from limited input views. Our code is avaliable at https://github.com/MediaX-SJTU/AlignGS .

