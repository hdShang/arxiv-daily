---
layout: default
title: AlignGS: Aligning Geometry and Semantics for Robust Indoor Reconstruction from Sparse Views
---

# AlignGS: Aligning Geometry and Semantics for Robust Indoor Reconstruction from Sparse Views

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.07839" target="_blank" class="toolbar-btn">arXiv: 2510.07839v1</a>
    <a href="https://arxiv.org/pdf/2510.07839.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.07839v1" 
            onclick="toggleFavorite(this, '2510.07839v1', 'AlignGS: Aligning Geometry and Semantics for Robust Indoor Reconstruction from Sparse Views')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yijie Gao, Houqiang Zhong, Tianchi Zhu, Zhengxue Cheng, Qiang Hu, Li Song

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-09

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/MediaX-SJTU/AlignGS)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**AlignGSÔºöÂØπÈΩêÂá†‰Ωï‰∏éËØ≠‰πâÔºåÂÆûÁé∞Á®ÄÁñèËßÜËßí‰∏ãÈ≤ÅÊ£íÁöÑÂÆ§ÂÜÖÈáçÂª∫**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `‰∏âÁª¥ÈáçÂª∫` `ËØ≠‰πâÂÖàÈ™å` `Âá†‰Ωï‰ºòÂåñ` `Á®ÄÁñèËßÜËßí` `È´òÊñØÊ∫ÖÂ∞Ñ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®Á®ÄÁñèËßÜËßí‰∏ãÈáçÂª∫ÂÆ§ÂÜÖÂú∫ÊôØÊó∂ÔºåÂá†‰ΩïÁªìÊûÑÊòìÂá∫Áé∞Ê≠ß‰πâÔºåËØ≠‰πâ‰ø°ÊÅØÊú™ËÉΩÊúâÊïàÊåáÂØºÂá†‰ΩïÈáçÂª∫„ÄÇ
2. AlignGSÁöÑÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÂà©Áî®2DÂü∫Á°ÄÊ®°ÂûãÊèêÂèñÁöÑËØ≠‰πâÂÖàÈ™åÔºå‰∏ªÂä®ÂºïÂØº3DÂá†‰ΩïÁªìÊûÑÁöÑÈáçÂª∫ÔºåÂÆûÁé∞Âá†‰Ωï‰∏éËØ≠‰πâÁöÑÂçèÂêå‰ºòÂåñ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåAlignGSÂú®novel view synthesisÂíåÂá†‰ΩïÁ≤æÂ∫¶‰∏äÂùá‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÈ™åËØÅ‰∫ÜËØ≠‰πâÂÖàÈ™å‰Ωú‰∏∫Âá†‰ΩïÊ≠£ÂàôÂåñÁöÑÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫AlignGSÊ°ÜÊû∂ÔºåÊó®Âú®Ëß£ÂÜ≥‰ªéÁ®ÄÁñèËßÜËßíÈáçÂª∫ËØ≠‰πâ‰∏∞ÂØåÁöÑÂÆ§ÂÜÖ‰∏âÁª¥Ê®°ÂûãËøô‰∏ÄÈöæÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏Â∞ÜËØ≠‰πâËßÜ‰∏∫Âá†‰ΩïÁªìÊûÑÁöÑË¢´Âä®ÁâπÂæÅÔºåÂøΩÁï•‰∫ÜËØ≠‰πâÂØπÂá†‰ΩïÈáçÂª∫ÁöÑÊåáÂØº‰ΩúÁî®„ÄÇAlignGSÂàõÊñ∞ÊÄßÂú∞ÂÆûÁé∞‰∫ÜÂá†‰Ωï‰∏éËØ≠‰πâÁöÑÂçèÂêåÁ´ØÂà∞Á´Ø‰ºòÂåñ„ÄÇËØ•ÊñπÊ≥ï‰ªé2DÂü∫Á°ÄÊ®°Âûã‰∏≠ÊèêÂèñ‰∏∞ÂØåÁöÑÂÖàÈ™åÁü•ËØÜÔºåÂπ∂ÈÄöËøá‰∏ÄÁ≥ªÂàóËØ≠‰πâÂà∞Âá†‰ΩïÁöÑÊåáÂØºÊú∫Âà∂ÔºàÂåÖÊã¨Ê∑±Â∫¶‰∏ÄËá¥ÊÄßÂíåÂ§öÊñπÈù¢Ê≥ïÂêëÈáèÊ≠£ÂàôÂåñÔºâÁõ¥Êé•Á∫¶Êùü3DË°®Á§∫„ÄÇÂú®Ê†áÂáÜÊï∞ÊçÆÈõÜ‰∏äÁöÑÂ§ßÈáèËØÑ‰º∞Ë°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú® novel view synthesis ‰ªªÂä°‰∏äÂèñÂæó‰∫Üstate-of-the-artÁöÑÁªìÊûúÔºåÂπ∂ÁîüÊàê‰∫ÜÂÖ∑ÊúâÊõ¥È´òÂá†‰ΩïÁ≤æÂ∫¶ÁöÑÈáçÂª∫Ê®°Âûã„ÄÇÂÆûÈ™åÁªìÊûúÈ™åËØÅ‰∫ÜÂà©Áî®ËØ≠‰πâÂÖàÈ™å‰Ωú‰∏∫Âá†‰ΩïÊ≠£ÂàôÂåñÈ°πÔºåËÉΩÂ§ü‰ªéÊúâÈôêÁöÑËæìÂÖ•ËßÜËßíÁîüÊàêÊõ¥ËøûË¥ØÂíåÂÆåÊï¥ÁöÑ3DÊ®°Âûã„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥‰ªéÁ®ÄÁñèËßÜËßíÈáçÂª∫ÂÆ§ÂÜÖÂú∫ÊôØÊó∂ÔºåÁî±‰∫éÂá†‰ΩïÊ≠ß‰πâÊÄßÂØºËá¥ÁöÑÈáçÂª∫Ë¥®ÈáèÂ∑ÆÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏Â∞ÜËØ≠‰πâ‰ø°ÊÅØ‰Ωú‰∏∫ÂêéÂ§ÑÁêÜÊ≠•È™§ÔºåÂú®Âá†‰ΩïÁªìÊûÑÂ∑≤ÁªèÁîüÊàêÂêéÊâçËøõË°åËØ≠‰πâÊ†áÊ≥®ÔºåÂøΩÁï•‰∫ÜËØ≠‰πâ‰ø°ÊÅØÂØπÂá†‰ΩïÈáçÂª∫ÁöÑÊåáÂØº‰ΩúÁî®ÔºåÂØºËá¥ÈáçÂª∫ÁªìÊûú‰∏çÈ≤ÅÊ£í„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöAlignGSÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜËØ≠‰πâÁêÜËß£‰Ωú‰∏∫‰∏ªÂä®ÁöÑÊåáÂØºÂäõÈáèÔºåÈÄöËøáËØ≠‰πâÂÖàÈ™åÊù•Ê≠£ÂàôÂåñÂá†‰ΩïÈáçÂª∫ËøáÁ®ã„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÂà©Áî®2DÂü∫Á°ÄÊ®°ÂûãÊèêÂèñÁöÑËØ≠‰πâ‰ø°ÊÅØÔºåÊåáÂØº3DÂá†‰ΩïÁªìÊûÑÁöÑÁîüÊàêÔºå‰ªéËÄåÊèêÈ´òÈáçÂª∫ÁöÑÈ≤ÅÊ£íÊÄßÂíåÂáÜÁ°ÆÊÄß„ÄÇËøôÁßçÁ´ØÂà∞Á´ØÁöÑÂá†‰Ωï‰∏éËØ≠‰πâÂçèÂêå‰ºòÂåñÊòØÊú¨ËÆ∫ÊñáÁöÑÂÖ≥ÈîÆ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöAlignGSÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) 2DËØ≠‰πâÂÖàÈ™åÊèêÂèñÔºöÂà©Áî®È¢ÑËÆ≠ÁªÉÁöÑ2DÂü∫Á°ÄÊ®°ÂûãÔºàÂ¶ÇËØ≠‰πâÂàÜÂâ≤Ê®°ÂûãÔºâÊèêÂèñËæìÂÖ•ÂõæÂÉèÁöÑËØ≠‰πâ‰ø°ÊÅØ„ÄÇ2) 3DË°®Á§∫Ôºö‰ΩøÁî®È´òÊñØÊ∫ÖÂ∞ÑÔºàGaussian SplattingÔºâ‰Ωú‰∏∫3DÂú∫ÊôØÁöÑË°®Á§∫ÊñπÊ≥ï„ÄÇ3) ËØ≠‰πâÂà∞Âá†‰ΩïÁöÑÊåáÂØºÔºöËÆæËÆ°‰∫Ü‰∏ÄÁ≥ªÂàóËØ≠‰πâÂà∞Âá†‰ΩïÁöÑÊåáÂØºÊú∫Âà∂ÔºåÂåÖÊã¨Ê∑±Â∫¶‰∏ÄËá¥ÊÄßÁ∫¶ÊùüÂíåÂ§öÊñπÈù¢Ê≥ïÂêëÈáèÊ≠£ÂàôÂåñ„ÄÇ4) Á´ØÂà∞Á´Ø‰ºòÂåñÔºöÂ∞Ü‰∏äËø∞Ê®°ÂùóÈõÜÊàêÂà∞‰∏Ä‰∏™Á´ØÂà∞Á´ØÁöÑ‰ºòÂåñÊ°ÜÊû∂‰∏≠ÔºåËÅîÂêà‰ºòÂåñÂá†‰ΩïÁªìÊûÑÂíåËØ≠‰πâ‰ø°ÊÅØ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöAlignGSÊúÄÂÖ≥ÈîÆÁöÑÂàõÊñ∞Âú®‰∫éÂ∞ÜËØ≠‰πâ‰ø°ÊÅØ‰Ωú‰∏∫Âá†‰ΩïÈáçÂª∫ÁöÑÂº∫ÂÖàÈ™åÔºåÂπ∂ËÆæËÆ°‰∫ÜÊúâÊïàÁöÑËØ≠‰πâÂà∞Âá†‰ΩïÁöÑÊåáÂØºÊú∫Âà∂„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ï‰∏çÂêåÔºåAlignGS‰∏çÊòØÁÆÄÂçïÂú∞Â∞ÜËØ≠‰πâ‰ø°ÊÅØ‚ÄúÁªòÂà∂‚ÄùÂú®Â∑≤ÊúâÁöÑÂá†‰ΩïÁªìÊûÑ‰∏äÔºåËÄåÊòØÂà©Áî®ËØ≠‰πâ‰ø°ÊÅØ‰∏ªÂä®Âú∞Â°ëÈÄ†Âá†‰ΩïÁªìÊûÑÔºå‰ªéËÄåÊèêÈ´ò‰∫ÜÈáçÂª∫ÁöÑÈ≤ÅÊ£íÊÄßÂíåÂáÜÁ°ÆÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËØ≠‰πâÂà∞Âá†‰ΩïÁöÑÊåáÂØºÊñπÈù¢ÔºåAlignGSËÆæËÆ°‰∫ÜÊ∑±Â∫¶‰∏ÄËá¥ÊÄßÁ∫¶ÊùüÂíåÂ§öÊñπÈù¢Ê≥ïÂêëÈáèÊ≠£ÂàôÂåñ„ÄÇÊ∑±Â∫¶‰∏ÄËá¥ÊÄßÁ∫¶ÊùüÊó®Âú®‰øùËØÅÈáçÂª∫ÁöÑ3DÁªìÊûÑ‰∏é2DÂõæÂÉèÁöÑÊ∑±Â∫¶‰ø°ÊÅØ‰∏ÄËá¥„ÄÇÂ§öÊñπÈù¢Ê≥ïÂêëÈáèÊ≠£ÂàôÂåñÂàôÂà©Áî®ËØ≠‰πâ‰ø°ÊÅØÊù•Á∫¶Êùü3DÁªìÊûÑÁöÑÊ≥ïÂêëÈáèÔºå‰ΩøÂÖ∂Êõ¥Âä†Âπ≥ÊªëÂíåÁ¨¶ÂêàÁâ©‰ΩìÁöÑÂΩ¢Áä∂ÂÖàÈ™å„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨Ê∏≤ÊüìÊçüÂ§±„ÄÅÊ∑±Â∫¶‰∏ÄËá¥ÊÄßÊçüÂ§±ÂíåÊ≥ïÂêëÈáèÊ≠£ÂàôÂåñÊçüÂ§±„ÄÇÁΩëÁªúÁªìÊûÑÊñπÈù¢Ôºå‰∏ªË¶Å‰æùËµñ‰∫éÈ´òÊñØÊ∫ÖÂ∞ÑÁöÑ‰ºòÂåñËøáÁ®ãÔºå‰ª•Âèä2DËØ≠‰πâÂàÜÂâ≤Ê®°ÂûãÊèê‰æõÁöÑËØ≠‰πâÂÖàÈ™å„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

AlignGSÂú®Ê†áÂáÜÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫Üstate-of-the-artÁöÑnovel view synthesisÁªìÊûúÔºåÂπ∂ÊòæËëóÊèêÈ´ò‰∫ÜÈáçÂª∫Ê®°ÂûãÁöÑÂá†‰ΩïÁ≤æÂ∫¶„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåAlignGSËÉΩÂ§üÁîüÊàêÊõ¥ËøûË¥Ø„ÄÅÊõ¥ÂÆåÊï¥ÁöÑ3DÊ®°ÂûãÔºåÂ∞§ÂÖ∂ÊòØÂú®Á®ÄÁñèËßÜËßí‰∏ã„ÄÇÂÆûÈ™åÁªìÊûúÈ™åËØÅ‰∫ÜËØ≠‰πâÂÖàÈ™å‰Ωú‰∏∫Âá†‰ΩïÊ≠£ÂàôÂåñÁöÑÊúâÊïàÊÄßÔºå‰∏∫Êú™Êù•ÁöÑ‰∏âÁª¥ÈáçÂª∫Á†îÁ©∂Êèê‰æõ‰∫ÜÊñ∞ÁöÑÊñπÂêë„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

AlignGSÂú®Â¢ûÂº∫Áé∞ÂÆû„ÄÅËôöÊãüÁé∞ÂÆûÂíåÊú∫Âô®‰∫∫Á≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇÈ´òË¥®ÈáèÁöÑËØ≠‰πâ‰∏âÁª¥ÈáçÂª∫Ê®°ÂûãÂèØ‰ª•Áî®‰∫éAR/VRÂú∫ÊôØÁöÑÊûÑÂª∫„ÄÅÊú∫Âô®‰∫∫ÁöÑÁéØÂ¢ÉÊÑüÁü•ÂíåÂØºËà™„ÄÅ‰ª•ÂèäÂÆ§ÂÜÖÂú∫ÊôØÁöÑÊï∞Â≠óÂåñÂª∫Ê®°Á≠â„ÄÇËØ•Á†îÁ©∂ÊúâÂä©‰∫éÊèêÂçáËøô‰∫õÂ∫îÁî®ÁöÑÁî®Êà∑‰ΩìÈ™åÂíåÊô∫ËÉΩÂåñÊ∞¥Âπ≥ÔºåÂπ∂‰∏∫Áõ∏ÂÖ≥È¢ÜÂüüÁöÑÁ†îÁ©∂Êèê‰æõÊñ∞ÁöÑÊÄùË∑Ø„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> The demand for semantically rich 3D models of indoor scenes is rapidly growing, driven by applications in augmented reality, virtual reality, and robotics. However, creating them from sparse views remains a challenge due to geometric ambiguity. Existing methods often treat semantics as a passive feature painted on an already-formed, and potentially flawed, geometry. We posit that for robust sparse-view reconstruction, semantic understanding instead be an active, guiding force. This paper introduces AlignGS, a novel framework that actualizes this vision by pioneering a synergistic, end-to-end optimization of geometry and semantics. Our method distills rich priors from 2D foundation models and uses them to directly regularize the 3D representation through a set of novel semantic-to-geometry guidance mechanisms, including depth consistency and multi-faceted normal regularization. Extensive evaluations on standard benchmarks demonstrate that our approach achieves state-of-the-art results in novel view synthesis and produces reconstructions with superior geometric accuracy. The results validate that leveraging semantic priors as a geometric regularizer leads to more coherent and complete 3D models from limited input views. Our code is avaliable at https://github.com/MediaX-SJTU/AlignGS .

