---
layout: default
title: Reinforcement Learning-Driven Edge Management for Reliable Multi-view 3D Reconstruction
---

# Reinforcement Learning-Driven Edge Management for Reliable Multi-view 3D Reconstruction

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.08839" target="_blank" class="toolbar-btn">arXiv: 2510.08839v1</a>
    <a href="https://arxiv.org/pdf/2510.08839.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.08839v1" 
            onclick="toggleFavorite(this, '2510.08839v1', 'Reinforcement Learning-Driven Edge Management for Reliable Multi-view 3D Reconstruction')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Motahare Mounesan, Sourya Saha, Houchao Gan, Md. Nurul Absur, Saptarshi Debroy

**ÂàÜÁ±ª**: cs.LG, cs.AI, cs.CV, cs.DC, cs.GR, cs.MM

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-09

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éÂº∫ÂåñÂ≠¶‰π†ÁöÑËæπÁºòÁÆ°ÁêÜÊ°ÜÊû∂ÔºåÊèêÂçáÂ§öËßÜËßí3DÈáçÂª∫Âú®Âä®ÊÄÅÁéØÂ¢É‰∏ãÁöÑÂèØÈù†ÊÄß„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Â§öËßÜËßí3DÈáçÂª∫` `ËæπÁºòËÆ°ÁÆó` `Âº∫ÂåñÂ≠¶‰π†` `ËµÑÊ∫êÁÆ°ÁêÜ` `Q-learning`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ËæπÁºòËÆ°ÁÆóËµÑÊ∫êÁöÑ‰∏çÁ°ÆÂÆöÊÄßÂØπÂÆûÊó∂Â§öËßÜËßí3DÈáçÂª∫ÁöÑÂèØÈù†ÊÄßÊûÑÊàêÊåëÊàòÔºåÂ∞§ÂÖ∂ÊòØÂú®ÁÅ´ÁÅæÊïëÊè¥Á≠âÂÖ≥ÈîÆÂ∫îÁî®‰∏≠„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫‰∏ÄÁßçÂü∫‰∫éÂº∫ÂåñÂ≠¶‰π†ÁöÑËæπÁºòËµÑÊ∫êÁÆ°ÁêÜÊ°ÜÊû∂ÔºåÈÄöËøáÁõ∏Êú∫ÂíåÊúçÂä°Âô®ÈÄâÊã©Ôºå‰ºòÂåñËµÑÊ∫êÂàÜÈÖçÔºåÊèêÂçáÈáçÂª∫Ë¥®ÈáèÂíåÊïàÁéá„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•Ê°ÜÊû∂Âú®Âä®ÊÄÅÁéØÂ¢É‰∏≠ËÉΩÂ§üÊúâÊïàÂπ≥Ë°°Á´ØÂà∞Á´ØÂª∂ËøüÂíåÈáçÂª∫Ë¥®ÈáèÔºå‰ªéËÄåÊèêÈ´òÂ∫îÁî®ÂèØÈù†ÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÂº∫ÂåñÂ≠¶‰π†(RL)ÁöÑËæπÁºòËµÑÊ∫êÁÆ°ÁêÜÊ°ÜÊû∂ÔºåÁî®‰∫éÊèêÈ´òÂ§öËßÜËßí3DÈáçÂª∫ÁöÑÂèØÈù†ÊÄß„ÄÇËØ•Ê°ÜÊû∂Êó®Âú®Ëß£ÂÜ≥ËæπÁºòËµÑÊ∫êÂä®ÊÄÅÊÄßÂíå‰∏çÂèØÈ¢ÑÊµãÊÄßÂ∏¶Êù•ÁöÑÊåëÊàòÔºå‰æãÂ¶ÇÂõæÂÉèË¥®Èáè‰∏ãÈôç„ÄÅÁΩëÁªúËøûÊé•‰∏çÁ®≥ÂÆöÂíåÊúçÂä°Âô®Ë¥üËΩΩÊ≥¢Âä®„ÄÇËØ•Ê°ÜÊû∂ÈááÁî®‰∏§‰∏™ÂçèÂêåÁöÑQ-learningÊô∫ËÉΩ‰ΩìÔºåÂàÜÂà´Ë¥üË¥£Áõ∏Êú∫ÈÄâÊã©ÂíåÊúçÂä°Âô®ÈÄâÊã©ÔºåÂÆåÂÖ®Âú®Á∫øËøêË°åÔºåÂπ∂ÈÄöËøá‰∏éËæπÁºòÁéØÂ¢ÉÁöÑ‰∫§‰∫íÂ≠¶‰π†Á≠ñÁï•„ÄÇ‰∏∫‰∫ÜÊîØÊåÅÂú®ÁúüÂÆûÁ∫¶Êùü‰∏ãÁöÑÂ≠¶‰π†Âπ∂ËØÑ‰º∞Á≥ªÁªüÊÄßËÉΩÔºåÊàë‰ª¨ÂÆûÁé∞‰∫Ü‰∏Ä‰∏™ÂàÜÂ∏ÉÂºèÊµãËØïÂπ≥Âè∞ÔºåÂåÖÊã¨ÂÆûÈ™åÂÆ§ÊâòÁÆ°ÁöÑÁªàÁ´ØËÆæÂ§áÂíåFABRICÂü∫Á°ÄËÆæÊñΩÊâòÁÆ°ÁöÑËæπÁºòÊúçÂä°Âô®Ôºå‰ª•Ê®°ÊãüÊô∫ËÉΩÂüéÂ∏ÇËæπÁºòÂü∫Á°ÄËÆæÊñΩÂú®ÁúüÂÆû‰∏≠Êñ≠Âú∫ÊôØ‰∏ãÁöÑÊÉÖÂÜµ„ÄÇÁªìÊûúË°®ÊòéÔºåÊâÄÊèêÂá∫ÁöÑÊ°ÜÊû∂ÈÄöËøáÊúâÊïàÂú∞Âπ≥Ë°°Á´ØÂà∞Á´ØÂª∂ËøüÂíåÈáçÂª∫Ë¥®ÈáèÔºåÊèêÈ´ò‰∫ÜÂä®ÊÄÅÁéØÂ¢É‰∏≠ÁöÑÂ∫îÁî®ÂèØÈù†ÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÂú®ËæπÁºòËÆ°ÁÆóÁéØÂ¢É‰∏ãÔºåÂÆûÊó∂Â§öËßÜËßí3DÈáçÂª∫Èù¢‰∏¥ËµÑÊ∫êÂä®ÊÄÅÂèòÂåñÂíå‰∏çÂèØÈ¢ÑÊµãÁöÑÊåëÊàòÔºå‰æãÂ¶ÇÁΩëÁªúÂ∏¶ÂÆΩÊ≥¢Âä®„ÄÅÊúçÂä°Âô®Ë¥üËΩΩÂèòÂåñ‰ª•ÂèäÁõ∏Êú∫ÂõæÂÉèË¥®ÈáèÂèóÊçü„ÄÇËøô‰∫õÂõ†Á¥†‰ºöÂØºËá¥ÈáçÂª∫Âª∂ËøüÂ¢ûÂä†„ÄÅÈáçÂª∫Ë¥®Èáè‰∏ãÈôçÔºå‰∏•ÈáçÂΩ±Âìç‰æùËµñ‰∫éÂÆûÊó∂3D‰ø°ÊÅØÁöÑÂ∫îÁî®ÔºåÂ¶ÇÁÅ´ÁÅæÊïëÊè¥Á≠â„ÄÇÁé∞ÊúâÊñπÊ≥ïÈöæ‰ª•Âú®ËµÑÊ∫êÂèóÈôêÂíåÊòìÂèóÂπ≤Êâ∞ÁöÑÁéØÂ¢É‰∏≠‰øùËØÅÈáçÂª∫ÁöÑÂèØÈù†ÊÄßÂíåÊïàÁéá„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Âº∫ÂåñÂ≠¶‰π†ÔºåËÆ©Êô∫ËÉΩ‰ΩìÈÄöËøá‰∏éËæπÁºòÁéØÂ¢ÉÁöÑ‰∫§‰∫íÔºåÂ≠¶‰π†Â¶Ç‰ΩïÂú®Âä®ÊÄÅÂèòÂåñÁöÑËµÑÊ∫êÊù°‰ª∂‰∏ãÔºåÈÄâÊã©ÊúÄ‰Ω≥ÁöÑÁõ∏Êú∫ÁªÑÂêàÂíåÊúçÂä°Âô®ËµÑÊ∫êÔºå‰ªéËÄåÂú®ÈáçÂª∫Ë¥®ÈáèÂíåÂª∂Ëøü‰πãÈó¥ÂèñÂæóÂπ≥Ë°°„ÄÇÈÄöËøáÂú®Á∫øÂ≠¶‰π†ÔºåÊô∫ËÉΩ‰ΩìËÉΩÂ§üÈÄÇÂ∫îÁéØÂ¢ÉÂèòÂåñÔºåÂÅöÂá∫ÊúÄ‰ºòÂÜ≥Á≠ñÔºå‰øùËØÅÈáçÂª∫ÁöÑÂèØÈù†ÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•Ê°ÜÊû∂ÂåÖÂê´‰∏§‰∏™ÂçèÂêåÁöÑQ-learningÊô∫ËÉΩ‰ΩìÔºöÁõ∏Êú∫ÈÄâÊã©Êô∫ËÉΩ‰ΩìÂíåÊúçÂä°Âô®ÈÄâÊã©Êô∫ËÉΩ‰Ωì„ÄÇÁõ∏Êú∫ÈÄâÊã©Êô∫ËÉΩ‰ΩìË¥üË¥£‰ªéÂ§ö‰∏™ÂèØÁî®Áõ∏Êú∫‰∏≠ÈÄâÊã©ÊúÄ‰Ω≥ÁöÑÁõ∏Êú∫ÁªÑÂêàÔºå‰ª•Ëé∑ÂæóÈ´òË¥®ÈáèÁöÑÂõæÂÉèÊï∞ÊçÆ„ÄÇÊúçÂä°Âô®ÈÄâÊã©Êô∫ËÉΩ‰ΩìË¥üË¥£ÈÄâÊã©ÂêàÈÄÇÁöÑËæπÁºòÊúçÂä°Âô®Êù•Â§ÑÁêÜÈáçÂª∫‰ªªÂä°Ôºå‰ª•Èôç‰ΩéÂª∂Ëøü„ÄÇËøô‰∏§‰∏™Êô∫ËÉΩ‰ΩìÁõ∏‰∫íÂçè‰ΩúÔºåÂÖ±Âêå‰ºòÂåñÊï¥‰∏™ÈáçÂª∫ÊµÅÁ®ã„ÄÇÊï¥‰∏™Á≥ªÁªüÂú®‰∏Ä‰∏™ÂàÜÂ∏ÉÂºèÊµãËØïÂπ≥Âè∞‰∏äËøõË°åËØÑ‰º∞ÔºåËØ•Âπ≥Âè∞Ê®°Êãü‰∫ÜÊô∫ËÉΩÂüéÂ∏ÇËæπÁºòÂü∫Á°ÄËÆæÊñΩÂú®ÁúüÂÆû‰∏≠Êñ≠Âú∫ÊôØ‰∏ãÁöÑÊÉÖÂÜµ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜÂº∫ÂåñÂ≠¶‰π†Â∫îÁî®‰∫éËæπÁºòËÆ°ÁÆóÁéØÂ¢É‰∏ãÁöÑÂ§öËßÜËßí3DÈáçÂª∫ËµÑÊ∫êÁÆ°ÁêÜ„ÄÇ‰∏é‰º†ÁªüÁöÑÈùôÊÄÅËµÑÊ∫êÂàÜÈÖçÊñπÊ≥ï‰∏çÂêåÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÊ†πÊçÆÁéØÂ¢ÉÁöÑÂä®ÊÄÅÂèòÂåñÔºåÂÆûÊó∂Ë∞ÉÊï¥ËµÑÊ∫êÂàÜÈÖçÁ≠ñÁï•Ôºå‰ªéËÄåÊèêÈ´òÈáçÂª∫ÁöÑÂèØÈù†ÊÄßÂíåÊïàÁéá„ÄÇÊ≠§Â§ñÔºå‰∏§‰∏™ÂçèÂêåÁöÑQ-learningÊô∫ËÉΩ‰ΩìÁöÑËÆæËÆ°Ôºå‰ΩøÂæóÁõ∏Êú∫ÈÄâÊã©ÂíåÊúçÂä°Âô®ÈÄâÊã©ËÉΩÂ§üÂçèÂêå‰ºòÂåñÔºåËøõ‰∏ÄÊ≠•ÊèêÂçá‰∫ÜÁ≥ªÁªüÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÁõ∏Êú∫ÈÄâÊã©Êô∫ËÉΩ‰ΩìÁöÑÁä∂ÊÄÅÁ©∫Èó¥ÂåÖÊã¨Áõ∏Êú∫ÁöÑÂõæÂÉèË¥®Èáè„ÄÅÁΩëÁªúËøûÊé•Áä∂ÊÄÅÁ≠â‰ø°ÊÅØ„ÄÇÊúçÂä°Âô®ÈÄâÊã©Êô∫ËÉΩ‰ΩìÁöÑÁä∂ÊÄÅÁ©∫Èó¥ÂåÖÊã¨ÊúçÂä°Âô®ÁöÑË¥üËΩΩ„ÄÅÁΩëÁªúÂª∂ËøüÁ≠â‰ø°ÊÅØ„ÄÇ‰∏§‰∏™Êô∫ËÉΩ‰ΩìÈÉΩ‰ΩøÁî®Q-learningÁÆóÊ≥ïËøõË°åÂ≠¶‰π†ÔºåÂ•ñÂä±ÂáΩÊï∞ÁöÑËÆæËÆ°Êó®Âú®Âπ≥Ë°°ÈáçÂª∫Ë¥®ÈáèÂíåÂª∂Ëøü„ÄÇÂÖ∑‰ΩìÁöÑÂ•ñÂä±ÂáΩÊï∞ÂΩ¢ÂºèÂíåQ-learningÁöÑÂèÇÊï∞ËÆæÁΩÆÔºàÂ¶ÇÂ≠¶‰π†Áéá„ÄÅÊäòÊâ£Âõ†Â≠êÁ≠âÔºâÈúÄË¶ÅÊ†πÊçÆÂÆûÈôÖÂ∫îÁî®Âú∫ÊôØËøõË°åË∞ÉÊï¥„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•Ê°ÜÊû∂ËÉΩÂ§üÊúâÊïàÂπ≥Ë°°Á´ØÂà∞Á´ØÂª∂ËøüÂíåÈáçÂª∫Ë¥®ÈáèÔºå‰ªéËÄåÊèêÈ´òÂ∫îÁî®ÂèØÈù†ÊÄß„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåÂú®Ê®°ÊãüÁöÑÊô∫ËÉΩÂüéÂ∏ÇËæπÁºòÂü∫Á°ÄËÆæÊñΩ‰∏≠Êñ≠Âú∫ÊôØ‰∏ãÔºåËØ•Ê°ÜÊû∂ËÉΩÂ§üÊòæËëóÈôç‰ΩéÈáçÂª∫Âª∂ËøüÔºåÂêåÊó∂‰øùËØÅÈáçÂª∫Ë¥®ÈáèÂú®ÂèØÊé•ÂèóÁöÑËåÉÂõ¥ÂÜÖ„ÄÇ‰∏é‰º†ÁªüÁöÑÈùôÊÄÅËµÑÊ∫êÂàÜÈÖçÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•Ê°ÜÊû∂ËÉΩÂ§üÊõ¥Â•ΩÂú∞ÈÄÇÂ∫îÁéØÂ¢ÉÂèòÂåñÔºåÊèê‰æõÊõ¥Á®≥ÂÆöÁöÑÊÄßËÉΩ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂ§öÁßçÈúÄË¶ÅÂÆûÊó∂3DÈáçÂª∫ÁöÑËæπÁºòËÆ°ÁÆóÂú∫ÊôØÔºå‰æãÂ¶ÇÔºöÁÅ´ÁÅæÊïëÊè¥„ÄÅÊô∫ËÉΩ‰∫§ÈÄö„ÄÅÂ∑•‰∏öËá™Âä®Âåñ„ÄÅÂ¢ûÂº∫Áé∞ÂÆûÁ≠â„ÄÇÈÄöËøá‰ºòÂåñËæπÁºòËµÑÊ∫êÁÆ°ÁêÜÔºåÂèØ‰ª•ÊèêÈ´òËøô‰∫õÂ∫îÁî®Âú®ËµÑÊ∫êÂèóÈôêÂíåÂä®ÊÄÅÂèòÂåñÁéØÂ¢É‰∏ãÁöÑÂèØÈù†ÊÄßÂíåÊïàÁéáÔºå‰∏∫Áî®Êà∑Êèê‰æõÊõ¥‰ºòË¥®ÁöÑÊúçÂä°„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïËøòÂèØ‰ª•Êâ©Â±ïÂà∞ÂÖ∂‰ªñÁ±ªÂûãÁöÑËæπÁºòËÆ°ÁÆóÂ∫îÁî®Ôºå‰æãÂ¶ÇËßÜÈ¢ëÂàÜÊûê„ÄÅËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÁ≠â„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Real-time multi-view 3D reconstruction is a mission-critical application for key edge-native use cases, such as fire rescue, where timely and accurate 3D scene modeling enables situational awareness and informed decision-making. However, the dynamic and unpredictable nature of edge resource availability introduces disruptions, such as degraded image quality, unstable network links, and fluctuating server loads, which challenge the reliability of the reconstruction pipeline. In this work, we present a reinforcement learning (RL)-based edge resource management framework for reliable 3D reconstruction to ensure high quality reconstruction within a reasonable amount of time, despite the system operating under a resource-constrained and disruption-prone environment. In particular, the framework adopts two cooperative Q-learning agents, one for camera selection and one for server selection, both of which operate entirely online, learning policies through interactions with the edge environment. To support learning under realistic constraints and evaluate system performance, we implement a distributed testbed comprising lab-hosted end devices and FABRIC infrastructure-hosted edge servers to emulate smart city edge infrastructure under realistic disruption scenarios. Results show that the proposed framework improves application reliability by effectively balancing end-to-end latency and reconstruction quality in dynamic environments.

