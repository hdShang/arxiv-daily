---
layout: default
title: MMHOI: Modeling Complex 3D Multi-Human Multi-Object Interactions
---

# MMHOI: Modeling Complex 3D Multi-Human Multi-Object Interactions

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.07828" target="_blank" class="toolbar-btn">arXiv: 2510.07828v3</a>
    <a href="https://arxiv.org/pdf/2510.07828.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.07828v3" 
            onclick="toggleFavorite(this, '2510.07828v3', 'MMHOI: Modeling Complex 3D Multi-Human Multi-Object Interactions')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Kaen Kogashi, Anoop Cherian, Meng-Yu Jennifer Kuo

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-09 (Êõ¥Êñ∞: 2025-12-04)

**Â§áÊ≥®**: Accepted to WACV 2026

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫MMHOIÊï∞ÊçÆÈõÜÂíåMMHOI-NetÔºåÁî®‰∫éÂª∫Ê®°Â§çÊùÇ3DÂ§ö‰∫∫Â§öÁâ©‰∫§‰∫í**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫îÔºö‰∫§‰∫í‰∏éÂèçÂ∫î (Interaction & Reaction)**

**ÂÖ≥ÈîÆËØç**: `‰∫∫-Áâ©‰∫§‰∫í` `3DÂú∫ÊôØÁêÜËß£` `Â§ö‰∫∫‰∫§‰∫í` `TransformerÁΩëÁªú` `Êï∞ÊçÆÈõÜÊûÑÂª∫`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞Êúâ3D‰∫∫-Áâ©‰∫§‰∫íÊï∞ÊçÆÈõÜÈöæ‰ª•ÊçïÊçâÁúüÂÆûÂú∫ÊôØ‰∏≠Â§çÊùÇÁöÑÂ§ö‰∫∫Â§öÁâ©‰∫§‰∫íÔºåÈôêÂà∂‰∫ÜÁõ∏ÂÖ≥Á†îÁ©∂ÁöÑËøõÂ±ï„ÄÇ
2. ÊèêÂá∫MMHOIÊï∞ÊçÆÈõÜÂíåMMHOI-NetÔºåÂà©Áî®ÁªìÊûÑÂåñÂèåpatchË°®Á§∫Âª∫Ê®°ÂØπË±°ÂèäÂÖ∂‰∫§‰∫íÔºåÂπ∂ÁªìÂêàÂä®‰ΩúËØÜÂà´ÊèêÂçá‰∫§‰∫íÈ¢ÑÊµã„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåMMHOI-NetÂú®MMHOIÂíåCORE4DÊï∞ÊçÆÈõÜ‰∏äÂùáÂèñÂæó‰∫Üstate-of-the-artÁöÑÊÄßËÉΩÔºåÂ∞§ÂÖ∂Âú®ÂáÜÁ°ÆÊÄßÂíåÈáçÂª∫Ë¥®Èáè‰∏ä„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÁúüÂÆûÂú∫ÊôØÈÄöÂ∏∏ÂåÖÂê´Â§ö‰∫∫‰∏éÂ§öÁâ©‰ΩìÁöÑÂõ†Êûú„ÄÅÁõÆÊ†áÂØºÂêëÊàñÂçè‰Ωú‰∫§‰∫í„ÄÇÁé∞ÊúâÁöÑ3D‰∫∫-Áâ©‰∫§‰∫í(HOI)Âü∫ÂáÜÊµãËØï‰ªÖËÄÉËôë‰∫ÜËøô‰∫õÂ§çÊùÇ‰∫§‰∫íÁöÑ‰∏ÄÂ∞èÈÉ®ÂàÜ„ÄÇ‰∏∫‰∫ÜÂº•Ë°•Ëøô‰∏ÄÂ∑ÆË∑ùÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜMMHOI‚Äî‚Äî‰∏Ä‰∏™Â§ßËßÑÊ®°ÁöÑÂ§ö‰∫∫Â§öÁâ©‰∫§‰∫íÊï∞ÊçÆÈõÜÔºåÂåÖÂê´Êù•Ëá™12‰∏™Êó•Â∏∏Âú∫ÊôØÁöÑÂõæÂÉè„ÄÇMMHOI‰∏∫ÊØè‰∏™‰∫∫ÂíåÁâ©‰ΩìÊèê‰æõÂÆåÊï¥ÁöÑ3DÂΩ¢Áä∂ÂíåÂßøÂäøÊ†áÊ≥®Ôºå‰ª•Âèä78‰∏™Âä®‰ΩúÁ±ªÂà´Âíå14‰∏™‰∫§‰∫íÁâπÂÆöË∫´‰ΩìÈÉ®‰ΩçÁöÑÊ†áÁ≠æÔºå‰∏∫‰∏ã‰∏Ä‰ª£HOIÁ†îÁ©∂Êèê‰æõ‰∫Ü‰∏Ä‰∏™ÂÖ®Èù¢ÁöÑÊµãËØïÂπ≥Âè∞„ÄÇÂü∫‰∫éMMHOIÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜMMHOI-NetÔºå‰∏Ä‰∏™Á´ØÂà∞Á´ØÁöÑÂü∫‰∫éTransformerÁöÑÁ•ûÁªèÁΩëÁªúÔºåÁî®‰∫éËÅîÂêà‰º∞ËÆ°‰∫∫-Áâ©3DÂá†‰ΩïÂΩ¢Áä∂„ÄÅÂÆÉ‰ª¨ÁöÑ‰∫§‰∫íÂíåÁõ∏ÂÖ≥Âä®‰Ωú„ÄÇÊàë‰ª¨Ê°ÜÊû∂ÁöÑ‰∏Ä‰∏™ÂÖ≥ÈîÆÂàõÊñ∞ÊòØÁî®‰∫éÂª∫Ê®°ÂØπË±°ÂèäÂÖ∂‰∫§‰∫íÁöÑÁªìÊûÑÂåñÂèåpatchË°®Á§∫ÔºåÁªìÂêàÂä®‰ΩúËØÜÂà´Êù•Â¢ûÂº∫‰∫§‰∫íÈ¢ÑÊµã„ÄÇÂú®MMHOIÂíåÊúÄËøëÊèêÂá∫ÁöÑCORE4DÊï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åË°®ÊòéÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®Â§öHOIÂª∫Ê®°‰∏≠ÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÂú®ÂáÜÁ°ÆÊÄßÂíåÈáçÂª∫Ë¥®ÈáèÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤„ÄÇMMHOIÊï∞ÊçÆÈõÜÂèØÂú®https://zenodo.org/records/17711786ÂÖ¨ÂºÄËé∑Âèñ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Áé∞Êúâ3D‰∫∫-Áâ©‰∫§‰∫í(HOI)Êï∞ÊçÆÈõÜÊó†Ê≥ïÂÖÖÂàÜÂª∫Ê®°ÁúüÂÆûÂú∫ÊôØ‰∏≠Â§çÊùÇÁöÑÂ§ö‰∫∫Â§öÁâ©‰∫§‰∫íÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏Âè™ÂÖ≥Ê≥®Âçï‰∫∫‰∏éÂçïÁâ©ÁöÑ‰∫§‰∫íÔºåÂøΩÁï•‰∫ÜÂ§ö‰∫∫‰πãÈó¥ÁöÑÂçè‰Ωú„ÄÅÁâ©‰Ωì‰πãÈó¥ÁöÑÂÖ≥Á≥ª‰ª•Âèä‰∫§‰∫íÁöÑÂõ†ÊûúÊÄßÂíåÁõÆÊ†áÂØºÂêëÊÄß„ÄÇËøôÂØºËá¥Ê®°ÂûãÂú®ÁúüÂÆûÂú∫ÊôØ‰∏≠ÁöÑÊ≥õÂåñËÉΩÂäõËæÉÂ∑Æ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÊûÑÂª∫‰∏Ä‰∏™Â§ßËßÑÊ®°„ÄÅÊ†áÊ≥®ÂÖ®Èù¢ÁöÑÂ§ö‰∫∫Â§öÁâ©‰∫§‰∫íÊï∞ÊçÆÈõÜMMHOIÔºåÂπ∂ËÆæËÆ°‰∏Ä‰∏™Á´ØÂà∞Á´ØÁöÑÁ•ûÁªèÁΩëÁªúMMHOI-NetÊù•ËÅîÂêà‰º∞ËÆ°‰∫∫-Áâ©3DÂá†‰ΩïÂΩ¢Áä∂„ÄÅ‰∫§‰∫íÂíåÂä®‰Ωú„ÄÇÈÄöËøáÂºïÂÖ•ÁªìÊûÑÂåñÁöÑÂèåpatchË°®Á§∫Êù•Âª∫Ê®°ÂØπË±°ÂèäÂÖ∂‰∫§‰∫íÔºåÂπ∂ÁªìÂêàÂä®‰ΩúËØÜÂà´Êù•Â¢ûÂº∫‰∫§‰∫íÈ¢ÑÊµã„ÄÇËøôÁßçËÆæËÆ°Êó®Âú®Êõ¥ÂÖ®Èù¢Âú∞ÊçïÊçâÂ§çÊùÇ‰∫§‰∫íÁöÑÊú¨Ë¥®ÔºåÊèêÈ´òÊ®°ÂûãÁöÑÂáÜÁ°ÆÊÄßÂíåÈ≤ÅÊ£íÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöMMHOI-NetÊòØ‰∏Ä‰∏™Âü∫‰∫éTransformerÁöÑÁ´ØÂà∞Á´ØÁ•ûÁªèÁΩëÁªúÔºåÂÖ∂Êï¥‰ΩìÊû∂ÊûÑÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) ÁâπÂæÅÊèêÂèñÊ®°ÂùóÔºöÁî®‰∫éÊèêÂèñÂõæÂÉè‰∏≠‰∫∫ÂíåÁâ©‰ΩìÁöÑËßÜËßâÁâπÂæÅ„ÄÇ2) 3DÂá†‰Ωï‰º∞ËÆ°Ê®°ÂùóÔºöÁî®‰∫é‰º∞ËÆ°‰∫∫ÂíåÁâ©‰ΩìÁöÑ3DÂΩ¢Áä∂ÂíåÂßøÂäø„ÄÇ3) ‰∫§‰∫íÂª∫Ê®°Ê®°ÂùóÔºö‰ΩøÁî®ÁªìÊûÑÂåñÁöÑÂèåpatchË°®Á§∫Êù•Âª∫Ê®°ÂØπË±°ÂèäÂÖ∂‰∫§‰∫í„ÄÇ4) Âä®‰ΩúËØÜÂà´Ê®°ÂùóÔºöÁî®‰∫éËØÜÂà´‰∫∫ÁöÑÂä®‰Ωú„ÄÇ5) ‰∫§‰∫íÈ¢ÑÊµãÊ®°ÂùóÔºöÁªìÂêàËßÜËßâÁâπÂæÅ„ÄÅ3DÂá†‰Ωï‰ø°ÊÅØÂíåÂä®‰Ωú‰ø°ÊÅØÊù•È¢ÑÊµã‰∫∫-Áâ©‰∫§‰∫í„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÊèêÂá∫‰∫ÜÁªìÊûÑÂåñÁöÑÂèåpatchË°®Á§∫Êù•Âª∫Ê®°ÂØπË±°ÂèäÂÖ∂‰∫§‰∫í„ÄÇ‰º†ÁªüÁöÑHOIÂª∫Ê®°ÊñπÊ≥ïÈÄöÂ∏∏Â∞Ü‰∫∫ÂíåÁâ©‰ΩìËßÜ‰∏∫Áã¨Á´ãÁöÑ‰∏™‰ΩìÔºåÂøΩÁï•‰∫ÜÂÆÉ‰ª¨‰πãÈó¥ÁöÑÂÖ≥Á≥ª„ÄÇÂèåpatchË°®Á§∫Â∞ÜÊØè‰∏™Áâ©‰ΩìË°®Á§∫‰∏∫‰∏§‰∏™patchÔºö‰∏Ä‰∏™Ë°®Á§∫Áâ©‰ΩìÁöÑÊï¥‰ΩìÂ§ñËßÇÔºåÂè¶‰∏Ä‰∏™Ë°®Á§∫Áâ©‰Ωì‰∏é‰∫∫‰∫§‰∫íÁöÑÂå∫Âüü„ÄÇËøôÁßçË°®Á§∫ÊñπÊ≥ïËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞ÊçïÊçâ‰∫§‰∫íÁöÑÂ±ÄÈÉ®ÁâπÂæÅÔºåÊèêÈ´ò‰∫§‰∫íÈ¢ÑÊµãÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®MMHOI-Net‰∏≠ÔºåÂèåpatchË°®Á§∫ÈÄöËøáTransformerÁΩëÁªúËøõË°åÂ§ÑÁêÜÔºå‰ª•Â≠¶‰π†patch‰πãÈó¥ÁöÑÂÖ≥Á≥ª„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨3DÂá†‰ΩïÈáçÂª∫ÊçüÂ§±„ÄÅÂä®‰ΩúËØÜÂà´ÊçüÂ§±Âíå‰∫§‰∫íÈ¢ÑÊµãÊçüÂ§±„ÄÇÁΩëÁªúÁªìÊûÑÂíåÂèÇÊï∞ËÆæÁΩÆÁªèËøá‰∫ÜÂ§ßÈáèÁöÑÂÆûÈ™åÈ™åËØÅÔºå‰ª•ËææÂà∞ÊúÄ‰Ω≥ÊÄßËÉΩ„ÄÇÂÖ∑‰ΩìÂèÇÊï∞ËÆæÁΩÆÁªÜËäÇÂú®ËÆ∫Êñá‰∏≠ÊúâËØ¶ÁªÜÊèèËø∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

MMHOI-NetÂú®MMHOIÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåÂú®‰∫§‰∫íÈ¢ÑÊµãÂáÜÁ°ÆÁéáÂíå3DÂá†‰ΩïÈáçÂª∫Ë¥®ÈáèÊñπÈù¢Âùá‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïÂú®CORE4DÊï∞ÊçÆÈõÜ‰∏ä‰πüË°®Áé∞Âá∫ËâØÂ•ΩÁöÑÊ≥õÂåñËÉΩÂäõÔºåËØÅÊòé‰∫ÜÂÖ∂Âú®Â§çÊùÇHOIÂª∫Ê®°ÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÂÖ∑‰ΩìÊÄßËÉΩÊï∞ÊçÆÂú®ËÆ∫ÊñáÁöÑÂÆûÈ™åÈÉ®ÂàÜÊúâËØ¶ÁªÜÂ±ïÁ§∫„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫„ÄÅËôöÊãüÁé∞ÂÆû„ÄÅËá™Âä®È©æÈ©∂Á≠âÈ¢ÜÂüü„ÄÇ‰æãÂ¶ÇÔºåÊú∫Âô®‰∫∫ÂèØ‰ª•Âà©Áî®ËØ•ÊäÄÊúØÁêÜËß£‰∫∫Á±ªÁöÑÊÑèÂõæÔºå‰ªéËÄåÊõ¥Â•ΩÂú∞‰∏é‰∫∫Á±ªÂçè‰ΩúÂÆåÊàê‰ªªÂä°„ÄÇÂú®ËôöÊãüÁé∞ÂÆû‰∏≠ÔºåËØ•ÊäÄÊúØÂèØ‰ª•ÂàõÂª∫Êõ¥ÈÄºÁúüÁöÑ‰∫§‰∫í‰ΩìÈ™å„ÄÇËá™Âä®È©æÈ©∂Á≥ªÁªüÂèØ‰ª•Âà©Áî®ËØ•ÊäÄÊúØËØÜÂà´Ë°å‰∫∫‰∏éÂë®Âõ¥Áâ©‰ΩìÁöÑ‰∫§‰∫íÔºå‰ªéËÄåÂÅöÂá∫Êõ¥ÂÆâÂÖ®ÁöÑÂÜ≥Á≠ñ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Real-world scenes often feature multiple humans interacting with multiple objects in ways that are causal, goal-oriented, or cooperative. Yet existing 3D human-object interaction (HOI) benchmarks consider only a fraction of these complex interactions. To close this gap, we present MMHOI -- a large-scale, Multi-human Multi-object Interaction dataset consisting of images from 12 everyday scenarios. MMHOI offers complete 3D shape and pose annotations for every person and object, along with labels for 78 action categories and 14 interaction-specific body parts, providing a comprehensive testbed for next-generation HOI research. Building on MMHOI, we present MMHOI-Net, an end-to-end transformer-based neural network for jointly estimating human-object 3D geometries, their interactions, and associated actions. A key innovation in our framework is a structured dual-patch representation for modeling objects and their interactions, combined with action recognition to enhance the interaction prediction. Experiments on MMHOI and the recently proposed CORE4D datasets demonstrate that our approach achieves state-of-the-art performance in multi-HOI modeling, excelling in both accuracy and reconstruction quality. The MMHOI dataset is publicly available at https://zenodo.org/records/17711786.

