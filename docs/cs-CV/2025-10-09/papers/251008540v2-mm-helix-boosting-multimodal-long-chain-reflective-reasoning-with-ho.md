---
layout: default
title: MM-HELIX: Boosting Multimodal Long-Chain Reflective Reasoning with Holistic Platform and Adaptive Hybrid Policy Optimization
---

# MM-HELIX: Boosting Multimodal Long-Chain Reflective Reasoning with Holistic Platform and Adaptive Hybrid Policy Optimization

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.08540" target="_blank" class="toolbar-btn">arXiv: 2510.08540v2</a>
    <a href="https://arxiv.org/pdf/2510.08540.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.08540v2" 
            onclick="toggleFavorite(this, '2510.08540v2', 'MM-HELIX: Boosting Multimodal Long-Chain Reflective Reasoning with Holistic Platform and Adaptive Hybrid Policy Optimization')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Xiangyu Zhao, Junming Lin, Tianhao Liang, Yifan Zhou, Wenhao Chai, Yuzhe Gu, Weiyun Wang, Kai Chen, Gen Luo, Wenwei Zhang, Junchi Yan, Hua Yang, Haodong Duan, Xue Yang

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-09 (Êõ¥Êñ∞: 2025-10-11)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**MM-HELIXÔºöÈÄöËøáÊï¥‰ΩìÂπ≥Âè∞ÂíåËá™ÈÄÇÂ∫îÊ∑∑ÂêàÁ≠ñÁï•‰ºòÂåñÊèêÂçáÂ§öÊ®°ÊÄÅÈïøÈìæÂèçÊÄùÊé®ÁêÜËÉΩÂäõ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `ÈïøÈìæÊé®ÁêÜ` `ÂèçÊÄùÊé®ÁêÜ` `Âº∫ÂåñÂ≠¶‰π†` `Ëá™ÈÄÇÂ∫î‰ºòÂåñ` `Êåá‰ª§ÂæÆË∞É` `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÂú®ÈïøÈìæÂèçÊÄùÊé®ÁêÜËÉΩÂäõ‰∏çË∂≥ÔºåÈöæ‰ª•Ëß£ÂÜ≥ÈúÄË¶ÅËø≠‰ª£ÊÄùËÄÉÂíåÂõûÊ∫ØÁöÑÂ§çÊùÇÁé∞ÂÆûÈóÆÈ¢ò„ÄÇ
2. ÊèêÂá∫Ëá™ÈÄÇÂ∫îÊ∑∑ÂêàÁ≠ñÁï•‰ºòÂåñ(AHPO)ÔºåÂä®ÊÄÅÁªü‰∏ÄÁ¶ªÁ∫øÁõëÁù£ÂíåÂú®Á∫ø‰ºòÂåñÔºå‰ΩøÊ®°ÂûãÂú®Â•ñÂä±Á®ÄÁñèÊó∂Â≠¶‰π†‰∏ìÂÆ∂Êï∞ÊçÆÔºåÁÜüÁªÉÂêéÁã¨Á´ãÊé¢Á¥¢„ÄÇ
3. Âú®MM-HELIXÂü∫ÂáÜÊµãËØï‰∏≠ÔºåAHPO‰ΩøQwen2.5-VL-7BÊ®°ÂûãÂáÜÁ°ÆÁéáÊèêÂçá18.6%ÔºåÂπ∂Âú®ÈÄöÁî®Êï∞Â≠¶ÂíåÈÄªËæë‰ªªÂä°‰∏≠Âπ≥ÂùáÊÄßËÉΩÊèêÂçá5.7%„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÂΩìÂâçÁöÑÂ§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã(MLLM)Âú®Êï∞Â≠¶ÂíåÈÄªËæëÁ≠âÊé®ÁêÜ‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫‰∏ÄÂÆöÁöÑËÉΩÂäõÔºå‰ΩÜÂÆÉ‰ª¨Âú®ÈïøÈìæÂèçÊÄùÊé®ÁêÜÊñπÈù¢ÁöÑËÉΩÂäõ‰ªçÊú™Ë¢´ÂÖÖÂàÜÊé¢Á¥¢ÔºåËÄåÈïøÈìæÂèçÊÄùÊé®ÁêÜÊòØËß£ÂÜ≥Â§çÊùÇÁé∞ÂÆû‰∏ñÁïåÈóÆÈ¢òÁöÑÂÖàÂÜ≥Êù°‰ª∂„ÄÇÊú¨ÊñáÈ¶ñÂÖàËøõË°å‰∫Ü‰∏ÄÈ°πÂπøÊ≥õÁöÑÂÆûËØÅÁ†îÁ©∂Êù•ËØÑ‰º∞ËøôÁßçËÉΩÂäõ„ÄÇÂà©Áî®Á≤æÂøÉËÆæËÆ°ÁöÑÊï∞ÊçÆÂêàÊàêÂºïÊìéÔºåÊàë‰ª¨ÊûÑÂª∫‰∫ÜMM-HELIXÔºåËøôÊòØ‰∏Ä‰∏™Â§öÊ®°ÊÄÅÂü∫ÂáÜÔºåÂåÖÂê´1260‰∏™Ê†∑Êú¨ÔºåÊ∂µÁõñ42‰∏™ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÂêàÊàê‰ªªÂä°ÔºåËøô‰∫õ‰ªªÂä°ÈúÄË¶ÅËø≠‰ª£ÊÄùËÄÉÂíåÂõûÊ∫Ø„ÄÇÂú®ËØ•Âü∫ÂáÜ‰∏äÁöÑÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÁé∞ÊúâÁöÑMLLMÂú®ÈïøÈìæÂèçÊÄùÊé®ÁêÜÊñπÈù¢Â≠òÂú®ÊòæËëóÁöÑÊÄßËÉΩÁº∫Èô∑„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈôêÂà∂ÔºåÊàë‰ª¨ÁîüÊàê‰∫ÜÂêéËÆ≠ÁªÉÊï∞ÊçÆÔºåÂπ∂Ëøõ‰∏ÄÊ≠•Êé¢Á¥¢‰∫ÜÂà©Áî®Ëøô‰∫õÊï∞ÊçÆÁöÑÂ≠¶‰π†ËåÉÂºè„ÄÇÊàë‰ª¨È¶ñÂÖàÂºÄÂèë‰∫ÜStep-Elicited Response GenerationÊµÅÁ®ãÔºå‰ª•ÂàõÂª∫MM-HELIX-100KÔºåËøôÊòØ‰∏Ä‰∏™Â§ßËßÑÊ®°Êï∞ÊçÆÈõÜÔºåÂåÖÂê´10‰∏á‰∏™È´òË¥®ÈáèÁöÑÂèçÊÄùÊé®ÁêÜËΩ®ËøπÔºåÁî®‰∫éÊåá‰ª§Ë∞ÉÊï¥Èò∂ÊÆµ„ÄÇÈâ¥‰∫éÊ†áÂáÜÁöÑÂº∫ÂåñÂ≠¶‰π†Âú®Â§çÊùÇ‰ªªÂä°‰∏≠Áî±‰∫éÁ®ÄÁñèÁöÑÂ•ñÂä±‰ø°Âè∑ÂíåÁõëÁù£ÂæÆË∞ÉÂêéÁöÑÁÅæÈöæÊÄßÈÅóÂøòËÄåÂ§±Ë¥•ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçËá™ÈÄÇÂ∫îÊ∑∑ÂêàÁ≠ñÁï•‰ºòÂåñ(AHPO)ÔºåËøôÊòØ‰∏ÄÁßçÊñ∞È¢ñÁöÑËÆ≠ÁªÉÁ≠ñÁï•ÔºåÂÆÉÂ∞ÜÁ¶ªÁ∫øÁõëÁù£ÂíåÂú®Á∫ø‰ºòÂåñÂä®ÊÄÅÂú∞Áªü‰∏ÄÂà∞‰∏Ä‰∏™Èò∂ÊÆµ„ÄÇËøôÁßçÁ≠ñÁï•‰ΩøÊ®°ÂûãËÉΩÂ§üÂú®Â•ñÂä±Á®ÄÁñèÊó∂‰ªé‰∏ìÂÆ∂Êï∞ÊçÆ‰∏≠Â≠¶‰π†ÔºåÂπ∂Âú®ÁÜüÁªÉÂêéËøõË°åÁã¨Á´ãÁöÑÊé¢Á¥¢„ÄÇÂΩìÂ∫îÁî®‰∫éQwen2.5-VL-7BÂü∫Á∫øÊó∂ÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®MM-HELIXÂü∫ÂáÜ‰∏äÂÆûÁé∞‰∫Ü+18.6%ÁöÑÂáÜÁ°ÆÁéáÊèêÂçáÔºåÂπ∂Âú®‰∏ÄËà¨ÁöÑÊï∞Â≠¶ÂíåÈÄªËæë‰ªªÂä°‰∏äË°®Áé∞Âá∫Âº∫Â§ßÁöÑÊ≥õÂåñËÉΩÂäõÔºåÂπ≥ÂùáÊÄßËÉΩÊèêÂçá+5.7%„ÄÇÊàë‰ª¨ÁöÑÂ∑•‰ΩúË°®ÊòéÔºåMLLM‰∏≠ÁöÑÂèçÊÄùÊé®ÁêÜÂèØ‰ª•ÊúâÊïàÂú∞Â≠¶‰π†ÂíåÊ≥õÂåñÔºå‰∏∫ÂºÄÂèëÊõ¥Âº∫Â§ßÁöÑMLLMÈì∫Âπ≥‰∫ÜÈÅìË∑Ø„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâMLLMÂú®ÈïøÈìæÂèçÊÄùÊé®ÁêÜËÉΩÂäõ‰∏äÂ≠òÂú®ÊòéÊòæ‰∏çË∂≥ÔºåÊó†Ê≥ïÊúâÊïàËß£ÂÜ≥ÈúÄË¶ÅËø≠‰ª£ÊÄùËÄÉÂíåÂõûÊ∫ØÁöÑÂ§çÊùÇ‰ªªÂä°„ÄÇÊ†áÂáÜÁöÑÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÂú®Â§çÊùÇ‰ªªÂä°‰∏≠Èù¢‰∏¥Â•ñÂä±Á®ÄÁñèÂíåÁÅæÈöæÊÄßÈÅóÂøòÁöÑÈóÆÈ¢òÔºåÈöæ‰ª•ÊúâÊïàËÆ≠ÁªÉÊ®°Âûã„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÊèêÂá∫‰∏ÄÁßçËá™ÈÄÇÂ∫îÊ∑∑ÂêàÁ≠ñÁï•‰ºòÂåñÔºàAHPOÔºâÊñπÊ≥ïÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÂä®ÊÄÅÂú∞ÁªìÂêàÁ¶ªÁ∫øÁõëÁù£Â≠¶‰π†ÂíåÂú®Á∫øÂº∫ÂåñÂ≠¶‰π†ÁöÑ‰ºòÂäø„ÄÇÈÄöËøáÁ¶ªÁ∫øÁõëÁù£Â≠¶‰π†ÔºåÊ®°ÂûãÂèØ‰ª•‰ªé‰∏ìÂÆ∂Êï∞ÊçÆ‰∏≠Â≠¶‰π†Âà∞ÂàùÊ≠•ÁöÑÊé®ÁêÜËÉΩÂäõÔºåÂÖãÊúçÂ•ñÂä±Á®ÄÁñèÁöÑÈóÆÈ¢ò„ÄÇÈÄöËøáÂú®Á∫øÂº∫ÂåñÂ≠¶‰π†ÔºåÊ®°ÂûãÂèØ‰ª•Âú®ÂÆûÈôÖ‰ªªÂä°‰∏≠ËøõË°åÊé¢Á¥¢ÔºåËøõ‰∏ÄÊ≠•ÊèêÂçáÊé®ÁêÜËÉΩÂäõÔºåÂπ∂ÈÅøÂÖçÁÅæÈöæÊÄßÈÅóÂøò„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´Êï∞ÊçÆÂêàÊàê„ÄÅÊåá‰ª§ÂæÆË∞ÉÂíåËá™ÈÄÇÂ∫îÊ∑∑ÂêàÁ≠ñÁï•‰ºòÂåñ‰∏â‰∏™‰∏ªË¶ÅÈò∂ÊÆµ„ÄÇÈ¶ñÂÖàÔºåÂà©Áî®Êï∞ÊçÆÂêàÊàêÂºïÊìéÊûÑÂª∫Â§öÊ®°ÊÄÅÂü∫ÂáÜMM-HELIX„ÄÇÁÑ∂ÂêéÔºå‰ΩøÁî®Step-Elicited Response GenerationÊµÅÁ®ãÁîüÊàêÈ´òË¥®ÈáèÁöÑÂèçÊÄùÊé®ÁêÜËΩ®ËøπÊï∞ÊçÆÈõÜMM-HELIX-100KÔºåÁî®‰∫éÊåá‰ª§ÂæÆË∞É„ÄÇÊúÄÂêéÔºåÈááÁî®AHPOÊñπÊ≥ïÂØπÊ®°ÂûãËøõË°åËÆ≠ÁªÉÔºåËØ•ÊñπÊ≥ïÂä®ÊÄÅÂú∞Ë∞ÉÊï¥Á¶ªÁ∫øÁõëÁù£ÂíåÂú®Á∫ø‰ºòÂåñÁöÑÊØî‰æã„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöAHPOÊòØËÆ∫ÊñáÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπ„ÄÇÂÆÉ‰∏é‰º†ÁªüÁöÑÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ï‰∏çÂêåÔºåËÉΩÂ§üÊ†πÊçÆÊ®°ÂûãÁöÑÂ≠¶‰π†Áä∂ÊÄÅËá™ÈÄÇÂ∫îÂú∞Ë∞ÉÊï¥ËÆ≠ÁªÉÁ≠ñÁï•„ÄÇÂΩìÊ®°ÂûãÂ§Ñ‰∫éÂ≠¶‰π†ÂàùÊúüÔºåÂ•ñÂä±‰ø°Âè∑Á®ÄÁñèÊó∂ÔºåAHPO‰æßÈáç‰∫éÁ¶ªÁ∫øÁõëÁù£Â≠¶‰π†ÔºåÂà©Áî®‰∏ìÂÆ∂Êï∞ÊçÆËøõË°åÊåáÂØº„ÄÇÂΩìÊ®°ÂûãÂÖ∑Â§á‰∏ÄÂÆöÁöÑÊé®ÁêÜËÉΩÂäõÂêéÔºåAHPO‰æßÈáç‰∫éÂú®Á∫øÂº∫ÂåñÂ≠¶‰π†ÔºåÈºìÂä±Ê®°ÂûãËøõË°åËá™‰∏ªÊé¢Á¥¢„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöAHPOÁöÑÂÖ≥ÈîÆËÆæËÆ°Âú®‰∫éÂä®ÊÄÅË∞ÉÊï¥Á¶ªÁ∫øÁõëÁù£ÂíåÂú®Á∫ø‰ºòÂåñÁöÑÊØî‰æã„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåËÆ∫ÊñáËÆæËÆ°‰∫Ü‰∏Ä‰∏™Ëá™ÈÄÇÂ∫îÁ≥ªÊï∞ÔºåËØ•Á≥ªÊï∞Ê†πÊçÆÊ®°ÂûãÁöÑË°®Áé∞Âä®ÊÄÅÂèòÂåñ„ÄÇÂΩìÊ®°ÂûãË°®Áé∞ËæÉÂ∑ÆÊó∂ÔºåËá™ÈÄÇÂ∫îÁ≥ªÊï∞ËæÉÈ´òÔºåÁ¶ªÁ∫øÁõëÁù£Â≠¶‰π†ÁöÑÊùÉÈáçËæÉÂ§ß„ÄÇÂΩìÊ®°ÂûãË°®Áé∞ËæÉÂ•ΩÊó∂ÔºåËá™ÈÄÇÂ∫îÁ≥ªÊï∞ËæÉ‰ΩéÔºåÂú®Á∫øÂº∫ÂåñÂ≠¶‰π†ÁöÑÊùÉÈáçËæÉÂ§ß„ÄÇÊ≠§Â§ñÔºåËÆ∫ÊñáËøòËÆæËÆ°‰∫ÜÁâπÂÆöÁöÑÂ•ñÂä±ÂáΩÊï∞ÔºåÁî®‰∫éÊåáÂØºÂú®Á∫øÂº∫ÂåñÂ≠¶‰π†ËøáÁ®ã„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊèêÂá∫ÁöÑAHPOÊñπÊ≥ïÂú®MM-HELIXÂü∫ÂáÜÊµãËØï‰∏≠Ôºå‰ΩøQwen2.5-VL-7BÊ®°ÂûãÁöÑÂáÜÁ°ÆÁéáÊèêÂçá‰∫Ü18.6%„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïÂú®ÈÄöÁî®Êï∞Â≠¶ÂíåÈÄªËæë‰ªªÂä°‰∏ä‰πüË°®Áé∞Âá∫Âº∫Â§ßÁöÑÊ≥õÂåñËÉΩÂäõÔºåÂπ≥ÂùáÊÄßËÉΩÊèêÂçá‰∫Ü5.7%„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéÔºåAHPOËÉΩÂ§üÊúâÊïàÊèêÂçáMLLMÁöÑÈïøÈìæÂèçÊÄùÊé®ÁêÜËÉΩÂäõÔºåÂπ∂ÂÖ∑ÊúâËâØÂ•ΩÁöÑÊ≥õÂåñÊÄßËÉΩ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÈúÄË¶ÅÂ§çÊùÇÊé®ÁêÜÂíåÂÜ≥Á≠ñÁöÑÈ¢ÜÂüüÔºå‰æãÂ¶ÇÊô∫ËÉΩÂÆ¢Êúç„ÄÅËá™Âä®È©æÈ©∂„ÄÅÂåªÁñóËØäÊñ≠Á≠â„ÄÇÈÄöËøáÊèêÂçáMLLMÁöÑÈïøÈìæÂèçÊÄùÊé®ÁêÜËÉΩÂäõÔºåÂèØ‰ª•‰ΩøÂÖ∂Êõ¥Â•ΩÂú∞ÁêÜËß£ÂíåËß£ÂÜ≥Áé∞ÂÆû‰∏ñÁïå‰∏≠ÁöÑÂ§çÊùÇÈóÆÈ¢òÔºå‰ªéËÄåÊèêÈ´òËá™Âä®ÂåñÊ∞¥Âπ≥ÂíåÂÜ≥Á≠ñË¥®Èáè„ÄÇÊú™Êù•ÔºåËØ•ÊäÄÊúØÊúâÊúõÊé®Âä®‰∫∫Â∑•Êô∫ËÉΩÂú®Êõ¥ÂπøÊ≥õÈ¢ÜÂüüÁöÑÂ∫îÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> While current Multimodal Large Language Models (MLLMs) have demonstrated proficiency in reasoning tasks such as mathematics and logic, their capacity for long-chain reflective reasoning, a prerequisite for solving complex real-world problems, remains largely underexplored. In this work, we first conduct an extensive empirical investigation to evaluate this capability. Leveraging a carefully designed data synthesis engine, we construct MM-HELIX, a multimodal benchmark consisting 1,260 samples of 42 challenging synthetic tasks that require iterative thinking and backtracking. Empirical results on this benchmark reveal that existing MLLMs exhibit significant performance deficits in long-chain reflective reasoning. To address this limitation, we generate post-training data and further explore learning paradigms for exploiting such data. We first develop the Step-Elicited Response Generation pipeline to create MM-HELIX-100K, a large-scale dataset of 100k high-quality, reflective reasoning traces for instruction-tuning stage. Given that standard Reinforcement Learning fails on complex tasks due to sparse reward signals and catastrophic forgetting after Supervised Fine-Tuning, we propose Adaptive Hybrid Policy Optimization (AHPO), a novel training strategy that dynamically unifies offline supervision and online optimization into a single stage. This strategy enables the model to learn from expert data when rewards are sparse and conduct independent exploration once proficient. When applied to the Qwen2.5-VL-7B baseline, our method achieves a +18.6\% accuracy improvement on MM-HELIX benchmark and demonstrates strong generalization with a +5.7\% average performance gain on general mathematic and logic tasks. Our work demonstrate that reflective reasoning in MLLMs can be effectively learned and generalized, paving the way for developing more capable MLLMs.

