---
layout: default
title: Improving Temporal Understanding Logic Consistency in Video-Language Models via Attention Enhancement
---

# Improving Temporal Understanding Logic Consistency in Video-Language Models via Attention Enhancement

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.08138" target="_blank" class="toolbar-btn">arXiv: 2510.08138v1</a>
    <a href="https://arxiv.org/pdf/2510.08138.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.08138v1" 
            onclick="toggleFavorite(this, '2510.08138v1', 'Improving Temporal Understanding Logic Consistency in Video-Language Models via Attention Enhancement')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Chengzhi Li, Heyan Huang, Ping Jian, Zhen Yang, Yaning Tian

**ÂàÜÁ±ª**: cs.CV, cs.AI, cs.MM

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-09

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Êó∂Â∫èÊù°‰ª∂Ê≥®ÊÑèÂäõÈîêÂåñ(TCAS)ÊñπÊ≥ïÔºåÊèêÂçáËßÜÈ¢ëËØ≠Ë®ÄÊ®°ÂûãÊó∂Â∫èÁêÜËß£ÈÄªËæë‰∏ÄËá¥ÊÄß**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËßÜÈ¢ëËØ≠Ë®ÄÊ®°Âûã` `Êó∂Â∫èÁêÜËß£` `ÈÄªËæë‰∏ÄËá¥ÊÄß` `Ê≥®ÊÑèÂäõÊú∫Âà∂` `Ë∑®Ê®°ÊÄÅÂ≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËßÜÈ¢ëËØ≠Ë®ÄÊ®°ÂûãÂú®Â§ÑÁêÜÂü∫‰∫éÁõ∏ÂêåËßÜÈ¢ëÂÜÖÂÆπÁöÑ‰∏çÂêåÊèêÈóÆÊó∂ÔºåÂÆπÊòì‰∫ßÁîüÈÄªËæë‰∏ç‰∏ÄËá¥ÁöÑÂõûÁ≠îÔºåÊ†πÊú¨ÂéüÂõ†Â∞ö‰∏çÊòéÁ°Æ„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫Êó∂Â∫èÊù°‰ª∂Ê≥®ÊÑèÂäõÈîêÂåñ(TCAS)ÊñπÊ≥ïÔºåÈÄöËøáÂ¢ûÂº∫Ê®°ÂûãÂå∫ÂàÜ‰∏çÂêåÊó∂Èó¥Êà≥ËßÜÈ¢ëtokenÁöÑËÉΩÂäõÔºåÊèêÂçáÊó∂Â∫èÁêÜËß£ÈÄªËæë‰∏ÄËá¥ÊÄß„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåTCASÊòæËëóÊèêÂçá‰∫ÜËßÜÈ¢ëËØ≠Ë®ÄÊ®°ÂûãÁöÑÊó∂Èó¥ÈÄªËæë‰∏ÄËá¥ÊÄßÔºåÂπ∂Âú®ËßÜÈ¢ëÊó∂Â∫è grounding ‰ªªÂä°‰∏≠ÂèñÂæó‰∫ÜÊÄßËÉΩÊèêÂçá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã(LLMs)Â∏∏Â∏∏‰∫ßÁîüËá™Áõ∏ÁüõÁõæÁöÑËæìÂá∫Ôºå‰∏•ÈáçÂΩ±Âìç‰∫ÜÂÆÉ‰ª¨ÁöÑÂèØÈù†ÊÄßÔºåÂπ∂ÈòªÁ¢ç‰∫ÜÂÆÉ‰ª¨Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÈááÁî®„ÄÇÂú®ËßÜÈ¢ëËØ≠Ë®ÄÊ®°Âûã(Video-LLMs)‰∏≠ÔºåËøôÁßçÁé∞Ë±°ÊúÄËøëÂºïËµ∑‰∫ÜÁ†îÁ©∂‰∫∫ÂëòÁöÑÂÖ≥Ê≥®„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåËøô‰∫õÊ®°ÂûãÊó†Ê≥ïÂØπÂÖ∂Âü∫‰∫é grounding ËæìÂá∫ÁöÑÈáä‰πâÈóÆÈ¢òÊèê‰æõÈÄªËæë‰∏ä‰∏ÄËá¥ÁöÑÂìçÂ∫î„ÄÇÁÑ∂ËÄåÔºåËøôÁßçÁé∞Ë±°ÁöÑÊ†πÊú¨ÂéüÂõ†‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜÊé¢Á¥¢„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨ÈááÁî®‰∫Ü‰∏ÄÁßçÂèØËß£ÈáäÊÄßÈ©±Âä®ÁöÑÊñπÊ≥ïÊù•ÂàÜÊûê„ÄÅÁªüËÆ°ÊÄªÁªìÂíåÂπ≤È¢ÑËØ•Áé∞Ë±°ÁöÑÊΩúÂú®Âõ†Á¥†„ÄÇÊàë‰ª¨ÂèëÁé∞ÔºåÂìçÂ∫î‰∏ç‰∏ÄËá¥ÁöÑ‰∏ªË¶ÅÂéüÂõ†‰πã‰∏ÄÊòØË∑®Ê®°ÊÄÅÊ≥®ÊÑèÂäõÂ§¥Êó†Ê≥ïÊúâÊïàÂú∞Âå∫ÂàÜ‰∏çÂêåÊó∂Èó¥Êà≥ÁöÑËßÜÈ¢ë tokens„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫Êó∂Â∫èÊù°‰ª∂Ê≥®ÊÑèÂäõÈîêÂåñ(TCAS)ÁöÑÊ≥®ÊÑèÂäõÂ¢ûÂº∫ÊñπÊ≥ïÔºåËØ•ÊñπÊ≥ïÊûÑÂª∫‰∫Ü‰∏Ä‰∏™Âü∫‰∫éÊ≥®ÊÑèÂäõÂå∫ÂàÜÁöÑÂ¢ûÂº∫ÁõÆÊ†áÔºå‰ª•Â¢ûÂº∫Ê®°ÂûãÁöÑÊó∂Èó¥ÂàÜËæ®ÁéáËÉΩÂäõÔºå‰ªéËÄåÊèêÈ´òÂÖ∂Êó∂Èó¥ÁêÜËß£ÈÄªËæë‰∏ÄËá¥ÊÄß„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÊòæËëóÊèêÈ´ò‰∫Ü Video-LLMs ÁöÑÊó∂Èó¥ÈÄªËæë‰∏ÄËá¥ÊÄß„ÄÇËøõ‰∏ÄÊ≠•ÁöÑÂèØËß£ÈáäÊÄßÂàÜÊûêË°®ÊòéÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÁ°ÆÂÆûÊèêÈ´ò‰∫ÜÊ≥®ÊÑèÂäõÂ§¥ÁöÑÊó∂Èó¥ÂèØÂå∫ÂàÜÊÄßÔºåÈ™åËØÅ‰∫ÜÊàë‰ª¨ÁöÑÁªìËÆ∫„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®‰∏ÄËà¨ÁöÑËßÜÈ¢ëÊó∂Â∫è grounding ‰ªªÂä°‰∏≠‰πüÂèñÂæó‰∫ÜÊÄßËÉΩÊèêÂçáÔºåÁ™ÅÂá∫‰∫ÜÊó∂Èó¥ÈÄªËæë‰∏ÄËá¥ÊÄßÊòØÊó∂Èó¥ÁêÜËß£ÁöÑÁì∂È¢à„ÄÇÈÄöËøáÂ¢ûÂº∫‰∏ÄËá¥ÊÄßÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÊé®Âä®‰∫ÜËßÜÈ¢ëÊó∂Èó¥ÁêÜËß£ÁöÑÊòæËëóËøõÂ±ï„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËßÜÈ¢ëËØ≠Ë®ÄÊ®°ÂûãÂú®ÁêÜËß£ËßÜÈ¢ëÂÜÖÂÆπÊó∂ÔºåÂØπ‰∫éÂü∫‰∫éÁõ∏ÂêåËßÜÈ¢ëÂÜÖÂÆπÁöÑ‰∏çÂêåÊèêÈóÆÔºåÁªèÂ∏∏ÁªôÂá∫ÈÄªËæë‰∏ç‰∏ÄËá¥ÁöÑÂõûÁ≠î„ÄÇÁé∞ÊúâÊñπÊ≥ïÁº∫‰πèÂØπËøôÁßç‰∏ç‰∏ÄËá¥ÊÄßÁöÑÊ∑±ÂÖ•ÂàÜÊûêÔºå‰ª•ÂèäÊúâÊïàÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇÁóõÁÇπÂú®‰∫éË∑®Ê®°ÊÄÅÊ≥®ÊÑèÂäõÊú∫Âà∂Êó†Ê≥ïÊúâÊïàÂå∫ÂàÜ‰∏çÂêåÊó∂Èó¥Êà≥ÁöÑËßÜÈ¢ë tokensÔºåÂØºËá¥Ê®°ÂûãÊó†Ê≥ïÂáÜÁ°ÆÊçïÊçâËßÜÈ¢ë‰∏≠ÁöÑÊó∂Â∫è‰ø°ÊÅØ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÂ¢ûÂº∫Ê®°ÂûãÂØπ‰∏çÂêåÊó∂Èó¥Êà≥ËßÜÈ¢ë tokens ÁöÑÂå∫ÂàÜËÉΩÂäõÔºå‰ªéËÄåÊèêÈ´òÂÖ∂Êó∂Â∫èÁêÜËß£ÁöÑÈÄªËæë‰∏ÄËá¥ÊÄß„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÈÄöËøáÂºïÂÖ•‰∏Ä‰∏™È¢ùÂ§ñÁöÑÊçüÂ§±ÂáΩÊï∞ÔºåÈºìÂä±Ê≥®ÊÑèÂäõÂ§¥Êõ¥Âä†ÂÖ≥Ê≥®‰∏çÂêåÊó∂Èó¥Êà≥‰πãÈó¥ÁöÑÂ∑ÆÂºÇÔºå‰ªéËÄåÊèêÈ´òÊ®°ÂûãÁöÑÊó∂Èó¥ÂàÜËæ®Áéá„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊ°ÜÊû∂ÊòØÂú®Áé∞ÊúâÁöÑËßÜÈ¢ëËØ≠Ë®ÄÊ®°ÂûãÂü∫Á°Ä‰∏äÔºåÂ¢ûÂä†‰∏Ä‰∏™Êó∂Â∫èÊù°‰ª∂Ê≥®ÊÑèÂäõÈîêÂåñ(TCAS)Ê®°Âùó„ÄÇËØ•Ê®°Âùó‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Èò∂ÊÆµÔºö1) ‰ªéËßÜÈ¢ë‰∏≠ÊèêÂèñËßÜËßâÁâπÂæÅÔºõ2) ‰ΩøÁî®Ë∑®Ê®°ÊÄÅÊ≥®ÊÑèÂäõÊú∫Âà∂Â∞ÜËßÜËßâÁâπÂæÅ‰∏éÊñáÊú¨ÁâπÂæÅËøõË°åËûçÂêàÔºõ3) ËÆ°ÁÆóÊ≥®ÊÑèÂäõÂ§¥ÂØπ‰∏çÂêåÊó∂Èó¥Êà≥ËßÜÈ¢ë tokens ÁöÑÂå∫ÂàÜÂ∫¶Ôºõ4) ‰ΩøÁî® TCAS ÊçüÂ§±ÂáΩÊï∞‰ºòÂåñÊ®°ÂûãÔºåÂ¢ûÂº∫Ê≥®ÊÑèÂäõÂ§¥ÁöÑÊó∂Èó¥ÂàÜËæ®ÁéáËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÊèêÂá∫‰∫ÜÊó∂Â∫èÊù°‰ª∂Ê≥®ÊÑèÂäõÈîêÂåñ(TCAS)ÊñπÊ≥ïÔºåËØ•ÊñπÊ≥ïÈÄöËøáÊûÑÂª∫‰∏Ä‰∏™Âü∫‰∫éÊ≥®ÊÑèÂäõÂå∫ÂàÜÁöÑÂ¢ûÂº∫ÁõÆÊ†áÔºåÊòæÂºèÂú∞ÊèêÂçáÊ®°ÂûãÁöÑÊó∂Èó¥ÂàÜËæ®ÁéáËÉΩÂäõ„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåTCAS Êõ¥Âä†ÂÖ≥Ê≥®Ê®°ÂûãÂÜÖÈÉ®ÁöÑÊ≥®ÊÑèÂäõÊú∫Âà∂ÔºåÈÄöËøá‰ºòÂåñÊ≥®ÊÑèÂäõÂ§¥ÁöÑË°å‰∏∫Êù•ÊèêÈ´òÊ®°ÂûãÁöÑÊó∂Â∫èÁêÜËß£ËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöTCAS ÁöÑÂÖ≥ÈîÆËÆæËÆ°Âú®‰∫é TCAS ÊçüÂ§±ÂáΩÊï∞„ÄÇËØ•ÊçüÂ§±ÂáΩÊï∞ÁöÑÁõÆÊ†áÊòØÊúÄÂ§ßÂåñÊ≥®ÊÑèÂäõÂ§¥ÂØπ‰∏çÂêåÊó∂Èó¥Êà≥ËßÜÈ¢ë tokens ÁöÑÂå∫ÂàÜÂ∫¶„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÂØπ‰∫éÊØè‰∏™Ê≥®ÊÑèÂäõÂ§¥ÔºåËÆ°ÁÆóÂÖ∂ÂØπ‰∏çÂêåÊó∂Èó¥Êà≥ËßÜÈ¢ë tokens ÁöÑÊ≥®ÊÑèÂäõÊùÉÈáçÂàÜÂ∏ÉÔºåÁÑ∂Âêé‰ΩøÁî®‰∫§ÂèâÁÜµÊçüÂ§±ÂáΩÊï∞Êù•ÈºìÂä±Ëøô‰∫õÂàÜÂ∏É‰πãÈó¥ÁöÑÂ∑ÆÂºÇ„ÄÇÊ≠§Â§ñÔºå‰∏∫‰∫ÜÈÅøÂÖçËøáÂ∫¶‰ºòÂåñÔºåËøòÂºïÂÖ•‰∫Ü‰∏Ä‰∏™Ê≠£ÂàôÂåñÈ°πÔºåÈôêÂà∂Ê≥®ÊÑèÂäõÊùÉÈáçÁöÑÂèòÂåñÂπÖÂ∫¶„ÄÇÂÖ∑‰ΩìÁöÑÂèÇÊï∞ËÆæÁΩÆÂíåÁΩëÁªúÁªìÊûÑÁªÜËäÇÂú®ËÆ∫Êñá‰∏≠ÊúâËØ¶ÁªÜÊèèËø∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊèêÂá∫ÁöÑ TCAS ÊñπÊ≥ïÊòæËëóÊèêÈ´ò‰∫ÜËßÜÈ¢ëËØ≠Ë®ÄÊ®°ÂûãÁöÑÊó∂Èó¥ÈÄªËæë‰∏ÄËá¥ÊÄß„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÂú®ÊèêÂá∫ÁöÑËØÑ‰º∞ÊåáÊ†á‰∏äÔºåTCAS ÊñπÊ≥ïÁõ∏ÊØîÂü∫Á∫øÊ®°ÂûãÂèñÂæó‰∫ÜÊòæËëóÁöÑÊèêÂçá„ÄÇÊ≠§Â§ñÔºåTCAS ÊñπÊ≥ïËøòÂú®‰∏ÄËà¨ÁöÑËßÜÈ¢ëÊó∂Â∫è grounding ‰ªªÂä°‰∏≠ÂèñÂæó‰∫ÜÊÄßËÉΩÊèêÂçáÔºåÈ™åËØÅ‰∫ÜÊó∂Èó¥ÈÄªËæë‰∏ÄËá¥ÊÄßÊòØÊó∂Èó¥ÁêÜËß£ÁöÑÁì∂È¢à„ÄÇÂèØËß£ÈáäÊÄßÂàÜÊûêË°®ÊòéÔºåTCAS ÊñπÊ≥ïÁ°ÆÂÆûÊèêÈ´ò‰∫ÜÊ≥®ÊÑèÂäõÂ§¥ÁöÑÊó∂Èó¥ÂèØÂå∫ÂàÜÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊô∫ËÉΩËßÜÈ¢ëÂàÜÊûê„ÄÅËßÜÈ¢ëÈóÆÁ≠î„ÄÅËßÜÈ¢ëÊëòË¶ÅÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÊèêÈ´òËßÜÈ¢ëËØ≠Ë®ÄÊ®°ÂûãÁöÑÊó∂Â∫èÁêÜËß£ËÉΩÂäõÔºåÂèØ‰ª•‰ΩøÂÖ∂Êõ¥Â•ΩÂú∞ÁêÜËß£ËßÜÈ¢ëÂÜÖÂÆπÔºå‰ªéËÄå‰∏∫Áî®Êà∑Êèê‰æõÊõ¥ÂáÜÁ°Æ„ÄÅÊõ¥ÂèØÈù†ÁöÑÊúçÂä°„ÄÇ‰æãÂ¶ÇÔºåÂú®Êô∫ËÉΩÁõëÊéßÈ¢ÜÂüüÔºåÂèØ‰ª•Âà©Áî®ËØ•ÊäÄÊúØÊù•ËØÜÂà´ÂºÇÂ∏∏Ë°å‰∏∫ÔºõÂú®ËßÜÈ¢ëÊêúÁ¥¢È¢ÜÂüüÔºåÂèØ‰ª•Âà©Áî®ËØ•ÊäÄÊúØÊù•ÊèêÈ´òÊêúÁ¥¢ÁªìÊûúÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Large language models (LLMs) often generate self-contradictory outputs, which severely impacts their reliability and hinders their adoption in practical applications. In video-language models (Video-LLMs), this phenomenon recently draws the attention of researchers. Specifically, these models fail to provide logically consistent responses to rephrased questions based on their grounding outputs. However, the underlying causes of this phenomenon remain underexplored. In this work, we adopt an interpretability-driven approach to analyze, statistically summarize, and intervention the potential factors of the phenomenon. We find that one of the primary reasons for the inconsistency in responses lies in the inability of cross-modal attention heads to effectively distinguish video tokens across different timestamps. To address this, we propose an attention enhancement method called Temporally Conditioned Attention Sharpening (TCAS), which constructs an enhancement objective based on attention distinctions to enhance the model's temporal resolution capability, thereby improving its temporal understanding logic consistency. Experimental results demonstrate that our method significantly enhances the temporal logic consistency of Video-LLMs. Further interpretability analyses reveal that our method indeed improves the temporal discriminability of attention heads, validating our conclusions. Additionally, our method achieves performance improvements in general video temporal grounding tasks, highlighting that temporal logic consistency is a bottleneck in temporal understanding. By enhancing consistency, our method drives significant progress in video temporal understanding.

