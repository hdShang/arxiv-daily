---
layout: default
title: Dream to Recall: Imagination-Guided Experience Retrieval for Memory-Persistent Vision-and-Language Navigation
---

# Dream to Recall: Imagination-Guided Experience Retrieval for Memory-Persistent Vision-and-Language Navigation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.08553" target="_blank" class="toolbar-btn">arXiv: 2510.08553v1</a>
    <a href="https://arxiv.org/pdf/2510.08553.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.08553v1" 
            onclick="toggleFavorite(this, '2510.08553v1', 'Dream to Recall: Imagination-Guided Experience Retrieval for Memory-Persistent Vision-and-Language Navigation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yunzhe Xu, Yiyuan Pan, Zhe Liu

**ÂàÜÁ±ª**: cs.CV, cs.AI, cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-09

**Â§áÊ≥®**: 14 pages, 6 figures, 13 tables

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/xyz9911/Memoir)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**MemoirÔºöÊèêÂá∫Âü∫‰∫éÊÉ≥Ë±°ÂºïÂØºÁöÑÁªèÈ™åÊ£ÄÁ¥¢ÊñπÊ≥ïÔºåÊèêÂçáËÆ∞ÂøÜÊåÅ‰πÖÊÄßËßÜËßâËØ≠Ë®ÄÂØºËà™ÊÄßËÉΩ„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâËØ≠Ë®ÄÂØºËà™` `ËÆ∞ÂøÜÊåÅ‰πÖÊÄß` `ÁªèÈ™åÊ£ÄÁ¥¢` `‰∏ñÁïåÊ®°Âûã` `Ë°å‰∏∫Ê®°Âºè`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËÆ∞ÂøÜÊåÅ‰πÖÊÄßVLNÊñπÊ≥ïÁº∫‰πèÊúâÊïàÁöÑËÆ∞ÂøÜËÆøÈóÆÊú∫Âà∂Ôºå‰∏îÂøΩÁï•‰∫ÜÂØºËà™Ë°å‰∏∫Ê®°ÂºèÔºåÈôêÂà∂‰∫ÜÊÄßËÉΩÊèêÂçá„ÄÇ
2. MemoirÂà©Áî®ËØ≠Ë®ÄÊù°‰ª∂ÁöÑ‰∏ñÁïåÊ®°ÂûãÊÉ≥Ë±°Êú™Êù•Áä∂ÊÄÅÔºå‰Ωú‰∏∫Ê£ÄÁ¥¢Êü•ËØ¢ÔºåÈÄâÊã©ÊÄßÊ£ÄÁ¥¢ÁéØÂ¢ÉËßÇÂØüÂíåË°å‰∏∫ÂéÜÂè≤„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåMemoirÂú®Â§ö‰∏™ËÆ∞ÂøÜÊåÅ‰πÖÊÄßVLNÂü∫ÂáÜ‰∏äÊòæËëóÊèêÂçáÊÄßËÉΩÔºåSPLÊèêÂçá5.4%ÔºåËÆ≠ÁªÉÈÄüÂ∫¶ÊèêÂçá8.3ÂÄç„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËßÜËßâËØ≠Ë®ÄÂØºËà™(VLN)Ë¶ÅÊ±ÇÊô∫ËÉΩ‰ΩìÂú®ÁéØÂ¢É‰∏≠ÈÅµÂæ™Ëá™ÁÑ∂ËØ≠Ë®ÄÊåá‰ª§ÔºåËÄåËÆ∞ÂøÜÊåÅ‰πÖÊÄßÂèò‰ΩìÂàôÈúÄË¶ÅÈÄöËøáÁßØÁ¥ØÁöÑÁªèÈ™åÈÄêÊ≠•ÊîπËøõ„ÄÇÁé∞ÊúâÁöÑËÆ∞ÂøÜÊåÅ‰πÖÊÄßVLNÊñπÊ≥ïÈù¢‰∏¥ÂÖ≥ÈîÆÈôêÂà∂ÔºöÁº∫‰πèÊúâÊïàÁöÑËÆ∞ÂøÜËÆøÈóÆÊú∫Âà∂Ôºå‰æùËµñ‰∫éÊï¥‰∏™ËÆ∞ÂøÜÁöÑÊï¥ÂêàÊàñÂõ∫ÂÆöËåÉÂõ¥ÁöÑÊü•ÊâæÔºåÂπ∂‰∏î‰∏ªË¶ÅÂ≠òÂÇ®ÁéØÂ¢ÉËßÇÂØüÔºåÂøΩÁï•‰∫ÜÁºñÁ†ÅÊúâ‰ª∑ÂÄºÂÜ≥Á≠ñÁ≠ñÁï•ÁöÑÂØºËà™Ë°å‰∏∫Ê®°Âºè„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫ÜMemoirÔºåÂÆÉÈááÁî®ÊÉ≥Ë±°‰Ωú‰∏∫Áî±ÊòæÂºèËÆ∞ÂøÜÊîØÊåÅÁöÑÊ£ÄÁ¥¢Êú∫Âà∂Ôºö‰∏Ä‰∏™‰∏ñÁïåÊ®°ÂûãÊÉ≥Ë±°Êú™Êù•ÁöÑÂØºËà™Áä∂ÊÄÅ‰Ωú‰∏∫Êü•ËØ¢Ôºå‰ª•ÈÄâÊã©ÊÄßÂú∞Ê£ÄÁ¥¢Áõ∏ÂÖ≥ÁöÑÁéØÂ¢ÉËßÇÂØüÂíåË°å‰∏∫ÂéÜÂè≤„ÄÇËØ•ÊñπÊ≥ïÂåÖÊã¨Ôºö1)‰∏Ä‰∏™ËØ≠Ë®ÄÊù°‰ª∂ÁöÑ‰∏ñÁïåÊ®°ÂûãÔºåÊÉ≥Ë±°Êú™Êù•Áä∂ÊÄÅÔºåÂÖ∑ÊúâÂèåÈáçÁõÆÁöÑÔºöÁºñÁ†ÅÁªèÈ™å‰ª•‰æõÂ≠òÂÇ®ÂíåÁîüÊàêÊ£ÄÁ¥¢Êü•ËØ¢Ôºõ2)Ê∑∑ÂêàËßÜÁÇπÁ∫ßÂà´ËÆ∞ÂøÜÔºåÂ∞ÜËßÇÂØüÂíåË°å‰∏∫Ê®°ÂºèÈîöÂÆöÂà∞ËßÜÁÇπÔºåÂÆûÁé∞Ê∑∑ÂêàÊ£ÄÁ¥¢Ôºõ3)‰∏Ä‰∏™ÁªèÈ™åÂ¢ûÂº∫ÁöÑÂØºËà™Ê®°ÂûãÔºåÈÄöËøá‰∏ìÈó®ÁöÑÁºñÁ†ÅÂô®Êï¥ÂêàÊ£ÄÁ¥¢Âà∞ÁöÑÁü•ËØÜ„ÄÇÂú®ÂÖ∑Êúâ10‰∏™‰∏çÂêåÊµãËØïÂú∫ÊôØÁöÑÂêÑÁßçËÆ∞ÂøÜÊåÅ‰πÖÊÄßVLNÂü∫ÂáÜ‰∏äÁöÑÂπøÊ≥õËØÑ‰º∞ËØÅÊòé‰∫ÜMemoirÁöÑÊúâÊïàÊÄßÔºöÂú®ÊâÄÊúâÂú∫ÊôØ‰∏≠ÈÉΩÊúâÊòæËëóÁöÑÊîπËøõÔºåÂú®IR2R‰∏äÊØîÊúÄ‰Ω≥ËÆ∞ÂøÜÊåÅ‰πÖÊÄßÂü∫Á∫øÊèêÈ´ò‰∫Ü5.4%ÁöÑSPLÔºåÂêåÊó∂ËÆ≠ÁªÉÈÄüÂ∫¶ÊèêÈ´ò‰∫Ü8.3ÂÄçÔºåÊé®ÁêÜÂÜÖÂ≠òÂáèÂ∞ë‰∫Ü74%„ÄÇÁªìÊûúÈ™åËØÅ‰∫ÜÁéØÂ¢ÉÂíåË°å‰∏∫ËÆ∞ÂøÜÁöÑÈ¢ÑÊµãÊÄßÊ£ÄÁ¥¢ËÉΩÂ§üÂÆûÁé∞Êõ¥ÊúâÊïàÁöÑÂØºËà™ÔºåÂàÜÊûêË°®ÊòéËøôÁßçÊÉ≥Ë±°ÂºïÂØºÁöÑËåÉ‰æãÂÖ∑ÊúâÂæàÂ§ßÁöÑÊèêÂçáÁ©∫Èó¥(73.3% vs 93.4%‰∏äÈôê)„ÄÇ‰ª£Á†Å‰Ωç‰∫éhttps://github.com/xyz9911/Memoir„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÁöÑËÆ∞ÂøÜÊåÅ‰πÖÊÄßËßÜËßâËØ≠Ë®ÄÂØºËà™ÔºàVLNÔºâÊñπÊ≥ïÂú®Âà©Áî®ÂéÜÂè≤ÁªèÈ™åÊñπÈù¢Â≠òÂú®‰∏çË∂≥„ÄÇÂÆÉ‰ª¨Ë¶Å‰πàÁÆÄÂçïÂú∞Â∞ÜÊâÄÊúâÂéÜÂè≤‰ø°ÊÅØÊï¥ÂêàÔºåË¶Å‰πàÈááÁî®Âõ∫ÂÆöËåÉÂõ¥ÁöÑÊü•ÊâæÔºåÁº∫‰πèÈÄâÊã©ÊÄßÂú∞ËÆøÈóÆÂíåÂà©Áî®Áõ∏ÂÖ≥ËÆ∞ÂøÜÁöÑËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåÁé∞ÊúâÊñπÊ≥ï‰∏ªË¶ÅÂÖ≥Ê≥®ÁéØÂ¢ÉËßÇÂØüÔºåÂøΩÁï•‰∫ÜÂØºËà™ËøáÁ®ã‰∏≠ÁöÑË°å‰∏∫Ê®°ÂºèÔºåËøô‰∫õÊ®°ÂºèËï¥Âê´ÁùÄÈáçË¶ÅÁöÑÂÜ≥Á≠ñ‰ø°ÊÅØ„ÄÇÂõ†Ê≠§ÔºåÂ¶Ç‰ΩïÊúâÊïàÂú∞ËÆøÈóÆÂíåÂà©Áî®ÂéÜÂè≤ÁªèÈ™åÔºàÂåÖÊã¨ÁéØÂ¢ÉËßÇÂØüÂíåË°å‰∏∫Ê®°ÂºèÔºâÊòØËØ•ËÆ∫ÊñáË¶ÅËß£ÂÜ≥ÁöÑÊ†∏ÂøÉÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËØ•ËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®‚ÄúÊÉ≥Ë±°‚Äù‰Ωú‰∏∫‰∏ÄÁßçÊ£ÄÁ¥¢Êú∫Âà∂„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÈÄöËøá‰∏Ä‰∏™ËØ≠Ë®ÄÊù°‰ª∂ÁöÑ‰∏ñÁïåÊ®°ÂûãÔºåÊô∫ËÉΩ‰ΩìÂèØ‰ª•‚ÄúÊÉ≥Ë±°‚ÄùÊú™Êù•ÁöÑÂØºËà™Áä∂ÊÄÅÔºåÂπ∂Â∞ÜËøô‰∫õÊÉ≥Ë±°ÁöÑÁä∂ÊÄÅ‰Ωú‰∏∫Êü•ËØ¢ÔºåÁî®‰∫é‰ªéËÆ∞ÂøÜÂ∫ì‰∏≠Ê£ÄÁ¥¢Áõ∏ÂÖ≥ÁöÑÁéØÂ¢ÉËßÇÂØüÂíåË°å‰∏∫ÂéÜÂè≤„ÄÇËøôÁßçÂü∫‰∫éÊÉ≥Ë±°ÁöÑÊ£ÄÁ¥¢ÊñπÂºèËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞ÈÄâÊã©‰∏éÂΩìÂâç‰ªªÂä°Áõ∏ÂÖ≥ÁöÑÂéÜÂè≤ÁªèÈ™åÔºå‰ªéËÄåÊèêÂçáÂØºËà™ÊÄßËÉΩ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöMemoirÁöÑÊäÄÊúØÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰∏â‰∏™Ê®°ÂùóÔºö1) ËØ≠Ë®ÄÊù°‰ª∂ÁöÑ‰∏ñÁïåÊ®°ÂûãÔºöÁî®‰∫éÊÉ≥Ë±°Êú™Êù•Áä∂ÊÄÅÔºåÂπ∂ÁºñÁ†ÅÁªèÈ™å‰ª•‰æõÂ≠òÂÇ®ÂíåÁîüÊàêÊ£ÄÁ¥¢Êü•ËØ¢„ÄÇ2) Ê∑∑ÂêàËßÜÁÇπÁ∫ßÂà´ËÆ∞ÂøÜÔºöÂ∞ÜÁéØÂ¢ÉËßÇÂØüÂíåË°å‰∏∫Ê®°ÂºèÈÉΩÈîöÂÆöÂà∞ËßÜÁÇπÔºåÊîØÊåÅÊ∑∑ÂêàÊ£ÄÁ¥¢„ÄÇ3) ÁªèÈ™åÂ¢ûÂº∫ÁöÑÂØºËà™Ê®°ÂûãÔºöÊï¥ÂêàÊ£ÄÁ¥¢Âà∞ÁöÑÁü•ËØÜÔºåÁî®‰∫éÊåáÂØºÂØºËà™ÂÜ≥Á≠ñ„ÄÇÊï¥‰ΩìÊµÅÁ®ãÊòØÔºåÈ¶ñÂÖàÂà©Áî®‰∏ñÁïåÊ®°ÂûãÊÉ≥Ë±°Êú™Êù•Áä∂ÊÄÅÔºåÁÑ∂Âêé‰ΩøÁî®Ëøô‰∫õÁä∂ÊÄÅ‰Ωú‰∏∫Êü•ËØ¢Ôºå‰ªéÊ∑∑ÂêàËßÜÁÇπÁ∫ßÂà´ËÆ∞ÂøÜ‰∏≠Ê£ÄÁ¥¢Áõ∏ÂÖ≥ÁöÑÁéØÂ¢ÉËßÇÂØüÂíåË°å‰∏∫ÂéÜÂè≤ÔºåÊúÄÂêéÂ∞ÜÊ£ÄÁ¥¢Âà∞ÁöÑ‰ø°ÊÅØËæìÂÖ•Âà∞ÁªèÈ™åÂ¢ûÂº∫ÁöÑÂØºËà™Ê®°Âûã‰∏≠ÔºåÊåáÂØºÊô∫ËÉΩ‰ΩìÁöÑÂØºËà™Ë°å‰∏∫„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫ÜÂü∫‰∫éÊÉ≥Ë±°ÁöÑÁªèÈ™åÊ£ÄÁ¥¢Êú∫Âà∂„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ï‰∏çÂêåÔºåMemoir‰∏çÊòØÁÆÄÂçïÂú∞Êï¥ÂêàÊâÄÊúâÂéÜÂè≤‰ø°ÊÅØÔºåËÄåÊòØÂà©Áî®‰∏ñÁïåÊ®°ÂûãÊÉ≥Ë±°Êú™Êù•Áä∂ÊÄÅÔºåÂπ∂Â∞ÜÂÖ∂‰Ωú‰∏∫Êü•ËØ¢Êù•ÈÄâÊã©ÊÄßÂú∞Ê£ÄÁ¥¢Áõ∏ÂÖ≥ÁªèÈ™å„ÄÇËøôÁßçÊñπÊ≥ïËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞Âà©Áî®ÂéÜÂè≤‰ø°ÊÅØÔºåÂπ∂ÊèêÂçáÂØºËà™ÊÄßËÉΩ„ÄÇÊ≠§Â§ñÔºåMemoirËøòÊèêÂá∫‰∫ÜÊ∑∑ÂêàËßÜÁÇπÁ∫ßÂà´ËÆ∞ÂøÜÔºåÂêåÊó∂Â≠òÂÇ®ÁéØÂ¢ÉËßÇÂØüÂíåË°å‰∏∫Ê®°ÂºèÔºå‰ªéËÄåÊõ¥ÂÖ®Èù¢Âú∞ÊçïÊçâÂéÜÂè≤ÁªèÈ™å„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËØ≠Ë®ÄÊù°‰ª∂ÁöÑ‰∏ñÁïåÊ®°Âûã‰∏≠Ôºå‰ΩøÁî®‰∫ÜTransformerÊû∂ÊûÑÊù•È¢ÑÊµãÊú™Êù•ÁöÑÂØºËà™Áä∂ÊÄÅ„ÄÇÊ∑∑ÂêàËßÜÁÇπÁ∫ßÂà´ËÆ∞ÂøÜÈááÁî®‰∫Ü‰∏ÄÁßçÊ∑∑ÂêàÁ¥¢ÂºïÁªìÊûÑÔºåÂèØ‰ª•ÂêåÊó∂Ê†πÊçÆÁéØÂ¢ÉËßÇÂØüÂíåË°å‰∏∫Ê®°ÂºèËøõË°åÊ£ÄÁ¥¢„ÄÇÁªèÈ™åÂ¢ûÂº∫ÁöÑÂØºËà™Ê®°Âûã‰ΩøÁî®‰∫Ü‰∏ÄÁßçÊ≥®ÊÑèÂäõÊú∫Âà∂Êù•Êï¥ÂêàÊ£ÄÁ¥¢Âà∞ÁöÑÁü•ËØÜ„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨ÂØºËà™ÊçüÂ§±Âíå‰∏ñÁïåÊ®°ÂûãÈ¢ÑÊµãÊçüÂ§±ÔºåÂÖ±Âêå‰ºòÂåñÊï¥‰∏™Ê®°Âûã„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

MemoirÂú®Â§ö‰∏™ËÆ∞ÂøÜÊåÅ‰πÖÊÄßVLNÂü∫ÂáÜ‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇÂú®IR2RÂü∫ÂáÜ‰∏äÔºåMemoirÊØîÊúÄ‰Ω≥ËÆ∞ÂøÜÊåÅ‰πÖÊÄßÂü∫Á∫øÊèêÈ´ò‰∫Ü5.4%ÁöÑSPL„ÄÇÊ≠§Â§ñÔºåMemoirËøòÊòæËëóÊèêÂçá‰∫ÜËÆ≠ÁªÉÈÄüÂ∫¶Ôºà8.3ÂÄçÔºâÂπ∂ÂáèÂ∞ë‰∫ÜÊé®ÁêÜÂÜÖÂ≠òÔºà74%Ôºâ„ÄÇÊ∂àËûçÂÆûÈ™åË°®ÊòéÔºåÂü∫‰∫éÊÉ≥Ë±°ÁöÑÊ£ÄÁ¥¢Êú∫Âà∂ÂíåÊ∑∑ÂêàËßÜÁÇπÁ∫ßÂà´ËÆ∞ÂøÜÈÉΩÂØπÊÄßËÉΩÊèêÂçáÂÅöÂá∫‰∫ÜË¥°ÁåÆ„ÄÇÂàÜÊûêÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ï‰ªçÊúâÂæàÂ§ßÁöÑÊèêÂçáÁ©∫Èó¥Ôºà73.3% vs 93.4%‰∏äÈôêÔºâ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫ÂØºËà™„ÄÅËá™Âä®È©æÈ©∂„ÄÅËôöÊãüÁé∞ÂÆûÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáËÆ©Êô∫ËÉΩ‰ΩìÂÖ∑Â§áÊõ¥Âº∫ÁöÑËÆ∞ÂøÜËÉΩÂäõÂíåÁªèÈ™åÂà©Áî®ËÉΩÂäõÔºåÂèØ‰ª•ÊèêÂçáÂÖ∂Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑÂØºËà™ÊÄßËÉΩÂíåÂÜ≥Á≠ñËÉΩÂäõ„ÄÇ‰æãÂ¶ÇÔºåÂú®‰ªìÂ∫ìÊú∫Âô®‰∫∫‰∏≠ÔºåÂèØ‰ª•Âà©Áî®ËØ•ÊñπÊ≥ïËÆ©Êú∫Âô®‰∫∫ËÆ∞‰Ωè‰πãÂâçÁöÑÂØºËà™Ë∑ØÂæÑÂíåÈÅáÂà∞ÁöÑÈöúÁ¢çÁâ©Ôºå‰ªéËÄåÊõ¥È´òÊïàÂú∞ÂÆåÊàê‰ªªÂä°„ÄÇÂú®Ëá™Âä®È©æÈ©∂È¢ÜÂüüÔºåÂèØ‰ª•Â∏ÆÂä©ËΩ¶ËæÜÊõ¥Â•ΩÂú∞ÁêÜËß£Âë®Âõ¥ÁéØÂ¢ÉÔºåÂπ∂ÂÅöÂá∫Êõ¥ÂÆâÂÖ®ÁöÑÈ©æÈ©∂ÂÜ≥Á≠ñ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Vision-and-Language Navigation (VLN) requires agents to follow natural language instructions through environments, with memory-persistent variants demanding progressive improvement through accumulated experience. Existing approaches for memory-persistent VLN face critical limitations: they lack effective memory access mechanisms, instead relying on entire memory incorporation or fixed-horizon lookup, and predominantly store only environmental observations while neglecting navigation behavioral patterns that encode valuable decision-making strategies. We present Memoir, which employs imagination as a retrieval mechanism grounded by explicit memory: a world model imagines future navigation states as queries to selectively retrieve relevant environmental observations and behavioral histories. The approach comprises: 1) a language-conditioned world model that imagines future states serving dual purposes: encoding experiences for storage and generating retrieval queries; 2) Hybrid Viewpoint-Level Memory that anchors both observations and behavioral patterns to viewpoints, enabling hybrid retrieval; and 3) an experience-augmented navigation model that integrates retrieved knowledge through specialized encoders. Extensive evaluation across diverse memory-persistent VLN benchmarks with 10 distinctive testing scenarios demonstrates Memoir's effectiveness: significant improvements across all scenarios, with 5.4% SPL gains on IR2R over the best memory-persistent baseline, accompanied by 8.3x training speedup and 74% inference memory reduction. The results validate that predictive retrieval of both environmental and behavioral memories enables more effective navigation, with analysis indicating substantial headroom (73.3% vs 93.4% upper bound) for this imagination-guided paradigm. Code at https://github.com/xyz9911/Memoir.

