---
layout: default
title: "TTOM: Test-Time Optimization and Memorization for Compositional Video Generation"
---

# TTOM: Test-Time Optimization and Memorization for Compositional Video Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.07940" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.07940v1</a>
  <a href="https://arxiv.org/pdf/2510.07940.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.07940v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.07940v1', 'TTOM: Test-Time Optimization and Memorization for Compositional Video Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Leigang Qu, Ziyang Wang, Na Zheng, Wenjie Wang, Liqiang Nie, Tat-Seng Chua

**åˆ†ç±»**: cs.CV, cs.AI, cs.CL, cs.LG, cs.MM

**å‘å¸ƒæ—¥æœŸ**: 2025-10-09

**å¤‡æ³¨**: Project page: https://ttom-t2v.github.io/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTTOMï¼šä¸€ç§æµ‹è¯•æ—¶ä¼˜åŒ–ä¸è®°å¿†æ¡†æ¶ï¼Œç”¨äºç»„åˆè§†é¢‘ç”Ÿæˆã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†é¢‘ç”Ÿæˆ` `ç»„åˆç”Ÿæˆ` `æµ‹è¯•æ—¶ä¼˜åŒ–` `è®°å¿†æœºåˆ¶` `è·¨æ¨¡æ€å¯¹é½` `è§†é¢‘åŸºç¡€æ¨¡å‹` `æ—¶ç©ºå¸ƒå±€`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. è§†é¢‘ç”Ÿæˆæ¨¡å‹åœ¨ç»„åˆåœºæ™¯ä¸­é¢ä¸´æŒ‘æˆ˜ï¼Œéš¾ä»¥å‡†ç¡®ç†è§£å’Œç”Ÿæˆå¤æ‚çš„æ—¶ç©ºå…³ç³»ã€‚
2. TTOMæ¡†æ¶é€šè¿‡åœ¨æµ‹è¯•æ—¶ä¼˜åŒ–å’Œè®°å¿†å†å²ä¿¡æ¯ï¼ŒåŠ¨æ€è°ƒæ•´æ¨¡å‹è¾“å‡ºä»¥ç¬¦åˆç»™å®šçš„æ—¶ç©ºå¸ƒå±€ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒTTOMåœ¨ç»„åˆè§†é¢‘ç”Ÿæˆä»»åŠ¡ä¸Šæ˜¾è‘—æå‡äº†æ–‡æœ¬-å›¾åƒå¯¹é½æ•ˆæœï¼Œå¹¶å±•ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†é¢‘åŸºç¡€æ¨¡å‹(VFMs)åœ¨è§†è§‰ç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨ç»„åˆåœºæ™¯ï¼ˆä¾‹å¦‚ï¼Œè¿åŠ¨ã€æ•°é‡å’Œç©ºé—´å…³ç³»ï¼‰ä¸­è¡¨ç°ä¸ä½³ã€‚æœ¬æ–‡æå‡ºæµ‹è¯•æ—¶ä¼˜åŒ–ä¸è®°å¿†(TTOM)ï¼Œè¿™æ˜¯ä¸€ä¸ªæ— éœ€è®­ç»ƒçš„æ¡†æ¶ï¼Œåœ¨æ¨ç†æœŸé—´å°†VFMè¾“å‡ºä¸æ—¶ç©ºå¸ƒå±€å¯¹é½ï¼Œä»¥å®ç°æ›´å¥½çš„æ–‡æœ¬-å›¾åƒå¯¹é½ã€‚ä¸ç°æœ‰å·¥ä½œä¸­ç›´æ¥å¹²é¢„æ½œåœ¨ç©ºé—´æˆ–é€æ ·æœ¬æ³¨æ„åŠ›ä¸åŒï¼Œæˆ‘ä»¬é›†æˆå¹¶ä¼˜åŒ–ç”±é€šç”¨å¸ƒå±€-æ³¨æ„åŠ›ç›®æ ‡å¼•å¯¼çš„æ–°å‚æ•°ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†è§†é¢‘ç”Ÿæˆå½¢å¼åŒ–ä¸ºæµå¼è®¾ç½®ï¼Œå¹¶ä½¿ç”¨å‚æ•°åŒ–è®°å¿†æœºåˆ¶ç»´æŠ¤å†å²ä¼˜åŒ–ä¸Šä¸‹æ–‡ï¼Œè¯¥æœºåˆ¶æ”¯æŒçµæ´»çš„æ“ä½œï¼Œä¾‹å¦‚æ’å…¥ã€è¯»å–ã€æ›´æ–°å’Œåˆ é™¤ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬å‘ç°TTOMè§£è€¦äº†ç»„åˆä¸–ç•ŒçŸ¥è¯†ï¼Œæ˜¾ç¤ºå‡ºå¼ºå¤§çš„å¯è¿ç§»æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚åœ¨T2V-CompBenchå’ŒVbenchåŸºå‡†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒTTOMæ˜¯ä¸€ä¸ªæœ‰æ•ˆã€å®ç”¨ã€å¯æ‰©å±•ä¸”é«˜æ•ˆçš„æ¡†æ¶ï¼Œå¯ç”¨äºå³æ—¶å®ç°ç»„åˆè§†é¢‘ç”Ÿæˆçš„è·¨æ¨¡æ€å¯¹é½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰è§†é¢‘åŸºç¡€æ¨¡å‹åœ¨å¤„ç†ç»„åˆè§†é¢‘ç”Ÿæˆä»»åŠ¡æ—¶ï¼Œéš¾ä»¥å‡†ç¡®æ•æ‰å’Œç”Ÿæˆå¤æ‚çš„æ—¶ç©ºå…³ç³»ï¼Œä¾‹å¦‚ç‰©ä½“é—´çš„è¿åŠ¨ã€æ•°é‡å…³ç³»å’Œç©ºé—´å¸ƒå±€ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ç›´æ¥å¹²é¢„æ½œåœ¨ç©ºé—´æˆ–é€æ ·æœ¬æ³¨æ„åŠ›ï¼Œç¼ºä¹å¯¹å†å²ä¿¡æ¯çš„æœ‰æ•ˆåˆ©ç”¨å’Œå¯¹ç»„åˆä¸–ç•ŒçŸ¥è¯†çš„è§£è€¦ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šTTOMçš„æ ¸å¿ƒåœ¨äºé€šè¿‡æµ‹è¯•æ—¶ä¼˜åŒ–å’Œè®°å¿†æœºåˆ¶ï¼ŒåŠ¨æ€è°ƒæ•´è§†é¢‘ç”Ÿæˆæ¨¡å‹çš„è¾“å‡ºï¼Œä½¿å…¶æ›´å¥½åœ°ç¬¦åˆç»™å®šçš„æ—¶ç©ºå¸ƒå±€ã€‚é€šè¿‡å¼•å…¥å¯å­¦ä¹ çš„å‚æ•°ï¼Œå¹¶åœ¨æ¨ç†é˜¶æ®µè¿›è¡Œä¼˜åŒ–ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œç”Ÿæˆç»„åˆè§†é¢‘ã€‚åŒæ—¶ï¼Œåˆ©ç”¨å‚æ•°åŒ–è®°å¿†æœºåˆ¶ç»´æŠ¤å†å²ä¼˜åŒ–ä¸Šä¸‹æ–‡ï¼Œä»è€Œå®ç°æ›´ç¨³å®šçš„ç”Ÿæˆæ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTTOMæ¡†æ¶ä¸»è¦åŒ…å«ä¸¤ä¸ªæ ¸å¿ƒæ¨¡å—ï¼šæµ‹è¯•æ—¶ä¼˜åŒ–æ¨¡å—å’Œå‚æ•°åŒ–è®°å¿†æ¨¡å—ã€‚æµ‹è¯•æ—¶ä¼˜åŒ–æ¨¡å—é€šè¿‡å¼•å…¥æ–°çš„å¯å­¦ä¹ å‚æ•°ï¼Œå¹¶åˆ©ç”¨å¸ƒå±€-æ³¨æ„åŠ›ç›®æ ‡å‡½æ•°è¿›è¡Œä¼˜åŒ–ï¼Œä»è€Œä½¿æ¨¡å‹è¾“å‡ºä¸æ—¶ç©ºå¸ƒå±€å¯¹é½ã€‚å‚æ•°åŒ–è®°å¿†æ¨¡å—åˆ™ç”¨äºç»´æŠ¤å†å²ä¼˜åŒ–ä¸Šä¸‹æ–‡ï¼Œæ”¯æŒçµæ´»çš„æ’å…¥ã€è¯»å–ã€æ›´æ–°å’Œåˆ é™¤æ“ä½œï¼Œä»è€Œå®ç°æ›´ç¨³å®šçš„è§†é¢‘ç”Ÿæˆã€‚æ•´ä¸ªæ¡†æ¶é‡‡ç”¨æµå¼å¤„ç†æ–¹å¼ï¼Œé€æ­¥ç”Ÿæˆè§†é¢‘å¸§ã€‚

**å…³é”®åˆ›æ–°**ï¼šTTOMçš„å…³é”®åˆ›æ–°åœ¨äºå…¶æµ‹è¯•æ—¶ä¼˜åŒ–å’Œè®°å¿†æœºåˆ¶ã€‚ä¸ç°æœ‰æ–¹æ³•ä¸åŒï¼ŒTTOMä¸ç›´æ¥å¹²é¢„æ½œåœ¨ç©ºé—´æˆ–é€æ ·æœ¬æ³¨æ„åŠ›ï¼Œè€Œæ˜¯é€šè¿‡ä¼˜åŒ–æ–°çš„å‚æ•°æ¥å®ç°æ›´å¥½çš„æ–‡æœ¬-å›¾åƒå¯¹é½ã€‚æ­¤å¤–ï¼ŒTTOMçš„å‚æ•°åŒ–è®°å¿†æœºåˆ¶èƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨å†å²ä¿¡æ¯ï¼Œä»è€Œæé«˜è§†é¢‘ç”Ÿæˆçš„ç¨³å®šæ€§å’Œä¸€è‡´æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šTTOMçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) å¸ƒå±€-æ³¨æ„åŠ›ç›®æ ‡å‡½æ•°ï¼Œç”¨äºæŒ‡å¯¼æµ‹è¯•æ—¶ä¼˜åŒ–è¿‡ç¨‹ï¼›2) å‚æ•°åŒ–è®°å¿†æ¨¡å—ï¼Œç”¨äºç»´æŠ¤å†å²ä¼˜åŒ–ä¸Šä¸‹æ–‡ï¼›3) æµå¼å¤„ç†æ–¹å¼ï¼Œç”¨äºé€æ­¥ç”Ÿæˆè§†é¢‘å¸§ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ï¼Œä½†æ‘˜è¦ä¸­æœªæä¾›å…·ä½“æ•°å€¼ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

TTOMåœ¨T2V-CompBenchå’ŒVbenchåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¯æ˜äº†å…¶åœ¨ç»„åˆè§†é¢‘ç”Ÿæˆä»»åŠ¡ä¸Šçš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTTOMèƒ½å¤Ÿæœ‰æ•ˆè§£è€¦ç»„åˆä¸–ç•ŒçŸ¥è¯†ï¼Œå¹¶å±•ç°å‡ºå¼ºå¤§çš„å¯è¿ç§»æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚å…·ä½“æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦éœ€è¦åœ¨è®ºæ–‡ä¸­æŸ¥æ‰¾ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

TTOMæ¡†æ¶å¯åº”ç”¨äºå„ç§éœ€è¦ç»„åˆè§†é¢‘ç”Ÿæˆçš„åœºæ™¯ï¼Œä¾‹å¦‚ï¼šæ ¹æ®æ–‡æœ¬æè¿°ç”ŸæˆåŒ…å«ç‰¹å®šç‰©ä½“è¿åŠ¨å’Œäº¤äº’çš„è§†é¢‘ï¼Œæˆ–è€…æ ¹æ®ç»™å®šçš„æ—¶ç©ºå¸ƒå±€ç”Ÿæˆç¬¦åˆè¦æ±‚çš„è§†é¢‘å†…å®¹ã€‚è¯¥æŠ€æœ¯åœ¨æ¸¸æˆå¼€å‘ã€ç”µå½±åˆ¶ä½œã€æ•™è‚²å¨±ä¹ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡è§†é¢‘å†…å®¹çš„ç”Ÿæˆæ•ˆç‡å’Œè´¨é‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Video Foundation Models (VFMs) exhibit remarkable visual generation performance, but struggle in compositional scenarios (e.g., motion, numeracy, and spatial relation). In this work, we introduce Test-Time Optimization and Memorization (TTOM), a training-free framework that aligns VFM outputs with spatiotemporal layouts during inference for better text-image alignment. Rather than direct intervention to latents or attention per-sample in existing work, we integrate and optimize new parameters guided by a general layout-attention objective. Furthermore, we formulate video generation within a streaming setting, and maintain historical optimization contexts with a parametric memory mechanism that supports flexible operations, such as insert, read, update, and delete. Notably, we found that TTOM disentangles compositional world knowledge, showing powerful transferability and generalization. Experimental results on the T2V-CompBench and Vbench benchmarks establish TTOM as an effective, practical, scalable, and efficient framework to achieve cross-modal alignment for compositional video generation on the fly.

