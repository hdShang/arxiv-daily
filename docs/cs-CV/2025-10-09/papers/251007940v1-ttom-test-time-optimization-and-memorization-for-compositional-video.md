---
layout: default
title: TTOM: Test-Time Optimization and Memorization for Compositional Video Generation
---

# TTOM: Test-Time Optimization and Memorization for Compositional Video Generation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.07940" target="_blank" class="toolbar-btn">arXiv: 2510.07940v1</a>
    <a href="https://arxiv.org/pdf/2510.07940.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.07940v1" 
            onclick="toggleFavorite(this, '2510.07940v1', 'TTOM: Test-Time Optimization and Memorization for Compositional Video Generation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Leigang Qu, Ziyang Wang, Na Zheng, Wenjie Wang, Liqiang Nie, Tat-Seng Chua

**ÂàÜÁ±ª**: cs.CV, cs.AI, cs.CL, cs.LG, cs.MM

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-09

**Â§áÊ≥®**: Project page: https://ttom-t2v.github.io/

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫TTOMÔºö‰∏ÄÁßçÊµãËØïÊó∂‰ºòÂåñ‰∏éËÆ∞ÂøÜÊ°ÜÊû∂ÔºåÁî®‰∫éÁªÑÂêàËßÜÈ¢ëÁîüÊàê„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±ÂÖ´ÔºöÁâ©ÁêÜÂä®Áîª (Physics-based Animation)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËßÜÈ¢ëÁîüÊàê` `ÁªÑÂêàÁîüÊàê` `ÊµãËØïÊó∂‰ºòÂåñ` `ËÆ∞ÂøÜÊú∫Âà∂` `Ë∑®Ê®°ÊÄÅÂØπÈΩê` `ËßÜÈ¢ëÂü∫Á°ÄÊ®°Âûã` `Êó∂Á©∫Â∏ÉÂ±Ä`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ËßÜÈ¢ëÁîüÊàêÊ®°ÂûãÂú®ÁªÑÂêàÂú∫ÊôØ‰∏≠Èù¢‰∏¥ÊåëÊàòÔºåÈöæ‰ª•ÂáÜÁ°ÆÁêÜËß£ÂíåÁîüÊàêÂ§çÊùÇÁöÑÊó∂Á©∫ÂÖ≥Á≥ª„ÄÇ
2. TTOMÊ°ÜÊû∂ÈÄöËøáÂú®ÊµãËØïÊó∂‰ºòÂåñÂíåËÆ∞ÂøÜÂéÜÂè≤‰ø°ÊÅØÔºåÂä®ÊÄÅË∞ÉÊï¥Ê®°ÂûãËæìÂá∫‰ª•Á¨¶ÂêàÁªôÂÆöÁöÑÊó∂Á©∫Â∏ÉÂ±Ä„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåTTOMÂú®ÁªÑÂêàËßÜÈ¢ëÁîüÊàê‰ªªÂä°‰∏äÊòæËëóÊèêÂçá‰∫ÜÊñáÊú¨-ÂõæÂÉèÂØπÈΩêÊïàÊûúÔºåÂπ∂Â±ïÁé∞Âá∫ËâØÂ•ΩÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËßÜÈ¢ëÂü∫Á°ÄÊ®°Âûã(VFMs)Âú®ËßÜËßâÁîüÊàêÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤Ôºå‰ΩÜÂú®ÁªÑÂêàÂú∫ÊôØÔºà‰æãÂ¶ÇÔºåËøêÂä®„ÄÅÊï∞ÈáèÂíåÁ©∫Èó¥ÂÖ≥Á≥ªÔºâ‰∏≠Ë°®Áé∞‰∏ç‰Ω≥„ÄÇÊú¨ÊñáÊèêÂá∫ÊµãËØïÊó∂‰ºòÂåñ‰∏éËÆ∞ÂøÜ(TTOM)ÔºåËøôÊòØ‰∏Ä‰∏™Êó†ÈúÄËÆ≠ÁªÉÁöÑÊ°ÜÊû∂ÔºåÂú®Êé®ÁêÜÊúüÈó¥Â∞ÜVFMËæìÂá∫‰∏éÊó∂Á©∫Â∏ÉÂ±ÄÂØπÈΩêÔºå‰ª•ÂÆûÁé∞Êõ¥Â•ΩÁöÑÊñáÊú¨-ÂõæÂÉèÂØπÈΩê„ÄÇ‰∏éÁé∞ÊúâÂ∑•‰Ωú‰∏≠Áõ¥Êé•Âπ≤È¢ÑÊΩúÂú®Á©∫Èó¥ÊàñÈÄêÊ†∑Êú¨Ê≥®ÊÑèÂäõ‰∏çÂêåÔºåÊàë‰ª¨ÈõÜÊàêÂπ∂‰ºòÂåñÁî±ÈÄöÁî®Â∏ÉÂ±Ä-Ê≥®ÊÑèÂäõÁõÆÊ†áÂºïÂØºÁöÑÊñ∞ÂèÇÊï∞„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨Â∞ÜËßÜÈ¢ëÁîüÊàêÂΩ¢ÂºèÂåñ‰∏∫ÊµÅÂºèËÆæÁΩÆÔºåÂπ∂‰ΩøÁî®ÂèÇÊï∞ÂåñËÆ∞ÂøÜÊú∫Âà∂Áª¥Êä§ÂéÜÂè≤‰ºòÂåñ‰∏ä‰∏ãÊñáÔºåËØ•Êú∫Âà∂ÊîØÊåÅÁÅµÊ¥ªÁöÑÊìç‰ΩúÔºå‰æãÂ¶ÇÊèíÂÖ•„ÄÅËØªÂèñ„ÄÅÊõ¥Êñ∞ÂíåÂà†Èô§„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊàë‰ª¨ÂèëÁé∞TTOMËß£ËÄ¶‰∫ÜÁªÑÂêà‰∏ñÁïåÁü•ËØÜÔºåÊòæÁ§∫Âá∫Âº∫Â§ßÁöÑÂèØËøÅÁßªÊÄßÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇÂú®T2V-CompBenchÂíåVbenchÂü∫ÂáÜ‰∏äÁöÑÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåTTOMÊòØ‰∏Ä‰∏™ÊúâÊïà„ÄÅÂÆûÁî®„ÄÅÂèØÊâ©Â±ï‰∏îÈ´òÊïàÁöÑÊ°ÜÊû∂ÔºåÂèØÁî®‰∫éÂç≥Êó∂ÂÆûÁé∞ÁªÑÂêàËßÜÈ¢ëÁîüÊàêÁöÑË∑®Ê®°ÊÄÅÂØπÈΩê„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâËßÜÈ¢ëÂü∫Á°ÄÊ®°ÂûãÂú®Â§ÑÁêÜÁªÑÂêàËßÜÈ¢ëÁîüÊàê‰ªªÂä°Êó∂ÔºåÈöæ‰ª•ÂáÜÁ°ÆÊçïÊçâÂíåÁîüÊàêÂ§çÊùÇÁöÑÊó∂Á©∫ÂÖ≥Á≥ªÔºå‰æãÂ¶ÇÁâ©‰ΩìÈó¥ÁöÑËøêÂä®„ÄÅÊï∞ÈáèÂÖ≥Á≥ªÂíåÁ©∫Èó¥Â∏ÉÂ±Ä„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏Áõ¥Êé•Âπ≤È¢ÑÊΩúÂú®Á©∫Èó¥ÊàñÈÄêÊ†∑Êú¨Ê≥®ÊÑèÂäõÔºåÁº∫‰πèÂØπÂéÜÂè≤‰ø°ÊÅØÁöÑÊúâÊïàÂà©Áî®ÂíåÂØπÁªÑÂêà‰∏ñÁïåÁü•ËØÜÁöÑËß£ËÄ¶„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöTTOMÁöÑÊ†∏ÂøÉÂú®‰∫éÈÄöËøáÊµãËØïÊó∂‰ºòÂåñÂíåËÆ∞ÂøÜÊú∫Âà∂ÔºåÂä®ÊÄÅË∞ÉÊï¥ËßÜÈ¢ëÁîüÊàêÊ®°ÂûãÁöÑËæìÂá∫Ôºå‰ΩøÂÖ∂Êõ¥Â•ΩÂú∞Á¨¶ÂêàÁªôÂÆöÁöÑÊó∂Á©∫Â∏ÉÂ±Ä„ÄÇÈÄöËøáÂºïÂÖ•ÂèØÂ≠¶‰π†ÁöÑÂèÇÊï∞ÔºåÂπ∂Âú®Êé®ÁêÜÈò∂ÊÆµËøõË°å‰ºòÂåñÔºå‰ΩøÊ®°ÂûãËÉΩÂ§üÊõ¥Â•ΩÂú∞ÁêÜËß£ÂíåÁîüÊàêÁªÑÂêàËßÜÈ¢ë„ÄÇÂêåÊó∂ÔºåÂà©Áî®ÂèÇÊï∞ÂåñËÆ∞ÂøÜÊú∫Âà∂Áª¥Êä§ÂéÜÂè≤‰ºòÂåñ‰∏ä‰∏ãÊñáÔºå‰ªéËÄåÂÆûÁé∞Êõ¥Á®≥ÂÆöÁöÑÁîüÊàêÊïàÊûú„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöTTOMÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰∏§‰∏™Ê†∏ÂøÉÊ®°ÂùóÔºöÊµãËØïÊó∂‰ºòÂåñÊ®°ÂùóÂíåÂèÇÊï∞ÂåñËÆ∞ÂøÜÊ®°Âùó„ÄÇÊµãËØïÊó∂‰ºòÂåñÊ®°ÂùóÈÄöËøáÂºïÂÖ•Êñ∞ÁöÑÂèØÂ≠¶‰π†ÂèÇÊï∞ÔºåÂπ∂Âà©Áî®Â∏ÉÂ±Ä-Ê≥®ÊÑèÂäõÁõÆÊ†áÂáΩÊï∞ËøõË°å‰ºòÂåñÔºå‰ªéËÄå‰ΩøÊ®°ÂûãËæìÂá∫‰∏éÊó∂Á©∫Â∏ÉÂ±ÄÂØπÈΩê„ÄÇÂèÇÊï∞ÂåñËÆ∞ÂøÜÊ®°ÂùóÂàôÁî®‰∫éÁª¥Êä§ÂéÜÂè≤‰ºòÂåñ‰∏ä‰∏ãÊñáÔºåÊîØÊåÅÁÅµÊ¥ªÁöÑÊèíÂÖ•„ÄÅËØªÂèñ„ÄÅÊõ¥Êñ∞ÂíåÂà†Èô§Êìç‰ΩúÔºå‰ªéËÄåÂÆûÁé∞Êõ¥Á®≥ÂÆöÁöÑËßÜÈ¢ëÁîüÊàê„ÄÇÊï¥‰∏™Ê°ÜÊû∂ÈááÁî®ÊµÅÂºèÂ§ÑÁêÜÊñπÂºèÔºåÈÄêÊ≠•ÁîüÊàêËßÜÈ¢ëÂ∏ß„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöTTOMÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂ÊµãËØïÊó∂‰ºòÂåñÂíåËÆ∞ÂøÜÊú∫Âà∂„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ï‰∏çÂêåÔºåTTOM‰∏çÁõ¥Êé•Âπ≤È¢ÑÊΩúÂú®Á©∫Èó¥ÊàñÈÄêÊ†∑Êú¨Ê≥®ÊÑèÂäõÔºåËÄåÊòØÈÄöËøá‰ºòÂåñÊñ∞ÁöÑÂèÇÊï∞Êù•ÂÆûÁé∞Êõ¥Â•ΩÁöÑÊñáÊú¨-ÂõæÂÉèÂØπÈΩê„ÄÇÊ≠§Â§ñÔºåTTOMÁöÑÂèÇÊï∞ÂåñËÆ∞ÂøÜÊú∫Âà∂ËÉΩÂ§üÊúâÊïàÂà©Áî®ÂéÜÂè≤‰ø°ÊÅØÔºå‰ªéËÄåÊèêÈ´òËßÜÈ¢ëÁîüÊàêÁöÑÁ®≥ÂÆöÊÄßÂíå‰∏ÄËá¥ÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöTTOMÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) Â∏ÉÂ±Ä-Ê≥®ÊÑèÂäõÁõÆÊ†áÂáΩÊï∞ÔºåÁî®‰∫éÊåáÂØºÊµãËØïÊó∂‰ºòÂåñËøáÁ®ãÔºõ2) ÂèÇÊï∞ÂåñËÆ∞ÂøÜÊ®°ÂùóÔºåÁî®‰∫éÁª¥Êä§ÂéÜÂè≤‰ºòÂåñ‰∏ä‰∏ãÊñáÔºõ3) ÊµÅÂºèÂ§ÑÁêÜÊñπÂºèÔºåÁî®‰∫éÈÄêÊ≠•ÁîüÊàêËßÜÈ¢ëÂ∏ß„ÄÇÂÖ∑‰ΩìÁöÑÂèÇÊï∞ËÆæÁΩÆÂíåÁΩëÁªúÁªìÊûÑÁªÜËäÇÂú®ËÆ∫Êñá‰∏≠ËøõË°å‰∫ÜËØ¶ÁªÜÊèèËø∞Ôºå‰ΩÜÊëòË¶Å‰∏≠Êú™Êèê‰æõÂÖ∑‰ΩìÊï∞ÂÄº„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

TTOMÂú®T2V-CompBenchÂíåVbenchÂü∫ÂáÜÊµãËØï‰∏≠ÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåËØÅÊòé‰∫ÜÂÖ∂Âú®ÁªÑÂêàËßÜÈ¢ëÁîüÊàê‰ªªÂä°‰∏äÁöÑÊúâÊïàÊÄß„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåTTOMËÉΩÂ§üÊúâÊïàËß£ËÄ¶ÁªÑÂêà‰∏ñÁïåÁü•ËØÜÔºåÂπ∂Â±ïÁé∞Âá∫Âº∫Â§ßÁöÑÂèØËøÅÁßªÊÄßÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇÂÖ∑‰ΩìÊÄßËÉΩÊï∞ÊçÆÂíåÊèêÂçáÂπÖÂ∫¶ÈúÄË¶ÅÂú®ËÆ∫Êñá‰∏≠Êü•Êâæ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

TTOMÊ°ÜÊû∂ÂèØÂ∫îÁî®‰∫éÂêÑÁßçÈúÄË¶ÅÁªÑÂêàËßÜÈ¢ëÁîüÊàêÁöÑÂú∫ÊôØÔºå‰æãÂ¶ÇÔºöÊ†πÊçÆÊñáÊú¨ÊèèËø∞ÁîüÊàêÂåÖÂê´ÁâπÂÆöÁâ©‰ΩìËøêÂä®Âíå‰∫§‰∫íÁöÑËßÜÈ¢ëÔºåÊàñËÄÖÊ†πÊçÆÁªôÂÆöÁöÑÊó∂Á©∫Â∏ÉÂ±ÄÁîüÊàêÁ¨¶ÂêàË¶ÅÊ±ÇÁöÑËßÜÈ¢ëÂÜÖÂÆπ„ÄÇËØ•ÊäÄÊúØÂú®Ê∏∏ÊàèÂºÄÂèë„ÄÅÁîµÂΩ±Âà∂‰Ωú„ÄÅÊïôËÇ≤Â®±‰πêÁ≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåËÉΩÂ§üÊòæËëóÊèêÂçáËßÜÈ¢ëÂÜÖÂÆπÁöÑÁîüÊàêÊïàÁéáÂíåË¥®Èáè„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Video Foundation Models (VFMs) exhibit remarkable visual generation performance, but struggle in compositional scenarios (e.g., motion, numeracy, and spatial relation). In this work, we introduce Test-Time Optimization and Memorization (TTOM), a training-free framework that aligns VFM outputs with spatiotemporal layouts during inference for better text-image alignment. Rather than direct intervention to latents or attention per-sample in existing work, we integrate and optimize new parameters guided by a general layout-attention objective. Furthermore, we formulate video generation within a streaming setting, and maintain historical optimization contexts with a parametric memory mechanism that supports flexible operations, such as insert, read, update, and delete. Notably, we found that TTOM disentangles compositional world knowledge, showing powerful transferability and generalization. Experimental results on the T2V-CompBench and Vbench benchmarks establish TTOM as an effective, practical, scalable, and efficient framework to achieve cross-modal alignment for compositional video generation on the fly.

