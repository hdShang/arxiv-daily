---
layout: default
title: Beyond Textual CoT: Interleaved Text-Image Chains with Deep Confidence Reasoning for Image Editing
---

# Beyond Textual CoT: Interleaved Text-Image Chains with Deep Confidence Reasoning for Image Editing

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.08157" target="_blank" class="toolbar-btn">arXiv: 2510.08157v1</a>
    <a href="https://arxiv.org/pdf/2510.08157.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.08157v1" 
            onclick="toggleFavorite(this, '2510.08157v1', 'Beyond Textual CoT: Interleaved Text-Image Chains with Deep Confidence Reasoning for Image Editing')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Zhentao Zou, Zhengrong Yue, Kunpeng Du, Binlei Bao, Hanting Li, Haizhen Xie, Guozheng Xu, Yue Zhou, Yali Wang, Jie Hu, Xue Jiang, Xinghao Chen

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-09

**Â§áÊ≥®**: 25pages,20figures

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫MUREÊ°ÜÊû∂ÔºåÂà©Áî®‰∫§ÈîôÊñáÊú¨-ÂõæÂÉèÈìæÂíåÊ∑±Â∫¶ÁΩÆ‰ø°Êé®ÁêÜËøõË°åÂõæÂÉèÁºñËæë**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÉÔºöÂä®‰ΩúÈáçÂÆöÂêë (Motion Retargeting)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÂõæÂÉèÁºñËæë` `Â§öÊ®°ÊÄÅÊé®ÁêÜ` `Chain-of-Thought` `Ê∑±Â∫¶ÁΩÆ‰ø°Â≠¶‰π†` `ÊñáÊú¨-ÂõæÂÉè‰∫§Èîô` `ËßÜËßâÊé®ÁêÜ` `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `ÂõæÂÉèÁîüÊàê`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂü∫‰∫éÊñáÊú¨ÁöÑÂõæÂÉèÁºñËæëÊñπÊ≥ïÈöæ‰ª•Â§ÑÁêÜÂ§çÊùÇÁöÑÂØπË±°ÂÖ≥Á≥ªÂíåÁ≤æÁªÜÁöÑÁ©∫Èó¥Â∏ÉÂ±ÄÔºåÁº∫‰πèÊòæÂºèÁöÑÊé®ÁêÜËøáÁ®ã„ÄÇ
2. MUREÊ°ÜÊû∂ÈááÁî®‰∫§ÈîôÁöÑÊñáÊú¨ÂíåÂõæÂÉèÊé®ÁêÜÈìæÔºåÁªìÂêàËßÜËßâÁ∫øÁ¥¢ÊåáÂØºÂÉèÁ¥†Á∫ßÂà´ÁöÑÁªÜËäÇÁîüÊàêÔºåÊèêÂçáÁºñËæëÁ≤æÂ∫¶„ÄÇ
3. ÂºïÂÖ•Â§öÊ®°ÊÄÅÊ∑±Â∫¶ÁΩÆ‰ø°Êé®ÁêÜÔºåÈÄöËøáÁΩÆ‰ø°Â∫¶ËØÑ‰º∞‰øÆÂâ™‰ΩéË¥®ÈáèÊé®ÁêÜË∑ØÂæÑÔºåÂáèËΩªÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÂπªËßâÈóÆÈ¢òÔºåÊèêÂçáÁºñËæëË¥®Èáè„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫Â§öÊ®°ÊÄÅÊé®ÁêÜÁºñËæëÔºàMUREÔºâÁöÑÊñ∞Ê°ÜÊû∂ÔºåÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâÊñπÊ≥ïÂú®Â§ÑÁêÜÂ§çÊùÇÂØπË±°‰∫§ÂèâÂíåÁ≤æÁªÜÁ©∫Èó¥ÂÖ≥Á≥ªÊó∂Èù¢‰∏¥ÁöÑÊåëÊàò„ÄÇMUREÂ∞ÜÂõæÂÉèÁºñËæëËøáÁ®ã‰ªéÁ∫ØÊñáÊú¨Êé®ÁêÜËΩ¨Âèò‰∏∫‰∏ÄÁ≥ªÂàó‰∫§ÈîôÁöÑÊñáÊú¨ÂíåËßÜËßâ‰æùÊçÆÔºåÈááÁî®ÂéüÁîüÂ§öÊ®°ÊÄÅÁöÑ‰∫§ÈîôÊñáÊú¨-ÂõæÂÉèCoTÔºåÁîüÊàêÈÄêÊ≠•Êé®ÁêÜÈìæÔºåÂÖ∂‰∏≠ÊñáÊú¨ÊèèËø∞ÂêéË∑üÁõ∏Â∫îÁöÑËßÜËßâÊèêÁ§∫ÔºåÂ¶ÇÂÆö‰πâÁõÆÊ†áÁºñËæëÂå∫ÂüüÁöÑ‰ΩçÁΩÆÊé©Á†ÅÊàñÊñ∞ÂÜÖÂÆπÁöÑË°®Á§∫„ÄÇÊ≠§Â§ñÔºåÂºïÂÖ•Â§öÊ®°ÊÄÅÊ∑±Â∫¶ÁΩÆ‰ø°ÔºàMMDCÔºâÊé®ÁêÜËåÉÂºèÔºåÈÄöËøáÊé¢Á¥¢ËßÜËßâÊé®ÁêÜË∑ØÂæÑÊ†ëÔºåÂπ∂‰ΩøÁî®Â•ñÂä±Ê®°ÂûãÁöÑÊ∑±Â∫¶ÁΩÆ‰ø°Â∫¶ÂàÜÊï∞‰øÆÂâ™‰ΩéË¥®ÈáèÂàÜÊîØÔºå‰ªéËÄåÂáèËΩªÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÂπªËßâÁé∞Ë±°„ÄÇËØ•ÊñπÊ≥ïÂ∞ÜÂ§çÊùÇÁöÑÁºñËæë‰ªªÂä°ÂàÜËß£‰∏∫Áõ∏‰∫í‰æùËµñÁöÑÂ≠ê‰ªªÂä°Ôºå‰ªéËÄåÂú®ÊØè‰∏™Èò∂ÊÆµÂÆûÁé∞Êõ¥È´òÁöÑÁ≤æÂ∫¶ÔºåÂπ∂‰∫ßÁîüÈ´ò‰øùÁúüÂ∫¶ÁöÑÁºñËæëÁªìÊûú„ÄÇÊàë‰ª¨ÂÆö‰πâ‰∫Ü‰∫§ÈîôÊñáÊú¨-ÂõæÂÉèÈìæÁöÑÂÖ¨ÂºèÔºåÂπ∂ÂèëÂ∏É‰∫ÜÈ¶ñ‰∏™CoT-Edit-14KÊï∞ÊçÆÈõÜÔºåÂåÖÂê´14K‰∏™È´òË¥®ÈáèÁöÑÁºñËæëÁ§∫‰æã„ÄÇÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®‰∏â‰∏™ÂõæÂÉèÁºñËæëÂü∫ÂáÜÊµãËØï‰∏≠ÂùáÂèñÂæó‰∫ÜÊòæËëóÁöÑÊîπËøõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÂü∫‰∫éËá™ÁÑ∂ËØ≠Ë®ÄÁöÑÂõæÂÉèÁºñËæëÊñπÊ≥ïÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§ÑÁêÜÂ§çÊùÇÂØπË±°‰πãÈó¥ÁöÑ‰∫§‰∫íÂíåÁ≤æÁªÜÁöÑÁ©∫Èó¥ÂÖ≥Á≥ªÊó∂ÔºåÈù¢‰∏¥ÁùÄÊåëÊàò„ÄÇÁ∫ØÊñáÊú¨ÁöÑChain-of-Thought (CoT) ÊàñÂùêÊ†áÂ¢ûÂº∫ÁöÑCoTÂú®Ë°®Á§∫Â§çÊùÇÁöÑËßÜËßâÂ∏ÉÂ±ÄÊñπÈù¢Â≠òÂú®Ê†πÊú¨ÊÄßÈôêÂà∂ÔºåÂπ∂‰∏îÁº∫‰πèÊåáÂØºÁîüÊàêÁ≤æÁªÜÂÉèÁ¥†Á∫ßÁªÜËäÇÊâÄÈúÄÁöÑËßÜËßâÁ∫øÁ¥¢„ÄÇÂõ†Ê≠§ÔºåÈúÄË¶Å‰∏ÄÁßçËÉΩÂ§üÊúâÊïàÂà©Áî®ËßÜËßâ‰ø°ÊÅØËøõË°åÊé®ÁêÜÂíåÁºñËæëÁöÑÊñπÊ≥ï„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊú¨ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜÂõæÂÉèÁºñËæëËøáÁ®ã‰ªéÁ∫ØÊñáÊú¨Êé®ÁêÜËΩ¨Âèò‰∏∫‰∫§ÈîôÁöÑÊñáÊú¨ÂíåËßÜËßâÊé®ÁêÜ„ÄÇÈÄöËøáÂú®ÊñáÊú¨ÊèèËø∞ÂêéË∑üÈöèÁõ∏Â∫îÁöÑËßÜËßâÊèêÁ§∫Ôºà‰æãÂ¶Ç‰ΩçÁΩÆÊé©Á†ÅÊàñÊñ∞ÂÜÖÂÆπÁöÑË°®Á§∫ÔºâÔºåÊ®°ÂûãÂèØ‰ª•Êõ¥Â•ΩÂú∞ÁêÜËß£ÂíåÊâßË°åÁºñËæë‰ªªÂä°„ÄÇÊ≠§Â§ñÔºåÂºïÂÖ•Â§öÊ®°ÊÄÅÊ∑±Â∫¶ÁΩÆ‰ø°Êé®ÁêÜÔºåÈÄöËøáËØÑ‰º∞‰∏çÂêåÊé®ÁêÜË∑ØÂæÑÁöÑË¥®ÈáèÔºåÈÄâÊã©È´òË¥®ÈáèÁöÑË∑ØÂæÑÔºå‰ªéËÄåÂáèÂ∞ëÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÂπªËßâÈóÆÈ¢ò„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöMUREÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ã‰∏ªË¶ÅÊ®°ÂùóÔºö1) ‰∫§ÈîôÊñáÊú¨-ÂõæÂÉèCoTÁîüÊàêÂô®ÔºöË¥üË¥£ÁîüÊàêÈÄêÊ≠•ÁöÑÊé®ÁêÜÈìæÔºåÂÖ∂‰∏≠ÊñáÊú¨ÊèèËø∞‰∏éÁõ∏Â∫îÁöÑËßÜËßâÊèêÁ§∫‰∫§ÊõøÂá∫Áé∞„ÄÇ2) Â§öÊ®°ÊÄÅÊ∑±Â∫¶ÁΩÆ‰ø°ÔºàMMDCÔºâÊé®ÁêÜÊ®°ÂùóÔºöÂú®ÊØè‰∏™Êé®ÁêÜÊ≠•È™§‰∏≠ÔºåÊé¢Á¥¢Â§ö‰∏™ËßÜËßâÊé®ÁêÜË∑ØÂæÑÔºåÂπ∂‰ΩøÁî®Â•ñÂä±Ê®°ÂûãËØÑ‰º∞ÊØè‰∏™Ë∑ØÂæÑÁöÑÁΩÆ‰ø°Â∫¶„ÄÇ3) Ë∑ØÂæÑ‰øÆÂâ™Ê®°ÂùóÔºöÊ†πÊçÆMMDCÁöÑÁΩÆ‰ø°Â∫¶ÂàÜÊï∞Ôºå‰øÆÂâ™‰ΩéË¥®ÈáèÁöÑÊé®ÁêÜË∑ØÂæÑÔºåÁ°Æ‰øùÊ®°ÂûãÂßãÁªàÊ≤øÁùÄÈ´òË¥®ÈáèÁöÑËΩ®ËøπÂâçËøõ„ÄÇ4) ÂõæÂÉèÁºñËæëÊ®°ÂùóÔºöÊ†πÊçÆÊúÄÁªàÁöÑÊé®ÁêÜÁªìÊûúÔºåÂØπÂõæÂÉèËøõË°åÁºñËæë„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1) ÊèêÂá∫‰∫Ü‰∫§ÈîôÊñáÊú¨-ÂõæÂÉèCoTÁöÑÊ¶ÇÂøµÔºåÂ∞ÜËßÜËßâ‰ø°ÊÅØËûçÂÖ•Âà∞Êé®ÁêÜËøáÁ®ã‰∏≠„ÄÇ2) ÂºïÂÖ•‰∫ÜÂ§öÊ®°ÊÄÅÊ∑±Â∫¶ÁΩÆ‰ø°Êé®ÁêÜÔºåÈÄöËøáËØÑ‰º∞Êé®ÁêÜË∑ØÂæÑÁöÑË¥®ÈáèÊù•ÂáèÂ∞ëÂπªËßâÈóÆÈ¢ò„ÄÇ3) ÊûÑÂª∫‰∫ÜCoT-Edit-14KÊï∞ÊçÆÈõÜÔºå‰∏∫‰∫§ÈîôÊñáÊú¨-ÂõæÂÉèCoTÁöÑÂõæÂÉèÁºñËæëÁ†îÁ©∂Êèê‰æõ‰∫ÜÊï∞ÊçÆÊîØÊåÅ„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåMUREËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞Âà©Áî®ËßÜËßâ‰ø°ÊÅØËøõË°åÊé®ÁêÜÂíåÁºñËæëÔºå‰ªéËÄåÊèêÈ´òÁºñËæëÁöÑÁ≤æÂ∫¶ÂíåË¥®Èáè„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®MMDCÊé®ÁêÜ‰∏≠Ôºå‰ΩøÁî®Â•ñÂä±Ê®°ÂûãÊù•ËØÑ‰º∞ÊØè‰∏™ËßÜËßâÊé®ÁêÜË∑ØÂæÑÁöÑÁΩÆ‰ø°Â∫¶„ÄÇÂ•ñÂä±Ê®°ÂûãÂèØ‰ª•ÊòØ‰∏Ä‰∏™È¢ÑËÆ≠ÁªÉÁöÑÂõæÂÉèË¥®ÈáèËØÑ‰º∞Ê®°ÂûãÔºå‰πüÂèØ‰ª•ÊòØ‰∏Ä‰∏™‰∏ìÈó®ËÆ≠ÁªÉÁöÑÁî®‰∫éËØÑ‰º∞ÁºñËæëÁªìÊûúË¥®ÈáèÁöÑÊ®°Âûã„ÄÇÂú®Ë∑ØÂæÑ‰øÆÂâ™ËøáÁ®ã‰∏≠ÔºåÂèØ‰ª•ËÆæÁΩÆ‰∏Ä‰∏™ÁΩÆ‰ø°Â∫¶ÈòàÂÄºÔºå‰Ωé‰∫éËØ•ÈòàÂÄºÁöÑË∑ØÂæÑÂ∞ÜË¢´‰∏¢ÂºÉ„ÄÇÊ≠§Â§ñÔºåÂú®‰∫§ÈîôÊñáÊú¨-ÂõæÂÉèCoTÁîüÊàêÂô®‰∏≠ÔºåÂèØ‰ª•‰ΩøÁî®‰∏çÂêåÁöÑËßÜËßâÊèêÁ§∫Á±ªÂûãÔºå‰æãÂ¶Ç‰ΩçÁΩÆÊé©Á†Å„ÄÅÂàÜÂâ≤Êé©Á†ÅÊàñÊñ∞ÂÜÖÂÆπÁöÑË°®Á§∫„ÄÇÂÖ∑‰ΩìÈÄâÊã©Âì™ÁßçËßÜËßâÊèêÁ§∫Á±ªÂûãÂèñÂÜ≥‰∫éÂÖ∑‰ΩìÁöÑÁºñËæë‰ªªÂä°„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåMUREÂú®‰∏â‰∏™ÂõæÂÉèÁºñËæëÂü∫ÂáÜÊµãËØï‰∏≠ÂùáÂèñÂæó‰∫ÜÊòæËëóÁöÑÊîπËøõ„ÄÇÂÖ∑‰ΩìÊÄßËÉΩÊï∞ÊçÆÂíåÂØπÊØîÂü∫Á∫øÂú®ËÆ∫Êñá‰∏≠ÊúâËØ¶ÁªÜÂ±ïÁ§∫ÔºåÊÄª‰ΩìËÄåË®ÄÔºåMUREÂú®ÁºñËæëË¥®ÈáèÂíåÁî®Êà∑Êª°ÊÑèÂ∫¶ÊñπÈù¢Âùá‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇCoT-Edit-14KÊï∞ÊçÆÈõÜÁöÑÂèëÂ∏É‰πü‰∏∫ÂêéÁª≠Á†îÁ©∂Êèê‰æõ‰∫ÜÂÆùË¥µËµÑÊ∫ê„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂ§öÁßçÂõæÂÉèÁºñËæëÂú∫ÊôØÔºå‰æãÂ¶ÇÁîµÂïÜ‰∫ßÂìÅÁöÑÂõæÂÉè‰ºòÂåñ„ÄÅÁ§æ‰∫§Â™í‰ΩìÂÜÖÂÆπÁöÑ‰∏™ÊÄßÂåñÂÆöÂà∂„ÄÅ‰ª•Âèä‰∏ì‰∏öËÆæËÆ°È¢ÜÂüüÁöÑÂõæÂÉèÂ§ÑÁêÜÁ≠â„ÄÇÈÄöËøáÊõ¥Á≤æÁ°ÆÁöÑÁêÜËß£Áî®Êà∑ÊÑèÂõæÂíåÁîüÊàêÈ´òË¥®ÈáèÁöÑÁºñËæëÁªìÊûúÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÊòæËëóÊèêÂçáÂõæÂÉèÁºñËæëÁöÑÊïàÁéáÂíåÁî®Êà∑‰ΩìÈ™åÔºåÂπ∂‰∏∫Êú™Êù•ÁöÑÊô∫ËÉΩÂõæÂÉèÁºñËæëÂ∑•ÂÖ∑Â•†ÂÆöÂü∫Á°Ä„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Image editing with natural language has gained significant popularity, yet existing methods struggle with intricate object intersections and fine-grained spatial relationships due to the lack of an explicit reasoning process. While Chain-of-Thought (CoT) has been explored to enhance reasoning, purely textual CoT or CoT augmented with coordinate information is fundamentally limited in its ability to represent intricate visual layouts and lacks the necessary visual cues to guide the generation of fine-grained, pixel-level details. To address these challenges, we propose Multimodal Reasoning Edit (MURE), a novel framework that shifts the visual editing process from purely text-based reasoning to a series of interleaved textual and visual rationales. Our framework performs image editing using a natively multimodal, interleaved text-image CoT. This approach generates a step-by-step chain of reasoning where a textual description is followed by a corresponding visual cue, such as a positional mask that defined intended edited regions or a representation of new content. Furthermore, to mitigate the hallucination phenomenon of large language models, we introduce Multimodal Deep Confidence (MMDC) reasoning paradigm. This paradigm explores a tree of visual reasoning paths at each step. By pruning low-quality branches using a deep confidence score from a reward model, it ensures the model consistently follows a high-quality trajectory towards the final edited result. The proposed method decomposes complex editing tasks into interdependent sub-tasks, achieving greater precision at each stage and yielding high-fidelity edited results. We define the formulation for interleaved text-image chains and release the first CoT-Edit-14K dataset, comprising 14K high-quality editing examples. Extensive experiments show that our method yields significant improvements across three image editing benchmarks.

