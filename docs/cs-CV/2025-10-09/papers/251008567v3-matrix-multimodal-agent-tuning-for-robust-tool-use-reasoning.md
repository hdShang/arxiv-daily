---
layout: default
title: MATRIX: Multimodal Agent Tuning for Robust Tool-Use Reasoning
---

# MATRIX: Multimodal Agent Tuning for Robust Tool-Use Reasoning

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.08567" target="_blank" class="toolbar-btn">arXiv: 2510.08567v3</a>
    <a href="https://arxiv.org/pdf/2510.08567.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.08567v3" 
            onclick="toggleFavorite(this, '2510.08567v3', 'MATRIX: Multimodal Agent Tuning for Robust Tool-Use Reasoning')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Tajamul Ashraf, Umair Nawaz, Abdelrahman M. Shaker, Rao Anwer, Philip Torr, Fahad Shahbaz Khan, Salman Khan

**ÂàÜÁ±ª**: cs.CV, cs.AI, cs.CL

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-09 (Êõ¥Êñ∞: 2025-10-21)

**Â§áÊ≥®**: We have come across a recent approach that has not been properly attributed at the time of submission and compared in a fair setting. Therefore, we would like to withdraw the paper to address these concerns

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/mbzuai-oryx/MATRIX)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫MATRIXÊ°ÜÊû∂ÔºåÈÄöËøáÂ§öÊ®°ÊÄÅAgentË∞É‰ºòÂÆûÁé∞Á®≥ÂÅ•ÁöÑÂ∑•ÂÖ∑‰ΩøÁî®Êé®ÁêÜ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `ËßÜËßâËØ≠Ë®ÄÊ®°Âûã` `Â∑•ÂÖ∑‰ΩøÁî®` `Âº∫ÂåñÂ≠¶‰π†` `Ê®°‰ªøÂ≠¶‰π†` `ÂÅèÂ•ΩÂ≠¶‰π†` `AgentË∞É‰ºò`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâVLMÂú®Â∑•ÂÖ∑‰ΩøÁî®Êé®ÁêÜÊñπÈù¢ÂèóÈôê‰∫éÈ´òË¥®ÈáèÂ§öÊ®°ÊÄÅÊï∞ÊçÆÁöÑÁ®ÄÁº∫‰ª•ÂèäÈ´òÊòÇÁöÑ‰∫∫Â∑•Ê†áÊ≥®ÊàêÊú¨„ÄÇ
2. ÊèêÂá∫MATRIXÊ°ÜÊû∂ÔºåÈÄöËøáËá™Âä®ÂêàÊàêÂ§öÊ®°ÊÄÅËΩ®ËøπÂíåÂÅèÂ•ΩÂØπÔºåÂÆûÁé∞VLMÊéßÂà∂Âô®ÁöÑÁ®≥ÂÅ•Â∑•ÂÖ∑‰ΩøÁî®Êé®ÁêÜ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåMATRIXÂú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠Ë∂ÖË∂ä‰∫ÜÁé∞ÊúâÂºÄÊ∫êÂíåÈó≠Ê∫êVLMÔºåËØÅÊòé‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËßÜËßâËØ≠Ë®ÄÊ®°Âûã(VLMs)Ë∂äÊù•Ë∂äÂ§öÂú∞Ë¢´ÈÉ®ÁΩ≤‰∏∫ÊéßÂà∂Âô®ÔºåÁî®‰∫éËÆøÈóÆÂ§ñÈÉ®Â∑•ÂÖ∑‰ª•ËøõË°åÂ§çÊùÇÁöÑÊé®ÁêÜÂíåÂÜ≥Á≠ñÔºå‰ΩÜÂÖ∂ÊúâÊïàÊÄß‰ªçÁÑ∂ÂèóÂà∞È´òË¥®ÈáèÂ§öÊ®°ÊÄÅËΩ®ËøπÁ®ÄÁº∫ÂíåÊâãÂä®Ê†áÊ≥®ÊàêÊú¨ÁöÑÈôêÂà∂„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßç‰ª•ËßÜËßâ‰∏∫‰∏≠ÂøÉAgentË∞É‰ºòÊ°ÜÊû∂ÔºåËØ•Ê°ÜÊû∂Ëá™Âä®ÂêàÊàêÂ§öÊ®°ÊÄÅËΩ®ËøπÔºåÁîüÊàêÈÄêÊ≠•ÂÅèÂ•ΩÂØπÔºåÂπ∂ËÆ≠ÁªÉVLMÊéßÂà∂Âô®‰ª•ÂÆûÁé∞Á®≥ÂÅ•ÁöÑÂ∑•ÂÖ∑‰ΩøÁî®Êé®ÁêÜ„ÄÇËØ•ÊµÅÁ®ãÈ¶ñÂÖàÊûÑÂª∫M-TRACEÔºå‰∏Ä‰∏™ÂåÖÂê´28.5KÂ§öÊ®°ÊÄÅ‰ªªÂä°Âíå177KÈ™åËØÅËΩ®ËøπÁöÑÂ§ßËßÑÊ®°Êï∞ÊçÆÈõÜÔºå‰ªéËÄåÂÆûÁé∞Âü∫‰∫éÊ®°‰ªøÁöÑËΩ®ËøπË∞É‰ºò„ÄÇÂú®Ê≠§Âü∫Á°Ä‰∏äÔºåÂºÄÂèë‰∫ÜMATRIX AgentÔºå‰∏Ä‰∏™Âú®M-TRACE‰∏äËøõË°åÂæÆË∞ÉÁöÑÊéßÂà∂Âô®ÔºåÁî®‰∫éÈÄêÊ≠•Â∑•ÂÖ∑Êé®ÁêÜ„ÄÇ‰∏∫‰∫ÜÂÆûÁé∞Êõ¥Á≤æÁªÜÁöÑÂØπÈΩêÔºåËøõ‰∏ÄÊ≠•ÂºïÂÖ•‰∫ÜPref-XÔºå‰∏Ä‰∏™ÂåÖÂê´11KËá™Âä®ÁîüÊàêÁöÑÂÅèÂ•ΩÂØπÁöÑÈõÜÂêàÔºåÂπ∂ÈÄöËøáÈÄêÊ≠•ÂÅèÂ•ΩÂ≠¶‰π†ÂØπÂÖ∂ËøõË°å‰ºòÂåñ„ÄÇÂú®Agent-X„ÄÅGTAÂíåGAIA‰∏â‰∏™Âü∫ÂáÜÊµãËØï‰∏≠ÔºåMATRIXÂßãÁªà‰ºò‰∫éÂºÄÊ∫êÂíåÈó≠Ê∫êVLMÔºåÂ±ïÁ§∫‰∫ÜÂèØÊâ©Â±ï‰∏îÊúâÊïàÁöÑÂ§öÊ®°ÊÄÅÂ∑•ÂÖ∑‰ΩøÁî®„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÂú®Â§çÊùÇÊé®ÁêÜÂíåÂÜ≥Á≠ñ‰ªªÂä°‰∏≠ÔºåÈúÄË¶ÅÂÄüÂä©Â§ñÈÉ®Â∑•ÂÖ∑Ôºå‰ΩÜÁº∫‰πèË∂≥Â§üÁöÑÈ´òË¥®ÈáèÂ§öÊ®°ÊÄÅÊï∞ÊçÆÊù•ËÆ≠ÁªÉÂíå‰ºòÂåñËøô‰∫õÊ®°ÂûãÔºåÂêåÊó∂‰∫∫Â∑•Ê†áÊ≥®ÊàêÊú¨ËøáÈ´òÔºåÈôêÂà∂‰∫ÜÊ®°ÂûãÁöÑÊÄßËÉΩÊèêÂçá„ÄÇÁé∞ÊúâÊñπÊ≥ïÈöæ‰ª•ÊúâÊïàÂú∞Âà©Áî®ÊúâÈôêÁöÑÊï∞ÊçÆËøõË°åËÆ≠ÁªÉÔºåÂØºËá¥Â∑•ÂÖ∑‰ΩøÁî®Êé®ÁêÜËÉΩÂäõ‰∏çË∂≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáËá™Âä®ÁîüÊàêÂ§ßËßÑÊ®°ÁöÑÂ§öÊ®°ÊÄÅËΩ®ËøπÊï∞ÊçÆÂíåÂÅèÂ•ΩÂØπÊï∞ÊçÆÔºåÊù•Ëß£ÂÜ≥Êï∞ÊçÆÁ®ÄÁº∫ÈóÆÈ¢ò„ÄÇÈÄöËøáÊ®°‰ªøÂ≠¶‰π†ÂíåÂÅèÂ•ΩÂ≠¶‰π†ÔºåÂØπVLMÊéßÂà∂Âô®ËøõË°åÂæÆË∞ÉÔºå‰ªéËÄåÊèêÂçáÂÖ∂Â∑•ÂÖ∑‰ΩøÁî®Êé®ÁêÜËÉΩÂäõ„ÄÇËøôÁßçÊñπÊ≥ïÈÅøÂÖç‰∫ÜÊòÇË¥µÁöÑ‰∫∫Â∑•Ê†áÊ≥®ÔºåÂπ∂ËÉΩÂ§üÊúâÊïàÂú∞Âà©Áî®ÂêàÊàêÊï∞ÊçÆËøõË°åÊ®°ÂûãËÆ≠ÁªÉ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöMATRIXÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÈò∂ÊÆµÔºö1) **M-TRACEÊï∞ÊçÆÈõÜÊûÑÂª∫**ÔºöËá™Âä®ÂêàÊàêÂ§ßËßÑÊ®°Â§öÊ®°ÊÄÅ‰ªªÂä°ÂíåÈ™åËØÅËΩ®Ëøπ„ÄÇ2) **AgentÂàùÂßãÂåñ**ÔºöÂú®M-TRACEÊï∞ÊçÆÈõÜ‰∏äËøõË°åÊ®°‰ªøÂ≠¶‰π†ÔºåËÆ≠ÁªÉÂæóÂà∞MATRIX Agent„ÄÇ3) **Pref-XÊï∞ÊçÆÈõÜÊûÑÂª∫**ÔºöËá™Âä®ÁîüÊàêÂÅèÂ•ΩÂØπÊï∞ÊçÆÔºåÁî®‰∫éÂÅèÂ•ΩÂ≠¶‰π†„ÄÇ4) **ÂÅèÂ•ΩÂ≠¶‰π†**ÔºöÂà©Áî®Pref-XÊï∞ÊçÆÈõÜÂØπMATRIX AgentËøõË°åÂæÆË∞ÉÔºåËøõ‰∏ÄÊ≠•ÊèêÂçáÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫Ü‰∏ÄÁßçËá™Âä®ÁîüÊàêÂ§öÊ®°ÊÄÅËΩ®ËøπÂíåÂÅèÂ•ΩÂØπÊï∞ÊçÆÁöÑÊñπÊ≥ïÔºå‰ªéËÄåËß£ÂÜ≥‰∫ÜVLMÂú®Â∑•ÂÖ∑‰ΩøÁî®Êé®ÁêÜÊñπÈù¢ÁöÑÊï∞ÊçÆÁ®ÄÁº∫ÈóÆÈ¢ò„ÄÇËøôÁßçÊñπÊ≥ïËÉΩÂ§üÊúâÊïàÂú∞Âà©Áî®ÂêàÊàêÊï∞ÊçÆËøõË°åÊ®°ÂûãËÆ≠ÁªÉÔºåÈÅøÂÖç‰∫ÜÊòÇË¥µÁöÑ‰∫∫Â∑•Ê†áÊ≥®ÔºåÂπ∂ÊòæËëóÊèêÂçá‰∫ÜÊ®°ÂûãÁöÑÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöM-TRACEÊï∞ÊçÆÈõÜÂåÖÂê´28.5KÂ§öÊ®°ÊÄÅ‰ªªÂä°Âíå177KÈ™åËØÅËΩ®Ëøπ„ÄÇPref-XÊï∞ÊçÆÈõÜÂåÖÂê´11KËá™Âä®ÁîüÊàêÁöÑÂÅèÂ•ΩÂØπ„ÄÇMATRIX AgentÂü∫‰∫éVLMËøõË°åÂæÆË∞ÉÔºåÈááÁî®Ê®°‰ªøÂ≠¶‰π†ÂíåÂÅèÂ•ΩÂ≠¶‰π†Áõ∏ÁªìÂêàÁöÑÊñπÂºèËøõË°åËÆ≠ÁªÉ„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨Ê®°‰ªøÂ≠¶‰π†ÊçüÂ§±ÂíåÂÅèÂ•ΩÂ≠¶‰π†ÊçüÂ§±„ÄÇÂÖ∑‰ΩìVLMÊû∂ÊûÑÂíåË∂ÖÂèÇÊï∞ËÆæÁΩÆÂú®ËÆ∫Êñá‰∏≠ÊúâËØ¶ÁªÜÊèèËø∞ÔºàÊ≠§Â§ÑÊú™Áü•ÔºåÊ†πÊçÆËÆ∫ÊñáË°•ÂÖÖÔºâ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåMATRIXÂú®Agent-X„ÄÅGTAÂíåGAIA‰∏â‰∏™Âü∫ÂáÜÊµãËØï‰∏≠ÂùáÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåË∂ÖË∂ä‰∫ÜÁé∞ÊúâÁöÑÂºÄÊ∫êÂíåÈó≠Ê∫êVLM„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåMATRIXÂú®ÂêÑÈ°πÊåáÊ†á‰∏äÂùá‰ºò‰∫éÂØπÊØîÊñπÊ≥ïÔºåËØÅÊòé‰∫ÜÂÖ∂Âú®Â§öÊ®°ÊÄÅÂ∑•ÂÖ∑‰ΩøÁî®Êé®ÁêÜÊñπÈù¢ÁöÑÊúâÊïàÊÄßÂíå‰ºòË∂äÊÄß„ÄÇÂÖ∑‰ΩìÁöÑÊÄßËÉΩÊèêÂçáÂπÖÂ∫¶ÈúÄË¶ÅÂú®ËÆ∫Êñá‰∏≠Êü•ÊâæÂÖ∑‰ΩìÊï∞ÊçÆ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂêÑÁßçÈúÄË¶ÅËßÜËßâËØ≠Ë®ÄÊ®°ÂûãËøõË°åÂ§çÊùÇÊé®ÁêÜÂíåÂÜ≥Á≠ñÁöÑÂú∫ÊôØÔºå‰æãÂ¶ÇÊú∫Âô®‰∫∫ÊéßÂà∂„ÄÅÊô∫ËÉΩÂä©Êâã„ÄÅÊ∏∏ÊàèAIÁ≠â„ÄÇÈÄöËøáÊèêÂçáVLMÁöÑÂ∑•ÂÖ∑‰ΩøÁî®Êé®ÁêÜËÉΩÂäõÔºåÂèØ‰ª•ÂÆûÁé∞Êõ¥Êô∫ËÉΩ„ÄÅÊõ¥Ëá™‰∏ªÁöÑÁ≥ªÁªüÔºå‰ªéËÄåÊèêÈ´òÁîü‰∫ßÊïàÁéáÂíåÁî®Êà∑‰ΩìÈ™å„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïÂèØ‰ª•Êâ©Â±ïÂà∞Êõ¥Â§öÊ®°ÊÄÅÂíåÊõ¥Â§çÊùÇÁöÑ‰ªªÂä°‰∏≠„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Vision language models (VLMs) are increasingly deployed as controllers with access to external tools for complex reasoning and decision-making, yet their effectiveness remains limited by the scarcity of high-quality multimodal trajectories and the cost of manual annotation. We address this challenge with a vision-centric agent tuning framework that automatically synthesizes multimodal trajectories, generates step-wise preference pairs, and trains a VLM controller for robust tool-use reasoning. Our pipeline first constructs M-TRACE, a large-scale dataset of 28.5K multimodal tasks with 177K verified trajectories, enabling imitation-based trajectory tuning. Building on this, we develop MATRIX Agent, a controller finetuned on M-TRACE for step-wise tool reasoning. To achieve finer alignment, we further introduce Pref-X, a set of 11K automatically generated preference pairs, and optimize MATRIX on it via step-wise preference learning. Across three benchmarks, Agent-X, GTA, and GAIA, MATRIX consistently surpasses both open- and closed-source VLMs, demonstrating scalable and effective multimodal tool use. Our data and code is avaliable at https://github.com/mbzuai-oryx/MATRIX.

