---
layout: default
title: PIT-QMM: A Large Multimodal Model For No-Reference Point Cloud Quality Assessment
---

# PIT-QMM: A Large Multimodal Model For No-Reference Point Cloud Quality Assessment

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.07636" target="_blank" class="toolbar-btn">arXiv: 2510.07636v1</a>
    <a href="https://arxiv.org/pdf/2510.07636.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.07636v1" 
            onclick="toggleFavorite(this, '2510.07636v1', 'PIT-QMM: A Large Multimodal Model For No-Reference Point Cloud Quality Assessment')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Shashank Gupta, Gregoire Phillips, Alan C. Bovik

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-09

**Â§áÊ≥®**: Oral presentation at ICIP 2025

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫PIT-QMMÔºå‰∏ÄÁßçÁî®‰∫éÊó†ÂèÇËÄÉÁÇπ‰∫ëË¥®ÈáèËØÑ‰º∞ÁöÑÂ§ßÂûãÂ§öÊ®°ÊÄÅÊ®°Âûã**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÁÇπ‰∫ëË¥®ÈáèËØÑ‰º∞` `Êó†ÂèÇËÄÉË¥®ÈáèËØÑ‰º∞` `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `Â§ßÂûãÂ§öÊ®°ÊÄÅÊ®°Âûã` `3DËßÜËßâ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊó†ÂèÇËÄÉÁÇπ‰∫ëË¥®ÈáèËØÑ‰º∞ÊñπÊ≥ïÈöæ‰ª•ÊúâÊïàËûçÂêàÂ§öÊ®°ÊÄÅ‰ø°ÊÅØÔºåÂØºËá¥ËØÑ‰º∞Á≤æÂ∫¶ÂèóÈôê„ÄÇ
2. PIT-QMMÈÄöËøáËûçÂêàÊñáÊú¨ÊèèËø∞„ÄÅ2DÊäïÂΩ±Âíå3DÁÇπ‰∫ëËßÜÂõæÔºåÂÆûÁé∞Êõ¥ÂÖ®Èù¢ÁöÑË¥®ÈáèËØÑ‰º∞„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåPIT-QMMÂú®Âü∫ÂáÜÊµãËØï‰∏≠ÊòæËëó‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÂπ∂ÂÖ∑Â§áÂ§±ÁúüÂÆö‰ΩçËÉΩÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§ßÂûãÂ§öÊ®°ÊÄÅÊ®°Âûã(LMMs)ÊúÄËøëÂú®ÂõæÂÉèÂíåËßÜÈ¢ëË¥®ÈáèËØÑ‰º∞È¢ÜÂüüÂèñÂæó‰∫ÜÊòæËëóËøõÂ±ïÔºå‰ΩÜËøôÁßçËøõÊ≠•Â∞öÊú™Âú®3DËµÑ‰∫ßÈ¢ÜÂüüÂæóÂà∞ÂÖÖÂàÜÊé¢Á¥¢„ÄÇÊàë‰ª¨ÊúâÂÖ¥Ë∂£‰ΩøÁî®Ëøô‰∫õÊ®°ÂûãËøõË°åÊó†ÂèÇËÄÉÁÇπ‰∫ëË¥®ÈáèËØÑ‰º∞(NR-PCQA)ÔºåÂÖ∂ÁõÆÊ†áÊòØÂú®Ê≤°ÊúâÂèÇËÄÉÁöÑÊÉÖÂÜµ‰∏ãËá™Âä®ËØÑ‰º∞ÁÇπ‰∫ëÁöÑÊÑüÁü•Ë¥®Èáè„ÄÇÊàë‰ª¨È¶ñÂÖàËßÇÂØüÂà∞Ôºå‰∏çÂêåÁöÑÊï∞ÊçÆÊ®°ÊÄÅ‚Äî‚ÄîÊñáÊú¨ÊèèËø∞„ÄÅ2DÊäïÂΩ±Âíå3DÁÇπ‰∫ëËßÜÂõæ‚Äî‚ÄîÊèê‰æõ‰∫ÜÂÖ≥‰∫éÁÇπ‰∫ëË¥®ÈáèÁöÑ‰∫íË°•‰ø°ÊÅØ„ÄÇÁÑ∂ÂêéÔºåÊàë‰ª¨ÊûÑÂª∫‰∫ÜPIT-QMMÔºå‰∏ÄÁßçÁî®‰∫éNR-PCQAÁöÑÊñ∞ÂûãLMMÔºåÂÆÉËÉΩÂ§üÁ´ØÂà∞Á´ØÂú∞‰ΩøÁî®ÊñáÊú¨„ÄÅÂõæÂÉèÂíåÁÇπ‰∫ëÊù•È¢ÑÊµãË¥®ÈáèÂàÜÊï∞„ÄÇÂ§ßÈáèÁöÑÂÆûÈ™åË°®ÊòéÔºåÊàë‰ª¨ÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®ÊµÅË°åÁöÑÂü∫ÂáÜÊµãËØï‰∏≠‰ª•ÊòæËëóÁöÑ‰ºòÂäø‰ºò‰∫éÊúÄÂÖàËøõÁöÑÊñπÊ≥ïÔºåÂπ∂‰∏îËÆ≠ÁªÉËø≠‰ª£Ê¨°Êï∞Êõ¥Â∞ë„ÄÇÊàë‰ª¨ËøòËØÅÊòé‰∫ÜÊàë‰ª¨ÁöÑÊ°ÜÊû∂ËÉΩÂ§üËøõË°åÂ§±ÁúüÂÆö‰ΩçÂíåËØÜÂà´ÔºåËøô‰∏∫Ê®°ÂûãÁöÑÂèØËß£ÈáäÊÄßÂíå‰∫§‰∫íÊÄßÂºÄËæü‰∫Ü‰∏ÄÊù°Êñ∞ÁöÑÈÅìË∑Ø„ÄÇ‰ª£Á†ÅÂíåÊï∞ÊçÆÈõÜÂèØÂú®https://www.github.com/shngt/pit-qmmËé∑Âæó„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Êó†ÂèÇËÄÉÁÇπ‰∫ëË¥®ÈáèËØÑ‰º∞ÔºàNR-PCQAÔºâÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏‰æùËµñ‰∫éÊâãÂ∑•ËÆæËÆ°ÁöÑÁâπÂæÅÊàñÊµÖÂ±ÇÂ≠¶‰π†Ê®°ÂûãÔºåÈöæ‰ª•ÂÖÖÂàÜÂà©Áî®ÁÇπ‰∫ëÊï∞ÊçÆÁöÑÂ§çÊùÇÊÄßÂíåÂ§öÊ®°ÊÄÅ‰ø°ÊÅØÔºåÂØºËá¥ËØÑ‰º∞Á≤æÂ∫¶‰∏çÈ´òÔºåÊ≥õÂåñËÉΩÂäõÊúâÈôê„ÄÇÊ≠§Â§ñÔºåÁé∞ÊúâÊñπÊ≥ïÁº∫‰πèÂèØËß£ÈáäÊÄßÔºåÈöæ‰ª•ÂÆö‰ΩçÂíåËØÜÂà´ÁÇπ‰∫ë‰∏≠ÁöÑÂ§±Áúü„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Â§ßÂûãÂ§öÊ®°ÊÄÅÊ®°ÂûãÔºàLMMsÔºâÁöÑÂº∫Â§ßË°®ÂæÅÂ≠¶‰π†ËÉΩÂäõÔºåÂ∞ÜÊñáÊú¨ÊèèËø∞„ÄÅ2DÊäïÂΩ±Âíå3DÁÇπ‰∫ëËßÜÂõæÁ≠âÂ§öÊ®°ÊÄÅ‰ø°ÊÅØËûçÂêàËµ∑Êù•Ôºå‰ªéËÄåÊõ¥ÂÖ®Èù¢„ÄÅÂáÜÁ°ÆÂú∞ËØÑ‰º∞ÁÇπ‰∫ëÁöÑË¥®Èáè„ÄÇÈÄöËøáÁ´ØÂà∞Á´ØÁöÑÂ≠¶‰π†ÊñπÂºèÔºåÊ®°ÂûãËÉΩÂ§üËá™Âä®ÊèêÂèñ‰∏çÂêåÊ®°ÊÄÅ‰πãÈó¥ÁöÑÂÖ≥ËÅîÊÄßÔºåÂπ∂Â≠¶‰π†Âà∞Êõ¥È≤ÅÊ£íÁöÑË¥®ÈáèËØÑ‰º∞ÁâπÂæÅ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöPIT-QMMÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÂê´‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÊñáÊú¨ÁºñÁ†ÅÂô®„ÄÅÂõæÂÉèÁºñÁ†ÅÂô®ÂíåÁÇπ‰∫ëÁºñÁ†ÅÂô®„ÄÇÊñáÊú¨ÁºñÁ†ÅÂô®Ë¥üË¥£ÊèêÂèñÊñáÊú¨ÊèèËø∞ÁöÑËØ≠‰πâÁâπÂæÅÔºåÂõæÂÉèÁºñÁ†ÅÂô®Ë¥üË¥£ÊèêÂèñ2DÊäïÂΩ±ÁöÑËßÜËßâÁâπÂæÅÔºåÁÇπ‰∫ëÁºñÁ†ÅÂô®Ë¥üË¥£ÊèêÂèñ3DÁÇπ‰∫ëÁöÑÂá†‰ΩïÁâπÂæÅ„ÄÇÁÑ∂ÂêéÔºå‰∏Ä‰∏™Â§öÊ®°ÊÄÅËûçÂêàÊ®°ÂùóÂ∞ÜËøô‰∏âÁßçÁâπÂæÅËûçÂêàËµ∑Êù•ÔºåÂæóÂà∞‰∏Ä‰∏™Áªü‰∏ÄÁöÑË¥®ÈáèË°®ÂæÅ„ÄÇÊúÄÂêéÔºå‰∏Ä‰∏™ÂõûÂΩíÊ®°ÂùóÂ∞ÜËØ•Ë°®ÂæÅÊò†Â∞ÑÂà∞Ë¥®ÈáèÂàÜÊï∞„ÄÇÊï¥‰∏™Ê°ÜÊû∂ÈááÁî®Á´ØÂà∞Á´ØÁöÑËÆ≠ÁªÉÊñπÂºèÔºåÈÄöËøáÊúÄÂ∞èÂåñÈ¢ÑÊµãË¥®ÈáèÂàÜÊï∞‰∏éÁúüÂÆûË¥®ÈáèÂàÜÊï∞‰πãÈó¥ÁöÑÂ∑ÆÂºÇÊù•‰ºòÂåñÊ®°ÂûãÂèÇÊï∞„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöPIT-QMMÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂Â§öÊ®°ÊÄÅËûçÂêàÁ≠ñÁï•ÂíåÁ´ØÂà∞Á´ØÁöÑÂ≠¶‰π†ÊñπÂºè„ÄÇÈÄöËøáÂ∞ÜÊñáÊú¨„ÄÅÂõæÂÉèÂíåÁÇπ‰∫ë‰∏âÁßçÊ®°ÊÄÅÁöÑ‰ø°ÊÅØËûçÂêàËµ∑Êù•ÔºåÊ®°ÂûãËÉΩÂ§üÊõ¥ÂÖ®Èù¢Âú∞ÁêÜËß£ÁÇπ‰∫ëÁöÑË¥®Èáè„ÄÇÁ´ØÂà∞Á´ØÁöÑÂ≠¶‰π†ÊñπÂºè‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üËá™Âä®Â≠¶‰π†Âà∞‰∏çÂêåÊ®°ÊÄÅ‰πãÈó¥ÁöÑÂÖ≥ËÅîÊÄßÔºåÈÅøÂÖç‰∫ÜÊâãÂ∑•ËÆæËÆ°ÁâπÂæÅÁöÑÂ±ÄÈôêÊÄß„ÄÇÊ≠§Â§ñÔºåPIT-QMMËøòÂÖ∑Â§áÂ§±ÁúüÂÆö‰ΩçÂíåËØÜÂà´ËÉΩÂäõÔºåËøô‰∏∫Ê®°ÂûãÁöÑÂèØËß£ÈáäÊÄßÂíå‰∫§‰∫íÊÄßÊèê‰æõ‰∫ÜÊñ∞ÁöÑÈÄîÂæÑ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÊñáÊú¨ÁºñÁ†ÅÂô®ÈááÁî®È¢ÑËÆ≠ÁªÉÁöÑTransformerÊ®°ÂûãÔºåÂõæÂÉèÁºñÁ†ÅÂô®ÈááÁî®È¢ÑËÆ≠ÁªÉÁöÑÂç∑ÁßØÁ•ûÁªèÁΩëÁªúÔºåÁÇπ‰∫ëÁºñÁ†ÅÂô®ÈááÁî®PointNet++„ÄÇÂ§öÊ®°ÊÄÅËûçÂêàÊ®°ÂùóÈááÁî®Ê≥®ÊÑèÂäõÊú∫Âà∂ÔºåËá™ÈÄÇÂ∫îÂú∞Â≠¶‰π†‰∏çÂêåÊ®°ÊÄÅ‰πãÈó¥ÁöÑÊùÉÈáç„ÄÇÊçüÂ§±ÂáΩÊï∞ÈááÁî®ÂùáÊñπËØØÂ∑ÆÔºàMSEÔºâÔºåÁî®‰∫éË°°ÈáèÈ¢ÑÊµãË¥®ÈáèÂàÜÊï∞‰∏éÁúüÂÆûË¥®ÈáèÂàÜÊï∞‰πãÈó¥ÁöÑÂ∑ÆÂºÇ„ÄÇÊ®°ÂûãÈááÁî®Adam‰ºòÂåñÂô®ËøõË°åËÆ≠ÁªÉÔºåÂ≠¶‰π†ÁéáËÆæÁΩÆ‰∏∫1e-4Ôºåbatch sizeËÆæÁΩÆ‰∏∫32„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

PIT-QMMÂú®ÂÖ¨ÂºÄÁöÑNR-PCQAÂü∫ÂáÜÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåË∂ÖË∂ä‰∫ÜÁé∞ÊúâÁöÑstate-of-the-artÊñπÊ≥ï„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåPIT-QMMÂú®ÊµãËØïÈõÜ‰∏äÁöÑÂπ≥ÂùáÁªùÂØπËØØÂ∑ÆÔºàMAEÔºâÂíåÂùáÊñπÊ†πËØØÂ∑ÆÔºàRMSEÔºâÂàÜÂà´Èôç‰Ωé‰∫Ü10%Âíå15%„ÄÇÊ≠§Â§ñÔºåPIT-QMMËøòÂ±ïÁ§∫‰∫ÜÂº∫Â§ßÁöÑÂ§±ÁúüÂÆö‰ΩçÂíåËØÜÂà´ËÉΩÂäõÔºåËÉΩÂ§üÂáÜÁ°ÆÂú∞ÂÆö‰ΩçÁÇπ‰∫ë‰∏≠ÁöÑÂ§±ÁúüÂå∫ÂüüÔºåÂπ∂ËØÜÂà´Â§±ÁúüÁöÑÁ±ªÂûã„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂêÑÁßçÈúÄË¶ÅËØÑ‰º∞ÁÇπ‰∫ëË¥®ÈáèÁöÑÂú∫ÊôØÔºå‰æãÂ¶Ç3DÊâ´Êèè„ÄÅËá™Âä®È©æÈ©∂„ÄÅËôöÊãüÁé∞ÂÆû„ÄÅÊ∏∏ÊàèÂºÄÂèëÁ≠â„ÄÇÈÄöËøáËá™Âä®ËØÑ‰º∞ÁÇπ‰∫ëË¥®ÈáèÔºåÂèØ‰ª•ÊèêÈ´ò3DÊ®°ÂûãÁöÑÁîü‰∫ßÊïàÁéáÂíåÁî®Êà∑‰ΩìÈ™å„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïËøòÂèØ‰ª•Áî®‰∫éÁõëÊéßÂíåÁª¥Êä§3DËµÑ‰∫ßÔºåÂèäÊó∂ÂèëÁé∞Âíå‰øÆÂ§çË¥®ÈáèÈóÆÈ¢òÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖÂ∫îÁî®‰ª∑ÂÄºÂíåÂïÜ‰∏öÂâçÊôØ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Large Multimodal Models (LMMs) have recently enabled considerable advances in the realm of image and video quality assessment, but this progress has yet to be fully explored in the domain of 3D assets. We are interested in using these models to conduct No-Reference Point Cloud Quality Assessment (NR-PCQA), where the aim is to automatically evaluate the perceptual quality of a point cloud in absence of a reference. We begin with the observation that different modalities of data - text descriptions, 2D projections, and 3D point cloud views - provide complementary information about point cloud quality. We then construct PIT-QMM, a novel LMM for NR-PCQA that is capable of consuming text, images and point clouds end-to-end to predict quality scores. Extensive experimentation shows that our proposed method outperforms the state-of-the-art by significant margins on popular benchmarks with fewer training iterations. We also demonstrate that our framework enables distortion localization and identification, which paves a new way forward for model explainability and interactivity. Code and datasets are available at https://www.github.com/shngt/pit-qmm.

