---
layout: default
title: InstructX: Towards Unified Visual Editing with MLLM Guidance
---

# InstructX: Towards Unified Visual Editing with MLLM Guidance

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.08485" target="_blank" class="toolbar-btn">arXiv: 2510.08485v1</a>
    <a href="https://arxiv.org/pdf/2510.08485.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.08485v1" 
            onclick="toggleFavorite(this, '2510.08485v1', 'InstructX: Towards Unified Visual Editing with MLLM Guidance')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Chong Mou, Qichao Sun, Yanze Wu, Pengze Zhang, Xinghui Li, Fulong Ye, Songtao Zhao, Qian He

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-09

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**InstructXÔºöÂü∫‰∫éMLLMÊåáÂØºÁöÑÁªü‰∏ÄËßÜËßâÁºñËæëÊ°ÜÊû∂ÔºåÂÆûÁé∞ÂõæÂÉèÂíåËßÜÈ¢ëÁºñËæë**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `ÂõæÂÉèÁºñËæë` `ËßÜÈ¢ëÁºñËæë` `Êâ©Êï£Ê®°Âûã` `Êåá‰ª§È©±Âä®ÁºñËæë`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÁº∫‰πèÂØπMLLMËÆæËÆ°ÈÄâÊã©ÁöÑÊ∑±ÂÖ•ÂàÜÊûêÔºå‰∏îMLLM‰∏éÊâ©Êï£Ê®°ÂûãÂú®ËßÜÈ¢ëÁºñËæëÁ≠â‰ªªÂä°‰∏≠ÁöÑÈõÜÊàê‰ªçÂÖ∑ÊåëÊàò„ÄÇ
2. InstructXÈÄöËøáÁ†îÁ©∂MLLM‰∏éÊâ©Êï£Ê®°ÂûãÁöÑÈõÜÊàêÔºåÂπ∂ÁªìÂêàÊ®°ÊÄÅÁâπÂÆöMLLMÁâπÂæÅÔºåÂÆûÁé∞‰∫ÜÂõæÂÉèÂíåËßÜÈ¢ëÁºñËæëÁöÑÁªü‰∏Ä„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåInstructXÊó†ÈúÄÊòæÂºèËßÜÈ¢ëÁõëÁù£ÔºåÂç≥ÂèØÂú®ÂõæÂÉèÊï∞ÊçÆËÆ≠ÁªÉÂêéÊ∂åÁé∞ËßÜÈ¢ëÁºñËæëËÉΩÂäõÔºåÂπ∂ËææÂà∞SOTAÊÄßËÉΩ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÈöèÁùÄÂ§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã(MLLM)Âú®ËßÜËßâÁêÜËß£ÂíåÊé®ÁêÜÊñπÈù¢ÁöÑÊúÄÊñ∞ËøõÂ±ïÔºå‰∫∫‰ª¨Ë∂äÊù•Ë∂äÊúâÂÖ¥Ë∂£Âà©Áî®ÂÆÉ‰ª¨Êù•ÊèêÈ´òÊâ©Êï£Ê®°ÂûãÁöÑÁºñËæëÊÄßËÉΩ„ÄÇÂ∞ΩÁÆ°ËøõÂ±ïËøÖÈÄüÔºå‰ΩÜÂ§ßÂ§öÊï∞Á†îÁ©∂Áº∫‰πèÂØπMLLMËÆæËÆ°ÈÄâÊã©ÁöÑÊ∑±ÂÖ•ÂàÜÊûê„ÄÇÊ≠§Â§ñÔºåÂú®‰∏Ä‰∫õÂõ∞ÈöæÁöÑ‰ªªÂä°‰∏≠Ôºå‰æãÂ¶ÇËßÜÈ¢ëÁºñËæëÔºåMLLMÂíåÊâ©Êï£Ê®°ÂûãÁöÑÈõÜÊàê‰ªçÁÑ∂ÊòØ‰∏Ä‰∏™ÂºÄÊîæÁöÑÊåëÊàò„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜInstructXÔºå‰∏Ä‰∏™Áî®‰∫éÂõæÂÉèÂíåËßÜÈ¢ëÁºñËæëÁöÑÁªü‰∏ÄÊ°ÜÊû∂„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨ÂØπMLLMÂíåÊâ©Êï£Ê®°ÂûãÁöÑÈõÜÊàêËøõË°å‰∫ÜÂÖ®Èù¢ÁöÑÁ†îÁ©∂Ôºå‰ª•ÂÆûÁé∞Ë∑®‰∏çÂêå‰ªªÂä°ÁöÑÊåá‰ª§È©±Âä®ÁºñËæë„ÄÇÂü∫‰∫éËøôÈ°πÁ†îÁ©∂ÔºåÊàë‰ª¨ÂàÜÊûê‰∫ÜÂõæÂÉèÂíåËßÜÈ¢ëÂú®Áªü‰∏ÄÂª∫Ê®°‰∏≠ÁöÑÂêà‰Ωú‰∏éÂå∫Âà´„ÄÇ(1)Êàë‰ª¨Ë°®ÊòéÔºåÂú®ÂõæÂÉèÊï∞ÊçÆ‰∏äËÆ≠ÁªÉÂèØ‰ª•‰∫ßÁîüÊñ∞ÂÖ¥ÁöÑËßÜÈ¢ëÁºñËæëËÉΩÂäõÔºåËÄåÊó†ÈúÄÊòéÁ°ÆÁöÑÁõëÁù£Ôºå‰ªéËÄåÂáèËΩª‰∫ÜÁ®ÄÁº∫ËßÜÈ¢ëËÆ≠ÁªÉÊï∞ÊçÆÂ∏¶Êù•ÁöÑÁ∫¶Êùü„ÄÇ(2)ÈÄöËøáÁªìÂêàÁâπÂÆöÊ®°ÊÄÅÁöÑMLLMÁâπÂæÅÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÊúâÊïàÂú∞Â∞ÜÂõæÂÉèÂíåËßÜÈ¢ëÁºñËæë‰ªªÂä°Áªü‰∏ÄÂú®‰∏Ä‰∏™Ê®°Âûã‰∏≠„ÄÇÂ§ßÈáèÁöÑÂÆûÈ™åË°®ÊòéÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂèØ‰ª•Â§ÑÁêÜÂπøÊ≥õÁöÑÂõæÂÉèÂíåËßÜÈ¢ëÁºñËæë‰ªªÂä°ÔºåÂπ∂ËææÂà∞ÊúÄÂÖàËøõÁöÑÊÄßËÉΩ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥ÂõæÂÉèÂíåËßÜÈ¢ëÁºñËæë‰ªªÂä°‰∏≠ÔºåÁé∞ÊúâÊñπÊ≥ïÂØπÂ§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMÔºâÂà©Áî®‰∏çË∂≥Ôºå‰ª•ÂèäÂõæÂÉèÂíåËßÜÈ¢ëÁºñËæë‰ªªÂä°ÂàÜÁ¶ªÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏ÈíàÂØπÁâπÂÆöÊ®°ÊÄÅÊàñ‰ªªÂä°ËøõË°åËÆæËÆ°ÔºåÁº∫‰πèÈÄöÁî®ÊÄßÂíåÊ≥õÂåñËÉΩÂäõÔºåÂ∞§ÂÖ∂ÊòØÂú®ËßÜÈ¢ëÁºñËæëÊï∞ÊçÆÁ®ÄÁº∫ÁöÑÊÉÖÂÜµ‰∏ãË°®Áé∞‰∏ç‰Ω≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöInstructXÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®MLLMÂº∫Â§ßÁöÑËßÜËßâÁêÜËß£ÂíåÊé®ÁêÜËÉΩÂäõÔºåÊåáÂØºÊâ©Êï£Ê®°ÂûãËøõË°åÂõæÂÉèÂíåËßÜÈ¢ëÁºñËæë„ÄÇÈÄöËøáÁªü‰∏ÄÁöÑÊ°ÜÊû∂ÔºåÂ∞ÜÂõæÂÉèÂíåËßÜÈ¢ëÁºñËæë‰ªªÂä°Êï¥ÂêàÂú®‰∏ÄËµ∑ÔºåÂπ∂Âà©Áî®ÂõæÂÉèÊï∞ÊçÆËÆ≠ÁªÉÊù•ÊèêÂçáËßÜÈ¢ëÁºñËæëËÉΩÂäõÔºå‰ªéËÄåÁºìËß£ËßÜÈ¢ëÊï∞ÊçÆÁ®ÄÁº∫ÁöÑÈóÆÈ¢ò„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöInstructXÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) MLLMÁâπÂæÅÊèêÂèñÊ®°ÂùóÔºöÁî®‰∫éÊèêÂèñÂõæÂÉèÂíåËßÜÈ¢ëÁöÑÊ®°ÊÄÅÁâπÂÆöÁâπÂæÅ„ÄÇ2) Êâ©Êï£Ê®°ÂûãÁºñËæëÊ®°ÂùóÔºöÂà©Áî®Êâ©Êï£Ê®°ÂûãÁîüÊàêÁºñËæëÂêéÁöÑÂõæÂÉèÊàñËßÜÈ¢ë„ÄÇ3) Êåá‰ª§ÂºïÂØºÊ®°ÂùóÔºöÂà©Áî®MLLMÁöÑÊåá‰ª§ÁêÜËß£ËÉΩÂäõÔºåÊåáÂØºÊâ©Êï£Ê®°ÂûãÁöÑÁºñËæëËøáÁ®ã„ÄÇÊï¥‰∏™ÊµÅÁ®ãÊòØÔºåÈ¶ñÂÖàËæìÂÖ•ÂõæÂÉèÊàñËßÜÈ¢ë‰ª•ÂèäÁºñËæëÊåá‰ª§ÔºåMLLMÊèêÂèñÊ®°ÊÄÅÁâπÂÆöÁâπÂæÅÔºåÁÑ∂ÂêéÊåá‰ª§ÂºïÂØºÊâ©Êï£Ê®°ÂûãÊ†πÊçÆÊèêÂèñÁöÑÁâπÂæÅÂíåÊåá‰ª§ÁîüÊàêÁºñËæëÂêéÁöÑÁªìÊûú„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöInstructXÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1) ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Áªü‰∏ÄÁöÑÂõæÂÉèÂíåËßÜÈ¢ëÁºñËæëÊ°ÜÊû∂ÔºåËÉΩÂ§üÂ§ÑÁêÜÂ§öÁßçÁºñËæë‰ªªÂä°„ÄÇ2) ËØÅÊòé‰∫ÜÂú®ÂõæÂÉèÊï∞ÊçÆ‰∏äËÆ≠ÁªÉÂèØ‰ª•‰∫ßÁîüÊñ∞ÂÖ¥ÁöÑËßÜÈ¢ëÁºñËæëËÉΩÂäõÔºå‰ªéËÄåÁºìËß£‰∫ÜËßÜÈ¢ëÊï∞ÊçÆÁ®ÄÁº∫ÁöÑÈóÆÈ¢ò„ÄÇ3) ÈÄöËøáÁªìÂêàÊ®°ÊÄÅÁâπÂÆöMLLMÁâπÂæÅÔºåÊúâÊïàÊèêÂçá‰∫ÜÂõæÂÉèÂíåËßÜÈ¢ëÁºñËæëÁöÑÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöInstructXÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ‰ΩøÁî®ÁâπÂÆöÊ®°ÊÄÅÁöÑMLLMÁâπÂæÅÔºå‰ª•Âå∫ÂàÜÂõæÂÉèÂíåËßÜÈ¢ëÁöÑÁâπÊÄß„ÄÇ2) ËÆæËÆ°‰∫ÜÂêàÈÄÇÁöÑÊçüÂ§±ÂáΩÊï∞Ôºå‰ª•‰øùËØÅÁºñËæëÂêéÁöÑÂõæÂÉèÂíåËßÜÈ¢ëÁöÑË¥®ÈáèÂíå‰∏ÄËá¥ÊÄß„ÄÇ3) Êé¢Á¥¢‰∫Ü‰∏çÂêåÁöÑÁΩëÁªúÁªìÊûÑÔºå‰ª•ÊèêÂçáÊ®°ÂûãÁöÑÊÄßËÉΩÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇÂÖ∑‰ΩìÁöÑÂèÇÊï∞ËÆæÁΩÆÂíåÁΩëÁªúÁªìÊûÑÁªÜËäÇÂú®ËÆ∫Êñá‰∏≠ÊúâËØ¶ÁªÜÊèèËø∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

InstructXÂú®ÂõæÂÉèÂíåËßÜÈ¢ëÁºñËæë‰ªªÂä°‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåËææÂà∞‰∫Üstate-of-the-artÊ∞¥Âπ≥„ÄÇËØ•ÊñπÊ≥ïÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äËøõË°å‰∫ÜËØÑ‰º∞ÔºåÂåÖÊã¨ÂõæÂÉèÁºñËæëÊï∞ÊçÆÈõÜÂíåËßÜÈ¢ëÁºñËæëÊï∞ÊçÆÈõÜ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåInstructXËÉΩÂ§üÊúâÊïàÂú∞Â§ÑÁêÜÂêÑÁßçÁºñËæë‰ªªÂä°ÔºåÂπ∂‰∏îÂú®ËßÜÈ¢ëÁºñËæë‰ªªÂä°‰∏äË°®Áé∞Â∞§‰∏∫Á™ÅÂá∫ÔºåËØÅÊòé‰∫ÜÂÖ∂Âú®ÂõæÂÉèÊï∞ÊçÆ‰∏äËÆ≠ÁªÉÂêéÊ∂åÁé∞ËßÜÈ¢ëÁºñËæëËÉΩÂäõÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

InstructXÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂåÖÊã¨ÂõæÂÉèÂíåËßÜÈ¢ëÂÜÖÂÆπÂàõ‰Ωú„ÄÅËá™Âä®ÂåñÂõæÂÉèÂíåËßÜÈ¢ëÁºñËæë„ÄÅËôöÊãüÁé∞ÂÆûÂíåÂ¢ûÂº∫Áé∞ÂÆûÁ≠âÈ¢ÜÂüü„ÄÇËØ•Á†îÁ©∂ÂèØ‰ª•Â∏ÆÂä©Áî®Êà∑Êõ¥ËΩªÊùæÂú∞ÁºñËæëÂõæÂÉèÂíåËßÜÈ¢ëÔºåÊèêÈ´òÂÜÖÂÆπÂàõ‰ΩúÊïàÁéáÔºåÂπ∂‰∏∫ËôöÊãüÁé∞ÂÆûÂíåÂ¢ûÂº∫Áé∞ÂÆûÂ∫îÁî®Êèê‰æõÊõ¥ÈÄºÁúüÁöÑËßÜËßâ‰ΩìÈ™å„ÄÇÊú™Êù•ÔºåInstructXÊúâÊúõÊàê‰∏∫ËßÜËßâÂÜÖÂÆπÂàõ‰ΩúÂíåÁºñËæëÁöÑÈáçË¶ÅÂ∑•ÂÖ∑„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> With recent advances in Multimodal Large Language Models (MLLMs) showing strong visual understanding and reasoning, interest is growing in using them to improve the editing performance of diffusion models. Despite rapid progress, most studies lack an in-depth analysis of MLLM design choices. Moreover, the integration of MLLMs and diffusion models remains an open challenge in some difficult tasks, such as video editing. In this paper, we present InstructX, a unified framework for image and video editing. Specifically, we conduct a comprehensive study on integrating MLLMs and diffusion models for instruction-driven editing across diverse tasks. Building on this study, we analyze the cooperation and distinction between images and videos in unified modeling. (1) We show that training on image data can lead to emergent video editing capabilities without explicit supervision, thereby alleviating the constraints imposed by scarce video training data. (2) By incorporating modality-specific MLLM features, our approach effectively unifies image and video editing tasks within a single model. Extensive experiments demonstrate that our method can handle a broad range of image and video editing tasks and achieves state-of-the-art performance.

