---
layout: default
title: VideoNorms: Benchmarking Cultural Awareness of Video Language Models
---

# VideoNorms: Benchmarking Cultural Awareness of Video Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.08543" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.08543v1</a>
  <a href="https://arxiv.org/pdf/2510.08543.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.08543v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.08543v1', 'VideoNorms: Benchmarking Cultural Awareness of Video Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Nikhil Reddy Varimalla, Yunfei Xu, Arkadiy Saakyan, Meng Fan Wang, Smaranda Muresan

**åˆ†ç±»**: cs.CV, cs.AI, cs.CL, cs.CY

**å‘å¸ƒæ—¥æœŸ**: 2025-10-09

**å¤‡æ³¨**: 24 pages, 5 figures, under review

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**VideoNormsï¼šæ„å»ºè§†é¢‘è¯­è¨€æ¨¡å‹æ–‡åŒ–æ„è¯†åŸºå‡†ï¼Œæ­ç¤ºæ¨¡å‹åœ¨è·¨æ–‡åŒ–ç†è§£ä¸Šçš„ä¸è¶³ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†é¢‘è¯­è¨€æ¨¡å‹` `æ–‡åŒ–æ„è¯†` `åŸºå‡†æ•°æ®é›†` `äººæœºåä½œ` `ç¤¾ä¼šæ–‡åŒ–è§„èŒƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†é¢‘è¯­è¨€æ¨¡å‹ç¼ºä¹å¯¹ä¸åŒæ–‡åŒ–çš„æ·±å…¥ç†è§£ï¼Œå¯¼è‡´åœ¨å…¨çƒéƒ¨ç½²æ—¶å¯èƒ½å‡ºç°è¯¯è§£æˆ–é”™è¯¯ã€‚
2. è®ºæ–‡æå‡ºVideoNormsåŸºå‡†ï¼ŒåŒ…å«ç¾å›½å’Œä¸­å›½æ–‡åŒ–çš„è§†é¢‘ç‰‡æ®µï¼Œæ ‡æ³¨äº†ç¤¾ä¼šæ–‡åŒ–è§„èŒƒåŠå…¶è¿åæƒ…å†µã€‚
3. å®éªŒè¡¨æ˜ï¼Œç°æœ‰æ¨¡å‹åœ¨æ–‡åŒ–è§„èŒƒè¿åã€ä¸­å›½æ–‡åŒ–ç†è§£å’Œéè¯­è¨€è¯æ®è¯†åˆ«æ–¹é¢è¡¨ç°è¾ƒå·®ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€è§†é¢‘å¤§è¯­è¨€æ¨¡å‹ï¼ˆVideoLLMï¼‰åœ¨å…¨çƒèŒƒå›´å†…çš„éƒ¨ç½²ï¼Œå®ƒä»¬éœ€è¦ç†è§£å¹¶æ‰æ ¹äºç›¸å…³çš„æ–‡åŒ–èƒŒæ™¯ã€‚ä¸ºäº†æ­£ç¡®è¯„ä¼°è¿™äº›æ¨¡å‹çš„æ–‡åŒ–æ„è¯†ï¼Œéœ€è¦å……åˆ†çš„åŸºå‡†ã€‚æˆ‘ä»¬å¼•å…¥äº†VideoNormsï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«1000å¤šä¸ªï¼ˆè§†é¢‘ç‰‡æ®µï¼Œè§„èŒƒï¼‰å¯¹çš„åŸºå‡†ï¼Œè¿™äº›æ•°æ®æ¥è‡ªç¾å›½å’Œä¸­å›½æ–‡åŒ–ï¼Œå¹¶æ ‡æ³¨äº†åŸºäºè¨€è¯­è¡Œä¸ºç†è®ºçš„ç¤¾ä¼šæ–‡åŒ–è§„èŒƒã€è§„èŒƒéµå®ˆå’Œè¿åæ ‡ç­¾ï¼Œä»¥åŠå£å¤´å’Œéå£å¤´è¯æ®ã€‚ä¸ºäº†æ„å»ºVideoNormsï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä¸€ç§äººæœºåä½œæ¡†æ¶ï¼Œå…¶ä¸­ä½¿ç”¨ç†è®ºé©±åŠ¨çš„æç¤ºçš„æ•™å¸ˆæ¨¡å‹æä¾›å€™é€‰æ³¨é‡Šï¼Œä¸€ç»„è®­ç»ƒæœ‰ç´ çš„äººç±»ä¸“å®¶éªŒè¯å¹¶çº æ­£è¿™äº›æ³¨é‡Šã€‚æˆ‘ä»¬åœ¨æ–°æ•°æ®é›†ä¸Šå¯¹å„ç§å¼€æºVideoLLMè¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼Œçªå‡ºäº†å‡ ä¸ªå¸¸è§è¶‹åŠ¿ï¼š1ï¼‰æ¨¡å‹åœ¨è§„èŒƒè¿åæ–¹é¢çš„è¡¨ç°æ¯”éµå®ˆå·®ï¼›2ï¼‰æ¨¡å‹åœ¨æ¶‰åŠä¸­å›½æ–‡åŒ–æ–¹é¢çš„è¡¨ç°æ¯”ç¾å›½æ–‡åŒ–å·®ï¼›3ï¼‰æ¨¡å‹åœ¨ä¸ºè§„èŒƒéµå®ˆ/è¿åæ ‡ç­¾æä¾›éå£å¤´è¯æ®æ–¹é¢æ¯”å£å¤´è¯æ®æ›´å›°éš¾ï¼Œå¹¶ä¸”éš¾ä»¥è¯†åˆ«ä¸è¨€è¯­è¡Œä¸ºç›¸å¯¹åº”çš„ç¡®åˆ‡è§„èŒƒï¼›4ï¼‰ä¸äººç±»ä¸åŒï¼Œæ¨¡å‹åœ¨æ­£å¼ã€éå¹½é»˜çš„è¯­å¢ƒä¸­è¡¨ç°æ›´å·®ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœå¼ºè°ƒäº†å¯¹æ–‡åŒ–åŸºç¡€çš„è§†é¢‘è¯­è¨€æ¨¡å‹è®­ç»ƒçš„éœ€æ±‚â€”â€”æˆ‘ä»¬çš„åŸºå‡†å’Œæ¡†æ¶å¼€å§‹è§£å†³è¿™ä¸€å·®è·ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰è§†é¢‘è¯­è¨€æ¨¡å‹ï¼ˆVideoLLMï¼‰åœ¨å…¨çƒéƒ¨ç½²æ—¶ï¼Œç¼ºä¹å¯¹ä¸åŒæ–‡åŒ–çš„ç†è§£ï¼Œå°¤å…¶æ˜¯åœ¨ç¤¾ä¼šæ–‡åŒ–è§„èŒƒæ–¹é¢ã€‚è¿™å¯¼è‡´æ¨¡å‹åœ¨è·¨æ–‡åŒ–åœºæ™¯ä¸‹çš„è¡¨ç°ä¸ä½³ï¼Œä¾‹å¦‚æ— æ³•æ­£ç¡®è¯†åˆ«è§„èŒƒçš„éµå®ˆæˆ–è¿åæƒ…å†µã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹é’ˆå¯¹æ–‡åŒ–æ„è¯†çš„ä¸“é—¨è¯„ä¼°åŸºå‡†ï¼Œéš¾ä»¥æœ‰æ•ˆè¡¡é‡å’Œæå‡æ¨¡å‹åœ¨è¿™æ–¹é¢çš„èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªåŒ…å«ä¸åŒæ–‡åŒ–ï¼ˆç¾å›½å’Œä¸­å›½ï¼‰çš„è§†é¢‘ç‰‡æ®µï¼Œå¹¶æ ‡æ³¨äº†ç¤¾ä¼šæ–‡åŒ–è§„èŒƒçš„åŸºå‡†æ•°æ®é›†VideoNormsã€‚é€šè¿‡è®©äººå·¥æ™ºèƒ½æ•™å¸ˆæ¨¡å‹ç”Ÿæˆå€™é€‰æ ‡æ³¨ï¼Œå†ç”±äººå·¥ä¸“å®¶è¿›è¡ŒéªŒè¯å’Œä¿®æ­£ï¼Œä»è€Œä¿è¯æ ‡æ³¨çš„è´¨é‡å’Œå‡†ç¡®æ€§ã€‚åˆ©ç”¨è¯¥åŸºå‡†ï¼Œå¯ä»¥ç³»ç»Ÿåœ°è¯„ä¼°ç°æœ‰VideoLLMåœ¨æ–‡åŒ–æ„è¯†æ–¹é¢çš„è¡¨ç°ï¼Œå¹¶ä¸ºæœªæ¥çš„æ¨¡å‹è®­ç»ƒæä¾›æŒ‡å¯¼ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVideoNormsçš„æ„å»ºæµç¨‹ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) æ•°æ®æ”¶é›†ï¼šæ”¶é›†æ¥è‡ªç¾å›½å’Œä¸­å›½æ–‡åŒ–çš„è§†é¢‘ç‰‡æ®µã€‚2) è§„èŒƒæ ‡æ³¨ï¼šä½¿ç”¨åŸºäºè¨€è¯­è¡Œä¸ºç†è®ºçš„æç¤ºï¼Œç”±æ•™å¸ˆæ¨¡å‹ç”Ÿæˆå€™é€‰çš„ç¤¾ä¼šæ–‡åŒ–è§„èŒƒæ ‡æ³¨ï¼ŒåŒ…æ‹¬è§„èŒƒéµå®ˆå’Œè¿åæ ‡ç­¾ï¼Œä»¥åŠå£å¤´å’Œéå£å¤´è¯æ®ã€‚3) äººå·¥éªŒè¯ï¼šç”±è®­ç»ƒæœ‰ç´ çš„äººå·¥ä¸“å®¶å¯¹æ•™å¸ˆæ¨¡å‹ç”Ÿæˆçš„æ ‡æ³¨è¿›è¡ŒéªŒè¯å’Œä¿®æ­£ï¼Œç¡®ä¿æ ‡æ³¨çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚4) æ¨¡å‹è¯„ä¼°ï¼šä½¿ç”¨VideoNormsåŸºå‡†è¯„ä¼°ç°æœ‰VideoLLMåœ¨æ–‡åŒ–æ„è¯†æ–¹é¢çš„è¡¨ç°ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†VideoNormsåŸºå‡†ï¼Œè¿™æ˜¯é¦–ä¸ªä¸“é—¨ç”¨äºè¯„ä¼°VideoLLMæ–‡åŒ–æ„è¯†çš„æ•°æ®é›†ã€‚2) é‡‡ç”¨äº†äººæœºåä½œçš„æ ‡æ³¨æ¡†æ¶ï¼Œç»“åˆäº†äººå·¥æ™ºèƒ½çš„æ•ˆç‡å’Œäººç±»ä¸“å®¶çš„å‡†ç¡®æ€§ï¼Œæé«˜äº†æ ‡æ³¨è´¨é‡ã€‚3) åŸºäºè¨€è¯­è¡Œä¸ºç†è®ºï¼Œå¯¹ç¤¾ä¼šæ–‡åŒ–è§„èŒƒè¿›è¡Œäº†ç³»ç»Ÿæ€§çš„æ ‡æ³¨ï¼Œä¸ºæ¨¡å‹æä¾›äº†æ›´ä¸°å¯Œçš„è¯­ä¹‰ä¿¡æ¯ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ ‡æ³¨è¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨äº†åŸºäºè¨€è¯­è¡Œä¸ºç†è®ºçš„æç¤ºï¼Œå¼•å¯¼æ•™å¸ˆæ¨¡å‹ç”Ÿæˆå€™é€‰æ ‡æ³¨ã€‚äººå·¥ä¸“å®¶åœ¨éªŒè¯å’Œä¿®æ­£æ ‡æ³¨æ—¶ï¼Œéœ€è¦æä¾›å£å¤´å’Œéå£å¤´è¯æ®ï¼Œä»¥æ”¯æŒå…¶åˆ¤æ–­ã€‚åœ¨æ¨¡å‹è¯„ä¼°æ–¹é¢ï¼Œè®ºæ–‡å…³æ³¨æ¨¡å‹åœ¨è§„èŒƒéµå®ˆå’Œè¿åã€ä¸åŒæ–‡åŒ–èƒŒæ™¯ã€å£å¤´å’Œéå£å¤´è¯æ®è¯†åˆ«ç­‰æ–¹é¢çš„è¡¨ç°å·®å¼‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œç°æœ‰VideoLLMåœ¨æ–‡åŒ–æ„è¯†æ–¹é¢å­˜åœ¨æ˜¾è‘—ä¸è¶³ã€‚æ¨¡å‹åœ¨è§„èŒƒè¿åæ–¹é¢çš„è¡¨ç°æ¯”éµå®ˆå·®ï¼Œå¯¹ä¸­å›½æ–‡åŒ–çš„ç†è§£ä¸å¦‚ç¾å›½æ–‡åŒ–ï¼Œä¸”éš¾ä»¥è¯†åˆ«éè¯­è¨€è¯æ®ã€‚æ­¤å¤–ï¼Œæ¨¡å‹åœ¨æ­£å¼ã€éå¹½é»˜çš„è¯­å¢ƒä¸­è¡¨ç°æ›´å·®ï¼Œè¿™ä¸äººç±»çš„è®¤çŸ¥æ¨¡å¼å­˜åœ¨å·®å¼‚ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†æ–‡åŒ–åŸºç¡€çš„è§†é¢‘è¯­è¨€æ¨¡å‹è®­ç»ƒçš„é‡è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæå‡è§†é¢‘è¯­è¨€æ¨¡å‹åœ¨å…¨çƒèŒƒå›´å†…çš„å¯ç”¨æ€§å’Œå¯é æ€§ã€‚é€šè¿‡ä½¿ç”¨VideoNormsåŸºå‡†è¿›è¡Œè¯„ä¼°å’Œè®­ç»ƒï¼Œå¯ä»¥æé«˜æ¨¡å‹å¯¹ä¸åŒæ–‡åŒ–çš„ç†è§£èƒ½åŠ›ï¼Œå‡å°‘å› æ–‡åŒ–å·®å¼‚å¯¼è‡´çš„è¯¯è§£æˆ–é”™è¯¯ã€‚è¿™å¯¹äºè·¨æ–‡åŒ–äº¤æµã€æ•™è‚²ã€å¨±ä¹ç­‰é¢†åŸŸå…·æœ‰é‡è¦æ„ä¹‰ï¼Œæœ‰åŠ©äºæ„å»ºæ›´åŠ æ™ºèƒ½å’Œäººæ€§åŒ–çš„è§†é¢‘ç†è§£ç³»ç»Ÿã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> As Video Large Language Models (VideoLLMs) are deployed globally, they require understanding of and grounding in the relevant cultural background. To properly assess these models' cultural awareness, adequate benchmarks are needed. We introduce VideoNorms, a benchmark of over 1000 (video clip, norm) pairs from US and Chinese cultures annotated with socio-cultural norms grounded in speech act theory, norm adherence and violations labels, and verbal and non-verbal evidence. To build VideoNorms, we use a human-AI collaboration framework, where a teacher model using theoretically-grounded prompting provides candidate annotations and a set of trained human experts validate and correct the annotations. We benchmark a variety of open-weight VideoLLMs on the new dataset which highlight several common trends: 1) models performs worse on norm violation than adherence; 2) models perform worse w.r.t Chinese culture compared to the US culture; 3) models have more difficulty in providing non-verbal evidence compared to verbal for the norm adhere/violation label and struggle to identify the exact norm corresponding to a speech-act; and 4) unlike humans, models perform worse in formal, non-humorous contexts. Our findings emphasize the need for culturally-grounded video language model training - a gap our benchmark and framework begin to address.

