---
layout: default
title: "M^3Detection: Multi-Frame Multi-Level Feature Fusion for Multi-Modal 3D Object Detection with Camera and 4D Imaging Radar"
---

# M^3Detection: Multi-Frame Multi-Level Feature Fusion for Multi-Modal 3D Object Detection with Camera and 4D Imaging Radar

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.27166" class="toolbar-btn" target="_blank">üìÑ arXiv: 2510.27166v1</a>
  <a href="https://arxiv.org/pdf/2510.27166.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.27166v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.27166v1', 'M^3Detection: Multi-Frame Multi-Level Feature Fusion for Multi-Modal 3D Object Detection with Camera and 4D Imaging Radar')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Xiaozhi Li, Huijun Di, Jian Li, Feng Liu, Wei Liang

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-31

**Â§áÊ≥®**: 16 pages, 9 figures

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**M^3DetectionÔºöÂ§öÂ∏ßÂ§öÂ±ÇÁâπÂæÅËûçÂêàÁöÑÁõ∏Êú∫-4DÈõ∑ËææÂ§öÊ®°ÊÄÅ3DÁõÆÊ†áÊ£ÄÊµã**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±ÂÖ´ÔºöÁâ©ÁêÜÂä®Áîª (Physics-based Animation)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅËûçÂêà` `3DÁõÆÊ†áÊ£ÄÊµã` `Áõ∏Êú∫-Èõ∑ËææËûçÂêà` `Â§öÂ∏ßËûçÂêà` `4DÊàêÂÉèÈõ∑Ëææ` `Êó∂Á©∫Êé®ÁêÜ` `Ëá™Âä®È©æÈ©∂`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁõ∏Êú∫-Èõ∑ËææËûçÂêàÊñπÊ≥ïÂ±ÄÈôê‰∫éÂçïÂ∏ßËæìÂÖ•ÔºåÂú∫ÊôØ‰ø°ÊÅØ‰∏çÂÆåÊï¥ÔºåÂõæÂÉèË¥®Èáè‰∏ãÈôçÂíå4DÈõ∑ËææÊï∞ÊçÆÁ®ÄÁñèÔºåÈôêÂà∂‰∫ÜÊ£ÄÊµãÊÄßËÉΩ„ÄÇ
2. M^3DetectionÈÄöËøáÂ§öÂ∏ßËûçÂêàÊèê‰æõÊõ¥‰∏∞ÂØåÁöÑÊó∂Á©∫‰ø°ÊÅØÔºåÂπ∂ËÆæËÆ°Â§öÂ±ÇÁâπÂæÅËûçÂêàÊ®°ÂùóÔºåÊúâÊïàËûçÂêàË∑®Â∏ßÂíåË∑®Ê®°ÊÄÅÁöÑÂØπË±°ÁâπÂæÅ„ÄÇ
3. Âú®VoDÂíåTJ4DRadSetÊï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåM^3DetectionËææÂà∞‰∫ÜÊúÄÂÖàËøõÁöÑ3DÊ£ÄÊµãÊÄßËÉΩÔºåÈ™åËØÅ‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫M^3DetectionÁöÑÁªü‰∏ÄÂ§öÂ∏ß3DÁõÆÊ†áÊ£ÄÊµãÊ°ÜÊû∂ÔºåËØ•Ê°ÜÊû∂ÂØπÊù•Ëá™Áõ∏Êú∫Âíå4DÊàêÂÉèÈõ∑ËææÁöÑÂ§öÊ®°ÊÄÅÊï∞ÊçÆÊâßË°åÂ§öÂ±ÇÁâπÂæÅËûçÂêà„ÄÇËØ•Ê°ÜÊû∂Âà©Áî®Âü∫Á∫øÊ£ÄÊµãÂô®ÁöÑ‰∏≠Èó¥ÁâπÂæÅÔºåÂπ∂‰ΩøÁî®Ë∑üË∏™Âô®ÁîüÊàêÂèÇËÄÉËΩ®ËøπÔºå‰ªéËÄåÊèêÈ´òËÆ°ÁÆóÊïàÁéáÂπ∂‰∏∫Á¨¨‰∫åÈò∂ÊÆµÊèê‰æõÊõ¥‰∏∞ÂØåÁöÑ‰ø°ÊÅØ„ÄÇÂú®Á¨¨‰∫åÈò∂ÊÆµÔºåËÆæËÆ°‰∫Ü‰∏Ä‰∏™Áî±Èõ∑Ëææ‰ø°ÊÅØÂºïÂØºÁöÑÂÖ®Â±ÄÁ∫ßÂØπË±°Èó¥ÁâπÂæÅËÅöÂêàÊ®°ÂùóÔºåÁî®‰∫éÂØπÈΩêÂÄôÈÄâÊèêËÆÆÁöÑÂÖ®Â±ÄÁâπÂæÅÔºõ‰ª•Âèä‰∏Ä‰∏™Â±ÄÈÉ®Á∫ßÁΩëÊ†ºÈó¥ÁâπÂæÅËÅöÂêàÊ®°ÂùóÔºåÁî®‰∫éÊ≤øÂèÇËÄÉËΩ®ËøπÊâ©Â±ïÂ±ÄÈÉ®ÁâπÂæÅÔºå‰ª•Â¢ûÂº∫ÁªÜÁ≤íÂ∫¶ÁöÑÂØπË±°Ë°®Á§∫„ÄÇÁÑ∂ÂêéÔºåËÅöÂêàÁöÑÁâπÂæÅÁî±ËΩ®ËøπÁ∫ßÂ§öÂ∏ßÊó∂Á©∫Êé®ÁêÜÊ®°ÂùóÂ§ÑÁêÜÔºå‰ª•ÁºñÁ†ÅË∑®Â∏ß‰∫§‰∫íÂπ∂Â¢ûÂº∫Êó∂Èó¥Ë°®Á§∫„ÄÇÂú®VoDÂíåTJ4DRadSetÊï∞ÊçÆÈõÜ‰∏äÁöÑÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåM^3DetectionÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑ3DÊ£ÄÊµãÊÄßËÉΩÔºåÈ™åËØÅ‰∫ÜÂÖ∂Âú®Áõ∏Êú∫-4DÊàêÂÉèÈõ∑ËææËûçÂêàÁöÑÂ§öÂ∏ßÊ£ÄÊµã‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÁöÑÁõ∏Êú∫-Èõ∑ËææËûçÂêà3DÁõÆÊ†áÊ£ÄÊµãÊñπÊ≥ïÈÄöÂ∏∏Âè™‰ΩøÁî®ÂçïÂ∏ßÊï∞ÊçÆÔºåÂØºËá¥Âú∫ÊôØ‰ø°ÊÅØ‰∏çÂÆåÊï¥ÔºåÈöæ‰ª•Â∫îÂØπÊÅ∂Âä£Â§©Ê∞îÂíåÈõ∑ËææÊï∞ÊçÆÁ®ÄÁñèÁ≠âÈóÆÈ¢ò„ÄÇÊ≠§Â§ñÔºåÂ§öÂ∏ßËûçÂêàÈù¢‰∏¥ÁùÄË∑®Â∏ßÂíåË∑®Ê®°ÊÄÅÁâπÂæÅËûçÂêàÁöÑÊåëÊàòÔºå‰ª•ÂèäÂÜó‰ΩôÁâπÂæÅÊèêÂèñÂ∏¶Êù•ÁöÑËÆ°ÁÆóÊàêÊú¨ÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöM^3DetectionÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Â§öÂ∏ß‰ø°ÊÅØÊù•Â¢ûÂº∫3DÁõÆÊ†áÊ£ÄÊµãÁöÑÈ≤ÅÊ£íÊÄßÂíåÂáÜÁ°ÆÊÄß„ÄÇÈÄöËøáËûçÂêàÊù•Ëá™Áõ∏Êú∫Âíå4DÈõ∑ËææÁöÑÂ§öÂ∏ßÊï∞ÊçÆÔºåÂèØ‰ª•Ëé∑ÂæóÊõ¥‰∏∞ÂØåÁöÑÊó∂Á©∫‰ø°ÊÅØÔºå‰ªéËÄåÂÖãÊúçÂçïÂ∏ßÊñπÊ≥ïÁöÑÂ±ÄÈôêÊÄß„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïËøòÈÄöËøáÂ§öÂ±ÇÁâπÂæÅËûçÂêàÂíåËΩ®ËøπË∑üË∏™Á≠âÊäÄÊúØÔºåÊúâÊïàÂú∞ËûçÂêàË∑®Â∏ßÂíåË∑®Ê®°ÊÄÅÁöÑÁâπÂæÅÔºåÂπ∂Èôç‰ΩéËÆ°ÁÆóÊàêÊú¨„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöM^3DetectionÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Ê®°ÂùóÔºö1) Âü∫‰∫éÂü∫Á∫øÊ£ÄÊµãÂô®ÁöÑÁâπÂæÅÊèêÂèñÊ®°ÂùóÔºåÁî®‰∫éÊèêÂèñÁõ∏Êú∫ÂíåÈõ∑ËææÁöÑ‰∏≠Èó¥ÁâπÂæÅÔºõ2) ËΩ®ËøπË∑üË∏™Ê®°ÂùóÔºåÁî®‰∫éÁîüÊàêÂèÇËÄÉËΩ®ËøπÔºåÊèêÈ´òËÆ°ÁÆóÊïàÁéáÂπ∂Êèê‰æõÊõ¥‰∏∞ÂØåÁöÑ‰ø°ÊÅØÔºõ3) ÂÖ®Â±ÄÁ∫ßÂØπË±°Èó¥ÁâπÂæÅËÅöÂêàÊ®°ÂùóÔºåÁî®‰∫éÂØπÈΩêÂÄôÈÄâÊèêËÆÆÁöÑÂÖ®Â±ÄÁâπÂæÅÔºõ4) Â±ÄÈÉ®Á∫ßÁΩëÊ†ºÈó¥ÁâπÂæÅËÅöÂêàÊ®°ÂùóÔºåÁî®‰∫éÊâ©Â±ïÂ±ÄÈÉ®ÁâπÂæÅÔºåÂ¢ûÂº∫ÁªÜÁ≤íÂ∫¶ÁöÑÂØπË±°Ë°®Á§∫Ôºõ5) ËΩ®ËøπÁ∫ßÂ§öÂ∏ßÊó∂Á©∫Êé®ÁêÜÊ®°ÂùóÔºåÁî®‰∫éÁºñÁ†ÅË∑®Â∏ß‰∫§‰∫íÔºåÂ¢ûÂº∫Êó∂Èó¥Ë°®Á§∫„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöM^3DetectionÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂Â§öÂ±ÇÁâπÂæÅËûçÂêàÁ≠ñÁï•ÂíåËΩ®ËøπÁ∫ßÊó∂Á©∫Êé®ÁêÜÊ®°Âùó„ÄÇÂ§öÂ±ÇÁâπÂæÅËûçÂêàËÉΩÂ§üÊúâÊïàÂú∞ËûçÂêàÊù•Ëá™‰∏çÂêåÊ®°ÊÄÅÂíå‰∏çÂêåÂ∏ßÁöÑÁâπÂæÅÔºå‰ªéËÄåÊèêÈ´òÊ£ÄÊµãÁöÑÂáÜÁ°ÆÊÄß„ÄÇËΩ®ËøπÁ∫ßÊó∂Á©∫Êé®ÁêÜÊ®°ÂùóËÉΩÂ§üÊçïÊçâÁõÆÊ†áÂú®Êó∂Èó¥‰∏äÁöÑËøêÂä®‰ø°ÊÅØÔºå‰ªéËÄåÊèêÈ´òÊ£ÄÊµãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåM^3DetectionËÉΩÂ§üÊõ¥Â•ΩÂú∞Âà©Áî®Â§öÂ∏ß‰ø°ÊÅØÔºå‰ªéËÄåÂú®ÊÅ∂Âä£Â§©Ê∞îÂíåÈõ∑ËææÊï∞ÊçÆÁ®ÄÁñèÁ≠âÊÉÖÂÜµ‰∏ãÂÆûÁé∞Êõ¥ÂáÜÁ°ÆÁöÑ3DÁõÆÊ†áÊ£ÄÊµã„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËØ•Ê°ÜÊû∂Âà©Áî®Ë∑üË∏™Âô®‰∫ßÁîüÂèÇËÄÉËΩ®ËøπÔºå‰ªéËÄåÊåáÂØºÁâπÂæÅËÅöÂêàËøáÁ®ãÔºåÊèêÈ´òËÆ°ÁÆóÊïàÁéá„ÄÇÂÖ®Â±ÄÁ∫ßÂØπË±°Èó¥ÁâπÂæÅËÅöÂêàÊ®°ÂùóÂíåÂ±ÄÈÉ®Á∫ßÁΩëÊ†ºÈó¥ÁâπÂæÅËÅöÂêàÊ®°ÂùóÁöÑËÆæËÆ°ÔºåÊó®Âú®ÂàÜÂà´‰ªéÂÖ®Â±ÄÂíåÂ±ÄÈÉ®Â±ÇÈù¢Â¢ûÂº∫ÁâπÂæÅË°®Á§∫„ÄÇËΩ®ËøπÁ∫ßÂ§öÂ∏ßÊó∂Á©∫Êé®ÁêÜÊ®°ÂùóÁöÑÂÖ∑‰ΩìÂÆûÁé∞ÁªÜËäÇÔºà‰æãÂ¶ÇÔºå‰ΩøÁî®ÁöÑÂæ™ÁéØÁ•ûÁªèÁΩëÁªúÁªìÊûÑ„ÄÅÊçüÂ§±ÂáΩÊï∞Á≠âÔºâÂú®ËÆ∫Êñá‰∏≠Êú™ËØ¶ÁªÜËØ¥ÊòéÔºåÂ±û‰∫éÊú™Áü•‰ø°ÊÅØ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

M^3DetectionÂú®VoDÂíåTJ4DRadSetÊï∞ÊçÆÈõÜ‰∏äËøõË°å‰∫ÜÂπøÊ≥õÁöÑÂÆûÈ™åÔºåÁªìÊûúË°®ÊòéËØ•ÊñπÊ≥ïËææÂà∞‰∫ÜÊúÄÂÖàËøõÁöÑ3DÊ£ÄÊµãÊÄßËÉΩ„ÄÇÂÖ∑‰ΩìÁöÑÊÄßËÉΩÊï∞ÊçÆÂíåÊèêÂçáÂπÖÂ∫¶Âú®ÊëòË¶Å‰∏≠Ê≤°ÊúâÊòéÁ°ÆÁªôÂá∫ÔºåÂ±û‰∫éÊú™Áü•‰ø°ÊÅØ„ÄÇ‰ΩÜÁªìËÆ∫Ë°®ÊòéÔºåM^3DetectionÂú®Â§öÂ∏ßÁõ∏Êú∫-4DÈõ∑ËææËûçÂêàÁöÑ3DÁõÆÊ†áÊ£ÄÊµãÊñπÈù¢ÂÖ∑ÊúâÊòæËëóÁöÑ‰ºòÂäø„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

M^3DetectionÂú®Ëá™Âä®È©æÈ©∂È¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇÂÆÉÂèØ‰ª•Áî®‰∫éÊèêÈ´òËΩ¶ËæÜÂú®ÂêÑÁßçÂ§©Ê∞îÊù°‰ª∂‰∏ãÁöÑÁéØÂ¢ÉÊÑüÁü•ËÉΩÂäõÔºå‰ªéËÄåÊèêÈ´òÈ©æÈ©∂ÂÆâÂÖ®ÊÄß„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïËøòÂèØ‰ª•Â∫îÁî®‰∫éÊô∫ËÉΩ‰∫§ÈÄöÁ≥ªÁªü„ÄÅÊú∫Âô®‰∫∫ÂØºËà™Á≠âÈ¢ÜÂüüÔºå‰∏∫Ëøô‰∫õÂ∫îÁî®Êèê‰æõÊõ¥ÂáÜÁ°Æ„ÄÅÊõ¥È≤ÅÊ£íÁöÑ3DÁõÆÊ†áÊ£ÄÊµãËÉΩÂäõ„ÄÇÊú™Êù•ÔºåËØ•Á†îÁ©∂ÂèØ‰ª•Ëøõ‰∏ÄÊ≠•Êâ©Â±ïÂà∞Êõ¥Â§öÊ®°ÊÄÅÁöÑ‰º†ÊÑüÂô®ËûçÂêàÔºå‰æãÂ¶ÇÊøÄÂÖâÈõ∑ËææÁ≠â„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Recent advances in 4D imaging radar have enabled robust perception in adverse weather, while camera sensors provide dense semantic information. Fusing the these complementary modalities has great potential for cost-effective 3D perception. However, most existing camera-radar fusion methods are limited to single-frame inputs, capturing only a partial view of the scene. The incomplete scene information, compounded by image degradation and 4D radar sparsity, hinders overall detection performance. In contrast, multi-frame fusion offers richer spatiotemporal information but faces two challenges: achieving robust and effective object feature fusion across frames and modalities, and mitigating the computational cost of redundant feature extraction. Consequently, we propose M^3Detection, a unified multi-frame 3D object detection framework that performs multi-level feature fusion on multi-modal data from camera and 4D imaging radar. Our framework leverages intermediate features from the baseline detector and employs the tracker to produce reference trajectories, improving computational efficiency and providing richer information for second-stage. In the second stage, we design a global-level inter-object feature aggregation module guided by radar information to align global features across candidate proposals and a local-level inter-grid feature aggregation module that expands local features along the reference trajectories to enhance fine-grained object representation. The aggregated features are then processed by a trajectory-level multi-frame spatiotemporal reasoning module to encode cross-frame interactions and enhance temporal representation. Extensive experiments on the VoD and TJ4DRadSet datasets demonstrate that M^3Detection achieves state-of-the-art 3D detection performance, validating its effectiveness in multi-frame detection with camera-4D imaging radar fusion.

