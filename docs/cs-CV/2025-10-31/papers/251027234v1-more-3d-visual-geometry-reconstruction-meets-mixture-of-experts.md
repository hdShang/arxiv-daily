---
layout: default
title: MoRE: 3D Visual Geometry Reconstruction Meets Mixture-of-Experts
---

# MoRE: 3D Visual Geometry Reconstruction Meets Mixture-of-Experts

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.27234" target="_blank" class="toolbar-btn">arXiv: 2510.27234v1</a>
    <a href="https://arxiv.org/pdf/2510.27234.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.27234v1" 
            onclick="toggleFavorite(this, '2510.27234v1', 'MoRE: 3D Visual Geometry Reconstruction Meets Mixture-of-Experts')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Jingnan Gao, Zhe Wang, Xianze Fang, Xingyu Ren, Zhuo Chen, Shengqi Liu, Yuhao Cheng, Jiangjing Lyu, Xiaokang Yang, Yichao Yan

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-31

**Â§áÊ≥®**: Project Page: https://g-1nonly.github.io/MoRE_Website/, Code: https://github.com/alibaba/Taobao3D

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫MoREÔºöÂü∫‰∫éÊ∑∑Âêà‰∏ìÂÆ∂Ê®°ÂûãÁöÑ3DËßÜËßâÂá†‰ΩïÈáçÂª∫Ê°ÜÊû∂ÔºåÊèêÂçáÂèØÊâ©Â±ïÊÄßÂíåÈÄÇÂ∫îÊÄß„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `3DËßÜËßâÂá†‰ΩïÈáçÂª∫` `Ê∑∑Âêà‰∏ìÂÆ∂Ê®°Âûã` `Ê∑±Â∫¶Â≠¶‰π†` `Ê®°ÂûãÊâ©Â±ï` `È≤ÅÊ£íÊÄß` `Ë°®Èù¢Ê≥ïÁ∫øÈ¢ÑÊµã` `ÁΩÆ‰ø°Â∫¶Ê∑±Â∫¶ÁªÜÂåñ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞Êúâ3DËßÜËßâÂá†‰ΩïÈáçÂª∫Ê®°ÂûãÈöæ‰ª•Ëøõ‰∏ÄÊ≠•Êâ©Â±ïÔºåÂèóÈôê‰∫éÂá†‰ΩïÁõëÁù£ÁöÑÂ§çÊùÇÊÄßÂíå3DÊï∞ÊçÆÁöÑÂ§öÊ†∑ÊÄß„ÄÇ
2. MoREÈááÁî®Ê∑∑Âêà‰∏ìÂÆ∂Ê®°ÂûãÔºåÂä®ÊÄÅË∑ØÁî±ÁâπÂæÅÂà∞ÁâπÂÆö‰ªªÂä°‰∏ìÂÆ∂ÔºåÊèêÂçáÊ®°ÂûãÂØπ‰∏çÂêåÊï∞ÊçÆÁâπÂæÅÁöÑÈÄÇÂ∫îÊÄßÂíåÂèØÊâ©Â±ïÊÄß„ÄÇ
3. MoREÈÄöËøáÁΩÆ‰ø°Â∫¶Ê∑±Â∫¶ÁªÜÂåñÊ®°ÂùóÂíåÂÆöÂà∂ÊçüÂ§±ÂáΩÊï∞ÔºåÂú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠ËææÂà∞SOTAÔºåÂπ∂ÊîØÊåÅ‰∏ãÊ∏∏Â∫îÁî®„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫MoREÁöÑÂØÜÈõÜ3DËßÜËßâÂü∫Á°ÄÊ®°ÂûãÔºåËØ•Ê®°ÂûãÂü∫‰∫éÊ∑∑Âêà‰∏ìÂÆ∂(MoE)Êû∂ÊûÑÔºåËÉΩÂ§üÂä®ÊÄÅÂú∞Â∞ÜÁâπÂæÅË∑ØÁî±Âà∞ÁâπÂÆö‰ªªÂä°ÁöÑ‰∏ìÂÆ∂Ôºå‰ªéËÄå‰Ωø‰∏ìÂÆ∂ËÉΩÂ§ü‰∏ìÊ≥®‰∫é‰∫íË°•ÁöÑÊï∞ÊçÆÊñπÈù¢ÔºåÂπ∂Â¢ûÂº∫Ê®°ÂûãÁöÑÂèØÊâ©Â±ïÊÄßÂíåÈÄÇÂ∫îÊÄß„ÄÇ‰∏∫‰∫ÜÊèêÈ´òÂú®ÁúüÂÆû‰∏ñÁïåÊù°‰ª∂‰∏ãÁöÑÈ≤ÅÊ£íÊÄßÔºåMoREÂåÖÂê´‰∏Ä‰∏™Âü∫‰∫éÁΩÆ‰ø°Â∫¶ÁöÑÊ∑±Â∫¶ÁªÜÂåñÊ®°ÂùóÔºåËØ•Ê®°ÂùóÂèØ‰ª•Á®≥ÂÆöÂíåÁªÜÂåñÂá†‰Ωï‰º∞ËÆ°„ÄÇÊ≠§Â§ñÔºåÂÆÉËøòÈõÜÊàê‰∫ÜÂØÜÈõÜËØ≠‰πâÁâπÂæÅ‰∏éÂÖ®Â±ÄÂØπÈΩêÁöÑ3DÈ™®Âπ≤Ë°®Á§∫Ôºå‰ª•ÂÆûÁé∞È´ò‰øùÁúüÂ∫¶ÁöÑË°®Èù¢Ê≥ïÁ∫øÈ¢ÑÊµã„ÄÇMoREÈÄöËøáÂÆöÂà∂ÁöÑÊçüÂ§±ÂáΩÊï∞ËøõË°åËøõ‰∏ÄÊ≠•‰ºòÂåñÔºå‰ª•Á°Æ‰øùË∑®‰∏çÂêåËæìÂÖ•ÂíåÂ§ö‰∏™Âá†‰Ωï‰ªªÂä°ÁöÑÈ≤ÅÊ£íÂ≠¶‰π†„ÄÇÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåMoREÂú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠ÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÂπ∂ÊîØÊåÅÊúâÊïàÁöÑ‰∏ãÊ∏∏Â∫îÁî®ÔºåËÄåÊó†ÈúÄÈ¢ùÂ§ñÁöÑËÆ°ÁÆó„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥3DËßÜËßâÂá†‰ΩïÈáçÂª∫‰∏≠Ê®°ÂûãÊâ©Â±ïÁöÑÈöæÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®Â§ÑÁêÜÂ§çÊùÇÂá†‰ΩïÁõëÁù£ÂíåÂ§öÊ†∑Âåñ3DÊï∞ÊçÆÊó∂Èù¢‰∏¥ÊåëÊàòÔºåÈöæ‰ª•Ëøõ‰∏ÄÊ≠•ÊèêÂçáÊÄßËÉΩ„ÄÇÊ®°ÂûãËßÑÊ®°ÁöÑÊâ©Â§ßÂèóÂà∞ÈôêÂà∂ÔºåÈòªÁ¢ç‰∫Ü3DËßÜËßâÈ¢ÜÂüüÁöÑÂèëÂ±ï„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Ê∑∑Âêà‰∏ìÂÆ∂Ê®°ÂûãÔºàMoEÔºâÔºåÂ∞ÜÊ®°ÂûãÁöÑËÉΩÂäõÂàÜÊï£Âà∞Â§ö‰∏™‰∏ìÂÆ∂ÁΩëÁªú‰∏≠ÔºåÊØè‰∏™‰∏ìÂÆ∂Ë¥üË¥£Â§ÑÁêÜÁâπÂÆöÁöÑÊï∞ÊçÆÁâπÂæÅÊàñ‰ªªÂä°„ÄÇÈÄöËøáÂä®ÊÄÅË∑ØÁî±Êú∫Âà∂ÔºåÂ∞ÜËæìÂÖ•ÁâπÂæÅÂàÜÈÖçÁªôÊúÄÂêàÈÄÇÁöÑ‰∏ìÂÆ∂Ôºå‰ªéËÄåÊèêÈ´òÊ®°ÂûãÁöÑÈÄÇÂ∫îÊÄßÂíåÂèØÊâ©Â±ïÊÄß„ÄÇËøôÁßçÊñπÊ≥ïÂÖÅËÆ∏Ê®°ÂûãÂú®‰∏çÊòæËëóÂ¢ûÂä†ËÆ°ÁÆóÊàêÊú¨ÁöÑÊÉÖÂÜµ‰∏ãÔºåÂ≠¶‰π†Êõ¥‰∏∞ÂØåÁöÑË°®Á§∫„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöMoREÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) 3DÈ™®Âπ≤ÁΩëÁªúÔºöÁî®‰∫éÊèêÂèñÂÖ®Â±ÄÂØπÈΩêÁöÑ3DÁâπÂæÅË°®Á§∫„ÄÇ2) Ê∑∑Âêà‰∏ìÂÆ∂Â±ÇÔºöÂåÖÂê´Â§ö‰∏™‰∏ìÂÆ∂ÁΩëÁªúÔºåÊØè‰∏™‰∏ìÂÆ∂‰∏ìÈó®Â§ÑÁêÜÁâπÂÆöÁöÑÊï∞ÊçÆÊñπÈù¢„ÄÇ3) Âä®ÊÄÅË∑ØÁî±Êú∫Âà∂ÔºöÊ†πÊçÆËæìÂÖ•ÁâπÂæÅÁöÑÁâπÊÄßÔºåÂ∞ÜÁâπÂæÅË∑ØÁî±Âà∞ÊúÄÂêàÈÄÇÁöÑ‰∏ìÂÆ∂„ÄÇ4) ÁΩÆ‰ø°Â∫¶Ê∑±Â∫¶ÁªÜÂåñÊ®°ÂùóÔºöÁî®‰∫éÁ®≥ÂÆöÂíåÁªÜÂåñÂá†‰Ωï‰º∞ËÆ°ÔºåÊèêÈ´òÈ≤ÅÊ£íÊÄß„ÄÇ5) Ë°®Èù¢Ê≥ïÁ∫øÈ¢ÑÊµãÊ®°ÂùóÔºöÈõÜÊàê‰∫ÜÂØÜÈõÜËØ≠‰πâÁâπÂæÅÔºåÁî®‰∫éÈ´ò‰øùÁúüÂ∫¶ÁöÑË°®Èù¢Ê≥ïÁ∫øÈ¢ÑÊµã„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöMoREÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜÊ∑∑Âêà‰∏ìÂÆ∂Ê®°ÂûãÂºïÂÖ•Âà∞3DËßÜËßâÂá†‰ΩïÈáçÂª∫È¢ÜÂüü„ÄÇ‰∏é‰º†ÁªüÁöÑÂçï‰∏ÄÊ®°ÂûãÁõ∏ÊØîÔºåMoREËÉΩÂ§üÂä®ÊÄÅÂú∞Ë∞ÉÊï¥Ê®°ÂûãÁöÑÁªìÊûÑÔºå‰ª•ÈÄÇÂ∫î‰∏çÂêåÁöÑËæìÂÖ•Êï∞ÊçÆÂíå‰ªªÂä°„ÄÇÊ≠§Â§ñÔºåÁΩÆ‰ø°Â∫¶Ê∑±Â∫¶ÁªÜÂåñÊ®°ÂùóÂíåË°®Èù¢Ê≥ïÁ∫øÈ¢ÑÊµãÊ®°Âùó‰πüËøõ‰∏ÄÊ≠•ÊèêÈ´ò‰∫ÜÊ®°ÂûãÁöÑÊÄßËÉΩÂíåÈ≤ÅÊ£íÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöMoREÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ‰∏ìÂÆ∂ÁΩëÁªúÁöÑÊï∞ÈáèÂíåÁªìÊûÑÔºöÊ†πÊçÆ‰ªªÂä°ÁöÑÂ§çÊùÇÂ∫¶ÂíåÊï∞ÊçÆÁöÑÂ§öÊ†∑ÊÄßËøõË°åË∞ÉÊï¥„ÄÇ2) Âä®ÊÄÅË∑ØÁî±Êú∫Âà∂ÁöÑËÆæËÆ°ÔºöÈááÁî®ÂèØÂ≠¶‰π†ÁöÑË∑ØÁî±ÂáΩÊï∞ÔºåÊ†πÊçÆËæìÂÖ•ÁâπÂæÅÁöÑÁâπÊÄßËøõË°åË∑ØÁî±„ÄÇ3) ÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°ÔºöÈááÁî®ÂÆöÂà∂ÁöÑÊçüÂ§±ÂáΩÊï∞Ôºå‰ª•Á°Æ‰øùË∑®‰∏çÂêåËæìÂÖ•ÂíåÂ§ö‰∏™Âá†‰Ωï‰ªªÂä°ÁöÑÈ≤ÅÊ£íÂ≠¶‰π†„ÄÇ‰æãÂ¶ÇÔºåÂèØËÉΩÂåÖÊã¨Ê∑±Â∫¶È¢ÑÊµãÊçüÂ§±„ÄÅË°®Èù¢Ê≥ïÁ∫øÈ¢ÑÊµãÊçüÂ§±ÂíåËØ≠‰πâÂàÜÂâ≤ÊçüÂ§±Á≠â„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

MoREÂú®Â§ö‰∏™3DËßÜËßâÂá†‰ΩïÈáçÂª∫Âü∫ÂáÜÊµãËØï‰∏≠ÂèñÂæó‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩ„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåMoREÂú®Ê∑±Â∫¶È¢ÑÊµã„ÄÅË°®Èù¢Ê≥ïÁ∫øÈ¢ÑÊµãÁ≠â‰ªªÂä°‰∏äÊòæËëó‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåMoREËÉΩÂ§üÊúâÊïàÂú∞Âà©Áî®Ê∑∑Âêà‰∏ìÂÆ∂Ê®°ÂûãÔºåÊèêÈ´òÊ®°ÂûãÁöÑÈÄÇÂ∫îÊÄßÂíåÂèØÊâ©Â±ïÊÄßÔºå‰ªéËÄåÂÆûÁé∞Êõ¥È´òÁöÑÁ≤æÂ∫¶ÂíåÈ≤ÅÊ£íÊÄß„ÄÇÊ≠§Â§ñÔºåMoREËøòÊîØÊåÅÊúâÊïàÁöÑ‰∏ãÊ∏∏Â∫îÁî®ÔºåËÄåÊó†ÈúÄÈ¢ùÂ§ñÁöÑËÆ°ÁÆó„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

MoREÂú®Êú∫Âô®‰∫∫ÂØºËà™„ÄÅËá™Âä®È©æÈ©∂„ÄÅËôöÊãüÁé∞ÂÆû„ÄÅÂ¢ûÂº∫Áé∞ÂÆû„ÄÅ3DÂª∫Ê®°Á≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇÂÆÉÂèØ‰ª•Áî®‰∫éÊûÑÂª∫Êõ¥Á≤æÁ°Æ„ÄÅÊõ¥È≤ÅÊ£íÁöÑ3DÁéØÂ¢ÉÊ®°ÂûãÔºå‰ªéËÄåÊèêÈ´òÊú∫Âô®‰∫∫ÁöÑËá™‰∏ªÂØºËà™ËÉΩÂäõÔºåÊîπÂñÑËá™Âä®È©æÈ©∂Á≥ªÁªüÁöÑÂÆâÂÖ®ÊÄßÔºåÂπ∂‰∏∫Áî®Êà∑Êèê‰æõÊõ¥Ê≤âÊµ∏ÂºèÁöÑËôöÊãüÁé∞ÂÆûÂíåÂ¢ûÂº∫Áé∞ÂÆû‰ΩìÈ™å„ÄÇÊ≠§Â§ñÔºåMoREËøòÂèØ‰ª•Áî®‰∫éÁîüÊàêÈ´òË¥®ÈáèÁöÑ3DÊ®°ÂûãÔºåÂ∫îÁî®‰∫éÊ∏∏ÊàèÂºÄÂèë„ÄÅÁîµÂΩ±Âà∂‰ΩúÁ≠âÈ¢ÜÂüü„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Recent advances in language and vision have demonstrated that scaling up model capacity consistently improves performance across diverse tasks. In 3D visual geometry reconstruction, large-scale training has likewise proven effective for learning versatile representations. However, further scaling of 3D models is challenging due to the complexity of geometric supervision and the diversity of 3D data. To overcome these limitations, we propose MoRE, a dense 3D visual foundation model based on a Mixture-of-Experts (MoE) architecture that dynamically routes features to task-specific experts, allowing them to specialize in complementary data aspects and enhance both scalability and adaptability. Aiming to improve robustness under real-world conditions, MoRE incorporates a confidence-based depth refinement module that stabilizes and refines geometric estimation. In addition, it integrates dense semantic features with globally aligned 3D backbone representations for high-fidelity surface normal prediction. MoRE is further optimized with tailored loss functions to ensure robust learning across diverse inputs and multiple geometric tasks. Extensive experiments demonstrate that MoRE achieves state-of-the-art performance across multiple benchmarks and supports effective downstream applications without extra computation.

