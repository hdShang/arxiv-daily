---
layout: default
title: MoRE: 3D Visual Geometry Reconstruction Meets Mixture-of-Experts
---

# MoRE: 3D Visual Geometry Reconstruction Meets Mixture-of-Experts

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.27234" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.27234v1</a>
  <a href="https://arxiv.org/pdf/2510.27234.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.27234v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.27234v1', 'MoRE: 3D Visual Geometry Reconstruction Meets Mixture-of-Experts')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jingnan Gao, Zhe Wang, Xianze Fang, Xingyu Ren, Zhuo Chen, Shengqi Liu, Yuhao Cheng, Jiangjing Lyu, Xiaokang Yang, Yichao Yan

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-31

**å¤‡æ³¨**: Project Page: https://g-1nonly.github.io/MoRE_Website/, Code: https://github.com/alibaba/Taobao3D

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMoREï¼šåŸºäºæ··åˆä¸“å®¶æ¨¡å‹çš„3Dè§†è§‰å‡ ä½•é‡å»ºæ¡†æ¶ï¼Œæå‡å¯æ‰©å±•æ€§å’Œé€‚åº”æ€§ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `3Dè§†è§‰å‡ ä½•é‡å»º` `æ··åˆä¸“å®¶æ¨¡å‹` `æ·±åº¦å­¦ä¹ ` `æ¨¡å‹æ‰©å±•` `é²æ£’æ€§` `è¡¨é¢æ³•çº¿é¢„æµ‹` `ç½®ä¿¡åº¦æ·±åº¦ç»†åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰3Dè§†è§‰å‡ ä½•é‡å»ºæ¨¡å‹éš¾ä»¥è¿›ä¸€æ­¥æ‰©å±•ï¼Œå—é™äºå‡ ä½•ç›‘ç£çš„å¤æ‚æ€§å’Œ3Dæ•°æ®çš„å¤šæ ·æ€§ã€‚
2. MoREé‡‡ç”¨æ··åˆä¸“å®¶æ¨¡å‹ï¼ŒåŠ¨æ€è·¯ç”±ç‰¹å¾åˆ°ç‰¹å®šä»»åŠ¡ä¸“å®¶ï¼Œæå‡æ¨¡å‹å¯¹ä¸åŒæ•°æ®ç‰¹å¾çš„é€‚åº”æ€§å’Œå¯æ‰©å±•æ€§ã€‚
3. MoREé€šè¿‡ç½®ä¿¡åº¦æ·±åº¦ç»†åŒ–æ¨¡å—å’Œå®šåˆ¶æŸå¤±å‡½æ•°ï¼Œåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°SOTAï¼Œå¹¶æ”¯æŒä¸‹æ¸¸åº”ç”¨ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºMoREçš„å¯†é›†3Dè§†è§‰åŸºç¡€æ¨¡å‹ï¼Œè¯¥æ¨¡å‹åŸºäºæ··åˆä¸“å®¶(MoE)æ¶æ„ï¼Œèƒ½å¤ŸåŠ¨æ€åœ°å°†ç‰¹å¾è·¯ç”±åˆ°ç‰¹å®šä»»åŠ¡çš„ä¸“å®¶ï¼Œä»è€Œä½¿ä¸“å®¶èƒ½å¤Ÿä¸“æ³¨äºäº’è¡¥çš„æ•°æ®æ–¹é¢ï¼Œå¹¶å¢å¼ºæ¨¡å‹çš„å¯æ‰©å±•æ€§å’Œé€‚åº”æ€§ã€‚ä¸ºäº†æé«˜åœ¨çœŸå®ä¸–ç•Œæ¡ä»¶ä¸‹çš„é²æ£’æ€§ï¼ŒMoREåŒ…å«ä¸€ä¸ªåŸºäºç½®ä¿¡åº¦çš„æ·±åº¦ç»†åŒ–æ¨¡å—ï¼Œè¯¥æ¨¡å—å¯ä»¥ç¨³å®šå’Œç»†åŒ–å‡ ä½•ä¼°è®¡ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜é›†æˆäº†å¯†é›†è¯­ä¹‰ç‰¹å¾ä¸å…¨å±€å¯¹é½çš„3Déª¨å¹²è¡¨ç¤ºï¼Œä»¥å®ç°é«˜ä¿çœŸåº¦çš„è¡¨é¢æ³•çº¿é¢„æµ‹ã€‚MoREé€šè¿‡å®šåˆ¶çš„æŸå¤±å‡½æ•°è¿›è¡Œè¿›ä¸€æ­¥ä¼˜åŒ–ï¼Œä»¥ç¡®ä¿è·¨ä¸åŒè¾“å…¥å’Œå¤šä¸ªå‡ ä½•ä»»åŠ¡çš„é²æ£’å­¦ä¹ ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒMoREåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶æ”¯æŒæœ‰æ•ˆçš„ä¸‹æ¸¸åº”ç”¨ï¼Œè€Œæ— éœ€é¢å¤–çš„è®¡ç®—ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³3Dè§†è§‰å‡ ä½•é‡å»ºä¸­æ¨¡å‹æ‰©å±•çš„éš¾é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚å‡ ä½•ç›‘ç£å’Œå¤šæ ·åŒ–3Dæ•°æ®æ—¶é¢ä¸´æŒ‘æˆ˜ï¼Œéš¾ä»¥è¿›ä¸€æ­¥æå‡æ€§èƒ½ã€‚æ¨¡å‹è§„æ¨¡çš„æ‰©å¤§å—åˆ°é™åˆ¶ï¼Œé˜»ç¢äº†3Dè§†è§‰é¢†åŸŸçš„å‘å±•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMoEï¼‰ï¼Œå°†æ¨¡å‹çš„èƒ½åŠ›åˆ†æ•£åˆ°å¤šä¸ªä¸“å®¶ç½‘ç»œä¸­ï¼Œæ¯ä¸ªä¸“å®¶è´Ÿè´£å¤„ç†ç‰¹å®šçš„æ•°æ®ç‰¹å¾æˆ–ä»»åŠ¡ã€‚é€šè¿‡åŠ¨æ€è·¯ç”±æœºåˆ¶ï¼Œå°†è¾“å…¥ç‰¹å¾åˆ†é…ç»™æœ€åˆé€‚çš„ä¸“å®¶ï¼Œä»è€Œæé«˜æ¨¡å‹çš„é€‚åº”æ€§å’Œå¯æ‰©å±•æ€§ã€‚è¿™ç§æ–¹æ³•å…è®¸æ¨¡å‹åœ¨ä¸æ˜¾è‘—å¢åŠ è®¡ç®—æˆæœ¬çš„æƒ…å†µä¸‹ï¼Œå­¦ä¹ æ›´ä¸°å¯Œçš„è¡¨ç¤ºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMoREçš„æ•´ä½“æ¶æ„åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) 3Déª¨å¹²ç½‘ç»œï¼šç”¨äºæå–å…¨å±€å¯¹é½çš„3Dç‰¹å¾è¡¨ç¤ºã€‚2) æ··åˆä¸“å®¶å±‚ï¼šåŒ…å«å¤šä¸ªä¸“å®¶ç½‘ç»œï¼Œæ¯ä¸ªä¸“å®¶ä¸“é—¨å¤„ç†ç‰¹å®šçš„æ•°æ®æ–¹é¢ã€‚3) åŠ¨æ€è·¯ç”±æœºåˆ¶ï¼šæ ¹æ®è¾“å…¥ç‰¹å¾çš„ç‰¹æ€§ï¼Œå°†ç‰¹å¾è·¯ç”±åˆ°æœ€åˆé€‚çš„ä¸“å®¶ã€‚4) ç½®ä¿¡åº¦æ·±åº¦ç»†åŒ–æ¨¡å—ï¼šç”¨äºç¨³å®šå’Œç»†åŒ–å‡ ä½•ä¼°è®¡ï¼Œæé«˜é²æ£’æ€§ã€‚5) è¡¨é¢æ³•çº¿é¢„æµ‹æ¨¡å—ï¼šé›†æˆäº†å¯†é›†è¯­ä¹‰ç‰¹å¾ï¼Œç”¨äºé«˜ä¿çœŸåº¦çš„è¡¨é¢æ³•çº¿é¢„æµ‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šMoREçš„å…³é”®åˆ›æ–°åœ¨äºå°†æ··åˆä¸“å®¶æ¨¡å‹å¼•å…¥åˆ°3Dè§†è§‰å‡ ä½•é‡å»ºé¢†åŸŸã€‚ä¸ä¼ ç»Ÿçš„å•ä¸€æ¨¡å‹ç›¸æ¯”ï¼ŒMoREèƒ½å¤ŸåŠ¨æ€åœ°è°ƒæ•´æ¨¡å‹çš„ç»“æ„ï¼Œä»¥é€‚åº”ä¸åŒçš„è¾“å…¥æ•°æ®å’Œä»»åŠ¡ã€‚æ­¤å¤–ï¼Œç½®ä¿¡åº¦æ·±åº¦ç»†åŒ–æ¨¡å—å’Œè¡¨é¢æ³•çº¿é¢„æµ‹æ¨¡å—ä¹Ÿè¿›ä¸€æ­¥æé«˜äº†æ¨¡å‹çš„æ€§èƒ½å’Œé²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šMoREçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä¸“å®¶ç½‘ç»œçš„æ•°é‡å’Œç»“æ„ï¼šæ ¹æ®ä»»åŠ¡çš„å¤æ‚åº¦å’Œæ•°æ®çš„å¤šæ ·æ€§è¿›è¡Œè°ƒæ•´ã€‚2) åŠ¨æ€è·¯ç”±æœºåˆ¶çš„è®¾è®¡ï¼šé‡‡ç”¨å¯å­¦ä¹ çš„è·¯ç”±å‡½æ•°ï¼Œæ ¹æ®è¾“å…¥ç‰¹å¾çš„ç‰¹æ€§è¿›è¡Œè·¯ç”±ã€‚3) æŸå¤±å‡½æ•°çš„è®¾è®¡ï¼šé‡‡ç”¨å®šåˆ¶çš„æŸå¤±å‡½æ•°ï¼Œä»¥ç¡®ä¿è·¨ä¸åŒè¾“å…¥å’Œå¤šä¸ªå‡ ä½•ä»»åŠ¡çš„é²æ£’å­¦ä¹ ã€‚ä¾‹å¦‚ï¼Œå¯èƒ½åŒ…æ‹¬æ·±åº¦é¢„æµ‹æŸå¤±ã€è¡¨é¢æ³•çº¿é¢„æµ‹æŸå¤±å’Œè¯­ä¹‰åˆ†å‰²æŸå¤±ç­‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

MoREåœ¨å¤šä¸ª3Dè§†è§‰å‡ ä½•é‡å»ºåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚å…·ä½“è€Œè¨€ï¼ŒMoREåœ¨æ·±åº¦é¢„æµ‹ã€è¡¨é¢æ³•çº¿é¢„æµ‹ç­‰ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMoREèƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨æ··åˆä¸“å®¶æ¨¡å‹ï¼Œæé«˜æ¨¡å‹çš„é€‚åº”æ€§å’Œå¯æ‰©å±•æ€§ï¼Œä»è€Œå®ç°æ›´é«˜çš„ç²¾åº¦å’Œé²æ£’æ€§ã€‚æ­¤å¤–ï¼ŒMoREè¿˜æ”¯æŒæœ‰æ•ˆçš„ä¸‹æ¸¸åº”ç”¨ï¼Œè€Œæ— éœ€é¢å¤–çš„è®¡ç®—ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MoREåœ¨æœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ã€è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ã€3Då»ºæ¨¡ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥ç”¨äºæ„å»ºæ›´ç²¾ç¡®ã€æ›´é²æ£’çš„3Dç¯å¢ƒæ¨¡å‹ï¼Œä»è€Œæé«˜æœºå™¨äººçš„è‡ªä¸»å¯¼èˆªèƒ½åŠ›ï¼Œæ”¹å–„è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„å®‰å…¨æ€§ï¼Œå¹¶ä¸ºç”¨æˆ·æä¾›æ›´æ²‰æµ¸å¼çš„è™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®ä½“éªŒã€‚æ­¤å¤–ï¼ŒMoREè¿˜å¯ä»¥ç”¨äºç”Ÿæˆé«˜è´¨é‡çš„3Dæ¨¡å‹ï¼Œåº”ç”¨äºæ¸¸æˆå¼€å‘ã€ç”µå½±åˆ¶ä½œç­‰é¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in language and vision have demonstrated that scaling up model capacity consistently improves performance across diverse tasks. In 3D visual geometry reconstruction, large-scale training has likewise proven effective for learning versatile representations. However, further scaling of 3D models is challenging due to the complexity of geometric supervision and the diversity of 3D data. To overcome these limitations, we propose MoRE, a dense 3D visual foundation model based on a Mixture-of-Experts (MoE) architecture that dynamically routes features to task-specific experts, allowing them to specialize in complementary data aspects and enhance both scalability and adaptability. Aiming to improve robustness under real-world conditions, MoRE incorporates a confidence-based depth refinement module that stabilizes and refines geometric estimation. In addition, it integrates dense semantic features with globally aligned 3D backbone representations for high-fidelity surface normal prediction. MoRE is further optimized with tailored loss functions to ensure robust learning across diverse inputs and multiple geometric tasks. Extensive experiments demonstrate that MoRE achieves state-of-the-art performance across multiple benchmarks and supports effective downstream applications without extra computation.

