---
layout: default
title: "E-MMDiT: Revisiting Multimodal Diffusion Transformer Design for Fast Image Synthesis under Limited Resources"
---

# E-MMDiT: Revisiting Multimodal Diffusion Transformer Design for Fast Image Synthesis under Limited Resources

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.27135" class="toolbar-btn" target="_blank">üìÑ arXiv: 2510.27135v1</a>
  <a href="https://arxiv.org/pdf/2510.27135.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.27135v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.27135v1', 'E-MMDiT: Revisiting Multimodal Diffusion Transformer Design for Fast Image Synthesis under Limited Resources')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Tong Shen, Jingai Yu, Dong Zhou, Dong Li, Emad Barsoum

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-31

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/AMD-AGI/Nitro-E)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫E-MMDiTÔºå‰∏ÄÁßçËΩªÈáèÁ∫ßÂ§öÊ®°ÊÄÅÊâ©Êï£TransformerÔºåÁî®‰∫éËµÑÊ∫êÂèóÈôê‰∏ãÁöÑÂø´ÈÄüÂõæÂÉèÂêàÊàê„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Êâ©Êï£Ê®°Âûã` `Transformer` `ÂõæÂÉèÁîüÊàê` `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `ËΩªÈáèÂåñÊ®°Âûã` `tokenÁº©Âáè` `ËµÑÊ∫êÂèóÈôê`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊâ©Êï£Ê®°ÂûãËÆ≠ÁªÉÊàêÊú¨È´òÊòÇÔºåÈúÄË¶ÅÂ§ßÈáèÊï∞ÊçÆÂíåÁÆóÂäõÔºåÊàñÊ®°ÂûãÁªìÊûÑÂ§çÊùÇÂØºËá¥Êé®ÁêÜÂª∂ËøüÈ´ò„ÄÇ
2. E-MMDiTÈÄöËøátokenÁº©ÂáèÁ≠ñÁï•ÔºåÁªìÂêàÈ´òÂéãÁº©ËßÜËßâtokenizerÂíåÂ§öË∑ØÂæÑÂéãÁº©Ê®°ÂùóÔºåÂÆûÁé∞ËΩªÈáèÂåñËÆæËÆ°„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåE-MMDiT‰ªÖÁî®Â∞ëÈáèÊï∞ÊçÆÂíåËµÑÊ∫êÂç≥ÂèØËÆ≠ÁªÉÔºåÂπ∂Âú®ÂõæÂÉèÁîüÊàêË¥®Èáè‰∏äËææÂà∞ÂÖ∑ÊúâÁ´û‰∫âÂäõÁöÑÊ∞¥Âπ≥„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êâ©Êï£Ê®°ÂûãÂú®‰ªéÊñáÊú¨ÊèêÁ§∫ÁîüÊàêÈ´òË¥®ÈáèÂõæÂÉèÊñπÈù¢Ë°®Áé∞Âá∫Âº∫Â§ßÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåËøô‰∫õÊ®°ÂûãÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßËßÑÊ®°ÁöÑËÆ≠ÁªÉÊï∞ÊçÆÂíåÂ§ßÈáèÁöÑËÆ°ÁÆóËµÑÊ∫êËøõË°åËÆ≠ÁªÉÔºåÊàñËÄÖÂ≠òÂú®ÁªìÊûÑÂ§çÊùÇ„ÄÅÂª∂ËøüÈ´òÁ≠âÈóÆÈ¢ò„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜÈ´òÊïàÂ§öÊ®°ÊÄÅÊâ©Êï£TransformerÔºàE-MMDiTÔºâÔºåËøôÊòØ‰∏Ä‰∏™È´òÊïà‰∏îËΩªÈáèÁ∫ßÁöÑÂ§öÊ®°ÊÄÅÊâ©Êï£Ê®°ÂûãÔºå‰ªÖÊúâ304MÂèÇÊï∞ÔºåÁî®‰∫éÂú®‰ΩéËÆ≠ÁªÉËµÑÊ∫ê‰∏ãËøõË°åÂø´ÈÄüÂõæÂÉèÂêàÊàê„ÄÇÊàë‰ª¨Êèê‰æõ‰∫Ü‰∏Ä‰∏™Êòì‰∫éÂ§çÁé∞ÁöÑÂü∫Á∫øÔºåÂπ∂ÂèñÂæó‰∫ÜÂÖ∑ÊúâÁ´û‰∫âÂäõÁöÑÁªìÊûú„ÄÇÊàë‰ª¨ÁöÑ512pxÁîüÊàêÊ®°ÂûãÔºå‰ªÖ‰ΩøÁî®25MÂÖ¨ÂÖ±Êï∞ÊçÆÂú®Âçï‰∏™ÂåÖÂê´8‰∏™AMD MI300X GPUÁöÑËäÇÁÇπ‰∏äËÆ≠ÁªÉ1.5Â§©ÔºåÂú®GenEval‰∏äËææÂà∞‰∫Ü0.66ÔºåÂπ∂‰∏îÈÄöËøá‰∏Ä‰∫õËÆ≠ÁªÉÂêéÊäÄÊúØÔºàÂ¶ÇGRPOÔºâÂèØ‰ª•ËΩªÊùæËææÂà∞0.72„ÄÇÊàë‰ª¨ÁöÑËÆæËÆ°ÁêÜÂøµ‰ª•tokenÁº©Âáè‰∏∫‰∏≠ÂøÉÔºåÂõ†‰∏∫ËÆ°ÁÆóÊàêÊú¨ÈöètokenÊï∞ÈáèÊòæËëóÂ¢ûÂä†„ÄÇÊàë‰ª¨ÈááÁî®‰∫Ü‰∏ÄÁßçÈ´òÂ∫¶ÂéãÁº©ÁöÑËßÜËßâtokenizerÊù•‰∫ßÁîüÊõ¥Á¥ßÂáëÁöÑË°®Á§∫ÔºåÂπ∂ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÂ§öË∑ØÂæÑÂéãÁº©Ê®°ÂùóÊù•Ëøõ‰∏ÄÊ≠•ÂéãÁº©token„ÄÇ‰∏∫‰∫ÜÂ¢ûÂº∫Êàë‰ª¨ÁöÑËÆæËÆ°ÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰ΩçÁΩÆÂº∫ÂåñÔºàPosition ReinforcementÔºâÔºåÂÆÉÂä†Âº∫‰∫Ü‰ΩçÁΩÆ‰ø°ÊÅØ‰ª•‰øùÊåÅÁ©∫Èó¥ËøûË¥ØÊÄßÔºå‰ª•Âèä‰∫§ÊõøÂ≠êÂå∫ÂüüÊ≥®ÊÑèÂäõÔºàASAÔºâÔºåÂÆÉÂú®Â≠êÂå∫ÂüüÂÜÖÊâßË°åÊ≥®ÊÑèÂäõ‰ª•Ëøõ‰∏ÄÊ≠•Èôç‰ΩéËÆ°ÁÆóÊàêÊú¨„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜAdaLN-affineÔºå‰∏Ä‰∏™È´òÊïàÁöÑËΩªÈáèÁ∫ßÊ®°ÂùóÔºåÁî®‰∫éËÆ°ÁÆóTransformerÂùó‰∏≠ÁöÑË∞ÉÂà∂ÂèÇÊï∞„ÄÇÊàë‰ª¨ÁöÑ‰ª£Á†ÅÂèØÂú®https://github.com/AMD-AGI/Nitro-E Ëé∑ÂæóÔºåÊàë‰ª¨Â∏åÊúõE-MMDiTËÉΩÂ§üÊàê‰∏∫Êú™Êù•Á†îÁ©∂ÁöÑÂº∫Â§ßËÄåÂÆûÁî®ÁöÑÂü∫Á∫øÔºåÂπ∂‰∏∫ÁîüÊàêÂºèAIÊ®°ÂûãÁöÑÊôÆÂèäÂÅöÂá∫Ë¥°ÁåÆ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Êâ©Êï£Ê®°ÂûãÂú®ËµÑÊ∫êÂèóÈôêÁéØÂ¢É‰∏ãËÆ≠ÁªÉÂíåÈÉ®ÁΩ≤ÁöÑÈöæÈ¢ò„ÄÇÁé∞ÊúâÊâ©Êï£Ê®°ÂûãÈÄöÂ∏∏ÂèÇÊï∞ÈáèÂ∑®Â§ßÔºåÈúÄË¶ÅÂ§ßÈáèÁöÑËÆ≠ÁªÉÊï∞ÊçÆÂíåËÆ°ÁÆóËµÑÊ∫êÔºåËøôÈôêÂà∂‰∫ÜÂÖ∂Âú®ÁÆóÂäõ‰∏çË∂≥ÁöÑÂú∫ÊôØ‰∏ãÁöÑÂ∫îÁî®„ÄÇÊ≠§Â§ñÔºåÂç≥‰ΩøÊ®°ÂûãËÆ≠ÁªÉÂÆåÊàêÔºåÂÖ∂Â§çÊùÇÁöÑÁªìÊûÑ‰πüÂØºËá¥Êé®ÁêÜÈÄüÂ∫¶ÊÖ¢ÔºåÈöæ‰ª•Êª°Ë∂≥ÂÆûÊó∂ÊÄßË¶ÅÊ±Ç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøátokenÁº©ÂáèÊù•Èôç‰ΩéËÆ°ÁÆóÂ§çÊùÇÂ∫¶„ÄÇÁî±‰∫éTransformerÁöÑËÆ°ÁÆóÊàêÊú¨‰∏étokenÊï∞ÈáèÂëàÊòæËëóÁõ∏ÂÖ≥ÔºåÂõ†Ê≠§ÂáèÂ∞ëtokenÊï∞ÈáèÂèØ‰ª•Áõ¥Êé•Èôç‰ΩéËÆ°ÁÆóÈáèÔºå‰ªéËÄåÂÆûÁé∞Ê®°ÂûãÁöÑËΩªÈáèÂåñÂíåÂä†ÈÄü„ÄÇÂêåÊó∂ÔºåËÆ∫ÊñáËøòÈÄöËøáÂ¢ûÂº∫‰ΩçÁΩÆ‰ø°ÊÅØÂíå‰ºòÂåñÊ≥®ÊÑèÂäõÊú∫Âà∂Êù•‰øùÊåÅÂõæÂÉèÁîüÊàêÁöÑË¥®Èáè„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöE-MMDiTÁöÑÊï¥‰ΩìÊû∂ÊûÑÂü∫‰∫éÊâ©Êï£TransformerÔºå‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Ê®°ÂùóÔºö1) È´òÂ∫¶ÂéãÁº©ÁöÑËßÜËßâTokenizerÔºöÂ∞ÜËæìÂÖ•ÂõæÂÉèËΩ¨Êç¢‰∏∫Êõ¥Á¥ßÂáëÁöÑtokenË°®Á§∫„ÄÇ2) Â§öË∑ØÂæÑÂéãÁº©Ê®°ÂùóÔºöËøõ‰∏ÄÊ≠•ÂáèÂ∞ëtokenÊï∞Èáè„ÄÇ3) ‰ΩçÁΩÆÂº∫ÂåñÔºàPosition ReinforcementÔºâÔºöÂ¢ûÂº∫‰ΩçÁΩÆ‰ø°ÊÅØÔºå‰øùÊåÅÁ©∫Èó¥ËøûË¥ØÊÄß„ÄÇ4) ‰∫§ÊõøÂ≠êÂå∫ÂüüÊ≥®ÊÑèÂäõÔºàASAÔºâÔºöÂú®Â≠êÂå∫ÂüüÂÜÖÊâßË°åÊ≥®ÊÑèÂäõÔºåÈôç‰ΩéËÆ°ÁÆóÊàêÊú¨„ÄÇ5) AdaLN-affineÔºö‰∏Ä‰∏™ËΩªÈáèÁ∫ßÁöÑÊ®°ÂùóÔºåÁî®‰∫éËÆ°ÁÆóTransformerÂùó‰∏≠ÁöÑË∞ÉÂà∂ÂèÇÊï∞„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫étokenÁº©ÂáèÁ≠ñÁï•Âíå‰∫§ÊõøÂ≠êÂå∫ÂüüÊ≥®ÊÑèÂäõÊú∫Âà∂„ÄÇÈÄöËøáÈ´òÂ∫¶ÂéãÁº©ÁöÑËßÜËßâTokenizerÂíåÂ§öË∑ØÂæÑÂéãÁº©Ê®°ÂùóÔºåÊòæËëóÂáèÂ∞ë‰∫ÜtokenÊï∞ÈáèÔºå‰ªéËÄåÈôç‰Ωé‰∫ÜËÆ°ÁÆóÂ§çÊùÇÂ∫¶„ÄÇ‰∫§ÊõøÂ≠êÂå∫ÂüüÊ≥®ÊÑèÂäõÊú∫Âà∂ÂàôÂú®‰øùËØÅÊ®°ÂûãÊÄßËÉΩÁöÑÂêåÊó∂ÔºåËøõ‰∏ÄÊ≠•Èôç‰Ωé‰∫ÜËÆ°ÁÆóÊàêÊú¨„ÄÇÊ≠§Â§ñÔºåAdaLN-affineÊ®°Âùó‰πüÊèê‰æõ‰∫Ü‰∏ÄÁßçÈ´òÊïàÁöÑËÆ°ÁÆóË∞ÉÂà∂ÂèÇÊï∞ÁöÑÊñπÊ≥ï„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËßÜËßâTokenizerÊñπÈù¢ÔºåÈááÁî®‰∫ÜÊõ¥ÊøÄËøõÁöÑÂéãÁº©Á≠ñÁï•Ôºå‰ª•Ëé∑ÂæóÊõ¥Â∞ëÁöÑtoken„ÄÇÂ§öË∑ØÂæÑÂéãÁº©Ê®°ÂùóÁöÑËÆæËÆ°ÁªÜËäÇÊú™Áü•„ÄÇ‰ΩçÁΩÆÂº∫ÂåñÊ®°ÂùóÁöÑÂÖ∑‰ΩìÂÆûÁé∞ÊñπÂºèÊú™Áü•Ôºå‰ΩÜÂÖ∂ÁõÆÁöÑÊòØ‰∏∫‰∫ÜÂº•Ë°•tokenÁº©ÂáèÂèØËÉΩÂØºËá¥ÁöÑÁ©∫Èó¥‰ø°ÊÅØÊçüÂ§±„ÄÇ‰∫§ÊõøÂ≠êÂå∫ÂüüÊ≥®ÊÑèÂäõÊú∫Âà∂Â∞ÜÂõæÂÉèÂàíÂàÜ‰∏∫Â§ö‰∏™Â≠êÂå∫ÂüüÔºåÂπ∂Âú®Â≠êÂå∫ÂüüÂÜÖËøõË°åÊ≥®ÊÑèÂäõËÆ°ÁÆóÔºå‰ªéËÄåÈôç‰Ωé‰∫ÜËÆ°ÁÆóÂ§çÊùÇÂ∫¶„ÄÇAdaLN-affineÊ®°ÂùóÁöÑÂÖ∑‰ΩìÁªìÊûÑÂíåÂèÇÊï∞ËÆæÁΩÆÊú™Áü•„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

E-MMDiT‰ªÖ‰ΩøÁî®304MÂèÇÊï∞ÔºåÂú®Âçï‰∏™ÂåÖÂê´8‰∏™AMD MI300X GPUÁöÑËäÇÁÇπ‰∏äÔºå‰ΩøÁî®25MÂÖ¨ÂÖ±Êï∞ÊçÆËÆ≠ÁªÉ1.5Â§©ÔºåÂç≥ÂèØÂú®512pxÂõæÂÉèÁîüÊàê‰ªªÂä°ÁöÑGenEvalÊåáÊ†á‰∏äËææÂà∞0.66„ÄÇÈÄöËøáGRPOÁ≠âËÆ≠ÁªÉÂêéÊäÄÊúØÔºåËØ•ÊåáÊ†áÂèØËΩªÊùæÊèêÂçáËá≥0.72„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéÔºåE-MMDiTÂú®ËµÑÊ∫êÂèóÈôêÁöÑÊÉÖÂÜµ‰∏ãÔºå‰ªçËÉΩÂÆûÁé∞ÂÖ∑ÊúâÁ´û‰∫âÂäõÁöÑÂõæÂÉèÁîüÊàêË¥®Èáè„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

E-MMDiTÂèØÂ∫îÁî®‰∫éËµÑÊ∫êÂèóÈôêÁöÑËæπÁºòËÆæÂ§áÊàñÁßªÂä®ËÆæÂ§á‰∏äÁöÑÂõæÂÉèÁîüÊàê‰ªªÂä°Ôºå‰æãÂ¶ÇÁßªÂä®Á´ØÁöÑAIÁªòÁîªÂ∫îÁî®„ÄÅ‰ΩéÊàêÊú¨ÁöÑÂõæÂÉèÁºñËæëÂ∑•ÂÖ∑Á≠â„ÄÇËØ•Á†îÁ©∂ÊúâÂä©‰∫éÈôç‰ΩéÁîüÊàêÂºèAIÁöÑ‰ΩøÁî®Èó®ÊßõÔºå‰øÉËøõÂÖ∂Âú®Êõ¥ÂπøÊ≥õÁöÑÂú∫ÊôØ‰∏≠Â∫îÁî®ÔºåÂπ∂Âä†ÈÄüÁîüÊàêÂºèAIÁöÑÊôÆÂèä„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Diffusion models have shown strong capabilities in generating high-quality images from text prompts. However, these models often require large-scale training data and significant computational resources to train, or suffer from heavy structure with high latency. To this end, we propose Efficient Multimodal Diffusion Transformer (E-MMDiT), an efficient and lightweight multimodal diffusion model with only 304M parameters for fast image synthesis requiring low training resources. We provide an easily reproducible baseline with competitive results. Our model for 512px generation, trained with only 25M public data in 1.5 days on a single node of 8 AMD MI300X GPUs, achieves 0.66 on GenEval and easily reaches to 0.72 with some post-training techniques such as GRPO. Our design philosophy centers on token reduction as the computational cost scales significantly with the token count. We adopt a highly compressive visual tokenizer to produce a more compact representation and propose a novel multi-path compression module for further compression of tokens. To enhance our design, we introduce Position Reinforcement, which strengthens positional information to maintain spatial coherence, and Alternating Subregion Attention (ASA), which performs attention within subregions to further reduce computational cost. In addition, we propose AdaLN-affine, an efficient lightweight module for computing modulation parameters in transformer blocks. Our code is available at https://github.com/AMD-AGI/Nitro-E and we hope E-MMDiT serves as a strong and practical baseline for future research and contributes to democratization of generative AI models.

