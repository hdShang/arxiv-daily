---
layout: default
title: ANCHOR: Integrating Adversarial Training with Hard-mined Supervised Contrastive Learning for Robust Representation Learning
---

# ANCHOR: Integrating Adversarial Training with Hard-mined Supervised Contrastive Learning for Robust Representation Learning

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.27599" target="_blank" class="toolbar-btn">arXiv: 2510.27599v1</a>
    <a href="https://arxiv.org/pdf/2510.27599.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.27599v1" 
            onclick="toggleFavorite(this, '2510.27599v1', 'ANCHOR: Integrating Adversarial Training with Hard-mined Supervised Contrastive Learning for Robust Representation Learning')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Samarup Bhattacharya, Anubhab Bhattacharya, Abir Chakraborty

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-31

**Â§áÊ≥®**: 11 pages, 1 figure

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫ANCHORÊ°ÜÊû∂ÔºåÁªìÂêàÂØπÊäóËÆ≠ÁªÉ‰∏éÈöæ‰æãÁõëÁù£ÂØπÊØîÂ≠¶‰π†ÔºåÊèêÂçáË°®ÂæÅÂ≠¶‰π†ÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `ÂØπÊäóËÆ≠ÁªÉ` `ÁõëÁù£ÂØπÊØîÂ≠¶‰π†` `Èöæ‰æãÊåñÊéò` `È≤ÅÊ£íË°®ÂæÅÂ≠¶‰π†` `Ê∑±Â∫¶Â≠¶‰π†` `ÂØπÊäóÊîªÂáª` `ÂõæÂÉèÂàÜÁ±ª`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Á•ûÁªèÁΩëÁªúÊòìÂèóÂØπÊäóÊîªÂáªÔºåÂæÆÂ∞èÊâ∞Âä®Âç≥ÂèØÂØºËá¥ÈîôËØØÈ¢ÑÊµãÔºåÁé∞ÊúâÊñπÊ≥ïÈöæ‰ª•ÂÖºÈ°æÂáÜÁ°ÆÁéáÂíåÈ≤ÅÊ£íÊÄß„ÄÇ
2. ANCHORÊ°ÜÊû∂ÁªìÂêàÂØπÊäóËÆ≠ÁªÉ‰∏éÁõëÁù£ÂØπÊØîÂ≠¶‰π†ÔºåÈÄöËøáÈöæ‰æãÊåñÊéòÔºå‰ΩøÂêåÁ±ªÂõæÂÉèÂèäÂÖ∂Êâ∞Âä®Âú®ÂµåÂÖ•Á©∫Èó¥ËÅöÈõÜ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåANCHORÂú®CIFAR-10‰∏äÊòæËëóÊèêÂçá‰∫ÜÂØπÊäóÁéØÂ¢É‰∏ãÁöÑÂáÜÁ°ÆÁéáÔºå‰ºò‰∫éÊ†áÂáÜÂØπÊäóËÆ≠ÁªÉÊñπÊ≥ï„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Á•ûÁªèÁΩëÁªúÈÄöËøáÊ¢ØÂ∫¶‰∏ãÈôçÂ≠¶‰π†Êï∞ÊçÆ‰∏≠ÁöÑÂà§Âà´Ê®°ÂºèÔºå‰ΩÜ‰πüÂõ†Ê≠§Â≠òÂú®ÂØπÊäóÊîªÂáªÁöÑÊºèÊ¥û„ÄÇÂæÆÂ∞èÁöÑ„ÄÅÈöæ‰ª•ÂØüËßâÁöÑÊâ∞Âä®Â∞±ËÉΩÂØºËá¥Ê®°ÂûãÂÅöÂá∫ÈîôËØØÂà§Êñ≠„ÄÇÊú¨ÊñáÊèêÂá∫‰∫ÜÂØπÊäóËÆ≠ÁªÉÁöÑÂØπÊØîÁ°¨ÊåñÊéò‰ºòÂåñÈ≤ÅÊ£íÊÄßÊ°ÜÊû∂ÔºàANCHORÔºâ„ÄÇËØ•Ê°ÜÊû∂Âà©Áî®ÁõëÁù£ÂØπÊØîÂ≠¶‰π†ÂíåÊòæÂºèÁöÑÈöæÊ≠£‰æãÊåñÊéòÔºå‰ΩøÊ®°ÂûãÂ≠¶‰π†Âà∞ÁöÑÂõæÂÉèË°®ÂæÅËÉΩÂ§üÂ∞ÜÂõæÂÉèÊú¨Ë∫´„ÄÅÂÖ∂Â¢ûÂº∫ÁâàÊú¨‰ª•ÂèäÊâ∞Âä®ÁâàÊú¨Ôºå‰∏éÂêåÁ±ªÂà´ÁöÑÂÖ∂‰ªñÂõæÂÉèÂú®ÂµåÂÖ•Á©∫Èó¥‰∏≠ËÅöÈõÜÂú®‰∏ÄËµ∑ÔºåÂêåÊó∂‰∏éÂÖ∂‰ªñÁ±ªÂà´ÁöÑÂõæÂÉèÂàÜÁ¶ª„ÄÇËøôÁßçÂØπÈΩêÊúâÂä©‰∫éÊ®°ÂûãÂÖ≥Ê≥®Á®≥ÂÆö„ÄÅÊúâÊÑè‰πâÁöÑÊ®°ÂºèÔºåËÄå‰∏çÊòØËÑÜÂº±ÁöÑÊ¢ØÂ∫¶Á∫øÁ¥¢„ÄÇÂú®CIFAR-10Êï∞ÊçÆÈõÜ‰∏äÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®PGD-20Ôºàepsilon = 0.031ÔºâÊîªÂáª‰∏ãÔºåÂÆûÁé∞‰∫Ü‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÂπ≤ÂáÄÂáÜÁ°ÆÁéáÂíåÈ≤ÅÊ£íÂáÜÁ°ÆÁéáÔºå‰ºò‰∫éÊ†áÂáÜÂØπÊäóËÆ≠ÁªÉÊñπÊ≥ï„ÄÇÁªìÊûúË°®ÊòéÔºåÂ∞ÜÂØπÊäóÊåáÂØº‰∏éÁ°¨ÊåñÊéòÂØπÊØîÁõëÁù£Áõ∏ÁªìÂêàÔºåÊúâÂä©‰∫éÊ®°ÂûãÂ≠¶‰π†Êõ¥ÁªìÊûÑÂåñÂíåÈ≤ÅÊ£íÁöÑË°®ÂæÅÔºåÁº©Â∞èÂáÜÁ°ÆÁéáÂíåÈ≤ÅÊ£íÊÄß‰πãÈó¥ÁöÑÂ∑ÆË∑ù„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Ê∑±Â∫¶Â≠¶‰π†Ê®°ÂûãÂú®ÂØπÊäóÊîªÂáª‰∏ãÁöÑËÑÜÂº±ÊÄßÈóÆÈ¢ò„ÄÇÁé∞ÊúâÂØπÊäóËÆ≠ÁªÉÊñπÊ≥ïËôΩÁÑ∂ËÉΩÊèêÈ´òÊ®°ÂûãÁöÑÈ≤ÅÊ£íÊÄßÔºå‰ΩÜÂæÄÂæÄ‰ºöÁâ∫Áâ≤Âú®Âπ≤ÂáÄÊï∞ÊçÆ‰∏äÁöÑÂáÜÁ°ÆÁéá„ÄÇÊ≠§Â§ñÔºåÁé∞ÊúâÊñπÊ≥ïÂú®Â≠¶‰π†È≤ÅÊ£íË°®ÂæÅÊó∂ÔºåÂèØËÉΩÊó†Ê≥ïÂÖÖÂàÜÂà©Áî®Á±ªÂà´‰ø°ÊÅØÔºåÂØºËá¥Â≠¶‰π†Âà∞ÁöÑË°®ÂæÅÂå∫ÂàÜÊÄß‰∏çË∂≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜÂØπÊäóËÆ≠ÁªÉ‰∏éÁõëÁù£ÂØπÊØîÂ≠¶‰π†Áõ∏ÁªìÂêàÔºåÂπ∂ÂºïÂÖ•Èöæ‰æãÊåñÊéòÊú∫Âà∂„ÄÇÈÄöËøáÂØπÊäóËÆ≠ÁªÉÔºåÊ®°ÂûãÂèØ‰ª•Â≠¶‰π†ÊäµÊäóÂæÆÂ∞èÊâ∞Âä®ÁöÑËÉΩÂäõ„ÄÇÁõëÁù£ÂØπÊØîÂ≠¶‰π†ÂàôÂà©Áî®Á±ªÂà´‰ø°ÊÅØÔºå‰øÉ‰ΩøÂêåÁ±ªÊ†∑Êú¨Âú®ÂµåÂÖ•Á©∫Èó¥‰∏≠ËÅöÈõÜÔºå‰∏çÂêåÁ±ªÊ†∑Êú¨ÂàÜÁ¶ª„ÄÇÈöæ‰æãÊåñÊéòÂàôÂÖ≥Ê≥®ÈÇ£‰∫õÂÆπÊòìË¢´ËØØÂàÜÁ±ªÁöÑÊ†∑Êú¨Ôºå‰ªéËÄåËøõ‰∏ÄÊ≠•ÊèêÂçáÊ®°ÂûãÁöÑÂå∫ÂàÜËÉΩÂäõÂíåÈ≤ÅÊ£íÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöANCHORÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰∏â‰∏™ÁªÑÊàêÈÉ®ÂàÜÔºöÂõæÂÉèÂ¢ûÂº∫Ê®°Âùó„ÄÅÂØπÊäóÊ†∑Êú¨ÁîüÊàêÊ®°ÂùóÂíåÂØπÊØîÂ≠¶‰π†Ê®°Âùó„ÄÇÈ¶ñÂÖàÔºåÂØπËæìÂÖ•ÂõæÂÉèËøõË°åÂ¢ûÂº∫ÔºåÁîüÊàêÂ§ö‰∏™Â¢ûÂº∫Ê†∑Êú¨„ÄÇÁÑ∂ÂêéÔºåÂà©Áî®ÂØπÊäóÊîªÂáªÁÆóÊ≥ïÔºàÂ¶ÇPGDÔºâÁîüÊàêÂØπÊäóÊ†∑Êú¨„ÄÇÊúÄÂêéÔºåÂ∞ÜÂéüÂßãÂõæÂÉè„ÄÅÂ¢ûÂº∫Ê†∑Êú¨ÂíåÂØπÊäóÊ†∑Êú¨ËæìÂÖ•Âà∞ÁºñÁ†ÅÂô®‰∏≠ÔºåÂæóÂà∞ÂÆÉ‰ª¨ÁöÑÂµåÂÖ•ÂêëÈáè„ÄÇÂØπÊØîÂ≠¶‰π†Ê®°ÂùóÂà©Áî®Ëøô‰∫õÂµåÂÖ•ÂêëÈáèÔºåËÆ°ÁÆóÂØπÊØîÊçüÂ§±ÔºåÂπ∂Êõ¥Êñ∞Ê®°ÂûãÂèÇÊï∞„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜÂØπÊäóËÆ≠ÁªÉ„ÄÅÁõëÁù£ÂØπÊØîÂ≠¶‰π†ÂíåÈöæ‰æãÊåñÊéòÊúâÊú∫ÁªìÂêà„ÄÇ‰º†ÁªüÁöÑÂØπÊäóËÆ≠ÁªÉ‰∏ªË¶ÅÂÖ≥Ê≥®Âçï‰∏™Ê†∑Êú¨ÁöÑÂàÜÁ±ªÊ≠£Á°ÆÊÄßÔºåËÄåANCHORÂàôÂÖ≥Ê≥®Ê†∑Êú¨‰πãÈó¥ÁöÑÂÖ≥Á≥ªÔºåÈÄöËøáÂØπÊØîÂ≠¶‰π†Ôºå‰ΩøÊ®°ÂûãÂ≠¶‰π†Âà∞Êõ¥ÂÖ∑Âå∫ÂàÜÊÄßÁöÑË°®ÂæÅ„ÄÇÈöæ‰æãÊåñÊéòÂàôËøõ‰∏ÄÊ≠•ÊèêÂçá‰∫ÜÊ®°ÂûãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöANCHORÊ°ÜÊû∂ÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ‰ΩøÁî®ÁõëÁù£ÂØπÊØîÊçüÂ§±ÂáΩÊï∞ÔºåÈºìÂä±ÂêåÁ±ªÊ†∑Êú¨ÁöÑÂµåÂÖ•ÂêëÈáèËÅöÈõÜÔºå‰∏çÂêåÁ±ªÊ†∑Êú¨ÂàÜÁ¶ª„ÄÇ2) ÈááÁî®Èöæ‰æãÊåñÊéòÁ≠ñÁï•ÔºåÈÄâÊã©ÈÇ£‰∫õË∑ùÁ¶ªËæÉËøëÁöÑÂêåÁ±ªÊ†∑Êú¨‰Ωú‰∏∫ÈöæÊ≠£‰æãÔºåÂπ∂Â∞ÜÂÖ∂Á∫≥ÂÖ•ÂØπÊØîÊçüÂ§±ÁöÑËÆ°ÁÆó‰∏≠„ÄÇ3) ‰ΩøÁî®ÂØπÊäóËÆ≠ÁªÉÁîüÊàêÂØπÊäóÊ†∑Êú¨ÔºåÂπ∂Â∞ÜÂÖ∂‰Ωú‰∏∫ÂØπÊØîÂ≠¶‰π†ÁöÑËæìÂÖ•Ôºå‰ªéËÄåÊèêÂçáÊ®°ÂûãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇÂÖ∑‰ΩìÁöÑÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨ÂØπÊØîÊçüÂ§±Âíå‰∫§ÂèâÁÜµÊçüÂ§±ÔºåÈÄöËøáÂä†ÊùÉÊ±ÇÂíåËøõË°å‰ºòÂåñ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®CIFAR-10Êï∞ÊçÆÈõÜ‰∏äÔºåANCHORÂú®PGD-20ÊîªÂáª‰∏ãÔºåÂÆûÁé∞‰∫Ü‰ºò‰∫éÊ†áÂáÜÂØπÊäóËÆ≠ÁªÉÊñπÊ≥ïÁöÑÈ≤ÅÊ£íÂáÜÁ°ÆÁéá„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåANCHORÂú®‰øùÊåÅËæÉÈ´òÂπ≤ÂáÄÊï∞ÊçÆÂáÜÁ°ÆÁéáÁöÑÂêåÊó∂ÔºåÊòæËëóÊèêÂçá‰∫ÜÂØπÊäóÁéØÂ¢É‰∏ãÁöÑÂáÜÁ°ÆÁéáÔºåÁº©Â∞è‰∫ÜÂáÜÁ°ÆÁéáÂíåÈ≤ÅÊ£íÊÄß‰πãÈó¥ÁöÑÂ∑ÆË∑ù„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÁªìÂêàÂØπÊäóÊåáÂØº‰∏éÁ°¨ÊåñÊéòÂØπÊØîÁõëÁù£ËÉΩÂ§üÊúâÊïàÊèêÂçáÊ®°ÂûãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂØπÂÆâÂÖ®ÊÄßË¶ÅÊ±ÇËæÉÈ´òÁöÑÈ¢ÜÂüüÔºåÂ¶ÇËá™Âä®È©æÈ©∂„ÄÅÂåªÁñóËØäÊñ≠ÂíåÈáëËûçÈ£éÊéßÁ≠â„ÄÇÂú®Ëøô‰∫õÈ¢ÜÂüüÔºåÊ®°ÂûãÈúÄË¶ÅËÉΩÂ§üÊäµÊäóÊÅ∂ÊÑèÊîªÂáªÔºå‰øùËØÅÂÜ≥Á≠ñÁöÑÂèØÈù†ÊÄß„ÄÇÈÄöËøáÊèêÂçáÊ®°ÂûãÁöÑÈ≤ÅÊ£íÊÄßÔºåÂèØ‰ª•ÊúâÊïàÈôç‰ΩéÊ®°ÂûãË¢´ÊîªÂáªÁöÑÈ£éÈô©ÔºåÊèêÈ´òÁ≥ªÁªüÁöÑÂÆâÂÖ®ÊÄß„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Neural networks have changed the way machines interpret the world. At their core, they learn by following gradients, adjusting their parameters step by step until they identify the most discriminant patterns in the data. This process gives them their strength, yet it also opens the door to a hidden flaw. The very gradients that help a model learn can also be used to produce small, imperceptible tweaks that cause the model to completely alter its decision. Such tweaks are called adversarial attacks. These attacks exploit this vulnerability by adding tiny, imperceptible changes to images that, while leaving them identical to the human eye, cause the model to make wrong predictions. In this work, we propose Adversarially-trained Contrastive Hard-mining for Optimized Robustness (ANCHOR), a framework that leverages the power of supervised contrastive learning with explicit hard positive mining to enable the model to learn representations for images such that the embeddings for the images, their augmentations, and their perturbed versions cluster together in the embedding space along with those for other images of the same class while being separated from images of other classes. This alignment helps the model focus on stable, meaningful patterns rather than fragile gradient cues. On CIFAR-10, our approach achieves impressive results for both clean and robust accuracy under PGD-20 (epsilon = 0.031), outperforming standard adversarial training methods. Our results indicate that combining adversarial guidance with hard-mined contrastive supervision helps models learn more structured and robust representations, narrowing the gap between accuracy and robustness.

