---
layout: default
title: ANCHOR: Integrating Adversarial Training with Hard-mined Supervised Contrastive Learning for Robust Representation Learning
---

# ANCHOR: Integrating Adversarial Training with Hard-mined Supervised Contrastive Learning for Robust Representation Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.27599" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.27599v1</a>
  <a href="https://arxiv.org/pdf/2510.27599.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.27599v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.27599v1', 'ANCHOR: Integrating Adversarial Training with Hard-mined Supervised Contrastive Learning for Robust Representation Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Samarup Bhattacharya, Anubhab Bhattacharya, Abir Chakraborty

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-31

**å¤‡æ³¨**: 11 pages, 1 figure

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºANCHORæ¡†æ¶ï¼Œç»“åˆå¯¹æŠ—è®­ç»ƒä¸éš¾ä¾‹ç›‘ç£å¯¹æ¯”å­¦ä¹ ï¼Œæå‡è¡¨å¾å­¦ä¹ çš„é²æ£’æ€§ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¯¹æŠ—è®­ç»ƒ` `ç›‘ç£å¯¹æ¯”å­¦ä¹ ` `éš¾ä¾‹æŒ–æ˜` `é²æ£’è¡¨å¾å­¦ä¹ ` `æ·±åº¦å­¦ä¹ ` `å¯¹æŠ—æ”»å‡»` `å›¾åƒåˆ†ç±»`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç¥ç»ç½‘ç»œæ˜“å—å¯¹æŠ—æ”»å‡»ï¼Œå¾®å°æ‰°åŠ¨å³å¯å¯¼è‡´é”™è¯¯é¢„æµ‹ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥å…¼é¡¾å‡†ç¡®ç‡å’Œé²æ£’æ€§ã€‚
2. ANCHORæ¡†æ¶ç»“åˆå¯¹æŠ—è®­ç»ƒä¸ç›‘ç£å¯¹æ¯”å­¦ä¹ ï¼Œé€šè¿‡éš¾ä¾‹æŒ–æ˜ï¼Œä½¿åŒç±»å›¾åƒåŠå…¶æ‰°åŠ¨åœ¨åµŒå…¥ç©ºé—´èšé›†ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒANCHORåœ¨CIFAR-10ä¸Šæ˜¾è‘—æå‡äº†å¯¹æŠ—ç¯å¢ƒä¸‹çš„å‡†ç¡®ç‡ï¼Œä¼˜äºæ ‡å‡†å¯¹æŠ—è®­ç»ƒæ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç¥ç»ç½‘ç»œé€šè¿‡æ¢¯åº¦ä¸‹é™å­¦ä¹ æ•°æ®ä¸­çš„åˆ¤åˆ«æ¨¡å¼ï¼Œä½†ä¹Ÿå› æ­¤å­˜åœ¨å¯¹æŠ—æ”»å‡»çš„æ¼æ´ã€‚å¾®å°çš„ã€éš¾ä»¥å¯Ÿè§‰çš„æ‰°åŠ¨å°±èƒ½å¯¼è‡´æ¨¡å‹åšå‡ºé”™è¯¯åˆ¤æ–­ã€‚æœ¬æ–‡æå‡ºäº†å¯¹æŠ—è®­ç»ƒçš„å¯¹æ¯”ç¡¬æŒ–æ˜ä¼˜åŒ–é²æ£’æ€§æ¡†æ¶ï¼ˆANCHORï¼‰ã€‚è¯¥æ¡†æ¶åˆ©ç”¨ç›‘ç£å¯¹æ¯”å­¦ä¹ å’Œæ˜¾å¼çš„éš¾æ­£ä¾‹æŒ–æ˜ï¼Œä½¿æ¨¡å‹å­¦ä¹ åˆ°çš„å›¾åƒè¡¨å¾èƒ½å¤Ÿå°†å›¾åƒæœ¬èº«ã€å…¶å¢å¼ºç‰ˆæœ¬ä»¥åŠæ‰°åŠ¨ç‰ˆæœ¬ï¼Œä¸åŒç±»åˆ«çš„å…¶ä»–å›¾åƒåœ¨åµŒå…¥ç©ºé—´ä¸­èšé›†åœ¨ä¸€èµ·ï¼ŒåŒæ—¶ä¸å…¶ä»–ç±»åˆ«çš„å›¾åƒåˆ†ç¦»ã€‚è¿™ç§å¯¹é½æœ‰åŠ©äºæ¨¡å‹å…³æ³¨ç¨³å®šã€æœ‰æ„ä¹‰çš„æ¨¡å¼ï¼Œè€Œä¸æ˜¯è„†å¼±çš„æ¢¯åº¦çº¿ç´¢ã€‚åœ¨CIFAR-10æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨PGD-20ï¼ˆepsilon = 0.031ï¼‰æ”»å‡»ä¸‹ï¼Œå®ç°äº†ä»¤äººå°è±¡æ·±åˆ»çš„å¹²å‡€å‡†ç¡®ç‡å’Œé²æ£’å‡†ç¡®ç‡ï¼Œä¼˜äºæ ‡å‡†å¯¹æŠ—è®­ç»ƒæ–¹æ³•ã€‚ç»“æœè¡¨æ˜ï¼Œå°†å¯¹æŠ—æŒ‡å¯¼ä¸ç¡¬æŒ–æ˜å¯¹æ¯”ç›‘ç£ç›¸ç»“åˆï¼Œæœ‰åŠ©äºæ¨¡å‹å­¦ä¹ æ›´ç»“æ„åŒ–å’Œé²æ£’çš„è¡¨å¾ï¼Œç¼©å°å‡†ç¡®ç‡å’Œé²æ£’æ€§ä¹‹é—´çš„å·®è·ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å¯¹æŠ—æ”»å‡»ä¸‹çš„è„†å¼±æ€§é—®é¢˜ã€‚ç°æœ‰å¯¹æŠ—è®­ç»ƒæ–¹æ³•è™½ç„¶èƒ½æé«˜æ¨¡å‹çš„é²æ£’æ€§ï¼Œä½†å¾€å¾€ä¼šç‰ºç‰²åœ¨å¹²å‡€æ•°æ®ä¸Šçš„å‡†ç¡®ç‡ã€‚æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•åœ¨å­¦ä¹ é²æ£’è¡¨å¾æ—¶ï¼Œå¯èƒ½æ— æ³•å……åˆ†åˆ©ç”¨ç±»åˆ«ä¿¡æ¯ï¼Œå¯¼è‡´å­¦ä¹ åˆ°çš„è¡¨å¾åŒºåˆ†æ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†å¯¹æŠ—è®­ç»ƒä¸ç›‘ç£å¯¹æ¯”å­¦ä¹ ç›¸ç»“åˆï¼Œå¹¶å¼•å…¥éš¾ä¾‹æŒ–æ˜æœºåˆ¶ã€‚é€šè¿‡å¯¹æŠ—è®­ç»ƒï¼Œæ¨¡å‹å¯ä»¥å­¦ä¹ æŠµæŠ—å¾®å°æ‰°åŠ¨çš„èƒ½åŠ›ã€‚ç›‘ç£å¯¹æ¯”å­¦ä¹ åˆ™åˆ©ç”¨ç±»åˆ«ä¿¡æ¯ï¼Œä¿ƒä½¿åŒç±»æ ·æœ¬åœ¨åµŒå…¥ç©ºé—´ä¸­èšé›†ï¼Œä¸åŒç±»æ ·æœ¬åˆ†ç¦»ã€‚éš¾ä¾‹æŒ–æ˜åˆ™å…³æ³¨é‚£äº›å®¹æ˜“è¢«è¯¯åˆ†ç±»çš„æ ·æœ¬ï¼Œä»è€Œè¿›ä¸€æ­¥æå‡æ¨¡å‹çš„åŒºåˆ†èƒ½åŠ›å’Œé²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šANCHORæ¡†æ¶ä¸»è¦åŒ…å«ä¸‰ä¸ªç»„æˆéƒ¨åˆ†ï¼šå›¾åƒå¢å¼ºæ¨¡å—ã€å¯¹æŠ—æ ·æœ¬ç”Ÿæˆæ¨¡å—å’Œå¯¹æ¯”å­¦ä¹ æ¨¡å—ã€‚é¦–å…ˆï¼Œå¯¹è¾“å…¥å›¾åƒè¿›è¡Œå¢å¼ºï¼Œç”Ÿæˆå¤šä¸ªå¢å¼ºæ ·æœ¬ã€‚ç„¶åï¼Œåˆ©ç”¨å¯¹æŠ—æ”»å‡»ç®—æ³•ï¼ˆå¦‚PGDï¼‰ç”Ÿæˆå¯¹æŠ—æ ·æœ¬ã€‚æœ€åï¼Œå°†åŸå§‹å›¾åƒã€å¢å¼ºæ ·æœ¬å’Œå¯¹æŠ—æ ·æœ¬è¾“å…¥åˆ°ç¼–ç å™¨ä¸­ï¼Œå¾—åˆ°å®ƒä»¬çš„åµŒå…¥å‘é‡ã€‚å¯¹æ¯”å­¦ä¹ æ¨¡å—åˆ©ç”¨è¿™äº›åµŒå…¥å‘é‡ï¼Œè®¡ç®—å¯¹æ¯”æŸå¤±ï¼Œå¹¶æ›´æ–°æ¨¡å‹å‚æ•°ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†å¯¹æŠ—è®­ç»ƒã€ç›‘ç£å¯¹æ¯”å­¦ä¹ å’Œéš¾ä¾‹æŒ–æ˜æœ‰æœºç»“åˆã€‚ä¼ ç»Ÿçš„å¯¹æŠ—è®­ç»ƒä¸»è¦å…³æ³¨å•ä¸ªæ ·æœ¬çš„åˆ†ç±»æ­£ç¡®æ€§ï¼Œè€ŒANCHORåˆ™å…³æ³¨æ ·æœ¬ä¹‹é—´çš„å…³ç³»ï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ ï¼Œä½¿æ¨¡å‹å­¦ä¹ åˆ°æ›´å…·åŒºåˆ†æ€§çš„è¡¨å¾ã€‚éš¾ä¾‹æŒ–æ˜åˆ™è¿›ä¸€æ­¥æå‡äº†æ¨¡å‹çš„é²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šANCHORæ¡†æ¶çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨ç›‘ç£å¯¹æ¯”æŸå¤±å‡½æ•°ï¼Œé¼“åŠ±åŒç±»æ ·æœ¬çš„åµŒå…¥å‘é‡èšé›†ï¼Œä¸åŒç±»æ ·æœ¬åˆ†ç¦»ã€‚2) é‡‡ç”¨éš¾ä¾‹æŒ–æ˜ç­–ç•¥ï¼Œé€‰æ‹©é‚£äº›è·ç¦»è¾ƒè¿‘çš„åŒç±»æ ·æœ¬ä½œä¸ºéš¾æ­£ä¾‹ï¼Œå¹¶å°†å…¶çº³å…¥å¯¹æ¯”æŸå¤±çš„è®¡ç®—ä¸­ã€‚3) ä½¿ç”¨å¯¹æŠ—è®­ç»ƒç”Ÿæˆå¯¹æŠ—æ ·æœ¬ï¼Œå¹¶å°†å…¶ä½œä¸ºå¯¹æ¯”å­¦ä¹ çš„è¾“å…¥ï¼Œä»è€Œæå‡æ¨¡å‹çš„é²æ£’æ€§ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°åŒ…æ‹¬å¯¹æ¯”æŸå¤±å’Œäº¤å‰ç†µæŸå¤±ï¼Œé€šè¿‡åŠ æƒæ±‚å’Œè¿›è¡Œä¼˜åŒ–ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨CIFAR-10æ•°æ®é›†ä¸Šï¼ŒANCHORåœ¨PGD-20æ”»å‡»ä¸‹ï¼Œå®ç°äº†ä¼˜äºæ ‡å‡†å¯¹æŠ—è®­ç»ƒæ–¹æ³•çš„é²æ£’å‡†ç¡®ç‡ã€‚å…·ä½“è€Œè¨€ï¼ŒANCHORåœ¨ä¿æŒè¾ƒé«˜å¹²å‡€æ•°æ®å‡†ç¡®ç‡çš„åŒæ—¶ï¼Œæ˜¾è‘—æå‡äº†å¯¹æŠ—ç¯å¢ƒä¸‹çš„å‡†ç¡®ç‡ï¼Œç¼©å°äº†å‡†ç¡®ç‡å’Œé²æ£’æ€§ä¹‹é—´çš„å·®è·ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç»“åˆå¯¹æŠ—æŒ‡å¯¼ä¸ç¡¬æŒ–æ˜å¯¹æ¯”ç›‘ç£èƒ½å¤Ÿæœ‰æ•ˆæå‡æ¨¡å‹çš„é²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¯¹å®‰å…¨æ€§è¦æ±‚è¾ƒé«˜çš„é¢†åŸŸï¼Œå¦‚è‡ªåŠ¨é©¾é©¶ã€åŒ»ç–—è¯Šæ–­å’Œé‡‘èé£æ§ç­‰ã€‚åœ¨è¿™äº›é¢†åŸŸï¼Œæ¨¡å‹éœ€è¦èƒ½å¤ŸæŠµæŠ—æ¶æ„æ”»å‡»ï¼Œä¿è¯å†³ç­–çš„å¯é æ€§ã€‚é€šè¿‡æå‡æ¨¡å‹çš„é²æ£’æ€§ï¼Œå¯ä»¥æœ‰æ•ˆé™ä½æ¨¡å‹è¢«æ”»å‡»çš„é£é™©ï¼Œæé«˜ç³»ç»Ÿçš„å®‰å…¨æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Neural networks have changed the way machines interpret the world. At their core, they learn by following gradients, adjusting their parameters step by step until they identify the most discriminant patterns in the data. This process gives them their strength, yet it also opens the door to a hidden flaw. The very gradients that help a model learn can also be used to produce small, imperceptible tweaks that cause the model to completely alter its decision. Such tweaks are called adversarial attacks. These attacks exploit this vulnerability by adding tiny, imperceptible changes to images that, while leaving them identical to the human eye, cause the model to make wrong predictions. In this work, we propose Adversarially-trained Contrastive Hard-mining for Optimized Robustness (ANCHOR), a framework that leverages the power of supervised contrastive learning with explicit hard positive mining to enable the model to learn representations for images such that the embeddings for the images, their augmentations, and their perturbed versions cluster together in the embedding space along with those for other images of the same class while being separated from images of other classes. This alignment helps the model focus on stable, meaningful patterns rather than fragile gradient cues. On CIFAR-10, our approach achieves impressive results for both clean and robust accuracy under PGD-20 (epsilon = 0.031), outperforming standard adversarial training methods. Our results indicate that combining adversarial guidance with hard-mined contrastive supervision helps models learn more structured and robust representations, narrowing the gap between accuracy and robustness.

