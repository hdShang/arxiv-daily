---
layout: default
title: GUI-Rise: Structured Reasoning and History Summarization for GUI Navigation
---

# GUI-Rise: Structured Reasoning and History Summarization for GUI Navigation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.27210" target="_blank" class="toolbar-btn">arXiv: 2510.27210v1</a>
    <a href="https://arxiv.org/pdf/2510.27210.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.27210v1" 
            onclick="toggleFavorite(this, '2510.27210v1', 'GUI-Rise: Structured Reasoning and History Summarization for GUI Navigation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Tao Liu, Chongyu Wang, Rongjie Li, Yingchen Yu, Xuming He, Bai Song

**ÂàÜÁ±ª**: cs.AI, cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-31

**Â§áÊ≥®**: Published in NeurIPS 2025

**üîó ‰ª£Á†Å/È°πÁõÆ**: [PROJECT_PAGE](https://leon022.github.io/GUI-Rise)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**GUI-RiseÔºöÊèêÂá∫‰∏ÄÁßçËûçÂêàÁªìÊûÑÂåñÊé®ÁêÜÂíåÂéÜÂè≤ÊÄªÁªìÁöÑGUIÂØºËà™Ê°ÜÊû∂ÔºåÊèêÂçáË∑®È¢ÜÂüüÊ≥õÂåñËÉΩÂäõ„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `GUIÂØºËà™` `Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã` `ÁªìÊûÑÂåñÊé®ÁêÜ` `ÂéÜÂè≤ÊÄªÁªì` `Âº∫ÂåñÂ≠¶‰π†` `Chain-of-Thought` `Ë∑®È¢ÜÂüüÊ≥õÂåñ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâGUIÂØºËà™‰ª£ÁêÜÂú®Ë∑®È¢ÜÂüüÊ≥õÂåñËÉΩÂäõÂíåÂéÜÂè≤‰ø°ÊÅØÊúâÊïàÂà©Áî®ÊñπÈù¢Â≠òÂú®‰∏çË∂≥ÔºåÈôêÂà∂‰∫ÜÂÖ∂Â∫îÁî®ËåÉÂõ¥„ÄÇ
2. GUI-RiseÊ°ÜÊû∂ÈÄöËøáÁªìÊûÑÂåñÊé®ÁêÜÁîüÊàêChain-of-ThoughtÂàÜÊûêÔºåÊåáÂØºÂä®‰ΩúÈ¢ÑÊµãÂíåÂéÜÂè≤ÊÄªÁªìÔºåÊèêÂçáÂÜ≥Á≠ñË¥®Èáè„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåGUI-RiseÂú®Ê†áÂáÜÂü∫ÂáÜ‰∏äÂèñÂæó‰∫ÜÊúÄÂÖàËøõÁöÑÁªìÊûúÔºåÂ∞§ÂÖ∂ÊòØÂú®È¢ÜÂüüÂ§ñÂú∫ÊôØ‰∏≠Ë°®Áé∞Âá∫Âº∫Â§ßÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMsÔºâÂú®GUIÂØºËà™‰ª£ÁêÜÊñπÈù¢ÂèñÂæó‰∫ÜËøõÂ±ïÔºå‰ΩÜÁé∞ÊúâÊñπÊ≥ïÂú®Ë∑®È¢ÜÂüüÊ≥õÂåñÂíåÊúâÊïàÂà©Áî®ÂéÜÂè≤‰ø°ÊÅØÊñπÈù¢Â≠òÂú®Â±ÄÈôêÊÄß„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊé®ÁêÜÂ¢ûÂº∫Ê°ÜÊû∂ÔºåËØ•Ê°ÜÊû∂Á≥ªÁªüÂú∞Êï¥Âêà‰∫ÜÁªìÊûÑÂåñÊé®ÁêÜ„ÄÅÂä®‰ΩúÈ¢ÑÊµãÂíåÂéÜÂè≤ÊÄªÁªì„ÄÇÁªìÊûÑÂåñÊé®ÁêÜÁªÑ‰ª∂ÁîüÊàêËøûË¥ØÁöÑChain-of-ThoughtÂàÜÊûêÔºåÁªìÂêà‰∫ÜËøõÂ∫¶‰º∞ËÆ°ÂíåÂÜ≥Á≠ñÊé®ÁêÜÔºå‰∏∫Âç≥Êó∂Âä®‰ΩúÈ¢ÑÊµãÂíåÊú™Êù•Ê≠•È™§ÁöÑÁ¥ßÂáëÂéÜÂè≤ÊÄªÁªìÊèê‰æõ‰ø°ÊÅØ„ÄÇÂü∫‰∫éÊ≠§Ê°ÜÊû∂ÔºåÊàë‰ª¨ÈÄöËøáÂú®‰º™Ê†áÁ≠æËΩ®Ëøπ‰∏äËøõË°åÁõëÁù£ÂæÆË∞ÉÂíå‰ΩøÁî®Áæ§‰ΩìÁõ∏ÂØπÁ≠ñÁï•‰ºòÂåñÔºàGRPOÔºâËøõË°åÂº∫ÂåñÂ≠¶‰π†ÔºåËÆ≠ÁªÉ‰∫Ü‰∏Ä‰∏™GUI‰ª£ÁêÜÔºåÂêç‰∏∫GUI-Rise„ÄÇËØ•Ê°ÜÊû∂ÈááÁî®‰∏ìÈó®ÁöÑÂ•ñÂä±ÔºåÂåÖÊã¨‰∏Ä‰∏™ÂéÜÂè≤ÊÑüÁü•ÁõÆÊ†áÔºåÁõ¥Êé•Â∞ÜÊÄªÁªìË¥®Èáè‰∏éÂêéÁª≠Âä®‰ΩúË°®Áé∞ËÅîÁ≥ªËµ∑Êù•„ÄÇÂú®Ê†áÂáÜÂü∫ÂáÜ‰∏äÁöÑÂÖ®Èù¢ËØÑ‰º∞Ë°®ÊòéÔºåÂú®Áõ∏ÂêåÁöÑËÆ≠ÁªÉÊï∞ÊçÆÊù°‰ª∂‰∏ãÔºåËØ•ÊñπÊ≥ïÂèñÂæó‰∫ÜÊúÄÂÖàËøõÁöÑÁªìÊûúÔºåÂ∞§ÂÖ∂ÊòØÂú®È¢ÜÂüüÂ§ñÂú∫ÊôØ‰∏≠Ë°®Áé∞Âá∫Ëâ≤„ÄÇËøô‰∫õÂèëÁé∞È™åËØÅ‰∫ÜÊàë‰ª¨ÁöÑÊ°ÜÊû∂Âú®ÂêÑÁßçGUIÂØºËà™‰ªªÂä°‰∏≠‰øùÊåÅÁ®≥ÂÅ•ÁöÑÊé®ÁêÜÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÂü∫‰∫éÂ§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑGUIÂØºËà™‰ª£ÁêÜÂú®Ë∑®È¢ÜÂüüÊ≥õÂåñËÉΩÂäõÂíåÂéÜÂè≤‰ø°ÊÅØÂà©Áî®ÊñπÈù¢Â≠òÂú®‰∏çË∂≥„ÄÇÂÆÉ‰ª¨Èöæ‰ª•ÊúâÊïàÂú∞Â§ÑÁêÜ‰∏çÂêåÁ±ªÂûãÁöÑGUIÁïåÈù¢ÔºåÂπ∂‰∏îÊó†Ê≥ïÂÖÖÂàÜÂà©Áî®ÂéÜÂè≤‰∫§‰∫í‰ø°ÊÅØÊù•ÊåáÂØºÊú™Êù•ÁöÑÂä®‰ΩúÂÜ≥Á≠ñÔºåÂØºËá¥ÊÄßËÉΩ‰∏ãÈôç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöGUI-RiseÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂºïÂÖ•ÁªìÊûÑÂåñÊé®ÁêÜÂíåÂéÜÂè≤ÊÄªÁªìÊú∫Âà∂ÔºåÂ¢ûÂº∫‰ª£ÁêÜÁöÑÂÜ≥Á≠ñËÉΩÂäõÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇÈÄöËøáÁªìÊûÑÂåñÊé®ÁêÜÔºå‰ª£ÁêÜÂèØ‰ª•Êõ¥Ê∏ÖÊô∞Âú∞ÁêÜËß£ÂΩìÂâç‰ªªÂä°ÁöÑÁä∂ÊÄÅÂíåÁõÆÊ†áÔºåÂπ∂ÁîüÊàêËøûË¥ØÁöÑChain-of-ThoughtÂàÜÊûê„ÄÇÈÄöËøáÂéÜÂè≤ÊÄªÁªìÔºå‰ª£ÁêÜÂèØ‰ª•Â∞ÜËøáÂéªÁöÑÂÖ≥ÈîÆ‰ø°ÊÅØÂéãÁº©ÊàêÁ¥ßÂáëÁöÑË°®Á§∫Ôºå‰ª•‰æøÂú®Êú™Êù•ÁöÑÂÜ≥Á≠ñ‰∏≠‰ΩøÁî®„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöGUI-RiseÊ°ÜÊû∂ÂåÖÂê´‰∏â‰∏™‰∏ªË¶ÅÁªÑ‰ª∂ÔºöÁªìÊûÑÂåñÊé®ÁêÜ„ÄÅÂä®‰ΩúÈ¢ÑÊµãÂíåÂéÜÂè≤ÊÄªÁªì„ÄÇÈ¶ñÂÖàÔºåÁªìÊûÑÂåñÊé®ÁêÜÁªÑ‰ª∂Êé•Êî∂GUIÁïåÈù¢ÂõæÂÉèÂíåÂéÜÂè≤‰ø°ÊÅØ‰Ωú‰∏∫ËæìÂÖ•ÔºåÁîüÊàêChain-of-ThoughtÂàÜÊûêÔºåÂåÖÊã¨ËøõÂ∫¶‰º∞ËÆ°ÂíåÂÜ≥Á≠ñÊé®ÁêÜ„ÄÇÁÑ∂ÂêéÔºåÂä®‰ΩúÈ¢ÑÊµãÁªÑ‰ª∂Âü∫‰∫éChain-of-ThoughtÂàÜÊûêÈ¢ÑÊµã‰∏ã‰∏ÄÊ≠•ÁöÑÂä®‰Ωú„ÄÇÂêåÊó∂ÔºåÂéÜÂè≤ÊÄªÁªìÁªÑ‰ª∂Â∞ÜChain-of-ThoughtÂàÜÊûêÂéãÁº©ÊàêÁ¥ßÂáëÁöÑÂéÜÂè≤ÊëòË¶ÅÔºåÁî®‰∫éÊåáÂØºÊú™Êù•ÁöÑÊé®ÁêÜÂíåÂä®‰ΩúÈ¢ÑÊµã„ÄÇÊï¥‰∏™Ê°ÜÊû∂ÈÄöËøáÁõëÁù£ÂæÆË∞ÉÂíåÂº∫ÂåñÂ≠¶‰π†ËøõË°åËÆ≠ÁªÉ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöGUI-RiseÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜÁªìÊûÑÂåñÊé®ÁêÜÂíåÂéÜÂè≤ÊÄªÁªìÁõ∏ÁªìÂêàÔºåÂΩ¢Êàê‰∏Ä‰∏™Èó≠ÁéØÁöÑÂèçÈ¶àÊú∫Âà∂„ÄÇÁªìÊûÑÂåñÊé®ÁêÜ‰∏ç‰ªÖÊåáÂØºÂä®‰ΩúÈ¢ÑÊµãÔºåËøòÁî®‰∫éÁîüÊàêÂéÜÂè≤ÊëòË¶ÅÔºåËÄåÂéÜÂè≤ÊëòË¶ÅÂèàÂèçËøáÊù•ÂΩ±ÂìçÊú™Êù•ÁöÑÊé®ÁêÜËøáÁ®ã„ÄÇËøôÁßçËÆæËÆ°‰ΩøÂæó‰ª£ÁêÜËÉΩÂ§üÊõ¥Â•ΩÂú∞ÁêÜËß£‰ªªÂä°Áä∂ÊÄÅ„ÄÅÂà©Áî®ÂéÜÂè≤‰ø°ÊÅØÔºåÂπ∂ÂÅöÂá∫Êõ¥ÊòéÊô∫ÁöÑÂÜ≥Á≠ñ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöGUI-Rise‰ΩøÁî®Chain-of-ThoughtÊèêÁ§∫Â∑•Á®ãÊù•ÂºïÂØºÁªìÊûÑÂåñÊé®ÁêÜ„ÄÇÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠Ôºå‰ΩøÁî®‰º™Ê†áÁ≠æËΩ®ËøπËøõË°åÁõëÁù£ÂæÆË∞ÉÔºåÂπ∂‰ΩøÁî®Áæ§‰ΩìÁõ∏ÂØπÁ≠ñÁï•‰ºòÂåñÔºàGRPOÔºâËøõË°åÂº∫ÂåñÂ≠¶‰π†„ÄÇÁâπÂà´Âú∞ÔºåËÆæËÆ°‰∫Ü‰∏Ä‰∏™ÂéÜÂè≤ÊÑüÁü•Â•ñÂä±ÂáΩÊï∞ÔºåÂ∞ÜÂéÜÂè≤ÊëòË¶ÅÁöÑË¥®Èáè‰∏éÂêéÁª≠Âä®‰ΩúÁöÑË°®Áé∞Áõ¥Êé•ËÅîÁ≥ªËµ∑Êù•ÔºåÈºìÂä±‰ª£ÁêÜÁîüÊàêÊõ¥ÊúâÁî®ÁöÑÂéÜÂè≤ÊëòË¶Å„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

GUI-RiseÂú®Ê†áÂáÜGUIÂØºËà™Âü∫ÂáÜÊµãËØï‰∏≠ÂèñÂæó‰∫ÜÊúÄÂÖàËøõÁöÑÁªìÊûúÔºåÂ∞§ÂÖ∂ÊòØÂú®È¢ÜÂüüÂ§ñÂú∫ÊôØ‰∏≠Ë°®Áé∞Âá∫Ëâ≤„ÄÇÂú®Áõ∏ÂêåÁöÑËÆ≠ÁªÉÊï∞ÊçÆÊù°‰ª∂‰∏ãÔºåGUI-RiseÁöÑÊÄßËÉΩÊòæËëó‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÈ™åËØÅ‰∫ÜÂÖ∂Ê°ÜÊû∂ÁöÑÊúâÊïàÊÄßÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÁªìÊûÑÂåñÊé®ÁêÜÂíåÂéÜÂè≤ÊÄªÁªìÊú∫Âà∂ËÉΩÂ§üÊúâÊïàÊèêÂçáGUIÂØºËà™‰ª£ÁêÜÁöÑÊÄßËÉΩ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

GUI-RiseÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂèØÁî®‰∫éËá™Âä®ÂåñËΩØ‰ª∂ÊµãËØï„ÄÅÁî®Êà∑ÁïåÈù¢Ëá™Âä®Âåñ„ÄÅËæÖÂä©ÊäÄÊúØÁ≠âÈ¢ÜÂüü„ÄÇÂÆÉÂèØ‰ª•Â∏ÆÂä©Áî®Êà∑Êõ¥È´òÊïàÂú∞ÂÆåÊàêÂêÑÁßçGUIÂØºËà™‰ªªÂä°ÔºåÊèêÈ´òÂ∑•‰ΩúÊïàÁéáÂíåÁî®Êà∑‰ΩìÈ™å„ÄÇÊú™Êù•ÔºåËØ•ÊäÄÊúØÊúâÊúõÂ∫îÁî®‰∫éÊõ¥Â§çÊùÇÁöÑ‰∫§‰∫íÂºèÁ≥ªÁªü‰∏≠Ôºå‰æãÂ¶ÇËôöÊãüÂä©ÊâãÂíåÊú∫Âô®‰∫∫„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> While Multimodal Large Language Models (MLLMs) have advanced GUI navigation agents, current approaches face limitations in cross-domain generalization and effective history utilization. We present a reasoning-enhanced framework that systematically integrates structured reasoning, action prediction, and history summarization. The structured reasoning component generates coherent Chain-of-Thought analyses combining progress estimation and decision reasoning, which inform both immediate action predictions and compact history summaries for future steps. Based on this framework, we train a GUI agent, \textbf{GUI-Rise}, through supervised fine-tuning on pseudo-labeled trajectories and reinforcement learning with Group Relative Policy Optimization (GRPO). This framework employs specialized rewards, including a history-aware objective, directly linking summary quality to subsequent action performance. Comprehensive evaluations on standard benchmarks demonstrate state-of-the-art results under identical training data conditions, with particularly strong performance in out-of-domain scenarios. These findings validate our framework's ability to maintain robust reasoning and generalization across diverse GUI navigation tasks. Code is available at https://leon022.github.io/GUI-Rise.

