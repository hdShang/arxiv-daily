---
layout: default
title: Towards Universal Video Retrieval: Generalizing Video Embedding via Synthesized Multimodal Pyramid Curriculum
---

# Towards Universal Video Retrieval: Generalizing Video Embedding via Synthesized Multimodal Pyramid Curriculum

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.27571" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.27571v1</a>
  <a href="https://arxiv.org/pdf/2510.27571.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.27571v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.27571v1', 'Towards Universal Video Retrieval: Generalizing Video Embedding via Synthesized Multimodal Pyramid Curriculum')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhuoning Guo, Mingxin Li, Yanzhao Zhang, Dingkun Long, Pengjun Xie, Xiaowen Chu

**åˆ†ç±»**: cs.CV, cs.AI, cs.CL, cs.IR, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-10-31

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé€šç”¨è§†é¢‘æ£€ç´¢æ¡†æ¶ï¼Œé€šè¿‡åˆæˆå¤šæ¨¡æ€é‡‘å­—å¡”è¯¾ç¨‹æ³›åŒ–è§†é¢‘åµŒå…¥**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†é¢‘æ£€ç´¢` `é€šç”¨æ€§` `å¤šæ¨¡æ€å­¦ä¹ ` `é›¶æ ·æœ¬å­¦ä¹ ` `æ•°æ®åˆæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†é¢‘æ£€ç´¢æ–¹æ³•åœ¨ç‹­çª„åŸºå‡†ä¸Šè®­ç»ƒï¼Œç¼ºä¹å¤šç»´åº¦æ³›åŒ–èƒ½åŠ›ï¼Œé™åˆ¶äº†é€šç”¨æ€§ã€‚
2. è®ºæ–‡æå‡ºååŒè®¾è®¡çš„æ¡†æ¶ï¼ŒåŒ…å«è¯„ä¼°åŸºå‡†ã€æ•°æ®åˆæˆå’Œæ¨¡æ€é‡‘å­—å¡”è¯¾ç¨‹å­¦ä¹ ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é€šç”¨è§†é¢‘æ£€ç´¢åŸºå‡†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„é›¶æ ·æœ¬æ³›åŒ–æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å½“å‰è§†é¢‘æ£€ç´¢èŒƒå¼å­˜åœ¨ç»“æ„æ€§åå·®ï¼Œç‹­éš˜çš„åŸºå‡†æµ‹è¯•é¼“åŠ±äº†ç›¸åº”æœ‰é™çš„æ•°æ®å’Œå•ä»»åŠ¡è®­ç»ƒã€‚å› æ­¤ï¼Œç”±äºç¼ºä¹å®šä¹‰å’Œè¦æ±‚å¤šç»´åº¦æ³›åŒ–çš„è¯Šæ–­æ€§è¯„ä¼°ï¼Œé€šç”¨èƒ½åŠ›å—åˆ°æŠ‘åˆ¶ã€‚ä¸ºäº†æ‰“ç ´è¿™ä¸ªå¾ªç¯ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå»ºç«‹åœ¨è¯„ä¼°ã€æ•°æ®å’Œå»ºæ¨¡ååŒè®¾è®¡ä¹‹ä¸Šçš„æ¡†æ¶ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å»ºç«‹äº†é€šç”¨è§†é¢‘æ£€ç´¢åŸºå‡†ï¼ˆUVRBï¼‰ï¼Œå®ƒåŒ…å«16ä¸ªæ•°æ®é›†ï¼Œæ—¨åœ¨ä¸ä»…è¡¡é‡æ€§èƒ½ï¼Œè¿˜è¯Šæ–­è·¨ä»»åŠ¡å’Œé¢†åŸŸçš„å…³é”®èƒ½åŠ›å·®è·ã€‚å…¶æ¬¡ï¼Œåœ¨UVRBè¯Šæ–­çš„æŒ‡å¯¼ä¸‹ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªå¯æ‰©å±•çš„åˆæˆå·¥ä½œæµç¨‹ï¼Œç”Ÿæˆ155ä¸‡ä¸ªé«˜è´¨é‡çš„pairï¼Œä»¥å¡«å……é€šç”¨æ€§æ‰€éœ€çš„è¯­ä¹‰ç©ºé—´ã€‚æœ€åï¼Œæˆ‘ä»¬è®¾è®¡äº†æ¨¡æ€é‡‘å­—å¡”ï¼Œè¿™æ˜¯ä¸€ç§è¯¾ç¨‹ï¼Œé€šè¿‡æ˜¾å¼åˆ©ç”¨æˆ‘ä»¬å¤šæ ·åŒ–æ•°æ®ä¸­çš„æ½œåœ¨äº’è¿æ¥è®­ç»ƒæˆ‘ä»¬çš„é€šç”¨è§†é¢‘åµŒå…¥å™¨ï¼ˆGVEï¼‰ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒGVEåœ¨UVRBä¸Šå®ç°äº†æœ€å…ˆè¿›çš„é›¶æ ·æœ¬æ³›åŒ–ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬çš„åˆ†æè¡¨æ˜ï¼Œæµè¡Œçš„åŸºå‡†æµ‹è¯•ä¸èƒ½å¾ˆå¥½åœ°é¢„æµ‹é€šç”¨èƒ½åŠ›ï¼Œå¹¶ä¸”éƒ¨åˆ†ç›¸å…³çš„æ£€ç´¢æ˜¯ä¸€ç§ä¸»è¦çš„ä½†è¢«å¿½è§†çš„åœºæ™¯ã€‚æ€»çš„æ¥è¯´ï¼Œæˆ‘ä»¬çš„ååŒè®¾è®¡æ¡†æ¶æä¾›äº†ä¸€æ¡æ‘†è„±æœ‰é™èŒƒå›´å¹¶æœç€çœŸæ­£é€šç”¨è§†é¢‘æ£€ç´¢å‘å±•çš„å®ç”¨è·¯å¾„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰è§†é¢‘æ£€ç´¢æ–¹æ³•é€šå¸¸åœ¨ç‰¹å®šæ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ï¼Œå¯¼è‡´æ¨¡å‹åœ¨é¢å¯¹æ–°çš„ã€æœªè§è¿‡çš„æ•°æ®é›†æ—¶è¡¨ç°ä¸ä½³ï¼Œç¼ºä¹é€šç”¨æ€§ã€‚æµè¡Œçš„åŸºå‡†æµ‹è¯•æ— æ³•å‡†ç¡®é¢„æµ‹æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶ä¸”å¿½ç•¥äº†éƒ¨åˆ†ç›¸å…³æ£€ç´¢è¿™ä¸€é‡è¦åœºæ™¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ååŒè®¾è®¡è¯„ä¼°åŸºå‡†ã€æ•°æ®åˆæˆå’Œæ¨¡å‹è®­ç»ƒï¼Œä»è€Œæå‡è§†é¢‘æ£€ç´¢æ¨¡å‹çš„é€šç”¨æ€§ã€‚å…·ä½“æ¥è¯´ï¼Œé¦–å…ˆæ„å»ºä¸€ä¸ªåŒ…å«å¤šä¸ªæ•°æ®é›†çš„é€šç”¨è§†é¢‘æ£€ç´¢åŸºå‡†ï¼Œç”¨äºè¯Šæ–­æ¨¡å‹åœ¨ä¸åŒä»»åŠ¡å’Œé¢†åŸŸçš„èƒ½åŠ›å·®è·ã€‚ç„¶åï¼Œé€šè¿‡åˆæˆé«˜è´¨é‡çš„æ•°æ®æ¥æ‰©å……è®­ç»ƒé›†ï¼Œå¹¶è®¾è®¡æ¨¡æ€é‡‘å­—å¡”è¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼Œå¼•å¯¼æ¨¡å‹å­¦ä¹ ä¸åŒæ¨¡æ€ä¹‹é—´çš„å…³è”ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…å«ä¸‰ä¸ªä¸»è¦ç»„æˆéƒ¨åˆ†ï¼šé€šç”¨è§†é¢‘æ£€ç´¢åŸºå‡†ï¼ˆUVRBï¼‰ã€æ•°æ®åˆæˆå·¥ä½œæµç¨‹å’Œæ¨¡æ€é‡‘å­—å¡”è¯¾ç¨‹å­¦ä¹ ã€‚UVRBåŒ…å«16ä¸ªæ•°æ®é›†ï¼Œæ¶µç›–ä¸åŒçš„ä»»åŠ¡å’Œé¢†åŸŸã€‚æ•°æ®åˆæˆå·¥ä½œæµç¨‹ç”¨äºç”Ÿæˆé«˜è´¨é‡çš„è§†é¢‘-æ–‡æœ¬pairï¼Œä»¥æ‰©å……è®­ç»ƒæ•°æ®ã€‚æ¨¡æ€é‡‘å­—å¡”è¯¾ç¨‹å­¦ä¹ ç­–ç•¥åˆ™ç”¨äºæŒ‡å¯¼æ¨¡å‹å­¦ä¹ ä¸åŒæ¨¡æ€ä¹‹é—´çš„å…³è”ï¼Œä»è€Œæå‡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ä¸ªååŒè®¾è®¡çš„æ¡†æ¶ï¼Œå°†è¯„ä¼°åŸºå‡†ã€æ•°æ®åˆæˆå’Œæ¨¡å‹è®­ç»ƒæœ‰æœºåœ°ç»“åˆèµ·æ¥ã€‚é€šè¿‡UVRBè¯Šæ–­æ¨¡å‹çš„èƒ½åŠ›å·®è·ï¼Œå¹¶åˆ©ç”¨åˆæˆæ•°æ®å’Œæ¨¡æ€é‡‘å­—å¡”è¯¾ç¨‹å­¦ä¹ æ¥å¼¥è¡¥è¿™äº›å·®è·ï¼Œä»è€Œæå‡æ¨¡å‹çš„é€šç”¨æ€§ã€‚æ­¤å¤–ï¼Œè¯¥è®ºæ–‡è¿˜å¼ºè°ƒäº†éƒ¨åˆ†ç›¸å…³æ£€ç´¢çš„é‡è¦æ€§ï¼Œå¹¶å°†å…¶çº³å…¥è¯„ä¼°æŒ‡æ ‡ä¸­ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡æ€é‡‘å­—å¡”è¯¾ç¨‹å­¦ä¹ ç­–ç•¥æ˜¯è¯¥æ¡†æ¶çš„å…³é”®è®¾è®¡ä¹‹ä¸€ã€‚è¯¥ç­–ç•¥é€šè¿‡é€æ­¥å¢åŠ è®­ç»ƒæ•°æ®çš„éš¾åº¦ï¼Œå¼•å¯¼æ¨¡å‹å­¦ä¹ ä¸åŒæ¨¡æ€ä¹‹é—´çš„å…³è”ã€‚å…·ä½“æ¥è¯´ï¼Œé¦–å…ˆä½¿ç”¨å•æ¨¡æ€æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œç„¶åé€æ­¥å¼•å…¥å¤šæ¨¡æ€æ•°æ®ï¼Œå¹¶è°ƒæ•´ä¸åŒæ¨¡æ€ä¹‹é—´çš„æƒé‡ã€‚æ­¤å¤–ï¼Œè¯¥è®ºæ–‡è¿˜ä½¿ç”¨äº†å¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°ï¼Œé¼“åŠ±æ¨¡å‹å­¦ä¹ è§†é¢‘å’Œæ–‡æœ¬ä¹‹é—´çš„ç›¸ä¼¼æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒGVEåœ¨UVRBä¸Šå®ç°äº†æœ€å…ˆè¿›çš„é›¶æ ·æœ¬æ³›åŒ–æ€§èƒ½ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰çš„è§†é¢‘æ£€ç´¢æ¨¡å‹ã€‚åˆ†æè¡¨æ˜ï¼Œæµè¡Œçš„åŸºå‡†æµ‹è¯•ä¸èƒ½å¾ˆå¥½åœ°é¢„æµ‹é€šç”¨èƒ½åŠ›ï¼Œå¹¶ä¸”éƒ¨åˆ†ç›¸å…³çš„æ£€ç´¢æ˜¯ä¸€ç§ä¸»è¦çš„ä½†è¢«å¿½è§†çš„åœºæ™¯ã€‚GVEåœ¨UVRBä¸Šçš„è¡¨ç°è¯æ˜äº†è¯¥æ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§è§†é¢‘æ£€ç´¢åœºæ™¯ï¼Œä¾‹å¦‚è§†é¢‘æœç´¢å¼•æ“ã€è§†é¢‘æ¨èç³»ç»Ÿã€è§†é¢‘å†…å®¹åˆ†æç­‰ã€‚é€šè¿‡æå‡è§†é¢‘æ£€ç´¢æ¨¡å‹çš„é€šç”¨æ€§ï¼Œå¯ä»¥æ›´å¥½åœ°æ»¡è¶³ç”¨æˆ·åœ¨ä¸åŒé¢†åŸŸå’Œä»»åŠ¡ä¸­çš„æ£€ç´¢éœ€æ±‚ï¼Œæé«˜æ£€ç´¢æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚è¯¥ç ”ç©¶è¿˜æœ‰åŠ©äºæ¨åŠ¨è§†é¢‘ç†è§£å’Œå¤šæ¨¡æ€å­¦ä¹ é¢†åŸŸçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The prevailing video retrieval paradigm is structurally misaligned, as narrow benchmarks incentivize correspondingly limited data and single-task training. Therefore, universal capability is suppressed due to the absence of a diagnostic evaluation that defines and demands multi-dimensional generalization. To break this cycle, we introduce a framework built on the co-design of evaluation, data, and modeling. First, we establish the Universal Video Retrieval Benchmark (UVRB), a suite of 16 datasets designed not only to measure performance but also to diagnose critical capability gaps across tasks and domains. Second, guided by UVRB's diagnostics, we introduce a scalable synthesis workflow that generates 1.55 million high-quality pairs to populate the semantic space required for universality. Finally, we devise the Modality Pyramid, a curriculum that trains our General Video Embedder (GVE) by explicitly leveraging the latent interconnections within our diverse data. Extensive experiments show GVE achieves state-of-the-art zero-shot generalization on UVRB. In particular, our analysis reveals that popular benchmarks are poor predictors of general ability and that partially relevant retrieval is a dominant but overlooked scenario. Overall, our co-designed framework provides a practical path to escape the limited scope and advance toward truly universal video retrieval.

