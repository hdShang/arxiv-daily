---
layout: default
title: NAUTILUS: A Large Multimodal Model for Underwater Scene Understanding
---

# NAUTILUS: A Large Multimodal Model for Underwater Scene Understanding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.27481" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.27481v1</a>
  <a href="https://arxiv.org/pdf/2510.27481.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.27481v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.27481v1', 'NAUTILUS: A Large Multimodal Model for Underwater Scene Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wei Xu, Cheng Wang, Dingkang Liang, Zongchuang Zhao, Xingyu Jiang, Peng Zhang, Xiang Bai

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-31

**å¤‡æ³¨**: Accepted to NeurIPS 2025. Data and models are available at https://github.com/H-EmbodVis/NAUTILUS

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/H-EmbodVis/NAUTILUS)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**NAUTILUSï¼šç”¨äºæ°´ä¸‹åœºæ™¯ç†è§£çš„å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ï¼Œæå‡æ°´ä¸‹ä»»åŠ¡é²æ£’æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ°´ä¸‹åœºæ™¯ç†è§£` `å¤šæ¨¡æ€æ¨¡å‹` `è§†è§‰ç‰¹å¾å¢å¼º` `æ°´ä¸‹å›¾åƒå¤„ç†` `å¤§å‹è¯­è¨€æ¨¡å‹` `æŒ‡ä»¤è°ƒä¼˜` `æ•°æ®é›†æ„å»º` `ç‰©ç†å…ˆéªŒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ°´ä¸‹åœºæ™¯ç†è§£é¢ä¸´ç¼ºä¹å¤§è§„æ¨¡å¤šä»»åŠ¡æ•°æ®é›†çš„æŒ‘æˆ˜ï¼Œé™åˆ¶äº†ç›¸å…³ç ”ç©¶çš„è¿›å±•ã€‚
2. è®ºæ–‡æå‡ºNAUTILUSï¼Œé€šè¿‡æ„å»ºNautDataæ•°æ®é›†å’Œå¼•å…¥è§†è§‰ç‰¹å¾å¢å¼ºæ¨¡å—VFEæ¥æå‡æ°´ä¸‹åœºæ™¯ç†è§£çš„é²æ£’æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒVFEæ¨¡å—èƒ½æœ‰æ•ˆæå‡LLaVA-1.5å’ŒQwen2.5-VLåœ¨æ°´ä¸‹ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼ŒéªŒè¯äº†NAUTILUSçš„ä¼˜è¶Šæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ°´ä¸‹æ¢ç´¢ä¸ºæˆ‘ä»¬æ˜Ÿçƒæä¾›äº†é‡è¦çš„è§è§£ï¼Œå¹¶åœ¨èµ„æºå‹˜æ¢ã€å›½å®¶å®‰å…¨ç­‰é¢†åŸŸå¼•èµ·äº†è¶Šæ¥è¶Šå¤šçš„å…³æ³¨ã€‚æœ¬æ–‡ç ”ç©¶äº†æ°´ä¸‹åœºæ™¯ç†è§£æ–¹æ³•ï¼Œæ—¨åœ¨å®ç°è‡ªåŠ¨æ°´ä¸‹æ¢ç´¢ã€‚æ°´ä¸‹åœºæ™¯ç†è§£ä»»åŠ¡éœ€è¦å¤šç²’åº¦çš„å¤šä»»åŠ¡æ„ŸçŸ¥ã€‚ç„¶è€Œï¼Œç¼ºä¹å¤§è§„æ¨¡çš„æ°´ä¸‹å¤šä»»åŠ¡æŒ‡ä»¤è°ƒä¼˜æ•°æ®é›†é˜»ç¢äº†è¿™é¡¹ç ”ç©¶çš„è¿›å±•ã€‚ä¸ºäº†å¼¥åˆè¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æ„å»ºäº†NautDataï¼Œä¸€ä¸ªåŒ…å«145ä¸‡ä¸ªå›¾åƒ-æ–‡æœ¬å¯¹çš„æ•°æ®é›†ï¼Œæ”¯æŒå…«ä¸ªæ°´ä¸‹åœºæ™¯ç†è§£ä»»åŠ¡ï¼Œä»è€Œèƒ½å¤Ÿå¼€å‘å’Œå…¨é¢è¯„ä¼°æ°´ä¸‹åœºæ™¯ç†è§£æ¨¡å‹ã€‚æ°´ä¸‹å›¾åƒé€€åŒ–æ˜¯ä¸€ä¸ªå…¬è®¤çš„æŒ‘æˆ˜ï¼Œå®ƒå¹²æ‰°äº†æ°´ä¸‹ä»»åŠ¡ã€‚ä¸ºäº†æé«˜æ°´ä¸‹åœºæ™¯ç†è§£çš„é²æ£’æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†æºè‡ªæ°´ä¸‹æˆåƒæ¨¡å‹çš„ç‰©ç†å…ˆéªŒï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªå³æ’å³ç”¨çš„è§†è§‰ç‰¹å¾å¢å¼ºï¼ˆVFEï¼‰æ¨¡å—ï¼Œè¯¥æ¨¡å—æ˜¾å¼åœ°æ¢å¤æ¸…æ™°çš„æ°´ä¸‹ä¿¡æ¯ã€‚æˆ‘ä»¬å°†æ­¤æ¨¡å—é›†æˆåˆ°è‘—åçš„åŸºçº¿LLaVA-1.5å’ŒQwen2.5-VLä¸­ï¼Œå¹¶æ„å»ºäº†æˆ‘ä»¬çš„æ°´ä¸‹LMMï¼ŒNAUTILUSã€‚åœ¨NautDataå’Œå…¬å…±æ°´ä¸‹æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼ŒVFEæ¨¡å—çš„æœ‰æ•ˆæ€§ï¼Œå§‹ç»ˆå¦‚ä¸€åœ°æé«˜äº†ä¸¤ä¸ªåŸºçº¿åœ¨å¤§å¤šæ•°æ”¯æŒä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œä»è€Œç¡®ä¿äº†NAUTILUSåœ¨æ°´ä¸‹åœºæ™¯ç†è§£é¢†åŸŸçš„ä¼˜è¶Šæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæ°´ä¸‹åœºæ™¯ç†è§£ä»»åŠ¡éœ€è¦å¤šç²’åº¦çš„å¤šä»»åŠ¡æ„ŸçŸ¥èƒ½åŠ›ï¼Œä½†ç°æœ‰æ–¹æ³•å—é™äºç¼ºä¹å¤§è§„æ¨¡æ°´ä¸‹å¤šä»»åŠ¡æŒ‡ä»¤è°ƒä¼˜æ•°æ®é›†ï¼Œå¹¶ä¸”æ°´ä¸‹å›¾åƒè´¨é‡å·®ï¼Œå­˜åœ¨ä¸¥é‡çš„å›¾åƒé€€åŒ–é—®é¢˜ï¼Œå½±å“äº†æ¨¡å‹çš„æ€§èƒ½å’Œé²æ£’æ€§ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆåˆ©ç”¨æ°´ä¸‹æˆåƒçš„ç‰©ç†å…ˆéªŒçŸ¥è¯†æ¥æå‡å›¾åƒè´¨é‡å’Œç‰¹å¾è¡¨è¾¾ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªå¤§è§„æ¨¡çš„æ°´ä¸‹å¤šä»»åŠ¡æ•°æ®é›†NautDataï¼Œå¹¶è®¾è®¡ä¸€ä¸ªå³æ’å³ç”¨çš„è§†è§‰ç‰¹å¾å¢å¼ºï¼ˆVFEï¼‰æ¨¡å—ï¼Œåˆ©ç”¨æ°´ä¸‹æˆåƒçš„ç‰©ç†å…ˆéªŒçŸ¥è¯†æ¥æ¢å¤æ¸…æ™°çš„æ°´ä¸‹ä¿¡æ¯ï¼Œä»è€Œæé«˜æ°´ä¸‹åœºæ™¯ç†è§£æ¨¡å‹çš„æ€§èƒ½å’Œé²æ£’æ€§ã€‚é€šè¿‡å°†VFEæ¨¡å—é›†æˆåˆ°ç°æœ‰çš„LLMä¸­ï¼Œå¯ä»¥æœ‰æ•ˆæå‡æ¨¡å‹åœ¨æ°´ä¸‹ç¯å¢ƒä¸‹çš„è¡¨ç°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šNAUTILUSçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬æ•°æ®æ„å»ºå’Œæ¨¡å‹æ„å»ºä¸¤éƒ¨åˆ†ã€‚é¦–å…ˆï¼Œæ„å»ºåŒ…å«145ä¸‡å›¾åƒ-æ–‡æœ¬å¯¹çš„NautDataæ•°æ®é›†ï¼Œæ”¯æŒå…«ä¸ªæ°´ä¸‹åœºæ™¯ç†è§£ä»»åŠ¡ã€‚ç„¶åï¼Œè®¾è®¡VFEæ¨¡å—ï¼Œè¯¥æ¨¡å—åˆ©ç”¨æ°´ä¸‹æˆåƒæ¨¡å‹ä¸­çš„ç‰©ç†å…ˆéªŒçŸ¥è¯†æ¥å¢å¼ºè§†è§‰ç‰¹å¾ã€‚æœ€åï¼Œå°†VFEæ¨¡å—é›†æˆåˆ°LLaVA-1.5å’ŒQwen2.5-VLç­‰å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ä¸­ï¼Œè¿›è¡ŒæŒ‡ä»¤è°ƒä¼˜ï¼Œå¾—åˆ°NAUTILUSæ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æ„å»ºäº†å¤§è§„æ¨¡çš„æ°´ä¸‹å¤šä»»åŠ¡æ•°æ®é›†NautDataï¼Œä¸ºæ°´ä¸‹åœºæ™¯ç†è§£ç ”ç©¶æä¾›äº†æ•°æ®åŸºç¡€ã€‚2) æå‡ºäº†VFEæ¨¡å—ï¼Œè¯¥æ¨¡å—åˆ©ç”¨æ°´ä¸‹æˆåƒçš„ç‰©ç†å…ˆéªŒçŸ¥è¯†æ¥æ˜¾å¼åœ°æ¢å¤æ¸…æ™°çš„æ°´ä¸‹ä¿¡æ¯ï¼Œä»è€Œæé«˜äº†æ¨¡å‹çš„é²æ£’æ€§ã€‚3) å°†VFEæ¨¡å—ä»¥å³æ’å³ç”¨çš„æ–¹å¼é›†æˆåˆ°ç°æœ‰çš„å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ä¸­ï¼Œå®ç°äº†æ°´ä¸‹åœºæ™¯ç†è§£èƒ½åŠ›çš„æå‡ã€‚

**å…³é”®è®¾è®¡**ï¼šVFEæ¨¡å—çš„å…³é”®è®¾è®¡åœ¨äºåˆ©ç”¨æ°´ä¸‹æˆåƒæ¨¡å‹ä¸­çš„è¡°å‡ç³»æ•°ã€æ•£å°„å…‰ç­‰ç‰©ç†å‚æ•°ä½œä¸ºå…ˆéªŒçŸ¥è¯†ï¼Œé€šè¿‡ç‰¹å®šçš„ç½‘ç»œç»“æ„æ¥ä¼°è®¡å’Œè¡¥å¿å›¾åƒä¸­çš„é€€åŒ–æ•ˆåº”ã€‚å…·ä½“å®ç°ç»†èŠ‚ï¼ˆå¦‚ç½‘ç»œç»“æ„ã€æŸå¤±å‡½æ•°ç­‰ï¼‰åœ¨è®ºæ–‡ä¸­æœªè¯¦ç»†æè¿°ï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚NautDataæ•°æ®é›†çš„æ„å»ºç»†èŠ‚ï¼ŒåŒ…æ‹¬æ•°æ®å¢å¼ºæ–¹æ³•å’Œä»»åŠ¡å®šä¹‰ï¼Œä¹Ÿéœ€è¦å‚è€ƒè®ºæ–‡åŸæ–‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒVFEæ¨¡å—èƒ½å¤Ÿæ˜¾è‘—æå‡LLaVA-1.5å’ŒQwen2.5-VLåœ¨NautDataå’Œå…¬å…±æ°´ä¸‹æ•°æ®é›†ä¸Šçš„æ€§èƒ½ã€‚åœ¨å¤§å¤šæ•°æ”¯æŒçš„ä»»åŠ¡ä¸Šï¼ŒVFEæ¨¡å—éƒ½å¸¦æ¥äº†æ€§èƒ½æå‡ï¼ŒéªŒè¯äº†NAUTILUSåœ¨æ°´ä¸‹åœºæ™¯ç†è§£æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚å…·ä½“çš„æ€§èƒ½æå‡å¹…åº¦éœ€è¦å‚è€ƒè®ºæ–‡ä¸­çš„å®éªŒæ•°æ®ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

NAUTILUSåœ¨æ°´ä¸‹æœºå™¨äººã€æ°´ä¸‹èµ„æºå‹˜æ¢ã€æµ·æ´‹ç¯å¢ƒç›‘æµ‹ã€æ°´ä¸‹è€ƒå¤ã€æ°´ä¸‹æœæ•‘ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚è¯¥ç ”ç©¶å¯ä»¥å¸®åŠ©å®ç°è‡ªåŠ¨åŒ–çš„æ°´ä¸‹æ¢ç´¢å’Œä½œä¸šï¼Œæé«˜æ°´ä¸‹ä»»åŠ¡çš„æ•ˆç‡å’Œå®‰å…¨æ€§ï¼Œå¹¶ä¸ºæµ·æ´‹ç§‘å­¦ç ”ç©¶æä¾›æ›´å¼ºå¤§çš„å·¥å…·ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Underwater exploration offers critical insights into our planet and attracts increasing attention for its broader applications in resource exploration, national security, etc. We study the underwater scene understanding methods, which aim to achieve automated underwater exploration. The underwater scene understanding task demands multi-task perceptions from multiple granularities. However, the absence of large-scale underwater multi-task instruction-tuning datasets hinders the progress of this research. To bridge this gap, we construct NautData, a dataset containing 1.45 M image-text pairs supporting eight underwater scene understanding tasks. It enables the development and thorough evaluation of the underwater scene understanding models. Underwater image degradation is a widely recognized challenge that interferes with underwater tasks. To improve the robustness of underwater scene understanding, we introduce physical priors derived from underwater imaging models and propose a plug-and-play vision feature enhancement (VFE) module, which explicitly restores clear underwater information. We integrate this module into renowned baselines LLaVA-1.5 and Qwen2.5-VL and build our underwater LMM, NAUTILUS. Experiments conducted on the NautData and public underwater datasets demonstrate the effectiveness of the VFE module, consistently improving the performance of both baselines on the majority of supported tasks, thus ensuring the superiority of NAUTILUS in the underwater scene understanding area. Data and models are available at https://github.com/H-EmbodVis/NAUTILUS.

