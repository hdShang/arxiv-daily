---
layout: default
title: PA-FAS: Towards Interpretable and Generalizable Multimodal Face Anti-Spoofing via Path-Augmented Reinforcement Learning
---

# PA-FAS: Towards Interpretable and Generalizable Multimodal Face Anti-Spoofing via Path-Augmented Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.17927" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.17927v1</a>
  <a href="https://arxiv.org/pdf/2511.17927.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.17927v1" onclick="toggleFavorite(this, '2511.17927v1', 'PA-FAS: Towards Interpretable and Generalizable Multimodal Face Anti-Spoofing via Path-Augmented Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yingjie Ma, Xun Lin, Yong Xu, Weicheng Xie, Zitong Yu

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-22

**å¤‡æ³¨**: Accepted by AAAI 2026 (Oral)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPA-FASï¼Œé€šè¿‡è·¯å¾„å¢å¼ºå¼ºåŒ–å­¦ä¹ æå‡å¤šæ¨¡æ€äººè„¸åæ¬ºéª—çš„æ³›åŒ–æ€§å’Œå¯è§£é‡Šæ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `äººè„¸åæ¬ºéª—` `å¤šæ¨¡æ€èåˆ` `å¼ºåŒ–å­¦ä¹ ` `è·¯å¾„å¢å¼º` `è·¨åŸŸæ³›åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤šæ¨¡æ€äººè„¸åæ¬ºéª—ä¸­ï¼Œé¢ä¸´æ¨ç†è·¯å¾„å—é™å’Œå•ä»»åŠ¡ç›‘ç£ä¸å¤šæ ·æ¨ç†è·¯å¾„ä¸åŒ¹é…çš„é—®é¢˜ï¼Œå¯¼è‡´æ³›åŒ–æ€§å’Œå¯è§£é‡Šæ€§ä¸è¶³ã€‚
2. PA-FASé€šè¿‡æ„å»ºé«˜è´¨é‡çš„æ‰©å±•æ¨ç†åºåˆ—æ¥å¢å¼ºæ¨ç†è·¯å¾„ï¼Œå¹¶å¼•å…¥ç­”æ¡ˆæ´—ç‰Œæœºåˆ¶ï¼Œé¿å…æ¨¡å‹åˆ©ç”¨æ·å¾„ï¼Œä»è€Œæå‡æ¨ç†æ·±åº¦ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒPA-FASæ˜¾è‘—æé«˜äº†å¤šæ¨¡æ€æ¨ç†çš„å‡†ç¡®æ€§å’Œè·¨åŸŸæ³›åŒ–èƒ½åŠ›ï¼Œå®ç°äº†æ›´å¯ä¿¡èµ–çš„äººè„¸åæ¬ºéª—ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äººè„¸åæ¬ºéª—(FAS)è¿‘å¹´æ¥åœ¨å¤šæ¨¡æ€èåˆã€è·¨åŸŸæ³›åŒ–å’Œå¯è§£é‡Šæ€§æ–¹é¢å–å¾—äº†è¿›å±•ã€‚å€ŸåŠ©å¤§å‹è¯­è¨€æ¨¡å‹å’Œå¼ºåŒ–å­¦ä¹ (RL)ï¼ŒåŸºäºç­–ç•¥çš„è®­ç»ƒä¸ºè”åˆå»ºæ¨¡è¿™äº›æ–¹é¢æä¾›äº†æ–°çš„æœºä¼šã€‚ç„¶è€Œï¼Œå¤šæ¨¡æ€æ¨ç†æ¯”å•æ¨¡æ€æ¨ç†æ›´å¤æ‚ï¼Œéœ€è¦å‡†ç¡®çš„ç‰¹å¾è¡¨ç¤ºå’Œè·¨æ¨¡æ€éªŒè¯ï¼ŒåŒæ—¶é¢ä¸´é«˜è´¨é‡æ ‡æ³¨æ•°æ®ç¨€ç¼ºçš„é—®é¢˜ï¼Œè¿™ä½¿å¾—ç›´æ¥åº”ç”¨RLæ•ˆæœæ¬ ä½³ã€‚æˆ‘ä»¬å‘ç°ç›‘ç£å¾®è°ƒåŠ RL(SFT+RL)ç”¨äºå¤šæ¨¡æ€FASå­˜åœ¨ä¸¤ä¸ªå…³é”®é™åˆ¶ï¼š(1)æœ‰é™çš„å¤šæ¨¡æ€æ¨ç†è·¯å¾„é™åˆ¶äº†äº’è¡¥æ¨¡æ€çš„ä½¿ç”¨ï¼Œå¹¶ç¼©å°äº†SFTåçš„æ¢ç´¢ç©ºé—´ï¼Œå‰Šå¼±äº†RLçš„æ•ˆæœï¼›(2)å•ä»»åŠ¡ç›‘ç£ä¸å¤šæ ·åŒ–æ¨ç†è·¯å¾„ä¸åŒ¹é…å¯¼è‡´æ¨ç†æ··æ·†ï¼Œæ¨¡å‹å¯èƒ½åˆ©ç”¨æ·å¾„å°†å›¾åƒç›´æ¥æ˜ å°„åˆ°ç­”æ¡ˆï¼Œè€Œå¿½ç•¥äº†é¢„æœŸçš„æ¨ç†ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†PA-FASï¼Œå®ƒé€šè¿‡ä»æœ‰é™çš„æ ‡æ³¨ä¸­æ„å»ºé«˜è´¨é‡çš„æ‰©å±•æ¨ç†åºåˆ—æ¥å¢å¼ºæ¨ç†è·¯å¾„ï¼Œä¸°å¯Œè·¯å¾„å¹¶æ”¾æ¾æ¢ç´¢çº¦æŸã€‚æˆ‘ä»¬è¿›ä¸€æ­¥åœ¨SFTæœŸé—´å¼•å…¥äº†ä¸€ç§ç­”æ¡ˆæ´—ç‰Œæœºåˆ¶ï¼Œä»¥å¼ºåˆ¶è¿›è¡Œå…¨é¢çš„å¤šæ¨¡æ€åˆ†æï¼Œè€Œä¸æ˜¯ä½¿ç”¨è¡¨é¢çº¿ç´¢ï¼Œä»è€Œé¼“åŠ±æ›´æ·±å…¥çš„æ¨ç†å¹¶å‡è½»æ·å¾„å­¦ä¹ ã€‚PA-FASæ˜¾è‘—æé«˜äº†å¤šæ¨¡æ€æ¨ç†çš„å‡†ç¡®æ€§å’Œè·¨åŸŸæ³›åŒ–èƒ½åŠ›ï¼Œå¹¶æ›´å¥½åœ°ç»Ÿä¸€äº†å¤šæ¨¡æ€èåˆã€æ³›åŒ–å’Œå¯è§£é‡Šæ€§ï¼Œä»è€Œå®ç°å¯ä¿¡èµ–çš„FASã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€äººè„¸åæ¬ºéª—ä»»åŠ¡ä¸­ï¼Œç°æœ‰æ–¹æ³•ç”±äºæ¨ç†è·¯å¾„å—é™å’Œç›‘ç£æ–¹å¼ä¸å½“å¯¼è‡´çš„æ³›åŒ–èƒ½åŠ›å·®å’Œå¯è§£é‡Šæ€§ä½çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸é‡‡ç”¨ç›‘ç£å¾®è°ƒåŠ å¼ºåŒ–å­¦ä¹ (SFT+RL)çš„æ¡†æ¶ï¼Œä½†å­˜åœ¨ä¸¤ä¸ªç—›ç‚¹ï¼šä¸€æ˜¯å¤šæ¨¡æ€æ¨ç†è·¯å¾„æœ‰é™ï¼Œæ— æ³•å……åˆ†åˆ©ç”¨ä¸åŒæ¨¡æ€çš„äº’è¡¥ä¿¡æ¯ï¼›äºŒæ˜¯å•ä»»åŠ¡ç›‘ç£å®¹æ˜“å¯¼è‡´æ¨¡å‹å­¦ä¹ æ·å¾„ï¼Œå¿½ç•¥æ·±å±‚æ¨ç†è¿‡ç¨‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¢å¼ºæ¨ç†è·¯å¾„å’Œæ”¹è¿›ç›‘ç£æ–¹å¼æ¥æå‡æ¨¡å‹çš„æ¨ç†èƒ½åŠ›å’Œæ³›åŒ–èƒ½åŠ›ã€‚å…·ä½“æ¥è¯´ï¼Œé€šè¿‡æ„å»ºé«˜è´¨é‡çš„æ‰©å±•æ¨ç†åºåˆ—æ¥ä¸°å¯Œæ¨ç†è·¯å¾„ï¼Œå¹¶é‡‡ç”¨ç­”æ¡ˆæ´—ç‰Œæœºåˆ¶æ¥é¿å…æ¨¡å‹å­¦ä¹ æ·å¾„ï¼Œä»è€Œé¼“åŠ±æ¨¡å‹è¿›è¡Œæ›´æ·±å…¥çš„å¤šæ¨¡æ€åˆ†æã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPA-FASçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šé¦–å…ˆæ˜¯ç›‘ç£å¾®è°ƒ(SFT)é˜¶æ®µï¼Œè¯¥é˜¶æ®µä½¿ç”¨ç­”æ¡ˆæ´—ç‰Œæœºåˆ¶æ¥è®­ç»ƒæ¨¡å‹ï¼Œé¿å…æ¨¡å‹å­¦ä¹ æ·å¾„ã€‚ç„¶åæ˜¯å¼ºåŒ–å­¦ä¹ (RL)é˜¶æ®µï¼Œè¯¥é˜¶æ®µä½¿ç”¨å¢å¼ºçš„æ¨ç†è·¯å¾„æ¥è®­ç»ƒæ¨¡å‹ï¼Œé¼“åŠ±æ¨¡å‹è¿›è¡Œæ›´æ·±å…¥çš„å¤šæ¨¡æ€åˆ†æã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†è·¯å¾„å¢å¼ºå’Œç­”æ¡ˆæ´—ç‰Œä¸¤ç§æœºåˆ¶ã€‚è·¯å¾„å¢å¼ºé€šè¿‡æ„å»ºé«˜è´¨é‡çš„æ‰©å±•æ¨ç†åºåˆ—æ¥ä¸°å¯Œæ¨ç†è·¯å¾„ï¼Œä»è€Œæå‡æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚ç­”æ¡ˆæ´—ç‰Œé€šè¿‡éšæœºæ‰“ä¹±ç­”æ¡ˆçš„é¡ºåºæ¥é¿å…æ¨¡å‹å­¦ä¹ æ·å¾„ï¼Œä»è€Œé¼“åŠ±æ¨¡å‹è¿›è¡Œæ›´æ·±å…¥çš„å¤šæ¨¡æ€åˆ†æã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨SFTé˜¶æ®µï¼Œç­”æ¡ˆæ´—ç‰Œæœºåˆ¶é€šè¿‡éšæœºæ‰“ä¹±è®­ç»ƒæ ·æœ¬çš„ç­”æ¡ˆé¡ºåºï¼Œè¿«ä½¿æ¨¡å‹ä¸èƒ½ç®€å•åœ°å°†å›¾åƒæ˜ å°„åˆ°ç­”æ¡ˆï¼Œè€Œæ˜¯éœ€è¦è¿›è¡Œæ›´æ·±å…¥çš„å¤šæ¨¡æ€åˆ†æã€‚åœ¨RLé˜¶æ®µï¼Œè·¯å¾„å¢å¼ºé€šè¿‡æ„å»ºé«˜è´¨é‡çš„æ‰©å±•æ¨ç†åºåˆ—ï¼Œä¸ºæ¨¡å‹æä¾›æ›´å¤šçš„æ¢ç´¢ç©ºé—´ï¼Œä»è€Œæå‡æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ï¼ˆæœªçŸ¥ï¼‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

PA-FASåœ¨å¤šä¸ªäººè„¸åæ¬ºéª—æ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPA-FASä¸ä»…æé«˜äº†å¤šæ¨¡æ€æ¨ç†çš„å‡†ç¡®æ€§ï¼Œè¿˜æ˜¾è‘—æå‡äº†è·¨åŸŸæ³›åŒ–èƒ½åŠ›ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ï¼ˆæœªçŸ¥ï¼‰ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºèº«ä»½éªŒè¯ã€è®¿é—®æ§åˆ¶ã€é‡‘èå®‰å…¨ç­‰é¢†åŸŸï¼Œæœ‰æ•ˆé˜²å¾¡åŸºäºäººè„¸æ¬ºéª—çš„æ”»å‡»ï¼Œæå‡ç³»ç»Ÿçš„å®‰å…¨æ€§ä¸å¯é æ€§ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æ‰©å±•åˆ°æ›´å¤šæ¨¡æ€å’Œæ›´å¤æ‚çš„åæ¬ºéª—åœºæ™¯ï¼Œä¾‹å¦‚è¯­éŸ³åæ¬ºéª—ã€è¡Œä¸ºåæ¬ºéª—ç­‰ï¼Œå…·æœ‰å¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Face anti-spoofing (FAS) has recently advanced in multimodal fusion, cross-domain generalization, and interpretability. With large language models and reinforcement learning (RL), strategy-based training offers new opportunities to jointly model these aspects. However, multimodal reasoning is more complex than unimodal reasoning, requiring accurate feature representation and cross-modal verification while facing scarce, high-quality annotations, which makes direct application of RL sub-optimal. We identify two key limitations of supervised fine-tuning plus RL (SFT+RL) for multimodal FAS: (1) limited multimodal reasoning paths restrict the use of complementary modalities and shrink the exploration space after SFT, weakening the effect of RL; and (2) mismatched single-task supervision versus diverse reasoning paths causes reasoning confusion, where models may exploit shortcuts by mapping images directly to answers and ignoring the intended reasoning. To address this, we propose PA-FAS, which enhances reasoning paths by constructing high-quality extended reasoning sequences from limited annotations, enriching paths and relaxing exploration constraints. We further introduce an answer-shuffling mechanism during SFT to force comprehensive multimodal analysis instead of using superficial cues, thereby encouraging deeper reasoning and mitigating shortcut learning. PA-FAS significantly improves multimodal reasoning accuracy and cross-domain generalization, and better unifies multimodal fusion, generalization, and interpretability for trustworthy FAS.

