---
layout: default
title: Plan-X: Instruct Video Generation via Semantic Planning
---

# Plan-X: Instruct Video Generation via Semantic Planning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.17986" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.17986v1</a>
  <a href="https://arxiv.org/pdf/2511.17986.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.17986v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.17986v1', 'Plan-X: Instruct Video Generation via Semantic Planning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Lun Huang, You Xie, Hongyi Xu, Tianpei Gu, Chenxu Zhang, Guoxian Song, Zenan Li, Xiaochen Zhao, Linjie Luo, Guillermo Sapiro

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-22

**å¤‡æ³¨**: The project page is at https://byteaigc.github.io/Plan-X

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Plan-Xé€šè¿‡è¯­ä¹‰è§„åˆ’æŒ‡å¯¼è§†é¢‘ç”Ÿæˆï¼Œæ˜¾è‘—å‡å°‘è§†è§‰å¹»è§‰å¹¶æå‡æŒ‡ä»¤å¯¹é½ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)** **æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction)**

**å…³é”®è¯**: `è§†é¢‘ç”Ÿæˆ` `è¯­ä¹‰è§„åˆ’` `æ‰©æ•£æ¨¡å‹` `å¤šæ¨¡æ€å­¦ä¹ ` `æŒ‡ä»¤å¯¹é½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†é¢‘ç”Ÿæˆæ¨¡å‹åœ¨é«˜å±‚æ¬¡è¯­ä¹‰æ¨ç†å’Œé•¿ç¨‹è§„åˆ’æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œæ˜“äº§ç”Ÿè§†è§‰å¹»è§‰å’ŒæŒ‡ä»¤ä¸å¯¹é½ã€‚
2. Plan-Xé€šè¿‡å¼•å…¥è¯­ä¹‰è§„åˆ’å™¨ï¼Œåˆ©ç”¨å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹ç”Ÿæˆæ—¶ç©ºè¯­ä¹‰tokenï¼ŒæŒ‡å¯¼è§†é¢‘æ‰©æ•£æ¨¡å‹ç”Ÿæˆã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒPlan-Xèƒ½æœ‰æ•ˆå‡å°‘è§†è§‰å¹»è§‰ï¼Œç”Ÿæˆä¸æŒ‡ä»¤å’Œå¤šæ¨¡æ€ä¸Šä¸‹æ–‡å¯¹é½çš„ç»†ç²’åº¦è§†é¢‘ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ‰©æ•£Transformeråœ¨è§†è§‰åˆæˆæ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„èƒ½åŠ›ï¼Œä½†å®ƒä»¬åœ¨é«˜å±‚æ¬¡è¯­ä¹‰æ¨ç†å’Œé•¿ç¨‹è§„åˆ’æ–¹é¢å¸¸å¸¸é‡åˆ°å›°éš¾ã€‚è¿™ç§å±€é™æ€§ç»å¸¸å¯¼è‡´è§†è§‰å¹»è§‰ä»¥åŠä¸ç”¨æˆ·æŒ‡ä»¤çš„ä¸å¯¹é½ï¼Œå°¤å…¶æ˜¯åœ¨æ¶‰åŠå¤æ‚åœºæ™¯ç†è§£ã€äºº-ç‰©äº¤äº’ã€å¤šé˜¶æ®µåŠ¨ä½œå’Œä¸Šä¸‹æ–‡è¿åŠ¨æ¨ç†çš„åœºæ™¯ä¸­ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†Plan-Xï¼Œä¸€ä¸ªæ˜¾å¼åœ°æ‰§è¡Œé«˜å±‚æ¬¡è¯­ä¹‰è§„åˆ’ä»¥æŒ‡å¯¼è§†é¢‘ç”Ÿæˆè¿‡ç¨‹çš„æ¡†æ¶ã€‚å…¶æ ¸å¿ƒæ˜¯ä¸€ä¸ªè¯­ä¹‰è§„åˆ’å™¨ï¼Œä¸€ä¸ªå¯å­¦ä¹ çš„å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹ï¼Œå®ƒåŸºäºæ–‡æœ¬æç¤ºå’Œè§†è§‰ä¸Šä¸‹æ–‡æ¥æ¨ç†ç”¨æˆ·çš„æ„å›¾ï¼Œå¹¶è‡ªå›å½’åœ°ç”Ÿæˆä¸€ç³»åˆ—æ–‡æœ¬ç›¸å…³çš„æ—¶ç©ºè¯­ä¹‰tokenã€‚è¿™äº›è¯­ä¹‰tokenä½œä¸ºé«˜å±‚æ¬¡æ–‡æœ¬æç¤ºæŒ‡å¯¼çš„è¡¥å……ï¼Œä¸ºè§†é¢‘æ‰©æ•£æ¨¡å‹æä¾›éšæ—¶é—´å˜åŒ–çš„ç»“æ„åŒ–â€œè¯­ä¹‰è‰å›¾â€ï¼Œè€Œè§†é¢‘æ‰©æ•£æ¨¡å‹æ“…é•¿åˆæˆé«˜ä¿çœŸè§†è§‰ç»†èŠ‚ã€‚Plan-Xæœ‰æ•ˆåœ°æ•´åˆäº†è¯­è¨€æ¨¡å‹åœ¨å¤šæ¨¡æ€ä¸Šä¸‹æ–‡æ¨ç†å’Œè§„åˆ’æ–¹é¢çš„ä¼˜åŠ¿ï¼Œä»¥åŠæ‰©æ•£æ¨¡å‹åœ¨ç…§ç‰‡çº§çœŸå®æ„Ÿè§†é¢‘åˆæˆæ–¹é¢çš„ä¼˜åŠ¿ã€‚å¤§é‡çš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¡†æ¶å¤§å¤§å‡å°‘äº†è§†è§‰å¹»è§‰ï¼Œå¹¶å®ç°äº†ä¸å¤šæ¨¡æ€ä¸Šä¸‹æ–‡ä¸€è‡´çš„ç»†ç²’åº¦ã€æŒ‡ä»¤å¯¹é½çš„è§†é¢‘ç”Ÿæˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰åŸºäºæ‰©æ•£Transformerçš„è§†é¢‘ç”Ÿæˆæ–¹æ³•åœ¨é«˜å±‚æ¬¡è¯­ä¹‰ç†è§£å’Œé•¿ç¨‹è§„åˆ’æ–¹é¢å­˜åœ¨å›°éš¾ï¼Œå¯¼è‡´ç”Ÿæˆçš„è§†é¢‘å†…å®¹ä¸ç”¨æˆ·æŒ‡ä»¤ä¸ç¬¦ï¼Œå®¹æ˜“å‡ºç°è§†è§‰å¹»è§‰ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚åœºæ™¯å’Œå¤šæ­¥éª¤åŠ¨ä½œä¸­ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹å¯¹è§†é¢‘å†…å®¹çš„æ—¶ç©ºç»“æ„åŒ–ç†è§£å’Œè§„åˆ’èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šPlan-Xçš„æ ¸å¿ƒæ€è·¯æ˜¯å¼•å…¥ä¸€ä¸ªè¯­ä¹‰è§„åˆ’å™¨ï¼Œè¯¥è§„åˆ’å™¨èƒ½å¤Ÿç†è§£ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬æç¤ºå’Œè§†è§‰ä¸Šä¸‹æ–‡ï¼Œå¹¶ç”Ÿæˆä¸€ç³»åˆ—æ—¶ç©ºè¯­ä¹‰tokenã€‚è¿™äº›tokenå¯ä»¥çœ‹ä½œæ˜¯å¯¹è§†é¢‘å†…å®¹çš„â€œè¯­ä¹‰è‰å›¾â€ï¼Œä¸ºåç»­çš„è§†é¢‘æ‰©æ•£æ¨¡å‹æä¾›ç»“æ„åŒ–çš„æŒ‡å¯¼ï¼Œä»è€Œä¿è¯ç”Ÿæˆè§†é¢‘çš„å†…å®¹ä¸ç”¨æˆ·æ„å›¾å¯¹é½ï¼Œå¹¶å‡å°‘è§†è§‰å¹»è§‰ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPlan-Xæ¡†æ¶ä¸»è¦åŒ…å«ä¸¤ä¸ªæ ¸å¿ƒæ¨¡å—ï¼šè¯­ä¹‰è§„åˆ’å™¨å’Œè§†é¢‘æ‰©æ•£æ¨¡å‹ã€‚è¯­ä¹‰è§„åˆ’å™¨æ˜¯ä¸€ä¸ªå¯å­¦ä¹ çš„å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹ï¼Œå®ƒæ¥æ”¶æ–‡æœ¬æç¤ºå’Œè§†è§‰ä¸Šä¸‹æ–‡ä½œä¸ºè¾“å…¥ï¼Œè‡ªå›å½’åœ°ç”Ÿæˆä¸€ç³»åˆ—æ—¶ç©ºè¯­ä¹‰tokenã€‚è¿™äº›tokenéšåè¢«è¾“å…¥åˆ°è§†é¢‘æ‰©æ•£æ¨¡å‹ä¸­ï¼Œä½œä¸ºé¢å¤–çš„æ¡ä»¶ä¿¡æ¯ï¼ŒæŒ‡å¯¼è§†é¢‘çš„ç”Ÿæˆè¿‡ç¨‹ã€‚è§†é¢‘æ‰©æ•£æ¨¡å‹è´Ÿè´£å°†è¿™äº›è¯­ä¹‰tokenè½¬åŒ–ä¸ºé«˜ä¿çœŸåº¦çš„è§†è§‰å†…å®¹ã€‚

**å…³é”®åˆ›æ–°**ï¼šPlan-Xçš„å…³é”®åˆ›æ–°åœ¨äºå¼•å…¥äº†è¯­ä¹‰è§„åˆ’å™¨ï¼Œå°†é«˜å±‚æ¬¡çš„è¯­ä¹‰æ¨ç†å’Œè§„åˆ’ä¸åº•å±‚çš„è§†è§‰åˆæˆè§£è€¦ã€‚è¯­ä¹‰è§„åˆ’å™¨è´Ÿè´£ç†è§£ç”¨æˆ·æ„å›¾å¹¶ç”Ÿæˆç»“æ„åŒ–çš„è¯­ä¹‰è¡¨ç¤ºï¼Œè€Œè§†é¢‘æ‰©æ•£æ¨¡å‹åˆ™è´Ÿè´£å°†è¿™äº›è¯­ä¹‰è¡¨ç¤ºè½¬åŒ–ä¸ºè§†è§‰å†…å®¹ã€‚è¿™ç§è§£è€¦ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°æ§åˆ¶è§†é¢‘çš„ç”Ÿæˆè¿‡ç¨‹ï¼Œå¹¶å‡å°‘è§†è§‰å¹»è§‰ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒPlan-Xèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ç”¨æˆ·æŒ‡ä»¤ï¼Œå¹¶ç”Ÿæˆä¸æŒ‡ä»¤å¯¹é½çš„è§†é¢‘å†…å®¹ã€‚

**å…³é”®è®¾è®¡**ï¼šè¯­ä¹‰è§„åˆ’å™¨é‡‡ç”¨Transformeræ¶æ„ï¼Œå¹¶ä½¿ç”¨å¤šæ¨¡æ€æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œä½¿å…¶èƒ½å¤Ÿç†è§£æ–‡æœ¬æç¤ºå’Œè§†è§‰ä¸Šä¸‹æ–‡ã€‚æ—¶ç©ºè¯­ä¹‰tokençš„è®¾è®¡éœ€è¦èƒ½å¤Ÿæœ‰æ•ˆåœ°è¡¨ç¤ºè§†é¢‘å†…å®¹çš„å…³é”®ä¿¡æ¯ï¼Œä¾‹å¦‚åœºæ™¯ä¸­çš„ç‰©ä½“ã€äººç‰©åŠ¨ä½œå’Œç‰©ä½“ä¹‹é—´çš„äº¤äº’å…³ç³»ã€‚è§†é¢‘æ‰©æ•£æ¨¡å‹å¯ä»¥ä½¿ç”¨ç°æœ‰çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œå¹¶è¿›è¡Œå¾®è°ƒï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨è¯­ä¹‰è§„åˆ’å™¨æä¾›çš„æ¡ä»¶ä¿¡æ¯ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡éœ€è¦èƒ½å¤Ÿä¿è¯ç”Ÿæˆçš„è§†é¢‘å†…å®¹ä¸ç”¨æˆ·æŒ‡ä»¤å¯¹é½ï¼Œå¹¶å…·æœ‰è¾ƒé«˜çš„è§†è§‰è´¨é‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒPlan-Xåœ¨è§†é¢‘ç”Ÿæˆè´¨é‡å’ŒæŒ‡ä»¤å¯¹é½æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚é€šè¿‡å®šé‡è¯„ä¼°å’Œäººå·¥è¯„ä¼°ï¼ŒPlan-Xæ˜¾è‘—å‡å°‘äº†è§†è§‰å¹»è§‰ï¼Œå¹¶ç”Ÿæˆäº†ä¸ç”¨æˆ·æŒ‡ä»¤æ›´åŠ ä¸€è‡´çš„è§†é¢‘å†…å®¹ã€‚ä¾‹å¦‚ï¼Œåœ¨å¤æ‚åœºæ™¯å’Œå¤šæ­¥éª¤åŠ¨ä½œçš„ç”Ÿæˆä»»åŠ¡ä¸­ï¼ŒPlan-Xçš„æ€§èƒ½æå‡å°¤ä¸ºæ˜æ˜¾ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Plan-Xå¯åº”ç”¨äºå¤šç§è§†é¢‘ç”Ÿæˆåœºæ™¯ï¼Œä¾‹å¦‚æ ¹æ®æ–‡æœ¬æè¿°ç”Ÿæˆç”µå½±ç‰‡æ®µã€æ ¹æ®æ•…äº‹æ¢—æ¦‚ç”ŸæˆåŠ¨ç”»çŸ­ç‰‡ã€æ ¹æ®ç”¨æˆ·æŒ‡ä»¤ç¼–è¾‘ç°æœ‰è§†é¢‘ç­‰ã€‚è¯¥æŠ€æœ¯åœ¨å¨±ä¹ã€æ•™è‚²ã€å¹¿å‘Šç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œèƒ½å¤Ÿé™ä½è§†é¢‘åˆ¶ä½œçš„é—¨æ§›ï¼Œå¹¶æé«˜è§†é¢‘å†…å®¹çš„åˆ›ä½œæ•ˆç‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Diffusion Transformers have demonstrated remarkable capabilities in visual synthesis, yet they often struggle with high-level semantic reasoning and long-horizon planning. This limitation frequently leads to visual hallucinations and mis-alignments with user instructions, especially in scenarios involving complex scene understanding, human-object interactions, multi-stage actions, and in-context motion reasoning. To address these challenges, we propose Plan-X, a framework that explicitly enforces high-level semantic planning to instruct video generation process. At its core lies a Semantic Planner, a learnable multimodal language model that reasons over the user's intent from both text prompts and visual context, and autoregressively generates a sequence of text-grounded spatio-temporal semantic tokens. These semantic tokens, complementary to high-level text prompt guidance, serve as structured "semantic sketches" over time for the video diffusion model, which has its strength at synthesizing high-fidelity visual details. Plan-X effectively integrates the strength of language models in multimodal in-context reasoning and planning, together with the strength of diffusion models in photorealistic video synthesis. Extensive experiments demonstrate that our framework substantially reduces visual hallucinations and enables fine-grained, instruction-aligned video generation consistent with multimodal context.

