---
layout: default
title: ActDistill: General Action-Guided Self-Derived Distillation for Efficient Vision-Language-Action Models
---

# ActDistill: General Action-Guided Self-Derived Distillation for Efficient Vision-Language-Action Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.18082" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.18082v1</a>
  <a href="https://arxiv.org/pdf/2511.18082.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.18082v1" onclick="toggleFavorite(this, '2511.18082v1', 'ActDistill: General Action-Guided Self-Derived Distillation for Efficient Vision-Language-Action Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wencheng Ye, Tianshi Wang, Lei Zhu, Fengling Li, Guoli Yang

**åˆ†ç±»**: cs.CV, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-11-22

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ActDistillï¼šé¢å‘é«˜æ•ˆVLAæ¨¡å‹çš„åŠ¨ä½œå¼•å¯¼è‡ªè’¸é¦æ¡†æ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹` `æ¨¡å‹è’¸é¦` `çŸ¥è¯†è¿ç§»` `åŠ¨ä½œå¼•å¯¼` `åŠ¨æ€è·¯ç”±`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„VLAæ¨¡å‹è®¡ç®—å¼€é”€å¤§ã€æ¨ç†å»¶è¿Ÿé«˜ï¼Œéš¾ä»¥éƒ¨ç½²äºæœºå™¨äººæ“ä½œç­‰å®é™…åœºæ™¯ã€‚
2. ActDistillåˆ©ç”¨åŠ¨ä½œå…ˆéªŒå¼•å¯¼çŸ¥è¯†è¿ç§»å’Œæ¨¡å‹å‹ç¼©ï¼Œå°†å¤§å‹VLAæ¨¡å‹çš„åŠ¨ä½œé¢„æµ‹èƒ½åŠ›è¿ç§»åˆ°è½»é‡çº§æ¨¡å‹ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒActDistillåœ¨æ˜¾è‘—é™ä½è®¡ç®—é‡å’Œæ¨ç†å»¶è¿Ÿçš„åŒæ—¶ï¼Œä¿æŒç”šè‡³æå‡äº†VLAæ¨¡å‹çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºActDistillï¼Œä¸€ç§é€šç”¨çš„åŠ¨ä½œå¼•å¯¼è‡ªè’¸é¦æ¡†æ¶ï¼Œæ—¨åœ¨å°†ç°æœ‰è§†è§‰-è¯­è¨€-åŠ¨ä½œ(VLA)æ¨¡å‹çš„åŠ¨ä½œé¢„æµ‹èƒ½åŠ›è¿ç§»åˆ°è½»é‡çº§æ¨¡å‹ï¼Œä»è€Œé™ä½è®¡ç®—å¼€é”€å’Œæ¨ç†å»¶è¿Ÿã€‚ä¸ä»¥å¾€ä¾§é‡è§†è§‰-è¯­è¨€ç›¸å…³æ€§çš„æ•ˆç‡ç­–ç•¥ä¸åŒï¼ŒActDistillåˆ©ç”¨åŠ¨ä½œå…ˆéªŒæ¥æŒ‡å¯¼çŸ¥è¯†è¿ç§»å’Œæ¨¡å‹å‹ç¼©ï¼Œå®ç°VLAæ¨¡å‹é¢å‘åŠ¨ä½œçš„æ•ˆç‡æå‡ã€‚å…·ä½“è€Œè¨€ï¼Œè¯¥æ–¹æ³•ä½¿ç”¨è®­ç»ƒå¥½çš„VLAæ¨¡å‹ä½œä¸ºæ•™å¸ˆï¼Œå¹¶å¼•å…¥å›¾ç»“æ„å°è£…ç­–ç•¥æ¥æ˜¾å¼å»ºæ¨¡åŠ¨ä½œé¢„æµ‹çš„å±‚çº§æ¼”åŒ–ã€‚ä»å›¾å°è£…çš„æ•™å¸ˆæ¨¡å‹æ´¾ç”Ÿå‡ºçš„å­¦ç”Ÿæ¨¡å‹ï¼Œé…å¤‡äº†åŠ¨æ€è·¯ç”±ï¼Œå¯ä»¥æ ¹æ®åŠ¨ä½œé¢„æµ‹éœ€æ±‚è‡ªé€‚åº”åœ°é€‰æ‹©è®¡ç®—è·¯å¾„ï¼Œå¹¶åœ¨å±‚çº§å›¾ä¿¡æ¯çš„ç›‘ç£ä¸‹å¹³æ»‘é«˜æ•ˆåœ°æ¼”åŒ–ã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œç§»é™¤å›¾ç›¸å…³çš„è¾…åŠ©ç»„ä»¶ï¼Œå­¦ç”Ÿæ¨¡å‹ä»…æ‰§è¡ŒåŠ¨æ€è·¯ç”±çš„å±‚ï¼Œä»¥æœ€å°çš„è®¡ç®—å’Œå»¶è¿Ÿé¢„æµ‹é«˜ç²¾åº¦åŠ¨ä½œã€‚åœ¨å…·èº«æ™ºèƒ½åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒActDistillåœ¨è®¡ç®—é‡å‡å°‘50%ä»¥ä¸Šï¼Œé€Ÿåº¦æå‡é«˜è¾¾1.67å€çš„æƒ…å†µä¸‹ï¼Œå®ç°äº†ä¸å…¨å°ºå¯¸VLAæ¨¡å‹ç›¸å½“ç”šè‡³æ›´ä¼˜çš„æ€§èƒ½ï¼Œä»è€Œä¸ºé«˜æ•ˆå…·èº«æ™ºèƒ½å»ºç«‹äº†ä¸€ä¸ªé€šç”¨èŒƒä¾‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰è§†è§‰-è¯­è¨€-åŠ¨ä½œ(VLA)æ¨¡å‹è™½ç„¶å±•ç°å‡ºå¼ºå¤§çš„çµæ´»æ€§å’Œæ³›åŒ–èƒ½åŠ›ï¼Œä½†å…¶åºå¤§çš„è®¡ç®—å¼€é”€å’Œé«˜æ¨ç†å»¶è¿Ÿé™åˆ¶äº†å®ƒä»¬åœ¨æœºå™¨äººæ“ä½œç­‰é¢†åŸŸçš„å®é™…åº”ç”¨ã€‚ç°æœ‰çš„æ¨¡å‹å‹ç¼©æ–¹æ³•ä¸»è¦å…³æ³¨è§†è§‰å’Œè¯­è¨€æ¨¡æ€ä¹‹é—´çš„ç›¸å…³æ€§ï¼Œå¿½ç•¥äº†åŠ¨ä½œé¢„æµ‹æœ¬èº«çš„é‡è¦æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šActDistillçš„æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨åŠ¨ä½œå…ˆéªŒçŸ¥è¯†æ¥æŒ‡å¯¼æ¨¡å‹è’¸é¦å’Œå‹ç¼©ï¼Œä»è€Œå®ç°é¢å‘åŠ¨ä½œé¢„æµ‹çš„é«˜æ•ˆVLAæ¨¡å‹ã€‚é€šè¿‡å°†å¤§å‹VLAæ¨¡å‹çš„çŸ¥è¯†è¿ç§»åˆ°è½»é‡çº§å­¦ç”Ÿæ¨¡å‹ï¼Œå¹¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ˜¾å¼åœ°å»ºæ¨¡åŠ¨ä½œé¢„æµ‹çš„å±‚çº§æ¼”åŒ–è¿‡ç¨‹ï¼Œä½¿å¾—å­¦ç”Ÿæ¨¡å‹èƒ½å¤Ÿä»¥æ›´å°‘çš„è®¡ç®—èµ„æºå®ç°ä¸æ•™å¸ˆæ¨¡å‹ç›¸å½“ç”šè‡³æ›´ä¼˜çš„æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šActDistillæ¡†æ¶ä¸»è¦åŒ…å«ä¸‰ä¸ªå…³é”®ç»„ä»¶ï¼šæ•™å¸ˆæ¨¡å‹ã€å›¾ç»“æ„å°è£…ç­–ç•¥å’ŒåŠ¨æ€è·¯ç”±å­¦ç”Ÿæ¨¡å‹ã€‚é¦–å…ˆï¼Œä½¿ç”¨ä¸€ä¸ªé¢„è®­ç»ƒå¥½çš„VLAæ¨¡å‹ä½œä¸ºæ•™å¸ˆæ¨¡å‹ã€‚ç„¶åï¼Œå¼•å…¥å›¾ç»“æ„å°è£…ç­–ç•¥æ¥æ˜¾å¼åœ°å»ºæ¨¡æ•™å¸ˆæ¨¡å‹ä¸­åŠ¨ä½œé¢„æµ‹çš„å±‚çº§æ¼”åŒ–è¿‡ç¨‹ï¼Œå°†æ•™å¸ˆæ¨¡å‹å°è£…æˆä¸€ä¸ªå›¾ç»“æ„ã€‚æœ€åï¼ŒåŸºäºè¯¥å›¾ç»“æ„ï¼Œæ„å»ºä¸€ä¸ªåŠ¨æ€è·¯ç”±å­¦ç”Ÿæ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥æ ¹æ®åŠ¨ä½œé¢„æµ‹çš„éœ€æ±‚è‡ªé€‚åº”åœ°é€‰æ‹©è®¡ç®—è·¯å¾„ã€‚

**å…³é”®åˆ›æ–°**ï¼šActDistillçš„å…³é”®åˆ›æ–°åœ¨äºå…¶åŠ¨ä½œå¼•å¯¼çš„è‡ªè’¸é¦æ–¹æ³•å’Œå›¾ç»“æ„å°è£…ç­–ç•¥ã€‚ä¼ ç»Ÿçš„æ¨¡å‹è’¸é¦æ–¹æ³•é€šå¸¸åªå…³æ³¨è¾“å…¥-è¾“å‡ºä¹‹é—´çš„æ˜ å°„å…³ç³»ï¼Œè€ŒActDistillåˆ™æ˜¾å¼åœ°åˆ©ç”¨äº†åŠ¨ä½œå…ˆéªŒçŸ¥è¯†æ¥æŒ‡å¯¼çŸ¥è¯†è¿ç§»ã€‚å›¾ç»“æ„å°è£…ç­–ç•¥èƒ½å¤Ÿæœ‰æ•ˆåœ°å»ºæ¨¡åŠ¨ä½œé¢„æµ‹çš„å±‚çº§æ¼”åŒ–è¿‡ç¨‹ï¼Œä»è€Œä½¿å¾—å­¦ç”Ÿæ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°å­¦ä¹ æ•™å¸ˆæ¨¡å‹çš„çŸ¥è¯†ã€‚

**å…³é”®è®¾è®¡**ï¼šå›¾ç»“æ„å°è£…ç­–ç•¥å°†æ•™å¸ˆæ¨¡å‹çš„æ¯ä¸€å±‚æˆ–å‡ å±‚ç»„åˆæˆå›¾ä¸­çš„èŠ‚ç‚¹ï¼ŒèŠ‚ç‚¹ä¹‹é—´çš„è¿æ¥è¡¨ç¤ºä¿¡æ¯ä¼ é€’å…³ç³»ã€‚åŠ¨æ€è·¯ç”±å­¦ç”Ÿæ¨¡å‹ä½¿ç”¨ä¸€ä¸ªåŠ¨æ€è·¯ç”±å™¨æ¥å†³å®šæ¯ä¸€å±‚åº”è¯¥é€‰æ‹©å“ªæ¡è®¡ç®—è·¯å¾„ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬æ¨¡ä»¿æŸå¤±ï¼ˆæ¨¡ä»¿æ•™å¸ˆæ¨¡å‹çš„è¾“å‡ºï¼‰å’Œå›¾ä¿¡æ¯ç›‘ç£æŸå¤±ï¼ˆé¼“åŠ±å­¦ç”Ÿæ¨¡å‹å­¦ä¹ å›¾ç»“æ„ä¸­çš„å±‚çº§å…³ç³»ï¼‰ã€‚å…·ä½“å‚æ•°è®¾ç½®ï¼ˆå¦‚å­¦ä¹ ç‡ã€batch sizeç­‰ï¼‰å’Œç½‘ç»œç»“æ„ç»†èŠ‚ï¼ˆå¦‚å›¾çš„æ„å»ºæ–¹å¼ã€åŠ¨æ€è·¯ç”±å™¨çš„è®¾è®¡ç­‰ï¼‰æœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ActDistillåœ¨å…·èº«æ™ºèƒ½åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œåœ¨è®¡ç®—é‡å‡å°‘50%ä»¥ä¸Šçš„æƒ…å†µä¸‹ï¼Œå®ç°äº†ä¸å…¨å°ºå¯¸VLAæ¨¡å‹ç›¸å½“ç”šè‡³æ›´ä¼˜çš„æ€§èƒ½ã€‚åŒæ—¶ï¼Œæ¨ç†é€Ÿåº¦æå‡é«˜è¾¾1.67å€ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•åœ¨æé«˜VLAæ¨¡å‹æ•ˆç‡æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚è¿™äº›ç»“æœè¡¨æ˜ActDistillä¸ºé«˜æ•ˆå…·èº«æ™ºèƒ½æä¾›äº†ä¸€ä¸ªæœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ActDistillå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå°¤å…¶æ˜¯åœ¨èµ„æºå—é™çš„æœºå™¨äººæ“ä½œã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸã€‚é€šè¿‡é™ä½VLAæ¨¡å‹çš„è®¡ç®—å¼€é”€å’Œæ¨ç†å»¶è¿Ÿï¼Œå¯ä»¥ä½¿å¾—è¿™äº›æ¨¡å‹èƒ½å¤Ÿæ›´é«˜æ•ˆåœ°éƒ¨ç½²åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šï¼Œä»è€Œå®ç°æ›´æ™ºèƒ½ã€æ›´è‡ªä¸»çš„æœºå™¨äººå’Œè‡ªåŠ¨é©¾é©¶ç³»ç»Ÿã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥åº”ç”¨äºå…¶ä»–éœ€è¦é«˜æ•ˆå¤šæ¨¡æ€ç†è§£å’Œå†³ç­–çš„ä»»åŠ¡ä¸­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent Vision-Language-Action (VLA) models have shown impressive flexibility and generalization, yet their deployment in robotic manipulation remains limited by heavy computational overhead and inference latency. In this work, we present ActDistill, a general action-guided self-derived distillation framework that transfers the action prediction capability of any existing VLA model to a lightweight counterpart. Unlike previous efficiency strategies that primarily emphasize vision-language correlations, ActDistill leverages action priors to guide knowledge transfer and model compression, achieving action-oriented efficiency for VLA models. Specifically, we employ a well-trained VLA model as the teacher and introduce a graph-structured encapsulation strategy to explicitly model the hierarchical evolution of action prediction. The student model, derived from the graph-encapsulated teacher, is further equipped with a dynamic router that adaptively selects computation paths based on action prediction demands, guided by hierarchical graph-informed supervision to ensure smooth and efficient evolution. During inference, graph-related auxiliary components are removed, allowing the student to execute only dynamically routed layers and predict high-precision actions with minimal computation and latency. Experiments on embodied benchmarks demonstrate that ActDistill achieves comparable or superior performance to full-scale VLA models while reducing computation by over 50% with up to 1.67 times speedup, thereby establishing a general paradigm toward efficient embodied intelligence.

