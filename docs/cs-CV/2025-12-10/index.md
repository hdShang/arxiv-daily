---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CV - 2025-12-10
---

# cs.CVï¼ˆ2025-12-10ï¼‰

ğŸ“Š å…± **19** ç¯‡è®ºæ–‡
 | ğŸ”— **2** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (14 ğŸ”—1)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2)</a>
<a href="#æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion" class="interest-badge">æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (1)</a>
<a href="#æ”¯æŸ±ä¸ƒåŠ¨ä½œé‡å®šå‘-motion-retargeting" class="interest-badge">æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting) (1 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (14 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251209646v1-vhoi-controllable-video-generation-of-human-object-interactions-from.html">VHOI: Controllable Video Generation of Human-Object Interactions from Sparse Trajectories via Motion Densification</a></td>
  <td>VHOIï¼šé€šè¿‡è¿åŠ¨ç¨ å¯†åŒ–ï¼Œä»ç¨€ç–è½¨è¿¹æ§åˆ¶äººä½“-ç‰©ä½“äº¤äº’è§†é¢‘ç”Ÿæˆ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09646v1" onclick="toggleFavorite(this, '2512.09646v1', 'VHOI: Controllable Video Generation of Human-Object Interactions from Sparse Trajectories via Motion Densification')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251209923v1-splatent-splatting-diffusion-latents-for-novel-view-synthesis.html">Splatent: Splatting Diffusion Latents for Novel View Synthesis</a></td>
  <td>Splatentï¼šé€šè¿‡Splattingæ‰©æ•£æ¨¡å‹æ½œåœ¨ç©ºé—´æå‡æ–°è§†è§’åˆæˆè´¨é‡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09923v1" onclick="toggleFavorite(this, '2512.09923v1', 'Splatent: Splatting Diffusion Latents for Novel View Synthesis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251209335v2-relightable-and-dynamic-gaussian-avatar-reconstruction-from-monocula.html">Relightable and Dynamic Gaussian Avatar Reconstruction from Monocular Video</a></td>
  <td>æå‡ºRnD-Avatarï¼ŒåŸºäº3DGSé‡å»ºå¯é‡å…‰ç…§å’ŒåŠ¨æ€äººä½“Avatarï¼Œæå‡å‡ ä½•ç»†èŠ‚ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09335v2" onclick="toggleFavorite(this, '2512.09335v2', 'Relightable and Dynamic Gaussian Avatar Reconstruction from Monocular Video')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251209407v1-generative-point-cloud-registration.html">Generative Point Cloud Registration</a></td>
  <td>æå‡ºç”Ÿæˆå¼ç‚¹äº‘é…å‡†æ–¹æ³•ï¼Œåˆ©ç”¨2Dç”Ÿæˆæ¨¡å‹æå‡3DåŒ¹é…æ€§èƒ½</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09407v1" onclick="toggleFavorite(this, '2512.09407v1', 'Generative Point Cloud Registration')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251211894v1-mmweaver-environment-specific-mmwave-signal-synthesis-from-a-photo-a.html">mmWEAVER: Environment-Specific mmWave Signal Synthesis from a Photo and Activity Description</a></td>
  <td>mmWeaverï¼šåˆ©ç”¨ç…§ç‰‡å’Œæ´»åŠ¨æè¿°åˆæˆç¯å¢ƒç‰¹å®šçš„æ¯«ç±³æ³¢ä¿¡å·</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11894v1" onclick="toggleFavorite(this, '2512.11894v1', 'mmWEAVER: Environment-Specific mmWave Signal Synthesis from a Photo and Activity Description')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251209792v1-fastpose-vit-a-vision-transformer-for-real-time-spacecraft-pose-esti.html">FastPose-ViT: A Vision Transformer for Real-Time Spacecraft Pose Estimation</a></td>
  <td>æå‡ºFastPose-ViTï¼Œç”¨äºèµ„æºå—é™å¹³å°ä¸Šçš„èˆªå¤©å™¨å®æ—¶å§¿æ€ä¼°è®¡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09792v1" onclick="toggleFavorite(this, '2512.09792v1', 'FastPose-ViT: A Vision Transformer for Real-Time Spacecraft Pose Estimation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/251209393v1-detection-and-localization-of-subdural-hematoma-using-deep-learning-.html">Detection and Localization of Subdural Hematoma Using Deep Learning on Computed Tomography</a></td>
  <td>æå‡ºå¤šæ¨¡æ€æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºè„‘éƒ¨CTå½±åƒä¸­ç¡¬è†œä¸‹è¡€è‚¿çš„ç²¾å‡†æ£€æµ‹ä¸å®šä½</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09393v1" onclick="toggleFavorite(this, '2512.09393v1', 'Detection and Localization of Subdural Hematoma Using Deep Learning on Computed Tomography')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251209270v1-morel-long-range-flicker-free-4d-motion-modeling-via-anchor-relay-ba.html">MoRel: Long-Range Flicker-Free 4D Motion Modeling via Anchor Relay-based Bidirectional Blending with Hierarchical Densification</a></td>
  <td>MoRelï¼šåŸºäºé”šç‚¹ä¸­ç»§åŒå‘èåˆå’Œåˆ†å±‚ç¨ å¯†åŒ–çš„é•¿ç¨‹æ— é—ªçƒ4Dè¿åŠ¨å»ºæ¨¡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09270v1" onclick="toggleFavorite(this, '2512.09270v1', 'MoRel: Long-Range Flicker-Free 4D Motion Modeling via Anchor Relay-based Bidirectional Blending with Hierarchical Densification')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/251209373v1-fuser-feed-forward-multiview-3d-registration-transformer-and-se3n-di.html">FUSER: Feed-Forward MUltiview 3D Registration Transformer and SE(3)$^N$ Diffusion Refinement</a></td>
  <td>æå‡ºFUSERä»¥è§£å†³å¤šè§†è§’ç‚¹äº‘é…å‡†é—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09373v1" onclick="toggleFavorite(this, '2512.09373v1', 'FUSER: Feed-Forward MUltiview 3D Registration Transformer and SE(3)$^N$ Diffusion Refinement')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/251209925v1-gains-gaussian-based-inverse-rendering-from-sparse-multi-view-captur.html">GAINS: Gaussian-based Inverse Rendering from Sparse Multi-View Captures</a></td>
  <td>GAINSï¼šåŸºäºé«˜æ–¯çš„ç¨€ç–å¤šè§†è§’é€†æ¸²æŸ“ï¼Œæå‡å‡ ä½•ä¸æè´¨æ¢å¤è´¨é‡</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09925v1" onclick="toggleFavorite(this, '2512.09925v1', 'GAINS: Gaussian-based Inverse Rendering from Sparse Multi-View Captures')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/251210095v1-traceflow-dynamic-3d-reconstruction-of-specular-scenes-driven-by-ray.html">TraceFlow: Dynamic 3D Reconstruction of Specular Scenes Driven by Ray Tracing</a></td>
  <td>TraceFlowï¼šå…‰çº¿è¿½è¸ªé©±åŠ¨çš„åŠ¨æ€é«˜å…‰åœºæ™¯ä¸‰ç»´é‡å»º</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.10095v1" onclick="toggleFavorite(this, '2512.10095v1', 'TraceFlow: Dynamic 3D Reconstruction of Specular Scenes Driven by Ray Tracing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/251209847v1-from-detection-to-anticipation-online-understanding-of-struggles-acr.html">From Detection to Anticipation: Online Understanding of Struggles across Various Tasks and Activities</a></td>
  <td>æå‡ºåœ¨çº¿æŒ£æ‰æ£€æµ‹ä¸é¢„æµ‹æ¡†æ¶ï¼ŒåŠ©åŠ›å®æ—¶è¾…åŠ©ç³»ç»Ÿç†è§£äººç±»æŠ€èƒ½è¡¨ç°</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09847v1" onclick="toggleFavorite(this, '2512.09847v1', 'From Detection to Anticipation: Online Understanding of Struggles across Various Tasks and Activities')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/251209463v1-privacy-preserving-computer-vision-for-industry-three-case-studies-i.html">Privacy-Preserving Computer Vision for Industry: Three Case Studies in Human-Centric Manufacturing</a></td>
  <td>æå‡ºä¸€ç§é¢å‘å·¥ä¸šçš„éšç§ä¿æŠ¤è®¡ç®—æœºè§†è§‰æ¡†æ¶ï¼Œåº”ç”¨äºäººæœºåä½œåˆ¶é€ åœºæ™¯</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09463v1" onclick="toggleFavorite(this, '2512.09463v1', 'Privacy-Preserving Computer Vision for Industry: Three Case Studies in Human-Centric Manufacturing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/251209364v1-assist-3d-adapted-scene-synthesis-for-class-agnostic-3d-instance-seg.html">ASSIST-3D: Adapted Scene Synthesis for Class-Agnostic 3D Instance Segmentation</a></td>
  <td>ASSIST-3Dï¼šç”¨äºç±»åˆ«æ— å…³3Då®ä¾‹åˆ†å‰²çš„è‡ªé€‚åº”åœºæ™¯åˆæˆ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09364v1" onclick="toggleFavorite(this, '2512.09364v1', 'ASSIST-3D: Adapted Scene Synthesis for Class-Agnostic 3D Instance Segmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>15</td>
  <td><a href="./papers/251209375v1-log-nerf-comparing-spaces-for-learning-radiance-fields.html">Log NeRF: Comparing Spaces for Learning Radiance Fields</a></td>
  <td>Log NeRFï¼šé€šè¿‡æ¯”è¾ƒä¸åŒè‰²å½©ç©ºé—´ï¼Œæå‡ç¥ç»è¾å°„åœºçš„å­¦ä¹ æ•ˆæœ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09375v1" onclick="toggleFavorite(this, '2512.09375v1', 'Log NeRF: Comparing Spaces for Learning Radiance Fields')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/251211901v1-clarga-multimodal-graph-representation-learning-over-arbitrary-sets-.html">CLARGA: Multimodal Graph Representation Learning over Arbitrary Sets of Modalities</a></td>
  <td>CLARGAï¼šæå‡ºä¸€ç§é€šç”¨çš„å¤šæ¨¡æ€å›¾è¡¨ç¤ºå­¦ä¹ æ¡†æ¶ï¼Œé€‚ç”¨äºä»»æ„æ¨¡æ€ç»„åˆã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11901v1" onclick="toggleFavorite(this, '2512.11901v1', 'CLARGA: Multimodal Graph Representation Learning over Arbitrary Sets of Modalities')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion">ğŸ”¬ æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>17</td>
  <td><a href="./papers/251209423v1-funphase-a-periodic-functional-autoencoder-for-motion-generation-via.html">FunPhase: A Periodic Functional Autoencoder for Motion Generation via Phase Manifolds</a></td>
  <td>FunPhaseï¼šé€šè¿‡ç›¸ä½æµå½¢å®ç°è¿åŠ¨ç”Ÿæˆçš„å‘¨æœŸæ€§å‡½æ•°è‡ªç¼–ç å™¨</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09423v1" onclick="toggleFavorite(this, '2512.09423v1', 'FunPhase: A Periodic Functional Autoencoder for Motion Generation via Phase Manifolds')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸ƒåŠ¨ä½œé‡å®šå‘-motion-retargeting">ğŸ”¬ æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>18</td>
  <td><a href="./papers/251209363v2-stereoworld-geometry-aware-monocular-to-stereo-video-generation.html">StereoWorld: Geometry-Aware Monocular-to-Stereo Video Generation</a></td>
  <td>StereoWorldï¼šæå‡ºå‡ ä½•æ„ŸçŸ¥å•ç›®è§†é¢‘è½¬ç«‹ä½“è§†é¢‘ç”Ÿæˆæ¡†æ¶ï¼Œæå‡è§†è§‰ä¿çœŸåº¦å’Œå‡ ä½•ä¸€è‡´æ€§ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09363v2" onclick="toggleFavorite(this, '2512.09363v2', 'StereoWorld: Geometry-Aware Monocular-to-Stereo Video Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>19</td>
  <td><a href="./papers/251209617v1-fromat-multiview-material-appearance-transfer-via-few-shot-self-atte.html">FROMAT: Multiview Material Appearance Transfer via Few-Shot Self-Attention Adaptation</a></td>
  <td>æå‡ºFROMATï¼Œé€šè¿‡å°‘æ ·æœ¬è‡ªæ³¨æ„åŠ›é€‚é…å®ç°å¤šè§†è§’æè´¨å¤–è§‚è¿ç§»</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09617v1" onclick="toggleFavorite(this, '2512.09617v1', 'FROMAT: Multiview Material Appearance Transfer via Few-Shot Self-Attention Adaptation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CV é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)