---
layout: default
title: "FastPose-ViT: A Vision Transformer for Real-Time Spacecraft Pose Estimation"
---

# FastPose-ViT: A Vision Transformer for Real-Time Spacecraft Pose Estimation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.09792" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.09792v1</a>
  <a href="https://arxiv.org/pdf/2512.09792.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.09792v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.09792v1', 'FastPose-ViT: A Vision Transformer for Real-Time Spacecraft Pose Estimation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Pierre Ancey, Andrew Price, Saqib Javed, Mathieu Salzmann

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-10

**å¤‡æ³¨**: Accepted to WACV 2026. Preprint version

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFastPose-ViTï¼Œç”¨äºèµ„æºå—é™å¹³å°ä¸Šçš„èˆªå¤©å™¨å®æ—¶å§¿æ€ä¼°è®¡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `èˆªå¤©å™¨å§¿æ€ä¼°è®¡` `Vision Transformer` `å®æ—¶æ€§` `è¾¹ç¼˜è®¡ç®—` `6DoFå§¿æ€ä¼°è®¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰èˆªå¤©å™¨å§¿æ€ä¼°è®¡æ–¹æ³•ä¾èµ–è¿­ä»£PnPç®—æ³•ï¼Œè®¡ç®—é‡å¤§ï¼Œéš¾ä»¥åœ¨èµ„æºå—é™è®¾å¤‡ä¸Šå®æ—¶éƒ¨ç½²ã€‚
2. FastPose-ViTåŸºäºViTç›´æ¥å›å½’6DoFå§¿æ€ï¼Œå¹¶æå‡ºæ–°çš„æ•°å­¦å½¢å¼ï¼Œå°†å±€éƒ¨é¢„æµ‹æ˜ å°„åˆ°å…¨å±€ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒFastPose-ViTæ€§èƒ½ä¼˜äºéPnPæ–¹æ³•ï¼Œä¸PnPæ–¹æ³•ç›¸å½“ï¼Œå¹¶åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šå®ç°å®æ—¶æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºVision Transformer (ViT)çš„FastPose-ViTæ¶æ„ï¼Œç”¨äºç›´æ¥å›å½’èˆªå¤©å™¨çš„6è‡ªç”±åº¦(6DoF)å§¿æ€ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰åŸºäºè¿­ä»£Perspective-n-Point (PnP)ç®—æ³•è®¡ç®—å¯†é›†ã€ä¸é€‚ç”¨äºèµ„æºå—é™è¾¹ç¼˜è®¾å¤‡å®æ—¶éƒ¨ç½²çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•å¤„ç†æ¥è‡ªç›®æ ‡è¾¹ç•Œæ¡†çš„è£å‰ªå›¾åƒï¼Œå¹¶å¼•å…¥äº†ä¸€ç§æ–°çš„æ•°å­¦å½¢å¼ï¼Œå°†è¿™äº›å±€éƒ¨é¢„æµ‹æ˜ å°„å›å®Œæ•´å›¾åƒå°ºåº¦ã€‚è¯¥å½¢å¼æºäºå°„å½±å‡ ä½•åŸç†å’Œâ€œè§†åœ¨æ—‹è½¬â€çš„æ¦‚å¿µï¼Œæ¨¡å‹é¢„æµ‹ä¸€ä¸ªè§†åœ¨æ—‹è½¬çŸ©é˜µï¼Œç„¶åå¯¹å…¶è¿›è¡Œæ ¡æ­£ä»¥æ‰¾åˆ°çœŸå®çš„å§¿æ€ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºå…¶ä»–éPnPç­–ç•¥ï¼Œå¹¶åœ¨SPEEDæ•°æ®é›†ä¸Šå®ç°äº†ä¸æœ€å…ˆè¿›çš„PnPæ–¹æ³•ç›¸åª²ç¾çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œé€šè¿‡é‡åŒ–æ¨¡å‹å¹¶å°†å…¶éƒ¨ç½²åœ¨åŠŸè€—å—é™çš„è¾¹ç¼˜ç¡¬ä»¶ä¸Šï¼ŒéªŒè¯äº†å…¶åœ¨å®é™…ç©ºé—´ä»»åŠ¡ä¸­çš„é€‚ç”¨æ€§ã€‚åœ¨NVIDIA Jetson Orin Nanoä¸Šï¼Œç«¯åˆ°ç«¯æµæ°´çº¿åœ¨é¡ºåºæ‰§è¡Œä¸‹å®ç°äº†çº¦75æ¯«ç§’/å¸§çš„å»¶è¿Ÿï¼Œåœ¨å¹¶å‘è°ƒåº¦é˜¶æ®µå®ç°äº†é«˜è¾¾33 FPSçš„éé˜»å¡ååé‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³èˆªå¤©å™¨6DoFå§¿æ€ä¼°è®¡é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ä¸Šè¿›è¡Œå®æ—¶å§¿æ€ä¼°è®¡ã€‚ç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åŸºäºè¿­ä»£PnPç®—æ³•çš„æ–¹æ³•ï¼Œè®¡ç®—å¤æ‚åº¦é«˜ï¼Œéš¾ä»¥æ»¡è¶³å®æ—¶æ€§è¦æ±‚ï¼Œé™åˆ¶äº†å…¶åœ¨å®é™…ç©ºé—´ä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨Vision Transformer (ViT)ç›´æ¥å›å½’6DoFå§¿æ€ï¼Œé¿å…è¿­ä»£è®¡ç®—ã€‚é€šè¿‡å­¦ä¹ å›¾åƒç‰¹å¾ä¸å§¿æ€ä¹‹é—´çš„ç›´æ¥æ˜ å°„å…³ç³»ï¼Œé™ä½è®¡ç®—å¤æ‚åº¦ï¼Œæé«˜æ¨ç†é€Ÿåº¦ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜å¼•å…¥äº†ä¸€ç§æ–°çš„æ•°å­¦å½¢å¼ï¼Œå°†è£å‰ªå›¾åƒçš„å±€éƒ¨å§¿æ€é¢„æµ‹æ˜ å°„å›å®Œæ•´å›¾åƒçš„å…¨å±€å§¿æ€ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFastPose-ViTçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦é˜¶æ®µï¼š1) è¾“å…¥è£å‰ªåçš„èˆªå¤©å™¨å›¾åƒï¼›2) ä½¿ç”¨ViTæå–å›¾åƒç‰¹å¾ï¼›3) é€šè¿‡å›å½’å¤´é¢„æµ‹è§†åœ¨æ—‹è½¬çŸ©é˜µï¼›4) åˆ©ç”¨æå‡ºçš„æ•°å­¦å½¢å¼ï¼Œå°†è§†åœ¨æ—‹è½¬çŸ©é˜µæ ¡æ­£ä¸ºçœŸå®çš„æ—‹è½¬çŸ©é˜µï¼Œå¹¶é¢„æµ‹å¹³ç§»å‘é‡ã€‚æ•´ä¸ªæµç¨‹æ˜¯ç«¯åˆ°ç«¯å¯è®­ç»ƒçš„ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§æ–°çš„æ•°å­¦å½¢å¼ï¼Œç”¨äºå°†è£å‰ªå›¾åƒçš„å±€éƒ¨å§¿æ€é¢„æµ‹æ˜ å°„å›å®Œæ•´å›¾åƒçš„å…¨å±€å§¿æ€ã€‚è¿™ç§æ–¹æ³•åŸºäºå°„å½±å‡ ä½•å’Œâ€œè§†åœ¨æ—‹è½¬â€çš„æ¦‚å¿µï¼Œé€šè¿‡é¢„æµ‹ä¸€ä¸ªè§†åœ¨æ—‹è½¬çŸ©é˜µï¼Œç„¶åå¯¹å…¶è¿›è¡Œæ ¡æ­£ï¼Œä»è€Œå¾—åˆ°çœŸå®çš„æ—‹è½¬çŸ©é˜µã€‚è¿™ç§æ–¹æ³•é¿å…äº†ç›´æ¥å›å½’å…¨å±€å§¿æ€çš„å›°éš¾ï¼Œæé«˜äº†æ¨¡å‹çš„ç²¾åº¦å’Œé²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šFastPose-ViTä½¿ç”¨æ ‡å‡†çš„ViTæ¶æ„ä½œä¸ºç‰¹å¾æå–å™¨ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬æ—‹è½¬æŸå¤±å’Œå¹³ç§»æŸå¤±ã€‚æ—‹è½¬æŸå¤±å¯ä»¥ä½¿ç”¨å››å…ƒæ•°æŸå¤±æˆ–æ—‹è½¬çŸ©é˜µæŸå¤±ã€‚å¹³ç§»æŸå¤±å¯ä»¥ä½¿ç”¨L1æˆ–L2æŸå¤±ã€‚å…³é”®å‚æ•°åŒ…æ‹¬ViTçš„å±‚æ•°ã€å¤´æ•°ã€åµŒå…¥ç»´åº¦ç­‰ã€‚æ­¤å¤–ï¼Œè§†åœ¨æ—‹è½¬çŸ©é˜µçš„æ ¡æ­£è¿‡ç¨‹ä¹Ÿéœ€è¦ä»”ç»†è®¾è®¡ï¼Œä»¥ä¿è¯æ ¡æ­£çš„å‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

FastPose-ViTåœ¨SPEEDæ•°æ®é›†ä¸Šå–å¾—äº†ä¸æœ€å…ˆè¿›çš„PnPæ–¹æ³•ç›¸åª²ç¾çš„æ€§èƒ½ï¼ŒåŒæ—¶æ˜¾è‘—é™ä½äº†è®¡ç®—å¤æ‚åº¦ã€‚åœ¨NVIDIA Jetson Orin Nanoä¸Šï¼Œè¯¥æ–¹æ³•å®ç°äº†çº¦75æ¯«ç§’/å¸§çš„å»¶è¿Ÿï¼Œä»¥åŠé«˜è¾¾33 FPSçš„éé˜»å¡ååé‡ï¼ŒéªŒè¯äº†å…¶åœ¨èµ„æºå—é™è¾¹ç¼˜è®¾å¤‡ä¸Šçš„å®æ—¶æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒFastPose-ViTæ˜¯ä¸€ç§é«˜æ•ˆã€å‡†ç¡®çš„èˆªå¤©å™¨å§¿æ€ä¼°è®¡æ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºåœ¨è½¨æœåŠ¡ã€ç©ºé—´ç¢ç‰‡ç§»é™¤ã€è‡ªä¸»å¯¼èˆªç­‰èˆªå¤©ä»»åŠ¡ä¸­ã€‚é€šè¿‡åœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ä¸Šå®ç°å®æ—¶å§¿æ€ä¼°è®¡ï¼Œå¯ä»¥æé«˜èˆªå¤©å™¨çš„è‡ªä¸»æ€§å’Œæ™ºèƒ½åŒ–æ°´å¹³ï¼Œé™ä½å¯¹åœ°é¢ç«™çš„ä¾èµ–ï¼Œä»è€Œé™ä½ä»»åŠ¡æˆæœ¬ï¼Œæé«˜ä»»åŠ¡æ•ˆç‡ã€‚è¯¥æ–¹æ³•è¿˜å¯æ¨å¹¿åˆ°å…¶ä»–éœ€è¦å®æ—¶å§¿æ€ä¼°è®¡çš„åœºæ™¯ï¼Œå¦‚æœºå™¨äººå¯¼èˆªã€å¢å¼ºç°å®ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Estimating the 6-degrees-of-freedom (6DoF) pose of a spacecraft from a single image is critical for autonomous operations like in-orbit servicing and space debris removal. Existing state-of-the-art methods often rely on iterative Perspective-n-Point (PnP)-based algorithms, which are computationally intensive and ill-suited for real-time deployment on resource-constrained edge devices. To overcome these limitations, we propose FastPose-ViT, a Vision Transformer (ViT)-based architecture that directly regresses the 6DoF pose. Our approach processes cropped images from object bounding boxes and introduces a novel mathematical formalism to map these localized predictions back to the full-image scale. This formalism is derived from the principles of projective geometry and the concept of "apparent rotation", where the model predicts an apparent rotation matrix that is then corrected to find the true orientation. We demonstrate that our method outperforms other non-PnP strategies and achieves performance competitive with state-of-the-art PnP-based techniques on the SPEED dataset. Furthermore, we validate our model's suitability for real-world space missions by quantizing it and deploying it on power-constrained edge hardware. On the NVIDIA Jetson Orin Nano, our end-to-end pipeline achieves a latency of ~75 ms per frame under sequential execution, and a non-blocking throughput of up to 33 FPS when stages are scheduled concurrently.

