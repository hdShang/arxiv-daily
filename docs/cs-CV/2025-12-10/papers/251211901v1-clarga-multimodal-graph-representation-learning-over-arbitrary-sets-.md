---
layout: default
title: CLARGA: Multimodal Graph Representation Learning over Arbitrary Sets of Modalities
---

# CLARGA: Multimodal Graph Representation Learning over Arbitrary Sets of Modalities

**arXiv**: [2512.11901v1](https://arxiv.org/abs/2512.11901) | [PDF](https://arxiv.org/pdf/2512.11901.pdf)

**ä½œè€…**: Santosh Patapati

**åˆ†ç±»**: cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-12-10

**å¤‡æ³¨**: WACV; Supplementary material is available on CVF proceedings

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**CLARGAï¼šæå‡ºä¸€ç§é€šç”¨çš„å¤šæ¨¡æ€å›¾è¡¨ç¤ºå­¦ä¹ æ¡†æž¶ï¼Œé€‚ç”¨äºŽä»»æ„æ¨¡æ€ç»„åˆã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `å¤šæ¨¡æ€èžåˆ` `å›¾ç¥žç»ç½‘ç»œ` `æ³¨æ„åŠ›æœºåˆ¶` `è¡¨ç¤ºå­¦ä¹ ` `è·¨æ¨¡æ€å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤šæ¨¡æ€æ•°æ®æ—¶ï¼Œéš¾ä»¥é€‚åº”ä¸åŒæ¨¡æ€ç»„åˆï¼Œä¸”è®¡ç®—å¤æ‚åº¦é«˜ï¼Œé™åˆ¶äº†å…¶åº”ç”¨èŒƒå›´ã€‚
2. CLARGAé€šè¿‡æž„å»ºæ³¨æ„åŠ›åŠ æƒå›¾ï¼Œå­¦ä¹ æ¨¡æ€é—´çš„ç›¸äº’å½±å“ï¼Œå¹¶åˆ©ç”¨å›¾æ³¨æ„åŠ›ç½‘ç»œè¿›è¡Œæ¶ˆæ¯ä¼ é€’ï¼Œå®žçŽ°é«˜æ•ˆèžåˆã€‚
3. å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒCLARGAåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œå¹¶å¯¹ç¼ºå¤±æ¨¡æ€å’Œå™ªå£°è¾“å…¥å…·æœ‰é²æ£’æ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ä»‹ç»äº†ä¸€ç§é€šç”¨çš„å¤šæ¨¡æ€èžåˆæž¶æž„CLARGAï¼Œç”¨äºŽå¤šæ¨¡æ€è¡¨ç¤ºå­¦ä¹ ï¼Œå®ƒå¯ä»¥åœ¨ä¸æ”¹å˜åº•å±‚æ¡†æž¶çš„æƒ…å†µä¸‹å¤„ç†ä»»æ„æ•°é‡å’Œç±»åž‹çš„æ¨¡æ€ã€‚ç»™å®šä¸€ä¸ªæœ‰ç›‘ç£æ•°æ®é›†ï¼ŒCLARGAå¯ä»¥åº”ç”¨äºŽå‡ ä¹Žä»»ä½•æœºå™¨å­¦ä¹ ä»»åŠ¡ï¼Œä»¥èžåˆä¸åŒçš„å¤šæ¨¡æ€è¡¨ç¤ºï¼Œä¾›ä¸‹æ¸¸å±‚å¤„ç†ã€‚CLARGAé€šè¿‡æž„å»ºä¸€ä¸ªæ³¨æ„åŠ›åŠ æƒå›¾æ¥å­¦ä¹ æ¨¡æ€ä¹‹é—´å¦‚ä½•ç›¸äº’å½±å“ï¼Œå¹¶åœ¨è¯¥å›¾ä¸Šä½¿ç”¨å¤šå¤´å›¾æ³¨æ„åŠ›ç½‘ç»œä¼ é€’æ¶ˆæ¯ï¼Œä»Žè€Œå®žçŽ°æ ·æœ¬çº§åˆ«çš„æ¨¡æ€èžåˆã€‚è¿™ç§è®¾è®¡ä¸ä»…ä½¿CLARGAå…·æœ‰é«˜åº¦çš„é€‚åº”æ€§ï¼Œå› ä¸ºå®ƒä¸ºä¸åŒçš„æ ·æœ¬æž„å»ºç‹¬ç‰¹çš„å›¾ï¼Œè€Œä¸”éšç€æ¨¡æ€æ•°é‡çš„å¢žé•¿ï¼Œå®ƒè¿˜èƒ½å®žçŽ°äºšäºŒæ¬¡å¤æ‚åº¦çš„æœ‰æ•ˆèžåˆã€‚é€šè¿‡å¯å­¦ä¹ çš„æŽ©ç ï¼Œå®ƒè¿˜å¯ä»¥é€‚åº”ç¼ºå¤±çš„æ¨¡æ€è¾“å…¥ã€‚è¯¥æ¨¡åž‹é‡‡ç”¨æ··åˆç›®æ ‡è¿›è¡Œè®­ç»ƒï¼Œè¯¥ç›®æ ‡å°†æœ‰ç›‘ç£ä»»åŠ¡æŸå¤±ä¸Žå¯¹æ¯”InfoNCEæŸå¤±ç›¸ç»“åˆï¼Œä»Žè€Œæé«˜è·¨æ¨¡æ€ä¸€è‡´æ€§å’Œå¯¹å™ªå£°è¾“å…¥çš„é²æ£’æ€§ã€‚æˆ‘ä»¬åœ¨æ¶µç›–é‡‘èžã€äººæœºäº¤äº’ã€é€šç”¨å¤šåª’ä½“åˆ†ç±»å’Œæƒ…æ„Ÿè®¡ç®—çš„7ä¸ªæ•°æ®é›†ä¸Šçš„å„ç§å¤šæ¨¡æ€è¡¨ç¤ºå­¦ä¹ ä»»åŠ¡ä¸­è¯æ˜Žäº†CLARGAçš„æœ‰æ•ˆæ€§ã€‚å®ƒå§‹ç»ˆä¼˜äºŽåŸºçº¿æ¨¡åž‹ã€æœ€å…ˆè¿›çš„æ¨¡åž‹å’Œæ¶ˆèžå®žéªŒã€‚é¢å¤–çš„å®žéªŒä¹Ÿè¯æ˜Žäº†å®ƒå¯¹ç¼ºå¤±è¾“å…¥çš„é²æ£’æ€§ä»¥åŠåœ¨å°ä¼—ä»»åŠ¡ä¸­è¡¨çŽ°å‡ºè‰²çš„èƒ½åŠ›ã€‚æ€»çš„æ¥è¯´ï¼ŒCLARGAå¯ä»¥å¾ˆå®¹æ˜“åœ°æ’å…¥åˆ°æœºå™¨å­¦ä¹ æ¨¡åž‹ä¸­ï¼Œä»¥æœ‰æ•ˆåœ°å­¦ä¹ å„ç§ä»»åŠ¡çš„è¡¨ç¤ºã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰çš„å¤šæ¨¡æ€èžåˆæ–¹æ³•é€šå¸¸éœ€è¦é’ˆå¯¹ç‰¹å®šæ¨¡æ€ç»„åˆè¿›è¡Œè®¾è®¡ï¼Œç¼ºä¹é€šç”¨æ€§ã€‚æ­¤å¤–ï¼Œéšç€æ¨¡æ€æ•°é‡çš„å¢žåŠ ï¼Œèžåˆè¿‡ç¨‹çš„è®¡ç®—å¤æ‚åº¦ä¹Ÿä¼šæ˜¾è‘—å¢žåŠ ï¼Œé™åˆ¶äº†å…¶åœ¨å¤§è§„æ¨¡å¤šæ¨¡æ€æ•°æ®ä¸Šçš„åº”ç”¨ã€‚å¦‚ä½•è®¾è®¡ä¸€ç§é€šç”¨çš„ã€é«˜æ•ˆçš„å¤šæ¨¡æ€èžåˆæ¡†æž¶ï¼Œæ˜¯æœ¬æ–‡è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šCLARGAçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å›¾ç»“æž„æ¥å»ºæ¨¡ä¸åŒæ¨¡æ€ä¹‹é—´çš„å…³ç³»ã€‚å…·ä½“æ¥è¯´ï¼Œå¯¹äºŽæ¯ä¸ªæ ·æœ¬ï¼ŒCLARGAæž„å»ºä¸€ä¸ªä»¥æ¨¡æ€ç‰¹å¾ä¸ºèŠ‚ç‚¹çš„å›¾ï¼Œå¹¶ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶å­¦ä¹ èŠ‚ç‚¹ä¹‹é—´çš„è¾¹æƒé‡ï¼Œä»Žè€Œè¡¨ç¤ºæ¨¡æ€ä¹‹é—´çš„ç›¸äº’å½±å“ã€‚ç„¶åŽï¼Œåˆ©ç”¨å›¾æ³¨æ„åŠ›ç½‘ç»œåœ¨è¯¥å›¾ä¸Šè¿›è¡Œæ¶ˆæ¯ä¼ é€’ï¼Œå®žçŽ°æ¨¡æ€ä¿¡æ¯çš„èžåˆã€‚è¿™ç§åŸºäºŽå›¾çš„èžåˆæ–¹å¼å…·æœ‰å¾ˆå¼ºçš„çµæ´»æ€§å’Œå¯æ‰©å±•æ€§ï¼Œå¯ä»¥é€‚åº”ä»»æ„æ•°é‡å’Œç±»åž‹çš„æ¨¡æ€ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šCLARGAçš„æ•´ä½“æž¶æž„åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) ç‰¹å¾æå–æ¨¡å—ï¼šç”¨äºŽæå–æ¯ä¸ªæ¨¡æ€çš„ç‰¹å¾è¡¨ç¤ºï¼›2) å›¾æž„å»ºæ¨¡å—ï¼šåŸºäºŽæ¨¡æ€ç‰¹å¾æž„å»ºæ³¨æ„åŠ›åŠ æƒå›¾ï¼›3) å›¾æ³¨æ„åŠ›ç½‘ç»œæ¨¡å—ï¼šåœ¨è¯¥å›¾ä¸Šè¿›è¡Œæ¶ˆæ¯ä¼ é€’ï¼Œèžåˆæ¨¡æ€ä¿¡æ¯ï¼›4) é¢„æµ‹æ¨¡å—ï¼šåŸºäºŽèžåˆåŽçš„ç‰¹å¾è¿›è¡Œé¢„æµ‹ã€‚æ•´ä¸ªæµç¨‹æ˜¯ç«¯åˆ°ç«¯å¯è®­ç»ƒçš„ã€‚

**å…³é”®åˆ›æ–°**ï¼šCLARGAæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽå…¶åŸºäºŽå›¾çš„æ¨¡æ€èžåˆæ–¹å¼ã€‚ä¸Žä¼ ç»Ÿçš„åŸºäºŽè¿žæŽ¥æˆ–æ³¨æ„åŠ›æœºåˆ¶çš„èžåˆæ–¹æ³•ç›¸æ¯”ï¼ŒCLARGAèƒ½å¤Ÿæ›´çµæ´»åœ°å»ºæ¨¡æ¨¡æ€ä¹‹é—´çš„å¤æ‚å…³ç³»ï¼Œå¹¶æœ‰æ•ˆåœ°åˆ©ç”¨æ¨¡æ€ä¹‹é—´çš„äº’è¡¥ä¿¡æ¯ã€‚æ­¤å¤–ï¼ŒCLARGAè¿˜å¼•å…¥äº†å¯å­¦ä¹ çš„æŽ©ç æœºåˆ¶ï¼Œä»¥é€‚åº”ç¼ºå¤±æ¨¡æ€çš„æƒ…å†µï¼Œæé«˜äº†æ¨¡åž‹çš„é²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šCLARGAçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨å¤šå¤´å›¾æ³¨æ„åŠ›ç½‘ç»œè¿›è¡Œæ¶ˆæ¯ä¼ é€’ï¼Œä»¥æ•æ‰ä¸åŒæ–¹é¢çš„æ¨¡æ€å…³ç³»ï¼›2) é‡‡ç”¨InfoNCEæŸå¤±æ¥æé«˜è·¨æ¨¡æ€ä¸€è‡´æ€§ï¼›3) ä½¿ç”¨å¯å­¦ä¹ çš„æŽ©ç æ¥å¤„ç†ç¼ºå¤±æ¨¡æ€ï¼›4) æ··åˆäº†æœ‰ç›‘ç£ä»»åŠ¡æŸå¤±å’Œå¯¹æ¯”å­¦ä¹ æŸå¤±ï¼Œä»¥æé«˜æ¨¡åž‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

CLARGAåœ¨7ä¸ªä¸åŒçš„å¤šæ¨¡æ€æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œæ¶µç›–äº†é‡‘èžã€äººæœºäº¤äº’ã€é€šç”¨å¤šåª’ä½“åˆ†ç±»å’Œæƒ…æ„Ÿè®¡ç®—ç­‰å¤šä¸ªé¢†åŸŸã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒCLARGAåœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šéƒ½ä¼˜äºŽçŽ°æœ‰çš„åŸºçº¿æ¨¡åž‹å’Œæœ€å…ˆè¿›çš„æ¨¡åž‹ã€‚ä¾‹å¦‚ï¼Œåœ¨æŸäº›æ•°æ®é›†ä¸Šï¼ŒCLARGAçš„æ€§èƒ½æå‡è¶…è¿‡äº†5%ã€‚æ­¤å¤–ï¼Œå®žéªŒè¿˜è¯æ˜Žäº†CLARGAå¯¹ç¼ºå¤±æ¨¡æ€å’Œå™ªå£°è¾“å…¥çš„é²æ£’æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

CLARGAå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚é‡‘èžé¢†åŸŸçš„é£Žé™©é¢„æµ‹ã€äººæœºäº¤äº’é¢†åŸŸçš„æƒ…æ„Ÿè¯†åˆ«ã€å¤šåª’ä½“å†…å®¹ç†è§£ç­‰ã€‚è¯¥ç ”ç©¶çš„å®žé™…ä»·å€¼åœ¨äºŽæä¾›äº†ä¸€ç§é€šç”¨çš„å¤šæ¨¡æ€èžåˆæ¡†æž¶ï¼Œå¯ä»¥æ–¹ä¾¿åœ°åº”ç”¨äºŽå„ç§æœºå™¨å­¦ä¹ ä»»åŠ¡ï¼Œå¹¶æé«˜æ¨¡åž‹çš„æ€§èƒ½å’Œé²æ£’æ€§ã€‚æœªæ¥ï¼Œå¯ä»¥è¿›ä¸€æ­¥ç ”ç©¶å¦‚ä½•å°†CLARGAåº”ç”¨äºŽæ›´å¤§è§„æ¨¡çš„å¤šæ¨¡æ€æ•°æ®ï¼Œå¹¶æŽ¢ç´¢æ›´æœ‰æ•ˆçš„å›¾ç»“æž„å­¦ä¹ æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We introduce CLARGA, a general-purpose multimodal fusion architecture for multimodal representation learning that works with any number and type of modalities without changing the underlying framework. Given a supervised dataset, CLARGA can be applied to virtually any machine learning task to fuse different multimodal representations for processing by downstream layers. On a sample-by-sample basis, CLARGA learns how modalities should inform one another by building an attention weighted graph over their features and passing messages along this graph with a multi-head Graph Attention Network. Not only does this make CLARGA highly adaptive, as it constructs unique graphs for different samples, it makes for efficient fusion with sub-quadratic complexity as the number of modalities grows. Through a learnable mask, it can also adapt to missing modality inputs. The model is trained with a hybrid objective that combines a supervised task loss with contrastive InfoNCE loss, improving cross-modal consistency and robustness to noisy inputs. We demonstrate CLARGA's effectiveness in diverse multimodal representation learning tasks across 7 datasets spanning finance, human-computer interaction, general multimedia classification, and affective computing. It consistently outperforms baselines, state-of-the-art models, and ablations. Additional experiments also demonstrate its robustness to missing inputs and ability to excel on niche tasks. Overall, CLARGA can be easily plugged into machine learning models for effective and efficient learning of representations across a wide variety of tasks.

