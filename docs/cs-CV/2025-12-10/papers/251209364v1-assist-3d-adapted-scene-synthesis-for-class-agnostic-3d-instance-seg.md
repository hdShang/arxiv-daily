---
layout: default
title: ASSIST-3D: Adapted Scene Synthesis for Class-Agnostic 3D Instance Segmentation
---

# ASSIST-3D: Adapted Scene Synthesis for Class-Agnostic 3D Instance Segmentation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.09364" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.09364v1</a>
  <a href="https://arxiv.org/pdf/2512.09364.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.09364v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.09364v1', 'ASSIST-3D: Adapted Scene Synthesis for Class-Agnostic 3D Instance Segmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shengchao Zhou, Jiehong Lin, Jiahui Liu, Shizhen Zhao, Chirui Chang, Xiaojuan Qi

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-10

**å¤‡æ³¨**: Accepted by AAAI 2026

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ASSIST-3Dï¼šç”¨äºç±»åˆ«æ— å…³3Då®ä¾‹åˆ†å‰²çš„è‡ªé€‚åº”åœºæ™¯åˆæˆ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `3Då®ä¾‹åˆ†å‰²` `åœºæ™¯åˆæˆ` `æ•°æ®å¢å¼º` `å¤§å‹è¯­è¨€æ¨¡å‹` `ç‚¹äº‘` `æœºå™¨äºº` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç±»åˆ«æ— å…³3Då®ä¾‹åˆ†å‰²é¢ä¸´ç¼ºä¹æ ‡æ³¨æ•°æ®å’Œç°æœ‰æ–¹æ³•æ³›åŒ–æ€§å·®çš„æŒ‘æˆ˜ã€‚
2. ASSIST-3Dé€šè¿‡å¼‚æ„å¯¹è±¡é€‰æ‹©ã€LLMå¼•å¯¼çš„åœºæ™¯å¸ƒå±€å’ŒçœŸå®ç‚¹äº‘æ„å»ºæ¥åˆæˆé«˜è´¨é‡è®­ç»ƒæ•°æ®ã€‚
3. å®éªŒè¡¨æ˜ï¼Œä½¿ç”¨ASSIST-3Dç”Ÿæˆçš„æ•°æ®è®­ç»ƒçš„æ¨¡å‹åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºASSIST-3Dçš„è‡ªé€‚åº”3Dåœºæ™¯åˆæˆæµç¨‹ï¼Œç”¨äºç±»åˆ«æ— å…³çš„3Då®ä¾‹åˆ†å‰²ï¼Œæ—¨åœ¨åˆæˆåˆé€‚çš„æ•°æ®ä»¥å¢å¼ºæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚ç°æœ‰æ–¹æ³•ç”±äºç¼ºä¹å¸¦æ ‡æ³¨çš„3Dåœºæ™¯æ•°æ®æˆ–2Dåˆ†å‰²çš„å™ªå£°è€Œéš¾ä»¥æ³›åŒ–ã€‚è™½ç„¶åˆæˆæ•°æ®ç”Ÿæˆæä¾›äº†ä¸€ä¸ªæœ‰å¸Œæœ›çš„è§£å†³æ–¹æ¡ˆï¼Œä½†ç°æœ‰çš„3Dåœºæ™¯åˆæˆæ–¹æ³•æ— æ³•åŒæ—¶æ»¡è¶³å‡ ä½•å¤šæ ·æ€§ã€ä¸Šä¸‹æ–‡å¤æ‚æ€§å’Œå¸ƒå±€åˆç†æ€§ï¼Œè€Œè¿™äº›å¯¹äºè¯¥ä»»åŠ¡è‡³å…³é‡è¦ã€‚ASSIST-3Då…·æœ‰ä¸‰ä¸ªå…³é”®åˆ›æ–°ï¼š1) ä»å¹¿æ³›çš„3D CADèµ„äº§é›†åˆä¸­è¿›è¡Œå¼‚æ„å¯¹è±¡é€‰æ‹©ï¼Œåœ¨å¯¹è±¡é‡‡æ ·ä¸­åŠ å…¥éšæœºæ€§ä»¥æœ€å¤§åŒ–å‡ ä½•å’Œä¸Šä¸‹æ–‡å¤šæ ·æ€§ï¼›2) é€šè¿‡LLMå¼•å¯¼çš„ç©ºé—´æ¨ç†ç»“åˆæ·±åº¦ä¼˜å…ˆæœç´¢æ¥ç”Ÿæˆåˆç†çš„ç‰©ä½“å¸ƒå±€ï¼›3) é€šè¿‡å¤šè§†è§’RGB-Då›¾åƒæ¸²æŸ“å’Œèåˆæ¥æ„å»ºé€¼çœŸçš„ç‚¹äº‘ï¼Œä»è€Œç´§å¯†æ¨¡ä»¿çœŸå®ä¸–ç•Œçš„ä¼ æ„Ÿå™¨æ•°æ®é‡‡é›†ã€‚åœ¨ScanNetV2ã€ScanNet++å’ŒS3DISåŸºå‡†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œä½¿ç”¨ASSIST-3Dç”Ÿæˆçš„æ•°æ®è®­ç»ƒçš„æ¨¡å‹æ˜æ˜¾ä¼˜äºç°æœ‰æ–¹æ³•ã€‚è¿›ä¸€æ­¥çš„æ¯”è¾ƒçªå‡ºäº†æˆ‘ä»¬ä¸“é—¨æ„å»ºçš„æµç¨‹ä¼˜äºç°æœ‰çš„3Dåœºæ™¯åˆæˆæ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç±»åˆ«æ— å…³çš„3Då®ä¾‹åˆ†å‰²æ—¨åœ¨åˆ†å‰²åœºæ™¯ä¸­æ‰€æœ‰å¯¹è±¡å®ä¾‹ï¼ŒåŒ…æ‹¬ä¹‹å‰æœªè§è¿‡çš„å¯¹è±¡ï¼Œè€Œä¸ä¾èµ–äºè¯­ä¹‰ç±»åˆ«ä¿¡æ¯ã€‚ç°æœ‰æ–¹æ³•ç”±äºç¼ºä¹å¸¦æ ‡æ³¨çš„3Dåœºæ™¯æ•°æ®ï¼Œæˆ–è€…ä¾èµ–äºæœ‰å™ªå£°çš„2Dåˆ†å‰²ç»“æœï¼Œå¯¼è‡´æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚ç°æœ‰çš„3Dåœºæ™¯åˆæˆæ–¹æ³•éš¾ä»¥åŒæ—¶ä¿è¯å‡ ä½•å¤šæ ·æ€§ã€ä¸Šä¸‹æ–‡å¤æ‚æ€§å’Œå¸ƒå±€åˆç†æ€§ï¼Œè¿™é™åˆ¶äº†åˆæˆæ•°æ®å¯¹æ¨¡å‹è®­ç»ƒçš„æœ‰æ•ˆæ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šASSIST-3Dçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ä¸€ä¸ªä¸“é—¨è®¾è®¡çš„3Dåœºæ™¯åˆæˆæµç¨‹ï¼Œç”Ÿæˆé«˜è´¨é‡çš„åˆæˆæ•°æ®ï¼Œç”¨äºè®­ç»ƒç±»åˆ«æ— å…³çš„3Då®ä¾‹åˆ†å‰²æ¨¡å‹ã€‚è¯¥æµç¨‹æ—¨åœ¨å…‹æœç°æœ‰åˆæˆæ–¹æ³•çš„å±€é™æ€§ï¼ŒåŒæ—¶æ»¡è¶³å‡ ä½•å¤šæ ·æ€§ã€ä¸Šä¸‹æ–‡å¤æ‚æ€§å’Œå¸ƒå±€åˆç†æ€§çš„è¦æ±‚ã€‚é€šè¿‡åœ¨åˆæˆæ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œæé«˜æ¨¡å‹åœ¨çœŸå®ä¸–ç•Œåœºæ™¯ä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šASSIST-3DåŒ…å«ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š1) å¼‚æ„å¯¹è±¡é€‰æ‹©ï¼šä»å¤§é‡çš„3D CADæ¨¡å‹åº“ä¸­éšæœºé€‰æ‹©å¯¹è±¡ï¼Œä»¥å¢åŠ å‡ ä½•å’Œä¸Šä¸‹æ–‡çš„å¤šæ ·æ€§ã€‚2) åœºæ™¯å¸ƒå±€ç”Ÿæˆï¼šåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œç©ºé—´æ¨ç†ï¼Œç»“åˆæ·±åº¦ä¼˜å…ˆæœç´¢ç®—æ³•ï¼Œç”Ÿæˆåˆç†çš„ç‰©ä½“å¸ƒå±€ã€‚3) çœŸå®ç‚¹äº‘æ„å»ºï¼šé€šè¿‡å¤šè§†è§’RGB-Då›¾åƒæ¸²æŸ“å’Œèåˆï¼Œç”Ÿæˆé€¼çœŸçš„ç‚¹äº‘æ•°æ®ï¼Œæ¨¡æ‹ŸçœŸå®ä¼ æ„Ÿå™¨çš„æ•°æ®é‡‡é›†è¿‡ç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šASSIST-3Dçš„å…³é”®åˆ›æ–°åœ¨äºå…¶å®šåˆ¶åŒ–çš„3Dåœºæ™¯åˆæˆæµç¨‹ï¼Œè¯¥æµç¨‹ä¸“é—¨ä¸ºç±»åˆ«æ— å…³çš„3Då®ä¾‹åˆ†å‰²ä»»åŠ¡è®¾è®¡ã€‚ä¸ç°æœ‰çš„é€šç”¨3Dåœºæ™¯åˆæˆæ–¹æ³•ç›¸æ¯”ï¼ŒASSIST-3Dæ›´åŠ å…³æ³¨å‡ ä½•å¤šæ ·æ€§ã€ä¸Šä¸‹æ–‡å¤æ‚æ€§å’Œå¸ƒå±€åˆç†æ€§ï¼Œä»è€Œç”Ÿæˆæ›´é€‚åˆæ¨¡å‹è®­ç»ƒçš„æ•°æ®ã€‚æ­¤å¤–ï¼Œåˆ©ç”¨LLMè¿›è¡Œç©ºé—´æ¨ç†ä¹Ÿæ˜¯ä¸€ä¸ªé‡è¦çš„åˆ›æ–°ç‚¹ï¼Œå¯ä»¥ç”Ÿæˆæ›´ç¬¦åˆäººç±»ç›´è§‰çš„åœºæ™¯å¸ƒå±€ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å¼‚æ„å¯¹è±¡é€‰æ‹©ä¸­ï¼Œé‡‡ç”¨äº†éšæœºé‡‡æ ·ç­–ç•¥ï¼Œä»¥æœ€å¤§åŒ–å‡ ä½•å’Œä¸Šä¸‹æ–‡çš„å¤šæ ·æ€§ã€‚åœ¨åœºæ™¯å¸ƒå±€ç”Ÿæˆä¸­ï¼ŒLLMè¢«ç”¨äºæŒ‡å¯¼ç‰©ä½“çš„ä½ç½®å’Œæ–¹å‘ï¼Œæ·±åº¦ä¼˜å…ˆæœç´¢ç®—æ³•ç”¨äºç¡®ä¿ç‰©ä½“ä¹‹é—´çš„åˆç†å…³ç³»ã€‚åœ¨çœŸå®ç‚¹äº‘æ„å»ºä¸­ï¼Œé‡‡ç”¨äº†å¤šè§†è§’æ¸²æŸ“å’ŒèåˆæŠ€æœ¯ï¼Œä»¥ç”Ÿæˆå…·æœ‰çœŸå®æ„Ÿçš„ç‚¹äº‘æ•°æ®ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ï¼ˆæœªçŸ¥ï¼‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨ASSIST-3Dç”Ÿæˆçš„æ•°æ®è®­ç»ƒçš„æ¨¡å‹åœ¨ScanNetV2ã€ScanNet++å’ŒS3DISç­‰æ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨ScanNetV2æ•°æ®é›†ä¸Šï¼Œä½¿ç”¨ASSIST-3Dè®­ç»ƒçš„æ¨¡å‹åœ¨ç±»åˆ«æ— å…³çš„3Då®ä¾‹åˆ†å‰²ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼ˆå…·ä½“æ•°å€¼æœªçŸ¥ï¼‰ã€‚ä¸å…¶ä»–3Dåœºæ™¯åˆæˆæ–¹æ³•ç›¸æ¯”ï¼ŒASSIST-3Dä¹Ÿè¡¨ç°å‡ºæ˜æ˜¾çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ASSIST-3Dç”Ÿæˆçš„åˆæˆæ•°æ®å¯ç”¨äºè®­ç»ƒå„ç§3Dåœºæ™¯ç†è§£æ¨¡å‹ï¼Œä¾‹å¦‚æœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ã€å®¤å†…åœºæ™¯é‡å»ºç­‰ã€‚é€šè¿‡æé«˜æ¨¡å‹åœ¨æœªè§è¿‡çš„åœºæ™¯å’Œå¯¹è±¡ä¸Šçš„æ³›åŒ–èƒ½åŠ›ï¼Œå¯ä»¥æ˜¾è‘—æå‡è¿™äº›åº”ç”¨åœ¨å®é™…ç¯å¢ƒä¸­çš„æ€§èƒ½å’Œå¯é æ€§ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯å¯ä»¥æ‰©å±•åˆ°å…¶ä»–3Dè§†è§‰ä»»åŠ¡ï¼Œä¾‹å¦‚3Dç›®æ ‡æ£€æµ‹å’Œè¯­ä¹‰åˆ†å‰²ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Class-agnostic 3D instance segmentation tackles the challenging task of segmenting all object instances, including previously unseen ones, without semantic class reliance. Current methods struggle with generalization due to the scarce annotated 3D scene data or noisy 2D segmentations. While synthetic data generation offers a promising solution, existing 3D scene synthesis methods fail to simultaneously satisfy geometry diversity, context complexity, and layout reasonability, each essential for this task. To address these needs, we propose an Adapted 3D Scene Synthesis pipeline for class-agnostic 3D Instance SegmenTation, termed as ASSIST-3D, to synthesize proper data for model generalization enhancement. Specifically, ASSIST-3D features three key innovations, including 1) Heterogeneous Object Selection from extensive 3D CAD asset collections, incorporating randomness in object sampling to maximize geometric and contextual diversity; 2) Scene Layout Generation through LLM-guided spatial reasoning combined with depth-first search for reasonable object placements; and 3) Realistic Point Cloud Construction via multi-view RGB-D image rendering and fusion from the synthetic scenes, closely mimicking real-world sensor data acquisition. Experiments on ScanNetV2, ScanNet++, and S3DIS benchmarks demonstrate that models trained with ASSIST-3D-generated data significantly outperform existing methods. Further comparisons underscore the superiority of our purpose-built pipeline over existing 3D scene synthesis approaches.

