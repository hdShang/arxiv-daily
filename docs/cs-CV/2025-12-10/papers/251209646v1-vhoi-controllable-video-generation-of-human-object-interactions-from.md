---
layout: default
title: VHOI: Controllable Video Generation of Human-Object Interactions from Sparse Trajectories via Motion Densification
---

# VHOI: Controllable Video Generation of Human-Object Interactions from Sparse Trajectories via Motion Densification

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.09646" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.09646v1</a>
  <a href="https://arxiv.org/pdf/2512.09646.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.09646v1" onclick="toggleFavorite(this, '2512.09646v1', 'VHOI: Controllable Video Generation of Human-Object Interactions from Sparse Trajectories via Motion Densification')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wanyue Zhang, Lin Geng Foo, Thabo Beeler, Rishabh Dabral, Christian Theobalt

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-10

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**VHOIï¼šé€šè¿‡è¿åŠ¨ç¨ å¯†åŒ–ï¼Œä»ç¨€ç–è½¨è¿¹æ§åˆ¶äººä½“-ç‰©ä½“äº¤äº’è§†é¢‘ç”Ÿæˆ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)** **æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction)**

**å…³é”®è¯**: `è§†é¢‘ç”Ÿæˆ` `äººä½“-ç‰©ä½“äº¤äº’` `å¯æ§ç”Ÿæˆ` `è¿åŠ¨ç¨ å¯†åŒ–` `æ‰©æ•£æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¯æ§è§†é¢‘ç”Ÿæˆæ–¹æ³•åœ¨ç¨€ç–æ§åˆ¶ï¼ˆæ˜“äºæŒ‡å®šä½†ç¼ºä¹å®ä¾‹æ„ŸçŸ¥ï¼‰å’Œå¯†é›†ä¿¡å·ï¼ˆä¿¡æ¯ä¸°å¯Œä½†è·å–æˆæœ¬é«˜æ˜‚ï¼‰ä¹‹é—´å­˜åœ¨æƒè¡¡ã€‚
2. VHOIé€šè¿‡ä¸¤é˜¶æ®µæ¡†æ¶è§£å†³è¯¥é—®é¢˜ï¼šé¦–å…ˆå°†ç¨€ç–è½¨è¿¹ç¨ å¯†åŒ–ä¸ºHOIæ©ç åºåˆ—ï¼Œç„¶åæ ¹æ®è¿™äº›å¯†é›†æ©ç å¾®è°ƒè§†é¢‘æ‰©æ•£æ¨¡å‹ã€‚
3. VHOIå¼•å…¥HOIæ„ŸçŸ¥è¿åŠ¨è¡¨ç¤ºï¼Œä½¿ç”¨é¢œè‰²ç¼–ç åŒºåˆ†äººç±»å’Œç‰©ä½“çš„è¿åŠ¨ï¼Œä»¥åŠèº«ä½“éƒ¨ä½ç‰¹å®šçš„åŠ¨æ€ï¼Œå®éªŒç»“æœè¡¨æ˜å…¶æ€§èƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨è§†é¢‘ä¸­åˆæˆé€¼çœŸçš„äººä½“-ç‰©ä½“äº¤äº’ï¼ˆHOIï¼‰æå…·æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºäººç±»å’Œç‰©ä½“ä¹‹é—´å­˜åœ¨å¤æ‚çš„ã€ç‰¹å®šäºå®ä¾‹çš„äº¤äº’åŠ¨æ€ã€‚åœ¨è§†é¢‘ç”Ÿæˆä¸­åŠ å…¥å¯æ§æ€§è¿›ä¸€æ­¥å¢åŠ äº†å¤æ‚æ€§ã€‚ç°æœ‰çš„å¯æ§è§†é¢‘ç”Ÿæˆæ–¹æ³•é¢ä¸´ä¸€ä¸ªæƒè¡¡ï¼šè¯¸å¦‚å…³é”®ç‚¹è½¨è¿¹ä¹‹ç±»çš„ç¨€ç–æ§åˆ¶æ˜“äºæŒ‡å®šï¼Œä½†ç¼ºä¹å®ä¾‹æ„ŸçŸ¥ï¼›è€Œè¯¸å¦‚å…‰æµã€æ·±åº¦æˆ–3Dç½‘æ ¼ä¹‹ç±»çš„å¯†é›†ä¿¡å·ä¿¡æ¯ä¸°å¯Œï¼Œä½†è·å–æˆæœ¬é«˜æ˜‚ã€‚æˆ‘ä»¬æå‡ºäº†VHOIï¼Œè¿™æ˜¯ä¸€ä¸ªä¸¤é˜¶æ®µæ¡†æ¶ï¼Œå®ƒé¦–å…ˆå°†ç¨€ç–è½¨è¿¹ç¨ å¯†åŒ–ä¸ºHOIæ©ç åºåˆ—ï¼Œç„¶åæ ¹æ®è¿™äº›å¯†é›†æ©ç å¾®è°ƒè§†é¢‘æ‰©æ•£æ¨¡å‹ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°é¢–çš„HOIæ„ŸçŸ¥è¿åŠ¨è¡¨ç¤ºï¼Œå®ƒä½¿ç”¨é¢œè‰²ç¼–ç æ¥åŒºåˆ†äººç±»å’Œç‰©ä½“çš„è¿åŠ¨ï¼Œä»¥åŠèº«ä½“éƒ¨ä½ç‰¹å®šçš„åŠ¨æ€ã€‚è¿™ç§è®¾è®¡å°†äººç±»å…ˆéªŒçŸ¥è¯†èå…¥åˆ°æ¡ä»¶ä¿¡å·ä¸­ï¼Œå¹¶å¢å¼ºäº†æ¨¡å‹ç†è§£å’Œç”Ÿæˆé€¼çœŸHOIåŠ¨æ€çš„èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ï¼ŒVHOIåœ¨å¯æ§HOIè§†é¢‘ç”Ÿæˆæ–¹é¢å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚VHOIä¸ä»…é™äºä»…äº¤äº’åœºæ™¯ï¼Œè¿˜å¯ä»¥ç«¯åˆ°ç«¯åœ°ç”Ÿæˆå®Œæ•´çš„äººç±»å¯¼èˆªï¼Œä»è€Œå®ç°ä¸ç‰©ä½“çš„äº¤äº’ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¯æ§äººä½“-ç‰©ä½“äº¤äº’ï¼ˆHOIï¼‰è§†é¢‘ç”Ÿæˆé—®é¢˜ã€‚ç°æœ‰æ–¹æ³•è¦ä¹ˆä½¿ç”¨ç¨€ç–æ§åˆ¶ä¿¡å·ï¼ˆå¦‚å…³é”®ç‚¹è½¨è¿¹ï¼‰ï¼Œç¼ºä¹å®ä¾‹æ„ŸçŸ¥èƒ½åŠ›ï¼Œéš¾ä»¥ç”Ÿæˆé€¼çœŸçš„äº¤äº’ï¼›è¦ä¹ˆä½¿ç”¨å¯†é›†ä¿¡å·ï¼ˆå¦‚å…‰æµã€æ·±åº¦ï¼‰ï¼Œè·å–æˆæœ¬é«˜æ˜‚ï¼Œé™åˆ¶äº†åº”ç”¨èŒƒå›´ã€‚å› æ­¤ï¼Œå¦‚ä½•åœ¨ä¿è¯å¯æ§æ€§çš„å‰æä¸‹ï¼Œç”Ÿæˆé«˜è´¨é‡ã€é€¼çœŸçš„HOIè§†é¢‘æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†ç¨€ç–çš„æ§åˆ¶ä¿¡å·ï¼ˆå¦‚å…³é”®ç‚¹è½¨è¿¹ï¼‰è½¬åŒ–ä¸ºå¯†é›†çš„HOIæ©ç åºåˆ—ï¼Œç„¶ååˆ©ç”¨è¿™äº›å¯†é›†çš„æ©ç åºåˆ—ä½œä¸ºæ¡ä»¶ï¼Œé©±åŠ¨è§†é¢‘æ‰©æ•£æ¨¡å‹ç”Ÿæˆæœ€ç»ˆçš„è§†é¢‘ã€‚é€šè¿‡è¿™ç§ä¸¤é˜¶æ®µçš„æ–¹æ³•ï¼Œæ—¢ä¿ç•™äº†ç¨€ç–æ§åˆ¶çš„å¯æ§æ€§ï¼Œåˆåˆ©ç”¨äº†å¯†é›†æ©ç çš„ä¿¡æ¯ä¸°å¯Œæ€§ï¼Œä»è€Œç”Ÿæˆæ›´é€¼çœŸçš„HOIè§†é¢‘ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVHOIæ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼š1) **è¿åŠ¨ç¨ å¯†åŒ–é˜¶æ®µ**ï¼šå°†ç¨€ç–çš„äººä½“å’Œç‰©ä½“è½¨è¿¹ä½œä¸ºè¾“å…¥ï¼Œç”Ÿæˆå¯†é›†çš„HOIæ©ç åºåˆ—ã€‚è¯¥é˜¶æ®µçš„å…³é”®æ˜¯HOI-awareè¿åŠ¨è¡¨ç¤ºï¼Œå®ƒä½¿ç”¨é¢œè‰²ç¼–ç æ¥åŒºåˆ†äººç±»å’Œç‰©ä½“çš„è¿åŠ¨ï¼Œä»¥åŠèº«ä½“éƒ¨ä½ç‰¹å®šçš„åŠ¨æ€ã€‚2) **è§†é¢‘ç”Ÿæˆé˜¶æ®µ**ï¼šä½¿ç”¨è¿åŠ¨ç¨ å¯†åŒ–é˜¶æ®µç”Ÿæˆçš„HOIæ©ç åºåˆ—ä½œä¸ºæ¡ä»¶ï¼Œå¾®è°ƒä¸€ä¸ªè§†é¢‘æ‰©æ•£æ¨¡å‹ï¼Œç”Ÿæˆæœ€ç»ˆçš„HOIè§†é¢‘ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†HOI-awareè¿åŠ¨è¡¨ç¤ºã€‚è¯¥è¡¨ç¤ºä¸ä»…åŒºåˆ†äº†äººç±»å’Œç‰©ä½“çš„è¿åŠ¨ï¼Œè¿˜åŒºåˆ†äº†èº«ä½“éƒ¨ä½ç‰¹å®šçš„åŠ¨æ€ã€‚è¿™ç§è®¾è®¡å°†äººç±»å…ˆéªŒçŸ¥è¯†èå…¥åˆ°æ¡ä»¶ä¿¡å·ä¸­ï¼Œå¢å¼ºäº†æ¨¡å‹ç†è§£å’Œç”Ÿæˆé€¼çœŸHOIåŠ¨æ€çš„èƒ½åŠ›ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒVHOIçš„è¿åŠ¨è¡¨ç¤ºæ›´å…·è¡¨è¾¾èƒ½åŠ›ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰HOIçš„å¤æ‚åŠ¨æ€ã€‚

**å…³é”®è®¾è®¡**ï¼šHOI-awareè¿åŠ¨è¡¨ç¤ºä½¿ç”¨é¢œè‰²ç¼–ç æ¥è¡¨ç¤ºä¸åŒçš„è¿åŠ¨ä¿¡æ¯ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥ä½¿ç”¨ä¸åŒçš„é¢œè‰²é€šé“æ¥è¡¨ç¤ºäººä½“å’Œç‰©ä½“çš„è¿åŠ¨ï¼Œä»¥åŠä¸åŒèº«ä½“éƒ¨ä½çš„è¿åŠ¨ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜å¯èƒ½ä½¿ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥è®­ç»ƒè¿åŠ¨ç¨ å¯†åŒ–æ¨¡å‹ï¼Œä»¥ç¡®ä¿ç”Ÿæˆçš„HOIæ©ç åºåˆ—ä¸è¾“å…¥çš„ç¨€ç–è½¨è¿¹ä¸€è‡´ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ•æ‰åˆ°HOIçš„åŠ¨æ€ä¿¡æ¯ã€‚è§†é¢‘ç”Ÿæˆé˜¶æ®µï¼Œæ‰©æ•£æ¨¡å‹é€šå¸¸ä¼šé‡‡ç”¨U-Netç»“æ„ï¼Œå¹¶ä½¿ç”¨HOIæ©ç åºåˆ—ä½œä¸ºæ¡ä»¶è¾“å…¥åˆ°U-Netçš„ä¸­é—´å±‚æˆ–è¾“å…¥å±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒVHOIåœ¨å¯æ§HOIè§†é¢‘ç”Ÿæˆæ–¹é¢å–å¾—äº†state-of-the-artçš„ç»“æœã€‚é€šè¿‡ä¸ç°æœ‰æ–¹æ³•çš„å¯¹æ¯”ï¼ŒVHOIèƒ½å¤Ÿç”Ÿæˆæ›´é€¼çœŸã€æ›´å¯æ§çš„HOIè§†é¢‘ã€‚è®ºæ–‡å±•ç¤ºäº†VHOIåœ¨ä¸åŒåœºæ™¯ä¸‹çš„ç”Ÿæˆæ•ˆæœï¼ŒåŒ…æ‹¬äººä¸ç‰©ä½“çš„äº¤äº’ã€äººä¸ç¯å¢ƒçš„äº¤äº’ç­‰ï¼Œè¯æ˜äº†VHOIçš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

VHOIæŠ€æœ¯åœ¨è™šæ‹Ÿç°å®ã€æ¸¸æˆå¼€å‘ã€ç”µå½±åˆ¶ä½œç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥ç”¨äºç”Ÿæˆé€¼çœŸçš„äººæœºäº¤äº’åœºæ™¯ï¼Œä¾‹å¦‚è™šæ‹ŸåŠ©æ‰‹ã€æ¸¸æˆè§’è‰²äº¤äº’ã€ç”µå½±ç‰¹æ•ˆç­‰ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥ç”¨äºè®­ç»ƒæœºå™¨äººï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œæ‰§è¡Œä¸äººç±»çš„äº¤äº’ä»»åŠ¡ã€‚æœªæ¥ï¼ŒVHOIæœ‰æœ›æˆä¸ºäººæœºäº¤äº’é¢†åŸŸçš„é‡è¦æŠ€æœ¯æ”¯æ’‘ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Synthesizing realistic human-object interactions (HOI) in video is challenging due to the complex, instance-specific interaction dynamics of both humans and objects. Incorporating controllability in video generation further adds to the complexity. Existing controllable video generation approaches face a trade-off: sparse controls like keypoint trajectories are easy to specify but lack instance-awareness, while dense signals such as optical flow, depths or 3D meshes are informative but costly to obtain. We propose VHOI, a two-stage framework that first densifies sparse trajectories into HOI mask sequences, and then fine-tunes a video diffusion model conditioned on these dense masks. We introduce a novel HOI-aware motion representation that uses color encodings to distinguish not only human and object motion, but also body-part-specific dynamics. This design incorporates a human prior into the conditioning signal and strengthens the model's ability to understand and generate realistic HOI dynamics. Experiments demonstrate state-of-the-art results in controllable HOI video generation. VHOI is not limited to interaction-only scenarios and can also generate full human navigation leading up to object interactions in an end-to-end manner. Project page: https://vcai.mpi-inf.mpg.de/projects/vhoi/.

