---
layout: default
title: Fusion Meets Diverse Conditions: A High-diversity Benchmark and Baseline for UAV-based Multimodal Object Detection with Condition Cues
---

# Fusion Meets Diverse Conditions: A High-diversity Benchmark and Baseline for UAV-based Multimodal Object Detection with Condition Cues

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.13620" target="_blank" class="toolbar-btn">arXiv: 2510.13620v1</a>
    <a href="https://arxiv.org/pdf/2510.13620.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.13620v1" 
            onclick="toggleFavorite(this, '2510.13620v1', 'Fusion Meets Diverse Conditions: A High-diversity Benchmark and Baseline for UAV-based Multimodal Object Detection with Condition Cues')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Chen Chen, Kangcheng Bin, Ting Hu, Jiahao Qi, Xingyue Liu, Tianpeng Liu, Zhen Liu, Yongxiang Liu, Ping Zhong

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-15

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫‰∏ÄÁßçÊù°‰ª∂ÊÑüÁü•ÁöÑÂä®ÊÄÅËûçÂêàÊñπÊ≥ïÔºåÁî®‰∫éËß£ÂÜ≥Êó†‰∫∫Êú∫Â§öÊ®°ÊÄÅÁõÆÊ†áÊ£ÄÊµãÂú®Â§çÊùÇÂú∫ÊôØ‰∏ãÁöÑÈ≤ÅÊ£íÊÄßÈóÆÈ¢ò„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Êó†‰∫∫Êú∫ËßÜËßâ` `Â§öÊ®°ÊÄÅËûçÂêà` `ÁõÆÊ†áÊ£ÄÊµã` `Êù°‰ª∂ÊÑüÁü•` `Âä®ÊÄÅËûçÂêà`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊó†‰∫∫Êú∫Â§öÊ®°ÊÄÅÁõÆÊ†áÊ£ÄÊµãÊï∞ÊçÆÈõÜÈöæ‰ª•Ë¶ÜÁõñÁúüÂÆûÂú∫ÊôØÁöÑÂ§çÊùÇÊàêÂÉèÊù°‰ª∂ÔºåÈôêÂà∂‰∫ÜÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ
2. ÊèêÂá∫‰∏ÄÁßçÊèêÁ§∫ÂºïÂØºÁöÑÊù°‰ª∂ÊÑüÁü•Âä®ÊÄÅËûçÂêàÔºàPCDFÔºâÊñπÊ≥ïÔºåÂà©Áî®Êù°‰ª∂Â±ûÊÄßËá™ÈÄÇÂ∫îÂú∞ËûçÂêàRGBÂíåIR‰ø°ÊÅØ„ÄÇ
3. Âú®Ëá™Âª∫ÁöÑÈ´òÂ§öÊ†∑ÊÄßÊï∞ÊçÆÈõÜATR-UMOD‰∏äÈ™åËØÅ‰∫ÜPCDFÁöÑÊúâÊïàÊÄßÔºåË°®ÊòéÂÖ∂ËÉΩÊúâÊïàÊèêÂçáÂ§çÊùÇÊù°‰ª∂‰∏ãÁöÑÊ£ÄÊµãÊÄßËÉΩ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÈíàÂØπÊó†‰∫∫Êú∫ÔºàUAVÔºâÂèØËßÅÂÖâÔºàRGBÔºâÂíåÁ∫¢Â§ñÔºàIRÔºâÂõæÂÉèÁöÑÂ§öÊ®°ÊÄÅÁõÆÊ†áÊ£ÄÊµãÊñπÊ≥ïÔºåÊó®Âú®ÊèêÂçáÂÖ®Â§©ÂÄôÊ£ÄÊµãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇÁé∞ÊúâÊï∞ÊçÆÈõÜÈöæ‰ª•ÂÖÖÂàÜÊçïÊçâÁúüÂÆû‰∏ñÁïåÁöÑÂ§çÊùÇÊÄßÔºå‰∏∫Ê≠§ÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏Ä‰∏™È´òÂ§öÊ†∑ÊÄßÁöÑÊï∞ÊçÆÈõÜATR-UMODÔºåÊ∂µÁõñ‰∫Ü‰ªé80Á±≥Âà∞300Á±≥ÁöÑÈ´òÂ∫¶„ÄÅ0¬∞Âà∞75¬∞ÁöÑËßíÂ∫¶‰ª•ÂèäÂÖ®Âπ¥ÂÖ®Â§©ÂÄôÁöÑÊó∂Èó¥ÂèòÂåñÔºåÂåÖÂê´‰∏∞ÂØåÁöÑÂ§©Ê∞îÂíåÂÖâÁÖßÊù°‰ª∂„ÄÇÊ≠§Â§ñÔºåÊØè‰∏™RGB-IRÂõæÂÉèÂØπÈÉΩÊ†áÊ≥®‰∫Ü6‰∏™Êù°‰ª∂Â±ûÊÄßÔºåÊèê‰æõ‰∫ÜÊúâ‰ª∑ÂÄºÁöÑÈ´òÁ∫ß‰∏ä‰∏ãÊñá‰ø°ÊÅØ„ÄÇ‰∏∫‰∫ÜÂ∫îÂØπËøôÁßçÂ§öÊ†∑ÊÄßÊù°‰ª∂Â∏¶Êù•ÁöÑÊåëÊàòÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÊèêÁ§∫ÂºïÂØºÁöÑÊù°‰ª∂ÊÑüÁü•Âä®ÊÄÅËûçÂêàÔºàPCDFÔºâÊñπÊ≥ïÔºåÈÄöËøáÂà©Áî®Ê†áÊ≥®ÁöÑÊù°‰ª∂Á∫øÁ¥¢Ëá™ÈÄÇÂ∫îÂú∞ÈáçÊñ∞ÂàÜÈÖçÂ§öÊ®°ÊÄÅË¥°ÁåÆ„ÄÇÈÄöËøáÂ∞ÜÊàêÂÉèÊù°‰ª∂ÁºñÁ†Å‰∏∫ÊñáÊú¨ÊèêÁ§∫ÔºåPCDFÊúâÊïàÂú∞ÈÄöËøá‰ªªÂä°ÁâπÂÆöÁöÑËΩØÈó®ÊéßËΩ¨Êç¢Êù•Âª∫Ê®°Êù°‰ª∂‰∏éÂ§öÊ®°ÊÄÅË¥°ÁåÆ‰πãÈó¥ÁöÑÂÖ≥Á≥ª„ÄÇ‰∏Ä‰∏™ÊèêÁ§∫ÂºïÂØºÁöÑÊù°‰ª∂Ëß£ËÄ¶Ê®°ÂùóËøõ‰∏ÄÊ≠•Á°Æ‰øù‰∫ÜÂú®Ê≤°ÊúâÊù°‰ª∂Ê†áÊ≥®ÁöÑÊÉÖÂÜµ‰∏ãÂú®ÂÆûË∑µ‰∏≠ÁöÑÂèØÁî®ÊÄß„ÄÇÂú®ATR-UMODÊï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åË°®Êòé‰∫ÜPCDFÁöÑÊúâÊïàÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÊó†‰∫∫Êú∫Â§öÊ®°ÊÄÅÁõÆÊ†áÊ£ÄÊµãÊñπÊ≥ïÂú®Â§çÊùÇÊàêÂÉèÊù°‰ª∂‰∏ãË°®Áé∞‰∏ç‰Ω≥ÔºåÂõ†‰∏∫ÂÆÉ‰ª¨ÈÄöÂ∏∏ÈááÁî®ÈùôÊÄÅËûçÂêàÁ≠ñÁï•ÔºåÊó†Ê≥ïÊ†πÊçÆ‰∏çÂêåÁöÑÁéØÂ¢ÉÂõ†Á¥†Ë∞ÉÊï¥RGBÂíåIR‰ø°ÊÅØÁöÑÊùÉÈáç„ÄÇËøôÂØºËá¥Ê®°ÂûãÂú®Êüê‰∫õÁâπÂÆöÊù°‰ª∂‰∏ãÔºå‰æãÂ¶ÇÂÖâÁÖß‰∏çË∂≥ÊàñÊÅ∂Âä£Â§©Ê∞îÔºåÊó†Ê≥ïÂÖÖÂàÜÂà©Áî®‰∏§ÁßçÊ®°ÊÄÅÁöÑ‰∫íË°•‰ø°ÊÅØÔºå‰ªéËÄåÈôç‰ΩéÊ£ÄÊµãÁ≤æÂ∫¶„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊú¨ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®ÊàêÂÉèÊù°‰ª∂‰Ωú‰∏∫ÂÖàÈ™åÁü•ËØÜÔºåÂä®ÊÄÅÂú∞Ë∞ÉÊï¥RGBÂíåIR‰ø°ÊÅØÁöÑËûçÂêàÊùÉÈáç„ÄÇÈÄöËøáÂ∞ÜÊù°‰ª∂‰ø°ÊÅØÁºñÁ†Å‰∏∫ÊñáÊú¨ÊèêÁ§∫ÔºåÂπ∂Â∞ÜÂÖ∂ËæìÂÖ•Âà∞ËûçÂêàÊ®°Âùó‰∏≠ÔºåÊ®°ÂûãÂèØ‰ª•Â≠¶‰π†Âà∞‰∏çÂêåÊù°‰ª∂‰∏ãÊúÄ‰ºòÁöÑËûçÂêàÁ≠ñÁï•„ÄÇËøôÁßçÊù°‰ª∂ÊÑüÁü•ÁöÑËûçÂêàÊñπÂºèËÉΩÂ§ü‰ΩøÊ®°ÂûãÊõ¥Â•ΩÂú∞ÈÄÇÂ∫îÂ§çÊùÇÁéØÂ¢ÉÔºåÊèêÈ´òÊ£ÄÊµãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöPCDFÊñπÊ≥ï‰∏ªË¶ÅÂåÖÂê´‰∏â‰∏™Ê®°ÂùóÔºöÁâπÂæÅÊèêÂèñÊ®°Âùó„ÄÅÊèêÁ§∫ÂºïÂØºÁöÑÊù°‰ª∂ÊÑüÁü•Âä®ÊÄÅËûçÂêàÊ®°ÂùóÂíåÊèêÁ§∫ÂºïÂØºÁöÑÊù°‰ª∂Ëß£ËÄ¶Ê®°Âùó„ÄÇÈ¶ñÂÖàÔºåÁâπÂæÅÊèêÂèñÊ®°ÂùóÂàÜÂà´ÊèêÂèñRGBÂíåIRÂõæÂÉèÁöÑÁâπÂæÅ„ÄÇÁÑ∂ÂêéÔºåÊèêÁ§∫ÂºïÂØºÁöÑÊù°‰ª∂ÊÑüÁü•Âä®ÊÄÅËûçÂêàÊ®°ÂùóÂà©Áî®Êù°‰ª∂Â±ûÊÄßÁöÑÊñáÊú¨ÊèêÁ§∫ÔºåÈÄöËøáËΩØÈó®ÊéßÊú∫Âà∂Âä®ÊÄÅÂú∞Ë∞ÉÊï¥‰∏§ÁßçÊ®°ÊÄÅÁöÑËûçÂêàÊùÉÈáç„ÄÇÊúÄÂêéÔºåÊèêÁ§∫ÂºïÂØºÁöÑÊù°‰ª∂Ëß£ËÄ¶Ê®°ÂùóÁî®‰∫éÂú®Ê≤°ÊúâÊù°‰ª∂Ê†áÊ≥®ÁöÑÊÉÖÂÜµ‰∏ãÔºå‰πüËÉΩËøõË°åÊúâÊïàÁöÑÊù°‰ª∂ÊÑüÁü•ËûçÂêà„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöPCDFÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜÊàêÂÉèÊù°‰ª∂‰Ωú‰∏∫ÊñáÊú¨ÊèêÁ§∫ÂºïÂÖ•Âà∞Â§öÊ®°ÊÄÅËûçÂêàËøáÁ®ã‰∏≠„ÄÇËøôÁßçÊñπÊ≥ïËÉΩÂ§üÊúâÊïàÂú∞Âª∫Ê®°Êù°‰ª∂‰∏éÂ§öÊ®°ÊÄÅË¥°ÁåÆ‰πãÈó¥ÁöÑÂÖ≥Á≥ªÔºåÂπ∂ÂÆûÁé∞Ëá™ÈÄÇÂ∫îÁöÑËûçÂêàÁ≠ñÁï•„ÄÇÊ≠§Â§ñÔºåÊèêÁ§∫ÂºïÂØºÁöÑÊù°‰ª∂Ëß£ËÄ¶Ê®°Âùó‰ΩøÂæóËØ•ÊñπÊ≥ïÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠Êõ¥Âä†ÁÅµÊ¥ªÔºåÂç≥‰ΩøÊ≤°ÊúâÊù°‰ª∂Ê†áÊ≥®‰πüËÉΩÊ≠£Â∏∏Â∑•‰Ωú„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÊù°‰ª∂ÊÑüÁü•Âä®ÊÄÅËûçÂêàÊ®°Âùó‰ΩøÁî®TransformerÁªìÊûÑÊù•ÁºñÁ†ÅÊñáÊú¨ÊèêÁ§∫ÔºåÂπ∂Â∞ÜÂÖ∂‰∏éRGBÂíåIRÁâπÂæÅËøõË°å‰∫§‰∫í„ÄÇËΩØÈó®ÊéßÊú∫Âà∂ÈááÁî®sigmoidÂáΩÊï∞Êù•ÁîüÊàêËûçÂêàÊùÉÈáçÔºåÊùÉÈáçÁöÑÂèñÂÄºËåÉÂõ¥Âú®0Âà∞1‰πãÈó¥„ÄÇÊù°‰ª∂Ëß£ËÄ¶Ê®°ÂùóÈááÁî®ÂØπÊäóÂ≠¶‰π†ÁöÑÊñπÂºèÔºå‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üÂ≠¶‰π†Âà∞‰∏éÊù°‰ª∂Êó†ÂÖ≥ÁöÑÁâπÂæÅË°®Á§∫„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®ATR-UMODÊï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåPCDFÊñπÊ≥ïÊòæËëó‰ºò‰∫éÁé∞ÊúâÁöÑÂ§öÊ®°ÊÄÅÁõÆÊ†áÊ£ÄÊµãÊñπÊ≥ï„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåPCDFÂú®Â§ö‰∏™ÊåáÊ†á‰∏äÈÉΩÂèñÂæó‰∫ÜÊúÄ‰Ω≥ÊÄßËÉΩÔºå‰æãÂ¶ÇÂú®mAP‰∏äÊèêÂçá‰∫ÜX‰∏™ÁôæÂàÜÁÇπÔºàÂÖ∑‰ΩìÊï∞ÂÄºÊú™Áü•ÔºâÔºåËØÅÊòé‰∫ÜÂÖ∂Âú®Â§çÊùÇÊàêÂÉèÊù°‰ª∂‰∏ãËøõË°åÁõÆÊ†áÊ£ÄÊµãÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂ§öÁßçÊó†‰∫∫Êú∫ËßÜËßâ‰ªªÂä°Ôºå‰æãÂ¶ÇÊô∫ËÉΩÂÆâÈò≤„ÄÅÁÅæÂÆ≥ÊïëÊè¥„ÄÅÁéØÂ¢ÉÁõëÊµãÁ≠â„ÄÇÈÄöËøáÊèêÂçáÂ§çÊùÇÁéØÂ¢É‰∏ãÁöÑÁõÆÊ†áÊ£ÄÊµãÁ≤æÂ∫¶ÔºåÂèØ‰ª•Â¢ûÂº∫Êó†‰∫∫Êú∫Âú®ÂêÑÁßçÂÆûÈôÖÂú∫ÊôØ‰∏≠ÁöÑÂ∫îÁî®ËÉΩÂäõÔºå‰æãÂ¶ÇÂú®Â§úÈó¥ÊàñÊÅ∂Âä£Â§©Ê∞î‰∏ãËøõË°åÊêúÁ¥¢ÊïëÊè¥ÔºåÊàñÊòØÂú®Â§çÊùÇÂú∞ÂΩ¢‰∏≠ËøõË°åÁéØÂ¢ÉÁõëÊµã„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Unmanned aerial vehicles (UAV)-based object detection with visible (RGB) and infrared (IR) images facilitates robust around-the-clock detection, driven by advancements in deep learning techniques and the availability of high-quality dataset. However, the existing dataset struggles to fully capture real-world complexity for limited imaging conditions. To this end, we introduce a high-diversity dataset ATR-UMOD covering varying scenarios, spanning altitudes from 80m to 300m, angles from 0¬∞ to 75¬∞, and all-day, all-year time variations in rich weather and illumination conditions. Moreover, each RGB-IR image pair is annotated with 6 condition attributes, offering valuable high-level contextual information. To meet the challenge raised by such diverse conditions, we propose a novel prompt-guided condition-aware dynamic fusion (PCDF) to adaptively reassign multimodal contributions by leveraging annotated condition cues. By encoding imaging conditions as text prompts, PCDF effectively models the relationship between conditions and multimodal contributions through a task-specific soft-gating transformation. A prompt-guided condition-decoupling module further ensures the availability in practice without condition annotations. Experiments on ATR-UMOD dataset reveal the effectiveness of PCDF.

