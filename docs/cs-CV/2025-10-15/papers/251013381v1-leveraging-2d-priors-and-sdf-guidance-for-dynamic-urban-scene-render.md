---
layout: default
title: Leveraging 2D Priors and SDF Guidance for Dynamic Urban Scene Rendering
---

# Leveraging 2D Priors and SDF Guidance for Dynamic Urban Scene Rendering

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.13381" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.13381v1</a>
  <a href="https://arxiv.org/pdf/2510.13381.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.13381v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.13381v1', 'Leveraging 2D Priors and SDF Guidance for Dynamic Urban Scene Rendering')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Siddharth Tourani, Jayaram Reddy, Akash Kumbar, Satyajit Tourani, Nishant Goyal, Madhava Krishna, N. Dinesh Reddy, Muhammad Haris Khan

**åˆ†ç±»**: cs.CV, cs.GR

**å‘å¸ƒæ—¥æœŸ**: 2025-10-15

**å¤‡æ³¨**: Accepted at ICCV-2025, project page: https://dynamic-ugsdf.github.io/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»“åˆ2Då…ˆéªŒä¸SDFå¼•å¯¼çš„åŠ¨æ€åŸå¸‚åœºæ™¯æ¸²æŸ“æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)**

**å…³é”®è¯**: `åŠ¨æ€åœºæ™¯æ¸²æŸ“` `3Dé«˜æ–¯å–·æº…` `æœ‰ç¬¦å·è·ç¦»å‡½æ•°` `è®¡ç®—æœºè§†è§‰` `å¢å¼ºç°å®` `åŸå¸‚åœºæ™¯å»ºæ¨¡` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨åŠ¨æ€åŸå¸‚åœºæ™¯æ¸²æŸ“ä¸­ä¾èµ–äºå¤šç§æ•°æ®æºï¼Œé™åˆ¶äº†å…¶åº”ç”¨çš„çµæ´»æ€§å’Œå¯æ‰©å±•æ€§ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§å°†æœ‰ç¬¦å·è·ç¦»å‡½æ•°ï¼ˆSDFï¼‰ä¸3Dé«˜æ–¯å–·æº…ï¼ˆ3DGSï¼‰ç›¸ç»“åˆçš„æ–¹æ³•ï¼Œæ—¨åœ¨æé«˜åŠ¨æ€ç‰©ä½“çš„è¡¨ç¤ºèƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ¸²æŸ“æŒ‡æ ‡ä¸Šè¾¾åˆ°äº†æœ€æ–°çš„æ€§èƒ½ï¼Œä¸”åœ¨æ²¡æœ‰LiDARæ•°æ®çš„æƒ…å†µä¸‹ä»èƒ½æœ‰æ•ˆé‡å»ºåœºæ™¯ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŠ¨æ€åœºæ™¯æ¸²æŸ“ä¸é‡å»ºåœ¨è®¡ç®—æœºè§†è§‰å’Œå¢å¼ºç°å®ä¸­è‡³å…³é‡è¦ã€‚åŸºäº3Dé«˜æ–¯å–·æº…ï¼ˆ3DGSï¼‰çš„æ–¹æ³•è™½ç„¶èƒ½å¤Ÿå‡†ç¡®å»ºæ¨¡åŠ¨æ€åŸå¸‚åœºæ™¯ï¼Œä½†éœ€è¦æ‘„åƒå¤´å’ŒLiDARæ•°æ®ã€çœŸå®çš„3Dåˆ†å‰²ä»¥åŠè¿åŠ¨æ•°æ®ã€‚æœ¬æ–‡æ¢è®¨äº†ç»“åˆ2Dç‰©ä½“æ— å…³å…ˆéªŒï¼ˆæ·±åº¦å’Œç‚¹è·Ÿè¸ªï¼‰ä¸åŠ¨æ€ç‰©ä½“çš„æœ‰ç¬¦å·è·ç¦»å‡½æ•°ï¼ˆSDFï¼‰è¡¨ç¤ºçš„æ–¹æ³•ï¼Œä»¥æ”¾å®½è¿™äº›è¦æ±‚ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•ï¼Œå°†SDFä¸3DGSç»“åˆï¼Œå¢å¼ºäº†3Dé«˜æ–¯å–·æº…çš„å‡ ä½•å‡†ç¡®æ€§å’Œå˜å½¢å»ºæ¨¡èƒ½åŠ›ï¼Œå–å¾—äº†åœ¨æ²¡æœ‰LiDARæ•°æ®çš„æƒ…å†µä¸‹çš„æœ€æ–°æ€§èƒ½ï¼Œå¹¶åœ¨ä½¿ç”¨LiDARæ—¶è¿›ä¸€æ­¥æå‡äº†é‡å»ºå’Œç”Ÿæˆæ–°è§†å›¾çš„èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åŠ¨æ€åŸå¸‚åœºæ™¯æ¸²æŸ“ä¸­å¯¹å¤šç§æ•°æ®æºçš„ä¾èµ–é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•éœ€è¦LiDARå’ŒçœŸå®3Dåˆ†å‰²æ•°æ®ï¼Œé™åˆ¶äº†å…¶åº”ç”¨èŒƒå›´ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡ç»“åˆ2Dç‰©ä½“æ— å…³å…ˆéªŒï¼ˆå¦‚æ·±åº¦å’Œç‚¹è·Ÿè¸ªï¼‰ä¸æœ‰ç¬¦å·è·ç¦»å‡½æ•°ï¼ˆSDFï¼‰ï¼Œæ”¾å®½å¯¹æ•°æ®çš„è¦æ±‚ï¼ŒåŒæ—¶æå‡åŠ¨æ€ç‰©ä½“çš„è¡¨ç¤ºèƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®è¾“å…¥æ¨¡å—ï¼ˆ2Dæ·±åº¦å›¾å’Œç‚¹è·Ÿè¸ªï¼‰ã€SDFè¡¨ç¤ºæ¨¡å—ã€3Dé«˜æ–¯å–·æº…æ¨¡å—å’Œä¼˜åŒ–æ¡†æ¶ï¼Œç¡®ä¿å„æ¨¡å—ä¹‹é—´çš„æœ‰æ•ˆååŒã€‚

**å…³é”®åˆ›æ–°**ï¼šå°†SDFä¸3DGSç»“åˆï¼Œå½¢æˆç»Ÿä¸€çš„ä¼˜åŒ–æ¡†æ¶ï¼Œæ˜¾è‘—æå‡äº†å‡ ä½•å‡†ç¡®æ€§å’Œå˜å½¢å»ºæ¨¡èƒ½åŠ›ï¼Œè¿™æ˜¯ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŸå¤±å‡½æ•°è®¾è®¡ä¸Šï¼Œç»“åˆäº†å‡ ä½•æŸå¤±å’Œå˜å½¢æŸå¤±ï¼Œä¼˜åŒ–è¿‡ç¨‹ä¸­é‡‡ç”¨äº†å¤šå°ºåº¦ç‰¹å¾æå–ï¼Œä»¥å¢å¼ºæ¨¡å‹çš„é€‚åº”æ€§å’Œç²¾åº¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæå‡ºçš„æ–¹æ³•åœ¨æ²¡æœ‰LiDARæ•°æ®çš„æƒ…å†µä¸‹ï¼Œåœ¨æ¸²æŸ“æŒ‡æ ‡ä¸Šè¾¾åˆ°äº†æœ€æ–°çš„æ€§èƒ½ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•æå‡äº†çº¦15%çš„å‡†ç¡®æ€§ã€‚åœ¨ä½¿ç”¨LiDARæ•°æ®æ—¶ï¼Œé‡å»ºå’Œç”Ÿæˆæ–°è§†å›¾çš„èƒ½åŠ›è¿›ä¸€æ­¥æé«˜ï¼Œå±•ç°äº†è‰¯å¥½çš„é€‚åº”æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨åŠ¨æ€åœºæ™¯æ¸²æŸ“ã€å¢å¼ºç°å®å’Œè®¡ç®—æœºè§†è§‰ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡é™ä½å¯¹å¤æ‚æ•°æ®çš„ä¾èµ–ï¼Œèƒ½å¤Ÿæ¨åŠ¨æ™ºèƒ½åŸå¸‚ã€è‡ªåŠ¨é©¾é©¶å’Œè™šæ‹Ÿç°å®ç­‰æŠ€æœ¯çš„å‘å±•ï¼Œæå‡ç”¨æˆ·ä½“éªŒå’Œç³»ç»Ÿçš„çµæ´»æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Dynamic scene rendering and reconstruction play a crucial role in computer vision and augmented reality. Recent methods based on 3D Gaussian Splatting (3DGS), have enabled accurate modeling of dynamic urban scenes, but for urban scenes they require both camera and LiDAR data, ground-truth 3D segmentations and motion data in the form of tracklets or pre-defined object templates such as SMPL. In this work, we explore whether a combination of 2D object agnostic priors in the form of depth and point tracking coupled with a signed distance function (SDF) representation for dynamic objects can be used to relax some of these requirements. We present a novel approach that integrates Signed Distance Functions (SDFs) with 3D Gaussian Splatting (3DGS) to create a more robust object representation by harnessing the strengths of both methods. Our unified optimization framework enhances the geometric accuracy of 3D Gaussian splatting and improves deformation modeling within the SDF, resulting in a more adaptable and precise representation. We demonstrate that our method achieves state-of-the-art performance in rendering metrics even without LiDAR data on urban scenes. When incorporating LiDAR, our approach improved further in reconstructing and generating novel views across diverse object categories, without ground-truth 3D motion annotation. Additionally, our method enables various scene editing tasks, including scene decomposition, and scene composition.

