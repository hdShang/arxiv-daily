---
layout: default
title: Scaling Vision Transformers for Functional MRI with Flat Maps
---

# Scaling Vision Transformers for Functional MRI with Flat Maps

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.13768" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.13768v1</a>
  <a href="https://arxiv.org/pdf/2510.13768.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.13768v1" onclick="toggleFavorite(this, '2510.13768v1', 'Scaling Vision Transformers for Functional MRI with Flat Maps')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Connor Lane, Daniel Z. Kaplan, Tanishq Mathew Abraham, Paul S. Scotti

**åˆ†ç±»**: cs.CV, cs.AI, q-bio.NC

**å‘å¸ƒæ—¥æœŸ**: 2025-10-15

**å¤‡æ³¨**: NeurIPS 2025 Workshop, Foundation Models for the Brain and Body; Code: https://github.com/MedARC-AI/fmri-fm; Discord: https://discord.gg/tVR4TWnRM9

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/MedARC-AI/fmri-fm)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ©ç”¨å¹³é¢å›¾å’Œè§†è§‰Transformeræ‰©å±•åŠŸèƒ½ç£å…±æŒ¯æˆåƒç ”ç©¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åŠŸèƒ½ç£å…±æŒ¯æˆåƒ` `è§†è§‰Transformer` `æ©ç è‡ªç¼–ç å™¨` `è„‘è¿æ¥ç»„` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰fMRIæ•°æ®åˆ†ææ–¹æ³•éš¾ä»¥æœ‰æ•ˆåˆ©ç”¨å¤§è§„æ¨¡æ•°æ®é›†ï¼Œä¸”ç¼ºä¹ä¸æ·±åº¦å­¦ä¹ æ¶æ„çš„æœ‰æ•ˆè¡”æ¥ã€‚
2. è®ºæ–‡æå‡ºå°†4D fMRIæ•°æ®è½¬æ¢ä¸º2Då¹³é¢å›¾è§†é¢‘ï¼Œå¹¶åˆ©ç”¨è§†è§‰Transformerè¿›è¡Œæ—¶ç©ºæ©ç è‡ªç¼–ç å»ºæ¨¡ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸‹æ¸¸åˆ†ç±»ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œèƒ½å¤Ÿè§£ç å—è¯•è€…çŠ¶æ€å’Œä¸ªä½“ç‰¹å¾ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸ºäº†å°†ç°ä»£æ·±åº¦å­¦ä¹ æ¶æ„åº”ç”¨äºåŠŸèƒ½ç£å…±æŒ¯æˆåƒ(fMRI)ï¼Œä¸€ä¸ªå…³é”®é—®é¢˜æ˜¯å¦‚ä½•è¡¨ç¤ºæ¨¡å‹è¾“å…¥çš„æ•°æ®ã€‚ä¸ºäº†å¼¥åˆfMRIå’Œè‡ªç„¶å›¾åƒä¹‹é—´çš„æ¨¡æ€å·®è·ï¼Œæˆ‘ä»¬å°†4Dä½“ç§¯fMRIæ•°æ®è½¬æ¢ä¸º2D fMRIæ´»åŠ¨å¹³é¢å›¾çš„è§†é¢‘ã€‚æˆ‘ä»¬ä½¿ç”¨æ—¶ç©ºæ©ç è‡ªç¼–ç å™¨(MAE)æ¡†æ¶ï¼Œåœ¨æ¥è‡ªäººç±»è¿æ¥ç»„è®¡åˆ’çš„2.3Kå°æ—¶çš„fMRIå¹³é¢å›¾è§†é¢‘ä¸Šè®­ç»ƒè§†è§‰Transformerã€‚æˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œæ©ç fMRIå»ºæ¨¡æ€§èƒ½éšç€æ•°æ®é›†å¤§å°çš„å¢åŠ è€Œä¸¥æ ¼éµå¾ªå¹‚å¾‹ç¼©æ”¾ã€‚ä¸‹æ¸¸åˆ†ç±»åŸºå‡†æµ‹è¯•è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å­¦ä¹ äº†ä¸°å¯Œçš„è¡¨ç¤ºï¼Œæ”¯æŒè·¨å—è¯•è€…çš„ç»†ç²’åº¦çŠ¶æ€è§£ç ï¼Œä»¥åŠè·¨å¤§è„‘çŠ¶æ€å˜åŒ–çš„å—è¯•è€…ç‰¹å®šç‰¹å¾è§£ç ã€‚è¿™é¡¹å·¥ä½œæ˜¯ä¸€ä¸ªæ­£åœ¨è¿›è¡Œçš„å¼€æ”¾ç§‘å­¦é¡¹ç›®çš„ä¸€éƒ¨åˆ†ï¼Œæ—¨åœ¨ä¸ºfMRIæ•°æ®æ„å»ºåŸºç¡€æ¨¡å‹ã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ•°æ®é›†å¯åœ¨https://github.com/MedARC-AI/fmri-fmä¸Šæ‰¾åˆ°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¦‚ä½•å°†å¤§è§„æ¨¡fMRIæ•°æ®æœ‰æ•ˆåœ°è¾“å…¥åˆ°æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯è§†è§‰Transformerä¸­çš„é—®é¢˜ã€‚ç°æœ‰çš„fMRIæ•°æ®å¤„ç†æ–¹æ³•é€šå¸¸éš¾ä»¥ç›´æ¥åº”ç”¨äºæ·±åº¦å­¦ä¹ æ¶æ„ï¼Œå¹¶ä¸”ç¼ºä¹å¯¹æ—¶ç©ºä¿¡æ¯çš„æœ‰æ•ˆåˆ©ç”¨ã€‚æ­¤å¤–ï¼Œå¦‚ä½•åˆ©ç”¨å¤§è§„æ¨¡fMRIæ•°æ®é›†è®­ç»ƒå‡ºå…·æœ‰æ³›åŒ–èƒ½åŠ›çš„æ¨¡å‹ä¹Ÿæ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†4D fMRIæ•°æ®è½¬æ¢ä¸º2D fMRIæ´»åŠ¨å¹³é¢å›¾çš„è§†é¢‘ï¼Œä»è€Œå°†fMRIæ•°æ®è½¬æ¢ä¸ºç±»ä¼¼äºè‡ªç„¶å›¾åƒè§†é¢‘çš„æ•°æ®æ ¼å¼ã€‚è¿™ç§è½¬æ¢ä½¿å¾—å¯ä»¥ç›´æ¥åˆ©ç”¨åœ¨è‡ªç„¶å›¾åƒè§†é¢‘ä¸Šè®­ç»ƒçš„è§†è§‰Transformeræ¶æ„ã€‚é€šè¿‡åœ¨å¤§é‡fMRIå¹³é¢å›¾è§†é¢‘ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œæ¨¡å‹å¯ä»¥å­¦ä¹ åˆ°fMRIæ•°æ®çš„å†…åœ¨ç»“æ„å’Œè¡¨ç¤ºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ­¥éª¤ï¼š1) å°†4D fMRIæ•°æ®è½¬æ¢ä¸º2D fMRIæ´»åŠ¨å¹³é¢å›¾è§†é¢‘ã€‚2) ä½¿ç”¨æ—¶ç©ºæ©ç è‡ªç¼–ç å™¨(MAE)æ¡†æ¶åœ¨å¤§é‡fMRIå¹³é¢å›¾è§†é¢‘ä¸Šé¢„è®­ç»ƒè§†è§‰Transformerã€‚3) åœ¨ä¸‹æ¸¸åˆ†ç±»ä»»åŠ¡ä¸Šè¯„ä¼°é¢„è®­ç»ƒæ¨¡å‹çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬è·¨å—è¯•è€…çš„çŠ¶æ€è§£ç å’Œå—è¯•è€…ç‰¹å®šç‰¹å¾è§£ç ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†fMRIæ•°æ®è½¬æ¢ä¸ºå¹³é¢å›¾è§†é¢‘ï¼Œä»è€Œèƒ½å¤Ÿåˆ©ç”¨è§†è§‰Transformerè¿›è¡Œå»ºæ¨¡ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æ¢ç´¢äº†ä½¿ç”¨æ—¶ç©ºæ©ç è‡ªç¼–ç å™¨(MAE)æ¡†æ¶è¿›è¡ŒfMRIæ•°æ®é¢„è®­ç»ƒçš„æ–¹æ³•ï¼Œå¹¶éªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹èƒ½å¤Ÿå­¦ä¹ åˆ°fMRIæ•°æ®çš„æ—¶ç©ºç‰¹å¾ï¼Œä»è€Œåœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­å–å¾—æ›´å¥½çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä½¿ç”¨äº†è§†è§‰Transformerä½œä¸ºåŸºç¡€æ¨¡å‹ï¼Œå¹¶é‡‡ç”¨äº†æ—¶ç©ºæ©ç è‡ªç¼–ç å™¨(MAE)æ¡†æ¶è¿›è¡Œé¢„è®­ç»ƒã€‚åœ¨MAEæ¡†æ¶ä¸­ï¼Œä¸€éƒ¨åˆ†è¾“å…¥è§†é¢‘å¸§è¢«éšæœºæ©ç›–ï¼Œæ¨¡å‹éœ€è¦æ ¹æ®æœªè¢«æ©ç›–çš„å¸§æ¥é¢„æµ‹è¢«æ©ç›–çš„å¸§ã€‚è¿™ç§é¢„è®­ç»ƒæ–¹å¼å¯ä»¥æœ‰æ•ˆåœ°å­¦ä¹ åˆ°fMRIæ•°æ®çš„æ—¶ç©ºä¾èµ–å…³ç³»ã€‚è®ºæ–‡ä½¿ç”¨äº†æ¥è‡ªäººç±»è¿æ¥ç»„è®¡åˆ’çš„2.3Kå°æ—¶çš„fMRIå¹³é¢å›¾è§†é¢‘è¿›è¡Œè®­ç»ƒï¼Œå¹¶ä½¿ç”¨æ ‡å‡†çš„åˆ†ç±»åŸºå‡†æµ‹è¯•æ¥è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ©ç fMRIå»ºæ¨¡æ€§èƒ½éšç€æ•°æ®é›†å¤§å°çš„å¢åŠ è€Œä¸¥æ ¼éµå¾ªå¹‚å¾‹ç¼©æ”¾ï¼ŒéªŒè¯äº†å¤§è§„æ¨¡æ•°æ®è®­ç»ƒçš„æœ‰æ•ˆæ€§ã€‚ä¸‹æ¸¸åˆ†ç±»åŸºå‡†æµ‹è¯•æ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ åˆ°ä¸°å¯Œçš„è¡¨ç¤ºï¼Œæ”¯æŒè·¨å—è¯•è€…çš„ç»†ç²’åº¦çŠ¶æ€è§£ç ï¼Œä»¥åŠè·¨å¤§è„‘çŠ¶æ€å˜åŒ–çš„å—è¯•è€…ç‰¹å®šç‰¹å¾è§£ç ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°æå–fMRIæ•°æ®ä¸­çš„æœ‰ç”¨ä¿¡æ¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè„‘ç–¾ç—…è¯Šæ–­ã€è®¤çŸ¥çŠ¶æ€è§£ç ã€ä¸ªä½“ç‰¹å¾é¢„æµ‹ç­‰é¢†åŸŸã€‚é€šè¿‡æ„å»ºfMRIæ•°æ®çš„åŸºç¡€æ¨¡å‹ï¼Œå¯ä»¥ä¸ºç¥ç»ç§‘å­¦ç ”ç©¶æä¾›å¼ºå¤§çš„å·¥å…·ï¼ŒåŠ é€Ÿå¯¹å¤§è„‘åŠŸèƒ½å’Œè¿æ¥çš„ç†è§£ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›åº”ç”¨äºä¸´åºŠï¼Œè¾…åŠ©åŒ»ç”Ÿè¿›è¡Œç–¾ç—…è¯Šæ–­å’Œæ²»ç–—æ–¹æ¡ˆåˆ¶å®šã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> A key question for adapting modern deep learning architectures to functional MRI (fMRI) is how to represent the data for model input. To bridge the modality gap between fMRI and natural images, we transform the 4D volumetric fMRI data into videos of 2D fMRI activity flat maps. We train Vision Transformers on 2.3K hours of fMRI flat map videos from the Human Connectome Project using the spatiotemporal masked autoencoder (MAE) framework. We observe that masked fMRI modeling performance improves with dataset size according to a strict power scaling law. Downstream classification benchmarks show that our model learns rich representations supporting both fine-grained state decoding across subjects, as well as subject-specific trait decoding across changes in brain state. This work is part of an ongoing open science project to build foundation models for fMRI data. Our code and datasets are available at https://github.com/MedARC-AI/fmri-fm.

