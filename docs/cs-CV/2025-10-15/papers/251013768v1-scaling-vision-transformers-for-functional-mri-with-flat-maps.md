---
layout: default
title: Scaling Vision Transformers for Functional MRI with Flat Maps
---

# Scaling Vision Transformers for Functional MRI with Flat Maps

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.13768" target="_blank" class="toolbar-btn">arXiv: 2510.13768v1</a>
    <a href="https://arxiv.org/pdf/2510.13768.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.13768v1" 
            onclick="toggleFavorite(this, '2510.13768v1', 'Scaling Vision Transformers for Functional MRI with Flat Maps')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Connor Lane, Daniel Z. Kaplan, Tanishq Mathew Abraham, Paul S. Scotti

**ÂàÜÁ±ª**: cs.CV, cs.AI, q-bio.NC

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-15

**Â§áÊ≥®**: NeurIPS 2025 Workshop, Foundation Models for the Brain and Body; Code: https://github.com/MedARC-AI/fmri-fm; Discord: https://discord.gg/tVR4TWnRM9

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/MedARC-AI/fmri-fm)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**Âà©Áî®Âπ≥Èù¢ÂõæÂíåËßÜËßâTransformerÊâ©Â±ïÂäüËÉΩÁ£ÅÂÖ±ÊåØÊàêÂÉèÁ†îÁ©∂**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±ÂÖ´ÔºöÁâ©ÁêÜÂä®Áîª (Physics-based Animation)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÂäüËÉΩÁ£ÅÂÖ±ÊåØÊàêÂÉè` `ËßÜËßâTransformer` `Êé©Á†ÅËá™ÁºñÁ†ÅÂô®` `ËÑëËøûÊé•ÁªÑ` `Ê∑±Â∫¶Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâfMRIÊï∞ÊçÆÂàÜÊûêÊñπÊ≥ïÈöæ‰ª•ÊúâÊïàÂà©Áî®Â§ßËßÑÊ®°Êï∞ÊçÆÈõÜÔºå‰∏îÁº∫‰πè‰∏éÊ∑±Â∫¶Â≠¶‰π†Êû∂ÊûÑÁöÑÊúâÊïàË°îÊé•„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫Â∞Ü4D fMRIÊï∞ÊçÆËΩ¨Êç¢‰∏∫2DÂπ≥Èù¢ÂõæËßÜÈ¢ëÔºåÂπ∂Âà©Áî®ËßÜËßâTransformerËøõË°åÊó∂Á©∫Êé©Á†ÅËá™ÁºñÁ†ÅÂª∫Ê®°„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®‰∏ãÊ∏∏ÂàÜÁ±ª‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫Ëâ≤ÔºåËÉΩÂ§üËß£Á†ÅÂèóËØïËÄÖÁä∂ÊÄÅÂíå‰∏™‰ΩìÁâπÂæÅ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

‰∏∫‰∫ÜÂ∞ÜÁé∞‰ª£Ê∑±Â∫¶Â≠¶‰π†Êû∂ÊûÑÂ∫îÁî®‰∫éÂäüËÉΩÁ£ÅÂÖ±ÊåØÊàêÂÉè(fMRI)Ôºå‰∏Ä‰∏™ÂÖ≥ÈîÆÈóÆÈ¢òÊòØÂ¶Ç‰ΩïË°®Á§∫Ê®°ÂûãËæìÂÖ•ÁöÑÊï∞ÊçÆ„ÄÇ‰∏∫‰∫ÜÂº•ÂêàfMRIÂíåËá™ÁÑ∂ÂõæÂÉè‰πãÈó¥ÁöÑÊ®°ÊÄÅÂ∑ÆË∑ùÔºåÊàë‰ª¨Â∞Ü4D‰ΩìÁßØfMRIÊï∞ÊçÆËΩ¨Êç¢‰∏∫2D fMRIÊ¥ªÂä®Âπ≥Èù¢ÂõæÁöÑËßÜÈ¢ë„ÄÇÊàë‰ª¨‰ΩøÁî®Êó∂Á©∫Êé©Á†ÅËá™ÁºñÁ†ÅÂô®(MAE)Ê°ÜÊû∂ÔºåÂú®Êù•Ëá™‰∫∫Á±ªËøûÊé•ÁªÑËÆ°ÂàíÁöÑ2.3KÂ∞èÊó∂ÁöÑfMRIÂπ≥Èù¢ÂõæËßÜÈ¢ë‰∏äËÆ≠ÁªÉËßÜËßâTransformer„ÄÇÊàë‰ª¨ËßÇÂØüÂà∞ÔºåÊé©Á†ÅfMRIÂª∫Ê®°ÊÄßËÉΩÈöèÁùÄÊï∞ÊçÆÈõÜÂ§ßÂ∞èÁöÑÂ¢ûÂä†ËÄå‰∏•Ê†ºÈÅµÂæ™ÂπÇÂæãÁº©Êîæ„ÄÇ‰∏ãÊ∏∏ÂàÜÁ±ªÂü∫ÂáÜÊµãËØïË°®ÊòéÔºåÊàë‰ª¨ÁöÑÊ®°ÂûãÂ≠¶‰π†‰∫Ü‰∏∞ÂØåÁöÑË°®Á§∫ÔºåÊîØÊåÅË∑®ÂèóËØïËÄÖÁöÑÁªÜÁ≤íÂ∫¶Áä∂ÊÄÅËß£Á†ÅÔºå‰ª•ÂèäË∑®Â§ßËÑëÁä∂ÊÄÅÂèòÂåñÁöÑÂèóËØïËÄÖÁâπÂÆöÁâπÂæÅËß£Á†Å„ÄÇËøôÈ°πÂ∑•‰ΩúÊòØ‰∏Ä‰∏™Ê≠£Âú®ËøõË°åÁöÑÂºÄÊîæÁßëÂ≠¶È°πÁõÆÁöÑ‰∏ÄÈÉ®ÂàÜÔºåÊó®Âú®‰∏∫fMRIÊï∞ÊçÆÊûÑÂª∫Âü∫Á°ÄÊ®°Âûã„ÄÇÊàë‰ª¨ÁöÑ‰ª£Á†ÅÂíåÊï∞ÊçÆÈõÜÂèØÂú®https://github.com/MedARC-AI/fmri-fm‰∏äÊâæÂà∞„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Â¶Ç‰ΩïÂ∞ÜÂ§ßËßÑÊ®°fMRIÊï∞ÊçÆÊúâÊïàÂú∞ËæìÂÖ•Âà∞Ê∑±Â∫¶Â≠¶‰π†Ê®°ÂûãÔºåÁâπÂà´ÊòØËßÜËßâTransformer‰∏≠ÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÁöÑfMRIÊï∞ÊçÆÂ§ÑÁêÜÊñπÊ≥ïÈÄöÂ∏∏Èöæ‰ª•Áõ¥Êé•Â∫îÁî®‰∫éÊ∑±Â∫¶Â≠¶‰π†Êû∂ÊûÑÔºåÂπ∂‰∏îÁº∫‰πèÂØπÊó∂Á©∫‰ø°ÊÅØÁöÑÊúâÊïàÂà©Áî®„ÄÇÊ≠§Â§ñÔºåÂ¶Ç‰ΩïÂà©Áî®Â§ßËßÑÊ®°fMRIÊï∞ÊçÆÈõÜËÆ≠ÁªÉÂá∫ÂÖ∑ÊúâÊ≥õÂåñËÉΩÂäõÁöÑÊ®°Âûã‰πüÊòØ‰∏Ä‰∏™ÊåëÊàò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞Ü4D fMRIÊï∞ÊçÆËΩ¨Êç¢‰∏∫2D fMRIÊ¥ªÂä®Âπ≥Èù¢ÂõæÁöÑËßÜÈ¢ëÔºå‰ªéËÄåÂ∞ÜfMRIÊï∞ÊçÆËΩ¨Êç¢‰∏∫Á±ª‰ºº‰∫éËá™ÁÑ∂ÂõæÂÉèËßÜÈ¢ëÁöÑÊï∞ÊçÆÊ†ºÂºè„ÄÇËøôÁßçËΩ¨Êç¢‰ΩøÂæóÂèØ‰ª•Áõ¥Êé•Âà©Áî®Âú®Ëá™ÁÑ∂ÂõæÂÉèËßÜÈ¢ë‰∏äËÆ≠ÁªÉÁöÑËßÜËßâTransformerÊû∂ÊûÑ„ÄÇÈÄöËøáÂú®Â§ßÈáèfMRIÂπ≥Èù¢ÂõæËßÜÈ¢ë‰∏äËøõË°åÈ¢ÑËÆ≠ÁªÉÔºåÊ®°ÂûãÂèØ‰ª•Â≠¶‰π†Âà∞fMRIÊï∞ÊçÆÁöÑÂÜÖÂú®ÁªìÊûÑÂíåË°®Á§∫„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ≠•È™§Ôºö1) Â∞Ü4D fMRIÊï∞ÊçÆËΩ¨Êç¢‰∏∫2D fMRIÊ¥ªÂä®Âπ≥Èù¢ÂõæËßÜÈ¢ë„ÄÇ2) ‰ΩøÁî®Êó∂Á©∫Êé©Á†ÅËá™ÁºñÁ†ÅÂô®(MAE)Ê°ÜÊû∂Âú®Â§ßÈáèfMRIÂπ≥Èù¢ÂõæËßÜÈ¢ë‰∏äÈ¢ÑËÆ≠ÁªÉËßÜËßâTransformer„ÄÇ3) Âú®‰∏ãÊ∏∏ÂàÜÁ±ª‰ªªÂä°‰∏äËØÑ‰º∞È¢ÑËÆ≠ÁªÉÊ®°ÂûãÁöÑÊÄßËÉΩÔºåÂåÖÊã¨Ë∑®ÂèóËØïËÄÖÁöÑÁä∂ÊÄÅËß£Á†ÅÂíåÂèóËØïËÄÖÁâπÂÆöÁâπÂæÅËß£Á†Å„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜfMRIÊï∞ÊçÆËΩ¨Êç¢‰∏∫Âπ≥Èù¢ÂõæËßÜÈ¢ëÔºå‰ªéËÄåËÉΩÂ§üÂà©Áî®ËßÜËßâTransformerËøõË°åÂª∫Ê®°„ÄÇÊ≠§Â§ñÔºåËÆ∫ÊñáËøòÊé¢Á¥¢‰∫Ü‰ΩøÁî®Êó∂Á©∫Êé©Á†ÅËá™ÁºñÁ†ÅÂô®(MAE)Ê°ÜÊû∂ËøõË°åfMRIÊï∞ÊçÆÈ¢ÑËÆ≠ÁªÉÁöÑÊñπÊ≥ïÔºåÂπ∂È™åËØÅ‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇÈÄöËøáËøôÁßçÊñπÂºèÔºåÊ®°ÂûãËÉΩÂ§üÂ≠¶‰π†Âà∞fMRIÊï∞ÊçÆÁöÑÊó∂Á©∫ÁâπÂæÅÔºå‰ªéËÄåÂú®‰∏ãÊ∏∏‰ªªÂä°‰∏≠ÂèñÂæóÊõ¥Â•ΩÁöÑÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËÆ∫Êñá‰ΩøÁî®‰∫ÜËßÜËßâTransformer‰Ωú‰∏∫Âü∫Á°ÄÊ®°ÂûãÔºåÂπ∂ÈááÁî®‰∫ÜÊó∂Á©∫Êé©Á†ÅËá™ÁºñÁ†ÅÂô®(MAE)Ê°ÜÊû∂ËøõË°åÈ¢ÑËÆ≠ÁªÉ„ÄÇÂú®MAEÊ°ÜÊû∂‰∏≠Ôºå‰∏ÄÈÉ®ÂàÜËæìÂÖ•ËßÜÈ¢ëÂ∏ßË¢´ÈöèÊú∫Êé©ÁõñÔºåÊ®°ÂûãÈúÄË¶ÅÊ†πÊçÆÊú™Ë¢´Êé©ÁõñÁöÑÂ∏ßÊù•È¢ÑÊµãË¢´Êé©ÁõñÁöÑÂ∏ß„ÄÇËøôÁßçÈ¢ÑËÆ≠ÁªÉÊñπÂºèÂèØ‰ª•ÊúâÊïàÂú∞Â≠¶‰π†Âà∞fMRIÊï∞ÊçÆÁöÑÊó∂Á©∫‰æùËµñÂÖ≥Á≥ª„ÄÇËÆ∫Êñá‰ΩøÁî®‰∫ÜÊù•Ëá™‰∫∫Á±ªËøûÊé•ÁªÑËÆ°ÂàíÁöÑ2.3KÂ∞èÊó∂ÁöÑfMRIÂπ≥Èù¢ÂõæËßÜÈ¢ëËøõË°åËÆ≠ÁªÉÔºåÂπ∂‰ΩøÁî®Ê†áÂáÜÁöÑÂàÜÁ±ªÂü∫ÂáÜÊµãËØïÊù•ËØÑ‰º∞Ê®°ÂûãÁöÑÊÄßËÉΩ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊé©Á†ÅfMRIÂª∫Ê®°ÊÄßËÉΩÈöèÁùÄÊï∞ÊçÆÈõÜÂ§ßÂ∞èÁöÑÂ¢ûÂä†ËÄå‰∏•Ê†ºÈÅµÂæ™ÂπÇÂæãÁº©ÊîæÔºåÈ™åËØÅ‰∫ÜÂ§ßËßÑÊ®°Êï∞ÊçÆËÆ≠ÁªÉÁöÑÊúâÊïàÊÄß„ÄÇ‰∏ãÊ∏∏ÂàÜÁ±ªÂü∫ÂáÜÊµãËØïÊòæÁ§∫ÔºåËØ•Ê®°ÂûãËÉΩÂ§üÂ≠¶‰π†Âà∞‰∏∞ÂØåÁöÑË°®Á§∫ÔºåÊîØÊåÅË∑®ÂèóËØïËÄÖÁöÑÁªÜÁ≤íÂ∫¶Áä∂ÊÄÅËß£Á†ÅÔºå‰ª•ÂèäË∑®Â§ßËÑëÁä∂ÊÄÅÂèòÂåñÁöÑÂèóËØïËÄÖÁâπÂÆöÁâπÂæÅËß£Á†Å„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÊúâÊïàÂú∞ÊèêÂèñfMRIÊï∞ÊçÆ‰∏≠ÁöÑÊúâÁî®‰ø°ÊÅØ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éËÑëÁñæÁóÖËØäÊñ≠„ÄÅËÆ§Áü•Áä∂ÊÄÅËß£Á†Å„ÄÅ‰∏™‰ΩìÁâπÂæÅÈ¢ÑÊµãÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÊûÑÂª∫fMRIÊï∞ÊçÆÁöÑÂü∫Á°ÄÊ®°ÂûãÔºåÂèØ‰ª•‰∏∫Á•ûÁªèÁßëÂ≠¶Á†îÁ©∂Êèê‰æõÂº∫Â§ßÁöÑÂ∑•ÂÖ∑ÔºåÂä†ÈÄüÂØπÂ§ßËÑëÂäüËÉΩÂíåËøûÊé•ÁöÑÁêÜËß£„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïÊúâÊúõÂ∫îÁî®‰∫é‰∏¥Â∫äÔºåËæÖÂä©ÂåªÁîüËøõË°åÁñæÁóÖËØäÊñ≠ÂíåÊ≤ªÁñóÊñπÊ°àÂà∂ÂÆö„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> A key question for adapting modern deep learning architectures to functional MRI (fMRI) is how to represent the data for model input. To bridge the modality gap between fMRI and natural images, we transform the 4D volumetric fMRI data into videos of 2D fMRI activity flat maps. We train Vision Transformers on 2.3K hours of fMRI flat map videos from the Human Connectome Project using the spatiotemporal masked autoencoder (MAE) framework. We observe that masked fMRI modeling performance improves with dataset size according to a strict power scaling law. Downstream classification benchmarks show that our model learns rich representations supporting both fine-grained state decoding across subjects, as well as subject-specific trait decoding across changes in brain state. This work is part of an ongoing open science project to build foundation models for fMRI data. Our code and datasets are available at https://github.com/MedARC-AI/fmri-fm.

