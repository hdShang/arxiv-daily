---
layout: default
title: RECODE: Reasoning Through Code Generation for Visual Question Answering
---

# RECODE: Reasoning Through Code Generation for Visual Question Answering

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.13756" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.13756v1</a>
  <a href="https://arxiv.org/pdf/2510.13756.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.13756v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.13756v1', 'RECODE: Reasoning Through Code Generation for Visual Question Answering')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Junhong Shen, Mu Cai, Bo Hu, Ameet Talwalkar, David A Ross, Cordelia Schmid, Alireza Fathi

**åˆ†ç±»**: cs.CV, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-10-15

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRECODEæ¡†æ¶ï¼Œé€šè¿‡ä»£ç ç”Ÿæˆå®ç°è§†è§‰é—®ç­”ä¸­æ›´ç²¾ç¡®çš„å¯éªŒè¯æ¨ç†ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰é—®ç­”` `ä»£ç ç”Ÿæˆ` `åå‘æ¸²æŸ“` `å¤šæ¨¡æ€æ¨ç†` `å¯éªŒè¯æ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨å¤„ç†ç»“æ„åŒ–è§†è§‰ä¿¡æ¯æ—¶ï¼Œç¼ºä¹æœ‰æ•ˆçš„éªŒè¯æœºåˆ¶ï¼Œå¯¼è‡´æ¨ç†ç²¾åº¦ä¸è¶³ã€‚
2. RECODEæ¡†æ¶é€šè¿‡ç”Ÿæˆå¯æ‰§è¡Œä»£ç æ¥é‡æ„å›¾åƒï¼Œå°†è§†è§‰æ¨ç†è½¬åŒ–ä¸ºå¯éªŒè¯çš„ç¬¦å·é—®é¢˜ï¼Œæå‡æ¨ç†ç²¾åº¦ã€‚
3. åœ¨å¤šä¸ªè§†è§‰æ¨ç†åŸºå‡†æµ‹è¯•ä¸­ï¼ŒRECODEæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒéªŒè¯äº†åŸºäºä»£ç çš„è§†è§‰æ¨ç†çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹(MLLMs)åœ¨å¤„ç†å›¾è¡¨ç­‰ç»“æ„åŒ–è§†è§‰ä¿¡æ¯æ—¶ï¼Œç”±äºåŸºäºåƒç´ çš„æ„ŸçŸ¥ç¼ºä¹éªŒè¯æœºåˆ¶ï¼Œéš¾ä»¥è¿›è¡Œç²¾ç¡®æ¨ç†ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºåˆ©ç”¨åå‘æ¸²æŸ“â€”â€”å°†è§†è§‰ä¿¡æ¯é€†å‘å·¥ç¨‹ä¸ºå¯æ‰§è¡Œä»£ç çš„è¿‡ç¨‹â€”â€”ä½œä¸ºä¸€ç§æ–°çš„å¯éªŒè¯è§†è§‰æ¨ç†æ–¹å¼ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æå‡ºäº†RECODEï¼Œä¸€ä¸ªagenticæ¡†æ¶ï¼Œå®ƒé¦–å…ˆç”Ÿæˆå¤šä¸ªå€™é€‰ç¨‹åºæ¥é‡ç°è¾“å…¥å›¾åƒï¼Œç„¶åä½¿ç”¨è¯„è®ºå™¨é€‰æ‹©æœ€å¿ å®çš„é‡å»ºï¼Œå¹¶è¿­ä»£åœ°æ”¹è¿›ä»£ç ã€‚è¿™ä¸ªè¿‡ç¨‹ä¸ä»…å°†æ¨¡ç³Šçš„æ„ŸçŸ¥ä»»åŠ¡è½¬åŒ–ä¸ºå¯éªŒè¯çš„ç¬¦å·é—®é¢˜ï¼Œè€Œä¸”è¿˜èƒ½å¤Ÿåœ¨åç»­è¿›è¡Œç²¾ç¡®çš„è®¡ç®—å’Œé€»è¾‘æ¨ç†ã€‚åœ¨CharXivã€ChartQAå’ŒGeometry3Kç­‰å„ç§è§†è§‰æ¨ç†åŸºå‡†æµ‹è¯•ä¸­ï¼ŒRECODEæ˜¾è‘—ä¼˜äºä¸åˆ©ç”¨ä»£ç æˆ–ä»…ä½¿ç”¨ä»£ç ç»˜åˆ¶è¾…åŠ©çº¿æˆ–è£å‰ªçš„æ–¹æ³•ã€‚æˆ‘ä»¬çš„å·¥ä½œè¡¨æ˜ï¼Œå°†è§†è§‰æ„ŸçŸ¥å»ºç«‹åœ¨å¯æ‰§è¡Œä»£ç çš„åŸºç¡€ä¸Šï¼Œä¸ºæ›´å‡†ç¡®å’Œå¯éªŒè¯çš„å¤šæ¨¡æ€æ¨ç†æä¾›äº†ä¸€æ¡æ–°çš„é€”å¾„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨å¤„ç†å¦‚å›¾è¡¨ã€ç¤ºæ„å›¾ç­‰ç»“æ„åŒ–è§†è§‰ä¿¡æ¯æ—¶ï¼Œä¾èµ–äºåƒç´ çº§åˆ«çš„æ„ŸçŸ¥ï¼Œç¼ºä¹å¯¹æ¨ç†è¿‡ç¨‹çš„éªŒè¯æœºåˆ¶ï¼Œå®¹æ˜“äº§ç”Ÿé”™è¯¯ã€‚å°¤å…¶æ˜¯åœ¨éœ€è¦ç²¾ç¡®è®¡ç®—æˆ–é€»è¾‘æ¨ç†çš„åœºæ™¯ä¸‹ï¼Œæ€§èƒ½è¡¨ç°ä¸ä½³ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸æ— æ³•æœ‰æ•ˆåœ°å°†è§†è§‰ä¿¡æ¯è½¬åŒ–ä¸ºå¯éªŒè¯çš„ç¬¦å·è¡¨ç¤ºï¼Œé™åˆ¶äº†æ¨ç†çš„å‡†ç¡®æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šRECODEçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†è§†è§‰æ¨ç†é—®é¢˜è½¬åŒ–ä¸ºä»£ç ç”Ÿæˆå’ŒéªŒè¯é—®é¢˜ã€‚é€šè¿‡å°†å›¾åƒâ€œåå‘æ¸²æŸ“â€ä¸ºå¯æ‰§è¡Œä»£ç ï¼Œå°†æ¨¡ç³Šçš„åƒç´ æ„ŸçŸ¥è½¬åŒ–ä¸ºç²¾ç¡®çš„ç¬¦å·è¡¨ç¤ºã€‚è¿™æ ·ï¼Œæ¨¡å‹å¯ä»¥é€šè¿‡æ‰§è¡Œç”Ÿæˆçš„ä»£ç æ¥éªŒè¯å…¶å¯¹å›¾åƒçš„ç†è§£ï¼Œä»è€Œæé«˜æ¨ç†çš„å‡†ç¡®æ€§å’Œå¯ä¿¡åº¦ã€‚è¿™ç§æ–¹æ³•å€Ÿé‰´äº†ç¨‹åºåˆæˆçš„æ€æƒ³ï¼Œå°†è§†è§‰ä¿¡æ¯è½¬åŒ–ä¸ºè®¡ç®—æœºå¯ä»¥ç†è§£å’Œæ“ä½œçš„å½¢å¼ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRECODEæ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) **ä»£ç ç”Ÿæˆå™¨**ï¼šç”Ÿæˆå¤šä¸ªå€™é€‰ç¨‹åºï¼Œç”¨äºé‡æ„è¾“å…¥å›¾åƒã€‚2) **ä»£ç æ‰§è¡Œå™¨**ï¼šæ‰§è¡Œç”Ÿæˆçš„ä»£ç ï¼Œå¾—åˆ°é‡æ„åçš„å›¾åƒã€‚3) **è¯„è®ºå™¨**ï¼šè¯„ä¼°é‡æ„å›¾åƒä¸åŸå§‹å›¾åƒçš„ç›¸ä¼¼åº¦ï¼Œé€‰æ‹©æœ€å¿ å®çš„é‡å»ºä»£ç ã€‚4) **è¿­ä»£ä¼˜åŒ–å™¨**ï¼šæ ¹æ®è¯„è®ºå™¨çš„åé¦ˆï¼Œè¿­ä»£åœ°æ”¹è¿›ä»£ç ï¼Œç›´åˆ°æ»¡è¶³ç²¾åº¦è¦æ±‚ã€‚æ•´ä¸ªæµç¨‹æ˜¯ä¸€ä¸ªagenticæ¡†æ¶ï¼Œé€šè¿‡ä¸æ–­è¯•é”™å’Œåé¦ˆï¼Œæœ€ç»ˆå¾—åˆ°èƒ½å¤Ÿç²¾ç¡®é‡æ„å›¾åƒçš„ä»£ç ã€‚

**å…³é”®åˆ›æ–°**ï¼šRECODEæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†è§†è§‰æ¨ç†é—®é¢˜è½¬åŒ–ä¸ºä»£ç ç”Ÿæˆå’ŒéªŒè¯é—®é¢˜ã€‚ä¸ä»¥å¾€ä»…ä½¿ç”¨ä»£ç ç»˜åˆ¶è¾…åŠ©çº¿æˆ–è£å‰ªçš„æ–¹æ³•ä¸åŒï¼ŒRECODEå°†æ•´ä¸ªå›¾åƒçš„ç†è§£å’Œæ¨ç†è¿‡ç¨‹éƒ½å»ºç«‹åœ¨å¯æ‰§è¡Œä»£ç çš„åŸºç¡€ä¸Šã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨ä»£ç çš„ç²¾ç¡®æ€§å’Œå¯éªŒè¯æ€§ï¼Œä»è€Œæé«˜è§†è§‰æ¨ç†çš„å‡†ç¡®æ€§å’Œå¯ä¿¡åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šRECODEæ¡†æ¶çš„å…·ä½“å®ç°ç»†èŠ‚åŒ…æ‹¬ï¼šä»£ç ç”Ÿæˆå™¨å¯ä»¥ä½¿ç”¨é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»¥ç”Ÿæˆç¬¦åˆè¯­æ³•è§„åˆ™ä¸”èƒ½å¤Ÿæœ‰æ•ˆé‡æ„å›¾åƒçš„ä»£ç ã€‚è¯„è®ºå™¨å¯ä»¥ä½¿ç”¨å›¾åƒç›¸ä¼¼åº¦åº¦é‡æŒ‡æ ‡ï¼ˆå¦‚SSIMã€PSNRï¼‰æ¥è¯„ä¼°é‡æ„å›¾åƒçš„è´¨é‡ã€‚è¿­ä»£ä¼˜åŒ–å™¨å¯ä»¥ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æˆ–æ¢¯åº¦ä¸‹é™ç­‰æ–¹æ³•æ¥æ”¹è¿›ä»£ç ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„éœ€è¦æ ¹æ®å…·ä½“çš„ä»»åŠ¡å’Œæ•°æ®é›†è¿›è¡Œè°ƒæ•´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

RECODEåœ¨CharXivã€ChartQAå’ŒGeometry3Kç­‰å¤šä¸ªè§†è§‰æ¨ç†åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¾‹å¦‚ï¼Œåœ¨ChartQAæ•°æ®é›†ä¸Šï¼ŒRECODEçš„æ€§èƒ½è¶…è¿‡äº†ç°æœ‰æœ€ä½³æ–¹æ³•ï¼Œè¯æ˜äº†åŸºäºä»£ç çš„è§†è§‰æ¨ç†çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRECODEèƒ½å¤Ÿæ›´å‡†ç¡®åœ°ç†è§£å’Œæ¨ç†ç»“æ„åŒ–è§†è§‰ä¿¡æ¯ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦ç²¾ç¡®è®¡ç®—å’Œé€»è¾‘æ¨ç†çš„åœºæ™¯ä¸‹ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

RECODEæ¡†æ¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚å¯ä»¥åº”ç”¨äºè‡ªåŠ¨å›¾è¡¨åˆ†æã€ç§‘å­¦å›¾è¡¨ç†è§£ã€å‡ ä½•é—®é¢˜æ±‚è§£ç­‰é¢†åŸŸã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºæå‡AIç³»ç»Ÿåœ¨å¤„ç†ç»“æ„åŒ–è§†è§‰ä¿¡æ¯æ—¶çš„æ¨ç†èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å‡†ç¡®åœ°ç†è§£å’Œåˆ©ç”¨è§†è§‰æ•°æ®ï¼Œä»è€Œåœ¨æ•™è‚²ã€ç§‘ç ”ã€é‡‘èç­‰é¢†åŸŸå‘æŒ¥æ›´å¤§çš„ä½œç”¨ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºæ›´å¤æ‚çš„è§†è§‰æ¨ç†ä»»åŠ¡ï¼Œä¾‹å¦‚æœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal Large Language Models (MLLMs) struggle with precise reasoning for structured visuals like charts and diagrams, as pixel-based perception lacks a mechanism for verification. To address this, we propose to leverage derendering -- the process of reverse-engineering visuals into executable code -- as a new modality for verifiable visual reasoning. Specifically, we propose RECODE, an agentic framework that first generates multiple candidate programs to reproduce the input image. It then uses a critic to select the most faithful reconstruction and iteratively refines the code. This process not only transforms an ambiguous perceptual task into a verifiable, symbolic problem, but also enables precise calculations and logical inferences later on. On various visual reasoning benchmarks such as CharXiv, ChartQA, and Geometry3K, RECODE significantly outperforms methods that do not leverage code or only use code for drawing auxiliary lines or cropping. Our work demonstrates that grounding visual perception in executable code provides a new path toward more accurate and verifiable multimodal reasoning.

