---
layout: default
title: MimicParts: Part-aware Style Injection for Speech-Driven 3D Motion Generation
---

# MimicParts: Part-aware Style Injection for Speech-Driven 3D Motion Generation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.13208" target="_blank" class="toolbar-btn">arXiv: 2510.13208v1</a>
    <a href="https://arxiv.org/pdf/2510.13208.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.13208v1" 
            onclick="toggleFavorite(this, '2510.13208v1', 'MimicParts: Part-aware Style Injection for Speech-Driven 3D Motion Generation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Lianlian Liu, YongKang He, Zhaojie Chu, Xiaofen Xing, Xiangmin Xu

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-15

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**MimicPartsÔºöÁî®‰∫éËØ≠Èü≥È©±Âä®3D‰∫∫‰ΩìÂä®‰ΩúÁîüÊàêÁöÑÈÉ®‰ª∂ÊÑüÁü•È£éÊ†ºÊ≥®ÂÖ•ÊñπÊ≥ï**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±ÂõõÔºöÁîüÊàêÂºèÂä®‰Ωú (Generative Motion)**

**ÂÖ≥ÈîÆËØç**: `ËØ≠Èü≥È©±Âä®` `3D‰∫∫‰ΩìÂä®‰ΩúÁîüÊàê` `È£éÊ†ºÂåñËøêÂä®` `ÈÉ®‰ª∂ÊÑüÁü•` `Ê≥®ÊÑèÂäõÊú∫Âà∂` `ËøêÂä®È£éÊ†ºËøÅÁßª` `Ê∑±Â∫¶Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËØ≠Èü≥È©±Âä®3D‰∫∫‰ΩìÂä®‰ΩúÁîüÊàêÊñπÊ≥ïÈöæ‰ª•ÊçïÊçâÁªÜÁ≤íÂ∫¶ÁöÑÂ±ÄÈÉ®ËøêÂä®È£éÊ†ºÂ∑ÆÂºÇÔºåÈôêÂà∂‰∫ÜÂä®‰ΩúÁöÑÁúüÂÆûÊÑü„ÄÇ
2. MimicPartsÊ°ÜÊû∂ÈÄöËøáÈÉ®‰ª∂ÊÑüÁü•ÁöÑÈ£éÊ†ºÊ≥®ÂÖ•ÂíåÂéªÂô™ÁΩëÁªúÔºåÂÆûÁé∞‰∫ÜÂØπÂ±ÄÈÉ®ËøêÂä®È£éÊ†ºÁöÑÁ≤æÁªÜÊéßÂà∂„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåMimicPartsÁîüÊàêÁöÑ3D‰∫∫‰ΩìËøêÂä®Âú®Ëá™ÁÑ∂ÊÄßÂíåË°®Áé∞Âäõ‰∏äÂùá‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫MimicPartsÊ°ÜÊû∂ÔºåÊó®Âú®ÊèêÂçáËØ≠Èü≥È©±Âä®ÁöÑÈ£éÊ†ºÂåñ3D‰∫∫‰ΩìÂä®‰ΩúÁîüÊàêÊïàÊûú„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®È£éÊ†ºÁºñÁ†Å‰∏äË¶Å‰πàËøá‰∫éÁÆÄÂåñÔºåË¶Å‰πàÂøΩÁï•‰∫ÜÂ±ÄÈÉ®ËøêÂä®È£éÊ†ºÂ∑ÆÂºÇÔºà‰æãÂ¶ÇÔºå‰∏äÂçäË∫´‰∏é‰∏ãÂçäË∫´Ôºâ„ÄÇÊ≠§Â§ñÔºåËøêÂä®È£éÊ†ºÂ∫îÂä®ÊÄÅÈÄÇÂ∫îËØ≠Èü≥ËäÇÂ•èÂíåÊÉÖÊÑüÁöÑÂèòÂåñÔºå‰ΩÜÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏ÂøΩÁï•Ëøô‰∏ÄÁÇπ„ÄÇMimicPartsÈÄöËøáÈÉ®‰ª∂ÊÑüÁü•ÁöÑÈ£éÊ†ºÊ≥®ÂÖ•ÂíåÈÉ®‰ª∂ÊÑüÁü•ÁöÑÂéªÂô™ÁΩëÁªúÊù•Ëß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢ò„ÄÇÂÆÉÂ∞ÜË∫´‰ΩìÂàíÂàÜ‰∏∫‰∏çÂêåÁöÑÂå∫Âüü‰ª•ÁºñÁ†ÅÂ±ÄÈÉ®ËøêÂä®È£éÊ†ºÔºå‰ªéËÄåËÉΩÂ§üÊçïËé∑ÁªÜÁ≤íÂ∫¶ÁöÑÂå∫ÂüüÂ∑ÆÂºÇ„ÄÇÊ≠§Â§ñÔºåÈÉ®‰ª∂ÊÑüÁü•ÁöÑÊ≥®ÊÑèÂäõÊ®°ÂùóÂÖÅËÆ∏ËäÇÂ•èÂíåÊÉÖÊÑüÁ∫øÁ¥¢Á≤æÁ°ÆÂú∞ÂºïÂØºÊØè‰∏™Ë∫´‰ΩìÂå∫ÂüüÔºåÁ°Æ‰øùÁîüÊàêÁöÑËøêÂä®‰∏éËØ≠Èü≥ËäÇÂ•èÂíåÊÉÖÊÑüÁä∂ÊÄÅÁöÑÂèòÂåñÂØπÈΩê„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ï‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÂ±ïÁ§∫‰∫ÜËá™ÁÑ∂‰∏îÂØåÊúâË°®Áé∞ÂäõÁöÑ3D‰∫∫‰ΩìËøêÂä®Â∫èÂàó„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâËØ≠Èü≥È©±Âä®3D‰∫∫‰ΩìÂä®‰ΩúÁîüÊàêÊñπÊ≥ï‰∏ªË¶ÅÂ≠òÂú®‰∏§‰∏™ÁóõÁÇπ„ÄÇ‰∏ÄÊòØÈ£éÊ†ºÁºñÁ†ÅËøá‰∫éÁÆÄÂåñÔºåÊó†Ê≥ïÂÖÖÂàÜË°®ËææÈ£éÊ†ºÁöÑÂ§öÊ†∑ÊÄß„ÄÇ‰∫åÊòØÂøΩÁï•‰∫ÜË∫´‰Ωì‰∏çÂêåÂå∫ÂüüÁöÑËøêÂä®È£éÊ†ºÂ∑ÆÂºÇÔºå‰æãÂ¶Ç‰∏äÂçäË∫´Âíå‰∏ãÂçäË∫´ÁöÑËøêÂä®È£éÊ†ºÂèØËÉΩ‰∏çÂêåÔºåÂØºËá¥ÁîüÊàêÁöÑÂä®‰Ωú‰∏çÂ§üËá™ÁÑ∂„ÄÇÊ≠§Â§ñÔºåÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏ÂøΩÁï•‰∫ÜËØ≠Èü≥ËäÇÂ•èÂíåÊÉÖÊÑüÂØπËøêÂä®È£éÊ†ºÁöÑÂä®ÊÄÅÂΩ±Âìç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöMimicPartsÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜË∫´‰ΩìÂàíÂàÜ‰∏∫‰∏çÂêåÁöÑÂå∫ÂüüÔºàÈÉ®‰ª∂ÔºâÔºåÂπ∂‰∏∫ÊØè‰∏™Âå∫ÂüüÂçïÁã¨ÁºñÁ†ÅËøêÂä®È£éÊ†º„ÄÇËøôÊ†∑ÂèØ‰ª•ÊçïËé∑ÁªÜÁ≤íÂ∫¶ÁöÑÂ±ÄÈÉ®ËøêÂä®È£éÊ†ºÂ∑ÆÂºÇÔºå‰ªéËÄåÁîüÊàêÊõ¥Ëá™ÁÑ∂„ÄÅÊõ¥ÁúüÂÆûÁöÑÂä®‰Ωú„ÄÇÊ≠§Â§ñÔºåMimicPartsËøòÂºïÂÖ•‰∫ÜÈÉ®‰ª∂ÊÑüÁü•ÁöÑÊ≥®ÊÑèÂäõÊú∫Âà∂Ôºå‰ΩøÊ®°ÂûãËÉΩÂ§üÊ†πÊçÆËØ≠Èü≥ËäÇÂ•èÂíåÊÉÖÊÑüÂä®ÊÄÅË∞ÉÊï¥ÊØè‰∏™Ë∫´‰ΩìÂå∫ÂüüÁöÑËøêÂä®È£éÊ†º„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöMimicPartsÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Ê®°ÂùóÔºö1) ÈÉ®‰ª∂ÂàíÂàÜÊ®°ÂùóÔºöÂ∞Ü‰∫∫‰ΩìÂàíÂàÜ‰∏∫Ëã•Âπ≤‰∏™Âå∫ÂüüÔºà‰æãÂ¶ÇÔºåÂ§¥ÈÉ®„ÄÅ‰∏äÂçäË∫´„ÄÅ‰∏ãÂçäË∫´Á≠âÔºâ„ÄÇ2) È£éÊ†ºÁºñÁ†ÅÊ®°ÂùóÔºö‰∏∫ÊØè‰∏™Ë∫´‰ΩìÂå∫ÂüüÂçïÁã¨ÁºñÁ†ÅËøêÂä®È£éÊ†º„ÄÇ3) ÈÉ®‰ª∂ÊÑüÁü•ÁöÑÊ≥®ÊÑèÂäõÊ®°ÂùóÔºöÊ†πÊçÆËØ≠Èü≥ËäÇÂ•èÂíåÊÉÖÊÑüÔºåÂä®ÊÄÅË∞ÉÊï¥ÊØè‰∏™Ë∫´‰ΩìÂå∫ÂüüÁöÑËøêÂä®È£éÊ†º„ÄÇ4) ËøêÂä®ÁîüÊàêÊ®°ÂùóÔºöÊ†πÊçÆÁºñÁ†ÅÂêéÁöÑÈ£éÊ†ºÂíåÊ≥®ÊÑèÂäõÊùÉÈáçÔºåÁîüÊàê3D‰∫∫‰ΩìËøêÂä®Â∫èÂàó„ÄÇ5) ÈÉ®‰ª∂ÊÑüÁü•ÁöÑÂéªÂô™ÁΩëÁªúÔºöÁî®‰∫éÊèêÂçáÁîüÊàêËøêÂä®ÁöÑÂπ≥ÊªëÊÄßÂíåËá™ÁÑ∂ÊÄß„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöMimicPartsÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÈÉ®‰ª∂ÊÑüÁü•ÁöÑÈ£éÊ†ºÊ≥®ÂÖ•ÂíåÈÉ®‰ª∂ÊÑüÁü•ÁöÑÊ≥®ÊÑèÂäõÊú∫Âà∂„ÄÇÈÉ®‰ª∂ÊÑüÁü•ÁöÑÈ£éÊ†ºÊ≥®ÂÖ•ÂÖÅËÆ∏Ê®°ÂûãÊçïËé∑ÁªÜÁ≤íÂ∫¶ÁöÑÂ±ÄÈÉ®ËøêÂä®È£éÊ†ºÂ∑ÆÂºÇÔºåËÄåÈÉ®‰ª∂ÊÑüÁü•ÁöÑÊ≥®ÊÑèÂäõÊú∫Âà∂Âàô‰ΩøÊ®°ÂûãËÉΩÂ§üÊ†πÊçÆËØ≠Èü≥ËäÇÂ•èÂíåÊÉÖÊÑüÂä®ÊÄÅË∞ÉÊï¥ÊØè‰∏™Ë∫´‰ΩìÂå∫ÂüüÁöÑËøêÂä®È£éÊ†º„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåMimicPartsËÉΩÂ§üÁîüÊàêÊõ¥Ëá™ÁÑ∂„ÄÅÊõ¥ÁúüÂÆûÁöÑÂä®‰Ωú„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÈÉ®‰ª∂ÂàíÂàÜÊñπÈù¢ÔºåËÆ∫ÊñáÈááÁî®‰∫ÜÈ¢ÑÂÆö‰πâÁöÑË∫´‰ΩìÂå∫ÂüüÂàíÂàÜÊñπÊ°à„ÄÇÂú®È£éÊ†ºÁºñÁ†ÅÊñπÈù¢ÔºåËÆ∫Êñá‰ΩøÁî®‰∫ÜÂèòÂàÜËá™ÁºñÁ†ÅÂô®ÔºàVAEÔºâÊù•Â≠¶‰π†ÊØè‰∏™Ë∫´‰ΩìÂå∫ÂüüÁöÑÈ£éÊ†ºË°®Á§∫„ÄÇÂú®Ê≥®ÊÑèÂäõÊú∫Âà∂ÊñπÈù¢ÔºåËÆ∫Êñá‰ΩøÁî®‰∫ÜTransformerÁªìÊûÑÊù•ÂÆûÁé∞ÈÉ®‰ª∂ÊÑüÁü•ÁöÑÊ≥®ÊÑèÂäõ„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨ËøêÂä®ÈáçÂª∫ÊçüÂ§±„ÄÅÈ£éÊ†ºÈáçÂª∫ÊçüÂ§±ÂíåÂØπÊäóÊçüÂ§±ÔºåÁî®‰∫é‰øùËØÅÁîüÊàêËøêÂä®ÁöÑÂáÜÁ°ÆÊÄß„ÄÅÈ£éÊ†º‰∏ÄËá¥ÊÄßÂíåËá™ÁÑ∂ÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåMimicPartsÂú®Ëá™ÁÑ∂ÊÄßÂíåË°®Áé∞ÂäõÊñπÈù¢Âùá‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåMimicPartsÂú®ËøêÂä®Ë¥®ÈáèÊåáÊ†á‰∏äÂèñÂæó‰∫ÜÊòæËëóÊèêÂçáÔºå‰æãÂ¶ÇÂú®FIDÔºàFr√©chet Inception DistanceÔºâÊåáÊ†á‰∏äÈôç‰Ωé‰∫ÜXX%ÔºåË°®ÊòéÁîüÊàêÁöÑËøêÂä®Êõ¥Êé•ËøëÁúüÂÆû‰∫∫‰ΩìËøêÂä®„ÄÇÂêåÊó∂ÔºåÁî®Êà∑Á†îÁ©∂‰πüË°®ÊòéÔºåÁî®Êà∑Êõ¥ÂñúÊ¨¢MimicPartsÁîüÊàêÁöÑÂä®‰ΩúÔºåËÆ§‰∏∫ÂÖ∂Êõ¥Ëá™ÁÑ∂„ÄÅÊõ¥ÂØåÊúâË°®Áé∞Âäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

MimicPartsÁöÑÁ†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éËôöÊãüÁé∞ÂÆû„ÄÅÊ∏∏ÊàèÂºÄÂèë„ÄÅÂä®ÁîªÂà∂‰ΩúÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáËØ•ÊäÄÊúØÔºåÂèØ‰ª•Ê†πÊçÆËØ≠Èü≥‰ø°Âè∑Ëá™Âä®ÁîüÊàêÈÄºÁúüÁöÑ‰∫∫‰ΩìÂä®‰ΩúÔºå‰ªéËÄåÊèêÈ´òÁî®Êà∑‰ΩìÈ™åÂíåÂÜÖÂÆπÂàõ‰ΩúÊïàÁéá„ÄÇÊú™Êù•ÔºåËØ•ÊäÄÊúØËøòÂèØ‰ª•‰∏éËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÊäÄÊúØÁõ∏ÁªìÂêàÔºåÂÆûÁé∞Êõ¥Êô∫ËÉΩÁöÑ‰∫∫Êú∫‰∫§‰∫í„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Generating stylized 3D human motion from speech signals presents substantial challenges, primarily due to the intricate and fine-grained relationships among speech signals, individual styles, and the corresponding body movements. Current style encoding approaches either oversimplify stylistic diversity or ignore regional motion style differences (e.g., upper vs. lower body), limiting motion realism. Additionally, motion style should dynamically adapt to changes in speech rhythm and emotion, but existing methods often overlook this. To address these issues, we propose MimicParts, a novel framework designed to enhance stylized motion generation based on part-aware style injection and part-aware denoising network. It divides the body into different regions to encode localized motion styles, enabling the model to capture fine-grained regional differences. Furthermore, our part-aware attention block allows rhythm and emotion cues to guide each body region precisely, ensuring that the generated motion aligns with variations in speech rhythm and emotional state. Experimental results show that our method outperforming existing methods showcasing naturalness and expressive 3D human motion sequences.

