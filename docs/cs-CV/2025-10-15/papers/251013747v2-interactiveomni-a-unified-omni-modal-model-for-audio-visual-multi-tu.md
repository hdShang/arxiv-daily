---
layout: default
title: InteractiveOmni: A Unified Omni-modal Model for Audio-Visual Multi-turn Dialogue
---

# InteractiveOmni: A Unified Omni-modal Model for Audio-Visual Multi-turn Dialogue

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.13747" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.13747v2</a>
  <a href="https://arxiv.org/pdf/2510.13747.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.13747v2" onclick="toggleFavorite(this, '2510.13747v2', 'InteractiveOmni: A Unified Omni-modal Model for Audio-Visual Multi-turn Dialogue')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wenwen Tong, Hewei Guo, Dongchuan Ran, Jiangnan Chen, Jiefan Lu, Kaibin Wang, Keqiang Li, Xiaoxu Zhu, Jiakui Li, Kehan Li, Xueheng Li, Lumin Li, Chenxu Guo, Jiasheng Zhou, Jiandong Chen, Xianye Wu, Jiahao Wang, Silei Wu, Lei Chen, Hanming Deng, Yuxuan Song, Dinghao Zhou, Guiping Zhong, Ken Zheng, Shiyin Kang, Lewei Lu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-15 (æ›´æ–°: 2025-12-03)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºInteractiveOmniï¼Œä¸€ä¸ªç”¨äºéŸ³è§†é¢‘å¤šè½®äº¤äº’çš„ç»Ÿä¸€å…¨æ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `éŸ³è§†é¢‘äº¤äº’` `å¤§è¯­è¨€æ¨¡å‹` `è½»é‡åŒ–æ¨¡å‹` `å¤šè½®å¯¹è¯` `è¯­éŸ³ç”Ÿæˆ` `è·¨æ¨¡æ€ç†è§£`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰éŸ³è§†é¢‘å¤šè½®äº¤äº’æ¨¡å‹åœ¨è½»é‡åŒ–å’Œå…¨æ¨¡æ€ç†è§£èƒ½åŠ›ä¸Šå­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥å®ç°é«˜æ•ˆä¸”å…¨é¢çš„äº¤äº’ã€‚
2. InteractiveOmnié€šè¿‡ç»Ÿä¸€çš„æ¶æ„æ•´åˆè§†è§‰ã€éŸ³é¢‘ç¼–ç å™¨ã€LLMå’Œè¯­éŸ³è§£ç å™¨ï¼Œå®ç°å…¨æ¨¡æ€ç†è§£å’Œè¯­éŸ³ç”Ÿæˆã€‚
3. å®éªŒè¡¨æ˜ï¼ŒInteractiveOmniåœ¨å¤šè½®è®°å¿†å’Œè¯­éŸ³äº¤äº’æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰å¼€æºæ¨¡å‹ï¼Œä¸”4Bç‰ˆæœ¬æ€§èƒ½æ¥è¿‘7Bæ¨¡å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ä»‹ç»InteractiveOmniï¼Œä¸€ä¸ªç»Ÿä¸€ä¸”å¼€æºçš„å…¨æ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼Œå‚æ•°è§„æ¨¡ä»4Båˆ°8Bï¼Œæ—¨åœ¨é€šè¿‡æä¾›å…¨é¢çš„å…¨æ¨¡æ€ç†è§£å’Œè¯­éŸ³ç”Ÿæˆèƒ½åŠ›ï¼Œå¼•é¢†è½»é‡çº§æ¨¡å‹é¢†åŸŸã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†è§†è§‰ç¼–ç å™¨ã€éŸ³é¢‘ç¼–ç å™¨ã€å¤§å‹è¯­è¨€æ¨¡å‹å’Œè¯­éŸ³è§£ç å™¨é›†æˆåˆ°ä¸€ä¸ªç»Ÿä¸€çš„æ¨¡å‹ä¸­ï¼Œç”¨äºç†è§£å’Œç”Ÿæˆä»»åŠ¡ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªå¤šé˜¶æ®µè®­ç»ƒç­–ç•¥ï¼Œä»¥ç¡®ä¿å¼ºå¤§çš„è·¨æ¨¡æ€èƒ½åŠ›ï¼ŒåŒ…æ‹¬å…¨æ¨¡æ€ç†è§£çš„é¢„è®­ç»ƒï¼Œä»¥åŠè¯­éŸ³å¯¹è¯å’ŒéŸ³è§†é¢‘äº¤äº’çš„åè®­ç»ƒã€‚ä¸ºäº†å®ç°ç±»ä¼¼äººç±»çš„é•¿æœŸå¯¹è¯èƒ½åŠ›ï¼Œæˆ‘ä»¬ç²¾å¿ƒç­–åˆ’äº†ä¸€ä¸ªå¤šè½®è®­ç»ƒæ•°æ®é›†ï¼Œä»¥å¢å¼ºæ¨¡å‹å¤„ç†å¤æ‚å’Œå¤šè½®äº¤äº’çš„èƒ½åŠ›ã€‚ä¸ºäº†æœ‰æ•ˆè¯„ä¼°å¤šè½®è®°å¿†å’Œè¯­éŸ³äº¤äº’èƒ½åŠ›ï¼Œæˆ‘ä»¬æ„å»ºäº†å¤šæ¨¡æ€å¤šè½®è®°å¿†åŸºå‡†å’Œå¤šè½®è¯­éŸ³äº¤äº’åŸºå‡†ã€‚å®éªŒè¡¨æ˜ï¼ŒInteractiveOmniæ˜¾è‘—ä¼˜äºé¢†å…ˆçš„å¼€æºæ¨¡å‹ï¼Œå¹¶æä¾›äº†æ›´æ™ºèƒ½çš„å¤šè½®éŸ³è§†é¢‘ä½“éªŒï¼Œå°¤å…¶æ˜¯åœ¨å…¶é•¿æœŸè®°å¿†èƒ½åŠ›æ–¹é¢ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒInteractiveOmni-4Båœ¨é€šç”¨åŸºå‡†æµ‹è¯•ä¸­ä¸æ›´å¤§çš„æ¨¡å‹ï¼ˆå¦‚Qwen2.5-Omni-7Bï¼‰ç›¸å½“ï¼Œå¹¶ä¸”ä»…ä½¿ç”¨50%çš„æ¨¡å‹å¤§å°å³å¯ä¿æŒInteractiveOmni-8B 97%çš„æ€§èƒ½ã€‚InteractiveOmniåœ¨å›¾åƒã€éŸ³é¢‘ã€è§†é¢‘ç†è§£å’Œè¯­éŸ³ç”Ÿæˆä»»åŠ¡ä¸­å–å¾—äº†ä¸åŒç­‰è§„æ¨¡æ¨¡å‹ç›¸æ¯”æœ€å…ˆè¿›çš„ç»“æœï¼Œæ˜¯ä¸‹ä¸€ä»£æ™ºèƒ½äº¤äº’ç³»ç»Ÿçš„ä¸€ä¸ªå¯è®¿é—®çš„å¼€æºåŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰éŸ³è§†é¢‘å¤šè½®äº¤äº’æ¨¡å‹é€šå¸¸å­˜åœ¨æ¨¡å‹ä½“ç§¯å¤§ã€è®¡ç®—èµ„æºæ¶ˆè€—é«˜çš„é—®é¢˜ï¼Œéš¾ä»¥åœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šéƒ¨ç½²ã€‚æ­¤å¤–ï¼Œè¿™äº›æ¨¡å‹åœ¨å¤„ç†å¤šæ¨¡æ€ä¿¡æ¯ï¼ˆå¦‚åŒæ—¶ç†è§£å›¾åƒã€éŸ³é¢‘å’Œæ–‡æœ¬ï¼‰ä»¥åŠè¿›è¡Œå¤šè½®å¯¹è¯æ—¶ï¼Œæ€§èƒ½å¾€å¾€ä¸å°½å¦‚äººæ„ï¼Œç¼ºä¹é•¿æœŸè®°å¿†èƒ½åŠ›ï¼Œæ— æ³•è¿›è¡Œæµç•…è‡ªç„¶çš„äº¤äº’ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šInteractiveOmniçš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªç»Ÿä¸€çš„å…¨æ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼Œé€šè¿‡æ•´åˆè§†è§‰ã€éŸ³é¢‘ç¼–ç å™¨ã€å¤§å‹è¯­è¨€æ¨¡å‹å’Œè¯­éŸ³è§£ç å™¨ï¼Œå®ç°å¯¹å¤šç§æ¨¡æ€ä¿¡æ¯çš„ç†è§£å’Œç”Ÿæˆã€‚è¯¥æ¨¡å‹æ—¨åœ¨é€šè¿‡è½»é‡åŒ–çš„è®¾è®¡å’Œé«˜æ•ˆçš„è®­ç»ƒç­–ç•¥ï¼Œåœ¨ä¿è¯æ€§èƒ½çš„åŒæ—¶é™ä½è®¡ç®—æˆæœ¬ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨å„ç§è®¾å¤‡ä¸Šéƒ¨ç½²å’Œåº”ç”¨ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šInteractiveOmniçš„æ•´ä½“æ¶æ„åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) è§†è§‰ç¼–ç å™¨ï¼šç”¨äºæå–å›¾åƒå’Œè§†é¢‘çš„è§†è§‰ç‰¹å¾ã€‚2) éŸ³é¢‘ç¼–ç å™¨ï¼šç”¨äºæå–éŸ³é¢‘çš„å£°å­¦ç‰¹å¾ã€‚3) å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼šä½œä¸ºæ ¸å¿ƒçš„è¯­è¨€å¤„ç†æ¨¡å—ï¼Œè´Ÿè´£ç†è§£ç”¨æˆ·è¾“å…¥å¹¶ç”Ÿæˆå›å¤ã€‚4) è¯­éŸ³è§£ç å™¨ï¼šç”¨äºå°†LLMç”Ÿæˆçš„æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³è¾“å‡ºã€‚æ¨¡å‹è®­ç»ƒåˆ†ä¸ºå¤šä¸ªé˜¶æ®µï¼šé¦–å…ˆè¿›è¡Œå…¨æ¨¡æ€ç†è§£çš„é¢„è®­ç»ƒï¼Œç„¶åè¿›è¡Œè¯­éŸ³å¯¹è¯å’ŒéŸ³è§†é¢‘äº¤äº’çš„åè®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šInteractiveOmniçš„å…³é”®åˆ›æ–°åœ¨äºå…¶ç»Ÿä¸€çš„å…¨æ¨¡æ€æ¶æ„å’Œå¤šé˜¶æ®µè®­ç»ƒç­–ç•¥ã€‚ä¼ ç»Ÿçš„éŸ³è§†é¢‘äº¤äº’æ¨¡å‹é€šå¸¸éœ€è¦é’ˆå¯¹ä¸åŒçš„æ¨¡æ€å’Œä»»åŠ¡è¿›è¡Œå•ç‹¬è®¾è®¡å’Œè®­ç»ƒï¼Œè€ŒInteractiveOmnié€šè¿‡ä¸€ä¸ªç»Ÿä¸€çš„æ¨¡å‹å®ç°äº†å¯¹å¤šç§æ¨¡æ€ä¿¡æ¯çš„å¤„ç†å’Œç”Ÿæˆï¼Œç®€åŒ–äº†æ¨¡å‹çš„è®¾è®¡å’Œè®­ç»ƒæµç¨‹ã€‚æ­¤å¤–ï¼Œå¤šé˜¶æ®µè®­ç»ƒç­–ç•¥èƒ½å¤Ÿæœ‰æ•ˆåœ°æå‡æ¨¡å‹çš„è·¨æ¨¡æ€ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œè®ºæ–‡ä½œè€…ç²¾å¿ƒç­–åˆ’äº†ä¸€ä¸ªå¤šè½®è®­ç»ƒæ•°æ®é›†ï¼Œä»¥å¢å¼ºæ¨¡å‹å¤„ç†å¤æ‚å’Œå¤šè½®äº¤äº’çš„èƒ½åŠ›ã€‚ä¸ºäº†æœ‰æ•ˆè¯„ä¼°å¤šè½®è®°å¿†å’Œè¯­éŸ³äº¤äº’èƒ½åŠ›ï¼Œä»–ä»¬æ„å»ºäº†å¤šæ¨¡æ€å¤šè½®è®°å¿†åŸºå‡†å’Œå¤šè½®è¯­éŸ³äº¤äº’åŸºå‡†ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®ã€æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç­‰æŠ€æœ¯ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœªè¯¦ç»†è¯´æ˜ï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

InteractiveOmniåœ¨å¤šé¡¹åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œæ˜¾è‘—ä¼˜äºåŒç­‰è§„æ¨¡çš„å¼€æºæ¨¡å‹ã€‚ä¾‹å¦‚ï¼ŒInteractiveOmni-4Båœ¨é€šç”¨åŸºå‡†æµ‹è¯•ä¸­ä¸æ›´å¤§çš„æ¨¡å‹ï¼ˆå¦‚Qwen2.5-Omni-7Bï¼‰ç›¸å½“ï¼Œå¹¶ä¸”ä»…ä½¿ç”¨50%çš„æ¨¡å‹å¤§å°å³å¯ä¿æŒInteractiveOmni-8B 97%çš„æ€§èƒ½ã€‚è¿™è¡¨æ˜è¯¥æ¨¡å‹åœ¨æ€§èƒ½å’Œæ•ˆç‡ä¹‹é—´å–å¾—äº†è‰¯å¥½çš„å¹³è¡¡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

InteractiveOmniå¯åº”ç”¨äºæ™ºèƒ½åŠ©æ‰‹ã€è™šæ‹Ÿå®¢æœã€æ•™è‚²æœºå™¨äººç­‰é¢†åŸŸï¼Œå®ç°æ›´è‡ªç„¶ã€æ™ºèƒ½çš„äººæœºäº¤äº’ã€‚å…¶è½»é‡åŒ–çš„è®¾è®¡ä½¿å…¶èƒ½å¤Ÿåœ¨ç§»åŠ¨è®¾å¤‡ã€æ™ºèƒ½å®¶å±…ç­‰èµ„æºå—é™çš„å¹³å°ä¸Šéƒ¨ç½²ï¼Œä¸ºç”¨æˆ·æä¾›éšæ—¶éšåœ°çš„éŸ³è§†é¢‘äº¤äº’æœåŠ¡ã€‚è¯¥ç ”ç©¶æœ‰æœ›æ¨åŠ¨ä¸‹ä¸€ä»£æ™ºèƒ½äº¤äº’ç³»ç»Ÿçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We introduce InteractiveOmni, a unified and open-source omni-modal large language model for audio-visual multi-turn interaction, ranging from 4B to 8B parameters, designed to lead the field of lightweight models by offering comprehensive omni-modal understanding and speech generation capabilities. To achieve this, we integrate the vision encoder, audio encoder, large language model, and speech decoder into a unified model for understanding and generation tasks. We design a multi-stage training strategy to ensure robust cross-modal capabilities, including pre-training for omni-modal understanding, followed by post-training with speech conversation and audio-visual interaction. To enable human-like long-term conversational ability, we meticulously curate a multi-turn training dataset that enhances the model's ability to handle complex and multi-turn interactions. To effectively evaluate the multi-turn memory and speech interaction capabilities, we construct the multi-modal multi-turn memory benchmark and the multi-turn speech interaction benchmark. Experiments demonstrate that InteractiveOmni significantly outperforms leading open-source models and provides a more intelligent multi-turn audio-visual experience, particularly in its long-term memory capabilities. Notably, InteractiveOmni-4B is comparable to the much larger model like Qwen2.5-Omni-7B on general benchmarks, and it can retain 97% of the performance of the InteractiveOmni-8B while utilizing only 50% of the model size. Achieving state-of-the-art results against similarly sized models across image, audio, video understanding, and speech generation tasks, InteractiveOmni is an accessible, open-source foundation for next-generation intelligent interactive systems.

