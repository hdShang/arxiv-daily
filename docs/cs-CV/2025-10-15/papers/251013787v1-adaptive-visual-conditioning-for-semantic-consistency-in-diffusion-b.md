---
layout: default
title: Adaptive Visual Conditioning for Semantic Consistency in Diffusion-Based Story Continuation
---

# Adaptive Visual Conditioning for Semantic Consistency in Diffusion-Based Story Continuation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.13787" target="_blank" class="toolbar-btn">arXiv: 2510.13787v1</a>
    <a href="https://arxiv.org/pdf/2510.13787.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.13787v1" 
            onclick="toggleFavorite(this, '2510.13787v1', 'Adaptive Visual Conditioning for Semantic Consistency in Diffusion-Based Story Continuation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Seyed Mohammad Mousavi, Morteza Analoui

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-15

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫AVCÊ°ÜÊû∂ÔºåËá™ÈÄÇÂ∫îËßÜËßâÊù°‰ª∂ÊéßÂà∂Êâ©Êï£Ê®°ÂûãÔºåÊèêÂçáÊïÖ‰∫ãÂª∂Áª≠ÁîüÊàêËØ≠‰πâ‰∏ÄËá¥ÊÄß„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÊïÖ‰∫ãÂª∂Áª≠` `Êâ©Êï£Ê®°Âûã` `Ëá™ÈÄÇÂ∫îËßÜËßâÊù°‰ª∂ÊéßÂà∂` `ËØ≠‰πâ‰∏ÄËá¥ÊÄß` `CLIPÊ®°Âûã`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ÊïÖ‰∫ãÂª∂Áª≠ÁîüÊàê‰ªªÂä°Èù¢‰∏¥Â¶Ç‰ΩïÊúâÊïàÂà©Áî®ÂÖàÂâçËßÜËßâ‰ø°ÊÅØÔºåÂêåÊó∂‰øùËØÅ‰∏éÂΩìÂâçÊñáÊú¨ËØ≠‰πâÂØπÈΩêÁöÑÊåëÊàò„ÄÇ
2. AVCÊ°ÜÊû∂ÈÄöËøáCLIPÊ®°ÂûãÊ£ÄÁ¥¢Áõ∏ÂÖ≥ÂõæÂÉèÔºåÂπ∂Ëá™ÈÄÇÂ∫îÂú∞ÊéßÂà∂ÂÖàÂâçËßÜËßâ‰ø°ÊÅØÂú®Êâ©Êï£ËøáÁ®ã‰∏≠ÁöÑÂΩ±Âìç„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåAVCÂú®ËøûË¥ØÊÄß„ÄÅËØ≠‰πâ‰∏ÄËá¥ÊÄßÂíåËßÜËßâ‰øùÁúüÂ∫¶ÊñπÈù¢‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÊâ©Êï£Ê®°ÂûãÁöÑÊïÖ‰∫ãÂª∂Áª≠Ê°ÜÊû∂‚Äî‚ÄîËá™ÈÄÇÂ∫îËßÜËßâÊù°‰ª∂ÊéßÂà∂(AVC)„ÄÇÊïÖ‰∫ãÂª∂Áª≠Êó®Âú®ÁîüÊàêÂèô‰∫ãÂ∫èÂàó‰∏≠ÁöÑ‰∏ã‰∏ÄÂº†ÂõæÂÉèÔºå‰ΩøÂÖ∂‰∏éÂ∑≤ÊúâÁöÑÊñáÊú¨ÊèèËø∞ÂíåÂÖàÂâçËßÇÂØüÂà∞ÁöÑÂõæÂÉè‰øùÊåÅËøûË¥ØÊÄß„ÄÇËØ•‰ªªÂä°ÁöÑÊ†∏ÂøÉÊåëÊàòÂú®‰∫éÂ¶Ç‰ΩïÊúâÊïàÂú∞Âà©Áî®ÂÖàÂâçÁöÑËßÜËßâ‰∏ä‰∏ãÊñáÔºåÂêåÊó∂Á°Æ‰øù‰∏éÂΩìÂâçÊñáÊú¨ËæìÂÖ•ÁöÑËØ≠‰πâÂØπÈΩê„ÄÇAVCÂà©Áî®CLIPÊ®°ÂûãÊ£ÄÁ¥¢ÂÖàÂâçÂ∏ß‰∏≠ÊúÄÁ¨¶ÂêàËØ≠‰πâÁöÑÂõæÂÉè„ÄÇÂΩìÊâæ‰∏çÂà∞Ë∂≥Â§üÁõ∏ÂÖ≥ÁöÑÂõæÂÉèÊó∂ÔºåAVC‰ºöËá™ÈÄÇÂ∫îÂú∞ÈôêÂà∂ÂÖàÂâçËßÜËßâ‰ø°ÊÅØÂØπÊâ©Êï£ËøáÁ®ãÊó©ÊúüÈò∂ÊÆµÁöÑÂΩ±ÂìçÔºå‰ªéËÄåÂú®ÊúâÂà©Êó∂Âà©Áî®ËßÜËßâ‰∏ä‰∏ãÊñáÔºåÈÅøÂÖçÊ≥®ÂÖ•ËØØÂØºÊÄßÊàñ‰∏çÁõ∏ÂÖ≥ÁöÑ‰ø°ÊÅØ„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÈÄöËøá‰ΩøÁî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÈáçÊñ∞Ê†áÊ≥®Âô™Â£∞Êï∞ÊçÆÈõÜÊù•ÊèêÈ´òÊï∞ÊçÆË¥®ÈáèÔºå‰ªéËÄåÂä†Âº∫ÊñáÊú¨ÁõëÁù£ÂíåËØ≠‰πâÂØπÈΩê„ÄÇÂÆöÈáèÁªìÊûúÂíå‰∫∫Â∑•ËØÑ‰º∞Ë°®ÊòéÔºåAVCÂú®ËøûË¥ØÊÄß„ÄÅËØ≠‰πâ‰∏ÄËá¥ÊÄßÂíåËßÜËßâ‰øùÁúüÂ∫¶ÊñπÈù¢‰ºò‰∫éÂº∫Â§ßÁöÑÂü∫Á∫øÊñπÊ≥ïÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂÖàÂâçËßÜËßâ‰ø°ÊÅØ‰∏éÂΩìÂâçËæìÂÖ•ÂÜ≤Á™ÅÁöÑÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÊÉÖÂÜµ‰∏ã„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊïÖ‰∫ãÂª∂Áª≠‰ªªÂä°Êó®Âú®Ê†πÊçÆÂ∑≤ÊúâÁöÑÂõæÂÉèÂíåÊñáÊú¨ÊèèËø∞ÁîüÊàê‰∏ã‰∏ÄÂº†ÂõæÂÉèÔºåÂÖ≥ÈîÆÂú®‰∫éÂ¶Ç‰ΩïÊúâÊïàÂú∞Âà©Áî®ÂÖàÂâçÁöÑËßÜËßâ‰ø°ÊÅØÔºåÂêåÊó∂‰øùËØÅ‰∏éÂΩìÂâçÊñáÊú¨ÊèèËø∞ÁöÑËØ≠‰πâ‰∏ÄËá¥ÊÄß„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®Â§ÑÁêÜËßÜËßâ‰ø°ÊÅØ‰∏éÊñáÊú¨ÊèèËø∞ÂÜ≤Á™ÅÁöÑÊÉÖÂÜµÊó∂ÔºåÂÆπÊòìÂºïÂÖ•ËØØÂØº‰ø°ÊÅØÔºåÂØºËá¥ÁîüÊàêÁªìÊûúËØ≠‰πâ‰∏ç‰∏ÄËá¥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊ†∏ÂøÉÊÄùË∑ØÊòØËá™ÈÄÇÂ∫îÂú∞ÊéßÂà∂ÂÖàÂâçËßÜËßâ‰ø°ÊÅØÂØπÊâ©Êï£ËøáÁ®ãÁöÑÂΩ±Âìç„ÄÇÂΩìÂÖàÂâçÂõæÂÉè‰∏éÂΩìÂâçÊñáÊú¨ËØ≠‰πâÁõ∏ÂÖ≥Êó∂ÔºåÂÖÖÂàÜÂà©Áî®ËßÜËßâ‰ø°ÊÅØÔºõÂΩì‰∏§ËÄÖËØ≠‰πâ‰∏çÁõ∏ÂÖ≥Êó∂ÔºåÈôêÂà∂ËßÜËßâ‰ø°ÊÅØÁöÑÂΩ±ÂìçÔºåÈÅøÂÖçÂºïÂÖ•Âô™Â£∞„ÄÇËøôÁßçËá™ÈÄÇÂ∫îÊéßÂà∂ÈÄöËøáCLIPÊ®°ÂûãÂà§Êñ≠ËØ≠‰πâÁõ∏ÂÖ≥ÊÄßÔºåÂπ∂Ê†πÊçÆÁõ∏ÂÖ≥ÊÄßË∞ÉÊï¥ËßÜËßâ‰ø°ÊÅØÁöÑÊ≥®ÂÖ•Âº∫Â∫¶„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöAVCÊ°ÜÊû∂Âü∫‰∫éÊâ©Êï£Ê®°ÂûãÔºå‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÊ®°ÂùóÔºö1) CLIPÊ®°ÂûãÔºöÁî®‰∫éËÆ°ÁÆóÂÖàÂâçÂõæÂÉè‰∏éÂΩìÂâçÊñáÊú¨ÊèèËø∞ÁöÑËØ≠‰πâÁõ∏‰ººÂ∫¶„ÄÇ2) Ëá™ÈÄÇÂ∫îËßÜËßâÊù°‰ª∂ÊéßÂà∂Ê®°ÂùóÔºöÊ†πÊçÆCLIPÊ®°ÂûãËÆ°ÁÆóÁöÑÁõ∏‰ººÂ∫¶ÔºåÂä®ÊÄÅË∞ÉÊï¥ÂÖàÂâçÂõæÂÉèÂØπÊâ©Êï£ËøáÁ®ãÁöÑÂΩ±Âìç„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÂΩìÁõ∏‰ººÂ∫¶ËæÉÈ´òÊó∂ÔºåÂú®Êâ©Êï£ËøáÁ®ãÁöÑÊó©ÊúüÈò∂ÊÆµÊ≥®ÂÖ•ËßÜËßâ‰ø°ÊÅØÔºõÂΩìÁõ∏‰ººÂ∫¶ËæÉ‰ΩéÊó∂ÔºåÈôêÂà∂ËßÜËßâ‰ø°ÊÅØÁöÑÂΩ±ÂìçÔºå‰ªÖÂú®ÊûÅÊó©ÊúüÈò∂ÊÆµÊ≥®ÂÖ•Â∞ëÈáè‰ø°ÊÅØ„ÄÇ3) Êâ©Êï£Ê®°ÂûãÔºöË¥üË¥£Ê†πÊçÆÊñáÊú¨ÊèèËø∞ÂíåËßÜËßâ‰ø°ÊÅØÁîüÊàêÂõæÂÉè„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éËá™ÈÄÇÂ∫îËßÜËßâÊù°‰ª∂ÊéßÂà∂Êú∫Âà∂„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ¥Êé•Â∞ÜÂÖàÂâçÂõæÂÉè‰Ωú‰∏∫Êù°‰ª∂ËæìÂÖ•‰∏çÂêåÔºåAVCËÉΩÂ§üÊ†πÊçÆËØ≠‰πâÁõ∏ÂÖ≥ÊÄßÂä®ÊÄÅË∞ÉÊï¥ËßÜËßâ‰ø°ÊÅØÁöÑÂΩ±ÂìçÔºå‰ªéËÄåÈÅøÂÖçÂºïÂÖ•Âô™Â£∞ÔºåÊèêÈ´òÁîüÊàêÁªìÊûúÁöÑËØ≠‰πâ‰∏ÄËá¥ÊÄß„ÄÇËøôÁßçËá™ÈÄÇÂ∫îÊéßÂà∂Êú∫Âà∂‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üÊõ¥Â•ΩÂú∞Â§ÑÁêÜËßÜËßâ‰ø°ÊÅØ‰∏éÊñáÊú¨ÊèèËø∞ÂÜ≤Á™ÅÁöÑÊÉÖÂÜµ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ‰ΩøÁî®CLIPÊ®°ÂûãËÆ°ÁÆóËØ≠‰πâÁõ∏‰ººÂ∫¶Ôºå‰∏∫Ëá™ÈÄÇÂ∫îÊéßÂà∂Êèê‰æõ‰æùÊçÆ„ÄÇ2) Ê†πÊçÆËØ≠‰πâÁõ∏‰ººÂ∫¶Ë∞ÉÊï¥ËßÜËßâ‰ø°ÊÅØÊ≥®ÂÖ•ÁöÑÊó∂Èó¥Ê≠•ÔºåÁõ∏‰ººÂ∫¶Ë∂äÈ´òÔºåÊ≥®ÂÖ•Êó∂Èó¥Ë∂äÊó©„ÄÇ3) ‰ΩøÁî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÈáçÊñ∞Ê†áÊ≥®Êï∞ÊçÆÈõÜÔºåÊèêÈ´òÊï∞ÊçÆË¥®ÈáèÔºåÂ¢ûÂº∫ÊñáÊú¨ÁõëÁù£ÂíåËØ≠‰πâÂØπÈΩê„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåAVCÊ°ÜÊû∂Âú®ÊïÖ‰∫ãÂª∂Áª≠‰ªªÂä°‰∏≠ÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇÂú®ÂÆöÈáèÊåáÊ†áÊñπÈù¢ÔºåAVCÂú®ËøûË¥ØÊÄß„ÄÅËØ≠‰πâ‰∏ÄËá¥ÊÄßÂíåËßÜËßâ‰øùÁúüÂ∫¶ÊñπÈù¢Âùá‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇ‰∫∫Â∑•ËØÑ‰º∞ÁªìÊûú‰πüË°®ÊòéÔºåAVCÁîüÊàêÁöÑÂõæÂÉèÊõ¥Á¨¶Âêà‰∫∫Á±ªÁöÑËÆ§Áü•ÔºåÂÖ∑ÊúâÊõ¥È´òÁöÑË¥®Èáè„ÄÇÂ∞§ÂÖ∂ÊòØÂú®ÂÖàÂâçËßÜËßâ‰ø°ÊÅØ‰∏éÂΩìÂâçËæìÂÖ•ÂÜ≤Á™ÅÁöÑÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÊÉÖÂÜµ‰∏ãÔºåAVCÁöÑ‰ºòÂäøÊõ¥Âä†ÊòéÊòæ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éËá™Âä®ÂåñÊïÖ‰∫ãÂàõ‰Ωú„ÄÅÁîµÂΩ±Âà∂‰Ωú„ÄÅÊ∏∏ÊàèÂºÄÂèëÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÁîüÊàêËøûË¥Ø‰∏îËØ≠‰πâ‰∏ÄËá¥ÁöÑÂõæÂÉèÂ∫èÂàóÔºåÂèØ‰ª•ËæÖÂä©Âàõ‰ΩúËÄÖÂø´ÈÄüÊûÑÂª∫ËßÜËßâÊïÖ‰∫ãÔºåÊèêÈ´òÂàõ‰ΩúÊïàÁéá„ÄÇÊ≠§Â§ñÔºåËØ•ÊäÄÊúØËøòÂèØÁî®‰∫éËôöÊãüÁé∞ÂÆûÂíåÂ¢ûÂº∫Áé∞ÂÆûÁ≠âÈ¢ÜÂüüÔºå‰∏∫Áî®Êà∑Êèê‰æõÊõ¥Âä†Ê≤âÊµ∏ÂºèÁöÑ‰ΩìÈ™å„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Story continuation focuses on generating the next image in a narrative sequence so that it remains coherent with both the ongoing text description and the previously observed images. A central challenge in this setting lies in utilizing prior visual context effectively, while ensuring semantic alignment with the current textual input. In this work, we introduce AVC (Adaptive Visual Conditioning), a framework for diffusion-based story continuation. AVC employs the CLIP model to retrieve the most semantically aligned image from previous frames. Crucially, when no sufficiently relevant image is found, AVC adaptively restricts the influence of prior visuals to only the early stages of the diffusion process. This enables the model to exploit visual context when beneficial, while avoiding the injection of misleading or irrelevant information. Furthermore, we improve data quality by re-captioning a noisy dataset using large language models, thereby strengthening textual supervision and semantic alignment. Quantitative results and human evaluations demonstrate that AVC achieves superior coherence, semantic consistency, and visual fidelity compared to strong baselines, particularly in challenging cases where prior visuals conflict with the current input.

