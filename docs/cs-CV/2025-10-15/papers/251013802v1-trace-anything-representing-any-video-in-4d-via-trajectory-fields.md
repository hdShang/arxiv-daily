---
layout: default
title: "Trace Anything: Representing Any Video in 4D via Trajectory Fields"
---

# Trace Anything: Representing Any Video in 4D via Trajectory Fields

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.13802" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.13802v1</a>
  <a href="https://arxiv.org/pdf/2510.13802.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.13802v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.13802v1', 'Trace Anything: Representing Any Video in 4D via Trajectory Fields')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xinhang Liu, Yuxi Xiao, Donny Y. Chen, Jiashi Feng, Yu-Wing Tai, Chi-Keung Tang, Bingyi Kang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-15

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://trace-anything.github.io/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Trace Anythingï¼šæå‡ºåŸºäºè½¨è¿¹åœºçš„è§†é¢‘4Dè¡¨ç¤ºæ–¹æ³•ï¼Œå®ç°é«˜æ•ˆæ—¶ç©ºå»ºæ¨¡ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `è§†é¢‘è¡¨ç¤º` `è½¨è¿¹åœº` `æ—¶ç©ºå»ºæ¨¡` `Bæ ·æ¡æ›²çº¿` `ç¥ç»ç½‘ç»œ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†é¢‘ç†è§£æ–¹æ³•éš¾ä»¥æœ‰æ•ˆå»ºæ¨¡åƒç´ çº§åˆ«çš„æ—¶ç©ºåŠ¨æ€ï¼Œé™åˆ¶äº†å…¶åœ¨å¤æ‚åœºæ™¯ä¸­çš„åº”ç”¨ã€‚
2. Trace Anythingé€šè¿‡é¢„æµ‹æ¯ä¸ªåƒç´ çš„3Dè½¨è¿¹å‡½æ•°ï¼Œå°†è§†é¢‘è¡¨ç¤ºä¸ºè½¨è¿¹åœºï¼Œä»è€Œæ•æ‰ç»†ç²’åº¦çš„æ—¶ç©ºä¿¡æ¯ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒTrace Anythingåœ¨è½¨è¿¹åœºä¼°è®¡å’Œç‚¹è·Ÿè¸ªä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œå¹¶å±•ç°å‡ºç›®æ ‡æ¡ä»¶æ“ä½œç­‰æ¶Œç°èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ‰æ•ˆçš„æ—¶ç©ºè¡¨ç¤ºæ˜¯å»ºæ¨¡ã€ç†è§£å’Œé¢„æµ‹è§†é¢‘åŠ¨æ€çš„åŸºç¡€ã€‚è§†é¢‘çš„åŸºæœ¬å•å…ƒâ€”â€”åƒç´ ï¼Œéšç€æ—¶é—´æ¨ç§»ä¼šå½¢æˆè¿ç»­çš„3Dè½¨è¿¹ï¼Œè¿™æ˜¯åŠ¨æ€çš„åŸºæœ¬å…ƒç´ ã€‚åŸºäºæ­¤ï¼Œæˆ‘ä»¬æå‡ºå°†ä»»ä½•è§†é¢‘è¡¨ç¤ºä¸ºä¸€ä¸ªè½¨è¿¹åœºï¼šä¸€ä¸ªå¯†é›†çš„æ˜ å°„ï¼Œå®ƒä¸ºæ¯ä¸€å¸§ä¸­çš„æ¯ä¸ªåƒç´ åˆ†é…ä¸€ä¸ªéšæ—¶é—´å˜åŒ–çš„è¿ç»­3Dè½¨è¿¹å‡½æ•°ã€‚åŸºäºè¿™ç§è¡¨ç¤ºï¼Œæˆ‘ä»¬å¼•å…¥äº†Trace Anythingï¼Œä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œå¯ä»¥é€šè¿‡ä¸€æ¬¡å‰å‘ä¼ æ’­é¢„æµ‹æ•´ä¸ªè½¨è¿¹åœºã€‚å…·ä½“æ¥è¯´ï¼Œå¯¹äºæ¯ä¸€å¸§ä¸­çš„æ¯ä¸ªåƒç´ ï¼Œæˆ‘ä»¬çš„æ¨¡å‹é¢„æµ‹ä¸€ç»„æ§åˆ¶ç‚¹ï¼Œè¿™äº›æ§åˆ¶ç‚¹å‚æ•°åŒ–ä¸€æ¡è½¨è¿¹ï¼ˆå³Bæ ·æ¡ï¼‰ï¼Œä»è€Œåœ¨ä»»æ„æŸ¥è¯¢æ—¶é—´ç¬é—´äº§ç”Ÿå…¶3Dä½ç½®ã€‚æˆ‘ä»¬åœ¨å¤§è§„æ¨¡4Dæ•°æ®ä¸Šè®­ç»ƒäº†Trace Anythingæ¨¡å‹ï¼ŒåŒ…æ‹¬æ¥è‡ªæˆ‘ä»¬æ–°å¹³å°çš„æ•°æ®ã€‚å®éªŒè¡¨æ˜ï¼šï¼ˆiï¼‰Trace Anythingåœ¨æˆ‘ä»¬æ–°çš„è½¨è¿¹åœºä¼°è®¡åŸºå‡†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶åœ¨å·²å»ºç«‹çš„ç‚¹è·Ÿè¸ªåŸºå‡†ä¸Šè¡¨ç°å‡ºç«äº‰åŠ›ï¼›ï¼ˆiiï¼‰ç”±äºå…¶ä¸€æ¬¡æ€§èŒƒå¼ï¼Œæ— éœ€è¿­ä»£ä¼˜åŒ–æˆ–è¾…åŠ©ä¼°è®¡å™¨ï¼Œå› æ­¤å®ƒæä¾›äº†æ˜¾è‘—çš„æ•ˆç‡æå‡ï¼›ï¼ˆiiiï¼‰å®ƒè¡¨ç°å‡ºæ¶Œç°èƒ½åŠ›ï¼ŒåŒ…æ‹¬ç›®æ ‡æ¡ä»¶æ“ä½œã€è¿åŠ¨é¢„æµ‹å’Œæ—¶ç©ºèåˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰è§†é¢‘ç†è§£æ–¹æ³•é€šå¸¸ä¾èµ–äºç¦»æ•£çš„å¸§åºåˆ—å¤„ç†ï¼Œéš¾ä»¥æ•æ‰åƒç´ çº§åˆ«çš„è¿ç»­æ—¶ç©ºåŠ¨æ€ã€‚ä¾‹å¦‚ï¼ŒåŸºäºå…‰æµçš„æ–¹æ³•è™½ç„¶å¯ä»¥ä¼°è®¡åƒç´ çš„è¿åŠ¨ï¼Œä½†é€šå¸¸æ˜¯å±€éƒ¨å’Œç¬æ—¶çš„ï¼Œæ— æ³•æä¾›å®Œæ•´çš„è½¨è¿¹ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œè¿­ä»£ä¼˜åŒ–å’Œè¾…åŠ©ä¼°è®¡å™¨å¢åŠ äº†è®¡ç®—å¤æ‚åº¦ï¼Œé™åˆ¶äº†æ•ˆç‡ã€‚å› æ­¤ï¼Œå¦‚ä½•é«˜æ•ˆåœ°è¡¨ç¤ºå’Œå»ºæ¨¡è§†é¢‘ä¸­çš„åƒç´ è½¨è¿¹æ˜¯äºŸå¾…è§£å†³çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†è§†é¢‘ä¸­çš„æ¯ä¸ªåƒç´ è§†ä¸ºä¸€ä¸ªåœ¨æ—¶ç©ºä¸­è¿åŠ¨çš„ç‚¹ï¼Œå¹¶ç”¨è¿ç»­çš„3Dè½¨è¿¹å‡½æ•°æ¥æè¿°å…¶è¿åŠ¨è½¨è¿¹ã€‚é€šè¿‡é¢„æµ‹æ¯ä¸ªåƒç´ çš„è½¨è¿¹å‡½æ•°ï¼Œå¯ä»¥å°†è§†é¢‘è¡¨ç¤ºä¸ºä¸€ä¸ªå¯†é›†çš„è½¨è¿¹åœºï¼Œä»è€Œæ•æ‰ç»†ç²’åº¦çš„æ—¶ç©ºä¿¡æ¯ã€‚è¿™ç§è¡¨ç¤ºæ–¹æ³•å¯ä»¥å…‹æœä¼ ç»Ÿæ–¹æ³•çš„å±€é™æ€§ï¼Œå®ç°é«˜æ•ˆçš„æ—¶ç©ºå»ºæ¨¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTrace Anythingçš„æ•´ä½“æ¡†æ¶æ˜¯ä¸€ä¸ªå•é˜¶æ®µçš„å‰å‘ç¥ç»ç½‘ç»œã€‚è¾“å…¥æ˜¯è§†é¢‘å¸§åºåˆ—ï¼Œè¾“å‡ºæ˜¯æ¯ä¸ªåƒç´ çš„3Dè½¨è¿¹å‡½æ•°ã€‚å…·ä½“æ¥è¯´ï¼Œå¯¹äºæ¯ä¸€å¸§ä¸­çš„æ¯ä¸ªåƒç´ ï¼Œç½‘ç»œé¢„æµ‹ä¸€ç»„æ§åˆ¶ç‚¹ï¼Œè¿™äº›æ§åˆ¶ç‚¹å‚æ•°åŒ–ä¸€æ¡Bæ ·æ¡æ›²çº¿ï¼Œä»è€Œè¡¨ç¤ºè¯¥åƒç´ çš„3Dè½¨è¿¹ã€‚æ•´ä¸ªè¿‡ç¨‹æ— éœ€è¿­ä»£ä¼˜åŒ–æˆ–è¾…åŠ©ä¼°è®¡å™¨ï¼Œå¯ä»¥ä¸€æ¬¡æ€§å®Œæˆã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†è§†é¢‘è¡¨ç¤ºä¸ºè½¨è¿¹åœºçš„æ¦‚å¿µï¼Œä»¥åŠé€šè¿‡ç¥ç»ç½‘ç»œç›´æ¥é¢„æµ‹è½¨è¿¹å‡½æ•°çš„æ–¹æ³•ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒTrace Anythingå¯ä»¥æ›´å®Œæ•´ã€æ›´é«˜æ•ˆåœ°æ•æ‰è§†é¢‘ä¸­çš„æ—¶ç©ºåŠ¨æ€ã€‚æ­¤å¤–ï¼Œé€šè¿‡Bæ ·æ¡æ›²çº¿å‚æ•°åŒ–è½¨è¿¹ï¼Œå¯ä»¥çµæ´»åœ°è¡¨ç¤ºå„ç§å¤æ‚çš„è¿åŠ¨æ¨¡å¼ã€‚

**å…³é”®è®¾è®¡**ï¼šTrace Anythingçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š(1) ä½¿ç”¨Bæ ·æ¡æ›²çº¿å‚æ•°åŒ–è½¨è¿¹ï¼Œé€šè¿‡æ§åˆ¶ç‚¹æ¥è°ƒèŠ‚è½¨è¿¹çš„å½¢çŠ¶ï¼›(2) è®¾è®¡åˆé€‚çš„ç½‘ç»œç»“æ„ï¼Œç”¨äºé¢„æµ‹æ¯ä¸ªåƒç´ çš„æ§åˆ¶ç‚¹ï¼›(3) ä½¿ç”¨å¤§è§„æ¨¡4Dæ•°æ®è¿›è¡Œè®­ç»ƒï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼›(4) è®¾è®¡åˆé€‚çš„æŸå¤±å‡½æ•°ï¼Œä¾‹å¦‚è½¨è¿¹å¹³æ»‘æŸå¤±å’Œè½¨è¿¹ä¸€è‡´æ€§æŸå¤±ï¼Œä»¥ä¿è¯è½¨è¿¹çš„è´¨é‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

Trace Anythingåœ¨æ–°çš„è½¨è¿¹åœºä¼°è®¡åŸºå‡†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶åœ¨å·²å»ºç«‹çš„ç‚¹è·Ÿè¸ªåŸºå‡†ä¸Šè¡¨ç°å‡ºç«äº‰åŠ›ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒTrace Anythingå…·æœ‰æ˜¾è‘—çš„æ•ˆç‡ä¼˜åŠ¿ï¼Œå› ä¸ºå®ƒå¯ä»¥é€šè¿‡ä¸€æ¬¡å‰å‘ä¼ æ’­é¢„æµ‹æ•´ä¸ªè½¨è¿¹åœºï¼Œè€Œæ— éœ€è¿­ä»£ä¼˜åŒ–æˆ–è¾…åŠ©ä¼°è®¡å™¨ã€‚æ­¤å¤–ï¼ŒTrace Anythingè¿˜å±•ç°å‡ºç›®æ ‡æ¡ä»¶æ“ä½œã€è¿åŠ¨é¢„æµ‹å’Œæ—¶ç©ºèåˆç­‰æ¶Œç°èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Trace Anythingå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼ŒåŒ…æ‹¬è§†é¢‘ç¼–è¾‘ã€è¿åŠ¨æ•æ‰ã€è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨è§†é¢‘ç¼–è¾‘ä¸­ï¼Œå¯ä»¥åˆ©ç”¨Trace Anythingå®ç°ç²¾ç¡®çš„ç‰©ä½“è·Ÿè¸ªå’Œåˆ†å‰²ï¼›åœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼Œå¯ä»¥åˆ©ç”¨Trace Anythingé¢„æµ‹è¡Œäººå’Œè½¦è¾†çš„è¿åŠ¨è½¨è¿¹ï¼Œæé«˜å®‰å…¨æ€§ã€‚æ­¤å¤–ï¼ŒTrace Anythingè¿˜å¯ä»¥ç”¨äºç”Ÿæˆé€¼çœŸçš„è™šæ‹Ÿç°å®åœºæ™¯ï¼Œä»¥åŠè¿›è¡Œè§†é¢‘ä¿®å¤å’Œå¢å¼ºã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Effective spatio-temporal representation is fundamental to modeling, understanding, and predicting dynamics in videos. The atomic unit of a video, the pixel, traces a continuous 3D trajectory over time, serving as the primitive element of dynamics. Based on this principle, we propose representing any video as a Trajectory Field: a dense mapping that assigns a continuous 3D trajectory function of time to each pixel in every frame. With this representation, we introduce Trace Anything, a neural network that predicts the entire trajectory field in a single feed-forward pass. Specifically, for each pixel in each frame, our model predicts a set of control points that parameterizes a trajectory (i.e., a B-spline), yielding its 3D position at arbitrary query time instants. We trained the Trace Anything model on large-scale 4D data, including data from our new platform, and our experiments demonstrate that: (i) Trace Anything achieves state-of-the-art performance on our new benchmark for trajectory field estimation and performs competitively on established point-tracking benchmarks; (ii) it offers significant efficiency gains thanks to its one-pass paradigm, without requiring iterative optimization or auxiliary estimators; and (iii) it exhibits emergent abilities, including goal-conditioned manipulation, motion forecasting, and spatio-temporal fusion. Project page: https://trace-anything.github.io/.

