---
layout: default
title: Group-Wise Optimization for Self-Extensible Codebooks in Vector Quantized Models
---

# Group-Wise Optimization for Self-Extensible Codebooks in Vector Quantized Models

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.13331" target="_blank" class="toolbar-btn">arXiv: 2510.13331v2</a>
    <a href="https://arxiv.org/pdf/2510.13331.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.13331v2" 
            onclick="toggleFavorite(this, '2510.13331v2', 'Group-Wise Optimization for Self-Extensible Codebooks in Vector Quantized Models')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Hong-Kai Zheng, Piji Li

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-15 (Êõ¥Êñ∞: 2025-10-16)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Group-VQÔºåÈÄöËøáÂàÜÁªÑ‰ºòÂåñËá™Êâ©Â±ïÁ†Å‰π¶Ëß£ÂÜ≥VQ-VAE‰∏≠ÁöÑÁ†Å‰π¶ÂùçÂ°åÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±ÂõõÔºöÁîüÊàêÂºèÂä®‰Ωú (Generative Motion)**

**ÂÖ≥ÈîÆËØç**: `ÂêëÈáèÈáèÂåñ` `ÂèòÂàÜËá™ÁºñÁ†ÅÂô®` `Á†Å‰π¶Â≠¶‰π†` `ÂàÜÁªÑ‰ºòÂåñ` `Ëá™ÁõëÁù£Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. VQ-VAE‰∏≠Á†Å‰π¶ÂùçÂ°åÈôêÂà∂‰∫ÜÊ®°ÂûãÊÄßËÉΩÔºåÁé∞ÊúâÊñπÊ≥ïÊàñÈááÁî®ÈùôÊÄÅÁ†Å‰π¶ÔºåÊàñÂÖ®Â±ÄËÅîÂêà‰ºòÂåñÔºåÂùáÁ∫¶Êùü‰∫ÜÁ†Å‰π¶ÁöÑÂ≠¶‰π†ËÉΩÂäõ„ÄÇ
2. Group-VQÈÄöËøáÂàÜÁªÑ‰ºòÂåñÁ†Å‰π¶ÔºåÁªÑÂÜÖËÅîÂêà‰ºòÂåñÔºåÁªÑÈó¥Áã¨Á´ã‰ºòÂåñÔºåÊèêÂçáÁ†Å‰π¶Âà©Áî®ÁéáÂíåÈáçÂª∫ÊïàÊûúÁöÑÂπ≥Ë°°„ÄÇ
3. ÂºïÂÖ•ÂÖçËÆ≠ÁªÉÁöÑÁ†Å‰π¶ÈáçÈááÊ†∑ÊñπÊ≥ïÔºåÊîØÊåÅËÆ≠ÁªÉÂêéÁÅµÊ¥ªË∞ÉÊï¥Á†Å‰π¶Â§ßÂ∞èÔºåÂÆûÈ™åË°®ÊòéGroup-VQÂú®ÂõæÂÉèÈáçÂª∫‰ªªÂä°‰∏äÊÄßËÉΩÊèêÂçá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÂêëÈáèÈáèÂåñÂèòÂàÜËá™ÁºñÁ†ÅÂô®(VQ-VAE)Âà©Áî®Ëá™ÁõëÁù£Â≠¶‰π†ÔºåÈÄöËøáÈáçÂª∫‰ªªÂä°Ôºå‰ΩøÁî®Á†Å‰π¶‰∏≠ÊúÄËøëÁöÑÂêëÈáèÊù•Ë°®Á§∫ËøûÁª≠ÂêëÈáè„ÄÇÁÑ∂ËÄåÔºåÁ†Å‰π¶ÂùçÂ°åÁ≠âÈóÆÈ¢ò‰ªçÁÑ∂Â≠òÂú®‰∫éVQÊ®°Âûã‰∏≠„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåÁé∞ÊúâÁöÑÊñπÊ≥ïÈááÁî®ÈöêÂºèÁöÑÈùôÊÄÅÁ†Å‰π¶ÊàñËÅîÂêà‰ºòÂåñÊï¥‰∏™Á†Å‰π¶Ôºå‰ΩÜËøô‰∫õÊñπÊ≥ïÈôêÂà∂‰∫ÜÁ†Å‰π¶ÁöÑÂ≠¶‰π†ËÉΩÂäõÔºåÂØºËá¥ÈáçÂª∫Ë¥®Èáè‰∏ãÈôç„ÄÇÊú¨ÊñáÊèêÂá∫‰∫ÜGroup-VQÔºåÂÆÉÂØπÁ†Å‰π¶ËøõË°åÂàÜÁªÑ‰ºòÂåñ„ÄÇÊØè‰∏™ÁªÑÁã¨Á´ã‰ºòÂåñÔºåÁªÑÂÜÖËøõË°åËÅîÂêà‰ºòÂåñ„ÄÇËøôÁßçÊñπÊ≥ïÊîπÂñÑ‰∫ÜÁ†Å‰π¶Âà©Áî®ÁéáÂíåÈáçÂª∫ÊÄßËÉΩ‰πãÈó¥ÁöÑÊùÉË°°„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ËøòÂºïÂÖ•‰∫Ü‰∏ÄÁßçÊó†ÈúÄËÆ≠ÁªÉÁöÑÁ†Å‰π¶ÈáçÈááÊ†∑ÊñπÊ≥ïÔºåÂÖÅËÆ∏Âú®ËÆ≠ÁªÉÂêéË∞ÉÊï¥Á†Å‰π¶Â§ßÂ∞è„ÄÇÂú®ÂêÑÁßçËÆæÁΩÆ‰∏ãÁöÑÂõæÂÉèÈáçÂª∫ÂÆûÈ™å‰∏≠ÔºåGroup-VQËØÅÊòé‰∫ÜÈáçÂª∫ÊåáÊ†áÁöÑÊÄßËÉΩÊúâÊâÄÊèêÈ´òÔºåÂπ∂‰∏îËÆ≠ÁªÉÂêéÁöÑÁ†Å‰π¶ÈááÊ†∑ÊñπÊ≥ïÂÆûÁé∞‰∫ÜË∞ÉÊï¥Á†Å‰π¶Â§ßÂ∞èÁöÑÊúüÊúõÁÅµÊ¥ªÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöVQ-VAE‰∏≠ÁöÑÁ†Å‰π¶ÂùçÂ°åÈóÆÈ¢òÔºåÂç≥ÈÉ®ÂàÜÁ†ÅÂ≠óË¢´ËøáÂ∫¶‰ΩøÁî®ÔºåËÄåÂè¶‰∏Ä‰∫õÁ†ÅÂ≠óÂàôÂæàÂ∞ëÊàñÊ†πÊú¨‰∏çË¢´‰ΩøÁî®ÔºåÂØºËá¥Á†Å‰π¶Âà©Áî®Áéá‰ΩéÔºåÂΩ±ÂìçÈáçÂª∫Ë¥®Èáè„ÄÇÁé∞ÊúâÊñπÊ≥ïË¶Å‰πà‰ΩøÁî®ÈùôÊÄÅÁ†Å‰π¶ÔºåÈôêÂà∂‰∫ÜÁ†Å‰π¶ÁöÑÂ≠¶‰π†ËÉΩÂäõÔºõË¶Å‰πàÂÖ®Â±ÄËÅîÂêà‰ºòÂåñÊï¥‰∏™Á†Å‰π¶ÔºåËÆ°ÁÆóÂ§çÊùÇÂ∫¶È´òÔºå‰∏îÂÆπÊòìÈô∑ÂÖ•Â±ÄÈÉ®ÊúÄ‰ºò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÂ∞ÜÁ†Å‰π¶ÂàÜÊàêÂ§ö‰∏™ÁªÑÔºåÊØè‰∏™ÁªÑÁã¨Á´ã‰ºòÂåñÔºåÁªÑÂÜÖËøõË°åËÅîÂêà‰ºòÂåñ„ÄÇËøôÊ†∑Êó¢ËÉΩ‰øùËØÅÁªÑÂÜÖÁ†ÅÂ≠óÁöÑÂçèÂêåÂ≠¶‰π†ÔºåÂèàËÉΩÈÅøÂÖçÂÖ®Â±Ä‰ºòÂåñÂ∏¶Êù•ÁöÑËÆ°ÁÆóË¥üÊãÖÂíåÂ±ÄÈÉ®ÊúÄ‰ºòÈóÆÈ¢ò„ÄÇÈÄöËøáÂàÜÁªÑ‰ºòÂåñÔºåÂèØ‰ª•Êõ¥Â•ΩÂú∞Âπ≥Ë°°Á†Å‰π¶Âà©Áî®ÁéáÂíåÈáçÂª∫ÊÄßËÉΩ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöGroup-VQÊ≤øÁî®VQ-VAEÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÔºåÂåÖÊã¨ÁºñÁ†ÅÂô®„ÄÅÈáèÂåñÂ±ÇÂíåËß£Á†ÅÂô®„ÄÇÂÖ≥ÈîÆÂú®‰∫éÈáèÂåñÂ±ÇÔºåÂÆÉÂ∞ÜÁºñÁ†ÅÂô®ÁöÑËæìÂá∫Êò†Â∞ÑÂà∞Á†Å‰π¶‰∏≠ÁöÑÊúÄËøëÂêëÈáè„ÄÇ‰∏çÂêå‰πãÂ§ÑÂú®‰∫éÔºåGroup-VQÂ∞ÜÁ†Å‰π¶ÂàíÂàÜ‰∏∫Â§ö‰∏™ÁªÑÔºåÊØè‰∏™ÁªÑÁã¨Á´ãËøõË°åÈáèÂåñÂíå‰ºòÂåñ„ÄÇËÆ≠ÁªÉËøáÁ®ã‰∏≠ÔºåÊØè‰∏™ÁªÑÁöÑÁ†ÅÂ≠óÂè™‰∏éËØ•ÁªÑÂÜÖÁöÑÊ†∑Êú¨ËøõË°åÂÖ≥ËÅîÂíåÊõ¥Êñ∞„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊ†∏ÂøÉÂàõÊñ∞Âú®‰∫éÂàÜÁªÑ‰ºòÂåñÁ≠ñÁï•„ÄÇ‰∏éÂÖ®Â±Ä‰ºòÂåñÁõ∏ÊØîÔºåÂàÜÁªÑ‰ºòÂåñÈôç‰Ωé‰∫ÜËÆ°ÁÆóÂ§çÊùÇÂ∫¶ÔºåÂπ∂ÂÖÅËÆ∏ÊØè‰∏™ÁªÑ‰∏ìÊ≥®‰∫éÂ≠¶‰π†ÁâπÂÆöÁöÑÁâπÂæÅË°®Á§∫„ÄÇ‰∏éÈùôÊÄÅÁ†Å‰π¶Áõ∏ÊØîÔºåÂàÜÁªÑ‰ºòÂåñËµã‰∫à‰∫ÜÁ†Å‰π¶Êõ¥Âº∫ÁöÑÂ≠¶‰π†ËÉΩÂäõÂíåÈÄÇÂ∫îÊÄß„ÄÇÊ≠§Â§ñÔºåÊèêÂá∫ÁöÑÂÖçËÆ≠ÁªÉÁ†Å‰π¶ÈáçÈááÊ†∑ÊñπÊ≥ïÔºåÂÖÅËÆ∏Âú®ËÆ≠ÁªÉÂêéÁÅµÊ¥ªË∞ÉÊï¥Á†Å‰π¶Â§ßÂ∞èÔºåËøõ‰∏ÄÊ≠•ÊèêÂçá‰∫ÜÊ®°ÂûãÁöÑÁÅµÊ¥ªÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂàÜÁªÑÊï∞ÈáèÊòØÂÖ≥ÈîÆÂèÇÊï∞ÔºåÈúÄË¶ÅÊ†πÊçÆÊï∞ÊçÆÈõÜÂíå‰ªªÂä°ËøõË°åË∞ÉÊï¥„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨ÈáçÂª∫ÊçüÂ§±ÂíåÁ†Å‰π¶Êõ¥Êñ∞ÊçüÂ§±„ÄÇÈáçÂª∫ÊçüÂ§±Ë°°ÈáèËß£Á†ÅÂô®ÁöÑËæìÂá∫‰∏éÂéüÂßãËæìÂÖ•ÁöÑÂ∑ÆÂºÇ„ÄÇÁ†Å‰π¶Êõ¥Êñ∞ÊçüÂ§±ÈºìÂä±Á†ÅÂ≠óÂêëÂÖ∂ÊúÄËøëÁöÑÁºñÁ†ÅÂô®ËæìÂá∫ÁßªÂä®ÔºåÂπ∂Èò≤Ê≠¢Á†Å‰π¶ÂùçÂ°å„ÄÇÂÖçËÆ≠ÁªÉÁ†Å‰π¶ÈáçÈááÊ†∑ÊñπÊ≥ïÂü∫‰∫éÁ†ÅÂ≠óÁöÑ‰ΩøÁî®È¢ëÁéáËøõË°åÈááÊ†∑Ôºå‰øùÁïô‰ΩøÁî®È¢ëÁéáÈ´òÁöÑÁ†ÅÂ≠óÔºåÂπ∂ÈöèÊú∫ÂàùÂßãÂåñÊñ∞ÁöÑÁ†ÅÂ≠ó„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåGroup-VQÂú®ÂõæÂÉèÈáçÂª∫‰ªªÂä°‰∏ä‰ºò‰∫éÁé∞ÊúâÁöÑVQ-VAEÂèò‰Ωì„ÄÇÂú®‰∏çÂêåÊï∞ÊçÆÈõÜÂíåËÆæÁΩÆ‰∏ãÔºåGroup-VQÂùáÂèñÂæó‰∫ÜÊõ¥È´òÁöÑÈáçÂª∫Ë¥®ÈáèÔºåÂπ∂ÊúâÊïàÁºìËß£‰∫ÜÁ†Å‰π¶ÂùçÂ°åÈóÆÈ¢ò„ÄÇÊ≠§Â§ñÔºåÂÖçËÆ≠ÁªÉÁ†Å‰π¶ÈáçÈááÊ†∑ÊñπÊ≥ïËÉΩÂ§üÁÅµÊ¥ªË∞ÉÊï¥Á†Å‰π¶Â§ßÂ∞èÔºåÂπ∂Âú®‰øùÊåÅÈáçÂª∫Ë¥®ÈáèÁöÑÂêåÊó∂ÔºåÈôç‰ΩéËÆ°ÁÆóÂ§çÊùÇÂ∫¶„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

Group-VQÂèØÂ∫îÁî®‰∫éÂõæÂÉè„ÄÅÈü≥È¢ë„ÄÅËßÜÈ¢ëÁ≠âÂ§öÁßçÊ®°ÊÄÅÊï∞ÊçÆÁöÑÂéãÁº©„ÄÅÈáçÂª∫ÂíåÁîüÊàê‰ªªÂä°„ÄÇ‰æãÂ¶ÇÔºåÂú®ÂõæÂÉèÂéãÁº©È¢ÜÂüüÔºåGroup-VQÂèØ‰ª•Â≠¶‰π†Âà∞Êõ¥ÊúâÊïàÁöÑÂõæÂÉèË°®Á§∫Ôºå‰ªéËÄåÂÆûÁé∞Êõ¥È´òÁöÑÂéãÁº©ÁéáÂíåÊõ¥Â•ΩÁöÑÈáçÂª∫Ë¥®Èáè„ÄÇÂú®ÁîüÊàêÊ®°ÂûãÈ¢ÜÂüüÔºåGroup-VQÂèØ‰ª•‰Ωú‰∏∫‰∏ÄÁßçÊúâÊïàÁöÑÂÖàÈ™åÁü•ËØÜÔºåÂºïÂØºÁîüÊàêËøáÁ®ãÔºåÁîüÊàêÊõ¥ÈÄºÁúüÁöÑÂõæÂÉèÊàñÈü≥È¢ë„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Vector Quantized Variational Autoencoders (VQ-VAEs) leverage self-supervised learning through reconstruction tasks to represent continuous vectors using the closest vectors in a codebook. However, issues such as codebook collapse persist in the VQ model. To address these issues, existing approaches employ implicit static codebooks or jointly optimize the entire codebook, but these methods constrain the codebook's learning capability, leading to reduced reconstruction quality. In this paper, we propose Group-VQ, which performs group-wise optimization on the codebook. Each group is optimized independently, with joint optimization performed within groups. This approach improves the trade-off between codebook utilization and reconstruction performance. Additionally, we introduce a training-free codebook resampling method, allowing post-training adjustment of the codebook size. In image reconstruction experiments under various settings, Group-VQ demonstrates improved performance on reconstruction metrics. And the post-training codebook sampling method achieves the desired flexibility in adjusting the codebook size.

