---
layout: default
title: Group-Wise Optimization for Self-Extensible Codebooks in Vector Quantized Models
---

# Group-Wise Optimization for Self-Extensible Codebooks in Vector Quantized Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.13331" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.13331v2</a>
  <a href="https://arxiv.org/pdf/2510.13331.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.13331v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.13331v2', 'Group-Wise Optimization for Self-Extensible Codebooks in Vector Quantized Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hong-Kai Zheng, Piji Li

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-15 (æ›´æ–°: 2025-10-16)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGroup-VQï¼Œé€šè¿‡åˆ†ç»„ä¼˜åŒ–è‡ªæ‰©å±•ç ä¹¦è§£å†³VQ-VAEä¸­çš„ç ä¹¦åå¡Œé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)**

**å…³é”®è¯**: `å‘é‡é‡åŒ–` `å˜åˆ†è‡ªç¼–ç å™¨` `ç ä¹¦å­¦ä¹ ` `åˆ†ç»„ä¼˜åŒ–` `è‡ªç›‘ç£å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. VQ-VAEä¸­ç ä¹¦åå¡Œé™åˆ¶äº†æ¨¡å‹æ€§èƒ½ï¼Œç°æœ‰æ–¹æ³•æˆ–é‡‡ç”¨é™æ€ç ä¹¦ï¼Œæˆ–å…¨å±€è”åˆä¼˜åŒ–ï¼Œå‡çº¦æŸäº†ç ä¹¦çš„å­¦ä¹ èƒ½åŠ›ã€‚
2. Group-VQé€šè¿‡åˆ†ç»„ä¼˜åŒ–ç ä¹¦ï¼Œç»„å†…è”åˆä¼˜åŒ–ï¼Œç»„é—´ç‹¬ç«‹ä¼˜åŒ–ï¼Œæå‡ç ä¹¦åˆ©ç”¨ç‡å’Œé‡å»ºæ•ˆæœçš„å¹³è¡¡ã€‚
3. å¼•å…¥å…è®­ç»ƒçš„ç ä¹¦é‡é‡‡æ ·æ–¹æ³•ï¼Œæ”¯æŒè®­ç»ƒåçµæ´»è°ƒæ•´ç ä¹¦å¤§å°ï¼Œå®éªŒè¡¨æ˜Group-VQåœ¨å›¾åƒé‡å»ºä»»åŠ¡ä¸Šæ€§èƒ½æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å‘é‡é‡åŒ–å˜åˆ†è‡ªç¼–ç å™¨(VQ-VAE)åˆ©ç”¨è‡ªç›‘ç£å­¦ä¹ ï¼Œé€šè¿‡é‡å»ºä»»åŠ¡ï¼Œä½¿ç”¨ç ä¹¦ä¸­æœ€è¿‘çš„å‘é‡æ¥è¡¨ç¤ºè¿ç»­å‘é‡ã€‚ç„¶è€Œï¼Œç ä¹¦åå¡Œç­‰é—®é¢˜ä»ç„¶å­˜åœ¨äºVQæ¨¡å‹ä¸­ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œç°æœ‰çš„æ–¹æ³•é‡‡ç”¨éšå¼çš„é™æ€ç ä¹¦æˆ–è”åˆä¼˜åŒ–æ•´ä¸ªç ä¹¦ï¼Œä½†è¿™äº›æ–¹æ³•é™åˆ¶äº†ç ä¹¦çš„å­¦ä¹ èƒ½åŠ›ï¼Œå¯¼è‡´é‡å»ºè´¨é‡ä¸‹é™ã€‚æœ¬æ–‡æå‡ºäº†Group-VQï¼Œå®ƒå¯¹ç ä¹¦è¿›è¡Œåˆ†ç»„ä¼˜åŒ–ã€‚æ¯ä¸ªç»„ç‹¬ç«‹ä¼˜åŒ–ï¼Œç»„å†…è¿›è¡Œè”åˆä¼˜åŒ–ã€‚è¿™ç§æ–¹æ³•æ”¹å–„äº†ç ä¹¦åˆ©ç”¨ç‡å’Œé‡å»ºæ€§èƒ½ä¹‹é—´çš„æƒè¡¡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ç§æ— éœ€è®­ç»ƒçš„ç ä¹¦é‡é‡‡æ ·æ–¹æ³•ï¼Œå…è®¸åœ¨è®­ç»ƒåè°ƒæ•´ç ä¹¦å¤§å°ã€‚åœ¨å„ç§è®¾ç½®ä¸‹çš„å›¾åƒé‡å»ºå®éªŒä¸­ï¼ŒGroup-VQè¯æ˜äº†é‡å»ºæŒ‡æ ‡çš„æ€§èƒ½æœ‰æ‰€æé«˜ï¼Œå¹¶ä¸”è®­ç»ƒåçš„ç ä¹¦é‡‡æ ·æ–¹æ³•å®ç°äº†è°ƒæ•´ç ä¹¦å¤§å°çš„æœŸæœ›çµæ´»æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šVQ-VAEä¸­çš„ç ä¹¦åå¡Œé—®é¢˜ï¼Œå³éƒ¨åˆ†ç å­—è¢«è¿‡åº¦ä½¿ç”¨ï¼Œè€Œå¦ä¸€äº›ç å­—åˆ™å¾ˆå°‘æˆ–æ ¹æœ¬ä¸è¢«ä½¿ç”¨ï¼Œå¯¼è‡´ç ä¹¦åˆ©ç”¨ç‡ä½ï¼Œå½±å“é‡å»ºè´¨é‡ã€‚ç°æœ‰æ–¹æ³•è¦ä¹ˆä½¿ç”¨é™æ€ç ä¹¦ï¼Œé™åˆ¶äº†ç ä¹¦çš„å­¦ä¹ èƒ½åŠ›ï¼›è¦ä¹ˆå…¨å±€è”åˆä¼˜åŒ–æ•´ä¸ªç ä¹¦ï¼Œè®¡ç®—å¤æ‚åº¦é«˜ï¼Œä¸”å®¹æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šå°†ç ä¹¦åˆ†æˆå¤šä¸ªç»„ï¼Œæ¯ä¸ªç»„ç‹¬ç«‹ä¼˜åŒ–ï¼Œç»„å†…è¿›è¡Œè”åˆä¼˜åŒ–ã€‚è¿™æ ·æ—¢èƒ½ä¿è¯ç»„å†…ç å­—çš„ååŒå­¦ä¹ ï¼Œåˆèƒ½é¿å…å…¨å±€ä¼˜åŒ–å¸¦æ¥çš„è®¡ç®—è´Ÿæ‹…å’Œå±€éƒ¨æœ€ä¼˜é—®é¢˜ã€‚é€šè¿‡åˆ†ç»„ä¼˜åŒ–ï¼Œå¯ä»¥æ›´å¥½åœ°å¹³è¡¡ç ä¹¦åˆ©ç”¨ç‡å’Œé‡å»ºæ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šGroup-VQæ²¿ç”¨VQ-VAEçš„æ•´ä½“æ¡†æ¶ï¼ŒåŒ…æ‹¬ç¼–ç å™¨ã€é‡åŒ–å±‚å’Œè§£ç å™¨ã€‚å…³é”®åœ¨äºé‡åŒ–å±‚ï¼Œå®ƒå°†ç¼–ç å™¨çš„è¾“å‡ºæ˜ å°„åˆ°ç ä¹¦ä¸­çš„æœ€è¿‘å‘é‡ã€‚ä¸åŒä¹‹å¤„åœ¨äºï¼ŒGroup-VQå°†ç ä¹¦åˆ’åˆ†ä¸ºå¤šä¸ªç»„ï¼Œæ¯ä¸ªç»„ç‹¬ç«‹è¿›è¡Œé‡åŒ–å’Œä¼˜åŒ–ã€‚è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¯ä¸ªç»„çš„ç å­—åªä¸è¯¥ç»„å†…çš„æ ·æœ¬è¿›è¡Œå…³è”å’Œæ›´æ–°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæ ¸å¿ƒåˆ›æ–°åœ¨äºåˆ†ç»„ä¼˜åŒ–ç­–ç•¥ã€‚ä¸å…¨å±€ä¼˜åŒ–ç›¸æ¯”ï¼Œåˆ†ç»„ä¼˜åŒ–é™ä½äº†è®¡ç®—å¤æ‚åº¦ï¼Œå¹¶å…è®¸æ¯ä¸ªç»„ä¸“æ³¨äºå­¦ä¹ ç‰¹å®šçš„ç‰¹å¾è¡¨ç¤ºã€‚ä¸é™æ€ç ä¹¦ç›¸æ¯”ï¼Œåˆ†ç»„ä¼˜åŒ–èµ‹äºˆäº†ç ä¹¦æ›´å¼ºçš„å­¦ä¹ èƒ½åŠ›å’Œé€‚åº”æ€§ã€‚æ­¤å¤–ï¼Œæå‡ºçš„å…è®­ç»ƒç ä¹¦é‡é‡‡æ ·æ–¹æ³•ï¼Œå…è®¸åœ¨è®­ç»ƒåçµæ´»è°ƒæ•´ç ä¹¦å¤§å°ï¼Œè¿›ä¸€æ­¥æå‡äº†æ¨¡å‹çš„çµæ´»æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåˆ†ç»„æ•°é‡æ˜¯å…³é”®å‚æ•°ï¼Œéœ€è¦æ ¹æ®æ•°æ®é›†å’Œä»»åŠ¡è¿›è¡Œè°ƒæ•´ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬é‡å»ºæŸå¤±å’Œç ä¹¦æ›´æ–°æŸå¤±ã€‚é‡å»ºæŸå¤±è¡¡é‡è§£ç å™¨çš„è¾“å‡ºä¸åŸå§‹è¾“å…¥çš„å·®å¼‚ã€‚ç ä¹¦æ›´æ–°æŸå¤±é¼“åŠ±ç å­—å‘å…¶æœ€è¿‘çš„ç¼–ç å™¨è¾“å‡ºç§»åŠ¨ï¼Œå¹¶é˜²æ­¢ç ä¹¦åå¡Œã€‚å…è®­ç»ƒç ä¹¦é‡é‡‡æ ·æ–¹æ³•åŸºäºç å­—çš„ä½¿ç”¨é¢‘ç‡è¿›è¡Œé‡‡æ ·ï¼Œä¿ç•™ä½¿ç”¨é¢‘ç‡é«˜çš„ç å­—ï¼Œå¹¶éšæœºåˆå§‹åŒ–æ–°çš„ç å­—ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒGroup-VQåœ¨å›¾åƒé‡å»ºä»»åŠ¡ä¸Šä¼˜äºç°æœ‰çš„VQ-VAEå˜ä½“ã€‚åœ¨ä¸åŒæ•°æ®é›†å’Œè®¾ç½®ä¸‹ï¼ŒGroup-VQå‡å–å¾—äº†æ›´é«˜çš„é‡å»ºè´¨é‡ï¼Œå¹¶æœ‰æ•ˆç¼“è§£äº†ç ä¹¦åå¡Œé—®é¢˜ã€‚æ­¤å¤–ï¼Œå…è®­ç»ƒç ä¹¦é‡é‡‡æ ·æ–¹æ³•èƒ½å¤Ÿçµæ´»è°ƒæ•´ç ä¹¦å¤§å°ï¼Œå¹¶åœ¨ä¿æŒé‡å»ºè´¨é‡çš„åŒæ—¶ï¼Œé™ä½è®¡ç®—å¤æ‚åº¦ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Group-VQå¯åº”ç”¨äºå›¾åƒã€éŸ³é¢‘ã€è§†é¢‘ç­‰å¤šç§æ¨¡æ€æ•°æ®çš„å‹ç¼©ã€é‡å»ºå’Œç”Ÿæˆä»»åŠ¡ã€‚ä¾‹å¦‚ï¼Œåœ¨å›¾åƒå‹ç¼©é¢†åŸŸï¼ŒGroup-VQå¯ä»¥å­¦ä¹ åˆ°æ›´æœ‰æ•ˆçš„å›¾åƒè¡¨ç¤ºï¼Œä»è€Œå®ç°æ›´é«˜çš„å‹ç¼©ç‡å’Œæ›´å¥½çš„é‡å»ºè´¨é‡ã€‚åœ¨ç”Ÿæˆæ¨¡å‹é¢†åŸŸï¼ŒGroup-VQå¯ä»¥ä½œä¸ºä¸€ç§æœ‰æ•ˆçš„å…ˆéªŒçŸ¥è¯†ï¼Œå¼•å¯¼ç”Ÿæˆè¿‡ç¨‹ï¼Œç”Ÿæˆæ›´é€¼çœŸçš„å›¾åƒæˆ–éŸ³é¢‘ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vector Quantized Variational Autoencoders (VQ-VAEs) leverage self-supervised learning through reconstruction tasks to represent continuous vectors using the closest vectors in a codebook. However, issues such as codebook collapse persist in the VQ model. To address these issues, existing approaches employ implicit static codebooks or jointly optimize the entire codebook, but these methods constrain the codebook's learning capability, leading to reduced reconstruction quality. In this paper, we propose Group-VQ, which performs group-wise optimization on the codebook. Each group is optimized independently, with joint optimization performed within groups. This approach improves the trade-off between codebook utilization and reconstruction performance. Additionally, we introduce a training-free codebook resampling method, allowing post-training adjustment of the codebook size. In image reconstruction experiments under various settings, Group-VQ demonstrates improved performance on reconstruction metrics. And the post-training codebook sampling method achieves the desired flexibility in adjusting the codebook size.

