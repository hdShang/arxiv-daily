---
layout: default
title: Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN
---

# Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.13137" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.13137v2</a>
  <a href="https://arxiv.org/pdf/2510.13137.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.13137v2" onclick="toggleFavorite(this, '2510.13137v2', 'Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Madhumati Pol, Anvay Anturkar, Anushka Khot, Ayush Andure, Aniruddha Ghosh, Anvit Magadum, Anvay Bahadur

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-15 (æ›´æ–°: 2025-11-18)

**æœŸåˆŠ**: International Journal of Computer Applications, Vol. 187, No. 55, pp. 31-35 (2025)

**DOI**: [10.5120/ijca2025925946](https://doi.org/10.5120/ijca2025925946)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**å¯¹æ¯”LSTMä¸3D CNNï¼Œå®ç°å®æ—¶æ‰‹è¯­åˆ°æ–‡æœ¬çš„æ·±åº¦å­¦ä¹ ç¿»è¯‘**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `æ‰‹è¯­è¯†åˆ«` `3D CNN` `LSTM` `æ·±åº¦å­¦ä¹ ` `å®æ—¶ç¿»è¯‘`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ‰‹è¯­è¯†åˆ«æ–¹æ³•åœ¨ç²¾åº¦å’Œå®æ—¶æ€§ä¹‹é—´å­˜åœ¨æƒè¡¡ï¼Œéš¾ä»¥å…¼é¡¾è¾¹ç¼˜è®¡ç®—ç¯å¢ƒä¸‹çš„èµ„æºé™åˆ¶ã€‚
2. è®ºæ–‡å¯¹æ¯”3D CNNå’ŒLSTMåœ¨æ‰‹è¯­è¯†åˆ«ä¸­çš„æ€§èƒ½ï¼Œå¹¶æ¢ç´¢æ··åˆæ¨¡å‹ä»¥ä¼˜åŒ–ç²¾åº¦å’Œæ•ˆç‡ã€‚
3. å®éªŒè¡¨æ˜3D CNNç²¾åº¦æ›´é«˜ï¼Œä½†LSTMèµ„æºæ¶ˆè€—æ›´ä½ï¼Œæ··åˆæ¨¡å‹æ€§èƒ½è‰¯å¥½ï¼Œä¸ºå®é™…éƒ¨ç½²æä¾›å‚è€ƒã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶æ¢è®¨äº†3Då·ç§¯ç¥ç»ç½‘ç»œï¼ˆ3D CNNï¼‰å’Œé•¿çŸ­æœŸè®°å¿†ï¼ˆLSTMï¼‰ç½‘ç»œåœ¨å®æ—¶ç¾å›½æ‰‹è¯­ï¼ˆASLï¼‰è¯†åˆ«ä¸­çš„æ€§èƒ½ã€‚è™½ç„¶3D CNNæ“…é•¿ä»è§†é¢‘åºåˆ—ä¸­æå–æ—¶ç©ºç‰¹å¾ï¼Œä½†LSTMé’ˆå¯¹å»ºæ¨¡åºåˆ—æ•°æ®ä¸­çš„æ—¶é—´ä¾èµ–æ€§è¿›è¡Œäº†ä¼˜åŒ–ã€‚æˆ‘ä»¬åœ¨åŒ…å«50ä¸ªç±»åˆ«å…±1200ä¸ªASLç¬¦å·çš„æ•°æ®é›†ä¸Šè¯„ä¼°äº†è¿™ä¸¤ç§æ¶æ„ï¼Œæ¯”è¾ƒäº†å®ƒä»¬åœ¨ç›¸ä¼¼è®­ç»ƒæ¡ä»¶ä¸‹çš„å‡†ç¡®æ€§ã€è®¡ç®—æ•ˆç‡å’Œå»¶è¿Ÿã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œ3D CNNå®ç°äº†92.4%çš„è¯†åˆ«å‡†ç¡®ç‡ï¼Œä½†æ¯ä¸ªå¸§çš„å¤„ç†æ—¶é—´æ¯”LSTMå¤š3.2%ï¼Œè€ŒLSTMåœ¨èµ„æºæ¶ˆè€—æ˜¾è‘—é™ä½çš„æƒ…å†µä¸‹ä¿æŒäº†86.7%çš„å‡†ç¡®ç‡ã€‚æ··åˆ3D CNN-LSTMæ¨¡å‹æ˜¾ç¤ºå‡ºä¸é”™çš„æ€§èƒ½ï¼Œè¿™è¡¨æ˜ä¸Šä¸‹æ–‡ç›¸å…³çš„æ¶æ„é€‰æ‹©å¯¹äºå®é™…åº”ç”¨è‡³å…³é‡è¦ã€‚è¯¥é¡¹ç›®ä¸ºå¼€å‘è¾…åŠ©æŠ€æœ¯æä¾›äº†ä¸“ä¸šçš„åŸºå‡†ï¼Œçªå‡ºäº†è¾¹ç¼˜è®¡ç®—ç¯å¢ƒä¸­è¯†åˆ«ç²¾åº¦å’Œå®æ—¶æ“ä½œè¦æ±‚ä¹‹é—´çš„æƒè¡¡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å®æ—¶æ‰‹è¯­åˆ°æ–‡æœ¬çš„ç¿»è¯‘é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹ç¾å›½æ‰‹è¯­ï¼ˆASLï¼‰ã€‚ç°æœ‰æ–¹æ³•åœ¨ç²¾åº¦å’Œè®¡ç®—æ•ˆç‡ä¹‹é—´å­˜åœ¨æƒè¡¡ã€‚3D CNNæ“…é•¿æå–è§†é¢‘çš„æ—¶ç©ºç‰¹å¾ï¼Œä½†è®¡ç®—æˆæœ¬è¾ƒé«˜ï¼›LSTMæ“…é•¿å¤„ç†åºåˆ—æ•°æ®ï¼Œä½†å¯èƒ½åœ¨ç©ºé—´ç‰¹å¾æå–æ–¹é¢æœ‰æ‰€ä¸è¶³ã€‚å› æ­¤ï¼Œéœ€è¦æ‰¾åˆ°ä¸€ç§åœ¨ç²¾åº¦å’Œå®æ—¶æ€§ä¹‹é—´å–å¾—å¹³è¡¡çš„è§£å†³æ–¹æ¡ˆï¼Œå°¤å…¶æ˜¯åœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¡ç®—ç¯å¢ƒä¸­ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å¯¹æ¯”å’Œè¯„ä¼°3D CNNå’ŒLSTMä¸¤ç§æ·±åº¦å­¦ä¹ æ¶æ„åœ¨æ‰‹è¯­è¯†åˆ«ä»»åŠ¡ä¸­çš„æ€§èƒ½ï¼Œå¹¶æ¢ç´¢æ··åˆæ¨¡å‹ä»¥ç»“åˆä¸¤è€…çš„ä¼˜åŠ¿ã€‚é€šè¿‡å®éªŒåˆ†æå®ƒä»¬çš„å‡†ç¡®æ€§ã€è®¡ç®—æ•ˆç‡å’Œå»¶è¿Ÿï¼Œä»è€Œä¸ºå®é™…åº”ç”¨æä¾›æ¶æ„é€‰æ‹©çš„ä¾æ®ã€‚åŒæ—¶ï¼Œç ”ç©¶å¼ºè°ƒäº†ä¸Šä¸‹æ–‡ç›¸å…³çš„æ¶æ„é€‰æ‹©çš„é‡è¦æ€§ï¼Œå³æ ¹æ®å…·ä½“çš„åº”ç”¨åœºæ™¯å’Œèµ„æºé™åˆ¶æ¥é€‰æ‹©åˆé€‚çš„æ¨¡å‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œæ€§èƒ½è¯„ä¼°ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚é¦–å…ˆï¼Œå¯¹åŒ…å«1200ä¸ªASLç¬¦å·çš„æ•°æ®é›†è¿›è¡Œé¢„å¤„ç†ï¼Œç„¶ååˆ†åˆ«è®­ç»ƒ3D CNNã€LSTMå’Œæ··åˆ3D CNN-LSTMæ¨¡å‹ã€‚3D CNNç›´æ¥ä»è§†é¢‘å¸§ä¸­æå–æ—¶ç©ºç‰¹å¾ï¼ŒLSTMå°†è§†é¢‘å¸§åºåˆ—ä½œä¸ºè¾“å…¥ï¼Œå­¦ä¹ æ—¶é—´ä¾èµ–å…³ç³»ã€‚æ··åˆæ¨¡å‹çš„å…·ä½“ç»“æ„æœªçŸ¥ï¼Œä½†æ¨æµ‹å¯èƒ½æ˜¯å°†3D CNNæå–çš„ç‰¹å¾ä½œä¸ºLSTMçš„è¾“å…¥ã€‚æœ€åï¼Œè¯„ä¼°ä¸‰ç§æ¨¡å‹åœ¨å‡†ç¡®æ€§ã€è®¡ç®—æ•ˆç‡å’Œå»¶è¿Ÿæ–¹é¢çš„æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå¯¹æ‰‹è¯­è¯†åˆ«ä»»åŠ¡ä¸­3D CNNå’ŒLSTMçš„æ€§èƒ½è¿›è¡Œäº†ç³»ç»Ÿçš„å¯¹æ¯”åˆ†æï¼Œå¹¶æå‡ºäº†æ··åˆæ¨¡å‹çš„æ¦‚å¿µã€‚è™½ç„¶3D CNNå’ŒLSTMæœ¬èº«å¹¶éæ–°é¢–çš„æŠ€æœ¯ï¼Œä½†å°†å…¶åº”ç”¨äºæ‰‹è¯­è¯†åˆ«å¹¶è¿›è¡Œæ·±å…¥çš„æ€§èƒ½æ¯”è¾ƒï¼Œä¸ºå®é™…åº”ç”¨æä¾›äº†æœ‰ä»·å€¼çš„å‚è€ƒã€‚æ­¤å¤–ï¼Œå¼ºè°ƒä¸Šä¸‹æ–‡ç›¸å…³çš„æ¶æ„é€‰æ‹©ä¹Ÿæ˜¯ä¸€ä¸ªé‡è¦çš„è´¡çŒ®ï¼Œå³æ ¹æ®å…·ä½“çš„åº”ç”¨åœºæ™¯å’Œèµ„æºé™åˆ¶æ¥é€‰æ‹©åˆé€‚çš„æ¨¡å‹ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­å…³äºæ¨¡å‹å’Œè®­ç»ƒçš„ç»†èŠ‚ä¿¡æ¯æœ‰é™ã€‚å·²çŸ¥çš„ä¿¡æ¯åŒ…æ‹¬ï¼šæ•°æ®é›†åŒ…å«1200ä¸ªASLç¬¦å·ï¼Œåˆ†ä¸º50ä¸ªç±»åˆ«ï¼›è¯„ä¼°æŒ‡æ ‡åŒ…æ‹¬å‡†ç¡®æ€§ã€è®¡ç®—æ•ˆç‡å’Œå»¶è¿Ÿï¼›æ¯”è¾ƒäº†3D CNNã€LSTMå’Œæ··åˆ3D CNN-LSTMæ¨¡å‹ã€‚å…³äºå…·ä½“çš„ç½‘ç»œç»“æ„ã€æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨ç­‰æŠ€æœ¯ç»†èŠ‚ï¼Œè®ºæ–‡æ‘˜è¦ä¸­æ²¡æœ‰æä¾›æ˜ç¡®çš„ä¿¡æ¯ï¼Œå±äºæœªçŸ¥å†…å®¹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œ3D CNNè¾¾åˆ°äº†92.4%çš„è¯†åˆ«å‡†ç¡®ç‡ï¼Œä½†æ¯ä¸ªå¸§çš„å¤„ç†æ—¶é—´æ¯”LSTMå¤š3.2%ã€‚LSTMåœ¨èµ„æºæ¶ˆè€—æ˜¾è‘—é™ä½çš„æƒ…å†µä¸‹ä¿æŒäº†86.7%çš„å‡†ç¡®ç‡ã€‚æ··åˆ3D CNN-LSTMæ¨¡å‹æ˜¾ç¤ºå‡ºä¸é”™çš„æ€§èƒ½ï¼Œä½†å…·ä½“æ•°æ®æœªçŸ¥ã€‚è¿™äº›ç»“æœçªå‡ºäº†ç²¾åº¦å’Œå®æ—¶æ€§ä¹‹é—´çš„æƒè¡¡ï¼Œä¸ºå®é™…åº”ç”¨æä¾›äº†é‡è¦çš„å‚è€ƒã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¼€å‘è¾…åŠ©æŠ€æœ¯ï¼Œä¾‹å¦‚å®æ—¶æ‰‹è¯­ç¿»è¯‘è½¯ä»¶æˆ–è®¾å¤‡ï¼Œå¸®åŠ©å¬åŠ›éšœç¢äººå£«ä¸ä»–äººäº¤æµã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶å¯¹æ‰‹è¯­è¯†åˆ«åœ¨è¾¹ç¼˜è®¡ç®—ç¯å¢ƒä¸‹çš„éƒ¨ç½²å…·æœ‰æŒ‡å¯¼æ„ä¹‰ï¼Œå¯åº”ç”¨äºæ™ºèƒ½å®¶å±…ã€æ™ºèƒ½ç©¿æˆ´è®¾å¤‡ç­‰é¢†åŸŸï¼Œæå‡äººæœºäº¤äº’çš„ä¾¿æ·æ€§å’Œæ™ºèƒ½åŒ–æ°´å¹³ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This study investigates the performance of 3D Convolutional Neural Networks (3D CNNs) and Long Short-Term Memory (LSTM) networks for real-time American Sign Language (ASL) recognition. Though 3D CNNs are good at spatiotemporal feature extraction from video sequences, LSTMs are optimized for modeling temporal dependencies in sequential data. We evaluate both architectures on a dataset containing 1,200 ASL signs across 50 classes, comparing their accuracy, computational efficiency, and latency under similar training conditions. Experimental results demonstrate that 3D CNNs achieve 92.4% recognition accuracy but require 3.2% more processing time per frame compared to LSTMs, which maintain 86.7% accuracy with significantly lower resource consumption. The hybrid 3D CNNLSTM model shows decent performance, which suggests that context-dependent architecture selection is crucial for practical implementation.This project provides professional benchmarks for developing assistive technologies, highlighting trade-offs between recognition precision and real-time operational requirements in edge computing environments.

