---
layout: default
title: End-to-End Multi-Modal Diffusion Mamba
---

# End-to-End Multi-Modal Diffusion Mamba

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.13253" target="_blank" class="toolbar-btn">arXiv: 2510.13253v1</a>
    <a href="https://arxiv.org/pdf/2510.13253.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.13253v1" 
            onclick="toggleFavorite(this, '2510.13253v1', 'End-to-End Multi-Modal Diffusion Mamba')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Chunhao Lu, Qiang Lu, Meichen Dong, Jake Luo

**ÂàÜÁ±ª**: cs.CV, cs.AI, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-15

**Â§áÊ≥®**: Accepted by ICCV 2025

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Â§öÊ®°ÊÄÅÊâ©Êï£MambaÔºàMDMÔºâÔºåÁî®‰∫éÁªü‰∏ÄÂ§öÊ®°ÊÄÅÂ§ÑÁêÜÂπ∂ÊèêÂçáÁîüÊàêÊÄßËÉΩ„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±ÂõõÔºöÁîüÊàêÂºèÂä®‰Ωú (Generative Motion)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `Êâ©Êï£Ê®°Âûã` `Mamba` `Á´ØÂà∞Á´ØÊ®°Âûã` `ÂèòÂàÜËá™ÁºñÁ†ÅÂô®` `ÂõæÂÉèÁîüÊàê` `ËßÜËßâÈóÆÁ≠î`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁ´ØÂà∞Á´ØÂ§öÊ®°ÊÄÅÊ®°Âûã‰æùËµñÂàÜÁ¶ªÁöÑÁºñÁ†ÅÂô®ÂíåËß£Á†ÅÂô®ÔºåÈòªÁ¢ç‰∫ÜË∑®Ê®°ÊÄÅÁöÑËÅîÂêàË°®Á§∫Â≠¶‰π†„ÄÇ
2. MDMÂà©Áî®Âü∫‰∫éMambaÁöÑÂ§öÊ≠•ÈÄâÊã©Êâ©Êï£Ê®°ÂûãÔºåÈÄöËøáÁªü‰∏ÄÁöÑÂèòÂàÜËá™ÁºñÁ†ÅÂô®ÂÆûÁé∞Â§öÊ®°ÊÄÅ‰ø°ÊÅØÁöÑÁîüÊàêÂíå‰ºòÂåñ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåMDMÂú®ÂõæÂÉèÁîüÊàê„ÄÅËßÜËßâÈóÆÁ≠îÁ≠â‰ªªÂä°‰∏≠Ë∂ÖË∂äÁé∞ÊúâÁ´ØÂà∞Á´ØÊ®°ÂûãÔºåÂπ∂‰∏éSOTAÊ®°ÂûãÁ´û‰∫â„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫Â§öÊ®°ÊÄÅÊâ©Êï£MambaÔºàMDMÔºâÁöÑÊñ∞ÂûãÊû∂ÊûÑÔºåÊó®Âú®Áªü‰∏ÄÂ§öÊ®°ÊÄÅÂ§ÑÁêÜ„ÄÇMDMÈááÁî®Âü∫‰∫éMambaÁöÑÂ§öÊ≠•ÈÄâÊã©Êâ©Êï£Ê®°ÂûãÔºåÈÄöËøáÁªü‰∏ÄÁöÑÂèòÂàÜËá™ÁºñÁ†ÅÂô®ËøõË°åÁºñÁ†ÅÂíåËß£Á†ÅÔºå‰ªéËÄåÈÄêÊ≠•ÁîüÊàêÂíå‰ºòÂåñÁâπÂÆöÊ®°ÊÄÅÁöÑ‰ø°ÊÅØ„ÄÇËøôÁßçÂàõÊñ∞ÊñπÊ≥ï‰ΩøMDMÂú®Â§ÑÁêÜÈ´òÁª¥Êï∞ÊçÆÊó∂Ë°®Áé∞Âá∫Ëâ≤ÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂêåÊó∂ÁîüÊàêÈ´òÂàÜËæ®ÁéáÂõæÂÉèÂíåÊâ©Â±ïÊñáÊú¨Â∫èÂàóÊñπÈù¢„ÄÇÂú®ÂõæÂÉèÁîüÊàê„ÄÅÂõæÂÉèÊèèËø∞„ÄÅËßÜËßâÈóÆÁ≠î„ÄÅÊñáÊú¨ÁêÜËß£ÂíåÊé®ÁêÜ‰ªªÂä°Á≠âÈ¢ÜÂüüÁöÑËØÑ‰º∞Ë°®ÊòéÔºåMDMÊòæËëó‰ºò‰∫éÁé∞ÊúâÁöÑÁ´ØÂà∞Á´ØÊ®°ÂûãÔºàÂ¶ÇMonoFormer„ÄÅLlamaGenÂíåChameleonÁ≠âÔºâÔºåÂπ∂ËÉΩ‰∏éGPT-4V„ÄÅGemini ProÂíåMistralÁ≠âSOTAÊ®°ÂûãÊúâÊïàÁ´û‰∫â„ÄÇÂÆûÈ™åÁªìÊûúÈ™åËØÅ‰∫ÜMDMÂú®Áªü‰∏ÄÂ§öÊ®°ÊÄÅÂ§ÑÁêÜÊñπÈù¢ÁöÑÊúâÊïàÊÄßÔºåÂêåÊó∂‰øùÊåÅ‰∫ÜËÆ°ÁÆóÊïàÁéáÔºå‰∏∫Á´ØÂà∞Á´ØÂ§öÊ®°ÊÄÅÊû∂ÊûÑÂºÄËæü‰∫ÜÊñ∞ÁöÑÊñπÂêë„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÁ´ØÂà∞Á´ØÂ§öÊ®°ÊÄÅÊ®°ÂûãÈÄöÂ∏∏ÈááÁî®ÂàÜÁ¶ªÁöÑÁºñÁ†ÅÂô®ÂíåËß£Á†ÅÂô®Êù•Â§ÑÁêÜ‰∏çÂêåÊ®°ÊÄÅÁöÑËæìÂÖ•ÂíåËæìÂá∫‰ø°ÊÅØ„ÄÇËøôÁßçÂàÜÁ¶ªÁöÑËÆæËÆ°ÈòªÁ¢ç‰∫Ü‰∏çÂêåÊ®°ÊÄÅ‰πãÈó¥ÁöÑËÅîÂêàË°®Á§∫Â≠¶‰π†ÔºåÈôêÂà∂‰∫ÜÊ®°ÂûãÂú®Â§çÊùÇÂ§öÊ®°ÊÄÅ‰ªªÂä°‰∏≠ÁöÑÊÄßËÉΩ„ÄÇÂ∞§ÂÖ∂ÊòØÂú®Â§ÑÁêÜÈ´òÁª¥Êï∞ÊçÆÔºåÂ¶ÇÈ´òÂàÜËæ®ÁéáÂõæÂÉèÂíåÈïøÊñáÊú¨Â∫èÂàóÊó∂ÔºåËøôÁßçÈóÆÈ¢òÊõ¥Âä†Á™ÅÂá∫„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöMDMÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®‰∏Ä‰∏™Áªü‰∏ÄÁöÑÊû∂ÊûÑÊù•Â§ÑÁêÜÊâÄÊúâÊ®°ÊÄÅÁöÑ‰ø°ÊÅØÔºå‰ªéËÄå‰øÉËøõË∑®Ê®°ÊÄÅÁöÑÁü•ËØÜÂÖ±‰∫´ÂíåËûçÂêà„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåMDMÈááÁî®Âü∫‰∫éMambaÁöÑÂ§öÊ≠•ÈÄâÊã©Êâ©Êï£Ê®°ÂûãÔºåÂπ∂‰ΩøÁî®Áªü‰∏ÄÁöÑÂèòÂàÜËá™ÁºñÁ†ÅÂô®ËøõË°åÁºñÁ†ÅÂíåËß£Á†Å„ÄÇÈÄöËøáÊâ©Êï£ËøáÁ®ãÔºåÊ®°ÂûãËÉΩÂ§üÈÄêÊ≠•ÁîüÊàêÂíå‰ºòÂåñÁâπÂÆöÊ®°ÊÄÅÁöÑ‰ø°ÊÅØÔºå‰ªéËÄåÂÆûÁé∞È´òË¥®ÈáèÁöÑÂ§öÊ®°ÊÄÅÁîüÊàêÂíåÁêÜËß£„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöMDMÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÂê´‰∏Ä‰∏™Áªü‰∏ÄÁöÑÂèòÂàÜËá™ÁºñÁ†ÅÂô®ÔºàVAEÔºâÂíå‰∏Ä‰∏™Âü∫‰∫éMambaÁöÑÂ§öÊ≠•ÈÄâÊã©Êâ©Êï£Ê®°Âûã„ÄÇVAEË¥üË¥£Â∞Ü‰∏çÂêåÊ®°ÊÄÅÁöÑËæìÂÖ•ÁºñÁ†ÅÂà∞Áªü‰∏ÄÁöÑÊΩúÂú®Á©∫Èó¥‰∏≠ÔºåËÄåÊâ©Êï£Ê®°ÂûãÂàôË¥üË¥£‰ªéÊΩúÂú®Á©∫Èó¥‰∏≠ÈÄêÊ≠•ÁîüÊàêÁõÆÊ†áÊ®°ÊÄÅÁöÑ‰ø°ÊÅØ„ÄÇÊï¥‰∏™ÊµÅÁ®ãÂåÖÊã¨ÁºñÁ†ÅÈò∂ÊÆµÂíåËß£Á†ÅÔºàÊâ©Êï£ÔºâÈò∂ÊÆµ„ÄÇÂú®ÁºñÁ†ÅÈò∂ÊÆµÔºå‰∏çÂêåÊ®°ÊÄÅÁöÑËæìÂÖ•ÈÄöËøáVAEÁºñÁ†ÅÂà∞ÊΩúÂú®Á©∫Èó¥„ÄÇÂú®Ëß£Á†ÅÈò∂ÊÆµÔºåÊâ©Êï£Ê®°Âûã‰ªéÊΩúÂú®Á©∫Èó¥Âá∫ÂèëÔºåÈÄêÊ≠•ÁîüÊàêÁõÆÊ†áÊ®°ÊÄÅÁöÑ‰ø°ÊÅØÔºåÂπ∂ÈÄöËøáMambaÁªìÊûÑËøõË°åÂ∫èÂàóÂª∫Ê®°ÂíåÈÄâÊã©„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöMDMÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫é‰ΩøÁî®Âü∫‰∫éMambaÁöÑÊâ©Êï£Ê®°ÂûãÊù•Áªü‰∏ÄÂ§öÊ®°ÊÄÅÂ§ÑÁêÜ„ÄÇMambaÁªìÊûÑÂÖ∑ÊúâÁ∫øÊÄßÂ§çÊùÇÂ∫¶ÔºåËÉΩÂ§üÈ´òÊïàÂú∞Â§ÑÁêÜÈïøÂ∫èÂàóÊï∞ÊçÆÔºåËøô‰ΩøÂæóMDMÂú®Â§ÑÁêÜÈ´òÁª¥Â§öÊ®°ÊÄÅÊï∞ÊçÆÊó∂ÂÖ∑ÊúâÊòæËëóÁöÑ‰ºòÂäø„ÄÇ‰∏é‰º†ÁªüÁöÑTransformerÁªìÊûÑÁõ∏ÊØîÔºåMambaÁªìÊûÑÂú®ËÆ°ÁÆóÊïàÁéáÂíåÂª∫Ê®°ËÉΩÂäõ‰πãÈó¥ÂèñÂæó‰∫ÜÊõ¥Â•ΩÁöÑÂπ≥Ë°°„ÄÇÊ≠§Â§ñÔºåMDMÈááÁî®Áªü‰∏ÄÁöÑVAEËøõË°åÁºñÁ†ÅÂíåËß£Á†ÅÔºåËøõ‰∏ÄÊ≠•‰øÉËøõ‰∫ÜË∑®Ê®°ÊÄÅÁöÑÁü•ËØÜÂÖ±‰∫´„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöMDMÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨MambaÂùóÁöÑÂÖ∑‰ΩìÈÖçÁΩÆ„ÄÅÊâ©Êï£Ê®°ÂûãÁöÑÂô™Â£∞Ë∞ÉÂ∫¶Á≠ñÁï•‰ª•ÂèäVAEÁöÑÁªìÊûÑËÆæËÆ°„ÄÇËÆ∫ÊñáÂèØËÉΩËØ¶ÁªÜÊèèËø∞‰∫ÜMambaÂùó‰∏≠ÈÄâÊã©Êú∫Âà∂ÁöÑÂÖ∑‰ΩìÂÆûÁé∞ÊñπÂºèÔºå‰æãÂ¶ÇÈÄâÊã©Èó®ÁöÑÊøÄÊ¥ªÂáΩÊï∞ÂíåÂèÇÊï∞ÂàùÂßãÂåñÊñπÊ≥ï„ÄÇÊâ©Êï£Ê®°ÂûãÁöÑÂô™Â£∞Ë∞ÉÂ∫¶Á≠ñÁï•ÂÜ≥ÂÆö‰∫ÜÁîüÊàêËøáÁ®ãÁöÑË¥®ÈáèÂíåÈÄüÂ∫¶ÔºåÂèØËÉΩÈááÁî®‰∫ÜÁ∫øÊÄßÊàñÈùûÁ∫øÊÄßÁöÑÂô™Â£∞Ê∑ªÂä†ÊñπÂºè„ÄÇVAEÁöÑÁªìÊûÑËÆæËÆ°ÔºåÂåÖÊã¨ÁºñÁ†ÅÂô®ÂíåËß£Á†ÅÂô®ÁöÑÂ±ÇÊï∞„ÄÅÊøÄÊ¥ªÂáΩÊï∞ÂíåÊÆãÂ∑ÆËøûÊé•Á≠âÔºå‰πü‰ºöÂΩ±ÂìçÊ®°ÂûãÁöÑÊÄßËÉΩ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåMDMÂú®ÂõæÂÉèÁîüÊàê„ÄÅÂõæÂÉèÊèèËø∞„ÄÅËßÜËßâÈóÆÁ≠î„ÄÅÊñáÊú¨ÁêÜËß£ÂíåÊé®ÁêÜ‰ªªÂä°Á≠âÂ§ö‰∏™È¢ÜÂüüÂùáÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇ‰æãÂ¶ÇÔºåÂú®ÂõæÂÉèÁîüÊàê‰ªªÂä°‰∏≠ÔºåMDMÁîüÊàêÁöÑÂõæÂÉèË¥®Èáè‰ºò‰∫éÁé∞ÊúâÁöÑÁ´ØÂà∞Á´ØÊ®°Âûã„ÄÇÂú®ËßÜËßâÈóÆÁ≠î‰ªªÂä°‰∏≠ÔºåMDMÁöÑÂáÜÁ°ÆÁéá‰πüÂæóÂà∞‰∫ÜÊòæËëóÊèêÂçáÔºåÁîöËá≥ÂèØ‰ª•‰∏éGPT-4V„ÄÅGemini ProÂíåMistralÁ≠âÂ§ßÂûãÊ®°ÂûãÁ´û‰∫â„ÄÇËøô‰∫õÁªìÊûúÈ™åËØÅ‰∫ÜMDMÂú®Áªü‰∏ÄÂ§öÊ®°ÊÄÅÂ§ÑÁêÜÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

MDMÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂåÖÊã¨‰ΩÜ‰∏çÈôê‰∫éÔºöÂ§öÊ®°ÊÄÅÂÜÖÂÆπÁîüÊàêÔºàÂ¶ÇÊ†πÊçÆÊñáÊú¨ÁîüÊàêÂõæÂÉèÔºâ„ÄÅËßÜËßâÈóÆÁ≠î„ÄÅÂõæÂÉèÊèèËø∞„ÄÅÊô∫ËÉΩÂØπËØùÁ≥ªÁªü„ÄÅ‰ª•ÂèäË∑®Ê®°ÊÄÅ‰ø°ÊÅØÊ£ÄÁ¥¢Á≠â„ÄÇËØ•Á†îÁ©∂ÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂú®‰∫éÊèêÂçáÂ§öÊ®°ÊÄÅÊ®°ÂûãÁöÑÊÄßËÉΩÂíåÊïàÁéáÔºå‰∏∫ÂºÄÂèëÊõ¥Êô∫ËÉΩ„ÄÅÊõ¥Ëá™ÁÑ∂ÁöÑ‰∫∫Êú∫‰∫§‰∫íÁ≥ªÁªüÂ•†ÂÆöÂü∫Á°Ä„ÄÇÊú™Êù•ÔºåMDMÊúâÊúõÂ∫îÁî®‰∫éÂåªÁñóËØäÊñ≠„ÄÅËá™Âä®È©æÈ©∂Á≠âÈ¢ÜÂüüÔºåÂÆûÁé∞Êõ¥Á≤æÂáÜ„ÄÅÊõ¥ÂèØÈù†ÁöÑÂ§öÊ®°ÊÄÅ‰ø°ÊÅØÂ§ÑÁêÜ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Current end-to-end multi-modal models utilize different encoders and decoders to process input and output information. This separation hinders the joint representation learning of various modalities. To unify multi-modal processing, we propose a novel architecture called MDM (Multi-modal Diffusion Mamba). MDM utilizes a Mamba-based multi-step selection diffusion model to progressively generate and refine modality-specific information through a unified variational autoencoder for both encoding and decoding. This innovative approach allows MDM to achieve superior performance when processing high-dimensional data, particularly in generating high-resolution images and extended text sequences simultaneously. Our evaluations in areas such as image generation, image captioning, visual question answering, text comprehension, and reasoning tasks demonstrate that MDM significantly outperforms existing end-to-end models (MonoFormer, LlamaGen, and Chameleon etc.) and competes effectively with SOTA models like GPT-4V, Gemini Pro, and Mistral. Our results validate MDM's effectiveness in unifying multi-modal processes while maintaining computational efficiency, establishing a new direction for end-to-end multi-modal architectures.

