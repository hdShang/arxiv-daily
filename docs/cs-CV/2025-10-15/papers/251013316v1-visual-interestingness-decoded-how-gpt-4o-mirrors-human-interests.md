---
layout: default
title: Visual Interestingness Decoded: How GPT-4o Mirrors Human Interests
---

# Visual Interestingness Decoded: How GPT-4o Mirrors Human Interests

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.13316" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.13316v1</a>
  <a href="https://arxiv.org/pdf/2510.13316.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.13316v1" onclick="toggleFavorite(this, '2510.13316v1', 'Visual Interestingness Decoded: How GPT-4o Mirrors Human Interests')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Fitim Abdullahu, Helmut Grabner

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-15

**å¤‡æ³¨**: ICCV 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ¢ç´¢GPT-4oå¯¹è§†è§‰è¶£å‘³æ€§çš„ç†è§£ï¼Œå¹¶ç”¨äºæå‡å­¦ä¹ æ’åºæ¨¡å‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰è¶£å‘³æ€§` `GPT-4o` `å¤šæ¨¡æ€æ¨¡å‹` `å­¦ä¹ æ’åº` `çŸ¥è¯†è’¸é¦`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•éš¾ä»¥å‡†ç¡®æ•æ‰å’Œé‡åŒ–äººç±»å¯¹è§†è§‰å†…å®¹çš„å…´è¶£åå¥½ï¼Œç¼ºä¹æœ‰æ•ˆæ¨¡å‹ã€‚
2. åˆ©ç”¨GPT-4oç†è§£è§†è§‰è¶£å‘³æ€§ï¼Œé€šè¿‡å¯¹æ¯”åˆ†æè¯„ä¼°å…¶ä¸äººç±»åˆ¤æ–­çš„ä¸€è‡´æ€§ã€‚
3. GPT-4oåœ¨è§†è§‰è¶£å‘³æ€§ç†è§£ä¸Šè¡¨ç°å‡ºæ½œåŠ›ï¼Œå¯ç”¨äºæ ‡æ³¨æ•°æ®å¹¶è’¸é¦åˆ°æ’åºæ¨¡å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰è¶£å‘³æ€§ï¼Œå³å¸å¼•å’Œä¿æŒäººä»¬æ³¨æ„åŠ›çš„èƒ½åŠ›ï¼Œå¯¹æˆ‘ä»¬çš„æ—¥å¸¸ç”Ÿæ´»è‡³å…³é‡è¦ã€‚æœ¬æ–‡æ—¨åœ¨æ¢ç´¢å¤§è§„æ¨¡å¤šæ¨¡æ€æ¨¡å‹(LMMs)åœ¨ç†è§£è§†è§‰è¶£å‘³æ€§æ–¹é¢çš„æ½œåŠ›ã€‚é€šè¿‡å¯¹æ¯”åˆ†æï¼Œç ”ç©¶äº†é¢†å…ˆçš„LMMâ€”â€”GPT-4oçš„é¢„æµ‹ä¸äººç±»è¯„ä¼°ä¹‹é—´çš„ä¸€è‡´æ€§ã€‚ç ”ç©¶è¡¨æ˜ï¼ŒGPT-4oåœ¨ä¸€å®šç¨‹åº¦ä¸Šæ•æ‰åˆ°äº†è§†è§‰è¶£å‘³æ€§çš„æ¦‚å¿µï¼Œå…¶è¡¨ç°ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚å› æ­¤ï¼Œè¯¥æ¨¡å‹å¯ä»¥æœ‰æ•ˆåœ°æ ‡æ³¨å›¾åƒå¯¹çš„è¶£å‘³æ€§ï¼Œè¿™äº›æ ‡æ³¨æ•°æ®è¢«ç”¨äºçŸ¥è¯†è’¸é¦ï¼Œè®­ç»ƒä¸€ä¸ªå­¦ä¹ æ’åºæ¨¡å‹ã€‚è¿™äº›å‘ç°ä¸ºæ›´æ·±å…¥åœ°ç†è§£äººç±»å…´è¶£å¼€è¾Ÿäº†é“è·¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¦‚ä½•è®©æœºå™¨ç†è§£å¹¶é¢„æµ‹äººç±»å¯¹è§†è§‰å†…å®¹çš„â€œè¶£å‘³æ€§â€è¿™ä¸€é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•è¦ä¹ˆä¾èµ–äººå·¥æ ‡æ³¨ï¼Œæˆæœ¬é«˜æ˜‚ä¸”ä¸»è§‚æ€§å¼ºï¼Œè¦ä¹ˆéš¾ä»¥æœ‰æ•ˆæ•æ‰å›¾åƒçš„å¤æ‚ç‰¹å¾å’Œäººç±»çš„å¾®å¦™åå¥½ã€‚å› æ­¤ï¼Œå¦‚ä½•åˆ©ç”¨å¤§è§„æ¨¡æ•°æ®å’Œå…ˆè¿›æ¨¡å‹è‡ªåŠ¨å­¦ä¹ è§†è§‰è¶£å‘³æ€§æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨é¢„è®­ç»ƒçš„å¤§å‹å¤šæ¨¡æ€æ¨¡å‹GPT-4oï¼Œå‡­å€Ÿå…¶åœ¨æµ·é‡è§†è§‰å’Œæ–‡æœ¬æ•°æ®ä¸Šçš„è®­ç»ƒï¼Œæ¥æ¨¡æ‹Ÿäººç±»å¯¹è§†è§‰è¶£å‘³æ€§çš„åˆ¤æ–­ã€‚é€šè¿‡å¯¹æ¯”GPT-4oçš„é¢„æµ‹å’Œäººç±»çš„è¯„ä¼°ï¼ŒéªŒè¯å…¶ç†è§£è§†è§‰è¶£å‘³æ€§çš„èƒ½åŠ›ï¼Œå¹¶åˆ©ç”¨å…¶è¿›è¡Œæ•°æ®æ ‡æ³¨ï¼Œè¿›è€Œè®­ç»ƒä¸€ä¸ªæ›´è½»é‡çº§çš„å­¦ä¹ æ’åºæ¨¡å‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼š1) ä½¿ç”¨GPT-4oå¯¹å›¾åƒå¯¹çš„è¶£å‘³æ€§è¿›è¡Œæ’åºå’Œæ ‡æ³¨ï¼›2) å°†GPT-4oçš„æ’åºç»“æœä¸äººç±»è¯„ä¼°è¿›è¡Œå¯¹æ¯”ï¼Œè¯„ä¼°GPT-4oçš„æ€§èƒ½ï¼›3) ä½¿ç”¨GPT-4oæ ‡æ³¨çš„æ•°æ®è®­ç»ƒä¸€ä¸ªå­¦ä¹ æ’åºæ¨¡å‹ï¼Œå°†GPT-4oçš„çŸ¥è¯†è’¸é¦åˆ°è¯¥æ¨¡å‹ä¸­ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºåˆ©ç”¨GPT-4oè¿™ç§å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹æ¥ç†è§£å’Œé¢„æµ‹è§†è§‰è¶£å‘³æ€§ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼ŒGPT-4oæ— éœ€äººå·¥è®¾è®¡ç‰¹å¾ï¼Œèƒ½å¤Ÿè‡ªåŠ¨å­¦ä¹ å›¾åƒçš„å¤æ‚ç‰¹å¾å’Œäººç±»çš„åå¥½ã€‚æ­¤å¤–ï¼Œé€šè¿‡çŸ¥è¯†è’¸é¦ï¼Œå¯ä»¥å°†GPT-4oçš„çŸ¥è¯†è¿ç§»åˆ°ä¸€ä¸ªæ›´è½»é‡çº§çš„æ¨¡å‹ä¸­ï¼Œä½¿å…¶æ›´æ˜“äºéƒ¨ç½²å’Œåº”ç”¨ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ç²¾å¿ƒè®¾è®¡çš„å›¾åƒå¯¹ï¼Œç”¨äºè¯„ä¼°GPT-4oçš„æ’åºèƒ½åŠ›ï¼›2) ä½¿ç”¨åˆé€‚çš„æŸå¤±å‡½æ•°ï¼ˆä¾‹å¦‚æ’åºæŸå¤±ï¼‰æ¥è®­ç»ƒå­¦ä¹ æ’åºæ¨¡å‹ï¼›3) è¯¦ç»†å¯¹æ¯”GPT-4oå’Œäººç±»è¯„ä¼°ç»“æœï¼Œåˆ†æå…¶ä¼˜åŠ¿å’Œä¸è¶³ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒGPT-4oåœ¨ç†è§£è§†è§‰è¶£å‘³æ€§æ–¹é¢è¡¨ç°å‡ºä¸€å®šçš„èƒ½åŠ›ï¼Œå…¶é¢„æµ‹ç»“æœä¸äººç±»è¯„ä¼°å…·æœ‰ä¸€å®šçš„ç›¸å…³æ€§ã€‚æ­¤å¤–ï¼Œä½¿ç”¨GPT-4oæ ‡æ³¨çš„æ•°æ®è®­ç»ƒçš„å­¦ä¹ æ’åºæ¨¡å‹ï¼Œåœ¨æ€§èƒ½ä¸Šä¼˜äºå…¶ä»–åŸºçº¿æ–¹æ³•ã€‚è¿™äº›ç»“æœéªŒè¯äº†åˆ©ç”¨å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ç†è§£è§†è§‰è¶£å‘³æ€§çš„å¯è¡Œæ€§ï¼Œå¹¶ä¸ºåç»­ç ”ç©¶æä¾›äº†æœ‰ç›Šçš„å‚è€ƒã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå›¾åƒæ¨èç³»ç»Ÿã€å¹¿å‘ŠæŠ•æ”¾ã€å†…å®¹åˆ›ä½œç­‰é¢†åŸŸã€‚é€šè¿‡ç†è§£ç”¨æˆ·çš„è§†è§‰å…´è¶£ï¼Œå¯ä»¥æ›´ç²¾å‡†åœ°æ¨èç”¨æˆ·æ„Ÿå…´è¶£çš„å›¾åƒå†…å®¹ï¼Œæé«˜ç”¨æˆ·æ»¡æ„åº¦å’Œå‚ä¸åº¦ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥ç”¨äºè¾…åŠ©å†…å®¹åˆ›ä½œè€…ï¼Œå¸®åŠ©ä»–ä»¬åˆ›ä½œæ›´å¸å¼•äººçš„è§†è§‰å†…å®¹ã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶å¯ä»¥æ‰©å±•åˆ°è§†é¢‘é¢†åŸŸï¼Œå®ç°æ›´å¹¿æ³›çš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Our daily life is highly influenced by what we consume and see. Attracting and holding one's attention -- the definition of (visual) interestingness -- is essential. The rise of Large Multimodal Models (LMMs) trained on large-scale visual and textual data has demonstrated impressive capabilities. We explore these models' potential to understand to what extent the concepts of visual interestingness are captured and examine the alignment between human assessments and GPT-4o's, a leading LMM, predictions through comparative analysis. Our studies reveal partial alignment between humans and GPT-4o. It already captures the concept as best compared to state-of-the-art methods. Hence, this allows for the effective labeling of image pairs according to their (commonly) interestingness, which are used as training data to distill the knowledge into a learning-to-rank model. The insights pave the way for a deeper understanding of human interest.

