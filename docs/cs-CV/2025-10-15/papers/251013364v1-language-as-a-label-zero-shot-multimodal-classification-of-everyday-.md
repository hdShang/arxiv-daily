---
layout: default
title: Language as a Label: Zero-Shot Multimodal Classification of Everyday Postures under Data Scarcity
---

# Language as a Label: Zero-Shot Multimodal Classification of Everyday Postures under Data Scarcity

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.13364" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.13364v1</a>
  <a href="https://arxiv.org/pdf/2510.13364.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.13364v1" onclick="toggleFavorite(this, '2510.13364v1', 'Language as a Label: Zero-Shot Multimodal Classification of Everyday Postures under Data Scarcity')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: MingZe Tang, Jubal Chandy Jacob

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-10-15

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ©ç”¨è¯­è¨€æ ‡ç­¾è¿›è¡Œé›¶æ ·æœ¬å¤šæ¨¡æ€åˆ†ç±»ï¼Œè§£å†³æ•°æ®ç¨€ç¼ºä¸‹çš„æ—¥å¸¸å§¿æ€è¯†åˆ«é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é›¶æ ·æœ¬å­¦ä¹ ` `å¤šæ¨¡æ€åˆ†ç±»` `è§†è§‰-è¯­è¨€æ¨¡å‹` `æç¤ºè¯å·¥ç¨‹` `äººä½“å§¿æ€è¯†åˆ«`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æ•°æ®ç¨€ç¼ºåœºæ™¯ä¸‹ï¼Œéš¾ä»¥æœ‰æ•ˆåˆ©ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹è¿›è¡Œç»†ç²’åº¦å§¿æ€è¯†åˆ«ï¼Œæç¤ºè¯è®¾è®¡çš„å½±å“å°šä¸æ˜ç¡®ã€‚
2. è®ºæ–‡æ¢ç´¢äº†ä¸åŒè¯¦ç»†ç¨‹åº¦çš„æç¤ºè¯å¯¹é›¶æ ·æœ¬å§¿æ€åˆ†ç±»çš„å½±å“ï¼Œæ—¨åœ¨æ‰¾åˆ°æœ€ä½³çš„æç¤ºè¯è®¾è®¡ç­–ç•¥ã€‚
3. å®éªŒè¡¨æ˜ï¼Œå¯¹äºé«˜æ€§èƒ½æ¨¡å‹ï¼Œç®€å•æç¤ºè¯ä¼˜äºå¤æ‚æç¤ºè¯ï¼Œå¹¶æå‡ºäº†â€œæç¤ºè¯è¿‡æ‹Ÿåˆâ€ç°è±¡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ç ”ç©¶äº†åœ¨æ•°æ®ç¨€ç¼ºæ¡ä»¶ä¸‹ï¼Œå¦‚ä½•åˆ©ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰è¿›è¡Œé›¶æ ·æœ¬åˆ†ç±»ï¼Œç‰¹åˆ«å…³æ³¨äº†æç¤ºè¯è®¾è®¡å¯¹è¯†åˆ«è§†è§‰ç›¸ä¼¼ç±»åˆ«ï¼ˆå¦‚äººä½“å§¿æ€ï¼‰çš„å½±å“ã€‚ç ”ç©¶ä½¿ç”¨ä¸€ä¸ªç”±285å¼ COCOå›¾åƒè¡ç”Ÿçš„æ•°æ®é›†ï¼Œè¯„ä¼°äº†OpenCLIPã€MetaCLIP 2å’ŒSigLipç­‰æ¨¡å‹åœ¨åã€ç«™ã€èµ°/è·‘ä¸‰ç§å§¿æ€åˆ†ç±»ä¸Šçš„è¡¨ç°ã€‚é€šè¿‡ç³»ç»Ÿåœ°å¢åŠ è¯­è¨€ç»†èŠ‚çš„ä¸‰å±‚æç¤ºè¯è®¾è®¡ï¼Œå‘ç°äº†ä¸€ä¸ªè¿åç›´è§‰çš„è¶‹åŠ¿ï¼šå¯¹äºMetaCLIP 2å’ŒOpenCLIPç­‰é«˜æ€§èƒ½æ¨¡å‹ï¼Œæœ€ç®€å•ã€æœ€åŸºç¡€çš„æç¤ºè¯æ•ˆæœæœ€ä½³ã€‚æ·»åŠ æè¿°æ€§ç»†èŠ‚ä¼šæ˜¾è‘—é™ä½æ€§èƒ½ï¼Œä¾‹å¦‚MetaCLIP 2çš„å¤šç±»ç²¾åº¦ä»68.8%é™è‡³55.1%ï¼Œè¿™ç§ç°è±¡è¢«ç§°ä¸ºâ€œæç¤ºè¯è¿‡æ‹Ÿåˆâ€ã€‚ç›¸åï¼Œå¯¹äºæ€§èƒ½è¾ƒä½çš„SigLipæ¨¡å‹ï¼Œæ›´å…·æè¿°æ€§çš„ã€åŸºäºèº«ä½“çº¿ç´¢çš„æç¤ºè¯å¯ä»¥æ”¹å–„æ¨¡ç³Šç±»åˆ«çš„åˆ†ç±»ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æ•°æ®ç¨€ç¼ºåœºæ™¯ä¸‹ï¼Œåˆ©ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹è¿›è¡Œäººä½“æ—¥å¸¸å§¿æ€ï¼ˆåã€ç«™ã€èµ°/è·‘ï¼‰é›¶æ ·æœ¬åˆ†ç±»çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨æç¤ºè¯è®¾è®¡ä¸Šç¼ºä¹ç³»ç»Ÿæ€§ç ”ç©¶ï¼Œéš¾ä»¥å……åˆ†å‘æŒ¥è§†è§‰-è¯­è¨€æ¨¡å‹çš„æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨è§†è§‰ç›¸ä¼¼ç±»åˆ«çš„åŒºåˆ†ä¸Šè¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ç³»ç»Ÿæ€§åœ°è®¾è®¡ä¸åŒè¯¦ç»†ç¨‹åº¦çš„æç¤ºè¯ï¼Œæ¢ç©¶æç¤ºè¯çš„ç‰¹å¼‚æ€§å¯¹é›¶æ ·æœ¬åˆ†ç±»æ€§èƒ½çš„å½±å“ã€‚ä½œè€…å‡è®¾ï¼Œæ›´è¯¦ç»†çš„æç¤ºè¯èƒ½å¤Ÿæä¾›æ›´ä¸°å¯Œçš„ä¿¡æ¯ï¼Œä»è€Œæé«˜åˆ†ç±»ç²¾åº¦ã€‚ä½†å®éªŒç»“æœè¡¨æ˜ï¼Œå¯¹äºé«˜æ€§èƒ½æ¨¡å‹ï¼Œç®€å•çš„æç¤ºè¯åè€Œæ›´æœ‰æ•ˆï¼Œè¿™è¡¨æ˜å¯èƒ½å­˜åœ¨â€œæç¤ºè¯è¿‡æ‹Ÿåˆâ€ç°è±¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨äº†ä¸€ä¸ªä¸‰å±‚æç¤ºè¯è®¾è®¡æ¡†æ¶ï¼Œé€æ­¥å¢åŠ æç¤ºè¯çš„è¯­è¨€ç»†èŠ‚ã€‚å…·ä½“æ¥è¯´ï¼Œç¬¬ä¸€å±‚ä½¿ç”¨æœ€ç®€å•çš„æç¤ºè¯ï¼ˆå¦‚â€œsittingâ€ï¼‰ï¼Œç¬¬äºŒå±‚å¢åŠ ä¸€äº›æè¿°æ€§è¯è¯­ï¼ˆå¦‚â€œa person sittingâ€ï¼‰ï¼Œç¬¬ä¸‰å±‚åˆ™åŒ…å«æ›´è¯¦ç»†çš„èº«ä½“çº¿ç´¢ï¼ˆå¦‚â€œa person sitting with their legs bentâ€ï¼‰ã€‚ç„¶åï¼Œä½¿ç”¨è¿™äº›æç¤ºè¯å¯¹OpenCLIPã€MetaCLIP 2å’ŒSigLipç­‰è§†è§‰-è¯­è¨€æ¨¡å‹è¿›è¡Œé›¶æ ·æœ¬åˆ†ç±»ï¼Œå¹¶æ¯”è¾ƒä¸åŒæç¤ºè¯ä¸‹çš„åˆ†ç±»ç²¾åº¦ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå‘ç°äº†â€œæç¤ºè¯è¿‡æ‹Ÿåˆâ€ç°è±¡ï¼Œå³å¯¹äºé«˜æ€§èƒ½è§†è§‰-è¯­è¨€æ¨¡å‹ï¼Œæ›´è¯¦ç»†çš„æç¤ºè¯åè€Œä¼šé™ä½åˆ†ç±»ç²¾åº¦ã€‚è¿™ä¸ç›´è§‰ç›¸åï¼Œè¡¨æ˜åœ¨é›¶æ ·æœ¬åˆ†ç±»ä¸­ï¼Œæç¤ºè¯çš„è®¾è®¡éœ€è¦ä»”ç»†æƒè¡¡ï¼Œé¿å…è¿‡åº¦æ‹Ÿåˆè®­ç»ƒæ•°æ®ä¸­çš„åå·®ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä¸‰å±‚æç¤ºè¯è®¾è®¡ï¼Œç³»ç»Ÿæ€§åœ°æ§åˆ¶æç¤ºè¯çš„è¯¦ç»†ç¨‹åº¦ï¼›2) ä½¿ç”¨COCOæ•°æ®é›†è¡ç”Ÿçš„ä¸€ä¸ªå°è§„æ¨¡æ•°æ®é›†ï¼Œæ¨¡æ‹Ÿæ•°æ®ç¨€ç¼ºåœºæ™¯ï¼›3) è¯„ä¼°å¤šä¸ªå…ˆè¿›çš„è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ŒåŒ…æ‹¬OpenCLIPã€MetaCLIP 2å’ŒSigLipï¼›4) é‡‡ç”¨å¤šç±»ç²¾åº¦ä½œä¸ºè¯„ä¼°æŒ‡æ ‡ï¼Œè¡¡é‡åˆ†ç±»æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå¯¹äºMetaCLIP 2å’ŒOpenCLIPç­‰é«˜æ€§èƒ½æ¨¡å‹ï¼Œæœ€ç®€å•çš„æç¤ºè¯å–å¾—äº†æœ€ä½³çš„åˆ†ç±»ç²¾åº¦ã€‚ä¾‹å¦‚ï¼ŒMetaCLIP 2åœ¨ä½¿ç”¨æœ€ç®€å•æç¤ºè¯æ—¶çš„å¤šç±»ç²¾åº¦ä¸º68.8%ï¼Œè€Œä½¿ç”¨æœ€è¯¦ç»†æç¤ºè¯æ—¶åˆ™é™è‡³55.1%ã€‚ç›¸åï¼Œå¯¹äºSigLipæ¨¡å‹ï¼Œæ›´è¯¦ç»†çš„æç¤ºè¯å¯ä»¥æé«˜åˆ†ç±»ç²¾åº¦ï¼Œè¿™è¡¨æ˜ä¸åŒæ¨¡å‹çš„æç¤ºè¯è®¾è®¡ç­–ç•¥å¯èƒ½ä¸åŒã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ™ºèƒ½ç›‘æ§ã€äººæœºäº¤äº’ã€åº·å¤è®­ç»ƒç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨æ™ºèƒ½ç›‘æ§ä¸­ï¼Œå¯ä»¥åˆ©ç”¨é›¶æ ·æœ¬åˆ†ç±»æŠ€æœ¯è¯†åˆ«å¼‚å¸¸å§¿æ€ï¼Œæé«˜å®‰å…¨é¢„è­¦èƒ½åŠ›ã€‚åœ¨äººæœºäº¤äº’ä¸­ï¼Œå¯ä»¥æ ¹æ®ç”¨æˆ·çš„å§¿æ€è¿›è¡Œä¸ªæ€§åŒ–æœåŠ¡ã€‚åœ¨åº·å¤è®­ç»ƒä¸­ï¼Œå¯ä»¥è¾…åŠ©è¯„ä¼°æ‚£è€…çš„åº·å¤è¿›å±•ã€‚æœªæ¥çš„ç ”ç©¶å¯ä»¥æ¢ç´¢æ›´æœ‰æ•ˆçš„æç¤ºè¯è®¾è®¡æ–¹æ³•ï¼Œæé«˜é›¶æ ·æœ¬åˆ†ç±»çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent Vision-Language Models (VLMs) enable zero-shot classification by aligning images and text in a shared space, a promising approach for data-scarce conditions. However, the influence of prompt design on recognizing visually similar categories, such as human postures, is not well understood. This study investigates how prompt specificity affects the zero-shot classification of sitting, standing, and walking/running on a small, 285-image COCO-derived dataset. A suite of modern VLMs, including OpenCLIP, MetaCLIP 2, and SigLip, were evaluated using a three-tiered prompt design that systematically increases linguistic detail. Our findings reveal a compelling, counter-intuitive trend: for the highest-performing models (MetaCLIP 2 and OpenCLIP), the simplest, most basic prompts consistently achieve the best results. Adding descriptive detail significantly degrades performance for instance, MetaCLIP 2's multi-class accuracy drops from 68.8\% to 55.1\% a phenomenon we term "prompt overfitting". Conversely, the lower-performing SigLip model shows improved classification on ambiguous classes when given more descriptive, body-cue-based prompts.

