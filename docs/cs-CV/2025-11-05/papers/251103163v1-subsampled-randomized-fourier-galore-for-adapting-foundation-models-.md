---
layout: default
title: Subsampled Randomized Fourier GaLore for Adapting Foundation Models in Depth-Driven Liver Landmark Segmentation
---

# Subsampled Randomized Fourier GaLore for Adapting Foundation Models in Depth-Driven Liver Landmark Segmentation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.03163" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.03163v1</a>
  <a href="https://arxiv.org/pdf/2511.03163.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.03163v1" onclick="toggleFavorite(this, '2511.03163v1', 'Subsampled Randomized Fourier GaLore for Adapting Foundation Models in Depth-Driven Liver Landmark Segmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yun-Chen Lin, Jiayuan Huang, Hanyuan Zhang, Sergi Kavtaradze, Matthew J. Clarkson, Mobarak I. Hoque

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-05

**å¤‡æ³¨**: 12 pages

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSRFT-GaLoreï¼Œç”¨äºæ·±åº¦é©±åŠ¨çš„è‚è„åœ°æ ‡åˆ†å‰²ä¸­é«˜æ•ˆè‡ªé€‚åº”åŸºç¡€æ¨¡å‹ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `è‚è„åœ°æ ‡åˆ†å‰²` `æ·±åº¦å­¦ä¹ ` `è…¹è…”é•œæ‰‹æœ¯` `SRFT-GaLore` `æ·±åº¦ä¿¡æ¯èåˆ` `åŒ»å­¦å½±åƒåˆ†æ` `è‡ªé€‚åº”åŸºç¡€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. è…¹è…”é•œè‚è„æ‰‹æœ¯ä¸­ï¼Œ2Dè§†é¢‘æµé™åˆ¶äº†æ·±åº¦æ„ŸçŸ¥ï¼Œä½¿å¾—åœ°æ ‡å®šä½å˜å¾—å¤æ‚ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆèåˆRGBå’Œæ·±åº¦ç‰¹å¾ã€‚
2. æå‡ºä¸€ç§æ·±åº¦å¼•å¯¼çš„è‚è„åœ°æ ‡åˆ†å‰²æ¡†æ¶ï¼Œåˆ©ç”¨SAM2å’ŒDA2æå–RGBå’Œæ·±åº¦ç‰¹å¾ï¼Œå¹¶å¼•å…¥SRFT-GaLoreé«˜æ•ˆå¾®è°ƒSAM2ã€‚
3. åœ¨L3Dæ•°æ®é›†ä¸Šï¼ŒDiceç›¸ä¼¼ç³»æ•°æå‡4.85%ï¼Œå¹³å‡å¯¹ç§°è¡¨é¢è·ç¦»å‡å°‘11.78ä¸ªç‚¹ï¼Œå¹¶åœ¨LLSDæ•°æ®é›†ä¸Šè¡¨ç°å‡ºå¼ºå¤§çš„è·¨æ•°æ®é›†é²æ£’æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ·±åº¦å¼•å¯¼çš„è‚è„åœ°æ ‡åˆ†å‰²æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡è§†è§‰åŸºç¡€ç¼–ç å™¨æ•´åˆè¯­ä¹‰å’Œå‡ ä½•çº¿ç´¢ã€‚åˆ©ç”¨Segment Anything Model V2 (SAM2) ç¼–ç å™¨æå–RGBç‰¹å¾ï¼ŒDepth Anything V2 (DA2) ç¼–ç å™¨æå–æ·±åº¦æ„ŸçŸ¥ç‰¹å¾ã€‚ä¸ºäº†é«˜æ•ˆåœ°è‡ªé€‚åº”SAM2ï¼Œå¼•å…¥äº†SRFT-GaLoreï¼Œä¸€ç§æ–°é¢–çš„ä½ç§©æ¢¯åº¦æŠ•å½±æ–¹æ³•ï¼Œç”¨Subsampled Randomized Fourier Transform (SRFT) æ›¿ä»£äº†è®¡ç®—æˆæœ¬é«˜çš„SVDã€‚è¿™ä½¿å¾—èƒ½å¤Ÿé«˜æ•ˆåœ°å¾®è°ƒé«˜ç»´æ³¨æ„åŠ›å±‚ï¼Œè€Œä¸ä¼šç‰ºç‰²è¡¨å¾èƒ½åŠ›ã€‚ä¸€ä¸ªäº¤å‰æ³¨æ„åŠ›èåˆæ¨¡å—è¿›ä¸€æ­¥æ•´åˆäº†RGBå’Œæ·±åº¦çº¿ç´¢ã€‚ä¸ºäº†è¯„ä¼°è·¨æ•°æ®é›†çš„æ³›åŒ–èƒ½åŠ›ï¼Œæ„å»ºäº†ä¸€ä¸ªæ–°çš„è…¹è…”é•œè‚è„æ‰‹æœ¯æ•°æ®é›†(LLSD)ä½œä¸ºå¤–éƒ¨éªŒè¯åŸºå‡†ã€‚åœ¨å…¬å¼€çš„L3Dæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•åœ¨Diceç›¸ä¼¼ç³»æ•°ä¸Šå®ç°äº†4.85%çš„æå‡ï¼Œåœ¨å¹³å‡å¯¹ç§°è¡¨é¢è·ç¦»ä¸Šå‡å°‘äº†11.78ä¸ªç‚¹ã€‚åœ¨LLSDæ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ¨¡å‹ä¿æŒäº†ç«äº‰æ€§çš„æ€§èƒ½ï¼Œå¹¶æ˜¾è‘—ä¼˜äºåŸºäºSAMçš„åŸºçº¿ï¼Œè¯æ˜äº†å…¶å¼ºå¤§çš„è·¨æ•°æ®é›†é²æ£’æ€§å’Œå¯¹æœªè§æ‰‹æœ¯ç¯å¢ƒçš„é€‚åº”æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šåœ¨è…¹è…”é•œè‚è„æ‰‹æœ¯ä¸­ï¼Œç²¾ç¡®æ£€æµ‹å’Œåˆ†å‰²è§£å‰–ç»“æ„è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œ2Dè§†é¢‘æµç¼ºä¹æ·±åº¦ä¿¡æ¯ï¼Œä½¿å¾—åœ°æ ‡å®šä½æˆä¸ºä¸€é¡¹æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•åœ¨èåˆRGBå’Œæ·±åº¦ç‰¹å¾ä»¥åŠå°†å¤§è§„æ¨¡è§†è§‰æ¨¡å‹é«˜æ•ˆåœ°é€‚åº”æ‰‹æœ¯é¢†åŸŸæ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œè®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œæ³›åŒ–èƒ½åŠ›æœ‰é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ·±åº¦ä¿¡æ¯æ¥å¢å¼ºè‚è„åœ°æ ‡çš„åˆ†å‰²æ€§èƒ½ã€‚é€šè¿‡ç»“åˆRGBå›¾åƒçš„è¯­ä¹‰ä¿¡æ¯å’Œæ·±åº¦å›¾åƒçš„å‡ ä½•ä¿¡æ¯ï¼Œå¯ä»¥æ›´å‡†ç¡®åœ°å®šä½å’Œåˆ†å‰²è‚è„åœ°æ ‡ã€‚æ­¤å¤–ï¼Œé€šè¿‡å¼•å…¥SRFT-GaLoreï¼Œå¯ä»¥é«˜æ•ˆåœ°å¾®è°ƒå¤§è§„æ¨¡è§†è§‰æ¨¡å‹ï¼Œä½¿å…¶é€‚åº”æ‰‹æœ¯é¢†åŸŸï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹çš„è¡¨å¾èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) ä½¿ç”¨Segment Anything Model V2 (SAM2) ç¼–ç å™¨æå–RGBç‰¹å¾ï¼›2) ä½¿ç”¨Depth Anything V2 (DA2) ç¼–ç å™¨æå–æ·±åº¦æ„ŸçŸ¥ç‰¹å¾ï¼›3) ä½¿ç”¨SRFT-GaLoreé«˜æ•ˆå¾®è°ƒSAM2ï¼›4) ä½¿ç”¨äº¤å‰æ³¨æ„åŠ›èåˆæ¨¡å—æ•´åˆRGBå’Œæ·±åº¦çº¿ç´¢ï¼›5) ä½¿ç”¨åˆ†å‰²å¤´è¿›è¡Œè‚è„åœ°æ ‡åˆ†å‰²ã€‚æ•´ä½“æµç¨‹æ˜¯å…ˆåˆ†åˆ«æå–RGBå’Œæ·±åº¦ç‰¹å¾ï¼Œç„¶åé€šè¿‡SRFT-GaLoreé«˜æ•ˆå¾®è°ƒSAM2ï¼Œå†é€šè¿‡äº¤å‰æ³¨æ„åŠ›èåˆç‰¹å¾ï¼Œæœ€åè¿›è¡Œåˆ†å‰²ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹æ˜¯SRFT-GaLoreï¼Œå®ƒæ˜¯ä¸€ç§æ–°é¢–çš„ä½ç§©æ¢¯åº¦æŠ•å½±æ–¹æ³•ï¼Œç”¨Subsampled Randomized Fourier Transform (SRFT) æ›¿ä»£äº†è®¡ç®—æˆæœ¬é«˜çš„SVDã€‚ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºï¼ŒSRFT-GaLoreå¯ä»¥åœ¨ä¸ç‰ºç‰²è¡¨å¾èƒ½åŠ›çš„æƒ…å†µä¸‹ï¼Œé«˜æ•ˆåœ°å¾®è°ƒé«˜ç»´æ³¨æ„åŠ›å±‚ï¼Œä»è€Œé™ä½è®¡ç®—æˆæœ¬ï¼Œæé«˜è®­ç»ƒæ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šSRFT-GaLoreçš„å…³é”®è®¾è®¡åœ¨äºä½¿ç”¨Subsampled Randomized Fourier Transform (SRFT) æ¥è¿‘ä¼¼SVDã€‚å…·ä½“æ¥è¯´ï¼ŒSRFTé€šè¿‡éšæœºé‡‡æ ·å’Œå‚…é‡Œå¶å˜æ¢æ¥é™ä½è®¡ç®—å¤æ‚åº¦ï¼ŒåŒæ—¶ä¿ç•™äº†SVDçš„ä¸»è¦ä¿¡æ¯ã€‚äº¤å‰æ³¨æ„åŠ›èåˆæ¨¡å—çš„å…³é”®è®¾è®¡åœ¨äºä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶æ¥åŠ¨æ€åœ°è°ƒæ•´RGBå’Œæ·±åº¦ç‰¹å¾çš„æƒé‡ï¼Œä»è€Œæ›´å¥½åœ°èåˆä¸¤ç§æ¨¡æ€çš„ä¿¡æ¯ã€‚æŸå¤±å‡½æ•°é‡‡ç”¨Dice Losså’Œäº¤å‰ç†µæŸå¤±çš„ç»„åˆï¼Œä»¥æé«˜åˆ†å‰²ç²¾åº¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å…¬å¼€çš„L3Dæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•åœ¨Diceç›¸ä¼¼ç³»æ•°ä¸Šå®ç°äº†4.85%çš„æå‡ï¼Œåœ¨å¹³å‡å¯¹ç§°è¡¨é¢è·ç¦»ä¸Šå‡å°‘äº†11.78ä¸ªç‚¹ï¼Œæ˜¾è‘—ä¼˜äºD2GPLandã€‚åœ¨LLSDæ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ¨¡å‹ä¿æŒäº†ç«äº‰æ€§çš„æ€§èƒ½ï¼Œå¹¶æ˜¾è‘—ä¼˜äºåŸºäºSAMçš„åŸºçº¿ï¼Œè¯æ˜äº†å…¶å¼ºå¤§çš„è·¨æ•°æ®é›†é²æ£’æ€§å’Œå¯¹æœªè§æ‰‹æœ¯ç¯å¢ƒçš„é€‚åº”æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè®¡ç®—æœºè¾…åŠ©è…¹è…”é•œè‚è„æ‰‹æœ¯ï¼Œæé«˜æ‰‹æœ¯ç²¾åº¦å’Œæ•ˆç‡ï¼Œå‡å°‘æ‰‹æœ¯é£é™©ã€‚é€šè¿‡ç²¾ç¡®çš„åœ°æ ‡åˆ†å‰²ï¼ŒåŒ»ç”Ÿå¯ä»¥æ›´å¥½åœ°è§„åˆ’æ‰‹æœ¯è·¯å¾„ï¼Œé¿å…æŸä¼¤é‡è¦è¡€ç®¡å’Œç»„ç»‡ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥æ¨å¹¿åˆ°å…¶ä»–åŒ»å­¦å½±åƒåˆ†å‰²ä»»åŠ¡ä¸­ï¼Œä¾‹å¦‚è‚¿ç˜¤åˆ†å‰²ã€å™¨å®˜åˆ†å‰²ç­‰ï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Accurate detection and delineation of anatomical structures in medical imaging are critical for computer-assisted interventions, particularly in laparoscopic liver surgery where 2D video streams limit depth perception and complicate landmark localization. While recent works have leveraged monocular depth cues for enhanced landmark detection, challenges remain in fusing RGB and depth features and in efficiently adapting large-scale vision models to surgical domains. We propose a depth-guided liver landmark segmentation framework integrating semantic and geometric cues via vision foundation encoders. We employ Segment Anything Model V2 (SAM2) encoder to extract RGB features and Depth Anything V2 (DA2) encoder to extract depth-aware features. To efficiently adapt SAM2, we introduce SRFT-GaLore, a novel low-rank gradient projection method that replaces the computationally expensive SVD with a Subsampled Randomized Fourier Transform (SRFT). This enables efficient fine-tuning of high-dimensional attention layers without sacrificing representational power. A cross-attention fusion module further integrates RGB and depth cues. To assess cross-dataset generalization, we also construct a new Laparoscopic Liver Surgical Dataset (LLSD) as an external validation benchmark. On the public L3D dataset, our method achieves a 4.85% improvement in Dice Similarity Coefficient and a 11.78-point reduction in Average Symmetric Surface Distance compared to the D2GPLand. To further assess generalization capability, we evaluate our model on LLSD dataset. Our model maintains competitive performance and significantly outperforms SAM-based baselines, demonstrating strong cross-dataset robustness and adaptability to unseen surgical environments. These results demonstrate that our SRFT-GaLore-enhanced dual-encoder framework enables scalable and precise segmentation under real-time, depth-constrained surgical settings.

