---
layout: default
title: Discrete Facial Encoding: : A Framework for Data-driven Facial Display Discovery
---

# Discrete Facial Encoding: : A Framework for Data-driven Facial Display Discovery

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.01662" target="_blank" class="toolbar-btn">arXiv: 2510.01662v1</a>
    <a href="https://arxiv.org/pdf/2510.01662.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.01662v1" 
            onclick="toggleFavorite(this, '2510.01662v1', 'Discrete Facial Encoding: : A Framework for Data-driven Facial Display Discovery')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Minh Tran, Maksim Siniukov, Zhangyu Jin, Mohammad Soleymani

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-02

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Á¶ªÊï£Èù¢ÈÉ®ÁºñÁ†Å(DFE)ÔºåÁî®‰∫éÊï∞ÊçÆÈ©±Âä®ÁöÑÈù¢ÈÉ®Ë°®ÊÉÖÂèëÁé∞ÔºåÊõø‰ª£FACS„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±ÂõõÔºöÁîüÊàêÂºèÂä®‰Ωú (Generative Motion)**

**ÂÖ≥ÈîÆËØç**: `Èù¢ÈÉ®Ë°®ÊÉÖÂàÜÊûê` `Á¶ªÊï£Èù¢ÈÉ®ÁºñÁ†Å` `Êó†ÁõëÁù£Â≠¶‰π†` `RVQ-VAE` `3DÂΩ¢ÂèòÊ®°Âûã`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÈù¢ÈÉ®Ë°®ÊÉÖÂàÜÊûêÊñπÊ≥ïÂ¶ÇFACSÂ≠òÂú®Ë¶ÜÁõñËåÉÂõ¥ÊúâÈôêÂíåÊ†áÊ≥®ÊàêÊú¨È´òÁöÑÈóÆÈ¢òÔºåÈôêÂà∂‰∫ÜÂÖ∂Â∫îÁî®„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫Á¶ªÊï£Èù¢ÈÉ®ÁºñÁ†Å(DFE)ÔºåÂà©Áî®RVQ-VAEÂ≠¶‰π†Èù¢ÈÉ®Ë°®ÊÉÖÁöÑÁ¶ªÊï£tokenË°®Á§∫ÔºåÂÆûÁé∞Êó†ÁõëÁù£Â≠¶‰π†„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåDFEÂú®ÂéãÂäõÊ£ÄÊµã„ÄÅ‰∫∫Ê†ºÈ¢ÑÊµãÂíåÊäëÈÉÅÁóáÊ£ÄÊµãÁ≠â‰ªªÂä°‰∏≠‰ºò‰∫éFACSÂíåMasked Autoencoders„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Èù¢ÈÉ®Ë°®ÊÉÖÂàÜÊûêÊòØÁêÜËß£‰∫∫Á±ªË°å‰∏∫ÁöÑÂÖ≥ÈîÆÔºå‰ΩÜÁé∞ÊúâÁöÑÁºñÁ†ÅÁ≥ªÁªüÔºåÂ¶ÇÈù¢ÈÉ®Âä®‰ΩúÁºñÁ†ÅÁ≥ªÁªü(FACS)ÔºåÂèóÂà∞Ë¶ÜÁõñËåÉÂõ¥ÊúâÈôêÂíå‰∫∫Â∑•Ê†áÊ≥®ÊàêÊú¨È´òÊòÇÁöÑÈôêÂà∂„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊó†ÁõëÁù£ÁöÑ„ÄÅÊï∞ÊçÆÈ©±Âä®ÁöÑÊõø‰ª£ÊñπÊ°à‚Äî‚ÄîÁ¶ªÊï£Èù¢ÈÉ®ÁºñÁ†Å(DFE)ÔºåÂÆÉ‰ªé3DÁΩëÊ†ºÂ∫èÂàó‰∏≠Â≠¶‰π†Á¥ßÂáë‰∏îÂèØËß£ÈáäÁöÑÈù¢ÈÉ®Ë°®ÊÉÖÂ≠óÂÖ∏ÔºåËØ•Â≠óÂÖ∏ÈÄöËøáÊÆãÂ∑ÆÂêëÈáèÈáèÂåñÂèòÂàÜËá™ÁºñÁ†ÅÂô®(RVQ-VAE)Â≠¶‰π†ÂæóÂà∞„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÈ¶ñÂÖà‰ΩøÁî®3DÂΩ¢ÂèòÊ®°Âûã(3DMM)‰ªéÂõæÂÉè‰∏≠ÊèêÂèñ‰∏éË∫´‰ªΩÊó†ÂÖ≥ÁöÑË°®ÊÉÖÁâπÂæÅÔºåÊúâÊïàÂú∞Ëß£ËÄ¶‰∫ÜÂ§¥ÈÉ®ÂßøÂäøÂíåÈù¢ÈÉ®Âá†‰ΩïÁ≠âÂõ†Á¥†„ÄÇÁÑ∂ÂêéÔºåÊàë‰ª¨‰ΩøÁî®RVQ-VAEÂØπËøô‰∫õÁâπÂæÅËøõË°åÁºñÁ†ÅÔºå‰ªéÂÖ±‰∫´Á†ÅÊú¨‰∏≠ÁîüÊàê‰∏ÄÁ≥ªÂàóÁ¶ªÊï£tokenÔºåÊØè‰∏™tokenÊçïËé∑‰∏Ä‰∏™ÁâπÂÆöÁöÑ„ÄÅÂèØÈáçÁî®ÁöÑÈù¢ÈÉ®ÂèòÂΩ¢Ê®°ÂºèÔºåËØ•Ê®°ÂºèÊúâÂä©‰∫éÊï¥‰ΩìË°®ÊÉÖÁöÑË°®Ëææ„ÄÇÈÄöËøáÂ§ßÈáèÁöÑÂÆûÈ™åÔºåÊàë‰ª¨ËØÅÊòé‰∫ÜÁ¶ªÊï£Èù¢ÈÉ®ÁºñÁ†ÅÊØîFACSÂíåÂÖ∂‰ªñÈù¢ÈÉ®ÁºñÁ†ÅÊõø‰ª£ÊñπÊ°àËÉΩÊçïÊçâÂà∞Êõ¥Á≤æÁ°ÆÁöÑÈù¢ÈÉ®Ë°å‰∏∫„ÄÇÊàë‰ª¨Âú®‰∏â‰∏™È´òÂ±ÇÊ¨°ÁöÑÂøÉÁêÜÂ≠¶‰ªªÂä°‰∏≠ËØÑ‰º∞‰∫ÜÊàë‰ª¨Ë°®Á§∫ÁöÑÊïàÁî®ÔºöÂéãÂäõÊ£ÄÊµã„ÄÅ‰∫∫Ê†ºÈ¢ÑÊµãÂíåÊäëÈÉÅÁóáÊ£ÄÊµã„ÄÇ‰ΩøÁî®Âª∫Á´ãÂú®Â≠¶‰π†Âà∞ÁöÑtoken‰πã‰∏äÁöÑÁÆÄÂçïËØçË¢ãÊ®°ÂûãÔºåÊàë‰ª¨ÁöÑÁ≥ªÁªüÂßãÁªà‰ºò‰∫éÂü∫‰∫éFACSÁöÑpipeline‰ª•ÂèäÂº∫Â§ßÁöÑÂõæÂÉèÂíåËßÜÈ¢ëË°®Á§∫Â≠¶‰π†Ê®°ÂûãÔºåÂ¶ÇÊé©Á†ÅËá™ÁºñÁ†ÅÂô®„ÄÇËøõ‰∏ÄÊ≠•ÁöÑÂàÜÊûêË°®ÊòéÔºåÊàë‰ª¨ÁöÑË°®Á§∫Ê∂µÁõñ‰∫ÜÊõ¥ÂπøÊ≥õÁöÑÈù¢ÈÉ®Â±ïÁ§∫ÔºåÁ™ÅÂá∫‰∫ÜÂÖ∂‰Ωú‰∏∫FACSÂú®ÂøÉÁêÜÂíåÊÉÖÊÑüËÆ°ÁÆóÂ∫îÁî®‰∏≠ÂèØÊâ©Â±ï‰∏îÊúâÊïàÁöÑÊõø‰ª£ÊñπÊ°àÁöÑÊΩúÂäõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÈù¢ÈÉ®Ë°®ÊÉÖÂàÜÊûêÊñπÊ≥ïÔºåÂ¶ÇFACSÔºå‰æùËµñ‰∫é‰∫∫Â∑•Ê†áÊ≥®ÔºåÊàêÊú¨È´òÊòÇ‰∏îË¶ÜÁõñËåÉÂõ¥ÊúâÈôêÔºåÈöæ‰ª•ÊçïÊçâÁªÜÂæÆÁöÑÈù¢ÈÉ®ÂèòÂåñ„ÄÇËøôÈôêÂà∂‰∫ÜÂÖ∂Âú®ÂøÉÁêÜÂ≠¶ÂíåÊÉÖÊÑüËÆ°ÁÆóÁ≠âÈ¢ÜÂüüÁöÑÂ∫îÁî®„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Êó†ÁõëÁù£Â≠¶‰π†ÊñπÊ≥ïÔºåËá™Âä®‰ªéÈù¢ÈÉ®ÂõæÂÉèÂ∫èÂàó‰∏≠Â≠¶‰π†Âà∞‰∏ÄÁªÑÁ¶ªÊï£ÁöÑ„ÄÅÂèØËß£ÈáäÁöÑÈù¢ÈÉ®Ë°®ÊÉÖÂçïÂÖÉÔºàtokensÔºâ„ÄÇÈÄöËøáÂ∞ÜÂ§çÊùÇÁöÑÈù¢ÈÉ®Ë°®ÊÉÖÂàÜËß£‰∏∫Ëøô‰∫õÂü∫Êú¨ÂçïÂÖÉÁöÑÁªÑÂêàÔºåÂèØ‰ª•Êõ¥ÊúâÊïàÂú∞Ë°®Á§∫ÂíåÂàÜÊûêÈù¢ÈÉ®Ë°å‰∏∫„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöDFEÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÈò∂ÊÆµÔºö1) ‰ΩøÁî®3DMMÊèêÂèñË∫´‰ªΩÊó†ÂÖ≥ÁöÑË°®ÊÉÖÁâπÂæÅÔºåÊ∂àÈô§Â§¥ÈÉ®ÂßøÂäøÂíåÈù¢ÈÉ®Âá†‰ΩïÁöÑÂΩ±ÂìçÔºõ2) ‰ΩøÁî®RVQ-VAEÂØπÊèêÂèñÁöÑÁâπÂæÅËøõË°åÁºñÁ†ÅÔºåÁîüÊàêÁ¶ªÊï£ÁöÑtokenÂ∫èÂàóÔºõ3) ‰ΩøÁî®Â≠¶‰π†Âà∞ÁöÑtokenÊûÑÂª∫ËØçË¢ãÊ®°ÂûãÔºåÁî®‰∫é‰∏ãÊ∏∏‰ªªÂä°ÁöÑÂàÜÁ±ªÊàñÂõûÂΩí„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöDFEÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫é‰ΩøÁî®RVQ-VAEÂ≠¶‰π†Èù¢ÈÉ®Ë°®ÊÉÖÁöÑÁ¶ªÊï£Ë°®Á§∫„ÄÇ‰∏é‰º†ÁªüÁöÑËøûÁª≠Ë°®Á§∫Áõ∏ÊØîÔºåÁ¶ªÊï£Ë°®Á§∫Êõ¥Êòì‰∫éËß£ÈáäÔºåÂπ∂‰∏îÂèØ‰ª•Êõ¥Â•ΩÂú∞ÊçïÊçâÈù¢ÈÉ®Ë°®ÊÉÖÁöÑÁªìÊûÑÂåñ‰ø°ÊÅØ„ÄÇÊ≠§Â§ñÔºåRVQ-VAEÈÄöËøáÊÆãÂ∑ÆÈáèÂåñÔºåÂèØ‰ª•Êõ¥ÊúâÊïàÂú∞Âà©Áî®Á†ÅÊú¨Á©∫Èó¥ÔºåÊèêÈ´òË°®Á§∫ÁöÑÁ≤æÂ∫¶„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**Ôºö3DMMÁî®‰∫éÊèêÂèñË∫´‰ªΩÊó†ÂÖ≥ÁöÑË°®ÊÉÖÁâπÂæÅÔºåÁ°Æ‰øùÊ®°ÂûãÂÖ≥Ê≥®Ë°®ÊÉÖÊú¨Ë∫´ËÄåÈùû‰∏™‰ΩìÂ∑ÆÂºÇ„ÄÇRVQ-VAEÁöÑÁ†ÅÊú¨Â§ßÂ∞èÂíåÂ±ÇÊï∞ÊòØÈáçË¶ÅÁöÑË∂ÖÂèÇÊï∞ÔºåÈúÄË¶ÅÊ†πÊçÆÊï∞ÊçÆÈõÜËøõË°åË∞ÉÊï¥„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨ÈáçÊûÑÊçüÂ§±ÂíåÈáèÂåñÊçüÂ§±ÔºåÁî®‰∫é‰øùËØÅÈáçÊûÑË¥®ÈáèÂíåÁ†ÅÊú¨ÁöÑÊúâÊïàÊÄß„ÄÇËØçË¢ãÊ®°Âûã‰ΩøÁî®TF-IDFÂä†ÊùÉÔºåÁ™ÅÂá∫ÈáçË¶ÅtokenÁöÑ‰ΩúÁî®„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåDFEÂú®ÂéãÂäõÊ£ÄÊµã„ÄÅ‰∫∫Ê†ºÈ¢ÑÊµãÂíåÊäëÈÉÅÁóáÊ£ÄÊµãÁ≠â‰ªªÂä°‰∏≠ÔºåÂùá‰ºò‰∫éÂü∫‰∫éFACSÁöÑpipeline‰ª•ÂèäMasked AutoencodersÁ≠âÂÖàËøõÊ®°Âûã„ÄÇ‰æãÂ¶ÇÔºåÂú®ÊäëÈÉÅÁóáÊ£ÄÊµã‰ªªÂä°‰∏≠ÔºåDFEÁöÑÊÄßËÉΩÊèêÂçáË∂ÖËøá5%„ÄÇËøôË°®ÊòéDFEËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞ÊçïÊçâ‰∏éÂøÉÁêÜÁä∂ÊÄÅÁõ∏ÂÖ≥ÁöÑÈù¢ÈÉ®Ë°å‰∏∫„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂøÉÁêÜÂ≠¶„ÄÅÊÉÖÊÑüËÆ°ÁÆó„ÄÅ‰∫∫Êú∫‰∫§‰∫íÁ≠âÈ¢ÜÂüü„ÄÇ‰æãÂ¶ÇÔºåÂèØ‰ª•Áî®‰∫éËá™Âä®ËØäÊñ≠ÂøÉÁêÜÁñæÁóÖ„ÄÅËØÑ‰º∞Áî®Êà∑ÁöÑÊÉÖÁª™Áä∂ÊÄÅ„ÄÅÊîπÂñÑËôöÊãüËßíËâ≤ÁöÑË°®ÊÉÖÁîüÊàêÁ≠â„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïÊúâÊúõÊâ©Â±ïÂà∞ÂÖ∂‰ªñÈùûËØ≠Ë®ÄË°å‰∏∫ÁöÑÂàÜÊûêÔºå‰æãÂ¶ÇË∫´‰ΩìÂßøÂäøÂíåËØ≠Èü≥ËØ≠Ë∞É„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Facial expression analysis is central to understanding human behavior, yet existing coding systems such as the Facial Action Coding System (FACS) are constrained by limited coverage and costly manual annotation. In this work, we introduce Discrete Facial Encoding (DFE), an unsupervised, data-driven alternative of compact and interpretable dictionary of facial expressions from 3D mesh sequences learned through a Residual Vector Quantized Variational Autoencoder (RVQ-VAE). Our approach first extracts identity-invariant expression features from images using a 3D Morphable Model (3DMM), effectively disentangling factors such as head pose and facial geometry. We then encode these features using an RVQ-VAE, producing a sequence of discrete tokens from a shared codebook, where each token captures a specific, reusable facial deformation pattern that contributes to the overall expression. Through extensive experiments, we demonstrate that Discrete Facial Encoding captures more precise facial behaviors than FACS and other facial encoding alternatives. We evaluate the utility of our representation across three high-level psychological tasks: stress detection, personality prediction, and depression detection. Using a simple Bag-of-Words model built on top of the learned tokens, our system consistently outperforms both FACS-based pipelines and strong image and video representation learning models such as Masked Autoencoders. Further analysis reveals that our representation covers a wider variety of facial displays, highlighting its potential as a scalable and effective alternative to FACS for psychological and affective computing applications.

