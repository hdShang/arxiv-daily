---
layout: default
title: "VidGuard-R1: AI-Generated Video Detection and Explanation via Reasoning MLLMs and RL"
---

# VidGuard-R1: AI-Generated Video Detection and Explanation via Reasoning MLLMs and RL

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.02282" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.02282v2</a>
  <a href="https://arxiv.org/pdf/2510.02282.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.02282v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.02282v2', 'VidGuard-R1: AI-Generated Video Detection and Explanation via Reasoning MLLMs and RL')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kyoungjun Park, Yifan Yang, Juheon Yi, Shicheng Zheng, Yifei Shen, Dongqi Han, Caihua Shan, Muhammad Muaz, Lili Qiu

**åˆ†ç±»**: cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-10-02 (æ›´æ–°: 2025-10-06)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**VidGuard-R1ï¼šåˆ©ç”¨æ¨ç†MLLMå’Œå¼ºåŒ–å­¦ä¹ è¿›è¡ŒAIç”Ÿæˆè§†é¢‘æ£€æµ‹ä¸è§£é‡Š**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `AIç”Ÿæˆè§†é¢‘æ£€æµ‹` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `å¼ºåŒ–å­¦ä¹ ` `å¯è§£é‡Šæ€§` `ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰AIç”Ÿæˆè§†é¢‘æ£€æµ‹æ–¹æ³•ç¼ºä¹å¯è§£é‡Šæ€§ï¼Œéš¾ä»¥æ»¡è¶³ç›‘ç®¡å’Œç”¨æˆ·å¯¹é€æ˜åº¦çš„éœ€æ±‚ã€‚
2. VidGuard-R1é€šè¿‡ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰å¾®è°ƒå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼Œå®ç°å‡†ç¡®æ£€æµ‹å’Œå¯è§£é‡Šæ¨ç†ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒVidGuard-R1åœ¨é›¶æ ·æœ¬è®¾ç½®ä¸‹è¾¾åˆ°SOTAï¼Œç»è¿‡è®­ç»ƒåå‡†ç¡®ç‡è¶…è¿‡95%ï¼Œå¹¶èƒ½æä¾›ç²¾ç¡®çš„è§£é‡Šã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€AIç”Ÿæˆè§†é¢‘çš„å¿«é€Ÿå‘å±•ï¼Œè¿«åˆ‡éœ€è¦æœ‰æ•ˆçš„æ£€æµ‹å·¥å…·æ¥å‡è½»è¯¸å¦‚è™šå‡ä¿¡æ¯å’Œå£°èª‰æŸå®³ç­‰ç¤¾ä¼šé£é™©ã€‚é™¤äº†å‡†ç¡®çš„åˆ†ç±»ä¹‹å¤–ï¼Œæ£€æµ‹æ¨¡å‹æä¾›å¯è§£é‡Šçš„è§£é‡Šå¯¹äºç¡®ä¿ç›‘ç®¡æœºæ„å’Œæœ€ç»ˆç”¨æˆ·çš„é€æ˜åº¦è‡³å…³é‡è¦ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†VidGuard-R1ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªè§†é¢‘çœŸå®æ€§æ£€æµ‹å™¨ï¼Œå®ƒä½¿ç”¨ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰å¾®è°ƒå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ã€‚æˆ‘ä»¬çš„æ¨¡å‹æä¾›é«˜åº¦å‡†ç¡®çš„åˆ¤æ–­å’Œæ·±åˆ»çš„æ¨ç†ã€‚æˆ‘ä»¬ç²¾å¿ƒç­–åˆ’äº†ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«ç”±æœ€å…ˆè¿›çš„ç”Ÿæˆæ¨¡å‹ç”Ÿæˆçš„14ä¸‡ä¸ªçœŸå®å’ŒAIç”Ÿæˆçš„è§†é¢‘ï¼Œå¹¶ä»”ç»†è®¾è®¡äº†ç”Ÿæˆè¿‡ç¨‹ä»¥æœ€å¤§é™åº¦åœ°æé«˜åŒºåˆ†éš¾åº¦ã€‚ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨GRPOå’Œä¸¤ä¸ªä¸“é—¨çš„å¥–åŠ±æ¨¡å‹ï¼ˆé’ˆå¯¹æ—¶é—´ä¼ªå½±å’Œç”Ÿæˆå¤æ‚æ€§ï¼‰æ¥å¾®è°ƒQwen-VLã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒVidGuard-R1åœ¨ç°æœ‰åŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æœ€å…ˆè¿›çš„é›¶æ ·æœ¬æ€§èƒ½ï¼Œé¢å¤–çš„è®­ç»ƒå°†å‡†ç¡®ç‡æé«˜åˆ°95%ä»¥ä¸Šã€‚æ¡ˆä¾‹ç ”ç©¶è¿›ä¸€æ­¥è¡¨æ˜ï¼ŒVidGuard-R1äº§ç”Ÿäº†å…¶é¢„æµ‹èƒŒåç²¾ç¡®ä¸”å¯è§£é‡Šçš„åŸºæœ¬åŸç†ã€‚ä»£ç å·²åœ¨https://VidGuard-R1.github.ioä¸Šå…¬å¼€å‘å¸ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå½“å‰AIç”Ÿæˆè§†é¢‘æ£€æµ‹æ–¹æ³•ä¸»è¦å…³æ³¨å‡†ç¡®ç‡ï¼Œä½†ç¼ºä¹å¯¹æ£€æµ‹ç»“æœçš„è§£é‡Šèƒ½åŠ›ï¼Œå¯¼è‡´ç”¨æˆ·éš¾ä»¥ä¿¡ä»»æ£€æµ‹ç»“æœï¼Œä¹Ÿç»™ç›‘ç®¡å¸¦æ¥æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆåŒºåˆ†çœŸå®è§†é¢‘å’Œå¤æ‚AIç”Ÿæˆè§†é¢‘ï¼Œå°¤å…¶æ˜¯åœ¨æ—¶é—´ä¸€è‡´æ€§å’Œç”Ÿæˆå¤æ‚æ€§æ–¹é¢ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šVidGuard-R1çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰çš„æ¨ç†èƒ½åŠ›ï¼Œç»“åˆå¼ºåŒ–å­¦ä¹ ï¼Œä½¿å…¶ä¸ä»…èƒ½åˆ¤æ–­è§†é¢‘çœŸä¼ªï¼Œè¿˜èƒ½ç»™å‡ºåˆ¤æ–­ä¾æ®ã€‚é€šè¿‡å¥–åŠ±æ¨¡å‹å¼•å¯¼MLLMå…³æ³¨è§†é¢‘ä¸­çš„æ—¶é—´ä¼ªå½±å’Œç”Ÿæˆå¤æ‚æ€§ï¼Œä»è€Œæé«˜æ£€æµ‹å‡†ç¡®ç‡å’Œå¯è§£é‡Šæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVidGuard-R1çš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ï¼š1) æ•°æ®é›†æ„å»ºï¼šæ„å»ºåŒ…å«çœŸå®å’ŒAIç”Ÿæˆè§†é¢‘çš„å¤§è§„æ¨¡æ•°æ®é›†ï¼Œå¹¶ç€é‡æé«˜ç”Ÿæˆéš¾åº¦ï¼›2) MLLMå¾®è°ƒï¼šä½¿ç”¨ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰å¾®è°ƒQwen-VLæ¨¡å‹ï¼›3) å¥–åŠ±æ¨¡å‹ï¼šè®­ç»ƒä¸¤ä¸ªå¥–åŠ±æ¨¡å‹ï¼Œåˆ†åˆ«è¯„ä¼°è§†é¢‘çš„æ—¶é—´ä¼ªå½±å’Œç”Ÿæˆå¤æ‚æ€§ï¼›4) æ¨ç†ç”Ÿæˆï¼šåˆ©ç”¨å¾®è°ƒåçš„MLLMç”Ÿæˆè§†é¢‘çœŸä¼ªçš„åˆ¤æ–­å’Œè§£é‡Šã€‚

**å…³é”®åˆ›æ–°**ï¼šVidGuard-R1çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) é¦–æ¬¡å°†å¼ºåŒ–å­¦ä¹ å¼•å…¥AIç”Ÿæˆè§†é¢‘æ£€æµ‹é¢†åŸŸï¼Œé€šè¿‡å¥–åŠ±æ¨¡å‹å¼•å¯¼MLLMå­¦ä¹ ï¼›2) æå‡ºç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰æ–¹æ³•ï¼Œæé«˜è®­ç»ƒæ•ˆç‡å’Œç¨³å®šæ€§ï¼›3) å®ç°äº†æ—¢èƒ½å‡†ç¡®æ£€æµ‹ï¼Œåˆèƒ½æä¾›å¯è§£é‡Šæ¨ç†çš„è§†é¢‘çœŸå®æ€§æ£€æµ‹å™¨ã€‚

**å…³é”®è®¾è®¡**ï¼šGRPOçš„å…·ä½“å®ç°ç»†èŠ‚åŒ…æ‹¬ï¼šå®šä¹‰å¥–åŠ±å‡½æ•°ï¼Œé¼“åŠ±æ¨¡å‹å…³æ³¨æ—¶é—´ä¼ªå½±å’Œç”Ÿæˆå¤æ‚æ€§ï¼›è®¾è®¡åˆé€‚çš„promptæ¨¡æ¿ï¼Œå¼•å¯¼MLLMç”Ÿæˆæ¸…æ™°çš„è§£é‡Šï¼›ä½¿ç”¨Qwen-VLä½œä¸ºåŸºç¡€æ¨¡å‹ï¼Œåˆ©ç”¨å…¶å¼ºå¤§çš„å¤šæ¨¡æ€ç†è§£èƒ½åŠ›ã€‚å¥–åŠ±æ¨¡å‹çš„è®¾è®¡ä¹Ÿè‡³å…³é‡è¦ï¼Œéœ€è¦èƒ½å¤Ÿå‡†ç¡®è¯„ä¼°è§†é¢‘çš„æ—¶é—´ä¸€è‡´æ€§å’Œç”Ÿæˆéš¾åº¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

VidGuard-R1åœ¨ç°æœ‰åŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æœ€å…ˆè¿›çš„é›¶æ ·æœ¬æ€§èƒ½ï¼Œæ— éœ€é¢å¤–è®­ç»ƒå³å¯è¾¾åˆ°SOTAæ°´å¹³ã€‚ç»è¿‡é’ˆå¯¹æ—¶é—´ä¼ªå½±å’Œç”Ÿæˆå¤æ‚æ€§çš„è®­ç»ƒåï¼Œå‡†ç¡®ç‡è¿›ä¸€æ­¥æå‡è‡³95%ä»¥ä¸Šã€‚æ¡ˆä¾‹ç ”ç©¶è¡¨æ˜ï¼ŒVidGuard-R1èƒ½å¤Ÿç”Ÿæˆç²¾ç¡®ä¸”å¯è§£é‡Šçš„æ¨ç†ï¼Œä¸ºç”¨æˆ·æä¾›å¯ä¿¡çš„åˆ¤æ–­ä¾æ®ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

VidGuard-R1å¯åº”ç”¨äºç¤¾äº¤åª’ä½“å¹³å°ã€æ–°é—»åª’ä½“æœºæ„ç­‰ï¼Œç”¨äºæ£€æµ‹å’Œæ ‡è®°AIç”Ÿæˆçš„è™šå‡è§†é¢‘ï¼Œé˜²æ­¢è™šå‡ä¿¡æ¯ä¼ æ’­ï¼Œç»´æŠ¤ç½‘ç»œå®‰å…¨ã€‚è¯¥æŠ€æœ¯è¿˜å¯ç”¨äºç‰ˆæƒä¿æŠ¤ï¼Œè¯†åˆ«æœªç»æˆæƒçš„AIç”Ÿæˆå†…å®¹ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›æˆä¸ºå†…å®¹å®¡æ ¸çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œæå‡å†…å®¹å¹³å°çš„å…¬ä¿¡åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> With the rapid advancement of AI-generated videos, there is an urgent need for effective detection tools to mitigate societal risks such as misinformation and reputational harm. In addition to accurate classification, it is essential that detection models provide interpretable explanations to ensure transparency for regulators and end users. To address these challenges, we introduce VidGuard-R1, the first video authenticity detector that fine-tunes a multi-modal large language model (MLLM) using group relative policy optimization (GRPO). Our model delivers both highly accurate judgments and insightful reasoning. We curate a challenging dataset of 140k real and AI-generated videos produced by state-of-the-art generation models, carefully designing the generation process to maximize discrimination difficulty. We then fine-tune Qwen-VL using GRPO with two specialized reward models that target temporal artifacts and generation complexity. Extensive experiments demonstrate that VidGuard-R1 achieves state-of-the-art zero-shot performance on existing benchmarks, with additional training pushing accuracy above 95%. Case studies further show that VidGuard-R1 produces precise and interpretable rationales behind its predictions. The code is publicly available at https://VidGuard-R1.github.io.

