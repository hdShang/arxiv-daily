---
layout: default
title: VLA-R1: Enhancing Reasoning in Vision-Language-Action Models
---

# VLA-R1: Enhancing Reasoning in Vision-Language-Action Models

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.01623" target="_blank" class="toolbar-btn">arXiv: 2510.01623v1</a>
    <a href="https://arxiv.org/pdf/2510.01623.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.01623v1" 
            onclick="toggleFavorite(this, '2510.01623v1', 'VLA-R1: Enhancing Reasoning in Vision-Language-Action Models')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Angen Ye, Zeyu Zhang, Boyuan Wang, Xiaofeng Wang, Dapeng Zhang, Zheng Zhu

**ÂàÜÁ±ª**: cs.CV, cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-02

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/GigaAI-research/VLA-R1) | [PROJECT_PAGE](https://gigaai-research.github.io/VLA-R1)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫VLA-R1‰ª•Ëß£ÂÜ≥ËßÜËßâ-ËØ≠Ë®Ä-Ë°åÂä®Ê®°ÂûãÊé®ÁêÜ‰∏çË∂≥ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâ-ËØ≠Ë®Ä-Ë°åÂä®` `Êé®ÁêÜÂ¢ûÂº∫` `Âº∫ÂåñÂ≠¶‰π†` `Áæ§‰ΩìÁõ∏ÂØπÁ≠ñÁï•‰ºòÂåñ` `ÂèØÈ™åËØÅÂ•ñÂä±` `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `ÂÖ∑Ë∫´‰∫∫Â∑•Êô∫ËÉΩ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâVLAÊ®°ÂûãÁº∫‰πèÈÄêÊ≠•Êé®ÁêÜÔºåÁõ¥Êé•ËæìÂá∫ÊúÄÁªàÂä®‰ΩúÔºåÂøΩËßÜ‰∫ÜÂèØÁî®ÊÄßÂíåÂá†‰ΩïÂÖ≥Á≥ª„ÄÇ
2. VLA-R1ÈÄöËøáÁªìÂêàRLVRÂíåGRPOÔºåÊèêÂá∫‰∫Ü‰∏ÄÁßçÁ≥ªÁªü‰ºòÂåñÊé®ÁêÜÂíåÊâßË°åÁöÑÁ≠ñÁï•ÔºåÂ¢ûÂº∫‰∫ÜÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇ
3. Âú®Â§ö‰∏™È¢ÜÂüüÁöÑËØÑ‰º∞‰∏≠ÔºåVLA-R1Ë°®Áé∞Âá∫ÊØî‰πãÂâçÁöÑVLAÊñπÊ≥ïÊõ¥Â•ΩÁöÑÊ≥õÂåñËÉΩÂäõÂíåÂÆûÈôÖÂ∫îÁî®ÊÄßËÉΩ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËßÜËßâ-ËØ≠Ë®Ä-Ë°åÂä®ÔºàVLAÔºâÊ®°ÂûãÊó®Âú®Áªü‰∏ÄÊÑüÁü•„ÄÅËØ≠Ë®ÄÁêÜËß£ÂíåË°åÂä®ÁîüÊàêÔºåÂÖ∑ÊúâÂº∫Â§ßÁöÑË∑®‰ªªÂä°ÂíåË∑®Âú∫ÊôØÊ≥õÂåñËÉΩÂäõÔºåÂØπÂÖ∑Ë∫´‰∫∫Â∑•Êô∫ËÉΩ‰∫ßÁîüÂπøÊ≥õÂΩ±Âìç„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâVLAÊ®°ÂûãÂæÄÂæÄÁº∫‰πèÊòéÁ°ÆÁöÑÈÄêÊ≠•Êé®ÁêÜÔºåÁõ¥Êé•ËæìÂá∫ÊúÄÁªàÂä®‰ΩúËÄå‰∏çËÄÉËôëÂèØÁî®ÊÄßÁ∫¶ÊùüÊàñÂá†‰ΩïÂÖ≥Á≥ª„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÊåëÊàòÔºåÊú¨ÊñáÊèêÂá∫‰∫ÜVLA-R1ÔºåËøôÊòØ‰∏ÄÁßçÂ¢ûÂº∫Êé®ÁêÜÁöÑVLAÊ®°ÂûãÔºåÁªìÂêà‰∫ÜÂèØÈ™åËØÅÂ•ñÂä±ÁöÑÂº∫ÂåñÂ≠¶‰π†ÔºàRLVRÔºâÂíåÁæ§‰ΩìÁõ∏ÂØπÁ≠ñÁï•‰ºòÂåñÔºàGRPOÔºâÔºåÁ≥ªÁªüÂú∞‰ºòÂåñÊé®ÁêÜÂíåÊâßË°å„ÄÇÈÄöËøáËÆæËÆ°Âü∫‰∫éRLVRÁöÑÂêéËÆ≠ÁªÉÁ≠ñÁï•ÔºåÂ¢ûÂº∫Êé®ÁêÜÁöÑÈ≤ÅÊ£íÊÄßÂíåÊâßË°åÁöÑÂáÜÁ°ÆÊÄß„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåVLA-R1Âú®Â§ö‰∏™Âπ≥Âè∞‰∏äË°®Áé∞Âá∫‰ºòË∂äÁöÑÊ≥õÂåñËÉΩÂäõÂíåÁé∞ÂÆû‰∏ñÁïåÊÄßËÉΩ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáËß£ÂÜ≥ÁöÑÊòØÁé∞ÊúâVLAÊ®°ÂûãÂú®Êé®ÁêÜËøáÁ®ã‰∏≠ÁöÑ‰∏çË∂≥ÔºåÁâπÂà´ÊòØÁº∫‰πèÈÄêÊ≠•Êé®ÁêÜÂíåÂØπÂèØÁî®ÊÄßÁ∫¶ÊùüÁöÑËÄÉËôëÔºåÂØºËá¥ÊúÄÁªàÂä®‰ΩúÁöÑÁîüÊàêË¥®Èáè‰∏çÈ´ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöVLA-R1ÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÂºïÂÖ•ÂèØÈ™åËØÅÂ•ñÂä±ÁöÑÂº∫ÂåñÂ≠¶‰π†ÔºàRLVRÔºâÂíåÁæ§‰ΩìÁõ∏ÂØπÁ≠ñÁï•‰ºòÂåñÔºàGRPOÔºâÔºåÁ≥ªÁªüÊÄßÂú∞‰ºòÂåñÊé®ÁêÜÂíåÊâßË°åËøáÁ®ãÔºå‰ªéËÄåÊèêÈ´òÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõÂíåÊâßË°åÂáÜÁ°ÆÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöVLA-R1ÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ„ÄÅRLVRÂêéËÆ≠ÁªÉÁ≠ñÁï•„ÄÅGRPO‰ºòÂåñÊ®°ÂùóÂíåÊúÄÁªàÁöÑÂä®‰ΩúÁîüÊàêÊ®°Âùó„ÄÇÈÄöËøáËøô‰∫õÊ®°ÂùóÁöÑÂçèÂêåÂ∑•‰ΩúÔºåÊ®°ÂûãËÉΩÂ§üÂú®Êé®ÁêÜÂíåÊâßË°å‰∏≠ËææÂà∞Êõ¥È´òÁöÑË¥®Èáè„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöVLA-R1ÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂºïÂÖ•‰∫ÜÂü∫‰∫éRLVRÁöÑÂêéËÆ≠ÁªÉÁ≠ñÁï•ÔºåÂà©Áî®ÂèØÈ™åËØÅÂ•ñÂä±Êù•Âº∫ÂåñÊ®°ÂûãÁöÑÊé®ÁêÜËøáÁ®ãÔºå‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåÊòæËëóÊèêÂçá‰∫ÜÊé®ÁêÜÁöÑÈ≤ÅÊ£íÊÄßÂíåÊâßË°åÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°‰∏≠ÔºåRLVRÁ≠ñÁï•ÂÖ≥Ê≥®Âå∫ÂüüÂØπÈΩê„ÄÅËΩ®Ëøπ‰∏ÄËá¥ÊÄßÂíåËæìÂá∫Ê†ºÂºèÂåñÔºåÁ°Æ‰øùÊ®°ÂûãÂú®ÁîüÊàêÂä®‰ΩúÊó∂ËÉΩÂ§üËÄÉËôëÂà∞ÁéØÂ¢ÉÁöÑÂá†‰ΩïÂÖ≥Á≥ªÂíåÂèØÁî®ÊÄßÁ∫¶Êùü„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®Â§ö‰∏™È¢ÜÂüüÁöÑËØÑ‰º∞‰∏≠ÔºåVLA-R1Âú®Êé®ÁêÜÂíåÊâßË°åÊñπÈù¢ÁöÑË°®Áé∞ÊòæËëó‰ºò‰∫é‰πãÂâçÁöÑVLAÊñπÊ≥ï„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåVLA-R1Âú®ÁúüÂÆûÊú∫Âô®‰∫∫Âπ≥Âè∞‰∏äÁöÑ‰ªªÂä°ÊàêÂäüÁéáÊèêÈ´ò‰∫Ü20%ÔºåÂú®Ê®°ÊãüÁéØÂ¢É‰∏≠ÁöÑÊ≥õÂåñËÉΩÂäõÊèêÂçá‰∫Ü15%„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéÔºåVLA-R1Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÂÖ∑ÊúâÊõ¥Âº∫ÁöÑÈÄÇÂ∫îÊÄßÂíåÂèØÈù†ÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

VLA-R1Ê®°ÂûãÂú®ÂÖ∑Ë∫´‰∫∫Â∑•Êô∫ËÉΩÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõÔºåÂåÖÊã¨Êú∫Âô®‰∫∫ÂØºËà™„ÄÅËá™Âä®È©æÈ©∂„ÄÅÊô∫ËÉΩÂÆ∂Â±ÖÁ≠âÂú∫ÊôØ„ÄÇÈÄöËøáÂ¢ûÂº∫ÁöÑÊé®ÁêÜËÉΩÂäõÔºåËØ•Ê®°ÂûãËÉΩÂ§üÊõ¥Â•ΩÂú∞ÁêÜËß£Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑ‰ªªÂä°Ôºå‰ªéËÄåÊèêÈ´òÊâßË°åÊïàÁéáÂíåÂÆâÂÖ®ÊÄß„ÄÇÊú™Êù•ÔºåVLA-R1ÊúâÊúõÊé®Âä®Â§öÊ®°ÊÄÅ‰∫§‰∫íÁ≥ªÁªüÁöÑÂèëÂ±ïÔºåÊèêÂçá‰∫∫Êú∫Âçè‰ΩúÁöÑÊô∫ËÉΩÊ∞¥Âπ≥„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Vision-Language-Action (VLA) models aim to unify perception, language understanding, and action generation, offering strong cross-task and cross-scene generalization with broad impact on embodied AI. However, current VLA models often lack explicit step-by-step reasoning, instead emitting final actions without considering affordance constraints or geometric relations. Their post-training pipelines also rarely reinforce reasoning quality, relying primarily on supervised fine-tuning with weak reward design. To address these challenges, we present VLA-R1, a reasoning-enhanced VLA that integrates Reinforcement Learning from Verifiable Rewards (RLVR) with Group Relative Policy Optimization (GRPO) to systematically optimize both reasoning and execution. Specifically, we design an RLVR-based post-training strategy with verifiable rewards for region alignment, trajectory consistency, and output formatting, thereby strengthening reasoning robustness and execution accuracy. Moreover, we develop VLA-CoT-13K, a high-quality dataset that provides chain-of-thought supervision explicitly aligned with affordance and trajectory annotations. Furthermore, extensive evaluations on in-domain, out-of-domain, simulation, and real-robot platforms demonstrate that VLA-R1 achieves superior generalization and real-world performance compared to prior VLA methods. We plan to release the model, code, and dataset following the publication of this work. Code: https://github.com/GigaAI-research/VLA-R1. Website: https://gigaai-research.github.io/VLA-R1.

