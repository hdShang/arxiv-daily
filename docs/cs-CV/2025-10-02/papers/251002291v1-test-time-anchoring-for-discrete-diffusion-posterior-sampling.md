---
layout: default
title: Test-Time Anchoring for Discrete Diffusion Posterior Sampling
---

# Test-Time Anchoring for Discrete Diffusion Posterior Sampling

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.02291" target="_blank" class="toolbar-btn">arXiv: 2510.02291v1</a>
    <a href="https://arxiv.org/pdf/2510.02291.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.02291v1" 
            onclick="toggleFavorite(this, '2510.02291v1', 'Test-Time Anchoring for Discrete Diffusion Posterior Sampling')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Litu Rout, Andreas Lugmayr, Yasamin Jafarian, Srivatsan Varadharajan, Constantine Caramanis, Sanjay Shakkottai, Ira Kemelmacher-Shlizerman

**ÂàÜÁ±ª**: cs.LG, cs.CV, stat.ML

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-02

**Â§áÊ≥®**: Preprint

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Anchored Posterior Sampling (APS)ÔºåÁî®‰∫éÁ¶ªÊï£Êâ©Êï£ÂêéÈ™åÈááÊ†∑ÔºåËß£ÂÜ≥ÈÄÜÈóÆÈ¢ò„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Á¶ªÊï£Êâ©Êï£Ê®°Âûã` `ÂêéÈ™åÈááÊ†∑` `ÂõæÂÉèÈÄÜÈóÆÈ¢ò` `ÈáèÂåñÊúüÊúõ` `ÈîöÂÆöÈáçÊé©Á†Å` `ÂÖçËÆ≠ÁªÉ` `ÂõæÂÉèÊÅ¢Â§ç`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁ¶ªÊï£Êâ©Êï£ÂêéÈ™åÈááÊ†∑ÊñπÊ≥ïÈù¢‰∏¥Á®ÄÁñè‰ø°Âè∑„ÄÅÈÄÇÁî®ÊÄßÂèóÈôêÂíåÁª¥Â∫¶ÁÅæÈöæÁ≠âÊåëÊàò„ÄÇ
2. ÊèêÂá∫Anchored Posterior Sampling (APS)ÔºåÂà©Áî®ÈáèÂåñÊúüÊúõËøõË°åÊ¢ØÂ∫¶ÂºïÂØºÔºåÂπ∂ÈááÁî®ÈîöÂÆöÈáçÊé©Á†ÅËøõË°åËá™ÈÄÇÂ∫îËß£Á†Å„ÄÇ
3. APSÂú®ÂõæÂÉèÈÄÜÈóÆÈ¢ò‰∏äÂèñÂæó‰∫ÜSOTAÊÄßËÉΩÔºåÂπ∂Âú®ÂÖçËÆ≠ÁªÉÈ£éÊ†ºÂåñÂíåÊñáÊú¨ÂºïÂØºÁºñËæë‰∏≠Â±ïÁé∞‰∫Ü‰ºòÂäø„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÁ†îÁ©∂‰∫Ü‰ΩøÁî®È¢ÑËÆ≠ÁªÉÁ¶ªÊï£Êâ©Êï£Âü∫Á°ÄÊ®°ÂûãËøõË°åÂêéÈ™åÈááÊ†∑ÁöÑÈóÆÈ¢òÔºåÊó®Âú®‰ªéÂ∏¶Âô™Â£∞ÁöÑÊµãÈáèÊï∞ÊçÆ‰∏≠ÊÅ¢Â§çÂõæÂÉèÔºåËÄåÊó†ÈúÄÈáçÊñ∞ËÆ≠ÁªÉÁâπÂÆö‰ªªÂä°ÁöÑÊ®°Âûã„ÄÇËôΩÁÑ∂Êâ©Êï£Ê®°ÂûãÂú®ÁîüÊàêÂª∫Ê®°ÊñπÈù¢ÂèñÂæó‰∫ÜÊòæËëóÊàêÂäüÔºå‰ΩÜÂ§ßÂ§öÊï∞ËøõÂ±ï‰æùËµñ‰∫éËøûÁª≠È´òÊñØÊâ©Êï£„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåÁ¶ªÊï£Êâ©Êï£‰∏∫ËÅîÂêàÂª∫Ê®°ÂàÜÁ±ªÊï∞ÊçÆÔºàÂ¶ÇÊñáÊú¨ÂíåÂõæÂÉèÔºâÊèê‰æõ‰∫Ü‰∏Ä‰∏™Áªü‰∏ÄÁöÑÊ°ÜÊû∂„ÄÇÈô§‰∫ÜÁªü‰∏ÄÊÄß‰πãÂ§ñÔºåÁ¶ªÊï£Êâ©Êï£ËøòÊèê‰æõÊõ¥Âø´ÁöÑÊé®ÁêÜ„ÄÅÊõ¥Á≤æÁªÜÁöÑÊéßÂà∂ÂíåÊúâÂéüÂàôÁöÑÂÖçËÆ≠ÁªÉË¥ùÂè∂ÊñØÊé®ÁêÜÔºå‰ΩøÂÖ∂ÁâπÂà´ÈÄÇÂêàÂêéÈ™åÈááÊ†∑„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÁöÑÁ¶ªÊï£Êâ©Êï£ÂêéÈ™åÈááÊ†∑ÊñπÊ≥ïÈù¢‰∏¥‰∏•Â≥ªÊåëÊàòÔºöÊó†ÂØºÊï∞ÂºïÂØº‰∫ßÁîüÁ®ÄÁñè‰ø°Âè∑ÔºåËøûÁª≠ÊùæÂºõÈôêÂà∂‰∫ÜÈÄÇÁî®ÊÄßÔºåÂπ∂‰∏îÂàÜË£ÇÂêâÂ∏ÉÊñØÈááÊ†∑Âô®ÈÅ≠ÂèóÁª¥Â∫¶ÁÅæÈöæ„ÄÇ‰∏∫‰∫ÜÂÖãÊúçËøô‰∫õÈôêÂà∂ÔºåÊàë‰ª¨‰∏∫Êé©Á†ÅÊâ©Êï£Âü∫Á°ÄÊ®°ÂûãÂºïÂÖ•‰∫ÜAnchored Posterior Sampling (APS)ÔºåÂÆÉÂª∫Á´ãÂú®‰∏§‰∏™ÂÖ≥ÈîÆÂàõÊñ∞‰πã‰∏ä‚Äî‚ÄîÁ¶ªÊï£ÂµåÂÖ•Á©∫Èó¥‰∏≠Áî®‰∫éÁ±ªÊ¢ØÂ∫¶ÂºïÂØºÁöÑÈáèÂåñÊúüÊúõÔºå‰ª•ÂèäÁî®‰∫éËá™ÈÄÇÂ∫îËß£Á†ÅÁöÑÈîöÂÆöÈáçÊé©Á†Å„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®Ê†áÂáÜÂü∫ÂáÜ‰∏äÁöÑÁ∫øÊÄßÂíåÈùûÁ∫øÊÄßÈÄÜÈóÆÈ¢ò‰∏≠ÔºåÂÆûÁé∞‰∫ÜÁ¶ªÊï£Êâ©Êï£ÈááÊ†∑Âô®‰∏≠ÁöÑÊúÄÂÖàËøõÊÄßËÉΩ„ÄÇÊàë‰ª¨Ëøõ‰∏ÄÊ≠•Â±ïÁ§∫‰∫ÜÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®ÂÖçËÆ≠ÁªÉÈ£éÊ†ºÂåñÂíåÊñáÊú¨ÂºïÂØºÁºñËæë‰∏≠ÁöÑ‰ºòÂäø„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Á¶ªÊï£Êâ©Êï£Ê®°ÂûãÂú®ÂêéÈ™åÈááÊ†∑‰∏≠Èù¢‰∏¥ÁöÑÊåëÊàòÔºåÁâπÂà´ÊòØÂú®ÂõæÂÉèÈÄÜÈóÆÈ¢ò‰∏≠ÔºåÂ¶Ç‰Ωï‰ªéÂô™Â£∞ÊµãÈáè‰∏≠ÊÅ¢Â§çÂõæÂÉè„ÄÇÁé∞ÊúâÊñπÊ≥ïÔºåÂ¶ÇÊó†ÂØºÊï∞ÂºïÂØº„ÄÅËøûÁª≠ÊùæÂºõÂíåÂàÜË£ÇÂêâÂ∏ÉÊñØÈááÊ†∑Âô®ÔºåÂ≠òÂú®‰ø°Âè∑Á®ÄÁñè„ÄÅÈÄÇÁî®ÊÄßÂèóÈôêÂíåÁª¥Â∫¶ÁÅæÈöæÁ≠âÈóÆÈ¢òÔºåÂØºËá¥ÊÄßËÉΩ‰∏ç‰Ω≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®ÈáèÂåñÊúüÊúõÊù•Ëøë‰ººÊ¢ØÂ∫¶Ôºå‰ªéËÄåÂú®Á¶ªÊï£ÂµåÂÖ•Á©∫Èó¥‰∏≠Êèê‰æõÊõ¥ÊúâÊïàÁöÑÂºïÂØº‰ø°Âè∑„ÄÇÂêåÊó∂ÔºåÈÄöËøáÈîöÂÆöÈáçÊé©Á†ÅÁ≠ñÁï•ÔºåÂÆûÁé∞Ëá™ÈÄÇÂ∫îÁöÑËß£Á†ÅËøáÁ®ãÔºåÂÖãÊúç‰º†ÁªüÊñπÊ≥ïÁöÑÂ±ÄÈôêÊÄß„ÄÇËøôÁßçËÆæËÆ°Êó®Âú®ÂÖÖÂàÜÂà©Áî®Á¶ªÊï£Êâ©Êï£Ê®°ÂûãÁöÑ‰ºòÂäøÔºåÂÆûÁé∞Êõ¥Á≤æÁ°Æ„ÄÅÊõ¥È´òÊïàÁöÑÂêéÈ™åÈááÊ†∑„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöAPSÊñπÊ≥ï‰∏ªË¶ÅÂåÖÂê´‰∏§‰∏™ÂÖ≥ÈîÆÊ®°ÂùóÔºöÈáèÂåñÊúüÊúõÊ®°ÂùóÂíåÈîöÂÆöÈáçÊé©Á†ÅÊ®°Âùó„ÄÇÈáèÂåñÊúüÊúõÊ®°ÂùóÁî®‰∫éÂú®Á¶ªÊï£ÂµåÂÖ•Á©∫Èó¥‰∏≠ËÆ°ÁÆóÁ±ªÊ¢ØÂ∫¶ÂºïÂØºÔºå‰∏∫Êâ©Êï£ËøáÁ®ãÊèê‰æõÊñπÂêë„ÄÇÈîöÂÆöÈáçÊé©Á†ÅÊ®°ÂùóÂàôÊ†πÊçÆÂΩìÂâçÁä∂ÊÄÅËá™ÈÄÇÂ∫îÂú∞Ë∞ÉÊï¥Êé©Á†ÅÂå∫ÂüüÔºå‰ªéËÄåÂÆûÁé∞Êõ¥Á≤æÁªÜÁöÑËß£Á†ÅËøáÁ®ã„ÄÇÊï¥‰ΩìÊµÅÁ®ãÂåÖÊã¨ÔºöÈ¶ñÂÖàÔºåÂØπËæìÂÖ•ÂõæÂÉèËøõË°åÊé©Á†ÅÂ§ÑÁêÜÔºõÁÑ∂ÂêéÔºåÈÄöËøáÊâ©Êï£ËøáÁ®ãÈÄêÊ≠•Ê∑ªÂä†Âô™Â£∞ÔºõÊé•ÁùÄÔºåÂà©Áî®ÈáèÂåñÊúüÊúõÂíåÈîöÂÆöÈáçÊé©Á†ÅËøõË°åÂêéÈ™åÈááÊ†∑ÔºåÈÄêÊ≠•ÊÅ¢Â§çÂõæÂÉè„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöAPSÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1) ‰ΩøÁî®ÈáèÂåñÊúüÊúõÊù•Ëøë‰ººÊ¢ØÂ∫¶ÔºåÂÖãÊúç‰∫ÜÁ¶ªÊï£Á©∫Èó¥‰∏≠Ê¢ØÂ∫¶ËÆ°ÁÆóÁöÑÈöæÈ¢òÔºåÊèê‰æõ‰∫ÜÊõ¥ÊúâÊïàÁöÑÂºïÂØº‰ø°Âè∑„ÄÇ2) ÂºïÂÖ•ÈîöÂÆöÈáçÊé©Á†ÅÁ≠ñÁï•ÔºåÂÆûÁé∞‰∫ÜËá™ÈÄÇÂ∫îÁöÑËß£Á†ÅËøáÁ®ãÔºåÈÅøÂÖç‰∫Ü‰º†ÁªüÊñπÊ≥ï‰∏≠Âõ∫ÂÆöÊé©Á†ÅÂ∏¶Êù•ÁöÑÂ±ÄÈôêÊÄß„ÄÇËøô‰∫õÂàõÊñ∞‰ΩøÂæóAPSËÉΩÂ§üÂú®Á¶ªÊï£Êâ©Êï£Ê®°Âûã‰∏≠ÂÆûÁé∞Êõ¥Á≤æÁ°Æ„ÄÅÊõ¥È´òÊïàÁöÑÂêéÈ™åÈááÊ†∑„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÈáèÂåñÊúüÊúõÊ®°ÂùóÈÄöËøáËÆ°ÁÆóÁ¶ªÊï£ÂµåÂÖ•Á©∫Èó¥‰∏≠Áõ∏ÈÇªÁä∂ÊÄÅÁöÑÊúüÊúõÂÄºÔºåÊù•Ëøë‰ººÊ¢ØÂ∫¶ÊñπÂêë„ÄÇÈîöÂÆöÈáçÊé©Á†ÅÊ®°ÂùóÂàôÊ†πÊçÆÂΩìÂâçÁä∂ÊÄÅÁöÑÁΩÆ‰ø°Â∫¶ÔºåËá™ÈÄÇÂ∫îÂú∞Ë∞ÉÊï¥Êé©Á†ÅÂå∫ÂüüÁöÑÂ§ßÂ∞èÂíå‰ΩçÁΩÆ„ÄÇÂÖ∑‰ΩìÁöÑÂèÇÊï∞ËÆæÁΩÆÂíåÁΩëÁªúÁªìÊûÑÂèñÂÜ≥‰∫éÊâÄ‰ΩøÁî®ÁöÑÁ¶ªÊï£Êâ©Êï£Âü∫Á°ÄÊ®°Âûã„ÄÇÊçüÂ§±ÂáΩÊï∞ÈÄöÂ∏∏ÂåÖÊã¨ÈáçÊûÑÊçüÂ§±ÂíåÊ≠£ÂàôÂåñÈ°πÔºå‰ª•‰øùËØÅÊÅ¢Â§çÂõæÂÉèÁöÑË¥®ÈáèÂíå‰∏ÄËá¥ÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

APSÂú®ÂõæÂÉèÈÄÜÈóÆÈ¢ò‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåÂú®Ê†áÂáÜÂü∫ÂáÜÊµãËØï‰∏≠ËææÂà∞‰∫ÜSOTAÊ∞¥Âπ≥„ÄÇ‰∏éÁé∞ÊúâÁ¶ªÊï£Êâ©Êï£ÈááÊ†∑Âô®Áõ∏ÊØîÔºåAPSÂú®ÊÅ¢Â§çÂõæÂÉèÁöÑË¥®ÈáèÂíåÊïàÁéáÊñπÈù¢ÂùáÊúâÊòéÊòæ‰ºòÂäø„ÄÇÊ≠§Â§ñÔºåAPSÂú®ÂÖçËÆ≠ÁªÉÈ£éÊ†ºÂåñÂíåÊñáÊú¨ÂºïÂØºÁºñËæëÁ≠â‰ªªÂä°‰∏≠‰πüÂ±ïÁé∞‰∫ÜËâØÂ•ΩÁöÑÊïàÊûú„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂπøÊ≥õÂ∫îÁî®‰∫éÂõæÂÉè‰øÆÂ§ç„ÄÅÂõæÂÉèÂéªÂô™„ÄÅÂõæÂÉèË∂ÖÂàÜËæ®ÁéáÁ≠âÂõæÂÉèÈÄÜÈóÆÈ¢òÔºå‰ª•ÂèäÈ£éÊ†ºËøÅÁßª„ÄÅÂõæÂÉèÁºñËæëÁ≠âÁîüÊàê‰ªªÂä°„ÄÇÂÖ∂ÂÖçËÆ≠ÁªÉÁöÑÁâπÊÄß‰ΩøÂÖ∂Âú®ËµÑÊ∫êÂèóÈôêÁöÑÂú∫ÊôØ‰∏ãÂÖ∑ÊúâÈáçË¶Å‰ª∑ÂÄº„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïÊúâÊúõÊâ©Â±ïÂà∞ÂÖ∂‰ªñÁ¶ªÊï£Êï∞ÊçÆÈ¢ÜÂüüÔºåÂ¶ÇÊñáÊú¨ÁîüÊàê„ÄÅËØ≠Èü≥ÂêàÊàêÁ≠â„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> We study the problem of posterior sampling using pretrained discrete diffusion foundation models, aiming to recover images from noisy measurements without retraining task-specific models. While diffusion models have achieved remarkable success in generative modeling, most advances rely on continuous Gaussian diffusion. In contrast, discrete diffusion offers a unified framework for jointly modeling categorical data such as text and images. Beyond unification, discrete diffusion provides faster inference, finer control, and principled training-free Bayesian inference, making it particularly well-suited for posterior sampling. However, existing approaches to discrete diffusion posterior sampling face severe challenges: derivative-free guidance yields sparse signals, continuous relaxations limit applicability, and split Gibbs samplers suffer from the curse of dimensionality. To overcome these limitations, we introduce Anchored Posterior Sampling (APS) for masked diffusion foundation models, built on two key innovations -- quantized expectation for gradient-like guidance in discrete embedding space, and anchored remasking for adaptive decoding. Our approach achieves state-of-the-art performance among discrete diffusion samplers across linear and nonlinear inverse problems on the standard benchmarks. We further demonstrate the benefits of our approach in training-free stylization and text-guided editing.

