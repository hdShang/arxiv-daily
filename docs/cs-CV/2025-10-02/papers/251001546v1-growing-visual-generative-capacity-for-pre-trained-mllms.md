---
layout: default
title: Growing Visual Generative Capacity for Pre-Trained MLLMs
---

# Growing Visual Generative Capacity for Pre-Trained MLLMs

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.01546" target="_blank" class="toolbar-btn">arXiv: 2510.01546v1</a>
    <a href="https://arxiv.org/pdf/2510.01546.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.01546v1" 
            onclick="toggleFavorite(this, '2510.01546v1', 'Growing Visual Generative Capacity for Pre-Trained MLLMs')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Hanyu Wang, Jiaming Han, Ziyan Yang, Qi Zhao, Shanchuan Lin, Xiangyu Yue, Abhinav Shrivastava, Zhenheng Yang, Hao Chen

**ÂàÜÁ±ª**: cs.CV, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-02

**Â§áÊ≥®**: Project page: https://hywang66.github.io/bridge/

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫BridgeÔºö‰∏ÄÁßçÂü∫‰∫éÊ∑∑ÂêàTransformerÊû∂ÊûÑÁöÑÁ∫ØËá™ÂõûÂΩíÁªü‰∏ÄÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºåÊèêÂçáËßÜËßâÁîüÊàêËÉΩÂäõ„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã` `Ëá™ÂõûÂΩíÊ®°Âûã` `ÂõæÂÉèÁîüÊàê` `ËßÜËßâÁêÜËß£` `Ê∑∑ÂêàTransformer` `ËØ≠‰πâÂà∞ÂÉèÁ¥†` `next-tokenÈ¢ÑÊµã`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâMLLMÂú®ËßÜËßâÁîüÊàêÊñπÈù¢Â≠òÂú®ÊåëÊàòÔºåÊ∑∑ÂêàÊñπÊ≥ïÊâìÁ†¥Ëá™ÂõûÂΩíËåÉÂºèÔºåÁ∫ØËá™ÂõûÂΩíÊñπÊ≥ïÂàôÂú®ËØ≠‰πâÂØπÈΩêÂíåÂÉèÁ¥†‰øùÁúüÂ∫¶Èó¥ÊùÉË°°„ÄÇ
2. BridgeÈÄöËøáÊ∑∑ÂêàTransformerÊû∂ÊûÑÔºåÂú®Á∫ØËá™ÂõûÂΩíÊ°ÜÊû∂‰∏ãÔºåÂ¢ûÂº∫È¢ÑËÆ≠ÁªÉËßÜËßâÁêÜËß£Ê®°ÂûãÁöÑÁîüÊàêËÉΩÂäõÔºåÂÆûÁé∞Áªü‰∏ÄÁöÑÂõæÂÉèÁêÜËß£ÂíåÁîüÊàê„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåBridgeÂú®ÁêÜËß£ÂíåÁîüÊàê‰ªªÂä°‰∏äË°®Áé∞‰ºòÂºÇÔºå‰∏îËÆ≠ÁªÉÊâÄÈúÄÊï∞ÊçÆÊõ¥Â∞ëÔºåÊó∂Èó¥Êõ¥Áü≠ÔºåÊòæËëóÊèêÂçá‰∫ÜÊïàÁéá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã(MLLM)Â∞ÜËØ≠Ë®ÄÊ®°ÂûãÁöÑÊàêÂäüÊâ©Â±ïÂà∞ËßÜËßâÁêÜËß£È¢ÜÂüü„ÄÇÁõÆÂâçÁöÑÁ†îÁ©∂Ëá¥Âäõ‰∫éÊûÑÂª∫Áªü‰∏ÄÁöÑMLLMÔºå‰ª•ÊîØÊåÅÁêÜËß£ÂíåÁîüÊàê„ÄÇÁÑ∂ËÄåÔºåÊûÑÂª∫Ê≠§Á±ªÊ®°Âûã‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊàòÊÄßÔºöÊ∑∑ÂêàÊñπÊ≥ïÂ∞ÜËøûÁª≠ÂµåÂÖ•‰∏éÊâ©Êï£ÊàñÂü∫‰∫éÊµÅÁöÑÁõÆÊ†áÁõ∏ÁªìÂêàÔºå‰∫ßÁîüÈ´òË¥®ÈáèÁöÑÂõæÂÉèÔºå‰ΩÜÊâìÁ†¥‰∫ÜËá™ÂõûÂΩíËåÉÂºèÔºõËÄåÁ∫ØËá™ÂõûÂΩíÊñπÊ≥ïÁªü‰∏Ä‰∫ÜÊñáÊú¨ÂíåÂõæÂÉèÈ¢ÑÊµãÔºåÈÄöËøáÁ¶ªÊï£ËßÜËßâtokensÔºå‰ΩÜÈÄöÂ∏∏Èù¢‰∏¥ËØ≠‰πâÂØπÈΩêÂíåÂÉèÁ¥†Á∫ß‰øùÁúüÂ∫¶‰πãÈó¥ÁöÑÊùÉË°°„ÄÇÊú¨ÊñáÊèêÂá∫BridgeÔºå‰∏ÄÁßçÁ∫ØËá™ÂõûÂΩíÁªü‰∏ÄMLLMÔºåÈÄöËøáÊ∑∑ÂêàTransformerÊû∂ÊûÑÂ¢ûÂº∫È¢ÑËÆ≠ÁªÉËßÜËßâÁêÜËß£Ê®°ÂûãÁöÑÁîüÊàêËÉΩÂäõÔºå‰ªéËÄåÂú®Âçï‰∏™next-tokenÈ¢ÑÊµãÊ°ÜÊû∂ÂÜÖÂÆûÁé∞ÂõæÂÉèÁêÜËß£ÂíåÁîüÊàê„ÄÇ‰∏∫‰∫ÜËøõ‰∏ÄÊ≠•ÊèêÈ´òËßÜËßâÁîüÊàê‰øùÁúüÂ∫¶ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçËØ≠‰πâÂà∞ÂÉèÁ¥†ÁöÑÁ¶ªÊï£Ë°®Á§∫ÔºåËØ•Ë°®Á§∫Â∞ÜÁ¥ßÂáëÁöÑËØ≠‰πâtokens‰∏éÁªÜÁ≤íÂ∫¶ÁöÑÂÉèÁ¥†tokensÈõÜÊàêÂú®‰∏ÄËµ∑Ôºå‰ªÖ‰ª•7.9%ÁöÑÂ∫èÂàóÈïøÂ∫¶Â¢ûÂä†ÂÆûÁé∞‰∫ÜÂº∫Â§ßÁöÑËØ≠Ë®ÄÂØπÈΩêÂíåËßÜËßâÁªÜËäÇÁöÑÁ≤æÁ°ÆÊèèËø∞„ÄÇÂú®ÂêÑÁßçÂ§öÊ®°ÊÄÅÂü∫ÂáÜ‰∏äÁöÑÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºå‰∏é‰πãÂâçÁöÑÁªü‰∏ÄMLLMÁõ∏ÊØîÔºåBridgeÂú®ÁêÜËß£ÂíåÁîüÊàêÂü∫ÂáÜ‰∏äÈÉΩÂèñÂæó‰∫ÜÊúâÁ´û‰∫âÂäõÁöÑÊàñÊõ¥‰ºòË∂äÁöÑÁªìÊûúÔºåÂêåÊó∂ÈúÄË¶ÅÊõ¥Â∞ëÁöÑËÆ≠ÁªÉÊï∞ÊçÆÂíåÊõ¥Áü≠ÁöÑËÆ≠ÁªÉÊó∂Èó¥„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâMLLMÊ®°ÂûãÂú®Áªü‰∏ÄÁêÜËß£ÂíåÁîüÊàêËÉΩÂäõÊñπÈù¢Èù¢‰∏¥ÊåëÊàò„ÄÇÊ∑∑ÂêàÊñπÊ≥ïËôΩÁÑ∂ËÉΩÁîüÊàêÈ´òË¥®ÈáèÂõæÂÉèÔºå‰ΩÜÁ†¥Âùè‰∫ÜËá™ÂõûÂΩíÁâπÊÄß„ÄÇÁ∫ØËá™ÂõûÂΩíÊñπÊ≥ïËôΩÁÑ∂Áªü‰∏Ä‰∫ÜÊñáÊú¨ÂíåÂõæÂÉèÈ¢ÑÊµãÔºå‰ΩÜÂú®ËØ≠‰πâÂØπÈΩêÂíåÂÉèÁ¥†Á∫ß‰øùÁúüÂ∫¶‰πãÈó¥Â≠òÂú®trade-off„ÄÇÂõ†Ê≠§ÔºåÂ¶Ç‰ΩïÊûÑÂª∫‰∏Ä‰∏™Êó¢ËÉΩÁêÜËß£ÂèàËÉΩÁîüÊàêÔºå‰∏î‰øùÊåÅËá™ÂõûÂΩíÁâπÊÄßÁöÑMLLMÊòØ‰∏Ä‰∏™ÂÖ≥ÈîÆÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöBridgeÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÊ∑∑ÂêàTransformerÊû∂ÊûÑÔºåÂ∞ÜÈ¢ÑËÆ≠ÁªÉÁöÑËßÜËßâÁêÜËß£Ê®°Âûã‰∏éÁîüÊàêËÉΩÂäõÁõ∏ÁªìÂêàÔºå‰ªéËÄåÂú®Á∫ØËá™ÂõûÂΩíÊ°ÜÊû∂‰∏ãÂÆûÁé∞ÂõæÂÉèÁêÜËß£ÂíåÁîüÊàê„ÄÇÈÄöËøánext-tokenÈ¢ÑÊµãÁöÑÊñπÂºèÔºåÁªü‰∏ÄÂ§ÑÁêÜÊñáÊú¨ÂíåÂõæÂÉèÔºåÈÅøÂÖç‰∫ÜÊ∑∑ÂêàÊñπÊ≥ïÂ∏¶Êù•ÁöÑËá™ÂõûÂΩíÈóÆÈ¢òÔºåÂêåÊó∂ÈÄöËøáËØ≠‰πâÂà∞ÂÉèÁ¥†ÁöÑÁ¶ªÊï£Ë°®Á§∫ÔºåÊèêÂçáÁîüÊàêÂõæÂÉèÁöÑ‰øùÁúüÂ∫¶„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöBridgeÁöÑÊï¥‰ΩìÊû∂ÊûÑÊòØ‰∏Ä‰∏™Âü∫‰∫éTransformerÁöÑËá™ÂõûÂΩíÊ®°Âûã„ÄÇÂÆÉÂåÖÂê´‰ª•‰∏ã‰∏ªË¶ÅÊ®°ÂùóÔºö1) È¢ÑËÆ≠ÁªÉÁöÑËßÜËßâÁêÜËß£Ê®°ÂûãÔºåÁî®‰∫éÊèêÂèñÂõæÂÉèÁöÑËØ≠‰πâÁâπÂæÅÔºõ2) Ê∑∑ÂêàTransformerÊ®°ÂùóÔºåÁî®‰∫éËûçÂêàËßÜËßâÁâπÂæÅÂíåÊñáÊú¨‰ø°ÊÅØÔºåÂπ∂ËøõË°ånext-tokenÈ¢ÑÊµãÔºõ3) ËØ≠‰πâÂà∞ÂÉèÁ¥†ÁöÑÁ¶ªÊï£Ë°®Á§∫Ê®°ÂùóÔºåÁî®‰∫éÂ∞ÜËØ≠‰πâtokensËΩ¨Êç¢‰∏∫ÁªÜÁ≤íÂ∫¶ÁöÑÂÉèÁ¥†tokensÔºå‰ªéËÄåÊèêÈ´òÁîüÊàêÂõæÂÉèÁöÑ‰øùÁúüÂ∫¶„ÄÇÊï¥‰∏™ÊµÅÁ®ãÊòØÔºöËæìÂÖ•ÊñáÊú¨ÂíåÂõæÂÉèÔºåËßÜËßâÁêÜËß£Ê®°ÂûãÊèêÂèñÂõæÂÉèÁâπÂæÅÔºåÊ∑∑ÂêàTransformerËûçÂêàÁâπÂæÅÂπ∂È¢ÑÊµã‰∏ã‰∏Ä‰∏™tokenÔºåËØ≠‰πâÂà∞ÂÉèÁ¥†Ê®°ÂùóÂ∞ÜËØ≠‰πâtokenËΩ¨Êç¢‰∏∫ÂÉèÁ¥†tokenÔºåÊúÄÁªàÁîüÊàêÂõæÂÉè„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöBridgeÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫é‰ª•‰∏ã‰∏§ÁÇπÔºö1) Ê∑∑ÂêàTransformerÊû∂ÊûÑÔºåÂÆÉÂÖÅËÆ∏Ê®°ÂûãÂú®Á∫ØËá™ÂõûÂΩíÊ°ÜÊû∂‰∏ãÂêåÊó∂ËøõË°åÁêÜËß£ÂíåÁîüÊàêÔºõ2) ËØ≠‰πâÂà∞ÂÉèÁ¥†ÁöÑÁ¶ªÊï£Ë°®Á§∫ÔºåÂÆÉÈÄöËøáÂ∞ÜÁ¥ßÂáëÁöÑËØ≠‰πâtokens‰∏éÁªÜÁ≤íÂ∫¶ÁöÑÂÉèÁ¥†tokensÁõ∏ÁªìÂêàÔºåÂÆûÁé∞‰∫ÜÂº∫Â§ßÁöÑËØ≠Ë®ÄÂØπÈΩêÂíåËßÜËßâÁªÜËäÇÁöÑÁ≤æÁ°ÆÊèèËø∞„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁöÑÊú¨Ë¥®Âå∫Âà´Âú®‰∫éÔºåBridgeÈÅøÂÖç‰∫ÜÊ∑∑ÂêàÊñπÊ≥ïÂ∏¶Êù•ÁöÑËá™ÂõûÂΩíÈóÆÈ¢òÔºåÂêåÊó∂ÊèêÂçá‰∫ÜÁîüÊàêÂõæÂÉèÁöÑ‰øùÁúüÂ∫¶„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöBridgeÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) Ê∑∑ÂêàTransformerÊ®°ÂùóÁöÑÂÖ∑‰ΩìÁªìÊûÑÔºå‰æãÂ¶ÇTransformerÂ±ÇÊï∞„ÄÅÊ≥®ÊÑèÂäõÊú∫Âà∂ÁöÑÈÄâÊã©Á≠âÔºõ2) ËØ≠‰πâÂà∞ÂÉèÁ¥†ÁöÑÁ¶ªÊï£Ë°®Á§∫ÁöÑÂÖ∑‰ΩìÂÆûÁé∞ÊñπÂºèÔºå‰æãÂ¶ÇËØ≠‰πâtokenÂíåÂÉèÁ¥†tokenÁöÑÊï∞Èáè„ÄÅÁºñÁ†ÅÊñπÂºèÁ≠âÔºõ3) ËÆ≠ÁªÉÁõÆÊ†áÂáΩÊï∞ÁöÑËÆæËÆ°Ôºå‰æãÂ¶ÇÂ¶Ç‰ΩïÂπ≥Ë°°ÁêÜËß£ÂíåÁîüÊàê‰ªªÂä°ÁöÑÊçüÂ§±ÔºåÂ¶Ç‰Ωï‰ºòÂåñËØ≠‰πâÂà∞ÂÉèÁ¥†ÁöÑËΩ¨Êç¢ËøáÁ®ãÁ≠â„ÄÇËÆ∫Êñá‰∏≠ÂèØËÉΩËøòÊ∂âÂèä‰∏Ä‰∫õË∂ÖÂèÇÊï∞ÁöÑËÆæÁΩÆÔºå‰æãÂ¶ÇÂ≠¶‰π†Áéá„ÄÅbatch sizeÁ≠â„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåBridgeÂú®Â§ö‰∏™Â§öÊ®°ÊÄÅÂü∫ÂáÜÊµãËØï‰∏≠ÂèñÂæó‰∫Ü‰ºòÂºÇÁöÑÊàêÁª©ÔºåÂåÖÊã¨ÂõæÂÉèÊèèËø∞„ÄÅËßÜËßâÈóÆÁ≠îÂíåÂõæÂÉèÁîüÊàêÁ≠â‰ªªÂä°„ÄÇ‰∏é‰πãÂâçÁöÑÁªü‰∏ÄMLLMÁõ∏ÊØîÔºåBridgeÂú®ÁêÜËß£ÂíåÁîüÊàêÂü∫ÂáÜ‰∏äÈÉΩÂèñÂæó‰∫ÜÊúâÁ´û‰∫âÂäõÁöÑÊàñÊõ¥‰ºòË∂äÁöÑÁªìÊûúÔºåÂêåÊó∂ÈúÄË¶ÅÊõ¥Â∞ëÁöÑËÆ≠ÁªÉÊï∞ÊçÆÂíåÊõ¥Áü≠ÁöÑËÆ≠ÁªÉÊó∂Èó¥„ÄÇ‰æãÂ¶ÇÔºåÂú®ÂõæÂÉèÁîüÊàê‰ªªÂä°‰∏äÔºåBridgeÁîüÊàêÁöÑÂõæÂÉèË¥®ÈáèÊòéÊòæ‰ºò‰∫éÂÖ∂‰ªñËá™ÂõûÂΩíÊ®°ÂûãÔºåÂπ∂‰∏îÂú®ËØ≠‰πâÂØπÈΩêÊñπÈù¢‰πüË°®Áé∞Âá∫Ëâ≤„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

BridgeÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºå‰æãÂ¶ÇÂõæÂÉèÁºñËæë„ÄÅÂõæÂÉèÁîüÊàê„ÄÅËßÜËßâÂØπËØù„ÄÅÊú∫Âô®‰∫∫ÊéßÂà∂Á≠â„ÄÇÂÆÉÂèØ‰ª•Áî®‰∫éÂàõÂª∫Êõ¥ÈÄºÁúü„ÄÅÊõ¥ÂèØÊéßÁöÑËôöÊãü‰∏ñÁïåÔºå‰πüÂèØ‰ª•Áî®‰∫éËæÖÂä©‰∫∫Á±ªËøõË°åËÆæËÆ°ÂíåÂàõ‰Ωú„ÄÇÊ≠§Â§ñÔºåBridgeËøòÂèØ‰ª•Â∫îÁî®‰∫éÊô∫ËÉΩÂÆ¢Êúç„ÄÅËá™Âä®È©æÈ©∂Á≠âÈ¢ÜÂüüÔºåÊèêÂçá‰∫∫Êú∫‰∫§‰∫íÁöÑÊïàÁéáÂíåË¥®Èáè„ÄÇÊú™Êù•ÔºåBridgeÊúâÊúõÊàê‰∏∫Â§öÊ®°ÊÄÅ‰∫∫Â∑•Êô∫ËÉΩÈ¢ÜÂüüÁöÑÈáçË¶ÅÂü∫Áü≥„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Multimodal large language models (MLLMs) extend the success of language models to visual understanding, and recent efforts have sought to build unified MLLMs that support both understanding and generation. However, constructing such models remains challenging: hybrid approaches combine continuous embeddings with diffusion or flow-based objectives, producing high-quality images but breaking the autoregressive paradigm, while pure autoregressive approaches unify text and image prediction over discrete visual tokens but often face trade-offs between semantic alignment and pixel-level fidelity. In this work, we present Bridge, a pure autoregressive unified MLLM that augments pre-trained visual understanding models with generative ability through a Mixture-of-Transformers architecture, enabling both image understanding and generation within a single next-token prediction framework. To further improve visual generation fidelity, we propose a semantic-to-pixel discrete representation that integrates compact semantic tokens with fine-grained pixel tokens, achieving strong language alignment and precise description of visual details with only a 7.9% increase in sequence length. Extensive experiments across diverse multimodal benchmarks demonstrate that Bridge achieves competitive or superior results in both understanding and generation benchmarks, while requiring less training data and reduced training time compared to prior unified MLLMs.

