---
layout: default
title: RefBench-PRO: Perceptual and Reasoning Oriented Benchmark for Referring Expression Comprehension
---

# RefBench-PRO: Perceptual and Reasoning Oriented Benchmark for Referring Expression Comprehension

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.06276" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.06276v2</a>
  <a href="https://arxiv.org/pdf/2512.06276.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.06276v2" onclick="toggleFavorite(this, '2512.06276v2', 'RefBench-PRO: Perceptual and Reasoning Oriented Benchmark for Referring Expression Comprehension')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Tianyi Gao, Hao Li, Han Fang, Xin Wei, Xiaodong Dong, Hongbo Sun, Ye Yuan, Zhongjiang He, Jinglin Xu, Jingmin Xin, Hao Sun

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-06 (æ›´æ–°: 2025-12-13)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRefBench-PROåŸºå‡†ï¼Œç”¨äºè¯„ä¼°å¤šæ¨¡æ€å¤§æ¨¡å‹åœ¨æŒ‡ä»£è¡¨è¾¾ç†è§£ä¸­çš„æ„ŸçŸ¥å’Œæ¨ç†èƒ½åŠ›ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `æŒ‡ä»£è¡¨è¾¾ç†è§£` `å¤šæ¨¡æ€å­¦ä¹ ` `è§†è§‰è¯­è¨€` `åŸºå‡†æµ‹è¯•` `æ¨ç†èƒ½åŠ›` `æ„ŸçŸ¥èƒ½åŠ›` `å¼ºåŒ–å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰RECåŸºå‡†ä¾§é‡æ„ŸçŸ¥èƒ½åŠ›è¯„ä¼°ï¼Œç¼ºä¹å¯¹å¤šæ¨¡æ€å¤§æ¨¡å‹æ¨ç†èƒ½åŠ›çš„é’ˆå¯¹æ€§è¯„ä¼°å’Œå¯è§£é‡Šçš„è¯„åˆ†æœºåˆ¶ã€‚
2. RefBench-PROåŸºå‡†å°†æŒ‡ä»£è¡¨è¾¾ç†è§£åˆ†è§£ä¸ºæ„ŸçŸ¥å’Œæ¨ç†ä¸¤ä¸ªç»´åº¦ï¼Œå¹¶ç»†åˆ†ä¸ºå…­ä¸ªæ›´å…·æŒ‘æˆ˜æ€§çš„å­ä»»åŠ¡ã€‚
3. æå‡ºäº†Ref-R1å­¦ä¹ æ–¹æ¡ˆï¼Œé€šè¿‡ç»“åˆåŠ¨æ€IoUçš„GRPOï¼Œæå‡äº†åœ¨å¤æ‚æ¨ç†æ¡ä»¶ä¸‹çš„å®šä½ç²¾åº¦ï¼Œå¹¶å»ºç«‹äº†æ›´å¼ºçš„åŸºçº¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æŒ‡ä»£è¡¨è¾¾ç†è§£ï¼ˆRECï¼‰æ˜¯ä¸€é¡¹è§†è§‰-è¯­è¨€ä»»åŠ¡ï¼Œæ—¨åœ¨æ ¹æ®æ–‡æœ¬æè¿°å®šä½ç‰¹å®šçš„å›¾åƒåŒºåŸŸã€‚ç°æœ‰çš„RECåŸºå‡†ä¸»è¦è¯„ä¼°æ„ŸçŸ¥èƒ½åŠ›ï¼Œç¼ºä¹å¯è§£é‡Šçš„è¯„åˆ†æœºåˆ¶ï¼Œæ— æ³•æ­ç¤ºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰åœ¨ä¸åŒè®¤çŸ¥èƒ½åŠ›ä¸Šçš„åŸºç¡€èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†RefBench-PROï¼Œè¿™æ˜¯ä¸€ä¸ªå…¨é¢çš„RECåŸºå‡†ï¼Œå®ƒå°†æŒ‡ä»£è¡¨è¾¾åˆ†è§£ä¸ºä¸¤ä¸ªæ ¸å¿ƒç»´åº¦ï¼Œå³æ„ŸçŸ¥å’Œæ¨ç†ï¼Œå¹¶è¿›ä¸€æ­¥ç»†åˆ†ä¸ºå…­ä¸ªæ¸è¿›å¼æŒ‘æˆ˜ä»»åŠ¡ï¼Œå¦‚å±æ€§ã€ä½ç½®ã€äº¤äº’ã€å¸¸è¯†ã€å…³ç³»å’Œæ‹’ç»ã€‚æˆ‘ä»¬è¿˜å¼€å‘äº†ä¸€ä¸ªå…¨è‡ªåŠ¨çš„æ•°æ®ç”Ÿæˆç®¡é“ï¼Œç”¨äºç”Ÿæˆè·¨è¿™å…­ä¸ªå­ç»´åº¦çš„å¤šæ ·åŒ–æŒ‡ä»£è¡¨è¾¾ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†Ref-R1ï¼Œä¸€ç§åŸºäºRLçš„å­¦ä¹ æ–¹æ¡ˆï¼Œå®ƒç»“åˆäº†åŸºäºåŠ¨æ€IoUçš„GRPOï¼Œä»¥æé«˜åœ¨æ—¥ç›Šå¤æ‚çš„æ¨ç†æ¡ä»¶ä¸‹çš„å®šä½ç²¾åº¦ï¼Œä¸ºRECå»ºç«‹æ›´å¼ºçš„åŸºçº¿ã€‚å¤§é‡çš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„RefBench-PROèƒ½å¤Ÿå¯¹MLLMåœ¨æŒ‡ä»£è¡¨è¾¾ç†è§£æ–¹é¢è¿›è¡Œå¯è§£é‡Šçš„è¯„ä¼°ï¼Œåœ¨æ„ŸçŸ¥å’Œæ¨ç†æ–¹é¢éƒ½æå‡ºäº†æ›´å¤§çš„æŒ‘æˆ˜ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰æŒ‡ä»£è¡¨è¾¾ç†è§£ï¼ˆRECï¼‰åŸºå‡†çš„ä¸è¶³ï¼Œå³ä¸»è¦ä¾§é‡äºæ„ŸçŸ¥èƒ½åŠ›çš„è¯„ä¼°ï¼Œè€Œå¿½ç•¥äº†å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰çš„æ¨ç†èƒ½åŠ›ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥å¯¹MLLMåœ¨ä¸åŒè®¤çŸ¥èƒ½åŠ›ä¸Šçš„åŸºç¡€èƒ½åŠ›è¿›è¡Œæœ‰æ•ˆè¯„ä¼°ï¼Œç¼ºä¹å¯è§£é‡Šçš„è¯„åˆ†æœºåˆ¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†æŒ‡ä»£è¡¨è¾¾ç†è§£ä»»åŠ¡åˆ†è§£ä¸ºæ„ŸçŸ¥å’Œæ¨ç†ä¸¤ä¸ªæ ¸å¿ƒç»´åº¦ï¼Œå¹¶è¿›ä¸€æ­¥ç»†åˆ†ä¸ºå…­ä¸ªå…·æœ‰é€’è¿›éš¾åº¦çš„å­ä»»åŠ¡ã€‚é€šè¿‡è¿™ç§åˆ†è§£ï¼Œå¯ä»¥æ›´ç²¾ç»†åœ°è¯„ä¼°MLLMåœ¨ä¸åŒè®¤çŸ¥èƒ½åŠ›ä¸Šçš„è¡¨ç°ï¼Œå¹¶æä¾›æ›´å…·è§£é‡Šæ€§çš„è¯„ä¼°ç»“æœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRefBench-PROåŸºå‡†åŒ…å«ä¸€ä¸ªå…¨è‡ªåŠ¨çš„æ•°æ®ç”Ÿæˆç®¡é“ï¼Œç”¨äºç”Ÿæˆå¤šæ ·åŒ–çš„æŒ‡ä»£è¡¨è¾¾ï¼Œæ¶µç›–å±æ€§ã€ä½ç½®ã€äº¤äº’ã€å¸¸è¯†ã€å…³ç³»å’Œæ‹’ç»å…­ä¸ªå­ç»´åº¦ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æå‡ºäº†Ref-R1å­¦ä¹ æ–¹æ¡ˆï¼Œè¯¥æ–¹æ¡ˆåŸºäºå¼ºåŒ–å­¦ä¹ ï¼Œå¹¶ç»“åˆäº†åŠ¨æ€IoUçš„GRPOï¼ˆæœªçŸ¥å…·ä½“å«ä¹‰ï¼‰ï¼Œä»¥æé«˜åœ¨å¤æ‚æ¨ç†æ¡ä»¶ä¸‹çš„å®šä½ç²¾åº¦ã€‚æ•´ä½“æµç¨‹åŒ…æ‹¬æ•°æ®ç”Ÿæˆã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†RefBench-PROåŸºå‡†ï¼Œè¯¥åŸºå‡†èƒ½å¤Ÿå¯¹MLLMåœ¨æŒ‡ä»£è¡¨è¾¾ç†è§£ä¸­çš„æ„ŸçŸ¥å’Œæ¨ç†èƒ½åŠ›è¿›è¡Œæ›´å…¨é¢ã€æ›´ç²¾ç»†çš„è¯„ä¼°ã€‚ä¸ç°æœ‰åŸºå‡†ç›¸æ¯”ï¼ŒRefBench-PROæ›´æ³¨é‡æ¨ç†èƒ½åŠ›çš„è¯„ä¼°ï¼Œå¹¶æä¾›äº†æ›´å…·è§£é‡Šæ€§çš„è¯„ä¼°ç»“æœã€‚æ­¤å¤–ï¼ŒRef-R1å­¦ä¹ æ–¹æ¡ˆçš„å¼•å…¥ä¹Ÿä¸ºRECä»»åŠ¡æä¾›äº†ä¸€ç§æ–°çš„è§£å†³æ€è·¯ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³äºæ•°æ®ç”Ÿæˆç®¡é“çš„å…·ä½“å®ç°ç»†èŠ‚ã€åŠ¨æ€IoU-based GRPOçš„å…·ä½“ç®—æ³•ç»†èŠ‚ã€å¼ºåŒ–å­¦ä¹ çš„å¥–åŠ±å‡½æ•°è®¾è®¡ã€ä»¥åŠç½‘ç»œç»“æ„çš„å…·ä½“å‚æ•°è®¾ç½®ç­‰æŠ€æœ¯ç»†èŠ‚ï¼Œè®ºæ–‡æ‘˜è¦ä¸­æœªæä¾›è¯¦ç»†ä¿¡æ¯ï¼Œå› æ­¤æ— æ³•è¿›è¡Œæ·±å…¥æè¿°ã€‚è¿™äº›ç»†èŠ‚å¯èƒ½åœ¨è®ºæ–‡æ­£æ–‡ä¸­æœ‰æ‰€é˜è¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒRefBench-PROåŸºå‡†èƒ½å¤Ÿæœ‰æ•ˆè¯„ä¼°MLLMåœ¨æŒ‡ä»£è¡¨è¾¾ç†è§£ä¸­çš„æ„ŸçŸ¥å’Œæ¨ç†èƒ½åŠ›ï¼Œå¹¶å¯¹ç°æœ‰æ¨¡å‹æå‡ºäº†æ›´å¤§çš„æŒ‘æˆ˜ã€‚Ref-R1å­¦ä¹ æ–¹æ¡ˆåœ¨å¤æ‚æ¨ç†æ¡ä»¶ä¸‹æ˜¾è‘—æé«˜äº†å®šä½ç²¾åº¦ï¼Œä¸ºRECä»»åŠ¡å»ºç«‹äº†ä¸€ä¸ªæ›´å¼ºçš„åŸºçº¿ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦éœ€è¦åœ¨è®ºæ–‡æ­£æ–‡ä¸­æŸ¥æ‰¾ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ™ºèƒ½æœºå™¨äººã€è‡ªåŠ¨é©¾é©¶ã€å›¾åƒæœç´¢ç­‰é¢†åŸŸã€‚é€šè¿‡æå‡å¤šæ¨¡æ€å¤§æ¨¡å‹åœ¨æŒ‡ä»£è¡¨è¾¾ç†è§£æ–¹é¢çš„èƒ½åŠ›ï¼Œå¯ä»¥ä½¿æœºå™¨æ›´å¥½åœ°ç†è§£äººç±»æŒ‡ä»¤ï¼Œä»è€Œå®ç°æ›´æ™ºèƒ½çš„äººæœºäº¤äº’å’Œæ›´ç²¾å‡†çš„ç›®æ ‡å®šä½ã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶æœ‰æœ›æ¨åŠ¨è§†è§‰-è¯­è¨€æ™ºèƒ½çš„å‘å±•ï¼Œå¹¶ä¸ºç›¸å…³åº”ç”¨å¸¦æ¥æ›´å¹¿é˜”çš„å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Referring Expression Comprehension (REC) is a vision-language task that localizes a specific image region based on a textual description. Existing REC benchmarks primarily evaluate perceptual capabilities and lack interpretable scoring mechanisms, which cannot reveal the grounding capability of Multi-modal Large Language Model (MLLM) across different cognitive abilities. To address this limitation, we introduce RefBench-PRO, a comprehensive REC benchmark, which decomposes referring expressions into two core dimensions, i.e., perception and reasoning, and further subdivides them into six progressively challenging tasks, such as attribute, position, interaction, commonsense, relation and reject. We also develop a fully automated data-generation pipeline that produces diverse referring expressions across these six sub-dimensions. Furthermore, We propose Ref-R1, an RL-based learning scheme, which incorporates Dynamic IoU-based GRPO to improve localization accuracy under increasingly complex reasoning conditions, establishing a stronger baseline for REC. Extensive experiments demonstrate that our RefBench-PRO enables interpretable evaluation of MLLM on referring expression comprehension, presenting greater challenges in both perception and reasoning.

