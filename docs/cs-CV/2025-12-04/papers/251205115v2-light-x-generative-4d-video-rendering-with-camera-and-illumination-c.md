---
layout: default
title: Light-X: Generative 4D Video Rendering with Camera and Illumination Control
---

# Light-X: Generative 4D Video Rendering with Camera and Illumination Control

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.05115" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.05115v2</a>
  <a href="https://arxiv.org/pdf/2512.05115.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.05115v2" onclick="toggleFavorite(this, '2512.05115v2', 'Light-X: Generative 4D Video Rendering with Camera and Illumination Control')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Tianqi Liu, Zhaoxi Chen, Zihao Huang, Shaocong Xu, Saining Zhang, Chongjie Ye, Bohan Li, Zhiguo Cao, Wei Li, Hao Zhao, Ziwei Liu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-04 (æ›´æ–°: 2025-12-15)

**å¤‡æ³¨**: Project Page: https://lightx-ai.github.io/ , Code: https://github.com/TQTQliu/Light-X

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Light-Xï¼šæå‡ºå¯æ§ç›¸æœºä¸å…‰ç…§çš„ç”Ÿæˆå¼4Dè§†é¢‘æ¸²æŸ“æ¡†æ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `è§†é¢‘ç”Ÿæˆ` `å…‰ç…§æ§åˆ¶` `è§†è§’æ§åˆ¶` `åŠ¨æ€ç‚¹äº‘` `è§£è€¦è¡¨ç¤º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å…‰ç…§æ§åˆ¶æ–¹æ³•åœ¨è§†é¢‘é¢†åŸŸé¢ä¸´å…‰ç…§ä¿çœŸåº¦å’Œæ—¶é—´ä¸€è‡´æ€§ä¹‹é—´çš„æƒè¡¡ã€‚
2. Light-Xé€šè¿‡è§£è€¦å‡ ä½•ä¸å…‰ç…§ä¿¡å·ï¼Œå¹¶åˆ©ç”¨åŠ¨æ€ç‚¹äº‘å’Œé‡ç…§æ˜å¸§å®ç°è§†è§’å’Œå…‰ç…§çš„è”åˆæ§åˆ¶ã€‚
3. Light-Xåœ¨è”åˆç›¸æœº-å…‰ç…§æ§åˆ¶å’Œè§†é¢‘é‡ç…§æ˜ä»»åŠ¡ä¸Šï¼Œå‡è¶…è¶Šäº†ç°æœ‰æ–¹æ³•ï¼Œå±•ç°äº†ä¼˜è¶Šçš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºLight-Xï¼Œä¸€ä¸ªè§†é¢‘ç”Ÿæˆæ¡†æ¶ï¼Œèƒ½å¤Ÿä»å•ç›®è§†é¢‘ä¸­è¿›è¡Œå¯æ§æ¸²æŸ“ï¼ŒåŒæ—¶æ§åˆ¶è§†è§’å’Œå…‰ç…§ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸¤ä¸ªå…³é”®è®¾è®¡ï¼š1) è§£è€¦è®¾è®¡ï¼Œå°†å‡ ä½•å’Œå…‰ç…§ä¿¡å·åˆ†ç¦»ã€‚å‡ ä½•å’Œè¿åŠ¨é€šè¿‡æ²¿ç”¨æˆ·å®šä¹‰çš„ç›¸æœºè½¨è¿¹æŠ•å½±çš„åŠ¨æ€ç‚¹äº‘æ•è·ï¼Œè€Œå…‰ç…§çº¿ç´¢ç”±ä¸€è‡´åœ°æŠ•å½±åˆ°ç›¸åŒå‡ ä½•ä½“ä¸­çš„é‡ç…§æ˜å¸§æä¾›ã€‚è¿™äº›æ˜¾å¼çš„ã€ç»†ç²’åº¦çš„çº¿ç´¢èƒ½å¤Ÿå®ç°æœ‰æ•ˆçš„è§£è€¦å¹¶æŒ‡å¯¼é«˜è´¨é‡çš„å…‰ç…§ã€‚2) ä¸ºäº†è§£å†³ç¼ºä¹é…å¯¹çš„å¤šè§†è§’å’Œå¤šå…‰ç…§è§†é¢‘çš„é—®é¢˜ï¼Œå¼•å…¥Light-Synï¼Œä¸€ä¸ªåŸºäºé€€åŒ–çš„æµæ°´çº¿ï¼Œé€šè¿‡é€†æ˜ å°„ä»çœŸå®å•ç›®è§†é¢‘ä¸­åˆæˆè®­ç»ƒå¯¹ã€‚è¯¥ç­–ç•¥ç”Ÿæˆä¸€ä¸ªè¦†ç›–é™æ€ã€åŠ¨æ€å’ŒAIç”Ÿæˆåœºæ™¯çš„æ•°æ®é›†ï¼Œç¡®ä¿é²æ£’çš„è®­ç»ƒã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒLight-Xåœ¨è”åˆç›¸æœº-å…‰ç…§æ§åˆ¶æ–¹é¢ä¼˜äºåŸºçº¿æ–¹æ³•ï¼Œå¹¶ä¸”åœ¨æ–‡æœ¬å’ŒèƒŒæ™¯æ¡ä»¶è®¾ç½®ä¸‹è¶…è¿‡äº†å…ˆå‰çš„è§†é¢‘é‡ç…§æ˜æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰åŸºäºå›¾åƒçš„å…‰ç…§æ§åˆ¶æ–¹æ³•æ‰©å±•åˆ°è§†é¢‘é¢†åŸŸæ—¶ï¼Œéš¾ä»¥åŒæ—¶ä¿è¯å…‰ç…§çš„çœŸå®æ€§å’Œæ—¶é—´ä¸Šçš„ä¸€è‡´æ€§ã€‚æ›´è¿›ä¸€æ­¥ï¼ŒçœŸå®ä¸–ç•Œåœºæ™¯çš„ç”Ÿæˆå¼å»ºæ¨¡éœ€è¦è”åˆæ§åˆ¶ç›¸æœºè½¨è¿¹å’Œå…‰ç…§ï¼Œå› ä¸ºè§†è§‰åŠ¨æ€æœ¬è´¨ä¸Šæ˜¯ç”±å‡ ä½•å’Œå…‰ç…§å…±åŒå†³å®šçš„ã€‚å› æ­¤ï¼Œå¦‚ä½•ä»å•ç›®è§†é¢‘ä¸­å®ç°å¯æ§çš„è§†è§’å’Œå…‰ç…§çš„è§†é¢‘ç”Ÿæˆæ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šLight-Xçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†å‡ ä½•å’Œå…‰ç…§ä¿¡å·è§£è€¦ã€‚å…·ä½“æ¥è¯´ï¼Œä½¿ç”¨åŠ¨æ€ç‚¹äº‘æ¥è¡¨ç¤ºåœºæ™¯çš„å‡ ä½•å’Œè¿åŠ¨ä¿¡æ¯ï¼Œå¹¶é€šè¿‡ç”¨æˆ·å®šä¹‰çš„ç›¸æœºè½¨è¿¹è¿›è¡ŒæŠ•å½±ã€‚åŒæ—¶ï¼Œä½¿ç”¨é‡ç…§æ˜å¸§æ¥æä¾›å…‰ç…§çº¿ç´¢ï¼Œå¹¶å°†è¿™äº›çº¿ç´¢ä¸€è‡´åœ°æŠ•å½±åˆ°ç›¸åŒçš„å‡ ä½•ä½“ä¸Šã€‚è¿™ç§è§£è€¦çš„è®¾è®¡ä½¿å¾—å¯ä»¥ç‹¬ç«‹åœ°æ§åˆ¶è§†è§’å’Œå…‰ç…§ï¼Œä»è€Œå®ç°é«˜è´¨é‡çš„è§†é¢‘ç”Ÿæˆã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLight-Xçš„æ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) åŠ¨æ€ç‚¹äº‘ç”Ÿæˆæ¨¡å—ï¼Œç”¨äºä»å•ç›®è§†é¢‘ä¸­ä¼°è®¡åœºæ™¯çš„å‡ ä½•å’Œè¿åŠ¨ä¿¡æ¯ã€‚2) ç›¸æœºè½¨è¿¹æ§åˆ¶æ¨¡å—ï¼Œå…è®¸ç”¨æˆ·è‡ªå®šä¹‰ç›¸æœºè½¨è¿¹ã€‚3) é‡ç…§æ˜æ¨¡å—ï¼Œç”¨äºç”Ÿæˆå…·æœ‰ä¸åŒå…‰ç…§æ¡ä»¶çš„å¸§ã€‚4) æ¸²æŸ“æ¨¡å—ï¼Œå°†åŠ¨æ€ç‚¹äº‘å’Œé‡ç…§æ˜å¸§æ¸²æŸ“æˆæœ€ç»ˆçš„è§†é¢‘ã€‚ä¸ºäº†è§£å†³è®­ç»ƒæ•°æ®ä¸è¶³çš„é—®é¢˜ï¼Œè¿˜å¼•å…¥äº†Light-Synæ•°æ®åˆæˆæµæ°´çº¿ã€‚

**å…³é”®åˆ›æ–°**ï¼šLight-Xæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå…¶è§£è€¦çš„å‡ ä½•å’Œå…‰ç…§è¡¨ç¤ºï¼Œä»¥åŠLight-Synæ•°æ®åˆæˆæµæ°´çº¿ã€‚é€šè¿‡è§£è€¦å‡ ä½•å’Œå…‰ç…§ï¼Œå¯ä»¥å®ç°å¯¹è§†è§’å’Œå…‰ç…§çš„ç‹¬ç«‹æ§åˆ¶ï¼Œä»è€Œç”Ÿæˆæ›´é€¼çœŸã€æ›´å¯æ§çš„è§†é¢‘ã€‚Light-Syné€šè¿‡é€†æ˜ å°„ä»çœŸå®å•ç›®è§†é¢‘ä¸­åˆæˆè®­ç»ƒæ•°æ®ï¼Œè§£å†³äº†ç¼ºä¹é…å¯¹çš„å¤šè§†è§’å’Œå¤šå…‰ç…§è§†é¢‘çš„é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šLight-Xçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨åŠ¨æ€ç‚¹äº‘æ¥è¡¨ç¤ºåœºæ™¯çš„å‡ ä½•å’Œè¿åŠ¨ä¿¡æ¯ã€‚2) è®¾è®¡äº†ä¸“é—¨çš„ç½‘ç»œç»“æ„æ¥å¤„ç†åŠ¨æ€ç‚¹äº‘å’Œé‡ç…§æ˜å¸§ã€‚3) ä½¿ç”¨äº†å¤šç§æŸå¤±å‡½æ•°æ¥ä¿è¯ç”Ÿæˆè§†é¢‘çš„è´¨é‡ï¼ŒåŒ…æ‹¬å…‰åº¦ä¸€è‡´æ€§æŸå¤±ã€æ—¶é—´ä¸€è‡´æ€§æŸå¤±å’Œå¯¹æŠ—æŸå¤±ç­‰ã€‚Light-Synæ•°æ®åˆæˆæµæ°´çº¿é€šè¿‡å›¾åƒé€€åŒ–å’Œé€†æ˜ å°„ç”Ÿæˆè®­ç»ƒæ•°æ®ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLight-Xåœ¨è”åˆç›¸æœº-å…‰ç…§æ§åˆ¶æ–¹é¢æ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚åœ¨æ–‡æœ¬å’ŒèƒŒæ™¯æ¡ä»¶è®¾ç½®ä¸‹ï¼ŒLight-Xä¹Ÿè¶…è¿‡äº†å…ˆå‰çš„è§†é¢‘é‡ç…§æ˜æ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼ŒLight-Xåœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æå‡ï¼Œä¾‹å¦‚ï¼Œåœ¨FID (FrÃ©chet Inception Distance) æŒ‡æ ‡ä¸Šé™ä½äº†XX%ï¼Œåœ¨LPIPS (Learned Perceptual Image Patch Similarity) æŒ‡æ ‡ä¸Šé™ä½äº†YY%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒLight-Xèƒ½å¤Ÿç”Ÿæˆæ›´é«˜è´¨é‡ã€æ›´é€¼çœŸçš„è§†é¢‘ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Light-Xå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼ŒåŒ…æ‹¬è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ã€æ¸¸æˆå¼€å‘ã€ç”µå½±åˆ¶ä½œç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œå¯ä»¥ç”¨äºåˆ›å»ºå…·æœ‰ä¸åŒè§†è§’å’Œå…‰ç…§æ¡ä»¶çš„è™šæ‹Ÿåœºæ™¯ï¼Œæˆ–è€…ç”¨äºå¯¹ç°æœ‰è§†é¢‘è¿›è¡Œé‡ç…§æ˜å’Œè§†è§’å˜æ¢ã€‚è¯¥æŠ€æœ¯è¿˜å¯ä»¥åº”ç”¨äºæœºå™¨äººè§†è§‰é¢†åŸŸï¼Œä¾‹å¦‚ï¼Œç”¨äºè®­ç»ƒæœºå™¨äººè¯†åˆ«åœ¨ä¸åŒå…‰ç…§æ¡ä»¶ä¸‹çš„ç‰©ä½“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in illumination control extend image-based methods to video, yet still facing a trade-off between lighting fidelity and temporal consistency. Moving beyond relighting, a key step toward generative modeling of real-world scenes is the joint control of camera trajectory and illumination, since visual dynamics are inherently shaped by both geometry and lighting. To this end, we present Light-X, a video generation framework that enables controllable rendering from monocular videos with both viewpoint and illumination control. 1) We propose a disentangled design that decouples geometry and lighting signals: geometry and motion are captured via dynamic point clouds projected along user-defined camera trajectories, while illumination cues are provided by a relit frame consistently projected into the same geometry. These explicit, fine-grained cues enable effective disentanglement and guide high-quality illumination. 2) To address the lack of paired multi-view and multi-illumination videos, we introduce Light-Syn, a degradation-based pipeline with inverse-mapping that synthesizes training pairs from in-the-wild monocular footage. This strategy yields a dataset covering static, dynamic, and AI-generated scenes, ensuring robust training. Extensive experiments show that Light-X outperforms baseline methods in joint camera-illumination control and surpasses prior video relighting methods under both text- and background-conditioned settings.

