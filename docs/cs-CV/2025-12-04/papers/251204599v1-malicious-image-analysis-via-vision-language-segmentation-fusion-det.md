---
layout: default
title: "Malicious Image Analysis via Vision-Language Segmentation Fusion: Detection, Element, and Location in One-shot"
---

# Malicious Image Analysis via Vision-Language Segmentation Fusion: Detection, Element, and Location in One-shot

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.04599" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.04599v1</a>
  <a href="https://arxiv.org/pdf/2512.04599.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.04599v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.04599v1', 'Malicious Image Analysis via Vision-Language Segmentation Fusion: Detection, Element, and Location in One-shot')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sheng Hang, Chaoxiang He, Hongsheng Hu, Hanqing Hu, Bin Benjamin Zhu, Shi-Feng Sun, Dawu Gu, Shuo Wang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-04

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºè§†è§‰-è¯­è¨€åˆ†å‰²èåˆçš„æ¶æ„å›¾åƒåˆ†ææ–¹æ³•ï¼Œå®ç°ä¸€æ­¥åˆ°ä½çš„å†…å®¹æ£€æµ‹ã€å…ƒç´ è¯†åˆ«å’Œå®šä½ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `æ¶æ„å›¾åƒåˆ†æ` `è§†è§‰-è¯­è¨€æ¨¡å‹` `å›¾åƒåˆ†å‰²` `é›¶æ ·æœ¬å­¦ä¹ ` `å†…å®¹å®¡æ ¸` `å¯¹æŠ—é²æ£’æ€§` `å¯è§£é‡Šæ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ¶æ„å›¾åƒæ£€æµ‹æ–¹æ³•é€šå¸¸ä»…æä¾›å›¾åƒçº§åˆ«çš„NSFWæ ‡å¿—ï¼Œç¼ºä¹å¯¹æœ‰å®³å…ƒç´ åŠå…¶ä½ç½®çš„ç»†ç²’åº¦ç†è§£ã€‚
2. è¯¥è®ºæ–‡æå‡ºä¸€ç§é›¶æ ·æœ¬çš„è§†è§‰-è¯­è¨€åˆ†å‰²èåˆæ–¹æ³•ï¼Œèƒ½å¤Ÿä¸€æ­¥åˆ°ä½åœ°æ£€æµ‹æ¶æ„å†…å®¹ã€è¯†åˆ«å…³é”®å…ƒç´ å¹¶ç²¾ç¡®å®šä½ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ¶æ„å†…å®¹æ£€æµ‹çš„å¬å›ç‡ã€ç²¾ç¡®ç‡å’Œåˆ†å‰²æˆåŠŸç‡ä¸Šå‡æœ‰æ˜¾è‘—æå‡ï¼Œå¹¶å…·æœ‰è¾ƒå¼ºçš„æŠ—æ”»å‡»é²æ£’æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§é›¶æ ·æœ¬æ¶æ„å›¾åƒåˆ†ææµç¨‹ï¼Œèƒ½å¤ŸåŒæ—¶å®Œæˆä¸‰ä¸ªä»»åŠ¡ï¼š(i) æ£€æµ‹å›¾åƒæ˜¯å¦åŒ…å«æœ‰å®³å†…å®¹ï¼›(ii) è¯†åˆ«å›¾åƒä¸­æ¶‰åŠçš„å…³é”®å…ƒç´ ï¼›(iii) ä»¥åƒç´ çº§ç²¾åº¦å®šä½è¿™äº›å…ƒç´ ã€‚è¯¥ç³»ç»Ÿé¦–å…ˆåº”ç”¨åŸºç¡€åˆ†å‰²æ¨¡å‹ï¼ˆSAMï¼‰ç”Ÿæˆå€™é€‰å¯¹è±¡æ©ç ï¼Œå¹¶å°†å…¶ä¼˜åŒ–ä¸ºæ›´å¤§çš„ç‹¬ç«‹åŒºåŸŸã€‚ç„¶åï¼Œä½¿ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹å’Œå¼€æ”¾è¯æ±‡æç¤ºå¯¹æ¯ä¸ªåŒºåŸŸè¿›è¡Œæ¶æ„ç›¸å…³æ€§è¯„åˆ†ï¼›è¿™äº›åˆ†æ•°ç”¨äºåŠ æƒèåˆæ­¥éª¤ï¼Œç”Ÿæˆç»Ÿä¸€çš„æ¶æ„å¯¹è±¡å›¾ã€‚é€šè¿‡é›†æˆå¤šä¸ªåˆ†å‰²å™¨ï¼Œå¢å¼ºäº†æµç¨‹å¯¹é’ˆå¯¹å•ä¸€åˆ†å‰²æ–¹æ³•çš„è‡ªé€‚åº”æ”»å‡»çš„æŠµæŠ—èƒ½åŠ›ã€‚åœ¨åŒ…å«æ¯’å“ã€æ€§ã€æš´åŠ›å’Œæç«¯ä¸»ä¹‰å†…å®¹çš„æ–°æ ‡æ³¨çš„790å¼ å›¾åƒæ•°æ®é›†ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œè¯¥æ–¹æ³•è¾¾åˆ°äº†85.8%çš„å…ƒç´ çº§å¬å›ç‡ï¼Œ78.1%çš„ç²¾ç¡®ç‡å’Œ92.1%çš„åˆ†å‰²æˆåŠŸç‡ï¼Œåœ¨å¯æ¯”ç²¾åº¦ä¸‹ï¼Œæ¯”ç›´æ¥çš„é›¶æ ·æœ¬VLMå®šä½æé«˜äº†27.4%çš„å¬å›ç‡ã€‚é’ˆå¯¹æ—¨åœ¨ç ´åSAMå’ŒVLMçš„PGDå¯¹æŠ—æ‰°åŠ¨ï¼Œè¯¥æ–¹æ³•çš„ç²¾ç¡®ç‡å’Œå¬å›ç‡ä¸‹é™ä¸è¶…è¿‡10%ï¼Œè¡¨ç°å‡ºå¾ˆé«˜çš„æŠ—æ”»å‡»é²æ£’æ€§ã€‚å®Œæ•´çš„æµç¨‹åœ¨å‡ ç§’é’Ÿå†…å¤„ç†ä¸€å¼ å›¾åƒï¼Œæ— ç¼åœ°æ’å…¥ç°æœ‰çš„VLMå·¥ä½œæµç¨‹ï¼Œå¹¶æ„æˆäº†ç¬¬ä¸€ä¸ªç”¨äºç»†ç²’åº¦ã€å¯è§£é‡Šçš„æ¶æ„å›¾åƒå®¡æ ¸çš„å®ç”¨å·¥å…·ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæ¶æ„å›¾åƒåˆ†ææ—¨åœ¨è¯†åˆ«å›¾åƒä¸­å­˜åœ¨çš„æœ‰å®³å†…å®¹ï¼Œå¹¶ç¡®å®šå¯¼è‡´å›¾åƒè¢«åˆ¤å®šä¸ºæ¶æ„çš„å…·ä½“å…ƒç´ åŠå…¶ä½ç½®ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸åªèƒ½ç»™å‡ºå›¾åƒçº§åˆ«çš„åˆ¤æ–­ï¼Œæ— æ³•æä¾›ç»†ç²’åº¦çš„è§£é‡Šï¼Œä¸”å®¹æ˜“å—åˆ°å¯¹æŠ—æ”»å‡»çš„å½±å“ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè¯¥è®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹çš„å¼€æ”¾è¯æ±‡èƒ½åŠ›ï¼Œç»“åˆå›¾åƒåˆ†å‰²æŠ€æœ¯ï¼Œå®ç°å¯¹æ¶æ„å›¾åƒä¸­å…³é”®å…ƒç´ çš„å®šä½å’Œè¯†åˆ«ã€‚é€šè¿‡èåˆå¤šä¸ªåˆ†å‰²å™¨çš„ç»“æœï¼Œæé«˜æ¨¡å‹çš„é²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) ä½¿ç”¨åŸºç¡€åˆ†å‰²æ¨¡å‹ï¼ˆSAMï¼‰ç”Ÿæˆå€™é€‰å¯¹è±¡æ©ç ï¼›2) å°†æ©ç ä¼˜åŒ–ä¸ºæ›´å¤§çš„ç‹¬ç«‹åŒºåŸŸï¼›3) ä½¿ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹å¯¹æ¯ä¸ªåŒºåŸŸè¿›è¡Œæ¶æ„ç›¸å…³æ€§è¯„åˆ†ï¼›4) æ ¹æ®è¯„åˆ†è¿›è¡Œèåˆï¼Œç”Ÿæˆæ¶æ„å¯¹è±¡å›¾ï¼›5) é›†æˆå¤šä¸ªåˆ†å‰²å™¨çš„ç»“æœï¼Œæé«˜é²æ£’æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå°†è§†è§‰-è¯­è¨€æ¨¡å‹ä¸å›¾åƒåˆ†å‰²æŠ€æœ¯ç›¸ç»“åˆï¼Œå®ç°äº†é›¶æ ·æœ¬çš„ç»†ç²’åº¦æ¶æ„å›¾åƒåˆ†æã€‚é€šè¿‡èåˆå¤šä¸ªåˆ†å‰²å™¨çš„ç»“æœï¼Œæé«˜äº†æ¨¡å‹çš„é²æ£’æ€§ï¼Œä½¿å…¶èƒ½å¤ŸæŠµæŠ—é’ˆå¯¹å•ä¸€åˆ†å‰²æ–¹æ³•çš„å¯¹æŠ—æ”»å‡»ã€‚

**å…³é”®è®¾è®¡**ï¼šè¯¥æ–¹æ³•ä½¿ç”¨SAMä½œä¸ºåŸºç¡€åˆ†å‰²æ¨¡å‹ï¼Œåˆ©ç”¨å…¶å¼ºå¤§çš„åˆ†å‰²èƒ½åŠ›ç”Ÿæˆå€™é€‰åŒºåŸŸã€‚ä½¿ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹è¿›è¡Œè¯„åˆ†æ—¶ï¼Œé‡‡ç”¨å¼€æ”¾è¯æ±‡æç¤ºï¼Œå…è®¸æ¨¡å‹è¯†åˆ«å„ç§ç±»å‹çš„æ¶æ„å…ƒç´ ã€‚é€šè¿‡åŠ æƒèåˆä¸åŒåŒºåŸŸçš„è¯„åˆ†ï¼Œç”Ÿæˆæœ€ç»ˆçš„æ¶æ„å¯¹è±¡å›¾ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥æ–¹æ³•åœ¨åŒ…å«æ¯’å“ã€æ€§ã€æš´åŠ›å’Œæç«¯ä¸»ä¹‰å†…å®¹çš„æ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—æˆæœï¼Œå…ƒç´ çº§å¬å›ç‡è¾¾åˆ°85.8%ï¼Œç²¾ç¡®ç‡è¾¾åˆ°78.1%ï¼Œåˆ†å‰²æˆåŠŸç‡è¾¾åˆ°92.1%ã€‚ä¸ç›´æ¥çš„é›¶æ ·æœ¬VLMå®šä½ç›¸æ¯”ï¼Œå¬å›ç‡æé«˜äº†27.4%ã€‚åŒæ—¶ï¼Œè¯¥æ–¹æ³•å¯¹PGDå¯¹æŠ—æ‰°åŠ¨è¡¨ç°å‡ºè¾ƒå¼ºçš„é²æ£’æ€§ï¼Œç²¾ç¡®ç‡å’Œå¬å›ç‡ä¸‹é™ä¸è¶…è¿‡10%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå†…å®¹å®¡æ ¸ã€ç½‘ç»œå®‰å…¨ã€æ™ºèƒ½ç›‘æ§ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œå¯ä»¥å¸®åŠ©ç¤¾äº¤åª’ä½“å¹³å°è‡ªåŠ¨æ£€æµ‹å’Œè¿‡æ»¤æ¶æ„å›¾åƒï¼Œå‡å°‘äººå·¥å®¡æ ¸çš„å·¥ä½œé‡ï¼Œæé«˜å®¡æ ¸æ•ˆç‡ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºè¯†åˆ«å’Œå®šä½çŠ¯ç½ªç°åœºçš„è¯æ®ï¼Œè¾…åŠ©æ¡ˆä»¶ä¾¦ç ´ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Detecting illicit visual content demands more than image-level NSFW flags; moderators must also know what objects make an image illegal and where those objects occur. We introduce a zero-shot pipeline that simultaneously (i) detects if an image contains harmful content, (ii) identifies each critical element involved, and (iii) localizes those elements with pixel-accurate masks - all in one pass. The system first applies foundation segmentation model (SAM) to generate candidate object masks and refines them into larger independent regions. Each region is scored for malicious relevance by a vision-language model using open-vocabulary prompts; these scores weight a fusion step that produces a consolidated malicious object map. An ensemble across multiple segmenters hardens the pipeline against adaptive attacks that target any single segmentation method. Evaluated on a newly-annotated 790-image dataset spanning drug, sexual, violent and extremist content, our method attains 85.8% element-level recall, 78.1% precision and a 92.1% segment-success rate - exceeding direct zero-shot VLM localization by 27.4% recall at comparable precision. Against PGD adversarial perturbations crafted to break SAM and VLM, our method's precision and recall decreased by no more than 10%, demonstrating high robustness against attacks. The full pipeline processes an image in seconds, plugs seamlessly into existing VLM workflows, and constitutes the first practical tool for fine-grained, explainable malicious-image moderation.

