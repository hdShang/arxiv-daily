---
layout: default
title: Age-Inclusive 3D Human Mesh Recovery for Action-Preserving Data Anonymization
---

# Age-Inclusive 3D Human Mesh Recovery for Action-Preserving Data Anonymization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.05259" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.05259v1</a>
  <a href="https://arxiv.org/pdf/2512.05259.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.05259v1" onclick="toggleFavorite(this, '2512.05259v1', 'Age-Inclusive 3D Human Mesh Recovery for Action-Preserving Data Anonymization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Georgios Chatzichristodoulou, Niki Efthymiou, Panagiotis Filntisis, Georgios Pavlakos, Petros Maragos

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-04

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAionHMRæ¡†æ¶ï¼Œå®ç°å¹´é¾„åŒ…å®¹çš„3Däººä½“ç½‘æ ¼é‡å»ºï¼Œç”¨äºä¿æŠ¤éšç§çš„æ•°æ®åŒ¿ååŒ–ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)** **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction & Matching)**

**å…³é”®è¯**: `3Däººä½“é‡å»º` `å¹´é¾„åŒ…å®¹æ€§` `SMPL-Aæ¨¡å‹` `æ•°æ®åŒ¿ååŒ–` `Transformerç½‘ç»œ` `å„¿ç«¥å»ºæ¨¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰3Däººä½“å»ºæ¨¡æ–¹æ³•åœ¨æˆäººæ•°æ®ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨å„¿ç«¥å’Œå©´å„¿æ•°æ®ä¸Šçš„æ³›åŒ–èƒ½åŠ›ä¸è¶³ï¼Œå­˜åœ¨æ˜¾è‘—çš„é¢†åŸŸå·®è·ã€‚
2. è®ºæ–‡æå‡ºAionHMRæ¡†æ¶ï¼Œæ ¸å¿ƒåœ¨äºå°†SMPL-Aèº«ä½“æ¨¡å‹èå…¥ä¼˜åŒ–æ–¹æ³•ï¼Œå®ç°å¯¹ä¸åŒå¹´é¾„æ®µäººç¾¤çš„ç²¾ç¡®å»ºæ¨¡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æå‡äº†å„¿ç«¥å’Œå©´å„¿çš„å½¢çŠ¶å’Œå§¿æ€ä¼°è®¡ç²¾åº¦ï¼ŒåŒæ—¶ä¿æŒäº†æˆäººæ•°æ®çš„å‡†ç¡®æ€§ï¼Œå¹¶å¯ç”¨äºæ•°æ®åŒ¿ååŒ–ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºAionHMRï¼Œæ—¨åœ¨è§£å†³ç°æœ‰3Däººä½“å½¢çŠ¶å’Œå§¿æ€ä¼°è®¡æ–¹æ³•åœ¨å„¿ç«¥å’Œå©´å„¿ç¾¤ä½“ä¸Šçš„æ³›åŒ–æ€§ä¸è¶³é—®é¢˜ã€‚AionHMRæ˜¯ä¸€ä¸ªç»¼åˆæ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥SMPL-Aèº«ä½“æ¨¡å‹æ‰©å±•äº†ç°æœ‰æœ€ä¼˜æ¨¡å‹ï¼Œå®ç°äº†å¯¹æˆäººã€å„¿ç«¥å’Œå©´å„¿çš„åŒæ­¥ç²¾ç¡®å»ºæ¨¡ã€‚åˆ©ç”¨è¯¥æ–¹æ³•ï¼Œæˆ‘ä»¬ä¸ºå…¬å¼€çš„å„¿ç«¥å’Œå©´å„¿å›¾åƒæ•°æ®åº“ç”Ÿæˆäº†ä¼ªground-truthæ ‡æ³¨ã€‚åŸºäºè¿™äº›æ–°è®­ç»ƒæ•°æ®ï¼Œæˆ‘ä»¬å¼€å‘å¹¶è®­ç»ƒäº†ä¸€ä¸ªåŸºäºTransformerçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œèƒ½å¤Ÿå®æ—¶è¿›è¡Œå¹´é¾„åŒ…å®¹çš„3Däººä½“é‡å»ºã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜¾è‘—æé«˜äº†å„¿ç«¥å’Œå©´å„¿çš„å½¢çŠ¶å’Œå§¿æ€ä¼°è®¡ç²¾åº¦ï¼ŒåŒæ—¶ä¸å½±å“æˆäººæ•°æ®çš„å‡†ç¡®æ€§ã€‚é‡å»ºçš„ç½‘æ ¼å¯ä»¥ä½œä¸ºåŸå§‹å›¾åƒçš„éšç§ä¿æŠ¤æ›¿ä»£å“ï¼Œä¿ç•™äº†å…³é”®çš„åŠ¨ä½œã€å§¿æ€å’Œå‡ ä½•ä¿¡æ¯ï¼Œä»è€Œå®ç°åŒ¿åæ•°æ®é›†çš„å‘å¸ƒã€‚æˆ‘ä»¬è¿˜å‘å¸ƒäº†3D-BabyRobotæ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«å„¿ç«¥ä¸æœºå™¨äººäº¤äº’çš„åŠ¨ä½œä¿æŒ3Dé‡å»ºã€‚è¿™é¡¹å·¥ä½œå¼¥åˆäº†ä¸€ä¸ªå…³é”®çš„é¢†åŸŸå·®è·ï¼Œå¹¶ä¸ºåŒ…å®¹æ€§ã€éšç§ä¿æŠ¤å’Œå¹´é¾„å¤šæ ·åŒ–çš„3Däººä½“å»ºæ¨¡å¥ å®šäº†åŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰3Däººä½“å½¢çŠ¶å’Œå§¿æ€ä¼°è®¡æ–¹æ³•ä¸»è¦é’ˆå¯¹æˆäººè®¾è®¡ï¼Œåœ¨åº”ç”¨äºå„¿ç«¥å’Œå©´å„¿æ—¶ï¼Œç”±äºèº«ä½“æ¯”ä¾‹å’Œå½¢æ€çš„å·®å¼‚ï¼Œæ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚è¿™é™åˆ¶äº†ç›¸å…³æŠ€æœ¯åœ¨å„¿ç«¥ç›¸å…³ç ”ç©¶å’Œåº”ç”¨ä¸­çš„ä½¿ç”¨ï¼ŒåŒæ—¶ä¹Ÿé˜»ç¢äº†åŒ…å«å„¿ç«¥æ•°æ®çš„å…¬å…±æ•°æ®é›†çš„å‘å¸ƒï¼Œå› ä¸ºå­˜åœ¨éšç§æ³„éœ²çš„é£é™©ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨SMPL-Aèº«ä½“æ¨¡å‹ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿå‚æ•°åŒ–åœ°è¡¨ç¤ºä¸åŒå¹´é¾„æ®µï¼ˆåŒ…æ‹¬æˆäººã€å„¿ç«¥å’Œå©´å„¿ï¼‰çš„äººä½“å½¢çŠ¶å’Œå§¿æ€ã€‚é€šè¿‡å°†SMPL-Aæ¨¡å‹é›†æˆåˆ°ç°æœ‰çš„3Däººä½“é‡å»ºæ¡†æ¶ä¸­ï¼Œå¯ä»¥å®ç°å¯¹ä¸åŒå¹´é¾„æ®µäººç¾¤çš„ç»Ÿä¸€å»ºæ¨¡ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”å„¿ç«¥å’Œå©´å„¿çš„èº«ä½“ç‰¹å¾ï¼Œä»è€Œæé«˜é‡å»ºç²¾åº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAionHMRæ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šä¼ªground-truthç”Ÿæˆå’Œæ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒã€‚é¦–å…ˆï¼Œåˆ©ç”¨åŸºäºä¼˜åŒ–çš„æ–¹æ³•ï¼Œå°†SMPL-Aæ¨¡å‹æ‹Ÿåˆåˆ°å…¬å¼€çš„å„¿ç«¥å’Œå©´å„¿å›¾åƒæ•°æ®é›†ï¼Œç”Ÿæˆä¼ªground-truthæ ‡æ³¨ã€‚ç„¶åï¼ŒåŸºäºè¿™äº›æ ‡æ³¨ï¼Œè®­ç»ƒä¸€ä¸ªåŸºäºTransformerçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œç”¨äºå®æ—¶3Däººä½“é‡å»ºã€‚è¯¥æ¨¡å‹ä»¥å›¾åƒä½œä¸ºè¾“å…¥ï¼Œè¾“å‡ºSMPL-Aæ¨¡å‹çš„å‚æ•°ï¼Œä»è€Œå¾—åˆ°3Däººä½“ç½‘æ ¼ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†SMPL-Aæ¨¡å‹é›†æˆåˆ°3Däººä½“é‡å»ºæ¡†æ¶ä¸­ï¼Œä»è€Œå®ç°äº†å¹´é¾„åŒ…å®¹æ€§ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒAionHMRèƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†å„¿ç«¥å’Œå©´å„¿çš„èº«ä½“ç‰¹å¾ï¼Œæ˜¾è‘—æé«˜äº†é‡å»ºç²¾åº¦ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜æå‡ºäº†ä¸€ç§ç”Ÿæˆä¼ªground-truthæ ‡æ³¨çš„ç­–ç•¥ï¼Œè§£å†³äº†å„¿ç«¥å’Œå©´å„¿æ•°æ®é›†ç¼ºä¹é«˜è´¨é‡æ ‡æ³¨çš„é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ä¼ªground-truthç”Ÿæˆé˜¶æ®µï¼Œè®ºæ–‡é‡‡ç”¨åŸºäºä¼˜åŒ–çš„æ–¹æ³•ï¼Œæœ€å°åŒ–SMPL-Aæ¨¡å‹ä¸å›¾åƒä¹‹é—´çš„é‡æŠ•å½±è¯¯å·®å’Œå…ˆéªŒçº¦æŸã€‚åœ¨æ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒé˜¶æ®µï¼Œè®ºæ–‡ä½¿ç”¨Transformerä½œä¸ºä¸»å¹²ç½‘ç»œï¼Œå¹¶è®¾è®¡äº†åˆé€‚çš„æŸå¤±å‡½æ•°ï¼ŒåŒ…æ‹¬é‡æŠ•å½±è¯¯å·®ã€å§¿æ€è¯¯å·®å’Œå½¢çŠ¶è¯¯å·®ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜é‡‡ç”¨äº†æ•°æ®å¢å¼ºæŠ€æœ¯ï¼Œä»¥æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚æœªåœ¨æ‘˜è¦ä¸­è¯¦ç»†è¯´æ˜ï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒAionHMRæ¡†æ¶æ˜¾è‘—æé«˜äº†å„¿ç«¥å’Œå©´å„¿çš„3Däººä½“é‡å»ºç²¾åº¦ï¼ŒåŒæ—¶ä¿æŒäº†æˆäººæ•°æ®çš„å‡†ç¡®æ€§ã€‚å…·ä½“æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿æœªåœ¨æ‘˜è¦ä¸­ç»™å‡ºï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚è¯¥æ–¹æ³•ç”Ÿæˆçš„3Däººä½“ç½‘æ ¼å¯ä»¥ä½œä¸ºåŸå§‹å›¾åƒçš„éšç§ä¿æŠ¤æ›¿ä»£å“ï¼Œä¸ºåŒ¿åæ•°æ®é›†çš„å‘å¸ƒæä¾›äº†å¯èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºå„¿ç«¥ç›¸å…³çš„ç ”ç©¶é¢†åŸŸï¼Œä¾‹å¦‚å„¿ç«¥è¡Œä¸ºåˆ†æã€å„¿ç«¥å¥åº·ç›‘æµ‹å’Œå„¿ç«¥äººæœºäº¤äº’ç­‰ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºç”ŸæˆåŒ¿ååŒ–çš„å„¿ç«¥æ•°æ®é›†ï¼Œä¿ƒè¿›ç›¸å…³ç ”ç©¶çš„å¼€å±•ï¼ŒåŒæ—¶ä¿æŠ¤å„¿ç«¥çš„éšç§ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºè™šæ‹Ÿç°å®ã€æ¸¸æˆå’ŒåŠ¨ç”»ç­‰é¢†åŸŸï¼Œåˆ›é€ æ›´åŠ é€¼çœŸå’Œè‡ªç„¶çš„å„¿ç«¥è§’è‰²ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While three-dimensional (3D) shape and pose estimation is a highly researched area that has yielded significant advances, the resulting methods, despite performing well for the adult population, generally fail to generalize effectively to children and infants. This paper addresses this challenge by introducing AionHMR, a comprehensive framework designed to bridge this domain gap. We propose an optimization-based method that extends a top-performing model by incorporating the SMPL-A body model, enabling the concurrent and accurate modeling of adults, children, and infants. Leveraging this approach, we generated pseudo-ground-truth annotations for publicly available child and infant image databases. Using these new training data, we then developed and trained a specialized transformer-based deep learning model capable of real-time 3D age-inclusive human reconstruction. Extensive experiments demonstrate that our methods significantly improve shape and pose estimation for children and infants without compromising accuracy on adults. Importantly, our reconstructed meshes serve as privacy-preserving substitutes for raw images, retaining essential action, pose, and geometry information while enabling anonymized datasets release. As a demonstration, we introduce the 3D-BabyRobot dataset, a collection of action-preserving 3D reconstructions of children interacting with robots. This work bridges a crucial domain gap and establishes a foundation for inclusive, privacy-aware, and age-diverse 3D human modeling.

