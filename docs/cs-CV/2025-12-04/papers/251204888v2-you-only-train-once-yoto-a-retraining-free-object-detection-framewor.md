---
layout: default
title: "You Only Train Once (YOTO): A Retraining-Free Object Detection Framework"
---

# You Only Train Once (YOTO): A Retraining-Free Object Detection Framework

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.04888" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.04888v2</a>
  <a href="https://arxiv.org/pdf/2512.04888.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.04888v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.04888v2', 'You Only Train Once (YOTO): A Retraining-Free Object Detection Framework')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Priyanto Hidayatullah, Nurjannah Syakrani, Yudi Widhiyasana, Muhammad Rizqi Sholahuddin, Refdinal Tubagus, Zahri Al Adzani Hidayat, Hanri Fajar Ramadhan, Dafa Alfarizki Pratama, Farhan Muhammad Yasin

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-04 (æ›´æ–°: 2025-12-05)

**å¤‡æ³¨**: This manuscript was first submitted to the Engineering (Elsevier Journal). The preprint version was posted to arXiv afterwards to facilitate open access and community feedback

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºYOTOæ¡†æ¶ï¼Œè§£å†³ç›®æ ‡æ£€æµ‹ä¸­å…é‡è®­ç»ƒçš„æ–°å“å¢é‡å­¦ä¹ é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `ç›®æ ‡æ£€æµ‹` `å¢é‡å­¦ä¹ ` `å…é‡è®­ç»ƒ` `åº¦é‡å­¦ä¹ ` `é›¶å”®åº”ç”¨` `ç¾éš¾æ€§é—å¿˜` `YOLO` `è¾¹ç¼˜è®¡ç®—`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç›®æ ‡æ£€æµ‹é¢ä¸´ç¾éš¾æ€§é—å¿˜é—®é¢˜ï¼Œæ¯æ¬¡æ–°å¢äº§å“éƒ½éœ€è¦é‡è®­ç»ƒæ•´ä¸ªæ¨¡å‹ï¼Œè€—æ—¶è€—åŠ›ã€‚
2. YOTOæ¡†æ¶ç»“åˆYOLO11nè¿›è¡Œå®šä½ï¼ŒDeITå’ŒProxy Anchor Lossè¿›è¡Œç‰¹å¾æå–ï¼Œå¹¶ä½¿ç”¨å‘é‡æ•°æ®åº“è¿›è¡Œåˆ†ç±»ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒYOTOåœ¨é›¶å”®åœºæ™¯ä¸‹æ— éœ€é‡è®­ç»ƒå³å¯æœ‰æ•ˆæ£€æµ‹æ–°æ—§äº§å“ï¼Œè®­ç»ƒæ•ˆç‡æå‡æ˜¾è‘—ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºYou Only Train Once (YOTO) çš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç›®æ ‡æ£€æµ‹ä¸­ç¾éš¾æ€§é—å¿˜çš„é—®é¢˜ã€‚å½“å¼•å…¥æ–°äº§å“æ—¶ï¼Œä¼ ç»Ÿæ–¹æ³•éœ€è¦ä½¿ç”¨æ–°äº§å“æ•°æ®é›†å’Œå®Œæ•´æ—§æ•°æ®é›†è¿›è¡Œé‡è®­ç»ƒï¼Œå¯¼è‡´è®­ç»ƒæˆæœ¬å¢åŠ å’Œæ—¶é—´æ¶ˆè€—ã€‚YOTOé€šè¿‡ç»“åˆYOLO11nè¿›è¡Œç›®æ ‡å®šä½ï¼ŒDeITå’ŒProxy Anchor Lossè¿›è¡Œç‰¹å¾æå–å’Œåº¦é‡å­¦ä¹ æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚åˆ†ç±»é˜¶æ®µï¼Œä½¿ç”¨ç›®æ ‡äº§å“å’ŒQdrantå‘é‡æ•°æ®åº“ä¸­ç‰¹å¾å‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦ã€‚åœ¨åŒ…å«140ç§äº§å“çš„é›¶å”®åº—æ¡ˆä¾‹ç ”ç©¶ä¸­ï¼Œå®éªŒç»“æœè¡¨æ˜è¯¥æ¡†æ¶åœ¨æ£€æµ‹æ–°äº§å“å’Œç°æœ‰äº§å“æ–¹é¢éƒ½å–å¾—äº†ä»¤äººé¼“èˆçš„å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œæ— éœ€é‡è®­ç»ƒæ˜¾è‘—æé«˜äº†è®­ç»ƒæ•ˆç‡ï¼Œç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•æå‡è¿‘3å€ï¼Œå¹¶ä¸”éšç€æ–°äº§å“å¢åŠ æ•ˆç‡æ›´é«˜ã€‚åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šï¼Œæ¯å¼ åŒ…å«å¤šä¸ªäº§å“çš„å›¾åƒå¹³å‡æ¨ç†æ—¶é—´ä¸º580æ¯«ç§’ï¼ŒéªŒè¯äº†è¯¥æ¡†æ¶çš„å®é™…åº”ç”¨å¯è¡Œæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç›®æ ‡æ£€æµ‹æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­ï¼Œç»å¸¸éœ€è¦å¤„ç†æ–°å¢ç±»åˆ«ï¼ˆä¾‹å¦‚é›¶å”®åœºæ™¯ä¸­çš„æ–°äº§å“ï¼‰ã€‚ä¼ ç»Ÿçš„åšæ³•æ˜¯ï¼Œæ¯æ¬¡æ–°å¢ç±»åˆ«ï¼Œéƒ½éœ€è¦ä½¿ç”¨åŒ…å«æ–°ç±»åˆ«å’Œæ—§ç±»åˆ«çš„æ•°æ®é›†é‡æ–°è®­ç»ƒæ•´ä¸ªæ¨¡å‹ã€‚è¿™ç§é‡è®­ç»ƒçš„æ–¹å¼ä¸ä»…è€—è´¹å¤§é‡æ—¶é—´å’Œè®¡ç®—èµ„æºï¼Œè€Œä¸”å®¹æ˜“å¯¼è‡´ç¾éš¾æ€§é—å¿˜ï¼Œå³æ¨¡å‹åœ¨å­¦ä¹ æ–°çŸ¥è¯†çš„åŒæ—¶å¿˜è®°äº†æ—§çŸ¥è¯†ã€‚å› æ­¤ï¼Œå¦‚ä½•å®ç°å…é‡è®­ç»ƒçš„ç›®æ ‡æ£€æµ‹ï¼Œå³åœ¨ä¸é‡æ–°è®­ç»ƒæ•´ä¸ªæ¨¡å‹çš„æƒ…å†µä¸‹ï¼Œå¿«é€Ÿé€‚åº”æ–°çš„ç±»åˆ«ï¼Œæ˜¯ä¸€ä¸ªé‡è¦çš„ç ”ç©¶é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šYOTOæ¡†æ¶çš„æ ¸å¿ƒæ€è·¯æ˜¯è§£è€¦ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸­çš„å®šä½å’Œåˆ†ç±»ä¸¤ä¸ªå­ä»»åŠ¡ã€‚å¯¹äºå®šä½ä»»åŠ¡ï¼Œä½¿ç”¨YOLO11nè¿›è¡Œç›®æ ‡æ¡†çš„é¢„æµ‹ï¼›å¯¹äºåˆ†ç±»ä»»åŠ¡ï¼Œåˆ™é‡‡ç”¨åº¦é‡å­¦ä¹ çš„æ–¹å¼ï¼Œå°†æ¯ä¸ªç±»åˆ«å­¦ä¹ åˆ°ä¸€ä¸ªç‰¹å¾å‘é‡ç©ºé—´ä¸­çš„åµŒå…¥è¡¨ç¤ºã€‚å½“éœ€è¦è¯†åˆ«æ–°çš„ç±»åˆ«æ—¶ï¼Œåªéœ€è¦å°†æ–°ç±»åˆ«çš„ç‰¹å¾å‘é‡æ·»åŠ åˆ°ç‰¹å¾å‘é‡æ•°æ®åº“ä¸­ï¼Œè€Œæ— éœ€é‡æ–°è®­ç»ƒæ•´ä¸ªæ¨¡å‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šYOTOæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) YOLO11nç›®æ ‡æ£€æµ‹å™¨ï¼šè´Ÿè´£æ£€æµ‹å›¾åƒä¸­çš„ç›®æ ‡ï¼Œå¹¶æå–ç›®æ ‡åŒºåŸŸçš„ç‰¹å¾ã€‚2) DeITç‰¹å¾æå–å™¨ï¼šç”¨äºæå–ç›®æ ‡åŒºåŸŸçš„è§†è§‰ç‰¹å¾ï¼Œå¹¶å°†å…¶æ˜ å°„åˆ°ç‰¹å¾å‘é‡ç©ºé—´ä¸­ã€‚3) Proxy Anchor Lossï¼šç”¨äºè®­ç»ƒç‰¹å¾æå–å™¨ï¼Œä½¿å¾—åŒä¸€ç±»åˆ«çš„ç›®æ ‡åœ¨ç‰¹å¾å‘é‡ç©ºé—´ä¸­æ›´åŠ æ¥è¿‘ï¼Œä¸åŒç±»åˆ«çš„ç›®æ ‡æ›´åŠ è¿œç¦»ã€‚4) Qdrantå‘é‡æ•°æ®åº“ï¼šç”¨äºå­˜å‚¨æ‰€æœ‰ç±»åˆ«çš„ç‰¹å¾å‘é‡ã€‚5) Cosine Similarityåˆ†ç±»å™¨ï¼šç”¨äºè®¡ç®—ç›®æ ‡åŒºåŸŸçš„ç‰¹å¾å‘é‡ä¸å‘é‡æ•°æ®åº“ä¸­å„ä¸ªç±»åˆ«ç‰¹å¾å‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œä»è€Œåˆ¤æ–­ç›®æ ‡çš„ç±»åˆ«ã€‚

**å…³é”®åˆ›æ–°**ï¼šYOTOæ¡†æ¶çš„å…³é”®åˆ›æ–°åœ¨äºå°†ç›®æ ‡æ£€æµ‹ä»»åŠ¡è§£è€¦ä¸ºå®šä½å’Œåˆ†ç±»ä¸¤ä¸ªå­ä»»åŠ¡ï¼Œå¹¶é‡‡ç”¨åº¦é‡å­¦ä¹ çš„æ–¹å¼è¿›è¡Œåˆ†ç±»ã€‚è¿™ç§è§£è€¦çš„æ–¹å¼ä½¿å¾—æ¨¡å‹å¯ä»¥ç‹¬ç«‹åœ°å­¦ä¹ æ–°ç±»åˆ«çš„ç‰¹å¾ï¼Œè€Œæ— éœ€é‡æ–°è®­ç»ƒæ•´ä¸ªæ¨¡å‹ã€‚æ­¤å¤–ï¼Œä½¿ç”¨Proxy Anchor Losså¯ä»¥æœ‰æ•ˆåœ°æé«˜ç‰¹å¾å‘é‡çš„åŒºåˆ†æ€§ï¼Œä»è€Œæé«˜åˆ†ç±»çš„å‡†ç¡®ç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç‰¹å¾æå–å™¨æ–¹é¢ï¼Œé€‰æ‹©äº†DeITæ¨¡å‹ï¼Œå› ä¸ºå®ƒå…·æœ‰è¾ƒå¼ºçš„ç‰¹å¾æå–èƒ½åŠ›ã€‚åœ¨æŸå¤±å‡½æ•°æ–¹é¢ï¼Œé€‰æ‹©äº†Proxy Anchor Lossï¼Œå› ä¸ºå®ƒèƒ½å¤Ÿæœ‰æ•ˆåœ°æé«˜ç‰¹å¾å‘é‡çš„åŒºåˆ†æ€§ã€‚åœ¨å‘é‡æ•°æ®åº“æ–¹é¢ï¼Œé€‰æ‹©äº†Qdrantï¼Œå› ä¸ºå®ƒå…·æœ‰é«˜æ•ˆçš„å‘é‡æ£€ç´¢èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¿˜å¯¹YOLO11nè¿›è¡Œäº†å¾®è°ƒï¼Œä»¥é€‚åº”ç‰¹å®šçš„ç›®æ ‡æ£€æµ‹ä»»åŠ¡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒYOTOæ¡†æ¶åœ¨é›¶å”®åº—çš„140ç§äº§å“æ•°æ®é›†ä¸Šå–å¾—äº†ä»¤äººé¼“èˆçš„å‡†ç¡®æ€§ï¼Œæ— è®ºæ˜¯æ£€æµ‹æ–°äº§å“è¿˜æ˜¯ç°æœ‰äº§å“ã€‚ä¸ä¼ ç»Ÿçš„é‡è®­ç»ƒæ–¹æ³•ç›¸æ¯”ï¼ŒYOTOæ¡†æ¶çš„è®­ç»ƒæ—¶é—´æ•ˆç‡æé«˜äº†è¿‘3å€ï¼Œå¹¶ä¸”éšç€æ–°äº§å“æ•°é‡çš„å¢åŠ ï¼Œæ•ˆç‡æå‡æ›´åŠ æ˜¾è‘—ã€‚æ­¤å¤–ï¼Œåœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šï¼ŒYOTOæ¡†æ¶çš„å¹³å‡æ¨ç†æ—¶é—´ä¸º580æ¯«ç§’/å›¾åƒï¼ŒéªŒè¯äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å¯è¡Œæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

YOTOæ¡†æ¶åœ¨é›¶å”®ã€å·¥ä¸šè´¨æ£€ã€æ™ºèƒ½å®‰é˜²ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚ä¾‹å¦‚ï¼Œåœ¨é›¶å”®åœºæ™¯ä¸­ï¼Œå¯ä»¥å¿«é€Ÿæ·»åŠ æ–°äº§å“è€Œæ— éœ€é‡æ–°è®­ç»ƒæ¨¡å‹ï¼Œæé«˜è¿è¥æ•ˆç‡ã€‚åœ¨å·¥ä¸šè´¨æ£€ä¸­ï¼Œå¯ä»¥å¿«é€Ÿé€‚åº”æ–°çš„ç¼ºé™·ç±»å‹ï¼Œæé«˜æ£€æµ‹ç²¾åº¦ã€‚åœ¨æ™ºèƒ½å®‰é˜²ä¸­ï¼Œå¯ä»¥å¿«é€Ÿè¯†åˆ«æ–°çš„ç›®æ ‡ï¼Œæé«˜å®‰å…¨ç­‰çº§ã€‚è¯¥ç ”ç©¶ä¸ºè§£å†³ç›®æ ‡æ£€æµ‹ä¸­çš„ç¾éš¾æ€§é—å¿˜é—®é¢˜æä¾›äº†ä¸€ç§æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Object detection constitutes the primary task within the domain of computer vision. It is utilized in numerous domains. Nonetheless, object detection continues to encounter the issue of catastrophic forgetting. The model must be retrained whenever new products are introduced, utilizing not only the new products dataset but also the entirety of the previous dataset. The outcome is obvious: increasing model training expenses and significant time consumption. In numerous sectors, particularly retail checkout, the frequent introduction of new products presents a great challenge. This study introduces You Only Train Once (YOTO), a methodology designed to address the issue of catastrophic forgetting by integrating YOLO11n for object localization with DeIT and Proxy Anchor Loss for feature extraction and metric learning. For classification, we utilize cosine similarity between the embedding features of the target product and those in the Qdrant vector database. In a case study conducted in a retail store with 140 products, the experimental results demonstrate that our proposed framework achieves encouraging accuracy, whether for detecting new or existing products. Furthermore, without retraining, the training duration difference is significant. We achieve almost 3 times the training time efficiency compared to classical object detection approaches. This efficiency escalates as additional new products are added to the product database. The average inference time is 580 ms per image containing multiple products, on an edge device, validating the proposed framework's feasibility for practical use.

