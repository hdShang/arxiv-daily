---
layout: default
title: Contact-Aware Refinement of Human Pose Pseudo-Ground Truth via Bioimpedance Sensing
---

# Contact-Aware Refinement of Human Pose Pseudo-Ground Truth via Bioimpedance Sensing

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.04862" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.04862v1</a>
  <a href="https://arxiv.org/pdf/2512.04862.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.04862v1" onclick="toggleFavorite(this, '2512.04862v1', 'Contact-Aware Refinement of Human Pose Pseudo-Ground Truth via Bioimpedance Sensing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Maria-Paola Forte, Nikos Athanasiou, Giulia Ballardini, Jan Ulrich Bartels, Katherine J. Kuchenbecker, Michael J. Black

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-04

**å¤‡æ³¨**: * Equal contribution. Minor figure corrections compared to the ICCV 2025 version

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºBioTUCHï¼Œç»“åˆç”Ÿç‰©é˜»æŠ—æ„ŸçŸ¥ä¼˜åŒ–è‡ªæ¥è§¦åœºæ™¯ä¸‹çš„äººä½“å§¿æ€ä¼ªæ ‡ç­¾ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)** **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)**

**å…³é”®è¯**: `äººä½“å§¿æ€ä¼°è®¡` `è‡ªæ¥è§¦` `ç”Ÿç‰©é˜»æŠ—ä¼ æ„Ÿ` `å§¿æ€ä¼˜åŒ–` `å¯ç©¿æˆ´è®¾å¤‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŸºäºè§†è§‰çš„3Däººä½“å§¿æ€ä¼°è®¡æ–¹æ³•åœ¨è‡ªæ¥è§¦åœºæ™¯ä¸‹è¡¨ç°ä¸ä½³ï¼Œä¾‹å¦‚æ‰‹ä¸è„¸éƒ¨çš„æ¥è§¦ã€‚
2. BioTUCHç»“åˆè§†è§‰å§¿æ€ä¼°è®¡å™¨å’Œç”Ÿç‰©é˜»æŠ—ä¼ æ„Ÿï¼Œåˆ©ç”¨ç”Ÿç‰©é˜»æŠ—æ„ŸçŸ¥çš®è‚¤æ¥è§¦ï¼Œä¼˜åŒ–äººä½“å§¿æ€ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒBioTUCHåœ¨é‡å»ºç²¾åº¦ä¸Šå¹³å‡æå‡äº†11.7%ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸ºäº†è·å–ç²¾ç¡®çš„é‡å¤–3Däººä½“å§¿æ€ï¼Œä»è€Œä¸ºå§¿æ€ä¼°è®¡å’ŒåŠ¨ä½œç”Ÿæˆæ–¹æ³•æä¾›æœ‰ä»·å€¼çš„æ•°æ®ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶ã€‚è™½ç„¶åŸºäºè§†é¢‘çš„ä¼°è®¡æ–¹æ³•å·²ç»å˜å¾—è¶Šæ¥è¶Šç²¾ç¡®ï¼Œä½†å®ƒä»¬åœ¨æ¶‰åŠè‡ªæ¥è§¦çš„å¸¸è§åœºæ™¯ä¸­ç»å¸¸å¤±æ•ˆï¼Œä¾‹å¦‚æ‰‹è§¦æ‘¸è„¸éƒ¨ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œå¯ç©¿æˆ´ç”Ÿç‰©é˜»æŠ—ä¼ æ„Ÿå¯ä»¥å»‰ä»·ä¸”ä¸å¼•äººæ³¨ç›®åœ°æµ‹é‡çœŸå®çš„çš®è‚¤æ¥è§¦ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç»“åˆè§†è§‰å§¿æ€ä¼°è®¡å™¨å’Œç”Ÿç‰©é˜»æŠ—ä¼ æ„Ÿçš„æ¡†æ¶ï¼Œé€šè¿‡è€ƒè™‘è‡ªæ¥è§¦æ¥æ•è·äººçš„3Då§¿æ€ã€‚æˆ‘ä»¬çš„æ–¹æ³•BioTUCHï¼Œä½¿ç”¨ç°æˆçš„ä¼°è®¡å™¨åˆå§‹åŒ–å§¿æ€ï¼Œå¹¶åœ¨æµ‹é‡çš„è‡ªæ¥è§¦æœŸé—´å¼•å…¥æ¥è§¦æ„ŸçŸ¥å§¿æ€ä¼˜åŒ–ï¼šåœ¨å¼ºåˆ¶æ‰§è¡Œé¡¶ç‚¹é‚»è¿‘çº¦æŸçš„åŒæ—¶ï¼Œæœ€å°åŒ–é‡æŠ•å½±è¯¯å·®å’Œä¸è¾“å…¥ä¼°è®¡çš„åå·®ã€‚æˆ‘ä»¬ä½¿ç”¨åŒæ­¥RGBè§†é¢‘ã€ç”Ÿç‰©é˜»æŠ—æµ‹é‡å’Œ3Dè¿åŠ¨æ•æ‰çš„æ–°æ•°æ®é›†éªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•ã€‚é€šè¿‡ä½¿ç”¨ä¸‰ä¸ªè¾“å…¥å§¿æ€ä¼°è®¡å™¨è¿›è¡Œæµ‹è¯•ï¼Œæˆ‘ä»¬è¯æ˜äº†é‡å»ºç²¾åº¦å¹³å‡æé«˜äº†11.7%ã€‚æˆ‘ä»¬è¿˜å±•ç¤ºäº†ä¸€ç§å¾®å‹å¯ç©¿æˆ´ç”Ÿç‰©é˜»æŠ—ä¼ æ„Ÿå™¨ï¼Œè¯¥ä¼ æ„Ÿå™¨èƒ½å¤Ÿæœ‰æ•ˆçš„å¤§è§„æ¨¡æ”¶é›†æ¥è§¦æ„ŸçŸ¥è®­ç»ƒæ•°æ®ï¼Œä»è€Œä½¿ç”¨BioTUCHæ”¹è¿›å§¿æ€ä¼°è®¡å’Œç”Ÿæˆã€‚ä»£ç å’Œæ•°æ®å¯åœ¨biotuch.is.tue.mpg.deè·å¾—ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åœ¨è‡ªæ¥è§¦åœºæ™¯ä¸‹ï¼ŒåŸºäºè§†è§‰çš„3Däººä½“å§¿æ€ä¼°è®¡ç²¾åº¦ä½çš„é—®é¢˜ã€‚ç°æœ‰çš„æ–¹æ³•éš¾ä»¥å‡†ç¡®å¤„ç†é®æŒ¡å’Œè‡ªæ¥è§¦å¸¦æ¥çš„æ­§ä¹‰æ€§ï¼Œå¯¼è‡´å§¿æ€ä¼°è®¡è¯¯å·®å¢å¤§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨ç”Ÿç‰©é˜»æŠ—ä¼ æ„Ÿæ¥è·å–çš®è‚¤é—´çš„æ¥è§¦ä¿¡æ¯ï¼Œå¹¶å°†è¿™äº›ä¿¡æ¯èå…¥åˆ°å§¿æ€ä¼˜åŒ–è¿‡ç¨‹ä¸­ã€‚é€šè¿‡ç”Ÿç‰©é˜»æŠ—ä¼ æ„Ÿå™¨æ£€æµ‹çš®è‚¤æ¥è§¦ï¼Œä¸ºå§¿æ€ä¼°è®¡æä¾›é¢å¤–çš„çº¦æŸï¼Œä»è€Œæé«˜åœ¨è‡ªæ¥è§¦åœºæ™¯ä¸‹çš„å§¿æ€ä¼°è®¡ç²¾åº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šBioTUCHæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) ä½¿ç”¨ç°æˆçš„å§¿æ€ä¼°è®¡å™¨åˆå§‹åŒ–äººä½“å§¿æ€ï¼›2) åˆ©ç”¨ç”Ÿç‰©é˜»æŠ—ä¼ æ„Ÿå™¨æ£€æµ‹çš®è‚¤é—´çš„æ¥è§¦ï¼›3) åŸºäºæ£€æµ‹åˆ°çš„æ¥è§¦ä¿¡æ¯ï¼Œè¿›è¡Œæ¥è§¦æ„ŸçŸ¥çš„å§¿æ€ä¼˜åŒ–ã€‚å§¿æ€ä¼˜åŒ–è¿‡ç¨‹åŒæ—¶è€ƒè™‘äº†é‡æŠ•å½±è¯¯å·®ã€ä¸åˆå§‹å§¿æ€çš„åå·®ä»¥åŠé¡¶ç‚¹é‚»è¿‘çº¦æŸã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå°†ç”Ÿç‰©é˜»æŠ—ä¼ æ„Ÿä¸è§†è§‰å§¿æ€ä¼°è®¡ç›¸ç»“åˆï¼Œåˆ©ç”¨ç”Ÿç‰©é˜»æŠ—æä¾›çš„æ¥è§¦ä¿¡æ¯æ¥çº¦æŸå§¿æ€ä¼˜åŒ–è¿‡ç¨‹ã€‚è¿™ç§ç»“åˆæ–¹å¼èƒ½å¤Ÿæœ‰æ•ˆåœ°è§£å†³è‡ªæ¥è§¦åœºæ™¯ä¸‹çš„æ­§ä¹‰æ€§é—®é¢˜ï¼Œä»è€Œæé«˜å§¿æ€ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å§¿æ€ä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œè®ºæ–‡è®¾è®¡äº†åŒ…å«é‡æŠ•å½±è¯¯å·®é¡¹ã€ä¸åˆå§‹å§¿æ€åå·®é¡¹ä»¥åŠé¡¶ç‚¹é‚»è¿‘çº¦æŸé¡¹çš„æŸå¤±å‡½æ•°ã€‚é‡æŠ•å½±è¯¯å·®é¡¹ç”¨äºä¿è¯ä¼°è®¡çš„å§¿æ€ä¸å›¾åƒè§‚æµ‹ä¸€è‡´ï¼›åå·®é¡¹ç”¨äºé˜²æ­¢å§¿æ€è¿‡åº¦åç¦»åˆå§‹ä¼°è®¡ï¼›é¡¶ç‚¹é‚»è¿‘çº¦æŸé¡¹ç”¨äºä¿è¯äººä½“ç»“æ„çš„åˆç†æ€§ã€‚ç”Ÿç‰©é˜»æŠ—ä¼ æ„Ÿå™¨é‡‡ç”¨å¾®å‹å¯ç©¿æˆ´è®¾è®¡ï¼Œæ–¹ä¾¿å¤§è§„æ¨¡æ•°æ®é‡‡é›†ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒBioTUCHæ–¹æ³•åœ¨ä¸‰ä¸ªä¸åŒçš„è¾“å…¥å§¿æ€ä¼°è®¡å™¨ä¸Šå‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå¹³å‡é‡å»ºç²¾åº¦æé«˜äº†11.7%ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜å±•ç¤ºäº†ä¸€ç§å¾®å‹å¯ç©¿æˆ´ç”Ÿç‰©é˜»æŠ—ä¼ æ„Ÿå™¨ï¼Œä¸ºå¤§è§„æ¨¡æ”¶é›†æ¥è§¦æ„ŸçŸ¥è®­ç»ƒæ•°æ®æä¾›äº†å¯èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºäººæœºäº¤äº’ã€è™šæ‹Ÿç°å®ã€è¿åŠ¨åˆ†æã€åŒ»ç–—åº·å¤ç­‰é¢†åŸŸã€‚é€šè¿‡æé«˜è‡ªæ¥è§¦åœºæ™¯ä¸‹çš„äººä½“å§¿æ€ä¼°è®¡ç²¾åº¦ï¼Œå¯ä»¥æ”¹å–„äººæœºäº¤äº’çš„è‡ªç„¶æ€§å’Œå‡†ç¡®æ€§ï¼Œæå‡è™šæ‹Ÿç°å®ä½“éªŒçš„æ²‰æµ¸æ„Ÿï¼Œä¸ºè¿åŠ¨åˆ†ææä¾›æ›´å¯é çš„æ•°æ®ï¼Œå¹¶ä¸ºåŒ»ç–—åº·å¤æä¾›æ›´ç²¾ç¡®çš„å§¿æ€è¯„ä¼°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Capturing accurate 3D human pose in the wild would provide valuable data for training pose estimation and motion generation methods. While video-based estimation approaches have become increasingly accurate, they often fail in common scenarios involving self-contact, such as a hand touching the face. In contrast, wearable bioimpedance sensing can cheaply and unobtrusively measure ground-truth skin-to-skin contact. Consequently, we propose a novel framework that combines visual pose estimators with bioimpedance sensing to capture the 3D pose of people by taking self-contact into account. Our method, BioTUCH, initializes the pose using an off-the-shelf estimator and introduces contact-aware pose optimization during measured self-contact: reprojection error and deviations from the input estimate are minimized while enforcing vertex proximity constraints. We validate our approach using a new dataset of synchronized RGB video, bioimpedance measurements, and 3D motion capture. Testing with three input pose estimators, we demonstrate an average of 11.7% improvement in reconstruction accuracy. We also present a miniature wearable bioimpedance sensor that enables efficient large-scale collection of contact-aware training data for improving pose estimation and generation using BioTUCH. Code and data are available at biotuch.is.tue.mpg.de

