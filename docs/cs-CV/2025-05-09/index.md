---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CV - 2025-05-09
---

# cs.CVï¼ˆ2025-05-09ï¼‰

ğŸ“Š å…± **6** ç¯‡è®ºæ–‡
 | ğŸ”— **1** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (3)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (2 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (3 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250506381v2-temperature-driven-robust-disease-detection-in-brain-and-gastrointes.html">Temperature-Driven Robust Disease Detection in Brain and Gastrointestinal Disorders via Context-Aware Adaptive Knowledge Distillation</a></td>
  <td>æå‡ºåŸºäºæ¸©åº¦é©±åŠ¨çš„çŸ¥è¯†è’¸é¦æ¡†æ¶ä»¥æé«˜è„‘éƒ¨å’Œèƒƒè‚ ç–¾ç—…æ£€æµ‹çš„é²æ£’æ€§</td>
  <td class="tags-cell"><span class="paper-tag">teacher-student</span> <span class="paper-tag">distillation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.06381v2" data-paper-url="./papers/250506381v2-temperature-driven-robust-disease-detection-in-brain-and-gastrointes.html" onclick="toggleFavorite(this, '2505.06381v2', 'Temperature-Driven Robust Disease Detection in Brain and Gastrointestinal Disorders via Context-Aware Adaptive Knowledge Distillation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250506210v1-topo-vm-unetv2-encoding-topology-into-vision-mamba-unet-for-polyp-se.html">Topo-VM-UNetV2: Encoding Topology into Vision Mamba UNet for Polyp Segmentation</a></td>
  <td>æå‡ºTopo-VM-UNetV2ä»¥è§£å†³å¤šè¾¹å½¢åˆ†å‰²ä¸­çš„æ‹“æ‰‘ç‰¹å¾æ•æ‰é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">Mamba</span> <span class="paper-tag">state space model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.06210v1" data-paper-url="./papers/250506210v1-topo-vm-unetv2-encoding-topology-into-vision-mamba-unet-for-polyp-se.html" onclick="toggleFavorite(this, '2505.06210v1', 'Topo-VM-UNetV2: Encoding Topology into Vision Mamba UNet for Polyp Segmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250506219v3-vin-nbv-a-view-introspection-network-for-next-best-view-selection.html">VIN-NBV: A View Introspection Network for Next-Best-View Selection</a></td>
  <td>æå‡ºVIN-NBVä»¥è§£å†³å¤æ‚åœºæ™¯ä¸‹çš„ä¸‹ä¸€æœ€ä½³è§†è§’é€‰æ‹©é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">deep reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.06219v3" data-paper-url="./papers/250506219v3-vin-nbv-a-view-introspection-network-for-next-best-view-selection.html" onclick="toggleFavorite(this, '2505.06219v3', 'VIN-NBV: A View Introspection Network for Next-Best-View Selection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>4</td>
  <td><a href="./papers/250506217v1-adapting-a-segmentation-foundation-model-for-medical-image-classific.html">Adapting a Segmentation Foundation Model for Medical Image Classification</a></td>
  <td>æå‡ºä¸€ç§æ–°æ¡†æ¶ä»¥é€‚åº”SAMæ¨¡å‹è¿›è¡ŒåŒ»å­¦å›¾åƒåˆ†ç±»</td>
  <td class="tags-cell"><span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.06217v1" data-paper-url="./papers/250506217v1-adapting-a-segmentation-foundation-model-for-medical-image-classific.html" onclick="toggleFavorite(this, '2505.06217v1', 'Adapting a Segmentation Foundation Model for Medical Image Classification')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250506152v1-mm-skin-enhancing-dermatology-vision-language-model-with-an-image-te.html">MM-Skin: Enhancing Dermatology Vision-Language Model with an Image-Text Dataset Derived from Textbooks</a></td>
  <td>æå‡ºMM-Skinä»¥è§£å†³çš®è‚¤ç§‘å¤šæ¨¡æ€æ•°æ®ä¸è¶³é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span> <span class="paper-tag">instruction following</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.06152v1" data-paper-url="./papers/250506152v1-mm-skin-enhancing-dermatology-vision-language-model-with-an-image-te.html" onclick="toggleFavorite(this, '2505.06152v1', 'MM-Skin: Enhancing Dermatology Vision-Language Model with an Image-Text Dataset Derived from Textbooks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>6</td>
  <td><a href="./papers/250506113v1-camera-only-birds-eye-view-perception-a-neural-approach-to-lidar-fre.html">Camera-Only Bird's Eye View Perception: A Neural Approach to LiDAR-Free Environmental Mapping for Autonomous Vehicles</a></td>
  <td>æå‡ºåŸºäºç›¸æœºçš„é¸Ÿç°è§†å›¾æ„ŸçŸ¥æ¡†æ¶ä»¥è§£å†³æ¿€å…‰é›·è¾¾ä¾èµ–é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">depth estimation</span> <span class="paper-tag">monocular depth</span> <span class="paper-tag">Depth Anything</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.06113v1" data-paper-url="./papers/250506113v1-camera-only-birds-eye-view-perception-a-neural-approach-to-lidar-fre.html" onclick="toggleFavorite(this, '2505.06113v1', 'Camera-Only Bird&#39;s Eye View Perception: A Neural Approach to LiDAR-Free Environmental Mapping for Autonomous Vehicles')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CV é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)