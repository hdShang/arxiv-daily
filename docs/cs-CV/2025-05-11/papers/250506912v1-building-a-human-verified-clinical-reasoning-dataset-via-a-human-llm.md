---
layout: default
title: Building a Human-Verified Clinical Reasoning Dataset via a Human LLM Hybrid Pipeline for Trustworthy Medical AI
---

# Building a Human-Verified Clinical Reasoning Dataset via a Human LLM Hybrid Pipeline for Trustworthy Medical AI

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.06912" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.06912v1</a>
  <a href="https://arxiv.org/pdf/2505.06912.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.06912v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.06912v1', 'Building a Human-Verified Clinical Reasoning Dataset via a Human LLM Hybrid Pipeline for Trustworthy Medical AI')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chao Ding, Mouxiao Bian, Pengcheng Chen, Hongliang Zhang, Tianbin Li, Lihao Liu, Jiayuan Chen, Zhuoran Li, Yabei Zhong, Yongqi Liu, Haiqing Huang, Dongming Shan, Junjun He, Jie Xu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-11

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºäººç±»éªŒè¯çš„ä¸´åºŠæ¨ç†æ•°æ®é›†ä»¥è§£å†³åŒ»ç–—AIä¿¡ä»»é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åŒ»ç–—AI` `å¤§å‹è¯­è¨€æ¨¡å‹` `ä¸´åºŠæ¨ç†` `ä¸“å®¶éªŒè¯` `æ•°æ®é›†æ„å»º` `é€æ˜æ¨ç†` `ä¿¡ä»»æœºåˆ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŒ»å­¦LLMsçš„æ¨ç†è¿‡ç¨‹ä¸é€æ˜ï¼Œå¯¼è‡´ä¸´åºŠåŒ»ç”Ÿå¯¹å…¶ä¿¡ä»»åº¦ä½ï¼Œé™åˆ¶äº†å…¶åº”ç”¨ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåŒ…å«31,247ä¸ªåŒ»å­¦é—®ç­”å¯¹çš„æ•°æ®é›†ï¼Œç»“åˆäººç±»ä¸“å®¶å’ŒLLMçš„æ··åˆç®¡é“è¿›è¡ŒéªŒè¯å’Œä¼˜åŒ–ã€‚
3. è¯¥æ•°æ®é›†çš„å‘å¸ƒä¸ºå¼€å‘é€æ˜ä¸”å¯éªŒè¯æ¨ç†çš„åŒ»å­¦LLMsæä¾›äº†é‡è¦èµ„æºï¼Œæå‡äº†AIåœ¨åŒ»å­¦ä¸­çš„åº”ç”¨å®‰å…¨æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨åŒ»å­¦é—®ç­”ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†ç”±äºå…¶ä¸é€æ˜çš„æ¨ç†è¿‡ç¨‹ï¼Œä¸´åºŠåº”ç”¨å—åˆ°ä¸¥é‡åˆ¶çº¦ã€‚å½“å‰åŒ»å­¦LLMsä¸»è¦ä¾èµ–ç§‘å­¦æ–‡çŒ®æˆ–åˆæˆæ•°æ®ï¼Œç¼ºä¹ä¸“å®¶éªŒè¯å’Œä¸´åºŠç›¸å…³æ€§ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåŒ…å«31,247ä¸ªåŒ»å­¦é—®ç­”å¯¹çš„æ•°æ®é›†ï¼Œæ¯ä¸ªé—®ç­”éƒ½é™„æœ‰ä¸“å®¶éªŒè¯çš„æ¨ç†é“¾è§£é‡Šã€‚è¯¥æ•°æ®é›†é€šè¿‡äººç±»ä¸LLMçš„æ··åˆç®¡é“è¿›è¡Œç­–åˆ’ï¼Œç¡®ä¿äº†æ•°æ®çš„ä¸´åºŠç›¸å…³æ€§å’Œé€æ˜æ€§ï¼Œæ—¨åœ¨æ¨åŠ¨æ›´å®‰å…¨å’Œå¯è§£é‡Šçš„åŒ»ç–—AIçš„å‘å±•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å½“å‰åŒ»å­¦LLMsåœ¨ä¸´åºŠåº”ç”¨ä¸­å› æ¨ç†ä¸é€æ˜è€Œå¯¼è‡´çš„ä¿¡ä»»é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äºç¼ºä¹ä¸“å®¶éªŒè¯çš„æ–‡çŒ®æˆ–åˆæˆæ•°æ®ï¼Œå¯¼è‡´ä¸´åºŠç›¸å…³æ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å»ºç«‹ä¸€ä¸ªäººç±»ä¸LLMçš„æ··åˆç®¡é“ï¼Œè¿­ä»£ç”Ÿæˆå’ŒéªŒè¯åŒ»å­¦é—®ç­”å¯¹ï¼Œç¡®ä¿æ•°æ®çš„ä¸“å®¶éªŒè¯å’Œä¸´åºŠç›¸å…³æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•åŒ…æ‹¬å¤šä¸ªé˜¶æ®µï¼šé¦–å…ˆç”±LLMç”Ÿæˆåˆæ­¥çš„æ¨ç†é“¾ï¼Œç„¶åç”±åŒ»å­¦ä¸“å®¶è¿›è¡Œå®¡æŸ¥å’Œè¯„åˆ†ï¼Œæœ€åæ ¹æ®ç»“æ„åŒ–æ ‡å‡†è¿›è¡Œä¼˜åŒ–ï¼Œç¡®ä¿è¾“å‡ºè¾¾åˆ°ä¸“å®¶å…±è¯†ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºç»“åˆäººç±»ä¸“å®¶ä¸LLMçš„åä½œï¼Œå½¢æˆä¸€ä¸ªå¯æ‰©å±•çš„éªŒè¯æµç¨‹ï¼Œæ˜¾è‘—æé«˜äº†æ•°æ®çš„è´¨é‡å’Œä¸´åºŠé€‚ç”¨æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®ç”Ÿæˆå’ŒéªŒè¯è¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†ç»“æ„åŒ–è¯„åˆ†æ ‡å‡†ï¼Œç¡®ä¿æ¯ä¸ªé—®ç­”å¯¹çš„æ¨ç†é“¾éƒ½ç»è¿‡ä¸¥æ ¼å®¡æŸ¥ï¼Œå¿…è¦æ—¶é€šè¿‡äººç±»å¹²é¢„æˆ–LLMå†ç”Ÿç”Ÿæˆè¿›è¡Œä¿®æ­£ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æå‡ºçš„æ•°æ®é›†åœ¨å¤šä¸ªä¸´åºŠé¢†åŸŸçš„é—®ç­”å‡†ç¡®æ€§æ˜¾è‘—æé«˜ï¼Œä¸“å®¶éªŒè¯çš„æ¨ç†é“¾ä½¿å¾—LLMsçš„æ¨ç†è¿‡ç¨‹æ›´åŠ é€æ˜ï¼Œæå‡äº†ä¸´åºŠåŒ»ç”Ÿçš„ä¿¡ä»»åº¦ã€‚å…·ä½“æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿å°šæœªæŠ«éœ²ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŒ»ç–—AIçš„å¼€å‘å’Œä¸´åºŠå†³ç­–æ”¯æŒç³»ç»Ÿã€‚é€šè¿‡æä¾›ä¸€ä¸ªé«˜è´¨é‡çš„éªŒè¯æ•°æ®é›†ï¼Œå¯ä»¥æ˜¾è‘—æå‡åŒ»å­¦LLMsçš„é€æ˜æ€§å’Œå¯ä¿¡åº¦ï¼Œä»è€Œæ¨åŠ¨å…¶åœ¨å®é™…åŒ»ç–—ç¯å¢ƒä¸­çš„åº”ç”¨ï¼Œæœ€ç»ˆæ”¹å–„æ‚£è€…æŠ¤ç†è´¨é‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Despite strong performance in medical question-answering, the clinical adoption of Large Language Models (LLMs) is critically hampered by their opaque 'black-box' reasoning, limiting clinician trust. This challenge is compounded by the predominant reliance of current medical LLMs on corpora from scientific literature or synthetic data, which often lack the granular expert validation and high clinical relevance essential for advancing their specialized medical capabilities. To address these critical gaps, we introduce a highly clinically relevant dataset with 31,247 medical question-answer pairs, each accompanied by expert-validated chain-of-thought (CoT) explanations. This resource, spanning multiple clinical domains, was curated via a scalable human-LLM hybrid pipeline: LLM-generated rationales were iteratively reviewed, scored, and refined by medical experts against a structured rubric, with substandard outputs revised through human effort or guided LLM regeneration until expert consensus. This publicly available dataset provides a vital source for the development of medical LLMs that capable of transparent and verifiable reasoning, thereby advancing safer and more interpretable AI in medicine.

