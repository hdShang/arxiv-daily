---
layout: default
title: MELLM: A Flow-Guided Large Language Model for Micro-Expression Understanding
---

# MELLM: A Flow-Guided Large Language Model for Micro-Expression Understanding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.07007" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.07007v3</a>
  <a href="https://arxiv.org/pdf/2505.07007.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.07007v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.07007v3', 'MELLM: A Flow-Guided Large Language Model for Micro-Expression Understanding')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Sirui Zhao, Zhengye Zhang, Shifeng Liu, Xinglong Mao, Shukang Yin, Chaoyou Fu, Tong Xu, Enhong Chen

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-11 (Êõ¥Êñ∞: 2025-12-09)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫MELLM‰ª•Ëß£ÂÜ≥ÂæÆË°®ÊÉÖÁêÜËß£ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÂæÆË°®ÊÉÖÁêÜËß£` `ÂÖâÊµÅ‰º∞ËÆ°` `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `ÊÉÖÊÑüËÆ°ÁÆó` `Â§öÊ®°ÊÄÅÂ≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂæÆË°®ÊÉÖËØÜÂà´ÊñπÊ≥ï‰∏ªË¶ÅÈõÜ‰∏≠‰∫éÁ¶ªÊï£ÊÉÖÊÑüÂàÜÁ±ªÔºåÁº∫‰πèÂØπÁªÜÂæÆÈù¢ÈÉ®Âä®ÊÄÅÂíåÊÉÖÊÑüÁ∫øÁ¥¢ÁöÑÂÖ®Èù¢ÁêÜËß£„ÄÇ
2. Êú¨ÊñáÊèêÂá∫MELLMÔºåÈÄöËøáÁªìÂêàÂÖâÊµÅÊïèÊÑüÊÄß‰∏éÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõÔºåÊèêÂçáÂæÆË°®ÊÉÖÁêÜËß£ÁöÑÂáÜÁ°ÆÊÄß„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåMEFlowNetÂú®ÂÖâÊµÅ‰º∞ËÆ°ÊñπÈù¢Ë∂ÖË∂äÁé∞ÊúâÊñπÊ≥ïÔºåMELLMÂú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠ÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÂæÆË°®ÊÉÖÔºàMEsÔºâÊòØÊè≠Á§∫ÈöêËóèÊÉÖÊÑüÁöÑÁü≠ÊöÇ‰ΩéÂº∫Â∫¶Èù¢ÈÉ®Âä®‰ΩúÔºåÂØπ‰∫éÊÉÖÊÑüËÆ°ÁÆóËá≥ÂÖ≥ÈáçË¶Å„ÄÇÂ∞ΩÁÆ°ÂæÆË°®ÊÉÖËØÜÂà´Â∑≤ÊúâÊòæËëóËøõÂ±ïÔºå‰ΩÜÁé∞ÊúâÊñπÊ≥ï‰∏ªË¶ÅÂ±ÄÈôê‰∫éÁ¶ªÊï£ÊÉÖÊÑüÂàÜÁ±ªÔºåÁº∫‰πèÂÖ®Èù¢ÁöÑÂæÆË°®ÊÉÖÁêÜËß£ÔºàMEUÔºâËÉΩÂäõÔºåÂ∞§ÂÖ∂ÊòØÂú®Ëß£ËØªÁªÜÂæÆÈù¢ÈÉ®Âä®ÊÄÅÂíåÊÉÖÊÑüÁ∫øÁ¥¢ÊñπÈù¢„ÄÇ‰∏∫Ê≠§ÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂæÆË°®ÊÉÖÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàMELLMÔºâÔºåÂÆÉÁªìÂêà‰∫ÜÂü∫‰∫éÂÖâÊµÅÁöÑÁªÜÂæÆÈù¢ÈÉ®Âä®‰ΩúÊïèÊÑüÊÄß‰∏éÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏ÄÁßçÂêç‰∏∫MEFlowNetÁöÑËø≠‰ª£ÂÖâÊµÅ‰º∞ËÆ°Âô®Ôºå‰ª•Á≤æÁ°ÆÊçïÊçâÈù¢ÈÉ®ÂæÆËøêÂä®ÔºåÂπ∂ÊûÑÂª∫‰∫ÜMEFlowDatasetÔºå‰∏Ä‰∏™ÂåÖÂê´54,611ÂØπËµ∑Âßã-È°∂ÁÇπÂõæÂÉèÁöÑÂ§ßËßÑÊ®°ÂÖâÊµÅÊï∞ÊçÆÈõÜ„ÄÇÂÆûÈ™åË°®ÊòéÔºåMEFlowNetÂú®Èù¢ÈÉ®ÂíåÂæÆË°®ÊÉÖÂÖâÊµÅ‰º∞ËÆ°ÊñπÈù¢ÊòæËëó‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåËÄåMELLMÂú®Â§ö‰∏™ÂæÆË°®ÊÉÖÂü∫ÂáÜÊµãËØï‰∏≠ÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÂáÜÁ°ÆÊÄßÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥ÂæÆË°®ÊÉÖÁêÜËß£ÔºàMEUÔºâ‰∏≠ÁöÑÁªÜÂæÆÈù¢ÈÉ®Âä®ÊÄÅËß£ËØª‰∏çË∂≥ÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂ§öÈõÜ‰∏≠‰∫éÁ¶ªÊï£ÊÉÖÊÑüÂàÜÁ±ªÔºåÊó†Ê≥ïÂÖ®Èù¢ÊçïÊçâÂæÆË°®ÊÉÖÁöÑÂ§çÊùÇÊÄß„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊèêÂá∫MELLMÔºåÈÄöËøáÈõÜÊàêÂÖâÊµÅ‰º∞ËÆ°‰∏éÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõÔºåÂ¢ûÂº∫Ê®°ÂûãÂØπÁªÜÂæÆÈù¢ÈÉ®Âä®‰ΩúÁöÑÁêÜËß£„ÄÇMEFlowNet‰Ωú‰∏∫ÂÖâÊµÅ‰º∞ËÆ°Âô®Ôºå‰∏ìÊ≥®‰∫éÊçïÊçâÂæÆË°®ÊÉÖÁöÑÁªÜÂæÆÂèòÂåñ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨MEFlowNetÂÖâÊµÅ‰º∞ËÆ°Ê®°ÂùóÂíåMELLMËØ≠Ë®ÄÊ®°Âûã„ÄÇMEFlowNetË¥üË¥£ÊèêÂèñÈù¢ÈÉ®ÂæÆËøêÂä®ÁöÑÂÖâÊµÅ‰ø°Âè∑ÔºåËÄåMELLMÂàôÂú®Ê≠§Âü∫Á°Ä‰∏äËøõË°åÂæÆË°®ÊÉÖÁêÜËß£ÁöÑÊåá‰ª§Ë∞É‰ºò„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöMEFlowNetÊòØÈ¶ñ‰∏™‰∏ìÈó®ÈíàÂØπÂæÆË°®ÊÉÖÁöÑÂÖâÊµÅ‰º∞ËÆ°Âô®ÔºåMELLMÂàôÊòØÈ¶ñ‰∏™‰∏∫ÂæÆË°®ÊÉÖÁêÜËß£ÈáèË∫´ÂÆöÂà∂ÁöÑÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºåËøô‰∏§ËÄÖÁöÑÁªìÂêàÊòæËëóÊèêÂçá‰∫ÜÂæÆË°®ÊÉÖÁöÑÁêÜËß£ËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®MEFlowNet‰∏≠ÔºåÈááÁî®‰∫ÜËø≠‰ª£ÂÖâÊµÅ‰º∞ËÆ°ÊäÄÊúØÔºåÁ°Æ‰øùÂØπÁªÜÂæÆÈù¢ÈÉ®Âä®‰ΩúÁöÑÈ´òÁ≤æÂ∫¶ÊçïÊçâ„ÄÇÊçüÂ§±ÂáΩÊï∞ËÆæËÆ°‰∏äÔºåÊ≥®ÈáçÂÖâÊµÅ‰º∞ËÆ°ÁöÑÂáÜÁ°ÆÊÄß‰∏éÂæÆË°®ÊÉÖÁâπÂæÅÁöÑÊèêÂèñÔºåÁ°Æ‰øùÊ®°ÂûãÁöÑÊúâÊïàËÆ≠ÁªÉ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåMEFlowNetÂú®Èù¢ÈÉ®ÂíåÂæÆË°®ÊÉÖÂÖâÊµÅ‰º∞ËÆ°ÊñπÈù¢ÁöÑÊÄßËÉΩÊòæËëó‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåMELLMÂú®Â§ö‰∏™ÂæÆË°®ÊÉÖÂü∫ÂáÜÊµãËØï‰∏≠ÂÆûÁé∞‰∫ÜË∂ÖËøá90%ÁöÑÂáÜÁ°ÆÁéáÔºåÂ±ïÁé∞Âá∫Âº∫Â§ßÁöÑÊ≥õÂåñËÉΩÂäõÂíåÂ∫îÁî®ÊΩúÂäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂Âú®ÊÉÖÊÑüËÆ°ÁÆó„ÄÅÂøÉÁêÜÂ≠¶„ÄÅÂÆâÈò≤ÁõëÊéßÁ≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõ„ÄÇÈÄöËøáÊèêÂçáÂæÆË°®ÊÉÖÁêÜËß£ËÉΩÂäõÔºåMELLMÂèØÁî®‰∫éÊÉÖÊÑüËØÜÂà´„ÄÅÂøÉÁêÜÁä∂ÊÄÅËØÑ‰º∞Âèä‰∫∫Êú∫‰∫§‰∫íÁ≠âÂú∫ÊôØÔºåÊú™Êù•ÂèØËÉΩÊé®Âä®Áõ∏ÂÖ≥ÊäÄÊúØÁöÑÂïÜ‰∏öÂåñ‰∏éÊôÆÂèä„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Micro-expressions (MEs), brief and low-intensity facial movements revealing concealed emotions, are crucial for affective computing. Despite notable progress in ME recognition, existing methods are largely confined to discrete emotion classification, lacking the capacity for comprehensive ME Understanding (MEU), particularly in interpreting subtle facial dynamics and underlying emotional cues. While Multimodal Large Language Models (MLLMs) offer potential for MEU with their advanced reasoning abilities, they still struggle to perceive such subtle facial affective behaviors. To bridge this gap, we propose a ME Large Language Model (MELLM) that integrates optical flow-based sensitivity to subtle facial motions with the powerful inference ability of LLMs. Specifically, an iterative, warping-based optical-flow estimator, named MEFlowNet, is introduced to precisely capture facial micro-movements. For its training and evaluation, we construct MEFlowDataset, a large-scale optical-flow dataset with 54,611 onset-apex image pairs spanning diverse identities and subtle facial motions. Subsequently, we design a Flow-Guided Micro-Expression Understanding paradigm. Under this framework, the optical flow signals extracted by MEFlowNet are leveraged to build MEU-Instruct, an instruction-tuning dataset for MEU. MELLM is then fine-tuned on MEU-Instruct, enabling it to translate subtle motion patterns into human-readable descriptions and generate corresponding emotional inferences. Experiments demonstrate that MEFlowNet significantly outperforms existing optical flow methods in facial and ME-flow estimation, while MELLM achieves state-of-the-art accuracy and generalization across multiple ME benchmarks. To the best of our knowledge, this work presents two key contributions: MEFlowNet as the first dedicated ME flow estimator, and MELLM as the first LLM tailored for MEU.

