---
layout: default
title: Hallucination-Aware Multimodal Benchmark for Gastrointestinal Image Analysis with Large Vision-Language Models
---

# Hallucination-Aware Multimodal Benchmark for Gastrointestinal Image Analysis with Large Vision-Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.07001" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.07001v2</a>
  <a href="https://arxiv.org/pdf/2505.07001.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.07001v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.07001v2', 'Hallucination-Aware Multimodal Benchmark for Gastrointestinal Image Analysis with Large Vision-Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Bidur Khanal, Sandesh Pokhrel, Sanjay Bhandari, Ramesh Rana, Nikesh Shrestha, Ram Bahadur Gurung, Cristian Linte, Angus Watson, Yash Raj Shrestha, Binod Bhattarai

**åˆ†ç±»**: cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-11 (æ›´æ–°: 2025-06-22)

**å¤‡æ³¨**: Accepted at MICCAI 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/bhattarailab/Hallucination-Aware-VLM)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šæ¨¡æ€åŸºå‡†ä»¥è§£å†³åŒ»ç–—å›¾åƒåˆ†æä¸­çš„å¹»è§‰é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€æ¨¡å‹` `å¹»è§‰æ£€æµ‹` `åŒ»å­¦å›¾åƒåˆ†æ` `å¤šæ¨¡æ€æ•°æ®é›†` `ä¸´åºŠåº”ç”¨` `å¾®è°ƒç­–ç•¥`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨ç”ŸæˆåŒ»å­¦æŠ¥å‘Šæ—¶ï¼Œå¸¸å¸¸å‡ºç°å¹»è§‰ç°è±¡ï¼Œå¯¼è‡´ç”Ÿæˆçš„æè¿°ä¸å®é™…å›¾åƒä¸ç¬¦ï¼Œå½±å“ä¸´åºŠåº”ç”¨ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ•°æ®é›†Gut-VLMï¼Œå¹¶é‡‡ç”¨å¹»è§‰æ„ŸçŸ¥å¾®è°ƒç­–ç•¥ï¼Œä¸“æ³¨äºæ£€æµ‹å’Œçº æ­£å¹»è§‰ï¼Œè€Œä¸ä»…ä»…æ˜¯ç”Ÿæˆæè¿°æ€§æŠ¥å‘Šã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œå¹»è§‰æ„ŸçŸ¥å¾®è°ƒæ–¹æ³•åœ¨å¤šä¸ªè¯„ä¼°æŒ‡æ ‡ä¸Šä¼˜äºä¼ ç»Ÿçš„å¾®è°ƒæ–¹æ³•ï¼Œä¸ºVLMåœ¨åŒ»å­¦é¢†åŸŸçš„åº”ç”¨æä¾›äº†æ–°çš„æ€è·¯ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨åŒ»å­¦é¢†åŸŸçš„æ—¥ç›Šæ™®åŠï¼Œå®ƒä»¬åœ¨ç†è§£åŒ»å­¦å›¾åƒå’Œä¸´åºŠè¯­è¨€æ–¹é¢å±•ç°å‡ºæ˜¾è‘—èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå¹»è§‰ç°è±¡ï¼Œå³ç”Ÿæˆä¸è§†è§‰å†…å®¹ä¸ä¸€è‡´çš„æè¿°ï¼Œä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§é—®é¢˜ï¼Œå°¤å…¶åœ¨åŒ»ç–—é¢†åŸŸå½±å“æ·±è¿œã€‚ä¸ºä¿ƒè¿›VLMåœ¨èƒƒè‚ é“å›¾åƒåˆ†æä¸­çš„ç ”ç©¶å¹¶ç ”ç©¶å¹»è§‰ç°è±¡ï¼Œæœ¬æ–‡æ„å»ºäº†ä¸€ä¸ªå¤šæ¨¡æ€å›¾åƒ-æ–‡æœ¬æ•°æ®é›†Gut-VLMã€‚è¯¥æ•°æ®é›†é‡‡ç”¨ä¸¤é˜¶æ®µæµç¨‹ç”Ÿæˆï¼Œé¦–å…ˆä½¿ç”¨ChatGPTç”ŸæˆKvasir-v2å›¾åƒçš„æè¿°æ€§åŒ»å­¦æŠ¥å‘Šï¼Œéšåç”±åŒ»å­¦ä¸“å®¶ç³»ç»Ÿæ€§å®¡æŸ¥å¹¶çº æ­£æ½œåœ¨ä¸å‡†ç¡®ä¹‹å¤„ã€‚ä¸ä¼ ç»Ÿæ•°æ®é›†ä¸åŒï¼ŒGut-VLMä¸ä»…åŒ…å«æè¿°æ–‡æœ¬ï¼Œè¿˜æ ‡è¯†å¹»è§‰å¥å­åŠå…¶å¯¹åº”çš„ä¿®æ­£ã€‚æˆ‘ä»¬æå‡ºçš„å¹»è§‰æ„ŸçŸ¥å¾®è°ƒæ–¹æ³•æ˜¾ç¤ºå‡ºä¼˜äºä¼ ç»Ÿå¾®è°ƒæ–¹æ³•çš„æ•ˆæœï¼Œå¹¶å¯¹å¤šç§æœ€å…ˆè¿›çš„VLMè¿›è¡Œäº†å¹¿æ³›è¯„ä¼°ï¼Œå»ºç«‹äº†åŸºå‡†ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨åŒ»å­¦å›¾åƒåˆ†æä¸­ç”Ÿæˆä¸ä¸€è‡´æè¿°çš„å¹»è§‰é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ä»…å…³æ³¨ç”Ÿæˆæè¿°ï¼Œå¿½è§†äº†å¹»è§‰ç°è±¡çš„å½±å“ï¼Œå¯¼è‡´ä¸´åºŠåº”ç”¨çš„å¯é æ€§é™ä½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„å¹»è§‰æ„ŸçŸ¥å¾®è°ƒæ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡ä¸“æ³¨äºæ£€æµ‹å’Œçº æ­£å¹»è§‰ï¼Œæå‡æ¨¡å‹çš„ç”Ÿæˆè´¨é‡ã€‚è¿™ç§æ–¹æ³•ä¸ä»…å…³æ³¨æ–‡æœ¬ç”Ÿæˆï¼Œè¿˜å¼ºè°ƒæ–‡æœ¬ä¸å›¾åƒå†…å®¹çš„ä¸€è‡´æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åˆ†ä¸ºä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µä½¿ç”¨ChatGPTç”ŸæˆKvasir-v2å›¾åƒçš„åŒ»å­¦æŠ¥å‘Šï¼Œç¬¬äºŒé˜¶æ®µç”±åŒ»å­¦ä¸“å®¶å®¡æŸ¥å¹¶ä¿®æ­£æŠ¥å‘Šä¸­çš„å¹»è§‰å¥å­ã€‚æ•°æ®é›†Gut-VLMåŒ…å«æ ‡è¯†å¹»è§‰å¥å­åŠå…¶ä¿®æ­£çš„æ ‡ç­¾ï¼Œä¾¿äºåç»­æ¨¡å‹è®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæå‡ºäº†å¹»è§‰æ„ŸçŸ¥å¾®è°ƒç­–ç•¥ï¼ŒåŒºåˆ«äºä¼ ç»Ÿçš„ä»…ç”Ÿæˆæè¿°çš„å¾®è°ƒæ–¹æ³•ã€‚é€šè¿‡è¿™ç§ç­–ç•¥ï¼Œæ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°è¯†åˆ«å’Œçº æ­£ç”Ÿæˆä¸­çš„å¹»è§‰ï¼Œæé«˜äº†ç”ŸæˆæŠ¥å‘Šçš„ä¸´åºŠå¯é æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥æƒ©ç½šå¹»è§‰ç”Ÿæˆï¼Œå¹¶è®¾è®¡äº†å¤šå±‚æ¬¡çš„è¯„ä¼°æŒ‡æ ‡ï¼Œä»¥å…¨é¢è¯„ä¼°æ¨¡å‹åœ¨å¹»è§‰æ£€æµ‹å’ŒæŠ¥å‘Šç”Ÿæˆä¸Šçš„æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œé‡‡ç”¨å¹»è§‰æ„ŸçŸ¥å¾®è°ƒæ–¹æ³•çš„æ¨¡å‹åœ¨å¤šä¸ªè¯„ä¼°æŒ‡æ ‡ä¸Šå‡ä¼˜äºä¼ ç»Ÿå¾®è°ƒæ–¹æ³•ï¼Œå…·ä½“æ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°15%-20%ã€‚è¯¥ç ”ç©¶ä¸ºVLMåœ¨åŒ»å­¦é¢†åŸŸçš„åº”ç”¨æä¾›äº†æ–°çš„åŸºå‡†å’Œæ–¹å‘ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŒ»ç–—å½±åƒåˆ†æã€ä¸´åºŠå†³ç­–æ”¯æŒç³»ç»Ÿç­‰ã€‚é€šè¿‡æé«˜VLMåœ¨ç”ŸæˆåŒ»å­¦æŠ¥å‘Šæ—¶çš„å‡†ç¡®æ€§å’Œå¯é æ€§ï¼Œèƒ½å¤Ÿæœ‰æ•ˆè¾…åŠ©åŒ»ç”Ÿçš„è¯Šæ–­è¿‡ç¨‹ï¼Œæå‡åŒ»ç–—æœåŠ¡è´¨é‡ï¼Œæœªæ¥å¯èƒ½åœ¨æ™ºèƒ½åŒ»ç–—é¢†åŸŸäº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision-Language Models (VLMs) are becoming increasingly popular in the medical domain, bridging the gap between medical images and clinical language. Existing VLMs demonstrate an impressive ability to comprehend medical images and text queries to generate detailed, descriptive diagnostic medical reports. However, hallucination--the tendency to generate descriptions that are inconsistent with the visual content--remains a significant issue in VLMs, with particularly severe implications in the medical field. To facilitate VLM research on gastrointestinal (GI) image analysis and study hallucination, we curate a multimodal image-text GI dataset: Gut-VLM. This dataset is created using a two-stage pipeline: first, descriptive medical reports of Kvasir-v2 images are generated using ChatGPT, which introduces some hallucinated or incorrect texts. In the second stage, medical experts systematically review these reports, and identify and correct potential inaccuracies to ensure high-quality, clinically reliable annotations. Unlike traditional datasets that contain only descriptive texts, our dataset also features tags identifying hallucinated sentences and their corresponding corrections. A common approach to reducing hallucination in VLM is to finetune the model on a small-scale, problem-specific dataset. However, we take a different strategy using our dataset. Instead of finetuning the VLM solely for generating textual reports, we finetune it to detect and correct hallucinations, an approach we call hallucination-aware finetuning. Our results show that this approach is better than simply finetuning for descriptive report generation. Additionally, we conduct an extensive evaluation of state-of-the-art VLMs across several metrics, establishing a benchmark. GitHub Repo: https://github.com/bhattarailab/Hallucination-Aware-VLM.

