---
layout: default
title: LongVie 2: Multimodal Controllable Ultra-Long Video World Model
---

# LongVie 2: Multimodal Controllable Ultra-Long Video World Model

**arXiv**: [2512.13604v1](https://arxiv.org/abs/2512.13604) | [PDF](https://arxiv.org/pdf/2512.13604.pdf)

**ä½œè€…**: Jianxiong Gao, Zhaoxi Chen, Xian Liu, Junhao Zhuang, Chengming Xu, Jianfeng Feng, Yu Qiao, Yanwei Fu, Chenyang Si, Ziwei Liu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-15

**å¤‡æ³¨**: Project Page: https://vchitect.github.io/LongVie2-project/

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**LongVie 2ï¼šå¤šæ¨¡æ€å¯æŽ§è¶…é•¿è§†é¢‘ä¸–ç•Œæ¨¡åž‹ï¼Œå®žçŽ°é«˜è´¨é‡é•¿æ—¶åºè§†é¢‘ç”Ÿæˆã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `è§†é¢‘ä¸–ç•Œæ¨¡åž‹` `é•¿è§†é¢‘ç”Ÿæˆ` `å¤šæ¨¡æ€æŽ§åˆ¶` `è‡ªå›žå½’æ¨¡åž‹` `æ—¶é—´ä¸€è‡´æ€§` `è§†è§‰è´¨é‡` `å¯æŽ§è§†é¢‘ç”Ÿæˆ` `è§†é¢‘ç”ŸæˆåŸºå‡†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è§†é¢‘ä¸–ç•Œæ¨¡åž‹åœ¨å¯æŽ§æ€§ã€é•¿æœŸè§†è§‰è´¨é‡å’Œæ—¶é—´ä¸€è‡´æ€§æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ï¼Œéš¾ä»¥ç”Ÿæˆé«˜è´¨é‡é•¿æ—¶åºè§†é¢‘ã€‚
2. LongVie 2é€šè¿‡å¤šæ¨¡æ€æŒ‡å¯¼å¢žå¼ºå¯æŽ§æ€§ï¼Œé€€åŒ–æ„ŸçŸ¥è®­ç»ƒä¿æŒè§†è§‰è´¨é‡ï¼ŒåŽ†å²ä¸Šä¸‹æ–‡æŒ‡å¯¼ç¡®ä¿æ—¶é—´ä¸€è‡´æ€§ã€‚
3. LongVie 2åœ¨LongVGenBenchåŸºå‡†æµ‹è¯•ä¸­è¡¨çŽ°å‡ºè‰²ï¼Œå®žçŽ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶æ”¯æŒé•¿è¾¾äº”åˆ†é’Ÿçš„è¿žç»­è§†é¢‘ç”Ÿæˆã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æž„å»ºäºŽé¢„è®­ç»ƒè§†é¢‘ç”Ÿæˆç³»ç»Ÿä¹‹ä¸Šçš„è§†é¢‘ä¸–ç•Œæ¨¡åž‹æ˜¯é€šå¾€é€šç”¨æ—¶ç©ºæ™ºèƒ½çš„é‡è¦ä¸€æ­¥ï¼Œä½†ä¹Ÿæžå…·æŒ‘æˆ˜ã€‚ä¸€ä¸ªä¸–ç•Œæ¨¡åž‹åº”å…·å¤‡ä¸‰ä¸ªåŸºæœ¬å±žæ€§ï¼šå¯æŽ§æ€§ã€é•¿æœŸè§†è§‰è´¨é‡å’Œæ—¶é—´ä¸€è‡´æ€§ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬é‡‡å–äº†ä¸€ç§æ¸è¿›å¼çš„æ–¹æ³•â€”â€”é¦–å…ˆå¢žå¼ºå¯æŽ§æ€§ï¼Œç„¶åŽæ‰©å±•åˆ°é•¿æœŸã€é«˜è´¨é‡çš„ç”Ÿæˆã€‚æˆ‘ä»¬æå‡ºäº†LongVie 2ï¼Œä¸€ä¸ªç«¯åˆ°ç«¯çš„è‡ªå›žå½’æ¡†æž¶ï¼Œé€šè¿‡ä¸‰ä¸ªé˜¶æ®µè¿›è¡Œè®­ç»ƒï¼šï¼ˆ1ï¼‰å¤šæ¨¡æ€æŒ‡å¯¼ï¼Œæ•´åˆå¯†é›†å’Œç¨€ç–æŽ§åˆ¶ä¿¡å·ï¼Œæä¾›éšå¼çš„ä¸–ç•Œçº§ç›‘ç£ï¼Œå¹¶æé«˜å¯æŽ§æ€§ï¼›ï¼ˆ2ï¼‰è¾“å…¥å¸§ä¸Šçš„é€€åŒ–æ„ŸçŸ¥è®­ç»ƒï¼Œå¼¥åˆè®­ç»ƒå’Œé•¿æœŸæŽ¨ç†ä¹‹é—´çš„å·®è·ï¼Œä»¥ä¿æŒé«˜è§†è§‰è´¨é‡ï¼›ï¼ˆ3ï¼‰åŽ†å²ä¸Šä¸‹æ–‡æŒ‡å¯¼ï¼Œå¯¹é½ç›¸é‚»ç‰‡æ®µä¹‹é—´çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»¥ç¡®ä¿æ—¶é—´ä¸€è‡´æ€§ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥æŽ¨å‡ºäº†LongVGenBenchï¼Œä¸€ä¸ªåŒ…å«100ä¸ªé«˜åˆ†è¾¨çŽ‡ä¸€åˆ†é’Ÿè§†é¢‘çš„ç»¼åˆåŸºå‡†ï¼Œæ¶µç›–äº†å„ç§çœŸå®žå’ŒåˆæˆçŽ¯å¢ƒã€‚å¤§é‡å®žéªŒè¡¨æ˜Žï¼ŒLongVie 2åœ¨é•¿ç¨‹å¯æŽ§æ€§ã€æ—¶é—´è¿žè´¯æ€§å’Œè§†è§‰ä¿çœŸåº¦æ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶æ”¯æŒé•¿è¾¾äº”åˆ†é’Ÿçš„è¿žç»­è§†é¢‘ç”Ÿæˆï¼Œæ ‡å¿—ç€æœç€ç»Ÿä¸€è§†é¢‘ä¸–ç•Œå»ºæ¨¡è¿ˆå‡ºäº†é‡è¦ä¸€æ­¥ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è§†é¢‘ä¸–ç•Œæ¨¡åž‹åœ¨ç”Ÿæˆé•¿æ—¶åºè§†é¢‘æ—¶é¢ä¸´çš„å¯æŽ§æ€§å·®ã€è§†è§‰è´¨é‡ä¸‹é™ä»¥åŠæ—¶é—´ä¸€è‡´æ€§éš¾ä»¥ä¿æŒçš„é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•é€šå¸¸éš¾ä»¥åŒæ—¶å…¼é¡¾è¿™ä¸‰ä¸ªæ–¹é¢ï¼Œå°¤å…¶æ˜¯åœ¨ç”Ÿæˆè¶…é•¿è§†é¢‘æ—¶ï¼Œé—®é¢˜ä¼šæ›´åŠ çªå‡ºã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šLongVie 2çš„æ ¸å¿ƒæ€è·¯æ˜¯é‡‡ç”¨ä¸€ç§æ¸è¿›å¼çš„è®­ç»ƒç­–ç•¥ï¼Œåˆ†é˜¶æ®µåœ°è§£å†³å¯æŽ§æ€§ã€è§†è§‰è´¨é‡å’Œæ—¶é—´ä¸€è‡´æ€§é—®é¢˜ã€‚é¦–å…ˆé€šè¿‡å¤šæ¨¡æ€æŒ‡å¯¼å¢žå¼ºæ¨¡åž‹çš„å¯æŽ§æ€§ï¼Œç„¶åŽé€šè¿‡é€€åŒ–æ„ŸçŸ¥è®­ç»ƒæ¥æå‡é•¿æœŸè§†è§‰è´¨é‡ï¼Œæœ€åŽé€šè¿‡åŽ†å²ä¸Šä¸‹æ–‡æŒ‡å¯¼æ¥ä¿è¯æ—¶é—´ä¸€è‡´æ€§ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šLongVie 2æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„è‡ªå›žå½’æ¡†æž¶ï¼ŒåŒ…å«ä¸‰ä¸ªä¸»è¦çš„è®­ç»ƒé˜¶æ®µï¼š
1. **å¤šæ¨¡æ€æŒ‡å¯¼**ï¼šæ•´åˆå¯†é›†å’Œç¨€ç–æŽ§åˆ¶ä¿¡å·ï¼Œä¾‹å¦‚è¯­ä¹‰åˆ†å‰²å›¾ã€åŠ¨ä½œæŒ‡ä»¤ç­‰ï¼Œä¸ºè§†é¢‘ç”Ÿæˆæä¾›æ›´ä¸°å¯Œçš„æŽ§åˆ¶ä¿¡æ¯ã€‚
2. **é€€åŒ–æ„ŸçŸ¥è®­ç»ƒ**ï¼šé€šè¿‡åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ¨¡æ‹Ÿè§†é¢‘å¸§çš„é€€åŒ–çŽ°è±¡ï¼Œä¾‹å¦‚æ¨¡ç³Šã€å™ªå£°ç­‰ï¼Œæ¥æé«˜æ¨¡åž‹åœ¨é•¿æœŸæŽ¨ç†è¿‡ç¨‹ä¸­çš„é²æ£’æ€§ï¼Œä»Žè€Œä¿æŒè§†è§‰è´¨é‡ã€‚
3. **åŽ†å²ä¸Šä¸‹æ–‡æŒ‡å¯¼**ï¼šåˆ©ç”¨ç›¸é‚»è§†é¢‘ç‰‡æ®µçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä¾‹å¦‚å‰ä¸€å¸§çš„éšè—çŠ¶æ€ï¼Œæ¥æŒ‡å¯¼å½“å‰å¸§çš„ç”Ÿæˆï¼Œä»Žè€Œä¿è¯æ—¶é—´ä¸€è‡´æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šLongVie 2çš„å…³é”®åˆ›æ–°åœ¨äºŽå…¶ç»¼åˆåˆ©ç”¨äº†å¤šæ¨¡æ€ä¿¡æ¯ã€é€€åŒ–æ„ŸçŸ¥è®­ç»ƒå’ŒåŽ†å²ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»Žè€Œåœ¨å¯æŽ§æ€§ã€è§†è§‰è´¨é‡å’Œæ—¶é—´ä¸€è‡´æ€§æ–¹é¢éƒ½å–å¾—äº†æ˜¾è‘—çš„æå‡ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒLongVie 2èƒ½å¤Ÿç”Ÿæˆæ›´é•¿ã€æ›´é€¼çœŸã€æ›´å¯æŽ§çš„è§†é¢‘ã€‚

**å…³é”®è®¾è®¡**ï¼š
* **å¤šæ¨¡æ€èžåˆ**ï¼šé‡‡ç”¨æ³¨æ„åŠ›æœºåˆ¶å°†ä¸åŒæ¨¡æ€çš„æŽ§åˆ¶ä¿¡å·èžåˆåˆ°è§†é¢‘ç”Ÿæˆè¿‡ç¨‹ä¸­ã€‚
* **é€€åŒ–æ¨¡åž‹**ï¼šè®¾è®¡å¤šç§é€€åŒ–æ¨¡åž‹æ¥æ¨¡æ‹ŸçœŸå®žè§†é¢‘ä¸­å¯èƒ½å‡ºçŽ°çš„å„ç§é€€åŒ–çŽ°è±¡ã€‚
* **æŸå¤±å‡½æ•°**ï¼šé‡‡ç”¨å¯¹æŠ—æŸå¤±ã€æ„ŸçŸ¥æŸå¤±å’Œæ—¶é—´ä¸€è‡´æ€§æŸå¤±ç­‰å¤šç§æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ¨¡åž‹ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

LongVie 2åœ¨LongVGenBenchåŸºå‡†æµ‹è¯•ä¸­ï¼Œç›¸æ¯”çŽ°æœ‰æ–¹æ³•ï¼Œåœ¨é•¿ç¨‹å¯æŽ§æ€§ã€æ—¶é—´è¿žè´¯æ€§å’Œè§†è§‰ä¿çœŸåº¦æ–¹é¢å‡å–å¾—äº†æ˜¾è‘—æå‡ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒLongVie 2èƒ½å¤Ÿç”Ÿæˆé•¿è¾¾äº”åˆ†é’Ÿçš„è¿žç»­è§†é¢‘ï¼Œå¹¶ä¸”åœ¨è§†è§‰è´¨é‡å’Œæ—¶é—´ä¸€è‡´æ€§æ–¹é¢è¡¨çŽ°å‡ºè‰²ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

LongVie 2åœ¨æ¸¸æˆå¼€å‘ã€ç”µå½±åˆ¶ä½œã€è™šæ‹ŸçŽ°å®žã€æœºå™¨äººæŽ§åˆ¶ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥ç”¨äºŽç”Ÿæˆé€¼çœŸçš„æ¸¸æˆåœºæ™¯ã€åˆ›å»ºé«˜è´¨é‡çš„ç”µå½±ç‰¹æ•ˆã€æž„å»ºæ²‰æµ¸å¼çš„è™šæ‹ŸçŽ°å®žä½“éªŒï¼Œä»¥åŠè®­ç»ƒæœºå™¨äººåœ¨å¤æ‚çŽ¯å¢ƒä¸­çš„è¡Œä¸ºã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Building video world models upon pretrained video generation systems represents an important yet challenging step toward general spatiotemporal intelligence. A world model should possess three essential properties: controllability, long-term visual quality, and temporal consistency. To this end, we take a progressive approach-first enhancing controllability and then extending toward long-term, high-quality generation. We present LongVie 2, an end-to-end autoregressive framework trained in three stages: (1) Multi-modal guidance, which integrates dense and sparse control signals to provide implicit world-level supervision and improve controllability; (2) Degradation-aware training on the input frame, bridging the gap between training and long-term inference to maintain high visual quality; and (3) History-context guidance, which aligns contextual information across adjacent clips to ensure temporal consistency. We further introduce LongVGenBench, a comprehensive benchmark comprising 100 high-resolution one-minute videos covering diverse real-world and synthetic environments. Extensive experiments demonstrate that LongVie 2 achieves state-of-the-art performance in long-range controllability, temporal coherence, and visual fidelity, and supports continuous video generation lasting up to five minutes, marking a significant step toward unified video world modeling.

