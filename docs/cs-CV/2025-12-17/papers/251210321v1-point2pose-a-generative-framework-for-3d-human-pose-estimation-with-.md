---
layout: default
title: Point2Pose: A Generative Framework for 3D Human Pose Estimation with Multi-View Point Cloud Dataset
---

# Point2Pose: A Generative Framework for 3D Human Pose Estimation with Multi-View Point Cloud Dataset

**arXiv**: [2512.10321v1](https://arxiv.org/abs/2512.10321) | [PDF](https://arxiv.org/pdf/2512.10321.pdf)

**ä½œè€…**: Hyunsoo Lee, Daeum Jeon, Hyeokjae Oh

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-11

**å¤‡æ³¨**: WACV 2026 camera ready

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Point2Poseï¼šæå‡ºä¸€ç§åŸºäºŽå¤šè§†è§’ç‚¹äº‘æ•°æ®é›†çš„3Däººä½“å§¿æ€ä¼°è®¡ç”Ÿæˆæ¡†æž¶**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `3Däººä½“å§¿æ€ä¼°è®¡` `ç”Ÿæˆæ¨¡åž‹` `ç‚¹äº‘å¤„ç†` `æ³¨æ„åŠ›æœºåˆ¶` `æ—¶ç©ºå»ºæ¨¡` `å¤šè§†è§’æ•°æ®` `æ·±åº¦å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. 3Däººä½“å§¿æ€ä¼°è®¡é¢ä¸´äººä½“å‡ ä½•å¤æ‚ã€å…³èŠ‚è‡ªé®æŒ¡ä»¥åŠç¼ºä¹å¤§è§„æ¨¡çœŸå®žè¿åŠ¨æ•°æ®é›†ç­‰æŒ‘æˆ˜ã€‚
2. Point2Poseé€šè¿‡æ—¶ç©ºç‚¹äº‘ç¼–ç å™¨å’Œå§¿æ€ç‰¹å¾ç¼–ç å™¨æå–ç‰¹å¾ï¼Œå¹¶ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶çš„ç”Ÿæˆå¼å›žå½’å™¨å»ºæ¨¡å§¿æ€åˆ†å¸ƒã€‚
3. æå‡ºçš„MVPose3Dæ•°æ®é›†åŒ…å«IMUæ•°æ®ã€å¤šè§†è§’ç‚¹äº‘å’ŒRGBå›¾åƒï¼Œå®žéªŒç»“æžœè¡¨æ˜Žè¯¥æ–¹æ³•ä¼˜äºŽçŽ°æœ‰åŸºçº¿æ¨¡åž‹ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç”Ÿæˆå¼æ–¹æ³•ç”¨äºŽ3Däººä½“å§¿æ€ä¼°è®¡ã€‚ç”±äºŽäººä½“å¤æ‚çš„å‡ ä½•ç»“æž„ã€å…³èŠ‚çš„è‡ªé®æŒ¡ä»¥åŠå¯¹å¤§è§„æ¨¡çœŸå®žä¸–ç•Œè¿åŠ¨æ•°æ®é›†çš„éœ€æ±‚ï¼Œ3Däººä½“å§¿æ€ä¼°è®¡é¢ä¸´ç€å‡ ä¸ªå…³é”®æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†Point2Poseï¼Œè¯¥æ¡†æž¶æœ‰æ•ˆåœ°å»ºæ¨¡äº†ä»¥è¿žç»­ç‚¹äº‘å’Œå§¿æ€åŽ†å²ä¸ºæ¡ä»¶çš„äººä½“å§¿æ€åˆ†å¸ƒã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é‡‡ç”¨æ—¶ç©ºç‚¹äº‘ç¼–ç å™¨å’Œå§¿æ€ç‰¹å¾ç¼–ç å™¨æ¥æå–å…³èŠ‚ç›¸å…³çš„ç‰¹å¾ï¼Œç„¶åŽä½¿ç”¨åŸºäºŽæ³¨æ„åŠ›çš„ç”Ÿæˆå¼å›žå½’å™¨ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå¤§è§„æ¨¡å®¤å†…æ•°æ®é›†MVPose3Dï¼Œå…¶ä¸­åŒ…å«å¤šç§æ¨¡æ€ï¼ŒåŒ…æ‹¬éžå¹³å‡¡äººä½“è¿åŠ¨çš„IMUæ•°æ®ã€å¯†é›†çš„å¤šè§†è§’ç‚¹äº‘å’ŒRGBå›¾åƒã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼Œæ‰€æå‡ºçš„æ–¹æ³•ä¼˜äºŽåŸºçº¿æ¨¡åž‹ï¼Œè¯æ˜Žäº†å…¶åœ¨å„ç§æ•°æ®é›†ä¸Šçš„å“è¶Šæ€§èƒ½ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³3Däººä½“å§¿æ€ä¼°è®¡é—®é¢˜ï¼ŒçŽ°æœ‰æ–¹æ³•éš¾ä»¥å¤„ç†äººä½“å¤æ‚çš„å‡ ä½•ç»“æž„ã€å…³èŠ‚è‡ªé®æŒ¡ä»¥åŠç¼ºä¹å¤§è§„æ¨¡çœŸå®žä¸–ç•Œè¿åŠ¨æ•°æ®é›†çš„é—®é¢˜ã€‚è¿™äº›é—®é¢˜å¯¼è‡´å§¿æ€ä¼°è®¡ç²¾åº¦ä¸é«˜ï¼Œé²æ£’æ€§è¾ƒå·®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨ç”Ÿæˆæ¨¡åž‹ï¼Œå°†3Däººä½“å§¿æ€ä¼°è®¡é—®é¢˜è½¬åŒ–ä¸ºä¸€ä¸ªæ¡ä»¶ç”Ÿæˆé—®é¢˜ã€‚é€šè¿‡å»ºæ¨¡ä»¥è¿žç»­ç‚¹äº‘å’Œå§¿æ€åŽ†å²ä¸ºæ¡ä»¶çš„äººä½“å§¿æ€åˆ†å¸ƒï¼Œå¯ä»¥æ›´å¥½åœ°åˆ©ç”¨æ—¶ç©ºä¿¡æ¯ï¼Œä»Žè€Œæé«˜å§¿æ€ä¼°è®¡çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šPoint2Poseæ¡†æž¶ä¸»è¦åŒ…å«ä¸‰ä¸ªæ¨¡å—ï¼šæ—¶ç©ºç‚¹äº‘ç¼–ç å™¨ã€å§¿æ€ç‰¹å¾ç¼–ç å™¨å’ŒåŸºäºŽæ³¨æ„åŠ›çš„ç”Ÿæˆå¼å›žå½’å™¨ã€‚é¦–å…ˆï¼Œæ—¶ç©ºç‚¹äº‘ç¼–ç å™¨ç”¨äºŽæå–ç‚¹äº‘åºåˆ—ä¸­çš„æ—¶ç©ºç‰¹å¾ï¼›ç„¶åŽï¼Œå§¿æ€ç‰¹å¾ç¼–ç å™¨ç”¨äºŽæå–åŽ†å²å§¿æ€çš„ç‰¹å¾ï¼›æœ€åŽï¼ŒåŸºäºŽæ³¨æ„åŠ›çš„ç”Ÿæˆå¼å›žå½’å™¨å°†æå–çš„ç‰¹å¾èžåˆï¼Œå¹¶ç”Ÿæˆå½“å‰æ—¶åˆ»çš„3Däººä½“å§¿æ€ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•çš„ä¸»è¦åˆ›æ–°åœ¨äºŽæå‡ºäº†ä¸€ä¸ªåŸºäºŽç”Ÿæˆæ¨¡åž‹çš„3Däººä½“å§¿æ€ä¼°è®¡æ¡†æž¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°å»ºæ¨¡äººä½“å§¿æ€çš„åˆ†å¸ƒï¼Œå¹¶åˆ©ç”¨æ—¶ç©ºä¿¡æ¯æé«˜ä¼°è®¡ç²¾åº¦ã€‚æ­¤å¤–ï¼Œæå‡ºçš„æ³¨æ„åŠ›æœºåˆ¶èƒ½å¤Ÿæ›´å¥½åœ°å…³æ³¨å…³é”®å…³èŠ‚ï¼Œä»Žè€Œæé«˜ä¼°è®¡çš„é²æ£’æ€§ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†è‡ªé®æŒ¡å’Œå™ªå£°ç­‰é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šæ—¶ç©ºç‚¹äº‘ç¼–ç å™¨é‡‡ç”¨PointNet++ç½‘ç»œç»“æž„ï¼Œç”¨äºŽæå–ç‚¹äº‘ç‰¹å¾ã€‚å§¿æ€ç‰¹å¾ç¼–ç å™¨é‡‡ç”¨LSTMç½‘ç»œç»“æž„ï¼Œç”¨äºŽæå–åŽ†å²å§¿æ€çš„æ—¶åºç‰¹å¾ã€‚æ³¨æ„åŠ›æœºåˆ¶é‡‡ç”¨Transformerç»“æž„ï¼Œç”¨äºŽèžåˆç‚¹äº‘ç‰¹å¾å’Œå§¿æ€ç‰¹å¾ã€‚æŸå¤±å‡½æ•°é‡‡ç”¨å‡æ–¹è¯¯å·®æŸå¤±å‡½æ•°ï¼Œç”¨äºŽè¡¡é‡ä¼°è®¡å§¿æ€ä¸ŽçœŸå®žå§¿æ€ä¹‹é—´çš„å·®å¼‚ã€‚æ•°æ®é›†MVPose3DåŒ…å«å¤šç§æ¨¡æ€æ•°æ®ï¼Œä¸ºæ¨¡åž‹çš„è®­ç»ƒæä¾›äº†ä¸°å¯Œçš„ä¿¡æ¯ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒPoint2Poseåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šä¼˜äºŽçŽ°æœ‰çš„åŸºçº¿æ¨¡åž‹ã€‚å°¤å…¶æ˜¯åœ¨MVPose3Dæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¯æ˜Žäº†å…¶åœ¨å¤„ç†å¤æ‚åœºæ™¯å’Œå¤šæ¨¡æ€æ•°æ®æ–¹é¢çš„ä¼˜åŠ¿ã€‚å…·ä½“æ€§èƒ½æ•°æ®æœªçŸ¥ï¼Œä½†è®ºæ–‡å¼ºè°ƒäº†ä¼˜äºŽåŸºçº¿æ¨¡åž‹ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽäººæœºäº¤äº’ã€è™šæ‹ŸçŽ°å®žã€è¿åŠ¨åˆ†æžã€æ™ºèƒ½ç›‘æŽ§ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨è™šæ‹ŸçŽ°å®žä¸­ï¼Œå¯ä»¥åˆ©ç”¨è¯¥æ–¹æ³•å®žçŽ°æ›´è‡ªç„¶ã€æ›´é€¼çœŸçš„äººä½“å§¿æ€æ•æ‰ï¼›åœ¨è¿åŠ¨åˆ†æžä¸­ï¼Œå¯ä»¥åˆ©ç”¨è¯¥æ–¹æ³•åˆ†æžè¿åŠ¨å‘˜çš„åŠ¨ä½œï¼Œæé«˜è®­ç»ƒæ•ˆæžœï¼›åœ¨æ™ºèƒ½ç›‘æŽ§ä¸­ï¼Œå¯ä»¥åˆ©ç”¨è¯¥æ–¹æ³•è¯†åˆ«å¼‚å¸¸è¡Œä¸ºï¼Œæé«˜å®‰å…¨æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We propose a novel generative approach for 3D human pose estimation. 3D human pose estimation poses several key challenges due to the complex geometry of the human body, self-occluding joints, and the requirement for large-scale real-world motion datasets. To address these challenges, we introduce Point2Pose, a framework that effectively models the distribution of human poses conditioned on sequential point cloud and pose history. Specifically, we employ a spatio-temporal point cloud encoder and a pose feature encoder to extract joint-wise features, followed by an attention-based generative regressor. Additionally, we present a large-scale indoor dataset MVPose3D, which contains multiple modalities, including IMU data of non-trivial human motions, dense multi-view point clouds, and RGB images. Experimental results show that the proposed method outperforms the baseline models, demonstrating its superior performance across various datasets.

