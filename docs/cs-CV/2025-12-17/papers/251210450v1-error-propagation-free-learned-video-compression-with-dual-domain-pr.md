---
layout: default
title: Error-Propagation-Free Learned Video Compression With Dual-Domain Progressive Temporal Alignment
---

# Error-Propagation-Free Learned Video Compression With Dual-Domain Progressive Temporal Alignment

**arXiv**: [2512.10450v1](https://arxiv.org/abs/2512.10450) | [PDF](https://arxiv.org/pdf/2512.10450.pdf)

**ä½œè€…**: Han Li, Shaohui Li, Wenrui Dai, Chenglin Li, Xinlong Pan, Haipeng Wang, Junni Zou, Hongkai Xiong

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-11

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŒåŸŸæ¸è¿›å¼æ—¶åºå¯¹é½çš„æ— è¯¯å·®ä¼ æ’­å­¦ä¹ è§†é¢‘åŽ‹ç¼©æ¡†æž¶**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `è§†é¢‘åŽ‹ç¼©` `å­¦ä¹ è§†é¢‘åŽ‹ç¼©` `è¿åŠ¨ä¼°è®¡` `æ—¶åºå¯¹é½` `å¯å˜å½¢Transformer` `ç çŽ‡æŽ§åˆ¶` `æ— è¯¯å·®ä¼ æ’­` `è´¨é‡æ¡ä»¶æ··åˆä¸“å®¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰å­¦ä¹ è§†é¢‘åŽ‹ç¼©æ–¹æ³•åœ¨æ—¶åºå¯¹é½ç²¾åº¦å’Œè¯¯å·®ä¼ æ’­æŽ§åˆ¶é—´å­˜åœ¨çŸ›ç›¾ï¼Œå½±å“åŽ‹ç¼©æ€§èƒ½ã€‚
2. æå‡ºåŒåŸŸæ¸è¿›å¼æ—¶åºå¯¹é½ï¼Œç»“åˆåƒç´ åŸŸå’Œæ½œåœ¨åŸŸçš„è¿åŠ¨ä¼°è®¡ï¼Œæå‡æ—¶åºå»ºæ¨¡èƒ½åŠ›ã€‚
3. è®¾è®¡è´¨é‡æ¡ä»¶æ··åˆä¸“å®¶æ¨¡å—ï¼Œå®žçŽ°è¿žç»­æ¯”ç‰¹çŽ‡è‡ªé€‚åº”ï¼Œå¹¶åœ¨çŽ‡å¤±çœŸæ€§èƒ½ä¸Šå–å¾—ç«žäº‰ä¼˜åŠ¿ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

çŽ°æœ‰çš„å­¦ä¹ è§†é¢‘åŽ‹ç¼©æ¡†æž¶åœ¨è¿åŠ¨ä¼°è®¡å’Œè¡¥å¿ï¼ˆME/MCï¼‰æ–¹é¢é¢ä¸´ç€ä¸å‡†ç¡®çš„æ—¶åºå¯¹é½å’Œè¯¯å·®ä¼ æ’­ä¹‹é—´çš„ä¸¤éš¾é€‰æ‹©ã€‚åˆ†ç¦»å˜æ¢æ¡†æž¶å¯¹å¸§å†…å’Œå¸§é—´åŽ‹ç¼©é‡‡ç”¨ä¸åŒçš„å˜æ¢ï¼Œä»Žè€Œäº§ç”Ÿä»¤äººå°è±¡æ·±åˆ»çš„çŽ‡å¤±çœŸï¼ˆR-Dï¼‰æ€§èƒ½ï¼Œä½†ä¼šå¯¼è‡´æ˜Žæ˜¾çš„è¯¯å·®ä¼ æ’­ï¼Œè€Œç»Ÿä¸€å˜æ¢æ¡†æž¶é€šè¿‡å…±äº«å˜æ¢æ¶ˆé™¤è¯¯å·®ä¼ æ’­ï¼Œä½†åœ¨å…±äº«æ½œåœ¨åŸŸä¸­çš„ME/MCæ–¹é¢è¡¨çŽ°è¾ƒå·®ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé™åˆ¶ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ç»Ÿä¸€å˜æ¢æ¡†æž¶ï¼Œè¯¥æ¡†æž¶å…·æœ‰åŒåŸŸæ¸è¿›å¼æ—¶åºå¯¹é½å’Œè´¨é‡æ¡ä»¶æ··åˆä¸“å®¶ï¼ˆQCMoEï¼‰ï¼Œä»Žè€Œä¸ºå­¦ä¹ è§†é¢‘åŽ‹ç¼©å®žçŽ°è´¨é‡ä¸€è‡´ä¸”æ— è¯¯å·®ä¼ æ’­çš„æµå¼ä¼ è¾“ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æå‡ºäº†ç”¨äºŽME/MCçš„åŒåŸŸæ¸è¿›å¼æ—¶åºå¯¹é½ï¼Œè¯¥å¯¹é½åˆ©ç”¨ç²—ç•¥çš„åƒç´ åŸŸå¯¹é½å’Œç²¾ç»†çš„æ½œåœ¨åŸŸå¯¹é½ï¼Œä»¥ç²—åˆ°ç²¾çš„æ–¹å¼æ˜¾ç€å¢žå¼ºæ—¶åºä¸Šä¸‹æ–‡å»ºæ¨¡ã€‚ç²—ç•¥çš„åƒç´ åŸŸå¯¹é½æœ‰æ•ˆåœ°å¤„ç†äº†æ¥è‡ªå•ä¸ªå‚è€ƒå¸§çš„å…‰æµä¼°è®¡çš„ç®€å•è¿åŠ¨æ¨¡å¼ï¼Œè€Œç²¾ç»†çš„æ½œåœ¨åŸŸå¯¹é½å¼€å‘äº†ä¸€ç§åŸºäºŽå¤šä¸ªå‚è€ƒå¸§çš„æ½œåœ¨å˜é‡çš„æµå¼•å¯¼å¯å˜å½¢Transformerï¼ˆFGDTï¼‰ï¼Œä»¥å®žçŽ°å¤æ‚è¿åŠ¨æ¨¡å¼çš„é•¿æœŸè¿åŠ¨ç»†åŒ–ï¼ˆLTMRï¼‰ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªQCMoEæ¨¡å—ï¼Œç”¨äºŽè¿žç»­æ¯”ç‰¹çŽ‡è‡ªé€‚åº”ï¼Œè¯¥æ¨¡å—åŠ¨æ€åœ°åˆ†é…ä¸åŒçš„ä¸“å®¶ï¼Œä»¥æ ¹æ®ç›®æ ‡è´¨é‡å’Œå†…å®¹è°ƒæ•´æ¯ä¸ªåƒç´ çš„é‡åŒ–æ­¥é•¿ï¼Œè€Œä¸æ˜¯ä¾èµ–äºŽå•ä¸ªé‡åŒ–æ­¥é•¿ã€‚QCMoEå…è®¸è¿žç»­ä¸”ä¸€è‡´çš„é€ŸçŽ‡æŽ§åˆ¶ï¼Œå¹¶å…·æœ‰å¸å¼•äººçš„R-Dæ€§èƒ½ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼Œä¸Žæœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•å®žçŽ°äº†å…·æœ‰ç«žäº‰åŠ›çš„R-Dæ€§èƒ½ï¼ŒåŒæ—¶æˆåŠŸæ¶ˆé™¤äº†è¯¯å·®ä¼ æ’­ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰å­¦ä¹ è§†é¢‘åŽ‹ç¼©æ¡†æž¶åœ¨è¿åŠ¨ä¼°è®¡å’Œè¡¥å¿(ME/MC)ä¸­é¢ä¸´ä¸¤éš¾ï¼šåˆ†ç¦»å˜æ¢æ¡†æž¶è™½ç„¶çŽ‡å¤±çœŸæ€§èƒ½å¥½ï¼Œä½†è¯¯å·®ä¼ æ’­ä¸¥é‡ï¼›ç»Ÿä¸€å˜æ¢æ¡†æž¶è™½èƒ½é¿å…è¯¯å·®ä¼ æ’­ï¼Œä½†åœ¨ME/MCä¸Šè¡¨çŽ°è¾ƒå·®ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚è¿åŠ¨åœºæ™¯ä¸‹ï¼Œéš¾ä»¥å‡†ç¡®å¯¹é½æ—¶åºä¿¡æ¯ï¼Œå¯¼è‡´åŽ‹ç¼©æ•ˆçŽ‡é™ä½Žã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒåœ¨äºŽæå‡ºä¸€ç§ç»Ÿä¸€å˜æ¢æ¡†æž¶ä¸‹çš„åŒåŸŸæ¸è¿›å¼æ—¶åºå¯¹é½æ–¹æ³•ï¼Œä»¥åŠè´¨é‡æ¡ä»¶æ··åˆä¸“å®¶æ¨¡å—ã€‚é€šè¿‡åƒç´ åŸŸçš„ç²—ç•¥å¯¹é½å’Œæ½œåœ¨åŸŸçš„ç²¾ç»†å¯¹é½ï¼Œæå‡æ—¶åºå»ºæ¨¡èƒ½åŠ›ï¼ŒåŒæ—¶åˆ©ç”¨QCMoEå®žçŽ°æ›´çµæ´»çš„ç çŽ‡æŽ§åˆ¶ï¼Œä»Žè€Œåœ¨ä¿è¯æ— è¯¯å·®ä¼ æ’­çš„å‰æä¸‹ï¼Œæé«˜åŽ‹ç¼©æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æ¡†æž¶é‡‡ç”¨ç»Ÿä¸€å˜æ¢ç»“æž„ï¼Œä¸»è¦åŒ…å«ä»¥ä¸‹æ¨¡å—ï¼š1) åƒç´ åŸŸå…‰æµä¼°è®¡ï¼šåˆ©ç”¨å•å‚è€ƒå¸§ä¼°è®¡å…‰æµï¼Œè¿›è¡Œç²—ç•¥çš„åƒç´ åŸŸå¯¹é½ã€‚2) æ½œåœ¨åŸŸæµå¼•å¯¼å¯å˜å½¢Transformer (FGDT)ï¼šåœ¨æ½œåœ¨åŸŸä¸­ï¼Œåˆ©ç”¨å¤šä¸ªå‚è€ƒå¸§çš„æ½œåœ¨å˜é‡ï¼Œé€šè¿‡FGDTè¿›è¡Œé•¿æœŸè¿åŠ¨ç»†åŒ–(LTMR)ã€‚3) è´¨é‡æ¡ä»¶æ··åˆä¸“å®¶(QCMoE)ï¼šæ ¹æ®ç›®æ ‡è´¨é‡å’Œå†…å®¹ï¼ŒåŠ¨æ€åˆ†é…ä¸åŒçš„ä¸“å®¶æ¥è°ƒæ•´é‡åŒ–æ­¥é•¿ã€‚æ•´ä¸ªæµç¨‹æ—¨åœ¨å®žçŽ°ä»Žç²—åˆ°ç²¾çš„æ—¶åºå¯¹é½ï¼Œå¹¶æ ¹æ®è´¨é‡éœ€æ±‚è¿›è¡Œçµæ´»çš„ç çŽ‡æŽ§åˆ¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šä¸»è¦åˆ›æ–°ç‚¹åœ¨äºŽåŒåŸŸæ¸è¿›å¼æ—¶åºå¯¹é½å’ŒQCMoEæ¨¡å—ã€‚åŒåŸŸå¯¹é½ç»“åˆäº†åƒç´ åŸŸå’Œæ½œåœ¨åŸŸçš„ä¼˜åŠ¿ï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å¤„ç†å¤æ‚è¿åŠ¨ã€‚QCMoEåˆ™æ‰“ç ´äº†ä¼ ç»Ÿæ–¹æ³•ä¸­å•ä¸€é‡åŒ–æ­¥é•¿çš„é™åˆ¶ï¼Œå®žçŽ°äº†æ›´ç²¾ç»†çš„ç çŽ‡æŽ§åˆ¶ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨ä¿è¯æ— è¯¯å·®ä¼ æ’­çš„åŒæ—¶ï¼Œæ˜¾è‘—æå‡äº†åŽ‹ç¼©æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šFGDTçš„å…³é”®åœ¨äºŽå¦‚ä½•å°†å…‰æµä¿¡æ¯èžå…¥åˆ°Transformerä¸­ï¼Œä»¥å¼•å¯¼æ³¨æ„åŠ›æœºåˆ¶ã€‚QCMoEçš„å…³é”®åœ¨äºŽå¦‚ä½•è®¾è®¡ä¸“å®¶ç½‘ç»œï¼Œä»¥åŠå¦‚ä½•æ ¹æ®ç›®æ ‡è´¨é‡å’Œå†…å®¹åŠ¨æ€åœ°é€‰æ‹©ä¸“å®¶ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡éœ€è¦å¹³è¡¡çŽ‡å¤±çœŸæ€§èƒ½ï¼ŒåŒæ—¶è€ƒè™‘æ¨¡åž‹çš„å¤æ‚åº¦ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨çŽ‡å¤±çœŸæ€§èƒ½ä¸Šä¸Žå½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•å…·æœ‰ç«žäº‰åŠ›ï¼ŒåŒæ—¶æˆåŠŸæ¶ˆé™¤äº†è¯¯å·®ä¼ æ’­ã€‚å…·ä½“æ€§èƒ½æ•°æ®æœªçŸ¥ï¼Œä½†æ‘˜è¦å¼ºè°ƒäº†å…¶åœ¨ä¿è¯è´¨é‡ä¸€è‡´æ€§å’Œæ— è¯¯å·®ä¼ æ’­æ–¹é¢çš„ä¼˜åŠ¿ã€‚è¯¥æ–¹æ³•ä¸ºå­¦ä¹ è§†é¢‘åŽ‹ç¼©æä¾›äº†ä¸€ç§æ–°çš„æ€è·¯ï¼Œå…·æœ‰é‡è¦çš„ç ”ç©¶ä»·å€¼ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽå„ç§è§†é¢‘æµåª’ä½“æœåŠ¡ã€è§†é¢‘ä¼šè®®ã€è¿œç¨‹ç›‘æŽ§ç­‰é¢†åŸŸã€‚é€šè¿‡æé«˜è§†é¢‘åŽ‹ç¼©æ•ˆçŽ‡ï¼Œå¯ä»¥åœ¨ç›¸åŒå¸¦å®½ä¸‹ä¼ è¾“æ›´é«˜è´¨é‡çš„è§†é¢‘ï¼Œæˆ–è€…åœ¨ç›¸åŒè´¨é‡ä¸‹èŠ‚çœå¸¦å®½æˆæœ¬ã€‚æ— è¯¯å·®ä¼ æ’­çš„ç‰¹æ€§ä½¿å¾—è¯¥æ–¹æ³•å°¤å…¶é€‚ç”¨äºŽå¯¹è§†é¢‘è´¨é‡è¦æ±‚è¾ƒé«˜çš„åº”ç”¨åœºæ™¯ï¼Œä¾‹å¦‚åŒ»ç–—å½±åƒã€å·¥ä¸šæ£€æµ‹ç­‰ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Existing frameworks for learned video compression suffer from a dilemma between inaccurate temporal alignment and error propagation for motion estimation and compensation (ME/MC). The separate-transform framework employs distinct transforms for intra-frame and inter-frame compression to yield impressive rate-distortion (R-D) performance but causes evident error propagation, while the unified-transform framework eliminates error propagation via shared transforms but is inferior in ME/MC in shared latent domains. To address this limitation, in this paper, we propose a novel unifiedtransform framework with dual-domain progressive temporal alignment and quality-conditioned mixture-of-expert (QCMoE) to enable quality-consistent and error-propagation-free streaming for learned video compression. Specifically, we propose dualdomain progressive temporal alignment for ME/MC that leverages coarse pixel-domain alignment and refined latent-domain alignment to significantly enhance temporal context modeling in a coarse-to-fine fashion. The coarse pixel-domain alignment efficiently handles simple motion patterns with optical flow estimated from a single reference frame, while the refined latent-domain alignment develops a Flow-Guided Deformable Transformer (FGDT) over latents from multiple reference frames to achieve long-term motion refinement (LTMR) for complex motion patterns. Furthermore, we design a QCMoE module for continuous bit-rate adaptation that dynamically assigns different experts to adjust quantization steps per pixel based on target quality and content rather than relies on a single quantization step. QCMoE allows continuous and consistent rate control with appealing R-D performance. Experimental results show that the proposed method achieves competitive R-D performance compared with the state-of-the-arts, while successfully eliminating error propagation.

