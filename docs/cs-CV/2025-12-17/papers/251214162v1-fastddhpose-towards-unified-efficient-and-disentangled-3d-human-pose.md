---
layout: default
title: FastDDHPose: Towards Unified, Efficient, and Disentangled 3D Human Pose Estimation
---

# FastDDHPose: Towards Unified, Efficient, and Disentangled 3D Human Pose Estimation

**arXiv**: [2512.14162v1](https://arxiv.org/abs/2512.14162) | [PDF](https://arxiv.org/pdf/2512.14162.pdf)

**ä½œè€…**: Qingyuan Cai, Linxin Zhang, Xuecai Hu, Saihui Hou, Yongzhen Huang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**ðŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Andyen512/Fast3DHPE)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**FastDDHPoseï¼šç»Ÿä¸€ã€é«˜æ•ˆã€è§£è€¦çš„3Däººä½“å§¿æ€ä¼°è®¡æ–¹æ³•**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `3Däººä½“å§¿æ€ä¼°è®¡` `æ‰©æ•£æ¨¡åž‹` `è§£è€¦è¡¨ç¤º` `è¿åŠ¨å­¦å±‚çº§` `å•ç›®è§†è§‰`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰3Däººä½“å§¿æ€ä¼°è®¡æ–¹æ³•ç¼ºä¹ç»Ÿä¸€çš„è®­ç»ƒå’Œè¯„ä¼°æ¡†æž¶ï¼Œéš¾ä»¥è¿›è¡Œå…¬å¹³æ¯”è¾ƒï¼Œä¸”è®­ç»ƒæ•ˆçŽ‡æœ‰å¾…æé«˜ã€‚
2. FastDDHPoseåˆ©ç”¨æ‰©æ•£æ¨¡åž‹è§£è€¦å»ºæ¨¡éª¨éª¼é•¿åº¦å’Œæ–¹å‘ï¼Œé¿å…å±‚çº§è¯¯å·®ç´¯ç§¯ï¼Œå¹¶è®¾è®¡é«˜æ•ˆåŽ»å™ªå™¨å…³æ³¨è¿åŠ¨å­¦å…³èŠ‚å±‚çº§ã€‚
3. FastDDHPoseåœ¨Human3.6Må’ŒMPI-INF-3DHPæ•°æ®é›†ä¸Šå–å¾—äº†SOTAæ€§èƒ½ï¼Œå¹¶å±•çŽ°å‡ºè‰¯å¥½çš„æ³›åŒ–æ€§å’Œé²æ£’æ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºFast3DHPEï¼Œä¸€ä¸ªæ¨¡å—åŒ–æ¡†æž¶ï¼Œæ—¨åœ¨ä¿ƒè¿›å•ç›®3Däººä½“å§¿æ€ä¼°è®¡ï¼ˆ3D HPEï¼‰çš„å¿«é€Ÿå¤çŽ°å’Œçµæ´»å¼€å‘ï¼Œè§£å†³çŽ°æœ‰æ–¹æ³•è®­ç»ƒå’Œè¯„ä¼°æ¡†æž¶ä¸ç»Ÿä¸€ï¼Œç¼ºä¹å…¬å¹³æ¯”è¾ƒçš„é—®é¢˜ã€‚Fast3DHPEæ ‡å‡†åŒ–äº†è®­ç»ƒå’Œè¯„ä¼°æµç¨‹ï¼Œæ˜¾è‘—æé«˜äº†è®­ç»ƒæ•ˆçŽ‡ï¼Œå¹¶æ”¯æŒå„ç§3Däººä½“å§¿æ€ä¼°è®¡æ–¹æ³•çš„å…¬å¹³æ¯”è¾ƒã€‚åœ¨æ­¤æ¡†æž¶ä¸‹ï¼Œæœ¬æ–‡è¿›ä¸€æ­¥æå‡ºäº†FastDDHPoseï¼Œä¸€ç§åŸºäºŽè§£è€¦æ‰©æ•£çš„3Däººä½“å§¿æ€ä¼°è®¡æ–¹æ³•ï¼Œåˆ©ç”¨æ‰©æ•£æ¨¡åž‹å¼ºå¤§çš„æ½œåœ¨åˆ†å¸ƒå»ºæ¨¡èƒ½åŠ›ï¼Œæ˜¾å¼åœ°å¯¹éª¨éª¼é•¿åº¦å’Œéª¨éª¼æ–¹å‘çš„åˆ†å¸ƒè¿›è¡Œå»ºæ¨¡ï¼Œé¿å…äº†å±‚çº§è¯¯å·®ç´¯ç§¯çš„è¿›ä¸€æ­¥æ”¾å¤§ã€‚æ­¤å¤–ï¼Œè®¾è®¡äº†ä¸€ç§é«˜æ•ˆçš„è¿åŠ¨å­¦å±‚çº§æ—¶ç©ºåŽ»å™ªå™¨ï¼Œé¼“åŠ±æ¨¡åž‹å…³æ³¨è¿åŠ¨å­¦å…³èŠ‚å±‚çº§ï¼Œé¿å…å¯¹è¿‡äºŽå¤æ‚çš„å…³èŠ‚æ‹“æ‰‘è¿›è¡Œä¸å¿…è¦çš„å»ºæ¨¡ã€‚åœ¨Human3.6Må’ŒMPI-INF-3DHPä¸Šçš„å¤§é‡å®žéªŒè¡¨æ˜Žï¼ŒFast3DHPEæ¡†æž¶èƒ½å¤Ÿå®žçŽ°æ‰€æœ‰æ–¹æ³•çš„å…¬å¹³æ¯”è¾ƒï¼Œå¹¶æ˜¾è‘—æé«˜è®­ç»ƒæ•ˆçŽ‡ã€‚åœ¨ç»Ÿä¸€æ¡†æž¶ä¸‹ï¼ŒFastDDHPoseå®žçŽ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶åœ¨å®žé™…åœºæ™¯ä¸­å…·æœ‰å¾ˆå¼ºçš„æ³›åŒ–æ€§å’Œé²æ£’æ€§ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰å•ç›®3Däººä½“å§¿æ€ä¼°è®¡æ–¹æ³•é€šå¸¸åœ¨ä¸åŒçš„æ¡†æž¶ä¸‹è¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ï¼Œç¼ºä¹ä¸€ä¸ªç»Ÿä¸€çš„å¹³å°è¿›è¡Œå…¬å¹³æ¯”è¾ƒã€‚æ­¤å¤–ï¼ŒçŽ°æœ‰æ–¹æ³•åœ¨å»ºæ¨¡äººä½“å§¿æ€æ—¶ï¼Œå®¹æ˜“å—åˆ°å±‚çº§è¯¯å·®ç´¯ç§¯çš„å½±å“ï¼Œå¹¶ä¸”å¯èƒ½å¯¹è¿‡äºŽå¤æ‚çš„å…³èŠ‚æ‹“æ‰‘è¿›è¡Œä¸å¿…è¦çš„å»ºæ¨¡ï¼Œå¯¼è‡´æ•ˆçŽ‡é™ä½Žã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æž„å»ºä¸€ä¸ªç»Ÿä¸€çš„æ¡†æž¶Fast3DHPEï¼Œç”¨äºŽå…¬å¹³åœ°è¯„ä¼°å’Œæ¯”è¾ƒä¸åŒçš„3Däººä½“å§¿æ€ä¼°è®¡æ–¹æ³•ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šæå‡ºFastDDHPoseï¼Œåˆ©ç”¨è§£è€¦æ‰©æ•£æ¨¡åž‹æ˜¾å¼åœ°å»ºæ¨¡éª¨éª¼é•¿åº¦å’Œæ–¹å‘ï¼Œä»Žè€Œé¿å…å±‚çº§è¯¯å·®ç´¯ç§¯ã€‚åŒæ—¶ï¼Œè®¾è®¡é«˜æ•ˆçš„åŽ»å™ªå™¨ï¼Œä¸“æ³¨äºŽè¿åŠ¨å­¦å…³èŠ‚å±‚çº§ï¼Œå‡å°‘ä¸å¿…è¦çš„è®¡ç®—å¼€é”€ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šFast3DHPEæ¡†æž¶åŒ…å«æ•°æ®é¢„å¤„ç†ã€æ¨¡åž‹è®­ç»ƒã€æ¨¡åž‹è¯„ä¼°ç­‰æ¨¡å—ï¼Œæä¾›æ ‡å‡†åŒ–çš„æŽ¥å£å’Œæµç¨‹ï¼Œæ–¹ä¾¿ç ”ç©¶äººå‘˜å¿«é€Ÿå¤çŽ°å’Œå¼€å‘æ–°çš„3Däººä½“å§¿æ€ä¼°è®¡æ–¹æ³•ã€‚FastDDHPoseæ¨¡åž‹åˆ™åŸºäºŽæ‰©æ•£æ¨¡åž‹ï¼Œé€šè¿‡è¿­ä»£åŽ»å™ªçš„æ–¹å¼ä»Žå™ªå£°ä¸­ç”Ÿæˆ3Däººä½“å§¿æ€ã€‚è¯¥æ¨¡åž‹åŒ…å«ä¸€ä¸ªç¼–ç å™¨ï¼Œç”¨äºŽå°†2Då…³é”®ç‚¹åºåˆ—æ˜ å°„åˆ°æ½œåœ¨ç©ºé—´ï¼›ä¸€ä¸ªæ‰©æ•£æ¨¡åž‹ï¼Œç”¨äºŽå»ºæ¨¡æ½œåœ¨ç©ºé—´ä¸­éª¨éª¼é•¿åº¦å’Œæ–¹å‘çš„åˆ†å¸ƒï¼›ä»¥åŠä¸€ä¸ªè§£ç å™¨ï¼Œç”¨äºŽå°†æ½œåœ¨ç©ºé—´ä¸­çš„è¡¨ç¤ºæ˜ å°„å›ž3Däººä½“å§¿æ€ã€‚

**å…³é”®åˆ›æ–°**ï¼šFastDDHPoseçš„å…³é”®åˆ›æ–°åœ¨äºŽä½¿ç”¨è§£è€¦æ‰©æ•£æ¨¡åž‹æ˜¾å¼åœ°å»ºæ¨¡éª¨éª¼é•¿åº¦å’Œæ–¹å‘ã€‚ä¸Žç›´æŽ¥å›žå½’3Då§¿æ€çš„æ–¹æ³•ç›¸æ¯”ï¼Œè¿™ç§æ–¹æ³•å¯ä»¥æ›´å¥½åœ°æ•æ‰äººä½“å§¿æ€çš„å†…åœ¨ç»“æž„ï¼Œå¹¶é¿å…å±‚çº§è¯¯å·®ç´¯ç§¯ã€‚æ­¤å¤–ï¼Œé«˜æ•ˆçš„è¿åŠ¨å­¦å±‚çº§æ—¶ç©ºåŽ»å™ªå™¨èƒ½å¤Ÿå‡å°‘ä¸å¿…è¦çš„è®¡ç®—ï¼Œæé«˜æ¨¡åž‹çš„æ•ˆçŽ‡ã€‚

**å…³é”®è®¾è®¡**ï¼šFastDDHPoseä½¿ç”¨äº†ä¸€ç§åŸºäºŽTransformerçš„ç¼–ç å™¨å’Œè§£ç å™¨ï¼Œç”¨äºŽå¤„ç†2Då…³é”®ç‚¹åºåˆ—å’Œæ½œåœ¨ç©ºé—´ä¸­çš„è¡¨ç¤ºã€‚æ‰©æ•£æ¨¡åž‹é‡‡ç”¨U-Netç»“æž„ï¼Œå¹¶å¼•å…¥äº†æ³¨æ„åŠ›æœºåˆ¶ï¼Œä»¥æ›´å¥½åœ°æ•æ‰éª¨éª¼é•¿åº¦å’Œæ–¹å‘ä¹‹é—´çš„å…³ç³»ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬é‡å»ºæŸå¤±å’Œæ‰©æ•£æŸå¤±ï¼Œç”¨äºŽä¼˜åŒ–æ¨¡åž‹çš„æ€§èƒ½ã€‚è¿åŠ¨å­¦å±‚çº§æ—¶ç©ºåŽ»å™ªå™¨é€šè¿‡maskæœºåˆ¶ï¼Œä½¿å¾—æ¨¡åž‹æ›´åŠ å…³æ³¨é‡è¦çš„è¿åŠ¨å­¦å…³èŠ‚å±‚çº§ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

FastDDHPoseåœ¨Human3.6Må’ŒMPI-INF-3DHPæ•°æ®é›†ä¸Šå–å¾—äº†state-of-the-artçš„æ€§èƒ½ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒFastDDHPoseåœ¨ä¿è¯ç²¾åº¦çš„åŒæ—¶ï¼Œæ˜¾è‘—æé«˜äº†è®­ç»ƒæ•ˆçŽ‡ã€‚æ­¤å¤–ï¼ŒFastDDHPoseåœ¨å®žé™…åœºæ™¯ä¸­è¡¨çŽ°å‡ºå¾ˆå¼ºçš„æ³›åŒ–æ€§å’Œé²æ£’æ€§ï¼Œä¼˜äºŽå…¶ä»–æ–¹æ³•ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽäººæœºäº¤äº’ã€è™šæ‹ŸçŽ°å®žã€è¿åŠ¨åˆ†æžã€æ¸¸æˆå¼€å‘ç­‰é¢†åŸŸã€‚é€šè¿‡å‡†ç¡®é«˜æ•ˆåœ°ä¼°è®¡äººä½“å§¿æ€ï¼Œå¯ä»¥å®žçŽ°æ›´è‡ªç„¶çš„äººæœºäº¤äº’ï¼Œæå‡è™šæ‹ŸçŽ°å®žä½“éªŒï¼Œè¾…åŠ©è¿åŠ¨å‘˜è¿›è¡Œè®­ç»ƒåˆ†æžï¼Œå¹¶ä¸ºæ¸¸æˆè§’è‰²æä¾›æ›´é€¼çœŸçš„åŠ¨ä½œã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent approaches for monocular 3D human pose estimation (3D HPE) have achieved leading performance by directly regressing 3D poses from 2D keypoint sequences. Despite the rapid progress in 3D HPE, existing methods are typically trained and evaluated under disparate frameworks, lacking a unified framework for fair comparison. To address these limitations, we propose Fast3DHPE, a modular framework that facilitates rapid reproduction and flexible development of new methods. By standardizing training and evaluation protocols, Fast3DHPE enables fair comparison across 3D human pose estimation methods while significantly improving training efficiency. Within this framework, we introduce FastDDHPose, a Disentangled Diffusion-based 3D Human Pose Estimation method which leverages the strong latent distribution modeling capability of diffusion models to explicitly model the distributions of bone length and bone direction while avoiding further amplification of hierarchical error accumulation. Moreover, we design an efficient Kinematic-Hierarchical Spatial and Temporal Denoiser that encourages the model to focus on kinematic joint hierarchies while avoiding unnecessary modeling of overly complex joint topologies. Extensive experiments on Human3.6M and MPI-INF-3DHP show that the Fast3DHPE framework enables fair comparison of all methods while significantly improving training efficiency. Within this unified framework, FastDDHPose achieves state-of-the-art performance with strong generalization and robustness in in-the-wild scenarios. The framework and models will be released at: https://github.com/Andyen512/Fast3DHPE

