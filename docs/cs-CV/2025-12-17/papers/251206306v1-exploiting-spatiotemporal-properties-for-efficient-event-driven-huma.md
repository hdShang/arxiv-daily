---
layout: default
title: Exploiting Spatiotemporal Properties for Efficient Event-Driven Human Pose Estimation
---

# Exploiting Spatiotemporal Properties for Efficient Event-Driven Human Pose Estimation

**arXiv**: [2512.06306v1](https://arxiv.org/abs/2512.06306) | [PDF](https://arxiv.org/pdf/2512.06306.pdf)

**ä½œè€…**: Haoxian Zhou, Chuanzhi Xu, Langyi Chen, Haodong Chen, Yuk Ying Chung, Qiang Qu, Xaoming Chen, Weidong Cai

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-06

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽæ—¶ç©ºç‰¹æ€§çš„äº‹ä»¶ç›¸æœºäººä½“å§¿æ€ä¼°è®¡æ–¹æ³•ï¼Œæå‡æ•ˆçŽ‡ä¸Žç²¾åº¦**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `äº‹ä»¶ç›¸æœº` `äººä½“å§¿æ€ä¼°è®¡` `ç‚¹äº‘` `æ—¶ç©ºå»ºæ¨¡` `äº‹ä»¶æµ` `æ·±åº¦å­¦ä¹ ` `è¾¹ç¼˜å¢žå¼º`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰äº‹ä»¶ç›¸æœºäººä½“å§¿æ€ä¼°è®¡æ–¹æ³•é€šå¸¸è½¬æ¢ä¸ºå¯†é›†å¸§ï¼Œç‰ºç‰²äº†äº‹ä»¶æµé«˜æ—¶é—´åˆ†è¾¨çŽ‡çš„ä¼˜åŠ¿ï¼Œè®¡ç®—æˆæœ¬ä¹Ÿè¾ƒé«˜ã€‚
2. æœ¬æ–‡æå‡ºä¸€ç§åŸºäºŽç‚¹äº‘æ¡†æž¶çš„æ—¶ç©ºç‰¹æ€§åˆ©ç”¨æ–¹æ³•ï¼Œé€šè¿‡äº‹ä»¶æ—¶é—´åˆ‡ç‰‡å·ç§¯å’Œäº‹ä»¶åˆ‡ç‰‡æŽ’åºæ¨¡å—è¿›è¡Œæ—¶åºå»ºæ¨¡ã€‚
3. å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨DHP19æ•°æ®é›†ä¸Šï¼ŒåŸºäºŽPointNetã€DGCNNå’ŒPoint Transformerç­‰éª¨å¹²ç½‘ç»œå‡å–å¾—äº†æ€§èƒ½æå‡ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äººä½“å§¿æ€ä¼°è®¡æ—¨åœ¨é¢„æµ‹äººä½“å…³é”®ç‚¹ä»¥åˆ†æžäººä½“è¿åŠ¨ã€‚äº‹ä»¶ç›¸æœºæä¾›é«˜æ—¶é—´åˆ†è¾¨çŽ‡å’Œä½Žå»¶è¿Ÿï¼Œä»Žè€Œèƒ½å¤Ÿåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ¡ä»¶ä¸‹å®žçŽ°é²æ£’çš„ä¼°è®¡ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°çŽ°æœ‰æ–¹æ³•å°†äº‹ä»¶æµè½¬æ¢ä¸ºå¯†é›†çš„äº‹ä»¶å¸§ï¼Œè¿™å¢žåŠ äº†é¢å¤–çš„è®¡ç®—é‡å¹¶ç‰ºç‰²äº†äº‹ä»¶ä¿¡å·çš„é«˜æ—¶é—´åˆ†è¾¨çŽ‡ã€‚æœ¬æ–‡æ—¨åœ¨åˆ©ç”¨åŸºäºŽç‚¹äº‘æ¡†æž¶çš„äº‹ä»¶æµçš„æ—¶ç©ºç‰¹æ€§ï¼Œä»¥å¢žå¼ºäººä½“å§¿æ€ä¼°è®¡æ€§èƒ½ã€‚æˆ‘ä»¬è®¾è®¡äº†äº‹ä»¶æ—¶é—´åˆ‡ç‰‡å·ç§¯æ¨¡å—æ¥æ•èŽ·äº‹ä»¶åˆ‡ç‰‡ä¹‹é—´çš„çŸ­æœŸä¾èµ–å…³ç³»ï¼Œå¹¶å°†å…¶ä¸Žäº‹ä»¶åˆ‡ç‰‡æŽ’åºæ¨¡å—ç»“åˆä»¥è¿›è¡Œç»“æž„åŒ–æ—¶é—´å»ºæ¨¡ã€‚æˆ‘ä»¬è¿˜åœ¨åŸºäºŽç‚¹äº‘çš„äº‹ä»¶è¡¨ç¤ºä¸­åº”ç”¨è¾¹ç¼˜å¢žå¼ºï¼Œä»¥å¢žå¼ºç¨€ç–äº‹ä»¶æ¡ä»¶ä¸‹çš„ç©ºé—´è¾¹ç¼˜ä¿¡æ¯ï¼Œä»Žè€Œè¿›ä¸€æ­¥æé«˜æ€§èƒ½ã€‚åœ¨DHP19æ•°æ®é›†ä¸Šçš„å®žéªŒè¡¨æ˜Žï¼Œæˆ‘ä»¬æå‡ºçš„æ–¹æ³•åœ¨ä¸‰ä¸ªå…·æœ‰ä»£è¡¨æ€§çš„ç‚¹äº‘éª¨å¹²ç½‘ç»œï¼ˆPointNetã€DGCNNå’ŒPoint Transformerï¼‰ä¸Šå§‹ç»ˆå¦‚ä¸€åœ°æé«˜äº†æ€§èƒ½ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰åŸºäºŽäº‹ä»¶ç›¸æœºçš„äººä½“å§¿æ€ä¼°è®¡æ–¹æ³•ï¼Œé€šå¸¸å°†äº‹ä»¶æµè½¬æ¢ä¸ºå¯†é›†çš„äº‹ä»¶å¸§ï¼Œè¿™å¯¼è‡´ä¸¤ä¸ªä¸»è¦é—®é¢˜ï¼šä¸€æ˜¯å¢žåŠ äº†é¢å¤–çš„è®¡ç®—è´Ÿæ‹…ï¼ŒäºŒæ˜¯ç‰ºç‰²äº†äº‹ä»¶ç›¸æœºæœ¬èº«æ‰€å…·æœ‰çš„é«˜æ—¶é—´åˆ†è¾¨çŽ‡ä¼˜åŠ¿ã€‚å› æ­¤ï¼Œå¦‚ä½•åœ¨ä¸æŸå¤±æ—¶é—´åˆ†è¾¨çŽ‡çš„å‰æä¸‹ï¼Œé«˜æ•ˆåœ°åˆ©ç”¨äº‹ä»¶æµè¿›è¡Œäººä½“å§¿æ€ä¼°è®¡æ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ç›´æŽ¥åˆ©ç”¨äº‹ä»¶æµçš„æ—¶ç©ºç‰¹æ€§ï¼Œé¿å…è½¬æ¢ä¸ºå¯†é›†å¸§ã€‚å…·ä½“æ¥è¯´ï¼Œé€šè¿‡å°†äº‹ä»¶æµåˆ‡ç‰‡ï¼Œå¹¶è®¾è®¡ä¸“é—¨çš„æ¨¡å—æ¥æ•èŽ·è¿™äº›åˆ‡ç‰‡ä¹‹é—´çš„æ—¶åºä¾èµ–å…³ç³»ï¼Œä»Žè€Œå®žçŽ°é«˜æ•ˆçš„äººä½“å§¿æ€ä¼°è®¡ã€‚åŒæ—¶ï¼Œé’ˆå¯¹äº‹ä»¶æ•°æ®ç¨€ç–çš„é—®é¢˜ï¼Œå¼•å…¥è¾¹ç¼˜å¢žå¼ºæŠ€æœ¯ï¼Œæå‡ç©ºé—´ä¿¡æ¯çš„è¡¨è¾¾èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æ¡†æž¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) äº‹ä»¶æ•°æ®é¢„å¤„ç†ï¼šå°†äº‹ä»¶æµè½¬æ¢ä¸ºç‚¹äº‘è¡¨ç¤ºã€‚2) ç‰¹å¾æå–ï¼šåˆ©ç”¨äº‹ä»¶æ—¶é—´åˆ‡ç‰‡å·ç§¯ï¼ˆEvent Temporal Slicing Convolutionï¼‰æ¨¡å—æå–æ¯ä¸ªæ—¶é—´åˆ‡ç‰‡çš„ç‰¹å¾ã€‚3) æ—¶åºå»ºæ¨¡ï¼šä½¿ç”¨äº‹ä»¶åˆ‡ç‰‡æŽ’åºï¼ˆEvent Slice Sequencingï¼‰æ¨¡å—å¯¹æ—¶é—´åˆ‡ç‰‡ç‰¹å¾è¿›è¡Œå»ºæ¨¡ï¼Œæ•èŽ·æ—¶åºä¾èµ–å…³ç³»ã€‚4) è¾¹ç¼˜å¢žå¼ºï¼šåœ¨ç‚¹äº‘è¡¨ç¤ºä¸­åº”ç”¨è¾¹ç¼˜å¢žå¼ºæŠ€æœ¯ï¼Œæå‡ç©ºé—´ä¿¡æ¯ã€‚5) å§¿æ€ä¼°è®¡ï¼šåˆ©ç”¨ç‚¹äº‘éª¨å¹²ç½‘ç»œï¼ˆå¦‚PointNetã€DGCNNã€Point Transformerï¼‰è¿›è¡Œäººä½“å…³é”®ç‚¹é¢„æµ‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽï¼š1) äº‹ä»¶æ—¶é—´åˆ‡ç‰‡å·ç§¯æ¨¡å—ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ•èŽ·äº‹ä»¶åˆ‡ç‰‡ä¹‹é—´çš„çŸ­æœŸä¾èµ–å…³ç³»ï¼Œé¿å…äº†ä¼ ç»Ÿæ–¹æ³•ä¸­è½¬æ¢ä¸ºå¯†é›†å¸§å¸¦æ¥çš„ä¿¡æ¯æŸå¤±ã€‚2) äº‹ä»¶åˆ‡ç‰‡æŽ’åºæ¨¡å—ï¼Œç”¨äºŽç»“æž„åŒ–åœ°å»ºæ¨¡æ—¶é—´åºåˆ—ä¿¡æ¯ï¼Œæå‡äº†æ—¶åºå»ºæ¨¡èƒ½åŠ›ã€‚3) è¾¹ç¼˜å¢žå¼ºæŠ€æœ¯ï¼Œåœ¨ç¨€ç–äº‹ä»¶æ¡ä»¶ä¸‹ï¼Œå¢žå¼ºäº†ç©ºé—´è¾¹ç¼˜ä¿¡æ¯ï¼Œæé«˜äº†å§¿æ€ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šäº‹ä»¶æ—¶é—´åˆ‡ç‰‡å·ç§¯æ¨¡å—çš„å…·ä½“å®žçŽ°ç»†èŠ‚ï¼ˆä¾‹å¦‚å·ç§¯æ ¸å¤§å°ã€æ­¥é•¿ç­‰ï¼‰ä»¥åŠäº‹ä»¶åˆ‡ç‰‡æŽ’åºæ¨¡å—çš„ç»“æž„ï¼ˆä¾‹å¦‚ä½¿ç”¨çš„å¾ªçŽ¯ç¥žç»ç½‘ç»œç±»åž‹ã€å±‚æ•°ç­‰ï¼‰åœ¨è®ºæ–‡ä¸­åº”è¯¥æœ‰è¯¦ç»†æè¿°ã€‚è¾¹ç¼˜å¢žå¼ºæŠ€æœ¯çš„å…·ä½“å®žçŽ°æ–¹å¼ï¼ˆä¾‹å¦‚ä½¿ç”¨çš„è¾¹ç¼˜æ£€æµ‹ç®—å­ã€å¢žå¼ºå¼ºåº¦ç­‰ï¼‰ä¹Ÿæ˜¯å…³é”®è®¾è®¡çš„ä¸€éƒ¨åˆ†ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿè‡³å…³é‡è¦ï¼Œé€šå¸¸ä¼šé‡‡ç”¨å…³é”®ç‚¹ä½ç½®çš„å›žå½’æŸå¤±ï¼Œå¹¶å¯èƒ½ç»“åˆå…¶ä»–æ­£åˆ™åŒ–é¡¹ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨DHP19æ•°æ®é›†ä¸Šï¼ŒåŸºäºŽPointNetã€DGCNNå’ŒPoint Transformerç­‰éª¨å¹²ç½‘ç»œå‡å–å¾—äº†æ€§èƒ½æå‡ã€‚å…·ä½“æå‡å¹…åº¦æœªçŸ¥ï¼Œä½†æ‘˜è¦ä¸­å¼ºè°ƒäº†â€œconsistently improves performanceâ€ï¼Œè¡¨æ˜Žè¯¥æ–¹æ³•å…·æœ‰è¾ƒå¥½çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚è¾¹ç¼˜å¢žå¼ºæŠ€æœ¯ä¹Ÿå¯¹æ€§èƒ½æå‡åšå‡ºäº†è´¡çŒ®ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽå„ç§éœ€è¦å¿«é€Ÿã€å‡†ç¡®äººä½“å§¿æ€ä¼°è®¡çš„åœºæ™¯ï¼Œä¾‹å¦‚ï¼šæ™ºèƒ½ç›‘æŽ§ã€è¿åŠ¨åˆ†æžã€äººæœºäº¤äº’ã€è‡ªåŠ¨é©¾é©¶ç­‰ã€‚å°¤å…¶æ˜¯åœ¨å…‰ç…§æ¡ä»¶å·®ã€è¿åŠ¨é€Ÿåº¦å¿«çš„åœºæ™¯ä¸‹ï¼ŒåŸºäºŽäº‹ä»¶ç›¸æœºçš„å§¿æ€ä¼°è®¡æ–¹æ³•å…·æœ‰ç‹¬ç‰¹çš„ä¼˜åŠ¿ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›è¿›ä¸€æ­¥åº”ç”¨äºŽè™šæ‹ŸçŽ°å®žã€å¢žå¼ºçŽ°å®žç­‰é¢†åŸŸï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Human pose estimation focuses on predicting body keypoints to analyze human motion. Event cameras provide high temporal resolution and low latency, enabling robust estimation under challenging conditions. However, most existing methods convert event streams into dense event frames, which adds extra computation and sacrifices the high temporal resolution of the event signal. In this work, we aim to exploit the spatiotemporal properties of event streams based on point cloud-based framework, designed to enhance human pose estimation performance. We design Event Temporal Slicing Convolution module to capture short-term dependencies across event slices, and combine it with Event Slice Sequencing module for structured temporal modeling. We also apply edge enhancement in point cloud-based event representation to enhance spatial edge information under sparse event conditions to further improve performance. Experiments on the DHP19 dataset show our proposed method consistently improves performance across three representative point cloud backbones: PointNet, DGCNN, and Point Transformer.

