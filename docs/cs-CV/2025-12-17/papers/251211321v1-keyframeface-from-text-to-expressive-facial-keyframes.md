---
layout: default
title: KeyframeFace: From Text to Expressive Facial Keyframes
---

# KeyframeFace: From Text to Expressive Facial Keyframes

**arXiv**: [2512.11321v1](https://arxiv.org/abs/2512.11321) | [PDF](https://arxiv.org/pdf/2512.11321.pdf)

**ä½œè€…**: Jingchao Wu, Zejian Kang, Haibo Liu, Yuanchen Fei, Xiangru Huang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-12

**ðŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/wjc12345123/KeyframeFace)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**KeyframeFaceï¼šæå‡ºåŸºäºŽæ–‡æœ¬é©±åŠ¨çš„ã€å¯è§£é‡Šçš„å…³é”®å¸§äººè„¸è¡¨æƒ…åŠ¨ç”»ç”Ÿæˆæ¡†æž¶**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)**

**å…³é”®è¯**: `æ–‡æœ¬é©±åŠ¨åŠ¨ç”»` `äººè„¸è¡¨æƒ…ç”Ÿæˆ` `å…³é”®å¸§åŠ¨ç”»` `å¤§åž‹è¯­è¨€æ¨¡åž‹` `å¤šæ¨¡æ€æ•°æ®é›†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•åœ¨æ–‡æœ¬é©±åŠ¨äººè„¸åŠ¨ç”»ç”Ÿæˆæ–¹é¢ï¼Œç¼ºä¹å¯¹æ—¶åºè¯­ä¹‰å’Œç»†ç²’åº¦è¡¨æƒ…å˜åŒ–çš„æœ‰æ•ˆå»ºæ¨¡ï¼Œæ•°æ®é›†ä¹Ÿå¤šé›†ä¸­äºŽè¯­éŸ³é©±åŠ¨æˆ–éžç»“æž„åŒ–è¡¨æƒ…åºåˆ—ã€‚
2. KeyframeFaceé€šè¿‡æž„å»ºå¤§è§„æ¨¡å¤šæ¨¡æ€æ•°æ®é›†ï¼Œå¹¶ç»“åˆLLMå…ˆéªŒçŸ¥è¯†ï¼Œæ˜¾å¼åœ°åˆ©ç”¨å…³é”®å¸§è¿›è¡Œäººè„¸è¿åŠ¨åˆæˆï¼Œå®žçŽ°å¯è§£é‡Šçš„é«˜ä¿çœŸåŠ¨ç”»ç”Ÿæˆã€‚
3. è®ºæ–‡æž„å»ºäº†åŒ…å«ä¸°å¯Œæ ‡æ³¨çš„æ•°æ®é›†ï¼Œå¹¶æå‡ºäº†åŸºäºŽLLMçš„æ–‡æœ¬åˆ°åŠ¨ç”»æ¡†æž¶ï¼Œä¸ºåŽç»­ç ”ç©¶å¥ å®šäº†åŸºç¡€ï¼Œå…·ä½“æ€§èƒ½æå‡æ•°æ®æœªçŸ¥ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºKeyframeFaceï¼Œä¸€ä¸ªå¤§è§„æ¨¡å¤šæ¨¡æ€æ•°æ®é›†ï¼Œæ—¨åœ¨é€šè¿‡å…³é”®å¸§çº§åˆ«çš„ç›‘ç£è¿›è¡Œæ–‡æœ¬åˆ°åŠ¨ç”»çš„ç ”ç©¶ã€‚KeyframeFaceæä¾›äº†2100ä¸ªå¯Œæœ‰è¡¨çŽ°åŠ›çš„è„šæœ¬ï¼Œå¹¶é…æœ‰å•ç›®è§†é¢‘ã€é€å¸§ARKitç³»æ•°ã€ä¸Šä¸‹æ–‡èƒŒæ™¯ã€å¤æ‚çš„æƒ…æ„Ÿã€æ‰‹åŠ¨å®šä¹‰çš„å…³é”®å¸§ï¼Œä»¥åŠåŸºäºŽARKitç³»æ•°å’Œå›¾åƒï¼Œé€šè¿‡å¤§åž‹è¯­è¨€æ¨¡åž‹ï¼ˆLLMï¼‰å’Œå¤šæ¨¡æ€å¤§åž‹è¯­è¨€æ¨¡åž‹ï¼ˆMLLMï¼‰è¿›è¡Œçš„å¤šè§†è§’æ ‡æ³¨ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ç¬¬ä¸€ä¸ªæ–‡æœ¬åˆ°åŠ¨ç”»çš„æ¡†æž¶ï¼Œè¯¥æ¡†æž¶æ˜¾å¼åœ°åˆ©ç”¨LLMå…ˆéªŒçŸ¥è¯†è¿›è¡Œå¯è§£é‡Šçš„é¢éƒ¨è¿åŠ¨åˆæˆã€‚è¿™ç§è®¾è®¡å°†LLMçš„è¯­ä¹‰ç†è§£èƒ½åŠ›ä¸ŽARKitç³»æ•°çš„å¯è§£é‡Šç»“æž„å¯¹é½ï¼Œä»Žè€Œå®žçŽ°é«˜ä¿çœŸåº¦çš„è¡¨æƒ…åŠ¨ç”»ã€‚KeyframeFaceå’ŒåŸºäºŽLLMçš„æ¡†æž¶å…±åŒä¸ºå¯è§£é‡Šçš„ã€å…³é”®å¸§å¼•å¯¼çš„ã€ä»¥åŠä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„æ–‡æœ¬åˆ°åŠ¨ç”»å¥ å®šäº†æ–°çš„åŸºç¡€ã€‚ä»£ç å’Œæ•°æ®å¯åœ¨https://github.com/wjc12345123/KeyframeFaceèŽ·å–ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰æ–‡æœ¬é©±åŠ¨äººè„¸åŠ¨ç”»ç”Ÿæˆæ–¹æ³•éš¾ä»¥æ•æ‰æ—¶åºè¯­ä¹‰å’Œç»†ç²’åº¦è¡¨æƒ…å˜åŒ–ï¼Œæ•°æ®é›†é€šå¸¸ç¼ºä¹è¯­ä¹‰ grounding å’Œæ—¶åºç»“æž„ï¼Œé™åˆ¶äº†ç”Ÿæˆå¯Œæœ‰è¡¨çŽ°åŠ›çš„äººè„¸åŠ¨ç”»çš„èƒ½åŠ›ã€‚çŽ°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨è¯­éŸ³é©±åŠ¨æˆ–éžç»“æž„åŒ–è¡¨æƒ…åºåˆ—ï¼Œå¿½ç•¥äº†æ–‡æœ¬ä¸­è•´å«çš„ä¸°å¯Œæƒ…æ„Ÿå’Œä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§åž‹è¯­è¨€æ¨¡åž‹ï¼ˆLLMï¼‰çš„å¼ºå¤§è¯­ä¹‰ç†è§£èƒ½åŠ›ï¼Œç»“åˆARKitç³»æ•°çš„å¯è§£é‡Šç»“æž„ï¼Œé€šè¿‡å…³é”®å¸§å¼•å¯¼çš„æ–¹å¼ï¼Œå®žçŽ°é«˜ä¿çœŸåº¦çš„è¡¨æƒ…åŠ¨ç”»ç”Ÿæˆã€‚é€šè¿‡æ˜¾å¼åœ°åˆ©ç”¨LLMçš„å…ˆéªŒçŸ¥è¯†ï¼Œå°†æ–‡æœ¬ä¸­çš„è¯­ä¹‰ä¿¡æ¯è½¬åŒ–ä¸ºå¯æŽ§çš„é¢éƒ¨è¿åŠ¨å‚æ•°ï¼Œä»Žè€Œç”Ÿæˆæ›´è‡ªç„¶ã€æ›´å¯Œæœ‰è¡¨çŽ°åŠ›çš„äººè„¸åŠ¨ç”»ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æ¡†æž¶åŒ…å«æ•°æ®é›†æž„å»ºå’Œæ¨¡åž‹è®­ç»ƒä¸¤éƒ¨åˆ†ã€‚æ•°æ®é›†æž„å»ºæ–¹é¢ï¼ŒKeyframeFaceæ•°æ®é›†åŒ…å«2100ä¸ªè„šæœ¬ï¼Œæ¯ä¸ªè„šæœ¬éƒ½é…æœ‰å•ç›®è§†é¢‘ã€é€å¸§ARKitç³»æ•°ã€ä¸Šä¸‹æ–‡èƒŒæ™¯ã€å¤æ‚æƒ…æ„Ÿã€æ‰‹åŠ¨å®šä¹‰çš„å…³é”®å¸§ä»¥åŠå¤šè§†è§’æ ‡æ³¨ã€‚æ¨¡åž‹è®­ç»ƒæ–¹é¢ï¼Œè¯¥æ¡†æž¶åˆ©ç”¨LLMå°†æ–‡æœ¬ä¿¡æ¯æ˜ å°„åˆ°ARKitç³»æ•°ç©ºé—´ï¼Œå¹¶é€šè¿‡å…³é”®å¸§å¼•å¯¼çš„æ–¹å¼ä¼˜åŒ–ç”Ÿæˆç»“æžœã€‚å…·ä½“æ¨¡å—ç»†èŠ‚æœªçŸ¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºŽæ˜¾å¼åœ°åˆ©ç”¨LLMçš„å…ˆéªŒçŸ¥è¯†è¿›è¡Œå¯è§£é‡Šçš„é¢éƒ¨è¿åŠ¨åˆæˆã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£æ–‡æœ¬ä¸­çš„è¯­ä¹‰ä¿¡æ¯ï¼Œå¹¶å°†è¿™äº›ä¿¡æ¯è½¬åŒ–ä¸ºå¯æŽ§çš„é¢éƒ¨è¿åŠ¨å‚æ•°ï¼Œä»Žè€Œç”Ÿæˆæ›´è‡ªç„¶ã€æ›´å¯Œæœ‰è¡¨çŽ°åŠ›çš„äººè„¸åŠ¨ç”»ã€‚æ­¤å¤–ï¼ŒKeyframeFaceæ•°æ®é›†çš„æž„å»ºä¹Ÿä¸ºæ–‡æœ¬é©±åŠ¨äººè„¸åŠ¨ç”»ç”Ÿæˆç ”ç©¶æä¾›äº†æ–°çš„èµ„æºã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­å…³äºŽå‚æ•°è®¾ç½®ã€æŸå¤±å‡½æ•°ã€ç½‘ç»œç»“æž„ç­‰æŠ€æœ¯ç»†èŠ‚æè¿°è¾ƒå°‘ï¼Œå…·ä½“è®¾è®¡æœªçŸ¥ã€‚ä½†å¯ä»¥æŽ¨æµ‹ï¼ŒæŸå¤±å‡½æ•°å¯èƒ½åŒ…å«é‡æž„æŸå¤±ã€å…³é”®å¸§å¯¹é½æŸå¤±ç­‰ï¼Œä»¥ä¿è¯ç”Ÿæˆç»“æžœçš„ä¿çœŸåº¦å’Œå…³é”®å¸§çš„å‡†ç¡®æ€§ã€‚ç½‘ç»œç»“æž„å¯èƒ½åŒ…å«æ–‡æœ¬ç¼–ç å™¨ã€ARKitç³»æ•°è§£ç å™¨ç­‰æ¨¡å—ï¼Œå…·ä½“ç»“æž„æœªçŸ¥ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

è®ºæ–‡æž„å»ºäº†å¤§è§„æ¨¡å¤šæ¨¡æ€æ•°æ®é›†KeyframeFaceï¼ŒåŒ…å«2100ä¸ªè„šæœ¬å’Œä¸°å¯Œçš„æ ‡æ³¨ä¿¡æ¯ã€‚æå‡ºäº†åŸºäºŽLLMçš„æ–‡æœ¬åˆ°åŠ¨ç”»æ¡†æž¶ï¼Œèƒ½å¤Ÿç”Ÿæˆé«˜ä¿çœŸåº¦çš„è¡¨æƒ…åŠ¨ç”»ã€‚è™½ç„¶è®ºæ–‡ä¸­æ²¡æœ‰ç»™å‡ºå…·ä½“çš„æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿ï¼Œä½†è¯¥æ¡†æž¶ä¸ºå¯è§£é‡Šçš„ã€å…³é”®å¸§å¼•å¯¼çš„ã€ä»¥åŠä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„æ–‡æœ¬åˆ°åŠ¨ç”»å¥ å®šäº†æ–°çš„åŸºç¡€ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽè™šæ‹ŸçŽ°å®žã€æ¸¸æˆå¼€å‘ã€åœ¨çº¿æ•™è‚²ã€æ•°å­—äººç­‰é¢†åŸŸã€‚é€šè¿‡æ–‡æœ¬é©±åŠ¨ï¼Œå¯ä»¥å¿«é€Ÿç”Ÿæˆå„ç§è¡¨æƒ…å’ŒåŠ¨ä½œçš„äººè„¸åŠ¨ç”»ï¼Œæé«˜å†…å®¹åˆ›ä½œæ•ˆçŽ‡å’Œç”¨æˆ·ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºŽä¸ªæ€§åŒ–è™šæ‹ŸåŠ©æ‰‹ã€æƒ…æ„Ÿé™ªä¼´æœºå™¨äººç­‰é¢†åŸŸï¼Œå®žçŽ°æ›´è‡ªç„¶ã€æ›´æ™ºèƒ½çš„äººæœºäº¤äº’ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Generating dynamic 3D facial animation from natural language requires understanding both temporally structured semantics and fine-grained expression changes. Existing datasets and methods mainly focus on speech-driven animation or unstructured expression sequences and therefore lack the semantic grounding and temporal structures needed for expressive human performance generation. In this work, we introduce KeyframeFace, a large-scale multimodal dataset designed for text-to-animation research through keyframe-level supervision. KeyframeFace provides 2,100 expressive scripts paired with monocular videos, per-frame ARKit coefficients, contextual backgrounds, complex emotions, manually defined keyframes, and multi-perspective annotations based on ARKit coefficients and images via Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs). Beyond the dataset, we propose the first text-to-animation framework that explicitly leverages LLM priors for interpretable facial motion synthesis. This design aligns the semantic understanding capabilities of LLMs with the interpretable structure of ARKit's coefficients, enabling high-fidelity expressive animation. KeyframeFace and our LLM-based framework together establish a new foundation for interpretable, keyframe-guided, and context-aware text-to-animation. Code and data are available at https://github.com/wjc12345123/KeyframeFace.

