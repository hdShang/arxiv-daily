---
layout: default
title: WorldLens: Full-Spectrum Evaluations of Driving World Models in Real World
---

# WorldLens: Full-Spectrum Evaluations of Driving World Models in Real World

**arXiv**: [2512.10958v1](https://arxiv.org/abs/2512.10958) | [PDF](https://arxiv.org/pdf/2512.10958.pdf)

**ä½œè€…**: Ao Liang, Lingdong Kong, Tianyi Yan, Hongsi Liu, Wesley Yang, Ziqi Huang, Wei Yin, Jialong Zuo, Yixuan Hu, Dekai Zhu, Dongyue Lu, Youquan Liu, Guangfeng Jiang, Linfeng Li, Xiangtai Li, Long Zhuo, Lai Xing Ng, Benoit R. Cottereau, Changxin Gao, Liang Pan, Wei Tsang Ooi, Ziwei Liu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-11

**å¤‡æ³¨**: Preprint; 80 pages, 37 figures, 29 tables; Project Page at https://worldbench.github.io/worldlens

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**WorldLensï¼šçœŸå®žä¸–ç•Œä¸­é©¾é©¶ä¸–ç•Œæ¨¡åž‹çš„å…¨æ–¹ä½è¯„ä¼°åŸºå‡†**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)** **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)**

**å…³é”®è¯**: `ä¸–ç•Œæ¨¡åž‹` `é©¾é©¶åœºæ™¯` `è¯„ä¼°åŸºå‡†` `å…·èº«æ™ºèƒ½` `ç”Ÿæˆå¼æ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰ä¸–ç•Œæ¨¡åž‹åœ¨è§†è§‰çœŸå®žæ„Ÿã€ç‰©ç†åˆç†æ€§å’Œè¡Œä¸ºä¿çœŸåº¦ä¹‹é—´å­˜åœ¨trade-offï¼Œç¼ºä¹ç»Ÿä¸€çš„è¯„ä¼°æ ‡å‡†ã€‚
2. WorldLensé€šè¿‡äº”ä¸ªæ–¹é¢ï¼ˆç”Ÿæˆã€é‡å»ºã€åŠ¨ä½œè·Ÿéšã€ä¸‹æ¸¸ä»»åŠ¡ã€äººç±»åå¥½ï¼‰ç»¼åˆè¯„ä¼°ä¸–ç•Œæ¨¡åž‹çš„æ€§èƒ½ã€‚
3. æž„å»ºå¤§è§„æ¨¡äººå·¥æ ‡æ³¨æ•°æ®é›†WorldLens-26Kï¼Œå¹¶è®­ç»ƒè¯„ä¼°æ¨¡åž‹WorldLens-Agentï¼Œå®žçŽ°å¯æ‰©å±•çš„è¯„ä¼°ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç”Ÿæˆå¼ä¸–ç•Œæ¨¡åž‹æ­£åœ¨é‡å¡‘å…·èº«æ™ºèƒ½ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿåˆæˆé€¼çœŸçš„4Dé©¾é©¶çŽ¯å¢ƒã€‚ç„¶è€Œï¼Œè¿™äº›çŽ¯å¢ƒåœ¨è§†è§‰ä¸Šä»¤äººä¿¡æœï¼Œä½†åœ¨ç‰©ç†æˆ–è¡Œä¸ºä¸Šå¸¸å¸¸å¤±è´¥ã€‚å°½ç®¡è¿›å±•è¿…é€Ÿï¼Œä½†è¯¥é¢†åŸŸä»ç„¶ç¼ºä¹ç»Ÿä¸€çš„æ–¹æ³•æ¥è¯„ä¼°ç”Ÿæˆçš„ä¸–ç•Œæ˜¯å¦ä¿ç•™äº†å‡ ä½•ç»“æž„ã€éµå®ˆç‰©ç†å®šå¾‹æˆ–æ”¯æŒå¯é çš„æŽ§åˆ¶ã€‚æˆ‘ä»¬æŽ¨å‡ºäº†WorldLensï¼Œè¿™æ˜¯ä¸€ä¸ªå…¨æ–¹ä½åŸºå‡†ï¼Œç”¨äºŽè¯„ä¼°æ¨¡åž‹åœ¨å…¶ç”Ÿæˆçš„ä¸–ç•Œä¸­æž„å»ºã€ç†è§£å’Œè¡Œä¸ºçš„èƒ½åŠ›ã€‚å®ƒæ¶µç›–äº”ä¸ªæ–¹é¢â€”â€”ç”Ÿæˆã€é‡å»ºã€åŠ¨ä½œè·Ÿéšã€ä¸‹æ¸¸ä»»åŠ¡å’Œäººç±»åå¥½â€”â€”å…±åŒæ¶µç›–è§†è§‰çœŸå®žæ„Ÿã€å‡ ä½•ä¸€è‡´æ€§ã€ç‰©ç†åˆç†æ€§å’ŒåŠŸèƒ½å¯é æ€§ã€‚ç»“æžœè¡¨æ˜Žï¼Œæ²¡æœ‰çŽ°æœ‰çš„ä¸–ç•Œæ¨¡åž‹åœ¨æ‰€æœ‰æ–¹é¢éƒ½è¡¨çŽ°å‡ºè‰²ï¼šçº¹ç†å¼ºçš„æ¨¡åž‹å¸¸å¸¸è¿åç‰©ç†å®šå¾‹ï¼Œè€Œå‡ ä½•ç¨³å®šçš„æ¨¡åž‹åˆ™ç¼ºä¹è¡Œä¸ºä¿çœŸåº¦ã€‚ä¸ºäº†ä½¿å®¢è§‚æŒ‡æ ‡ä¸Žäººç±»åˆ¤æ–­å¯¹é½ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥æž„å»ºäº†WorldLens-26Kï¼Œè¿™æ˜¯ä¸€ä¸ªå¤§è§„æ¨¡çš„äººå·¥æ ‡æ³¨è§†é¢‘æ•°æ®é›†ï¼ŒåŒ…å«æ•°å€¼è¯„åˆ†å’Œæ–‡æœ¬ç†ç”±ï¼Œå¹¶å¼€å‘äº†WorldLens-Agentï¼Œè¿™æ˜¯ä¸€ä¸ªä»Žè¿™äº›æ ‡æ³¨ä¸­æç‚¼å‡ºæ¥çš„è¯„ä¼°æ¨¡åž‹ï¼Œä»¥å®žçŽ°å¯æ‰©å±•ã€å¯è§£é‡Šçš„è¯„åˆ†ã€‚åŸºå‡†ã€æ•°æ®é›†å’Œæ™ºèƒ½ä½“å…±åŒæž„æˆäº†ä¸€ä¸ªç»Ÿä¸€çš„ç”Ÿæ€ç³»ç»Ÿï¼Œç”¨äºŽè¡¡é‡ä¸–ç•Œä¿çœŸåº¦â€”â€”æ ‡å‡†åŒ–æœªæ¥æ¨¡åž‹ä¸ä»…è¦æ ¹æ®å®ƒä»¬çœ‹èµ·æ¥æœ‰å¤šçœŸå®žæ¥åˆ¤æ–­ï¼Œè¿˜è¦æ ¹æ®å®ƒä»¬è¡Œä¸ºæœ‰å¤šçœŸå®žæ¥åˆ¤æ–­ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰ç”Ÿæˆå¼ä¸–ç•Œæ¨¡åž‹è™½ç„¶åœ¨è§†è§‰ä¸Šé€¼çœŸï¼Œä½†åœ¨å‡ ä½•ä¸€è‡´æ€§ã€ç‰©ç†åˆç†æ€§å’Œè¡Œä¸ºæŽ§åˆ¶æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œç¼ºä¹ä¸€ä¸ªç»Ÿä¸€çš„ã€å…¨æ–¹ä½çš„è¯„ä¼°æ ‡å‡†æ¥è¡¡é‡æ¨¡åž‹çš„ç»¼åˆæ€§èƒ½ã€‚çŽ°æœ‰æ–¹æ³•éš¾ä»¥å¹³è¡¡è§†è§‰çœŸå®žæ„Ÿã€ç‰©ç†åˆç†æ€§å’Œè¡Œä¸ºä¿çœŸåº¦ï¼Œå¯¼è‡´æ¨¡åž‹åœ¨å®žé™…åº”ç”¨ä¸­è¡¨çŽ°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šWorldLensçš„æ ¸å¿ƒæ€è·¯æ˜¯æž„å»ºä¸€ä¸ªå…¨é¢çš„è¯„ä¼°ä½“ç³»ï¼Œä»Žå¤šä¸ªç»´åº¦è¯„ä¼°ä¸–ç•Œæ¨¡åž‹çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬ç”Ÿæˆè´¨é‡ã€é‡å»ºç²¾åº¦ã€åŠ¨ä½œè·Ÿéšèƒ½åŠ›ã€ä¸‹æ¸¸ä»»åŠ¡è¡¨çŽ°ä»¥åŠäººç±»åå¥½ã€‚é€šè¿‡å¤šæ–¹é¢çš„è¯„ä¼°ï¼Œå¯ä»¥æ›´å‡†ç¡®åœ°äº†è§£æ¨¡åž‹çš„ä¼˜ç¼ºç‚¹ï¼Œå¹¶æŒ‡å¯¼æ¨¡åž‹æ”¹è¿›ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šWorldLensè¯„ä¼°ä½“ç³»åŒ…å«äº”ä¸ªä¸»è¦æ¨¡å—ï¼š1) **ç”Ÿæˆ (Generation)**ï¼šè¯„ä¼°ç”ŸæˆçŽ¯å¢ƒçš„è§†è§‰çœŸå®žæ„Ÿï¼›2) **é‡å»º (Reconstruction)**ï¼šè¯„ä¼°æ¨¡åž‹é‡å»ºçŽ¯å¢ƒçš„èƒ½åŠ›ï¼›3) **åŠ¨ä½œè·Ÿéš (Action-Following)**ï¼šè¯„ä¼°æ¨¡åž‹é¢„æµ‹åŠ¨ä½œæ‰§è¡ŒåŽçŽ¯å¢ƒå˜åŒ–çš„èƒ½åŠ›ï¼›4) **ä¸‹æ¸¸ä»»åŠ¡ (Downstream Task)**ï¼šè¯„ä¼°æ¨¡åž‹åœ¨å®žé™…é©¾é©¶ä»»åŠ¡ä¸­çš„è¡¨çŽ°ï¼›5) **äººç±»åå¥½ (Human Preference)**ï¼šé€šè¿‡äººå·¥è¯„ä¼°æ¥è¡¡é‡æ¨¡åž‹çš„æ•´ä½“è´¨é‡ã€‚æ­¤å¤–ï¼Œè¿˜æž„å»ºäº†WorldLens-26Kæ•°æ®é›†ï¼ŒåŒ…å«äººå·¥æ ‡æ³¨çš„è§†é¢‘ï¼Œç”¨äºŽè®­ç»ƒWorldLens-Agentè¯„ä¼°æ¨¡åž‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šWorldLensçš„å…³é”®åˆ›æ–°åœ¨äºŽå…¶å…¨æ–¹ä½çš„è¯„ä¼°ä½“ç³»ï¼Œå®ƒä¸ä»…å…³æ³¨è§†è§‰çœŸå®žæ„Ÿï¼Œè¿˜å…³æ³¨å‡ ä½•ä¸€è‡´æ€§ã€ç‰©ç†åˆç†æ€§å’Œè¡Œä¸ºä¿çœŸåº¦ã€‚æ­¤å¤–ï¼ŒWorldLens-Agentçš„å¼•å…¥ä½¿å¾—è¯„ä¼°è¿‡ç¨‹æ›´åŠ é«˜æ•ˆå’Œå¯æ‰©å±•ï¼Œèƒ½å¤Ÿè‡ªåŠ¨è¯„ä¼°ç”ŸæˆçŽ¯å¢ƒçš„è´¨é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šWorldLens-26Kæ•°æ®é›†åŒ…å«å¤§é‡äººå·¥æ ‡æ³¨çš„é©¾é©¶åœºæ™¯è§†é¢‘ï¼Œæ¯ä¸ªè§†é¢‘éƒ½åŒ…å«æ•°å€¼è¯„åˆ†å’Œæ–‡æœ¬ç†ç”±ï¼Œç”¨äºŽè®­ç»ƒWorldLens-Agentã€‚WorldLens-Agentæ˜¯ä¸€ä¸ªæ·±åº¦å­¦ä¹ æ¨¡åž‹ï¼Œé€šè¿‡å­¦ä¹ äººç±»çš„è¯„ä¼°æ ‡å‡†ï¼Œèƒ½å¤Ÿè‡ªåŠ¨è¯„ä¼°ç”ŸæˆçŽ¯å¢ƒçš„è´¨é‡ã€‚å…·ä½“çš„ç½‘ç»œç»“æž„å’ŒæŸå¤±å‡½æ•°ç­‰ç»†èŠ‚åœ¨è®ºæ–‡ä¸­å¯èƒ½æœ‰æ‰€æè¿°ï¼Œä½†æ‘˜è¦ä¸­æœªæ˜Žç¡®æåŠã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼Œæ²¡æœ‰çŽ°æœ‰çš„ä¸–ç•Œæ¨¡åž‹åœ¨æ‰€æœ‰è¯„ä¼°ç»´åº¦ä¸Šéƒ½è¡¨çŽ°å‡ºè‰²ã€‚æŸäº›æ¨¡åž‹åœ¨è§†è§‰çœŸå®žæ„Ÿæ–¹é¢è¡¨çŽ°è‰¯å¥½ï¼Œä½†åœ¨ç‰©ç†åˆç†æ€§æ–¹é¢å­˜åœ¨ç¼ºé™·ï¼›è€Œå¦ä¸€äº›æ¨¡åž‹åœ¨å‡ ä½•ä¸€è‡´æ€§æ–¹é¢è¡¨çŽ°å‡ºè‰²ï¼Œä½†åœ¨è¡Œä¸ºä¿çœŸåº¦æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚WorldLens-Agentèƒ½å¤Ÿæœ‰æ•ˆåœ°å­¦ä¹ äººç±»çš„è¯„ä¼°æ ‡å‡†ï¼Œå¹¶è‡ªåŠ¨è¯„ä¼°ç”ŸæˆçŽ¯å¢ƒçš„è´¨é‡ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

WorldLenså¯åº”ç”¨äºŽè‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººã€æ¸¸æˆç­‰é¢†åŸŸï¼Œç”¨äºŽè¯„ä¼°å’Œæ”¹è¿›ç”Ÿæˆå¼ä¸–ç•Œæ¨¡åž‹ã€‚é€šè¿‡è¯¥åŸºå‡†ï¼Œå¯ä»¥å¼€å‘å‡ºæ›´é€¼çœŸã€æ›´å¯é çš„ä¸–ç•Œæ¨¡åž‹ï¼Œä»Žè€Œæé«˜æ™ºèƒ½ä½“åœ¨å¤æ‚çŽ¯å¢ƒä¸­çš„é€‚åº”æ€§å’Œå†³ç­–èƒ½åŠ›ã€‚æœªæ¥ï¼ŒWorldLenså¯ä»¥æ‰©å±•åˆ°å…¶ä»–é¢†åŸŸï¼Œä¾‹å¦‚å®¤å†…å¯¼èˆªã€è™šæ‹ŸçŽ°å®žç­‰ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Generative world models are reshaping embodied AI, enabling agents to synthesize realistic 4D driving environments that look convincing but often fail physically or behaviorally. Despite rapid progress, the field still lacks a unified way to assess whether generated worlds preserve geometry, obey physics, or support reliable control. We introduce WorldLens, a full-spectrum benchmark evaluating how well a model builds, understands, and behaves within its generated world. It spans five aspects -- Generation, Reconstruction, Action-Following, Downstream Task, and Human Preference -- jointly covering visual realism, geometric consistency, physical plausibility, and functional reliability. Across these dimensions, no existing world model excels universally: those with strong textures often violate physics, while geometry-stable ones lack behavioral fidelity. To align objective metrics with human judgment, we further construct WorldLens-26K, a large-scale dataset of human-annotated videos with numerical scores and textual rationales, and develop WorldLens-Agent, an evaluation model distilled from these annotations to enable scalable, explainable scoring. Together, the benchmark, dataset, and agent form a unified ecosystem for measuring world fidelity -- standardizing how future models are judged not only by how real they look, but by how real they behave.

