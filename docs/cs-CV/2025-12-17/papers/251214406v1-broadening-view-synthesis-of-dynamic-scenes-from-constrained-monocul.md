---
layout: default
title: Broadening View Synthesis of Dynamic Scenes from Constrained Monocular Videos
---

# Broadening View Synthesis of Dynamic Scenes from Constrained Monocular Videos

**arXiv**: [2512.14406v1](https://arxiv.org/abs/2512.14406) | [PDF](https://arxiv.org/pdf/2512.14406.pdf)

**ä½œè€…**: Le Jiang, Shaotong Zhu, Yedi Luo, Shayda Moezzi, Sarah Ostadabbas

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ExpanDyNeRFï¼šæ‰©å±•åŠ¨æ€åœºæ™¯è§†è§’åˆæˆï¼Œè§£å†³å•ç›®è§†é¢‘å¤§è§’åº¦æ¸²æŸ“å¤±çœŸé—®é¢˜**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `åŠ¨æ€NeRF` `è§†è§’åˆæˆ` `é«˜æ–¯æº…å°„` `å•ç›®è§†é¢‘` `ä¼ªçœŸå€¼ç”Ÿæˆ` `ç¥žç»æ¸²æŸ“` `åŠ¨æ€åœºæ™¯é‡å»º` `å¤§è§’åº¦æ¸²æŸ“`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰åŠ¨æ€NeRFæ–¹æ³•åœ¨è§†è§’å˜åŒ–è¾ƒå¤§æ—¶ï¼Œæ¸²æŸ“æ•ˆæžœä¸ç¨³å®šä¸”ä¸çœŸå®žï¼Œéš¾ä»¥æ»¡è¶³å®žé™…åº”ç”¨éœ€æ±‚ã€‚
2. ExpanDyNeRFåˆ©ç”¨é«˜æ–¯æº…å°„å…ˆéªŒå’Œä¼ªçœŸå€¼ç”Ÿæˆç­–ç•¥ï¼Œä¼˜åŒ–å¯†åº¦å’Œé¢œè‰²ç‰¹å¾ï¼Œä»Žè€Œå®žçŽ°å¤§è§’åº¦ä¸‹çš„é«˜è´¨é‡è§†è§’åˆæˆã€‚
3. åœ¨SynDMå’ŒçœŸå®žæ•°æ®é›†ä¸Šï¼ŒExpanDyNeRFæ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œè¯æ˜Žäº†å…¶åœ¨æžç«¯è§†è§’å˜åŒ–ä¸‹çš„æ¸²æŸ“ä¿çœŸåº¦ä¼˜åŠ¿ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é’ˆå¯¹åŠ¨æ€ç¥žç»è¾å°„åœºï¼ˆNeRFï¼‰ç³»ç»Ÿä¸­ï¼ŒçŽ°æœ‰è§†è§’åˆæˆæ–¹æ³•åœ¨å¤§è§’åº¦è§†è§’åå·®ä¸‹æ˜“äº§ç”Ÿä¸ç¨³å®šå’Œä¸çœŸå®žæ¸²æŸ“çš„é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†æ‰©å±•åŠ¨æ€NeRFï¼ˆExpanDyNeRFï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªå•ç›®NeRFæ¡†æž¶ï¼Œåˆ©ç”¨é«˜æ–¯æº…å°„å…ˆéªŒå’Œä¼ªçœŸå€¼ç”Ÿæˆç­–ç•¥ï¼Œå®žçŽ°å¤§è§’åº¦æ—‹è½¬ä¸‹çš„é€¼çœŸåˆæˆã€‚ExpanDyNeRFä¼˜åŒ–å¯†åº¦å’Œé¢œè‰²ç‰¹å¾ï¼Œä»¥æ”¹å–„ä»Žå…·æœ‰æŒ‘æˆ˜æ€§çš„è§†è§’è¿›è¡Œåœºæ™¯é‡å»ºçš„æ•ˆæžœã€‚æˆ‘ä»¬è¿˜æå‡ºäº†åˆæˆåŠ¨æ€å¤šè§†è§’ï¼ˆSynDMï¼‰æ•°æ®é›†ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå…·æœ‰æ˜¾å¼ä¾§è§†å›¾ç›‘ç£çš„åŠ¨æ€åœºæ™¯åˆæˆå¤šè§†è§’æ•°æ®é›†ï¼Œä½¿ç”¨å®šåˆ¶çš„åŸºäºŽGTA Vçš„æ¸²æŸ“ç®¡çº¿åˆ›å»ºã€‚åœ¨SynDMå’ŒçœŸå®žä¸–ç•Œæ•°æ®é›†ä¸Šçš„å®šé‡å’Œå®šæ€§ç»“æžœè¡¨æ˜Žï¼ŒExpanDyNeRFåœ¨æžç«¯è§†è§’å˜åŒ–ä¸‹çš„æ¸²æŸ“ä¿çœŸåº¦æ–¹é¢æ˜¾è‘—ä¼˜äºŽçŽ°æœ‰çš„åŠ¨æ€NeRFæ–¹æ³•ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰åŠ¨æ€NeRFæ–¹æ³•åœ¨å¤„ç†å•ç›®è§†é¢‘æ—¶ï¼Œå½“è§†è§’å‘ç”Ÿè¾ƒå¤§å˜åŒ–æ—¶ï¼Œæ¸²æŸ“ç»“æžœå¾€å¾€å‡ºçŽ°å¤±çœŸã€ä¸ç¨³å®šç­‰é—®é¢˜ã€‚è¿™æ˜¯å› ä¸ºå•ç›®è§†é¢‘æä¾›çš„è§†è§’ä¿¡æ¯æœ‰é™ï¼Œéš¾ä»¥å‡†ç¡®é‡å»ºåœºæ™¯çš„å‡ ä½•å’Œå¤–è§‚ä¿¡æ¯ï¼Œå°¤å…¶æ˜¯åœ¨ç¼ºä¹ä¾§è§†å›¾ç›‘ç£çš„æƒ…å†µä¸‹ã€‚çŽ°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆåº”å¯¹è¿™ç§æŒ‘æˆ˜ï¼Œå¯¼è‡´åˆæˆçš„æ–°è§†è§’å›¾åƒè´¨é‡ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šExpanDyNeRFçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨é«˜æ–¯æº…å°„ï¼ˆGaussian Splattingï¼‰ä½œä¸ºå…ˆéªŒçŸ¥è¯†ï¼Œå¹¶ç»“åˆä¼ªçœŸå€¼ç”Ÿæˆç­–ç•¥ï¼Œæ¥å¼¥è¡¥å•ç›®è§†é¢‘è§†è§’ä¿¡æ¯ä¸è¶³çš„é—®é¢˜ã€‚é«˜æ–¯æº…å°„èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°è¡¨ç¤ºåœºæ™¯çš„å‡ ä½•ç»“æž„å’Œå¤–è§‚ï¼Œè€Œä¼ªçœŸå€¼ç”Ÿæˆåˆ™å¯ä»¥æä¾›é¢å¤–çš„ç›‘ç£ä¿¡æ¯ï¼Œä»Žè€Œæé«˜åœºæ™¯é‡å»ºçš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒExpanDyNeRFèƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†å¤§è§’åº¦è§†è§’å˜åŒ–ï¼Œç”Ÿæˆæ›´é€¼çœŸçš„æ–°è§†è§’å›¾åƒã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šExpanDyNeRFçš„æ•´ä½“æ¡†æž¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) **é«˜æ–¯æº…å°„åˆå§‹åŒ–**ï¼šä½¿ç”¨å•ç›®è§†é¢‘æ•°æ®åˆå§‹åŒ–åœºæ™¯çš„é«˜æ–¯æº…å°„è¡¨ç¤ºã€‚2) **ä¼ªçœŸå€¼ç”Ÿæˆ**ï¼šåˆ©ç”¨åˆå§‹åŒ–çš„é«˜æ–¯æº…å°„è¡¨ç¤ºï¼Œç”Ÿæˆä¸åŒè§†è§’çš„ä¼ªçœŸå€¼å›¾åƒã€‚3) **NeRFä¼˜åŒ–**ï¼šåˆ©ç”¨å•ç›®è§†é¢‘æ•°æ®å’Œç”Ÿæˆçš„ä¼ªçœŸå€¼å›¾åƒï¼Œè”åˆä¼˜åŒ–NeRFæ¨¡åž‹çš„å¯†åº¦å’Œé¢œè‰²ç‰¹å¾ã€‚4) **æ–°è§†è§’åˆæˆ**ï¼šä½¿ç”¨ä¼˜åŒ–åŽçš„NeRFæ¨¡åž‹ï¼Œåˆæˆä»»æ„è§†è§’çš„æ–°è§†è§’å›¾åƒã€‚

**å…³é”®åˆ›æ–°**ï¼šExpanDyNeRFçš„å…³é”®åˆ›æ–°åœ¨äºŽä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š1) **é«˜æ–¯æº…å°„å…ˆéªŒ**ï¼šå°†é«˜æ–¯æº…å°„å¼•å…¥åŠ¨æ€NeRFæ¡†æž¶ï¼Œæé«˜äº†åœºæ™¯è¡¨ç¤ºçš„æ•ˆçŽ‡å’Œå‡†ç¡®æ€§ã€‚2) **ä¼ªçœŸå€¼ç”Ÿæˆç­–ç•¥**ï¼šé€šè¿‡ç”Ÿæˆé¢å¤–çš„ç›‘ç£ä¿¡æ¯ï¼Œå¼¥è¡¥äº†å•ç›®è§†é¢‘è§†è§’ä¿¡æ¯ä¸è¶³çš„é—®é¢˜ã€‚3) **SynDMæ•°æ®é›†**ï¼šæž„å»ºäº†é¦–ä¸ªå…·æœ‰æ˜¾å¼ä¾§è§†å›¾ç›‘ç£çš„åŠ¨æ€åœºæ™¯åˆæˆå¤šè§†è§’æ•°æ®é›†ï¼Œä¸ºåŠ¨æ€NeRFçš„ç ”ç©¶æä¾›äº†æ–°çš„benchmarkã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒExpanDyNeRFèƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†å¤§è§’åº¦è§†è§’å˜åŒ–ï¼Œç”Ÿæˆæ›´é€¼çœŸçš„æ–°è§†è§’å›¾åƒã€‚

**å…³é”®è®¾è®¡**ï¼šExpanDyNeRFçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) **é«˜æ–¯æº…å°„çš„å‚æ•°åŒ–**ï¼šä½¿ç”¨å‡å€¼ã€æ–¹å·®å’Œé¢œè‰²ç­‰å‚æ•°æ¥è¡¨ç¤ºæ¯ä¸ªé«˜æ–¯çƒã€‚2) **ä¼ªçœŸå€¼ç”Ÿæˆå™¨çš„è®¾è®¡**ï¼šä½¿ç”¨ä¸€ä¸ªç¥žç»ç½‘ç»œæ¥ç”Ÿæˆä¸åŒè§†è§’çš„ä¼ªçœŸå€¼å›¾åƒï¼Œå¹¶ä½¿ç”¨å¯¹æŠ—æŸå¤±æ¥æé«˜ç”Ÿæˆå›¾åƒçš„çœŸå®žæ„Ÿã€‚3) **NeRFæ¨¡åž‹çš„ç»“æž„**ï¼šä½¿ç”¨ä¸€ä¸ªå¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰æ¥é¢„æµ‹æ¯ä¸ªç‚¹çš„å¯†åº¦å’Œé¢œè‰²ã€‚4) **æŸå¤±å‡½æ•°çš„è®¾è®¡**ï¼šä½¿ç”¨åŒ…æ‹¬å›¾åƒé‡å»ºæŸå¤±ã€æ­£åˆ™åŒ–æŸå¤±å’Œå¯¹æŠ—æŸå¤±åœ¨å†…çš„å¤šç§æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ¨¡åž‹ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

ExpanDyNeRFåœ¨SynDMæ•°æ®é›†å’ŒçœŸå®žä¸–ç•Œæ•°æ®é›†ä¸Šéƒ½å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚åœ¨SynDMæ•°æ®é›†ä¸Šï¼ŒExpanDyNeRFåœ¨PSNRã€SSIMå’ŒLPIPSç­‰æŒ‡æ ‡ä¸Šå‡ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨æžç«¯è§†è§’å˜åŒ–ä¸‹ï¼ŒExpanDyNeRFçš„PSNRæ¯”çŽ°æœ‰æ–¹æ³•æé«˜äº†5dBä»¥ä¸Šã€‚åœ¨çœŸå®žä¸–ç•Œæ•°æ®é›†ä¸Šï¼ŒExpanDyNeRFä¹Ÿèƒ½å¤Ÿç”Ÿæˆæ›´é€¼çœŸã€æ›´ç¨³å®šçš„æ–°è§†è§’å›¾åƒï¼Œè¯æ˜Žäº†å…¶åœ¨å®žé™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

ExpanDyNeRFåœ¨è™šæ‹ŸçŽ°å®žã€å¢žå¼ºçŽ°å®žã€æœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥ç”¨äºŽç”Ÿæˆé«˜è´¨é‡çš„åŠ¨æ€åœºæ™¯æ–°è§†è§’å›¾åƒï¼Œä»Žè€Œæé«˜ç”¨æˆ·ä½“éªŒå’Œç³»ç»Ÿæ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨è™šæ‹ŸçŽ°å®žä¸­ï¼Œç”¨æˆ·å¯ä»¥è‡ªç”±åœ°æ”¹å˜è§†è§’ï¼Œè§‚å¯ŸåŠ¨æ€åœºæ™¯çš„ç»†èŠ‚ã€‚åœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼Œç³»ç»Ÿå¯ä»¥åˆ©ç”¨ExpanDyNeRFç”Ÿæˆä¸åŒè§†è§’çš„å›¾åƒï¼Œä»Žè€Œæé«˜å¯¹å‘¨å›´çŽ¯å¢ƒçš„æ„ŸçŸ¥èƒ½åŠ›ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›è¿›ä¸€æ­¥å‘å±•ï¼Œåº”ç”¨äºŽæ›´å¤æ‚çš„åŠ¨æ€åœºæ™¯å’Œæ›´å¹¿æ³›çš„é¢†åŸŸã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In dynamic Neural Radiance Fields (NeRF) systems, state-of-the-art novel view synthesis methods often fail under significant viewpoint deviations, producing unstable and unrealistic renderings. To address this, we introduce Expanded Dynamic NeRF (ExpanDyNeRF), a monocular NeRF framework that leverages Gaussian splatting priors and a pseudo-ground-truth generation strategy to enable realistic synthesis under large-angle rotations. ExpanDyNeRF optimizes density and color features to improve scene reconstruction from challenging perspectives. We also present the Synthetic Dynamic Multiview (SynDM) dataset, the first synthetic multiview dataset for dynamic scenes with explicit side-view supervision-created using a custom GTA V-based rendering pipeline. Quantitative and qualitative results on SynDM and real-world datasets demonstrate that ExpanDyNeRF significantly outperforms existing dynamic NeRF methods in rendering fidelity under extreme viewpoint shifts. Further details are provided in the supplementary materials.

