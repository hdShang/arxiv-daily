---
layout: default
title: When Gender is Hard to See: Multi-Attribute Support for Long-Range Recognition
---

# When Gender is Hard to See: Multi-Attribute Support for Long-Range Recognition

**arXiv**: [2512.06426v1](https://arxiv.org/abs/2512.06426) | [PDF](https://arxiv.org/pdf/2512.06426.pdf)

**ä½œè€…**: Nzakiese Mbongo, Kailash A. Hambarde, Hugo ProenÃ§a

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-06

**å¤‡æ³¨**: 12 pages, 9 figures

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŒè·¯å¾„Transformeræ¡†æž¶ï¼Œåˆ©ç”¨CLIPè§£å†³è¿œè·ç¦»å›¾åƒæ€§åˆ«è¯†åˆ«éš¾é¢˜**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `è¿œè·ç¦»è¯†åˆ«` `æ€§åˆ«è¯†åˆ«` `CLIPæ¨¡åž‹` `åŒè·¯å¾„Transformer` `å±žæ€§è¯†åˆ«` `è¡Œäººé‡è¯†åˆ«` `å¤šæ¨¡æ€å­¦ä¹ ` `æ³¨æ„åŠ›æœºåˆ¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. è¿œè·ç¦»å›¾åƒæ€§åˆ«è¯†åˆ«é¢ä¸´ç©ºé—´åˆ†è¾¨çŽ‡ä½Žã€è§†è§’å˜åŒ–å¤§å’Œé¢éƒ¨çº¿ç´¢ä¸¢å¤±ç­‰æŒ‘æˆ˜ï¼ŒçŽ°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆåº”å¯¹ã€‚
2. æå‡ºåŒè·¯å¾„Transformeræ¡†æž¶ï¼Œç»“åˆè§†è§‰ä¿¡æ¯å’Œå±žæ€§çº¿ç´¢ï¼Œåˆ©ç”¨CLIPæ¨¡åž‹è¿›è¡Œè”åˆå»ºæ¨¡ï¼Œæå‡è¯†åˆ«å‡†ç¡®çŽ‡ã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨è‡ªå»ºæ•°æ®é›†ä¸Šä¼˜äºŽçŽ°æœ‰è¡Œäººå±žæ€§è¯†åˆ«å’Œé‡è¯†åˆ«æ–¹æ³•ï¼Œä¸”å¯¹è·ç¦»ã€è§’åº¦å’Œé«˜åº¦å˜åŒ–å…·æœ‰é²æ£’æ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åŒè·¯å¾„Transformeræ¡†æž¶ï¼Œåˆ©ç”¨CLIPæ¨¡åž‹ï¼Œè”åˆå»ºæ¨¡è§†è§‰å’Œå±žæ€§é©±åŠ¨çš„çº¿ç´¢ï¼Œç”¨äºŽè¿œè·ç¦»å›¾åƒçš„æ€§åˆ«è¯†åˆ«ã€‚è¯¥æ¡†æž¶åŒ…å«ä¸¤ä¸ªäº’è¡¥çš„è·¯å¾„ï¼šä¸€æ˜¯ç›´æŽ¥è§†è§‰è·¯å¾„ï¼Œé€šè¿‡é€‰æ‹©æ€§åœ°å¾®è°ƒé¢„è®­ç»ƒçš„CLIPå›¾åƒç¼–ç å™¨çš„ä¸Šå±‚ï¼Œæ¥ä¼˜åŒ–è§†è§‰ç‰¹å¾ï¼›äºŒæ˜¯å±žæ€§ä»‹å¯¼è·¯å¾„ï¼Œä»Žä¸€ç»„è½¯ç”Ÿç‰©ç‰¹å¾æç¤ºï¼ˆå¦‚å‘åž‹ã€æœè£…ã€é…é¥°ï¼‰ä¸­æŽ¨æ–­æ€§åˆ«ï¼Œè¿™äº›æç¤ºåœ¨CLIPæ–‡æœ¬-å›¾åƒç©ºé—´ä¸­å¯¹é½ã€‚ç©ºé—´é€šé“æ³¨æ„åŠ›æ¨¡å—è¿›ä¸€æ­¥å¢žå¼ºäº†é®æŒ¡å’Œä½Žåˆ†è¾¨çŽ‡ä¸‹çš„åˆ¤åˆ«å®šä½èƒ½åŠ›ã€‚ä¸ºäº†æ”¯æŒå¤§è§„æ¨¡è¯„ä¼°ï¼Œæž„å»ºäº†U-DetAGReIDæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†ç»Ÿä¸€äº†DetReIDxå’ŒAG-ReID.v2ï¼Œå¹¶é‡‡ç”¨ä¸€è‡´çš„ä¸‰å…ƒæ ‡ç­¾æ–¹æ¡ˆï¼ˆç”·ã€å¥³ã€æœªçŸ¥ï¼‰ã€‚å¤§é‡å®žéªŒè¡¨æ˜Žï¼Œæ‰€æå‡ºçš„è§£å†³æ–¹æ¡ˆåœ¨å¤šä¸ªæŒ‡æ ‡ï¼ˆå®F1ã€å‡†ç¡®çŽ‡ã€AUCï¼‰ä¸Šä¼˜äºŽæœ€å…ˆè¿›çš„è¡Œäººå±žæ€§å’Œé‡è¯†åˆ«åŸºçº¿ï¼Œå¹¶ä¸”å¯¹è·ç¦»ã€è§’åº¦å’Œé«˜åº¦å˜åŒ–å…·æœ‰ä¸€è‡´çš„é²æ£’æ€§ã€‚å®šæ€§çš„æ³¨æ„åŠ›å¯è§†åŒ–è¯å®žäº†è§£é‡Šæ€§çš„å±žæ€§å®šä½å’Œè´Ÿè´£ä»»çš„æ‹’ç»è¡Œä¸ºã€‚ç ”ç©¶ç»“æžœè¡¨æ˜Žï¼Œè¯­è¨€å¼•å¯¼çš„åŒè·¯å¾„å­¦ä¹ ä¸ºåœ¨æ— çº¦æŸçš„è¿œè·ç¦»åœºæ™¯ä¸­è¿›è¡Œè´Ÿè´£ä»»çš„æ€§åˆ«è¯†åˆ«æä¾›äº†ä¸€ä¸ªåŽŸåˆ™æ€§çš„ã€å¯æ‰©å±•çš„åŸºç¡€ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æžç«¯è¿œè·ç¦»å›¾åƒä¸­çš„æ€§åˆ«è¯†åˆ«é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•åœ¨å¤„ç†ä½Žåˆ†è¾¨çŽ‡ã€é®æŒ¡å’Œè§†è§’å˜åŒ–ç­‰æƒ…å†µæ—¶è¡¨çŽ°ä¸ä½³ï¼Œæ— æ³•æœ‰æ•ˆæå–æ€§åˆ«ç›¸å…³çš„åˆ¤åˆ«ç‰¹å¾ã€‚æ­¤å¤–ï¼Œç¼ºä¹å¤§è§„æ¨¡çš„è¿œè·ç¦»æ€§åˆ«è¯†åˆ«æ•°æ®é›†ä¹Ÿé™åˆ¶äº†ç®—æ³•çš„è®­ç»ƒå’Œè¯„ä¼°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨CLIPæ¨¡åž‹å¼ºå¤§çš„å¤šæ¨¡æ€è¡¨ç¤ºèƒ½åŠ›ï¼Œç»“åˆè§†è§‰ä¿¡æ¯å’Œå±žæ€§ä¿¡æ¯è¿›è¡Œæ€§åˆ«è¯†åˆ«ã€‚é€šè¿‡åŒè·¯å¾„Transformeræ¡†æž¶ï¼Œåˆ†åˆ«å¤„ç†å›¾åƒçš„è§†è§‰ç‰¹å¾å’Œå±žæ€§ç‰¹å¾ï¼Œå¹¶è¿›è¡Œèžåˆï¼Œä»Žè€Œæé«˜è¯†åˆ«çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨å›¾åƒä¸­çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¼¥è¡¥é¢éƒ¨ç‰¹å¾ç¼ºå¤±å¸¦æ¥çš„å½±å“ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æ¡†æž¶åŒ…å«ä¸¤ä¸ªä¸»è¦è·¯å¾„ï¼š(1) ç›´æŽ¥è§†è§‰è·¯å¾„ï¼šä½¿ç”¨é¢„è®­ç»ƒçš„CLIPå›¾åƒç¼–ç å™¨æå–å›¾åƒçš„è§†è§‰ç‰¹å¾ï¼Œå¹¶é€šè¿‡é€‰æ‹©æ€§å¾®è°ƒä¸Šå±‚ç½‘ç»œæ¥é€‚åº”æ€§åˆ«è¯†åˆ«ä»»åŠ¡ã€‚(2) å±žæ€§ä»‹å¯¼è·¯å¾„ï¼šåˆ©ç”¨CLIPæ–‡æœ¬ç¼–ç å™¨å°†è½¯ç”Ÿç‰©ç‰¹å¾æç¤ºï¼ˆå¦‚å‘åž‹ã€æœè£…ç­‰ï¼‰ç¼–ç ä¸ºæ–‡æœ¬ç‰¹å¾ï¼Œç„¶åŽåœ¨CLIPçš„æ–‡æœ¬-å›¾åƒç©ºé—´ä¸­ä¸Žè§†è§‰ç‰¹å¾å¯¹é½ã€‚æ­¤å¤–ï¼Œè¿˜ä½¿ç”¨äº†ç©ºé—´é€šé“æ³¨æ„åŠ›æ¨¡å—æ¥å¢žå¼ºç‰¹å¾çš„åˆ¤åˆ«èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨é®æŒ¡å’Œä½Žåˆ†è¾¨çŽ‡æƒ…å†µä¸‹ã€‚æœ€åŽï¼Œå°†ä¸¤ä¸ªè·¯å¾„çš„ç‰¹å¾è¿›è¡Œèžåˆï¼Œå¹¶é€šè¿‡åˆ†ç±»å™¨è¿›è¡Œæ€§åˆ«é¢„æµ‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽæå‡ºäº†åŒè·¯å¾„Transformeræ¡†æž¶ï¼Œå°†è§†è§‰ä¿¡æ¯å’Œå±žæ€§ä¿¡æ¯è¿›è¡Œæœ‰æ•ˆèžåˆã€‚åˆ©ç”¨CLIPæ¨¡åž‹å¼ºå¤§çš„å¤šæ¨¡æ€è¡¨ç¤ºèƒ½åŠ›ï¼Œå°†æ–‡æœ¬ä¿¡æ¯ï¼ˆå±žæ€§æè¿°ï¼‰èžå…¥åˆ°å›¾åƒè¯†åˆ«ä»»åŠ¡ä¸­ï¼Œä»Žè€Œæé«˜äº†è¯†åˆ«çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚æ­¤å¤–ï¼Œè‡ªå»ºçš„U-DetAGReIDæ•°æ®é›†ä¸ºè¿œè·ç¦»æ€§åˆ«è¯†åˆ«ç ”ç©¶æä¾›äº†æ•°æ®æ”¯æŒã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç›´æŽ¥è§†è§‰è·¯å¾„ä¸­ï¼Œé€‰æ‹©æ€§å¾®è°ƒCLIPå›¾åƒç¼–ç å™¨çš„ä¸Šå±‚ç½‘ç»œï¼Œé¿å…äº†å¯¹åº•å±‚ç‰¹å¾çš„ç ´åï¼ŒåŒæ—¶èƒ½å¤Ÿæœ‰æ•ˆåœ°é€‚åº”æ€§åˆ«è¯†åˆ«ä»»åŠ¡ã€‚åœ¨å±žæ€§ä»‹å¯¼è·¯å¾„ä¸­ï¼Œä½¿ç”¨CLIPæ–‡æœ¬ç¼–ç å™¨å°†è½¯ç”Ÿç‰©ç‰¹å¾æç¤ºç¼–ç ä¸ºæ–‡æœ¬ç‰¹å¾ï¼Œå¹¶é€šè¿‡å¯¹æ¯”å­¦ä¹ çš„æ–¹å¼ä¸Žè§†è§‰ç‰¹å¾å¯¹é½ã€‚ç©ºé—´é€šé“æ³¨æ„åŠ›æ¨¡å—èƒ½å¤Ÿè‡ªé€‚åº”åœ°è°ƒæ•´ä¸åŒé€šé“å’Œç©ºé—´ä½ç½®çš„æƒé‡ï¼Œä»Žè€Œå¢žå¼ºç‰¹å¾çš„åˆ¤åˆ«èƒ½åŠ›ã€‚æŸå¤±å‡½æ•°æ–¹é¢ï¼Œä½¿ç”¨äº†äº¤å‰ç†µæŸå¤±å‡½æ•°æ¥è®­ç»ƒåˆ†ç±»å™¨ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨è‡ªå»ºçš„U-DetAGReIDæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œåœ¨å®F1ã€å‡†ç¡®çŽ‡å’ŒAUCç­‰æŒ‡æ ‡ä¸Šå‡ä¼˜äºŽçŽ°æœ‰çš„è¡Œäººå±žæ€§è¯†åˆ«å’Œé‡è¯†åˆ«æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨è¿œè·ç¦»åœºæ™¯ä¸‹ï¼Œè¯¥æ–¹æ³•çš„å‡†ç¡®çŽ‡æ¯”çŽ°æœ‰æ–¹æ³•æé«˜äº†5%-10%ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•å¯¹è·ç¦»ã€è§’åº¦å’Œé«˜åº¦å˜åŒ–å…·æœ‰è¾ƒå¼ºçš„é²æ£’æ€§ï¼Œèƒ½å¤Ÿé€‚åº”å¤æ‚çš„å®žé™…åœºæ™¯ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽæ™ºèƒ½å®‰é˜²ã€å…¬å…±å®‰å…¨ã€æ™ºæ…§åŸŽå¸‚ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨ç›‘æŽ§è§†é¢‘ä¸­è¿›è¡Œè¿œè·ç¦»æ€§åˆ«è¯†åˆ«ï¼Œè¾…åŠ©è¿›è¡Œäººç¾¤åˆ†æžã€å«Œç–‘äººè¿½è¸ªç­‰ä»»åŠ¡ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥åº”ç”¨äºŽäººæœºäº¤äº’ã€ä¸ªæ€§åŒ–æŽ¨èç­‰é¢†åŸŸï¼Œä¾‹å¦‚æ ¹æ®ç”¨æˆ·çš„æ€§åˆ«æä¾›å®šåˆ¶åŒ–çš„æœåŠ¡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Accurate gender recognition from extreme long-range imagery remains a challenging problem due to limited spatial resolution, viewpoint variability, and loss of facial cues. For such purpose, we present a dual-path transformer framework that leverages CLIP to jointly model visual and attribute-driven cues for gender recognition at a distance. The framework integrates two complementary streams: (1) a direct visual path that refines a pre-trained CLIP image encoder through selective fine-tuning of its upper layers, and (2) an attribute-mediated path that infers gender from a set of soft-biometric prompts (e.g., hairstyle, clothing, accessories) aligned in the CLIP text-image space. Spatial channel attention modules further enhance discriminative localization under occlusion and low resolution. To support large-scale evaluation, we construct U-DetAGReID, a unified long-range gender dataset derived from DetReIDx and AG-ReID.v2, harmonized under a consistent ternary labeling scheme (Male, Female, Unknown). Extensive experiments suggest that the proposed solution surpasses state-of-the-art person-attribute and re-identification baselines across multiple metrics (macro-F1, accuracy, AUC), with consistent robustness to distance, angle, and height variations. Qualitative attention visualizations confirm interpretable attribute localization and responsible abstention behavior. Our results show that language-guided dual-path learning offers a principled, extensible foundation for responsible gender recognition in unconstrained long-range scenarios.

