---
layout: default
title: Learning to Generate Human-Human-Object Interactions from Textual Descriptions
---

# Learning to Generate Human-Human-Object Interactions from Textual Descriptions

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.20446" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.20446v1</a>
  <a href="https://arxiv.org/pdf/2511.20446.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.20446v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.20446v1', 'Learning to Generate Human-Human-Object Interactions from Textual Descriptions')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jeonghyeon Na, Sangwon Baik, Inhee Lee, Junyoung Lee, Hanbyul Joo

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-25

**å¤‡æ³¨**: Project Page: https://tlb-miss.github.io/hhoi/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHHOIç”Ÿæˆæ¡†æ¶ï¼Œä»æ–‡æœ¬æè¿°ç”Ÿæˆäºº-äºº-ç‰©äº¤äº’åœºæ™¯ï¼Œå¹¶æ„å»ºäº†ç›¸å…³æ•°æ®é›†ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)** **æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction)**

**å…³é”®è¯**: `äºº-äºº-ç‰©äº¤äº’` `HHOIç”Ÿæˆ` `æ‰©æ•£æ¨¡å‹` `æ–‡æœ¬ç”Ÿæˆå›¾åƒ` `å¤šä¸»ä½“äº¤äº’`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•éš¾ä»¥ç†è§£å¤æ‚ã€ä¸Šä¸‹æ–‡ç›¸å…³çš„äººé™…äº’åŠ¨è¡Œä¸ºï¼Œå°¤å…¶æ˜¯åœ¨æ¶‰åŠå¤šä¸ªä¸ªä½“å’Œåœºæ™¯ç‰©ä½“æ—¶ã€‚
2. è®ºæ–‡æå‡ºä¸€ç§æ–°é¢–çš„HHOIç”Ÿæˆæ¡†æ¶ï¼Œé€šè¿‡è§£è€¦äºº-ç‰©å’Œäºº-äººäº¤äº’ï¼Œå¹¶ç»“åˆæ‰©æ•£æ¨¡å‹å®ç°é«˜è´¨é‡ç”Ÿæˆã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ–‡æœ¬é©±åŠ¨çš„HHOIç”Ÿæˆä»»åŠ¡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶å¯æ‰©å±•åˆ°å¤šäººè¿åŠ¨ç”Ÿæˆã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ç ”ç©¶é—®é¢˜ï¼Œå³å»ºæ¨¡æ¶‰åŠç‰©ä½“çš„ä¸¤ä¸ªäººä¹‹é—´çš„äºº-äºº-ç‰©äº¤äº’(HHOI)ã€‚ä¸ºäº†è§£å†³HHOIä¸“ç”¨æ•°æ®é›†çš„ç¼ºä¹é—®é¢˜ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªæ–°çš„HHOIæ•°æ®é›†ï¼Œå¹¶æå‡ºäº†ä¸€ç§åˆ©ç”¨å›¾åƒç”Ÿæˆæ¨¡å‹åˆæˆHHOIæ•°æ®çš„æ–¹æ³•ã€‚æˆ‘ä»¬é¦–å…ˆä»HHOIä¸­æå–å‡ºå•ä¸ªäºº-ç‰©äº¤äº’(HOI)å’Œäºº-äººäº¤äº’(HHI)ï¼Œå¹¶ä½¿ç”¨åŸºäºåˆ†æ•°çš„æ‰©æ•£æ¨¡å‹è®­ç»ƒæ–‡æœ¬åˆ°HOIå’Œæ–‡æœ¬åˆ°HHIæ¨¡å‹ã€‚æœ€åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„ç”Ÿæˆæ¡†æ¶ï¼Œé›†æˆäº†è¿™ä¸¤ä¸ªç‹¬ç«‹çš„æ¨¡å‹ï¼Œèƒ½å¤Ÿåœ¨å•ä¸ªé«˜çº§é‡‡æ ·è¿‡ç¨‹ä¸­åˆæˆå®Œæ•´çš„HHOIã€‚æˆ‘ä»¬çš„æ–¹æ³•å°†HHOIç”Ÿæˆæ‰©å±•åˆ°å¤šäººè®¾ç½®ï¼Œå®ç°æ¶‰åŠä¸¤ä¸ªä»¥ä¸Šä¸ªä½“çš„äº¤äº’ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿæ ¹æ®æ–‡æœ¬æè¿°ç”Ÿæˆé€¼çœŸçš„HHOIï¼Œä¼˜äºä»¥å¾€ä»…å…³æ³¨å•äººHOIçš„æ–¹æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜ä»‹ç»äº†æ¶‰åŠç‰©ä½“çš„å¤šäººè¿åŠ¨ç”Ÿæˆä½œä¸ºæˆ‘ä»¬æ¡†æ¶çš„ä¸€ä¸ªåº”ç”¨ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­äºå•ä¸ªäººä¸ç‰©ä½“çš„äº¤äº’(HOI)ç”Ÿæˆï¼Œå¿½ç•¥äº†äººä¸äººä¹‹é—´çš„äº¤äº’å…³ç³»ï¼Œä»¥åŠè¿™ç§å…³ç³»å¦‚ä½•å—åˆ°ç‰©ä½“çš„å½±å“ã€‚å› æ­¤ï¼Œç°æœ‰æ–¹æ³•æ— æ³•ç”Ÿæˆå¤æ‚çš„äºº-äºº-ç‰©äº¤äº’(HHOI)åœºæ™¯ï¼Œç¼ºä¹å¯¹å¤šä¸»ä½“äº¤äº’è¡Œä¸ºçš„å»ºæ¨¡èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†HHOIåˆ†è§£ä¸ºä¸¤ä¸ªæ›´ç®€å•çš„å­é—®é¢˜ï¼šäºº-ç‰©äº¤äº’(HOI)å’Œäºº-äººäº¤äº’(HHI)ã€‚é€šè¿‡åˆ†åˆ«å»ºæ¨¡è¿™ä¸¤ä¸ªå­é—®é¢˜ï¼Œç„¶åå°†å®ƒä»¬é›†æˆåˆ°ä¸€ä¸ªç»Ÿä¸€çš„ç”Ÿæˆæ¡†æ¶ä¸­ï¼Œä»è€Œå®ç°HHOIçš„ç”Ÿæˆã€‚è¿™ç§è§£è€¦çš„æ–¹å¼é™ä½äº†å»ºæ¨¡çš„å¤æ‚æ€§ï¼Œå¹¶å…è®¸åˆ©ç”¨ç°æœ‰çš„HOIå’ŒHHIæ•°æ®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) æ•°æ®é›†æ„å»ºï¼šæ”¶é›†å¹¶æ ‡æ³¨HHOIæ•°æ®ï¼Œå¹¶ä»ä¸­æå–HOIå’ŒHHIæ•°æ®ã€‚2) æ–‡æœ¬åˆ°HOIæ¨¡å‹ï¼šä½¿ç”¨åŸºäºåˆ†æ•°çš„æ‰©æ•£æ¨¡å‹ï¼Œæ ¹æ®æ–‡æœ¬æè¿°ç”ŸæˆHOIã€‚3) æ–‡æœ¬åˆ°HHIæ¨¡å‹ï¼šä½¿ç”¨åŸºäºåˆ†æ•°çš„æ‰©æ•£æ¨¡å‹ï¼Œæ ¹æ®æ–‡æœ¬æè¿°ç”ŸæˆHHIã€‚4) ç»Ÿä¸€ç”Ÿæˆæ¡†æ¶ï¼šå°†HOIå’ŒHHIæ¨¡å‹é›†æˆåˆ°ä¸€ä¸ªæ¡†æ¶ä¸­ï¼Œé€šè¿‡è”åˆé‡‡æ ·ç”Ÿæˆå®Œæ•´çš„HHOIåœºæ™¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†HHOIçš„æ¦‚å¿µï¼Œå¹¶è®¾è®¡äº†ä¸€ä¸ªè§£è€¦çš„ç”Ÿæˆæ¡†æ¶æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ˜¾å¼åœ°å»ºæ¨¡äººä¸äººä¹‹é—´çš„äº¤äº’å…³ç³»ï¼Œå¹¶å°†å…¶ä¸äººä¸ç‰©ä½“çš„äº¤äº’å…³ç³»ç›¸ç»“åˆï¼Œä»è€Œç”Ÿæˆæ›´é€¼çœŸã€æ›´ç¬¦åˆä¸Šä¸‹æ–‡çš„äº¤äº’åœºæ™¯ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜æå‡ºäº†ä¸€ä¸ªæ•°æ®åˆæˆç­–ç•¥ï¼Œç”¨äºè§£å†³HHOIæ•°æ®é›†çš„ç¼ºä¹é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä½¿ç”¨äº†åŸºäºåˆ†æ•°çš„æ‰©æ•£æ¨¡å‹ä½œä¸ºHOIå’ŒHHIç”Ÿæˆå™¨çš„æ ¸å¿ƒã€‚æ‰©æ•£æ¨¡å‹é€šè¿‡é€æ­¥æ·»åŠ å™ªå£°åˆ°æ•°æ®ä¸­ï¼Œç„¶åå­¦ä¹ å¦‚ä½•ä»å™ªå£°ä¸­æ¢å¤æ•°æ®ï¼Œä»è€Œå®ç°é«˜è´¨é‡çš„ç”Ÿæˆã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜è®¾è®¡äº†ä¸€ä¸ªç»Ÿä¸€çš„é‡‡æ ·è¿‡ç¨‹ï¼Œç”¨äºå°†HOIå’ŒHHIæ¨¡å‹é›†æˆåœ¨ä¸€èµ·ï¼Œç”Ÿæˆå®Œæ•´çš„HHOIåœºæ™¯ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ï¼Œä½†æ‘˜è¦ä¸­æœªæ˜ç¡®æåŠã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ–‡æœ¬é©±åŠ¨çš„HHOIç”Ÿæˆä»»åŠ¡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ã€‚é€šè¿‡å®šæ€§å’Œå®šé‡è¯„ä¼°ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆæ›´é€¼çœŸã€æ›´ç¬¦åˆæ–‡æœ¬æè¿°çš„HHOIåœºæ™¯ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜æˆåŠŸåœ°åº”ç”¨äºå¤šäººè¿åŠ¨ç”Ÿæˆä»»åŠ¡ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤æ‚åœºæ™¯ä¸‹çš„æ³›åŒ–èƒ½åŠ›ã€‚å…·ä½“çš„æ€§èƒ½æŒ‡æ ‡å’Œå¯¹æ¯”åŸºçº¿åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†çš„å±•ç¤ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè™šæ‹Ÿç°å®ã€æ¸¸æˆå¼€å‘ã€ç¤¾äº¤æœºå™¨äººç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œå¯ä»¥ç”¨äºç”Ÿæˆæ›´é€¼çœŸçš„è™šæ‹Ÿç¤¾äº¤åœºæ™¯ï¼Œè®­ç»ƒç¤¾äº¤æœºå™¨äººç†è§£å’Œæ¨¡æ‹Ÿäººç±»çš„äº¤äº’è¡Œä¸ºï¼Œä»¥åŠè¾…åŠ©è®¾è®¡æ›´ç¬¦åˆäººç±»ä¹ æƒ¯çš„äº¤äº’ç•Œé¢ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›æ‰©å±•åˆ°æ›´å¤æ‚çš„å¤šäººäº¤äº’åœºæ™¯ï¼Œå¹¶åº”ç”¨äºæ™ºèƒ½ç›‘æ§ã€è¡Œä¸ºåˆ†æç­‰é¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The way humans interact with each other, including interpersonal distances, spatial configuration, and motion, varies significantly across different situations. To enable machines to understand such complex, context-dependent behaviors, it is essential to model multiple people in relation to the surrounding scene context. In this paper, we present a novel research problem to model the correlations between two people engaged in a shared interaction involving an object. We refer to this formulation as Human-Human-Object Interactions (HHOIs). To overcome the lack of dedicated datasets for HHOIs, we present a newly captured HHOIs dataset and a method to synthesize HHOI data by leveraging image generative models. As an intermediary, we obtain individual human-object interaction (HOIs) and human-human interaction (HHIs) from the HHOIs, and with these data, we train an text-to-HOI and text-to-HHI model using score-based diffusion model. Finally, we present a unified generative framework that integrates the two individual model, capable of synthesizing complete HHOIs in a single advanced sampling process. Our method extends HHOI generation to multi-human settings, enabling interactions involving more than two individuals. Experimental results show that our method generates realistic HHOIs conditioned on textual descriptions, outperforming previous approaches that focus only on single-human HOIs. Furthermore, we introduce multi-human motion generation involving objects as an application of our framework.

