---
layout: default
title: Material-informed Gaussian Splatting for 3D World Reconstruction in a Digital Twin
---

# Material-informed Gaussian Splatting for 3D World Reconstruction in a Digital Twin

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.20348" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.20348v2</a>
  <a href="https://arxiv.org/pdf/2511.20348.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.20348v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.20348v2', 'Material-informed Gaussian Splatting for 3D World Reconstruction in a Digital Twin')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Andy Huynh, JoÃ£o Malheiro Silva, Holger Caesar, Tong Duy Son

**åˆ†ç±»**: cs.CV, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-11-25 (æ›´æ–°: 2025-11-28)

**å¤‡æ³¨**: 8 pages, 5 figures. Submitted to IEEE Intelligent Vehicles Symposium (IV) 2026 for possible publication. Revised version (v2) to correct author order

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºæè´¨ä¿¡æ¯çš„3Dé«˜æ–¯æº…å°„æ–¹æ³•ï¼Œç”¨äºæ•°å­—å­ªç”Ÿä¸­çš„ä¸‰ç»´ä¸–ç•Œé‡å»º**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `3Dé‡å»º` `é«˜æ–¯æº…å°„` `æ•°å­—å­ªç”Ÿ` `æè´¨ä¿¡æ¯` `ä¼ æ„Ÿå™¨æ¨¡æ‹Ÿ` `è®¡ç®—æœºè§†è§‰` `è¯­ä¹‰åˆ†å‰²`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿæ¿€å…‰é›·è¾¾-ç›¸æœºèåˆæ–¹æ³•æ ‡å®šå¤æ‚ï¼Œä¸”éš¾ä»¥å¤„ç†ç»ç’ƒç­‰æè´¨ï¼Œè¿™äº›æè´¨åœ¨å›¾åƒä¸­å¯è§ï¼Œä½†åœ¨ç‚¹äº‘ä¸­è¡¨ç°ä¸ä½³ã€‚
2. æå‡ºä¸€ç§çº¯ç›¸æœºæµæ°´çº¿ï¼Œåˆ©ç”¨3Dé«˜æ–¯æº…å°„é‡å»ºåœºæ™¯ï¼Œæå–è¯­ä¹‰æè´¨æ©ç ï¼Œå¹¶èµ‹äºˆç‰©ç†æè´¨å±æ€§ï¼Œç”¨äºä¼ æ„Ÿå™¨æ¨¡æ‹Ÿã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¼ æ„Ÿå™¨æ¨¡æ‹Ÿä¿çœŸåº¦ä¸Šå¯ä¸æ¿€å…‰é›·è¾¾-ç›¸æœºèåˆåª²ç¾ï¼ŒåŒæ—¶é™ä½äº†ç¡¬ä»¶å¤æ‚åº¦å’Œæ ‡å®šéš¾åº¦ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§ä»…ä½¿ç”¨ç›¸æœºçš„æµæ°´çº¿æ–¹æ³•ï¼Œç”¨äºæ•°å­—å­ªç”Ÿä¸­çš„ä¸‰ç»´é‡å»ºã€‚è¯¥æ–¹æ³•åˆ©ç”¨å¤šè§†è§’å›¾åƒé€šè¿‡3Dé«˜æ–¯æº…å°„é‡å»ºåœºæ™¯ï¼Œé€šè¿‡è§†è§‰æ¨¡å‹æå–è¯­ä¹‰æè´¨æ©ç ï¼Œå¹¶å°†é«˜æ–¯è¡¨ç¤ºè½¬æ¢ä¸ºå¸¦æœ‰æŠ•å½±æè´¨æ ‡ç­¾çš„ç½‘æ ¼è¡¨é¢ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜ä¸ºç½‘æ ¼èµ‹äºˆåŸºäºç‰©ç†çš„æè´¨å±æ€§ï¼Œä»¥ä¾¿åœ¨ç°ä»£å›¾å½¢å¼•æ“å’Œæ¨¡æ‹Ÿå™¨ä¸­å®ç°ç²¾ç¡®çš„ä¼ æ„Ÿå™¨æ¨¡æ‹Ÿã€‚è¯¥æ–¹æ³•ç»“åˆäº†ç…§ç‰‡çº§çœŸå®æ„Ÿé‡å»ºå’ŒåŸºäºç‰©ç†çš„æè´¨åˆ†é…ï¼Œæä¾›äº†ä¸æ¿€å…‰é›·è¾¾-ç›¸æœºèåˆç›¸å½“çš„ä¼ æ„Ÿå™¨æ¨¡æ‹Ÿä¿çœŸåº¦ï¼ŒåŒæ—¶æ¶ˆé™¤äº†ç¡¬ä»¶å¤æ‚æ€§å’Œæ ‡å®šéœ€æ±‚ã€‚æˆ‘ä»¬ä½¿ç”¨æ¥è‡ªä»ªå™¨åŒ–æµ‹è¯•è½¦è¾†çš„å†…éƒ¨æ•°æ®é›†éªŒè¯äº†æˆ‘ä»¬çš„çº¯ç›¸æœºæ–¹æ³•ï¼Œåˆ©ç”¨æ¿€å…‰é›·è¾¾ä½œä¸ºåå°„ç‡éªŒè¯çš„ground truthï¼Œå¹¶ç»“åˆå›¾åƒç›¸ä¼¼æ€§æŒ‡æ ‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æ•°å­—å­ªç”Ÿä¸­çš„ä¸‰ç»´é‡å»ºæ–¹æ³•é€šå¸¸ä¾èµ–äºæ¿€å…‰é›·è¾¾ï¼Œè™½ç„¶èƒ½æä¾›ç²¾ç¡®çš„å‡ ä½•ä¿¡æ¯ï¼Œä½†ç¼ºä¹ç›¸æœºæ•æ‰çš„è¯­ä¹‰å’Œçº¹ç†ä¿¡æ¯ã€‚æ¿€å…‰é›·è¾¾-ç›¸æœºèåˆæ–¹æ³•éœ€è¦å¤æ‚çš„æ ‡å®šè¿‡ç¨‹ï¼Œå¹¶ä¸”åœ¨å¤„ç†ç»ç’ƒç­‰æè´¨æ—¶æ•ˆæœä¸ä½³ï¼Œå› ä¸ºè¿™äº›æè´¨åœ¨å›¾åƒä¸­æ¸…æ™°å¯è§ï¼Œä½†åœ¨æ¿€å…‰é›·è¾¾ç‚¹äº‘ä¸­è¡¨ç°å¾ˆå·®ã€‚å› æ­¤ï¼Œå¦‚ä½•ä»…ä½¿ç”¨ç›¸æœºæ•°æ®ï¼Œå®ç°é«˜è´¨é‡ã€å…·æœ‰è¯­ä¹‰ä¿¡æ¯å’Œç‰©ç†å±æ€§çš„ä¸‰ç»´é‡å»ºæ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨3Dé«˜æ–¯æº…å°„æŠ€æœ¯ï¼Œä»å¤šè§†è§’å›¾åƒä¸­é‡å»ºåœºæ™¯ï¼Œå¹¶ç»“åˆè§†è§‰æ¨¡å‹æå–è¯­ä¹‰æè´¨ä¿¡æ¯ï¼Œç„¶åå°†è¿™äº›ä¿¡æ¯èµ‹äºˆåˆ°é‡å»ºçš„3Dæ¨¡å‹ä¸Šã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå¯ä»¥å®ç°ç…§ç‰‡çº§çœŸå®æ„Ÿçš„ä¸‰ç»´é‡å»ºï¼Œå¹¶ä¸ºæ¨¡å‹èµ‹äºˆåŸºäºç‰©ç†çš„æè´¨å±æ€§ï¼Œä»è€Œæé«˜ä¼ æ„Ÿå™¨æ¨¡æ‹Ÿçš„çœŸå®åº¦å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) ä½¿ç”¨å¤šè§†è§’å›¾åƒè¿›è¡Œ3Dé«˜æ–¯æº…å°„é‡å»ºï¼›2) åˆ©ç”¨è§†è§‰æ¨¡å‹æå–è¯­ä¹‰æè´¨æ©ç ï¼›3) å°†é«˜æ–¯è¡¨ç¤ºè½¬æ¢ä¸ºå¸¦æœ‰æŠ•å½±æè´¨æ ‡ç­¾çš„ç½‘æ ¼è¡¨é¢ï¼›4) ä¸ºç½‘æ ¼è¡¨é¢èµ‹äºˆåŸºäºç‰©ç†çš„æè´¨å±æ€§ã€‚æ•´ä¸ªæµç¨‹ä»å›¾åƒæ•°æ®å¼€å§‹ï¼Œæœ€ç»ˆç”Ÿæˆå…·æœ‰å‡ ä½•ã€çº¹ç†ã€è¯­ä¹‰å’Œç‰©ç†å±æ€§çš„ä¸‰ç»´æ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå°†3Dé«˜æ–¯æº…å°„æŠ€æœ¯ä¸æè´¨ä¿¡æ¯æå–ç›¸ç»“åˆï¼Œå®ç°äº†ä»…ä½¿ç”¨ç›¸æœºæ•°æ®çš„é«˜è´¨é‡ä¸‰ç»´é‡å»ºã€‚ä¸ä¼ ç»Ÿçš„æ¿€å…‰é›·è¾¾-ç›¸æœºèåˆæ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•æ— éœ€å¤æ‚çš„ç¡¬ä»¶æ ‡å®šï¼Œå¹¶ä¸”èƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†ç»ç’ƒç­‰æè´¨ã€‚æ­¤å¤–ï¼Œé€šè¿‡èµ‹äºˆæ¨¡å‹åŸºäºç‰©ç†çš„æè´¨å±æ€§ï¼Œæé«˜äº†ä¼ æ„Ÿå™¨æ¨¡æ‹Ÿçš„çœŸå®åº¦å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­ä½¿ç”¨äº†3Dé«˜æ–¯æº…å°„æŠ€æœ¯è¿›è¡Œåœºæ™¯é‡å»ºï¼Œå¹¶åˆ©ç”¨è§†è§‰æ¨¡å‹ï¼ˆå…·ä½“æ¨¡å‹æœªçŸ¥ï¼‰æå–è¯­ä¹‰æè´¨æ©ç ã€‚é«˜æ–¯è¡¨ç¤ºåˆ°ç½‘æ ¼è¡¨é¢çš„è½¬æ¢ä»¥åŠæè´¨æ ‡ç­¾çš„æŠ•å½±æ–¹æ³•çš„å…·ä½“ç»†èŠ‚æœªçŸ¥ã€‚æ­¤å¤–ï¼Œå¦‚ä½•æ ¹æ®è¯­ä¹‰æè´¨ä¿¡æ¯ç¡®å®šåˆé€‚çš„ç‰©ç†æè´¨å±æ€§ï¼Œä»¥åŠå…·ä½“çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ç­‰ç»†èŠ‚ä¹ŸæœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡ä½¿ç”¨å†…éƒ¨æ•°æ®é›†è¿›è¡Œäº†éªŒè¯ï¼Œè¯¥æ•°æ®é›†æ¥è‡ªä»ªå™¨åŒ–æµ‹è¯•è½¦è¾†ï¼Œå¹¶ä½¿ç”¨æ¿€å…‰é›·è¾¾æ•°æ®ä½œä¸ºåå°„ç‡éªŒè¯çš„ground truthã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥çº¯ç›¸æœºæ–¹æ³•åœ¨ä¼ æ„Ÿå™¨æ¨¡æ‹Ÿä¿çœŸåº¦ä¸Šå¯ä¸æ¿€å…‰é›·è¾¾-ç›¸æœºèåˆæ–¹æ³•ç›¸åª²ç¾ï¼ŒåŒæ—¶æ¶ˆé™¤äº†ç¡¬ä»¶å¤æ‚æ€§å’Œæ ‡å®šéœ€æ±‚ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦æœªçŸ¥ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºæ•°å­—å­ªç”Ÿã€è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€è™šæ‹Ÿç°å®ç­‰é¢†åŸŸã€‚é€šè¿‡æ„å»ºå…·æœ‰çœŸå®æ„Ÿå’Œç‰©ç†å±æ€§çš„ä¸‰ç»´ç¯å¢ƒæ¨¡å‹ï¼Œå¯ä»¥ä¸ºè‡ªåŠ¨é©¾é©¶è½¦è¾†çš„ä¼ æ„Ÿå™¨æ¨¡æ‹Ÿæä¾›æ›´å‡†ç¡®çš„æ•°æ®ï¼Œæé«˜ç®—æ³•çš„é²æ£’æ€§å’Œå®‰å…¨æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºè™šæ‹Ÿç°å®åœºæ™¯çš„åˆ›å»ºï¼Œæä¾›æ›´é€¼çœŸçš„ç”¨æˆ·ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> 3D reconstruction for Digital Twins often relies on LiDAR-based methods, which provide accurate geometry but lack the semantics and textures naturally captured by cameras. Traditional LiDAR-camera fusion approaches require complex calibration and still struggle with certain materials like glass, which are visible in images but poorly represented in point clouds. We propose a camera-only pipeline that reconstructs scenes using 3D Gaussian Splatting from multi-view images, extracts semantic material masks via vision models, converts Gaussian representations to mesh surfaces with projected material labels, and assigns physics-based material properties for accurate sensor simulation in modern graphics engines and simulators. This approach combines photorealistic reconstruction with physics-based material assignment, providing sensor simulation fidelity comparable to LiDAR-camera fusion while eliminating hardware complexity and calibration requirements. We validate our camera-only method using an internal dataset from an instrumented test vehicle, leveraging LiDAR as ground truth for reflectivity validation alongside image similarity metrics.

