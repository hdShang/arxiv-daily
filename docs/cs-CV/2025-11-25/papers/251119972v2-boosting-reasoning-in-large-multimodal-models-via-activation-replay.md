---
layout: default
title: Boosting Reasoning in Large Multimodal Models via Activation Replay
---

# Boosting Reasoning in Large Multimodal Models via Activation Replay

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.19972" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.19972v2</a>
  <a href="https://arxiv.org/pdf/2511.19972.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.19972v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.19972v2', 'Boosting Reasoning in Large Multimodal Models via Activation Replay')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yun Xing, Xiaobin Hu, Qingdong He, Jiangning Zhang, Shuicheng Yan, Shijian Lu, Yu-Gang Jiang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-25 (æ›´æ–°: 2025-11-27)

**å¤‡æ³¨**: 11 figures, 10 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºActivation Replayï¼Œé€šè¿‡æ¿€æ´»é‡æ”¾æå‡å¤§å‹å¤šæ¨¡æ€æ¨¡å‹æ¨ç†èƒ½åŠ›ï¼Œæ— éœ€é¢å¤–è®­ç»ƒã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ¨ç†` `å¤§å‹è¯­è¨€æ¨¡å‹` `å¼ºåŒ–å­¦ä¹ ` `æ¿€æ´»é‡æ”¾` `ä½ç†µæ¿€æ´»` `è§†è§‰æ™ºèƒ½ä½“` `è§†é¢‘ç†è§£`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•å¯¹RLVRæå‡LMMæ¨ç†èƒ½åŠ›çš„æœºåˆ¶ç†è§£ä¸è¶³ï¼Œç¼ºä¹æœ‰æ•ˆåˆ©ç”¨æ¿€æ´»ä¿¡æ¯çš„ç­–ç•¥ã€‚
2. æå‡ºActivation Replayï¼Œé€šè¿‡é‡æ”¾ä½ç†µæ¿€æ´»æ¥è°ƒèŠ‚RLVRåçš„LMMï¼Œæå‡æ¨ç†èƒ½åŠ›ï¼Œæ— éœ€é¢å¤–è®­ç»ƒã€‚
3. å®éªŒè¡¨æ˜ï¼ŒActivation Replayåœ¨å¤šç§æ¨ç†ä»»åŠ¡ä¸Šæœ‰æ•ˆï¼Œæå‡Pass@KæŒ‡æ ‡ï¼Œå¹¶æ‰©å¤§æ¨ç†è¦†ç›–èŒƒå›´ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æ—¨åœ¨æ·±å…¥ç†è§£ä½¿ç”¨å¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ (RLVR)æå‡å¤§å‹å¤šæ¨¡æ€æ¨¡å‹(LMMs)æ¨ç†èƒ½åŠ›çš„å†…åœ¨æœºåˆ¶ã€‚é€šè¿‡logit lensè§†è§’ï¼Œç ”ç©¶å‘ç°RLVRä¸»è¦å½±å“ä½ç†µæ¿€æ´»ï¼Œè€Œå¯¹é«˜ç†µæ¿€æ´»å½±å“è¾ƒå°ã€‚å—æ­¤å¯å‘ï¼Œè®ºæ–‡æå‡ºActivation Replayï¼Œä¸€ç§æ— éœ€è®­ç»ƒçš„æ–¹æ³•ï¼Œé€šè¿‡åœ¨æµ‹è¯•æ—¶æ“çºµè§†è§‰tokensï¼Œé‡æ”¾æ¥è‡ªåŸºç¡€LMMè¾“å…¥ä¸Šä¸‹æ–‡çš„ä½ç†µæ¿€æ´»ï¼Œä»¥è°ƒèŠ‚RLVRåçš„æ¨¡å‹ï¼Œä»è€Œæå‡å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ï¼ŒActivation Replayåœ¨æ•°å­¦ã€è§†è§‰æ™ºèƒ½ä½“å’Œè§†é¢‘æ¨ç†ç­‰åœºæ™¯ä¸­å‡èƒ½æœ‰æ•ˆæå‡æ¨ç†èƒ½åŠ›ï¼Œæé«˜Pass@KæŒ‡æ ‡ï¼Œå¹¶ç¼“è§£RLVRå¸¦æ¥çš„æ¨ç†è¦†ç›–èŒƒå›´ç¼©å°é—®é¢˜ã€‚å¯¹æ¯”å®éªŒéªŒè¯äº†é‡æ”¾ä½ç†µæ¿€æ´»ä¼˜äºé«˜ç†µæ¿€æ´»ï¼Œä»¥åŠæ“çºµè¾“å…¥tokensä¼˜äºç›´æ¥è·¨æ¨¡å‹å¹²é¢„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ï¼ˆLMMsï¼‰åœ¨ç»è¿‡åŸºäºå¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLVRï¼‰åï¼Œå…¶æ¨ç†èƒ½åŠ›æå‡çš„å†…åœ¨æœºåˆ¶ä¸æ˜ç¡®çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹å¯¹RLVRå¦‚ä½•å½±å“æ¨¡å‹å†…éƒ¨æ¿€æ´»çš„æ·±å…¥ç†è§£ï¼Œä»¥åŠå¦‚ä½•æœ‰æ•ˆåˆ©ç”¨è¿™äº›æ¿€æ´»ä¿¡æ¯æ¥è¿›ä¸€æ­¥æå‡æ¨ç†èƒ½åŠ›ã€‚RLVRè™½ç„¶èƒ½æå‡æ¨ç†èƒ½åŠ›ï¼Œä½†ä¹Ÿå¯èƒ½å¯¼è‡´æ¨ç†è¦†ç›–èŒƒå›´ç¼©å°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯è§‚å¯Ÿåˆ°RLVRä¸»è¦å½±å“ä½ç†µæ¿€æ´»ï¼Œè€Œå¯¹é«˜ç†µæ¿€æ´»å½±å“è¾ƒå°ã€‚åŸºäºæ­¤ï¼Œè®ºæ–‡æå‡ºé€šè¿‡åœ¨æµ‹è¯•æ—¶é‡æ”¾ä½ç†µæ¿€æ´»æ¥è°ƒèŠ‚RLVRåçš„æ¨¡å‹ï¼Œä»è€Œåœ¨ä¸è¿›è¡Œé¢å¤–è®­ç»ƒçš„æƒ…å†µä¸‹æå‡æ¨ç†èƒ½åŠ›ã€‚è¿™ç§æ€è·¯çš„åˆç†æ€§åœ¨äºï¼Œä½ç†µæ¿€æ´»å¯èƒ½åŒ…å«æ¨¡å‹æ¨ç†è¿‡ç¨‹ä¸­æ›´å…³é”®çš„ä¿¡æ¯ï¼Œé€šè¿‡é‡æ”¾è¿™äº›æ¿€æ´»å¯ä»¥å¼•å¯¼æ¨¡å‹è¿›è¡Œæ›´å‡†ç¡®çš„æ¨ç†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šActivation Replayçš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1) ä½¿ç”¨åŸºç¡€LMMå¤„ç†è¾“å…¥ä¸Šä¸‹æ–‡ï¼Œè·å–ä½ç†µæ¿€æ´»ï¼›2) ä½¿ç”¨RLVRåçš„LMMå¤„ç†ç›¸åŒçš„è¾“å…¥ä¸Šä¸‹æ–‡ï¼›3) åœ¨RLVRåçš„LMMä¸­ï¼Œé€šè¿‡æ“çºµè§†è§‰tokensï¼Œé‡æ”¾æ¥è‡ªåŸºç¡€LMMçš„ä½ç†µæ¿€æ´»ï¼›4) ä½¿ç”¨é‡æ”¾æ¿€æ´»åçš„RLVRæ¨¡å‹è¿›è¡Œæ¨ç†å¹¶è¾“å‡ºç»“æœã€‚æ•´ä¸ªè¿‡ç¨‹æ— éœ€è®­ç»ƒï¼Œä»…åœ¨æµ‹è¯•é˜¶æ®µè¿›è¡Œã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºActivation Replayè¿™ä¸€ç®€å•è€Œæœ‰æ•ˆçš„è®­ç»ƒ-freeæ–¹æ³•ï¼Œé€šè¿‡é‡æ”¾ä½ç†µæ¿€æ´»æ¥æå‡LMMçš„æ¨ç†èƒ½åŠ›ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒActivation Replayä¸éœ€è¦é¢å¤–çš„è®­ç»ƒï¼Œå¯ä»¥ç›´æ¥åº”ç”¨äºå·²ç»ç»è¿‡RLVRè®­ç»ƒçš„æ¨¡å‹ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜é€šè¿‡å®éªŒéªŒè¯äº†é‡æ”¾ä½ç†µæ¿€æ´»ä¼˜äºé‡æ”¾é«˜ç†µæ¿€æ´»ï¼Œä»¥åŠæ“çºµè¾“å…¥tokensä¼˜äºç›´æ¥è·¨æ¨¡å‹å¹²é¢„ã€‚

**å…³é”®è®¾è®¡**ï¼šActivation Replayçš„å…³é”®è®¾è®¡åœ¨äºå¦‚ä½•é€‰æ‹©å’Œé‡æ”¾ä½ç†µæ¿€æ´»ã€‚è®ºæ–‡é€šè¿‡è®¡ç®—è§†è§‰tokensçš„ç†µå€¼æ¥é€‰æ‹©ä½ç†µæ¿€æ´»ï¼Œå…·ä½“å®ç°ç»†èŠ‚æœªçŸ¥ã€‚é‡æ”¾çš„æ–¹å¼æ˜¯é€šè¿‡æ“çºµè§†è§‰tokensï¼Œå°†åŸºç¡€LMMçš„ä½ç†µæ¿€æ´»æ³¨å…¥åˆ°RLVRåçš„LMMä¸­ã€‚å…·ä½“æ“çºµæ–¹å¼å’Œå‚æ•°è®¾ç½®æœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒActivation Replayåœ¨æ•°å­¦ã€è§†è§‰æ™ºèƒ½ä½“å’Œè§†é¢‘æ¨ç†ç­‰å¤šç§åœºæ™¯ä¸­å‡èƒ½æœ‰æ•ˆæå‡æ¨ç†èƒ½åŠ›ã€‚ä¾‹å¦‚ï¼Œåœ¨æŸäº›ä»»åŠ¡ä¸Šï¼ŒPass@KæŒ‡æ ‡å¾—åˆ°äº†æ˜¾è‘—æå‡ï¼Œå¹¶ä¸”ç¼“è§£äº†RLVRå¸¦æ¥çš„æ¨ç†è¦†ç›–èŒƒå›´ç¼©å°é—®é¢˜ã€‚å¯¹æ¯”å®éªŒéªŒè¯äº†é‡æ”¾ä½ç†µæ¿€æ´»ä¼˜äºé«˜ç†µæ¿€æ´»ï¼Œä»¥åŠæ“çºµè¾“å…¥tokensä¼˜äºç›´æ¥è·¨æ¨¡å‹å¹²é¢„ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Activation Replayå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯ä»¥åº”ç”¨äºå„ç§éœ€è¦å¤šæ¨¡æ€æ¨ç†çš„åœºæ™¯ï¼Œä¾‹å¦‚æ™ºèƒ½å®¢æœã€è‡ªåŠ¨é©¾é©¶ã€åŒ»ç–—è¯Šæ–­ç­‰ã€‚è¯¥æ–¹æ³•æ— éœ€é¢å¤–è®­ç»ƒï¼Œå¯ä»¥å¿«é€Ÿæå‡ç°æœ‰LMMçš„æ¨ç†èƒ½åŠ›ï¼Œå…·æœ‰å¾ˆé«˜çš„å®é™…åº”ç”¨ä»·å€¼ã€‚æœªæ¥å¯ä»¥æ¢ç´¢å¦‚ä½•æ›´æœ‰æ•ˆåœ°é€‰æ‹©å’Œé‡æ”¾æ¿€æ´»ï¼Œä»¥åŠå¦‚ä½•å°†Activation Replayä¸å…¶ä»–æ¨ç†å¢å¼ºæŠ€æœ¯ç›¸ç»“åˆã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recently, Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as an effective approach to incentivizing reasoning capability in Large Multimodal Models (LMMs), while the underlying mechanisms behind this post-training paradigm are poorly understood. We begin by exploring how input activations are affected by RLVR through the perspective of logit lens. Our systematic investigations across multiple post-trained LMMs suggest that RLVR shifts low-entropy activations unexpectedly, while high-entropy ones are less affected. We further demonstrate that such phenomena are associated with LMM reasoning by controlled experiments, suggesting a potentially beneficial role of modulating low-entropy activations. To this end, we propose Activation Replay, a novel simple yet effective training-free approach that boosts multimodal reasoning of post-trained LMMs without requiring expensive policy optimization. Our design involves manipulation of visual tokens at test time, replaying low-entropy activations from the input context of base LMMs to regulating the RLVR counterparts. Activation Replay triggers better reasoning across diverse scenarios, including mathematics, o3-like visual agents, and video reasoning. We further show that Activation Replay boosts Pass@K and mitigates narrower reasoning coverage of RLVR. Our design is compared against alternative choices, such as replaying high-entropy activations instead of low-entropy ones, or direct cross-model intervention instead of manipulating input tokens, demonstrating the superiority of our implementation. Codes will be made publicly available.

