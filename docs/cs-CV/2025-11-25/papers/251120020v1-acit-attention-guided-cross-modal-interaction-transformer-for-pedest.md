---
layout: default
title: "ACIT: Attention-Guided Cross-Modal Interaction Transformer for Pedestrian Crossing Intention Prediction"
---

# ACIT: Attention-Guided Cross-Modal Interaction Transformer for Pedestrian Crossing Intention Prediction

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.20020" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.20020v1</a>
  <a href="https://arxiv.org/pdf/2511.20020.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.20020v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.20020v1', 'ACIT: Attention-Guided Cross-Modal Interaction Transformer for Pedestrian Crossing Intention Prediction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuanzhe Li, Steffen MÃ¼ller

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-25

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºACITæ¨¡å‹ï¼Œåˆ©ç”¨æ³¨æ„åŠ›æœºåˆ¶å’Œè·¨æ¨¡æ€äº¤äº’Transformeræå‡è¡Œäººè¿‡è¡—æ„å›¾é¢„æµ‹ç²¾åº¦ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)** **æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction)**

**å…³é”®è¯**: `è¡Œäººæ„å›¾é¢„æµ‹` `è·¨æ¨¡æ€äº¤äº’` `æ³¨æ„åŠ›æœºåˆ¶` `Transformer` `è‡ªåŠ¨é©¾é©¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è¡Œäººæ„å›¾é¢„æµ‹æ–¹æ³•éš¾ä»¥æœ‰æ•ˆæå–å’Œæ•´åˆæ¥è‡ªä¸åŒç±»å‹æ•°æ®çš„äº’è¡¥ä¿¡æ¯ã€‚
2. ACITæ¨¡å‹é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶å¼•å¯¼è·¨æ¨¡æ€ç‰¹å¾äº¤äº’ï¼Œå¹¶åˆ©ç”¨Transformeræ•è·æ—¶åºä¾èµ–å…³ç³»ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒACITåœ¨JAADæ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ³¨æ„åŠ›æœºåˆ¶å¼•å¯¼çš„è·¨æ¨¡æ€äº¤äº’Transformer (ACIT) ç”¨äºè¡Œäººè¿‡è¡—æ„å›¾é¢„æµ‹ã€‚ACITåˆ©ç”¨å…­ç§è§†è§‰å’Œè¿åŠ¨æ¨¡æ€æ•°æ®ï¼Œå¹¶å°†å®ƒä»¬åˆ†ä¸ºä¸‰ä¸ªäº¤äº’å¯¹ï¼š(1) å…¨å±€è¯­ä¹‰åœ°å›¾å’Œå…¨å±€å…‰æµï¼Œ(2) å±€éƒ¨RGBå›¾åƒå’Œå±€éƒ¨å…‰æµï¼Œ(3) è‡ªè½¦é€Ÿåº¦å’Œè¡Œäººè¾¹ç•Œæ¡†ã€‚åœ¨æ¯ä¸ªè§†è§‰äº¤äº’å¯¹ä¸­ï¼ŒåŒè·¯å¾„æ³¨æ„åŠ›æœºåˆ¶é€šè¿‡å†…æ¨¡æ€è‡ªæ³¨æ„åŠ›å¢å¼ºä¸»è¦æ¨¡æ€ä¸­çš„æ˜¾è‘—åŒºåŸŸï¼Œå¹¶é€šè¿‡å…‰æµå¼•å¯¼çš„æ³¨æ„åŠ›ä¿ƒè¿›ä¸è¾…åŠ©æ¨¡æ€ï¼ˆå³å…‰æµï¼‰çš„æ·±åº¦äº¤äº’ã€‚åœ¨è¿åŠ¨äº¤äº’å¯¹ä¸­ï¼Œé‡‡ç”¨è·¨æ¨¡æ€æ³¨æ„åŠ›æ¥å»ºæ¨¡è·¨æ¨¡æ€åŠ¨æ€ï¼Œä»è€Œæœ‰æ•ˆæå–äº’è¡¥çš„è¿åŠ¨ç‰¹å¾ã€‚é™¤äº†æˆå¯¹äº¤äº’ä¹‹å¤–ï¼Œå¤šæ¨¡æ€ç‰¹å¾èåˆæ¨¡å—è¿›ä¸€æ­¥ä¿ƒè¿›æ¯ä¸ªæ—¶é—´æ­¥çš„è·¨æ¨¡æ€äº¤äº’ã€‚æ­¤å¤–ï¼Œå¼•å…¥åŸºäºTransformerçš„æ—¶åºç‰¹å¾èšåˆæ¨¡å—æ¥æ•è·åºåˆ—ä¾èµ–æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒACITä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œåœ¨JAADbehå’ŒJAADallæ•°æ®é›†ä¸Šåˆ†åˆ«å®ç°äº†70%å’Œ89%çš„å‡†ç¡®ç‡ã€‚æ­¤å¤–ï¼Œè¿˜è¿›è¡Œäº†å¹¿æ³›çš„æ¶ˆèç ”ç©¶ï¼Œä»¥ç ”ç©¶ACITä¸åŒæ¨¡å—çš„è´¡çŒ®ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè¡Œäººè¿‡è¡—æ„å›¾é¢„æµ‹æ˜¯è‡ªåŠ¨é©¾é©¶çš„å…³é”®ä»»åŠ¡ï¼Œæ—¨åœ¨å‡å°‘è¡Œäººç›¸å…³çš„äº¤é€šäº‹æ•…ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆèåˆæ¥è‡ªä¸åŒæ¨¡æ€ï¼ˆå¦‚è§†è§‰å’Œè¿åŠ¨ï¼‰çš„äº’è¡¥ä¿¡æ¯ï¼Œå¯¼è‡´é¢„æµ‹ç²¾åº¦å—é™ã€‚å°¤å…¶æ˜¯åœ¨å¤æ‚åœºæ™¯ä¸‹ï¼Œå¦‚ä½•å‡†ç¡®æ•æ‰è¡Œäººè¡Œä¸ºçš„æ—¶åºä¾èµ–æ€§ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šACITçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶å¼•å¯¼è·¨æ¨¡æ€ç‰¹å¾çš„äº¤äº’ï¼Œå¹¶åˆ©ç”¨Transformeræ¨¡å‹æ•è·æ—¶åºä¾èµ–å…³ç³»ã€‚é€šè¿‡å°†è§†è§‰å’Œè¿åŠ¨æ¨¡æ€è¿›è¡Œé…å¯¹ï¼Œå¹¶è®¾è®¡ç›¸åº”çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ¨¡å‹èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°æå–å’Œèåˆä¸åŒæ¨¡æ€çš„äº’è¡¥ä¿¡æ¯ã€‚Transformeræ¨¡å‹åˆ™ç”¨äºå»ºæ¨¡è¡Œäººè¡Œä¸ºçš„æ—¶åºåŠ¨æ€ï¼Œä»è€Œæé«˜é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šACITçš„æ•´ä½“æ¶æ„åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) **è·¨æ¨¡æ€äº¤äº’æ¨¡å—**ï¼šå°†å…­ç§æ¨¡æ€æ•°æ®åˆ†ä¸ºä¸‰ä¸ªäº¤äº’å¯¹ï¼Œåˆ†åˆ«æ˜¯å…¨å±€è¯­ä¹‰åœ°å›¾å’Œå…¨å±€å…‰æµã€å±€éƒ¨RGBå›¾åƒå’Œå±€éƒ¨å…‰æµã€è‡ªè½¦é€Ÿåº¦å’Œè¡Œäººè¾¹ç•Œæ¡†ã€‚2) **åŒè·¯å¾„æ³¨æ„åŠ›æœºåˆ¶**ï¼šåœ¨è§†è§‰äº¤äº’å¯¹ä¸­ï¼Œåˆ©ç”¨åŒè·¯å¾„æ³¨æ„åŠ›æœºåˆ¶å¢å¼ºä¸»è¦æ¨¡æ€çš„æ˜¾è‘—åŒºåŸŸï¼Œå¹¶é€šè¿‡å…‰æµå¼•å¯¼çš„æ³¨æ„åŠ›ä¿ƒè¿›ä¸è¾…åŠ©æ¨¡æ€çš„æ·±åº¦äº¤äº’ã€‚3) **è·¨æ¨¡æ€æ³¨æ„åŠ›**ï¼šåœ¨è¿åŠ¨äº¤äº’å¯¹ä¸­ï¼Œé‡‡ç”¨è·¨æ¨¡æ€æ³¨æ„åŠ›æ¥å»ºæ¨¡è·¨æ¨¡æ€åŠ¨æ€ã€‚4) **å¤šæ¨¡æ€ç‰¹å¾èåˆæ¨¡å—**ï¼šè¿›ä¸€æ­¥ä¿ƒè¿›æ¯ä¸ªæ—¶é—´æ­¥çš„è·¨æ¨¡æ€äº¤äº’ã€‚5) **Transformeræ—¶åºç‰¹å¾èšåˆæ¨¡å—**ï¼šæ•è·åºåˆ—ä¾èµ–æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šACITçš„å…³é”®åˆ›æ–°åœ¨äºå…¶æ³¨æ„åŠ›å¼•å¯¼çš„è·¨æ¨¡æ€äº¤äº’æœºåˆ¶ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒACITèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°æå–å’Œèåˆä¸åŒæ¨¡æ€çš„äº’è¡¥ä¿¡æ¯ï¼Œä»è€Œæé«˜é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼ŒACITè¿˜å¼•å…¥äº†Transformeræ¨¡å‹æ¥æ•è·è¡Œäººè¡Œä¸ºçš„æ—¶åºä¾èµ–æ€§ï¼Œè¿›ä¸€æ­¥æå‡äº†é¢„æµ‹æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è§†è§‰äº¤äº’å¯¹ä¸­ï¼ŒåŒè·¯å¾„æ³¨æ„åŠ›æœºåˆ¶åŒ…å«å†…æ¨¡æ€è‡ªæ³¨æ„åŠ›å’Œå…‰æµå¼•å¯¼çš„æ³¨æ„åŠ›ã€‚å†…æ¨¡æ€è‡ªæ³¨æ„åŠ›ç”¨äºå¢å¼ºä¸»è¦æ¨¡æ€çš„æ˜¾è‘—åŒºåŸŸï¼Œå…‰æµå¼•å¯¼çš„æ³¨æ„åŠ›åˆ™ç”¨äºä¿ƒè¿›ä¸å…‰æµæ¨¡æ€çš„äº¤äº’ã€‚åœ¨è¿åŠ¨äº¤äº’å¯¹ä¸­ï¼Œè·¨æ¨¡æ€æ³¨æ„åŠ›é‡‡ç”¨æ ‡å‡†çš„Transformeræ³¨æ„åŠ›æœºåˆ¶ã€‚Transformeræ—¶åºç‰¹å¾èšåˆæ¨¡å—é‡‡ç”¨å¤šå±‚Transformerç¼–ç å™¨ç»“æ„ï¼Œç”¨äºæ•è·æ—¶åºä¾èµ–æ€§ã€‚æŸå¤±å‡½æ•°æœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ACITæ¨¡å‹åœ¨JAADbehæ•°æ®é›†ä¸Šè¾¾åˆ°äº†70%çš„å‡†ç¡®ç‡ï¼Œåœ¨JAADallæ•°æ®é›†ä¸Šè¾¾åˆ°äº†89%çš„å‡†ç¡®ç‡ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚æ¶ˆèå®éªŒè¡¨æ˜ï¼Œå„ä¸ªæ¨¡å—éƒ½å¯¹æœ€ç»ˆæ€§èƒ½æœ‰è´¡çŒ®ï¼ŒéªŒè¯äº†ACITæ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ç³»ç»Ÿï¼Œæé«˜è½¦è¾†å¯¹è¡Œäººè¿‡è¡—æ„å›¾çš„é¢„æµ‹èƒ½åŠ›ï¼Œä»è€Œå‡å°‘äº¤é€šäº‹æ•…ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•ä¹Ÿå¯åº”ç”¨äºæ™ºèƒ½ç›‘æ§ã€æœºå™¨äººå¯¼èˆªç­‰é¢†åŸŸï¼Œæå‡ç³»ç»Ÿå¯¹è¡Œäººè¡Œä¸ºçš„ç†è§£å’Œé¢„æµ‹èƒ½åŠ›ï¼Œå…·æœ‰é‡è¦çš„å®é™…åº”ç”¨ä»·å€¼å’Œå¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Predicting pedestrian crossing intention is crucial for autonomous vehicles to prevent pedestrian-related collisions. However, effectively extracting and integrating complementary cues from different types of data remains one of the major challenges. This paper proposes an attention-guided cross-modal interaction Transformer (ACIT) for pedestrian crossing intention prediction. ACIT leverages six visual and motion modalities, which are grouped into three interaction pairs: (1) Global semantic map and global optical flow, (2) Local RGB image and local optical flow, and (3) Ego-vehicle speed and pedestrian's bounding box. Within each visual interaction pair, a dual-path attention mechanism enhances salient regions within the primary modality through intra-modal self-attention and facilitates deep interactions with the auxiliary modality (i.e., optical flow) via optical flow-guided attention. Within the motion interaction pair, cross-modal attention is employed to model the cross-modal dynamics, enabling the effective extraction of complementary motion features. Beyond pairwise interactions, a multi-modal feature fusion module further facilitates cross-modal interactions at each time step. Furthermore, a Transformer-based temporal feature aggregation module is introduced to capture sequential dependencies. Experimental results demonstrate that ACIT outperforms state-of-the-art methods, achieving accuracy rates of 70% and 89% on the JAADbeh and JAADall datasets, respectively. Extensive ablation studies are further conducted to investigate the contribution of different modules of ACIT.

