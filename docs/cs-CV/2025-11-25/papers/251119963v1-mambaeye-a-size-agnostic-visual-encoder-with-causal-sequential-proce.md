---
layout: default
title: MambaEye: A Size-Agnostic Visual Encoder with Causal Sequential Processing
---

# MambaEye: A Size-Agnostic Visual Encoder with Causal Sequential Processing

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.19963" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.19963v1</a>
  <a href="https://arxiv.org/pdf/2511.19963.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.19963v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.19963v1', 'MambaEye: A Size-Agnostic Visual Encoder with Causal Sequential Processing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Changho Choi, Minho Kim, Jinkyu Kim

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-25

**å¤‡æ³¨**: Code will be released in github

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**MambaEyeï¼šåŸºäºå› æœåºåˆ—å¤„ç†çš„å°ºå¯¸æ— å…³è§†è§‰ç¼–ç å™¨**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è§†è§‰ç¼–ç å™¨` `Mamba` `çŠ¶æ€ç©ºé—´æ¨¡å‹` `å› æœåºåˆ—å¤„ç†` `å°ºå¯¸æ— å…³` `ç›¸å¯¹ç§»åŠ¨åµŒå…¥` `é«˜åˆ†è¾¨ç‡å›¾åƒ` `å›¾åƒåˆ†ç±»`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰ç¼–ç å™¨éš¾ä»¥å®ç°è¾“å…¥å°ºå¯¸æ— å…³æ€§ï¼Œé™åˆ¶äº†å…¶åœ¨ä¸åŒåˆ†è¾¨ç‡å›¾åƒä¸Šçš„åº”ç”¨ã€‚
2. MambaEyeåˆ©ç”¨å•å‘Mamba2éª¨å¹²ç½‘ç»œå’Œç›¸å¯¹ç§»åŠ¨åµŒå…¥ï¼Œå®ç°å› æœåºåˆ—å¤„ç†å’Œå¯¹ä»»æ„åˆ†è¾¨ç‡çš„é€‚åº”æ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒMambaEyeåœ¨ImageNet-1Kåˆ†ç±»ä»»åŠ¡ä¸­ï¼Œé«˜åˆ†è¾¨ç‡å›¾åƒä¸Šè¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ï¼Œä¸”ä¿æŒçº¿æ€§å¤æ‚åº¦ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„å› æœåºåˆ—ç¼–ç å™¨MambaEyeï¼Œæ—¨åœ¨è§£å†³è§†è§‰ç¼–ç å™¨å¯¹è¾“å…¥å°ºå¯¸çš„ä¾èµ–é—®é¢˜ï¼Œè¿™æ˜¯äººç±»è§†è§‰çš„ä¸€ä¸ªåŸºæœ¬ç‰¹å¾ä½†é•¿æœŸæœªè¢«è§£å†³ã€‚MambaEyeåˆ©ç”¨ä½å¤æ‚åº¦å’ŒåŸºäºå› æœè¿‡ç¨‹çš„çº¯Mamba2éª¨å¹²ç½‘ç»œã€‚ä¸ä»¥å¾€åŸºäºMambaçš„åŒå‘è§†è§‰ç¼–ç å™¨ä¸åŒï¼ŒMambaEyeé‡‡ç”¨ä¸¥æ ¼çš„å•å‘æ–¹æ³•ï¼Œä¿ç•™äº†çŠ¶æ€ç©ºé—´æ¨¡å‹çš„å›ºæœ‰å› æœæ€§ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨è¾“å…¥åºåˆ—çš„ä»»ä½•ç‚¹ç”Ÿæˆé¢„æµ‹ã€‚æ ¸å¿ƒåˆ›æ–°æ˜¯ç›¸å¯¹ç§»åŠ¨åµŒå…¥ï¼Œå®ƒç¼–ç äº†è¿ç»­å›¾åƒå—ä¹‹é—´çš„ç©ºé—´ä½ç§»ï¼Œä¸ºå¹³ç§»ä¸å˜æ€§æä¾›äº†å¼ºå¤§çš„å½’çº³åç½®ï¼Œå¹¶ä½¿æ¨¡å‹èƒ½å¤Ÿé€‚åº”ä»»æ„å›¾åƒåˆ†è¾¨ç‡å’Œæ‰«ææ¨¡å¼ã€‚æ­¤å¤–ï¼Œå¼•å…¥äº†ä¸€ç§å—æ‰©æ•£å¯å‘çš„æŸå¤±å‡½æ•°ï¼Œæä¾›å¯†é›†çš„ã€é€æ­¥çš„ç›‘ç£ï¼Œè®­ç»ƒæ¨¡å‹åœ¨æ”¶é›†æ›´å¤šè§†è§‰è¯æ®æ—¶å»ºç«‹ç½®ä¿¡åº¦ã€‚å®éªŒè¡¨æ˜ï¼ŒMambaEyeåœ¨å„ç§å›¾åƒåˆ†è¾¨ç‡ä¸‹è¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨ImageNet-1Kåˆ†ç±»ä»»åŠ¡ä¸­ï¼Œåˆ†è¾¨ç‡é«˜è¾¾$1536^2$æ—¶ã€‚åŒæ—¶ï¼Œç›¸å¯¹äºå›¾åƒå—çš„æ•°é‡ï¼Œä¿æŒäº†çº¿æ€§çš„æ—¶é—´å’Œå†…å­˜å¤æ‚åº¦ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰è§†è§‰ç¼–ç å™¨é€šå¸¸å¯¹è¾“å…¥å›¾åƒçš„å°ºå¯¸æœ‰ä¸¥æ ¼è¦æ±‚ï¼Œæ— æ³•åƒäººç±»è§†è§‰ä¸€æ ·çµæ´»å¤„ç†ä»»æ„åˆ†è¾¨ç‡çš„å›¾åƒã€‚è¿™é™åˆ¶äº†å®ƒä»¬åœ¨å®é™…åº”ç”¨ä¸­çš„æ³›åŒ–èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨é«˜åˆ†è¾¨ç‡å›¾åƒå¤„ç†æ–¹é¢ï¼Œè®¡ç®—å¤æ‚åº¦ä¼šæ˜¾è‘—å¢åŠ ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMambaEyeçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å•å‘çš„Mamba2æ¶æ„ï¼Œç»“åˆç›¸å¯¹ç§»åŠ¨åµŒå…¥ï¼Œå®ç°å¯¹å›¾åƒå—åºåˆ—çš„å› æœå»ºæ¨¡ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹å¯ä»¥é€æ­¥ç§¯ç´¯è§†è§‰ä¿¡æ¯ï¼Œå¹¶åœ¨ä»»æ„æ—¶åˆ»ç”Ÿæˆé¢„æµ‹ï¼Œä»è€Œæ‘†è„±å¯¹å›ºå®šè¾“å…¥å°ºå¯¸çš„ä¾èµ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMambaEyeçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ­¥éª¤ï¼š1) å°†è¾“å…¥å›¾åƒåˆ†å‰²æˆå›¾åƒå—åºåˆ—ï¼›2) ä½¿ç”¨ç›¸å¯¹ç§»åŠ¨åµŒå…¥ç¼–ç å›¾åƒå—ä¹‹é—´çš„ç©ºé—´å…³ç³»ï¼›3) å°†ç¼–ç åçš„åºåˆ—è¾“å…¥åˆ°å•å‘Mamba2éª¨å¹²ç½‘ç»œä¸­è¿›è¡Œç‰¹å¾æå–ï¼›4) ä½¿ç”¨åˆ†ç±»å¤´åŸºäºæå–çš„ç‰¹å¾è¿›è¡Œé¢„æµ‹ã€‚å…³é”®åœ¨äºMamba2çš„å•å‘æ€§å’Œç›¸å¯¹ç§»åŠ¨åµŒå…¥çš„ç©ºé—´ä¿¡æ¯ç¼–ç ã€‚

**å…³é”®åˆ›æ–°**ï¼šMambaEyeçš„å…³é”®åˆ›æ–°åœ¨äºä»¥ä¸‹ä¸¤ç‚¹ï¼šä¸€æ˜¯é‡‡ç”¨äº†å•å‘çš„Mamba2æ¶æ„ï¼Œä¿ç•™äº†çŠ¶æ€ç©ºé—´æ¨¡å‹çš„å› æœæ€§ï¼Œä½¿å…¶èƒ½å¤Ÿè¿›è¡Œåºåˆ—åŒ–çš„è§†è§‰ä¿¡æ¯å¤„ç†ï¼›äºŒæ˜¯å¼•å…¥äº†ç›¸å¯¹ç§»åŠ¨åµŒå…¥ï¼Œæœ‰æ•ˆåœ°ç¼–ç äº†å›¾åƒå—ä¹‹é—´çš„ç©ºé—´å…³ç³»ï¼Œä¸ºå¹³ç§»ä¸å˜æ€§æä¾›äº†å¼ºå¤§çš„å½’çº³åç½®ï¼Œå¹¶ä½¿æ¨¡å‹èƒ½å¤Ÿé€‚åº”ä»»æ„å›¾åƒåˆ†è¾¨ç‡å’Œæ‰«ææ¨¡å¼ã€‚

**å…³é”®è®¾è®¡**ï¼šMambaEyeçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨ç›¸å¯¹ç§»åŠ¨åµŒå…¥æ¥ç¼–ç å›¾åƒå—ä¹‹é—´çš„ç©ºé—´ä½ç§»ï¼Œå…·ä½“å®ç°æ–¹å¼æœªçŸ¥ï¼›2) é‡‡ç”¨å—æ‰©æ•£å¯å‘çš„æŸå¤±å‡½æ•°ï¼Œæä¾›å¯†é›†çš„ã€é€æ­¥çš„ç›‘ç£ï¼Œè®­ç»ƒæ¨¡å‹åœ¨æ”¶é›†æ›´å¤šè§†è§‰è¯æ®æ—¶å»ºç«‹ç½®ä¿¡åº¦ï¼ŒæŸå¤±å‡½æ•°çš„å…·ä½“å½¢å¼æœªçŸ¥ï¼›3) Mamba2éª¨å¹²ç½‘ç»œçš„å…·ä½“å‚æ•°è®¾ç½®æœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

MambaEyeåœ¨ImageNet-1Kåˆ†ç±»ä»»åŠ¡ä¸­ï¼Œå°¤å…¶æ˜¯åœ¨é«˜åˆ†è¾¨ç‡ï¼ˆå¦‚$1536^2$ï¼‰å›¾åƒä¸Šè¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ã€‚ç›¸è¾ƒäºä¼ ç»Ÿçš„è§†è§‰ç¼–ç å™¨ï¼ŒMambaEyeåœ¨é«˜åˆ†è¾¨ç‡å›¾åƒå¤„ç†æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼ŒåŒæ—¶ä¿æŒäº†çº¿æ€§çš„æ—¶é—´å’Œå†…å­˜å¤æ‚åº¦ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿æœªåœ¨æ‘˜è¦ä¸­æ˜ç¡®ç»™å‡ºï¼Œéœ€è¦æŸ¥é˜…è®ºæ–‡å…¨æ–‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MambaEyeå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚åœ¨é«˜åˆ†è¾¨ç‡å›¾åƒè¯†åˆ«ã€åŒ»å­¦å›¾åƒåˆ†æã€é¥æ„Ÿå›¾åƒå¤„ç†ç­‰é¢†åŸŸã€‚å…¶å°ºå¯¸æ— å…³çš„ç‰¹æ€§ä½¿å…¶èƒ½å¤Ÿçµæ´»åº”ç”¨äºå„ç§åœºæ™¯ï¼Œé™ä½äº†å¯¹è¾“å…¥å›¾åƒå°ºå¯¸çš„é™åˆ¶ï¼Œæå‡äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚æœªæ¥ï¼ŒMambaEyeæœ‰æœ›æˆä¸ºä¸€ç§é€šç”¨çš„è§†è§‰ç¼–ç å™¨ï¼Œä¸ºå„ç§è§†è§‰ä»»åŠ¡æä¾›å¼ºå¤§çš„æ”¯æŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Despite decades of progress, a truly input-size agnostic visual encoder-a fundamental characteristic of human vision-has remained elusive. We address this limitation by proposing \textbf{MambaEye}, a novel, causal sequential encoder that leverages the low complexity and causal-process based pure Mamba2 backbone. Unlike previous Mamba-based vision encoders that often employ bidirectional processing, our strictly unidirectional approach preserves the inherent causality of State Space Models, enabling the model to generate a prediction at any point in its input sequence. A core innovation is our use of relative move embedding, which encodes the spatial shift between consecutive patches, providing a strong inductive bias for translation invariance and making the model inherently adaptable to arbitrary image resolutions and scanning patterns. To achieve this, we introduce a novel diffusion-inspired loss function that provides dense, step-wise supervision, training the model to build confidence as it gathers more visual evidence. We demonstrate that MambaEye exhibits robust performance across a wide range of image resolutions, especially at higher resolutions such as $1536^2$ on the ImageNet-1K classification task. This feat is achieved while maintaining linear time and memory complexity relative to the number of patches.

