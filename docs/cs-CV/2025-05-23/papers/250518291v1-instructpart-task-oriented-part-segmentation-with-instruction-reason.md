---
layout: default
title: InstructPart: Task-Oriented Part Segmentation with Instruction Reasoning
---

# InstructPart: Task-Oriented Part Segmentation with Instruction Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.18291" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.18291v1</a>
  <a href="https://arxiv.org/pdf/2505.18291.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.18291v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.18291v1', 'InstructPart: Task-Oriented Part Segmentation with Instruction Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zifu Wan, Yaqi Xie, Ce Zhang, Zhiqiu Lin, Zihan Wang, Simon Stepputtis, Deva Ramanan, Katia Sycara

**åˆ†ç±»**: cs.CV, cs.CL, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-05-23

**å¤‡æ³¨**: Accepted by ACL 2025 Main. Project page: https://zifuwan.github.io/InstructPart/

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://zifuwan.github.io/InstructPart/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºInstructPartä»¥è§£å†³ä»»åŠ¡å¯¼å‘çš„éƒ¨ä»¶åˆ†å‰²é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `éƒ¨ä»¶åˆ†å‰²` `å¤šæ¨¡æ€æ¨¡å‹` `ä»»åŠ¡å¯¼å‘` `è§†è§‰-è¯­è¨€æ¨¡å‹` `æœºå™¨äººæŠ€æœ¯` `è™šæ‹Ÿç°å®` `ä¿¡æ¯æ£€ç´¢`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€æ¨¡å‹åœ¨å¤„ç†ç‰©ä½“æ—¶å¸¸å¸¸å¿½è§†å…¶å†…éƒ¨ç»“æ„ï¼Œå¯¼è‡´æ— æ³•æœ‰æ•ˆæ‰§è¡Œéƒ¨ä»¶çº§ä»»åŠ¡ã€‚
2. æœ¬æ–‡æå‡ºäº†InstructPartåŸºå‡†ï¼Œç»“åˆæ‰‹å·¥æ ‡æ³¨çš„éƒ¨ä»¶åˆ†å‰²å’Œä»»åŠ¡å¯¼å‘æŒ‡ä»¤ï¼Œä»¥æå‡æ¨¡å‹å¯¹éƒ¨ä»¶çš„ç†è§£èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŸºäºè¯¥æ•°æ®é›†çš„å¾®è°ƒæ–¹æ³•å®ç°äº†ä¸¤å€çš„æ€§èƒ½æå‡ï¼Œå±•ç¤ºäº†ä»»åŠ¡å¯¼å‘éƒ¨ä»¶åˆ†å‰²çš„æ½œåŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹åœ¨è¯­è¨€å’Œè§†è§‰é¢†åŸŸçš„è¿›å±•æ˜¾è‘—ï¼Œä½†è®¸å¤šæ¨¡å‹å°†ç‰©ä½“è§†ä¸ºä¸å¯åˆ†å‰²çš„æ•´ä½“ï¼Œå¿½è§†äº†æ„æˆå®ƒä»¬çš„å„ä¸ªç»„ä»¶ã€‚ç†è§£è¿™äº›ç»„ä»¶åŠå…¶åŠŸèƒ½å¯¹äºæ‰§è¡Œå¤šç§ä»»åŠ¡è‡³å…³é‡è¦ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„åŸºå‡†æ•°æ®é›†InstructPartï¼ŒåŒ…å«æ‰‹å·¥æ ‡æ³¨çš„éƒ¨ä»¶åˆ†å‰²æ³¨é‡Šå’Œä»»åŠ¡å¯¼å‘çš„æŒ‡ä»¤ï¼Œä»¥è¯„ä¼°å½“å‰æ¨¡å‹åœ¨æ—¥å¸¸åœºæ™¯ä¸­ç†è§£å’Œæ‰§è¡Œéƒ¨ä»¶çº§ä»»åŠ¡çš„èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ï¼Œä»»åŠ¡å¯¼å‘çš„éƒ¨ä»¶åˆ†å‰²ä»ç„¶æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ï¼Œå³ä½¿å¯¹äºæœ€å…ˆè¿›çš„è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ä¸ªç®€å•çš„åŸºçº¿ï¼Œé€šè¿‡ä½¿ç”¨æˆ‘ä»¬çš„æ•°æ®é›†è¿›è¡Œå¾®è°ƒï¼Œå®ç°äº†ä¸¤å€çš„æ€§èƒ½æå‡ã€‚é€šè¿‡è¯¥æ•°æ®é›†å’ŒåŸºå‡†ï¼Œæˆ‘ä»¬æ—¨åœ¨ä¿ƒè¿›ä»»åŠ¡å¯¼å‘çš„éƒ¨ä»¶åˆ†å‰²ç ”ç©¶ï¼Œå¹¶å¢å¼ºVLMsåœ¨æœºå™¨äººã€è™šæ‹Ÿç°å®ã€ä¿¡æ¯æ£€ç´¢ç­‰é¢†åŸŸçš„é€‚ç”¨æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä»»åŠ¡å¯¼å‘çš„éƒ¨ä»¶åˆ†å‰²é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†ç‰©ä½“å†…éƒ¨ç»“æ„æ—¶å­˜åœ¨ä¸è¶³ï¼Œæ— æ³•æœ‰æ•ˆè¯†åˆ«å’Œåˆ©ç”¨éƒ¨ä»¶ä¿¡æ¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥InstructPartæ•°æ®é›†ï¼Œç»“åˆæ‰‹å·¥æ ‡æ³¨çš„éƒ¨ä»¶åˆ†å‰²å’Œä»»åŠ¡å¯¼å‘çš„æŒ‡ä»¤ï¼Œæå‡æ¨¡å‹å¯¹éƒ¨ä»¶çš„ç†è§£å’Œæ‰§è¡Œèƒ½åŠ›ã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨å®é™…åº”ç”¨ä¸­æ›´å¥½åœ°å¤„ç†å¤æ‚çš„ä»»åŠ¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚æ•°æ®é›†æä¾›äº†ä¸°å¯Œçš„éƒ¨ä»¶åˆ†å‰²æ³¨é‡Šå’Œä»»åŠ¡æŒ‡ä»¤ï¼Œæ¨¡å‹é€šè¿‡å¾®è°ƒåœ¨ç‰¹å®šä»»åŠ¡ä¸Šè¿›è¡Œä¼˜åŒ–ï¼Œæœ€åé€šè¿‡æ ‡å‡†åŒ–è¯„ä¼°æŒ‡æ ‡è¿›è¡Œæ€§èƒ½æµ‹è¯•ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†InstructPartåŸºå‡†ï¼Œå¡«è¡¥äº†ç°æœ‰æ¨¡å‹åœ¨éƒ¨ä»¶çº§ä»»åŠ¡ç†è§£ä¸Šçš„ç©ºç™½ï¼Œæ¨åŠ¨äº†å¤šæ¨¡æ€æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„å‘å±•ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–éƒ¨ä»¶åˆ†å‰²çš„å‡†ç¡®æ€§ï¼Œå¹¶é€šè¿‡å¾®è°ƒç­–ç•¥æå‡äº†æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºInstructPartæ•°æ®é›†çš„å¾®è°ƒæ–¹æ³•å®ç°äº†ä¸¤å€çš„æ€§èƒ½æå‡ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰çš„è§†è§‰-è¯­è¨€æ¨¡å‹ï¼Œå±•ç¤ºäº†ä»»åŠ¡å¯¼å‘éƒ¨ä»¶åˆ†å‰²çš„æœ‰æ•ˆæ€§å’Œæ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæŠ€æœ¯ã€è™šæ‹Ÿç°å®ã€ä¿¡æ¯æ£€ç´¢ç­‰ï¼Œèƒ½å¤Ÿå¸®åŠ©æ¨¡å‹æ›´å¥½åœ°ç†è§£ç‰©ä½“çš„ç»„æˆéƒ¨åˆ†åŠå…¶åŠŸèƒ½ï¼Œä»è€Œåœ¨å¤æ‚ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½æ¨åŠ¨å¤šæ¨¡æ€æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„å¹¿æ³›é‡‡ç”¨ï¼Œæå‡æ™ºèƒ½ç³»ç»Ÿçš„äº¤äº’èƒ½åŠ›å’Œä»»åŠ¡æ‰§è¡Œæ•ˆç‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large multimodal foundation models, particularly in the domains of language and vision, have significantly advanced various tasks, including robotics, autonomous driving, information retrieval, and grounding. However, many of these models perceive objects as indivisible, overlooking the components that constitute them. Understanding these components and their associated affordances provides valuable insights into an object's functionality, which is fundamental for performing a wide range of tasks. In this work, we introduce a novel real-world benchmark, InstructPart, comprising hand-labeled part segmentation annotations and task-oriented instructions to evaluate the performance of current models in understanding and executing part-level tasks within everyday contexts. Through our experiments, we demonstrate that task-oriented part segmentation remains a challenging problem, even for state-of-the-art Vision-Language Models (VLMs). In addition to our benchmark, we introduce a simple baseline that achieves a twofold performance improvement through fine-tuning with our dataset. With our dataset and benchmark, we aim to facilitate research on task-oriented part segmentation and enhance the applicability of VLMs across various domains, including robotics, virtual reality, information retrieval, and other related fields. Project website: https://zifuwan.github.io/InstructPart/.

