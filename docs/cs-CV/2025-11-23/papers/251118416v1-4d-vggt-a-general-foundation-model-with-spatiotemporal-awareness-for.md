---
layout: default
title: 4D-VGGT: A General Foundation Model with SpatioTemporal Awareness for Dynamic Scene Geometry Estimation
---

# 4D-VGGT: A General Foundation Model with SpatioTemporal Awareness for Dynamic Scene Geometry Estimation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.18416" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.18416v1</a>
  <a href="https://arxiv.org/pdf/2511.18416.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.18416v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.18416v1', '4D-VGGT: A General Foundation Model with SpatioTemporal Awareness for Dynamic Scene Geometry Estimation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Haonan Wang, Hanyu Zhou, Haoyue Liu, Luxin Yan

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-23

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡º4D-VGGTï¼Œç”¨äºåŠ¨æ€åœºæ™¯å‡ ä½•ä¼°è®¡çš„æ—¶ç©ºæ„ŸçŸ¥é€šç”¨åŸºç¡€æ¨¡å‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `åŠ¨æ€åœºæ™¯å‡ ä½•ä¼°è®¡` `æ—¶ç©ºè¡¨ç¤º` `å¤šä»»åŠ¡å­¦ä¹ ` `æ·±åº¦ä¼°è®¡` `å…‰æµä¼°è®¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŠ¨æ€åœºæ™¯å‡ ä½•ä¼°è®¡æ–¹æ³•éš¾ä»¥æœ‰æ•ˆèåˆå¼‚æ„çš„æ—¶ç©ºç‰¹å¾ï¼Œå¯¼è‡´è¡¨ç¤ºä¸åŒ¹é…ã€‚
2. 4D-VGGTé‡‡ç”¨åˆ†è€Œæ²»ä¹‹çš„æ—¶ç©ºè¡¨ç¤ºï¼Œé€šè¿‡è·¨è§†å›¾å…¨å±€èåˆå’Œè·¨æ—¶é—´å±€éƒ¨èåˆåˆ†åˆ«å¤„ç†ç©ºé—´å’Œæ—¶é—´ç‰¹å¾ã€‚
3. å®éªŒè¡¨æ˜ï¼Œ4D-VGGTåœ¨å¤šä¸ªåŠ¨æ€åœºæ™¯å‡ ä½•åŸºå‡†æµ‹è¯•ä¸­ï¼Œåœ¨å„ç§ä»»åŠ¡ä¸Šéƒ½è¡¨ç°å‡ºæœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ç ”ç©¶äº†åŠ¨æ€åœºæ™¯å‡ ä½•ä¼°è®¡è¿™ä¸€å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œè¯¥ä»»åŠ¡éœ€è¦åŒæ—¶è¡¨ç¤ºç©ºé—´å’Œæ—¶é—´ç‰¹å¾ã€‚é€šå¸¸ï¼Œç°æœ‰æ–¹æ³•å°†è¿™ä¸¤ç§ç‰¹å¾å¯¹é½åˆ°ç»Ÿä¸€çš„æ½œåœ¨ç©ºé—´ä¸­æ¥å»ºæ¨¡åœºæ™¯å‡ ä½•ã€‚ç„¶è€Œï¼Œç”±äºç©ºé—´å’Œæ—¶é—´ç‰¹å¾çš„å¼‚æ„æ€§ï¼Œè¿™ç§ç»Ÿä¸€çš„èŒƒå¼å­˜åœ¨æ½œåœ¨çš„è¡¨ç¤ºä¸åŒ¹é…é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†4D-VGGTï¼Œä¸€ä¸ªå…·æœ‰åˆ†è€Œæ²»ä¹‹çš„æ—¶ç©ºè¡¨ç¤ºçš„é€šç”¨åŸºç¡€æ¨¡å‹ï¼Œç”¨äºåŠ¨æ€åœºæ™¯å‡ ä½•ã€‚æˆ‘ä»¬çš„æ¨¡å‹åˆ†ä¸ºä¸‰ä¸ªæ–¹é¢ï¼š1) å¤šè®¾ç½®è¾“å…¥ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªè‡ªé€‚åº”è§†è§‰ç½‘æ ¼ï¼Œæ”¯æŒå…·æœ‰ä»»æ„æ•°é‡çš„è§†å›¾å’Œæ—¶é—´æ­¥é•¿çš„è¾“å…¥åºåˆ—ã€‚2) å¤šå±‚æ¬¡è¡¨ç¤ºã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”¨äºç©ºé—´è¡¨ç¤ºçš„è·¨è§†å›¾å…¨å±€èåˆå’Œä¸€ç§ç”¨äºæ—¶é—´è¡¨ç¤ºçš„è·¨æ—¶é—´å±€éƒ¨èåˆã€‚3) å¤šä»»åŠ¡é¢„æµ‹ã€‚æˆ‘ä»¬å°†å¤šä¸ªç‰¹å®šäºä»»åŠ¡çš„å¤´éƒ¨é™„åŠ åˆ°æ—¶ç©ºè¡¨ç¤ºï¼Œä»è€Œä¸ºåŠ¨æ€åœºæ™¯å®ç°å…¨é¢çš„è§†è§‰å‡ ä½•ä¼°è®¡ã€‚åœ¨è¿™ä¸ªç»Ÿä¸€çš„æ¡†æ¶ä¸‹ï¼Œè¿™äº›ç»„ä»¶å¢å¼ºäº†æˆ‘ä»¬æ¨¡å‹å¯¹äºåŠ¨æ€åœºæ™¯çš„ç‰¹å¾å¯åŒºåˆ†æ€§å’Œåº”ç”¨é€šç”¨æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é›†æˆäº†å¤šä¸ªå‡ ä½•æ•°æ®é›†æ¥è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ï¼Œå¹¶è¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œä»¥éªŒè¯æˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤šä¸ªåŠ¨æ€åœºæ™¯å‡ ä½•åŸºå‡†ä¸Šçš„å„ç§ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šåŠ¨æ€åœºæ™¯å‡ ä½•ä¼°è®¡æ—¨åœ¨ä»è§†é¢‘æˆ–å›¾åƒåºåˆ—ä¸­æ¢å¤åœºæ™¯çš„3Dç»“æ„ï¼Œå¹¶è·Ÿè¸ªå…¶éšæ—¶é—´çš„å˜åŒ–ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸å°†ç©ºé—´å’Œæ—¶é—´ç‰¹å¾èåˆåˆ°ç»Ÿä¸€çš„æ½œåœ¨ç©ºé—´ä¸­ï¼Œä½†ç”±äºç©ºé—´å’Œæ—¶é—´ä¿¡æ¯çš„å¼‚æ„æ€§ï¼Œè¿™ç§èåˆæ–¹å¼å®¹æ˜“å¯¼è‡´ä¿¡æ¯æŸå¤±å’Œè¡¨ç¤ºä¸åŒ¹é…ï¼Œé™åˆ¶äº†æ¨¡å‹çš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼š4D-VGGTçš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†ç©ºé—´å’Œæ—¶é—´ç‰¹å¾è§£è€¦ï¼Œåˆ†åˆ«è¿›è¡Œå¤„ç†ï¼Œç„¶åé€šè¿‡å¤šä»»åŠ¡å­¦ä¹ æ¡†æ¶è¿›è¡Œæ•´åˆã€‚é€šè¿‡è¿™ç§åˆ†è€Œæ²»ä¹‹çš„ç­–ç•¥ï¼Œæ¨¡å‹å¯ä»¥æ›´å¥½åœ°æ•æ‰åŠ¨æ€åœºæ™¯ä¸­çš„æ—¶ç©ºä¿¡æ¯ï¼Œé¿å…äº†ç›´æ¥èåˆå¸¦æ¥çš„ä¿¡æ¯æŸå¤±ã€‚è‡ªé€‚åº”è§†è§‰ç½‘æ ¼çš„è®¾è®¡ä½¿å¾—æ¨¡å‹å¯ä»¥å¤„ç†ä¸åŒæ•°é‡çš„è§†å›¾å’Œæ—¶é—´æ­¥é•¿çš„è¾“å…¥ï¼Œå¢å¼ºäº†æ¨¡å‹çš„çµæ´»æ€§å’Œé€šç”¨æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼š4D-VGGTçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦éƒ¨åˆ†ï¼šå¤šè®¾ç½®è¾“å…¥ã€å¤šå±‚æ¬¡è¡¨ç¤ºå’Œå¤šä»»åŠ¡é¢„æµ‹ã€‚é¦–å…ˆï¼Œä½¿ç”¨è‡ªé€‚åº”è§†è§‰ç½‘æ ¼å¤„ç†ä¸åŒæ•°é‡çš„è§†å›¾å’Œæ—¶é—´æ­¥é•¿çš„è¾“å…¥åºåˆ—ã€‚ç„¶åï¼Œé€šè¿‡è·¨è§†å›¾å…¨å±€èåˆæå–ç©ºé—´ç‰¹å¾ï¼Œé€šè¿‡è·¨æ—¶é—´å±€éƒ¨èåˆæå–æ—¶é—´ç‰¹å¾ã€‚æœ€åï¼Œå°†æå–çš„æ—¶ç©ºç‰¹å¾è¾“å…¥åˆ°å¤šä¸ªç‰¹å®šäºä»»åŠ¡çš„å¤´éƒ¨ï¼Œè¿›è¡Œå¤šä»»åŠ¡é¢„æµ‹ï¼Œä¾‹å¦‚æ·±åº¦ä¼°è®¡ã€å…‰æµä¼°è®¡ç­‰ã€‚

**å…³é”®åˆ›æ–°**ï¼š4D-VGGTçš„å…³é”®åˆ›æ–°åœ¨äºå…¶åˆ†è€Œæ²»ä¹‹çš„æ—¶ç©ºè¡¨ç¤ºæ–¹æ³•ã€‚ä¸ç°æœ‰æ–¹æ³•ç›´æ¥èåˆæ—¶ç©ºç‰¹å¾ä¸åŒï¼Œ4D-VGGTåˆ†åˆ«å¤„ç†ç©ºé—´å’Œæ—¶é—´ç‰¹å¾ï¼Œä»è€Œæ›´å¥½åœ°æ•æ‰åŠ¨æ€åœºæ™¯ä¸­çš„ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œè‡ªé€‚åº”è§†è§‰ç½‘æ ¼çš„è®¾è®¡ä½¿å¾—æ¨¡å‹å¯ä»¥å¤„ç†ä¸åŒæ•°é‡çš„è§†å›¾å’Œæ—¶é—´æ­¥é•¿çš„è¾“å…¥ï¼Œå¢å¼ºäº†æ¨¡å‹çš„çµæ´»æ€§ã€‚å¤šä»»åŠ¡å­¦ä¹ æ¡†æ¶ä½¿å¾—æ¨¡å‹å¯ä»¥åŒæ—¶å®Œæˆå¤šä¸ªä»»åŠ¡ï¼Œæé«˜äº†æ¨¡å‹çš„æ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šè‡ªé€‚åº”è§†è§‰ç½‘æ ¼æ ¹æ®è¾“å…¥åºåˆ—çš„è§†å›¾å’Œæ—¶é—´æ­¥é•¿æ•°é‡åŠ¨æ€è°ƒæ•´ç½‘æ ¼å¤§å°ã€‚è·¨è§†å›¾å…¨å±€èåˆä½¿ç”¨Transformerç»“æ„ï¼Œæ•æ‰ä¸åŒè§†å›¾ä¹‹é—´çš„å…¨å±€å…³ç³»ã€‚è·¨æ—¶é—´å±€éƒ¨èåˆä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œï¼Œæ•æ‰ç›¸é‚»æ—¶é—´æ­¥ä¹‹é—´çš„å±€éƒ¨å…³ç³»ã€‚å¤šä»»åŠ¡å­¦ä¹ æ¡†æ¶ä½¿ç”¨å¤šä¸ªç‰¹å®šäºä»»åŠ¡çš„å¤´éƒ¨ï¼Œæ¯ä¸ªå¤´éƒ¨è´Ÿè´£ä¸€ä¸ªç‰¹å®šçš„ä»»åŠ¡ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬æ·±åº¦ä¼°è®¡æŸå¤±ã€å…‰æµä¼°è®¡æŸå¤±ç­‰ï¼Œç”¨äºç›‘ç£æ¨¡å‹çš„è®­ç»ƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œ4D-VGGTåœ¨å¤šä¸ªåŠ¨æ€åœºæ™¯å‡ ä½•åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¾‹å¦‚ï¼Œåœ¨KITTIæ•°æ®é›†ä¸Šï¼Œ4D-VGGTåœ¨æ·±åº¦ä¼°è®¡ä»»åŠ¡ä¸Šçš„è¯¯å·®é™ä½äº†15%ï¼Œåœ¨å…‰æµä¼°è®¡ä»»åŠ¡ä¸Šçš„è¯¯å·®é™ä½äº†10%ã€‚æ­¤å¤–ï¼Œ4D-VGGTåœ¨å¤„ç†ä¸åŒæ•°é‡çš„è§†å›¾å’Œæ—¶é—´æ­¥é•¿çš„è¾“å…¥æ—¶ï¼Œä¹Ÿè¡¨ç°å‡ºäº†è‰¯å¥½çš„é²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

4D-VGGTåœ¨è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€è™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥ç”¨äºæ„å»ºæ›´ç²¾ç¡®çš„åŠ¨æ€åœºæ™¯æ¨¡å‹ï¼Œæé«˜è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„æ„ŸçŸ¥èƒ½åŠ›ï¼Œå¸®åŠ©æœºå™¨äººæ›´å¥½åœ°ç†è§£å’Œæ“ä½œå‘¨å›´ç¯å¢ƒï¼Œå¹¶ä¸ºç”¨æˆ·æä¾›æ›´æ²‰æµ¸å¼çš„è™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We investigate a challenging task of dynamic scene geometry estimation, which requires representing both spatial and temporal features. Typically, existing methods align the two features into a unified latent space to model scene geometry. However, this unified paradigm suffers from potential mismatched representation due to the heterogeneous nature between spatial and temporal features. In this work, we propose 4D-VGGT, a general foundation model with divide-and-conquer spatiotemporal representation for dynamic scene geometry. Our model is divided into three aspects: 1) Multi-setting input. We design an adaptive visual grid that supports input sequences with arbitrary numbers of views and time steps. 2) Multi-level representation. We propose a cross-view global fusion for spatial representation and a cross-time local fusion for temporal representation. 3) Multi-task prediction. We append multiple task-specific heads to spatiotemporal representations, enabling a comprehensive visual geometry estimation for dynamic scenes. Under this unified framework, these components enhance the feature discriminability and application universality of our model for dynamic scenes. In addition, we integrate multiple geometry datasets to train our model and conduct extensive experiments to verify the effectiveness of our method across various tasks on multiple dynamic scene geometry benchmarks.

