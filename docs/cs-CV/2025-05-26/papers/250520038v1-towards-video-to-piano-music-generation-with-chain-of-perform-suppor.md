---
layout: default
title: Towards Video to Piano Music Generation with Chain-of-Perform Support Benchmarks
---

# Towards Video to Piano Music Generation with Chain-of-Perform Support Benchmarks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20038" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.20038v1</a>
  <a href="https://arxiv.org/pdf/2505.20038.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20038v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20038v1', 'Towards Video to Piano Music Generation with Chain-of-Perform Support Benchmarks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chang Liu, Haomin Zhang, Shiyu Xia, Zihao Chen, Chaofan Ding, Xin Yue, Huizhe Chen, Xinhan Di

**åˆ†ç±»**: cs.SD, cs.CV, eess.AS

**å‘å¸ƒæ—¥æœŸ**: 2025-05-26

**å¤‡æ³¨**: 4 pages, 1 figure, accepted by CVPR 2025 MMFM Workshop

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/acappemin/Video-to-Audio-and-Piano)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCoPåŸºå‡†æ•°æ®é›†ä»¥è§£å†³è§†é¢‘åˆ°é’¢ç´éŸ³ä¹ç”Ÿæˆçš„è¯„ä¼°é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†é¢‘éŸ³ä¹ç”Ÿæˆ` `å¤šæ¨¡æ€æ³¨é‡Š` `Chain-of-Perform` `é’¢ç´éŸ³é¢‘ç”Ÿæˆ` `å¼€æºæ•°æ®é›†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è¯„ä¼°æ•°æ®é›†æ— æ³•å……åˆ†åæ˜ è§†é¢‘åˆ°é’¢ç´éŸ³ä¹ç”Ÿæˆæ‰€éœ€çš„å¤æ‚åŒæ­¥ï¼Œå¯¼è‡´è¯„ä¼°æ ‡å‡†ä¸è¶³ã€‚
2. æå‡ºCoPåŸºå‡†æ•°æ®é›†ï¼Œé€šè¿‡è¯¦ç»†çš„å¤šæ¨¡æ€æ³¨é‡Šå’Œé€æ­¥æŒ‡å¯¼ï¼Œæå‡è§†é¢‘ä¸é’¢ç´éŸ³é¢‘çš„è¯­ä¹‰å’Œæ—¶é—´å¯¹é½ã€‚
3. æ•°æ®é›†å…¬å¼€å¯ç”¨ï¼Œå¹¶è®¾æœ‰æŒç»­æ›´æ–°çš„æ’è¡Œæ¦œï¼Œä¿ƒè¿›è¯¥é¢†åŸŸçš„ç ”ç©¶è¿›å±•å’Œåº”ç”¨æ¢ç´¢ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç”Ÿæˆé«˜è´¨é‡çš„é’¢ç´éŸ³é¢‘éœ€è¦è§†è§‰çº¿ç´¢ä¸éŸ³ä¹è¾“å‡ºä¹‹é—´çš„ç²¾ç¡®åŒæ­¥ï¼Œç¡®ä¿è¯­ä¹‰å’Œæ—¶é—´ä¸Šçš„å‡†ç¡®å¯¹é½ã€‚ç„¶è€Œï¼Œç°æœ‰çš„è¯„ä¼°æ•°æ®é›†æœªèƒ½å……åˆ†æ•æ‰é’¢ç´éŸ³ä¹ç”Ÿæˆæ‰€éœ€çš„å¤æ‚åŒæ­¥ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡å¼•å…¥äº†CoPåŸºå‡†æ•°æ®é›†ï¼Œè¿™æ˜¯ä¸€ä¸ªå®Œå…¨å¼€æºçš„å¤šæ¨¡æ€åŸºå‡†ï¼Œä¸“é—¨ä¸ºè§†é¢‘å¼•å¯¼çš„é’¢ç´éŸ³ä¹ç”Ÿæˆè®¾è®¡ã€‚è¯¥åŸºå‡†æä¾›äº†è¯¦ç»†çš„å¤šæ¨¡æ€æ³¨é‡Šï¼Œæ”¯æŒé€æ­¥çš„Chain-of-PerformæŒ‡å¯¼ï¼Œæ„å»ºäº†ä¸€ä¸ªå¤šåŠŸèƒ½çš„è¯„ä¼°æ¡†æ¶ï¼Œå¹¶å…¬å¼€äº†æ•°æ®é›†ã€æ³¨é‡Šå’Œè¯„ä¼°åè®®ï¼Œæ—¨åœ¨æ¨åŠ¨é«˜è´¨é‡é’¢ç´éŸ³ä¹ç”Ÿæˆçš„ç ”ç©¶è¿›å±•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰è§†é¢‘åˆ°é’¢ç´éŸ³ä¹ç”Ÿæˆè¯„ä¼°æ•°æ®é›†ç¼ºä¹å¤æ‚åŒæ­¥æ•æ‰çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•æ— æ³•å‡†ç¡®åæ˜ è§†é¢‘ä¸éŸ³ä¹ä¹‹é—´çš„äº’åŠ¨å…³ç³»ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºCoPåŸºå‡†æ•°æ®é›†ï¼Œé€šè¿‡è¯¦ç»†çš„å¤šæ¨¡æ€æ³¨é‡Šå’ŒChain-of-PerformæŒ‡å¯¼ï¼Œç¡®ä¿è§†é¢‘å†…å®¹ä¸é’¢ç´éŸ³é¢‘ä¹‹é—´çš„ç²¾ç¡®å¯¹é½ï¼Œæå‡ç”Ÿæˆè´¨é‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é‡‡é›†ã€æ³¨é‡Šç”Ÿæˆã€è¯„ä¼°æ¡†æ¶ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚æ•°æ®é‡‡é›†é˜¶æ®µè·å–è§†é¢‘å’ŒéŸ³é¢‘ï¼Œæ³¨é‡Šç”Ÿæˆé˜¶æ®µæä¾›å¤šæ¨¡æ€ä¿¡æ¯ï¼Œè¯„ä¼°æ¡†æ¶ç”¨äºè¯„ä¼°ç”Ÿæˆæ•ˆæœã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†Chain-of-PerformæŒ‡å¯¼ï¼Œå…è®¸é€æ­¥çš„è¯­ä¹‰å’Œæ—¶é—´å¯¹é½ï¼Œæ˜¾è‘—æå‡äº†ç”Ÿæˆä»»åŠ¡çš„è¯„ä¼°æ ‡å‡†å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®é›†æ„å»ºä¸­ï¼Œé‡‡ç”¨äº†è¯¦ç»†çš„å¤šæ¨¡æ€æ³¨é‡Šï¼Œè®¾è®¡äº†é€‚åº”ä¸åŒç”Ÿæˆä»»åŠ¡çš„è¯„ä¼°æŒ‡æ ‡ï¼Œå¹¶ç¡®ä¿æ•°æ®é›†å’Œæ³¨é‡Šçš„å®Œå…¨å¼€æºã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨CoPåŸºå‡†æ•°æ®é›†è¿›è¡Œè®­ç»ƒçš„æ¨¡å‹åœ¨è§†é¢‘åˆ°é’¢ç´éŸ³ä¹ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œç”Ÿæˆè´¨é‡æ˜¾è‘—æå‡ï¼Œè¯„ä¼°æŒ‡æ ‡ç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•æé«˜äº†20%ä»¥ä¸Šï¼Œå±•ç¤ºäº†è¯¥åŸºå‡†åœ¨æ¨åŠ¨ç ”ç©¶è¿›å±•æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬éŸ³ä¹åˆ›ä½œã€æ•™è‚²å’Œå¨±ä¹ç­‰ï¼Œèƒ½å¤Ÿä¸ºè§†é¢‘å†…å®¹åˆ›ä½œè€…æä¾›æ–°çš„éŸ³ä¹ç”Ÿæˆå·¥å…·ï¼Œæå‡åˆ›ä½œæ•ˆç‡å’Œè´¨é‡ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯å¯èƒ½åœ¨è‡ªåŠ¨åŒ–éŸ³ä¹ç”Ÿæˆå’Œäººæœºåä½œåˆ›ä½œä¸­å‘æŒ¥é‡è¦ä½œç”¨ï¼Œæ¨åŠ¨éŸ³ä¹äº§ä¸šçš„åˆ›æ–°å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Generating high-quality piano audio from video requires precise synchronization between visual cues and musical output, ensuring accurate semantic and temporal alignment.However, existing evaluation datasets do not fully capture the intricate synchronization required for piano music generation. A comprehensive benchmark is essential for two primary reasons: (1) existing metrics fail to reflect the complexity of video-to-piano music interactions, and (2) a dedicated benchmark dataset can provide valuable insights to accelerate progress in high-quality piano music generation. To address these challenges, we introduce the CoP Benchmark Dataset-a fully open-sourced, multimodal benchmark designed specifically for video-guided piano music generation. The proposed Chain-of-Perform (CoP) benchmark offers several compelling features: (1) detailed multimodal annotations, enabling precise semantic and temporal alignment between video content and piano audio via step-by-step Chain-of-Perform guidance; (2) a versatile evaluation framework for rigorous assessment of both general-purpose and specialized video-to-piano generation tasks; and (3) full open-sourcing of the dataset, annotations, and evaluation protocols. The dataset is publicly available at https://github.com/acappemin/Video-to-Audio-and-Piano, with a continuously updated leaderboard to promote ongoing research in this domain.

