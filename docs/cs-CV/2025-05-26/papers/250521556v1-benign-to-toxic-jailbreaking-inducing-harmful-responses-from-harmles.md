---
layout: default
title: "Benign-to-Toxic Jailbreaking: Inducing Harmful Responses from Harmless Prompts"
---

# Benign-to-Toxic Jailbreaking: Inducing Harmful Responses from Harmless Prompts

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21556" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21556v1</a>
  <a href="https://arxiv.org/pdf/2505.21556.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21556v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21556v1', 'Benign-to-Toxic Jailbreaking: Inducing Harmful Responses from Harmless Prompts')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hee-Seon Kim, Minbeom Kim, Wonjun Lee, Kihyun Kim, Changick Kim

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-26

**å¤‡æ³¨**: LVLM, Jailbreak

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºBenign-to-Toxicæ–¹æ³•ä»¥è§£å†³å®‰å…¨æœºåˆ¶å¤±æ•ˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¶Šç‹±æŠ€æœ¯` `å¤šæ¨¡æ€å¯¹é½` `å¯¹æŠ—æ€§æ”»å‡»` `å®‰å…¨æœºåˆ¶` `äººå·¥æ™ºèƒ½å®‰å…¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ¯’æ€§å»¶ç»­æ–¹æ³•åœ¨å¤„ç†æ— å®³è¾“å…¥æ—¶ï¼Œéš¾ä»¥è¯±å¯¼æ¨¡å‹äº§ç”Ÿæœ‰å®³è¾“å‡ºï¼Œå­˜åœ¨å®‰å…¨æœºåˆ¶å¤±æ•ˆçš„æŒ‘æˆ˜ã€‚
2. æœ¬æ–‡æå‡ºçš„Benign-to-Toxicè¶Šç‹±æ–¹æ³•ï¼Œé€šè¿‡ä¼˜åŒ–å¯¹æŠ—å›¾åƒï¼Œä»æ— å®³æ¡ä»¶ä¸­è¯±å¯¼æœ‰å®³è¾“å‡ºï¼Œçªç ´äº†ä¼ ç»Ÿæ–¹æ³•çš„å±€é™ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒB2Tæ–¹æ³•åœ¨å¤šç§è®¾ç½®ä¸‹å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå±•ç¤ºäº†å…¶åœ¨é»‘ç®±ç¯å¢ƒä¸­çš„æœ‰æ•ˆæ€§å’Œå¹¿æ³›é€‚ç”¨æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¼˜åŒ–åŸºç¡€çš„è¶Šç‹±æ–¹æ³•é€šå¸¸é‡‡ç”¨æ¯’æ€§å»¶ç»­è®¾ç½®ï¼Œä¾èµ–äºä¸‹ä¸€ä¸ªæ ‡è®°é¢„æµ‹ç›®æ ‡ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•åœ¨ç¼ºä¹æ˜ç¡®æ¯’æ€§ä¿¡å·æ—¶éš¾ä»¥è¯±å¯¼å®‰å…¨å¤±è°ƒã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„è¶Šç‹±èŒƒå¼ï¼šBenign-to-Toxicï¼ˆB2Tï¼‰ï¼Œé€šè¿‡ä¼˜åŒ–å¯¹æŠ—å›¾åƒï¼Œä»æ— å®³çš„æ¡ä»¶è¯±å¯¼æœ‰å®³è¾“å‡ºã€‚è¯¥æ–¹æ³•åœ¨é»‘ç®±è®¾ç½®ä¸­è¡¨ç°ä¼˜è¶Šï¼Œå¹¶ä¸åŸºäºæ–‡æœ¬çš„è¶Šç‹±æ–¹æ³•äº’è¡¥ï¼Œæ­ç¤ºäº†å¤šæ¨¡æ€å¯¹é½ä¸­çš„æ½œåœ¨è„†å¼±æ€§ï¼Œå¼€è¾Ÿäº†æ–°çš„è¶Šç‹±ç ”ç©¶æ–¹å‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰æ¯’æ€§å»¶ç»­æ–¹æ³•åœ¨æ— å®³è¾“å…¥ä¸‹æ— æ³•è¯±å¯¼æœ‰å®³è¾“å‡ºçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äºå·²æœ‰çš„æ¯’æ€§ä¿¡å·ï¼Œå¯¼è‡´åœ¨ç¼ºä¹æ˜ç¡®æ¯’æ€§ä¿¡å·æ—¶è¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºBenign-to-Toxicï¼ˆB2Tï¼‰è¶Šç‹±æ–¹æ³•ï¼Œé€šè¿‡ä¼˜åŒ–å¯¹æŠ—å›¾åƒï¼Œä½¿æ¨¡å‹åœ¨æ— å®³æ¡ä»¶ä¸‹äº§ç”Ÿæœ‰å®³è¾“å‡ºã€‚è¿™ä¸€è®¾è®¡æ—¨åœ¨çªç ´æ¨¡å‹çš„å®‰å…¨æœºåˆ¶ï¼Œæ­ç¤ºå…¶æ½œåœ¨è„†å¼±æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šB2Tæ–¹æ³•çš„æ•´ä½“æµç¨‹åŒ…æ‹¬ï¼š1ï¼‰ç”Ÿæˆæ— å®³çš„è¾“å…¥æ¡ä»¶ï¼›2ï¼‰ä¼˜åŒ–å¯¹æŠ—å›¾åƒä»¥è¯±å¯¼æœ‰å®³è¾“å‡ºï¼›3ï¼‰è¯„ä¼°æ¨¡å‹å¯¹ä¼˜åŒ–å›¾åƒçš„å“åº”ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬è¾“å…¥ç”Ÿæˆã€å¯¹æŠ—ä¼˜åŒ–å’Œè¾“å‡ºè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šB2Tæ–¹æ³•çš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶ä»æ— å®³æ¡ä»¶è¯±å¯¼æœ‰å®³è¾“å‡ºçš„èƒ½åŠ›ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ä¾èµ–å·²æœ‰æ¯’æ€§ä¿¡å·çš„æ–¹å¼æœ¬è´¨ä¸Šä¸åŒï¼Œå¼€è¾Ÿäº†æ–°çš„ç ”ç©¶æ–¹å‘ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼ŒB2Tæ–¹æ³•é‡‡ç”¨ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–å¯¹æŠ—å›¾åƒï¼Œå¹¶è®¾è®¡äº†é€‚åº”æ€§å‚æ•°è®¾ç½®ï¼Œä»¥ç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåœ°çªç ´å®‰å…¨æœºåˆ¶ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒB2Tæ–¹æ³•åœ¨å¤šç§é»‘ç®±è®¾ç½®ä¸­è¡¨ç°ä¼˜äºä¼ ç»Ÿæ¯’æ€§å»¶ç»­æ–¹æ³•ï¼ŒæˆåŠŸè¯±å¯¼æœ‰å®³è¾“å‡ºçš„æ¯”ä¾‹æé«˜äº†çº¦30%ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•ä¸æ–‡æœ¬åŸºç¡€çš„è¶Šç‹±æ–¹æ³•ç›¸ç»“åˆï¼Œè¿›ä¸€æ­¥å¢å¼ºäº†æ¨¡å‹çš„æ”»å‡»èƒ½åŠ›ï¼Œå±•ç¤ºäº†å…¶å¹¿æ³›çš„é€‚ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å®‰å…¨æ€§æµ‹è¯•ã€å¯¹æŠ—æ€§æ”»å‡»ç ”ç©¶ä»¥åŠå¤šæ¨¡æ€ç³»ç»Ÿçš„é²æ£’æ€§è¯„ä¼°ã€‚é€šè¿‡æ­ç¤ºæ¨¡å‹çš„è„†å¼±æ€§ï¼ŒB2Tæ–¹æ³•å¯ä»¥å¸®åŠ©å¼€å‘æ›´å®‰å…¨çš„AIç³»ç»Ÿï¼Œå‡å°‘æ½œåœ¨çš„æ»¥ç”¨é£é™©ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Optimization-based jailbreaks typically adopt the Toxic-Continuation setting in large vision-language models (LVLMs), following the standard next-token prediction objective. In this setting, an adversarial image is optimized to make the model predict the next token of a toxic prompt. However, we find that the Toxic-Continuation paradigm is effective at continuing already-toxic inputs, but struggles to induce safety misalignment when explicit toxic signals are absent. We propose a new paradigm: Benign-to-Toxic (B2T) jailbreak. Unlike prior work, we optimize adversarial images to induce toxic outputs from benign conditioning. Since benign conditioning contains no safety violations, the image alone must break the model's safety mechanisms. Our method outperforms prior approaches, transfers in black-box settings, and complements text-based jailbreaks. These results reveal an underexplored vulnerability in multimodal alignment and introduce a fundamentally new direction for jailbreak approaches.

