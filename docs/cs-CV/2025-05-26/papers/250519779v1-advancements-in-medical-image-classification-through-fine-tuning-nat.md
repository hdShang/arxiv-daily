---
layout: default
title: Advancements in Medical Image Classification through Fine-Tuning Natural Domain Foundation Models
---

# Advancements in Medical Image Classification through Fine-Tuning Natural Domain Foundation Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.19779" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.19779v1</a>
  <a href="https://arxiv.org/pdf/2505.19779.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.19779v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.19779v1', 'Advancements in Medical Image Classification through Fine-Tuning Natural Domain Foundation Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mobina Mansoori, Sajjad Shahabodini, Farnoush Bayatmakou, Jamshid Abouei, Konstantinos N. Plataniotis, Arash Mohammadi

**åˆ†ç±»**: eess.IV, cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-26

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/sajjad-sh33/Medical-Transfer-Learning)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é€šè¿‡å¾®è°ƒè‡ªç„¶é¢†åŸŸåŸºç¡€æ¨¡å‹æå‡åŒ»å­¦å›¾åƒåˆ†ç±»æ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åŒ»å­¦å›¾åƒåˆ†ç±»` `åŸºç¡€æ¨¡å‹` `å¾®è°ƒæŠ€æœ¯` `æ·±åº¦å­¦ä¹ ` `å›¾åƒå¤„ç†` `æœºå™¨å­¦ä¹ ` `æ•°æ®é›†è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŒ»å­¦å›¾åƒåˆ†ç±»æ–¹æ³•åœ¨å¤„ç†æœ‰é™æ ‡æ³¨æ•°æ®æ—¶æ•ˆæœä¸ä½³ï¼Œéš¾ä»¥å……åˆ†åˆ©ç”¨åŸºç¡€æ¨¡å‹çš„æ½œåŠ›ã€‚
2. æœ¬æ–‡é€šè¿‡å¾®è°ƒå¤šç§æœ€æ–°åŸºç¡€æ¨¡å‹ï¼Œæ¢ç´¢å…¶åœ¨åŒ»å­¦å›¾åƒåˆ†ç±»ä¸­çš„åº”ç”¨ï¼Œæ—¨åœ¨æå‡åˆ†ç±»æ€§èƒ½ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAIMv2ã€DINOv2å’ŒSAM2æ¨¡å‹åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œåˆ†ç±»å‡†ç¡®ç‡æ˜¾è‘—æé«˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºç¡€æ¨¡å‹æ˜¯å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ï¼Œèƒ½å¤Ÿæ‰§è¡Œå¤šç§ä»»åŠ¡ã€‚æœ¬æ–‡ç ”ç©¶äº†DINOv2ã€MAEã€VMambaã€CoCaã€SAM2å’ŒAIMv2ç­‰æœ€æ–°åŸºç¡€æ¨¡å‹åœ¨åŒ»å­¦å›¾åƒåˆ†ç±»ä¸­çš„åº”ç”¨ï¼Œåˆ†æå…¶å¯¹CBIS-DDSMã€ISIC2019ã€APTOS2019å’ŒCHEXPERTç­‰æ•°æ®é›†çš„æœ‰æ•ˆæ€§ã€‚é€šè¿‡å¾®è°ƒè¿™äº›æ¨¡å‹ï¼Œç»“æœè¡¨æ˜ï¼Œå°½ç®¡æ ‡æ³¨æ•°æ®æœ‰é™ï¼Œè¿™äº›å…ˆè¿›æ¨¡å‹æ˜¾è‘—æå‡äº†åˆ†ç±»æ•ˆæœï¼Œå°¤å…¶æ˜¯AIMv2ã€DINOv2å’ŒSAM2æ¨¡å‹è¡¨ç°ä¼˜å¼‚ï¼Œè¯æ˜è‡ªç„¶é¢†åŸŸè®­ç»ƒçš„è¿›å±•å¯¹åŒ»å­¦é¢†åŸŸäº§ç”Ÿäº†ç§¯æå½±å“ã€‚ä»£ç å·²å…¬å¼€åœ¨GitHubä¸Šã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åŒ»å­¦å›¾åƒåˆ†ç±»ä¸­ç°æœ‰æ–¹æ³•åœ¨æœ‰é™æ ‡æ³¨æ•°æ®ä¸‹çš„æ€§èƒ½ä¸è¶³ï¼Œæ¢ç´¢å¦‚ä½•æœ‰æ•ˆåˆ©ç”¨åŸºç¡€æ¨¡å‹çš„æ½œåŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¾®è°ƒæœ€æ–°çš„åŸºç¡€æ¨¡å‹ï¼Œç»“åˆåŒ»å­¦å›¾åƒç‰¹å¾ï¼Œæå‡åˆ†ç±»å‡†ç¡®æ€§ï¼ŒéªŒè¯å…¶åœ¨åŒ»å­¦é¢†åŸŸçš„åº”ç”¨æ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨äº†DINOv2ã€MAEã€VMambaã€CoCaã€SAM2å’ŒAIMv2ç­‰æ¨¡å‹ï¼Œé’ˆå¯¹ä¸åŒåŒ»å­¦å›¾åƒæ•°æ®é›†è¿›è¡Œå¾®è°ƒå’Œè¯„ä¼°ï¼Œæ•´ä½“æµç¨‹åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œæ€§èƒ½è¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°åœ¨äºç³»ç»Ÿæ€§åœ°è¯„ä¼°å¤šç§åŸºç¡€æ¨¡å‹åœ¨åŒ»å­¦å›¾åƒåˆ†ç±»ä¸­çš„è¡¨ç°ï¼Œç‰¹åˆ«æ˜¯é€šè¿‡å¾®è°ƒæŠ€æœ¯æ˜¾è‘—æå‡äº†åˆ†ç±»æ•ˆæœï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”å…·æœ‰æ˜æ˜¾ä¼˜åŠ¿ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œä¼˜åŒ–ç®—æ³•ï¼Œè°ƒæ•´äº†è¶…å‚æ•°è®¾ç½®ï¼Œä»¥é€‚åº”åŒ»å­¦å›¾åƒçš„ç‰¹å¾å’Œéœ€æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒAIMv2ã€DINOv2å’ŒSAM2æ¨¡å‹åœ¨CBIS-DDSMã€ISIC2019ã€APTOS2019å’ŒCHEXPERTæ•°æ®é›†ä¸Šå‡æ˜¾è‘—æå‡äº†åˆ†ç±»æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨æ ‡æ³¨æ•°æ®æœ‰é™çš„æƒ…å†µä¸‹ï¼Œåˆ†ç±»å‡†ç¡®ç‡æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œå±•ç°äº†å¼ºå¤§çš„åº”ç”¨æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŒ»å­¦å½±åƒè¯Šæ–­ã€ç–¾ç—…ç­›æŸ¥å’Œè¾…åŠ©å†³ç­–ç³»ç»Ÿã€‚é€šè¿‡æå‡åŒ»å­¦å›¾åƒåˆ†ç±»çš„å‡†ç¡®æ€§ï¼Œèƒ½å¤Ÿä¸ºä¸´åºŠåŒ»ç”Ÿæä¾›æ›´å¯é çš„æ”¯æŒï¼Œä¿ƒè¿›æ—©æœŸè¯Šæ–­å’Œä¸ªæ€§åŒ–æ²»ç–—çš„å‘å±•ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œç¤¾ä¼šå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Using massive datasets, foundation models are large-scale, pre-trained models that perform a wide range of tasks. These models have shown consistently improved results with the introduction of new methods. It is crucial to analyze how these trends impact the medical field and determine whether these advancements can drive meaningful change. This study investigates the application of recent state-of-the-art foundation models, DINOv2, MAE, VMamba, CoCa, SAM2, and AIMv2, for medical image classification. We explore their effectiveness on datasets including CBIS-DDSM for mammography, ISIC2019 for skin lesions, APTOS2019 for diabetic retinopathy, and CHEXPERT for chest radiographs. By fine-tuning these models and evaluating their configurations, we aim to understand the potential of these advancements in medical image classification. The results indicate that these advanced models significantly enhance classification outcomes, demonstrating robust performance despite limited labeled data. Based on our results, AIMv2, DINOv2, and SAM2 models outperformed others, demonstrating that progress in natural domain training has positively impacted the medical domain and improved classification outcomes. Our code is publicly available at: https://github.com/sajjad-sh33/Medical-Transfer-Learning.

