---
layout: default
title: "MMGeoLM: Hard Negative Contrastive Learning for Fine-Grained Geometric Understanding in Large Multimodal Models"
---

# MMGeoLM: Hard Negative Contrastive Learning for Fine-Grained Geometric Understanding in Large Multimodal Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20152" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.20152v3</a>
  <a href="https://arxiv.org/pdf/2505.20152.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20152v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20152v3', 'MMGeoLM: Hard Negative Contrastive Learning for Fine-Grained Geometric Understanding in Large Multimodal Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kai Sun, Yushi Bai, Zhen Yang, Jiajie Zhang, Ji Qi, Lei Hou, Juanzi Li

**åˆ†ç±»**: cs.CV, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-26 (æ›´æ–°: 2025-10-01)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/THU-KEG/MMGeoLM)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMMGeoLMä»¥è§£å†³å¤§è§„æ¨¡å¤šæ¨¡æ€æ¨¡å‹çš„å‡ ä½•ç†è§£é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ¨¡å‹` `å‡ ä½•ç†è§£` `å¯¹æ¯”å­¦ä¹ ` `ç¡¬è´Ÿæ ·æœ¬` `è§†è§‰ç¼–ç å™¨` `ç»†ç²’åº¦å·®å¼‚` `æ¨¡å‹ä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€æ¨¡å‹åœ¨å‡ ä½•ç†è§£ä»»åŠ¡ä¸­è¡¨ç°ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨æ•æ‰ç»†ç²’åº¦è§†è§‰å·®å¼‚æ–¹é¢ï¼Œé™åˆ¶äº†å…¶åº”ç”¨æ•ˆæœã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§ç¡¬è´Ÿæ ·æœ¬å¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡ç”Ÿæˆå’Œé€‰æ‹©è´Ÿæ ·æœ¬æ¥å¢å¼ºè§†è§‰ç¼–ç å™¨çš„è®­ç»ƒæ•ˆæœï¼Œä»è€Œæå‡å‡ ä½•ç†è§£èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMMGeoLMåœ¨å¤šä¸ªå‡ ä½•æ¨ç†åŸºå‡†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†å…¶ä»–å¼€æºæ¨¡å‹ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤§è§„æ¨¡æ¨¡å‹ä¸­çš„æ½œåŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§è§„æ¨¡å¤šæ¨¡æ€æ¨¡å‹ï¼ˆLMMsï¼‰é€šå¸¸åŸºäºè§†è§‰å˜æ¢å™¨ï¼ˆå¦‚CLIPï¼‰ï¼Œä½†ä½¿ç”¨ç®€å•çš„éšæœºæ‰¹å†…è´Ÿæ ·æœ¬é™åˆ¶äº†å…¶æ•æ‰ç»†ç²’åº¦è§†è§‰å·®å¼‚çš„èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨å‡ ä½•åœºæ™¯ä¸­ã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç¡¬è´Ÿæ ·æœ¬å¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œç»“åˆäº†åŸºäºå›¾åƒçš„å¯¹æ¯”å­¦ä¹ å’ŒåŸºäºæ–‡æœ¬çš„å¯¹æ¯”å­¦ä¹ ã€‚é€šè¿‡ç”Ÿæˆæ‰°åŠ¨å›¾ç¤ºç”Ÿæˆä»£ç åˆ›å»ºçš„ç¡¬è´Ÿæ ·æœ¬ä»¥åŠåŸºäºä¿®æ”¹å‡ ä½•æè¿°å’Œæ£€ç´¢ç›¸ä¼¼æ€§é€‰æ‹©çš„è´Ÿæ ·æœ¬ï¼Œè®­ç»ƒäº†è§†è§‰ç¼–ç å™¨CLIPï¼Œå¹¶è¿›ä¸€æ­¥è®­ç»ƒäº†ç”¨äºå‡ ä½•é—®é¢˜æ±‚è§£çš„LMMã€‚å®éªŒè¡¨æ˜ï¼Œè®­ç»ƒå‡ºçš„æ¨¡å‹MMGeoLMåœ¨ä¸‰ä¸ªå‡ ä½•æ¨ç†åŸºå‡†ä¸Šæ˜¾è‘—ä¼˜äºå…¶ä»–å¼€æºæ¨¡å‹ï¼Œç”šè‡³åœ¨7Bå‚æ•°è§„æ¨¡ä¸‹ä¹Ÿèƒ½ä¸å¼ºå¤§çš„é—­æºæ¨¡å‹å¦‚GPT-4oç›¸åª²ç¾ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è§„æ¨¡å¤šæ¨¡æ€æ¨¡å‹åœ¨å‡ ä½•ç†è§£ä»»åŠ¡ä¸­å¯¹ç»†ç²’åº¦è§†è§‰å·®å¼‚æ•æ‰èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä½¿ç”¨ç®€å•çš„éšæœºæ‰¹å†…è´Ÿæ ·æœ¬ï¼Œå¯¼è‡´æ¨¡å‹åœ¨å¤æ‚å‡ ä½•åœºæ™¯ä¸­çš„è¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºäº†ä¸€ç§ç¡¬è´Ÿæ ·æœ¬å¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œç»“åˆå›¾åƒç”Ÿæˆçš„ç¡¬è´Ÿæ ·æœ¬å’ŒåŸºäºæ–‡æœ¬çš„è§„åˆ™è´Ÿæ ·æœ¬ï¼Œä»¥å¢å¼ºè§†è§‰ç¼–ç å™¨çš„è®­ç»ƒæ•ˆæœï¼Œä»è€Œæå‡å‡ ä½•ç†è§£èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šé¦–å…ˆï¼Œä½¿ç”¨ç”Ÿæˆæ‰°åŠ¨çš„å›¾ç¤ºç”Ÿæˆä»£ç åˆ›å»ºç¡¬è´Ÿæ ·æœ¬è¿›è¡Œå›¾åƒå¯¹æ¯”å­¦ä¹ ï¼›å…¶æ¬¡ï¼ŒåŸºäºä¿®æ”¹çš„å‡ ä½•æè¿°å’Œæ£€ç´¢ç›¸ä¼¼æ€§é€‰æ‹©è´Ÿæ ·æœ¬è¿›è¡Œæ–‡æœ¬å¯¹æ¯”å­¦ä¹ ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥äº†ç”Ÿæˆå’Œé€‰æ‹©çš„ç¡¬è´Ÿæ ·æœ¬ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨ç»†ç²’åº¦å‡ ä½•ç†è§£ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°æ•æ‰è§†è§‰å·®å¼‚ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡æ­£è´Ÿæ ·æœ¬çš„å½±å“ï¼ŒåŒæ—¶å¯¹ç½‘ç»œç»“æ„è¿›è¡Œäº†ä¼˜åŒ–ï¼Œä»¥é€‚åº”å¤šæ¨¡æ€è¾“å…¥çš„ç‰¹æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒMMGeoLMåœ¨ä¸‰ä¸ªå‡ ä½•æ¨ç†åŸºå‡†ä¸Šæ˜¾è‘—ä¼˜äºå…¶ä»–å¼€æºæ¨¡å‹ï¼Œå°¤å…¶æ˜¯åœ¨7Bå‚æ•°è§„æ¨¡ä¸‹ï¼Œå…¶æ€§èƒ½æ¥è¿‘äºå¼ºå¤§çš„é—­æºæ¨¡å‹GPT-4oï¼Œå±•ç¤ºäº†ç¡¬è´Ÿæ ·æœ¬å¯¹æ¯”å­¦ä¹ çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€è‡ªåŠ¨åŒ–è®¾è®¡å’Œæœºå™¨äººè§†è§‰ç­‰ï¼Œèƒ½å¤Ÿä¸ºå‡ ä½•é—®é¢˜æ±‚è§£æä¾›æ›´ä¸ºç²¾ç¡®çš„æ”¯æŒã€‚æœªæ¥ï¼Œéšç€æ¨¡å‹çš„è¿›ä¸€æ­¥ä¼˜åŒ–ï¼ŒMMGeoLMæœ‰æœ›åœ¨æ›´å¹¿æ³›çš„å¤šæ¨¡æ€ä»»åŠ¡ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Multimodal Models (LMMs) typically build on ViTs (e.g., CLIP), yet their training with simple random in-batch negatives limits the ability to capture fine-grained visual differences, particularly in geometric scenarios. To address this challenge, we propose a novel hard negative contrastive learning framework for the vision encoder, which combines image-based contrastive learning using generation-based hard negatives created by perturbing diagram generation code, and text-based contrastive learning using rule-based negatives derived from modified geometric descriptions and retrieval-based negatives selected based on caption similarity. We train a vision encoder (CLIP) using our hard negative training method, namely MMCLIP (Multimodal Math CLIP), and subsequently train an LMM for geometric problem-solving. Experiments show that our trained model, MMGeoLM, significantly outperforms other open-source models on three geometric reasoning benchmarks. Even with a size of 7B, it can rival powerful closed-source models like GPT-4o. We further conduct ablation studies to analyze three key factors: hard negative types, the efficiency of image-based negatives, and training configurations. These analyses yield important insights into optimizing the training pipeline of vision encoder for fine-grained geometric reasoning tasks. https://github.com/THU-KEG/MMGeoLM.

