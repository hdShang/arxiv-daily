---
layout: default
title: Structured Initialization for Vision Transformers
---

# Structured Initialization for Vision Transformers

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.19985" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.19985v2</a>
  <a href="https://arxiv.org/pdf/2505.19985.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.19985v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.19985v2', 'Structured Initialization for Vision Transformers')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jianqiao Zheng, Xueqian Li, Hemanth Saratchandran, Simon Lucey

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-26 (æ›´æ–°: 2025-12-06)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»“æ„åŒ–åˆå§‹åŒ–æ–¹æ³•ä»¥æå‡è§†è§‰å˜æ¢å™¨æ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `è§†è§‰å˜æ¢å™¨` `ç»“æ„åŒ–åˆå§‹åŒ–` `å·ç§¯ç¥ç»ç½‘ç»œ` `å°æ•°æ®é›†` `æ€§èƒ½æå‡` `è®¡ç®—æœºè§†è§‰` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†è§‰å˜æ¢å™¨åˆå§‹åŒ–æ–¹æ³•é€šå¸¸ä¾èµ–ç»éªŒå¯å‘å¼ï¼Œç¼ºä¹æœ‰æ•ˆçš„ç»“æ„æ€§è®¾è®¡ï¼Œå¯¼è‡´åœ¨å°æ•°æ®é›†ä¸Šçš„æ€§èƒ½ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„åˆå§‹åŒ–ç­–ç•¥ï¼Œé€šè¿‡å¼•å…¥CNNçš„å½’çº³åç½®ï¼Œä½¿å¾—ViTåœ¨å°æ•°æ®é›†ä¸Šè¡¨ç°æ›´ä½³ï¼ŒåŒæ—¶ä¿æŒåœ¨å¤§æ•°æ®é›†ä¸Šçš„æ‰©å±•æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæœ¬æ–‡æ–¹æ³•åœ¨Food-101ã€CIFAR-10ç­‰å¤šä¸ªå°å‹æ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºæ ‡å‡†ViTåˆå§‹åŒ–ï¼Œä¸”åœ¨ImageNet-1Kä¸Šè¡¨ç°ç›¸å½“ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å›ºæœ‰åœ°ç¼–ç äº†å¼ºå¤§çš„å½’çº³åç½®ï¼Œä½¿å…¶åœ¨å°è§„æ¨¡æ•°æ®é›†ä¸Šèƒ½å¤Ÿæœ‰æ•ˆæ³›åŒ–ã€‚æœ¬æ–‡æå‡ºå°†è¿™ç§å½’çº³åç½®æ•´åˆåˆ°è§†è§‰å˜æ¢å™¨ï¼ˆViTï¼‰ä¸­ï¼Œæ–¹æ³•æ˜¯é€šè¿‡åˆå§‹åŒ–è€Œéæ¶æ„å¹²é¢„ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯ä½¿ViTåœ¨æ•°æ®èµ„äº§è¾ƒå°‘æ—¶èƒ½å¤Ÿäº«æœ‰ç±»ä¼¼CNNçš„å¼ºå¤§æ€§èƒ½ï¼ŒåŒæ—¶åœ¨æ•°æ®æ‰©å±•æ—¶ä»èƒ½è¾¾åˆ°ViTçš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„æ–¹æ³•åŸºäºå®è¯ç»“æœï¼Œè¡¨æ˜éšæœºè„‰å†²æ»¤æ³¢å™¨åœ¨CNNä¸­å¯ä»¥è¾¾åˆ°ä¸å­¦ä¹ æ»¤æ³¢å™¨ç›¸å½“çš„æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤šä¸ªå°å‹å’Œä¸­å‹åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºæ ‡å‡†ViTåˆå§‹åŒ–ï¼ŒåŒæ—¶åœ¨å¤§è§„æ¨¡æ•°æ®é›†å¦‚ImageNet-1Kä¸Šä¿æŒäº†ç›¸å¯¹çš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„åˆå§‹åŒ–ç­–ç•¥è¿˜å¯ä»¥è½»æ¾é›†æˆåˆ°å„ç§åŸºäºå˜æ¢å™¨çš„æ¶æ„ä¸­ï¼Œå¦‚Swin Transformerå’ŒMLP-Mixerï¼Œå¹¶æŒç»­æå‡æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è§†è§‰å˜æ¢å™¨ï¼ˆViTï¼‰åœ¨å°è§„æ¨¡æ•°æ®é›†ä¸Šæ€§èƒ½ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰çš„åˆå§‹åŒ–ç­–ç•¥å¤šä¾èµ–äºç»éªŒå¯å‘å¼ï¼Œæœªèƒ½æœ‰æ•ˆåˆ©ç”¨CNNçš„å½’çº³åç½®ï¼Œå¯¼è‡´ViTåœ¨æ•°æ®ç¨€ç¼ºæ—¶è¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºé€šè¿‡ç»“æ„åŒ–åˆå§‹åŒ–æ¥å¼•å…¥CNNçš„å½’çº³åç½®ï¼Œè€Œéæ”¹å˜ViTçš„æ¶æ„ã€‚è¿™ä¸€è®¾è®¡æ—¨åœ¨ä½¿ViTåœ¨å°æ•°æ®é›†ä¸Šè·å¾—ç±»ä¼¼CNNçš„æ€§èƒ½ï¼ŒåŒæ—¶åœ¨æ•°æ®é‡å¢åŠ æ—¶ä¿æŒViTçš„ä¼˜åŠ¿ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•çš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬åˆå§‹åŒ–é˜¶æ®µå’Œè®­ç»ƒé˜¶æ®µã€‚åœ¨åˆå§‹åŒ–é˜¶æ®µï¼Œæˆ‘ä»¬ä½¿ç”¨éšæœºè„‰å†²æ»¤æ³¢å™¨æ¥æ›¿ä»£ä¼ ç»Ÿçš„å­¦ä¹ æ»¤æ³¢å™¨ï¼Œä»¥å¢å¼ºæ¨¡å‹çš„åˆå§‹æ€§èƒ½ã€‚åœ¨è®­ç»ƒé˜¶æ®µï¼Œæ¨¡å‹é€šè¿‡æ ‡å‡†çš„è®­ç»ƒæµç¨‹è¿›è¡Œä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„ä¸»è¦åˆ›æ–°åœ¨äºé€šè¿‡åˆå§‹åŒ–å¼•å…¥ç»“æ„æ€§è®¾è®¡ï¼Œæ˜¾è‘—æ”¹å–„äº†ViTåœ¨å°æ•°æ®é›†ä¸Šçš„è¡¨ç°ã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºä¸ä¾èµ–äºé¢„è®­ç»ƒæ¨¡å‹çš„æ³¨æ„åŠ›æƒé‡ï¼Œè€Œæ˜¯é€šè¿‡éšæœºæ»¤æ³¢å™¨å®ç°æ€§èƒ½æå‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œæˆ‘ä»¬ä½¿ç”¨äº†éšæœºè„‰å†²æ»¤æ³¢å™¨ï¼Œå¹¶åœ¨æŸå¤±å‡½æ•°ä¸Šä¿æŒä¸ä¼ ç»ŸCNNä¸€è‡´çš„è®¾è®¡ã€‚æ­¤å¤–ï¼Œåˆå§‹åŒ–ç­–ç•¥å¯ä»¥çµæ´»åº”ç”¨äºä¸åŒçš„å˜æ¢å™¨æ¶æ„ï¼Œå¦‚Swin Transformerå’ŒMLP-Mixerï¼Œç¡®ä¿äº†å¹¿æ³›çš„é€‚ç”¨æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡æå‡ºçš„åˆå§‹åŒ–æ–¹æ³•åœ¨Food-101ã€CIFAR-10ç­‰å°å‹æ•°æ®é›†ä¸Šæ˜¾è‘—æé«˜äº†ViTçš„æ€§èƒ½ï¼Œæå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šã€‚åŒæ—¶ï¼Œåœ¨å¤§è§„æ¨¡æ•°æ®é›†ImageNet-1Kä¸Šï¼Œæ€§èƒ½ä¿æŒç›¸å¯¹ç¨³å®šï¼Œæ˜¾ç¤ºå‡ºè‰¯å¥½çš„æ‰©å±•æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è®¡ç®—æœºè§†è§‰ä¸­çš„å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ç­‰ä»»åŠ¡ï¼Œå°¤å…¶æ˜¯åœ¨æ•°æ®ç¨€ç¼ºçš„åœºæ™¯ä¸‹ã€‚é€šè¿‡æå‡è§†è§‰å˜æ¢å™¨åœ¨å°è§„æ¨¡æ•°æ®é›†ä¸Šçš„æ€§èƒ½ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿä¸ºå®é™…åº”ç”¨æä¾›æ›´å¼ºçš„æ”¯æŒï¼Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Convolutional Neural Networks (CNNs) inherently encode strong inductive biases, enabling effective generalization on small-scale datasets. In this paper, we propose integrating this inductive bias into ViTs, not through an architectural intervention but solely through initialization. The motivation here is to have a ViT that can enjoy strong CNN-like performance when data assets are small, but can still scale to ViT-like performance as the data expands. Our approach is motivated by our empirical results that random impulse filters can achieve commensurate performance to learned filters within a CNN. We improve upon current ViT initialization strategies, which typically rely on empirical heuristics such as using attention weights from pretrained models or focusing on the distribution of attention weights without enforcing structures. Empirical results demonstrate that our method significantly outperforms standard ViT initialization across numerous small and medium-scale benchmarks, including Food-101, CIFAR-10, CIFAR-100, STL-10, Flowers, and Pets, while maintaining comparative performance on large-scale datasets such as ImageNet-1K. Moreover, our initialization strategy can be easily integrated into various transformer-based architectures such as Swin Transformer and MLP-Mixer with consistent improvements in performance.

