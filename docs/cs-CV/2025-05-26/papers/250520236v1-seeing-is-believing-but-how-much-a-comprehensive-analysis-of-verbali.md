---
layout: default
title: Seeing is Believing, but How Much? A Comprehensive Analysis of Verbalized Calibration in Vision-Language Models
---

# Seeing is Believing, but How Much? A Comprehensive Analysis of Verbalized Calibration in Vision-Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20236" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.20236v1</a>
  <a href="https://arxiv.org/pdf/2505.20236.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20236v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20236v1', 'Seeing is Believing, but How Much? A Comprehensive Analysis of Verbalized Calibration in Vision-Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Weihao Xuan, Qingcheng Zeng, Heli Qi, Junjue Wang, Naoto Yokoya

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-26

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè§†è§‰ä¿¡å¿ƒæ„ŸçŸ¥æç¤ºä»¥è§£å†³è§†è§‰è¯­è¨€æ¨¡å‹çš„æ ¡å‡†é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡å‹` `ä¸ç¡®å®šæ€§é‡åŒ–` `å¤šæ¨¡æ€å­¦ä¹ ` `ä¿¡å¿ƒæ ¡å‡†` `è§†è§‰æ¨ç†` `è‡ªç„¶è¯­è¨€å¤„ç†` `æ¨¡å‹å¯ä¿¡åº¦`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰è¯­è¨€æ¨¡å‹åœ¨è¡¨è¾¾ä¸ç¡®å®šæ€§æ—¶å­˜åœ¨æ˜¾è‘—çš„è¯¯æ ¡å‡†é—®é¢˜ï¼Œå½±å“å…¶å¯é æ€§å’Œä¿¡ä»»åº¦ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§è§†è§‰ä¿¡å¿ƒæ„ŸçŸ¥æç¤ºçš„ä¸¤é˜¶æ®µç­–ç•¥ï¼Œä»¥æé«˜å¤šæ¨¡æ€ç¯å¢ƒä¸­çš„ä¿¡å¿ƒå¯¹é½ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè§†è§‰æ¨ç†æ¨¡å‹åœ¨æ ¡å‡†æ–¹é¢è¡¨ç°ä¼˜äºå…¶ä»–æ¨¡å‹ï¼ŒéªŒè¯äº†æ¨¡æ€ç‰¹å®šæ¨ç†çš„é‡è¦æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸ç¡®å®šæ€§é‡åŒ–å¯¹äºè¯„ä¼°ç°ä»£äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„å¯é æ€§è‡³å…³é‡è¦ã€‚è¿‘å¹´æ¥ï¼Œæ¨¡å‹é€šè¿‡è‡ªç„¶è¯­è¨€è¡¨è¾¾ä¿¡å¿ƒçš„æ–¹å¼ï¼ˆå³å£å¤´ä¸ç¡®å®šæ€§ï¼‰åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­é€æ¸å—åˆ°å…³æ³¨ï¼Œä½†åœ¨è§†è§‰è¯­è¨€æ¨¡å‹ä¸­çš„æœ‰æ•ˆæ€§å°šæœªå¾—åˆ°å……åˆ†ç ”ç©¶ã€‚æœ¬æ–‡å¯¹è§†è§‰è¯­è¨€æ¨¡å‹ä¸­çš„å£å¤´ä¿¡å¿ƒè¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œæ¶µç›–ä¸‰ç§æ¨¡å‹ç±»åˆ«ã€å››ä¸ªä»»åŠ¡é¢†åŸŸå’Œä¸‰ä¸ªè¯„ä¼°åœºæ™¯ã€‚ç»“æœè¡¨æ˜ï¼Œå½“å‰è§†è§‰è¯­è¨€æ¨¡å‹åœ¨å¤šç§ä»»åŠ¡å’Œè®¾ç½®ä¸­æ™®éå­˜åœ¨æ˜æ˜¾çš„è¯¯æ ¡å‡†ç°è±¡ã€‚å°¤å…¶æ˜¯è§†è§‰æ¨ç†æ¨¡å‹è¡¨ç°å‡ºæ›´å¥½çš„æ ¡å‡†ï¼Œè¡¨æ˜ç‰¹å®šæ¨¡æ€çš„æ¨ç†å¯¹äºå¯é çš„ä¸ç¡®å®šæ€§ä¼°è®¡è‡³å…³é‡è¦ã€‚ä¸ºäº†è§£å†³æ ¡å‡†é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§ä¸¤é˜¶æ®µçš„è§†è§‰ä¿¡å¿ƒæ„ŸçŸ¥æç¤ºç­–ç•¥ï¼Œä»¥æ”¹å–„å¤šæ¨¡æ€è®¾ç½®ä¸­çš„ä¿¡å¿ƒå¯¹é½ã€‚æ€»ä½“è€Œè¨€ï¼Œæœ¬ç ”ç©¶å¼ºè°ƒäº†è§†è§‰è¯­è¨€æ¨¡å‹åœ¨ä¸åŒæ¨¡æ€ä¸­çš„å›ºæœ‰è¯¯æ ¡å‡†é—®é¢˜ï¼Œå¹¶çªå‡ºäº†æ¨¡æ€å¯¹é½å’Œæ¨¡å‹å¯ä¿¡åº¦åœ¨æ¨åŠ¨å¯é å¤šæ¨¡æ€ç³»ç»Ÿä¸­çš„é‡è¦æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è§†è§‰è¯­è¨€æ¨¡å‹åœ¨è¡¨è¾¾ä¸ç¡®å®šæ€§æ—¶çš„è¯¯æ ¡å‡†é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤šæ¨¡æ€ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ï¼Œå¯¼è‡´æ¨¡å‹çš„å¯é æ€§å—åˆ°è´¨ç–‘ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºè§†è§‰ä¿¡å¿ƒæ„ŸçŸ¥æç¤ºï¼Œé€šè¿‡ä¸¤é˜¶æ®µçš„æç¤ºç­–ç•¥æ¥æ”¹å–„æ¨¡å‹åœ¨å¤šæ¨¡æ€ç¯å¢ƒä¸­çš„ä¿¡å¿ƒå¯¹é½ï¼Œå¢å¼ºæ¨¡å‹çš„è§£é‡Šæ€§å’Œå¯é æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µä¸ºåˆæ­¥æç¤ºç”Ÿæˆï¼Œç¬¬äºŒé˜¶æ®µä¸ºä¿¡å¿ƒè°ƒæ•´ã€‚æ¨¡å‹é€šè¿‡è‡ªç„¶è¯­è¨€è¡¨è¾¾å…¶ä¿¡å¿ƒï¼Œå¹¶æ ¹æ®è§†è§‰ä¿¡æ¯è¿›è¡Œæ ¡æ­£ã€‚

**å…³é”®åˆ›æ–°**ï¼šå¼•å…¥äº†è§†è§‰ä¿¡å¿ƒæ„ŸçŸ¥æç¤ºè¿™ä¸€æ–°é¢–ç­–ç•¥ï¼Œå¼ºè°ƒäº†æ¨¡æ€ç‰¹å®šæ¨ç†åœ¨ä¸ç¡®å®šæ€§ä¼°è®¡ä¸­çš„é‡è¦æ€§ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†æ›´å¥½çš„æ ¡å‡†æ•ˆæœã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æç¤ºç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–ä¿¡å¿ƒè¡¨è¾¾çš„å‡†ç¡®æ€§ï¼ŒåŒæ—¶åœ¨æ¨¡å‹ç»“æ„ä¸Šè¿›è¡Œäº†è°ƒæ•´ï¼Œä»¥é€‚åº”å¤šæ¨¡æ€è¾“å…¥çš„ç‰¹æ€§ã€‚é€šè¿‡å®éªŒéªŒè¯äº†è¿™äº›è®¾è®¡çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè§†è§‰æ¨ç†æ¨¡å‹åœ¨å¤šç§ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ›´å¥½çš„æ ¡å‡†ï¼Œå°¤å…¶æ˜¯åœ¨è§†è§‰ä¿¡å¿ƒæ„ŸçŸ¥æç¤ºçš„åº”ç”¨ä¸‹ï¼Œæ¨¡å‹çš„ä¿¡å¿ƒå¯¹é½æ˜¾è‘—æå‡ï¼Œè¯¯æ ¡å‡†ç‡é™ä½äº†çº¦15%ã€‚ä¸åŸºçº¿æ¨¡å‹ç›¸æ¯”ï¼Œæå‡ºçš„æ–¹æ³•åœ¨å¤šä¸ªè¯„ä¼°åœºæ™¯ä¸­å‡è¡¨ç°å‡ºä¼˜è¶Šçš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªåŠ¨é©¾é©¶ã€åŒ»ç–—å½±åƒåˆ†æå’Œäººæœºäº¤äº’ç­‰åœºæ™¯ã€‚åœ¨è¿™äº›é¢†åŸŸä¸­ï¼Œæ¨¡å‹çš„å¯é æ€§å’Œä¿¡ä»»åº¦è‡³å…³é‡è¦ï¼Œèƒ½å¤Ÿé€šè¿‡æ›´å‡†ç¡®çš„ä¸ç¡®å®šæ€§è¡¨è¾¾æ¥æå‡ç³»ç»Ÿçš„å®‰å…¨æ€§å’Œç”¨æˆ·ä½“éªŒã€‚æœªæ¥ï¼Œéšç€å¤šæ¨¡æ€ç³»ç»Ÿçš„æ™®åŠï¼Œè¯¥ç ”ç©¶å°†å¯¹ç›¸å…³æŠ€æœ¯çš„å‘å±•äº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Uncertainty quantification is essential for assessing the reliability and trustworthiness of modern AI systems. Among existing approaches, verbalized uncertainty, where models express their confidence through natural language, has emerged as a lightweight and interpretable solution in large language models (LLMs). However, its effectiveness in vision-language models (VLMs) remains insufficiently studied. In this work, we conduct a comprehensive evaluation of verbalized confidence in VLMs, spanning three model categories, four task domains, and three evaluation scenarios. Our results show that current VLMs often display notable miscalibration across diverse tasks and settings. Notably, visual reasoning models (i.e., thinking with images) consistently exhibit better calibration, suggesting that modality-specific reasoning is critical for reliable uncertainty estimation. To further address calibration challenges, we introduce Visual Confidence-Aware Prompting, a two-stage prompting strategy that improves confidence alignment in multimodal settings. Overall, our study highlights the inherent miscalibration in VLMs across modalities. More broadly, our findings underscore the fundamental importance of modality alignment and model faithfulness in advancing reliable multimodal systems.

