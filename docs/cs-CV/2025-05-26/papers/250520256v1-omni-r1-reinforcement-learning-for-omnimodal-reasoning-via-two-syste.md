---
layout: default
title: Omni-R1: Reinforcement Learning for Omnimodal Reasoning via Two-System Collaboration
---

# Omni-R1: Reinforcement Learning for Omnimodal Reasoning via Two-System Collaboration

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20256" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.20256v1</a>
  <a href="https://arxiv.org/pdf/2505.20256.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20256v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20256v1', 'Omni-R1: Reinforcement Learning for Omnimodal Reasoning via Two-System Collaboration')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hao Zhong, Muzhi Zhu, Zongze Du, Zheng Huang, Canyu Zhao, Mingyu Liu, Wen Wang, Hao Chen, Chunhua Shen

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-26

**å¤‡æ³¨**: Project page: https://aim-uofa.github.io/OmniR1

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOmni-R1ä»¥è§£å†³é•¿è§†é¢‘éŸ³é¢‘æ¨ç†ä¸ç»†ç²’åº¦åƒç´ ç†è§£çš„çŸ›ç›¾é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é•¿è§†é¢‘ç†è§£` `éŸ³é¢‘æ¨ç†` `ç»†ç²’åº¦åƒç´ ç†è§£` `å¼ºåŒ–å­¦ä¹ ` `å¤šæ¨¡æ€æ¨¡å‹` `å…³é”®å¸§é€‰æ‹©` `å±‚æ¬¡å¥–åŠ±æœºåˆ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨é•¿è§†é¢‘éŸ³é¢‘æ¨ç†ä¸ç»†ç²’åº¦åƒç´ ç†è§£ä¹‹é—´å­˜åœ¨çŸ›ç›¾ï¼Œéš¾ä»¥åŒæ—¶æ»¡è¶³ä½åˆ†è¾¨ç‡å’Œé«˜åˆ†è¾¨ç‡çš„éœ€æ±‚ã€‚
2. è®ºæ–‡æå‡ºçš„Omni-R1é€šè¿‡åŒç³»ç»Ÿæ¶æ„ï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–å…³é”®å¸§é€‰æ‹©å’Œä»»åŠ¡é‡å†™ï¼Œè§£å†³äº†è¿™ä¸€çŸ›ç›¾ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒOmni-R1åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†ç°æœ‰çš„ç›‘ç£å’Œä¸“é—¨æ¨¡å‹ï¼Œæå‡äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é•¿æ—¶é—´çš„è§†é¢‘éŸ³é¢‘æ¨ç†ä¸ç»†ç²’åº¦åƒç´ ç†è§£å¯¹å…¨æ¨¡æ€æ¨¡å‹æå‡ºäº†ç›¸äº’çŸ›ç›¾çš„è¦æ±‚ï¼šå¯†é›†çš„æ—¶é—´è¦†ç›–éœ€è¦è®¸å¤šä½åˆ†è¾¨ç‡å¸§ï¼Œè€Œç²¾ç¡®çš„å®šä½åˆ™éœ€è¦é«˜åˆ†è¾¨ç‡è¾“å…¥ã€‚ä¸ºäº†è§£å†³è¿™ä¸€æƒè¡¡ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŒç³»ç»Ÿæ¶æ„ï¼šå…¨çƒæ¨ç†ç³»ç»Ÿé€‰æ‹©ä¿¡æ¯ä¸°å¯Œçš„å…³é”®å¸§å¹¶ä»¥ä½ç©ºé—´æˆæœ¬é‡å†™ä»»åŠ¡ï¼Œè€Œç»†èŠ‚ç†è§£ç³»ç»Ÿåˆ™åœ¨é€‰å®šçš„é«˜åˆ†è¾¨ç‡ç‰‡æ®µä¸Šæ‰§è¡Œåƒç´ çº§çš„å®šä½ã€‚ç”±äºâ€œæœ€ä½³â€å…³é”®å¸§é€‰æ‹©å’Œé‡æ„æ¨¡ç³Šä¸”éš¾ä»¥ç›‘ç£ï¼Œæœ¬æ–‡å°†å…¶å½¢å¼åŒ–ä¸ºå¼ºåŒ–å­¦ä¹ é—®é¢˜ï¼Œå¹¶æå‡ºäº†Omni-R1ï¼Œä¸€ä¸ªåŸºäºç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–çš„ç«¯åˆ°ç«¯å¼ºåŒ–å­¦ä¹ æ¡†æ¶ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒOmni-R1åœ¨RefAVSå’ŒREVOSä¸¤ä¸ªåŸºå‡†ä¸Šè¶…è¶Šäº†å¼ºå¤§çš„ç›‘ç£åŸºçº¿ï¼Œå¹¶åœ¨é¢†åŸŸå¤–æ³›åŒ–å’Œå¤šæ¨¡æ€å¹»è§‰çš„ç¼“è§£æ–¹é¢æ˜¾è‘—æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³é•¿è§†é¢‘éŸ³é¢‘æ¨ç†ä¸ç»†ç²’åº¦åƒç´ ç†è§£ä¹‹é—´çš„çŸ›ç›¾ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†ä½åˆ†è¾¨ç‡å’Œé«˜åˆ†è¾¨ç‡è¾“å…¥æ—¶å­˜åœ¨å±€é™æ€§ï¼Œéš¾ä»¥åŒæ—¶æ»¡è¶³ä¸¤è€…çš„éœ€æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„Omni-R1é‡‡ç”¨åŒç³»ç»Ÿæ¶æ„ï¼Œå…¨çƒæ¨ç†ç³»ç»Ÿè´Ÿè´£é€‰æ‹©å…³é”®å¸§å¹¶é‡å†™ä»»åŠ¡ï¼Œè€Œç»†èŠ‚ç†è§£ç³»ç»Ÿåˆ™åœ¨é«˜åˆ†è¾¨ç‡ç‰‡æ®µä¸Šè¿›è¡Œåƒç´ çº§å®šä½ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–å…³é”®å¸§é€‰æ‹©å’Œä»»åŠ¡é‡å†™ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šOmni-R1çš„æ•´ä½“æ¶æ„åˆ†ä¸ºä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šå…¨çƒæ¨ç†ç³»ç»Ÿå’Œç»†èŠ‚ç†è§£ç³»ç»Ÿã€‚å…¨çƒæ¨ç†ç³»ç»Ÿé€šè¿‡ä½ç©ºé—´æˆæœ¬é€‰æ‹©å…³é”®å¸§ï¼Œç»†èŠ‚ç†è§£ç³»ç»Ÿåˆ™åœ¨è¿™äº›å…³é”®å¸§ä¸Šè¿›è¡Œé«˜ç²¾åº¦çš„åƒç´ çº§åˆ†æã€‚

**å…³é”®åˆ›æ–°**ï¼šOmni-R1é¦–æ¬¡å°†å¼ºåŒ–å­¦ä¹ åº”ç”¨äºå¤§è§„æ¨¡å…¨æ¨¡æ€æ¨ç†ï¼Œåˆ©ç”¨åœ¨çº¿åä½œçš„å±‚æ¬¡å¥–åŠ±è®­ç»ƒå…¨çƒæ¨ç†ç³»ç»Ÿï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼ŒOmni-R1é‡‡ç”¨äº†ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–æ–¹æ³•ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸Šç»“åˆäº†å±‚æ¬¡å¥–åŠ±æœºåˆ¶ï¼Œç¡®ä¿äº†åœ¨å°ä»»åŠ¡åˆ†å‰²ä¸Šä»…éœ€ä¸€è½®å¼ºåŒ–å­¦ä¹ å³å¯å®Œæˆè®­ç»ƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨RefAVSå’ŒREVOSä¸¤ä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒOmni-R1ä¸ä»…è¶…è¶Šäº†å¼ºå¤§çš„ç›‘ç£åŸºçº¿ï¼Œè¿˜åœ¨å¤šä¸ªä¸“é—¨æ¨¡å‹ä¸Šå–å¾—äº†æ›´å¥½çš„æ€§èƒ½ï¼Œæ˜¾è‘—æå‡äº†é¢†åŸŸå¤–çš„æ³›åŒ–èƒ½åŠ›ï¼Œå‡å°‘äº†å¤šæ¨¡æ€å¹»è§‰ç°è±¡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è§†é¢‘ç›‘æ§ã€è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½å®¶å±…ç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡ç³»ç»Ÿåœ¨å¤æ‚ç¯å¢ƒä¸‹çš„ç†è§£å’Œå†³ç­–èƒ½åŠ›ã€‚æœªæ¥ï¼ŒOmni-R1æœ‰æœ›ä¸ºå¤šæ¨¡æ€åŸºç¡€æ¨¡å‹çš„å‘å±•æä¾›æ–°çš„æ€è·¯ï¼Œæ¨åŠ¨æ›´å¹¿æ³›çš„åº”ç”¨è½åœ°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Long-horizon video-audio reasoning and fine-grained pixel understanding impose conflicting requirements on omnimodal models: dense temporal coverage demands many low-resolution frames, whereas precise grounding calls for high-resolution inputs. We tackle this trade-off with a two-system architecture: a Global Reasoning System selects informative keyframes and rewrites the task at low spatial cost, while a Detail Understanding System performs pixel-level grounding on the selected high-resolution snippets. Because ``optimal'' keyframe selection and reformulation are ambiguous and hard to supervise, we formulate them as a reinforcement learning (RL) problem and present Omni-R1, an end-to-end RL framework built on Group Relative Policy Optimization. Omni-R1 trains the Global Reasoning System through hierarchical rewards obtained via online collaboration with the Detail Understanding System, requiring only one epoch of RL on small task splits.
>   Experiments on two challenging benchmarks, namely Referring Audio-Visual Segmentation (RefAVS) and Reasoning Video Object Segmentation (REVOS), show that Omni-R1 not only surpasses strong supervised baselines but also outperforms specialized state-of-the-art models, while substantially improving out-of-domain generalization and mitigating multimodal hallucination. Our results demonstrate the first successful application of RL to large-scale omnimodal reasoning and highlight a scalable path toward universally foundation models.

