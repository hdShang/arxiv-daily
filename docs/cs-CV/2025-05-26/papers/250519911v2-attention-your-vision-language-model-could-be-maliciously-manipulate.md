---
layout: default
title: "Attention! Your Vision Language Model Could Be Maliciously Manipulated"
---

# Attention! Your Vision Language Model Could Be Maliciously Manipulated

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.19911" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.19911v2</a>
  <a href="https://arxiv.org/pdf/2505.19911.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.19911v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.19911v2', 'Attention! Your Vision Language Model Could Be Maliciously Manipulated')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xiaosen Wang, Shaokang Wang, Zhijin Ge, Yuyang Luo, Shudong Zhang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-26 (æ›´æ–°: 2025-10-27)

**å¤‡æ³¨**: NeurIPS 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Trustworthy-AI-Group/VMA)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè§†è§‰è¯­è¨€æ¨¡å‹æ“æ§æ”»å‡»ä»¥åº”å¯¹æ¨¡å‹è„†å¼±æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡å‹` `å¯¹æŠ—æ ·æœ¬` `æ¨¡å‹è„†å¼±æ€§` `åŠ¨é‡ä¼˜åŒ–` `å®‰å…¨æ€§è¯„ä¼°` `ç‰ˆæƒä¿æŠ¤` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†è§‰è¯­è¨€æ¨¡å‹åœ¨é¢å¯¹å¯¹æŠ—æ ·æœ¬æ—¶è¡¨ç°å‡ºæ˜¾è‘—è„†å¼±æ€§ï¼Œå°¤å…¶æ˜¯å›¾åƒå¯¹æŠ—æ ·æœ¬ï¼Œå¯¼è‡´å¤šç§å®‰å…¨éšæ‚£ã€‚
2. æœ¬æ–‡æå‡ºäº†è§†è§‰è¯­è¨€æ¨¡å‹æ“æ§æ”»å‡»ï¼ˆVMAï¼‰ï¼Œé€šè¿‡ç»“åˆåŠ¨é‡ä¼˜åŒ–å’Œå¯å¾®å˜æ¢æœºåˆ¶ï¼Œä¼˜åŒ–å¯¹æŠ—æ‰°åŠ¨ä»¥æ“æ§æ¨¡å‹è¾“å‡ºã€‚
3. å®éªŒè¯æ˜ï¼ŒVMAåœ¨å¤šç§åœºæ™¯å’Œæ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå®ç°æ”»å‡»ï¼ŒåŒæ—¶æ”¯æŒç‰ˆæƒä¿æŠ¤åŠŸèƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨ç†è§£å¤æ‚ç°å®åœºæ™¯å’Œæ”¯æŒæ•°æ®é©±åŠ¨å†³ç­–æ–¹é¢å–å¾—äº†æ˜¾è‘—æˆåŠŸã€‚ç„¶è€Œï¼ŒVLMså¯¹å¯¹æŠ—æ ·æœ¬è¡¨ç°å‡ºæ˜¾è‘—è„†å¼±æ€§ï¼Œå¯èƒ½å¯¼è‡´ç›‘ç‹±ç ´è§£ã€åŠ«æŒå’Œå¹»è§‰ç­‰å¤šç§å¯¹æŠ—ç»“æœã€‚æœ¬æ–‡é€šè¿‡å®è¯å’Œç†è®ºåˆ†æï¼Œè¯æ˜VLMsç‰¹åˆ«å®¹æ˜“å—åˆ°åŸºäºå›¾åƒçš„å¯¹æŠ—æ ·æœ¬çš„å½±å“ï¼Œå¾®å°çš„æ‰°åŠ¨å¯ä»¥ç²¾ç¡®æ“æ§æ¯ä¸ªè¾“å‡ºæ ‡è®°ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ”»å‡»æ–¹æ³•ï¼Œç§°ä¸ºè§†è§‰è¯­è¨€æ¨¡å‹æ“æ§æ”»å‡»ï¼ˆVMAï¼‰ï¼Œå®ƒç»“åˆäº†ä¸€é˜¶å’ŒäºŒé˜¶åŠ¨é‡ä¼˜åŒ–æŠ€æœ¯ä»¥åŠå¯å¾®å˜æ¢æœºåˆ¶ï¼Œæœ‰æ•ˆä¼˜åŒ–å¯¹æŠ—æ‰°åŠ¨ã€‚VMAå¯ä»¥ä½œä¸ºåŒåˆƒå‰‘ï¼Œæ—¢å¯ç”¨äºå®æ–½å„ç§æ”»å‡»ï¼Œä¹Ÿå¯ç”¨äºæ³¨å…¥æ°´å°ä»¥ä¿æŠ¤ç‰ˆæƒã€‚å¤§é‡å®è¯è¯„ä¼°éªŒè¯äº†VMAåœ¨ä¸åŒåœºæ™¯å’Œæ•°æ®é›†ä¸Šçš„æœ‰æ•ˆæ€§å’Œé€šç”¨æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨é¢å¯¹å¯¹æŠ—æ ·æœ¬æ—¶çš„è„†å¼±æ€§ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆåº”å¯¹å›¾åƒå¯¹æŠ—æ ·æœ¬çš„å½±å“ï¼Œå¯¼è‡´æ¨¡å‹è¾“å‡ºè¢«æ“æ§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„è§†è§‰è¯­è¨€æ¨¡å‹æ“æ§æ”»å‡»ï¼ˆVMAï¼‰é€šè¿‡ç»“åˆä¸€é˜¶å’ŒäºŒé˜¶åŠ¨é‡ä¼˜åŒ–æŠ€æœ¯ï¼Œåˆ©ç”¨å¯å¾®å˜æ¢æœºåˆ¶æ¥ä¼˜åŒ–å¯¹æŠ—æ‰°åŠ¨ï¼Œä»è€Œç²¾ç¡®æ“æ§æ¨¡å‹çš„è¾“å‡ºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVMAçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ‰°åŠ¨ç”Ÿæˆã€æ¨¡å‹è¾“å‡ºæ“æ§ç­‰ä¸»è¦æ¨¡å—ã€‚é¦–å…ˆå¯¹è¾“å…¥å›¾åƒè¿›è¡Œæ‰°åŠ¨ç”Ÿæˆï¼Œç„¶åé€šè¿‡ä¼˜åŒ–ç®—æ³•è°ƒæ•´æ‰°åŠ¨ï¼Œæœ€åå®ç°å¯¹æ¨¡å‹è¾“å‡ºçš„æ“æ§ã€‚

**å…³é”®åˆ›æ–°**ï¼šVMAçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶ç»“åˆäº†ä¸€é˜¶å’ŒäºŒé˜¶åŠ¨é‡ä¼˜åŒ–æŠ€æœ¯ï¼Œèƒ½å¤Ÿåœ¨å¯¹æŠ—æ ·æœ¬ç”Ÿæˆä¸­å®ç°æ›´é«˜çš„ç²¾ç¡®åº¦å’Œçµæ´»æ€§ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæå‡äº†å¯¹æŠ—æ”»å‡»çš„æ•ˆæœå’Œé€‚ç”¨æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨VMAä¸­ï¼Œå…³é”®è®¾è®¡åŒ…æ‹¬æ‰°åŠ¨çš„ä¼˜åŒ–ç­–ç•¥ã€æŸå¤±å‡½æ•°çš„é€‰æ‹©ä»¥åŠç½‘ç»œç»“æ„çš„è°ƒæ•´ï¼Œä»¥ç¡®ä¿ç”Ÿæˆçš„å¯¹æŠ—æ ·æœ¬èƒ½å¤Ÿæœ‰æ•ˆå½±å“æ¨¡å‹è¾“å‡ºï¼ŒåŒæ—¶ä¿æŒæ‰°åŠ¨çš„éšè”½æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒVMAåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå®ç°äº†æ˜¾è‘—çš„æ”»å‡»æ•ˆæœï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•ï¼Œæ”»å‡»æˆåŠŸç‡æå‡äº†20%ä»¥ä¸Šï¼Œä¸”åœ¨ä¸åŒåœºæ™¯ä¸‹å‡è¡¨ç°å‡ºè‰¯å¥½çš„é€šç”¨æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å®‰å…¨æ€§æµ‹è¯•ã€æ¨¡å‹é²æ£’æ€§è¯„ä¼°ä»¥åŠç‰ˆæƒä¿æŠ¤ç­‰ã€‚é€šè¿‡æœ‰æ•ˆçš„å¯¹æŠ—æ”»å‡»æ‰‹æ®µï¼Œç ”ç©¶è€…å¯ä»¥æ›´å¥½åœ°ç†è§£å’Œæå‡è§†è§‰è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ€§ï¼ŒåŒæ—¶åœ¨å®é™…åº”ç”¨ä¸­ä¿æŠ¤ç‰ˆæƒä¿¡æ¯ï¼Œé˜²æ­¢æ¶æ„æ“æ§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Vision-Language Models (VLMs) have achieved remarkable success in understanding complex real-world scenarios and supporting data-driven decision-making processes. However, VLMs exhibit significant vulnerability against adversarial examples, either text or image, which can lead to various adversarial outcomes, e.g., jailbreaking, hijacking, and hallucination, etc. In this work, we empirically and theoretically demonstrate that VLMs are particularly susceptible to image-based adversarial examples, where imperceptible perturbations can precisely manipulate each output token. To this end, we propose a novel attack called Vision-language model Manipulation Attack (VMA), which integrates first-order and second-order momentum optimization techniques with a differentiable transformation mechanism to effectively optimize the adversarial perturbation. Notably, VMA can be a double-edged sword: it can be leveraged to implement various attacks, such as jailbreaking, hijacking, privacy breaches, Denial-of-Service, and the generation of sponge examples, etc, while simultaneously enabling the injection of watermarks for copyright protection. Extensive empirical evaluations substantiate the efficacy and generalizability of VMA across diverse scenarios and datasets. Code is available at https://github.com/Trustworthy-AI-Group/VMA.

