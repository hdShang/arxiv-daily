---
layout: default
title: MMPerspective: Do MLLMs Understand Perspective? A Comprehensive Benchmark for Perspective Perception, Reasoning, and Robustness
---

# MMPerspective: Do MLLMs Understand Perspective? A Comprehensive Benchmark for Perspective Perception, Reasoning, and Robustness

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20426" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.20426v5</a>
  <a href="https://arxiv.org/pdf/2505.20426.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20426v5" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20426v5', 'MMPerspective: Do MLLMs Understand Perspective? A Comprehensive Benchmark for Perspective Perception, Reasoning, and Robustness')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yolo Y. Tang, Pinxin Liu, Zhangyun Tan, Mingqian Feng, Rui Mao, Chao Huang, Jing Bi, Yunzhong Xiao, Susan Liang, Hang Hua, Ali Vosoughi, Luchuan Song, Zeliang Zhang, Chenliang Xu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-26 (æ›´æ–°: 2025-11-25)

**å¤‡æ³¨**: Accepted to NeurIPS 2025 DB Track. Rating: 5,5,5,5

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://yunlong10.github.io/MMPerspective/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMMPerspectiveä»¥è¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„è§†è§’ç†è§£èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `è§†è§’ç†è§£` `ç©ºé—´æ¨ç†` `é²æ£’æ€§è¯„ä¼°` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨ç†è§£è§†è§’å‡ ä½•æ–¹é¢å­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨ç»„åˆæ¨ç†å’Œç©ºé—´ä¸€è‡´æ€§æ–¹é¢ã€‚
2. MMPerspectiveåŸºå‡†é€šè¿‡10ä¸ªä»»åŠ¡ç³»ç»Ÿè¯„ä¼°MLLMsçš„è§†è§’ç†è§£ï¼Œæ¶µç›–æ„ŸçŸ¥ã€æ¨ç†å’Œé²æ£’æ€§ä¸‰ä¸ªç»´åº¦ã€‚
3. å¯¹43ä¸ªMLLMsçš„è¯„ä¼°æ˜¾ç¤ºï¼Œå°½ç®¡åœ¨è¡¨é¢ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨å¤æ‚æ¨ç†å’Œæ‰°åŠ¨ä¸‹çš„è¡¨ç°ä»æœ‰å¾…æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç†è§£è§†è§’æ˜¯äººç±»è§†è§‰æ„ŸçŸ¥çš„åŸºç¡€ï¼Œä½†å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨è§†è§’å‡ ä½•æ–¹é¢çš„ç†è§£ç¨‹åº¦å°šä¸æ˜ç¡®ã€‚æˆ‘ä»¬å¼•å…¥äº†MMPerspectiveï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªä¸“é—¨è®¾è®¡çš„åŸºå‡†ï¼Œç³»ç»Ÿè¯„ä¼°MLLMså¯¹è§†è§’çš„ç†è§£ï¼Œæ¶µç›–10ä¸ªç²¾å¿ƒè®¾è®¡çš„ä»»åŠ¡ï¼Œæ¶‰åŠè§†è§’æ„ŸçŸ¥ã€æ¨ç†å’Œé²æ£’æ€§ä¸‰ä¸ªç»´åº¦ã€‚åŸºå‡†åŒ…å«2,711ä¸ªçœŸå®å’Œåˆæˆå›¾åƒå®ä¾‹åŠ5,083ä¸ªé—®ç­”å¯¹ï¼Œæ¢è®¨äº†æ¶ˆå¤±ç‚¹æ„ŸçŸ¥ã€è§†è§’ç±»å‹æ¨ç†ã€3Dç©ºé—´ä¸­çš„çº¿å…³ç³»ç†è§£ç­‰å…³é”®èƒ½åŠ›ã€‚é€šè¿‡å¯¹43ä¸ªæœ€å…ˆè¿›çš„MLLMsçš„å…¨é¢è¯„ä¼°ï¼Œæˆ‘ä»¬å‘ç°æ¨¡å‹åœ¨è¡¨é¢æ„ŸçŸ¥ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨ç»„åˆæ¨ç†å’Œæ‰°åŠ¨ä¸‹ä¿æŒç©ºé—´ä¸€è‡´æ€§æ–¹é¢å­˜åœ¨æ˜¾è‘—å±€é™æ€§ã€‚æˆ‘ä»¬çš„åˆ†ææ­ç¤ºäº†æ¨¡å‹æ¶æ„ã€è§„æ¨¡ä¸è§†è§’èƒ½åŠ›ä¹‹é—´çš„æœ‰è¶£æ¨¡å¼ï¼Œçªæ˜¾äº†é²æ£’æ€§ç“¶é¢ˆå’Œé“¾å¼æ€ç»´æç¤ºçš„ä¼˜åŠ¿ã€‚MMPerspectiveä¸ºè¯Šæ–­å’Œæ¨åŠ¨è§†è§‰-è¯­è¨€ç³»ç»Ÿçš„ç©ºé—´ç†è§£æä¾›äº†å®è´µçš„æµ‹è¯•å¹³å°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨è§†è§’ç†è§£æ–¹é¢çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯å®ƒä»¬åœ¨ç»„åˆæ¨ç†å’Œç©ºé—´ä¸€è‡´æ€§æ–¹é¢çš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½ç³»ç»Ÿè¯„ä¼°è¿™äº›æ¨¡å‹çš„è§†è§’èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥MMPerspectiveåŸºå‡†ï¼Œè®ºæ–‡è®¾è®¡äº†10ä¸ªä»»åŠ¡ï¼Œæ¶µç›–è§†è§’æ„ŸçŸ¥ã€æ¨ç†å’Œé²æ£’æ€§ï¼Œä»¥å…¨é¢è¯„ä¼°MLLMsçš„è§†è§’ç†è§£èƒ½åŠ›ã€‚è¿™æ ·çš„è®¾è®¡èƒ½å¤Ÿæ›´å¥½åœ°æ­ç¤ºæ¨¡å‹çš„æ½œåœ¨å±€é™æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMMPerspectiveåŸºå‡†åŒ…æ‹¬2,711ä¸ªå›¾åƒå®ä¾‹å’Œ5,083ä¸ªé—®ç­”å¯¹ï¼Œä»»åŠ¡åˆ†ä¸ºä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šè§†è§’æ„ŸçŸ¥ã€æ¨ç†å’Œé²æ£’æ€§è¯„ä¼°ã€‚æ¯ä¸ªæ¨¡å—é’ˆå¯¹ç‰¹å®šèƒ½åŠ›è¿›è¡Œè®¾è®¡ï¼Œä»¥ç¡®ä¿å…¨é¢æ€§å’Œç³»ç»Ÿæ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šMMPerspectiveæ˜¯ç¬¬ä¸€ä¸ªä¸“é—¨é’ˆå¯¹MLLMsè§†è§’ç†è§£çš„åŸºå‡†ï¼Œæä¾›äº†ç³»ç»Ÿçš„è¯„ä¼°æ¡†æ¶ï¼Œæ­ç¤ºäº†æ¨¡å‹åœ¨ä¸åŒä»»åŠ¡ä¸Šçš„è¡¨ç°å·®å¼‚ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚æ¨ç†æ–¹é¢çš„å±€é™æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œä»»åŠ¡åŒ…æ‹¬æ¶ˆå¤±ç‚¹æ„ŸçŸ¥ã€è§†è§’ç±»å‹æ¨ç†å’Œ3Dç©ºé—´çº¿å…³ç³»ç†è§£ç­‰ï¼Œé‡‡ç”¨äº†å¤šæ ·åŒ–çš„å›¾åƒå®ä¾‹å’Œé—®ç­”å¯¹ï¼Œä»¥ç¡®ä¿è¯„ä¼°çš„å…¨é¢æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œ43ä¸ªMLLMsåœ¨è¡¨é¢æ„ŸçŸ¥ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨ç»„åˆæ¨ç†å’Œæ‰°åŠ¨ä¸‹çš„ç©ºé—´ä¸€è‡´æ€§æ–¹é¢å­˜åœ¨æ˜¾è‘—ä¸è¶³ã€‚å…·ä½“è€Œè¨€ï¼Œæ¨¡å‹åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„è¡¨ç°æå‡å¹…åº¦æœ‰é™ï¼Œæ­ç¤ºäº†é²æ£’æ€§ç“¶é¢ˆå’Œé“¾å¼æ€ç»´æç¤ºçš„æ½œåœ¨ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è®¡ç®—æœºè§†è§‰ã€æœºå™¨äººå¯¼èˆªå’Œå¢å¼ºç°å®ç­‰ã€‚é€šè¿‡æå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„è§†è§’ç†è§£èƒ½åŠ›ï¼Œå¯ä»¥å¢å¼ºè¿™äº›ç³»ç»Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­çš„è¡¨ç°ï¼Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿçš„å®é™…åº”ç”¨å’Œå‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Understanding perspective is fundamental to human visual perception, yet the extent to which multimodal large language models (MLLMs) internalize perspective geometry remains unclear. We introduce MMPerspective, the first benchmark specifically designed to systematically evaluate MLLMs' understanding of perspective through 10 carefully crafted tasks across three complementary dimensions: Perspective Perception, Reasoning, and Robustness. Our benchmark comprises 2,711 real-world and synthetic image instances with 5,083 question-answer pairs that probe key capabilities, such as vanishing point perception and counting, perspective type reasoning, line relationship understanding in 3D space, invariance to perspective-preserving transformations, etc. Through a comprehensive evaluation of 43 state-of-the-art MLLMs, we uncover significant limitations: while models demonstrate competence on surface-level perceptual tasks, they struggle with compositional reasoning and maintaining spatial consistency under perturbations. Our analysis further reveals intriguing patterns between model architecture, scale, and perspective capabilities, highlighting both robustness bottlenecks and the benefits of chain-of-thought prompting. MMPerspective establishes a valuable testbed for diagnosing and advancing spatial understanding in vision-language systems. Resources available at: https://yunlong10.github.io/MMPerspective/

