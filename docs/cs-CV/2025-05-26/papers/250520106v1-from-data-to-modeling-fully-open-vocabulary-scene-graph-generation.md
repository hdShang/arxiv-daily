---
layout: default
title: "From Data to Modeling: Fully Open-vocabulary Scene Graph Generation"
---

# From Data to Modeling: Fully Open-vocabulary Scene Graph Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20106" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.20106v1</a>
  <a href="https://arxiv.org/pdf/2505.20106.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20106v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20106v1', 'From Data to Modeling: Fully Open-vocabulary Scene Graph Generation')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Zuyao Chen, Jinlin Wu, Zhen Lei, Chang Wen Chen

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-26

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫OvSGTR‰ª•Ëß£ÂÜ≥‰º†ÁªüÂú∫ÊôØÂõæÁîüÊàêÁöÑÂºÄÊîæËØçÊ±áÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÂºÄÊîæËØçÊ±á` `Âú∫ÊôØÂõæÁîüÊàê` `ÂèòÊç¢Âô®Êû∂ÊûÑ` `Âº±ÁõëÁù£Â≠¶‰π†` `ÂÖ≥Á≥ªÊÑüÁü•È¢ÑËÆ≠ÁªÉ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÂú∫ÊôØÂõæÁîüÊàêÊñπÊ≥ïÈÄöÂ∏∏ÈôêÂà∂Âú®Âõ∫ÂÆöÁöÑËØçÊ±áÂÜÖÔºåÊó†Ê≥ïÈÄÇÂ∫îÊñ∞ÂÖ¥Ê¶ÇÂøµÔºåÂΩ±ÂìçÂÆûÈôÖÂ∫îÁî®„ÄÇ
2. OvSGTRÈÄöËøáËÅîÂêàÈ¢ÑÊµãÂØπË±°ÂíåÂÖ≥Á≥ªÔºåÈááÁî®DETR-likeÊû∂ÊûÑÂíåÂÖ≥Á≥ªÊÑüÁü•È¢ÑËÆ≠ÁªÉÁ≠ñÁï•ÔºåÁ™ÅÁ†¥‰∫Ü‰º†ÁªüÊ®°ÂûãÁöÑÈôêÂà∂„ÄÇ
3. Âú®VG150Âü∫ÂáÜ‰∏äÔºåOvSGTRÂú®Èó≠ÈõÜÂíåÂºÄÊîæËØçÊ±áÂú∫ÊôØ‰∏ãÂùáË°®Áé∞Âá∫Ëâ≤ÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®ËßÜËßâÁêÜËß£‰∏≠ÁöÑÊΩúÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êàë‰ª¨ÊèêÂá∫‰∫ÜOvSGTRÔºåËøôÊòØ‰∏ÄÁßçÊñ∞È¢ñÁöÑÂü∫‰∫éÂèòÊç¢Âô®ÁöÑÊ°ÜÊû∂ÔºåÁî®‰∫éÂÆåÂÖ®ÂºÄÊîæËØçÊ±áÁöÑÂú∫ÊôØÂõæÁîüÊàêÔºåÂÖãÊúç‰∫Ü‰º†ÁªüÈó≠ÈõÜÊ®°ÂûãÁöÑÂ±ÄÈôêÊÄß„ÄÇ‰º†ÁªüÊñπÊ≥ïÂ∞ÜÂØπË±°ÂíåÂÖ≥Á≥ªËØÜÂà´ÈôêÂà∂Âú®Âõ∫ÂÆöËØçÊ±áÂÜÖÔºåÈôêÂà∂‰∫ÜÂÖ∂Âú®Êñ∞Ê¶ÇÂøµÈ¢ëÁπÅÂá∫Áé∞ÁöÑÁé∞ÂÆûÂú∫ÊôØ‰∏≠ÁöÑÈÄÇÁî®ÊÄß„ÄÇÊàë‰ª¨ÁöÑÊñπÊ°àË∂ÖË∂ä‰∫ÜÈ¢ÑÂÆö‰πâÁ±ªÂà´ÔºåËÅîÂêàÈ¢ÑÊµãÂØπË±°ÔºàËäÇÁÇπÔºâÂèäÂÖ∂Áõ∏‰∫íÂÖ≥Á≥ªÔºàËæπÔºâ„ÄÇOvSGTRÂà©Áî®Á±ª‰ººDETRÁöÑÊû∂ÊûÑÔºåÁªìÂêàÂÜªÁªìÁöÑÂõæÂÉè‰∏ªÂπ≤ÂíåÊñáÊú¨ÁºñÁ†ÅÂô®ÊèêÂèñÈ´òË¥®ÈáèÁöÑËßÜËßâÂíåËØ≠‰πâÁâπÂæÅÔºåÂπ∂ÈÄöËøáÂèòÊç¢Âô®Ëß£Á†ÅÂô®ËøõË°åÁ´ØÂà∞Á´ØÁöÑÂú∫ÊôØÂõæÈ¢ÑÊµã„ÄÇ‰∏∫Â¢ûÂº∫Ê®°ÂûãÂØπÂ§çÊùÇËßÜËßâÂÖ≥Á≥ªÁöÑÁêÜËß£ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÂÖ≥Á≥ªÊÑüÁü•ÁöÑÈ¢ÑËÆ≠ÁªÉÁ≠ñÁï•ÔºåÈááÁî®Âº±ÁõëÁù£ÊñπÂºèÂêàÊàêÂú∫ÊôØÂõæÊ≥®Èáä„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåOvSGTRÂú®VG150Âü∫ÂáÜ‰∏äÂÆûÁé∞‰∫ÜÂ§öÁßçËÆæÁΩÆ‰∏ãÁöÑÊúÄÂÖàËøõÊÄßËÉΩ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥‰º†ÁªüÂú∫ÊôØÂõæÁîüÊàêÊ®°ÂûãÂú®ÂºÄÊîæËØçÊ±áÂú∫ÊôØ‰∏≠ÁöÑÂ±ÄÈôêÊÄßÔºåÁé∞ÊúâÊñπÊ≥ïÊó†Ê≥ïÂ§ÑÁêÜÊñ∞Âá∫Áé∞ÁöÑÂØπË±°ÂíåÂÖ≥Á≥ªÔºåÈôêÂà∂‰∫ÜÂÖ∂Â∫îÁî®ËåÉÂõ¥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöOvSGTRÈÄöËøáËÅîÂêàÈ¢ÑÊµãÂØπË±°ÂíåÂÖ≥Á≥ªÔºåÈááÁî®ÂèòÊç¢Âô®Êû∂ÊûÑÔºåÁªìÂêàÂº±ÁõëÁù£ÁöÑÂÖ≥Á≥ªÊÑüÁü•È¢ÑËÆ≠ÁªÉÁ≠ñÁï•ÔºåÂ¢ûÂº∫Ê®°ÂûãÂØπÂ§çÊùÇËßÜËßâÂÖ≥Á≥ªÁöÑÁêÜËß£„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöOvSGTRÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏Ä‰∏™ÂÜªÁªìÁöÑÂõæÂÉè‰∏ªÂπ≤ÂíåÊñáÊú¨ÁºñÁ†ÅÂô®ÔºåÁî®‰∫éÊèêÂèñËßÜËßâÂíåËØ≠‰πâÁâπÂæÅÔºåÈöèÂêéÈÄöËøáÂèòÊç¢Âô®Ëß£Á†ÅÂô®ËøõË°åÂú∫ÊôØÂõæÁöÑÁ´ØÂà∞Á´ØÈ¢ÑÊµã„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊú¨Á†îÁ©∂ÁöÑÊ†∏ÂøÉÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫ÜÂºÄÊîæËØçÊ±áÁöÑÂú∫ÊôØÂõæÁîüÊàêÊñπÊ≥ïÔºåÁªìÂêà‰∫ÜÂÖ≥Á≥ªÊÑüÁü•ÁöÑÈ¢ÑËÆ≠ÁªÉÁ≠ñÁï•ÂíåËßÜËßâÊ¶ÇÂøµ‰øùÁïôÊú∫Âà∂ÔºåÊòæËëóÊèêÂçá‰∫ÜÊ®°ÂûãÂú®Êñ∞Ê¶ÇÂøµÂú∫ÊôØ‰∏ãÁöÑË°®Áé∞„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÊ®°ÂûãÈááÁî®‰∫ÜDETR-likeÊû∂ÊûÑÔºåÁªìÂêà‰∫ÜÂ§öÁßçÁîüÊàêÁõëÁù£‰ø°Âè∑ÁöÑÁÆ°ÈÅìÔºåÁ°Æ‰øùÂú®ÂæÆË∞ÉËøáÁ®ã‰∏≠‰øùÁïô‰∏∞ÂØåÁöÑËØ≠‰πâÁ∫øÁ¥¢ÔºåÂêåÊó∂ÂºïÂÖ•Áü•ËØÜËí∏È¶èÁ≠ñÁï•‰ª•Â∫îÂØπÁÅæÈöæÊÄßÈÅóÂøòÈóÆÈ¢ò„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®VG150Âü∫ÂáÜÊµãËØï‰∏≠ÔºåOvSGTRÂú®Â§ö‰∏™ËÆæÁΩÆ‰∏ãÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÂåÖÊã¨Èó≠ÈõÜÂíåÂºÄÊîæËØçÊ±áÂØπË±°Ê£ÄÊµã„ÄÅÂÖ≥Á≥ªÂü∫Á°ÄÂíåÂÆåÂÖ®ÂºÄÊîæËØçÊ±áÂú∫ÊôØÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®Â§çÊùÇËßÜËßâÁêÜËß£‰∏≠ÁöÑÊúâÊïàÊÄßÂíåÂèØÈù†ÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Êô∫ËÉΩÁõëÊéß„ÄÅËá™Âä®È©æÈ©∂„ÄÅËôöÊãüÁé∞ÂÆûÁ≠âÔºåËÉΩÂ§üÊèêÂçáËÆ°ÁÆóÊú∫ËßÜËßâÁ≥ªÁªüÂØπÂ§çÊùÇÂú∫ÊôØÁöÑÁêÜËß£ËÉΩÂäõÔºåÊé®Âä®Áõ∏ÂÖ≥ÊäÄÊúØÁöÑÂÆûÈôÖÂ∫îÁî®ÂíåÂèëÂ±ï„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïÂèØËÉΩÂú®Êõ¥ÂπøÊ≥õÁöÑËßÜËßâÁêÜËß£‰ªªÂä°‰∏≠ÂèëÊå•ÈáçË¶Å‰ΩúÁî®Ôºå‰øÉËøõÂºÄÊîæËØçÊ±áÁöÑÊô∫ËÉΩÁ≥ªÁªüÊûÑÂª∫„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> We present OvSGTR, a novel transformer-based framework for fully open-vocabulary scene graph generation that overcomes the limitations of traditional closed-set models. Conventional methods restrict both object and relationship recognition to a fixed vocabulary, hindering their applicability to real-world scenarios where novel concepts frequently emerge. In contrast, our approach jointly predicts objects (nodes) and their inter-relationships (edges) beyond predefined categories. OvSGTR leverages a DETR-like architecture featuring a frozen image backbone and text encoder to extract high-quality visual and semantic features, which are then fused via a transformer decoder for end-to-end scene graph prediction. To enrich the model's understanding of complex visual relations, we propose a relation-aware pre-training strategy that synthesizes scene graph annotations in a weakly supervised manner. Specifically, we investigate three pipelines--scene parser-based, LLM-based, and multimodal LLM-based--to generate transferable supervision signals with minimal manual annotation. Furthermore, we address the common issue of catastrophic forgetting in open-vocabulary settings by incorporating a visual-concept retention mechanism coupled with a knowledge distillation strategy, ensuring that the model retains rich semantic cues during fine-tuning. Extensive experiments on the VG150 benchmark demonstrate that OvSGTR achieves state-of-the-art performance across multiple settings, including closed-set, open-vocabulary object detection-based, relation-based, and fully open-vocabulary scenarios. Our results highlight the promise of large-scale relation-aware pre-training and transformer architectures for advancing scene graph generation towards more generalized and reliable visual understanding.

