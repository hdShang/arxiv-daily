---
layout: default
title: "VisualToolAgent (VisTA): A Reinforcement Learning Framework for Visual Tool Selection"
---

# VisualToolAgent (VisTA): A Reinforcement Learning Framework for Visual Tool Selection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20289" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.20289v2</a>
  <a href="https://arxiv.org/pdf/2505.20289.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20289v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20289v2', 'VisualToolAgent (VisTA): A Reinforcement Learning Framework for Visual Tool Selection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zeyi Huang, Yuyang Ji, Anirudh Sundara Rajan, Zefan Cai, Wen Xiao, Haohan Wang, Junjie Hu, Yong Jae Lee

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-26 (æ›´æ–°: 2025-07-19)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVisTAæ¡†æ¶ä»¥è§£å†³å·¥å…·é€‰æ‹©çš„åŠ¨æ€æ¢ç´¢é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `å·¥å…·é€‰æ‹©` `è§†è§‰æ¨ç†` `åŠ¨æ€æ¢ç´¢` `ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–` `å¤šæ ·æ€§åˆ©ç”¨` `è‡ªåŠ¨åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å·¥å…·å¢å¼ºæ¨ç†æ–¹æ³•ä¾èµ–æ— è®­ç»ƒæç¤ºæˆ–å¤§è§„æ¨¡å¾®è°ƒï¼Œç¼ºä¹ä¸»åŠ¨å·¥å…·æ¢ç´¢ï¼Œä¸”å‡è®¾å·¥å…·å¤šæ ·æ€§æœ‰é™ã€‚
2. VisTAæ¡†æ¶é€šè¿‡ç«¯åˆ°ç«¯å¼ºåŒ–å­¦ä¹ ï¼Œè¿­ä»£ä¼˜åŒ–å·¥å…·é€‰æ‹©ç­–ç•¥ï¼Œä»¥ä»»åŠ¡ç»“æœä½œä¸ºåé¦ˆä¿¡å·ï¼Œæ”¯æŒåŠ¨æ€å·¥å…·ç»„åˆã€‚
3. åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒVisTAç›¸è¾ƒäºæ— è®­ç»ƒåŸºçº¿è¡¨ç°å‡ºæ˜¾è‘—æ€§èƒ½æå‡ï¼Œå°¤å…¶åœ¨å¤„ç†åˆ†å¸ƒå¤–ç¤ºä¾‹æ—¶æ•ˆæœæ˜¾è‘—ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬ä»‹ç»äº†VisTAï¼Œä¸€ä¸ªæ–°çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œèµ‹èƒ½è§†è§‰ä»£ç†åŠ¨æ€æ¢ç´¢ã€é€‰æ‹©å’Œç»„åˆæ¥è‡ªå¤šæ ·åŒ–åº“çš„å·¥å…·ï¼ŒåŸºäºç»éªŒæ€§èƒ½è¿›è¡Œä¼˜åŒ–ã€‚ç°æœ‰çš„å·¥å…·å¢å¼ºæ¨ç†æ–¹æ³•é€šå¸¸ä¾èµ–äºæ— è®­ç»ƒçš„æç¤ºæˆ–å¤§è§„æ¨¡å¾®è°ƒï¼Œç¼ºä¹ä¸»åŠ¨çš„å·¥å…·æ¢ç´¢ï¼Œä¸”é€šå¸¸å‡è®¾å·¥å…·å¤šæ ·æ€§æœ‰é™ï¼Œè€Œå¾®è°ƒæ–¹æ³•è¿˜éœ€è¦å¤§é‡çš„äººç±»ç›‘ç£ã€‚ç›¸è¾ƒä¹‹ä¸‹ï¼ŒVisTAåˆ©ç”¨ç«¯åˆ°ç«¯çš„å¼ºåŒ–å­¦ä¹ ï¼Œè¿­ä»£ä¼˜åŒ–å¤æ‚çš„ã€ç‰¹å®šæŸ¥è¯¢çš„å·¥å…·é€‰æ‹©ç­–ç•¥ï¼Œä»¥ä»»åŠ¡ç»“æœä½œä¸ºåé¦ˆä¿¡å·ã€‚é€šè¿‡ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰ï¼Œæˆ‘ä»¬çš„æ¡†æ¶ä½¿ä»£ç†èƒ½å¤Ÿè‡ªä¸»å‘ç°æœ‰æ•ˆçš„å·¥å…·é€‰æ‹©è·¯å¾„ï¼Œè€Œæ— éœ€æ˜¾å¼çš„æ¨ç†ç›‘ç£ã€‚åœ¨ChartQAã€Geometry3Kå’ŒBlindTeståŸºå‡†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒVisTAåœ¨æ— è®­ç»ƒåŸºçº¿ä¹‹ä¸Šå®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå°¤å…¶æ˜¯åœ¨åˆ†å¸ƒå¤–ç¤ºä¾‹ä¸Šã€‚è¿™äº›ç»“æœçªæ˜¾äº†VisTAå¢å¼ºæ³›åŒ–èƒ½åŠ›ã€é€‚åº”æ€§åˆ©ç”¨å¤šæ ·åŒ–å·¥å…·çš„èƒ½åŠ›ï¼Œå¹¶ä¸ºçµæ´»çš„ã€ç»éªŒé©±åŠ¨çš„è§†è§‰æ¨ç†ç³»ç»Ÿé“ºå¹³äº†é“è·¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰å·¥å…·é€‰æ‹©æ–¹æ³•åœ¨åŠ¨æ€æ¢ç´¢å’Œå¤šæ ·æ€§åˆ©ç”¨æ–¹é¢çš„ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–äºå›ºå®šçš„å·¥å…·é›†å’Œå¤§é‡äººå·¥ç›‘ç£ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šVisTAé€šè¿‡å¼ºåŒ–å­¦ä¹ å®ç°å·¥å…·é€‰æ‹©çš„åŠ¨æ€ä¼˜åŒ–ï¼Œåˆ©ç”¨ä»»åŠ¡ç»“æœåé¦ˆä¸æ–­è°ƒæ•´é€‰æ‹©ç­–ç•¥ï¼Œä»è€Œæå‡å·¥å…·çš„ä½¿ç”¨æ•ˆç‡å’Œæ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVisTAçš„æ•´ä½“æ¶æ„åŒ…æ‹¬å·¥å…·åº“çš„åŠ¨æ€æ¢ç´¢ã€ç­–ç•¥ä¼˜åŒ–æ¨¡å—å’Œåé¦ˆæœºåˆ¶ã€‚ä»£ç†é€šè¿‡ä¸æ–­è¯•éªŒå’Œè°ƒæ•´ï¼Œå½¢æˆæœ‰æ•ˆçš„å·¥å…·é€‰æ‹©è·¯å¾„ã€‚

**å…³é”®åˆ›æ–°**ï¼šVisTAçš„ä¸»è¦åˆ›æ–°åœ¨äºå¼•å…¥ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰ï¼Œä½¿ä»£ç†èƒ½å¤Ÿåœ¨æ²¡æœ‰æ˜¾å¼æ¨ç†ç›‘ç£çš„æƒ…å†µä¸‹ï¼Œè‡ªä¸»å‘ç°æœ‰æ•ˆçš„å·¥å…·é€‰æ‹©ç­–ç•¥ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒVisTAé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–å·¥å…·é€‰æ‹©ç­–ç•¥ï¼Œå¹¶é€šè¿‡å¼ºåŒ–å­¦ä¹ ç®—æ³•ä¸æ–­æ›´æ–°ä»£ç†çš„ç­–ç•¥ç½‘ç»œï¼Œä»¥é€‚åº”ä¸åŒä»»åŠ¡çš„éœ€æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒVisTAåœ¨ChartQAã€Geometry3Kå’ŒBlindTeståŸºå‡†ä¸Šç›¸è¾ƒäºæ— è®­ç»ƒåŸºçº¿å®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå°¤å…¶åœ¨å¤„ç†åˆ†å¸ƒå¤–ç¤ºä¾‹æ—¶ï¼Œæ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°XX%ï¼ˆå…·ä½“æ•°æ®æœªçŸ¥ï¼‰ï¼Œå±•ç¤ºäº†å…¶åœ¨å·¥å…·é€‰æ‹©å’Œè§†è§‰æ¨ç†ä¸­çš„å¼ºå¤§èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªåŠ¨åŒ–å·¥å…·é€‰æ‹©ã€æ™ºèƒ½åŠ©æ‰‹å’Œæœºå™¨äººæ“ä½œç­‰ã€‚VisTAèƒ½å¤Ÿåœ¨å¤šå˜çš„ç¯å¢ƒä¸­çµæ´»åº”å¯¹ä¸åŒä»»åŠ¡ï¼Œæé«˜å·¥å…·ä½¿ç”¨çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ï¼Œæœªæ¥å¯èƒ½åœ¨å·¥ä¸šã€åŒ»ç–—å’Œæ•™è‚²ç­‰é¢†åŸŸäº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We introduce VisTA, a new reinforcement learning framework that empowers visual agents to dynamically explore, select, and combine tools from a diverse library based on empirical performance. Existing methods for tool-augmented reasoning either rely on training-free prompting or large-scale fine-tuning; both lack active tool exploration and typically assume limited tool diversity, and fine-tuning methods additionally demand extensive human supervision. In contrast, VisTA leverages end-to-end reinforcement learning to iteratively refine sophisticated, query-specific tool selection strategies, using task outcomes as feedback signals. Through Group Relative Policy Optimization (GRPO), our framework enables an agent to autonomously discover effective tool-selection pathways without requiring explicit reasoning supervision. Experiments on the ChartQA, Geometry3K, and BlindTest benchmarks demonstrate that VisTA achieves substantial performance gains over training-free baselines, especially on out-of-distribution examples. These results highlight VisTA's ability to enhance generalization, adaptively utilize diverse tools, and pave the way for flexible, experience-driven visual reasoning systems.

