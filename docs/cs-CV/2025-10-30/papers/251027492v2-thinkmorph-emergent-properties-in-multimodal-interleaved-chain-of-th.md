---
layout: default
title: ThinkMorph: Emergent Properties in Multimodal Interleaved Chain-of-Thought Reasoning
---

# ThinkMorph: Emergent Properties in Multimodal Interleaved Chain-of-Thought Reasoning

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.27492" target="_blank" class="toolbar-btn">arXiv: 2510.27492v2</a>
    <a href="https://arxiv.org/pdf/2510.27492.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.27492v2" 
            onclick="toggleFavorite(this, '2510.27492v2', 'ThinkMorph: Emergent Properties in Multimodal Interleaved Chain-of-Thought Reasoning')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Jiawei Gu, Yunzhuo Hao, Huichen Will Wang, Linjie Li, Michael Qizhe Shieh, Yejin Choi, Ranjay Krishna, Yu Cheng

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-30 (Êõ¥Êñ∞: 2025-11-04)

**Â§áÊ≥®**: project page: https://thinkmorph.github.io/

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ThinkMorphÔºöÈÄöËøáÂ§öÊ®°ÊÄÅ‰∫§ÈîôCoTÊé®ÁêÜÊ∂åÁé∞ËßÜËßâÊìç‰ΩúËÉΩÂäõ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅÊé®ÁêÜ` `ÊÄùÁª¥Èìæ` `ËßÜËßâÊìç‰Ωú` `‰∫§ÈîôÊé®ÁêÜ` `ËßÜËßâËØ≠Ë®ÄÊ®°Âûã`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Â§öÊ®°ÊÄÅÊé®ÁêÜÈúÄË¶ÅËØ≠Ë®ÄÂíåËßÜËßâÁöÑÂçèÂêåÔºå‰ΩÜÁé∞ÊúâÊñπÊ≥ïÈöæ‰ª•ÊúâÊïàÂà©Áî®‰∏§ÁßçÊ®°ÊÄÅÁöÑ‰∫íË°•ÊÄß„ÄÇ
2. ThinkMorphÈÄöËøáÁîüÊàê‰∫§ÈîôÁöÑÊñáÊú¨-ÂõæÂÉèÊé®ÁêÜÊ≠•È™§ÔºåÊòæÂºèÂú∞Êìç‰ΩúËßÜËßâÂÜÖÂÆπÔºå‰øÉËøõÊ®°ÊÄÅÈó¥ÁöÑÊúâÊïà‰∫íÂä®„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåThinkMorphÂú®ËßÜËßâ‰ªªÂä°‰∏äÊÄßËÉΩÊòæËëóÊèêÂçáÔºåÂπ∂Â±ïÁé∞Âá∫ËßÜËßâÊìç‰ΩúÁ≠âÊ∂åÁé∞ËÉΩÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§öÊ®°ÊÄÅÊé®ÁêÜÈúÄË¶ÅÂú®ËØ≠Ë®ÄÂíåËßÜËßâ‰πãÈó¥ËøõË°åËø≠‰ª£ÂçèË∞ÉÔºå‰ΩÜ‰Ωï‰∏∫ÊúâÊÑè‰πâÁöÑ‰∫§ÈîôÂºèÊÄùÁª¥ÈìæÂ∞ö‰∏çÊòéÁ°Æ„ÄÇÊàë‰ª¨ËÆ§‰∏∫ÔºåÊñáÊú¨ÂíåÂõæÂÉèÂ∫î‰Ωú‰∏∫‰∫íË°•ËÄåÈùûÂêåÊûÑÁöÑÊ®°ÊÄÅÔºå‰ª•Áõ∏‰∫í‰øÉËøõÊé®ÁêÜ„ÄÇÂü∫‰∫éÊ≠§ÔºåÊàë‰ª¨ÊûÑÂª∫‰∫ÜThinkMorphÔºå‰∏Ä‰∏™Âú®Á∫¶24KÈ´òË¥®Èáè‰∫§ÈîôÊé®ÁêÜËΩ®Ëøπ‰∏äÂæÆË∞ÉÁöÑÁªü‰∏ÄÊ®°ÂûãÔºåÊ∂µÁõñ‰∫Ü‰∏çÂêåËßÜËßâÂèÇ‰∏éÂ∫¶ÁöÑ‰ªªÂä°„ÄÇThinkMorphÂ≠¶‰π†ÁîüÊàêÊ∏êËøõÂºèÁöÑÊñáÊú¨-ÂõæÂÉèÊé®ÁêÜÊ≠•È™§ÔºåÂÖ∑‰ΩìÂú∞Êìç‰ΩúËßÜËßâÂÜÖÂÆπÔºåÂêåÊó∂‰øùÊåÅËøûË¥ØÁöÑËØ≠Ë®ÄÈÄªËæë„ÄÇÂÆÉÂú®‰ª•ËßÜËßâ‰∏∫‰∏≠ÂøÉÁöÑÂü∫ÂáÜÊµãËØï‰∏≠ÂèñÂæó‰∫ÜÊòæËëóÊèêÂçáÔºàÂπ≥ÂùáË∂ÖËøáÂü∫Á∫øÊ®°Âûã34.7%ÔºâÔºåÂπ∂Ê≥õÂåñÂà∞È¢ÜÂüüÂ§ñ‰ªªÂä°ÔºåËææÂà∞ÁîöËá≥Ë∂ÖËøá‰∫ÜÊõ¥Â§ßËßÑÊ®°ÁöÑ‰∏ìÊúâVLM„ÄÇÊ≠§Â§ñÔºåThinkMorphËøòË°®Áé∞Âá∫Ê∂åÁé∞ÁöÑÂ§öÊ®°ÊÄÅÊô∫ËÉΩÔºåÂåÖÊã¨Êú™ËßÅËøáÁöÑËßÜËßâÊìç‰ΩúÊäÄËÉΩ„ÄÅÊé®ÁêÜÊ®°Âºè‰πãÈó¥ÁöÑËá™ÈÄÇÂ∫îÂàáÊç¢Ôºå‰ª•ÂèäÈÄöËøáÂ§öÊ†∑ÂåñÁöÑÂ§öÊ®°ÊÄÅÊÄùÁª¥ÂÆûÁé∞ÁöÑÊõ¥Â•ΩÁöÑÊµãËØïÊó∂Áº©Êîæ„ÄÇËøô‰∫õÂèëÁé∞‰∏∫Ë°®ÂæÅÂ§öÊ®°ÊÄÅÊé®ÁêÜÁªü‰∏ÄÊ®°ÂûãÁöÑÊ∂åÁé∞ËÉΩÂäõÊèê‰æõ‰∫ÜÊúâÂ∏åÊúõÁöÑÊñπÂêë„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÁöÑÂ§öÊ®°ÊÄÅÊé®ÁêÜÊ®°ÂûãÈÄöÂ∏∏Èöæ‰ª•ÊúâÊïàÂú∞Âà©Áî®ËØ≠Ë®ÄÂíåËßÜËßâ‰ø°ÊÅØ‰πãÈó¥ÁöÑ‰∫íË°•ÊÄßÔºåÂæÄÂæÄÂ∞Ü‰∏§ÁßçÊ®°ÊÄÅËßÜ‰∏∫ÂêåÊûÑÁöÑÔºåÂØºËá¥Êé®ÁêÜËøáÁ®ãÁº∫‰πèÊ∑±Â∫¶ÂíåÁÅµÊ¥ªÊÄß„ÄÇÊ≠§Â§ñÔºåÂ¶Ç‰ΩïÊûÑÂª∫ÊúâÊïàÁöÑ‰∫§ÈîôÂºèÊÄùÁª¥ÈìæÔºàChain-of-Thought, CoTÔºâ‰πüÊòØ‰∏Ä‰∏™ÊåëÊàòÔºåÈúÄË¶ÅÊ®°ÂûãËÉΩÂ§üÂú®‰∏çÂêåÊ®°ÊÄÅ‰πãÈó¥Ëá™ÈÄÇÂ∫îÂú∞ÂàáÊç¢ÔºåÂπ∂ÈÄêÊ≠•Êé®ËøõÊé®ÁêÜËøáÁ®ã„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöThinkMorphÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜÊñáÊú¨ÂíåÂõæÂÉèËßÜ‰∏∫‰∫íË°•ÁöÑÊ®°ÊÄÅÔºåÈÄöËøáÁîüÊàê‰∫§ÈîôÁöÑÊñáÊú¨-ÂõæÂÉèÊé®ÁêÜÊ≠•È™§ÔºåÊòæÂºèÂú∞Êìç‰ΩúËßÜËßâÂÜÖÂÆπÔºå‰ªéËÄå‰øÉËøõÊ®°ÊÄÅÈó¥ÁöÑÊúâÊïà‰∫íÂä®„ÄÇÊ®°ÂûãÂ≠¶‰π†ÁîüÊàêÊ∏êËøõÂºèÁöÑÊé®ÁêÜÊ≠•È™§ÔºåÊØè‰∏ÄÊ≠•ÈÉΩÂåÖÂê´ÊñáÊú¨ÂíåÂõæÂÉè‰ø°ÊÅØÔºåÊñáÊú¨Ë¥üË¥£ÈÄªËæëÊé®ÁêÜÔºåÂõæÂÉèË¥üË¥£ËßÜËßâÊìç‰ΩúÔºå‰∏§ËÄÖÁõ∏‰∫í‰øÉËøõÔºåÂÖ±ÂêåÂÆåÊàêÊé®ÁêÜ‰ªªÂä°„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöThinkMorphÊòØ‰∏Ä‰∏™Áªü‰∏ÄÁöÑÊ®°ÂûãÔºåÂü∫‰∫éÈ¢ÑËÆ≠ÁªÉÁöÑËßÜËßâËØ≠Ë®ÄÊ®°ÂûãËøõË°åÂæÆË∞É„ÄÇÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´‰∏Ä‰∏™Â§öÊ®°ÊÄÅÁºñÁ†ÅÂô®Âíå‰∏Ä‰∏™Â§öÊ®°ÊÄÅËß£Á†ÅÂô®„ÄÇÁºñÁ†ÅÂô®Ë¥üË¥£Â∞ÜÊñáÊú¨ÂíåÂõæÂÉè‰ø°ÊÅØÁºñÁ†ÅÊàêÁªü‰∏ÄÁöÑË°®Á§∫ÔºåËß£Á†ÅÂô®Ë¥üË¥£ÁîüÊàê‰∫§ÈîôÁöÑÊñáÊú¨-ÂõæÂÉèÊé®ÁêÜÊ≠•È™§„ÄÇËÆ≠ÁªÉÊï∞ÊçÆÂåÖÂê´Â§ßÈáèÁöÑ‰∫§ÈîôÊé®ÁêÜËΩ®ËøπÔºåÊ∂µÁõñ‰∫Ü‰∏çÂêåËßÜËßâÂèÇ‰∏éÂ∫¶ÁöÑ‰ªªÂä°„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöThinkMorphÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂‰∫§ÈîôÂºèÁöÑÊé®ÁêÜÊñπÂºèÔºåÂÆÉÂÖÅËÆ∏Ê®°ÂûãÂú®ÊñáÊú¨ÂíåÂõæÂÉè‰πãÈó¥Ëá™Áî±ÂàáÊç¢ÔºåÂπ∂ÊòæÂºèÂú∞Êìç‰ΩúËßÜËßâÂÜÖÂÆπ„ÄÇËøôÁßçÊñπÂºèËÉΩÂ§üÊõ¥Â•ΩÂú∞Âà©Áî®‰∏§ÁßçÊ®°ÊÄÅÁöÑ‰∫íË°•ÊÄßÔºå‰ªéËÄåÊèêÈ´òÊé®ÁêÜÁöÑÂáÜÁ°ÆÊÄßÂíåÊïàÁéá„ÄÇÊ≠§Â§ñÔºåThinkMorphËøòÂ±ïÁé∞Âá∫Ê∂åÁé∞ÁöÑÂ§öÊ®°ÊÄÅÊô∫ËÉΩÔºåÂåÖÊã¨Êú™ËßÅËøáÁöÑËßÜËßâÊìç‰ΩúÊäÄËÉΩÂíåÊé®ÁêÜÊ®°Âºè‰πãÈó¥ÁöÑËá™ÈÄÇÂ∫îÂàáÊç¢„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöThinkMorph‰ΩøÁî®‰∫Ü‰∏ÄÁßçÁâπÊÆäÁöÑËÆ≠ÁªÉÁ≠ñÁï•ÔºåÁß∞‰∏∫‚ÄúËßÜËßâÊìç‰ΩúÊåáÂØº‚ÄùÔºàVisual Manipulation GuidanceÔºâÔºåÈºìÂä±Ê®°ÂûãÁîüÊàêËÉΩÂ§üÊúâÊïàÊìç‰ΩúËßÜËßâÂÜÖÂÆπÁöÑÊé®ÁêÜÊ≠•È™§„ÄÇÊ≠§Â§ñÔºåÊ®°ÂûãËøò‰ΩøÁî®‰∫Ü‰∏ÄÁßçËá™ÈÄÇÂ∫îÁöÑÊé®ÁêÜÊ®°ÂºèÂàáÊç¢Êú∫Âà∂ÔºåÊ†πÊçÆÂΩìÂâçÁöÑÁä∂ÊÄÅÂä®ÊÄÅÂú∞ÈÄâÊã©‰ΩøÁî®ÊñáÊú¨Êé®ÁêÜÊàñÂõæÂÉèÊé®ÁêÜ„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨ËØ≠Ë®ÄÂª∫Ê®°ÊçüÂ§±ÂíåËßÜËßâÊìç‰ΩúÊçüÂ§±ÔºåÁî®‰∫é‰ºòÂåñÊ®°ÂûãÁöÑÁîüÊàêËÉΩÂäõÂíåËßÜËßâÊìç‰ΩúËÉΩÂäõ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ThinkMorphÂú®‰ª•ËßÜËßâ‰∏∫‰∏≠ÂøÉÁöÑÂü∫ÂáÜÊµãËØï‰∏≠ÂèñÂæó‰∫ÜÊòæËëóÊèêÂçáÔºåÂπ≥ÂùáË∂ÖËøáÂü∫Á∫øÊ®°Âûã34.7%„ÄÇÂú®È¢ÜÂüüÂ§ñ‰ªªÂä°‰∏≠ÔºåThinkMorphÁöÑÊÄßËÉΩËææÂà∞ÁîöËá≥Ë∂ÖËøá‰∫ÜÊõ¥Â§ßËßÑÊ®°ÁöÑ‰∏ìÊúâVLM„ÄÇÊ≠§Â§ñÔºåThinkMorphËøòÂ±ïÁé∞Âá∫Ê∂åÁé∞ÁöÑÂ§öÊ®°ÊÄÅÊô∫ËÉΩÔºåÂåÖÊã¨Êú™ËßÅËøáÁöÑËßÜËßâÊìç‰ΩúÊäÄËÉΩÂíåÊé®ÁêÜÊ®°Âºè‰πãÈó¥ÁöÑËá™ÈÄÇÂ∫îÂàáÊç¢ÔºåË°®ÊòéÂÖ∂ÂÖ∑ÊúâÂº∫Â§ßÁöÑÊ≥õÂåñËÉΩÂäõÂíåÊé®ÁêÜËÉΩÂäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ThinkMorphÁöÑÁ†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂêÑÁßçÈúÄË¶ÅÂ§öÊ®°ÊÄÅÊé®ÁêÜÁöÑÂú∫ÊôØÔºå‰æãÂ¶ÇÊô∫ËÉΩÊú∫Âô®‰∫∫„ÄÅËá™Âä®È©æÈ©∂„ÄÅÂõæÂÉèÁºñËæëÂíåËßÜËßâÈóÆÁ≠îÁ≠â„ÄÇËØ•Ê®°ÂûãËÉΩÂ§üÁêÜËß£ÂíåÊìç‰ΩúËßÜËßâÁéØÂ¢ÉÔºå‰ªéËÄåÂÆûÁé∞Êõ¥Êô∫ËÉΩ„ÄÅÊõ¥ÁÅµÊ¥ªÁöÑ‰ªªÂä°ÊâßË°å„ÄÇÊú™Êù•ÔºåËØ•Á†îÁ©∂ÊúâÊúõÊé®Âä®Â§öÊ®°ÊÄÅ‰∫∫Â∑•Êô∫ËÉΩÁöÑÂèëÂ±ïÔºåÂπ∂‰∏∫ÊûÑÂª∫Êõ¥Âº∫Â§ßÁöÑÈÄöÁî®‰∫∫Â∑•Êô∫ËÉΩÁ≥ªÁªüÂ•†ÂÆöÂü∫Á°Ä„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Multimodal reasoning requires iterative coordination between language and vision, yet it remains unclear what constitutes a meaningful interleaved chain of thought. We posit that text and image thoughts should function as complementary rather than isomorphic modalities that mutually advance reasoning. Guided by this principle, we build ThinkMorph, a unified model fine-tuned on approximately 24K high-quality interleaved reasoning traces spanning tasks with varying visual engagement. ThinkMorph learns to generate progressive text-image reasoning steps that concretely manipulate visual content while maintaining coherent verbal logic. It delivers large gains on vision-centric benchmarks (averaging 34.7 percent over the base model) and generalizes to out-of-domain tasks, matching or surpassing larger and proprietary VLMs. Beyond performance, ThinkMorph exhibits emergent multimodal intelligence, including unseen visual manipulation skills, adaptive switching between reasoning modes, and better test-time scaling through diversified multimodal thoughts. These findings suggest promising directions for characterizing the emergent capabilities of unified models for multimodal reasoning.

