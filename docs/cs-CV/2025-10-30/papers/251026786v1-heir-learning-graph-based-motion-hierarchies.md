---
layout: default
title: HEIR: Learning Graph-Based Motion Hierarchies
---

# HEIR: Learning Graph-Based Motion Hierarchies

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.26786" target="_blank" class="toolbar-btn">arXiv: 2510.26786v1</a>
    <a href="https://arxiv.org/pdf/2510.26786.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.26786v1" 
            onclick="toggleFavorite(this, '2510.26786v1', 'HEIR: Learning Graph-Based Motion Hierarchies')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Cheng Zheng, William Koch, Baiang Li, Felix Heide

**ÂàÜÁ±ª**: cs.CV, cs.GR, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-30

**Â§áÊ≥®**: Code link: https://github.com/princeton-computational-imaging/HEIR

**ÊúüÂàä**: Advances in Neural Information Processing Systems 38 (NeurIPS 2025)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫HEIRÔºåÂ≠¶‰π†Âü∫‰∫éÂõæÁöÑËøêÂä®Â±ÇÊ¨°ÁªìÊûÑÔºåÂÆûÁé∞Êï∞ÊçÆÈ©±Âä®ÁöÑËøêÂä®Âª∫Ê®°„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)**

**ÂÖ≥ÈîÆËØç**: `ËøêÂä®Âª∫Ê®°` `Â±ÇÊ¨°ÁªìÊûÑÂ≠¶‰π†` `ÂõæÁ•ûÁªèÁΩëÁªú` `ËøêÂä®ÂàÜËß£` `Âä®ÊÄÅÂú∫ÊôØÈáçÂª∫`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËøêÂä®Âª∫Ê®°ÊñπÊ≥ï‰æùËµñÊâãÂä®ÂÆö‰πâÊàñÂêØÂèëÂºèËßÑÂàôÔºåÁº∫‰πèÂØπ‰∏çÂêå‰ªªÂä°ÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ
2. HEIRÊñπÊ≥ïÈÄöËøáÂõæÁ•ûÁªèÁΩëÁªúÂ≠¶‰π†ËøêÂä®Â±ÇÊ¨°ÁªìÊûÑÔºåÂ∞ÜÂÖ®Â±ÄËøêÂä®ÂàÜËß£‰∏∫ÁªßÊâøÊ®°ÂºèÂíåÂ±ÄÈÉ®ÊÆãÂ∑Æ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåHEIRÂú®1D/2DËøêÂä®ÈáçÂª∫‰∏≠ËÉΩÊÅ¢Â§çÂÜÖÂú®ÁªìÊûÑÔºåÂú®3DÂä®ÊÄÅÂú∫ÊôØÂèòÂΩ¢‰∏≠Ë°®Áé∞Êõ¥‰ºò„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÈÄöÁî®ÁöÑÂàÜÂ±ÇËøêÂä®Âª∫Ê®°ÊñπÊ≥ïÔºåËØ•ÊñπÊ≥ïÁõ¥Êé•‰ªéÊï∞ÊçÆ‰∏≠Â≠¶‰π†ÁªìÊûÑÂåñÁöÑ„ÄÅÂèØËß£ÈáäÁöÑËøêÂä®ÂÖ≥Á≥ª„ÄÇËØ•ÊñπÊ≥ï‰ΩøÁî®Âü∫‰∫éÂõæÁöÑÂ±ÇÊ¨°ÁªìÊûÑÊù•Ë°®Á§∫ËßÇÂØüÂà∞ÁöÑËøêÂä®ÔºåÂ∞ÜÂÖ®Â±ÄÁªùÂØπËøêÂä®ÊòæÂºèÂú∞ÂàÜËß£‰∏∫Áà∂ËäÇÁÇπÁªßÊâøÁöÑÊ®°ÂºèÂíåÂ±ÄÈÉ®ËøêÂä®ÊÆãÂ∑Æ„ÄÇÊàë‰ª¨Â∞ÜÂ±ÇÊ¨°ÁªìÊûÑÊé®Êñ≠Âª∫Ê®°‰∏∫‰∏Ä‰∏™ÂèØÂæÆÁöÑÂõæÂ≠¶‰π†ÈóÆÈ¢òÔºåÂÖ∂‰∏≠È°∂ÁÇπË°®Á§∫Âü∫Êú¨ËøêÂä®ÔºåÊúâÂêëËæπÈÄöËøáÂõæÁ•ûÁªèÁΩëÁªúÊçïËé∑Â≠¶‰π†Âà∞ÁöÑÁà∂Â≠ê‰æùËµñÂÖ≥Á≥ª„ÄÇÊàë‰ª¨Âú®‰∏â‰∏™‰æãÂ≠ê‰∏äËØÑ‰º∞‰∫ÜÊàë‰ª¨ÁöÑÂàÜÂ±ÇÈáçÂª∫ÊñπÊ≥ïÔºö1DÂπ≥ÁßªËøêÂä®„ÄÅ2DÊóãËΩ¨ËøêÂä®‰ª•ÂèäÈÄöËøáÈ´òÊñØÊ∫ÖÂ∞ÑÂÆûÁé∞ÁöÑÂä®ÊÄÅ3DÂú∫ÊôØÂèòÂΩ¢„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÈáçÂª∫‰∫Ü1DÂíå2DÊ°à‰æã‰∏≠ÁöÑÂÜÖÂú®ËøêÂä®Â±ÇÊ¨°ÁªìÊûÑÔºåÂπ∂‰∏î‰∏éÂä®ÊÄÅ3DÈ´òÊñØÊ∫ÖÂ∞ÑÂú∫ÊôØ‰∏äÁöÑÂü∫Á∫øÁõ∏ÊØîÔºå‰∫ßÁîü‰∫ÜÊõ¥ÈÄºÁúüÂíåÂèØËß£ÈáäÁöÑÂèòÂΩ¢„ÄÇÈÄöËøáÊèê‰æõ‰∏ÄÁßçÈÄÇÂ∫îÊÄßÂº∫„ÄÅÊï∞ÊçÆÈ©±Âä®ÁöÑÂàÜÂ±ÇÂª∫Ê®°ËåÉ‰æãÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÊèê‰æõ‰∫Ü‰∏ÄÁßçÈÄÇÁî®‰∫éÂπøÊ≥õÁöÑ‰ª•ËøêÂä®‰∏∫‰∏≠ÂøÉ‰ªªÂä°ÁöÑÂÖ¨Âºè„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâËøêÂä®Âª∫Ê®°ÊñπÊ≥ïÈÄöÂ∏∏‰æùËµñ‰∫éÊâãÂä®ÂÆö‰πâÁöÑÊàñÂêØÂèëÂºèÁöÑÂ±ÇÊ¨°ÁªìÊûÑÔºå‰ª•ÂèäÂõ∫ÂÆöÁöÑËøêÂä®ÂéüËØ≠ÔºåËøôÈôêÂà∂‰∫ÜÂÆÉ‰ª¨Âú®‰∏çÂêå‰ªªÂä°‰∏≠ÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Â¶Ç‰ΩïËá™Âä®Âú∞„ÄÅÊï∞ÊçÆÈ©±Âä®Âú∞Â≠¶‰π†ËøêÂä®ÁöÑÂ±ÇÊ¨°ÁªìÊûÑÔºå‰ªéËÄåÊõ¥Â•ΩÂú∞Âª∫Ê®°Â§çÊùÇËøêÂä®Âä®ÂäõÂ≠¶ÁöÑÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜÂ§çÊùÇÁöÑËøêÂä®ÂàÜËß£‰∏∫‰∏ÄÁ≥ªÂàóÂÖ∑ÊúâÂ±ÇÊ¨°ÂÖ≥Á≥ªÁöÑÁÆÄÂçïËøêÂä®ÂçïÂÖÉÔºåÂπ∂ÈÄöËøáÂõæÁªìÊûÑÊù•Ë°®Á§∫Ëøô‰∫õÂçïÂÖÉ‰πãÈó¥ÁöÑ‰æùËµñÂÖ≥Á≥ª„ÄÇÈÄöËøáÂ≠¶‰π†ÂõæÁöÑÁªìÊûÑÔºåÂèØ‰ª•Ëá™Âä®Âú∞ÂèëÁé∞ËøêÂä®ÁöÑÂÜÖÂú®Â±ÇÊ¨°ÁªìÊûÑÔºå‰ªéËÄåÂÆûÁé∞Êõ¥ÁÅµÊ¥ªÂíåÂèØËß£ÈáäÁöÑËøêÂä®Âª∫Ê®°„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöHEIRÊñπÊ≥ïÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ≠•È™§Ôºö1) ‰ΩøÁî®ÂõæÁªìÊûÑË°®Á§∫ËøêÂä®ÔºåÂÖ∂‰∏≠ËäÇÁÇπ‰ª£Ë°®Âü∫Êú¨ËøêÂä®ÂçïÂÖÉÔºåËæπ‰ª£Ë°®ÂçïÂÖÉÈó¥ÁöÑ‰æùËµñÂÖ≥Á≥ªÔºõ2) ‰ΩøÁî®ÂõæÁ•ûÁªèÁΩëÁªúÂ≠¶‰π†ÂõæÁöÑÁªìÊûÑÔºåÂç≥Â≠¶‰π†ËäÇÁÇπÈó¥ÁöÑËøûÊé•ÂÖ≥Á≥ªÔºõ3) Â∞ÜÂÖ®Â±ÄËøêÂä®ÂàÜËß£‰∏∫Áà∂ËäÇÁÇπÁªßÊâøÁöÑËøêÂä®Ê®°ÂºèÂíåÂ±ÄÈÉ®ËøêÂä®ÊÆãÂ∑ÆÔºõ4) ÈÄöËøáÊúÄÂ∞èÂåñÈáçÂª∫ËØØÂ∑ÆÊù•‰ºòÂåñÂõæÁöÑÁªìÊûÑÂíåËøêÂä®ÂàÜËß£„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ÊñπÊ≥ïÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫é‰ΩøÁî®ÂõæÁ•ûÁªèÁΩëÁªúÊù•Â≠¶‰π†ËøêÂä®ÁöÑÂ±ÇÊ¨°ÁªìÊûÑ„ÄÇ‰∏é‰º†ÁªüÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üËá™Âä®Âú∞‰ªéÊï∞ÊçÆ‰∏≠Â≠¶‰π†ËøêÂä®ÂçïÂÖÉ‰πãÈó¥ÁöÑ‰æùËµñÂÖ≥Á≥ªÔºåËÄåÊó†ÈúÄÊâãÂä®ÂÆö‰πâÊàñ‰ΩøÁî®ÂêØÂèëÂºèËßÑÂàô„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïËøòËÉΩÂ§üÂ∞ÜÂÖ®Â±ÄËøêÂä®ÂàÜËß£‰∏∫ÂèØËß£ÈáäÁöÑËøêÂä®Ê®°ÂºèÂíåÊÆãÂ∑ÆÔºå‰ªéËÄåÊõ¥Â•ΩÂú∞ÁêÜËß£ËøêÂä®ÁöÑÊú¨Ë¥®„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÂõæÁ•ûÁªèÁΩëÁªúÁöÑËÆæËÆ°‰∏äÔºåËÆ∫Êñá‰ΩøÁî®‰∫ÜÂèØÂæÆÁöÑÂõæÂ≠¶‰π†ÊñπÊ≥ïÔºå‰ΩøÂæóÊï¥‰∏™Ê®°ÂûãÂèØ‰ª•ËøõË°åÁ´ØÂà∞Á´ØÁöÑËÆ≠ÁªÉ„ÄÇÊçüÂ§±ÂáΩÊï∞‰∏ªË¶ÅÂåÖÊã¨ÈáçÂª∫ÊçüÂ§±ÂíåÊ≠£ÂàôÂåñÈ°πÔºåÂÖ∂‰∏≠ÈáçÂª∫ÊçüÂ§±Áî®‰∫é‰øùËØÅËøêÂä®ÁöÑÈáçÂª∫Á≤æÂ∫¶ÔºåÊ≠£ÂàôÂåñÈ°πÁî®‰∫éÁ∫¶ÊùüÂõæÁöÑÁªìÊûÑÔºå‰æãÂ¶ÇÁ®ÄÁñèÊÄß„ÄÇÂÖ∑‰ΩìÁöÑÁΩëÁªúÁªìÊûÑÂíåÂèÇÊï∞ËÆæÁΩÆÂú®ËÆ∫Êñá‰∏≠ÊúâËØ¶ÁªÜÊèèËø∞ÔºåÈúÄË¶ÅÊ†πÊçÆÂÖ∑‰ΩìÁöÑÂ∫îÁî®Âú∫ÊôØËøõË°åË∞ÉÊï¥„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåHEIRÊñπÊ≥ïÂú®1DÂíå2DËøêÂä®ÈáçÂª∫‰ªªÂä°‰∏≠ËÉΩÂ§üÂáÜÁ°ÆÂú∞ÊÅ¢Â§çÂÜÖÂú®ÁöÑËøêÂä®Â±ÇÊ¨°ÁªìÊûÑ„ÄÇÂú®Âä®ÊÄÅ3DÈ´òÊñØÊ∫ÖÂ∞ÑÂú∫ÊôØ‰∏≠ÔºåHEIRÊñπÊ≥ïÁîüÊàêÁöÑÂèòÂΩ¢ÊïàÊûúÊØîÂü∫Á∫øÊñπÊ≥ïÊõ¥ÈÄºÁúüÂíåÂèØËß£Èáä„ÄÇËøô‰∫õÁªìÊûúÈ™åËØÅ‰∫ÜHEIRÊñπÊ≥ïÂú®ËøêÂä®Âª∫Ê®°ÊñπÈù¢ÁöÑÊúâÊïàÊÄßÂíå‰ºòË∂äÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éËÆ°ÁÆóÊú∫ËßÜËßâ„ÄÅÂõæÂΩ¢Â≠¶ÂíåÊú∫Âô®‰∫∫Á≠âÈ¢ÜÂüüÔºå‰æãÂ¶ÇÂä®‰ΩúËØÜÂà´„ÄÅËøêÂä®È¢ÑÊµã„ÄÅÂä®ÁîªÁîüÊàê„ÄÅÊú∫Âô®‰∫∫ÊéßÂà∂Á≠â„ÄÇÈÄöËøáÂ≠¶‰π†ËøêÂä®ÁöÑÂ±ÇÊ¨°ÁªìÊûÑÔºåÂèØ‰ª•Êõ¥Â•ΩÂú∞ÁêÜËß£ÂíåÂª∫Ê®°Â§çÊùÇÁöÑËøêÂä®Âä®ÂäõÂ≠¶Ôºå‰ªéËÄåÊèêÈ´òÁõ∏ÂÖ≥‰ªªÂä°ÁöÑÊÄßËÉΩÂíåÈ≤ÅÊ£íÊÄß„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïÊúâÊúõÂ∫îÁî®‰∫éÊõ¥ÂπøÊ≥õÁöÑËøêÂä®Áõ∏ÂÖ≥‰ªªÂä°Ôºå‰æãÂ¶ÇËá™Âä®È©æÈ©∂„ÄÅËôöÊãüÁé∞ÂÆûÁ≠â„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Hierarchical structures of motion exist across research fields, including computer vision, graphics, and robotics, where complex dynamics typically arise from coordinated interactions among simpler motion components. Existing methods to model such dynamics typically rely on manually-defined or heuristic hierarchies with fixed motion primitives, limiting their generalizability across different tasks. In this work, we propose a general hierarchical motion modeling method that learns structured, interpretable motion relationships directly from data. Our method represents observed motions using graph-based hierarchies, explicitly decomposing global absolute motions into parent-inherited patterns and local motion residuals. We formulate hierarchy inference as a differentiable graph learning problem, where vertices represent elemental motions and directed edges capture learned parent-child dependencies through graph neural networks. We evaluate our hierarchical reconstruction approach on three examples: 1D translational motion, 2D rotational motion, and dynamic 3D scene deformation via Gaussian splatting. Experimental results show that our method reconstructs the intrinsic motion hierarchy in 1D and 2D cases, and produces more realistic and interpretable deformations compared to the baseline on dynamic 3D Gaussian splatting scenes. By providing an adaptable, data-driven hierarchical modeling paradigm, our method offers a formulation applicable to a broad range of motion-centric tasks. Project Page: https://light.princeton.edu/HEIR/

