---
layout: default
title: Semantic Frame Aggregation-based Transformer for Live Video Comment Generation
---

# Semantic Frame Aggregation-based Transformer for Live Video Comment Generation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.26978" target="_blank" class="toolbar-btn">arXiv: 2510.26978v1</a>
    <a href="https://arxiv.org/pdf/2510.26978.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.26978v1" 
            onclick="toggleFavorite(this, '2510.26978v1', 'Semantic Frame Aggregation-based Transformer for Live Video Comment Generation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Anam Fatima, Yi Yu, Janak Kapuriya, Julien Lalanne, Jainendra Shukla

**ÂàÜÁ±ª**: cs.CV, cs.CL

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-30

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éËØ≠‰πâÂ∏ßËÅöÂêàTransformerÁöÑSFATÊ®°ÂûãÔºåÁî®‰∫éÁîüÊàêÁõ¥Êí≠ËßÜÈ¢ëËØÑËÆ∫„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Áõ¥Êí≠ËßÜÈ¢ëËØÑËÆ∫ÁîüÊàê` `ËØ≠‰πâÂ∏ßËÅöÂêà` `Transformer` `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `CLIP` `Ë∑®Ê≥®ÊÑèÂäõÊú∫Âà∂` `ËßÜÈ¢ëÁêÜËß£` `Ëá™ÁÑ∂ËØ≠Ë®ÄÁîüÊàê`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®ÁîüÊàêÁõ¥Êí≠ËßÜÈ¢ëËØÑËÆ∫Êó∂ÔºåÊú™ËÉΩÂÖÖÂàÜËÄÉËôëËßÜÈ¢ëÂ∏ß‰∏éËßÇ‰ºó‰∫íÂä®‰πãÈó¥ÁöÑËØ≠‰πâÁõ∏ÂÖ≥ÊÄßÔºåÂØºËá¥ÁîüÊàêÁöÑËØÑËÆ∫‰∏é‰∏ä‰∏ãÊñáÂÖ≥ËÅîÊÄßËæÉÂº±„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫SFATÊ®°ÂûãÔºåÂà©Áî®CLIPÁöÑÂ§öÊ®°ÊÄÅÁü•ËØÜÔºåÈÄöËøáËØ≠‰πâÂ∏ßËÅöÂêàÊú∫Âà∂ÔºåÂØπËßÜÈ¢ëÂ∏ßËøõË°åÂä†ÊùÉÔºå‰ªéËÄåÁ™ÅÂá∫ÂÖ≥ÈîÆÂ∏ßÔºåÊèêÂçáËØÑËÆ∫ÁöÑ‰∏ä‰∏ãÊñáÁõ∏ÂÖ≥ÊÄß„ÄÇ
3. ËÆ∫ÊñáÊûÑÂª∫‰∫Ü‰∏Ä‰∏™Â§ßËßÑÊ®°„ÄÅÂ§öÊ†∑ÂåñÁöÑËã±ËØ≠Áõ¥Êí≠ËßÜÈ¢ëËØÑËÆ∫Êï∞ÊçÆÈõÜÔºåÂπ∂ÈÄöËøáÂÆûÈ™åËØÅÊòé‰∫ÜSFATÊ®°ÂûãÂú®ÁîüÊàêËØÑËÆ∫ÊñπÈù¢ÁöÑÊúâÊïàÊÄßÔºå‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÁî®‰∫éÁîüÊàêÁõ¥Êí≠ËßÜÈ¢ëËØÑËÆ∫ÁöÑÂü∫‰∫éËØ≠‰πâÂ∏ßËÅöÂêàTransformerÔºàSFATÔºâÊ®°Âûã„ÄÇÁõ¥Êí≠ËØÑËÆ∫Âú®TwitchÁ≠âÂπ≥Âè∞‰∏äÁöÑËßÜÈ¢ëÊµÅ‰∏≠Ë∂äÊù•Ë∂äÂèóÊ¨¢ËøéÔºåÈÄöËøáÂä®ÊÄÅ‰∫§‰∫íÂ¢ûÂº∫‰∫ÜËßÇ‰ºóÁöÑÂèÇ‰∏éÂ∫¶„ÄÇÁÑ∂ËÄåÔºåËá™Âä®ÁîüÊàêÁ¨¶ÂêàËØ≠Â¢ÉÁöÑËØÑËÆ∫‰ªçÁÑ∂ÊòØ‰∏Ä‰∏™ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑ‰ªªÂä°„ÄÇËßÜÈ¢ëÊµÅÂåÖÂê´Â§ßÈáèÊï∞ÊçÆÂíåÊó†ÂÖ≥ÂÜÖÂÆπ„ÄÇÁé∞ÊúâÊñπÊ≥ïÂÄæÂêë‰∫éÂøΩÁï•‰∏Ä‰∏™ÈáçË¶ÅÊñπÈù¢ÔºåÂç≥‰ºòÂÖàËÄÉËôë‰∏éÊ≠£Âú®ËøõË°åÁöÑËßÇ‰ºó‰∫íÂä®ÊúÄÁõ∏ÂÖ≥ÁöÑËßÜÈ¢ëÂ∏ß„ÄÇËøôÁßç‰ºòÂÖàÁ∫ßÂØπ‰∫éÁîüÊàêÁ¨¶ÂêàËØ≠Â¢ÉÁöÑËØÑËÆ∫Ëá≥ÂÖ≥ÈáçË¶Å„ÄÇSFATÊ®°ÂûãÂà©Áî®CLIPÁöÑËßÜËßâ-ÊñáÊú¨Â§öÊ®°ÊÄÅÁü•ËØÜÊù•ÁîüÊàêËØÑËÆ∫ÔºåÂπ∂Ê†πÊçÆËßÜÈ¢ëÂ∏ß‰∏éÊ≠£Âú®ËøõË°åÁöÑËßÇ‰ºóÂØπËØùÁöÑËØ≠‰πâÁõ∏ÂÖ≥ÊÄß‰∏∫ÂÖ∂ÂàÜÈÖçÊùÉÈáç„ÄÇÂÆÉÈááÁî®‰∫Ü‰∏ÄÁßçÊúâÊïàÁöÑÂ∏ßÂä†ÊùÉÊ±ÇÂíåÊäÄÊúØÊù•Âº∫Ë∞É‰ø°ÊÅØ‰∏∞ÂØåÁöÑÂ∏ßÔºåÂêåÊó∂ÂáèÂ∞ëÂØπ‰∏çÁõ∏ÂÖ≥Â∏ßÁöÑÂÖ≥Ê≥®„ÄÇÊúÄÂêéÔºåÂ∏¶ÊúâË∑®Ê≥®ÊÑèÂäõÊú∫Âà∂ÁöÑËØÑËÆ∫Ëß£Á†ÅÂô®Á°Æ‰øùÁîüÊàêÁöÑËØÑËÆ∫ÂèçÊò†‰∫ÜÊù•Ëá™ËÅäÂ§©ÂíåËßÜÈ¢ëÁöÑ‰∏ä‰∏ãÊñáÁ∫øÁ¥¢„ÄÇÊ≠§Â§ñÔºå‰∏∫‰∫ÜËß£ÂÜ≥Áé∞ÊúâÊï∞ÊçÆÈõÜÁöÑÂ±ÄÈôêÊÄßÔºà‰∏ªË¶ÅÈõÜ‰∏≠‰∫é‰∏≠ÊñáÂÜÖÂÆπÂíåÊúâÈôêÁöÑËßÜÈ¢ëÁ±ªÂà´ÔºâÔºåÊàë‰ª¨ÊûÑÂª∫‰∫Ü‰∏Ä‰∏™Â§ßËßÑÊ®°„ÄÅÂ§öÊ†∑ÂåñÁöÑÂ§öÊ®°ÊÄÅËã±ËØ≠ËßÜÈ¢ëËØÑËÆ∫Êï∞ÊçÆÈõÜ„ÄÇËØ•Êï∞ÊçÆÈõÜ‰ªéTwitchÊèêÂèñÔºåÊ∂µÁõñ11‰∏™ËßÜÈ¢ëÁ±ªÂà´ÔºåÊÄªËÆ°438Â∞èÊó∂Âíå320‰∏áÊù°ËØÑËÆ∫„ÄÇÈÄöËøáÂ∞ÜÊàë‰ª¨ÁöÑSFATÊ®°Âûã‰∏éÁé∞ÊúâÊñπÊ≥ïËøõË°åÊØîËæÉÔºåËØÅÊòé‰∫ÜÂÖ∂Âú®‰ªéÁõ¥Êí≠ËßÜÈ¢ëÂíåÊ≠£Âú®ËøõË°åÁöÑÂØπËØù‰∏ä‰∏ãÊñá‰∏≠ÁîüÊàêËØÑËÆ∫ÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Áõ¥Êí≠ËßÜÈ¢ëËØÑËÆ∫Ëá™Âä®ÁîüÊàêÁöÑÈóÆÈ¢òÔºåÁé∞ÊúâÊñπÊ≥ïÁöÑÁóõÁÇπÂú®‰∫éÊó†Ê≥ïÊúâÊïàÂå∫ÂàÜËßÜÈ¢ëÂ∏ßÁöÑÈáçË¶ÅÊÄßÔºåÂØºËá¥ÁîüÊàêÁöÑËØÑËÆ∫‰∏é‰∏ä‰∏ãÊñáÂÖ≥ËÅîÊÄßËæÉÂ∑ÆÔºåÊó†Ê≥ïÂáÜÁ°ÆÂèçÊò†ËßÇ‰ºóÁöÑÂÖ≥Ê≥®ÁÇπ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®ËßÜÈ¢ëÂ∏ß‰∏éËßÇ‰ºóÂØπËØù‰πãÈó¥ÁöÑËØ≠‰πâÁõ∏ÂÖ≥ÊÄßÔºåÂØπËßÜÈ¢ëÂ∏ßËøõË°åÂä†ÊùÉÔºå‰ªéËÄåÁ™ÅÂá∫‰∏éËßÇ‰ºó‰∫íÂä®ÊúÄÁõ∏ÂÖ≥ÁöÑÂ∏ß„ÄÇÈÄöËøáËøôÁßçÊñπÂºèÔºåÊ®°ÂûãÂèØ‰ª•Êõ¥Âä†ÂÖ≥Ê≥®ÂÖ≥ÈîÆ‰ø°ÊÅØÔºåÁîüÊàêÊõ¥Á¨¶ÂêàËØ≠Â¢ÉÁöÑËØÑËÆ∫„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöSFATÊ®°Âûã‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Ê®°ÂùóÔºö1) ËßÜÈ¢ëÂ∏ßÁºñÁ†ÅÂô®ÔºöÂà©Áî®È¢ÑËÆ≠ÁªÉÁöÑCLIPÊ®°ÂûãÊèêÂèñËßÜÈ¢ëÂ∏ßÁöÑËßÜËßâÁâπÂæÅ„ÄÇ2) ËØ≠‰πâÂ∏ßËÅöÂêàÊ®°ÂùóÔºöËÆ°ÁÆóÊØè‰∏™ËßÜÈ¢ëÂ∏ß‰∏éËßÇ‰ºóÂØπËØùÁöÑËØ≠‰πâÁõ∏ÂÖ≥ÊÄßÔºåÂπ∂ÊçÆÊ≠§ÂØπËßÜÈ¢ëÂ∏ßËøõË°åÂä†ÊùÉ„ÄÇ3) ËØÑËÆ∫Ëß£Á†ÅÂô®ÔºöÂà©Áî®Ë∑®Ê≥®ÊÑèÂäõÊú∫Âà∂ÔºåËûçÂêàËßÜÈ¢ëÂíåÂØπËØù‰ø°ÊÅØÔºåÁîüÊàêÊúÄÁªàÁöÑËØÑËÆ∫„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫ÜËØ≠‰πâÂ∏ßËÅöÂêàÊú∫Âà∂ÔºåËØ•Êú∫Âà∂ËÉΩÂ§üÊ†πÊçÆËßÜÈ¢ëÂ∏ß‰∏éËßÇ‰ºóÂØπËØùÁöÑËØ≠‰πâÁõ∏ÂÖ≥ÊÄßÔºåÂä®ÊÄÅÂú∞Ë∞ÉÊï¥ËßÜÈ¢ëÂ∏ßÁöÑÊùÉÈáçÔºå‰ªéËÄå‰ΩøÊ®°ÂûãÊõ¥Âä†ÂÖ≥Ê≥®ÂÖ≥ÈîÆ‰ø°ÊÅØ„ÄÇËøôÁßçÊñπÊ≥ïËÉΩÂ§üÊúâÊïàÂú∞ÊèêÂçáÁîüÊàêËØÑËÆ∫ÁöÑ‰∏ä‰∏ãÊñáÁõ∏ÂÖ≥ÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËØ≠‰πâÂ∏ßËÅöÂêàÊ®°ÂùóÁöÑÂÖ≥ÈîÆËÆæËÆ°Âú®‰∫éÂ¶Ç‰ΩïËÆ°ÁÆóËßÜÈ¢ëÂ∏ß‰∏éËßÇ‰ºóÂØπËØùÁöÑËØ≠‰πâÁõ∏ÂÖ≥ÊÄß„ÄÇËÆ∫ÊñáÈááÁî®‰∫Ü‰∏ÄÁßçÂü∫‰∫é‰ΩôÂº¶Áõ∏‰ººÂ∫¶ÁöÑËÆ°ÁÆóÊñπÊ≥ïÔºåÂ∞ÜËßÜÈ¢ëÂ∏ßÂíåËßÇ‰ºóÂØπËØùÂàÜÂà´ÁºñÁ†Å‰∏∫ÂêëÈáèÔºåÁÑ∂ÂêéËÆ°ÁÆóÂÆÉ‰ª¨‰πãÈó¥ÁöÑ‰ΩôÂº¶Áõ∏‰ººÂ∫¶Ôºå‰Ωú‰∏∫ËßÜÈ¢ëÂ∏ßÁöÑÊùÉÈáç„ÄÇËØÑËÆ∫Ëß£Á†ÅÂô®ÈááÁî®TransformerÁªìÊûÑÔºåÂπ∂ÂºïÂÖ•‰∫ÜË∑®Ê≥®ÊÑèÂäõÊú∫Âà∂Ôºå‰ª•‰æøÊõ¥Â•ΩÂú∞ËûçÂêàËßÜÈ¢ëÂíåÂØπËØù‰ø°ÊÅØ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ËÆ∫ÊñáÊûÑÂª∫‰∫Ü‰∏Ä‰∏™ÂåÖÂê´438Â∞èÊó∂ËßÜÈ¢ëÂíå320‰∏áÊù°ËØÑËÆ∫ÁöÑÂ§ßËßÑÊ®°Ëã±ËØ≠Áõ¥Êí≠ËßÜÈ¢ëËØÑËÆ∫Êï∞ÊçÆÈõÜ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåSFATÊ®°ÂûãÂú®ÁîüÊàêËØÑËÆ∫ÊñπÈù¢‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåËÉΩÂ§üÁîüÊàêÊõ¥Á¨¶ÂêàËØ≠Â¢É„ÄÅÊõ¥ÂÖ∑Áõ∏ÂÖ≥ÊÄßÁöÑËØÑËÆ∫„ÄÇÂÖ∑‰ΩìÁöÑÊÄßËÉΩÊèêÂçáÊï∞ÊçÆÂú®ËÆ∫Êñá‰∏≠ÁªôÂá∫Ôºå‰ΩÜÊ≠§Â§ÑÊú™Êèê‰æõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂêÑÁßçÁõ¥Êí≠Âπ≥Âè∞Ôºå‰æãÂ¶ÇÊ∏∏ÊàèÁõ¥Êí≠„ÄÅ‰ΩìËÇ≤Ëµõ‰∫ãÁõ¥Êí≠„ÄÅÊñ∞ÈóªÁõ¥Êí≠Á≠âÔºåËÉΩÂ§üËá™Âä®ÁîüÊàê‰∏éËßÜÈ¢ëÂÜÖÂÆπÂíåËßÇ‰ºó‰∫íÂä®Áõ∏ÂÖ≥ÁöÑËØÑËÆ∫ÔºåÊèêÂçáÁî®Êà∑ÂèÇ‰∏éÂ∫¶ÂíåËßÇÁúã‰ΩìÈ™å„ÄÇÊ≠§Â§ñÔºåËØ•ÊäÄÊúØËøòÂèØ‰ª•Â∫îÁî®‰∫éËßÜÈ¢ëÊëòË¶ÅÁîüÊàê„ÄÅÊô∫ËÉΩÂÆ¢ÊúçÁ≠âÈ¢ÜÂüüÔºåÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Live commenting on video streams has surged in popularity on platforms like Twitch, enhancing viewer engagement through dynamic interactions. However, automatically generating contextually appropriate comments remains a challenging and exciting task. Video streams can contain a vast amount of data and extraneous content. Existing approaches tend to overlook an important aspect of prioritizing video frames that are most relevant to ongoing viewer interactions. This prioritization is crucial for producing contextually appropriate comments. To address this gap, we introduce a novel Semantic Frame Aggregation-based Transformer (SFAT) model for live video comment generation. This method not only leverages CLIP's visual-text multimodal knowledge to generate comments but also assigns weights to video frames based on their semantic relevance to ongoing viewer conversation. It employs an efficient weighted sum of frames technique to emphasize informative frames while focusing less on irrelevant ones. Finally, our comment decoder with a cross-attention mechanism that attends to each modality ensures that the generated comment reflects contextual cues from both chats and video. Furthermore, to address the limitations of existing datasets, which predominantly focus on Chinese-language content with limited video categories, we have constructed a large scale, diverse, multimodal English video comments dataset. Extracted from Twitch, this dataset covers 11 video categories, totaling 438 hours and 3.2 million comments. We demonstrate the effectiveness of our SFAT model by comparing it to existing methods for generating comments from live video and ongoing dialogue contexts.

