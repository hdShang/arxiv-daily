---
layout: default
title: MoTDiff: High-resolution Motion Trajectory estimation from a single blurred image using Diffusion models
---

# MoTDiff: High-resolution Motion Trajectory estimation from a single blurred image using Diffusion models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.26173" class="toolbar-btn" target="_blank">üìÑ arXiv: 2510.26173v1</a>
  <a href="https://arxiv.org/pdf/2510.26173.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.26173v1" onclick="toggleFavorite(this, '2510.26173v1', 'MoTDiff: High-resolution Motion Trajectory estimation from a single blurred image using Diffusion models')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Wontae Choi, Jaelin Lee, Hyung Sup Yun, Byeungwoo Jeon, Il Yong Chun

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-30

**Â§áÊ≥®**: 10 pages, 6 figures

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**MoTDiffÔºöÂà©Áî®Êâ©Êï£Ê®°Âûã‰ªéÂçïÂº†Ê®°Á≥äÂõæÂÉè‰∏≠‰º∞ËÆ°È´òÂàÜËæ®ÁéáËøêÂä®ËΩ®Ëøπ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)**

**ÂÖ≥ÈîÆËØç**: `ËøêÂä®ËΩ®Ëøπ‰º∞ËÆ°` `Êâ©Êï£Ê®°Âûã` `ÂõæÂÉèÂéªÊ®°Á≥ä` `Êù°‰ª∂ÁîüÊàê` `È´òÂàÜËæ®ÁéáÂõæÂÉè`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®ÂçïÂº†Ê®°Á≥äÂõæÂÉè‰∏≠ÊèêÂèñËøêÂä®‰ø°ÊÅØÊó∂ÔºåËøêÂä®ËΩ®ËøπË°®Á§∫Á≤óÁ≥ô‰∏îÁ≤æÂ∫¶‰ΩéÔºåÈöæ‰ª•Êª°Ë∂≥È´òÁ≤æÂ∫¶Â∫îÁî®ÈúÄÊ±Ç„ÄÇ
2. MoTDiffÂà©Áî®Êù°‰ª∂Êâ©Êï£Ê®°ÂûãÔºå‰ª•Â§öÂ∞∫Â∫¶ÁâπÂæÅÂõæ‰∏∫Êù°‰ª∂ÔºåÁîüÊàêÈ´òÂàÜËæ®ÁéáËøêÂä®ËΩ®ËøπÔºåÂÆûÁé∞Êõ¥Á≤æÁªÜÁöÑËøêÂä®‰ø°ÊÅØÊèêÂèñ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåMoTDiffÂú®Áõ≤ÂõæÂÉèÂéªÊ®°Á≥äÂíåÁºñÁ†ÅÊõùÂÖâÊëÑÂΩ±Á≠âÂ∫îÁî®‰∏≠ÔºåÊÄßËÉΩË∂ÖË∂ä‰∫ÜÁé∞ÊúâÊúÄ‰Ω≥ÊñπÊ≥ï„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Á≤æÁ°Æ‰º∞ËÆ°ËøêÂä®‰ø°ÊÅØÂú®ÂêÑÁßçËÆ°ÁÆóÊàêÂÉèÂíåËÆ°ÁÆóÊú∫ËßÜËßâÂ∫îÁî®‰∏≠Ëá≥ÂÖ≥ÈáçË¶Å„ÄÇÁ†îÁ©∂‰∫∫ÂëòÂ∑≤ÁªèÁ†îÁ©∂‰∫ÜÂ§öÁßçÊñπÊ≥ïÊù•‰ªéÂçïÂº†Ê®°Á≥äÂõæÂÉè‰∏≠ÊèêÂèñËøêÂä®‰ø°ÊÅØÔºåÂåÖÊã¨Ê®°Á≥äÊ†∏ÂíåÂÖâÊµÅ„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÁöÑËøêÂä®Ë°®Á§∫ÈÄöÂ∏∏Ë¥®ÈáèËæÉ‰ΩéÔºåÂç≥Á≤óÁ≤íÂ∫¶Âíå‰∏çÂáÜÁ°Æ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜÁ¨¨‰∏Ä‰∏™‰ΩøÁî®Êâ©Êï£Ê®°ÂûãÁöÑÈ´òÂàÜËæ®ÁéáÔºàHRÔºâËøêÂä®ËΩ®Ëøπ‰º∞ËÆ°Ê°ÜÊû∂ÔºàMoTDiffÔºâ„ÄÇ‰∏éÁé∞ÊúâÁöÑËøêÂä®Ë°®Á§∫‰∏çÂêåÔºåÊàë‰ª¨ÁöÑÁõÆÊ†áÊòØ‰ªéÂçïÂº†ËøêÂä®Ê®°Á≥äÂõæÂÉè‰∏≠‰º∞ËÆ°È´òË¥®ÈáèÁöÑHRËøêÂä®ËΩ®Ëøπ„ÄÇÊâÄÊèêÂá∫ÁöÑMoTDiffÁî±‰∏§‰∏™ÂÖ≥ÈîÆÁªÑ‰ª∂ÁªÑÊàêÔºö1Ôºâ‰∏ÄÁßçÊñ∞ÁöÑÊù°‰ª∂Êâ©Êï£Ê°ÜÊû∂ÔºåÂÆÉ‰ΩøÁî®‰ªéÂçïÂº†Ê®°Á≥äÂõæÂÉè‰∏≠ÊèêÂèñÁöÑÂ§öÂ∞∫Â∫¶ÁâπÂæÅÂõæ‰Ωú‰∏∫Êù°‰ª∂Ôºõ2Ôºâ‰∏ÄÁßçÊñ∞ÁöÑËÆ≠ÁªÉÊñπÊ≥ïÔºåÂèØ‰ª•‰øÉËøõÂØπÁªÜÁ≤íÂ∫¶ËøêÂä®ËΩ®ËøπÁöÑÁ≤æÁ°ÆËØÜÂà´ÔºåËøêÂä®Ë∑ØÂæÑÊï¥‰ΩìÂΩ¢Áä∂Âíå‰ΩçÁΩÆÁöÑ‰∏ÄËá¥‰º∞ËÆ°Ôºå‰ª•ÂèäÊ≤øËøêÂä®ËΩ®ËøπÁöÑÂÉèÁ¥†ËøûÈÄöÊÄß„ÄÇÊàë‰ª¨ÁöÑÂÆûÈ™åË°®ÊòéÔºåÊâÄÊèêÂá∫ÁöÑMoTDiffÂú®Áõ≤ÂõæÂÉèÂéªÊ®°Á≥äÂíåÁºñÁ†ÅÊõùÂÖâÊëÑÂΩ±Â∫îÁî®‰∏≠Âùá‰ºò‰∫éÊúÄÂÖàËøõÁöÑÊñπÊ≥ï„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥‰ªéÂçïÂº†Ê®°Á≥äÂõæÂÉè‰∏≠Á≤æÁ°Æ‰º∞ËÆ°È´òÂàÜËæ®ÁéáËøêÂä®ËΩ®ËøπÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÔºåÂ¶ÇÂü∫‰∫éÊ®°Á≥äÊ†∏ÊàñÂÖâÊµÅÁöÑÊñπÊ≥ïÔºåÈÄöÂ∏∏Âè™ËÉΩËé∑Âæó‰ΩéÂàÜËæ®Áéá„ÄÅÁ≤óÁ≤íÂ∫¶ÁöÑËøêÂä®‰ø°ÊÅØÔºåÊó†Ê≥ïÊª°Ë∂≥ÂØπËøêÂä®ËΩ®ËøπÁ≤æÂ∫¶Ë¶ÅÊ±ÇÈ´òÁöÑÂ∫îÁî®Âú∫ÊôØ„ÄÇËøô‰∫õÊñπÊ≥ïÂú®Â§ÑÁêÜÂ§çÊùÇËøêÂä®Êàñ‰∏•ÈáçÊ®°Á≥äÊó∂ÔºåÊÄßËÉΩ‰ºöÊòæËëó‰∏ãÈôç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Êâ©Êï£Ê®°ÂûãÂº∫Â§ßÁöÑÁîüÊàêËÉΩÂäõÔºåÂ∞ÜËøêÂä®ËΩ®Ëøπ‰º∞ËÆ°ÈóÆÈ¢òËΩ¨Âåñ‰∏∫‰∏Ä‰∏™Êù°‰ª∂ÁîüÊàêÈóÆÈ¢ò„ÄÇÈÄöËøáÂ∞ÜÊ®°Á≥äÂõæÂÉèÁöÑÂ§öÂ∞∫Â∫¶ÁâπÂæÅ‰Ωú‰∏∫Êù°‰ª∂ÔºåÂºïÂØºÊâ©Êï£Ê®°ÂûãÁîüÊàê‰∏éÊ®°Á≥äÂõæÂÉèÂØπÂ∫îÁöÑ„ÄÅÈ´òÂàÜËæ®ÁéáÁöÑËøêÂä®ËΩ®Ëøπ„ÄÇËøôÁßçÊñπÊ≥ïËÉΩÂ§üÊúâÊïàÂà©Áî®ÂõæÂÉè‰∏≠ÁöÑ‰∏ä‰∏ãÊñá‰ø°ÊÅØÔºåÂπ∂ÁîüÊàêÊõ¥ÂáÜÁ°Æ„ÄÅÊõ¥Á≤æÁªÜÁöÑËøêÂä®ËΩ®Ëøπ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöMoTDiffÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´‰∏§‰∏™‰∏ªË¶ÅÈÉ®ÂàÜÔºöÊù°‰ª∂Êâ©Êï£Ê®°ÂûãÂíåËÆ≠ÁªÉÊñπÊ≥ï„ÄÇÈ¶ñÂÖàÔºå‰ªéËæìÂÖ•ÁöÑÊ®°Á≥äÂõæÂÉè‰∏≠ÊèêÂèñÂ§öÂ∞∫Â∫¶ÁâπÂæÅÂõæÔºå‰Ωú‰∏∫Êù°‰ª∂Êâ©Êï£Ê®°ÂûãÁöÑËæìÂÖ•„ÄÇÁÑ∂ÂêéÔºåÊù°‰ª∂Êâ©Êï£Ê®°ÂûãÈÄöËøáÈÄêÊ≠•ÂéªÂô™ÁöÑËøáÁ®ãÔºå‰ªéÈöèÊú∫Âô™Â£∞‰∏≠ÁîüÊàêÈ´òÂàÜËæ®ÁéáÁöÑËøêÂä®ËΩ®Ëøπ„ÄÇËÆ≠ÁªÉÈò∂ÊÆµÔºåËÆæËÆ°‰∫ÜÊñ∞ÁöÑËÆ≠ÁªÉÊñπÊ≥ïÔºå‰ª•‰øÉËøõÁªÜÁ≤íÂ∫¶ËøêÂä®ËΩ®ËøπÁöÑËØÜÂà´„ÄÅÊï¥‰ΩìÂΩ¢Áä∂Âíå‰ΩçÁΩÆÁöÑ‰∏ÄËá¥ÊÄß‰º∞ËÆ°‰ª•ÂèäÂÉèÁ¥†ËøûÈÄöÊÄß„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöMoTDiffÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫é‰ª•‰∏ãÂá†ÁÇπÔºö1) È¶ñÊ¨°ÊèêÂá∫‰ΩøÁî®Êâ©Êï£Ê®°ÂûãËøõË°åÈ´òÂàÜËæ®ÁéáËøêÂä®ËΩ®Ëøπ‰º∞ËÆ°Ôºõ2) ËÆæËÆ°‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÊù°‰ª∂Êâ©Êï£Ê°ÜÊû∂ÔºåËÉΩÂ§üÊúâÊïàÂà©Áî®Ê®°Á≥äÂõæÂÉèÁöÑÂ§öÂ∞∫Â∫¶ÁâπÂæÅÔºõ3) ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑËÆ≠ÁªÉÊñπÊ≥ïÔºåËÉΩÂ§üÊèêÂçáËøêÂä®ËΩ®Ëøπ‰º∞ËÆ°ÁöÑÁ≤æÂ∫¶Âíå‰∏ÄËá¥ÊÄß„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåMoTDiffËÉΩÂ§üÁîüÊàêÊõ¥È´òË¥®Èáè„ÄÅÊõ¥Á≤æÁªÜÁöÑËøêÂä®ËΩ®Ëøπ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Êù°‰ª∂Êâ©Êï£Ê®°Âûã‰∏≠Ôºå‰ΩøÁî®‰∫ÜU-NetÁªìÊûÑ‰Ωú‰∏∫È™®Âπ≤ÁΩëÁªúÔºåÂπ∂Â∞ÜÊ®°Á≥äÂõæÂÉèÁöÑÂ§öÂ∞∫Â∫¶ÁâπÂæÅÂõæÈÄöËøáËá™ÈÄÇÂ∫îÁöÑÊñπÂºèÊ≥®ÂÖ•Âà∞U-NetÁöÑÂêÑ‰∏™Â±ÇÁ∫ß‰∏≠„ÄÇÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠Ôºå‰ΩøÁî®‰∫ÜÂåÖÊã¨L1ÊçüÂ§±„ÄÅÊÑüÁü•ÊçüÂ§±ÂíåÊÄªÂèòÂàÜÊçüÂ§±Âú®ÂÜÖÁöÑÂ§öÁßçÊçüÂ§±ÂáΩÊï∞Ôºå‰ª•‰øùËØÅÁîüÊàêËøêÂä®ËΩ®ËøπÁöÑÁ≤æÂ∫¶„ÄÅËßÜËßâË¥®ÈáèÂíåËøûÈÄöÊÄß„ÄÇÊ≠§Â§ñÔºåËøòËÆæËÆ°‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÊï∞ÊçÆÂ¢ûÂº∫ÊñπÊ≥ïÔºåÈÄöËøáÊ®°Êãü‰∏çÂêåÁöÑËøêÂä®ËΩ®ËøπÔºåÂ¢ûÂä†‰∫ÜËÆ≠ÁªÉÊï∞ÊçÆÁöÑÂ§öÊ†∑ÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåMoTDiffÂú®Áõ≤ÂõæÂÉèÂéªÊ®°Á≥äÂíåÁºñÁ†ÅÊõùÂÖâÊëÑÂΩ±‰ªªÂä°‰∏≠ÂùáÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇÂú®ÂêàÊàêÊï∞ÊçÆÈõÜ‰∏äÔºåMoTDiffÁöÑPSNRÂíåSSIMÊåáÊ†áÂàÜÂà´ÊØîÁé∞ÊúâÊúÄ‰Ω≥ÊñπÊ≥ïÊèêÈ´ò‰∫ÜÁ∫¶2dBÂíå0.03„ÄÇÂú®ÁúüÂÆûÊï∞ÊçÆÈõÜ‰∏äÔºåMoTDiff‰πüËÉΩÂ§üÁîüÊàêÊõ¥Ê∏ÖÊô∞„ÄÅÊõ¥ÁúüÂÆûÁöÑÂéªÊ®°Á≥äÂõæÂÉèÔºåÂπ∂ËÉΩÂ§üÊõ¥ÂáÜÁ°ÆÂú∞‰º∞ËÆ°ËøêÂä®ËΩ®Ëøπ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

MoTDiffÂú®Â§ö‰∏™È¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂåÖÊã¨Áõ≤ÂõæÂÉèÂéªÊ®°Á≥ä„ÄÅÁºñÁ†ÅÊõùÂÖâÊëÑÂΩ±„ÄÅËßÜÈ¢ëÁ®≥ÂÆö„ÄÅËøêÂä®ÂàÜÊûêÂíåÁõÆÊ†áË∑üË∏™Á≠â„ÄÇÈÄöËøáÁ≤æÁ°Æ‰º∞ËÆ°ËøêÂä®ËΩ®ËøπÔºåÂèØ‰ª•ÊúâÊïàÂéªÈô§ÂõæÂÉè‰∏≠ÁöÑËøêÂä®Ê®°Á≥äÔºåÊèêÈ´òÂõæÂÉèË¥®Èáè„ÄÇÊ≠§Â§ñÔºåËøòÂèØ‰ª•Áî®‰∫éÂàÜÊûêÁâ©‰ΩìÁöÑËøêÂä®Ê®°ÂºèÔºå‰∏∫ËøêÂä®ËßÑÂàíÂíåÊéßÂà∂Êèê‰æõ‰æùÊçÆ„ÄÇËØ•Á†îÁ©∂ÁöÑÊàêÊûúÊúâÊúõÊé®Âä®ËÆ°ÁÆóÊú∫ËßÜËßâÂíåËÆ°ÁÆóÊàêÂÉèÈ¢ÜÂüüÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Accurate estimation of motion information is crucial in diverse computational imaging and computer vision applications. Researchers have investigated various methods to extract motion information from a single blurred image, including blur kernels and optical flow. However, existing motion representations are often of low quality, i.e., coarse-grained and inaccurate. In this paper, we propose the first high-resolution (HR) Motion Trajectory estimation framework using Diffusion models (MoTDiff). Different from existing motion representations, we aim to estimate an HR motion trajectory with high-quality from a single motion-blurred image. The proposed MoTDiff consists of two key components: 1) a new conditional diffusion framework that uses multi-scale feature maps extracted from a single blurred image as a condition, and 2) a new training method that can promote precise identification of a fine-grained motion trajectory, consistent estimation of overall shape and position of a motion path, and pixel connectivity along a motion trajectory. Our experiments demonstrate that the proposed MoTDiff can outperform state-of-the-art methods in both blind image deblurring and coded exposure photography applications.

