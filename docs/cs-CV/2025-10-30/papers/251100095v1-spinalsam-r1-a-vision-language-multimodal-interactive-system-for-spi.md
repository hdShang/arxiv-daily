---
layout: default
title: "SpinalSAM-R1: A Vision-Language Multimodal Interactive System for Spine CT Segmentation"
---

# SpinalSAM-R1: A Vision-Language Multimodal Interactive System for Spine CT Segmentation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.00095" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.00095v1</a>
  <a href="https://arxiv.org/pdf/2511.00095.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.00095v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.00095v1', 'SpinalSAM-R1: A Vision-Language Multimodal Interactive System for Spine CT Segmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiaming Liu, Dingwei Fan, Junyong Zhao, Chunlin Li, Haipeng Si, Liang Sun

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-10-30

**å¤‡æ³¨**: 2 Tables,5 Figures,16 Equations

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/6jm233333/spinalsam-r1)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**SpinalSAM-R1ï¼šç”¨äºè„ŠæŸ±CTåˆ†å‰²çš„è§†è§‰-è¯­è¨€å¤šæ¨¡æ€äº¤äº’ç³»ç»Ÿ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è„ŠæŸ±CTåˆ†å‰²` `è§†è§‰-è¯­è¨€æ¨¡å‹` `å¤šæ¨¡æ€äº¤äº’` `Segment Anything Model` `DeepSeek-R1`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. è„ŠæŸ±CTå›¾åƒåˆ†å‰²é¢ä¸´ä½å¯¹æ¯”åº¦å’Œå¤æ‚è¾¹ç•Œçš„æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•éœ€è¦å¤§é‡æ ‡æ³¨ä¸”é¢†åŸŸé€‚åº”æ€§å·®ã€‚
2. SpinalSAM-R1é€šè¿‡é›†æˆå¾®è°ƒçš„SAMå’ŒDeepSeek-R1ï¼Œåˆ©ç”¨è§£å‰–å¼•å¯¼æ³¨æ„åŠ›æœºåˆ¶å’Œè¯­ä¹‰é©±åŠ¨äº¤äº’åè®®ï¼Œæå‡åˆ†å‰²æ€§èƒ½ã€‚
3. å®éªŒè¡¨æ˜SpinalSAM-R1å®ç°äº†å“è¶Šçš„åˆ†å‰²æ€§èƒ½ï¼Œå¹¶å¼€å‘äº†æ”¯æŒå¤šç§äº¤äº’æ–¹å¼çš„PyQt5è½¯ä»¶ï¼Œè§£æå‡†ç¡®ç‡è¾¾94.3%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è„ŠæŸ±åŠå…¶é‚»è¿‘ç»“æ„çš„CTå›¾åƒè§£å‰–ç»“æ„åˆ†å‰²æ˜¯è„ŠæŸ±ç–¾ç—…è¯Šæ–­å’Œæ²»ç–—çš„å…³é”®æ­¥éª¤ã€‚ç„¶è€Œï¼ŒCTå›¾åƒçš„åˆ†å‰²å—åˆ°ä½å¯¹æ¯”åº¦å’Œå¤æ‚æ¤éª¨è¾¹ç•Œçš„é˜»ç¢ã€‚å°½ç®¡è¯¸å¦‚Segment Anything Model (SAM)ç­‰å…ˆè¿›æ¨¡å‹åœ¨å„ç§åˆ†å‰²ä»»åŠ¡ä¸­æ˜¾ç¤ºå‡ºå‰æ™¯ï¼Œä½†å®ƒä»¬åœ¨è„ŠæŸ±CTæˆåƒä¸­çš„æ€§èƒ½å—åˆ°é«˜æ ‡æ³¨è¦æ±‚å’Œè¾ƒå·®é¢†åŸŸé€‚åº”æ€§çš„é™åˆ¶ã€‚ä¸ºäº†è§£å†³è¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºSpinalSAM-R1ï¼Œä¸€ä¸ªå¤šæ¨¡æ€è§†è§‰-è¯­è¨€äº¤äº’ç³»ç»Ÿï¼Œå®ƒé›†æˆäº†å¾®è°ƒçš„SAMä¸DeepSeek-R1ï¼Œç”¨äºè„ŠæŸ±CTå›¾åƒåˆ†å‰²ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„SpinalSAM-R1å¼•å…¥äº†ä¸€ç§è§£å‰–å¼•å¯¼çš„æ³¨æ„åŠ›æœºåˆ¶æ¥æé«˜è„ŠæŸ±åˆ†å‰²æ€§èƒ½ï¼Œä»¥åŠä¸€ç§ç”±DeepSeek-R1é©±åŠ¨çš„è¯­ä¹‰é©±åŠ¨çš„äº¤äº’åè®®ï¼Œä»è€Œå®ç°è‡ªç„¶è¯­è¨€å¼•å¯¼çš„ç»†åŒ–ã€‚SpinalSAM-R1ä½¿ç”¨ä½ç§©é€‚åº”(LoRA)è¿›è¡Œå¾®è°ƒï¼Œä»¥å®ç°é«˜æ•ˆé€‚åº”ã€‚æˆ‘ä»¬åœ¨è„ŠæŸ±CTå›¾åƒçš„è§£å‰–ç»“æ„ä¸ŠéªŒè¯äº†æˆ‘ä»¬çš„SpinalSAM-R1ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å®ç°äº†å“è¶Šçš„åˆ†å‰²æ€§èƒ½ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªåŸºäºPyQt5çš„äº¤äº’å¼è½¯ä»¶ï¼Œå®ƒæ”¯æŒåŸºäºç‚¹ã€æ¡†å’Œæ–‡æœ¬çš„æç¤ºã€‚è¯¥ç³»ç»Ÿæ”¯æŒ11ä¸ªä¸´åºŠæ“ä½œï¼Œè§£æå‡†ç¡®ç‡ä¸º94.3%ï¼Œå“åº”æ—¶é—´ä½äº800æ¯«ç§’ã€‚è¯¥è½¯ä»¶å·²åœ¨https://github.com/6jm233333/spinalsam-r1ä¸Šå‘å¸ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è„ŠæŸ±CTå›¾åƒåˆ†å‰²ä¸­ï¼Œç”±äºä½å¯¹æ¯”åº¦å’Œå¤æ‚æ¤éª¨è¾¹ç•Œå¯¼è‡´çš„åˆ†å‰²ç²¾åº¦ä¸é«˜çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚ç›´æ¥åº”ç”¨SAMï¼Œéœ€è¦å¤§é‡çš„æ ‡æ³¨æ•°æ®ï¼Œä¸”åœ¨è„ŠæŸ±CTå›¾åƒè¿™ç§ç‰¹å®šé¢†åŸŸè¡¨ç°ä¸ä½³ï¼Œæ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†é¢„è®­ç»ƒçš„SAMæ¨¡å‹ä¸å¤§å‹è¯­è¨€æ¨¡å‹DeepSeek-R1ç›¸ç»“åˆï¼Œæ„å»ºä¸€ä¸ªå¤šæ¨¡æ€äº¤äº’ç³»ç»Ÿã€‚é€šè¿‡å¾®è°ƒSAMï¼Œå¹¶å¼•å…¥è§£å‰–å¼•å¯¼çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œæå‡æ¨¡å‹å¯¹è„ŠæŸ±ç»“æ„çš„æ„ŸçŸ¥èƒ½åŠ›ã€‚åŒæ—¶ï¼Œåˆ©ç”¨DeepSeek-R1çš„è¯­ä¹‰ç†è§£èƒ½åŠ›ï¼Œå®ç°è‡ªç„¶è¯­è¨€å¼•å¯¼çš„åˆ†å‰²ç»†åŒ–ï¼Œé™ä½å¯¹ç²¾ç¡®æ ‡æ³¨çš„ä¾èµ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSpinalSAM-R1ç³»ç»Ÿä¸»è¦åŒ…å«ä¸‰ä¸ªæ¨¡å—ï¼š1) å¾®è°ƒçš„SAMæ¨¡å‹ï¼Œç”¨äºåˆæ­¥çš„è„ŠæŸ±åˆ†å‰²ï¼›2) è§£å‰–å¼•å¯¼çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œç”¨äºå¢å¼ºæ¨¡å‹å¯¹è„ŠæŸ±ç»“æ„çš„å…³æ³¨ï¼›3) DeepSeek-R1é©±åŠ¨çš„è¯­ä¹‰äº¤äº’æ¨¡å—ï¼Œç”¨äºæ ¹æ®ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼Œå¯¹åˆ†å‰²ç»“æœè¿›è¡Œç²¾ç»†è°ƒæ•´ã€‚æ•´ä¸ªæµç¨‹æ˜¯ï¼šç”¨æˆ·æä¾›CTå›¾åƒå’Œè‡ªç„¶è¯­è¨€æè¿°ï¼ŒSAMæ¨¡å‹è¿›è¡Œåˆæ­¥åˆ†å‰²ï¼Œæ³¨æ„åŠ›æœºåˆ¶ä¼˜åŒ–åˆ†å‰²ç»“æœï¼ŒDeepSeek-R1è§£æç”¨æˆ·æŒ‡ä»¤å¹¶æŒ‡å¯¼åˆ†å‰²ç»“æœçš„è¿›ä¸€æ­¥ç»†åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†è§†è§‰åˆ†å‰²æ¨¡å‹SAMä¸å¤§å‹è¯­è¨€æ¨¡å‹DeepSeek-R1è¿›è¡Œæœ‰æ•ˆèåˆï¼Œæ„å»ºäº†ä¸€ä¸ªå¤šæ¨¡æ€äº¤äº’ç³»ç»Ÿã€‚è¿™ç§èåˆæ–¹å¼ä¸ä»…æå‡äº†åˆ†å‰²ç²¾åº¦ï¼Œè¿˜é™ä½äº†å¯¹å¤§é‡ç²¾ç¡®æ ‡æ³¨æ•°æ®çš„éœ€æ±‚ã€‚æ­¤å¤–ï¼Œè§£å‰–å¼•å¯¼çš„æ³¨æ„åŠ›æœºåˆ¶ä¹Ÿé’ˆå¯¹è„ŠæŸ±CTå›¾åƒçš„ç‰¹ç‚¹è¿›è¡Œäº†ä¼˜åŒ–ï¼Œæé«˜äº†æ¨¡å‹å¯¹å…³é”®åŒºåŸŸçš„å…³æ³¨åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šSpinalSAM-R1ä½¿ç”¨LoRAï¼ˆLow-Rank Adaptationï¼‰è¿›è¡Œé«˜æ•ˆå¾®è°ƒï¼Œé™ä½äº†è®¡ç®—æˆæœ¬ã€‚è§£å‰–å¼•å¯¼çš„æ³¨æ„åŠ›æœºåˆ¶çš„å…·ä½“å®ç°æ–¹å¼æœªçŸ¥ï¼ˆè®ºæ–‡æœªè¯¦ç»†æè¿°ï¼‰ã€‚PyQt5äº¤äº’è½¯ä»¶æ”¯æŒç‚¹ã€æ¡†å’Œæ–‡æœ¬ä¸‰ç§æç¤ºæ–¹å¼ï¼Œæ–¹ä¾¿ç”¨æˆ·è¿›è¡Œäº¤äº’ã€‚DeepSeek-R1çš„promptè®¾è®¡å’ŒæŒ‡ä»¤è§£æç­–ç•¥æœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

SpinalSAM-R1åœ¨è„ŠæŸ±CTå›¾åƒåˆ†å‰²ä»»åŠ¡ä¸Šå–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼Œä½†å…·ä½“æŒ‡æ ‡å’Œå¯¹æ¯”åŸºçº¿æœªçŸ¥ã€‚è¯¥ç³»ç»Ÿæ”¯æŒ11ç§ä¸´åºŠæ“ä½œï¼Œè§£æå‡†ç¡®ç‡è¾¾åˆ°94.3%ï¼Œå“åº”æ—¶é—´ä½äº800æ¯«ç§’ï¼Œè¡¨æ˜å…¶å…·æœ‰è¾ƒé«˜çš„å®ç”¨ä»·å€¼å’Œäº¤äº’æ•ˆç‡ã€‚è¯¥è½¯ä»¶å·²å¼€æºï¼Œæ–¹ä¾¿å…¶ä»–ç ”ç©¶è€…è¿›è¡Œå¤ç°å’Œæ”¹è¿›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SpinalSAM-R1å¯åº”ç”¨äºè„ŠæŸ±ç–¾ç—…çš„è¾…åŠ©è¯Šæ–­ã€æ‰‹æœ¯è§„åˆ’å’Œæœ¯åè¯„ä¼°ã€‚é€šè¿‡è‡ªç„¶è¯­è¨€äº¤äº’ï¼ŒåŒ»ç”Ÿå¯ä»¥æ›´é«˜æ•ˆã€å‡†ç¡®åœ°åˆ†å‰²è„ŠæŸ±CTå›¾åƒï¼Œä»è€Œæé«˜è¯Šæ–­æ•ˆç‡å’Œæ²»ç–—æ•ˆæœã€‚è¯¥ç³»ç»Ÿæœ‰æœ›å‡å°‘äººå·¥æ ‡æ³¨çš„å·¥ä½œé‡ï¼Œå¹¶ä¸ºè¿œç¨‹åŒ»ç–—å’Œæ™ºèƒ½åŒ–åŒ»ç–—æä¾›æŠ€æœ¯æ”¯æŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The anatomical structure segmentation of the spine and adjacent structures from computed tomography (CT) images is a key step for spinal disease diagnosis and treatment. However, the segmentation of CT images is impeded by low contrast and complex vertebral boundaries. Although advanced models such as the Segment Anything Model (SAM) have shown promise in various segmentation tasks, their performance in spinal CT imaging is limited by high annotation requirements and poor domain adaptability. To address these limitations, we propose SpinalSAM-R1, a multimodal vision-language interactive system that integrates a fine-tuned SAM with DeepSeek-R1, for spine CT image segmentation. Specifically, our SpinalSAM-R1 introduces an anatomy-guided attention mechanism to improve spine segmentation performance, and a semantics-driven interaction protocol powered by DeepSeek-R1, enabling natural language-guided refinement. The SpinalSAM-R1 is fine-tuned using Low-Rank Adaptation (LoRA) for efficient adaptation. We validate our SpinalSAM-R1 on the spine anatomical structure with CT images. Experimental results suggest that our method achieves superior segmentation performance. Meanwhile, we develop a PyQt5-based interactive software, which supports point, box, and text-based prompts. The system supports 11 clinical operations with 94.3\% parsing accuracy and sub-800 ms response times. The software is released on https://github.com/6jm233333/spinalsam-r1.

