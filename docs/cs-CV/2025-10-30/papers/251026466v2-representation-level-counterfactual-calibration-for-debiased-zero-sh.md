---
layout: default
title: Representation-Level Counterfactual Calibration for Debiased Zero-Shot Recognition
---

# Representation-Level Counterfactual Calibration for Debiased Zero-Shot Recognition

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.26466" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.26466v2</a>
  <a href="https://arxiv.org/pdf/2510.26466.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.26466v2" onclick="toggleFavorite(this, '2510.26466v2', 'Representation-Level Counterfactual Calibration for Debiased Zero-Shot Recognition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Pei Peng, MingKun Xie, Hang Hao, Tong Jin, ShengJun Huang

**åˆ†ç±»**: cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-10-30 (æ›´æ–°: 2025-11-03)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè¡¨å¾çº§åäº‹å®æ ¡å‡†æ–¹æ³•ï¼Œè§£å†³é›¶æ ·æœ¬è¯†åˆ«ä¸­çš„ä¸Šä¸‹æ–‡åå·®é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é›¶æ ·æœ¬å­¦ä¹ ` `åäº‹å®æ¨ç†` `å› æœæ¨æ–­` `ä¸Šä¸‹æ–‡åå·®` `è§†è§‰-è¯­è¨€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. è§†è§‰-è¯­è¨€æ¨¡å‹æ˜“å—å¯¹è±¡-ä¸Šä¸‹æ–‡æ·å¾„çš„å½±å“ï¼Œå¯¼è‡´é›¶æ ·æœ¬è¯†åˆ«åœ¨ä¸åŒåœºæ™¯ä¸‹è¡¨ç°ä¸ä½³ã€‚
2. é€šè¿‡åœ¨CLIPè¡¨å¾ç©ºé—´ä¸­åˆæˆåäº‹å®åµŒå…¥ï¼Œæ¨¡æ‹Ÿå¯¹è±¡åœ¨ä¸åŒä¸Šä¸‹æ–‡ä¸­çš„è¡¨ç°ï¼Œä»è€Œå‡è½»ä¸Šä¸‹æ–‡åå·®ã€‚
3. è¯¥æ–¹æ³•æ— éœ€é‡æ–°è®­ç»ƒæˆ–æç¤ºè®¾è®¡ï¼Œåœ¨ä¸Šä¸‹æ–‡æ•æ„ŸåŸºå‡†ä¸Šæ˜¾è‘—æå‡äº†é›¶æ ·æœ¬è¯†åˆ«çš„å‡†ç¡®ç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€æ¨¡å‹ä¸­çš„å¯¹è±¡-ä¸Šä¸‹æ–‡æ·å¾„æ˜¯ä¸€ä¸ªæŒç»­å­˜åœ¨çš„æŒ‘æˆ˜ï¼Œå½“æµ‹è¯•åœºæ™¯ä¸ç†Ÿæ‚‰çš„è®­ç»ƒå…±ç°ä¸åŒæ—¶ï¼Œä¼šæŸå®³é›¶æ ·æœ¬çš„å¯é æ€§ã€‚æœ¬æ–‡å°†æ­¤é—®é¢˜é‡æ–°å®šä¹‰ä¸ºå› æœæ¨æ–­é—®é¢˜ï¼Œå¹¶æå‡ºï¼šå¦‚æœå¯¹è±¡å‡ºç°åœ¨ä¸åŒçš„ç¯å¢ƒä¸­ï¼Œé¢„æµ‹ç»“æœæ˜¯å¦ä»ç„¶æˆç«‹ï¼Ÿä¸ºäº†åœ¨æ¨ç†æ—¶å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œæœ¬æ–‡ä¼°è®¡CLIPè¡¨å¾ç©ºé—´ä¸­çš„å¯¹è±¡å’ŒèƒŒæ™¯æœŸæœ›ï¼Œå¹¶é€šè¿‡å°†å¯¹è±¡ç‰¹å¾ä¸æ¥è‡ªå¤–éƒ¨æ•°æ®é›†ã€æ‰¹é‚»å±…æˆ–æ–‡æœ¬æè¿°çš„å¤šæ ·åŒ–æ›¿ä»£ä¸Šä¸‹æ–‡é‡æ–°ç»„åˆæ¥åˆæˆåäº‹å®åµŒå…¥ã€‚é€šè¿‡ä¼°è®¡æ€»ç›´æ¥æ•ˆåº”å¹¶æ¨¡æ‹Ÿå¹²é¢„ï¼Œè¿›ä¸€æ­¥å‡å»ä»…èƒŒæ™¯æ¿€æ´»ï¼Œä¿ç•™æœ‰ç›Šçš„å¯¹è±¡-ä¸Šä¸‹æ–‡äº¤äº’ï¼ŒåŒæ—¶å‡è½»å¹»è§‰åˆ†æ•°ã€‚æ— éœ€é‡æ–°è®­ç»ƒæˆ–æç¤ºè®¾è®¡ï¼Œæœ¬æ–‡çš„æ–¹æ³•æ˜¾è‘—æé«˜äº†ä¸Šä¸‹æ–‡æ•æ„ŸåŸºå‡†ä¸Šçš„æœ€å·®ç»„å’Œå¹³å‡å‡†ç¡®ç‡ï¼Œå»ºç«‹äº†æ–°çš„é›¶æ ·æœ¬æŠ€æœ¯æ°´å¹³ã€‚é™¤äº†æ€§èƒ½ä¹‹å¤–ï¼Œæœ¬æ–‡çš„æ¡†æ¶è¿˜æä¾›äº†ä¸€ç§è½»é‡çº§çš„è¡¨å¾çº§åäº‹å®æ–¹æ³•ï¼Œä¸ºå»åå’Œå¯é çš„å¤šæ¨¡æ€æ¨ç†æä¾›äº†ä¸€ç§å®ç”¨çš„å› æœé€”å¾„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨é›¶æ ·æœ¬è¯†åˆ«ä¸­ï¼Œå®¹æ˜“å—åˆ°è®­ç»ƒæ•°æ®ä¸­å¯¹è±¡ä¸ä¸Šä¸‹æ–‡ä¹‹é—´è™šå‡ç›¸å…³æ€§çš„å½±å“ï¼Œå³â€œå¯¹è±¡-ä¸Šä¸‹æ–‡æ·å¾„â€ã€‚å½“æµ‹è¯•åœºæ™¯çš„ä¸Šä¸‹æ–‡ä¸è®­ç»ƒæ•°æ®ä¸åŒæ—¶ï¼Œæ¨¡å‹ä¼šé”™è¯¯åœ°å°†ä¸Šä¸‹æ–‡ä¿¡æ¯ä½œä¸ºé¢„æµ‹çš„å…³é”®ä¾æ®ï¼Œå¯¼è‡´æ³›åŒ–èƒ½åŠ›ä¸‹é™ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦é‡æ–°è®­ç»ƒæ¨¡å‹æˆ–è¿›è¡Œå¤æ‚çš„æç¤ºå·¥ç¨‹ï¼Œæˆæœ¬è¾ƒé«˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†é›¶æ ·æœ¬è¯†åˆ«ä¸­çš„ä¸Šä¸‹æ–‡åå·®é—®é¢˜è§†ä¸ºä¸€ä¸ªå› æœæ¨æ–­é—®é¢˜ã€‚é€šè¿‡åäº‹å®æ¨ç†ï¼Œæ¨¡æ‹Ÿå¦‚æœå¯¹è±¡å‡ºç°åœ¨ä¸åŒçš„ä¸Šä¸‹æ–‡ä¸­ï¼Œæ¨¡å‹åº”è¯¥å¦‚ä½•é¢„æµ‹ã€‚å…·ä½“æ¥è¯´ï¼Œé€šè¿‡åœ¨CLIPçš„è¡¨å¾ç©ºé—´ä¸­ï¼Œå°†å¯¹è±¡çš„è§†è§‰ç‰¹å¾ä¸ä¸åŒçš„èƒŒæ™¯ä¸Šä¸‹æ–‡ç‰¹å¾è¿›è¡Œç»„åˆï¼Œç”Ÿæˆåäº‹å®æ ·æœ¬ï¼Œä»è€Œæ¶ˆé™¤æ¨¡å‹å¯¹åŸå§‹ä¸Šä¸‹æ–‡çš„ä¾èµ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) **è¡¨å¾æå–**ï¼šä½¿ç”¨CLIPæ¨¡å‹æå–å›¾åƒä¸­å¯¹è±¡å’ŒèƒŒæ™¯çš„è§†è§‰è¡¨å¾ã€‚2) **ä¸Šä¸‹æ–‡é‡‡æ ·**ï¼šä»å¤–éƒ¨æ•°æ®é›†ã€æ‰¹é‚»å±…æˆ–æ–‡æœ¬æè¿°ä¸­é‡‡æ ·ä¸åŒçš„èƒŒæ™¯ä¸Šä¸‹æ–‡è¡¨å¾ã€‚3) **åäº‹å®åˆæˆ**ï¼šå°†å¯¹è±¡è¡¨å¾ä¸é‡‡æ ·çš„èƒŒæ™¯ä¸Šä¸‹æ–‡è¡¨å¾è¿›è¡Œç»„åˆï¼Œç”Ÿæˆåäº‹å®åµŒå…¥ã€‚4) **å› æœå¹²é¢„**ï¼šé€šè¿‡ä¼°è®¡æ€»ç›´æ¥æ•ˆåº”ï¼ˆTotal Direct Effectï¼‰å¹¶æ¨¡æ‹Ÿå¹²é¢„ï¼Œå‡å»ä»…èƒŒæ™¯æ¿€æ´»ï¼Œä¿ç•™æœ‰ç›Šçš„å¯¹è±¡-ä¸Šä¸‹æ–‡äº¤äº’ã€‚5) **é¢„æµ‹**ï¼šä½¿ç”¨ä¿®æ­£åçš„è¡¨å¾è¿›è¡Œé›¶æ ·æœ¬é¢„æµ‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ä¸€ä¸ªè½»é‡çº§çš„è¡¨å¾çº§åäº‹å®æ ¡å‡†æ¡†æ¶ï¼Œå¯ä»¥åœ¨ä¸é‡æ–°è®­ç»ƒæ¨¡å‹æˆ–è¿›è¡Œæç¤ºè®¾è®¡çš„æƒ…å†µä¸‹ï¼Œæœ‰æ•ˆåœ°æ¶ˆé™¤é›¶æ ·æœ¬è¯†åˆ«ä¸­çš„ä¸Šä¸‹æ–‡åå·®ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•æ›´åŠ é«˜æ•ˆå’Œçµæ´»ï¼Œå¯ä»¥ç›´æ¥åº”ç”¨äºé¢„è®­ç»ƒçš„è§†è§‰-è¯­è¨€æ¨¡å‹ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨åäº‹å®åˆæˆé˜¶æ®µï¼Œä½¿ç”¨äº†ä¸åŒçš„ä¸Šä¸‹æ–‡é‡‡æ ·ç­–ç•¥ï¼ŒåŒ…æ‹¬ä»å¤–éƒ¨æ•°æ®é›†ã€æ‰¹é‚»å±…å’Œæ–‡æœ¬æè¿°ä¸­é‡‡æ ·ã€‚åœ¨å› æœå¹²é¢„é˜¶æ®µï¼Œé€šè¿‡ä¼°è®¡æ€»ç›´æ¥æ•ˆåº”æ¥è¡¡é‡å¯¹è±¡ç‰¹å¾å¯¹é¢„æµ‹ç»“æœçš„ç›´æ¥å½±å“ï¼Œå¹¶å‡å»ä»…èƒŒæ™¯æ¿€æ´»ï¼Œä»è€Œä¿ç•™æœ‰ç›Šçš„å¯¹è±¡-ä¸Šä¸‹æ–‡äº¤äº’ã€‚å…·ä½“æ¥è¯´ï¼Œæ€»ç›´æ¥æ•ˆåº”çš„è®¡ç®—å…¬å¼ä¸ºï¼šTDE = E[Y(X=x', Z=z) - Y(X=x, Z=z)]ï¼Œå…¶ä¸­Xè¡¨ç¤ºå¯¹è±¡ç‰¹å¾ï¼ŒZè¡¨ç¤ºèƒŒæ™¯ç‰¹å¾ï¼ŒYè¡¨ç¤ºé¢„æµ‹ç»“æœï¼Œx'è¡¨ç¤ºå¹²é¢„åçš„å¯¹è±¡ç‰¹å¾ï¼Œxè¡¨ç¤ºåŸå§‹å¯¹è±¡ç‰¹å¾ï¼Œzè¡¨ç¤ºåŸå§‹èƒŒæ™¯ç‰¹å¾ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥æ–¹æ³•åœ¨å¤šä¸ªä¸Šä¸‹æ–‡æ•æ„Ÿçš„é›¶æ ·æœ¬è¯†åˆ«åŸºå‡†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼ŒåŒ…æ‹¬åœ¨Worst-Group Accuracyå’ŒAverage Accuracyä¸Šå‡è¶…è¶Šäº†ç°æœ‰æ–¹æ³•ï¼Œå»ºç«‹äº†æ–°çš„é›¶æ ·æœ¬æŠ€æœ¯æ°´å¹³ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°æ¶ˆé™¤ä¸Šä¸‹æ–‡åå·®ï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶ä¸”æ— éœ€é‡æ–°è®­ç»ƒæˆ–æç¤ºè®¾è®¡ï¼Œå…·æœ‰å¾ˆé«˜çš„å®ç”¨ä»·å€¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºé›¶æ ·æœ¬å›¾åƒè¯†åˆ«ã€å›¾åƒæ£€ç´¢ã€è§†è§‰é—®ç­”ç­‰é¢†åŸŸï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦æ¨¡å‹å…·å¤‡é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›çš„åœºæ™¯ä¸‹ã€‚ä¾‹å¦‚ï¼Œåœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸï¼Œæ¨¡å‹éœ€è¦è¯†åˆ«å„ç§å¤æ‚ç¯å¢ƒä¸‹çš„äº¤é€šæ ‡å¿—å’Œè¡Œäººï¼Œè¯¥æ–¹æ³•å¯ä»¥æé«˜æ¨¡å‹åœ¨ä¸åŒå…‰ç…§ã€å¤©æ°”æ¡ä»¶ä¸‹çš„è¯†åˆ«å‡†ç¡®ç‡ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥åº”ç”¨äºåŒ»ç–—å›¾åƒåˆ†æã€é¥æ„Ÿå›¾åƒè§£è¯‘ç­‰é¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Object-context shortcuts remain a persistent challenge in vision-language models, undermining zero-shot reliability when test-time scenes differ from familiar training co-occurrences. We recast this issue as a causal inference problem and ask: Would the prediction remain if the object appeared in a different environment? To answer this at inference time, we estimate object and background expectations within CLIP's representation space, and synthesize counterfactual embeddings by recombining object features with diverse alternative contexts sampled from external datasets, batch neighbors, or text-derived descriptions. By estimating the Total Direct Effect and simulating intervention, we further subtract background-only activation, preserving beneficial object-context interactions while mitigating hallucinated scores. Without retraining or prompt design, our method substantially improves both worst-group and average accuracy on context-sensitive benchmarks, establishing a new zero-shot state of the art. Beyond performance, our framework provides a lightweight representation-level counterfactual approach, offering a practical causal avenue for debiased and reliable multimodal reasoning.

