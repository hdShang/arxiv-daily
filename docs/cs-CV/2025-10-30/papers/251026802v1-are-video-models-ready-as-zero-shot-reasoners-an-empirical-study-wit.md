---
layout: default
title: Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study with the MME-CoF Benchmark
---

# Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study with the MME-CoF Benchmark

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.26802" target="_blank" class="toolbar-btn">arXiv: 2510.26802v1</a>
    <a href="https://arxiv.org/pdf/2510.26802.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.26802v1" 
            onclick="toggleFavorite(this, '2510.26802v1', 'Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study with the MME-CoF Benchmark')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Ziyu Guo, Xinyan Chen, Renrui Zhang, Ruichuan An, Yu Qi, Dongzhi Jiang, Xiangtai Li, Manyuan Zhang, Hongsheng Li, Pheng-Ann Heng

**ÂàÜÁ±ª**: cs.CV, cs.AI, cs.CL

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-30

**Â§áÊ≥®**: Project Page: https://video-cof.github.io

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ËØÑ‰º∞ËßÜÈ¢ëÊ®°ÂûãÈõ∂Ê†∑Êú¨Êé®ÁêÜËÉΩÂäõÔºöÊèêÂá∫MME-CoFÂü∫ÂáÜÂπ∂ÂàÜÊûêVeo-3ÁöÑÊé®ÁêÜÂ±ÄÈôêÊÄß**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)**

**ÂÖ≥ÈîÆËØç**: `ËßÜÈ¢ëÊ®°Âûã` `Èõ∂Ê†∑Êú¨Êé®ÁêÜ` `ËßÜËßâÊé®ÁêÜ` `MME-CoFÂü∫ÂáÜ` `Veo-3` `ËßÜÈ¢ëÁîüÊàê` `Âõ†ÊûúÊé®ÁêÜ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËßÜÈ¢ëÁîüÊàêÊ®°ÂûãÂú®ËßÜËßâÊÑüÁü•ÂíåÂª∫Ê®°ÊñπÈù¢Â±ïÁé∞ÊΩúÂäõÔºå‰ΩÜÂÖ∂Èõ∂Ê†∑Êú¨Êé®ÁêÜËÉΩÂäõÂ∞ö‰∏çÊòéÁ°ÆÔºåÈù¢‰∏¥ÊåëÊàò„ÄÇ
2. ËÆ∫ÊñáÈÄöËøáÊûÑÂª∫MME-CoFÂü∫ÂáÜÔºåÁ≥ªÁªüËØÑ‰º∞‰∫ÜVeo-3Âú®Â§öÁßçÊé®ÁêÜÁª¥Â∫¶‰∏äÁöÑË°®Áé∞ÔºåÊè≠Á§∫ÂÖ∂‰ºòÂäø‰∏é‰∏çË∂≥„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåËßÜÈ¢ëÊ®°ÂûãÂú®Áü≠Á®ãÁ©∫Èó¥Êé®ÁêÜË°®Áé∞ËâØÂ•ΩÔºå‰ΩÜÂú®ÈïøÁ®ãÂõ†ÊûúÊé®ÁêÜÂíåÊäΩË±°ÈÄªËæëÊñπÈù¢Â≠òÂú®Â±ÄÈôêÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÊúÄËøëÁöÑËßÜÈ¢ëÁîüÊàêÊ®°ÂûãËÉΩÂ§ü‰∫ßÁîüÈ´ò‰øùÁúü„ÄÅÊó∂Èó¥ËøûË¥ØÁöÑËßÜÈ¢ëÔºåË°®ÊòéÂÆÉ‰ª¨ÂèØËÉΩÁºñÁ†Å‰∫ÜÂ§ßÈáèÁöÑ‰∏ñÁïåÁü•ËØÜ„ÄÇÈô§‰∫ÜÈÄºÁúüÁöÑÂêàÊàê‰πãÂ§ñÔºåÂÆÉ‰ª¨ËøòË°®Áé∞Âá∫ËßÜËßâÊÑüÁü•„ÄÅÂª∫Ê®°ÂíåÊìç‰ΩúÁöÑÊñ∞ÂÖ¥Ë°å‰∏∫„ÄÇÁÑ∂ËÄåÔºå‰∏Ä‰∏™ÈáçË¶ÅÁöÑÈóÆÈ¢ò‰ªçÁÑ∂Â≠òÂú®ÔºöËßÜÈ¢ëÊ®°ÂûãÊòØÂê¶Â∑≤ÂáÜÂ§áÂ•ΩÂú®ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑËßÜËßâÊé®ÁêÜÂú∫ÊôØ‰∏≠ÂÖÖÂΩìÈõ∂Ê†∑Êú¨Êé®ÁêÜÂô®ÔºüÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨ËøõË°å‰∫Ü‰∏ÄÈ°πÂÆûËØÅÁ†îÁ©∂Ôºå‰ª•ÂÖ®Èù¢Ë∞ÉÊü•Ëøô‰∏™ÈóÆÈ¢òÔºåÈáçÁÇπÂÖ≥Ê≥®È¢ÜÂÖà‰∏îÊµÅË°åÁöÑVeo-3„ÄÇÊàë‰ª¨ËØÑ‰º∞‰∫ÜÂÆÉÂú®12‰∏™Áª¥Â∫¶‰∏äÁöÑÊé®ÁêÜË°å‰∏∫ÔºåÂåÖÊã¨Á©∫Èó¥„ÄÅÂá†‰Ωï„ÄÅÁâ©ÁêÜ„ÄÅÊó∂Èó¥ÂíåÂÖ∑Ë∫´ÈÄªËæëÔºåÁ≥ªÁªüÂú∞ÊèèËø∞‰∫ÜÂÆÉÁöÑ‰ºòÂäøÂíåÂ§±Ë¥•Ê®°Âºè„ÄÇ‰∏∫‰∫ÜÊ†áÂáÜÂåñËøôÈ°πÁ†îÁ©∂ÔºåÊàë‰ª¨Â∞ÜËØÑ‰º∞Êï∞ÊçÆÊï¥ÁêÜÊàêMME-CoFÔºåËøôÊòØ‰∏Ä‰∏™Á¥ßÂáëÁöÑÂü∫ÂáÜÔºåÂèØ‰ª•ÂØπÂ∏ßÈìæÔºàCoFÔºâÊé®ÁêÜËøõË°åÊ∑±ÂÖ•ËÄåÂΩªÂ∫ïÁöÑËØÑ‰º∞„ÄÇÊàë‰ª¨ÁöÑÁ†îÁ©∂ÁªìÊûúË°®ÊòéÔºåËôΩÁÑ∂ÂΩìÂâçÁöÑËßÜÈ¢ëÊ®°ÂûãÂú®Áü≠Á®ãÁ©∫Èó¥ËøûË¥ØÊÄß„ÄÅÁ≤æÁªÜÁöÑ grounding ÂíåÂ±ÄÈÉ®‰∏ÄËá¥ÁöÑÂä®ÊÄÅÊñπÈù¢Ë°®Áé∞Âá∫ÊúâÂ∏åÊúõÁöÑÊé®ÁêÜÊ®°ÂºèÔºå‰ΩÜÂÆÉ‰ª¨Âú®ÈïøÁ®ãÂõ†ÊûúÊé®ÁêÜ„ÄÅ‰∏•Ê†ºÁöÑÂá†‰ΩïÁ∫¶ÊùüÂíåÊäΩË±°ÈÄªËæëÊñπÈù¢‰ªçÁÑ∂ÂèóÂà∞ÈôêÂà∂„ÄÇÊÄªÁöÑÊù•ËØ¥ÔºåÂÆÉ‰ª¨Ëøò‰∏çËÉΩ‰Ωú‰∏∫Áã¨Á´ãÁöÑÈõ∂Ê†∑Êú¨Êé®ÁêÜÂô®Ôºå‰ΩÜ‰Ωú‰∏∫‰∏ìÁî®Êé®ÁêÜÊ®°ÂûãÁöÑË°•ÂÖÖËßÜËßâÂºïÊìéÔºåÂÆÉ‰ª¨Ë°®Áé∞Âá∫‰ª§‰∫∫ÈºìËàûÁöÑËøπË±°„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®ËØÑ‰º∞ÂΩìÂâçÂÖàËøõÁöÑËßÜÈ¢ëÁîüÊàêÊ®°ÂûãÔºàÂ¶ÇVeo-3ÔºâÊòØÂê¶ÂÖ∑Â§áÂú®Â§çÊùÇËßÜËßâÊé®ÁêÜ‰ªªÂä°‰∏≠ËøõË°åÈõ∂Ê†∑Êú¨Êé®ÁêÜÁöÑËÉΩÂäõ„ÄÇÁé∞ÊúâÊñπÊ≥ïÁº∫‰πèÂØπËßÜÈ¢ëÊ®°ÂûãÊé®ÁêÜËÉΩÂäõÁöÑÁ≥ªÁªüÊÄßËØÑ‰º∞ÔºåÈöæ‰ª•‰∫ÜËß£ÂÖ∂Âú®‰∏çÂêåÊé®ÁêÜÁª¥Â∫¶‰∏äÁöÑ‰ºòÁº∫ÁÇπ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÊûÑÂª∫‰∏Ä‰∏™‰∏ìÈó®ÁöÑËØÑ‰º∞Âü∫ÂáÜMME-CoFÔºåÂπ∂ËÆæËÆ°‰∏ÄÁ≥ªÂàóÈíàÂØπ‰∏çÂêåÊé®ÁêÜÁª¥Â∫¶ÁöÑÊµãËØïÁî®‰æãÔºåÊù•Á≥ªÁªüÊÄßÂú∞ËØÑ‰º∞ËßÜÈ¢ëÊ®°ÂûãÂú®Èõ∂Ê†∑Êú¨Êù°‰ª∂‰∏ãÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇÈÄöËøáÂàÜÊûêÊ®°ÂûãÂú®‰∏çÂêåÁª¥Â∫¶‰∏äÁöÑË°®Áé∞ÔºåÊè≠Á§∫ÂÖ∂‰ºòÂäøÂíåÂ±ÄÈôêÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËÆ∫Êñá‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Èò∂ÊÆµÔºö1) ÈÄâÊã©‰ª£Ë°®ÊÄßÁöÑËßÜÈ¢ëÁîüÊàêÊ®°ÂûãVeo-3‰Ωú‰∏∫ËØÑ‰º∞ÂØπË±°„ÄÇ2) ÊûÑÂª∫MME-CoFÂü∫ÂáÜÔºåËØ•Âü∫ÂáÜÂåÖÂê´12‰∏™Êé®ÁêÜÁª¥Â∫¶ÔºåÊ∂µÁõñÁ©∫Èó¥„ÄÅÂá†‰Ωï„ÄÅÁâ©ÁêÜ„ÄÅÊó∂Èó¥ÂíåÂÖ∑Ë∫´ÈÄªËæëÁ≠â„ÄÇ3) ËÆæËÆ°ÈíàÂØπÊØè‰∏™Êé®ÁêÜÁª¥Â∫¶ÁöÑÊµãËØïÁî®‰æãÔºåÂπ∂ÁîüÊàêÁõ∏Â∫îÁöÑËßÜÈ¢ëÊèêÁ§∫„ÄÇ4) ‰ΩøÁî®Veo-3ÁîüÊàêËßÜÈ¢ëÔºåÂπ∂ËØÑ‰º∞ÂÖ∂Âú®ÊØè‰∏™ÊµãËØïÁî®‰æã‰∏äÁöÑË°®Áé∞„ÄÇ5) ÂàÜÊûêÂÆûÈ™åÁªìÊûúÔºåÊÄªÁªìVeo-3Âú®‰∏çÂêåÊé®ÁêÜÁª¥Â∫¶‰∏äÁöÑ‰ºòÂäøÂíå‰∏çË∂≥„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫ÜMME-CoFÂü∫ÂáÜÔºåËøôÊòØ‰∏Ä‰∏™‰∏ìÈó®Áî®‰∫éËØÑ‰º∞ËßÜÈ¢ëÊ®°ÂûãÈõ∂Ê†∑Êú¨Êé®ÁêÜËÉΩÂäõÁöÑÁ¥ßÂáëÂûãÂü∫ÂáÜ„ÄÇ‰∏éÁé∞ÊúâÁöÑËßÜÈ¢ëÁêÜËß£Âü∫ÂáÜ‰∏çÂêåÔºåMME-CoFÊõ¥Âä†ÂÖ≥Ê≥®Ê®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõÔºåÂπ∂ËÆæËÆ°‰∫ÜÈíàÂØπ‰∏çÂêåÊé®ÁêÜÁª¥Â∫¶ÁöÑÊµãËØïÁî®‰æãÔºå‰ªéËÄåËÉΩÂ§üÊõ¥ÂÖ®Èù¢Âú∞ËØÑ‰º∞ËßÜÈ¢ëÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöMME-CoFÂü∫ÂáÜÂåÖÂê´12‰∏™Êé®ÁêÜÁª¥Â∫¶ÔºåÊØè‰∏™Áª¥Â∫¶ÈÉΩËÆæËÆ°‰∫ÜÂ§ö‰∏™ÊµãËØïÁî®‰æã„ÄÇÊµãËØïÁî®‰æãÁöÑËÆæËÆ°ËÄÉËôë‰∫ÜËßÜÈ¢ëÁöÑÊó∂Â∫èÊÄßÂíåÂõ†ÊûúÂÖ≥Á≥ªÔºåË¶ÅÊ±ÇÊ®°ÂûãËÉΩÂ§üÁêÜËß£ËßÜÈ¢ë‰∏≠ÁöÑÁâ©‰Ωì„ÄÅÂÖ≥Á≥ªÂíå‰∫ã‰ª∂ÔºåÂπ∂ËøõË°åÊé®ÁêÜ„ÄÇËØÑ‰º∞ÊåáÊ†áÂåÖÊã¨ÂáÜÁ°ÆÁéá„ÄÅÂè¨ÂõûÁéáÁ≠âÔºåÁî®‰∫éË°°ÈáèÊ®°ÂûãÂú®ÊØè‰∏™ÊµãËØïÁî®‰æã‰∏äÁöÑË°®Áé∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåVeo-3Âú®Áü≠Á®ãÁ©∫Èó¥ËøûË¥ØÊÄß„ÄÅÁ≤æÁªÜÁöÑ grounding ÂíåÂ±ÄÈÉ®‰∏ÄËá¥ÁöÑÂä®ÊÄÅÊñπÈù¢Ë°®Áé∞Âá∫ÊúâÂ∏åÊúõÁöÑÊé®ÁêÜÊ®°Âºè„ÄÇÁÑ∂ËÄåÔºåÂú®ÈïøÁ®ãÂõ†ÊûúÊé®ÁêÜ„ÄÅ‰∏•Ê†ºÁöÑÂá†‰ΩïÁ∫¶ÊùüÂíåÊäΩË±°ÈÄªËæëÊñπÈù¢‰ªçÁÑ∂Â≠òÂú®ÊòæËëóÁöÑÂ±ÄÈôêÊÄß„ÄÇMME-CoFÂü∫ÂáÜÁöÑËØÑ‰º∞ÁªìÊûú‰∏∫ÂêéÁª≠Á†îÁ©∂Êèê‰æõ‰∫ÜÈáçË¶ÅÁöÑÂèÇËÄÉ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éËØÑ‰º∞ÂíåÊîπËøõËßÜÈ¢ëÁîüÊàêÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõÔºåÊé®Âä®ËßÜÈ¢ëÊ®°ÂûãÂú®Êô∫ËÉΩÁõëÊéß„ÄÅËá™Âä®È©æÈ©∂„ÄÅÊú∫Âô®‰∫∫ÂØºËà™Á≠âÈ¢ÜÂüüÁöÑÂ∫îÁî®„ÄÇÈÄöËøá‰∫ÜËß£ËßÜÈ¢ëÊ®°ÂûãÁöÑÊé®ÁêÜÂ±ÄÈôêÊÄßÔºåÂèØ‰ª•Êõ¥Â•ΩÂú∞Â∞ÜÂÖ∂‰∏é‰∏ìÁî®Êé®ÁêÜÊ®°ÂûãÁªìÂêàÔºåÊûÑÂª∫Êõ¥Âº∫Â§ßÁöÑËßÜËßâÊô∫ËÉΩÁ≥ªÁªü„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Recent video generation models can produce high-fidelity, temporally coherent videos, indicating that they may encode substantial world knowledge. Beyond realistic synthesis, they also exhibit emerging behaviors indicative of visual perception, modeling, and manipulation. Yet, an important question still remains: Are video models ready to serve as zero-shot reasoners in challenging visual reasoning scenarios? In this work, we conduct an empirical study to comprehensively investigate this question, focusing on the leading and popular Veo-3. We evaluate its reasoning behavior across 12 dimensions, including spatial, geometric, physical, temporal, and embodied logic, systematically characterizing both its strengths and failure modes. To standardize this study, we curate the evaluation data into MME-CoF, a compact benchmark that enables in-depth and thorough assessment of Chain-of-Frame (CoF) reasoning. Our findings reveal that while current video models demonstrate promising reasoning patterns on short-horizon spatial coherence, fine-grained grounding, and locally consistent dynamics, they remain limited in long-horizon causal reasoning, strict geometric constraints, and abstract logic. Overall, they are not yet reliable as standalone zero-shot reasoners, but exhibit encouraging signs as complementary visual engines alongside dedicated reasoning models. Project page: https://video-cof.github.io

