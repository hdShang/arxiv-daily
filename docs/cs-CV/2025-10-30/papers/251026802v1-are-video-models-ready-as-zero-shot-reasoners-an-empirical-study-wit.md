---
layout: default
title: Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study with the MME-CoF Benchmark
---

# Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study with the MME-CoF Benchmark

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.26802" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.26802v1</a>
  <a href="https://arxiv.org/pdf/2510.26802.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.26802v1" onclick="toggleFavorite(this, '2510.26802v1', 'Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study with the MME-CoF Benchmark')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ziyu Guo, Xinyan Chen, Renrui Zhang, Ruichuan An, Yu Qi, Dongzhi Jiang, Xiangtai Li, Manyuan Zhang, Hongsheng Li, Pheng-Ann Heng

**åˆ†ç±»**: cs.CV, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-10-30

**å¤‡æ³¨**: Project Page: https://video-cof.github.io

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°è§†é¢‘æ¨¡å‹é›¶æ ·æœ¬æ¨ç†èƒ½åŠ›ï¼šæå‡ºMME-CoFåŸºå‡†å¹¶åˆ†æVeo-3çš„æ¨ç†å±€é™æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `è§†é¢‘æ¨¡å‹` `é›¶æ ·æœ¬æ¨ç†` `è§†è§‰æ¨ç†` `MME-CoFåŸºå‡†` `Veo-3` `è§†é¢‘ç”Ÿæˆ` `å› æœæ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†é¢‘ç”Ÿæˆæ¨¡å‹åœ¨è§†è§‰æ„ŸçŸ¥å’Œå»ºæ¨¡æ–¹é¢å±•ç°æ½œåŠ›ï¼Œä½†å…¶é›¶æ ·æœ¬æ¨ç†èƒ½åŠ›å°šä¸æ˜ç¡®ï¼Œé¢ä¸´æŒ‘æˆ˜ã€‚
2. è®ºæ–‡é€šè¿‡æ„å»ºMME-CoFåŸºå‡†ï¼Œç³»ç»Ÿè¯„ä¼°äº†Veo-3åœ¨å¤šç§æ¨ç†ç»´åº¦ä¸Šçš„è¡¨ç°ï¼Œæ­ç¤ºå…¶ä¼˜åŠ¿ä¸ä¸è¶³ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè§†é¢‘æ¨¡å‹åœ¨çŸ­ç¨‹ç©ºé—´æ¨ç†è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨é•¿ç¨‹å› æœæ¨ç†å’ŒæŠ½è±¡é€»è¾‘æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ€è¿‘çš„è§†é¢‘ç”Ÿæˆæ¨¡å‹èƒ½å¤Ÿäº§ç”Ÿé«˜ä¿çœŸã€æ—¶é—´è¿è´¯çš„è§†é¢‘ï¼Œè¡¨æ˜å®ƒä»¬å¯èƒ½ç¼–ç äº†å¤§é‡çš„ä¸–ç•ŒçŸ¥è¯†ã€‚é™¤äº†é€¼çœŸçš„åˆæˆä¹‹å¤–ï¼Œå®ƒä»¬è¿˜è¡¨ç°å‡ºè§†è§‰æ„ŸçŸ¥ã€å»ºæ¨¡å’Œæ“ä½œçš„æ–°å…´è¡Œä¸ºã€‚ç„¶è€Œï¼Œä¸€ä¸ªé‡è¦çš„é—®é¢˜ä»ç„¶å­˜åœ¨ï¼šè§†é¢‘æ¨¡å‹æ˜¯å¦å·²å‡†å¤‡å¥½åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„è§†è§‰æ¨ç†åœºæ™¯ä¸­å……å½“é›¶æ ·æœ¬æ¨ç†å™¨ï¼Ÿåœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è¿›è¡Œäº†ä¸€é¡¹å®è¯ç ”ç©¶ï¼Œä»¥å…¨é¢è°ƒæŸ¥è¿™ä¸ªé—®é¢˜ï¼Œé‡ç‚¹å…³æ³¨é¢†å…ˆä¸”æµè¡Œçš„Veo-3ã€‚æˆ‘ä»¬è¯„ä¼°äº†å®ƒåœ¨12ä¸ªç»´åº¦ä¸Šçš„æ¨ç†è¡Œä¸ºï¼ŒåŒ…æ‹¬ç©ºé—´ã€å‡ ä½•ã€ç‰©ç†ã€æ—¶é—´å’Œå…·èº«é€»è¾‘ï¼Œç³»ç»Ÿåœ°æè¿°äº†å®ƒçš„ä¼˜åŠ¿å’Œå¤±è´¥æ¨¡å¼ã€‚ä¸ºäº†æ ‡å‡†åŒ–è¿™é¡¹ç ”ç©¶ï¼Œæˆ‘ä»¬å°†è¯„ä¼°æ•°æ®æ•´ç†æˆMME-CoFï¼Œè¿™æ˜¯ä¸€ä¸ªç´§å‡‘çš„åŸºå‡†ï¼Œå¯ä»¥å¯¹å¸§é“¾ï¼ˆCoFï¼‰æ¨ç†è¿›è¡Œæ·±å…¥è€Œå½»åº•çš„è¯„ä¼°ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œè™½ç„¶å½“å‰çš„è§†é¢‘æ¨¡å‹åœ¨çŸ­ç¨‹ç©ºé—´è¿è´¯æ€§ã€ç²¾ç»†çš„ grounding å’Œå±€éƒ¨ä¸€è‡´çš„åŠ¨æ€æ–¹é¢è¡¨ç°å‡ºæœ‰å¸Œæœ›çš„æ¨ç†æ¨¡å¼ï¼Œä½†å®ƒä»¬åœ¨é•¿ç¨‹å› æœæ¨ç†ã€ä¸¥æ ¼çš„å‡ ä½•çº¦æŸå’ŒæŠ½è±¡é€»è¾‘æ–¹é¢ä»ç„¶å—åˆ°é™åˆ¶ã€‚æ€»çš„æ¥è¯´ï¼Œå®ƒä»¬è¿˜ä¸èƒ½ä½œä¸ºç‹¬ç«‹çš„é›¶æ ·æœ¬æ¨ç†å™¨ï¼Œä½†ä½œä¸ºä¸“ç”¨æ¨ç†æ¨¡å‹çš„è¡¥å……è§†è§‰å¼•æ“ï¼Œå®ƒä»¬è¡¨ç°å‡ºä»¤äººé¼“èˆçš„è¿¹è±¡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è¯„ä¼°å½“å‰å…ˆè¿›çš„è§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼ˆå¦‚Veo-3ï¼‰æ˜¯å¦å…·å¤‡åœ¨å¤æ‚è§†è§‰æ¨ç†ä»»åŠ¡ä¸­è¿›è¡Œé›¶æ ·æœ¬æ¨ç†çš„èƒ½åŠ›ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹å¯¹è§†é¢‘æ¨¡å‹æ¨ç†èƒ½åŠ›çš„ç³»ç»Ÿæ€§è¯„ä¼°ï¼Œéš¾ä»¥äº†è§£å…¶åœ¨ä¸åŒæ¨ç†ç»´åº¦ä¸Šçš„ä¼˜ç¼ºç‚¹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ„å»ºä¸€ä¸ªä¸“é—¨çš„è¯„ä¼°åŸºå‡†MME-CoFï¼Œå¹¶è®¾è®¡ä¸€ç³»åˆ—é’ˆå¯¹ä¸åŒæ¨ç†ç»´åº¦çš„æµ‹è¯•ç”¨ä¾‹ï¼Œæ¥ç³»ç»Ÿæ€§åœ°è¯„ä¼°è§†é¢‘æ¨¡å‹åœ¨é›¶æ ·æœ¬æ¡ä»¶ä¸‹çš„æ¨ç†èƒ½åŠ›ã€‚é€šè¿‡åˆ†ææ¨¡å‹åœ¨ä¸åŒç»´åº¦ä¸Šçš„è¡¨ç°ï¼Œæ­ç¤ºå…¶ä¼˜åŠ¿å’Œå±€é™æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) é€‰æ‹©ä»£è¡¨æ€§çš„è§†é¢‘ç”Ÿæˆæ¨¡å‹Veo-3ä½œä¸ºè¯„ä¼°å¯¹è±¡ã€‚2) æ„å»ºMME-CoFåŸºå‡†ï¼Œè¯¥åŸºå‡†åŒ…å«12ä¸ªæ¨ç†ç»´åº¦ï¼Œæ¶µç›–ç©ºé—´ã€å‡ ä½•ã€ç‰©ç†ã€æ—¶é—´å’Œå…·èº«é€»è¾‘ç­‰ã€‚3) è®¾è®¡é’ˆå¯¹æ¯ä¸ªæ¨ç†ç»´åº¦çš„æµ‹è¯•ç”¨ä¾‹ï¼Œå¹¶ç”Ÿæˆç›¸åº”çš„è§†é¢‘æç¤ºã€‚4) ä½¿ç”¨Veo-3ç”Ÿæˆè§†é¢‘ï¼Œå¹¶è¯„ä¼°å…¶åœ¨æ¯ä¸ªæµ‹è¯•ç”¨ä¾‹ä¸Šçš„è¡¨ç°ã€‚5) åˆ†æå®éªŒç»“æœï¼Œæ€»ç»“Veo-3åœ¨ä¸åŒæ¨ç†ç»´åº¦ä¸Šçš„ä¼˜åŠ¿å’Œä¸è¶³ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†MME-CoFåŸºå‡†ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºè¯„ä¼°è§†é¢‘æ¨¡å‹é›¶æ ·æœ¬æ¨ç†èƒ½åŠ›çš„ç´§å‡‘å‹åŸºå‡†ã€‚ä¸ç°æœ‰çš„è§†é¢‘ç†è§£åŸºå‡†ä¸åŒï¼ŒMME-CoFæ›´åŠ å…³æ³¨æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œå¹¶è®¾è®¡äº†é’ˆå¯¹ä¸åŒæ¨ç†ç»´åº¦çš„æµ‹è¯•ç”¨ä¾‹ï¼Œä»è€Œèƒ½å¤Ÿæ›´å…¨é¢åœ°è¯„ä¼°è§†é¢‘æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šMME-CoFåŸºå‡†åŒ…å«12ä¸ªæ¨ç†ç»´åº¦ï¼Œæ¯ä¸ªç»´åº¦éƒ½è®¾è®¡äº†å¤šä¸ªæµ‹è¯•ç”¨ä¾‹ã€‚æµ‹è¯•ç”¨ä¾‹çš„è®¾è®¡è€ƒè™‘äº†è§†é¢‘çš„æ—¶åºæ€§å’Œå› æœå…³ç³»ï¼Œè¦æ±‚æ¨¡å‹èƒ½å¤Ÿç†è§£è§†é¢‘ä¸­çš„ç‰©ä½“ã€å…³ç³»å’Œäº‹ä»¶ï¼Œå¹¶è¿›è¡Œæ¨ç†ã€‚è¯„ä¼°æŒ‡æ ‡åŒ…æ‹¬å‡†ç¡®ç‡ã€å¬å›ç‡ç­‰ï¼Œç”¨äºè¡¡é‡æ¨¡å‹åœ¨æ¯ä¸ªæµ‹è¯•ç”¨ä¾‹ä¸Šçš„è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒVeo-3åœ¨çŸ­ç¨‹ç©ºé—´è¿è´¯æ€§ã€ç²¾ç»†çš„ grounding å’Œå±€éƒ¨ä¸€è‡´çš„åŠ¨æ€æ–¹é¢è¡¨ç°å‡ºæœ‰å¸Œæœ›çš„æ¨ç†æ¨¡å¼ã€‚ç„¶è€Œï¼Œåœ¨é•¿ç¨‹å› æœæ¨ç†ã€ä¸¥æ ¼çš„å‡ ä½•çº¦æŸå’ŒæŠ½è±¡é€»è¾‘æ–¹é¢ä»ç„¶å­˜åœ¨æ˜¾è‘—çš„å±€é™æ€§ã€‚MME-CoFåŸºå‡†çš„è¯„ä¼°ç»“æœä¸ºåç»­ç ”ç©¶æä¾›äº†é‡è¦çš„å‚è€ƒã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè¯„ä¼°å’Œæ”¹è¿›è§†é¢‘ç”Ÿæˆæ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œæ¨åŠ¨è§†é¢‘æ¨¡å‹åœ¨æ™ºèƒ½ç›‘æ§ã€è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªç­‰é¢†åŸŸçš„åº”ç”¨ã€‚é€šè¿‡äº†è§£è§†é¢‘æ¨¡å‹çš„æ¨ç†å±€é™æ€§ï¼Œå¯ä»¥æ›´å¥½åœ°å°†å…¶ä¸ä¸“ç”¨æ¨ç†æ¨¡å‹ç»“åˆï¼Œæ„å»ºæ›´å¼ºå¤§çš„è§†è§‰æ™ºèƒ½ç³»ç»Ÿã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent video generation models can produce high-fidelity, temporally coherent videos, indicating that they may encode substantial world knowledge. Beyond realistic synthesis, they also exhibit emerging behaviors indicative of visual perception, modeling, and manipulation. Yet, an important question still remains: Are video models ready to serve as zero-shot reasoners in challenging visual reasoning scenarios? In this work, we conduct an empirical study to comprehensively investigate this question, focusing on the leading and popular Veo-3. We evaluate its reasoning behavior across 12 dimensions, including spatial, geometric, physical, temporal, and embodied logic, systematically characterizing both its strengths and failure modes. To standardize this study, we curate the evaluation data into MME-CoF, a compact benchmark that enables in-depth and thorough assessment of Chain-of-Frame (CoF) reasoning. Our findings reveal that while current video models demonstrate promising reasoning patterns on short-horizon spatial coherence, fine-grained grounding, and locally consistent dynamics, they remain limited in long-horizon causal reasoning, strict geometric constraints, and abstract logic. Overall, they are not yet reliable as standalone zero-shot reasoners, but exhibit encouraging signs as complementary visual engines alongside dedicated reasoning models. Project page: https://video-cof.github.io

