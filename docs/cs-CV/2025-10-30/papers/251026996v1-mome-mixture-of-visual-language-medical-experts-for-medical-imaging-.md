---
layout: default
title: MoME: Mixture of Visual Language Medical Experts for Medical Imaging Segmentation
---

# MoME: Mixture of Visual Language Medical Experts for Medical Imaging Segmentation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.26996" target="_blank" class="toolbar-btn">arXiv: 2510.26996v1</a>
    <a href="https://arxiv.org/pdf/2510.26996.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.26996v1" 
            onclick="toggleFavorite(this, '2510.26996v1', 'MoME: Mixture of Visual Language Medical Experts for Medical Imaging Segmentation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Arghavan Rezvani, Xiangyi Yan, Anthony T. Wu, Kun Han, Pooya Khosravi, Xiaohui Xie

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-30

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫MoMEÔºö‰∏ÄÁßçÁî®‰∫éÂåªÂ≠¶ÂΩ±ÂÉèÂàÜÂâ≤ÁöÑËßÜËßâËØ≠Ë®ÄÊ∑∑Âêà‰∏ìÂÆ∂Ê®°Âûã**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÂåªÂ≠¶ÂΩ±ÂÉèÂàÜÂâ≤` `Ê∑∑Âêà‰∏ìÂÆ∂Ê®°Âûã` `ËßÜËßâËØ≠Ë®ÄÊ®°Âûã` `Â§öÊ®°ÊÄÅËûçÂêà` `Ê∑±Â∫¶Â≠¶‰π†` `CTÊâ´Êèè`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂåªÂ≠¶ÂΩ±ÂÉèÂàÜÂâ≤ÊñπÊ≥ïÁº∫‰πèÂØπÂ§öÊ®°ÊÄÅ‰ø°ÊÅØÁöÑÊúâÊïàÂà©Áî®ÔºåÈôêÂà∂‰∫ÜÊ®°ÂûãÊÄßËÉΩÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ
2. MoMEÈÄöËøáÂºïÂÖ•ËßÜËßâËØ≠Ë®ÄÊ∑∑Âêà‰∏ìÂÆ∂Ê®°ÂûãÔºåÂà©Áî®Â§öÂ∞∫Â∫¶ËßÜËßâÁâπÂæÅÂíåÊñáÊú¨ÂµåÂÖ•ÔºåÂÆûÁé∞Âä®ÊÄÅ‰∏ìÂÆ∂ÈÄâÊã©ÔºåÊèêÂçáÂàÜÂâ≤Á≤æÂ∫¶„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåMoMEÂú®ÂåÖÂê´3410‰∏™CTÊâ´ÊèèÁöÑ10‰∏™Êï∞ÊçÆÈõÜ‰∏äË°®Áé∞Âá∫Âº∫Â§ßÁöÑÊÄßËÉΩÔºåÈ™åËØÅ‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁßçÁî®‰∫éÂåªÂ≠¶ÂΩ±ÂÉèÂàÜÂâ≤ÁöÑËßÜËßâËØ≠Ë®ÄÊ∑∑Âêà‰∏ìÂÆ∂Ê®°ÂûãMoME„ÄÇMoMEÂ∞ÜÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã(LLM)‰∏≠ÂπøÊ≥õ‰ΩøÁî®ÁöÑÊ∑∑Âêà‰∏ìÂÆ∂(MoE)ËåÉÂºèÂ∫îÁî®‰∫éÂåªÂ≠¶ËßÜËßâËØ≠Ë®Ä‰ªªÂä°„ÄÇËØ•Êû∂ÊûÑÈÄöËøáÊúâÊïàÂà©Áî®ÈíàÂØπÂåªÂ≠¶ÂΩ±ÂÉèÂ§çÊùÇÊÄßÂÆöÂà∂ÁöÑÂ§öÂ∞∫Â∫¶ËßÜËßâÁâπÂæÅÔºåÂπ∂ÁªìÂêàÊñáÊú¨ÂµåÂÖ•ÔºåÂÆûÁé∞‰∫ÜÂä®ÊÄÅ‰∏ìÂÆ∂ÈÄâÊã©„ÄÇËøôÈ°πÂ∑•‰ΩúÊé¢Á¥¢‰∫ÜËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÂú®ËØ•È¢ÜÂüü‰∏≠ÁöÑ‰∏ÄÁßçÊñ∞È¢ñÈõÜÊàê„ÄÇMoMEÂà©Áî®ÂåÖÂê´3410‰∏™CTÊâ´ÊèèÁöÑ10‰∏™Êï∞ÊçÆÈõÜÁöÑÈõÜÂêàÔºåÂú®ÂÖ®Èù¢ÁöÑÂåªÂ≠¶ÂΩ±ÂÉèÂàÜÂâ≤Âü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞Âá∫Âº∫Â§ßÁöÑÊÄßËÉΩ„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÊé¢Á¥¢‰∫ÜÁî®‰∫éÂåªÂ≠¶ÂΩ±ÂÉèÁöÑÂü∫Á°ÄÊ®°ÂûãÁöÑÈõÜÊàêÔºåÂèóÁõä‰∫éMoEÈÄöËøáÁªìÂêàÊñáÊú¨‰ø°ÊÅØÊù•ÊèêÈ´òÊ®°ÂûãÊÄßËÉΩÁöÑÊó¢ÂÆöÂäüÊïà„ÄÇMoMEÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äÂ±ïÁ§∫‰∫ÜÂÖ∑ÊúâÁ´û‰∫âÂäõÁöÑÁ≤æÂ∫¶ÔºåÊé¢Á¥¢‰∫Ü‰∏ÄÁßçÁî®‰∫éÂú®ÂåªÂ≠¶ÂõæÂÉèÂàÜÊûê‰∏≠ÂÆûÁé∞Á®≥ÂÅ•ÁªìÊûúÁöÑÊñ∞È¢ñÊû∂ÊûÑ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÂåªÂ≠¶ÂΩ±ÂÉèÂàÜÂâ≤Êó®Âú®Á≤æÁ°ÆËØÜÂà´ÂíåÂàÜÂâ≤ÂåªÂ≠¶ÂõæÂÉè‰∏≠ÁöÑÁâπÂÆöÁªÑÁªáÊàñÁóÖÁÅ∂„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏‰æùËµñ‰∫éÂçï‰∏ÄÊ®°ÊÄÅÁöÑÂõæÂÉè‰ø°ÊÅØÔºåÂøΩÁï•‰∫Ü‰∏éÂõæÂÉèÁõ∏ÂÖ≥ÁöÑÊñáÊú¨ÊèèËø∞ÔºàÂ¶ÇËØäÊñ≠Êä•ÂëäÔºâÔºåÈôêÂà∂‰∫ÜÊ®°ÂûãÂØπÂ§çÊùÇÂåªÂ≠¶ÂõæÂÉèÁöÑÁêÜËß£ÂíåÂàÜÂâ≤Á≤æÂ∫¶„ÄÇÊ≠§Â§ñÔºå‰∏çÂêåÊï∞ÊçÆÈõÜÁöÑÂõæÂÉèÁâπÂæÅÂ∑ÆÂºÇËæÉÂ§ßÔºåÂçï‰∏ÄÊ®°ÂûãÈöæ‰ª•Ê≥õÂåñÂà∞ÊâÄÊúâÊï∞ÊçÆÈõÜ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöMoMEÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜËßÜËßâ‰ø°ÊÅØÂíåÊñáÊú¨‰ø°ÊÅØËûçÂêàÔºåÂπ∂Âà©Áî®Ê∑∑Âêà‰∏ìÂÆ∂Ê®°ÂûãÂä®ÊÄÅÈÄâÊã©ÊúÄÈÄÇÂêàÂΩìÂâçËæìÂÖ•Êï∞ÊçÆÁöÑ‰∏ìÂÆ∂„ÄÇÈÄöËøáËøôÁßçÊñπÂºèÔºåÊ®°ÂûãÂèØ‰ª•Êõ¥Â•ΩÂú∞ÁêÜËß£ÂåªÂ≠¶ÂõæÂÉèÔºåÂπ∂Ê†πÊçÆ‰∏çÂêåÁöÑÊï∞ÊçÆÈõÜÁâπÂæÅÈÄâÊã©‰∏çÂêåÁöÑ‰∏ìÂÆ∂Ôºå‰ªéËÄåÊèêÈ´òÂàÜÂâ≤Á≤æÂ∫¶ÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöMoMEÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) Â§öÂ∞∫Â∫¶ËßÜËßâÁâπÂæÅÊèêÂèñÊ®°ÂùóÔºåÁî®‰∫éÊèêÂèñÂåªÂ≠¶ÂõæÂÉèÁöÑÂ§öÂ∞∫Â∫¶ÁâπÂæÅÔºõ2) ÊñáÊú¨ÂµåÂÖ•Ê®°ÂùóÔºåÁî®‰∫éÂ∞ÜÊñáÊú¨ÊèèËø∞ËΩ¨Êç¢‰∏∫ÂêëÈáèË°®Á§∫Ôºõ3) Ê∑∑Âêà‰∏ìÂÆ∂Ê®°ÂùóÔºåÂåÖÂê´Â§ö‰∏™‰∏ìÂÆ∂ÁΩëÁªúÔºåÊØè‰∏™‰∏ìÂÆ∂ÁΩëÁªúÊìÖÈïøÂ§ÑÁêÜÁâπÂÆöÁ±ªÂûãÁöÑÊï∞ÊçÆÔºõ4) Èó®ÊéßÁΩëÁªúÔºåÁî®‰∫éÊ†πÊçÆËßÜËßâÁâπÂæÅÂíåÊñáÊú¨ÂµåÂÖ•Âä®ÊÄÅÈÄâÊã©‰∏ìÂÆ∂Ôºõ5) ÂàÜÂâ≤Ê®°ÂùóÔºåÁî®‰∫éÊ†πÊçÆÈÄâÊã©ÁöÑ‰∏ìÂÆ∂ËæìÂá∫ÂàÜÂâ≤ÁªìÊûú„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöMoMEÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜÊ∑∑Âêà‰∏ìÂÆ∂Ê®°ÂûãÂ∫îÁî®‰∫éÂåªÂ≠¶ÂΩ±ÂÉèÂàÜÂâ≤‰ªªÂä°ÔºåÂπ∂ÁªìÂêàËßÜËßâÂíåÊñáÊú¨‰ø°ÊÅØËøõË°åÂä®ÊÄÅ‰∏ìÂÆ∂ÈÄâÊã©„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåMoMEËÉΩÂ§üÊõ¥Â•ΩÂú∞Âà©Áî®Â§öÊ®°ÊÄÅ‰ø°ÊÅØÔºåÂπ∂Ê†πÊçÆ‰∏çÂêåÁöÑÊï∞ÊçÆÁâπÂæÅÈÄâÊã©‰∏çÂêåÁöÑ‰∏ìÂÆ∂Ôºå‰ªéËÄåÊèêÈ´òÂàÜÂâ≤Á≤æÂ∫¶ÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöMoMEÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ‰ΩøÁî®Â§öÂ∞∫Â∫¶Âç∑ÁßØÁ•ûÁªèÁΩëÁªúÊèêÂèñËßÜËßâÁâπÂæÅÔºõ2) ‰ΩøÁî®È¢ÑËÆ≠ÁªÉÁöÑËØ≠Ë®ÄÊ®°ÂûãÔºàÂ¶ÇBERTÔºâËøõË°åÊñáÊú¨ÂµåÂÖ•Ôºõ3) ‰ΩøÁî®Èó®ÊéßÁΩëÁªúÊ†πÊçÆËßÜËßâÁâπÂæÅÂíåÊñáÊú¨ÂµåÂÖ•ËÆ°ÁÆóÊØè‰∏™‰∏ìÂÆ∂ÁöÑÊùÉÈáçÔºõ4) ‰ΩøÁî®Âä†ÊùÉÂπ≥ÂùáÁöÑÊñπÂºèÂ∞ÜÂ§ö‰∏™‰∏ìÂÆ∂ÁöÑËæìÂá∫ËøõË°åËûçÂêàÔºåÂæóÂà∞ÊúÄÁªàÁöÑÂàÜÂâ≤ÁªìÊûú„ÄÇÂÖ∑‰ΩìÁöÑÊçüÂ§±ÂáΩÊï∞ÂíåÁΩëÁªúÁªìÊûÑÁ≠âÊäÄÊúØÁªÜËäÇÂú®ËÆ∫Êñá‰∏≠ËøõË°å‰∫ÜËØ¶ÁªÜÊèèËø∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

MoMEÂú®ÂåÖÂê´3410‰∏™CTÊâ´ÊèèÁöÑ10‰∏™Êï∞ÊçÆÈõÜ‰∏äËøõË°å‰∫ÜËØÑ‰º∞ÔºåÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåMoMEÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜÂÖ∑ÊúâÁ´û‰∫âÂäõÁöÑÁ≤æÂ∫¶„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåMoMEËÉΩÂ§üÊõ¥Â•ΩÂú∞Âà©Áî®Â§öÊ®°ÊÄÅ‰ø°ÊÅØÔºåÂπ∂Ê†πÊçÆ‰∏çÂêåÁöÑÊï∞ÊçÆÁâπÂæÅÈÄâÊã©‰∏çÂêåÁöÑ‰∏ìÂÆ∂Ôºå‰ªéËÄåÊèêÈ´ò‰∫ÜÂàÜÂâ≤Á≤æÂ∫¶ÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇÂÖ∑‰ΩìÊÄßËÉΩÊèêÂçáÊï∞ÊçÆÈúÄË¶ÅÂú®ËÆ∫Êñá‰∏≠Êü•Êâæ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

MoMEÂèØÂ∫îÁî®‰∫éÂ§öÁßçÂåªÂ≠¶ÂΩ±ÂÉèÂàÜÂâ≤‰ªªÂä°Ôºå‰æãÂ¶ÇËÇøÁò§ÂàÜÂâ≤„ÄÅÂô®ÂÆòÂàÜÂâ≤ÂíåÁóÖÁÅ∂ÂàÜÂâ≤„ÄÇËØ•Á†îÁ©∂ÊàêÊûúÊúâÂä©‰∫éÊèêÈ´òÂåªÂ≠¶ÂΩ±ÂÉèÂàÜÊûêÁöÑÂáÜÁ°ÆÊÄßÂíåÊïàÁéáÔºåËæÖÂä©ÂåªÁîüËøõË°åËØäÊñ≠ÂíåÊ≤ªÁñóÂÜ≥Á≠ñÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑ‰∏¥Â∫äÂ∫îÁî®‰ª∑ÂÄº„ÄÇÊú™Êù•ÔºåMoMEÂèØ‰ª•Ëøõ‰∏ÄÊ≠•Êâ©Â±ïÂà∞ÂÖ∂‰ªñÂåªÂ≠¶ÂΩ±ÂÉèÂàÜÊûê‰ªªÂä°Ôºå‰æãÂ¶ÇÁñæÁóÖËØäÊñ≠ÂíåÈ¢ÑÂêéÈ¢ÑÊµã„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> In this study, we propose MoME, a Mixture of Visual Language Medical Experts, for Medical Image Segmentation. MoME adapts the successful Mixture of Experts (MoE) paradigm, widely used in Large Language Models (LLMs), for medical vision-language tasks. The architecture enables dynamic expert selection by effectively utilizing multi-scale visual features tailored to the intricacies of medical imagery, enriched with textual embeddings. This work explores a novel integration of vision-language models for this domain. Utilizing an assembly of 10 datasets, encompassing 3,410 CT scans, MoME demonstrates strong performance on a comprehensive medical imaging segmentation benchmark. Our approach explores the integration of foundation models for medical imaging, benefiting from the established efficacy of MoE in boosting model performance by incorporating textual information. Demonstrating competitive precision across multiple datasets, MoME explores a novel architecture for achieving robust results in medical image analysis.

