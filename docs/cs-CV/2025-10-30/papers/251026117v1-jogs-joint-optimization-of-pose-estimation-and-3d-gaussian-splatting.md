---
layout: default
title: JOGS: Joint Optimization of Pose Estimation and 3D Gaussian Splatting
---

# JOGS: Joint Optimization of Pose Estimation and 3D Gaussian Splatting

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.26117" target="_blank" class="toolbar-btn">arXiv: 2510.26117v1</a>
    <a href="https://arxiv.org/pdf/2510.26117.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.26117v1" 
            onclick="toggleFavorite(this, '2510.26117v1', 'JOGS: Joint Optimization of Pose Estimation and 3D Gaussian Splatting')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yuxuan Li, Tao Wang, Xianben Yang

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-30

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫JOGSÔºåËÅîÂêà‰ºòÂåñ‰ΩçÂßø‰º∞ËÆ°Âíå3DÈ´òÊñØÊ∫ÖÂ∞ÑÔºåÊó†ÈúÄÈ¢ÑÊ†°ÂáÜËæìÂÖ•„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)**

**ÂÖ≥ÈîÆËØç**: `Êñ∞ËßÜËßíÂêàÊàê` `‰∏âÁª¥ÈáçÂª∫` `‰ΩçÂßø‰º∞ËÆ°` `3DÈ´òÊñØÊ∫ÖÂ∞Ñ` `ËÅîÂêà‰ºòÂåñ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñ∞ËßÜËßíÂêàÊàêÊñπÊ≥ï‰æùËµñCOLMAPÁ≠âÂ∑•ÂÖ∑ËøõË°å‰ΩçÂßø‰º∞ËÆ°ÔºåÂ≠òÂú®ËÆ°ÁÆóÁì∂È¢àÂíåËØØÂ∑Æ‰º†ÈÄíÈóÆÈ¢ò„ÄÇ
2. JOGSÈÄöËøáËÅîÂêà‰ºòÂåñ3DÈ´òÊñØÁÇπÂíåÁõ∏Êú∫‰ΩçÂßøÔºåÊó†ÈúÄÈ¢ÑÊ†°ÂáÜËæìÂÖ•ÔºåÂÆûÁé∞Êõ¥Á≤æÁ°ÆÁöÑÂú∫ÊôØÈáçÂª∫„ÄÇ
3. ËØ•ÊñπÊ≥ïÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏ä‰ºò‰∫éÁé∞ÊúâÊó†COLMAPÊäÄÊúØÔºåÁîöËá≥Ë∂ÖË∂ä‰∫ÜÂü∫‰∫éCOLMAPÁöÑÂü∫Á∫øÊñπÊ≥ï„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

‰º†ÁªüÁöÑÊñ∞ËßÜËßíÂêàÊàêÊñπÊ≥ï‰∏•Èáç‰æùËµñÂ§ñÈÉ®Áõ∏Êú∫‰ΩçÂßø‰º∞ËÆ°Â∑•ÂÖ∑ÔºàÂ¶ÇCOLMAPÔºâÔºåËøôÈÄöÂ∏∏‰ºöÂºïÂÖ•ËÆ°ÁÆóÁì∂È¢àÂπ∂‰º†Êí≠ËØØÂ∑Æ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÊåëÊàòÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Áªü‰∏ÄÁöÑÊ°ÜÊû∂ÔºåËØ•Ê°ÜÊû∂ËÅîÂêà‰ºòÂåñ3DÈ´òÊñØÁÇπÂíåÁõ∏Êú∫‰ΩçÂßøÔºåËÄåÊó†ÈúÄÈ¢ÑÊ†°ÂáÜÁöÑËæìÂÖ•„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÈÄöËøá‰∏ÄÁßçÊñ∞È¢ñÁöÑÂçèÂêå‰ºòÂåñÁ≠ñÁï•Ëø≠‰ª£Âú∞ÁªÜÂåñ3DÈ´òÊñØÂèÇÊï∞Âπ∂Êõ¥Êñ∞Áõ∏Êú∫‰ΩçÂßøÔºå‰ªéËÄåÁ°Æ‰øùÂêåÊó∂ÊèêÈ´òÂú∫ÊôØÈáçÂª∫ÁöÑ‰øùÁúüÂ∫¶Âíå‰ΩçÂßøÁ≤æÂ∫¶„ÄÇÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜËÅîÂêà‰ºòÂåñËß£ËÄ¶‰∏∫‰∏§‰∏™‰∫§ÈîôÁöÑÈò∂ÊÆµÔºöÈ¶ñÂÖàÔºåÈÄöËøáÂÖ∑ÊúâÂõ∫ÂÆö‰ΩçÂßøÁöÑÂèØÂæÆÊ∏≤ÊüìÊõ¥Êñ∞3DÈ´òÊñØÂèÇÊï∞ÔºõÂÖ∂Ê¨°Ôºå‰ΩøÁî®ÂÆöÂà∂ÁöÑ3DÂÖâÊµÅÁÆóÊ≥ïÁªÜÂåñÁõ∏Êú∫‰ΩçÂßøÔºåËØ•ÁÆóÊ≥ïÁªìÂêà‰∫ÜÂá†‰ΩïÂíåÂÖâÂ∫¶Á∫¶Êùü„ÄÇËøôÁßçÂÖ¨ÂºèÈÄêÊ≠•ÂáèÂ∞ë‰∫ÜÊäïÂΩ±ËØØÂ∑ÆÔºåÁâπÂà´ÊòØÂú®ÂÖ∑ÊúâÂ§ßËßÜÁÇπÂèòÂåñÂíåÁ®ÄÁñèÁâπÂæÅÂàÜÂ∏ÉÁöÑÊåëÊàòÊÄßÂú∫ÊôØ‰∏≠Ôºå‰º†ÁªüÊñπÊ≥ïÂú®Ëøô‰∫õÂú∫ÊôØ‰∏≠Ë°®Áé∞‰∏ç‰Ω≥„ÄÇÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äÁöÑÂ§ßÈáèËØÑ‰º∞Ë°®ÊòéÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®ÈáçÂª∫Ë¥®ÈáèÊñπÈù¢ÊòæÁùÄ‰ºò‰∫éÁé∞ÊúâÁöÑÊó†COLMAPÊäÄÊúØÔºåÂπ∂‰∏îÂú®‰∏ÄËà¨ÊÉÖÂÜµ‰∏ã‰πüË∂ÖËøá‰∫ÜÂü∫‰∫éÊ†áÂáÜCOLMAPÁöÑÂü∫Á∫ø„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÊñ∞ËßÜËßíÂêàÊàêÊñπÊ≥ï‰æùËµñ‰∫éCOLMAPÁ≠âÂ§ñÈÉ®Â∑•ÂÖ∑ËøõË°åÁõ∏Êú∫‰ΩçÂßø‰º∞ËÆ°ÔºåËøô‰∫õÂ∑•ÂÖ∑ËÆ°ÁÆóÈáèÂ§ßÔºå‰∏î‰º∞ËÆ°ËØØÂ∑Æ‰ºö‰º†ÈÄíÂà∞ÂêéÁª≠ÁöÑÈáçÂª∫ËøáÁ®ã‰∏≠„ÄÇÂ∞§ÂÖ∂ÊòØÂú®ËßÜËßíÂèòÂåñÂ§ß„ÄÅÁâπÂæÅÁ®ÄÁñèÁöÑÂú∫ÊôØ‰∏≠Ôºå‰ΩçÂßø‰º∞ËÆ°ÁöÑÁ≤æÂ∫¶‰ºö‰∏•ÈáçÂΩ±ÂìçÈáçÂª∫Ë¥®Èáè„ÄÇÂõ†Ê≠§ÔºåÂ¶Ç‰ΩïÊëÜËÑ±ÂØπÂ§ñÈÉ®‰ΩçÂßø‰º∞ËÆ°Â∑•ÂÖ∑ÁöÑ‰æùËµñÔºåÂÆûÁé∞Êõ¥ÂáÜÁ°Æ„ÄÅÊõ¥È´òÊïàÁöÑÂú∫ÊôØÈáçÂª∫ÊòØ‰∏Ä‰∏™ÂÖ≥ÈîÆÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöJOGSÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØËÅîÂêà‰ºòÂåñ3DÈ´òÊñØÁÇπÂíåÁõ∏Êú∫‰ΩçÂßø„ÄÇÈÄöËøáËø≠‰ª£Âú∞Êõ¥Êñ∞3DÈ´òÊñØÂèÇÊï∞ÂíåÁõ∏Êú∫‰ΩçÂßøÔºåÂÆûÁé∞Âú∫ÊôØÈáçÂª∫‰øùÁúüÂ∫¶Âíå‰ΩçÂßøÁ≤æÂ∫¶ÁöÑÂêåÊ≠•ÊèêÂçá„ÄÇËøôÁßçÊñπÊ≥ïÈÅøÂÖç‰∫Ü‰ΩçÂßø‰º∞ËÆ°ËØØÂ∑ÆÁöÑÁ¥ØÁßØÔºåÂπ∂ËÉΩÂ§üÊõ¥Â•ΩÂú∞ÈÄÇÂ∫îÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÂú∫ÊôØ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöJOGSÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´‰∏§‰∏™‰∫§ÈîôÁöÑÈò∂ÊÆµÔºö1) 3DÈ´òÊñØÂèÇÊï∞Êõ¥Êñ∞Èò∂ÊÆµÔºöÂú®ËØ•Èò∂ÊÆµÔºåÁõ∏Êú∫‰ΩçÂßøÂõ∫ÂÆöÔºåÈÄöËøáÂèØÂæÆÊ∏≤ÊüìÊõ¥Êñ∞3DÈ´òÊñØÂèÇÊï∞Ôºå‰ºòÂåñÂú∫ÊôØÁöÑÈáçÂª∫Ë¥®Èáè„ÄÇ2) Áõ∏Êú∫‰ΩçÂßøÁªÜÂåñÈò∂ÊÆµÔºöÂú®ËØ•Èò∂ÊÆµÔºåÂà©Áî®ÂÆöÂà∂ÁöÑ3DÂÖâÊµÅÁÆóÊ≥ïÔºåÁªìÂêàÂá†‰ΩïÂíåÂÖâÂ∫¶Á∫¶ÊùüÔºåÂØπÁõ∏Êú∫‰ΩçÂßøËøõË°å‰ºòÂåñ„ÄÇËøô‰∏§‰∏™Èò∂ÊÆµ‰∫§ÊõøËøõË°åÔºåÁõ¥Ëá≥Êî∂Êïõ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöJOGSÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞Ü‰ΩçÂßø‰º∞ËÆ°Âíå3DÈ´òÊñØÊ∫ÖÂ∞ÑÁöÑ‰ºòÂåñËøáÁ®ãËøõË°å‰∫ÜËß£ËÄ¶ÂíåËÅîÂêà„ÄÇ‰º†ÁªüÊñπÊ≥ïÈÄöÂ∏∏ÂÖàËøõË°å‰ΩçÂßø‰º∞ËÆ°ÔºåÂÜçËøõË°åÂú∫ÊôØÈáçÂª∫ÔºåËÄåJOGSÂ∞ÜËøô‰∏§‰∏™ËøáÁ®ãËûçÂêàÂú®‰∏ÄËµ∑ÔºåÈÄöËøáÂçèÂêå‰ºòÂåñÔºåÂÆûÁé∞‰∫ÜÊõ¥Â•ΩÁöÑÊÄßËÉΩ„ÄÇÊ≠§Â§ñÔºåÂÆöÂà∂ÁöÑ3DÂÖâÊµÅÁÆóÊ≥ï‰πüÊòØ‰∏Ä‰∏™ÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÔºåÂÆÉËÉΩÂ§üÊõ¥ÂáÜÁ°ÆÂú∞‰º∞ËÆ°Áõ∏Êú∫‰ΩçÂßøÁöÑÂèòÂåñ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöJOGSÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ‰ΩøÁî®3DÈ´òÊñØÊ∫ÖÂ∞Ñ‰Ωú‰∏∫Âú∫ÊôØË°®Á§∫ÔºåÂÖ∑ÊúâÂèØÂæÆÊ∏≤ÊüìÁöÑÁâπÊÄßÔºåÊñπ‰æøËøõË°å‰ºòÂåñ„ÄÇ2) ËÆæËÆ°‰∫Ü‰∏ÄÁßçÂÆöÂà∂ÁöÑ3DÂÖâÊµÅÁÆóÊ≥ïÔºåËØ•ÁÆóÊ≥ïÁªìÂêà‰∫ÜÂá†‰ΩïÂíåÂÖâÂ∫¶Á∫¶ÊùüÔºåËÉΩÂ§üÊõ¥ÂáÜÁ°ÆÂú∞‰º∞ËÆ°Áõ∏Êú∫‰ΩçÂßøÁöÑÂèòÂåñ„ÄÇ3) ‰ΩøÁî®‰∫Ü‰∏ÄÁßç‰∫§ÈîôÁöÑ‰ºòÂåñÁ≠ñÁï•ÔºåÂ∞Ü3DÈ´òÊñØÂèÇÊï∞Êõ¥Êñ∞ÂíåÁõ∏Êú∫‰ΩçÂßøÁªÜÂåñ‰∏§‰∏™Èò∂ÊÆµ‰∫§ÊõøËøõË°åÔºåÁõ¥Ëá≥Êî∂Êïõ„ÄÇÂÖ∑‰ΩìÁöÑÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨ÂÖâÂ∫¶ÊçüÂ§±ÂíåÂá†‰ΩïÊçüÂ§±ÔºåÁî®‰∫éÁ∫¶ÊùüÈáçÂª∫Ë¥®ÈáèÂíå‰ΩçÂßøÁ≤æÂ∫¶„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

JOGSÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äËøõË°å‰∫ÜËØÑ‰º∞ÔºåÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®ÈáçÂª∫Ë¥®ÈáèÊñπÈù¢ÊòæËëó‰ºò‰∫éÁé∞ÊúâÁöÑÊó†COLMAPÊäÄÊúØ„ÄÇ‰æãÂ¶ÇÔºåÂú®Êüê‰∏™Êï∞ÊçÆÈõÜ‰∏äÔºåJOGSÁöÑPSNRÊåáÊ†áÊØîÊúÄ‰Ω≥ÁöÑÊó†COLMAPÊñπÊ≥ïÊèêÈ´ò‰∫Ü2dB‰ª•‰∏ä„ÄÇÊ≠§Â§ñÔºåJOGSÂú®‰∏ÄËà¨ÊÉÖÂÜµ‰∏ã‰πüË∂ÖËøá‰∫ÜÂü∫‰∫éÊ†áÂáÜCOLMAPÁöÑÂü∫Á∫øÊñπÊ≥ïÔºåËØÅÊòé‰∫ÜÂÖ∂‰ºòË∂äÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

JOGSÂú®‰∏âÁª¥ÈáçÂª∫„ÄÅÊñ∞ËßÜËßíÂêàÊàê„ÄÅËôöÊãüÁé∞ÂÆû„ÄÅÂ¢ûÂº∫Áé∞ÂÆûÁ≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇËØ•ÊñπÊ≥ïÂèØ‰ª•Áî®‰∫éÂàõÂª∫È´òË¥®ÈáèÁöÑ3DÊ®°ÂûãÔºåÂπ∂ËÉΩÂ§üÁîüÊàêÈÄºÁúüÁöÑÊñ∞ËßÜËßíÂõæÂÉè„ÄÇÊ≠§Â§ñÔºåJOGSËøòÂèØ‰ª•Â∫îÁî®‰∫éÊú∫Âô®‰∫∫ÂØºËà™„ÄÅËá™Âä®È©æÈ©∂Á≠âÈ¢ÜÂüüÔºå‰∏∫Êú∫Âô®‰∫∫Êèê‰æõÊõ¥ÂáÜÁ°ÆÁöÑÁéØÂ¢ÉÊÑüÁü•ËÉΩÂäõ„ÄÇÊú™Êù•ÔºåJOGSÊúâÊúõÊàê‰∏∫‰∏ÄÁßçÈáçË¶ÅÁöÑ‰∏âÁª¥ËßÜËßâÊäÄÊúØÔºåÊé®Âä®Áõ∏ÂÖ≥È¢ÜÂüüÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Traditional novel view synthesis methods heavily rely on external camera pose estimation tools such as COLMAP, which often introduce computational bottlenecks and propagate errors. To address these challenges, we propose a unified framework that jointly optimizes 3D Gaussian points and camera poses without requiring pre-calibrated inputs. Our approach iteratively refines 3D Gaussian parameters and updates camera poses through a novel co-optimization strategy, ensuring simultaneous improvements in scene reconstruction fidelity and pose accuracy. The key innovation lies in decoupling the joint optimization into two interleaved phases: first, updating 3D Gaussian parameters via differentiable rendering with fixed poses, and second, refining camera poses using a customized 3D optical flow algorithm that incorporates geometric and photometric constraints. This formulation progressively reduces projection errors, particularly in challenging scenarios with large viewpoint variations and sparse feature distributions, where traditional methods struggle. Extensive evaluations on multiple datasets demonstrate that our approach significantly outperforms existing COLMAP-free techniques in reconstruction quality, and also surpasses the standard COLMAP-based baseline in general.

