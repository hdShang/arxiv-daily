---
layout: default
title: JOGS: Joint Optimization of Pose Estimation and 3D Gaussian Splatting
---

# JOGS: Joint Optimization of Pose Estimation and 3D Gaussian Splatting

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.26117" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.26117v1</a>
  <a href="https://arxiv.org/pdf/2510.26117.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.26117v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.26117v1', 'JOGS: Joint Optimization of Pose Estimation and 3D Gaussian Splatting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuxuan Li, Tao Wang, Xianben Yang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-30

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºJOGSï¼Œè”åˆä¼˜åŒ–ä½å§¿ä¼°è®¡å’Œ3Dé«˜æ–¯æº…å°„ï¼Œæ— éœ€é¢„æ ¡å‡†è¾“å…¥ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `æ–°è§†è§’åˆæˆ` `ä¸‰ç»´é‡å»º` `ä½å§¿ä¼°è®¡` `3Dé«˜æ–¯æº…å°„` `è”åˆä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–°è§†è§’åˆæˆæ–¹æ³•ä¾èµ–COLMAPç­‰å·¥å…·è¿›è¡Œä½å§¿ä¼°è®¡ï¼Œå­˜åœ¨è®¡ç®—ç“¶é¢ˆå’Œè¯¯å·®ä¼ é€’é—®é¢˜ã€‚
2. JOGSé€šè¿‡è”åˆä¼˜åŒ–3Dé«˜æ–¯ç‚¹å’Œç›¸æœºä½å§¿ï¼Œæ— éœ€é¢„æ ¡å‡†è¾“å…¥ï¼Œå®ç°æ›´ç²¾ç¡®çš„åœºæ™¯é‡å»ºã€‚
3. è¯¥æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šä¼˜äºç°æœ‰æ— COLMAPæŠ€æœ¯ï¼Œç”šè‡³è¶…è¶Šäº†åŸºäºCOLMAPçš„åŸºçº¿æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¼ ç»Ÿçš„æ–°è§†è§’åˆæˆæ–¹æ³•ä¸¥é‡ä¾èµ–å¤–éƒ¨ç›¸æœºä½å§¿ä¼°è®¡å·¥å…·ï¼ˆå¦‚COLMAPï¼‰ï¼Œè¿™é€šå¸¸ä¼šå¼•å…¥è®¡ç®—ç“¶é¢ˆå¹¶ä¼ æ’­è¯¯å·®ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ï¼Œè¯¥æ¡†æ¶è”åˆä¼˜åŒ–3Dé«˜æ–¯ç‚¹å’Œç›¸æœºä½å§¿ï¼Œè€Œæ— éœ€é¢„æ ¡å‡†çš„è¾“å…¥ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡ä¸€ç§æ–°é¢–çš„ååŒä¼˜åŒ–ç­–ç•¥è¿­ä»£åœ°ç»†åŒ–3Dé«˜æ–¯å‚æ•°å¹¶æ›´æ–°ç›¸æœºä½å§¿ï¼Œä»è€Œç¡®ä¿åŒæ—¶æé«˜åœºæ™¯é‡å»ºçš„ä¿çœŸåº¦å’Œä½å§¿ç²¾åº¦ã€‚å…³é”®åˆ›æ–°åœ¨äºå°†è”åˆä¼˜åŒ–è§£è€¦ä¸ºä¸¤ä¸ªäº¤é”™çš„é˜¶æ®µï¼šé¦–å…ˆï¼Œé€šè¿‡å…·æœ‰å›ºå®šä½å§¿çš„å¯å¾®æ¸²æŸ“æ›´æ–°3Dé«˜æ–¯å‚æ•°ï¼›å…¶æ¬¡ï¼Œä½¿ç”¨å®šåˆ¶çš„3Då…‰æµç®—æ³•ç»†åŒ–ç›¸æœºä½å§¿ï¼Œè¯¥ç®—æ³•ç»“åˆäº†å‡ ä½•å’Œå…‰åº¦çº¦æŸã€‚è¿™ç§å…¬å¼é€æ­¥å‡å°‘äº†æŠ•å½±è¯¯å·®ï¼Œç‰¹åˆ«æ˜¯åœ¨å…·æœ‰å¤§è§†ç‚¹å˜åŒ–å’Œç¨€ç–ç‰¹å¾åˆ†å¸ƒçš„æŒ‘æˆ˜æ€§åœºæ™¯ä¸­ï¼Œä¼ ç»Ÿæ–¹æ³•åœ¨è¿™äº›åœºæ™¯ä¸­è¡¨ç°ä¸ä½³ã€‚åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å¤§é‡è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨é‡å»ºè´¨é‡æ–¹é¢æ˜¾ç€ä¼˜äºç°æœ‰çš„æ— COLMAPæŠ€æœ¯ï¼Œå¹¶ä¸”åœ¨ä¸€èˆ¬æƒ…å†µä¸‹ä¹Ÿè¶…è¿‡äº†åŸºäºæ ‡å‡†COLMAPçš„åŸºçº¿ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æ–°è§†è§’åˆæˆæ–¹æ³•ä¾èµ–äºCOLMAPç­‰å¤–éƒ¨å·¥å…·è¿›è¡Œç›¸æœºä½å§¿ä¼°è®¡ï¼Œè¿™äº›å·¥å…·è®¡ç®—é‡å¤§ï¼Œä¸”ä¼°è®¡è¯¯å·®ä¼šä¼ é€’åˆ°åç»­çš„é‡å»ºè¿‡ç¨‹ä¸­ã€‚å°¤å…¶æ˜¯åœ¨è§†è§’å˜åŒ–å¤§ã€ç‰¹å¾ç¨€ç–çš„åœºæ™¯ä¸­ï¼Œä½å§¿ä¼°è®¡çš„ç²¾åº¦ä¼šä¸¥é‡å½±å“é‡å»ºè´¨é‡ã€‚å› æ­¤ï¼Œå¦‚ä½•æ‘†è„±å¯¹å¤–éƒ¨ä½å§¿ä¼°è®¡å·¥å…·çš„ä¾èµ–ï¼Œå®ç°æ›´å‡†ç¡®ã€æ›´é«˜æ•ˆçš„åœºæ™¯é‡å»ºæ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šJOGSçš„æ ¸å¿ƒæ€è·¯æ˜¯è”åˆä¼˜åŒ–3Dé«˜æ–¯ç‚¹å’Œç›¸æœºä½å§¿ã€‚é€šè¿‡è¿­ä»£åœ°æ›´æ–°3Dé«˜æ–¯å‚æ•°å’Œç›¸æœºä½å§¿ï¼Œå®ç°åœºæ™¯é‡å»ºä¿çœŸåº¦å’Œä½å§¿ç²¾åº¦çš„åŒæ­¥æå‡ã€‚è¿™ç§æ–¹æ³•é¿å…äº†ä½å§¿ä¼°è®¡è¯¯å·®çš„ç´¯ç§¯ï¼Œå¹¶èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”å…·æœ‰æŒ‘æˆ˜æ€§çš„åœºæ™¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šJOGSçš„æ•´ä½“æ¡†æ¶åŒ…å«ä¸¤ä¸ªäº¤é”™çš„é˜¶æ®µï¼š1) 3Dé«˜æ–¯å‚æ•°æ›´æ–°é˜¶æ®µï¼šåœ¨è¯¥é˜¶æ®µï¼Œç›¸æœºä½å§¿å›ºå®šï¼Œé€šè¿‡å¯å¾®æ¸²æŸ“æ›´æ–°3Dé«˜æ–¯å‚æ•°ï¼Œä¼˜åŒ–åœºæ™¯çš„é‡å»ºè´¨é‡ã€‚2) ç›¸æœºä½å§¿ç»†åŒ–é˜¶æ®µï¼šåœ¨è¯¥é˜¶æ®µï¼Œåˆ©ç”¨å®šåˆ¶çš„3Då…‰æµç®—æ³•ï¼Œç»“åˆå‡ ä½•å’Œå…‰åº¦çº¦æŸï¼Œå¯¹ç›¸æœºä½å§¿è¿›è¡Œä¼˜åŒ–ã€‚è¿™ä¸¤ä¸ªé˜¶æ®µäº¤æ›¿è¿›è¡Œï¼Œç›´è‡³æ”¶æ•›ã€‚

**å…³é”®åˆ›æ–°**ï¼šJOGSçš„å…³é”®åˆ›æ–°åœ¨äºå°†ä½å§¿ä¼°è®¡å’Œ3Dé«˜æ–¯æº…å°„çš„ä¼˜åŒ–è¿‡ç¨‹è¿›è¡Œäº†è§£è€¦å’Œè”åˆã€‚ä¼ ç»Ÿæ–¹æ³•é€šå¸¸å…ˆè¿›è¡Œä½å§¿ä¼°è®¡ï¼Œå†è¿›è¡Œåœºæ™¯é‡å»ºï¼Œè€ŒJOGSå°†è¿™ä¸¤ä¸ªè¿‡ç¨‹èåˆåœ¨ä¸€èµ·ï¼Œé€šè¿‡ååŒä¼˜åŒ–ï¼Œå®ç°äº†æ›´å¥½çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œå®šåˆ¶çš„3Då…‰æµç®—æ³•ä¹Ÿæ˜¯ä¸€ä¸ªé‡è¦çš„åˆ›æ–°ç‚¹ï¼Œå®ƒèƒ½å¤Ÿæ›´å‡†ç¡®åœ°ä¼°è®¡ç›¸æœºä½å§¿çš„å˜åŒ–ã€‚

**å…³é”®è®¾è®¡**ï¼šJOGSçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨3Dé«˜æ–¯æº…å°„ä½œä¸ºåœºæ™¯è¡¨ç¤ºï¼Œå…·æœ‰å¯å¾®æ¸²æŸ“çš„ç‰¹æ€§ï¼Œæ–¹ä¾¿è¿›è¡Œä¼˜åŒ–ã€‚2) è®¾è®¡äº†ä¸€ç§å®šåˆ¶çš„3Då…‰æµç®—æ³•ï¼Œè¯¥ç®—æ³•ç»“åˆäº†å‡ ä½•å’Œå…‰åº¦çº¦æŸï¼Œèƒ½å¤Ÿæ›´å‡†ç¡®åœ°ä¼°è®¡ç›¸æœºä½å§¿çš„å˜åŒ–ã€‚3) ä½¿ç”¨äº†ä¸€ç§äº¤é”™çš„ä¼˜åŒ–ç­–ç•¥ï¼Œå°†3Dé«˜æ–¯å‚æ•°æ›´æ–°å’Œç›¸æœºä½å§¿ç»†åŒ–ä¸¤ä¸ªé˜¶æ®µäº¤æ›¿è¿›è¡Œï¼Œç›´è‡³æ”¶æ•›ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°åŒ…æ‹¬å…‰åº¦æŸå¤±å’Œå‡ ä½•æŸå¤±ï¼Œç”¨äºçº¦æŸé‡å»ºè´¨é‡å’Œä½å§¿ç²¾åº¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

JOGSåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é‡å»ºè´¨é‡æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰çš„æ— COLMAPæŠ€æœ¯ã€‚ä¾‹å¦‚ï¼Œåœ¨æŸä¸ªæ•°æ®é›†ä¸Šï¼ŒJOGSçš„PSNRæŒ‡æ ‡æ¯”æœ€ä½³çš„æ— COLMAPæ–¹æ³•æé«˜äº†2dBä»¥ä¸Šã€‚æ­¤å¤–ï¼ŒJOGSåœ¨ä¸€èˆ¬æƒ…å†µä¸‹ä¹Ÿè¶…è¿‡äº†åŸºäºæ ‡å‡†COLMAPçš„åŸºçº¿æ–¹æ³•ï¼Œè¯æ˜äº†å…¶ä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

JOGSåœ¨ä¸‰ç»´é‡å»ºã€æ–°è§†è§’åˆæˆã€è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚è¯¥æ–¹æ³•å¯ä»¥ç”¨äºåˆ›å»ºé«˜è´¨é‡çš„3Dæ¨¡å‹ï¼Œå¹¶èƒ½å¤Ÿç”Ÿæˆé€¼çœŸçš„æ–°è§†è§’å›¾åƒã€‚æ­¤å¤–ï¼ŒJOGSè¿˜å¯ä»¥åº”ç”¨äºæœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸï¼Œä¸ºæœºå™¨äººæä¾›æ›´å‡†ç¡®çš„ç¯å¢ƒæ„ŸçŸ¥èƒ½åŠ›ã€‚æœªæ¥ï¼ŒJOGSæœ‰æœ›æˆä¸ºä¸€ç§é‡è¦çš„ä¸‰ç»´è§†è§‰æŠ€æœ¯ï¼Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Traditional novel view synthesis methods heavily rely on external camera pose estimation tools such as COLMAP, which often introduce computational bottlenecks and propagate errors. To address these challenges, we propose a unified framework that jointly optimizes 3D Gaussian points and camera poses without requiring pre-calibrated inputs. Our approach iteratively refines 3D Gaussian parameters and updates camera poses through a novel co-optimization strategy, ensuring simultaneous improvements in scene reconstruction fidelity and pose accuracy. The key innovation lies in decoupling the joint optimization into two interleaved phases: first, updating 3D Gaussian parameters via differentiable rendering with fixed poses, and second, refining camera poses using a customized 3D optical flow algorithm that incorporates geometric and photometric constraints. This formulation progressively reduces projection errors, particularly in challenging scenarios with large viewpoint variations and sparse feature distributions, where traditional methods struggle. Extensive evaluations on multiple datasets demonstrate that our approach significantly outperforms existing COLMAP-free techniques in reconstruction quality, and also surpasses the standard COLMAP-based baseline in general.

