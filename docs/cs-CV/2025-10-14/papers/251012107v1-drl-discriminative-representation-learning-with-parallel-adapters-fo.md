---
layout: default
title: DRL: Discriminative Representation Learning with Parallel Adapters for Class Incremental Learning
---

# DRL: Discriminative Representation Learning with Parallel Adapters for Class Incremental Learning

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.12107" target="_blank" class="toolbar-btn">arXiv: 2510.12107v1</a>
    <a href="https://arxiv.org/pdf/2510.12107.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.12107v1" 
            onclick="toggleFavorite(this, '2510.12107v1', 'DRL: Discriminative Representation Learning with Parallel Adapters for Class Incremental Learning')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Jiawei Zhan, Jun Liu, Jinlong Peng, Xiaochen Chen, Bin-Bin Gao, Yong Liu, Chengjie Wang

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-14

**Â§áÊ≥®**: 13 pages, 7 figures

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫DRLÊ°ÜÊû∂‰ª•Ëß£ÂÜ≥Â¢ûÈáèÂ≠¶‰π†‰∏≠ÁöÑË°®Á§∫ËΩ¨ÁßªÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Á±ªÂ¢ûÈáèÂ≠¶‰π†` `Ë°®Á§∫Â≠¶‰π†` `Â¢ûÈáèÂπ∂Ë°åÈÄÇÈÖçÂô®` `Ëß£ËÄ¶ÈîöÁõëÁù£` `Ê∑±Â∫¶Â≠¶‰π†` `Ê®°ÂûãÈÄÇÂ∫îÊÄß` `ÁâπÂæÅÂØπÈΩê`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®Á±ªÂ¢ûÈáèÂ≠¶‰π†‰∏≠Èù¢‰∏¥Ê®°ÂûãÂ§çÊùÇÊÄßÂ¢ûÂä†„ÄÅË°®Á§∫ËΩ¨Áßª‰∏çÂπ≥ÊªëÂíå‰ºòÂåñ‰∏ç‰∏ÄËá¥Á≠âÊåëÊàò„ÄÇ
2. ÊèêÂá∫ÁöÑDRLÊ°ÜÊû∂ÈÄöËøáÂ¢ûÈáèÂπ∂Ë°åÈÄÇÈÖçÂô®ÔºàIPAÔºâÁΩëÁªúÂíåËß£ËÄ¶ÈîöÁõëÁù£ÔºàDASÔºâÊúâÊïàËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢ò„ÄÇ
3. Âú®ÂÖ≠‰∏™Âü∫ÂáÜÊµãËØï‰∏äÁöÑÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåDRLÂú®Êï¥‰∏™Â¢ûÈáèÂ≠¶‰π†ËøáÁ®ã‰∏≠ÊÄßËÉΩ‰ºòË∂äÔºåËÆ≠ÁªÉÂíåÊé®ÁêÜÊïàÁéáÈ´ò„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÈöèÁùÄÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãÔºàPTMsÔºâÂú®ÈùûÈáçÊºîÁ±ªÂ¢ûÈáèÂ≠¶‰π†ÔºàCILÔºâÁ†îÁ©∂‰∏≠ÁöÑÂá∫Ëâ≤Ë°®Á§∫ËÉΩÂäõÔºåÂèñÂæó‰∫ÜÊòæËëóËøõÂ±ï„ÄÇÁÑ∂ËÄåÔºåÁî±‰∫éÊ®°ÂûãÂ§çÊùÇÊÄßÂ¢ûÂä†„ÄÅÂ¢ûÈáèÂ≠¶‰π†‰∏≠ÁöÑË°®Á§∫ËΩ¨Áßª‰∏çÂπ≥Êªë‰ª•ÂèäÈò∂ÊÆµÊÄßÂ≠êÈóÆÈ¢ò‰ºòÂåñ‰∏éÂÖ®Â±ÄÊé®ÁêÜ‰∏ç‰∏ÄËá¥Á≠âÊåëÊàòÔºåCIL‰ªçÁÑ∂ÊòØ‰∏ÄÈ°πÊûÅÂÖ∑ÊåëÊàòÊÄßÁöÑ‰ªªÂä°„ÄÇÊú¨ÊñáÊèêÂá∫‰∫ÜÂà§Âà´Ë°®Á§∫Â≠¶‰π†ÔºàDRLÔºâÊ°ÜÊû∂ÔºåÊó®Âú®ÊúâÊïà‰∏îÈ´òÊïàÂú∞ËøõË°åÂ¢ûÈáèÂ≠¶‰π†„ÄÇDRLÁöÑÁΩëÁªúÁß∞‰∏∫Â¢ûÈáèÂπ∂Ë°åÈÄÇÈÖçÂô®ÔºàIPAÔºâÁΩëÁªúÔºåÂü∫‰∫éPTMÊûÑÂª∫ÔºåÈÄöËøáÂú®ÊØè‰∏™Â¢ûÈáèÈò∂ÊÆµÂ≠¶‰π†ËΩªÈáèÁ∫ßÈÄÇÈÖçÂô®Êù•ÈÄêÊ≠•Â¢ûÂº∫Ê®°Âûã„ÄÇÈÄÇÈÖçÂô®ÈÄöËøáËΩ¨ÁßªÈó®‰∏éÂΩìÂâçÊ®°ÂûãÂπ∂Ë°åËøûÊé•ÔºåË¥üË¥£ÈÄÇÂ∫îÊñ∞Á±ªÂà´Ôºå‰ªéËÄå‰øùËØÅ‰∏çÂêåÂ¢ûÈáèÈò∂ÊÆµ‰πãÈó¥ÁöÑÂπ≥ÊªëË°®Á§∫ËΩ¨Áßª„ÄÇÊ≠§Â§ñÔºåËÆæËÆ°‰∫ÜËß£ËÄ¶ÈîöÁõëÁù£ÔºàDASÔºâÔºåÈÄöËøá‰∏éËôöÊãüÈîöÁÇπÊØîËæÉÊ≠£Ë¥üÊ†∑Êú¨ÁöÑÁ∫¶ÊùüÔºå‰øÉËøõÂà§Âà´Ë°®Á§∫Â≠¶‰π†ÔºåÁº©Â∞èÈò∂ÊÆµÊÄßÂ±ÄÈÉ®‰ºòÂåñ‰∏éÂÖ®Â±ÄÊé®ÁêÜ‰πãÈó¥ÁöÑÂ∑ÆË∑ù„ÄÇÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåDRLÂú®Êï¥‰∏™CILËøáÁ®ã‰∏≠ÂßãÁªà‰ºò‰∫éÂÖ∂‰ªñÊúÄÂÖàËøõÁöÑÊñπÊ≥ïÔºåÂêåÊó∂Âú®ËÆ≠ÁªÉÂíåÊé®ÁêÜÈò∂ÊÆµ‰øùÊåÅÈ´òÊïà„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Á±ªÂ¢ûÈáèÂ≠¶‰π†‰∏≠ÁöÑË°®Á§∫ËΩ¨Áßª‰∏çÂπ≥Êªë„ÄÅÊ®°ÂûãÂ§çÊùÇÊÄßÂ¢ûÂä†ÂèäÈò∂ÊÆµÊÄß‰ºòÂåñ‰∏éÂÖ®Â±ÄÊé®ÁêÜ‰∏ç‰∏ÄËá¥Á≠âÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®Â§ÑÁêÜÊñ∞Á±ªÂà´Êó∂ÔºåÂæÄÂæÄÂØºËá¥Ê®°ÂûãÊÄßËÉΩ‰∏ãÈôçÂíåË°®Á§∫ËÉΩÂäõ‰∏çË∂≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöDRLÊ°ÜÊû∂ÈÄöËøáÂ¢ûÈáèÂπ∂Ë°åÈÄÇÈÖçÂô®ÔºàIPAÔºâÁΩëÁªúÔºåÈÄêÊ≠•Â¢ûÂº∫Ê®°ÂûãËÉΩÂäõÔºåÈÄÇÂ∫îÊñ∞Á±ªÂà´ÔºåÂêåÊó∂‰øùÊåÅË°®Á§∫ËÉΩÂäõÁöÑ‰º†Êâø‰∏éÂπ≥ÊªëËΩ¨Áßª„ÄÇËß£ËÄ¶ÈîöÁõëÁù£ÔºàDASÔºâÂàôÈÄöËøáËß£ËÄ¶Ê≠£Ë¥üÊ†∑Êú¨ÁöÑÁ∫¶ÊùüÔºå‰øÉËøõ‰∏çÂêåÈò∂ÊÆµÁâπÂæÅÁ©∫Èó¥ÁöÑ‰∏ÄËá¥ÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöDRLÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÊã¨‰∏§‰∏™Ê®°ÂùóÔºöÂ¢ûÈáèÂπ∂Ë°åÈÄÇÈÖçÂô®ÔºàIPAÔºâÁΩëÁªúÂíåËß£ËÄ¶ÈîöÁõëÁù£ÔºàDASÔºâ„ÄÇIPAÁΩëÁªúÂú®ÊØè‰∏™Â¢ûÈáèÈò∂ÊÆµÂ≠¶‰π†ËΩªÈáèÁ∫ßÈÄÇÈÖçÂô®ÔºåDASÂàôÈÄöËøáËôöÊãüÈîöÁÇπÂØπÊ†∑Êú¨ËøõË°åÊØîËæÉÔºåÁ°Æ‰øùÁâπÂæÅË°®Á§∫ÁöÑ‰∏ÄËá¥ÊÄß„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöDRLÁöÑÊ†∏ÂøÉÂàõÊñ∞Âú®‰∫éÈÄöËøáËΩªÈáèÁ∫ßÈÄÇÈÖçÂô®ÂÆûÁé∞Âπ≥ÊªëÁöÑË°®Á§∫ËΩ¨ÁßªÔºåÂπ∂ÈÄöËøáËß£ËÄ¶ÈîöÁõëÁù£‰øÉËøõ‰∏çÂêåÈò∂ÊÆµÈó¥ÁöÑÁâπÂæÅÂØπÈΩê„ÄÇËøôÁßçËÆæËÆ°‰∏é‰º†ÁªüÊñπÊ≥ïÁõ∏ÊØîÔºåÊòæËëóÊèêÈ´ò‰∫ÜÊ®°ÂûãÂú®Â¢ûÈáèÂ≠¶‰π†‰∏≠ÁöÑË°®Áé∞„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÁΩëÁªúÁªìÊûÑ‰∏äÔºåÈááÁî®ËΩªÈáèÁ∫ßÈÄÇÈÖçÂô®‰ª•ÂáèÂ∞ëÂèÇÊï∞Â≠¶‰π†ÂºÄÈîÄÔºõÊçüÂ§±ÂáΩÊï∞ËÆæËÆ°‰∏äÔºåDASÈÄöËøáËôöÊãüÈîöÁÇπËß£ËÄ¶Ê≠£Ë¥üÊ†∑Êú¨ÁöÑÁ∫¶ÊùüÔºåÁ°Æ‰øùÁâπÂæÅÁ©∫Èó¥ÁöÑÂØπÈΩê‰∏é‰∏ÄËá¥ÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåDRLÂú®ÂÖ≠‰∏™Âü∫ÂáÜÊµãËØï‰∏äÂùá‰ºò‰∫éÂÖ∂‰ªñÊúÄÂÖàËøõÁöÑÊñπÊ≥ïÔºåÂ∞§ÂÖ∂Âú®ËÆ≠ÁªÉÂíåÊé®ÁêÜÊïàÁéáÊñπÈù¢Ë°®Áé∞Á™ÅÂá∫ÔºåÊèêÂçáÂπÖÂ∫¶ËææÂà∞10%‰ª•‰∏äÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®Á±ªÂ¢ûÈáèÂ≠¶‰π†‰∏≠ÁöÑÊúâÊïàÊÄßÂíåÂèØÈù†ÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Êô∫ËÉΩÊú∫Âô®‰∫∫„ÄÅËá™Âä®È©æÈ©∂„ÄÅÂåªÁñóÂΩ±ÂÉèÂàÜÊûêÁ≠âÈúÄË¶ÅÊåÅÁª≠Â≠¶‰π†Êñ∞Á±ªÂà´ÁöÑÂú∫ÊôØ„ÄÇÈÄöËøáÊúâÊïàÁöÑÂ¢ûÈáèÂ≠¶‰π†ÔºåÊ®°ÂûãËÉΩÂ§üÂú®‰∏çÊñ≠ÂèòÂåñÁöÑÁéØÂ¢É‰∏≠‰øùÊåÅÈ´òÊïàÁöÑÂ≠¶‰π†ËÉΩÂäõÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÊú™Êù•ÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> With the excellent representation capabilities of Pre-Trained Models (PTMs), remarkable progress has been made in non-rehearsal Class-Incremental Learning (CIL) research. However, it remains an extremely challenging task due to three conundrums: increasingly large model complexity, non-smooth representation shift during incremental learning and inconsistency between stage-wise sub-problem optimization and global inference. In this work, we propose the Discriminative Representation Learning (DRL) framework to specifically address these challenges. To conduct incremental learning effectively and yet efficiently, the DRL's network, called Incremental Parallel Adapter (IPA) network, is built upon a PTM and increasingly augments the model by learning a lightweight adapter with a small amount of parameter learning overhead in each incremental stage. The adapter is responsible for adapting the model to new classes, it can inherit and propagate the representation capability from the current model through parallel connection between them by a transfer gate. As a result, this design guarantees a smooth representation shift between different incremental stages. Furthermore, to alleviate inconsistency and enable comparable feature representations across incremental stages, we design the Decoupled Anchor Supervision (DAS). It decouples constraints of positive and negative samples by respectively comparing them with the virtual anchor. This decoupling promotes discriminative representation learning and aligns the feature spaces learned at different stages, thereby narrowing the gap between stage-wise local optimization over a subset of data and global inference across all classes. Extensive experiments on six benchmarks reveal that our DRL consistently outperforms other state-of-the-art methods throughout the entire CIL period while maintaining high efficiency in both training and inference phases.

