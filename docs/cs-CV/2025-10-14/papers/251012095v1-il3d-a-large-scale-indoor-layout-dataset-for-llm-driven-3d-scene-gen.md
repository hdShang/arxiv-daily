---
layout: default
title: IL3D: A Large-Scale Indoor Layout Dataset for LLM-Driven 3D Scene Generation
---

# IL3D: A Large-Scale Indoor Layout Dataset for LLM-Driven 3D Scene Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.12095" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.12095v1</a>
  <a href="https://arxiv.org/pdf/2510.12095.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.12095v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.12095v1', 'IL3D: A Large-Scale Indoor Layout Dataset for LLM-Driven 3D Scene Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wenxu Zhou, Kaixuan Nie, Hang Du, Dong Yin, Wei Huang, Siqiang Guo, Xiaobo Zhang, Pengbo Hu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-14

**å¤‡æ³¨**: 9 pages main paper; 15 pages references and appendix

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**IL3Dï¼šç”¨äºLLMé©±åŠ¨çš„3Dåœºæ™¯ç”Ÿæˆçš„å¤§è§„æ¨¡å®¤å†…å¸ƒå±€æ•°æ®é›†**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `3Dåœºæ™¯ç”Ÿæˆ` `å®¤å†…å¸ƒå±€` `å¤§å‹è¯­è¨€æ¨¡å‹` `å¤šæ¨¡æ€å­¦ä¹ ` `æ•°æ®é›†` `å…·èº«æ™ºèƒ½` `è‡ªç„¶è¯­è¨€æ ‡æ³¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰3Dåœºæ™¯ç”Ÿæˆæ–¹æ³•ç¼ºä¹å¤§è§„æ¨¡ã€é«˜è´¨é‡ã€å¤šæ ·åŒ–çš„å®¤å†…å¸ƒå±€æ•°æ®é›†ï¼Œé™åˆ¶äº†LLMåœ¨ç›¸å…³ä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚
2. IL3Dæ•°æ®é›†é€šè¿‡æä¾›å¤§é‡å®¤å†…å¸ƒå±€ã€3Då¯¹è±¡èµ„äº§å’Œè‡ªç„¶è¯­è¨€æ ‡æ³¨ï¼Œä¸ºLLMé©±åŠ¨çš„3Dåœºæ™¯ç”Ÿæˆæä¾›æ”¯æŒã€‚
3. å®éªŒè¡¨æ˜ï¼Œåœ¨IL3Dä¸Šè¿›è¡Œç›‘ç£å¾®è°ƒçš„LLMåœ¨åœºæ™¯ç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°å‡ºæ›´å¥½çš„æ³›åŒ–èƒ½åŠ›å’Œæ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶æå‡ºäº†IL3Dï¼Œä¸€ä¸ªå¤§è§„æ¨¡æ•°æ®é›†ï¼Œä¸“ä¸ºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„3Dåœºæ™¯ç”Ÿæˆè€Œè®¾è®¡ï¼Œæ—¨åœ¨è§£å†³å®¤å†…å¸ƒå±€è®¾è®¡ä¸­å¯¹å¤šæ ·åŒ–ã€é«˜è´¨é‡è®­ç»ƒæ•°æ®çš„è¿«åˆ‡éœ€æ±‚ã€‚IL3DåŒ…å«27,816ä¸ªå®¤å†…å¸ƒå±€ï¼Œæ¶µç›–18ç§å¸¸è§çš„æˆ¿é—´ç±»å‹ï¼Œä»¥åŠä¸€ä¸ªåŒ…å«29,215ä¸ªé«˜ä¿çœŸ3Då¯¹è±¡èµ„äº§çš„åº“ã€‚æ•°æ®é›†è¿˜å¯Œå«å®ä¾‹çº§åˆ«çš„è‡ªç„¶è¯­è¨€æ ‡æ³¨ï¼Œä»¥æ”¯æŒè§†è§‰-è¯­è¨€ä»»åŠ¡çš„é²æ£’å¤šæ¨¡æ€å­¦ä¹ ã€‚æˆ‘ä»¬å»ºç«‹äº†ä¸¥æ ¼çš„åŸºå‡†æ¥è¯„ä¼°LLMé©±åŠ¨çš„åœºæ™¯ç”Ÿæˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨IL3Dä¸Šå¯¹LLMè¿›è¡Œç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æ˜¾è‘—æé«˜äº†æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶è¶…è¶Šäº†åœ¨å…¶ä»–æ•°æ®é›†ä¸Šè¿›è¡ŒSFTçš„æ€§èƒ½ã€‚IL3Dæä¾›çµæ´»çš„å¤šæ¨¡æ€æ•°æ®å¯¼å‡ºåŠŸèƒ½ï¼ŒåŒ…æ‹¬ç‚¹äº‘ã€3Dè¾¹ç•Œæ¡†ã€å¤šè§†è§’å›¾åƒã€æ·±åº¦å›¾ã€æ³•çº¿è´´å›¾å’Œè¯­ä¹‰æ©ç ï¼Œä»è€Œèƒ½å¤Ÿæ— ç¼é€‚åº”å„ç§è§†è§‰ä»»åŠ¡ã€‚ä½œä¸ºä¸€ä¸ªé€šç”¨ä¸”å¼ºå¤§çš„èµ„æºï¼ŒIL3Dé€šè¿‡æä¾›é«˜ä¿çœŸåœºæ™¯æ•°æ®æ¥æ”¯æŒå…·èº«æ™ºèƒ½ä½“çš„ç¯å¢ƒæ„ŸçŸ¥ä»»åŠ¡ï¼Œä»è€Œæ˜¾è‘—æ¨è¿›äº†3Dåœºæ™¯ç”Ÿæˆå’Œå…·èº«æ™ºèƒ½é¢†åŸŸçš„ç ”ç©¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰3Dåœºæ™¯ç”Ÿæˆæ–¹æ³•é¢ä¸´æ•°æ®åŒ®ä¹çš„æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯ç¼ºä¹å¤§è§„æ¨¡ã€å¤šæ ·åŒ–ã€å¸¦æœ‰è‡ªç„¶è¯­è¨€æè¿°çš„å®¤å†…åœºæ™¯æ•°æ®é›†ã€‚è¿™é™åˆ¶äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ç†è§£å’Œç”Ÿæˆé€¼çœŸã€ç¬¦åˆäººç±»æ„å›¾çš„3Då®¤å†…åœºæ™¯æ–¹é¢çš„èƒ½åŠ›ã€‚ç°æœ‰æ•°æ®é›†é€šå¸¸è§„æ¨¡è¾ƒå°ï¼Œè¦†ç›–çš„åœºæ™¯ç±»å‹æœ‰é™ï¼Œä¸”ç¼ºä¹ç»†ç²’åº¦çš„è¯­ä¹‰ä¿¡æ¯å’Œè‡ªç„¶è¯­è¨€æè¿°ï¼Œéš¾ä»¥æ»¡è¶³LLMçš„è®­ç»ƒéœ€æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šIL3Dçš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªå¤§è§„æ¨¡ã€é«˜è´¨é‡ã€å¤šæ¨¡æ€çš„å®¤å†…å¸ƒå±€æ•°æ®é›†ï¼ŒåŒ…å«ä¸°å¯Œçš„3Dåœºæ™¯ã€å¯¹è±¡èµ„äº§å’Œè‡ªç„¶è¯­è¨€æ ‡æ³¨ã€‚é€šè¿‡æä¾›å……è¶³çš„è®­ç»ƒæ•°æ®ï¼Œä½¿LLMèƒ½å¤Ÿå­¦ä¹ åˆ°å®¤å†…åœºæ™¯çš„ç»“æ„ã€å¯¹è±¡ä¹‹é—´çš„å…³ç³»ä»¥åŠäººç±»å¯¹åœºæ™¯çš„æè¿°æ–¹å¼ï¼Œä»è€Œæå‡LLMåœ¨3Dåœºæ™¯ç”Ÿæˆä»»åŠ¡ä¸­çš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šIL3Dæ•°æ®é›†çš„æ„å»ºä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) åœºæ™¯æ”¶é›†ï¼šæ”¶é›†å¤§é‡çš„å®¤å†…å¸ƒå±€æ•°æ®ï¼Œæ¶µç›–å¤šç§æˆ¿é—´ç±»å‹ã€‚2) å¯¹è±¡èµ„äº§æ„å»ºï¼šæ„å»ºä¸€ä¸ªåŒ…å«å¤§é‡é«˜ä¿çœŸ3Då¯¹è±¡èµ„äº§çš„åº“ã€‚3) æ•°æ®æ ‡æ³¨ï¼šå¯¹åœºæ™¯ä¸­çš„å¯¹è±¡è¿›è¡Œå®ä¾‹çº§åˆ«çš„è‡ªç„¶è¯­è¨€æ ‡æ³¨ï¼Œæè¿°å¯¹è±¡çš„ä½ç½®ã€å±æ€§å’Œä¸å…¶ä»–å¯¹è±¡çš„å…³ç³»ã€‚4) æ•°æ®æ ¼å¼è½¬æ¢ï¼šå°†æ•°æ®è½¬æ¢ä¸ºå¤šç§æ ¼å¼ï¼ŒåŒ…æ‹¬ç‚¹äº‘ã€3Dè¾¹ç•Œæ¡†ã€å¤šè§†è§’å›¾åƒç­‰ï¼Œä»¥é€‚åº”ä¸åŒçš„è§†è§‰ä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šIL3Dçš„å…³é”®åˆ›æ–°åœ¨äºå…¶æ•°æ®é›†çš„è§„æ¨¡ã€å¤šæ ·æ€§å’Œå¤šæ¨¡æ€æ€§ã€‚ç›¸æ¯”äºç°æœ‰æ•°æ®é›†ï¼ŒIL3DåŒ…å«æ›´å¤šçš„åœºæ™¯ã€å¯¹è±¡å’Œæ ‡æ³¨ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ”¯æŒLLMçš„è®­ç»ƒã€‚æ­¤å¤–ï¼ŒIL3Dè¿˜æä¾›äº†å¤šç§æ•°æ®æ ¼å¼ï¼Œæ–¹ä¾¿ç ”ç©¶äººå‘˜åœ¨ä¸åŒçš„è§†è§‰ä»»åŠ¡ä¸­ä½¿ç”¨ã€‚

**å…³é”®è®¾è®¡**ï¼šIL3Dæ•°æ®é›†çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) åœºæ™¯ç±»å‹çš„é€‰æ‹©ï¼šé€‰æ‹©äº†18ç§å¸¸è§çš„æˆ¿é—´ç±»å‹ï¼Œä»¥ä¿è¯æ•°æ®é›†çš„å¤šæ ·æ€§ã€‚2) å¯¹è±¡èµ„äº§çš„è´¨é‡ï¼šä½¿ç”¨äº†é«˜ä¿çœŸçš„3Då¯¹è±¡èµ„äº§ï¼Œä»¥ä¿è¯åœºæ™¯çš„çœŸå®æ„Ÿã€‚3) è‡ªç„¶è¯­è¨€æ ‡æ³¨çš„ç»†ç²’åº¦ï¼šå¯¹åœºæ™¯ä¸­çš„å¯¹è±¡è¿›è¡Œå®ä¾‹çº§åˆ«çš„æ ‡æ³¨ï¼Œå¹¶æè¿°å¯¹è±¡ä¹‹é—´çš„å…³ç³»ï¼Œä»¥æä¾›æ›´ä¸°å¯Œçš„ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨IL3Dä¸Šå¯¹LLMè¿›è¡Œç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æ˜¾è‘—æé«˜äº†æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶è¶…è¶Šäº†åœ¨å…¶ä»–æ•°æ®é›†ä¸Šè¿›è¡ŒSFTçš„æ€§èƒ½ã€‚å…·ä½“æ¥è¯´ï¼Œä½¿ç”¨IL3Dè¿›è¡ŒSFTçš„LLMåœ¨åœºæ™¯ç”Ÿæˆä»»åŠ¡ä¸­çš„æŒ‡æ ‡æå‡äº†XX%ï¼ˆå…·ä½“æ•°å€¼æœªçŸ¥ï¼‰ï¼Œè¡¨æ˜IL3Dèƒ½å¤Ÿæœ‰æ•ˆåœ°æå‡LLMåœ¨3Dåœºæ™¯ç”Ÿæˆæ–¹é¢çš„èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

IL3Dæ•°æ®é›†å¯å¹¿æ³›åº”ç”¨äº3Dåœºæ™¯ç”Ÿæˆã€å…·èº«æ™ºèƒ½ã€æœºå™¨äººå¯¼èˆªã€è™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®ç­‰é¢†åŸŸã€‚å®ƒèƒ½å¤Ÿä¸ºLLMæä¾›å……è¶³çš„è®­ç»ƒæ•°æ®ï¼Œæå‡LLMåœ¨ç†è§£å’Œç”Ÿæˆ3Dåœºæ™¯æ–¹é¢çš„èƒ½åŠ›ï¼Œä»è€Œä¿ƒè¿›è¿™äº›é¢†åŸŸçš„å‘å±•ã€‚ä¾‹å¦‚ï¼Œåœ¨å…·èº«æ™ºèƒ½é¢†åŸŸï¼ŒIL3Då¯ä»¥ç”¨äºè®­ç»ƒæœºå™¨äººç†è§£å®¤å†…ç¯å¢ƒï¼Œå¹¶æ ¹æ®äººç±»æŒ‡ä»¤è¿›è¡Œå¯¼èˆªå’Œæ“ä½œã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In this study, we present IL3D, a large-scale dataset meticulously designed for large language model (LLM)-driven 3D scene generation, addressing the pressing demand for diverse, high-quality training data in indoor layout design. Comprising 27,816 indoor layouts across 18 prevalent room types and a library of 29,215 high-fidelity 3D object assets, IL3D is enriched with instance-level natural language annotations to support robust multimodal learning for vision-language tasks. We establish rigorous benchmarks to evaluate LLM-driven scene generation. Experimental results show that supervised fine-tuning (SFT) of LLMs on IL3D significantly improves generalization and surpasses the performance of SFT on other datasets. IL3D offers flexible multimodal data export capabilities, including point clouds, 3D bounding boxes, multiview images, depth maps, normal maps, and semantic masks, enabling seamless adaptation to various visual tasks. As a versatile and robust resource, IL3D significantly advances research in 3D scene generation and embodied intelligence, by providing high-fidelity scene data to support environment perception tasks of embodied agents.

