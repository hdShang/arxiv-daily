---
layout: default
title: CrossRay3D: Geometry and Distribution Guidance for Efficient Multimodal 3D Detection
---

# CrossRay3D: Geometry and Distribution Guidance for Efficient Multimodal 3D Detection

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.15991" target="_blank" class="toolbar-btn">arXiv: 2510.15991v3</a>
    <a href="https://arxiv.org/pdf/2510.15991.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.15991v3" 
            onclick="toggleFavorite(this, '2510.15991v3', 'CrossRay3D: Geometry and Distribution Guidance for Efficient Multimodal 3D Detection')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Huiming Yang, Wenzhuo Liu, Yicheng Qiao, Lei Yang, Xianzhu Zeng, Li Wang, Zhiwei Li, Zijian Zeng, Zhiying Jiang, Huaping Liu, Kunfeng Wang

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-14 (Êõ¥Êñ∞: 2025-11-04)

**Â§áÊ≥®**: 13 pages

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**CrossRay3DÔºöÈÄöËøáÂá†‰Ωï‰∏éÂàÜÂ∏ÉÂºïÂØºÊèêÂçáÂ§öÊ®°ÊÄÅ3DÊ£ÄÊµãÊïàÁéá**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅ3DÊ£ÄÊµã` `Á®ÄÁñèÊ£ÄÊµãÂô®` `Âá†‰Ωï‰ø°ÊÅØ` `Á±ªÂà´Âπ≥Ë°°` `Ëá™Âä®È©æÈ©∂`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁ®ÄÁñèÂ§öÊ®°ÊÄÅ3DÊ£ÄÊµãÂô®ÂøΩÁï•‰∫ÜtokenË°®ÂæÅÁöÑË¥®ÈáèÔºåÂØºËá¥ÂâçÊôØË¥®Èáè‰∏ç‰Ω≥ÔºåÈôêÂà∂‰∫ÜÊ£ÄÊµãÊÄßËÉΩ„ÄÇ
2. CrossRay3DÈÄöËøáÂºïÂÖ•Ray-Aware SupervisionÂíåClass-Balanced SupervisionÔºåÂ¢ûÂº∫tokenÁöÑÂá†‰Ωï‰ø°ÊÅØÂíåÁ±ªÂà´ËØ≠‰πâË°®ÂæÅ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåCrossRay3DÂú®nuScenesÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜSOTAÊÄßËÉΩÔºåÂπ∂Âú®Êï∞ÊçÆÁº∫Â§±ÊÉÖÂÜµ‰∏ãË°®Áé∞Âá∫ËâØÂ•ΩÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫CrossRay3DÁöÑÈ´òÊïàÂ§öÊ®°ÊÄÅ3DÊ£ÄÊµãÂô®„ÄÇÈíàÂØπÁé∞ÊúâÁ®ÄÁñèÊ£ÄÊµãÂô®tokenË°®ÂæÅË¥®Èáè‰∏çÈ´òÔºåÂØºËá¥ÂâçÊôØË¥®ÈáèÊ¨†‰Ω≥ÂíåÊÄßËÉΩÂèóÈôêÁöÑÈóÆÈ¢òÔºåÊú¨ÊñáÊèêÂá∫Sparse Selector (SS)„ÄÇSSÁöÑÊ†∏ÂøÉÊ®°ÂùóÊòØRay-Aware Supervision (RAS)ÔºåÂÆÉÂú®ËÆ≠ÁªÉÈò∂ÊÆµ‰øùÁïô‰∏∞ÂØåÁöÑÂá†‰Ωï‰ø°ÊÅØÔºå‰ª•ÂèäClass-Balanced SupervisionÔºåËá™ÈÄÇÂ∫îÂú∞ÈáçÊñ∞Âä†ÊùÉÁ±ªÂà´ËØ≠‰πâÁöÑÈáçË¶ÅÊÄßÔºåÁ°Æ‰øù‰∏éÂ∞èÁâ©‰ΩìÁõ∏ÂÖ≥ÁöÑtokenÂú®tokenÈááÊ†∑ÊúüÈó¥Ë¢´‰øùÁïôÔºå‰ªéËÄå‰ºò‰∫éÂÖ∂‰ªñÁ®ÄÁñèÂ§öÊ®°ÊÄÅÊ£ÄÊµãÂô®„ÄÇÊ≠§Â§ñÔºåÊú¨ÊñáËÆæËÆ°‰∫ÜRay Positional Encoding (Ray PE)Êù•Ëß£ÂÜ≥LiDARÊ®°ÊÄÅÂíåÂõæÂÉè‰πãÈó¥ÁöÑÂàÜÂ∏ÉÂ∑ÆÂºÇ„ÄÇÂú®nuScenesÂü∫ÂáÜÊµãËØï‰∏≠ÔºåCrossRay3DÂÆûÁé∞‰∫Ü72.4 mAPÂíå74.7 NDSÁöÑstate-of-the-artÊÄßËÉΩÔºåÂπ∂‰∏îÊØîÂÖ∂‰ªñÈ¢ÜÂÖàÊñπÊ≥ïÂø´1.84ÂÄç„ÄÇCrossRay3DÂú®LiDARÊàñÁõ∏Êú∫Êï∞ÊçÆÈÉ®ÂàÜÊàñÂÆåÂÖ®Áº∫Â§±ÁöÑÊÉÖÂÜµ‰∏ã‰πüË°®Áé∞Âá∫Âº∫Â§ßÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÁ®ÄÁñèÂ§öÊ®°ÊÄÅ3DÊ£ÄÊµãÂô®Âú®tokenË°®ÂæÅË¥®Èáè‰∏äÂ≠òÂú®‰∏çË∂≥ÔºåÂØºËá¥Ê£ÄÊµãÁ≤æÂ∫¶ÂèóÈôêÔºåÂ∞§ÂÖ∂ÊòØÂú®Â∞èÁâ©‰ΩìÊ£ÄÊµãÊñπÈù¢Ë°®Áé∞‰∏ç‰Ω≥„ÄÇËøô‰∫õÊ£ÄÊµãÂô®ÈÄöÂ∏∏Êó†Ê≥ïÂÖÖÂàÜÂà©Áî®Âá†‰ΩïÁªìÊûÑ‰ø°ÊÅØÂíåÁ±ªÂà´ÂàÜÂ∏É‰ø°ÊÅØÔºå‰ªéËÄåÂΩ±Âìç‰∫ÜÊï¥‰ΩìÊÄßËÉΩ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊú¨ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÂºïÂÖ•Âá†‰ΩïÁªìÊûÑÂíåÁ±ªÂà´ÂàÜÂ∏ÉÁöÑÂºïÂØºÔºåÊù•ÊèêÂçátokenË°®ÂæÅÁöÑË¥®Èáè„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÈÄöËøáRay-Aware Supervision‰øùÁïô‰∏∞ÂØåÁöÑÂá†‰Ωï‰ø°ÊÅØÔºåÂπ∂ÈÄöËøáClass-Balanced SupervisionËá™ÈÄÇÂ∫îÂú∞Ë∞ÉÊï¥Á±ªÂà´ËØ≠‰πâÁöÑÈáçË¶ÅÊÄßÔºå‰ªéËÄåÊîπÂñÑtokenÁöÑÈááÊ†∑ÂíåÈÄâÊã©ËøáÁ®ã„ÄÇËøôÊ†∑ËÆæËÆ°ÁöÑÁõÆÁöÑÊòØ‰ΩøÊ£ÄÊµãÂô®ËÉΩÂ§üÊõ¥Â•ΩÂú∞ÂÖ≥Ê≥®ÂâçÊôØÁõÆÊ†áÔºåÁâπÂà´ÊòØÂ∞èÁâ©‰Ωì„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöCrossRay3DÊòØ‰∏Ä‰∏™Á´ØÂà∞Á´ØÁöÑÁ®ÄÁñèÂ§öÊ®°ÊÄÅ3DÊ£ÄÊµãÂô®ÔºåÂÖ∂‰∏ªË¶ÅÁªÑÊàêÈÉ®ÂàÜÂåÖÊã¨Ôºö1) ÁâπÂæÅÊèêÂèñÊ®°ÂùóÔºàÁî®‰∫éÊèêÂèñLiDARÂíåÂõæÂÉèÁöÑÁâπÂæÅÔºâÔºõ2) Sparse Selector (SS)Ê®°ÂùóÔºåÂåÖÂê´Ray-Aware Supervision (RAS)ÂíåClass-Balanced SupervisionÔºõ3) Ray Positional Encoding (Ray PE)Ê®°ÂùóÔºõ4) Ê£ÄÊµãÂ§¥„ÄÇÊï¥‰ΩìÊµÅÁ®ãÊòØÈ¶ñÂÖàÊèêÂèñÂ§öÊ®°ÊÄÅÁâπÂæÅÔºåÁÑ∂ÂêéÈÄöËøáSSÊ®°ÂùóÈÄâÊã©È´òË¥®ÈáèÁöÑtokenÔºåÂπ∂Âà©Áî®Ray PEÊ®°ÂùóËøõË°å‰ΩçÁΩÆÁºñÁ†ÅÔºåÊúÄÂêéÈÄöËøáÊ£ÄÊµãÂ§¥ËøõË°å3DÁõÆÊ†áÊ£ÄÊµã„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊú¨ÊñáÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éSparse Selector (SS)Ê®°ÂùóÔºåÁâπÂà´ÊòØÂÖ∂‰∏≠ÁöÑRay-Aware Supervision (RAS)ÂíåClass-Balanced Supervision„ÄÇRASÈÄöËøáÂ∞ÑÁ∫øÊÑüÁü•ÁöÑÁõëÁù£ÊñπÂºèÔºåÂú®ËÆ≠ÁªÉÈò∂ÊÆµ‰øùÁïô‰∏∞ÂØåÁöÑÂá†‰Ωï‰ø°ÊÅØÔºåËøô‰∏é‰º†ÁªüÁöÑÁõëÁù£ÊñπÂºè‰∏çÂêåÔºåÂêéËÄÖÂèØËÉΩÂøΩÁï•‰∫ÜÈáçË¶ÅÁöÑÂá†‰ΩïÁªìÊûÑ„ÄÇClass-Balanced SupervisionÂàôÈÄöËøáËá™ÈÄÇÂ∫îÂú∞Ë∞ÉÊï¥Á±ªÂà´ÊùÉÈáçÔºåËß£ÂÜ≥‰∫ÜÂ∞èÁâ©‰ΩìÊ£ÄÊµã‰∏≠ÁöÑÁ±ªÂà´‰∏çÂπ≥Ë°°ÈóÆÈ¢ò„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöRay-Aware Supervision (RAS)ÁöÑÂÖ∑‰ΩìÂÆûÁé∞ÊñπÂºèÊòØÔºåÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠ÔºåÂØπÊØè‰∏™tokenÂºïÂÖ•Â∞ÑÁ∫øÊñπÂêëÁöÑÁõëÁù£‰ø°Âè∑ÔºåÈºìÂä±ÁΩëÁªúÂ≠¶‰π†token‰∏éÂ∞ÑÁ∫ø‰πãÈó¥ÁöÑÂá†‰ΩïÂÖ≥Á≥ª„ÄÇClass-Balanced SupervisionÁöÑÂÖ∑‰ΩìÂÆûÁé∞ÊñπÂºèÊòØÔºåÊ†πÊçÆÊØè‰∏™Á±ªÂà´ÁöÑÊ†∑Êú¨Êï∞ÈáèÔºåÂä®ÊÄÅÂú∞Ë∞ÉÊï¥ÊçüÂ§±ÂáΩÊï∞ÁöÑÊùÉÈáçÔºå‰ΩøÂæóÂ∞èÊ†∑Êú¨Á±ªÂà´ËÉΩÂ§üËé∑ÂæóÊõ¥Â§ßÁöÑÂÖ≥Ê≥®„ÄÇRay Positional Encoding (Ray PE)ÁöÑËÆæËÆ°ËÄÉËôë‰∫ÜLiDARÂíåÂõæÂÉèÂú®Á©∫Èó¥ÂàÜÂ∏É‰∏äÁöÑÂ∑ÆÂºÇÔºåÈÄöËøáÂºïÂÖ•Â∞ÑÁ∫øÊñπÂêëÁöÑ‰ΩçÁΩÆÁºñÁ†ÅÔºå‰ΩøÂæóÁΩëÁªúËÉΩÂ§üÊõ¥Â•ΩÂú∞ÁêÜËß£Â§öÊ®°ÊÄÅÁâπÂæÅ‰πãÈó¥ÁöÑÂÖ≥Á≥ª„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

CrossRay3DÂú®nuScenesÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåmAPËææÂà∞72.4ÔºåNDSËææÂà∞74.7ÔºåË∂ÖË∂ä‰∫ÜÁé∞ÊúâÁöÑSOTAÊñπÊ≥ï„ÄÇÊõ¥ÈáçË¶ÅÁöÑÊòØÔºåCrossRay3DÂú®‰øùÊåÅÈ´òÊÄßËÉΩÁöÑÂêåÊó∂ÔºåÂÆûÁé∞‰∫Ü1.84ÂÄçÁöÑÂä†ÈÄüÔºå‰ΩøÂÖ∂Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠Êõ¥ÂÖ∑‰ºòÂäø„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïÂú®LiDARÊàñÁõ∏Êú∫Êï∞ÊçÆÈÉ®ÂàÜÊàñÂÆåÂÖ®Áº∫Â§±ÁöÑÊÉÖÂÜµ‰∏ãÔºå‰ªçÁÑ∂Ë°®Áé∞Âá∫Âº∫Â§ßÁöÑÈ≤ÅÊ£íÊÄßÔºåËØÅÊòé‰∫ÜÂÖ∂Âú®ÊÅ∂Âä£ÁéØÂ¢É‰∏ãÁöÑÂèØÈù†ÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

CrossRay3DÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂåÖÊã¨Ëá™Âä®È©æÈ©∂„ÄÅÊú∫Âô®‰∫∫ÂØºËà™„ÄÅÊô∫ËÉΩ‰∫§ÈÄöÁ≠âÈ¢ÜÂüü„ÄÇÂÖ∂È´òÊïàÁöÑËÆ°ÁÆóÊÄßËÉΩÂíåÂº∫Â§ßÁöÑÈ≤ÅÊ£íÊÄß‰ΩøÂÖ∂ËÉΩÂ§üÂú®ËµÑÊ∫êÂèóÈôêÁöÑÂπ≥Âè∞‰∏äÈÉ®ÁΩ≤ÔºåÂπ∂ÈÄÇÂ∫îÂêÑÁßçÂ§çÊùÇÁöÑÁéØÂ¢ÉÊù°‰ª∂„ÄÇËØ•Á†îÁ©∂ÁöÑÊú™Êù•ÂΩ±ÂìçÂú®‰∫éÊé®Âä®Â§öÊ®°ÊÄÅ3DÊÑüÁü•ÊäÄÊúØÁöÑÂèëÂ±ïÔºåÂπ∂‰∏∫Êõ¥ÂÆâÂÖ®„ÄÅÊõ¥Êô∫ËÉΩÁöÑËá™‰∏ªÁ≥ªÁªüÊèê‰æõÊäÄÊúØÊîØÊåÅ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> The sparse cross-modality detector offers more advantages than its counterpart, the Bird's-Eye-View (BEV) detector, particularly in terms of adaptability for downstream tasks and computational cost savings. However, existing sparse detectors overlook the quality of token representation, leaving it with a sub-optimal foreground quality and limited performance. In this paper, we identify that the geometric structure preserved and the class distribution are the key to improving the performance of the sparse detector, and propose a Sparse Selector (SS). The core module of SS is Ray-Aware Supervision (RAS), which preserves rich geometric information during the training stage, and Class-Balanced Supervision, which adaptively reweights the salience of class semantics, ensuring that tokens associated with small objects are retained during token sampling. Thereby, outperforming other sparse multi-modal detectors in the representation of tokens. Additionally, we design Ray Positional Encoding (Ray PE) to address the distribution differences between the LiDAR modality and the image. Finally, we integrate the aforementioned module into an end-to-end sparse multi-modality detector, dubbed CrossRay3D. Experiments show that, on the challenging nuScenes benchmark, CrossRay3D achieves state-of-the-art performance with 72.4 mAP and 74.7 NDS, while running 1.84 faster than other leading methods. Moreover, CrossRay3D demonstrates strong robustness even in scenarios where LiDAR or camera data are partially or entirely missing.

