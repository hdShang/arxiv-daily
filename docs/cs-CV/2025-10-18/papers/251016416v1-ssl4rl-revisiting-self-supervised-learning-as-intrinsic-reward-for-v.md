---
layout: default
title: SSL4RL: Revisiting Self-supervised Learning as Intrinsic Reward for Visual-Language Reasoning
---

# SSL4RL: Revisiting Self-supervised Learning as Intrinsic Reward for Visual-Language Reasoning

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.16416" target="_blank" class="toolbar-btn">arXiv: 2510.16416v1</a>
    <a href="https://arxiv.org/pdf/2510.16416.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.16416v1" 
            onclick="toggleFavorite(this, '2510.16416v1', 'SSL4RL: Revisiting Self-supervised Learning as Intrinsic Reward for Visual-Language Reasoning')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Xiaojun Guo, Runyu Zhou, Yifei Wang, Qi Zhang, Chenheng Zhang, Stefanie Jegelka, Xiaohan Wang, Jiajun Chai, Guojun Yin, Wei Lin, Yisen Wang

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-18

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**SSL4RLÔºöÂà©Áî®Ëá™ÁõëÁù£Â≠¶‰π†‰Ωú‰∏∫ËßÜËßâ-ËØ≠Ë®ÄÊé®ÁêÜÁöÑÂÜÖÂú®Â•ñÂä±**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâ-ËØ≠Ë®ÄÊé®ÁêÜ` `Ëá™ÁõëÁù£Â≠¶‰π†` `Âº∫ÂåñÂ≠¶‰π†` `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `ÂÜÖÂú®Â•ñÂä±`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÂú®Âà©Áî®ËßÜËßâ‰ø°ÊÅØÊñπÈù¢Â≠òÂú®‰∏çË∂≥ÔºåÂÆπÊòì‰æùËµñËØ≠Ë®ÄÂÖàÈ™åÊàñÊñáÊú¨Êç∑ÂæÑÔºåÈôêÂà∂‰∫ÜÂÖ∂Êé®ÁêÜËÉΩÂäõ„ÄÇ
2. SSL4RLÊ°ÜÊû∂Â∞ÜËá™ÁõëÁù£Â≠¶‰π†‰ªªÂä°ÁöÑÁõÆÊ†áËΩ¨Âåñ‰∏∫Âº∫ÂåñÂ≠¶‰π†ÁöÑÂ•ñÂä±‰ø°Âè∑ÔºåÊó†ÈúÄ‰∫∫Â∑•Ê†áÊ≥®ÊàñÂ§çÊùÇÁöÑÂ•ñÂä±ÂáΩÊï∞ËÆæËÆ°„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåSSL4RLÂú®ËßÜËßâ‰∏≠ÂøÉÂíåËßÜËßâ-ËØ≠Ë®ÄÊé®ÁêÜ‰ªªÂä°‰∏äÂùáÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåÂπ∂ÊàêÂäüÂ∫îÁî®‰∫éÂõæÂ≠¶‰π†„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÔºàVLMÔºâÈÄöËøáÊï¥ÂêàÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂíåËßÜËßâËæìÂÖ•Â±ïÁé∞‰∫ÜÂçìË∂äÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÂÆÉ‰ª¨Â∏∏Â∏∏Êó†Ê≥ïÂÖÖÂàÜÂà©Áî®ËßÜËßâËØÅÊçÆÔºåË¶Å‰πà‰æùËµñ‰∫éËßÜËßâ‰∏≠ÂøÉ‰ªªÂä°‰∏≠ÁöÑËØ≠Ë®ÄÂÖàÈ™åÔºåË¶Å‰πàÂú®Êé®ÁêÜËøáÁ®ã‰∏≠‰æùËµñ‰∫éÊñáÊú¨Êç∑ÂæÑ„ÄÇËôΩÁÑ∂Âº∫ÂåñÂ≠¶‰π†ÔºàRLÔºâÂèØ‰ª•‰ΩøÊ®°Âûã‰∏éÊúüÊúõÁöÑË°å‰∏∫ÂØπÈΩêÔºå‰ΩÜÁî±‰∫éÁº∫‰πèÂèØÊâ©Â±ïÂíåÂèØÈù†ÁöÑÂ•ñÂä±Êú∫Âà∂ÔºåÂÖ∂Âú®VLM‰∏≠ÁöÑÂ∫îÁî®ÂèóÂà∞ÈòªÁ¢ç„ÄÇ‰∏∫‰∫ÜÂÖãÊúçËøô‰∏ÄÊåëÊàòÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜSSL4RLÔºåËøôÊòØ‰∏Ä‰∏™Êñ∞È¢ñÁöÑÊ°ÜÊû∂ÔºåÂÆÉÂà©Áî®Ëá™ÁõëÁù£Â≠¶‰π†ÔºàSSLÔºâ‰ªªÂä°‰Ωú‰∏∫Âü∫‰∫éRLÂæÆË∞ÉÁöÑÂèØÈ™åËØÅÂ•ñÂä±Êù•Ê∫ê„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÂ∞ÜSSLÁõÆÊ†áÔºà‰æãÂ¶ÇÈ¢ÑÊµãÂõæÂÉèÊóãËΩ¨ÊàñÈáçÂª∫Êé©Á†ÅË°•‰∏ÅÔºâÈáçÊñ∞ÂÆö‰πâ‰∏∫ÂØÜÈõÜ„ÄÅËá™Âä®ÁöÑÂ•ñÂä±‰ø°Âè∑Ôºå‰ªéËÄåÊ∂àÈô§‰∫ÜÂØπ‰∫∫Á±ªÂÅèÂ•ΩÊï∞ÊçÆÊàñ‰∏çÂèØÈù†ÁöÑAIËØÑ‰º∞Âô®ÁöÑÈúÄÊ±Ç„ÄÇÂÆûÈ™åË°®ÊòéÔºåSSL4RLÊòæËëóÊèêÈ´ò‰∫ÜËßÜËßâ‰∏≠ÂøÉÂíåËßÜËßâ-ËØ≠Ë®ÄÊé®ÁêÜÂü∫ÂáÜÁöÑÊÄßËÉΩ„ÄÇÊ≠§Â§ñÔºåÈÄöËøáÁ≥ªÁªüÁöÑÊ∂àËûçÁ†îÁ©∂ÔºåÊàë‰ª¨Á°ÆÂÆö‰∫ÜÂΩ±ÂìçSSL4RL‰ªªÂä°ÊúâÊïàÊÄßÁöÑÂÖ≥ÈîÆÂõ†Á¥†Ôºà‰æãÂ¶Ç‰ªªÂä°ÈöæÂ∫¶„ÄÅÊ®°ÂûãËßÑÊ®°‰ª•Âèä‰∏éÁõÆÊ†áÈ¢ÜÂüüÁöÑËØ≠‰πâÂØπÈΩêÔºâÔºå‰∏∫Êú™Êù•ÁöÑÂ∑•‰ΩúÊèê‰æõ‰∫ÜÊñ∞ÁöÑËÆæËÆ°ÂéüÂàô„ÄÇÊàë‰ª¨ËøòÈÄöËøáÂ∞ÜÂÖ∂Â∫îÁî®‰∫éÂõæÂ≠¶‰π†Êù•ËØÅÊòé‰∫ÜËØ•Ê°ÜÊû∂ÁöÑÈÄöÁî®ÊÄßÔºå‰ªéËÄåËé∑Âæó‰∫ÜÊòæËëóÁöÑÊî∂Áõä„ÄÇSSL4RL‰∏∫‰ΩøÁî®ÂèØÈ™åËØÅÁöÑËá™ÁõëÁù£ÁõÆÊ†áÂØπÈΩêÂ§öÊ®°ÊÄÅÊ®°ÂûãÂª∫Á´ã‰∫Ü‰∏Ä‰∏™ÈÄöÁî®‰∏îÊúâÊïàÁöÑËåÉ‰æã„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÂú®ËßÜËßâÊé®ÁêÜ‰ªªÂä°‰∏≠Ë°®Áé∞‰∏ç‰Ω≥Ôºå‰∏ªË¶ÅÂéüÂõ†ÊòØÊ®°ÂûãËøáÂ∫¶‰æùËµñËØ≠Ë®Ä‰ø°ÊÅØÔºåËÄåÂøΩÁï•‰∫ÜËßÜËßâËØÅÊçÆ„ÄÇÁé∞ÊúâÁöÑÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïËôΩÁÑ∂ÂèØ‰ª•Áî®‰∫éÂæÆË∞ÉÊ®°ÂûãË°å‰∏∫Ôºå‰ΩÜÁº∫‰πèÂèØÊâ©Â±ïÂíåÂèØÈù†ÁöÑÂ•ñÂä±Êú∫Âà∂Ôºå‰æãÂ¶ÇÈúÄË¶Å‰∫∫Â∑•Ê†áÊ≥®Êàñ‰æùËµñ‰∏çÂèØÈù†ÁöÑAIËØÑ‰º∞Âô®„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜËá™ÁõëÁù£Â≠¶‰π†ÔºàSSLÔºâ‰ªªÂä°ÁöÑÁõÆÊ†áÂáΩÊï∞ËΩ¨Âåñ‰∏∫Âº∫ÂåñÂ≠¶‰π†ÁöÑÂ•ñÂä±‰ø°Âè∑„ÄÇÈÄöËøáËøôÁßçÊñπÂºèÔºåÂèØ‰ª•Âà©Áî®SSL‰ªªÂä°ÁöÑÂÜÖÂú®ÁõëÁù£‰ø°ÊÅØÊù•ÂºïÂØºÊ®°ÂûãÁöÑÂ≠¶‰π†ÔºåËÄåÊó†ÈúÄ‰∫∫Â∑•Âπ≤È¢Ñ„ÄÇËøôÁßçÊñπÊ≥ïÂèØ‰ª•Êèê‰æõÂØÜÈõÜ„ÄÅËá™Âä®‰∏îÂèØÈ™åËØÅÁöÑÂ•ñÂä±‰ø°Âè∑Ôºå‰ªéËÄåÂÖãÊúç‰∫Ü‰º†ÁªüÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÁöÑÂ±ÄÈôêÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöSSL4RLÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Èò∂ÊÆµÔºö1) È¢ÑËÆ≠ÁªÉÁöÑËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÔºõ2) ÂÆö‰πâËá™ÁõëÁù£Â≠¶‰π†‰ªªÂä°Ôºå‰æãÂ¶ÇÂõæÂÉèÊóãËΩ¨È¢ÑÊµãÊàñÊé©Á†ÅÂõæÂÉèÈáçÂª∫Ôºõ3) Â∞ÜSSL‰ªªÂä°ÁöÑÁõÆÊ†áÂáΩÊï∞ËΩ¨Âåñ‰∏∫Âº∫ÂåñÂ≠¶‰π†ÁöÑÂ•ñÂä±ÂáΩÊï∞Ôºõ4) ‰ΩøÁî®Âº∫ÂåñÂ≠¶‰π†ÁÆóÊ≥ïÔºà‰æãÂ¶ÇPPOÔºâÂØπËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãËøõË°åÂæÆË∞ÉÔºå‰ª•ÊúÄÂ§ßÂåñSSLÂ•ñÂä±„ÄÇÊï¥‰ΩìÊµÅÁ®ãÊòØÂà©Áî®SSL‰ªªÂä°Êèê‰æõÁöÑÂÜÖÂú®Â•ñÂä±Êù•ÂºïÂØºÊ®°ÂûãÂ≠¶‰π†Ôºå‰ªéËÄåÊèêÈ´òÂÖ∂ËßÜËßâÊé®ÁêÜËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜËá™ÁõëÁù£Â≠¶‰π†‰∏éÂº∫ÂåñÂ≠¶‰π†Áõ∏ÁªìÂêàÔºåÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÂæÆË∞ÉÊ°ÜÊû∂„ÄÇ‰∏é‰º†ÁªüÁöÑÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÁõ∏ÊØîÔºåSSL4RLÊó†ÈúÄ‰∫∫Â∑•Ê†áÊ≥®ÊàñÂ§çÊùÇÁöÑÂ•ñÂä±ÂáΩÊï∞ËÆæËÆ°ÔºåËÄåÊòØÂà©Áî®SSL‰ªªÂä°ÁöÑÂÜÖÂú®ÁõëÁù£‰ø°ÊÅØÊù•Êèê‰æõÂ•ñÂä±‰ø°Âè∑„ÄÇËøô‰ΩøÂæóÂº∫ÂåñÂ≠¶‰π†ÂèØ‰ª•Êõ¥ÂÆπÊòìÂú∞Â∫îÁî®‰∫éËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÔºåÂπ∂ÊèêÈ´òÂÖ∂ËßÜËßâÊé®ÁêÜËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËÆ∫Êñá‰∏≠ÂÖ≥ÈîÆÁöÑËÆæËÆ°ÂåÖÊã¨Ôºö1) ÈÄâÊã©ÂêàÈÄÇÁöÑËá™ÁõëÁù£Â≠¶‰π†‰ªªÂä°Ôºå‰æãÂ¶ÇÂõæÂÉèÊóãËΩ¨È¢ÑÊµã„ÄÅÊé©Á†ÅÂõæÂÉèÈáçÂª∫Á≠âÔºåËøô‰∫õ‰ªªÂä°ÈúÄË¶ÅÊ®°ÂûãÁêÜËß£ÂõæÂÉèÁöÑÁªìÊûÑÂíåËØ≠‰πâ‰ø°ÊÅØÔºõ2) ËÆæËÆ°ÂêàÈÄÇÁöÑÂ•ñÂä±ÂáΩÊï∞ÔºåÂ∞ÜSSL‰ªªÂä°ÁöÑÁõÆÊ†áÂáΩÊï∞ËΩ¨Âåñ‰∏∫Âº∫ÂåñÂ≠¶‰π†ÁöÑÂ•ñÂä±‰ø°Âè∑Ôºõ3) ‰ΩøÁî®ÂêàÈÄÇÁöÑÂº∫ÂåñÂ≠¶‰π†ÁÆóÊ≥ïÔºå‰æãÂ¶ÇPPOÔºåÂØπËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãËøõË°åÂæÆË∞É„ÄÇÊ≠§Â§ñÔºåËÆ∫ÊñáËøòÁ†îÁ©∂‰∫Ü‰ªªÂä°ÈöæÂ∫¶„ÄÅÊ®°ÂûãËßÑÊ®°‰ª•Âèä‰∏éÁõÆÊ†áÈ¢ÜÂüüÁöÑËØ≠‰πâÂØπÈΩêÁ≠âÂõ†Á¥†ÂØπSSL4RL‰ªªÂä°ÊúâÊïàÊÄßÁöÑÂΩ±Âìç„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåSSL4RLÂú®ËßÜËßâ‰∏≠ÂøÉÂíåËßÜËßâ-ËØ≠Ë®ÄÊé®ÁêÜÂü∫ÂáÜ‰∏äÂùáÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇ‰æãÂ¶ÇÔºåÂú®Êüê‰∫õ‰ªªÂä°‰∏äÔºåSSL4RLÁöÑÊÄßËÉΩË∂ÖËøá‰∫ÜÁé∞ÊúâÁöÑÊúÄÂÖàËøõÊñπÊ≥ï„ÄÇÊ≠§Â§ñÔºåÊ∂àËûçÂÆûÈ™åË°®ÊòéÔºå‰ªªÂä°ÈöæÂ∫¶„ÄÅÊ®°ÂûãËßÑÊ®°‰ª•Âèä‰∏éÁõÆÊ†áÈ¢ÜÂüüÁöÑËØ≠‰πâÂØπÈΩêÁ≠âÂõ†Á¥†ÂØπSSL4RL‰ªªÂä°ÁöÑÊúâÊïàÊÄßÊúâÈáçË¶ÅÂΩ±Âìç„ÄÇËØ•Ê°ÜÊû∂ËøòÊàêÂäüÂ∫îÁî®‰∫éÂõæÂ≠¶‰π†ÔºåÂπ∂Ëé∑Âæó‰∫ÜÊòæËëóÁöÑÊî∂Áõä„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

SSL4RLÊ°ÜÊû∂ÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂèØ‰ª•Â∫îÁî®‰∫éÂêÑÁßçÈúÄË¶ÅËßÜËßâ-ËØ≠Ë®ÄÊé®ÁêÜÁöÑ‰ªªÂä°Ôºå‰æãÂ¶ÇËßÜËßâÈóÆÁ≠î„ÄÅÂõæÂÉèÊèèËø∞„ÄÅËßÜËßâÂØºËà™Á≠â„ÄÇËØ•ÊñπÊ≥ïÂèØ‰ª•ÊèêÈ´òÊ®°ÂûãÂú®Ëøô‰∫õ‰ªªÂä°‰∏≠ÁöÑÊÄßËÉΩÔºåÂπ∂Èôç‰ΩéÂØπ‰∫∫Â∑•Ê†áÊ≥®Êï∞ÊçÆÁöÑ‰æùËµñ„ÄÇÊ≠§Â§ñÔºåËØ•Ê°ÜÊû∂ËøòÂèØ‰ª•Êé®ÂπøÂà∞ÂÖ∂‰ªñÂ§öÊ®°ÊÄÅÂ≠¶‰π†‰ªªÂä°‰∏≠Ôºå‰æãÂ¶ÇËØ≠Èü≥-ËØ≠Ë®ÄÂ≠¶‰π†„ÄÅËßÜÈ¢ë-ËØ≠Ë®ÄÂ≠¶‰π†Á≠â„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Vision-language models (VLMs) have shown remarkable abilities by integrating large language models with visual inputs. However, they often fail to utilize visual evidence adequately, either depending on linguistic priors in vision-centric tasks or resorting to textual shortcuts during reasoning. Although reinforcement learning (RL) can align models with desired behaviors, its application to VLMs has been hindered by the lack of scalable and reliable reward mechanisms. To overcome this challenge, we propose SSL4RL, a novel framework that leverages self-supervised learning (SSL) tasks as a source of verifiable rewards for RL-based fine-tuning. Our approach reformulates SSL objectives-such as predicting image rotation or reconstructing masked patches-into dense, automatic reward signals, eliminating the need for human preference data or unreliable AI evaluators. Experiments show that SSL4RL substantially improves performance on both vision-centric and vision-language reasoning benchmarks. Furthermore, through systematic ablations, we identify key factors-such as task difficulty, model scale, and semantic alignment with the target domain-that influence the effectiveness of SSL4RL tasks, offering new design principles for future work. We also demonstrate the framework's generality by applying it to graph learning, where it yields significant gains. SSL4RL establishes a versatile and effective paradigm for aligning multimodal models using verifiable, self-supervised objectives.

