---
layout: default
title: PRISMM-Bench: A Benchmark of Peer-Review Grounded Multimodal Inconsistencies
---

# PRISMM-Bench: A Benchmark of Peer-Review Grounded Multimodal Inconsistencies

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.16505" target="_blank" class="toolbar-btn">arXiv: 2510.16505v2</a>
    <a href="https://arxiv.org/pdf/2510.16505.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.16505v2" 
            onclick="toggleFavorite(this, '2510.16505v2', 'PRISMM-Bench: A Benchmark of Peer-Review Grounded Multimodal Inconsistencies')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Lukas Selch, Yufang Hou, M. Jehanzeb Mirza, Sivan Doveh, James Glass, Rogerio Feris, Wei Lin

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-18 (Êõ¥Êñ∞: 2025-10-21)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**PRISMM-BenchÔºöÈ¶ñ‰∏™Âü∫‰∫éÂêåË°åËØÑÂÆ°ÁöÑÂ§öÊ®°ÊÄÅ‰∏ç‰∏ÄËá¥ÊÄßÂü∫ÂáÜÔºåÁî®‰∫éËØÑ‰º∞LMMsÁöÑÁßëÂ≠¶Êé®ÁêÜËÉΩÂäõ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `ÁßëÂ≠¶Êé®ÁêÜ` `‰∏ç‰∏ÄËá¥ÊÄßÊ£ÄÊµã` `ÂêåË°åËØÑÂÆ°` `Âü∫ÂáÜÊµãËØï`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâLMMsÂú®ÁßëÂ≠¶ËÆ∫ÊñáÁêÜËß£‰∏≠Èù¢‰∏¥Â§öÊ®°ÊÄÅ‰ø°ÊÅØ‰∏ç‰∏ÄËá¥ÊÄßÊ£ÄÊµãÁöÑÊåëÊàòÔºåÁé∞ÊúâÂü∫ÂáÜÊµãËØïÊú™ËÉΩÂÖÖÂàÜÊçïÊçâÁúüÂÆû‰∏ñÁïåÂ§çÊùÇÊÄß„ÄÇ
2. PRISMM-BenchÈÄöËøáÊåñÊéòÂêåË°åËØÑÂÆ°ÊÑèËßÅÔºåÊûÑÂª∫ÂåÖÂê´ÁúüÂÆû‰∏ç‰∏ÄËá¥ÊÄßÁöÑÊï∞ÊçÆÈõÜÔºåÂπ∂ËÆæËÆ°‰ªªÂä°ËØÑ‰º∞LMMsÁöÑÊ£ÄÊµã„ÄÅÁ∫†Ê≠£ÂíåÊé®ÁêÜËÉΩÂäõ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÁé∞ÊúâLMMsÂú®PRISMM-Bench‰∏äÁöÑË°®Áé∞‰∏ç‰Ω≥Ôºà26.1-54.2%ÔºâÔºåÊè≠Á§∫‰∫ÜÂ§öÊ®°ÊÄÅÁßëÂ≠¶Êé®ÁêÜÁöÑÂ∑®Â§ßÊåëÊàò„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§ßÂûãÂ§öÊ®°ÊÄÅÊ®°ÂûãÔºàLMMsÔºâË∂äÊù•Ë∂äÂ§öÂú∞Â∫îÁî®‰∫éÁßëÂ≠¶Á†îÁ©∂Ôºå‰ΩÜÂÆÉ‰ª¨ÊòØÂê¶ËÉΩÂèØÈù†Âú∞ÁêÜËß£ÂíåÊé®ÁêÜËÆ∫Êñá‰∏≠Â§çÊùÇÁöÑÂ§öÊ®°ÊÄÅ‰ø°ÊÅØ‰ªç‰∏çÊ∏ÖÊ•ö„ÄÇ‰∏Ä‰∏™Ê†∏ÂøÉÊåëÊàòÂú®‰∫éÊ£ÄÊµãÂíåËß£ÂÜ≥ÊñáÊú¨„ÄÅÂõæË°®„ÄÅÂÖ¨ÂºèÁ≠â‰πãÈó¥ÁöÑ‰∏ç‰∏ÄËá¥ÊÄßÔºåËøô‰∫õÈóÆÈ¢òÈÄöÂ∏∏ÂæàÂæÆÂ¶ôÔºåÂÖ∑ÊúâÈ¢ÜÂüüÁâπÂºÇÊÄßÔºåÂπ∂ÊúÄÁªàÊçüÂÆ≥Ê∏ÖÊô∞Â∫¶„ÄÅÂèØÈáçÂ§çÊÄßÂíå‰ø°‰ªªÂ∫¶„ÄÇÁé∞ÊúâÂü∫ÂáÜÂøΩÁï•‰∫ÜËøô‰∏™ÈóÆÈ¢òÔºåË¶Å‰πàÂ≠§Á´ãÂú∞Â§ÑÁêÜÂçï‰∏ÄÊ®°ÊÄÅÔºåË¶Å‰πà‰æùËµñ‰∫éÊú™ËÉΩÊçïÊçâÁúüÂÆû‰∏ñÁïåÂ§çÊùÇÊÄßÁöÑÂêàÊàêÈîôËØØ„ÄÇÊàë‰ª¨Êé®Âá∫‰∫ÜPRISMM-BenchÔºàÂ§öÊ®°ÊÄÅÊ®°ÂûãÂêåË°åËØÑÂÆ°Êù•Ê∫ê‰∏ç‰∏ÄËá¥ÊÄßÈõÜÔºâÔºåËøôÊòØÁ¨¨‰∏Ä‰∏™Âü∫‰∫éÁßëÂ≠¶ËÆ∫Êñá‰∏≠ÁúüÂÆûËØÑÂÆ°ÂëòÊ†áËÆ∞ÁöÑ‰∏ç‰∏ÄËá¥ÊÄßÁöÑÂü∫ÂáÜ„ÄÇÈÄöËøáËØÑÂÆ°ÊåñÊéò„ÄÅLLMËæÖÂä©ËøáÊª§Âíå‰∫∫Â∑•È™åËØÅÁöÑÂ§öÈò∂ÊÆµÊµÅÁ®ãÔºåÊàë‰ª¨‰ªé242ÁØáËÆ∫Êñá‰∏≠Êï¥ÁêÜÂá∫262‰∏™‰∏ç‰∏ÄËá¥ÊÄß„ÄÇÂü∫‰∫éÊ≠§ÔºåÊàë‰ª¨ËÆæËÆ°‰∫Ü‰∏â‰∏™‰ªªÂä°ÔºåÂç≥‰∏ç‰∏ÄËá¥ÊÄßËØÜÂà´„ÄÅË°•ÊïëÂíåÈÖçÂØπÂåπÈÖçÔºå‰ª•ËØÑ‰º∞Ê®°ÂûãÊ£ÄÊµã„ÄÅÁ∫†Ê≠£ÂíåÊé®ÁêÜ‰∏çÂêåÊ®°ÊÄÅ‰πãÈó¥‰∏ç‰∏ÄËá¥ÊÄßÁöÑËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºå‰∏∫‰∫ÜËß£ÂÜ≥Â§öÈ°πÈÄâÊã©ËØÑ‰º∞‰∏≠Ëá≠ÂêçÊò≠ËëóÁöÑ‚Äú‰ªÖÂá≠ÈÄâÊã©‚ÄùÁöÑÊç∑ÂæÑÈóÆÈ¢òÔºåÊàë‰ª¨Ëøõ‰∏ÄÊ≠•ÂºïÂÖ•‰∫ÜÂü∫‰∫éJSONÁöÑÁªìÊûÑÂåñÁ≠îÊ°àË°®Á§∫ÔºåÈÄöËøáÂáèÂ∞ëÂØπË°®Èù¢Êñá‰ΩìÁ∫øÁ¥¢ÁöÑ‰æùËµñÊù•ÊúÄÂ∞èÂåñËØ≠Ë®ÄÂÅèÂ∑Æ„ÄÇÊàë‰ª¨ÂØπ21‰∏™È¢ÜÂÖàÁöÑLMMËøõË°å‰∫ÜÂü∫ÂáÜÊµãËØïÔºåÂåÖÊã¨Â§ßÂûãÂºÄÊ∫êÊ®°ÂûãÔºàGLM-4.5V 106B„ÄÅInternVL3 78BÔºâÂíå‰∏ìÊúâÊ®°ÂûãÔºàGemini 2.5 Pro„ÄÅÂÖ∑ÊúâÈ´òÊé®ÁêÜËÉΩÂäõÁöÑGPT-5Ôºâ„ÄÇÁªìÊûúÊòæÁ§∫ÊÄßËÉΩÈùûÂ∏∏‰ΩéÔºà26.1-54.2%ÔºâÔºåÁ™ÅÊòæ‰∫ÜÂ§öÊ®°ÊÄÅÁßëÂ≠¶Êé®ÁêÜÁöÑÊåëÊàòÔºåÂπ∂Êé®Âä®‰∫ÜÂØπÂÄºÂæó‰ø°ËµñÁöÑÁßëÂ≠¶Âä©ÊâãÁöÑÁ†îÁ©∂„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Â§ßÂûãÂ§öÊ®°ÊÄÅÊ®°ÂûãÔºàLMMsÔºâÂú®ÁêÜËß£ÂíåÊé®ÁêÜÁßëÂ≠¶ËÆ∫ÊñáÊó∂ÔºåÈöæ‰ª•Ê£ÄÊµãÂíåËß£ÂÜ≥ÊñáÊú¨„ÄÅÂõæË°®„ÄÅÂÖ¨ÂºèÁ≠âÊ®°ÊÄÅÈó¥‰∏ç‰∏ÄËá¥ÊÄßÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÂü∫ÂáÜÊµãËØïË¶Å‰πàÂè™ÂÖ≥Ê≥®Âçï‰∏ÄÊ®°ÊÄÅÔºåË¶Å‰πà‰ΩøÁî®ÂêàÊàêÊï∞ÊçÆÔºåÊó†Ê≥ïÁúüÂÆûÂèçÊò†ÁßëÂ≠¶ËÆ∫Êñá‰∏≠Â§çÊùÇ‰∏îÁªÜÂæÆÁöÑ‰∏ç‰∏ÄËá¥ÊÄßÔºåÂØºËá¥Ê®°ÂûãÈöæ‰ª•Â∫îÁî®‰∫éÂÆûÈôÖÁßëÁ†îÂú∫ÊôØ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÊûÑÂª∫‰∏Ä‰∏™Âü∫‰∫éÁúüÂÆûÂêåË°åËØÑÂÆ°ÊÑèËßÅÁöÑÊï∞ÊçÆÈõÜPRISMM-BenchÔºåÂÖ∂‰∏≠ÂåÖÂê´ËØÑÂÆ°ÂëòÂú®ÂÆûÈôÖËÆ∫Êñá‰∏≠ÂèëÁé∞ÁöÑ‰∏ç‰∏ÄËá¥ÊÄß„ÄÇÈÄöËøáËøô‰∏™Êï∞ÊçÆÈõÜÔºåÂèØ‰ª•Êõ¥ÁúüÂÆûÂú∞ËØÑ‰º∞LMMsÂú®Â§öÊ®°ÊÄÅÁßëÂ≠¶Êé®ÁêÜÊñπÈù¢ÁöÑËÉΩÂäõÔºåÂπ∂Êé®Âä®Ê®°ÂûãÊúùÁùÄÊõ¥ÂèØÈù†ÁöÑÁßëÂ≠¶Âä©ÊâãÊñπÂêëÂèëÂ±ï„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöPRISMM-BenchÁöÑÊûÑÂª∫ÊµÅÁ®ãÂåÖÊã¨Ôºö1) ‰ªéÂÖ¨ÂºÄÁöÑÂêåË°åËØÑÂÆ°Êï∞ÊçÆ‰∏≠ÊåñÊéòÊΩúÂú®ÁöÑ‰∏ç‰∏ÄËá¥ÊÄßÔºõ2) ‰ΩøÁî®LLMËæÖÂä©ËøáÊª§ÔºåÂàùÊ≠•Á≠õÈÄâÂá∫ÂèØËÉΩÁöÑ‰∏ç‰∏ÄËá¥ÊÄßÔºõ3) ÈÄöËøá‰∫∫Â∑•È™åËØÅÔºåÁ°ÆËÆ§ÊúÄÁªàÁöÑ‰∏ç‰∏ÄËá¥ÊÄßÊ†∑Êú¨„ÄÇÂü∫‰∫éPRISMM-BenchÔºåËÆ∫ÊñáËÆæËÆ°‰∫Ü‰∏â‰∏™‰ªªÂä°Ôºö‰∏ç‰∏ÄËá¥ÊÄßËØÜÂà´ÔºàInconsistency IdentificationÔºâ„ÄÅË°•ÊïëÔºàRemedyÔºâÂíåÈÖçÂØπÂåπÈÖçÔºàPair MatchingÔºâÔºåÁî®‰∫éÂÖ®Èù¢ËØÑ‰º∞LMMsÁöÑËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ËÆ∫ÊñáÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éÊûÑÂª∫‰∫Ü‰∏Ä‰∏™Âü∫‰∫éÁúüÂÆûÂêåË°åËØÑÂÆ°ÊÑèËßÅÁöÑÂ§öÊ®°ÊÄÅ‰∏ç‰∏ÄËá¥ÊÄßÂü∫ÂáÜPRISMM-Bench„ÄÇ‰∏é‰ª•ÂæÄÁöÑÂêàÊàêÊï∞ÊçÆÊàñÂçï‰∏ÄÊ®°ÊÄÅÂü∫ÂáÜÁõ∏ÊØîÔºåPRISMM-BenchÊõ¥Ë¥¥ËøëÂÆûÈôÖÁßëÁ†îÂú∫ÊôØÔºåËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞ËØÑ‰º∞LMMsÂú®Â§öÊ®°ÊÄÅÁßëÂ≠¶Êé®ÁêÜÊñπÈù¢ÁöÑËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåËÆ∫ÊñáËøòÂºïÂÖ•‰∫ÜÂü∫‰∫éJSONÁöÑÁªìÊûÑÂåñÁ≠îÊ°àË°®Á§∫Ôºå‰ª•ÂáèÂ∞ëÂ§öÈ°πÈÄâÊã©È¢ò‰∏≠ÁöÑËØ≠Ë®ÄÂÅèÂ∑Æ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Êï∞ÊçÆÊûÑÂª∫ÊñπÈù¢ÔºåËÆ∫ÊñáÈááÁî®‰∫ÜÂ§öÈò∂ÊÆµÁöÑËøáÊª§ÂíåÈ™åËØÅÊµÅÁ®ãÔºå‰ª•Á°Æ‰øùÊï∞ÊçÆÈõÜÁöÑË¥®Èáè„ÄÇÂú®‰ªªÂä°ËÆæËÆ°ÊñπÈù¢ÔºåËÆ∫ÊñáËÆæËÆ°‰∫Ü‰∏â‰∏™‰∏çÂêåÈöæÂ∫¶ÁöÑ‰ªªÂä°Ôºå‰ª•ÂÖ®Èù¢ËØÑ‰º∞LMMsÁöÑËÉΩÂäõ„ÄÇ‰∏∫‰∫ÜÂáèÂ∞ëÂ§öÈ°πÈÄâÊã©È¢ò‰∏≠ÁöÑËØ≠Ë®ÄÂÅèÂ∑ÆÔºåËÆ∫Êñá‰ΩøÁî®‰∫ÜÁªìÊûÑÂåñÁöÑJSONÁ≠îÊ°àË°®Á§∫ÔºåÈÅøÂÖçÊ®°Âûã‰ªÖ‰ªÖ‰æùËµñ‰∫éË°®Èù¢Êñá‰ΩìÁ∫øÁ¥¢ËøõË°åÈÄâÊã©„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÂåÖÊã¨GLM-4.5V 106B„ÄÅInternVL3 78B„ÄÅGemini 2.5 ProÂíåGPT-5Âú®ÂÜÖÁöÑ21‰∏™È¢ÜÂÖàLMMsÂú®PRISMM-Bench‰∏äÁöÑË°®Áé∞Âùá‰∏ç‰Ω≥ÔºåÊúÄÈ´òÊÄßËÉΩ‰ªÖ‰∏∫54.2%ÔºåÊúÄ‰Ωé‰∏∫26.1%„ÄÇËøôÁ™ÅÊòæ‰∫ÜÁé∞ÊúâLMMsÂú®Â§öÊ®°ÊÄÅÁßëÂ≠¶Êé®ÁêÜÊñπÈù¢Â≠òÂú®ÁöÑÂ∑®Â§ßÊåëÊàòÔºåÂπ∂‰∏∫Êú™Êù•ÁöÑÁ†îÁ©∂ÊåáÊòé‰∫ÜÊñπÂêë„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂºÄÂèëÊõ¥ÂèØÈù†ÁöÑÁßëÂ≠¶Âä©ÊâãÔºåËæÖÂä©ÁßëÁ†î‰∫∫ÂëòËøõË°åÊñáÁåÆÈòÖËØª„ÄÅËÆ∫ÊñáÊí∞ÂÜôÂíåÂÆûÈ™åËÆæËÆ°„ÄÇÈÄöËøáÊ£ÄÊµãÂíåËß£ÂÜ≥Â§öÊ®°ÊÄÅ‰ø°ÊÅØÁöÑ‰∏ç‰∏ÄËá¥ÊÄßÔºåÊèêÈ´òÁßëÁ†îÊàêÊûúÁöÑÊ∏ÖÊô∞Â∫¶„ÄÅÂèØÈáçÂ§çÊÄßÂíåÂèØ‰ø°Â∫¶ÔºåÂä†ÈÄüÁßëÂ≠¶ÂèëÁé∞ÁöÑËøõÁ®ã„ÄÇÊú™Êù•ÔºåËØ•Âü∫ÂáÜÂèØ‰ª•Êâ©Â±ïÂà∞ÂÖ∂‰ªñÁßëÂ≠¶È¢ÜÂüüÔºåÂπ∂Áî®‰∫éËØÑ‰º∞ÂíåÊîπËøõÊõ¥Â§öÁ±ªÂûãÁöÑÂ§öÊ®°ÊÄÅÊ®°Âûã„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Large Multimodal Models (LMMs) are increasingly applied to scientific research, yet it remains unclear whether they can reliably understand and reason over the multimodal complexity of papers. A central challenge lies in detecting and resolving inconsistencies across text, figures, tables, and equations, issues that are often subtle, domain-specific, and ultimately undermine clarity, reproducibility, and trust. Existing benchmarks overlook this issue, either isolating single modalities or relying on synthetic errors that fail to capture real-world complexity. We introduce PRISMM-Bench (Peer-Review-sourced Inconsistency Set for Multimodal Models), the first benchmark grounded in real reviewer-flagged inconsistencies in scientific papers. Through a multi-stage pipeline of review mining, LLM-assisted filtering and human verification, we curate 262 inconsistencies from 242 papers. Based on this set, we design three tasks, namely inconsistency identification, remedy and pair matching, which assess a model's capacity to detect, correct, and reason over inconsistencies across different modalities. Furthermore, to address the notorious problem of choice-only shortcuts in multiple-choice evaluation, where models exploit answer patterns without truly understanding the question, we further introduce structured JSON-based answer representations that minimize linguistic biases by reducing reliance on superficial stylistic cues. We benchmark 21 leading LMMs, including large open-weight models (GLM-4.5V 106B, InternVL3 78B) and proprietary models (Gemini 2.5 Pro, GPT-5 with high reasoning). Results reveal strikingly low performance (26.1-54.2%), underscoring the challenge of multimodal scientific reasoning and motivating progress towards trustworthy scientific assistants.

