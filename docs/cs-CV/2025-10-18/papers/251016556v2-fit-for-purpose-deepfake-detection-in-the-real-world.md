---
layout: default
title: Fit for Purpose? Deepfake Detection in the Real World
---

# Fit for Purpose? Deepfake Detection in the Real World

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.16556" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.16556v2</a>
  <a href="https://arxiv.org/pdf/2510.16556.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.16556v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.16556v2', 'Fit for Purpose? Deepfake Detection in the Real World')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Guangyu Lin, Li Lin, Christina P. Walker, Daniel S. Schiff, Shu Hu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-18 (æ›´æ–°: 2025-10-30)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ„å»ºçœŸå®æ”¿æ²»DeepfakeåŸºå‡†ï¼Œæ­ç¤ºç°æœ‰æ£€æµ‹å™¨æ³›åŒ–èƒ½åŠ›ä¸è¶³**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `Deepfakeæ£€æµ‹` `æ”¿æ²»Deepfake` `çœŸå®æ•°æ®åŸºå‡†` `æ³›åŒ–èƒ½åŠ›` `é²æ£’æ€§è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰deepfakeæ£€æµ‹æ¨¡å‹ä¸»è¦åœ¨åˆæˆæ•°æ®é›†ä¸Šè®­ç»ƒï¼Œç¼ºä¹å¯¹çœŸå®æ”¿æ²»deepfakeçš„æ³›åŒ–èƒ½åŠ›ã€‚
2. è®ºæ–‡æ„å»ºäº†åŸºäºçœŸå®æ”¿æ²»Deepfakeäº‹ä»¶æ•°æ®åº“çš„åŸºå‡†ï¼Œç”¨äºç³»ç»Ÿè¯„ä¼°ç°æœ‰æ£€æµ‹å™¨çš„æ€§èƒ½ã€‚
3. å®éªŒè¡¨æ˜ï¼Œç°æœ‰æ£€æµ‹å™¨åœ¨çœŸå®æ”¿æ²»deepfakeä¸Šè¡¨ç°ä¸ä½³ï¼Œæ˜“å—ç®€å•æ”»å‡»ï¼Œéœ€åŠ å¼ºæ”¿æ²»è¯­å¢ƒåŒ–ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äººå·¥æ™ºèƒ½ç”Ÿæˆå†…å®¹ï¼ˆç‰¹åˆ«æ˜¯åŸºäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œã€æ‰©æ•£æ¨¡å‹å’Œå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼‰çš„è¿…é€Ÿæ™®åŠï¼Œä½¿å¾—åˆæˆåª’ä½“çš„åˆ›å»ºå’Œä¼ æ’­å˜å¾—è½»è€Œæ˜“ä¸¾ï¼Œä»è€ŒåŠ å‰§äº†é”™è¯¯ä¿¡æ¯çš„é£é™©ï¼Œå°¤å…¶æ˜¯æ‰­æ›²çœŸç›¸å¹¶ç ´åå¯¹æ”¿æ²»æœºæ„ä¿¡ä»»çš„æ”¿æ²»deepfakeã€‚ä½œä¸ºå›åº”ï¼Œæ”¿åºœã€ç ”ç©¶æœºæ„å’Œè¡Œä¸šå¤§åŠ›æ¨å¹¿deepfakeæ£€æµ‹è®¡åˆ’ä½œä¸ºè§£å†³æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰æ¨¡å‹éƒ½æ˜¯åœ¨åˆæˆçš„ã€å®éªŒå®¤æ§åˆ¶çš„æ•°æ®é›†ä¸Šè®­ç»ƒå’ŒéªŒè¯çš„ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬å¯¹åœ¨ç¤¾äº¤å¹³å°ä¸Šæµä¼ çš„å½±å“å…¬ä¼—çš„çœŸå®æ”¿æ²»deepfakeçš„æ³›åŒ–èƒ½åŠ›ã€‚æœ¬æ–‡åŸºäºæ”¿æ²»Deepfakeäº‹ä»¶æ•°æ®åº“ï¼ˆä¸€ä¸ªè‡ª2018å¹´ä»¥æ¥åœ¨ç¤¾äº¤åª’ä½“ä¸Šåˆ†äº«çš„çœŸå®æ”¿æ²»deepfakeçš„ç²¾é€‰é›†åˆï¼‰ï¼Œå¼•å…¥äº†ç¬¬ä¸€ä¸ªç³»ç»Ÿæ€§åŸºå‡†ã€‚æˆ‘ä»¬çš„ç ”ç©¶åŒ…æ‹¬å¯¹æ¥è‡ªå­¦æœ¯ç•Œã€æ”¿åºœå’Œå·¥ä¸šç•Œçš„æœ€æ–°deepfakeæ£€æµ‹å™¨çš„ç³»ç»Ÿè¯„ä¼°ã€‚æˆ‘ä»¬å‘ç°ï¼Œæ¥è‡ªå­¦æœ¯ç•Œå’Œæ”¿åºœçš„æ£€æµ‹å™¨è¡¨ç°ç›¸å¯¹è¾ƒå·®ã€‚è™½ç„¶ä»˜è´¹æ£€æµ‹å·¥å…·çš„æ€§èƒ½ç›¸å¯¹é«˜äºå…è´¹è®¿é—®æ¨¡å‹ï¼Œä½†æ‰€æœ‰è¯„ä¼°çš„æ£€æµ‹å™¨éƒ½éš¾ä»¥æœ‰æ•ˆåœ°æ³›åŒ–åˆ°çœŸå®çš„æ”¿æ²»deepfakeï¼Œå¹¶ä¸”å®¹æ˜“å—åˆ°ç®€å•çš„æ“ä½œæ”»å‡»ï¼Œå°¤å…¶æ˜¯åœ¨è§†é¢‘é¢†åŸŸã€‚ç»“æœè¡¨æ˜ï¼Œéœ€è¦æ”¿æ²»è¯­å¢ƒåŒ–çš„deepfakeæ£€æµ‹æ¡†æ¶ï¼Œä»¥ä¾¿æ›´å¥½åœ°åœ¨ç°å®ç¯å¢ƒä¸­ä¿æŠ¤å…¬ä¼—ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰deepfakeæ£€æµ‹æ–¹æ³•ä¸»è¦åœ¨å®éªŒå®¤ç¯å¢ƒä¸‹ç”Ÿæˆçš„åˆæˆæ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ï¼Œç¼ºä¹å¯¹çœŸå®ä¸–ç•Œæ”¿æ²»deepfakeçš„æ³›åŒ–èƒ½åŠ›ã€‚è¿™äº›çœŸå®ä¸–ç•Œçš„deepfakeé€šå¸¸å…·æœ‰æ›´å¤æ‚çš„æ“ä½œå’Œä¼ªé€ æ–¹å¼ï¼Œä½¿å¾—ç°æœ‰æ£€æµ‹å™¨éš¾ä»¥æœ‰æ•ˆè¯†åˆ«ï¼Œä»è€Œå¯¼è‡´é”™è¯¯ä¿¡æ¯çš„ä¼ æ’­å’Œå¯¹æ”¿æ²»æœºæ„ä¿¡ä»»çš„ç ´åã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªåŸºäºçœŸå®æ”¿æ²»deepfakeçš„åŸºå‡†æ•°æ®é›†ï¼Œå¹¶åœ¨æ­¤æ•°æ®é›†ä¸Šç³»ç»Ÿåœ°è¯„ä¼°ç°æœ‰deepfakeæ£€æµ‹å™¨çš„æ€§èƒ½ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå¯ä»¥æ›´å‡†ç¡®åœ°äº†è§£ç°æœ‰æ–¹æ³•åœ¨å®é™…åº”ç”¨ä¸­çš„å±€é™æ€§ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›æ›´å¯é çš„è¯„ä¼°æ ‡å‡†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥ç ”ç©¶çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1) æ„å»ºæ”¿æ²»Deepfakeäº‹ä»¶æ•°æ®åº“ï¼Œæ”¶é›†è‡ª2018å¹´ä»¥æ¥åœ¨ç¤¾äº¤åª’ä½“ä¸Šåˆ†äº«çš„çœŸå®æ”¿æ²»deepfakeï¼›2) é€‰æ‹©æ¥è‡ªå­¦æœ¯ç•Œã€æ”¿åºœå’Œå·¥ä¸šç•Œçš„ä»£è¡¨æ€§deepfakeæ£€æµ‹å™¨ï¼›3) åœ¨æ„å»ºçš„åŸºå‡†æ•°æ®é›†ä¸Šå¯¹è¿™äº›æ£€æµ‹å™¨è¿›è¡Œç³»ç»Ÿè¯„ä¼°ï¼›4) åˆ†æè¯„ä¼°ç»“æœï¼Œæ­ç¤ºç°æœ‰æ£€æµ‹å™¨åœ¨çœŸå®æ”¿æ²»deepfakeä¸Šçš„æ€§èƒ½ç“¶é¢ˆã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæ„å»ºäº†ç¬¬ä¸€ä¸ªåŸºäºçœŸå®æ”¿æ²»deepfakeçš„ç³»ç»Ÿæ€§åŸºå‡†ã€‚ä¸ä»¥å¾€ä¸»è¦ä½¿ç”¨åˆæˆæ•°æ®çš„ç ”ç©¶ä¸åŒï¼Œè¯¥åŸºå‡†èƒ½å¤Ÿæ›´çœŸå®åœ°åæ˜ å®é™…åº”ç”¨åœºæ™¯ä¸­deepfakeçš„ç‰¹ç‚¹å’ŒæŒ‘æˆ˜ï¼Œä»è€Œä¸ºdeepfakeæ£€æµ‹çš„ç ”ç©¶æä¾›æ›´å…·ä»·å€¼çš„å‚è€ƒã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åœ¨äºæ•°æ®é›†çš„æ„å»ºå’Œè¯„ä¼°æŒ‡æ ‡çš„é€‰æ‹©ã€‚æ•°æ®é›†çš„æ„å»ºéœ€è¦ä»”ç»†ç­›é€‰å’Œæ ‡æ³¨çœŸå®æ”¿æ²»deepfakeï¼Œä»¥ç¡®ä¿å…¶ä»£è¡¨æ€§å’Œå¯é æ€§ã€‚è¯„ä¼°æŒ‡æ ‡çš„é€‰æ‹©éœ€è¦èƒ½å¤Ÿå…¨é¢åæ˜ æ£€æµ‹å™¨åœ¨ä¸åŒæ–¹é¢çš„æ€§èƒ½ï¼Œä¾‹å¦‚å‡†ç¡®ç‡ã€å¬å›ç‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜è€ƒè™‘äº†ä¸åŒç±»å‹çš„æ”»å‡»æ–¹å¼ï¼Œä¾‹å¦‚ç®€å•çš„å›¾åƒæˆ–è§†é¢‘æ“ä½œï¼Œä»¥è¯„ä¼°æ£€æµ‹å™¨çš„é²æ£’æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œç°æœ‰deepfakeæ£€æµ‹å™¨åœ¨çœŸå®æ”¿æ²»deepfakeä¸Šçš„æ€§èƒ½æ˜¾è‘—ä½äºåœ¨åˆæˆæ•°æ®ä¸Šçš„æ€§èƒ½ã€‚æ¥è‡ªå­¦æœ¯ç•Œå’Œæ”¿åºœçš„æ£€æµ‹å™¨è¡¨ç°ç›¸å¯¹è¾ƒå·®ï¼Œè€Œä»˜è´¹æ£€æµ‹å·¥å…·çš„æ€§èƒ½ç•¥æœ‰æå‡ï¼Œä½†æ‰€æœ‰è¯„ä¼°çš„æ£€æµ‹å™¨éƒ½éš¾ä»¥æœ‰æ•ˆåœ°æ³›åŒ–åˆ°çœŸå®çš„æ”¿æ²»deepfakeï¼Œå¹¶ä¸”å®¹æ˜“å—åˆ°ç®€å•çš„æ“ä½œæ”»å‡»ã€‚ä¾‹å¦‚ï¼Œåœ¨è§†é¢‘é¢†åŸŸï¼Œç®€å•çš„å›¾åƒå¤„ç†æŠ€æœ¯å°±èƒ½æ˜¾è‘—é™ä½æ£€æµ‹å™¨çš„å‡†ç¡®ç‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºç¤¾äº¤åª’ä½“å¹³å°ã€æ–°é—»åª’ä½“å’Œæ”¿åºœæœºæ„ï¼Œç”¨äºæ£€æµ‹å’Œè¯†åˆ«æ”¿æ²»deepfakeï¼Œä»è€Œå‡å°‘é”™è¯¯ä¿¡æ¯çš„ä¼ æ’­ï¼Œç»´æŠ¤å…¬ä¼—å¯¹æ”¿æ²»æœºæ„çš„ä¿¡ä»»ã€‚æœªæ¥çš„ç ”ç©¶å¯ä»¥åŸºäºè¯¥åŸºå‡†å¼€å‘æ›´å…·é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›çš„deepfakeæ£€æµ‹æ–¹æ³•ï¼Œå¹¶æ¢ç´¢æ”¿æ²»è¯­å¢ƒä¸‹çš„deepfakeæ£€æµ‹æ¡†æ¶ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The rapid proliferation of AI-generated content, driven by advances in generative adversarial networks, diffusion models, and multimodal large language models, has made the creation and dissemination of synthetic media effortless, heightening the risks of misinformation, particularly political deepfakes that distort truth and undermine trust in political institutions. In turn, governments, research institutions, and industry have strongly promoted deepfake detection initiatives as solutions. Yet, most existing models are trained and validated on synthetic, laboratory-controlled datasets, limiting their generalizability to the kinds of real-world political deepfakes circulating on social platforms that affect the public. In this work, we introduce the first systematic benchmark based on the Political Deepfakes Incident Database, a curated collection of real-world political deepfakes shared on social media since 2018. Our study includes a systematic evaluation of state-of-the-art deepfake detectors across academia, government, and industry. We find that the detectors from academia and government perform relatively poorly. While paid detection tools achieve relatively higher performance than free-access models, all evaluated detectors struggle to generalize effectively to authentic political deepfakes, and are vulnerable to simple manipulations, especially in the video domain. Results urge the need for politically contextualized deepfake detection frameworks to better safeguard the public in real-world settings.

