---
layout: default
title: RL makes MLLMs see better than SFT
---

# RL makes MLLMs see better than SFT

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.16333" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.16333v1</a>
  <a href="https://arxiv.org/pdf/2510.16333.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.16333v1" onclick="toggleFavorite(this, '2510.16333v1', 'RL makes MLLMs see better than SFT')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Junha Song, Sangdoo Yun, Dongyoon Han, Jaegul Choo, Byeongho Heo

**åˆ†ç±»**: cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-10-18

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://june-page.github.io/pivot/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPIVOTï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–MLLMè§†è§‰ç¼–ç å™¨ï¼Œæ˜¾è‘—æå‡è§†è§‰æ„ŸçŸ¥èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `è§†è§‰ç¼–ç å™¨` `å¼ºåŒ–å­¦ä¹ ` `è§†è§‰é—®ç­”` `è¡¨å¾å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰MLLMç ”ç©¶è¿‡åº¦ä¾èµ–LLMï¼Œå¿½è§†äº†è§†è§‰ç¼–ç å™¨å¯¹æ¨¡å‹æ€§èƒ½çš„å…³é”®å½±å“ï¼Œå°¤å…¶æ˜¯åœ¨è®­ç»ƒç­–ç•¥ä»SFTè½¬å‘RLåã€‚
2. è®ºæ–‡æå‡ºPreference-Instructed Vision OpTimization (PIVOT)æ–¹æ³•ï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ æŒ‡å¯¼è§†è§‰ç¼–ç å™¨çš„ä¼˜åŒ–ï¼Œæå‡è§†è§‰è¡¨å¾èƒ½åŠ›ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒPIVOTè®­ç»ƒçš„è§†è§‰ç¼–ç å™¨åœ¨MLLMä¸­è¡¨ç°ä¼˜å¼‚ï¼Œç”šè‡³è¶…è¶Šäº†æ›´å¤§è§„æ¨¡ä¸”è®­ç»ƒæ›´å……åˆ†çš„åŒç±»æ¨¡å‹ï¼ŒåŒæ—¶æ˜¾è‘—é™ä½äº†è®¡ç®—æˆæœ¬ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹(MLLM)ç ”ç©¶ä¸­çš„ä¸€ä¸ªä¸»è¦å‡è®¾æ˜¯ï¼Œå…¶æ€§èƒ½å¾ˆå¤§ç¨‹åº¦ä¸Šç»§æ‰¿è‡ªLLMéª¨å¹²ç½‘ç»œï¼Œå› ä¸ºLLMå…·æœ‰å·¨å¤§çš„å‚æ•°è§„æ¨¡å’Œå“è¶Šçš„èƒ½åŠ›ã€‚è¿™å¯¼è‡´äº†å¯¹è§†è§‰ç¼–ç å™¨çš„ç†è§£å­˜åœ¨ç©ºç™½ï¼Œè€Œè§†è§‰ç¼–ç å™¨å†³å®šäº†MLLMå¦‚ä½•æ„ŸçŸ¥å›¾åƒã€‚æœ€è¿‘MLLMè®­ç»ƒèŒƒå¼çš„è½¬å˜ï¼Œä»ç›‘ç£å¾®è°ƒ(SFT)åˆ°å¼ºåŒ–å­¦ä¹ (RL)ï¼Œæ”¾å¤§äº†è¿™ç§ç–å¿½â€”â€”å³ï¼Œä¸¥é‡ç¼ºä¹å¯¹è¿™ç§è®­ç»ƒå¦‚ä½•é‡å¡‘è§†è§‰ç¼–ç å™¨ä»¥åŠMLLMçš„åˆ†æã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬é¦–å…ˆç ”ç©¶äº†è®­ç»ƒç­–ç•¥å¯¹MLLMçš„å½±å“ï¼Œå…¶ä¸­RLåœ¨å¼ºè§†è§‰ç›¸å…³çš„VQAåŸºå‡†æµ‹è¯•ä¸­æ˜¾ç¤ºå‡ºæ˜æ˜¾ä¼˜äºSFTçš„ä¼˜åŠ¿ã€‚å—æ­¤å¯å‘ï¼Œæˆ‘ä»¬é€šè¿‡ä»ImageNetåˆ†ç±»å’Œåˆ†å‰²åˆ°æ¢¯åº¦å¯è§†åŒ–çš„å„ç§æ·±å…¥å®éªŒï¼Œå¯¹MLLMçš„è§†è§‰ç¼–ç å™¨è¿›è¡Œäº†å…³é”®ä½†æœªè¢«å……åˆ†æ¢ç´¢çš„åˆ†æã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼ŒMLLMçš„åè®­ç»ƒç­–ç•¥(å³SFTæˆ–RL)ä¸ä»…å¯¼è‡´MLLMä¸‹æ¸¸ä»»åŠ¡çš„ä¸åŒç»“æœï¼Œè€Œä¸”ä»æ ¹æœ¬ä¸Šé‡å¡‘äº†MLLMçš„åº•å±‚è§†è§‰è¡¨ç¤ºã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ç ”ç©¶çš„å…³é”®å‘ç°æ˜¯ï¼Œä¸SFTç›¸æ¯”ï¼ŒRLäº§ç”Ÿæ›´å¼ºå’Œæ›´ç²¾ç¡®å®šä½çš„è§†è§‰è¡¨ç¤ºï¼Œä»è€Œæé«˜äº†MLLMè§†è§‰ç¼–ç å™¨çš„èƒ½åŠ›ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†æˆ‘ä»¬çš„å‘ç°é‡æ–°æ„å»ºä¸ºä¸€ä¸ªç®€å•çš„é…æ–¹ï¼Œç”¨äºæ„å»ºMLLMçš„å¼ºå¤§è§†è§‰ç¼–ç å™¨ï¼Œå³åå¥½æŒ‡å¯¼çš„è§†è§‰ä¼˜åŒ–(PIVOT)ã€‚å½“é›†æˆåˆ°MLLMä¸­æ—¶ï¼Œç»è¿‡PIVOTè®­ç»ƒçš„è§†è§‰ç¼–ç å™¨ç”šè‡³ä¼˜äºæ›´å¤§å’Œè®­ç»ƒæ›´é‡çš„åŒç±»äº§å“ï¼Œå°½ç®¡æ‰€éœ€çš„è®¡ç®—æˆæœ¬ä¸åˆ°æ ‡å‡†è§†è§‰é¢„è®­ç»ƒçš„1%ã€‚è¿™ä¸€ç»“æœä¸ºæ¨è¿›MLLMçš„è§†è§‰éª¨å¹²ç½‘ç»œå¼€è¾Ÿäº†ä¸€æ¡æœ‰æ•ˆè€Œé«˜æ•ˆçš„é“è·¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰MLLMç ”ç©¶ä¸»è¦å…³æ³¨LLMéƒ¨åˆ†çš„ä¼˜åŒ–ï¼Œå¿½ç•¥äº†è§†è§‰ç¼–ç å™¨åœ¨å¤šæ¨¡æ€ç†è§£ä¸­çš„é‡è¦ä½œç”¨ã€‚ç‰¹åˆ«æ˜¯ï¼Œå½“è®­ç»ƒèŒƒå¼ä»ç›‘ç£å¾®è°ƒ(SFT)è½¬å‘å¼ºåŒ–å­¦ä¹ (RL)æ—¶ï¼Œè§†è§‰ç¼–ç å™¨çš„è¡Œä¸ºå˜åŒ–ç¼ºä¹æ·±å…¥åˆ†æã€‚ç°æœ‰æ–¹æ³•åœ¨è§†è§‰è¡¨å¾å­¦ä¹ æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´MLLMåœ¨è§†è§‰ç›¸å…³ä»»åŠ¡ä¸­è¡¨ç°å—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¼ºåŒ–å­¦ä¹ (RL)æ¥ä¼˜åŒ–MLLMçš„è§†è§‰ç¼–ç å™¨ï¼Œä½¿å…¶èƒ½å¤Ÿå­¦ä¹ åˆ°æ›´å¼ºå’Œæ›´ç²¾ç¡®å®šä½çš„è§†è§‰è¡¨å¾ã€‚é€šè¿‡RLï¼Œæ¨¡å‹å¯ä»¥æ ¹æ®åå¥½ä¿¡å·è°ƒæ•´è§†è§‰ç¼–ç å™¨çš„å‚æ•°ï¼Œä»è€Œæ›´å¥½åœ°é€‚åº”ä¸‹æ¸¸ä»»åŠ¡çš„éœ€æ±‚ã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨å¼¥è¡¥SFTåœ¨è§†è§‰è¡¨å¾å­¦ä¹ æ–¹é¢çš„ä¸è¶³ï¼Œæå‡MLLMçš„æ•´ä½“æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPIVOT (Preference-Instructed Vision OpTimization) çš„æ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) è§†è§‰ç¼–ç å™¨ï¼šè´Ÿè´£å°†è¾“å…¥å›¾åƒè½¬æ¢ä¸ºè§†è§‰ç‰¹å¾è¡¨ç¤ºã€‚2) LLMï¼šä½œä¸ºMLLMçš„è¯­è¨€å¤„ç†æ ¸å¿ƒï¼Œæ¥æ”¶è§†è§‰ç‰¹å¾å¹¶ç”Ÿæˆæ–‡æœ¬è¾“å‡ºã€‚3) å¥–åŠ±æ¨¡å‹ï¼šæ ¹æ®æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬è¾“å‡ºä¸æœŸæœ›è¾“å‡ºä¹‹é—´çš„åŒ¹é…ç¨‹åº¦ï¼Œæä¾›å¥–åŠ±ä¿¡å·ã€‚4) å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼šåˆ©ç”¨å¥–åŠ±ä¿¡å·ä¼˜åŒ–è§†è§‰ç¼–ç å™¨çš„å‚æ•°ã€‚è®­ç»ƒæµç¨‹æ˜¯ï¼šé¦–å…ˆï¼Œè§†è§‰ç¼–ç å™¨å°†å›¾åƒç¼–ç ä¸ºè§†è§‰ç‰¹å¾ï¼Œç„¶åLLMåŸºäºè¿™äº›ç‰¹å¾ç”Ÿæˆæ–‡æœ¬ã€‚å¥–åŠ±æ¨¡å‹è¯„ä¼°ç”Ÿæˆçš„æ–‡æœ¬ï¼Œå¹¶æä¾›å¥–åŠ±ä¿¡å·ã€‚æœ€åï¼Œå¼ºåŒ–å­¦ä¹ ç®—æ³•åˆ©ç”¨è¿™äº›å¥–åŠ±ä¿¡å·æ›´æ–°è§†è§‰ç¼–ç å™¨çš„å‚æ•°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºä½¿ç”¨å¼ºåŒ–å­¦ä¹ æ¥ç›´æ¥ä¼˜åŒ–è§†è§‰ç¼–ç å™¨ï¼Œè€Œä¸æ˜¯åƒä¼ ç»Ÿæ–¹æ³•é‚£æ ·ä¾èµ–äºç›‘ç£å­¦ä¹ æˆ–é¢„è®­ç»ƒã€‚è¿™ç§æ–¹æ³•å…è®¸è§†è§‰ç¼–ç å™¨æ ¹æ®ä¸‹æ¸¸ä»»åŠ¡çš„åå¥½è¿›è¡Œè‡ªé€‚åº”è°ƒæ•´ï¼Œä»è€Œå­¦ä¹ åˆ°æ›´æœ‰æ•ˆçš„è§†è§‰è¡¨å¾ã€‚ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºï¼ŒPIVOT æ˜¯ä¸€ç§ç«¯åˆ°ç«¯çš„ä¼˜åŒ–æ–¹æ³•ï¼Œå¯ä»¥ç›´æ¥ä¼˜åŒ–è§†è§‰ç¼–ç å™¨ä»¥é€‚åº”MLLMçš„éœ€æ±‚ã€‚

**å…³é”®è®¾è®¡**ï¼šPIVOTçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) å¥–åŠ±å‡½æ•°çš„è®¾è®¡ï¼šå¥–åŠ±å‡½æ•°éœ€è¦èƒ½å¤Ÿå‡†ç¡®åœ°åæ˜ æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬è¾“å‡ºä¸æœŸæœ›è¾“å‡ºä¹‹é—´çš„åŒ¹é…ç¨‹åº¦ã€‚å¯ä»¥ä½¿ç”¨è¯¸å¦‚BLEUã€ROUGEç­‰æŒ‡æ ‡æ¥è¡¡é‡æ–‡æœ¬ç›¸ä¼¼åº¦ã€‚2) å¼ºåŒ–å­¦ä¹ ç®—æ³•çš„é€‰æ‹©ï¼šå¯ä»¥ä½¿ç”¨è¯¸å¦‚PPOã€SACç­‰å…ˆè¿›çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•æ¥ä¼˜åŒ–è§†è§‰ç¼–ç å™¨çš„å‚æ•°ã€‚3) è§†è§‰ç¼–ç å™¨çš„ç»“æ„ï¼šå¯ä»¥ä½¿ç”¨è¯¸å¦‚ViTã€ResNetç­‰å¸¸ç”¨çš„è§†è§‰ç¼–ç å™¨ç»“æ„ã€‚4) åå¥½æ•°æ®çš„æ„å»ºï¼šéœ€è¦æ„å»ºåŒ…å«åå¥½ä¿¡æ¯çš„è®­ç»ƒæ•°æ®ï¼Œä¾‹å¦‚ï¼Œå¯¹äºVQAä»»åŠ¡ï¼Œå¯ä»¥æä¾›å¤šä¸ªå¯èƒ½çš„ç­”æ¡ˆï¼Œå¹¶æ ¹æ®å…¶æ­£ç¡®æ€§è¿›è¡Œæ’åºã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨PIVOTè®­ç»ƒçš„è§†è§‰ç¼–ç å™¨åœ¨å¤šä¸ªVQAåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†ä½¿ç”¨SFTè®­ç»ƒçš„åŒç±»æ¨¡å‹ã€‚æ›´é‡è¦çš„æ˜¯ï¼ŒPIVOTè®­ç»ƒçš„è§†è§‰ç¼–ç å™¨ç”šè‡³ä¼˜äºæ›´å¤§è§„æ¨¡ä¸”è®­ç»ƒæ›´å……åˆ†çš„åŒç±»æ¨¡å‹ï¼ŒåŒæ—¶æ˜¾è‘—é™ä½äº†è®¡ç®—æˆæœ¬ï¼Œè®¡ç®—æˆæœ¬ä½äºæ ‡å‡†è§†è§‰é¢„è®­ç»ƒçš„1%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºå¤šæ¨¡æ€ç†è§£é¢†åŸŸï¼Œä¾‹å¦‚è§†è§‰é—®ç­”ã€å›¾åƒæè¿°ã€è§†è§‰æ¨ç†ç­‰ã€‚é€šè¿‡æå‡MLLMçš„è§†è§‰æ„ŸçŸ¥èƒ½åŠ›ï¼Œå¯ä»¥æ”¹å–„äººæœºäº¤äº’ä½“éªŒï¼Œæé«˜è‡ªåŠ¨åŒ–ç³»ç»Ÿçš„æ™ºèƒ½åŒ–æ°´å¹³ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›åº”ç”¨äºæ™ºèƒ½å®¢æœã€è‡ªåŠ¨é©¾é©¶ã€åŒ»ç–—è¯Šæ–­ç­‰é¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> A dominant assumption in Multimodal Language Model (MLLM) research is that its performance is largely inherited from the LLM backbone, given its immense parameter scale and remarkable capabilities. This has created a void in the understanding of the vision encoder, which determines how MLLMs perceive images. The recent shift in MLLM training paradigms, from Supervised Finetuning (SFT) to Reinforcement Learning (RL), magnifies this oversight-namely, the significant lack of analysis on how such training reshapes the vision encoder as well as the MLLM. To address this, we first investigate the impact of training strategies on MLLMs, where RL shows a clear advantage over SFT in strongly vision-related VQA benchmarks. Motivated by this, we conduct a critical yet under-explored analysis of the vision encoder of MLLMs through diverse and in-depth experiments, ranging from ImageNet classification and segmentation to gradient visualization. Our results demonstrate that MLLM's post-training strategy (i.e., SFT or RL) not only leads to distinct outcomes on MLLM downstream tasks, but also fundamentally reshapes MLLM's underlying visual representations. Specifically, the key finding of our study is that RL produces stronger and precisely localized visual representations compared to SFT, boosting the ability of the vision encoder for MLLM. We then reframe our findings into a simple recipe for building strong vision encoders for MLLMs, Preference-Instructed Vision OpTimization (PIVOT). When integrated into MLLMs, a PIVOT-trained vision encoder outperforms even larger and more heavily-trained counterparts, despite requiring less than 1% of the computational cost of standard vision pretraining. This result opens an effective and efficient path for advancing the vision backbones of MLLMs. Project page available at https://june-page.github.io/pivot/

