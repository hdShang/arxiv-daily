---
layout: default
title: VIPAMIN: Visual Prompt Initialization via Embedding Selection and Subspace Expansion
---

# VIPAMIN: Visual Prompt Initialization via Embedding Selection and Subspace Expansion

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.16446" target="_blank" class="toolbar-btn">arXiv: 2510.16446v1</a>
    <a href="https://arxiv.org/pdf/2510.16446.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.16446v1" 
            onclick="toggleFavorite(this, '2510.16446v1', 'VIPAMIN: Visual Prompt Initialization via Embedding Selection and Subspace Expansion')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Jaekyun Park, Hye Won Chung

**ÂàÜÁ±ª**: cs.CV, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-18

**Â§áÊ≥®**: NeurIPS 2025

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/iamjaekyun/vipamin)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**VIPAMINÔºöÈÄöËøáÂµåÂÖ•ÈÄâÊã©ÂíåÂ≠êÁ©∫Èó¥Êâ©Â±ïÂÆûÁé∞ËßÜËßâPromptÂàùÂßãÂåñÔºåÊèêÂçáËá™ÁõëÁù£Ê®°ÂûãÂú®‰∏ãÊ∏∏‰ªªÂä°ÁöÑÊÄßËÉΩ„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâPromptË∞É‰ºò` `Ëá™ÁõëÁù£Â≠¶‰π†` `ÂµåÂÖ•ÈÄâÊã©` `Â≠êÁ©∫Èó¥Êâ©Â±ï` `PromptÂàùÂßãÂåñ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËßÜËßâPromptË∞É‰ºòÊñπÊ≥ïÂú®Ëá™ÁõëÁù£Ê®°Âûã‰∏äË°®Áé∞‰∏ç‰Ω≥ÔºåÂ∞§ÂÖ∂ÊòØÂú®Êï∞ÊçÆÁ®ÄÁº∫ÂíåÂ§çÊùÇ‰ªªÂä°‰∏≠ÔºåÊó†Ê≥ïÊúâÊïàÈÄÇÂ∫î„ÄÇ
2. VIPAMINÈÄöËøáÂµåÂÖ•ÈÄâÊã©Â∞ÜPrompt‰∏éËØ≠‰πâ‰ø°ÊÅØÂå∫ÂüüÂØπÈΩêÔºåÂπ∂ÈÄöËøáÂ≠êÁ©∫Èó¥Êâ©Â±ïÊ≥®ÂÖ•Êñ∞ÁöÑË°®Á§∫ÊñπÂêëÔºåÂ¢ûÂº∫Ê®°ÂûãÈÄÇÂ∫îÊÄß„ÄÇ
3. VIPAMIN‰ªÖÈúÄÂçïÊ¨°ÂâçÂêë‰º†ÈÄíÂíåËΩªÈáèÊìç‰ΩúÔºåÂç≥ÂèØÂú®Â§öÁßç‰ªªÂä°ÂíåÊï∞ÊçÆÈõÜ‰∏äÊòæËëóÊèêÂçáÊÄßËÉΩÔºåËææÂà∞ËßÜËßâPromptË∞É‰ºòÁöÑÊñ∞È´òÂ∫¶„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Âú®Â§ßËßÑÊ®°È¢ÑËÆ≠ÁªÉÊ®°ÂûãÊó∂‰ª£Ôºå‰∏∫ÊØè‰∏™‰∏ãÊ∏∏‰ªªÂä°ÂÆåÂÖ®ÂæÆË∞ÉÈ¢ÑËÆ≠ÁªÉÁΩëÁªúÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáèÁöÑËµÑÊ∫ê„ÄÇPromptË∞É‰ºòÊèê‰æõ‰∫Ü‰∏ÄÁßçËΩªÈáèÁ∫ßÁöÑÊõø‰ª£ÊñπÊ°àÔºåÈÄöËøáÂºïÂÖ•ÂèØË∞ÉPromptÂêåÊó∂‰øùÊåÅÈ™®Âπ≤ÁΩëÁªúÂÜªÁªì„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÁöÑËßÜËßâPromptË∞É‰ºòÊñπÊ≥ïÈÄöÂ∏∏Êó†Ê≥ï‰∏ìÈó®ÂåñPromptÊàñ‰∏∞ÂØåË°®Á§∫Á©∫Èó¥ÔºåÂ∞§ÂÖ∂ÊòØÂú®Â∫îÁî®‰∫éËá™ÁõëÁù£È™®Âπ≤ÁΩëÁªúÊó∂„ÄÇÊàë‰ª¨Ë°®ÊòéÔºåËøô‰∫õÈôêÂà∂Âú®ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑ‰ªªÂä°ÂíåÊï∞ÊçÆÁ®ÄÁº∫ÁöÑÁéØÂ¢É‰∏≠ÂèòÂæóÂ∞§‰∏∫ÊòéÊòæÔºåËÄåÂú®Ëøô‰∫õÊÉÖÂÜµ‰∏ãÔºåÊúâÊïàÁöÑÈÄÇÂ∫îËá≥ÂÖ≥ÈáçË¶Å„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨‰ªãÁªç‰∫Ü‰∏ÄÁßçËßÜËßâPromptÂàùÂßãÂåñÁ≠ñÁï•VIPAMINÔºåÂÆÉÈÄöËøá‰ª•‰∏ãÊñπÂºèÂ¢ûÂº∫Ëá™ÁõëÁù£Ê®°ÂûãÁöÑÈÄÇÂ∫îÊÄßÔºöÔºà1ÔºâÂ∞ÜPrompt‰∏éÂµåÂÖ•Á©∫Èó¥‰∏≠ËØ≠‰πâ‰ø°ÊÅØ‰∏∞ÂØåÁöÑÂå∫ÂüüÂØπÈΩêÔºå‰ª•ÂèäÔºà2ÔºâÊ≥®ÂÖ•Ë∂ÖÂá∫È¢ÑËÆ≠ÁªÉÂ≠êÁ©∫Èó¥ÁöÑÊñ∞Ë°®Á§∫ÊñπÂêë„ÄÇÂ∞ΩÁÆ°ÂÖ∂ÁÆÄÂçïÊÄß‚Äî‚Äî‰ªÖÈúÄË¶Å‰∏ÄÊ¨°ÂâçÂêë‰º†ÈÄíÂíåËΩªÈáèÁ∫ßÊìç‰Ωú‚Äî‚ÄîVIPAMINÂßãÁªàÂ¶Ç‰∏ÄÂú∞ÊèêÈ´ò‰∫ÜÂêÑÁßç‰ªªÂä°ÂíåÊï∞ÊçÆÈõÜÂ§ßÂ∞èÁöÑÊÄßËÉΩÔºåÂπ∂Âú®ËßÜËßâPromptË∞É‰ºò‰∏≠Âª∫Á´ã‰∫ÜÊñ∞ÁöÑÊúÄÂÖàËøõÊ∞¥Âπ≥„ÄÇÊàë‰ª¨ÁöÑ‰ª£Á†ÅÂèØÂú®https://github.com/iamjaekyun/vipaminËé∑Âæó„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÁöÑËßÜËßâPromptË∞É‰ºòÊñπÊ≥ïÂú®Â∫îÁî®‰∫éËá™ÁõëÁù£Ê®°ÂûãÊó∂ÔºåÂ≠òÂú®PromptÊó†Ê≥ïÊúâÊïàÁâπÂåñ‰ª•ÂèäË°®Á§∫Á©∫Èó¥‰∏çÂ§ü‰∏∞ÂØåÁöÑÈóÆÈ¢ò„ÄÇÂ∞§ÂÖ∂ÊòØÂú®Êï∞ÊçÆÈáèËæÉÂ∞ëÊàñËÄÖ‰ªªÂä°ÊØîËæÉÂ§çÊùÇÁöÑÊÉÖÂÜµ‰∏ãÔºåËøô‰∫õÈóÆÈ¢ò‰ºöÊõ¥Âä†Á™ÅÂá∫ÔºåÂØºËá¥Ê®°ÂûãÊÄßËÉΩ‰∏ãÈôç„ÄÇÂõ†Ê≠§ÔºåÂ¶Ç‰ΩïÊúâÊïàÂú∞ÂàùÂßãÂåñPromptÔºå‰ΩøÂÖ∂ËÉΩÂ§üÊõ¥Â•ΩÂú∞ÈÄÇÂ∫î‰∏ãÊ∏∏‰ªªÂä°ÔºåÊòØÊú¨ÊñáË¶ÅËß£ÂÜ≥ÁöÑÊ†∏ÂøÉÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöVIPAMINÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøá‰∏§‰∏™ÂÖ≥ÈîÆÊ≠•È™§Êù•ÊîπÂñÑPromptÁöÑÂàùÂßãÂåñÔºöÈ¶ñÂÖàÔºåÈÄöËøáÂµåÂÖ•ÈÄâÊã©ÔºåÂ∞ÜPrompt‰∏éÂµåÂÖ•Á©∫Èó¥‰∏≠ÂÖ∑ÊúâËØ≠‰πâ‰ø°ÊÅØÁöÑÂå∫ÂüüÂØπÈΩêÔºå‰ªéËÄå‰ΩøPromptËÉΩÂ§üÊõ¥Â•ΩÂú∞ÊçïÊçâÂà∞‰ªªÂä°Áõ∏ÂÖ≥ÁöÑÁâπÂæÅ„ÄÇÂÖ∂Ê¨°ÔºåÈÄöËøáÂ≠êÁ©∫Èó¥Êâ©Â±ïÔºåÂêëPrompt‰∏≠Ê≥®ÂÖ•Êñ∞ÁöÑË°®Á§∫ÊñπÂêëÔºå‰ΩøÂÖ∂ËÉΩÂ§üË∂ÖË∂äÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãÁöÑÂõ∫ÊúâË°®Á§∫ËÉΩÂäõÔºå‰ªéËÄåÊèêÈ´òÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöVIPAMINÁöÑÊï¥‰ΩìÊµÅÁ®ãÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™Ê≠•È™§Ôºö1. ‰ΩøÁî®È¢ÑËÆ≠ÁªÉÁöÑËá™ÁõëÁù£Ê®°ÂûãÊèêÂèñËæìÂÖ•ÂõæÂÉèÁöÑÂµåÂÖ•ÁâπÂæÅ„ÄÇ2. ÈÄöËøáÂµåÂÖ•ÈÄâÊã©Ê®°ÂùóÔºå‰ªéÂµåÂÖ•Á©∫Èó¥‰∏≠ÈÄâÊã©ÂÖ∑Êúâ‰ª£Ë°®ÊÄßÁöÑÂå∫Âüü‰Ωú‰∏∫PromptÁöÑÂàùÂßãÂåñÂÄº„ÄÇ3. ÈÄöËøáÂ≠êÁ©∫Èó¥Êâ©Â±ïÊ®°ÂùóÔºåÂêëPrompt‰∏≠Ê≥®ÂÖ•Êñ∞ÁöÑË°®Á§∫ÊñπÂêëÔºå‰ª•Â¢ûÂº∫ÂÖ∂Ë°®Á§∫ËÉΩÂäõ„ÄÇ4. Â∞ÜÂàùÂßãÂåñÂêéÁöÑPromptÊ∑ªÂä†Âà∞ËæìÂÖ•ÂõæÂÉèÁöÑÂµåÂÖ•ÁâπÂæÅ‰∏≠ÔºåÁÑ∂ÂêéËæìÂÖ•Âà∞‰∏ãÊ∏∏‰ªªÂä°ÁöÑÊ®°Âûã‰∏≠ËøõË°åËÆ≠ÁªÉ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöVIPAMINÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂PromptÂàùÂßãÂåñÁ≠ñÁï•ÔºåËØ•Á≠ñÁï•ÁªìÂêà‰∫ÜÂµåÂÖ•ÈÄâÊã©ÂíåÂ≠êÁ©∫Èó¥Êâ©Â±ï‰∏§ÁßçÊñπÊ≥ï„ÄÇÂµåÂÖ•ÈÄâÊã©ËÉΩÂ§ü‰ΩøPrompt‰∏é‰ªªÂä°Áõ∏ÂÖ≥ÁöÑËØ≠‰πâ‰ø°ÊÅØÂØπÈΩêÔºåËÄåÂ≠êÁ©∫Èó¥Êâ©Â±ïËÉΩÂ§üÂ¢ûÂº∫PromptÁöÑË°®Á§∫ËÉΩÂäõÔºå‰ªéËÄåÊèêÈ´òÊ®°ÂûãÁöÑÊÄßËÉΩ„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåVIPAMIN‰∏çÈúÄË¶ÅÂ§çÊùÇÁöÑËÆ≠ÁªÉËøáÁ®ãÔºåÂè™ÈúÄË¶Å‰∏ÄÊ¨°ÂâçÂêë‰º†ÈÄíÂíåËΩªÈáèÁ∫ßÁöÑÊìç‰ΩúÂç≥ÂèØÂÆåÊàêPromptÁöÑÂàùÂßãÂåñ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöVIPAMINÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1. ÂµåÂÖ•ÈÄâÊã©Ê®°ÂùóÔºöËØ•Ê®°ÂùóÈÄöËøáËÆ°ÁÆóÂµåÂÖ•ÁâπÂæÅ‰πãÈó¥ÁöÑÁõ∏‰ººÂ∫¶ÔºåÈÄâÊã©ÂÖ∑Êúâ‰ª£Ë°®ÊÄßÁöÑÂå∫Âüü‰Ωú‰∏∫PromptÁöÑÂàùÂßãÂåñÂÄº„ÄÇÂÖ∑‰ΩìÂÆûÁé∞ÂèØ‰ª•‰ΩøÁî®ËÅöÁ±ªÁÆóÊ≥ïÊàñËÄÖKËøëÈÇªÁÆóÊ≥ï„ÄÇ2. Â≠êÁ©∫Èó¥Êâ©Â±ïÊ®°ÂùóÔºöËØ•Ê®°ÂùóÈÄöËøáÈöèÊú∫ÁîüÊàêÊñ∞ÁöÑÂêëÈáèÔºåÂπ∂Â∞ÜËøô‰∫õÂêëÈáèÊ∑ªÂä†Âà∞Prompt‰∏≠Ôºå‰ªéËÄåÊâ©Â±ïPromptÁöÑË°®Á§∫Á©∫Èó¥„ÄÇÊñ∞ÂêëÈáèÁöÑÁîüÊàêÂèØ‰ª•ÈááÁî®È´òÊñØÂàÜÂ∏ÉÊàñËÄÖÂùáÂåÄÂàÜÂ∏É„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

VIPAMINÂú®Â§ö‰∏™ËßÜËßâ‰ªªÂä°ÂíåÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºå‰æãÂ¶ÇÂú®ÂõæÂÉèÂàÜÁ±ª„ÄÅÁõÆÊ†áÊ£ÄÊµãÁ≠â‰ªªÂä°‰∏äÔºåÁõ∏ÊØî‰∫éÁé∞ÊúâÁöÑPromptË∞É‰ºòÊñπÊ≥ïÔºåVIPAMINËÉΩÂ§üÂèñÂæóÊõ¥È´òÁöÑÂáÜÁ°ÆÁéáÂíåÊõ¥Âø´ÁöÑÊî∂ÊïõÈÄüÂ∫¶„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåVIPAMINËÉΩÂ§üÊúâÊïàÂú∞Âà©Áî®Ëá™ÁõëÁù£Ê®°ÂûãÁöÑÈ¢ÑËÆ≠ÁªÉÁü•ËØÜÔºåÂπ∂Â∞ÜÂÖ∂ËøÅÁßªÂà∞‰∏ãÊ∏∏‰ªªÂä°‰∏≠Ôºå‰ªéËÄåÊèêÈ´òÊ®°ÂûãÁöÑÊÄßËÉΩ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

VIPAMINÂèØÂπøÊ≥õÂ∫îÁî®‰∫éËÆ°ÁÆóÊú∫ËßÜËßâÈ¢ÜÂüüÁöÑÂêÑÁßç‰∏ãÊ∏∏‰ªªÂä°ÔºåÂ∞§ÂÖ∂ÊòØÂú®Êï∞ÊçÆÁ®ÄÁº∫ÊàñËÆ°ÁÆóËµÑÊ∫êÊúâÈôêÁöÑÊÉÖÂÜµ‰∏ã„ÄÇ‰æãÂ¶ÇÔºåÂú®ÂåªÂ≠¶ÂõæÂÉèÂàÜÊûê„ÄÅÈÅ•ÊÑüÂõæÂÉèÂ§ÑÁêÜ„ÄÅËá™Âä®È©æÈ©∂Á≠âÈ¢ÜÂüüÔºåÂèØ‰ª•Âà©Áî®VIPAMINÊù•ÊèêÈ´òÊ®°ÂûãÁöÑÊÄßËÉΩÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåVIPAMINËøòÂèØ‰ª•‰Ωú‰∏∫‰∏ÄÁßçÈÄöÁî®ÁöÑPromptË∞É‰ºòÊñπÊ≥ïÔºåÂ∫îÁî®‰∫éÂÖ∂‰ªñÁ±ªÂûãÁöÑÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãÔºå‰æãÂ¶ÇËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÊ®°Âûã„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> In the era of large-scale foundation models, fully fine-tuning pretrained networks for each downstream task is often prohibitively resource-intensive. Prompt tuning offers a lightweight alternative by introducing tunable prompts while keeping the backbone frozen. However, existing visual prompt tuning methods often fail to specialize the prompts or enrich the representation space--especially when applied to self-supervised backbones. We show that these limitations become especially pronounced in challenging tasks and data-scarce settings, where effective adaptation is most critical. In this work, we introduce VIPAMIN, a visual prompt initialization strategy that enhances adaptation of self-supervised models by (1) aligning prompts with semantically informative regions in the embedding space, and (2) injecting novel representational directions beyond the pretrained subspace. Despite its simplicity--requiring only a single forward pass and lightweight operations--VIPAMIN consistently improves performance across diverse tasks and dataset sizes, setting a new state of the art in visual prompt tuning. Our code is available at https://github.com/iamjaekyun/vipamin.

