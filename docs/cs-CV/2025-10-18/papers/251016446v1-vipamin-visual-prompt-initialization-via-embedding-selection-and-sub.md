---
layout: default
title: VIPAMIN: Visual Prompt Initialization via Embedding Selection and Subspace Expansion
---

# VIPAMIN: Visual Prompt Initialization via Embedding Selection and Subspace Expansion

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.16446" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.16446v1</a>
  <a href="https://arxiv.org/pdf/2510.16446.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.16446v1" onclick="toggleFavorite(this, '2510.16446v1', 'VIPAMIN: Visual Prompt Initialization via Embedding Selection and Subspace Expansion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jaekyun Park, Hye Won Chung

**åˆ†ç±»**: cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-10-18

**å¤‡æ³¨**: NeurIPS 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/iamjaekyun/vipamin)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**VIPAMINï¼šé€šè¿‡åµŒå…¥é€‰æ‹©å’Œå­ç©ºé—´æ‰©å±•å®ç°è§†è§‰Promptåˆå§‹åŒ–ï¼Œæå‡è‡ªç›‘ç£æ¨¡å‹åœ¨ä¸‹æ¸¸ä»»åŠ¡çš„æ€§èƒ½ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰Promptè°ƒä¼˜` `è‡ªç›‘ç£å­¦ä¹ ` `åµŒå…¥é€‰æ‹©` `å­ç©ºé—´æ‰©å±•` `Promptåˆå§‹åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰Promptè°ƒä¼˜æ–¹æ³•åœ¨è‡ªç›‘ç£æ¨¡å‹ä¸Šè¡¨ç°ä¸ä½³ï¼Œå°¤å…¶æ˜¯åœ¨æ•°æ®ç¨€ç¼ºå’Œå¤æ‚ä»»åŠ¡ä¸­ï¼Œæ— æ³•æœ‰æ•ˆé€‚åº”ã€‚
2. VIPAMINé€šè¿‡åµŒå…¥é€‰æ‹©å°†Promptä¸è¯­ä¹‰ä¿¡æ¯åŒºåŸŸå¯¹é½ï¼Œå¹¶é€šè¿‡å­ç©ºé—´æ‰©å±•æ³¨å…¥æ–°çš„è¡¨ç¤ºæ–¹å‘ï¼Œå¢å¼ºæ¨¡å‹é€‚åº”æ€§ã€‚
3. VIPAMINä»…éœ€å•æ¬¡å‰å‘ä¼ é€’å’Œè½»é‡æ“ä½œï¼Œå³å¯åœ¨å¤šç§ä»»åŠ¡å’Œæ•°æ®é›†ä¸Šæ˜¾è‘—æå‡æ€§èƒ½ï¼Œè¾¾åˆ°è§†è§‰Promptè°ƒä¼˜çš„æ–°é«˜åº¦ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹æ—¶ä»£ï¼Œä¸ºæ¯ä¸ªä¸‹æ¸¸ä»»åŠ¡å®Œå…¨å¾®è°ƒé¢„è®­ç»ƒç½‘ç»œé€šå¸¸éœ€è¦å¤§é‡çš„èµ„æºã€‚Promptè°ƒä¼˜æä¾›äº†ä¸€ç§è½»é‡çº§çš„æ›¿ä»£æ–¹æ¡ˆï¼Œé€šè¿‡å¼•å…¥å¯è°ƒPromptåŒæ—¶ä¿æŒéª¨å¹²ç½‘ç»œå†»ç»“ã€‚ç„¶è€Œï¼Œç°æœ‰çš„è§†è§‰Promptè°ƒä¼˜æ–¹æ³•é€šå¸¸æ— æ³•ä¸“é—¨åŒ–Promptæˆ–ä¸°å¯Œè¡¨ç¤ºç©ºé—´ï¼Œå°¤å…¶æ˜¯åœ¨åº”ç”¨äºè‡ªç›‘ç£éª¨å¹²ç½‘ç»œæ—¶ã€‚æˆ‘ä»¬è¡¨æ˜ï¼Œè¿™äº›é™åˆ¶åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡å’Œæ•°æ®ç¨€ç¼ºçš„ç¯å¢ƒä¸­å˜å¾—å°¤ä¸ºæ˜æ˜¾ï¼Œè€Œåœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œæœ‰æ•ˆçš„é€‚åº”è‡³å…³é‡è¦ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸€ç§è§†è§‰Promptåˆå§‹åŒ–ç­–ç•¥VIPAMINï¼Œå®ƒé€šè¿‡ä»¥ä¸‹æ–¹å¼å¢å¼ºè‡ªç›‘ç£æ¨¡å‹çš„é€‚åº”æ€§ï¼šï¼ˆ1ï¼‰å°†Promptä¸åµŒå…¥ç©ºé—´ä¸­è¯­ä¹‰ä¿¡æ¯ä¸°å¯Œçš„åŒºåŸŸå¯¹é½ï¼Œä»¥åŠï¼ˆ2ï¼‰æ³¨å…¥è¶…å‡ºé¢„è®­ç»ƒå­ç©ºé—´çš„æ–°è¡¨ç¤ºæ–¹å‘ã€‚å°½ç®¡å…¶ç®€å•æ€§â€”â€”ä»…éœ€è¦ä¸€æ¬¡å‰å‘ä¼ é€’å’Œè½»é‡çº§æ“ä½œâ€”â€”VIPAMINå§‹ç»ˆå¦‚ä¸€åœ°æé«˜äº†å„ç§ä»»åŠ¡å’Œæ•°æ®é›†å¤§å°çš„æ€§èƒ½ï¼Œå¹¶åœ¨è§†è§‰Promptè°ƒä¼˜ä¸­å»ºç«‹äº†æ–°çš„æœ€å…ˆè¿›æ°´å¹³ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨https://github.com/iamjaekyun/vipaminè·å¾—ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„è§†è§‰Promptè°ƒä¼˜æ–¹æ³•åœ¨åº”ç”¨äºè‡ªç›‘ç£æ¨¡å‹æ—¶ï¼Œå­˜åœ¨Promptæ— æ³•æœ‰æ•ˆç‰¹åŒ–ä»¥åŠè¡¨ç¤ºç©ºé—´ä¸å¤Ÿä¸°å¯Œçš„é—®é¢˜ã€‚å°¤å…¶æ˜¯åœ¨æ•°æ®é‡è¾ƒå°‘æˆ–è€…ä»»åŠ¡æ¯”è¾ƒå¤æ‚çš„æƒ…å†µä¸‹ï¼Œè¿™äº›é—®é¢˜ä¼šæ›´åŠ çªå‡ºï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸‹é™ã€‚å› æ­¤ï¼Œå¦‚ä½•æœ‰æ•ˆåœ°åˆå§‹åŒ–Promptï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”ä¸‹æ¸¸ä»»åŠ¡ï¼Œæ˜¯æœ¬æ–‡è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šVIPAMINçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ä¸¤ä¸ªå…³é”®æ­¥éª¤æ¥æ”¹å–„Promptçš„åˆå§‹åŒ–ï¼šé¦–å…ˆï¼Œé€šè¿‡åµŒå…¥é€‰æ‹©ï¼Œå°†Promptä¸åµŒå…¥ç©ºé—´ä¸­å…·æœ‰è¯­ä¹‰ä¿¡æ¯çš„åŒºåŸŸå¯¹é½ï¼Œä»è€Œä½¿Promptèƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰åˆ°ä»»åŠ¡ç›¸å…³çš„ç‰¹å¾ã€‚å…¶æ¬¡ï¼Œé€šè¿‡å­ç©ºé—´æ‰©å±•ï¼Œå‘Promptä¸­æ³¨å…¥æ–°çš„è¡¨ç¤ºæ–¹å‘ï¼Œä½¿å…¶èƒ½å¤Ÿè¶…è¶Šé¢„è®­ç»ƒæ¨¡å‹çš„å›ºæœ‰è¡¨ç¤ºèƒ½åŠ›ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVIPAMINçš„æ•´ä½“æµç¨‹åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1. ä½¿ç”¨é¢„è®­ç»ƒçš„è‡ªç›‘ç£æ¨¡å‹æå–è¾“å…¥å›¾åƒçš„åµŒå…¥ç‰¹å¾ã€‚2. é€šè¿‡åµŒå…¥é€‰æ‹©æ¨¡å—ï¼Œä»åµŒå…¥ç©ºé—´ä¸­é€‰æ‹©å…·æœ‰ä»£è¡¨æ€§çš„åŒºåŸŸä½œä¸ºPromptçš„åˆå§‹åŒ–å€¼ã€‚3. é€šè¿‡å­ç©ºé—´æ‰©å±•æ¨¡å—ï¼Œå‘Promptä¸­æ³¨å…¥æ–°çš„è¡¨ç¤ºæ–¹å‘ï¼Œä»¥å¢å¼ºå…¶è¡¨ç¤ºèƒ½åŠ›ã€‚4. å°†åˆå§‹åŒ–åçš„Promptæ·»åŠ åˆ°è¾“å…¥å›¾åƒçš„åµŒå…¥ç‰¹å¾ä¸­ï¼Œç„¶åè¾“å…¥åˆ°ä¸‹æ¸¸ä»»åŠ¡çš„æ¨¡å‹ä¸­è¿›è¡Œè®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šVIPAMINçš„å…³é”®åˆ›æ–°åœ¨äºå…¶Promptåˆå§‹åŒ–ç­–ç•¥ï¼Œè¯¥ç­–ç•¥ç»“åˆäº†åµŒå…¥é€‰æ‹©å’Œå­ç©ºé—´æ‰©å±•ä¸¤ç§æ–¹æ³•ã€‚åµŒå…¥é€‰æ‹©èƒ½å¤Ÿä½¿Promptä¸ä»»åŠ¡ç›¸å…³çš„è¯­ä¹‰ä¿¡æ¯å¯¹é½ï¼Œè€Œå­ç©ºé—´æ‰©å±•èƒ½å¤Ÿå¢å¼ºPromptçš„è¡¨ç¤ºèƒ½åŠ›ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒVIPAMINä¸éœ€è¦å¤æ‚çš„è®­ç»ƒè¿‡ç¨‹ï¼Œåªéœ€è¦ä¸€æ¬¡å‰å‘ä¼ é€’å’Œè½»é‡çº§çš„æ“ä½œå³å¯å®ŒæˆPromptçš„åˆå§‹åŒ–ã€‚

**å…³é”®è®¾è®¡**ï¼šVIPAMINçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1. åµŒå…¥é€‰æ‹©æ¨¡å—ï¼šè¯¥æ¨¡å—é€šè¿‡è®¡ç®—åµŒå…¥ç‰¹å¾ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œé€‰æ‹©å…·æœ‰ä»£è¡¨æ€§çš„åŒºåŸŸä½œä¸ºPromptçš„åˆå§‹åŒ–å€¼ã€‚å…·ä½“å®ç°å¯ä»¥ä½¿ç”¨èšç±»ç®—æ³•æˆ–è€…Kè¿‘é‚»ç®—æ³•ã€‚2. å­ç©ºé—´æ‰©å±•æ¨¡å—ï¼šè¯¥æ¨¡å—é€šè¿‡éšæœºç”Ÿæˆæ–°çš„å‘é‡ï¼Œå¹¶å°†è¿™äº›å‘é‡æ·»åŠ åˆ°Promptä¸­ï¼Œä»è€Œæ‰©å±•Promptçš„è¡¨ç¤ºç©ºé—´ã€‚æ–°å‘é‡çš„ç”Ÿæˆå¯ä»¥é‡‡ç”¨é«˜æ–¯åˆ†å¸ƒæˆ–è€…å‡åŒ€åˆ†å¸ƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

VIPAMINåœ¨å¤šä¸ªè§†è§‰ä»»åŠ¡å’Œæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œä¾‹å¦‚åœ¨å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ç­‰ä»»åŠ¡ä¸Šï¼Œç›¸æ¯”äºç°æœ‰çš„Promptè°ƒä¼˜æ–¹æ³•ï¼ŒVIPAMINèƒ½å¤Ÿå–å¾—æ›´é«˜çš„å‡†ç¡®ç‡å’Œæ›´å¿«çš„æ”¶æ•›é€Ÿåº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒVIPAMINèƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨è‡ªç›‘ç£æ¨¡å‹çš„é¢„è®­ç»ƒçŸ¥è¯†ï¼Œå¹¶å°†å…¶è¿ç§»åˆ°ä¸‹æ¸¸ä»»åŠ¡ä¸­ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

VIPAMINå¯å¹¿æ³›åº”ç”¨äºè®¡ç®—æœºè§†è§‰é¢†åŸŸçš„å„ç§ä¸‹æ¸¸ä»»åŠ¡ï¼Œå°¤å…¶æ˜¯åœ¨æ•°æ®ç¨€ç¼ºæˆ–è®¡ç®—èµ„æºæœ‰é™çš„æƒ…å†µä¸‹ã€‚ä¾‹å¦‚ï¼Œåœ¨åŒ»å­¦å›¾åƒåˆ†æã€é¥æ„Ÿå›¾åƒå¤„ç†ã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸï¼Œå¯ä»¥åˆ©ç”¨VIPAMINæ¥æé«˜æ¨¡å‹çš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒVIPAMINè¿˜å¯ä»¥ä½œä¸ºä¸€ç§é€šç”¨çš„Promptè°ƒä¼˜æ–¹æ³•ï¼Œåº”ç”¨äºå…¶ä»–ç±»å‹çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œä¾‹å¦‚è‡ªç„¶è¯­è¨€å¤„ç†æ¨¡å‹ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In the era of large-scale foundation models, fully fine-tuning pretrained networks for each downstream task is often prohibitively resource-intensive. Prompt tuning offers a lightweight alternative by introducing tunable prompts while keeping the backbone frozen. However, existing visual prompt tuning methods often fail to specialize the prompts or enrich the representation space--especially when applied to self-supervised backbones. We show that these limitations become especially pronounced in challenging tasks and data-scarce settings, where effective adaptation is most critical. In this work, we introduce VIPAMIN, a visual prompt initialization strategy that enhances adaptation of self-supervised models by (1) aligning prompts with semantically informative regions in the embedding space, and (2) injecting novel representational directions beyond the pretrained subspace. Despite its simplicity--requiring only a single forward pass and lightweight operations--VIPAMIN consistently improves performance across diverse tasks and dataset sizes, setting a new state of the art in visual prompt tuning. Our code is available at https://github.com/iamjaekyun/vipamin.

