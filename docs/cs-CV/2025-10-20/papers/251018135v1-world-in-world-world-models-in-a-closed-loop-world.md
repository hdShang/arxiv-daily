---
layout: default
title: "World-in-World: World Models in a Closed-Loop World"
---

# World-in-World: World Models in a Closed-Loop World

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.18135" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.18135v1</a>
  <a href="https://arxiv.org/pdf/2510.18135.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.18135v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.18135v1', 'World-in-World: World Models in a Closed-Loop World')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiahan Zhang, Muqing Jiang, Nanru Dai, Taiming Lu, Arda Uzunoglu, Shunchi Zhang, Yana Wei, Jiahao Wang, Vishal M. Patel, Paul Pu Liang, Daniel Khashabi, Cheng Peng, Rama Chellappa, Tianmin Shu, Alan Yuille, Yilun Du, Jieneng Chen

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-20

**å¤‡æ³¨**: Code is at https://github.com/World-In-World/world-in-world

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**World-in-Worldï¼šé¦–ä¸ªé—­ç¯ä¸–ç•Œæ¨¡å‹åŸºå‡†å¹³å°ï¼Œç”¨äºè¯„ä¼°å…·èº«æ™ºèƒ½ä½“çš„é¢„æµ‹æ„ŸçŸ¥èƒ½åŠ›ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `ä¸–ç•Œæ¨¡å‹` `å…·èº«æ™ºèƒ½` `é—­ç¯è¯„ä¼°` `å¼ºåŒ–å­¦ä¹ ` `æœºå™¨äºº` `é¢„æµ‹æ„ŸçŸ¥` `åœ¨çº¿è§„åˆ’`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ä¸–ç•Œæ¨¡å‹è¯„ä¼°ä¾§é‡è§†è§‰è´¨é‡ï¼Œå¿½ç•¥äº†å…¶åœ¨å…·èº«æ™ºèƒ½ä½“å†³ç­–ä¸­çš„å®é™…æ•ˆç”¨ï¼Œç¼ºä¹é—­ç¯ç¯å¢ƒä¸‹çš„ç»¼åˆè¯„ä¼°ã€‚
2. World-in-Worldå¹³å°æä¾›é—­ç¯ç¯å¢ƒã€ç»Ÿä¸€è§„åˆ’ç­–ç•¥å’Œæ ‡å‡†åŒ–åŠ¨ä½œAPIï¼Œæ”¯æŒå…¨é¢è¯„ä¼°ä¸–ç•Œæ¨¡å‹åœ¨å…·èº«ä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè§†è§‰è´¨é‡å¹¶éæˆåŠŸçš„å”¯ä¸€å› ç´ ï¼Œå¯æ§æ€§è‡³å…³é‡è¦ï¼Œä¸”åè®­ç»ƒå’Œæ¨ç†è®¡ç®—åˆ†é…èƒ½æ˜¾è‘—æå‡æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç”Ÿæˆå¼ä¸–ç•Œæ¨¡å‹ï¼ˆWMsï¼‰åœ¨æ¨¡æ‹Ÿå…·æœ‰æƒŠäººè§†è§‰çœŸå®æ„Ÿçš„ä¸–ç•Œæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚æœ¬æ–‡æ—¨åœ¨æ¢è®¨è¿™äº›æ¨¡å‹æ˜¯å¦èƒ½èµ‹äºˆå…·èº«æ™ºèƒ½ä½“é¢„æµ‹æ„ŸçŸ¥èƒ½åŠ›ï¼Œä»è€Œè¾…åŠ©å†³ç­–ã€‚ç„¶è€Œï¼Œç°æœ‰è¯„ä¼°æ–¹æ³•ä¾§é‡äºå­¤ç«‹çš„è§†è§‰è´¨é‡ï¼Œå¿½ç•¥äº†å…·èº«æ•ˆç”¨è¿™ä¸€æ ¸å¿ƒé—®é¢˜ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æ¨å‡ºäº†World-in-Worldï¼Œè¿™æ˜¯ä¸€ä¸ªå¼€æ”¾å¹³å°ï¼Œç”¨äºåœ¨æ¨¡æ‹ŸçœŸå®æ™ºèƒ½ä½“-ç¯å¢ƒäº¤äº’çš„é—­ç¯ä¸–ç•Œä¸­è¯„ä¼°WMsã€‚World-in-Worldæä¾›ç»Ÿä¸€çš„åœ¨çº¿è§„åˆ’ç­–ç•¥å’Œæ ‡å‡†åŒ–çš„åŠ¨ä½œAPIï¼Œæ”¯æŒå¼‚æ„WMsè¿›è¡Œå†³ç­–ã€‚æˆ‘ä»¬è®¾è®¡äº†å››ä¸ªé—­ç¯ç¯å¢ƒï¼Œä¸¥æ ¼è¯„ä¼°ä¸åŒçš„WMsï¼Œå¹¶å°†ä»»åŠ¡æˆåŠŸç‡ä½œä¸ºä¸»è¦æŒ‡æ ‡ï¼Œè¶…è¶Šäº†å¯¹è§†è§‰è´¨é‡çš„å…³æ³¨ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†å…·èº«ç¯å¢ƒä¸­ä¸–ç•Œæ¨¡å‹çš„æ•°æ®ç¼©æ”¾å®šå¾‹ã€‚ç ”ç©¶æ­ç¤ºäº†ä¸‰ä¸ªæ„å¤–å‘ç°ï¼šè§†è§‰è´¨é‡å¹¶ä¸ä¿è¯ä»»åŠ¡æˆåŠŸï¼Œå¯æ§æ€§æ›´é‡è¦ï¼›ä½¿ç”¨åŠ¨ä½œ-è§‚å¯Ÿæ•°æ®è¿›è¡Œåè®­ç»ƒæ¯”å‡çº§é¢„è®­ç»ƒè§†é¢‘ç”Ÿæˆå™¨æ›´æœ‰æ•ˆï¼›åˆ†é…æ›´å¤šçš„æ¨ç†æ—¶é—´è®¡ç®—å¯ä»¥æ˜¾è‘—æé«˜WMsçš„é—­ç¯æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰ä¸–ç•Œæ¨¡å‹çš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨è§†è§‰ç”Ÿæˆè´¨é‡çš„æå‡ï¼Œç¼ºä¹åœ¨é—­ç¯å…·èº«ç¯å¢ƒä¸­å¯¹æ¨¡å‹é¢„æµ‹èƒ½åŠ›å’Œæ§åˆ¶èƒ½åŠ›çš„æœ‰æ•ˆè¯„ä¼°ã€‚ç°æœ‰benchmarké€šå¸¸é‡‡ç”¨å¼€ç¯åè®®ï¼Œæ— æ³•çœŸå®åæ˜ æ™ºèƒ½ä½“ä¸ç¯å¢ƒçš„äº¤äº’è¿‡ç¨‹ï¼Œéš¾ä»¥è¡¡é‡ä¸–ç•Œæ¨¡å‹å¯¹æ™ºèƒ½ä½“å†³ç­–çš„å®é™…å¸®åŠ©ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªåä¸ºWorld-in-Worldçš„é—­ç¯è¯„ä¼°å¹³å°ï¼Œè¯¥å¹³å°æ¨¡æ‹ŸçœŸå®çš„æ™ºèƒ½ä½“-ç¯å¢ƒäº¤äº’ï¼Œå…è®¸ç ”ç©¶äººå‘˜åœ¨ç»Ÿä¸€çš„ç¯å¢ƒä¸­æµ‹è¯•ä¸åŒçš„ä¸–ç•Œæ¨¡å‹ã€‚é€šè¿‡å…³æ³¨ä»»åŠ¡æˆåŠŸç‡è€Œéå•çº¯çš„è§†è§‰è´¨é‡ï¼Œæ›´å…¨é¢åœ°è¯„ä¼°ä¸–ç•Œæ¨¡å‹åœ¨å…·èº«ä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šWorld-in-Worldå¹³å°åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦ç»„æˆéƒ¨åˆ†ï¼š1) ä¸€ç³»åˆ—é—­ç¯ç¯å¢ƒï¼Œè¿™äº›ç¯å¢ƒè®¾è®¡ç”¨äºè¯„ä¼°ä¸åŒç±»å‹çš„ä¸–ç•Œæ¨¡å‹ï¼›2) ä¸€ä¸ªç»Ÿä¸€çš„åœ¨çº¿è§„åˆ’ç­–ç•¥ï¼Œç”¨äºæŒ‡å¯¼æ™ºèƒ½ä½“çš„è¡Œä¸ºï¼›3) ä¸€ä¸ªæ ‡å‡†åŒ–çš„åŠ¨ä½œAPIï¼Œå…è®¸ä¸åŒçš„ä¸–ç•Œæ¨¡å‹ä¸ç¯å¢ƒè¿›è¡Œäº¤äº’ã€‚ç ”ç©¶äººå‘˜å¯ä»¥ä½¿ç”¨è¯¥å¹³å°æ¥è®­ç»ƒå’Œè¯„ä¼°è‡ªå·±çš„ä¸–ç•Œæ¨¡å‹ï¼Œå¹¶ä¸å…¶ä»–æ¨¡å‹è¿›è¡Œæ¯”è¾ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥å¹³å°çš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶é—­ç¯è¯„ä¼°æ–¹æ³•ï¼Œå®ƒèƒ½å¤Ÿæ›´çœŸå®åœ°åæ˜ ä¸–ç•Œæ¨¡å‹åœ¨å…·èº«ä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œè¯¥å¹³å°è¿˜æä¾›äº†ä¸€ä¸ªæ ‡å‡†åŒ–çš„æ¥å£ï¼Œä½¿å¾—ç ”ç©¶äººå‘˜å¯ä»¥æ›´å®¹æ˜“åœ°æ¯”è¾ƒä¸åŒçš„ä¸–ç•Œæ¨¡å‹ã€‚é€šè¿‡æ•°æ®ç¼©æ”¾å®éªŒï¼Œæ­ç¤ºäº†åœ¨å…·èº«ç¯å¢ƒä¸­ï¼ŒåŠ¨ä½œ-è§‚å¯Ÿæ•°æ®å¯¹ä¸–ç•Œæ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚

**å…³é”®è®¾è®¡**ï¼šå¹³å°é‡‡ç”¨æ ‡å‡†åŒ–çš„åŠ¨ä½œAPIï¼Œå…è®¸ä¸åŒçš„ä¸–ç•Œæ¨¡å‹ä¸ç¯å¢ƒè¿›è¡Œäº¤äº’ã€‚ç»Ÿä¸€çš„åœ¨çº¿è§„åˆ’ç­–ç•¥ï¼Œä¾‹å¦‚CEMï¼ˆCross-Entropy Methodï¼‰ï¼Œç”¨äºæŒ‡å¯¼æ™ºèƒ½ä½“çš„è¡Œä¸ºã€‚å¹³å°è¿˜æä¾›äº†ä¸€ç³»åˆ—è¯„ä¼°æŒ‡æ ‡ï¼ŒåŒ…æ‹¬ä»»åŠ¡æˆåŠŸç‡ã€å¥–åŠ±å’Œè§†è§‰è´¨é‡ç­‰ã€‚æ•°æ®ç¼©æ”¾å®éªŒä¸­ï¼Œç ”ç©¶äººå‘˜ç³»ç»Ÿåœ°æ”¹å˜äº†è®­ç»ƒæ•°æ®çš„è§„æ¨¡ï¼Œå¹¶è§‚å¯Ÿäº†ä¸–ç•Œæ¨¡å‹æ€§èƒ½çš„å˜åŒ–ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè§†è§‰è´¨é‡ä¸ä»»åŠ¡æˆåŠŸç‡å¹¶éå®Œå…¨æ­£ç›¸å…³ï¼Œå¯æ§æ€§æ›´ä¸ºé‡è¦ã€‚é€šè¿‡åŠ¨ä½œ-è§‚å¯Ÿæ•°æ®è¿›è¡Œåè®­ç»ƒæ¯”å•çº¯æå‡é¢„è®­ç»ƒè§†é¢‘ç”Ÿæˆå™¨çš„æ€§èƒ½æ›´æœ‰æ•ˆã€‚æ­¤å¤–ï¼Œå¢åŠ æ¨ç†æ—¶é—´è®¡ç®—å¯ä»¥æ˜¾è‘—æå‡é—­ç¯æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨ç‰¹å®šç¯å¢ƒä¸­ï¼Œå¢åŠ æ¨ç†è®¡ç®—é‡åï¼Œä»»åŠ¡æˆåŠŸç‡æå‡äº†X%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ã€æ¸¸æˆAIç­‰é¢†åŸŸã€‚é€šè¿‡æ›´æœ‰æ•ˆåœ°è¯„ä¼°å’Œæ”¹è¿›ä¸–ç•Œæ¨¡å‹ï¼Œå¯ä»¥æå‡æ™ºèƒ½ä½“åœ¨å¤æ‚ç¯å¢ƒä¸­çš„å†³ç­–èƒ½åŠ›å’Œé€‚åº”æ€§ï¼Œä»è€Œå®ç°æ›´æ™ºèƒ½ã€æ›´å¯é çš„è‡ªåŠ¨åŒ–ç³»ç»Ÿã€‚è¯¥å¹³å°ä¸ºæœªæ¥ä¸–ç•Œæ¨¡å‹åœ¨å…·èº«æ™ºèƒ½ä½“ä¸­çš„åº”ç”¨å¥ å®šäº†åŸºç¡€ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Generative world models (WMs) can now simulate worlds with striking visual realism, which naturally raises the question of whether they can endow embodied agents with predictive perception for decision making. Progress on this question has been limited by fragmented evaluation: most existing benchmarks adopt open-loop protocols that emphasize visual quality in isolation, leaving the core issue of embodied utility unresolved, i.e., do WMs actually help agents succeed at embodied tasks? To address this gap, we introduce World-in-World, the first open platform that benchmarks WMs in a closed-loop world that mirrors real agent-environment interactions. World-in-World provides a unified online planning strategy and a standardized action API, enabling heterogeneous WMs for decision making. We curate four closed-loop environments that rigorously evaluate diverse WMs, prioritize task success as the primary metric, and move beyond the common focus on visual quality; we also present the first data scaling law for world models in embodied settings. Our study uncovers three surprises: (1) visual quality alone does not guarantee task success, controllability matters more; (2) scaling post-training with action-observation data is more effective than upgrading the pretrained video generators; and (3) allocating more inference-time compute allows WMs to substantially improve closed-loop performance.

