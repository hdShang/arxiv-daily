---
layout: default
title: Towards a Generalizable Fusion Architecture for Multimodal Object Detection
---

# Towards a Generalizable Fusion Architecture for Multimodal Object Detection

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.17078" target="_blank" class="toolbar-btn">arXiv: 2510.17078v1</a>
    <a href="https://arxiv.org/pdf/2510.17078.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.17078v1" 
            onclick="toggleFavorite(this, '2510.17078v1', 'Towards a Generalizable Fusion Architecture for Multimodal Object Detection')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Jad Berjawi, Yoann Dupas, Christophe C'erin

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-20

**Â§áÊ≥®**: 8 pages, 8 figures, accepted at ICCV 2025 MIRA Workshop

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫FMCAFÊû∂ÊûÑÔºåÊèêÂçáÂ§öÊ®°ÊÄÅÁõÆÊ†áÊ£ÄÊµãÁöÑÊ≥õÂåñËÉΩÂäõ‰∏éÈ≤ÅÊ£íÊÄß**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅËûçÂêà` `ÁõÆÊ†áÊ£ÄÊµã` `‰∫§ÂèâÊ≥®ÊÑèÂäõ` `È¢ëÂüüÊª§Ê≥¢` `Á∫¢Â§ñÂõæÂÉè` `RGBÂõæÂÉè` `Ê≥õÂåñËÉΩÂäõ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®Â§öÊ®°ÊÄÅÁõÆÊ†áÊ£ÄÊµã‰∏≠Ê≥õÂåñÊÄß‰∏çË∂≥Ôºå‰æùËµñÁâπÂÆöÊï∞ÊçÆÈõÜË∞É‰ºòÔºåÈôêÂà∂‰∫ÜÂÖ∂Âú®‰∏çÂêåÂú∫ÊôØ‰∏ãÁöÑÂ∫îÁî®„ÄÇ
2. FMCAFÈÄöËøáÈ¢ëÂüüÊª§Ê≥¢ÊäëÂà∂ÂÜó‰ΩôÁâπÂæÅÔºåÂπ∂Âà©Áî®‰∫§ÂèâÊ≥®ÊÑèÂäõÊú∫Âà∂‰øÉËøõÊ®°ÊÄÅÈó¥‰ø°ÊÅØ‰∫§‰∫íÔºåÊèêÂçáËûçÂêàÊïàÊûú„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåFMCAFÂú®LLVIPÂíåVEDAIÊï∞ÊçÆÈõÜ‰∏äÂùá‰ºò‰∫é‰º†ÁªüËûçÂêàÊñπÊ≥ïÔºåÈ™åËØÅ‰∫ÜÂÖ∂Ê≥õÂåñÊÄßÂíåÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫ËøáÊª§Â§öÊ®°ÊÄÅ‰∫§ÂèâÊ≥®ÊÑèÂäõËûçÂêà(FMCAF)ÁöÑÈ¢ÑÂ§ÑÁêÜÊû∂ÊûÑÔºåÊó®Âú®Â¢ûÂº∫RGBÂíåÁ∫¢Â§ñ(IR)ÂõæÂÉèËûçÂêàÁöÑÂ§öÊ®°ÊÄÅÁõÆÊ†áÊ£ÄÊµãÊÄßËÉΩ„ÄÇFMCAFÁªìÂêà‰∫ÜÈ¢ëÂüüÊª§Ê≥¢Ê®°Âùó(Freq-Filter)Êù•ÊäëÂà∂ÂÜó‰ΩôÈ¢ëË∞±ÁâπÂæÅÔºå‰ª•ÂèäÂü∫‰∫é‰∫§ÂèâÊ≥®ÊÑèÂäõÁöÑËûçÂêàÊ®°Âùó(MCAF)Êù•ÊîπÂñÑÊ®°ÊÄÅÈó¥ÁâπÂæÅÂÖ±‰∫´„ÄÇ‰∏éÈíàÂØπÁâπÂÆöÊï∞ÊçÆÈõÜÁöÑÊñπÊ≥ï‰∏çÂêåÔºåFMCAFËá¥Âäõ‰∫éÊèêÈ´òÊ≥õÂåñËÉΩÂäõÔºåÂú®‰∏çÂêåÁöÑÂ§öÊ®°ÊÄÅÊåëÊàò‰∏≠ÊèêÂçáÊÄßËÉΩÔºåËÄåÊó†ÈúÄÈíàÂØπÁâπÂÆöÊï∞ÊçÆÈõÜËøõË°åË∞ÉÊï¥„ÄÇÂú®LLVIP(‰ΩéÂÖâË°å‰∫∫Ê£ÄÊµã)ÂíåVEDAI(Ëà™Á©∫ËΩ¶ËæÜÊ£ÄÊµã)Êï∞ÊçÆÈõÜ‰∏äÔºåFMCAF‰ºò‰∫é‰º†ÁªüËûçÂêà(ÊãºÊé•)ÊñπÊ≥ïÔºåÂú®VEDAI‰∏äÂÆûÁé∞‰∫Ü+13.9%ÁöÑmAP@50ÔºåÂú®LLVIP‰∏äÂÆûÁé∞‰∫Ü+1.1%ÁöÑmAP@50„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéFMCAFÊúâÊΩúÂäõÊàê‰∏∫Êú™Êù•Ê£ÄÊµãÊµÅÁ®ã‰∏≠È≤ÅÊ£íÂ§öÊ®°ÊÄÅËûçÂêàÁöÑÁÅµÊ¥ªÂü∫Á°Ä„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÂ§öÊ®°ÊÄÅÁõÆÊ†áÊ£ÄÊµãÊó®Âú®Âà©Áî®Êù•Ëá™‰∏çÂêå‰º†ÊÑüÂô®ÔºàÂ¶ÇRGBÂíåÁ∫¢Â§ñÔºâÁöÑ‰∫íË°•‰ø°ÊÅØÔºåÊèêÈ´òÂú®Â§çÊùÇÁéØÂ¢É‰∏ãÁöÑÊ£ÄÊµãÊÄßËÉΩ„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÊñπÊ≥ïÂæÄÂæÄÈíàÂØπÁâπÂÆöÊï∞ÊçÆÈõÜËÆæËÆ°ÔºåÁº∫‰πèÊ≥õÂåñËÉΩÂäõÔºåÈúÄË¶ÅÂú®Êñ∞Êï∞ÊçÆÈõÜ‰∏äËøõË°åÂ§ßÈáèË∞É‰ºòÔºåÈôêÂà∂‰∫ÜÂÖ∂Â∫îÁî®ËåÉÂõ¥„ÄÇÂõ†Ê≠§ÔºåÂ¶Ç‰ΩïËÆæËÆ°‰∏ÄÁßçÈÄöÁî®ÁöÑÂ§öÊ®°ÊÄÅËûçÂêàÊû∂ÊûÑÔºå‰ΩøÂÖ∂ËÉΩÂ§üÂú®‰∏çÂêåÊï∞ÊçÆÈõÜ‰∏äÂèñÂæóËâØÂ•ΩÊÄßËÉΩÔºåÊòØ‰∏Ä‰∏™ÈáçË¶ÅÁöÑÁ†îÁ©∂ÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊú¨ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÈ¢ÑÂ§ÑÁêÜÊù•Â¢ûÂº∫Â§öÊ®°ÊÄÅÁâπÂæÅÁöÑËûçÂêàÊïàÊûú„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÈ¶ñÂÖàÂà©Áî®È¢ëÂüüÊª§Ê≥¢ÂéªÈô§ÂÜó‰ΩôÁöÑÈ¢ëË∞±ÁâπÂæÅÔºåÂáèÂ∞ëÊ®°ÊÄÅÈó¥ÁöÑÂπ≤Êâ∞ÔºõÁÑ∂ÂêéÔºåÂà©Áî®‰∫§ÂèâÊ≥®ÊÑèÂäõÊú∫Âà∂ÔºåÊòæÂºèÂú∞Âª∫Ê®°‰∏çÂêåÊ®°ÊÄÅ‰πãÈó¥ÁöÑ‰æùËµñÂÖ≥Á≥ªÔºå‰øÉËøõÁâπÂæÅÁöÑÊúâÊïàËûçÂêà„ÄÇËøôÁßçÊñπÊ≥ïÊó®Âú®ÊèêÈ´òÁâπÂæÅÁöÑË¥®ÈáèÂíåÁõ∏ÂÖ≥ÊÄßÔºå‰ªéËÄåÊèêÂçáÊ£ÄÊµãÂô®ÁöÑÊÄßËÉΩÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöFMCAFÊû∂ÊûÑ‰∏ªË¶ÅÂåÖÂê´‰∏§‰∏™Ê®°ÂùóÔºöÈ¢ëÂüüÊª§Ê≥¢Ê®°Âùó(Freq-Filter)Âíå‰∫§ÂèâÊ≥®ÊÑèÂäõËûçÂêàÊ®°Âùó(MCAF)„ÄÇÈ¶ñÂÖàÔºåRGBÂíåIRÂõæÂÉèÂàÜÂà´ÁªèËøáFreq-FilterÊ®°ÂùóÔºåËØ•Ê®°ÂùóÂ∞ÜÂõæÂÉèËΩ¨Êç¢Âà∞È¢ëÂüüÔºåÂπ∂ÂØπÁâπÂÆöÈ¢ëÁéáÁöÑÊàêÂàÜËøõË°åÊª§Ê≥¢Ôºå‰ª•ÂéªÈô§ÂÜó‰Ωô‰ø°ÊÅØ„ÄÇÁÑ∂ÂêéÔºåÊª§Ê≥¢ÂêéÁöÑÁâπÂæÅË¢´ËæìÂÖ•Âà∞MCAFÊ®°ÂùóÔºåËØ•Ê®°ÂùóÂà©Áî®‰∫§ÂèâÊ≥®ÊÑèÂäõÊú∫Âà∂ÔºåËÆ°ÁÆóRGBÂíåIRÁâπÂæÅ‰πãÈó¥ÁöÑÁõ∏ÂÖ≥ÊÄßÔºåÂπ∂Ê†πÊçÆÁõ∏ÂÖ≥ÊÄßÊùÉÈáçÂØπÁâπÂæÅËøõË°åËûçÂêà„ÄÇÊúÄÂêéÔºåËûçÂêàÂêéÁöÑÁâπÂæÅË¢´ËæìÂÖ•Âà∞ÁõÆÊ†áÊ£ÄÊµãÂô®‰∏≠ËøõË°åÁõÆÊ†áÊ£ÄÊµã„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊú¨ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫Ü‰∏Ä‰∏™ÈÄöÁî®ÁöÑÂ§öÊ®°ÊÄÅËûçÂêàÊû∂ÊûÑFMCAFÔºåËØ•Êû∂ÊûÑ‰∏ç‰æùËµñ‰∫éÁâπÂÆöÊï∞ÊçÆÈõÜÁöÑË∞É‰ºòÔºåËÉΩÂ§üÂú®‰∏çÂêåÁöÑÂ§öÊ®°ÊÄÅÁõÆÊ†áÊ£ÄÊµã‰ªªÂä°‰∏≠ÂèñÂæóËâØÂ•ΩÁöÑÊÄßËÉΩ„ÄÇ‰∏é‰º†ÁªüÁöÑÊãºÊé•ËûçÂêàÊñπÊ≥ïÁõ∏ÊØîÔºåFMCAFËÉΩÂ§üÊõ¥Â•ΩÂú∞Âà©Áî®‰∏çÂêåÊ®°ÊÄÅ‰πãÈó¥ÁöÑ‰∫íË°•‰ø°ÊÅØÔºåÂπ∂ÊäëÂà∂ÂÜó‰Ωô‰ø°ÊÅØÔºå‰ªéËÄåÊèêÈ´òÊ£ÄÊµãÂô®ÁöÑÈ≤ÅÊ£íÊÄßÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöFreq-FilterÊ®°Âùó‰ΩøÁî®Á¶ªÊï£‰ΩôÂº¶ÂèòÊç¢(DCT)Â∞ÜÂõæÂÉèËΩ¨Êç¢Âà∞È¢ëÂüüÔºåÂπ∂Ê†πÊçÆÁªèÈ™åÈÄâÊã©ÂêàÈÄÇÁöÑÈ¢ëÁéáËåÉÂõ¥ËøõË°åÊª§Ê≥¢„ÄÇMCAFÊ®°Âùó‰ΩøÁî®Â§öÂ§¥Ê≥®ÊÑèÂäõÊú∫Âà∂Ôºå‰ª•ÊçïÊçâ‰∏çÂêåÊ®°ÊÄÅ‰πãÈó¥ÁöÑÂ§çÊùÇÂÖ≥Á≥ª„ÄÇÊçüÂ§±ÂáΩÊï∞ÈááÁî®Ê†áÂáÜÁöÑ‰∫§ÂèâÁÜµÊçüÂ§±ÂáΩÊï∞ÂíåËæπÁïåÊ°ÜÂõûÂΩíÊçüÂ§±ÂáΩÊï∞„ÄÇÁΩëÁªúÁªìÊûÑÂü∫‰∫éÂ∏∏Áî®ÁöÑÁõÆÊ†áÊ£ÄÊµãÊ°ÜÊû∂ÔºåÂ¶ÇFaster R-CNNÊàñYOLO„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

FMCAFÂú®VEDAIÊï∞ÊçÆÈõÜ‰∏äÂÆûÁé∞‰∫Ü+13.9%ÁöÑmAP@50ÊèêÂçáÔºåÂú®LLVIPÊï∞ÊçÆÈõÜ‰∏äÂÆûÁé∞‰∫Ü+1.1%ÁöÑmAP@50ÊèêÂçáÔºåÊòæËëó‰ºò‰∫é‰º†ÁªüÁöÑÊãºÊé•ËûçÂêàÊñπÊ≥ï„ÄÇËøôË°®ÊòéFMCAFËÉΩÂ§üÊúâÊïàÂú∞Âà©Áî®Â§öÊ®°ÊÄÅ‰ø°ÊÅØÔºåÊèêÈ´òÁõÆÊ†áÊ£ÄÊµãÁöÑÊÄßËÉΩÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇÂ∞§ÂÖ∂Âú®VEDAIÊï∞ÊçÆÈõÜ‰∏äÂ§ßÂπÖÊèêÂçáÔºåËØÅÊòé‰∫ÜËØ•ÊñπÊ≥ïÂú®Â§çÊùÇÂú∫ÊôØ‰∏ãÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éËá™Âä®È©æÈ©∂„ÄÅÂÆâÈò≤ÁõëÊéß„ÄÅÊú∫Âô®‰∫∫Á≠âÈ¢ÜÂüü„ÄÇÂú®Ëá™Âä®È©æÈ©∂‰∏≠ÔºåÂèØ‰ª•Âà©Áî®RGBÂíåÁ∫¢Â§ñÂõæÂÉèËûçÂêàÔºåÊèêÈ´òÂú®Â§úÈó¥ÊàñÊÅ∂Âä£Â§©Ê∞îÊù°‰ª∂‰∏ãÁöÑÁõÆÊ†áÊ£ÄÊµãËÉΩÂäõ„ÄÇÂú®ÂÆâÈò≤ÁõëÊéß‰∏≠ÔºåÂèØ‰ª•Âà©Áî®ÂèØËßÅÂÖâÂíåÁÉ≠ÊàêÂÉèËûçÂêàÔºåÊèêÈ´òÂØπÂºÇÂ∏∏Ë°å‰∏∫ÁöÑÊ£ÄÊµãËÉΩÂäõ„ÄÇÂú®Êú∫Âô®‰∫∫È¢ÜÂüüÔºåÂèØ‰ª•Âà©Áî®Â§öÁßç‰º†ÊÑüÂô®Êï∞ÊçÆËûçÂêàÔºåÊèêÈ´òÊú∫Âô®‰∫∫ÂØπÁéØÂ¢ÉÁöÑÊÑüÁü•ËÉΩÂäõ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Multimodal object detection improves robustness in chal- lenging conditions by leveraging complementary cues from multiple sensor modalities. We introduce Filtered Multi- Modal Cross Attention Fusion (FMCAF), a preprocess- ing architecture designed to enhance the fusion of RGB and infrared (IR) inputs. FMCAF combines a frequency- domain filtering block (Freq-Filter) to suppress redun- dant spectral features with a cross-attention-based fusion module (MCAF) to improve intermodal feature sharing. Unlike approaches tailored to specific datasets, FMCAF aims for generalizability, improving performance across different multimodal challenges without requiring dataset- specific tuning. On LLVIP (low-light pedestrian detec- tion) and VEDAI (aerial vehicle detection), FMCAF outper- forms traditional fusion (concatenation), achieving +13.9% mAP@50 on VEDAI and +1.1% on LLVIP. These results support the potential of FMCAF as a flexible foundation for robust multimodal fusion in future detection pipelines.

