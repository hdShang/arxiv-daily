---
layout: default
title: Towards a Generalizable Fusion Architecture for Multimodal Object Detection
---

# Towards a Generalizable Fusion Architecture for Multimodal Object Detection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.17078" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.17078v1</a>
  <a href="https://arxiv.org/pdf/2510.17078.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.17078v1" onclick="toggleFavorite(this, '2510.17078v1', 'Towards a Generalizable Fusion Architecture for Multimodal Object Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jad Berjawi, Yoann Dupas, Christophe C'erin

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-20

**å¤‡æ³¨**: 8 pages, 8 figures, accepted at ICCV 2025 MIRA Workshop

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFMCAFæ¶æ„ï¼Œæå‡å¤šæ¨¡æ€ç›®æ ‡æ£€æµ‹çš„æ³›åŒ–èƒ½åŠ›ä¸é²æ£’æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€èåˆ` `ç›®æ ‡æ£€æµ‹` `äº¤å‰æ³¨æ„åŠ›` `é¢‘åŸŸæ»¤æ³¢` `çº¢å¤–å›¾åƒ` `RGBå›¾åƒ` `æ³›åŒ–èƒ½åŠ›`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤šæ¨¡æ€ç›®æ ‡æ£€æµ‹ä¸­æ³›åŒ–æ€§ä¸è¶³ï¼Œä¾èµ–ç‰¹å®šæ•°æ®é›†è°ƒä¼˜ï¼Œé™åˆ¶äº†å…¶åœ¨ä¸åŒåœºæ™¯ä¸‹çš„åº”ç”¨ã€‚
2. FMCAFé€šè¿‡é¢‘åŸŸæ»¤æ³¢æŠ‘åˆ¶å†—ä½™ç‰¹å¾ï¼Œå¹¶åˆ©ç”¨äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ä¿ƒè¿›æ¨¡æ€é—´ä¿¡æ¯äº¤äº’ï¼Œæå‡èåˆæ•ˆæœã€‚
3. å®éªŒè¡¨æ˜ï¼ŒFMCAFåœ¨LLVIPå’ŒVEDAIæ•°æ®é›†ä¸Šå‡ä¼˜äºä¼ ç»Ÿèåˆæ–¹æ³•ï¼ŒéªŒè¯äº†å…¶æ³›åŒ–æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºè¿‡æ»¤å¤šæ¨¡æ€äº¤å‰æ³¨æ„åŠ›èåˆ(FMCAF)çš„é¢„å¤„ç†æ¶æ„ï¼Œæ—¨åœ¨å¢å¼ºRGBå’Œçº¢å¤–(IR)å›¾åƒèåˆçš„å¤šæ¨¡æ€ç›®æ ‡æ£€æµ‹æ€§èƒ½ã€‚FMCAFç»“åˆäº†é¢‘åŸŸæ»¤æ³¢æ¨¡å—(Freq-Filter)æ¥æŠ‘åˆ¶å†—ä½™é¢‘è°±ç‰¹å¾ï¼Œä»¥åŠåŸºäºäº¤å‰æ³¨æ„åŠ›çš„èåˆæ¨¡å—(MCAF)æ¥æ”¹å–„æ¨¡æ€é—´ç‰¹å¾å…±äº«ã€‚ä¸é’ˆå¯¹ç‰¹å®šæ•°æ®é›†çš„æ–¹æ³•ä¸åŒï¼ŒFMCAFè‡´åŠ›äºæé«˜æ³›åŒ–èƒ½åŠ›ï¼Œåœ¨ä¸åŒçš„å¤šæ¨¡æ€æŒ‘æˆ˜ä¸­æå‡æ€§èƒ½ï¼Œè€Œæ— éœ€é’ˆå¯¹ç‰¹å®šæ•°æ®é›†è¿›è¡Œè°ƒæ•´ã€‚åœ¨LLVIP(ä½å…‰è¡Œäººæ£€æµ‹)å’ŒVEDAI(èˆªç©ºè½¦è¾†æ£€æµ‹)æ•°æ®é›†ä¸Šï¼ŒFMCAFä¼˜äºä¼ ç»Ÿèåˆ(æ‹¼æ¥)æ–¹æ³•ï¼Œåœ¨VEDAIä¸Šå®ç°äº†+13.9%çš„mAP@50ï¼Œåœ¨LLVIPä¸Šå®ç°äº†+1.1%çš„mAP@50ã€‚è¿™äº›ç»“æœè¡¨æ˜FMCAFæœ‰æ½œåŠ›æˆä¸ºæœªæ¥æ£€æµ‹æµç¨‹ä¸­é²æ£’å¤šæ¨¡æ€èåˆçš„çµæ´»åŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå¤šæ¨¡æ€ç›®æ ‡æ£€æµ‹æ—¨åœ¨åˆ©ç”¨æ¥è‡ªä¸åŒä¼ æ„Ÿå™¨ï¼ˆå¦‚RGBå’Œçº¢å¤–ï¼‰çš„äº’è¡¥ä¿¡æ¯ï¼Œæé«˜åœ¨å¤æ‚ç¯å¢ƒä¸‹çš„æ£€æµ‹æ€§èƒ½ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å¾€å¾€é’ˆå¯¹ç‰¹å®šæ•°æ®é›†è®¾è®¡ï¼Œç¼ºä¹æ³›åŒ–èƒ½åŠ›ï¼Œéœ€è¦åœ¨æ–°æ•°æ®é›†ä¸Šè¿›è¡Œå¤§é‡è°ƒä¼˜ï¼Œé™åˆ¶äº†å…¶åº”ç”¨èŒƒå›´ã€‚å› æ­¤ï¼Œå¦‚ä½•è®¾è®¡ä¸€ç§é€šç”¨çš„å¤šæ¨¡æ€èåˆæ¶æ„ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨ä¸åŒæ•°æ®é›†ä¸Šå–å¾—è‰¯å¥½æ€§èƒ½ï¼Œæ˜¯ä¸€ä¸ªé‡è¦çš„ç ”ç©¶é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡é¢„å¤„ç†æ¥å¢å¼ºå¤šæ¨¡æ€ç‰¹å¾çš„èåˆæ•ˆæœã€‚å…·ä½“æ¥è¯´ï¼Œé¦–å…ˆåˆ©ç”¨é¢‘åŸŸæ»¤æ³¢å»é™¤å†—ä½™çš„é¢‘è°±ç‰¹å¾ï¼Œå‡å°‘æ¨¡æ€é—´çš„å¹²æ‰°ï¼›ç„¶åï¼Œåˆ©ç”¨äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ˜¾å¼åœ°å»ºæ¨¡ä¸åŒæ¨¡æ€ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼Œä¿ƒè¿›ç‰¹å¾çš„æœ‰æ•ˆèåˆã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨æé«˜ç‰¹å¾çš„è´¨é‡å’Œç›¸å…³æ€§ï¼Œä»è€Œæå‡æ£€æµ‹å™¨çš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFMCAFæ¶æ„ä¸»è¦åŒ…å«ä¸¤ä¸ªæ¨¡å—ï¼šé¢‘åŸŸæ»¤æ³¢æ¨¡å—(Freq-Filter)å’Œäº¤å‰æ³¨æ„åŠ›èåˆæ¨¡å—(MCAF)ã€‚é¦–å…ˆï¼ŒRGBå’ŒIRå›¾åƒåˆ†åˆ«ç»è¿‡Freq-Filteræ¨¡å—ï¼Œè¯¥æ¨¡å—å°†å›¾åƒè½¬æ¢åˆ°é¢‘åŸŸï¼Œå¹¶å¯¹ç‰¹å®šé¢‘ç‡çš„æˆåˆ†è¿›è¡Œæ»¤æ³¢ï¼Œä»¥å»é™¤å†—ä½™ä¿¡æ¯ã€‚ç„¶åï¼Œæ»¤æ³¢åçš„ç‰¹å¾è¢«è¾“å…¥åˆ°MCAFæ¨¡å—ï¼Œè¯¥æ¨¡å—åˆ©ç”¨äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œè®¡ç®—RGBå’ŒIRç‰¹å¾ä¹‹é—´çš„ç›¸å…³æ€§ï¼Œå¹¶æ ¹æ®ç›¸å…³æ€§æƒé‡å¯¹ç‰¹å¾è¿›è¡Œèåˆã€‚æœ€åï¼Œèåˆåçš„ç‰¹å¾è¢«è¾“å…¥åˆ°ç›®æ ‡æ£€æµ‹å™¨ä¸­è¿›è¡Œç›®æ ‡æ£€æµ‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ä¸ªé€šç”¨çš„å¤šæ¨¡æ€èåˆæ¶æ„FMCAFï¼Œè¯¥æ¶æ„ä¸ä¾èµ–äºç‰¹å®šæ•°æ®é›†çš„è°ƒä¼˜ï¼Œèƒ½å¤Ÿåœ¨ä¸åŒçš„å¤šæ¨¡æ€ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸­å–å¾—è‰¯å¥½çš„æ€§èƒ½ã€‚ä¸ä¼ ç»Ÿçš„æ‹¼æ¥èåˆæ–¹æ³•ç›¸æ¯”ï¼ŒFMCAFèƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨ä¸åŒæ¨¡æ€ä¹‹é—´çš„äº’è¡¥ä¿¡æ¯ï¼Œå¹¶æŠ‘åˆ¶å†—ä½™ä¿¡æ¯ï¼Œä»è€Œæé«˜æ£€æµ‹å™¨çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šFreq-Filteræ¨¡å—ä½¿ç”¨ç¦»æ•£ä½™å¼¦å˜æ¢(DCT)å°†å›¾åƒè½¬æ¢åˆ°é¢‘åŸŸï¼Œå¹¶æ ¹æ®ç»éªŒé€‰æ‹©åˆé€‚çš„é¢‘ç‡èŒƒå›´è¿›è¡Œæ»¤æ³¢ã€‚MCAFæ¨¡å—ä½¿ç”¨å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼Œä»¥æ•æ‰ä¸åŒæ¨¡æ€ä¹‹é—´çš„å¤æ‚å…³ç³»ã€‚æŸå¤±å‡½æ•°é‡‡ç”¨æ ‡å‡†çš„äº¤å‰ç†µæŸå¤±å‡½æ•°å’Œè¾¹ç•Œæ¡†å›å½’æŸå¤±å‡½æ•°ã€‚ç½‘ç»œç»“æ„åŸºäºå¸¸ç”¨çš„ç›®æ ‡æ£€æµ‹æ¡†æ¶ï¼Œå¦‚Faster R-CNNæˆ–YOLOã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

FMCAFåœ¨VEDAIæ•°æ®é›†ä¸Šå®ç°äº†+13.9%çš„mAP@50æå‡ï¼Œåœ¨LLVIPæ•°æ®é›†ä¸Šå®ç°äº†+1.1%çš„mAP@50æå‡ï¼Œæ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„æ‹¼æ¥èåˆæ–¹æ³•ã€‚è¿™è¡¨æ˜FMCAFèƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨å¤šæ¨¡æ€ä¿¡æ¯ï¼Œæé«˜ç›®æ ‡æ£€æµ‹çš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚å°¤å…¶åœ¨VEDAIæ•°æ®é›†ä¸Šå¤§å¹…æå‡ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•åœ¨å¤æ‚åœºæ™¯ä¸‹çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ã€å®‰é˜²ç›‘æ§ã€æœºå™¨äººç­‰é¢†åŸŸã€‚åœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼Œå¯ä»¥åˆ©ç”¨RGBå’Œçº¢å¤–å›¾åƒèåˆï¼Œæé«˜åœ¨å¤œé—´æˆ–æ¶åŠ£å¤©æ°”æ¡ä»¶ä¸‹çš„ç›®æ ‡æ£€æµ‹èƒ½åŠ›ã€‚åœ¨å®‰é˜²ç›‘æ§ä¸­ï¼Œå¯ä»¥åˆ©ç”¨å¯è§å…‰å’Œçƒ­æˆåƒèåˆï¼Œæé«˜å¯¹å¼‚å¸¸è¡Œä¸ºçš„æ£€æµ‹èƒ½åŠ›ã€‚åœ¨æœºå™¨äººé¢†åŸŸï¼Œå¯ä»¥åˆ©ç”¨å¤šç§ä¼ æ„Ÿå™¨æ•°æ®èåˆï¼Œæé«˜æœºå™¨äººå¯¹ç¯å¢ƒçš„æ„ŸçŸ¥èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal object detection improves robustness in chal- lenging conditions by leveraging complementary cues from multiple sensor modalities. We introduce Filtered Multi- Modal Cross Attention Fusion (FMCAF), a preprocess- ing architecture designed to enhance the fusion of RGB and infrared (IR) inputs. FMCAF combines a frequency- domain filtering block (Freq-Filter) to suppress redun- dant spectral features with a cross-attention-based fusion module (MCAF) to improve intermodal feature sharing. Unlike approaches tailored to specific datasets, FMCAF aims for generalizability, improving performance across different multimodal challenges without requiring dataset- specific tuning. On LLVIP (low-light pedestrian detec- tion) and VEDAI (aerial vehicle detection), FMCAF outper- forms traditional fusion (concatenation), achieving +13.9% mAP@50 on VEDAI and +1.1% on LLVIP. These results support the potential of FMCAF as a flexible foundation for robust multimodal fusion in future detection pipelines.

