---
layout: default
title: MUG-V 10B: High-efficiency Training Pipeline for Large Video Generation Models
---

# MUG-V 10B: High-efficiency Training Pipeline for Large Video Generation Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.17519" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.17519v2</a>
  <a href="https://arxiv.org/pdf/2510.17519.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.17519v2" onclick="toggleFavorite(this, '2510.17519v2', 'MUG-V 10B: High-efficiency Training Pipeline for Large Video Generation Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yongshun Zhang, Zhongyi Fan, Yonghang Zhang, Zhangzikang Li, Weifeng Chen, Zhongwei Feng, Chaoyue Wang, Peng Hou, Anxiang Zeng

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-10-20 (æ›´æ–°: 2025-10-22)

**å¤‡æ³¨**: Technical Report; Project Page: https://github.com/Shopee-MUG/MUG-V

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Shopee-MUG/MUG-V)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**MUG-V 10Bï¼šé¢å‘å¤§è§„æ¨¡è§†é¢‘ç”Ÿæˆæ¨¡å‹çš„é«˜æ•ˆè®­ç»ƒæ¡†æ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `è§†é¢‘ç”Ÿæˆ` `å¤§è§„æ¨¡æ¨¡å‹` `é«˜æ•ˆè®­ç»ƒ` `Megatron-Core` `ç”µå•†è§†é¢‘` `è·¨æ¨¡æ€å­¦ä¹ ` `æ¨¡å‹å¼€æº`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤§è§„æ¨¡è§†é¢‘ç”Ÿæˆæ¨¡å‹è®­ç»ƒé¢ä¸´è·¨æ¨¡æ€å¯¹é½ã€é•¿åºåˆ—ä¾èµ–å’Œæ—¶ç©ºå¤æ‚åº¦ç­‰æŒ‘æˆ˜ï¼Œå¯¼è‡´èµ„æºæ¶ˆè€—å·¨å¤§ã€‚
2. è®ºæ–‡æå‡ºä¸€ä¸ªå››æ”¯æŸ±ä¼˜åŒ–çš„è®­ç»ƒæ¡†æ¶ï¼Œæ¶µç›–æ•°æ®å¤„ç†ã€æ¨¡å‹æ¶æ„ã€è®­ç»ƒç­–ç•¥å’ŒåŸºç¡€è®¾æ–½ï¼Œæå‡è®­ç»ƒæ•ˆç‡ã€‚
3. MUG-V 10Bæ¨¡å‹åœ¨ç”µå•†è§†é¢‘ç”Ÿæˆä»»åŠ¡ä¸Šè¶…è¶Šäº†å¼€æºåŸºçº¿ï¼Œå¹¶å¼€æºäº†æ¨¡å‹æƒé‡å’Œè®­ç»ƒä»£ç ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œè§†è§‰å†…å®¹ç”Ÿæˆæ¨¡å‹ï¼ˆå¦‚å›¾åƒã€è§†é¢‘å’Œ3Då¯¹è±¡/åœºæ™¯ï¼‰å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œç”±äºè·¨æ¨¡æ€æ–‡æœ¬-è§†é¢‘å¯¹é½ã€é•¿åºåˆ—å¤„ç†ä»¥åŠå¤æ‚çš„æ—¶ç©ºä¾èµ–å…³ç³»ï¼Œå¤§è§„æ¨¡è§†é¢‘ç”Ÿæˆæ¨¡å‹çš„è®­ç»ƒä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ä¸”èµ„æºå¯†é›†ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªè®­ç»ƒæ¡†æ¶ï¼Œè¯¥æ¡†æ¶ä¼˜åŒ–äº†å››ä¸ªå…³é”®æ–¹é¢ï¼šï¼ˆiï¼‰æ•°æ®å¤„ç†ï¼Œï¼ˆiiï¼‰æ¨¡å‹æ¶æ„ï¼Œï¼ˆiiiï¼‰è®­ç»ƒç­–ç•¥ï¼Œä»¥åŠï¼ˆivï¼‰å¤§è§„æ¨¡è§†é¢‘ç”Ÿæˆæ¨¡å‹çš„åŸºç¡€è®¾æ–½ã€‚è¿™äº›ä¼˜åŒ–åœ¨æ•°æ®é¢„å¤„ç†ã€è§†é¢‘å‹ç¼©ã€å‚æ•°ç¼©æ”¾ã€åŸºäºè¯¾ç¨‹çš„é¢„è®­ç»ƒå’Œä»¥å¯¹é½ä¸ºä¸­å¿ƒçš„åè®­ç»ƒç­‰å„ä¸ªé˜¶æ®µéƒ½å¸¦æ¥äº†æ˜¾è‘—çš„æ•ˆç‡æå‡å’Œæ€§èƒ½æ”¹è¿›ã€‚æˆ‘ä»¬æœ€ç»ˆçš„æ¨¡å‹MUG-V 10Båœ¨æ•´ä½“ä¸Šä¸æœ€æ–°çš„è§†é¢‘ç”Ÿæˆå™¨ç›¸åŒ¹é…ï¼Œå¹¶ä¸”åœ¨é¢å‘ç”µå•†çš„è§†é¢‘ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œåœ¨äººå·¥è¯„ä¼°ä¸­è¶…è¿‡äº†é¢†å…ˆçš„å¼€æºåŸºçº¿ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬å¼€æºäº†å®Œæ•´çš„æŠ€æœ¯æ ˆï¼ŒåŒ…æ‹¬æ¨¡å‹æƒé‡ã€åŸºäºMegatron-Coreçš„å¤§è§„æ¨¡è®­ç»ƒä»£ç ä»¥åŠç”¨äºè§†é¢‘ç”Ÿæˆå’Œå¢å¼ºçš„æ¨ç†ç®¡é“ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå…¬å¼€å‘å¸ƒçš„å¤§è§„æ¨¡è§†é¢‘ç”Ÿæˆè®­ç»ƒä»£ç ï¼Œå®ƒåˆ©ç”¨Megatron-Coreæ¥å®ç°é«˜è®­ç»ƒæ•ˆç‡å’Œè¿‘ä¹çº¿æ€§çš„å¤šèŠ‚ç‚¹æ‰©å±•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå¤§è§„æ¨¡è§†é¢‘ç”Ÿæˆæ¨¡å‹è®­ç»ƒé¢ä¸´ç€æ•°æ®å¤„ç†ã€æ¨¡å‹æ¶æ„ã€è®­ç»ƒç­–ç•¥å’ŒåŸºç¡€è®¾æ–½ç­‰å¤šæ–¹é¢çš„æŒ‘æˆ˜ã€‚ç°æœ‰çš„æ–¹æ³•åœ¨å¤„ç†é•¿åºåˆ—è§†é¢‘ã€è·¨æ¨¡æ€å¯¹é½ä»¥åŠé«˜æ•ˆåˆ©ç”¨è®¡ç®—èµ„æºæ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´è®­ç»ƒæˆæœ¬é«˜æ˜‚ï¼Œæ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¯¹æ•°æ®å¤„ç†ã€æ¨¡å‹æ¶æ„ã€è®­ç»ƒç­–ç•¥å’ŒåŸºç¡€è®¾æ–½è¿›è¡Œå…¨é¢ä¼˜åŒ–ï¼Œä»è€Œæé«˜å¤§è§„æ¨¡è§†é¢‘ç”Ÿæˆæ¨¡å‹çš„è®­ç»ƒæ•ˆç‡ã€‚è¿™ç§å¤šæ–¹é¢çš„ä¼˜åŒ–ç­–ç•¥æ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•åœ¨å¤„ç†é•¿åºåˆ—ã€è·¨æ¨¡æ€å¯¹é½å’Œèµ„æºåˆ©ç”¨æ–¹é¢çš„ç“¶é¢ˆã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«æ•°æ®é¢„å¤„ç†ã€è§†é¢‘å‹ç¼©ã€æ¨¡å‹æ¶æ„è®¾è®¡ã€è®­ç»ƒç­–ç•¥å’ŒåŸºç¡€è®¾æ–½ä¼˜åŒ–ç­‰å¤šä¸ªé˜¶æ®µã€‚æ•°æ®é¢„å¤„ç†é˜¶æ®µè´Ÿè´£æ¸…æ´—å’Œå‡†å¤‡è®­ç»ƒæ•°æ®ï¼›è§†é¢‘å‹ç¼©é˜¶æ®µæ—¨åœ¨å‡å°‘è§†é¢‘æ•°æ®çš„å­˜å‚¨å’Œè®¡ç®—å¼€é”€ï¼›æ¨¡å‹æ¶æ„è®¾è®¡é˜¶æ®µå…³æ³¨å¦‚ä½•æ„å»ºèƒ½å¤Ÿæœ‰æ•ˆæ•æ‰æ—¶ç©ºä¾èµ–å…³ç³»çš„æ¨¡å‹ï¼›è®­ç»ƒç­–ç•¥é˜¶æ®µåˆ™ä¾§é‡äºå¦‚ä½•é€šè¿‡è¯¾ç¨‹å­¦ä¹ ç­‰æ–¹æ³•æé«˜è®­ç»ƒæ•ˆç‡ï¼›åŸºç¡€è®¾æ–½ä¼˜åŒ–é˜¶æ®µåˆ™å…³æ³¨å¦‚ä½•åˆ©ç”¨åˆ†å¸ƒå¼è®¡ç®—èµ„æºåŠ é€Ÿè®­ç»ƒè¿‡ç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ä¸ªç»¼åˆæ€§çš„è®­ç»ƒæ¡†æ¶ï¼Œè¯¥æ¡†æ¶ä¸ä»…å…³æ³¨æ¨¡å‹æ¶æ„æœ¬èº«ï¼Œè¿˜å…³æ³¨æ•°æ®å¤„ç†ã€è®­ç»ƒç­–ç•¥å’ŒåŸºç¡€è®¾æ–½ç­‰å¤šä¸ªæ–¹é¢ã€‚é€šè¿‡å¯¹è¿™äº›æ–¹é¢è¿›è¡ŒååŒä¼˜åŒ–ï¼Œå¯ä»¥æ˜¾è‘—æé«˜å¤§è§„æ¨¡è§†é¢‘ç”Ÿæˆæ¨¡å‹çš„è®­ç»ƒæ•ˆç‡ã€‚æ­¤å¤–ï¼Œå¼€æºæ¨¡å‹å’Œè®­ç»ƒä»£ç ä¹ŸåŠ é€Ÿäº†è¯¥é¢†åŸŸçš„ç ”ç©¶è¿›å±•ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡é‡‡ç”¨äº†Megatron-Coreæ¥å®ç°é«˜æ•ˆçš„åˆ†å¸ƒå¼è®­ç»ƒï¼Œå¹¶è®¾è®¡äº†é’ˆå¯¹è§†é¢‘æ•°æ®çš„å‹ç¼©ç®—æ³•ã€‚åœ¨è®­ç»ƒç­–ç•¥æ–¹é¢ï¼Œé‡‡ç”¨äº†è¯¾ç¨‹å­¦ä¹ çš„æ–¹æ³•ï¼Œé€æ­¥å¢åŠ è®­ç»ƒéš¾åº¦ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®ã€æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç­‰ç»†èŠ‚æœªåœ¨æ‘˜è¦ä¸­è¯¦ç»†æè¿°ï¼Œéœ€è¦å‚è€ƒè®ºæ–‡å…¨æ–‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

MUG-V 10Bæ¨¡å‹åœ¨ç”µå•†è§†é¢‘ç”Ÿæˆä»»åŠ¡ä¸Šçš„äººå·¥è¯„ä¼°ä¸­è¶…è¶Šäº†é¢†å…ˆçš„å¼€æºåŸºçº¿ï¼Œè¡¨æ˜è¯¥æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­å…·æœ‰æ˜¾è‘—çš„ä¼˜åŠ¿ã€‚æ­¤å¤–ï¼Œå¼€æºçš„å®Œæ•´æŠ€æœ¯æ ˆï¼ŒåŒ…æ‹¬æ¨¡å‹æƒé‡å’Œè®­ç»ƒä»£ç ï¼Œä¸ºç ”ç©¶äººå‘˜å’Œå¼€å‘è€…æä¾›äº†å®è´µçš„èµ„æºï¼ŒåŠ é€Ÿäº†è¯¥é¢†åŸŸçš„ç ”ç©¶è¿›å±•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºç”µå•†è§†é¢‘ç”Ÿæˆã€å¹¿å‘Šåˆ›æ„ã€æ¸¸æˆå†…å®¹ç”Ÿæˆã€å½±è§†åˆ¶ä½œç­‰é¢†åŸŸã€‚é€šè¿‡é«˜æ•ˆçš„è§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼Œå¯ä»¥é™ä½è§†é¢‘åˆ¶ä½œæˆæœ¬ï¼Œæé«˜å†…å®¹åˆ›ä½œæ•ˆç‡ï¼Œå¹¶ä¸ºç”¨æˆ·æä¾›æ›´åŠ ä¸ªæ€§åŒ–å’Œå¤šæ ·åŒ–çš„è§†é¢‘ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›è¿›ä¸€æ­¥æ¨åŠ¨è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ç­‰é¢†åŸŸçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In recent years, large-scale generative models for visual content (\textit{e.g.,} images, videos, and 3D objects/scenes) have made remarkable progress. However, training large-scale video generation models remains particularly challenging and resource-intensive due to cross-modal text-video alignment, the long sequences involved, and the complex spatiotemporal dependencies. To address these challenges, we present a training framework that optimizes four pillars: (i) data processing, (ii) model architecture, (iii) training strategy, and (iv) infrastructure for large-scale video generation models. These optimizations delivered significant efficiency gains and performance improvements across all stages of data preprocessing, video compression, parameter scaling, curriculum-based pretraining, and alignment-focused post-training. Our resulting model, MUG-V 10B, matches recent state-of-the-art video generators overall and, on e-commerce-oriented video generation tasks, surpasses leading open-source baselines in human evaluations. More importantly, we open-source the complete stack, including model weights, Megatron-Core-based large-scale training code, and inference pipelines for video generation and enhancement. To our knowledge, this is the first public release of large-scale video generation training code that exploits Megatron-Core to achieve high training efficiency and near-linear multi-node scaling, details are available in https://github.com/Shopee-MUG/MUG-V.

