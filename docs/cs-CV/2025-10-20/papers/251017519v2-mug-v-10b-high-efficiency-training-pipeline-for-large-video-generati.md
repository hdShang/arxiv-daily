---
layout: default
title: MUG-V 10B: High-efficiency Training Pipeline for Large Video Generation Models
---

# MUG-V 10B: High-efficiency Training Pipeline for Large Video Generation Models

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.17519" target="_blank" class="toolbar-btn">arXiv: 2510.17519v2</a>
    <a href="https://arxiv.org/pdf/2510.17519.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.17519v2" 
            onclick="toggleFavorite(this, '2510.17519v2', 'MUG-V 10B: High-efficiency Training Pipeline for Large Video Generation Models')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yongshun Zhang, Zhongyi Fan, Yonghang Zhang, Zhangzikang Li, Weifeng Chen, Zhongwei Feng, Chaoyue Wang, Peng Hou, Anxiang Zeng

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-20 (Êõ¥Êñ∞: 2025-10-22)

**Â§áÊ≥®**: Technical Report; Project Page: https://github.com/Shopee-MUG/MUG-V

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/Shopee-MUG/MUG-V)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**MUG-V 10BÔºöÈù¢ÂêëÂ§ßËßÑÊ®°ËßÜÈ¢ëÁîüÊàêÊ®°ÂûãÁöÑÈ´òÊïàËÆ≠ÁªÉÊ°ÜÊû∂**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±ÂÖ´ÔºöÁâ©ÁêÜÂä®Áîª (Physics-based Animation)**

**ÂÖ≥ÈîÆËØç**: `ËßÜÈ¢ëÁîüÊàê` `Â§ßËßÑÊ®°Ê®°Âûã` `È´òÊïàËÆ≠ÁªÉ` `Megatron-Core` `ÁîµÂïÜËßÜÈ¢ë` `Ë∑®Ê®°ÊÄÅÂ≠¶‰π†` `Ê®°ÂûãÂºÄÊ∫ê`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Â§ßËßÑÊ®°ËßÜÈ¢ëÁîüÊàêÊ®°ÂûãËÆ≠ÁªÉÈù¢‰∏¥Ë∑®Ê®°ÊÄÅÂØπÈΩê„ÄÅÈïøÂ∫èÂàó‰æùËµñÂíåÊó∂Á©∫Â§çÊùÇÂ∫¶Á≠âÊåëÊàòÔºåÂØºËá¥ËµÑÊ∫êÊ∂àËÄóÂ∑®Â§ß„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫‰∏Ä‰∏™ÂõõÊîØÊü±‰ºòÂåñÁöÑËÆ≠ÁªÉÊ°ÜÊû∂ÔºåÊ∂µÁõñÊï∞ÊçÆÂ§ÑÁêÜ„ÄÅÊ®°ÂûãÊû∂ÊûÑ„ÄÅËÆ≠ÁªÉÁ≠ñÁï•ÂíåÂü∫Á°ÄËÆæÊñΩÔºåÊèêÂçáËÆ≠ÁªÉÊïàÁéá„ÄÇ
3. MUG-V 10BÊ®°ÂûãÂú®ÁîµÂïÜËßÜÈ¢ëÁîüÊàê‰ªªÂä°‰∏äË∂ÖË∂ä‰∫ÜÂºÄÊ∫êÂü∫Á∫øÔºåÂπ∂ÂºÄÊ∫ê‰∫ÜÊ®°ÂûãÊùÉÈáçÂíåËÆ≠ÁªÉ‰ª£Á†Å„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËøëÂπ¥Êù•ÔºåËßÜËßâÂÜÖÂÆπÁîüÊàêÊ®°ÂûãÔºàÂ¶ÇÂõæÂÉè„ÄÅËßÜÈ¢ëÂíå3DÂØπË±°/Âú∫ÊôØÔºâÂèñÂæó‰∫ÜÊòæËëóËøõÂ±ï„ÄÇÁÑ∂ËÄåÔºåÁî±‰∫éË∑®Ê®°ÊÄÅÊñáÊú¨-ËßÜÈ¢ëÂØπÈΩê„ÄÅÈïøÂ∫èÂàóÂ§ÑÁêÜ‰ª•ÂèäÂ§çÊùÇÁöÑÊó∂Á©∫‰æùËµñÂÖ≥Á≥ªÔºåÂ§ßËßÑÊ®°ËßÜÈ¢ëÁîüÊàêÊ®°ÂûãÁöÑËÆ≠ÁªÉ‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊàòÊÄß‰∏îËµÑÊ∫êÂØÜÈõÜ„ÄÇ‰∏∫‰∫ÜÂ∫îÂØπËøô‰∫õÊåëÊàòÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™ËÆ≠ÁªÉÊ°ÜÊû∂ÔºåËØ•Ê°ÜÊû∂‰ºòÂåñ‰∫ÜÂõõ‰∏™ÂÖ≥ÈîÆÊñπÈù¢ÔºöÔºàiÔºâÊï∞ÊçÆÂ§ÑÁêÜÔºåÔºàiiÔºâÊ®°ÂûãÊû∂ÊûÑÔºåÔºàiiiÔºâËÆ≠ÁªÉÁ≠ñÁï•Ôºå‰ª•ÂèäÔºàivÔºâÂ§ßËßÑÊ®°ËßÜÈ¢ëÁîüÊàêÊ®°ÂûãÁöÑÂü∫Á°ÄËÆæÊñΩ„ÄÇËøô‰∫õ‰ºòÂåñÂú®Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ„ÄÅËßÜÈ¢ëÂéãÁº©„ÄÅÂèÇÊï∞Áº©Êîæ„ÄÅÂü∫‰∫éËØæÁ®ãÁöÑÈ¢ÑËÆ≠ÁªÉÂíå‰ª•ÂØπÈΩê‰∏∫‰∏≠ÂøÉÁöÑÂêéËÆ≠ÁªÉÁ≠âÂêÑ‰∏™Èò∂ÊÆµÈÉΩÂ∏¶Êù•‰∫ÜÊòæËëóÁöÑÊïàÁéáÊèêÂçáÂíåÊÄßËÉΩÊîπËøõ„ÄÇÊàë‰ª¨ÊúÄÁªàÁöÑÊ®°ÂûãMUG-V 10BÂú®Êï¥‰Ωì‰∏ä‰∏éÊúÄÊñ∞ÁöÑËßÜÈ¢ëÁîüÊàêÂô®Áõ∏ÂåπÈÖçÔºåÂπ∂‰∏îÂú®Èù¢ÂêëÁîµÂïÜÁöÑËßÜÈ¢ëÁîüÊàê‰ªªÂä°‰∏≠ÔºåÂú®‰∫∫Â∑•ËØÑ‰º∞‰∏≠Ë∂ÖËøá‰∫ÜÈ¢ÜÂÖàÁöÑÂºÄÊ∫êÂü∫Á∫ø„ÄÇÊõ¥ÈáçË¶ÅÁöÑÊòØÔºåÊàë‰ª¨ÂºÄÊ∫ê‰∫ÜÂÆåÊï¥ÁöÑÊäÄÊúØÊ†àÔºåÂåÖÊã¨Ê®°ÂûãÊùÉÈáç„ÄÅÂü∫‰∫éMegatron-CoreÁöÑÂ§ßËßÑÊ®°ËÆ≠ÁªÉ‰ª£Á†Å‰ª•ÂèäÁî®‰∫éËßÜÈ¢ëÁîüÊàêÂíåÂ¢ûÂº∫ÁöÑÊé®ÁêÜÁÆ°ÈÅì„ÄÇÊçÆÊàë‰ª¨ÊâÄÁü•ÔºåËøôÊòØÁ¨¨‰∏Ä‰∏™ÂÖ¨ÂºÄÂèëÂ∏ÉÁöÑÂ§ßËßÑÊ®°ËßÜÈ¢ëÁîüÊàêËÆ≠ÁªÉ‰ª£Á†ÅÔºåÂÆÉÂà©Áî®Megatron-CoreÊù•ÂÆûÁé∞È´òËÆ≠ÁªÉÊïàÁéáÂíåËøë‰πéÁ∫øÊÄßÁöÑÂ§öËäÇÁÇπÊâ©Â±ï„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÂ§ßËßÑÊ®°ËßÜÈ¢ëÁîüÊàêÊ®°ÂûãËÆ≠ÁªÉÈù¢‰∏¥ÁùÄÊï∞ÊçÆÂ§ÑÁêÜ„ÄÅÊ®°ÂûãÊû∂ÊûÑ„ÄÅËÆ≠ÁªÉÁ≠ñÁï•ÂíåÂü∫Á°ÄËÆæÊñΩÁ≠âÂ§öÊñπÈù¢ÁöÑÊåëÊàò„ÄÇÁé∞ÊúâÁöÑÊñπÊ≥ïÂú®Â§ÑÁêÜÈïøÂ∫èÂàóËßÜÈ¢ë„ÄÅË∑®Ê®°ÊÄÅÂØπÈΩê‰ª•ÂèäÈ´òÊïàÂà©Áî®ËÆ°ÁÆóËµÑÊ∫êÊñπÈù¢Â≠òÂú®‰∏çË∂≥ÔºåÂØºËá¥ËÆ≠ÁªÉÊàêÊú¨È´òÊòÇÔºåÊïàÁéá‰Ωé‰∏ã„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÂØπÊï∞ÊçÆÂ§ÑÁêÜ„ÄÅÊ®°ÂûãÊû∂ÊûÑ„ÄÅËÆ≠ÁªÉÁ≠ñÁï•ÂíåÂü∫Á°ÄËÆæÊñΩËøõË°åÂÖ®Èù¢‰ºòÂåñÔºå‰ªéËÄåÊèêÈ´òÂ§ßËßÑÊ®°ËßÜÈ¢ëÁîüÊàêÊ®°ÂûãÁöÑËÆ≠ÁªÉÊïàÁéá„ÄÇËøôÁßçÂ§öÊñπÈù¢ÁöÑ‰ºòÂåñÁ≠ñÁï•Êó®Âú®Ëß£ÂÜ≥Áé∞ÊúâÊñπÊ≥ïÂú®Â§ÑÁêÜÈïøÂ∫èÂàó„ÄÅË∑®Ê®°ÊÄÅÂØπÈΩêÂíåËµÑÊ∫êÂà©Áî®ÊñπÈù¢ÁöÑÁì∂È¢à„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ„ÄÅËßÜÈ¢ëÂéãÁº©„ÄÅÊ®°ÂûãÊû∂ÊûÑËÆæËÆ°„ÄÅËÆ≠ÁªÉÁ≠ñÁï•ÂíåÂü∫Á°ÄËÆæÊñΩ‰ºòÂåñÁ≠âÂ§ö‰∏™Èò∂ÊÆµ„ÄÇÊï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÈò∂ÊÆµË¥üË¥£Ê∏ÖÊ¥óÂíåÂáÜÂ§áËÆ≠ÁªÉÊï∞ÊçÆÔºõËßÜÈ¢ëÂéãÁº©Èò∂ÊÆµÊó®Âú®ÂáèÂ∞ëËßÜÈ¢ëÊï∞ÊçÆÁöÑÂ≠òÂÇ®ÂíåËÆ°ÁÆóÂºÄÈîÄÔºõÊ®°ÂûãÊû∂ÊûÑËÆæËÆ°Èò∂ÊÆµÂÖ≥Ê≥®Â¶Ç‰ΩïÊûÑÂª∫ËÉΩÂ§üÊúâÊïàÊçïÊçâÊó∂Á©∫‰æùËµñÂÖ≥Á≥ªÁöÑÊ®°ÂûãÔºõËÆ≠ÁªÉÁ≠ñÁï•Èò∂ÊÆµÂàô‰æßÈáç‰∫éÂ¶Ç‰ΩïÈÄöËøáËØæÁ®ãÂ≠¶‰π†Á≠âÊñπÊ≥ïÊèêÈ´òËÆ≠ÁªÉÊïàÁéáÔºõÂü∫Á°ÄËÆæÊñΩ‰ºòÂåñÈò∂ÊÆµÂàôÂÖ≥Ê≥®Â¶Ç‰ΩïÂà©Áî®ÂàÜÂ∏ÉÂºèËÆ°ÁÆóËµÑÊ∫êÂä†ÈÄüËÆ≠ÁªÉËøáÁ®ã„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫Ü‰∏Ä‰∏™ÁªºÂêàÊÄßÁöÑËÆ≠ÁªÉÊ°ÜÊû∂ÔºåËØ•Ê°ÜÊû∂‰∏ç‰ªÖÂÖ≥Ê≥®Ê®°ÂûãÊû∂ÊûÑÊú¨Ë∫´ÔºåËøòÂÖ≥Ê≥®Êï∞ÊçÆÂ§ÑÁêÜ„ÄÅËÆ≠ÁªÉÁ≠ñÁï•ÂíåÂü∫Á°ÄËÆæÊñΩÁ≠âÂ§ö‰∏™ÊñπÈù¢„ÄÇÈÄöËøáÂØπËøô‰∫õÊñπÈù¢ËøõË°åÂçèÂêå‰ºòÂåñÔºåÂèØ‰ª•ÊòæËëóÊèêÈ´òÂ§ßËßÑÊ®°ËßÜÈ¢ëÁîüÊàêÊ®°ÂûãÁöÑËÆ≠ÁªÉÊïàÁéá„ÄÇÊ≠§Â§ñÔºåÂºÄÊ∫êÊ®°ÂûãÂíåËÆ≠ÁªÉ‰ª£Á†Å‰πüÂä†ÈÄü‰∫ÜËØ•È¢ÜÂüüÁöÑÁ†îÁ©∂ËøõÂ±ï„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËÆ∫ÊñáÈááÁî®‰∫ÜMegatron-CoreÊù•ÂÆûÁé∞È´òÊïàÁöÑÂàÜÂ∏ÉÂºèËÆ≠ÁªÉÔºåÂπ∂ËÆæËÆ°‰∫ÜÈíàÂØπËßÜÈ¢ëÊï∞ÊçÆÁöÑÂéãÁº©ÁÆóÊ≥ï„ÄÇÂú®ËÆ≠ÁªÉÁ≠ñÁï•ÊñπÈù¢ÔºåÈááÁî®‰∫ÜËØæÁ®ãÂ≠¶‰π†ÁöÑÊñπÊ≥ïÔºåÈÄêÊ≠•Â¢ûÂä†ËÆ≠ÁªÉÈöæÂ∫¶Ôºå‰ªéËÄåÊèêÈ´òÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÂÖ∑‰ΩìÁöÑÂèÇÊï∞ËÆæÁΩÆ„ÄÅÊçüÂ§±ÂáΩÊï∞ÂíåÁΩëÁªúÁªìÊûÑÁ≠âÁªÜËäÇÊú™Âú®ÊëòË¶Å‰∏≠ËØ¶ÁªÜÊèèËø∞ÔºåÈúÄË¶ÅÂèÇËÄÉËÆ∫ÊñáÂÖ®Êñá„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

MUG-V 10BÊ®°ÂûãÂú®ÁîµÂïÜËßÜÈ¢ëÁîüÊàê‰ªªÂä°‰∏äÁöÑ‰∫∫Â∑•ËØÑ‰º∞‰∏≠Ë∂ÖË∂ä‰∫ÜÈ¢ÜÂÖàÁöÑÂºÄÊ∫êÂü∫Á∫øÔºåË°®ÊòéËØ•Ê®°ÂûãÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÂÖ∑ÊúâÊòæËëóÁöÑ‰ºòÂäø„ÄÇÊ≠§Â§ñÔºåÂºÄÊ∫êÁöÑÂÆåÊï¥ÊäÄÊúØÊ†àÔºåÂåÖÊã¨Ê®°ÂûãÊùÉÈáçÂíåËÆ≠ÁªÉ‰ª£Á†ÅÔºå‰∏∫Á†îÁ©∂‰∫∫ÂëòÂíåÂºÄÂèëËÄÖÊèê‰æõ‰∫ÜÂÆùË¥µÁöÑËµÑÊ∫êÔºåÂä†ÈÄü‰∫ÜËØ•È¢ÜÂüüÁöÑÁ†îÁ©∂ËøõÂ±ï„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂπøÊ≥õÂ∫îÁî®‰∫éÁîµÂïÜËßÜÈ¢ëÁîüÊàê„ÄÅÂπøÂëäÂàõÊÑè„ÄÅÊ∏∏ÊàèÂÜÖÂÆπÁîüÊàê„ÄÅÂΩ±ËßÜÂà∂‰ΩúÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÈ´òÊïàÁöÑËßÜÈ¢ëÁîüÊàêÊ®°ÂûãÔºåÂèØ‰ª•Èôç‰ΩéËßÜÈ¢ëÂà∂‰ΩúÊàêÊú¨ÔºåÊèêÈ´òÂÜÖÂÆπÂàõ‰ΩúÊïàÁéáÔºåÂπ∂‰∏∫Áî®Êà∑Êèê‰æõÊõ¥Âä†‰∏™ÊÄßÂåñÂíåÂ§öÊ†∑ÂåñÁöÑËßÜÈ¢ë‰ΩìÈ™å„ÄÇÊú™Êù•ÔºåËØ•ÊäÄÊúØÊúâÊúõËøõ‰∏ÄÊ≠•Êé®Âä®ËôöÊãüÁé∞ÂÆû„ÄÅÂ¢ûÂº∫Áé∞ÂÆûÁ≠âÈ¢ÜÂüüÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> In recent years, large-scale generative models for visual content (\textit{e.g.,} images, videos, and 3D objects/scenes) have made remarkable progress. However, training large-scale video generation models remains particularly challenging and resource-intensive due to cross-modal text-video alignment, the long sequences involved, and the complex spatiotemporal dependencies. To address these challenges, we present a training framework that optimizes four pillars: (i) data processing, (ii) model architecture, (iii) training strategy, and (iv) infrastructure for large-scale video generation models. These optimizations delivered significant efficiency gains and performance improvements across all stages of data preprocessing, video compression, parameter scaling, curriculum-based pretraining, and alignment-focused post-training. Our resulting model, MUG-V 10B, matches recent state-of-the-art video generators overall and, on e-commerce-oriented video generation tasks, surpasses leading open-source baselines in human evaluations. More importantly, we open-source the complete stack, including model weights, Megatron-Core-based large-scale training code, and inference pipelines for video generation and enhancement. To our knowledge, this is the first public release of large-scale video generation training code that exploits Megatron-Core to achieve high training efficiency and near-linear multi-node scaling, details are available in https://github.com/Shopee-MUG/MUG-V.

