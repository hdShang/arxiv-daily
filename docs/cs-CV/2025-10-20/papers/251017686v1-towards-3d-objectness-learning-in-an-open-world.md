---
layout: default
title: Towards 3D Objectness Learning in an Open World
---

# Towards 3D Objectness Learning in an Open World

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.17686" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.17686v1</a>
  <a href="https://arxiv.org/pdf/2510.17686.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.17686v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.17686v1', 'Towards 3D Objectness Learning in an Open World')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Taichi Liu, Zhenyu Wang, Ruofeng Liu, Guang Wang, Desheng Zhang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-20

**å¤‡æ³¨**: Accepted by NeurIPS 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOP3Detï¼Œè§£å†³å¼€æ”¾ä¸–ç•Œä¸­æ— æ–‡æœ¬æç¤ºçš„é€šç”¨3Dç›®æ ‡æ£€æµ‹é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¼€æ”¾ä¸–ç•Œå­¦ä¹ ` `3Dç›®æ ‡æ£€æµ‹` `ç±»åˆ«æ— å…³æ£€æµ‹` `è·¨æ¨¡æ€èåˆ` `æ··åˆä¸“å®¶æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰3Dç›®æ ‡æ£€æµ‹å™¨åœ¨å°é—­ç¯å¢ƒä¸­è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨å¼€æ”¾ä¸–ç•Œä¸­æ³›åŒ–èƒ½åŠ›ä¸è¶³ï¼Œæ— æ³•æ£€æµ‹è®­ç»ƒæ—¶æœªè§è¿‡çš„ç‰©ä½“ã€‚
2. OP3Detåˆ©ç”¨2DåŸºç¡€æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œç»“åˆ2Dè¯­ä¹‰å’Œ3Då‡ ä½•å…ˆéªŒç”Ÿæˆç±»åˆ«æ— å…³çš„æè®®ï¼Œå¹¶é‡‡ç”¨è·¨æ¨¡æ€æ··åˆä¸“å®¶æ¨¡å‹èåˆç‚¹äº‘å’Œå›¾åƒä¿¡æ¯ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒOP3Detåœ¨å¼€æ”¾ä¸–ç•Œ3Dç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒARæŒ‡æ ‡æå‡é«˜è¾¾16.0%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ç ”ç©¶å¼€æ”¾ä¸–ç•Œ3Dç›®æ ‡ç‰©æ€§å­¦ä¹ ï¼Œæ—¨åœ¨æ£€æµ‹3Dåœºæ™¯ä¸­çš„æ‰€æœ‰ç‰©ä½“ï¼ŒåŒ…æ‹¬è®­ç»ƒæœŸé—´æœªè§è¿‡çš„ç‰©ä½“ã€‚ä¼ ç»Ÿçš„å°é—­é›†3Dæ£€æµ‹å™¨éš¾ä»¥æ³›åŒ–åˆ°å¼€æ”¾ä¸–ç•Œåœºæ™¯ï¼Œè€Œç›´æ¥é‡‡ç”¨3Då¼€æ”¾è¯æ±‡æ¨¡å‹è¿›è¡Œå¼€æ”¾ä¸–ç•Œèƒ½åŠ›å­¦ä¹ åˆé¢ä¸´è¯æ±‡æ‰©å±•å’Œè¯­ä¹‰é‡å çš„é—®é¢˜ã€‚ä¸ºäº†å®ç°é€šç”¨çš„3Dç‰©ä½“å‘ç°ï¼Œæˆ‘ä»¬æå‡ºäº†OP3Detï¼Œä¸€ç§æ— éœ€æ–‡æœ¬æç¤ºçš„ç±»åˆ«æ— å…³å¼€æ”¾ä¸–ç•Œ3Dæ£€æµ‹å™¨ï¼Œç”¨äºæ£€æµ‹3Dåœºæ™¯ä¸­çš„ä»»ä½•ç‰©ä½“ã€‚æˆ‘ä»¬åˆ©ç”¨2DåŸºç¡€æ¨¡å‹çš„å¼ºå¤§æ³›åŒ–å’Œé›¶æ ·æœ¬èƒ½åŠ›ï¼Œç»“åˆ2Dè¯­ä¹‰å…ˆéªŒå’Œ3Då‡ ä½•å…ˆéªŒè¿›è¡Œç±»åˆ«æ— å…³çš„æè®®ç”Ÿæˆï¼Œä»è€Œæ‰©å¤§3Dç‰©ä½“å‘ç°èŒƒå›´ã€‚ç„¶åï¼Œé€šè¿‡åœ¨è·¨æ¨¡æ€æ··åˆä¸“å®¶æ¨¡å‹ä¸­æ•´åˆç‚¹äº‘å’ŒRGBå›¾åƒçš„äº’è¡¥ä¿¡æ¯ï¼ŒOP3DetåŠ¨æ€åœ°è·¯ç”±å•æ¨¡æ€å’Œå¤šæ¨¡æ€ç‰¹å¾ï¼Œä»¥å­¦ä¹ é€šç”¨çš„3Dç‰©ä½“å±æ€§ã€‚å¤§é‡å®éªŒè¡¨æ˜OP3Detå…·æœ‰éå‡¡çš„æ€§èƒ½ï¼Œåœ¨ARæŒ‡æ ‡ä¸Šæ˜¾è‘—è¶…è¶Šç°æœ‰çš„å¼€æ”¾ä¸–ç•Œ3Dæ£€æµ‹å™¨é«˜è¾¾16.0%ï¼Œå¹¶ä¸”æ¯”å°é—­ä¸–ç•Œ3Dæ£€æµ‹å™¨æé«˜äº†13.5%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰3Dç›®æ ‡æ£€æµ‹æ–¹æ³•é€šå¸¸åœ¨å°é—­ä¸–ç•Œå‡è®¾ä¸‹è¿›è¡Œï¼Œå³è®­ç»ƒå’Œæµ‹è¯•æ•°æ®æ¥è‡ªç›¸åŒçš„ç±»åˆ«é›†åˆã€‚ç„¶è€Œï¼Œåœ¨å®é™…åº”ç”¨ä¸­ï¼Œ3Dåœºæ™¯å¾€å¾€åŒ…å«è®­ç»ƒæ—¶æœªè§è¿‡çš„ç‰©ä½“ã€‚ç›´æ¥å°†å°é—­ä¸–ç•Œçš„æ£€æµ‹å™¨åº”ç”¨äºå¼€æ”¾ä¸–ç•Œä¼šå¯¼è‡´æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚æ­¤å¤–ï¼Œåˆ©ç”¨3Då¼€æ”¾è¯æ±‡æ¨¡å‹è¿›è¡Œå¼€æ”¾ä¸–ç•Œæ£€æµ‹é¢ä¸´è¯æ±‡æ‰©å±•å’Œè¯­ä¹‰é‡å çš„æŒ‘æˆ˜ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§èƒ½å¤Ÿæ£€æµ‹ä»»æ„3Dç‰©ä½“çš„é€šç”¨æ–¹æ³•ï¼Œè€Œæ— éœ€é¢„å…ˆå®šä¹‰ç±»åˆ«æˆ–ä¾èµ–æ–‡æœ¬æç¤ºã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šOP3Detçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨2DåŸºç¡€æ¨¡å‹çš„å¼ºå¤§æ³›åŒ–èƒ½åŠ›å’Œé›¶æ ·æœ¬å­¦ä¹ èƒ½åŠ›ï¼Œç»“åˆ3Då‡ ä½•å…ˆéªŒï¼Œç”Ÿæˆç±»åˆ«æ— å…³çš„3Dç‰©ä½“æè®®ã€‚é€šè¿‡è·¨æ¨¡æ€æ··åˆä¸“å®¶æ¨¡å‹ï¼ŒåŠ¨æ€èåˆç‚¹äº‘å’ŒRGBå›¾åƒçš„äº’è¡¥ä¿¡æ¯ï¼Œä»è€Œå­¦ä¹ é€šç”¨çš„3Dç‰©ä½“å±æ€§ã€‚è¿™ç§æ–¹æ³•é¿å…äº†å¯¹é¢„å®šä¹‰ç±»åˆ«çš„ä¾èµ–ï¼Œå¹¶èƒ½å¤Ÿæœ‰æ•ˆåœ°æ£€æµ‹è®­ç»ƒæ—¶æœªè§è¿‡çš„ç‰©ä½“ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šOP3Detçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) 2Dè¯­ä¹‰å…ˆéªŒæå–ï¼šåˆ©ç”¨é¢„è®­ç»ƒçš„2DåŸºç¡€æ¨¡å‹æå–RGBå›¾åƒçš„è¯­ä¹‰ç‰¹å¾ã€‚2) 3Då‡ ä½•å…ˆéªŒæå–ï¼šä»ç‚¹äº‘æ•°æ®ä¸­æå–å‡ ä½•ç‰¹å¾ï¼Œä¾‹å¦‚å½¢çŠ¶ã€å¤§å°å’Œä½ç½®ã€‚3) ç±»åˆ«æ— å…³æè®®ç”Ÿæˆï¼šç»“åˆ2Dè¯­ä¹‰å’Œ3Då‡ ä½•å…ˆéªŒï¼Œç”Ÿæˆå€™é€‰çš„3Dç‰©ä½“æè®®ã€‚4) è·¨æ¨¡æ€æ··åˆä¸“å®¶æ¨¡å‹ï¼šåˆ©ç”¨æ··åˆä¸“å®¶æ¨¡å‹ï¼ŒåŠ¨æ€åœ°èåˆç‚¹äº‘å’ŒRGBå›¾åƒçš„ç‰¹å¾ï¼Œä»¥å­¦ä¹ é€šç”¨çš„3Dç‰©ä½“å±æ€§ã€‚5) ç‰©ä½“æ€§è¯„åˆ†ï¼šå¯¹æ¯ä¸ªæè®®è¿›è¡Œè¯„åˆ†ï¼Œåˆ¤æ–­å…¶æ˜¯å¦åŒ…å«ä¸€ä¸ªç‰©ä½“ã€‚

**å…³é”®åˆ›æ–°**ï¼šOP3Detçš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†ä¸€ç§æ— éœ€æ–‡æœ¬æç¤ºçš„ç±»åˆ«æ— å…³å¼€æ”¾ä¸–ç•Œ3Dæ£€æµ‹å™¨ï¼Œèƒ½å¤Ÿæ£€æµ‹ä»»æ„3Dç‰©ä½“ã€‚2) åˆ©ç”¨2DåŸºç¡€æ¨¡å‹çš„å¼ºå¤§æ³›åŒ–èƒ½åŠ›å’Œé›¶æ ·æœ¬å­¦ä¹ èƒ½åŠ›ï¼Œç»“åˆ3Då‡ ä½•å…ˆéªŒï¼Œç”Ÿæˆç±»åˆ«æ— å…³çš„3Dç‰©ä½“æè®®ã€‚3) é‡‡ç”¨è·¨æ¨¡æ€æ··åˆä¸“å®¶æ¨¡å‹ï¼ŒåŠ¨æ€èåˆç‚¹äº‘å’ŒRGBå›¾åƒçš„ç‰¹å¾ï¼Œä»¥å­¦ä¹ é€šç”¨çš„3Dç‰©ä½“å±æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç±»åˆ«æ— å…³æè®®ç”Ÿæˆé˜¶æ®µï¼Œè®ºæ–‡è®¾è®¡äº†ä¸€ç§èåˆ2Dè¯­ä¹‰å’Œ3Då‡ ä½•ä¿¡æ¯çš„ç­–ç•¥ï¼Œå…·ä½“æ¥è¯´ï¼Œé€šè¿‡å°†2Då›¾åƒç‰¹å¾æŠ•å½±åˆ°3Dç©ºé—´ï¼Œå¹¶ä¸3Då‡ ä½•ç‰¹å¾è¿›è¡Œèåˆï¼Œä»è€Œç”Ÿæˆé«˜è´¨é‡çš„3Dç‰©ä½“æè®®ã€‚åœ¨è·¨æ¨¡æ€æ··åˆä¸“å®¶æ¨¡å‹ä¸­ï¼Œè®ºæ–‡è®¾è®¡äº†ä¸€ç§åŠ¨æ€è·¯ç”±æœºåˆ¶ï¼Œæ ¹æ®è¾“å…¥æ•°æ®çš„ç‰¹å¾ï¼Œè‡ªåŠ¨é€‰æ‹©åˆé€‚çš„ä¸“å®¶è¿›è¡Œç‰¹å¾èåˆã€‚æŸå¤±å‡½æ•°æ–¹é¢ï¼Œé‡‡ç”¨äº†æ ‡å‡†çš„äºŒå…ƒäº¤å‰ç†µæŸå¤±å‡½æ•°æ¥è®­ç»ƒç‰©ä½“æ€§è¯„åˆ†æ¨¡å—ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

OP3Detåœ¨å¼€æ”¾ä¸–ç•Œ3Dç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚åœ¨å®éªŒä¸­ï¼ŒOP3Detåœ¨ARæŒ‡æ ‡ä¸Šè¶…è¶Šäº†ç°æœ‰çš„å¼€æ”¾ä¸–ç•Œ3Dæ£€æµ‹å™¨é«˜è¾¾16.0%ï¼Œå¹¶ä¸”æ¯”å°é—­ä¸–ç•Œ3Dæ£€æµ‹å™¨æé«˜äº†13.5%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒOP3Detèƒ½å¤Ÿæœ‰æ•ˆåœ°æ£€æµ‹è®­ç»ƒæ—¶æœªè§è¿‡çš„ç‰©ä½“ï¼Œå¹¶ä¸”å…·æœ‰å¾ˆå¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€åœºæ™¯ç†è§£ã€ä¸‰ç»´é‡å»ºç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ£€æµ‹é“è·¯ä¸Šçš„å„ç§ç‰©ä½“ï¼ŒåŒ…æ‹¬è¡Œäººã€è½¦è¾†ã€äº¤é€šæ ‡å¿—ç­‰ï¼Œä»è€Œæé«˜é©¾é©¶å®‰å…¨æ€§ã€‚åœ¨æœºå™¨äººå¯¼èˆªä¸­ï¼Œè¯¥æ–¹æ³•å¯ä»¥å¸®åŠ©æœºå™¨äººç†è§£å‘¨å›´ç¯å¢ƒï¼Œå¹¶è¿›è¡Œè‡ªä¸»å¯¼èˆªã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºä¸‰ç»´åœºæ™¯é‡å»ºï¼Œä¾‹å¦‚ï¼Œå¯ä»¥ç”¨äºç”Ÿæˆè™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advancements in 3D object detection and novel category detection have made significant progress, yet research on learning generalized 3D objectness remains insufficient. In this paper, we delve into learning open-world 3D objectness, which focuses on detecting all objects in a 3D scene, including novel objects unseen during training. Traditional closed-set 3D detectors struggle to generalize to open-world scenarios, while directly incorporating 3D open-vocabulary models for open-world ability struggles with vocabulary expansion and semantic overlap. To achieve generalized 3D object discovery, We propose OP3Det, a class-agnostic Open-World Prompt-free 3D Detector to detect any objects within 3D scenes without relying on hand-crafted text prompts. We introduce the strong generalization and zero-shot capabilities of 2D foundation models, utilizing both 2D semantic priors and 3D geometric priors for class-agnostic proposals to broaden 3D object discovery. Then, by integrating complementary information from point cloud and RGB image in the cross-modal mixture of experts, OP3Det dynamically routes uni-modal and multi-modal features to learn generalized 3D objectness. Extensive experiments demonstrate the extraordinary performance of OP3Det, which significantly surpasses existing open-world 3D detectors by up to 16.0% in AR and achieves a 13.5% improvement compared to closed-world 3D detectors.

