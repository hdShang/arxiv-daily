---
layout: default
title: MT-Video-Bench: A Holistic Video Understanding Benchmark for Evaluating Multimodal LLMs in Multi-Turn Dialogues
---

# MT-Video-Bench: A Holistic Video Understanding Benchmark for Evaluating Multimodal LLMs in Multi-Turn Dialogues

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.17722" target="_blank" class="toolbar-btn">arXiv: 2510.17722v1</a>
    <a href="https://arxiv.org/pdf/2510.17722.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.17722v1" 
            onclick="toggleFavorite(this, '2510.17722v1', 'MT-Video-Bench: A Holistic Video Understanding Benchmark for Evaluating Multimodal LLMs in Multi-Turn Dialogues')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yaning Pan, Zekun Wang, Qianqian Xie, Yongqian Wen, Yuanxing Zhang, Guohui Zhang, Haoxuan Hu, Zhiyu Pan, Yibing Huang, Zhidong Gan, Yonghong Lin, An Ping, Tianhao Peng, Jiaheng Liu

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-20

**Â§áÊ≥®**: Project Website: https://github.com/NJU-LINK/MT-Video-Bench

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫MT-Video-BenchÔºåÁî®‰∫éËØÑ‰º∞Â§öÊ®°ÊÄÅLLMÂú®Â§öËΩÆÂØπËØù‰∏≠ÁöÑËßÜÈ¢ëÁêÜËß£ËÉΩÂäõ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `ËßÜÈ¢ëÁêÜËß£` `Â§öËΩÆÂØπËØù` `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `ËØÑ‰º∞Âü∫ÂáÜ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËßÜÈ¢ëÁêÜËß£ËØÑ‰º∞Âü∫ÂáÜ‰∏ªË¶ÅÈõÜ‰∏≠‰∫éÂçïËΩÆÈóÆÁ≠îÔºåÁº∫‰πèÂØπÂ§öËΩÆ‰∫§‰∫íÂú∫ÊôØÁöÑÊúâÊïàËØÑ‰º∞„ÄÇ
2. MT-Video-BenchÈÄöËøáÊûÑÂª∫ÂåÖÂê´987‰∏™Â§öËΩÆÂØπËØùÁöÑÂü∫ÂáÜÔºåÂÖ®Èù¢ËØÑ‰º∞MLLMÁöÑÊÑüÁü•Âíå‰∫§‰∫íËÉΩÂäõ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊè≠Á§∫‰∫ÜÁé∞ÊúâMLLMÂú®Â§ÑÁêÜÂ§öËΩÆËßÜÈ¢ëÂØπËØùÊñπÈù¢ÁöÑÊÄßËÉΩÂ∑ÆÂºÇÂíåÂ±ÄÈôêÊÄßÔºå‰∏∫Êú™Êù•Á†îÁ©∂Êèê‰æõÂèÇËÄÉ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMÔºâÁöÑÊúÄÊñ∞ÂèëÂ±ïÊòæËëóÊèêÂçá‰∫ÜAIÁêÜËß£ËßÜËßâÊ®°ÊÄÅÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÁöÑËØÑ‰º∞Âü∫ÂáÜ‰ªçÁÑ∂Â±ÄÈôê‰∫éÂçïËΩÆÈóÆÁ≠îÔºåÂøΩÁï•‰∫ÜÁúüÂÆûÂú∫ÊôØ‰∏≠Â§öËΩÆÂØπËØùÁöÑÂ§çÊùÇÊÄß„ÄÇ‰∏∫‰∫ÜÂº•Ë°•Ëøô‰∏ÄÂ∑ÆË∑ùÔºåÊàë‰ª¨Êé®Âá∫‰∫ÜMT-Video-BenchÔºåËøôÊòØ‰∏Ä‰∏™ÂÖ®Èù¢ÁöÑËßÜÈ¢ëÁêÜËß£Âü∫ÂáÜÔºåÁî®‰∫éËØÑ‰º∞MLLMÂú®Â§öËΩÆÂØπËØù‰∏≠ÁöÑË°®Áé∞„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåMT-Video-Bench‰∏ªË¶ÅËØÑ‰º∞ÂÖ≠È°πÊ†∏ÂøÉËÉΩÂäõÔºå‰æßÈáç‰∫éÊÑüÁü•Âíå‰∫§‰∫íÊÄßÔºåÂåÖÂê´Êù•Ëá™‰∏çÂêåÈ¢ÜÂüüÁöÑ987‰∏™Á≤æÂøÉÁ≠ñÂàíÁöÑÂ§öËΩÆÂØπËØù„ÄÇËøô‰∫õËÉΩÂäõ‰∏éÂÆûÈôÖÂ∫îÁî®‰∏•Ê†ºÂØπÈΩêÔºå‰æãÂ¶Ç‰∫§‰∫íÂºè‰ΩìËÇ≤ÂàÜÊûêÂíåÂü∫‰∫éËßÜÈ¢ëÁöÑÂ§öËΩÆÊô∫ËÉΩËæÖÂØº„ÄÇÈÄöËøáMT-Video-BenchÔºåÊàë‰ª¨ÂπøÊ≥õËØÑ‰º∞‰∫ÜÂêÑÁßçÊúÄÂÖàËøõÁöÑÂºÄÊ∫êÂíåÈó≠Ê∫êMLLMÔºåÊè≠Á§∫‰∫ÜÂÆÉ‰ª¨Âú®Â§ÑÁêÜÂ§öËΩÆËßÜÈ¢ëÂØπËØùÊñπÈù¢ÁöÑÊòæËëóÊÄßËÉΩÂ∑ÆÂºÇÂíåÂ±ÄÈôêÊÄß„ÄÇËØ•Âü∫ÂáÜÂ∞ÜÂÖ¨ÂºÄÊèê‰æõÔºå‰ª•‰øÉËøõÊú™Êù•ÁöÑÁ†îÁ©∂„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâMLLMÁöÑËßÜÈ¢ëÁêÜËß£ËØÑ‰º∞‰∏ªË¶ÅÈõÜ‰∏≠Âú®ÂçïËΩÆÈóÆÁ≠îÔºåÊó†Ê≥ïÊúâÊïàËØÑ‰º∞Ê®°ÂûãÂú®ÁúüÂÆûÂú∫ÊôØ‰∏ãÁöÑÂ§öËΩÆ‰∫§‰∫íËÉΩÂäõ„ÄÇÁé∞ÊúâÊñπÊ≥ïÁº∫‰πèÂØπÊ®°ÂûãÊÑüÁü•ËÉΩÂäõÂíå‰∫§‰∫íËÉΩÂäõÁöÑÂÖ®Èù¢ËØÑ‰º∞ÔºåÈöæ‰ª•ÂèçÊò†Ê®°ÂûãÂú®Â§çÊùÇÂú∫ÊôØ‰∏ãÁöÑÂÆûÈôÖÂ∫îÁî®ÊïàÊûú„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöMT-Video-BenchÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÊûÑÂª∫‰∏Ä‰∏™ÂåÖÂê´Â§öËΩÆÂØπËØùÁöÑËßÜÈ¢ëÁêÜËß£Âü∫ÂáÜÔºåÈÄöËøáÊ®°ÊãüÁúüÂÆûÂú∫ÊôØ‰∏ãÁöÑ‰∫§‰∫íËøáÁ®ãÔºåÂÖ®Èù¢ËØÑ‰º∞MLLMÁöÑÊÑüÁü•ËÉΩÂäõÂíå‰∫§‰∫íËÉΩÂäõ„ÄÇËØ•Âü∫ÂáÜ‰æßÈáç‰∫éËØÑ‰º∞Ê®°ÂûãÂú®Â§öËΩÆÂØπËØù‰∏≠ÁêÜËß£ËßÜÈ¢ëÂÜÖÂÆπ„ÄÅËøõË°åÊé®ÁêÜÂíåÁîüÊàêÂõûÂ§çÁöÑËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöMT-Video-BenchÂåÖÂê´987‰∏™Á≤æÂøÉÁ≠ñÂàíÁöÑÂ§öËΩÆÂØπËØùÔºåÊ∂µÁõñ‰∏çÂêåÁöÑÈ¢ÜÂüüÂíåÂú∫ÊôØ„ÄÇÊØè‰∏™ÂØπËØùÈÉΩÂåÖÂê´ËßÜÈ¢ëÁâáÊÆµÂíå‰∏ÄÁ≥ªÂàóÈóÆÈ¢òÔºåÈóÆÈ¢òËÆæËÆ°Êó®Âú®ËØÑ‰º∞Ê®°ÂûãÁöÑÂÖ≠È°πÊ†∏ÂøÉËÉΩÂäõÔºöÊÑüÁü•ËÉΩÂäõÔºà‰æãÂ¶ÇÁõÆÊ†áÊ£ÄÊµã„ÄÅÂú∫ÊôØÁêÜËß£Ôºâ„ÄÅ‰∫§‰∫íËÉΩÂäõÔºà‰æãÂ¶ÇÈóÆÈ¢òÂõûÁ≠î„ÄÅÂØπËØùÁîüÊàêÔºâ„ÄÇÂü∫ÂáÜËøòÊèê‰æõËØÑ‰º∞ÊåáÊ†áÔºåÁî®‰∫éË°°ÈáèÊ®°ÂûãÂú®‰∏çÂêåËÉΩÂäõ‰∏äÁöÑË°®Áé∞„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöMT-Video-BenchÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂Â§öËΩÆÂØπËØùÁöÑËÆæËÆ°ÔºåËÉΩÂ§üÊõ¥ÁúüÂÆûÂú∞ÂèçÊò†Ê®°ÂûãÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑË°®Áé∞„ÄÇ‰∏éÁé∞ÊúâÂçïËΩÆÈóÆÁ≠îÂü∫ÂáÜÁõ∏ÊØîÔºåMT-Video-BenchËÉΩÂ§üÊõ¥ÂÖ®Èù¢Âú∞ËØÑ‰º∞Ê®°ÂûãÁöÑÊÑüÁü•ËÉΩÂäõÂíå‰∫§‰∫íËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåËØ•Âü∫ÂáÜËøòÊ∂µÁõñ‰∫Ü‰∏çÂêåÁöÑÈ¢ÜÂüüÂíåÂú∫ÊôØÔºåÂÖ∑ÊúâÊõ¥ÂπøÊ≥õÁöÑÈÄÇÁî®ÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöMT-Video-BenchÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) Â§öÊ†∑ÂåñÁöÑËßÜÈ¢ëÂÜÖÂÆπÔºåÊ∂µÁõñ‰∏çÂêåÁöÑÈ¢ÜÂüüÂíåÂú∫ÊôØÔºõ2) Á≤æÂøÉËÆæËÆ°ÁöÑÂ§öËΩÆÂØπËØùÔºåÊ®°ÊãüÁúüÂÆûÂú∫ÊôØ‰∏ãÁöÑ‰∫§‰∫íËøáÁ®ãÔºõ3) ÊòéÁ°ÆÂÆö‰πâÁöÑËØÑ‰º∞ÊåáÊ†áÔºåÁî®‰∫éË°°ÈáèÊ®°ÂûãÂú®‰∏çÂêåËÉΩÂäõ‰∏äÁöÑË°®Áé∞Ôºõ4) ÂÖ≠È°πÊ†∏ÂøÉËÉΩÂäõÔºåÂåÖÊã¨ÁõÆÊ†áÊ£ÄÊµã„ÄÅÂú∫ÊôØÁêÜËß£„ÄÅÈóÆÈ¢òÂõûÁ≠î„ÄÅÂØπËØùÁîüÊàêÁ≠â„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÈÄöËøáÂú®MT-Video-Bench‰∏äÂØπÂ§öÁßçÂºÄÊ∫êÂíåÈó≠Ê∫êMLLMËøõË°åËØÑ‰º∞ÔºåËÆ∫ÊñáÊè≠Á§∫‰∫ÜÂÆÉ‰ª¨Âú®Â§ÑÁêÜÂ§öËΩÆËßÜÈ¢ëÂØπËØùÊñπÈù¢ÁöÑÊòæËëóÊÄßËÉΩÂ∑ÆÂºÇÂíåÂ±ÄÈôêÊÄß„ÄÇ‰æãÂ¶ÇÔºå‰∏Ä‰∫õÊ®°ÂûãÂú®ÁõÆÊ†áÊ£ÄÊµãÂíåÂú∫ÊôØÁêÜËß£ÊñπÈù¢Ë°®Áé∞ËâØÂ•ΩÔºå‰ΩÜÂú®ÂØπËØùÁîüÊàêÊñπÈù¢Â≠òÂú®‰∏çË∂≥„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÁé∞ÊúâMLLMÂú®Â§ÑÁêÜÂ§çÊùÇÁöÑÂ§öËΩÆËßÜÈ¢ëÂØπËØùÊó∂‰ªçÈù¢‰∏¥ÊåëÊàòÔºåÈúÄË¶ÅËøõ‰∏ÄÊ≠•ÁöÑÁ†îÁ©∂ÂíåÊîπËøõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

MT-Video-BenchÂèØÂ∫îÁî®‰∫éÂºÄÂèëÊõ¥Êô∫ËÉΩÁöÑËßÜÈ¢ëÁêÜËß£Á≥ªÁªüÔºå‰æãÂ¶ÇÊô∫ËÉΩÂÆ¢Êúç„ÄÅËßÜÈ¢ëÁõëÊéß„ÄÅÊô∫ËÉΩÊïôËÇ≤Á≠â„ÄÇÈÄöËøáËØÑ‰º∞ÂíåÊèêÂçáMLLMÂú®Â§öËΩÆËßÜÈ¢ëÂØπËØù‰∏≠ÁöÑËÉΩÂäõÔºåÂèØ‰ª•ÂÆûÁé∞Êõ¥Ëá™ÁÑ∂„ÄÅÊõ¥È´òÊïàÁöÑ‰∫∫Êú∫‰∫§‰∫í„ÄÇËØ•Âü∫ÂáÜÁöÑÂèëÂ∏ÉÂ∞Ü‰øÉËøõÂ§öÊ®°ÊÄÅÂ≠¶‰π†È¢ÜÂüüÁöÑÁ†îÁ©∂ÔºåÊé®Âä®ËßÜÈ¢ëÁêÜËß£ÊäÄÊúØÁöÑËøõÊ≠•ÔºåÂπ∂‰∏∫Áõ∏ÂÖ≥‰∫ß‰∏öÂ∏¶Êù•ÊΩúÂú®ÁöÑÂïÜ‰∏ö‰ª∑ÂÄº„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> The recent development of Multimodal Large Language Models (MLLMs) has significantly advanced AI's ability to understand visual modalities. However, existing evaluation benchmarks remain limited to single-turn question answering, overlooking the complexity of multi-turn dialogues in real-world scenarios. To bridge this gap, we introduce MT-Video-Bench, a holistic video understanding benchmark for evaluating MLLMs in multi-turn dialogues. Specifically, our MT-Video-Bench mainly assesses six core competencies that focus on perceptivity and interactivity, encompassing 987 meticulously curated multi-turn dialogues from diverse domains. These capabilities are rigorously aligned with real-world applications, such as interactive sports analysis and multi-turn video-based intelligent tutoring. With MT-Video-Bench, we extensively evaluate various state-of-the-art open-source and closed-source MLLMs, revealing their significant performance discrepancies and limitations in handling multi-turn video dialogues. The benchmark will be publicly available to foster future research.

