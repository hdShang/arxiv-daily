---
layout: default
title: Seeing but Not Believing: Probing the Disconnect Between Visual Attention and Answer Correctness in VLMs
---

# Seeing but Not Believing: Probing the Disconnect Between Visual Attention and Answer Correctness in VLMs

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.17771" target="_blank" class="toolbar-btn">arXiv: 2510.17771v1</a>
    <a href="https://arxiv.org/pdf/2510.17771.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.17771v1" 
            onclick="toggleFavorite(this, '2510.17771v1', 'Seeing but Not Believing: Probing the Disconnect Between Visual Attention and Answer Correctness in VLMs')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Zhining Liu, Ziyi Chen, Hui Liu, Chen Luo, Xianfeng Tang, Suhang Wang, Joy Zeng, Zhenwei Dai, Zhan Shi, Tianxin Wei, Benoit Dumoulin, Hanghang Tong

**ÂàÜÁ±ª**: cs.AI, cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-20

**Â§áÊ≥®**: 21 pages, 10 figures, 6 tables

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**Êè≠Á§∫ËßÜËßâËØ≠Ë®ÄÊ®°Âûã‚ÄúËßÜËÄå‰∏ç‰ø°‚ÄùÁé∞Ë±°ÔºåÊèêÂá∫Êó†ÈúÄËÆ≠ÁªÉÁöÑÊ≥®ÊÑèÂäõÂπ≤È¢ÑÊñπÊ≥ï**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâËØ≠Ë®ÄÊ®°Âûã` `ËßÜËßâÈóÆÁ≠î` `Ê≥®ÊÑèÂäõÊú∫Âà∂` `Êé®ÁêÜÊó∂Âπ≤È¢Ñ` `ËßÜËÄå‰∏ç‰ø°`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÂú®ËßÜËßâÈóÆÁ≠î‰ªªÂä°‰∏≠ÔºåÂç≥‰ΩøÂ≠òÂú®Ê≠£Á°ÆËßÜËßâËØÅÊçÆÔºå‰ªç‰ºöÁªôÂá∫ÈîôËØØÁ≠îÊ°àÔºåÂéüÂõ†Â∞ö‰∏çÊòéÁ°Æ„ÄÇ
2. ËØ•Á†îÁ©∂ÂèëÁé∞Ê∑±Â±ÇÊ≥®ÊÑèÂäõÊú∫Âà∂ËÉΩÂ§üÂÆö‰ΩçÂà∞ÂÖ≥ÈîÆËßÜËßâËØÅÊçÆÔºå‰ΩÜÊ®°ÂûãÊú™ËÉΩÊúâÊïàÂà©Áî®Ëøô‰∫õ‰ø°ÊÅØËøõË°åÊé®ÁêÜ„ÄÇ
3. ÊèêÂá∫‰∏ÄÁßçÊó†ÈúÄËÆ≠ÁªÉÁöÑÊé®ÁêÜÊó∂Âπ≤È¢ÑÊñπÊ≥ïÔºåÈÄöËøáÁ™ÅÂá∫Ê∑±Â±ÇÊ≥®ÊÑèÂäõÂå∫ÂüüÔºåÊòæËëóÊèêÂçá‰∫ÜÂ§öÁßçVLMsÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËßÜËßâËØ≠Ë®ÄÊ®°Âûã(VLMs)Âú®ËßÜËßâÈóÆÁ≠îÁ≠âÂ§öÊ®°ÊÄÅ‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫Ëâ≤Ôºå‰ΩÜÂç≥‰ΩøÂ≠òÂú®Ê≠£Á°ÆÁöÑËßÜËßâËØÅÊçÆÔºå‰ªçÁÑ∂ÂèØËÉΩÂ§±Ë¥•„ÄÇÊú¨ÊñáÁ≥ªÁªüÂú∞Á†îÁ©∂‰∫ÜËøô‰∫õÂ§±Ë¥•ÊòØÊ∫ê‰∫éÊú™ËÉΩÊÑüÁü•Âà∞ËØÅÊçÆÔºåËøòÊòØÊú™ËÉΩÊúâÊïàÂú∞Âà©Áî®ËØÅÊçÆ„ÄÇÈÄöËøáÊ£ÄÊü•ÈÄêÂ±ÇÊ≥®ÊÑèÂäõÂä®ÊÄÅÔºåÂèëÁé∞ÊµÖÂ±Ç‰∏ªË¶ÅÂÖ≥Ê≥®ÊñáÊú¨ÔºåËÄåÊ∑±Â±ÇÁ®ÄÁñè‰ΩÜÂèØÈù†Âú∞ÂÖ≥Ê≥®Â±ÄÈÉ®ËØÅÊçÆÂå∫Âüü„ÄÇ‰ª§‰∫∫ÊÉäËÆ∂ÁöÑÊòØÔºåVLMsÂú®ËæìÂá∫ÈîôËØØÁ≠îÊ°àÊó∂ÈÄöÂ∏∏ÊÑüÁü•Âà∞ËßÜËßâËØÅÊçÆÔºåËøôÁßçÁé∞Ë±°Ë¢´Áß∞‰∏∫‚ÄúËßÜËÄå‰∏ç‰ø°‚ÄùÔºåÂπøÊ≥õÂ≠òÂú®‰∫é‰∏ªË¶ÅÁöÑVLMÂÆ∂Êóè‰∏≠„ÄÇÂú®Ê≠§Âü∫Á°Ä‰∏äÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊé®ÁêÜÊó∂Âπ≤È¢ÑÊñπÊ≥ïÔºåÈÄöËøáÂü∫‰∫éÈÄâÊã©ÊÄßÊ≥®ÊÑèÂäõÁöÑÊé©Á†ÅÁ™ÅÂá∫ÊòæÁ§∫Ê∑±Â±ÇËØÅÊçÆÂå∫Âüü„ÄÇËØ•ÊñπÊ≥ïÊó†ÈúÄËÆ≠ÁªÉÔºåÂπ∂ËÉΩÊåÅÁª≠ÊèêÈ´òÂ§ö‰∏™VLMÂÆ∂ÊóèÔºàÂåÖÊã¨LLaVA„ÄÅQwen„ÄÅGemmaÂíåInternVLÔºâÁöÑÂáÜÁ°ÆÊÄß„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéÔºåVLMsÂú®ÂÜÖÈÉ®ÁºñÁ†Å‰∫ÜÂèØÈù†ÁöÑËØÅÊçÆÔºå‰ΩÜÊú™ËÉΩÂÖÖÂàÜÂà©Áî®ÂÆÉÔºå‰ΩøËøô‰∫õ‰ø°Âè∑ÊòæÂºèÂåñÂèØ‰ª•Âº•ÂêàÊÑüÁü•ÂíåÊé®ÁêÜ‰πãÈó¥ÁöÑÂ∑ÆË∑ùÔºå‰ªéËÄåÊèêÈ´òVLMsÁöÑËØäÊñ≠ÁêÜËß£ËÉΩÂäõÂíåÂèØÈù†ÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÂú®ËßÜËßâÈóÆÁ≠î‰ªªÂä°‰∏≠ÔºåÂç≥‰ΩøËÉΩÂ§ü‚ÄúÁúãÂà∞‚ÄùÊ≠£Á°ÆÁöÑËßÜËßâËØÅÊçÆÔºå‰ªçÁÑ∂‰ºöÁªôÂá∫ÈîôËØØÁöÑÁ≠îÊ°à„ÄÇÁé∞ÊúâÁöÑÊñπÊ≥ïÁº∫‰πèÂØπËøôÁßç‚ÄúËßÜËÄå‰∏ç‰ø°‚ÄùÁé∞Ë±°ÁöÑÊ∑±ÂÖ•ÁêÜËß£ÔºåÊó†Ê≥ïÊúâÊïàÂà©Áî®Ê®°ÂûãÂÜÖÈÉ®Â∑≤ÁªèÂ≠òÂú®ÁöÑËßÜËßâ‰ø°ÊÅØÔºåÂØºËá¥ÊÄßËÉΩÁì∂È¢à„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÔºåËôΩÁÑ∂VLMsÁöÑÊ∑±Â±ÇÁΩëÁªúËÉΩÂ§üÂÆö‰ΩçÂà∞ÂÖ≥ÈîÆÁöÑËßÜËßâËØÅÊçÆÔºå‰ΩÜËøô‰∫õËØÅÊçÆÂπ∂Ê≤°ÊúâË¢´ÂÖÖÂàÜÂà©Áî®„ÄÇÈÄöËøáÂú®Êé®ÁêÜÊó∂ÂØπÊ∑±Â±ÇÁΩëÁªúÁöÑÊ≥®ÊÑèÂäõËøõË°åÂπ≤È¢ÑÔºåÁ™ÅÂá∫ÊòæÁ§∫Ëøô‰∫õÂÖ≥ÈîÆÂå∫ÂüüÔºåÂèØ‰ª•Ëø´‰ΩøÊ®°ÂûãÊõ¥Âä†ÂÖ≥Ê≥®Ëøô‰∫õËØÅÊçÆÔºå‰ªéËÄåÊèêÈ´òÁ≠îÊ°àÁöÑÊ≠£Á°ÆÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•ÊñπÊ≥ï‰∏ªË¶ÅÂàÜ‰∏∫‰∏§‰∏™Èò∂ÊÆµÔºöÈ¶ñÂÖàÔºåÂàÜÊûêVLMsÁöÑÈÄêÂ±ÇÊ≥®ÊÑèÂäõÂä®ÊÄÅÔºåÁ°ÆÂÆöÊ∑±Â±ÇÁΩëÁªú‰∏≠ËÉΩÂ§üÊúâÊïàÂÆö‰ΩçËßÜËßâËØÅÊçÆÁöÑÂ±Ç„ÄÇÁÑ∂ÂêéÔºåÂú®Êé®ÁêÜÊó∂ÔºåÂü∫‰∫éËøô‰∫õÊ∑±Â±ÇÁΩëÁªúÁöÑÊ≥®ÊÑèÂäõÊùÉÈáçÔºåÂØπËæìÂÖ•ÂõæÂÉèËøõË°åÈÄâÊã©ÊÄßÊé©Á†ÅÔºåÁ™ÅÂá∫ÊòæÁ§∫Ê≥®ÊÑèÂäõÈõÜ‰∏≠ÁöÑÂå∫Âüü„ÄÇ‰øÆÊîπÂêéÁöÑÂõæÂÉèÂíåÂéüÂßãÈóÆÈ¢ò‰∏ÄËµ∑ËæìÂÖ•Âà∞VLM‰∏≠ÔºåÂæóÂà∞ÊúÄÁªàÁöÑÁ≠îÊ°à„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ÊñπÊ≥ïÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂèëÁé∞‰∫ÜVLMsÁöÑ‚ÄúËßÜËÄå‰∏ç‰ø°‚ÄùÁé∞Ë±°ÔºåÂπ∂ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊó†ÈúÄËÆ≠ÁªÉÁöÑÊé®ÁêÜÊó∂Âπ≤È¢ÑÊñπÊ≥ïÊù•Ëß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢ò„ÄÇ‰∏éÈúÄË¶ÅÈáçÊñ∞ËÆ≠ÁªÉÊ®°ÂûãÊàñ‰øÆÊîπÊ®°ÂûãÁªìÊûÑÁöÑ‰º†ÁªüÊñπÊ≥ï‰∏çÂêåÔºåËØ•ÊñπÊ≥ïÂèØ‰ª•Âú®Áé∞ÊúâÊ®°ÂûãÁöÑÂü∫Á°Ä‰∏äÁõ¥Êé•Â∫îÁî®ÔºåÂÖ∑ÊúâÂæàÂº∫ÁöÑÈÄöÁî®ÊÄßÂíåÂÆûÁî®ÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËØ•ÊñπÊ≥ïÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ÈÄâÊã©ÂêàÈÄÇÁöÑÊ∑±Â±ÇÁΩëÁªúÂ±ÇËøõË°åÊ≥®ÊÑèÂäõÂàÜÊûêÂíåÂπ≤È¢ÑÔºõ2) ËÆæËÆ°ÊúâÊïàÁöÑÈÄâÊã©ÊÄßÊé©Á†ÅÁ≠ñÁï•Ôºå‰ª•Á™ÅÂá∫ÊòæÁ§∫Ê≥®ÊÑèÂäõÈõÜ‰∏≠ÁöÑÂå∫ÂüüÔºåÂêåÊó∂ÈÅøÂÖçËøáÂ∫¶Âπ≤Êâ∞ÂéüÂßãÂõæÂÉèÁöÑ‰ø°ÊÅØÔºõ3) Á°ÆÂÆöÂêàÈÄÇÁöÑÂπ≤È¢ÑÂº∫Â∫¶Ôºå‰ª•Âπ≥Ë°°ËßÜËßâËØÅÊçÆÁöÑÁ™ÅÂá∫ÂíåÂéüÂßã‰ø°ÊÅØÁöÑ‰øùÁïô„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®Â§ö‰∏™VLMÂÆ∂ÊóèÔºàÂåÖÊã¨LLaVA„ÄÅQwen„ÄÅGemmaÂíåInternVLÔºâ‰∏äÂùáÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇ‰æãÂ¶ÇÔºåÂú®ËßÜËßâÈóÆÁ≠î‰ªªÂä°‰∏≠ÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÂú®‰∏çËøõË°å‰ªª‰ΩïËÆ≠ÁªÉÁöÑÊÉÖÂÜµ‰∏ãÔºåÊèêÈ´òÊ®°ÂûãÁöÑÂáÜÁ°ÆÁéá„ÄÇËøô‰∏ÄÁªìÊûúÈ™åËØÅ‰∫ÜVLMsÂÜÖÈÉ®ÁºñÁ†Å‰∫ÜÂèØÈù†ÁöÑËßÜËßâËØÅÊçÆÔºå‰ΩÜÊú™ËÉΩÂÖÖÂàÜÂà©Áî®Ëøô‰∫õËØÅÊçÆ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊèêÂçáÁé∞ÊúâËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÁöÑÂèØÈù†ÊÄßÂíåÂáÜÁ°ÆÊÄßÔºåÂ∞§ÂÖ∂ÊòØÂú®ÈúÄË¶ÅÁ≤æÁ°ÆËßÜËßâÊé®ÁêÜÁöÑÂú∫ÊôØÔºåÂ¶ÇÂåªÁñóÂΩ±ÂÉèËØäÊñ≠„ÄÅËá™Âä®È©æÈ©∂„ÄÅÊô∫ËÉΩÂÆ¢ÊúçÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÊèêÈ´òÊ®°ÂûãÂØπËßÜËßâËØÅÊçÆÁöÑÂà©Áî®ÁéáÔºåÂèØ‰ª•ÂáèÂ∞ëÈîôËØØÁ≠îÊ°àÁöÑ‰∫ßÁîüÔºåÂ¢ûÂº∫Áî®Êà∑ÂØπÊ®°ÂûãÁöÑ‰ø°‰ªªÂ∫¶ÔºåÂπ∂‰∏∫Êú™Êù•ÁöÑVLMÁ†îÁ©∂Êèê‰æõÊñ∞ÁöÑÊñπÂêë„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Vision-Language Models (VLMs) achieve strong results on multimodal tasks such as visual question answering, yet they can still fail even when the correct visual evidence is present. In this work, we systematically investigate whether these failures arise from not perceiving the evidence or from not leveraging it effectively. By examining layer-wise attention dynamics, we find that shallow layers focus primarily on text, while deeper layers sparsely but reliably attend to localized evidence regions. Surprisingly, VLMs often perceive the visual evidence when outputting incorrect answers, a phenomenon we term ``seeing but not believing'' that widely exists in major VLM families. Building on this, we introduce an inference-time intervention that highlights deep-layer evidence regions through selective attention-based masking. It requires no training and consistently improves accuracy across multiple families, including LLaVA, Qwen, Gemma, and InternVL. These results show that VLMs encode reliable evidence internally but under-utilize it, making such signals explicit can bridge the gap between perception and reasoning, advancing the diagnostic understanding and reliability of VLMs.

