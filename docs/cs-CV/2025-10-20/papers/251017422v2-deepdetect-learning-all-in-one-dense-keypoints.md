---
layout: default
title: "DeepDetect: Learning All-in-One Dense Keypoints"
---

# DeepDetect: Learning All-in-One Dense Keypoints

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.17422" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.17422v2</a>
  <a href="https://arxiv.org/pdf/2510.17422.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.17422v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.17422v2', 'DeepDetect: Learning All-in-One Dense Keypoints')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shaharyar Ahmed Khan Tareen, Filza Khan Tareen

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-20 (æ›´æ–°: 2025-10-21)

**å¤‡æ³¨**: 6 pages, 6 figures, 2 tables, 7 equations

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**DeepDetectï¼šæå‡ºä¸€ç§èåˆç»å…¸æ£€æµ‹å™¨ä¼˜åŠ¿çš„ç«¯åˆ°ç«¯å¯†é›†å…³é”®ç‚¹æ£€æµ‹æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `å…³é”®ç‚¹æ£€æµ‹` `æ·±åº¦å­¦ä¹ ` `å›¾åƒé…å‡†` `ä¸‰ç»´é‡å»º` `è§†è§‰SLAM` `ç‰¹å¾æå–` `å¯†é›†é¢„æµ‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å…³é”®ç‚¹æ£€æµ‹æ–¹æ³•å¯¹å…‰ç…§å˜åŒ–æ•æ„Ÿï¼Œå…³é”®ç‚¹å¯†åº¦ä½ï¼Œéš¾ä»¥é€‚åº”å¤æ‚åœºæ™¯ï¼Œä¸”ç¼ºä¹å¯¹å›¾åƒè¯­ä¹‰çš„ç†è§£ã€‚
2. DeepDetectèåˆå¤šç§ç»å…¸æ£€æµ‹å™¨çš„ä¼˜åŠ¿ï¼Œåˆ©ç”¨æ·±åº¦å­¦ä¹ è®­ç»ƒæ¨¡å‹ï¼Œä½¿å…¶èƒ½å¤Ÿå…³æ³¨å›¾åƒè¯­ä¹‰å¹¶ç”Ÿæˆé«˜å¯†åº¦å…³é”®ç‚¹ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒDeepDetectåœ¨å…³é”®ç‚¹å¯†åº¦ã€é‡å¤æ€§å’Œæ­£ç¡®åŒ¹é…æ•°é‡ä¸Šå‡ä¼˜äºå…¶ä»–æ£€æµ‹å™¨ï¼Œæ€§èƒ½æ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å…³é”®ç‚¹æ£€æµ‹æ˜¯è¯¸å¤šè®¡ç®—æœºè§†è§‰ä»»åŠ¡çš„åŸºç¡€ï¼ŒåŒ…æ‹¬å›¾åƒé…å‡†ã€è¿åŠ¨ç»“æ„é‡å»ºã€ä¸‰ç»´é‡å»ºã€è§†è§‰é‡Œç¨‹è®¡å’ŒSLAMã€‚ä¼ ç»Ÿæ£€æµ‹å™¨ï¼ˆSIFTã€SURFã€ORBã€BRISKç­‰ï¼‰å’ŒåŸºäºå­¦ä¹ çš„æ–¹æ³•ï¼ˆSuperPointã€R2D2ã€LF-Netã€D2-Netç­‰ï¼‰è™½ç„¶è¡¨ç°å‡ºè‰²ï¼Œä½†å­˜åœ¨ä¸€äº›å±€é™æ€§ï¼šå¯¹å…‰åº¦å˜åŒ–æ•æ„Ÿã€å…³é”®ç‚¹å¯†åº¦å’Œé‡å¤æ€§ä½ã€å¯¹å¤æ‚åœºæ™¯çš„é€‚åº”æ€§æœ‰é™ï¼Œå¹¶ä¸”ç¼ºä¹è¯­ä¹‰ç†è§£ï¼Œå¸¸å¸¸æ— æ³•ä¼˜å…ˆè€ƒè™‘è§†è§‰ä¸Šé‡è¦çš„åŒºåŸŸã€‚æˆ‘ä»¬æå‡ºäº†DeepDetectï¼Œä¸€ç§æ™ºèƒ½çš„ã€ä¸€ä½“åŒ–çš„å¯†é›†å…³é”®ç‚¹æ£€æµ‹å™¨ï¼Œå®ƒåˆ©ç”¨æ·±åº¦å­¦ä¹ ç»Ÿä¸€äº†ç»å…¸æ£€æµ‹å™¨çš„ä¼˜åŠ¿ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬é€šè¿‡èåˆ7ä¸ªå…³é”®ç‚¹æ£€æµ‹å™¨å’Œ2ä¸ªè¾¹ç¼˜æ£€æµ‹å™¨çš„è¾“å‡ºï¼Œåˆ›å»ºground-truthæ©ç ï¼Œä»å›¾åƒä¸­çš„è§’ç‚¹å’Œæ–‘ç‚¹åˆ°æ˜¾è‘—è¾¹ç¼˜å’Œçº¹ç†ä¸­æå–ä¸åŒçš„è§†è§‰çº¿ç´¢ã€‚ç„¶åï¼Œä½¿ç”¨è¿™äº›æ©ç ä½œä¸ºæ ‡ç­¾ï¼Œè®­ç»ƒä¸€ä¸ªè½»é‡çº§ä¸”é«˜æ•ˆçš„æ¨¡å‹ï¼šESPNetï¼Œä½¿DeepDetectèƒ½å¤Ÿè¯­ä¹‰åœ°å…³æ³¨å›¾åƒï¼ŒåŒæ—¶ç”Ÿæˆé«˜åº¦å¯†é›†çš„å…³é”®ç‚¹ï¼Œè¿™äº›å…³é”®ç‚¹èƒ½å¤Ÿé€‚åº”ä¸åŒçš„å’Œè§†è§‰é€€åŒ–çš„æ¡ä»¶ã€‚åœ¨Oxford Affine Covariant Regionsæ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼ŒDeepDetectåœ¨å…³é”®ç‚¹å¯†åº¦ã€é‡å¤æ€§å’Œæ­£ç¡®åŒ¹é…çš„æ•°é‡æ–¹é¢è¶…è¿‡äº†å…¶ä»–æ£€æµ‹å™¨ï¼Œå®ç°äº†0.5143ï¼ˆå¹³å‡å…³é”®ç‚¹å¯†åº¦ï¼‰ã€0.9582ï¼ˆå¹³å‡é‡å¤æ€§ï¼‰å’Œ59,003ï¼ˆæ­£ç¡®åŒ¹é…æ•°ï¼‰çš„æœ€å¤§å€¼ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰å…³é”®ç‚¹æ£€æµ‹æ–¹æ³•åœ¨å…‰ç…§å˜åŒ–é€‚åº”æ€§ã€å…³é”®ç‚¹å¯†åº¦ã€åœºæ™¯é€‚åº”æ€§å’Œè¯­ä¹‰ç†è§£æ–¹é¢çš„ä¸è¶³ã€‚ä¼ ç»Ÿæ–¹æ³•å’Œç°æœ‰æ·±åº¦å­¦ä¹ æ–¹æ³•éš¾ä»¥å…¼é¡¾è¿™äº›æ–¹é¢ï¼Œå¯¼è‡´åœ¨å¤æ‚è§†è§‰ç¯å¢ƒä¸‹æ€§èƒ½ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ·±åº¦å­¦ä¹ èåˆå¤šç§ç»å…¸å…³é”®ç‚¹å’Œè¾¹ç¼˜æ£€æµ‹å™¨çš„ä¼˜åŠ¿ï¼Œä»è€Œè·å¾—æ›´é²æ£’ã€æ›´å¯†é›†çš„å…³é”®ç‚¹è¡¨ç¤ºï¼Œå¹¶èµ‹äºˆæ¨¡å‹ä¸€å®šçš„è¯­ä¹‰ç†è§£èƒ½åŠ›ã€‚é€šè¿‡æ¨¡ä»¿å¤šç§æ£€æµ‹å™¨çš„è¡Œä¸ºï¼Œæ¨¡å‹èƒ½å¤Ÿå­¦ä¹ åˆ°æ›´å…¨é¢çš„å›¾åƒç‰¹å¾ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDeepDetectçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼š1) Ground-truthæ©ç ç”Ÿæˆé˜¶æ®µï¼šèåˆ7ä¸ªå…³é”®ç‚¹æ£€æµ‹å™¨å’Œ2ä¸ªè¾¹ç¼˜æ£€æµ‹å™¨çš„è¾“å‡ºï¼Œç”Ÿæˆè®­ç»ƒæ‰€éœ€çš„ground-truthæ©ç ã€‚2) æ¨¡å‹è®­ç»ƒé˜¶æ®µï¼šä½¿ç”¨ESPNetä½œä¸ºåŸºç¡€ç½‘ç»œï¼Œä»¥ç”Ÿæˆçš„æ©ç ä½œä¸ºæ ‡ç­¾è¿›è¡Œè®­ç»ƒï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿé¢„æµ‹å¯†é›†çš„å…³é”®ç‚¹ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºèåˆäº†å¤šç§ç»å…¸æ£€æµ‹å™¨çš„ä¼˜åŠ¿ï¼Œå¹¶åˆ©ç”¨æ·±åº¦å­¦ä¹ è¿›è¡Œç«¯åˆ°ç«¯è®­ç»ƒã€‚è¿™ç§èåˆç­–ç•¥ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ åˆ°ä¸åŒæ£€æµ‹å™¨çš„äº’è¡¥ä¿¡æ¯ï¼Œä»è€Œæé«˜å…³é”®ç‚¹æ£€æµ‹çš„é²æ£’æ€§å’Œå¯†åº¦ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒDeepDetectå¹¶éä¾èµ–å•ä¸€çš„ç‰¹å¾æå–æ–¹å¼ï¼Œè€Œæ˜¯ç»¼åˆè€ƒè™‘äº†å¤šç§è§†è§‰çº¿ç´¢ã€‚

**å…³é”®è®¾è®¡**ï¼šGround-truthæ©ç çš„ç”Ÿæˆæ–¹å¼æ˜¯å…³é”®è®¾è®¡ä¹‹ä¸€ï¼Œé€šè¿‡èåˆå¤šç§æ£€æµ‹å™¨çš„è¾“å‡ºï¼Œå°½å¯èƒ½è¦†ç›–å›¾åƒä¸­çš„å„ç§å…³é”®ç‚¹å’Œè¾¹ç¼˜ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œé€‰æ‹©ESPNetä½œä¸ºåŸºç¡€ç½‘ç»œï¼Œä¿è¯äº†æ¨¡å‹çš„è½»é‡åŒ–å’Œé«˜æ•ˆæ€§ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿè‡³å…³é‡è¦ï¼Œéœ€è¦å¹³è¡¡å…³é”®ç‚¹å¯†åº¦å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

DeepDetectåœ¨Oxford Affine Covariant Regionsæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå¹³å‡å…³é”®ç‚¹å¯†åº¦è¾¾åˆ°0.5143ï¼Œå¹³å‡é‡å¤æ€§è¾¾åˆ°0.9582ï¼Œæ­£ç¡®åŒ¹é…æ•°é‡è¾¾åˆ°59,003ï¼Œå‡ä¼˜äºå…¶ä»–å¯¹æ¯”æ–¹æ³•ã€‚è¿™äº›ç»“æœè¡¨æ˜DeepDetectåœ¨å…³é”®ç‚¹æ£€æµ‹æ–¹é¢å…·æœ‰å¾ˆå¼ºçš„ç«äº‰åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

DeepDetectåœ¨å›¾åƒé…å‡†ã€ä¸‰ç»´é‡å»ºã€è§†è§‰SLAMç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚é«˜å¯†åº¦ã€é«˜é‡å¤æ€§çš„å…³é”®ç‚¹æ£€æµ‹ç»“æœå¯ä»¥æé«˜è¿™äº›ä»»åŠ¡çš„ç²¾åº¦å’Œé²æ£’æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥åº”ç”¨äºç›®æ ‡è¯†åˆ«ã€å›¾åƒæ£€ç´¢ç­‰é¢†åŸŸï¼Œæå‡ç›¸å…³åº”ç”¨çš„æ€§èƒ½ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Keypoint detection is the foundation of many computer vision tasks, including image registration, structure-from motion, 3D reconstruction, visual odometry, and SLAM. Traditional detectors (SIFT, SURF, ORB, BRISK, etc.) and learning based methods (SuperPoint, R2D2, LF-Net, D2-Net, etc.) have shown strong performance yet suffer from key limitations: sensitivity to photometric changes, low keypoint density and repeatability, limited adaptability to challenging scenes, and lack of semantic understanding, often failing to prioritize visually important regions. We present DeepDetect, an intelligent, all-in-one, dense keypoint detector that unifies the strengths of classical detectors using deep learning. Firstly, we create ground-truth masks by fusing outputs of 7 keypoint and 2 edge detectors, extracting diverse visual cues from corners and blobs to prominent edges and textures in the images. Afterwards, a lightweight and efficient model: ESPNet, is trained using these masks as labels, enabling DeepDetect to focus semantically on images while producing highly dense keypoints, that are adaptable to diverse and visually degraded conditions. Evaluations on the Oxford Affine Covariant Regions dataset demonstrate that DeepDetect surpasses other detectors in keypoint density, repeatability, and the number of correct matches, achieving maximum values of 0.5143 (average keypoint density), 0.9582 (average repeatability), and 59,003 (correct matches).

