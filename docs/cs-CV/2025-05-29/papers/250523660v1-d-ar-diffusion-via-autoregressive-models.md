---
layout: default
title: "D-AR: Diffusion via Autoregressive Models"
---

# D-AR: Diffusion via Autoregressive Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.23660" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.23660v1</a>
  <a href="https://arxiv.org/pdf/2505.23660.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.23660v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.23660v1', 'D-AR: Diffusion via Autoregressive Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ziteng Gao, Mike Zheng Shou

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-29

**å¤‡æ³¨**: Technical report

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/showlab/D-AR)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºD-ARä»¥é‡æ„å›¾åƒæ‰©æ•£è¿‡ç¨‹ä¸ºè‡ªå›å½’æ¨¡å‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å›¾åƒç”Ÿæˆ` `è‡ªå›å½’æ¨¡å‹` `æ‰©æ•£è¿‡ç¨‹` `ç¦»æ•£æ ‡è®°` `è§†è§‰åˆæˆ` `æ·±åº¦å­¦ä¹ ` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å›¾åƒç”Ÿæˆæ–¹æ³•åœ¨æ‰©æ•£è¿‡ç¨‹çš„å»ºæ¨¡ä¸Šå­˜åœ¨å¤æ‚æ€§å’Œæ•ˆç‡ä½ä¸‹çš„é—®é¢˜ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡è‡ªå›å½’æ¨¡å‹å°†å›¾åƒæ‰©æ•£è¿‡ç¨‹ç®€åŒ–ä¸ºæ ‡å‡†çš„ä¸‹ä¸€ä¸ªæ ‡è®°é¢„æµ‹ï¼Œè®¾è®¡äº†é€‚åˆçš„åˆ†è¯å™¨ã€‚
3. åœ¨ImageNetåŸºå‡†æµ‹è¯•ä¸­ï¼ŒD-ARæ–¹æ³•è¾¾åˆ°äº†2.09çš„FIDï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•æœ‰æ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„èŒƒå¼â€”â€”é€šè¿‡è‡ªå›å½’æ¨¡å‹è¿›è¡Œæ‰©æ•£ï¼ˆD-ARï¼‰ï¼Œå°†å›¾åƒæ‰©æ•£è¿‡ç¨‹é‡æ–°æ„å»ºä¸ºæ ‡å‡†çš„ä¸‹ä¸€ä¸ªæ ‡è®°é¢„æµ‹çš„è‡ªå›å½’ç¨‹åºã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ç§åˆ†è¯å™¨ï¼Œå°†å›¾åƒè½¬æ¢ä¸ºç¦»æ•£æ ‡è®°åºåˆ—ï¼Œä¸åŒä½ç½®çš„æ ‡è®°å¯ä»¥è§£ç ä¸ºåƒç´ ç©ºé—´ä¸­çš„ä¸åŒæ‰©æ•£å»å™ªæ­¥éª¤ã€‚å¾—ç›Šäºæ‰©æ•£ç‰¹æ€§ï¼Œè¿™äº›æ ‡è®°è‡ªç„¶éµå¾ªç²—åˆ°ç»†çš„é¡ºåºï¼Œé€‚åˆè‡ªå›å½’å»ºæ¨¡ã€‚æˆ‘ä»¬åœ¨æ ‡å‡†çš„ImageNetåŸºå‡†ä¸Šï¼Œä½¿ç”¨775Mçš„Llamaéª¨å¹²ç½‘ç»œå’Œ256ä¸ªç¦»æ•£æ ‡è®°ï¼Œè¾¾åˆ°äº†2.09çš„FIDã€‚å¸Œæœ›æˆ‘ä»¬çš„å·¥ä½œèƒ½æ¿€å‘æœªæ¥åœ¨è§†è§‰åˆæˆç»Ÿä¸€è‡ªå›å½’æ¶æ„æ–¹é¢çš„ç ”ç©¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å›¾åƒç”Ÿæˆæ–¹æ³•åœ¨æ‰©æ•£è¿‡ç¨‹ä¸­çš„å¤æ‚æ€§å’Œæ•ˆç‡é—®é¢˜ï¼Œä¼ ç»Ÿæ–¹æ³•å¾€å¾€éœ€è¦å¤æ‚çš„è®¾è®¡å’Œè®­ç»ƒç­–ç•¥ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šD-ARé€šè¿‡å°†å›¾åƒæ‰©æ•£è¿‡ç¨‹è½¬åŒ–ä¸ºè‡ªå›å½’æ¨¡å‹çš„ä¸‹ä¸€ä¸ªæ ‡è®°é¢„æµ‹ï¼Œç®€åŒ–äº†ç”Ÿæˆæµç¨‹ï¼Œåˆ©ç”¨åˆ†è¯å™¨å°†å›¾åƒè½¬åŒ–ä¸ºç¦»æ•£æ ‡è®°åºåˆ—ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬åˆ†è¯å™¨ã€æ ‡è®°åºåˆ—ç”Ÿæˆå’Œè§£ç æ¨¡å—ã€‚åˆ†è¯å™¨å°†å›¾åƒè½¬æ¢ä¸ºç¦»æ•£æ ‡è®°ï¼Œéšåé€šè¿‡è‡ªå›å½’æ¨¡å‹ç”Ÿæˆæ ‡è®°ï¼Œæœ€åå°†ç”Ÿæˆçš„æ ‡è®°è§£ç ä¸ºæ‰©æ•£å»å™ªæ­¥éª¤ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†å›¾åƒæ‰©æ•£è¿‡ç¨‹ä¸è‡ªå›å½’å»ºæ¨¡ç›¸ç»“åˆï¼Œåˆ©ç”¨æ‰©æ•£ç‰¹æ€§ä½¿å¾—æ ‡è®°ç”Ÿæˆéµå¾ªç²—åˆ°ç»†çš„é¡ºåºï¼Œç›´æ¥åæ˜ æ‰©æ•£è¿‡ç¨‹ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œä½¿ç”¨775Mçš„Llamaéª¨å¹²ç½‘ç»œå’Œ256ä¸ªç¦»æ•£æ ‡è®°ï¼Œä¿æŒäº†è®­ç»ƒå’Œæ¨ç†ç­–ç•¥çš„æ ‡å‡†åŒ–ï¼Œç¡®ä¿äº†ç”Ÿæˆè¿‡ç¨‹çš„é«˜æ•ˆæ€§å’Œä¸€è‡´æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨æ ‡å‡†ImageNetåŸºå‡†æµ‹è¯•ä¸­ï¼ŒD-ARæ–¹æ³•è¾¾åˆ°äº†2.09çš„FIDï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•æœ‰æ˜¾è‘—æå‡ï¼Œå±•ç¤ºäº†å…¶åœ¨å›¾åƒç”Ÿæˆä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§å’Œæ½œåŠ›ã€‚è¯¥æ–¹æ³•çš„è®¾è®¡ä½¿å¾—ç”Ÿæˆè¿‡ç¨‹æ›´åŠ é«˜æ•ˆä¸”ä¸€è‡´ï¼Œæ”¯æŒé›¶-shotå¸ƒå±€æ§åˆ¶åˆæˆã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å›¾åƒç”Ÿæˆã€è§†é¢‘åˆæˆå’Œè®¡ç®—æœºè§†è§‰ä¸­çš„å„ç§ä»»åŠ¡ã€‚é€šè¿‡ç®€åŒ–æ‰©æ•£è¿‡ç¨‹ï¼ŒD-ARå¯ä»¥æé«˜ç”Ÿæˆæ¨¡å‹çš„æ•ˆç‡å’Œæ•ˆæœï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼ã€‚æœªæ¥ï¼Œéšç€å¤§è¯­è¨€æ¨¡å‹çš„è¿›ä¸€æ­¥å‘å±•ï¼ŒD-ARå¯èƒ½ä¼šåœ¨è§†è§‰åˆæˆé¢†åŸŸäº§ç”Ÿæ›´æ·±è¿œçš„å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper presents Diffusion via Autoregressive models (D-AR), a new paradigm recasting the image diffusion process as a vanilla autoregressive procedure in the standard next-token-prediction fashion. We start by designing the tokenizer that converts images into sequences of discrete tokens, where tokens in different positions can be decoded into different diffusion denoising steps in the pixel space. Thanks to the diffusion properties, these tokens naturally follow a coarse-to-fine order, which directly lends itself to autoregressive modeling. Therefore, we apply standard next-token prediction on these tokens, without modifying any underlying designs (either causal masks or training/inference strategies), and such sequential autoregressive token generation directly mirrors the diffusion procedure in image space. That is, once the autoregressive model generates an increment of tokens, we can directly decode these tokens into the corresponding diffusion denoising step in the streaming manner. Our pipeline naturally reveals several intriguing properties, for example, it supports consistent previews when generating only a subset of tokens and enables zero-shot layout-controlled synthesis. On the standard ImageNet benchmark, our method achieves 2.09 FID using a 775M Llama backbone with 256 discrete tokens. We hope our work can inspire future research on unified autoregressive architectures of visual synthesis, especially with large language models. Code and models will be available at https://github.com/showlab/D-AR

