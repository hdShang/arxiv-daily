---
layout: default
title: ScaleLong: A Multi-Timescale Benchmark for Long Video Understanding
---

# ScaleLong: A Multi-Timescale Benchmark for Long Video Understanding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.23922" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.23922v1</a>
  <a href="https://arxiv.org/pdf/2505.23922.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.23922v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.23922v1', 'ScaleLong: A Multi-Timescale Benchmark for Long Video Understanding')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: David Ma, Huaqing Yuan, Xingjian Wang, Qianbo Zang, Tianci Liu, Xinyang He, Yanbin Wei, Jiawei Guo, Ni Jiahui, Zhenzhu Yang, Meng Cao, Shanghaoran Quan, Yizhi Li, Wangchunshu Zhou, Jiaheng Liu, Wenhao Huang, Ge Zhang, Shiwen Ni, Xiaojie Jin

**ÂàÜÁ±ª**: cs.CV, cs.CL

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-29

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/multimodal-art-projection/ScaleLong)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫ScaleLongÂü∫ÂáÜ‰ª•Ëß£ÂÜ≥ÈïøËßÜÈ¢ëÁêÜËß£‰∏≠ÁöÑÂ§öÊó∂Èó¥Â∞∫Â∫¶ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÈïøËßÜÈ¢ëÁêÜËß£` `Â§öÊó∂Èó¥Â∞∫Â∫¶` `Âü∫ÂáÜÊµãËØï` `Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã` `ËßÜÈ¢ëÂàÜÊûê` `ÂÜÖÂÆπÊé®Ëçê` `Êô∫ËÉΩÊëòË¶Å`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÈïøËßÜÈ¢ëÁêÜËß£ÊñπÊ≥ïÂæÄÂæÄÂøΩËßÜÂ§öÊó∂Èó¥Â∞∫Â∫¶ËÆæËÆ°ÔºåÂØºËá¥Êó†Ê≥ïÂú®Áõ∏ÂêåËßÜÈ¢ëÂÜÖÂÆπ‰∏äËøõË°åÊúâÊïàÁöÑÊ®°ÂûãÊÄßËÉΩÊØîËæÉ„ÄÇ
2. Êú¨ÊñáÊèêÂá∫ScaleLongÂü∫ÂáÜÔºåÈÄöËøáÂú®Âêå‰∏ÄËßÜÈ¢ë‰∏≠ÂµåÂÖ•ÈíàÂØπ‰∏çÂêåÊó∂Èó¥Â∞∫Â∫¶ÁöÑÈóÆÈ¢òÔºåËß£ÂÜ≥‰∫ÜÂ§öÂ∞∫Â∫¶ÊØîËæÉÁöÑÊåëÊàò„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫Ôºå23‰∏™Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÊÄßËÉΩÂëàUÂûãÊõ≤Á∫øÔºåËßÜËßâÊ†áËÆ∞ÂÆπÈáèÁöÑÂ¢ûÂä†ÊòæËëóÊèêÂçá‰∫ÜÊé®ÁêÜËÉΩÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÈïøËßÜÈ¢ëÁêÜËß£Ë¶ÅÊ±ÇÊ®°ÂûãÊçïÊçâÂ±ÇÊ¨°ÂåñÁöÑÊó∂Èó¥‰ø°ÊÅØÔºåÂåÖÊã¨Ââ™ËæëÔºàÁßíÔºâ„ÄÅÈïúÂ§¥ÔºàÂçÅÁßíÔºâ„ÄÅ‰∫ã‰ª∂ÔºàÂàÜÈíüÔºâÂíåÊïÖ‰∫ãÔºàÂ∞èÊó∂Ôºâ„ÄÇÁé∞ÊúâÂü∫ÂáÜÂøΩËßÜ‰∫ÜËøôÁßçÂ§öÂ∞∫Â∫¶ËÆæËÆ°ÔºåÂØºËá¥Êó†Ê≥ïÂú®Áõ∏ÂêåÂÜÖÂÆπ‰∏äÁõ¥Êé•ÊØîËæÉÊ®°ÂûãÊÄßËÉΩ„ÄÇ‰∏∫Ê≠§ÔºåÊú¨ÊñáÊèêÂá∫ScaleLongÔºåËøôÊòØÁ¨¨‰∏Ä‰∏™ÈÄöËøáÂú®Âêå‰∏ÄËßÜÈ¢ëÂÜÖÂÆπ‰∏≠ÂµåÂÖ•ÈíàÂØπÂõõ‰∏™Â±ÇÊ¨°Êó∂Èó¥Â∞∫Â∫¶ÁöÑÈóÆÈ¢òÊù•Ëß£ÂÜ≥Ëøô‰∏ÄÈóÆÈ¢òÁöÑÂü∫ÂáÜ„ÄÇScaleLongÂåÖÂê´269‰∏™ÈïøËßÜÈ¢ëÔºåÂπ≥ÂùáÊó∂Èïø86ÂàÜÈíüÔºåÊ∂µÁõñ5‰∏™‰∏ªË¶ÅÁ±ªÂà´Âíå36‰∏™Â≠êÁ±ªÂà´ÔºåÊØè‰∏™ËßÜÈ¢ëËÆæËÆ°4Âà∞8‰∏™ÈóÆÈ¢òÔºåÁ°Æ‰øùÊØè‰∏™Êó∂Èó¥Â∞∫Â∫¶Ëá≥Â∞ëÊúâ‰∏Ä‰∏™ÈóÆÈ¢ò„ÄÇÂØπ23‰∏™Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑËØÑ‰º∞ÊòæÁ§∫Âá∫UÂûãÊÄßËÉΩÊõ≤Á∫øÔºåÁü≠Êó∂Èó¥Â∞∫Â∫¶ÂíåÈïøÊó∂Èó¥Â∞∫Â∫¶ÁöÑÂáÜÁ°ÆÁéáËæÉÈ´òÔºåËÄå‰∏≠Èó¥Ê∞¥Âπ≥ÂàôÊúâÊâÄ‰∏ãÈôç„ÄÇÊ≠§Â§ñÔºåÊ∂àËûçÁ†îÁ©∂Ë°®ÊòéÔºåÂ¢ûÂä†ËßÜËßâÊ†áËÆ∞ÂÆπÈáèËÉΩÊåÅÁª≠ÊèêÂçáÂêÑÊó∂Èó¥Â∞∫Â∫¶ÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇScaleLong‰∏∫ÊèêÂçáÈïøËßÜÈ¢ëÁêÜËß£‰∏≠ÁöÑÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãËÉΩÂäõÊèê‰æõ‰∫ÜÁªÜÁ≤íÂ∫¶ÁöÑÂ§öÊó∂Èó¥Â∞∫Â∫¶Âü∫ÂáÜ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥ÈïøËßÜÈ¢ëÁêÜËß£‰∏≠Áº∫‰πèÊúâÊïàÂ§öÊó∂Èó¥Â∞∫Â∫¶ÊØîËæÉÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂæÄÂæÄÂ∞ÜÂ∞∫Â∫¶ÁâπÂÆöÁöÑÈóÆÈ¢òÂàÜÊï£Âú®‰∏çÂêåËßÜÈ¢ë‰∏≠ÔºåÊó†Ê≥ïÁõ¥Êé•ÊØîËæÉÊ®°ÂûãÂú®Áõ∏ÂêåÂÜÖÂÆπ‰∏äÁöÑË°®Áé∞„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöScaleLongÂü∫ÂáÜÈÄöËøáÂú®Âêå‰∏ÄËßÜÈ¢ëÂÜÖÂÆπ‰∏≠ËÆæËÆ°ÈíàÂØπÂõõ‰∏™Â±ÇÊ¨°Êó∂Èó¥Â∞∫Â∫¶ÔºàÂâ™Ëæë„ÄÅÈïúÂ§¥„ÄÅ‰∫ã‰ª∂ÂíåÊïÖ‰∫ãÔºâÁöÑÈóÆÈ¢òÔºåÊèê‰æõ‰∫Ü‰∏Ä‰∏™Áªü‰∏ÄÁöÑËØÑ‰º∞Ê°ÜÊû∂Ôºå‰ΩøÂæó‰∏çÂêåÊ®°ÂûãÂú®Áõ∏ÂêåËßÜÈ¢ë‰∏äÁöÑÊÄßËÉΩÂèØ‰ª•Áõ¥Êé•ÊØîËæÉ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöScaleLongÂåÖÂê´269‰∏™ÈïøËßÜÈ¢ëÔºåÂπ≥ÂùáÊó∂Èïø86ÂàÜÈíüÔºåË¶ÜÁõñ5‰∏™‰∏ªË¶ÅÁ±ªÂà´Âíå36‰∏™Â≠êÁ±ªÂà´„ÄÇÊØè‰∏™ËßÜÈ¢ëËÆæËÆ°4Âà∞8‰∏™ÈóÆÈ¢òÔºåÁ°Æ‰øùÊØè‰∏™Êó∂Èó¥Â∞∫Â∫¶Ëá≥Â∞ëÊúâ‰∏Ä‰∏™ÈóÆÈ¢ò„ÄÇËØÑ‰º∞ËøáÁ®ã‰∏≠Ôºå‰ΩøÁî®23‰∏™Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãËøõË°åÊÄßËÉΩÊµãËØï„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöScaleLongÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÂÖ∂Â§öÊó∂Èó¥Â∞∫Â∫¶ÁöÑÈóÆÈ¢òËÆæËÆ°Ôºå‰ΩøÂæóÊ®°ÂûãÂú®Áõ∏ÂêåËßÜÈ¢ëÂÜÖÂÆπ‰∏äÁöÑË°®Áé∞ÂèØ‰ª•Ë¢´Áõ¥Êé•ÊØîËæÉ„ÄÇËøô‰∏ÄËÆæËÆ°Á™ÅÁ†¥‰∫ÜÁé∞ÊúâÂü∫ÂáÜÁöÑÂ±ÄÈôêÊÄßÔºåÊèê‰æõ‰∫ÜÊõ¥‰∏∫ÁªÜËá¥ÁöÑËØÑ‰º∞Ê†áÂáÜ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÂÆûÈ™å‰∏≠ÔºåÂ¢ûÂä†ËßÜËßâÊ†áËÆ∞ÁöÑÂÆπÈáèË¢´ËØÅÊòéËÉΩÂ§üÊåÅÁª≠ÊèêÂçáÊ®°ÂûãÂú®ÂêÑÊó∂Èó¥Â∞∫Â∫¶‰∏äÁöÑÊé®ÁêÜËÉΩÂäõÔºå‰∏îËØÑ‰º∞ÁªìÊûúÂëàÁé∞Âá∫UÂûãÊÄßËÉΩÊõ≤Á∫øÔºåÁü≠Êó∂Èó¥Â∞∫Â∫¶ÂíåÈïøÊó∂Èó¥Â∞∫Â∫¶ÁöÑÂáÜÁ°ÆÁéáËæÉÈ´òÔºåËÄå‰∏≠Èó¥Êó∂Èó¥Â∞∫Â∫¶ÁöÑË°®Áé∞Áõ∏ÂØπËæÉ‰Ωé„ÄÇÂÆûÈ™åËøòË°®ÊòéÔºåËÆæËÆ°ÈóÆÈ¢òÊó∂ÁöÑÁªÜËá¥ËÄÉËôëÂØπÊ®°ÂûãÊÄßËÉΩÊúâÊòæËëóÂΩ±Âìç„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®ÂØπ23‰∏™Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑËØÑ‰º∞‰∏≠ÔºåScaleLongÂ±ïÁé∞Âá∫UÂûãÊÄßËÉΩÊõ≤Á∫øÔºåÁü≠Êó∂Èó¥Â∞∫Â∫¶ÂíåÈïøÊó∂Èó¥Â∞∫Â∫¶ÁöÑÂáÜÁ°ÆÁéáÊòæËëóÈ´ò‰∫é‰∏≠Èó¥Êó∂Èó¥Â∞∫Â∫¶„ÄÇÊ≠§Â§ñÔºåÂ¢ûÂä†ËßÜËßâÊ†áËÆ∞ÂÆπÈáèÁöÑÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊé®ÁêÜËÉΩÂäõÂú®ÊâÄÊúâÊó∂Èó¥Â∞∫Â∫¶‰∏äÂùáÂæóÂà∞‰∫ÜÊèêÂçáÔºåÈ™åËØÅ‰∫ÜËØ•Âü∫ÂáÜÁöÑÊúâÊïàÊÄßÂíåÂÆûÁî®ÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ScaleLongÂü∫ÂáÜÁöÑÊèêÂá∫‰∏∫ÈïøËßÜÈ¢ëÁêÜËß£È¢ÜÂüüÊèê‰æõ‰∫ÜÊñ∞ÁöÑËØÑ‰º∞Ê†áÂáÜÔºåÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõ„ÄÇÂÆÉÂèØ‰ª•Áî®‰∫éÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑËÆ≠ÁªÉ‰∏éËØÑ‰º∞ÔºåÊé®Âä®Êô∫ËÉΩËßÜÈ¢ëÂàÜÊûê„ÄÅÂÜÖÂÆπÊé®ËçêÂèäËá™Âä®ÊëòË¶ÅÁ≠âÈ¢ÜÂüüÁöÑÂèëÂ±ï„ÄÇÊú™Êù•ÔºåÈöèÁùÄÈïøËßÜÈ¢ëÂÜÖÂÆπÁöÑÊó•ÁõäÂ¢ûÂä†ÔºåËØ•Âü∫ÂáÜÂ∞ÜÂØπÁõ∏ÂÖ≥Á†îÁ©∂ÂíåÂ∫îÁî®‰∫ßÁîüÊ∑±ËøúÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Although long-video understanding demands that models capture hierarchical temporal information -- from clip (seconds) and shot (tens of seconds) to event (minutes) and story (hours) -- existing benchmarks either neglect this multi-scale design or scatter scale-specific questions across different videos, preventing direct comparison of model performance across timescales on the same content. To address this, we introduce ScaleLong, the first benchmark to disentangle these factors by embedding questions targeting four hierarchical timescales -- clip (seconds), shot (tens of seconds), event (minutes), and story (hours) -- all within the same video content. This within-content multi-timescale questioning design enables direct comparison of model performance across timescales on identical videos. ScaleLong features 269 long videos (avg.\ 86\,min) from 5 main categories and 36 sub-categories, with 4--8 carefully designed questions, including at least one question for each timescale. Evaluating 23 MLLMs reveals a U-shaped performance curve, with higher accuracy at the shortest and longest timescales and a dip at intermediate levels. Furthermore, ablation studies show that increased visual token capacity consistently enhances reasoning across all timescales. ScaleLong offers a fine-grained, multi-timescale benchmark for advancing MLLM capabilities in long-video understanding. The code and dataset are available https://github.com/multimodal-art-projection/ScaleLong.

