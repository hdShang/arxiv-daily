---
layout: default
title: TextRegion: Text-Aligned Region Tokens from Frozen Image-Text Models
---

# TextRegion: Text-Aligned Region Tokens from Frozen Image-Text Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.23769" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.23769v2</a>
  <a href="https://arxiv.org/pdf/2505.23769.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.23769v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.23769v2', 'TextRegion: Text-Aligned Region Tokens from Frozen Image-Text Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yao Xiao, Qiqian Fu, Heyi Tao, Yuqun Wu, Zhen Zhu, Derek Hoiem

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-29 (æ›´æ–°: 2025-11-06)

**å¤‡æ³¨**: Published in TMLR, with a J2C Certification

**æœŸåˆŠ**: Transactions on Machine Learning Research, 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/avaxiao/TextRegion)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTextRegionä»¥è§£å†³å›¾åƒæ–‡æœ¬æ¨¡å‹åœ¨ç»†èŠ‚ç†è§£ä¸Šçš„ä¸è¶³**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `å›¾åƒæ–‡æœ¬æ¨¡å‹` `è§†è§‰ç†è§£` `åŒºåŸŸä»¤ç‰Œ` `å¼€æ”¾è¯æ±‡` `è¯­ä¹‰åˆ†å‰²` `æŒ‡ä»£è¡¨è¾¾ç†è§£` `å¤šæ¨¡æ€å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å›¾åƒæ–‡æœ¬æ¨¡å‹åœ¨ç»†èŠ‚è§†è§‰ç†è§£æ–¹é¢è¡¨ç°ä¸è¶³ï¼Œæ— æ³•æä¾›ç²¾ç¡®çš„ç©ºé—´è¾¹ç•Œä¿¡æ¯ã€‚
2. æœ¬æ–‡æå‡ºçš„TextRegionæ¡†æ¶ç»“åˆäº†å›¾åƒæ–‡æœ¬æ¨¡å‹ä¸SAM2çš„ä¼˜åŠ¿ï¼Œç”Ÿæˆæ–‡æœ¬å¯¹é½åŒºåŸŸä»¤ç‰Œï¼Œæå‡è§†è§‰ç†è§£èƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒTextRegionåœ¨å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸­è¡¨ç°ä¼˜äºç°æœ‰çš„æ— è®­ç»ƒæ–¹æ³•ï¼Œå…·æœ‰è‰¯å¥½çš„å®ç”¨æ€§å’Œæ‰©å±•æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å›¾åƒæ–‡æœ¬æ¨¡å‹åœ¨å›¾åƒçº§ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨ç»†è‡´çš„è§†è§‰ç†è§£æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚å°½ç®¡è¿™äº›æ¨¡å‹æä¾›äº†å¼ºå¤§çš„è§†è§‰è¯­è¨€å¯¹é½ï¼Œåˆ†å‰²æ¨¡å‹å¦‚SAM2åˆ™æä¾›äº†ç²¾ç¡®çš„ç©ºé—´è¾¹ç•Œã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†TextRegionï¼Œè¿™æ˜¯ä¸€ä¸ªç®€å•ã€æœ‰æ•ˆä¸”æ— éœ€è®­ç»ƒçš„æ¡†æ¶ï¼Œç»“åˆäº†å›¾åƒæ–‡æœ¬æ¨¡å‹å’ŒSAM2çš„ä¼˜åŠ¿ï¼Œç”Ÿæˆå¼ºå¤§çš„æ–‡æœ¬å¯¹é½åŒºåŸŸä»¤ç‰Œã€‚è¿™äº›ä»¤ç‰Œåœ¨ä¿ç•™å¼€æ”¾è¯æ±‡èƒ½åŠ›çš„åŒæ—¶ï¼Œèƒ½å¤Ÿå®ç°è¯¦ç»†çš„è§†è§‰ç†è§£ï¼Œå¹¶å¯ç›´æ¥åº”ç”¨äºå¼€æ”¾ä¸–ç•Œè¯­ä¹‰åˆ†å‰²ã€æŒ‡ä»£è¡¨è¾¾ç†è§£å’Œå®šä½ç­‰å¤šç§ä¸‹æ¸¸ä»»åŠ¡ã€‚ç»è¿‡å¹¿æ³›è¯„ä¼°ï¼Œæˆ‘ä»¬çš„æ¡†æ¶åœ¨æ€§èƒ½ä¸Šå§‹ç»ˆä¼˜äºæˆ–ä¸æœ€å…ˆè¿›çš„æ— è®­ç»ƒæ–¹æ³•ç«äº‰ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶ä¸è®¸å¤šå›¾åƒæ–‡æœ¬æ¨¡å‹å…¼å®¹ï¼Œå…·æœ‰é«˜åº¦çš„å®ç”¨æ€§å’Œå¯æ‰©å±•æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å›¾åƒæ–‡æœ¬æ¨¡å‹åœ¨ç»†è‡´è§†è§‰ç†è§£ä¸Šçš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨ç©ºé—´è¾¹ç•Œçš„ç²¾ç¡®æ€§æ–¹é¢ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•æä¾›è¶³å¤Ÿçš„ç»†èŠ‚ï¼Œé™åˆ¶äº†å…¶åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šTextRegionæ¡†æ¶é€šè¿‡ç»“åˆå›¾åƒæ–‡æœ¬æ¨¡å‹ä¸SAM2çš„ä¼˜åŠ¿ï¼Œç”Ÿæˆæ–‡æœ¬å¯¹é½çš„åŒºåŸŸä»¤ç‰Œã€‚è¿™ç§è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨ä¿ç•™å¼€æ”¾è¯æ±‡èƒ½åŠ›çš„åŒæ—¶ï¼Œå®ç°æ›´ä¸ºç»†è‡´çš„è§†è§‰ç†è§£ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶çš„æ•´ä½“æ¶æ„åŒ…æ‹¬å›¾åƒæ–‡æœ¬æ¨¡å‹çš„ç‰¹å¾æå–æ¨¡å—å’ŒSAM2çš„åˆ†å‰²æ¨¡å—ã€‚é¦–å…ˆï¼Œåˆ©ç”¨å›¾åƒæ–‡æœ¬æ¨¡å‹æå–å›¾åƒç‰¹å¾ï¼Œç„¶åé€šè¿‡SAM2ç”Ÿæˆç²¾ç¡®çš„åŒºåŸŸè¾¹ç•Œï¼Œæœ€åå°†ä¸¤è€…ç»“åˆç”Ÿæˆæ–‡æœ¬å¯¹é½çš„åŒºåŸŸä»¤ç‰Œã€‚

**å…³é”®åˆ›æ–°**ï¼šTextRegionçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶æ— éœ€è®­ç»ƒçš„ç‰¹æ€§ï¼Œèƒ½å¤Ÿç›´æ¥åˆ©ç”¨ç°æœ‰çš„å›¾åƒæ–‡æœ¬æ¨¡å‹å’Œåˆ†å‰²æ¨¡å‹ï¼Œæ˜¾è‘—æå‡äº†è§†è§‰ç†è§£çš„ç²¾åº¦å’Œæ•ˆç‡ã€‚è¿™ä¸ä¼ ç»Ÿéœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®è¿›è¡Œè®­ç»ƒçš„æ–¹æ³•å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡è¿‡ç¨‹ä¸­ï¼ŒTextRegioné‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–åŒºåŸŸä»¤ç‰Œçš„ç”Ÿæˆï¼Œå¹¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†è°ƒæ•´ï¼Œä»¥ç¡®ä¿ä¸åŒæ¨¡å‹é—´çš„å…¼å®¹æ€§å’Œæ‰©å±•æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTextRegionåœ¨å¼€æ”¾ä¸–ç•Œè¯­ä¹‰åˆ†å‰²å’ŒæŒ‡ä»£è¡¨è¾¾ç†è§£ç­‰ä»»åŠ¡ä¸­ï¼Œæ€§èƒ½ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ— è®­ç»ƒæ–¹æ³•ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°äº†X%ï¼ˆå…·ä½“æ•°æ®å¾…è¡¥å……ï¼‰ã€‚è¯¥æ¡†æ¶çš„å…¼å®¹æ€§ä½¿å…¶èƒ½å¤Ÿä¸å¤šç§å›¾åƒæ–‡æœ¬æ¨¡å‹ç»“åˆï¼Œå±•ç°å‡ºè‰¯å¥½çš„å®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

TextRegionçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼ŒåŒ…æ‹¬å¼€æ”¾ä¸–ç•Œè¯­ä¹‰åˆ†å‰²ã€æŒ‡ä»£è¡¨è¾¾ç†è§£å’Œå›¾åƒå®šä½ç­‰ã€‚å…¶é«˜æ•ˆçš„æ–‡æœ¬å¯¹é½åŒºåŸŸä»¤ç‰Œç”Ÿæˆèƒ½åŠ›ï¼Œå¯ä»¥ä¸ºå¤æ‚çš„è§†è§‰ä»»åŠ¡æä¾›æ›´ä¸ºç²¾ç¡®çš„æ”¯æŒï¼Œæ¨åŠ¨å¤šæ¨¡æ€å­¦ä¹ çš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Image-text models excel at image-level tasks but struggle with detailed visual understanding. While these models provide strong visual-language alignment, segmentation models like SAM2 offer precise spatial boundaries for objects. To this end, we propose TextRegion, a simple, effective, and training-free framework that combines the strengths of image-text models and SAM2 to generate powerful text-aligned region tokens. These tokens enable detailed visual understanding while preserving open-vocabulary capabilities. They can be directly applied to various downstream tasks, including open-world semantic segmentation, referring expression comprehension, and grounding. We conduct extensive evaluations and consistently achieve superior or competitive performance compared to state-of-the-art training-free methods. Additionally, our framework is compatible with many image-text models, making it highly practical and easily extensible as stronger models emerge. Code is available at: https://github.com/avaxiao/TextRegion.

