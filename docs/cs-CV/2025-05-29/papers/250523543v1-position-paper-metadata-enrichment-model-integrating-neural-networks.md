---
layout: default
title: Position Paper: Metadata Enrichment Model: Integrating Neural Networks and Semantic Knowledge Graphs for Cultural Heritage Applications
---

# Position Paper: Metadata Enrichment Model: Integrating Neural Networks and Semantic Knowledge Graphs for Cultural Heritage Applications

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.23543" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.23543v1</a>
  <a href="https://arxiv.org/pdf/2505.23543.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.23543v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.23543v1', 'Position Paper: Metadata Enrichment Model: Integrating Neural Networks and Semantic Knowledge Graphs for Cultural Heritage Applications')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jan Ignatowicz, Krzysztof Kutt, Grzegorz J. Nalepa

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-29

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå…ƒæ•°æ®å¢å¼ºæ¨¡å‹ä»¥è§£å†³æ–‡åŒ–é—äº§æ•°å­—åŒ–ä¸­çš„å…ƒæ•°æ®ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å…ƒæ•°æ®å¢å¼º` `æ–‡åŒ–é—äº§` `ç¥ç»ç½‘ç»œ` `çŸ¥è¯†å›¾è°±` `è®¡ç®—æœºè§†è§‰` `è¯­ä¹‰æŠ€æœ¯` `æ•°å­—åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ–‡åŒ–é—äº§æ•°å­—åŒ–æ–¹æ³•ç¼ºä¹ä¸°å¯Œçš„å…ƒæ•°æ®ï¼Œé™åˆ¶äº†å…¶å¯è®¿é—®æ€§å’Œäº’æ“ä½œæ€§ã€‚
2. æå‡ºçš„å…ƒæ•°æ®å¢å¼ºæ¨¡å‹ï¼ˆMEMï¼‰ç»“åˆäº†è®¡ç®—æœºè§†è§‰ã€è¯­è¨€æ¨¡å‹å’ŒçŸ¥è¯†å›¾è°±ï¼Œä»¥æé«˜å…ƒæ•°æ®çš„ä¸°å¯Œæ€§ã€‚
3. MEMåœ¨é›…ç›–éš†æ•°å­—å›¾ä¹¦é¦†çš„å¤ç±æ•°æ®é›†ä¸Šåº”ç”¨ï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…GLAMæœºæ„ä¸­çš„æœ‰æ•ˆæ€§å’Œçµæ´»æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ–‡åŒ–é—äº§æ”¶è—çš„æ•°å­—åŒ–ä¸ºç ”ç©¶å¼€è¾Ÿäº†æ–°æ–¹å‘ï¼Œä½†ç¼ºä¹ä¸°å¯Œçš„å…ƒæ•°æ®å¯¹å¯è®¿é—®æ€§ã€äº’æ“ä½œæ€§å’Œè·¨æœºæ„åˆä½œæ„æˆäº†é‡å¤§æŒ‘æˆ˜ã€‚è¿‘å¹´æ¥ï¼ŒYOLOv11å’ŒDetectron2ç­‰ç¥ç»ç½‘ç»œæ¨¡å‹åœ¨è§†è§‰æ•°æ®åˆ†æä¸­å–å¾—äº†é©å‘½æ€§è¿›å±•ï¼Œä½†åœ¨ç‰¹å®šé¢†åŸŸçš„æ–‡åŒ–é—äº§ï¼ˆå¦‚æ‰‹ç¨¿å’Œå¤ç±ï¼‰ä¸­ï¼Œç”±äºç¼ºä¹é’ˆå¯¹ç»“æ„ç‰¹å¾æå–å’Œè¯­ä¹‰äº’æ“ä½œæ€§çš„æ–¹æ³•ï¼Œå…¶åº”ç”¨ä»ç„¶æœ‰é™ã€‚æœ¬æ–‡æå‡ºäº†å…ƒæ•°æ®å¢å¼ºæ¨¡å‹ï¼ˆMEMï¼‰ï¼Œé€šè¿‡ç»“åˆå¾®è°ƒçš„è®¡ç®—æœºè§†è§‰æ¨¡å‹ã€å¤§å‹è¯­è¨€æ¨¡å‹å’Œç»“æ„åŒ–çŸ¥è¯†å›¾è°±ï¼Œæ—¨åœ¨ä¸°å¯Œæ•°å­—åŒ–æ”¶è—çš„å…ƒæ•°æ®ã€‚æˆ‘ä»¬å±•ç¤ºäº†MEMçš„æ½œåŠ›ï¼Œå¹¶åº”ç”¨äºé›…ç›–éš†æ•°å­—å›¾ä¹¦é¦†çš„æ•°å­—åŒ–å¤ç±æ•°æ®é›†ï¼Œå‘å¸ƒäº†105é¡µæ‰‹ç¨¿çš„æ‰‹åŠ¨æ³¨é‡Šæ•°æ®é›†ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ–‡åŒ–é—äº§æ•°å­—åŒ–è¿‡ç¨‹ä¸­å…ƒæ•°æ®ä¸è¶³çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨ç»“æ„ç‰¹å¾æå–å’Œè¯­ä¹‰äº’æ“ä½œæ€§æ–¹é¢å­˜åœ¨æ˜¾è‘—ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å°†ç¥ç»ç½‘ç»œä¸è¯­ä¹‰æŠ€æœ¯ç›¸ç»“åˆï¼ŒMEMæä¾›äº†ä¸€ç§æ–°çš„æ–¹æ³•è®ºï¼Œä»¥åŠ¨æ€æ£€æµ‹å’Œæå–æ–‡åŒ–é—äº§ä¸­çš„åµŒå¥—ç‰¹å¾ï¼Œä»è€Œå¢å¼ºå…ƒæ•°æ®çš„è´¨é‡å’Œä¸°å¯Œæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMEMçš„æ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼šé¦–å…ˆæ˜¯å¾®è°ƒçš„è®¡ç®—æœºè§†è§‰æ¨¡å‹ç”¨äºç‰¹å¾æå–ï¼Œå…¶æ¬¡æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ç”¨äºè¯­ä¹‰ç†è§£ï¼Œæœ€åæ˜¯ç»“æ„åŒ–çŸ¥è¯†å›¾è°±ç”¨äºå…ƒæ•°æ®çš„ç»„ç»‡å’Œå­˜å‚¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šMEMçš„å…³é”®åˆ›æ–°åœ¨äºå¤šå±‚è§†è§‰æœºåˆ¶ï¼ˆMVMï¼‰ï¼Œè¯¥æœºåˆ¶èƒ½å¤ŸåŠ¨æ€æ£€æµ‹åµŒå¥—ç‰¹å¾ï¼Œå¦‚å°ç« ä¸­çš„æ–‡æœ¬æˆ–å›¾åƒï¼Œä»è€Œæ˜¾è‘—æå‡è§†è§‰åˆ†æçš„èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸Šï¼ŒMEMé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–ç‰¹å¾æå–æ•ˆæœï¼Œå¹¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†é’ˆå¯¹æ–‡åŒ–é—äº§ç‰¹å¾çš„å¾®è°ƒï¼Œä»¥ç¡®ä¿æ¨¡å‹çš„æœ‰æ•ˆæ€§å’Œé€‚åº”æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼ŒMEMåœ¨é›…ç›–éš†æ•°å­—å›¾ä¹¦é¦†çš„å¤ç±æ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ï¼ŒæˆåŠŸå‘å¸ƒäº†105é¡µæ‰‹ç¨¿çš„æ‰‹åŠ¨æ³¨é‡Šæ•°æ®é›†ï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§å’Œçµæ´»æ€§ï¼Œæ˜¾è‘—æå‡äº†å…ƒæ•°æ®çš„è´¨é‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åšç‰©é¦†ã€å›¾ä¹¦é¦†å’Œæ¡£æ¡ˆé¦†ç­‰æ–‡åŒ–é—äº§æœºæ„ï¼Œèƒ½å¤Ÿé€šè¿‡ä¸°å¯Œçš„å…ƒæ•°æ®æå‡æ•°å­—åŒ–è—å“çš„å¯è®¿é—®æ€§å’Œäº’æ“ä½œæ€§ã€‚æœªæ¥ï¼ŒMEMæœ‰æœ›æ¨åŠ¨æ–‡åŒ–é—äº§ç ”ç©¶çš„è¿›æ­¥ï¼Œå¹¶ä¿ƒè¿›è·¨æœºæ„çš„åˆä½œä¸äº¤æµã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The digitization of cultural heritage collections has opened new directions for research, yet the lack of enriched metadata poses a substantial challenge to accessibility, interoperability, and cross-institutional collaboration. In several past years neural networks models such as YOLOv11 and Detectron2 have revolutionized visual data analysis, but their application to domain-specific cultural artifacts - such as manuscripts and incunabula - remains limited by the absence of methodologies that address structural feature extraction and semantic interoperability. In this position paper, we argue, that the integration of neural networks with semantic technologies represents a paradigm shift in cultural heritage digitization processes. We present the Metadata Enrichment Model (MEM), a conceptual framework designed to enrich metadata for digitized collections by combining fine-tuned computer vision models, large language models (LLMs) and structured knowledge graphs. The Multilayer Vision Mechanism (MVM) appears as the key innovation of MEM. This iterative process improves visual analysis by dynamically detecting nested features, such as text within seals or images within stamps. To expose MEM's potential, we apply it to a dataset of digitized incunabula from the Jagiellonian Digital Library and release a manually annotated dataset of 105 manuscript pages. We examine the practical challenges of MEM's usage in real-world GLAM institutions, including the need for domain-specific fine-tuning, the adjustment of enriched metadata with Linked Data standards and computational costs. We present MEM as a flexible and extensible methodology. This paper contributes to the discussion on how artificial intelligence and semantic web technologies can advance cultural heritage research, and also use these technologies in practice.

