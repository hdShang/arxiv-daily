---
layout: default
title: "Uni-MuMER: Unified Multi-Task Fine-Tuning of Vision-Language Model for Handwritten Mathematical Expression Recognition"
---

# Uni-MuMER: Unified Multi-Task Fine-Tuning of Vision-Language Model for Handwritten Mathematical Expression Recognition

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.23566" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.23566v4</a>
  <a href="https://arxiv.org/pdf/2505.23566.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.23566v4" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.23566v4', 'Uni-MuMER: Unified Multi-Task Fine-Tuning of Vision-Language Model for Handwritten Mathematical Expression Recognition')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Yu Li, Jin Jiang, Jianhua Zhu, Shuai Peng, Baole Wei, Yuxuan Zhou, Liangcai Gao

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-29 (Êõ¥Êñ∞: 2025-10-25)

**Â§áÊ≥®**: Accepted by NeurIPS 2025 as a spotlight

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/BFlameSwift/Uni-MuMER)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Uni-MuMER‰ª•Ëß£ÂÜ≥ÊâãÂÜôÊï∞Â≠¶Ë°®ËææÂºèËØÜÂà´ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÊâãÂÜôÊï∞Â≠¶ËØÜÂà´` `ËßÜËßâ-ËØ≠Ë®ÄÊ®°Âûã` `Â§ö‰ªªÂä°Â≠¶‰π†` `ÈîôËØØÈ©±Âä®Â≠¶‰π†` `Ê†ëÁä∂ÈìæÂºèÊÄùÁª¥` `Á¨¶Âè∑ËÆ°Êï∞` `ÂÖâÂ≠¶Â≠óÁ¨¶ËØÜÂà´`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ÊâãÂÜôÊï∞Â≠¶Ë°®ËææÂºèËØÜÂà´Èù¢‰∏¥Á¨¶Âè∑Â∏ÉÂ±ÄËá™Áî±Â∫¶È´òÂíå‰π¶ÂÜôÈ£éÊ†ºÂ§öÊ†∑ÊÄßÁöÑÈóÆÈ¢òÔºåÁé∞ÊúâÊñπÊ≥ïÈöæ‰ª•ÊúâÊïàÊï¥Âêà„ÄÇ
2. Uni-MuMERÈÄöËøáÂÖ®Èù¢ÂæÆË∞ÉËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÔºåÁªìÂêàÂ§ö‰∏™Êï∞ÊçÆÈ©±Âä®‰ªªÂä°ÔºåÊ≥®ÂÖ•È¢ÜÂüüÁü•ËØÜ‰ª•ÊèêÂçáËØÜÂà´ÊÄßËÉΩ„ÄÇ
3. Âú®CROHMEÂíåHME100KÊï∞ÊçÆÈõÜ‰∏äÔºåUni-MuMERÁöÑÊÄßËÉΩË∂ÖË∂ä‰∫ÜÁé∞ÊúâÊúÄ‰Ω≥Ê®°ÂûãÔºåÊòæÁ§∫Âá∫ÊòæËëóÁöÑÊèêÂçáÊïàÊûú„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÊâãÂÜôÊï∞Â≠¶Ë°®ËææÂºèËØÜÂà´ÔºàHMERÔºâÂú®ÂÖâÂ≠¶Â≠óÁ¨¶ËØÜÂà´ÔºàOCRÔºâ‰∏≠‰ªçÁÑ∂Èù¢‰∏¥ÊåëÊàòÔºå‰∏ªË¶ÅÁî±‰∫éÁ¨¶Âè∑Â∏ÉÂ±ÄÁöÑËá™Áî±Â∫¶Âíå‰π¶ÂÜôÈ£éÊ†ºÁöÑÂ§öÊ†∑ÊÄß„ÄÇ‰ª•ÂæÄÊñπÊ≥ïÈÄöËøáÂ≠§Á´ãÁöÑÊû∂ÊûÑ‰øÆÊîπÈù¢‰∏¥ÊÄßËÉΩÁì∂È¢àÔºåÈöæ‰ª•Êï¥ÂêàÊàêÁªü‰∏ÄÊ°ÜÊû∂„ÄÇÊú¨ÊñáÊèêÂá∫Uni-MuMERÔºåÂÖ®Èù¢ÂæÆË∞ÉËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÔºàVLMÔºâ‰ª•Â∫îÂØπHMER‰ªªÂä°ÔºåËÄå‰∏ç‰øÆÊîπÂÖ∂Êû∂ÊûÑÔºåÊúâÊïàÂú∞Â∞ÜÈ¢ÜÂüüÁâπÂÆöÁü•ËØÜÊ≥®ÂÖ•ÈÄöÁî®Ê°ÜÊû∂„ÄÇËØ•ÊñπÊ≥ïÊï¥Âêà‰∫Ü‰∏â‰∏™Êï∞ÊçÆÈ©±Âä®‰ªªÂä°ÔºöÊ†ëÁä∂ÈìæÂºèÊÄùÁª¥ÔºàTree-CoTÔºâÁî®‰∫éÁªìÊûÑÂåñÁ©∫Èó¥Êé®ÁêÜÔºåÈîôËØØÈ©±Âä®Â≠¶‰π†ÔºàEDLÔºâÁî®‰∫éÂáèÂ∞ëËßÜËßâÁõ∏‰ººÂ≠óÁ¨¶‰πãÈó¥ÁöÑÊ∑∑Ê∑ÜÔºå‰ª•ÂèäÁ¨¶Âè∑ËÆ°Êï∞ÔºàSCÔºâ‰ª•ÊèêÈ´òÈïøË°®ËææÂºèÁöÑËØÜÂà´‰∏ÄËá¥ÊÄß„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåUni-MuMERÂú®CROHMEÂíåHME100KÊï∞ÊçÆÈõÜ‰∏äÂÆûÁé∞‰∫ÜË∂ÖË∂äÊúÄ‰ºòËΩªÈáèÁ∫ß‰∏ìÁî®Ê®°ÂûãSSAN 16.31%ÁöÑÊÄßËÉΩÊèêÂçáÔºå‰ª•ÂèäË∂ÖË∂äÈ°∂Á∫ßVLM Gemini2.5-flash 24.42%ÁöÑË°®Áé∞„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥ÊâãÂÜôÊï∞Â≠¶Ë°®ËææÂºèËØÜÂà´ÔºàHMERÔºâ‰∏≠ÁöÑÊÄßËÉΩÁì∂È¢àÔºåÁé∞ÊúâÊñπÊ≥ïÈÄöËøáÂ≠§Á´ãÁöÑÊû∂ÊûÑ‰øÆÊîπÈöæ‰ª•ÂΩ¢ÊàêÁªü‰∏ÄÁöÑËß£ÂÜ≥ÊñπÊ°àÔºåÂØºËá¥ËØÜÂà´ÊïàÊûú‰∏ç‰Ω≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöUni-MuMERÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂÖ®Èù¢ÂæÆË∞É‰∏Ä‰∏™È¢ÑËÆ≠ÁªÉÁöÑËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÔºàVLMÔºâÔºåËÄå‰∏çÊîπÂèòÂÖ∂Êû∂ÊûÑÔºå‰ªéËÄåÊúâÊïàÂú∞Â∞ÜÈ¢ÜÂüüÁâπÂÆöÁü•ËØÜËûçÂÖ•ÈÄöÁî®Ê°ÜÊû∂‰∏≠„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•ÊñπÊ≥ïÊï¥Âêà‰∫Ü‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÊ†ëÁä∂ÈìæÂºèÊÄùÁª¥ÔºàTree-CoTÔºâÁî®‰∫éÁªìÊûÑÂåñÁ©∫Èó¥Êé®ÁêÜÔºåÈîôËØØÈ©±Âä®Â≠¶‰π†ÔºàEDLÔºâÁî®‰∫éÂáèÂ∞ëËßÜËßâÁõ∏‰ººÂ≠óÁ¨¶ÁöÑÊ∑∑Ê∑ÜÔºå‰ª•ÂèäÁ¨¶Âè∑ËÆ°Êï∞ÔºàSCÔºâÁî®‰∫éÊèêÈ´òÈïøË°®ËææÂºèÁöÑËØÜÂà´‰∏ÄËá¥ÊÄß„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöUni-MuMERÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂ÈÄöËøáÂæÆË∞ÉVLMÊù•ÂÆûÁé∞Ë∑®‰ªªÂä°ÁöÑÈÄöÁî®ÊÄßÔºåÈÅøÂÖç‰∫Ü‰ª•ÂæÄÊñπÊ≥ïÁöÑÊû∂ÊûÑÈôêÂà∂Ôºå‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üÂú®Â§ö‰∏™‰ªªÂä°‰∏äË°®Áé∞Âá∫Ëâ≤„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Ê®°ÂûãËÆæËÆ°‰∏≠ÔºåÈááÁî®‰∫ÜÁâπÂÆöÁöÑÊçüÂ§±ÂáΩÊï∞‰ª•‰ºòÂåñÊØè‰∏™‰ªªÂä°ÁöÑÂ≠¶‰π†ÊïàÊûúÔºåÂêåÊó∂Âú®Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÈò∂ÊÆµËøõË°å‰∫ÜÈíàÂØπÊÄßÁöÑÁ¨¶Âè∑Â∏ÉÂ±ÄÂíå‰π¶ÂÜôÈ£éÊ†ºÁöÑÂ¢ûÂº∫Ôºå‰ª•ÊèêÈ´òÊ®°ÂûãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåUni-MuMERÂú®CROHMEÂíåHME100KÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜË∂ÖË∂äÊúÄ‰Ω≥ËΩªÈáèÁ∫ß‰∏ìÁî®Ê®°ÂûãSSAN 16.31%ÁöÑÊÄßËÉΩÊèêÂçáÔºå‰ª•ÂèäË∂ÖË∂äÈ°∂Á∫ßVLM Gemini2.5-flash 24.42%ÁöÑË°®Áé∞ÔºåÂ±ïÁé∞‰∫ÜÂÖ∂Âú®Èõ∂-shotËÆæÁΩÆ‰∏ãÁöÑÂº∫Â§ßËÉΩÂäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨ÊïôËÇ≤„ÄÅÁßëÂ≠¶ËÆ°ÁÆóÂíåËá™Âä®ÂåñÊñáÊ°£Â§ÑÁêÜÁ≠â„ÄÇÈÄöËøáÊèêÂçáÊâãÂÜôÊï∞Â≠¶Ë°®ËææÂºèÁöÑËØÜÂà´ÂáÜÁ°ÆÊÄßÔºåUni-MuMERËÉΩÂ§üÂú®ÊïôËÇ≤ÊäÄÊúØÂíåÊô∫ËÉΩÊñáÊ°£ÂàÜÊûê‰∏≠ÂèëÊå•ÈáçË¶Å‰ΩúÁî®ÔºåÊú™Êù•ÂèØËÉΩÊé®Âä®Êõ¥Â§öÂü∫‰∫éÊâãÂÜôËæìÂÖ•ÁöÑÊô∫ËÉΩÂ∫îÁî®ÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Handwritten Mathematical Expression Recognition (HMER) remains a persistent challenge in Optical Character Recognition (OCR) due to the inherent freedom of symbol layouts and variability in handwriting styles. Prior methods have faced performance bottlenecks by proposing isolated architectural modifications, making them difficult to integrate coherently into a unified framework. Meanwhile, recent advances in pretrained vision-language models (VLMs) have demonstrated strong cross-task generalization, offering a promising foundation for developing unified solutions. In this paper, we introduce Uni-MuMER, which fully fine-tunes a VLM for the HMER task without modifying its architecture, effectively injecting domain-specific knowledge into a generalist framework. Our method integrates three data-driven tasks: Tree-Aware Chain-of-Thought (Tree-CoT) for structured spatial reasoning, Error-Driven Learning (EDL) for reducing confusion among visually similar characters, and Symbol Counting (SC) for improving recognition consistency in long expressions. Experiments on the CROHME and HME100K datasets show that Uni-MuMER achieves super state-of-the-art performance, outperforming the best lightweight specialized model SSAN by 16.31\% and the top-performing VLM Gemini2.5-flash by 24.42\% under zero-shot setting. Our datasets, models, and code are open-sourced at: {https://github.com/BFlameSwift/Uni-MuMER

