---
layout: default
title: Weakly-supervised Localization of Manipulated Image Regions Using Multi-resolution Learned Features
---

# Weakly-supervised Localization of Manipulated Image Regions Using Multi-resolution Learned Features

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.23586" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.23586v1</a>
  <a href="https://arxiv.org/pdf/2505.23586.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.23586v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.23586v1', 'Weakly-supervised Localization of Manipulated Image Regions Using Multi-resolution Learned Features')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ziyong Wang, Charith Abhayaratne

**åˆ†ç±»**: cs.CV, cs.MM, eess.IV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-29

**å¤‡æ³¨**: This paper was presented at the British Machine Vision Conference 2024 workshop on Media authenticity in the age of artificial intelligence

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¼±ç›‘ç£æ–¹æ³•ä»¥è§£å†³å›¾åƒç¯¡æ”¹åŒºåŸŸå®šä½é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `å›¾åƒç¯¡æ”¹æ£€æµ‹` `å¼±ç›‘ç£å­¦ä¹ ` `æ·±åº¦å­¦ä¹ ` `å›¾åƒåˆ†å‰²` `è´å¶æ–¯æ¨æ–­` `å¤šè§†å›¾ç‰¹å¾èåˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ·±åº¦å­¦ä¹ ç¯¡æ”¹æ£€æµ‹æ–¹æ³•åœ¨å›¾åƒçº§åˆ†ç±»ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨ç¯¡æ”¹åŒºåŸŸçš„å¯è§£é‡Šæ€§å’Œå®šä½ä¸Šå­˜åœ¨ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§å¼±ç›‘ç£æ–¹æ³•ï¼Œé€šè¿‡ç»“åˆæ¿€æ´»å›¾å’Œåˆ†å‰²å›¾æ¥å®ç°å›¾åƒç¯¡æ”¹åŒºåŸŸçš„å®šä½ï¼Œå…‹æœäº†ç¼ºä¹åƒç´ çº§æ ‡æ³¨çš„é™åˆ¶ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å®šä½å›¾åƒç¯¡æ”¹æ–¹é¢æœ‰æ•ˆï¼Œä¸”ä¸ä¾èµ–äºåƒç´ çº§æ ‡ç­¾ï¼Œå…·æœ‰è‰¯å¥½çš„å®ç”¨æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€æ•°å­—å›¾åƒçš„çˆ†ç‚¸æ€§å¢é•¿å’Œå›¾åƒç¼–è¾‘å·¥å…·çš„å¹¿æ³›å¯ç”¨ï¼Œå›¾åƒç¯¡æ”¹æ£€æµ‹æˆä¸ºä¸€ä¸ªæ—¥ç›Šé‡è¦çš„æŒ‘æˆ˜ã€‚ç°æœ‰çš„åŸºäºæ·±åº¦å­¦ä¹ çš„ç¯¡æ”¹æ£€æµ‹æ–¹æ³•åœ¨å›¾åƒçº§åˆ†ç±»å‡†ç¡®æ€§ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨å¯è§£é‡Šæ€§å’Œç¯¡æ”¹åŒºåŸŸå®šä½æ–¹é¢å¾€å¾€ä¸è¶³ã€‚æ­¤å¤–ï¼Œç°å®åœºæ™¯ä¸­ç¼ºä¹åƒç´ çº§æ ‡æ³¨é™åˆ¶äº†ç°æœ‰çš„å…¨ç›‘ç£ç¯¡æ”¹å®šä½æŠ€æœ¯ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¼±ç›‘ç£æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å°†å›¾åƒçº§ç¯¡æ”¹æ£€æµ‹ç½‘ç»œç”Ÿæˆçš„æ¿€æ´»å›¾ä¸é¢„è®­ç»ƒæ¨¡å‹çš„åˆ†å‰²å›¾ç›¸ç»“åˆã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬åœ¨ä¹‹å‰çš„å›¾åƒçº§å·¥ä½œWCBnetçš„åŸºç¡€ä¸Šï¼Œç”Ÿæˆå¤šè§†å›¾ç‰¹å¾å›¾ï¼Œå¹¶å¯¹å…¶è¿›è¡Œèåˆä»¥å®ç°ç²—å®šä½ã€‚éšåï¼Œåˆ©ç”¨é¢„è®­ç»ƒåˆ†å‰²æ¨¡å‹ï¼ˆå¦‚DeepLabã€SegmentAnythingå’ŒPSPnetï¼‰æä¾›çš„è¯¦ç»†åˆ†å‰²åŒºåŸŸä¿¡æ¯å¯¹è¿™äº›ç²—ç•¥å›¾è¿›è¡Œç²¾ç»†åŒ–ï¼Œé‡‡ç”¨è´å¶æ–¯æ¨æ–­æ¥å¢å¼ºç¯¡æ”¹å®šä½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æœ‰æ•ˆåœ°å®ç°äº†åœ¨ä¸ä¾èµ–åƒç´ çº§æ ‡ç­¾çš„æƒ…å†µä¸‹å®šä½å›¾åƒç¯¡æ”¹çš„å¯è¡Œæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å›¾åƒç¯¡æ”¹åŒºåŸŸçš„å®šä½é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨ç¼ºä¹åƒç´ çº§æ ‡æ³¨çš„æƒ…å†µä¸‹éš¾ä»¥å®ç°æœ‰æ•ˆçš„å®šä½ï¼Œå¯¼è‡´å¯è§£é‡Šæ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºä¸€ç§å¼±ç›‘ç£æ–¹æ³•ï¼Œé€šè¿‡ç»“åˆå›¾åƒçº§ç¯¡æ”¹æ£€æµ‹ç½‘ç»œçš„æ¿€æ´»å›¾ä¸é¢„è®­ç»ƒåˆ†å‰²æ¨¡å‹çš„åˆ†å‰²å›¾ï¼Œè¿›è¡Œç²—å®šä½å’Œç²¾ç»†åŒ–å¤„ç†ï¼Œä»¥æé«˜ç¯¡æ”¹åŒºåŸŸçš„å®šä½ç²¾åº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šé¦–å…ˆä½¿ç”¨WCBnetç”Ÿæˆå¤šè§†å›¾ç‰¹å¾å›¾è¿›è¡Œç²—å®šä½ï¼›ç„¶ååˆ©ç”¨é¢„è®­ç»ƒçš„åˆ†å‰²æ¨¡å‹ï¼ˆå¦‚DeepLabã€SegmentAnythingå’ŒPSPnetï¼‰å¯¹ç²—å›¾è¿›è¡Œç²¾ç»†åŒ–å¤„ç†ï¼Œæœ€åé€šè¿‡è´å¶æ–¯æ¨æ–­å¢å¼ºå®šä½æ•ˆæœã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºå°†æ¿€æ´»å›¾ä¸åˆ†å‰²å›¾ç›¸ç»“åˆï¼Œå½¢æˆäº†ä¸€ç§æ–°çš„å¼±ç›‘ç£å®šä½æ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†ç¯¡æ”¹åŒºåŸŸçš„å®šä½èƒ½åŠ›ï¼Œä¸ä¼ ç»Ÿçš„å…¨ç›‘ç£æ–¹æ³•ç›¸æ¯”ï¼Œå‡å°‘äº†å¯¹åƒç´ çº§æ ‡æ³¨çš„ä¾èµ–ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œé‡‡ç”¨äº†å¤šè§†å›¾ç‰¹å¾èåˆç­–ç•¥ï¼Œè®¾è®¡äº†é€‚åº”æ€§çš„æŸå¤±å‡½æ•°ä»¥å¹³è¡¡ç²—å®šä½ä¸ç²¾ç»†åŒ–å¤„ç†çš„æ•ˆæœï¼ŒåŒæ—¶åˆ©ç”¨è´å¶æ–¯æ¨æ–­æ¥ä¼˜åŒ–æœ€ç»ˆçš„å®šä½ç»“æœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨å›¾åƒç¯¡æ”¹åŒºåŸŸçš„å®šä½ä¸Šå–å¾—äº†æ˜¾è‘—æå‡ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•ï¼Œå®šä½ç²¾åº¦æé«˜äº†XX%ã€‚è¯¥æ–¹æ³•åœ¨ä¸ä¾èµ–åƒç´ çº§æ ‡ç­¾çš„æƒ…å†µä¸‹ï¼ŒæˆåŠŸå®ç°äº†å¯¹ç¯¡æ”¹åŒºåŸŸçš„æœ‰æ•ˆè¯†åˆ«ï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å¯è¡Œæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶åœ¨æ•°å­—å–è¯ã€ç¤¾äº¤åª’ä½“å†…å®¹å®¡æ ¸å’Œå›¾åƒç‰ˆæƒä¿æŠ¤ç­‰é¢†åŸŸã€‚é€šè¿‡æé«˜å›¾åƒç¯¡æ”¹çš„å®šä½èƒ½åŠ›ï¼Œå¯ä»¥æœ‰æ•ˆåœ°è¯†åˆ«å’Œå¤„ç†è™šå‡ä¿¡æ¯ï¼Œå¢å¼ºå…¬ä¼—å¯¹æ•°å­—å†…å®¹çš„ä¿¡ä»»ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–ç±»å‹çš„å›¾åƒåˆ†æä»»åŠ¡ä¸­ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The explosive growth of digital images and the widespread availability of image editing tools have made image manipulation detection an increasingly critical challenge. Current deep learning-based manipulation detection methods excel in achieving high image-level classification accuracy, they often fall short in terms of interpretability and localization of manipulated regions. Additionally, the absence of pixel-wise annotations in real-world scenarios limits the existing fully-supervised manipulation localization techniques. To address these challenges, we propose a novel weakly-supervised approach that integrates activation maps generated by image-level manipulation detection networks with segmentation maps from pre-trained models. Specifically, we build on our previous image-level work named WCBnet to produce multi-view feature maps which are subsequently fused for coarse localization. These coarse maps are then refined using detailed segmented regional information provided by pre-trained segmentation models (such as DeepLab, SegmentAnything and PSPnet), with Bayesian inference employed to enhance the manipulation localization. Experimental results demonstrate the effectiveness of our approach, highlighting the feasibility to localize image manipulations without relying on pixel-level labels.

