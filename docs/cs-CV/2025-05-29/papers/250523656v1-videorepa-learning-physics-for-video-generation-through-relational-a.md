---
layout: default
title: "VideoREPA: Learning Physics for Video Generation through Relational Alignment with Foundation Models"
---

# VideoREPA: Learning Physics for Video Generation through Relational Alignment with Foundation Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.23656" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.23656v1</a>
  <a href="https://arxiv.org/pdf/2505.23656.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.23656v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.23656v1', 'VideoREPA: Learning Physics for Video Generation through Relational Alignment with Foundation Models')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Xiangdong Zhang, Jiaqi Liao, Shaofeng Zhang, Fanqing Meng, Xiangpeng Wan, Junchi Yan, Yu Cheng

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-29

**üîó ‰ª£Á†Å/È°πÁõÆ**: [PROJECT_PAGE](https://videorepa.github.io/)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫VideoREPA‰ª•Ëß£ÂÜ≥ËßÜÈ¢ëÁîüÊàê‰∏≠ÁöÑÁâ©ÁêÜÁêÜËß£ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±ÂõõÔºöÁîüÊàêÂºèÂä®‰Ωú (Generative Motion)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËßÜÈ¢ëÁîüÊàê` `Áâ©ÁêÜÁêÜËß£` `Ëí∏È¶èËÆ≠ÁªÉ` `Êó∂Á©∫ÂØπÈΩê` `Â§öÊ®°ÊÄÅÂ≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÊñáÊú¨Âà∞ËßÜÈ¢ëÁîüÊàêÊ®°ÂûãÂú®ÁîüÊàêÁâ©ÁêÜÂêàÁêÜÂÜÖÂÆπÊñπÈù¢Â≠òÂú®ÊòæËëó‰∏çË∂≥ÔºåÈöæ‰ª•ÂáÜÁ°ÆÁêÜËß£Áâ©ÁêÜËßÑÂæã„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫VideoREPAÊ°ÜÊû∂ÔºåÈÄöËøáÂØπÈΩê‰ª§ÁâåÁ∫ßÂÖ≥Á≥ªÔºåÂ∞ÜËßÜÈ¢ëÁêÜËß£Ê®°ÂûãÁöÑÁâ©ÁêÜÁü•ËØÜËí∏È¶èÂà∞T2VÊ®°Âûã‰∏≠„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåVideoREPAÂú®Áâ©ÁêÜÂ∏∏ËØÜÊñπÈù¢ÊòæËëóÊèêÂçá‰∫ÜÂü∫Á∫øÊ®°ÂûãCogVideoXÁöÑÊÄßËÉΩÔºåË°®Áé∞Âá∫Âº∫Â§ßÁöÑÁîüÊàêËÉΩÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËøëÂπ¥Êù•ÔºåÊñáÊú¨Âà∞ËßÜÈ¢ëÔºàT2VÔºâÊâ©Êï£Ê®°ÂûãÁöÑËøõÂ±ï‰ΩøÂæóÈ´ò‰øùÁúüÂíåÁúüÂÆûÁöÑËßÜÈ¢ëÂêàÊàêÊàê‰∏∫ÂèØËÉΩ„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÁöÑT2VÊ®°ÂûãÂú®ÁîüÊàêÁâ©ÁêÜ‰∏äÂêàÁêÜÁöÑÂÜÖÂÆπÊñπÈù¢Â≠òÂú®Âõ∞ÈöæÔºå‰∏ªË¶ÅÁî±‰∫éÂÖ∂ÂØπÁâ©ÁêÜÁêÜËß£ÁöÑËÉΩÂäõÊúâÈôê„ÄÇÊàë‰ª¨ÂèëÁé∞ÔºåÂ∞ΩÁÆ°T2VÊ®°ÂûãÁöÑË°®Á§∫Âú®‰∏ÄÂÆöÁ®ãÂ∫¶‰∏äÂÖ∑Â§áÁâ©ÁêÜÁêÜËß£ËÉΩÂäõÔºå‰ΩÜ‰∏éÊúÄÊñ∞ÁöÑËßÜÈ¢ëËá™ÁõëÁù£Â≠¶‰π†ÊñπÊ≥ïÁõ∏ÊØîÔºå‰ªçÊòæ‰∏çË∂≥„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞Ê°ÜÊû∂VideoREPAÔºåÈÄöËøáÂØπÈΩê‰ª§ÁâåÁ∫ßÂÖ≥Á≥ªÔºåÂ∞ÜËßÜÈ¢ëÁêÜËß£Âü∫Á°ÄÊ®°Âûã‰∏≠ÁöÑÁâ©ÁêÜÁêÜËß£ËÉΩÂäõËí∏È¶èÂà∞T2VÊ®°Âûã‰∏≠Ôºå‰ªéËÄåÁº©Â∞èÁâ©ÁêÜÁêÜËß£ÁöÑÂ∑ÆË∑ùÔºåÂÆûÁé∞Êõ¥ÂÖ∑Áâ©ÁêÜÂêàÁêÜÊÄßÁöÑËßÜÈ¢ëÁîüÊàê„ÄÇÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰ª§ÁâåÂÖ≥Á≥ªËí∏È¶èÔºàTRDÔºâÊçüÂ§±ÔºåÂà©Áî®Êó∂Á©∫ÂØπÈΩê‰∏∫Âº∫Â§ßÁöÑÈ¢ÑËÆ≠ÁªÉT2VÊ®°ÂûãÁöÑÂæÆË∞ÉÊèê‰æõËΩØÊåáÂØºÔºåËøôÊòØ‰∏é‰ª•ÂæÄË°®Á§∫ÂØπÈΩêÊñπÊ≥ïÁöÑÂÖ≥ÈîÆÂå∫Âà´„ÄÇÂÆûËØÅËØÑ‰º∞Ë°®ÊòéÔºåVideoREPAÊòæËëóÂ¢ûÂº∫‰∫ÜÂü∫Á∫øÊñπÊ≥ïCogVideoXÁöÑÁâ©ÁêÜÂ∏∏ËØÜÔºåÂèñÂæó‰∫ÜÁõ∏ÂÖ≥Âü∫ÂáÜÁöÑÊòæËëóÊèêÂçá„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáË¶ÅËß£ÂÜ≥ÁöÑÈóÆÈ¢òÊòØÁé∞ÊúâÊñáÊú¨Âà∞ËßÜÈ¢ëÁîüÊàêÊ®°ÂûãÂú®ÁîüÊàêÁâ©ÁêÜÂêàÁêÜÂÜÖÂÆπÊó∂ÁöÑ‰∏çË∂≥ÔºåÁâπÂà´ÊòØÂÆÉ‰ª¨ÂØπÁâ©ÁêÜËßÑÂæãÁöÑÁêÜËß£ËÉΩÂäõËæÉÂº±„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®Áâ©ÁêÜÁêÜËß£ÊñπÈù¢ÁöÑË°®Áé∞Ëøú‰∏çÂ¶ÇÊúÄÊñ∞ÁöÑËßÜÈ¢ëËá™ÁõëÁù£Â≠¶‰π†ÊñπÊ≥ï„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉËß£ÂÜ≥ÊÄùË∑ØÊòØÈÄöËøáVideoREPAÊ°ÜÊû∂ÔºåÂ∞ÜËßÜÈ¢ëÁêÜËß£Âü∫Á°ÄÊ®°Âûã‰∏≠ÁöÑÁâ©ÁêÜÁêÜËß£ËÉΩÂäõËí∏È¶èÂà∞T2VÊ®°Âûã‰∏≠ÔºåÂÖ∑‰ΩìÈÄöËøáÂØπÈΩê‰ª§ÁâåÁ∫ßÂÖ≥Á≥ªÊù•ÂÆûÁé∞„ÄÇËøôÁßçËÆæËÆ°Êó®Âú®Áº©Â∞èÁâ©ÁêÜÁêÜËß£ÁöÑÂ∑ÆË∑ùÔºå‰ªéËÄåÊèêÈ´òÁîüÊàêËßÜÈ¢ëÁöÑÁâ©ÁêÜÂêàÁêÜÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöVideoREPAÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏§‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöËßÜÈ¢ëÁêÜËß£Âü∫Á°ÄÊ®°ÂûãÂíåÊñáÊú¨Âà∞ËßÜÈ¢ëÁîüÊàêÊ®°Âûã„ÄÇÈ¶ñÂÖàÔºåÈÄöËøáÂØπËßÜÈ¢ëÁêÜËß£Ê®°ÂûãËøõË°åËÆ≠ÁªÉÔºåÊèêÂèñÂÖ∂Áâ©ÁêÜÁü•ËØÜÔºõÁÑ∂ÂêéÔºåÈÄöËøá‰ª§ÁâåÂÖ≥Á≥ªËí∏È¶èÊçüÂ§±ÔºàTRDÔºâÂ∞ÜËøô‰∫õÁü•ËØÜÂ∫îÁî®‰∫éT2VÊ®°ÂûãÁöÑÂæÆË∞ÉËøáÁ®ã‰∏≠„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÂºïÂÖ•‰∫Ü‰ª§ÁâåÂÖ≥Á≥ªËí∏È¶èÔºàTRDÔºâÊçüÂ§±ÔºåËøô‰∏ÄÊñπÊ≥ïÂà©Áî®Êó∂Á©∫ÂØπÈΩê‰∏∫T2VÊ®°ÂûãÁöÑÂæÆË∞ÉÊèê‰æõ‰∫ÜËΩØÊåáÂØº„ÄÇËøô‰∏é‰ª•ÂæÄÁöÑË°®Á§∫ÂØπÈΩêÊñπÊ≥ïÊúâÊú¨Ë¥®Âå∫Âà´ÔºåÂêéËÄÖÈÄöÂ∏∏‰∏ç‰∏ìÊ≥®‰∫éÁâ©ÁêÜÁü•ËØÜÁöÑÊ≥®ÂÖ•„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÂÖ≥ÈîÆËÆæËÆ°ÊñπÈù¢ÔºåTRDÊçüÂ§±ÂáΩÊï∞ÁöÑÊûÑÂª∫ÊòØÊ†∏ÂøÉÔºåÂº∫Ë∞É‰∫ÜÊó∂Á©∫ÂØπÈΩêÁöÑÈáçË¶ÅÊÄß„ÄÇÊ≠§Â§ñÔºåÊ®°ÂûãÁöÑÂèÇÊï∞ËÆæÁΩÆÂíåÁΩëÁªúÁªìÊûÑÁªèËøáÁ≤æÂøÉËÆæËÆ°Ôºå‰ª•Á°Æ‰øùÂú®ÂæÆË∞ÉËøáÁ®ã‰∏≠ËÉΩÂ§üÊúâÊïàÂú∞‰º†ÈÄíÁâ©ÁêÜÁü•ËØÜ„ÄÇÂÖ∑‰ΩìÁöÑÂèÇÊï∞ËÆæÁΩÆÂíåÁΩëÁªúÁªìÊûÑÁªÜËäÇÂú®ËÆ∫Êñá‰∏≠ËøõË°å‰∫ÜËØ¶ÁªÜÊèèËø∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåVideoREPAÊòæËëóÊèêÂçá‰∫ÜÂü∫Á∫øÊ®°ÂûãCogVideoXÁöÑÁâ©ÁêÜÂ∏∏ËØÜÔºåÂÖ∑‰ΩìÂú®Áõ∏ÂÖ≥Âü∫ÂáÜÊµãËØï‰∏≠ÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®ÁîüÊàêÁ¨¶ÂêàÁõ¥ËßÇÁâ©ÁêÜËßÑÂæãÁöÑËßÜÈ¢ëÊñπÈù¢ÁöÑÂº∫Â§ßËÉΩÂäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨ÂΩ±ËßÜÂà∂‰Ωú„ÄÅÊ∏∏ÊàèÂºÄÂèëÂíåËôöÊãüÁé∞ÂÆûÁ≠âÂú∫ÊôØÔºåËÉΩÂ§ü‰∏∫Ëøô‰∫õÈ¢ÜÂüüÊèê‰æõÊõ¥‰∏∫ÁúüÂÆûÂíåÁâ©ÁêÜÂêàÁêÜÁöÑËßÜÈ¢ëÁîüÊàêËÉΩÂäõ„ÄÇÊú™Êù•ÔºåÈöèÁùÄÊäÄÊúØÁöÑËøõ‰∏ÄÊ≠•ÂèëÂ±ïÔºåVideoREPAÂèØËÉΩÂú®Ëá™Âä®ÂåñÂÜÖÂÆπÂàõ‰ΩúÂíåÊô∫ËÉΩ‰∫§‰∫íÁ≥ªÁªü‰∏≠ÂèëÊå•ÈáçË¶Å‰ΩúÁî®ÔºåÊèêÂçáÁî®Êà∑‰ΩìÈ™å„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Recent advancements in text-to-video (T2V) diffusion models have enabled high-fidelity and realistic video synthesis. However, current T2V models often struggle to generate physically plausible content due to their limited inherent ability to accurately understand physics. We found that while the representations within T2V models possess some capacity for physics understanding, they lag significantly behind those from recent video self-supervised learning methods. To this end, we propose a novel framework called VideoREPA, which distills physics understanding capability from video understanding foundation models into T2V models by aligning token-level relations. This closes the physics understanding gap and enable more physics-plausible generation. Specifically, we introduce the Token Relation Distillation (TRD) loss, leveraging spatio-temporal alignment to provide soft guidance suitable for finetuning powerful pre-trained T2V models, a critical departure from prior representation alignment (REPA) methods. To our knowledge, VideoREPA is the first REPA method designed for finetuning T2V models and specifically for injecting physical knowledge. Empirical evaluations show that VideoREPA substantially enhances the physics commonsense of baseline method, CogVideoX, achieving significant improvement on relevant benchmarks and demonstrating a strong capacity for generating videos consistent with intuitive physics. More video results are available at https://videorepa.github.io/.

