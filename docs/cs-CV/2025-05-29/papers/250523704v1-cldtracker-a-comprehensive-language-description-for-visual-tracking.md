---
layout: default
title: "CLDTracker: A Comprehensive Language Description for Visual Tracking"
---

# CLDTracker: A Comprehensive Language Description for Visual Tracking

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.23704" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.23704v1</a>
  <a href="https://arxiv.org/pdf/2505.23704.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.23704v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.23704v1', 'CLDTracker: A Comprehensive Language Description for Visual Tracking')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Mohamad Alansari, Sajid Javed, Iyyakutti Iyappan Ganapathi, Sara Alansari, Muzammal Naseer

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-29

**Â§áÊ≥®**: 47 pages, 9 figures, Information Fusion Journal

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/HamadYA/CLDTracker)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫CLDTracker‰ª•Ëß£ÂÜ≥ËßÜËßâË∑üË∏™‰∏≠ÁöÑËØ≠Ë®ÄÊèèËø∞‰∏çË∂≥ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâÁõÆÊ†áË∑üË∏™` `ËØ≠Ë®ÄÊèèËø∞` `Â§öÊ®°ÊÄÅËûçÂêà` `ËßÜËßâËØ≠Ë®ÄÊ®°Âûã` `Ê∑±Â∫¶Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑËßÜËßâË∑üË∏™ÊñπÊ≥ï‰∏ªË¶Å‰æùËµñËßÜËßâÁ∫øÁ¥¢ÔºåÈöæ‰ª•Â∫îÂØπÂä®ÊÄÅÂèòÂåñÂíåÂ§çÊùÇËÉåÊôØÔºåÂØºËá¥Ë∑üË∏™ÊÄßËÉΩ‰∏ãÈôç„ÄÇ
2. CLDTrackerÈÄöËøáÂºïÂÖ•ÂèåÂàÜÊîØÊû∂ÊûÑÔºåÁªìÂêàÊñáÊú¨ÂíåËßÜËßâ‰ø°ÊÅØÔºåÊûÑÂª∫‰∏∞ÂØåÁöÑÊñáÊú¨ÊèèËø∞‰ª•Â¢ûÂº∫ÁõÆÊ†áÁöÑËØ≠‰πâÁêÜËß£„ÄÇ
3. Âú®ÂÖ≠‰∏™Ê†áÂáÜVOTÂü∫ÂáÜ‰∏äÁöÑÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåCLDTrackerËææÂà∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÊòæËëóÊèêÂçá‰∫ÜË∑üË∏™ÁöÑÂáÜÁ°ÆÊÄßÂíåÈ≤ÅÊ£íÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËßÜËßâÁõÆÊ†áË∑üË∏™ÔºàVOTÔºâÊòØËÆ°ÁÆóÊú∫ËßÜËßâ‰∏≠ÁöÑ‰∏ÄÈ°πÂü∫Êú¨ËÄåÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑ‰ªªÂä°ÔºåÈù¢‰∏¥Âä®ÊÄÅÂ§ñËßÇÂèòÂåñ„ÄÅÈÅÆÊå°ÂíåËÉåÊôØÊùÇ‰π±Á≠âÈóÆÈ¢ò„ÄÇ‰º†ÁªüÁöÑË∑üË∏™Âô®‰∏ªË¶Å‰æùËµñËßÜËßâÁ∫øÁ¥¢ÔºåÂæÄÂæÄÂú®Â§çÊùÇÂú∫ÊôØ‰∏≠Ë°®Áé∞‰∏ç‰Ω≥„ÄÇÂ∞ΩÁÆ°ÊúÄËøëÁöÑËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÔºàVLMsÔºâÂú®ËØ≠‰πâÁêÜËß£ÊñπÈù¢Â±ïÁé∞Âá∫ÊΩúÂäõÔºå‰ΩÜÂÖ∂Âú®VOT‰∏≠ÁöÑÁõ¥Êé•Â∫îÁî®ÂèóÂà∞ÈôêÂà∂Ôºå‰∏ªË¶Å‰ΩìÁé∞Âú®Áº∫‰πè‰∏∞ÂØåÁöÑÊñáÊú¨Ë°®Á§∫„ÄÅ‰ΩéÊïàÁöÑËßÜËßâ‰∏éÊñáÊú¨ÁâπÂæÅËûçÂêàÊú∫Âà∂‰ª•ÂèäÁº∫‰πèÊó∂Èó¥Âª∫Ê®°Á≠âÊñπÈù¢„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåÊú¨ÊñáÊèêÂá∫‰∫ÜCLDTrackerÔºå‰∏Ä‰∏™ÁªºÂêàËØ≠Ë®ÄÊèèËø∞Ê°ÜÊû∂ÔºåÊó®Âú®Â¢ûÂº∫ËßÜËßâË∑üË∏™ÁöÑÈ≤ÅÊ£íÊÄß„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåCLDTrackerÂú®ÂÖ≠‰∏™Ê†áÂáÜVOTÂü∫ÂáÜ‰∏äÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÈ™åËØÅ‰∫ÜÂº∫Â§ß‰∏îÈÄÇÂ∫îÊó∂Èó¥ÂèòÂåñÁöÑËßÜËßâ-ËØ≠Ë®ÄË°®Á§∫Âú®Ë∑üË∏™‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥ËßÜËßâÁõÆÊ†áË∑üË∏™‰∏≠ÂØπÁõÆÊ†áÂØπË±°ÁöÑËØ≠Ë®ÄÊèèËø∞‰∏çË∂≥ÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®Â§çÊùÇÂú∫ÊôØ‰∏≠Èöæ‰ª•ÊúâÊïàÂà©Áî®ËØ≠Ë®Ä‰ø°ÊÅØÔºåÂØºËá¥Ë∑üË∏™ÊÄßËÉΩÂèóÈôê„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöCLDTrackerÁöÑÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÈÄöËøáÊûÑÂª∫‰∏Ä‰∏™ÂèåÂàÜÊîØÊû∂ÊûÑÔºåÂàÜÂà´Â§ÑÁêÜÊñáÊú¨ÂíåËßÜËßâ‰ø°ÊÅØÔºå‰ªéËÄåÂÆûÁé∞Êõ¥‰∏∞ÂØåÁöÑËØ≠‰πâË°®Á§∫ÂíåÊõ¥ÊúâÊïàÁöÑÁâπÂæÅËûçÂêà„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•Ê°ÜÊû∂ÂåÖÊã¨ÊñáÊú¨ÂàÜÊîØÂíåËßÜËßâÂàÜÊîØ„ÄÇÂú®ÊñáÊú¨ÂàÜÊîØ‰∏≠ÔºåÂà©Áî®Âº∫Â§ßÁöÑËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÔºàÂ¶ÇCLIPÂíåGPT-4VÔºâÁîüÊàê‰∏∞ÂØåÁöÑÊñáÊú¨ÊèèËø∞ÔºåÂ¢ûÂº∫ËØ≠‰πâÂíå‰∏ä‰∏ãÊñá‰ø°ÊÅØ„ÄÇÂú®ËßÜËßâÂàÜÊîØ‰∏≠ÔºåÁªìÂêàËßÜËßâÁâπÂæÅËøõË°åÁõÆÊ†áË∑üË∏™„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöCLDTrackerÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÂÖ∂ÁªºÂêàËØ≠Ë®ÄÊèèËø∞Ê°ÜÊû∂ÔºåËÉΩÂ§üÊúâÊïàÊï¥ÂêàËßÜËßâÂíåÊñáÊú¨‰ø°ÊÅØÔºåÂÖãÊúç‰∫Ü‰º†ÁªüÊñπÊ≥ïÂú®ËØ≠‰πâÁêÜËß£ÂíåÊó∂Èó¥Âª∫Ê®°ÊñπÈù¢ÁöÑ‰∏çË∂≥„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°‰∏≠ÔºåÈááÁî®‰∫Ü‰∏∞ÂØåÁöÑÊñáÊú¨ÊèèËø∞ÁîüÊàêÁ≠ñÁï•ÔºåÁªìÂêà‰∫ÜÂ§öÁßç‰∏ä‰∏ãÊñá‰ø°ÊÅØÔºåÂπ∂Âú®ÁâπÂæÅËûçÂêàÊó∂‰ΩøÁî®‰∫ÜÈ´òÊïàÁöÑÊú∫Âà∂Ôºå‰ª•Á°Æ‰øùËßÜËßâÂíåÊñáÊú¨‰ø°ÊÅØÁöÑÊúÄ‰Ω≥Êï¥Âêà„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®ÂÖ≠‰∏™Ê†áÂáÜVOTÂü∫ÂáÜ‰∏äÁöÑÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåCLDTrackerÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÁõ∏ËæÉ‰∫é‰º†ÁªüÊñπÊ≥ïÔºåË∑üË∏™ÂáÜÁ°ÆÊÄßÊèêÂçá‰∫ÜÊòæËëóÁöÑÁôæÂàÜÊØîÔºåÈ™åËØÅ‰∫ÜÂÖ∂Âú®Â§çÊùÇÂú∫ÊôØ‰∏ãÁöÑÊúâÊïàÊÄßÂíåÈ≤ÅÊ£íÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

CLDTrackerÁöÑÁ†îÁ©∂ÊàêÊûúÂú®Â§ö‰∏™È¢ÜÂüüÂÖ∑ÊúâÊΩúÂú®Â∫îÁî®‰ª∑ÂÄºÔºåÂåÖÊã¨Êô∫ËÉΩÁõëÊéß„ÄÅËá™Âä®È©æÈ©∂„ÄÅÂ¢ûÂº∫Áé∞ÂÆûÁ≠â„ÄÇÈÄöËøáÊèêÂçáËßÜËßâË∑üË∏™ÁöÑÂáÜÁ°ÆÊÄßÂíåÈ≤ÅÊ£íÊÄßÔºåËØ•ÊäÄÊúØËÉΩÂ§üÂú®Â§çÊùÇÁéØÂ¢É‰∏≠Êõ¥Â•ΩÂú∞ËØÜÂà´ÂíåË∑üË∏™ÁõÆÊ†áÔºåÊé®Âä®Áõ∏ÂÖ≥Â∫îÁî®ÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> VOT remains a fundamental yet challenging task in computer vision due to dynamic appearance changes, occlusions, and background clutter. Traditional trackers, relying primarily on visual cues, often struggle in such complex scenarios. Recent advancements in VLMs have shown promise in semantic understanding for tasks like open-vocabulary detection and image captioning, suggesting their potential for VOT. However, the direct application of VLMs to VOT is hindered by critical limitations: the absence of a rich and comprehensive textual representation that semantically captures the target object's nuances, limiting the effective use of language information; inefficient fusion mechanisms that fail to optimally integrate visual and textual features, preventing a holistic understanding of the target; and a lack of temporal modeling of the target's evolving appearance in the language domain, leading to a disconnect between the initial description and the object's subsequent visual changes. To bridge these gaps and unlock the full potential of VLMs for VOT, we propose CLDTracker, a novel Comprehensive Language Description framework for robust visual Tracking. Our tracker introduces a dual-branch architecture consisting of a textual and a visual branch. In the textual branch, we construct a rich bag of textual descriptions derived by harnessing the powerful VLMs such as CLIP and GPT-4V, enriched with semantic and contextual cues to address the lack of rich textual representation. Experiments on six standard VOT benchmarks demonstrate that CLDTracker achieves SOTA performance, validating the effectiveness of leveraging robust and temporally-adaptive vision-language representations for tracking. Code and models are publicly available at: https://github.com/HamadYA/CLDTracker

