---
layout: default
title: "CMIE: Combining MLLM Insights with External Evidence for Explainable Out-of-Context Misinformation Detection"
---

# CMIE: Combining MLLM Insights with External Evidence for Explainable Out-of-Context Misinformation Detection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.23449" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.23449v3</a>
  <a href="https://arxiv.org/pdf/2505.23449.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.23449v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.23449v3', 'CMIE: Combining MLLM Insights with External Evidence for Explainable Out-of-Context Misinformation Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Fanxiao Li, Jiaying Wu, Canyuan He, Wei Zhou

**åˆ†ç±»**: cs.MM, cs.CV, cs.IR

**å‘å¸ƒæ—¥æœŸ**: 2025-05-29 (æ›´æ–°: 2025-10-27)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCMIEæ¡†æ¶ä»¥è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨è™šå‡ä¿¡æ¯æ£€æµ‹ä¸­çš„ä¸è¶³**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `è™šå‡ä¿¡æ¯æ£€æµ‹` `å…±å­˜å…³ç³»ç”Ÿæˆ` `å…³è”è¯„åˆ†æœºåˆ¶` `æ·±åº¦å­¦ä¹ ` `ä¿¡æ¯éªŒè¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨ä¸Šä¸‹æ–‡å¤–è™šå‡ä¿¡æ¯æ£€æµ‹ä¸­å­˜åœ¨æ•æ‰å›¾åƒä¸æ–‡æœ¬æ·±å±‚å…³ç³»çš„å›°éš¾ã€‚
2. CMIEæ¡†æ¶é€šè¿‡å…±å­˜å…³ç³»ç”Ÿæˆå’Œå…³è”è¯„åˆ†æœºåˆ¶ï¼Œè¯†åˆ«å›¾åƒä¸æ–‡æœ¬ä¹‹é—´çš„æ½œåœ¨å…³ç³»ï¼Œæå‡æ£€æµ‹èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCMIEåœ¨è™šå‡ä¿¡æ¯æ£€æµ‹ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰åœ¨è§†è§‰æ¨ç†å’Œæ–‡æœ¬ç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºè‰²ã€‚ç„¶è€Œï¼Œé’ˆå¯¹ä¸Šä¸‹æ–‡å¤–ï¼ˆOOCï¼‰è™šå‡ä¿¡æ¯æ£€æµ‹çš„ç ”ç©¶å‘ç°ï¼Œç°æœ‰æ–¹æ³•é¢ä¸´ä¸¤ä¸ªä¸»è¦æŒ‘æˆ˜ï¼šä¸€æ˜¯éš¾ä»¥æ•æ‰å›¾åƒä¸æ–‡æœ¬ä¹‹é—´çš„æ·±å±‚å…³ç³»ï¼ŒäºŒæ˜¯è¯æ®ä¸­çš„å™ªå£°å½±å“æ£€æµ‹å‡†ç¡®æ€§ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºCMIEæ¡†æ¶ï¼Œç»“åˆå…±å­˜å…³ç³»ç”Ÿæˆï¼ˆCRGï¼‰ç­–ç•¥å’Œå…³è”è¯„åˆ†ï¼ˆASï¼‰æœºåˆ¶ï¼Œä»¥è¯†åˆ«å›¾åƒä¸æ–‡æœ¬ä¹‹é—´çš„æ½œåœ¨å…±å­˜å…³ç³»ï¼Œå¹¶é€‰æ‹©æ€§åœ°åˆ©ç”¨ç›¸å…³è¯æ®æ¥æå‡è™šå‡ä¿¡æ¯æ£€æµ‹çš„æ•ˆæœã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCMIEä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨ä¸Šä¸‹æ–‡å¤–è™šå‡ä¿¡æ¯æ£€æµ‹ä¸­çš„ä¸è¶³ï¼Œç‰¹åˆ«æ˜¯æ•æ‰å›¾åƒä¸æ–‡æœ¬ä¹‹é—´æ·±å±‚å…³ç³»çš„æŒ‘æˆ˜ï¼Œä»¥åŠè¯æ®å™ªå£°å¯¹æ£€æµ‹å‡†ç¡®æ€§çš„å½±å“ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šCMIEæ¡†æ¶é€šè¿‡å¼•å…¥å…±å­˜å…³ç³»ç”Ÿæˆï¼ˆCRGï¼‰ç­–ç•¥ï¼Œè¯†åˆ«å›¾åƒä¸æ–‡æœ¬ä¹‹é—´çš„æ½œåœ¨å…±å­˜å…³ç³»ï¼Œå¹¶ç»“åˆå…³è”è¯„åˆ†ï¼ˆASï¼‰æœºåˆ¶ï¼Œé€‰æ‹©æ€§åœ°åˆ©ç”¨ç›¸å…³è¯æ®ï¼Œä»è€Œæå‡è™šå‡ä¿¡æ¯æ£€æµ‹çš„å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCMIEçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šå…±å­˜å…³ç³»ç”Ÿæˆæ¨¡å—å’Œå…³è”è¯„åˆ†æ¨¡å—ã€‚å…±å­˜å…³ç³»ç”Ÿæˆæ¨¡å—è´Ÿè´£è¯†åˆ«å›¾åƒä¸æ–‡æœ¬ä¹‹é—´çš„æ½œåœ¨å…³ç³»ï¼Œè€Œå…³è”è¯„åˆ†æ¨¡å—åˆ™é€šè¿‡è¯„ä¼°è¯æ®çš„ç›¸å…³æ€§æ¥å¢å¼ºæ£€æµ‹æ•ˆæœã€‚

**å…³é”®åˆ›æ–°**ï¼šCMIEçš„ä¸»è¦åˆ›æ–°åœ¨äºå¼•å…¥äº†å…±å­˜å…³ç³»ç”Ÿæˆç­–ç•¥å’Œå…³è”è¯„åˆ†æœºåˆ¶ï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„ç›´æ¥å…³è”æ€§åˆ†æå½¢æˆäº†é²œæ˜å¯¹æ¯”ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰æ½œåœ¨çš„è¯­ä¹‰è”ç³»ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒCMIEé‡‡ç”¨äº†ç‰¹å®šçš„å‚æ•°è®¾ç½®ä»¥ä¼˜åŒ–å…±å­˜å…³ç³»çš„ç”Ÿæˆï¼Œå¹¶é€šè¿‡æŸå¤±å‡½æ•°æ¥å¹³è¡¡æ£€æµ‹ç²¾åº¦ä¸å¬å›ç‡ã€‚æ­¤å¤–ï¼Œç½‘ç»œç»“æ„ä¸Šï¼ŒCMIEç»“åˆäº†å¤šæ¨¡æ€ç‰¹å¾æå–ä¸æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œä»¥æå‡æ•´ä½“æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒCMIEæ¡†æ¶åœ¨è™šå‡ä¿¡æ¯æ£€æµ‹ä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå…·ä½“è¡¨ç°ä¸ºæ£€æµ‹å‡†ç¡®ç‡æå‡äº†çº¦15%ï¼Œå¹¶åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå‡å–å¾—äº†é¢†å…ˆçš„æ€§èƒ½ã€‚è¿™ä¸€æˆæœéªŒè¯äº†CMIEåœ¨å¤„ç†å¤æ‚å¤šæ¨¡æ€ä¿¡æ¯æ—¶çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

CMIEæ¡†æ¶åœ¨è™šå‡ä¿¡æ¯æ£€æµ‹é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨ç¤¾äº¤åª’ä½“ã€æ–°é—»éªŒè¯å’Œå†…å®¹å®¡æ ¸ç­‰åœºæ™¯ä¸­ã€‚é€šè¿‡æé«˜æ£€æµ‹çš„å‡†ç¡®æ€§ï¼ŒCMIEèƒ½å¤Ÿæœ‰æ•ˆå‡å°‘è™šå‡ä¿¡æ¯çš„ä¼ æ’­ï¼Œæå‡å…¬ä¼—çš„ä¿¡æ¯ç´ å…»å’Œå®‰å…¨æ€§ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶è¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–å¤šæ¨¡æ€ä»»åŠ¡ï¼Œå¦‚å›¾åƒä¸æ–‡æœ¬çš„è‡ªåŠ¨æ ‡æ³¨å’Œå†…å®¹ç”Ÿæˆç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal large language models (MLLMs) have demonstrated impressive capabilities in visual reasoning and text generation. While previous studies have explored the application of MLLM for detecting out-of-context (OOC) misinformation, our empirical analysis reveals two persisting challenges of this paradigm. Evaluating the representative GPT-4o model on direct reasoning and evidence augmented reasoning, results indicate that MLLM struggle to capture the deeper relationships-specifically, cases in which the image and text are not directly connected but are associated through underlying semantic links. Moreover, noise in the evidence further impairs detection accuracy. To address these challenges, we propose CMIE, a novel OOC misinformation detection framework that incorporates a Coexistence Relationship Generation (CRG) strategy and an Association Scoring (AS) mechanism. CMIE identifies the underlying coexistence relationships between images and text, and selectively utilizes relevant evidence to enhance misinformation detection. Experimental results demonstrate that our approach outperforms existing methods.

