---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CV - 2025-12-12
---

# cs.CVï¼ˆ2025-12-12ï¼‰

ğŸ“Š å…± **33** ç¯‡è®ºæ–‡
 | ğŸ”— **5** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (20 ğŸ”—3)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (5)</a>
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (4)</a>
<a href="#æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion" class="interest-badge">æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (2 ğŸ”—2)</a>
<a href="#æ”¯æŸ±äº”äº¤äº’ä¸ååº”-interaction-reaction" class="interest-badge">æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction) (1)</a>
<a href="#æ”¯æŸ±ä¸ƒåŠ¨ä½œé‡å®šå‘-motion-retargeting" class="interest-badge">æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (20 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251211800v1-moment-based-3d-gaussian-splatting-resolving-volumetric-occlusion-wi.html">Moment-Based 3D Gaussian Splatting: Resolving Volumetric Occlusion with Order-Independent Transmittance</a></td>
  <td>æå‡ºåŸºäºçŸ©çš„3Dé«˜æ–¯æº…å°„ï¼Œé€šè¿‡ä¸é¡ºåºæ— å…³çš„é€å°„ç‡è§£å†³ä½“ç§¯é®æŒ¡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">3D gaussian splatting</span> <span class="paper-tag">3DGS</span> <span class="paper-tag">gaussian splatting</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11800v1" onclick="toggleFavorite(this, '2512.11800v1', 'Moment-Based 3D Gaussian Splatting: Resolving Volumetric Occlusion with Order-Independent Transmittance')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251211356v1-prior-enhanced-gaussian-splatting-for-dynamic-scene-reconstruction-f.html">Prior-Enhanced Gaussian Splatting for Dynamic Scene Reconstruction from Casual Video</a></td>
  <td>æå‡ºå…ˆéªŒå¢å¼ºçš„é«˜æ–¯æº…å°„æ–¹æ³•ï¼Œç”¨äºä»æ—¥å¸¸è§†é¢‘ä¸­é‡å»ºåŠ¨æ€åœºæ™¯</td>
  <td class="tags-cell"><span class="paper-tag">gaussian splatting</span> <span class="paper-tag">scene reconstruction</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11356v1" onclick="toggleFavorite(this, '2512.11356v1', 'Prior-Enhanced Gaussian Splatting for Dynamic Scene Reconstruction from Casual Video')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251211186v1-lightweight-3d-gaussian-splatting-compression-via-video-codec.html">Lightweight 3D Gaussian Splatting Compression via Video Codec</a></td>
  <td>æå‡ºåŸºäºè§†é¢‘ç¼–è§£ç å™¨çš„è½»é‡çº§3Dé«˜æ–¯æº…å°„å‹ç¼©æ–¹æ³•ï¼Œé€‚ç”¨äºè½»é‡çº§è®¾å¤‡ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">3D gaussian splatting</span> <span class="paper-tag">gaussian splatting</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11186v1" onclick="toggleFavorite(this, '2512.11186v1', 'Lightweight 3D Gaussian Splatting Compression via Video Codec')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251211301v1-multiego-a-multi-view-egocentric-video-dataset-for-4d-scene-reconstr.html">MultiEgo: A Multi-View Egocentric Video Dataset for 4D Scene Reconstruction</a></td>
  <td>æå‡ºMultiEgoï¼šç”¨äº4Dåœºæ™¯é‡å»ºçš„å¤šè§†è§’ç¬¬ä¸€äººç§°è§†é¢‘æ•°æ®é›†</td>
  <td class="tags-cell"><span class="paper-tag">scene reconstruction</span> <span class="paper-tag">social interaction</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11301v1" onclick="toggleFavorite(this, '2512.11301v1', 'MultiEgo: A Multi-View Egocentric Video Dataset for 4D Scene Reconstruction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251211524v1-super-resolved-canopy-height-mapping-from-sentinel-2-time-series-usi.html">Super-Resolved Canopy Height Mapping from Sentinel-2 Time Series Using LiDAR HD Reference Data across Metropolitan France</a></td>
  <td>æå‡ºTHREASURE-Netï¼Œåˆ©ç”¨Sentinel-2æ—¶é—´åºåˆ—å’ŒLiDARæ•°æ®è¿›è¡Œé«˜åˆ†è¾¨ç‡æ£®æ—å† å±‚é«˜åº¦åˆ¶å›¾ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">height map</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11524v1" onclick="toggleFavorite(this, '2512.11524v1', 'Super-Resolved Canopy Height Mapping from Sentinel-2 Time Series Using LiDAR HD Reference Data across Metropolitan France')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251211508v1-on-geometric-understanding-and-learned-data-priors-in-vggt.html">On Geometric Understanding and Learned Data Priors in VGGT</a></td>
  <td>åˆ†æVGGTå‡ ä½•ç†è§£èƒ½åŠ›ï¼šæ­ç¤ºå…¶éšå¼å‡ ä½•å­¦ä¹ ä¸æ•°æ®å…ˆéªŒä¾èµ–</td>
  <td class="tags-cell"><span class="paper-tag">VGGT</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11508v1" onclick="toggleFavorite(this, '2512.11508v1', 'On Geometric Understanding and Learned Data Priors in VGGT')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/251211189v1-multi-task-learning-with-extended-temporal-shift-module-for-temporal.html">Multi-task Learning with Extended Temporal Shift Module for Temporal Action Localization</a></td>
  <td>æå‡ºæ‰©å±•æ—¶åºä½ç§»æ¨¡å—çš„å¤šä»»åŠ¡å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºæ—¶åºåŠ¨ä½œå®šä½</td>
  <td class="tags-cell"><span class="paper-tag">localization</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11189v1" onclick="toggleFavorite(this, '2512.11189v1', 'Multi-task Learning with Extended Temporal Shift Module for Temporal Action Localization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251212013v1-exploring-spatial-temporal-representation-via-star-graph-for-mmwave-.html">Exploring Spatial-Temporal Representation via Star Graph for mmWave Radar-based Human Activity Recognition</a></td>
  <td>æå‡ºåŸºäºæ˜Ÿå‹å›¾çš„ç¦»æ•£åŠ¨æ€å›¾ç¥ç»ç½‘ç»œï¼Œç”¨äºæ¯«ç±³æ³¢é›·è¾¾äººä½“æ´»åŠ¨è¯†åˆ«</td>
  <td class="tags-cell"><span class="paper-tag">point cloud</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.12013v1" onclick="toggleFavorite(this, '2512.12013v1', 'Exploring Spatial-Temporal Representation via Star Graph for mmWave Radar-based Human Activity Recognition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/251211798v1-particulate-feed-forward-3d-object-articulation.html">Particulate: Feed-Forward 3D Object Articulation</a></td>
  <td>Particulateï¼šæå‡ºä¸€ç§å‰é¦ˆ3Dç‰©ä½“å…³èŠ‚è¿åŠ¨ä¼°è®¡æ–¹æ³•ï¼Œæ— éœ€é€å¯¹è±¡ä¼˜åŒ–ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">point cloud</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11798v1" onclick="toggleFavorite(this, '2512.11798v1', 'Particulate: Feed-Forward 3D Object Articulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/251211792v1-structure-from-tracking-distilling-structure-preserving-motion-for-v.html">Structure From Tracking: Distilling Structure-Preserving Motion for Video Generation</a></td>
  <td>æå‡ºSAM2VideoXï¼Œé€šè¿‡è’¸é¦ç»“æ„ä¿æŒè¿åŠ¨å…ˆéªŒï¼Œæå‡è§†é¢‘ç”Ÿæˆè´¨é‡ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">optical flow</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11792v1" onclick="toggleFavorite(this, '2512.11792v1', 'Structure From Tracking: Distilling Structure-Preserving Motion for Video Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/251211683v1-depth-copy-paste-multimodal-and-depth-aware-compositing-for-robust-f.html">Depth-Copy-Paste: Multimodal and Depth-Aware Compositing for Robust Face Detection</a></td>
  <td>æå‡ºDepth-Copy-Pasteï¼Œé€šè¿‡å¤šæ¨¡æ€æ·±åº¦æ„ŸçŸ¥åˆæˆå¢å¼ºäººè„¸æ£€æµ‹é²æ£’æ€§ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">Depth Anything</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11683v1" onclick="toggleFavorite(this, '2512.11683v1', 'Depth-Copy-Paste: Multimodal and Depth-Aware Compositing for Robust Face Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/251211645v1-factorportrait-controllable-portrait-animation-via-disentangled-expr.html">FactorPortrait: Controllable Portrait Animation via Disentangled Expression, Pose, and Viewpoint</a></td>
  <td>FactorPortraitï¼šé€šè¿‡è§£è€¦çš„è¡¨æƒ…ã€å§¿åŠ¿å’Œè§†è§’å®ç°å¯æ§çš„äººåƒåŠ¨ç”»</td>
  <td class="tags-cell"><span class="paper-tag">novel view synthesis</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11645v1" onclick="toggleFavorite(this, '2512.11645v1', 'FactorPortrait: Controllable Portrait Animation via Disentangled Expression, Pose, and Viewpoint')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/251211557v1-3dteethsam-taming-sam2-for-3d-teeth-segmentation.html">3DTeethSAM: Taming SAM2 for 3D Teeth Segmentation</a></td>
  <td>3DTeethSAMï¼šåˆ©ç”¨SAM2è¿›è¡Œä¸‰ç»´ç‰™é½¿åˆ†å‰²ï¼Œå®ç°ç‰™ç§‘æ•°å­—åŒ–</td>
  <td class="tags-cell"><span class="paper-tag">localization</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11557v1" onclick="toggleFavorite(this, '2512.11557v1', '3DTeethSAM: Taming SAM2 for 3D Teeth Segmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/251211510v1-reconstruction-as-a-bridge-for-event-based-visual-question-answering.html">Reconstruction as a Bridge for Event-Based Visual Question Answering</a></td>
  <td>æå‡ºåŸºäºé‡å»ºçš„äº‹ä»¶ç›¸æœºè§†è§‰é—®ç­”æ¡†æ¶ï¼Œè§£å†³äº‹ä»¶æ•°æ®ä¸å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹å…¼å®¹æ€§é—®é¢˜ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">scene understanding</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11510v1" onclick="toggleFavorite(this, '2512.11510v1', 'Reconstruction as a Bridge for Event-Based Visual Question Answering')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/251211465v1-dos-distilling-observable-softmaps-of-zipfian-prototypes-for-self-su.html">DOS: Distilling Observable Softmaps of Zipfian Prototypes for Self-Supervised Point Representation</a></td>
  <td>DOSï¼šé€šè¿‡ZipfianåŸå‹è’¸é¦å¯è§‚æµ‹è½¯æ ‡ç­¾ï¼Œå®ç°è‡ªç›‘ç£ç‚¹äº‘è¡¨ç¤ºå­¦ä¹ </td>
  <td class="tags-cell"><span class="paper-tag">point cloud</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11465v1" onclick="toggleFavorite(this, '2512.11465v1', 'DOS: Distilling Observable Softmaps of Zipfian Prototypes for Self-Supervised Point Representation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/251211401v1-collaborative-reconstruction-and-repair-for-multi-class-industrial-a.html">Collaborative Reconstruction and Repair for Multi-class Industrial Anomaly Detection</a></td>
  <td>æå‡ºååŒé‡å»ºä¸ä¿®å¤ç½‘ç»œCRRï¼Œè§£å†³å¤šç±»åˆ«å·¥ä¸šå¼‚å¸¸æ£€æµ‹ä¸­çš„èº«ä»½æ˜ å°„é—®é¢˜ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">localization</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11401v1" onclick="toggleFavorite(this, '2512.11401v1', 'Collaborative Reconstruction and Repair for Multi-class Industrial Anomaly Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/251211369v1-assisted-refinement-network-based-on-channel-information-interaction.html">Assisted Refinement Network Based on Channel Information Interaction for Camouflaged and Salient Object Detection</a></td>
  <td>æå‡ºåŸºäºé€šé“ä¿¡æ¯äº¤äº’çš„è¾…åŠ©ç²¾ç‚¼ç½‘ç»œï¼Œç”¨äºä¼ªè£…ç›®æ ‡æ£€æµ‹å’Œæ˜¾è‘—æ€§ç›®æ ‡æ£€æµ‹ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">localization</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11369v1" onclick="toggleFavorite(this, '2512.11369v1', 'Assisted Refinement Network Based on Channel Information Interaction for Camouflaged and Salient Object Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/251211350v1-surveillance-video-based-traffic-accident-detection-using-transforme.html">Surveillance Video-Based Traffic Accident Detection Using Transformer Architecture</a></td>
  <td>æå‡ºåŸºäºTransformerçš„äº¤é€šè§†é¢‘äº‹æ•…æ£€æµ‹æ¨¡å‹ï¼Œå¹¶æ„å»ºäº†å¤§è§„æ¨¡å¹³è¡¡æ•°æ®é›†ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">optical flow</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11350v1" onclick="toggleFavorite(this, '2512.11350v1', 'Surveillance Video-Based Traffic Accident Detection Using Transformer Architecture')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/251211336v1-ufvideo-towards-unified-fine-grained-video-cooperative-understanding.html">UFVideo: Towards Unified Fine-Grained Video Cooperative Understanding with Large Language Models</a></td>
  <td>æå‡ºUFVideoï¼Œå®ç°ç»Ÿä¸€çš„å¤šç²’åº¦è§†é¢‘ååŒç†è§£ï¼Œè¶…è¶Šç°æœ‰Video LLMã€‚</td>
  <td class="tags-cell"><span class="paper-tag">localization</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11336v1" onclick="toggleFavorite(this, '2512.11336v1', 'UFVideo: Towards Unified Fine-Grained Video Cooperative Understanding with Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/251211215v1-smokebench-evaluating-multimodal-large-language-models-for-wildfire-.html">SmokeBench: Evaluating Multimodal Large Language Models for Wildfire Smoke Detection</a></td>
  <td>SmokeBenchï¼šè¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨é‡ç«çƒŸé›¾æ£€æµ‹ä¸­çš„æ€§èƒ½</td>
  <td class="tags-cell"><span class="paper-tag">localization</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11215v1" onclick="toggleFavorite(this, '2512.11215v1', 'SmokeBench: Evaluating Multimodal Large Language Models for Wildfire Smoke Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (5 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>21</td>
  <td><a href="./papers/251211503v1-tskel-mamba-temporal-dynamic-modeling-via-state-space-model-for-huma.html">TSkel-Mamba: Temporal Dynamic Modeling via State Space Model for Human Skeleton-based Action Recognition</a></td>
  <td>TSkel-Mambaï¼šåˆ©ç”¨çŠ¶æ€ç©ºé—´æ¨¡å‹è¿›è¡Œäººä½“éª¨éª¼åŠ¨ä½œè¯†åˆ«çš„æ—¶åºåŠ¨æ€å»ºæ¨¡</td>
  <td class="tags-cell"><span class="paper-tag">Mamba</span> <span class="paper-tag">SSM</span> <span class="paper-tag">state space model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11503v1" onclick="toggleFavorite(this, '2512.11503v1', 'TSkel-Mamba: Temporal Dynamic Modeling via State Space Model for Human Skeleton-based Action Recognition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>22</td>
  <td><a href="./papers/251211225v1-vfmf-world-modeling-by-forecasting-vision-foundation-model-features.html">VFMF: World Modeling by Forecasting Vision Foundation Model Features</a></td>
  <td>VFMFï¼šé€šè¿‡é¢„æµ‹è§†è§‰åŸºç¡€æ¨¡å‹ç‰¹å¾å®ç°ä¸–ç•Œå»ºæ¨¡</td>
  <td class="tags-cell"><span class="paper-tag">world model</span> <span class="paper-tag">flow matching</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11225v1" onclick="toggleFavorite(this, '2512.11225v1', 'VFMF: World Modeling by Forecasting Vision Foundation Model Features')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>23</td>
  <td><a href="./papers/251211438v1-flowception-temporally-expansive-flow-matching-for-video-generation.html">Flowception: Temporally Expansive Flow Matching for Video Generation</a></td>
  <td>Flowceptionï¼šæ—¶åºæ‰©å±•çš„Flow Matchingç”¨äºå¯å˜é•¿åº¦è§†é¢‘ç”Ÿæˆ</td>
  <td class="tags-cell"><span class="paper-tag">flow matching</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11438v1" onclick="toggleFavorite(this, '2512.11438v1', 'Flowception: Temporally Expansive Flow Matching for Video Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>24</td>
  <td><a href="./papers/251211327v1-physics-informed-video-flare-synthesis-and-removal-leveraging-motion.html">Physics-Informed Video Flare Synthesis and Removal Leveraging Motion Independence between Flare and Scene</a></td>
  <td>æå‡ºä¸€ç§åŸºäºç‰©ç†ä¿¡æ¯çš„è§†é¢‘å…‰æ™•åˆæˆä¸å»é™¤æ–¹æ³•ï¼Œè§£å†³å…‰æ™•ä¸åœºæ™¯è¿åŠ¨ç‹¬ç«‹æ€§é—®é¢˜ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">Mamba</span> <span class="paper-tag">optical flow</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11327v1" onclick="toggleFavorite(this, '2512.11327v1', 'Physics-Informed Video Flare Synthesis and Removal Leveraging Motion Independence between Flare and Scene')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>25</td>
  <td><a href="./papers/251212080v1-bagger-backwards-aggregation-for-mitigating-drift-in-autoregressive-.html">BAgger: Backwards Aggregation for Mitigating Drift in Autoregressive Video Diffusion Models</a></td>
  <td>æå‡ºBAggerï¼Œé€šè¿‡åå‘èšåˆç¼“è§£è‡ªå›å½’è§†é¢‘æ‰©æ•£æ¨¡å‹ä¸­çš„æ¼‚ç§»é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">world model</span> <span class="paper-tag">flow matching</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.12080v1" onclick="toggleFavorite(this, '2512.12080v1', 'BAgger: Backwards Aggregation for Mitigating Drift in Autoregressive Video Diffusion Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (4 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>26</td>
  <td><a href="./papers/251211226v1-futurex-enhance-end-to-end-autonomous-driving-via-latent-chain-of-th.html">FutureX: Enhance End-to-End Autonomous Driving via Latent Chain-of-Thought World Model</a></td>
  <td>FutureXï¼šåŸºäºæ½œåœ¨æ€ç»´é“¾ä¸–ç•Œæ¨¡å‹çš„ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶å¢å¼ºæ–¹æ¡ˆ</td>
  <td class="tags-cell"><span class="paper-tag">motion planning</span> <span class="paper-tag">world model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11226v1" onclick="toggleFavorite(this, '2512.11226v1', 'FutureX: Enhance End-to-End Autonomous Driving via Latent Chain-of-Thought World Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>27</td>
  <td><a href="./papers/251212012v2-semantic-drive-democratizing-long-tail-data-curation-via-open-vocabu.html">Semantic-Drive: Democratizing Long-Tail Data Curation via Open-Vocabulary Grounding and Neuro-Symbolic VLM Consensus</a></td>
  <td>Semantic-Driveï¼šé€šè¿‡å¼€æ”¾è¯æ±‡ grounding å’Œç¥ç»ç¬¦å· VLM å…±è¯†å®ç°é•¿å°¾æ•°æ®æŒ–æ˜</td>
  <td class="tags-cell"><span class="paper-tag">walking</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.12012v2" onclick="toggleFavorite(this, '2512.12012v2', 'Semantic-Drive: Democratizing Long-Tail Data Curation via Open-Vocabulary Grounding and Neuro-Symbolic VLM Consensus')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>28</td>
  <td><a href="./papers/251211799v1-v-rgbx-video-editing-with-accurate-controls-over-intrinsic-propertie.html">V-RGBX: Video Editing with Accurate Controls over Intrinsic Properties</a></td>
  <td>V-RGBXï¼šé¦–ä¸ªæ”¯æŒç²¾ç¡®æ§åˆ¶å†…å‚å±æ€§çš„è§†é¢‘ç¼–è¾‘ç«¯åˆ°ç«¯æ¡†æ¶</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11799v1" onclick="toggleFavorite(this, '2512.11799v1', 'V-RGBX: Video Editing with Accurate Controls over Intrinsic Properties')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>29</td>
  <td><a href="./papers/251211612v1-embodied-image-compression.html">Embodied Image Compression</a></td>
  <td>æå‡ºå…·èº«å›¾åƒå‹ç¼©ï¼Œè§£å†³å…·èº«æ™ºèƒ½ä½“åœ¨ä½æ¯”ç‰¹ç‡ä¸‹çš„å®æ—¶ä»»åŠ¡æ‰§è¡Œé—®é¢˜ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11612v1" onclick="toggleFavorite(this, '2512.11612v1', 'Embodied Image Compression')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion">ğŸ”¬ æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>30</td>
  <td><a href="./papers/251211654v1-kinetic-mining-in-context-few-shot-action-synthesis-via-text-to-moti.html">Kinetic Mining in Context: Few-Shot Action Synthesis via Text-to-Motion Distillation</a></td>
  <td>KineMICï¼šé€šè¿‡æ–‡æœ¬åˆ°åŠ¨ä½œè’¸é¦å®ç°å°‘æ ·æœ¬åŠ¨ä½œåˆæˆï¼Œè§£å†³HARæ•°æ®ç¨€ç¼ºé—®é¢˜ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">text-to-motion</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11654v1" onclick="toggleFavorite(this, '2512.11654v1', 'Kinetic Mining in Context: Few-Shot Action Synthesis via Text-to-Motion Distillation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>31</td>
  <td><a href="./papers/251211321v1-keyframeface-from-text-to-expressive-facial-keyframes.html">KeyframeFace: From Text to Expressive Facial Keyframes</a></td>
  <td>KeyframeFaceï¼šæå‡ºåŸºäºæ–‡æœ¬é©±åŠ¨çš„ã€å¯è§£é‡Šçš„å…³é”®å¸§äººè„¸è¡¨æƒ…åŠ¨ç”»ç”Ÿæˆæ¡†æ¶</td>
  <td class="tags-cell"><span class="paper-tag">motion synthesis</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11321v1" onclick="toggleFavorite(this, '2512.11321v1', 'KeyframeFace: From Text to Expressive Facial Keyframes')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äº”äº¤äº’ä¸ååº”-interaction-reaction">ğŸ”¬ æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>32</td>
  <td><a href="./papers/251211988v1-cari4d-category-agnostic-4d-reconstruction-of-human-object-interacti.html">CARI4D: Category Agnostic 4D Reconstruction of Human-Object Interaction</a></td>
  <td>CARI4Dï¼šæå‡ºä¸€ç§ç±»åˆ«æ— å…³çš„4Däºº-ç‰©äº¤äº’é‡å»ºæ–¹æ³•ï¼Œè§£å†³å•ç›®RGBè§†é¢‘é‡å»ºéš¾é¢˜ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">human-object interaction</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11988v1" onclick="toggleFavorite(this, '2512.11988v1', 'CARI4D: Category Agnostic 4D Reconstruction of Human-Object Interaction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸ƒåŠ¨ä½œé‡å®šå‘-motion-retargeting">ğŸ”¬ æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>33</td>
  <td><a href="./papers/251211480v1-cadmorph-geometry-driven-parametric-cad-editing-via-a-plan-generate-.html">CADMorph: Geometry-Driven Parametric CAD Editing via a Plan-Generate-Verify Loop</a></td>
  <td>CADMorphï¼šæå‡ºå‡ ä½•é©±åŠ¨çš„å‚æ•°åŒ–CADç¼–è¾‘æ¡†æ¶ï¼Œè§£å†³è®¾è®¡è¿­ä»£ä¸­å‡ ä½•å½¢çŠ¶è°ƒæ•´ä¸å‚æ•°åºåˆ—åŒæ­¥ç¼–è¾‘é—®é¢˜ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">structure preservation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11480v1" onclick="toggleFavorite(this, '2512.11480v1', 'CADMorph: Geometry-Driven Parametric CAD Editing via a Plan-Generate-Verify Loop')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CV é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)