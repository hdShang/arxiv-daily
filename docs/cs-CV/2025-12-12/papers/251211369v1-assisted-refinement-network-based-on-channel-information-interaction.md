---
layout: default
title: Assisted Refinement Network Based on Channel Information Interaction for Camouflaged and Salient Object Detection
---

# Assisted Refinement Network Based on Channel Information Interaction for Camouflaged and Salient Object Detection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.11369" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.11369v1</a>
  <a href="https://arxiv.org/pdf/2512.11369.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.11369v1" onclick="toggleFavorite(this, '2512.11369v1', 'Assisted Refinement Network Based on Channel Information Interaction for Camouflaged and Salient Object Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kuan Wang, Yanjun Qin, Mengge Lu, Liejun Wang, Xiaoming Tao

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-12

**å¤‡æ³¨**: 15 pages, 9 figures

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/akuan1234/ARNet-v2)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºé€šé“ä¿¡æ¯äº¤äº’çš„è¾…åŠ©ç²¾ç‚¼ç½‘ç»œï¼Œç”¨äºä¼ªè£…ç›®æ ‡æ£€æµ‹å’Œæ˜¾è‘—æ€§ç›®æ ‡æ£€æµ‹ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `ä¼ªè£…ç›®æ ‡æ£€æµ‹` `æ˜¾è‘—æ€§ç›®æ ‡æ£€æµ‹` `é€šé“ä¿¡æ¯äº¤äº’` `ååŒè§£ç ` `æ³¨æ„åŠ›æœºåˆ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ä¼ªè£…ç›®æ ‡æ£€æµ‹æ–¹æ³•åœ¨è§£ç é˜¶æ®µç¼ºä¹æœ‰æ•ˆçš„è·¨é€šé“ä¿¡æ¯äº¤äº’ï¼Œé™åˆ¶äº†ç‰¹å¾çš„è¡¨è¾¾èƒ½åŠ›ã€‚
2. è®ºæ–‡æå‡ºé€šé“ä¿¡æ¯äº¤äº’æ¨¡å—(CIIM)å’ŒååŒè§£ç æ¶æ„ï¼Œåˆ†åˆ«å¢å¼ºç‰¹å¾è¡¨è¾¾å’ŒååŒå»ºæ¨¡è¾¹ç•Œä¸åŒºåŸŸä¿¡æ¯ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨CODå’ŒSODä»»åŠ¡ä¸Šå‡å–å¾—äº†state-of-the-artçš„æ€§èƒ½ï¼Œå¹¶æˆåŠŸè¿ç§»åˆ°å…¶ä»–ä¸‹æ¸¸ä»»åŠ¡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¼ªè£…ç›®æ ‡æ£€æµ‹(COD)æ˜¯è®¡ç®—æœºè§†è§‰ä¸­çš„ä¸€é¡¹é‡å¤§æŒ‘æˆ˜ï¼Œæ—¨åœ¨è¯†åˆ«å’Œåˆ†å‰²ä¸èƒŒæ™¯é«˜åº¦èåˆçš„å¯¹è±¡ã€‚ç›®å‰ä¸»æµæ–¹æ³•åœ¨è·¨å±‚ç‰¹å¾èåˆæ–¹é¢å–å¾—è¿›å±•ï¼Œä½†åœ¨è§£ç é˜¶æ®µä»å­˜åœ¨ä¸¤ä¸ªå…³é”®é—®é¢˜ï¼šä¸€æ˜¯åŒå±‚ç‰¹å¾å†…è·¨é€šé“ä¿¡æ¯äº¤äº’ä¸è¶³ï¼Œé™åˆ¶äº†ç‰¹å¾è¡¨è¾¾èƒ½åŠ›ï¼›äºŒæ˜¯æ— æ³•æœ‰æ•ˆååŒå»ºæ¨¡è¾¹ç•Œå’ŒåŒºåŸŸä¿¡æ¯ï¼Œéš¾ä»¥å‡†ç¡®é‡å»ºå¯¹è±¡çš„å®Œæ•´åŒºåŸŸå’Œæ¸…æ™°è¾¹ç•Œã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†é€šé“ä¿¡æ¯äº¤äº’æ¨¡å—(CIIM)ï¼Œå¼•å…¥äº†ä¸€ç§é€šé“ç»´åº¦ä¸Šçš„æ°´å¹³-å‚ç›´é›†æˆæœºåˆ¶ï¼Œæ‰§è¡Œè·¨é€šé“çš„ç‰¹å¾é‡ç»„å’Œäº¤äº’ï¼Œæœ‰æ•ˆæ•è·äº’è¡¥çš„è·¨é€šé“ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªç”±å…ˆéªŒçŸ¥è¯†å¼•å¯¼çš„ååŒè§£ç æ¶æ„ï¼Œé€šè¿‡è¾¹ç•Œæå–(BE)å’ŒåŒºåŸŸæå–(RE)æ¨¡å—ç”Ÿæˆè¾¹ç•Œå…ˆéªŒå’Œå¯¹è±¡å®šä½å›¾ï¼Œç„¶ååˆ©ç”¨æ··åˆæ³¨æ„åŠ›ååŒæ ¡å‡†è§£ç ç‰¹å¾ï¼Œæœ‰æ•ˆå…‹æœè¯­ä¹‰æ¨¡ç³Šå’Œä¸ç²¾ç¡®è¾¹ç•Œã€‚å¤šå°ºåº¦å¢å¼º(MSE)æ¨¡å—ä¸°å¯Œäº†ä¸Šä¸‹æ–‡ç‰¹å¾è¡¨ç¤ºã€‚åœ¨å››ä¸ªCODåŸºå‡†æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒéªŒè¯äº†æ‰€æå‡ºæ¨¡å‹çš„æœ‰æ•ˆæ€§å’Œæœ€å…ˆè¿›æ€§èƒ½ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥å°†æ¨¡å‹è¿ç§»åˆ°æ˜¾è‘—æ€§ç›®æ ‡æ£€æµ‹(SOD)ä»»åŠ¡ï¼Œå¹¶å±•ç¤ºäº†å…¶åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­çš„é€‚åº”æ€§ï¼ŒåŒ…æ‹¬æ¯è‚‰åˆ†å‰²ã€é€æ˜å¯¹è±¡æ£€æµ‹ä»¥åŠå·¥ä¸šå’Œé“è·¯ç¼ºé™·æ£€æµ‹ã€‚ä»£ç å’Œå®éªŒç»“æœå·²å…¬å¼€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šä¼ªè£…ç›®æ ‡æ£€æµ‹æ—¨åœ¨è¯†åˆ«å¹¶åˆ†å‰²ä¸èƒŒæ™¯é«˜åº¦èåˆçš„ç›®æ ‡ã€‚ç°æœ‰æ–¹æ³•åœ¨è·¨å±‚ç‰¹å¾èåˆæ–¹é¢æœ‰æ‰€è¿›å±•ï¼Œä½†è§£ç é˜¶æ®µå­˜åœ¨ä¸¤ä¸ªä¸»è¦ç—›ç‚¹ï¼šä¸€æ˜¯åŒå±‚ç‰¹å¾å†…éƒ¨çš„è·¨é€šé“ä¿¡æ¯äº¤äº’ä¸è¶³ï¼Œå¯¼è‡´ç‰¹å¾è¡¨è¾¾èƒ½åŠ›å—é™ï¼›äºŒæ˜¯è¾¹ç•Œå’ŒåŒºåŸŸä¿¡æ¯æ— æ³•æœ‰æ•ˆååŒå»ºæ¨¡ï¼Œéš¾ä»¥å‡†ç¡®é‡å»ºç›®æ ‡çš„å®Œæ•´åŒºåŸŸå’Œæ¸…æ™°è¾¹ç•Œã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å¢å¼ºç‰¹å¾è¡¨è¾¾èƒ½åŠ›ï¼Œå¹¶ååŒå»ºæ¨¡è¾¹ç•Œå’ŒåŒºåŸŸä¿¡æ¯ã€‚é€šè¿‡é€šé“ä¿¡æ¯äº¤äº’æ¨¡å—(CIIM)æ¥ä¿ƒè¿›è·¨é€šé“ä¿¡æ¯äº¤äº’ï¼Œæå‡ç‰¹å¾çš„åˆ¤åˆ«æ€§ã€‚åŒæ—¶ï¼Œåˆ©ç”¨è¾¹ç•Œæå–(BE)å’ŒåŒºåŸŸæå–(RE)æ¨¡å—ç”Ÿæˆå…ˆéªŒçŸ¥è¯†ï¼ŒæŒ‡å¯¼è§£ç è¿‡ç¨‹ï¼Œä»è€Œæ›´å‡†ç¡®åœ°åˆ†å‰²ç›®æ ‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ç¼–ç å™¨ã€CIIMã€BEæ¨¡å—ã€REæ¨¡å—ã€ååŒè§£ç æ¶æ„å’ŒMSEæ¨¡å—ã€‚ç¼–ç å™¨æå–å¤šå°ºåº¦ç‰¹å¾ï¼ŒCIIMå¢å¼ºç‰¹å¾è¡¨è¾¾ï¼ŒBEå’ŒREæ¨¡å—åˆ†åˆ«æå–è¾¹ç•Œå’ŒåŒºåŸŸå…ˆéªŒï¼ŒååŒè§£ç æ¶æ„åˆ©ç”¨è¿™äº›å…ˆéªŒä¿¡æ¯æ ¡å‡†è§£ç ç‰¹å¾ï¼ŒMSEæ¨¡å—è¿›ä¸€æ­¥ä¸°å¯Œä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚æ•´ä¸ªæµç¨‹æ—¨åœ¨æå‡æ¨¡å‹å¯¹ä¼ªè£…ç›®æ ‡çš„æ„ŸçŸ¥èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†CIIMï¼Œé€šè¿‡æ°´å¹³-å‚ç›´é›†æˆæœºåˆ¶å®ç°è·¨é€šé“ä¿¡æ¯äº¤äº’ï¼Œæœ‰æ•ˆæå‡äº†ç‰¹å¾çš„è¡¨è¾¾èƒ½åŠ›ã€‚2) æ„å»ºäº†ååŒè§£ç æ¶æ„ï¼Œåˆ©ç”¨è¾¹ç•Œå’ŒåŒºåŸŸå…ˆéªŒçŸ¥è¯†æŒ‡å¯¼è§£ç è¿‡ç¨‹ï¼Œå…‹æœäº†è¯­ä¹‰æ¨¡ç³Šå’Œè¾¹ç•Œä¸ç²¾ç¡®çš„é—®é¢˜ã€‚3) æå‡ºäº†MSEæ¨¡å—ï¼Œè¿›ä¸€æ­¥å¢å¼ºäº†ä¸Šä¸‹æ–‡ç‰¹å¾è¡¨ç¤ºã€‚

**å…³é”®è®¾è®¡**ï¼šCIIMæ¨¡å—é‡‡ç”¨æ°´å¹³å’Œå‚ç›´æ–¹å‘çš„å·ç§¯æ“ä½œï¼Œä»¥æ•è·ä¸åŒæ–¹å‘ä¸Šçš„é€šé“ä¾èµ–å…³ç³»ã€‚ååŒè§£ç æ¶æ„ä½¿ç”¨æ··åˆæ³¨æ„åŠ›æœºåˆ¶ï¼Œèåˆè¾¹ç•Œå’ŒåŒºåŸŸå…ˆéªŒä¿¡æ¯ï¼Œè‡ªé€‚åº”åœ°è°ƒæ•´è§£ç ç‰¹å¾ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬åˆ†å‰²æŸå¤±ã€è¾¹ç•ŒæŸå¤±å’ŒåŒºåŸŸæŸå¤±ï¼Œä»¥å…±åŒä¼˜åŒ–æ¨¡å‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥æ¨¡å‹åœ¨å››ä¸ªä¼ªè£…ç›®æ ‡æ£€æµ‹åŸºå‡†æ•°æ®é›†ä¸Šå–å¾—äº†state-of-the-artçš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨XXXæ•°æ®é›†ä¸Šï¼ŒæŒ‡æ ‡S-measureæå‡äº†X%ï¼ŒE-measureæå‡äº†Y%ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹æˆåŠŸè¿ç§»åˆ°æ˜¾è‘—æ€§ç›®æ ‡æ£€æµ‹ä»»åŠ¡ï¼Œå¹¶åœ¨æ¯è‚‰åˆ†å‰²ã€é€æ˜å¯¹è±¡æ£€æµ‹ç­‰ä¸‹æ¸¸ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰¯å¥½çš„é€‚åº”æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¤šä¸ªé¢†åŸŸï¼ŒåŒ…æ‹¬åŒ»å­¦å›¾åƒåˆ†æï¼ˆå¦‚æ¯è‚‰æ£€æµ‹ï¼‰ã€å·¥ä¸šæ£€æµ‹ï¼ˆå¦‚ç¼ºé™·æ£€æµ‹ï¼‰ã€è‡ªåŠ¨é©¾é©¶ï¼ˆå¦‚é“è·¯ç¼ºé™·æ£€æµ‹ï¼‰ä»¥åŠå®‰å…¨ç›‘æ§ç­‰ã€‚é€šè¿‡æé«˜å¯¹ä¼ªè£…ç›®æ ‡çš„æ£€æµ‹ç²¾åº¦ï¼Œå¯ä»¥æå‡ç›¸å…³ç³»ç»Ÿçš„æ™ºèƒ½åŒ–æ°´å¹³å’Œå¯é æ€§ï¼Œå…·æœ‰é‡è¦çš„å®é™…åº”ç”¨ä»·å€¼å’Œæ½œåœ¨çš„ç¤¾ä¼šç»æµæ•ˆç›Šã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Camouflaged Object Detection (COD) stands as a significant challenge in computer vision, dedicated to identifying and segmenting objects visually highly integrated with their backgrounds. Current mainstream methods have made progress in cross-layer feature fusion, but two critical issues persist during the decoding stage. The first is insufficient cross-channel information interaction within the same-layer features, limiting feature expressiveness. The second is the inability to effectively co-model boundary and region information, making it difficult to accurately reconstruct complete regions and sharp boundaries of objects. To address the first issue, we propose the Channel Information Interaction Module (CIIM), which introduces a horizontal-vertical integration mechanism in the channel dimension. This module performs feature reorganization and interaction across channels to effectively capture complementary cross-channel information. To address the second issue, we construct a collaborative decoding architecture guided by prior knowledge. This architecture generates boundary priors and object localization maps through Boundary Extraction (BE) and Region Extraction (RE) modules, then employs hybrid attention to collaboratively calibrate decoded features, effectively overcoming semantic ambiguity and imprecise boundaries. Additionally, the Multi-scale Enhancement (MSE) module enriches contextual feature representations. Extensive experiments on four COD benchmark datasets validate the effectiveness and state-of-the-art performance of the proposed model. We further transferred our model to the Salient Object Detection (SOD) task and demonstrated its adaptability across downstream tasks, including polyp segmentation, transparent object detection, and industrial and road defect detection. Code and experimental results are publicly available at: https://github.com/akuan1234/ARNet-v2.

