---
layout: default
title: 3DTeethSAM: Taming SAM2 for 3D Teeth Segmentation
---

# 3DTeethSAM: Taming SAM2 for 3D Teeth Segmentation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.11557" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.11557v1</a>
  <a href="https://arxiv.org/pdf/2512.11557.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.11557v1" onclick="toggleFavorite(this, '2512.11557v1', '3DTeethSAM: Taming SAM2 for 3D Teeth Segmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhiguo Lu, Jianwen Lou, Mingjun Ma, Hairong Jin, Youyi Zheng, Kun Zhou

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-12

**å¤‡æ³¨**: Accepted by AAAI 2026

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**3DTeethSAMï¼šåˆ©ç”¨SAM2è¿›è¡Œä¸‰ç»´ç‰™é½¿åˆ†å‰²ï¼Œå®ç°ç‰™ç§‘æ•°å­—åŒ–**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `ä¸‰ç»´ç‰™é½¿åˆ†å‰²` `SAM2` `æ•°å­—åŒ–ç‰™ç§‘` `å¯å˜å½¢æ³¨æ„åŠ›` `å›¾åƒæ¸²æŸ“`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¸‰ç»´ç‰™é½¿åˆ†å‰²åœ¨æ•°å­—åŒ–ç‰™ç§‘ä¸­è‡³å…³é‡è¦ï¼Œä½†ç”±äºç‰™é½¿ç»“æ„çš„å¤æ‚æ€§ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥è¾¾åˆ°ç†æƒ³çš„åˆ†å‰²ç²¾åº¦å’Œæ•ˆç‡ã€‚
2. 3DTeethSAMé€šè¿‡æ¸²æŸ“3Dç‰™é½¿æ¨¡å‹å›¾åƒï¼Œåˆ©ç”¨SAM2è¿›è¡Œ2Dåˆ†å‰²ï¼Œå†æŠ•å½±å›3Dç©ºé—´ï¼Œå¹¶å¼•å…¥è½»é‡çº§æ¨¡å—ä¼˜åŒ–åˆ†å‰²ç»“æœã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨3DTeethSegåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†91.90%çš„IoUï¼Œæ˜¾è‘—æå‡äº†ä¸‰ç»´ç‰™é½¿åˆ†å‰²çš„æ€§èƒ½ï¼Œè¾¾åˆ°æ–°çš„SOTAã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡º3DTeethSAMï¼Œä¸€ç§ç”¨äºä¸‰ç»´ç‰™é½¿åˆ†å‰²çš„Segment Anything Model 2 (SAM2)çš„æ”¹è¿›æ–¹æ³•ã€‚ä¸‰ç»´ç‰™é½¿åˆ†å‰²ï¼ŒåŒ…æ‹¬åœ¨ä¸‰ç»´ç‰™ç§‘æ¨¡å‹ä¸­å®šä½ç‰™é½¿å®ä¾‹åŠå…¶è¯­ä¹‰åˆ†ç±»ï¼Œæ˜¯æ•°å­—åŒ–ç‰™ç§‘ä¸­ä¸€é¡¹å…³é”®ä½†å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œå› ä¸ºç°å®ä¸–ç•Œä¸­çš„ç‰™åˆ—éå¸¸å¤æ‚ã€‚SAM2æ˜¯ä¸€ä¸ªç”¨äºå›¾åƒå’Œè§†é¢‘åˆ†å‰²çš„é¢„è®­ç»ƒåŸºç¡€æ¨¡å‹ï¼Œåœ¨å„ç§ä¸‹æ¸¸åœºæ™¯ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„éª¨å¹²èƒ½åŠ›ã€‚ä¸ºäº†ä½¿SAM2é€‚åº”ä¸‰ç»´ç‰™é½¿æ•°æ®ï¼Œæˆ‘ä»¬ä»é¢„å®šä¹‰çš„è§†å›¾æ¸²æŸ“ä¸‰ç»´ç‰™é½¿æ¨¡å‹çš„å›¾åƒï¼Œåº”ç”¨SAM2è¿›è¡ŒäºŒç»´åˆ†å‰²ï¼Œå¹¶ä½¿ç”¨äºŒç»´-ä¸‰ç»´æŠ•å½±é‡å»ºä¸‰ç»´ç»“æœã€‚ç”±äºSAM2çš„æ€§èƒ½å–å†³äºè¾“å…¥æç¤ºï¼Œå¹¶ä¸”å…¶åˆå§‹è¾“å‡ºé€šå¸¸å­˜åœ¨ç¼ºé™·ï¼Œå¹¶ä¸”è€ƒè™‘åˆ°å…¶ç±»åˆ«æ— å…³çš„æ€§è´¨ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸‰ä¸ªè½»é‡çº§çš„å¯å­¦ä¹ æ¨¡å—ï¼šï¼ˆ1ï¼‰ä¸€ä¸ªæç¤ºåµŒå…¥ç”Ÿæˆå™¨ï¼Œç”¨äºä»å›¾åƒåµŒå…¥ä¸­å¯¼å‡ºæç¤ºåµŒå…¥ï¼Œä»¥è¿›è¡Œç²¾ç¡®çš„æ©ç è§£ç ï¼Œï¼ˆ2ï¼‰ä¸€ä¸ªæ©ç ç»†åŒ–å™¨ï¼Œç”¨äºå¢å¼ºSAM2çš„åˆå§‹åˆ†å‰²ç»“æœï¼Œä»¥åŠï¼ˆ3ï¼‰ä¸€ä¸ªæ©ç åˆ†ç±»å™¨ï¼Œç”¨äºå¯¹ç”Ÿæˆçš„æ©ç è¿›è¡Œåˆ†ç±»ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†å¯å˜å½¢å…¨å±€æ³¨æ„åŠ›æ’ä»¶ï¼ˆDGAPï¼‰é›†æˆåˆ°SAM2çš„å›¾åƒç¼–ç å™¨ä¸­ã€‚DGAPæé«˜äº†åˆ†å‰²ç²¾åº¦å’Œè®­ç»ƒé€Ÿåº¦ã€‚æˆ‘ä»¬çš„æ–¹æ³•å·²åœ¨3DTeethSegåŸºå‡†ä¸Šå¾—åˆ°éªŒè¯ï¼Œåœ¨é«˜åˆ†è¾¨ç‡ä¸‰ç»´ç‰™é½¿ç½‘æ ¼ä¸Šå®ç°äº†91.90%çš„IoUï¼Œåœ¨è¯¥é¢†åŸŸå»ºç«‹äº†æ–°çš„æœ€å…ˆè¿›æ°´å¹³ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ä¸‰ç»´ç‰™é½¿åˆ†å‰²é—®é¢˜ï¼Œå³åœ¨ä¸‰ç»´ç‰™ç§‘æ¨¡å‹ä¸­å‡†ç¡®åœ°å®šä½å’Œåˆ†å‰²å‡ºæ¯ä¸ªç‰™é½¿å®ä¾‹ï¼Œå¹¶è¿›è¡Œè¯­ä¹‰åˆ†ç±»ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚ç‰™é½¿ç»“æ„æ—¶ï¼Œåˆ†å‰²ç²¾åº¦å’Œæ•ˆç‡è¾ƒä½ï¼Œéš¾ä»¥æ»¡è¶³å®é™…åº”ç”¨éœ€æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨é¢„è®­ç»ƒçš„SAM2æ¨¡å‹å¼ºå¤§çš„åˆ†å‰²èƒ½åŠ›ï¼Œå¹¶é’ˆå¯¹ä¸‰ç»´ç‰™é½¿æ•°æ®çš„ç‰¹ç‚¹è¿›è¡Œé€‚é…å’Œä¼˜åŒ–ã€‚é€šè¿‡å°†ä¸‰ç»´æ•°æ®æ¸²æŸ“æˆäºŒç»´å›¾åƒï¼Œåˆ©ç”¨SAM2è¿›è¡Œåˆ†å‰²ï¼Œå†å°†åˆ†å‰²ç»“æœæŠ•å½±å›ä¸‰ç»´ç©ºé—´ï¼Œä»è€Œå®ç°ä¸‰ç»´ç‰™é½¿åˆ†å‰²ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼š3DTeethSAMçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) 3Dç‰™é½¿æ¨¡å‹æ¸²æŸ“æ¨¡å—ï¼šå°†ä¸‰ç»´ç‰™é½¿æ¨¡å‹ä»é¢„å®šä¹‰è§†è§’æ¸²æŸ“æˆäºŒç»´å›¾åƒï¼›2) SAM2åˆ†å‰²æ¨¡å—ï¼šåˆ©ç”¨SAM2å¯¹äºŒç»´å›¾åƒè¿›è¡Œåˆ†å‰²ï¼Œç”Ÿæˆåˆå§‹çš„åˆ†å‰²æ©ç ï¼›3) æç¤ºåµŒå…¥ç”Ÿæˆå™¨ï¼šä»å›¾åƒåµŒå…¥ä¸­ç”Ÿæˆæç¤ºåµŒå…¥ï¼Œç”¨äºæ›´ç²¾ç¡®çš„æ©ç è§£ç ï¼›4) æ©ç ç»†åŒ–å™¨ï¼šå¯¹SAM2çš„åˆå§‹åˆ†å‰²ç»“æœè¿›è¡Œç»†åŒ–ï¼Œæé«˜åˆ†å‰²ç²¾åº¦ï¼›5) æ©ç åˆ†ç±»å™¨ï¼šå¯¹ç”Ÿæˆçš„æ©ç è¿›è¡Œåˆ†ç±»ï¼Œç¡®å®šæ¯ä¸ªæ©ç å¯¹åº”çš„ç‰™é½¿ç±»åˆ«ï¼›6) å¯å˜å½¢å…¨å±€æ³¨æ„åŠ›æ’ä»¶ï¼ˆDGAPï¼‰ï¼šé›†æˆåˆ°SAM2çš„å›¾åƒç¼–ç å™¨ä¸­ï¼Œæé«˜åˆ†å‰²ç²¾åº¦å’Œè®­ç»ƒé€Ÿåº¦ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†SAM2åº”ç”¨äºä¸‰ç»´ç‰™é½¿åˆ†å‰²ï¼Œå¹¶é’ˆå¯¹è¯¥ä»»åŠ¡çš„ç‰¹ç‚¹ï¼Œè®¾è®¡äº†è½»é‡çº§çš„å¯å­¦ä¹ æ¨¡å—ï¼ŒåŒ…æ‹¬æç¤ºåµŒå…¥ç”Ÿæˆå™¨ã€æ©ç ç»†åŒ–å™¨å’Œæ©ç åˆ†ç±»å™¨ã€‚æ­¤å¤–ï¼ŒDGAPçš„å¼•å…¥è¿›ä¸€æ­¥æé«˜äº†åˆ†å‰²ç²¾åº¦å’Œè®­ç»ƒé€Ÿåº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šæç¤ºåµŒå…¥ç”Ÿæˆå™¨ç”¨äºä»å›¾åƒåµŒå…¥ä¸­å¯¼å‡ºæç¤ºåµŒå…¥ï¼Œä»¥æŒ‡å¯¼SAM2è¿›è¡Œæ›´ç²¾ç¡®çš„æ©ç è§£ç ã€‚æ©ç ç»†åŒ–å™¨é‡‡ç”¨è½»é‡çº§çš„å·ç§¯ç¥ç»ç½‘ç»œï¼Œå¯¹SAM2çš„åˆå§‹åˆ†å‰²ç»“æœè¿›è¡Œç»†åŒ–ï¼Œå»é™¤å™ªå£°å’Œä¸å‡†ç¡®çš„åˆ†å‰²åŒºåŸŸã€‚æ©ç åˆ†ç±»å™¨ç”¨äºå¯¹ç”Ÿæˆçš„æ©ç è¿›è¡Œåˆ†ç±»ï¼Œç¡®å®šæ¯ä¸ªæ©ç å¯¹åº”çš„ç‰™é½¿ç±»åˆ«ã€‚DGAPé€šè¿‡å¯å˜å½¢å·ç§¯ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæé«˜åˆ†å‰²ç²¾åº¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œ3DTeethSAMåœ¨3DTeethSegåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†91.90%çš„IoUï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå»ºç«‹äº†æ–°çš„state-of-the-artã€‚DGAPçš„å¼•å…¥è¿›ä¸€æ­¥æé«˜äº†åˆ†å‰²ç²¾åº¦å’Œè®­ç»ƒé€Ÿåº¦ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œ3DTeethSAMæ˜¯ä¸€ç§æœ‰æ•ˆçš„ä¸‰ç»´ç‰™é½¿åˆ†å‰²æ–¹æ³•ï¼Œå…·æœ‰å¾ˆé«˜çš„åº”ç”¨ä»·å€¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºæ•°å­—åŒ–ç‰™ç§‘é¢†åŸŸï¼Œä¾‹å¦‚è¾…åŠ©ç‰™é½¿çŸ«æ­£ã€ç§æ¤ç‰™æ‰‹æœ¯è§„åˆ’ã€ç‰™é½¿ç–¾ç—…è¯Šæ–­ç­‰ã€‚é€šè¿‡ç²¾ç¡®çš„ä¸‰ç»´ç‰™é½¿åˆ†å‰²ï¼ŒåŒ»ç”Ÿå¯ä»¥æ›´å‡†ç¡®åœ°è¯„ä¼°æ‚£è€…çš„ç‰™é½¿çŠ¶å†µï¼Œåˆ¶å®šæ›´æœ‰æ•ˆçš„æ²»ç–—æ–¹æ¡ˆï¼Œæé«˜æ²»ç–—æ•ˆæœã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥åº”ç”¨äºç‰™ç§‘æ•™è‚²å’Œç§‘ç ”é¢†åŸŸï¼Œä¾‹å¦‚ç”¨äºæ„å»ºè™šæ‹Ÿç‰™é½¿æ¨¡å‹ã€è¿›è¡Œç‰™é½¿å½¢æ€åˆ†æç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> 3D teeth segmentation, involving the localization of tooth instances and their semantic categorization in 3D dental models, is a critical yet challenging task in digital dentistry due to the complexity of real-world dentition. In this paper, we propose 3DTeethSAM, an adaptation of the Segment Anything Model 2 (SAM2) for 3D teeth segmentation. SAM2 is a pretrained foundation model for image and video segmentation, demonstrating a strong backbone in various downstream scenarios. To adapt SAM2 for 3D teeth data, we render images of 3D teeth models from predefined views, apply SAM2 for 2D segmentation, and reconstruct 3D results using 2D-3D projections. Since SAM2's performance depends on input prompts and its initial outputs often have deficiencies, and given its class-agnostic nature, we introduce three light-weight learnable modules: (1) a prompt embedding generator to derive prompt embeddings from image embeddings for accurate mask decoding, (2) a mask refiner to enhance SAM2's initial segmentation results, and (3) a mask classifier to categorize the generated masks. Additionally, we incorporate Deformable Global Attention Plugins (DGAP) into SAM2's image encoder. The DGAP enhances both the segmentation accuracy and the speed of the training process. Our method has been validated on the 3DTeethSeg benchmark, achieving an IoU of 91.90% on high-resolution 3D teeth meshes, establishing a new state-of-the-art in the field.

