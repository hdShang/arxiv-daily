---
layout: default
title: Particulate: Feed-Forward 3D Object Articulation
---

# Particulate: Feed-Forward 3D Object Articulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.11798" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.11798v1</a>
  <a href="https://arxiv.org/pdf/2512.11798.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.11798v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.11798v1', 'Particulate: Feed-Forward 3D Object Articulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ruining Li, Yuxin Yao, Chuanxia Zheng, Christian Rupprecht, Joan Lasenby, Shangzhe Wu, Andrea Vedaldi

**åˆ†ç±»**: cs.CV, cs.AI, cs.GR

**å‘å¸ƒæ—¥æœŸ**: 2025-12-12

**å¤‡æ³¨**: Project page: https://ruiningli.com/particulate

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Particulateï¼šæå‡ºä¸€ç§å‰é¦ˆ3Dç‰©ä½“å…³èŠ‚è¿åŠ¨ä¼°è®¡æ–¹æ³•ï¼Œæ— éœ€é€å¯¹è±¡ä¼˜åŒ–ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `3Dç‰©ä½“å…³èŠ‚è¿åŠ¨ä¼°è®¡` `Transformerç½‘ç»œ` `ç‚¹äº‘å¤„ç†` `å‰é¦ˆç½‘ç»œ` `è¿åŠ¨å­¦ç»“æ„` `éƒ¨ä»¶åˆ†å‰²`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰3Dç‰©ä½“å…³èŠ‚è¿åŠ¨ä¼°è®¡æ–¹æ³•é€šå¸¸éœ€è¦é€å¯¹è±¡ä¼˜åŒ–ï¼Œè®¡ç®—æˆæœ¬é«˜ï¼Œéš¾ä»¥å¿«é€Ÿéƒ¨ç½²ã€‚
2. Particulateé‡‡ç”¨å‰é¦ˆTransformerç½‘ç»œç›´æ¥ä»3Dç½‘æ ¼é¢„æµ‹å…³èŠ‚ç»“æ„ï¼Œæ— éœ€è¿­ä»£ä¼˜åŒ–ï¼Œé€Ÿåº¦æ›´å¿«ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒParticulateåœ¨å…³èŠ‚è¿åŠ¨ä¼°è®¡ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶å¯åº”ç”¨äºAIç”Ÿæˆçš„3Dèµ„äº§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºParticulateçš„å‰é¦ˆæ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä»…éœ€ä¸€ä¸ªé™æ€3Dç½‘æ ¼å³å¯ç›´æ¥æ¨æ–­å‡ºåº•å±‚å…³èŠ‚ç»“æ„çš„æ‰€æœ‰å±æ€§ï¼ŒåŒ…æ‹¬å…¶3Déƒ¨ä»¶ã€è¿åŠ¨å­¦ç»“æ„å’Œè¿åŠ¨çº¦æŸã€‚å…¶æ ¸å¿ƒæ˜¯ä¸€ä¸ªTransformerç½‘ç»œï¼Œå³Part Articulation Transformerï¼Œå®ƒä½¿ç”¨çµæ´»ä¸”å¯æ‰©å±•çš„æ¶æ„å¤„ç†è¾“å…¥ç½‘æ ¼çš„ç‚¹äº‘ï¼Œä»¥é¢„æµ‹æ‰€æœ‰ä¸Šè¿°å±æ€§ï¼Œå¹¶åŸç”Ÿæ”¯æŒå¤šå…³èŠ‚ã€‚æˆ‘ä»¬åœ¨æ¥è‡ªå…¬å…±æ•°æ®é›†çš„å„ç§å…³èŠ‚3Dèµ„äº§ä¸Šç«¯åˆ°ç«¯åœ°è®­ç»ƒè¯¥ç½‘ç»œã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼ŒParticulateå°†ç½‘ç»œçš„é¢„æµ‹ç»“æœæ˜ å°„åˆ°è¾“å…¥ç½‘æ ¼ï¼Œä»è€Œåœ¨å‡ ç§’é’Ÿå†…ç”Ÿæˆä¸€ä¸ªå®Œå…¨å…³èŠ‚åŒ–çš„3Dæ¨¡å‹ï¼Œè¿™æ¯”éœ€è¦é€å¯¹è±¡ä¼˜åŒ–çš„å…ˆå‰æ–¹æ³•å¿«å¾—å¤šã€‚Particulateè¿˜å¯ä»¥å‡†ç¡®åœ°æ¨æ–­AIç”Ÿæˆçš„3Dèµ„äº§çš„å…³èŠ‚ç»“æ„ï¼Œå½“ä¸ç°æˆçš„å›¾åƒåˆ°3Dç”Ÿæˆå™¨ç»“åˆä½¿ç”¨æ—¶ï¼Œèƒ½å¤Ÿä»å•ä¸ªï¼ˆçœŸå®æˆ–åˆæˆï¼‰å›¾åƒä¸­å®Œå…¨æå–å…³èŠ‚3Då¯¹è±¡ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥å¼•å…¥äº†ä¸€ä¸ªæ–°çš„å…·æœ‰æŒ‘æˆ˜æ€§çš„3Då…³èŠ‚ä¼°è®¡åŸºå‡†ï¼Œè¯¥åŸºå‡†ä»é«˜è´¨é‡çš„å…¬å…±3Dèµ„äº§ä¸­æ•´ç†è€Œæ¥ï¼Œå¹¶é‡æ–°è®¾è®¡äº†è¯„ä¼°åè®®ï¼Œä½¿å…¶ä¸äººç±»åå¥½æ›´åŠ ä¸€è‡´ã€‚å®šé‡å’Œå®šæ€§ç»“æœè¡¨æ˜ï¼ŒParticulateæ˜æ˜¾ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰3Dç‰©ä½“å…³èŠ‚è¿åŠ¨ä¼°è®¡æ–¹æ³•ï¼Œå¦‚ä¼˜åŒ–æ–¹æ³•ï¼Œé€šå¸¸éœ€è¦å¯¹æ¯ä¸ªå¯¹è±¡è¿›è¡Œå•ç‹¬çš„ä¼˜åŒ–ï¼Œè®¡ç®—é‡å¤§ï¼Œè€—æ—¶è¾ƒé•¿ï¼Œéš¾ä»¥æ»¡è¶³å¿«é€Ÿæ¨ç†çš„éœ€æ±‚ã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•åœ¨å¤„ç†AIç”Ÿæˆçš„3Dèµ„äº§æ—¶ï¼Œç”±äºå…¶ç»“æ„å¤æ‚æ€§å’Œå™ªå£°ï¼Œæ€§èƒ½å¯èƒ½ä¼šä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šParticulateçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨Transformerç½‘ç»œå¼ºå¤§çš„ç‰¹å¾æå–å’Œå»ºæ¨¡èƒ½åŠ›ï¼Œç›´æ¥ä»3Dç½‘æ ¼çš„ç‚¹äº‘æ•°æ®ä¸­é¢„æµ‹ç‰©ä½“çš„å…³èŠ‚ç»“æ„ã€‚é€šè¿‡ç«¯åˆ°ç«¯çš„è®­ç»ƒï¼Œç½‘ç»œå¯ä»¥å­¦ä¹ åˆ°3Då½¢çŠ¶ä¸å…³èŠ‚å±æ€§ä¹‹é—´çš„æ˜ å°„å…³ç³»ï¼Œä»è€Œå®ç°å¿«é€Ÿä¸”å‡†ç¡®çš„å…³èŠ‚è¿åŠ¨ä¼°è®¡ã€‚è¿™ç§å‰é¦ˆæ–¹æ³•é¿å…äº†è€—æ—¶çš„é€å¯¹è±¡ä¼˜åŒ–ï¼Œæé«˜äº†æ¨ç†æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šParticulateçš„æ•´ä½“æ¶æ„åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) ç‚¹äº‘é‡‡æ ·ï¼šä»è¾“å…¥çš„3Dç½‘æ ¼ä¸­é‡‡æ ·å¾—åˆ°ç‚¹äº‘æ•°æ®ã€‚2) Part Articulation Transformerï¼šä¸€ä¸ªåŸºäºTransformerçš„ç½‘ç»œï¼Œç”¨äºå¤„ç†ç‚¹äº‘æ•°æ®å¹¶é¢„æµ‹å…³èŠ‚å±æ€§ï¼ŒåŒ…æ‹¬éƒ¨ä»¶åˆ†å‰²ã€è¿åŠ¨å­¦ç»“æ„å’Œè¿åŠ¨çº¦æŸã€‚3) å…³èŠ‚ç»“æ„æ˜ å°„ï¼šå°†ç½‘ç»œé¢„æµ‹çš„å…³èŠ‚å±æ€§æ˜ å°„å›åŸå§‹3Dç½‘æ ¼ï¼Œç”Ÿæˆä¸€ä¸ªå®Œå…¨å…³èŠ‚åŒ–çš„3Dæ¨¡å‹ã€‚æ•´ä¸ªæµç¨‹æ˜¯ç«¯åˆ°ç«¯å¯è®­ç»ƒçš„ã€‚

**å…³é”®åˆ›æ–°**ï¼šParticulateçš„å…³é”®åˆ›æ–°åœ¨äºå…¶å‰é¦ˆçš„æ¶æ„å’ŒPart Articulation Transformerçš„è®¾è®¡ã€‚ä¸éœ€è¦é€å¯¹è±¡ä¼˜åŒ–çš„ä¼ ç»Ÿæ–¹æ³•ä¸åŒï¼ŒParticulateç›´æ¥ä»3Dç½‘æ ¼é¢„æµ‹å…³èŠ‚ç»“æ„ï¼Œå¤§å¤§æé«˜äº†æ¨ç†é€Ÿåº¦ã€‚Part Articulation Transformerèƒ½å¤Ÿæœ‰æ•ˆåœ°å¤„ç†ç‚¹äº‘æ•°æ®ï¼Œå¹¶é¢„æµ‹å¤šå…³èŠ‚ç‰©ä½“çš„å¤æ‚è¿åŠ¨å­¦ç»“æ„ã€‚

**å…³é”®è®¾è®¡**ï¼šPart Articulation Transformeré‡‡ç”¨Transformerç¼–ç å™¨-è§£ç å™¨ç»“æ„ï¼Œç¼–ç å™¨ç”¨äºæå–ç‚¹äº‘ç‰¹å¾ï¼Œè§£ç å™¨ç”¨äºé¢„æµ‹å…³èŠ‚å±æ€§ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬éƒ¨ä»¶åˆ†å‰²æŸå¤±ã€è¿åŠ¨å­¦ç»“æ„æŸå¤±å’Œè¿åŠ¨çº¦æŸæŸå¤±ï¼Œç”¨äºæŒ‡å¯¼ç½‘ç»œå­¦ä¹ ã€‚ç½‘ç»œä½¿ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶æ¥å»ºæ¨¡ç‚¹äº‘ä¸­ä¸åŒç‚¹ä¹‹é—´çš„å…³ç³»ï¼Œå¹¶ä½¿ç”¨äº¤å‰æ³¨æ„åŠ›æœºåˆ¶æ¥èåˆä¸åŒéƒ¨ä»¶çš„ä¿¡æ¯ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒParticulateåœ¨3Då…³èŠ‚è¿åŠ¨ä¼°è®¡ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚åœ¨æ–°çš„å…·æœ‰æŒ‘æˆ˜æ€§çš„åŸºå‡†æµ‹è¯•ä¸­ï¼ŒParticulateåœ¨éƒ¨ä»¶åˆ†å‰²ã€è¿åŠ¨å­¦ç»“æ„å’Œè¿åŠ¨çº¦æŸé¢„æµ‹æ–¹é¢å‡å–å¾—äº†state-of-the-artçš„æ€§èƒ½ã€‚ä¸éœ€è¦é€å¯¹è±¡ä¼˜åŒ–çš„æ–¹æ³•ç›¸æ¯”ï¼ŒParticulateçš„æ¨ç†é€Ÿåº¦æé«˜äº†å‡ ä¸ªæ•°é‡çº§ã€‚æ­¤å¤–ï¼ŒParticulateè¿˜æˆåŠŸåœ°åº”ç”¨äºAIç”Ÿæˆçš„3Dèµ„äº§ï¼Œè¯æ˜äº†å…¶æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Particulateå¯å¹¿æ³›åº”ç”¨äºæœºå™¨äººã€åŠ¨ç”»åˆ¶ä½œã€æ¸¸æˆå¼€å‘ã€è™šæ‹Ÿç°å®ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œæœºå™¨äººå¯ä»¥åˆ©ç”¨Particulateå¿«é€Ÿè¯†åˆ«å’Œæ“ä½œæ–°çš„ç‰©ä½“ï¼›åŠ¨ç”»å¸ˆå¯ä»¥åˆ©ç”¨Particulateå¿«é€Ÿåˆ›å»ºå…·æœ‰å¤æ‚å…³èŠ‚è¿åŠ¨çš„è§’è‰²ï¼›æ¸¸æˆå¼€å‘è€…å¯ä»¥åˆ©ç”¨Particulateç”Ÿæˆé€¼çœŸçš„3Däº’åŠ¨ç¯å¢ƒã€‚æ­¤å¤–ï¼ŒParticulateè¿˜å¯ä»¥ä¸å›¾åƒåˆ°3Dç”Ÿæˆå™¨ç»“åˆä½¿ç”¨ï¼Œä»å•å¼ å›¾åƒä¸­æå–å¯äº¤äº’çš„3Då¯¹è±¡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present Particulate, a feed-forward approach that, given a single static 3D mesh of an everyday object, directly infers all attributes of the underlying articulated structure, including its 3D parts, kinematic structure, and motion constraints. At its core is a transformer network, Part Articulation Transformer, which processes a point cloud of the input mesh using a flexible and scalable architecture to predict all the aforementioned attributes with native multi-joint support. We train the network end-to-end on a diverse collection of articulated 3D assets from public datasets. During inference, Particulate lifts the network's feed-forward prediction to the input mesh, yielding a fully articulated 3D model in seconds, much faster than prior approaches that require per-object optimization. Particulate can also accurately infer the articulated structure of AI-generated 3D assets, enabling full-fledged extraction of articulated 3D objects from a single (real or synthetic) image when combined with an off-the-shelf image-to-3D generator. We further introduce a new challenging benchmark for 3D articulation estimation curated from high-quality public 3D assets, and redesign the evaluation protocol to be more consistent with human preferences. Quantitative and qualitative results show that Particulate significantly outperforms state-of-the-art approaches.

