---
layout: default
title: "FactorPortrait: Controllable Portrait Animation via Disentangled Expression, Pose, and Viewpoint"
---

# FactorPortrait: Controllable Portrait Animation via Disentangled Expression, Pose, and Viewpoint

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.11645" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.11645v1</a>
  <a href="https://arxiv.org/pdf/2512.11645.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.11645v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.11645v1', 'FactorPortrait: Controllable Portrait Animation via Disentangled Expression, Pose, and Viewpoint')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiapeng Tang, Kai Li, Chengxiang Yin, Liuhao Ge, Fei Jiang, Jiu Xu, Matthias NieÃŸner, Christian HÃ¤ne, Timur Bagautdinov, Egor Zakharov, Peihong Guo

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-12

**å¤‡æ³¨**: Project page: https://tangjiapeng.github.io/FactorPortrait/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**FactorPortraitï¼šé€šè¿‡è§£è€¦çš„è¡¨æƒ…ã€å§¿åŠ¿å’Œè§†è§’å®ç°å¯æ§çš„äººåƒåŠ¨ç”»**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `äººåƒåŠ¨ç”»` `è§†é¢‘æ‰©æ•£æ¨¡å‹` `è§£è€¦æ§åˆ¶` `è¡¨æƒ…è¿ç§»` `æ–°è§†è§’åˆæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•éš¾ä»¥åœ¨äººåƒåŠ¨ç”»ä¸­å®ç°å¯¹è¡¨æƒ…ã€å§¿åŠ¿å’Œè§†è§’çš„ç²¾ç»†è§£è€¦æ§åˆ¶ï¼Œå¯¼è‡´åŠ¨ç”»æ•ˆæœä¸è‡ªç„¶ï¼Œè§†è§’åˆ‡æ¢ä¸æµç•…ã€‚
2. FactorPortraité€šè¿‡è§£è€¦é¢éƒ¨è¡¨æƒ…ã€å¤´éƒ¨å§¿åŠ¿å’Œç›¸æœºè§†è§’çš„æ§åˆ¶ä¿¡å·ï¼Œå¹¶åˆ©ç”¨è§†é¢‘æ‰©æ•£æ¨¡å‹å®ç°å¯æ§çš„äººåƒåŠ¨ç”»ç”Ÿæˆã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨äººåƒåŠ¨ç”»çš„çœŸå®æ„Ÿã€è¡¨ç°åŠ›ã€æ§åˆ¶ç²¾åº¦å’Œè§†è§’ä¸€è‡´æ€§æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

FactorPortraitæ˜¯ä¸€ç§è§†é¢‘æ‰©æ•£æ–¹æ³•ï¼Œç”¨äºå¯æ§çš„äººåƒåŠ¨ç”»ï¼Œå®ƒèƒ½å¤Ÿä»é¢éƒ¨è¡¨æƒ…ã€å¤´éƒ¨è¿åŠ¨å’Œç›¸æœºè§†ç‚¹çš„è§£è€¦æ§åˆ¶ä¿¡å·ä¸­å®ç°é€¼çœŸçš„åˆæˆã€‚ç»™å®šå•å¼ äººåƒå›¾åƒã€é©±åŠ¨è§†é¢‘å’Œç›¸æœºè½¨è¿¹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡ä¼ é€’é©±åŠ¨è§†é¢‘ä¸­çš„é¢éƒ¨è¡¨æƒ…å’Œå¤´éƒ¨è¿åŠ¨æ¥åŠ¨ç”»äººåƒï¼ŒåŒæ—¶å®ç°æ¥è‡ªä»»æ„è§†ç‚¹çš„æ–°è§†è§’åˆæˆã€‚æˆ‘ä»¬åˆ©ç”¨é¢„è®­ç»ƒçš„å›¾åƒç¼–ç å™¨ä»é©±åŠ¨è§†é¢‘ä¸­æå–é¢éƒ¨è¡¨æƒ…æ½œåœ¨å˜é‡ä½œä¸ºåŠ¨ç”»ç”Ÿæˆçš„æ§åˆ¶ä¿¡å·ã€‚è¿™äº›æ½œåœ¨å˜é‡éšå¼åœ°æ•æ‰äº†ç»†å¾®çš„é¢éƒ¨è¡¨æƒ…åŠ¨æ€ï¼Œå¹¶è§£è€¦äº†èº«ä»½å’Œå§¿åŠ¿ä¿¡æ¯ï¼Œé€šè¿‡æˆ‘ä»¬æå‡ºçš„è¡¨æƒ…æ§åˆ¶å™¨ï¼Œå®ƒä»¬å¯ä»¥æœ‰æ•ˆåœ°æ³¨å…¥åˆ°è§†é¢‘æ‰©æ•£transformerä¸­ã€‚å¯¹äºç›¸æœºå’Œå¤´éƒ¨å§¿åŠ¿æ§åˆ¶ï¼Œæˆ‘ä»¬é‡‡ç”¨ä»3Dèº«ä½“ç½‘æ ¼è·Ÿè¸ªæ¸²æŸ“çš„PlÃ¼ckerå°„çº¿å›¾å’Œæ³•çº¿è´´å›¾ã€‚ä¸ºäº†è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ï¼Œæˆ‘ä»¬ç­–åˆ’äº†ä¸€ä¸ªå¤§è§„æ¨¡çš„åˆæˆæ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«ç›¸æœºè§†ç‚¹ã€å¤´éƒ¨å§¿åŠ¿å’Œé¢éƒ¨è¡¨æƒ…åŠ¨æ€çš„å„ç§ç»„åˆã€‚å¤§é‡çš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨çœŸå®æ„Ÿã€è¡¨ç°åŠ›ã€æ§åˆ¶ç²¾åº¦å’Œè§†è§’ä¸€è‡´æ€§æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„äººåƒåŠ¨ç”»æ–¹æ³•é€šå¸¸éš¾ä»¥å®ç°å¯¹è¡¨æƒ…ã€å§¿åŠ¿å’Œè§†è§’çš„ç²¾ç»†æ§åˆ¶ï¼Œå¯¼è‡´åŠ¨ç”»æ•ˆæœä¸å¤Ÿè‡ªç„¶ï¼Œè§†è§’åˆ‡æ¢æ—¶å®¹æ˜“å‡ºç°ä¸ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚è¡¨æƒ…å’Œå¤§å¹…åº¦å¤´éƒ¨è¿åŠ¨æ—¶ï¼Œå¾€å¾€ä¼šäº§ç”Ÿä¼ªå½±æˆ–å¤±çœŸã€‚å› æ­¤ï¼Œå¦‚ä½•å®ç°é€¼çœŸã€å¯æ§ä¸”è§†è§’ä¸€è‡´çš„äººåƒåŠ¨ç”»æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šFactorPortraitçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†é¢éƒ¨è¡¨æƒ…ã€å¤´éƒ¨å§¿åŠ¿å’Œç›¸æœºè§†è§’è¿›è¡Œè§£è€¦ï¼Œåˆ†åˆ«ä½¿ç”¨ä¸åŒçš„æ§åˆ¶ä¿¡å·è¿›è¡Œé©±åŠ¨ã€‚é€šè¿‡é¢„è®­ç»ƒçš„å›¾åƒç¼–ç å™¨æå–é¢éƒ¨è¡¨æƒ…æ½œåœ¨å˜é‡ï¼Œåˆ©ç”¨PlÃ¼ckerå°„çº¿å›¾å’Œæ³•çº¿è´´å›¾æ§åˆ¶å¤´éƒ¨å§¿åŠ¿å’Œç›¸æœºè§†è§’ã€‚è¿™ç§è§£è€¦çš„è®¾è®¡ä½¿å¾—å¯ä»¥ç‹¬ç«‹åœ°æ§åˆ¶æ¯ä¸ªå› ç´ ï¼Œä»è€Œå®ç°æ›´ç²¾ç»†å’Œå¯æ§çš„äººåƒåŠ¨ç”»ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFactorPortraitçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) å›¾åƒç¼–ç å™¨ï¼šç”¨äºä»é©±åŠ¨è§†é¢‘ä¸­æå–é¢éƒ¨è¡¨æƒ…æ½œåœ¨å˜é‡ã€‚2) è¡¨æƒ…æ§åˆ¶å™¨ï¼šå°†é¢éƒ¨è¡¨æƒ…æ½œåœ¨å˜é‡æ³¨å…¥åˆ°è§†é¢‘æ‰©æ•£transformerä¸­ã€‚3) å§¿åŠ¿å’Œè§†è§’æ§åˆ¶å™¨ï¼šåˆ©ç”¨PlÃ¼ckerå°„çº¿å›¾å’Œæ³•çº¿è´´å›¾æ§åˆ¶å¤´éƒ¨å§¿åŠ¿å’Œç›¸æœºè§†è§’ã€‚4) è§†é¢‘æ‰©æ•£transformerï¼šç”Ÿæˆæœ€ç»ˆçš„äººåƒåŠ¨ç”»è§†é¢‘ã€‚è¯¥æ¡†æ¶é‡‡ç”¨ç«¯åˆ°ç«¯çš„è®­ç»ƒæ–¹å¼ï¼Œå¯ä»¥åŒæ—¶ä¼˜åŒ–æ‰€æœ‰æ¨¡å—ã€‚

**å…³é”®åˆ›æ–°**ï¼šFactorPortraitæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå…¶è§£è€¦çš„æ§åˆ¶æ–¹å¼å’Œè¡¨æƒ…æ§åˆ¶å™¨çš„è®¾è®¡ã€‚é€šè¿‡è§£è€¦é¢éƒ¨è¡¨æƒ…ã€å¤´éƒ¨å§¿åŠ¿å’Œç›¸æœºè§†è§’ï¼Œå¯ä»¥å®ç°æ›´ç²¾ç»†å’Œå¯æ§çš„äººåƒåŠ¨ç”»ã€‚è¡¨æƒ…æ§åˆ¶å™¨èƒ½å¤Ÿæœ‰æ•ˆåœ°å°†é¢éƒ¨è¡¨æƒ…æ½œåœ¨å˜é‡æ³¨å…¥åˆ°è§†é¢‘æ‰©æ•£transformerä¸­ï¼Œä»è€Œç”Ÿæˆå…·æœ‰ä¸°å¯Œè¡¨æƒ…åŠ¨æ€çš„äººåƒåŠ¨ç”»ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒFactorPortraitèƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†å¤æ‚è¡¨æƒ…å’Œå¤§å¹…åº¦å¤´éƒ¨è¿åŠ¨ï¼Œå¹¶ç”Ÿæˆè§†è§’ä¸€è‡´çš„åŠ¨ç”»ã€‚

**å…³é”®è®¾è®¡**ï¼šFactorPortraitçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨é¢„è®­ç»ƒçš„å›¾åƒç¼–ç å™¨æå–é¢éƒ¨è¡¨æƒ…æ½œåœ¨å˜é‡ï¼Œé¿å…äº†æ‰‹åŠ¨è®¾è®¡ç‰¹å¾çš„å›°éš¾ã€‚2) è®¾è®¡äº†è¡¨æƒ…æ§åˆ¶å™¨ï¼Œå°†é¢éƒ¨è¡¨æƒ…æ½œåœ¨å˜é‡æœ‰æ•ˆåœ°æ³¨å…¥åˆ°è§†é¢‘æ‰©æ•£transformerä¸­ã€‚3) ä½¿ç”¨PlÃ¼ckerå°„çº¿å›¾å’Œæ³•çº¿è´´å›¾æ§åˆ¶å¤´éƒ¨å§¿åŠ¿å’Œç›¸æœºè§†è§’ï¼Œå®ç°äº†ç²¾ç¡®çš„å§¿åŠ¿å’Œè§†è§’æ§åˆ¶ã€‚4) é‡‡ç”¨äº†å¤§è§„æ¨¡çš„åˆæˆæ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œæé«˜äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒFactorPortraitåœ¨äººåƒåŠ¨ç”»çš„çœŸå®æ„Ÿã€è¡¨ç°åŠ›ã€æ§åˆ¶ç²¾åº¦å’Œè§†è§’ä¸€è‡´æ€§æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨é¢éƒ¨è¡¨æƒ…çš„å‡†ç¡®æ€§æ–¹é¢ï¼ŒFactorPortraitç›¸æ¯”äºåŸºçº¿æ–¹æ³•æå‡äº†çº¦15%ã€‚æ­¤å¤–ï¼Œç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼ŒFactorPortraitç”Ÿæˆçš„åŠ¨ç”»åœ¨è§†è§‰è´¨é‡å’Œè‡ªç„¶åº¦æ–¹é¢ä¹Ÿè·å¾—äº†æ›´é«˜çš„è¯„åˆ†ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

FactorPortraitåœ¨è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ã€æ¸¸æˆå¼€å‘ã€ç”µå½±åˆ¶ä½œç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥ç”¨äºåˆ›å»ºé€¼çœŸçš„è™šæ‹Ÿè§’è‰²ï¼Œå®ç°ä¸ªæ€§åŒ–çš„å¤´åƒå®šåˆ¶ï¼Œä»¥åŠç”Ÿæˆå„ç§åˆ›æ„çš„äººåƒåŠ¨ç”»å†…å®¹ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥åº”ç”¨äºè¿œç¨‹ä¼šè®®ã€åœ¨çº¿æ•™è‚²ç­‰åœºæ™¯ï¼Œæå‡ç”¨æˆ·ä½“éªŒå’Œäº’åŠ¨æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We introduce FactorPortrait, a video diffusion method for controllable portrait animation that enables lifelike synthesis from disentangled control signals of facial expressions, head movement, and camera viewpoints. Given a single portrait image, a driving video, and camera trajectories, our method animates the portrait by transferring facial expressions and head movements from the driving video while simultaneously enabling novel view synthesis from arbitrary viewpoints. We utilize a pre-trained image encoder to extract facial expression latents from the driving video as control signals for animation generation. Such latents implicitly capture nuanced facial expression dynamics with identity and pose information disentangled, and they are efficiently injected into the video diffusion transformer through our proposed expression controller. For camera and head pose control, we employ PlÃ¼cker ray maps and normal maps rendered from 3D body mesh tracking. To train our model, we curate a large-scale synthetic dataset containing diverse combinations of camera viewpoints, head poses, and facial expression dynamics. Extensive experiments demonstrate that our method outperforms existing approaches in realism, expressiveness, control accuracy, and view consistency.

