---
layout: default
title: You May Speak Freely: Improving the Fine-Grained Visual Recognition Capabilities of Multimodal Large Language Models with Answer Extraction
---

# You May Speak Freely: Improving the Fine-Grained Visual Recognition Capabilities of Multimodal Large Language Models with Answer Extraction

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.14885" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.14885v2</a>
  <a href="https://arxiv.org/pdf/2510.14885.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.14885v2" onclick="toggleFavorite(this, '2510.14885v2', 'You May Speak Freely: Improving the Fine-Grained Visual Recognition Capabilities of Multimodal Large Language Models with Answer Extraction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Logan Lawrence, Oindrila Saha, Megan Wei, Chen Sun, Subhransu Maji, Grant Van Horn

**åˆ†ç±»**: cs.CV, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-10-16 (æ›´æ–°: 2025-12-09)

**å¤‡æ³¨**: Accepted to WACV26. 12 pages, 8 tables, 5 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºnlg2choiceæ–¹æ³•ï¼Œæå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨ç»†ç²’åº¦è§†è§‰è¯†åˆ«ä¸­çš„åˆ†ç±»ä¸æ£€ç´¢èƒ½åŠ›ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `ç»†ç²’åº¦è§†è§‰åˆ†ç±»` `é›¶æ ·æœ¬å­¦ä¹ ` `æ–‡æœ¬çº¦æŸè§£ç ` `å¼€æ”¾å¼æé—®`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨ç»†ç²’åº¦è§†è§‰åˆ†ç±»ä»»åŠ¡ä¸­é¢ä¸´é€‰é¡¹æ•°é‡å·¨å¤§ä¸”é«˜åº¦ç›¸å…³çš„æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆå¤„ç†ã€‚
2. è®ºæ–‡æå‡ºnlg2choiceæ–¹æ³•ï¼Œé€šè¿‡å¼€æ”¾å¼æé—®å’Œæ–‡æœ¬çº¦æŸè§£ç ï¼Œæœ‰æ•ˆæå–MLLMçš„ç­”æ¡ˆå¹¶è¿›è¡Œé€‰æ‹©é¢„æµ‹ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œnlg2choiceåœ¨å¤šä¸ªç»†ç²’åº¦è§†è§‰æ•°æ®é›†ä¸Šï¼Œåˆ†ç±»å’Œæ£€ç´¢æ€§èƒ½å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸”å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç”±äºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰çš„å…´èµ·ï¼Œé›¶æ ·æœ¬è§†è§‰åˆ†ç±»é‡æ–°å¼•èµ·äº†äººä»¬çš„å…´è¶£ã€‚ç„¶è€Œï¼Œè¯„ä¼°è‡ªå›å½’æ¨¡å‹çš„è‡ªç”±å½¢å¼å“åº”ä»ç„¶æ˜¯ä¸€ä¸ªæŒç»­çš„æŒ‘æˆ˜ã€‚ç°æœ‰å·¥ä½œå¤§å¤šä¾§é‡äºçº¯è¯­è¨€ä»»åŠ¡ï¼Œæˆ–è€…ä¸è€ƒè™‘è¶…è¿‡5é€‰é¡¹çš„å¤šé¡¹é€‰æ‹©é¢˜ï¼ˆMCQï¼‰ã€‚è¿™ä¸¤ç§æƒ…å†µéƒ½æ— æ³•è§£å†³ç»†ç²’åº¦è§†è§‰åˆ†ç±»ï¼ˆFGVCï¼‰ä¸­çš„ä»»åŠ¡ï¼Œå› ä¸ºFGVCçš„é€‰æ‹©æ•°é‡å¯è¾¾æ•°ç™¾ç”šè‡³æ•°åƒï¼Œä¸”é€‰é¡¹ä¹‹é—´é«˜åº¦ç›¸å…³ã€‚æ­¤å¤–ï¼Œåœ¨è¿™ç§é«˜åº¦å¤šé¡¹é€‰æ‹©çš„ç¯å¢ƒä¸‹ï¼Œå¦‚ä½•å°†LLMé€‰æ‹©æå–æ‰©å±•åˆ°åŸºäºæ£€ç´¢çš„é—®é¢˜å°šä¸æ¸…æ¥šï¼Œå› ä¸ºè®¡ç®—é€‰æ‹©é›†ä¸Šçš„æ¦‚ç‡è®¡ç®—æˆæœ¬å¾ˆé«˜ã€‚æœ¬æ–‡ç ”ç©¶äº†ä¸€ç§ç®€å•çš„ä¸¤é˜¶æ®µæ–¹æ³•nlg2choiceï¼Œè¯¥æ–¹æ³•é¦–å…ˆå‘MLLMæå‡ºä¸€ä¸ªå…·æœ‰æœ€å°çº¦æŸçš„å¼€æ”¾å¼é—®é¢˜ï¼Œç„¶åä½¿ç”¨çº¯æ–‡æœ¬çº¦æŸè§£ç æ¥é¢„æµ‹æœ€å¯èƒ½çš„é€‰æ‹©ã€‚åœ¨æ£€ç´¢è®¾ç½®ä¸­ï¼Œæˆ‘ä»¬è®¡ç®—å—çº¦æŸå“åº”é‡‡ç”¨è¯¥é€‰æ‹©çš„æ¦‚ç‡ï¼Œå¹¶é‡‡ç”¨æ—©åœæ–¹æ³•æ¥æ˜¾è‘—æé«˜ååé‡ã€‚ç»“æœè¡¨æ˜ï¼Œåœ¨åˆ†ç±»å’Œæ£€ç´¢æ–¹é¢ï¼Œè¯¥æ–¹æ³•åœ¨ä¸ƒä¸ªç»†ç²’åº¦è§†è§‰æ•°æ®é›†ä¸Šå‡æœ‰æ”¹è¿›ï¼Œå¹¶ä¸”è¯¥æ€§èƒ½åœ¨LLMç”¨æˆ·ä»¥è‡ªç„¶è¯­è¨€å®ç°ä»»åŠ¡çš„å„ç§æ–¹å¼ä¸­å‡æˆç«‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰åœ¨ç»†ç²’åº¦è§†è§‰åˆ†ç±»ï¼ˆFGVCï¼‰ä»»åŠ¡ä¸­é¢ä¸´çš„æŒ‘æˆ˜ã€‚å…·ä½“æ¥è¯´ï¼ŒFGVCä»»åŠ¡é€šå¸¸æ¶‰åŠæ•°ç™¾ç”šè‡³æ•°åƒä¸ªé«˜åº¦ç›¸å…³çš„é€‰é¡¹ï¼Œè¿™ä½¿å¾—ä¼ ç»Ÿçš„åŸºäºæ¦‚ç‡è®¡ç®—çš„é€‰æ‹©æå–æ–¹æ³•è®¡ç®—æˆæœ¬è¿‡é«˜ï¼Œä¸”éš¾ä»¥æœ‰æ•ˆå¤„ç†ã€‚ç°æœ‰æ–¹æ³•è¦ä¹ˆä¾§é‡äºçº¯è¯­è¨€ä»»åŠ¡ï¼Œè¦ä¹ˆåªè€ƒè™‘å°‘é‡é€‰é¡¹çš„å¤šé¡¹é€‰æ‹©é¢˜ï¼Œæ— æ³•ç›´æ¥åº”ç”¨äºFGVCä»»åŠ¡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†é—®é¢˜åˆ†è§£ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šé¦–å…ˆï¼Œä½¿ç”¨å¼€æ”¾å¼æé—®çš„æ–¹å¼ï¼Œè®©MLLMè‡ªç”±ç”Ÿæˆç­”æ¡ˆï¼Œé¿å…ç›´æ¥åœ¨å¤§é‡é€‰é¡¹ä¸­è¿›è¡Œé€‰æ‹©ï¼›ç„¶åï¼Œåˆ©ç”¨æ–‡æœ¬çº¦æŸè§£ç ï¼Œå°†MLLMç”Ÿæˆçš„ç­”æ¡ˆä¸å€™é€‰é€‰é¡¹è¿›è¡ŒåŒ¹é…ï¼Œé¢„æµ‹æœ€å¯èƒ½çš„é€‰æ‹©ã€‚è¿™ç§æ–¹æ³•é™ä½äº†è®¡ç®—å¤æ‚åº¦ï¼Œå¹¶å…è®¸MLLMæ›´çµæ´»åœ°è¡¨è¾¾å…¶ç†è§£ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šnlg2choiceæ–¹æ³•åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼š
1. **å¼€æ”¾å¼æé—®ï¼ˆOpen-ended Questioningï¼‰**ï¼šå‘MLLMæå‡ºä¸€ä¸ªå¼€æ”¾å¼é—®é¢˜ï¼Œè¦æ±‚å…¶æ ¹æ®è¾“å…¥å›¾åƒç”Ÿæˆæè¿°æˆ–ç­”æ¡ˆï¼Œå°½é‡å‡å°‘çº¦æŸã€‚
2. **æ–‡æœ¬çº¦æŸè§£ç ï¼ˆText-only Constrained Decodingï¼‰**ï¼šåˆ©ç”¨æ–‡æœ¬çº¦æŸè§£ç æŠ€æœ¯ï¼Œå°†MLLMç”Ÿæˆçš„ç­”æ¡ˆä¸å€™é€‰é€‰é¡¹è¿›è¡ŒåŒ¹é…ã€‚å…·ä½“æ¥è¯´ï¼Œå¯¹äºæ¯ä¸ªå€™é€‰é€‰é¡¹ï¼Œè®¡ç®—MLLMç”Ÿæˆè¯¥é€‰é¡¹çš„æ¦‚ç‡ï¼Œå¹¶é€‰æ‹©æ¦‚ç‡æœ€é«˜çš„é€‰é¡¹ä½œä¸ºæœ€ç»ˆé¢„æµ‹ç»“æœã€‚åœ¨æ£€ç´¢ä»»åŠ¡ä¸­ï¼Œé‡‡ç”¨æ—©åœæ–¹æ³•ï¼Œåœ¨è¾¾åˆ°ä¸€å®šæ¦‚ç‡é˜ˆå€¼ååœæ­¢è®¡ç®—ï¼Œä»¥æé«˜ååé‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šnlg2choiceæ–¹æ³•çš„å…³é”®åˆ›æ–°åœ¨äºå°†å¤šé¡¹é€‰æ‹©é—®é¢˜è½¬åŒ–ä¸ºä¸€ä¸ªç”Ÿæˆå¼é—®é¢˜ï¼Œå¹¶åˆ©ç”¨æ–‡æœ¬çº¦æŸè§£ç è¿›è¡Œé€‰æ‹©ã€‚è¿™ç§æ–¹æ³•é¿å…äº†ç›´æ¥åœ¨å¤§é‡é€‰é¡¹ä¸­è¿›è¡Œæ¦‚ç‡è®¡ç®—ï¼Œé™ä½äº†è®¡ç®—å¤æ‚åº¦ï¼Œå¹¶å…è®¸MLLMæ›´çµæ´»åœ°è¡¨è¾¾å…¶ç†è§£ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¼•å…¥äº†æ—©åœæœºåˆ¶ï¼Œè¿›ä¸€æ­¥æé«˜äº†æ£€ç´¢ä»»åŠ¡çš„æ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å¼€æ”¾å¼æé—®é˜¶æ®µï¼Œé—®é¢˜çš„è®¾è®¡éœ€è¦å°½é‡ç®€æ´æ˜äº†ï¼Œé¿å…å¼•å…¥è¿‡å¤šçš„å…ˆéªŒçŸ¥è¯†æˆ–çº¦æŸï¼Œä»¥ä¾¿è®©MLLMèƒ½å¤Ÿå……åˆ†å‘æŒ¥å…¶ç”Ÿæˆèƒ½åŠ›ã€‚åœ¨æ–‡æœ¬çº¦æŸè§£ç é˜¶æ®µï¼Œå¯ä»¥ä½¿ç”¨ä¸åŒçš„è§£ç ç­–ç•¥ï¼Œä¾‹å¦‚beam searchæˆ–top-k samplingï¼Œä»¥æé«˜ç”Ÿæˆç­”æ¡ˆçš„å¤šæ ·æ€§å’Œå‡†ç¡®æ€§ã€‚æ—©åœæœºåˆ¶çš„é˜ˆå€¼éœ€è¦æ ¹æ®å…·ä½“ä»»åŠ¡è¿›è¡Œè°ƒæ•´ï¼Œä»¥åœ¨å‡†ç¡®æ€§å’Œæ•ˆç‡ä¹‹é—´å–å¾—å¹³è¡¡ã€‚è®ºæ–‡ä¸­æ²¡æœ‰æ˜ç¡®æåŠæŸå¤±å‡½æ•°æˆ–ç½‘ç»œç»“æ„ç­‰æŠ€æœ¯ç»†èŠ‚ï¼Œæ¨æµ‹ä½¿ç”¨äº†MLLMè‡ªå¸¦çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„è¿›è¡Œè®­ç»ƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œnlg2choiceæ–¹æ³•åœ¨ä¸ƒä¸ªç»†ç²’åº¦è§†è§‰æ•°æ®é›†ä¸Šå‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œnlg2choiceæ–¹æ³•ç›¸æ¯”äºç°æœ‰æ–¹æ³•ï¼Œå¹³å‡å‡†ç¡®ç‡æå‡äº†X%ã€‚åœ¨æ£€ç´¢ä»»åŠ¡ä¸­ï¼Œnlg2choiceæ–¹æ³•åœ¨ä¿æŒå‡†ç¡®ç‡çš„åŒæ—¶ï¼Œæ˜¾è‘—æé«˜äº†ååé‡ï¼Œé™ä½äº†è®¡ç®—æˆæœ¬ã€‚ï¼ˆå…·ä½“æå‡æ•°æ®æœªçŸ¥ï¼Œè®ºæ–‡æœªæä¾›å…·ä½“æ•°å€¼ï¼‰

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºç»†ç²’åº¦å›¾åƒè¯†åˆ«é¢†åŸŸï¼Œä¾‹å¦‚åŠ¨æ¤ç‰©è¯†åˆ«ã€è½¦å‹è¯†åˆ«ã€å•†å“è¯†åˆ«ç­‰ã€‚é€šè¿‡æå‡MLLMåœ¨è¿™äº›ä»»åŠ¡ä¸­çš„æ€§èƒ½ï¼Œå¯ä»¥å®ç°æ›´æ™ºèƒ½åŒ–çš„å›¾åƒæœç´¢ã€è‡ªåŠ¨æ ‡æ³¨å’Œè¾…åŠ©è¯Šæ–­ç­‰åº”ç”¨ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–éœ€è¦å¤„ç†å¤§é‡é€‰é¡¹çš„åˆ†ç±»å’Œæ£€ç´¢ä»»åŠ¡ä¸­ï¼Œå…·æœ‰é‡è¦çš„å®é™…åº”ç”¨ä»·å€¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Despite the renewed interest in zero-shot visual classification due to the rise of Multimodal Large Language Models (MLLMs), the problem of evaluating free-form responses of auto-regressive models remains a persistent challenge. Most existing works focus on language-only tasks or don't consider Multiple Choice Questions (MCQs) beyond 5-way options, both of which are critical capabilities to solve tasks in Fine-Grained Visual Classification (FGVC) where choice counts are in the hundreds to thousands and the choices are highly related. Furthermore, in this highly multi-way MCQ setting it is not clear how to extend LLM choice extraction to retrieval-based problems, where computing probabilities over the choice set is computationally costly. In this work we investigate nlg2choice, a simple two-stage method which first asks the MLLM an open-ended question for the task with minimal constraints, then uses text-only constrained decoding to predict the most likely choice. In retrieval settings, we compute the probability of the constrained response taking that choice with an early stopping method to significantly improve throughput. Our results show improvement over a suite of seven fine-grained visual datasets when evaluating in terms of classification and retrieval, and show that this performance holds over the various ways that users of LLMs can implement tasks in natural language.

