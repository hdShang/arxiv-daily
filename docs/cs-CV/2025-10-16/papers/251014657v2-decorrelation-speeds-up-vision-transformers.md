---
layout: default
title: Decorrelation Speeds Up Vision Transformers
---

# Decorrelation Speeds Up Vision Transformers

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.14657" target="_blank" class="toolbar-btn">arXiv: 2510.14657v2</a>
    <a href="https://arxiv.org/pdf/2510.14657.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.14657v2" 
            onclick="toggleFavorite(this, '2510.14657v2', 'Decorrelation Speeds Up Vision Transformers')" title="æ”¶è—">
      â˜† æ”¶è—
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="å¤åˆ¶é“¾æ¥">
      ğŸ”— åˆ†äº«
    </button>
  </div>
</div>


**ä½œè€…**: Kieran Carrigg, Rob van Gastel, Melda Yeghaian, Sander Dalm, Faysal Boughorbel, Marcel van Gerven

**åˆ†ç±»**: cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-10-16 (æ›´æ–°: 2025-11-26)

**å¤‡æ³¨**: 16 pages, 12 figures, submitted to CVC 2026

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDBP-MAEåŠ é€ŸViTé¢„è®­ç»ƒï¼Œé™ä½è®¡ç®—æˆæœ¬å’Œç¢³æ’æ”¾ï¼Œæå‡ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `Vision Transformer` `æ©ç è‡ªç¼–ç å™¨` `è§£ç›¸å…³åå‘ä¼ æ’­` `é«˜æ•ˆé¢„è®­ç»ƒ` `ä½ç¢³AI`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. MAEé¢„è®­ç»ƒViTè™½ç„¶æ€§èƒ½å¼ºå¤§ï¼Œä½†è®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œé™åˆ¶äº†å…¶åœ¨èµ„æºå—é™åœºæ™¯ä¸‹çš„åº”ç”¨ã€‚
2. æœ¬æ–‡å°†è§£ç›¸å…³åå‘ä¼ æ’­(DBP)èå…¥MAEé¢„è®­ç»ƒï¼Œé€šè¿‡å‡å°‘å±‚é—´è¾“å…¥ç›¸å…³æ€§æ¥åŠ é€Ÿæ”¶æ•›ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒDBP-MAEåœ¨é™ä½è®­ç»ƒæ—¶é—´å’Œç¢³æ’æ”¾çš„åŒæ—¶ï¼Œè¿˜èƒ½æå‡ä¸‹æ¸¸åˆ†å‰²ä»»åŠ¡çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºå°†è§£ç›¸å…³åå‘ä¼ æ’­(DBP)é›†æˆåˆ°æ©ç è‡ªç¼–ç å™¨(MAE)çš„ViTé¢„è®­ç»ƒä¸­ï¼ŒDBPæ˜¯ä¸€ç§ä¼˜åŒ–æ–¹æ³•ï¼Œé€šè¿‡è¿­ä»£å‡å°‘æ¯ä¸€å±‚çš„è¾“å…¥ç›¸å…³æ€§æ¥åŠ é€Ÿæ”¶æ•›ã€‚DBPé€‰æ‹©æ€§åœ°åº”ç”¨äºç¼–ç å™¨ï¼Œå¯ä»¥åœ¨ä¸æŸå¤±ç¨³å®šæ€§çš„å‰æä¸‹å®ç°æ›´å¿«çš„é¢„è®­ç»ƒã€‚ä¸ºäº†æ¨¡æ‹Ÿçº¦æŸæ•°æ®åœºæ™¯ï¼Œæˆ‘ä»¬åœ¨ImageNet-1Ké¢„è®­ç»ƒå’ŒADE20Kå¾®è°ƒä¸Šï¼Œä½¿ç”¨éšæœºé‡‡æ ·çš„å­é›†è¯„ä¼°äº†è¯¥æ–¹æ³•ã€‚åœ¨æ­¤è®¾ç½®ä¸‹ï¼ŒDBP-MAEå°†è¾¾åˆ°åŸºçº¿æ€§èƒ½çš„å®é™…è¿è¡Œæ—¶é—´å‡å°‘äº†21.1%ï¼Œç¢³æ’æ”¾é™ä½äº†21.4%ï¼Œå¹¶æé«˜äº†1.1ä¸ªç™¾åˆ†ç‚¹çš„åˆ†å‰²mIoUã€‚åœ¨ä¸“æœ‰çš„å·¥ä¸šæ•°æ®ä¸Šè¿›è¡Œé¢„è®­ç»ƒå’Œå¾®è°ƒæ—¶ï¼Œä¹Ÿè§‚å¯Ÿåˆ°äº†ç±»ä¼¼çš„å¢ç›Šï¼Œè¯å®äº†è¯¥æ–¹æ³•åœ¨å®é™…åœºæ™¯ä¸­çš„é€‚ç”¨æ€§ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒDBPå¯ä»¥å‡å°‘å¤§è§„æ¨¡ViTé¢„è®­ç»ƒçš„è®­ç»ƒæ—¶é—´å’Œèƒ½æºæ¶ˆè€—ï¼ŒåŒæ—¶æé«˜ä¸‹æ¸¸æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³Vision Transformer (ViT) çš„ Masked Autoencoder (MAE) é¢„è®­ç»ƒè®¡ç®—æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨æ—¶é—´å’Œèµ„æºå—é™çš„å·¥ä¸šç¯å¢ƒä¸­ã€‚ç°æœ‰çš„MAEé¢„è®­ç»ƒæ–¹æ³•è™½ç„¶æ€§èƒ½ä¼˜è¶Šï¼Œä½†å…¶å·¨å¤§çš„è®¡ç®—é‡ä½¿å…¶éš¾ä»¥åœ¨å®é™…åº”ç”¨ä¸­æ™®åŠã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°† Decorrelated Backpropagation (DBP) é›†æˆåˆ° MAE é¢„è®­ç»ƒè¿‡ç¨‹ä¸­ã€‚DBP æ—¨åœ¨å‡å°‘ç¥ç»ç½‘ç»œæ¯ä¸€å±‚çš„è¾“å…¥ç›¸å…³æ€§ï¼Œä»è€ŒåŠ é€Ÿè®­ç»ƒè¿‡ç¨‹çš„æ”¶æ•›ã€‚é€šè¿‡é™ä½è¾“å…¥ç‰¹å¾ä¹‹é—´çš„å†—ä½™ä¿¡æ¯ï¼ŒDBP å¯ä»¥ä½¿ç½‘ç»œæ›´å¿«åœ°å­¦ä¹ åˆ°æœ‰æ•ˆçš„ç‰¹å¾è¡¨ç¤ºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDBP-MAE çš„æ•´ä½“æ¡†æ¶ä¸æ ‡å‡†çš„ MAE ç±»ä¼¼ï¼ŒåŒ…æ‹¬ä¸€ä¸ª ViT ç¼–ç å™¨å’Œä¸€ä¸ª ViT è§£ç å™¨ã€‚ä¸åŒä¹‹å¤„åœ¨äºï¼ŒDBP è¢«é€‰æ‹©æ€§åœ°åº”ç”¨äºç¼–ç å™¨éƒ¨åˆ†ã€‚åœ¨é¢„è®­ç»ƒé˜¶æ®µï¼Œè¾“å…¥å›¾åƒè¢«éšæœºæ©ç ï¼Œç¼–ç å™¨å¤„ç†æœªè¢«æ©ç çš„éƒ¨åˆ†ï¼Œç„¶åè§£ç å™¨é‡å»ºåŸå§‹å›¾åƒã€‚DBP åœ¨ç¼–ç å™¨çš„åå‘ä¼ æ’­è¿‡ç¨‹ä¸­èµ·ä½œç”¨ï¼Œé€šè¿‡è°ƒæ•´æ¢¯åº¦æ¥å‡å°‘è¾“å…¥ç›¸å…³æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°† DBP æˆåŠŸåœ°åº”ç”¨äº ViT çš„ MAE é¢„è®­ç»ƒä¸­ï¼Œå¹¶è¯æ˜äº†å…¶åœ¨åŠ é€Ÿè®­ç»ƒå’Œé™ä½è®¡ç®—æˆæœ¬æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚ä¸ç›´æ¥åº”ç”¨ DBP åˆ°æ•´ä¸ªç½‘ç»œä¸åŒï¼Œè®ºæ–‡é€‰æ‹©æ€§åœ°å°†å…¶åº”ç”¨äºç¼–ç å™¨ï¼Œä»è€Œåœ¨åŠ é€Ÿæ”¶æ•›çš„åŒæ—¶ä¿æŒäº†è®­ç»ƒçš„ç¨³å®šæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šDBP çš„å…·ä½“å®ç°æ¶‰åŠåœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ä¿®æ”¹æ¢¯åº¦ã€‚å…·ä½“æ¥è¯´ï¼Œå¯¹äºæ¯ä¸€å±‚ï¼Œè®¡ç®—è¾“å…¥ç‰¹å¾çš„åæ–¹å·®çŸ©é˜µï¼Œå¹¶ä½¿ç”¨è¯¥åæ–¹å·®çŸ©é˜µæ¥è°ƒæ•´æ¢¯åº¦ã€‚è¿™ç§è°ƒæ•´æ—¨åœ¨å‡å°‘è¾“å…¥ç‰¹å¾ä¹‹é—´çš„ç›¸å…³æ€§ã€‚è®ºæ–‡ä¸­æ²¡æœ‰è¯¦ç»†è¯´æ˜å…·ä½“çš„ DBP å‚æ•°è®¾ç½®ï¼Œä½†å¼ºè°ƒäº†é€‰æ‹©æ€§åº”ç”¨ DBP åˆ°ç¼–ç å™¨çš„é‡è¦æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨ImageNet-1Ké¢„è®­ç»ƒå’ŒADE20Kå¾®è°ƒå®éªŒä¸­ï¼ŒDBP-MAEå°†è¾¾åˆ°åŸºçº¿æ€§èƒ½çš„å®é™…è¿è¡Œæ—¶é—´å‡å°‘äº†21.1%ï¼Œç¢³æ’æ”¾é™ä½äº†21.4%ï¼Œå¹¶æé«˜äº†1.1ä¸ªç™¾åˆ†ç‚¹çš„åˆ†å‰²mIoUã€‚åœ¨ä¸“æœ‰å·¥ä¸šæ•°æ®é›†ä¸Šçš„å®éªŒä¹ŸéªŒè¯äº†DBP-MAEçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºéœ€è¦é«˜æ•ˆé¢„è®­ç»ƒViTæ¨¡å‹çš„åœºæ™¯ï¼Œä¾‹å¦‚å·¥ä¸šè§†è§‰æ£€æµ‹ã€è‡ªåŠ¨é©¾é©¶ã€åŒ»å­¦å›¾åƒåˆ†æç­‰ã€‚é€šè¿‡é™ä½è®¡ç®—æˆæœ¬å’Œç¢³æ’æ”¾ï¼ŒDBP-MAE æœ‰åŠ©äºæ¨åŠ¨å¤§è§„æ¨¡ViTæ¨¡å‹åœ¨èµ„æºå—é™ç¯å¢ƒä¸­çš„åº”ç”¨ï¼Œå¹¶ä¿ƒè¿›ç»¿è‰²äººå·¥æ™ºèƒ½çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Masked Autoencoder (MAE) pre-training of vision transformers (ViTs) yields strong performance in low-label data regimes but comes with substantial computational costs, making it impractical in time- and resource-constrained industrial settings. We address this by nitegrating Decorrelated Backpropagation (DBP) into MAE pre-training, an optimization method that iteratively reduces input correlations at each layer to accelerate convergence. Applied selectively to the encoder, DBP achieves faster pre-training without loss of stability. To mimic constrained-data scenarios, we evaluate our approach on ImageNet-1K pre-training and ADE20K fine-tuning using randomly sampled subsets of each dataset. Under this setting, DBP-MAE reduces wall-clock time to baseline performance by 21.1%, lowers carbon emissions by 21.4%, and improves segmentation mIoU by 1.1 points. We observe similar gains when pre-training and fine-tuning on proprietary industrial data, confirming the method's applicability in real-world scenarios. These results demonstrate that DBP can reduce training time and energy use while improving downstream performance for large-scale ViT pre-training.
>   Keywords: Deep learning, Vision transformers, Efficient AI, Decorrelation

