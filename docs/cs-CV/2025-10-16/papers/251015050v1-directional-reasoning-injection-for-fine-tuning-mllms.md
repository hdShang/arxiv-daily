---
layout: default
title: Directional Reasoning Injection for Fine-Tuning MLLMs
---

# Directional Reasoning Injection for Fine-Tuning MLLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.15050" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.15050v1</a>
  <a href="https://arxiv.org/pdf/2510.15050.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.15050v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.15050v1', 'Directional Reasoning Injection for Fine-Tuning MLLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chao Huang, Zeliang Zhang, Jiang Liu, Ximeng Sun, Jialian Wu, Xiaodong Yu, Ze Wang, Chenliang Xu, Emad Barsoum, Zicheng Liu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-16

**å¤‡æ³¨**: Project Page: https://wikichao.github.io/DRIFT/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDRIFTï¼Œé€šè¿‡æ¢¯åº¦ç©ºé—´æ³¨å…¥æ–¹å‘æ€§æ¨ç†çŸ¥è¯†ï¼Œé«˜æ•ˆå¾®è°ƒå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `æ¨ç†èƒ½åŠ›` `æ¢¯åº¦ç©ºé—´` `çŸ¥è¯†è¿ç§»` `æ¨¡å‹å¾®è°ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›ä¸è¶³ï¼Œç°æœ‰å¾®è°ƒæ–¹æ³•æˆæœ¬é«˜æ˜‚ï¼Œæ¨¡å‹åˆå¹¶æ•ˆæœä¸ç¨³å®šã€‚
2. DRIFTé€šè¿‡é¢„è®¡ç®—æ¨ç†å…ˆéªŒï¼Œåœ¨æ¢¯åº¦ç©ºé—´æ³¨å…¥æ–¹å‘æ€§æ¨ç†çŸ¥è¯†ï¼Œå®ç°é«˜æ•ˆæ¨ç†è¿ç§»ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒDRIFTåœ¨æ¨ç†åŸºå‡†ä¸Šä¼˜äºæœ´ç´ åˆå¹¶å’Œç›‘ç£å¾®è°ƒï¼Œä¸”æˆæœ¬è¿œä½äºè®­ç»ƒå¯†é›†å‹æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)å‘å±•è¿…é€Ÿï¼Œä½†å…¶æ¨ç†èƒ½åŠ›é€šå¸¸è½åäºå¼ºå¤§çš„çº¯æ–‡æœ¬æ¨¡å‹ã€‚ç°æœ‰å¼¥è¡¥å·®è·çš„æ–¹æ³•ä¾èµ–äºå¤§è§„æ¨¡å¤šæ¨¡æ€æ¨ç†æ•°æ®çš„ç›‘ç£å¾®è°ƒæˆ–å¼ºåŒ–å­¦ä¹ ï¼Œä¸¤è€…éƒ½è€—è´¹èµ„æºã€‚æ¨¡å‹åˆå¹¶æ˜¯ä¸€ç§æœ‰å‰æ™¯çš„æ›¿ä»£æ–¹æ¡ˆï¼Œå®ƒåœ¨æ¨ç†å¢å¼ºçš„LLMå’Œå¤šæ¨¡æ€å˜ä½“ä¹‹é—´æ’å€¼å‚æ•°ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬çš„åˆ†æè¡¨æ˜ï¼Œç®€å•çš„åˆå¹¶å¹¶éæ€»æ˜¯â€œå…è´¹åˆé¤â€ï¼šå…¶æœ‰æ•ˆæ€§åœ¨æ¨¡å‹å®¶æ—ä¹‹é—´å·®å¼‚å¾ˆå¤§ï¼Œä¸€äº›æ¨¡å‹ï¼ˆä¾‹å¦‚ï¼ŒLLaVAï¼ŒIdeficsï¼‰å—ç›Šï¼Œè€Œå¦ä¸€äº›æ¨¡å‹ï¼ˆä¾‹å¦‚ï¼ŒQwenï¼‰æ€§èƒ½ä¸‹é™ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”¨äºå¾®è°ƒMLLMçš„æ–¹å‘æ€§æ¨ç†æ³¨å…¥ï¼ˆDRIFTï¼‰æ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§è½»é‡çº§æ–¹æ³•ï¼Œå¯åœ¨æ¢¯åº¦ç©ºé—´ä¸­ä¼ é€’æ¨ç†çŸ¥è¯†ï¼Œè€Œä¸ä¼šç ´åå¤šæ¨¡æ€å¯¹é½ã€‚DRIFTé¢„å…ˆè®¡ç®—æ¨ç†å…ˆéªŒï¼Œä½œä¸ºæ¨ç†å’Œå¤šæ¨¡æ€å˜ä½“ä¹‹é—´çš„å‚æ•°ç©ºé—´å·®å¼‚ï¼Œç„¶ååœ¨å¤šæ¨¡æ€å¾®è°ƒæœŸé—´ä½¿ç”¨å®ƒæ¥åç½®æ¢¯åº¦ã€‚è¿™ç§æ–¹æ³•ä¿ç•™äº†æ ‡å‡†ç›‘ç£å¾®è°ƒç®¡é“çš„ç®€å•æ€§ï¼ŒåŒæ—¶å®ç°äº†é«˜æ•ˆçš„æ¨ç†è½¬ç§»ã€‚åœ¨åŒ…æ‹¬MathVistaå’ŒMathVerseåœ¨å†…çš„å¤šæ¨¡æ€æ¨ç†åŸºå‡†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒDRIFTå§‹ç»ˆä¼˜äºæœ´ç´ åˆå¹¶å’Œç›‘ç£å¾®è°ƒï¼ŒåŒæ—¶ä»¥ä¸€å°éƒ¨åˆ†æˆæœ¬åŒ¹é…æˆ–è¶…è¿‡äº†è®­ç»ƒå¯†é›†å‹æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)æ¨ç†èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚å¤§è§„æ¨¡æ•°æ®ä¸Šçš„ç›‘ç£å¾®è°ƒå’Œå¼ºåŒ–å­¦ä¹ ï¼Œè®¡ç®—æˆæœ¬é«˜æ˜‚ã€‚æ¨¡å‹åˆå¹¶è™½ç„¶æ˜¯ä¸€ç§æ½œåœ¨çš„æ›¿ä»£æ–¹æ¡ˆï¼Œä½†å…¶æ•ˆæœåœ¨ä¸åŒæ¨¡å‹å®¶æ—ä¹‹é—´å·®å¼‚å¾ˆå¤§ï¼Œæœ‰æ—¶ç”šè‡³ä¼šé™ä½æ€§èƒ½ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§é«˜æ•ˆä¸”ç¨³å®šçš„æ–¹æ³•æ¥æå‡MLLMsçš„æ¨ç†èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åœ¨æ¢¯åº¦ç©ºé—´ä¸­æ³¨å…¥æ–¹å‘æ€§æ¨ç†çŸ¥è¯†ã€‚å…·ä½“æ¥è¯´ï¼Œé€šè¿‡é¢„å…ˆè®¡ç®—ä¸€ä¸ªâ€œæ¨ç†å…ˆéªŒâ€ï¼Œè¯¥å…ˆéªŒè¡¨ç¤ºæ¨ç†å¢å¼ºçš„LLMå’Œå¤šæ¨¡æ€å˜ä½“ä¹‹é—´çš„å‚æ•°ç©ºé—´å·®å¼‚ã€‚åœ¨å¤šæ¨¡æ€å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œåˆ©ç”¨è¿™ä¸ªæ¨ç†å…ˆéªŒæ¥åç½®æ¢¯åº¦ï¼Œä»è€Œå¼•å¯¼æ¨¡å‹å­¦ä¹ æ¨ç†èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒå¤šæ¨¡æ€å¯¹é½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDRIFTæ–¹æ³•ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š
1. **æ¨ç†å…ˆéªŒè®¡ç®—**ï¼šé¦–å…ˆï¼Œé€‰æ‹©ä¸€ä¸ªå…·æœ‰è¾ƒå¼ºæ¨ç†èƒ½åŠ›çš„LLMå’Œä¸€ä¸ªå¤šæ¨¡æ€å˜ä½“ã€‚è®¡ç®—è¿™ä¸¤ä¸ªæ¨¡å‹åœ¨å‚æ•°ç©ºé—´ä¸Šçš„å·®å¼‚ï¼Œå¾—åˆ°æ¨ç†å…ˆéªŒã€‚
2. **å¤šæ¨¡æ€å¾®è°ƒ**ï¼šä½¿ç”¨æ ‡å‡†çš„å¤šæ¨¡æ€æ•°æ®é›†å¯¹å¤šæ¨¡æ€æ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚åœ¨è®¡ç®—æ¢¯åº¦æ—¶ï¼Œå°†æ¨ç†å…ˆéªŒå¼•å…¥æ¢¯åº¦è®¡ç®—ä¸­ï¼Œä»è€Œå¼•å¯¼æ¨¡å‹å­¦ä¹ æ¨ç†èƒ½åŠ›ã€‚
3. **æ¨¡å‹è¯„ä¼°**ï¼šåœ¨å¤šæ¨¡æ€æ¨ç†åŸºå‡†ä¸Šè¯„ä¼°å¾®è°ƒåçš„æ¨¡å‹æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šDRIFTçš„å…³é”®åˆ›æ–°åœ¨äºï¼š
1. **æ¢¯åº¦ç©ºé—´æ³¨å…¥**ï¼šä¸åŒäºç›´æ¥åˆå¹¶æ¨¡å‹å‚æ•°ï¼ŒDRIFTåœ¨æ¢¯åº¦ç©ºé—´ä¸­æ³¨å…¥æ¨ç†çŸ¥è¯†ï¼Œé¿å…äº†å‚æ•°å†²çªå’Œæ¨¡å‹ä¸ç¨³å®šé—®é¢˜ã€‚
2. **æ–¹å‘æ€§æ¨ç†**ï¼šé€šè¿‡é¢„è®¡ç®—æ¨ç†å…ˆéªŒï¼Œæ˜ç¡®äº†æ¨ç†çŸ¥è¯†çš„æ–¹å‘ï¼Œä»è€Œæ›´æœ‰æ•ˆåœ°å¼•å¯¼æ¨¡å‹å­¦ä¹ æ¨ç†èƒ½åŠ›ã€‚
3. **è½»é‡çº§**ï¼šDRIFTä¸éœ€è¦é¢å¤–çš„è®­ç»ƒæ•°æ®æˆ–å¤æ‚çš„è®­ç»ƒç­–ç•¥ï¼Œåªéœ€åœ¨æ ‡å‡†å¾®è°ƒè¿‡ç¨‹ä¸­å¼•å…¥æ¨ç†å…ˆéªŒå³å¯ã€‚

**å…³é”®è®¾è®¡**ï¼š
1. **æ¨ç†å…ˆéªŒçš„è®¡ç®—**ï¼šæ¨ç†å…ˆéªŒè¢«å®šä¹‰ä¸ºæ¨ç†æ¨¡å‹å’Œå¤šæ¨¡æ€æ¨¡å‹å‚æ•°çš„å·®å€¼ï¼Œå³ Î”Î¸ = Î¸_reasoning - Î¸_multimodalã€‚
2. **æ¢¯åº¦åç½®**ï¼šåœ¨å¤šæ¨¡æ€å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œæ¢¯åº¦æ›´æ–°è§„åˆ™è¢«ä¿®æ”¹ä¸ºï¼šÎ¸ = Î¸ - Î·(âˆ‡L + Î»Î”Î¸)ï¼Œå…¶ä¸­ Î· æ˜¯å­¦ä¹ ç‡ï¼ŒÎ» æ˜¯ä¸€ä¸ªè¶…å‚æ•°ï¼Œç”¨äºæ§åˆ¶æ¨ç†å…ˆéªŒçš„å½±å“ç¨‹åº¦ã€‚
3. **è¶…å‚æ•°Î»çš„é€‰æ‹©**ï¼šÎ» çš„å€¼éœ€è¦æ ¹æ®å…·ä½“ä»»åŠ¡å’Œæ•°æ®é›†è¿›è¡Œè°ƒæ•´ï¼Œä»¥å¹³è¡¡æ¨ç†èƒ½åŠ›å’Œå¤šæ¨¡æ€å¯¹é½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒDRIFTåœ¨MathVistaå’ŒMathVerseç­‰åŸºå‡†æµ‹è¯•ä¸­ï¼Œæ˜¾è‘—ä¼˜äºæœ´ç´ æ¨¡å‹åˆå¹¶å’Œæ ‡å‡†ç›‘ç£å¾®è°ƒã€‚ä¾‹å¦‚ï¼Œåœ¨MathVistaä¸Šï¼ŒDRIFTç›¸è¾ƒäºNaive Mergingæå‡äº†è¶…è¿‡5%ï¼Œå¹¶ä¸”åœ¨æ€§èƒ½ä¸Šå¯ä»¥åŒ¹é…ç”šè‡³è¶…è¿‡éœ€è¦å¤§é‡è®­ç»ƒèµ„æºçš„æ–¹æ³•ï¼ŒåŒæ—¶æ˜¾è‘—é™ä½äº†è®­ç»ƒæˆæœ¬ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

DRIFTæ–¹æ³•å¯å¹¿æ³›åº”ç”¨äºå„ç§éœ€è¦å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›çš„åœºæ™¯ï¼Œä¾‹å¦‚è§†è§‰é—®ç­”ã€å›¾åƒæè¿°ã€æœºå™¨äººå¯¼èˆªç­‰ã€‚é€šè¿‡æå‡MLLMsçš„æ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥æé«˜è¿™äº›åº”ç”¨åœ¨å¤æ‚ç¯å¢ƒä¸‹çš„æ€§èƒ½å’Œå¯é æ€§ã€‚è¯¥æ–¹æ³•é™ä½äº†æ¨ç†èƒ½åŠ›è¿ç§»çš„æˆæœ¬ï¼Œä½¿å¾—æ›´å¤šç ”ç©¶è€…å’Œå¼€å‘è€…èƒ½å¤Ÿæ„å»ºæ›´æ™ºèƒ½çš„å¤šæ¨¡æ€ç³»ç»Ÿã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal large language models (MLLMs) are rapidly advancing, yet their reasoning ability often lags behind that of strong text-only counterparts. Existing methods to bridge this gap rely on supervised fine-tuning over large-scale multimodal reasoning data or reinforcement learning, both of which are resource-intensive. A promising alternative is model merging, which interpolates parameters between reasoning-enhanced LLMs and multimodal variants. However, our analysis shows that naive merging is not always a "free lunch": its effectiveness varies drastically across model families, with some (e.g., LLaVA, Idefics) benefiting while others (e.g., Qwen) suffer performance degradation. To address this, we propose Directional Reasoning Injection for Fine-Tuning (DRIFT) MLLMs, a lightweight method that transfers reasoning knowledge in the gradient space, without destabilizing multimodal alignment. DRIFT precomputes a reasoning prior as the parameter-space difference between reasoning and multimodal variants, then uses it to bias gradients during multimodal fine-tuning. This approach preserves the simplicity of standard supervised fine-tuning pipelines while enabling efficient reasoning transfer. Extensive experiments on multimodal reasoning benchmarks, including MathVista and MathVerse, demonstrate that DRIFT consistently improves reasoning performance over naive merging and supervised fine-tuning, while matching or surpassing training-heavy methods at a fraction of the cost.

