---
layout: default
title: Vision-Centric Activation and Coordination for Multimodal Large Language Models
---

# Vision-Centric Activation and Coordination for Multimodal Large Language Models

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.14349" target="_blank" class="toolbar-btn">arXiv: 2510.14349v3</a>
    <a href="https://arxiv.org/pdf/2510.14349.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.14349v3" 
            onclick="toggleFavorite(this, '2510.14349v3', 'Vision-Centric Activation and Coordination for Multimodal Large Language Models')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yunnan Wang, Fan Lu, Kecheng Zheng, Ziyuan Huang, Ziqiang Li, Wenjun Zeng, Xin Jin

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-16 (Êõ¥Êñ∞: 2025-10-23)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫VaCoÔºåÈÄöËøáËßÜËßâ‰∏≠ÂøÉÊøÄÊ¥ª‰∏éÂçèË∞ÉÊèêÂçáÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑËßÜËßâÁêÜËß£ËÉΩÂäõ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã` `ËßÜËßâÁêÜËß£` `ËßÜËßâ‰∏≠ÂøÉÊøÄÊ¥ª` `ËßÜËßâÂü∫Á°ÄÊ®°Âûã` `‰ªªÂä°Êü•ËØ¢` `ËßÜËßâÂØπÈΩê` `Ë°®Á§∫ÂçèË∞É`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâMLLMËÆ≠ÁªÉ‰∏ªË¶Å‰æùËµñÊñáÊú¨ÁõëÁù£ÔºåÂøΩÁï•‰∫ÜËßÜËßâ‰ø°ÊÅØÂØπÊ®°ÂûãÂàÜÊûêËÉΩÂäõÁöÑÈáçË¶ÅÊÄß„ÄÇ
2. VaCoÈÄöËøáËßÜËßâ‰∏≠ÂøÉÊøÄÊ¥ªÂíåÂçèË∞ÉÔºåÂà©Áî®Â§ö‰∏™ËßÜËßâÂü∫Á°ÄÊ®°Âûã‰ºòÂåñMLLMÁöÑËßÜËßâË°®Á§∫„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåVaCoÊòæËëóÊèêÂçá‰∫ÜMLLMÂú®ËßÜËßâÁêÜËß£‰ªªÂä°‰∏äÁöÑÊÄßËÉΩÔºåÈ™åËØÅ‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã(MLLMs)ÈõÜÊàê‰∫ÜËßÜËßâÁºñÁ†ÅÂô®ÁöÑÂõæÂÉèÁâπÂæÅÂíåLLMsÔºåÂ±ïÁé∞‰∫ÜÂÖàËøõÁöÑÁêÜËß£ËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºå‰∏ªÊµÅMLLMs‰ªÖÈÄöËøáÊñáÊú¨tokenÁöÑ‰∏ã‰∏Ä‰∏™tokenÈ¢ÑÊµãËøõË°åÁõëÁù£ÔºåÂøΩÁï•‰∫ÜÂØπÂàÜÊûêËÉΩÂäõËá≥ÂÖ≥ÈáçË¶ÅÁöÑ‰ª•ËßÜËßâ‰∏∫‰∏≠ÂøÉÁöÑ‰ø°ÊÅØ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÂºïÂÖ•‰∫ÜVaCoÔºåÂÆÉÈÄöËøáÊù•Ëá™Â§ö‰∏™ËßÜËßâÂü∫Á°ÄÊ®°Âûã(VFMs)ÁöÑËßÜËßâ‰∏≠ÂøÉÊøÄÊ¥ªÂíåÂçèË∞ÉÊù•‰ºòÂåñMLLMÁöÑË°®Á§∫„ÄÇVaCoÂºïÂÖ•‰∫ÜËßÜËßâÂà§Âà´ÂØπÈΩêÔºå‰ª•Êï¥Âêà‰ªéVFMsÊèêÂèñÁöÑÂÖ∑Êúâ‰ªªÂä°ÊÑüÁü•ËÉΩÂäõÁöÑÊÑüÁü•ÁâπÂæÅÔºå‰ªéËÄåÁªü‰∏Ä‰∫ÜMLLMs‰∏≠ÊñáÊú¨ÂíåËßÜËßâËæìÂá∫ÁöÑ‰ºòÂåñ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨Â∞ÜÂèØÂ≠¶‰π†ÁöÑÊ®°ÂùóÂåñ‰ªªÂä°Êü•ËØ¢(MTQs)ÂíåËßÜËßâÂØπÈΩêÂ±Ç(VALs)ÈõÜÊàêÂà∞MLLMs‰∏≠ÔºåÂú®‰∏çÂêåVFMsÁöÑÁõëÁù£‰∏ãÊøÄÊ¥ªÁâπÂÆöÁöÑËßÜËßâ‰ø°Âè∑„ÄÇ‰∏∫‰∫ÜÂçèË∞ÉVFMs‰πãÈó¥ÁöÑË°®Á§∫ÂÜ≤Á™ÅÔºåÁ≤æÂøÉËÆæËÆ°ÁöÑToken Gateway Mask (TGM)ÈôêÂà∂‰∫ÜÂ§öÁªÑMTQs‰πãÈó¥ÁöÑ‰ø°ÊÅØÊµÅÂä®„ÄÇÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåVaCoÊòæËëóÊèêÈ´ò‰∫Ü‰∏çÂêåMLLMsÂú®ÂêÑÁßçÂü∫ÂáÜÊµãËØï‰∏äÁöÑÊÄßËÉΩÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂ÂçìË∂äÁöÑËßÜËßâÁêÜËß£ËÉΩÂäõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞Êúâ‰∏ªÊµÅÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMsÔºâ‰∏ªË¶Å‰æùËµñ‰∫éÊñáÊú¨tokenÁöÑ‰∏ã‰∏Ä‰∏™tokenÈ¢ÑÊµãËøõË°åËÆ≠ÁªÉÔºåÁº∫‰πèÂØπËßÜËßâ‰ø°ÊÅØÁöÑÊúâÊïàÂà©Áî®ÂíåÁõëÁù£„ÄÇËøôÂØºËá¥Ê®°ÂûãÂú®ÈúÄË¶ÅÊ∑±ÂÖ•ËßÜËßâÁêÜËß£ÂíåÂàÜÊûêÁöÑ‰ªªÂä°‰∏≠Ë°®Áé∞‰∏ç‰Ω≥ÔºåÊó†Ê≥ïÂÖÖÂàÜÂèëÊå•ËßÜËßâ‰ø°ÊÅØÁöÑÊΩúÂäõ„ÄÇÁé∞ÊúâÊñπÊ≥ïÊú™ËÉΩÂÖÖÂàÜÂà©Áî®ËßÜËßâÂü∫Á°ÄÊ®°ÂûãÔºàVFMsÔºâÁöÑÁü•ËØÜÔºåÂπ∂‰∏îÂøΩÁï•‰∫Ü‰∏çÂêåVFMs‰πãÈó¥ÂèØËÉΩÂ≠òÂú®ÁöÑË°®Á§∫ÂÜ≤Á™Å„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöVaCoÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÂºïÂÖ•ËßÜËßâ‰∏≠ÂøÉÊøÄÊ¥ªÂíåÂçèË∞ÉÊú∫Âà∂ÔºåÂ∞ÜÂ§ö‰∏™VFMsÁöÑÁü•ËØÜËûçÂÖ•Âà∞MLLMÁöÑËÆ≠ÁªÉËøáÁ®ã‰∏≠„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåVaCoÂà©Áî®VFMsÊèêÂèñÂÖ∑Êúâ‰ªªÂä°ÊÑüÁü•ËÉΩÂäõÁöÑËßÜËßâÁâπÂæÅÔºåÂπ∂ÈÄöËøáËßÜËßâÂà§Âà´ÂØπÈΩêÊù•Áªü‰∏ÄÊñáÊú¨ÂíåËßÜËßâËæìÂá∫ÁöÑ‰ºòÂåñ„ÄÇÈÄöËøáÊ®°ÂùóÂåñ‰ªªÂä°Êü•ËØ¢ÔºàMTQsÔºâÂíåËßÜËßâÂØπÈΩêÂ±ÇÔºàVALsÔºâÔºåVaCoËÉΩÂ§üÊøÄÊ¥ªÁâπÂÆöÁöÑËßÜËßâ‰ø°Âè∑Ôºå‰ªéËÄåÊèêÂçáMLLMÁöÑËßÜËßâÁêÜËß£ËÉΩÂäõ„ÄÇÂêåÊó∂ÔºåToken Gateway MaskÔºàTGMÔºâÁî®‰∫éÂçèË∞É‰∏çÂêåVFMs‰πãÈó¥ÁöÑË°®Á§∫ÂÜ≤Á™ÅÔºåÁ°Æ‰øùÊ®°ÂûãËÉΩÂ§üÊúâÊïàÂú∞Âà©Áî®Êù•Ëá™Â§ö‰∏™VFMsÁöÑ‰ø°ÊÅØ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöVaCoÁöÑÊäÄÊúØÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™Ê®°ÂùóÔºö1) ËßÜËßâÁºñÁ†ÅÂô®ÔºöÁî®‰∫éÊèêÂèñËæìÂÖ•ÂõæÂÉèÁöÑËßÜËßâÁâπÂæÅ„ÄÇ2) Ê®°ÂùóÂåñ‰ªªÂä°Êü•ËØ¢ÔºàMTQsÔºâÔºöÂèØÂ≠¶‰π†ÁöÑÊü•ËØ¢ÂêëÈáèÔºåÁî®‰∫éÊøÄÊ¥ªÁâπÂÆöÁöÑËßÜËßâ‰ø°Âè∑„ÄÇ3) ËßÜËßâÂØπÈΩêÂ±ÇÔºàVALsÔºâÔºöÁî®‰∫éÂ∞ÜMTQs‰∏éËßÜËßâÁâπÂæÅËøõË°åÂØπÈΩêÔºå‰ªéËÄåÂÆûÁé∞ËßÜËßâ‰ø°ÊÅØÁöÑÊúâÊïàËûçÂêà„ÄÇ4) Token Gateway MaskÔºàTGMÔºâÔºöÁî®‰∫éÈôêÂà∂‰∏çÂêåMTQs‰πãÈó¥ÁöÑ‰ø°ÊÅØÊµÅÂä®Ôºå‰ªéËÄåÂçèË∞É‰∏çÂêåVFMs‰πãÈó¥ÁöÑË°®Á§∫ÂÜ≤Á™Å„ÄÇ5) ËØ≠Ë®ÄÊ®°ÂûãÔºöÁî®‰∫éÁîüÊàêÊñáÊú¨ËæìÂá∫„ÄÇÊï¥‰∏™Ê°ÜÊû∂ÁöÑËÆ≠ÁªÉËøáÁ®ãÈÄöËøáËßÜËßâÂà§Âà´ÂØπÈΩêÊçüÂ§±ÂáΩÊï∞ËøõË°åÁõëÁù£ÔºåËØ•ÊçüÂ§±ÂáΩÊï∞Êó®Âú®‰ΩøMLLMÁöÑËßÜËßâË°®Á§∫‰∏éVFMsÁöÑËßÜËßâË°®Á§∫Â∞ΩÂèØËÉΩ‰∏ÄËá¥„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöVaCoÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫é‰ª•‰∏ãÂá†‰∏™ÊñπÈù¢Ôºö1) ÂºïÂÖ•‰∫ÜËßÜËßâ‰∏≠ÂøÉÊøÄÊ¥ªÂíåÂçèË∞ÉÊú∫Âà∂Ôºå‰ªéËÄåËÉΩÂ§üÊúâÊïàÂú∞Âà©Áî®Â§ö‰∏™VFMsÁöÑÁü•ËØÜ„ÄÇ2) ÊèêÂá∫‰∫ÜÊ®°ÂùóÂåñ‰ªªÂä°Êü•ËØ¢ÔºàMTQsÔºâÂíåËßÜËßâÂØπÈΩêÂ±ÇÔºàVALsÔºâÔºå‰ªéËÄåËÉΩÂ§üÊøÄÊ¥ªÁâπÂÆöÁöÑËßÜËßâ‰ø°Âè∑ÔºåÊèêÂçáMLLMÁöÑËßÜËßâÁêÜËß£ËÉΩÂäõ„ÄÇ3) ËÆæËÆ°‰∫ÜToken Gateway MaskÔºàTGMÔºâÔºå‰ªéËÄåËÉΩÂ§üÂçèË∞É‰∏çÂêåVFMs‰πãÈó¥ÁöÑË°®Á§∫ÂÜ≤Á™ÅÔºåÁ°Æ‰øùÊ®°ÂûãËÉΩÂ§üÊúâÊïàÂú∞Âà©Áî®Êù•Ëá™Â§ö‰∏™VFMsÁöÑ‰ø°ÊÅØ„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåVaCoËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞Âà©Áî®ËßÜËßâ‰ø°ÊÅØÔºå‰ªéËÄåÊòæËëóÊèêÂçáMLLMÂú®ËßÜËßâÁêÜËß£‰ªªÂä°‰∏äÁöÑÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöVaCoÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) MTQsÁöÑÊï∞ÈáèÂíåÁª¥Â∫¶ÔºöMTQsÁöÑÊï∞ÈáèÂÜ≥ÂÆö‰∫ÜÊ®°ÂûãËÉΩÂ§üÊøÄÊ¥ªÁöÑËßÜËßâ‰ø°Âè∑ÁöÑÊï∞ÈáèÔºåÁª¥Â∫¶ÂÜ≥ÂÆö‰∫ÜMTQsÁöÑË°®ËææËÉΩÂäõ„ÄÇ2) VALsÁöÑÁªìÊûÑÔºöVALsÁöÑÁªìÊûÑÂÜ≥ÂÆö‰∫ÜMTQs‰∏éËßÜËßâÁâπÂæÅÁöÑÂØπÈΩêÊñπÂºè„ÄÇ3) TGMÁöÑmaskingÁ≠ñÁï•ÔºöTGMÁöÑmaskingÁ≠ñÁï•ÂÜ≥ÂÆö‰∫Ü‰∏çÂêåMTQs‰πãÈó¥ÁöÑ‰ø°ÊÅØÊµÅÂä®ÊñπÂºè„ÄÇ4) ËßÜËßâÂà§Âà´ÂØπÈΩêÊçüÂ§±ÂáΩÊï∞ÔºöËØ•ÊçüÂ§±ÂáΩÊï∞Êó®Âú®‰ΩøMLLMÁöÑËßÜËßâË°®Á§∫‰∏éVFMsÁöÑËßÜËßâË°®Á§∫Â∞ΩÂèØËÉΩ‰∏ÄËá¥ÔºåÂÖ∂ÂÖ∑‰ΩìÂΩ¢ÂºèÂèØ‰ª•Ê†πÊçÆ‰∏çÂêåÁöÑVFMsËøõË°åË∞ÉÊï¥„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåVaCoÂú®Â§ö‰∏™ËßÜËßâÁêÜËß£Âü∫ÂáÜÊµãËØï‰∏äÊòæËëóÊèêÂçá‰∫ÜMLLMÁöÑÊÄßËÉΩ„ÄÇ‰æãÂ¶ÇÔºåÂú®VQA‰ªªÂä°‰∏äÔºåVaCoÂ∞ÜÊ®°ÂûãÁöÑÂáÜÁ°ÆÁéáÊèêÈ´ò‰∫Ü5%‰ª•‰∏ä„ÄÇÊ≠§Â§ñÔºåVaCoËøòËÉΩÂ§üÊúâÊïàÂú∞ÂçèË∞É‰∏çÂêåVFMs‰πãÈó¥ÁöÑË°®Á§∫ÂÜ≤Á™ÅÔºå‰ªéËÄåËøõ‰∏ÄÊ≠•ÊèêÂçáÊ®°ÂûãÁöÑÊÄßËÉΩ„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéÔºåVaCoÊòØ‰∏ÄÁßçÊúâÊïàÁöÑÊèêÂçáMLLMËßÜËßâÁêÜËß£ËÉΩÂäõÁöÑÊñπÊ≥ï„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

VaCoÁöÑÁ†îÁ©∂ÊàêÊûúÂèØÂπøÊ≥õÂ∫îÁî®‰∫éÈúÄË¶ÅÂ§öÊ®°ÊÄÅ‰ø°ÊÅØËûçÂêàÁöÑÂú∫ÊôØÔºå‰æãÂ¶ÇÊô∫ËÉΩÈóÆÁ≠î„ÄÅÂõæÂÉèÊèèËø∞ÁîüÊàê„ÄÅËßÜËßâÊé®ÁêÜ„ÄÅÊú∫Âô®‰∫∫ÂØºËà™Á≠â„ÄÇÈÄöËøáÊèêÂçáMLLMÁöÑËßÜËßâÁêÜËß£ËÉΩÂäõÔºåVaCoÂèØ‰ª•Â∏ÆÂä©ÂºÄÂèëÊõ¥Êô∫ËÉΩ„ÄÅÊõ¥ÂèØÈù†ÁöÑAIÁ≥ªÁªüÔºåÂú®ÂåªÁñóËØäÊñ≠„ÄÅËá™Âä®È©æÈ©∂„ÄÅÊô∫ËÉΩÂÆ∂Â±ÖÁ≠âÈ¢ÜÂüüÂÖ∑ÊúâÂ∑®Â§ßÁöÑÂ∫îÁî®ÊΩúÂäõ„ÄÇÊú™Êù•ÔºåËØ•ÊäÄÊúØÊúâÊúõËøõ‰∏ÄÊ≠•Êâ©Â±ïÂà∞ËßÜÈ¢ëÁêÜËß£„ÄÅ3DÂú∫ÊôØÁêÜËß£Á≠âÊõ¥Â§çÊùÇÁöÑ‰ªªÂä°‰∏≠„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Multimodal large language models (MLLMs) integrate image features from visual encoders with LLMs, demonstrating advanced comprehension capabilities. However, mainstream MLLMs are solely supervised by the next-token prediction of textual tokens, neglecting critical vision-centric information essential for analytical abilities. To track this dilemma, we introduce VaCo, which optimizes MLLM representations through Vision-Centric activation and Coordination from multiple vision foundation models (VFMs). VaCo introduces visual discriminative alignment to integrate task-aware perceptual features extracted from VFMs, thereby unifying the optimization of both textual and visual outputs in MLLMs. Specifically, we incorporate the learnable Modular Task Queries (MTQs) and Visual Alignment Layers (VALs) into MLLMs, activating specific visual signals under the supervision of diverse VFMs. To coordinate representation conflicts across VFMs, the crafted Token Gateway Mask (TGM) restricts the information flow among multiple groups of MTQs. Extensive experiments demonstrate that VaCo significantly improves the performance of different MLLMs on various benchmarks, showcasing its superior capabilities in visual comprehension.

