---
layout: default
title: MaskCaptioner: Learning to Jointly Segment and Caption Object Trajectories in Videos
---

# MaskCaptioner: Learning to Jointly Segment and Caption Object Trajectories in Videos

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.14904" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.14904v2</a>
  <a href="https://arxiv.org/pdf/2510.14904.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.14904v2" onclick="toggleFavorite(this, '2510.14904v2', 'MaskCaptioner: Learning to Jointly Segment and Caption Object Trajectories in Videos')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Gabriel Fiastre, Antoine Yang, Cordelia Schmid

**åˆ†ç±»**: cs.CV, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-10-16 (æ›´æ–°: 2025-10-30)

**å¤‡æ³¨**: 20 pages, 8 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMaskCaptionerï¼Œé€šè¿‡è”åˆå­¦ä¹ åˆ†å‰²å’Œæè¿°è§†é¢‘ä¸­çš„ç‰©ä½“è½¨è¿¹ï¼Œå®ç°ç«¯åˆ°ç«¯çš„å¯†é›†è§†é¢‘ç‰©ä½“æè¿°ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¯†é›†è§†é¢‘ç‰©ä½“æè¿°` `è§†é¢‘ç†è§£` `è§†è§‰è¯­è¨€æ¨¡å‹` `ç«¯åˆ°ç«¯å­¦ä¹ ` `è”åˆè®­ç»ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¯†é›†è§†é¢‘ç‰©ä½“æè¿°(DVOC)ä»»åŠ¡å¤æ‚ä¸”æ ‡æ³¨æˆæœ¬é«˜ï¼Œç°æœ‰æ–¹æ³•é‡‡ç”¨åˆ†ç¦»è®­ç»ƒç­–ç•¥ï¼Œæ€§èƒ½å—é™ã€‚
2. è®ºæ–‡æå‡ºMaskCaptionerï¼Œåˆ©ç”¨VLMç”Ÿæˆæ—¶ç©ºå±€éƒ¨å®ä½“çš„æè¿°ï¼Œå¹¶æ‰©å±•æ•°æ®é›†è¿›è¡Œè”åˆè®­ç»ƒã€‚
3. MaskCaptioneråœ¨VidSTGã€VLNå’ŒBenSMOTç­‰åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„DVOCç»“æœï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¯†é›†è§†é¢‘ç‰©ä½“æè¿°(DVOC)ä»»åŠ¡æ—¨åœ¨è”åˆæ£€æµ‹ã€è·Ÿè¸ªå’Œæè¿°è§†é¢‘ä¸­çš„ç‰©ä½“è½¨è¿¹ï¼Œè¿™éœ€è¦ç†è§£æ—¶ç©ºç»†èŠ‚å¹¶ç”¨è‡ªç„¶è¯­è¨€æè¿°å®ƒä»¬çš„èƒ½åŠ›ã€‚ç”±äºä»»åŠ¡çš„å¤æ‚æ€§å’Œæ‰‹åŠ¨æ ‡æ³¨çš„é«˜æˆæœ¬ï¼Œä»¥å¾€çš„æ–¹æ³•é€šå¸¸é‡‡ç”¨åˆ†ç¦»çš„è®­ç»ƒç­–ç•¥ï¼Œå¯èƒ½å¯¼è‡´æ¬¡ä¼˜çš„æ€§èƒ½ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºåˆ©ç”¨æœ€å…ˆè¿›çš„VLMç”Ÿæˆå…³äºæ—¶ç©ºå±€éƒ¨å®ä½“çš„æè¿°ã€‚é€šè¿‡ä½¿ç”¨æˆ‘ä»¬çš„åˆæˆæè¿°æ‰©å±•LVISå’ŒLV-VISæ•°æ®é›†ï¼ˆLVISCapå’ŒLV-VISCapï¼‰ï¼Œæˆ‘ä»¬è®­ç»ƒäº†MaskCaptionerï¼Œä¸€ä¸ªèƒ½å¤Ÿè”åˆæ£€æµ‹ã€åˆ†å‰²ã€è·Ÿè¸ªå’Œæè¿°ç‰©ä½“è½¨è¿¹çš„ç«¯åˆ°ç«¯æ¨¡å‹ã€‚æ­¤å¤–ï¼Œé€šè¿‡åœ¨LVISCapå’ŒLV-VISCapä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼ŒMaskCaptioneråœ¨ä¸‰ä¸ªç°æœ‰çš„åŸºå‡†æµ‹è¯•VidSTGã€VLNå’ŒBenSMOTä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„DVOCç»“æœã€‚æ•°æ®é›†å’Œä»£ç å¯åœ¨https://www.gabriel.fiastre.fr/maskcaptioner/ è·å–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¯†é›†è§†é¢‘ç‰©ä½“æè¿°ï¼ˆDVOCï¼‰ä»»åŠ¡ï¼Œå³åœ¨è§†é¢‘ä¸­åŒæ—¶æ£€æµ‹ã€è·Ÿè¸ªå’Œæè¿°ç‰©ä½“è½¨è¿¹ã€‚ç°æœ‰æ–¹æ³•çš„ç—›ç‚¹åœ¨äºï¼Œç”±äºä»»åŠ¡çš„å¤æ‚æ€§å’Œæ ‡æ³¨æˆæœ¬é«˜æ˜‚ï¼Œé€šå¸¸é‡‡ç”¨åˆ†ç¦»çš„è®­ç»ƒç­–ç•¥ï¼Œä¾‹å¦‚å…ˆæ£€æµ‹å’Œè·Ÿè¸ªï¼Œå†è¿›è¡Œæè¿°ï¼Œè¿™å¯¼è‡´å„ä¸ªæ¨¡å—ä¹‹é—´ç¼ºä¹æœ‰æ•ˆçš„è”åˆä¼˜åŒ–ï¼Œä»è€Œé™åˆ¶äº†æ•´ä½“æ€§èƒ½çš„æå‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§è§„æ¨¡è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰çš„å¼ºå¤§èƒ½åŠ›ï¼Œç”Ÿæˆå…³äºæ—¶ç©ºå±€éƒ¨å®ä½“çš„æè¿°ï¼Œå¹¶ä»¥æ­¤æ‰©å±•ç°æœ‰çš„æ•°æ®é›†ã€‚é€šè¿‡æ„å»ºåŒ…å«ç‰©ä½“åˆ†å‰²ã€è·Ÿè¸ªå’Œæè¿°ä¿¡æ¯çš„åˆæˆæ•°æ®ï¼Œå®ç°ç«¯åˆ°ç«¯çš„è”åˆè®­ç»ƒã€‚è¿™æ ·å¯ä»¥é¿å…åˆ†ç¦»è®­ç»ƒå¸¦æ¥çš„æ¬¡ä¼˜é—®é¢˜ï¼Œå……åˆ†åˆ©ç”¨å„ä¸ªæ¨¡å—ä¹‹é—´çš„å…³è”æ€§ï¼Œæå‡æ•´ä½“æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMaskCaptionerçš„æ•´ä½“æ¡†æ¶æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„æ¨¡å‹ï¼Œå®ƒæ¥æ”¶è§†é¢‘ä½œä¸ºè¾“å…¥ï¼Œè¾“å‡ºåŒ…å«ç‰©ä½“åˆ†å‰²ã€è·Ÿè¸ªå’Œæè¿°ä¿¡æ¯çš„è½¨è¿¹ã€‚è¯¥æ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) ç‰©ä½“æ£€æµ‹å’Œåˆ†å‰²æ¨¡å—ï¼šè´Ÿè´£æ£€æµ‹è§†é¢‘ä¸­çš„ç‰©ä½“å¹¶ç”Ÿæˆåˆ†å‰²æ©ç ã€‚2) ç‰©ä½“è·Ÿè¸ªæ¨¡å—ï¼šè´Ÿè´£è·Ÿè¸ªè§†é¢‘ä¸­ç‰©ä½“çš„è¿åŠ¨è½¨è¿¹ã€‚3) æè¿°ç”Ÿæˆæ¨¡å—ï¼šåˆ©ç”¨VLMç”Ÿæˆå…³äºç‰©ä½“è½¨è¿¹çš„è‡ªç„¶è¯­è¨€æè¿°ã€‚4) è”åˆè®­ç»ƒæ¨¡å—ï¼šå°†ä¸Šè¿°ä¸‰ä¸ªæ¨¡å—è¿›è¡Œç«¯åˆ°ç«¯çš„è”åˆè®­ç»ƒï¼Œä¼˜åŒ–æ•´ä½“æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ä¸€ä¸ªç«¯åˆ°ç«¯çš„è”åˆè®­ç»ƒæ¡†æ¶MaskCaptionerï¼Œèƒ½å¤ŸåŒæ—¶è¿›è¡Œç‰©ä½“æ£€æµ‹ã€åˆ†å‰²ã€è·Ÿè¸ªå’Œæè¿°ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒMaskCaptioneré¿å…äº†åˆ†ç¦»è®­ç»ƒå¸¦æ¥çš„æ¬¡ä¼˜é—®é¢˜ï¼Œå®ç°äº†å„ä¸ªæ¨¡å—ä¹‹é—´çš„æœ‰æ•ˆååŒã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜é€šè¿‡åˆ©ç”¨VLMç”Ÿæˆåˆæˆæ•°æ®ï¼Œæœ‰æ•ˆç¼“è§£äº†DVOCä»»åŠ¡ä¸­æ•°æ®æ ‡æ³¨æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) åˆ©ç”¨LVISå’ŒLV-VISæ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨VLMç”Ÿæˆåˆæˆæè¿°ï¼Œæ„å»ºäº†LVISCapå’ŒLV-VISCapæ•°æ®é›†ã€‚2) é‡‡ç”¨Mask R-CNNä½œä¸ºç‰©ä½“æ£€æµ‹å’Œåˆ†å‰²æ¨¡å—çš„åŸºç¡€æ¶æ„ã€‚3) ä½¿ç”¨Transformeræ¶æ„ä½œä¸ºæè¿°ç”Ÿæˆæ¨¡å—çš„åŸºç¡€æ¶æ„ã€‚4) è®¾è®¡äº†åˆé€‚çš„æŸå¤±å‡½æ•°ï¼Œç”¨äºè”åˆä¼˜åŒ–ç‰©ä½“æ£€æµ‹ã€åˆ†å‰²ã€è·Ÿè¸ªå’Œæè¿°ä»»åŠ¡ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

MaskCaptioneråœ¨VidSTGã€VLNå’ŒBenSMOTä¸‰ä¸ªåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„DVOCç»“æœã€‚ä¾‹å¦‚ï¼Œåœ¨VidSTGæ•°æ®é›†ä¸Šï¼ŒMaskCaptionerçš„æ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚é€šè¿‡åœ¨LVISCapå’ŒLV-VISCapä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œæ¨¡å‹æ€§èƒ½å¾—åˆ°è¿›ä¸€æ­¥æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ™ºèƒ½è§†é¢‘ç›‘æ§ã€è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨æ™ºèƒ½è§†é¢‘ç›‘æ§ä¸­ï¼Œå¯ä»¥è‡ªåŠ¨è¯†åˆ«å’Œæè¿°è§†é¢‘ä¸­çš„å¼‚å¸¸è¡Œä¸ºã€‚åœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼Œå¯ä»¥å¸®åŠ©è½¦è¾†ç†è§£å‘¨å›´ç¯å¢ƒï¼Œå¹¶åšå‡ºæ›´å®‰å…¨çš„å†³ç­–ã€‚åœ¨æœºå™¨äººå¯¼èˆªä¸­ï¼Œå¯ä»¥å¸®åŠ©æœºå™¨äººç†è§£ä»»åŠ¡æŒ‡ä»¤ï¼Œå¹¶å®Œæˆå¤æ‚çš„ä»»åŠ¡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Dense Video Object Captioning (DVOC) is the task of jointly detecting, tracking, and captioning object trajectories in a video, requiring the ability to understand spatio-temporal details and describe them in natural language. Due to the complexity of the task and the high cost associated with manual annotation, previous approaches resort to disjoint training strategies, potentially leading to suboptimal performance. To circumvent this issue, we propose to generate captions about spatio-temporally localized entities leveraging a state-of-the-art VLM. By extending the LVIS and LV-VIS datasets with our synthetic captions (LVISCap and LV-VISCap), we train MaskCaptioner, an end-to-end model capable of jointly detecting, segmenting, tracking and captioning object trajectories. Moreover, with pretraining on LVISCap and LV-VISCap, MaskCaptioner achieves state-of-the-art DVOC results on three existing benchmarks, VidSTG, VLN and BenSMOT. The datasets and code are available at https://www.gabriel.fiastre.fr/maskcaptioner/.

