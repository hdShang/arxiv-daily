---
layout: default
title: MOBIUS: Big-to-Mobile Universal Instance Segmentation via Multi-modal Bottleneck Fusion and Calibrated Decoder Pruning
---

# MOBIUS: Big-to-Mobile Universal Instance Segmentation via Multi-modal Bottleneck Fusion and Calibrated Decoder Pruning

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.15026" target="_blank" class="toolbar-btn">arXiv: 2510.15026v1</a>
    <a href="https://arxiv.org/pdf/2510.15026.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.15026v1" 
            onclick="toggleFavorite(this, '2510.15026v1', 'MOBIUS: Big-to-Mobile Universal Instance Segmentation via Multi-modal Bottleneck Fusion and Calibrated Decoder Pruning')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Mattia Segu, Marta Tintore Gazulla, Yongqin Xian, Luc Van Gool, Federico Tombari

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-16

**Â§áÊ≥®**: ICCV 2025

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**MOBIUSÔºöÈÄöËøáÂ§öÊ®°ÊÄÅÁì∂È¢àËûçÂêà‰∏éÊ†°ÂáÜËß£Á†ÅÂô®Ââ™ÊûùÂÆûÁé∞Big-to-MobileÈÄöÁî®ÂÆû‰æãÂàÜÂâ≤**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÂÆû‰æãÂàÜÂâ≤` `Ê®°ÂûãÂéãÁº©` `ÁßªÂä®ËÆæÂ§á` `Â§öÊ®°ÊÄÅËûçÂêà` `Ëß£Á†ÅÂô®Ââ™Êûù` `‰∏çÁ°ÆÂÆöÊÄßÊ†°ÂáÜ` `Áì∂È¢àÁªìÊûÑ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂÆû‰æãÂàÜÂâ≤Ê®°ÂûãËÆ°ÁÆóÊàêÊú¨È´òÊòÇÔºåÈöæ‰ª•Âú®ËµÑÊ∫êÂèóÈôêÁöÑËæπÁºòËÆæÂ§á‰∏äÈÉ®ÁΩ≤ÔºåÈôêÂà∂‰∫ÜÂÖ∂Â∫îÁî®ËåÉÂõ¥„ÄÇ
2. MOBIUSÈÄöËøáÁì∂È¢àÂÉèÁ¥†Ëß£Á†ÅÂô®„ÄÅËØ≠Ë®ÄÂºïÂØºÁöÑ‰∏çÁ°ÆÂÆöÊÄßÊ†°ÂáÜÊçüÂ§±ÂíåÁªü‰∏ÄËÆ≠ÁªÉÁ≠ñÁï•ÔºåÈôç‰ΩéËÆ≠ÁªÉÂíåÊé®ÁêÜÈúÄÊ±Ç„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåMOBIUSÂú®ÊòæËëóÈôç‰ΩéËÆ°ÁÆóÈáèÁöÑÂêåÊó∂Ôºå‰øùÊåÅ‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÂπ∂Âú®ÁßªÂä®ËÆæÂ§á‰∏äÂÆûÁé∞‰∫ÜÈ´òÊïàÂàÜÂâ≤„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫MOBIUSÔºå‰∏Ä‰∏™Èù¢ÂêëÈÄöÁî®ÂÆû‰æãÂàÜÂâ≤ÁöÑÂü∫Á°ÄÊ®°ÂûãÂÆ∂ÊóèÔºåÊó®Âú®ÂÆûÁé∞ParetoÊúÄ‰ºòÁöÑÁº©ÊîæÔºå‰ª•ÊîØÊåÅ‰ªéÈ´òÁ´ØÂä†ÈÄüÂô®Âà∞ÁßªÂä®Á°¨‰ª∂ÁöÑÈÉ®ÁΩ≤„ÄÇ‰∏∫‰∫ÜÈôç‰ΩéËÆ≠ÁªÉÂíåÊé®ÁêÜÈúÄÊ±ÇÔºåÊú¨ÊñáÊèêÂá∫‰∫ÜÔºöÔºàiÔºâÁî®‰∫éÈ´òÊïàÂ§öÂ∞∫Â∫¶ÂíåÂ§öÊ®°ÊÄÅËûçÂêàÁöÑÁì∂È¢àÂÉèÁ¥†Ëß£Á†ÅÂô®ÔºõÔºàiiÔºâÁî®‰∫éËá™ÈÄÇÂ∫îËß£Á†ÅÂô®Ââ™ÊûùÁöÑËØ≠Ë®ÄÂºïÂØºÁöÑ‰∏çÁ°ÆÂÆöÊÄßÊ†°ÂáÜÊçüÂ§±ÔºõÔºàiiiÔºâÁÆÄÂåñÁöÑÁªü‰∏ÄËÆ≠ÁªÉÁ≠ñÁï•„ÄÇ‰∏é‰ª•Áâ∫Áâ≤Á≤æÂ∫¶‰∏∫‰ª£‰ª∑Êù•Èôç‰ΩéÂ§çÊùÇÊÄßÁöÑÈ´òÊïàÂü∫Á∫ø‰∏çÂêåÔºåMOBIUSÂ∞ÜÂÉèÁ¥†ÂíåTransformerËß£Á†ÅÂô®ÁöÑFLOPsÂàÜÂà´Èôç‰ΩéÈ´òËææ55%Âíå75%ÔºåÂêåÊó∂Âú®‰ªÖ‰∏âÂàÜ‰πã‰∏ÄÁöÑËÆ≠ÁªÉËø≠‰ª£‰∏≠‰øùÊåÅ‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩ„ÄÇMOBIUS‰∏∫È´òÊÄßËÉΩËÆ°ÁÆóÂπ≥Âè∞ÂíåÁßªÂä®ËÆæÂ§á‰∏äÁöÑÈ´òÊïàÂàÜÂâ≤Âª∫Á´ã‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑÂü∫ÂáÜ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÂÆû‰æãÂàÜÂâ≤Ê®°ÂûãÔºåÁâπÂà´ÊòØÂü∫‰∫éTransformerÁöÑÂ§ßÂûãÊ®°ÂûãÔºåËôΩÁÑ∂Âú®Á≤æÂ∫¶‰∏äÂèñÂæó‰∫ÜÊòæËëóËøõÂ±ïÔºå‰ΩÜÂÖ∂Â∫ûÂ§ßÁöÑËÆ°ÁÆóÈáèÂíåÂÜÖÂ≠òÈúÄÊ±Ç‰ΩøÂÖ∂Èöæ‰ª•Âú®ÁßªÂä®ËÆæÂ§áÁ≠âËµÑÊ∫êÂèóÈôêÁöÑÂπ≥Âè∞‰∏äÈÉ®ÁΩ≤„ÄÇÁé∞ÊúâÁöÑÊ®°ÂûãÂéãÁº©ÊñπÊ≥ïÈÄöÂ∏∏‰ª•Áâ∫Áâ≤Á≤æÂ∫¶‰∏∫‰ª£‰ª∑Êù•Èôç‰ΩéËÆ°ÁÆóÂ§çÊùÇÂ∫¶ÔºåÊó†Ê≥ïÂú®Á≤æÂ∫¶ÂíåÊïàÁéá‰πãÈó¥ÂèñÂæóÂπ≥Ë°°„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöMOBIUSÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáËÆæËÆ°È´òÊïàÁöÑÊ®°ÂùóÂíåËÆ≠ÁªÉÁ≠ñÁï•ÔºåÂú®‰∏çÊòæËëóÈôç‰ΩéÁ≤æÂ∫¶ÁöÑÂâçÊèê‰∏ãÔºåÂ§ßÂπÖÈôç‰ΩéÊ®°ÂûãÁöÑËÆ°ÁÆóÈáèÂíåÂÜÖÂ≠òÈúÄÊ±ÇÔºå‰ªéËÄåÂÆûÁé∞Ê®°ÂûãÂú®‰∏çÂêåÁ°¨‰ª∂Âπ≥Âè∞‰∏äÁöÑÁÅµÊ¥ªÈÉ®ÁΩ≤„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÈÄöËøáÂ§öÊ®°ÊÄÅÁì∂È¢àËûçÂêàÂáèÂ∞ëÁâπÂæÅÁª¥Â∫¶ÔºåÂπ∂ÈÄöËøáËØ≠Ë®ÄÂºïÂØºÁöÑ‰∏çÁ°ÆÂÆöÊÄßÊ†°ÂáÜÊçüÂ§±ÂÆûÁé∞Ëá™ÈÄÇÂ∫îÁöÑËß£Á†ÅÂô®Ââ™Êûù„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöMOBIUSÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö(1) BackboneÁΩëÁªúÔºöÁî®‰∫éÊèêÂèñÂõæÂÉèÁâπÂæÅ„ÄÇ(2) Áì∂È¢àÂÉèÁ¥†Ëß£Á†ÅÂô®ÔºöÁî®‰∫éÈ´òÊïàÂú∞ËûçÂêàÂ§öÂ∞∫Â∫¶ÂíåÂ§öÊ®°ÊÄÅÁâπÂæÅÔºåÈôç‰ΩéÁâπÂæÅÁª¥Â∫¶„ÄÇ(3) ÂàÜÂâ≤Â§¥ÔºöÁî®‰∫éÈ¢ÑÊµãÂÆû‰æãÂàÜÂâ≤ÁªìÊûú„ÄÇ(4) ËØ≠Ë®ÄÂºïÂØºÁöÑ‰∏çÁ°ÆÂÆöÊÄßÊ†°ÂáÜÊ®°ÂùóÔºöÁî®‰∫éËØÑ‰º∞Ëß£Á†ÅÂô®ÁöÑ‰∏çÁ°ÆÂÆöÊÄßÔºåÂπ∂ÊåáÂØºËß£Á†ÅÂô®ÁöÑÂâ™Êûù„ÄÇÊï¥‰∏™ËÆ≠ÁªÉËøáÁ®ãÈááÁî®Áªü‰∏ÄÁöÑËÆ≠ÁªÉÁ≠ñÁï•ÔºåÁÆÄÂåñ‰∫ÜËÆ≠ÁªÉÊµÅÁ®ã„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöMOBIUSÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö(1) Áì∂È¢àÂÉèÁ¥†Ëß£Á†ÅÂô®ÔºöÈÄöËøáÂºïÂÖ•Áì∂È¢àÁªìÊûÑÔºåÈôç‰Ωé‰∫ÜÁâπÂæÅÁª¥Â∫¶Ôºå‰ªéËÄåÂáèÂ∞ë‰∫ÜËÆ°ÁÆóÈáè„ÄÇ(2) ËØ≠Ë®ÄÂºïÂØºÁöÑ‰∏çÁ°ÆÂÆöÊÄßÊ†°ÂáÜÊçüÂ§±ÔºöÂà©Áî®ËØ≠Ë®Ä‰ø°ÊÅØÊù•ËØÑ‰º∞Ëß£Á†ÅÂô®ÁöÑ‰∏çÁ°ÆÂÆöÊÄßÔºåÂπ∂ÊåáÂØºËß£Á†ÅÂô®ÁöÑÂâ™ÊûùÔºå‰ªéËÄåÂÆûÁé∞‰∫ÜËá™ÈÄÇÂ∫îÁöÑËß£Á†ÅÂô®ÂéãÁº©„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåMOBIUSËÉΩÂ§üÂú®‰øùÊåÅÁ≤æÂ∫¶ÁöÑÂâçÊèê‰∏ãÔºåÊõ¥ÊúâÊïàÂú∞Èôç‰ΩéËÆ°ÁÆóÈáè„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**Ôºö(1) Áì∂È¢àÂÉèÁ¥†Ëß£Á†ÅÂô®ÔºöÈááÁî®Â§öÂ±ÇÊÑüÁü•Êú∫ÔºàMLPÔºâ‰Ωú‰∏∫Áì∂È¢àÁªìÊûÑÔºåÂ∞ÜÈ´òÁª¥ÁâπÂæÅÊò†Â∞ÑÂà∞‰ΩéÁª¥Á©∫Èó¥„ÄÇ(2) ËØ≠Ë®ÄÂºïÂØºÁöÑ‰∏çÁ°ÆÂÆöÊÄßÊ†°ÂáÜÊçüÂ§±ÔºöÂà©Áî®È¢ÑËÆ≠ÁªÉÁöÑËØ≠Ë®ÄÊ®°ÂûãÊù•ÊèêÂèñÂõæÂÉèÊèèËø∞ÁöÑËØ≠‰πâ‰ø°ÊÅØÔºåÂπ∂Â∞ÜÂÖ∂Áî®‰∫éËØÑ‰º∞Ëß£Á†ÅÂô®ÁöÑ‰∏çÁ°ÆÂÆöÊÄß„ÄÇÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°Êó®Âú®ÈºìÂä±Ê®°ÂûãÂ≠¶‰π†Âà∞Êõ¥ÂáÜÁ°ÆÁöÑÂàÜÂâ≤ÁªìÊûúÔºåÂπ∂Èôç‰ΩéÂØπ‰∏çÁ°ÆÂÆöÂå∫ÂüüÁöÑËøáÂ∫¶ÂÖ≥Ê≥®„ÄÇ(3) Áªü‰∏ÄËÆ≠ÁªÉÁ≠ñÁï•ÔºöÈááÁî®Á´ØÂà∞Á´ØÁöÑËÆ≠ÁªÉÊñπÂºèÔºåÁÆÄÂåñ‰∫ÜËÆ≠ÁªÉÊµÅÁ®ãÔºåÂπ∂ÊèêÈ´ò‰∫ÜÊ®°ÂûãÁöÑÊÄßËÉΩ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

MOBIUSÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äËøõË°å‰∫ÜÂÆûÈ™åÔºåÁªìÊûúË°®ÊòéÔºå‰∏éÁé∞ÊúâÁöÑÈ´òÊïàÂÆû‰æãÂàÜÂâ≤Ê®°ÂûãÁõ∏ÊØîÔºåMOBIUSÂú®ÊòæËëóÈôç‰ΩéËÆ°ÁÆóÈáèÁöÑÂêåÊó∂Ôºå‰øùÊåÅ‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåMOBIUSÂ∞ÜÂÉèÁ¥†ÂíåTransformerËß£Á†ÅÂô®ÁöÑFLOPsÂàÜÂà´Èôç‰ΩéÈ´òËææ55%Âíå75%ÔºåÂêåÊó∂Âú®‰ªÖ‰∏âÂàÜ‰πã‰∏ÄÁöÑËÆ≠ÁªÉËø≠‰ª£‰∏≠‰øùÊåÅ‰∫ÜÁõ∏ÂΩìÁîöËá≥Êõ¥Â•ΩÁöÑÁ≤æÂ∫¶„ÄÇËøôË°®ÊòéMOBIUSÂú®ÊïàÁéáÂíåÁ≤æÂ∫¶‰πãÈó¥ÂèñÂæó‰∫ÜËâØÂ•ΩÁöÑÂπ≥Ë°°„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

MOBIUSÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂåÖÊã¨ÁßªÂä®Êú∫Âô®‰∫∫„ÄÅËá™Âä®È©æÈ©∂„ÄÅÂ¢ûÂº∫Áé∞ÂÆûÂíåËôöÊãüÁé∞ÂÆûÁ≠âÈ¢ÜÂüü„ÄÇÂÆÉËÉΩÂ§ü‰ΩøËøô‰∫õÂ∫îÁî®Âú®ËµÑÊ∫êÂèóÈôêÁöÑËÆæÂ§á‰∏äÂÆûÁé∞È´òÊÄßËÉΩÁöÑÂÆû‰æãÂàÜÂâ≤Ôºå‰ªéËÄåÊèêÈ´òÁ≥ªÁªüÁöÑÊô∫ËÉΩÂåñÊ∞¥Âπ≥ÂíåÁî®Êà∑‰ΩìÈ™å„ÄÇÊ≠§Â§ñÔºåMOBIUSËøòÂèØ‰ª•Â∫îÁî®‰∫éÂåªÂ≠¶ÂõæÂÉèÂàÜÊûê„ÄÅÈÅ•ÊÑüÂõæÂÉèÂ§ÑÁêÜÁ≠âÈ¢ÜÂüüÔºå‰∏∫Ëøô‰∫õÈ¢ÜÂüüÊèê‰æõÈ´òÊïàÁöÑÂõæÂÉèÂàÜÂâ≤Ëß£ÂÜ≥ÊñπÊ°à„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Scaling up model size and training data has advanced foundation models for instance-level perception, achieving state-of-the-art in-domain and zero-shot performance across object detection and segmentation. However, their high computational cost limits adoption on resource-constrained platforms. We first examine the limitations of existing architectures in enabling efficient edge deployment without compromising performance. We then introduce MOBIUS, a family of foundation models for universal instance segmentation, designed for Pareto-optimal downscaling to support deployment across devices ranging from high-end accelerators to mobile hardware. To reduce training and inference demands, we propose: (i) a bottleneck pixel decoder for efficient multi-scale and multi-modal fusion, (ii) a language-guided uncertainty calibration loss for adaptive decoder pruning, and (iii) a streamlined, unified training strategy. Unlike efficient baselines that trade accuracy for reduced complexity, MOBIUS reduces pixel and transformer decoder FLOPs by up to 55% and 75%, respectively, while maintaining state-of-the-art performance in just a third of the training iterations. MOBIUS establishes a new benchmark for efficient segmentation on both high-performance computing platforms and mobile devices.

