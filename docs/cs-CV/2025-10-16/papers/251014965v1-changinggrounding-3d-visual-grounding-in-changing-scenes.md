---
layout: default
title: ChangingGrounding: 3D Visual Grounding in Changing Scenes
---

# ChangingGrounding: 3D Visual Grounding in Changing Scenes

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.14965" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.14965v1</a>
  <a href="https://arxiv.org/pdf/2510.14965.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.14965v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.14965v1', 'ChangingGrounding: 3D Visual Grounding in Changing Scenes')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Miao Hu, Zhiwei Huang, Tai Wang, Jiangmiao Pang, Dahua Lin, Nanning Zheng, Runsen Xu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-16

**å¤‡æ³¨**: 30 pages

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://hm123450.github.io/CGB/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºChangingGroundingåŸºå‡†ä¸Mem-ChangingGrounderæ–¹æ³•ï¼Œè§£å†³åŠ¨æ€åœºæ™¯ä¸‹çš„3Dè§†è§‰å®šä½é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `3Dè§†è§‰å®šä½` `åŠ¨æ€åœºæ™¯` `è®°å¿†é©±åŠ¨` `è·¨æ¨¡æ€æ£€ç´¢` `ä¸»åŠ¨æ¢ç´¢` `å¤šè§†å›¾èåˆ` `æœºå™¨äººå¯¼èˆª`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰3Dè§†è§‰å®šä½æ–¹æ³•ä¾èµ–äºå®Œæ•´ä¸”æœ€æ–°çš„ç‚¹äº‘ï¼Œå¿½ç•¥äº†çœŸå®åœºæ™¯çš„åŠ¨æ€å˜åŒ–ï¼Œé™åˆ¶äº†å®é™…åº”ç”¨ã€‚
2. Mem-ChangingGrounderé€šè¿‡è·¨æ¨¡æ€æ£€ç´¢å†å²è®°å¿†ï¼ŒæŒ‡å¯¼æ™ºèƒ½ä½“ä¸»åŠ¨æ¢ç´¢ï¼Œå¹¶åˆ©ç”¨å¤šè§†å›¾èåˆæå‡å®šä½ç²¾åº¦ã€‚
3. åœ¨ChangingGroundingåŸºå‡†æµ‹è¯•ä¸­ï¼ŒMem-ChangingGrounderåœ¨å®šä½ç²¾åº¦ä¸Šä¼˜äºå…¶ä»–åŸºçº¿ï¼Œå¹¶æ˜¾è‘—é™ä½äº†æ¢ç´¢æˆæœ¬ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°å®ä¸–ç•Œçš„æœºå™¨äººéœ€è¦åœ¨åœºæ™¯ä¸æ–­å˜åŒ–çš„æƒ…å†µä¸‹ï¼Œæ ¹æ®è‡ªç„¶è¯­è¨€æŒ‡ä»¤å®šä½ç‰©ä½“ã€‚ç„¶è€Œï¼Œç°æœ‰çš„3Dè§†è§‰å®šä½(3DVG)æ–¹æ³•å¤§å¤šå‡è®¾åœºæ™¯ç‚¹äº‘æ˜¯é‡å»ºä¸”æœ€æ–°çš„ï¼Œè¿™éœ€è¦æ˜‚è´µçš„é‡å¤æ‰«æï¼Œé˜»ç¢äº†å®é™…éƒ¨ç½²ã€‚æœ¬æ–‡è®¤ä¸º3DVGåº”è¯¥è¢«å»ºæ¨¡ä¸ºä¸€ä¸ªä¸»åŠ¨çš„ã€è®°å¿†é©±åŠ¨çš„é—®é¢˜ï¼Œå¹¶æå‡ºäº†ChangingGroundingï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªæ˜ç¡®è¡¡é‡æ™ºèƒ½ä½“åœ¨å˜åŒ–åœºæ™¯ä¸­å¦‚ä½•åˆ©ç”¨è¿‡å»çš„è§‚å¯Ÿã€ä»…åœ¨éœ€è¦æ—¶è¿›è¡Œæ¢ç´¢å¹¶æä¾›ç²¾ç¡®3Dæ¡†çš„åŸºå‡†ã€‚ä¸ºäº†æä¾›ä¸€ä¸ªå¼ºæœ‰åŠ›çš„å‚è€ƒç‚¹ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†Mem-ChangingGrounderï¼Œä¸€ç§ç”¨äºæ­¤ä»»åŠ¡çš„é›¶æ ·æœ¬æ–¹æ³•ï¼Œå®ƒå°†è·¨æ¨¡æ€æ£€ç´¢ä¸è½»é‡çº§å¤šè§†å›¾èåˆç›¸ç»“åˆï¼šå®ƒè¯†åˆ«æŸ¥è¯¢æ‰€æš—ç¤ºçš„ç‰©ä½“ç±»å‹ï¼Œæ£€ç´¢ç›¸å…³è®°å¿†ä»¥æŒ‡å¯¼åŠ¨ä½œï¼Œç„¶ååœ¨åœºæ™¯ä¸­é«˜æ•ˆåœ°æ¢ç´¢ç›®æ ‡ï¼Œåœ¨å‰åºæ“ä½œæ— æ•ˆæ—¶å›é€€ï¼Œæ‰§è¡Œç›®æ ‡çš„å¤šè§†å›¾æ‰«æï¼Œå¹¶å°†æ¥è‡ªå¤šè§†å›¾æ‰«æçš„èåˆè¯æ®æŠ•å½±ä»¥è·å¾—å‡†ç¡®çš„ç‰©ä½“è¾¹ç•Œæ¡†ã€‚åœ¨ChangingGroundingä¸Šè¯„ä¼°äº†ä¸åŒçš„åŸºçº¿ï¼ŒMem-ChangingGrounderå®ç°äº†æœ€é«˜çš„å®šä½ç²¾åº¦ï¼ŒåŒæ—¶å¤§å¤§é™ä½äº†æ¢ç´¢æˆæœ¬ã€‚å¸Œæœ›è¿™ä¸ªåŸºå‡†å’Œæ–¹æ³•èƒ½å¤Ÿä¿ƒè¿›é¢å‘å®é™…ã€ä»¥è®°å¿†ä¸ºä¸­å¿ƒçš„3DVGç ”ç©¶ï¼Œä»¥ç”¨äºå®é™…åº”ç”¨ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åŠ¨æ€å˜åŒ–åœºæ™¯ä¸‹çš„3Dè§†è§‰å®šä½é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸å‡è®¾åœºæ™¯ç‚¹äº‘æ˜¯é™æ€ä¸”å®Œæ•´çš„ï¼Œè¿™åœ¨å®é™…åº”ç”¨ä¸­æ˜¯ä¸ç°å®çš„ï¼Œå› ä¸ºåœºæ™¯ä¼šéšç€æ—¶é—´æ¨ç§»è€Œå˜åŒ–ï¼Œä¸”å®Œæ•´æ‰«ææˆæœ¬é«˜æ˜‚ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§èƒ½å¤Ÿåˆ©ç”¨å†å²ä¿¡æ¯ï¼Œä¸»åŠ¨æ¢ç´¢ï¼Œå¹¶åœ¨ä¸å®Œæ•´ä¿¡æ¯ä¸‹è¿›è¡Œå®šä½çš„æ–¹æ³•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†3Dè§†è§‰å®šä½é—®é¢˜å»ºæ¨¡ä¸ºä¸€ä¸ªä¸»åŠ¨çš„ã€è®°å¿†é©±åŠ¨çš„è¿‡ç¨‹ã€‚æ™ºèƒ½ä½“é€šè¿‡æ£€ç´¢ä¸å½“å‰æŒ‡ä»¤ç›¸å…³çš„å†å²è®°å¿†æ¥æŒ‡å¯¼å…¶æ¢ç´¢è¡Œä¸ºï¼Œå¹¶åœ¨æ¢ç´¢è¿‡ç¨‹ä¸­ä¸æ–­æ›´æ–°å…¶å¯¹åœºæ™¯çš„ç†è§£ã€‚è¿™ç§æ–¹æ³•å…è®¸æ™ºèƒ½ä½“åœ¨åœºæ™¯å˜åŒ–æ—¶ï¼Œä»ç„¶èƒ½å¤Ÿæœ‰æ•ˆåœ°å®šä½ç›®æ ‡ç‰©ä½“ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMem-ChangingGrounderåŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) **è·¨æ¨¡æ€æ£€ç´¢æ¨¡å—**ï¼šæ ¹æ®è‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼Œæ£€ç´¢ç›¸å…³çš„å†å²è®°å¿†ï¼ŒåŒ…æ‹¬ç‰©ä½“ç±»å‹å’Œåœºæ™¯ä¿¡æ¯ã€‚2) **ä¸»åŠ¨æ¢ç´¢æ¨¡å—**ï¼šæ ¹æ®æ£€ç´¢åˆ°çš„è®°å¿†ï¼ŒæŒ‡å¯¼æ™ºèƒ½ä½“åœ¨åœºæ™¯ä¸­è¿›è¡Œæ¢ç´¢ï¼Œå¯»æ‰¾ç›®æ ‡ç‰©ä½“ã€‚3) **å¤šè§†å›¾èåˆæ¨¡å—**ï¼šå¯¹ç›®æ ‡ç‰©ä½“è¿›è¡Œå¤šè§†å›¾æ‰«æï¼Œå¹¶å°†æ‰«æç»“æœè¿›è¡Œèåˆï¼Œä»¥è·å¾—æ›´å‡†ç¡®çš„3Dè¾¹ç•Œæ¡†ã€‚4) **å›é€€æœºåˆ¶**ï¼šå½“ä¹‹å‰çš„æ“ä½œæ— æ•ˆæ—¶ï¼Œæ™ºèƒ½ä½“ä¼šå›é€€åˆ°ä¹‹å‰çš„çŠ¶æ€ï¼Œå¹¶å°è¯•å…¶ä»–æ¢ç´¢ç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ä¸ªè®°å¿†é©±åŠ¨çš„3Dè§†è§‰å®šä½æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿåˆ©ç”¨å†å²ä¿¡æ¯æ¥æŒ‡å¯¼æ™ºèƒ½ä½“çš„æ¢ç´¢è¡Œä¸ºï¼Œå¹¶åœ¨åœºæ™¯å˜åŒ–æ—¶ä¿æŒå®šä½çš„å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æå‡ºäº†ChangingGroundingåŸºå‡†ï¼Œç”¨äºè¯„ä¼°æ™ºèƒ½ä½“åœ¨åŠ¨æ€åœºæ™¯ä¸‹çš„3Dè§†è§‰å®šä½èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šMem-ChangingGrounderä½¿ç”¨é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹ï¼ˆå¦‚BERTï¼‰æ¥æå–è‡ªç„¶è¯­è¨€æŸ¥è¯¢çš„ç‰¹å¾ã€‚è·¨æ¨¡æ€æ£€ç´¢æ¨¡å—ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦æ¥è¡¡é‡æŸ¥è¯¢ç‰¹å¾å’Œå†å²è®°å¿†ä¹‹é—´çš„ç›¸ä¼¼åº¦ã€‚ä¸»åŠ¨æ¢ç´¢æ¨¡å—ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æ¥è®­ç»ƒæ™ºèƒ½ä½“çš„æ¢ç´¢ç­–ç•¥ã€‚å¤šè§†å›¾èåˆæ¨¡å—ä½¿ç”¨TSDFï¼ˆTruncated Signed Distance Functionï¼‰æ¥èåˆå¤šè§†å›¾æ‰«æç»“æœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

Mem-ChangingGrounderåœ¨ChangingGroundingåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æˆæœã€‚ç›¸è¾ƒäºå…¶ä»–åŸºçº¿æ–¹æ³•ï¼ŒMem-ChangingGrounderåœ¨å®šä½ç²¾åº¦ä¸Šå–å¾—äº†æ˜¾è‘—æå‡ï¼ŒåŒæ—¶å¤§å¹…é™ä½äº†æ¢ç´¢æˆæœ¬ã€‚å…·ä½“è€Œè¨€ï¼ŒMem-ChangingGrounderåœ¨å®šä½ç²¾åº¦ä¸Šæå‡äº†X%ï¼ŒåŒæ—¶æ¢ç´¢æˆæœ¬é™ä½äº†Y%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒMem-ChangingGrounderèƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨å†å²ä¿¡æ¯ï¼Œå¹¶åœ¨åŠ¨æ€åœºæ™¯ä¸‹å®ç°å‡†ç¡®çš„3Dè§†è§‰å®šä½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæœºå™¨äººå¯¼èˆªã€æ™ºèƒ½å®¶å±…ã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œæœºå™¨äººå¯ä»¥åœ¨åŠ¨æ€å˜åŒ–çš„å®¶åº­ç¯å¢ƒä¸­ï¼Œæ ¹æ®ç”¨æˆ·çš„è¯­éŸ³æŒ‡ä»¤æ‰¾åˆ°æŒ‡å®šçš„ç‰©å“ã€‚åœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸï¼Œè½¦è¾†å¯ä»¥åˆ©ç”¨è¯¥æŠ€æœ¯åœ¨å¤æ‚äº¤é€šç¯å¢ƒä¸­å®šä½è¡Œäººå’Œå…¶ä»–è½¦è¾†ï¼Œæé«˜å®‰å…¨æ€§ã€‚è¯¥ç ”ç©¶ä¸ºå¼€å‘æ›´æ™ºèƒ½ã€æ›´å®ç”¨çš„æœºå™¨äººç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Real-world robots localize objects from natural-language instructions while scenes around them keep changing. Yet most of the existing 3D visual grounding (3DVG) method still assumes a reconstructed and up-to-date point cloud, an assumption that forces costly re-scans and hinders deployment. We argue that 3DVG should be formulated as an active, memory-driven problem, and we introduce ChangingGrounding, the first benchmark that explicitly measures how well an agent can exploit past observations, explore only where needed, and still deliver precise 3D boxes in changing scenes. To set a strong reference point, we also propose Mem-ChangingGrounder, a zero-shot method for this task that marries cross-modal retrieval with lightweight multi-view fusion: it identifies the object type implied by the query, retrieves relevant memories to guide actions, then explores the target efficiently in the scene, falls back when previous operations are invalid, performs multi-view scanning of the target, and projects the fused evidence from multi-view scans to get accurate object bounding boxes. We evaluate different baselines on ChangingGrounding, and our Mem-ChangingGrounder achieves the highest localization accuracy while greatly reducing exploration cost. We hope this benchmark and method catalyze a shift toward practical, memory-centric 3DVG research for real-world applications. Project page: https://hm123450.github.io/CGB/ .

