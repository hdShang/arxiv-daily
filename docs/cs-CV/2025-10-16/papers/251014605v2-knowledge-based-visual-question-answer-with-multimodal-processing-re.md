---
layout: default
title: Knowledge-based Visual Question Answer with Multimodal Processing, Retrieval and Filtering
---

# Knowledge-based Visual Question Answer with Multimodal Processing, Retrieval and Filtering

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.14605" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.14605v2</a>
  <a href="https://arxiv.org/pdf/2510.14605.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.14605v2" onclick="toggleFavorite(this, '2510.14605v2', 'Knowledge-based Visual Question Answer with Multimodal Processing, Retrieval and Filtering')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuyang Hong, Jiaqi Gu, Qi Yang, Lubin Fan, Yue Wu, Ying Wang, Kun Ding, Shiming Xiang, Jieping Ye

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-10-16 (æ›´æ–°: 2025-10-20)

**å¤‡æ³¨**: Accepted by NeurIPS 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/cqu-student/Wiki-PRF)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºWiki-PRFæ¡†æ¶ï¼Œè§£å†³çŸ¥è¯†åº“VQAä¸­å¤šæ¨¡æ€æŸ¥è¯¢è´¨é‡å’Œæ£€ç´¢ç»“æœç›¸å…³æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `çŸ¥è¯†åº“è§†è§‰é—®ç­”` `å¤šæ¨¡æ€èåˆ` `æ£€ç´¢å¢å¼ºç”Ÿæˆ` `å¼ºåŒ–å­¦ä¹ ` `è§†è§‰å·¥å…·` `çŸ¥è¯†æ£€ç´¢` `ç›¸å…³æ€§è¿‡æ»¤`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰KB-VQAæ–¹æ³•åœ¨å¤šæ¨¡æ€æŸ¥è¯¢è´¨é‡å’Œæ£€ç´¢ç»“æœç›¸å…³æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå½±å“äº†ç­”æ¡ˆçš„å‡†ç¡®æ€§ã€‚
2. Wiki-PRFæ¡†æ¶é€šè¿‡å¤„ç†ã€æ£€ç´¢å’Œè¿‡æ»¤ä¸‰ä¸ªé˜¶æ®µï¼Œæå‡å¤šæ¨¡æ€æŸ¥è¯¢è´¨é‡å’Œæ£€ç´¢ç»“æœçš„ç›¸å…³æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒWiki-PRFåœ¨E-VQAå’ŒInfoSeekæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¾¾åˆ°SOTAæ°´å¹³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºäºçŸ¥è¯†çš„è§†è§‰é—®ç­”(KB-VQA)è¦æ±‚è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)å°†è§†è§‰ç†è§£ä¸å¤–éƒ¨çŸ¥è¯†æ£€ç´¢ç›¸ç»“åˆã€‚æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)é€šè¿‡ç»“åˆçŸ¥è¯†åº“æŸ¥è¯¢åœ¨è¯¥ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ä»ç„¶éš¾ä»¥åº”å¯¹å¤šæ¨¡æ€æŸ¥è¯¢çš„è´¨é‡å’Œæ£€ç´¢ç»“æœçš„ç›¸å…³æ€§ã€‚ä¸ºäº†å…‹æœè¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„ä¸‰é˜¶æ®µæ–¹æ³•ï¼Œç§°ä¸ºWiki-PRFï¼ŒåŒ…æ‹¬å¤„ç†(Processing)ã€æ£€ç´¢(Retrieval)å’Œè¿‡æ»¤(Filtering)é˜¶æ®µã€‚å¤„ç†é˜¶æ®µåŠ¨æ€åœ°è°ƒç”¨è§†è§‰å·¥å…·æ¥æå–ç²¾ç¡®çš„å¤šæ¨¡æ€ä¿¡æ¯ä»¥è¿›è¡Œæ£€ç´¢ã€‚æ£€ç´¢é˜¶æ®µé›†æˆäº†è§†è§‰å’Œæ–‡æœ¬ç‰¹å¾ä»¥å®ç°å¤šæ¨¡æ€çŸ¥è¯†æ£€ç´¢ã€‚è¿‡æ»¤é˜¶æ®µå¯¹æ£€ç´¢ç»“æœæ‰§è¡Œç›¸å…³æ€§è¿‡æ»¤å’Œé›†ä¸­ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªè§†è§‰è¯­è¨€æ¨¡å‹ï¼Œè¯¥æ¨¡å‹é€šè¿‡å¼ºåŒ–å­¦ä¹ çš„æ–¹å¼ï¼Œä»¥ç­”æ¡ˆå‡†ç¡®æ€§å’Œæ ¼å¼ä¸€è‡´æ€§ä½œä¸ºå¥–åŠ±ä¿¡å·è¿›è¡Œè®­ç»ƒã€‚è¿™å¢å¼ºäº†æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€ç”¨äºå‡†ç¡®æŸ¥è¯¢çš„å·¥å…·è°ƒç”¨ä»¥åŠå¯¹ä¸ç›¸å…³å†…å®¹çš„è¿‡æ»¤ã€‚åœ¨åŸºå‡†æ•°æ®é›†(E-VQAå’ŒInfoSeek)ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œç­”æ¡ˆè´¨é‡æœ‰äº†æ˜¾è‘—æé«˜(36.0å’Œ42.8)ï¼Œå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³çŸ¥è¯†åº“è§†è§‰é—®ç­”(KB-VQA)ä»»åŠ¡ä¸­ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚è§†è§‰ä¿¡æ¯å’Œè¿›è¡Œæœ‰æ•ˆçŸ¥è¯†æ£€ç´¢æ—¶é‡åˆ°çš„é—®é¢˜ã€‚å…·ä½“æ¥è¯´ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥ç”Ÿæˆé«˜è´¨é‡çš„å¤šæ¨¡æ€æŸ¥è¯¢ï¼Œå¹¶ä¸”æ£€ç´¢åˆ°çš„çŸ¥è¯†å¾€å¾€åŒ…å«å¤§é‡ä¸ç›¸å…³ä¿¡æ¯ï¼Œå¯¼è‡´ç­”æ¡ˆè´¨é‡ä¸‹é™ã€‚ç°æœ‰æ–¹æ³•çš„ç—›ç‚¹åœ¨äºå¦‚ä½•å‡†ç¡®æå–è§†è§‰ä¿¡æ¯ï¼Œå¹¶å°†å…¶ä¸æ–‡æœ¬ä¿¡æ¯æœ‰æ•ˆèåˆï¼Œä»è€Œå®ç°æ›´ç²¾å‡†çš„çŸ¥è¯†æ£€ç´¢å’Œè¿‡æ»¤ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æå‡ºä¸€ä¸ªä¸‰é˜¶æ®µæ¡†æ¶Wiki-PRFï¼Œåˆ†åˆ«è´Ÿè´£å¤šæ¨¡æ€ä¿¡æ¯çš„å¤„ç†ã€çŸ¥è¯†æ£€ç´¢å’Œç»“æœè¿‡æ»¤ã€‚é€šè¿‡åŠ¨æ€è°ƒç”¨è§†è§‰å·¥å…·æå–ç²¾ç¡®ä¿¡æ¯ï¼Œèåˆè§†è§‰å’Œæ–‡æœ¬ç‰¹å¾è¿›è¡Œæ£€ç´¢ï¼Œå¹¶åˆ©ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„æ¨¡å‹è¿›è¡Œç›¸å…³æ€§è¿‡æ»¤ï¼Œä»è€Œæé«˜ç­”æ¡ˆçš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šWiki-PRFæ¡†æ¶åŒ…å«ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼š
1. **å¤„ç†(Processing)é˜¶æ®µ**ï¼šåŠ¨æ€è°ƒç”¨è§†è§‰å·¥å…·ï¼Œä¾‹å¦‚ç›®æ ‡æ£€æµ‹ã€OCRç­‰ï¼Œæå–å›¾åƒä¸­çš„å…³é”®ä¿¡æ¯ï¼Œç”Ÿæˆæ›´ç²¾ç¡®çš„å¤šæ¨¡æ€æŸ¥è¯¢ã€‚
2. **æ£€ç´¢(Retrieval)é˜¶æ®µ**ï¼šèåˆè§†è§‰å’Œæ–‡æœ¬ç‰¹å¾ï¼Œåˆ©ç”¨å¤šæ¨¡æ€çŸ¥è¯†åº“è¿›è¡Œæ£€ç´¢ï¼Œè·å–ä¸é—®é¢˜å’Œå›¾åƒç›¸å…³çš„çŸ¥è¯†ç‰‡æ®µã€‚
3. **è¿‡æ»¤(Filtering)é˜¶æ®µ**ï¼šåˆ©ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œå¯¹æ£€ç´¢åˆ°çš„çŸ¥è¯†ç‰‡æ®µè¿›è¡Œç›¸å…³æ€§è¿‡æ»¤å’Œé›†ä¸­ï¼Œå»é™¤ä¸ç›¸å…³çš„ä¿¡æ¯ï¼Œä¿ç•™æœ€ç›¸å…³çš„çŸ¥è¯†ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š
1. æå‡ºäº†ä¸€ç§åŠ¨æ€è°ƒç”¨è§†è§‰å·¥å…·çš„å¤„ç†é˜¶æ®µï¼Œèƒ½å¤Ÿæ›´å‡†ç¡®åœ°æå–å›¾åƒä¸­çš„ä¿¡æ¯ï¼Œç”Ÿæˆé«˜è´¨é‡çš„å¤šæ¨¡æ€æŸ¥è¯¢ã€‚
2. åˆ©ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒè§†è§‰è¯­è¨€æ¨¡å‹ï¼Œä»¥ç­”æ¡ˆå‡†ç¡®æ€§å’Œæ ¼å¼ä¸€è‡´æ€§ä½œä¸ºå¥–åŠ±ä¿¡å·ï¼Œå¢å¼ºäº†æ¨¡å‹å¯¹æ£€ç´¢ç»“æœçš„è¿‡æ»¤èƒ½åŠ›ã€‚
3. æ•´ä½“æ¡†æ¶å°†å¤šæ¨¡æ€ä¿¡æ¯å¤„ç†ã€çŸ¥è¯†æ£€ç´¢å’Œç»“æœè¿‡æ»¤ä¸‰ä¸ªé˜¶æ®µæœ‰æœºç»“åˆï¼Œå½¢æˆä¸€ä¸ªå®Œæ•´çš„KB-VQAè§£å†³æ–¹æ¡ˆã€‚

**å…³é”®è®¾è®¡**ï¼š
1. **è§†è§‰å·¥å…·é€‰æ‹©**ï¼šæ ¹æ®é—®é¢˜ç±»å‹å’Œå›¾åƒå†…å®¹ï¼ŒåŠ¨æ€é€‰æ‹©åˆé€‚çš„è§†è§‰å·¥å…·è¿›è¡Œä¿¡æ¯æå–ã€‚
2. **å¤šæ¨¡æ€ç‰¹å¾èåˆ**ï¼šé‡‡ç”¨åˆé€‚çš„ç‰¹å¾èåˆæ–¹æ³•ï¼Œå°†è§†è§‰ç‰¹å¾å’Œæ–‡æœ¬ç‰¹å¾è¿›è¡Œæœ‰æ•ˆèåˆï¼Œç”¨äºçŸ¥è¯†æ£€ç´¢ã€‚
3. **å¼ºåŒ–å­¦ä¹ å¥–åŠ±å‡½æ•°**ï¼šè®¾è®¡ä»¥ç­”æ¡ˆå‡†ç¡®æ€§å’Œæ ¼å¼ä¸€è‡´æ€§ä¸ºå¯¼å‘çš„å¥–åŠ±å‡½æ•°ï¼Œè®­ç»ƒè§†è§‰è¯­è¨€æ¨¡å‹ï¼Œæé«˜å…¶è¿‡æ»¤èƒ½åŠ›ã€‚
4. **æŸå¤±å‡½æ•°**ï¼šä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°è®­ç»ƒæ¨¡å‹ï¼Œå¹¶ç»“åˆå¼ºåŒ–å­¦ä¹ çš„å¥–åŠ±ä¿¡å·è¿›è¡Œå¾®è°ƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒWiki-PRFæ¡†æ¶åœ¨E-VQAå’ŒInfoSeekæ•°æ®é›†ä¸Šåˆ†åˆ«å–å¾—äº†36.0å’Œ42.8çš„æ˜¾è‘—æå‡ï¼Œè¾¾åˆ°äº†state-of-the-artçš„æ€§èƒ½ã€‚è¿™è¡¨æ˜è¯¥æ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆåœ°æé«˜KB-VQAä»»åŠ¡çš„ç­”æ¡ˆè´¨é‡å’Œå‡†ç¡®æ€§ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ™ºèƒ½å®¢æœã€æ•™è‚²è¾…åŠ©ã€åŒ»ç–—è¯Šæ–­ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨æ™ºèƒ½å®¢æœä¸­ï¼Œå¯ä»¥åˆ©ç”¨è¯¥æŠ€æœ¯ç†è§£ç”¨æˆ·æå‡ºçš„åŒ…å«å›¾åƒçš„é—®é¢˜ï¼Œå¹¶ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯ï¼Œç»™å‡ºå‡†ç¡®çš„ç­”æ¡ˆã€‚åœ¨åŒ»ç–—è¯Šæ–­ä¸­ï¼Œå¯ä»¥è¾…åŠ©åŒ»ç”Ÿåˆ†æåŒ»å­¦å½±åƒï¼Œå¹¶ç»“åˆåŒ»å­¦çŸ¥è¯†åº“è¿›è¡Œè¯Šæ–­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Knowledge-based visual question answering (KB-VQA) requires visual language models (VLMs) to integrate visual understanding with external knowledge retrieval. Although retrieval-augmented generation (RAG) achieves significant advances in this task by combining knowledge-base querying, it still struggles with the quality of multimodal queries and the relevance of retrieved results. To overcome these challenges, we propose a novel three-stage method, termed Wiki-PRF, including Processing, Retrieval and Filtering stages. The processing stage dynamically invokes visual tools to extract precise multimodal information for retrieval. The retrieval stage integrates visual and text features to achieve multimodal knowledge retrieval. The filtering stage performs relevance filtering and concentration on retrieval results. To this end, we introduce a visual language model trained with answer accuracy and format consistency as reward signals via a reinforcement learning manner. This enhances the model's reasoning, tool invocation for accurate queries, and filtering of irrelevant content. Experiments on benchmark datasets (E-VQA and InfoSeek) show significant improvements~(36.0 and 42.8) in answer quality, achieving state-of-the-art performance. Code is available at https://github.com/cqu-student/Wiki-PRF

