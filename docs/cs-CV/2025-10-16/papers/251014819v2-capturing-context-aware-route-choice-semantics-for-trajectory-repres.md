---
layout: default
title: Capturing Context-Aware Route Choice Semantics for Trajectory Representation Learning
---

# Capturing Context-Aware Route Choice Semantics for Trajectory Representation Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.14819" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.14819v2</a>
  <a href="https://arxiv.org/pdf/2510.14819.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.14819v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.14819v2', 'Capturing Context-Aware Route Choice Semantics for Trajectory Representation Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ji Cao, Yu Wang, Tongya Zheng, Jie Song, Qinghong Guo, Zujie Ren, Canghong Jin, Gang Chen, Mingli Song

**åˆ†ç±»**: cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-10-16 (æ›´æ–°: 2025-12-01)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/caoji2001/CORE)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCOREæ¡†æ¶ï¼Œèåˆä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„è·¯å¾„é€‰æ‹©è¯­ä¹‰ï¼Œæå‡è½¨è¿¹è¡¨ç¤ºå­¦ä¹ æ•ˆæœ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è½¨è¿¹è¡¨ç¤ºå­¦ä¹ ` `è·¯å¾„é€‰æ‹©å»ºæ¨¡` `ä¸Šä¸‹æ–‡æ„ŸçŸ¥` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ··åˆä¸“å®¶æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è½¨è¿¹è¡¨ç¤ºå­¦ä¹ æ–¹æ³•å¿½ç•¥äº†è½¨è¿¹èƒŒåè•´å«çš„è·¯å¾„é€‰æ‹©å†³ç­–è¿‡ç¨‹ï¼Œé™åˆ¶äº†è¡¨ç¤ºçš„è¯­ä¹‰ä¸°å¯Œæ€§ã€‚
2. COREæ¡†æ¶é€šè¿‡èåˆä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„è·¯å¾„é€‰æ‹©è¯­ä¹‰æ¥å¢å¼ºè½¨è¿¹è¡¨ç¤ºï¼Œåˆ©ç”¨LLMæå–ç¯å¢ƒè¯­ä¹‰ï¼Œå¹¶ç»“åˆMoEæ¶æ„æ•è·è·¯å¾„é€‰æ‹©æ¨¡å¼ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒCOREåœ¨å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹³å‡æå‡é«˜è¾¾9.79%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è½¨è¿¹è¡¨ç¤ºå­¦ä¹ (TRL)æ—¨åœ¨å°†åŸå§‹è½¨è¿¹æ•°æ®ç¼–ç ä¸ºä½ç»´åµŒå…¥ï¼Œç”¨äºæ—…è¡Œæ—¶é—´ä¼°è®¡ã€ç§»åŠ¨æ€§é¢„æµ‹å’Œè½¨è¿¹ç›¸ä¼¼æ€§åˆ†æç­‰ä¸‹æ¸¸ä»»åŠ¡ã€‚ä»è¡Œä¸ºè§’åº¦æ¥çœ‹ï¼Œè½¨è¿¹åæ˜ äº†åŸå¸‚ç¯å¢ƒä¸­ä¸€ç³»åˆ—çš„è·¯å¾„é€‰æ‹©ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰çš„TRLæ–¹æ³•å¿½ç•¥äº†è¿™ç§æ½œåœ¨çš„å†³ç­–è¿‡ç¨‹ï¼Œè€Œæ˜¯å°†è½¨è¿¹è§†ä¸ºé™æ€çš„ã€è¢«åŠ¨çš„æ—¶ç©ºåºåˆ—ï¼Œä»è€Œé™åˆ¶äº†å­¦ä¹ åˆ°çš„è¡¨ç¤ºçš„è¯­ä¹‰ä¸°å¯Œæ€§ã€‚ä¸ºäº†å¼¥åˆè¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†COREï¼Œä¸€ä¸ªå°†ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„è·¯å¾„é€‰æ‹©è¯­ä¹‰é›†æˆåˆ°è½¨è¿¹åµŒå…¥ä¸­çš„TRLæ¡†æ¶ã€‚COREé¦–å…ˆç»“åˆäº†ä¸€ä¸ªå¤šç²’åº¦çš„ç¯å¢ƒæ„ŸçŸ¥æ¨¡å—ï¼Œè¯¥æ¨¡å—åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹(llm)ä»å…´è¶£ç‚¹(POI)åˆ†å¸ƒä¸­æå–ç¯å¢ƒè¯­ä¹‰ï¼Œä»è€Œæ„å»ºä¸€ä¸ªä¸Šä¸‹æ–‡ä¸°å¯Œçš„é“è·¯ç½‘ç»œã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼ŒCOREé‡‡ç”¨äº†ä¸€ä¸ªå…·æœ‰æ··åˆä¸“å®¶(MoE)æ¶æ„çš„è·¯å¾„é€‰æ‹©ç¼–ç å™¨ï¼Œé€šè¿‡è”åˆåˆ©ç”¨ä¸Šä¸‹æ–‡ä¸°å¯Œçš„é“è·¯ç½‘ç»œå’Œå¯¼èˆªå› ç´ æ¥æ•è·è·¯å¾„é€‰æ‹©æ¨¡å¼ã€‚æœ€åï¼ŒTransformerç¼–ç å™¨å°†è·¯å¾„é€‰æ‹©æ„ŸçŸ¥çš„è¡¨ç¤ºèšåˆä¸ºå…¨å±€è½¨è¿¹åµŒå…¥ã€‚åœ¨6ä¸ªä¸‹æ¸¸ä»»åŠ¡çš„4ä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒCOREå§‹ç»ˆä¼˜äº12ä¸ªæœ€å…ˆè¿›çš„TRLæ–¹æ³•ï¼Œä¸æ€§èƒ½æœ€ä½³çš„åŸºçº¿ç›¸æ¯”ï¼Œå¹³å‡æé«˜äº†9.79%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰è½¨è¿¹è¡¨ç¤ºå­¦ä¹ æ–¹æ³•ä¸»è¦å°†è½¨è¿¹è§†ä¸ºé™æ€çš„æ—¶ç©ºåºåˆ—ï¼Œå¿½ç•¥äº†è½¨è¿¹æ˜¯ç”±ä¸€ç³»åˆ—è·¯å¾„é€‰æ‹©å†³ç­–æ„æˆçš„ã€‚è¿™ç§å¿½ç•¥å¯¼è‡´å­¦ä¹ åˆ°çš„è½¨è¿¹è¡¨ç¤ºç¼ºä¹å¯¹ç¯å¢ƒä¸Šä¸‹æ–‡å’Œç”¨æˆ·è¡Œä¸ºçš„ç†è§£ï¼Œé™åˆ¶äº†å…¶åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚å› æ­¤ï¼Œå¦‚ä½•å°†è·¯å¾„é€‰æ‹©çš„è¯­ä¹‰ä¿¡æ¯èå…¥åˆ°è½¨è¿¹è¡¨ç¤ºä¸­æ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šCOREçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†è½¨è¿¹è§†ä¸ºä¸€ç³»åˆ—ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„è·¯å¾„é€‰æ‹©è¡Œä¸ºçš„é›†åˆã€‚é€šè¿‡æ˜¾å¼åœ°å»ºæ¨¡æ¯ä¸ªè·¯å¾„é€‰æ‹©å†³ç­–ï¼Œå¹¶ç»“åˆç¯å¢ƒä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¯ä»¥æ›´å…¨é¢åœ°ç†è§£è½¨è¿¹çš„è¯­ä¹‰ã€‚å…·ä½“æ¥è¯´ï¼ŒCOREåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹æå–ç¯å¢ƒè¯­ä¹‰ï¼Œå¹¶ä½¿ç”¨æ··åˆä¸“å®¶æ¨¡å‹æ¥æ•è·ä¸åŒçš„è·¯å¾„é€‰æ‹©æ¨¡å¼ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCOREæ¡†æ¶ä¸»è¦åŒ…å«ä¸‰ä¸ªæ¨¡å—ï¼šç¯å¢ƒæ„ŸçŸ¥æ¨¡å—ã€è·¯å¾„é€‰æ‹©ç¼–ç å™¨å’Œè½¨è¿¹ç¼–ç å™¨ã€‚é¦–å…ˆï¼Œç¯å¢ƒæ„ŸçŸ¥æ¨¡å—åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ä»POIæ•°æ®ä¸­æå–ç¯å¢ƒè¯­ä¹‰ï¼Œæ„å»ºä¸Šä¸‹æ–‡ä¸°å¯Œçš„é“è·¯ç½‘ç»œã€‚ç„¶åï¼Œè·¯å¾„é€‰æ‹©ç¼–ç å™¨ä½¿ç”¨æ··åˆä¸“å®¶æ¨¡å‹ï¼Œç»“åˆä¸Šä¸‹æ–‡ä¸°å¯Œçš„é“è·¯ç½‘ç»œå’Œå¯¼èˆªå› ç´ ï¼Œå¯¹æ¯ä¸ªè·¯å¾„é€‰æ‹©å†³ç­–è¿›è¡Œç¼–ç ã€‚æœ€åï¼Œè½¨è¿¹ç¼–ç å™¨ä½¿ç”¨Transformeræ¨¡å‹å°†æ‰€æœ‰è·¯å¾„é€‰æ‹©çš„è¡¨ç¤ºèšåˆä¸ºå…¨å±€è½¨è¿¹åµŒå…¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šCOREçš„å…³é”®åˆ›æ–°åœ¨äºå°†ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„è·¯å¾„é€‰æ‹©è¯­ä¹‰èå…¥åˆ°è½¨è¿¹è¡¨ç¤ºå­¦ä¹ ä¸­ã€‚å…·ä½“æ¥è¯´ï¼ŒCOREé¦–æ¬¡åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹æ¥æå–ç¯å¢ƒè¯­ä¹‰ï¼Œå¹¶ä½¿ç”¨æ··åˆä¸“å®¶æ¨¡å‹æ¥æ•è·ä¸åŒçš„è·¯å¾„é€‰æ‹©æ¨¡å¼ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæ›´å…¨é¢åœ°ç†è§£è½¨è¿¹çš„è¯­ä¹‰ï¼Œå¹¶æé«˜è½¨è¿¹è¡¨ç¤ºçš„è´¨é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šç¯å¢ƒæ„ŸçŸ¥æ¨¡å—ä½¿ç”¨é¢„è®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆå…·ä½“æ¨¡å‹æœªçŸ¥ï¼‰æ¥ç¼–ç POIæ•°æ®ï¼Œå¾—åˆ°ç¯å¢ƒè¯­ä¹‰å‘é‡ã€‚è·¯å¾„é€‰æ‹©ç¼–ç å™¨ä½¿ç”¨æ··åˆä¸“å®¶æ¨¡å‹ï¼Œå…¶ä¸­æ¯ä¸ªä¸“å®¶è´Ÿè´£æ•è·ä¸€ç§ç‰¹å®šçš„è·¯å¾„é€‰æ‹©æ¨¡å¼ã€‚æ··åˆä¸“å®¶æ¨¡å‹çš„è¾“å‡ºé€šè¿‡ä¸€ä¸ªé—¨æ§ç½‘ç»œè¿›è¡ŒåŠ æƒï¼Œå¾—åˆ°æœ€ç»ˆçš„è·¯å¾„é€‰æ‹©è¡¨ç¤ºã€‚è½¨è¿¹ç¼–ç å™¨ä½¿ç”¨Transformeræ¨¡å‹ï¼Œå°†æ‰€æœ‰è·¯å¾„é€‰æ‹©çš„è¡¨ç¤ºèšåˆä¸ºå…¨å±€è½¨è¿¹åµŒå…¥ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡ç»†èŠ‚æœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

COREåœ¨å››ä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œå¹¶åœ¨å…­ä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¸12ä¸ªæœ€å…ˆè¿›çš„è½¨è¿¹è¡¨ç¤ºå­¦ä¹ æ–¹æ³•ç›¸æ¯”ï¼ŒCOREå¹³å‡æå‡äº†9.79%ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚å°¤å…¶åœ¨æ—…è¡Œæ—¶é—´ä¼°è®¡å’Œè½¨è¿¹ç›¸ä¼¼æ€§åˆ†æç­‰ä»»åŠ¡ä¸Šï¼ŒCOREè¡¨ç°å‡ºæ›´å¼ºçš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºæ™ºèƒ½äº¤é€šé¢†åŸŸï¼Œä¾‹å¦‚ï¼šæå‡æ—…è¡Œæ—¶é—´ä¼°è®¡çš„å‡†ç¡®æ€§ï¼Œæ”¹è¿›å‡ºè¡Œè·¯çº¿æ¨èçš„åˆç†æ€§ï¼Œä¼˜åŒ–äº¤é€šæµé‡é¢„æµ‹çš„å¯é æ€§ï¼Œä»¥åŠå¢å¼ºè½¨è¿¹ç›¸ä¼¼æ€§åˆ†æçš„æœ‰æ•ˆæ€§ã€‚é€šè¿‡æ›´ç²¾å‡†åœ°ç†è§£ç”¨æˆ·å‡ºè¡Œè¡Œä¸ºï¼Œå¯ä»¥ä¸ºåŸå¸‚äº¤é€šç®¡ç†å’Œä¸ªäººå‡ºè¡ŒæœåŠ¡æä¾›æ›´æ™ºèƒ½çš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Trajectory representation learning (TRL) aims to encode raw trajectory data into low-dimensional embeddings for downstream tasks such as travel time estimation, mobility prediction, and trajectory similarity analysis. From a behavioral perspective, a trajectory reflects a sequence of route choices within an urban environment. However, most existing TRL methods ignore this underlying decision-making process and instead treat trajectories as static, passive spatiotemporal sequences, thereby limiting the semantic richness of the learned representations. To bridge this gap, we propose CORE, a TRL framework that integrates context-aware route choice semantics into trajectory embeddings. CORE first incorporates a multi-granular Environment Perception Module, which leverages large language models (LLMs) to distill environmental semantics from point of interest (POI) distributions, thereby constructing a context-enriched road network. Building upon this backbone, CORE employs a Route Choice Encoder with a mixture-of-experts (MoE) architecture, which captures route choice patterns by jointly leveraging the context-enriched road network and navigational factors. Finally, a Transformer encoder aggregates the route-choice-aware representations into a global trajectory embedding. Extensive experiments on 4 real-world datasets across 6 downstream tasks demonstrate that CORE consistently outperforms 12 state-of-the-art TRL methods, achieving an average improvement of 9.79% over the best-performing baseline. Our code is available at https://github.com/caoji2001/CORE.

