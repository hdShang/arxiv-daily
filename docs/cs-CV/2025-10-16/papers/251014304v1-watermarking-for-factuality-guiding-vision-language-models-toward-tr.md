---
layout: default
title: Watermarking for Factuality: Guiding Vision-Language Models Toward Truth via Tri-layer Contrastive Decoding
---

# Watermarking for Factuality: Guiding Vision-Language Models Toward Truth via Tri-layer Contrastive Decoding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.14304" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.14304v1</a>
  <a href="https://arxiv.org/pdf/2510.14304.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.14304v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.14304v1', 'Watermarking for Factuality: Guiding Vision-Language Models Toward Truth via Tri-layer Contrastive Decoding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kyungryul Back, Seongbeom Park, Milim Kim, Mincheol Kwon, SangHyeok Lee, Hyunyoung Lee, Junhee Cho, Seunghyun Park, Jinkyu Kim

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-10-16

**å¤‡æ³¨**: EMNLP 2025 Findings; Project: https://github.com/KR-0822/TCD

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºæ°´å°çš„ä¸‰å±‚å¯¹æ¯”è§£ç æ–¹æ³•ï¼Œæå‡è§†è§‰-è¯­è¨€æ¨¡å‹çš„äº‹å®æ€§å’Œè§†è§‰ groundingã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€æ¨¡å‹` `å¹»è§‰æŠ‘åˆ¶` `å¯¹æ¯”è§£ç ` `è§†è§‰ grounding` `æ°´å°æŠ€æœ¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LVLMsæ˜“äº§ç”Ÿå¹»è§‰ï¼Œè¿‡åº¦ä¾èµ–å•ä¸€æ¨¡æ€æˆ–è®°å¿†æ•°æ®ï¼Œç¼ºä¹æœ‰æ•ˆçš„è§†è§‰ groundingã€‚
2. æå‡ºä¸‰å±‚å¯¹æ¯”è§£ç æ–¹æ³•ï¼Œåˆ©ç”¨æ°´å°ç›¸å…³é—®é¢˜è¯„ä¼°è§†è§‰ groundingï¼ŒæŒ‡å¯¼æ¨¡å‹ç”Ÿæˆæ›´çœŸå®çš„å“åº”ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—å‡å°‘äº†å¹»è§‰ï¼Œæå‡äº†è§†è§‰ grounding æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰åœ¨å„ç§å¤šæ¨¡æ€ä»»åŠ¡ä¸Šå±•ç°å‡ºä»¤äººé¼“èˆçš„ç»“æœï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ç”šè‡³è¾¾åˆ°äº†ä¸äººç±»ç›¸å½“çš„æ€§èƒ½ã€‚ç„¶è€Œï¼ŒLVLMsä»ç„¶å®¹æ˜“äº§ç”Ÿå¹»è§‰â€”â€”å®ƒä»¬å¸¸å¸¸è¿‡åº¦ä¾èµ–å•ä¸€æ¨¡æ€æˆ–è®°å¿†è®­ç»ƒæ•°æ®ï¼Œè€Œæ²¡æœ‰é€‚å½“åœ° grounding å…¶è¾“å‡ºã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„ã€åŸºäºæ°´å°çš„ä¸‰å±‚å¯¹æ¯”è§£ç æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åŒ…æ‹¬ä¸‰ä¸ªæ­¥éª¤ï¼šï¼ˆ1ï¼‰åœ¨è§£ç å±‚ä¸­é€‰æ‹©ä¸€ä¸ªæˆç†Ÿå±‚å’Œä¸€ä¸ªåˆçº§å±‚ï¼›ï¼ˆ2ï¼‰ä½¿ç”¨ä¸æ°´å°ç›¸å…³çš„é—®é¢˜æ¥è¯†åˆ«ä¸€ä¸ªæ”¯ç‚¹å±‚ï¼Œä»¥è¯„ä¼°è¯¥å±‚æ˜¯å¦å…·æœ‰è‰¯å¥½çš„è§†è§‰ groundingï¼›ï¼ˆ3ï¼‰åº”ç”¨ä¸‰å±‚å¯¹æ¯”è§£ç æ¥ç”Ÿæˆæœ€ç»ˆè¾“å‡ºã€‚åœ¨POPEã€MMEå’ŒAMBERç­‰å…¬å…±åŸºå‡†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å‡å°‘LVLMsä¸­çš„å¹»è§‰æ–¹é¢å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶ç”Ÿæˆäº†æ›´å…·æœ‰è§†è§‰ grounding çš„å“åº”ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šLVLMs å®¹æ˜“äº§ç”Ÿå¹»è§‰ï¼Œå³ç”Ÿæˆä¸è¾“å…¥å›¾åƒä¸ç¬¦æˆ–ä¸çœŸå®çš„æ–‡æœ¬å†…å®¹ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆæå‡æ¨¡å‹çš„äº‹å®æ€§å’Œè§†è§‰ grounding èƒ½åŠ›ï¼Œæ¨¡å‹å®¹æ˜“è¿‡åº¦ä¾èµ–è¯­è¨€å…ˆéªŒæˆ–è®°å¿†è®­ç»ƒæ•°æ®ï¼Œå¿½ç•¥è§†è§‰ä¿¡æ¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè¯¥è®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼•å…¥æ°´å°æœºåˆ¶ï¼Œåœ¨è§£ç è¿‡ç¨‹ä¸­è¯†åˆ«å¹¶åˆ©ç”¨å…·æœ‰è‰¯å¥½è§†è§‰ grounding çš„ä¸­é—´å±‚ï¼Œä»è€Œå¼•å¯¼æ¨¡å‹ç”Ÿæˆæ›´ç¬¦åˆäº‹å®çš„å“åº”ã€‚é€šè¿‡å¯¹æ¯”ä¸åŒè§£ç å±‚çš„è¾“å‡ºï¼Œçªå‡ºè§†è§‰ä¿¡æ¯çš„ä½œç”¨ï¼ŒæŠ‘åˆ¶å¹»è§‰çš„äº§ç”Ÿã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•åŒ…å«ä¸‰ä¸ªä¸»è¦æ­¥éª¤ï¼š1) **å±‚é€‰æ‹©**ï¼šåœ¨ LVLM çš„è§£ç å±‚ä¸­é€‰æ‹©ä¸€ä¸ªâ€œæˆç†Ÿå±‚â€ï¼ˆè§£ç èƒ½åŠ›è¾ƒå¼ºï¼‰å’Œä¸€ä¸ªâ€œåˆçº§å±‚â€ï¼ˆè§£ç èƒ½åŠ›è¾ƒå¼±ï¼‰ã€‚2) **æ”¯ç‚¹å±‚è¯†åˆ«**ï¼šä½¿ç”¨ä¸æ°´å°ç›¸å…³çš„é—®é¢˜ï¼ˆä¾‹å¦‚ï¼Œè¯¢é—®å›¾åƒä¸­æ˜¯å¦å­˜åœ¨æ°´å°ï¼‰æ¥è¯„ä¼°æ¯ä¸ªè§£ç å±‚å¯¹è§†è§‰ä¿¡æ¯çš„ç†è§£ç¨‹åº¦ï¼Œé€‰æ‹©ä¸€ä¸ªâ€œæ”¯ç‚¹å±‚â€ï¼Œè¯¥å±‚è¢«è®¤ä¸ºå…·æœ‰è¾ƒå¥½çš„è§†è§‰ groundingã€‚3) **ä¸‰å±‚å¯¹æ¯”è§£ç **ï¼šåˆ©ç”¨æˆç†Ÿå±‚ã€åˆçº§å±‚å’Œæ”¯ç‚¹å±‚çš„è¾“å‡ºï¼Œé€šè¿‡å¯¹æ¯”è§£ç çš„æ–¹å¼ç”Ÿæˆæœ€ç»ˆçš„æ–‡æœ¬å“åº”ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•çš„ä¸»è¦åˆ›æ–°åœ¨äºï¼š1) å¼•å…¥æ°´å°æœºåˆ¶æ¥è¯„ä¼°å’Œé€‰æ‹©å…·æœ‰è‰¯å¥½è§†è§‰ grounding çš„è§£ç å±‚ã€‚2) æå‡ºä¸‰å±‚å¯¹æ¯”è§£ç ç­–ç•¥ï¼Œæœ‰æ•ˆåœ°èåˆä¸åŒè§£ç å±‚çš„ä¼˜åŠ¿ï¼ŒæŠ‘åˆ¶å¹»è§‰çš„äº§ç”Ÿã€‚3) è¯¥æ–¹æ³•æ˜¯ training-free çš„ï¼Œæ— éœ€é¢å¤–çš„è®­ç»ƒæ•°æ®æˆ–å‚æ•°è°ƒæ•´ï¼Œå¯ä»¥ç›´æ¥åº”ç”¨äºç°æœ‰çš„ LVLMsã€‚

**å…³é”®è®¾è®¡**ï¼šå…·ä½“æ¥è¯´ï¼Œæ°´å°ç›¸å…³é—®é¢˜ç”¨äºè¯„ä¼°æ¯ä¸ªè§£ç å±‚è¾“å‡ºçš„ç½®ä¿¡åº¦ï¼Œç½®ä¿¡åº¦æœ€é«˜çš„å±‚è¢«é€‰ä¸ºæ”¯ç‚¹å±‚ã€‚ä¸‰å±‚å¯¹æ¯”è§£ç çš„å…·ä½“å®ç°æ–¹å¼æœªçŸ¥ï¼Œè®ºæ–‡ä¸­å¯èƒ½ä½¿ç”¨äº†æŸç§åŠ æƒå¹³å‡æˆ–é€‰æ‹©æœºåˆ¶æ¥èåˆä¸åŒå±‚çš„è¾“å‡ºã€‚æŸå¤±å‡½æ•°æœªçŸ¥ï¼Œä½†ç›®æ ‡æ˜¯æœ€å¤§åŒ–ç”Ÿæˆæ–‡æœ¬ä¸è§†è§‰ä¿¡æ¯çš„å…³è”æ€§ï¼Œæœ€å°åŒ–å¹»è§‰çš„äº§ç”Ÿã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥æ–¹æ³•åœ¨ POPEã€MME å’Œ AMBER ç­‰å¤šä¸ªå…¬å¼€åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº† state-of-the-art çš„æ€§èƒ½ï¼Œæ˜¾è‘—é™ä½äº† LVLMs çš„å¹»è§‰ç‡ï¼Œå¹¶ç”Ÿæˆäº†æ›´å…·æœ‰è§†è§‰ grounding çš„å“åº”ã€‚å…·ä½“çš„æ€§èƒ½æå‡æ•°æ®æœªçŸ¥ï¼Œä½†æ‘˜è¦ä¸­æ˜ç¡®æŒ‡å‡ºä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºéœ€è¦é«˜å¯é æ€§å’ŒçœŸå®æ€§çš„è§†è§‰-è¯­è¨€ä»»åŠ¡ä¸­ï¼Œä¾‹å¦‚å›¾åƒæè¿°ã€è§†è§‰é—®ç­”ã€æœºå™¨äººå¯¼èˆªã€åŒ»ç–—å½±åƒè¯Šæ–­ç­‰ã€‚é€šè¿‡å‡å°‘ LVLMs çš„å¹»è§‰ï¼Œå¯ä»¥æé«˜è¿™äº›åº”ç”¨çš„å¯ä¿¡åº¦å’Œå®ç”¨æ€§ï¼Œå¹¶ä¸ºæœªæ¥çš„å¤šæ¨¡æ€äººå·¥æ™ºèƒ½ç³»ç»Ÿå¥ å®šåŸºç¡€ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Vision-Language Models (LVLMs) have recently shown promising results on various multimodal tasks, even achieving human-comparable performance in certain cases. Nevertheless, LVLMs remain prone to hallucinations -- they often rely heavily on a single modality or memorize training data without properly grounding their outputs. To address this, we propose a training-free, tri-layer contrastive decoding with watermarking, which proceeds in three steps: (1) select a mature layer and an amateur layer among the decoding layers, (2) identify a pivot layer using a watermark-related question to assess whether the layer is visually well-grounded, and (3) apply tri-layer contrastive decoding to generate the final output. Experiments on public benchmarks such as POPE, MME and AMBER demonstrate that our method achieves state-of-the-art performance in reducing hallucinations in LVLMs and generates more visually grounded responses.

