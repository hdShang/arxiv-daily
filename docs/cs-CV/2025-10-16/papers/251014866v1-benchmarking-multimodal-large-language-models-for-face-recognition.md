---
layout: default
title: Benchmarking Multimodal Large Language Models for Face Recognition
---

# Benchmarking Multimodal Large Language Models for Face Recognition

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.14866" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.14866v1</a>
  <a href="https://arxiv.org/pdf/2510.14866.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.14866v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.14866v1', 'Benchmarking Multimodal Large Language Models for Face Recognition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hatef Otroshi Shahreza, SÃ©bastien Marcel

**åˆ†ç±»**: cs.CV, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-10-16

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç³»ç»Ÿæ€§è¯„æµ‹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨äººè„¸è¯†åˆ«ä»»åŠ¡ä¸Šçš„æ€§èƒ½è¡¨ç°ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `äººè„¸è¯†åˆ«` `åŸºå‡†æµ‹è¯•` `é›¶æ ·æœ¬å­¦ä¹ ` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ç¼ºä¹å¯¹å¼€æºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨äººè„¸è¯†åˆ«ä»»åŠ¡ä¸Šçš„ç³»ç»Ÿæ€§è¯„ä¼°ã€‚
2. æœ¬æ–‡é€šè¿‡åŸºå‡†æµ‹è¯•ï¼Œæ¢ç´¢MLLMåœ¨äººè„¸è¯†åˆ«ä¸­çš„æ½œåŠ›ï¼Œå¹¶åˆ†æå…¶ä¼˜ç¼ºç‚¹ã€‚
3. å®éªŒè¡¨æ˜MLLMèƒ½æ•æ‰è¯­ä¹‰ä¿¡æ¯ï¼Œä½†åœ¨é«˜ç²¾åº¦äººè„¸è¯†åˆ«ä¸­æ€§èƒ½ä¸å¦‚ä¸“ç”¨æ¨¡å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLM)åœ¨å„ç§è§†è§‰-è¯­è¨€ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œå®ƒä»¬åœ¨äººè„¸è¯†åˆ«æ–¹é¢çš„æ½œåŠ›ä»æœªè¢«å……åˆ†æ¢ç´¢ã€‚ç‰¹åˆ«æ˜¯ï¼Œéœ€è¦è¯„ä¼°å¼€æºMLLMçš„æ€§èƒ½ï¼Œå¹¶å°†å…¶ä¸å…·æœ‰ç±»ä¼¼åè®®çš„æ ‡å‡†åŸºå‡†ä¸Šç°æœ‰çš„é¢éƒ¨è¯†åˆ«æ¨¡å‹è¿›è¡Œæ¯”è¾ƒã€‚æœ¬æ–‡å¯¹æœ€å…ˆè¿›çš„MLLMåœ¨å¤šä¸ªäººè„¸è¯†åˆ«æ•°æ®é›†ï¼ˆåŒ…æ‹¬LFWã€CALFWã€CPLFWã€CFPã€AgeDBå’ŒRFWï¼‰ä¸Šè¿›è¡Œäº†ç³»ç»Ÿçš„äººè„¸è¯†åˆ«åŸºå‡†æµ‹è¯•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè™½ç„¶MLLMæ•è·äº†å¯¹äººè„¸ç›¸å…³ä»»åŠ¡æœ‰ç”¨çš„ä¸°å¯Œè¯­ä¹‰çº¿ç´¢ï¼Œä½†åœ¨é›¶æ ·æœ¬åº”ç”¨çš„é«˜ç²¾åº¦è¯†åˆ«åœºæ™¯ä¸­ï¼Œå®ƒä»¬è½åäºä¸“ç”¨æ¨¡å‹ã€‚è¯¥åŸºå‡†ä¸ºæ¨è¿›åŸºäºMLLMçš„äººè„¸è¯†åˆ«å¥ å®šäº†åŸºç¡€ï¼Œä¸ºè®¾è®¡å…·æœ‰æ›´é«˜ç²¾åº¦å’Œæ³›åŒ–èƒ½åŠ›çš„ä¸‹ä¸€ä»£æ¨¡å‹æä¾›äº†è§è§£ã€‚æˆ‘ä»¬çš„åŸºå‡†æµ‹è¯•çš„æºä»£ç å·²åœ¨é¡¹ç›®é¡µé¢ä¸­å…¬å¼€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨äººè„¸è¯†åˆ«ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚ç°æœ‰çš„äººè„¸è¯†åˆ«ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨ä¸“é—¨è®¾è®¡çš„æ¨¡å‹ä¸Šï¼Œè€Œå¿½ç•¥äº†MLLMsçš„æ½œåŠ›ã€‚æ­¤å¤–ï¼Œç¼ºä¹é’ˆå¯¹MLLMsåœ¨äººè„¸è¯†åˆ«é¢†åŸŸè¿›è¡Œç³»ç»Ÿæ€§è¯„ä¼°çš„åŸºå‡†æµ‹è¯•ï¼Œè¿™ä½¿å¾—éš¾ä»¥äº†è§£å®ƒä»¬çš„ä¼˜åŠ¿å’Œå±€é™æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å»ºç«‹ä¸€ä¸ªåŸºå‡†æµ‹è¯•ï¼Œç”¨äºè¯„ä¼°ç°æœ‰æœ€å…ˆè¿›çš„MLLMsåœ¨æ ‡å‡†äººè„¸è¯†åˆ«æ•°æ®é›†ä¸Šçš„æ€§èƒ½ã€‚é€šè¿‡å°†MLLMsçš„æ€§èƒ½ä¸ä¸“é—¨çš„äººè„¸è¯†åˆ«æ¨¡å‹è¿›è¡Œæ¯”è¾ƒï¼Œå¯ä»¥ç¡®å®šMLLMsåœ¨äººè„¸è¯†åˆ«ä»»åŠ¡ä¸­çš„ä¼˜åŠ¿å’ŒåŠ£åŠ¿ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æ–¹å‘æä¾›æŒ‡å¯¼ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥ç ”ç©¶çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1) é€‰æ‹©ä¸€ç³»åˆ—å…·æœ‰ä»£è¡¨æ€§çš„äººè„¸è¯†åˆ«æ•°æ®é›†ï¼Œå¦‚LFWã€CALFWã€CPLFWç­‰ï¼›2) é€‰æ‹©å½“å‰æœ€å…ˆè¿›çš„MLLMsä½œä¸ºè¯„ä¼°å¯¹è±¡ï¼›3) è®¾è®¡å®éªŒæ–¹æ¡ˆï¼ŒåŒ…æ‹¬é›¶æ ·æœ¬è®¾ç½®ç­‰ï¼›4) ä½¿ç”¨é€‰å®šçš„æ•°æ®é›†å’ŒMLLMsè¿›è¡Œå®éªŒï¼Œå¹¶è®°å½•å®éªŒç»“æœï¼›5) åˆ†æå®éªŒç»“æœï¼Œæ¯”è¾ƒä¸åŒMLLMsçš„æ€§èƒ½ï¼Œå¹¶ä¸ä¸“é—¨çš„äººè„¸è¯†åˆ«æ¨¡å‹è¿›è¡Œæ¯”è¾ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶çš„å…³é”®åˆ›æ–°åœ¨äºé¦–æ¬¡å¯¹ä¸€ç³»åˆ—æœ€å…ˆè¿›çš„MLLMsåœ¨äººè„¸è¯†åˆ«ä»»åŠ¡ä¸Šè¿›è¡Œäº†ç³»ç»Ÿæ€§çš„åŸºå‡†æµ‹è¯•ã€‚è¿™ä¸ºç ”ç©¶äººå‘˜æä¾›äº†ä¸€ä¸ªäº†è§£MLLMsåœ¨äººè„¸è¯†åˆ«é¢†åŸŸèƒ½åŠ›çš„å¹³å°ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æ–¹å‘æä¾›äº†æŒ‡å¯¼ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜æ­ç¤ºäº†MLLMsåœ¨æ•æ‰äººè„¸ç›¸å…³è¯­ä¹‰ä¿¡æ¯æ–¹é¢çš„æ½œåŠ›ï¼Œä»¥åŠåœ¨é«˜ç²¾åº¦è¯†åˆ«æ–¹é¢çš„å±€é™æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šå®éªŒé‡‡ç”¨é›¶æ ·æœ¬è®¾ç½®ï¼Œå³MLLMsæ²¡æœ‰åœ¨ç‰¹å®šçš„äººè„¸è¯†åˆ«æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒã€‚è¯„ä¼°æŒ‡æ ‡ä¸»è¦åŒ…æ‹¬è¯†åˆ«å‡†ç¡®ç‡ç­‰ã€‚ç ”ç©¶ä¸­æ²¡æœ‰æ¶‰åŠå¯¹MLLMç»“æ„æˆ–è®­ç»ƒæ–¹å¼çš„ä¿®æ”¹ï¼Œè€Œæ˜¯ç›´æ¥ä½¿ç”¨é¢„è®­ç»ƒçš„MLLMsè¿›è¡Œè¯„ä¼°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒMLLMsèƒ½å¤Ÿæ•æ‰åˆ°äººè„¸ç›¸å…³çš„è¯­ä¹‰ä¿¡æ¯ï¼Œä½†åœ¨é«˜ç²¾åº¦äººè„¸è¯†åˆ«ä»»åŠ¡ä¸­ï¼Œå…¶æ€§èƒ½ä»ç„¶è½åäºä¸“é—¨è®¾è®¡çš„æ¨¡å‹ã€‚ä¾‹å¦‚ï¼Œåœ¨LFWæ•°æ®é›†ä¸Šï¼ŒMLLMsçš„è¯†åˆ«å‡†ç¡®ç‡ä¸æœ€å…ˆè¿›çš„äººè„¸è¯†åˆ«æ¨¡å‹ç›¸æ¯”ä»æœ‰å·®è·ã€‚è¯¥åŸºå‡†æµ‹è¯•ä¸ºæœªæ¥æ”¹è¿›MLLMåœ¨äººè„¸è¯†åˆ«æ–¹é¢çš„æ€§èƒ½æä¾›äº†é‡è¦çš„å‚è€ƒã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å®‰å…¨ç›‘æ§ã€èº«ä»½éªŒè¯ã€ç¤¾äº¤åª’ä½“åˆ†æç­‰ã€‚é€šè¿‡æå‡MLLMåœ¨äººè„¸è¯†åˆ«æ–¹é¢çš„æ€§èƒ½ï¼Œå¯ä»¥å®ç°æ›´æ™ºèƒ½ã€æ›´é«˜æ•ˆçš„äººè„¸è¯†åˆ«ç³»ç»Ÿã€‚æœªæ¥çš„å½±å“åœ¨äºæ¨åŠ¨å¤šæ¨¡æ€äººå·¥æ™ºèƒ½çš„å‘å±•ï¼Œå°†è§†è§‰å’Œè¯­è¨€ä¿¡æ¯èåˆï¼Œå®ç°æ›´å¼ºå¤§çš„æ™ºèƒ½åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal large language models (MLLMs) have achieved remarkable performance across diverse vision-and-language tasks. However, their potential in face recognition remains underexplored. In particular, the performance of open-source MLLMs needs to be evaluated and compared with existing face recognition models on standard benchmarks with similar protocol. In this work, we present a systematic benchmark of state-of-the-art MLLMs for face recognition on several face recognition datasets, including LFW, CALFW, CPLFW, CFP, AgeDB and RFW. Experimental results reveal that while MLLMs capture rich semantic cues useful for face-related tasks, they lag behind specialized models in high-precision recognition scenarios in zero-shot applications. This benchmark provides a foundation for advancing MLLM-based face recognition, offering insights for the design of next-generation models with higher accuracy and generalization. The source code of our benchmark is publicly available in the project page.

