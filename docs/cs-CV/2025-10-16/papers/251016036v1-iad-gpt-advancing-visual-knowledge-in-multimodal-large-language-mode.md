---
layout: default
title: IAD-GPT: Advancing Visual Knowledge in Multimodal Large Language Model for Industrial Anomaly Detection
---

# IAD-GPT: Advancing Visual Knowledge in Multimodal Large Language Model for Industrial Anomaly Detection

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.16036" target="_blank" class="toolbar-btn">arXiv: 2510.16036v1</a>
    <a href="https://arxiv.org/pdf/2510.16036.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.16036v1" 
            onclick="toggleFavorite(this, '2510.16036v1', 'IAD-GPT: Advancing Visual Knowledge in Multimodal Large Language Model for Industrial Anomaly Detection')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Zewen Li, Zitong Yu, Qilang Ye, Weicheng Xie, Wei Zhuo, Linlin Shen

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-16

**Â§áÊ≥®**: Accepted by IEEE Transactions on Instrumentation and Measurement (TIM)

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/LiZeWen1225/IAD-GPT)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫IAD-GPTÔºåÂà©Áî®Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊèêÂçáÂ∑•‰∏öÂºÇÂ∏∏Ê£ÄÊµãÁöÑËßÜËßâÁü•ËØÜ„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â∑•‰∏öÂºÇÂ∏∏Ê£ÄÊµã` `Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã` `ËßÜËßâËØ≠Ë®ÄÊ®°Âûã` `ÂºÇÂ∏∏ÊèêÁ§∫ÁîüÊàê` `ÊñáÊú¨ÂºïÂØºÂ¢ûÂº∫` `ÂÉèÁ¥†Á∫ßÂºÇÂ∏∏Ê£ÄÊµã`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ‰º†ÁªüÂ∑•‰∏öÂºÇÂ∏∏Ê£ÄÊµãÊñπÊ≥ïÁº∫‰πèÂ§öËΩÆ‰∫§‰∫íÂíåÁªÜÁ≤íÂ∫¶ÊèèËø∞ËÉΩÂäõÔºåÈôêÂà∂‰∫ÜÂÖ∂Â∫îÁî®ËåÉÂõ¥„ÄÇ
2. IAD-GPTÂà©Áî®ÂºÇÂ∏∏ÊèêÁ§∫ÁîüÊàêÂô®ÂíåÊñáÊú¨ÂºïÂØºÂ¢ûÂº∫Âô®ÔºåÊèêÂçáMLLMÂØπÂºÇÂ∏∏ÁöÑÊ£ÄÊµãÂíåÂàÜÂâ≤ËÉΩÂäõ„ÄÇ
3. Âú®MVTec-ADÂíåVisAÊï∞ÊçÆÈõÜ‰∏äÔºåIAD-GPTÂú®Ëá™ÁõëÁù£ÂíåÂ∞ëÊ†∑Êú¨ÂºÇÂ∏∏Ê£ÄÊµã‰ªªÂä°‰∏≠ÂèñÂæó‰∫ÜSOTAÊÄßËÉΩ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMÔºâÂº∫Â§ßÁöÑÂõ†ÊûúËÉΩÂäõ‰ΩøÂÖ∂Âú®Â∑•‰∏öÂºÇÂ∏∏Ê£ÄÊµãÔºàIADÔºâ‰∏≠Ê£ÄÊµãÁº∫Èô∑Áâ©‰ΩìÂÖ∑ÊúâÊΩúÂäõ„ÄÇÁÑ∂ËÄåÔºå‰º†ÁªüIADÊñπÊ≥ïÁº∫‰πèÂ§öËΩÆ‰∫∫Êú∫ÂØπËØùÂíåËØ¶ÁªÜÊèèËø∞ËÉΩÂäõÔºå‰æãÂ¶ÇÁâ©‰ΩìÈ¢úËâ≤„ÄÅÂºÇÂ∏∏ÂΩ¢Áä∂ÊàñÁâπÂÆöÂºÇÂ∏∏Á±ªÂûã„ÄÇÂêåÊó∂ÔºåÂü∫‰∫éÂ§ßÂûãÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãÁöÑÊñπÊ≥ïÂ∞öÊú™ÂÖÖÂàÜÊøÄÂèëÂ§ßÊ®°ÂûãÂú®ÂºÇÂ∏∏Ê£ÄÊµã‰ªªÂä°‰∏≠ÁöÑËÉΩÂäõ„ÄÇÊú¨ÊñáÊé¢Á¥¢‰∫Ü‰∏∞ÂØåÁöÑÊñáÊú¨ËØ≠‰πâ‰∏éÂõæÂÉèÁ∫ßÂíåÂÉèÁ¥†Á∫ß‰ø°ÊÅØÁöÑÁªìÂêàÔºåÊèêÂá∫‰∫ÜIAD-GPTÔºå‰∏ÄÁßçÂü∫‰∫éMLLMÁöÑIADÊñ∞ËåÉÂºè„ÄÇÊàë‰ª¨ÈááÁî®ÂºÇÂ∏∏ÊèêÁ§∫ÁîüÊàêÂô®ÔºàAPGÔºâ‰∏∫ÁâπÂÆöÂØπË±°ÁîüÊàêËØ¶ÁªÜÁöÑÂºÇÂ∏∏ÊèêÁ§∫„ÄÇÊù•Ëá™Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑËøô‰∫õÁâπÂÆöÊèêÁ§∫Áî®‰∫éÊøÄÊ¥ªÈ¢ÑËÆ≠ÁªÉËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÔºàÂç≥CLIPÔºâÁöÑÊ£ÄÊµãÂíåÂàÜÂâ≤ÂäüËÉΩ„ÄÇ‰∏∫‰∫ÜÂ¢ûÂº∫MLLMÁöÑËßÜËßâÂÆö‰ΩçËÉΩÂäõÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜÊñáÊú¨ÂºïÂØºÂ¢ûÂº∫Âô®ÔºåÂÖ∂‰∏≠ÂõæÂÉèÁâπÂæÅ‰∏éÊ≠£Â∏∏ÂíåÂºÇÂ∏∏ÊñáÊú¨ÊèêÁ§∫‰∫§‰∫íÔºå‰ª•Âä®ÊÄÅÈÄâÊã©Â¢ûÂº∫Ë∑ØÂæÑÔºå‰ΩøËØ≠Ë®ÄÊ®°ÂûãËÉΩÂ§ü‰∏ìÊ≥®‰∫éËßÜËßâÊï∞ÊçÆÁöÑÁâπÂÆöÊñπÈù¢Ôºå‰ªéËÄåÂ¢ûÂº∫ÂÖ∂ÂáÜÁ°ÆËß£ÈáäÂíåÂìçÂ∫îÂõæÂÉè‰∏≠ÂºÇÂ∏∏ÁöÑËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ËÆæËÆ°‰∫Ü‰∏Ä‰∏™Â§öÊé©Á†ÅËûçÂêàÊ®°ÂùóÔºåÂ∞ÜÊé©Á†Å‰Ωú‰∏∫‰∏ìÂÆ∂Áü•ËØÜÁ∫≥ÂÖ•ÂÖ∂‰∏≠Ôºå‰ªéËÄåÂ¢ûÂº∫LLMÂØπÂÉèÁ¥†Á∫ßÂºÇÂ∏∏ÁöÑÊÑüÁü•„ÄÇÂú®MVTec-ADÂíåVisAÊï∞ÊçÆÈõÜ‰∏äÁöÑÂ§ßÈáèÂÆûÈ™åËØÅÊòé‰∫ÜÊàë‰ª¨Âú®Ëá™ÁõëÁù£ÂíåÂ∞ëÊ†∑Êú¨ÂºÇÂ∏∏Ê£ÄÊµãÂíåÂàÜÂâ≤‰ªªÂä°‰∏äÁöÑÊúÄÂÖàËøõÊÄßËÉΩ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÂ∑•‰∏öÂºÇÂ∏∏Ê£ÄÊµãÊó®Âú®Ëá™Âä®ËØÜÂà´‰∫ßÂìÅË°®Èù¢ÁöÑÁº∫Èô∑Ôºå‰º†ÁªüÊñπÊ≥ïÈöæ‰ª•Êèê‰æõËØ¶ÁªÜÁöÑÂºÇÂ∏∏ÊèèËø∞ÂíåÂ§öËΩÆ‰∫§‰∫íÔºåÂêåÊó∂Áé∞ÊúâÂü∫‰∫éÂ§ßÊ®°ÂûãÁöÑÂºÇÂ∏∏Ê£ÄÊµãÊñπÊ≥ïÊú™ËÉΩÂÖÖÂàÜÂà©Áî®Â§ßÊ®°ÂûãÁöÑÊΩúÂäõÔºåÂ∞§ÂÖ∂ÊòØÂú®ËßÜËßâÂÆö‰ΩçÂíåÂÉèÁ¥†Á∫ßÁêÜËß£ÊñπÈù¢„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÂà©Áî®Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMÔºâÁöÑÂº∫Â§ßËØ≠‰πâÁêÜËß£ËÉΩÂäõÔºåÁªìÂêàÂõæÂÉèÁ∫ßÂíåÂÉèÁ¥†Á∫ß‰ø°ÊÅØÔºåÂÆûÁé∞Êõ¥Á≤æÁ°Æ„ÄÅÂèØËß£ÈáäÁöÑÂºÇÂ∏∏Ê£ÄÊµã„ÄÇÈÄöËøáÁîüÊàêÂºÇÂ∏∏ÊèêÁ§∫ÔºåÂºïÂØºÊ®°ÂûãÂÖ≥Ê≥®ÂõæÂÉè‰∏≠ÁöÑÂºÇÂ∏∏Âå∫ÂüüÔºåÂπ∂Âà©Áî®ÊñáÊú¨‰ø°ÊÅØÂ¢ûÂº∫Ê®°ÂûãÁöÑËßÜËßâÂÆö‰ΩçËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöIAD-GPTÂåÖÂê´‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÂºÇÂ∏∏ÊèêÁ§∫ÁîüÊàêÂô®ÔºàAPGÔºâ„ÄÅÊñáÊú¨ÂºïÂØºÂ¢ûÂº∫Âô®ÔºàText-Guided EnhancerÔºâÂíåÂ§öÊé©Á†ÅËûçÂêàÊ®°ÂùóÔºàMulti-Mask FusionÔºâ„ÄÇAPGÁîüÊàêËØ¶ÁªÜÁöÑÂºÇÂ∏∏ÊèêÁ§∫ÔºåÁî®‰∫éÊøÄÊ¥ªCLIPÊ®°ÂûãÁöÑÊ£ÄÊµãÂíåÂàÜÂâ≤ÂäüËÉΩ„ÄÇÊñáÊú¨ÂºïÂØºÂ¢ûÂº∫Âô®ÈÄöËøáÂõæÂÉèÁâπÂæÅ‰∏éÊñáÊú¨ÊèêÁ§∫ÁöÑ‰∫§‰∫íÔºåÂä®ÊÄÅÈÄâÊã©Â¢ûÂº∫Ë∑ØÂæÑÔºåÊèêÂçáËßÜËßâÂÆö‰ΩçËÉΩÂäõ„ÄÇÂ§öÊé©Á†ÅËûçÂêàÊ®°ÂùóÂ∞ÜÊé©Á†Å‰ø°ÊÅØ‰Ωú‰∏∫‰∏ìÂÆ∂Áü•ËØÜÔºåÂ¢ûÂº∫Ê®°ÂûãÂØπÂÉèÁ¥†Á∫ßÂºÇÂ∏∏ÁöÑÊÑüÁü•„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**Ôºö1. ÊèêÂá∫ÂºÇÂ∏∏ÊèêÁ§∫ÁîüÊàêÂô®ÔºåÂà©Áî®LLMÁîüÊàêÈíàÂØπÁâπÂÆöÂØπË±°ÁöÑËØ¶ÁªÜÂºÇÂ∏∏ÊèèËø∞ÔºåÂºïÂØºÊ®°ÂûãÂÖ≥Ê≥®ÂºÇÂ∏∏Âå∫Âüü„ÄÇ2. ÊèêÂá∫ÊñáÊú¨ÂºïÂØºÂ¢ûÂº∫Âô®ÔºåÈÄöËøáÊñáÊú¨‰ø°ÊÅØÂä®ÊÄÅÂ¢ûÂº∫ÂõæÂÉèÁâπÂæÅÔºåÊèêÂçáËßÜËßâÂÆö‰ΩçËÉΩÂäõ„ÄÇ3. ËÆæËÆ°Â§öÊé©Á†ÅËûçÂêàÊ®°ÂùóÔºåÂ∞ÜÊé©Á†Å‰ø°ÊÅØ‰Ωú‰∏∫‰∏ìÂÆ∂Áü•ËØÜÔºåÂ¢ûÂº∫Ê®°ÂûãÂØπÂÉèÁ¥†Á∫ßÂºÇÂ∏∏ÁöÑÊÑüÁü•„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂºÇÂ∏∏ÊèêÁ§∫ÁîüÊàêÂô®‰ΩøÁî®LLMÁîüÊàêÂåÖÂê´ÂºÇÂ∏∏Á±ªÂûã„ÄÅÂΩ¢Áä∂„ÄÅÈ¢úËâ≤Á≠â‰ø°ÊÅØÁöÑÊèêÁ§∫„ÄÇÊñáÊú¨ÂºïÂØºÂ¢ûÂº∫Âô®‰ΩøÁî®Ê≥®ÊÑèÂäõÊú∫Âà∂ÔºåÊ†πÊçÆÊñáÊú¨ÊèêÁ§∫Âä®ÊÄÅÈÄâÊã©ÂõæÂÉèÁâπÂæÅÁöÑÂ¢ûÂº∫Ë∑ØÂæÑ„ÄÇÂ§öÊé©Á†ÅËûçÂêàÊ®°ÂùóÂ∞Ü‰∏çÂêåÂ∞∫Â∫¶ÁöÑÊé©Á†Å‰ø°ÊÅØËûçÂêàÔºåÊèê‰æõÊõ¥ÂÖ®Èù¢ÁöÑÂÉèÁ¥†Á∫ßÂºÇÂ∏∏‰ø°ÊÅØ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

IAD-GPTÂú®MVTec-ADÂíåVisAÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇÂú®Ëá™ÁõëÁù£ÂºÇÂ∏∏Ê£ÄÊµã‰ªªÂä°‰∏≠ÔºåIAD-GPTÁöÑÊÄßËÉΩ‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÂπ∂Âú®Â∞ëÊ†∑Êú¨ÂºÇÂ∏∏Ê£ÄÊµã‰ªªÂä°‰∏≠‰πüË°®Áé∞Âá∫Âº∫Â§ßÁöÑÁ´û‰∫âÂäõ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåIAD-GPTËÉΩÂ§üÊúâÊïàÂú∞Âà©Áî®Â§öÊ®°ÊÄÅ‰ø°ÊÅØÔºåÊèêÂçáÂºÇÂ∏∏Ê£ÄÊµãÁöÑÂáÜÁ°ÆÊÄßÂíåÂèØËß£ÈáäÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

IAD-GPTÂèØÂ∫îÁî®‰∫éÂêÑÁßçÂ∑•‰∏öÁîü‰∫ßÁ∫øÁöÑË¥®ÈáèÊ£ÄÊµãÁéØËäÇÔºå‰æãÂ¶ÇÁîµÂ≠êÂÖÉ‰ª∂„ÄÅÁ∫∫ÁªáÂìÅ„ÄÅÊ±ΩËΩ¶Èõ∂ÈÉ®‰ª∂Á≠â„ÄÇËØ•ÊñπÊ≥ïËÉΩÂ§üËá™Âä®Ê£ÄÊµã‰∫ßÂìÅË°®Èù¢ÁöÑÁº∫Èô∑ÔºåÂπ∂Êèê‰æõËØ¶ÁªÜÁöÑÂºÇÂ∏∏ÊèèËø∞ÔºåÊúâÂä©‰∫éÊèêÈ´òÁîü‰∫ßÊïàÁéáÂíå‰∫ßÂìÅË¥®ÈáèÔºåÈôç‰Ωé‰∫∫Â∑•Ê£ÄÊµãÊàêÊú¨„ÄÇÊú™Êù•ÂèØÊâ©Â±ïÂà∞ÂåªÁñóÂΩ±ÂÉèÂàÜÊûê„ÄÅÈÅ•ÊÑüÂõæÂÉèÂàÜÊûêÁ≠âÈ¢ÜÂüü„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> The robust causal capability of Multimodal Large Language Models (MLLMs) hold the potential of detecting defective objects in Industrial Anomaly Detection (IAD). However, most traditional IAD methods lack the ability to provide multi-turn human-machine dialogues and detailed descriptions, such as the color of objects, the shape of an anomaly, or specific types of anomalies. At the same time, methods based on large pre-trained models have not fully stimulated the ability of large models in anomaly detection tasks. In this paper, we explore the combination of rich text semantics with both image-level and pixel-level information from images and propose IAD-GPT, a novel paradigm based on MLLMs for IAD. We employ Abnormal Prompt Generator (APG) to generate detailed anomaly prompts for specific objects. These specific prompts from the large language model (LLM) are used to activate the detection and segmentation functions of the pre-trained visual-language model (i.e., CLIP). To enhance the visual grounding ability of MLLMs, we propose Text-Guided Enhancer, wherein image features interact with normal and abnormal text prompts to dynamically select enhancement pathways, which enables language models to focus on specific aspects of visual data, enhancing their ability to accurately interpret and respond to anomalies within images. Moreover, we design a Multi-Mask Fusion module to incorporate mask as expert knowledge, which enhances the LLM's perception of pixel-level anomalies. Extensive experiments on MVTec-AD and VisA datasets demonstrate our state-of-the-art performance on self-supervised and few-shot anomaly detection and segmentation tasks, such as MVTec-AD and VisA datasets. The codes are available at \href{https://github.com/LiZeWen1225/IAD-GPT}{https://github.com/LiZeWen1225/IAD-GPT}.

