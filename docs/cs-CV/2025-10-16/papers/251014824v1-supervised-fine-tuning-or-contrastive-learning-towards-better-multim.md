---
layout: default
title: Supervised Fine-Tuning or Contrastive Learning? Towards Better Multimodal LLM Reranking
---

# Supervised Fine-Tuning or Contrastive Learning? Towards Better Multimodal LLM Reranking

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.14824" target="_blank" class="toolbar-btn">arXiv: 2510.14824v1</a>
    <a href="https://arxiv.org/pdf/2510.14824.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.14824v1" 
            onclick="toggleFavorite(this, '2510.14824v1', 'Supervised Fine-Tuning or Contrastive Learning? Towards Better Multimodal LLM Reranking')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Ziqi Dai, Xin Zhang, Mingxin Li, Yanzhao Zhang, Dingkun Long, Pengjun Xie, Meishan Zhang, Wenjie Li, Min Zhang

**ÂàÜÁ±ª**: cs.CL, cs.CV, cs.IR

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-16

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÈíàÂØπÂ§öÊ®°ÊÄÅLLMÈáçÊéíÂ∫èÔºåÂØπÊØîÁõëÁù£ÂæÆË∞É‰∏éÂØπÊØîÂ≠¶‰π†ÁöÑ‰ºòÂä£**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅÊ£ÄÁ¥¢` `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `ÈáçÊéíÂ∫è` `ÂØπÊØîÂ≠¶‰π†` `ÁõëÁù£ÂæÆË∞É` `‰ø°ÊÅØÊ£ÄÁ¥¢` `ÊùÉÈáçÂàÜÊûê` `ÊñπÂêëÂàÜÊûê`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂü∫‰∫éLLMÁöÑÈáçÊéíÂ∫èÊ®°ÂûãËÆ≠ÁªÉÊñπÊ≥ïÈÄâÊã©Â≠òÂú®‰∫âËÆÆÔºåÂØπÊØîÂ≠¶‰π†ÂíåÁõëÁù£ÂæÆË∞ÉÂ≠∞‰ºòÂ≠∞Âä£Â∞ö‰∏çÊòéÁ°Æ„ÄÇ
2. ËÆ∫ÊñáÂ∞ÜËÆ≠ÁªÉÁõÆÊ†áÂàÜËß£‰∏∫ÊùÉÈáçÂíåÊñπÂêë‰∏§‰∏™ÁªÑÊàêÈÉ®ÂàÜÔºåÊèêÂá∫‰∫Ü‰∏Ä‰∏™Áªü‰∏ÄÁöÑÊ°ÜÊû∂Êù•ÂàÜÊûêÂØπÊØîÂ≠¶‰π†ÂíåÁõëÁù£ÂæÆË∞ÉÁöÑ‰∫§‰∫í„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÁõëÁù£ÂæÆË∞ÉÂú®LLMÈáçÊéíÂ∫è‰∏≠ÂÖ∑Êúâ‰ºòÂäøÔºåÂπ∂Âú®MRBÂü∫ÂáÜÊµãËØï‰∏≠ÂèñÂæó‰∫ÜÊñ∞ÁöÑstate-of-the-artÁªìÊûú„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Âú®‰ø°ÊÅØÊ£ÄÁ¥¢‰∏≠ÔºåÈáçÊéíÂ∫èÊ®°ÂûãÁöÑËÆ≠ÁªÉ‰∏ªË¶ÅÈõÜ‰∏≠‰∫é‰∏§ÁßçÁõÆÊ†áÔºöÂ∫¶ÈáèÂ≠¶‰π†Ôºà‰æãÂ¶ÇÔºå‰ΩøÁî®ÂØπÊØîÊçüÂ§±Êù•Â¢ûÂä†Áõ∏ÂÖ≥Êü•ËØ¢-ÊñáÊ°£ÂØπÁöÑÈ¢ÑÊµãÂàÜÊï∞ÔºâÂíåÂàÜÁ±ªÔºàÂØπÁõ∏ÂÖ≥‰∏é‰∏çÁõ∏ÂÖ≥ÁöÑ‰∫åÂÖÉÊ†áÁ≠æËøõË°åÈ¢ÑÊµãÔºâ„ÄÇÂØπ‰∫éBERTÈ£éÊ†ºÁöÑÁºñÁ†ÅÂô®ÔºåÂ§ßÈáèÁ†îÁ©∂Ë°®ÊòéÂØπÊØîÂ≠¶‰π†ÔºàCLÔºâÊØîÂà§Âà´ÂºèÔºàÂàÜÁ±ªÔºâÂ≠¶‰π†Êõ¥ÊúâÊïà„ÄÇÁÑ∂ËÄåÔºåÂØπ‰∫éÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÔºåÈÄöËøáÁõëÁù£ÂæÆË∞ÉÔºàSFTÔºâËøõË°åÂàÜÁ±ªÔºåÂç≥È¢ÑÊµãÁõ∏ÂÖ≥ÔºàÊàñ‰∏çÁõ∏ÂÖ≥ÔºâÂØπÁöÑ‚ÄúÊòØ‚ÄùÔºàÊàñ‚ÄúÂê¶‚ÄùÔºâtokenÔºå‰ºº‰πéÊõ¥ÊúâÂâçÊôØÔºåÂõ†‰∏∫ÂÆÉ‰∏éLLMÁöÑÁîüÊàêÁâπÊÄßÈùûÂ∏∏ÂêªÂêà„ÄÇËøôÁßçÂ∑ÆÂºÇÊèêÂá∫‰∫Ü‰∏Ä‰∏™Ê†∏ÂøÉÈóÆÈ¢òÔºöÂì™ÁßçÁõÆÊ†áÊõ¥ÈÄÇÂêàÂü∫‰∫éLLMÁöÑÈáçÊéíÂ∫èÔºüÂÖ∂Â∑ÆÂºÇÁöÑÊΩúÂú®Êú∫Âà∂ÊòØ‰ªÄ‰πàÔºüÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨ÂØπCLÂíåSFTÂú®ÈáçÊéíÂ∫èÊñπÈù¢ËøõË°å‰∫ÜÂÖ®Èù¢ÁöÑÊØîËæÉÂíåÂàÜÊûêÔºåÂπ∂Â∞ÜÈÄöÁî®Â§öÊ®°ÊÄÅÊ£ÄÁ¥¢ÔºàUMRÔºâ‰Ωú‰∏∫ÂÆûÈ™åÂπ≥Âè∞„ÄÇÊàë‰ª¨È¶ñÂÖàÂ∞ÜÁõÆÊ†áÂàÜËß£‰∏∫‰∏§‰∏™ÁªÑÊàêÈÉ®ÂàÜÔºöÊùÉÈáçÔºàÊéßÂà∂Êõ¥Êñ∞ÂπÖÂ∫¶ÔºâÂíåÊñπÂêëÔºàÊåáÂØºÊ®°ÂûãÊõ¥Êñ∞ÔºâÔºåÁÑ∂ÂêéÊèêÂá∫‰∫Ü‰∏Ä‰∏™Áªü‰∏ÄÁöÑÊ°ÜÊû∂Êù•ÁêÜËß£ÂÆÉ‰ª¨ÁöÑÁõ∏‰∫í‰ΩúÁî®„ÄÇÈÄöËøáÊé¢ÊµãÂÆûÈ™åÔºåÊàë‰ª¨ÂèëÁé∞SFTÊèê‰æõ‰∫ÜÊØîCLÊõ¥Âº∫ÁöÑÂä†ÊùÉÊñπÊ°àÔºåËÄåÈ¶ñÈÄâÁöÑËØÑÂàÜÊñπÂêëÊ≤°ÊúâÊòéÊòæÁöÑËµ¢ÂÆ∂„ÄÇÊÄªËÄåË®Ä‰πãÔºåËøô‰∫õÁªìÊûúË°®ÊòéSFTÂú®LLMÈáçÊéíÂ∫èÊñπÈù¢ÂÖ∑Êúâ‰∏ÄËá¥ÁöÑ‰ºòÂäø„ÄÇ‰∏∫‰∫ÜËøõ‰∏ÄÊ≠•È™åËØÅÊàë‰ª¨ÁöÑÂèëÁé∞ÔºåÊàë‰ª¨‰ΩøÁî®SFTËøõË°å‰∫ÜÂ§ßËßÑÊ®°ËÆ≠ÁªÉÔºåÂπ∂Âú®MRBÂü∫ÂáÜÊµãËØï‰∏≠ÊèêÂá∫‰∫ÜÊñ∞ÁöÑÊúÄÂÖàËøõÁöÑÈáçÊéíÂ∫èÂô®„ÄÇÊàë‰ª¨ËøòÊèê‰æõ‰∫ÜÂÖ≥‰∫éSFTËÆæÁΩÆÁöÑÊ∂àËûçÁ†îÁ©∂ÔºåÂπ∂ÊúüÊúõÊàë‰ª¨ÁöÑÂèëÁé∞ËÉΩÂ§üÊúâÁõä‰∫éËØ•È¢ÜÂüüÊú™Êù•ÁöÑÁ†îÁ©∂ÂíåÂ∫îÁî®„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Âú®Â§öÊ®°ÊÄÅ‰ø°ÊÅØÊ£ÄÁ¥¢‰∏≠ÔºåÂ¶Ç‰ΩïÊúâÊïàÂú∞ËÆ≠ÁªÉÂü∫‰∫éÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑÈáçÊéíÂ∫èÊ®°ÂûãÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÔºåÁâπÂà´ÊòØÂØπÊØîÂ≠¶‰π†ÔºàCLÔºâÂíåÁõëÁù£ÂæÆË∞ÉÔºàSFTÔºâÔºåÂú®Â∫îÁî®‰∫éLLMÊó∂Ë°®Áé∞Âá∫Â∑ÆÂºÇ„ÄÇÂØπ‰∫éBERTÁ±ªÊ®°ÂûãÔºåCLÈÄöÂ∏∏Êõ¥ÊúâÊïàÔºå‰ΩÜÂØπ‰∫éLLMÔºåSFT‰ºº‰πéÊõ¥ÂÖ∑ÊΩúÂäõ„ÄÇÂõ†Ê≠§ÔºåËÆ∫ÊñáË¶ÅÊé¢Á©∂Âì™ÁßçËÆ≠ÁªÉÁõÆÊ†áÊõ¥ÈÄÇÂêàLLMÈáçÊéíÂ∫èÔºåÂπ∂Ëß£ÈáäÂÖ∂ÂÜÖÂú®Êú∫Âà∂„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜËÆ≠ÁªÉÁõÆÊ†áÂàÜËß£‰∏∫‰∏§‰∏™ÂÖ≥ÈîÆÁªÑÊàêÈÉ®ÂàÜÔºöÊùÉÈáçÔºàweightÔºâÂíåÊñπÂêëÔºàdirectionÔºâ„ÄÇÊùÉÈáçÊéßÂà∂Ê®°ÂûãÊõ¥Êñ∞ÁöÑÂπÖÂ∫¶ÔºåËÄåÊñπÂêëÊåáÂØºÊ®°ÂûãÊõ¥Êñ∞ÁöÑÊñπÂêë„ÄÇÈÄöËøáÂàÜÊûêCLÂíåSFTÂú®Ëøô‰∏§‰∏™ÊñπÈù¢ÁöÑÂ∑ÆÂºÇÔºåËÆ∫ÊñáÊó®Âú®ÁêÜËß£ÂÆÉ‰ª¨Âú®LLMÈáçÊéíÂ∫è‰∏≠ÁöÑË°®Áé∞Â∑ÆÂºÇ„ÄÇËøôÁßçÂàÜËß£Êèê‰æõ‰∫Ü‰∏Ä‰∏™Áªü‰∏ÄÁöÑÊ°ÜÊû∂ÔºåÁî®‰∫éÊØîËæÉÂíåÁêÜËß£‰∏çÂêåËÆ≠ÁªÉÁõÆÊ†á‰πãÈó¥ÁöÑ‰∫§‰∫í‰ΩúÁî®„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËÆ∫ÊñáÈááÁî®ÈÄöÁî®Â§öÊ®°ÊÄÅÊ£ÄÁ¥¢ÔºàUMRÔºâ‰Ωú‰∏∫ÂÆûÈ™åÂπ≥Âè∞„ÄÇÊï¥‰ΩìÊµÅÁ®ãÂåÖÊã¨Ôºö1) ‰ΩøÁî®CLÊàñSFTËÆ≠ÁªÉLLMÈáçÊéíÂ∫èÊ®°ÂûãÔºõ2) Â∞ÜËÆ≠ÁªÉÁõÆÊ†áÂàÜËß£‰∏∫ÊùÉÈáçÂíåÊñπÂêëÔºõ3) ÈÄöËøáÊé¢ÊµãÂÆûÈ™åÂàÜÊûêÊùÉÈáçÂíåÊñπÂêëÁöÑÂΩ±ÂìçÔºõ4) Âú®MRBÂü∫ÂáÜÊµãËØï‰∏äËØÑ‰º∞Ê®°ÂûãÊÄßËÉΩ„ÄÇËØ•Ê°ÜÊû∂ÂÖÅËÆ∏Á†îÁ©∂‰∫∫ÂëòÊ∑±ÂÖ•‰∫ÜËß£‰∏çÂêåËÆ≠ÁªÉÁõÆÊ†áÂØπLLMÈáçÊéíÂ∫èÁöÑÂΩ±Âìç„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞Âú®‰∫éÂ∞ÜËÆ≠ÁªÉÁõÆÊ†áÂàÜËß£‰∏∫ÊùÉÈáçÂíåÊñπÂêëÔºåÂπ∂ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Áªü‰∏ÄÁöÑÊ°ÜÊû∂Êù•ÁêÜËß£CLÂíåSFTÁöÑ‰∫§‰∫í‰ΩúÁî®„ÄÇËøôÁßçÂàÜËß£ÊñπÊ≥ïÊèê‰æõ‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑËßÜËßíÔºåÂèØ‰ª•Êõ¥Ê∑±ÂÖ•Âú∞ÁêÜËß£‰∏çÂêåËÆ≠ÁªÉÁõÆÊ†áÂØπLLMÈáçÊéíÂ∫èÁöÑÂΩ±Âìç„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ï‰∏ç‰ªÖÂÖ≥Ê≥®Ê®°ÂûãÁöÑÊÄßËÉΩÔºåËøòÂÖ≥Ê≥®ËÆ≠ÁªÉËøáÁ®ã‰∏≠ÁöÑÂÜÖÂú®Êú∫Âà∂„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ‰ΩøÁî®ÂØπÊØîÊçüÂ§±ÔºàCLÔºâÂíåÁõëÁù£ÂæÆË∞ÉÔºàSFTÔºâ‰Ωú‰∏∫‰∏§Áßç‰∏ªË¶ÅÁöÑËÆ≠ÁªÉÁõÆÊ†áÔºõ2) ËÆæËÆ°Êé¢ÊµãÂÆûÈ™åÊù•ÂàÜÊûêÊùÉÈáçÂíåÊñπÂêëÁöÑÂΩ±ÂìçÔºõ3) Âú®MRBÂü∫ÂáÜÊµãËØï‰∏äËøõË°åÂ§ßËßÑÊ®°ËÆ≠ÁªÉÂíåËØÑ‰º∞Ôºõ4) ÂØπSFTËÆæÁΩÆËøõË°åÊ∂àËûçÁ†îÁ©∂Ôºå‰ª•Ëøõ‰∏ÄÊ≠•È™åËØÅÁ†îÁ©∂ÁªìÊûú„ÄÇËÆ∫ÊñáËøòÁâπÂà´ÂÖ≥Ê≥®‰∫ÜÂ¶Ç‰ΩïÂ∞ÜSFTÂ∫îÁî®‰∫éLLMÔºå‰æãÂ¶ÇÔºåÈÄöËøáÈ¢ÑÊµã‚ÄúÊòØ‚ÄùÊàñ‚ÄúÂê¶‚ÄùtokenÊù•Ë°®Á§∫Áõ∏ÂÖ≥ÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÁõëÁù£ÂæÆË∞ÉÔºàSFTÔºâÂú®LLMÈáçÊéíÂ∫èÊñπÈù¢ÂÖ∑Êúâ‰∏ÄËá¥ÁöÑ‰ºòÂäø„ÄÇÈÄöËøáÂ§ßËßÑÊ®°ËÆ≠ÁªÉÔºåËÆ∫ÊñáÊèêÂá∫ÁöÑSFTÈáçÊéíÂ∫èÂô®Âú®MRBÂü∫ÂáÜÊµãËØï‰∏≠ÂèñÂæó‰∫ÜÊñ∞ÁöÑstate-of-the-artÁªìÊûú„ÄÇÊé¢ÊµãÂÆûÈ™åË°®ÊòéÔºåSFTÊèê‰æõ‰∫ÜÊØîÂØπÊØîÂ≠¶‰π†ÔºàCLÔºâÊõ¥Âº∫ÁöÑÂä†ÊùÉÊñπÊ°à„ÄÇÊ∂àËûçÁ†îÁ©∂Ëøõ‰∏ÄÊ≠•È™åËØÅ‰∫ÜSFTËÆæÁΩÆÂØπÊ®°ÂûãÊÄßËÉΩÁöÑÂΩ±Âìç„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂêÑÁßçÂ§öÊ®°ÊÄÅ‰ø°ÊÅØÊ£ÄÁ¥¢Âú∫ÊôØÔºå‰æãÂ¶ÇÂõæÂÉèÊêúÁ¥¢„ÄÅËßÜÈ¢ëÊêúÁ¥¢„ÄÅË∑®Ê®°ÊÄÅÊ£ÄÁ¥¢Á≠â„ÄÇÈÄöËøáÈÄâÊã©ÂêàÈÄÇÁöÑËÆ≠ÁªÉÁõÆÊ†áÔºåÂèØ‰ª•ÊòæËëóÊèêÈ´òLLMÈáçÊéíÂ∫èÊ®°ÂûãÁöÑÊÄßËÉΩÔºå‰ªéËÄåÊèêÂçáÁî®Êà∑‰ΩìÈ™å„ÄÇËØ•Á†îÁ©∂ËøòÊúâÂä©‰∫éÊé®Âä®LLMÂú®‰ø°ÊÅØÊ£ÄÁ¥¢È¢ÜÂüüÁöÑÂ∫îÁî®ÔºåÂπ∂‰∏∫Êú™Êù•ÁöÑÁ†îÁ©∂Êèê‰æõÊåáÂØº„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> In information retrieval, training reranking models mainly focuses on two types of objectives: metric learning (e.g. contrastive loss to increase the predicted scores on relevant query-document pairs) and classification (binary label prediction of relevance vs. irrelevance). For BERT-style encoders, various studies have shown that contrastive learning (CL) can be more effective than discriminative (classification) learning. However, for large language models (LLMs), classification via supervised fine-tuning (SFT), which predicts ''yes'' (resp. ''no'') token for relevant (resp. irrelevant) pairs, appears more promising as it aligns well with the generative nature of LLMs. This divergence raises a central question: which objective is intrinsically better suited to LLM-based reranking, and what mechanism underlies the difference? In this work, we conduct a comprehensive comparison and analysis between CL and SFT for reranking, taking the universal multimodal retrieval (UMR) as the experimental playground. We first decompose the objectives into two components: weight, which controls the magnitude of those updates, and direction, which guides the model updates, then present a unified framework for understanding their interactions. Through probing experiments, we find that SFT provides a substantially stronger weighting scheme than CL, whereas the preferred scoring direction shows no clear winner. Taken together, these results point to a consistent advantage of SFT over CL for LLM reranking. To further validate our findings, we conduct large-scale training with SFT and present new state-of-the-art rerankers on the MRB benchmark. We also provide ablations on SFT settings and expect our findings to benefit future research and applications in this area.

