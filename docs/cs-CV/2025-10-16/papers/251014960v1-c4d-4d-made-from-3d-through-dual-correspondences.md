---
layout: default
title: C4D: 4D Made from 3D through Dual Correspondences
---

# C4D: 4D Made from 3D through Dual Correspondences

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.14960" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.14960v1</a>
  <a href="https://arxiv.org/pdf/2510.14960.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.14960v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.14960v1', 'C4D: 4D Made from 3D through Dual Correspondences')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shizun Wang, Zhenxiang Jiang, Xingyi Yang, Xinchao Wang

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-10-16

**å¤‡æ³¨**: Accepted to ICCV 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://littlepure2333.github.io/C4D)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**C4Dï¼šé€šè¿‡åŒé‡å¯¹åº”å…³ç³»ä»3Dé‡å»º4DåŠ¨æ€åœºæ™¯**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `4Dé‡å»º` `åŠ¨æ€åœºæ™¯` `å•ç›®è§†é¢‘` `ç‚¹è·Ÿè¸ª` `å…‰æµ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŸºäºç‚¹äº‘åœ°å›¾çš„3Dé‡å»ºæ–¹æ³•åœ¨åŠ¨æ€åœºæ™¯ä¸­è¡¨ç°ä¸ä½³ï¼Œå› ä¸ºç§»åŠ¨ç‰©ä½“è¿åå¤šè§†å›¾å‡ ä½•çº¦æŸã€‚
2. C4Dæ¡†æ¶åˆ©ç”¨æ—¶é—´å¯¹åº”å…³ç³»ï¼ˆçŸ­æœŸå…‰æµå’Œé•¿æœŸç‚¹è·Ÿè¸ªï¼‰å°†3Dé‡å»ºæ‰©å±•åˆ°4Dï¼Œå®ç°åŠ¨æ€åœºæ™¯é‡å»ºã€‚
3. å®éªŒè¡¨æ˜ï¼ŒC4Dåœ¨æ·±åº¦ä¼°è®¡ã€ç›¸æœºä½å§¿ä¼°è®¡å’Œç‚¹è·Ÿè¸ªç­‰ä¸‹æ¸¸ä»»åŠ¡ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä»å•ç›®è§†é¢‘ä¸­æ¢å¤4Dåœºæ™¯ï¼ˆå³åŒæ—¶ä¼°è®¡åŠ¨æ€å‡ ä½•ä½“å’Œç›¸æœºä½å§¿ï¼‰æ˜¯ä¸€ä¸ªæå…·æŒ‘æˆ˜æ€§çš„é—®é¢˜ã€‚è™½ç„¶æœ€è¿‘åŸºäºç‚¹äº‘åœ°å›¾çš„3Dé‡å»ºæ–¹æ³•ï¼ˆå¦‚DUSt3Rï¼‰åœ¨é™æ€åœºæ™¯é‡å»ºæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ç›´æ¥å°†å…¶åº”ç”¨äºåŠ¨æ€åœºæ™¯ä¼šå¯¼è‡´ä¸å‡†ç¡®çš„ç»“æœã€‚è¿™ç§å·®å¼‚çš„äº§ç”Ÿæ˜¯å› ä¸ºç§»åŠ¨ç‰©ä½“è¿åäº†å¤šè§†å›¾å‡ ä½•çº¦æŸï¼Œä»è€Œæ‰°ä¹±äº†é‡å»ºè¿‡ç¨‹ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†C4Dï¼Œä¸€ä¸ªåˆ©ç”¨æ—¶é—´å¯¹åº”å…³ç³»å°†ç°æœ‰3Dé‡å»ºå…¬å¼æ‰©å±•åˆ°4Dçš„æ¡†æ¶ã€‚å…·ä½“æ¥è¯´ï¼Œé™¤äº†é¢„æµ‹ç‚¹äº‘åœ°å›¾å¤–ï¼ŒC4Dè¿˜æ•è·ä¸¤ç§ç±»å‹çš„å¯¹åº”å…³ç³»ï¼šçŸ­æœŸå…‰æµå’Œé•¿æœŸç‚¹è·Ÿè¸ªã€‚æˆ‘ä»¬è®­ç»ƒäº†ä¸€ä¸ªåŠ¨æ€æ„ŸçŸ¥ç‚¹è·Ÿè¸ªå™¨ï¼Œå®ƒæä¾›é¢å¤–çš„ç§»åŠ¨ä¿¡æ¯ï¼Œæœ‰åŠ©äºä¼°è®¡è¿åŠ¨æ©ç ï¼Œä»è€Œå°†ç§»åŠ¨å…ƒç´ ä¸é™æ€èƒŒæ™¯åˆ†ç¦»ï¼Œä¸ºåŠ¨æ€åœºæ™¯æä¾›æ›´å¯é çš„æŒ‡å¯¼ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç»„åŠ¨æ€åœºæ™¯ä¼˜åŒ–ç›®æ ‡ï¼Œä»¥æ¢å¤æ¯å¸§çš„3Då‡ ä½•ä½“å’Œç›¸æœºå‚æ•°ã€‚åŒæ—¶ï¼Œè¿™äº›å¯¹åº”å…³ç³»å°†2Dè½¨è¿¹æå‡ä¸ºå¹³æ»‘çš„3Dè½¨è¿¹ï¼Œä»è€Œå®ç°å®Œå…¨é›†æˆçš„4Dé‡å»ºã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¡†æ¶å®ç°äº†å®Œæ•´çš„4Dæ¢å¤ï¼Œå¹¶åœ¨å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡ï¼ˆåŒ…æ‹¬æ·±åº¦ä¼°è®¡ã€ç›¸æœºä½å§¿ä¼°è®¡å’Œç‚¹è·Ÿè¸ªï¼‰ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ä»å•ç›®è§†é¢‘ä¸­è¿›è¡ŒåŠ¨æ€åœºæ™¯çš„4Dé‡å»ºé—®é¢˜ï¼Œå³åŒæ—¶ä¼°è®¡åŠ¨æ€å‡ ä½•ä½“å’Œç›¸æœºä½å§¿ã€‚ç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯é‚£äº›åŸºäºç‚¹äº‘åœ°å›¾çš„3Dé‡å»ºæ–¹æ³•ï¼Œåœ¨é™æ€åœºæ™¯ä¸­è¡¨ç°è‰¯å¥½ï¼Œä½†ç›´æ¥åº”ç”¨äºåŠ¨æ€åœºæ™¯æ—¶ä¼šå› ä¸ºç§»åŠ¨ç‰©ä½“çš„å­˜åœ¨è€Œå¤±æ•ˆï¼Œå› ä¸ºç§»åŠ¨ç‰©ä½“ç ´åäº†å¤šè§†å›¾å‡ ä½•çº¦æŸï¼Œå¯¼è‡´é‡å»ºç»“æœä¸å‡†ç¡®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ—¶é—´å¯¹åº”å…³ç³»æ¥å¤„ç†åŠ¨æ€åœºæ™¯ä¸­çš„è¿åŠ¨é—®é¢˜ã€‚é€šè¿‡å¼•å…¥çŸ­æœŸå…‰æµå’Œé•¿æœŸç‚¹è·Ÿè¸ªï¼ŒC4Dèƒ½å¤Ÿæ•æ‰åœºæ™¯ä¸­ç‰©ä½“çš„è¿åŠ¨ä¿¡æ¯ï¼Œä»è€ŒåŒºåˆ†é™æ€èƒŒæ™¯å’ŒåŠ¨æ€ç‰©ä½“ï¼Œå¹¶ä¸ºåŠ¨æ€åœºæ™¯çš„é‡å»ºæä¾›æ›´å¯é çš„æŒ‡å¯¼ã€‚è¿™ç§æ–¹æ³•å°†ä¼ ç»Ÿçš„3Dé‡å»ºæ‰©å±•åˆ°4Dï¼Œå®ç°äº†åŠ¨æ€å‡ ä½•ä½“å’Œç›¸æœºä½å§¿çš„è”åˆä¼°è®¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šC4Dæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼šé¦–å…ˆï¼Œä½¿ç”¨ä¸€ä¸ªåŠ¨æ€æ„ŸçŸ¥ç‚¹è·Ÿè¸ªå™¨æ¥é¢„æµ‹çŸ­æœŸå…‰æµå’Œé•¿æœŸç‚¹è·Ÿè¸ªï¼Œä»è€Œæ•æ‰åœºæ™¯ä¸­çš„è¿åŠ¨ä¿¡æ¯ã€‚ç„¶åï¼Œåˆ©ç”¨è¿™äº›è¿åŠ¨ä¿¡æ¯ä¼°è®¡è¿åŠ¨æ©ç ï¼Œå°†ç§»åŠ¨å…ƒç´ ä¸é™æ€èƒŒæ™¯åˆ†ç¦»ã€‚æ¥ç€ï¼Œé€šè¿‡ä¸€ç»„åŠ¨æ€åœºæ™¯ä¼˜åŒ–ç›®æ ‡ï¼Œæ¢å¤æ¯å¸§çš„3Då‡ ä½•ä½“å’Œç›¸æœºå‚æ•°ã€‚æœ€åï¼Œåˆ©ç”¨å¯¹åº”å…³ç³»å°†2Dè½¨è¿¹æå‡ä¸ºå¹³æ»‘çš„3Dè½¨è¿¹ï¼Œå®ç°å®Œå…¨é›†æˆçš„4Dé‡å»ºã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºåˆ©ç”¨åŒé‡å¯¹åº”å…³ç³»ï¼ˆçŸ­æœŸå…‰æµå’Œé•¿æœŸç‚¹è·Ÿè¸ªï¼‰æ¥å¤„ç†åŠ¨æ€åœºæ™¯ä¸­çš„è¿åŠ¨é—®é¢˜ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒC4Dèƒ½å¤Ÿæ›´å‡†ç¡®åœ°æ•æ‰åœºæ™¯ä¸­ç‰©ä½“çš„è¿åŠ¨ä¿¡æ¯ï¼Œä»è€Œæ›´æœ‰æ•ˆåœ°åˆ†ç¦»é™æ€èƒŒæ™¯å’ŒåŠ¨æ€ç‰©ä½“ï¼Œå¹¶ä¸ºåŠ¨æ€åœºæ™¯çš„é‡å»ºæä¾›æ›´å¯é çš„æŒ‡å¯¼ã€‚æ­¤å¤–ï¼ŒC4Dè¿˜å¼•å…¥äº†ä¸€ç»„åŠ¨æ€åœºæ™¯ä¼˜åŒ–ç›®æ ‡ï¼Œä»¥æé«˜é‡å»ºçš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåŠ¨æ€æ„ŸçŸ¥ç‚¹è·Ÿè¸ªå™¨çš„å…·ä½“ç½‘ç»œç»“æ„æœªçŸ¥ï¼Œä½†å…¶è®­ç»ƒç›®æ ‡æ˜¯æä¾›å‡†ç¡®çš„çŸ­æœŸå…‰æµå’Œé•¿æœŸç‚¹è·Ÿè¸ªã€‚è¿åŠ¨æ©ç çš„ä¼°è®¡æ–¹æ³•æœªçŸ¥ï¼Œä½†å…¶ç›®çš„æ˜¯å°†ç§»åŠ¨å…ƒç´ ä¸é™æ€èƒŒæ™¯åˆ†ç¦»ã€‚åŠ¨æ€åœºæ™¯ä¼˜åŒ–ç›®æ ‡çš„å…·ä½“å½¢å¼æœªçŸ¥ï¼Œä½†å…¶ç›®çš„æ˜¯æ¢å¤æ¯å¸§çš„3Då‡ ä½•ä½“å’Œç›¸æœºå‚æ•°ã€‚è®ºæ–‡ä¸­å¯èƒ½ä½¿ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥çº¦æŸé‡å»ºç»“æœçš„å¹³æ»‘æ€§å’Œä¸€è‡´æ€§ï¼Œä½†å…·ä½“ç»†èŠ‚æœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

C4Dæ¡†æ¶åœ¨å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬æ·±åº¦ä¼°è®¡ã€ç›¸æœºä½å§¿ä¼°è®¡å’Œç‚¹è·Ÿè¸ªã€‚è™½ç„¶è®ºæ–‡ä¸­æ²¡æœ‰æä¾›å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿ï¼Œä½†æ‘˜è¦ä¸­æ˜ç¡®æŒ‡å‡ºC4Då®ç°äº†å®Œæ•´çš„4Dæ¢å¤ï¼Œè¡¨æ˜å…¶åœ¨åŠ¨æ€åœºæ™¯é‡å»ºæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚é¡¹ç›®ä¸»é¡µå¯èƒ½åŒ…å«æ›´è¯¦ç»†çš„å®éªŒç»“æœå’Œå¯¹æ¯”åˆ†æï¼Œä½†ç›®å‰ä¿¡æ¯æœ‰é™ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

C4Dæ¡†æ¶åœ¨æœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ã€å¢å¼ºç°å®ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥ç”¨äºæ„å»ºåŠ¨æ€ç¯å¢ƒçš„ç²¾ç¡®æ¨¡å‹ï¼Œå¸®åŠ©æœºå™¨äººæ›´å¥½åœ°ç†è§£å’Œé€‚åº”å‘¨å›´ç¯å¢ƒã€‚åœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼ŒC4Då¯ä»¥ç”¨äºæ£€æµ‹å’Œè·Ÿè¸ªç§»åŠ¨ç‰©ä½“ï¼Œæé«˜é©¾é©¶å®‰å…¨æ€§ã€‚åœ¨å¢å¼ºç°å®ä¸­ï¼ŒC4Då¯ä»¥ç”¨äºå°†è™šæ‹Ÿç‰©ä½“ä¸çœŸå®åœºæ™¯è¿›è¡Œæ›´è‡ªç„¶çš„èåˆï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›è¿›ä¸€æ­¥å‘å±•ï¼Œå®ç°æ›´å¤æ‚åŠ¨æ€åœºæ™¯çš„å®æ—¶é‡å»ºå’Œç†è§£ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recovering 4D from monocular video, which jointly estimates dynamic geometry and camera poses, is an inevitably challenging problem. While recent pointmap-based 3D reconstruction methods (e.g., DUSt3R) have made great progress in reconstructing static scenes, directly applying them to dynamic scenes leads to inaccurate results. This discrepancy arises because moving objects violate multi-view geometric constraints, disrupting the reconstruction. To address this, we introduce C4D, a framework that leverages temporal Correspondences to extend existing 3D reconstruction formulation to 4D. Specifically, apart from predicting pointmaps, C4D captures two types of correspondences: short-term optical flow and long-term point tracking. We train a dynamic-aware point tracker that provides additional mobility information, facilitating the estimation of motion masks to separate moving elements from the static background, thus offering more reliable guidance for dynamic scenes. Furthermore, we introduce a set of dynamic scene optimization objectives to recover per-frame 3D geometry and camera parameters. Simultaneously, the correspondences lift 2D trajectories into smooth 3D trajectories, enabling fully integrated 4D reconstruction. Experiments show that our framework achieves complete 4D recovery and demonstrates strong performance across multiple downstream tasks, including depth estimation, camera pose estimation, and point tracking. Project Page: https://littlepure2333.github.io/C4D

