---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CV - 2025-05-28
---

# cs.CVï¼ˆ2025-05-28ï¼‰

ğŸ“Š å…± **8** ç¯‡è®ºæ–‡
 | ğŸ”— **2** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (3)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (2 ğŸ”—2)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (2)</a>
<a href="#æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion" class="interest-badge">æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (3 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250602014v1-research-on-driving-scenario-technology-based-on-multimodal-large-la.html">Research on Driving Scenario Technology Based on Multimodal Large Lauguage Model Optimization</a></td>
  <td>æå‡ºå¤šæ¨¡æ€æ¨¡å‹ä¼˜åŒ–æ–¹æ³•ä»¥è§£å†³å¤æ‚é©¾é©¶åœºæ™¯ç†è§£é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">distillation</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.02014v1" data-paper-url="./papers/250602014v1-research-on-driving-scenario-technology-based-on-multimodal-large-la.html" onclick="toggleFavorite(this, '2506.02014v1', 'Research on Driving Scenario Technology Based on Multimodal Large Lauguage Model Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250521904v4-cast-contrastive-adaptation-and-distillation-for-semi-supervised-ins.html">CAST: Contrastive Adaptation and Distillation for Semi-Supervised Instance Segmentation</a></td>
  <td>æå‡ºCASTæ¡†æ¶ä»¥è§£å†³åŠç›‘ç£å®ä¾‹åˆ†å‰²é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">distillation</span> <span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.21904v4" data-paper-url="./papers/250521904v4-cast-contrastive-adaptation-and-distillation-for-semi-supervised-ins.html" onclick="toggleFavorite(this, '2505.21904v4', 'CAST: Contrastive Adaptation and Distillation for Semi-Supervised Instance Segmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250521920v2-infosam-fine-tuning-the-segment-anything-model-from-an-information-t.html">InfoSAM: Fine-Tuning the Segment Anything Model from An Information-Theoretic Perspective</a></td>
  <td>æå‡ºInfoSAMä»¥æå‡SAMåœ¨ä¸“ä¸šé¢†åŸŸçš„è¡¨ç°</td>
  <td class="tags-cell"><span class="paper-tag">distillation</span> <span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.21920v2" data-paper-url="./papers/250521920v2-infosam-fine-tuning-the-segment-anything-model-from-an-information-t.html" onclick="toggleFavorite(this, '2505.21920v2', 'InfoSAM: Fine-Tuning the Segment Anything Model from An Information-Theoretic Perspective')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>4</td>
  <td><a href="./papers/250521890v3-diffusion-denoised-hyperspectral-gaussian-splatting.html">Diffusion-Denoised Hyperspectral Gaussian Splatting</a></td>
  <td>æå‡ºæ‰©æ•£å»å™ªçš„é«˜å…‰è°±é«˜æ–¯ç‚¹äº‘æ–¹æ³•ä»¥è§£å†³é«˜å…‰è°±æˆåƒé‡å»ºé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">3D gaussian splatting</span> <span class="paper-tag">3DGS</span> <span class="paper-tag">gaussian splatting</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.21890v3" data-paper-url="./papers/250521890v3-diffusion-denoised-hyperspectral-gaussian-splatting.html" onclick="toggleFavorite(this, '2505.21890v3', 'Diffusion-Denoised Hyperspectral Gaussian Splatting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250521844v2-test-time-adaptation-of-vision-language-models-for-open-vocabulary-s.html">Test-Time Adaptation of Vision-Language Models for Open-Vocabulary Semantic Segmentation</a></td>
  <td>æå‡ºå¤šçº§å¤šæç¤ºç†µæœ€å°åŒ–æ–¹æ³•ä»¥è§£å†³å¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">open-vocabulary</span> <span class="paper-tag">open vocabulary</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.21844v2" data-paper-url="./papers/250521844v2-test-time-adaptation-of-vision-language-models-for-open-vocabulary-s.html" onclick="toggleFavorite(this, '2505.21844v2', 'Test-Time Adaptation of Vision-Language Models for Open-Vocabulary Semantic Segmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>6</td>
  <td><a href="./papers/250602015v2-ospo-object-centric-self-improving-preference-optimization-for-text-.html">OSPO: Object-centric Self-improving Preference Optimization for Text-to-Image Generation</a></td>
  <td>æå‡ºOSPOæ¡†æ¶ä»¥è§£å†³æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­çš„å¯¹è±¡å¯¹é½é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.02015v2" data-paper-url="./papers/250602015v2-ospo-object-centric-self-improving-preference-optimization-for-text-.html" onclick="toggleFavorite(this, '2506.02015v2', 'OSPO: Object-centric Self-improving Preference Optimization for Text-to-Image Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250521850v2-beyond-perception-evaluating-abstract-visual-reasoning-through-multi.html">Beyond Perception: Evaluating Abstract Visual Reasoning through Multi-Stage Task</a></td>
  <td>æå‡ºMultiStARåŸºå‡†ä»¥è§£å†³æŠ½è±¡è§†è§‰æ¨ç†è¯„ä¼°é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.21850v2" data-paper-url="./papers/250521850v2-beyond-perception-evaluating-abstract-visual-reasoning-through-multi.html" onclick="toggleFavorite(this, '2505.21850v2', 'Beyond Perception: Evaluating Abstract Visual Reasoning through Multi-Stage Task')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion">ğŸ”¬ æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>8</td>
  <td><a href="./papers/250521837v1-unimogen-universal-motion-generation.html">UniMoGen: Universal Motion Generation</a></td>
  <td>æå‡ºUniMoGenä»¥è§£å†³éª¨æ¶ä¾èµ–çš„è¿åŠ¨ç”Ÿæˆé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">motion generation</span> <span class="paper-tag">character animation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.21837v1" data-paper-url="./papers/250521837v1-unimogen-universal-motion-generation.html" onclick="toggleFavorite(this, '2505.21837v1', 'UniMoGen: Universal Motion Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CV é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)