---
layout: default
title: OSPO: Object-centric Self-improving Preference Optimization for Text-to-Image Generation
---

# OSPO: Object-centric Self-improving Preference Optimization for Text-to-Image Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.02015" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.02015v2</a>
  <a href="https://arxiv.org/pdf/2506.02015.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.02015v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.02015v2', 'OSPO: Object-centric Self-improving Preference Optimization for Text-to-Image Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yoonjin Oh, Yongjin Kim, Hyomin Kim, Donghwan Chi, Sungwoong Kim

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-28 (æ›´æ–°: 2025-09-19)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOSPOæ¡†æ¶ä»¥è§£å†³æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­çš„å¯¹è±¡å¯¹é½é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ` `å¯¹è±¡ä¸­å¿ƒä¼˜åŒ–` `è‡ªæˆ‘æ”¹è¿›æœºåˆ¶` `å¤šæ¨¡æ€å­¦ä¹ ` `å›¾åƒç”Ÿæˆ` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è‡ªæˆ‘æ”¹è¿›æ–¹æ³•æœªèƒ½æœ‰æ•ˆè§£å†³æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­çš„å¯¹è±¡å¹»è§‰é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨ç»†ç²’åº¦è§†è§‰ç»†èŠ‚æ–¹é¢ã€‚
2. æœ¬æ–‡æå‡ºäº†å¯¹è±¡ä¸­å¿ƒè‡ªæˆ‘æ”¹è¿›åå¥½ä¼˜åŒ–ï¼ˆOSPOï¼‰æ¡†æ¶ï¼Œé€šè¿‡æ„å»ºå¯¹è±¡çº§ç¡¬è´Ÿæ ·æœ¬æ•°æ®æ¥æå‡å¯¹è±¡çº§åˆ«çš„æ–‡æœ¬-å›¾åƒå¯¹é½ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒOSPOåœ¨ç»„åˆå›¾åƒç”ŸæˆåŸºå‡†ä¸Šæ˜¾è‘—æé«˜äº†ç»†ç²’åº¦å¯¹é½ï¼Œè¶…è¶Šäº†ä»¥å¾€çš„è‡ªæˆ‘æ”¹è¿›æ–¹æ³•å’ŒåŸºäºæ‰©æ•£çš„å›¾åƒç”Ÿæˆæ¨¡å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„è¿›å±•ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿä»¥ç»Ÿä¸€çš„æ–¹å¼ç†è§£å’Œç”Ÿæˆå¤šæ¨¡æ€æ•°æ®ã€‚ç„¶è€Œï¼Œåœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­ï¼Œå®ç°è¾“å…¥æç¤ºä¸ç”Ÿæˆå›¾åƒä¹‹é—´çš„ç»†ç²’åº¦å¯¹é½ä»ç„¶æ˜¯ä¸€ä¸ªä¸»è¦æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œè¿‘æœŸç ”ç©¶å¼•å…¥äº†åŸºäºè‡ªç”Ÿæˆæ•°æ®å’Œè‡ªåé¦ˆçš„è‡ªæˆ‘æ”¹è¿›æœºåˆ¶ï¼Œä»¥é«˜æ•ˆç¼“è§£è¿™ä¸€æŒ‘æˆ˜ï¼Œè€Œæ— éœ€ä¾èµ–å¤–éƒ¨å¤§è§„æ¨¡æ•°æ®æˆ–æ¨¡å‹ã€‚ç„¶è€Œï¼Œç°æœ‰çš„è‡ªæˆ‘æ”¹è¿›æ–¹æ³•æœªèƒ½å…³æ³¨ç”Ÿæˆè®­ç»ƒæ•°æ®æˆ–æä¾›åé¦ˆæ—¶çš„ç»†ç²’åº¦è§†è§‰ç»†èŠ‚ï¼Œå°¤å…¶æ˜¯åœ¨å¯¹è±¡å±‚é¢ï¼Œå› æ­¤åœ¨è§£å†³å¯¹è±¡å¹»è§‰é—®é¢˜ä¸Šä»ç„¶å­˜åœ¨å›°éš¾ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†å¯¹è±¡ä¸­å¿ƒè‡ªæˆ‘æ”¹è¿›åå¥½ä¼˜åŒ–ï¼ˆOSPOï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨å¢å¼ºå¯¹è±¡çº§æ–‡æœ¬-å›¾åƒå¯¹é½ã€‚OSPOæ˜ç¡®æ„å»ºå’Œåˆ©ç”¨å¯¹è±¡çº§ç¡¬è´Ÿæ ·æœ¬æ•°æ®ï¼Œå¹¶é€šè¿‡å¯¹è±¡ä¸­å¿ƒä¼˜åŒ–æ¥æé«˜å¯¹è±¡ç‰¹å®šçš„ä¿çœŸåº¦ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­çš„å¯¹è±¡å¹»è§‰é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨ç”Ÿæˆè®­ç»ƒæ•°æ®å’Œåé¦ˆæ—¶æœªèƒ½å…³æ³¨ç»†ç²’åº¦çš„è§†è§‰ç»†èŠ‚ï¼Œå¯¼è‡´å¯¹é½æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šOSPOæ¡†æ¶é€šè¿‡æ„å»ºå’Œåˆ©ç”¨å¯¹è±¡çº§ç¡¬è´Ÿæ ·æœ¬æ•°æ®ï¼Œç»“åˆå¯¹è±¡ä¸­å¿ƒä¼˜åŒ–ï¼Œæ—¨åœ¨æå‡å¯¹è±¡ç‰¹å®šçš„ä¿çœŸåº¦ï¼Œä»è€Œæ”¹å–„æ–‡æœ¬ä¸å›¾åƒä¹‹é—´çš„å¯¹é½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šOSPOæ¡†æ¶åŒ…æ‹¬å››ä¸ªä¸»è¦æ¨¡å—ï¼šåˆå§‹æç¤ºç”Ÿæˆã€ç¡¬åå¥½å¯¹ç”Ÿæˆã€è¿‡æ»¤ä¸é€‰æ‹©ã€ä»¥åŠåŸºäºæ¡ä»¶åå¥½æŸå¤±çš„å¯¹è±¡ä¸­å¿ƒåå¥½ä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šOSPOçš„åˆ›æ–°ä¹‹å¤„åœ¨äºå…¶ä¸“æ³¨äºå¯¹è±¡çº§åˆ«çš„ç»†èŠ‚ï¼Œé€šè¿‡ç¡¬è´Ÿæ ·æœ¬çš„æ„å»ºå’Œå¯¹è±¡ä¸­å¿ƒä¼˜åŒ–ï¼Œæ˜¾è‘—æå‡äº†ç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œå¯¹é½ç²¾åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œä½¿ç”¨äº†æ¡ä»¶åå¥½æŸå¤±ä½œä¸ºä¼˜åŒ–ç›®æ ‡ï¼Œç¡®ä¿ç”Ÿæˆçš„å›¾åƒåœ¨å¯¹è±¡å±‚é¢ä¸Šå…·æœ‰æ›´é«˜çš„ä¿çœŸåº¦ï¼ŒåŒæ—¶é€šè¿‡ç²¾ç»†çš„è¿‡æ»¤ä¸é€‰æ‹©æœºåˆ¶æ¥æå‡è®­ç»ƒæ•°æ®çš„è´¨é‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒOSPOåœ¨ç»„åˆå›¾åƒç”ŸæˆåŸºå‡†ä¸Šæ˜¾è‘—æé«˜äº†ç»†ç²’åº¦å¯¹é½ï¼Œè¶…è¶Šäº†ä»¥å¾€çš„è‡ªæˆ‘æ”¹è¿›æ–¹æ³•ï¼Œæ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°XX%ï¼ˆå…·ä½“æ•°æ®å¾…è¡¥å……ï¼‰ï¼Œå¹¶åœ¨ä¸åŸºäºæ‰©æ•£çš„å›¾åƒç”Ÿæˆæ¨¡å‹çš„å¯¹æ¯”ä¸­è¡¨ç°å‡ºæ›´ä¼˜çš„æ•ˆæœã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è®¡ç®—æœºè§†è§‰ã€å›¾åƒç”Ÿæˆã€è™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®ç­‰ã€‚é€šè¿‡æå‡æ–‡æœ¬ä¸å›¾åƒä¹‹é—´çš„å¯¹é½ç²¾åº¦ï¼ŒOSPOæ¡†æ¶èƒ½å¤Ÿä¸ºå¤šæ¨¡æ€å†…å®¹ç”Ÿæˆæä¾›æ›´é«˜è´¨é‡çš„è§£å†³æ–¹æ¡ˆï¼Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„å‘å±•ä¸åº”ç”¨ã€‚æœªæ¥ï¼ŒOSPOå¯èƒ½åœ¨è‰ºæœ¯åˆ›ä½œã€æ¸¸æˆè®¾è®¡å’Œæ•™è‚²ç­‰å¤šä¸ªé¢†åŸŸäº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in Multimodal Large Language Models (MLLMs) have enabled models to perform both understanding and generation of multimodal data in a unified manner. However, achieving a fine-grained alignment between input prompts and generated images remains a major challenge especially in text-to-image generation. Therefore, recent works have introduced self-improving mechanisms based on self-generated data and self-feedback to efficiently mitigate this challenge without relying on external large-scale data or models. However, existing self-improving approaches have not focused on fine-grained visual details especially at the object level in generating training data or providing a feedback, and thus they still struggle to resolve the object hallucination problem in text-to-image generation. To tackle this problem, we propose an Object-centric Self-improving Preference Optimization (OSPO), a self-improving framework for enhancing object-level text-image alignment. OSPO is designed to explicitly address the need for constructing and leveraging object-level hard negative data and an object-centric optimization in improving object-specific fidelity. In specific, OSPO consists of: (1) Initial Prompt Generation (2) Hard Preference Pair Generation (3) Filtering and Selection (4) Object-centric Preference Optimization with Conditional Preference Loss. Extensive experiments on compositional image generation benchmarks demonstrate that OSPO significantly improves fine-grained alignment in text-to-image generation, surpassing not only prior self-improving methods but also diffusion-based specialized image generation models.

