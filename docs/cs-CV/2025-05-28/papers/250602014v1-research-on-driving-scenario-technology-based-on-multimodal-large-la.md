---
layout: default
title: Research on Driving Scenario Technology Based on Multimodal Large Lauguage Model Optimization
---

# Research on Driving Scenario Technology Based on Multimodal Large Lauguage Model Optimization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.02014" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.02014v1</a>
  <a href="https://arxiv.org/pdf/2506.02014.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.02014v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.02014v1', 'Research on Driving Scenario Technology Based on Multimodal Large Lauguage Model Optimization')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Wang Mengjie, Zhu Huiping, Li Jian, Shi Wenxiu, Zhang Song

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-28

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Â§öÊ®°ÊÄÅÊ®°Âûã‰ºòÂåñÊñπÊ≥ï‰ª•Ëß£ÂÜ≥Â§çÊùÇÈ©æÈ©∂Âú∫ÊôØÁêÜËß£ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅÊ®°Âûã` `È©æÈ©∂Âú∫ÊôØ` `Âä®ÊÄÅÊèêÁ§∫‰ºòÂåñ` `Êï∞ÊçÆÈõÜÊûÑÂª∫` `Áü•ËØÜËí∏È¶è` `Ê®°ÂûãËÆ≠ÁªÉ` `ËµÑÊ∫ê‰ºòÂåñ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂ§öÊ®°ÊÄÅÊ®°ÂûãÂú®Â§çÊùÇÈ©æÈ©∂Âú∫ÊôØÁêÜËß£‰∏≠Èù¢‰∏¥Êï∞ÊçÆÊî∂ÈõÜÂíåËÆ≠ÁªÉ‰ºòÂåñÁ≠âÊåëÊàòÔºåÂΩ±ÂìçÂÆûÈôÖÂ∫îÁî®ÊïàÊûú„ÄÇ
2. Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÁªºÂêà‰ºòÂåñÊñπÊ≥ïÔºåÈÄöËøáÂä®ÊÄÅÊèêÁ§∫‰ºòÂåñÂíåÈ´òË¥®ÈáèÊï∞ÊçÆÈõÜÊûÑÂª∫ÔºåÊèêÂçáÊ®°ÂûãÁöÑ‰ªªÂä°‰∏ìÊ≥®Â∫¶ÂíåÂà§Êñ≠ËÉΩÂäõ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÊòæËëóÊèêÈ´ò‰∫ÜÊ®°ÂûãÂú®Èî•‰ΩìÊ£ÄÊµãÂíå‰∫§ÈÄöÁÅØËØÜÂà´Á≠âÂÖ≥ÈîÆ‰ªªÂä°‰∏≠ÁöÑÂáÜÁ°ÆÊÄßÔºåÂπ∂‰ºòÂåñ‰∫ÜËµÑÊ∫êÂà©Áî®„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÈöèÁùÄËá™Âä®È©æÈ©∂ÂíåËæÖÂä©È©æÈ©∂ÊäÄÊúØÁöÑÂèëÂ±ïÔºåÂØπÂ§çÊùÇÈ©æÈ©∂Âú∫ÊôØÁöÑÁêÜËß£ËÉΩÂäõÊèêÂá∫‰∫ÜÊõ¥È´òÁöÑË¶ÅÊ±Ç„ÄÇÂ§öÊ®°ÊÄÅÈÄöÁî®Â§ßÊ®°Âûã‰Ωú‰∏∫Â∫îÂØπËøô‰∏ÄÊåëÊàòÁöÑËß£ÂÜ≥ÊñπÊ°àÈÄêÊ∏êÊµÆÁé∞„ÄÇÁÑ∂ËÄåÔºåÂú®ÂûÇÁõ¥È¢ÜÂüüÂ∫îÁî®Ëøô‰∫õÊ®°ÂûãÊó∂ÔºåÊï∞ÊçÆÊî∂ÈõÜ„ÄÅÊ®°ÂûãËÆ≠ÁªÉÂíåÈÉ®ÁΩ≤‰ºòÂåñÁ≠âÊñπÈù¢Â≠òÂú®Âõ∞Èöæ„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÁªºÂêàÊñπÊ≥ïÔºå‰ºòÂåñÈ©æÈ©∂Âú∫ÊôØ‰∏≠ÁöÑÂ§öÊ®°ÊÄÅÊ®°ÂûãÔºåÂåÖÊã¨Èî•‰ΩìÊ£ÄÊµã„ÄÅ‰∫§ÈÄöÁÅØËØÜÂà´„ÄÅÈôêÈÄüÂª∫ËÆÆÂíå‰∫§ÂèâÂè£Ë≠¶Êä•Á≠â‰ªªÂä°„ÄÇËØ•ÊñπÊ≥ïÊ∂µÁõñÂä®ÊÄÅÊèêÁ§∫‰ºòÂåñ„ÄÅÊï∞ÊçÆÈõÜÊûÑÂª∫„ÄÅÊ®°ÂûãËÆ≠ÁªÉÂíåÈÉ®ÁΩ≤Á≠âÂÖ≥ÈîÆÊñπÈù¢ÔºåÊòæËëóÊèêÂçá‰∫ÜÊ®°ÂûãÂú®ÂÖ≥ÈîÆ‰ªªÂä°‰∏≠ÁöÑÂáÜÁ°ÆÊÄßÔºåÂπ∂ÂÆûÁé∞‰∫ÜËµÑÊ∫êÁöÑÈ´òÊïàÂà©Áî®„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Â§öÊ®°ÊÄÅÊ®°ÂûãÂú®Â§çÊùÇÈ©æÈ©∂Âú∫ÊôØ‰∏≠ÁöÑÂ∫îÁî®ÈóÆÈ¢òÔºåÁé∞ÊúâÊñπÊ≥ïÂú®Êï∞ÊçÆÊî∂ÈõÜ„ÄÅÊ®°ÂûãËÆ≠ÁªÉÂíåÈÉ®ÁΩ≤ÊñπÈù¢Â≠òÂú®ÊòæËëó‰∏çË∂≥ÔºåÂØºËá¥Ê®°ÂûãÊÄßËÉΩ‰∏ç‰Ω≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÊèêÂá∫ÈÄöËøáÂä®ÊÄÅÊèêÁ§∫‰ºòÂåñÂíåÈ´òË¥®ÈáèÊï∞ÊçÆÈõÜÊûÑÂª∫ÔºåÂ¢ûÂº∫Ê®°ÂûãÂØπÂΩ±ÂìçËá™ËΩ¶ÁöÑÁâ©‰ΩìÁöÑÂÖ≥Ê≥®Ôºå‰ªéËÄåÊèêÂçá‰ªªÂä°ÁâπÂÆöÁöÑÂà§Êñ≠ËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊñπÊ≥ïÂåÖÊã¨Âõõ‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÂä®ÊÄÅÊèêÁ§∫‰ºòÂåñ„ÄÅÊï∞ÊçÆÈõÜÊûÑÂª∫„ÄÅÊ®°ÂûãËÆ≠ÁªÉÂíåÈÉ®ÁΩ≤‰ºòÂåñ„ÄÇÂä®ÊÄÅÊèêÁ§∫Ê†πÊçÆËæìÂÖ•ÂõæÂÉèÂÜÖÂÆπË∞ÉÊï¥ÔºåÊï∞ÊçÆÈõÜÁªìÂêàÁúüÂÆû‰∏éÂêàÊàêÊï∞ÊçÆÔºåÊ®°ÂûãËÆ≠ÁªÉÈááÁî®Áü•ËØÜËí∏È¶èÁ≠âÂÖàËøõÊäÄÊúØ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÂä®ÊÄÅÊèêÁ§∫‰ºòÂåñÊòØÊú¨ÊñáÁöÑÊ†∏ÂøÉÂàõÊñ∞ÔºåÈÄöËøáË∞ÉÊï¥ÊèêÁ§∫ÂÜÖÂÆπÔºåÊèêÂçáÊ®°ÂûãÂØπÁâπÂÆö‰ªªÂä°ÁöÑËÅöÁÑ¶ËÉΩÂäõÔºåÊòæËëóÂå∫Âà´‰∫é‰º†ÁªüÊñπÊ≥ï„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Ê®°ÂûãËÆ≠ÁªÉ‰∏≠ÔºåÈááÁî®Áü•ËØÜËí∏È¶è„ÄÅÂä®ÊÄÅÂæÆË∞ÉÂíåÈáèÂåñÁ≠âÊäÄÊúØÔºå‰ºòÂåñÂ≠òÂÇ®ÂíåËÆ°ÁÆóÊàêÊú¨ÔºåÂêåÊó∂ÊèêÂçáÊ®°ÂûãÊÄßËÉΩ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫Ôºå‰ºòÂåñÂêéÁöÑÊ®°ÂûãÂú®Èî•‰ΩìÊ£ÄÊµãÂíå‰∫§ÈÄöÁÅØËØÜÂà´‰ªªÂä°‰∏≠ÂáÜÁ°ÆÁéáÊèêÂçáË∂ÖËøá20%ÔºåÂπ∂‰∏îÂú®ËµÑÊ∫êÂà©Áî®ÊïàÁéá‰∏ä‰πüÊúâÊòæËëóÊîπÂñÑÔºå‰∏∫ÂÆûÈôÖÂ∫îÁî®Êèê‰æõ‰∫ÜÂº∫ÊúâÂäõÁöÑÊîØÊåÅ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Ëá™Âä®È©æÈ©∂„ÄÅÊô∫ËÉΩ‰∫§ÈÄöÁ≥ªÁªüÂíåËæÖÂä©È©æÈ©∂ÊäÄÊúØÁ≠â„ÄÇÈÄöËøáÊèêÂçáÊ®°ÂûãÂú®Â§çÊùÇÈ©æÈ©∂Âú∫ÊôØ‰∏≠ÁöÑÁêÜËß£ËÉΩÂäõÔºåËÉΩÂ§üÊúâÊïàÊèêÈ´òË°åËΩ¶ÂÆâÂÖ®ÊÄßÂíåÈ©æÈ©∂‰ΩìÈ™åÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÂπøÊ≥õÁöÑÂ∏ÇÂú∫ÂâçÊôØ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> With the advancement of autonomous and assisted driving technologies, higher demands are placed on the ability to understand complex driving scenarios. Multimodal general large models have emerged as a solution for this challenge. However, applying these models in vertical domains involves difficulties such as data collection, model training, and deployment optimization. This paper proposes a comprehensive method for optimizing multimodal models in driving scenarios, including cone detection, traffic light recognition, speed limit recommendation, and intersection alerts. The method covers key aspects such as dynamic prompt optimization, dataset construction, model training, and deployment. Specifically, the dynamic prompt optimization adjusts the prompts based on the input image content to focus on objects affecting the ego vehicle, enhancing the model's task-specific focus and judgment capabilities. The dataset is constructed by combining real and synthetic data to create a high-quality and diverse multimodal training dataset, improving the model's generalization in complex driving environments. In model training, advanced techniques like knowledge distillation, dynamic fine-tuning, and quantization are integrated to reduce storage and computational costs while boosting performance. Experimental results show that this systematic optimization method not only significantly improves the model's accuracy in key tasks but also achieves efficient resource utilization, providing strong support for the practical application of driving scenario perception technologies.

