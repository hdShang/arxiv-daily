---
layout: default
title: "Beyond Perception: Evaluating Abstract Visual Reasoning through Multi-Stage Task"
---

# Beyond Perception: Evaluating Abstract Visual Reasoning through Multi-Stage Task

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21850" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21850v2</a>
  <a href="https://arxiv.org/pdf/2505.21850.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21850v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21850v2', 'Beyond Perception: Evaluating Abstract Visual Reasoning through Multi-Stage Task')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yanbei Jiang, Yihao Ding, Chao Lei, Jiayang Ao, Jey Han Lau, Krista A. Ehinger

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-28 (æ›´æ–°: 2025-05-30)

**å¤‡æ³¨**: Accepted at ACL Findings

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMultiStARåŸºå‡†ä»¥è§£å†³æŠ½è±¡è§†è§‰æ¨ç†è¯„ä¼°é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æŠ½è±¡è§†è§‰æ¨ç†` `å¤šé˜¶æ®µæ¨ç†` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `è¯„ä¼°æŒ‡æ ‡` `å¤æ‚ä»»åŠ¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æŠ½è±¡è§†è§‰æ¨ç†åŸºå‡†ä¸»è¦é›†ä¸­äºå•æ­¥æ¨ç†ï¼Œå¿½è§†äº†æ¨ç†è¿‡ç¨‹çš„å¤šé˜¶æ®µç‰¹æ€§ï¼Œå¯¼è‡´è¯„ä¼°ä¸å…¨é¢ã€‚
2. æœ¬æ–‡æå‡ºMultiStARåŸºå‡†ï¼Œæ—¨åœ¨é€šè¿‡å¤šé˜¶æ®µæ¨ç†è¯„ä¼°æ¨¡å‹åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œå¹¶å¼•å…¥æ–°æŒ‡æ ‡MSEvalä»¥è€ƒè™‘ä¸­é—´æ­¥éª¤çš„æ­£ç¡®æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œç°æœ‰MLLMsåœ¨åŸºæœ¬æ„ŸçŸ¥ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨å¤æ‚è§„åˆ™æ£€æµ‹é˜¶æ®µä»å­˜åœ¨æ˜¾è‘—æŒ‘æˆ˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å½“å‰çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨ä¸€èˆ¬è§†è§‰æ¨ç†æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨æŠ½è±¡è§†è§‰æ¨ç†ï¼ˆAVRï¼‰ä¸Šä»ç„¶æœªè¢«å……åˆ†æ¢ç´¢ã€‚ç°æœ‰çš„AVRåŸºå‡†ä¸»è¦é›†ä¸­äºå•æ­¥æ¨ç†ï¼Œå¼ºè°ƒæœ€ç»ˆç»“æœè€Œå¿½è§†æ¨ç†è¿‡ç¨‹çš„å¤šé˜¶æ®µç‰¹æ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†MultiStARï¼Œä¸€ä¸ªåŸºäºRAVENçš„å¤šé˜¶æ®µAVRåŸºå‡†ï¼Œæ—¨åœ¨è¯„ä¼°ä¸åŒå¤æ‚åº¦ä¸‹çš„æ¨ç†èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œç°æœ‰çš„è¯„ä¼°æŒ‡æ ‡å¦‚å‡†ç¡®ç‡ä»…å…³æ³¨æœ€ç»ˆç»“æœï¼Œè€Œæœªè€ƒè™‘ä¸­é—´æ­¥éª¤çš„æ­£ç¡®æ€§ï¼Œå› æ­¤æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„æŒ‡æ ‡MSEvalï¼Œç»¼åˆè€ƒè™‘ä¸­é—´æ­¥éª¤å’Œæœ€ç»ˆç»“æœçš„æ­£ç¡®æ€§ã€‚é€šè¿‡å¯¹17ç§ä»£è¡¨æ€§çš„é—­æºå’Œå¼€æºMLLMsè¿›è¡Œå…¨é¢å®éªŒï¼Œç»“æœæ˜¾ç¤ºï¼Œå°½ç®¡ç°æœ‰MLLMsåœ¨åŸºæœ¬æ„ŸçŸ¥ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨æ›´å¤æ‚çš„è§„åˆ™æ£€æµ‹é˜¶æ®µä»é¢ä¸´æŒ‘æˆ˜ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰æŠ½è±¡è§†è§‰æ¨ç†åŸºå‡†åœ¨è¯„ä¼°å¤šé˜¶æ®µæ¨ç†èƒ½åŠ›æ—¶çš„ä¸è¶³ï¼Œç‰¹åˆ«æ˜¯ç¼ºä¹å¯¹ä¸­é—´æ¨ç†æ­¥éª¤çš„å…³æ³¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥MultiStARåŸºå‡†ï¼Œå¼ºè°ƒå¤šé˜¶æ®µæ¨ç†çš„é‡è¦æ€§ï¼Œå¹¶æå‡ºMSEvalæŒ‡æ ‡æ¥ç»¼åˆè¯„ä¼°ä¸­é—´æ­¥éª¤å’Œæœ€ç»ˆç»“æœçš„æ­£ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMultiStARåŸºäºRAVENè®¾è®¡ï¼ŒåŒ…å«å¤šä¸ªæ¨ç†é˜¶æ®µï¼Œæ¯ä¸ªé˜¶æ®µé’ˆå¯¹ä¸åŒå¤æ‚åº¦çš„ä»»åŠ¡è¿›è¡Œè¯„ä¼°ï¼Œç¡®ä¿å…¨é¢è€ƒå¯Ÿæ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºMultiStARåŸºå‡†çš„æå‡ºå’ŒMSEvalæŒ‡æ ‡çš„è®¾è®¡ï¼Œä½¿å¾—è¯„ä¼°ä¸ä»…å…³æ³¨æœ€ç»ˆç»“æœï¼Œè¿˜èƒ½åæ˜ æ¨ç†è¿‡ç¨‹çš„å®Œæ•´æ€§ä¸å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œä½¿ç”¨äº†17ç§ä¸åŒçš„MLLMsï¼Œè®¾ç½®äº†å¤šç§å¤æ‚åº¦çš„ä»»åŠ¡ï¼Œå¹¶é€šè¿‡MSEvalè¯„ä¼°ä¸­é—´æ­¥éª¤çš„æ­£ç¡®æ€§ï¼Œç¡®ä¿è¯„ä¼°çš„å…¨é¢æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œç°æœ‰çš„MLLMsåœ¨åŸºæœ¬è§†è§‰æ„ŸçŸ¥ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ï¼Œå‡†ç¡®ç‡è¾¾åˆ°85%ä»¥ä¸Šï¼Œä½†åœ¨å¤æ‚è§„åˆ™æ£€æµ‹é˜¶æ®µçš„è¡¨ç°æ˜æ˜¾ä¸‹é™ï¼Œå‡†ç¡®ç‡ä»…ä¸º50%å·¦å³ï¼Œè¡¨æ˜å…¶åœ¨æŠ½è±¡è§†è§‰æ¨ç†æ–¹é¢çš„å±€é™æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€æœºå™¨äººè§†è§‰ç³»ç»Ÿå’Œæ™ºèƒ½ç›‘æ§ç­‰ï¼Œèƒ½å¤Ÿå¸®åŠ©æé«˜æœºå™¨åœ¨å¤æ‚è§†è§‰æ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚æœªæ¥ï¼ŒMultiStARåŸºå‡†å’ŒMSEvalæŒ‡æ ‡å¯èƒ½æˆä¸ºè¯„ä¼°è§†è§‰æ¨ç†èƒ½åŠ›çš„é‡è¦æ ‡å‡†ï¼Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„ç ”ç©¶è¿›å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Current Multimodal Large Language Models (MLLMs) excel in general visual reasoning but remain underexplored in Abstract Visual Reasoning (AVR), which demands higher-order reasoning to identify abstract rules beyond simple perception. Existing AVR benchmarks focus on single-step reasoning, emphasizing the end result but neglecting the multi-stage nature of reasoning process. Past studies found MLLMs struggle with these benchmarks, but it doesn't explain how they fail. To address this gap, we introduce MultiStAR, a Multi-Stage AVR benchmark, based on RAVEN, designed to assess reasoning across varying levels of complexity. Additionally, existing metrics like accuracy only focus on the final outcomes while do not account for the correctness of intermediate steps. Therefore, we propose a novel metric, MSEval, which considers the correctness of intermediate steps in addition to the final outcomes. We conduct comprehensive experiments on MultiStAR using 17 representative close-source and open-source MLLMs. The results reveal that while existing MLLMs perform adequately on basic perception tasks, they continue to face challenges in more complex rule detection stages.

