---
layout: default
title: A Comprehensive Analysis for Visual Object Hallucination in Large Vision-Language Models
---

# A Comprehensive Analysis for Visual Object Hallucination in Large Vision-Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.01958" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.01958v1</a>
  <a href="https://arxiv.org/pdf/2505.01958.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.01958v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.01958v1', 'A Comprehensive Analysis for Visual Object Hallucination in Large Vision-Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Liqiang Jing, Guiming Hardy Chen, Ehsan Aghazadeh, Xin Eric Wang, Xinya Du

**åˆ†ç±»**: cs.CV, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-04

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ†æè§†è§‰å¯¹è±¡å¹»è§‰é—®é¢˜å¹¶æå‡ºç¼“è§£æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰å¯¹è±¡å¹»è§‰` `å¤šæ¨¡æ€æ¨¡å‹` `è§†è§‰-è¯­è¨€æ¨¡å‹` `æ¨¡å‹è¯„ä¼°` `é”™è¯¯æ¥æºåˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆè§†è§‰å¯¹è±¡ä¿¡æ¯æ—¶å¸¸å‡ºç°å¹»è§‰ç°è±¡ï¼Œå¯¼è‡´ä¸å‡†ç¡®çš„ä¿¡æ¯è¾“å‡ºã€‚
2. æœ¬æ–‡é€šè¿‡åˆ†æLVLMçš„å„ä¸ªç»„æˆéƒ¨åˆ†ï¼Œæå‡ºäº†é’ˆå¯¹æ€§çš„æ–¹æ³•ä»¥ç¼“è§£è§†è§‰å¯¹è±¡å¹»è§‰é—®é¢˜ã€‚
3. ç ”ç©¶å¼€å‘äº†ä¸¤ä¸ªæ–°çš„å¹»è§‰åŸºå‡†ï¼Œåˆ†åˆ«å…³æ³¨å±æ€§ä¸å…³ç³»å¹»è§‰åŠåŸºäºè®¤çŸ¥çš„å¹»è§‰ï¼Œæ¨åŠ¨äº†è¯¥é¢†åŸŸçš„è¯„ä¼°æ ‡å‡†ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰åœ¨å¤šæ¨¡æ€ä»»åŠ¡ä¸­å±•ç°å‡ºå“è¶Šçš„èƒ½åŠ›ï¼Œä½†è§†è§‰å¯¹è±¡å¹»è§‰é—®é¢˜ä¾ç„¶å­˜åœ¨ã€‚è¿™ç§ç°è±¡æŒ‡çš„æ˜¯æ¨¡å‹åŸºäºæŸ¥è¯¢è¾“å…¥ç”Ÿæˆä¸å‡†ç¡®çš„è§†è§‰å¯¹è±¡ç›¸å…³ä¿¡æ¯ï¼Œå¯èƒ½å¯¼è‡´é”™è¯¯ä¿¡æ¯çš„ä¼ æ’­åŠå®‰å…¨æ€§å’Œå¯é æ€§é—®é¢˜ã€‚å°½ç®¡ä»¥å¾€ç ”ç©¶é›†ä¸­åœ¨è§†è§‰å¹»è§‰çš„è¯„ä¼°å’Œç¼“è§£ä¸Šï¼Œä½†å…¶æ ¹æœ¬åŸå› å°šæœªå¾—åˆ°å…¨é¢æ¢è®¨ã€‚æœ¬æ–‡åˆ†æäº†LLaVAç±»LVLMçš„å„ä¸ªç»„æˆéƒ¨åˆ†ï¼ŒåŒ…æ‹¬å¤§å‹è¯­è¨€æ¨¡å‹ã€è§†è§‰éª¨å¹²ç½‘ç»œå’ŒæŠ•å½±å™¨ï¼Œä»¥è¯†åˆ«æ½œåœ¨çš„é”™è¯¯æ¥æºåŠå…¶å½±å“ã€‚åŸºäºè§‚å¯Ÿç»“æœï¼Œæå‡ºäº†é’ˆå¯¹æ¯ä¸ªé—®é¢˜ç»„ä»¶çš„å¹»è§‰ç¼“è§£æ–¹æ³•ï¼Œå¹¶å¼€å‘äº†ä¸¤ä¸ªå¹»è§‰åŸºå‡†ï¼šQA-VisualGenomeå’ŒQA-FB15kã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹ä¸­è§†è§‰å¯¹è±¡å¹»è§‰çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨è¯„ä¼°å’Œç¼“è§£ï¼Œä½†æœªæ·±å…¥æ¢è®¨å…¶æ ¹æœ¬åŸå› ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¯¹LLaVAç±»LVLMçš„ç»„æˆéƒ¨åˆ†è¿›è¡Œæ·±å…¥åˆ†æï¼Œè¯†åˆ«å‡ºå„ç»„ä»¶çš„æ½œåœ¨é”™è¯¯æ¥æºï¼Œå¹¶æå‡ºç›¸åº”çš„ç¼“è§£ç­–ç•¥ï¼Œä»¥æé«˜æ¨¡å‹çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶çš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šå¤§å‹è¯­è¨€æ¨¡å‹ã€è§†è§‰éª¨å¹²ç½‘ç»œå’ŒæŠ•å½±å™¨ã€‚æ¯ä¸ªæ¨¡å—çš„æ€§èƒ½å’Œäº¤äº’å…³ç³»éƒ½è¢«ä»”ç»†åˆ†æï¼Œä»¥æ‰¾å‡ºå¯¼è‡´å¹»è§‰çš„å…·ä½“å› ç´ ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„åˆ›æ–°ä¹‹å¤„åœ¨äºç³»ç»Ÿæ€§åœ°åˆ†æäº†LVLMçš„å„ä¸ªç»„æˆéƒ¨åˆ†ï¼Œå¹¶æå‡ºäº†é’ˆå¯¹æ€§çš„ç¼“è§£æ–¹æ³•ï¼Œè€Œä¸ä»…ä»…æ˜¯å¯¹å¹»è§‰ç°è±¡çš„è¡¨é¢å¤„ç†ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ–¹æ³•è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œå‚æ•°è®¾ç½®ï¼Œä»¥ä¼˜åŒ–æ¯ä¸ªç»„ä»¶çš„æ€§èƒ½ï¼Œç¡®ä¿åœ¨ç”Ÿæˆè§†è§‰ä¿¡æ¯æ—¶å‡å°‘å¹»è§‰çš„å‘ç”Ÿã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„æ–¹æ³•åœ¨QA-VisualGenomeå’ŒQA-FB15kåŸºå‡†ä¸Šæ˜¾è‘—é™ä½äº†è§†è§‰å¯¹è±¡å¹»è§‰çš„å‘ç”Ÿç‡ï¼Œæå‡äº†æ¨¡å‹åœ¨å¤šæ¨¡æ€ä»»åŠ¡ä¸­çš„å‡†ç¡®æ€§ï¼Œå…·ä½“æ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œæ˜¾ç¤ºå‡ºè‰¯å¥½çš„å®ç”¨æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½åŠ©æ‰‹ã€è‡ªåŠ¨é©¾é©¶ã€è™šæ‹Ÿç°å®ç­‰å¤šæ¨¡æ€äº¤äº’ç³»ç»Ÿã€‚é€šè¿‡æé«˜è§†è§‰-è¯­è¨€æ¨¡å‹çš„å¯é æ€§ï¼Œå¯ä»¥å¢å¼ºç”¨æˆ·ä½“éªŒï¼Œå‡å°‘è¯¯å¯¼ä¿¡æ¯çš„ä¼ æ’­ï¼Œæå‡ç³»ç»Ÿçš„å®‰å…¨æ€§å’Œå¯ä¿¡åº¦ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Vision-Language Models (LVLMs) demonstrate remarkable capabilities in multimodal tasks, but visual object hallucination remains a persistent issue. It refers to scenarios where models generate inaccurate visual object-related information based on the query input, potentially leading to misinformation and concerns about safety and reliability. Previous works focus on the evaluation and mitigation of visual hallucinations, but the underlying causes have not been comprehensively investigated. In this paper, we analyze each component of LLaVA-like LVLMs -- the large language model, the vision backbone, and the projector -- to identify potential sources of error and their impact. Based on our observations, we propose methods to mitigate hallucination for each problematic component. Additionally, we developed two hallucination benchmarks: QA-VisualGenome, which emphasizes attribute and relation hallucinations, and QA-FB15k, which focuses on cognition-based hallucinations.

