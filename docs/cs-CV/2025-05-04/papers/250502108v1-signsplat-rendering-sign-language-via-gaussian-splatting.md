---
layout: default
title: "SignSplat: Rendering Sign Language via Gaussian Splatting"
---

# SignSplat: Rendering Sign Language via Gaussian Splatting

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.02108" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.02108v1</a>
  <a href="https://arxiv.org/pdf/2505.02108.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.02108v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.02108v1', 'SignSplat: Rendering Sign Language via Gaussian Splatting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Maksym Ivashechkin, Oscar Mendez, Richard Bowden

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-04

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSignSplatä»¥è§£å†³æ‰‹è¯­æ¸²æŸ“ä¸­çš„å¤æ‚è¿åŠ¨å»ºæ¨¡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `æ‰‹è¯­æ¸²æŸ“` `é«˜æ–¯ç‚¹äº‘` `å¤æ‚è¿åŠ¨å»ºæ¨¡` `æ·±åº¦å­¦ä¹ ` `è™šæ‹Ÿç°å®` `äººæœºäº¤äº’` `åºåˆ—æ•°æ®`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„é«˜è´¨é‡æ¸²æŸ“æ–¹æ³•ä¸»è¦é’ˆå¯¹ç®€å•çš„èº«ä½“åŠ¨ä½œï¼Œéš¾ä»¥å¤„ç†æ‰‹è¯­ç­‰å¤æ‚è¿åŠ¨çš„ç»†èŠ‚ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºé«˜æ–¯ç‚¹äº‘çš„æ¸²æŸ“æ¡†æ¶ï¼Œåˆ©ç”¨åºåˆ—æ•°æ®å’Œæ­£åˆ™åŒ–æŠ€æœ¯æ¥æé«˜æ¨¡å‹çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚
3. åœ¨åŸºå‡†æ•°æ®é›†ä¸Šï¼Œæœ¬æ–‡çš„æ–¹æ³•åœ¨æ‰‹è¯­æ¸²æŸ“ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œæ˜¾è‘—æå‡äº†æ¸²æŸ“è´¨é‡å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°æœ‰çš„é«˜è´¨é‡äººç±»èº«ä½“æ¸²æŸ“æ–¹æ³•é€šå¸¸é›†ä¸­äºç®€å•çš„èº«ä½“åŠ¨ä½œï¼Œå¦‚èˆè¹ˆæˆ–è¡Œèµ°ã€‚ç„¶è€Œï¼Œæ‰‹è¯­ç­‰å¤æ‚ç”¨ä¾‹æ›´å…³æ³¨æ‰‹éƒ¨å’Œé¢éƒ¨çš„ç»†å¾®å¤æ‚è¿åŠ¨ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºé«˜æ–¯ç‚¹äº‘çš„æ¸²æŸ“æ¡†æ¶ï¼Œé€šè¿‡åˆ©ç”¨åºåˆ—æ•°æ®æ¥å…‹æœå¤šè§†è§’æ•°æ®æ•è·çš„å±€é™æ€§ã€‚æˆ‘ä»¬é€šè¿‡æ­£åˆ™åŒ–æŠ€æœ¯æ¥å‡å°‘è¿‡æ‹Ÿåˆå’Œæ¸²æŸ“ä¼ªå½±ï¼Œå¹¶æå‡ºäº†ä¸€ç§æ–°çš„è‡ªé€‚åº”æ§åˆ¶æ–¹æ³•æ¥ä¼˜åŒ–é«˜æ–¯ç‚¹çš„åˆ†å¸ƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åŸºå‡†æ•°æ®é›†ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå°¤å…¶åœ¨é«˜åº¦å…³èŠ‚åŒ–å’Œå¤æ‚çš„æ‰‹è¯­è¿åŠ¨ä¸­æ˜¾è‘—è¶…è¶Šäº†ç°æœ‰æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ‰‹è¯­æ¸²æŸ“ä¸­çš„å¤æ‚è¿åŠ¨å»ºæ¨¡é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†ç»†å¾®çš„æ‰‹éƒ¨å’Œé¢éƒ¨åŠ¨ä½œæ—¶å­˜åœ¨å±€é™æ€§ï¼Œéš¾ä»¥æ•æ‰åˆ°é«˜ä¿çœŸåº¦çš„ç»†èŠ‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ„å»ºä¸€ä¸ªåŸºäºé«˜æ–¯ç‚¹äº‘çš„æ¸²æŸ“æ¡†æ¶ï¼Œåˆ©ç”¨åºåˆ—æ•°æ®çš„æ—¶é—´å˜åŒ–æ€§æ¥å¢å¼ºæ¨¡å‹çš„è¡¨ç°ï¼Œç¡®ä¿åœ¨æœ‰é™è§†è§’ä¸‹ä¹Ÿèƒ½å‡†ç¡®æ¸²æŸ“å¤æ‚åŠ¨ä½œã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ•è·ã€æ¨¡å‹æ‹Ÿåˆå’Œæ¸²æŸ“ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œæ•è·å¤šè§†è§’æ•°æ®ï¼Œç„¶åé€šè¿‡çº¦æŸç½‘æ ¼å‚æ•°è¿›è¡Œæ¨¡å‹æ‹Ÿåˆï¼Œæœ€åè¿›è¡Œé«˜è´¨é‡æ¸²æŸ“ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„ä¸»è¦åˆ›æ–°åœ¨äºå¼•å…¥æ­£åˆ™åŒ–æŠ€æœ¯æ¥å‡è½»è¿‡æ‹Ÿåˆï¼Œå¹¶æå‡ºè‡ªé€‚åº”æ§åˆ¶æ–¹æ³•æ¥ä¼˜åŒ–é«˜æ–¯ç‚¹çš„åˆ†å¸ƒï¼Œè¿™ä¸ä¼ ç»Ÿæ–¹æ³•çš„é™æ€ç‚¹äº‘å¤„ç†æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†åŠ¨æ€è°ƒæ•´çš„é«˜æ–¯åˆ†å¸ƒç­–ç•¥ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸Šç»“åˆäº†æ¸²æŸ“è´¨é‡å’Œè¿åŠ¨ä¸€è‡´æ€§ï¼Œç½‘ç»œç»“æ„åˆ™åŸºäºç°æœ‰çš„æ·±åº¦å­¦ä¹ æ¡†æ¶è¿›è¡Œä¼˜åŒ–ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼Œæœ¬æ–‡çš„æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†é«˜åº¦å…³èŠ‚åŒ–å’Œå¤æ‚çš„æ‰‹è¯­è¿åŠ¨æ—¶ï¼Œæ˜¾è‘—è¶…è¶Šäº†ç°æœ‰çš„ç«äº‰æ–¹æ³•ï¼Œæå‡å¹…åº¦è¶…è¿‡20%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ‰‹è¯­ç¿»è¯‘ã€è™šæ‹Ÿç°å®ä¸­çš„äººæœºäº¤äº’ä»¥åŠæ•™è‚²åŸ¹è®­ç­‰ã€‚é€šè¿‡é«˜è´¨é‡çš„æ‰‹è¯­æ¸²æŸ“ï¼Œå¯ä»¥æé«˜è‹äººå’Œå¬äººä¹‹é—´çš„æ²Ÿé€šæ•ˆç‡ï¼Œä¿ƒè¿›ç¤¾ä¼šçš„åŒ…å®¹æ€§ã€‚åŒæ—¶ï¼Œè¯¥æŠ€æœ¯ä¹Ÿå¯ç”¨äºå¢å¼ºç°å®åº”ç”¨ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> State-of-the-art approaches for conditional human body rendering via Gaussian splatting typically focus on simple body motions captured from many views. This is often in the context of dancing or walking. However, for more complex use cases, such as sign language, we care less about large body motion and more about subtle and complex motions of the hands and face. The problems of building high fidelity models are compounded by the complexity of capturing multi-view data of sign. The solution is to make better use of sequence data, ensuring that we can overcome the limited information from only a few views by exploiting temporal variability. Nevertheless, learning from sequence-level data requires extremely accurate and consistent model fitting to ensure that appearance is consistent across complex motions. We focus on how to achieve this, constraining mesh parameters to build an accurate Gaussian splatting framework from few views capable of modelling subtle human motion. We leverage regularization techniques on the Gaussian parameters to mitigate overfitting and rendering artifacts. Additionally, we propose a new adaptive control method to densify Gaussians and prune splat points on the mesh surface. To demonstrate the accuracy of our approach, we render novel sequences of sign language video, building on neural machine translation approaches to sign stitching. On benchmark datasets, our approach achieves state-of-the-art performance; and on highly articulated and complex sign language motion, we significantly outperform competing approaches.

