---
layout: default
title: "SparSplat: Fast Multi-View Reconstruction with Generalizable 2D Gaussian Splatting"
---

# SparSplat: Fast Multi-View Reconstruction with Generalizable 2D Gaussian Splatting

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.02175" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.02175v1</a>
  <a href="https://arxiv.org/pdf/2505.02175.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.02175v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.02175v1', 'SparSplat: Fast Multi-View Reconstruction with Generalizable 2D Gaussian Splatting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shubhendu Jena, Shishir Reddy Vutukur, Adnane Boukhayma

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-04

**å¤‡æ³¨**: Project page : https://shubhendu-jena.github.io/SparSplat/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSparSplatä»¥è§£å†³ç¨€ç–è§†å›¾ä¸‹çš„3Dé‡å»ºä¸æ–°è§†å›¾åˆæˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `å¤šè§†å›¾ç«‹ä½“é‡å»º` `æ–°è§†å›¾åˆæˆ` `é«˜æ–¯ç‚¹äº‘` `æ·±åº¦å­¦ä¹ ` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç¨€ç–è§†å›¾ä¸‹çš„3Dé‡å»ºå’Œæ–°è§†å›¾åˆæˆé¢ä¸´å‡†ç¡®æ€§å’Œå®æ—¶æ€§ä¸è¶³çš„æŒ‘æˆ˜ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºMVSçš„å­¦ä¹ ç®¡é“ï¼Œé€šè¿‡å›å½’2Dé«˜æ–¯è¡¨é¢å…ƒç´ å‚æ•°ï¼Œå®ç°ç¨€ç–è§†å›¾å›¾åƒçš„3Dé‡å»ºå’ŒNVSã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ¨¡å‹åœ¨DTUåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæ¨ç†é€Ÿåº¦æé«˜è¿‘ä¸¤ä¸ªæ•°é‡çº§ï¼Œè¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä»åœºæ™¯ä¸­æ¢å¤3Dä¿¡æ¯çš„å¤šè§†å›¾ç«‹ä½“é‡å»ºï¼ˆMVSï¼‰å’Œæ–°è§†å›¾åˆæˆï¼ˆNVSï¼‰åœ¨ç¨€ç–è§†å›¾è®¾ç½®ä¸‹å…·æœ‰æŒ‘æˆ˜æ€§ã€‚3Dé«˜æ–¯ç‚¹äº‘ï¼ˆ3DGSï¼‰çš„å‡ºç°ä½¿å¾—å®æ—¶ã€é€¼çœŸçš„NVSæˆä¸ºå¯èƒ½ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºMVSçš„å­¦ä¹ ç®¡é“ï¼Œé€šè¿‡å‰é¦ˆæ–¹å¼å›å½’2Dé«˜æ–¯è¡¨é¢å…ƒç´ å‚æ•°ï¼Œä»ç¨€ç–è§†å›¾å›¾åƒä¸­è¿›è¡Œ3Då½¢çŠ¶é‡å»ºå’ŒNVSã€‚æˆ‘ä»¬çš„æ¨¡å‹åœ¨DTUç¨€ç–3Dé‡å»ºåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œå¹¶åœ¨BlendedMVSå’ŒTanks and Templesæ•°æ®é›†ä¸Šè¡¨ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨ç¨€ç–è§†å›¾ä¸‹è¿›è¡Œ3Dé‡å»ºå’Œæ–°è§†å›¾åˆæˆçš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†ç¨€ç–è§†å›¾æ—¶ï¼Œå¾€å¾€é¢ä¸´å‡†ç¡®æ€§ä¸è¶³å’Œå®æ—¶æ€§å·®çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºMVSçš„å­¦ä¹ ç®¡é“ï¼Œåˆ©ç”¨å‰é¦ˆæ–¹å¼å›å½’2Dé«˜æ–¯è¡¨é¢å…ƒç´ å‚æ•°ï¼Œä»è€Œå®ç°é«˜æ•ˆçš„3Då½¢çŠ¶é‡å»ºå’Œæ–°è§†å›¾åˆæˆã€‚è¯¥è®¾è®¡æ—¨åœ¨æé«˜é‡å»ºçš„å‡†ç¡®æ€§ï¼ŒåŒæ—¶ä¿æŒå®æ—¶æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®è¾“å…¥ã€ç‰¹å¾æå–ã€2Dé«˜æ–¯è¡¨é¢å…ƒç´ å‚æ•°å›å½’å’Œ3Dé‡å»ºä¸NVSæ¨¡å—ã€‚é€šè¿‡æ·±åº¦å­¦ä¹ ç½‘ç»œæå–å¤šè§†å›¾æ·±åº¦è§†è§‰ç‰¹å¾ï¼Œè¿›è€Œè¿›è¡Œå‚æ•°å›å½’ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†2Dé«˜æ–¯ç‚¹äº‘ä¸MVSç»“åˆï¼Œå½¢æˆä¸€ç§é€šç”¨çš„ç¨€ç–3Dé‡å»ºä¸NVSæ–¹æ³•ã€‚è¿™ä¸€æ–¹æ³•åœ¨æ¨ç†é€Ÿåº¦å’Œé‡å»ºç²¾åº¦ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰åŸºäºéšå¼è¡¨ç¤ºçš„ä½“ç§¯æ¸²æŸ“æ–¹æ³•ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œç»“æ„ä¸Šï¼Œé‡‡ç”¨äº†æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œè¿›è¡Œç‰¹å¾æå–ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸ºç»“åˆChamferè·ç¦»å’Œé‡å»ºè¯¯å·®ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹çš„é‡å»ºç²¾åº¦å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ¨¡å‹åœ¨DTUç¨€ç–3Dé‡å»ºåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„Chamferè·ç¦»è¡¨ç°ï¼ŒåŒæ—¶åœ¨æ–°è§†å›¾åˆæˆä»»åŠ¡ä¸­ä¹Ÿè¾¾åˆ°äº†æœ€ä¼˜ç»“æœã€‚ä¸ä¹‹å‰çš„æœ€å…ˆè¿›æ–¹æ³•ç›¸æ¯”ï¼Œæ¨ç†é€Ÿåº¦æé«˜äº†è¿‘ä¸¤ä¸ªæ•°é‡çº§ï¼Œå±•ç¤ºäº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨è®¡ç®—æœºè§†è§‰ã€è™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡å®ç°é«˜æ•ˆçš„3Dé‡å»ºå’Œæ–°è§†å›¾åˆæˆï¼Œå¯ä»¥ä¸ºå®æ—¶åœºæ™¯é‡å»ºã€æ¸¸æˆå¼€å‘å’Œå½±è§†åˆ¶ä½œç­‰æä¾›å¼ºå¤§çš„æŠ€æœ¯æ”¯æŒï¼Œæ¨åŠ¨ç›¸å…³è¡Œä¸šçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recovering 3D information from scenes via multi-view stereo reconstruction (MVS) and novel view synthesis (NVS) is inherently challenging, particularly in scenarios involving sparse-view setups. The advent of 3D Gaussian Splatting (3DGS) enabled real-time, photorealistic NVS. Following this, 2D Gaussian Splatting (2DGS) leveraged perspective accurate 2D Gaussian primitive rasterization to achieve accurate geometry representation during rendering, improving 3D scene reconstruction while maintaining real-time performance. Recent approaches have tackled the problem of sparse real-time NVS using 3DGS within a generalizable, MVS-based learning framework to regress 3D Gaussian parameters. Our work extends this line of research by addressing the challenge of generalizable sparse 3D reconstruction and NVS jointly, and manages to perform successfully at both tasks. We propose an MVS-based learning pipeline that regresses 2DGS surface element parameters in a feed-forward fashion to perform 3D shape reconstruction and NVS from sparse-view images. We further show that our generalizable pipeline can benefit from preexisting foundational multi-view deep visual features. The resulting model attains the state-of-the-art results on the DTU sparse 3D reconstruction benchmark in terms of Chamfer distance to ground-truth, as-well as state-of-the-art NVS. It also demonstrates strong generalization on the BlendedMVS and Tanks and Temples datasets. We note that our model outperforms the prior state-of-the-art in feed-forward sparse view reconstruction based on volume rendering of implicit representations, while offering an almost 2 orders of magnitude higher inference speed.

