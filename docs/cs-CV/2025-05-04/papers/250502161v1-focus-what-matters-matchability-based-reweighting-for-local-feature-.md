---
layout: default
title: Focus What Matters: Matchability-Based Reweighting for Local Feature Matching
---

# Focus What Matters: Matchability-Based Reweighting for Local Feature Matching

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.02161" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.02161v1</a>
  <a href="https://arxiv.org/pdf/2505.02161.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.02161v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.02161v1', 'Focus What Matters: Matchability-Based Reweighting for Local Feature Matching')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Dongyue Li

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-04

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºåŒ¹é…æ€§é‡åŠ æƒçš„å±€éƒ¨ç‰¹å¾åŒ¹é…æ–¹æ³•ä»¥æå‡åŒ¹é…ç²¾åº¦**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)**

**å…³é”®è¯**: `ç‰¹å¾åŒ¹é…` `æ³¨æ„åŠ›æœºåˆ¶` `è®¡ç®—æœºè§†è§‰` `æ·±åº¦å­¦ä¹ ` `å›¾åƒå¤„ç†` `æœºå™¨å­¦ä¹ ` `Transformer`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç‰¹å¾åŒ¹é…æ–¹æ³•åœ¨å¤„ç†æ— å…³åŒºåŸŸæ—¶å­˜åœ¨å†—ä½™å’Œå™ªå£°äº¤äº’ï¼Œå¯¼è‡´åŒ¹é…ç²¾åº¦ä¸‹é™ã€‚
2. æœ¬æ–‡æå‡ºé€šè¿‡åˆ†ç±»åƒç´ ä¸ºå¯åŒ¹é…å’Œä¸å¯åŒ¹é…ï¼Œé‡åŠ æƒæ³¨æ„åŠ›æœºåˆ¶ä»¥æå‡ç‰¹å¾åŒ¹é…çš„æœ‰æ•ˆæ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›æŠ€æœ¯ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€Transformerçš„å…´èµ·ï¼Œè®¸å¤šåŠç¨ å¯†åŒ¹é…æ–¹æ³•é‡‡ç”¨æ³¨æ„åŠ›æœºåˆ¶æå–ç‰¹å¾æè¿°å­ã€‚ç„¶è€Œï¼Œæ³¨æ„åŠ›æƒé‡é€šå¸¸æ˜¯ä»å¤´å­¦ä¹ çš„ï¼Œè¿™å¯èƒ½å¯¼è‡´å†—ä½™å’Œæ¥è‡ªæ— å…³åŒºåŸŸçš„å™ªå£°äº¤äº’ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ³¨æ„åŠ›é‡åŠ æƒæœºåˆ¶ï¼Œé¦–å…ˆå°†æ‰€æœ‰åƒç´ åˆ†ç±»ä¸ºå¯åŒ¹é…å’Œä¸å¯åŒ¹é…ä¸¤ç±»ï¼ŒæœŸæœ›å¯åŒ¹é…åƒç´ è·å¾—æ›´é«˜çš„æ³¨æ„åŠ›æƒé‡ï¼Œè€Œä¸å¯åŒ¹é…çš„åˆ™è¢«é™æƒã€‚è¯¥æœºåˆ¶é€šè¿‡å¼•å…¥å¯å­¦ä¹ çš„åç½®é¡¹å’ŒåŒ¹é…æ€§ä¿¡æ¯çš„é‡ç¼©æ”¾ï¼ŒåŠ¨æ€è°ƒæ•´æ³¨æ„åŠ›æœºåˆ¶çš„å†…éƒ¨åŠ æƒæ–¹æ¡ˆå’Œè¾“å‡ºè¡¨ç¤ºçš„å¹…åº¦ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸‰ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå‡ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰ç‰¹å¾åŒ¹é…æ–¹æ³•ä¸­æ³¨æ„åŠ›æƒé‡å­¦ä¹ è¿‡ç¨‹ä¸­çš„å†—ä½™å’Œå™ªå£°é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆåŒºåˆ†å¯åŒ¹é…å’Œä¸å¯åŒ¹é…çš„åƒç´ ï¼Œå¯¼è‡´åŒ¹é…ç²¾åº¦ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºåŒ¹é…æ€§é‡åŠ æƒçš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œé¦–å…ˆå°†åƒç´ åˆ†ä¸ºå¯åŒ¹é…å’Œä¸å¯åŒ¹é…ä¸¤ç±»ï¼Œä»¥æ­¤æ¥è°ƒæ•´æ³¨æ„åŠ›æƒé‡ï¼Œä»è€Œæå‡ç‰¹å¾åŒ¹é…çš„å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯åƒç´ åˆ†ç±»æ¨¡å—ï¼Œå°†æ‰€æœ‰åƒç´ åˆ†ä¸ºå¯åŒ¹é…å’Œä¸å¯åŒ¹é…ï¼›å…¶æ¬¡æ˜¯é‡åŠ æƒæ¨¡å—ï¼Œé€šè¿‡å¼•å…¥å¯å­¦ä¹ çš„åç½®é¡¹å’Œç‰¹å¾é‡ç¼©æ”¾æ¥è°ƒæ•´æ³¨æ„åŠ›æƒé‡å’Œè¾“å‡ºã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†å¯å­¦ä¹ çš„åç½®é¡¹å’ŒåŒ¹é…æ€§ä¿¡æ¯çš„é‡ç¼©æ”¾ï¼Œè¿™ä½¿å¾—æ³¨æ„åŠ›æœºåˆ¶èƒ½å¤ŸåŠ¨æ€è°ƒæ•´å†…éƒ¨åŠ æƒæ–¹æ¡ˆå’Œè¾“å‡ºè¡¨ç¤ºçš„å¹…åº¦ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—æé«˜äº†åŒ¹é…ç²¾åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œåç½®é¡¹åœ¨softmaxæ“ä½œä¹‹å‰æ³¨å…¥ï¼Œä»¥æ ¹æ®æŸ¥è¯¢-å…³é”®ç‚¹äº¤äº’çš„ç½®ä¿¡åº¦é€‰æ‹©æ€§è°ƒæ•´æ³¨æ„åŠ›åˆ†æ•°ï¼›ç‰¹å¾é‡ç¼©æ”¾åˆ™åœ¨æ³¨æ„åŠ›è®¡ç®—åè¿›è¡Œï¼Œä»¥è°ƒèŠ‚æ¯ä¸ªå€¼å‘é‡åœ¨æœ€ç»ˆè¾“å‡ºä¸­çš„å½±å“åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨ä¸‰ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå‡ä¼˜äºç°æœ‰æœ€å…ˆè¿›æŠ€æœ¯ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°5%è‡³10%ã€‚è¯¥æ–¹æ³•åœ¨å¤„ç†å¤æ‚åœºæ™¯æ—¶è¡¨ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è®¡ç®—æœºè§†è§‰ä¸­çš„å›¾åƒåŒ¹é…ã€ä¸‰ç»´é‡å»ºå’Œæœºå™¨äººå¯¼èˆªç­‰ã€‚é€šè¿‡æå‡ç‰¹å¾åŒ¹é…çš„å‡†ç¡®æ€§ï¼Œèƒ½å¤Ÿåœ¨å®é™…åœºæ™¯ä¸­å®ç°æ›´é«˜æ•ˆçš„ç‰©ä½“è¯†åˆ«å’Œå®šä½ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Since the rise of Transformers, many semi-dense matching methods have adopted attention mechanisms to extract feature descriptors. However, the attention weights, which capture dependencies between pixels or keypoints, are often learned from scratch. This approach can introduce redundancy and noisy interactions from irrelevant regions, as it treats all pixels or keypoints equally. Drawing inspiration from keypoint selection processes, we propose to first classify all pixels into two categories: matchable and non-matchable. Matchable pixels are expected to receive higher attention weights, while non-matchable ones are down-weighted. In this work, we propose a novel attention reweighting mechanism that simultaneously incorporates a learnable bias term into the attention logits and applies a matchability-informed rescaling to the input value features. The bias term, injected prior to the softmax operation, selectively adjusts attention scores based on the confidence of query-key interactions. Concurrently, the feature rescaling acts post-attention by modulating the influence of each value vector in the final output. This dual design allows the attention mechanism to dynamically adjust both its internal weighting scheme and the magnitude of its output representations. Extensive experiments conducted on three benchmark datasets validate the effectiveness of our method, consistently outperforming existing state-of-the-art approaches.

