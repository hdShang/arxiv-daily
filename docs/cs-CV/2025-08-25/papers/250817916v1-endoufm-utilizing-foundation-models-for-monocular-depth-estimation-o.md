---
layout: default
title: "EndoUFM: Utilizing Foundation Models for Monocular depth estimation of endoscopic images"
---

# EndoUFM: Utilizing Foundation Models for Monocular depth estimation of endoscopic images

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.17916" class="toolbar-btn" target="_blank">üìÑ arXiv: 2508.17916v1</a>
  <a href="https://arxiv.org/pdf/2508.17916.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.17916v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.17916v1', 'EndoUFM: Utilizing Foundation Models for Monocular depth estimation of endoscopic images')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Xinning Yao, Bo Liu, Bojian Li, Jingjing Wang, Jinghua Yue, Fugen Zhou

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-25

**Â§áÊ≥®**: 12 pages

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫EndoUFM‰ª•Ëß£ÂÜ≥ÂÜÖÁ™•ÈïúÂõæÂÉèÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°` `ÂÜÖÁ™•ÈïúÂõæÂÉè` `Âü∫Á°ÄÊ®°Âûã` `ÂæÆÂàõÊâãÊúØ` `Ê∑±Â∫¶Â≠¶‰π†` `Ëá™ÈÄÇÂ∫îÂæÆË∞É` `Âπ≥ÊªëÊçüÂ§±`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°ÊñπÊ≥ïÂú®Â§çÊùÇÁöÑÊâãÊúØÁéØÂ¢É‰∏≠ÂèóÈôê‰∫éÂÖâÁÖßÂèòÂåñÂíåÁ∫πÁêÜÂ§çÊùÇÊÄßÔºåÂØºËá¥ÊÄßËÉΩ‰∏çË∂≥„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫EndoUFMÊ°ÜÊû∂ÔºåÈÄöËøáÊï¥ÂêàÂèåÈáçÂü∫Á°ÄÊ®°ÂûãÂíåËá™ÈÄÇÂ∫îÂæÆË∞ÉÁ≠ñÁï•ÔºåÊèêÂçáÂÜÖÁ™•ÈïúÂõæÂÉèÁöÑÊ∑±Â∫¶‰º∞ËÆ°ËÉΩÂäõ„ÄÇ
3. Âú®SCARED„ÄÅHamlyn„ÄÅSERV-CTÂíåEndoNeRFÊï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåËØ•ÊñπÊ≥ïÂú®ÊÄßËÉΩ‰∏äËææÂà∞‰∫ÜÊúÄÂÖàËøõÊ∞¥Âπ≥Ôºå‰∏îÊ®°ÂûãËßÑÊ®°È´òÊïà„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Ê∑±Â∫¶‰º∞ËÆ°ÊòØÂæÆÂàõÂÜÖÁ™•ÈïúÊâãÊúØ‰∏≠3DÈáçÂª∫ÁöÑÂü∫Á°ÄÁªÑÊàêÈÉ®ÂàÜ„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÁöÑÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°ÊäÄÊúØÂú®ÊâãÊúØÁéØÂ¢É‰∏≠Áî±‰∫éÂÖâÁÖßÂèòÂåñÂíåÂ§çÊùÇÁ∫πÁêÜÁöÑÂΩ±ÂìçÔºåË°®Áé∞Âá∫ÊúâÈôêÁöÑÊÄßËÉΩ„ÄÇÂ∞ΩÁÆ°Âº∫Â§ßÁöÑËßÜËßâÂü∫Á°ÄÊ®°ÂûãÊèê‰æõ‰∫ÜÊúâÂ∏åÊúõÁöÑËß£ÂÜ≥ÊñπÊ°àÔºå‰ΩÜÂÖ∂Âú®Ëá™ÁÑ∂ÂõæÂÉè‰∏äÁöÑËÆ≠ÁªÉÂØºËá¥Âú®ÂÜÖÁ™•ÈïúÂ∫îÁî®‰∏≠Â≠òÂú®ÊòæËëóÁöÑÈ¢ÜÂüüÈÄÇÂ∫îÊÄßÈôêÂà∂ÂíåËØ≠‰πâÊÑüÁü•‰∏çË∂≥„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∫ÜEndoUFMÔºå‰∏Ä‰∏™Êó†ÁõëÁù£ÁöÑÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°Ê°ÜÊû∂ÔºåÂàõÊñ∞ÊÄßÂú∞Êï¥Âêà‰∫ÜÂèåÈáçÂü∫Á°ÄÊ®°Âûã‰ª•Â¢ûÂº∫ÊâãÊúØÂú∫ÊôØÁöÑÊ∑±Â∫¶‰º∞ËÆ°ÊÄßËÉΩ„ÄÇËØ•Ê°ÜÊû∂ÈááÁî®‰∫ÜÈöèÊú∫ÂêëÈáè‰ΩéÁß©ÈÄÇÂ∫îÔºàRVLoRAÔºâÁöÑËá™ÈÄÇÂ∫îÂæÆË∞ÉÁ≠ñÁï•ÔºåÂπ∂Âü∫‰∫éÊ∑±Â∫¶ÂèØÂàÜÁ¶ªÂç∑ÁßØÁöÑÊÆãÂ∑ÆÂùóÔºàRes-DSCÔºâÊù•ÊîπÂñÑÁªÜÁ≤íÂ∫¶Â±ÄÈÉ®ÁâπÂæÅÁöÑÊçïÊçâ„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ËÆæËÆ°‰∫Ü‰∏ÄÁßçÊé©ËÜúÂºïÂØºÁöÑÂπ≥ÊªëÊçüÂ§±Ôºå‰ª•Â¢ûÂº∫Ëß£ÂâñÁªÑÁªáÁªìÊûÑÂÜÖÁöÑÊ∑±Â∫¶‰∏ÄËá¥ÊÄß„ÄÇÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÂêåÊó∂‰øùÊåÅ‰∫ÜÈ´òÊïàÁöÑÊ®°ÂûãËßÑÊ®°„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨Á†îÁ©∂Êó®Âú®Ëß£ÂÜ≥ÂÜÖÁ™•ÈïúÂõæÂÉèÁöÑÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°ÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®Â§çÊùÇÁöÑÊâãÊúØÁéØÂ¢É‰∏≠Ë°®Áé∞‰∏ç‰Ω≥Ôºå‰∏ªË¶ÅÁî±‰∫éÂÖâÁÖßÂèòÂåñÂíåÁ∫πÁêÜÂ§çÊùÇÊÄßÂØºËá¥ÁöÑÊÄßËÉΩÈôêÂà∂„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöEndoUFMÊ°ÜÊû∂ÈÄöËøáÊï¥ÂêàÂèåÈáçÂü∫Á°ÄÊ®°ÂûãÔºåÂà©Áî®È¢ÑÂ≠¶‰π†ÁöÑÂÖàÈ™åÁü•ËØÜÊù•Â¢ûÂº∫Ê∑±Â∫¶‰º∞ËÆ°ÊÄßËÉΩÔºåÂêåÊó∂ÈááÁî®Ëá™ÈÄÇÂ∫îÂæÆË∞ÉÁ≠ñÁï•‰ª•ÊèêÈ´òÊ®°ÂûãÁöÑÈÄÇÂ∫îÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•Ê°ÜÊû∂ÂåÖÊã¨‰∏§‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÈ¶ñÂÖàÊòØÂü∫‰∫éÂèåÈáçÂü∫Á°ÄÊ®°ÂûãÁöÑÊ∑±Â∫¶‰º∞ËÆ°Ê®°ÂùóÔºåÂÖ∂Ê¨°ÊòØÈááÁî®ÈöèÊú∫ÂêëÈáè‰ΩéÁß©ÈÄÇÂ∫îÔºàRVLoRAÔºâËøõË°åËá™ÈÄÇÂ∫îÂæÆË∞ÉÁöÑÊ®°Âùó„ÄÇÊ≠§Â§ñÔºåËÆæËÆ°‰∫ÜÊé©ËÜúÂºïÂØºÁöÑÂπ≥ÊªëÊçüÂ§±‰ª•Á°Æ‰øùÊ∑±Â∫¶‰∏ÄËá¥ÊÄß„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éÂ∞ÜÂèåÈáçÂü∫Á°ÄÊ®°Âûã‰∏éËá™ÈÄÇÂ∫îÂæÆË∞ÉÁ≠ñÁï•Áõ∏ÁªìÂêàÔºåÊòæËëóÊèêÈ´ò‰∫ÜÊ®°ÂûãÂú®Â§çÊùÇÊâãÊúØÂú∫ÊôØ‰∏≠ÁöÑÈÄÇÂ∫îÊÄßÂíåÊ∑±Â∫¶‰º∞ËÆ°Á≤æÂ∫¶„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÈááÁî®‰∫ÜÂü∫‰∫éÊ∑±Â∫¶ÂèØÂàÜÁ¶ªÂç∑ÁßØÁöÑÊÆãÂ∑ÆÂùóÔºàRes-DSCÔºâÊù•ÊçïÊçâÁªÜÁ≤íÂ∫¶Â±ÄÈÉ®ÁâπÂæÅÔºåÂπ∂ËÆæËÆ°‰∫ÜÊé©ËÜúÂºïÂØºÁöÑÂπ≥ÊªëÊçüÂ§±ÂáΩÊï∞Ôºå‰ª•Â¢ûÂº∫Ëß£ÂâñÁªìÊûÑÂÜÖÁöÑÊ∑±Â∫¶‰∏ÄËá¥ÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®SCARED„ÄÅHamlyn„ÄÅSERV-CTÂíåEndoNeRFÊï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåEndoUFMÊñπÊ≥ïÂú®Ê∑±Â∫¶‰º∞ËÆ°ÊÄßËÉΩ‰∏äËææÂà∞‰∫ÜÊúÄÂÖàËøõÊ∞¥Âπ≥ÔºåÁõ∏ËæÉ‰∫éÂü∫Á∫øÊñπÊ≥ïÊúâÊòæËëóÊèêÂçáÔºåÂÖ∑‰ΩìÊÄßËÉΩÊï∞ÊçÆÊú™Êèê‰æõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨ÂæÆÂàõÊâãÊúØ‰∏≠ÁöÑÊ∑±Â∫¶ÊÑüÁü•„ÄÅÂ¢ûÂº∫Áé∞ÂÆûÂíåÂØºËà™Á≥ªÁªü„ÄÇÈÄöËøáÊèêÈ´òÂ§ñÁßëÂåªÁîüÂú®ÊâãÊúØËøáÁ®ã‰∏≠ÁöÑÁ©∫Èó¥ÊÑüÁü•ËÉΩÂäõÔºåEndoUFMÊúâÂä©‰∫éÊèêÂçáÊâãÊúØÁöÑÁ≤æÁ°ÆÊÄßÂíåÂÆâÂÖ®ÊÄßÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑ‰∏¥Â∫ä‰ª∑ÂÄºÂíåÊú™Êù•ÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Depth estimation is a foundational component for 3D reconstruction in minimally invasive endoscopic surgeries. However, existing monocular depth estimation techniques often exhibit limited performance to the varying illumination and complex textures of the surgical environment. While powerful visual foundation models offer a promising solution, their training on natural images leads to significant domain adaptability limitations and semantic perception deficiencies when applied to endoscopy. In this study, we introduce EndoUFM, an unsupervised monocular depth estimation framework that innovatively integrating dual foundation models for surgical scenes, which enhance the depth estimation performance by leveraging the powerful pre-learned priors. The framework features a novel adaptive fine-tuning strategy that incorporates Random Vector Low-Rank Adaptation (RVLoRA) to enhance model adaptability, and a Residual block based on Depthwise Separable Convolution (Res-DSC) to improve the capture of fine-grained local features. Furthermore, we design a mask-guided smoothness loss to enforce depth consistency within anatomical tissue structures. Extensive experiments on the SCARED, Hamlyn, SERV-CT, and EndoNeRF datasets confirm that our method achieves state-of-the-art performance while maintaining an efficient model size. This work contributes to augmenting surgeons' spatial perception during minimally invasive procedures, thereby enhancing surgical precision and safety, with crucial implications for augmented reality and navigation systems.

