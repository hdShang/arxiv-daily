---
layout: default
title: Bridging the Gap Between Multimodal Foundation Models and World Models
---

# Bridging the Gap Between Multimodal Foundation Models and World Models

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.03727" target="_blank" class="toolbar-btn">arXiv: 2510.03727v1</a>
    <a href="https://arxiv.org/pdf/2510.03727.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.03727v1" 
            onclick="toggleFavorite(this, '2510.03727v1', 'Bridging the Gap Between Multimodal Foundation Models and World Models')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Xuehai He

**ÂàÜÁ±ª**: cs.AI, cs.CL, cs.CV, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-04

**Â§áÊ≥®**: PhD thesis

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**Âº•ÂêàÂ§öÊ®°ÊÄÅÂü∫Á°ÄÊ®°Âûã‰∏é‰∏ñÁïåÊ®°Âûã‰πãÈó¥ÁöÑÂ∑ÆË∑ùÔºåÊèêÂçáÊé®ÁêÜ‰∏éÁîüÊàêËÉΩÂäõ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±ÂÖ´ÔºöÁâ©ÁêÜÂä®Áîª (Physics-based Animation)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `‰∏ñÁïåÊ®°Âûã` `Âõ†ÊûúÊé®ÁêÜ` `Âèç‰∫ãÂÆûÊé®ÁêÜ` `Êó∂Á©∫Êé®ÁêÜ` `ÂèØÊéßÁîüÊàê` `4DÁîüÊàê`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÂ§öÊ®°ÊÄÅÂü∫Á°ÄÊ®°ÂûãÁº∫‰πèÂèç‰∫ãÂÆûÊé®ÁêÜ„ÄÅÂä®ÊÄÅÊ®°ÊãüÂíåÊó∂Á©∫ÁêÜËß£Á≠âËÉΩÂäõÔºåÈöæ‰ª•ËÉú‰ªª‰∏ñÁïåÊ®°ÂûãÁöÑËßíËâ≤„ÄÇ
2. Êú¨ÊñáÈÄöËøáÊèêÂçáÊé®ÁêÜËÉΩÂäõÂíåÂºïÂÖ•ÁªìÊûÑÂåñÊé®ÁêÜÊäÄËÉΩÔºåÂ¢ûÂº∫Â§öÊ®°ÊÄÅÂü∫Á°ÄÊ®°ÂûãÂØπËßÜËßâÂíåÊñáÊú¨Êï∞ÊçÆÊ∑±Â±ÇÂÖ≥Á≥ªÁöÑÁêÜËß£„ÄÇ
3. Êú¨ÊñáÊèêÂá∫‰∫ÜÊñ∞ÁöÑÊ°ÜÊû∂ÔºåÈÄöËøáÂú∫ÊôØÂõæ„ÄÅÂ§öÊ®°ÊÄÅÊù°‰ª∂ÂíåÂØπÈΩêÁ≠ñÁï•ÔºåÂÆûÁé∞ÁªìÊûÑÂåñÂíåÂèØÊéßÁöÑÂõæÂÉè„ÄÅËßÜÈ¢ë‰ª•Âèä4DÂÜÖÂÆπÁîüÊàê„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊó®Âú®Âº•ÂêàÂ§öÊ®°ÊÄÅÂü∫Á°ÄÊ®°Âûã(MFMs)‰∏é‰∏ñÁïåÊ®°Âûã‰πãÈó¥ÁöÑÂ∑ÆË∑ù„ÄÇÂΩìÂâçMFMsÂú®Âèç‰∫ãÂÆûÊé®ÁêÜ„ÄÅÂä®ÊÄÅÊ®°Êãü„ÄÅÊó∂Á©∫‰ø°ÊÅØÁêÜËß£„ÄÅÂèØÊéßËßÜËßâÁªìÊûúÁîüÊàê‰ª•ÂèäÂ§öÊñπÈù¢Êé®ÁêÜÁ≠âÂÖ≥ÈîÆËÉΩÂäõ‰∏äÂ≠òÂú®‰∏çË∂≥ÔºåÈöæ‰ª•‰Ωú‰∏∫ÊúâÊïàÁöÑ‰∏ñÁïåÊ®°Âûã„ÄÇÊú¨ÊñáÈÄöËøáÂà§Âà´‰ªªÂä°ÊèêÂçáMFMsÁöÑÊé®ÁêÜËÉΩÂäõÔºåÂπ∂Ëµã‰∫àÂÖ∂ÁªìÊûÑÂåñÊé®ÁêÜÊäÄËÉΩÔºåÂ¶ÇÂõ†ÊûúÊé®Êñ≠„ÄÅÂèç‰∫ãÂÆûÊÄùËÄÉÂíåÊó∂Á©∫Êé®ÁêÜÔºå‰ΩøÂÖ∂ËÉΩÂ§üË∂ÖË∂äË°®Èù¢Áõ∏ÂÖ≥ÊÄßÔºåÁêÜËß£ËßÜËßâÂíåÊñáÊú¨Êï∞ÊçÆ‰∏≠Êõ¥Ê∑±Â±ÇÊ¨°ÁöÑÂÖ≥Á≥ª„ÄÇÊ≠§Â§ñÔºåÊú¨ÊñáËøòÊé¢Á¥¢‰∫ÜMFMsÂú®ÂõæÂÉèÂíåËßÜÈ¢ëÊ®°ÊÄÅ‰∏≠ÁöÑÁîüÊàêËÉΩÂäõÔºåÂºïÂÖ•‰∫ÜÁî®‰∫éÁªìÊûÑÂåñÂíåÂèØÊéßÁîüÊàêÁöÑÊñ∞Ê°ÜÊû∂ÔºåÁªìÂêàÂú∫ÊôØÂõæ„ÄÅÂ§öÊ®°ÊÄÅÊù°‰ª∂ÂíåÂ§öÊ®°ÊÄÅÂØπÈΩêÁ≠ñÁï•Êù•ÊåáÂØºÁîüÊàêËøáÁ®ãÔºåÁ°Æ‰øù‰∏éÈ´òÂ±ÇËØ≠‰πâÂíåÁªÜÁ≤íÂ∫¶Áî®Êà∑ÊÑèÂõæÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÊúÄÂêéÔºåÂ∞ÜËøô‰∫õÊäÄÊúØÊâ©Â±ïÂà∞ÂèØÊéßÁöÑ4DÁîüÊàêÔºåÂÆûÁé∞ÈöèÊó∂Èó¥ÂíåÁ©∫Èó¥ÂèòÂåñÁöÑ‰∫§‰∫íÂºè„ÄÅÂèØÁºñËæëÂíåÂèØÂèòÂΩ¢ÁöÑÂØπË±°ÂêàÊàê„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÂΩìÂâçÁöÑÂ§öÊ®°ÊÄÅÂü∫Á°ÄÊ®°ÂûãÔºàMFMsÔºâËôΩÁÑ∂Âú®Â§öÊ®°ÊÄÅÁêÜËß£ÂíåÁîüÊàêÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤Ôºå‰ΩÜÂÆÉ‰ª¨Áº∫‰πè‰∏ñÁïåÊ®°ÂûãÊâÄÂøÖÈúÄÁöÑÂÖ≥ÈîÆËÉΩÂäõÔºå‰æãÂ¶ÇËøõË°åÂèç‰∫ãÂÆûÊé®ÁêÜ„ÄÅÊ®°ÊãüÂä®ÊÄÅËøáÁ®ã„ÄÅÁêÜËß£Êó∂Á©∫‰ø°ÊÅØ„ÄÅÊéßÂà∂ÁîüÊàêËßÜËßâÁªìÊûú‰ª•ÂèäÊâßË°åÂ§öÊñπÈù¢ÁöÑÊé®ÁêÜ„ÄÇÁé∞ÊúâÁöÑMFMs‰∏ªË¶ÅÂÖ≥Ê≥®Ë°®Èù¢Áõ∏ÂÖ≥ÊÄßÔºåÈöæ‰ª•ÊçïÊçâÊï∞ÊçÆ‰∏≠Êõ¥Ê∑±Â±ÇÊ¨°ÁöÑÂõ†ÊûúÂÖ≥Á≥ªÂíåÂä®ÊÄÅÂèòÂåñÔºåÈôêÂà∂‰∫ÜÂÖ∂Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑÂ∫îÁî®„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊú¨ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÂ¢ûÂº∫MFMsÁöÑÊé®ÁêÜËÉΩÂäõÂíåÁîüÊàêËÉΩÂäõÔºå‰ΩøÂÖ∂Êõ¥Êé•Ëøë‰∏ñÁïåÊ®°Âûã„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÈ¶ñÂÖàÈÄöËøáÂà§Âà´‰ªªÂä°ÂíåÁªìÊûÑÂåñÊé®ÁêÜÊäÄËÉΩÔºàÂ¶ÇÂõ†ÊûúÊé®Êñ≠„ÄÅÂèç‰∫ãÂÆûÊÄùËÄÉÂíåÊó∂Á©∫Êé®ÁêÜÔºâÊù•ÊèêÂçáMFMsÁöÑÊé®ÁêÜËÉΩÂäõÔºå‰ΩøÂÖ∂ËÉΩÂ§üÁêÜËß£ËßÜËßâÂíåÊñáÊú¨Êï∞ÊçÆ‰∏≠Êõ¥Ê∑±Â±ÇÊ¨°ÁöÑÂÖ≥Á≥ª„ÄÇÁÑ∂ÂêéÔºåÈÄöËøáÂºïÂÖ•Êñ∞ÁöÑÊ°ÜÊû∂ÔºåÁªìÂêàÂú∫ÊôØÂõæ„ÄÅÂ§öÊ®°ÊÄÅÊù°‰ª∂ÂíåÂ§öÊ®°ÊÄÅÂØπÈΩêÁ≠ñÁï•ÔºåÂÆûÁé∞ÁªìÊûÑÂåñÂíåÂèØÊéßÁöÑÂõæÂÉè„ÄÅËßÜÈ¢ë‰ª•Âèä4DÂÜÖÂÆπÁîüÊàê„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊú¨ÊñáÊèêÂá∫ÁöÑÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰∏§‰∏™ÈÉ®ÂàÜÔºöÊé®ÁêÜËÉΩÂäõÂ¢ûÂº∫ÂíåÁîüÊàêËÉΩÂäõÂ¢ûÂº∫„ÄÇÊé®ÁêÜËÉΩÂäõÂ¢ûÂº∫ÈÉ®ÂàÜ‰∏ªË¶ÅÈÄöËøáËÆ≠ÁªÉMFMsÊâßË°åÂà§Âà´‰ªªÂä°ÔºåÂπ∂Ëµã‰∫àÂÖ∂ÁªìÊûÑÂåñÊé®ÁêÜÊäÄËÉΩÊù•ÂÆûÁé∞„ÄÇÁîüÊàêËÉΩÂäõÂ¢ûÂº∫ÈÉ®ÂàÜÂàôÈÄöËøáÂºïÂÖ•Êñ∞ÁöÑÁîüÊàêÊ°ÜÊû∂ÔºåÁªìÂêàÂú∫ÊôØÂõæ„ÄÅÂ§öÊ®°ÊÄÅÊù°‰ª∂ÂíåÂ§öÊ®°ÊÄÅÂØπÈΩêÁ≠ñÁï•Êù•ÊåáÂØºÁîüÊàêËøáÁ®ã„ÄÇÂØπ‰∫é4DÁîüÊàêÔºåÂàôÊòØÂú®Ê≠§Âü∫Á°Ä‰∏äËøõ‰∏ÄÊ≠•Êâ©Â±ïÔºåÂÆûÁé∞ÈöèÊó∂Èó¥ÂíåÁ©∫Èó¥ÂèòÂåñÁöÑ‰∫§‰∫íÂºè„ÄÅÂèØÁºñËæëÂíåÂèØÂèòÂΩ¢ÁöÑÂØπË±°ÂêàÊàê„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊú¨ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜÁªìÊûÑÂåñÊé®ÁêÜÊäÄËÉΩÂºïÂÖ•Âà∞Â§öÊ®°ÊÄÅÂü∫Á°ÄÊ®°Âûã‰∏≠Ôºå‰ΩøÂÖ∂ËÉΩÂ§üË∂ÖË∂äË°®Èù¢Áõ∏ÂÖ≥ÊÄßÔºåÁêÜËß£Êï∞ÊçÆ‰∏≠Êõ¥Ê∑±Â±ÇÊ¨°ÁöÑÂõ†ÊûúÂÖ≥Á≥ªÂíåÂä®ÊÄÅÂèòÂåñ„ÄÇÊ≠§Â§ñÔºåÊú¨ÊñáËøòÊèêÂá∫‰∫ÜÊñ∞ÁöÑÁîüÊàêÊ°ÜÊû∂ÔºåÈÄöËøáÁªìÂêàÂú∫ÊôØÂõæ„ÄÅÂ§öÊ®°ÊÄÅÊù°‰ª∂ÂíåÂ§öÊ®°ÊÄÅÂØπÈΩêÁ≠ñÁï•ÔºåÂÆûÁé∞‰∫ÜÁªìÊûÑÂåñÂíåÂèØÊéßÁöÑÂõæÂÉè„ÄÅËßÜÈ¢ë‰ª•Âèä4DÂÜÖÂÆπÁîüÊàê„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Êé®ÁêÜËÉΩÂäõÂ¢ûÂº∫ÊñπÈù¢ÔºåÂÖ≥ÈîÆÂú®‰∫éËÆæËÆ°ÂêàÈÄÇÁöÑÂà§Âà´‰ªªÂä°ÂíåÁªìÊûÑÂåñÊé®ÁêÜÊäÄËÉΩËÆ≠ÁªÉÊñπÊ≥ï„ÄÇÂú®ÁîüÊàêËÉΩÂäõÂ¢ûÂº∫ÊñπÈù¢ÔºåÂÖ≥ÈîÆÂú®‰∫éÂ¶Ç‰ΩïÊúâÊïàÂú∞ÁªìÂêàÂú∫ÊôØÂõæ„ÄÅÂ§öÊ®°ÊÄÅÊù°‰ª∂ÂíåÂ§öÊ®°ÊÄÅÂØπÈΩêÁ≠ñÁï•Ôºå‰ª•ÂèäÂ¶Ç‰ΩïÂ∞ÜËøô‰∫õÊäÄÊúØÊâ©Â±ïÂà∞4DÁîüÊàê„ÄÇÂÖ∑‰ΩìÁöÑÂèÇÊï∞ËÆæÁΩÆ„ÄÅÊçüÂ§±ÂáΩÊï∞ÂíåÁΩëÁªúÁªìÊûÑÁ≠âÊäÄÊúØÁªÜËäÇÂú®ËÆ∫Êñá‰∏≠Â∫îËØ•ÊúâÊõ¥ËØ¶ÁªÜÁöÑÊèèËø∞ÔºàÊú™Áü•Ôºâ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Áî±‰∫éËÆ∫ÊñáÊëòË¶ÅÊú™Êèê‰æõÂÖ∑‰ΩìÁöÑÂÆûÈ™åÁªìÊûúÔºåÂõ†Ê≠§ÂÆûÈ™å‰∫ÆÁÇπÊú™Áü•„ÄÇ‰ΩÜÂèØ‰ª•Êé®ÊµãÔºåÂÆûÈ™åÈÉ®ÂàÜÂ∫îËØ•‰ºöÂ±ïÁ§∫Âú®ÂêÑÁßçÊé®ÁêÜ‰ªªÂä°ÂíåÁîüÊàê‰ªªÂä°‰∏äÁöÑÊÄßËÉΩÊèêÂçáÔºåÂπ∂‰∏éÂÖ∂‰ªñÂü∫Á∫øÊ®°ÂûãËøõË°åÂØπÊØîÔºå‰ª•È™åËØÅÊú¨ÊñáÊèêÂá∫ÁöÑÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇÔºàÂÖ∑‰ΩìÊï∞ÊçÆÊú™Áü•Ôºâ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂπøÊ≥õÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫„ÄÅËá™Âä®È©æÈ©∂„ÄÅËôöÊãüÁé∞ÂÆû„ÄÅÊ∏∏ÊàèÂºÄÂèëÁ≠âÈ¢ÜÂüü„ÄÇ‰æãÂ¶ÇÔºåÂú®Êú∫Âô®‰∫∫È¢ÜÂüüÔºåÂ¢ûÂº∫ÂêéÁöÑMFMsÂèØ‰ª•Â∏ÆÂä©Êú∫Âô®‰∫∫Êõ¥Â•ΩÂú∞ÁêÜËß£Âë®Âõ¥ÁéØÂ¢ÉÔºåËøõË°åÊõ¥Êô∫ËÉΩÁöÑÂÜ≥Á≠ñÂíåÊéßÂà∂„ÄÇÂú®Ëá™Âä®È©æÈ©∂È¢ÜÂüüÔºåÂèØ‰ª•ÊèêÈ´òËá™Âä®È©æÈ©∂Á≥ªÁªüÂØπÂ§çÊùÇ‰∫§ÈÄöÂú∫ÊôØÁöÑÁêÜËß£ÂíåÈ¢ÑÊµãËÉΩÂäõ„ÄÇÂú®ËôöÊãüÁé∞ÂÆûÂíåÊ∏∏ÊàèÂºÄÂèëÈ¢ÜÂüüÔºåÂèØ‰ª•ÁîüÊàêÊõ¥ÈÄºÁúü„ÄÅÊõ¥ÂèØÊéßÁöÑËôöÊãüÂÜÖÂÆπ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Humans understand the world through the integration of multiple sensory modalities, enabling them to perceive, reason about, and imagine dynamic physical processes. Inspired by this capability, multimodal foundation models (MFMs) have emerged as powerful tools for multimodal understanding and generation. However, today's MFMs fall short of serving as effective world models. They lack the essential ability such as perform counterfactual reasoning, simulate dynamics, understand the spatiotemporal information, control generated visual outcomes, and perform multifaceted reasoning. We investigates what it takes to bridge the gap between multimodal foundation models and world models. We begin by improving the reasoning capabilities of MFMs through discriminative tasks and equipping MFMs with structured reasoning skills, such as causal inference, counterfactual thinking, and spatiotemporal reasoning, enabling them to go beyond surface correlations and understand deeper relationships within visual and textual data. Next, we explore generative capabilities of multimodal foundation models across both image and video modalities, introducing new frameworks for structured and controllable generation. Our approaches incorporate scene graphs, multimodal conditioning, and multimodal alignment strategies to guide the generation process, ensuring consistency with high-level semantics and fine-grained user intent. We further extend these techniques to controllable 4D generation, enabling interactive, editable, and morphable object synthesis over time and space.

