---
layout: default
title: Exploring Instruction Data Quality for Explainable Image Quality Assessment
---

# Exploring Instruction Data Quality for Explainable Image Quality Assessment

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.03880" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.03880v1</a>
  <a href="https://arxiv.org/pdf/2510.03880.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.03880v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.03880v1', 'Exploring Instruction Data Quality for Explainable Image Quality Assessment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yunhao Li, Sijing Wu, Huiyu Duan, Yucheng Zhu, Qi Jia, Guangtao Zhai

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-04

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é’ˆå¯¹å¯è§£é‡Šå›¾åƒè´¨é‡è¯„ä¼°ï¼Œæå‡ºåŸºäºèšç±»çš„æ•°æ®é€‰æ‹©æ–¹æ³•IQA-Selectï¼Œæå‡æ•°æ®æ•ˆç‡ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å›¾åƒè´¨é‡è¯„ä¼°` `å¯è§£é‡Šæ€§` `æŒ‡ä»¤è°ƒä¼˜` `æ•°æ®é€‰æ‹©` `èšç±»åˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¯è§£é‡Šå›¾åƒè´¨é‡è¯„ä¼°æ–¹æ³•ä¾èµ–å¤§è§„æ¨¡æŒ‡ä»¤è°ƒä¼˜æ•°æ®ï¼Œè®¡ç®—æˆæœ¬é«˜æ˜‚ä¸”æ•°æ®å­˜åœ¨å†—ä½™ã€‚
2. è®ºæ–‡æå‡ºåŸºäºèšç±»çš„æ•°æ®é€‰æ‹©æ¡†æ¶IQA-Selectï¼Œæ—¨åœ¨é€‰æ‹©æœ€å…·ä»£è¡¨æ€§çš„æ•°æ®å­é›†è¿›è¡Œå¾®è°ƒï¼Œæé«˜æ•°æ®æ•ˆç‡ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒIQA-Selectä»…ä½¿ç”¨10%çš„æ•°æ®å³å¯è¾¾åˆ°ç”šè‡³è¶…è¿‡å…¨é‡æ•°æ®å¾®è°ƒçš„æ€§èƒ½ï¼Œæ˜¾è‘—é™ä½è®¡ç®—æˆæœ¬ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œéšç€å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰çš„å¿«é€Ÿå‘å±•ï¼Œå¯è§£é‡Šå›¾åƒè´¨é‡è¯„ä¼°ï¼ˆIQAï¼‰é€æ¸æµè¡Œï¼Œå…¶ç›®æ ‡æ˜¯æä¾›ä¸å›¾åƒè´¨é‡ç›¸å…³çš„æè¿°å’Œç­”æ¡ˆã€‚ä¸ºäº†å®ç°è¿™ä¸€ç›®æ ‡ï¼Œç›®å‰çš„æ–¹æ³•è¯•å›¾æ„å»ºå¤§è§„æ¨¡æŒ‡ä»¤è°ƒä¼˜æ•°æ®é›†ï¼Œä»¥èµ‹äºˆMLLMè´¨é‡æ„ŸçŸ¥èƒ½åŠ›ï¼Œéµå¾ªè‘—åçš„ç¼©æ”¾å®šå¾‹ã€‚ç„¶è€Œï¼Œå¤§é‡çš„æŒ‡ä»¤è°ƒä¼˜æ•°æ®å¯èƒ½å¯¼è‡´å·¨å¤§çš„è®¡ç®—æˆæœ¬å’Œå†—ä½™æ•°æ®ï¼Œè¿›è€ŒæŸå®³æ¨¡å‹çš„æ€§èƒ½ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæœ¬æ–‡æŒ‘æˆ˜äº†ç¼©æ”¾å®šå¾‹ï¼Œå¹¶ç³»ç»Ÿåœ°ç ”ç©¶äº†æŒ‡ä»¤è°ƒä¼˜æ•°æ®é›†çš„æ•°æ®è´¨é‡åœ¨å¯è§£é‡ŠIQAä¸­çš„ä½œç”¨ã€‚ä½¿ç”¨å¼ºå¤§çš„é¢„è®­ç»ƒMLLMï¼Œæˆ‘ä»¬é¦–å…ˆç ”ç©¶äº†ä½¿ç”¨ä¸åŒå¤§å°çš„æŒ‡ä»¤è°ƒä¼˜æ•°æ®è¿›è¡Œå¾®è°ƒåæ¨¡å‹æ€§èƒ½çš„å˜åŒ–ã€‚æˆ‘ä»¬å‘ç°ï¼Œä½¿ç”¨é€‚å½“çš„æ¯”ä¾‹éšæœºé€‰æ‹©æ•°æ®é›†çš„å­é›†ï¼Œç”šè‡³å¯ä»¥æ¯”ä½¿ç”¨æ•´ä¸ªæŒ‡ä»¤è°ƒä¼˜æ•°æ®é›†è¿›è¡Œè®­ç»ƒè·å¾—æ›´å¥½çš„ç»“æœï¼Œè¿™è¡¨æ˜å½“å‰å¯è§£é‡ŠIQAæŒ‡ä»¤è°ƒä¼˜æ•°æ®çš„å†—ä½™æ€§ã€‚é™¤äº†éšæœºæŠ½æ ·å­é›†å¤–ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ä¸ªåŸºäºèšç±»çš„æ•°æ®é€‰æ‹©æ¡†æ¶ï¼ŒåŒ…æ‹¬ä¸‰ä¸ªé˜¶æ®µï¼šèšç±»ç‰¹å¾æå–ã€èšç±»é…é¢åˆ†é…å’Œèšç±»æŠ½æ ·ç­–ç•¥ã€‚ç„¶åï¼Œæˆ‘ä»¬ç³»ç»Ÿåœ°åˆ†æäº†æ¯ä¸ªé˜¶æ®µçš„é€‰æ‹©ï¼Œå¹¶æå‡ºäº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ•°æ®é€‰æ‹©æ–¹æ³•IQA-Selectï¼Œç”¨äºå¯è§£é‡ŠIQAã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒIQA-Selectä»…ä½¿ç”¨10%çš„é€‰å®šæ•°æ®ï¼Œå³å¯åœ¨Q-Benchå’ŒAesBenchä¸­åˆ†åˆ«è¾¾åˆ°å®Œæ•´å¾®è°ƒçš„102.1%å’Œ103.7%çš„æ€§èƒ½ï¼Œä»è€Œæ˜¾è‘—é™ä½è®¡ç®—æˆæœ¬ï¼ŒåŒæ—¶è·å¾—æ›´å¥½çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰å¯è§£é‡Šå›¾åƒè´¨é‡è¯„ä¼°æ–¹æ³•ä¾èµ–äºå¤§è§„æ¨¡çš„æŒ‡ä»¤è°ƒä¼˜æ•°æ®é›†æ¥è®­ç»ƒå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹(MLLM)ï¼Œä»¥ä½¿å…¶å…·å¤‡è´¨é‡æ„ŸçŸ¥èƒ½åŠ›ã€‚ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•å­˜åœ¨ä¸¤ä¸ªä¸»è¦ç—›ç‚¹ï¼šä¸€æ˜¯è®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œè®­ç»ƒå¤§è§„æ¨¡æ•°æ®é›†éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºï¼›äºŒæ˜¯æ•°æ®é›†ä¸­å­˜åœ¨å†—ä½™ï¼Œå¹¶éæ‰€æœ‰æ•°æ®éƒ½å¯¹æ¨¡å‹æ€§èƒ½æå‡æœ‰è´¡çŒ®ã€‚å› æ­¤ï¼Œå¦‚ä½•é«˜æ•ˆåœ°åˆ©ç”¨æ•°æ®ï¼Œåœ¨ä¿è¯æ€§èƒ½çš„å‰æä¸‹å‡å°‘è®¡ç®—æˆæœ¬ï¼Œæ˜¯æœ¬æ–‡è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æŒ‘æˆ˜ä¼ ç»Ÿçš„â€œç¼©æ”¾å®šå¾‹â€ï¼Œå³å¹¶éæ•°æ®è¶Šå¤šè¶Šå¥½ï¼Œè€Œæ˜¯æ•°æ®è´¨é‡æ›´é‡è¦ã€‚é€šè¿‡é€‰æ‹©æœ€å…·ä»£è¡¨æ€§çš„æ•°æ®å­é›†è¿›è¡Œè®­ç»ƒï¼Œå¯ä»¥å‡å°‘å†—ä½™ï¼Œæé«˜è®­ç»ƒæ•ˆç‡ï¼Œç”šè‡³æå‡æ¨¡å‹æ€§èƒ½ã€‚è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºèšç±»çš„æ•°æ®é€‰æ‹©æ¡†æ¶ï¼Œæ—¨åœ¨ä»åŸå§‹æ•°æ®é›†ä¸­é€‰æ‹©ä¸€ä¸ªé«˜è´¨é‡çš„å­é›†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šIQA-Selectæ¡†æ¶åŒ…å«ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼š
1. **èšç±»ç‰¹å¾æå–**ï¼šé¦–å…ˆï¼Œä»æŒ‡ä»¤æ•°æ®ä¸­æå–ç‰¹å¾ï¼Œç”¨äºåç»­çš„èšç±»åˆ†æã€‚å…·ä½“å®ç°æ–¹å¼æœªçŸ¥ï¼Œä½†ç›®æ ‡æ˜¯è·å¾—èƒ½å¤Ÿä»£è¡¨æ•°æ®ç‰¹å¾çš„å‘é‡è¡¨ç¤ºã€‚
2. **èšç±»é…é¢åˆ†é…**ï¼šæ ¹æ®æ¯ä¸ªç°‡çš„é‡è¦æ€§ï¼Œä¸ºæ¯ä¸ªç°‡åˆ†é…ä¸åŒçš„æ•°æ®é€‰æ‹©é…é¢ã€‚é‡è¦æ€§é«˜çš„ç°‡åˆ†é…æ›´å¤šçš„é…é¢ï¼Œä»¥ä¿è¯å…¶ä»£è¡¨æ€§ã€‚
3. **èšç±»æŠ½æ ·ç­–ç•¥**ï¼šåœ¨æ¯ä¸ªç°‡å†…ï¼Œæ ¹æ®ä¸€å®šçš„ç­–ç•¥é€‰æ‹©æ•°æ®æ ·æœ¬ã€‚å…·ä½“ç­–ç•¥æœªçŸ¥ï¼Œä½†ç›®æ ‡æ˜¯é€‰æ‹©æœ€å…·ä»£è¡¨æ€§çš„æ ·æœ¬ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºï¼Œå®ƒæ‰“ç ´äº†å¯è§£é‡ŠIQAé¢†åŸŸå¯¹å¤§è§„æ¨¡æ•°æ®çš„ç›²ç›®ä¾èµ–ï¼Œè½¬è€Œå…³æ³¨æ•°æ®è´¨é‡ã€‚é€šè¿‡èšç±»åˆ†æï¼Œèƒ½å¤Ÿè¯†åˆ«å¹¶é€‰æ‹©æœ€å…·ä»£è¡¨æ€§çš„æ•°æ®å­é›†ï¼Œä»è€Œåœ¨ä¿è¯ç”šè‡³æå‡æ¨¡å‹æ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½è®¡ç®—æˆæœ¬ã€‚ä¸éšæœºæŠ½æ ·ç›¸æ¯”ï¼Œèšç±»æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°ä¿ç•™æ•°æ®çš„å¤šæ ·æ€§ï¼Œé¿å…ä¿¡æ¯æŸå¤±ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åœ¨äºä¸‰ä¸ªé˜¶æ®µçš„å…·ä½“å®ç°æ–¹å¼ï¼ŒåŒ…æ‹¬ç‰¹å¾æå–æ–¹æ³•ã€èšç±»ç®—æ³•çš„é€‰æ‹©ã€ç°‡é‡è¦æ€§çš„è¯„ä¼°æ ‡å‡†ä»¥åŠç°‡å†…æŠ½æ ·ç­–ç•¥ã€‚è®ºæ–‡æåˆ°å¯¹æ¯ä¸ªé˜¶æ®µçš„é€‰æ‹©è¿›è¡Œäº†ç³»ç»Ÿåˆ†æï¼Œå¹¶æœ€ç»ˆæå‡ºäº†ä¸€ç§ç®€å•ä½†æœ‰æ•ˆçš„IQA-Selectæ–¹æ³•ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®ã€æŸå¤±å‡½æ•°ã€ç½‘ç»œç»“æ„ç­‰æŠ€æœ¯ç»†èŠ‚åœ¨æ‘˜è¦ä¸­æ²¡æœ‰æåŠï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒIQA-Selectä»…ä½¿ç”¨10%çš„é€‰å®šæ•°æ®ï¼Œå³å¯åœ¨Q-Benchå’ŒAesBenchä¸¤ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šåˆ†åˆ«è¾¾åˆ°å®Œæ•´å¾®è°ƒçš„102.1%å’Œ103.7%çš„æ€§èƒ½ã€‚è¿™æ„å‘³ç€åœ¨æ˜¾è‘—é™ä½è®¡ç®—æˆæœ¬çš„åŒæ—¶ï¼Œæ¨¡å‹æ€§èƒ½ç”šè‡³æœ‰æ‰€æå‡ã€‚è¿™ä¸€ç»“æœå……åˆ†è¯æ˜äº†IQA-Selectæ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ï¼ŒæŒ‘æˆ˜äº†å¯è§£é‡ŠIQAé¢†åŸŸå¯¹å¤§è§„æ¨¡æ•°æ®çš„ç›²ç›®ä¾èµ–ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºå›¾åƒè´¨é‡è¯„ä¼°ç›¸å…³çš„é¢†åŸŸï¼Œä¾‹å¦‚å›¾åƒå¢å¼ºã€å›¾åƒå‹ç¼©ã€å›¾åƒä¼ è¾“ç­‰ã€‚é€šè¿‡å‡å°‘è®­ç»ƒæ•°æ®é‡ï¼Œå¯ä»¥é™ä½æ¨¡å‹è®­ç»ƒçš„æˆæœ¬å’Œæ—¶é—´ï¼ŒåŠ é€Ÿç®—æ³•çš„å¼€å‘å’Œéƒ¨ç½²ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥åº”ç”¨äºå…¶ä»–éœ€è¦å¤§è§„æ¨¡æ•°æ®è®­ç»ƒçš„ä»»åŠ¡ä¸­ï¼Œæé«˜æ•°æ®åˆ©ç”¨æ•ˆç‡ï¼Œé™ä½è®¡ç®—èµ„æºæ¶ˆè€—ã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶å¯ä»¥è¿›ä¸€æ­¥æ¢ç´¢æ›´é«˜æ•ˆçš„æ•°æ®é€‰æ‹©ç­–ç•¥ï¼Œæå‡æ¨¡å‹æ€§èƒ½ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In recent years, with the rapid development of powerful multimodal large language models (MLLMs), explainable image quality assessment (IQA) has gradually become popular, aiming at providing quality-related descriptions and answers of images. To achieve this goal, recent methods seek to construct a large-scale instruction tuning dataset to empower the MLLM with quality perception ability following the well-known scaling law. However, a large amount of instruction tuning data may cause substantial computational costs and redundant data, which in turn will cause harm to the performance of the model. To cope with this problem, in this paper, we challenge the scaling law and systematically investigate the role of data quality of the instruction tuning dataset for explainable IQA. Using a powerful pre-trained MLLM, we first investigate the changes in model performance after fine-tuning with different sizes of instruction tuning data. We find that selecting a subset of the data set randomly using an appropriate ratio can even lead to better results than training with the entire instruction tuning dataset, demonstrating the redundancy of current explainable IQA instruction tuning data. Beyond randomly sampling a subset, we propose a clustering-based data selection framework with three stages: clustering feature extraction, cluster quota allocation, and cluster sampling strategy. Then we systematically analyze the choices of each stage and propose a simple but efficient data selection method IQA-Select for explainable IQA. The experimental results demonstrate that IQA-Select can achieve 102.1% and 103.7% performance of full fine-tuning using only 10% selected data in Q-Bench and AesBench respectively, significantly reducing computational costs while achieving better performance.

