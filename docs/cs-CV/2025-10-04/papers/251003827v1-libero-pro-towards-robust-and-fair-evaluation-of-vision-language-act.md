---
layout: default
title: LIBERO-PRO: Towards Robust and Fair Evaluation of Vision-Language-Action Models Beyond Memorization
---

# LIBERO-PRO: Towards Robust and Fair Evaluation of Vision-Language-Action Models Beyond Memorization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.03827" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.03827v1</a>
  <a href="https://arxiv.org/pdf/2510.03827.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.03827v1" onclick="toggleFavorite(this, '2510.03827v1', 'LIBERO-PRO: Towards Robust and Fair Evaluation of Vision-Language-Action Models Beyond Memorization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xueyang Zhou, Yangming Xu, Guiyao Tie, Yongchao Chen, Guowen Zhang, Duanfeng Chu, Pan Zhou, Lichao Sun

**åˆ†ç±»**: cs.CV, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-10-04

**å¤‡æ³¨**: 12 pages,7 figures, 5 tables

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Zxy-MLlab/LIBERO-PRO)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLIBERO-PROä»¥è§£å†³ç°æœ‰VLAæ¨¡å‹è¯„ä¼°ä¸å…¬æ­£é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€-åŠ¨ä½œ` `æ¨¡å‹è¯„ä¼°` `æ³›åŒ–èƒ½åŠ›` `ç³»ç»Ÿè¯„ä¼°` `å¤šç»´åº¦æ‰°åŠ¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LIBEROåŸºå‡†åœ¨è¯„ä¼°VLAæ¨¡å‹æ—¶å­˜åœ¨è®­ç»ƒå’Œè¯„ä¼°è®¾ç½®ä¸åˆç†çš„é—®é¢˜ï¼Œå¯¼è‡´æ€§èƒ½ä¼°è®¡ä¸å‡†ç¡®ã€‚
2. LIBERO-PROé€šè¿‡åœ¨æ“ä½œå¯¹è±¡ã€åˆå§‹çŠ¶æ€ã€ä»»åŠ¡æŒ‡ä»¤å’Œç¯å¢ƒç­‰å››ä¸ªç»´åº¦ä¸Šå¼•å…¥åˆç†æ‰°åŠ¨ï¼Œç³»ç»Ÿè¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œç°æœ‰æ¨¡å‹åœ¨æ ‡å‡†è¯„ä¼°ä¸­è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨LIBERO-PROçš„è®¾ç½®ä¸‹æ€§èƒ½æ€¥å‰§ä¸‹é™ï¼Œæš´éœ²å‡ºå…¶å¯¹è®°å¿†çš„ä¾èµ–ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

LIBEROå·²æˆä¸ºè¯„ä¼°è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹çš„å¹¿æ³›é‡‡ç”¨åŸºå‡†ï¼Œä½†å…¶å½“å‰çš„è®­ç»ƒå’Œè¯„ä¼°è®¾ç½®å­˜åœ¨é—®é¢˜ï¼Œå¸¸å¯¼è‡´æ€§èƒ½ä¼°è®¡è†¨èƒ€ï¼Œé˜»ç¢æ¨¡å‹çš„å…¬å¹³æ¯”è¾ƒã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†LIBERO-PROï¼Œä¸€ä¸ªæ‰©å±•çš„LIBEROåŸºå‡†ï¼Œç³»ç»Ÿåœ°åœ¨å››ä¸ªç»´åº¦ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼šæ“ä½œå¯¹è±¡ã€åˆå§‹çŠ¶æ€ã€ä»»åŠ¡æŒ‡ä»¤å’Œç¯å¢ƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå°½ç®¡ç°æœ‰æ¨¡å‹åœ¨æ ‡å‡†LIBEROè¯„ä¼°ä¸­è¾¾åˆ°90%ä»¥ä¸Šçš„å‡†ç¡®ç‡ï¼Œä½†åœ¨æˆ‘ä»¬çš„å¹¿ä¹‰è®¾ç½®ä¸‹ï¼Œå…¶æ€§èƒ½å´©æºƒè‡³0.0%ã€‚è¿™ä¸€å·®å¼‚æ­ç¤ºäº†æ¨¡å‹å¯¹è®­ç»ƒé›†ä¸­çš„åŠ¨ä½œåºåˆ—å’Œç¯å¢ƒå¸ƒå±€çš„æ­»è®°ç¡¬èƒŒä¾èµ–ï¼Œè€ŒéçœŸæ­£çš„ä»»åŠ¡ç†è§£æˆ–ç¯å¢ƒæ„ŸçŸ¥ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰LIBEROåŸºå‡†åœ¨è¯„ä¼°VLAæ¨¡å‹æ—¶å­˜åœ¨çš„è®­ç»ƒå’Œè¯„ä¼°è®¾ç½®ä¸åˆç†çš„é—®é¢˜ï¼Œè¿™å¯¼è‡´äº†æ¨¡å‹æ€§èƒ½çš„è™šé«˜ä¼°è®¡å’Œä¸å…¬å¹³æ¯”è¾ƒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šLIBERO-PROé€šè¿‡å¼•å…¥åˆç†çš„æ‰°åŠ¨ï¼Œç³»ç»Ÿåœ°è¯„ä¼°æ¨¡å‹åœ¨å¤šç§æ¡ä»¶ä¸‹çš„æ€§èƒ½ï¼Œç¡®ä¿æ¨¡å‹ä¸ä»…ä¾èµ–äºè®°å¿†ï¼Œè€Œæ˜¯å…·å¤‡çœŸæ­£çš„ä»»åŠ¡ç†è§£èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLIBERO-PROçš„æ•´ä½“æ¶æ„åŒ…æ‹¬å››ä¸ªä¸»è¦æ¨¡å—ï¼šæ“ä½œå¯¹è±¡çš„æ“æ§ã€åˆå§‹çŠ¶æ€çš„è®¾å®šã€ä»»åŠ¡æŒ‡ä»¤çš„å˜åŒ–å’Œç¯å¢ƒçš„å¤šæ ·åŒ–ã€‚è¿™äº›æ¨¡å—å…±åŒä½œç”¨ï¼Œå½¢æˆä¸€ä¸ªç»¼åˆçš„è¯„ä¼°ä½“ç³»ã€‚

**å…³é”®åˆ›æ–°**ï¼šLIBERO-PROçš„æœ€å¤§åˆ›æ–°åœ¨äºå…¶ç³»ç»Ÿæ€§åœ°å¼•å…¥å¤šç»´åº¦æ‰°åŠ¨ï¼Œæ˜¾è‘—æé«˜äº†è¯„ä¼°çš„ä¸¥è°¨æ€§å’Œæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†æ›´ä¸ºçœŸå®çš„æ€§èƒ½è¯„ä¼°ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œå…³é”®å‚æ•°åŒ…æ‹¬æ‰°åŠ¨çš„ç±»å‹å’Œå¼ºåº¦ï¼ŒæŸå¤±å‡½æ•°çš„é€‰æ‹©ï¼Œä»¥åŠç½‘ç»œç»“æ„çš„é€‚åº”æ€§è°ƒæ•´ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨å„ç§æ¡ä»¶ä¸‹çš„ç¨³å®šæ€§å’Œå‡†ç¡®æ€§ã€‚é€šè¿‡è¿™äº›è®¾è®¡ï¼ŒLIBERO-PROèƒ½å¤Ÿæœ‰æ•ˆè¯„ä¼°æ¨¡å‹çš„çœŸå®èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå°½ç®¡ç°æœ‰æ¨¡å‹åœ¨æ ‡å‡†LIBEROè¯„ä¼°ä¸­è¡¨ç°è¶…è¿‡90%çš„å‡†ç¡®ç‡ï¼Œä½†åœ¨LIBERO-PROçš„å¹¿ä¹‰è®¾ç½®ä¸‹ï¼Œå…¶æ€§èƒ½é™è‡³0.0%ã€‚è¿™ä¸€ç»“æœæ­ç¤ºäº†æ¨¡å‹å¯¹è®­ç»ƒæ•°æ®çš„è¿‡åº¦ä¾èµ–ï¼Œå¼ºè°ƒäº†LIBERO-PROåœ¨è¯„ä¼°æ¨¡å‹æ³›åŒ–èƒ½åŠ›æ–¹é¢çš„é‡è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæ§åˆ¶ã€è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½åŠ©æ‰‹ç­‰éœ€è¦è§†è§‰ã€è¯­è¨€å’ŒåŠ¨ä½œç›¸ç»“åˆçš„ä»»åŠ¡ã€‚é€šè¿‡æä¾›æ›´å…¬æ­£çš„æ¨¡å‹è¯„ä¼°ï¼ŒLIBERO-PROèƒ½å¤Ÿæ¨åŠ¨VLAæ¨¡å‹çš„å®é™…åº”ç”¨å’Œå‘å±•ï¼Œæå‡å…¶åœ¨å¤æ‚ç¯å¢ƒä¸­çš„è¡¨ç°ã€‚æœªæ¥ï¼Œè¯¥åŸºå‡†å¯èƒ½æˆä¸ºVLAé¢†åŸŸçš„æ ‡å‡†è¯„ä¼°å·¥å…·ï¼Œä¿ƒè¿›æ›´é«˜æ°´å¹³çš„ç ”ç©¶å’Œåº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> LIBERO has emerged as a widely adopted benchmark for evaluating Vision-Language-Action (VLA) models; however, its current training and evaluation settings are problematic, often leading to inflated performance estimates and preventing fair model comparison. To address these issues, we introduce LIBERO-PRO, an extended LIBERO benchmark that systematically evaluates model performance under reasonable perturbations across four dimensions: manipulated objects, initial states, task instructions, and environments. Experimental results reveal that, although existing models achieve over 90% accuracy under the standard LIBERO evaluation, their performance collapses to 0.0% under our generalized setting. Crucially, this discrepancy exposes the models' reliance on rote memorization of action sequences and environment layouts from the training set, rather than genuine task understanding or environmental perception. For instance, models persist in executing grasping actions when the target object is replaced with irrelevant items, and their outputs remain unchanged even when given corrupted instructions or even messy tokens. These findings expose the severe flaws in current evaluation practices, and we call on the community to abandon misleading methodologies in favor of robust assessments of model generalization and comprehension. Our code is available at: https://github.com/Zxy-MLlab/LIBERO-PRO.

