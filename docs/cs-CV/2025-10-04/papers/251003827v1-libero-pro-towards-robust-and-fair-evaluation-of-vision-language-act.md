---
layout: default
title: LIBERO-PRO: Towards Robust and Fair Evaluation of Vision-Language-Action Models Beyond Memorization
---

# LIBERO-PRO: Towards Robust and Fair Evaluation of Vision-Language-Action Models Beyond Memorization

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.03827" target="_blank" class="toolbar-btn">arXiv: 2510.03827v1</a>
    <a href="https://arxiv.org/pdf/2510.03827.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.03827v1" 
            onclick="toggleFavorite(this, '2510.03827v1', 'LIBERO-PRO: Towards Robust and Fair Evaluation of Vision-Language-Action Models Beyond Memorization')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Xueyang Zhou, Yangming Xu, Guiyao Tie, Yongchao Chen, Guowen Zhang, Duanfeng Chu, Pan Zhou, Lichao Sun

**ÂàÜÁ±ª**: cs.CV, cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-04

**Â§áÊ≥®**: 12 pages,7 figures, 5 tables

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/Zxy-MLlab/LIBERO-PRO)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫LIBERO-PRO‰ª•Ëß£ÂÜ≥Áé∞ÊúâVLAÊ®°ÂûãËØÑ‰º∞‰∏çÂÖ¨Ê≠£ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰Ωú` `Ê®°ÂûãËØÑ‰º∞` `Ê≥õÂåñËÉΩÂäõ` `Á≥ªÁªüËØÑ‰º∞` `Â§öÁª¥Â∫¶Êâ∞Âä®`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâLIBEROÂü∫ÂáÜÂú®ËØÑ‰º∞VLAÊ®°ÂûãÊó∂Â≠òÂú®ËÆ≠ÁªÉÂíåËØÑ‰º∞ËÆæÁΩÆ‰∏çÂêàÁêÜÁöÑÈóÆÈ¢òÔºåÂØºËá¥ÊÄßËÉΩ‰º∞ËÆ°‰∏çÂáÜÁ°Æ„ÄÇ
2. LIBERO-PROÈÄöËøáÂú®Êìç‰ΩúÂØπË±°„ÄÅÂàùÂßãÁä∂ÊÄÅ„ÄÅ‰ªªÂä°Êåá‰ª§ÂíåÁéØÂ¢ÉÁ≠âÂõõ‰∏™Áª¥Â∫¶‰∏äÂºïÂÖ•ÂêàÁêÜÊâ∞Âä®ÔºåÁ≥ªÁªüËØÑ‰º∞Ê®°ÂûãÊÄßËÉΩ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåÁé∞ÊúâÊ®°ÂûãÂú®Ê†áÂáÜËØÑ‰º∞‰∏≠Ë°®Áé∞ËâØÂ•ΩÔºå‰ΩÜÂú®LIBERO-PROÁöÑËÆæÁΩÆ‰∏ãÊÄßËÉΩÊÄ•Ââß‰∏ãÈôçÔºåÊö¥Èú≤Âá∫ÂÖ∂ÂØπËÆ∞ÂøÜÁöÑ‰æùËµñ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

LIBEROÂ∑≤Êàê‰∏∫ËØÑ‰º∞ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÔºàVLAÔºâÊ®°ÂûãÁöÑÂπøÊ≥õÈááÁî®Âü∫ÂáÜÔºå‰ΩÜÂÖ∂ÂΩìÂâçÁöÑËÆ≠ÁªÉÂíåËØÑ‰º∞ËÆæÁΩÆÂ≠òÂú®ÈóÆÈ¢òÔºåÂ∏∏ÂØºËá¥ÊÄßËÉΩ‰º∞ËÆ°ËÜ®ËÉÄÔºåÈòªÁ¢çÊ®°ÂûãÁöÑÂÖ¨Âπ≥ÊØîËæÉ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåÊú¨ÊñáÊèêÂá∫‰∫ÜLIBERO-PROÔºå‰∏Ä‰∏™Êâ©Â±ïÁöÑLIBEROÂü∫ÂáÜÔºåÁ≥ªÁªüÂú∞Âú®Âõõ‰∏™Áª¥Â∫¶‰∏äËØÑ‰º∞Ê®°ÂûãÊÄßËÉΩÔºöÊìç‰ΩúÂØπË±°„ÄÅÂàùÂßãÁä∂ÊÄÅ„ÄÅ‰ªªÂä°Êåá‰ª§ÂíåÁéØÂ¢É„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÂ∞ΩÁÆ°Áé∞ÊúâÊ®°ÂûãÂú®Ê†áÂáÜLIBEROËØÑ‰º∞‰∏≠ËææÂà∞90%‰ª•‰∏äÁöÑÂáÜÁ°ÆÁéáÔºå‰ΩÜÂú®Êàë‰ª¨ÁöÑÂπø‰πâËÆæÁΩÆ‰∏ãÔºåÂÖ∂ÊÄßËÉΩÂ¥©Ê∫ÉËá≥0.0%„ÄÇËøô‰∏ÄÂ∑ÆÂºÇÊè≠Á§∫‰∫ÜÊ®°ÂûãÂØπËÆ≠ÁªÉÈõÜ‰∏≠ÁöÑÂä®‰ΩúÂ∫èÂàóÂíåÁéØÂ¢ÉÂ∏ÉÂ±ÄÁöÑÊ≠ªËÆ∞Á°¨ËÉå‰æùËµñÔºåËÄåÈùûÁúüÊ≠£ÁöÑ‰ªªÂä°ÁêÜËß£ÊàñÁéØÂ¢ÉÊÑüÁü•„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâLIBEROÂü∫ÂáÜÂú®ËØÑ‰º∞VLAÊ®°ÂûãÊó∂Â≠òÂú®ÁöÑËÆ≠ÁªÉÂíåËØÑ‰º∞ËÆæÁΩÆ‰∏çÂêàÁêÜÁöÑÈóÆÈ¢òÔºåËøôÂØºËá¥‰∫ÜÊ®°ÂûãÊÄßËÉΩÁöÑËôöÈ´ò‰º∞ËÆ°Âíå‰∏çÂÖ¨Âπ≥ÊØîËæÉ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöLIBERO-PROÈÄöËøáÂºïÂÖ•ÂêàÁêÜÁöÑÊâ∞Âä®ÔºåÁ≥ªÁªüÂú∞ËØÑ‰º∞Ê®°ÂûãÂú®Â§öÁßçÊù°‰ª∂‰∏ãÁöÑÊÄßËÉΩÔºåÁ°Æ‰øùÊ®°Âûã‰∏ç‰ªÖ‰æùËµñ‰∫éËÆ∞ÂøÜÔºåËÄåÊòØÂÖ∑Â§áÁúüÊ≠£ÁöÑ‰ªªÂä°ÁêÜËß£ËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöLIBERO-PROÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨Âõõ‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÊìç‰ΩúÂØπË±°ÁöÑÊìçÊéß„ÄÅÂàùÂßãÁä∂ÊÄÅÁöÑËÆæÂÆö„ÄÅ‰ªªÂä°Êåá‰ª§ÁöÑÂèòÂåñÂíåÁéØÂ¢ÉÁöÑÂ§öÊ†∑Âåñ„ÄÇËøô‰∫õÊ®°ÂùóÂÖ±Âêå‰ΩúÁî®ÔºåÂΩ¢Êàê‰∏Ä‰∏™ÁªºÂêàÁöÑËØÑ‰º∞‰ΩìÁ≥ª„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöLIBERO-PROÁöÑÊúÄÂ§ßÂàõÊñ∞Âú®‰∫éÂÖ∂Á≥ªÁªüÊÄßÂú∞ÂºïÂÖ•Â§öÁª¥Â∫¶Êâ∞Âä®ÔºåÊòæËëóÊèêÈ´ò‰∫ÜËØÑ‰º∞ÁöÑ‰∏•Ë∞®ÊÄßÂíåÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõÔºå‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåÊèê‰æõ‰∫ÜÊõ¥‰∏∫ÁúüÂÆûÁöÑÊÄßËÉΩËØÑ‰º∞„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°‰∏≠ÔºåÂÖ≥ÈîÆÂèÇÊï∞ÂåÖÊã¨Êâ∞Âä®ÁöÑÁ±ªÂûãÂíåÂº∫Â∫¶ÔºåÊçüÂ§±ÂáΩÊï∞ÁöÑÈÄâÊã©Ôºå‰ª•ÂèäÁΩëÁªúÁªìÊûÑÁöÑÈÄÇÂ∫îÊÄßË∞ÉÊï¥Ôºå‰ª•Á°Æ‰øùÊ®°ÂûãÂú®ÂêÑÁßçÊù°‰ª∂‰∏ãÁöÑÁ®≥ÂÆöÊÄßÂíåÂáÜÁ°ÆÊÄß„ÄÇÈÄöËøáËøô‰∫õËÆæËÆ°ÔºåLIBERO-PROËÉΩÂ§üÊúâÊïàËØÑ‰º∞Ê®°ÂûãÁöÑÁúüÂÆûËÉΩÂäõ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåÂ∞ΩÁÆ°Áé∞ÊúâÊ®°ÂûãÂú®Ê†áÂáÜLIBEROËØÑ‰º∞‰∏≠Ë°®Áé∞Ë∂ÖËøá90%ÁöÑÂáÜÁ°ÆÁéáÔºå‰ΩÜÂú®LIBERO-PROÁöÑÂπø‰πâËÆæÁΩÆ‰∏ãÔºåÂÖ∂ÊÄßËÉΩÈôçËá≥0.0%„ÄÇËøô‰∏ÄÁªìÊûúÊè≠Á§∫‰∫ÜÊ®°ÂûãÂØπËÆ≠ÁªÉÊï∞ÊçÆÁöÑËøáÂ∫¶‰æùËµñÔºåÂº∫Ë∞É‰∫ÜLIBERO-PROÂú®ËØÑ‰º∞Ê®°ÂûãÊ≥õÂåñËÉΩÂäõÊñπÈù¢ÁöÑÈáçË¶ÅÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Êú∫Âô®‰∫∫ÊéßÂà∂„ÄÅËá™Âä®È©æÈ©∂„ÄÅÊô∫ËÉΩÂä©ÊâãÁ≠âÈúÄË¶ÅËßÜËßâ„ÄÅËØ≠Ë®ÄÂíåÂä®‰ΩúÁõ∏ÁªìÂêàÁöÑ‰ªªÂä°„ÄÇÈÄöËøáÊèê‰æõÊõ¥ÂÖ¨Ê≠£ÁöÑÊ®°ÂûãËØÑ‰º∞ÔºåLIBERO-PROËÉΩÂ§üÊé®Âä®VLAÊ®°ÂûãÁöÑÂÆûÈôÖÂ∫îÁî®ÂíåÂèëÂ±ïÔºåÊèêÂçáÂÖ∂Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑË°®Áé∞„ÄÇÊú™Êù•ÔºåËØ•Âü∫ÂáÜÂèØËÉΩÊàê‰∏∫VLAÈ¢ÜÂüüÁöÑÊ†áÂáÜËØÑ‰º∞Â∑•ÂÖ∑Ôºå‰øÉËøõÊõ¥È´òÊ∞¥Âπ≥ÁöÑÁ†îÁ©∂ÂíåÂ∫îÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> LIBERO has emerged as a widely adopted benchmark for evaluating Vision-Language-Action (VLA) models; however, its current training and evaluation settings are problematic, often leading to inflated performance estimates and preventing fair model comparison. To address these issues, we introduce LIBERO-PRO, an extended LIBERO benchmark that systematically evaluates model performance under reasonable perturbations across four dimensions: manipulated objects, initial states, task instructions, and environments. Experimental results reveal that, although existing models achieve over 90% accuracy under the standard LIBERO evaluation, their performance collapses to 0.0% under our generalized setting. Crucially, this discrepancy exposes the models' reliance on rote memorization of action sequences and environment layouts from the training set, rather than genuine task understanding or environmental perception. For instance, models persist in executing grasping actions when the target object is replaced with irrelevant items, and their outputs remain unchanged even when given corrupted instructions or even messy tokens. These findings expose the severe flaws in current evaluation practices, and we call on the community to abandon misleading methodologies in favor of robust assessments of model generalization and comprehension. Our code is available at: https://github.com/Zxy-MLlab/LIBERO-PRO.

