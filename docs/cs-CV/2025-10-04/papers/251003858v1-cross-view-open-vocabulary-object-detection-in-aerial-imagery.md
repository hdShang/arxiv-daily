---
layout: default
title: Cross-View Open-Vocabulary Object Detection in Aerial Imagery
---

# Cross-View Open-Vocabulary Object Detection in Aerial Imagery

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.03858" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.03858v1</a>
  <a href="https://arxiv.org/pdf/2510.03858.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.03858v1" onclick="toggleFavorite(this, '2510.03858v1', 'Cross-View Open-Vocabulary Object Detection in Aerial Imagery')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jyoti Kini, Rohit Gupta, Mubarak Shah

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-04

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè·¨è§†è§’å¼€æ”¾è¯æ±‡ç›®æ ‡æ£€æµ‹æ¡†æ¶ï¼Œè§£å†³èˆªæ‹å›¾åƒç›®æ ‡è¯†åˆ«éš¾é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `å¼€æ”¾è¯æ±‡ç›®æ ‡æ£€æµ‹` `èˆªæ‹å›¾åƒ` `é¢†åŸŸè‡ªé€‚åº”` `å¯¹æ¯”å­¦ä¹ ` `å¤šå®ä¾‹å­¦ä¹ ` `é›¶æ ·æœ¬å­¦ä¹ ` `å›¾åƒ-æ–‡æœ¬å¯¹é½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿç›®æ ‡æ£€æµ‹æ¨¡å‹æ³›åŒ–æ€§å·®ï¼Œéš¾ä»¥è¯†åˆ«æœªè®­ç»ƒç±»åˆ«ï¼Œé™åˆ¶äº†å…¶åœ¨èˆªæ‹å›¾åƒç­‰å¤æ‚åœºæ™¯çš„åº”ç”¨ã€‚
2. è®ºæ–‡æå‡ºä¸€ç§è·¨è§†è§’å¼€æ”¾è¯æ±‡ç›®æ ‡æ£€æµ‹æ¡†æ¶ï¼Œé€šè¿‡é¢†åŸŸå¯¹é½å°†åœ°é¢å›¾åƒçŸ¥è¯†è¿ç§»åˆ°èˆªæ‹å›¾åƒã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªèˆªæ‹æ•°æ®é›†ä¸Šæ˜¾è‘—æå‡äº†é›¶æ ·æœ¬ç›®æ ‡æ£€æµ‹æ€§èƒ½ï¼Œä¼˜äºå¾®è°ƒçš„å°é—­è¯æ±‡æ¨¡å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¼ ç»Ÿç›®æ ‡æ£€æµ‹æ¨¡å‹é€šå¸¸åœ¨å›ºå®šçš„ç±»åˆ«é›†åˆä¸Šè®­ç»ƒï¼Œé™åˆ¶äº†å…¶çµæ´»æ€§ï¼Œå¹¶ä¸”å¢åŠ æ–°ç±»åˆ«çš„æˆæœ¬å¾ˆé«˜ã€‚å¼€æ”¾è¯æ±‡ç›®æ ‡æ£€æµ‹é€šè¿‡è¯†åˆ«æœªè§è¿‡çš„ç±»åˆ«æ¥è§£å†³æ­¤é™åˆ¶ï¼Œè€Œæ— éœ€æ˜¾å¼è®­ç»ƒã€‚åˆ©ç”¨åœ¨å¤§é‡å¯ç”¨çš„åœ°é¢å›¾åƒ-æ–‡æœ¬åˆ†ç±»å¯¹ä¸Šè¿›è¡Œå¯¹æ¯”è®­ç»ƒçš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œä¸ºèˆªæ‹å›¾åƒä¸­çš„å¼€æ”¾è¯æ±‡ç›®æ ‡æ£€æµ‹æä¾›äº†åšå®çš„åŸºç¡€ã€‚ç„¶è€Œï¼Œé¢†åŸŸè½¬ç§»ã€è§†è§’å˜åŒ–å’Œæç«¯å°ºåº¦å·®å¼‚ä½¿å¾—è·¨é¢†åŸŸçš„ç›´æ¥çŸ¥è¯†è¿ç§»æ— æ•ˆï¼Œéœ€è¦ä¸“é—¨çš„é€‚åº”ç­–ç•¥ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶ï¼Œé€šè¿‡ç»“æ„åŒ–çš„é¢†åŸŸå¯¹é½æ¥è°ƒæ•´æ¥è‡ªåœ°é¢å›¾åƒçš„å¼€æ”¾è¯æ±‡è¡¨ç¤ºï¼Œä»¥è§£å†³èˆªæ‹å›¾åƒä¸­çš„ç›®æ ‡æ£€æµ‹é—®é¢˜ã€‚è¯¥æ–¹æ³•å¼•å…¥äº†å¯¹æ¯”å›¾åƒåˆ°å›¾åƒçš„å¯¹é½ï¼Œä»¥å¢å¼ºèˆªæ‹å’Œåœ°é¢åµŒå…¥ä¹‹é—´çš„ç›¸ä¼¼æ€§ï¼Œå¹¶é‡‡ç”¨å¤šå®ä¾‹è¯æ±‡å…³è”æ¥å¯¹é½èˆªæ‹å›¾åƒå’Œæ–‡æœ¬åµŒå…¥ã€‚åœ¨xViewã€DOTAv2ã€VisDroneã€DIORå’ŒHRRSDæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚ä¸å¾®è°ƒçš„å°é—­è¯æ±‡æ•°æ®é›†ç‰¹å®šæ¨¡å‹æ€§èƒ½ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„å¼€æ”¾è¯æ±‡æ¨¡å‹åœ¨é›¶æ ·æœ¬è®¾ç½®ä¸‹ï¼Œåœ¨DOTAv2ä¸Šå®ç°äº†+6.32 mAPï¼Œåœ¨VisDroneï¼ˆå›¾åƒï¼‰ä¸Šå®ç°äº†+4.16 mAPï¼Œåœ¨HRRSDä¸Šå®ç°äº†+3.46 mAPçš„æ”¹è¿›ï¼Œä»è€Œä¸ºèˆªæ‹åº”ç”¨ä¸­æ›´çµæ´»å’Œå¯æ‰©å±•çš„ç›®æ ‡æ£€æµ‹ç³»ç»Ÿé“ºå¹³äº†é“è·¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³èˆªæ‹å›¾åƒä¸­å¼€æ”¾è¯æ±‡ç›®æ ‡æ£€æµ‹é—®é¢˜ã€‚ç°æœ‰ç›®æ ‡æ£€æµ‹æ¨¡å‹é€šå¸¸éœ€è¦åœ¨ç‰¹å®šæ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œæ— æ³•è¯†åˆ«æœªè§è¿‡çš„ç±»åˆ«ï¼Œæ³›åŒ–èƒ½åŠ›å·®ã€‚ç›´æ¥å°†åœ°é¢å›¾åƒä¸Šè®­ç»ƒçš„æ¨¡å‹åº”ç”¨äºèˆªæ‹å›¾åƒï¼Œä¼šå—åˆ°é¢†åŸŸå·®å¼‚ã€è§†è§’å˜åŒ–å’Œå°ºåº¦å·®å¼‚çš„å½±å“ï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡é¢†åŸŸå¯¹é½ï¼Œå°†ä»åœ°é¢å›¾åƒå­¦ä¹ åˆ°çš„å¼€æ”¾è¯æ±‡è¡¨ç¤ºè¿ç§»åˆ°èˆªæ‹å›¾åƒã€‚å…·ä½“æ¥è¯´ï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ ï¼Œæ‹‰è¿‘èˆªæ‹å›¾åƒå’Œåœ°é¢å›¾åƒçš„ç‰¹å¾è¡¨ç¤ºï¼Œå¹¶åˆ©ç”¨å¤šå®ä¾‹å­¦ä¹ ï¼Œå°†èˆªæ‹å›¾åƒä¸æ–‡æœ¬æè¿°è¿›è¡Œå…³è”ï¼Œä»è€Œå®ç°å¼€æ”¾è¯æ±‡ç›®æ ‡æ£€æµ‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶ä¸»è¦åŒ…å«ä¸¤ä¸ªæ¨¡å—ï¼šå›¾åƒ-å›¾åƒå¯¹é½æ¨¡å—å’Œå›¾åƒ-æ–‡æœ¬å¯¹é½æ¨¡å—ã€‚å›¾åƒ-å›¾åƒå¯¹é½æ¨¡å—é€šè¿‡å¯¹æ¯”å­¦ä¹ ï¼Œæœ€å°åŒ–èˆªæ‹å›¾åƒå’Œåœ°é¢å›¾åƒçš„ç‰¹å¾è·ç¦»ï¼Œä»è€Œå‡å°é¢†åŸŸå·®å¼‚ã€‚å›¾åƒ-æ–‡æœ¬å¯¹é½æ¨¡å—åˆ©ç”¨å¤šå®ä¾‹å­¦ä¹ ï¼Œå°†èˆªæ‹å›¾åƒä¸­çš„ç›®æ ‡ä¸æ–‡æœ¬æè¿°è¿›è¡Œå…³è”ï¼Œä»è€Œå®ç°å¼€æ”¾è¯æ±‡ç›®æ ‡æ£€æµ‹ã€‚æ•´ä½“æµç¨‹æ˜¯å…ˆè¿›è¡Œå›¾åƒ-å›¾åƒå¯¹é½ï¼Œå†è¿›è¡Œå›¾åƒ-æ–‡æœ¬å¯¹é½ï¼Œæœ€åè¿›è¡Œç›®æ ‡æ£€æµ‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ç»“æ„åŒ–çš„é¢†åŸŸå¯¹é½æ–¹æ³•ï¼ŒåŒ…æ‹¬å¯¹æ¯”å›¾åƒ-å›¾åƒå¯¹é½å’Œå¤šå®ä¾‹è¯æ±‡å…³è”ã€‚å¯¹æ¯”å›¾åƒ-å›¾åƒå¯¹é½èƒ½å¤Ÿæœ‰æ•ˆåœ°å‡å°èˆªæ‹å›¾åƒå’Œåœ°é¢å›¾åƒä¹‹é—´çš„é¢†åŸŸå·®å¼‚ï¼Œå¤šå®ä¾‹è¯æ±‡å…³è”èƒ½å¤Ÿå°†èˆªæ‹å›¾åƒä¸­çš„ç›®æ ‡ä¸æ–‡æœ¬æè¿°è¿›è¡Œå…³è”ï¼Œä»è€Œå®ç°å¼€æ”¾è¯æ±‡ç›®æ ‡æ£€æµ‹ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨åœ°é¢å›¾åƒçš„çŸ¥è¯†ï¼Œæé«˜èˆªæ‹å›¾åƒä¸­å¼€æ”¾è¯æ±‡ç›®æ ‡æ£€æµ‹çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å¯¹æ¯”å›¾åƒ-å›¾åƒå¯¹é½ä¸­ï¼Œä½¿ç”¨äº†InfoNCEæŸå¤±å‡½æ•°æ¥æœ€å¤§åŒ–æ­£æ ·æœ¬å¯¹çš„ç›¸ä¼¼åº¦ï¼Œæœ€å°åŒ–è´Ÿæ ·æœ¬å¯¹çš„ç›¸ä¼¼åº¦ã€‚åœ¨å¤šå®ä¾‹è¯æ±‡å…³è”ä¸­ï¼Œä½¿ç”¨äº†æœ€å¤§æ± åŒ–æ“ä½œæ¥é€‰æ‹©æœ€ç›¸å…³çš„æ–‡æœ¬æè¿°ã€‚ç½‘ç»œç»“æ„ä½¿ç”¨äº†ResNet-50ä½œä¸ºå›¾åƒç¼–ç å™¨ï¼ŒTransformerä½œä¸ºæ–‡æœ¬ç¼–ç å™¨ã€‚å®éªŒä¸­ï¼Œä½¿ç”¨äº†Adamä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡ä¸º0.0001ï¼Œbatch sizeä¸º32ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥è®ºæ–‡åœ¨å¤šä¸ªèˆªæ‹æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼ŒåŒ…æ‹¬xViewã€DOTAv2ã€VisDroneã€DIORå’ŒHRRSDã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é›¶æ ·æœ¬è®¾ç½®ä¸‹ï¼Œä¸å¾®è°ƒçš„å°é—­è¯æ±‡æ•°æ®é›†ç‰¹å®šæ¨¡å‹ç›¸æ¯”ï¼Œåœ¨DOTAv2ä¸Šå®ç°äº†+6.32 mAPï¼Œåœ¨VisDroneï¼ˆå›¾åƒï¼‰ä¸Šå®ç°äº†+4.16 mAPï¼Œåœ¨HRRSDä¸Šå®ç°äº†+3.46 mAPçš„æ”¹è¿›ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°æé«˜èˆªæ‹å›¾åƒä¸­å¼€æ”¾è¯æ±‡ç›®æ ‡æ£€æµ‹çš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ™ºæ…§åŸå¸‚ã€ç¯å¢ƒç›‘æµ‹ã€ç¾å®³æ•‘æ´ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œå¯ä»¥åˆ©ç”¨æ— äººæœºèˆªæ‹å›¾åƒè‡ªåŠ¨è¯†åˆ«å»ºç­‘ç‰©ã€è½¦è¾†ã€æ¤è¢«ç­‰ç›®æ ‡ï¼Œä¸ºåŸå¸‚è§„åˆ’å’Œç®¡ç†æä¾›æ•°æ®æ”¯æŒã€‚åœ¨ç¾å®³å‘ç”Ÿåï¼Œå¯ä»¥åˆ©ç”¨èˆªæ‹å›¾åƒå¿«é€Ÿè¯„ä¼°ç¾æƒ…ï¼Œä¸ºæ•‘æ´å·¥ä½œæä¾›å†³ç­–ä¾æ®ã€‚è¯¥æŠ€æœ¯å…·æœ‰å¹¿é˜”çš„åº”ç”¨å‰æ™¯å’Œé‡è¦çš„å®é™…ä»·å€¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Traditional object detection models are typically trained on a fixed set of classes, limiting their flexibility and making it costly to incorporate new categories. Open-vocabulary object detection addresses this limitation by enabling models to identify unseen classes without explicit training. Leveraging pretrained models contrastively trained on abundantly available ground-view image-text classification pairs provides a strong foundation for open-vocabulary object detection in aerial imagery. Domain shifts, viewpoint variations, and extreme scale differences make direct knowledge transfer across domains ineffective, requiring specialized adaptation strategies. In this paper, we propose a novel framework for adapting open-vocabulary representations from ground-view images to solve object detection in aerial imagery through structured domain alignment. The method introduces contrastive image-to-image alignment to enhance the similarity between aerial and ground-view embeddings and employs multi-instance vocabulary associations to align aerial images with text embeddings. Extensive experiments on the xView, DOTAv2, VisDrone, DIOR, and HRRSD datasets are used to validate our approach. Our open-vocabulary model achieves improvements of +6.32 mAP on DOTAv2, +4.16 mAP on VisDrone (Images), and +3.46 mAP on HRRSD in the zero-shot setting when compared to finetuned closed-vocabulary dataset-specific model performance, thus paving the way for more flexible and scalable object detection systems in aerial applications.

