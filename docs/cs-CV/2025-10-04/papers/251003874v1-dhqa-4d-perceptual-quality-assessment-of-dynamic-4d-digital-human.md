---
layout: default
title: DHQA-4D: Perceptual Quality Assessment of Dynamic 4D Digital Human
---

# DHQA-4D: Perceptual Quality Assessment of Dynamic 4D Digital Human

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.03874" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.03874v1</a>
  <a href="https://arxiv.org/pdf/2510.03874.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.03874v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.03874v1', 'DHQA-4D: Perceptual Quality Assessment of Dynamic 4D Digital Human')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yunhao Li, Sijing Wu, Yucheng Zhu, Huiyu Duan, Zicheng Zhang, Guangtao Zhai

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-04

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDHQA-4Dæ•°æ®é›†ä¸DynaMesh-Rateræ¨¡å‹ï¼Œç”¨äºåŠ¨æ€4Dæ•°å­—äººæ„ŸçŸ¥è´¨é‡è¯„ä¼°**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åŠ¨æ€4Dæ•°å­—äºº` `è´¨é‡è¯„ä¼°` `å¤šæ¨¡æ€å­¦ä¹ ` `å¤§å‹å¤šæ¨¡æ€æ¨¡å‹` `æ•°æ®é›†æ„å»º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŠ¨æ€4Dæ•°å­—äººæ˜“å—å™ªå£°å½±å“ï¼Œç¼ºä¹æœ‰æ•ˆçš„è´¨é‡è¯„ä¼°æ–¹æ³•æ¥ä¿è¯ç”¨æˆ·ä½“éªŒã€‚
2. æå‡ºDynaMesh-Raterï¼Œåˆ©ç”¨å¤§å‹å¤šæ¨¡æ€æ¨¡å‹èåˆè§†è§‰ã€è¿åŠ¨å’Œå‡ ä½•ç‰¹å¾è¿›è¡Œè´¨é‡é¢„æµ‹ã€‚
3. æ„å»ºå¤§è§„æ¨¡DHQA-4Dæ•°æ®é›†ï¼Œå®éªŒè¯æ˜DynaMesh-Raterä¼˜äºç°æœ‰è´¨é‡è¯„ä¼°æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€3Dæ‰«æå’Œé‡å»ºæŠ€æœ¯çš„å¿«é€Ÿå‘å±•ï¼ŒåŸºäº4Dç½‘æ ¼çš„åŠ¨æ€æ•°å­—äººåŒ–èº«è¶Šæ¥è¶Šå—æ¬¢è¿ã€‚é«˜ç²¾åº¦çš„åŠ¨æ€æ•°å­—äººåŒ–èº«å¯ä»¥åº”ç”¨äºæ¸¸æˆåˆ¶ä½œã€åŠ¨ç”»ç”Ÿæˆå’Œè¿œç¨‹æ²‰æµ¸å¼é€šä¿¡ç­‰å¤šä¸ªé¢†åŸŸã€‚ç„¶è€Œï¼Œè¿™äº›4Däººä½“åŒ–èº«ç½‘æ ¼åœ¨é‡‡é›†ã€å‹ç¼©å’Œä¼ è¾“è¿‡ç¨‹ä¸­å®¹æ˜“å—åˆ°å„ç§å™ªå£°çš„é€€åŒ–ï¼Œä»è€Œå½±å“ç”¨æˆ·çš„è§‚çœ‹ä½“éªŒã€‚é‰´äºæ­¤ï¼ŒåŠ¨æ€4Dæ•°å­—äººçš„è´¨é‡è¯„ä¼°å˜å¾—è¶Šæ¥è¶Šé‡è¦ã€‚æœ¬æ–‡é¦–å…ˆæå‡ºäº†ä¸€ä¸ªå¤§è§„æ¨¡çš„åŠ¨æ€æ•°å­—äººè´¨é‡è¯„ä¼°æ•°æ®é›†DHQA-4Dï¼Œå…¶ä¸­åŒ…å«32ä¸ªé«˜è´¨é‡çš„çœŸå®æ‰«æ4Däººä½“ç½‘æ ¼åºåˆ—ï¼Œ1920ä¸ªç”±11ç§çº¹ç†å¤±çœŸé€€åŒ–çš„æ‰­æ›²çº¹ç†4Däººä½“ç½‘æ ¼ï¼Œä»¥åŠå®ƒä»¬å¯¹åº”çš„çº¹ç†å’Œéçº¹ç†å¹³å‡æ„è§å¾—åˆ†ï¼ˆMOSï¼‰ã€‚åŸºäºDHQA-4Dæ•°æ®é›†ï¼Œæˆ‘ä»¬åˆ†æäº†ä¸åŒç±»å‹çš„å¤±çœŸå¯¹çº¹ç†åŠ¨æ€4Dç½‘æ ¼å’Œéçº¹ç†åŠ¨æ€4Dç½‘æ ¼çš„äººç±»æ„ŸçŸ¥çš„å½±å“ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºå¤§å‹å¤šæ¨¡æ€æ¨¡å‹ï¼ˆLMMï¼‰çš„æ–¹æ³•DynaMesh-Raterï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿè¯„ä¼°çº¹ç†4Dç½‘æ ¼å’Œéçº¹ç†4Dç½‘æ ¼ã€‚å…·ä½“è€Œè¨€ï¼ŒDynaMesh-Raterç²¾å¿ƒæå–å¤šç»´ç‰¹å¾ï¼ŒåŒ…æ‹¬æ¥è‡ªæŠ•å½±2Dè§†é¢‘çš„è§†è§‰ç‰¹å¾ã€æ¥è‡ªè£å‰ªè§†é¢‘ç‰‡æ®µçš„è¿åŠ¨ç‰¹å¾ä»¥åŠæ¥è‡ª4Däººä½“ç½‘æ ¼çš„å‡ ä½•ç‰¹å¾ï¼Œä»¥æä¾›å…¨é¢çš„è´¨é‡ç›¸å…³ä¿¡æ¯ã€‚ç„¶åï¼Œæˆ‘ä»¬åˆ©ç”¨LMMæ¨¡å‹æ¥æ•´åˆå¤šç»´ç‰¹å¾ï¼Œå¹¶é‡‡ç”¨åŸºäºLoRAçš„æŒ‡ä»¤è°ƒä¼˜æŠ€æœ¯æ¥è®­ç»ƒLMMæ¨¡å‹ä»¥é¢„æµ‹è´¨é‡åˆ†æ•°ã€‚åœ¨DHQA-4Dæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„DynaMesh-Rateræ–¹æ³•ä¼˜äºä»¥å¾€çš„è´¨é‡è¯„ä¼°æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åŠ¨æ€4Dæ•°å­—äººåœ¨é‡‡é›†ã€å‹ç¼©å’Œä¼ è¾“è¿‡ç¨‹ä¸­å¼•å…¥çš„å™ªå£°å¯¼è‡´çš„è´¨é‡ä¸‹é™é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆè¯„ä¼°åŠ¨æ€4Dæ•°å­—äººçš„æ„ŸçŸ¥è´¨é‡ï¼Œæ— æ³•å‡†ç¡®åæ˜ ç”¨æˆ·çš„ä¸»è§‚ä½“éªŒã€‚ç¼ºä¹å¤§è§„æ¨¡æ•°æ®é›†ä¹Ÿé™åˆ¶äº†ç›¸å…³ç ”ç©¶çš„è¿›å±•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ï¼ˆLMMï¼‰åŒæ—¶æå–å’ŒèåˆåŠ¨æ€4Dæ•°å­—äººçš„è§†è§‰ã€è¿åŠ¨å’Œå‡ ä½•ç‰¹å¾ï¼Œä»è€Œæ›´å…¨é¢åœ°è¯„ä¼°å…¶æ„ŸçŸ¥è´¨é‡ã€‚é€šè¿‡æ„å»ºå¤§è§„æ¨¡æ•°æ®é›†å¹¶è¿›è¡ŒæŒ‡ä»¤è°ƒä¼˜ï¼Œä½¿LMMèƒ½å¤Ÿå‡†ç¡®é¢„æµ‹ä¸»è§‚è´¨é‡è¯„åˆ†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDynaMesh-Raterçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) æ•°æ®é›†æ„å»ºï¼šæ„å»ºåŒ…å«é«˜è´¨é‡å’Œå¤±çœŸ4Dæ•°å­—äººç½‘æ ¼åºåˆ—çš„DHQA-4Dæ•°æ®é›†ã€‚2) ç‰¹å¾æå–ï¼šä»æŠ•å½±çš„2Dè§†é¢‘ä¸­æå–è§†è§‰ç‰¹å¾ï¼Œä»è£å‰ªçš„è§†é¢‘ç‰‡æ®µä¸­æå–è¿åŠ¨ç‰¹å¾ï¼Œå¹¶ä»4Däººä½“ç½‘æ ¼ä¸­æå–å‡ ä½•ç‰¹å¾ã€‚3) ç‰¹å¾èåˆï¼šä½¿ç”¨LMMæ¨¡å‹èåˆå¤šç»´ç‰¹å¾ã€‚4) è´¨é‡é¢„æµ‹ï¼šåˆ©ç”¨LoRAè¿›è¡ŒæŒ‡ä»¤è°ƒä¼˜ï¼Œè®­ç»ƒLMMæ¨¡å‹é¢„æµ‹è´¨é‡åˆ†æ•°ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æ„å»ºäº†å¤§è§„æ¨¡çš„åŠ¨æ€4Dæ•°å­—äººè´¨é‡è¯„ä¼°æ•°æ®é›†DHQA-4Dï¼Œä¸ºç›¸å…³ç ”ç©¶æä¾›äº†åŸºå‡†ã€‚2) æå‡ºäº†DynaMesh-Raterï¼Œä¸€ç§åŸºäºLMMçš„å¤šæ¨¡æ€è´¨é‡è¯„ä¼°æ–¹æ³•ï¼Œèƒ½å¤ŸåŒæ—¶å¤„ç†çº¹ç†å’Œéçº¹ç†4Dç½‘æ ¼ã€‚3) é‡‡ç”¨LoRAè¿›è¡ŒæŒ‡ä»¤è°ƒä¼˜ï¼Œæé«˜äº†LMMåœ¨è´¨é‡è¯„ä¼°ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒDynaMesh-Raterèƒ½å¤Ÿæ›´å…¨é¢åœ°æå–å’Œèåˆå¤šç»´ç‰¹å¾ï¼Œä»è€Œæ›´å‡†ç¡®åœ°è¯„ä¼°æ„ŸçŸ¥è´¨é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç‰¹å¾æå–æ–¹é¢ï¼Œå…·ä½“é‡‡ç”¨äº†å“ªäº›ç½‘ç»œç»“æ„æå–è§†è§‰ã€è¿åŠ¨å’Œå‡ ä½•ç‰¹å¾ï¼Œè®ºæ–‡ä¸­æœªæ˜ç¡®è¯´æ˜ï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚LoRAçš„å‚æ•°è®¾ç½®å’ŒæŒ‡ä»¤è°ƒä¼˜çš„å…·ä½“ç­–ç•¥ä¹Ÿæœªè¯¦ç»†æè¿°ï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡ä¹ŸæœªæåŠï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

DynaMesh-Rateråœ¨DHQA-4Dæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¶…è¶Šäº†ä»¥å¾€çš„è´¨é‡è¯„ä¼°æ–¹æ³•ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦åœ¨æ‘˜è¦ä¸­æœªæ˜ç¡®ç»™å‡ºï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚ä½†è®ºæ–‡å¼ºè°ƒäº†DynaMesh-Rateråœ¨çº¹ç†å’Œéçº¹ç†4Dç½‘æ ¼ä¸Šçš„é€šç”¨æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ¸¸æˆåˆ¶ä½œã€åŠ¨ç”»ç”Ÿæˆã€è¿œç¨‹æ²‰æµ¸å¼é€šä¿¡ç­‰é¢†åŸŸï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚é€šè¿‡è‡ªåŠ¨åŒ–çš„è´¨é‡è¯„ä¼°ï¼Œå¯ä»¥ä¼˜åŒ–4Dæ•°å­—äººçš„é‡‡é›†ã€å‹ç¼©å’Œä¼ è¾“æµç¨‹ï¼Œé™ä½æˆæœ¬å¹¶æé«˜æ•ˆç‡ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºè™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ç­‰æ–°å…´é¢†åŸŸï¼Œä¿ƒè¿›æ•°å­—äººæŠ€æœ¯çš„å¹¿æ³›åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> With the rapid development of 3D scanning and reconstruction technologies, dynamic digital human avatars based on 4D meshes have become increasingly popular. A high-precision dynamic digital human avatar can be applied to various fields such as game production, animation generation, and remote immersive communication. However, these 4D human avatar meshes are prone to being degraded by various types of noise during the processes of collection, compression, and transmission, thereby affecting the viewing experience of users. In light of this fact, quality assessment of dynamic 4D digital humans becomes increasingly important. In this paper, we first propose a large-scale dynamic digital human quality assessment dataset, DHQA-4D, which contains 32 high-quality real-scanned 4D human mesh sequences, 1920 distorted textured 4D human meshes degraded by 11 textured distortions, as well as their corresponding textured and non-textured mean opinion scores (MOSs). Equipped with DHQA-4D dataset, we analyze the influence of different types of distortion on human perception for textured dynamic 4D meshes and non-textured dynamic 4D meshes. Additionally, we propose DynaMesh-Rater, a novel large multimodal model (LMM) based approach that is able to assess both textured 4D meshes and non-textured 4D meshes. Concretely, DynaMesh-Rater elaborately extracts multi-dimensional features, including visual features from a projected 2D video, motion features from cropped video clips, and geometry features from the 4D human mesh to provide comprehensive quality-related information. Then we utilize a LMM model to integrate the multi-dimensional features and conduct a LoRA-based instruction tuning technique to teach the LMM model to predict the quality scores. Extensive experimental results on the DHQA-4D dataset demonstrate the superiority of our DynaMesh-Rater method over previous quality assessment methods.

