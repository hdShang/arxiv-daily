---
layout: default
title: OTTER: Open-Tagging via Text-Image Representation for Multi-modal Understanding
---

# OTTER: Open-Tagging via Text-Image Representation for Multi-modal Understanding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.00652" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.00652v1</a>
  <a href="https://arxiv.org/pdf/2510.00652.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.00652v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.00652v1', 'OTTER: Open-Tagging via Text-Image Representation for Multi-modal Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jieer Ouyang, Xiaoneng Xiang, Zheng Wang, Yangkai Ding

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-01

**å¤‡æ³¨**: Accepted at ICDM 2025 BigIS Workshop

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**OTTERï¼šé€šè¿‡æ–‡æœ¬-å›¾åƒè¡¨å¾è¿›è¡Œå¼€æ”¾æ ‡ç­¾å¤šæ¨¡æ€ç†è§£**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `å¼€æ”¾é›†è¯†åˆ«` `å¤šæ ‡ç­¾åˆ†ç±»` `è§†è§‰-è¯­è¨€å¯¹é½` `æ³¨æ„åŠ›æœºåˆ¶` `å›¾åƒæ ‡æ³¨` `æ–‡æœ¬ç†è§£`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•éš¾ä»¥å…¼é¡¾é¢„å®šä¹‰æ ‡ç­¾çš„ç¨³å®šæ€§å’Œç”¨æˆ·è‡ªå®šä¹‰æ ‡ç­¾çš„çµæ´»æ€§ï¼Œé™åˆ¶äº†å¤šæ¨¡æ€ç†è§£çš„æ³›åŒ–èƒ½åŠ›ã€‚
2. OTTERé€šè¿‡è”åˆå¯¹é½è§†è§‰å’Œæ–‡æœ¬è¡¨å¾ä¸å›ºå®šåŠå¼€æ”¾é›†æ ‡ç­¾åµŒå…¥ï¼Œå®ç°äº†åŠ¨æ€å’Œè¯­ä¹‰ä¸€è‡´çš„å¤šæ¨¡æ€æ ‡æ³¨ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒOTTERåœ¨å¼€æ”¾é›†å’Œé¢„å®šä¹‰æ ‡ç­¾ä¸Šå‡å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼Œæ˜¾è‘—è¶…è¶Šäº†ç°æœ‰åŸºçº¿æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬æå‡ºäº†OTTERï¼Œä¸€ä¸ªç»Ÿä¸€çš„å¼€æ”¾é›†å¤šæ ‡ç­¾æ ‡æ³¨æ¡†æ¶ï¼Œå®ƒåè°ƒäº†é¢„å®šä¹‰ç±»åˆ«é›†åˆçš„ç¨³å®šæ€§å’Œç”¨æˆ·é©±åŠ¨çš„å¼€æ”¾æ ‡ç­¾çš„é€‚åº”æ€§ã€‚OTTERæ„å»ºäºä¸€ä¸ªå¤§è§„æ¨¡ã€åˆ†å±‚ç»„ç»‡çš„å¤šæ¨¡æ€æ•°æ®é›†ä¹‹ä¸Šï¼Œè¯¥æ•°æ®é›†ä»ä¸åŒçš„åœ¨çº¿å­˜å‚¨åº“æ”¶é›†ï¼Œå¹¶é€šè¿‡ç»“åˆè‡ªåŠ¨è§†è§‰-è¯­è¨€æ ‡æ³¨ä¸äººå·¥æ”¹è¿›çš„æ··åˆæµç¨‹è¿›è¡Œæ ‡æ³¨ã€‚é€šè¿‡åˆ©ç”¨å¤šå¤´æ³¨æ„åŠ›æ¶æ„ï¼ŒOTTERå°†è§†è§‰å’Œæ–‡æœ¬è¡¨ç¤ºä¸å›ºå®šå’Œå¼€æ”¾é›†æ ‡ç­¾åµŒå…¥è”åˆå¯¹é½ï¼Œä»è€Œå®ç°åŠ¨æ€å’Œè¯­ä¹‰ä¸€è‡´çš„æ ‡æ³¨ã€‚åœ¨ä¸¤ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šï¼ŒOTTERå§‹ç»ˆä¼˜äºç«äº‰åŸºçº¿ï¼šåœ¨Otteræ•°æ®é›†ä¸Šå®ç°äº†0.81çš„æ€»ä½“F1åˆ†æ•°ï¼Œåœ¨Favoriteæ•°æ®é›†ä¸Šå®ç°äº†0.75çš„æ€»ä½“F1åˆ†æ•°ï¼Œåˆ†åˆ«è¶…è¿‡äº†æ¬¡ä¼˜ç»“æœ0.10å’Œ0.02ã€‚OTTERåœ¨å¼€æ”¾é›†æ ‡ç­¾ä¸Šè·å¾—äº†æ¥è¿‘å®Œç¾çš„æ€§èƒ½ï¼Œåœ¨Otteræ•°æ®é›†ä¸Šçš„F1åˆ†æ•°ä¸º0.99ï¼Œåœ¨Favoriteæ•°æ®é›†ä¸Šçš„F1åˆ†æ•°ä¸º0.97ï¼ŒåŒæ—¶ä¿æŒäº†é¢„å®šä¹‰æ ‡ç­¾ä¸Šå…·æœ‰ç«äº‰åŠ›çš„å‡†ç¡®æ€§ã€‚è¿™äº›ç»“æœè¯æ˜äº†OTTERåœ¨æ¡¥æ¥é—­é›†ä¸€è‡´æ€§å’Œå¼€æ”¾è¯æ±‡çµæ´»æ€§æ–¹é¢å¯¹äºå¤šæ¨¡æ€æ ‡æ³¨åº”ç”¨çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€æ•°æ®æ ‡æ³¨ä¸­ï¼Œå¦‚ä½•åŒæ—¶åˆ©ç”¨é¢„å®šä¹‰çš„ç±»åˆ«ä½“ç³»å’Œç”¨æˆ·è‡ªå®šä¹‰çš„å¼€æ”¾æ ‡ç­¾çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸åªå…³æ³¨é¢„å®šä¹‰ç±»åˆ«ï¼Œå¿½ç•¥äº†ç”¨æˆ·æä¾›çš„ä¸°å¯Œä¿¡æ¯ï¼Œæˆ–è€…éš¾ä»¥ä¿è¯å¼€æ”¾æ ‡ç­¾çš„è¯­ä¹‰ä¸€è‡´æ€§ï¼Œå¯¼è‡´æ ‡æ³¨ç»“æœä¸å¤Ÿå…¨é¢å’Œå‡†ç¡®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šOTTERçš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ï¼Œå°†è§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯ä¸é¢„å®šä¹‰æ ‡ç­¾å’Œå¼€æ”¾æ ‡ç­¾è¿›è¡Œè”åˆå¯¹é½ã€‚é€šè¿‡å­¦ä¹ å¤šæ¨¡æ€æ•°æ®çš„è”åˆè¡¨ç¤ºï¼Œæ¨¡å‹å¯ä»¥æ›´å¥½åœ°ç†è§£å›¾åƒå’Œæ–‡æœ¬çš„è¯­ä¹‰ä¿¡æ¯ï¼Œå¹¶å°†å…¶æ˜ å°„åˆ°ç›¸åº”çš„æ ‡ç­¾ç©ºé—´ã€‚è¿™ç§æ–¹æ³•æ—¢èƒ½ä¿è¯é¢„å®šä¹‰æ ‡ç­¾çš„å‡†ç¡®æ€§ï¼Œåˆèƒ½å……åˆ†åˆ©ç”¨å¼€æ”¾æ ‡ç­¾çš„çµæ´»æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šOTTERçš„æ•´ä½“æ¶æ„åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) å¤šæ¨¡æ€æ•°æ®æ”¶é›†å’Œæ ‡æ³¨æ¨¡å—ï¼Œç”¨äºæ„å»ºå¤§è§„æ¨¡ã€åˆ†å±‚ç»„ç»‡çš„å¤šæ¨¡æ€æ•°æ®é›†ï¼›2) è§†è§‰å’Œæ–‡æœ¬ç‰¹å¾æå–æ¨¡å—ï¼Œç”¨äºæå–å›¾åƒå’Œæ–‡æœ¬çš„ç‰¹å¾è¡¨ç¤ºï¼›3) å¤šå¤´æ³¨æ„åŠ›å¯¹é½æ¨¡å—ï¼Œç”¨äºå°†è§†è§‰å’Œæ–‡æœ¬ç‰¹å¾ä¸é¢„å®šä¹‰æ ‡ç­¾å’Œå¼€æ”¾æ ‡ç­¾çš„åµŒå…¥è¿›è¡Œå¯¹é½ï¼›4) æ ‡æ³¨é¢„æµ‹æ¨¡å—ï¼Œç”¨äºé¢„æµ‹å›¾åƒå’Œæ–‡æœ¬å¯¹åº”çš„æ ‡ç­¾ã€‚

**å…³é”®åˆ›æ–°**ï¼šOTTERçš„å…³é”®åˆ›æ–°åœ¨äºå…¶ç»Ÿä¸€çš„å¼€æ”¾é›†å¤šæ ‡ç­¾æ ‡æ³¨æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤ŸåŒæ—¶å¤„ç†é¢„å®šä¹‰æ ‡ç­¾å’Œå¼€æ”¾æ ‡ç­¾ã€‚é€šè¿‡å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ¨¡å‹å¯ä»¥å­¦ä¹ åˆ°è§†è§‰å’Œæ–‡æœ¬ç‰¹å¾ä¸ä¸åŒæ ‡ç­¾ä¹‹é—´çš„å¤æ‚å…³ç³»ï¼Œä»è€Œå®ç°æ›´å‡†ç¡®å’Œå…¨é¢çš„æ ‡æ³¨ã€‚æ­¤å¤–ï¼ŒOTTERè¿˜æ„å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡ã€åˆ†å±‚ç»„ç»‡çš„å¤šæ¨¡æ€æ•°æ®é›†ï¼Œä¸ºæ¨¡å‹çš„è®­ç»ƒå’Œè¯„ä¼°æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚

**å…³é”®è®¾è®¡**ï¼šOTTERçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶æ¥å­¦ä¹ è§†è§‰å’Œæ–‡æœ¬ç‰¹å¾ä¸æ ‡ç­¾ä¹‹é—´çš„å…³ç³»ï¼›2) è®¾è®¡äº†ä¸€ç§æ··åˆæ ‡æ³¨æµç¨‹ï¼Œç»“åˆè‡ªåŠ¨è§†è§‰-è¯­è¨€æ ‡æ³¨ä¸äººå·¥æ”¹è¿›ï¼Œä»¥æé«˜æ•°æ®é›†çš„è´¨é‡ï¼›3) é‡‡ç”¨åˆ†å±‚ç»„ç»‡çš„æ•°æ®é›†ç»“æ„ï¼Œä»¥æ›´å¥½åœ°æ”¯æŒæ¨¡å‹çš„è®­ç»ƒå’Œæ³›åŒ–ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

OTTERåœ¨Otterå’ŒFavoriteä¸¤ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚åœ¨Otteræ•°æ®é›†ä¸Šï¼ŒOTTERçš„æ€»ä½“F1åˆ†æ•°ä¸º0.81ï¼Œè¶…è¿‡æ¬¡ä¼˜ç»“æœ0.10ã€‚åœ¨Favoriteæ•°æ®é›†ä¸Šï¼ŒOTTERçš„æ€»ä½“F1åˆ†æ•°ä¸º0.75ï¼Œè¶…è¿‡æ¬¡ä¼˜ç»“æœ0.02ã€‚æ›´é‡è¦çš„æ˜¯ï¼ŒOTTERåœ¨å¼€æ”¾é›†æ ‡ç­¾ä¸Šè·å¾—äº†æ¥è¿‘å®Œç¾çš„æ€§èƒ½ï¼Œåœ¨Otteræ•°æ®é›†ä¸Šçš„F1åˆ†æ•°ä¸º0.99ï¼Œåœ¨Favoriteæ•°æ®é›†ä¸Šçš„F1åˆ†æ•°ä¸º0.97ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

OTTERå¯åº”ç”¨äºå›¾åƒæœç´¢ã€å†…å®¹æ¨èã€ç¤¾äº¤åª’ä½“åˆ†æç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨å›¾åƒæœç´¢ä¸­ï¼ŒOTTERå¯ä»¥æ ¹æ®ç”¨æˆ·æä¾›çš„æ–‡æœ¬æè¿°å’Œå›¾åƒå†…å®¹ï¼Œå‡†ç¡®åœ°è¯†åˆ«å›¾åƒä¸­çš„ç‰©ä½“å’Œåœºæ™¯ï¼Œä»è€Œæé«˜æœç´¢ç»“æœçš„å‡†ç¡®æ€§ã€‚åœ¨å†…å®¹æ¨èä¸­ï¼ŒOTTERå¯ä»¥æ ¹æ®ç”¨æˆ·çš„å…´è¶£å’Œåå¥½ï¼Œæ¨èç›¸å…³çš„å›¾åƒå’Œæ–‡æœ¬å†…å®¹ã€‚åœ¨ç¤¾äº¤åª’ä½“åˆ†æä¸­ï¼ŒOTTERå¯ä»¥åˆ†æç”¨æˆ·å‘å¸ƒçš„å›¾åƒå’Œæ–‡æœ¬ä¿¡æ¯ï¼Œäº†è§£ç”¨æˆ·çš„è§‚ç‚¹å’Œæƒ…æ„Ÿã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We introduce OTTER, a unified open-set multi-label tagging framework that harmonizes the stability of a curated, predefined category set with the adaptability of user-driven open tags. OTTER is built upon a large-scale, hierarchically organized multi-modal dataset, collected from diverse online repositories and annotated through a hybrid pipeline combining automated vision-language labeling with human refinement. By leveraging a multi-head attention architecture, OTTER jointly aligns visual and textual representations with both fixed and open-set label embeddings, enabling dynamic and semantically consistent tagging. OTTER consistently outperforms competitive baselines on two benchmark datasets: it achieves an overall F1 score of 0.81 on Otter and 0.75 on Favorite, surpassing the next-best results by margins of 0.10 and 0.02, respectively. OTTER attains near-perfect performance on open-set labels, with F1 of 0.99 on Otter and 0.97 on Favorite, while maintaining competitive accuracy on predefined labels. These results demonstrate OTTER's effectiveness in bridging closed-set consistency with open-vocabulary flexibility for multi-modal tagging applications.

