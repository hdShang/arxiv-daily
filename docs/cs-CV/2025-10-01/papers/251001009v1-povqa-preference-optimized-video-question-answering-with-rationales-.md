---
layout: default
title: "POVQA: Preference-Optimized Video Question Answering with Rationales for Data Efficiency"
---

# POVQA: Preference-Optimized Video Question Answering with Rationales for Data Efficiency

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.01009" class="toolbar-btn" target="_blank">üìÑ arXiv: 2510.01009v1</a>
  <a href="https://arxiv.org/pdf/2510.01009.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.01009v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.01009v1', 'POVQA: Preference-Optimized Video Question Answering with Rationales for Data Efficiency')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Ashim Dahal, Ankit Ghimire, Saydul Akbar Murad, Nick Rahimi

**ÂàÜÁ±ª**: cs.CV, cs.MM

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-01

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫POVQAÔºö‰∏ÄÁßçÊï∞ÊçÆÈ´òÊïàÁöÑÂÅèÂ•Ω‰ºòÂåñËßÜÈ¢ëÈóÆÁ≠îÊñπÊ≥ïÔºåÂà©Áî®ÁêÜÁî±ÊèêÂçáÊÄßËÉΩ„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `ËßÜÈ¢ëÈóÆÁ≠î` `ÈïøËßÜÈ¢ëÁêÜËß£` `ËßÜËßâËØ≠Ë®ÄÊ®°Âûã` `Êó∂Â∫èÊ±†Âåñ` `ÁêÜÁî±ÁîüÊàê` `ÂÅèÂ•Ω‰ºòÂåñ` `Êï∞ÊçÆÈ´òÊïà`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂü∫‰∫éLVLMÁöÑËßÜÈ¢ëÈóÆÁ≠îÊñπÊ≥ïÂú®Â§ÑÁêÜÈïøËßÜÈ¢ëÊó∂ÔºåÂèóÈôê‰∫é‰∏ä‰∏ãÊñáÁ™óÂè£Â§ßÂ∞èÔºåÊó†Ê≥ïÊúâÊïàÂà©Áî®ËßÜÈ¢ë‰ø°ÊÅØ„ÄÇ
2. POVQAÈÄöËøáÊó∂Â∫èÊ±†ÂåñÂ∞ÜËßÜÈ¢ëÂ∏ßÂéãÁº©‰∏∫‰ΩéÂ∏ßÁéáÂõæÂÉèÔºåÂπ∂ÁªìÂêàÁêÜÁî±ÁîüÊàêÔºåÊèêÂçáLVLMÂú®Êï∞ÊçÆÊúâÈôêÊÉÖÂÜµ‰∏ãÁöÑÊÄßËÉΩ„ÄÇ
3. Âú®ReasonVQAÊï∞ÊçÆÈõÜ‰∏äÔºåPOVQAÊòæËëóÊèêÂçá‰∫ÜVQAÊÄßËÉΩÂíåÁêÜÁî±Ë¥®ÈáèÔºåÂπ∂Âú®‰∏çÂêåÊ±†ÂåñÁ≠ñÁï•‰∏ãË°®Áé∞Âá∫È≤ÅÊ£íÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊï∞ÊçÆÈ´òÊïàÁöÑËßÜÈ¢ëÈóÆÁ≠îÔºàVQAÔºâÊµÅÁ®ãPOVQAÔºåÊó®Âú®Âà©Áî®Â§ßÂûãËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÔºàLVLMsÔºâËß£ÂÜ≥ÈïøËßÜÈ¢ëÈóÆÁ≠îÈóÆÈ¢ò„ÄÇËØ•ÊñπÊ≥ïÂ∞ÜÊØèÁßíËßÜÈ¢ëÂéãÁº©ÊàêÂçï‰∏™Êó∂Â∫èÊ±†ÂåñÂõæÂÉèÔºàÈÄöËøáËøêÂä®Ê®°Á≥äÂíåÂä†ÊùÉÂπ≥ÂùáÁöÑÂèò‰ΩìÔºâÔºåÁÑ∂ÂêéÈÄöËøáËΩªÈáèÁ∫ßÁõëÁù£ÂØπÈΩêLVLMs„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºå‰ΩøÁî®Blend Blur with Last Frame„ÄÅWeighted Average„ÄÅExponentialÂíåRampÊ±†ÂåñÊûÑÂª∫1 fpsÁöÑËæìÂÖ•Ê∫êÔºåÂπ∂‰ΩøÁî®ÁõëÁù£‰∏§ËΩÆÁõÆÊ†áÔºàÂåÖÊã¨Êé®ÁêÜÂíåÊúÄÁªàÁ≠îÊ°àÔºâÂØπQWEN-2.5-VL 7BËøõË°åÂæÆË∞É„ÄÇÂú®ReasonVQAÊï∞ÊçÆÈõÜ‰∏äÔºåÂ∫îÁî®ÁõëÁù£ÂæÆË∞ÉÔºàSFTÔºâÂíåÁõ¥Êé•ÂÅèÂ•Ω‰ºòÂåñÔºàDPOÔºâÔºåËØ•Êï∞ÊçÆÈõÜÂåÖÂê´12ÈÉ®ÁîµÂΩ±ÁöÑ239‰∏™‰∫∫Â∑•Ê†áÊ≥®ÁöÑÈóÆÈ¢ò-Á≠îÊ°àÂØπ‰ª•ÂèäÊé®ÁêÜÊèêÁ§∫„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÊòæËëóÊèêÈ´ò‰∫ÜÊÄßËÉΩÔºöF1ÂàÜÊï∞‰ªé0.212ÊèêÈ´òÂà∞0.543ÔºåBLEU-4‰ªé0.031ÊèêÈ´òÂà∞0.291ÔºåROUGE-L‰ªé0.196ÊèêÈ´òÂà∞0.528„ÄÇÁêÜÁî±Ë¥®Èáè‰πüÊòæËëóÊèêÈ´ò„ÄÇÂú®ÂêÑÁßçÊ±†ÂåñÂáΩÊï∞‰∏äËøõË°åÁöÑSFT + DPO‰∫§ÂèâËØÑ‰º∞Ë°®ÊòéÔºåÊó†ËÆ∫ËÆ≠ÁªÉÊàñÊµãËØïÊó∂‰ΩøÁî®ÁöÑÊ±†ÂåñÊñπÊ°àÂ¶Ç‰ΩïÔºåÂ¢ûÁõäÈÉΩÊåÅÁª≠Â≠òÂú®ÔºåË°®ÊòéÂú®Êó∂Â∫èËØÅÊçÆÊÄªÁªìÊñπÈù¢ÂÖ∑ÊúâÂæàÂº∫ÁöÑÈ≤ÅÊ£íÊÄß„ÄÇÂú®TVQAÁöÑÈõ∂Ê†∑Êú¨ËØÑ‰º∞‰∏≠‰πüËßÇÂØüÂà∞‰∫ÜÁ±ª‰ººÁöÑÁªìËÆ∫„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥ÈïøËßÜÈ¢ëÈóÆÁ≠î‰ªªÂä°‰∏≠ÔºåÁé∞ÊúâÊñπÊ≥ïÂõ†‰∏ä‰∏ãÊñáÁ™óÂè£ÈôêÂà∂ÂØºËá¥ÁöÑÊï∞ÊçÆÂà©Áî®Áéá‰Ωé‰∏ãÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÊó†Ê≥ïÊúâÊïàÂ§ÑÁêÜË∂ÖËøá50ÁßíÁöÑËßÜÈ¢ëÔºå‰∏îÂøΩÁï•‰∫ÜËßÜÈ¢ëÂ∏ß‰πãÈó¥ÁöÑÊó∂Èó¥Áõ∏ÂÖ≥ÊÄßÔºåÂØºËá¥‰ø°ÊÅØÊçüÂ§±„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÊó∂Â∫èÊ±†ÂåñÂ∞ÜËßÜÈ¢ëÂéãÁº©Êàê‰ΩéÂ∏ßÁéáÂõæÂÉèÔºåÂáèÂ∞ëËæìÂÖ•Â∫èÂàóÈïøÂ∫¶Ôºå‰ªéËÄåÂú®ÊúâÈôêÁöÑ‰∏ä‰∏ãÊñáÁ™óÂè£ÂÜÖÂ§ÑÁêÜÊõ¥ÈïøÁöÑËßÜÈ¢ë„ÄÇÂêåÊó∂ÔºåÂºïÂÖ•ÁêÜÁî±ÁîüÊàê‰Ωú‰∏∫ËæÖÂä©‰ªªÂä°ÔºåÊèêÂçáÊ®°ÂûãÂØπËßÜÈ¢ëÂÜÖÂÆπÁöÑÁêÜËß£ÂíåÊé®ÁêÜËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöPOVQAÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™Èò∂ÊÆµÔºö1) ËßÜÈ¢ëÈ¢ÑÂ§ÑÁêÜÔºö‰ΩøÁî®‰∏çÂêåÁöÑÊó∂Â∫èÊ±†ÂåñÊñπÊ≥ïÔºàBlend Blur with Last Frame„ÄÅWeighted Average„ÄÅExponentialÂíåRamp poolingÔºâÂ∞ÜËßÜÈ¢ëËΩ¨Êç¢‰∏∫1 fpsÁöÑÂõæÂÉèÂ∫èÂàó„ÄÇ2) Ê®°ÂûãÂæÆË∞ÉÔºö‰ΩøÁî®QWEN-2.5-VL 7B‰Ωú‰∏∫LVLMÔºåÈááÁî®ÁõëÁù£ÂæÆË∞ÉÔºàSFTÔºâÂíåÁõ¥Êé•ÂÅèÂ•Ω‰ºòÂåñÔºàDPOÔºâËøõË°åËÆ≠ÁªÉ„ÄÇ3) ÁêÜÁî±ÁîüÊàêÔºöÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠ÔºåÊ®°ÂûãÈúÄË¶ÅÁîüÊàêÂõûÁ≠îÈóÆÈ¢òÁöÑÁêÜÁî±Ôºå‰ª•ÊèêÈ´òÁ≠îÊ°àÁöÑÂáÜÁ°ÆÊÄßÂíåÂèØËß£ÈáäÊÄß„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1) ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊï∞ÊçÆÈ´òÊïàÁöÑËßÜÈ¢ëÈóÆÁ≠îÊµÅÁ®ãÔºåÈÄöËøáÊó∂Â∫èÊ±†ÂåñÂáèÂ∞ë‰∫ÜËÆ°ÁÆóÈáè„ÄÇ2) ÂºïÂÖ•ÁêÜÁî±ÁîüÊàê‰Ωú‰∏∫ËæÖÂä©‰ªªÂä°ÔºåÊèêÂçá‰∫ÜÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇ3) ÁªìÂêàSFTÂíåDPOÔºå‰ºòÂåñ‰∫ÜÊ®°ÂûãÁöÑÂÅèÂ•ΩÔºå‰ΩøÂÖ∂Êõ¥Á¨¶Âêà‰∫∫Á±ªÁöÑËÆ§Áü•„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Êó∂Â∫èÊ±†ÂåñÊñπÈù¢ÔºåËÆ∫ÊñáÂ∞ùËØï‰∫ÜÂ§öÁßçÊñπÊ≥ïÔºåÂåÖÊã¨Blend Blur with Last Frame„ÄÅWeighted Average„ÄÅExponentialÂíåRamp poolingÔºå‰ª•Êé¢Á¥¢ÊúÄ‰Ω≥ÁöÑÂéãÁº©Á≠ñÁï•„ÄÇÂú®Ê®°ÂûãËÆ≠ÁªÉÊñπÈù¢ÔºåËÆ∫Êñá‰ΩøÁî®‰∫ÜÁõëÁù£ÂæÆË∞ÉÔºàSFTÔºâÂíåÁõ¥Êé•ÂÅèÂ•Ω‰ºòÂåñÔºàDPOÔºâÔºåÂπ∂ËÆæËÆ°‰∫ÜÂåÖÂê´Êé®ÁêÜÂíåÊúÄÁªàÁ≠îÊ°àÁöÑ‰∏§ËΩÆÁõÆÊ†á„ÄÇReasonVQAÊï∞ÊçÆÈõÜÂåÖÂê´‰∫∫Â∑•Ê†áÊ≥®ÁöÑÈóÆÈ¢ò-Á≠îÊ°àÂØπ‰ª•ÂèäÊé®ÁêÜÊèêÁ§∫ÔºåÁî®‰∫éËÆ≠ÁªÉÂíåËØÑ‰º∞Ê®°Âûã„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåPOVQAÂú®ReasonVQAÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇF1ÂàÜÊï∞‰ªé0.212ÊèêÈ´òÂà∞0.543ÔºåBLEU-4‰ªé0.031ÊèêÈ´òÂà∞0.291ÔºåROUGE-L‰ªé0.196ÊèêÈ´òÂà∞0.528„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïÂú®‰∏çÂêåÊ±†ÂåñÁ≠ñÁï•‰∏ãË°®Áé∞Âá∫È≤ÅÊ£íÊÄßÔºåÂπ∂Âú®TVQAÊï∞ÊçÆÈõÜ‰∏äÂÆûÁé∞‰∫ÜÈõ∂Ê†∑Êú¨ËøÅÁßª„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

POVQAÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂåÖÊã¨Êô∫ËÉΩÁõëÊéß„ÄÅËßÜÈ¢ëÂÜÖÂÆπÂàÜÊûê„ÄÅÊïôËÇ≤ËßÜÈ¢ëÈóÆÁ≠î„ÄÅÁîµÂΩ±ÁêÜËß£Á≠âÈ¢ÜÂüü„ÄÇËØ•ÊñπÊ≥ïÂèØ‰ª•Â∏ÆÂä©Áî®Êà∑Âø´ÈÄüÁêÜËß£ËßÜÈ¢ëÂÜÖÂÆπÔºåÂπ∂‰ªé‰∏≠ÊèêÂèñÂÖ≥ÈîÆ‰ø°ÊÅØ„ÄÇÈÄöËøáÁªìÂêàÁêÜÁî±ÁîüÊàêÔºåÂèØ‰ª•ÊèêÈ´òÈóÆÁ≠îÁªìÊûúÁöÑÂèØ‰ø°Â∫¶ÂíåÂèØËß£ÈáäÊÄßÔºå‰∏∫Áî®Êà∑Êèê‰æõÊõ¥ÂèØÈù†ÁöÑÂÜ≥Á≠ñÊîØÊåÅ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Video Question Answering (VQA) with Large Vision Language Models (LVLMs) has gained significant traction in research ever since the Flamingo was introduced by Deepmind. Recent advancements in large context/long video question answering have allowed VQA tasks to have context window of 1500+ frames. However, this only leads to 50 seconds of video footage without losing any significant information. We introduce POVQA, a data-efficient pipeline that compresses each second of video into a single temporally pooled image (via motion blur and weighted averaging variants) and then align LVLMs with lightweight supervision. Concretely, we build 1 fps input sources using Blend Blur with Last Frame, Weighted Average, Exponential and Ramp pooling and fine-tune QWEN-2.5-VL 7B with supervised two turn target including reasoning and final answer. We apply Supervised Fine Tuning (SFT) and Direct Preference Optimization (DPO) on our novel dataset ReasonVQA consisting of 12 movies with 239 human annotated question-answer with reasoning prompts. On our ReasonVQA dataset, this method dramatically improves performance over pooled baselines: F1 score improves from 0.212 to 0.543, BLEU-4 from 0.031 to 0.291, and ROUGE-L from 0.196 to 0.528. Rationale quality also significantly increases. Cross-evaluation of SFT + DPO on various pooling functions show that the gains persist regardless of the pooling scheme used at train or test time, indicating strong robustness on summarization of temporal evidence. Similar observations were made on zero-shot in TVQA.

