---
layout: default
title: Can World Models Benefit VLMs for World Dynamics?
---

# Can World Models Benefit VLMs for World Dynamics?

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.00855" target="_blank" class="toolbar-btn">arXiv: 2510.00855v1</a>
    <a href="https://arxiv.org/pdf/2510.00855.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.00855v1" 
            onclick="toggleFavorite(this, '2510.00855v1', 'Can World Models Benefit VLMs for World Dynamics?')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Kevin Zhang, Kuangzhi Ge, Xiaowei Chi, Renrui Zhang, Shaojun Shi, Zhen Dong, Sirui Han, Shanghang Zhang

**ÂàÜÁ±ª**: cs.CV, cs.AI, cs.CL, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-01

**Â§áÊ≥®**: Project page: https://dyva-worldlm.github.io

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫WorldLMÔºåÂà©Áî®‰∏ñÁïåÊ®°ÂûãÂÖàÈ™åÂ¢ûÂº∫ËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÁöÑ‰∏ñÁïåÂä®ÊÄÅÁêÜËß£ËÉΩÂäõ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `‰∏ñÁïåÊ®°Âûã` `ËßÜËßâËØ≠Ë®ÄÊ®°Âûã` `ËßÜÈ¢ëÊâ©Êï£Ê®°Âûã` `ÁîüÊàêÂºèÁºñÁ†ÅÂô®` `Á©∫Èó¥Êé®ÁêÜ` `Âä®ÊÄÅÁêÜËß£` `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `ËøêÂä®‰∏ÄËá¥ÊÄß`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÂú®Â§ÑÁêÜÊ∂âÂèäÂä®ÊÄÅÂèòÂåñÂíåÁ©∫Èó¥Êé®ÁêÜÁöÑ‰ªªÂä°Êó∂Â≠òÂú®‰∏çË∂≥ÔºåÁº∫‰πèÂØπ‰∏ñÁïåÂä®ÊÄÅÁöÑÊúâÊïàÂª∫Ê®°„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫WorldLMÔºåÂà©Áî®ËßÜÈ¢ëÊâ©Êï£Ê®°Âûã‰Ωú‰∏∫ÁîüÊàêÂºèÁºñÁ†ÅÂô®ÔºåÊèêÂèñÂåÖÂê´ËøêÂä®‰ø°ÊÅØÁöÑËßÜËßâÂµåÂÖ•Ôºå‰ªéËÄåÂºïÂÖ•‰∏ñÁïåÊ®°ÂûãÂÖàÈ™å„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåÊèêÂá∫ÁöÑDynamic Vision Aligner (DyVA) Âú®Á©∫Èó¥Êé®ÁêÜ‰ªªÂä°‰∏äË∂ÖË∂ä‰∫ÜÁé∞ÊúâÊ®°ÂûãÔºåÂπ∂ÊèêÂçá‰∫ÜÂçïÂõæÂÉèÊ®°ÂûãÁöÑÂ§öÂ∏ßÊé®ÁêÜËÉΩÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊé¢ËÆ®‰∫Ü‰∏ñÁïåÊ®°ÂûãÔºàWorld ModelsÔºâËÉΩÂê¶ÊèêÂçáËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÔºàVLMsÔºâÂØπ‰∏ñÁïåÂä®ÊÄÅÁöÑÁêÜËß£ËÉΩÂäõ„ÄÇ‰∏ñÁïåÊ®°ÂûãÈÄöËøá‰∫íËÅîÁΩëËßÑÊ®°ÁöÑËßÜÈ¢ëÊï∞ÊçÆËÆ≠ÁªÉÔºåËÉΩÂ§üÁîüÊàêËøûË¥Ø‰∏îÂêàÁêÜÁöÑÁªìÊûÑ„ÄÅËøêÂä®ÂíåÁâ©ÁêÜÂä®ÊÄÅÔºåË¢´ËÆ§‰∏∫ÊòØÂº∫Â§ßÁöÑ‰∏ñÁïåÊ®°ÊãüÂô®„ÄÇÊú¨ÊñáÂ∞ÜËßÜÈ¢ëÊâ©Êï£Ê®°ÂûãÈáçÊñ∞Áî®‰ΩúÁîüÊàêÂºèÁºñÁ†ÅÂô®ÔºåÊâßË°åÂçïÊ≠•ÂéªÂô™ÔºåÂπ∂Â∞ÜÂæóÂà∞ÁöÑÊΩúÂú®ÂèòÈáè‰Ωú‰∏∫ËßÜËßâÂµåÂÖ•„ÄÇÈÄöËøáÂØπËøôÁ±ªÊ®°ÂûãÔºàÁß∞‰∏∫WorldLMsÔºâÁöÑÂÆûËØÅÁ†îÁ©∂ÔºåÂèëÁé∞ÁîüÊàêÂºèÁºñÁ†ÅÂô®ËÉΩÂ§üÊçïËé∑ÂØπ‰∏ãÊ∏∏ÁêÜËß£ÊúâÁî®ÁöÑÊΩúÂú®ÂèòÈáèÔºåËøô‰∫õÂèòÈáè‰∏é‰º†ÁªüÁºñÁ†ÅÂô®ÊúâÊâÄ‰∏çÂêå„ÄÇÊúÄ‰Ω≥Ê®°ÂûãDynamic Vision Aligner (DyVA) ÊòæËëóÂ¢ûÂº∫‰∫ÜÁ©∫Èó¥Êé®ÁêÜËÉΩÂäõÔºåÂπ∂‰ΩøÂçïÂõæÂÉèÊ®°ÂûãËÉΩÂ§üÊâßË°åÂ§öÂ∏ßÊé®ÁêÜ„ÄÇÂú®ËßÜËßâÊé®ÁêÜ‰ªªÂä°‰∏≠ÔºåDyVAË∂ÖË∂ä‰∫ÜÂºÄÊ∫êÂíå‰∏ìÊúâÂü∫Á∫øÔºåÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÊàñÂèØÊØîÁöÑÊÄßËÉΩ„ÄÇËøô‰∫õÊèêÂçáÂΩíÂõ†‰∫éWorldLM‰ªéËßÜÈ¢ëÈ¢ÑËÆ≠ÁªÉ‰∏≠ÁªßÊâøÁöÑËøêÂä®‰∏ÄËá¥ÊÄßÂÜÖÂåñ„ÄÇÊúÄÂêéÔºåÁ≥ªÁªüÂú∞Êé¢Á¥¢‰∫ÜÂπøÊ≥õÁöÑÊ®°ÂûãËÆæËÆ°Ôºå‰∏∫Êú™Êù•ÁöÑÂ∑•‰ΩúÊåáÊòé‰∫ÜÊñπÂêë„ÄÇÂ∏åÊúõËøôÈ°πÁ†îÁ©∂ËÉΩ‰∏∫Âà©Áî®‰∏ñÁïåÊ®°ÂûãÂÖàÈ™åÁöÑÊñ∞ÂûãVLMÈì∫Âπ≥ÈÅìË∑ØÔºåÂπ∂ÊúùÁùÄÈÄöÁî®ËßÜËßâÂ≠¶‰π†Âô®ÁöÑÊñπÂêëÂèëÂ±ï„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÂú®ÁêÜËß£‰∏ñÁïåÂä®ÊÄÅÂíåËøõË°åÁ©∫Èó¥Êé®ÁêÜÊñπÈù¢Â≠òÂú®Â±ÄÈôêÊÄß„ÄÇ‰º†ÁªüÁöÑËßÜËßâÁºñÁ†ÅÂô®Èöæ‰ª•ÊçïÊçâËßÜÈ¢ë‰∏≠ÁöÑÊó∂Èó¥‰ø°ÊÅØÂíåËøêÂä®ËßÑÂæãÔºåÂØºËá¥Ê®°ÂûãÂú®Â§ÑÁêÜÈúÄË¶ÅÁêÜËß£Áâ©‰ΩìËøêÂä®„ÄÅ‰∫§‰∫íÂíåÂèòÂåñÁöÑÂú∫ÊôØÊó∂Ë°®Áé∞‰∏ç‰Ω≥„ÄÇÂõ†Ê≠§ÔºåÂ¶Ç‰ΩïÊúâÊïàÂú∞Â∞Ü‰∏ñÁïåÂä®ÊÄÅÁü•ËØÜËûçÂÖ•ËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÊòØ‰∏Ä‰∏™ÂÖ≥ÈîÆÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®È¢ÑËÆ≠ÁªÉÁöÑ‰∏ñÁïåÊ®°Âûã‰Ωú‰∏∫ËßÜËßâÁºñÁ†ÅÂô®ÔºåÂ∞ÜËßÜÈ¢ëÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âà∞ÁöÑËøêÂä®ËßÑÂæãÂíåÁâ©ÁêÜÁü•ËØÜËøÅÁßªÂà∞ËßÜËßâËØ≠Ë®ÄÊ®°Âûã‰∏≠„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåËÆ∫Êñá‰ΩøÁî®ËßÜÈ¢ëÊâ©Êï£Ê®°Âûã‰Ωú‰∏∫ÁîüÊàêÂºèÁºñÁ†ÅÂô®ÔºåÈÄöËøáÂçïÊ≠•ÂéªÂô™ËøáÁ®ãÊèêÂèñËßÜËßâÁâπÂæÅÔºåËøô‰∫õÁâπÂæÅÂåÖÂê´‰∫Ü‰∏∞ÂØåÁöÑËøêÂä®‰ø°ÊÅØÂíå‰∏ñÁïåÂä®ÊÄÅÂÖàÈ™å„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ≠•È™§Ôºö1) ‰ΩøÁî®È¢ÑËÆ≠ÁªÉÁöÑËßÜÈ¢ëÊâ©Êï£Ê®°Âûã‰Ωú‰∏∫ÁîüÊàêÂºèÁºñÁ†ÅÂô®Ôºõ2) ÂØπËæìÂÖ•ÂõæÂÉèÊàñËßÜÈ¢ëÂ∏ßËøõË°åÂçïÊ≠•ÂéªÂô™ÔºåÂæóÂà∞ËßÜËßâÂµåÂÖ•Ôºõ3) Â∞ÜËßÜËßâÂµåÂÖ•ËæìÂÖ•Âà∞ËßÜËßâËØ≠Ë®ÄÊ®°Âûã‰∏≠ËøõË°å‰∏ãÊ∏∏‰ªªÂä°ÁöÑËÆ≠ÁªÉÂíåÊé®ÁêÜ„ÄÇÊèêÂá∫ÁöÑDynamic Vision Aligner (DyVA) ÊòØ‰∏Ä‰∏™ÂÖ∑‰ΩìÁöÑWorldLMÂÆûÁé∞ÔºåÂÆÉÂà©Áî®TransformerÁªìÊûÑÂØπËßÜËßâÂµåÂÖ•ËøõË°åÂ§ÑÁêÜÔºåÂπ∂Â∞ÜÂÖ∂‰∏éÊñáÊú¨ÂµåÂÖ•ËøõË°åÂØπÈΩê„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞Ü‰∏ñÁïåÊ®°ÂûãÔºàÁâπÂà´ÊòØËßÜÈ¢ëÊâ©Êï£Ê®°ÂûãÔºâÂºïÂÖ•ËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÔºåÂπ∂Â∞ÜÂÖ∂Áî®‰ΩúÁîüÊàêÂºèÁºñÁ†ÅÂô®„ÄÇËøôÁßçÊñπÊ≥ïËÉΩÂ§üÊúâÊïàÂú∞Â∞ÜËßÜÈ¢ëÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âà∞ÁöÑËøêÂä®ËßÑÂæãÂíåÁâ©ÁêÜÁü•ËØÜËøÅÁßªÂà∞ËßÜËßâËØ≠Ë®ÄÊ®°Âûã‰∏≠Ôºå‰ªéËÄåÊèêÂçáÊ®°ÂûãÂØπ‰∏ñÁïåÂä®ÊÄÅÁöÑÁêÜËß£ËÉΩÂäõ„ÄÇ‰∏é‰º†ÁªüÁöÑËßÜËßâÁºñÁ†ÅÂô®Áõ∏ÊØîÔºåÁîüÊàêÂºèÁºñÁ†ÅÂô®ËÉΩÂ§üÊçïËé∑Êõ¥‰∏∞ÂØåÁöÑËøêÂä®‰ø°ÊÅØÂíå‰∏ä‰∏ãÊñá‰ø°ÊÅØ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ‰ΩøÁî®È¢ÑËÆ≠ÁªÉÁöÑËßÜÈ¢ëÊâ©Êï£Ê®°ÂûãÔºåÁ°Æ‰øùÁºñÁ†ÅÂô®ÂÖ∑ÊúâÂº∫Â§ßÁöÑ‰∏ñÁïåÂä®ÊÄÅÂª∫Ê®°ËÉΩÂäõÔºõ2) ‰ΩøÁî®ÂçïÊ≠•ÂéªÂô™ËøáÁ®ãÔºå‰ª•È´òÊïàÂú∞ÊèêÂèñËßÜËßâÂµåÂÖ•Ôºõ3) ËÆæËÆ°Dynamic Vision Aligner (DyVA) Ê®°ÂûãÔºåÂà©Áî®TransformerÁªìÊûÑÂØπËßÜËßâÂµåÂÖ•ËøõË°åÂ§ÑÁêÜÔºåÂπ∂Â∞ÜÂÖ∂‰∏éÊñáÊú¨ÂµåÂÖ•ËøõË°åÂØπÈΩê„ÄÇËÆ∫ÊñáËøòÊé¢Á¥¢‰∫Ü‰∏çÂêåÁöÑÊ®°ÂûãËÆæËÆ°Ôºå‰æãÂ¶Ç‰∏çÂêåÁöÑÂéªÂô™Ê≠•Êï∞„ÄÅ‰∏çÂêåÁöÑTransformerÁªìÊûÑÁ≠âÔºå‰ª•ÊâæÂà∞ÊúÄ‰Ω≥ÁöÑÊ®°ÂûãÈÖçÁΩÆ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊèêÂá∫ÁöÑDynamic Vision Aligner (DyVA) Âú®ËßÜËßâÊé®ÁêÜ‰ªªÂä°‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåË∂ÖË∂ä‰∫ÜÁé∞ÊúâÁöÑÂºÄÊ∫êÂíå‰∏ìÊúâÊ®°Âûã„ÄÇ‰æãÂ¶ÇÔºåÂú®Êüê‰∫õÁ©∫Èó¥Êé®ÁêÜ‰ªªÂä°‰∏äÔºåDyVAÁöÑÊÄßËÉΩÊèêÂçáÂπÖÂ∫¶Ë∂ÖËøá‰∫Ü10%„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéÔºåÂà©Áî®‰∏ñÁïåÊ®°ÂûãÂÖàÈ™åÂèØ‰ª•ÊúâÊïàÂú∞ÊèêÂçáËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÂØπ‰∏ñÁïåÂä®ÊÄÅÁöÑÁêÜËß£ËÉΩÂäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫ÂØºËà™„ÄÅËá™Âä®È©æÈ©∂„ÄÅËßÜÈ¢ëÁêÜËß£„ÄÅÊô∫ËÉΩÁõëÊéßÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÊèêÂçáËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÂØπ‰∏ñÁïåÂä®ÊÄÅÁöÑÁêÜËß£ËÉΩÂäõÔºåÂèØ‰ª•‰ΩøÊú∫Âô®‰∫∫Âú®Â§çÊùÇÁéØÂ¢É‰∏≠Êõ¥Â•ΩÂú∞ÊÑüÁü•„ÄÅÊé®ÁêÜÂíåÂÜ≥Á≠ñÔºå‰ªéËÄåÂÆûÁé∞Êõ¥Êô∫ËÉΩÂåñÁöÑÂ∫îÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Trained on internet-scale video data, generative world models are increasingly recognized as powerful world simulators that can generate consistent and plausible dynamics over structure, motion, and physics. This raises a natural question: with the advent of strong video foundational models, might they supplant conventional vision encoder paradigms for general-purpose multimodal understanding? While recent studies have begun to explore the potential of world models on common vision tasks, these explorations typically lack a systematic investigation of generic, multimodal tasks. In this work, we strive to investigate the capabilities when world model priors are transferred into Vision-Language Models: we re-purpose a video diffusion model as a generative encoder to perform a single denoising step and treat the resulting latents as a set of visual embedding. We empirically investigate this class of models, which we refer to as World-Language Models (WorldLMs), and we find that generative encoders can capture latents useful for downstream understanding that show distinctions from conventional encoders. Naming our best-performing variant Dynamic Vision Aligner (DyVA), we further discover that this method significantly enhances spatial reasoning abilities and enables single-image models to perform multi-frame reasoning. Through the curation of a suite of visual reasoning tasks, we find DyVA to surpass both open-source and proprietary baselines, achieving state-of-the-art or comparable performance. We attribute these gains to WorldLM's inherited motion-consistency internalization from video pre-training. Finally, we systematically explore extensive model designs to highlight promising directions for future work. We hope our study can pave the way for a new family of VLMs that leverage priors from world models and are on a promising path towards generalist vision learners.

