---
layout: default
title: Feature Identification for Hierarchical Contrastive Learning
---

# Feature Identification for Hierarchical Contrastive Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.00837" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.00837v1</a>
  <a href="https://arxiv.org/pdf/2510.00837.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.00837v1" onclick="toggleFavorite(this, '2510.00837v1', 'Feature Identification for Hierarchical Contrastive Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Julius Ott, Nastassia Vysotskaya, Huawei Sun, Lorenzo Servadei, Robert Wille

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-10-01

**å¤‡æ³¨**: Submitted to ICASSP 2026

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸¤ç§å±‚çº§å¯¹æ¯”å­¦ä¹ æ–¹æ³•ï¼Œåˆ©ç”¨å±‚çº§å…³ç³»æå‡ç»†ç²’åº¦åˆ†ç±»æ€§èƒ½ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å±‚çº§åˆ†ç±»` `å¯¹æ¯”å­¦ä¹ ` `é«˜æ–¯æ··åˆæ¨¡å‹` `æ³¨æ„åŠ›æœºåˆ¶` `ç»†ç²’åº¦åˆ†ç±»` `è®¡ç®—æœºè§†è§‰` `è¡¨ç¤ºå­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿåˆ†ç±»æ–¹æ³•å¿½ç•¥äº†å±‚çº§ç»“æ„ä¸­å›ºæœ‰çš„ç±»é—´å…³ç³»ï¼Œä¸¢å¤±äº†é‡è¦çš„ç›‘ç£ä¿¡å·ã€‚
2. æå‡ºG-HMLCå’ŒA-HMLCä¸¤ç§æ–¹æ³•ï¼Œåˆ†åˆ«åˆ©ç”¨é«˜æ–¯æ··åˆæ¨¡å‹å’Œæ³¨æ„åŠ›æœºåˆ¶æ•è·å±‚çº§ç‰¹å¾ã€‚
3. åœ¨CIFAR100å’ŒModelNet40æ•°æ®é›†ä¸Šï¼Œçº¿æ€§è¯„ä¼°å‡†ç¡®ç‡è¶…è¶Šç°æœ‰æ–¹æ³•2ä¸ªç™¾åˆ†ç‚¹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸¤ç§æ–°é¢–çš„å±‚çº§å¯¹æ¯”å­¦ä¹ ï¼ˆHMLCï¼‰æ–¹æ³•ï¼Œç”¨äºè§£å†³å±‚çº§åˆ†ç±»é—®é¢˜ã€‚ç¬¬ä¸€ç§æ–¹æ³•ï¼ˆG-HMLCï¼‰åˆ©ç”¨é«˜æ–¯æ··åˆæ¨¡å‹ï¼Œç¬¬äºŒç§æ–¹æ³•ï¼ˆA-HMLCï¼‰ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶æ¥æ•è·å±‚çº§ç‰¹å®šçš„ç‰¹å¾ï¼Œæ¨¡ä»¿äººç±»å¤„ç†æ–¹å¼ã€‚è¯¥æ–¹æ³•æ˜¾å¼åœ°å»ºæ¨¡äº†ä¸åŒå±‚çº§é—´çš„ç±»é—´å…³ç³»ä»¥åŠé«˜å±‚çº§çš„ä¸å¹³è¡¡ç±»åˆ†å¸ƒï¼Œä»è€Œå®ç°è·¨æ‰€æœ‰å±‚çº§çš„ç»†ç²’åº¦èšç±»ã€‚åœ¨CIFAR100å’ŒModelNet40æ•°æ®é›†ä¸Šçš„çº¿æ€§è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œåœ¨å‡†ç¡®ç‡æ–¹é¢ä¼˜äºç°æœ‰çš„å±‚çº§å¯¹æ¯”å­¦ä¹ æ–¹æ³•2ä¸ªç™¾åˆ†ç‚¹ã€‚å®šé‡å’Œå®šæ€§ç»“æœå‡æ”¯æŒäº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œçªå‡ºäº†å…¶åœ¨è®¡ç®—æœºè§†è§‰åŠå…¶ä»–é¢†åŸŸçš„åº”ç”¨æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå±‚çº§åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œç°æœ‰æ–¹æ³•å¿½ç•¥äº†ä¸åŒå±‚çº§ç±»åˆ«ä¹‹é—´çš„å…³ç³»ï¼Œæœªèƒ½å……åˆ†åˆ©ç”¨å±‚çº§ç»“æ„æä¾›çš„ç›‘ç£ä¿¡æ¯ã€‚è¿™å¯¼è‡´æ¨¡å‹æ— æ³•æœ‰æ•ˆåŒºåˆ†ç»†ç²’åº¦ç±»åˆ«ï¼Œå°¤å…¶æ˜¯åœ¨é«˜å±‚çº§ç±»åˆ«åˆ†å¸ƒä¸å¹³è¡¡çš„æƒ…å†µä¸‹ï¼Œæ€§èƒ½ä¼šå—åˆ°æ˜¾è‘—å½±å“ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œæ˜¾å¼åœ°å»ºæ¨¡å±‚çº§ç»“æ„ä¸­çš„ç±»é—´å…³ç³»ã€‚é€šè¿‡åœ¨é«˜å±‚çº§å¼•å…¥é«˜æ–¯æ··åˆæ¨¡å‹æˆ–æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰å±‚çº§ç‰¹å®šçš„ç‰¹å¾ï¼Œå¹¶å­¦ä¹ åˆ°æ›´å…·åŒºåˆ†æ€§çš„è¡¨ç¤ºã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨æ¨¡ä»¿äººç±»åœ¨å¤„ç†å±‚çº§ä¿¡æ¯æ—¶çš„è®¤çŸ¥æ–¹å¼ï¼Œä»è€Œæå‡åˆ†ç±»æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ç‰¹å¾æå–ã€å±‚çº§å…³ç³»å»ºæ¨¡å’Œå¯¹æ¯”å­¦ä¹ ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚é¦–å…ˆï¼Œä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œæå–å›¾åƒæˆ–3Dæ¨¡å‹çš„ç‰¹å¾ã€‚ç„¶åï¼ŒG-HMLCæ–¹æ³•ä½¿ç”¨é«˜æ–¯æ··åˆæ¨¡å‹å¯¹é«˜å±‚çº§ç±»åˆ«è¿›è¡Œå»ºæ¨¡ï¼ŒA-HMLCæ–¹æ³•åˆ™ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶æ¥å…³æ³¨ä¸åŒå±‚çº§çš„ç‰¹å¾ã€‚æœ€åï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°ï¼Œä¿ƒä½¿æ¨¡å‹å­¦ä¹ åˆ°èƒ½å¤ŸåŒºåˆ†ä¸åŒå±‚çº§ç±»åˆ«çš„è¡¨ç¤ºã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå°†å¯¹æ¯”å­¦ä¹ ä¸å±‚çº§ç»“æ„ç›¸ç»“åˆï¼Œå¹¶æå‡ºäº†ä¸¤ç§ä¸åŒçš„å±‚çº§å…³ç³»å»ºæ¨¡æ–¹æ³•ï¼ˆG-HMLCå’ŒA-HMLCï¼‰ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæœ¬æ–‡çš„æ–¹æ³•èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨å±‚çº§ç»“æ„æä¾›çš„ç›‘ç£ä¿¡æ¯ï¼Œä»è€Œæå‡ç»†ç²’åº¦åˆ†ç±»çš„æ€§èƒ½ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸åªå…³æ³¨æœ€åä¸€å±‚çš„åˆ†ç±»ï¼Œè€Œå¿½ç•¥äº†å±‚çº§ç»“æ„ä¸­è•´å«çš„ä¸°å¯Œä¿¡æ¯ã€‚

**å…³é”®è®¾è®¡**ï¼šG-HMLCæ–¹æ³•çš„å…³é”®è®¾è®¡åœ¨äºé«˜æ–¯æ··åˆæ¨¡å‹çš„å‚æ•°è®¾ç½®ï¼Œä¾‹å¦‚é«˜æ–¯åˆ†é‡çš„æ•°é‡å’Œæ–¹å·®ã€‚A-HMLCæ–¹æ³•çš„å…³é”®è®¾è®¡åœ¨äºæ³¨æ„åŠ›æœºåˆ¶çš„ç»“æ„å’Œè®­ç»ƒæ–¹å¼ï¼Œä¾‹å¦‚æ³¨æ„åŠ›å¤´çš„æ•°é‡å’Œæ³¨æ„åŠ›æƒé‡çš„è®¡ç®—æ–¹æ³•ã€‚å¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°é€šå¸¸é‡‡ç”¨InfoNCEæŸå¤±ï¼Œéœ€è¦ä»”ç»†è°ƒæ•´æ¸©åº¦å‚æ•°ä»¥è·å¾—æœ€ä½³æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæ•°æ®å¢å¼ºç­–ç•¥çš„é€‰æ‹©ä¹Ÿä¼šå½±å“æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨CIFAR100å’ŒModelNet40æ•°æ®é›†ä¸Šï¼Œæœ¬æ–‡æå‡ºçš„æ–¹æ³•åœ¨çº¿æ€§è¯„ä¼°ä¸­å–å¾—äº†state-of-the-artçš„æ€§èƒ½ï¼Œè¶…è¶Šäº†ç°æœ‰çš„å±‚çº§å¯¹æ¯”å­¦ä¹ æ–¹æ³•2ä¸ªç™¾åˆ†ç‚¹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨å±‚çº§ç»“æ„ä¿¡æ¯ï¼Œæå‡ç»†ç²’åº¦åˆ†ç±»çš„å‡†ç¡®æ€§ã€‚æ¶ˆèå®éªŒéªŒè¯äº†é«˜æ–¯æ··åˆæ¨¡å‹å’Œæ³¨æ„åŠ›æœºåˆ¶åœ¨å±‚çº§å…³ç³»å»ºæ¨¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºè®¡ç®—æœºè§†è§‰å’Œæœºå™¨äººé¢†åŸŸçš„å±‚çº§åˆ†ç±»ä»»åŠ¡ï¼Œä¾‹å¦‚å›¾åƒåˆ†ç±»ã€ç‰©ä½“è¯†åˆ«ã€åœºæ™¯ç†è§£ç­‰ã€‚åœ¨ç”Ÿç‰©åŒ»å­¦é¢†åŸŸï¼Œå¯ç”¨äºç–¾ç—…è¯Šæ–­å’ŒåŸºå› åˆ†ç±»ã€‚åœ¨å·¥ä¸šç•Œï¼Œå¯ç”¨äºäº§å“åˆ†ç±»å’Œè´¨é‡æ£€æµ‹ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿæå‡ç»†ç²’åº¦åˆ†ç±»çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ï¼Œå…·æœ‰é‡è¦çš„å®é™…åº”ç”¨ä»·å€¼å’Œæ½œåœ¨çš„å•†ä¸šå‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Hierarchical classification is a crucial task in many applications, where objects are organized into multiple levels of categories. However, conventional classification approaches often neglect inherent inter-class relationships at different hierarchy levels, thus missing important supervisory signals. Thus, we propose two novel hierarchical contrastive learning (HMLC) methods. The first, leverages a Gaussian Mixture Model (G-HMLC) and the second uses an attention mechanism to capture hierarchy-specific features (A-HMLC), imitating human processing. Our approach explicitly models inter-class relationships and imbalanced class distribution at higher hierarchy levels, enabling fine-grained clustering across all hierarchy levels. On the competitive CIFAR100 and ModelNet40 datasets, our method achieves state-of-the-art performance in linear evaluation, outperforming existing hierarchical contrastive learning methods by 2 percentage points in terms of accuracy. The effectiveness of our approach is backed by both quantitative and qualitative results, highlighting its potential for applications in computer vision and beyond.

