---
layout: default
title: JEPA-T: Joint-Embedding Predictive Architecture with Text Fusion for Image Generation
---

# JEPA-T: Joint-Embedding Predictive Architecture with Text Fusion for Image Generation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.00974" target="_blank" class="toolbar-btn">arXiv: 2510.00974v1</a>
    <a href="https://arxiv.org/pdf/2510.00974.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.00974v1" 
            onclick="toggleFavorite(this, '2510.00974v1', 'JEPA-T: Joint-Embedding Predictive Architecture with Text Fusion for Image Generation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Siheng Wan, Zhengtao Yao, Zhengdao Li, Junhao Dong, Yanshu Li, Yikai Li, Linshan Li, Haoyan Xu, Yijiang Li, Zhikang Dong, Huacan Wang, Jifeng Shen

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-01

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/justin-herry/JEPA-T.git)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫JEPA-TÔºåÈÄöËøáÊñáÊú¨ËûçÂêàÁöÑËÅîÂêàÂµåÂÖ•È¢ÑÊµãÊû∂ÊûÑÊèêÂçáÂõæÂÉèÁîüÊàêÊïàÊûú**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÊñáÊú¨Âà∞ÂõæÂÉèÁîüÊàê` `ËÅîÂêàÂµåÂÖ•` `Transformer` `‰∫§ÂèâÊ≥®ÊÑèÂäõ` `Êù°‰ª∂ÂéªÂô™` `Â§öÊ®°ÊÄÅËûçÂêà` `Ëá™ÁõëÁù£Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñáÊú¨Âà∞ÂõæÂÉèÁîüÊàêÊñπÊ≥ïÈöæ‰ª•ÊúâÊïàËûçÂêàÊñáÊú¨ÂíåËßÜËßâtokenÔºåÈôêÂà∂‰∫ÜÁîüÊàêÊïàÊûú„ÄÇ
2. JEPA-TÊèêÂá∫ËÅîÂêàÂµåÂÖ•È¢ÑÊµãTransformerÔºåÁªìÂêà‰∫§ÂèâÊ≥®ÊÑèÂäõÂíåÁõÆÊ†áÁ∫ßÂà´ÂØπÈΩêÔºåÂ¢ûÂº∫ÊñáÊú¨ÂíåÂõæÂÉèÁöÑËûçÂêà„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåJEPA-TÂú®Êï∞ÊçÆÊïàÁéáÂíåÂºÄÊîæËØçÊ±áÊ≥õÂåñÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤Ôºå‰ºò‰∫éÁé∞ÊúâÂü∫Á∫øÊñπÊ≥ï„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Áé∞‰ª£ÊñáÊú¨Âà∞ÂõæÂÉèÔºàT2IÔºâÁîüÊàêË∂äÊù•Ë∂ä‰æùËµñ‰∫é‰ΩøÁî®Ëá™ÁõëÁù£ËÆ≠ÁªÉÁöÑ‰ª•token‰∏∫‰∏≠ÂøÉÁöÑÊû∂ÊûÑÔºåÁÑ∂ËÄåÔºåÊúâÊïàÂú∞ËûçÂêàÊñáÊú¨ÂíåËßÜËßâtoken‰ªçÁÑ∂ÊòØ‰∏Ä‰∏™ÊåëÊàò„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫ÜJEPA-TÔºå‰∏Ä‰∏™Áªü‰∏ÄÁöÑÂ§öÊ®°ÊÄÅÊ°ÜÊû∂ÔºåÂÆÉÂ∞ÜÂõæÂÉèÂíåÊ†áÈ¢òÁºñÁ†Å‰∏∫Á¶ªÊï£ÁöÑËßÜËßâÂíåÊñáÊú¨tokenÔºåÂπ∂Áî±ËÅîÂêàÂµåÂÖ•È¢ÑÊµãTransformerÂ§ÑÁêÜ„ÄÇ‰∏∫‰∫ÜÂ¢ûÂº∫ËûçÂêàÔºåÊàë‰ª¨Âú®ÁâπÂæÅÈ¢ÑÊµãÂô®‰πãÂêéÂä†ÂÖ•‰∫Ü‰∫§ÂèâÊ≥®ÊÑèÂäõÔºåÁî®‰∫éÊù°‰ª∂ÂéªÂô™ÔºåÂêåÊó∂‰øùÊåÅ‰ªªÂä°Êó†ÂÖ≥ÁöÑÈ™®Âπ≤ÁΩëÁªú„ÄÇÊ≠§Â§ñÔºåÂú®ÊµÅÂåπÈÖçÊçüÂ§±‰πãÂâçÊ≥®ÂÖ•ÂéüÂßãÊñáÊú¨ÂµåÂÖ•Ôºå‰ª•ÊèêÈ´òËÆ≠ÁªÉÊúüÈó¥ÁöÑÂØπÈΩê„ÄÇÂú®Êé®ÁêÜËøáÁ®ã‰∏≠ÔºåÂêå‰∏ÄÁΩëÁªúÈÄöËøáËø≠‰ª£Âú∞ÂØπ‰ª•ÊñáÊú¨‰∏∫Êù°‰ª∂ÁöÑËßÜËßâtokenËøõË°åÂéªÂô™ÔºåÊù•ÊâßË°åÁ±ªÊù°‰ª∂ÂíåËá™Áî±ÊñáÊú¨ÂõæÂÉèÁîüÊàê„ÄÇÂú®ImageNet-1K‰∏äÁöÑËØÑ‰º∞Ë°®ÊòéÔºåJEPA-TÂÆûÁé∞‰∫ÜÂº∫Â§ßÁöÑÊï∞ÊçÆÊïàÁéá„ÄÅÂºÄÊîæËØçÊ±áÊ≥õÂåñÔºåÂπ∂‰∏îÂßãÁªà‰ºò‰∫éÈùûËûçÂêàÂíåÊôöÊúüËûçÂêàÂü∫Á∫ø„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïË°®ÊòéÔºåÊôöÊúüÊû∂ÊûÑËûçÂêà‰∏éÁõÆÊ†áÁ∫ßÂà´ÁöÑÂØπÈΩêÁõ∏ÁªìÂêàÔºåÂú®Âü∫‰∫étokenÁöÑT2I‰∏≠ÔºåÂú®Êù°‰ª∂Âº∫Â∫¶ÂíåÈ™®Âπ≤ÈÄöÁî®ÊÄß‰πãÈó¥Êèê‰æõ‰∫Ü‰∏Ä‰∏™ÊúâÊïàÁöÑÂπ≥Ë°°„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÊñáÊú¨Âà∞ÂõæÂÉèÁîüÊàêÊ®°ÂûãÔºåÁâπÂà´ÊòØÂü∫‰∫étokenÁöÑÊû∂ÊûÑÔºåÂú®Â¶Ç‰ΩïÊúâÊïàÂú∞Â∞ÜÊñáÊú¨‰ø°ÊÅØËûçÂÖ•Âà∞ËßÜËßâtokenÁöÑÂ§ÑÁêÜÊµÅÁ®ã‰∏≠Èù¢‰∏¥ÊåëÊàò„ÄÇÁÆÄÂçïÁöÑÊãºÊé•ÊàñÊôöÊúüËûçÂêàÁ≠ñÁï•ÂèØËÉΩÊó†Ê≥ïÂÖÖÂàÜÂà©Áî®ÊñáÊú¨‰ø°ÊÅØÔºåÂØºËá¥ÁîüÊàêÂõæÂÉè‰∏éÊñáÊú¨ÊèèËø∞‰∏ç‰∏ÄËá¥ÊàñÁªÜËäÇÁº∫Â§±„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®Êù°‰ª∂Âº∫Â∫¶ÂíåÈ™®Âπ≤ÈÄöÁî®ÊÄß‰πãÈó¥Èöæ‰ª•ÂèñÂæóÂπ≥Ë°°„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöJEPA-TÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈááÁî®ËÅîÂêàÂµåÂÖ•È¢ÑÊµãÊû∂ÊûÑÔºåÂ∞ÜÂõæÂÉèÂíåÊñáÊú¨ÁºñÁ†Å‰∏∫Á¶ªÊï£ÁöÑtokenÔºåÂπ∂Âú®Transformer‰∏≠ËøõË°åËÅîÂêàÂ§ÑÁêÜ„ÄÇÈÄöËøáÂú®ÁâπÂæÅÈ¢ÑÊµãÂô®ÂêéÂºïÂÖ•‰∫§ÂèâÊ≥®ÊÑèÂäõÊú∫Âà∂ÔºåÂÆûÁé∞ÊñáÊú¨‰ø°ÊÅØÂØπËßÜËßâtokenÁöÑÊù°‰ª∂ÂéªÂô™Ôºå‰ªéËÄåÂ¢ûÂº∫ÊñáÊú¨ÂíåÂõæÂÉèÁöÑËûçÂêà„ÄÇÊ≠§Â§ñÔºåÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠ÔºåÈÄöËøáÂú®ÊµÅÂåπÈÖçÊçüÂ§±‰πãÂâçÊ≥®ÂÖ•ÂéüÂßãÊñáÊú¨ÂµåÂÖ•ÔºåËøõ‰∏ÄÊ≠•ÊèêÈ´òÊñáÊú¨ÂíåÂõæÂÉèÁöÑÂØπÈΩê„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöJEPA-TÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) ÂõæÂÉèÂíåÊñáÊú¨ÁºñÁ†ÅÂô®ÔºöÂ∞ÜÂõæÂÉèÂíåÊñáÊú¨ÂàÜÂà´ÁºñÁ†Å‰∏∫Á¶ªÊï£ÁöÑËßÜËßâÂíåÊñáÊú¨token„ÄÇ2) ËÅîÂêàÂµåÂÖ•È¢ÑÊµãTransformerÔºöÂ§ÑÁêÜËßÜËßâÂíåÊñáÊú¨tokenÔºåËøõË°åÁâπÂæÅÈ¢ÑÊµãÂíåËûçÂêà„ÄÇ3) ‰∫§ÂèâÊ≥®ÊÑèÂäõÊ®°ÂùóÔºöÂú®ÁâπÂæÅÈ¢ÑÊµãÂô®‰πãÂêéÔºåÂà©Áî®ÊñáÊú¨‰ø°ÊÅØÂØπËßÜËßâtokenËøõË°åÊù°‰ª∂ÂéªÂô™„ÄÇ4) ÊµÅÂåπÈÖçÊçüÂ§±ÔºöÁî®‰∫éËÆ≠ÁªÉÊ®°ÂûãÔºåÂπ∂Âú®ÊçüÂ§±ËÆ°ÁÆóÂâçÊ≥®ÂÖ•ÂéüÂßãÊñáÊú¨ÂµåÂÖ•‰ª•ÊèêÈ´òÂØπÈΩê„ÄÇÂú®Êé®ÁêÜÈò∂ÊÆµÔºåÈÄöËøáËø≠‰ª£ÂéªÂô™ËßÜËßâtokenÁîüÊàêÂõæÂÉè„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöJEPA-TÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂ËûçÂêàÁ≠ñÁï•ÔºåÂç≥ÊôöÊúüÊû∂ÊûÑËûçÂêà‰∏éÁõÆÊ†áÁ∫ßÂà´ÂØπÈΩêÁõ∏ÁªìÂêà„ÄÇËøôÁßçÁ≠ñÁï•Âú®‰øùÊåÅÈ™®Âπ≤ÁΩëÁªúÈÄöÁî®ÊÄßÁöÑÂêåÊó∂ÔºåÂ¢ûÂº∫‰∫ÜÊñáÊú¨‰ø°ÊÅØÁöÑÊù°‰ª∂‰ΩúÁî®„ÄÇÂÖ∑‰ΩìÊù•ËØ¥Ôºå‰∫§ÂèâÊ≥®ÊÑèÂäõÊ®°ÂùóÁöÑÂºïÂÖ•ÂíåÂéüÂßãÊñáÊú¨ÂµåÂÖ•ÁöÑÊ≥®ÂÖ•Ôºå‰ΩøÂæóÊñáÊú¨‰ø°ÊÅØËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞ÊåáÂØºÂõæÂÉèÁîüÊàêËøáÁ®ã„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöJEPA-TÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ‰ΩøÁî®Á¶ªÊï£ÁöÑËßÜËßâÂíåÊñáÊú¨tokenË°®Á§∫ÂõæÂÉèÂíåÊñáÊú¨‰ø°ÊÅØ„ÄÇ2) Âú®ÁâπÂæÅÈ¢ÑÊµãÂô®ÂêéÊ∑ªÂä†‰∫§ÂèâÊ≥®ÊÑèÂäõÊ®°ÂùóÔºåÂÆûÁé∞Êù°‰ª∂ÂéªÂô™„ÄÇ3) Âú®ÊµÅÂåπÈÖçÊçüÂ§±‰πãÂâçÊ≥®ÂÖ•ÂéüÂßãÊñáÊú¨ÂµåÂÖ•Ôºå‰ª•ÊèêÈ´òËÆ≠ÁªÉÊúüÈó¥ÁöÑÂØπÈΩê„ÄÇ4) ‰ΩøÁî®Transformer‰Ωú‰∏∫Ê†∏ÂøÉÂ§ÑÁêÜÊ®°ÂùóÔºåËøõË°åÁâπÂæÅÈ¢ÑÊµãÂíåËûçÂêà„ÄÇÂÖ∑‰ΩìÁöÑÂèÇÊï∞ËÆæÁΩÆÂíåÁΩëÁªúÁªìÊûÑÁªÜËäÇÊú™Âú®ÊëòË¶Å‰∏≠ËØ¶ÁªÜËØ¥ÊòéÔºåÈúÄË¶ÅÂèÇËÄÉËÆ∫ÊñáÂÖ®Êñá„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

JEPA-TÂú®ImageNet-1KÊï∞ÊçÆÈõÜ‰∏äËøõË°å‰∫ÜËØÑ‰º∞ÔºåÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåJEPA-TÂÆûÁé∞‰∫ÜÂº∫Â§ßÁöÑÊï∞ÊçÆÊïàÁéáÂíåÂºÄÊîæËØçÊ±áÊ≥õÂåñËÉΩÂäõÔºåÂπ∂‰∏îÂßãÁªà‰ºò‰∫éÈùûËûçÂêàÂíåÊôöÊúüËûçÂêàÂü∫Á∫øÊñπÊ≥ï„ÄÇÂÖ∑‰ΩìÁöÑÊÄßËÉΩÊï∞ÊçÆÂíåÊèêÂçáÂπÖÂ∫¶ÈúÄË¶ÅÂú®ËÆ∫ÊñáÂÖ®Êñá‰∏≠Êü•Êâæ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

JEPA-TÂú®ÊñáÊú¨Âà∞ÂõæÂÉèÁîüÊàêÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºå‰æãÂ¶ÇËâ∫ÊúØÂàõ‰Ωú„ÄÅÂõæÂÉèÁºñËæë„ÄÅËôöÊãüÁé∞ÂÆû„ÄÅÊ∏∏ÊàèÂºÄÂèëÁ≠â„ÄÇËØ•Á†îÁ©∂ÂèØ‰ª•Áî®‰∫éÁîüÊàêÈ´òË¥®Èáè„ÄÅ‰∏éÊñáÊú¨ÊèèËø∞È´òÂ∫¶‰∏ÄËá¥ÁöÑÂõæÂÉèÔºåÊèêÂçáÁî®Êà∑‰ΩìÈ™åÂíåÂàõ‰ΩúÊïàÁéá„ÄÇÊú™Êù•ÔºåËØ•ÊäÄÊúØÂèØ‰ª•Ëøõ‰∏ÄÊ≠•Êâ©Â±ïÂà∞ËßÜÈ¢ëÁîüÊàê„ÄÅ3DÊ®°ÂûãÁîüÊàêÁ≠âÈ¢ÜÂüüÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÊú™Êù•ÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Modern Text-to-Image (T2I) generation increasingly relies on token-centric architectures that are trained with self-supervision, yet effectively fusing text with visual tokens remains a challenge. We propose \textbf{JEPA-T}, a unified multimodal framework that encodes images and captions into discrete visual and textual tokens, processed by a joint-embedding predictive Transformer. To enhance fusion, we incorporate cross-attention after the feature predictor for conditional denoising while maintaining a task-agnostic backbone. Additionally, raw texts embeddings are injected prior to the flow matching loss to improve alignment during training. During inference, the same network performs both class-conditional and free-text image generation by iteratively denoising visual tokens conditioned on text. Evaluations on ImageNet-1K demonstrate that JEPA-T achieves strong data efficiency, open-vocabulary generalization, and consistently outperforms non-fusion and late-fusion baselines. Our approach shows that late architectural fusion combined with objective-level alignment offers an effective balance between conditioning strength and backbone generality in token-based T2I.The code is now available: https://github.com/justin-herry/JEPA-T.git

