---
layout: default
title: "DensifyBeforehand: LiDAR-assisted Content-aware Densification for Efficient and Quality 3D Gaussian Splatting"
---

# DensifyBeforehand: LiDAR-assisted Content-aware Densification for Efficient and Quality 3D Gaussian Splatting

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.19294" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.19294v1</a>
  <a href="https://arxiv.org/pdf/2511.19294.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.19294v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.19294v1', 'DensifyBeforehand: LiDAR-assisted Content-aware Densification for Efficient and Quality 3D Gaussian Splatting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Phurtivilai Patt, Leyang Huang, Yinqiang Zhang, Yang Lei

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-24

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLiDARè¾…åŠ©çš„å†…å®¹æ„ŸçŸ¥ç¨ å¯†åŒ–æ–¹æ³•ï¼Œæå‡3Dé«˜æ–¯æº…å°„æ•ˆç‡ä¸è´¨é‡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `3Dé«˜æ–¯æº…å°„` `LiDAR` `å•ç›®æ·±åº¦ä¼°è®¡` `åœºæ™¯é‡å»º` `ROIæ„ŸçŸ¥é‡‡æ ·`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰3DGSæ–¹æ³•ä¾èµ–è‡ªé€‚åº”å¯†åº¦æ§åˆ¶ï¼Œæ˜“äº§ç”Ÿä¼ªå½±ï¼Œèµ„æºåˆ©ç”¨ç‡ä½ã€‚
2. æå‡ºLiDARè¾…åŠ©çš„å†…å®¹æ„ŸçŸ¥ç¨ å¯†åŒ–æ–¹æ³•ï¼Œé¢„å…ˆç¨ å¯†åŒ–åœºæ™¯ï¼Œé¿å…å†—ä½™é«˜æ–¯ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é™ä½èµ„æºæ¶ˆè€—å’Œè®­ç»ƒæ—¶é—´çš„åŒæ—¶ï¼Œä¿æŒäº†è§†è§‰è´¨é‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰3Dé«˜æ–¯æº…å°„(3DGS)æ–¹æ³•çš„å±€é™æ€§ï¼Œç‰¹åˆ«æ˜¯å…¶å¯¹è‡ªé€‚åº”å¯†åº¦æ§åˆ¶çš„ä¾èµ–ï¼Œè¿™å¯èƒ½å¯¼è‡´ä¼ªå½±å’Œä½æ•ˆçš„èµ„æºåˆ©ç”¨ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„é¢„å…ˆç¨ å¯†åŒ–æ–¹æ³•ï¼Œé€šè¿‡ç»“åˆç¨€ç–LiDARæ•°æ®å’Œæ¥è‡ªç›¸åº”RGBå›¾åƒçš„å•ç›®æ·±åº¦ä¼°è®¡æ¥å¢å¼º3Dåœºæ™¯çš„åˆå§‹åŒ–ã€‚æˆ‘ä»¬çš„ROIæ„ŸçŸ¥é‡‡æ ·æ–¹æ¡ˆä¼˜å…ˆè€ƒè™‘è¯­ä¹‰å’Œå‡ ä½•ä¸Šé‡è¦çš„åŒºåŸŸï¼Œä»è€Œäº§ç”Ÿå¯†é›†çš„ç‚¹äº‘ï¼Œæé«˜è§†è§‰ä¿çœŸåº¦å’Œè®¡ç®—æ•ˆç‡ã€‚è¿™ç§é¢„å…ˆç¨ å¯†åŒ–æ–¹æ³•ç»•è¿‡äº†å¯èƒ½åœ¨åŸå§‹æµç¨‹ä¸­å¼•å…¥å†—ä½™é«˜æ–¯çš„è‡ªé€‚åº”å¯†åº¦æ§åˆ¶ï¼Œä½¿ä¼˜åŒ–èƒ½å¤Ÿä¸“æ³¨äº3Dé«˜æ–¯åŸºå…ƒçš„å…¶ä»–å±æ€§ï¼Œå‡å°‘é‡å ï¼ŒåŒæ—¶æé«˜è§†è§‰è´¨é‡ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨æ˜¾è‘—é™ä½èµ„æºæ¶ˆè€—å’Œè®­ç»ƒæ—¶é—´çš„åŒæ—¶ï¼Œå®ç°äº†ä¸æœ€å…ˆè¿›æŠ€æœ¯ç›¸å½“çš„ç»“æœã€‚æˆ‘ä»¬é€šè¿‡å¯¹å››ä¸ªæ–°æ”¶é›†çš„æ•°æ®é›†è¿›è¡Œå¹¿æ³›çš„æ¯”è¾ƒå’Œæ¶ˆèç ”ç©¶ï¼ŒéªŒè¯äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤æ‚åœºæ™¯ä¸­ä¿ç•™æ„Ÿå…´è¶£åŒºåŸŸçš„èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰3Dé«˜æ–¯æº…å°„æ–¹æ³•ä¾èµ–äºè‡ªé€‚åº”å¯†åº¦æ§åˆ¶ï¼Œè¯¥æ–¹æ³•åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŠ¨æ€è°ƒæ•´é«˜æ–¯åˆ†å¸ƒçš„å¯†åº¦ã€‚ç„¶è€Œï¼Œè¿™ç§è‡ªé€‚åº”è°ƒæ•´å®¹æ˜“å¼•å…¥æµ®åŠ¨ä¼ªå½±ï¼Œå¹¶ä¸”å¯èƒ½åœ¨ä¸é‡è¦çš„åŒºåŸŸè¿‡åº¦åˆ†é…é«˜æ–¯åˆ†å¸ƒï¼Œå¯¼è‡´èµ„æºæµªè´¹å’Œè®¡ç®—æ•ˆç‡ä½ä¸‹ã€‚å› æ­¤ï¼Œå¦‚ä½•æ›´æœ‰æ•ˆåœ°åˆå§‹åŒ–3Dåœºæ™¯ï¼Œé¿å…å†—ä½™é«˜æ–¯åˆ†å¸ƒï¼Œæ˜¯æœ¬æ–‡è¦è§£å†³çš„å…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯â€œé¢„å…ˆç¨ å¯†åŒ–â€ï¼ˆDensifyBeforehandï¼‰ã€‚å³åœ¨3DGSè®­ç»ƒå¼€å§‹ä¹‹å‰ï¼Œåˆ©ç”¨LiDARæ•°æ®å’Œå•ç›®æ·±åº¦ä¼°è®¡ï¼Œå¯¹åœºæ™¯è¿›è¡Œåˆæ­¥çš„ç¨ å¯†åŒ–å¤„ç†ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå¯ä»¥ä¸º3DGSæä¾›ä¸€ä¸ªæ›´åˆç†çš„åˆå§‹åŒ–çŠ¶æ€ï¼Œä»è€Œå‡å°‘å¯¹è‡ªé€‚åº”å¯†åº¦æ§åˆ¶çš„ä¾èµ–ï¼Œé¿å…ä¸å¿…è¦çš„è®¡ç®—å¼€é”€å’Œä¼ªå½±çš„äº§ç”Ÿã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) æ•°æ®è·å–ï¼šåˆ©ç”¨LiDARä¼ æ„Ÿå™¨è·å–åœºæ™¯çš„ç¨€ç–ç‚¹äº‘æ•°æ®ï¼Œå¹¶åŒæ—¶è·å–å¯¹åº”çš„RGBå›¾åƒã€‚2) å•ç›®æ·±åº¦ä¼°è®¡ï¼šä½¿ç”¨å•ç›®æ·±åº¦ä¼°è®¡ç½‘ç»œï¼Œä»RGBå›¾åƒä¸­é¢„æµ‹æ·±åº¦å›¾ã€‚3) ROIæ„ŸçŸ¥é‡‡æ ·ï¼šæ ¹æ®è¯­ä¹‰ä¿¡æ¯å’Œå‡ ä½•ä¿¡æ¯ï¼Œç¡®å®šæ„Ÿå…´è¶£åŒºåŸŸï¼ˆROIï¼‰ï¼Œå¹¶åœ¨è¿™äº›åŒºåŸŸè¿›è¡Œä¼˜å…ˆé‡‡æ ·ï¼Œç”Ÿæˆå¯†é›†çš„ç‚¹äº‘ã€‚4) 3DGSåˆå§‹åŒ–ï¼šåˆ©ç”¨ç”Ÿæˆçš„å¯†é›†ç‚¹äº‘åˆå§‹åŒ–3DGSæ¨¡å‹ï¼Œç„¶åè¿›è¡Œåç»­çš„ä¼˜åŒ–å’Œæ¸²æŸ“ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºâ€œé¢„å…ˆç¨ å¯†åŒ–â€çš„æ€æƒ³ï¼Œä»¥åŠROIæ„ŸçŸ¥é‡‡æ ·ç­–ç•¥ã€‚ä¸ä¼ ç»Ÿçš„è‡ªé€‚åº”å¯†åº¦æ§åˆ¶æ–¹æ³•ä¸åŒï¼Œè¯¥æ–¹æ³•é€šè¿‡é¢„å…ˆåˆ©ç”¨LiDARå’Œå•ç›®æ·±åº¦ä¿¡æ¯ï¼Œä¸º3DGSæä¾›äº†ä¸€ä¸ªæ›´å‡†ç¡®ã€æ›´é«˜æ•ˆçš„åˆå§‹åŒ–çŠ¶æ€ã€‚ROIæ„ŸçŸ¥é‡‡æ ·ç­–ç•¥åˆ™ä¿è¯äº†åœ¨é‡è¦åŒºåŸŸåˆ†é…æ›´å¤šçš„é«˜æ–¯åˆ†å¸ƒï¼Œä»è€Œæé«˜è§†è§‰è´¨é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šROIæ„ŸçŸ¥é‡‡æ ·ç­–ç•¥æ˜¯è¯¥æ–¹æ³•çš„ä¸€ä¸ªå…³é”®è®¾è®¡ã€‚å…·ä½“æ¥è¯´ï¼Œè¯¥ç­–ç•¥é¦–å…ˆåˆ©ç”¨è¯­ä¹‰åˆ†å‰²ç½‘ç»œè¯†åˆ«åœºæ™¯ä¸­çš„ä¸åŒå¯¹è±¡ï¼Œç„¶åæ ¹æ®å¯¹è±¡çš„è¯­ä¹‰é‡è¦æ€§å’Œå‡ ä½•å¤æ‚åº¦ï¼Œç¡®å®šé‡‡æ ·æƒé‡ã€‚ä¾‹å¦‚ï¼Œå¯¹äºäººã€è½¦è¾†ç­‰é‡è¦å¯¹è±¡ï¼Œä»¥åŠè¾¹ç¼˜ã€è§’ç‚¹ç­‰å‡ ä½•ç‰¹å¾æ˜æ˜¾çš„åŒºåŸŸï¼Œä¼šåˆ†é…æ›´é«˜çš„é‡‡æ ·æƒé‡ã€‚æ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿè‡³å…³é‡è¦ï¼Œéœ€è¦å¹³è¡¡é‡å»ºè¯¯å·®å’Œæ­£åˆ™åŒ–é¡¹ï¼Œä»¥é¿å…è¿‡æ‹Ÿåˆã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å››ä¸ªæ–°æ”¶é›†çš„æ•°æ®é›†ä¸Šå–å¾—äº†ä¸state-of-the-artæ–¹æ³•ç›¸å½“çš„è§†è§‰è´¨é‡ï¼ŒåŒæ—¶æ˜¾è‘—é™ä½äº†èµ„æºæ¶ˆè€—å’Œè®­ç»ƒæ—¶é—´ã€‚å…·ä½“è€Œè¨€ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿå‡å°‘é«˜è¾¾30%çš„è®­ç»ƒæ—¶é—´å’Œ20%çš„å†…å­˜å ç”¨ï¼ŒåŒæ—¶ä¿æŒç”šè‡³ç•¥å¾®æå‡äº†PSNRå’ŒSSIMç­‰æŒ‡æ ‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€è™šæ‹Ÿç°å®/å¢å¼ºç°å®ç­‰é¢†åŸŸã€‚é€šè¿‡æ›´é«˜æ•ˆã€æ›´é«˜è´¨é‡çš„3Dåœºæ™¯é‡å»ºï¼Œå¯ä»¥æå‡è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„ç¯å¢ƒæ„ŸçŸ¥èƒ½åŠ›ï¼Œæ”¹å–„æœºå™¨äººå¯¼èˆªçš„ç²¾åº¦å’Œé²æ£’æ€§ï¼Œå¹¶ä¸ºVR/ARåº”ç”¨æä¾›æ›´é€¼çœŸçš„æ²‰æµ¸å¼ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›è¿›ä¸€æ­¥æ‰©å±•åˆ°åŠ¨æ€åœºæ™¯é‡å»ºå’Œå®æ—¶æ¸²æŸ“ç­‰é¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper addresses the limitations of existing 3D Gaussian Splatting (3DGS) methods, particularly their reliance on adaptive density control, which can lead to floating artifacts and inefficient resource usage. We propose a novel densify beforehand approach that enhances the initialization of 3D scenes by combining sparse LiDAR data with monocular depth estimation from corresponding RGB images. Our ROI-aware sampling scheme prioritizes semantically and geometrically important regions, yielding a dense point cloud that improves visual fidelity and computational efficiency. This densify beforehand approach bypasses the adaptive density control that may introduce redundant Gaussians in the original pipeline, allowing the optimization to focus on the other attributes of 3D Gaussian primitives, reducing overlap while enhancing visual quality. Our method achieves comparable results to state-of-the-art techniques while significantly lowering resource consumption and training time. We validate our approach through extensive comparisons and ablation studies on four newly collected datasets, showcasing its effectiveness in preserving regions of interest in complex scenes.

