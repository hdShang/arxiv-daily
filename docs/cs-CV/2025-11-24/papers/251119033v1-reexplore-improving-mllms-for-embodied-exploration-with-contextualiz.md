---
layout: default
title: ReEXplore: Improving MLLMs for Embodied Exploration with Contextualized Retrospective Experience Replay
---

# ReEXplore: Improving MLLMs for Embodied Exploration with Contextualized Retrospective Experience Replay

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.19033" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.19033v1</a>
  <a href="https://arxiv.org/pdf/2511.19033.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.19033v1" onclick="toggleFavorite(this, '2511.19033v1', 'ReEXplore: Improving MLLMs for Embodied Exploration with Contextualized Retrospective Experience Replay')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Gengyuan Zhang, Mingcong Ding, Jingpei Wu, Ruotong Liao, Volker Tresp

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-24

**å¤‡æ³¨**: 8 main pages plus 13 pages Appendix

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ReEXploreï¼šåˆ©ç”¨æƒ…å¢ƒåŒ–å›é¡¾ç»éªŒå›æ”¾æ”¹è¿›MLLMåœ¨å…·èº«æ¢ç´¢ä¸­çš„æ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `å…·èº«æ¢ç´¢` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `ç»éªŒå›æ”¾` `åˆ†å±‚å†³ç­–` `æœºå™¨äººå¯¼èˆª`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŸºäºMLLMçš„å…·èº«æ™ºèƒ½ä½“ä¾èµ–äºé¢„è®­ç»ƒçŸ¥è¯†ï¼Œç¼ºä¹å¯¹æ–°ç¯å¢ƒçš„é€‚åº”æ€§ï¼Œä¸”è®­ç»ƒæˆæœ¬é«˜æ˜‚ã€‚
2. ReEXploreé€šè¿‡å›é¡¾æ€§ç»éªŒå›æ”¾æ³¨å…¥æç‚¼çš„æŠ½è±¡ç»éªŒï¼Œå¹¶é‡‡ç”¨åˆ†å±‚å‰æ²¿é€‰æ‹©ç­–ç•¥ï¼Œæå‡æ¢ç´¢æ•ˆç‡ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒReEXploreåœ¨å¤šä¸ªå…·èº«æ¢ç´¢åŸºå‡†æµ‹è¯•ä¸­ï¼ŒæˆåŠŸç‡å’Œå¯¼èˆªæ•ˆç‡å‡æ˜¾è‘—ä¼˜äºç°æœ‰MLLMåŸºçº¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å…·èº«æ¢ç´¢æ˜¯ä¸€ä¸ªç›®æ ‡é©±åŠ¨çš„è¿‡ç¨‹ï¼Œå®ƒè¦æ±‚å…·èº«æ™ºèƒ½ä½“å…·å¤‡ç²¾ç»†çš„æ„ŸçŸ¥å’ŒçŸ¥è¯†å¢å¼ºçš„å†³ç­–èƒ½åŠ›ã€‚å°½ç®¡æœ€è¿‘çš„ç ”ç©¶å°è¯•åˆ©ç”¨MLLMè¿›è¡Œæ¢ç´¢ï¼Œå› ä¸ºå®ƒä»¬å…·æœ‰å¼ºå¤§çš„æ„ŸçŸ¥å’Œæ¨ç†èƒ½åŠ›ï¼Œä½†æˆ‘ä»¬å‘ç°åŸºäºMLLMçš„å…·èº«æ™ºèƒ½ä½“åœ¨æ¢ç´¢æ–°ç¯å¢ƒæ—¶ä»ç„¶ä¸å°½å¦‚äººæ„ï¼šï¼ˆiï¼‰å®ƒä»¬ä¾èµ–äºæ·±åˆ»ä½†é™ˆæ—§çš„é¢„è®­ç»ƒçŸ¥è¯†ï¼›ï¼ˆiiï¼‰åŸºäºè®­ç»ƒçš„æ–¹æ³•ï¼Œå¦‚æ¨¡ä»¿å­¦ä¹ æˆ–å¼ºåŒ–å­¦ä¹ ï¼Œå¯¹äºå…·æœ‰ç¨€ç–ç»“æœå¥–åŠ±çš„é•¿æ—¶ç¨‹ä»»åŠ¡æ¥è¯´æˆæœ¬é«˜æ˜‚ï¼›ï¼ˆiiiï¼‰åŸºäºå‰æ²¿çš„æ¢ç´¢äº§ç”Ÿäº†ä¸€ä¸ªå·¨å¤§çš„ã€è§†è§‰ä¸Šç»†å¾®çš„åŠ¨ä½œç©ºé—´ï¼Œè¿™ä½¿å¾—MLLMéš¾ä»¥åšå‡ºå¯é çš„å†³ç­–ã€‚æˆ‘ä»¬æå‡ºäº†ReEXploreï¼Œè¿™æ˜¯ä¸€ä¸ªæ— éœ€è®­ç»ƒçš„æ¡†æ¶ï¼Œå®ƒåœ¨æ¨ç†æ—¶æ‰§è¡Œå›é¡¾æ€§ç»éªŒå›æ”¾ï¼Œä»¥æ³¨å…¥æç‚¼çš„ã€æŠ½è±¡çš„ç»éªŒï¼Œå¹¶è¿›è¡Œåˆ†å±‚å‰æ²¿é€‰æ‹©ï¼Œå°†å‰æ²¿æ’åºåˆ†è§£ä¸ºç”±ç²—åˆ°ç²¾çš„å†³ç­–ã€‚æˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿå®ç°ç¨³å¥ã€å¯è¿½æº¯å’Œé«˜æ•ˆçš„æ¢ç´¢ã€‚åœ¨å¤šä¸ªå…·èº«æ¢ç´¢åŸºå‡†æµ‹è¯•ä¸­ï¼ŒReEXploreåœ¨å¼€æºéª¨å¹²ç½‘ç»œä¸‹ï¼Œåœ¨æˆåŠŸç‡å’Œå¯¼èˆªæ•ˆç‡æ–¹é¢éƒ½æ¯”å¼ºå¤§çš„MLLMåŸºçº¿æé«˜äº†é«˜è¾¾3å€çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åŸºäºMLLMçš„å…·èº«æ™ºèƒ½ä½“åœ¨æœªçŸ¥ç¯å¢ƒä¸­æ¢ç´¢æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºé¢„è®­ç»ƒçŸ¥è¯†ï¼Œéš¾ä»¥é€‚åº”æ–°ç¯å¢ƒï¼›æ¨¡ä»¿å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ç­‰è®­ç»ƒæ–¹æ³•æˆæœ¬é«˜æ˜‚ï¼›åŸºäºå‰æ²¿çš„æ¢ç´¢äº§ç”Ÿåºå¤§ä¸”ç»†å¾®çš„åŠ¨ä½œç©ºé—´ï¼Œå¯¼è‡´å†³ç­–å›°éš¾ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šReEXploreçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å›é¡¾æ€§ç»éªŒå›æ”¾ï¼Œå°†æ™ºèƒ½ä½“è¿‡å»æ¢ç´¢çš„ç»éªŒæç‚¼æˆæŠ½è±¡çŸ¥è¯†ï¼Œå¹¶åœ¨æ¨ç†æ—¶æ³¨å…¥ï¼Œä»è€Œå¢å¼ºæ™ºèƒ½ä½“å¯¹ç¯å¢ƒçš„ç†è§£å’Œé€‚åº”èƒ½åŠ›ã€‚åŒæ—¶ï¼Œé‡‡ç”¨åˆ†å±‚å‰æ²¿é€‰æ‹©ç­–ç•¥ï¼Œå°†å¤æ‚çš„åŠ¨ä½œç©ºé—´åˆ†è§£ä¸ºç”±ç²—åˆ°ç²¾çš„å†³ç­–è¿‡ç¨‹ï¼Œé™ä½å†³ç­–éš¾åº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šReEXploreæ¡†æ¶ä¸»è¦åŒ…å«ä¸¤ä¸ªæ¨¡å—ï¼šå›é¡¾æ€§ç»éªŒå›æ”¾å’Œåˆ†å±‚å‰æ²¿é€‰æ‹©ã€‚å›é¡¾æ€§ç»éªŒå›æ”¾æ¨¡å—è´Ÿè´£ä»å†å²ç»éªŒä¸­æå–å…³é”®ä¿¡æ¯ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºæŠ½è±¡çš„çŸ¥è¯†è¡¨ç¤ºã€‚åˆ†å±‚å‰æ²¿é€‰æ‹©æ¨¡å—åˆ™å°†å‰æ²¿æ¢ç´¢ä»»åŠ¡åˆ†è§£ä¸ºå¤šä¸ªå±‚çº§ï¼Œé¦–å…ˆè¿›è¡Œç²—ç•¥çš„é€‰æ‹©ï¼Œç„¶åé€æ­¥ç»†åŒ–ï¼Œæœ€ç»ˆç¡®å®šæœ€ä½³çš„æ¢ç´¢æ–¹å‘ã€‚æ•´ä¸ªè¿‡ç¨‹æ— éœ€è®­ç»ƒï¼Œå¯ä»¥åœ¨æ¨ç†é˜¶æ®µç›´æ¥åº”ç”¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šReEXploreçš„å…³é”®åˆ›æ–°åœ¨äºå°†å›é¡¾æ€§ç»éªŒå›æ”¾å’Œåˆ†å±‚å‰æ²¿é€‰æ‹©ç›¸ç»“åˆï¼Œä»è€Œå®ç°äº†é«˜æ•ˆã€ç¨³å¥ä¸”å¯è¿½æº¯çš„å…·èº«æ¢ç´¢ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒReEXploreæ— éœ€è®­ç»ƒï¼Œèƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”æ–°ç¯å¢ƒï¼Œå¹¶ä¸”èƒ½å¤Ÿæä¾›æ›´æ¸…æ™°çš„å†³ç­–è¿‡ç¨‹ã€‚

**å…³é”®è®¾è®¡**ï¼šå›é¡¾æ€§ç»éªŒå›æ”¾æ¨¡å—ä½¿ç”¨MLLMå¯¹å†å²ç»éªŒè¿›è¡Œç¼–ç å’Œæç‚¼ï¼Œæå–å…³é”®çš„è§†è§‰å’Œè¯­ä¹‰ä¿¡æ¯ã€‚åˆ†å±‚å‰æ²¿é€‰æ‹©æ¨¡å—é‡‡ç”¨å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰å¯¹å‰æ²¿è¿›è¡Œæ’åºï¼Œå¹¶æ ¹æ®æ’åºç»“æœé€‰æ‹©æœ€ä½³çš„æ¢ç´¢æ–¹å‘ã€‚å…·ä½“å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ç­‰ç»†èŠ‚æœªåœ¨æ‘˜è¦ä¸­è¯¦ç»†è¯´æ˜ï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ReEXploreåœ¨å¤šä¸ªå…·èº«æ¢ç´¢åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼ŒæˆåŠŸç‡å’Œå¯¼èˆªæ•ˆç‡å‡æé«˜äº†é«˜è¾¾3å€ã€‚è¯¥æ–¹æ³•åœ¨å¼€æºéª¨å¹²ç½‘ç»œä¸‹è¿›è¡Œäº†éªŒè¯ï¼Œè¡¨æ˜å…¶å…·æœ‰è‰¯å¥½çš„é€šç”¨æ€§å’Œå¯æ‰©å±•æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒReEXploreèƒ½å¤Ÿæœ‰æ•ˆè§£å†³MLLMåœ¨å…·èº«æ¢ç´¢ä¸­é¢ä¸´çš„æŒ‘æˆ˜ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†æ–°çš„æ€è·¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ReEXploreå¯åº”ç”¨äºæœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ã€æœç´¢æ•‘æ´ç­‰é¢†åŸŸã€‚è¯¥ç ”ç©¶èƒ½å¤Ÿæå‡æ™ºèƒ½ä½“åœ¨æœªçŸ¥ç¯å¢ƒä¸­çš„æ¢ç´¢æ•ˆç‡å’Œé€‚åº”èƒ½åŠ›ï¼Œé™ä½å¯¹è®­ç»ƒæ•°æ®çš„ä¾èµ–ï¼Œå…·æœ‰é‡è¦çš„å®é™…åº”ç”¨ä»·å€¼å’Œå¹¿é˜”çš„æœªæ¥å‘å±•å‰æ™¯ã€‚ä¾‹å¦‚ï¼Œåœ¨ç¾éš¾æ•‘æ´åœºæ™¯ä¸­ï¼Œæœºå™¨äººå¯ä»¥åˆ©ç”¨ReEXploreå¿«é€Ÿæ¢ç´¢å—ç¾åŒºåŸŸï¼Œå¯»æ‰¾å¹¸å­˜è€…ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Embodied exploration is a target-driven process that requires embodied agents to possess fine-grained perception and knowledge-enhanced decision making. While recent attempts leverage MLLMs for exploration due to their strong perceptual and reasoning abilities, we find that MLLM-based embodied agents remain suboptimal in exploring new environments: (i) they rely on profound but stale pre-trained knowledge, (ii) training-based approaches such as imitation learning or reinforcement learning are expensive for long-horizon tasks with sparse outcome rewards, and (iii) frontier-based exploration yields a large, visually nuanced action space that is difficult for MLLMs to make reliable decisions. We address these challenges with ReEXplore, a training-free framework that performs retrospective experience replay to inject distilled, abstract experience at inference time, and hierarchical frontier selection to decompose frontier ranking into coarse-to-fine decisions. Our approach enables robust, traceable, and efficient exploration. Across multiple embodied exploration benchmarks, ReEXplore yields great improvements over strong MLLM baselines, up to 3x higher performance in both success rate and in navigation efficiency under open-source backbones.

