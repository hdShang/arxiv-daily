---
layout: default
title: Peregrine: One-Shot Fine-Tuning for FHE Inference of General Deep CNNs
---

# Peregrine: One-Shot Fine-Tuning for FHE Inference of General Deep CNNs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.18976" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.18976v1</a>
  <a href="https://arxiv.org/pdf/2511.18976.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.18976v1" onclick="toggleFavorite(this, '2511.18976v1', 'Peregrine: One-Shot Fine-Tuning for FHE Inference of General Deep CNNs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Huaming Ling, Ying Wang, Si Chen, Junfeng Fan

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-24

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Peregrineï¼šç”¨äºé€šç”¨æ·±åº¦CNNçš„FHEæ¨ç†çš„å•æ¬¡å¾®è°ƒæ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction)**

**å…³é”®è¯**: `åŒæ€åŠ å¯†` `æ·±åº¦å­¦ä¹ ` `å·ç§¯ç¥ç»ç½‘ç»œ` `éšç§ä¿æŠ¤` `å•é˜¶æ®µå¾®è°ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•éš¾ä»¥åœ¨FHEæ¨ç†ä¸­å…¼é¡¾éçº¿æ€§æ¿€æ´»çš„ä½é˜¶å¤šé¡¹å¼è¿‘ä¼¼å’Œç²¾åº¦ä¿æŒã€‚
2. æå‡ºå•é˜¶æ®µå¾®è°ƒç­–ç•¥ï¼Œç›´æ¥å°†é¢„è®­ç»ƒCNNè½¬åŒ–ä¸ºFHEå‹å¥½å½¢å¼ï¼Œé™ä½è®­ç»ƒå¼€é”€ã€‚
3. è®¾è®¡å¹¿ä¹‰äº¤é”™æ‰“åŒ…æ–¹æ¡ˆï¼Œå…¼å®¹ä»»æ„åˆ†è¾¨ç‡ç‰¹å¾å›¾ï¼Œå¹¶ä¿æŒåŒæ€åŠ å¯†å½¢å¼ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æ—¨åœ¨è§£å†³å°†é€šç”¨æ·±åº¦CNNåº”ç”¨äºåŸºäºåŒæ€åŠ å¯†ï¼ˆFHEï¼‰çš„æ¨ç†æ—¶é¢ä¸´çš„ä¸¤å¤§æŒ‘æˆ˜ï¼šä¸€æ˜¯ä½¿ç”¨ä½é˜¶å¤šé¡¹å¼é€¼è¿‘ReLUç­‰éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼ŒåŒæ—¶æœ€å¤§é™åº¦åœ°å‡å°‘ç²¾åº¦æŸå¤±ï¼›äºŒæ˜¯å…‹æœå¯†æ–‡å®¹é‡é™åˆ¶ï¼Œè¯¥é™åˆ¶é˜»ç¢äº†FHEæ¨ç†ä¸­çš„é«˜åˆ†è¾¨ç‡å›¾åƒå¤„ç†ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸¤æ–¹é¢çš„è´¡çŒ®ï¼šï¼ˆ1ï¼‰ä¸€ç§å•é˜¶æ®µå¾®è°ƒï¼ˆSFTï¼‰ç­–ç•¥ï¼Œè¯¥ç­–ç•¥ä½¿ç”¨ä½é˜¶å¤šé¡¹å¼ç›´æ¥å°†é¢„è®­ç»ƒçš„CNNè½¬æ¢ä¸ºFHEå‹å¥½çš„å½¢å¼ï¼Œä»¥æœ€å°çš„è®­ç»ƒå¼€é”€å®ç°å…·æœ‰ç«äº‰åŠ›çš„ç²¾åº¦ï¼›ï¼ˆ2ï¼‰ä¸€ç§å¹¿ä¹‰äº¤é”™æ‰“åŒ…ï¼ˆGIPï¼‰æ–¹æ¡ˆï¼Œè¯¥æ–¹æ¡ˆä¸å‡ ä¹ä»»æ„ç©ºé—´åˆ†è¾¨ç‡çš„ç‰¹å¾å›¾å…¼å®¹ï¼Œå¹¶é…æœ‰ä¸€å¥—ç²¾å¿ƒè®¾è®¡çš„åŒæ€ç®—å­ï¼Œå¯åœ¨æ•´ä¸ªè®¡ç®—è¿‡ç¨‹ä¸­ä¿æŒGIPå½¢å¼çš„åŠ å¯†ã€‚è¿™äº›è¿›æ­¥ä½¿å¾—èƒ½å¤Ÿè·¨å„ç§CNNæ¶æ„è¿›è¡Œé«˜æ•ˆçš„ç«¯åˆ°ç«¯FHEæ¨ç†ã€‚åœ¨CIFAR-10ã€ImageNetå’ŒMS COCOä¸Šçš„å®éªŒè¡¨æ˜ï¼Œé€šè¿‡æˆ‘ä»¬çš„SFTç­–ç•¥è·å¾—çš„FHEå‹å¥½å‹CNNå®ç°äº†ä¸ä½¿ç”¨ReLUæˆ–SiLUæ¿€æ´»å‡½æ•°çš„åŸºçº¿ç›¸å½“çš„ç²¾åº¦ã€‚æ­¤å¤–ï¼Œè¿™é¡¹å·¥ä½œé¦–æ¬¡å±•ç¤ºäº†åˆ©ç”¨ä½é˜¶å¤šé¡¹å¼æ¿€æ´»è¿›è¡Œå¯¹è±¡æ£€æµ‹çš„YOLOæ¶æ„çš„åŸºäºFHEçš„æ¨ç†ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å°†æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰åº”ç”¨äºåŒæ€åŠ å¯†ï¼ˆFHEï¼‰æ¨ç†æ—¶é‡åˆ°çš„ä¸¤ä¸ªä¸»è¦é—®é¢˜ã€‚é¦–å…ˆï¼Œå¦‚ä½•åœ¨ä¿è¯ç²¾åº¦çš„å‰æä¸‹ï¼Œä½¿ç”¨ä½é˜¶å¤šé¡¹å¼æ¥è¿‘ä¼¼ReLUç­‰éçº¿æ€§æ¿€æ´»å‡½æ•°ã€‚å…¶æ¬¡ï¼Œå¦‚ä½•å…‹æœFHEæ¨ç†ä¸­å¯†æ–‡å®¹é‡çš„é™åˆ¶ï¼Œä»è€Œæ”¯æŒé«˜åˆ†è¾¨ç‡å›¾åƒçš„å¤„ç†ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦åœ¨ç²¾åº¦å’Œè®¡ç®—å¤æ‚åº¦ä¹‹é—´è¿›è¡Œæƒè¡¡ï¼Œæˆ–è€…æ— æ³•æœ‰æ•ˆåœ°å¤„ç†é«˜åˆ†è¾¨ç‡å›¾åƒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å•é˜¶æ®µå¾®è°ƒï¼ˆSFTï¼‰å°†é¢„è®­ç»ƒçš„CNNç›´æ¥è½¬æ¢ä¸ºFHEå‹å¥½çš„å½¢å¼ï¼Œé¿å…äº†å¤æ‚çš„ä¸­é—´æ­¥éª¤ã€‚åŒæ—¶ï¼Œè®¾è®¡äº†ä¸€ç§å¹¿ä¹‰äº¤é”™æ‰“åŒ…ï¼ˆGIPï¼‰æ–¹æ¡ˆï¼Œä»¥æé«˜å¯†æ–‡çš„åˆ©ç”¨ç‡ï¼Œä»è€Œæ”¯æŒé«˜åˆ†è¾¨ç‡å›¾åƒçš„å¤„ç†ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨æœ€å¤§é™åº¦åœ°å‡å°‘ç²¾åº¦æŸå¤±ï¼Œå¹¶æé«˜FHEæ¨ç†çš„æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦éƒ¨åˆ†ï¼šå•é˜¶æ®µå¾®è°ƒï¼ˆSFTï¼‰å’Œå¹¿ä¹‰äº¤é”™æ‰“åŒ…ï¼ˆGIPï¼‰ã€‚SFTé¦–å…ˆä½¿ç”¨ä½é˜¶å¤šé¡¹å¼æ›¿æ¢åŸå§‹CNNä¸­çš„éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼Œç„¶åé€šè¿‡å¾®è°ƒæ¥æ¢å¤ç²¾åº¦ã€‚GIPåˆ™å°†ç‰¹å¾å›¾ä»¥äº¤é”™çš„æ–¹å¼æ‰“åŒ…åˆ°å¯†æ–‡ä¸­ï¼Œä»è€Œæé«˜å¯†æ–‡çš„åˆ©ç”¨ç‡ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜è®¾è®¡äº†ä¸€å¥—åŒæ€ç®—å­ï¼Œä»¥æ”¯æŒåœ¨GIPå½¢å¼çš„å¯†æ–‡ä¸Šè¿›è¡Œè®¡ç®—ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå•é˜¶æ®µå¾®è°ƒç­–ç•¥å’Œå¹¿ä¹‰äº¤é”™æ‰“åŒ…æ–¹æ¡ˆã€‚SFTå¯ä»¥ç›´æ¥å°†é¢„è®­ç»ƒçš„CNNè½¬æ¢ä¸ºFHEå‹å¥½çš„å½¢å¼ï¼Œè€Œæ— éœ€å¤æ‚çš„ä¸­é—´æ­¥éª¤ã€‚GIPåˆ™å¯ä»¥æœ‰æ•ˆåœ°åˆ©ç”¨å¯†æ–‡ç©ºé—´ï¼Œä»è€Œæ”¯æŒé«˜åˆ†è¾¨ç‡å›¾åƒçš„å¤„ç†ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¿™äº›åˆ›æ–°å¯ä»¥æ˜¾è‘—æé«˜FHEæ¨ç†çš„æ•ˆç‡å’Œç²¾åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šSFTçš„å…³é”®è®¾è®¡åœ¨äºé€‰æ‹©åˆé€‚çš„ä½é˜¶å¤šé¡¹å¼æ¥è¿‘ä¼¼éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼Œå¹¶é€šè¿‡å¾®è°ƒæ¥ä¼˜åŒ–ç½‘ç»œçš„å‚æ•°ã€‚GIPçš„å…³é”®è®¾è®¡åœ¨äºå¦‚ä½•å°†ç‰¹å¾å›¾ä»¥äº¤é”™çš„æ–¹å¼æ‰“åŒ…åˆ°å¯†æ–‡ä¸­ï¼Œå¹¶è®¾è®¡ç›¸åº”çš„åŒæ€ç®—å­æ¥æ”¯æŒè®¡ç®—ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜è€ƒè™‘äº†å¦‚ä½•åœ¨ä¿è¯å®‰å…¨æ€§çš„å‰æä¸‹ï¼Œæœ€å¤§é™åº¦åœ°æé«˜è®¡ç®—æ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé€šè¿‡SFTç­–ç•¥è·å¾—çš„FHEå‹å¥½å‹CNNåœ¨CIFAR-10ã€ImageNetå’ŒMS COCOæ•°æ®é›†ä¸Šå®ç°äº†ä¸ä½¿ç”¨ReLUæˆ–SiLUæ¿€æ´»å‡½æ•°çš„åŸºçº¿ç›¸å½“çš„ç²¾åº¦ã€‚æ­¤å¤–ï¼Œè¯¥å·¥ä½œé¦–æ¬¡å±•ç¤ºäº†åˆ©ç”¨ä½é˜¶å¤šé¡¹å¼æ¿€æ´»è¿›è¡Œå¯¹è±¡æ£€æµ‹çš„YOLOæ¶æ„çš„åŸºäºFHEçš„æ¨ç†ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å¯ä»¥åœ¨ä¿è¯ç²¾åº¦çš„å‰æä¸‹ï¼Œæœ‰æ•ˆåœ°æ”¯æŒFHEæ¨ç†ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºéšç§ä¿æŠ¤çš„å›¾åƒè¯†åˆ«ã€ç›®æ ‡æ£€æµ‹ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨åŒ»ç–—å½±åƒåˆ†æä¸­ï¼Œå¯ä»¥åœ¨ä¸æ³„éœ²æ‚£è€…éšç§çš„æƒ…å†µä¸‹ï¼Œåˆ©ç”¨FHEå¯¹åŒ»ç–—å½±åƒè¿›è¡Œåˆ†æå’Œè¯Šæ–­ã€‚åœ¨é‡‘èé£æ§é¢†åŸŸï¼Œå¯ä»¥åœ¨ä¿æŠ¤ç”¨æˆ·éšç§çš„å‰æä¸‹ï¼Œåˆ©ç”¨FHEå¯¹ç”¨æˆ·çš„ä¿¡ç”¨é£é™©è¿›è¡Œè¯„ä¼°ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åœ¨æ›´å¤šéœ€è¦éšç§ä¿æŠ¤çš„åœºæ™¯ä¸­å¾—åˆ°åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We address two fundamental challenges in adapting general deep CNNs for FHE-based inference: approximating non-linear activations such as ReLU with low-degree polynomials while minimizing accuracy degradation, and overcoming the ciphertext capacity barrier that constrains high-resolution image processing on FHE inference. Our contributions are twofold: (1) a single-stage fine-tuning (SFT) strategy that directly converts pre-trained CNNs into FHE-friendly forms using low-degree polynomials, achieving competitive accuracy with minimal training overhead; and (2) a generalized interleaved packing (GIP) scheme that is compatible with feature maps of virtually arbitrary spatial resolutions, accompanied by a suite of carefully designed homomorphic operators that preserve the GIP-form encryption throughout computation. These advances enable efficient, end-to-end FHE inference across diverse CNN architectures. Experiments on CIFAR-10, ImageNet, and MS COCO demonstrate that the FHE-friendly CNNs obtained via our SFT strategy achieve accuracy comparable to baselines using ReLU or SiLU activations. Moreover, this work presents the first demonstration of FHE-based inference for YOLO architectures in object detection leveraging low-degree polynomial activations.

