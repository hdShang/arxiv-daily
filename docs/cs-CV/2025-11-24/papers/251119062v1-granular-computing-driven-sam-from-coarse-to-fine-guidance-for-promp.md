---
layout: default
title: "Granular Computing-driven SAM: From Coarse-to-Fine Guidance for Prompt-Free Segmentation"
---

# Granular Computing-driven SAM: From Coarse-to-Fine Guidance for Prompt-Free Segmentation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.19062" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.19062v1</a>
  <a href="https://arxiv.org/pdf/2511.19062.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.19062v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.19062v1', 'Granular Computing-driven SAM: From Coarse-to-Fine Guidance for Prompt-Free Segmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Qiyang Yu, Yu Fang, Tianrui Li, Xuemei Cao, Yan Chen, Jianghao Li, Fan Min, Yi Zhang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-24

**å¤‡æ³¨**: 19 pages, 7 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºç²’è®¡ç®—çš„Grc-SAMï¼Œå®ç°æ— æç¤ºå›¾åƒåˆ†å‰²çš„ç²—åˆ°ç»†ç²¾åº¦æå‡ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `ç²’è®¡ç®—` `æ— æç¤ºåˆ†å‰²` `å›¾åƒåˆ†å‰²` `SAM` `Transformer`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ— æç¤ºå›¾åƒåˆ†å‰²æ–¹æ³•ç¼ºä¹è‡ªä¸»åŒºåŸŸå®šä½èƒ½åŠ›ï¼Œä¸”åœ¨é«˜åˆ†è¾¨ç‡ä¸‹éš¾ä»¥è¿›è¡Œç²¾ç»†å»ºæ¨¡ã€‚
2. Grc-SAMåˆ©ç”¨ç²’è®¡ç®—æ€æƒ³ï¼Œé€šè¿‡ç²—ç²’åº¦å®šä½å’Œç»†ç²’åº¦å»ºæ¨¡ï¼Œå®ç°ä»ç²—åˆ°ç»†çš„åˆ†å‰²ç²¾åº¦æå‡ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒGrc-SAMåœ¨åˆ†å‰²å‡†ç¡®æ€§å’Œå¯æ‰©å±•æ€§ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒéªŒè¯äº†ç²’è®¡ç®—çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºç²’è®¡ç®—é©±åŠ¨çš„SAMï¼ˆGrc-SAMï¼‰æ¡†æ¶ï¼Œç”¨äºè§£å†³æ— æç¤ºå›¾åƒåˆ†å‰²ä¸­çš„å±€éƒ¨æ€§å’Œå¯æ‰©å±•æ€§é—®é¢˜ã€‚ç°æœ‰é¢„è®­ç»ƒæ¨¡å‹ï¼Œå¦‚SAMï¼Œç›´æ¥åœ¨å•ä¸€ç²’åº¦çº§åˆ«ç”Ÿæˆæç¤ºï¼Œç¼ºä¹è‡ªä¸»åŒºåŸŸå®šä½æœºåˆ¶ï¼Œä¸”åœ¨é«˜åˆ†è¾¨ç‡ä¸‹ç²¾ç»†å»ºæ¨¡èƒ½åŠ›æœ‰é™ã€‚Grc-SAMé‡‡ç”¨ç²—åˆ°ç»†çš„ç­–ç•¥ï¼Œé¦–å…ˆåœ¨ç²—ç²’åº¦é˜¶æ®µè‡ªé€‚åº”åœ°ä»ç‰¹å¾ä¸­æå–é«˜å“åº”åŒºåŸŸï¼Œä»¥å®ç°ç²¾ç¡®çš„å‰æ™¯å®šä½å¹¶å‡å°‘å¯¹å¤–éƒ¨æç¤ºçš„ä¾èµ–ã€‚ç„¶ååœ¨ç»†ç²’åº¦é˜¶æ®µï¼Œåº”ç”¨æ›´ç²¾ç»†çš„patchåˆ’åˆ†å’Œç¨€ç–å±€éƒ¨swiné£æ ¼æ³¨æ„åŠ›ï¼Œä»¥å¢å¼ºç»†èŠ‚å»ºæ¨¡å¹¶å®ç°é«˜åˆ†è¾¨ç‡åˆ†å‰²ã€‚æœ€åï¼Œå°†ç»†åŒ–çš„æ©ç ç¼–ç ä¸ºæ½œåœ¨çš„æç¤ºåµŒå…¥ï¼Œç”¨äºSAMè§£ç å™¨ï¼Œç”¨è‡ªåŠ¨æ¨ç†è¿‡ç¨‹å–ä»£æ‰‹å·¥æç¤ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGrc-SAMåœ¨å‡†ç¡®æ€§å’Œå¯æ‰©å±•æ€§æ–¹é¢å‡ä¼˜äºåŸºçº¿æ–¹æ³•ï¼Œä¸ºæ— æç¤ºåˆ†å‰²æä¾›äº†ä¸€ç§ç‹¬ç‰¹çš„ç²’è®¡ç®—è§†è§’ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æ— æç¤ºå›¾åƒåˆ†å‰²ä»»åŠ¡ä¸­ï¼Œç°æœ‰æ–¹æ³•ï¼ˆå¦‚ç›´æ¥ä½¿ç”¨SAMï¼‰å­˜åœ¨çš„ä¸¤ä¸ªä¸»è¦é—®é¢˜ï¼šä¸€æ˜¯ç¼ºä¹è‡ªä¸»åŒºåŸŸå®šä½èƒ½åŠ›ï¼Œä¾èµ–å¤–éƒ¨æç¤ºï¼›äºŒæ˜¯éš¾ä»¥åœ¨é«˜åˆ†è¾¨ç‡å›¾åƒä¸Šè¿›è¡Œç²¾ç»†çš„ç»†èŠ‚å»ºæ¨¡ï¼Œå¯¼è‡´åˆ†å‰²ç²¾åº¦ä¸‹é™ã€‚ç°æœ‰æ–¹æ³•çš„ç—›ç‚¹åœ¨äºæ— æ³•æœ‰æ•ˆåœ°åˆ©ç”¨å›¾åƒçš„å…¨å±€ä¿¡æ¯è¿›è¡Œå¼•å¯¼ï¼Œå¹¶ä¸”è®¡ç®—å¤æ‚åº¦è¾ƒé«˜ï¼Œéš¾ä»¥æ‰©å±•åˆ°é«˜åˆ†è¾¨ç‡å›¾åƒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å€Ÿé‰´ç²’è®¡ç®—çš„æ€æƒ³ï¼Œå°†å›¾åƒåˆ†å‰²è¿‡ç¨‹åˆ†è§£ä¸ºç²—ç²’åº¦å’Œç»†ç²’åº¦ä¸¤ä¸ªé˜¶æ®µã€‚ç²—ç²’åº¦é˜¶æ®µè´Ÿè´£å¿«é€Ÿå®šä½å›¾åƒä¸­çš„æ˜¾è‘—åŒºåŸŸï¼Œå‡å°‘å¯¹å¤–éƒ¨æç¤ºçš„ä¾èµ–ï¼›ç»†ç²’åº¦é˜¶æ®µåˆ™ä¸“æ³¨äºå¯¹æ˜¾è‘—åŒºåŸŸè¿›è¡Œç²¾ç»†çš„åˆ†å‰²ï¼Œæå‡åˆ†å‰²ç²¾åº¦ã€‚é€šè¿‡è¿™ç§ç²—åˆ°ç»†çš„ç­–ç•¥ï¼Œå¯ä»¥æœ‰æ•ˆåœ°åˆ©ç”¨å›¾åƒçš„å…¨å±€å’Œå±€éƒ¨ä¿¡æ¯ï¼Œæé«˜åˆ†å‰²çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šGrc-SAMæ¡†æ¶ä¸»è¦åŒ…å«ä¸‰ä¸ªé˜¶æ®µï¼šç²—ç²’åº¦é˜¶æ®µã€ç»†ç²’åº¦é˜¶æ®µå’Œè§£ç é˜¶æ®µã€‚åœ¨ç²—ç²’åº¦é˜¶æ®µï¼Œæ¨¡å‹è‡ªé€‚åº”åœ°ä»å›¾åƒç‰¹å¾ä¸­æå–é«˜å“åº”åŒºåŸŸï¼Œç”Ÿæˆç²—ç•¥çš„åˆ†å‰²æ©ç ã€‚åœ¨ç»†ç²’åº¦é˜¶æ®µï¼Œæ¨¡å‹å¯¹ç²—ç•¥çš„åˆ†å‰²æ©ç è¿›è¡Œç²¾ç»†åŒ–ï¼Œåˆ©ç”¨å±€éƒ¨æ³¨æ„åŠ›æœºåˆ¶å¢å¼ºç»†èŠ‚å»ºæ¨¡èƒ½åŠ›ã€‚æœ€åï¼Œåœ¨è§£ç é˜¶æ®µï¼Œå°†ç²¾ç»†åŒ–çš„åˆ†å‰²æ©ç ç¼–ç ä¸ºæ½œåœ¨çš„æç¤ºåµŒå…¥ï¼Œè¾“å…¥åˆ°SAMè§£ç å™¨ä¸­ï¼Œç”Ÿæˆæœ€ç»ˆçš„åˆ†å‰²ç»“æœã€‚

**å…³é”®åˆ›æ–°**ï¼šGrc-SAMçš„å…³é”®åˆ›æ–°åœ¨äºå°†ç²’è®¡ç®—çš„æ€æƒ³å¼•å…¥åˆ°æ— æç¤ºå›¾åƒåˆ†å‰²ä»»åŠ¡ä¸­ï¼Œå¹¶è®¾è®¡äº†ä¸€ç§ç²—åˆ°ç»†çš„åˆ†å‰²æ¡†æ¶ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒGrc-SAMä¸éœ€è¦äººå·¥è®¾è®¡çš„æç¤ºï¼Œè€Œæ˜¯é€šè¿‡è‡ªåŠ¨æ¨ç†çš„æ–¹å¼ç”Ÿæˆæç¤ºåµŒå…¥ï¼Œä»è€Œæé«˜äº†åˆ†å‰²çš„è‡ªåŠ¨åŒ–ç¨‹åº¦å’Œæ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒGrc-SAMè¿˜é‡‡ç”¨äº†ç¨€ç–å±€éƒ¨æ³¨æ„åŠ›æœºåˆ¶ï¼Œé™ä½äº†è®¡ç®—å¤æ‚åº¦ï¼Œä½¿å…¶èƒ½å¤Ÿå¤„ç†é«˜åˆ†è¾¨ç‡å›¾åƒã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç²—ç²’åº¦é˜¶æ®µï¼Œè®ºæ–‡è®¾è®¡äº†ä¸€ç§è‡ªé€‚åº”çš„åŒºåŸŸæå–æ¨¡å—ï¼Œç”¨äºä»å›¾åƒç‰¹å¾ä¸­æå–é«˜å“åº”åŒºåŸŸã€‚è¯¥æ¨¡å—é€šè¿‡å­¦ä¹ ä¸€ä¸ªæ³¨æ„åŠ›æƒé‡ï¼Œè‡ªåŠ¨é€‰æ‹©é‡è¦çš„ç‰¹å¾é€šé“ã€‚åœ¨ç»†ç²’åº¦é˜¶æ®µï¼Œè®ºæ–‡é‡‡ç”¨äº†swin-styleçš„å±€éƒ¨æ³¨æ„åŠ›æœºåˆ¶ï¼Œå°†å›¾åƒåˆ’åˆ†ä¸ºå¤šä¸ªpatchï¼Œå¹¶åœ¨æ¯ä¸ªpatchå†…éƒ¨è¿›è¡Œæ³¨æ„åŠ›è®¡ç®—ã€‚è¿™ç§å±€éƒ¨æ³¨æ„åŠ›æœºåˆ¶å¯ä»¥æœ‰æ•ˆåœ°é™ä½è®¡ç®—å¤æ‚åº¦ï¼Œå¹¶å¢å¼ºç»†èŠ‚å»ºæ¨¡èƒ½åŠ›ã€‚æŸå¤±å‡½æ•°æ–¹é¢ï¼Œè®ºæ–‡é‡‡ç”¨äº†äº¤å‰ç†µæŸå¤±å‡½æ•°å’ŒDiceæŸå¤±å‡½æ•°ï¼Œç”¨äºä¼˜åŒ–åˆ†å‰²ç»“æœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒGrc-SAMåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå‡å–å¾—äº†ä¼˜äºåŸºçº¿æ–¹æ³•çš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨COCOæ•°æ®é›†ä¸Šï¼ŒGrc-SAMçš„åˆ†å‰²ç²¾åº¦æ¯”SAMæé«˜äº†çº¦3ä¸ªç™¾åˆ†ç‚¹ã€‚æ­¤å¤–ï¼ŒGrc-SAMåœ¨å¤„ç†é«˜åˆ†è¾¨ç‡å›¾åƒæ—¶ï¼Œä¹Ÿè¡¨ç°å‡ºäº†è‰¯å¥½çš„å¯æ‰©å±•æ€§ï¼Œè¯æ˜äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Grc-SAMåœ¨åŒ»å­¦å›¾åƒåˆ†æã€é¥æ„Ÿå›¾åƒå¤„ç†ã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥ç”¨äºè‡ªåŠ¨è¯†åˆ«ç—…ç¶åŒºåŸŸã€æå–åœ°ç‰©ä¿¡æ¯ã€åˆ†å‰²é“è·¯å’Œè½¦è¾†ç­‰ã€‚è¯¥ç ”ç©¶çš„å®é™…ä»·å€¼åœ¨äºæé«˜äº†æ— æç¤ºå›¾åƒåˆ†å‰²çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ï¼Œé™ä½äº†äººå·¥æ ‡æ³¨çš„æˆæœ¬ã€‚æœªæ¥ï¼ŒGrc-SAMå¯ä»¥è¿›ä¸€æ­¥æ‰©å±•åˆ°è§†é¢‘åˆ†å‰²ã€ä¸‰ç»´å›¾åƒåˆ†å‰²ç­‰ä»»åŠ¡ä¸­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Prompt-free image segmentation aims to generate accurate masks without manual guidance. Typical pre-trained models, notably Segmentation Anything Model (SAM), generate prompts directly at a single granularity level. However, this approach has two limitations: (1) Localizability, lacking mechanisms for autonomous region localization; (2) Scalability, limited fine-grained modeling at high resolution. To address these challenges, we introduce Granular Computing-driven SAM (Grc-SAM), a coarse-to-fine framework motivated by Granular Computing (GrC). First, the coarse stage adaptively extracts high-response regions from features to achieve precise foreground localization and reduce reliance on external prompts. Second, the fine stage applies finer patch partitioning with sparse local swin-style attention to enhance detail modeling and enable high-resolution segmentation. Third, refined masks are encoded as latent prompt embeddings for the SAM decoder, replacing handcrafted prompts with an automated reasoning process. By integrating multi-granularity attention, Grc-SAM bridges granular computing with vision transformers. Extensive experimental results demonstrate Grc-SAM outperforms baseline methods in both accuracy and scalability. It offers a unique granular computational perspective for prompt-free segmentation.

