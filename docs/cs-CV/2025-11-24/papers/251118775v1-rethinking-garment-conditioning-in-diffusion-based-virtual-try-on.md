---
layout: default
title: Rethinking Garment Conditioning in Diffusion-based Virtual Try-On
---

# Rethinking Garment Conditioning in Diffusion-based Virtual Try-On

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.18775" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.18775v1</a>
  <a href="https://arxiv.org/pdf/2511.18775.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.18775v1" onclick="toggleFavorite(this, '2511.18775v1', 'Rethinking Garment Conditioning in Diffusion-based Virtual Try-On')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kihyun Na, Jinyoung Choi, Injung Kim

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-24

**å¤‡æ³¨**: 15 pages (including references and supplementary material), 10 figures, 7 tables. Code and pretrained models will be released

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRe-CatVTONï¼Œé«˜æ•ˆå•UNetæ‰©æ•£æ¨¡å‹å®ç°é«˜æ€§èƒ½è™šæ‹Ÿè¯•ç©¿**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)**

**å…³é”®è¯**: `è™šæ‹Ÿè¯•ç©¿` `æ‰©æ•£æ¨¡å‹` `å•UNet` `ä¸Šä¸‹æ–‡ç‰¹å¾å­¦ä¹ ` `æ— åˆ†ç±»å™¨å¼•å¯¼` `å›¾åƒåˆæˆ` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŸºäºæ‰©æ•£æ¨¡å‹çš„è™šæ‹Ÿè¯•ç©¿æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åŒUNetç»“æ„ï¼Œè™½ç„¶æ•ˆæœå¥½ï¼Œä½†è®¡ç®—å’Œå†…å­˜å¼€é”€å·¨å¤§ã€‚
2. è®ºæ–‡æå‡ºRe-CatVTONï¼Œä¸€ä¸ªé«˜æ•ˆçš„å•UNetæ¨¡å‹ï¼Œé€šè¿‡ä¼˜åŒ–ä¸Šä¸‹æ–‡ç‰¹å¾å­¦ä¹ å’Œæ”¹è¿›å¼•å¯¼ç­–ç•¥ï¼Œæå‡æ€§èƒ½ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒRe-CatVTONåœ¨FIDã€KIDå’ŒLPIPSæŒ‡æ ‡ä¸Šä¼˜äºç°æœ‰å•UNetæ¨¡å‹ï¼Œå¹¶åœ¨æ•ˆç‡ä¸Šä¼˜äºåŒUNetæ¨¡å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è™šæ‹Ÿè¯•ç©¿(VTON)æ—¨åœ¨åˆæˆç»™å®šäººç‰©å›¾åƒå’Œæœè£…å›¾åƒæ¡ä»¶ä¸‹ï¼Œäººç‰©ç©¿ç€ç›®æ ‡æœè£…çš„å›¾åƒã€‚åŸºäºæ‰©æ•£æ¨¡å‹çš„VTONæ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯é‡‡ç”¨åŒUNetæ¶æ„çš„æ¨¡å‹ï¼Œç›¸æ¯”å•UNetæ¨¡å‹å±•ç°å‡ºæ›´é«˜çš„å›¾åƒä¿çœŸåº¦ï¼Œä½†å…¶åºå¤§çš„ç»“æ„å¯¼è‡´äº†æ˜¾è‘—çš„è®¡ç®—å’Œå†…å­˜å¼€é”€ã€‚æœ¬ç ”ç©¶é€šè¿‡å¯è§†åŒ–åˆ†æå’Œç†è®ºåˆ†æï¼Œæ¨å¯¼äº†å…³äºå­¦ä¹ ä¸Šä¸‹æ–‡ç‰¹å¾ä»¥è°ƒèŠ‚å»å™ªè¿‡ç¨‹çš„ä¸‰ä¸ªå‡è®¾ã€‚åŸºäºè¿™äº›å‡è®¾ï¼Œæˆ‘ä»¬å¼€å‘äº†Re-CatVTONï¼Œä¸€ä¸ªé«˜æ•ˆçš„å•UNetæ¨¡å‹ï¼Œå®ç°äº†é«˜æ€§èƒ½ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥é€šè¿‡å¼•å…¥é’ˆå¯¹VTONç©ºé—´æ‹¼æ¥æ¡ä»¶çš„æ”¹è¿›çš„æ— åˆ†ç±»å™¨å¼•å¯¼ç­–ç•¥ï¼Œä»¥åŠç›´æ¥æ³¨å…¥ä»å¹²å‡€æœè£…æ½œåœ¨å˜é‡å¯¼å‡ºçš„çœŸå®æœè£…æ½œåœ¨å˜é‡ä»¥é˜²æ­¢é¢„æµ‹è¯¯å·®ç´¯ç§¯ï¼Œæ¥å¢å¼ºæ¨¡å‹ã€‚æ‰€æå‡ºçš„Re-CatVTONç›¸æ¯”å…¶å‰èº«(CatVTON)æ˜¾è‘—æé«˜äº†æ€§èƒ½ï¼Œå¹¶ä¸”æ¯”é«˜æ€§èƒ½åŒUNetæ¨¡å‹Leffaéœ€è¦æ›´å°‘çš„è®¡ç®—å’Œå†…å­˜ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼ŒFIDã€KIDå’ŒLPIPSåˆ†æ•°æœ‰æ‰€æé«˜ï¼Œè€ŒSSIMç•¥æœ‰ä¸‹é™ï¼Œä¸ºå•UNet VTONæ¨¡å‹å»ºç«‹äº†ä¸€ç§æ–°çš„æ•ˆç‡-æ€§èƒ½æƒè¡¡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è™šæ‹Ÿè¯•ç©¿ä»»åŠ¡ä¸­ï¼ŒåŸºäºæ‰©æ•£æ¨¡å‹çš„åŒUNetç»“æ„è®¡ç®—å’Œå†…å­˜å¼€é”€è¿‡å¤§çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•è™½ç„¶èƒ½ç”Ÿæˆé«˜è´¨é‡çš„è¯•ç©¿å›¾åƒï¼Œä½†å…¶å¤æ‚çš„ç½‘ç»œç»“æ„é™åˆ¶äº†å…¶åœ¨èµ„æºå—é™åœºæ™¯ä¸‹çš„åº”ç”¨ã€‚å› æ­¤ï¼Œéœ€è¦è®¾è®¡ä¸€ç§æ›´é«˜æ•ˆçš„è™šæ‹Ÿè¯•ç©¿æ¨¡å‹ï¼Œåœ¨ä¿è¯ç”Ÿæˆè´¨é‡çš„åŒæ—¶ï¼Œé™ä½è®¡ç®—æˆæœ¬ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ·±å…¥åˆ†æä¸Šä¸‹æ–‡ç‰¹å¾çš„å­¦ä¹ è¿‡ç¨‹ï¼Œå¹¶åŸºäºåˆ†æç»“æœè®¾è®¡æ›´æœ‰æ•ˆçš„ç½‘ç»œç»“æ„å’Œè®­ç»ƒç­–ç•¥ï¼Œä»è€Œåœ¨å•UNetç»“æ„ä¸‹å®ç°ä¸åŒUNetç»“æ„ç›¸åª²ç¾çš„æ€§èƒ½ã€‚å…·ä½“æ¥è¯´ï¼Œè®ºæ–‡æå‡ºäº†å…³äºä¸Šä¸‹æ–‡ç‰¹å¾å­¦ä¹ çš„ä¸‰ä¸ªå‡è®¾ï¼Œå¹¶åŸºäºè¿™äº›å‡è®¾è®¾è®¡äº†Re-CatVTONæ¨¡å‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRe-CatVTONåŸºäºå•UNetæ¶æ„ï¼Œæ•´ä½“æµç¨‹å¦‚ä¸‹ï¼šé¦–å…ˆï¼Œå°†äººç‰©å›¾åƒå’Œæœè£…å›¾åƒè¿›è¡Œç©ºé—´æ‹¼æ¥ï¼Œä½œä¸ºUNetçš„è¾“å…¥ã€‚ç„¶åï¼ŒUNetè¿›è¡Œå»å™ªè¿‡ç¨‹ï¼Œé€æ­¥ç”Ÿæˆè¯•ç©¿å›¾åƒã€‚ä¸ºäº†æå‡æ€§èƒ½ï¼Œè®ºæ–‡è¿˜å¼•å…¥äº†æ”¹è¿›çš„æ— åˆ†ç±»å™¨å¼•å¯¼ç­–ç•¥å’Œç›´æ¥æ³¨å…¥çœŸå®æœè£…æ½œåœ¨å˜é‡çš„æ–¹æ³•ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°ç‚¹åœ¨äºï¼š1) åŸºäºå¯è§†åŒ–å’Œç†è®ºåˆ†æï¼Œæå‡ºäº†å…³äºä¸Šä¸‹æ–‡ç‰¹å¾å­¦ä¹ çš„ä¸‰ä¸ªå‡è®¾ã€‚2) åŸºäºè¿™äº›å‡è®¾ï¼Œè®¾è®¡äº†Re-CatVTONæ¨¡å‹ï¼Œè¯¥æ¨¡å‹åœ¨å•UNetç»“æ„ä¸‹å®ç°äº†é«˜æ€§èƒ½ã€‚3) æå‡ºäº†é’ˆå¯¹VTONç©ºé—´æ‹¼æ¥æ¡ä»¶çš„æ”¹è¿›çš„æ— åˆ†ç±»å™¨å¼•å¯¼ç­–ç•¥ã€‚4) æå‡ºäº†ç›´æ¥æ³¨å…¥çœŸå®æœè£…æ½œåœ¨å˜é‡çš„æ–¹æ³•ï¼Œä»¥é˜²æ­¢é¢„æµ‹è¯¯å·®ç´¯ç§¯ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ç½‘ç»œç»“æ„ï¼šé‡‡ç”¨å•UNetç»“æ„ï¼Œå¹¶é’ˆå¯¹VTONä»»åŠ¡è¿›è¡Œäº†ä¼˜åŒ–ã€‚2) æŸå¤±å‡½æ•°ï¼šé‡‡ç”¨æ ‡å‡†çš„æ‰©æ•£æ¨¡å‹æŸå¤±å‡½æ•°ã€‚3) è®­ç»ƒç­–ç•¥ï¼šé‡‡ç”¨äº†æ”¹è¿›çš„æ— åˆ†ç±»å™¨å¼•å¯¼ç­–ç•¥å’Œç›´æ¥æ³¨å…¥çœŸå®æœè£…æ½œåœ¨å˜é‡çš„æ–¹æ³•ã€‚4) å‚æ•°è®¾ç½®ï¼šå…·ä½“å‚æ•°è®¾ç½®åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ï¼Œè¿™é‡Œä¸å†èµ˜è¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

Re-CatVTONåœ¨è™šæ‹Ÿè¯•ç©¿ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œåœ¨FIDã€KIDå’ŒLPIPSæŒ‡æ ‡ä¸Šä¼˜äºå…¶å‰èº«CatVTONï¼Œå¹¶ä¸”åœ¨è®¡ç®—æ•ˆç‡ä¸Šä¼˜äºé«˜æ€§èƒ½åŒUNetæ¨¡å‹Leffaã€‚å…·ä½“æ¥è¯´ï¼ŒRe-CatVTONåœ¨ä¿è¯SSIMæŒ‡æ ‡ç•¥å¾®ä¸‹é™çš„æƒ…å†µä¸‹ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—å’Œå†…å­˜å¼€é”€ï¼Œä¸ºå•UNet VTONæ¨¡å‹å»ºç«‹äº†ä¸€ç§æ–°çš„æ•ˆç‡-æ€§èƒ½æƒè¡¡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºåœ¨çº¿è´­ç‰©ã€è™šæ‹Ÿè¯•è¡£é—´ç­‰é¢†åŸŸï¼Œå¸®åŠ©ç”¨æˆ·æ›´ç›´è§‚åœ°äº†è§£æœè£…çš„ä¸Šèº«æ•ˆæœï¼Œæå‡è´­ç‰©ä½“éªŒã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥åº”ç”¨äºæ¸¸æˆã€ç¤¾äº¤åª’ä½“ç­‰é¢†åŸŸï¼Œä¸ºç”¨æˆ·æä¾›ä¸ªæ€§åŒ–çš„è™šæ‹Ÿå½¢è±¡å®šåˆ¶æœåŠ¡ã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶å¯ä»¥è¿›ä¸€æ­¥æ‰©å±•åˆ°æ›´å¤æ‚çš„æœè£…ç±»å‹å’Œäººä½“å§¿æ€ï¼Œå®ç°æ›´é€¼çœŸçš„è™šæ‹Ÿè¯•ç©¿æ•ˆæœã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Virtual Try-On (VTON) is the task of synthesizing an image of a person wearing a target garment, conditioned on a person image and a garment image. While diffusion-based VTON models featuring a Dual UNet architecture demonstrate superior fidelity compared to single UNet models, they incur substantial computational and memory overhead due to their heavy structure. In this study, through visualization analysis and theoretical analysis, we derived three hypotheses regarding the learning of context features to condition the denoising process. Based on these hypotheses, we developed Re-CatVTON, an efficient single UNet model that achieves high performance. We further enhance the model by introducing a modified classifier-free guidance strategy tailored for VTON's spatial concatenation conditioning, and by directly injecting the ground-truth garment latent derived from the clean garment latent to prevent the accumulation of prediction error. The proposed Re-CatVTON significantly improves performance compared to its predecessor (CatVTON) and requires less computation and memory than the high-performance Dual UNet model, Leffa. Our results demonstrate improved FID, KID, and LPIPS scores, with only a marginal decrease in SSIM, establishing a new efficiency-performance trade-off for single UNet VTON models.

