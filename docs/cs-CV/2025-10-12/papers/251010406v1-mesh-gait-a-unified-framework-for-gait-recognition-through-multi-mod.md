---
layout: default
title: Mesh-Gait: A Unified Framework for Gait Recognition Through Multi-Modal Representation Learning from 2D Silhouettes
---

# Mesh-Gait: A Unified Framework for Gait Recognition Through Multi-Modal Representation Learning from 2D Silhouettes

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.10406" target="_blank" class="toolbar-btn">arXiv: 2510.10406v1</a>
    <a href="https://arxiv.org/pdf/2510.10406.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.10406v1" 
            onclick="toggleFavorite(this, '2510.10406v1', 'Mesh-Gait: A Unified Framework for Gait Recognition Through Multi-Modal Representation Learning from 2D Silhouettes')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Zhao-Yang Wang, Jieneng Chen, Jiang Liu, Yuxiang Guo, Rama Chellappa

**ÂàÜÁ±ª**: cs.CV, cs.AI, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-12

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**Mesh-GaitÔºöÊèêÂá∫‰∏ÄÁßçÂü∫‰∫é2DËΩÆÂªìÂ§öÊ®°ÊÄÅË°®ÂæÅÂ≠¶‰π†ÁöÑÁªü‰∏ÄÊ≠•ÊÄÅËØÜÂà´Ê°ÜÊû∂**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Ê≠•ÊÄÅËØÜÂà´` `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `3DÈáçÂª∫` `ÁÉ≠ÂõæË°®Á§∫` `ÁîüÁâ©ÁâπÂæÅËØÜÂà´`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊ≠•ÊÄÅËØÜÂà´ÊñπÊ≥ïÂú®ËßÜËßíÂèòÂåñ„ÄÅÈÅÆÊå°ÂíåÂô™Â£∞‰∏ãË°®Áé∞‰∏ç‰Ω≥ÔºåËÄåÁõ¥Êé•‰ΩøÁî®3D‰ø°ÊÅØËÆ°ÁÆóÊàêÊú¨ËøáÈ´ò„ÄÇ
2. Mesh-GaitÈÄöËøá‰ªé2DËΩÆÂªìÈáçÂª∫3DÁÉ≠Âõæ‰Ωú‰∏∫‰∏≠Èó¥Ë°®Á§∫ÔºåÈ´òÊïàÂú∞ËûçÂêà‰∫Ü2DÂíå3D‰ø°ÊÅØÁöÑ‰ºòÂäø„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåMesh-GaitÂú®Ê≠•ÊÄÅËØÜÂà´Á≤æÂ∫¶‰∏äËææÂà∞‰∫ÜÂΩìÂâçÊúÄ‰ºòÊ∞¥Âπ≥ÔºåËØÅÊòé‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Ê≠•ÊÄÅËØÜÂà´ÊòØ‰∏ÄÁßçÈáçË¶ÅÁöÑÁîüÁâ©ÁâπÂæÅÊäÄÊúØÔºåÂÆÉÂà©Áî®Áã¨ÁâπÁöÑË°åËµ∞Ê®°ÂºèËøõË°å‰∏™‰ΩìËØÜÂà´ÔºåÈÄöÂ∏∏‰ΩøÁî®ËΩÆÂªìÊàñÈ™®È™ºÁ≠â2DË°®Á§∫„ÄÇÁÑ∂ËÄåÔºåËøô‰∫õÊñπÊ≥ïÂú®ËßÜËßíÂèòÂåñ„ÄÅÈÅÆÊå°ÂíåÂô™Â£∞ÊñπÈù¢Â≠òÂú®‰∏çË∂≥„ÄÇÁªìÂêà3DË∫´‰ΩìÂΩ¢Áä∂‰ø°ÊÅØÁöÑÂ§öÊ®°ÊÄÅÊñπÊ≥ïËôΩÁÑ∂ÊèêÈ´ò‰∫ÜÈ≤ÅÊ£íÊÄßÔºå‰ΩÜËÆ°ÁÆóÊàêÊú¨È´òÊòÇÔºåÈôêÂà∂‰∫ÜÂÖ∂Âú®ÂÆûÊó∂Â∫îÁî®‰∏≠ÁöÑÂèØË°åÊÄß„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÊåëÊàòÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÁ´ØÂà∞Á´ØÂ§öÊ®°ÊÄÅÊ≠•ÊÄÅËØÜÂà´Ê°ÜÊû∂Mesh-GaitÔºåËØ•Ê°ÜÊû∂Áõ¥Êé•‰ªé2DËΩÆÂªìÈáçÂª∫3DË°®Á§∫ÔºåÊúâÊïàÂú∞ÁªìÂêà‰∫Ü‰∏§ÁßçÊ®°ÊÄÅÁöÑ‰ºòÂäø„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåÁõ¥Êé•‰ªé3DÂÖ≥ËäÇÊàñÁΩëÊ†ºÂ≠¶‰π†3DÁâπÂæÅÊòØÂ§çÊùÇ‰∏îÈöæ‰ª•‰∏éÂü∫‰∫éËΩÆÂªìÁöÑÊ≠•ÊÄÅÁâπÂæÅËûçÂêàÁöÑ„ÄÇ‰∏∫‰∫ÜÂÖãÊúçËøô‰∏ÄÁÇπÔºåMesh-GaitÈáçÂª∫3DÁÉ≠Âõæ‰Ωú‰∏∫‰∏≠Èó¥Ë°®Á§∫Ôºå‰ΩøÊ®°ÂûãËÉΩÂ§üÊúâÊïàÂú∞ÊçïËé∑3DÂá†‰Ωï‰ø°ÊÅØÔºåÂêåÊó∂‰øùÊåÅÁÆÄÂçïÊÄßÂíåËÆ°ÁÆóÊïàÁéá„ÄÇÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠Ôºå‰∏≠Èó¥3DÁÉ≠ÂõæÂú®ÁõëÁù£Â≠¶‰π†‰∏ãÈÄêÊ∏êÈáçÂª∫Âπ∂ÂèòÂæóË∂äÊù•Ë∂äÂáÜÁ°ÆÔºåÂÖ∂‰∏≠ÊçüÂ§±ÊòØÂú®ÈáçÂª∫ÁöÑ3DÂÖ≥ËäÇ„ÄÅËôöÊãüÊ†áËÆ∞Âíå3DÁΩëÊ†ºÂèäÂÖ∂ÂØπÂ∫îÁöÑÁúüÂÆûÂÄº‰πãÈó¥ËÆ°ÁÆóÁöÑÔºåÁ°Æ‰øùÁ≤æÁ°ÆÁöÑÁ©∫Èó¥ÂØπÈΩêÂíå‰∏ÄËá¥ÁöÑ3DÁªìÊûÑ„ÄÇMesh-Gait‰ª•ËÆ°ÁÆóÈ´òÊïàÁöÑÊñπÂºè‰ªéËΩÆÂªìÂíåÈáçÂª∫ÁöÑ3DÁÉ≠Âõæ‰∏≠ÊèêÂèñÂà§Âà´ÊÄßÁâπÂæÅ„ÄÇËøôÁßçËÆæËÆ°‰ΩøÊ®°ÂûãËÉΩÂ§üÊçïËé∑Á©∫Èó¥ÂíåÁªìÊûÑÊ≠•ÊÄÅÁâπÂæÅÔºåÂêåÊó∂ÈÅøÂÖç‰∫ÜÁõ¥Êé•‰ªéRGBËßÜÈ¢ëËøõË°å3DÈáçÂª∫ÁöÑÁπÅÈáçÂºÄÈîÄÔºå‰ªéËÄå‰ΩøÁΩëÁªúËÉΩÂ§ü‰∏ìÊ≥®‰∫éËøêÂä®Âä®ÊÄÅËÄå‰∏çÊòØ‰∏çÁõ∏ÂÖ≥ÁöÑËßÜËßâÁªÜËäÇ„ÄÇÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåMesh-GaitÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÂáÜÁ°ÆÊÄß„ÄÇ‰ª£Á†ÅÂ∞ÜÂú®ËÆ∫ÊñáË¢´Êé•ÂèóÂêéÂèëÂ∏É„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÊ≠•ÊÄÅËØÜÂà´ÊñπÊ≥ï‰∏ªË¶Å‰æùËµñ‰∫é2DËΩÆÂªìÊàñÈ™®È™º‰ø°ÊÅØÔºåÂÆπÊòìÂèóÂà∞ËßÜËßíÂèòÂåñ„ÄÅÈÅÆÊå°ÂíåÂô™Â£∞ÁöÑÂΩ±ÂìçÔºåÈ≤ÅÊ£íÊÄßËæÉÂ∑Æ„ÄÇËôΩÁÑ∂Âü∫‰∫é3D‰ø°ÊÅØÁöÑÊñπÊ≥ïÂèØ‰ª•ÊèêÈ´òÈ≤ÅÊ£íÊÄßÔºå‰ΩÜÁõ¥Êé•‰ªéRGBËßÜÈ¢ëËøõË°å3DÈáçÂª∫ËÆ°ÁÆóÊàêÊú¨È´òÊòÇÔºåÈöæ‰ª•Êª°Ë∂≥ÂÆûÊó∂ÊÄßË¶ÅÊ±Ç„ÄÇÂõ†Ê≠§ÔºåÂ¶Ç‰ΩïÂú®‰øùËØÅÈ≤ÅÊ£íÊÄßÁöÑÂâçÊèê‰∏ãÔºåÈôç‰ΩéËÆ°ÁÆóÂ§çÊùÇÂ∫¶ÔºåÊòØÊ≠•ÊÄÅËØÜÂà´È¢ÜÂüüÈù¢‰∏¥ÁöÑ‰∏Ä‰∏™ÈáçË¶ÅÊåëÊàò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöMesh-GaitÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøá2DËΩÆÂªìÈáçÂª∫3DÁÉ≠Âõæ‰Ωú‰∏∫‰∏≠Èó¥Ë°®Á§∫Ôºå‰ªéËÄåÂ∞Ü2DËΩÆÂªì‰ø°ÊÅØÂíå3DÂá†‰Ωï‰ø°ÊÅØÊúâÊïàÂú∞ÁªìÂêàËµ∑Êù•„ÄÇËøôÁßçÊñπÊ≥ïÈÅøÂÖç‰∫ÜÁõ¥Êé•‰ªéRGBËßÜÈ¢ëËøõË°å3DÈáçÂª∫ÁöÑÂ§çÊùÇÊÄßÔºåÂêåÊó∂ÂèàËÉΩÂà©Áî®3D‰ø°ÊÅØÊèêÈ´òÈ≤ÅÊ£íÊÄß„ÄÇÈÄöËøáÁõëÁù£Â≠¶‰π†ÔºåÈÄêÊ≠•‰ºòÂåñ3DÁÉ≠ÂõæÁöÑÈáçÂª∫Á≤æÂ∫¶ÔºåÁ°Æ‰øùÁ©∫Èó¥ÂØπÈΩêÂíåÁªìÊûÑ‰∏ÄËá¥ÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöMesh-GaitÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Èò∂ÊÆµÔºö1) ‰ªé2DËΩÆÂªìËæìÂÖ•ÂºÄÂßãÔºõ2) ÈÄöËøáÁΩëÁªúÈáçÂª∫3DÁÉ≠ÂõæÔºõ3) ‰ªé2DËΩÆÂªìÂíåÈáçÂª∫ÁöÑ3DÁÉ≠Âõæ‰∏≠ÊèêÂèñÁâπÂæÅÔºõ4) Â∞ÜÊèêÂèñÁöÑÁâπÂæÅËøõË°åËûçÂêàÔºõ5) ‰ΩøÁî®ÂàÜÁ±ªÂô®ËøõË°åÊ≠•ÊÄÅËØÜÂà´„ÄÇËØ•Ê°ÜÊû∂ÊòØ‰∏Ä‰∏™Á´ØÂà∞Á´ØÁöÑÂ≠¶‰π†Ê°ÜÊû∂ÔºåÂèØ‰ª•ÂêåÊó∂‰ºòÂåñ2DÂíå3DÁâπÂæÅÁöÑÊèêÂèñÂíåËûçÂêà„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöMesh-GaitÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫é‰ΩøÁî®3DÁÉ≠Âõæ‰Ωú‰∏∫‰∏≠Èó¥Ë°®Á§∫ÔºåËøûÊé•2DËΩÆÂªìÂíå3DÂá†‰Ωï‰ø°ÊÅØ„ÄÇ‰∏éÁõ¥Êé•‰ªé3DÂÖ≥ËäÇÊàñÁΩëÊ†ºÂ≠¶‰π†3DÁâπÂæÅÁõ∏ÊØîÔºåÈáçÂª∫3DÁÉ≠ÂõæÊõ¥Âä†ÁÆÄÂçïÈ´òÊïàÔºåÂπ∂‰∏îÊõ¥ÂÆπÊòì‰∏éÂü∫‰∫éËΩÆÂªìÁöÑÊ≠•ÊÄÅÁâπÂæÅËûçÂêà„ÄÇÊ≠§Â§ñÔºåÈÄöËøáÁõëÁù£Â≠¶‰π†ÔºåÈÄêÊ≠•‰ºòÂåñ3DÁÉ≠ÂõæÁöÑÈáçÂª∫Á≤æÂ∫¶ÔºåÁ°Æ‰øùÁ©∫Èó¥ÂØπÈΩêÂíåÁªìÊûÑ‰∏ÄËá¥ÊÄßÔºå‰πüÊòØ‰∏Ä‰∏™ÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠ÔºåÊçüÂ§±ÂáΩÊï∞ÊòØÂú®ÈáçÂª∫ÁöÑ3DÂÖ≥ËäÇ„ÄÅËôöÊãüÊ†áËÆ∞Âíå3DÁΩëÊ†ºÂèäÂÖ∂ÂØπÂ∫îÁöÑÁúüÂÆûÂÄº‰πãÈó¥ËÆ°ÁÆóÁöÑÔºå‰ª•Á°Æ‰øùÁ≤æÁ°ÆÁöÑÁ©∫Èó¥ÂØπÈΩêÂíå‰∏ÄËá¥ÁöÑ3DÁªìÊûÑ„ÄÇÂÖ∑‰ΩìÁöÑÁΩëÁªúÁªìÊûÑÂíåÂèÇÊï∞ËÆæÁΩÆÂú®ËÆ∫Êñá‰∏≠Ê≤°ÊúâËØ¶ÁªÜËØ¥ÊòéÔºåÈúÄË¶ÅÂú®‰ª£Á†ÅÂèëÂ∏ÉÂêéËøõ‰∏ÄÊ≠•ÂàÜÊûê„ÄÇÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°ÊòØÂÖ≥ÈîÆÔºåÈúÄË¶ÅÂπ≥Ë°°2DËΩÆÂªì‰ø°ÊÅØÂíå3DÂá†‰Ωï‰ø°ÊÅØÁöÑË¥°ÁåÆ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ËÆ∫ÊñáÈÄöËøáÂ§ßÈáèÂÆûÈ™åÈ™åËØÅ‰∫ÜMesh-GaitÁöÑÊúâÊïàÊÄßÔºåÁªìÊûúË°®ÊòéMesh-GaitÂú®Ê≠•ÊÄÅËØÜÂà´Á≤æÂ∫¶‰∏äËææÂà∞‰∫ÜÂΩìÂâçÊúÄ‰ºòÊ∞¥Âπ≥„ÄÇÂÖ∑‰ΩìÁöÑÊÄßËÉΩÊï∞ÊçÆÂíåÂØπÊØîÂü∫Á∫øÈúÄË¶ÅÂú®ËÆ∫Êñá‰∏≠Êü•Êâæ„ÄÇËØ•ÊñπÊ≥ïÂú®ËÆ°ÁÆóÊïàÁéáÂíåËØÜÂà´Á≤æÂ∫¶‰πãÈó¥ÂèñÂæó‰∫ÜËâØÂ•ΩÁöÑÂπ≥Ë°°Ôºå‰ΩøÂÖ∂Êõ¥ÈÄÇÂêàÂÆûÈôÖÂ∫îÁî®„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

Mesh-GaitÂú®ÂÆâÈò≤ÁõëÊéß„ÄÅÊô∫ËÉΩÂÆ∂Â±Ö„ÄÅÂåªÁñóÂÅ•Â∫∑Á≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇ‰æãÂ¶ÇÔºåÂèØ‰ª•Áî®‰∫éÂú®ÁõëÊéßËßÜÈ¢ë‰∏≠ËØÜÂà´ÁâπÂÆö‰∫∫ÂëòÔºåÂú®Êô∫ËÉΩÂÆ∂Â±Ö‰∏≠Ê†πÊçÆÊ≠•ÊÄÅËØÜÂà´Áî®Êà∑Ë∫´‰ªΩÔºåÂú®ÂåªÁñóÂÅ•Â∫∑È¢ÜÂüüËØÑ‰º∞ÊÇ£ËÄÖÁöÑÊ≠•ÊÄÅÂÅ•Â∫∑Áä∂ÂÜµ„ÄÇËØ•Á†îÁ©∂ÁöÑÊú™Êù•ÂΩ±ÂìçÂú®‰∫éÔºåÂÆÉ‰∏∫Ê≠•ÊÄÅËØÜÂà´Êèê‰æõ‰∫Ü‰∏ÄÁßçÊõ¥Âä†È≤ÅÊ£íÂíåÈ´òÊïàÁöÑËß£ÂÜ≥ÊñπÊ°àÔºåÊúâÊúõÊé®Âä®Ê≠•ÊÄÅËØÜÂà´ÊäÄÊúØÂú®ÂÆûÈôÖÂú∫ÊôØ‰∏≠ÁöÑÂ∫îÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Gait recognition, a fundamental biometric technology, leverages unique walking patterns for individual identification, typically using 2D representations such as silhouettes or skeletons. However, these methods often struggle with viewpoint variations, occlusions, and noise. Multi-modal approaches that incorporate 3D body shape information offer improved robustness but are computationally expensive, limiting their feasibility for real-time applications. To address these challenges, we introduce Mesh-Gait, a novel end-to-end multi-modal gait recognition framework that directly reconstructs 3D representations from 2D silhouettes, effectively combining the strengths of both modalities. Compared to existing methods, directly learning 3D features from 3D joints or meshes is complex and difficult to fuse with silhouette-based gait features. To overcome this, Mesh-Gait reconstructs 3D heatmaps as an intermediate representation, enabling the model to effectively capture 3D geometric information while maintaining simplicity and computational efficiency. During training, the intermediate 3D heatmaps are gradually reconstructed and become increasingly accurate under supervised learning, where the loss is calculated between the reconstructed 3D joints, virtual markers, and 3D meshes and their corresponding ground truth, ensuring precise spatial alignment and consistent 3D structure. Mesh-Gait extracts discriminative features from both silhouettes and reconstructed 3D heatmaps in a computationally efficient manner. This design enables the model to capture spatial and structural gait characteristics while avoiding the heavy overhead of direct 3D reconstruction from RGB videos, allowing the network to focus on motion dynamics rather than irrelevant visual details. Extensive experiments demonstrate that Mesh-Gait achieves state-of-the-art accuracy. The code will be released upon acceptance of the paper.

