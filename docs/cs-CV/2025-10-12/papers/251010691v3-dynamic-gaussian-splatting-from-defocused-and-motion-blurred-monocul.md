---
layout: default
title: Dynamic Gaussian Splatting from Defocused and Motion-blurred Monocular Videos
---

# Dynamic Gaussian Splatting from Defocused and Motion-blurred Monocular Videos

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.10691" target="_blank" class="toolbar-btn">arXiv: 2510.10691v3</a>
    <a href="https://arxiv.org/pdf/2510.10691.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.10691v3" 
            onclick="toggleFavorite(this, '2510.10691v3', 'Dynamic Gaussian Splatting from Defocused and Motion-blurred Monocular Videos')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Xuankai Zhang, Junjin Xiao, Qing Zhang

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-12 (Êõ¥Êñ∞: 2025-10-31)

**Â§áÊ≥®**: Accepted to NeurIPS 2025

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/hhhddddddd/dydeblur)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âä®ÊÄÅÈ´òÊñØÊ∫ÖÂ∞ÑÊ°ÜÊû∂ÔºåËß£ÂÜ≥Êï£ÁÑ¶ÂíåËøêÂä®Ê®°Á≥äËßÜÈ¢ëÁöÑÊñ∞ËßÜËßíÂêàÊàêÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)**

**ÂÖ≥ÈîÆËØç**: `Âä®ÊÄÅÈ´òÊñØÊ∫ÖÂ∞Ñ` `Êñ∞ËßÜËßíÂêàÊàê` `Êï£ÁÑ¶Ê®°Á≥ä` `ËøêÂä®Ê®°Á≥ä` `Ê®°Á≥äÊ†∏‰º∞ËÆ°` `ÂçïÁõÆËßÜÈ¢ë` `Âä®ÊÄÅÂú∫ÊôØÈáçÂª∫`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÈöæ‰ª•ÂêåÊó∂Â§ÑÁêÜÊï£ÁÑ¶ÂíåËøêÂä®Ê®°Á≥äÔºåÈôêÂà∂‰∫Ü‰ªéÊ®°Á≥äËßÜÈ¢ë‰∏≠ËøõË°åÈ´òË¥®ÈáèÊñ∞ËßÜËßíÂêàÊàêÁöÑËÉΩÂäõ„ÄÇ
2. ÊèêÂá∫‰∏ÄÁßçÂü∫‰∫éÊ®°Á≥äÈ¢ÑÊµãÁΩëÁªúÁöÑÂÉèÁ¥†Á∫ßÂèØÈù†Ê®°Á≥äÊ†∏‰º∞ËÆ°ÊñπÊ≥ïÔºåÂπ∂ÁªìÂêàÂä®ÊÄÅÈ´òÊñØËá¥ÂØÜÂåñÁ≠ñÁï•ÔºåÊèêÂçáÊ∏≤ÊüìË¥®Èáè„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®Êï£ÁÑ¶ÂíåËøêÂä®Ê®°Á≥äËßÜÈ¢ëÁöÑÊñ∞ËßÜËßíÂêàÊàê‰ªªÂä°‰∏≠ÔºåË∂ÖË∂ä‰∫ÜÁé∞ÊúâÊúÄ‰ºòÊñπÊ≥ï„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏Ä‰∏™Áªü‰∏ÄÁöÑÊ°ÜÊû∂ÔºåËÉΩÂ§ü‰ªéÊï£ÁÑ¶ÂíåËøêÂä®Ê®°Á≥äÁöÑÂçïÁõÆËßÜÈ¢ë‰∏≠ÁîüÊàêÈ´òË¥®ÈáèÁöÑÂä®ÊÄÅÈ´òÊñØÊ∫ÖÂ∞Ñ„ÄÇÁî±‰∫éÊï£ÁÑ¶Ê®°Á≥äÂíåËøêÂä®Ê®°Á≥äÁöÑÂΩ¢ÊàêËøáÁ®ãÂ≠òÂú®ÊòæËëóÂ∑ÆÂºÇÔºåÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏ÈíàÂØπÂÖ∂‰∏≠‰∏ÄÁßçÊ®°Á≥äËøõË°åÂÆöÂà∂ÔºåÁº∫‰πèÂêåÊó∂Â§ÑÁêÜ‰∏§ËÄÖÁöÑËÉΩÂäõ„ÄÇËôΩÁÑ∂‰∏§ËÄÖÂèØ‰ª•ËÅîÂêàÂª∫Ê®°‰∏∫Âü∫‰∫éÊ®°Á≥äÊ†∏ÁöÑÂç∑ÁßØÔºå‰ΩÜÂáÜÁ°Æ‰º∞ËÆ°Ê®°Á≥äÊ†∏ÁöÑÂõ∫ÊúâÈöæÂ∫¶ÊûÅÂ§ßÂú∞ÈôêÂà∂‰∫ÜËØ•ÊñπÂêëÁöÑËøõÂ±ï„ÄÇÊú¨ÊñáÂú®Ê≠§ÊñπÂêë‰∏äÊõ¥Ëøõ‰∏ÄÊ≠•ÔºåÁâπÂà´Âú∞ÔºåÊàë‰ª¨ÊèêÂá∫‰ΩøÁî®Ê®°Á≥äÈ¢ÑÊµãÁΩëÁªúÊù•‰º∞ËÆ°ÊØè‰∏™ÂÉèÁ¥†ÁöÑÂèØÈù†Ê®°Á≥äÊ†∏ÔºåËØ•ÁΩëÁªúÂà©Áî®‰∏éÊ®°Á≥äÁõ∏ÂÖ≥ÁöÑÂú∫ÊôØÂíåÁõ∏Êú∫‰ø°ÊÅØÔºåÂπ∂ÂèóÂà∞Ê®°Á≥äÊÑüÁü•Á®ÄÁñèÊÄßÁ∫¶Êùü„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏ÄÁßçÂä®ÊÄÅÈ´òÊñØËá¥ÂØÜÂåñÁ≠ñÁï•Ôºå‰ª•ÁºìËß£‰∏çÂÆåÊï¥Âå∫ÂüüÈ´òÊñØ‰∏çË∂≥ÁöÑÈóÆÈ¢òÔºåÂπ∂ÈÄöËøáÁªìÂêàÊú™ËßÅËßÜËßí‰ø°ÊÅØÊù•Á∫¶ÊùüÂú∫ÊôØ‰ºòÂåñÔºå‰ªéËÄåÊèêÈ´òÊñ∞ËßÜËßíÂêàÊàêÁöÑÊÄßËÉΩ„ÄÇÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®‰ªéÊï£ÁÑ¶ÂíåËøêÂä®Ê®°Á≥äÁöÑÂçïÁõÆËßÜÈ¢ë‰∏≠ÁîüÊàêÈÄºÁúüÁöÑÊñ∞ËßÜËßíÂêàÊàêÊñπÈù¢‰ºò‰∫éÊúÄÂÖàËøõÁöÑÊñπÊ≥ï„ÄÇ‰ª£Á†ÅÂ∑≤ÂºÄÊ∫ê„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥‰ªéÊï£ÁÑ¶ÂíåËøêÂä®Ê®°Á≥äÁöÑÂçïÁõÆËßÜÈ¢ë‰∏≠ËøõË°åÈ´òË¥®ÈáèÂä®ÊÄÅÈ´òÊñØÊ∫ÖÂ∞ÑÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏Âè™ËÉΩÂ§ÑÁêÜÂçï‰∏ÄÁ±ªÂûãÁöÑÊ®°Á≥äÔºåÊó†Ê≥ïÂêåÊó∂Â∫îÂØπÊï£ÁÑ¶ÂíåËøêÂä®Ê®°Á≥äÔºåÊàñËÄÖ‰æùËµñ‰∫é‰∏çÂáÜÁ°ÆÁöÑÊ®°Á≥äÊ†∏‰º∞ËÆ°ÔºåÂØºËá¥Êñ∞ËßÜËßíÂêàÊàêË¥®Èáè‰∏ãÈôç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®‰∏Ä‰∏™Ê®°Á≥äÈ¢ÑÊµãÁΩëÁªúÊù•‰º∞ËÆ°ÊØè‰∏™ÂÉèÁ¥†ÁöÑÂèØÈù†Ê®°Á≥äÊ†∏ÔºåËØ•ÁΩëÁªúËÉΩÂ§üÂà©Áî®Âú∫ÊôØÂíåÁõ∏Êú∫‰ø°ÊÅØÔºåÂπ∂ÂèóÂà∞Ê®°Á≥äÊÑüÁü•Á®ÄÁñèÊÄßÁ∫¶Êùü„ÄÇÂêåÊó∂ÔºåÂºïÂÖ•Âä®ÊÄÅÈ´òÊñØËá¥ÂØÜÂåñÁ≠ñÁï•Êù•Ë°•ÂÖÖ‰∏çÂÆåÊï¥Âå∫ÂüüÁöÑÈ´òÊñØÂàÜÂ∏ÉÔºåÂπ∂Âà©Áî®Êú™ËßÅËßÜËßíÁöÑ‰ø°ÊÅØÊù•Á∫¶ÊùüÂú∫ÊôØ‰ºòÂåñÔºå‰ªéËÄåÊèêÂçáÊñ∞ËßÜËßíÂêàÊàêÁöÑË¥®Èáè„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•Ê°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Ê®°ÂùóÔºö1) Ê®°Á≥äÈ¢ÑÊµãÁΩëÁªúÔºöÁî®‰∫é‰º∞ËÆ°ÊØè‰∏™ÂÉèÁ¥†ÁöÑÊ®°Á≥äÊ†∏Ôºõ2) Âä®ÊÄÅÈ´òÊñØÊ∫ÖÂ∞ÑÔºöÂà©Áî®È´òÊñØÂàÜÂ∏ÉË°®Á§∫Âú∫ÊôØÔºåÂπ∂ËøõË°åÂä®ÊÄÅÊõ¥Êñ∞Ôºõ3) Âä®ÊÄÅÈ´òÊñØËá¥ÂØÜÂåñÔºöÁî®‰∫éË°•ÂÖÖ‰∏çÂÆåÊï¥Âå∫ÂüüÁöÑÈ´òÊñØÂàÜÂ∏ÉÔºõ4) Êñ∞ËßÜËßíÂêàÊàêÔºöÂà©Áî®Ê∏≤ÊüìÊäÄÊúØÁîüÊàêÊñ∞ÁöÑËßÜËßíÂõæÂÉè„ÄÇÊï¥‰ΩìÊµÅÁ®ãÊòØÔºåÈ¶ñÂÖàÂà©Áî®Ê®°Á≥äÈ¢ÑÊµãÁΩëÁªú‰º∞ËÆ°Ê®°Á≥äÊ†∏ÔºåÁÑ∂ÂêéÂà©Áî®Ê®°Á≥äÊ†∏ÂíåËßÜÈ¢ëÂ∏ßËøõË°åÂä®ÊÄÅÈ´òÊñØÊ∫ÖÂ∞ÑÔºåÊé•ÁùÄËøõË°åÂä®ÊÄÅÈ´òÊñØËá¥ÂØÜÂåñÔºåÊúÄÂêéËøõË°åÊñ∞ËßÜËßíÂêàÊàê„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÊèêÂá∫‰∫Ü‰∏Ä‰∏™ËÉΩÂ§ü‰º∞ËÆ°ÊØè‰∏™ÂÉèÁ¥†ÂèØÈù†Ê®°Á≥äÊ†∏ÁöÑÊ®°Á≥äÈ¢ÑÊµãÁΩëÁªúÔºåËØ•ÁΩëÁªúËÉΩÂ§üÂêåÊó∂Âà©Áî®Âú∫ÊôØÂíåÁõ∏Êú∫‰ø°ÊÅØÔºåÂπ∂ÂèóÂà∞Ê®°Á≥äÊÑüÁü•Á®ÄÁñèÊÄßÁ∫¶Êùü„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÊõ¥ÂáÜÁ°ÆÂú∞‰º∞ËÆ°Ê®°Á≥äÊ†∏Ôºå‰ªéËÄåÊèêÂçáÊñ∞ËßÜËßíÂêàÊàêÁöÑË¥®Èáè„ÄÇÊ≠§Â§ñÔºåÂä®ÊÄÅÈ´òÊñØËá¥ÂØÜÂåñÁ≠ñÁï•ÂíåÊú™ËßÅËßÜËßí‰ø°ÊÅØÁ∫¶Êùü‰πüÊèêÂçá‰∫ÜÊ∏≤ÊüìÊïàÊûú„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÊ®°Á≥äÈ¢ÑÊµãÁΩëÁªúÁöÑËÆæËÆ°ÁªÜËäÇÊú™Áü•Ôºå‰ΩÜÂº∫Ë∞É‰∫ÜÂà©Áî®Âú∫ÊôØÂíåÁõ∏Êú∫‰ø°ÊÅØÔºåÂπ∂ÊñΩÂä†Ê®°Á≥äÊÑüÁü•Á®ÄÁñèÊÄßÁ∫¶Êùü„ÄÇÂä®ÊÄÅÈ´òÊñØËá¥ÂØÜÂåñÁ≠ñÁï•ÁöÑÂÖ∑‰ΩìÂÆûÁé∞ÊñπÂºèÊú™Áü•„ÄÇÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°‰πüÊú™Áü•Ôºå‰ΩÜÊé®Êµã‰ºöÂåÖÂê´Ê∏≤ÊüìÊçüÂ§±„ÄÅÊ®°Á≥äÊ†∏‰º∞ËÆ°ÊçüÂ§±Á≠â„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ËØ•ÊñπÊ≥ïÂú®Êï£ÁÑ¶ÂíåËøêÂä®Ê®°Á≥äÁöÑÂçïÁõÆËßÜÈ¢ëÊñ∞ËßÜËßíÂêàÊàê‰ªªÂä°‰∏≠ÔºåÂèñÂæó‰∫Ü‰ºò‰∫éÁé∞ÊúâÊúÄ‰ºòÊñπÊ≥ïÁöÑÁªìÊûú„ÄÇÂÖ∑‰ΩìÊÄßËÉΩÊï∞ÊçÆÂíåÂØπÊØîÂü∫Á∫øÊú™Áü•Ôºå‰ΩÜËÆ∫ÊñáÂº∫Ë∞É‰∫ÜÂú®ÁîüÊàêÈÄºÁúüÊñ∞ËßÜËßíÂêàÊàêÊñπÈù¢ÁöÑÊòæËëóÊèêÂçá„ÄÇ‰ª£Á†ÅÂ∑≤ÂºÄÊ∫êÔºåÊñπ‰æøÂ§çÁé∞ÂíåËøõ‰∏ÄÊ≠•Á†îÁ©∂„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éËôöÊãüÁé∞ÂÆû„ÄÅÂ¢ûÂº∫Áé∞ÂÆû„ÄÅÊú∫Âô®‰∫∫ÂØºËà™„ÄÅËá™Âä®È©æÈ©∂Á≠âÈ¢ÜÂüü„ÄÇÈÄöËøá‰ªéÊ®°Á≥äËßÜÈ¢ë‰∏≠ÈáçÂª∫È´òË¥®ÈáèÁöÑ3DÂú∫ÊôØÔºåÂèØ‰ª•ÊèêÂçáÁî®Êà∑‰ΩìÈ™åÔºåÂ¢ûÂº∫Êú∫Âô®‰∫∫ÁöÑÁéØÂ¢ÉÊÑüÁü•ËÉΩÂäõÔºåÂπ∂ÊèêÈ´òËá™Âä®È©æÈ©∂Á≥ªÁªüÁöÑÂÆâÂÖ®ÊÄß„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> This paper presents a unified framework that allows high-quality dynamic Gaussian Splatting from both defocused and motion-blurred monocular videos. Due to the significant difference between the formation processes of defocus blur and motion blur, existing methods are tailored for either one of them, lacking the ability to simultaneously deal with both of them. Although the two can be jointly modeled as blur kernel-based convolution, the inherent difficulty in estimating accurate blur kernels greatly limits the progress in this direction. In this work, we go a step further towards this direction. Particularly, we propose to estimate per-pixel reliable blur kernels using a blur prediction network that exploits blur-related scene and camera information and is subject to a blur-aware sparsity constraint. Besides, we introduce a dynamic Gaussian densification strategy to mitigate the lack of Gaussians for incomplete regions, and boost the performance of novel view synthesis by incorporating unseen view information to constrain scene optimization. Extensive experiments show that our method outperforms the state-of-the-art methods in generating photorealistic novel view synthesis from defocused and motion-blurred monocular videos. Our code is available at https://github.com/hhhddddddd/dydeblur.

