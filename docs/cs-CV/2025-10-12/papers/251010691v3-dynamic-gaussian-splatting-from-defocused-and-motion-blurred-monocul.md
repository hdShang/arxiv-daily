---
layout: default
title: Dynamic Gaussian Splatting from Defocused and Motion-blurred Monocular Videos
---

# Dynamic Gaussian Splatting from Defocused and Motion-blurred Monocular Videos

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.10691" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.10691v3</a>
  <a href="https://arxiv.org/pdf/2510.10691.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.10691v3" onclick="toggleFavorite(this, '2510.10691v3', 'Dynamic Gaussian Splatting from Defocused and Motion-blurred Monocular Videos')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xuankai Zhang, Junjin Xiao, Qing Zhang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-12 (æ›´æ–°: 2025-10-31)

**å¤‡æ³¨**: Accepted to NeurIPS 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/hhhddddddd/dydeblur)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŠ¨æ€é«˜æ–¯æº…å°„æ¡†æ¶ï¼Œè§£å†³æ•£ç„¦å’Œè¿åŠ¨æ¨¡ç³Šè§†é¢‘çš„æ–°è§†è§’åˆæˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `åŠ¨æ€é«˜æ–¯æº…å°„` `æ–°è§†è§’åˆæˆ` `æ•£ç„¦æ¨¡ç³Š` `è¿åŠ¨æ¨¡ç³Š` `æ¨¡ç³Šæ ¸ä¼°è®¡` `å•ç›®è§†é¢‘` `åŠ¨æ€åœºæ™¯é‡å»º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•éš¾ä»¥åŒæ—¶å¤„ç†æ•£ç„¦å’Œè¿åŠ¨æ¨¡ç³Šï¼Œé™åˆ¶äº†ä»æ¨¡ç³Šè§†é¢‘ä¸­è¿›è¡Œé«˜è´¨é‡æ–°è§†è§’åˆæˆçš„èƒ½åŠ›ã€‚
2. æå‡ºä¸€ç§åŸºäºæ¨¡ç³Šé¢„æµ‹ç½‘ç»œçš„åƒç´ çº§å¯é æ¨¡ç³Šæ ¸ä¼°è®¡æ–¹æ³•ï¼Œå¹¶ç»“åˆåŠ¨æ€é«˜æ–¯è‡´å¯†åŒ–ç­–ç•¥ï¼Œæå‡æ¸²æŸ“è´¨é‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ•£ç„¦å’Œè¿åŠ¨æ¨¡ç³Šè§†é¢‘çš„æ–°è§†è§’åˆæˆä»»åŠ¡ä¸­ï¼Œè¶…è¶Šäº†ç°æœ‰æœ€ä¼˜æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ï¼Œèƒ½å¤Ÿä»æ•£ç„¦å’Œè¿åŠ¨æ¨¡ç³Šçš„å•ç›®è§†é¢‘ä¸­ç”Ÿæˆé«˜è´¨é‡çš„åŠ¨æ€é«˜æ–¯æº…å°„ã€‚ç”±äºæ•£ç„¦æ¨¡ç³Šå’Œè¿åŠ¨æ¨¡ç³Šçš„å½¢æˆè¿‡ç¨‹å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œç°æœ‰æ–¹æ³•é€šå¸¸é’ˆå¯¹å…¶ä¸­ä¸€ç§æ¨¡ç³Šè¿›è¡Œå®šåˆ¶ï¼Œç¼ºä¹åŒæ—¶å¤„ç†ä¸¤è€…çš„èƒ½åŠ›ã€‚è™½ç„¶ä¸¤è€…å¯ä»¥è”åˆå»ºæ¨¡ä¸ºåŸºäºæ¨¡ç³Šæ ¸çš„å·ç§¯ï¼Œä½†å‡†ç¡®ä¼°è®¡æ¨¡ç³Šæ ¸çš„å›ºæœ‰éš¾åº¦æå¤§åœ°é™åˆ¶äº†è¯¥æ–¹å‘çš„è¿›å±•ã€‚æœ¬æ–‡åœ¨æ­¤æ–¹å‘ä¸Šæ›´è¿›ä¸€æ­¥ï¼Œç‰¹åˆ«åœ°ï¼Œæˆ‘ä»¬æå‡ºä½¿ç”¨æ¨¡ç³Šé¢„æµ‹ç½‘ç»œæ¥ä¼°è®¡æ¯ä¸ªåƒç´ çš„å¯é æ¨¡ç³Šæ ¸ï¼Œè¯¥ç½‘ç»œåˆ©ç”¨ä¸æ¨¡ç³Šç›¸å…³çš„åœºæ™¯å’Œç›¸æœºä¿¡æ¯ï¼Œå¹¶å—åˆ°æ¨¡ç³Šæ„ŸçŸ¥ç¨€ç–æ€§çº¦æŸã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åŠ¨æ€é«˜æ–¯è‡´å¯†åŒ–ç­–ç•¥ï¼Œä»¥ç¼“è§£ä¸å®Œæ•´åŒºåŸŸé«˜æ–¯ä¸è¶³çš„é—®é¢˜ï¼Œå¹¶é€šè¿‡ç»“åˆæœªè§è§†è§’ä¿¡æ¯æ¥çº¦æŸåœºæ™¯ä¼˜åŒ–ï¼Œä»è€Œæé«˜æ–°è§†è§’åˆæˆçš„æ€§èƒ½ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä»æ•£ç„¦å’Œè¿åŠ¨æ¨¡ç³Šçš„å•ç›®è§†é¢‘ä¸­ç”Ÿæˆé€¼çœŸçš„æ–°è§†è§’åˆæˆæ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚ä»£ç å·²å¼€æºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ä»æ•£ç„¦å’Œè¿åŠ¨æ¨¡ç³Šçš„å•ç›®è§†é¢‘ä¸­è¿›è¡Œé«˜è´¨é‡åŠ¨æ€é«˜æ–¯æº…å°„çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸åªèƒ½å¤„ç†å•ä¸€ç±»å‹çš„æ¨¡ç³Šï¼Œæ— æ³•åŒæ—¶åº”å¯¹æ•£ç„¦å’Œè¿åŠ¨æ¨¡ç³Šï¼Œæˆ–è€…ä¾èµ–äºä¸å‡†ç¡®çš„æ¨¡ç³Šæ ¸ä¼°è®¡ï¼Œå¯¼è‡´æ–°è§†è§’åˆæˆè´¨é‡ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨ä¸€ä¸ªæ¨¡ç³Šé¢„æµ‹ç½‘ç»œæ¥ä¼°è®¡æ¯ä¸ªåƒç´ çš„å¯é æ¨¡ç³Šæ ¸ï¼Œè¯¥ç½‘ç»œèƒ½å¤Ÿåˆ©ç”¨åœºæ™¯å’Œç›¸æœºä¿¡æ¯ï¼Œå¹¶å—åˆ°æ¨¡ç³Šæ„ŸçŸ¥ç¨€ç–æ€§çº¦æŸã€‚åŒæ—¶ï¼Œå¼•å…¥åŠ¨æ€é«˜æ–¯è‡´å¯†åŒ–ç­–ç•¥æ¥è¡¥å……ä¸å®Œæ•´åŒºåŸŸçš„é«˜æ–¯åˆ†å¸ƒï¼Œå¹¶åˆ©ç”¨æœªè§è§†è§’çš„ä¿¡æ¯æ¥çº¦æŸåœºæ™¯ä¼˜åŒ–ï¼Œä»è€Œæå‡æ–°è§†è§’åˆæˆçš„è´¨é‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) æ¨¡ç³Šé¢„æµ‹ç½‘ç»œï¼šç”¨äºä¼°è®¡æ¯ä¸ªåƒç´ çš„æ¨¡ç³Šæ ¸ï¼›2) åŠ¨æ€é«˜æ–¯æº…å°„ï¼šåˆ©ç”¨é«˜æ–¯åˆ†å¸ƒè¡¨ç¤ºåœºæ™¯ï¼Œå¹¶è¿›è¡ŒåŠ¨æ€æ›´æ–°ï¼›3) åŠ¨æ€é«˜æ–¯è‡´å¯†åŒ–ï¼šç”¨äºè¡¥å……ä¸å®Œæ•´åŒºåŸŸçš„é«˜æ–¯åˆ†å¸ƒï¼›4) æ–°è§†è§’åˆæˆï¼šåˆ©ç”¨æ¸²æŸ“æŠ€æœ¯ç”Ÿæˆæ–°çš„è§†è§’å›¾åƒã€‚æ•´ä½“æµç¨‹æ˜¯ï¼Œé¦–å…ˆåˆ©ç”¨æ¨¡ç³Šé¢„æµ‹ç½‘ç»œä¼°è®¡æ¨¡ç³Šæ ¸ï¼Œç„¶ååˆ©ç”¨æ¨¡ç³Šæ ¸å’Œè§†é¢‘å¸§è¿›è¡ŒåŠ¨æ€é«˜æ–¯æº…å°„ï¼Œæ¥ç€è¿›è¡ŒåŠ¨æ€é«˜æ–¯è‡´å¯†åŒ–ï¼Œæœ€åè¿›è¡Œæ–°è§†è§’åˆæˆã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ä¸€ä¸ªèƒ½å¤Ÿä¼°è®¡æ¯ä¸ªåƒç´ å¯é æ¨¡ç³Šæ ¸çš„æ¨¡ç³Šé¢„æµ‹ç½‘ç»œï¼Œè¯¥ç½‘ç»œèƒ½å¤ŸåŒæ—¶åˆ©ç”¨åœºæ™¯å’Œç›¸æœºä¿¡æ¯ï¼Œå¹¶å—åˆ°æ¨¡ç³Šæ„ŸçŸ¥ç¨€ç–æ€§çº¦æŸã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´å‡†ç¡®åœ°ä¼°è®¡æ¨¡ç³Šæ ¸ï¼Œä»è€Œæå‡æ–°è§†è§’åˆæˆçš„è´¨é‡ã€‚æ­¤å¤–ï¼ŒåŠ¨æ€é«˜æ–¯è‡´å¯†åŒ–ç­–ç•¥å’Œæœªè§è§†è§’ä¿¡æ¯çº¦æŸä¹Ÿæå‡äº†æ¸²æŸ“æ•ˆæœã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡ç³Šé¢„æµ‹ç½‘ç»œçš„è®¾è®¡ç»†èŠ‚æœªçŸ¥ï¼Œä½†å¼ºè°ƒäº†åˆ©ç”¨åœºæ™¯å’Œç›¸æœºä¿¡æ¯ï¼Œå¹¶æ–½åŠ æ¨¡ç³Šæ„ŸçŸ¥ç¨€ç–æ€§çº¦æŸã€‚åŠ¨æ€é«˜æ–¯è‡´å¯†åŒ–ç­–ç•¥çš„å…·ä½“å®ç°æ–¹å¼æœªçŸ¥ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡ä¹ŸæœªçŸ¥ï¼Œä½†æ¨æµ‹ä¼šåŒ…å«æ¸²æŸ“æŸå¤±ã€æ¨¡ç³Šæ ¸ä¼°è®¡æŸå¤±ç­‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥æ–¹æ³•åœ¨æ•£ç„¦å’Œè¿åŠ¨æ¨¡ç³Šçš„å•ç›®è§†é¢‘æ–°è§†è§’åˆæˆä»»åŠ¡ä¸­ï¼Œå–å¾—äº†ä¼˜äºç°æœ‰æœ€ä¼˜æ–¹æ³•çš„ç»“æœã€‚å…·ä½“æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿æœªçŸ¥ï¼Œä½†è®ºæ–‡å¼ºè°ƒäº†åœ¨ç”Ÿæˆé€¼çœŸæ–°è§†è§’åˆæˆæ–¹é¢çš„æ˜¾è‘—æå‡ã€‚ä»£ç å·²å¼€æºï¼Œæ–¹ä¾¿å¤ç°å’Œè¿›ä¸€æ­¥ç ”ç©¶ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ã€æœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸã€‚é€šè¿‡ä»æ¨¡ç³Šè§†é¢‘ä¸­é‡å»ºé«˜è´¨é‡çš„3Dåœºæ™¯ï¼Œå¯ä»¥æå‡ç”¨æˆ·ä½“éªŒï¼Œå¢å¼ºæœºå™¨äººçš„ç¯å¢ƒæ„ŸçŸ¥èƒ½åŠ›ï¼Œå¹¶æé«˜è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„å®‰å…¨æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper presents a unified framework that allows high-quality dynamic Gaussian Splatting from both defocused and motion-blurred monocular videos. Due to the significant difference between the formation processes of defocus blur and motion blur, existing methods are tailored for either one of them, lacking the ability to simultaneously deal with both of them. Although the two can be jointly modeled as blur kernel-based convolution, the inherent difficulty in estimating accurate blur kernels greatly limits the progress in this direction. In this work, we go a step further towards this direction. Particularly, we propose to estimate per-pixel reliable blur kernels using a blur prediction network that exploits blur-related scene and camera information and is subject to a blur-aware sparsity constraint. Besides, we introduce a dynamic Gaussian densification strategy to mitigate the lack of Gaussians for incomplete regions, and boost the performance of novel view synthesis by incorporating unseen view information to constrain scene optimization. Extensive experiments show that our method outperforms the state-of-the-art methods in generating photorealistic novel view synthesis from defocused and motion-blurred monocular videos. Our code is available at https://github.com/hhhddddddd/dydeblur.

