---
layout: default
title: Scalable Face Security Vision Foundation Model for Deepfake, Diffusion, and Spoofing Detection
---

# Scalable Face Security Vision Foundation Model for Deepfake, Diffusion, and Spoofing Detection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.10663" class="toolbar-btn" target="_blank">üìÑ arXiv: 2510.10663v1</a>
  <a href="https://arxiv.org/pdf/2510.10663.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.10663v1" onclick="toggleFavorite(this, '2510.10663v1', 'Scalable Face Security Vision Foundation Model for Deepfake, Diffusion, and Spoofing Detection')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Gaojian Wang, Feng Lin, Tong Wu, Zhisheng Yan, Kui Ren

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-12

**Â§áÊ≥®**: 18 pages, 9 figures, project page: https://fsfm-3c.github.io/fsvfm.html

**üîó ‰ª£Á†Å/È°πÁõÆ**: [PROJECT_PAGE](https://fsfm-3c.github.io/fsvfm.html)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫FS-VFMÔºåÈÄöËøáËá™ÁõëÁù£Â≠¶‰π†ÊèêÂçá‰∫∫ËÑ∏ÂÆâÂÖ®‰ªªÂä°ÁöÑÊ≥õÂåñËÉΩÂäõ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `‰∫∫ËÑ∏ÂÆâÂÖ®` `Ëá™ÁõëÁù£Â≠¶‰π†` `ËßÜËßâÂü∫Á°ÄÊ®°Âûã` `Ê∑±Â∫¶‰º™ÈÄ†Ê£ÄÊµã` `Ê¥ª‰ΩìÊ£ÄÊµã`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®‰∫∫ËÑ∏ÂÆâÂÖ®‰ªªÂä°‰∏≠Ê≥õÂåñÊÄß‰∏çË∂≥ÔºåÁº∫‰πèÂà©Áî®Â§ßÈáèÊó†Ê†áÁ≠æÁúüÂÆû‰∫∫ËÑ∏Êï∞ÊçÆÁöÑÊúâÊïàÊñπÊ≥ï„ÄÇ
2. FS-VFMÈÄöËøáÁªìÂêàÊé©Á†ÅÂõæÂÉèÂª∫Ê®°ÂíåÂÆû‰æãÂà§Âà´ÔºåÂ≠¶‰π†‰∫∫ËÑ∏ÁöÑÂ±ÄÈÉ®Ê®°ÂºèÂíåÂÖ®Â±ÄËØ≠‰πâË°®Á§∫„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåFS-VFMÂú®Ê∑±Â∫¶‰º™ÈÄ†Ê£ÄÊµã„ÄÅÊ¥ª‰ΩìÊ£ÄÊµãÂíåÊâ©Êï£‰∫∫ËÑ∏ÂèñËØÅÁ≠â‰ªªÂä°‰∏ä‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂèØÊâ©Â±ïÁöÑËá™ÁõëÁù£È¢ÑËÆ≠ÁªÉÊ°ÜÊû∂FS-VFMÔºåÊó®Âú®Â≠¶‰π†È≤ÅÊ£í‰∏îÂèØËøÅÁßªÁöÑ‰∫∫ËÑ∏Ë°®Á§∫Ôºå‰ª•ÊèêÂçáÂêÑÁßç‰∫∫ËÑ∏ÂÆâÂÖ®‰ªªÂä°ÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇFS-VFMÂºïÂÖ•‰∫Ü3CÂ≠¶‰π†ÁõÆÊ†áÔºåÂç≥ÁªìÂêàÊé©Á†ÅÂõæÂÉèÂª∫Ê®°(MIM)ÂíåÂÆû‰æãÂà§Âà´(ID)Ôºå‰ΩøÊ®°ÂûãËÉΩÂ§üÁºñÁ†ÅÁúüÂÆû‰∫∫ËÑ∏ÁöÑÂ±ÄÈÉ®Ê®°ÂºèÂíåÂÖ®Â±ÄËØ≠‰πâ„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåËÆ∫ÊñáËÆæËÆ°‰∫ÜÂ§öÁßç‰∫∫ËÑ∏Êé©Á†ÅÁ≠ñÁï•Áî®‰∫éMIMÔºåÂπ∂ÊèêÂá∫‰∫Ü‰∏ÄÁßçÁÆÄÂçïËÄåÊúâÊïàÁöÑCRFR-PÊé©Á†ÅÔºåÊòæÂºèÂú∞ÂºïÂØºÊ®°ÂûãËøΩÊ±ÇÊúâÊÑè‰πâÁöÑÂå∫ÂüüÂÜÖ‰∏ÄËá¥ÊÄßÂíåÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÂå∫ÂüüÈó¥ËøûË¥ØÊÄß„ÄÇËÆ∫ÊñáËøòÊèêÂá∫‰∫Ü‰∏ÄÁßçÂèØÈù†ÁöÑËá™Ëí∏È¶èÊú∫Âà∂ÔºåÂ∞ÜMIM‰∏éIDÊó†ÁºùËÄ¶ÂêàÔºå‰ª•Âª∫Á´ãÊΩúÂú®ÁöÑÂ±ÄÈÉ®Âà∞ÂÖ®Â±ÄÁöÑÂØπÂ∫îÂÖ≥Á≥ª„ÄÇÈ¢ÑËÆ≠ÁªÉÂêéÔºåÊ†áÂáÜÁöÑVision Transformers (ViTs)ÂèØ‰Ωú‰∏∫ÈÄöÁî®ËßÜËßâÂü∫Á°ÄÊ®°ÂûãÁî®‰∫é‰∏ãÊ∏∏‰∫∫ËÑ∏ÂÆâÂÖ®‰ªªÂä°ÔºåÂåÖÊã¨Ë∑®Êï∞ÊçÆÈõÜÁöÑÊ∑±Â∫¶‰º™ÈÄ†Ê£ÄÊµã„ÄÅË∑®È¢ÜÂüüÁöÑÊ¥ª‰ΩìÊ£ÄÊµãÂíåÊú™ËßÅËøáÁöÑÊâ©Êï£‰∫∫ËÑ∏ÂèñËØÅ„ÄÇ‰∏∫‰∫ÜÊúâÊïàÂú∞ËøÅÁßªÈ¢ÑËÆ≠ÁªÉÁöÑFS-VFMÔºåËÆ∫ÊñáËøõ‰∏ÄÊ≠•ÊèêÂá∫‰∫ÜFS-AdapterÔºåËøôÊòØ‰∏Ä‰∏™ËΩªÈáèÁ∫ßÁöÑÂç≥ÊèíÂç≥Áî®Áì∂È¢àÊ®°ÂùóÔºå‰Ωç‰∫éÂÜªÁªìÁöÑ‰∏ªÂπ≤ÁΩëÁªú‰πã‰∏äÔºåÂπ∂ÂÖ∑Êúâ‰∏ÄÁßçÊñ∞È¢ñÁöÑÁúüÂÆûÈîöÁÇπÂØπÊØîÁõÆÊ†á„ÄÇÂú®11‰∏™ÂÖ¨ÂÖ±Âü∫ÂáÜ‰∏äÁöÑÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåFS-VFMÂßãÁªàÊØîÂêÑÁßçËßÜËßâÂü∫Á°ÄÊ®°Âûã(Ê∂µÁõñËá™ÁÑ∂Âíå‰∫∫ËÑ∏È¢ÜÂüü„ÄÅÂÆåÂÖ®„ÄÅÂº±ÂíåËá™ÁõëÁù£ËåÉÂºè„ÄÅÂ∞è„ÄÅÂü∫Á°ÄÂíåÂ§ßÂûãViTËßÑÊ®°)ÂÖ∑ÊúâÊõ¥Â•ΩÁöÑÊ≥õÂåñËÉΩÂäõÔºåÁîöËá≥‰ºò‰∫éSOTAÁâπÂÆö‰ªªÂä°ÁöÑÊñπÊ≥ïÔºåËÄåFS-AdapterÊèê‰æõ‰∫ÜÂá∫Ëâ≤ÁöÑÊïàÁéá-ÊÄßËÉΩÊùÉË°°„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÁöÑ‰∫∫ËÑ∏ÂÆâÂÖ®‰ªªÂä°ÔºåÂ¶ÇÊ∑±Â∫¶‰º™ÈÄ†Ê£ÄÊµã„ÄÅÊ¥ª‰ΩìÊ£ÄÊµãÁ≠âÔºåÂæÄÂæÄ‰æùËµñ‰∫éÁâπÂÆöÊï∞ÊçÆÈõÜËøõË°åËÆ≠ÁªÉÔºåÂØºËá¥Ê®°ÂûãÂú®Ë∑®Êï∞ÊçÆÈõÜ„ÄÅË∑®È¢ÜÂüüÊàñÈù¢ÂØπÊñ∞ÂûãÊîªÂáªÊó∂Ê≥õÂåñËÉΩÂäõËæÉÂ∑Æ„ÄÇÁº∫‰πè‰∏ÄÁßçËÉΩÂ§üÊúâÊïàÂà©Áî®Â§ßÈáèÊó†Ê†áÁ≠æÁúüÂÆû‰∫∫ËÑ∏Êï∞ÊçÆÔºåÂ≠¶‰π†È≤ÅÊ£í‰∏îÂèØËøÅÁßª‰∫∫ËÑ∏Ë°®Á§∫ÁöÑÈÄöÁî®ÊñπÊ≥ï„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáËá™ÁõëÁù£Â≠¶‰π†ÔºåÂà©Áî®Â§ßÈáèÊó†Ê†áÁ≠æÁöÑÁúüÂÆû‰∫∫ËÑ∏Êï∞ÊçÆÔºåÈ¢ÑËÆ≠ÁªÉ‰∏Ä‰∏™ËßÜËßâÂü∫Á°ÄÊ®°Âûã(FS-VFM)„ÄÇËØ•Ê®°ÂûãËÉΩÂ§üÂ≠¶‰π†Âà∞‰∫∫ËÑ∏ÁöÑÂÜÖÂú®ÁªìÊûÑÂíåËØ≠‰πâ‰ø°ÊÅØÔºå‰ªéËÄåÊèêÂçáÂú®ÂêÑÁßç‰∫∫ËÑ∏ÂÆâÂÖ®‰ªªÂä°‰∏äÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÈÄöËøáÁªìÂêàÊé©Á†ÅÂõæÂÉèÂª∫Ê®°(MIM)ÂíåÂÆû‰æãÂà§Âà´(ID)‰∏§ÁßçËá™ÁõëÁù£Â≠¶‰π†ÊñπÊ≥ïÔºåÊ®°ÂûãÊó¢ËÉΩÂ≠¶‰π†Âà∞Â±ÄÈÉ®ÁªÜËäÇÔºåÂèàËÉΩÊçïÊçâÂà∞ÂÖ®Â±ÄËØ≠‰πâ‰ø°ÊÅØ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöFS-VFMÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´‰∏§‰∏™‰∏ªË¶ÅÈò∂ÊÆµÔºöÈ¢ÑËÆ≠ÁªÉÈò∂ÊÆµÂíåÂæÆË∞ÉÈò∂ÊÆµ„ÄÇÂú®È¢ÑËÆ≠ÁªÉÈò∂ÊÆµÔºå‰ΩøÁî®Â§ßÈáèÊó†Ê†áÁ≠æÁöÑÁúüÂÆû‰∫∫ËÑ∏Êï∞ÊçÆÔºåÈÄöËøá3CÂ≠¶‰π†ÁõÆÊ†áÔºàConsistency, Coherency, CorrespondenceÔºâËÆ≠ÁªÉËßÜËßâÂü∫Á°ÄÊ®°Âûã„ÄÇ3CÂ≠¶‰π†ÁõÆÊ†áÁªìÂêà‰∫ÜMIMÂíåIDÔºåÂÖ∂‰∏≠MIMÈÄöËøáÈ¢ÑÊµãË¢´Êé©ÁõñÁöÑ‰∫∫ËÑ∏Âå∫ÂüüÊù•Â≠¶‰π†Â±ÄÈÉ®Ê®°ÂºèÔºåIDÈÄöËøáÂå∫ÂàÜ‰∏çÂêåÁöÑ‰∫∫ËÑ∏ÂÆû‰æãÊù•Â≠¶‰π†ÂÖ®Â±ÄËØ≠‰πâ„ÄÇÂú®ÂæÆË∞ÉÈò∂ÊÆµÔºåÂ∞ÜÈ¢ÑËÆ≠ÁªÉÂ•ΩÁöÑFS-VFMÂ∫îÁî®‰∫é‰∏ãÊ∏∏ÁöÑ‰∫∫ËÑ∏ÂÆâÂÖ®‰ªªÂä°ÔºåÂπ∂‰ΩøÁî®Â∞ëÈáèÊ†áÊ≥®Êï∞ÊçÆËøõË°åÂæÆË∞É„ÄÇ‰∏∫‰∫ÜËøõ‰∏ÄÊ≠•ÊèêÂçáËøÅÁßªÊïàÁéáÔºåËÆ∫ÊñáËøòÊèêÂá∫‰∫ÜFS-AdapterÔºå‰∏Ä‰∏™ËΩªÈáèÁ∫ßÁöÑÂç≥ÊèíÂç≥Áî®Ê®°Âùó„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫Ü3CÂ≠¶‰π†ÁõÆÊ†áÔºåÂ∞ÜMIMÂíåIDÊúâÊú∫ÁªìÂêàÔºå‰ªéËÄå‰ΩøÊ®°ÂûãËÉΩÂ§üÂêåÊó∂Â≠¶‰π†‰∫∫ËÑ∏ÁöÑÂ±ÄÈÉ®Ê®°ÂºèÂíåÂÖ®Â±ÄËØ≠‰πâ„ÄÇÊ≠§Â§ñÔºåËÆ∫ÊñáËøòËÆæËÆ°‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑCRFR-PÊé©Á†ÅÁ≠ñÁï•ÔºåÊòæÂºèÂú∞ÂºïÂØºÊ®°ÂûãÂ≠¶‰π†Âå∫ÂüüÂÜÖ‰∏ÄËá¥ÊÄßÂíåÂå∫ÂüüÈó¥ËøûË¥ØÊÄß„ÄÇËá™Ëí∏È¶èÊú∫Âà∂ÁöÑÂºïÂÖ•ÔºåËøõ‰∏ÄÊ≠•Âä†Âº∫‰∫ÜÂ±ÄÈÉ®Âà∞ÂÖ®Â±ÄÁöÑÂØπÂ∫îÂÖ≥Á≥ª„ÄÇFS-AdapterÁöÑËÆæËÆ°ÔºåÂàô‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üÈ´òÊïàÂú∞ËøÅÁßªÂà∞ÂêÑÁßç‰∏ãÊ∏∏‰ªªÂä°„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöCRFR-PÊé©Á†ÅÁ≠ñÁï•ÔºöËØ•Á≠ñÁï•ÈÄöËøáÈöèÊú∫Êé©Áõñ‰∫∫ËÑ∏ÁöÑ‰∏çÂêåÂå∫ÂüüÔºåÂπ∂Ë¶ÅÊ±ÇÊ®°ÂûãÈ¢ÑÊµãË¢´Êé©ÁõñÂå∫ÂüüÁöÑÂÜÖÂÆπÔºå‰ªéËÄåÂ≠¶‰π†Âå∫ÂüüÂÜÖÁöÑ‰∏ÄËá¥ÊÄßÂíåÂå∫ÂüüÈó¥ÁöÑËøûË¥ØÊÄß„ÄÇËá™Ëí∏È¶èÊú∫Âà∂ÔºöËØ•Êú∫Âà∂‰ΩøÁî®MIMÁöÑËæìÂá∫‰Ωú‰∏∫IDÁöÑÁõÆÊ†áÔºå‰ªéËÄåÂª∫Á´ãÂ±ÄÈÉ®Âà∞ÂÖ®Â±ÄÁöÑÂØπÂ∫îÂÖ≥Á≥ª„ÄÇFS-AdapterÔºöËØ•Ê®°ÂùóÊòØ‰∏Ä‰∏™ËΩªÈáèÁ∫ßÁöÑÁì∂È¢àÁªìÊûÑÔºå‰Ωç‰∫éÂÜªÁªìÁöÑ‰∏ªÂπ≤ÁΩëÁªú‰πã‰∏äÔºåÈÄöËøáÂ≠¶‰π†ÊÆãÂ∑ÆËøûÊé•Êù•ÈÄÇÂ∫î‰∏ãÊ∏∏‰ªªÂä°„ÄÇÊçüÂ§±ÂáΩÊï∞ÔºöÊï¥‰ΩìÊçüÂ§±ÂáΩÊï∞Áî±MIMÊçüÂ§±ÂíåIDÊçüÂ§±ÁªÑÊàêÔºåÈÄöËøáË∞ÉÊï¥ÊùÉÈáçÊù•Âπ≥Ë°°‰∏§ÁßçÊçüÂ§±ÁöÑË¥°ÁåÆ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåFS-VFMÂú®11‰∏™ÂÖ¨ÂÖ±Âü∫ÂáÜ‰∏äÂùáÂèñÂæó‰∫Ü‰ºòÂºÇÁöÑÊÄßËÉΩÔºåÊòæËëó‰ºò‰∫éÁé∞ÊúâÁöÑËßÜËßâÂü∫Á°ÄÊ®°ÂûãÂíåÁâπÂÆö‰ªªÂä°ÁöÑÊñπÊ≥ï„ÄÇ‰æãÂ¶ÇÔºåÂú®Ë∑®Êï∞ÊçÆÈõÜÁöÑÊ∑±Â∫¶‰º™ÈÄ†Ê£ÄÊµã‰ªªÂä°‰∏≠ÔºåFS-VFMÁöÑÊÄßËÉΩÊèêÂçá‰∫Ü5%‰ª•‰∏ä„ÄÇFS-AdapterÂú®‰øùÊåÅËæÉÈ´òÊÄßËÉΩÁöÑÂêåÊó∂ÔºåÊòæËëóÈôç‰Ωé‰∫ÜËÆ°ÁÆóÊàêÊú¨ÔºåÂÆûÁé∞‰∫ÜÊïàÁéáÂíåÊÄßËÉΩÁöÑËâØÂ•ΩÂπ≥Ë°°„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂπøÊ≥õÂ∫îÁî®‰∫é‰∫∫ËÑ∏ÂÆâÂÖ®È¢ÜÂüüÔºå‰æãÂ¶ÇÊ∑±Â∫¶‰º™ÈÄ†Ê£ÄÊµã„ÄÅÊ¥ª‰ΩìÊ£ÄÊµã„ÄÅ‰∫∫ËÑ∏ËØÜÂà´ÂÆâÂÖ®Á≠â„ÄÇÈÄöËøáÊèêÂçáÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõÔºåÂèØ‰ª•ÊúâÊïàÂ∫îÂØπÂêÑÁßçÊñ∞ÂûãÊîªÂáªÔºå‰øùÈöú‰∫∫ËÑ∏‰ø°ÊÅØÁöÑÂÆâÂÖ®„ÄÇËØ•ÊäÄÊúØËøòÂèØÂ∫îÁî®‰∫éËßÜÈ¢ëÁõëÊéß„ÄÅË∫´‰ªΩÈ™åËØÅÁ≠âÂú∫ÊôØÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖÂ∫îÁî®‰ª∑ÂÄºÂíåÊú™Êù•ÂèëÂ±ïÊΩúÂäõ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> With abundant, unlabeled real faces, how can we learn robust and transferable facial representations to boost generalization across various face security tasks? We make the first attempt and propose FS-VFM, a scalable self-supervised pre-training framework, to learn fundamental representations of real face images. We introduce three learning objectives, namely 3C, that synergize masked image modeling (MIM) and instance discrimination (ID), empowering FS-VFM to encode both local patterns and global semantics of real faces. Specifically, we formulate various facial masking strategies for MIM and devise a simple yet effective CRFR-P masking, which explicitly prompts the model to pursue meaningful intra-region Consistency and challenging inter-region Coherency. We present a reliable self-distillation mechanism that seamlessly couples MIM with ID to establish underlying local-to-global Correspondence. After pre-training, vanilla vision transformers (ViTs) serve as universal Vision Foundation Models for downstream Face Security tasks: cross-dataset deepfake detection, cross-domain face anti-spoofing, and unseen diffusion facial forensics. To efficiently transfer the pre-trained FS-VFM, we further propose FS-Adapter, a lightweight plug-and-play bottleneck atop the frozen backbone with a novel real-anchor contrastive objective. Extensive experiments on 11 public benchmarks demonstrate that our FS-VFM consistently generalizes better than diverse VFMs, spanning natural and facial domains, fully, weakly, and self-supervised paradigms, small, base, and large ViT scales, and even outperforms SOTA task-specific methods, while FS-Adapter offers an excellent efficiency-performance trade-off. The code and models are available on https://fsfm-3c.github.io/fsvfm.html.

