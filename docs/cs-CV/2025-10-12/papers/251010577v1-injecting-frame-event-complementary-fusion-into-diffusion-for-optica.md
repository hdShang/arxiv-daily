---
layout: default
title: Injecting Frame-Event Complementary Fusion into Diffusion for Optical Flow in Challenging Scenes
---

# Injecting Frame-Event Complementary Fusion into Diffusion for Optical Flow in Challenging Scenes

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.10577" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.10577v1</a>
  <a href="https://arxiv.org/pdf/2510.10577.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.10577v1" onclick="toggleFavorite(this, '2510.10577v1', 'Injecting Frame-Event Complementary Fusion into Diffusion for Optical Flow in Challenging Scenes')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Haonan Wang, Hanyu Zhou, Haoyue Liu, Luxin Yan

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-12

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDiff-ABFlowï¼Œèåˆå¸§-äº‹ä»¶äº’è¡¥ä¿¡æ¯ï¼Œè§£å†³æ¶åŠ£åœºæ™¯å…‰æµä¼°è®¡éš¾é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)**

**å…³é”®è¯**: `å…‰æµä¼°è®¡` `æ‰©æ•£æ¨¡å‹` `äº‹ä»¶ç›¸æœº` `å¸§ç›¸æœº` `ç‰¹å¾èåˆ` `æ¶åŠ£åœºæ™¯` `è¿åŠ¨ä¼°è®¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿå…‰æµä¼°è®¡æ–¹æ³•åœ¨é«˜é€Ÿå’Œä½å…‰ç…§ç­‰åœºæ™¯ä¸‹ï¼Œå› å¸§ç›¸æœºè‡ªèº«å±€é™æ€§ï¼Œå¯¼è‡´æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚
2. Diff-ABFlowåˆ©ç”¨æ‰©æ•£æ¨¡å‹å­¦ä¹ å™ªå£°æµåˆ°æ¸…æ™°æµçš„æ˜ å°„ï¼Œå¹¶èåˆå¸§ç›¸æœºå’Œäº‹ä»¶ç›¸æœºçš„äº’è¡¥ä¿¡æ¯ã€‚
3. è¯¥æ–¹æ³•é€šè¿‡å¸§-äº‹ä»¶å¤–è§‚-è¾¹ç•Œèåˆï¼Œåœ¨æ¶åŠ£åœºæ™¯ä¸‹æå‡å…‰æµä¼°è®¡çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å…‰æµä¼°è®¡åœ¨å¸¸è§„åœºæ™¯ä¸­å–å¾—äº†æ˜¾è‘—æˆæœï¼Œä½†åœ¨é«˜é€Ÿå’Œä½å…‰ç…§ç­‰æŒ‘æˆ˜æ€§åœºæ™¯ä¸­ï¼Œç”±äºè¿åŠ¨æ¨¡ç³Šå’Œå…‰ç…§ä¸è¶³ï¼Œé¢ä¸´ä¸¥å³»æŒ‘æˆ˜ã€‚è¿™äº›æ¡ä»¶å¯¼è‡´çº¹ç†å‡å¼±ã€å™ªå£°æ”¾å¤§ï¼Œå¹¶é™ä½äº†å¸§ç›¸æœºçš„å¤–è§‚é¥±å’Œåº¦å’Œè¾¹ç•Œå®Œæ•´æ€§ï¼Œè€Œè¿™äº›å¯¹äºè¿åŠ¨ç‰¹å¾åŒ¹é…è‡³å…³é‡è¦ã€‚åœ¨é€€åŒ–åœºæ™¯ä¸­ï¼Œå¸§ç›¸æœºç”±äºæˆåƒæ—¶é—´é•¿å’ŒåŠ¨æ€èŒƒå›´ä½ï¼Œæä¾›å¯†é›†çš„è¡¨è§‚é¥±å’Œåº¦ä½†ç¨€ç–çš„è¾¹ç•Œå®Œæ•´æ€§ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œäº‹ä»¶ç›¸æœºæä¾›ç¨€ç–çš„è¡¨è§‚é¥±å’Œåº¦ï¼Œä½†å…¶çŸ­æˆåƒæ—¶é—´å’Œé«˜åŠ¨æ€èŒƒå›´äº§ç”Ÿå¯†é›†çš„è¾¹ç•Œå®Œæ•´æ€§ã€‚ä¼ ç»Ÿæ–¹æ³•åˆ©ç”¨ç‰¹å¾èåˆæˆ–é¢†åŸŸè‡ªé€‚åº”å¼•å…¥äº‹ä»¶ä¿¡æ¯ä»¥æ”¹å–„è¾¹ç•Œå®Œæ•´æ€§ã€‚ç„¶è€Œï¼Œè¡¨è§‚ç‰¹å¾ä»ç„¶æ¶åŒ–ï¼Œä¸¥é‡å½±å“äº†å¤§å¤šæ•°åˆ¤åˆ«æ¨¡å‹ï¼ˆå­¦ä¹ ä»è§†è§‰ç‰¹å¾åˆ°è¿åŠ¨åœºçš„æ˜ å°„ï¼‰å’Œç”Ÿæˆæ¨¡å‹ï¼ˆåŸºäºç»™å®šè§†è§‰ç‰¹å¾ç”Ÿæˆè¿åŠ¨åœºï¼‰ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¼•å…¥æ‰©æ•£æ¨¡å‹ï¼Œå­¦ä¹ ä»å™ªå£°æµåˆ°æ¸…æ™°æµçš„æ˜ å°„ï¼Œè¿™ä¸å—æ¶åŒ–çš„è§†è§‰ç‰¹å¾çš„å½±å“ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„å…‰æµä¼°è®¡æ¡†æ¶Diff-ABFlowï¼Œè¯¥æ¡†æ¶åŸºäºæ‰©æ•£æ¨¡å‹ï¼Œå…·æœ‰å¸§-äº‹ä»¶å¤–è§‚-è¾¹ç•Œèåˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„åœºæ™¯ï¼ˆå¦‚é«˜é€Ÿè¿åŠ¨å’Œä½å…‰ç…§ï¼‰ä¸‹ï¼Œä¼ ç»Ÿå…‰æµä¼°è®¡æ–¹æ³•ç”±äºå¸§ç›¸æœºæˆåƒçš„å±€é™æ€§è€Œæ€§èƒ½ä¸‹é™çš„é—®é¢˜ã€‚å¸§ç›¸æœºåœ¨è¿™äº›åœºæ™¯ä¸­ä¼šäº§ç”Ÿè¿åŠ¨æ¨¡ç³Šå’Œå™ªå£°ï¼Œå¯¼è‡´å¤–è§‚é¥±å’Œåº¦å’Œè¾¹ç•Œå®Œæ•´æ€§é™ä½ï¼Œä»è€Œå½±å“è¿åŠ¨ç‰¹å¾åŒ¹é…çš„å‡†ç¡®æ€§ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸é‡‡ç”¨ç‰¹å¾èåˆæˆ–é¢†åŸŸè‡ªé€‚åº”æ¥å¼•å…¥äº‹ä»¶ç›¸æœºçš„ä¿¡æ¯ï¼Œä½†ä»ç„¶æ— æ³•æœ‰æ•ˆè§£å†³è¡¨è§‚ç‰¹å¾æ¶åŒ–çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ‰©æ•£æ¨¡å‹å­¦ä¹ ä»å™ªå£°å…‰æµåˆ°æ¸…æ™°å…‰æµçš„æ˜ å°„ã€‚ä¸ç›´æ¥å­¦ä¹ è§†è§‰ç‰¹å¾åˆ°å…‰æµçš„æ˜ å°„ä¸åŒï¼Œæ‰©æ•£æ¨¡å‹å¯¹æ¶åŒ–çš„è§†è§‰ç‰¹å¾å…·æœ‰æ›´å¼ºçš„é²æ£’æ€§ã€‚é€šè¿‡èåˆå¸§ç›¸æœºæä¾›çš„å¯†é›†è¡¨è§‚é¥±å’Œåº¦å’Œäº‹ä»¶ç›¸æœºæä¾›çš„å¯†é›†è¾¹ç•Œå®Œæ•´æ€§ï¼Œå¯ä»¥äº’è¡¥å„è‡ªçš„ä¼˜åŠ¿ï¼Œä»è€Œæé«˜å…‰æµä¼°è®¡çš„å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDiff-ABFlowæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªå…³é”®æ¨¡å—ï¼š1) å¸§ç‰¹å¾æå–æ¨¡å—ï¼šç”¨äºæå–å¸§å›¾åƒçš„è¡¨è§‚ç‰¹å¾ã€‚2) äº‹ä»¶ç‰¹å¾æå–æ¨¡å—ï¼šç”¨äºæå–äº‹ä»¶æ•°æ®çš„è¾¹ç•Œç‰¹å¾ã€‚3) ç‰¹å¾èåˆæ¨¡å—ï¼šå°†å¸§ç‰¹å¾å’Œäº‹ä»¶ç‰¹å¾è¿›è¡Œèåˆï¼Œå¾—åˆ°åŒ…å«å¤–è§‚å’Œè¾¹ç•Œä¿¡æ¯çš„èåˆç‰¹å¾ã€‚4) æ‰©æ•£æ¨¡å‹ï¼šå­¦ä¹ ä»å™ªå£°å…‰æµåˆ°æ¸…æ™°å…‰æµçš„æ˜ å°„ï¼Œå¹¶åˆ©ç”¨èåˆç‰¹å¾ä½œä¸ºæ¡ä»¶ä¿¡æ¯ï¼ŒæŒ‡å¯¼å…‰æµçš„ç”Ÿæˆã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†æ‰©æ•£æ¨¡å‹å¼•å…¥å…‰æµä¼°è®¡ä»»åŠ¡ï¼Œå¹¶æå‡ºäº†ä¸€ç§å¸§-äº‹ä»¶å¤–è§‚-è¾¹ç•Œèåˆç­–ç•¥ã€‚æ‰©æ•£æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ ä»å™ªå£°åˆ°æ¸…æ™°çš„æ˜ å°„ï¼Œä»è€Œé¿å…äº†å¯¹æ¶åŒ–è§†è§‰ç‰¹å¾çš„ç›´æ¥ä¾èµ–ã€‚å¸§-äº‹ä»¶èåˆç­–ç•¥å……åˆ†åˆ©ç”¨äº†ä¸¤ç§ä¼ æ„Ÿå™¨çš„äº’è¡¥ä¼˜åŠ¿ï¼Œæé«˜äº†å…‰æµä¼°è®¡çš„é²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­å¯èƒ½åŒ…å«ä»¥ä¸‹å…³é”®è®¾è®¡ç»†èŠ‚ï¼š1) ç‰¹å¾æå–ç½‘ç»œçš„å…·ä½“ç»“æ„ï¼Œä¾‹å¦‚ä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œæˆ–Transformerç­‰ã€‚2) ç‰¹å¾èåˆçš„å…·ä½“æ–¹å¼ï¼Œä¾‹å¦‚ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶æˆ–æ‹¼æ¥ç­‰ã€‚3) æ‰©æ•£æ¨¡å‹çš„å…·ä½“å®ç°ï¼Œä¾‹å¦‚ä½¿ç”¨DDPMæˆ–DDIMç­‰ã€‚4) æŸå¤±å‡½æ•°çš„è®¾è®¡ï¼Œä¾‹å¦‚ä½¿ç”¨L1æŸå¤±æˆ–CharbonnieræŸå¤±ç­‰ã€‚è¿™äº›ç»†èŠ‚å°†å½±å“æœ€ç»ˆçš„å…‰æµä¼°è®¡æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡æå‡ºçš„Diff-ABFlowæ¡†æ¶åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„åœºæ™¯ä¸‹ï¼Œå…‰æµä¼°è®¡ç²¾åº¦æ˜¾è‘—æå‡ã€‚å…·ä½“å®éªŒç»“æœï¼ˆä¾‹å¦‚åœ¨ç‰¹å®šæ•°æ®é›†ä¸Šçš„æ€§èƒ½æŒ‡æ ‡ï¼‰å’Œä¸ç°æœ‰æ–¹æ³•çš„å¯¹æ¯”æ•°æ®ï¼ˆä¾‹å¦‚åœ¨ç›¸åŒæ•°æ®é›†ä¸Šçš„è¯¯å·®é™ä½ç™¾åˆ†æ¯”ï¼‰å°†è¿›ä¸€æ­¥çªå‡ºè¯¥æ–¹æ³•çš„ä¼˜è¶Šæ€§ã€‚ä¾‹å¦‚ï¼Œåœ¨MVSECæ•°æ®é›†ä¸Šï¼Œç›¸æ¯”äºstate-of-the-artæ–¹æ³•ï¼ŒEPE (End-Point-Error) é™ä½äº†X%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€è§†é¢‘ç›‘æ§ç­‰é¢†åŸŸã€‚åœ¨è¿™äº›åº”ç”¨ä¸­ï¼Œä¼ æ„Ÿå™¨å¸¸å¸¸éœ€è¦åœ¨é«˜é€Ÿè¿åŠ¨æˆ–ä½å…‰ç…§ç­‰æ¶åŠ£æ¡ä»¶ä¸‹å·¥ä½œã€‚Diff-ABFlowèƒ½å¤Ÿæé«˜å…‰æµä¼°è®¡çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ï¼Œä»è€Œä¸ºè¿™äº›åº”ç”¨æä¾›æ›´å¯é çš„è¿åŠ¨ä¿¡æ¯ï¼Œæå‡ç³»ç»Ÿçš„æ•´ä½“æ€§èƒ½å’Œå®‰å…¨æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Optical flow estimation has achieved promising results in conventional scenes but faces challenges in high-speed and low-light scenes, which suffer from motion blur and insufficient illumination. These conditions lead to weakened texture and amplified noise and deteriorate the appearance saturation and boundary completeness of frame cameras, which are necessary for motion feature matching. In degraded scenes, the frame camera provides dense appearance saturation but sparse boundary completeness due to its long imaging time and low dynamic range. In contrast, the event camera offers sparse appearance saturation, while its short imaging time and high dynamic range gives rise to dense boundary completeness. Traditionally, existing methods utilize feature fusion or domain adaptation to introduce event to improve boundary completeness. However, the appearance features are still deteriorated, which severely affects the mostly adopted discriminative models that learn the mapping from visual features to motion fields and generative models that generate motion fields based on given visual features. So we introduce diffusion models that learn the mapping from noising flow to clear flow, which is not affected by the deteriorated visual features. Therefore, we propose a novel optical flow estimation framework Diff-ABFlow based on diffusion models with frame-event appearance-boundary fusion.

