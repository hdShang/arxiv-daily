---
layout: default
title: "Towards Efficient 3D Gaussian Human Avatar Compression: A Prior-Guided Framework"
---

# Towards Efficient 3D Gaussian Human Avatar Compression: A Prior-Guided Framework

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.10492" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.10492v1</a>
  <a href="https://arxiv.org/pdf/2510.10492.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.10492v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.10492v1', 'Towards Efficient 3D Gaussian Human Avatar Compression: A Prior-Guided Framework')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shanzhi Yin, Bolin Chen, Xinju Wu, Ru-Ling Liao, Jie Chen, Shiqi Wang, Yan Ye

**åˆ†ç±»**: eess.IV, cs.CV, cs.MM

**å‘å¸ƒæ—¥æœŸ**: 2025-10-12

**å¤‡æ³¨**: 10 pages, 4 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§å…ˆéªŒå¼•å¯¼çš„3Dé«˜æ–¯äººä½“Avataré«˜æ•ˆå‹ç¼©æ¡†æ¶ï¼Œç”¨äºè¶…ä½ç ç‡é«˜è´¨é‡çš„å…ƒå®‡å®™åº”ç”¨ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `3Däººä½“Avatar` `é«˜æ–¯Splatting` `è§†é¢‘å‹ç¼©` `äººä½“å…ˆéªŒ` `çº¿æ€§æ··åˆè’™çš®` `å…ƒå®‡å®™` `ä½ç ç‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰3Däººä½“Avatarå‹ç¼©æ–¹æ³•åœ¨ä½ç ç‡ä¸‹éš¾ä»¥ä¿æŒé«˜è´¨é‡ï¼Œä¸”è®¡ç®—å¤æ‚åº¦é«˜ï¼Œé™åˆ¶äº†å…¶åœ¨èµ„æºå—é™åœºæ™¯çš„åº”ç”¨ã€‚
2. è¯¥è®ºæ–‡æå‡ºä¸€ç§åŸºäºäººä½“å…ˆéªŒå¼•å¯¼çš„3Dé«˜æ–¯Avatarå‹ç¼©æ¡†æ¶ï¼Œè§£è€¦å¤–è§‚å’Œè¿åŠ¨ï¼Œåˆ©ç”¨ç´§å‡‘å‚æ•°è¡¨ç¤ºå®ç°é«˜æ•ˆå‹ç¼©ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸»æµæ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿç¼–è§£ç å™¨å’Œç°æœ‰3Dé«˜æ–¯splattingå‹ç¼©æ–¹æ³•ï¼Œå®ç°äº†æ›´å¥½çš„ç‡å¤±çœŸæ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„3Däººä½“Avatarç¼–ç æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨ç´§å‡‘çš„äººä½“å…ˆéªŒå’Œè§„èŒƒåˆ°ç›®æ ‡çš„å˜æ¢ï¼Œå®ç°äº†è¶…ä½æ¯”ç‰¹ç‡ä¸‹çš„é«˜è´¨é‡3Däººä½“Avatarè§†é¢‘å‹ç¼©ã€‚è¯¥æ¡†æ¶é¦–å…ˆä»¥æ— ç½‘ç»œçš„æ–¹å¼è®­ç»ƒä¸€ä¸ªä½¿ç”¨é“°æ¥splattingçš„è§„èŒƒé«˜æ–¯Avatarï¼Œä½œä¸ºAvatarå¤–è§‚å»ºæ¨¡çš„åŸºç¡€ã€‚åŒæ—¶ï¼Œé‡‡ç”¨äººä½“å…ˆéªŒæ¨¡æ¿ï¼Œé€šè¿‡ç´§å‡‘çš„å‚æ•°åŒ–è¡¨ç¤ºæ¥æ•è·æ—¶é—´ä¸Šçš„èº«ä½“è¿åŠ¨ã€‚è¿™ç§å¤–è§‚å’Œæ—¶é—´æ¼”åŒ–çš„åˆ†è§£æœ€å¤§é™åº¦åœ°å‡å°‘äº†å†—ä½™ï¼Œä»è€Œå®ç°äº†é«˜æ•ˆçš„å‹ç¼©ï¼šè§„èŒƒAvataråœ¨æ•´ä¸ªåºåˆ—ä¸­å…±äº«ï¼Œåªéœ€è¦å‹ç¼©ä¸€æ¬¡ï¼Œè€Œæ—¶é—´å‚æ•°ï¼ˆæ¯å¸§ä»…åŒ…å«94ä¸ªå‚æ•°ï¼‰ä»¥æœ€å°çš„æ¯”ç‰¹ç‡ä¼ è¾“ã€‚å¯¹äºæ¯ä¸€å¸§ï¼Œç›®æ ‡äººä½“Avataré€šè¿‡çº¿æ€§æ··åˆè’™çš®å˜æ¢å¯¹è§„èŒƒAvatarè¿›è¡Œå˜å½¢æ¥ç”Ÿæˆï¼Œä»è€Œä¿ƒè¿›äº†æ—¶é—´ä¸Šè¿è´¯çš„è§†é¢‘é‡å»ºå’Œæ–°è§†è§’åˆæˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ä¸»æµçš„å¤šè§†è§’äººä½“è§†é¢‘æ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•åœ¨ç‡å¤±çœŸæ€§èƒ½æ–¹é¢æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„2D/3Dç¼–è§£ç å™¨å’Œç°æœ‰çš„å¯å­¦ä¹ åŠ¨æ€3Dé«˜æ–¯splattingå‹ç¼©æ–¹æ³•ï¼Œä¸ºå…ƒå®‡å®™åº”ç”¨ä¸­æ— ç¼çš„æ²‰æµ¸å¼å¤šåª’ä½“ä½“éªŒé“ºå¹³äº†é“è·¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰3Däººä½“Avatarå‹ç¼©æ–¹æ³•ï¼Œå¦‚ä¼ ç»Ÿ2D/3Dç¼–è§£ç å™¨å’ŒåŸºäºç¥ç»è¾å°„åœºçš„æ–¹æ³•ï¼Œåœ¨è¶…ä½ç ç‡ä¸‹éš¾ä»¥ä¿æŒé«˜è´¨é‡çš„æ¸²æŸ“æ•ˆæœï¼Œå¹¶ä¸”è®¡ç®—å¤æ‚åº¦è¾ƒé«˜ï¼Œéš¾ä»¥æ»¡è¶³å…ƒå®‡å®™ç­‰å®æ—¶æ€§è¦æ±‚é«˜çš„åº”ç”¨åœºæ™¯ã€‚æ­¤å¤–ï¼ŒåŠ¨æ€3Dé«˜æ–¯splattingè™½ç„¶èƒ½å®ç°é«˜è´¨é‡çš„æ¸²æŸ“ï¼Œä½†å…¶å‹ç¼©æ•ˆç‡ä»æœ‰æå‡ç©ºé—´ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè¯¥è®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†3Däººä½“Avatarçš„è¡¨ç¤ºè§£è€¦ä¸ºé™æ€çš„è§„èŒƒAvatarå¤–è§‚å’ŒåŠ¨æ€çš„èº«ä½“è¿åŠ¨ã€‚è§„èŒƒAvatarè´Ÿè´£æ•æ‰äººç‰©çš„é™æ€å¤–è§‚ä¿¡æ¯ï¼Œè€Œèº«ä½“è¿åŠ¨åˆ™é€šè¿‡ç´§å‡‘çš„å‚æ•°åŒ–äººä½“å…ˆéªŒæ¨¡æ¿è¿›è¡Œè¡¨ç¤ºã€‚é€šè¿‡è¿™ç§è§£è€¦ï¼Œå¯ä»¥é¿å…å¯¹æ¯ä¸€å¸§éƒ½è¿›è¡Œå®Œæ•´çš„3Dæ¨¡å‹å‹ç¼©ï¼Œä»è€Œå¤§å¤§é™ä½äº†ç ç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) è®­ç»ƒè§„èŒƒé«˜æ–¯Avatarï¼šä½¿ç”¨é“°æ¥splattingæ–¹æ³•è®­ç»ƒä¸€ä¸ªé™æ€çš„3Dé«˜æ–¯Avatarï¼Œä½œä¸ºäººç‰©å¤–è§‚çš„åŸºç¡€ã€‚2) äººä½“è¿åŠ¨å‚æ•°ä¼°è®¡ï¼šåˆ©ç”¨äººä½“å…ˆéªŒæ¨¡æ¿ï¼Œä¼°è®¡æ¯ä¸€å¸§çš„èº«ä½“è¿åŠ¨å‚æ•°ï¼ˆä¾‹å¦‚ï¼ŒSMPLå‚æ•°ï¼‰ã€‚3) Avatarå˜å½¢ï¼šä½¿ç”¨çº¿æ€§æ··åˆè’™çš®ï¼ˆLBSï¼‰å˜æ¢ï¼Œå°†è§„èŒƒAvataræ ¹æ®ä¼°è®¡çš„è¿åŠ¨å‚æ•°è¿›è¡Œå˜å½¢ï¼Œç”Ÿæˆç›®æ ‡Avatarã€‚4) å‹ç¼©ä¸ä¼ è¾“ï¼šå¯¹è§„èŒƒAvatarè¿›è¡Œä¸€æ¬¡æ€§å‹ç¼©ï¼Œå¹¶å¯¹æ¯ä¸€å¸§çš„è¿åŠ¨å‚æ•°è¿›è¡Œå‹ç¼©å’Œä¼ è¾“ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå°†3Dé«˜æ–¯Avatarä¸äººä½“å…ˆéªŒçŸ¥è¯†ç›¸ç»“åˆï¼Œå®ç°äº†å¤–è§‚å’Œè¿åŠ¨çš„è§£è€¦ã€‚è¿™ç§è§£è€¦ä½¿å¾—åªéœ€è¦å¯¹é™æ€çš„è§„èŒƒAvatarè¿›è¡Œä¸€æ¬¡å‹ç¼©ï¼Œè€ŒåŠ¨æ€çš„è¿åŠ¨ä¿¡æ¯åˆ™é€šè¿‡ç´§å‡‘çš„å‚æ•°åŒ–è¡¨ç¤ºè¿›è¡Œç¼–ç ï¼Œä»è€Œå¤§å¤§æé«˜äº†å‹ç¼©æ•ˆç‡ã€‚æ­¤å¤–ï¼Œä½¿ç”¨çº¿æ€§æ··åˆè’™çš®å˜æ¢è¿›è¡ŒAvatarå˜å½¢ï¼Œä¿è¯äº†æ—¶é—´ä¸Šçš„è¿è´¯æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šè¯¥æ–¹æ³•çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨é“°æ¥splattingè®­ç»ƒè§„èŒƒAvatarï¼Œä¿è¯äº†é«˜è´¨é‡çš„é™æ€å¤–è§‚è¡¨ç¤ºã€‚2) ä½¿ç”¨SMPLç­‰äººä½“å…ˆéªŒæ¨¡å‹è¿›è¡Œè¿åŠ¨å‚æ•°ä¼°è®¡ï¼Œå®ç°äº†ç´§å‡‘çš„è¿åŠ¨è¡¨ç¤ºã€‚3) ä½¿ç”¨çº¿æ€§æ··åˆè’™çš®å˜æ¢è¿›è¡ŒAvatarå˜å½¢ï¼Œä¿è¯äº†æ—¶é—´ä¸Šçš„è¿è´¯æ€§ã€‚4) æ¯å¸§ä»…ä½¿ç”¨94ä¸ªå‚æ•°è¡¨ç¤ºè¿åŠ¨ä¿¡æ¯ï¼Œæå¤§åœ°é™ä½äº†ç ç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸»æµå¤šè§†è§’äººä½“è§†é¢‘æ•°æ®é›†ä¸Šï¼Œåœ¨ç‡å¤±çœŸæ€§èƒ½æ–¹é¢æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„2D/3Dç¼–è§£ç å™¨å’Œç°æœ‰çš„å¯å­¦ä¹ åŠ¨æ€3Dé«˜æ–¯splattingå‹ç¼©æ–¹æ³•ã€‚å…·ä½“æ€§èƒ½æ•°æ®æœªçŸ¥ï¼Œä½†æ‘˜è¦å¼ºè°ƒäº†å…¶æ˜¾è‘—çš„ä¼˜è¶Šæ€§ï¼Œè¡¨æ˜è¯¥æ–¹æ³•åœ¨è¶…ä½ç ç‡ä¸‹èƒ½å¤Ÿå®ç°æ›´é«˜çš„å‹ç¼©æ•ˆç‡å’Œæ›´å¥½çš„æ¸²æŸ“è´¨é‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºå…ƒå®‡å®™ã€è™šæ‹Ÿä¼šè®®ã€è¿œç¨‹æ•™è‚²ã€æ¸¸æˆç­‰é¢†åŸŸã€‚é€šè¿‡è¶…ä½ç ç‡çš„3Däººä½“Avatarè§†é¢‘å‹ç¼©ï¼Œå¯ä»¥å®ç°æ›´æµç•…ã€æ›´é€¼çœŸçš„æ²‰æµ¸å¼ä½“éªŒï¼Œå°¤å…¶æ˜¯åœ¨ç½‘ç»œå¸¦å®½å—é™çš„ç§»åŠ¨è®¾å¤‡ä¸Šã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥ç”¨äºåˆ›å»ºä¸ªæ€§åŒ–çš„è™šæ‹ŸåŒ–èº«ï¼Œå¢å¼ºç”¨æˆ·åœ¨è™šæ‹Ÿç¯å¢ƒä¸­çš„äº’åŠ¨æ€§å’Œå‚ä¸æ„Ÿã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper proposes an efficient 3D avatar coding framework that leverages compact human priors and canonical-to-target transformation to enable high-quality 3D human avatar video compression at ultra-low bit rates. The framework begins by training a canonical Gaussian avatar using articulated splatting in a network-free manner, which serves as the foundation for avatar appearance modeling. Simultaneously, a human-prior template is employed to capture temporal body movements through compact parametric representations. This decomposition of appearance and temporal evolution minimizes redundancy, enabling efficient compression: the canonical avatar is shared across the sequence, requiring compression only once, while the temporal parameters, consisting of just 94 parameters per frame, are transmitted with minimal bit-rate. For each frame, the target human avatar is generated by deforming canonical avatar via Linear Blend Skinning transformation, facilitating temporal coherent video reconstruction and novel view synthesis. Experimental results demonstrate that the proposed method significantly outperforms conventional 2D/3D codecs and existing learnable dynamic 3D Gaussian splatting compression method in terms of rate-distortion performance on mainstream multi-view human video datasets, paving the way for seamless immersive multimedia experiences in meta-verse applications.

