---
layout: default
title: BitMar: Low-Bit Multimodal Fusion with Episodic Memory for Edge Devices
---

# BitMar: Low-Bit Multimodal Fusion with Episodic Memory for Edge Devices

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.10560" target="_blank" class="toolbar-btn">arXiv: 2510.10560v1</a>
    <a href="https://arxiv.org/pdf/2510.10560.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.10560v1" 
            onclick="toggleFavorite(this, '2510.10560v1', 'BitMar: Low-Bit Multimodal Fusion with Episodic Memory for Edge Devices')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Euhid Aman, Esteban Carlin, Hsing-Kuo Pao, Giovanni Beltrame, Ghaluh Indah Permata Sari, Yie-Tarng Chen

**ÂàÜÁ±ª**: cs.CL, cs.AI, cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-12

**Â§áÊ≥®**: 6 pages, BabyLM Workshop, EMNLP 2025

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**BitMarÔºöÈù¢ÂêëËæπÁºòËÆæÂ§áÁöÑ‰ΩéÊØîÁâπÂ§öÊ®°ÊÄÅËûçÂêà‰∏éÊÉÖÊôØËÆ∞ÂøÜÊ®°Âûã**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅËûçÂêà` `ËæπÁºòËÆ°ÁÆó` `‰ΩéÊØîÁâπÈáèÂåñ` `ÊÉÖÊôØËÆ∞ÂøÜ` `ÂõæÂÉèÊèèËø∞` `BitNet` `Transformer`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâË∑®Ê®°ÊÄÅÊ®°ÂûãËÆ°ÁÆóÈáèÂ§ßÔºåÈöæ‰ª•Âú®ËæπÁºòËÆæÂ§á‰∏äÈÉ®ÁΩ≤ÔºåÈôêÂà∂‰∫ÜÂÖ∂Â∫îÁî®ËåÉÂõ¥„ÄÇ
2. BitMarÊèêÂá∫‰∏ÄÁßçÈáèÂåñÁöÑÂ§öÊ®°ÊÄÅTransformerÔºåÂà©Áî®‰ΩéÊØîÁâπÁºñÁ†ÅÂô®ÂíåÊÉÖÊôØËÆ∞ÂøÜÔºåÈôç‰ΩéËÆ°ÁÆóÂíåÂ≠òÂÇ®ÈúÄÊ±Ç„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåBitMarÂú®‰ΩéÂª∂ËøüÂíåÂ∞èÊ®°Âûã‰ΩìÁßØ‰∏ãÔºåÂÆûÁé∞‰∫ÜÂÖ∑ÊúâÁ´û‰∫âÂäõÁöÑÂõæÂÉèÊèèËø∞ÂíåÂ§öÊ®°ÊÄÅÁêÜËß£ÊÄßËÉΩ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Ë∑®Ê≥®ÊÑèÂäõTransformerÂíåÂÖ∂‰ªñÂ§öÊ®°ÊÄÅËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÂú®ÂØπÈΩêÂíåÁîüÊàê‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫Ëâ≤Ôºå‰ΩÜÂÖ∂Â∫ûÂ§ß‰∏îÂÖ®Á≤æÂ∫¶ÁöÑÈ™®Âπ≤ÁΩëÁªú‰ΩøÂÖ∂Èöæ‰ª•ÈÉ®ÁΩ≤Âú®ËæπÁºòËÆæÂ§á‰∏ä„ÄÇËÆ∞ÂøÜÂ¢ûÂº∫Êû∂ÊûÑÂèØ‰ª•ÊèêÈ´òËøáÂéª‰∏ä‰∏ãÊñáÁöÑÂà©Áî®ÁéáÔºå‰ΩÜÂ§ßÂ§öÊï∞Â∑•‰ΩúÂæàÂ∞ëÂ∞ÜÂÖ∂‰∏éÈù¢ÂêëËæπÁºòÁöÑÊøÄËøõÈáèÂåñÁõ∏ÁªìÂêà„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫ÜBitMarÔºå‰∏ÄÁßçÈáèÂåñÁöÑÂ§öÊ®°ÊÄÅTransformerÔºåÂÆÉÊèêÂá∫‰∫Ü‰∏ÄÁßçÁ±ª‰ºº‰∫∫Á±ªÁöÑÂ§ñÈÉ®ÊÉÖÊôØËÆ∞ÂøÜÔºåÁî®‰∫éÂú®ËµÑÊ∫êÊúâÈôêÁöÑÁ°¨‰ª∂‰∏äËøõË°åÊúâÊïàÁöÑÂõæÂÉè-ÊñáÊú¨ÁîüÊàê„ÄÇBitMarÂà©Áî®1.58ÊØîÁâπÁöÑÁºñÁ†ÅÂô®Ôºå‰∏Ä‰∏™Áî®‰∫éÊñáÊú¨ÔºàBitNetÈ£éÊ†ºÔºâÔºå‰∏Ä‰∏™Áî®‰∫éËßÜËßâÔºàÂü∫‰∫éDiNOv2ÔºâÔºå‰ª•ÂàõÂª∫Á¥ßÂáëÁöÑÂµåÂÖ•ÔºåËøô‰∫õÂµåÂÖ•Ë¢´ÁªÑÂêàÂπ∂Áî®‰∫éÊü•ËØ¢Âõ∫ÂÆöÂ§ßÂ∞èÁöÑÈîÆÂÄºÊÉÖÊôØËÆ∞ÂøÜ„ÄÇÂú®ÂêëÈáèÊ£ÄÁ¥¢ÊúüÈó¥ÔºåBitNetËß£Á†ÅÂô®Â∫îÁî®ÈÄêÂ±ÇË∞ÉËäÇÔºå‰ªéËÄåÊèêÈ´òÁîüÊàêÂÜÖÂÆπÁöÑ‰∏ä‰∏ãÊñáÁõ∏ÂÖ≥ÊÄß„ÄÇËß£Á†ÅÂô®ËøòÈááÁî®Â∏¶ÊúâÊªëÂä®Á™óÂè£Êú∫Âà∂ÁöÑÊ≥®ÊÑèÂäõÊ±áËÅöÔºå‰ª•Âú®‰∏•Ê†ºÁöÑÂÜÖÂ≠òÈ¢ÑÁÆó‰∏ãÂ§ÑÁêÜÈïøËæìÂÖ•ÊàñÊµÅÂºèËæìÂÖ•„ÄÇÈÄêÂ±ÇË∞ÉËäÇÂíåÊªëÂä®Á™óÂè£Ê≥®ÊÑèÂäõÁöÑÁªìÂêàÂÆûÁé∞‰∫ÜÂº∫Â§ßÁöÑË¥®Èáè-ÈÄüÂ∫¶ÊùÉË°°Ôºå‰ª•‰ΩéÂª∂ËøüÂíåÂ∞èÊ®°ÂûãÂç†Áî®Á©∫Èó¥Êèê‰æõÊúâÁ´û‰∫âÂäõÁöÑÂõæÂÉèÊèèËø∞ÂíåÂ§öÊ®°ÊÄÅÁêÜËß£„ÄÇËøô‰∫õÁâπÊÄß‰ΩøBitMarÈùûÂ∏∏ÈÄÇÂêàËæπÁºòÈÉ®ÁΩ≤„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâË∑®Ê®°ÊÄÅËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÔºåÂ¶ÇÂü∫‰∫éTransformerÁöÑÊ®°ÂûãÔºåÈÄöÂ∏∏ÂÖ∑ÊúâÂ∫ûÂ§ßÁöÑÂèÇÊï∞ÈáèÂíåËÆ°ÁÆóÂ§çÊùÇÂ∫¶ÔºåÈöæ‰ª•Âú®ËµÑÊ∫êÂèóÈôêÁöÑËæπÁºòËÆæÂ§á‰∏äÈÉ®ÁΩ≤„ÄÇËøôÈôêÂà∂‰∫ÜÂÆÉ‰ª¨Âú®ÈúÄË¶ÅÂÆûÊó∂ÂìçÂ∫îÂíåÊú¨Âú∞Â§ÑÁêÜÁöÑÂ∫îÁî®Âú∫ÊôØ‰∏≠ÁöÑÂ∫îÁî®„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏ÂøΩÁï•‰∫ÜÊ®°ÂûãÈáèÂåñ‰∏éÂ§ñÈÉ®ËÆ∞ÂøÜÁªìÂêàÔºåÊó†Ê≥ïÂú®‰øùËØÅÊÄßËÉΩÁöÑÂêåÊó∂ÔºåÊúâÊïàÈôç‰ΩéËµÑÊ∫êÊ∂àËÄó„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöBitMarÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®‰ΩéÊØîÁâπÈáèÂåñÊäÄÊúØÂíåÊÉÖÊôØËÆ∞ÂøÜÊú∫Âà∂ÔºåÂú®‰øùËØÅÊ®°ÂûãÊÄßËÉΩÁöÑÂêåÊó∂ÔºåÊòæËëóÈôç‰ΩéÊ®°ÂûãÁöÑËÆ°ÁÆóÂ§çÊùÇÂ∫¶ÂíåÂ≠òÂÇ®ÈúÄÊ±Ç„ÄÇÈÄöËøá‰ΩéÊØîÁâπÁºñÁ†ÅÂô®ÊèêÂèñÁ¥ßÂáëÁöÑÂõæÂÉèÂíåÊñáÊú¨ÂµåÂÖ•ÔºåÂπ∂Âà©Áî®ÊÉÖÊôØËÆ∞ÂøÜÂ≠òÂÇ®ÂíåÊ£ÄÁ¥¢Áõ∏ÂÖ≥‰ø°ÊÅØÔºå‰ªéËÄåÂÆûÁé∞È´òÊïàÁöÑË∑®Ê®°ÊÄÅ‰ø°ÊÅØËûçÂêàÂíåÁîüÊàê„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöBitMarÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö‰ΩéÊØîÁâπÁºñÁ†ÅÂô®„ÄÅÊÉÖÊôØËÆ∞ÂøÜÊ®°ÂùóÂíåBitNetËß£Á†ÅÂô®„ÄÇÈ¶ñÂÖàÔºå‰ΩøÁî®1.58ÊØîÁâπÁöÑÊñáÊú¨ÔºàBitNetÈ£éÊ†ºÔºâÂíåËßÜËßâÔºàDiNOv2-basedÔºâÁºñÁ†ÅÂô®ÊèêÂèñÂõæÂÉèÂíåÊñáÊú¨ÁöÑÁ¥ßÂáëÂµåÂÖ•„ÄÇÁÑ∂ÂêéÔºåÂ∞ÜËøô‰∫õÂµåÂÖ•ÁªÑÂêàËµ∑Êù•ÔºåÊü•ËØ¢Âõ∫ÂÆöÂ§ßÂ∞èÁöÑÈîÆÂÄºÊÉÖÊôØËÆ∞ÂøÜÔºåÊ£ÄÁ¥¢Áõ∏ÂÖ≥‰ø°ÊÅØ„ÄÇÊúÄÂêéÔºåBitNetËß£Á†ÅÂô®Âà©Áî®ÈÄêÂ±ÇË∞ÉËäÇÂíåÊªëÂä®Á™óÂè£Ê≥®ÊÑèÂäõÊú∫Âà∂ÔºåÁîüÊàêÊúÄÁªàÁöÑÊñáÊú¨ÊèèËø∞ÊàñÂÆåÊàêÂÖ∂‰ªñÂ§öÊ®°ÊÄÅÁêÜËß£‰ªªÂä°„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöBitMarÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫é‰ª•‰∏ãÂá†‰∏™ÊñπÈù¢Ôºö1) ÈááÁî®ÊûÅ‰ΩéÊØîÁâπÔºà1.58bitÔºâÁöÑÁºñÁ†ÅÂô®ÔºåÊòæËëóÈôç‰Ωé‰∫ÜËÆ°ÁÆóÂíåÂ≠òÂÇ®ÂºÄÈîÄÔºõ2) ÂºïÂÖ•ÊÉÖÊôØËÆ∞ÂøÜÊ®°ÂùóÔºåÂ¢ûÂº∫‰∫ÜÊ®°ÂûãÂØπ‰∏ä‰∏ãÊñá‰ø°ÊÅØÁöÑÂà©Áî®ËÉΩÂäõÔºõ3) BitNetËß£Á†ÅÂô®ÈááÁî®ÈÄêÂ±ÇË∞ÉËäÇÂíåÊªëÂä®Á™óÂè£Ê≥®ÊÑèÂäõÊú∫Âà∂ÔºåÊèêÈ´ò‰∫ÜÁîüÊàêË¥®ÈáèÂíåÂ§ÑÁêÜÈïøÂ∫èÂàóÁöÑËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöBitMarÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ‰ΩøÁî®BitNetÈ£éÊ†ºÁöÑÊñáÊú¨ÁºñÁ†ÅÂô®ÂíåDiNOv2-basedÁöÑËßÜËßâÁºñÁ†ÅÂô®Ôºå‰ª•ÂÆûÁé∞È´òÊïàÁöÑÁâπÂæÅÊèêÂèñÔºõ2) ÊÉÖÊôØËÆ∞ÂøÜÊ®°ÂùóÈááÁî®Âõ∫ÂÆöÂ§ßÂ∞èÁöÑÈîÆÂÄºÂ≠òÂÇ®Ôºå‰ª•ÈôêÂà∂ÂÜÖÂ≠òÂç†Áî®Ôºõ3) BitNetËß£Á†ÅÂô®ÈááÁî®ÈÄêÂ±ÇË∞ÉËäÇÔºåÊ†πÊçÆ‰∏çÂêåÂ±ÇÁöÑ‰∏ä‰∏ãÊñá‰ø°ÊÅØË∞ÉÊï¥ÁîüÊàêËøáÁ®ãÔºõ4) ÊªëÂä®Á™óÂè£Ê≥®ÊÑèÂäõÊú∫Âà∂ÂÖÅËÆ∏Ê®°ÂûãÂ§ÑÁêÜÈïøËæìÂÖ•Â∫èÂàóÔºåÂêåÊó∂‰øùÊåÅËæÉ‰ΩéÁöÑÂÜÖÂ≠òÂç†Áî®„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

BitMarÂú®‰ΩéÂª∂ËøüÂíåÂ∞èÊ®°Âûã‰ΩìÁßØ‰∏ãÂÆûÁé∞‰∫ÜÂÖ∑ÊúâÁ´û‰∫âÂäõÁöÑÂõæÂÉèÊèèËø∞ÂíåÂ§öÊ®°ÊÄÅÁêÜËß£ÊÄßËÉΩ„ÄÇÈÄöËøá1.58ÊØîÁâπÁöÑÁºñÁ†ÅÂô®ÂíåÊÉÖÊôØËÆ∞ÂøÜÊú∫Âà∂ÔºåÊòæËëóÈôç‰Ωé‰∫ÜÊ®°ÂûãÁöÑËÆ°ÁÆóÂ§çÊùÇÂ∫¶ÂíåÂ≠òÂÇ®ÈúÄÊ±Ç„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåBitMarÂú®ËæπÁºòËÆæÂ§á‰∏äËÉΩÂ§üÂÆûÁé∞È´òÊïàÁöÑË∑®Ê®°ÊÄÅ‰ø°ÊÅØËûçÂêàÂíåÁîüÊàêÔºå‰∏∫ËæπÁºòËÆ°ÁÆóÂ∫îÁî®Êèê‰æõ‰∫ÜÊñ∞ÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

BitMarÈÄÇÁî®‰∫éÂêÑÁßçËæπÁºòËÆ°ÁÆóÂú∫ÊôØÔºå‰æãÂ¶ÇÊô∫ËÉΩÁõëÊéß„ÄÅÊú∫Âô®‰∫∫ÂØºËà™„ÄÅÊô∫ËÉΩÂÆ∂Â±ÖÁ≠â„ÄÇÂÆÉÂèØ‰ª•Áî®‰∫éÂõæÂÉèÊèèËø∞ÁîüÊàê„ÄÅËßÜËßâÈóÆÁ≠î„ÄÅÂ§öÊ®°ÊÄÅÂØπËØùÁ≠â‰ªªÂä°Ôºå‰∏∫ËæπÁºòËÆæÂ§áÊèê‰æõÂº∫Â§ßÁöÑÂ§öÊ®°ÊÄÅÁêÜËß£ËÉΩÂäõ„ÄÇËØ•Á†îÁ©∂ÊúâÂä©‰∫éÊé®Âä®‰∫∫Â∑•Êô∫ËÉΩÂú®ËµÑÊ∫êÂèóÈôêÁéØÂ¢É‰∏≠ÁöÑÂ∫îÁî®ÔºåÂÆûÁé∞Êõ¥Êô∫ËÉΩ„ÄÅÊõ¥È´òÊïàÁöÑËæπÁºòËÆ°ÁÆó„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Cross-attention transformers and other multimodal vision-language models excel at grounding and generation; however, their extensive, full-precision backbones make it challenging to deploy them on edge devices. Memory-augmented architectures enhance the utilization of past context; however, most works rarely pair them with aggressive edge-oriented quantization. We introduce BitMar, a quantized multimodal transformer that proposes an external human-like episodic memory for effective image-text generation on hardware with limited resources. BitMar utilizes 1.58-bit encoders, one for text (BitNet-style) and one for vision (DiNOv2-based), to create compact embeddings that are combined and used to query a fixed-size key-value episodic memory. During vector retrieval, the BitNet decoder applies per-layer conditioning, which increases the contextual relevance of generated content. The decoder also employs attention sinks with a sliding-window mechanism to process long or streaming inputs under tight memory budgets. The combination of per-layer conditioning and sliding-window attention achieves a strong quality-speed trade-off, delivering competitive captioning and multimodal understanding at low latency with a small model footprint. These characteristics make BitMar well-suited for edge deployment.

