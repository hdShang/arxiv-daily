---
layout: default
title: Equipping Vision Foundation Model with Mixture of Experts for Out-of-Distribution Detection
---

# Equipping Vision Foundation Model with Mixture of Experts for Out-of-Distribution Detection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.10584" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.10584v1</a>
  <a href="https://arxiv.org/pdf/2510.10584.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.10584v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.10584v1', 'Equipping Vision Foundation Model with Mixture of Experts for Out-of-Distribution Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shizhen Zhao, Jiahui Liu, Xin Wen, Haoru Tan, Xiaojuan Qi

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-12

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMoFEæ¨¡å—å’ŒåŠ¨æ€Mixupç­–ç•¥ï¼Œæå‡è§†è§‰åŸºç¡€æ¨¡å‹åœ¨OODæ£€æµ‹ä¸­çš„æ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åˆ†å¸ƒå¤–æ£€æµ‹` `è§†è§‰åŸºç¡€æ¨¡å‹` `ç‰¹å¾ä¸“å®¶æ··åˆ` `åŠ¨æ€Mixup` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨OODæ£€æµ‹ä¸­ï¼Œå½“è¯­ä¹‰ç©ºé—´è¾ƒå¤§æ—¶ï¼Œè§†è§‰åŸºç¡€æ¨¡å‹çš„æ€§èƒ½ä¸ä½³ï¼Œå†³ç­–è¾¹ç•Œå¤æ‚å¯¼è‡´ä¼˜åŒ–å›°éš¾ã€‚
2. æå‡ºç‰¹å¾ä¸“å®¶æ··åˆ(MoFE)æ¨¡å—ï¼Œå°†ç‰¹å¾åˆ’åˆ†ä¸ºå­ç©ºé—´ï¼Œæ•è·å¤æ‚æ•°æ®åˆ†å¸ƒå¹¶ç»†åŒ–å†³ç­–è¾¹ç•Œã€‚
3. å¼•å…¥åŠ¨æ€-$Î²$ Mixupç­–ç•¥ï¼Œè‡ªé€‚åº”è°ƒæ•´æ’å€¼æƒé‡ï¼Œæå‡å›°éš¾ç±»åˆ«çš„ç‰¹å¾å­¦ä¹ ï¼Œå®éªŒç»“æœæ˜¾è‘—ä¼˜äºåŸºçº¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é¢„è®­ç»ƒè§†è§‰åŸºç¡€æ¨¡å‹å·²ç»æ”¹å˜äº†è®¸å¤šè®¡ç®—æœºè§†è§‰ä»»åŠ¡ã€‚å°½ç®¡å®ƒä»¬å…·æœ‰å­¦ä¹ åˆ¤åˆ«æ€§å’Œæ³›åŒ–æ€§ç‰¹å¾çš„å¼ºå¤§èƒ½åŠ›ï¼Œè¿™å¯¹äºåˆ†å¸ƒå¤–(OOD)æ£€æµ‹è‡³å…³é‡è¦ï¼Œä½†å®ƒä»¬å¯¹è¿™é¡¹ä»»åŠ¡çš„å½±å“ä»æœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚å—æ­¤å·®è·çš„æ¨åŠ¨ï¼Œæˆ‘ä»¬ç³»ç»Ÿåœ°ç ”ç©¶äº†ç”¨äºOODæ£€æµ‹çš„ä»£è¡¨æ€§è§†è§‰åŸºç¡€æ¨¡å‹ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œå³ä½¿æ²¡æœ‰åœ¨åŸŸå†…(ID)æ•°æ®ä¸Šè¿›è¡Œå¾®è°ƒï¼Œé¢„è®­ç»ƒçš„DINOv2æ¨¡å‹è‡ªç„¶åœ°ä¸ºOODæ£€æµ‹æä¾›äº†é«˜åº¦åˆ¤åˆ«æ€§çš„ç‰¹å¾ç©ºé—´ï¼Œå®ç°äº†ä¸ç°æœ‰æœ€å…ˆè¿›æ–¹æ³•ç›¸å½“çš„æ€§èƒ½ï¼Œè€Œæ— éœ€å¤æ‚çš„è®¾è®¡ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜æ¢è®¨äº†åœ¨åŸŸå†…(ID)æ•°æ®ä¸Šå¾®è°ƒåŸºç¡€æ¨¡å‹å¦‚ä½•å¢å¼ºOODæ£€æµ‹ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œåœ¨å…·æœ‰è¾ƒå¤§è¯­ä¹‰ç©ºé—´çš„åœºæ™¯ä¸­ï¼Œè§†è§‰åŸºç¡€æ¨¡å‹çš„æ€§èƒ½ä»ç„¶ä¸èƒ½ä»¤äººæ»¡æ„ã€‚è¿™æ˜¯ç”±äºç±»åˆ«æ•°é‡çš„å¢åŠ å¯¼è‡´å†³ç­–è¾¹ç•Œçš„å¤æ‚æ€§å¢åŠ ï¼Œè¿™ä½¿å¾—ä¼˜åŒ–è¿‡ç¨‹å¤æ‚åŒ–ã€‚ä¸ºäº†ç¼“è§£è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ç‰¹å¾ä¸“å®¶æ··åˆ(MoFE)æ¨¡å—ï¼Œè¯¥æ¨¡å—å°†ç‰¹å¾åˆ’åˆ†ä¸ºå­ç©ºé—´ï¼Œæœ‰æ•ˆåœ°æ•è·å¤æ‚çš„æ•°æ®åˆ†å¸ƒå¹¶ç»†åŒ–å†³ç­–è¾¹ç•Œã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åŠ¨æ€-$Î²$ Mixupç­–ç•¥ï¼Œè¯¥ç­–ç•¥ä»åŠ¨æ€betaåˆ†å¸ƒä¸­é‡‡æ ·æ’å€¼æƒé‡ã€‚è¿™é€‚åº”äº†ä¸åŒç±»åˆ«ä¹‹é—´ä¸åŒç¨‹åº¦çš„å­¦ä¹ éš¾åº¦ï¼Œä»è€Œæ”¹è¿›äº†æ›´å…·æŒ‘æˆ˜æ€§ç±»åˆ«çš„ç‰¹å¾å­¦ä¹ ã€‚å¤§é‡çš„å®éªŒè¯æ˜äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œæ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è§†è§‰åŸºç¡€æ¨¡å‹åœ¨åˆ†å¸ƒå¤–(OOD)æ£€æµ‹ä»»åŠ¡ä¸­ï¼Œå°¤å…¶æ˜¯åœ¨å…·æœ‰è¾ƒå¤§è¯­ä¹‰ç©ºé—´çš„åœºæ™¯ä¸‹ï¼Œæ€§èƒ½ä¸ä½³çš„é—®é¢˜ã€‚ç°æœ‰çš„æ–¹æ³•åœ¨å¤„ç†å¤æ‚æ•°æ®åˆ†å¸ƒå’Œä¼˜åŒ–å†³ç­–è¾¹ç•Œæ–¹é¢å­˜åœ¨å›°éš¾ï¼Œå¯¼è‡´OODæ£€æµ‹çš„å‡†ç¡®ç‡ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å°†ç‰¹å¾ç©ºé—´åˆ’åˆ†ä¸ºå¤šä¸ªå­ç©ºé—´ï¼Œå¹¶åˆ©ç”¨ä¸“å®¶æ··åˆæ¨¡å‹(MoFE)æ¥å­¦ä¹ æ¯ä¸ªå­ç©ºé—´çš„ç‰¹å¾è¡¨ç¤ºï¼Œä»è€Œé™ä½å†³ç­–è¾¹ç•Œçš„å¤æ‚æ€§ã€‚åŒæ—¶ï¼Œå¼•å…¥åŠ¨æ€Mixupç­–ç•¥ï¼Œæ ¹æ®ç±»åˆ«çš„å­¦ä¹ éš¾åº¦åŠ¨æ€è°ƒæ•´æ•°æ®å¢å¼ºçš„å¼ºåº¦ï¼Œä»¥æå‡æ¨¡å‹å¯¹å›°éš¾ç±»åˆ«çš„è¯†åˆ«èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) ç‰¹å¾æå–å™¨ï¼šä½¿ç”¨é¢„è®­ç»ƒçš„è§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆå¦‚DINOv2ï¼‰æå–å›¾åƒç‰¹å¾ã€‚2) ç‰¹å¾ä¸“å®¶æ··åˆ(MoFE)æ¨¡å—ï¼šå°†æå–çš„ç‰¹å¾è¾“å…¥MoFEæ¨¡å—ï¼Œè¯¥æ¨¡å—å°†ç‰¹å¾åˆ’åˆ†ä¸ºå¤šä¸ªå­ç©ºé—´ï¼Œå¹¶å­¦ä¹ æ¯ä¸ªå­ç©ºé—´çš„ç‰¹å¾è¡¨ç¤ºã€‚3) åˆ†ç±»å™¨ï¼šä½¿ç”¨å­¦ä¹ åˆ°çš„ç‰¹å¾è¡¨ç¤ºè¿›è¡Œåˆ†ç±»ï¼Œå¹¶è¾“å‡ºOODæ£€æµ‹ç»“æœã€‚4) åŠ¨æ€-$Î²$ Mixupç­–ç•¥ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨åŠ¨æ€Mixupç­–ç•¥è¿›è¡Œæ•°æ®å¢å¼ºï¼Œä»¥æå‡æ¨¡å‹å¯¹å›°éš¾ç±»åˆ«çš„è¯†åˆ«èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ç‰¹å¾ä¸“å®¶æ··åˆ(MoFE)æ¨¡å—å’ŒåŠ¨æ€-$Î²$ Mixupç­–ç•¥ã€‚MoFEæ¨¡å—é€šè¿‡å°†ç‰¹å¾ç©ºé—´åˆ’åˆ†ä¸ºå¤šä¸ªå­ç©ºé—´ï¼Œé™ä½äº†å†³ç­–è¾¹ç•Œçš„å¤æ‚æ€§ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°å­¦ä¹ å¤æ‚çš„æ•°æ®åˆ†å¸ƒã€‚åŠ¨æ€Mixupç­–ç•¥åˆ™æ ¹æ®ç±»åˆ«çš„å­¦ä¹ éš¾åº¦åŠ¨æ€è°ƒæ•´æ•°æ®å¢å¼ºçš„å¼ºåº¦ï¼Œä»è€Œæå‡äº†æ¨¡å‹å¯¹å›°éš¾ç±»åˆ«çš„è¯†åˆ«èƒ½åŠ›ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å¤„ç†å…·æœ‰è¾ƒå¤§è¯­ä¹‰ç©ºé—´çš„OODæ£€æµ‹é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šMoFEæ¨¡å—çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨å¤šä¸ªä¸“å®¶ç½‘ç»œæ¥å­¦ä¹ æ¯ä¸ªå­ç©ºé—´çš„ç‰¹å¾è¡¨ç¤ºã€‚2) ä½¿ç”¨é—¨æ§ç½‘ç»œæ¥åŠ¨æ€åœ°é€‰æ‹©æ¯ä¸ªä¸“å®¶çš„æƒé‡ã€‚åŠ¨æ€Mixupç­–ç•¥çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨åŠ¨æ€betaåˆ†å¸ƒæ¥é‡‡æ ·æ’å€¼æƒé‡ã€‚2) æ ¹æ®ç±»åˆ«çš„å­¦ä¹ éš¾åº¦åŠ¨æ€è°ƒæ•´betaåˆ†å¸ƒçš„å‚æ•°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„MoFEæ¨¡å—å’ŒåŠ¨æ€Mixupç­–ç•¥èƒ½å¤Ÿæ˜¾è‘—æå‡è§†è§‰åŸºç¡€æ¨¡å‹åœ¨OODæ£€æµ‹ä¸­çš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•ç›¸æ¯”äºç°æœ‰æ–¹æ³•å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå°¤å…¶æ˜¯åœ¨å…·æœ‰è¾ƒå¤§è¯­ä¹‰ç©ºé—´çš„åœºæ™¯ä¸‹ï¼Œæ€§èƒ½æå‡æ›´ä¸ºæ˜æ˜¾ã€‚å…·ä½“æ€§èƒ½æ•°æ®åœ¨è®ºæ–‡ä¸­ç»™å‡ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå®‰å…¨ç›‘æ§ã€åŒ»ç–—è¯Šæ–­ã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨å®‰å…¨ç›‘æ§ä¸­ï¼Œå¯ä»¥æ£€æµ‹å¼‚å¸¸äº‹ä»¶ï¼›åœ¨åŒ»ç–—è¯Šæ–­ä¸­ï¼Œå¯ä»¥è¯†åˆ«ç½•è§ç–¾ç—…ï¼›åœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼Œå¯ä»¥è¯†åˆ«æœªçŸ¥çš„äº¤é€šçŠ¶å†µã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºæé«˜äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„é²æ£’æ€§å’Œå¯é æ€§ï¼Œå…·æœ‰é‡è¦çš„å®é™…åº”ç”¨ä»·å€¼å’Œå¹¿é˜”çš„æœªæ¥å‘å±•å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Pre-trained vision foundation models have transformed many computer vision tasks. Despite their strong ability to learn discriminative and generalizable features crucial for out-of-distribution (OOD) detection, their impact on this task remains underexplored. Motivated by this gap, we systematically investigate representative vision foundation models for OOD detection. Our findings reveal that a pre-trained DINOv2 model, even without fine-tuning on in-domain (ID) data, naturally provides a highly discriminative feature space for OOD detection, achieving performance comparable to existing state-of-the-art methods without requiring complex designs. Beyond this, we explore how fine-tuning foundation models on in-domain (ID) data can enhance OOD detection. However, we observe that the performance of vision foundation models remains unsatisfactory in scenarios with a large semantic space. This is due to the increased complexity of decision boundaries as the number of categories grows, which complicates the optimization process. To mitigate this, we propose the Mixture of Feature Experts (MoFE) module, which partitions features into subspaces, effectively capturing complex data distributions and refining decision boundaries. Further, we introduce a Dynamic-$Î²$ Mixup strategy, which samples interpolation weights from a dynamic beta distribution. This adapts to varying levels of learning difficulty across categories, improving feature learning for more challenging categories. Extensive experiments demonstrate the effectiveness of our approach, significantly outperforming baseline methods.

