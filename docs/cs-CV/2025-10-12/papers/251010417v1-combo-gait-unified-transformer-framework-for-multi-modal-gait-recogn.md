---
layout: default
title: "Combo-Gait: Unified Transformer Framework for Multi-Modal Gait Recognition and Attribute Analysis"
---

# Combo-Gait: Unified Transformer Framework for Multi-Modal Gait Recognition and Attribute Analysis

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.10417" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.10417v1</a>
  <a href="https://arxiv.org/pdf/2510.10417.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.10417v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.10417v1', 'Combo-Gait: Unified Transformer Framework for Multi-Modal Gait Recognition and Attribute Analysis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhao-Yang Wang, Zhimin Shao, Jieneng Chen, Rama Chellappa

**åˆ†ç±»**: cs.CV, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-10-12

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCombo-Gaitï¼Œç”¨äºå¤šæ¨¡æ€æ­¥æ€è¯†åˆ«å’Œå±æ€§åˆ†æçš„ç»Ÿä¸€Transformeræ¡†æ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)**

**å…³é”®è¯**: `æ­¥æ€è¯†åˆ«` `å¤šæ¨¡æ€èåˆ` `Transformer` `å¤šä»»åŠ¡å­¦ä¹ ` `äººä½“å±æ€§ä¼°è®¡` `è¿œè·ç¦»è¯†åˆ«` `ç”Ÿç‰©ç‰¹å¾è¯†åˆ«`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ­¥æ€è¯†åˆ«æ–¹æ³•ä¾èµ–å•ä¸€æ¨¡æ€ï¼Œæ— æ³•å……åˆ†æ•æ‰æ­¥æ€çš„å¤æ‚å‡ ä½•å’ŒåŠ¨æ€ä¿¡æ¯ï¼Œé™åˆ¶äº†è¯†åˆ«çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚
2. Combo-Gaitæ¡†æ¶èåˆ2Dè½®å»“å’Œ3D SMPLç‰¹å¾ï¼Œå¹¶é‡‡ç”¨ç»Ÿä¸€Transformerè¿›è¡Œå¤šæ¨¡æ€ç‰¹å¾èåˆå’Œå±æ€§ç›¸å…³è¡¨ç¤ºå­¦ä¹ ã€‚
3. åœ¨BRIARæ•°æ®é›†ä¸Šï¼ŒCombo-Gaitåœ¨è¿œè·ç¦»å’Œæç«¯è§’åº¦ä¸‹è¶…è¶Šç°æœ‰æ–¹æ³•ï¼ŒåŒæ—¶å®ç°äº†å‡†ç¡®çš„äººä½“å±æ€§ä¼°è®¡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ­¥æ€è¯†åˆ«æ˜¯ä¸€ç§é‡è¦çš„ç”Ÿç‰©ç‰¹å¾è¯†åˆ«æŠ€æœ¯ï¼Œå°¤å…¶é€‚ç”¨äºä½åˆ†è¾¨ç‡æˆ–æ— çº¦æŸç¯å¢ƒä¸‹çš„è¿œè·ç¦»äººä½“è¯†åˆ«ã€‚ç›®å‰çš„ç ”ç©¶é€šå¸¸ä¾§é‡äº2Dè¡¨ç¤ºï¼ˆå¦‚è½®å»“å’Œéª¨éª¼ï¼‰æˆ–3Dè¡¨ç¤ºï¼ˆå¦‚ç½‘æ ¼å’ŒSMPLæ¨¡å‹ï¼‰ï¼Œä½†ä¾èµ–å•ä¸€æ¨¡æ€å¾€å¾€æ— æ³•æ•æ‰äººç±»è¡Œèµ°æ¨¡å¼çš„å®Œæ•´å‡ ä½•å’ŒåŠ¨æ€å¤æ‚æ€§ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€å’Œå¤šä»»åŠ¡æ¡†æ¶ï¼Œå°†2Dæ—¶åºè½®å»“ä¸3D SMPLç‰¹å¾ç›¸ç»“åˆï¼Œä»¥å®ç°ç¨³å¥çš„æ­¥æ€åˆ†æã€‚é™¤äº†èº«ä»½è¯†åˆ«ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ç§å¤šä»»åŠ¡å­¦ä¹ ç­–ç•¥ï¼Œè”åˆæ‰§è¡Œæ­¥æ€è¯†åˆ«å’Œäººä½“å±æ€§ä¼°è®¡ï¼ŒåŒ…æ‹¬å¹´é¾„ã€èº«ä½“è´¨é‡æŒ‡æ•°ï¼ˆBMIï¼‰å’Œæ€§åˆ«ã€‚é‡‡ç”¨ç»Ÿä¸€çš„Transformeræ¥æœ‰æ•ˆåœ°èåˆå¤šæ¨¡æ€æ­¥æ€ç‰¹å¾ï¼Œå¹¶æ›´å¥½åœ°å­¦ä¹ ä¸å±æ€§ç›¸å…³çš„è¡¨ç¤ºï¼ŒåŒæ—¶ä¿ç•™åˆ¤åˆ«æ€§èº«ä»½çº¿ç´¢ã€‚åœ¨å¤§å‹BRIARæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ¡ä»¶ä¸‹ï¼Œä¾‹å¦‚è¿œè·ç¦»ï¼ˆé«˜è¾¾1å…¬é‡Œï¼‰å’Œæç«¯ä¿¯ä»°è§’ï¼ˆé«˜è¾¾50Â°ï¼‰ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºæœ€å…ˆè¿›çš„æ­¥æ€è¯†åˆ«æ–¹æ³•ï¼Œå¹¶æä¾›å‡†ç¡®çš„äººä½“å±æ€§ä¼°è®¡ã€‚è¿™äº›ç»“æœçªå‡ºäº†å¤šæ¨¡æ€å’Œå¤šä»»åŠ¡å­¦ä¹ åœ¨æ¨è¿›åŸºäºæ­¥æ€çš„äººä½“ç†è§£åœ¨ç°å®åœºæ™¯ä¸­çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æ­¥æ€è¯†åˆ«æ–¹æ³•é€šå¸¸åªä¾èµ–äº2Dæˆ–3Dçš„å•ä¸€æ¨¡æ€ä¿¡æ¯ï¼Œæ— æ³•å……åˆ†åˆ©ç”¨æ­¥æ€çš„å‡ ä½•å’ŒåŠ¨æ€ç‰¹å¾ï¼Œå¯¼è‡´åœ¨å¤æ‚åœºæ™¯ä¸‹è¯†åˆ«ç²¾åº¦ä¸‹é™ã€‚æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•å¾ˆå°‘åŒæ—¶è¿›è¡Œæ­¥æ€è¯†åˆ«å’Œå±æ€§åˆ†æï¼Œæ— æ³•å……åˆ†æŒ–æ˜æ­¥æ€ä¸­è•´å«çš„ä¸°å¯Œä¿¡æ¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤šæ¨¡æ€ä¿¡æ¯äº’è¡¥çš„ä¼˜åŠ¿ï¼Œå°†2Dæ—¶åºè½®å»“å’Œ3D SMPLç‰¹å¾ç›¸ç»“åˆï¼Œå¹¶é€šè¿‡å¤šä»»åŠ¡å­¦ä¹ ç­–ç•¥ï¼ŒåŒæ—¶è¿›è¡Œæ­¥æ€è¯†åˆ«å’Œäººä½“å±æ€§ä¼°è®¡ã€‚Transformeræ¶æ„èƒ½å¤Ÿæœ‰æ•ˆåœ°èåˆå¤šæ¨¡æ€ç‰¹å¾ï¼Œå¹¶å­¦ä¹ å±æ€§ç›¸å…³çš„è¡¨ç¤ºï¼ŒåŒæ—¶ä¿ç•™èº«ä»½åˆ¤åˆ«ä¿¡æ¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCombo-Gaitæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) 2Dè½®å»“ç‰¹å¾æå–æ¨¡å—ï¼šæå–æ­¥æ€è½®å»“çš„æ—¶åºä¿¡æ¯ã€‚2) 3D SMPLç‰¹å¾æå–æ¨¡å—ï¼šæå–äººä½“ä¸‰ç»´å§¿æ€å’Œå½¢çŠ¶ä¿¡æ¯ã€‚3) å¤šæ¨¡æ€ç‰¹å¾èåˆæ¨¡å—ï¼šä½¿ç”¨Transformeræ¶æ„èåˆ2Då’Œ3Dç‰¹å¾ã€‚4) å¤šä»»åŠ¡å­¦ä¹ æ¨¡å—ï¼šåŒæ—¶è¿›è¡Œæ­¥æ€è¯†åˆ«å’Œäººä½“å±æ€§ä¼°è®¡ã€‚æ•´ä¸ªæ¡†æ¶é‡‡ç”¨ç«¯åˆ°ç«¯çš„æ–¹å¼è¿›è¡Œè®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†ä¸€ä¸ªå¤šæ¨¡æ€æ­¥æ€è¯†åˆ«æ¡†æ¶ï¼Œæœ‰æ•ˆèåˆäº†2Då’Œ3Dç‰¹å¾ã€‚2) å¼•å…¥äº†å¤šä»»åŠ¡å­¦ä¹ ç­–ç•¥ï¼ŒåŒæ—¶è¿›è¡Œæ­¥æ€è¯†åˆ«å’Œäººä½“å±æ€§ä¼°è®¡ã€‚3) ä½¿ç”¨ç»Ÿä¸€çš„Transformeræ¶æ„è¿›è¡Œå¤šæ¨¡æ€ç‰¹å¾èåˆå’Œå±æ€§ç›¸å…³è¡¨ç¤ºå­¦ä¹ ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´å…¨é¢åœ°åˆ©ç”¨æ­¥æ€ä¿¡æ¯ï¼Œæé«˜è¯†åˆ«ç²¾åº¦å’Œé²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨Transformeræ¶æ„ä¸­ï¼Œä½¿ç”¨äº†å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶æ¥æ•æ‰ä¸åŒæ¨¡æ€ç‰¹å¾ä¹‹é—´çš„å…³è”æ€§ã€‚åœ¨å¤šä»»åŠ¡å­¦ä¹ ä¸­ï¼Œä½¿ç”¨äº†åŠ æƒæŸå¤±å‡½æ•°æ¥å¹³è¡¡æ­¥æ€è¯†åˆ«å’Œå±æ€§ä¼°è®¡ä»»åŠ¡ä¹‹é—´çš„é‡è¦æ€§ã€‚å…·ä½“çš„æƒé‡å‚æ•°éœ€è¦æ ¹æ®å®éªŒç»“æœè¿›è¡Œè°ƒæ•´ã€‚æ­¤å¤–ï¼Œè¿˜ä½¿ç”¨äº†æ•°æ®å¢å¼ºæŠ€æœ¯æ¥æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å¤§å‹BRIARæ•°æ®é›†ä¸Šï¼ŒCombo-Gaitåœ¨è¿œè·ç¦»ï¼ˆé«˜è¾¾1å…¬é‡Œï¼‰å’Œæç«¯ä¿¯ä»°è§’ï¼ˆé«˜è¾¾50Â°ï¼‰ç­‰æŒ‘æˆ˜æ€§æ¡ä»¶ä¸‹ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æ­¥æ€è¯†åˆ«æ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ­¥æ€è¯†åˆ«ç²¾åº¦å’Œäººä½“å±æ€§ä¼°è®¡å‡†ç¡®ç‡æ–¹é¢å‡å–å¾—äº†æ˜¾è‘—æå‡ï¼ŒéªŒè¯äº†å¤šæ¨¡æ€å’Œå¤šä»»åŠ¡å­¦ä¹ ç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Combo-Gaitæ¡†æ¶å¯åº”ç”¨äºæ™ºèƒ½å®‰é˜²ã€æ™ºæ…§åŸå¸‚ã€åŒ»ç–—å¥åº·ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨å®‰é˜²é¢†åŸŸï¼Œå¯ç”¨äºè¿œè·ç¦»äººä½“èº«ä»½è¯†åˆ«å’Œå¼‚å¸¸è¡Œä¸ºæ£€æµ‹ï¼›åœ¨åŒ»ç–—å¥åº·é¢†åŸŸï¼Œå¯ç”¨äºæ­¥æ€åˆ†æå’Œç–¾ç—…è¯Šæ–­ã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºæå‡æ­¥æ€è¯†åˆ«æŠ€æœ¯åœ¨å®é™…åœºæ™¯ä¸­çš„åº”ç”¨ä»·å€¼ï¼Œå¹¶ä¸ºæœªæ¥æ­¥æ€åˆ†æç ”ç©¶æä¾›æ–°çš„æ€è·¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Gait recognition is an important biometric for human identification at a distance, particularly under low-resolution or unconstrained environments. Current works typically focus on either 2D representations (e.g., silhouettes and skeletons) or 3D representations (e.g., meshes and SMPLs), but relying on a single modality often fails to capture the full geometric and dynamic complexity of human walking patterns. In this paper, we propose a multi-modal and multi-task framework that combines 2D temporal silhouettes with 3D SMPL features for robust gait analysis. Beyond identification, we introduce a multitask learning strategy that jointly performs gait recognition and human attribute estimation, including age, body mass index (BMI), and gender. A unified transformer is employed to effectively fuse multi-modal gait features and better learn attribute-related representations, while preserving discriminative identity cues. Extensive experiments on the large-scale BRIAR datasets, collected under challenging conditions such as long-range distances (up to 1 km) and extreme pitch angles (up to 50Â°), demonstrate that our approach outperforms state-of-the-art methods in gait recognition and provides accurate human attribute estimation. These results highlight the promise of multi-modal and multitask learning for advancing gait-based human understanding in real-world scenarios.

