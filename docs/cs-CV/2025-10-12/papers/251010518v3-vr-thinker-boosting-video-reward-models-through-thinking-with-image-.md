---
layout: default
title: VR-Thinker: Boosting Video Reward Models through Thinking-with-Image Reasoning
---

# VR-Thinker: Boosting Video Reward Models through Thinking-with-Image Reasoning

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.10518" target="_blank" class="toolbar-btn">arXiv: 2510.10518v3</a>
    <a href="https://arxiv.org/pdf/2510.10518.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.10518v3" 
            onclick="toggleFavorite(this, '2510.10518v3', 'VR-Thinker: Boosting Video Reward Models through Thinking-with-Image Reasoning')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Qunzhong Wang, Jie Liu, Jiajun Liang, Yilei Jiang, Yuanxing Zhang, Jinyuan Chen, Yaozhi Zheng, Xintao Wang, Pengfei Wan, Xiangyu Yue, Jiaheng Liu

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-12 (Êõ¥Êñ∞: 2025-10-15)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**VR-ThinkerÔºöÈÄöËøáÂõæÂÉèÊé®ÁêÜÂ¢ûÂº∫ËßÜÈ¢ëÂ•ñÂä±Ê®°ÂûãÔºåÊèêÂçáÈïøËßÜÈ¢ëÂÅèÂ•ΩÂà§Êñ≠„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËßÜÈ¢ëÂ•ñÂä±Ê®°Âûã` `ÂõæÂÉèÊé®ÁêÜ` `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `Âº∫ÂåñÂ≠¶‰π†` `ÈïøËßÜÈ¢ëÁêÜËß£` `ËßÜËßâËÆ∞ÂøÜ` `ÊÄùÁª¥ÈìæÊé®ÁêÜ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËßÜÈ¢ëÂ•ñÂä±Ê®°ÂûãÂèóÈôê‰∫éËßÜËßâËæìÂÖ•ÁöÑ‰∏ä‰∏ãÊñáÈ¢ÑÁÆóÔºåÂØºËá¥Êó†Ê≥ïÂ§ÑÁêÜÈïøËßÜÈ¢ëÔºå‰∏îÂÆπÊòìÂú®Êé®ÁêÜËøáÁ®ã‰∏≠‰∫ßÁîüÂπªËßâ„ÄÇ
2. VR-Thinker ÂºïÂÖ•‰∫Ü‚ÄúÂõæÂÉèÊé®ÁêÜ‚ÄùÊú∫Âà∂Ôºå‰ΩøÊ®°ÂûãËÉΩÂ§ü‰∏ªÂä®ÈÄâÊã©ÂíåÊõ¥Êñ∞ËßÜËßâËØÅÊçÆÔºå‰ªéËÄåÂú®ÊúâÈôêÁöÑ‰∏ä‰∏ãÊñá‰∏≠ËøõË°åÊõ¥ÂèØÈù†ÁöÑÊé®ÁêÜ„ÄÇ
3. ÈÄöËøáÂÜ∑ÂêØÂä®„ÄÅÊãíÁªùÈááÊ†∑ÂæÆË∞ÉÂíåÁªÑÁõ∏ÂØπÁ≠ñÁï•‰ºòÂåñÁ≠âÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÔºåVR-ThinkerÂú®Â§ö‰∏™ËßÜÈ¢ëÂÅèÂ•ΩÂü∫ÂáÜÊµãËØï‰∏≠ÂèñÂæó‰∫ÜSOTAÁªìÊûú„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§öÊ®°ÊÄÅÂ•ñÂä±Ê®°Âûã(RMs)ÁöÑÊúÄÊñ∞ËøõÂ±ïÊòæËëóÊîπÂñÑ‰∫ÜËßÜËßâÁîüÊàêÊ®°ÂûãÁöÑÂêéËÆ≠ÁªÉ„ÄÇÁÑ∂ËÄåÔºåÂΩìÂâçÁöÑRMsÈù¢‰∏¥Âõ∫ÊúâÁöÑÂ±ÄÈôêÊÄßÔºö(1)ËßÜËßâËæìÂÖ•Ê∂àËÄóÂ§ßÈáèÁöÑ‰∏ä‰∏ãÊñáÈ¢ÑÁÆóÔºåËø´‰ΩøÂáèÂ∞ëÂ∏ßÊï∞ÔºåÂØºËá¥‰∏¢Â§±ÁªÜÁ≤íÂ∫¶ÁªÜËäÇÔºõ(2)ÊâÄÊúâËßÜËßâ‰ø°ÊÅØÈÉΩË¢´ÊâìÂåÖÂà∞ÂàùÂßãÊèêÁ§∫‰∏≠ÔºåÂä†Ââß‰∫ÜÊÄùÁª¥ÈìæÊé®ÁêÜËøáÁ®ã‰∏≠ÁöÑÂπªËßâÂíåÈÅóÂøò„ÄÇ‰∏∫‰∫ÜÂÖãÊúçËøô‰∫õÈóÆÈ¢òÔºåÊàë‰ª¨ÂºïÂÖ•‰∫ÜVideoReward Thinker (VR-Thinker)ÔºåËøôÊòØ‰∏Ä‰∏™ÈÄöËøáÂõæÂÉèÊé®ÁêÜÁöÑÊ°ÜÊû∂ÔºåÂÆÉ‰∏∫RMÈÖçÂ§á‰∫ÜËßÜËßâÊé®ÁêÜÊìç‰Ωú(‰æãÂ¶ÇÔºåÈÄâÊã©Â∏ß)Âíå‰∏Ä‰∏™ÂèØÈÖçÁΩÆÁöÑËßÜËßâËÆ∞ÂøÜÁ™óÂè£„ÄÇËøô‰ΩøÂæóRMËÉΩÂ§üÂú®‰∏ä‰∏ãÊñáÈôêÂà∂ÂÜÖ‰∏ªÂä®Ëé∑ÂèñÂíåÊõ¥Êñ∞ËßÜËßâËØÅÊçÆÔºåÊèêÈ´òÊé®ÁêÜÁöÑ‰øùÁúüÂ∫¶ÂíåÂèØÈù†ÊÄß„ÄÇÊàë‰ª¨ÈÄöËøáÂº∫ÂåñÂæÆË∞ÉÁÆ°ÈÅìÊøÄÊ¥ªËßÜËßâÊé®ÁêÜÔºö(i)‰ΩøÁî®Á≤æÈÄâÁöÑËßÜËßâÊÄùÁª¥ÈìæÊï∞ÊçÆËøõË°åÂÜ∑ÂêØÂä®Ôºå‰ª•ÊèêÁÇºÂü∫Êú¨ÁöÑÊé®ÁêÜÊäÄËÉΩÂíåÊìç‰ΩúÊ†ºÂºèÔºõ(ii)ÈÄâÊã©ÊØè‰∏™Áª¥Â∫¶ÂíåÊÄª‰ΩìÂà§Êñ≠ÈÉΩÊ≠£Á°ÆÁöÑÊ†∑Êú¨ÔºåÁÑ∂ÂêéÂØπËøô‰∫õÈ´òË¥®ÈáèÁöÑËΩ®ËøπËøõË°åÊãíÁªùÈááÊ†∑ÂæÆË∞ÉÔºå‰ª•Ëøõ‰∏ÄÊ≠•Â¢ûÂº∫Êé®ÁêÜÔºõ(iii)Â∫îÁî®ÁªÑÁõ∏ÂØπÁ≠ñÁï•‰ºòÂåñ(GRPO)Êù•Âä†Âº∫Êé®ÁêÜ„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®ËßÜÈ¢ëÂÅèÂ•ΩÂü∫ÂáÜÊµãËØï‰∏≠Êèê‰æõ‰∫ÜÊúÄÂÖàËøõÁöÑÂáÜÁ°ÆÊÄßÔºåÂ∞§ÂÖ∂ÊòØÂú®ËæÉÈïøÁöÑËßÜÈ¢ë‰∏≠Ôºö‰∏Ä‰∏™7B VR-ThinkerÂú®VideoGen Reward‰∏äËææÂà∞80.5%ÔºåÂú®GenAI-Bench‰∏äËææÂà∞82.3%ÔºåÂú®MJ-Bench-Video‰∏äËææÂà∞75.6%„ÄÇËøô‰∫õÁªìÊûúÈ™åËØÅ‰∫ÜÈÄöËøáÂõæÂÉèËøõË°åÂ§öÊ®°ÊÄÅÂ•ñÂä±Âª∫Ê®°ÁöÑÊúâÊïàÊÄßÂíåÂâçÊôØ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâËßÜÈ¢ëÂ•ñÂä±Ê®°ÂûãÂú®Â§ÑÁêÜÈïøËßÜÈ¢ëÊó∂ÔºåÁî±‰∫éËßÜËßâ‰ø°ÊÅØÈáèÂ§ßÔºå‰∏ä‰∏ãÊñáÈ¢ÑÁÆóÊúâÈôêÔºåÂØºËá¥Ê®°ÂûãÊó†Ê≥ïÂÖÖÂàÜÂà©Áî®ÊâÄÊúâÂ∏ßÁöÑ‰ø°ÊÅØÔºåÂÆπÊòì‰∏¢Â§±ÁªÜËäÇÔºåÂπ∂‰∏îÂú®ÊÄùÁª¥ÈìæÊé®ÁêÜËøáÁ®ã‰∏≠Âá∫Áé∞ÂπªËßâÂíåÈÅóÂøòÁé∞Ë±°„ÄÇËøôÈôêÂà∂‰∫ÜÊ®°ÂûãÂØπËßÜÈ¢ëÂÜÖÂÆπËøõË°åÂáÜÁ°ÆÂíåÂèØÈù†ËØÑ‰º∞ÁöÑËÉΩÂäõ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöVR-ThinkerÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØËµã‰∫àÂ•ñÂä±Ê®°Âûã‚ÄúÊÄùËÄÉ‚ÄùÁöÑËÉΩÂäõÔºå‰ΩøÂÖ∂ËÉΩÂ§üÂÉè‰∫∫Á±ª‰∏ÄÊ†∑Ôºå‰∏ªÂä®ÈÄâÊã©ÂíåÂà©Áî®ÂÖ≥ÈîÆÁöÑËßÜËßâ‰ø°ÊÅØËøõË°åÊé®ÁêÜ„ÄÇÈÄöËøáÂºïÂÖ•ËßÜËßâÊé®ÁêÜÊìç‰ΩúÂíåËßÜËßâËÆ∞ÂøÜÁ™óÂè£ÔºåÊ®°ÂûãÂèØ‰ª•Âú®ÊúâÈôêÁöÑ‰∏ä‰∏ãÊñáÈ¢ÑÁÆó‰∏ãÔºåÂä®ÊÄÅÂú∞Ëé∑ÂèñÂíåÊõ¥Êñ∞ËßÜËßâËØÅÊçÆÔºå‰ªéËÄåÊèêÈ´òÊé®ÁêÜÁöÑÂáÜÁ°ÆÊÄßÂíåÂèØÈù†ÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöVR-ThinkerÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) ËßÜËßâÊé®ÁêÜÊ®°ÂùóÔºöË¥üË¥£ÊâßË°åËßÜËßâÊé®ÁêÜÊìç‰ΩúÔºå‰æãÂ¶ÇÈÄâÊã©ÂÖ≥ÈîÆÂ∏ß„ÄÇ2) ËßÜËßâËÆ∞ÂøÜÁ™óÂè£ÔºöÁî®‰∫éÂ≠òÂÇ®ÂíåÊõ¥Êñ∞ËßÜËßâËØÅÊçÆ„ÄÇ3) Â•ñÂä±Ê®°ÂûãÔºöÂü∫‰∫éËßÜËßâËØÅÊçÆËøõË°åÂ•ñÂä±È¢ÑÊµã„ÄÇËÆ≠ÁªÉËøáÁ®ãÂåÖÊã¨Ôºö(1) ÂÜ∑ÂêØÂä®Ôºö‰ΩøÁî®Á≤æÈÄâÁöÑËßÜËßâÊÄùÁª¥ÈìæÊï∞ÊçÆËøõË°åÈ¢ÑËÆ≠ÁªÉÔºåÂ≠¶‰π†Âü∫Êú¨ÁöÑÊé®ÁêÜÊäÄËÉΩÂíåÊìç‰ΩúÊ†ºÂºè„ÄÇ(2) ÊãíÁªùÈááÊ†∑ÂæÆË∞ÉÔºöÈÄâÊã©È´òË¥®ÈáèÁöÑÊé®ÁêÜËΩ®ËøπËøõË°åÂæÆË∞ÉÔºåËøõ‰∏ÄÊ≠•Â¢ûÂº∫Êé®ÁêÜËÉΩÂäõ„ÄÇ(3) ÁªÑÁõ∏ÂØπÁ≠ñÁï•‰ºòÂåñÔºö‰ΩøÁî®GRPOÁÆóÊ≥ï‰ºòÂåñÁ≠ñÁï•ÔºåÊèêÈ´òÊé®ÁêÜÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöVR-ThinkerÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫Ü‚ÄúÈÄöËøáÂõæÂÉèÊé®ÁêÜ‚ÄùÁöÑÂ§öÊ®°ÊÄÅÂ•ñÂä±Âª∫Ê®°ÊñπÊ≥ï„ÄÇ‰∏é‰º†ÁªüÁöÑÂ∞ÜÊâÄÊúâËßÜËßâ‰ø°ÊÅØÊâìÂåÖÂà∞ÂàùÂßãÊèêÁ§∫‰∏≠ÁöÑÊñπÊ≥ï‰∏çÂêåÔºåVR-ThinkerÂÖÅËÆ∏Ê®°Âûã‰∏ªÂä®Âú∞‰∏éËßÜËßâ‰ø°ÊÅØËøõË°å‰∫§‰∫íÔºåÈÄâÊã©ÂíåÂà©Áî®ÂÖ≥ÈîÆ‰ø°ÊÅØËøõË°åÊé®ÁêÜ„ÄÇËøôÁßçÊñπÊ≥ïÊõ¥Á¨¶Âêà‰∫∫Á±ªÁöÑËÆ§Áü•ËøáÁ®ãÔºåËÉΩÂ§üÊúâÊïàÂú∞ÊèêÈ´òÊé®ÁêÜÁöÑÂáÜÁ°ÆÊÄßÂíåÂèØÈù†ÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöVR-ThinkerÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö(1) ÂèØÈÖçÁΩÆÁöÑËßÜËßâËÆ∞ÂøÜÁ™óÂè£Â§ßÂ∞èÔºåÁî®‰∫éÊéßÂà∂Ê®°ÂûãÂèØ‰ª•Â≠òÂÇ®ÁöÑËßÜËßâËØÅÊçÆÊï∞Èáè„ÄÇ(2) Âü∫‰∫éÂº∫ÂåñÂ≠¶‰π†ÁöÑËÆ≠ÁªÉpipelineÔºåÂåÖÊã¨ÂÜ∑ÂêØÂä®„ÄÅÊãíÁªùÈááÊ†∑ÂæÆË∞ÉÂíåÁªÑÁõ∏ÂØπÁ≠ñÁï•‰ºòÂåñÔºåÁî®‰∫éÊúâÊïàÂú∞ËÆ≠ÁªÉËßÜËßâÊé®ÁêÜÊ®°Âùó„ÄÇ(3) ËßÜËßâÊé®ÁêÜÊìç‰ΩúÁöÑÂÖ∑‰ΩìÂÆûÁé∞Ôºå‰æãÂ¶Ç‰ΩøÁî®Ê≥®ÊÑèÂäõÊú∫Âà∂ÈÄâÊã©ÂÖ≥ÈîÆÂ∏ß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

VR-ThinkerÂú®Â§ö‰∏™ËßÜÈ¢ëÂÅèÂ•ΩÂü∫ÂáÜÊµãËØï‰∏≠ÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇ‰æãÂ¶ÇÔºå‰∏Ä‰∏™7BÂèÇÊï∞ÁöÑVR-ThinkerÊ®°ÂûãÂú®VideoGen Reward‰∏äËææÂà∞‰∫Ü80.5%ÁöÑÂáÜÁ°ÆÁéáÔºåÂú®GenAI-Bench‰∏äËææÂà∞‰∫Ü82.3%ÁöÑÂáÜÁ°ÆÁéáÔºåÂú®MJ-Bench-Video‰∏äËææÂà∞‰∫Ü75.6%ÁöÑÂáÜÁ°ÆÁéá„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéÔºåVR-ThinkerÂú®ÈïøËßÜÈ¢ëÂÅèÂ•ΩÂà§Êñ≠ÊñπÈù¢ÂÖ∑ÊúâÊòæËëó‰ºòÂäø„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

VR-ThinkerÂèØÂ∫îÁî®‰∫éËßÜÈ¢ëÁîüÊàêÊ®°ÂûãÁöÑËÆ≠ÁªÉÂíåËØÑ‰º∞Ôºå‰æãÂ¶ÇÈÄöËøáÂ•ñÂä±Ê®°ÂûãÂºïÂØºÁîüÊàêÊõ¥È´òË¥®Èáè„ÄÅÊõ¥Á¨¶Âêà‰∫∫Á±ªÂÅèÂ•ΩÁöÑËßÜÈ¢ëÂÜÖÂÆπ„ÄÇÊ≠§Â§ñÔºåËØ•ÊäÄÊúØËøòÂèØÁî®‰∫éËßÜÈ¢ëÂÜÖÂÆπÁêÜËß£„ÄÅËßÜÈ¢ëÊëòË¶Å„ÄÅËßÜÈ¢ëË¥®ÈáèËØÑ‰º∞Á≠âÈ¢ÜÂüüÔºåÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Recent advancements in multimodal reward models (RMs) have substantially improved post-training for visual generative models. However, current RMs face inherent limitations: (1) visual inputs consume large context budgets, forcing fewer frames and causing loss of fine-grained details; and (2) all visual information is packed into the initial prompt, exacerbating hallucination and forgetting during chain-of-thought reasoning. To overcome these issues, we introduce VideoReward Thinker (VR-Thinker), a thinking-with-image framework that equips the RM with visual reasoning operations (e.g., select frame) and a configurable visual memory window. This allows the RM to actively acquire and update visual evidence within context limits, improving reasoning fidelity and reliability. We activate visual reasoning via a reinforcement fine-tuning pipeline: (i) Cold Start with curated visual chain-of-thought data to distill basic reasoning skills and operation formatting; (ii) select samples whose per-dimension and overall judgments are all correct, then conduct Rejection sampling Fine-Tuning on these high-quality traces to further enhance reasoning; and (iii) apply Group Relative Policy Optimization (GRPO) to strengthen reasoning. Our approach delivers state-of-the-art accuracy among open-source models on video preference benchmarks, especially for longer videos: a 7B VR-Thinker achieves 80.5% on VideoGen Reward, 82.3% on GenAI-Bench, and 75.6% on MJ-Bench-Video. These results validate the effectiveness and promise of thinking-with-image multimodal reward modeling.

