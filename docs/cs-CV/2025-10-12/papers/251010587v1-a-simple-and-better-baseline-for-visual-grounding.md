---
layout: default
title: A Simple and Better Baseline for Visual Grounding
---

# A Simple and Better Baseline for Visual Grounding

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.10587" target="_blank" class="toolbar-btn">arXiv: 2510.10587v1</a>
    <a href="https://arxiv.org/pdf/2510.10587.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.10587v1" 
            onclick="toggleFavorite(this, '2510.10587v1', 'A Simple and Better Baseline for Visual Grounding')" title="æ”¶è—">
      â˜† æ”¶è—
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="å¤åˆ¶é“¾æ¥">
      ğŸ”— åˆ†äº«
    </button>
  </div>
</div>


**ä½œè€…**: Jingchao Wang, Wenlong Zhang, Dingjiang Huang, Hong Wang, Yefeng Zheng

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-12

**å¤‡æ³¨**: ICME2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/jcwang0602/FSVG)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºç‰¹å¾é€‰æ‹©çš„è§†è§‰å®šä½åŸºçº¿FSVGï¼Œæå‡ç²¾åº¦ä¸æ•ˆç‡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰å®šä½` `ç‰¹å¾é€‰æ‹©` `è·¨æ¨¡æ€å­¦ä¹ ` `è¯­è¨€å¼•å¯¼` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰å®šä½æ–¹æ³•éœ€åœ¨å¤šå°ºåº¦å›¾åƒä¸Šè¿­ä»£ï¼Œå¹¶ç¼“å­˜ç‰¹å¾ï¼Œè®¡ç®—å¼€é”€å¤§ã€‚
2. FSVGå°†è¯­è¨€å’Œè§†è§‰æ¨¡æ€å°è£…åˆ°ç»Ÿä¸€ç½‘ç»œï¼Œå¹¶è¡Œåˆ©ç”¨è¯­è¨€æŒ‡å¯¼è§†è§‰ç‰¹å¾æå–ã€‚
3. FSVGå¼•å…¥ç›¸ä¼¼åº¦ç‰¹å¾é€‰æ‹©æœºåˆ¶ï¼Œä»…åˆ©ç”¨ç›¸å…³è§†è§‰ç‰¹å¾ï¼Œæå‡é¢„æµ‹é€Ÿåº¦ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰å®šä½æ—¨åœ¨é¢„æµ‹æ–‡æœ¬æè¿°æ‰€æŒ‡å®šçš„ç›®æ ‡ç‰©ä½“çš„ä½ç½®ã€‚ç›®å‰çš„ç ”ç©¶è¶‹åŠ¿æ˜¯ä¾§é‡äºé€‰æ‹©ä¸è¯­è¨€ç›¸å…³çš„è§†è§‰åŒºåŸŸè¿›è¡Œç›®æ ‡å®šä½ï¼Œä»¥å‡å°‘è®¡ç®—å¼€é”€ã€‚å°½ç®¡è¿™ç§æ–¹æ³•å–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„æ€§èƒ½ï¼Œä½†å®ƒéœ€è¦åœ¨ä¸åŒçš„å›¾åƒå°ºåº¦ä¸Šè¿­ä»£æ‰§è¡Œï¼Œå¹¶ä¸”æ¯æ¬¡è¿­ä»£éƒ½éœ€è¦å°†è¯­è¨€ç‰¹å¾å’Œè§†è§‰ç‰¹å¾å­˜å‚¨åœ¨ç¼“å­˜ä¸­ï¼Œä»è€Œäº§ç”Ÿé¢å¤–çš„å¼€é”€ã€‚ä¸ºäº†ç®€åŒ–å®ç°ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºç‰¹å¾é€‰æ‹©çš„ç®€å•è€Œæœ‰æ•ˆçš„è§†è§‰å®šä½åŸºçº¿ï¼Œç§°ä¸ºFSVGã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ç›´æ¥å°†è¯­è¨€å’Œè§†è§‰æ¨¡æ€å°è£…åˆ°ä¸€ä¸ªæ•´ä½“ç½‘ç»œæ¶æ„ä¸­ï¼Œæ— éœ€å¤æ‚çš„è¿­ä»£è¿‡ç¨‹ï¼Œå¹¶å¹¶è¡Œåœ°åˆ©ç”¨è¯­è¨€ä½œä¸ºæŒ‡å¯¼ï¼Œä¿ƒè¿›è¯­è¨€æ¨¡æ€å’Œè§†è§‰æ¨¡æ€ä¹‹é—´çš„äº¤äº’ï¼Œä»¥æå–æœ‰æ•ˆçš„è§†è§‰ç‰¹å¾ã€‚æ­¤å¤–ï¼Œä¸ºäº†é™ä½è®¡ç®—æˆæœ¬ï¼Œåœ¨è§†è§‰ç‰¹å¾å­¦ä¹ è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åŸºäºç›¸ä¼¼åº¦çš„ç‰¹å¾é€‰æ‹©æœºåˆ¶ï¼Œä»…åˆ©ç”¨ä¸è¯­è¨€ç›¸å…³çš„è§†è§‰ç‰¹å¾è¿›è¡Œæ›´å¿«çš„é¢„æµ‹ã€‚åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¤§é‡å®éªŒå…¨é¢è¯å®ï¼Œæ‰€æå‡ºçš„FSVGåœ¨ç²¾åº¦å’Œæ•ˆç‡ä¹‹é—´å–å¾—äº†æ¯”å½“å‰æœ€å…ˆè¿›æ–¹æ³•æ›´å¥½çš„å¹³è¡¡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè§†è§‰å®šä½æ—¨åœ¨æ ¹æ®ç»™å®šçš„æ–‡æœ¬æè¿°ï¼Œåœ¨å›¾åƒä¸­æ‰¾åˆ°å¯¹åº”çš„ç›®æ ‡ç‰©ä½“çš„ä½ç½®ã€‚ç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯é‚£äº›åŸºäºç‰¹å¾é€‰æ‹©çš„æ–¹æ³•ï¼Œè™½ç„¶åœ¨ç²¾åº¦ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†é€šå¸¸éœ€è¦åœ¨ä¸åŒçš„å›¾åƒå°ºåº¦ä¸Šè¿›è¡Œå¤šæ¬¡è¿­ä»£ï¼Œå¹¶ä¸”æ¯æ¬¡è¿­ä»£éƒ½éœ€è¦ç¼“å­˜è¯­è¨€å’Œè§†è§‰ç‰¹å¾ï¼Œå¯¼è‡´è®¡ç®—å¼€é”€æ˜¾è‘—å¢åŠ ï¼Œå®ç°å¤æ‚æ€§ä¹Ÿè¾ƒé«˜ã€‚è¿™äº›ç—›ç‚¹é™åˆ¶äº†å®ƒä»¬åœ¨å®é™…åº”ç”¨ä¸­çš„éƒ¨ç½²ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šFSVGçš„æ ¸å¿ƒæ€è·¯æ˜¯ç®€åŒ–è§†è§‰å®šä½æµç¨‹ï¼Œé€šè¿‡ä¸€ä¸ªç«¯åˆ°ç«¯çš„ç½‘ç»œç»“æ„ç›´æ¥æ•´åˆè¯­è¨€å’Œè§†è§‰ä¿¡æ¯ï¼Œé¿å…äº†å¤šå°ºåº¦è¿­ä»£å’Œç‰¹å¾ç¼“å­˜ã€‚å®ƒå¹¶è¡Œåœ°åˆ©ç”¨è¯­è¨€ä¿¡æ¯æ¥æŒ‡å¯¼è§†è§‰ç‰¹å¾çš„æå–ï¼Œä»è€Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å…³æ³¨ä¸æ–‡æœ¬æè¿°ç›¸å…³çš„è§†è§‰åŒºåŸŸã€‚æ­¤å¤–ï¼Œé€šè¿‡å¼•å…¥åŸºäºç›¸ä¼¼åº¦çš„ç‰¹å¾é€‰æ‹©æœºåˆ¶ï¼Œè¿›ä¸€æ­¥å‡å°‘äº†è®¡ç®—é‡ï¼Œæé«˜äº†é¢„æµ‹é€Ÿåº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFSVGçš„æ•´ä½“æ¶æ„åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) è¯­è¨€ç‰¹å¾æå–æ¨¡å—ï¼šç”¨äºæå–æ–‡æœ¬æè¿°çš„è¯­è¨€ç‰¹å¾ã€‚2) è§†è§‰ç‰¹å¾æå–æ¨¡å—ï¼šç”¨äºæå–å›¾åƒçš„è§†è§‰ç‰¹å¾ã€‚3) è·¨æ¨¡æ€äº¤äº’æ¨¡å—ï¼šè¯¥æ¨¡å—å°†è¯­è¨€ç‰¹å¾ä½œä¸ºæŒ‡å¯¼ï¼Œä¿ƒè¿›è¯­è¨€å’Œè§†è§‰ç‰¹å¾ä¹‹é—´çš„äº¤äº’ï¼Œä»è€Œæå–ä¸è¯­è¨€ç›¸å…³çš„è§†è§‰ç‰¹å¾ã€‚4) ç‰¹å¾é€‰æ‹©æ¨¡å—ï¼šåŸºäºè¯­è¨€ç‰¹å¾å’Œè§†è§‰ç‰¹å¾ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œé€‰æ‹©ä¸è¯­è¨€æœ€ç›¸å…³çš„è§†è§‰ç‰¹å¾ã€‚5) å®šä½é¢„æµ‹æ¨¡å—ï¼šåˆ©ç”¨é€‰æ‹©åçš„è§†è§‰ç‰¹å¾é¢„æµ‹ç›®æ ‡ç‰©ä½“çš„ä½ç½®ã€‚

**å…³é”®åˆ›æ–°**ï¼šFSVGçš„å…³é”®åˆ›æ–°åœ¨äºå…¶ç®€æ´çš„ç«¯åˆ°ç«¯æ¶æ„å’ŒåŸºäºç›¸ä¼¼åº¦çš„ç‰¹å¾é€‰æ‹©æœºåˆ¶ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒFSVGé¿å…äº†å¤æ‚çš„å¤šå°ºåº¦è¿­ä»£å’Œç‰¹å¾ç¼“å­˜ï¼Œä»è€Œæ˜¾è‘—é™ä½äº†è®¡ç®—å¼€é”€ã€‚åŒæ—¶ï¼Œé€šè¿‡å¹¶è¡Œåœ°åˆ©ç”¨è¯­è¨€ä¿¡æ¯æ¥æŒ‡å¯¼è§†è§‰ç‰¹å¾çš„æå–ï¼Œæé«˜äº†ç‰¹å¾çš„æœ‰æ•ˆæ€§ã€‚åŸºäºç›¸ä¼¼åº¦çš„ç‰¹å¾é€‰æ‹©æœºåˆ¶è¿›ä¸€æ­¥å‡å°‘äº†è®¡ç®—é‡ï¼Œæé«˜äº†é¢„æµ‹é€Ÿåº¦ã€‚è¿™äº›åˆ›æ–°ä½¿å¾—FSVGåœ¨ç²¾åº¦å’Œæ•ˆç‡ä¹‹é—´å–å¾—äº†æ›´å¥½çš„å¹³è¡¡ã€‚

**å…³é”®è®¾è®¡**ï¼šFSVGçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) å¹¶è¡Œè¯­è¨€æŒ‡å¯¼ï¼šè¯­è¨€ç‰¹å¾è¢«å¹¶è¡Œåœ°ç”¨äºæŒ‡å¯¼è§†è§‰ç‰¹å¾çš„æå–ï¼Œä»è€Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å…³æ³¨ä¸æ–‡æœ¬æè¿°ç›¸å…³çš„è§†è§‰åŒºåŸŸã€‚2) ç›¸ä¼¼åº¦åº¦é‡ï¼šä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ç­‰æ–¹æ³•æ¥è¡¡é‡è¯­è¨€ç‰¹å¾å’Œè§†è§‰ç‰¹å¾ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œä»è€Œé€‰æ‹©ä¸è¯­è¨€æœ€ç›¸å…³çš„è§†è§‰ç‰¹å¾ã€‚3) æŸå¤±å‡½æ•°ï¼šä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°æˆ–IoUæŸå¤±å‡½æ•°æ¥è®­ç»ƒå®šä½é¢„æµ‹æ¨¡å—ï¼Œä»¥æé«˜å®šä½ç²¾åº¦ã€‚4) ç½‘ç»œç»“æ„ï¼šå¯ä»¥ä½¿ç”¨ResNetã€BERTç­‰é¢„è®­ç»ƒæ¨¡å‹ä½œä¸ºè§†è§‰å’Œè¯­è¨€ç‰¹å¾æå–æ¨¡å—çš„éª¨å¹²ç½‘ç»œã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒFSVGåœ¨ç²¾åº¦å’Œæ•ˆç‡ä¹‹é—´å–å¾—äº†æ¯”å½“å‰æœ€å…ˆè¿›æ–¹æ³•æ›´å¥½çš„å¹³è¡¡ã€‚ä¾‹å¦‚ï¼Œåœ¨RefCOCOæ•°æ®é›†ä¸Šï¼ŒFSVGåœ¨ä¿è¯ç²¾åº¦çš„å‰æä¸‹ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—æ—¶é—´ã€‚ä»£ç å·²å¼€æºï¼Œæ–¹ä¾¿ç ”ç©¶äººå‘˜å¤ç°å’Œè¿›ä¸€æ­¥ç ”ç©¶ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

FSVGå¯åº”ç”¨äºæ™ºèƒ½å›¾åƒæœç´¢ã€è§†è§‰é—®ç­”ã€æœºå™¨äººå¯¼èˆªç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨æ™ºèƒ½å›¾åƒæœç´¢ä¸­ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡æ–‡æœ¬æè¿°å¿«é€Ÿæ‰¾åˆ°å›¾åƒä¸­å¯¹åº”çš„ç‰©ä½“ï¼›åœ¨è§†è§‰é—®ç­”ä¸­ï¼ŒFSVGå¯ä»¥å¸®åŠ©æ¨¡å‹æ›´å‡†ç¡®åœ°ç†è§£é—®é¢˜å¹¶æ‰¾åˆ°ç­”æ¡ˆï¼›åœ¨æœºå™¨äººå¯¼èˆªä¸­ï¼Œæœºå™¨äººå¯ä»¥æ ¹æ®æŒ‡ä»¤æ‰¾åˆ°ç›®æ ‡ç‰©ä½“å¹¶æ‰§è¡Œç›¸åº”çš„æ“ä½œã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºæå‡äººæœºäº¤äº’çš„è‡ªç„¶æ€§å’Œæ•ˆç‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Visual grounding aims to predict the locations of target objects specified by textual descriptions. For this task with linguistic and visual modalities, there is a latest research line that focuses on only selecting the linguistic-relevant visual regions for object localization to reduce the computational overhead. Albeit achieving impressive performance, it is iteratively performed on different image scales, and at every iteration, linguistic features and visual features need to be stored in a cache, incurring extra overhead. To facilitate the implementation, in this paper, we propose a feature selection-based simple yet effective baseline for visual grounding, called FSVG. Specifically, we directly encapsulate the linguistic and visual modalities into an overall network architecture without complicated iterative procedures, and utilize the language in parallel as guidance to facilitate the interaction between linguistic modal and visual modal for extracting effective visual features. Furthermore, to reduce the computational cost, during the visual feature learning, we introduce a similarity-based feature selection mechanism to only exploit language-related visual features for faster prediction. Extensive experiments conducted on several benchmark datasets comprehensively substantiate that the proposed FSVG achieves a better balance between accuracy and efficiency beyond the current state-of-the-art methods. Code is available at https://github.com/jcwang0602/FSVG.

