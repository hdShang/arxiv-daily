---
layout: default
title: Multimodal Retrieval-Augmented Generation with Large Language Models for Medical VQA
---

# Multimodal Retrieval-Augmented Generation with Large Language Models for Medical VQA

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.13856" target="_blank" class="toolbar-btn">arXiv: 2510.13856v1</a>
    <a href="https://arxiv.org/pdf/2510.13856.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.13856v1" 
            onclick="toggleFavorite(this, '2510.13856v1', 'Multimodal Retrieval-Augmented Generation with Large Language Models for Medical VQA')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: A H M Rezaul Karim, Ozlem Uzuner

**ÂàÜÁ±ª**: cs.CL, cs.AI, cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-12

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**MasonNLPÊèêÂá∫Âü∫‰∫éÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÂíåÈÄöÁî®Â§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÂåªÁñóVQAÊñπÊ≥ïÔºåÂú®MEDIQA-WV 2025Á´ûËµõ‰∏≠ÊéíÂêçÁ¨¨‰∏â„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÂåªÂ≠¶ËßÜËßâÈóÆÁ≠î` `Ê£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàê` `Â§ßËØ≠Ë®ÄÊ®°Âûã` `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `‰∏¥Â∫äÂÜ≥Á≠ñÊîØÊåÅ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ÂåªÂ≠¶ËßÜËßâÈóÆÁ≠îÈù¢‰∏¥ÊåëÊàòÔºåÈúÄË¶ÅÁ≥ªÁªüËÉΩÂ§üÁêÜËß£ÂõæÂÉèÂíåÊñáÊú¨‰ø°ÊÅØÔºåÂπ∂ÁîüÊàêÂáÜÁ°Æ„ÄÅÁ¨¶Âêà‰∏¥Â∫äËßÑËåÉÁöÑÁ≠îÊ°à„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫Âà©Áî®Ê£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºàRAGÔºâÊ°ÜÊû∂ÔºåÁªìÂêàÈÄöÁî®Â§ßËØ≠Ë®ÄÊ®°ÂûãÔºå‰ªéÈ¢ÜÂüüÂÜÖÊï∞ÊçÆ‰∏≠Ê£ÄÁ¥¢Áõ∏ÂÖ≥Á§∫‰æãÔºåËæÖÂä©Á≠îÊ°àÁîüÊàê„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®MEDIQA-WV 2025Á´ûËµõ‰∏≠ÂèñÂæó‰∫ÜÁ¨¨‰∏âÂêçÁöÑÊàêÁª©ÔºåÈ™åËØÅ‰∫ÜÂÖ∂Âú®Â§öÊ®°ÊÄÅ‰∏¥Â∫äNLP‰ªªÂä°‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÂåªÂ≠¶ËßÜËßâÈóÆÁ≠î(MedVQA)ÈÄöËøáÂåªÂ≠¶ÂõæÂÉè‰∏äÁöÑËá™ÁÑ∂ËØ≠Ë®ÄÊü•ËØ¢Êù•ÊîØÊåÅ‰∏¥Â∫äÂÜ≥Á≠ñÂíåÊÇ£ËÄÖÊä§ÁêÜ„ÄÇMEDIQA-WV 2025ÂÖ±‰∫´‰ªªÂä°ÂÖ≥Ê≥®‰º§Âè£Êä§ÁêÜVQAÔºåË¶ÅÊ±ÇÁ≥ªÁªü‰ªéÂõæÂÉèÂíåÊÇ£ËÄÖÊü•ËØ¢‰∏≠ÁîüÊàêËá™Áî±ÊñáÊú¨ÂìçÂ∫îÂíåÁªìÊûÑÂåñ‰º§Âè£Â±ûÊÄß„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫ÜMasonNLPÁ≥ªÁªüÔºåËØ•Á≥ªÁªüÈááÁî®ÈÄöÁî®È¢ÜÂüüÁöÑ„ÄÅÊåá‰ª§Ë∞É‰ºòÁöÑÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºåÂπ∂ÁªìÂêàÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàê(RAG)Ê°ÜÊû∂ÔºåËØ•Ê°ÜÊû∂Êï¥Âêà‰∫ÜÊù•Ëá™È¢ÜÂüüÂÜÖÊï∞ÊçÆÁöÑÊñáÊú¨ÂíåËßÜËßâÁ§∫‰æã„ÄÇËøôÁßçÊñπÊ≥ïÂ∞ÜËæìÂá∫Âª∫Á´ãÂú®‰∏¥Â∫äÁõ∏ÂÖ≥ÁöÑÁ§∫‰æã‰πã‰∏äÔºå‰ªéËÄåÊèêÈ´ò‰∫ÜÊé®ÁêÜ„ÄÅÊ®°ÂºèÈÅµÂæ™ÂíåÂìçÂ∫îË¥®ÈáèÔºåÈÄöËøádBLEU„ÄÅROUGE„ÄÅBERTScoreÂíåÂü∫‰∫éLLMÁöÑÊåáÊ†áËøõË°åËØÑ‰º∞„ÄÇÊàë‰ª¨Ë°®Áé∞ÊúÄ‰Ω≥ÁöÑÁ≥ªÁªüÂú®19‰∏™Âõ¢ÈòüÂíå51‰∏™Êèê‰∫§‰∏≠ÊéíÂêçÁ¨¨‰∏âÔºåÂπ≥ÂùáÂæóÂàÜ41.37%ÔºåËøôË°®ÊòéËΩªÈáèÁ∫ßRAG‰∏éÈÄöÁî®LLMÁõ∏ÁªìÂêà‚Äî‚Äî‰∏Ä‰∏™ÊúÄÂ∞èÁöÑÊé®ÁêÜÊó∂Â±ÇÔºåÈÄöËøáÁÆÄÂçïÁöÑÁ¥¢ÂºïÂíåËûçÂêàÊ∑ªÂä†‰∏Ä‰∫õÁõ∏ÂÖ≥ÁöÑÁ§∫‰æãÔºåÊó†ÈúÄÈ¢ùÂ§ñÁöÑËÆ≠ÁªÉÊàñÂ§çÊùÇÁöÑÈáçÊñ∞ÊéíÂ∫è‚Äî‚Äî‰∏∫Â§öÊ®°ÊÄÅ‰∏¥Â∫äNLP‰ªªÂä°Êèê‰æõ‰∫Ü‰∏Ä‰∏™ÁÆÄÂçïËÄåÊúâÊïàÁöÑÂü∫Á∫ø„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥ÂåªÂ≠¶ËßÜËßâÈóÆÁ≠îÔºàMedVQAÔºâ‰ªªÂä°‰∏≠ÔºåÂ¶Ç‰ΩïÂà©Áî®ÂõæÂÉèÂíåÊñáÊú¨‰ø°ÊÅØÁîüÊàêÈ´òË¥®ÈáèÁ≠îÊ°àÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®Â§ÑÁêÜÂ§çÊùÇÂåªÂ≠¶ÂõæÂÉèÂíå‰∏¥Â∫äÈóÆÈ¢òÊó∂ÔºåÂæÄÂæÄÁº∫‰πèË∂≥Â§üÁöÑÈ¢ÜÂüüÁü•ËØÜÔºåÂØºËá¥Á≠îÊ°àÂáÜÁ°ÆÊÄßÂíå‰∏¥Â∫äÁõ∏ÂÖ≥ÊÄß‰∏çË∂≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Ê£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºàRAGÔºâÊ°ÜÊû∂ÔºåÈÄöËøáÊ£ÄÁ¥¢È¢ÜÂüüÂÜÖÁõ∏ÂÖ≥ÁöÑÊñáÊú¨ÂíåËßÜËßâÁ§∫‰æãÔºå‰∏∫Â§ßËØ≠Ë®ÄÊ®°ÂûãÊèê‰æõÈ¢ùÂ§ñÁöÑ‰∏ä‰∏ãÊñá‰ø°ÊÅØÔºå‰ªéËÄåÊèêÈ´òÁ≠îÊ°àÁöÑË¥®ÈáèÂíåÂáÜÁ°ÆÊÄß„ÄÇËøôÁßçÊñπÊ≥ïÊó†ÈúÄÂØπÂ§ßËØ≠Ë®ÄÊ®°ÂûãËøõË°åÈ¢ùÂ§ñÁöÑËÆ≠ÁªÉÔºåÂç≥ÂèØÊúâÊïàÊèêÂçáÂÖ∂Âú®ÁâπÂÆöÈ¢ÜÂüüÁöÑË°®Áé∞„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) Êü•ËØ¢ÁºñÁ†ÅÔºöÂ∞ÜËæìÂÖ•ÁöÑÂõæÂÉèÂíåÊñáÊú¨Êü•ËØ¢ÁºñÁ†ÅÊàêÂêëÈáèË°®Á§∫„ÄÇ2) Ê£ÄÁ¥¢ÔºöÂà©Áî®ÁºñÁ†ÅÂêéÁöÑÊü•ËØ¢ÂêëÈáèÔºå‰ªéÈ¢ÜÂüüÂÜÖÊï∞ÊçÆÈõÜ‰∏≠Ê£ÄÁ¥¢Áõ∏ÂÖ≥ÁöÑÊñáÊú¨ÂíåËßÜËßâÁ§∫‰æã„ÄÇ3) ÁîüÊàêÔºöÂ∞ÜÊ£ÄÁ¥¢Âà∞ÁöÑÁ§∫‰æã‰∏éÂéüÂßãÊü•ËØ¢‰∏ÄËµ∑ËæìÂÖ•Âà∞Â§ßËØ≠Ë®ÄÊ®°Âûã‰∏≠ÔºåÁîüÊàêÊúÄÁªàÁöÑÁ≠îÊ°à„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÂ∞ÜÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºàRAGÔºâÊ°ÜÊû∂Â∫îÁî®‰∫éÂåªÂ≠¶ËßÜËßâÈóÆÁ≠î‰ªªÂä°ÔºåÂπ∂ÁªìÂêàÈÄöÁî®Â§ßËØ≠Ë®ÄÊ®°ÂûãÔºåÂÆûÁé∞‰∫ÜÂú®Êó†ÈúÄÈ¢ùÂ§ñËÆ≠ÁªÉÁöÑÊÉÖÂÜµ‰∏ãÔºåÊúâÊïàÊèêÂçáÁ≠îÊ°àË¥®ÈáèÂíå‰∏¥Â∫äÁõ∏ÂÖ≥ÊÄß„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïÈááÁî®ËΩªÈáèÁ∫ßÁöÑRAGÔºåÈÅøÂÖç‰∫ÜÂ§çÊùÇÁöÑÈáçÊñ∞ÊéíÂ∫èÂíåËÆ≠ÁªÉËøáÁ®ãÔºåÈôç‰Ωé‰∫ÜËÆ°ÁÆóÊàêÊú¨„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËÆ∫ÊñáÈááÁî®ÈÄöÁî®È¢ÜÂüüÁöÑ„ÄÅÊåá‰ª§Ë∞É‰ºòÁöÑÂ§ßËØ≠Ë®ÄÊ®°Âûã‰Ωú‰∏∫ÁîüÊàêÂô®„ÄÇÊ£ÄÁ¥¢Ê®°Âùó‰ΩøÁî®ÁÆÄÂçïÁöÑÁ¥¢ÂºïÂíåËûçÂêàÊñπÊ≥ïÔºåÂ∞ÜÊ£ÄÁ¥¢Âà∞ÁöÑÊñáÊú¨ÂíåËßÜËßâÁ§∫‰æã‰∏éÂéüÂßãÊü•ËØ¢ËøõË°åËûçÂêà„ÄÇÊ≤°ÊúâÊèêÂèäÂÖ∑‰ΩìÁöÑÊçüÂ§±ÂáΩÊï∞ÊàñÁΩëÁªúÁªìÊûÑÁªÜËäÇÔºåÈáçÁÇπÂú®‰∫éRAGÊ°ÜÊû∂ÁöÑÊúâÊïàÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

MasonNLPÁ≥ªÁªüÂú®MEDIQA-WV 2025‰º§Âè£Êä§ÁêÜVQAÂÖ±‰∫´‰ªªÂä°‰∏≠ÊéíÂêçÁ¨¨‰∏âÔºåÂπ≥ÂùáÂæóÂàÜ41.37%„ÄÇËØ•ÁªìÊûúË°®ÊòéÔºåËΩªÈáèÁ∫ßRAG‰∏éÈÄöÁî®Â§ßËØ≠Ë®ÄÊ®°ÂûãÁõ∏ÁªìÂêàÔºåÊó†ÈúÄÈ¢ùÂ§ñËÆ≠ÁªÉÊàñÂ§çÊùÇÈáçÊéíÂ∫èÔºåÂç≥ÂèØ‰∏∫Â§öÊ®°ÊÄÅ‰∏¥Â∫äNLP‰ªªÂä°Êèê‰æõÁÆÄÂçïÊúâÊïàÁöÑÂü∫Á∫ø„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫é‰∏¥Â∫äÂÜ≥Á≠ñÊîØÊåÅÁ≥ªÁªüÔºåËæÖÂä©ÂåªÁîüËøõË°åËØäÊñ≠ÂíåÊ≤ªÁñóÊñπÊ°àÂà∂ÂÆö„ÄÇÈÄöËøáÊèê‰æõÂü∫‰∫éÂõæÂÉèÂíåÊñáÊú¨Êü•ËØ¢ÁöÑÊô∫ËÉΩÈóÆÁ≠îÊúçÂä°ÔºåÂèØ‰ª•ÊèêÈ´òÂåªÁñóÊïàÁéáÔºåÊîπÂñÑÊÇ£ËÄÖÊä§ÁêÜË¥®Èáè„ÄÇÊú™Êù•ÔºåËØ•ÊäÄÊúØÊúâÊúõÊâ©Â±ïÂà∞ÂÖ∂‰ªñÂåªÂ≠¶È¢ÜÂüüÔºå‰æãÂ¶ÇÁóÖÁêÜÂõæÂÉèÂàÜÊûê„ÄÅÂü∫Âõ†ÁªÑÂ≠¶Á≠â„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Medical Visual Question Answering (MedVQA) enables natural language queries over medical images to support clinical decision-making and patient care. The MEDIQA-WV 2025 shared task addressed wound-care VQA, requiring systems to generate free-text responses and structured wound attributes from images and patient queries. We present the MasonNLP system, which employs a general-domain, instruction-tuned large language model with a retrieval-augmented generation (RAG) framework that incorporates textual and visual examples from in-domain data. This approach grounds outputs in clinically relevant exemplars, improving reasoning, schema adherence, and response quality across dBLEU, ROUGE, BERTScore, and LLM-based metrics. Our best-performing system ranked 3rd among 19 teams and 51 submissions with an average score of 41.37%, demonstrating that lightweight RAG with general-purpose LLMs -- a minimal inference-time layer that adds a few relevant exemplars via simple indexing and fusion, with no extra training or complex re-ranking -- provides a simple and effective baseline for multimodal clinical NLP tasks.

