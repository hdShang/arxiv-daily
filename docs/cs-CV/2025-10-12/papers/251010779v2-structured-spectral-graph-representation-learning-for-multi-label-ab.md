---
layout: default
title: Structured Spectral Graph Representation Learning for Multi-label Abnormality Analysis from 3D CT Scans
---

# Structured Spectral Graph Representation Learning for Multi-label Abnormality Analysis from 3D CT Scans

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.10779" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.10779v2</a>
  <a href="https://arxiv.org/pdf/2510.10779.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.10779v2" onclick="toggleFavorite(this, '2510.10779v2', 'Structured Spectral Graph Representation Learning for Multi-label Abnormality Analysis from 3D CT Scans')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Theo Di Piazza, Carole Lazarus, Olivier Nempont, Loic Boussel

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-12 (æ›´æ–°: 2025-10-23)

**å¤‡æ³¨**: 24 pages, 15 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºç»“æ„åŒ–è°±å›¾è¡¨ç¤ºå­¦ä¹ çš„3D CTå¤šæ ‡ç­¾å¼‚å¸¸åˆ†ææ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)**

**å…³é”®è¯**: `3D CTæ‰«æ` `å¤šæ ‡ç­¾åˆ†ç±»` `è°±å›¾å·ç§¯` `åŒ»å­¦å½±åƒåˆ†æ` `å¼‚å¸¸æ£€æµ‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. 3D CTå¤šæ ‡ç­¾å¼‚å¸¸åˆ†æé¢ä¸´æŒ‘æˆ˜ï¼Œç°æœ‰3D CNNéš¾ä»¥æ•æ‰é•¿ç¨‹ä¾èµ–ï¼ŒVision Transformerä¾èµ–å¤§è§„æ¨¡é¢„è®­ç»ƒã€‚
2. æå‡ºä¸€ç§åŸºäºç»“æ„åŒ–å›¾çš„2.5Dæ–¹æ³•ï¼Œå°†3D CTè¡¨ç¤ºä¸ºå›¾ï¼Œåˆ©ç”¨è°±å›¾å·ç§¯å¤„ç†åˆ‡ç‰‡é—´ä¾èµ–ã€‚
3. åœ¨ä¸‰ä¸ªæ•°æ®é›†ä¸ŠéªŒè¯ï¼Œå®ç°è·¨æ•°æ®é›†æ³›åŒ–ï¼Œæ€§èƒ½ä¸SOTAè§†è§‰ç¼–ç å™¨ç›¸å½“ï¼Œå¹¶æ‰©å±•åˆ°æŠ¥å‘Šç”Ÿæˆã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€CTæ£€æŸ¥æ•°é‡çš„å¢é•¿ï¼Œå¯¹è‡ªåŠ¨åŒ–å·¥å…·ï¼ˆå¦‚å™¨å®˜åˆ†å‰²ã€å¼‚å¸¸æ£€æµ‹å’ŒæŠ¥å‘Šç”Ÿæˆï¼‰çš„éœ€æ±‚æ—¥ç›Šå¢åŠ ï¼Œä»¥æ”¯æŒæ”¾å°„ç§‘åŒ»ç”Ÿç®¡ç†ä¸´åºŠå·¥ä½œé‡ã€‚3Dèƒ¸éƒ¨CTæ‰«æçš„å¤šæ ‡ç­¾åˆ†ç±»ä»ç„¶æ˜¯ä¸€ä¸ªå…³é”®ä½†å…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ï¼Œå› ä¸ºå®¹ç§¯æ•°æ®ä¸­å›ºæœ‰çš„å¤æ‚ç©ºé—´å…³ç³»å’Œå¼‚å¸¸çš„å¹¿æ³›å˜å¼‚æ€§ã€‚ç°æœ‰çš„åŸºäº3Då·ç§¯ç¥ç»ç½‘ç»œçš„æ–¹æ³•éš¾ä»¥æ•æ‰é•¿ç¨‹ä¾èµ–å…³ç³»ï¼Œè€ŒVision Transformersé€šå¸¸éœ€è¦åœ¨å¤§è§„æ¨¡ã€ç‰¹å®šé¢†åŸŸçš„æ•°æ®é›†ä¸Šè¿›è¡Œå¹¿æ³›çš„é¢„è®­ç»ƒæ‰èƒ½è¡¨ç°å‡ºç«äº‰åŠ›ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§2.5Dæ›¿ä»£æ–¹æ¡ˆï¼Œå¼•å…¥äº†ä¸€ç§æ–°çš„åŸºäºå›¾çš„æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å°†3D CTä½“æ•°æ®è¡¨ç¤ºä¸ºç»“æ„åŒ–å›¾ï¼Œå…¶ä¸­è½´å‘åˆ‡ç‰‡ä¸‰å…ƒç»„ä½œä¸ºèŠ‚ç‚¹ï¼Œé€šè¿‡è°±å›¾å·ç§¯è¿›è¡Œå¤„ç†ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ¨ç†åˆ‡ç‰‡é—´çš„ä¾èµ–å…³ç³»ï¼ŒåŒæ—¶ä¿æŒä¸ä¸´åºŠéƒ¨ç½²å…¼å®¹çš„å¤æ‚åº¦ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨æ¥è‡ªç‹¬ç«‹æœºæ„çš„3ä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ï¼Œå®ç°äº†å¼ºå¤§çš„è·¨æ•°æ®é›†æ³›åŒ–ï¼Œå¹¶æ˜¾ç¤ºå‡ºä¸æœ€å…ˆè¿›çš„è§†è§‰ç¼–ç å™¨ç›¸æ¯”å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥è¿›è¡Œäº†å…¨é¢çš„æ¶ˆèç ”ç©¶ï¼Œä»¥è¯„ä¼°å„ç§èšåˆç­–ç•¥ã€è¾¹ç¼˜åŠ æƒæ–¹æ¡ˆå’Œå›¾è¿æ¥æ¨¡å¼çš„å½±å“ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é€šè¿‡åœ¨è‡ªåŠ¨æ”¾å°„æŠ¥å‘Šç”Ÿæˆå’Œè…¹éƒ¨CTæ•°æ®ä¸Šçš„è¿ç§»å®éªŒï¼Œè¯æ˜äº†æˆ‘ä»¬æ–¹æ³•çš„æ›´å¹¿æ³›é€‚ç”¨æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³3D CTæ‰«æå›¾åƒä¸­å¤šæ ‡ç­¾å¼‚å¸¸åˆ†æçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚3D CNNï¼Œéš¾ä»¥æ•æ‰CTå›¾åƒä¸­å­˜åœ¨çš„é•¿ç¨‹ä¾èµ–å…³ç³»ï¼Œè€ŒVision Transformeréœ€è¦å¤§é‡ç‰¹å®šé¢†åŸŸçš„æ•°æ®è¿›è¡Œé¢„è®­ç»ƒï¼Œè¿™åœ¨å®é™…åº”ç”¨ä¸­å¯èƒ½éš¾ä»¥æ»¡è¶³ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§èƒ½å¤Ÿæœ‰æ•ˆå»ºæ¨¡é•¿ç¨‹ä¾èµ–å…³ç³»ï¼ŒåŒæ—¶å¯¹æ•°æ®é‡éœ€æ±‚è¾ƒä½çš„æ–¹æ³•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†3D CTä½“æ•°æ®è½¬æ¢ä¸ºç»“æ„åŒ–çš„å›¾è¡¨ç¤ºï¼Œåˆ©ç”¨å›¾ç¥ç»ç½‘ç»œæ¥å»ºæ¨¡åˆ‡ç‰‡ä¹‹é—´çš„ä¾èµ–å…³ç³»ã€‚é€šè¿‡å°†ç›¸é‚»çš„è½´å‘åˆ‡ç‰‡ä¸‰å…ƒç»„ä½œä¸ºå›¾çš„èŠ‚ç‚¹ï¼Œå¹¶åˆ©ç”¨è°±å›¾å·ç§¯æ¥å¤„ç†è¿™äº›èŠ‚ç‚¹ï¼Œæ¨¡å‹å¯ä»¥æœ‰æ•ˆåœ°å­¦ä¹ åˆ‡ç‰‡ä¹‹é—´çš„ç©ºé—´å…³ç³»å’Œé•¿ç¨‹ä¾èµ–ã€‚è¿™ç§æ–¹æ³•åœ¨é™ä½è®¡ç®—å¤æ‚åº¦çš„åŒæ—¶ï¼Œä¿ç•™äº†3Dä¿¡æ¯çš„å…³é”®ç‰¹å¾ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) **æ•°æ®é¢„å¤„ç†**ï¼šå°†3D CTæ‰«ææ•°æ®åˆ†å‰²æˆä¸€ç³»åˆ—è½´å‘åˆ‡ç‰‡ã€‚2) **å›¾æ„å»º**ï¼šå°†ç›¸é‚»çš„ä¸‰ä¸ªè½´å‘åˆ‡ç‰‡ç»„æˆä¸€ä¸ªèŠ‚ç‚¹ï¼Œæ„å»ºå›¾ç»“æ„ã€‚èŠ‚ç‚¹ä¹‹é—´çš„è¿æ¥æ–¹å¼å¯ä»¥æ ¹æ®ä¸åŒçš„ç­–ç•¥è¿›è¡Œé€‰æ‹©ï¼Œä¾‹å¦‚kè¿‘é‚»æˆ–å…¨è¿æ¥ã€‚3) **è°±å›¾å·ç§¯**ï¼šä½¿ç”¨è°±å›¾å·ç§¯ç¥ç»ç½‘ç»œå¯¹å›¾è¿›è¡Œå¤„ç†ï¼Œå­¦ä¹ èŠ‚ç‚¹çš„è¡¨ç¤ºã€‚4) **åˆ†ç±»**ï¼šå°†å­¦ä¹ åˆ°çš„èŠ‚ç‚¹è¡¨ç¤ºè¾“å…¥åˆ°åˆ†ç±»å™¨ä¸­ï¼Œé¢„æµ‹æ¯ä¸ªCTæ‰«æå›¾åƒçš„å¤šæ ‡ç­¾å¼‚å¸¸ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•çš„å…³é”®åˆ›æ–°åœ¨äºä½¿ç”¨ç»“æ„åŒ–çš„è°±å›¾è¡¨ç¤ºæ¥å»ºæ¨¡3D CTæ•°æ®ã€‚ä¸ä¼ ç»Ÿçš„3D CNNç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰é•¿ç¨‹ä¾èµ–å…³ç³»ï¼Œå¹¶ä¸”è®¡ç®—å¤æ‚åº¦æ›´ä½ã€‚ä¸Vision Transformerç›¸æ¯”ï¼Œè¯¥æ–¹æ³•ä¸éœ€è¦å¤§è§„æ¨¡çš„é¢„è®­ç»ƒæ•°æ®ï¼Œæ›´é€‚ç”¨äºå®é™…åº”ç”¨ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å›¾æ„å»ºæ–¹é¢ï¼Œè®ºæ–‡ç ”ç©¶äº†ä¸åŒçš„è¿æ¥ç­–ç•¥ï¼Œä¾‹å¦‚kè¿‘é‚»å’Œå…¨è¿æ¥ã€‚åœ¨è°±å›¾å·ç§¯æ–¹é¢ï¼Œè®ºæ–‡ä½¿ç”¨äº†ChebNetsï¼Œè¿™æ˜¯ä¸€ç§é«˜æ•ˆçš„è°±å›¾å·ç§¯æ–¹æ³•ã€‚åœ¨æŸå¤±å‡½æ•°æ–¹é¢ï¼Œè®ºæ–‡ä½¿ç”¨äº†äºŒå…ƒäº¤å‰ç†µæŸå¤±å‡½æ•°ï¼Œç”¨äºå¤šæ ‡ç­¾åˆ†ç±»ä»»åŠ¡ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜ç ”ç©¶äº†ä¸åŒçš„èšåˆç­–ç•¥å’Œè¾¹ç¼˜åŠ æƒæ–¹æ¡ˆï¼Œä»¥è¿›ä¸€æ­¥æé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥æ–¹æ³•åœ¨ä¸‰ä¸ªç‹¬ç«‹æœºæ„çš„æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå®ç°äº†å¼ºå¤§çš„è·¨æ•°æ®é›†æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶ä¸”æ€§èƒ½ä¸æœ€å…ˆè¿›çš„è§†è§‰ç¼–ç å™¨ç›¸æ¯”å…·æœ‰ç«äº‰åŠ›ã€‚æ¶ˆèç ”ç©¶è¡¨æ˜ï¼Œä¸åŒçš„èšåˆç­–ç•¥ã€è¾¹ç¼˜åŠ æƒæ–¹æ¡ˆå’Œå›¾è¿æ¥æ¨¡å¼å¯¹æ¨¡å‹æ€§èƒ½æœ‰æ˜¾è‘—å½±å“ã€‚è¿ç§»å®éªŒè¯æ˜äº†è¯¥æ–¹æ³•åœ¨è‡ªåŠ¨æ”¾å°„æŠ¥å‘Šç”Ÿæˆå’Œè…¹éƒ¨CTæ•°æ®ä¸Šçš„é€‚ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºåŒ»å­¦å½±åƒåˆ†æé¢†åŸŸï¼Œè¾…åŠ©æ”¾å°„ç§‘åŒ»ç”Ÿè¿›è¡Œç–¾ç—…è¯Šæ–­å’ŒæŠ¥å‘Šç”Ÿæˆï¼Œæé«˜è¯Šæ–­æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚è¯¥æ–¹æ³•å…·æœ‰è‰¯å¥½çš„è·¨æ•°æ®é›†æ³›åŒ–èƒ½åŠ›ï¼Œæœ‰æœ›åœ¨ä¸åŒåŒ»ç–—æœºæ„çš„CTæ•°æ®ä¸Šæ¨å¹¿åº”ç”¨ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–3DåŒ»å­¦å½±åƒæ•°æ®ï¼Œå¦‚MRIå’ŒPETï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> With the growing volume of CT examinations, there is an increasing demand for automated tools such as organ segmentation, abnormality detection, and report generation to support radiologists in managing their clinical workload. Multi-label classification of 3D Chest CT scans remains a critical yet challenging problem due to the complex spatial relationships inherent in volumetric data and the wide variability of abnormalities. Existing methods based on 3D convolutional neural networks struggle to capture long-range dependencies, while Vision Transformers often require extensive pre-training on large-scale, domain-specific datasets to perform competitively. In this work of academic research, we propose a 2.5D alternative by introducing a new graph-based framework that represents 3D CT volumes as structured graphs, where axial slice triplets serve as nodes processed through spectral graph convolution, enabling the model to reason over inter-slice dependencies while maintaining complexity compatible with clinical deployment. Our method, trained and evaluated on 3 datasets from independent institutions, achieves strong cross-dataset generalization, and shows competitive performance compared to state-of-the-art visual encoders. We further conduct comprehensive ablation studies to evaluate the impact of various aggregation strategies, edge-weighting schemes, and graph connectivity patterns. Additionally, we demonstrate the broader applicability of our approach through transfer experiments on automated radiology report generation and abdominal CT data.

