---
layout: default
title: Taming a Retrieval Framework to Read Images in Humanlike Manner for Augmenting Generation of MLLMs
---

# Taming a Retrieval Framework to Read Images in Humanlike Manner for Augmenting Generation of MLLMs

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.10426" target="_blank" class="toolbar-btn">arXiv: 2510.10426v1</a>
    <a href="https://arxiv.org/pdf/2510.10426.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.10426v1" 
            onclick="toggleFavorite(this, '2510.10426v1', 'Taming a Retrieval Framework to Read Images in Humanlike Manner for Augmenting Generation of MLLMs')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Suyang Xi, Chenxi Yang, Hong Ding, Yiqing Ni, Catherine C. Liu, Yunhao Liu, Chengqi Zhang

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-12

**Â§áÊ≥®**: 12 pages, 5 figures

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫HuLiRAGÊ°ÜÊû∂ÔºåÈÄöËøáÊ®°Êãü‰∫∫Á±ªËßÜËßâÂ§ÑÁêÜÊñπÂºèÂ¢ûÂº∫Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÁîüÊàêËÉΩÂäõ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã` `ËßÜËßâÈóÆÁ≠î` `Ê£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàê` `ËßÜËßâ grounding` `‰∫∫Á±ªËßÜËßâÊ®°Êãü`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâMLLMÂú®ËßÜËßâÈóÆÁ≠î‰∏≠Êòì‰∫ßÁîüÂπªËßâÔºåÂéüÂõ†ÊòØÊñáÊú¨Êü•ËØ¢‰∏éËßÜËßâ‰ø°ÊÅØÁº∫‰πèÁ≤æÁ°ÆÈîöÂÆöÔºåÂØºËá¥Êé®ÁêÜ‰∏çÂáÜÁ°Æ„ÄÇ
2. HuLiRAGÊ°ÜÊû∂Ê®°Êãü‰∫∫Á±ªËßÜËßâÂ§ÑÁêÜÊµÅÁ®ãÔºåÈÄöËøá‚Äúwhat-where-reweight‚ÄùÁ∫ßËÅîÂÆûÁé∞Êõ¥Á≤æÁªÜÁöÑËßÜËßâ‰ø°ÊÅØÊ£ÄÁ¥¢‰∏éÂ¢ûÂº∫„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåHuLiRAGËÉΩÊúâÊïàÊèêÈ´ògrounding‰øùÁúüÂ∫¶ÔºåÂáèÂ∞ëÂπªËßâÔºåÊèêÂçáÂ§öÊ®°ÊÄÅÈóÆÁ≠îÁöÑ‰∫ãÂÆû‰∏ÄËá¥ÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã(MLLMs)Âú®ÁªÜÁ≤íÂ∫¶ËßÜËßâÈóÆÁ≠î‰∏≠Ë°®Áé∞‰∏ç‰Ω≥ÔºåÂ∏∏Â∏∏‰∫ßÁîüÂÖ≥‰∫éÁâ©‰ΩìË∫´‰ªΩ„ÄÅ‰ΩçÁΩÆÂíåÂÖ≥Á≥ªÁöÑÂπªËßâÔºåËøôÊòØÂõ†‰∏∫ÊñáÊú¨Êü•ËØ¢Ê≤°ÊúâÊòéÁ°ÆÂú∞ÈîöÂÆöÂà∞ËßÜËßâÂèÇÁÖßÁâ©‰∏ä„ÄÇÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàê(RAG)ÂèØ‰ª•ÁºìËß£‰∏Ä‰∫õÈîôËØØÔºå‰ΩÜÂÆÉÂú®Ê£ÄÁ¥¢ÂíåÂ¢ûÂº∫Â±ÇÈù¢ÈÉΩÊú™ËÉΩ‰∏é‰∫∫Á±ªÁöÑÂ§ÑÁêÜÊñπÂºèÂØπÈΩê„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåRAGÂè™ÂÖ≥Ê≥®ÂÖ®Â±ÄÂ±ÇÈù¢ÁöÑÂõæÂÉè‰ø°ÊÅØÔºåÁº∫‰πèÂ±ÄÈÉ®ÁªÜËäÇÔºåÂπ∂‰∏îÈôêÂà∂‰∫ÜÂØπÁªÜÁ≤íÂ∫¶‰∫§‰∫íÁöÑÊé®ÁêÜ„ÄÇ‰∏∫‰∫ÜÂÖãÊúçËøô‰∏™ÈôêÂà∂ÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜHuman-Like Retrieval-Augmented Generation (HuLiRAG)ÔºåËØ•Ê°ÜÊû∂Â∞ÜÂ§öÊ®°ÊÄÅÊé®ÁêÜÂàÜÈò∂ÊÆµËøõË°åÔºåÂΩ¢Êàê‰∏Ä‰∏™‚Äúwhat--where--reweight‚ÄùÁöÑÁ∫ßËÅî„ÄÇÈ¶ñÂÖàÈÄöËøáÂºÄÊîæËØçÊ±áÊ£ÄÊµãÂ∞ÜÊü•ËØ¢ÈîöÂÆöÂà∞ÂÄôÈÄâÂèÇÁÖßÁâ©(what)ÔºåÁÑ∂Âêé‰ΩøÁî®SAMË°çÁîüÁöÑÊé©Á†ÅÂú®Á©∫Èó¥‰∏äËß£ÊûêÔºå‰ª•ÊÅ¢Â§çÁªÜÁ≤íÂ∫¶Á≤æÂ∫¶(where)ÔºåÊúÄÂêéÈÄöËøáÂ±ÄÈÉ®ÂíåÂÖ®Â±ÄÂØπÈΩê‰πãÈó¥ÁöÑÊùÉË°°Êù•Ëá™ÈÄÇÂ∫îÂú∞Á°ÆÂÆö‰ºòÂÖàÁ∫ß(reweight)„ÄÇÊé©Á†ÅÂºïÂØºÁöÑÂæÆË∞ÉËøõ‰∏ÄÊ≠•Â∞ÜÁ©∫Èó¥ËØÅÊçÆÊ≥®ÂÖ•Âà∞ÁîüÊàêËøáÁ®ã‰∏≠ÔºåÂ∞Ügrounding‰ªéË¢´Âä®ÂÅèÂ∑ÆËΩ¨Âèò‰∏∫ÂØπÁ≠îÊ°àÂÖ¨ÂºèÂåñÁöÑÊòæÂºèÁ∫¶Êùü„ÄÇÂ§ßÈáèÁöÑÂÆûÈ™åË°®ÊòéÔºåËøôÁßçÁ±ª‰ºº‰∫∫Á±ªÁöÑÁ∫ßËÅîÊèêÈ´ò‰∫ÜgroundingÁöÑ‰øùÁúüÂ∫¶Âíå‰∫ãÂÆû‰∏ÄËá¥ÊÄßÔºåÂêåÊó∂ÂáèÂ∞ë‰∫ÜÂπªËßâÔºå‰ªéËÄåÊé®Âä®Â§öÊ®°ÊÄÅÈóÆÁ≠îÊúùÁùÄÂèØ‰ø°ÁöÑÊé®ÁêÜÊñπÂêëÂèëÂ±ï„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÂú®Â§ÑÁêÜÁªÜÁ≤íÂ∫¶ËßÜËßâÈóÆÁ≠îÊó∂ÔºåÂÆπÊòì‰∫ßÁîüÂπªËßâÔºåÂç≥ÁîüÊàê‰∏éÂõæÂÉèÂÜÖÂÆπ‰∏çÁ¨¶ÁöÑ‰ø°ÊÅØ„ÄÇÁé∞ÊúâÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÊñπÊ≥ïÔºàRAGÔºâËôΩÁÑ∂ËÉΩÁºìËß£ÈÉ®ÂàÜÈóÆÈ¢òÔºå‰ΩÜÂÖ∂Ê£ÄÁ¥¢ÊñπÂºè‰∏ªË¶ÅÂÖ≥Ê≥®ÂÖ®Â±ÄÂõæÂÉè‰ø°ÊÅØÔºåÂøΩÁï•‰∫ÜÂ±ÄÈÉ®ÁªÜËäÇÂíåÁªÜÁ≤íÂ∫¶‰∫§‰∫íÔºåÂØºËá¥Êó†Ê≥ïÂÉè‰∫∫Á±ª‰∏ÄÊ†∑ËøõË°åÁ≤æÁ°ÆÁöÑËßÜËßâÊé®ÁêÜ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöHuLiRAGÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÊ®°Êãü‰∫∫Á±ªÁöÑËßÜËßâÂ§ÑÁêÜÊñπÂºèÔºåÂ∞ÜÂ§öÊ®°ÊÄÅÊé®ÁêÜËøáÁ®ãÂàÜËß£‰∏∫‰∏â‰∏™Èò∂ÊÆµÔºö‚Äúwhat-where-reweight‚Äù„ÄÇÈ¶ñÂÖàÁ°ÆÂÆöÂõæÂÉè‰∏≠ÂèØËÉΩÁõ∏ÂÖ≥ÁöÑÁâ©‰ΩìÔºàwhatÔºâÔºåÁÑ∂ÂêéÁ≤æÁ°ÆÂÆö‰ΩçËøô‰∫õÁâ©‰ΩìÁöÑ‰ΩçÁΩÆÂíåËæπÁïåÔºàwhereÔºâÔºåÊúÄÂêéÊ†πÊçÆÂ±ÄÈÉ®ÂíåÂÖ®Â±Ä‰ø°ÊÅØÁöÑÈáçË¶ÅÊÄßË∞ÉÊï¥ÊùÉÈáçÔºå‰ªéËÄåÊõ¥Â•ΩÂú∞ÁêÜËß£ÂõæÂÉèÂÜÖÂÆπ„ÄÇËøôÁßçÂàÜÈò∂ÊÆµÂ§ÑÁêÜÁöÑÊñπÂºèÊó®Âú®ÊèêÈ´òÊ£ÄÁ¥¢ÁöÑÁ≤æÂ∫¶ÂíåÁõ∏ÂÖ≥ÊÄßÔºåÂáèÂ∞ëÂπªËßâÁöÑ‰∫ßÁîü„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöHuLiRAGÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ã‰∏ªË¶ÅÊ®°ÂùóÔºö1) **ÂºÄÊîæËØçÊ±áÊ£ÄÊµã (What)**Ôºö‰ΩøÁî®ÂºÄÊîæËØçÊ±áÊ£ÄÊµãÂô®ËØÜÂà´ÂõæÂÉè‰∏≠ÁöÑÂÄôÈÄâÂèÇÁÖßÁâ©ÔºåÂ∞ÜÊñáÊú¨Êü•ËØ¢‰∏éÂõæÂÉè‰∏≠ÁöÑÁâ©‰ΩìËøõË°åÂàùÊ≠•ÂÖ≥ËÅî„ÄÇ2) **Á©∫Èó¥Ëß£Êûê (Where)**ÔºöÂà©Áî®SAMÔºàSegment Anything ModelÔºâÁîüÊàêÂÄôÈÄâÂèÇÁÖßÁâ©ÁöÑÁ≤æÁ°ÆÊé©Á†ÅÔºå‰ªéËÄåËé∑ÂæóÁâ©‰ΩìÂú®ÂõæÂÉè‰∏≠ÁöÑÁ≤æÁ°ÆÂÆö‰Ωç‰ø°ÊÅØ„ÄÇ3) **ÈáçÂä†ÊùÉ (Reweight)**ÔºöÈÄöËøáÊùÉË°°Â±ÄÈÉ®ÂíåÂÖ®Â±ÄÂØπÈΩêÁ®ãÂ∫¶ÔºåËá™ÈÄÇÂ∫îÂú∞Ë∞ÉÊï¥‰∏çÂêåÂå∫ÂüüÁöÑÈáçË¶ÅÊÄßÔºå‰ªéËÄåÊõ¥Â•ΩÂú∞ÁêÜËß£ÂõæÂÉèÂÜÖÂÆπ„ÄÇ4) **Êé©Á†ÅÂºïÂØºÂæÆË∞É**ÔºöÂà©Áî®ÁîüÊàêÁöÑÊé©Á†Å‰ø°ÊÅØÂØπMLLMËøõË°åÂæÆË∞ÉÔºåÂ∞ÜÁ©∫Èó¥‰ø°ÊÅØÊòæÂºèÂú∞ËûçÂÖ•Âà∞ÁîüÊàêËøáÁ®ã‰∏≠„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöHuLiRAGÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂Ê®°Êãü‰∫∫Á±ªËßÜËßâÂ§ÑÁêÜÁöÑ‚Äúwhat-where-reweight‚ÄùÁ∫ßËÅîÊ°ÜÊû∂„ÄÇ‰∏é‰º†ÁªüÁöÑRAGÊñπÊ≥ïÁõ∏ÊØîÔºåHuLiRAGÊõ¥Âä†ÂÖ≥Ê≥®ÂõæÂÉèÁöÑÂ±ÄÈÉ®ÁªÜËäÇÂíåÁªÜÁ≤íÂ∫¶‰∫§‰∫íÔºåËÉΩÂ§üÊõ¥Á≤æÁ°ÆÂú∞Â∞ÜÊñáÊú¨Êü•ËØ¢‰∏éËßÜËßâ‰ø°ÊÅØËøõË°åÂÖ≥ËÅî„ÄÇÊ≠§Â§ñÔºåÊé©Á†ÅÂºïÂØºÁöÑÂæÆË∞ÉÂ∞ÜÁ©∫Èó¥‰ø°ÊÅØ‰ªéË¢´Âä®ÂÅèÂ∑ÆËΩ¨Âèò‰∏∫ÂØπÁ≠îÊ°àÁîüÊàêÁöÑÊòæÂºèÁ∫¶ÊùüÔºåËøõ‰∏ÄÊ≠•ÊèêÈ´ò‰∫ÜÁîüÊàêÁªìÊûúÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®‚Äúwhat‚ÄùÈò∂ÊÆµÔºå‰ΩøÁî®ÂºÄÊîæËØçÊ±áÊ£ÄÊµãÂô®ÔºàÂ¶ÇGrounding DINOÔºâÊù•ËØÜÂà´ÂõæÂÉè‰∏≠ÁöÑÂÄôÈÄâÂèÇÁÖßÁâ©„ÄÇÂú®‚Äúwhere‚ÄùÈò∂ÊÆµÔºåÂà©Áî®SAMÁîüÊàêÂÄôÈÄâÂèÇÁÖßÁâ©ÁöÑÁ≤æÁ°ÆÊé©Á†Å„ÄÇÂú®‚Äúreweight‚ÄùÈò∂ÊÆµÔºåËÆæËÆ°‰∫Ü‰∏ÄÁßçËá™ÈÄÇÂ∫îÊùÉÈáçË∞ÉÊï¥Êú∫Âà∂ÔºåÊ†πÊçÆÂ±ÄÈÉ®ÂíåÂÖ®Â±ÄÂØπÈΩêÁ®ãÂ∫¶Êù•Ë∞ÉÊï¥‰∏çÂêåÂå∫ÂüüÁöÑÈáçË¶ÅÊÄß„ÄÇÂú®Êé©Á†ÅÂºïÂØºÂæÆË∞ÉÈò∂ÊÆµÔºå‰ΩøÁî®‰∫§ÂèâÁÜµÊçüÂ§±ÂáΩÊï∞Êù•‰ºòÂåñMLLMÁöÑÁîüÊàêËÉΩÂäõÔºåÂπ∂‰ΩøÁî®ÁîüÊàêÁöÑÊé©Á†Å‰ø°ÊÅØ‰Ωú‰∏∫È¢ùÂ§ñÁöÑËæìÂÖ•ÁâπÂæÅ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåHuLiRAGÊ°ÜÊû∂Âú®Â§ö‰∏™ËßÜËßâÈóÆÁ≠îÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåÂ∞§ÂÖ∂ÊòØÂú®ÈúÄË¶ÅÁªÜÁ≤íÂ∫¶ËßÜËßâÊé®ÁêÜÁöÑ‰ªªÂä°‰∏ä„ÄÇ‰∏é‰º†ÁªüÁöÑRAGÊñπÊ≥ïÁõ∏ÊØîÔºåHuLiRAGËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞ÂáèÂ∞ëÂπªËßâÔºåÊèêÈ´ògroundingÁöÑ‰øùÁúüÂ∫¶Âíå‰∫ãÂÆû‰∏ÄËá¥ÊÄß„ÄÇÂÖ∑‰ΩìÁöÑÊÄßËÉΩÊï∞ÊçÆÂú®ËÆ∫Êñá‰∏≠ÊúâËØ¶ÁªÜÂ±ïÁ§∫ÔºåËØÅÊòé‰∫ÜËØ•Ê°ÜÊû∂ÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

HuLiRAGÊ°ÜÊû∂ÂèØÂ∫îÁî®‰∫éÂêÑÁßçÈúÄË¶ÅÁ≤æÁ°ÆËßÜËßâÁêÜËß£ÁöÑÂ§öÊ®°ÊÄÅ‰ªªÂä°Ôºå‰æãÂ¶ÇËßÜËßâÈóÆÁ≠î„ÄÅÂõæÂÉèÊèèËø∞„ÄÅÊú∫Âô®‰∫∫ÂØºËà™Á≠â„ÄÇËØ•Á†îÁ©∂ÊúâÂä©‰∫éÊèêÂçáÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÂèØ‰ø°Â∫¶ÂíåÂèØÈù†ÊÄßÔºå‰ΩøÂÖ∂Âú®ÂåªÁñóËØäÊñ≠„ÄÅËá™Âä®È©æÈ©∂„ÄÅÊô∫ËÉΩÂÆ¢ÊúçÁ≠âÈ¢ÜÂüüÂèëÊå•Êõ¥Â§ßÁöÑ‰ΩúÁî®„ÄÇÊú™Êù•ÔºåËØ•Ê°ÜÊû∂ÂèØ‰ª•Ëøõ‰∏ÄÊ≠•Êâ©Â±ïÂà∞Â§ÑÁêÜÊõ¥Â§çÊùÇÁöÑËßÜËßâÂú∫ÊôØÂíå‰ªªÂä°Ôºå‰æãÂ¶ÇËßÜÈ¢ëÁêÜËß£Âíå‰∏âÁª¥Âú∫ÊôØÁêÜËß£„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Multimodal large language models (MLLMs) often fail in fine-grained visual question answering, producing hallucinations about object identities, positions, and relations because textual queries are not explicitly anchored to visual referents. Retrieval-augmented generation (RAG) alleviates some errors, but it fails to align with human-like processing at both the retrieval and augmentation levels. Specifically, it focuses only on global-level image information but lacks local detail and limits reasoning about fine-grained interactions. To overcome this limitation, we present Human-Like Retrieval-Augmented Generation (HuLiRAG), a framework that stages multimodal reasoning as a ``what--where--reweight'' cascade. Queries are first anchored to candidate referents via open-vocabulary detection (what), then spatially resolved with SAM-derived masks to recover fine-grained precision (where), and adaptively prioritized through the trade-off between local and global alignment (reweight). Mask-guided fine-tuning further injects spatial evidence into the generation process, transforming grounding from a passive bias into an explicit constraint on answer formulation. Extensive experiments demonstrate that this human-like cascade improves grounding fidelity and factual consistency while reducing hallucinations, advancing multimodal question answering toward trustworthy reasoning.

