---
layout: default
title: EmoDiffTalk:Emotion-aware Diffusion for Editable 3D Gaussian Talking Head
---

# EmoDiffTalk:Emotion-aware Diffusion for Editable 3D Gaussian Talking Head

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.05991" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.05991v2</a>
  <a href="https://arxiv.org/pdf/2512.05991.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.05991v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.05991v2', 'EmoDiffTalk:Emotion-aware Diffusion for Editable 3D Gaussian Talking Head')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chang Liu, Tianjiao Jing, Chengcheng Ma, Xuanqi Zhou, Zhengxuan Lian, Qin Jin, Hongliang Yuan, Shi-Sheng Huang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-30 (æ›´æ–°: 2025-12-10)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**EmoDiffTalkï¼šæå‡ºæƒ…æ„Ÿæ„ŸçŸ¥æ‰©æ•£æ¨¡å‹ï¼Œç”¨äºå¯ç¼–è¾‘çš„3Dé«˜æ–¯è¯´è¯å¤´ç”Ÿæˆã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `3Dè¯´è¯å¤´ç”Ÿæˆ` `é«˜æ–¯æº…å°„` `æ‰©æ•£æ¨¡å‹` `æƒ…æ„Ÿæ„ŸçŸ¥` `åŠ¨ä½œå•å…ƒ` `å¤šæ¨¡æ€ç¼–è¾‘` `æ–‡æœ¬åˆ°AU` `å¯ç¼–è¾‘æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„åŸºäº3Dé«˜æ–¯æº…å°„çš„é€¼çœŸè¯´è¯å¤´åœ¨æƒ…æ„Ÿè¡¨è¾¾æ“æ§æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨ä½¿ç”¨å¤šæ¨¡æ€æ§åˆ¶è¿›è¡Œç»†ç²’åº¦å’Œå¹¿æ³›çš„åŠ¨æ€æƒ…æ„Ÿç¼–è¾‘æ—¶ã€‚
2. EmoDiffTalkæå‡ºäº†ä¸€ç§æƒ…æ„Ÿæ„ŸçŸ¥é«˜æ–¯æ‰©æ•£æ–¹æ³•ï¼Œé€šè¿‡åŠ¨ä½œå•å…ƒï¼ˆAUï¼‰æç¤ºå’Œæ–‡æœ¬åˆ°AUæƒ…æ„Ÿæ§åˆ¶å™¨ï¼Œå®ç°ç²¾ç»†çš„æƒ…æ„Ÿæ§åˆ¶å’Œç¼–è¾‘ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒEmoDiffTalkåœ¨æƒ…æ„Ÿè¡¨è¾¾çš„å¾®å¦™æ€§ã€å£å‹åŒæ­¥çš„å‡†ç¡®æ€§å’Œå¯æ§æ€§æ–¹é¢å‡ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œä¸ºé«˜è´¨é‡3Dè¯´è¯å¤´åˆæˆæä¾›äº†æ–°é€”å¾„ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„å¯ç¼–è¾‘3Dé«˜æ–¯è¯´è¯å¤´æ¡†æ¶ï¼Œåä¸ºEmoDiffTalkã€‚æ ¸å¿ƒæ€æƒ³æ˜¯å¼•å…¥ä¸€ç§æƒ…æ„Ÿæ„ŸçŸ¥é«˜æ–¯æ‰©æ•£æ–¹æ³•ï¼ŒåŒ…æ‹¬ç”¨äºç²¾ç»†é¢éƒ¨åŠ¨ç”»æ§åˆ¶çš„åŠ¨ä½œå•å…ƒï¼ˆAUï¼‰æç¤ºé«˜æ–¯æ‰©æ•£è¿‡ç¨‹ï¼Œä»¥åŠä¸€ä¸ªç²¾ç¡®çš„æ–‡æœ¬åˆ°AUæƒ…æ„Ÿæ§åˆ¶å™¨ï¼Œä»è€Œå®ç°ä½¿ç”¨æ–‡æœ¬è¾“å…¥è¿›è¡Œå‡†ç¡®å’Œå¹¿æ³›çš„åŠ¨æ€æƒ…æ„Ÿç¼–è¾‘ã€‚åœ¨å…¬å…±EmoTalk3Då’ŒRenderMe-360æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒEmoDiffTalkåœ¨æƒ…æ„Ÿå¾®å¦™æ€§ã€å£å‹åŒæ­¥ä¿çœŸåº¦å’Œå¯æ§æ€§æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸ºé«˜è´¨é‡ã€æ‰©æ•£é©±åŠ¨ã€å¤šæ¨¡æ€å¯ç¼–è¾‘3Dè¯´è¯å¤´åˆæˆå»ºç«‹äº†ä¸€æ¡æœ‰æ•ˆé€”å¾„ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼ŒEmoDiffTalkæ˜¯é¦–æ‰¹æ”¯æŒåŸºäºAUè¡¨æƒ…ç©ºé—´è¿›è¡Œè¿ç»­ã€å¤šæ¨¡æ€æƒ…æ„Ÿç¼–è¾‘çš„3Dé«˜æ–¯æº…å°„è¯´è¯å¤´ç”Ÿæˆæ¡†æ¶ä¹‹ä¸€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰3Dè¯´è¯å¤´ç”Ÿæˆæ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åŸºäº3Dé«˜æ–¯æº…å°„çš„æ–¹æ³•ï¼Œåœ¨æƒ…æ„Ÿè¡¨è¾¾çš„ç²¾ç»†æ§åˆ¶å’Œå¤šæ¨¡æ€æƒ…æ„Ÿç¼–è¾‘æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚éš¾ä»¥å®ç°ç»†ç²’åº¦çš„æƒ…æ„Ÿæ“æ§ï¼Œå¹¶ä¸”ç¼ºä¹é€šè¿‡æ–‡æœ¬ç­‰æ¨¡æ€è¿›è¡Œå¹¿æ³›æƒ…æ„Ÿç¼–è¾‘çš„èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šEmoDiffTalkçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆå…·æœ‰æƒ…æ„Ÿè¡¨è¾¾çš„3Dé«˜æ–¯è¯´è¯å¤´ã€‚é€šè¿‡å°†åŠ¨ä½œå•å…ƒï¼ˆAUï¼‰ä½œä¸ºæ‰©æ•£è¿‡ç¨‹çš„æç¤ºï¼Œå¹¶ç»“åˆæ–‡æœ¬åˆ°AUçš„æƒ…æ„Ÿæ§åˆ¶å™¨ï¼Œå®ç°å¯¹æƒ…æ„Ÿçš„ç²¾ç¡®æ§åˆ¶å’Œç¼–è¾‘ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆæ›´è‡ªç„¶ã€æ›´å¯Œæœ‰è¡¨ç°åŠ›çš„è¯´è¯å¤´ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEmoDiffTalkæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) 3Dé«˜æ–¯æº…å°„è¡¨ç¤ºæ¨¡å—ï¼Œç”¨äºè¡¨ç¤º3Dè¯´è¯å¤´ï¼›2) åŠ¨ä½œå•å…ƒï¼ˆAUï¼‰æç¤ºé«˜æ–¯æ‰©æ•£æ¨¡å—ï¼Œç”¨äºç”Ÿæˆå…·æœ‰ç‰¹å®šAUè¡¨æƒ…çš„3Dé«˜æ–¯å‚æ•°ï¼›3) æ–‡æœ¬åˆ°AUæƒ…æ„Ÿæ§åˆ¶å™¨ï¼Œç”¨äºå°†æ–‡æœ¬æƒ…æ„Ÿä¿¡æ¯è½¬æ¢ä¸ºAUå‚æ•°ï¼›4) æ¸²æŸ“æ¨¡å—ï¼Œç”¨äºå°†3Dé«˜æ–¯å‚æ•°æ¸²æŸ“æˆå›¾åƒã€‚æ•´ä¸ªæµç¨‹æ˜¯ä»æ–‡æœ¬è¾“å…¥å¼€å§‹ï¼Œé€šè¿‡æƒ…æ„Ÿæ§åˆ¶å™¨ç”ŸæˆAUå‚æ•°ï¼Œç„¶ååˆ©ç”¨AUæç¤ºé«˜æ–¯æ‰©æ•£æ¨¡å—ç”Ÿæˆ3Dé«˜æ–¯å‚æ•°ï¼Œæœ€åæ¸²æŸ“å¾—åˆ°è¯´è¯å¤´å›¾åƒã€‚

**å…³é”®åˆ›æ–°**ï¼šEmoDiffTalkçš„å…³é”®åˆ›æ–°åœ¨äºæƒ…æ„Ÿæ„ŸçŸ¥é«˜æ–¯æ‰©æ•£æ–¹æ³•ï¼Œå®ƒå°†åŠ¨ä½œå•å…ƒï¼ˆAUï¼‰ä½œä¸ºæ‰©æ•£è¿‡ç¨‹çš„æç¤ºï¼Œå¹¶ç»“åˆæ–‡æœ¬åˆ°AUçš„æƒ…æ„Ÿæ§åˆ¶å™¨ï¼Œå®ç°äº†å¯¹æƒ…æ„Ÿçš„ç²¾ç»†æ§åˆ¶å’Œç¼–è¾‘ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶æ˜¯é¦–æ‰¹æ”¯æŒåŸºäºAUè¡¨æƒ…ç©ºé—´è¿›è¡Œè¿ç»­ã€å¤šæ¨¡æ€æƒ…æ„Ÿç¼–è¾‘çš„3Dé«˜æ–¯æº…å°„è¯´è¯å¤´ç”Ÿæˆæ¡†æ¶ä¹‹ä¸€ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨AUæç¤ºé«˜æ–¯æ‰©æ•£æ¨¡å—ä¸­ï¼Œä½¿ç”¨äº†å™ªå£°é¢„æµ‹ç½‘ç»œæ¥é¢„æµ‹å™ªå£°ï¼Œå¹¶é€šè¿‡è¿­ä»£å»å™ªè¿‡ç¨‹ç”Ÿæˆ3Dé«˜æ–¯å‚æ•°ã€‚æ–‡æœ¬åˆ°AUæƒ…æ„Ÿæ§åˆ¶å™¨é‡‡ç”¨Transformerç»“æ„ï¼Œå°†æ–‡æœ¬æƒ…æ„Ÿä¿¡æ¯æ˜ å°„åˆ°AUå‚æ•°ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬é‡å»ºæŸå¤±ã€AUæŸå¤±å’Œå¯¹æŠ—æŸå¤±ï¼Œç”¨äºä¿è¯ç”Ÿæˆå›¾åƒçš„è´¨é‡ã€AUè¡¨æƒ…çš„å‡†ç¡®æ€§å’Œç”Ÿæˆç»“æœçš„çœŸå®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

EmoDiffTalkåœ¨EmoTalk3Då’ŒRenderMe-360æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼ŒEmoDiffTalkåœ¨æƒ…æ„Ÿå¾®å¦™æ€§ã€å£å‹åŒæ­¥ä¿çœŸåº¦å’Œå¯æ§æ€§æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚å°¤å…¶æ˜¯åœ¨æƒ…æ„Ÿç¼–è¾‘æ–¹é¢ï¼ŒEmoDiffTalkèƒ½å¤Ÿç”Ÿæˆæ›´è‡ªç„¶ã€æ›´å¯Œæœ‰è¡¨ç°åŠ›çš„è¯´è¯å¤´ï¼Œå¹¶ä¸”èƒ½å¤Ÿé€šè¿‡æ–‡æœ¬è¾“å…¥è¿›è¡Œç²¾ç¡®çš„æƒ…æ„Ÿæ§åˆ¶ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

EmoDiffTalkå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼ŒåŒ…æ‹¬è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ã€æ¸¸æˆã€ç”µå½±åˆ¶ä½œã€åœ¨çº¿æ•™è‚²å’Œè™šæ‹ŸåŠ©æ‰‹ç­‰é¢†åŸŸã€‚å®ƒå¯ä»¥ç”¨äºåˆ›å»ºæ›´é€¼çœŸã€æ›´å…·è¡¨ç°åŠ›çš„è™šæ‹Ÿè§’è‰²ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥åº”ç”¨äºæƒ…æ„Ÿåˆ†æå’Œæƒ…æ„Ÿè®¡ç®—ç­‰ç ”ç©¶é¢†åŸŸï¼Œå¸®åŠ©ç†è§£å’Œæ¨¡æ‹Ÿäººç±»æƒ…æ„Ÿã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent photo-realistic 3D talking head via 3D Gaussian Splatting still has significant shortcoming in emotional expression manipulation, especially for fine-grained and expansive dynamics emotional editing using multi-modal control. This paper introduces a new editable 3D Gaussian talking head, i.e. EmoDiffTalk. Our key idea is a novel Emotion-aware Gaussian Diffusion, which includes an action unit (AU) prompt Gaussian diffusion process for fine-grained facial animator, and moreover an accurate text-to-AU emotion controller to provide accurate and expansive dynamic emotional editing using text input. Experiments on public EmoTalk3D and RenderMe-360 datasets demonstrate superior emotional subtlety, lip-sync fidelity, and controllability of our EmoDiffTalk over previous works, establishing a principled pathway toward high-quality, diffusion-driven, multimodal editable 3D talking-head synthesis. To our best knowledge, our EmoDiffTalk is one of the first few 3D Gaussian Splatting talking-head generation framework, especially supporting continuous, multimodal emotional editing within the AU-based expression space.

