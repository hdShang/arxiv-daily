---
layout: default
title: OmniFD: A Unified Model for Versatile Face Forgery Detection
---

# OmniFD: A Unified Model for Versatile Face Forgery Detection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.01128" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.01128v1</a>
  <a href="https://arxiv.org/pdf/2512.01128.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.01128v1" onclick="toggleFavorite(this, '2512.01128v1', 'OmniFD: A Unified Model for Versatile Face Forgery Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Haotian Liu, Haoyu Chen, Chenhui Pan, You Hu, Guoying Zhao, Xiaobai Li

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-30

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/haotianll/OmniFD)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**OmniFDï¼šç”¨äºå¤šåŠŸèƒ½äººè„¸ä¼ªé€ æ£€æµ‹çš„ç»Ÿä¸€æ¨¡å‹ï¼Œæå‡æ•ˆç‡å’Œæ³›åŒ–æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `äººè„¸ä¼ªé€ æ£€æµ‹` `å¤šä»»åŠ¡å­¦ä¹ ` `Swin Transformer` `è·¨ä»»åŠ¡äº¤äº’` `æ—¶ç©ºç‰¹å¾æå–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„äººè„¸ä¼ªé€ æ£€æµ‹æ–¹æ³•é€šå¸¸é‡‡ç”¨ç‰¹å®šä»»åŠ¡çš„æ¨¡å‹ï¼Œå¯¼è‡´è®¡ç®—å†—ä½™ï¼Œå¿½ç•¥äº†ç›¸å…³ä»»åŠ¡ä¹‹é—´çš„æ½œåœ¨å…³è”ã€‚
2. OmniFDæå‡ºä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ï¼Œä½¿ç”¨å•ä¸ªæ¨¡å‹è”åˆå¤„ç†å›¾åƒå’Œè§†é¢‘åˆ†ç±»ã€ç©ºé—´å®šä½å’Œæ—¶é—´å®šä½å››é¡¹ä»»åŠ¡ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒOmniFDä¼˜äºç‰¹å®šä»»åŠ¡çš„æ¨¡å‹ï¼Œé€šè¿‡å¤šä»»åŠ¡å­¦ä¹ æ•è·é€šç”¨è¡¨ç¤ºï¼Œå¹¶å‡å°‘äº†æ¨¡å‹å‚æ•°å’Œè®­ç»ƒæ—¶é—´ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºOmniFDï¼Œä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ï¼Œç”¨äºè”åˆè§£å†³å››é¡¹æ ¸å¿ƒäººè„¸ä¼ªé€ æ£€æµ‹ä»»åŠ¡ï¼ŒåŒ…æ‹¬å›¾åƒå’Œè§†é¢‘åˆ†ç±»ã€ç©ºé—´å®šä½å’Œæ—¶é—´å®šä½ã€‚è¯¥æ¶æ„åŒ…å«ä¸‰ä¸ªä¸»è¦ç»„ä»¶ï¼šå…±äº«çš„Swin Transformerç¼–ç å™¨ï¼Œç”¨äºä»å›¾åƒå’Œè§†é¢‘è¾“å…¥ä¸­æå–ç»Ÿä¸€çš„4Dæ—¶ç©ºè¡¨ç¤ºï¼›ä¸€ä¸ªå…·æœ‰å¯å­¦ä¹ æŸ¥è¯¢çš„è·¨ä»»åŠ¡äº¤äº’æ¨¡å—ï¼Œé€šè¿‡åŸºäºæ³¨æ„åŠ›çš„æ¨ç†åŠ¨æ€æ•è·ä»»åŠ¡é—´çš„ä¾èµ–å…³ç³»ï¼›ä»¥åŠè½»é‡çº§çš„è§£ç å¤´ï¼Œå°†ç²¾ç»†åŒ–çš„è¡¨ç¤ºè½¬æ¢ä¸ºæ‰€æœ‰FFDä»»åŠ¡çš„ç›¸åº”é¢„æµ‹ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒOmniFDä¼˜äºç‰¹å®šä»»åŠ¡çš„æ¨¡å‹ã€‚å…¶ç»Ÿä¸€è®¾è®¡åˆ©ç”¨å¤šä»»åŠ¡å­¦ä¹ æ¥æ•è·è·¨ä»»åŠ¡çš„é€šç”¨è¡¨ç¤ºï¼Œå°¤å…¶èƒ½å¤Ÿå®ç°ç»†ç²’åº¦çš„çŸ¥è¯†è¿ç§»ï¼Œä»è€Œä¿ƒè¿›å…¶ä»–ä»»åŠ¡ã€‚ä¾‹å¦‚ï¼Œå½“åŒ…å«å›¾åƒæ•°æ®æ—¶ï¼Œè§†é¢‘åˆ†ç±»å‡†ç¡®ç‡æé«˜äº†4.63%ã€‚é€šè¿‡åœ¨ä¸€ä¸ªæ¡†æ¶å†…ç»Ÿä¸€å›¾åƒã€è§†é¢‘å’Œå››ä¸ªä»»åŠ¡ï¼ŒOmniFDåœ¨å„ç§åŸºå‡†æµ‹è¯•ä¸­å®ç°äº†å“è¶Šçš„æ€§èƒ½ï¼ŒåŒæ—¶å…·æœ‰é«˜æ•ˆç‡å’Œå¯æ‰©å±•æ€§ï¼Œä¾‹å¦‚ï¼Œå‡å°‘äº†63%çš„æ¨¡å‹å‚æ•°å’Œ50%çš„è®­ç»ƒæ—¶é—´ã€‚å®ƒä¸ºå®é™…åº”ç”¨ä¸­å…¨é¢çš„äººè„¸ä¼ªé€ æ£€æµ‹å»ºç«‹äº†ä¸€ä¸ªå®ç”¨ä¸”å¯æ¨å¹¿çš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„äººè„¸ä¼ªé€ æ£€æµ‹æ–¹æ³•é€šå¸¸é’ˆå¯¹ç‰¹å®šä»»åŠ¡è®¾è®¡ç‹¬ç«‹çš„æ¨¡å‹ï¼Œä¾‹å¦‚å›¾åƒåˆ†ç±»ã€è§†é¢‘åˆ†ç±»ã€ç¯¡æ”¹åŒºåŸŸå®šä½å’Œç¯¡æ”¹æ—¶é—´æ®µå®šä½ã€‚è¿™ç§æ–¹å¼å­˜åœ¨è®¡ç®—å†—ä½™ï¼Œå¹¶ä¸”å¿½ç•¥äº†ä¸åŒä»»åŠ¡ä¹‹é—´çš„æ½œåœ¨å…³è”æ€§ï¼Œä¾‹å¦‚å›¾åƒåˆ†ç±»çš„çŸ¥è¯†å¯ä»¥å¸®åŠ©è§†é¢‘åˆ†ç±»ï¼Œç©ºé—´å®šä½å¯ä»¥è¾…åŠ©æ—¶é—´å®šä½ã€‚å› æ­¤ï¼Œå¦‚ä½•è®¾è®¡ä¸€ä¸ªç»Ÿä¸€çš„æ¨¡å‹ï¼ŒåŒæ—¶é«˜æ•ˆåœ°å®Œæˆå¤šé¡¹äººè„¸ä¼ªé€ æ£€æµ‹ä»»åŠ¡æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šOmniFDçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨ä¸€ä¸ªå…±äº«çš„éª¨å¹²ç½‘ç»œæå–é€šç”¨çš„æ—¶ç©ºç‰¹å¾ï¼Œå¹¶é€šè¿‡è·¨ä»»åŠ¡äº¤äº’æ¨¡å—å­¦ä¹ ä¸åŒä»»åŠ¡ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼Œæœ€åä½¿ç”¨è½»é‡çº§çš„è§£ç å¤´å®Œæˆç‰¹å®šä»»åŠ¡çš„é¢„æµ‹ã€‚è¿™ç§è®¾è®¡å¯ä»¥é¿å…é‡å¤è®¡ç®—ï¼Œå¹¶ä¿ƒè¿›çŸ¥è¯†è¿ç§»ï¼Œä»è€Œæé«˜æ•´ä½“æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šOmniFDçš„æ•´ä½“æ¶æ„åŒ…å«ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š1) å…±äº«çš„Swin Transformerç¼–ç å™¨ï¼šç”¨äºä»å›¾åƒå’Œè§†é¢‘è¾“å…¥ä¸­æå–ç»Ÿä¸€çš„4Dæ—¶ç©ºè¡¨ç¤ºã€‚2) è·¨ä»»åŠ¡äº¤äº’æ¨¡å—ï¼šä½¿ç”¨å¯å­¦ä¹ çš„æŸ¥è¯¢å‘é‡ï¼Œé€šè¿‡æ³¨æ„åŠ›æœºåˆ¶åŠ¨æ€åœ°æ•è·ä¸åŒä»»åŠ¡ä¹‹é—´çš„ä¾èµ–å…³ç³»ã€‚3) è½»é‡çº§çš„è§£ç å¤´ï¼šå°†ç²¾ç»†åŒ–çš„è¡¨ç¤ºè½¬æ¢ä¸ºå¯¹åº”ä»»åŠ¡çš„é¢„æµ‹ç»“æœï¼Œä¾‹å¦‚åˆ†ç±»æ¦‚ç‡ã€åƒç´ çº§åˆ«çš„ç¯¡æ”¹æ¦‚ç‡å›¾æˆ–æ—¶é—´æ®µçš„ç½®ä¿¡åº¦å¾—åˆ†ã€‚

**å…³é”®åˆ›æ–°**ï¼šOmniFDæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå…¶ç»Ÿä¸€çš„æ¡†æ¶è®¾è®¡ï¼Œå®ƒå°†å›¾åƒå’Œè§†é¢‘åˆ†ç±»ã€ç©ºé—´å®šä½å’Œæ—¶é—´å®šä½å››ä¸ªä»»åŠ¡æ•´åˆåˆ°ä¸€ä¸ªæ¨¡å‹ä¸­ã€‚é€šè¿‡å…±äº«çš„ç‰¹å¾æå–å™¨å’Œè·¨ä»»åŠ¡äº¤äº’æ¨¡å—ï¼Œæ¨¡å‹å¯ä»¥å­¦ä¹ åˆ°æ›´é€šç”¨çš„è¡¨ç¤ºï¼Œå¹¶å®ç°çŸ¥è¯†è¿ç§»ã€‚è¿™ä¸ä»¥å¾€çš„ç‰¹å®šä»»åŠ¡æ¨¡å‹å½¢æˆäº†é²œæ˜å¯¹æ¯”ï¼Œæé«˜äº†æ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šè·¨ä»»åŠ¡äº¤äº’æ¨¡å—æ˜¯å…³é”®è®¾è®¡ä¹‹ä¸€ã€‚å®ƒä½¿ç”¨å¯å­¦ä¹ çš„æŸ¥è¯¢å‘é‡æ¥è¡¨ç¤ºæ¯ä¸ªä»»åŠ¡ï¼Œå¹¶é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶è®¡ç®—ä¸åŒä»»åŠ¡ä¹‹é—´çš„ç›¸å…³æ€§ã€‚Swin Transformerä½œä¸ºéª¨å¹²ç½‘ç»œï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°æå–æ—¶ç©ºç‰¹å¾ã€‚æŸå¤±å‡½æ•°æ–¹é¢ï¼Œé’ˆå¯¹ä¸åŒçš„ä»»åŠ¡é‡‡ç”¨ä¸åŒçš„æŸå¤±å‡½æ•°ï¼Œä¾‹å¦‚äº¤å‰ç†µæŸå¤±ç”¨äºåˆ†ç±»ä»»åŠ¡ï¼ŒäºŒå…ƒäº¤å‰ç†µæŸå¤±ç”¨äºåƒç´ çº§åˆ«çš„å®šä½ä»»åŠ¡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

OmniFDåœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¾‹å¦‚ï¼Œåœ¨è§†é¢‘åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œé€šè¿‡å¼•å…¥å›¾åƒæ•°æ®ï¼Œå‡†ç¡®ç‡æé«˜äº†4.63%ã€‚æ­¤å¤–ï¼ŒOmniFDè¿˜æ˜¾è‘—é™ä½äº†æ¨¡å‹å‚æ•°é‡å’Œè®­ç»ƒæ—¶é—´ï¼Œåˆ†åˆ«å‡å°‘äº†63%å’Œ50%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒOmniFDåœ¨æ•ˆç‡å’Œæ€§èƒ½æ–¹é¢éƒ½ä¼˜äºä¼ ç»Ÿçš„ç‰¹å®šä»»åŠ¡æ¨¡å‹ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

OmniFDå¯åº”ç”¨äºå„ç§å®‰å…¨ç›¸å…³çš„åœºæ™¯ï¼Œä¾‹å¦‚ç¤¾äº¤åª’ä½“å¹³å°çš„å†…å®¹å®¡æ ¸ã€è§†é¢‘ç›‘æ§ç³»ç»Ÿä¸­çš„å¼‚å¸¸æ£€æµ‹ã€ä»¥åŠé‡‘èé¢†åŸŸçš„èº«ä»½éªŒè¯ã€‚é€šè¿‡æ£€æµ‹äººè„¸ä¼ªé€ ï¼Œå¯ä»¥æœ‰æ•ˆé˜²æ­¢è™šå‡ä¿¡æ¯çš„ä¼ æ’­ã€æ¬ºè¯ˆè¡Œä¸ºçš„å‘ç”Ÿï¼Œç»´æŠ¤ç¤¾ä¼šå®‰å…¨å’Œç¨³å®šã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯å¯ä»¥è¿›ä¸€æ­¥æ‰©å±•åˆ°å…¶ä»–ç±»å‹çš„åª’ä½“å†…å®¹ï¼Œä¾‹å¦‚éŸ³é¢‘å’Œæ–‡æœ¬ï¼Œä»¥å®ç°æ›´å…¨é¢çš„ä¼ªé€ æ£€æµ‹ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Face forgery detection encompasses multiple critical tasks, including identifying forged images and videos and localizing manipulated regions and temporal segments. Current approaches typically employ task-specific models with independent architectures, leading to computational redundancy and ignoring potential correlations across related tasks. We introduce OmniFD, a unified framework that jointly addresses four core face forgery detection tasks within a single model, i.e., image and video classification, spatial localization, and temporal localization. Our architecture consists of three principal components: (1) a shared Swin Transformer encoder that extracts unified 4D spatiotemporal representations from both images and video inputs, (2) a cross-task interaction module with learnable queries that dynamically captures inter-task dependencies through attention-based reasoning, and (3) lightweight decoding heads that transform refined representations into corresponding predictions for all FFD tasks. Extensive experiments demonstrate OmniFD's advantage over task-specific models. Its unified design leverages multi-task learning to capture generalized representations across tasks, especially enabling fine-grained knowledge transfer that facilitates other tasks. For example, video classification accuracy improves by 4.63% when image data are incorporated. Furthermore, by unifying images, videos and the four tasks within one framework, OmniFD achieves superior performance across diverse benchmarks with high efficiency and scalability, e.g., reducing 63% model parameters and 50% training time. It establishes a practical and generalizable solution for comprehensive face forgery detection in real-world applications. The source code is made available at https://github.com/haotianll/OmniFD.

