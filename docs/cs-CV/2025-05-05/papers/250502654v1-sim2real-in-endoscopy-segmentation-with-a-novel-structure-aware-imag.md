---
layout: default
title: Sim2Real in endoscopy segmentation with a novel structure aware image translation
---

# Sim2Real in endoscopy segmentation with a novel structure aware image translation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.02654" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.02654v1</a>
  <a href="https://arxiv.org/pdf/2505.02654.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.02654v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.02654v1', 'Sim2Real in endoscopy segmentation with a novel structure aware image translation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Clara Tomasini, Luis Riazuelo, Ana C. Murillo

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-05

**æœŸåˆŠ**: In Int. Workshop on Simulation and Synthesis in Medical Imaging (pp. 89-101). Springer Nature (2024)

**DOI**: [10.1007/978-3-031-73281-2_9](https://doi.org/10.1007/978-3-031-73281-2_9)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§æ–°é¢–çš„å›¾åƒç¿»è¯‘æ¨¡å‹ä»¥è§£å†³å†…é•œå›¾åƒåˆ†å‰²é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `å†…é•œå›¾åƒ` `å›¾åƒåˆ†å‰²` `ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ` `åŒ»å­¦å›¾åƒåˆ†æ` `åˆæˆæ•°æ®` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨çœŸå®å†…é•œå›¾åƒçš„æ ‡æ³¨è·å–ä¸Šå­˜åœ¨å›°éš¾ï¼Œå¯¼è‡´è®­ç»ƒæ•°æ®ä¸è¶³ï¼Œå½±å“æ¨¡å‹æ€§èƒ½ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„å›¾åƒç¿»è¯‘æ¨¡å‹ï¼Œèƒ½å¤Ÿåœ¨ä¿æŒåœºæ™¯ç»“æ„çš„åŒæ—¶ä¸ºåˆæˆå†…é•œå›¾åƒæ·»åŠ é€¼çœŸçº¹ç†ã€‚
3. å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨æŠ˜å åˆ†å‰²ä»»åŠ¡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œç”Ÿæˆçš„å›¾åƒåœ¨å½¢çŠ¶å’Œä½ç½®ä¸Šæ›´æ¥è¿‘çœŸå®æŠ˜å ç»“æ„ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è‡ªåŠ¨åˆ†å‰²å†…é•œå›¾åƒä¸­çš„è§£å‰–æ ‡å¿—å¯ä»¥ä¸ºåŒ»ç”Ÿå’Œå¤–ç§‘åŒ»ç”Ÿæä¾›è¯Šæ–­ã€æ²»ç–—æˆ–åŒ»å­¦åŸ¹è®­çš„å¸®åŠ©ã€‚ç„¶è€Œï¼Œè·å–ç”¨äºè®­ç»ƒå¸¸ç”¨ç›‘ç£å­¦ä¹ æ–¹æ³•çš„æ ‡æ³¨æ˜¯ä¸€é¡¹ç¹çä¸”å›°éš¾çš„ä»»åŠ¡ï¼Œå°¤å…¶æ˜¯å¯¹äºçœŸå®å›¾åƒã€‚è™½ç„¶åˆæˆæ•°æ®çš„çœŸå®æ ‡æ³¨æ›´æ˜“è·å¾—ï¼Œä½†åœ¨æ­¤ç±»æ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹å¾€å¾€æ— æ³•å¾ˆå¥½åœ°æ³›åŒ–åˆ°çœŸå®æ•°æ®ã€‚ç”Ÿæˆæ–¹æ³•å¯ä»¥ä¸ºåˆæˆæ•°æ®æ·»åŠ é€¼çœŸçš„çº¹ç†ï¼Œä½†åœ¨ä¿æŒåŸå§‹åœºæ™¯ç»“æ„æ–¹é¢é¢ä¸´å›°éš¾ã€‚æœ¬æ–‡çš„ä¸»è¦è´¡çŒ®æ˜¯æå‡ºäº†ä¸€ç§æ–°é¢–çš„å›¾åƒç¿»è¯‘æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä¸ºæ¨¡æ‹Ÿå†…é•œå›¾åƒæ·»åŠ é€¼çœŸçš„çº¹ç†ï¼ŒåŒæ—¶ä¿æŒå…³é”®åœºæ™¯å¸ƒå±€ä¿¡æ¯ã€‚æˆ‘ä»¬å±•ç¤ºäº†è¿™äº›å›¾åƒå¯ä»¥æœ‰æ•ˆç”¨äºæˆåŠŸè®­ç»ƒä¸€ä¸ªåœ¨æ²¡æœ‰ä»»ä½•çœŸå®æ ‡æ³¨æ•°æ®çš„æƒ…å†µä¸‹å®ŒæˆæŠ˜å åˆ†å‰²çš„æ¨¡å‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å†…é•œå›¾åƒä¸­æŠ˜å åˆ†å‰²çš„æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•åœ¨çœŸå®å›¾åƒæ ‡æ³¨è·å–ä¸Šå­˜åœ¨å›°éš¾ï¼Œå¯¼è‡´æ¨¡å‹æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºä¸€ç§æ–°é¢–çš„å›¾åƒç¿»è¯‘æ¨¡å‹ï¼Œé€šè¿‡å°†åˆæˆå†…é•œå›¾åƒè½¬æ¢ä¸ºé€¼çœŸçš„å›¾åƒï¼Œä¿æŒå…³é”®çš„åœºæ™¯å¸ƒå±€ä¿¡æ¯ï¼Œä»è€Œæé«˜æ¨¡å‹åœ¨çœŸå®æ•°æ®ä¸Šçš„è¡¨ç°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å›¾åƒç”Ÿæˆæ¨¡å—å’Œç»“æ„ä¿æŒæ¨¡å—ã€‚å›¾åƒç”Ÿæˆæ¨¡å—è´Ÿè´£æ·»åŠ çº¹ç†ï¼Œè€Œç»“æ„ä¿æŒæ¨¡å—ç¡®ä¿åœºæ™¯å¸ƒå±€ä¸å˜ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºåŒæ—¶å®ç°äº†çº¹ç†çš„çœŸå®æ„Ÿå’Œç»“æ„çš„ä¿æŒï¼Œå…‹æœäº†ä¼ ç»Ÿç”Ÿæˆæ–¹æ³•åœ¨è¿™ä¸¤æ–¹é¢çš„ä¸è¶³ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡å‹é‡‡ç”¨ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥å¹³è¡¡çº¹ç†ç”Ÿæˆä¸ç»“æ„ä¿æŒï¼Œç½‘ç»œç»“æ„è®¾è®¡ä¸Šç»“åˆäº†å·ç§¯ç¥ç»ç½‘ç»œå’Œç”Ÿæˆå¯¹æŠ—ç½‘ç»œçš„ä¼˜åŠ¿ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œå±‚æ•°åœ¨å®éªŒä¸­ç»è¿‡è°ƒä¼˜ä»¥è¾¾åˆ°æœ€ä½³æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨æŠ˜å åˆ†å‰²ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿ï¼Œç”Ÿæˆçš„å›¾åƒåœ¨å½¢çŠ¶å’Œä½ç½®ä¸Šä¿æŒäº†æ›´é«˜çš„å‡†ç¡®æ€§ã€‚å…·ä½“è€Œè¨€ï¼Œæ¨¡å‹åœ¨åˆæˆæ•°æ®å’ŒçœŸå®æ•°æ®ä¸Šçš„è¡¨ç°å‡æœ‰æ˜¾è‘—æå‡ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨åŒ»å­¦å›¾åƒåˆ†æé¢†åŸŸã€‚é€šè¿‡æä¾›é«˜è´¨é‡çš„åˆæˆæ•°æ®ï¼Œèƒ½å¤Ÿå¸®åŠ©åŒ»ç”Ÿè¿›è¡Œæ›´å‡†ç¡®çš„è¯Šæ–­å’Œæ²»ç–—ï¼ŒåŒæ—¶ä¹Ÿä¸ºåŒ»å­¦åŸ¹è®­æä¾›äº†æ–°çš„å·¥å…·ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æ¨å¹¿åˆ°å…¶ä»–ç±»å‹çš„åŒ»å­¦æˆåƒä»»åŠ¡ä¸­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Automatic segmentation of anatomical landmarks in endoscopic images can provide assistance to doctors and surgeons for diagnosis, treatments or medical training. However, obtaining the annotations required to train commonly used supervised learning methods is a tedious and difficult task, in particular for real images. While ground truth annotations are easier to obtain for synthetic data, models trained on such data often do not generalize well to real data. Generative approaches can add realistic texture to it, but face difficulties to maintain the structure of the original scene. The main contribution in this work is a novel image translation model that adds realistic texture to simulated endoscopic images while keeping the key scene layout information. Our approach produces realistic images in different endoscopy scenarios. We demonstrate these images can effectively be used to successfully train a model for a challenging end task without any real labeled data. In particular, we demonstrate our approach for the task of fold segmentation in colonoscopy images. Folds are key anatomical landmarks that can occlude parts of the colon mucosa and possible polyps. Our approach generates realistic images maintaining the shape and location of the original folds, after the image-style-translation, better than existing methods. We run experiments both on a novel simulated dataset for fold segmentation, and real data from the EndoMapper (EM) dataset. All our new generated data and new EM metadata is being released to facilitate further research, as no public benchmark is currently available for the task of fold segmentation.

