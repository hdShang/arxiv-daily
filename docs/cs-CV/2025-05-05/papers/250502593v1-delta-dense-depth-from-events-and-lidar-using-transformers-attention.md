---
layout: default
title: DELTA: Dense Depth from Events and LiDAR using Transformer's Attention
---

# DELTA: Dense Depth from Events and LiDAR using Transformer's Attention

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.02593" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.02593v1</a>
  <a href="https://arxiv.org/pdf/2505.02593.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.02593v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.02593v1', 'DELTA: Dense Depth from Events and LiDAR using Transformer\'s Attention')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Vincent Brebion, Julien Moreau, Franck Davoine

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-05

**å¤‡æ³¨**: Accepted for the CVPR 2025 Workshop on Event-based Vision. For the project page, see https://vbrebion.github.io/DELTA/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDELTAä»¥èåˆäº‹ä»¶ç›¸æœºä¸LiDARæ•°æ®è§£å†³æ·±åº¦ä¼°è®¡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `æ·±åº¦ä¼°è®¡` `äº‹ä»¶ç›¸æœº` `LiDAR` `å¤šæ¨¡æ€èåˆ` `ç¥ç»ç½‘ç»œ` `æ³¨æ„åŠ›æœºåˆ¶` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨èåˆäº‹ä»¶ç›¸æœºä¸LiDARæ•°æ®æ—¶é¢ä¸´æŒ‘æˆ˜ï¼Œå¯¼è‡´æ·±åº¦ä¼°è®¡ç²¾åº¦ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºçš„DELTAæ¶æ„é€šè¿‡è‡ªæ³¨æ„åŠ›å’Œäº¤å‰æ³¨æ„åŠ›æœºåˆ¶æœ‰æ•ˆèåˆäº‹ä»¶å’ŒLiDARæ•°æ®ï¼Œæå‡æ·±åº¦å›¾çš„ç¨ å¯†æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDELTAåœ¨è¿‘è·ç¦»æ·±åº¦ä¼°è®¡ä¸­è¯¯å·®é™ä½è‡³ä¹‹å‰çš„å››åˆ†ä¹‹ä¸€ï¼Œæ˜¾è‘—æå‡äº†æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äº‹ä»¶ç›¸æœºä¸LiDARæä¾›äº’è¡¥ä½†ä¸åŒçš„æ•°æ®ï¼šå‰è€…æ˜¯å¼‚æ­¥çš„å…‰ç…§å˜åŒ–æ£€æµ‹ï¼Œåè€…åˆ™æ˜¯ä»¥å›ºå®šé€Ÿç‡æä¾›ç¨€ç–ä½†å‡†ç¡®çš„æ·±åº¦ä¿¡æ¯ã€‚è¿„ä»Šä¸ºæ­¢ï¼Œç»“åˆè¿™ä¸¤ç§æ¨¡æ€çš„ç ”ç©¶è¾ƒå°‘ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŸºäºç¥ç»ç½‘ç»œçš„æ–¹æ³•ï¼Œæ—¨åœ¨èåˆäº‹ä»¶å’ŒLiDARæ•°æ®ä»¥ä¼°è®¡ç¨ å¯†æ·±åº¦å›¾ã€‚æˆ‘ä»¬çš„æ¶æ„DELTAåˆ©ç”¨è‡ªæ³¨æ„åŠ›å’Œäº¤å‰æ³¨æ„åŠ›çš„æ¦‚å¿µï¼Œå»ºæ¨¡äº‹ä»¶å’ŒLiDARæ•°æ®å†…éƒ¨åŠä¹‹é—´çš„æ—¶ç©ºå…³ç³»ã€‚ç»è¿‡å…¨é¢è¯„ä¼°ï¼Œæˆ‘ä»¬è¯æ˜DELTAåœ¨åŸºäºäº‹ä»¶çš„æ·±åº¦ä¼°è®¡é—®é¢˜ä¸Šè®¾å®šäº†æ–°çš„æœ€å…ˆè¿›æ°´å¹³ï¼Œå¹¶ä¸”åœ¨è¿‘è·ç¦»ä¸‹èƒ½å¤Ÿå°†è¯¯å·®å‡å°‘è‡³ä¹‹å‰çš„å››åˆ†ä¹‹ä¸€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³äº‹ä»¶ç›¸æœºä¸LiDARæ•°æ®èåˆä¸è¶³çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨æ·±åº¦ä¼°è®¡ç²¾åº¦å’Œç¨ å¯†æ€§æ–¹é¢å­˜åœ¨æ˜æ˜¾çŸ­æ¿ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDELTAæ¶æ„é€šè¿‡å¼•å…¥è‡ªæ³¨æ„åŠ›å’Œäº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ•æ‰äº‹ä»¶æ•°æ®ä¸LiDARæ•°æ®ä¹‹é—´çš„æ—¶ç©ºå…³ç³»ï¼Œä»è€Œå®ç°æ›´é«˜ç²¾åº¦çš„æ·±åº¦ä¼°è®¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDELTAçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†æ¨¡å—ã€ç‰¹å¾æå–æ¨¡å—ã€æ³¨æ„åŠ›æœºåˆ¶æ¨¡å—å’Œæ·±åº¦å›¾ç”Ÿæˆæ¨¡å—ï¼Œå„æ¨¡å—ååŒå·¥ä½œä»¥å®ç°æ•°æ®èåˆä¸æ·±åº¦ä¼°è®¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šDELTAçš„ä¸»è¦åˆ›æ–°åœ¨äºåˆ©ç”¨æ³¨æ„åŠ›æœºåˆ¶å»ºæ¨¡äº‹ä»¶ä¸LiDARæ•°æ®ä¹‹é—´çš„å¤æ‚å…³ç³»ï¼Œè¿™ä¸€æ–¹æ³•åœ¨æ·±åº¦ä¼°è®¡é¢†åŸŸå°šå±é¦–æ¬¡ï¼Œæ˜¾è‘—æå‡äº†èåˆæ•ˆæœã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œç»“æ„ä¸Šï¼ŒDELTAé‡‡ç”¨äº†å¤šå±‚è‡ªæ³¨æ„åŠ›å’Œäº¤å‰æ³¨æ„åŠ›å±‚ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸Šåˆ™ç»“åˆäº†æ·±åº¦å›¾çš„ç¨ å¯†æ€§ä¸å‡†ç¡®æ€§ï¼Œç¡®ä¿æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­èƒ½å¤Ÿæœ‰æ•ˆå­¦ä¹ ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒDELTAåœ¨è¿‘è·ç¦»æ·±åº¦ä¼°è®¡ä¸­å°†è¯¯å·®é™ä½è‡³ä¹‹å‰æœ€å…ˆè¿›æ°´å¹³çš„å››åˆ†ä¹‹ä¸€ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿æ–¹æ³•ã€‚è¿™ä¸€æˆæœä¸ºäº‹ä»¶ç›¸æœºä¸LiDARæ•°æ®çš„èåˆæä¾›äº†æ–°çš„æ€è·¯å’Œæ–¹å‘ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªå’Œå¢å¼ºç°å®ç­‰åœºæ™¯ã€‚åœ¨è¿™äº›é¢†åŸŸä¸­ï¼Œå‡†ç¡®çš„æ·±åº¦ä¼°è®¡å¯¹äºç¯å¢ƒæ„ŸçŸ¥å’Œå†³ç­–åˆ¶å®šè‡³å…³é‡è¦ã€‚æœªæ¥ï¼ŒDELTAçš„æŠ€æœ¯å¯ä»¥è¿›ä¸€æ­¥æ¨åŠ¨å¤šæ¨¡æ€ä¼ æ„Ÿå™¨èåˆçš„å‘å±•ï¼Œæé«˜æ™ºèƒ½ç³»ç»Ÿçš„æ„ŸçŸ¥èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Event cameras and LiDARs provide complementary yet distinct data: respectively, asynchronous detections of changes in lighting versus sparse but accurate depth information at a fixed rate. To this day, few works have explored the combination of these two modalities. In this article, we propose a novel neural-network-based method for fusing event and LiDAR data in order to estimate dense depth maps. Our architecture, DELTA, exploits the concepts of self- and cross-attention to model the spatial and temporal relations within and between the event and LiDAR data. Following a thorough evaluation, we demonstrate that DELTA sets a new state of the art in the event-based depth estimation problem, and that it is able to reduce the errors up to four times for close ranges compared to the previous SOTA.

