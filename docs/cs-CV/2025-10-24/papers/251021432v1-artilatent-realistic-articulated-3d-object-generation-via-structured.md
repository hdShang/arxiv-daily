---
layout: default
title: ArtiLatent: Realistic Articulated 3D Object Generation via Structured Latents
---

# ArtiLatent: Realistic Articulated 3D Object Generation via Structured Latents

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.21432" target="_blank" class="toolbar-btn">arXiv: 2510.21432v1</a>
    <a href="https://arxiv.org/pdf/2510.21432.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.21432v1" 
            onclick="toggleFavorite(this, '2510.21432v1', 'ArtiLatent: Realistic Articulated 3D Object Generation via Structured Latents')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Honghua Chen, Yushi Lan, Yongwei Chen, Xingang Pan

**ÂàÜÁ±ª**: cs.CV, cs.GR

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-24

**Â§áÊ≥®**: accepted to SIGGRAPH Asia; Project page: https://chenhonghua.github.io/MyProjects/ArtiLatent/

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ArtiLatentÔºöÈÄöËøáÁªìÊûÑÂåñÈöêÁ©∫Èó¥ÁîüÊàêÈÄºÁúüÂèØÂä®3DÁâ©‰Ωì**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±ÂõõÔºöÁîüÊàêÂºèÂä®‰Ωú (Generative Motion)** **ÊîØÊü±‰∏ÉÔºöÂä®‰ΩúÈáçÂÆöÂêë (Motion Retargeting)**

**ÂÖ≥ÈîÆËØç**: `3DÁâ©‰ΩìÁîüÊàê` `ÂèØÂä®Áâ©‰Ωì` `ÈöêÁ©∫Èó¥Ë°®Á§∫` `Êâ©Êï£Ê®°Âûã` `Èì∞Êé•ÊÑüÁü•` `Âá†‰ΩïÂª∫Ê®°` `Â§ñËßÇÂª∫Ê®°`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÈöæ‰ª•ÁîüÊàêÂÖ∑ÊúâÁ≤æÁªÜÂá†‰Ωï„ÄÅÁ≤æÁ°ÆÈì∞Êé•ÂíåÈÄºÁúüÂ§ñËßÇÁöÑÂèØÂä®3DÁâ©‰ΩìÔºåÂ∞§ÂÖ∂ÊòØÂú®Èì∞Êé•Áä∂ÊÄÅÂèòÂåñÊó∂‰øùÊåÅËßÜËßâ‰∏ÄËá¥ÊÄß„ÄÇ
2. ArtiLatentÈÄöËøáÁªìÊûÑÂåñÈöêÁ©∫Èó¥ËÅîÂêàÂª∫Ê®°ÈÉ®‰ª∂Âá†‰ΩïÂíåÈì∞Êé•Âä®ÊÄÅÔºåÂà©Áî®ÈöêÊâ©Êï£Ê®°ÂûãÁîüÊàêÂ§öÊ†∑‰∏îÁâ©ÁêÜÂèØ‰ø°ÁöÑÊ†∑Êú¨„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåArtiLatentÂú®Âá†‰Ωï‰∏ÄËá¥ÊÄßÂíåÂ§ñËßÇ‰øùÁúüÂ∫¶‰∏ä‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÂ∞§ÂÖ∂Âú®Èì∞Êé•Áä∂ÊÄÅÂèòÂåñÊó∂ËÉΩ‰øùÊåÅËßÜËßâÁúüÂÆûÊÑü„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êàë‰ª¨ÊèêÂá∫‰∫ÜArtiLatentÔºå‰∏Ä‰∏™ÁîüÊàêÊ°ÜÊû∂ÔºåÁî®‰∫éÂêàÊàêÂÖ∑ÊúâÁ≤æÁªÜÂá†‰ΩïÂΩ¢Áä∂„ÄÅÁ≤æÁ°ÆÈì∞Êé•ÂíåÈÄºÁúüÂ§ñËßÇÁöÑ‰∫∫ÈÄ†3DÁâ©‰Ωì„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÈÄöËøáÂèòÂàÜËá™ÁºñÁ†ÅÂô®Â∞ÜÁ®ÄÁñè‰ΩìÁ¥†Ë°®Á§∫ÂíåÁõ∏ÂÖ≥ÁöÑÈì∞Êé•Â±ûÊÄßÔºàÂåÖÊã¨ÂÖ≥ËäÇÁ±ªÂûã„ÄÅËΩ¥„ÄÅÂéüÁÇπ„ÄÅËåÉÂõ¥ÂíåÈÉ®‰ª∂Á±ªÂà´ÔºâÂµåÂÖ•Âà∞Áªü‰∏ÄÁöÑÈöêÁ©∫Èó¥‰∏≠Ôºå‰ªéËÄåËÅîÂêàÂª∫Ê®°ÈÉ®‰ª∂Âá†‰ΩïÂΩ¢Áä∂ÂíåÈì∞Êé•Âä®ÊÄÅ„ÄÇÁÑ∂ÂêéÔºåÂú®Ëøô‰∏™Á©∫Èó¥‰∏äËÆ≠ÁªÉ‰∏Ä‰∏™ÈöêÊâ©Êï£Ê®°ÂûãÔºå‰ª•ÂÆûÁé∞Â§öÊ†∑‰ΩÜÁâ©ÁêÜ‰∏äÂêàÁêÜÁöÑÈááÊ†∑„ÄÇ‰∏∫‰∫ÜÈáçÂª∫ÈÄºÁúüÁöÑ3DÂΩ¢Áä∂ÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏Ä‰∏™Èì∞Êé•ÊÑüÁü•È´òÊñØËß£Á†ÅÂô®ÔºåËØ•Ëß£Á†ÅÂô®ËÄÉËôë‰∫ÜÈì∞Êé•Áõ∏ÂÖ≥ÁöÑÂèØËßÅÊÄßÂèòÂåñÔºà‰æãÂ¶ÇÔºåÊâìÂºÄÊäΩÂ±âÊó∂Èú≤Âá∫ÂÜÖÈÉ®Ôºâ„ÄÇÈÄöËøáÂ∞ÜÂ§ñËßÇËß£Á†ÅÂª∫Á´ãÂú®Èì∞Êé•Áä∂ÊÄÅÁöÑÂü∫Á°Ä‰∏äÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ï‰∏∫ÈùôÊÄÅÂßøÂäø‰∏≠ÈÄöÂ∏∏Ë¢´ÈÅÆÊå°ÁöÑÂå∫ÂüüÂàÜÈÖçÂêàÁêÜÁöÑÁ∫πÁêÜÁâπÂæÅÔºå‰ªéËÄåÊòæËëóÊèêÈ´ò‰∫ÜÂêÑÁßçÈì∞Êé•ÈÖçÁΩÆ‰∏≠ÁöÑËßÜËßâÁúüÂÆûÊÑü„ÄÇÂú®PartNet-MobilityÂíåACDÊï∞ÊçÆÈõÜ‰∏≠ÔºåÂØπÁ±ª‰ººÂÆ∂ÂÖ∑ÁöÑÁâ©‰ΩìËøõË°åÁöÑÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåArtiLatentÂú®Âá†‰Ωï‰∏ÄËá¥ÊÄßÂíåÂ§ñËßÇ‰øùÁúüÂ∫¶ÊñπÈù¢‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇÊàë‰ª¨ÁöÑÊ°ÜÊû∂‰∏∫ÂèØÂä®3DÁâ©‰ΩìÁöÑÂêàÊàêÂíåÊìç‰ΩúÊèê‰æõ‰∫Ü‰∏Ä‰∏™ÂèØÊâ©Â±ïÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥ÁîüÊàêÂÖ∑ÊúâÁúüÂÆûÊÑüÁöÑÂèØÂä®3DÁâ©‰ΩìÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®ÁîüÊàêÂÖ∑ÊúâÂ§çÊùÇÂá†‰ΩïÂΩ¢Áä∂„ÄÅÁ≤æÁ°ÆÈì∞Êé•ÂíåÈÄºÁúüÂ§ñËßÇÁöÑ3DÁâ©‰ΩìÊñπÈù¢Â≠òÂú®Âõ∞ÈöæÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§ÑÁêÜÈì∞Êé•ÈÉ®‰ª∂ÁöÑÈÅÆÊå°ÂíåÁ∫πÁêÜÂèòÂåñÊó∂ÔºåÈöæ‰ª•‰øùËØÅËßÜËßâ‰∏ÄËá¥ÊÄß„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜÈÉ®‰ª∂ÁöÑÂá†‰ΩïÂΩ¢Áä∂ÂíåÈì∞Êé•Â±ûÊÄßÁºñÁ†ÅÂà∞Áªü‰∏ÄÁöÑÈöêÁ©∫Èó¥‰∏≠ÔºåÂπ∂Âà©Áî®ÈöêÊâ©Êï£Ê®°ÂûãÁîüÊàêÂ§öÊ†∑ÂåñÁöÑÊ†∑Êú¨„ÄÇÈÄöËøáÈì∞Êé•ÊÑüÁü•ÁöÑÈ´òÊñØËß£Á†ÅÂô®ÔºåËÄÉËôëÈì∞Êé•Áä∂ÊÄÅÂØπÂèØËßÅÊÄßÁöÑÂΩ±ÂìçÔºå‰ªéËÄå‰∏∫ÈÄöÂ∏∏Ë¢´ÈÅÆÊå°ÁöÑÂå∫ÂüüÂàÜÈÖçÂêàÁêÜÁöÑÁ∫πÁêÜÁâπÂæÅÔºåÊèêÈ´òËßÜËßâÁúüÂÆûÊÑü„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöArtiLatentÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ã‰∏ªË¶ÅÊ®°ÂùóÔºö1) ÂèòÂàÜËá™ÁºñÁ†ÅÂô®ÔºàVAEÔºâÔºåÁî®‰∫éÂ∞ÜÁ®ÄÁñè‰ΩìÁ¥†Ë°®Á§∫ÂíåÈì∞Êé•Â±ûÊÄßÁºñÁ†ÅÂà∞ÈöêÁ©∫Èó¥Ôºõ2) ÈöêÊâ©Êï£Ê®°ÂûãÔºåÁî®‰∫éÂú®ÈöêÁ©∫Èó¥‰∏≠ÁîüÊàêÊñ∞ÁöÑÊ†∑Êú¨Ôºõ3) Èì∞Êé•ÊÑüÁü•È´òÊñØËß£Á†ÅÂô®ÔºåÁî®‰∫éÂ∞ÜÈöêÁ©∫Èó¥‰∏≠ÁöÑÊ†∑Êú¨Ëß£Á†Å‰∏∫3DÂΩ¢Áä∂ÔºåÂπ∂ËÄÉËôëÈì∞Êé•Áä∂ÊÄÅÂØπÂèØËßÅÊÄßÁöÑÂΩ±Âìç„ÄÇÊï¥‰ΩìÊµÅÁ®ãÊòØÂÖàÈÄöËøáVAEÂ∞Ü3DÁâ©‰ΩìÁºñÁ†ÅÂà∞ÈöêÁ©∫Èó¥ÔºåÁÑ∂ÂêéÂà©Áî®ÈöêÊâ©Êï£Ê®°ÂûãÁîüÊàêÊñ∞ÁöÑÈöêÁ©∫Èó¥ÂêëÈáèÔºåÊúÄÂêéÈÄöËøáÈì∞Êé•ÊÑüÁü•È´òÊñØËß£Á†ÅÂô®Â∞ÜÈöêÁ©∫Èó¥ÂêëÈáèËß£Á†Å‰∏∫3DÁâ©‰Ωì„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1) ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Áªü‰∏ÄÁöÑÈöêÁ©∫Èó¥Êù•ËÅîÂêàÂª∫Ê®°ÈÉ®‰ª∂Âá†‰ΩïÂΩ¢Áä∂ÂíåÈì∞Êé•Âä®ÊÄÅÔºõ2) ÂºïÂÖ•‰∫ÜÈì∞Êé•ÊÑüÁü•È´òÊñØËß£Á†ÅÂô®ÔºåËÄÉËôë‰∫ÜÈì∞Êé•Áä∂ÊÄÅÂØπÂèØËßÅÊÄßÁöÑÂΩ±ÂìçÔºå‰ªéËÄåÊèêÈ´ò‰∫ÜËßÜËßâÁúüÂÆûÊÑüÔºõ3) Âà©Áî®ÈöêÊâ©Êï£Ê®°ÂûãÁîüÊàêÂ§öÊ†∑ÂåñÁöÑÊ†∑Êú¨„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåArtiLatentËÉΩÂ§üÁîüÊàêÊõ¥ÈÄºÁúü„ÄÅÊõ¥ÂÖ∑Âá†‰Ωï‰∏ÄËá¥ÊÄßÁöÑÂèØÂä®3DÁâ©‰Ωì„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËÆ∫Êñá‰ΩøÁî®‰∫ÜÁ®ÄÁñè‰ΩìÁ¥†Ë°®Á§∫Êù•Ë°®Á§∫3DÁâ©‰ΩìÁöÑÂá†‰ΩïÂΩ¢Áä∂„ÄÇÈì∞Êé•Â±ûÊÄßÂåÖÊã¨ÂÖ≥ËäÇÁ±ªÂûã„ÄÅËΩ¥„ÄÅÂéüÁÇπ„ÄÅËåÉÂõ¥ÂíåÈÉ®‰ª∂Á±ªÂà´„ÄÇÂèòÂàÜËá™ÁºñÁ†ÅÂô®ÁöÑÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨ÈáçÂª∫ÊçüÂ§±ÂíåKLÊï£Â∫¶„ÄÇÈöêÊâ©Êï£Ê®°Âûã‰ΩøÁî®U-NetÊû∂ÊûÑ„ÄÇÈì∞Êé•ÊÑüÁü•È´òÊñØËß£Á†ÅÂô®ÈÄöËøáÂ∞ÜÈì∞Êé•Áä∂ÊÄÅ‰Ωú‰∏∫Êù°‰ª∂ËæìÂÖ•Êù•Ë∞ÉÊï¥Ëß£Á†ÅËøáÁ®ã„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåArtiLatentÂú®PartNet-MobilityÂíåACDÊï∞ÊçÆÈõÜ‰∏äÔºåÂú®Âá†‰Ωï‰∏ÄËá¥ÊÄßÂíåÂ§ñËßÇ‰øùÁúüÂ∫¶ÊñπÈù¢Âùá‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇÈÄöËøáÈì∞Êé•ÊÑüÁü•Ëß£Á†ÅÂô®ÔºåArtiLatentËÉΩÂ§ü‰∏∫ÈÄöÂ∏∏Ë¢´ÈÅÆÊå°ÁöÑÂå∫ÂüüÂàÜÈÖçÂêàÁêÜÁöÑÁ∫πÁêÜÁâπÂæÅÔºåÊòæËëóÊèêÈ´ò‰∫ÜËßÜËßâÁúüÂÆûÊÑü„ÄÇÂÆöÊÄßÂíåÂÆöÈáèÁªìÊûúÈÉΩËØÅÊòé‰∫ÜArtiLatentÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ArtiLatentÂèØÂ∫îÁî®‰∫éÊ∏∏ÊàèÂºÄÂèë„ÄÅËôöÊãüÁé∞ÂÆû„ÄÅÊú∫Âô®‰∫∫‰ªøÁúüÁ≠âÈ¢ÜÂüüÔºå‰∏∫Ëøô‰∫õÈ¢ÜÂüüÊèê‰æõÈ´òË¥®Èáè„ÄÅÂèØÂÆöÂà∂ÁöÑÂèØÂä®3DÁâ©‰ΩìËµÑÊ∫ê„ÄÇËØ•Á†îÁ©∂ÊúâÂä©‰∫éÊèêÂçáËôöÊãüÁéØÂ¢ÉÁöÑÁúüÂÆûÊÑüÂíå‰∫§‰∫íÊÄßÔºåÂπ∂‰∏∫Êú∫Âô®‰∫∫Êìç‰ΩúÂíåËßÑÂàíÊèê‰æõÊõ¥ÈÄºÁúüÁöÑÁéØÂ¢ÉÊ®°Âûã„ÄÇÊú™Êù•ÔºåËØ•ÊäÄÊúØÂèØÊâ©Â±ïÂà∞Êõ¥Â§çÊùÇÁöÑÁâ©‰ΩìÂíåÂú∫ÊôØÔºåÂπ∂Â∫îÁî®‰∫éËá™Âä®È©æÈ©∂„ÄÅÊô∫ËÉΩÂÆ∂Â±ÖÁ≠âÈ¢ÜÂüü„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> We propose ArtiLatent, a generative framework that synthesizes human-made 3D objects with fine-grained geometry, accurate articulation, and realistic appearance. Our approach jointly models part geometry and articulation dynamics by embedding sparse voxel representations and associated articulation properties, including joint type, axis, origin, range, and part category, into a unified latent space via a variational autoencoder. A latent diffusion model is then trained over this space to enable diverse yet physically plausible sampling. To reconstruct photorealistic 3D shapes, we introduce an articulation-aware Gaussian decoder that accounts for articulation-dependent visibility changes (e.g., revealing the interior of a drawer when opened). By conditioning appearance decoding on articulation state, our method assigns plausible texture features to regions that are typically occluded in static poses, significantly improving visual realism across articulation configurations. Extensive experiments on furniture-like objects from PartNet-Mobility and ACD datasets demonstrate that ArtiLatent outperforms existing approaches in geometric consistency and appearance fidelity. Our framework provides a scalable solution for articulated 3D object synthesis and manipulation.

