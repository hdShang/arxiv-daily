---
layout: default
title: Controllable-LPMoE: Adapting to Challenging Object Segmentation via Dynamic Local Priors from Mixture-of-Experts
---

# Controllable-LPMoE: Adapting to Challenging Object Segmentation via Dynamic Local Priors from Mixture-of-Experts

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.21114" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.21114v1</a>
  <a href="https://arxiv.org/pdf/2510.21114.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.21114v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.21114v1', 'Controllable-LPMoE: Adapting to Challenging Object Segmentation via Dynamic Local Priors from Mixture-of-Experts')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yanguang Sun, Jiawei Lian, Jian Yang, Lei Luo

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-24

**å¤‡æ³¨**: Accepted at ICCV 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/CSYSI/Controllable-LPMoE)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Controllable-LPMoEï¼šé€šè¿‡åŠ¨æ€å±€éƒ¨å…ˆéªŒæ··åˆä¸“å®¶ç½‘ç»œæå‡ç›®æ ‡åˆ†å‰²æ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç›®æ ‡åˆ†å‰²` `é¢„è®­ç»ƒæ¨¡å‹` `å¾®è°ƒ` `å±€éƒ¨å…ˆéªŒ` `æ··åˆä¸“å®¶ç½‘ç»œ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å…¨å‚æ•°å¾®è°ƒæ–¹æ³•è®¡ç®—å¼€é”€å¤§ï¼Œpromptå¾®è°ƒç¼ºä¹è¯­ä¹‰å…ˆéªŒï¼Œé™åˆ¶äº†é¢„è®­ç»ƒæ¨¡å‹çš„é€‚åº”æ€§ã€‚
2. æå‡ºControllable-LPMoEï¼Œé€šè¿‡åŠ¨æ€æ§åˆ¶å±€éƒ¨å…ˆéªŒè‡ªé€‚åº”è°ƒèŠ‚é¢„è®­ç»ƒæ¨¡å‹ï¼Œå¢å¼ºç»†ç²’åº¦æ„ŸçŸ¥èƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªäºŒå…ƒç›®æ ‡åˆ†å‰²ä»»åŠ¡ä¸Šä¼˜äº31ç§SOTAæ–¹æ³•ï¼Œå…·æœ‰å‡ºè‰²çš„åˆ†å‰²æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ä¸ºä¸‹æ¸¸ç›®æ ‡åˆ†å‰²ä»»åŠ¡æä¾›äº†å¼ºå¤§çš„ç‰¹å¾è¡¨ç¤ºã€‚ç„¶è€Œï¼Œé€šè¿‡å…¨å‚æ•°å¾®è°ƒå°†è¿™äº›æ¨¡å‹é€‚é…åˆ°ç‰¹å®šä»»åŠ¡æ—¶ï¼Œéœ€è¦æ›´æ–°çš„å‚æ•°é‡å·¨å¤§ï¼Œå¯¼è‡´è®¡ç®—å¼€é”€æ˜¾è‘—å¢åŠ ï¼Œæˆä¸ºè®­ç»ƒæ•ˆç‡çš„ç“¶é¢ˆã€‚ç°æœ‰æ–¹æ³•å°è¯•é€šè¿‡ç›´æ¥åµŒå…¥å¯è®­ç»ƒçš„æç¤ºï¼ˆpromptï¼‰æ¥å¾®è°ƒå†»ç»“çš„æ¨¡å‹ï¼Œä½†è¿™äº›æç¤ºç¼ºä¹å›ºæœ‰çš„è¯­ä¹‰å…ˆéªŒï¼Œé™åˆ¶äº†å¤§è§„æ¨¡æ¨¡å‹çš„é€‚åº”æ€§ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºåŠ¨æ€å…ˆéªŒçš„å¾®è°ƒèŒƒå¼ï¼Œåä¸ºControllable-LPMoEï¼Œå®ƒé€šè¿‡åŠ¨æ€æ§åˆ¶å±€éƒ¨å…ˆéªŒæ¥è‡ªé€‚åº”åœ°è°ƒèŠ‚å†»ç»“çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œä»è€Œå¢å¼ºç‰¹å®šåˆ†å‰²ä»»åŠ¡çš„ç»†ç²’åº¦æ„ŸçŸ¥èƒ½åŠ›ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªè½»é‡çº§çš„åŠ¨æ€æ··åˆå±€éƒ¨å…ˆéªŒæå–å™¨ï¼Œé€šè¿‡å¼‚æ„å·ç§¯ä»è¾“å…¥å›¾åƒä¸­æ•è·ä¸åŒçš„å±€éƒ¨å…ˆéªŒï¼Œå¹¶é‡‡ç”¨é—¨æ§ç½‘ç»œåŠ¨æ€è¾“å‡ºåç»­å¾®è°ƒæ‰€éœ€çš„ä¸“å®¶å…ˆéªŒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªåŒå‘äº¤äº’é€‚é…å™¨ï¼Œé‡‡ç”¨ä½™å¼¦å¯¹é½çš„å¯å˜å½¢æ³¨æ„åŠ›å’Œé€šé“å¯¼å‘çš„è‡ªé€‚åº”å°ºåº¦å¢å¼ºï¼Œåœ¨å†»ç»“ç‰¹å¾å’Œå¯è®­ç»ƒç‰¹å¾ä¹‹é—´è¿›è¡Œäº¤äº’å’Œé‡æ„ï¼Œå®ç°é«˜æ•ˆå¾®è°ƒã€‚å¤§é‡å®éªŒéªŒè¯äº†Controllable-LPMoEæ–¹æ³•çš„ä¼˜è¶Šæ€§ï¼Œè¡¨æ˜å…¶åœ¨å¤šä¸ªäºŒå…ƒç›®æ ‡åˆ†å‰²ä»»åŠ¡ä¸­ç›¸æ¯”äº31ç§æœ€å…ˆè¿›æ–¹æ³•å…·æœ‰å‡ºè‰²çš„åˆ†å‰²æ€§èƒ½å’Œé€‚åº”æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹åœ¨ç›®æ ‡åˆ†å‰²ä»»åŠ¡ä¸­å…¨å‚æ•°å¾®è°ƒæ—¶è®¡ç®—å¼€é”€è¿‡å¤§ï¼Œä»¥åŠpromptå¾®è°ƒæ–¹æ³•ç¼ºä¹è¯­ä¹‰å…ˆéªŒçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥åœ¨è®¡ç®—æ•ˆç‡å’Œæ¨¡å‹é€‚åº”æ€§ä¹‹é—´å–å¾—å¹³è¡¡ï¼Œé™åˆ¶äº†é¢„è®­ç»ƒæ¨¡å‹åœ¨ç‰¹å®šåˆ†å‰²ä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼•å…¥åŠ¨æ€å±€éƒ¨å…ˆéªŒæ¥æŒ‡å¯¼é¢„è®­ç»ƒæ¨¡å‹çš„å¾®è°ƒè¿‡ç¨‹ã€‚é€šè¿‡æå–å’Œåˆ©ç”¨å›¾åƒçš„å±€éƒ¨å…ˆéªŒä¿¡æ¯ï¼Œæ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œåˆ†å‰²ç›®æ ‡ï¼ŒåŒæ—¶é¿å…äº†å…¨å‚æ•°å¾®è°ƒå¸¦æ¥çš„å·¨å¤§è®¡ç®—å¼€é”€ã€‚åŠ¨æ€æ··åˆä¸“å®¶ç½‘ç»œçš„è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ ¹æ®è¾“å…¥å›¾åƒè‡ªé€‚åº”åœ°é€‰æ‹©åˆé€‚çš„å…ˆéªŒä¿¡æ¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šControllable-LPMoEä¸»è¦åŒ…å«ä¸¤ä¸ªæ ¸å¿ƒæ¨¡å—ï¼šåŠ¨æ€æ··åˆå±€éƒ¨å…ˆéªŒæå–å™¨å’ŒåŒå‘äº¤äº’é€‚é…å™¨ã€‚é¦–å…ˆï¼ŒåŠ¨æ€æ··åˆå±€éƒ¨å…ˆéªŒæå–å™¨é€šè¿‡å¼‚æ„å·ç§¯æå–å›¾åƒçš„å±€éƒ¨å…ˆéªŒï¼Œå¹¶ä½¿ç”¨é—¨æ§ç½‘ç»œé€‰æ‹©åˆé€‚çš„ä¸“å®¶å…ˆéªŒã€‚ç„¶åï¼ŒåŒå‘äº¤äº’é€‚é…å™¨åˆ©ç”¨ä½™å¼¦å¯¹é½çš„å¯å˜å½¢æ³¨æ„åŠ›å’Œé€šé“å¯¼å‘çš„è‡ªé€‚åº”å°ºåº¦å¢å¼ºï¼Œåœ¨å†»ç»“çš„é¢„è®­ç»ƒæ¨¡å‹ç‰¹å¾å’Œå¯è®­ç»ƒçš„å±€éƒ¨å…ˆéªŒç‰¹å¾ä¹‹é—´è¿›è¡Œäº¤äº’å’Œèåˆã€‚æœ€ç»ˆï¼Œèåˆåçš„ç‰¹å¾ç”¨äºç›®æ ‡åˆ†å‰²ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•çš„ä¸»è¦åˆ›æ–°åœ¨äºåŠ¨æ€å±€éƒ¨å…ˆéªŒçš„å¼•å…¥å’Œæ··åˆä¸“å®¶ç½‘ç»œçš„è®¾è®¡ã€‚ä¸ä¼ ç»Ÿçš„promptå¾®è°ƒæ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåˆ©ç”¨å›¾åƒçš„å±€éƒ¨ä¿¡æ¯ï¼Œæä¾›æ›´ä¸°å¯Œçš„è¯­ä¹‰å…ˆéªŒã€‚åŠ¨æ€æ··åˆä¸“å®¶ç½‘ç»œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ ¹æ®è¾“å…¥è‡ªé€‚åº”åœ°é€‰æ‹©åˆé€‚çš„å…ˆéªŒï¼Œæé«˜äº†æ¨¡å‹çš„é€‚åº”æ€§ã€‚åŒå‘äº¤äº’é€‚é…å™¨åˆ™å®ç°äº†å†»ç»“ç‰¹å¾å’Œå¯è®­ç»ƒç‰¹å¾ä¹‹é—´çš„æœ‰æ•ˆèåˆã€‚

**å…³é”®è®¾è®¡**ï¼šåŠ¨æ€æ··åˆå±€éƒ¨å…ˆéªŒæå–å™¨ä½¿ç”¨å¼‚æ„å·ç§¯æ¥æ•è·ä¸åŒå°ºåº¦çš„å±€éƒ¨å…ˆéªŒä¿¡æ¯ã€‚é—¨æ§ç½‘ç»œçš„è®¾è®¡å…è®¸æ¨¡å‹æ ¹æ®è¾“å…¥å›¾åƒçš„ç‰¹å¾åŠ¨æ€åœ°é€‰æ‹©åˆé€‚çš„ä¸“å®¶å…ˆéªŒã€‚åŒå‘äº¤äº’é€‚é…å™¨ä¸­çš„ä½™å¼¦å¯¹é½å¯å˜å½¢æ³¨æ„åŠ›èƒ½å¤Ÿæ›´å¥½åœ°å¯¹é½ä¸åŒç‰¹å¾ä¹‹é—´çš„ç©ºé—´å…³ç³»ã€‚é€šé“å¯¼å‘çš„è‡ªé€‚åº”å°ºåº¦å¢å¼ºåˆ™èƒ½å¤Ÿè°ƒæ•´ä¸åŒé€šé“çš„ç‰¹å¾å°ºåº¦ï¼Œæé«˜ç‰¹å¾çš„è¡¨è¾¾èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒControllable-LPMoEåœ¨å¤šä¸ªäºŒå…ƒç›®æ ‡åˆ†å‰²ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¶…è¶Šäº†31ç§SOTAæ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨æŸä¸ªæ•°æ®é›†ä¸Šï¼ŒControllable-LPMoEçš„åˆ†å‰²ç²¾åº¦æ¯”æœ€ä½³åŸºçº¿æ–¹æ³•æé«˜äº†X%ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•ä»…éœ€å¾®è°ƒå°‘é‡å‚æ•°ï¼Œå¤§å¤§é™ä½äº†è®¡ç®—å¼€é”€ï¼ŒéªŒè¯äº†å…¶é«˜æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Controllable-LPMoEåœ¨äºŒå…ƒç›®æ ‡åˆ†å‰²ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œå¯åº”ç”¨äºåŒ»å­¦å›¾åƒåˆ†æï¼ˆå¦‚è‚¿ç˜¤åˆ†å‰²ï¼‰ã€é¥æ„Ÿå›¾åƒåˆ†æï¼ˆå¦‚å»ºç­‘ç‰©æå–ï¼‰ã€è‡ªåŠ¨é©¾é©¶ï¼ˆå¦‚é“è·¯åˆ†å‰²ï¼‰ç­‰é¢†åŸŸã€‚è¯¥æ–¹æ³•é€šè¿‡é«˜æ•ˆå¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹ï¼Œé™ä½äº†è®¡ç®—æˆæœ¬ï¼Œä½¿å¾—å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°åº”ç”¨äºèµ„æºå—é™çš„åœºæ™¯ï¼Œå…·æœ‰é‡è¦çš„å®é™…åº”ç”¨ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large-scale foundation models provide powerful feature representations for downstream object segmentation tasks. However, when adapted to specific tasks through the full-parameter fine-tuning, the enormous parameters being updated often results in significant computational overhead, creating a bottleneck in training efficiency. Although existing methods attempt to fine-tune frozen models by directly embedding trainable prompts, these prompts lack inherent semantic priors, limiting the adaptability of large-scale models. In this paper, we propose a novel dynamic priors-based fine-tuning paradigm with fewer trainable parameters, dubbed Controllable-LPMoE, which adaptively modulates frozen foundation models by dynamically controlling local priors to enhance fine-grained perception for specific segmentation tasks. More specifically, we construct a lightweight dynamic mixed local priors extractor that captures diverse local priors from input images through heterogeneous convolutions while employing a gating network to dynamically output expert priors required for the subsequent fine-tuning. Furthermore, we design a bi-directional interaction adapter that employs cosine-aligned deformable attention and channel-oriented adaptive scale enhancement to interact and restructure between frozen and trainable features, achieving efficient fine-tuning. Extensive experiments validate the superiority of our \href{https://github.com/CSYSI/Controllable-LPMoE} {Controllable-LPMoE} approach, demonstrating excellent segmentation performance compared to 31 state-of-the-art (SOTA) methods and adaptability to multiple binary object segmentation tasks.

