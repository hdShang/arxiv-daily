---
layout: default
title: Blockwise Flow Matching: Improving Flow Matching Models For Efficient High-Quality Generation
---

# Blockwise Flow Matching: Improving Flow Matching Models For Efficient High-Quality Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.21167" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.21167v1</a>
  <a href="https://arxiv.org/pdf/2510.21167.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.21167v1" onclick="toggleFavorite(this, '2510.21167v1', 'Blockwise Flow Matching: Improving Flow Matching Models For Efficient High-Quality Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Dogyun Park, Taehoon Lee, Minseok Joo, Hyunwoo J. Kim

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-24

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/mlvlab/BFM)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºBlockwise Flow Matchingï¼Œæå‡Flow Matchingæ¨¡å‹ç”Ÿæˆæ•ˆç‡å’Œè´¨é‡ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `Flow Matching` `ç”Ÿæˆæ¨¡å‹` `å›¾åƒç”Ÿæˆ` `æ¨ç†åŠ é€Ÿ` `åˆ†å—å»ºæ¨¡` `è¯­ä¹‰ç‰¹å¾å¼•å¯¼` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰Flow Matchingæ¨¡å‹ä½¿ç”¨å•ä¸€å¤§å‹ç½‘ç»œï¼Œéš¾ä»¥å…¼é¡¾ä¸åŒæ—¶é—´æ­¥çš„ä¿¡å·ç‰¹å¾ï¼Œä¸”æ¨ç†æˆæœ¬é«˜æ˜‚ã€‚
2. BFMå°†ç”Ÿæˆè½¨è¿¹åˆ†æ®µï¼Œç”¨å°å‹ä¸“ä¸šç½‘ç»œå»ºæ¨¡ï¼Œæå‡æ¨ç†æ•ˆç‡å’Œç”Ÿæˆè´¨é‡ï¼Œå¹¶å¼•å…¥è¯­ä¹‰ç‰¹å¾å¼•å¯¼ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒBFMåœ¨ImageNet 256x256ä¸Šå®ç°äº†æ›´ä¼˜çš„Paretoå‰æ²¿ï¼Œæ¨ç†é€Ÿåº¦æå‡2.1åˆ°4.9å€ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

Flow Matchingæ¨¡å‹åœ¨å¤šä¸ªé¢†åŸŸçš„æ•°æ®ç”Ÿæˆæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•é€šå¸¸ä½¿ç”¨å•ä¸ªå¤§å‹ç½‘ç»œå­¦ä¹ ä»å™ªå£°åˆ°æ•°æ®çš„æ•´ä¸ªç”Ÿæˆè½¨è¿¹ï¼Œéš¾ä»¥åŒæ—¶æ•æ‰ä¸åŒæ—¶é—´æ­¥é•¿çš„ä¿¡å·ç‰¹å¾ï¼Œå¹¶ä¸”ç”±äºéœ€è¦è¿­ä»£è¯„ä¼°æ•´ä¸ªæ¨¡å‹è€Œå¯¼è‡´æ¨ç†æˆæœ¬é«˜æ˜‚ã€‚ä¸ºäº†è§£å†³è¿™äº›é™åˆ¶ï¼Œæœ¬æ–‡æå‡ºäº†Blockwise Flow Matching (BFM)ï¼Œè¯¥æ¡†æ¶å°†ç”Ÿæˆè½¨è¿¹åˆ’åˆ†ä¸ºå¤šä¸ªæ—¶é—´æ®µï¼Œæ¯ä¸ªæ—¶é—´æ®µç”±æ›´å°ä½†æ›´ä¸“ä¸šçš„é€Ÿåº¦å—å»ºæ¨¡ã€‚è¿™ç§åˆ†å—è®¾è®¡ä½¿æ¯ä¸ªå—èƒ½å¤Ÿæœ‰æ•ˆåœ°ä¸“æ³¨äºå…¶æŒ‡å®šçš„æ—¶é—´é—´éš”ï¼Œä»è€Œæé«˜æ¨ç†æ•ˆç‡å’Œæ ·æœ¬è´¨é‡ã€‚ä¸ºäº†è¿›ä¸€æ­¥æé«˜ç”Ÿæˆä¿çœŸåº¦ï¼Œæœ¬æ–‡å¼•å…¥äº†è¯­ä¹‰ç‰¹å¾å¼•å¯¼æ¨¡å—ï¼Œè¯¥æ¨¡å—æ˜¾å¼åœ°å°†é€Ÿåº¦å—ä¸å’Œé¢„è®­ç»ƒè¡¨ç¤ºå¯¹é½çš„è¯­ä¹‰ç‰¹å¾ç›¸å…³è”ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§è½»é‡çº§çš„ç‰¹å¾æ®‹å·®è¿‘ä¼¼ç­–ç•¥ï¼Œè¯¥ç­–ç•¥åœ¨æ˜¾è‘—é™ä½æ¨ç†æˆæœ¬çš„åŒæ—¶ä¿æŒäº†è¯­ä¹‰è´¨é‡ã€‚åœ¨ImageNet 256x256ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒBFMåœ¨ç°æœ‰Flow Matchingæ–¹æ³•ä¸Šå»ºç«‹äº†æ˜¾è‘—æ”¹è¿›çš„Paretoå‰æ²¿ï¼Œåœ¨å¯æ¯”çš„ç”Ÿæˆæ€§èƒ½ä¸‹å®ç°äº†2.1å€è‡³4.9å€çš„æ¨ç†åŠ é€Ÿã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šFlow Matchingæ¨¡å‹åœ¨é«˜è´¨é‡æ•°æ®ç”Ÿæˆä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†ç°æœ‰æ–¹æ³•ä½¿ç”¨å•ä¸ªå¤§å‹ç½‘ç»œå¤„ç†æ•´ä¸ªç”Ÿæˆè¿‡ç¨‹ï¼Œå¯¼è‡´ä¸¤ä¸ªä¸»è¦é—®é¢˜ï¼šä¸€æ˜¯éš¾ä»¥æ•æ‰ä¸åŒæ—¶é—´æ­¥é•¿çš„ç‹¬ç‰¹ä¿¡å·ç‰¹å¾ï¼›äºŒæ˜¯ç”±äºéœ€è¦è¿­ä»£è¯„ä¼°æ•´ä¸ªæ¨¡å‹ï¼Œæ¨ç†æˆæœ¬å¾ˆé«˜ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§æ›´é«˜æ•ˆä¸”èƒ½æ›´å¥½æ•æ‰æ—¶é—´æ­¥é•¿ç‰¹å¾çš„Flow Matchingæ¨¡å‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šBFMçš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†è¿ç»­çš„ç”Ÿæˆè½¨è¿¹åˆ†å‰²æˆå¤šä¸ªç¦»æ•£çš„å—ï¼ˆBlockï¼‰ï¼Œæ¯ä¸ªå—ç”±ä¸€ä¸ªä¸“é—¨çš„å°å‹ç½‘ç»œï¼ˆé€Ÿåº¦å—ï¼‰è´Ÿè´£ã€‚é€šè¿‡è¿™ç§åˆ†è€Œæ²»ä¹‹çš„æ–¹å¼ï¼Œæ¯ä¸ªé€Ÿåº¦å—å¯ä»¥ä¸“æ³¨äºç‰¹å®šæ—¶é—´æ®µå†…çš„ä¿¡å·ç‰¹å¾ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ•´ä½“è¡¨è¾¾èƒ½åŠ›å’Œæ¨ç†æ•ˆç‡ã€‚åŒæ—¶ï¼Œå¼•å…¥è¯­ä¹‰ç‰¹å¾å¼•å¯¼ï¼Œåˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹çš„çŸ¥è¯†æ¥æå‡ç”Ÿæˆè´¨é‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šBFMçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦ç»„æˆéƒ¨åˆ†ï¼š1) **è½¨è¿¹åˆ†å—**ï¼šå°†è¿ç»­çš„ç”Ÿæˆè½¨è¿¹åˆ’åˆ†ä¸ºå¤šä¸ªæ—¶é—´æ®µã€‚2) **é€Ÿåº¦å—**ï¼šæ¯ä¸ªæ—¶é—´æ®µå¯¹åº”ä¸€ä¸ªå°å‹ç¥ç»ç½‘ç»œï¼Œç”¨äºå­¦ä¹ è¯¥æ—¶é—´æ®µå†…çš„é€Ÿåº¦åœºã€‚3) **è¯­ä¹‰ç‰¹å¾å¼•å¯¼æ¨¡å—**ï¼šåˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹æå–çš„è¯­ä¹‰ç‰¹å¾ï¼Œå¼•å¯¼é€Ÿåº¦å—çš„å­¦ä¹ ï¼Œæå‡ç”Ÿæˆæ ·æœ¬çš„è¯­ä¹‰ä¸€è‡´æ€§ã€‚4) **ç‰¹å¾æ®‹å·®è¿‘ä¼¼ç­–ç•¥**ï¼šä¸ºäº†é™ä½æ¨ç†æˆæœ¬ï¼Œé‡‡ç”¨è½»é‡çº§çš„ç‰¹å¾æ®‹å·®è¿‘ä¼¼æ–¹æ³•ï¼Œåœ¨ä¿æŒè¯­ä¹‰è´¨é‡çš„åŒæ—¶å‡å°‘è®¡ç®—é‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šBFMçš„å…³é”®åˆ›æ–°åœ¨äºå…¶åˆ†å—å»ºæ¨¡çš„æ€æƒ³å’Œè¯­ä¹‰ç‰¹å¾å¼•å¯¼æœºåˆ¶ã€‚ä¸ä¼ ç»Ÿçš„Flow Matchingæ¨¡å‹ä½¿ç”¨å•ä¸ªå¤§å‹ç½‘ç»œä¸åŒï¼ŒBFMå°†ç”Ÿæˆè¿‡ç¨‹åˆ†è§£ä¸ºå¤šä¸ªç‹¬ç«‹çš„å­ä»»åŠ¡ï¼Œæ¯ä¸ªå­ä»»åŠ¡ç”±ä¸€ä¸ªä¸“é—¨çš„ç½‘ç»œè´Ÿè´£ï¼Œä»è€Œæé«˜äº†æ¨¡å‹çš„æ•ˆç‡å’Œè¡¨è¾¾èƒ½åŠ›ã€‚è¯­ä¹‰ç‰¹å¾å¼•å¯¼åˆ™åˆ©ç”¨äº†é¢„è®­ç»ƒæ¨¡å‹çš„çŸ¥è¯†ï¼Œè¿›ä¸€æ­¥æå‡äº†ç”Ÿæˆæ ·æœ¬çš„è´¨é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å…·ä½“å®ç°ä¸Šï¼Œè½¨è¿¹åˆ†å—çš„æ•°é‡å’Œæ¯ä¸ªé€Ÿåº¦å—çš„ç½‘ç»œç»“æ„æ˜¯é‡è¦çš„è®¾è®¡å‚æ•°ã€‚è®ºæ–‡ä¸­å¯èƒ½æ¢è®¨äº†ä¸åŒåˆ†å—æ•°é‡å’Œç½‘ç»œç»“æ„å¯¹æ€§èƒ½çš„å½±å“ã€‚è¯­ä¹‰ç‰¹å¾å¼•å¯¼æ¨¡å—çš„å…·ä½“å®ç°æ–¹å¼ï¼Œä¾‹å¦‚å¦‚ä½•å°†è¯­ä¹‰ç‰¹å¾èå…¥åˆ°é€Ÿåº¦å—çš„è¾“å…¥ä¸­ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªå…³é”®çš„è®¾è®¡ç»†èŠ‚ã€‚æ­¤å¤–ï¼Œç‰¹å¾æ®‹å·®è¿‘ä¼¼ç­–ç•¥çš„å…·ä½“å®ç°ï¼Œä¾‹å¦‚ä½¿ç”¨ä½•ç§è¿‘ä¼¼æ–¹æ³•ä»¥åŠå¦‚ä½•å¹³è¡¡è®¡ç®—é‡å’Œè¯­ä¹‰è´¨é‡ï¼Œä¹Ÿæ˜¯é‡è¦çš„æŠ€æœ¯ç»†èŠ‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒBFMåœ¨ImageNet 256x256æ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¸ç°æœ‰çš„Flow Matchingæ–¹æ³•ç›¸æ¯”ï¼ŒBFMåœ¨å¯æ¯”çš„ç”Ÿæˆæ€§èƒ½ä¸‹å®ç°äº†2.1å€è‡³4.9å€çš„æ¨ç†åŠ é€Ÿï¼Œå¹¶åœ¨ç”Ÿæˆè´¨é‡å’Œæ¨ç†æ•ˆç‡ä¹‹é—´å–å¾—äº†æ›´å¥½çš„å¹³è¡¡ã€‚è¿™äº›ç»“æœè¯æ˜äº†BFMåœ¨é«˜æ•ˆé«˜è´¨é‡æ•°æ®ç”Ÿæˆæ–¹é¢çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Blockwise Flow Matchingå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼ŒåŒ…æ‹¬å›¾åƒç”Ÿæˆã€è§†é¢‘ç”Ÿæˆã€éŸ³é¢‘åˆæˆç­‰é¢†åŸŸã€‚å…¶é«˜æ•ˆçš„æ¨ç†èƒ½åŠ›ä½¿å…¶åœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šéƒ¨ç½²æˆä¸ºå¯èƒ½ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥åº”ç”¨äºæ•°æ®å¢å¼ºã€å›¾åƒä¿®å¤ç­‰ä»»åŠ¡ï¼Œä¸ºç›¸å…³é¢†åŸŸçš„ç ”ç©¶å’Œåº”ç”¨æä¾›æ–°çš„æ€è·¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recently, Flow Matching models have pushed the boundaries of high-fidelity data generation across a wide range of domains. It typically employs a single large network to learn the entire generative trajectory from noise to data. Despite their effectiveness, this design struggles to capture distinct signal characteristics across timesteps simultaneously and incurs substantial inference costs due to the iterative evaluation of the entire model. To address these limitations, we propose Blockwise Flow Matching (BFM), a novel framework that partitions the generative trajectory into multiple temporal segments, each modeled by smaller but specialized velocity blocks. This blockwise design enables each block to specialize effectively in its designated interval, improving inference efficiency and sample quality. To further enhance generation fidelity, we introduce a Semantic Feature Guidance module that explicitly conditions velocity blocks on semantically rich features aligned with pretrained representations. Additionally, we propose a lightweight Feature Residual Approximation strategy that preserves semantic quality while significantly reducing inference cost. Extensive experiments on ImageNet 256x256 demonstrate that BFM establishes a substantially improved Pareto frontier over existing Flow Matching methods, achieving 2.1x to 4.9x accelerations in inference complexity at comparable generation performance. Code is available at https://github.com/mlvlab/BFM.

