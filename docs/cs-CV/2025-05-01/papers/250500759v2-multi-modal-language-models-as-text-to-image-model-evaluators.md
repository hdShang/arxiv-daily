---
layout: default
title: Multi-Modal Language Models as Text-to-Image Model Evaluators
---

# Multi-Modal Language Models as Text-to-Image Model Evaluators

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.00759" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.00759v2</a>
  <a href="https://arxiv.org/pdf/2505.00759.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.00759v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.00759v2', 'Multi-Modal Language Models as Text-to-Image Model Evaluators')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiahui Chen, Candace Ross, Reyhane Askari-Hemmat, Koustuv Sinha, Melissa Hall, Michal Drozdzal, Adriana Romero-Soriano

**åˆ†ç±»**: cs.CV, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-05-01 (æ›´æ–°: 2025-05-12)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šæ¨¡æ€è¯­è¨€æ¨¡å‹ä½œä¸ºæ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹è¯„ä¼°å·¥å…·**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹` `æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ` `æ¨¡å‹è¯„ä¼°` `ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹è¯„ä¼°æ–¹æ³•ä¾èµ–é™æ€æ•°æ®é›†ï¼Œéšç€æ¨¡å‹æ€§èƒ½æå‡ï¼Œè¿™äº›æ–¹æ³•é€æ¸å¤±æ•ˆã€‚
2. æœ¬æ–‡æå‡ºäº†MT2IEæ¡†æ¶ï¼Œé€šè¿‡å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹ç”Ÿæˆè¯„ä¼°æç¤ºï¼Œè¯„ä¼°å›¾åƒè´¨é‡å’Œä¸€è‡´æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒMT2IEåœ¨æç¤ºç”Ÿæˆä¸€è‡´æ€§è¯„åˆ†ä¸Šä¸äººç±»åˆ¤æ–­çš„ç›¸å…³æ€§æ›´é«˜ï¼ŒåŒæ—¶æ˜¾è‘—å‡å°‘äº†è¯„ä¼°æ‰€éœ€çš„æç¤ºæ•°é‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹çš„ä¸æ–­è¿›æ­¥ï¼Œä¾èµ–é™æ€æ•°æ®é›†çš„è‡ªåŠ¨è¯„ä¼°åŸºå‡†é€æ¸å¤±æ•ˆï¼Œä¿ƒä½¿ç ”ç©¶è€…å¯»æ‰¾æ–°çš„è¯„ä¼°æ–¹æ³•ã€‚æœ¬æ–‡æ¢è®¨äº†å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ä½œä¸ºè¯„ä¼°ä»£ç†çš„æ½œåŠ›ï¼Œæ—¨åœ¨è¯„ä¼°æç¤ºç”Ÿæˆçš„ä¸€è‡´æ€§å’Œå›¾åƒç¾å­¦ã€‚æˆ‘ä»¬æå‡ºäº†å¤šæ¨¡æ€æ–‡æœ¬åˆ°å›¾åƒè¯„ä¼°æ¡†æ¶ï¼ˆMT2IEï¼‰ï¼Œè¯¥æ¡†æ¶è¿­ä»£ç”Ÿæˆè¯„ä¼°æç¤ºï¼Œè¯„åˆ†ç”Ÿæˆçš„å›¾åƒï¼Œå¹¶å°†ç°æœ‰åŸºå‡†çš„T2Iè¯„ä¼°ä¸ä½¿ç”¨çš„æç¤ºæ•°é‡å¤§å¹…å‡å°‘çš„è¯„ä¼°ç»“æœè¿›è¡ŒåŒ¹é…ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å±•ç¤ºäº†MT2IEçš„æç¤ºç”Ÿæˆä¸€è‡´æ€§è¯„åˆ†ä¸äººç±»åˆ¤æ–­çš„ç›¸å…³æ€§é«˜äºæ–‡çŒ®ä¸­å…ˆå‰æå‡ºçš„è¯„åˆ†ã€‚MT2IEç”Ÿæˆçš„æç¤ºåœ¨æ¢æµ‹T2Iæ¨¡å‹æ€§èƒ½æ–¹é¢æ•ˆç‡é«˜ï¼Œä»…ä½¿ç”¨1/80çš„æç¤ºæ•°é‡å³å¯äº§ç”Ÿä¸ç°æœ‰åŸºå‡†ç›¸åŒçš„ç›¸å¯¹T2Iæ¨¡å‹æ’åã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä¼ ç»Ÿæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹è¯„ä¼°æ–¹æ³•çš„å±€é™æ€§ï¼Œå°¤å…¶æ˜¯ä¾èµ–é™æ€æ•°æ®é›†å¯¼è‡´çš„è¯„ä¼°å¤±æ•ˆé—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æ— æ³•é€‚åº”å¿«é€Ÿå‘å±•çš„ç”Ÿæˆæ¨¡å‹ï¼Œç¼ºä¹çµæ´»æ€§å’Œæœ‰æ•ˆæ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ä½œä¸ºè¯„ä¼°ä»£ç†ï¼ŒåŠ¨æ€ç”Ÿæˆè¯„ä¼°æç¤ºï¼Œä»¥æ›´å¥½åœ°è¯„ä¼°ç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œä¸€è‡´æ€§ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒMT2IEèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°é€‚åº”æ¨¡å‹çš„è¿›æ­¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMT2IEæ¡†æ¶åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼šé¦–å…ˆï¼ŒMLLMsç”Ÿæˆç”¨äºè¯„ä¼°çš„æç¤ºï¼›å…¶æ¬¡ï¼Œç”Ÿæˆçš„å›¾åƒé€šè¿‡è¯„åˆ†æœºåˆ¶è¿›è¡Œè¯„ä¼°ï¼›æœ€åï¼Œå°†è¿™äº›è¯„ä¼°ç»“æœä¸ç°æœ‰åŸºå‡†è¿›è¡Œå¯¹æ¯”ï¼Œä»¥éªŒè¯å…¶æœ‰æ•ˆæ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šMT2IEçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶æç¤ºç”Ÿæˆçš„ä¸€è‡´æ€§è¯„åˆ†ä¸äººç±»åˆ¤æ–­çš„ç›¸å…³æ€§æ˜¾è‘—æé«˜ï¼ŒåŒæ—¶åœ¨è¯„ä¼°æ•ˆç‡ä¸Šå¤§å¹…æå‡ï¼Œä»…ä½¿ç”¨1/80çš„æç¤ºæ•°é‡å³å¯è·å¾—ä¸ç°æœ‰åŸºå‡†ç›¸åŒçš„æ¨¡å‹æ’åã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒMT2IEé‡‡ç”¨äº†é«˜æ•ˆçš„æç¤ºç”Ÿæˆç®—æ³•ï¼Œç»“åˆäº†å¤šæ¨¡æ€å­¦ä¹ çš„ä¼˜åŠ¿ï¼Œç¡®ä¿ç”Ÿæˆçš„æç¤ºèƒ½å¤Ÿæœ‰æ•ˆæ¢æµ‹T2Iæ¨¡å‹çš„æ€§èƒ½ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡å°šæœªè¯¦ç»†æŠ«éœ²ï¼Œå±äºæœªçŸ¥é¢†åŸŸã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMT2IEçš„æç¤ºç”Ÿæˆä¸€è‡´æ€§è¯„åˆ†ä¸äººç±»åˆ¤æ–­çš„ç›¸å…³æ€§æ˜¾è‘—æé«˜ï¼Œä¸”åœ¨è¯„ä¼°æ•ˆç‡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä»…ä½¿ç”¨1/80çš„æç¤ºæ•°é‡å³å¯äº§ç”Ÿä¸ç°æœ‰åŸºå‡†ç›¸åŒçš„ç›¸å¯¹æ¨¡å‹æ’åã€‚è¿™ä¸€æˆæœä¸ºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹çš„è¯„ä¼°æä¾›äº†æ–°çš„æ€è·¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è®¡ç®—æœºè§†è§‰ã€ç”Ÿæˆå¯¹æŠ—ç½‘ç»œå’Œäººæœºäº¤äº’ç­‰ã€‚MT2IEæ¡†æ¶èƒ½å¤Ÿä¸ºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹çš„è¯„ä¼°æä¾›æ›´çµæ´»å’Œé«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨ç›¸å…³é¢†åŸŸçš„ç ”ç©¶è¿›å±•ä¸åº”ç”¨è½åœ°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The steady improvements of text-to-image (T2I) generative models lead to slow deprecation of automatic evaluation benchmarks that rely on static datasets, motivating researchers to seek alternative ways to evaluate the T2I progress. In this paper, we explore the potential of multi-modal large language models (MLLMs) as evaluator agents that interact with a T2I model, with the objective of assessing prompt-generation consistency and image aesthetics. We present Multimodal Text-to-Image Eval (MT2IE), an evaluation framework that iteratively generates prompts for evaluation, scores generated images and matches T2I evaluation of existing benchmarks with a fraction of the prompts used in existing static benchmarks. Moreover, we show that MT2IE's prompt-generation consistency scores have higher correlation with human judgment than scores previously introduced in the literature. MT2IE generates prompts that are efficient at probing T2I model performance, producing the same relative T2I model rankings as existing benchmarks while using only 1/80th the number of prompts for evaluation.

