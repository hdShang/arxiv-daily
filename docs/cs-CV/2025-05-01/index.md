---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CV - 2025-05-01
---

# cs.CVï¼ˆ2025-05-01ï¼‰

ğŸ“Š å…± **4** ç¯‡è®ºæ–‡
 | ğŸ”— **1** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (2)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250500690v1-towards-autonomous-micromobility-through-scalable-urban-simulation.html">Towards Autonomous Micromobility through Scalable Urban Simulation</a></td>
  <td>æå‡ºå¯æ‰©å±•åŸå¸‚ä»¿çœŸä»¥æ¨åŠ¨è‡ªä¸»å¾®å‹å‡ºè¡Œ</td>
  <td class="tags-cell"><span class="paper-tag">legged robot</span> <span class="paper-tag">locomotion</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.00690v1" data-paper-url="./papers/250500690v1-towards-autonomous-micromobility-through-scalable-urban-simulation.html" onclick="toggleFavorite(this, '2505.00690v1', 'Towards Autonomous Micromobility through Scalable Urban Simulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250500512v3-interloc-lidar-based-intersection-localization-using-road-segmentati.html">InterLoc: LiDAR-based Intersection Localization using Road Segmentation with Automated Evaluation Method</a></td>
  <td>æå‡ºä¸€ç§åŸºäºLiDARçš„äº¤å‰å£å®šä½æ–¹æ³•ä»¥è§£å†³è‡ªåŠ¨é©¾é©¶ä¸­çš„å®šä½æŒ‘æˆ˜</td>
  <td class="tags-cell"><span class="paper-tag">motion planning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.00512v3" data-paper-url="./papers/250500512v3-interloc-lidar-based-intersection-localization-using-road-segmentati.html" onclick="toggleFavorite(this, '2505.00512v3', 'InterLoc: LiDAR-based Intersection Localization using Road Segmentation with Automated Evaluation Method')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>3</td>
  <td><a href="./papers/250500703v2-t2i-r1-reinforcing-image-generation-with-collaborative-semantic-leve.html">T2I-R1: Reinforcing Image Generation with Collaborative Semantic-level and Token-level CoT</a></td>
  <td>æå‡ºT2I-R1ä»¥å¢å¼ºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆçš„æ¨ç†èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span> <span class="paper-tag">chain-of-thought</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.00703v2" data-paper-url="./papers/250500703v2-t2i-r1-reinforcing-image-generation-with-collaborative-semantic-leve.html" onclick="toggleFavorite(this, '2505.00703v2', 'T2I-R1: Reinforcing Image Generation with Collaborative Semantic-level and Token-level CoT')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>4</td>
  <td><a href="./papers/250500759v2-multi-modal-language-models-as-text-to-image-model-evaluators.html">Multi-Modal Language Models as Text-to-Image Model Evaluators</a></td>
  <td>æå‡ºå¤šæ¨¡æ€è¯­è¨€æ¨¡å‹ä½œä¸ºæ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹è¯„ä¼°å·¥å…·</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.00759v2" data-paper-url="./papers/250500759v2-multi-modal-language-models-as-text-to-image-model-evaluators.html" onclick="toggleFavorite(this, '2505.00759v2', 'Multi-Modal Language Models as Text-to-Image Model Evaluators')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CV é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)