---
layout: default
title: VideoRFT: Incentivizing Video Reasoning Capability in MLLMs via Reinforced Fine-Tuning
---

# VideoRFT: Incentivizing Video Reasoning Capability in MLLMs via Reinforced Fine-Tuning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.12434" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.12434v4</a>
  <a href="https://arxiv.org/pdf/2505.12434.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.12434v4" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.12434v4', 'VideoRFT: Incentivizing Video Reasoning Capability in MLLMs via Reinforced Fine-Tuning')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Qi Wang, Yanrui Yu, Ye Yuan, Rui Mao, Tianfei Zhou

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-18 (Êõ¥Êñ∞: 2025-10-14)

**Â§áÊ≥®**: Accepted by NeurIPS 2025. Code: https://github.com/QiWang98/VideoRFT

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫VideoRFT‰ª•Ëß£ÂÜ≥ËßÜÈ¢ëÊé®ÁêÜËÉΩÂäõ‰∏çË∂≥ÁöÑÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËßÜÈ¢ëÊé®ÁêÜ` `Âº∫ÂåñÂæÆË∞É` `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `ÊÄùÁª¥Èìæ` `ËØ≠‰πâ‰∏ÄËá¥ÊÄß` `Êï∞ÊçÆÈõÜÊûÑÂª∫` `ËÆ§Áü•È©±Âä®`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®ËßÜÈ¢ëÊé®ÁêÜÊñπÈù¢Èù¢‰∏¥Â§çÊùÇÈÄªËæëÂíåÂõ†ÊûúÁªìÊûÑÁöÑÊåëÊàòÔºåÂØºËá¥Êé®ÁêÜËÉΩÂäõ‰∏çË∂≥„ÄÇ
2. ÊèêÂá∫VideoRFTÔºåÈÄöËøáÂº∫ÂåñÂæÆË∞ÉÂíåËÆ§Áü•È©±Âä®ÁöÑCoTÁ≠ñÂàíÔºåÊèêÂçáMLLMsÁöÑ‰∫∫Á±ªËßÜÈ¢ëÊé®ÁêÜËÉΩÂäõ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåVideoRFTÂú®ÂÖ≠‰∏™ËßÜÈ¢ëÊé®ÁêÜÂü∫ÂáÜ‰∏äÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÊòæËëóÊèêÂçá‰∫ÜÊé®ÁêÜÊïàÊûú„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Âº∫ÂåñÂæÆË∞ÉÔºàRFTÔºâÂú®ÂÆûÁé∞Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÁöÑ‰∫∫Á±ªÁ∫ßÊé®ÁêÜËÉΩÂäõÊñπÈù¢Â±ïÁé∞Âá∫Â∑®Â§ßÊΩúÂäõÔºåÊúÄËøëÂ∑≤Êâ©Â±ïËá≥Â§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMsÔºâ„ÄÇÁÑ∂ËÄåÔºåËßÜÈ¢ëÊé®ÁêÜ‰ªçÁÑ∂ÊòØ‰∏Ä‰∏™ÊåëÊàòÔºåÂõ†‰∏∫ËßÜÈ¢ëÊï∞ÊçÆ‰∏≠Âõ∫ÊúâÁöÑÂ§çÊùÇÈÄªËæë„ÄÅÊó∂Èó¥ÂíåÂõ†ÊûúÁªìÊûÑ‰ΩøÂæóÊé®ÁêÜÂèòÂæóÂõ∞Èöæ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏ÄÈóÆÈ¢òÔºåÊú¨ÊñáÊèêÂá∫‰∫ÜVideoRFTÔºåËøôÊòØ‰∏ÄÁßçÊñ∞È¢ñÁöÑÊñπÊ≥ïÔºåÊó®Âú®ÂüπÂÖªMLLMsÁöÑ‰∫∫Á±ªËßÜÈ¢ëÊé®ÁêÜËÉΩÂäõ„ÄÇVideoRFTÈÅµÂæ™RFTÁöÑÊ†áÂáÜ‰∏§Èò∂ÊÆµÊñπÊ°àÔºöÈ¶ñÂÖàËøõË°åÂ∏¶ÊúâÊÄùÁª¥ÈìæÔºàCoTÔºâÊ≥®ÈáäÁöÑÁõëÁù£ÂæÆË∞ÉÔºàSFTÔºâÔºåÁÑ∂ÂêéÈÄöËøáÂº∫ÂåñÂ≠¶‰π†ÔºàRLÔºâÊèêÈ´òÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥ËßÜÈ¢ëÈ¢ÜÂüü‰∏≠È´òË¥®ÈáèCoTÊï∞ÊçÆÈõÜÁ®ÄÁº∫ÁöÑÈóÆÈ¢òÔºåÊú¨ÊñáÊûÑÂª∫‰∫Ü‰∏Ä‰∏™Â§ö‰∏ìÂÆ∂È©±Âä®ÁöÑ„ÄÅ‰ª•ËÆ§Áü•‰∏∫ÁÅµÊÑüÁöÑCoTÁ≠ñÂàíÁÆ°ÈÅìÔºåÂπ∂ÁîüÊàê‰∫Ü‰∏§‰∏™Êñ∞Êï∞ÊçÆÈõÜ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåVideoRFTÂú®ÂÖ≠‰∏™ËßÜÈ¢ëÊé®ÁêÜÂü∫ÂáÜ‰∏äËææÂà∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Â§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMsÔºâÂú®ËßÜÈ¢ëÊé®ÁêÜÊñπÈù¢ÁöÑ‰∏çË∂≥ÔºåÁé∞ÊúâÊñπÊ≥ïÂú®Â§ÑÁêÜËßÜÈ¢ëÊï∞ÊçÆÊó∂Èù¢‰∏¥Â§çÊùÇÁöÑÈÄªËæëÂíåÂõ†ÊûúÂÖ≥Á≥ªÔºåÁº∫‰πèÈ´òË¥®ÈáèÁöÑÊé®ÁêÜÊï∞ÊçÆÈõÜ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöVideoRFTÈÄöËøáÂº∫ÂåñÂæÆË∞ÉÔºàRFTÔºâÊñπÊ≥ïÔºåÁªìÂêàËÆ§Áü•È©±Âä®ÁöÑÊÄùÁª¥ÈìæÔºàCoTÔºâÁ≠ñÂàíÔºåÊó®Âú®ÂüπÂÖªÊ®°ÂûãÁöÑ‰∫∫Á±ªËßÜÈ¢ëÊé®ÁêÜËÉΩÂäõ„ÄÇËØ•ÊñπÊ≥ïÈÄöËøá‰∏§Èò∂ÊÆµÁöÑËÆ≠ÁªÉÊµÅÁ®ãÔºåÈ¶ñÂÖàËøõË°åÁõëÁù£ÂæÆË∞ÉÔºåÁÑ∂ÂêéÈÄöËøáÂº∫ÂåñÂ≠¶‰π†ÊèêÂçáÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöVideoRFTÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏§‰∏™‰∏ªË¶ÅÈò∂ÊÆµÔºö1) ÁõëÁù£ÂæÆË∞ÉÔºàSFTÔºâÔºåÂà©Áî®ËÆ§Áü•ÂêØÂèëÁöÑÊèêÁ§∫Á≠ñÁï•ÁîüÊàêÂàùÊ≠•ÁöÑCoTÔºõ2) Âº∫ÂåñÂ≠¶‰π†ÔºàRLÔºâÔºåÈÄöËøáÂºïÂÖ•ËØ≠‰πâ‰∏ÄËá¥ÊÄßÂ•ñÂä±Ôºå‰øÉËøõÊñáÊú¨Êé®ÁêÜ‰∏éËßÜËßâËØÅÊçÆ‰πãÈó¥ÁöÑÂØπÈΩê„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊú¨ÊñáÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫Ü‰∏ÄÁßçÂ§ö‰∏ìÂÆ∂È©±Âä®ÁöÑCoTÁ≠ñÂàíÁÆ°ÈÅìÔºåËß£ÂÜ≥‰∫ÜËßÜÈ¢ëÈ¢ÜÂüü‰∏≠È´òË¥®ÈáèCoTÊï∞ÊçÆÈõÜÁ®ÄÁº∫ÁöÑÈóÆÈ¢òÔºåÂπ∂ÂºïÂÖ•‰∫ÜËØ≠‰πâ‰∏ÄËá¥ÊÄßÂ•ñÂä±ÔºåÊòæËëóÊèêÂçá‰∫ÜÊé®ÁêÜÁöÑËøûË¥ØÊÄßÂíå‰∏ä‰∏ãÊñáÊÑüÁü•ËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Êï∞ÊçÆÈõÜÊûÑÂª∫‰∏≠ÔºåÈááÁî®‰∫ÜËÆ§Áü•ÂêØÂèëÁöÑÊèêÁ§∫Á≠ñÁï•ÔºåÁ°Æ‰øùÁîüÊàêÁöÑCoT‰∏éËßÜÈ¢ëÂÜÖÂÆπÁõ∏‰∏ÄËá¥ÔºõÂú®Âº∫ÂåñÂ≠¶‰π†Èò∂ÊÆµÔºåËÆæËÆ°‰∫ÜËØ≠‰πâ‰∏ÄËá¥ÊÄßÂ•ñÂä±Êú∫Âà∂ÔºåÈºìÂä±Ê®°ÂûãÁîüÊàêÂü∫‰∫éËßÜËßâËæìÂÖ•ÁöÑÂêàÁêÜÊé®ÁêÜËæìÂá∫„ÄÇÂÆûÈ™å‰∏≠‰ΩøÁî®‰∫Ü‰∏§‰∏™Êñ∞Êï∞ÊçÆÈõÜÔºöVideoRFT-CoT-102KÁî®‰∫éSFTÔºåVideoRFT-RL-310KÁî®‰∫éRL„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®ÂÖ≠‰∏™ËßÜÈ¢ëÊé®ÁêÜÂü∫ÂáÜ‰∏äÔºåVideoRFTÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÁõ∏ËæÉ‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÊé®ÁêÜÂáÜÁ°ÆÁéáÊèêÂçá‰∫ÜÊòæËëóÁöÑXX%ÔºàÂÖ∑‰ΩìÊï∞ÊçÆÊú™Áü•ÔºâÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®ËßÜÈ¢ëÊé®ÁêÜ‰ªªÂä°‰∏≠ÁöÑÊúâÊïàÊÄßÂíå‰ºòË∂äÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨ËßÜÈ¢ëÁêÜËß£„ÄÅÊô∫ËÉΩÁõëÊéß„ÄÅËá™Âä®È©æÈ©∂Á≠âÂú∫ÊôØÔºåËÉΩÂ§üÂ∏ÆÂä©Êú∫Âô®Êõ¥Â•ΩÂú∞ÁêÜËß£ÂíåÊé®ÁêÜËßÜÈ¢ëÂÜÖÂÆπÔºåÊèêÂçá‰∫∫Êú∫‰∫§‰∫íÁöÑÊô∫ËÉΩÂåñÊ∞¥Âπ≥„ÄÇÊú™Êù•ÔºåËøô‰∏ÄÊñπÊ≥ïÂèØËÉΩÂú®ÊïôËÇ≤„ÄÅÂ®±‰πêÁ≠âÂ§ö‰∏™È¢ÜÂüü‰∫ßÁîüÊ∑±ËøúÂΩ±ÂìçÔºåÊé®Âä®Â§öÊ®°ÊÄÅAIÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Reinforcement fine-tuning (RFT) has shown great promise in achieving humanlevel reasoning capabilities of Large Language Models (LLMs), and has recently been extended to MLLMs. Nevertheless, reasoning about videos, which is a fundamental aspect of human intelligence, remains a persistent challenge due to the complex logic, temporal and causal structures inherent in video data. To fill this gap, we propose VideoRFT, a novel approach that extends the RFT paradigm to cultivate human-like video reasoning capabilities in MLLMs. VideoRFT follows the standard two-stage scheme in RFT: supervised fine-tuning (SFT) with chain-of-thought (CoT) annotations, followed by reinforcement learning (RL) to improve generalization. A central challenge to achieve this in the video domain lies in the scarcity of large-scale, high-quality video CoT datasets. We address this by building a multi-expert-driven, cognition-inspired CoT curation pipeline. First, we devise a cognition-inspired prompting strategy to elicit a reasoning LLM to generate preliminary CoTs based solely on rich, structured, and literal representations of video content. Subsequently, these CoTs are revised by a MLLM conditioned on the actual video, ensuring visual consistency and reducing visual hallucinations. This pipeline results in two new datasets, i.e.VideoRFT-CoT-102K for SFT and VideoRFT-RL-310K for RL. To further strengthen the RL phase, we introduce a novel semantic-consistency reward that explicitly promotes the alignment between textual reasoning and visual evidence. This reward encourages the model to produce coherent, context-aware reasoning outputs grounded in visual input. Extensive experiments show that VideoRFT achieves state-of-the-art performance on six video reasoning benchmarks.

