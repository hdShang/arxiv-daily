---
layout: default
title: Can Large Multimodal Models Understand Agricultural Scenes? Benchmarking with AgroMind
---

# Can Large Multimodal Models Understand Agricultural Scenes? Benchmarking with AgroMind

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.12207" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.12207v3</a>
  <a href="https://arxiv.org/pdf/2505.12207.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.12207v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.12207v3', 'Can Large Multimodal Models Understand Agricultural Scenes? Benchmarking with AgroMind')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Qingmei Li, Yang Zhang, Zurong Mai, Yuhang Chen, Shuohong Lou, Henglian Huang, Jiarui Zhang, Zhiwei Zhang, Yibin Wen, Weijia Li, Haohuan Fu, Jianxi Huang, Juepeng Zheng

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-18 (æ›´æ–°: 2025-08-13)

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://rssysu.github.io/AgroMind/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAgroMindä»¥è§£å†³å†œä¸šé¥æ„ŸåŸºå‡†ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å†œä¸šé¥æ„Ÿ` `å¤šæ¨¡æ€æ¨¡å‹` `åŸºå‡†è¯„ä¼°` `ç©ºé—´æ¨ç†` `ä½œç‰©è¯†åˆ«` `ç¯å¢ƒåˆ†æ` `æ•°æ®é›†æ•´åˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å†œä¸šé¥æ„ŸåŸºå‡†ç¼ºä¹å¤šæ ·æ€§å’Œå¤æ‚æ€§ï¼Œæ— æ³•å…¨é¢è¯„ä¼°å¤§å‹å¤šæ¨¡æ€æ¨¡å‹çš„èƒ½åŠ›ã€‚
2. AgroMindé€šè¿‡æ•´åˆå¤šç§æ•°æ®é›†ï¼Œè®¾è®¡äº†æ¶µç›–å¤šç»´åº¦ä»»åŠ¡çš„ç»¼åˆè¯„ä¼°æ¡†æ¶ï¼Œæå‡äº†è¯„ä¼°çš„å…¨é¢æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œ20ä¸ªå¼€æºLMMså’Œ4ä¸ªé—­æºæ¨¡å‹åœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¡¨ç°ä¸å‡ï¼Œéƒ¨åˆ†LMMsè¶…è¶Šäº†äººç±»è¡¨ç°ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ï¼ˆLMMsï¼‰åœ¨å¤šä¸ªé¢†åŸŸå±•ç°å‡ºèƒ½åŠ›ï¼Œä½†å†œä¸šé¥æ„Ÿï¼ˆRSï¼‰é¢†åŸŸçš„ç»¼åˆåŸºå‡†ä»ç„¶ç¨€ç¼ºã€‚ç°æœ‰çš„å†œä¸šRSåŸºå‡†å­˜åœ¨æ˜æ˜¾ä¸è¶³ï¼Œä¸»è¦ä½“ç°åœ¨æ•°æ®é›†åœºæ™¯å¤šæ ·æ€§ä¸è¶³å’Œä»»åŠ¡è®¾è®¡è¿‡äºç®€åŒ–ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºAgroMindï¼Œä¸€ä¸ªæ¶µç›–ç©ºé—´æ„ŸçŸ¥ã€ç‰©ä½“ç†è§£ã€åœºæ™¯ç†è§£å’Œåœºæ™¯æ¨ç†å››ä¸ªä»»åŠ¡ç»´åº¦çš„ç»¼åˆå†œä¸šé¥æ„ŸåŸºå‡†ï¼Œå…±åŒ…å«13ç§ä»»åŠ¡ç±»å‹ï¼Œæ¶‰åŠä½œç‰©è¯†åˆ«ã€å¥åº·ç›‘æµ‹å’Œç¯å¢ƒåˆ†æç­‰ã€‚æˆ‘ä»¬é€šè¿‡æ•´åˆå…«ä¸ªå…¬å…±æ•°æ®é›†å’Œä¸€ä¸ªç§æœ‰å†œç”°æ•°æ®é›†ï¼Œæ„å»ºäº†ä¸€ä¸ªé«˜è´¨é‡çš„è¯„ä¼°é›†ï¼ŒåŒ…å«27,247ä¸ªé—®ç­”å¯¹å’Œ19,615å¼ å›¾åƒã€‚å®éªŒè¡¨æ˜ï¼ŒLMMsåœ¨ç©ºé—´æ¨ç†å’Œç»†ç²’åº¦è¯†åˆ«æ–¹é¢å­˜åœ¨æ˜¾è‘—æ€§èƒ½å·®è·ï¼Œä¸”äººç±»è¡¨ç°è½åäºå¤šä¸ªé¢†å…ˆçš„LMMsã€‚AgroMindä¸ºå†œä¸šRSå»ºç«‹äº†æ ‡å‡†åŒ–è¯„ä¼°æ¡†æ¶ï¼Œæ­ç¤ºäº†LMMsåœ¨é¢†åŸŸçŸ¥è¯†æ–¹é¢çš„å±€é™æ€§ï¼Œå¹¶çªå‡ºäº†æœªæ¥å·¥ä½œçš„å…³é”®æŒ‘æˆ˜ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å†œä¸šé¥æ„Ÿé¢†åŸŸç¼ºä¹å…¨é¢åŸºå‡†çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨åœºæ™¯å¤šæ ·æ€§å’Œä»»åŠ¡å¤æ‚æ€§ä¸Šå­˜åœ¨æ˜æ˜¾ä¸è¶³ï¼Œæ— æ³•æœ‰æ•ˆè¯„ä¼°LMMsçš„æ€§èƒ½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºAgroMindï¼Œé€šè¿‡æ•´åˆå¤šä¸ªæ•°æ®é›†å¹¶è®¾è®¡å¤šæ ·åŒ–çš„ä»»åŠ¡ï¼Œæ„å»ºä¸€ä¸ªå…¨é¢çš„è¯„ä¼°æ¡†æ¶ï¼Œä»¥æ›´å¥½åœ°æµ‹è¯•LMMsåœ¨å†œä¸šé¥æ„Ÿä¸­çš„åº”ç”¨èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ ¼å¼æ ‡å‡†åŒ–ã€æ³¨é‡Šä¼˜åŒ–å’Œä»»åŠ¡å®šä¹‰ï¼Œæœ€ç»ˆç”Ÿæˆå¤šæ ·åŒ–çš„å†œä¸šç›¸å…³é—®é¢˜ï¼Œå¹¶ä½¿ç”¨LMMsè¿›è¡Œæ¨ç†å’Œå“åº”ç”Ÿæˆã€‚

**å…³é”®åˆ›æ–°**ï¼šAgroMindçš„åˆ›æ–°åœ¨äºå…¶ç»¼åˆæ€§å’Œå¤šæ ·æ€§ï¼Œæ¶µç›–äº†ç©ºé—´æ„ŸçŸ¥ã€ç‰©ä½“ç†è§£ç­‰å¤šä¸ªç»´åº¦ï¼Œå¡«è¡¥äº†ç°æœ‰åŸºå‡†çš„ç©ºç™½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®é›†æ„å»ºä¸­ï¼Œæˆ‘ä»¬æ•´åˆäº†å…«ä¸ªå…¬å…±æ•°æ®é›†å’Œä¸€ä¸ªç§æœ‰æ•°æ®é›†ï¼Œç¡®ä¿äº†æ•°æ®çš„ä¸°å¯Œæ€§å’Œå¤šæ ·æ€§ï¼ŒåŒæ—¶è®¾è®¡äº†13ç§ä¸åŒçš„ä»»åŠ¡ç±»å‹ä»¥å…¨é¢è¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚å®éªŒä¸­ä½¿ç”¨äº†20ä¸ªå¼€æºå’Œ4ä¸ªé—­æºçš„LMMsè¿›è¡Œæ¯”è¾ƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œ20ä¸ªå¼€æºLMMså’Œ4ä¸ªé—­æºæ¨¡å‹åœ¨AgroMindåŸºå‡†ä¸Šè¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½å·®è·ï¼Œå°¤å…¶æ˜¯åœ¨ç©ºé—´æ¨ç†å’Œç»†ç²’åº¦è¯†åˆ«ä»»åŠ¡ä¸­ï¼Œéƒ¨åˆ†LMMsçš„è¡¨ç°è¶…è¿‡äº†äººç±»æ°´å¹³ï¼Œæ­ç¤ºäº†å½“å‰æŠ€æœ¯çš„æ½œåŠ›ä¸å±€é™ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

AgroMindçš„ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºå†œä¸šé¥æ„Ÿç›‘æµ‹ã€ä½œç‰©å¥åº·è¯„ä¼°å’Œç¯å¢ƒåˆ†æç­‰é¢†åŸŸã€‚é€šè¿‡æä¾›ä¸€ä¸ªæ ‡å‡†åŒ–çš„è¯„ä¼°æ¡†æ¶ï¼Œç ”ç©¶è€…å’Œå¼€å‘è€…å¯ä»¥æ›´æœ‰æ•ˆåœ°æµ‹è¯•å’Œä¼˜åŒ–å¤šæ¨¡æ€æ¨¡å‹åœ¨å†œä¸šåœºæ™¯ä¸­çš„åº”ç”¨ï¼Œæ¨åŠ¨å†œä¸šæ™ºèƒ½åŒ–çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Multimodal Models (LMMs) has demonstrated capabilities across various domains, but comprehensive benchmarks for agricultural remote sensing (RS) remain scarce. Existing benchmarks designed for agricultural RS scenarios exhibit notable limitations, primarily in terms of insufficient scene diversity in the dataset and oversimplified task design. To bridge this gap, we introduce AgroMind, a comprehensive agricultural remote sensing benchmark covering four task dimensions: spatial perception, object understanding, scene understanding, and scene reasoning, with a total of 13 task types, ranging from crop identification and health monitoring to environmental analysis. We curate a high-quality evaluation set by integrating eight public datasets and one private farmland plot dataset, containing 27,247 QA pairs and 19,615 images. The pipeline begins with multi-source data pre-processing, including collection, format standardization, and annotation refinement. We then generate a diverse set of agriculturally relevant questions through the systematic definition of tasks. Finally, we employ LMMs for inference, generating responses, and performing detailed examinations. We evaluated 20 open-source LMMs and 4 closed-source models on AgroMind. Experiments reveal significant performance gaps, particularly in spatial reasoning and fine-grained recognition, it is notable that human performance lags behind several leading LMMs. By establishing a standardized evaluation framework for agricultural RS, AgroMind reveals the limitations of LMMs in domain knowledge and highlights critical challenges for future work. Data and code can be accessed at https://rssysu.github.io/AgroMind/.

