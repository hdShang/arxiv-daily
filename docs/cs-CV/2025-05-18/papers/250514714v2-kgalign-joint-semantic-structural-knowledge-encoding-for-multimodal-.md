---
layout: default
title: "KGAlign: Joint Semantic-Structural Knowledge Encoding for Multimodal Fake News Detection"
---

# KGAlign: Joint Semantic-Structural Knowledge Encoding for Multimodal Fake News Detection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14714" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.14714v2</a>
  <a href="https://arxiv.org/pdf/2505.14714.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14714v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14714v2', 'KGAlign: Joint Semantic-Structural Knowledge Encoding for Multimodal Fake News Detection')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Tuan-Vinh La, Minh-Hieu Nguyen, Minh-Son Dao

**ÂàÜÁ±ª**: cs.CV, cs.AI, cs.CL

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-18 (Êõ¥Êñ∞: 2025-10-17)

**Â§áÊ≥®**: Withdrawn by the authors due to lack of explicit agreement from all co-authors to post this version publicly on arXiv

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/latuanvinh1998/KGAlign)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫KGAlign‰ª•Ëß£ÂÜ≥Â§öÊ®°ÊÄÅÂÅáÊñ∞ÈóªÊ£ÄÊµã‰∏≠ÁöÑÁü•ËØÜÁºñÁ†ÅÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÂÅáÊñ∞ÈóªÊ£ÄÊµã` `Â§öÊ®°ÊÄÅËûçÂêà` `Áü•ËØÜÂõæË∞±` `ËßÜËßâÁâπÂæÅÊèêÂèñ` `ÊñáÊú¨ÁºñÁ†Å` `TransformerÂàÜÁ±ªÂô®` `ÂÆû‰ΩìÈÄâÊã©` `ËØ≠‰πâÁêÜËß£`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂÅáÊñ∞ÈóªÊ£ÄÊµãÊñπÊ≥ïÂ≠òÂú®Â±ÄÈôêÔºå‰∏ªË¶ÅÈõÜ‰∏≠‰∫éÂÖ®Â±ÄÂõæÂÉè‰∏ä‰∏ãÊñáÔºåÂøΩËßÜ‰∫ÜÂ±ÄÈÉ®ÁªÜËäÇÂíåÂ§ñÈÉ®Áü•ËØÜÁöÑÊï¥Âêà„ÄÇ
2. ÊèêÂá∫KGAlignÊ°ÜÊû∂ÔºåÈÄöËøáËá™‰∏ãËÄå‰∏äÁöÑÊ≥®ÊÑèÂäõÊú∫Âà∂ÂíåÁü•ËØÜÂõæË∞±Â¢ûÂº∫Â§öÊ®°ÊÄÅÁâπÂæÅËûçÂêàÔºåÂÆûÁé∞Êõ¥Ê∑±Â±ÇÊ¨°ÁöÑËØ≠‰πâÁêÜËß£„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåKGAlignÂú®ÂÅáÊñ∞ÈóªÊ£ÄÊµã‰ªªÂä°‰∏≠Ë°®Áé∞‰ºòÂºÇÔºåË∂ÖË∂ä‰∫ÜÂ§öÁßçÂü∫Á∫øÊñπÊ≥ïÔºåÈ™åËØÅ‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÂÅáÊñ∞ÈóªÊ£ÄÊµã‰ªçÁÑ∂ÊòØ‰∏Ä‰∏™ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÈóÆÈ¢òÔºåÂõ†ÂÖ∂Ê∂âÂèäÊñáÊú¨ËôöÂÅá‰ø°ÊÅØ„ÄÅÊìçÊéßÂõæÂÉèÂíåÂ§ñÈÉ®Áü•ËØÜÊé®ÁêÜÁöÑÂ§çÊùÇ‰∫§‰∫í„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®È™åËØÅÁúüÂÆûÊÄßÂíåË∑®Ê®°ÊÄÅ‰∏ÄËá¥ÊÄßÊñπÈù¢ÂèñÂæó‰∫Ü‰∏ÄÂÆöÊàêÊûúÔºå‰ΩÜ‰ªçÈù¢‰∏¥‰∏§‰∏™‰∏ªË¶ÅÊåëÊàòÔºö‰∏ÄÊòØÁé∞ÊúâÊñπÊ≥ïÂæÄÂæÄÂè™ËÄÉËôëÂÖ®Â±ÄÂõæÂÉè‰∏ä‰∏ãÊñáÔºåËÄåÂøΩËßÜÂ±ÄÈÉ®ÂØπË±°Á∫ßÁªÜËäÇÔºõ‰∫åÊòØÊú™ËÉΩÁªìÂêàÂ§ñÈÉ®Áü•ËØÜÂíåÂÆû‰ΩìÂÖ≥Á≥ª‰ª•ÂÆûÁé∞Êõ¥Ê∑±Â±ÇÊ¨°ÁöÑËØ≠‰πâÁêÜËß£„ÄÇ‰∏∫Ê≠§ÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÂ§öÊ®°ÊÄÅÂÅáÊñ∞ÈóªÊ£ÄÊµãÊ°ÜÊû∂ÔºåÊï¥ÂêàËßÜËßâ„ÄÅÊñáÊú¨ÂíåÂü∫‰∫éÁü•ËØÜÁöÑË°®Á§∫„ÄÇÊàë‰ª¨ÁöÑÊñπÊ°àÂà©Áî®Ëá™‰∏ãËÄå‰∏äÁöÑÊ≥®ÊÑèÂäõÊú∫Âà∂ÊçïÊçâÁªÜÁ≤íÂ∫¶ÂØπË±°ÁªÜËäÇÔºå‰ΩøÁî®CLIPËøõË°åÂÖ®Â±ÄÂõæÂÉèËØ≠‰πâÁºñÁ†ÅÔºåÂπ∂ÈÄöËøáRoBERTaËøõË°å‰∏ä‰∏ãÊñáÊÑüÁü•ÁöÑÊñáÊú¨ÁºñÁ†Å„ÄÇÊàë‰ª¨Ëøõ‰∏ÄÊ≠•ÈÄöËøáÁü•ËØÜÂõæË∞±Ê£ÄÁ¥¢ÂíåËá™ÈÄÇÂ∫îÈÄâÊã©Áõ∏ÂÖ≥ÂÆû‰ΩìÊù•Â¢ûÂº∫Áü•ËØÜÂà©Áî®„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊàë‰ª¨ÁöÑÊ®°ÂûãÂú®ÂÅáÊñ∞ÈóªÊ£ÄÊµã‰∏≠‰ºò‰∫éËøëÊúüÊñπÊ≥ïÔºåÂ±ïÁ§∫‰∫ÜÈÇªÂ±ÖÈÄâÊã©Êú∫Âà∂ÂíåÂ§öÊ®°ÊÄÅËûçÂêàÁöÑÊúâÊïàÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Â§öÊ®°ÊÄÅÂÅáÊñ∞ÈóªÊ£ÄÊµã‰∏≠ÁöÑÁü•ËØÜÁºñÁ†ÅÈóÆÈ¢òÔºåÁé∞ÊúâÊñπÊ≥ïÊú™ËÉΩÂÖÖÂàÜÂà©Áî®Â±ÄÈÉ®ÂØπË±°‰ø°ÊÅØÂíåÂ§ñÈÉ®Áü•ËØÜÔºåÂØºËá¥Ê£ÄÊµãÊïàÊûú‰∏ç‰Ω≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöKGAlignÊ°ÜÊû∂ÈÄöËøáÊï¥ÂêàËßÜËßâ„ÄÅÊñáÊú¨ÂíåÁü•ËØÜË°®Á§∫ÔºåÂà©Áî®Ëá™‰∏ãËÄå‰∏äÁöÑÊ≥®ÊÑèÂäõÊú∫Âà∂ÊçïÊçâÁªÜÁ≤íÂ∫¶‰ø°ÊÅØÔºåÂπ∂ÁªìÂêàÁü•ËØÜÂõæË∞±ËøõË°åÂÆû‰ΩìÈÄâÊã©Ôºå‰ª•ÂÆûÁé∞Êõ¥Ê∑±Â±ÇÊ¨°ÁöÑËØ≠‰πâÁêÜËß£„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöËßÜËßâÁâπÂæÅÊèêÂèñÔºà‰ΩøÁî®CLIPÔºâ„ÄÅÊñáÊú¨ÁâπÂæÅÁºñÁ†ÅÔºà‰ΩøÁî®RoBERTaÔºâÂíåÁü•ËØÜÂõæË∞±ÁöÑÂÆû‰ΩìÈÄâÊã©ÔºåÊúÄÂêéÈÄöËøáTransformerÂàÜÁ±ªÂô®ËøõË°åÂÅáÊñ∞ÈóªÁöÑÁúüÂÆûÊÄßÈ¢ÑÊµã„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞Âú®‰∫éÂºïÂÖ•‰∫ÜÁü•ËØÜÈ©±Âä®ÁöÑÂ§öÊ®°ÊÄÅÊé®ÁêÜÔºåÈÄöËøáÊòæÂºèÁöÑÂÆû‰ΩìÈÄâÊã©ÂíåNLIÂºïÂØºÁöÑËøáÊª§ÔºåÂ∞ÜÂÅáÊñ∞ÈóªÊ£ÄÊµã‰ªéÁâπÂæÅËûçÂêàËΩ¨ÂêëËØ≠‰πâÂü∫Á°ÄÁöÑÈ™åËØÅ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Ê®°ÂûãËÆæËÆ°‰∏≠ÔºåÈááÁî®‰∫ÜËá™‰∏ãËÄå‰∏äÁöÑÊ≥®ÊÑèÂäõÊú∫Âà∂‰ª•ÊçïÊçâÁªÜÁ≤íÂ∫¶ÂØπË±°‰ø°ÊÅØÔºåÂπ∂ÈÄöËøáÁü•ËØÜÂõæË∞±ËøõË°åÂä®ÊÄÅÂÆû‰ΩìÈÄâÊã©ÔºåÁ°Æ‰øùÊ®°ÂûãËÉΩÂ§üÊúâÊïàÂà©Áî®Â§ñÈÉ®Áü•ËØÜ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåKGAlignÂú®ÂÅáÊñ∞ÈóªÊ£ÄÊµã‰ªªÂä°‰∏≠ÊòæËëó‰ºò‰∫éÂ§öÁßçÂü∫Á∫øÊñπÊ≥ïÔºåÂÖ∑‰ΩìÊÄßËÉΩÊèêÂçáËææÂà∞X%ÔºàÂÖ∑‰ΩìÊï∞ÊçÆÊú™Áü•ÔºâÔºåÈ™åËØÅ‰∫ÜÈÇªÂ±ÖÈÄâÊã©Êú∫Âà∂ÂíåÂ§öÊ®°ÊÄÅËûçÂêàÁöÑÊúâÊïàÊÄßÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÊΩúÂäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Á§æ‰∫§Â™í‰ΩìÁõëÊµã„ÄÅÊñ∞ÈóªÈ™åËØÅÂπ≥Âè∞Âíå‰ø°ÊÅØ‰º†Êí≠ÂàÜÊûêÁ≠â„ÄÇÈÄöËøáÊèêÈ´òÂÅáÊñ∞ÈóªÊ£ÄÊµãÁöÑÂáÜÁ°ÆÊÄßÔºåKGAlignËÉΩÂ§üÊúâÊïàÂáèÂ∞ëËôöÂÅá‰ø°ÊÅØÁöÑ‰º†Êí≠ÔºåÂ¢ûÂº∫ÂÖ¨‰ºóÂØπ‰ø°ÊÅØÁöÑ‰ø°‰ªªÂ∫¶ÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÁ§æ‰ºö‰ª∑ÂÄºÂíåÂÆûÈôÖÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Fake news detection remains a challenging problem due to the complex interplay between textual misinformation, manipulated images, and external knowledge reasoning. While existing approaches have achieved notable results in verifying veracity and cross-modal consistency, two key challenges persist: (1) Existing methods often consider only the global image context while neglecting local object-level details, and (2) they fail to incorporate external knowledge and entity relationships for deeper semantic understanding. To address these challenges, we propose a novel multi-modal fake news detection framework that integrates visual, textual, and knowledge-based representations. Our approach leverages bottom-up attention to capture fine-grained object details, CLIP for global image semantics, and RoBERTa for context-aware text encoding. We further enhance knowledge utilization by retrieving and adaptively selecting relevant entities from a knowledge graph. The fused multi-modal features are processed through a Transformer-based classifier to predict news veracity. Experimental results demonstrate that our model outperforms recent approaches, showcasing the effectiveness of neighbor selection mechanism and multi-modal fusion for fake news detection. Our proposal introduces a new paradigm: knowledge-grounded multimodal reasoning. By integrating explicit entity-level selection and NLI-guided filtering, we shift fake news detection from feature fusion to semantically grounded verification. For reproducibility and further research, the source code is publicly at \href{https://github.com/latuanvinh1998/KGAlign}{github.com/latuanvinh1998/KGAlign}.

