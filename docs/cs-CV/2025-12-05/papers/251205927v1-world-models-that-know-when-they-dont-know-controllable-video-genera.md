---
layout: default
title: World Models That Know When They Don't Know: Controllable Video Generation with Calibrated Uncertainty
---

# World Models That Know When They Don't Know: Controllable Video Generation with Calibrated Uncertainty

**arXiv**: [2512.05927v1](https://arxiv.org/abs/2512.05927) | [PDF](https://arxiv.org/pdf/2512.05927.pdf)

**ä½œè€…**: Zhiting Mei, Tenny Yin, Micah Baker, Ola Shorinwa, Anirudha Majumdar

**åˆ†ç±»**: cs.CV, cs.AI, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-12-05

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºC3æ–¹æ³•ï¼Œä¸ºå¯æŽ§è§†é¢‘ç”Ÿæˆæ¨¡åž‹æä¾›æ ¡å‡†çš„ä¸ç¡®å®šæ€§ä¼°è®¡ï¼Œç¼“è§£å¹»è§‰é—®é¢˜ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `å¯æŽ§è§†é¢‘ç”Ÿæˆ` `ä¸ç¡®å®šæ€§é‡åŒ–` `æœºå™¨äººå­¦ä¹ ` `ä¸–ç•Œæ¨¡åž‹` `æ·±åº¦å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰å¯æŽ§è§†é¢‘ç”Ÿæˆæ¨¡åž‹æ˜“äº§ç”Ÿä¸Žç‰©ç†çŽ°å®žä¸ç¬¦çš„å¹»è§‰ï¼Œä¸”ç¼ºä¹ç½®ä¿¡åº¦è¯„ä¼°èƒ½åŠ›ï¼Œé™åˆ¶äº†å…¶åœ¨æœºå™¨äººç­‰é¢†åŸŸçš„åº”ç”¨ã€‚
2. C3æ–¹æ³•é€šè¿‡å¼•å…¥ä¸ç¡®å®šæ€§é‡åŒ–æ¡†æž¶ï¼Œåœ¨æ½œåœ¨ç©ºé—´ä¸­è®­ç»ƒè§†é¢‘æ¨¡åž‹ï¼Œä½¿å…¶èƒ½å¤Ÿä¼°è®¡å¹¶è¡¨è¾¾ç”Ÿæˆè§†é¢‘å¸§çš„ä¸ç¡®å®šæ€§ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒC3æ–¹æ³•ä¸ä»…èƒ½æä¾›æ ¡å‡†çš„ä¸ç¡®å®šæ€§ä¼°è®¡ï¼Œè¿˜èƒ½æœ‰æ•ˆæ£€æµ‹åˆ†å¸ƒå¤–æ•°æ®ï¼Œæå‡æ¨¡åž‹åœ¨çœŸå®žåœºæ™¯ä¸­çš„å¯é æ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œç”Ÿæˆå¼è§†é¢‘æ¨¡åž‹åœ¨é«˜è´¨é‡è§†é¢‘åˆæˆæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œå°¤å…¶æ˜¯åœ¨å¯æŽ§è§†é¢‘ç”Ÿæˆé¢†åŸŸï¼Œç”Ÿæˆçš„è§†é¢‘ä»¥æ–‡æœ¬å’ŒåŠ¨ä½œè¾“å…¥ä¸ºæ¡ä»¶ï¼Œä¾‹å¦‚åœ¨æŒ‡ä»¤å¼•å¯¼çš„è§†é¢‘ç¼–è¾‘å’Œæœºå™¨äººæŠ€æœ¯ä¸­çš„ä¸–ç•Œå»ºæ¨¡ã€‚å°½ç®¡è¿™äº›æ¨¡åž‹å…·æœ‰å“è¶Šçš„èƒ½åŠ›ï¼Œä½†å¯æŽ§è§†é¢‘æ¨¡åž‹ç»å¸¸äº§ç”Ÿå¹»è§‰â€”â€”ç”Ÿæˆçš„æœªæ¥è§†é¢‘å¸§ä¸Žç‰©ç†çŽ°å®žä¸ç¬¦â€”â€”è¿™åœ¨æœºå™¨äººç­–ç•¥è¯„ä¼°å’Œè§„åˆ’ç­‰è®¸å¤šä»»åŠ¡ä¸­å¼•èµ·äº†ä¸¥é‡å…³æ³¨ã€‚ç„¶è€Œï¼Œæœ€å…ˆè¿›çš„è§†é¢‘æ¨¡åž‹ç¼ºä¹è¯„ä¼°å’Œè¡¨è¾¾å…¶ç½®ä¿¡åº¦çš„èƒ½åŠ›ï¼Œä»Žè€Œé˜»ç¢äº†å¹»è§‰çš„ç¼“è§£ã€‚ä¸ºäº†ä¸¥æ ¼åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä¸ç¡®å®šæ€§é‡åŒ–ï¼ˆUQï¼‰æ–¹æ³•C3ï¼Œç”¨äºŽè®­ç»ƒè¿žç»­å°ºåº¦æ ¡å‡†çš„å¯æŽ§è§†é¢‘æ¨¡åž‹ï¼Œä»¥åœ¨å­è¡¥ä¸çº§åˆ«è¿›è¡Œå¯†é›†ç½®ä¿¡åº¦ä¼°è®¡ï¼Œä»Žè€Œç²¾ç¡®å®šä½æ¯ä¸ªç”Ÿæˆçš„è§†é¢‘å¸§ä¸­çš„ä¸ç¡®å®šæ€§ã€‚æˆ‘ä»¬çš„UQæ–¹æ³•å¼•å…¥äº†ä¸‰ä¸ªæ ¸å¿ƒåˆ›æ–°ï¼Œä½¿è§†é¢‘æ¨¡åž‹èƒ½å¤Ÿä¼°è®¡å…¶ä¸ç¡®å®šæ€§ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¼€å‘äº†ä¸€ä¸ªæ–°é¢–çš„æ¡†æž¶ï¼Œè¯¥æ¡†æž¶é€šè¿‡ä¸¥æ ¼çš„é€‚å½“è¯„åˆ†è§„åˆ™è®­ç»ƒè§†é¢‘æ¨¡åž‹ä»¥å®žçŽ°æ­£ç¡®æ€§å’Œæ ¡å‡†ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬åœ¨æ½œåœ¨ç©ºé—´ä¸­ä¼°è®¡è§†é¢‘æ¨¡åž‹çš„ä¸ç¡®å®šæ€§ï¼Œé¿å…äº†ä¸Žåƒç´ ç©ºé—´æ–¹æ³•ç›¸å…³çš„è®­ç»ƒä¸ç¨³å®šæ€§å’Œè¿‡é«˜çš„è®­ç»ƒæˆæœ¬ã€‚ç¬¬ä¸‰ï¼Œæˆ‘ä»¬å°†å¯†é›†çš„æ½œåœ¨ç©ºé—´ä¸ç¡®å®šæ€§æ˜ å°„åˆ°RGBç©ºé—´ä¸­å¯è§£é‡Šçš„åƒç´ çº§ä¸ç¡®å®šæ€§ï¼Œä»¥è¿›è¡Œç›´è§‚çš„å¯è§†åŒ–ï¼Œä»Žè€Œæä¾›è¯†åˆ«ä¸å¯ä¿¡åŒºåŸŸçš„é«˜åˆ†è¾¨çŽ‡ä¸ç¡®å®šæ€§çƒ­å›¾ã€‚é€šè¿‡åœ¨å¤§åž‹æœºå™¨äººå­¦ä¹ æ•°æ®é›†ï¼ˆBridgeå’ŒDROIDï¼‰å’ŒçœŸå®žä¸–ç•Œè¯„ä¼°ä¸­çš„å¤§é‡å®žéªŒï¼Œæˆ‘ä»¬è¯æ˜Žäº†æˆ‘ä»¬çš„æ–¹æ³•ä¸ä»…åœ¨è®­ç»ƒåˆ†å¸ƒå†…æä¾›æ ¡å‡†çš„ä¸ç¡®å®šæ€§ä¼°è®¡ï¼Œè€Œä¸”èƒ½å¤Ÿå®žçŽ°æœ‰æ•ˆçš„åˆ†å¸ƒå¤–æ£€æµ‹ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå¯æŽ§è§†é¢‘ç”Ÿæˆæ¨¡åž‹åœ¨ç”Ÿæˆæœªæ¥å¸§æ—¶ï¼Œå®¹æ˜“å‡ºçŽ°ä¸ŽçœŸå®žç‰©ç†ä¸–ç•Œä¸ç¬¦çš„â€œå¹»è§‰â€çŽ°è±¡ã€‚çŽ°æœ‰æ¨¡åž‹æ— æ³•è¯„ä¼°è‡ªèº«é¢„æµ‹çš„å¯é æ€§ï¼Œå³ç¼ºä¹ä¸ç¡®å®šæ€§ä¼°è®¡èƒ½åŠ›ï¼Œè¿™é™åˆ¶äº†å…¶åœ¨å®‰å…¨æ”¸å…³åœºæ™¯ï¼ˆå¦‚æœºå™¨äººæŽ§åˆ¶ï¼‰ä¸­çš„åº”ç”¨ã€‚çŽ°æœ‰åƒç´ ç©ºé—´çš„ä¸ç¡®å®šæ€§ä¼°è®¡æ–¹æ³•è®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œä¸”è®­ç»ƒä¸ç¨³å®šã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šC3æ–¹æ³•çš„æ ¸å¿ƒåœ¨äºŽè®­ç»ƒè§†é¢‘ç”Ÿæˆæ¨¡åž‹ï¼Œä½¿å…¶èƒ½å¤Ÿé¢„æµ‹è‡ªèº«é¢„æµ‹çš„ä¸ç¡®å®šæ€§ã€‚é€šè¿‡åœ¨æ½œåœ¨ç©ºé—´ä¸­è¿›è¡Œä¸ç¡®å®šæ€§ä¼°è®¡ï¼Œé™ä½Žè®¡ç®—å¤æ‚åº¦å¹¶æé«˜è®­ç»ƒç¨³å®šæ€§ã€‚åŒæ—¶ï¼Œåˆ©ç”¨ä¸¥æ ¼çš„è¯„åˆ†è§„åˆ™æ¥æ ¡å‡†æ¨¡åž‹çš„ä¸ç¡®å®šæ€§ä¼°è®¡ï¼Œä½¿å…¶ä¸Žå®žé™…è¯¯å·®ç›¸åŒ¹é…ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šC3æ–¹æ³•åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) å¯æŽ§è§†é¢‘ç”Ÿæˆæ¨¡åž‹ï¼šç”¨äºŽç”Ÿæˆè§†é¢‘å¸§ï¼Œä»¥æ–‡æœ¬æˆ–åŠ¨ä½œæŒ‡ä»¤ä¸ºæ¡ä»¶ã€‚2) æ½œåœ¨ç©ºé—´ç¼–ç å™¨ï¼šå°†è§†é¢‘å¸§ç¼–ç åˆ°æ½œåœ¨ç©ºé—´ä¸­ã€‚3) ä¸ç¡®å®šæ€§ä¼°è®¡å™¨ï¼šåœ¨æ½œåœ¨ç©ºé—´ä¸­ä¼°è®¡æ¯ä¸ªæ½œåœ¨å‘é‡çš„ä¸ç¡®å®šæ€§ã€‚4) æ ¡å‡†æ¨¡å—ï¼šä½¿ç”¨ä¸¥æ ¼çš„è¯„åˆ†è§„åˆ™æ ¡å‡†ä¸ç¡®å®šæ€§ä¼°è®¡ã€‚5) è§£ç å™¨ï¼šå°†æ½œåœ¨ç©ºé—´çš„ä¸ç¡®å®šæ€§æ˜ å°„å›žåƒç´ ç©ºé—´ï¼Œç”Ÿæˆåƒç´ çº§åˆ«çš„ç½®ä¿¡åº¦çƒ­å›¾ã€‚

**å…³é”®åˆ›æ–°**ï¼šC3æ–¹æ³•çš„å…³é”®åˆ›æ–°åœ¨äºŽï¼š1) æå‡ºäº†ä¸€ç§åœ¨æ½œåœ¨ç©ºé—´ä¸­è¿›è¡Œä¸ç¡®å®šæ€§ä¼°è®¡çš„æ¡†æž¶ï¼Œé¿å…äº†åƒç´ ç©ºé—´æ–¹æ³•çš„è®¡ç®—ç“¶é¢ˆå’Œè®­ç»ƒéš¾é¢˜ã€‚2) ä½¿ç”¨ä¸¥æ ¼çš„è¯„åˆ†è§„åˆ™ï¼ˆstrictly proper scoring rulesï¼‰æ¥è®­ç»ƒæ¨¡åž‹ï¼Œç¡®ä¿ä¸ç¡®å®šæ€§ä¼°è®¡çš„æ ¡å‡†æ€§ã€‚3) è®¾è®¡äº†ä¸€ç§å°†æ½œåœ¨ç©ºé—´ä¸ç¡®å®šæ€§æ˜ å°„åˆ°åƒç´ ç©ºé—´çš„æœºåˆ¶ï¼Œä½¿å¾—ç”¨æˆ·å¯ä»¥ç›´è§‚åœ°ç†è§£æ¨¡åž‹åœ¨å“ªäº›åŒºåŸŸçš„é¢„æµ‹ä¸å¯é ã€‚

**å…³é”®è®¾è®¡**ï¼šC3æ–¹æ³•ä½¿ç”¨å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEï¼‰ä½œä¸ºè§†é¢‘ç”Ÿæˆæ¨¡åž‹çš„åŸºç¡€æž¶æž„ã€‚ä¸ç¡®å®šæ€§ä¼°è®¡å™¨é€šå¸¸æ˜¯ä¸€ä¸ªå°åž‹ç¥žç»ç½‘ç»œï¼Œè¾“å…¥æ˜¯æ½œåœ¨å‘é‡ï¼Œè¾“å‡ºæ˜¯ä¸ç¡®å®šæ€§å€¼ã€‚è¯„åˆ†è§„åˆ™çš„é€‰æ‹©è‡³å…³é‡è¦ï¼Œå¸¸ç”¨çš„è¯„åˆ†è§„åˆ™åŒ…æ‹¬è´Ÿå¯¹æ•°ä¼¼ç„¶ï¼ˆNegative Log-Likelihoodï¼‰å’Œè¿žç»­æŽ’åºæ¦‚çŽ‡åˆ†æ•°ï¼ˆContinuous Ranked Probability Score, CRPSï¼‰ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¨¡åž‹åŒæ—¶ä¼˜åŒ–è§†é¢‘ç”ŸæˆæŸå¤±å’Œä¸ç¡®å®šæ€§æ ¡å‡†æŸå¤±ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨Bridgeå’ŒDROIDæœºå™¨äººå­¦ä¹ æ•°æ®é›†ä¸Šçš„å®žéªŒè¡¨æ˜Žï¼ŒC3æ–¹æ³•èƒ½å¤Ÿæä¾›æ ¡å‡†çš„ä¸ç¡®å®šæ€§ä¼°è®¡ï¼Œå¹¶ä¸”èƒ½å¤Ÿæœ‰æ•ˆæ£€æµ‹åˆ†å¸ƒå¤–æ•°æ®ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒC3æ–¹æ³•åœ¨ä¸ç¡®å®šæ€§ä¼°è®¡çš„å‡†ç¡®æ€§å’Œæ•ˆçŽ‡æ–¹é¢å‡æœ‰æ˜¾è‘—æå‡ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒC3æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆç¼“è§£å¯æŽ§è§†é¢‘ç”Ÿæˆä¸­çš„å¹»è§‰é—®é¢˜ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

C3æ–¹æ³•å¯åº”ç”¨äºŽæœºå™¨äººæŽ§åˆ¶ã€è‡ªåŠ¨é©¾é©¶ã€è§†é¢‘ç¼–è¾‘ç­‰é¢†åŸŸã€‚åœ¨æœºå™¨äººæŽ§åˆ¶ä¸­ï¼Œå¯ä»¥å¸®åŠ©æœºå™¨äººè¯†åˆ«ä¸å¯é çš„é¢„æµ‹ï¼Œä»Žè€Œé¿å…å±é™©è¡Œä¸ºã€‚åœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼Œå¯ä»¥æé«˜ç³»ç»Ÿå¯¹çŽ¯å¢ƒæ„ŸçŸ¥çš„é²æ£’æ€§ã€‚åœ¨è§†é¢‘ç¼–è¾‘ä¸­ï¼Œå¯ä»¥è¾…åŠ©ç”¨æˆ·è¯†åˆ«å’Œä¿®å¤ç”Ÿæˆè§†é¢‘ä¸­çš„é”™è¯¯ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in generative video models have led to significant breakthroughs in high-fidelity video synthesis, specifically in controllable video generation where the generated video is conditioned on text and action inputs, e.g., in instruction-guided video editing and world modeling in robotics. Despite these exceptional capabilities, controllable video models often hallucinate - generating future video frames that are misaligned with physical reality - which raises serious concerns in many tasks such as robot policy evaluation and planning. However, state-of-the-art video models lack the ability to assess and express their confidence, impeding hallucination mitigation. To rigorously address this challenge, we propose C3, an uncertainty quantification (UQ) method for training continuous-scale calibrated controllable video models for dense confidence estimation at the subpatch level, precisely localizing the uncertainty in each generated video frame. Our UQ method introduces three core innovations to empower video models to estimate their uncertainty. First, our method develops a novel framework that trains video models for correctness and calibration via strictly proper scoring rules. Second, we estimate the video model's uncertainty in latent space, avoiding training instability and prohibitive training costs associated with pixel-space approaches. Third, we map the dense latent-space uncertainty to interpretable pixel-level uncertainty in the RGB space for intuitive visualization, providing high-resolution uncertainty heatmaps that identify untrustworthy regions. Through extensive experiments on large-scale robot learning datasets (Bridge and DROID) and real-world evaluations, we demonstrate that our method not only provides calibrated uncertainty estimates within the training distribution, but also enables effective out-of-distribution detection.

