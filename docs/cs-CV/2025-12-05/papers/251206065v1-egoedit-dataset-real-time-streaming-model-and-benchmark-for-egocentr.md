---
layout: default
title: EgoEdit: Dataset, Real-Time Streaming Model, and Benchmark for Egocentric Video Editing
---

# EgoEdit: Dataset, Real-Time Streaming Model, and Benchmark for Egocentric Video Editing

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.06065" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.06065v1</a>
  <a href="https://arxiv.org/pdf/2512.06065.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.06065v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.06065v1', 'EgoEdit: Dataset, Real-Time Streaming Model, and Benchmark for Egocentric Video Editing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Runjia Li, Moayed Haji-Ali, Ashkan Mirzaei, Chaoyang Wang, Arpit Sahni, Ivan Skorokhodov, Aliaksandr Siarohin, Tomas Jakab, Junlin Han, Sergey Tulyakov, Philip Torr, Willi Menapace

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-05

**å¤‡æ³¨**: Project page: https://snap-research.github.io/EgoEdit

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://snap-research.github.io/EgoEdit)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**EgoEditï¼šç”¨äºç¬¬ä¸€äººç§°è§†é¢‘ç¼–è¾‘çš„æ•°æ®é›†ã€å®æ—¶æ¨¡å‹ä¸è¯„æµ‹åŸºå‡†**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `ç¬¬ä¸€äººç§°è§†é¢‘ç¼–è¾‘` `æŒ‡ä»¤å¼•å¯¼ç¼–è¾‘` `å®æ—¶è§†é¢‘ç¼–è¾‘` `æ•°æ®é›†` `è¯„æµ‹åŸºå‡†` `æ‰‹éƒ¨äº¤äº’` `å¢å¼ºç°å®`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†é¢‘ç¼–è¾‘æ–¹æ³•åœ¨ç¬¬ä¸€äººç§°è§†è§’ä¸‹ï¼Œç”±äºå¿«é€Ÿè¿åŠ¨å’Œæ‰‹éƒ¨äº¤äº’ï¼Œæ•ˆæœä¸ä½³ã€‚
2. EgoEdité€šè¿‡æ„å»ºæ•°æ®é›†ã€è®¾è®¡å®æ—¶æ¨¡å‹å’Œè¯„æµ‹åŸºå‡†ï¼Œè§£å†³ç¬¬ä¸€äººç§°è§†é¢‘ç¼–è¾‘éš¾é¢˜ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒEgoEditåœ¨ç¬¬ä¸€äººç§°ç¼–è¾‘ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶ä¿æŒäº†å®æ—¶æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ç ”ç©¶äº†äº¤äº’å¼ARåº”ç”¨ä¸­ï¼ŒæŒ‡ä»¤å¼•å¯¼çš„ç¬¬ä¸€äººç§°è§†é¢‘ç¼–è¾‘ã€‚è™½ç„¶ç°æœ‰çš„AIè§†é¢‘ç¼–è¾‘å™¨åœ¨ç¬¬ä¸‰äººç§°ç´ æä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†ç¬¬ä¸€äººç§°è§†è§’å¸¦æ¥äº†ç‹¬ç‰¹çš„æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬å¿«é€Ÿçš„è‡ªæˆ‘è¿åŠ¨å’Œé¢‘ç¹çš„æ‰‹éƒ¨-ç‰©ä½“äº¤äº’ï¼Œé€ æˆäº†æ˜¾è‘—çš„é¢†åŸŸå·®è·ã€‚æ­¤å¤–ï¼Œç°æœ‰çš„ç¦»çº¿ç¼–è¾‘æµç¨‹å»¶è¿Ÿè¾ƒé«˜ï¼Œé™åˆ¶äº†å®æ—¶äº¤äº’ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªå®Œæ•´çš„ç¬¬ä¸€äººç§°è§†é¢‘ç¼–è¾‘ç”Ÿæ€ç³»ç»Ÿã€‚é¦–å…ˆï¼Œæ„å»ºäº†EgoEditDataï¼Œä¸€ä¸ªç²¾å¿ƒè®¾è®¡å’Œæ‰‹åŠ¨ç­–åˆ’çš„æ•°æ®é›†ï¼Œä¸“é—¨ç”¨äºç¬¬ä¸€äººç§°ç¼–è¾‘åœºæ™¯ï¼Œå…·æœ‰ä¸°å¯Œçš„æ‰‹éƒ¨-ç‰©ä½“äº¤äº’ï¼Œå¹¶æ˜ç¡®ä¿ç•™äº†æ‰‹éƒ¨ã€‚å…¶æ¬¡ï¼Œå¼€å‘äº†EgoEditï¼Œä¸€ä¸ªæŒ‡ä»¤è·Ÿéšçš„ç¬¬ä¸€äººç§°è§†é¢‘ç¼–è¾‘å™¨ï¼Œæ”¯æŒåœ¨å•ä¸ªGPUä¸Šè¿›è¡Œå®æ—¶æµæ¨ç†ã€‚æœ€åï¼Œå¼•å…¥äº†EgoEditBenchï¼Œä¸€ä¸ªè¯„ä¼°å¥—ä»¶ï¼Œé’ˆå¯¹æŒ‡ä»¤ä¿çœŸåº¦ã€æ‰‹éƒ¨å’Œäº¤äº’ä¿ç•™ä»¥åŠè‡ªæˆ‘è¿åŠ¨ä¸‹çš„æ—¶é—´ç¨³å®šæ€§ã€‚åœ¨ç¬¬ä¸€äººç§°å’Œé€šç”¨ç¼–è¾‘ä»»åŠ¡ä¸­ï¼ŒEgoEditäº§ç”Ÿäº†æ—¶é—´ç¨³å®šã€æŒ‡ä»¤ä¿çœŸçš„ç»“æœï¼Œå¹¶å…·æœ‰äº¤äº’å¼å»¶è¿Ÿã€‚å®ƒåœ¨ç¬¬ä¸€äººç§°ç¼–è¾‘åŸºå‡†ä¸Šå–å¾—äº†æ˜æ˜¾çš„ä¼˜åŠ¿ï¼Œè€Œç°æœ‰æ–¹æ³•éš¾ä»¥èƒœä»»ï¼ŒåŒæ—¶åœ¨é€šç”¨ç¼–è¾‘ä»»åŠ¡ä¸Šä¿æŒäº†ä¸æœ€å¼ºåŸºçº¿ç›¸å½“çš„æ€§èƒ½ã€‚EgoEditDataå’ŒEgoEditBenchå°†å‘ç ”ç©¶ç¤¾åŒºå…¬å¼€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ç¬¬ä¸€äººç§°è§†è§’è§†é¢‘çš„æŒ‡ä»¤å¼•å¯¼ç¼–è¾‘é—®é¢˜ã€‚ç°æœ‰è§†é¢‘ç¼–è¾‘æ–¹æ³•ä¸»è¦é’ˆå¯¹ç¬¬ä¸‰äººç§°è§†è§’ï¼Œæ— æ³•å¾ˆå¥½åœ°å¤„ç†ç¬¬ä¸€äººç§°è§†é¢‘ä¸­å¸¸è§çš„å¿«é€Ÿè‡ªæˆ‘è¿åŠ¨ã€é¢‘ç¹æ‰‹éƒ¨-ç‰©ä½“äº¤äº’ç­‰å¤æ‚æƒ…å†µï¼Œå¯¼è‡´ç¼–è¾‘æ•ˆæœä¸ä½³ï¼Œä¸”å»¶è¿Ÿè¾ƒé«˜ï¼Œéš¾ä»¥æ»¡è¶³å®æ—¶äº¤äº’éœ€æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªä¸“é—¨é’ˆå¯¹ç¬¬ä¸€äººç§°è§†é¢‘ç¼–è¾‘çš„å®Œæ•´ç”Ÿæ€ç³»ç»Ÿï¼ŒåŒ…æ‹¬æ•°æ®é›†ã€å®æ—¶æ¨¡å‹å’Œè¯„æµ‹åŸºå‡†ã€‚é€šè¿‡é«˜è´¨é‡çš„æ•°æ®é›†è®­ç»ƒæ¨¡å‹ï¼Œå¹¶è®¾è®¡é’ˆå¯¹æ€§çš„è¯„ä¼°æŒ‡æ ‡ï¼Œä»è€Œæå‡æ¨¡å‹åœ¨ç¬¬ä¸€äººç§°è§†é¢‘ç¼–è¾‘ä»»åŠ¡ä¸Šçš„æ€§èƒ½å’Œé²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEgoEditçš„æ•´ä½“æ¡†æ¶åŒ…å«ä¸‰ä¸ªä¸»è¦ç»„æˆéƒ¨åˆ†ï¼šEgoEditDataæ•°æ®é›†ã€EgoEditå®æ—¶ç¼–è¾‘æ¨¡å‹å’ŒEgoEditBenchè¯„æµ‹åŸºå‡†ã€‚EgoEditDataæä¾›é«˜è´¨é‡çš„ç¬¬ä¸€äººç§°è§†é¢‘æ•°æ®ï¼Œç”¨äºæ¨¡å‹è®­ç»ƒã€‚EgoEditæ¨¡å‹åŸºäºæµå¼å¤„ç†æ¶æ„ï¼Œæ”¯æŒå®æ—¶æ¨ç†ã€‚EgoEditBenchç”¨äºè¯„ä¼°æ¨¡å‹åœ¨æŒ‡ä»¤ä¿çœŸåº¦ã€æ‰‹éƒ¨å’Œäº¤äº’ä¿ç•™ä»¥åŠæ—¶é—´ç¨³å®šæ€§ç­‰æ–¹é¢çš„æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæ„å»ºäº†ä¸“é—¨é’ˆå¯¹ç¬¬ä¸€äººç§°è§†é¢‘ç¼–è¾‘çš„æ•°æ®é›†EgoEditDataï¼Œè¯¥æ•°æ®é›†åŒ…å«ä¸°å¯Œçš„æ‰‹éƒ¨-ç‰©ä½“äº¤äº’ï¼Œå¹¶æ˜ç¡®ä¿ç•™äº†æ‰‹éƒ¨ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æå‡ºäº†EgoEditBenchè¯„æµ‹åŸºå‡†ï¼Œç”¨äºå…¨é¢è¯„ä¼°æ¨¡å‹åœ¨ç¬¬ä¸€äººç§°è§†é¢‘ç¼–è¾‘ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šEgoEditæ¨¡å‹é‡‡ç”¨äº†æµå¼å¤„ç†æ¶æ„ï¼Œä»¥å®ç°å®æ—¶æ¨ç†ã€‚å…·ä½“çš„æŠ€æœ¯ç»†èŠ‚ï¼Œä¾‹å¦‚ç½‘ç»œç»“æ„ã€æŸå¤±å‡½æ•°ç­‰ï¼Œè®ºæ–‡ä¸­æ²¡æœ‰è¯¦ç»†æè¿°ï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚æ•°æ®é›†EgoEditDataçš„æ„å»ºè¿‡ç¨‹ä¸­ï¼Œä½œè€…è¿›è¡Œäº†ç²¾å¿ƒçš„è®¾è®¡å’Œæ‰‹åŠ¨ç­–åˆ’ï¼Œä»¥ä¿è¯æ•°æ®çš„è´¨é‡å’Œå¤šæ ·æ€§ã€‚è¯„æµ‹åŸºå‡†EgoEditBenchåˆ™é’ˆå¯¹ç¬¬ä¸€äººç§°è§†é¢‘ç¼–è¾‘çš„ç‰¹ç‚¹ï¼Œè®¾è®¡äº†å¤šä¸ªè¯„ä¼°æŒ‡æ ‡ï¼ŒåŒ…æ‹¬æŒ‡ä»¤ä¿çœŸåº¦ã€æ‰‹éƒ¨å’Œäº¤äº’ä¿ç•™ä»¥åŠæ—¶é—´ç¨³å®šæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

EgoEditåœ¨ç¬¬ä¸€äººç§°ç¼–è¾‘åŸºå‡†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¶…è¶Šäº†ç°æœ‰æ–¹æ³•ã€‚åœ¨é€šç”¨ç¼–è¾‘ä»»åŠ¡ä¸Šï¼ŒEgoEditä¿æŒäº†ä¸æœ€å¼ºåŸºçº¿ç›¸å½“çš„æ€§èƒ½ï¼ŒåŒæ—¶å®ç°äº†å®æ—¶æ¨ç†ã€‚EgoEditDataå’ŒEgoEditBenchçš„å‘å¸ƒå°†ä¸ºç¬¬ä¸€äººç§°è§†é¢‘ç¼–è¾‘é¢†åŸŸçš„ç ”ç©¶æä¾›æœ‰åŠ›æ”¯æŒã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¢å¼ºç°å®(AR)åº”ç”¨ã€æœºå™¨äººæ§åˆ¶ã€è™šæ‹Ÿç°å®(VR)å†…å®¹åˆ›ä½œç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡è¯­éŸ³æŒ‡ä»¤å®æ—¶ç¼–è¾‘ç¬¬ä¸€äººç§°è§†è§’ä¸‹çš„è§†é¢‘ï¼Œå®ç°è™šæ‹Ÿç‰©ä½“çš„æ·»åŠ ã€åœºæ™¯çš„ä¿®æ”¹ç­‰åŠŸèƒ½ã€‚è¯¥æŠ€æœ¯æœ‰æœ›æå‡ç”¨æˆ·åœ¨AR/VRç¯å¢ƒä¸­çš„äº¤äº’ä½“éªŒï¼Œå¹¶ä¸ºæœºå™¨äººæä¾›æ›´æ™ºèƒ½çš„è§†è§‰æ„ŸçŸ¥èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We study instruction-guided editing of egocentric videos for interactive AR applications. While recent AI video editors perform well on third-person footage, egocentric views present unique challenges - including rapid egomotion and frequent hand-object interactions - that create a significant domain gap. Moreover, existing offline editing pipelines suffer from high latency, limiting real-time interaction. To address these issues, we present a complete ecosystem for egocentric video editing. First, we construct EgoEditData, a carefully designed and manually curated dataset specifically designed for egocentric editing scenarios, featuring rich hand-object interactions, while explicitly preserving hands. Second, we develop EgoEdit, an instruction-following egocentric video editor that supports real-time streaming inference on a single GPU. Finally, we introduce EgoEditBench, an evaluation suite targeting instruction faithfulness, hand and interaction preservation, and temporal stability under egomotion. Across both egocentric and general editing tasks, EgoEdit produces temporally stable, instruction-faithful results with interactive latency. It achieves clear gains on egocentric editing benchmarks-where existing methods struggle-while maintaining performance comparable to the strongest baselines on general editing tasks. EgoEditData and EgoEditBench will be made public for the research community. See our website at https://snap-research.github.io/EgoEdit

