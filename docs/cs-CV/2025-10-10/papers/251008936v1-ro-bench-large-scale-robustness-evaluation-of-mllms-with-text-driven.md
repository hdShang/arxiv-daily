---
layout: default
title: RO-Bench: Large-scale robustness evaluation of MLLMs with text-driven counterfactual videos
---

# RO-Bench: Large-scale robustness evaluation of MLLMs with text-driven counterfactual videos

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.08936" target="_blank" class="toolbar-btn">arXiv: 2510.08936v1</a>
    <a href="https://arxiv.org/pdf/2510.08936.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.08936v1" 
            onclick="toggleFavorite(this, '2510.08936v1', 'RO-Bench: Large-scale robustness evaluation of MLLMs with text-driven counterfactual videos')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Zixi Yang, Jiapeng Li, Muxi Diao, Yinuo Jing, Kongming Liang

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-10

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫RO-BenchÔºåÁî®‰∫éÂ§ßËßÑÊ®°ËØÑ‰º∞MLLMÂú®ÊñáÊú¨È©±Âä®ÂØπÊäóËßÜÈ¢ë‰∏äÁöÑÈ≤ÅÊ£íÊÄß**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã` `ËßÜÈ¢ëÁêÜËß£` `È≤ÅÊ£íÊÄßËØÑ‰º∞` `ÂØπÊäóËßÜÈ¢ë` `ÊñáÊú¨È©±Âä®ÁîüÊàê`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâMLLMÂú®ËßÜÈ¢ëÁêÜËß£‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫Ëâ≤Ôºå‰ΩÜÈù¢ÂØπÂØπÊäóÊÄßÊîªÂáªÊàñÂÜÖÂÆπÁØ°ÊîπÊó∂ÔºåÈ≤ÅÊ£íÊÄß‰∏çË∂≥„ÄÇ
2. ÊèêÂá∫Ro-BenchÂü∫ÂáÜÔºåÈÄöËøáÊñáÊú¨È©±Âä®ÁöÑÊñπÂºèÁîüÊàêÂØπÊäóËßÜÈ¢ëÔºåÁî®‰∫éËØÑ‰º∞MLLMÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåÁé∞ÊúâMLLMÂú®Ro-Bench‰∏äÊÄßËÉΩÊòæËëó‰∏ãÈôçÔºå‰ΩøÁî®ÂØπÊäóÊï∞ÊçÆÂæÆË∞ÉÂêéÊÄßËÉΩÊèêÂçáÊòæËëó„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã(MLLM)ÊúÄËøëÂú®ÂêÑÁßçËßÜÈ¢ëÁêÜËß£‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫ÊòæËëóÁöÑÊÄßËÉΩ„ÄÇÁÑ∂ËÄåÔºåÂÆÉ‰ª¨ÁöÑÈ≤ÅÊ£íÊÄßÔºåÁâπÂà´ÊòØÂú®Èù¢ÂØπË¢´ÁØ°ÊîπÁöÑËßÜÈ¢ëÂÜÖÂÆπÊó∂ÔºåÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏ä‰ªçÊú™Ë¢´Êé¢Á¥¢„ÄÇÊú¨ÊñáÊèêÂá∫‰∫ÜRo-BenchÔºåËøôÊòØÁ¨¨‰∏Ä‰∏™Áî®‰∫éËØÑ‰º∞MLLMÂú®Âä®ÊÄÅÂàÜÂ∏ÉÂ§ñ(OOD)ÂØπÊäóËßÜÈ¢ëÊµãËØïÈõÜ‰∏äÁöÑÂü∫ÂáÜ„ÄÇRo-BenchÈÄöËøáÁºñËæëÈ£éÊ†º„ÄÅÂØπË±°„ÄÅËÉåÊôØÂèäÂÖ∂ÁªÑÂêàÔºåÊï¥Âêà‰∫ÜÈ´òË¥®Èáè„ÄÅÂ§öÊ†∑ÂåñÂíåÊó∂Èó¥Áõ∏ÂÖ≥ÁöÑËßÜÈ¢ëÊï∞ÊçÆ„ÄÇÊàë‰ª¨ËØÑ‰º∞‰∫ÜÂÖ´‰∏™ÊúÄÊñ∞ÁöÑËßÜÈ¢ëMLLMÔºåÂèëÁé∞ÂΩìÂâçÁöÑÊ®°ÂûãÂú®Ro-Bench‰∏äÊö¥Èú≤‰∫éÂØπÊäóËßÜÈ¢ëÂÜÖÂÆπÊó∂Ë°®Áé∞Âá∫ÊòæËëóÁöÑÊÄßËÉΩ‰∏ãÈôç„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ËØÅÊòé‰∫Ü‰ΩøÁî®ÂØπÊäóÊï∞ÊçÆÂæÆË∞ÉMLLMÂèØ‰ª•Â¢ûÂº∫È≤ÅÊ£íÊÄßÔºåÂú®Ro-Bench‰∏äÂÆûÁé∞‰∫Ü21.73%ÁöÑÊÄßËÉΩÊèêÂçáÔºåÂú®MVBenchÊï∞ÊçÆÈõÜÁöÑ20‰∏™‰ªªÂä°‰∏≠ÂÆûÁé∞‰∫Ü12.78%ÁöÑÊèêÂçá„ÄÇËøô‰∫õÂèëÁé∞Âº∫Ë∞É‰∫ÜÂØπÊäóÊï∞ÊçÆÂú®Â¢ûÂº∫MLLMÁöÑËßÜÈ¢ëÁêÜËß£ËÉΩÂäõÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇ‰ª£Á†ÅÂíåÊï∞ÊçÆÂ∞ÜÂæàÂø´ÂèëÂ∏É„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâMLLMÂú®Â§ÑÁêÜÁúüÂÆûËßÜÈ¢ëÊï∞ÊçÆÊó∂Ë°®Áé∞ËâØÂ•ΩÔºå‰ΩÜÂú®Èù¢ÂØπÂØπÊäóÊÄßÊîªÂáªÊàñÂÜÖÂÆπÁØ°ÊîπÁöÑËßÜÈ¢ëÊó∂ÔºåÊÄßËÉΩ‰ºöÊòæËëó‰∏ãÈôç„ÄÇËøôË°®ÊòéÁé∞ÊúâÊ®°ÂûãÁº∫‰πèÂØπÂàÜÂ∏ÉÂ§ñÊï∞ÊçÆÁöÑÈ≤ÅÊ£íÊÄß„ÄÇÁé∞ÊúâÊñπÊ≥ïÁº∫‰πè‰∏Ä‰∏™‰∏ìÈó®Áî®‰∫éËØÑ‰º∞MLLMÂú®ÂØπÊäóËßÜÈ¢ë‰∏äÁöÑÈ≤ÅÊ£íÊÄßÁöÑÂü∫ÂáÜ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÈÄöËøáÊñáÊú¨È©±Âä®ÁöÑÊñπÂºèÁîüÊàêÂØπÊäóËßÜÈ¢ëÔºåÊ®°ÊãüÁúüÂÆû‰∏ñÁïå‰∏≠ÂèØËÉΩÂá∫Áé∞ÁöÑÂêÑÁßçËßÜÈ¢ëÁØ°ÊîπÊÉÖÂÜµ„ÄÇÂà©Áî®Ëøô‰∫õÂØπÊäóËßÜÈ¢ëÊûÑÂª∫‰∏Ä‰∏™ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÊµãËØïÈõÜÔºåÁî®‰∫éËØÑ‰º∞MLLMÁöÑÈ≤ÅÊ£íÊÄß„ÄÇÈÄöËøáÂØπÊäóËÆ≠ÁªÉÔºåÊèêÈ´òMLLMÂØπËøô‰∫õÁØ°ÊîπËßÜÈ¢ëÁöÑËØÜÂà´ËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöRo-BenchÂü∫ÂáÜÂåÖÂê´‰ª•‰∏ãÂá†‰∏™ÂÖ≥ÈîÆÁªÑÊàêÈÉ®ÂàÜÔºö1) ÂéüÂßãËßÜÈ¢ëÊï∞ÊçÆÈõÜÔºõ2) ÊñáÊú¨ÊèèËø∞ÔºåÁî®‰∫éÊåáÂØºÂØπÊäóËßÜÈ¢ëÁöÑÁîüÊàêÔºõ3) ÂØπÊäóËßÜÈ¢ëÁîüÊàêÊ®°ÂùóÔºåÈÄöËøáÁºñËæëÈ£éÊ†º„ÄÅÂØπË±°„ÄÅËÉåÊôØÂèäÂÖ∂ÁªÑÂêàÊù•ÁîüÊàêÂØπÊäóËßÜÈ¢ëÔºõ4) ËØÑ‰º∞ÊåáÊ†áÔºåÁî®‰∫éË°°ÈáèMLLMÂú®ÂØπÊäóËßÜÈ¢ë‰∏äÁöÑÊÄßËÉΩ„ÄÇÊï¥‰ΩìÊµÅÁ®ãÊòØÔºöÈ¶ñÂÖàÔºå‰ΩøÁî®ÊñáÊú¨ÊèèËø∞ÊåáÂØºÂØπÊäóËßÜÈ¢ëÁîüÊàêÊ®°ÂùóÁîüÊàêÂØπÊäóËßÜÈ¢ë„ÄÇÁÑ∂ÂêéÔºåÂ∞ÜÂéüÂßãËßÜÈ¢ëÂíåÂØπÊäóËßÜÈ¢ëËæìÂÖ•Âà∞MLLM‰∏≠ËøõË°åÊµãËØï„ÄÇÊúÄÂêéÔºå‰ΩøÁî®ËØÑ‰º∞ÊåáÊ†áË°°ÈáèMLLMÂú®ÂØπÊäóËßÜÈ¢ë‰∏äÁöÑÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöRo-BenchÊòØÁ¨¨‰∏Ä‰∏™‰∏ìÈó®Áî®‰∫éËØÑ‰º∞MLLMÂú®ÂØπÊäóËßÜÈ¢ë‰∏äÁöÑÈ≤ÅÊ£íÊÄßÁöÑÂü∫ÂáÜ„ÄÇÂÆÉÈÄöËøáÊñáÊú¨È©±Âä®ÁöÑÊñπÂºèÁîüÊàêÂØπÊäóËßÜÈ¢ëÔºåÂèØ‰ª•Ê®°ÊãüÁúüÂÆû‰∏ñÁïå‰∏≠ÂèØËÉΩÂá∫Áé∞ÁöÑÂêÑÁßçËßÜÈ¢ëÁØ°ÊîπÊÉÖÂÜµ„ÄÇÊ≠§Â§ñÔºåËØ•Á†îÁ©∂ËøòËØÅÊòé‰∫Ü‰ΩøÁî®ÂØπÊäóÊï∞ÊçÆÂæÆË∞ÉMLLMÂèØ‰ª•ÊòæËëóÊèêÈ´òÂÖ∂È≤ÅÊ£íÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂØπÊäóËßÜÈ¢ëÁîüÊàêÊ®°Âùó‰ΩøÁî®‰∫ÜÂ§öÁßçÁºñËæëÊäÄÊúØÔºåÂåÖÊã¨È£éÊ†ºËøÅÁßª„ÄÅÂØπË±°ÊõøÊç¢„ÄÅËÉåÊôØÊõøÊç¢Á≠â„ÄÇËøô‰∫õÊäÄÊúØÂèØ‰ª•ÊúâÊïàÂú∞ÊîπÂèòËßÜÈ¢ëÁöÑÂÜÖÂÆπÂíåÈ£éÊ†ºÔºå‰ªéËÄåÁîüÊàêÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÂØπÊäóËßÜÈ¢ë„ÄÇÁ†îÁ©∂‰∏≠‰ΩøÁî®‰∫ÜÂ§öÁßçËØÑ‰º∞ÊåáÊ†áÔºåÂåÖÊã¨ÂáÜÁ°ÆÁéá„ÄÅÂè¨ÂõûÁéá„ÄÅF1ÂÄºÁ≠âÔºåÁî®‰∫éÂÖ®Èù¢ËØÑ‰º∞MLLMÂú®ÂØπÊäóËßÜÈ¢ë‰∏äÁöÑÊÄßËÉΩ„ÄÇÂØπÊäóËÆ≠ÁªÉËøáÁ®ã‰∏≠Ôºå‰ΩøÁî®‰∫Ü‰∫§ÂèâÁÜµÊçüÂ§±ÂáΩÊï∞ÂíåAdam‰ºòÂåñÂô®„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÁé∞ÊúâMLLMÂú®Ro-Bench‰∏äË°®Áé∞Âá∫ÊòæËëóÁöÑÊÄßËÉΩ‰∏ãÈôç„ÄÇ‰æãÂ¶ÇÔºåÂú®Êüê‰∫õ‰ªªÂä°‰∏äÔºåÂáÜÁ°ÆÁéá‰∏ãÈôç‰∫ÜË∂ÖËøá50%„ÄÇÈÄöËøá‰ΩøÁî®ÂØπÊäóÊï∞ÊçÆÂæÆË∞ÉMLLMÔºåÂèØ‰ª•Âú®Ro-Bench‰∏äÂÆûÁé∞21.73%ÁöÑÊÄßËÉΩÊèêÂçáÔºåÂú®MVBenchÊï∞ÊçÆÈõÜÁöÑ20‰∏™‰ªªÂä°‰∏≠ÂÆûÁé∞12.78%ÁöÑÊèêÂçá„ÄÇËøôË°®ÊòéÂØπÊäóËÆ≠ÁªÉÂèØ‰ª•ÊúâÊïàÂú∞ÊèêÈ´òMLLMÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éËßÜÈ¢ëÁõëÊéß„ÄÅËá™Âä®È©æÈ©∂„ÄÅÂÜÖÂÆπÂÆ°Ê†∏Á≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÊèêÈ´òMLLMÂú®ÂØπÊäóËßÜÈ¢ë‰∏äÁöÑÈ≤ÅÊ£íÊÄßÔºåÂèØ‰ª•Â¢ûÂº∫Ëøô‰∫õÁ≥ªÁªüÂú®Â§çÊùÇÁéØÂ¢É‰∏ãÁöÑÂèØÈù†ÊÄßÂíåÂÆâÂÖ®ÊÄß„ÄÇÊ≠§Â§ñÔºåËØ•Á†îÁ©∂ËøòÂèØ‰ª•‰øÉËøõÂØπÊäóÊîªÂáªÂíåÈò≤Âæ°ÊäÄÊúØÁöÑÂèëÂ±ïÔºåÊé®Âä®Â§öÊ®°ÊÄÅÊú∫Âô®Â≠¶‰π†È¢ÜÂüüÁöÑËøõÊ≠•„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Recently, Multi-modal Large Language Models (MLLMs) have demonstrated significant performance across various video understanding tasks. However, their robustness, particularly when faced with manipulated video content, remains largely unexplored. In this paper, we introduce Ro-Bench, the first benchmark for evaluating MLLMs on dynamic out-of-distribution (OOD) counterfactual video test sets. Ro-Bench incorporates high-quality, diverse and temporally relevant video data, by editing Style, Object, Background and their compositions. We evaluated eight recent video MLLMs and found that current models exhibit substantial performance degradation on Ro-Bench when exposed to counterfactual video content. Furthermore, we demonstrate that fine-tuning MLLMs with counterfactual data enhances robustness, achieving a 21.73% performance increase on Ro-Bench and a 12.78% improvement across 20 tasks in the MVBench dataset. These findings underscore the effectiveness of counterfactual data in enhancing the video understanding ability of MLLMs. The code and data will be released shortly.

