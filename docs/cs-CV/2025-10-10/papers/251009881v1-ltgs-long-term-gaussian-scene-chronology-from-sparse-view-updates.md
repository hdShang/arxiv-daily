---
layout: default
title: LTGS: Long-Term Gaussian Scene Chronology From Sparse View Updates
---

# LTGS: Long-Term Gaussian Scene Chronology From Sparse View Updates

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.09881" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.09881v1</a>
  <a href="https://arxiv.org/pdf/2510.09881.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.09881v1" onclick="toggleFavorite(this, '2510.09881v1', 'LTGS: Long-Term Gaussian Scene Chronology From Sparse View Updates')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Minkwan Kim, Seungmin Lee, Junho Kim, Young Min Kim

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-10

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**LTGSï¼šåŸºäºç¨€ç–è§†å›¾æ›´æ–°çš„é•¿æ—¶é«˜æ–¯åœºæ™¯æ—¶é—´çº¿å»ºæ¨¡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `é«˜æ–¯æº…å°„` `novel-view synthesis` `åœºæ™¯æ—¶é—´çº¿` `ç¨€ç–è§†å›¾æ›´æ–°` `å¯¹è±¡æ¨¡æ¿` `ä¸‰ç»´é‡å»º` `æ—¶é—´æ¼”åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿnovel-view synthesisæ–¹æ³•åœ¨å¤„ç†æ—¥å¸¸åœºæ™¯æ—¶ï¼Œç”±äºåœºæ™¯é¢‘ç¹å˜åŒ–ï¼Œéœ€è¦å¯†é›†çš„ç©ºé—´å’Œæ—¶é—´è§‚æµ‹ï¼Œé¢ä¸´æŒ‘æˆ˜ã€‚
2. LTGSæ–¹æ³•é€šè¿‡æ„å»ºå¯¹è±¡æ¨¡æ¿é«˜æ–¯ä½œä¸ºç»“æ„åŒ–å…ˆéªŒï¼Œå¹¶è¿›è¡Œç»†åŒ–ï¼Œä»è€Œåœ¨ç¨€ç–è§‚æµ‹ä¸‹é²æ£’åœ°å»ºæ¨¡åœºæ™¯çš„é•¿æœŸæ—¶é—´çº¿ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒLTGSåœ¨ç¨€ç–è§†å›¾æ›´æ–°ä¸‹ï¼Œç›¸æ¯”å…¶ä»–æ–¹æ³•ï¼Œå®ç°äº†æ›´é«˜çš„é‡å»ºè´¨é‡ï¼Œå¹¶æ”¯æŒå¿«é€Ÿæ›´æ–°ï¼Œå…·æœ‰è‰¯å¥½çš„å¯æ‰©å±•æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºLTGSçš„é•¿æ—¶é«˜æ–¯åœºæ™¯æ—¶é—´çº¿æ–¹æ³•ï¼Œç”¨äºè§£å†³æ—¥å¸¸ç¯å¢ƒä¸­ç”±äºé¢‘ç¹åœºæ™¯å˜åŒ–å¯¼è‡´çš„ novel-view synthesis é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨ç¨€ç–è§‚æµ‹æ¡ä»¶ä¸‹ã€‚è¯¥æ–¹æ³•åˆ©ç”¨é«˜æ–¯æº…å°„è¡¨ç¤ºä½œä¸ºåŸºç¡€ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šå¯¹åœºæ™¯çš„é•¿æœŸæ—¶é—´çº¿è¿›è¡Œå»ºæ¨¡ï¼Œå³ä½¿å­˜åœ¨çªå‘è¿åŠ¨å’Œç»†å¾®çš„ç¯å¢ƒå˜åŒ–ä¹Ÿèƒ½ä¿æŒé²æ£’æ€§ã€‚LTGSå°†å¯¹è±¡å»ºæ¨¡ä¸ºæ¨¡æ¿é«˜æ–¯ï¼Œä½œä¸ºå…±äº«å¯¹è±¡è½¨è¿¹çš„ç»“æ„åŒ–ã€å¯é‡ç”¨å…ˆéªŒã€‚ç„¶åï¼Œé€šè¿‡ä¸€ä¸ªç»†åŒ–æµç¨‹è°ƒæ•´è¿™äº›å…ˆéªŒï¼Œä½¿å…¶èƒ½å¤ŸåŸºäºå°‘é‡è§‚æµ‹é€‚åº”éšæ—¶é—´å˜åŒ–çš„ç¯å¢ƒã€‚è®­ç»ƒå®Œæˆåï¼Œè¯¥æ¡†æ¶å¯ä»¥é€šè¿‡ç®€å•çš„å˜æ¢æ¨å¹¿åˆ°å¤šä¸ªæ—¶é—´æ­¥ï¼Œä»è€Œæ˜¾è‘—å¢å¼ºäº†3Dç¯å¢ƒæ—¶é—´æ¼”åŒ–çš„å¯æ‰©å±•æ€§ã€‚ä½œè€…è¿˜æ”¶é›†äº†çœŸå®ä¸–ç•Œæ•°æ®é›†æ¥è¯„ä¼°è¯¥æ–¹æ³•çš„å®ç”¨æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒLTGSåœ¨å®ç°å¿«é€Ÿè½»é‡çº§æ›´æ–°çš„åŒæ—¶ï¼Œå®ç°äº†å“è¶Šçš„é‡å»ºè´¨é‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰novel-view synthesisæ–¹æ³•åœ¨å¤„ç†çœŸå®ä¸–ç•Œæ—¥å¸¸åœºæ™¯æ—¶ï¼Œç”±äºåœºæ™¯éšæ—¶é—´é¢‘ç¹å˜åŒ–ï¼Œéœ€è¦å¤§é‡çš„ç©ºé—´å’Œæ—¶é—´è§‚æµ‹æ•°æ®ã€‚ç„¶è€Œï¼Œåœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¾€å¾€åªèƒ½è·å–ç¨€ç–çš„ã€éç»“æ„åŒ–çš„å›¾åƒæ•°æ®ï¼Œè¿™ç»™åœºæ™¯çš„é‡å»ºå’Œæ—¶é—´æ¼”åŒ–å»ºæ¨¡å¸¦æ¥äº†æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥åœ¨ç¨€ç–è§‚æµ‹ä¸‹ä¿æŒé‡å»ºè´¨é‡å’Œæ—¶é—´ä¸€è‡´æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šLTGSçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨é«˜æ–¯æº…å°„è¡¨ç¤ºä½œä¸ºåœºæ™¯çš„åŸºç¡€ç»“æ„ï¼Œå¹¶å¼•å…¥å¯¹è±¡æ¨¡æ¿é«˜æ–¯ä½œä¸ºç»“æ„åŒ–å…ˆéªŒï¼Œæ¥çº¦æŸåœºæ™¯çš„æ—¶é—´æ¼”åŒ–ã€‚é€šè¿‡å°†å¯¹è±¡å»ºæ¨¡ä¸ºå¯é‡ç”¨çš„æ¨¡æ¿ï¼Œå¯ä»¥æœ‰æ•ˆåœ°åˆ©ç”¨è·¨æ—¶é—´æ­¥çš„ä¿¡æ¯ï¼Œä»è€Œåœ¨ç¨€ç–è§‚æµ‹ä¸‹å®ç°é²æ£’çš„åœºæ™¯é‡å»ºå’Œæ—¶é—´çº¿å»ºæ¨¡ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿé€‚åº”åœºæ™¯ä¸­çš„çªå‘è¿åŠ¨å’Œç»†å¾®å˜åŒ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLTGSæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) åˆå§‹åŒ–ï¼šä½¿ç”¨åˆå§‹å›¾åƒé›†åˆæ„å»ºä¸€ä¸ªä¸å®Œæ•´çš„é«˜æ–¯æº…å°„è¡¨ç¤ºã€‚2) å¯¹è±¡æ¨¡æ¿æ„å»ºï¼šå°†åœºæ™¯ä¸­çš„å¯¹è±¡å»ºæ¨¡ä¸ºæ¨¡æ¿é«˜æ–¯ï¼Œè¿™äº›æ¨¡æ¿ä½œä¸ºå…±äº«å¯¹è±¡è½¨è¿¹çš„ç»“æ„åŒ–å…ˆéªŒã€‚3) æ¨¡æ¿ç»†åŒ–ï¼šé€šè¿‡ä¸€ä¸ªç»†åŒ–æµç¨‹ï¼Œæ ¹æ®å°‘é‡è§‚æµ‹æ•°æ®è°ƒæ•´å¯¹è±¡æ¨¡æ¿ï¼Œä½¿å…¶é€‚åº”éšæ—¶é—´å˜åŒ–çš„ç¯å¢ƒã€‚4) æ—¶é—´æ¼”åŒ–ï¼šé€šè¿‡ç®€å•çš„å˜æ¢ï¼Œå°†è®­ç»ƒå¥½çš„æ¨¡å‹æ¨å¹¿åˆ°å¤šä¸ªæ—¶é—´æ­¥ï¼Œå®ç°åœºæ™¯çš„æ—¶é—´æ¼”åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šLTGSçš„å…³é”®åˆ›æ–°åœ¨äºå¼•å…¥äº†å¯¹è±¡æ¨¡æ¿é«˜æ–¯ä½œä¸ºç»“æ„åŒ–å…ˆéªŒï¼Œç”¨äºçº¦æŸåœºæ™¯çš„æ—¶é—´æ¼”åŒ–ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒLTGSèƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨è·¨æ—¶é—´æ­¥çš„ä¿¡æ¯ï¼Œä»è€Œåœ¨ç¨€ç–è§‚æµ‹ä¸‹å®ç°æ›´é²æ£’çš„åœºæ™¯é‡å»ºå’Œæ—¶é—´çº¿å»ºæ¨¡ã€‚æ­¤å¤–ï¼ŒLTGSçš„ç»†åŒ–æµç¨‹èƒ½å¤Ÿæœ‰æ•ˆåœ°é€‚åº”éšæ—¶é—´å˜åŒ–çš„ç¯å¢ƒï¼Œæé«˜äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šLTGSçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) å¯¹è±¡æ¨¡æ¿é«˜æ–¯çš„å‚æ•°åŒ–æ–¹å¼ï¼Œéœ€è¦èƒ½å¤Ÿæœ‰æ•ˆåœ°è¡¨ç¤ºå¯¹è±¡çš„å½¢çŠ¶ã€å¤§å°å’Œå§¿æ€ã€‚2) æ¨¡æ¿ç»†åŒ–æµç¨‹çš„è®¾è®¡ï¼Œéœ€è¦èƒ½å¤Ÿæ ¹æ®å°‘é‡è§‚æµ‹æ•°æ®å‡†ç¡®åœ°è°ƒæ•´å¯¹è±¡æ¨¡æ¿çš„å‚æ•°ã€‚3) æ—¶é—´æ¼”åŒ–æ¨¡å‹çš„é€‰æ‹©ï¼Œéœ€è¦èƒ½å¤Ÿæœ‰æ•ˆåœ°å°†æ¨¡å‹æ¨å¹¿åˆ°å¤šä¸ªæ—¶é—´æ­¥ï¼Œå¹¶ä¿æŒåœºæ™¯çš„æ—¶é—´ä¸€è‡´æ€§ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç­‰ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœªæ˜ç¡®ç»™å‡ºï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

LTGSåœ¨çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒLTGSåœ¨é‡å»ºè´¨é‡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æå‡ï¼ŒåŒæ—¶å®ç°äº†å¿«é€Ÿè½»é‡çº§çš„æ›´æ–°ã€‚å…·ä½“æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦åœ¨æ‘˜è¦ä¸­æœªæ˜ç¡®ç»™å‡ºï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚ä½œè€…æ”¶é›†çš„çœŸå®ä¸–ç•Œæ•°æ®é›†ä¹Ÿä¸ºè¯¥é¢†åŸŸçš„ç ”ç©¶æä¾›äº†å®è´µèµ„æºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

LTGSå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚å¢å¼ºç°å®(AR)ã€è™šæ‹Ÿç°å®(VR)ã€æœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸã€‚å®ƒå¯ä»¥ç”¨äºæ„å»ºåŠ¨æ€çš„ã€å¯äº¤äº’çš„3Dç¯å¢ƒï¼Œå¹¶æ”¯æŒåœ¨ç¨€ç–è§‚æµ‹ä¸‹çš„åœºæ™¯é‡å»ºå’Œæ—¶é—´æ¼”åŒ–å»ºæ¨¡ã€‚è¯¥æŠ€æœ¯å¯ä»¥åº”ç”¨äºæ™ºèƒ½å®¶å±…ã€æ™ºæ…§åŸå¸‚ç­‰åœºæ™¯ï¼Œå®ç°å¯¹ç¯å¢ƒçš„é•¿æœŸç›‘æ§å’Œç®¡ç†ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in novel-view synthesis can create the photo-realistic visualization of real-world environments from conventional camera captures. However, acquiring everyday environments from casual captures faces challenges due to frequent scene changes, which require dense observations both spatially and temporally. We propose long-term Gaussian scene chronology from sparse-view updates, coined LTGS, an efficient scene representation that can embrace everyday changes from highly under-constrained casual captures. Given an incomplete and unstructured Gaussian splatting representation obtained from an initial set of input images, we robustly model the long-term chronology of the scene despite abrupt movements and subtle environmental variations. We construct objects as template Gaussians, which serve as structural, reusable priors for shared object tracks. Then, the object templates undergo a further refinement pipeline that modulates the priors to adapt to temporally varying environments based on few-shot observations. Once trained, our framework is generalizable across multiple time steps through simple transformations, significantly enhancing the scalability for a temporal evolution of 3D environments. As existing datasets do not explicitly represent the long-term real-world changes with a sparse capture setup, we collect real-world datasets to evaluate the practicality of our pipeline. Experiments demonstrate that our framework achieves superior reconstruction quality compared to other baselines while enabling fast and light-weight updates.

