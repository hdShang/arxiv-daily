---
layout: default
title: Online Video Depth Anything: Temporally-Consistent Depth Prediction with Low Memory Consumption
---

# Online Video Depth Anything: Temporally-Consistent Depth Prediction with Low Memory Consumption

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.09182" target="_blank" class="toolbar-btn">arXiv: 2510.09182v1</a>
    <a href="https://arxiv.org/pdf/2510.09182.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.09182v1" 
            onclick="toggleFavorite(this, '2510.09182v1', 'Online Video Depth Anything: Temporally-Consistent Depth Prediction with Low Memory Consumption')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Johann-Friedrich Feiden, Tim K√ºchler, Denis Zavadski, Bogdan Savchynskyy, Carsten Rother

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-10

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫oVDAÔºåÈÄöËøáÁºìÂ≠òÂíåÊé©Á†ÅÊäÄÊúØÂÆûÁé∞‰ΩéÂÜÖÂ≠ò„ÄÅÂú®Á∫øËßÜÈ¢ëÊ∑±Â∫¶‰º∞ËÆ°**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Âú®Á∫øËßÜÈ¢ëÊ∑±Â∫¶‰º∞ËÆ°` `‰ΩéÂÜÖÂ≠òÂç†Áî®` `ËæπÁºòËÆ°ÁÆó` `Êó∂Èó¥‰∏ÄËá¥ÊÄß` `ÁºìÂ≠òÊú∫Âà∂` `Â∏ßÊé©Á†Å` `ÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâVDAÊñπÊ≥ï‰æùËµñÊâπÂ§ÑÁêÜÔºåÊó†Ê≥ïÊª°Ë∂≥Âú®Á∫øËßÜÈ¢ëÊ∑±Â∫¶‰º∞ËÆ°ÁöÑÂÆûÊó∂ÊÄßÈúÄÊ±ÇÔºåÈôêÂà∂‰∫ÜÂÖ∂Âú®ËæπÁºòËÆæÂ§á‰∏äÁöÑÂ∫îÁî®„ÄÇ
2. oVDAÂÄüÈâ¥LLMÁöÑÊÄùË∑ØÔºåÈÄöËøáÁºìÂ≠òÊé®ÁêÜËøáÁ®ã‰∏≠ÁöÑÊΩúÂú®ÁâπÂæÅÂíåËÆ≠ÁªÉÊó∂ÁöÑÂ∏ßÊé©Á†ÅÔºåÈôç‰Ωé‰∫ÜÂÜÖÂ≠òÂç†Áî®ÔºåÂÆûÁé∞‰∫ÜÂú®Á∫øÂ§ÑÁêÜ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåoVDAÂú®Á≤æÂ∫¶ÂíåVRAM‰ΩøÁî®‰∏ä‰ºò‰∫éÂÖ∂‰ªñÂú®Á∫øÊñπÊ≥ïÔºåÂπ∂Âú®NVIDIA A100ÂíåJetsonËÆæÂ§á‰∏äÂÆûÁé∞‰∫ÜËæÉÈ´òÁöÑÂ∏ßÁéá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÂçïÁõÆËßÜÈ¢ëÊ∑±Â∫¶‰º∞ËÆ°Â∑≤Êàê‰∏∫ËÆ∏Â§öÂÆûÈôÖËÆ°ÁÆóÊú∫ËßÜËßâÁ≥ªÁªüÁöÑÂÖ≥ÈîÆÁªÑÊàêÈÉ®ÂàÜ„ÄÇÊúÄËøëÔºåVideo Depth Anything (VDA) Âú®ÈïøËßÜÈ¢ëÂ∫èÂàó‰∏äË°®Áé∞Âá∫Âº∫Â§ßÁöÑÊÄßËÉΩ„ÄÇÁÑ∂ËÄåÔºåÂÆÉ‰æùËµñ‰∫éÊâπÂ§ÑÁêÜÔºåËøôÈôêÂà∂‰∫ÜÂÖ∂Âú®Âú®Á∫øÁéØÂ¢É‰∏≠ÁöÑ‰ΩøÁî®„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨ÂÖãÊúç‰∫ÜËøô‰∏™ÈôêÂà∂ÔºåÂπ∂ÂºïÂÖ•‰∫ÜÂú®Á∫øVDA (oVDA)„ÄÇÂÖ≥ÈîÆÂàõÊñ∞ÊòØÈááÁî®Êù•Ëá™Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÁöÑÊäÄÊúØÔºåÂç≥Âú®Êé®ÁêÜÊúüÈó¥ÁºìÂ≠òÊΩúÂú®ÁâπÂæÅÂπ∂Âú®ËÆ≠ÁªÉÊó∂Êé©ÁõñÂ∏ß„ÄÇÊàë‰ª¨ÁöÑoVDAÊñπÊ≥ïÂú®ÂáÜÁ°ÆÊÄßÂíåVRAM‰ΩøÁî®ÊñπÈù¢ÈÉΩ‰ºò‰∫éÊâÄÊúâÁ´û‰∫âÁöÑÂú®Á∫øËßÜÈ¢ëÊ∑±Â∫¶‰º∞ËÆ°ÊñπÊ≥ï„ÄÇ‰ΩéVRAM‰ΩøÁî®ÂØπ‰∫éÂú®ËæπÁºòËÆæÂ§á‰∏äÈÉ®ÁΩ≤Â∞§ÂÖ∂ÈáçË¶Å„ÄÇÊàë‰ª¨ËØÅÊòé‰∫ÜoVDAÂú®NVIDIA A100‰∏ä‰ª•42 FPSËøêË°åÔºåÂú®NVIDIA JetsonËæπÁºòËÆæÂ§á‰∏ä‰ª•20 FPSËøêË°å„ÄÇÊàë‰ª¨Â∞ÜÂèëÂ∏É‰ª£Á†ÅÂíåÁºñËØëËÑöÊú¨Ôºå‰ΩøoVDAÊòì‰∫éÈÉ®ÁΩ≤Âú®‰ΩéÂäüËÄóÁ°¨‰ª∂‰∏ä„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Âú®Á∫øËßÜÈ¢ëÊ∑±Â∫¶‰º∞ËÆ°ÈóÆÈ¢òÔºåÂç≥Âú®ËßÜÈ¢ëÊµÅÂÆûÊó∂ËæìÂÖ•ÁöÑÊÉÖÂÜµ‰∏ãÔºåÂø´ÈÄüÂáÜÁ°ÆÂú∞‰º∞ËÆ°ÊØè‰∏ÄÂ∏ßÁöÑÊ∑±Â∫¶‰ø°ÊÅØ„ÄÇÁé∞ÊúâÊñπÊ≥ïÔºåÁâπÂà´ÊòØVDAÔºåËôΩÁÑ∂Á≤æÂ∫¶È´òÔºå‰ΩÜ‰æùËµñ‰∫éÊâπÂ§ÑÁêÜÔºåÈúÄË¶Å‰∏ÄÊ¨°ÊÄßÂä†ËΩΩÊï¥‰∏™ËßÜÈ¢ëÂ∫èÂàóÔºåÊó†Ê≥ïÊª°Ë∂≥Âú®Á∫øÂú∫ÊôØÁöÑ‰ΩéÂª∂ËøüÈúÄÊ±ÇÔºå‰∏îÂÜÖÂ≠òÂç†Áî®È´òÔºåÈöæ‰ª•Âú®ËæπÁºòËÆæÂ§á‰∏äÈÉ®ÁΩ≤„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂÄüÈâ¥Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâ‰∏≠ÁöÑÁºìÂ≠òÊú∫Âà∂ÔºåÂú®Êé®ÁêÜËøáÁ®ã‰∏≠ÁºìÂ≠òÂÖàÂâçÂ∏ßÁöÑÊΩúÂú®ÁâπÂæÅÔºåÈÅøÂÖçÈáçÂ§çËÆ°ÁÆóÔºå‰ªéËÄåÈôç‰ΩéÂÜÖÂ≠òÂç†Áî®Âπ∂ÊèêÈ´òÂ§ÑÁêÜÈÄüÂ∫¶„ÄÇÊ≠§Â§ñÔºåÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠ÂºïÂÖ•Â∏ßÊé©Á†ÅÔºåÂ¢ûÂº∫Ê®°ÂûãÂØπÈÅÆÊå°ÂíåËøêÂä®Ê®°Á≥äÁöÑÈ≤ÅÊ£íÊÄßÔºåÊèêÈ´òÊ∑±Â∫¶‰º∞ËÆ°ÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöoVDAÁöÑÊï¥‰ΩìÊ°ÜÊû∂Âü∫‰∫éÁé∞ÊúâÁöÑVDAÊ®°ÂûãÔºå‰∏ªË¶ÅÂåÖÊã¨ÁâπÂæÅÊèêÂèñ„ÄÅÁâπÂæÅËûçÂêàÂíåÊ∑±Â∫¶È¢ÑÊµã‰∏â‰∏™Ê®°Âùó„ÄÇÂÖ≥ÈîÆÊîπËøõÂú®‰∫éÁâπÂæÅËûçÂêàÊ®°ÂùóÔºåËØ•Ê®°ÂùóÂºïÂÖ•‰∫ÜÁºìÂ≠òÊú∫Âà∂ÔºåÂ∞ÜÂÖàÂâçÂ∏ßÁöÑÊΩúÂú®ÁâπÂæÅÂ≠òÂÇ®Âú®ÁºìÂ≠ò‰∏≠ÔºåÂπ∂Âú®ÂΩìÂâçÂ∏ßÁöÑÁâπÂæÅËûçÂêàËøáÁ®ã‰∏≠Âà©Áî®Ëøô‰∫õÁºìÂ≠òÁâπÂæÅ„ÄÇÊ≠§Â§ñÔºåËÆ≠ÁªÉËøáÁ®ã‰πüËøõË°å‰∫Ü‰øÆÊîπÔºåÂºïÂÖ•‰∫ÜÂ∏ßÊé©Á†ÅÁ≠ñÁï•„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÂ∞ÜLLM‰∏≠ÁöÑÁºìÂ≠òÊú∫Âà∂ÂºïÂÖ•Âà∞ËßÜÈ¢ëÊ∑±Â∫¶‰º∞ËÆ°‰ªªÂä°‰∏≠„ÄÇ‰∏é‰º†ÁªüÁöÑÊâπÂ§ÑÁêÜÊñπÊ≥ïÁõ∏ÊØîÔºåoVDAÂè™ÈúÄË¶ÅÂ≠òÂÇ®Â∞ëÈáèÂÖàÂâçÂ∏ßÁöÑÊΩúÂú®ÁâπÂæÅÔºåÂ§ßÂ§ßÈôç‰Ωé‰∫ÜÂÜÖÂ≠òÂç†Áî®„ÄÇ‰∏éÁõ¥Êé•ÁöÑÂú®Á∫øÊñπÊ≥ïÁõ∏ÊØîÔºåoVDAÈÄöËøáÁºìÂ≠òÁâπÂæÅÂÆûÁé∞‰∫ÜÊõ¥Â•ΩÁöÑÊó∂Èó¥‰∏ÄËá¥ÊÄßÔºåÊèêÈ´ò‰∫ÜÊ∑±Â∫¶‰º∞ËÆ°ÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÁºìÂ≠òÂ§ßÂ∞èÊòØ‰∏Ä‰∏™ÂÖ≥ÈîÆÂèÇÊï∞ÔºåÂÜ≥ÂÆö‰∫ÜÂÜÖÂ≠òÂç†Áî®ÂíåÊó∂Èó¥‰∏ÄËá¥ÊÄß‰πãÈó¥ÁöÑÊùÉË°°„ÄÇËÆ∫ÊñáÂèØËÉΩÈááÁî®‰∫ÜÊªëÂä®Á™óÂè£ÁöÑÊñπÂºèÁÆ°ÁêÜÁºìÂ≠òÔºåÂπ∂ËÆæËÆ°‰∫ÜÁõ∏Â∫îÁöÑÁâπÂæÅÊõ¥Êñ∞Á≠ñÁï•„ÄÇÂ∏ßÊé©Á†ÅÁ≠ñÁï•ÂèØËÉΩÂåÖÊã¨ÈöèÊú∫Êé©ÁõñÈÉ®ÂàÜÂ∏ßÊàñÂå∫ÂüüÔºå‰ª•Ê®°ÊãüÈÅÆÊå°ÂíåËøêÂä®Ê®°Á≥ä„ÄÇÊçüÂ§±ÂáΩÊï∞ÂèØËÉΩÂåÖÊã¨Ê∑±Â∫¶È¢ÑÊµãÊçüÂ§±„ÄÅÊó∂Èó¥‰∏ÄËá¥ÊÄßÊçüÂ§±Á≠âÔºå‰ª•‰øùËØÅÊ∑±Â∫¶‰º∞ËÆ°ÁöÑÂáÜÁ°ÆÊÄßÂíåÊó∂Èó¥Á®≥ÂÆöÊÄß„ÄÇÂÖ∑‰ΩìÁöÑÁΩëÁªúÁªìÊûÑÁªÜËäÇÂíåÂèÇÊï∞ËÆæÁΩÆÈúÄË¶ÅÂú®ËÆ∫Êñá‰∏≠Ëøõ‰∏ÄÊ≠•Êü•Êâæ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

oVDAÂú®ÂáÜÁ°ÆÊÄßÂíåVRAM‰ΩøÁî®ÊñπÈù¢Âùá‰ºò‰∫éÁé∞ÊúâÂú®Á∫øËßÜÈ¢ëÊ∑±Â∫¶‰º∞ËÆ°ÊñπÊ≥ï„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåoVDAÂú®NVIDIA A100 GPU‰∏äÂÆûÁé∞‰∫Ü42 FPSÁöÑÂ∏ßÁéáÔºåÂú®NVIDIA JetsonËæπÁºòËÆæÂ§á‰∏äÂÆûÁé∞‰∫Ü20 FPSÁöÑÂ∏ßÁéáÔºåËØÅÊòé‰∫ÜÂÖ∂Âú®‰ΩéÂäüËÄóÁ°¨‰ª∂‰∏äÁöÑÈÉ®ÁΩ≤ÊΩúÂäõ„ÄÇÂÖ∑‰ΩìÁöÑÁ≤æÂ∫¶ÊèêÂçáÂπÖÂ∫¶ÈúÄË¶ÅÂèÇËÄÉËÆ∫Êñá‰∏≠ÁöÑÂÆûÈ™åÊï∞ÊçÆÔºå‰æãÂ¶Ç‰∏éÂÖ∂‰ªñÂú®Á∫øÊñπÊ≥ïÁöÑÊ∑±Â∫¶‰º∞ËÆ°ËØØÂ∑ÆÊåáÊ†áÂØπÊØî„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

oVDAÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂåÖÊã¨Ëá™Âä®È©æÈ©∂„ÄÅÊú∫Âô®‰∫∫ÂØºËà™„ÄÅÂ¢ûÂº∫Áé∞ÂÆûÂíåËôöÊãüÁé∞ÂÆûÁ≠âÈ¢ÜÂüü„ÄÇÂú®Ëá™Âä®È©æÈ©∂‰∏≠ÔºåÂèØ‰ª•Âà©Áî®oVDAÂÆûÊó∂ÊÑüÁü•Âë®Âõ¥ÁéØÂ¢ÉÁöÑÊ∑±Â∫¶‰ø°ÊÅØÔºåÊèêÈ´òÈ©æÈ©∂ÂÆâÂÖ®ÊÄß„ÄÇÂú®Êú∫Âô®‰∫∫ÂØºËà™‰∏≠ÔºåÂèØ‰ª•Â∏ÆÂä©Êú∫Âô®‰∫∫ÁêÜËß£Âë®Âõ¥ÁéØÂ¢ÉÔºåËßÑÂàíÊúÄ‰Ω≥Ë∑ØÂæÑ„ÄÇÂú®AR/VR‰∏≠ÔºåÂèØ‰ª•Êèê‰æõÊõ¥ÈÄºÁúüÁöÑÊ≤âÊµ∏Âºè‰ΩìÈ™å„ÄÇÁî±‰∫éÂÖ∂‰ΩéÂÜÖÂ≠òÂç†Áî®ÂíåÈ´òÊïàÁéáÔºåoVDAÁâπÂà´ÈÄÇÂêàÂú®ËæπÁºòËÆæÂ§á‰∏äÈÉ®ÁΩ≤Ôºå‰∏∫ÁßªÂä®Â∫îÁî®ÂíåÁâ©ËÅîÁΩëËÆæÂ§áÊèê‰æõÂº∫Â§ßÁöÑÊ∑±Â∫¶ÊÑüÁü•ËÉΩÂäõ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Depth estimation from monocular video has become a key component of many real-world computer vision systems. Recently, Video Depth Anything (VDA) has demonstrated strong performance on long video sequences. However, it relies on batch-processing which prohibits its use in an online setting. In this work, we overcome this limitation and introduce online VDA (oVDA). The key innovation is to employ techniques from Large Language Models (LLMs), namely, caching latent features during inference and masking frames at training. Our oVDA method outperforms all competing online video depth estimation methods in both accuracy and VRAM usage. Low VRAM usage is particularly important for deployment on edge devices. We demonstrate that oVDA runs at 42 FPS on an NVIDIA A100 and at 20 FPS on an NVIDIA Jetson edge device. We will release both, code and compilation scripts, making oVDA easy to deploy on low-power hardware.

