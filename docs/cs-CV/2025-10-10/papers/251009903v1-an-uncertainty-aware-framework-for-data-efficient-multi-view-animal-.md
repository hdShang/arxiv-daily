---
layout: default
title: An uncertainty-aware framework for data-efficient multi-view animal pose estimation
---

# An uncertainty-aware framework for data-efficient multi-view animal pose estimation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.09903" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.09903v1</a>
  <a href="https://arxiv.org/pdf/2510.09903.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.09903v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.09903v1', 'An uncertainty-aware framework for data-efficient multi-view animal pose estimation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Lenny Aharon, Keemin Lee, Karan Sikka, Selmaan Chettih, Cole Hurwitz, Liam Paninski, Matthew R Whiteway

**åˆ†ç±»**: cs.CV, q-bio.QM

**å‘å¸ƒæ—¥æœŸ**: 2025-10-10

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸ç¡®å®šæ€§æ„ŸçŸ¥æ¡†æ¶ï¼Œé«˜æ•ˆè§£å†³æ•°æ®ç¨€ç¼ºä¸‹çš„å¤šè§†è§’åŠ¨ç‰©å§¿æ€ä¼°è®¡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)**

**å…³é”®è¯**: `å¤šè§†è§’å§¿æ€ä¼°è®¡` `åŠ¨ç‰©è¡Œä¸ºåˆ†æ` `ä¸ç¡®å®šæ€§é‡åŒ–` `æ¨¡å‹è’¸é¦` `Transformerç½‘ç»œ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŠ¨ç‰©å¤šè§†è§’å§¿æ€ä¼°è®¡æ–¹æ³•åœ¨æ•°æ®é‡æœ‰é™çš„æƒ…å†µä¸‹ï¼Œç²¾åº¦éš¾ä»¥ä¿è¯ï¼Œä¸”ä¸ç¡®å®šæ€§è¯„ä¼°ä¸è¶³ã€‚
2. è®ºæ–‡æå‡ºç»“åˆå¤šè§†è§’Transformerã€patch maskingã€å‡ ä½•ä¸€è‡´æ€§ã€éçº¿æ€§EKSå¹³æ»‘å’Œæ¨¡å‹è’¸é¦çš„ç»¼åˆæ¡†æ¶ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨å¤šç§åŠ¨ç‰©ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå„ç»„ä»¶ä¼˜åŠ¿äº’è¡¥ï¼Œæå‡äº†å§¿æ€ä¼°è®¡çš„å¯é æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šè§†è§’å§¿æ€ä¼°è®¡å¯¹äºé‡åŒ–åŠ¨ç‰©è¡Œä¸ºè‡³å…³é‡è¦ï¼Œä½†ç°æœ‰æ–¹æ³•åœ¨æœ‰é™çš„æ ‡æ³¨æ•°æ®ä¸‹éš¾ä»¥å®ç°ç²¾ç¡®è·Ÿè¸ªï¼Œä¸”ä¸ç¡®å®šæ€§ä¼°è®¡è¾ƒå·®ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªç»¼åˆæ¡†æ¶ï¼Œç»“åˆäº†æ–°é¢–çš„è®­ç»ƒå’Œåå¤„ç†æŠ€æœ¯ï¼Œä»¥åŠæ¨¡å‹è’¸é¦è¿‡ç¨‹ï¼Œåˆ©ç”¨è¿™äº›æŠ€æœ¯çš„ä¼˜åŠ¿æ¥äº§ç”Ÿæ›´é«˜æ•ˆå’Œæœ‰æ•ˆçš„å§¿æ€ä¼°è®¡å™¨ã€‚å¤šè§†è§’Transformer (MVT) åˆ©ç”¨é¢„è®­ç»ƒéª¨å¹²ç½‘ç»œï¼Œèƒ½å¤ŸåŒæ—¶å¤„ç†æ¥è‡ªæ‰€æœ‰è§†è§’çš„ä¿¡æ¯ï¼ŒåŒæ—¶ä¸€ç§æ–°çš„patch maskingæ–¹æ¡ˆå­¦ä¹ é²æ£’çš„è·¨è§†è§’å¯¹åº”å…³ç³»ï¼Œæ— éœ€ç›¸æœºæ ‡å®šã€‚å¯¹äºå·²æ ‡å®šçš„è®¾ç½®ï¼Œæˆ‘ä»¬é€šè¿‡3Då¢å¼ºå’Œä¸‰è§’æµ‹é‡æŸå¤±æ¥ç»“åˆå‡ ä½•ä¸€è‡´æ€§ã€‚æˆ‘ä»¬å°†ç°æœ‰çš„é›†æˆå¡å°”æ›¼å¹³æ»‘å™¨ (EKS) åå¤„ç†å™¨æ‰©å±•åˆ°éçº¿æ€§æƒ…å†µï¼Œå¹¶é€šè¿‡æ–¹å·®è†¨èƒ€æŠ€æœ¯å¢å¼ºä¸ç¡®å®šæ€§é‡åŒ–ã€‚æœ€åï¼Œä¸ºäº†åˆ©ç”¨MVTçš„ç¼©æ”¾ç‰¹æ€§ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªè’¸é¦è¿‡ç¨‹ï¼Œåˆ©ç”¨æ”¹è¿›çš„EKSé¢„æµ‹å’Œä¸ç¡®å®šæ€§ä¼°è®¡æ¥ç”Ÿæˆé«˜è´¨é‡çš„ä¼ªæ ‡ç­¾ï¼Œä»è€Œå‡å°‘å¯¹äººå·¥æ ‡ç­¾çš„ä¾èµ–ã€‚æˆ‘ä»¬çš„æ¡†æ¶ç»„ä»¶åœ¨ä¸‰ç§ä¸åŒçš„åŠ¨ç‰©ç‰©ç§ï¼ˆæœè‡ã€å°é¼ ã€å±±é›€ï¼‰ä¸Šå§‹ç»ˆä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæ¯ä¸ªç»„ä»¶éƒ½è´¡çŒ®äº†äº’è¡¥çš„ä¼˜åŠ¿ã€‚æœ€ç»ˆå¾—åˆ°ä¸€ä¸ªå®ç”¨çš„ã€ä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„ç³»ç»Ÿï¼Œç”¨äºå¯é çš„å§¿æ€ä¼°è®¡ï¼Œä»è€Œèƒ½å¤Ÿåœ¨çœŸå®ä¸–ç•Œçš„æ•°æ®çº¦æŸä¸‹è¿›è¡Œä¸‹æ¸¸è¡Œä¸ºåˆ†æã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åœ¨æ•°æ®é‡æœ‰é™çš„æƒ…å†µä¸‹ï¼Œå¤šè§†è§’åŠ¨ç‰©å§¿æ€ä¼°è®¡ç²¾åº¦ä½å’Œä¸ç¡®å®šæ€§ä¼°è®¡å·®çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡çš„æ ‡æ³¨æ•°æ®æ‰èƒ½è¾¾åˆ°è¾ƒå¥½çš„æ€§èƒ½ï¼Œå¹¶ä¸”éš¾ä»¥æä¾›å¯é çš„ä¸ç¡®å®šæ€§è¯„ä¼°ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åœ¨å®é™…ç§‘ç ”ä¸­çš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤šè§†è§’ä¿¡æ¯ï¼Œé€šè¿‡æ–°é¢–çš„è®­ç»ƒå’Œåå¤„ç†æŠ€æœ¯ï¼Œä»¥åŠæ¨¡å‹è’¸é¦ï¼Œæ¥æé«˜å§¿æ€ä¼°è®¡çš„ç²¾åº¦å’Œå¯é æ€§ï¼ŒåŒæ—¶æä¾›å‡†ç¡®çš„ä¸ç¡®å®šæ€§ä¼°è®¡ã€‚é€šè¿‡ç»“åˆå‡ ä½•çº¦æŸã€è·¨è§†è§’å¯¹åº”å…³ç³»å­¦ä¹ å’Œä¸ç¡®å®šæ€§é‡åŒ–ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨æœ‰é™çš„æ ‡æ³¨æ•°æ®ï¼Œå¹¶ç”Ÿæˆé«˜è´¨é‡çš„ä¼ªæ ‡ç­¾ï¼Œä»è€Œè¿›ä¸€æ­¥æé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) å¤šè§†è§’Transformer (MVT)ï¼šç”¨äºæå–å¤šè§†è§’å›¾åƒçš„ç‰¹å¾ï¼Œå¹¶å­¦ä¹ è·¨è§†è§’å¯¹åº”å…³ç³»ã€‚2) Patch Maskingï¼šä¸€ç§æ–°çš„patch maskingæ–¹æ¡ˆï¼Œç”¨äºå­¦ä¹ é²æ£’çš„è·¨è§†è§’å¯¹åº”å…³ç³»ï¼Œæ— éœ€ç›¸æœºæ ‡å®šã€‚3) å‡ ä½•ä¸€è‡´æ€§ï¼šå¯¹äºå·²æ ‡å®šçš„è®¾ç½®ï¼Œé€šè¿‡3Då¢å¼ºå’Œä¸‰è§’æµ‹é‡æŸå¤±æ¥ç»“åˆå‡ ä½•ä¸€è‡´æ€§ã€‚4) é›†æˆå¡å°”æ›¼å¹³æ»‘å™¨ (EKS)ï¼šå°†ç°æœ‰çš„EKSåå¤„ç†å™¨æ‰©å±•åˆ°éçº¿æ€§æƒ…å†µï¼Œå¹¶é€šè¿‡æ–¹å·®è†¨èƒ€æŠ€æœ¯å¢å¼ºä¸ç¡®å®šæ€§é‡åŒ–ã€‚5) æ¨¡å‹è’¸é¦ï¼šåˆ©ç”¨æ”¹è¿›çš„EKSé¢„æµ‹å’Œä¸ç¡®å®šæ€§ä¼°è®¡æ¥ç”Ÿæˆé«˜è´¨é‡çš„ä¼ªæ ‡ç­¾ï¼Œä»è€Œå‡å°‘å¯¹äººå·¥æ ‡ç­¾çš„ä¾èµ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°ç‚¹åœ¨äºï¼š1) æå‡ºäº†ä¸€ä¸ªç»¼åˆæ€§çš„æ¡†æ¶ï¼Œå°†å¤šè§†è§’Transformerã€patch maskingã€å‡ ä½•ä¸€è‡´æ€§ã€éçº¿æ€§EKSå¹³æ»‘å’Œæ¨¡å‹è’¸é¦æœ‰æ•ˆåœ°ç»“åˆèµ·æ¥ã€‚2) æå‡ºäº†ä¸€ç§æ–°çš„patch maskingæ–¹æ¡ˆï¼Œç”¨äºå­¦ä¹ é²æ£’çš„è·¨è§†è§’å¯¹åº”å…³ç³»ï¼Œæ— éœ€ç›¸æœºæ ‡å®šã€‚3) å°†ç°æœ‰çš„EKSåå¤„ç†å™¨æ‰©å±•åˆ°éçº¿æ€§æƒ…å†µï¼Œå¹¶é€šè¿‡æ–¹å·®è†¨èƒ€æŠ€æœ¯å¢å¼ºä¸ç¡®å®šæ€§é‡åŒ–ã€‚4) è®¾è®¡äº†ä¸€ä¸ªæ¨¡å‹è’¸é¦è¿‡ç¨‹ï¼Œåˆ©ç”¨æ”¹è¿›çš„EKSé¢„æµ‹å’Œä¸ç¡®å®šæ€§ä¼°è®¡æ¥ç”Ÿæˆé«˜è´¨é‡çš„ä¼ªæ ‡ç­¾ã€‚

**å…³é”®è®¾è®¡**ï¼šMVTä½¿ç”¨é¢„è®­ç»ƒçš„éª¨å¹²ç½‘ç»œï¼Œä¾‹å¦‚ResNetï¼Œä»¥æé«˜ç‰¹å¾æå–èƒ½åŠ›ã€‚Patch maskingæ–¹æ¡ˆé€šè¿‡éšæœºmaskæ‰å›¾åƒçš„patchï¼Œè¿«ä½¿æ¨¡å‹å­¦ä¹ è·¨è§†è§’å¯¹åº”å…³ç³»ã€‚å‡ ä½•ä¸€è‡´æ€§é€šè¿‡3Då¢å¼ºå’Œä¸‰è§’æµ‹é‡æŸå¤±æ¥å®ç°ï¼Œå…¶ä¸­ä¸‰è§’æµ‹é‡æŸå¤±ç”¨äºçº¦æŸä¼°è®¡çš„3Då§¿æ€ä¸å¤šè§†è§’å›¾åƒä¹‹é—´çš„å‡ ä½•å…³ç³»ã€‚EKSåå¤„ç†å™¨ä½¿ç”¨æ–¹å·®è†¨èƒ€æŠ€æœ¯æ¥æé«˜ä¸ç¡®å®šæ€§ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚æ¨¡å‹è’¸é¦è¿‡ç¨‹ä½¿ç”¨EKSçš„é¢„æµ‹ä½œä¸ºä¼ªæ ‡ç­¾ï¼Œå¹¶ä½¿ç”¨ä¸ç¡®å®šæ€§ä¼°è®¡æ¥è¿‡æ»¤ä½è´¨é‡çš„ä¼ªæ ‡ç­¾ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨ä¸‰ç§ä¸åŒçš„åŠ¨ç‰©ç‰©ç§ï¼ˆæœè‡ã€å°é¼ ã€å±±é›€ï¼‰ä¸Šå§‹ç»ˆä¼˜äºç°æœ‰æ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼Œè¯¥æ¡†æ¶åœ¨å§¿æ€ä¼°è®¡ç²¾åº¦æ–¹é¢å–å¾—äº†æ˜¾è‘—æå‡ï¼Œå¹¶ä¸”èƒ½å¤Ÿæä¾›æ›´å‡†ç¡®çš„ä¸ç¡®å®šæ€§ä¼°è®¡ã€‚æ¯ä¸ªç»„ä»¶éƒ½è´¡çŒ®äº†äº’è¡¥çš„ä¼˜åŠ¿ï¼Œå…±åŒæé«˜äº†å§¿æ€ä¼°è®¡çš„å¯é æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºåŠ¨ç‰©è¡Œä¸ºå­¦ç ”ç©¶ã€ç”Ÿç‰©åŒ»å­¦å·¥ç¨‹ã€æœºå™¨äººå¯¼èˆªç­‰é¢†åŸŸã€‚é€šè¿‡ç²¾ç¡®çš„åŠ¨ç‰©å§¿æ€ä¼°è®¡ï¼Œå¯ä»¥æ·±å…¥åˆ†æåŠ¨ç‰©çš„è¡Œä¸ºæ¨¡å¼ï¼Œä¸ºç–¾ç—…è¯Šæ–­å’Œæ²»ç–—æä¾›æ–°çš„æ€è·¯ã€‚åœ¨æœºå™¨äººé¢†åŸŸï¼Œè¯¥æŠ€æœ¯å¯ç”¨äºæé«˜æœºå™¨äººå¯¹ç¯å¢ƒçš„æ„ŸçŸ¥èƒ½åŠ›ï¼Œå®ç°æ›´æ™ºèƒ½çš„å¯¼èˆªå’Œæ§åˆ¶ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multi-view pose estimation is essential for quantifying animal behavior in scientific research, yet current methods struggle to achieve accurate tracking with limited labeled data and suffer from poor uncertainty estimates. We address these challenges with a comprehensive framework combining novel training and post-processing techniques, and a model distillation procedure that leverages the strengths of these techniques to produce a more efficient and effective pose estimator. Our multi-view transformer (MVT) utilizes pretrained backbones and enables simultaneous processing of information across all views, while a novel patch masking scheme learns robust cross-view correspondences without camera calibration. For calibrated setups, we incorporate geometric consistency through 3D augmentation and a triangulation loss. We extend the existing Ensemble Kalman Smoother (EKS) post-processor to the nonlinear case and enhance uncertainty quantification via a variance inflation technique. Finally, to leverage the scaling properties of the MVT, we design a distillation procedure that exploits improved EKS predictions and uncertainty estimates to generate high-quality pseudo-labels, thereby reducing dependence on manual labels. Our framework components consistently outperform existing methods across three diverse animal species (flies, mice, chickadees), with each component contributing complementary benefits. The result is a practical, uncertainty-aware system for reliable pose estimation that enables downstream behavioral analyses under real-world data constraints.

