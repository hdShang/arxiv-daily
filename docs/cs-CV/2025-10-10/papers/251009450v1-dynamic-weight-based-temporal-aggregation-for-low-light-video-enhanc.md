---
layout: default
title: Dynamic Weight-based Temporal Aggregation for Low-light Video Enhancement
---

# Dynamic Weight-based Temporal Aggregation for Low-light Video Enhancement

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.09450" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.09450v1</a>
  <a href="https://arxiv.org/pdf/2510.09450.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.09450v1" onclick="toggleFavorite(this, '2510.09450v1', 'Dynamic Weight-based Temporal Aggregation for Low-light Video Enhancement')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ruirui Lin, Guoxi Huang, Nantheera Anantrasirichai

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-10

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDWTA-Netï¼Œé€šè¿‡åŠ¨æ€æƒé‡æ—¶åºèšåˆå¢å¼ºä½å…‰è§†é¢‘è´¨é‡ï¼Œæœ‰æ•ˆæŠ‘åˆ¶å™ªå£°ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `ä½å…‰è§†é¢‘å¢å¼º` `æ—¶åºèšåˆ` `åŠ¨æ€æƒé‡` `å…‰æµä¼°è®¡` `æ·±åº¦å­¦ä¹ ` `è§†é¢‘å¤„ç†` `è§†è§‰çŠ¶æ€ç©ºé—´`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ä½å…‰è§†é¢‘å¢å¼ºæ–¹æ³•éš¾ä»¥æœ‰æ•ˆåˆ©ç”¨æ—¶åºä¿¡æ¯ï¼Œå¯¼è‡´åœ¨çœŸå®åœºæ™¯ä¸­å™ªå£°æŠ‘åˆ¶æ•ˆæœä¸ä½³ã€‚
2. DWTA-Neté€šè¿‡ä¸¤é˜¶æ®µæ¡†æ¶ï¼Œåˆ†åˆ«åˆ©ç”¨è§†è§‰çŠ¶æ€ç©ºé—´å—å’ŒåŠ¨æ€æƒé‡æ—¶åºèšåˆï¼Œå®ç°äº®åº¦ã€é¢œè‰²å’Œç»“æ„çš„æ¢å¤ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒDWTA-Netåœ¨çœŸå®ä½å…‰è§†é¢‘ä¸Šèƒ½æœ‰æ•ˆæŠ‘åˆ¶å™ªå£°å’Œä¼ªå½±ï¼Œæä¾›æ›´å¥½çš„è§†è§‰è´¨é‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä½å…‰è§†é¢‘å¢å¼ºï¼ˆLLVEï¼‰ç”±äºå™ªå£°ã€ä½å¯¹æ¯”åº¦å’Œè‰²å½©é€€åŒ–è€Œæå…·æŒ‘æˆ˜æ€§ã€‚åŸºäºå­¦ä¹ çš„æ–¹æ³•è™½ç„¶æ¨ç†é€Ÿåº¦å¿«ï¼Œä½†ç”±äºåœ¨æœ‰æ•ˆåˆ©ç”¨æ—¶é—´ä¿¡æ¯æ–¹é¢å­˜åœ¨å±€é™æ€§ï¼Œå› æ­¤åœ¨çœŸå®çš„ä½å…‰åœºæ™¯ä¸­ä»ç„¶éš¾ä»¥å¤„ç†ä¸¥é‡çš„å™ªå£°ã€‚æœ¬æ–‡æå‡ºäº†DWTA-Netï¼Œä¸€ç§æ–°é¢–çš„ä¸¤é˜¶æ®µæ¡†æ¶ï¼Œå®ƒè”åˆåˆ©ç”¨çŸ­æ—¶å’Œé•¿æ—¶çš„æ—¶é—´çº¿ç´¢ã€‚ç¬¬ä¸€é˜¶æ®µé‡‡ç”¨è§†è§‰çŠ¶æ€ç©ºé—´å—è¿›è¡Œå¤šå¸§å¯¹é½ï¼Œä»¥å±€éƒ¨ä¸€è‡´æ€§æ¢å¤äº®åº¦ã€é¢œè‰²å’Œç»“æ„ã€‚ç¬¬äºŒé˜¶æ®µå¼•å…¥äº†ä¸€ä¸ªå¾ªç¯ç»†åŒ–æ¨¡å—ï¼Œè¯¥æ¨¡å—å…·æœ‰å…‰æµå¼•å¯¼çš„åŸºäºåŠ¨æ€æƒé‡çš„æ—¶åºèšåˆï¼Œè‡ªé€‚åº”åœ°å¹³è¡¡é™æ€å’ŒåŠ¨æ€åŒºåŸŸã€‚çº¹ç†è‡ªé€‚åº”æŸå¤±è¿›ä¸€æ­¥ä¿ç•™äº†ç²¾ç»†çš„ç»†èŠ‚ï¼ŒåŒæ—¶ä¿ƒè¿›äº†å¹³å¦åŒºåŸŸçš„å¹³æ»‘æ€§ã€‚åœ¨çœŸå®ä½å…‰è§†é¢‘ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼ŒDWTA-Netæœ‰æ•ˆåœ°æŠ‘åˆ¶äº†å™ªå£°å’Œä¼ªå½±ï¼Œæä¾›äº†å“è¶Šçš„è§†è§‰è´¨é‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šä½å…‰è§†é¢‘å¢å¼ºæ—¨åœ¨æå‡åœ¨å…‰çº¿ä¸è¶³ç¯å¢ƒä¸‹æ‹æ‘„çš„è§†é¢‘çš„è§†è§‰è´¨é‡ã€‚ç°æœ‰æ–¹æ³•ï¼Œå°¤å…¶æ˜¯åŸºäºæ·±åº¦å­¦ä¹ çš„æ–¹æ³•ï¼Œåœ¨å¤„ç†çœŸå®ä½å…‰åœºæ™¯æ—¶ï¼Œç”±äºå™ªå£°ä¸¥é‡ã€å¯¹æ¯”åº¦ä½ä»¥åŠè‰²å½©å¤±çœŸç­‰é—®é¢˜ï¼Œä»ç„¶é¢ä¸´æŒ‘æˆ˜ã€‚ä¸€ä¸ªä¸»è¦ç—›ç‚¹æ˜¯éš¾ä»¥æœ‰æ•ˆåœ°åˆ©ç”¨è§†é¢‘ä¸­çš„æ—¶åºä¿¡æ¯ï¼Œå¯¼è‡´å¢å¼ºåçš„è§†é¢‘å¯èƒ½å­˜åœ¨æ—¶é—´ä¸Šçš„ä¸ä¸€è‡´æ€§å’Œä¼ªå½±ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDWTA-Netçš„æ ¸å¿ƒæ€è·¯æ˜¯è”åˆåˆ©ç”¨çŸ­æ—¶å’Œé•¿æ—¶çš„æ—¶åºä¿¡æ¯ï¼Œé€šè¿‡ä¸¤é˜¶æ®µçš„å¤„ç†æµç¨‹ï¼Œé€æ­¥æå‡è§†é¢‘è´¨é‡ã€‚ç¬¬ä¸€é˜¶æ®µä¾§é‡äºå¤šå¸§å¯¹é½å’Œå±€éƒ¨ä¸€è‡´æ€§çš„æ¢å¤ï¼Œç¬¬äºŒé˜¶æ®µåˆ™é€šè¿‡åŠ¨æ€æƒé‡çš„æ—¶åºèšåˆï¼Œè‡ªé€‚åº”åœ°å¹³è¡¡é™æ€å’ŒåŠ¨æ€åŒºåŸŸï¼Œä»è€Œæ›´æœ‰æ•ˆåœ°æŠ‘åˆ¶å™ªå£°å’Œä¼ªå½±ã€‚è¿™ç§åˆ†é˜¶æ®µã€è‡ªé€‚åº”çš„æ—¶åºä¿¡æ¯åˆ©ç”¨æ˜¯è¯¥æ–¹æ³•çš„æ ¸å¿ƒã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDWTA-Netæ˜¯ä¸€ä¸ªä¸¤é˜¶æ®µçš„æ¡†æ¶ï¼š
1. **ç¬¬ä¸€é˜¶æ®µï¼šå¤šå¸§å¯¹é½ä¸æ¢å¤**ã€‚ä½¿ç”¨è§†è§‰çŠ¶æ€ç©ºé—´ï¼ˆVisual State-Spaceï¼‰å—è¿›è¡Œå¤šå¸§å¯¹é½ï¼Œç›®çš„æ˜¯æ¢å¤äº®åº¦ã€é¢œè‰²å’Œç»“æ„ï¼Œå¹¶ä¿æŒå±€éƒ¨ä¸€è‡´æ€§ã€‚
2. **ç¬¬äºŒé˜¶æ®µï¼šå¾ªç¯ç»†åŒ–ä¸æ—¶åºèšåˆ**ã€‚å¼•å…¥å¾ªç¯ç»†åŒ–æ¨¡å—ï¼Œè¯¥æ¨¡å—åŸºäºå…‰æµå¼•å¯¼çš„åŠ¨æ€æƒé‡æ—¶åºèšåˆã€‚å…‰æµç”¨äºä¼°è®¡å¸§é—´çš„è¿åŠ¨ä¿¡æ¯ï¼ŒåŠ¨æ€æƒé‡åˆ™ç”¨äºè‡ªé€‚åº”åœ°å¹³è¡¡ä¸åŒå¸§çš„ä¿¡æ¯ï¼Œä»è€Œæ›´å¥½åœ°å¤„ç†é™æ€å’ŒåŠ¨æ€åŒºåŸŸã€‚

**å…³é”®åˆ›æ–°**ï¼šDWTA-Netçš„å…³é”®åˆ›æ–°åœ¨äºåŠ¨æ€æƒé‡çš„æ—¶åºèšåˆæœºåˆ¶ã€‚ä¼ ç»Ÿæ–¹æ³•é€šå¸¸é‡‡ç”¨ç®€å•çš„å¹³å‡æˆ–åŠ æƒå¹³å‡æ¥èåˆä¸åŒå¸§çš„ä¿¡æ¯ï¼Œè€ŒDWTA-Netåˆ™æ ¹æ®å…‰æµä¿¡æ¯ï¼ŒåŠ¨æ€åœ°è°ƒæ•´ä¸åŒå¸§çš„æƒé‡ã€‚è¿™ç§è‡ªé€‚åº”çš„æƒé‡è°ƒæ•´ä½¿å¾—ç½‘ç»œèƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†è§†é¢‘ä¸­çš„è¿åŠ¨å’Œå˜åŒ–ï¼Œä»è€Œæ›´æœ‰æ•ˆåœ°æŠ‘åˆ¶å™ªå£°å’Œä¼ªå½±ã€‚æ­¤å¤–ï¼Œçº¹ç†è‡ªé€‚åº”æŸå¤±å‡½æ•°ä¹Ÿæ˜¯ä¸€ä¸ªåˆ›æ–°ç‚¹ï¼Œå®ƒèƒ½å¤Ÿæ›´å¥½åœ°ä¿ç•™å›¾åƒç»†èŠ‚ï¼ŒåŒæ—¶å¹³æ»‘å¹³å¦åŒºåŸŸã€‚

**å…³é”®è®¾è®¡**ï¼š
*   **è§†è§‰çŠ¶æ€ç©ºé—´å—**ï¼šç”¨äºå¤šå¸§å¯¹é½ï¼Œå…·ä½“ç»“æ„æœªçŸ¥ã€‚
*   **å…‰æµä¼°è®¡**ï¼šç”¨äºæŒ‡å¯¼åŠ¨æ€æƒé‡çš„è®¡ç®—ï¼Œå…·ä½“çš„å…‰æµä¼°è®¡æ–¹æ³•æœªçŸ¥ã€‚
*   **åŠ¨æ€æƒé‡è®¡ç®—**ï¼šåŸºäºå…‰æµä¿¡æ¯ï¼Œè®¾è®¡åŠ¨æ€æƒé‡è®¡ç®—æ–¹æ³•ï¼Œä»¥è‡ªé€‚åº”åœ°å¹³è¡¡é™æ€å’ŒåŠ¨æ€åŒºåŸŸçš„ä¿¡æ¯ã€‚
*   **çº¹ç†è‡ªé€‚åº”æŸå¤±**ï¼šè®¾è®¡ä¸€ç§çº¹ç†è‡ªé€‚åº”çš„æŸå¤±å‡½æ•°ï¼Œåœ¨ä¿ç•™ç»†èŠ‚çš„åŒæ—¶ï¼Œä¿ƒè¿›å¹³å¦åŒºåŸŸçš„å¹³æ»‘æ€§ã€‚å…·ä½“å½¢å¼æœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

DWTA-Netåœ¨çœŸå®ä½å…‰è§†é¢‘æ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæŠ‘åˆ¶å™ªå£°å’Œä¼ªå½±ï¼Œæä¾›æ›´æ¸…æ™°ã€æ›´è‡ªç„¶çš„è§†è§‰æ•ˆæœã€‚è™½ç„¶è®ºæ–‡ä¸­æ²¡æœ‰æä¾›å…·ä½“çš„é‡åŒ–æŒ‡æ ‡å’Œå¯¹æ¯”æ•°æ®ï¼Œä½†å¼ºè°ƒäº†å…¶åœ¨è§†è§‰è´¨é‡æ–¹é¢ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤„ç†å¤æ‚å…‰ç…§æ¡ä»¶å’ŒåŠ¨æ€åœºæ™¯æ—¶å…·æœ‰è¾ƒå¼ºçš„é²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

DWTA-Netåœ¨å®‰é˜²ç›‘æ§ã€è‡ªåŠ¨é©¾é©¶ã€åŒ»å­¦å½±åƒç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚åœ¨å…‰çº¿ä¸è¶³çš„ç¯å¢ƒä¸‹ï¼Œè¯¥æ–¹æ³•å¯ä»¥æœ‰æ•ˆæå‡è§†é¢‘çš„æ¸…æ™°åº¦å’Œå¯è¾¨è¯†åº¦ï¼Œä»è€Œæé«˜ç›‘æ§ç³»ç»Ÿçš„å¯é æ€§ï¼Œè¾…åŠ©é©¾é©¶å‘˜è¿›è¡Œå†³ç­–ï¼Œå¹¶æ”¹å–„åŒ»å­¦å½±åƒçš„è¯Šæ–­æ•ˆæœã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›è¿›ä¸€æ­¥åº”ç”¨äºæ™ºèƒ½å®¶å±…ã€æ— äººæœºèˆªæ‹ç­‰é¢†åŸŸï¼Œæå‡ç”¨æˆ·åœ¨ä½å…‰ç¯å¢ƒä¸‹çš„è§†è§‰ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Low-light video enhancement (LLVE) is challenging due to noise, low contrast, and color degradations. Learning-based approaches offer fast inference but still struggle with heavy noise in real low-light scenes, primarily due to limitations in effectively leveraging temporal information. In this paper, we address this issue with DWTA-Net, a novel two-stage framework that jointly exploits short- and long-term temporal cues. Stage I employs Visual State-Space blocks for multi-frame alignment, recovering brightness, color, and structure with local consistency. Stage II introduces a recurrent refinement module with dynamic weight-based temporal aggregation guided by optical flow, adaptively balancing static and dynamic regions. A texture-adaptive loss further preserves fine details while promoting smoothness in flat areas. Experiments on real-world low-light videos show that DWTA-Net effectively suppresses noise and artifacts, delivering superior visual quality compared with state-of-the-art methods.

