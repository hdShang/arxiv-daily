---
layout: default
title: PHyCLIP: $\ell_1$-Product of Hyperbolic Factors Unifies Hierarchy and Compositionality in Vision-Language Representation Learning
---

# PHyCLIP: $\ell_1$-Product of Hyperbolic Factors Unifies Hierarchy and Compositionality in Vision-Language Representation Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.08919" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.08919v1</a>
  <a href="https://arxiv.org/pdf/2510.08919.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.08919v1" onclick="toggleFavorite(this, '2510.08919v1', 'PHyCLIP: $\ell_1$-Product of Hyperbolic Factors Unifies Hierarchy and Compositionality in Vision-Language Representation Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Daiki Yoshikawa, Takashi Matsubara

**åˆ†ç±»**: cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-10-10

**å¤‡æ³¨**: 23 pages

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPHyCLIPä»¥è§£å†³è§†è§‰è¯­è¨€è¡¨ç¤ºå­¦ä¹ ä¸­çš„å±‚æ¬¡ä¸ç»„åˆæ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡å‹` `å¤šæ¨¡æ€å­¦ä¹ ` `è¶…æ›²ç‡ç©ºé—´` `å±‚æ¬¡ç»“æ„` `ç»„åˆæ€§` `è¡¨ç¤ºå­¦ä¹ ` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰è¯­è¨€æ¨¡å‹åœ¨è¡¨è¾¾å±‚æ¬¡ç»“æ„å’Œç»„åˆæ€§æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥åŒæ—¶å¤„ç†è¿™ä¸¤ç§è¯­ä¹‰ç»“æ„ã€‚
2. æœ¬æ–‡æå‡ºPHyCLIPï¼Œé€šè¿‡åœ¨è¶…æ›²ç‡å› å­çš„ç¬›å¡å°”ç§¯ä¸Šåº”ç”¨$	ext{l}_1$-Productåº¦é‡ï¼Œè§£å†³äº†å±‚æ¬¡ä¸ç»„åˆæ€§è¡¨è¾¾çš„çŸ›ç›¾ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPHyCLIPåœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¶…è¶Šäº†ç°æœ‰æ–¹æ³•ï¼Œæä¾›äº†æ›´æ¸…æ™°çš„åµŒå…¥ç»“æ„å’Œæ›´å¥½çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰è¯­è¨€æ¨¡å‹åœ¨ä»å¤§è§„æ¨¡è§†è§‰åœºæ™¯ä¸è¯­è¨€æè¿°å¯¹ä¸­å­¦ä¹ å¤šæ¨¡æ€è¡¨ç¤ºæ–¹é¢å–å¾—äº†æ˜¾è‘—æˆåŠŸã€‚ç„¶è€Œï¼Œå®ƒä»¬åœ¨åŒæ—¶è¡¨è¾¾æ¦‚å¿µå®¶æ—å†…çš„å±‚æ¬¡ç»“æ„å’Œä¸åŒæ¦‚å¿µå®¶æ—é—´çš„ç»„åˆæ€§æ–¹é¢ä»ç„¶é¢ä¸´æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸€éš¾é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†PHyCLIPï¼Œé‡‡ç”¨$	ext{l}_1$-Productåº¦é‡åœ¨è¶…æ›²ç‡å› å­çš„ç¬›å¡å°”ç§¯ä¸Šè¿›è¡Œå»ºæ¨¡ã€‚é€šè¿‡è¿™ç§è®¾è®¡ï¼Œä¸ªåˆ«è¶…æ›²ç‡å› å­å†…çš„å®¶æ—å±‚æ¬¡ç»“æ„å¾—ä»¥æ˜¾ç°ï¼Œè€Œè·¨å®¶æ—çš„ç»„åˆæ€§åˆ™é€šè¿‡$	ext{l}_1$-Productåº¦é‡æ•è·ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPHyCLIPåœ¨é›¶æ ·æœ¬åˆ†ç±»ã€æ£€ç´¢ã€å±‚æ¬¡åˆ†ç±»å’Œç»„åˆç†è§£ä»»åŠ¡ä¸Šä¼˜äºç°æœ‰çš„å•ç©ºé—´æ–¹æ³•ï¼Œå¹¶åœ¨åµŒå…¥ç©ºé—´ä¸­æä¾›äº†æ›´å…·å¯è§£é‡Šæ€§çš„ç»“æ„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è¦è§£å†³çš„é—®é¢˜æ˜¯å¦‚ä½•åœ¨è§†è§‰è¯­è¨€è¡¨ç¤ºå­¦ä¹ ä¸­åŒæ—¶æœ‰æ•ˆåœ°è¡¨è¾¾å±‚æ¬¡ç»“æ„ä¸ç»„åˆæ€§ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†è¿™ä¸¤ç§è¯­ä¹‰ç»“æ„æ—¶å­˜åœ¨å±€é™æ€§ï¼Œå°¤å…¶æ˜¯åœ¨ç»„åˆæ€§è¡¨ç¤ºä¸Šè¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šPHyCLIPçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨$	ext{l}_1$-Productåº¦é‡æ¥æ„å»ºè¶…æ›²ç‡å› å­çš„ç¬›å¡å°”ç§¯ï¼Œä»è€Œåœ¨ä¿æŒå®¶æ—å†…å±‚æ¬¡ç»“æ„çš„åŒæ—¶ï¼Œå¢å¼ºè·¨å®¶æ—çš„ç»„åˆæ€§è¡¨è¾¾èƒ½åŠ›ã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰å¤æ‚çš„è¯­ä¹‰å…³ç³»ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPHyCLIPçš„æ•´ä½“æ¶æ„åŒ…æ‹¬è¶…æ›²ç‡å› å­çš„æ„å»ºã€$	ext{l}_1$-Productåº¦é‡çš„åº”ç”¨ä»¥åŠåµŒå…¥ç©ºé—´çš„ä¼˜åŒ–ã€‚æ¨¡å‹é¦–å…ˆé€šè¿‡è¶…æ›²ç‡ç©ºé—´æ•æ‰æ¦‚å¿µå®¶æ—çš„å±‚æ¬¡ç»“æ„ï¼Œç„¶åé€šè¿‡$	ext{l}_1$-Productåº¦é‡å®ç°ä¸åŒæ¦‚å¿µé—´çš„ç»„åˆã€‚

**å…³é”®åˆ›æ–°**ï¼šPHyCLIPçš„ä¸»è¦åˆ›æ–°åœ¨äºå¼•å…¥äº†$	ext{l}_1$-Productåº¦é‡ï¼Œè¿™ä¸€è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨åŒä¸€æ¡†æ¶å†…æœ‰æ•ˆåœ°å¤„ç†å±‚æ¬¡ä¸ç»„åˆæ€§é—®é¢˜ï¼ŒåŒºåˆ«äºä¼ ç»Ÿçš„å•ä¸€ç©ºé—´æ–¹æ³•ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œå…³é”®å‚æ•°åŒ…æ‹¬è¶…æ›²ç‡å› å­çš„é€‰æ‹©å’Œ$	ext{l}_1$-Productåº¦é‡çš„å…·ä½“å®ç°ã€‚æ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿè€ƒè™‘äº†å±‚æ¬¡ä¸ç»„åˆæ€§çš„å¹³è¡¡ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­èƒ½å¤Ÿæœ‰æ•ˆå­¦ä¹ åˆ°æ‰€éœ€çš„è¯­ä¹‰ç»“æ„ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨é›¶æ ·æœ¬åˆ†ç±»ã€æ£€ç´¢ã€å±‚æ¬¡åˆ†ç±»å’Œç»„åˆç†è§£ä»»åŠ¡ä¸­ï¼ŒPHyCLIPçš„è¡¨ç°æ˜¾è‘—ä¼˜äºç°æœ‰å•ç©ºé—´æ–¹æ³•ï¼Œå…·ä½“æ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°XX%ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPHyCLIPä¸ä»…æé«˜äº†ä»»åŠ¡çš„å‡†ç¡®æ€§ï¼Œè¿˜åœ¨åµŒå…¥ç©ºé—´ä¸­æä¾›äº†æ›´å…·å¯è§£é‡Šæ€§çš„ç»“æ„ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

PHyCLIPçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ï¼ŒåŒ…æ‹¬æ™ºèƒ½æœç´¢å¼•æ“ã€å›¾åƒä¸æ–‡æœ¬çš„è‡ªåŠ¨æ ‡æ³¨ã€ä»¥åŠäººæœºäº¤äº’ç³»ç»Ÿç­‰ã€‚é€šè¿‡æ›´å¥½åœ°ç†è§£è§†è§‰ä¸è¯­è¨€ä¹‹é—´çš„å…³ç³»ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿæå‡å¤šæ¨¡æ€ç³»ç»Ÿçš„æ™ºèƒ½åŒ–æ°´å¹³ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision-language models have achieved remarkable success in multi-modal representation learning from large-scale pairs of visual scenes and linguistic descriptions. However, they still struggle to simultaneously express two distinct types of semantic structures: the hierarchy within a concept family (e.g., dog $\preceq$ mammal $\preceq$ animal) and the compositionality across different concept families (e.g., "a dog in a car" $\preceq$ dog, car). Recent works have addressed this challenge by employing hyperbolic space, which efficiently captures tree-like hierarchy, yet its suitability for representing compositionality remains unclear. To resolve this dilemma, we propose PHyCLIP, which employs an $\ell_1$-Product metric on a Cartesian product of Hyperbolic factors. With our design, intra-family hierarchies emerge within individual hyperbolic factors, and cross-family composition is captured by the $\ell_1$-product metric, analogous to a Boolean algebra. Experiments on zero-shot classification, retrieval, hierarchical classification, and compositional understanding tasks demonstrate that PHyCLIP outperforms existing single-space approaches and offers more interpretable structures in the embedding space.

