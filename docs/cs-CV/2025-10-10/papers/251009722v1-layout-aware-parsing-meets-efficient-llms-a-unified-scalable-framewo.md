---
layout: default
title: Layout-Aware Parsing Meets Efficient LLMs: A Unified, Scalable Framework for Resume Information Extraction and Evaluation
---

# Layout-Aware Parsing Meets Efficient LLMs: A Unified, Scalable Framework for Resume Information Extraction and Evaluation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.09722" target="_blank" class="toolbar-btn">arXiv: 2510.09722v1</a>
    <a href="https://arxiv.org/pdf/2510.09722.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.09722v1" 
            onclick="toggleFavorite(this, '2510.09722v1', 'Layout-Aware Parsing Meets Efficient LLMs: A Unified, Scalable Framework for Resume Information Extraction and Evaluation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Fanwei Zhu, Jinke Yu, Zulong Chen, Ying Zhou, Junhao Ji, Zhibo Yang, Yuxue Zhang, Haoyuan Hu, Zhenghao Liu

**ÂàÜÁ±ª**: cs.CL, cs.AI, cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-10

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Â∏ÉÂ±ÄÊÑüÁü•ÁöÑÈ´òÊïàLLMÊ°ÜÊû∂ÔºåÁî®‰∫éÁÆÄÂéÜ‰ø°ÊÅØÊäΩÂèñ‰∏éËØÑ‰º∞„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÁÆÄÂéÜ‰ø°ÊÅØÊäΩÂèñ` `Â∏ÉÂ±ÄÊÑüÁü•` `È´òÊïàLLM` `Êåá‰ª§ÂæÆË∞É` `Ëá™Âä®ÂåñËØÑ‰º∞` `‰∫∫ÊâçÊãõËÅò` `Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁÆÄÂéÜ‰ø°ÊÅØÊäΩÂèñÊñπÊ≥ïÈöæ‰ª•Â∫îÂØπÁÆÄÂéÜÂ∏ÉÂ±ÄÂíåÂÜÖÂÆπÁöÑÈ´òÂ∫¶ÂºÇÊûÑÊÄßÔºå‰∏î‰æùËµñÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂØºËá¥ÊàêÊú¨È´òÊòÇÂíåÂª∂ËøüÂ§ß„ÄÇ
2. ËØ•ËÆ∫ÊñáÊèêÂá∫‰∏Ä‰∏™Â∏ÉÂ±ÄÊÑüÁü•ÂíåÊïàÁéá‰ºòÂåñÁöÑÊ°ÜÊû∂ÔºåÂà©Áî®Â∏ÉÂ±ÄËß£ÊûêÂô®ËßÑËåÉÊñáÊ°£Ê†ºÂºèÔºåÂπ∂ÈááÁî®Âπ∂Ë°åÊèêÁ§∫ÂíåÊåá‰ª§ÂæÆË∞ÉÊù•ÊèêÂçáLLMÊïàÁéá„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•Ê°ÜÊû∂Âú®ÂáÜÁ°ÆÊÄßÂíåÊïàÁéá‰∏äÂùá‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÂπ∂‰∏î‰∏Ä‰∏™ÂæÆË∞ÉÁöÑ0.6B LLMÂÆûÁé∞‰∫ÜÈ´òÊÄßËÉΩÂíå‰ΩéÂª∂Ëøü„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂ∏ÉÂ±ÄÊÑüÁü•‰∏îÊïàÁéá‰ºòÂåñÁöÑÊ°ÜÊû∂ÔºåÁî®‰∫éËá™Âä®ÁÆÄÂéÜ‰ø°ÊÅØÊäΩÂèñÂíåËØÑ‰º∞ÔºåÊó®Âú®Ëß£ÂÜ≥ÂÆûÈôÖÈÉ®ÁΩ≤‰∏≠ÁÆÄÂéÜÂ∏ÉÂ±ÄÂíåÂÜÖÂÆπÁöÑÂ§öÊ†∑ÊÄß„ÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑÈ´òÊàêÊú¨ÂíåÂª∂Ëøü‰ª•ÂèäÁº∫‰πèÊ†áÂáÜÂåñÊï∞ÊçÆÈõÜÂíåËØÑ‰º∞Â∑•ÂÖ∑Ëøô‰∏âÂ§ßÊåëÊàò„ÄÇËØ•Á≥ªÁªüÁªìÂêà‰∫ÜÂæÆË∞ÉÁöÑÂ∏ÉÂ±ÄËß£ÊûêÂô®Êù•ËßÑËåÉÂåñ‰∏çÂêåÁöÑÊñáÊ°£Ê†ºÂºèÔºå‰∏Ä‰∏™Âü∫‰∫éÂπ∂Ë°åÊèêÁ§∫ÂíåÊåá‰ª§ÂæÆË∞ÉÁöÑÈ´òÊïàLLMÊäΩÂèñÂô®Ôºå‰ª•Âèä‰∏Ä‰∏™Áî±Êñ∞Âü∫ÂáÜÊï∞ÊçÆÈõÜÊîØÊåÅÁöÑÁ®≥ÂÅ•ÁöÑ‰∏§Èò∂ÊÆµËá™Âä®ËØÑ‰º∞Ê°ÜÊû∂„ÄÇÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåËØ•Ê°ÜÊû∂Âú®ÂáÜÁ°ÆÊÄßÂíåÊïàÁéáÊñπÈù¢ÂùáÊòæËëó‰ºò‰∫éÂº∫Â§ßÁöÑÂü∫Á∫øÊ®°Âûã„ÄÇÁâπÂà´Âú∞ÔºåÂÆûÈ™åËØÅÊòéÔºå‰∏Ä‰∏™ÂæÆË∞ÉÁöÑÁ¥ßÂáëÂûã0.6B LLMÂú®ÂÆûÁé∞È°∂Á∫ßÂáÜÁ°ÆÁéáÁöÑÂêåÊó∂ÔºåÊòæËëóÈôç‰Ωé‰∫ÜÊé®ÁêÜÂª∂ËøüÂíåËÆ°ÁÆóÊàêÊú¨„ÄÇËØ•Á≥ªÁªüÂ∑≤ÂÆåÂÖ®ÈÉ®ÁΩ≤Âú®ÈòøÈáåÂ∑¥Â∑¥ÁöÑÊô∫ËÉΩ‰∫∫ÂäõËµÑÊ∫êÂπ≥Âè∞‰∏≠ÔºåÊîØÊåÅÂÖ∂‰∏öÂä°ÈÉ®Èó®ÁöÑÂÆûÊó∂Â∫îÁî®„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁÆÄÂéÜ‰ø°ÊÅØËá™Âä®ÊäΩÂèñÈù¢‰∏¥‰∏âÂ§ßÊåëÊàòÔºö‰∏ÄÊòØÁÆÄÂéÜÂ∏ÉÂ±ÄÂíåÂÜÖÂÆπÊûÅÁ´ØÂ§öÊ†∑ÂåñÔºå‰∫åÊòØÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÊàêÊú¨È´ò„ÄÅÂª∂ËøüÂ§ßÔºå‰∏âÊòØÁº∫‰πèÊ†áÂáÜÂåñÁöÑÊï∞ÊçÆÈõÜÂíåËØÑ‰º∞Â∑•ÂÖ∑„ÄÇÁé∞ÊúâÊñπÊ≥ïÈöæ‰ª•ÂêåÊó∂ÂÖºÈ°æÂáÜÁ°ÆÊÄß„ÄÅÊïàÁéáÂíåÊ≥õÂåñËÉΩÂäõÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§ÑÁêÜÂ§çÊùÇÂ∏ÉÂ±ÄÁöÑÁÆÄÂéÜÊó∂Ë°®Áé∞‰∏ç‰Ω≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËØ•ËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÁªìÂêàÂ∏ÉÂ±Ä‰ø°ÊÅØÂíåÈ´òÊïàLLMÔºåÈÄöËøáÂ∏ÉÂ±ÄËß£ÊûêÂô®È¢ÑÂ§ÑÁêÜÁÆÄÂéÜÔºåËßÑËåÉÂåñÊñáÊ°£Ê†ºÂºèÔºåÁÑ∂ÂêéÂà©Áî®Êåá‰ª§ÂæÆË∞ÉÁöÑÂ∞èÂûãLLMËøõË°å‰ø°ÊÅØÊäΩÂèñ„ÄÇËøôÁßçÊñπÊ≥ïÊó®Âú®Èôç‰ΩéLLMÁöÑËÆ°ÁÆóÊàêÊú¨ÂíåÂª∂ËøüÔºåÂêåÊó∂ÊèêÈ´ò‰ø°ÊÅØÊäΩÂèñÁöÑÂáÜÁ°ÆÊÄßÂíåÈ≤ÅÊ£íÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•Ê°ÜÊû∂ÂåÖÂê´‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) Â∏ÉÂ±ÄËß£ÊûêÂô®ÔºöÁî®‰∫éËß£ÊûêÁÆÄÂéÜÁöÑÂ∏ÉÂ±ÄÁªìÊûÑÔºåÂ∞Ü‰∏çÂêåÊ†ºÂºèÁöÑÁÆÄÂéÜËΩ¨Êç¢‰∏∫Áªü‰∏ÄÁöÑË°®Á§∫Ôºõ2) LLMÊäΩÂèñÂô®ÔºöÂü∫‰∫éÂπ∂Ë°åÊèêÁ§∫ÂíåÊåá‰ª§ÂæÆË∞ÉÔºåÂà©Áî®Â∞èÂûãLLMËøõË°å‰ø°ÊÅØÊäΩÂèñÔºõ3) Ëá™Âä®ËØÑ‰º∞Ê°ÜÊû∂Ôºö‰∏Ä‰∏™‰∏§Èò∂ÊÆµÁöÑËØÑ‰º∞ÊµÅÁ®ãÔºåÁî®‰∫éËØÑ‰º∞‰ø°ÊÅØÊäΩÂèñÁöÑÂáÜÁ°ÆÊÄß„ÄÇÊï¥‰ΩìÊµÅÁ®ãÊòØÂÖàÈÄöËøáÂ∏ÉÂ±ÄËß£ÊûêÂô®Â§ÑÁêÜÁÆÄÂéÜÔºåÁÑ∂ÂêéÂ∞ÜËß£ÊûêÂêéÁöÑÁªìÊûúËæìÂÖ•Âà∞LLMÊäΩÂèñÂô®‰∏≠ÔºåÊúÄÂêé‰ΩøÁî®Ëá™Âä®ËØÑ‰º∞Ê°ÜÊû∂ËØÑ‰º∞ÊäΩÂèñÁªìÊûú„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜÂ∏ÉÂ±Ä‰ø°ÊÅØËûçÂÖ•Âà∞LLMÁöÑ‰ø°ÊÅØÊäΩÂèñËøáÁ®ã‰∏≠ÔºåÂπ∂ÈááÁî®Âπ∂Ë°åÊèêÁ§∫ÂíåÊåá‰ª§ÂæÆË∞ÉÊù•ÊèêÈ´òLLMÁöÑÊïàÁéá„ÄÇ‰∏é‰º†ÁªüÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÊõ¥Â•ΩÂú∞Â§ÑÁêÜÂ§çÊùÇÂ∏ÉÂ±ÄÁöÑÁÆÄÂéÜÔºåÂπ∂Èôç‰ΩéLLMÁöÑËÆ°ÁÆóÊàêÊú¨ÂíåÂª∂Ëøü„ÄÇÊ≠§Â§ñÔºåËØ•ËÆ∫ÊñáËøòÊûÑÂª∫‰∫ÜÊñ∞ÁöÑÂü∫ÂáÜÊï∞ÊçÆÈõÜÔºåÂπ∂ÊèêÂá∫‰∫Ü‰∏Ä‰∏™‰∏§Èò∂ÊÆµÁöÑËá™Âä®ËØÑ‰º∞Ê°ÜÊû∂„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂ∏ÉÂ±ÄËß£ÊûêÂô®ÈááÁî®ÂæÆË∞ÉÁöÑÁé∞ÊúâÊ®°ÂûãÔºåÂÖ∑‰ΩìÊ®°ÂûãÊú™Áü•„ÄÇLLMÊäΩÂèñÂô®‰ΩøÁî®‰∏Ä‰∏™0.6BÁöÑÁ¥ßÂáëÂûãLLMÔºåÂπ∂ÈÄöËøáÊåá‰ª§ÂæÆË∞ÉÊù•ÊèêÈ´òÂÖ∂‰ø°ÊÅØÊäΩÂèñËÉΩÂäõ„ÄÇÂπ∂Ë°åÊèêÁ§∫ÁöÑÂÖ∑‰ΩìÂÆûÁé∞ÊñπÂºèÊú™Áü•Ôºå‰ΩÜÂÖ∂ÁõÆÁöÑÊòØÊèêÈ´òLLMÁöÑÊé®ÁêÜÊïàÁéá„ÄÇËá™Âä®ËØÑ‰º∞Ê°ÜÊû∂ÂåÖÂê´‰∏§‰∏™Èò∂ÊÆµÔºåÂÖ∑‰ΩìËØÑ‰º∞ÊåáÊ†áÊú™Áü•Ôºå‰ΩÜÊó®Âú®ÂÖ®Èù¢ËØÑ‰º∞‰ø°ÊÅØÊäΩÂèñÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•Ê°ÜÊû∂Âú®ÂáÜÁ°ÆÊÄßÂíåÊïàÁéáÊñπÈù¢ÂùáÊòæËëó‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇÁâπÂà´Âú∞Ôºå‰∏Ä‰∏™ÂæÆË∞ÉÁöÑ0.6B LLMÂú®ÂÆûÁé∞È°∂Á∫ßÂáÜÁ°ÆÁéáÁöÑÂêåÊó∂ÔºåÊòæËëóÈôç‰Ωé‰∫ÜÊé®ÁêÜÂª∂ËøüÂíåËÆ°ÁÆóÊàêÊú¨„ÄÇÂÖ∑‰ΩìÊÄßËÉΩÊï∞ÊçÆÂíåÂØπÊØîÂü∫Á∫øÊú™Áü•Ôºå‰ΩÜÊï¥‰ΩìÊèêÂçáÊïàÊûúÊòæËëó„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂπøÊ≥õÂ∫îÁî®‰∫éÊô∫ËÉΩÊãõËÅò„ÄÅ‰∫∫ÊâçÁÆ°ÁêÜ„ÄÅ‰∫∫ÂäõËµÑÊ∫êËá™Âä®ÂåñÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáËá™Âä®ÊèêÂèñÂíåËØÑ‰º∞ÁÆÄÂéÜ‰ø°ÊÅØÔºåÂèØ‰ª•ÊòæËëóÊèêÈ´òÊãõËÅòÊïàÁéáÔºåÈôç‰ΩéÊãõËÅòÊàêÊú¨ÔºåÂπ∂‰∏∫‰ºÅ‰∏öÊèê‰æõÊõ¥ÂÖ®Èù¢ÁöÑ‰∫∫ÊâçÁîªÂÉè„ÄÇËØ•ÊäÄÊúØËøòÂèØÂ∫îÁî®‰∫éÂÖ∂‰ªñÊñáÊ°£‰ø°ÊÅØÊäΩÂèñÂú∫ÊôØÔºå‰æãÂ¶ÇÂêàÂêå„ÄÅÊä•ÂëäÁ≠â„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Automated resume information extraction is critical for scaling talent acquisition, yet its real-world deployment faces three major challenges: the extreme heterogeneity of resume layouts and content, the high cost and latency of large language models (LLMs), and the lack of standardized datasets and evaluation tools. In this work, we present a layout-aware and efficiency-optimized framework for automated extraction and evaluation that addresses all three challenges. Our system combines a fine-tuned layout parser to normalize diverse document formats, an inference-efficient LLM extractor based on parallel prompting and instruction tuning, and a robust two-stage automated evaluation framework supported by new benchmark datasets. Extensive experiments show that our framework significantly outperforms strong baselines in both accuracy and efficiency. In particular, we demonstrate that a fine-tuned compact 0.6B LLM achieves top-tier accuracy while significantly reducing inference latency and computational cost. The system is fully deployed in Alibaba's intelligent HR platform, supporting real-time applications across its business units.

