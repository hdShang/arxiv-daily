---
layout: default
title: On Epistemic Uncertainty of Visual Tokens for Object Hallucinations in Large Vision-Language Models
---

# On Epistemic Uncertainty of Visual Tokens for Object Hallucinations in Large Vision-Language Models

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.09008" target="_blank" class="toolbar-btn">arXiv: 2510.09008v1</a>
    <a href="https://arxiv.org/pdf/2510.09008.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.09008v1" 
            onclick="toggleFavorite(this, '2510.09008v1', 'On Epistemic Uncertainty of Visual Tokens for Object Hallucinations in Large Vision-Language Models')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Hoigi Seo, Dong Un Kang, Hyunjin Cho, Joohoon Lee, Se Young Chun

**ÂàÜÁ±ª**: cs.CV, cs.AI, cs.CL

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-10

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÈíàÂØπÂ§ßËßÜËßâËØ≠Ë®ÄÊ®°Âûã‰∏≠ÁöÑÂØπË±°ÂπªËßâÔºåÊèêÂá∫Âü∫‰∫éËßÜËßâtokenËÆ§Áü•‰∏çÁ°ÆÂÆöÊÄßÁöÑÁºìËß£ÊñπÊ≥ï**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâËØ≠Ë®ÄÊ®°Âûã` `ÂØπË±°ÂπªËßâ` `ËÆ§Áü•‰∏çÁ°ÆÂÆöÊÄß` `ÂØπÊäóÊâ∞Âä®` `ËßÜËßâÁºñÁ†ÅÂô®`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. LVLMÂ≠òÂú®ÂØπË±°ÂπªËßâÈóÆÈ¢òÔºåÂç≥ÁîüÊàêÂõæÂÉè‰∏≠‰∏çÂ≠òÂú®ÂØπË±°ÁöÑÊèèËø∞ÔºåÂΩ±ÂìçÊ®°ÂûãÂèØÈù†ÊÄß„ÄÇ
2. ÈÄöËøáËØÜÂà´Âπ∂Â±èËîΩËßÜËßâÁºñÁ†ÅÂô®‰∏≠ÂÖ∑ÊúâÈ´òËÆ§Áü•‰∏çÁ°ÆÂÆöÊÄßÁöÑËßÜËßâtokenÊù•ÁºìËß£ÂØπË±°ÂπªËßâ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåËØ•ÊñπÊ≥ïËÉΩÊúâÊïàÂáèÂ∞ëÂØπË±°ÂπªËßâÔºåÂπ∂ÂèØ‰∏éÂÖ∂‰ªñÊñπÊ≥ïÁªìÂêàËøõ‰∏ÄÊ≠•ÊèêÂçáÊÄßËÉΩ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§ßÂûãËßÜËßâËØ≠Ë®ÄÊ®°Âûã(LVLMs)ÈõÜÊàê‰∫ÜËßÜËßâÁºñÁ†ÅÂô®(VE)ÂíåÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºåÂú®ÂêÑÁßç‰ªªÂä°‰∏≠ÂèñÂæó‰∫ÜÊòæËëóÊàêÂäü„ÄÇÁÑ∂ËÄåÔºåLVLMs‰ªçÁÑ∂Èù¢‰∏¥ÁùÄÂØπË±°ÂπªËßâÁ≠âÂÖ≥ÈîÆÊåëÊàòÔºåÂç≥ÁîüÊàêËæìÂÖ•ÂõæÂÉè‰∏≠‰∏çÂ≠òÂú®ÁöÑÂØπË±°ÁöÑÊèèËø∞„ÄÇÊú¨ÊñáËÆ§‰∏∫ÔºåVE‰∏≠‰∏çÁ°ÆÂÆöÁöÑËßÜËßâtokenÊòØÂØºËá¥ÂØπË±°ÂπªËßâÁöÑÂÖ≥ÈîÆÂõ†Á¥†„ÄÇÁªüËÆ°ÂàÜÊûêË°®ÊòéÔºåÂÖ∑ÊúâÈ´òËÆ§Áü•‰∏çÁ°ÆÂÆöÊÄßÁöÑËßÜËßâtoken‰∏éÂπªËßâÁöÑÂèëÁîü‰πãÈó¥Â≠òÂú®Ê≠£Áõ∏ÂÖ≥ÂÖ≥Á≥ª„ÄÇÊ≠§Â§ñÔºåÁêÜËÆ∫ÂíåÂÆûÈ™åË°®ÊòéÔºåÊó©ÊúüVEÂ±Ç‰∏≠Âú®Â∞èÁöÑÂØπÊäóÊâ∞Âä®‰∏ãË°®Áé∞Âá∫ËæÉÂ§ßË°®ÂæÅÂÅèÂ∑ÆÁöÑËßÜËßâtokenÂÖ∑ÊúâËæÉÈ´òÁöÑËÆ§Áü•‰∏çÁ°ÆÂÆöÊÄß„ÄÇÂü∫‰∫éËøô‰∫õÂèëÁé∞ÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÁÆÄÂçïËÄåÊúâÊïàÁöÑÁ≠ñÁï•Ôºå‰ªÖÈÄöËøá‰øÆÊîπVEÊù•ÁºìËß£ÂØπË±°ÂπªËßâ„ÄÇËØ•ÊñπÊ≥ïÂåÖÊã¨‰∏Ä‰∏™‰ΩøÁî®ÂØπÊäóÊâ∞Âä®ÁöÑ‰ª£ÁêÜÊñπÊ≥ïÔºåÁî®‰∫éÊúâÊïàÂú∞ËØÜÂà´‰∏çÁ°ÆÂÆöÁöÑËßÜËßâtokenÔºå‰ª•Âèä‰∏ÄÁßçÂú®VE‰∏≠Èó¥Â±ÇÁöÑËá™Ê≥®ÊÑèÂäõËøáÁ®ã‰∏≠Â±èËîΩËøô‰∫õ‰∏çÁ°ÆÂÆöËßÜËßâtokenÁöÑÊñπÊ≥ïÔºå‰ªéËÄåÊäëÂà∂ÂÆÉ‰ª¨ÂØπËßÜËßâÁºñÁ†ÅÁöÑÂΩ±ÂìçÔºåËøõËÄåÂáèËΩªÂπªËßâ„ÄÇÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåËØ•ÊñπÊ≥ïÊòæËëóÂáèÂ∞ë‰∫ÜLVLMs‰∏≠ÁöÑÂØπË±°ÂπªËßâÔºåÂπ∂‰∏îÂèØ‰ª•‰∏éÂÖ∂‰ªñÁé∞ÊúâÊäÄÊúØÂçèÂêåÂ∑•‰Ωú„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöLVLMÂú®ÁîüÊàêÂõæÂÉèÊèèËø∞Êó∂Ôºå‰ºö‰∫ßÁîüÂõæÂÉè‰∏≠‰∏çÂ≠òÂú®ÁöÑÂØπË±°ÁöÑÊèèËø∞ÔºåÂç≥ÂØπË±°ÂπªËßâ„ÄÇÁé∞ÊúâÊñπÊ≥ïÊú™ËÉΩÊúâÊïàËß£ÂÜ≥ËßÜËßâÁºñÁ†ÅÂô®‰∏≠‰∏çÁ°ÆÂÆöËßÜËßâtokenÂØºËá¥ÁöÑÂπªËßâÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÔºåÈÄöËøáËØÜÂà´ËßÜËßâÁºñÁ†ÅÂô®‰∏≠ÂÖ∑ÊúâÈ´òËÆ§Áü•‰∏çÁ°ÆÂÆöÊÄßÁöÑËßÜËßâtokenÔºåÂπ∂Âú®ËßÜËßâÁºñÁ†ÅËøáÁ®ã‰∏≠Â±èËîΩËøô‰∫õtokenÔºå‰ªéËÄåÊäëÂà∂ÂÆÉ‰ª¨ÂØπÊúÄÁªàÁîüÊàêÁªìÊûúÁöÑÂΩ±ÂìçÔºåËøõËÄåÁºìËß£ÂØπË±°ÂπªËßâ„ÄÇËøôÁßçÊñπÊ≥ïÂü∫‰∫é‰∏Ä‰∏™ÂÅáËÆæÔºö‰∏çÁ°ÆÂÆöÁöÑËßÜËßâtokenÊòØÂØºËá¥ÂØπË±°ÂπªËßâÁöÑÂÖ≥ÈîÆÂõ†Á¥†„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•ÊñπÊ≥ï‰∏ªË¶ÅÂåÖÂê´‰∏§‰∏™Èò∂ÊÆµÔºö1) ‰ΩøÁî®ÂØπÊäóÊâ∞Âä®ËØÜÂà´‰∏çÁ°ÆÂÆöÁöÑËßÜËßâtoken„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÈÄöËøáÂØπËæìÂÖ•ÂõæÂÉèÊ∑ªÂä†Â∞èÁöÑÂØπÊäóÊâ∞Âä®ÔºåËßÇÂØüËßÜËßâÁºñÁ†ÅÂô®‰∏≠ÂêÑ‰∏™tokenÁöÑË°®ÂæÅÂèòÂåñ„ÄÇË°®ÂæÅÂèòÂåñÂ§ßÁöÑtokenË¢´ËÆ§‰∏∫ÊòØÂÖ∑ÊúâÈ´òËÆ§Áü•‰∏çÁ°ÆÂÆöÊÄßÁöÑtoken„ÄÇ2) Âú®ËßÜËßâÁºñÁ†ÅÂô®ÁöÑ‰∏≠Èó¥Â±ÇÔºåÈÄöËøámaskingÊú∫Âà∂Â±èËîΩËøô‰∫õ‰∏çÁ°ÆÂÆöÁöÑËßÜËßâtokenÔºå‰ªéËÄåÈôç‰ΩéÂÆÉ‰ª¨ÂØπÂêéÁª≠ËßÜËßâÁºñÁ†ÅÁöÑÂΩ±Âìç„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ÊñπÊ≥ïÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºåÂÆÉÂ∞ÜÂØπË±°ÂπªËßâÈóÆÈ¢ò‰∏éËßÜËßâtokenÁöÑËÆ§Áü•‰∏çÁ°ÆÂÆöÊÄßËÅîÁ≥ªËµ∑Êù•ÔºåÂπ∂ÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÂØπÊäóÊâ∞Âä®ÁöÑ‰ª£ÁêÜÊñπÊ≥ïÊù•È´òÊïàÂú∞ËØÜÂà´Ëøô‰∫õ‰∏çÁ°ÆÂÆöÁöÑtoken„ÄÇ‰∏é‰ª•ÂæÄÊñπÊ≥ï‰∏çÂêåÔºåËØ•ÊñπÊ≥ïÁõ¥Êé•ÈíàÂØπËßÜËßâÁºñÁ†ÅÂô®ËøõË°å‰øÆÊîπÔºåËÄåÊó†ÈúÄ‰øÆÊîπËØ≠Ë®ÄÊ®°Âûã„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**Ôºö1) ‰ΩøÁî®ÂØπÊäóÊâ∞Âä®Êù•‰º∞ËÆ°ËßÜËßâtokenÁöÑËÆ§Áü•‰∏çÁ°ÆÂÆöÊÄß„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÈÄöËøáËÆ°ÁÆóÂéüÂßãÂõæÂÉèÂíåÂØπÊäóÊâ∞Âä®ÂõæÂÉèÁöÑËßÜËßâtokenË°®ÂæÅ‰πãÈó¥ÁöÑÂ∑ÆÂºÇÊù•Ë°°Èáè‰∏çÁ°ÆÂÆöÊÄß„ÄÇ2) Âú®ËßÜËßâÁºñÁ†ÅÂô®ÁöÑ‰∏≠Èó¥Â±ÇÂ∫îÁî®maskingÊú∫Âà∂„ÄÇÈÄâÊã©‰∏≠Èó¥Â±ÇÊòØÂõ†‰∏∫Êó©ÊúüÂ±ÇÂèØËÉΩÂåÖÂê´Ëøá‰∫éÂ∫ïÂ±ÇÁöÑÁâπÂæÅÔºåËÄåÂêéÊúüÂ±ÇÂèØËÉΩÂ∑≤ÁªèÂèóÂà∞‰∫Ü‰∏çÁ°ÆÂÆötokenÁöÑÂΩ±Âìç„ÄÇ3) ÂØπÊäóÊâ∞Âä®ÁöÑÂπÖÂ∫¶ÊòØ‰∏Ä‰∏™ÈáçË¶ÅÁöÑË∂ÖÂèÇÊï∞ÔºåÈúÄË¶ÅÊ†πÊçÆÂÖ∑‰Ωì‰ªªÂä°ËøõË°åË∞ÉÊï¥„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÊòæËëóÂáèÂ∞ëLVLM‰∏≠ÁöÑÂØπË±°ÂπªËßâ„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåÂú®Â§ö‰∏™Âü∫ÂáÜÊï∞ÊçÆÈõÜ‰∏äÔºåËØ•ÊñπÊ≥ïÂú®Èôç‰ΩéÂπªËßâÁéáÊñπÈù¢ÂèñÂæó‰∫ÜÊòæËëóÊèêÂçáÔºåÂπ∂‰∏îÂèØ‰ª•‰∏éÂÖ∂‰ªñÁé∞ÊúâÊäÄÊúØÂçèÂêåÂ∑•‰ΩúÔºåËøõ‰∏ÄÊ≠•ÊèêÂçáÊÄßËÉΩ„ÄÇÂÆûÈ™åËøòÈ™åËØÅ‰∫ÜÂØπÊäóÊâ∞Âä®‰Ωú‰∏∫ËÆ§Áü•‰∏çÁ°ÆÂÆöÊÄß‰ª£ÁêÜÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊèêÂçáËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÁöÑÂèØÈù†ÊÄßÂíåÂèØ‰ø°Â∫¶ÔºåÂ∞§ÂÖ∂ÊòØÂú®ÈúÄË¶ÅÁ≤æÁ°ÆÂõæÂÉèÁêÜËß£ÂíåÊèèËø∞ÁöÑÂú∫ÊôØ‰∏≠Ôºå‰æãÂ¶ÇÂåªÁñóÂΩ±ÂÉèËØäÊñ≠„ÄÅËá™Âä®È©æÈ©∂„ÄÅÊô∫ËÉΩÁõëÊéßÁ≠â„ÄÇÈÄöËøáÂáèÂ∞ëÂØπË±°ÂπªËßâÔºåÂèØ‰ª•ÊèêÈ´òÊ®°ÂûãÂú®Ëøô‰∫õÂÖ≥ÈîÆÂ∫îÁî®‰∏≠ÁöÑÂÆûÁî®‰ª∑ÂÄº„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Large vision-language models (LVLMs), which integrate a vision encoder (VE) with a large language model, have achieved remarkable success across various tasks. However, there are still crucial challenges in LVLMs such as object hallucination, generating descriptions of objects that are not in the input image. Here, we argue that uncertain visual tokens within the VE is a key factor that contributes to object hallucination. Our statistical analysis found that there are positive correlations between visual tokens with high epistemic uncertainty and the occurrence of hallucinations. Furthermore, we show theoretically and empirically that visual tokens in early VE layers that exhibit large representation deviations under small adversarial perturbations indicate high epistemic uncertainty. Based on these findings, we propose a simple yet effective strategy to mitigate object hallucination by modifying the VE only. Our method comprises a proxy method with adversarial perturbations for identifying uncertain visual tokens efficiently and a method to mask these uncertain visual tokens during the self-attention process in the middle layers of the VE, suppressing their influence on visual encoding and thus alleviating hallucinations. Extensive experiments show that our method significantly reduces object hallucinations in LVLMs and can synergistically work with other prior arts.

