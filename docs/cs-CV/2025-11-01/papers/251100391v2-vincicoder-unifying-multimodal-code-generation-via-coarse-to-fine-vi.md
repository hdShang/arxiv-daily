---
layout: default
title: VinciCoder: Unifying Multimodal Code Generation via Coarse-to-fine Visual Reinforcement Learning
---

# VinciCoder: Unifying Multimodal Code Generation via Coarse-to-fine Visual Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.00391" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.00391v2</a>
  <a href="https://arxiv.org/pdf/2511.00391.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.00391v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.00391v2', 'VinciCoder: Unifying Multimodal Code Generation via Coarse-to-fine Visual Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xuanle Zhao, Deyang Jiang, Zhixiong Zeng, Lei Chen, Haibo Qiu, Jing Huang, Yufeng Zhong, Liming Zheng, Yilin Cao, Lin Ma

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-01 (æ›´æ–°: 2025-11-27)

**å¤‡æ³¨**: 15 pages, 11 figures

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/DocTron-hub/VinciCoder)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**VinciCoderï¼šé€šè¿‡ç²—åˆ°ç»†è§†è§‰å¼ºåŒ–å­¦ä¹ ç»Ÿä¸€å¤šæ¨¡æ€ä»£ç ç”Ÿæˆ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¤šæ¨¡æ€ä»£ç ç”Ÿæˆ` `è§†è§‰å¼ºåŒ–å­¦ä¹ ` `ç²—åˆ°ç»†å­¦ä¹ ` `è§†è§‰-è¯­è¨€æ¨¡å‹` `ä»£ç æ™ºèƒ½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨å¤šæ¨¡æ€ä»£ç ç”Ÿæˆä¸­ä¾èµ–å•ä»»åŠ¡è®­ç»ƒï¼Œç¼ºä¹é€šç”¨è§†è§‰ä»£ç æ™ºèƒ½ã€‚
2. VinciCoderé€šè¿‡ä¸¤é˜¶æ®µè®­ç»ƒæ¡†æ¶ï¼Œç»“åˆç›‘ç£å¾®è°ƒå’Œç²—åˆ°ç»†çš„è§†è§‰å¼ºåŒ–å­¦ä¹ æ¥æå‡æ€§èƒ½ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒVinciCoderåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†ç°æœ‰å¼€æºæ¨¡å‹ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€ä»£ç ç”Ÿæˆå·²å¼•èµ·ç ”ç©¶ç•Œçš„å¹¿æ³›å…³æ³¨ã€‚å°½ç®¡æœ€è¿‘çš„è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨è¯¸å¦‚å›¾è¡¨åˆ°ä»£ç ç”Ÿæˆç­‰ç‰¹å®šä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—æˆåŠŸï¼Œä½†å®ƒä»¬å¯¹å•ä»»åŠ¡è®­ç»ƒæ–¹æ¡ˆçš„ä¾èµ–é˜»ç¢äº†é€šç”¨è§†è§‰ä»£ç æ™ºèƒ½çš„å‘å±•ã€‚æœ¬æ–‡æå‡ºäº†VinciCoderï¼Œä¸€ä¸ªç»Ÿä¸€çš„å¤šæ¨¡æ€ä»£ç ç”Ÿæˆæ¨¡å‹ï¼Œé€šè¿‡ä¸¤é˜¶æ®µè®­ç»ƒæ¡†æ¶è§£å†³äº†è¿™ä¸€é™åˆ¶ã€‚é¦–å…ˆï¼Œæ„å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡çš„ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰è¯­æ–™åº“ï¼ŒåŒ…å«160ä¸‡ä¸ªå›¾åƒ-ä»£ç å¯¹ï¼Œç”¨äºç›´æ¥ä»£ç ç”Ÿæˆå’ŒåŸºäºè§†è§‰çš„ä»£ç æ”¹è¿›ä»»åŠ¡ã€‚å…¶æ¬¡ï¼Œå¼•å…¥äº†ä¸€ç§è§†è§‰å¼ºåŒ–å­¦ä¹ ï¼ˆViRLï¼‰ç­–ç•¥ï¼Œè¯¥ç­–ç•¥é‡‡ç”¨ç²—åˆ°ç»†çš„å¥–åŠ±æœºåˆ¶ï¼Œé€šè¿‡è®¡ç®—å±€éƒ¨å’Œå…¨å±€å›¾åƒå—ä¹‹é—´çš„è§†è§‰ç›¸ä¼¼æ€§æ¥æé«˜è§†è§‰ä¿çœŸåº¦ã€‚åœ¨å„ç§å¤šæ¨¡æ€ä»£ç ç”ŸæˆåŸºå‡†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒVinciCoderå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè¶…è¶Šäº†æœ€è¿‘çš„å¼€æºæ¨¡å‹ã€‚æ¶ˆèç ”ç©¶è¿›ä¸€æ­¥éªŒè¯äº†æˆ‘ä»¬æå‡ºçš„ç²—åˆ°ç»†ViRLç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚æ•°æ®ã€ä»£ç å’Œæ¨¡å‹å¯åœ¨https://github.com/DocTron-hub/VinciCoderè·å–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€ä»£ç ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œç°æœ‰è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰æ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸é’ˆå¯¹ç‰¹å®šä»»åŠ¡è¿›è¡Œè®­ç»ƒï¼Œç¼ºä¹åœ¨ä¸åŒè§†è§‰è¾“å…¥å’Œä»£ç ç”Ÿæˆä»»åŠ¡ä¹‹é—´çš„è¿ç§»èƒ½åŠ›ï¼Œé™åˆ¶äº†å…¶é€šç”¨æ€§å’Œå®ç”¨æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šVinciCoderçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ä¸€ä¸ªç»Ÿä¸€çš„æ¨¡å‹æ¡†æ¶ï¼Œç»“åˆç›‘ç£å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ï¼Œæå‡æ¨¡å‹åœ¨ä¸åŒå¤šæ¨¡æ€ä»£ç ç”Ÿæˆä»»åŠ¡ä¸Šçš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚é€šè¿‡ç²—åˆ°ç»†çš„è§†è§‰å¼ºåŒ–å­¦ä¹ ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å›¾åƒå†…å®¹ï¼Œå¹¶ç”Ÿæˆä¸ä¹‹å¯¹åº”çš„ä»£ç ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVinciCoderçš„è®­ç»ƒæ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼š1) ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ï¼šä½¿ç”¨å¤§è§„æ¨¡å›¾åƒ-ä»£ç å¯¹æ•°æ®é›†å¯¹æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒï¼Œä½¿å…¶å…·å¤‡åˆæ­¥çš„ä»£ç ç”Ÿæˆèƒ½åŠ›ã€‚2) è§†è§‰å¼ºåŒ–å­¦ä¹ ï¼ˆViRLï¼‰ï¼šåˆ©ç”¨å¼ºåŒ–å­¦ä¹ ç­–ç•¥ï¼Œé€šè¿‡å¥–åŠ±æœºåˆ¶å¼•å¯¼æ¨¡å‹ç”Ÿæˆæ›´ç¬¦åˆè§†è§‰ä¿¡æ¯çš„ä»£ç ã€‚ViRLé‡‡ç”¨ç²—åˆ°ç»†çš„å¥–åŠ±æœºåˆ¶ï¼Œåˆ†åˆ«ä»å…¨å±€å’Œå±€éƒ¨å›¾åƒå—çš„è§†è§‰ç›¸ä¼¼æ€§æ¥è¯„ä¼°ç”Ÿæˆä»£ç çš„è´¨é‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šVinciCoderçš„å…³é”®åˆ›æ–°åœ¨äºå…¶ç²—åˆ°ç»†çš„è§†è§‰å¼ºåŒ–å­¦ä¹ ï¼ˆViRLï¼‰ç­–ç•¥ã€‚ä¼ ç»Ÿçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•é€šå¸¸åªå…³æ³¨æ•´ä½“çš„å¥–åŠ±ï¼Œè€Œå¿½ç•¥äº†å›¾åƒçš„å±€éƒ¨ç»†èŠ‚ã€‚VinciCoderé€šè¿‡åˆ†åˆ«è®¡ç®—å…¨å±€å’Œå±€éƒ¨å›¾åƒå—çš„è§†è§‰ç›¸ä¼¼æ€§ï¼Œèƒ½å¤Ÿæ›´ç²¾ç»†åœ°è¯„ä¼°ç”Ÿæˆä»£ç çš„è´¨é‡ï¼Œä»è€Œæé«˜è§†è§‰ä¿çœŸåº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ViRLé˜¶æ®µï¼Œå¥–åŠ±å‡½æ•°çš„è®¾è®¡è‡³å…³é‡è¦ã€‚VinciCoderçš„å¥–åŠ±å‡½æ•°åŒ…å«ä¸¤éƒ¨åˆ†ï¼šå…¨å±€è§†è§‰ç›¸ä¼¼æ€§å¥–åŠ±å’Œå±€éƒ¨è§†è§‰ç›¸ä¼¼æ€§å¥–åŠ±ã€‚å…¨å±€è§†è§‰ç›¸ä¼¼æ€§å¥–åŠ±è¡¡é‡ç”Ÿæˆä»£ç å¯¹åº”çš„å›¾åƒä¸åŸå§‹å›¾åƒçš„æ•´ä½“ç›¸ä¼¼åº¦ï¼Œå±€éƒ¨è§†è§‰ç›¸ä¼¼æ€§å¥–åŠ±åˆ™å…³æ³¨å›¾åƒçš„å±€éƒ¨ç»†èŠ‚ã€‚é€šè¿‡è°ƒæ•´ä¸¤éƒ¨åˆ†å¥–åŠ±çš„æƒé‡ï¼Œå¯ä»¥æ§åˆ¶æ¨¡å‹å¯¹å…¨å±€å’Œå±€éƒ¨ä¿¡æ¯çš„å…³æ³¨ç¨‹åº¦ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„ç»†èŠ‚å’Œå‚æ•°è®¾ç½®åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

VinciCoderåœ¨å¤šä¸ªå¤šæ¨¡æ€ä»£ç ç”ŸæˆåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†state-of-the-artçš„æ€§èƒ½ï¼Œæ˜¾è‘—è¶…è¶Šäº†ç°æœ‰çš„å¼€æºæ¨¡å‹ã€‚æ¶ˆèå®éªŒè¡¨æ˜ï¼Œç²—åˆ°ç»†çš„è§†è§‰å¼ºåŒ–å­¦ä¹ ç­–ç•¥å¯¹æ€§èƒ½æå‡èµ·åˆ°äº†å…³é”®ä½œç”¨ã€‚å…·ä½“æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿å¯åœ¨è®ºæ–‡ä¸­æŸ¥é˜…ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

VinciCoderå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼ŒåŒ…æ‹¬è‡ªåŠ¨åŒ–å›¾è¡¨ç”Ÿæˆã€UIç•Œé¢ä»£ç ç”Ÿæˆã€å›¾åƒæè¿°ç”Ÿæˆä»£ç ç­‰ã€‚è¯¥æŠ€æœ¯å¯ä»¥åº”ç”¨äºè½¯ä»¶å¼€å‘ã€æ•°æ®å¯è§†åŒ–ã€è‡ªåŠ¨åŒ–æŠ¥å‘Šç”Ÿæˆç­‰é¢†åŸŸï¼Œæé«˜å¼€å‘æ•ˆç‡å’Œé™ä½å¼€å‘æˆæœ¬ã€‚æœªæ¥ï¼ŒVinciCoderæœ‰æœ›æˆä¸ºé€šç”¨è§†è§‰ä»£ç æ™ºèƒ½çš„åŸºç¡€æ¨¡å‹ï¼Œèµ‹èƒ½æ›´å¤šæ™ºèƒ½åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal code generation has garnered significant interest within the research community. Despite the notable success of recent vision-language models (VLMs) on specialized tasks like chart-to-code generation, their reliance on single-task training regimens fosters a narrow paradigm that hinders the development of generalized \textbf{VI}sio\textbf{N} \textbf{C}ode \textbf{I}ntelligence. In this work, we introduce \textbf{VinciCoder}, a unified multimodal code generation model that addresses this limitation via a two-stage training framework. We begin by constructing a large-scale Supervised Finetuning (SFT) corpus comprising 1.6M image-code pairs for tasks involving direct code generation and visual-based code refinement. Subsequently, we introduce a Visual Reinforcement Learning (ViRL) strategy, which employs a coarse-to-fine reward mechanism to improve visual fidelity by calculating visual similarity across local and global image patches. Extensive experiments on diverse multimodal code generation benchmarks demonstrate that VinciCoder achieves state-of-the-art performance, surpassing recent open-source models. The ablation study further validates the effectiveness of our proposed coarse-to-fine ViRL strategy. The data, code and model is available at https://github.com/DocTron-hub/VinciCoder.

