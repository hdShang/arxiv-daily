---
layout: default
title: Rethinking Facial Expression Recognition in the Era of Multimodal Large Language Models: Benchmark, Datasets, and Beyond
---

# Rethinking Facial Expression Recognition in the Era of Multimodal Large Language Models: Benchmark, Datasets, and Beyond

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.00389" class="toolbar-btn" target="_blank">üìÑ arXiv: 2511.00389v1</a>
  <a href="https://arxiv.org/pdf/2511.00389.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.00389v1" onclick="toggleFavorite(this, '2511.00389v1', 'Rethinking Facial Expression Recognition in the Era of Multimodal Large Language Models: Benchmark, Datasets, and Beyond')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Fan Zhang, Haoxuan Li, Shengju Qian, Xin Wang, Zheng Lian, Hao Wu, Zhihong Zhu, Yuan Gao, Qiankun Li, Yefeng Zheng, Zhouchen Lin, Pheng-Ann Heng

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-01

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫UniFER-7BÔºåÊèêÂçáÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÂú®Èù¢ÈÉ®Ë°®ÊÉÖËØÜÂà´‰∏≠ÁöÑÊé®ÁêÜÂíåÂèØËß£ÈáäÊÄß„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Èù¢ÈÉ®Ë°®ÊÉÖËØÜÂà´` `Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã` `ËßÜËßâÈóÆÁ≠î` `Âº∫ÂåñÂ≠¶‰π†` `ÊÉÖÊÑüËÆ°ÁÆó` `ÂèØËß£ÈáäÊÄß` `ÂêéËÆ≠ÁªÉÁ≠ñÁï•`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÈù¢ÈÉ®Ë°®ÊÉÖËØÜÂà´ÊñπÊ≥ï‰æùËµñ‰∫éÁâπÂÆöÈ¢ÜÂüüÊ®°ÂûãÔºåÁº∫‰πèÈÄöÁî®ÊÄßÂíåÂèØËß£ÈáäÊÄßÔºå‰∏îÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÂú®FER‰ªªÂä°‰∏äÁöÑÊÄßËÉΩÊúâÂæÖÊé¢Á¥¢„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫UniFER-7BÔºåÈÄöËøáÂ∞ÜFER‰ªªÂä°ËΩ¨Âåñ‰∏∫VQAÂΩ¢ÂºèÔºåÂπ∂Âà©Áî®ÂêéËÆ≠ÁªÉÁ≠ñÁï•ÔºåÊèêÂçáMLLMÂú®Èù¢ÈÉ®Ë°®ÊÉÖÊé®ÁêÜÊñπÈù¢ÁöÑËÉΩÂäõ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåUniFER-7BÂú®Â§ö‰∏™FERÊï∞ÊçÆÈõÜ‰∏ä‰ºò‰∫éËÆ∏Â§öÂºÄÊ∫êÂíåÈó≠Ê∫êÁöÑÈÄöÁî®MLLMÔºåËØÅÊòé‰∫ÜÂÖ∂ÊúâÊïàÊÄßÂíå‰ºòË∂äÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMsÔºâÂ∑≤ÁªèÂΩªÂ∫ïÊîπÂèò‰∫ÜÂåÖÊã¨ËÆ°ÁÆóÊú∫ËßÜËßâÂíåÊÉÖÊÑüËÆ°ÁÆóÂú®ÂÜÖÁöÑ‰ºóÂ§öÁ†îÁ©∂È¢ÜÂüü„ÄÇ‰Ωú‰∏∫ËØ•‰∫§ÂèâÈ¢ÜÂüü‰∏≠ÁöÑ‰∏Ä‰∏™ÂÖ≥ÈîÆÊåëÊàòÔºåÈù¢ÈÉ®Ë°®ÊÉÖËØÜÂà´ÔºàFERÔºâÂ∑≤Áªè‰ªéÂàÜÁ¶ªÁöÑ„ÄÅÁâπÂÆöÈ¢ÜÂüüÁöÑÊ®°ÂûãÂèëÂ±ïÂà∞Êõ¥Áªü‰∏ÄÁöÑÊñπÊ≥ï„ÄÇ‰∏ÄÁßçÁªü‰∏ÄFER‰ªªÂä°ÁöÑÊúâÂ∏åÊúõÁöÑÈÄîÂæÑÊòØÂ∞Ü‰º†ÁªüÁöÑFERÊï∞ÊçÆÈõÜËΩ¨Êç¢‰∏∫ËßÜËßâÈóÆÁ≠îÔºàVQAÔºâÊ†ºÂºèÔºå‰ªéËÄåËÉΩÂ§üÁõ¥Êé•Â∫îÁî®Âº∫Â§ßÁöÑÈÄöÁî®MLLMËøõË°åÊé®ÁêÜ„ÄÇ‰∏∫‰∫ÜÂº•Ë°•MLLMÂú®FER‰ªªÂä°‰∏äÁöÑÊÄßËÉΩÂ∑ÆË∑ùÔºåÊàë‰ª¨Êèê‰æõ‰∫ÜFERBenchÔºåËøôÊòØ‰∏Ä‰∏™Á≥ªÁªüÁöÑÂü∫ÂáÜÔºåÂåÖÂê´‰∫ÜÂõõ‰∏™ÂπøÊ≥õ‰ΩøÁî®ÁöÑFERÊï∞ÊçÆÈõÜ‰∏äÁöÑ20‰∏™ÊúÄÂÖàËøõÁöÑMLLM„ÄÇÁªìÊûúË°®ÊòéÔºåËôΩÁÑ∂MLLMË°®Áé∞Âá∫ËâØÂ•ΩÁöÑÂàÜÁ±ªÊÄßËÉΩÔºå‰ΩÜÂÆÉ‰ª¨Âú®Êé®ÁêÜÂíåÂèØËß£ÈáäÊÄßÊñπÈù¢‰ªçÁÑ∂Èù¢‰∏¥ÈáçÂ§ßÈôêÂà∂„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨ÂºïÂÖ•‰∫ÜÊó®Âú®Â¢ûÂº∫MLLMÁöÑÈù¢ÈÉ®Ë°®ÊÉÖÊé®ÁêÜËÉΩÂäõÁöÑÂêéËÆ≠ÁªÉÁ≠ñÁï•„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨Á≠ñÂàí‰∫Ü‰∏§‰∏™È´òË¥®ÈáèÂíåÂ§ßËßÑÊ®°ÁöÑÊï∞ÊçÆÈõÜÔºöÁî®‰∫éÂÜ∑ÂêØÂä®ÂàùÂßãÂåñÁöÑUniFER-CoT-230KÂíåÁî®‰∫éÂÖ∑ÊúâÂèØÈ™åËØÅÂ•ñÂä±ÁöÑÂº∫ÂåñÂ≠¶‰π†ÔºàRLVRÔºâÁöÑUniFER-RLVR-360K„ÄÇÂú®Ê≠§Âü∫Á°Ä‰∏äÔºåÊàë‰ª¨ÂºÄÂèë‰∫Ü‰∏Ä‰∏™Áªü‰∏Ä‰∏îÂèØËß£ÈáäÁöÑFERÂü∫Á°ÄÊ®°ÂûãÔºåÁß∞‰∏∫UniFER-7BÔºåÂÆÉ‰ºò‰∫éËÆ∏Â§öÂºÄÊ∫êÂíåÈó≠Ê∫êÈÄöÁî®MLLMÔºà‰æãÂ¶ÇÔºåGemini-2.5-ProÂíåQwen2.5-VL-72BÔºâ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMsÔºâÂú®Èù¢ÈÉ®Ë°®ÊÉÖËØÜÂà´ÔºàFERÔºâ‰ªªÂä°‰∏≠Êé®ÁêÜËÉΩÂäõ‰∏çË∂≥ÂíåÂèØËß£ÈáäÊÄßÂ∑ÆÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏ÊòØÈ¢ÜÂüüÁâπÂÆöÁöÑÔºåÊó†Ê≥ïÂÖÖÂàÜÂà©Áî®MLLMsÁöÑÈÄöÁî®ËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåÁº∫‰πè‰∏ìÈó®‰∏∫MLLMsËÆæËÆ°ÁöÑFERÊï∞ÊçÆÈõÜÂíåËÆ≠ÁªÉÁ≠ñÁï•ÔºåÂØºËá¥ÂÖ∂ÊÄßËÉΩÂèóÈôê„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞Ü‰º†ÁªüÁöÑFER‰ªªÂä°ËΩ¨Âåñ‰∏∫ËßÜËßâÈóÆÁ≠îÔºàVQAÔºâÁöÑÂΩ¢ÂºèÔºå‰ªéËÄåËÉΩÂ§üÁõ¥Êé•Âà©Áî®MLLMsËøõË°åÊé®ÁêÜ„ÄÇÈÄöËøáÊûÑÂª∫È´òË¥®ÈáèÁöÑFERÊï∞ÊçÆÈõÜÔºåÂπ∂ÈááÁî®ÂêéËÆ≠ÁªÉÁ≠ñÁï•ÔºåÂ¢ûÂº∫MLLMsÂú®Èù¢ÈÉ®Ë°®ÊÉÖÊé®ÁêÜÊñπÈù¢ÁöÑËÉΩÂäõ„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåÂà©Áî®Chain-of-Thought (CoT) Êï∞ÊçÆÈõÜËøõË°åÂÜ∑ÂêØÂä®ÂàùÂßãÂåñÔºåÂπ∂‰ΩøÁî®Reinforcement Learning with Verifiable Rewards (RLVR) ËøõË°åÂº∫ÂåñÂ≠¶‰π†Ôºå‰ªéËÄåÊèêÂçáÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõÂíåÂèØËß£ÈáäÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöUniFER-7BÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÈò∂ÊÆµÔºö1) Êï∞ÊçÆÈõÜÊûÑÂª∫ÔºöÊûÑÂª∫UniFER-CoT-230KÂíåUniFER-RLVR-360K‰∏§‰∏™Êï∞ÊçÆÈõÜÔºåÂàÜÂà´Áî®‰∫éÂÜ∑ÂêØÂä®ÂàùÂßãÂåñÂíåÂº∫ÂåñÂ≠¶‰π†„ÄÇ2) Ê®°ÂûãÂàùÂßãÂåñÔºö‰ΩøÁî®UniFER-CoT-230KÊï∞ÊçÆÈõÜÂØπMLLMËøõË°åÂÜ∑ÂêØÂä®ÂàùÂßãÂåñ„ÄÇ3) Âº∫ÂåñÂ≠¶‰π†Ôºö‰ΩøÁî®UniFER-RLVR-360KÊï∞ÊçÆÈõÜÔºåÈÄöËøáÂº∫ÂåñÂ≠¶‰π†ÊèêÂçáÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõÂíåÂèØËß£ÈáäÊÄß„ÄÇ4) Ê®°ÂûãËØÑ‰º∞ÔºöÂú®FERBenchÂü∫ÂáÜ‰∏äËØÑ‰º∞UniFER-7BÁöÑÊÄßËÉΩÔºåÂπ∂‰∏éÂÖ∂‰ªñMLLMsËøõË°åÊØîËæÉ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÊèêÂá∫‰∫ÜUniFER-7BÔºåËøôÊòØ‰∏Ä‰∏™Áªü‰∏Ä‰∏îÂèØËß£ÈáäÁöÑFERÂü∫Á°ÄÊ®°Âûã„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåUniFER-7BËÉΩÂ§üÁõ¥Êé•Âà©Áî®MLLMsÁöÑÈÄöÁî®ËÉΩÂäõËøõË°åFER‰ªªÂä°ÔºåÂπ∂ÈÄöËøáÂêéËÆ≠ÁªÉÁ≠ñÁï•ÊòæËëóÊèêÂçá‰∫ÜÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõÂíåÂèØËß£ÈáäÊÄß„ÄÇÊ≠§Â§ñÔºåUniFER-CoT-230KÂíåUniFER-RLVR-360K‰∏§‰∏™Êï∞ÊçÆÈõÜÁöÑÊûÑÂª∫‰πü‰∏∫MLLMsÂú®FER‰ªªÂä°‰∏≠ÁöÑÁ†îÁ©∂Êèê‰æõ‰∫ÜÈáçË¶ÅËµÑÊ∫ê„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöUniFER-CoT-230KÊï∞ÊçÆÈõÜÂåÖÂê´230K‰∏™Ê†∑Êú¨ÔºåÊØè‰∏™Ê†∑Êú¨ÂåÖÂê´‰∏ÄÂº†Èù¢ÈÉ®Ë°®ÊÉÖÂõæÂÉèÂíå‰∏Ä‰∏™CoTÊé®ÁêÜËøáÁ®ãÔºåÁî®‰∫éÂºïÂØºÊ®°ÂûãËøõË°åÊé®ÁêÜ„ÄÇUniFER-RLVR-360KÊï∞ÊçÆÈõÜÂåÖÂê´360K‰∏™Ê†∑Êú¨ÔºåÊØè‰∏™Ê†∑Êú¨ÂåÖÂê´‰∏ÄÂº†Èù¢ÈÉ®Ë°®ÊÉÖÂõæÂÉèÂíå‰∏Ä‰∏™ÂèØÈ™åËØÅÁöÑÂ•ñÂä±‰ø°Âè∑ÔºåÁî®‰∫éÊåáÂØºÊ®°ÂûãÁöÑÂº∫ÂåñÂ≠¶‰π†ËøáÁ®ã„ÄÇÂú®Âº∫ÂåñÂ≠¶‰π†ËøáÁ®ã‰∏≠ÔºåËÆ∫ÊñáËÆæËÆ°‰∫Ü‰∏Ä‰∏™Â•ñÂä±ÂáΩÊï∞ÔºåÁî®‰∫éËØÑ‰º∞Ê®°ÂûãÁöÑÊé®ÁêÜËøáÁ®ãÊòØÂê¶Ê≠£Á°ÆÂíåÂèØËß£Èáä„ÄÇÂÖ∑‰ΩìÂèÇÊï∞ËÆæÁΩÆÂíåÁΩëÁªúÁªìÊûÑÁªÜËäÇÊú™Âú®ÊëòË¶Å‰∏≠ËØ¶ÁªÜËØ¥ÊòéÔºåÂ±û‰∫éÊú™Áü•‰ø°ÊÅØ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

UniFER-7BÂú®FERBenchÂü∫ÂáÜÊµãËØï‰∏≠Ôºå‰ºò‰∫éËÆ∏Â§öÂºÄÊ∫êÂíåÈó≠Ê∫êÁöÑÈÄöÁî®MLLMÔºå‰æãÂ¶ÇGemini-2.5-ProÂíåQwen2.5-VL-72B„ÄÇËøôË°®ÊòéÈÄöËøá‰∏ìÈó®ÁöÑÊï∞ÊçÆÈõÜÂíåËÆ≠ÁªÉÁ≠ñÁï•ÔºåÂèØ‰ª•ÊòæËëóÊèêÂçáMLLMÂú®FER‰ªªÂä°‰∏≠ÁöÑÊÄßËÉΩ„ÄÇÂÖ∑‰ΩìÁöÑÊÄßËÉΩÊèêÂçáÂπÖÂ∫¶Êú™Âú®ÊëòË¶Å‰∏≠ÁªôÂá∫ÔºåÂ±û‰∫éÊú™Áü•‰ø°ÊÅØ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊÉÖÊÑüËÆ°ÁÆó„ÄÅ‰∫∫Êú∫‰∫§‰∫í„ÄÅÊô∫ËÉΩÁõëÊéß„ÄÅÂåªÁñóËØäÊñ≠Á≠âÈ¢ÜÂüü„ÄÇ‰æãÂ¶ÇÔºåÂú®‰∫∫Êú∫‰∫§‰∫í‰∏≠ÔºåUniFER-7BÂèØ‰ª•Â∏ÆÂä©Êú∫Âô®ÁêÜËß£‰∫∫Á±ªÁöÑÊÉÖÁª™Ôºå‰ªéËÄåÊèê‰æõÊõ¥Ëá™ÁÑ∂Âíå‰∏™ÊÄßÂåñÁöÑ‰∫§‰∫í‰ΩìÈ™å„ÄÇÂú®Êô∫ËÉΩÁõëÊéß‰∏≠ÔºåÂèØ‰ª•Áî®‰∫éËØÜÂà´ÂºÇÂ∏∏ÊÉÖÁª™Ôºå‰ªéËÄåÈ¢ÑÈò≤ÊΩúÂú®ÁöÑÂÆâÂÖ®‰∫ã‰ª∂„ÄÇÂú®ÂåªÁñóËØäÊñ≠‰∏≠ÔºåÂèØ‰ª•ËæÖÂä©ÂåªÁîüËØäÊñ≠Á≤æÁ•ûÁñæÁóÖ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Multimodal Large Language Models (MLLMs) have revolutionized numerous research fields, including computer vision and affective computing. As a pivotal challenge in this interdisciplinary domain, facial expression recognition (FER) has evolved from separate, domain-specific models to more unified approaches. One promising avenue to unify FER tasks is converting conventional FER datasets into visual question-answering (VQA) formats, enabling the direct application of powerful generalist MLLMs for inference. However, despite the success of cutting-edge MLLMs in various tasks, their performance on FER tasks remains largely unexplored. To address this gap, we provide FERBench, a systematic benchmark that incorporates 20 state-of-the-art MLLMs across four widely used FER datasets. Our results reveal that, while MLLMs exhibit good classification performance, they still face significant limitations in reasoning and interpretability. To this end, we introduce post-training strategies aimed at enhancing the facial expression reasoning capabilities of MLLMs. Specifically, we curate two high-quality and large-scale datasets: UniFER-CoT-230K for cold-start initialization and UniFER-RLVR-360K for reinforcement learning with verifiable rewards (RLVR), respectively. Building upon them, we develop a unified and interpretable FER foundation model termed UniFER-7B, which outperforms many open-sourced and closed-source generalist MLLMs (e.g., Gemini-2.5-Pro and Qwen2.5-VL-72B).

