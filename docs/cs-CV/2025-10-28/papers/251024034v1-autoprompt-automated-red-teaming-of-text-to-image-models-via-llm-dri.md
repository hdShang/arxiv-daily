---
layout: default
title: AutoPrompt: Automated Red-Teaming of Text-to-Image Models via LLM-Driven Adversarial Prompts
---

# AutoPrompt: Automated Red-Teaming of Text-to-Image Models via LLM-Driven Adversarial Prompts

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.24034" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.24034v1</a>
  <a href="https://arxiv.org/pdf/2510.24034.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.24034v1" onclick="toggleFavorite(this, '2510.24034v1', 'AutoPrompt: Automated Red-Teaming of Text-to-Image Models via LLM-Driven Adversarial Prompts')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yufan Liu, Wanqian Zhang, Huashan Chen, Lin Wang, Xiaojun Jia, Zheng Lin, Weiping Wang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-28

**å¤‡æ³¨**: Accepted by ICCV 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAutoPromptï¼Œåˆ©ç”¨LLMè‡ªåŠ¨ç”Ÿæˆå¯¹æŠ—æ€§æç¤ºï¼Œå®ç°å¯¹æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹çš„é»‘ç›’çº¢é˜Ÿæµ‹è¯•ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹` `å¯¹æŠ—æ€§æ”»å‡»` `çº¢é˜Ÿæµ‹è¯•` `å¤§å‹è¯­è¨€æ¨¡å‹` `é»‘ç›’æ”»å‡»`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹æ˜“å—å¯¹æŠ—æ€§æç¤ºæ”»å‡»ï¼Œç°æœ‰çº¢é˜Ÿæµ‹è¯•æ–¹æ³•ä¾èµ–ç™½ç›’è®¿é—®å’Œä½æ•ˆçš„é€æç¤ºä¼˜åŒ–ï¼Œä¸”æ˜“ç”Ÿæˆæ— æ„ä¹‰æç¤ºã€‚
2. AutoPromptåˆ©ç”¨LLMç”Ÿæˆäººç±»å¯è¯»çš„å¯¹æŠ—æ€§åç¼€ï¼Œé€šè¿‡äº¤æ›¿ä¼˜åŒ–å’Œå¾®è°ƒï¼Œæå‡å¯¹æŠ—æ€§æç¤ºçš„ç”Ÿæˆè´¨é‡å’Œæ•ˆç‡ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒAutoPromptç”Ÿæˆçš„æç¤ºå…·æœ‰ä¼˜ç§€çš„çº¢é˜Ÿæµ‹è¯•æ€§èƒ½å’Œé›¶æ ·æœ¬è¿ç§»èƒ½åŠ›ï¼Œèƒ½æœ‰æ•ˆæ”»å‡»å•†ä¸šAPIã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºAutoPrompt (APT)ï¼Œä¸€ä¸ªé»‘ç›’æ¡†æ¶ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹(LLM)ä¸ºè‰¯æ€§æç¤ºè‡ªåŠ¨ç”Ÿæˆäººç±»å¯è¯»çš„å¯¹æŠ—æ€§åç¼€ï¼Œä»è€Œå®ç°å¯¹æ–‡æœ¬åˆ°å›¾åƒ(T2I)æ¨¡å‹çš„çº¢é˜Ÿæµ‹è¯•ã€‚è¯¥æ¡†æ¶é¦–å…ˆå¼•å…¥å¯¹æŠ—æ€§åç¼€ä¼˜åŒ–å’ŒLLMå¾®è°ƒä¹‹é—´çš„äº¤æ›¿ä¼˜åŒ–-å¾®è°ƒæµç¨‹ï¼Œå¹¶åˆ©ç”¨ä¼˜åŒ–åçš„åç¼€å¯¹LLMè¿›è¡Œå¾®è°ƒã€‚æ­¤å¤–ï¼Œåœ¨ä¼˜åŒ–é˜¶æ®µé›†æˆäº†åŒé‡è§„é¿ç­–ç•¥ï¼Œä»¥ç»•è¿‡åŸºäºå›°æƒ‘åº¦çš„è¿‡æ»¤å™¨å’Œé»‘åå•è¯è¿‡æ»¤å™¨ï¼š(1) é€šè¿‡è¾…åŠ©LLMå›°æƒ‘åº¦è¯„åˆ†çº¦æŸLLMç”Ÿæˆäººç±»å¯è¯»çš„æç¤ºï¼Œè¿™ä¸ä¹‹å‰çš„tokençº§åˆ«ä¹±ç å½¢æˆé²œæ˜å¯¹æ¯”ï¼›(2) å¼•å…¥ç¦ç”¨tokenæƒ©ç½šï¼Œä»¥æŠ‘åˆ¶é»‘åå•ä¸­ç¦ç”¨tokençš„æ˜¾å¼ç”Ÿæˆã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„äººç±»å¯è¯»ã€æŠ—è¿‡æ»¤çš„å¯¹æŠ—æ€§æç¤ºå…·æœ‰å‡ºè‰²çš„çº¢é˜Ÿæµ‹è¯•æ€§èƒ½ï¼Œä»¥åŠå“è¶Šçš„é›¶æ ·æœ¬è¿ç§»èƒ½åŠ›ï¼Œèƒ½å¤Ÿå³æ—¶é€‚åº”æœªè§è¿‡çš„æç¤ºï¼Œå¹¶æš´éœ²å•†ä¸šAPIï¼ˆä¾‹å¦‚Leonardo.Aiï¼‰ä¸­çš„å…³é”®æ¼æ´ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæ–‡æœ¬åˆ°å›¾åƒ(T2I)æ¨¡å‹è™½ç„¶å‘å±•è¿…é€Ÿï¼Œä½†å…¶å®‰å…¨æœºåˆ¶å®¹æ˜“å—åˆ°å¯¹æŠ—æ€§æç¤ºçš„æ”»å‡»ï¼Œè¿™äº›æç¤ºä¼šæ¶æ„ç”Ÿæˆä¸å®‰å…¨çš„å›¾åƒã€‚ç°æœ‰çš„çº¢é˜Ÿæµ‹è¯•æ–¹æ³•é€šå¸¸éœ€è¦ç™½ç›’è®¿é—®T2Iæ¨¡å‹ï¼Œå¹¶ä¸”ä¾èµ–äºä½æ•ˆçš„é€æç¤ºä¼˜åŒ–ï¼Œè€Œä¸”ä¸å¯é¿å…åœ°ä¼šç”Ÿæˆè¯­ä¹‰ä¸Šæ— æ„ä¹‰çš„æç¤ºï¼Œè¿™äº›æç¤ºå¾ˆå®¹æ˜“è¢«è¿‡æ»¤å™¨é˜»æ­¢ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§é»‘ç›’æ–¹æ³•ï¼Œèƒ½å¤Ÿè‡ªåŠ¨ç”Ÿæˆäººç±»å¯è¯»ä¸”èƒ½ç»•è¿‡è¿‡æ»¤å™¨çš„å¯¹æŠ—æ€§æç¤ºï¼Œä»¥æœ‰æ•ˆè¯„ä¼°T2Iæ¨¡å‹çš„å®‰å…¨æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šAutoPromptçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹(LLM)ç”Ÿæˆå¯¹æŠ—æ€§åç¼€ï¼Œå¹¶å°†å…¶æ·»åŠ åˆ°è‰¯æ€§æç¤ºä¸­ï¼Œä»è€Œæ¬ºéª—T2Iæ¨¡å‹ç”Ÿæˆä¸å®‰å…¨çš„å›¾åƒã€‚é€šè¿‡ä¼˜åŒ–LLMç”Ÿæˆçš„åç¼€ï¼Œä½¿å…¶æ—¢èƒ½æœ‰æ•ˆæ”»å‡»T2Iæ¨¡å‹ï¼Œåˆèƒ½ä¿æŒäººç±»å¯è¯»æ€§å¹¶ç»•è¿‡å„ç§è¿‡æ»¤å™¨ã€‚è¿™ç§æ–¹æ³•çš„æ ¸å¿ƒåœ¨äºåˆ©ç”¨LLMçš„ç”Ÿæˆèƒ½åŠ›å’Œä¼˜åŒ–ç®—æ³•çš„æœç´¢èƒ½åŠ›ï¼Œè‡ªåŠ¨å‘ç°æœ‰æ•ˆçš„å¯¹æŠ—æ€§æç¤ºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAutoPromptæ¡†æ¶åŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) **å¯¹æŠ—æ€§åç¼€ä¼˜åŒ–**ï¼šä½¿ç”¨ä¼˜åŒ–ç®—æ³•ï¼ˆå¦‚æ¢¯åº¦ä¸‹é™ï¼‰æœç´¢èƒ½å¤Ÿæœ€å¤§åŒ–æ”»å‡»æˆåŠŸç‡çš„å¯¹æŠ—æ€§åç¼€ã€‚2) **LLMå¾®è°ƒ**ï¼šåˆ©ç”¨ä¼˜åŒ–åçš„å¯¹æŠ—æ€§åç¼€å¯¹LLMè¿›è¡Œå¾®è°ƒï¼Œæé«˜LLMç”Ÿæˆå¯¹æŠ—æ€§æç¤ºçš„èƒ½åŠ›ã€‚3) **åŒé‡è§„é¿ç­–ç•¥**ï¼šåŒ…æ‹¬åŸºäºå›°æƒ‘åº¦çš„è¿‡æ»¤å™¨è§„é¿å’Œé»‘åå•è¯è¿‡æ»¤å™¨è§„é¿ã€‚4) **äº¤æ›¿ä¼˜åŒ–-å¾®è°ƒæµç¨‹**ï¼šåœ¨å¯¹æŠ—æ€§åç¼€ä¼˜åŒ–å’ŒLLMå¾®è°ƒä¹‹é—´è¿›è¡Œäº¤æ›¿ï¼Œä¸æ–­æé«˜å¯¹æŠ—æ€§æç¤ºçš„è´¨é‡å’ŒLLMçš„ç”Ÿæˆèƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šAutoPromptçš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) **é»‘ç›’æ”»å‡»**ï¼šæ— éœ€è®¿é—®T2Iæ¨¡å‹çš„å†…éƒ¨å‚æ•°ï¼Œå³å¯è¿›è¡Œçº¢é˜Ÿæµ‹è¯•ã€‚2) **äººç±»å¯è¯»çš„å¯¹æŠ—æ€§æç¤º**ï¼šç”Ÿæˆçš„æç¤ºå…·æœ‰è‰¯å¥½çš„å¯è¯»æ€§ï¼Œæ›´éš¾è¢«è¿‡æ»¤å™¨è¯†åˆ«å’Œé˜»æ­¢ã€‚3) **åŒé‡è§„é¿ç­–ç•¥**ï¼šèƒ½å¤Ÿæœ‰æ•ˆç»•è¿‡åŸºäºå›°æƒ‘åº¦çš„è¿‡æ»¤å™¨å’Œé»‘åå•è¯è¿‡æ»¤å™¨ã€‚4) **äº¤æ›¿ä¼˜åŒ–-å¾®è°ƒæµç¨‹**ï¼šèƒ½å¤Ÿä¸æ–­æé«˜å¯¹æŠ—æ€§æç¤ºçš„è´¨é‡å’ŒLLMçš„ç”Ÿæˆèƒ½åŠ›ã€‚ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºï¼ŒAutoPromptåˆ©ç”¨LLMçš„ç”Ÿæˆèƒ½åŠ›å’Œä¼˜åŒ–ç®—æ³•çš„æœç´¢èƒ½åŠ›ï¼Œè‡ªåŠ¨å‘ç°æœ‰æ•ˆçš„å¯¹æŠ—æ€§æç¤ºï¼Œè€Œæ— éœ€äººå·¥è®¾è®¡æˆ–ä¿®æ”¹æç¤ºã€‚

**å…³é”®è®¾è®¡**ï¼šAutoPromptçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) **å›°æƒ‘åº¦çº¦æŸ**ï¼šé€šè¿‡è®¡ç®—LLMç”Ÿæˆæç¤ºçš„å›°æƒ‘åº¦ï¼Œçº¦æŸå…¶ç”Ÿæˆäººç±»å¯è¯»çš„æç¤ºã€‚2) **ç¦ç”¨tokenæƒ©ç½š**ï¼šå¯¹LLMç”Ÿæˆé»‘åå•ä¸­çš„tokenè¿›è¡Œæƒ©ç½šï¼Œé˜²æ­¢å…¶ç”ŸæˆåŒ…å«æ•æ„Ÿè¯æ±‡çš„æç¤ºã€‚3) **äº¤æ›¿ä¼˜åŒ–-å¾®è°ƒçš„è¶…å‚æ•°è®¾ç½®**ï¼šä¾‹å¦‚ï¼Œä¼˜åŒ–ç®—æ³•çš„å­¦ä¹ ç‡ã€å¾®è°ƒçš„epochæ•°ç­‰ã€‚4) **å¯¹æŠ—æ€§æŸå¤±å‡½æ•°çš„è®¾è®¡**ï¼šç”¨äºè¡¡é‡æ”»å‡»çš„æˆåŠŸç‡ï¼Œä¾‹å¦‚ï¼Œå¯ä»¥æ ¹æ®ç”Ÿæˆçš„å›¾åƒæ˜¯å¦åŒ…å«ä¸å®‰å…¨å†…å®¹æ¥è®¾è®¡æŸå¤±å‡½æ•°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒAutoPromptç”Ÿæˆçš„å¯¹æŠ—æ€§æç¤ºå…·æœ‰å‡ºè‰²çš„çº¢é˜Ÿæµ‹è¯•æ€§èƒ½ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ”»å‡»å„ç§æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ï¼ŒåŒ…æ‹¬å•†ä¸šAPIï¼ˆä¾‹å¦‚Leonardo.Aiï¼‰ã€‚AutoPromptè¿˜å…·æœ‰å“è¶Šçš„é›¶æ ·æœ¬è¿ç§»èƒ½åŠ›ï¼Œèƒ½å¤Ÿå³æ—¶é€‚åº”æœªè§è¿‡çš„æç¤ºï¼Œå¹¶æš´éœ²æ¨¡å‹ä¸­çš„å…³é”®æ¼æ´ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒAutoPromptç”Ÿæˆçš„æç¤ºæ›´å…·å¯è¯»æ€§ï¼Œä¸”æ›´éš¾è¢«è¿‡æ»¤å™¨é˜»æ­¢ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

AutoPromptå¯ç”¨äºè¯„ä¼°å’Œæé«˜æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹çš„å®‰å…¨æ€§ï¼Œå¸®åŠ©å¼€å‘è€…å‘ç°å’Œä¿®å¤æ½œåœ¨çš„å®‰å…¨æ¼æ´ã€‚è¯¥æŠ€æœ¯å¯åº”ç”¨äºå„ç§åœºæ™¯ï¼Œä¾‹å¦‚ï¼Œè¯„ä¼°å•†ä¸šAPIçš„å®‰å…¨æ€§ã€å¼€å‘æ›´å®‰å…¨çš„æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ã€ä»¥åŠé˜²æ­¢æ¶æ„ç”¨æˆ·åˆ©ç”¨å¯¹æŠ—æ€§æç¤ºç”Ÿæˆä¸å®‰å…¨å†…å®¹ã€‚æœªæ¥çš„ç ”ç©¶å¯ä»¥æ¢ç´¢æ›´æœ‰æ•ˆçš„å¯¹æŠ—æ€§æç¤ºç”Ÿæˆæ–¹æ³•ï¼Œä»¥åŠæ›´é²æ£’çš„é˜²å¾¡æœºåˆ¶ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Despite rapid advancements in text-to-image (T2I) models, their safety mechanisms are vulnerable to adversarial prompts, which maliciously generate unsafe images. Current red-teaming methods for proactively assessing such vulnerabilities usually require white-box access to T2I models, and rely on inefficient per-prompt optimization, as well as inevitably generate semantically meaningless prompts easily blocked by filters. In this paper, we propose APT (AutoPrompT), a black-box framework that leverages large language models (LLMs) to automatically generate human-readable adversarial suffixes for benign prompts. We first introduce an alternating optimization-finetuning pipeline between adversarial suffix optimization and fine-tuning the LLM utilizing the optimized suffix. Furthermore, we integrates a dual-evasion strategy in optimization phase, enabling the bypass of both perplexity-based filter and blacklist word filter: (1) we constrain the LLM generating human-readable prompts through an auxiliary LLM perplexity scoring, which starkly contrasts with prior token-level gibberish, and (2) we also introduce banned-token penalties to suppress the explicit generation of banned-tokens in blacklist. Extensive experiments demonstrate the excellent red-teaming performance of our human-readable, filter-resistant adversarial prompts, as well as superior zero-shot transferability which enables instant adaptation to unseen prompts and exposes critical vulnerabilities even in commercial APIs (e.g., Leonardo.Ai.).

