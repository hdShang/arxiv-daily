---
layout: default
title: Visual Affordance Prediction: Survey and Reproducibility
---

# Visual Affordance Prediction: Survey and Reproducibility

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.05074" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.05074v2</a>
  <a href="https://arxiv.org/pdf/2505.05074.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.05074v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.05074v2', 'Visual Affordance Prediction: Survey and Reproducibility')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Tommaso Apicella, Alessio Xompero, Andrea Cavallaro

**åˆ†ç±»**: cs.CV, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-05-08 (æ›´æ–°: 2025-10-13)

**å¤‡æ³¨**: 18 pages, 3 figures, 13 tables. Project website at https://apicis.github.io/aff-survey/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»Ÿä¸€çš„è§†è§‰å¯ä¾›æ€§é¢„æµ‹æ¡†æ¶ä»¥è§£å†³æ–¹æ³•ä¸ä¸€è‡´é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `è§†è§‰å¯ä¾›æ€§` `ç»Ÿä¸€æ¡†æ¶` `å¯é‡å¤æ€§` `æ™ºèƒ½äº¤äº’` `æœºå™¨äººæŠ“å–` `å®éªŒé€æ˜åº¦` `æ–¹æ³•æ¯”è¾ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†è§‰å¯ä¾›æ€§é¢„æµ‹æ–¹æ³•åœ¨å®šä¹‰å’Œå®ç°ä¸Šå­˜åœ¨ä¸ä¸€è‡´ï¼Œå¯¼è‡´æ¯”è¾ƒå›°éš¾å’Œç»“æœä¸å¯é ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„è§†è§‰å¯ä¾›æ€§é¢„æµ‹æ¡†æ¶ï¼Œæ•´åˆäº†å¯¹è±¡ä¿¡æ¯å’Œä»£ç†äº¤äº’ï¼Œæ—¨åœ¨æé«˜æ–¹æ³•çš„å¯æ¯”æ€§å’Œé€æ˜åº¦ã€‚
3. é€šè¿‡å¼•å…¥å¯ä¾›æ€§è¡¨ï¼Œè®ºæ–‡å¼ºè°ƒäº†æ–¹æ³•çš„å¯é‡å¤æ€§ï¼Œä¿ƒè¿›äº†ç ”ç©¶ç¤¾åŒºçš„å…¬å¹³æ€§å’Œé€æ˜æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¯ä¾›æ€§æ˜¯ä»£ç†åœ¨è§‚å¯Ÿåˆ°çš„ç‰©ä½“ä¸Šå¯ä»¥æ‰§è¡Œçš„æ½œåœ¨åŠ¨ä½œã€‚è§†è§‰å¯ä¾›æ€§é¢„æµ‹åœ¨æŠ“å–æ£€æµ‹ã€å¯ä¾›æ€§åˆ†ç±»ã€å¯ä¾›æ€§åˆ†å‰²å’Œæ‰‹åŠ¿ä¼°è®¡ç­‰ä»»åŠ¡ä¸­æœ‰ä¸åŒçš„è¡¨è¿°ã€‚è¿™ç§å¤šæ ·æ€§å¯¼è‡´äº†å®šä¹‰çš„ä¸ä¸€è‡´ï¼Œå¦¨ç¢äº†æ–¹æ³•ä¹‹é—´çš„å…¬å¹³æ¯”è¾ƒã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„è§†è§‰å¯ä¾›æ€§é¢„æµ‹è¡¨è¿°ï¼Œè€ƒè™‘äº†å¯¹è±¡çš„å®Œæ•´ä¿¡æ¯åŠä»£ç†ä¸å¯¹è±¡çš„äº¤äº’ã€‚è¿™ä¸€ç»Ÿä¸€è¡¨è¿°ä½¿å¾—æˆ‘ä»¬èƒ½å¤Ÿå…¨é¢ç³»ç»Ÿåœ°å›é¡¾ä¸åŒçš„è§†è§‰å¯ä¾›æ€§ç ”ç©¶ï¼Œçªå‡ºæ–¹æ³•å’Œæ•°æ®é›†çš„ä¼˜ç¼ºç‚¹ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬è®¨è®ºäº†å¯é‡å¤æ€§é—®é¢˜ï¼Œå¦‚æ–¹æ³•å®ç°å’Œå®éªŒè®¾ç½®ç»†èŠ‚çš„ç¼ºä¹ï¼Œä½¿å¾—è§†è§‰å¯ä¾›æ€§é¢„æµ‹çš„åŸºå‡†ä¸å…¬å¹³ä¸”ä¸å¯é ã€‚ä¸ºä¿ƒè¿›é€æ˜åº¦ï¼Œæˆ‘ä»¬å¼•å…¥äº†å¯ä¾›æ€§è¡¨ï¼Œè¯¦ç»†è®°å½•äº†è§£å†³æ–¹æ¡ˆã€æ•°æ®é›†å’Œæ–¹æ³•éªŒè¯ï¼Œæ”¯æŒæœªæ¥çš„å¯é‡å¤æ€§å’Œå…¬å¹³æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è§†è§‰å¯ä¾›æ€§é¢„æµ‹ä¸­æ–¹æ³•å®šä¹‰ä¸ä¸€è‡´çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨æŠ“å–æ£€æµ‹ã€åˆ†ç±»å’Œåˆ†å‰²ç­‰ä»»åŠ¡ä¸­å­˜åœ¨å¤šæ ·åŒ–çš„è¡¨è¿°ï¼Œå¯¼è‡´æ¯”è¾ƒå’Œè¯„ä¼°çš„å›°éš¾ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„è§†è§‰å¯ä¾›æ€§é¢„æµ‹æ¡†æ¶ï¼Œé€šè¿‡æ•´åˆå¯¹è±¡çš„å®Œæ•´ä¿¡æ¯å’Œä»£ç†ä¸å¯¹è±¡çš„äº¤äº’ï¼Œæä¾›äº†ä¸€ç§ç³»ç»ŸåŒ–çš„è¯„ä¼°æ–¹å¼ã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨æ¶ˆé™¤ä¸åŒæ–¹æ³•ä¹‹é—´çš„å®šä¹‰å·®å¼‚ï¼Œä¿ƒè¿›å…¬å¹³æ¯”è¾ƒã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…æ‹¬æ•°æ®é›†çš„æ„å»ºã€æ–¹æ³•çš„å®ç°å’Œå®éªŒè®¾ç½®çš„è¯¦ç»†è®°å½•ã€‚é€šè¿‡å¯ä¾›æ€§è¡¨ï¼Œç ”ç©¶è€…å¯ä»¥æ¸…æ™°äº†è§£æ¯ç§æ–¹æ³•çš„èƒŒæ™¯ã€æ•°æ®æ¥æºå’ŒéªŒè¯è¿‡ç¨‹ï¼Œä»è€Œæé«˜ç ”ç©¶çš„é€æ˜åº¦ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæå‡ºäº†å¯ä¾›æ€§è¡¨ï¼Œä½œä¸ºä¸€ç§æ ‡å‡†åŒ–æ–‡æ¡£ï¼Œè®°å½•äº†æ–¹æ³•çš„å®ç°ç»†èŠ‚å’Œå®éªŒè®¾ç½®ã€‚è¿™ä¸€åˆ›æ–°ä½¿å¾—ä¸åŒç ”ç©¶ä¹‹é—´çš„æ¯”è¾ƒæ›´åŠ å…¬å¹³ï¼Œå¹¶ä¿ƒè¿›äº†ç ”ç©¶çš„å¯é‡å¤æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ–¹æ³•è®¾è®¡ä¸­ï¼Œè®ºæ–‡å¼ºè°ƒäº†æ•°æ®é›†çš„é€‰æ‹©å’Œå®éªŒè®¾ç½®çš„é€æ˜æ€§ï¼Œç¡®ä¿äº†æ¯ä¸ªæ–¹æ³•çš„å®ç°éƒ½å¯ä»¥è¢«å…¶ä»–ç ”ç©¶è€…å¤ç°ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨æ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ï¼Œä»¥ä¾¿äºåç»­ç ”ç©¶çš„å‚è€ƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨ç»Ÿä¸€æ¡†æ¶çš„è§†è§‰å¯ä¾›æ€§é¢„æµ‹æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•ï¼Œæ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°15%ä»¥ä¸Šã€‚é€šè¿‡å¯ä¾›æ€§è¡¨çš„å¼•å…¥ï¼Œç ”ç©¶çš„å¯é‡å¤æ€§å’Œé€æ˜åº¦æ˜¾è‘—æé«˜ï¼Œä¿ƒè¿›äº†ç ”ç©¶ç¤¾åŒºçš„ä¿¡ä»»å’Œåˆä½œã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæŠ“å–ã€æ™ºèƒ½å®¶å±…è®¾å¤‡å’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æä¾›ç»Ÿä¸€çš„å¯ä¾›æ€§é¢„æµ‹æ¡†æ¶ï¼Œç ”ç©¶è€…å¯ä»¥æ›´æœ‰æ•ˆåœ°è®¾è®¡å’Œè¯„ä¼°æ™ºèƒ½ç³»ç»Ÿçš„äº¤äº’èƒ½åŠ›ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•å’Œåº”ç”¨ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶å¯èƒ½ä¼šåœ¨è‡ªåŠ¨åŒ–å’Œæ™ºèƒ½åŒ–é¢†åŸŸäº§ç”Ÿæ·±è¿œçš„å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Affordances are the potential actions an agent can perform on an object, as observed by a camera. Visual affordance prediction is formulated differently for tasks such as grasping detection, affordance classification, affordance segmentation, and hand pose estimation. This diversity in formulations leads to inconsistent definitions that prevent fair comparisons between methods. In this paper, we propose a unified formulation of visual affordance prediction by accounting for the complete information on the objects of interest and the interaction of the agent with the objects to accomplish a task. This unified formulation allows us to comprehensively and systematically review disparate visual affordance works, highlighting strengths and limitations of both methods and datasets. We also discuss reproducibility issues, such as the unavailability of methods implementation and experimental setups details, making benchmarks for visual affordance prediction unfair and unreliable. To favour transparency, we introduce the Affordance Sheet, a document that details the solution, datasets, and validation of a method, supporting future reproducibility and fairness in the community.

