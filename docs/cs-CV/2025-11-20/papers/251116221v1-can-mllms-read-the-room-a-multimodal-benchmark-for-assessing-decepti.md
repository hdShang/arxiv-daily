---
layout: default
title: Can MLLMs Read the Room? A Multimodal Benchmark for Assessing Deception in Multi-Party Social Interactions
---

# Can MLLMs Read the Room? A Multimodal Benchmark for Assessing Deception in Multi-Party Social Interactions

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.16221" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.16221v1</a>
  <a href="https://arxiv.org/pdf/2511.16221.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.16221v1" onclick="toggleFavorite(this, '2511.16221v1', 'Can MLLMs Read the Room? A Multimodal Benchmark for Assessing Deception in Multi-Party Social Interactions')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Caixin Kang, Yifei Huang, Liangyang Ouyang, Mingfang Zhang, Ruicong Liu, Yoichi Sato

**åˆ†ç±»**: cs.CV, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-11-20

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMIDAåŸºå‡†æµ‹è¯•ï¼Œè¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨å¤šäººç¤¾äº¤äº’åŠ¨ä¸­è¯†åˆ«æ¬ºéª—çš„èƒ½åŠ›ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `æ¬ºéª—æ£€æµ‹` `ç¤¾äº¤æ¨ç†` `å¤§è¯­è¨€æ¨¡å‹` `äººæœºäº¤äº’`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰MLLMåœ¨å¤æ‚ç¤¾äº¤äº’åŠ¨ä¸­è¯†åˆ«æ¬ºéª—çš„èƒ½åŠ›ä¸è¶³ï¼Œç¼ºä¹â€œè¯»æ‡‚æ°”æ°›â€çš„æ ¸å¿ƒäººç±»æ™ºèƒ½ã€‚
2. æå‡ºMIDAä»»åŠ¡å’Œæ•°æ®é›†ï¼Œå¹¶è®¾è®¡SoCoTæ¨ç†ç®¡é“å’ŒDSEMæ¨¡å—ï¼Œæå‡æ¨¡å‹ç¤¾äº¤æ¨ç†èƒ½åŠ›ã€‚
3. å®éªŒè¡¨æ˜ï¼Œå³ä½¿æ˜¯GPT-4oç­‰å¼ºå¤§æ¨¡å‹ä¹Ÿéš¾ä»¥å¯é åŒºåˆ†çœŸå‡ï¼ŒSoCoTå’ŒDSEMèƒ½æœ‰æ•ˆæå‡æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡æœ€å…ˆè¿›çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰å…·æœ‰å…ˆè¿›çš„æ¨ç†èƒ½åŠ›ï¼Œä½†å®ƒä»¬æ˜æ˜¾ç¼ºä¹äººç±»æ™ºèƒ½çš„ä¸€ä¸ªæ ¸å¿ƒç»„æˆéƒ¨åˆ†ï¼šå³â€œè¯»æ‡‚æ°”æ°›â€å¹¶è¯„ä¼°å¤æ‚ç¤¾äº¤äº’åŠ¨ä¸­æ¬ºéª—è¡Œä¸ºçš„èƒ½åŠ›ã€‚ä¸ºäº†ä¸¥æ ¼é‡åŒ–è¿™ç§ç¼ºé™·ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€é¡¹æ–°ä»»åŠ¡ï¼Œå³å¤šæ¨¡æ€äº’åŠ¨æ¬ºéª—è¯„ä¼°ï¼ˆMIDAï¼‰ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªæ–°çš„å¤šæ¨¡æ€æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†æä¾›åŒæ­¥çš„è§†é¢‘å’Œæ–‡æœ¬ï¼Œä»¥åŠæ¯ä¸ªé™ˆè¿°çš„å¯éªŒè¯çš„çœŸå®æ ‡ç­¾ã€‚æˆ‘ä»¬å»ºç«‹äº†ä¸€ä¸ªå…¨é¢çš„åŸºå‡†ï¼Œè¯„ä¼°äº†12ä¸ªæœ€å…ˆè¿›çš„å¼€æºå’Œé—­æºMLLMï¼Œæ­ç¤ºäº†ä¸€ä¸ªæ˜¾è‘—çš„æ€§èƒ½å·®è·ï¼šå³ä½¿æ˜¯åƒGPT-4oè¿™æ ·å¼ºå¤§çš„æ¨¡å‹ä¹Ÿéš¾ä»¥å¯é åœ°åŒºåˆ†çœŸå‡ã€‚æˆ‘ä»¬å¯¹å¤±è´¥æ¨¡å¼çš„åˆ†æè¡¨æ˜ï¼Œè¿™äº›æ¨¡å‹æœªèƒ½æœ‰æ•ˆåœ°å°†è¯­è¨€ä¸å¤šæ¨¡æ€ç¤¾äº¤çº¿ç´¢è”ç³»èµ·æ¥ï¼Œå¹¶ä¸”ç¼ºä¹å¯¹ä»–äººæ‰€çŸ¥ã€æ‰€ä¿¡æˆ–æ‰€æƒ³è¿›è¡Œå»ºæ¨¡çš„èƒ½åŠ›ï¼Œçªæ˜¾äº†è¿«åˆ‡éœ€è¦æ–°çš„æ–¹æ³•æ¥æ„å»ºæ›´å…·æ´å¯ŸåŠ›å’Œå€¼å¾—ä¿¡èµ–çš„AIç³»ç»Ÿã€‚ä¸ºäº†å‘å‰è¿ˆè¿›ä¸€æ­¥ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªç¤¾ä¼šé“¾å¼æ€è€ƒï¼ˆSoCoTï¼‰æ¨ç†ç®¡é“å’Œä¸€ä¸ªåŠ¨æ€ç¤¾ä¼šè®¤çŸ¥è®°å¿†ï¼ˆDSEMï¼‰æ¨¡å—ã€‚æˆ‘ä»¬çš„æ¡†æ¶åœ¨è¿™ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ä¸Šäº§ç”Ÿäº†æ€§èƒ½æå‡ï¼Œå±•ç¤ºäº†ä¸€æ¡æœ‰å¸Œæœ›çš„æ–°é€”å¾„ï¼Œå¯ä»¥æ„å»ºèƒ½å¤Ÿè¿›è¡ŒçœŸæ­£ç±»äººç¤¾äº¤æ¨ç†çš„MLLMã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ–¹ç¤¾äº¤äº’åŠ¨åœºæ™¯ä¸‹ï¼Œå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰éš¾ä»¥å‡†ç¡®è¯†åˆ«æ¬ºéª—è¡Œä¸ºçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹å¯¹å¤æ‚ç¤¾äº¤çº¿ç´¢çš„æœ‰æ•ˆåˆ©ç”¨ï¼Œæ— æ³•å‡†ç¡®å»ºæ¨¡å‚ä¸è€…çš„çŸ¥è¯†ã€ä¿¡å¿µå’Œæ„å›¾ï¼Œå¯¼è‡´åœ¨æ¬ºéª—è¯†åˆ«ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å¢å¼ºMLLMså¯¹å¤šæ¨¡æ€ç¤¾äº¤çº¿ç´¢çš„æ„ŸçŸ¥å’Œæ¨ç†èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œæ¨¡æ‹Ÿç¤¾äº¤äº’åŠ¨ä¸­çš„å¤æ‚åŠ¨æ€ã€‚é€šè¿‡å¼•å…¥ç¤¾ä¼šé“¾å¼æ€è€ƒï¼ˆSoCoTï¼‰æ¨ç†ç®¡é“å’ŒåŠ¨æ€ç¤¾ä¼šè®¤çŸ¥è®°å¿†ï¼ˆDSEMï¼‰æ¨¡å—ï¼Œæ¨¡å‹èƒ½å¤Ÿé€æ­¥æ¨ç†å¹¶è®°å¿†å…³é”®çš„ç¤¾äº¤ä¿¡æ¯ï¼Œä»è€Œæé«˜æ¬ºéª—è¯†åˆ«çš„å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) å¤šæ¨¡æ€è¾“å…¥ç¼–ç å™¨ï¼šç”¨äºå¤„ç†è§†é¢‘å’Œæ–‡æœ¬è¾“å…¥ï¼Œæå–ç›¸å…³çš„ç‰¹å¾è¡¨ç¤ºã€‚2) ç¤¾ä¼šé“¾å¼æ€è€ƒï¼ˆSoCoTï¼‰æ¨ç†ç®¡é“ï¼šå¼•å¯¼æ¨¡å‹é€æ­¥æ¨ç†ç¤¾äº¤äº’åŠ¨ä¸­çš„å…³é”®ä¿¡æ¯ï¼Œä¾‹å¦‚å‚ä¸è€…çš„æ„å›¾ã€ä¿¡å¿µå’ŒçŸ¥è¯†ã€‚3) åŠ¨æ€ç¤¾ä¼šè®¤çŸ¥è®°å¿†ï¼ˆDSEMï¼‰æ¨¡å—ï¼šç”¨äºå­˜å‚¨å’Œæ›´æ–°ç¤¾äº¤äº’åŠ¨ä¸­çš„å…³é”®ä¿¡æ¯ï¼Œä¾‹å¦‚å‚ä¸è€…çš„å…³ç³»ã€å†å²è¡Œä¸ºå’Œå½“å‰çŠ¶æ€ã€‚4) æ¬ºéª—æ£€æµ‹æ¨¡å—ï¼šåŸºäºç¼–ç åçš„ç‰¹å¾å’Œæ¨ç†ç»“æœï¼Œåˆ¤æ–­æ¯ä¸ªé™ˆè¿°çš„çœŸå‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ç¤¾ä¼šé“¾å¼æ€è€ƒï¼ˆSoCoTï¼‰æ¨ç†ç®¡é“å’ŒåŠ¨æ€ç¤¾ä¼šè®¤çŸ¥è®°å¿†ï¼ˆDSEMï¼‰æ¨¡å—ã€‚SoCoTé€šè¿‡å¼•å¯¼æ¨¡å‹é€æ­¥æ¨ç†ï¼Œæ¨¡æ‹Ÿäº†äººç±»åœ¨ç¤¾äº¤äº’åŠ¨ä¸­çš„æ€è€ƒè¿‡ç¨‹ã€‚DSEMåˆ™å…è®¸æ¨¡å‹åŠ¨æ€åœ°å­˜å‚¨å’Œæ›´æ–°ç¤¾äº¤ä¿¡æ¯ï¼Œä»è€Œæ›´å¥½åœ°ç†è§£ç¤¾äº¤äº’åŠ¨ä¸­çš„å¤æ‚åŠ¨æ€ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•æ›´æ³¨é‡å¯¹ç¤¾äº¤çº¿ç´¢çš„å»ºæ¨¡å’Œæ¨ç†ï¼Œè€Œéä»…ä»…ä¾èµ–äºè¡¨é¢çš„è¯­è¨€ç‰¹å¾ã€‚

**å…³é”®è®¾è®¡**ï¼šSoCoTæ¨ç†ç®¡é“çš„è®¾è®¡åŒ…æ‹¬å¤šä¸ªæ¨ç†æ­¥éª¤ï¼Œæ¯ä¸ªæ­¥éª¤éƒ½æ—¨åœ¨æå–ç‰¹å®šçš„ç¤¾äº¤ä¿¡æ¯ã€‚ä¾‹å¦‚ï¼Œç¬¬ä¸€ä¸ªæ­¥éª¤å¯èƒ½å…³æ³¨å‚ä¸è€…çš„æ„å›¾ï¼Œç¬¬äºŒä¸ªæ­¥éª¤å¯èƒ½å…³æ³¨å‚ä¸è€…çš„ä¿¡å¿µã€‚DSEMæ¨¡å—çš„è®¾è®¡åŒ…æ‹¬ä¸€ä¸ªè®°å¿†å•å…ƒå’Œä¸€ä¸ªæ›´æ–°æœºåˆ¶ã€‚è®°å¿†å•å…ƒç”¨äºå­˜å‚¨ç¤¾äº¤ä¿¡æ¯ï¼Œæ›´æ–°æœºåˆ¶ç”¨äºæ ¹æ®æ–°çš„ä¿¡æ¯æ›´æ–°è®°å¿†å•å…ƒã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡åŒ…æ‹¬ä¸€ä¸ªæ¬ºéª—æ£€æµ‹æŸå¤±å’Œä¸€ä¸ªæ¨ç†ä¸€è‡´æ€§æŸå¤±ã€‚æ¬ºéª—æ£€æµ‹æŸå¤±ç”¨äºè®­ç»ƒæ¨¡å‹è¯†åˆ«æ¬ºéª—è¡Œä¸ºï¼Œæ¨ç†ä¸€è‡´æ€§æŸå¤±ç”¨äºé¼“åŠ±æ¨¡å‹è¿›è¡Œä¸€è‡´çš„æ¨ç†ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„SoCoTæ¨ç†ç®¡é“å’ŒDSEMæ¨¡å—èƒ½å¤Ÿæ˜¾è‘—æå‡MLLMsåœ¨MIDAåŸºå‡†ä¸Šçš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨GPT-4oæ¨¡å‹ä¸Šï¼Œä½¿ç”¨SoCoTå’ŒDSEMåï¼Œæ¬ºéª—è¯†åˆ«å‡†ç¡®ç‡æå‡äº†çº¦5%-10%ã€‚æ­¤å¤–ï¼Œå®éªŒè¿˜åˆ†æäº†æ¨¡å‹çš„å¤±è´¥æ¨¡å¼ï¼Œæ­ç¤ºäº†ç°æœ‰MLLMsåœ¨å¤„ç†å¤æ‚ç¤¾äº¤çº¿ç´¢æ–¹é¢çš„ä¸è¶³ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ™ºèƒ½å®¢æœã€åœ¨çº¿ä¼šè®®ã€ç¤¾äº¤åª’ä½“ç›‘æ§ç­‰é¢†åŸŸï¼Œå¸®åŠ©è¯†åˆ«è™šå‡ä¿¡æ¯ã€æ¬ºè¯ˆè¡Œä¸ºå’Œæ¶æ„æ”»å‡»ã€‚é€šè¿‡æå‡AIç³»ç»Ÿåœ¨ç¤¾äº¤äº’åŠ¨ä¸­çš„æ„ŸçŸ¥å’Œæ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥æ„å»ºæ›´å€¼å¾—ä¿¡èµ–å’Œå®‰å…¨çš„AIåº”ç”¨ï¼Œä¾‹å¦‚è‡ªåŠ¨é©¾é©¶ä¸­çš„äººæœºäº¤äº’ï¼Œä»¥åŠåŒ»ç–—è¯Šæ–­ä¸­çš„æƒ…æ„Ÿåˆ†æã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Despite their advanced reasoning capabilities, state-of-the-art Multimodal Large Language Models (MLLMs) demonstrably lack a core component of human intelligence: the ability to `read the room' and assess deception in complex social interactions. To rigorously quantify this failure, we introduce a new task, Multimodal Interactive Deception Assessment (MIDA), and present a novel multimodal dataset providing synchronized video and text with verifiable ground-truth labels for every statement. We establish a comprehensive benchmark evaluating 12 state-of-the-art open- and closed-source MLLMs, revealing a significant performance gap: even powerful models like GPT-4o struggle to distinguish truth from falsehood reliably. Our analysis of failure modes indicates that these models fail to effectively ground language in multimodal social cues and lack the ability to model what others know, believe, or intend, highlighting the urgent need for novel approaches to building more perceptive and trustworthy AI systems. To take a step forward, we design a Social Chain-of-Thought (SoCoT) reasoning pipeline and a Dynamic Social Epistemic Memory (DSEM) module. Our framework yields performance improvement on this challenging task, demonstrating a promising new path toward building MLLMs capable of genuine human-like social reasoning.

