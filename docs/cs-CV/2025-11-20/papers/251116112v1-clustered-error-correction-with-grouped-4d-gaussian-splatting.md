---
layout: default
title: Clustered Error Correction with Grouped 4D Gaussian Splatting
---

# Clustered Error Correction with Grouped 4D Gaussian Splatting

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.16112" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.16112v1</a>
  <a href="https://arxiv.org/pdf/2511.16112.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.16112v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.16112v1', 'Clustered Error Correction with Grouped 4D Gaussian Splatting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Taeho Kang, Jaeyeon Park, Kyungjin Lee, Youngki Lee

**åˆ†ç±»**: cs.CV, cs.GR

**å‘å¸ƒæ—¥æœŸ**: 2025-11-20

**å¤‡æ³¨**: 16 pages, 8 figures, SIGGRAPH Asia Conference Papers 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/tho-kn/cem-4dgs)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºèšç±»è¯¯å·®æ ¡æ­£çš„åˆ†ç»„4Dé«˜æ–¯æº…å°„æ–¹æ³•ï¼Œæå‡åŠ¨æ€åœºæ™¯é‡å»ºè´¨é‡ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `åŠ¨æ€åœºæ™¯é‡å»º` `4Dé«˜æ–¯æº…å°„` `è¯¯å·®æ ¡æ­£` `æ¤­åœ†èšç±»` `æ—¶é—´ä¸€è‡´æ€§` `ç¥ç»æ¸²æŸ“` `ä¸‰ç»´é‡å»º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰4DGSæ–¹æ³•åœ¨åŠ¨æ€åœºæ™¯é‡å»ºä¸­ï¼Œéš¾ä»¥å¤„ç†åƒç´ å¯¹åº”æ¨¡ç³Šå’ŒåŠ¨æ€åŒºåŸŸå¯†åº¦ä¸è¶³çš„é—®é¢˜ã€‚
2. è¯¥æ–¹æ³•é€šè¿‡æ¤­åœ†è¯¯å·®èšç±»æ ¡æ­£å’Œåˆ†ç»„4Dé«˜æ–¯æº…å°„ï¼Œæå‡åŠ¨æ€å¯¹è±¡æ˜ å°„ä¸€è‡´æ€§å’Œé‡å»ºè´¨é‡ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ—¶é—´å’Œæ„ŸçŸ¥æ¸²æŸ“è´¨é‡ä¸Šå‡æœ‰æ˜¾è‘—æå‡ï¼Œå¹¶åœ¨Technicoloræ•°æ®é›†ä¸ŠPSNRæå‡0.39dBã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°æœ‰çš„4Dé«˜æ–¯æº…å°„(4DGS)æ–¹æ³•åœ¨ç²¾ç¡®é‡å»ºåŠ¨æ€åœºæ™¯æ—¶é¢ä¸´æŒ‘æˆ˜ï¼Œå¸¸å¸¸æ— æ³•è§£å†³æ¨¡ç³Šçš„åƒç´ å¯¹åº”å…³ç³»ï¼Œå¹¶ä¸”åœ¨åŠ¨æ€åŒºåŸŸçš„å¯†åº¦ä¸è¶³ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ç”±ä¸¤ä¸ªå…³é”®ç»„ä»¶ç»„æˆï¼š(1)æ¤­åœ†è¯¯å·®èšç±»å’Œè¯¯å·®æ ¡æ­£æº…å°„æ·»åŠ ï¼Œç”¨äºç²¾ç¡®å®šä½åŠ¨æ€åŒºåŸŸä»¥æ”¹è¿›å’Œåˆå§‹åŒ–æ‹Ÿåˆæº…å°„ï¼›(2)åˆ†ç»„4Dé«˜æ–¯æº…å°„ï¼Œç”¨äºæé«˜æº…å°„ä¸æ‰€è¡¨ç¤ºçš„åŠ¨æ€å¯¹è±¡ä¹‹é—´çš„æ˜ å°„ä¸€è‡´æ€§ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†æ¸²æŸ“è¯¯å·®åˆ†ä¸ºç¼ºå¤±é¢œè‰²å’Œé®æŒ¡ç±»å‹ï¼Œç„¶åé€šè¿‡åå‘æŠ•å½±æˆ–äº¤å‰è§†è§’é¢œè‰²ä¸€è‡´æ€§å¼•å¯¼çš„å‰æ™¯åˆ†å‰²è¿›è¡Œæœ‰é’ˆå¯¹æ€§çš„æ ¡æ­£ã€‚åœ¨Neural 3D Videoå’ŒTechnicoloræ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜¾è‘—æé«˜äº†æ—¶é—´ä¸€è‡´æ€§ï¼Œå¹¶å®ç°äº†æœ€å…ˆè¿›çš„æ„ŸçŸ¥æ¸²æŸ“è´¨é‡ï¼Œåœ¨Technicolor Light Fieldæ•°æ®é›†ä¸Šæé«˜äº†0.39dBçš„PSNRã€‚æˆ‘ä»¬çš„å¯è§†åŒ–ç»“æœæ˜¾ç¤ºäº†æº…å°„ä¸åŠ¨æ€å¯¹è±¡ä¹‹é—´æ›´å¥½çš„å¯¹é½ï¼Œä»¥åŠè¯¯å·®æ ¡æ­£æ–¹æ³•è¯†åˆ«è¯¯å·®å¹¶æ­£ç¡®åˆå§‹åŒ–æ–°æº…å°„çš„èƒ½åŠ›ã€‚æˆ‘ä»¬çš„å®ç°ç»†èŠ‚å’Œæºä»£ç å¯åœ¨https://github.com/tho-kn/cem-4dgs è·å¾—ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰4Dé«˜æ–¯æº…å°„æ–¹æ³•åœ¨åŠ¨æ€åœºæ™¯é‡å»ºä¸­ï¼Œç”±äºåŠ¨æ€åŒºåŸŸçš„å¤æ‚æ€§å’Œè¿åŠ¨æ¨¡ç³Šï¼Œå¸¸å¸¸å‡ºç°åƒç´ å¯¹åº”å…³ç³»ä¸æ˜ç¡®ä»¥åŠåŠ¨æ€åŒºåŸŸå¯†åº¦ä¸è¶³çš„é—®é¢˜ã€‚è¿™å¯¼è‡´é‡å»ºç»“æœåœ¨æ—¶é—´ä¸€è‡´æ€§å’Œè§†è§‰è´¨é‡ä¸Šè¡¨ç°ä¸ä½³ï¼Œå°¤å…¶æ˜¯åœ¨å¿«é€Ÿè¿åŠ¨æˆ–é®æŒ¡é¢‘ç¹çš„åŒºåŸŸã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè¯¥è®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è¯¯å·®åˆ†æå’Œé’ˆå¯¹æ€§çš„æ ¡æ­£æ¥æ”¹å–„åŠ¨æ€åŒºåŸŸçš„é‡å»ºè´¨é‡ã€‚å…·ä½“æ¥è¯´ï¼Œé¦–å…ˆå¯¹æ¸²æŸ“è¯¯å·®è¿›è¡Œåˆ†ç±»ï¼Œç„¶ååˆ©ç”¨èšç±»ç®—æ³•å®šä½è¯¯å·®é›†ä¸­çš„åŒºåŸŸï¼Œå¹¶æ ¹æ®è¯¯å·®ç±»å‹é‡‡å–ä¸åŒçš„æ ¡æ­£ç­–ç•¥ï¼Œä¾‹å¦‚æ·»åŠ æ–°çš„é«˜æ–¯æº…å°„æˆ–è°ƒæ•´ç°æœ‰æº…å°„çš„å‚æ•°ã€‚æ­¤å¤–ï¼Œé€šè¿‡åˆ†ç»„4Dé«˜æ–¯æº…å°„ï¼Œå¢å¼ºæº…å°„ä¸åŠ¨æ€å¯¹è±¡ä¹‹é—´çš„æ˜ å°„å…³ç³»ï¼Œæé«˜æ—¶é—´ä¸€è‡´æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•ä¸»è¦åŒ…å«ä¸¤ä¸ªé˜¶æ®µï¼š(1) æ¤­åœ†è¯¯å·®èšç±»å’Œè¯¯å·®æ ¡æ­£æº…å°„æ·»åŠ ï¼šé¦–å…ˆå°†æ¸²æŸ“è¯¯å·®åˆ†ä¸ºç¼ºå¤±é¢œè‰²å’Œé®æŒ¡ä¸¤ç§ç±»å‹ã€‚ç„¶åï¼Œåˆ©ç”¨æ¤­åœ†èšç±»ç®—æ³•å°†è¯¯å·®åƒç´ åˆ†ç»„ï¼Œå¹¶æ ¹æ®è¯¯å·®ç±»å‹é€‰æ‹©åˆé€‚çš„æ ¡æ­£ç­–ç•¥ï¼Œä¾‹å¦‚é€šè¿‡åå‘æŠ•å½±åˆå§‹åŒ–æ–°çš„æº…å°„ï¼Œæˆ–è€…é€šè¿‡å‰æ™¯åˆ†å‰²è°ƒæ•´ç°æœ‰æº…å°„ã€‚ (2) åˆ†ç»„4Dé«˜æ–¯æº…å°„ï¼šé€šè¿‡åˆ†ç»„ç­–ç•¥ï¼Œå°†é«˜æ–¯æº…å°„ä¸åŠ¨æ€å¯¹è±¡è¿›è¡Œå…³è”ï¼Œä»è€Œæé«˜æ—¶é—´ä¸€è‡´æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºè¯¯å·®èšç±»å’Œé’ˆå¯¹æ€§æ ¡æ­£ç­–ç•¥ã€‚é€šè¿‡å¯¹æ¸²æŸ“è¯¯å·®è¿›è¡Œåˆ†ç±»å’Œèšç±»ï¼Œèƒ½å¤Ÿæ›´ç²¾ç¡®åœ°å®šä½éœ€è¦æ”¹è¿›çš„åŒºåŸŸï¼Œå¹¶æ ¹æ®è¯¯å·®ç±»å‹é€‰æ‹©åˆé€‚çš„æ ¡æ­£æ–¹æ³•ï¼Œé¿å…äº†ç›²ç›®åœ°å¢åŠ æº…å°„æ•°é‡ï¼Œæé«˜äº†é‡å»ºæ•ˆç‡å’Œè´¨é‡ã€‚æ­¤å¤–ï¼Œåˆ†ç»„4Dé«˜æ–¯æº…å°„ä¹Ÿæœ‰åŠ©äºæé«˜æ—¶é—´ä¸€è‡´æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è¯¯å·®èšç±»æ–¹é¢ï¼Œé‡‡ç”¨äº†æ¤­åœ†èšç±»ç®—æ³•ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”åŠ¨æ€åŒºåŸŸçš„å½¢çŠ¶ã€‚åœ¨è¯¯å·®æ ¡æ­£æ–¹é¢ï¼Œæ ¹æ®è¯¯å·®ç±»å‹ï¼ˆç¼ºå¤±é¢œè‰²æˆ–é®æŒ¡ï¼‰é€‰æ‹©ä¸åŒçš„ç­–ç•¥ï¼Œä¾‹å¦‚å¯¹äºç¼ºå¤±é¢œè‰²è¯¯å·®ï¼Œé‡‡ç”¨åå‘æŠ•å½±åˆå§‹åŒ–æ–°çš„æº…å°„ï¼›å¯¹äºé®æŒ¡è¯¯å·®ï¼Œé‡‡ç”¨å‰æ™¯åˆ†å‰²è°ƒæ•´ç°æœ‰æº…å°„ã€‚åœ¨åˆ†ç»„4Dé«˜æ–¯æº…å°„æ–¹é¢ï¼Œå…·ä½“çš„åˆ†ç»„ç­–ç•¥å’ŒæŸå¤±å‡½æ•°çš„è®¾è®¡æ˜¯æé«˜æ—¶é—´ä¸€è‡´æ€§çš„å…³é”®ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥æ–¹æ³•åœ¨Neural 3D Videoå’ŒTechnicoloræ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æé«˜äº†æ—¶é—´ä¸€è‡´æ€§å’Œæ„ŸçŸ¥æ¸²æŸ“è´¨é‡ã€‚ç‰¹åˆ«æ˜¯åœ¨Technicolor Light Fieldæ•°æ®é›†ä¸Šï¼ŒPSNRæŒ‡æ ‡æå‡äº†0.39dBï¼Œè¯æ˜äº†è¯¥æ–¹æ³•åœ¨åŠ¨æ€åœºæ™¯é‡å»ºæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚å¯è§†åŒ–ç»“æœä¹Ÿæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°å¯¹é½æº…å°„ä¸åŠ¨æ€å¯¹è±¡ï¼Œå¹¶æœ‰æ•ˆåœ°è¯†åˆ«å’Œæ ¡æ­£æ¸²æŸ“è¯¯å·®ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºåŠ¨æ€åœºæ™¯çš„ä¸‰ç»´é‡å»ºã€è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œå¯ä»¥ç”¨äºåˆ›å»ºæ›´é€¼çœŸçš„è™šæ‹Ÿäººç‰©ï¼Œæˆ–è€…æé«˜è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿå¯¹åŠ¨æ€ç¯å¢ƒçš„æ„ŸçŸ¥èƒ½åŠ›ã€‚è¯¥æ–¹æ³•åœ¨åŠ¨æ€åœºæ™¯é‡å»ºæ–¹é¢çš„æå‡ï¼Œæœ‰åŠ©äºç›¸å…³åº”ç”¨è·å¾—æ›´å¥½çš„ç”¨æˆ·ä½“éªŒå’Œæ›´é«˜çš„æ€§èƒ½ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Existing 4D Gaussian Splatting (4DGS) methods struggle to accurately reconstruct dynamic scenes, often failing to resolve ambiguous pixel correspondences and inadequate densification in dynamic regions. We address these issues by introducing a novel method composed of two key components: (1) Elliptical Error Clustering and Error Correcting Splat Addition that pinpoints dynamic areas to improve and initialize fitting splats, and (2) Grouped 4D Gaussian Splatting that improves consistency of mapping between splats and represented dynamic objects. Specifically, we classify rendering errors into missing-color and occlusion types, then apply targeted corrections via backprojection or foreground splitting guided by cross-view color consistency. Evaluations on Neural 3D Video and Technicolor datasets demonstrate that our approach significantly improves temporal consistency and achieves state-of-the-art perceptual rendering quality, improving 0.39dB of PSNR on the Technicolor Light Field dataset. Our visualization shows improved alignment between splats and dynamic objects, and the error correction method's capability to identify errors and properly initialize new splats. Our implementation details and source code are available at https://github.com/tho-kn/cem-4dgs.

