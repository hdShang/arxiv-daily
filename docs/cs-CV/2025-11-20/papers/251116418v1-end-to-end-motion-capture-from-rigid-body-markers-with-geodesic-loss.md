---
layout: default
title: End-to-End Motion Capture from Rigid Body Markers with Geodesic Loss
---

# End-to-End Motion Capture from Rigid Body Markers with Geodesic Loss

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.16418" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.16418v1</a>
  <a href="https://arxiv.org/pdf/2511.16418.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.16418v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.16418v1', 'End-to-End Motion Capture from Rigid Body Markers with Geodesic Loss')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hai Lan, Zongyan Li, Jianmin Hu, Jialing Yang, Houde Dai

**åˆ†ç±»**: cs.CV, cs.HC

**å‘å¸ƒæ—¥æœŸ**: 2025-11-20

**å¤‡æ³¨**: The source code is available in : https://github.com/wer010/GLRBM-Mocap

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºåˆšä½“æ ‡è®°å’Œæµ‹åœ°çº¿æŸå¤±çš„ç«¯åˆ°ç«¯äººä½“è¿åŠ¨æ•æ‰æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)** **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction & Matching)**

**å…³é”®è¯**: `è¿åŠ¨æ•æ‰` `åˆšä½“æ ‡è®°` `æ·±åº¦å­¦ä¹ ` `SMPLæ¨¡å‹` `æµ‹åœ°çº¿æŸå¤±`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿå…‰å­¦è¿åŠ¨æ•æ‰ä¾èµ–å¯†é›†æ ‡è®°ç‚¹é…ç½®ï¼Œå‡†å¤‡è€—æ—¶ä¸”æ ‡è®°ç‚¹æ˜“æ··æ·†ï¼Œé™åˆ¶äº†å…¶å¯æ‰©å±•æ€§ã€‚
2. æå‡ºä½¿ç”¨åˆšä½“æ ‡è®°ï¼ˆRBMï¼‰ä½œä¸ºåŸºæœ¬å•å…ƒï¼Œæä¾›æ˜ç¡®çš„6è‡ªç”±åº¦æ•°æ®ï¼Œç®€åŒ–è®¾ç½®ã€‚
3. å¼€å‘åŸºäºæ·±åº¦å­¦ä¹ çš„ç«¯åˆ°ç«¯æ¨¡å‹ï¼Œç»“åˆæµ‹åœ°çº¿æŸå¤±ç›´æ¥å›å½’SMPLå‚æ•°ï¼Œè®¡ç®—æ•ˆç‡é«˜ä¸”ç²¾åº¦é«˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„è¿åŠ¨æ•æ‰ï¼ˆMoCapï¼‰åŸºæœ¬å•å…ƒâ€”â€”åˆšä½“æ ‡è®°ï¼ˆRBMï¼‰ï¼Œå®ƒæä¾›æ˜ç¡®çš„6è‡ªç”±åº¦æ•°æ®ï¼Œå¹¶æ˜¾è‘—ç®€åŒ–è®¾ç½®ã€‚é’ˆå¯¹ä¼ ç»ŸåŸºäºæ ‡è®°ç‚¹çš„å…‰å­¦è¿åŠ¨æ•æ‰ç³»ç»Ÿå‡†å¤‡è€—æ—¶ã€æ ‡è®°ç‚¹è¯†åˆ«æ˜“æ··æ·†ç­‰é—®é¢˜ï¼Œæœ¬æ–‡å¼€å‘äº†ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ çš„å›å½’æ¨¡å‹ï¼Œè¯¥æ¨¡å‹åœ¨æµ‹åœ°çº¿æŸå¤±ä¸‹ç›´æ¥ä¼°è®¡SMPLå‚æ•°ã€‚è¿™ç§ç«¯åˆ°ç«¯æ–¹æ³•åœ¨æ€§èƒ½ä¸Šä¸åŸºäºä¼˜åŒ–çš„æ–¹æ³•ç›¸åŒ¹é…ï¼Œä½†è®¡ç®—é‡å‡å°‘äº†ä¸€ä¸ªæ•°é‡çº§ä»¥ä¸Šã€‚è¯¥æ¨¡å‹åœ¨ä»AMASSæ•°æ®é›†åˆæˆçš„æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œåœ¨äººä½“å§¿æ€ä¼°è®¡æ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„ç²¾åº¦ã€‚ä½¿ç”¨Viconå…‰å­¦è·Ÿè¸ªç³»ç»Ÿæ•è·çš„çœŸå®ä¸–ç•Œæ•°æ®è¿›ä¸€æ­¥è¯æ˜äº†è¯¥æ–¹æ³•åœ¨å®é™…ä¸­çš„å¯è¡Œæ€§ã€‚æ€»ä½“è€Œè¨€ï¼Œç»“æœè¡¨æ˜ï¼Œå°†ç¨€ç–çš„6è‡ªç”±åº¦RBMä¸æµå½¢æ„ŸçŸ¥çš„æµ‹åœ°çº¿æŸå¤±ç›¸ç»“åˆï¼Œå¯ä»¥ä¸ºå›¾å½¢ã€è™šæ‹Ÿç°å®å’Œç”Ÿç‰©åŠ›å­¦ä¸­çš„å®æ—¶MoCapæä¾›å®ç”¨ä¸”é«˜ä¿çœŸçš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šä¼ ç»ŸåŸºäºæ ‡è®°ç‚¹çš„å…‰å­¦è¿åŠ¨æ•æ‰ç³»ç»Ÿéœ€è¦å¯†é›†çš„æ ‡è®°ç‚¹é…ç½®ï¼Œå¯¼è‡´å‡†å¤‡å·¥ä½œè€—æ—¶ï¼Œä¸”åœ¨è¿åŠ¨è¿‡ç¨‹ä¸­å®¹æ˜“å‡ºç°æ ‡è®°ç‚¹è¯†åˆ«çš„æ­§ä¹‰ï¼Œè¿™ä¸¥é‡é™åˆ¶äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å¯æ‰©å±•æ€§ã€‚ç°æœ‰çš„ä¼˜åŒ–æ–¹æ³•è™½ç„¶ç²¾åº¦è¾ƒé«˜ï¼Œä½†è®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œéš¾ä»¥æ»¡è¶³å®æ—¶æ€§éœ€æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨åˆšä½“æ ‡è®°ï¼ˆRBMï¼‰ä½œä¸ºè¿åŠ¨æ•æ‰çš„åŸºæœ¬å•å…ƒï¼Œæ¯ä¸ªRBMæä¾›æ˜ç¡®çš„6è‡ªç”±åº¦æ•°æ®ï¼Œä»è€Œå‡å°‘äº†å¯¹å¯†é›†æ ‡è®°ç‚¹é…ç½®çš„ä¾èµ–ï¼Œç®€åŒ–äº†è®¾ç½®è¿‡ç¨‹ã€‚åŒæ—¶ï¼Œé‡‡ç”¨æ·±åº¦å­¦ä¹ æ–¹æ³•ç›´æ¥ä»RBMæ•°æ®å›å½’SMPLå‚æ•°ï¼Œé¿å…äº†ä¼ ç»Ÿä¼˜åŒ–æ–¹æ³•çš„è¿­ä»£è¿‡ç¨‹ï¼Œæé«˜äº†è®¡ç®—æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•é‡‡ç”¨ç«¯åˆ°ç«¯çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚è¾“å…¥æ˜¯æ¥è‡ªRBMçš„6è‡ªç”±åº¦æ•°æ®ï¼Œè¾“å‡ºæ˜¯SMPLæ¨¡å‹å‚æ•°ã€‚æ•´ä¸ªæµç¨‹åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€ç¥ç»ç½‘ç»œæ¨¡å‹å’ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚æ•°æ®é¢„å¤„ç†é˜¶æ®µå°†RBMæ•°æ®è½¬æ¢ä¸ºé€‚åˆç¥ç»ç½‘ç»œè¾“å…¥çš„æ ¼å¼ã€‚ç¥ç»ç½‘ç»œæ¨¡å‹è´Ÿè´£ä»RBMæ•°æ®ä¸­æå–ç‰¹å¾å¹¶å›å½’SMPLå‚æ•°ã€‚æŸå¤±å‡½æ•°ç”¨äºè¡¡é‡é¢„æµ‹çš„SMPLå‚æ•°ä¸çœŸå®å€¼ä¹‹é—´çš„å·®è·ï¼Œå¹¶æŒ‡å¯¼ç½‘ç»œè®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†åˆšä½“æ ‡è®°ï¼ˆRBMï¼‰å¼•å…¥è¿åŠ¨æ•æ‰é¢†åŸŸï¼Œå¹¶ç»“åˆæµå½¢æ„ŸçŸ¥çš„æµ‹åœ°çº¿æŸå¤±å‡½æ•°ã€‚RBMçš„ä½¿ç”¨å‡å°‘äº†å¯¹å¯†é›†æ ‡è®°ç‚¹é…ç½®çš„ä¾èµ–ï¼Œç®€åŒ–äº†è®¾ç½®è¿‡ç¨‹ã€‚æµ‹åœ°çº¿æŸå¤±å‡½æ•°èƒ½å¤Ÿæ›´å¥½åœ°çº¦æŸSMPLå‚æ•°çš„è§£ç©ºé—´ï¼Œæé«˜å§¿æ€ä¼°è®¡çš„ç²¾åº¦ã€‚ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºï¼Œè¯¥æ–¹æ³•é‡‡ç”¨ç«¯åˆ°ç«¯çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œé¿å…äº†ä¼ ç»Ÿä¼˜åŒ–æ–¹æ³•çš„è¿­ä»£è¿‡ç¨‹ï¼Œæé«˜äº†è®¡ç®—æ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šè¯¥æ–¹æ³•ä½¿ç”¨ä»AMASSæ•°æ®é›†åˆæˆçš„æ•°æ®è¿›è¡Œè®­ç»ƒã€‚æŸå¤±å‡½æ•°é‡‡ç”¨æµ‹åœ°çº¿æŸå¤±ï¼Œä»¥æ›´å¥½åœ°çº¦æŸSMPLå‚æ•°çš„è§£ç©ºé—´ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„æœªçŸ¥ï¼Œä½†å¯ä»¥æ¨æ–­å…¶ä¸ºä¸€ä¸ªå›å½’ç½‘ç»œï¼Œç”¨äºå°†RBMæ•°æ®æ˜ å°„åˆ°SMPLå‚æ•°ç©ºé—´ã€‚RBMçš„å…·ä½“é…ç½®ï¼ˆæ•°é‡ã€ä½ç½®ç­‰ï¼‰ä¹Ÿæ˜¯ä¸€ä¸ªé‡è¦çš„è®¾è®¡å‚æ•°ï¼Œéœ€è¦åœ¨å®é™…åº”ç”¨ä¸­è¿›è¡Œè°ƒæ•´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥æ–¹æ³•åœ¨åˆæˆæ•°æ®é›†ä¸Šè¿›è¡Œäº†è®­ç»ƒï¼Œå¹¶åœ¨çœŸå®ä¸–ç•Œæ•°æ®ä¸Šè¿›è¡Œäº†éªŒè¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨äººä½“å§¿æ€ä¼°è®¡æ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„ç²¾åº¦ï¼ŒåŒæ—¶è®¡ç®—é‡æ¯”åŸºäºä¼˜åŒ–çš„æ–¹æ³•å‡å°‘äº†ä¸€ä¸ªæ•°é‡çº§ä»¥ä¸Šã€‚è¿™è¡¨æ˜è¯¥æ–¹æ³•åœ¨å®é™…åº”ç”¨ä¸­å…·æœ‰å¾ˆé«˜çš„å¯è¡Œæ€§å’Œæ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºå›¾å½¢å­¦ã€è™šæ‹Ÿç°å®ã€ç”Ÿç‰©åŠ›å­¦ç­‰é¢†åŸŸã€‚åœ¨å›¾å½¢å­¦ä¸­ï¼Œå¯ç”¨äºå®æ—¶äººä½“åŠ¨ç”»çš„ç”Ÿæˆã€‚åœ¨è™šæ‹Ÿç°å®ä¸­ï¼Œå¯ç”¨äºç”¨æˆ·åŠ¨ä½œçš„å®æ—¶æ•æ‰å’Œäº¤äº’ã€‚åœ¨ç”Ÿç‰©åŠ›å­¦ä¸­ï¼Œå¯ç”¨äºäººä½“è¿åŠ¨åˆ†æå’Œåº·å¤è®­ç»ƒã€‚è¯¥æ–¹æ³•å…·æœ‰è®¾ç½®ç®€å•ã€ç²¾åº¦é«˜ã€è®¡ç®—æ•ˆç‡é«˜ç­‰ä¼˜ç‚¹ï¼Œæœ‰æœ›æ¨åŠ¨è¿åŠ¨æ•æ‰æŠ€æœ¯åœ¨å„ä¸ªé¢†åŸŸçš„æ™®åŠå’Œåº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Marker-based optical motion capture (MoCap), while long regarded as the gold standard for accuracy, faces practical challenges, such as time-consuming preparation and marker identification ambiguity, due to its reliance on dense marker configurations, which fundamentally limit its scalability. To address this, we introduce a novel fundamental unit for MoCap, the Rigid Body Marker (RBM), which provides unambiguous 6-DoF data and drastically simplifies setup. Leveraging this new data modality, we develop a deep-learning-based regression model that directly estimates SMPL parameters under a geodesic loss. This end-to-end approach matches the performance of optimization-based methods while requiring over an order of magnitude less computation. Trained on synthesized data from the AMASS dataset, our end-to-end model achieves state-of-the-art accuracy in body pose estimation. Real-world data captured using a Vicon optical tracking system further demonstrates the practical viability of our approach. Overall, the results show that combining sparse 6-DoF RBM with a manifold-aware geodesic loss yields a practical and high-fidelity solution for real-time MoCap in graphics, virtual reality, and biomechanics.

