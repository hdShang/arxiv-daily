---
layout: default
title: Benchmarking Graph Neural Networks for Document Layout Analysis in Public Affairs
---

# Benchmarking Graph Neural Networks for Document Layout Analysis in Public Affairs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14699" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14699v2</a>
  <a href="https://arxiv.org/pdf/2505.14699.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14699v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14699v2', 'Benchmarking Graph Neural Networks for Document Layout Analysis in Public Affairs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Miguel Lopez-Duran, Julian Fierrez, Aythami Morales, Ruben Tolosana, Oscar Delgado-Mohatar, Alvaro Ortigosa

**åˆ†ç±»**: cs.CV, cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-12 (æ›´æ–°: 2025-07-28)

**å¤‡æ³¨**: 15 pages, 2 figures, accepted paper at The Fifth ICDAR International Workshop on Machine Learning

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åŸºäºå›¾ç¥ç»ç½‘ç»œçš„æ–‡æ¡£å¸ƒå±€åˆ†ææ–¹æ³•æå‡å…¬å…±äº‹åŠ¡æ–‡æ¡£å¤„ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å›¾ç¥ç»ç½‘ç»œ` `æ–‡æ¡£å¸ƒå±€åˆ†æ` `å¤šæ¨¡æ€èåˆ` `è‡ªåŠ¨åŒ–å¤„ç†` `å…¬å…±äº‹åŠ¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤„ç†æ•°å­—åŸç”ŸPDFæ–‡æ¡£æ—¶ï¼Œé¢ä¸´å¸ƒå±€å…ƒç´ å¼‚æ„æ€§å’Œæ–‡æœ¬å…ƒæ•°æ®ä¸ç²¾ç¡®çš„é—®é¢˜ï¼Œå¯¼è‡´è‡ªåŠ¨åˆ†ææ•ˆæœä¸ä½³ã€‚
2. æœ¬æ–‡æå‡ºåŸºäºå›¾ç¥ç»ç½‘ç»œçš„å¸ƒå±€åˆ†ç±»æ–¹æ³•ï¼Œåˆ©ç”¨k-æœ€è¿‘é‚»å›¾å’Œå…¨è¿æ¥å›¾æ„å»ºç»“æ„ï¼Œç»“åˆé¢„è®­ç»ƒæ¨¡å‹ç”ŸæˆèŠ‚ç‚¹ç‰¹å¾ï¼Œå‡å°‘æ‰‹åŠ¨ç‰¹å¾å·¥ç¨‹çš„éœ€æ±‚ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGraphSAGEåœ¨åŒåˆ†æ”¯é…ç½®ä¸‹çš„k-æœ€è¿‘é‚»å›¾å®ç°äº†æœ€é«˜çš„åˆ†ç±»å‡†ç¡®ç‡ï¼Œéƒ¨åˆ†æ¥æºè¶…è¶Šäº†åŸºçº¿ï¼Œå¼ºè°ƒäº†å±€éƒ¨å¸ƒå±€å…³ç³»å’Œå¤šæ¨¡æ€èåˆçš„é‡è¦æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ•°å­—åŸç”ŸPDFæ–‡æ¡£çš„è‡ªåŠ¨å¸ƒå±€åˆ†æå› æ–‡æœ¬ä¸éæ–‡æœ¬å…ƒç´ çš„å¼‚æ„æ’åˆ—ä»¥åŠæ–‡æœ¬å…ƒæ•°æ®çš„ä¸ç²¾ç¡®æ€§è€Œé¢ä¸´æŒ‘æˆ˜ã€‚æœ¬æ–‡åŸºäºå›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰æ¶æ„ï¼Œå¯¹æ–‡æœ¬å—è¿›è¡Œç»†ç²’åº¦å¸ƒå±€åˆ†ç±»ã€‚æˆ‘ä»¬å¼•å…¥äº†k-æœ€è¿‘é‚»å›¾å’Œå…¨è¿æ¥å›¾ä¸¤ç§å›¾æ„å»ºç»“æ„ï¼Œé€šè¿‡é¢„è®­ç»ƒçš„æ–‡æœ¬å’Œè§†è§‰æ¨¡å‹ç”ŸæˆèŠ‚ç‚¹ç‰¹å¾ï¼Œé¿å…äº†æ‰‹åŠ¨ç‰¹å¾å·¥ç¨‹ã€‚å®éªŒåœ¨åŒ…å«è¶…è¿‡20ä¸ªæ¥æºã€37K PDFæ–‡æ¡£å’Œ441Ké¡µé¢çš„å…¬å…±äº‹åŠ¡æ–‡æ¡£æ•°æ®é›†ä¸Šè¿›è¡Œï¼Œç»“æœè¡¨æ˜ï¼ŒGraphSAGEåœ¨k-æœ€è¿‘é‚»å›¾çš„åŒåˆ†æ”¯é…ç½®ä¸‹ï¼Œè¾¾åˆ°äº†æœ€é«˜çš„åˆ†ç±»å‡†ç¡®ç‡ï¼ŒéªŒè¯äº†å±€éƒ¨å¸ƒå±€å…³ç³»å’Œå¤šæ¨¡æ€èåˆåœ¨æ•°å­—æ–‡æ¡£å¸ƒå±€åˆ†æä¸­çš„é‡è¦æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ•°å­—åŸç”ŸPDFæ–‡æ¡£çš„è‡ªåŠ¨å¸ƒå±€åˆ†æé—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¼‚æ„å¸ƒå±€å’Œä¸ç²¾ç¡®å…ƒæ•°æ®æ—¶æ•ˆæœä¸ç†æƒ³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰æ¶æ„ï¼Œåˆ©ç”¨k-æœ€è¿‘é‚»å›¾å’Œå…¨è¿æ¥å›¾çš„æ„å»ºæ–¹å¼ï¼Œç»“åˆé¢„è®­ç»ƒæ¨¡å‹ç”ŸæˆèŠ‚ç‚¹ç‰¹å¾ï¼Œä»¥å‡å°‘æ‰‹åŠ¨ç‰¹å¾å·¥ç¨‹çš„å¤æ‚æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å›¾æ„å»ºã€èŠ‚ç‚¹ç‰¹å¾ç”Ÿæˆå’Œå¤šæ¨¡æ€èåˆä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼Œåˆ†åˆ«å¤„ç†æ–‡æœ¬å’Œè§†è§‰ä¿¡æ¯ï¼Œæœ€ç»ˆå®ç°ç»†ç²’åº¦å¸ƒå±€åˆ†ç±»ã€‚

**å…³é”®åˆ›æ–°**ï¼šå¼•å…¥äº†k-æœ€è¿‘é‚»å›¾å’Œå…¨è¿æ¥å›¾çš„æ„å»ºæ–¹å¼ï¼Œå¹¶é€šè¿‡åŒåˆ†æ”¯é…ç½®çš„GNNæ¨¡å‹å®ç°äº†æ›´é«˜çš„åˆ†ç±»å‡†ç¡®ç‡ï¼Œæ˜¾è‘—æå‡äº†å¸ƒå±€åˆ†æçš„æ•ˆæœã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨äº†GraphSAGEä½œä¸ºåŸºç¡€æ¨¡å‹ï¼Œè®¾ç½®äº†ä¸åŒçš„å›¾ç»“æ„å’Œç‰¹å¾ç”Ÿæˆæ–¹å¼ï¼Œä½¿ç”¨äº†å¤šæ¨¡æ€èåˆç­–ç•¥ä»¥ä¼˜åŒ–æ¨¡å‹æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒGraphSAGEåœ¨k-æœ€è¿‘é‚»å›¾çš„åŒåˆ†æ”¯é…ç½®ä¸‹ï¼Œè¾¾åˆ°äº†æœ€é«˜çš„åˆ†ç±»å‡†ç¡®ç‡ï¼Œéƒ¨åˆ†æ¥æºçš„æ€§èƒ½è¶…è¶Šäº†åŸºçº¿ï¼Œæ˜¾ç¤ºå‡ºå±€éƒ¨å¸ƒå±€å…³ç³»å’Œå¤šæ¨¡æ€èåˆçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å…¬å…±äº‹åŠ¡æ–‡æ¡£çš„è‡ªåŠ¨åŒ–å¤„ç†ã€ä¿¡æ¯æå–å’Œæ•°å­—åŒ–å½’æ¡£ç­‰ã€‚é€šè¿‡æå‡æ–‡æ¡£å¸ƒå±€åˆ†æçš„å‡†ç¡®æ€§ï¼Œå¯ä»¥æœ‰æ•ˆæ”¯æŒæ”¿åºœå’Œå…¬å…±æœºæ„çš„ä¿¡æ¯ç®¡ç†ä¸æœåŠ¡ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ™ºèƒ½æ–‡æ¡£å¤„ç†æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The automatic analysis of document layouts in digital-born PDF documents remains a challenging problem due to the heterogeneous arrangement of textual and nontextual elements and the imprecision of the textual metadata in the Portable Document Format. In this work, we benchmark Graph Neural Network (GNN) architectures for the task of fine-grained layout classification of text blocks from digital native documents. We introduce two graph construction structures: a k-closest-neighbor graph and a fully connected graph, and generate node features via pre-trained text and vision models, thus avoiding manual feature engineering. Three experimental frameworks are evaluated: single-modality (text or visual), concatenated multimodal, and dual-branch multimodal. We evaluated four foundational GNN models and compared them with the baseline. Our experiments are specifically conducted on a rich dataset of public affairs documents that includes more than 20 sources (e.g., regional and national-level official gazettes), 37K PDF documents, with 441K pages in total. Our results demonstrate that GraphSAGE operating on the k-closest-neighbor graph in a dual-branch configuration achieves the highest per-class and overall accuracy, outperforming the baseline in some sources. These findings confirm the importance of local layout relationships and multimodal fusion exploited through GNNs for the analysis of native digital document layouts.

