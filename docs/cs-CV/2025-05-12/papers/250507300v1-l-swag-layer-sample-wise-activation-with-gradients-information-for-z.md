---
layout: default
title: "L-SWAG: Layer-Sample Wise Activation with Gradients information for Zero-Shot NAS on Vision Transformers"
---

# L-SWAG: Layer-Sample Wise Activation with Gradients information for Zero-Shot NAS on Vision Transformers

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.07300" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.07300v1</a>
  <a href="https://arxiv.org/pdf/2505.07300.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.07300v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.07300v1', 'L-SWAG: Layer-Sample Wise Activation with Gradients information for Zero-Shot NAS on Vision Transformers')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Sofia Casarin, Sergio Escalera, Oswald Lanz

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-12

**Â§áÊ≥®**: accepted at CVPR 2025

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫L-SWAG‰ª•Ëß£ÂÜ≥Èõ∂ÊàêÊú¨Á•ûÁªèÊû∂ÊûÑÊêúÁ¥¢Âú®ËßÜËßâÂèòÊç¢Âô®‰∏≠ÁöÑÂ∫îÁî®ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Èõ∂ÊàêÊú¨Á•ûÁªèÊû∂ÊûÑÊêúÁ¥¢` `ËßÜËßâÂèòÊç¢Âô®` `L-SWAG` `LIBRA-NAS` `Ê∑±Â∫¶Â≠¶‰π†` `Ëá™Âä®ÂåñÊ®°ÂûãËÆæËÆ°` `ËÆ°ÁÆóÊú∫ËßÜËßâ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÈõ∂ÊàêÊú¨Á•ûÁªèÊû∂ÊûÑÊêúÁ¥¢ÊñπÊ≥ï‰∏ªË¶ÅÂ±ÄÈôê‰∫éÂç∑ÁßØÁΩëÁªúÔºåÁº∫‰πèÂØπËßÜËßâÂèòÊç¢Âô®ÁöÑÊúâÊïàÊîØÊåÅ„ÄÇ
2. Êú¨ÊñáÊèêÂá∫L-SWAGÂ∫¶ÈáèÔºåËÉΩÂ§üÂêåÊó∂Ë°®ÂæÅÂç∑ÁßØÂíåÂèòÊç¢Âô®Êû∂ÊûÑÔºåÊâ©Â±ï‰∫ÜZC-NASÁöÑÈÄÇÁî®ËåÉÂõ¥„ÄÇ
3. ÈÄöËøáLIBRA-NASÊñπÊ≥ïÔºåÁªìÂêà‰∏çÂêå‰ª£ÁêÜÁöÑ‰ø°ÊÅØÔºåÊòæËëóÊèêÂçá‰∫ÜNASÁöÑÊÄßËÉΩÔºåÂú®ImageNet1k‰∏äÂÆûÁé∞‰∫Ü17.0%ÁöÑÊµãËØïËØØÂ∑Æ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËÆ≠ÁªÉÊó†ÂÖ≥ÁöÑÁ•ûÁªèÊû∂ÊûÑÊêúÁ¥¢ÔºàNASÔºâÊúâÊïàËØÜÂà´È´òÊÄßËÉΩÁ•ûÁªèÁΩëÁªúÔºåÂà©Áî®Èõ∂ÊàêÊú¨ÔºàZCÔºâ‰ª£ÁêÜÂÆûÁé∞Êó∂Èó¥ÊïàÁéáÂíåÂèØËß£ÈáäÊÄß„ÄÇÂ∞ΩÁÆ°ËØ•È¢ÜÂüüËøÖÈÄüÂèëÂ±ïÔºåÂΩìÂâçÁöÑÊúÄÂÖàËøõZC‰ª£ÁêÜÈÄöÂ∏∏Â±ÄÈôê‰∫éÊàêÁÜüÁöÑÂç∑ÁßØÊêúÁ¥¢Á©∫Èó¥„ÄÇÊú¨ÊñáÂ∞ÜZC‰ª£ÁêÜÁöÑÈÄÇÁî®ÊÄßÊâ©Â±ïÂà∞ËßÜËßâÂèòÊç¢Âô®ÔºàViTsÔºâÔºåÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÂü∫ÂáÜÔºå‰ΩøÁî®AutoformerÊêúÁ¥¢Á©∫Èó¥Âú®ÂÖ≠‰∏™‰∏çÂêå‰ªªÂä°‰∏äËøõË°åËØÑ‰º∞ÔºåÂπ∂ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÈÄöÁî®Â∫¶ÈáèL-SWAGÔºåËÉΩÂ§üË°®ÂæÅÂç∑ÁßØÂíåÂèòÊç¢Âô®Êû∂ÊûÑ„ÄÇÊ≠§Â§ñÔºåÊú¨ÊñáËøòÂºïÂÖ•LIBRA-NASÊñπÊ≥ïÔºåÊàòÁï•ÊÄßÂú∞ÁªÑÂêà‰ª£ÁêÜ‰ª•ÊúÄ‰Ω≥Ë°®Á§∫ÁâπÂÆöÂü∫ÂáÜÔºåÊúÄÁªàÂú®ImageNet1k‰∏ä‰ª•0.1 GPUÂ§©ÁöÑÊó∂Èó¥ÂÆûÁé∞‰∫Ü17.0%ÁöÑÊµãËØïËØØÂ∑ÆÔºåË∂ÖË∂ä‰∫ÜËøõÂåñÂíåÂü∫‰∫éÊ¢ØÂ∫¶ÁöÑNASÊäÄÊúØ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥ÂΩìÂâçÈõ∂ÊàêÊú¨Á•ûÁªèÊû∂ÊûÑÊêúÁ¥¢ÔºàZC-NASÔºâÂú®ËßÜËßâÂèòÊç¢Âô®ÔºàViTsÔºâÂ∫îÁî®‰∏≠ÁöÑÂ±ÄÈôêÊÄßÔºåÁé∞ÊúâÊñπÊ≥ïÂ§öÈõÜ‰∏≠‰∫éÂç∑ÁßØÁΩëÁªúÔºåÁº∫‰πèÂØπÊñ∞ÂÖ¥Êû∂ÊûÑÁöÑÊîØÊåÅ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊèêÂá∫Layer-Sample Wise Activation with Gradients informationÔºàL-SWAGÔºâ‰Ωú‰∏∫‰∏ÄÁßçÊñ∞È¢ñÁöÑÂ∫¶ÈáèÔºåËÉΩÂ§üÊúâÊïàË°®ÂæÅ‰∏çÂêåÊû∂ÊûÑÁöÑÁâπÊÄßÔºåÂπ∂ÂºïÂÖ•LIBRA-NASÊñπÊ≥ïÔºåÈÄöËøáÁªÑÂêà‰∏çÂêåÁöÑZC‰ª£ÁêÜÊù•‰ºòÂåñÊû∂ÊûÑÈÄâÊã©„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏§‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöL-SWAGÂ∫¶ÈáèÊ®°ÂùóÁî®‰∫éËØÑ‰º∞Êû∂ÊûÑÊÄßËÉΩÔºåLIBRA-NASÊ®°ÂùóÁî®‰∫éÊï¥ÂêàÂíå‰ºòÂåñ‰∏çÂêå‰ª£ÁêÜÁöÑ‰ø°ÊÅØÔºå‰ª•‰æøÂú®ÁâπÂÆöÂü∫ÂáÜ‰∏äÈÄâÊã©ÊúÄ‰Ω≥Êû∂ÊûÑ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöL-SWAGÂ∫¶ÈáèÁöÑÊèêÂá∫ÊòØÊú¨ÊñáÁöÑÊ†∏ÂøÉÂàõÊñ∞ÔºåÂÆÉËÉΩÂ§üÂêåÊó∂ÈÄÇÁî®‰∫éÂç∑ÁßØÂíåÂèòÊç¢Âô®Êû∂ÊûÑÔºåÂ°´Ë°•‰∫ÜÁé∞ÊúâZC-NASÊñπÊ≥ïÁöÑÁ©∫ÁôΩ„ÄÇLIBRA-NASÊñπÊ≥ïÂàôÈÄöËøáÊô∫ËÉΩÁªÑÂêà‰∏çÂêå‰ª£ÁêÜÁöÑ‰ø°ÊÅØÔºåÊèêÂçá‰∫ÜÊû∂ÊûÑÊêúÁ¥¢ÁöÑÊïàÁéáÂíåÊïàÊûú„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°‰∏≠ÔºåL-SWAGÂ∫¶ÈáèËÄÉËôë‰∫ÜÂ±ÇÁ∫ßÂíåÊ†∑Êú¨ÁöÑÊøÄÊ¥ª‰ø°ÊÅØÔºåÁªìÂêàÊ¢ØÂ∫¶‰ø°ÊÅØËøõË°åËØÑ‰º∞ÔºõLIBRA-NASÂàôÈÄöËøá‰Ωé‰ø°ÊÅØÂ¢ûÁõäÂíåÂÅèÂ∑ÆÈáçÂØπÈΩêÁ≠ñÁï•Ôºå‰ºòÂåñ‰∫Ü‰ª£ÁêÜÁªÑÂêàÁöÑÈÄâÊã©ËøáÁ®ã„ÄÇÂÖ∑‰ΩìÁöÑÂèÇÊï∞ËÆæÁΩÆÂíåÊçüÂ§±ÂáΩÊï∞ËÆæËÆ°Âú®ÂÆûÈ™åÈÉ®ÂàÜËøõË°å‰∫ÜËØ¶ÁªÜÊèèËø∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®ÂÆûÈ™å‰∏≠ÔºåLIBRA-NASÊñπÊ≥ïÂú®ImageNet1kÊï∞ÊçÆÈõÜ‰∏äÂÆûÁé∞‰∫Ü17.0%ÁöÑÊµãËØïËØØÂ∑ÆÔºå‰∏î‰ªÖÈúÄ0.1 GPUÂ§©ÁöÑËÆ°ÁÆóÊó∂Èó¥ÔºåÊòæËëó‰ºò‰∫é‰º†ÁªüÁöÑËøõÂåñÂíåÂü∫‰∫éÊ¢ØÂ∫¶ÁöÑNASÊäÄÊúØ„ÄÇËøô‰∏ÄÁªìÊûúÂ±ïÁ§∫‰∫ÜÊñ∞ÊñπÊ≥ïÂú®ÊïàÁéáÂíåÊÄßËÉΩ‰∏äÁöÑ‰ºòÂäø„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨ËÆ°ÁÆóÊú∫ËßÜËßâ‰∏≠ÁöÑËá™Âä®ÂåñÊ®°ÂûãËÆæËÆ°ÔºåÂ∞§ÂÖ∂ÊòØÂú®ÈúÄË¶ÅÂø´ÈÄüËø≠‰ª£ÂíåÈ´òÊïàÊÄßËÉΩÁöÑÂú∫ÊôØÔºåÂ¶ÇÂõæÂÉèÂàÜÁ±ª„ÄÅÁõÆÊ†áÊ£ÄÊµãÂíåÂõæÂÉèÂàÜÂâ≤Á≠â„ÄÇÈÄöËøá‰ºòÂåñÊû∂ÊûÑÊêúÁ¥¢ËøáÁ®ãÔºåËÉΩÂ§ü‰∏∫ÂÆûÈôÖÂ∫îÁî®Êèê‰æõÊõ¥È´òÊïàÁöÑËß£ÂÜ≥ÊñπÊ°àÔºåÊé®Âä®Ê∑±Â∫¶Â≠¶‰π†ÊäÄÊúØÁöÑËøõ‰∏ÄÊ≠•ÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Training-free Neural Architecture Search (NAS) efficiently identifies high-performing neural networks using zero-cost (ZC) proxies. Unlike multi-shot and one-shot NAS approaches, ZC-NAS is both (i) time-efficient, eliminating the need for model training, and (ii) interpretable, with proxy designs often theoretically grounded. Despite rapid developments in the field, current SOTA ZC proxies are typically constrained to well-established convolutional search spaces. With the rise of Large Language Models shaping the future of deep learning, this work extends ZC proxy applicability to Vision Transformers (ViTs). We present a new benchmark using the Autoformer search space evaluated on 6 distinct tasks and propose Layer-Sample Wise Activation with Gradients information (L-SWAG), a novel, generalizable metric that characterizes both convolutional and transformer architectures across 14 tasks. Additionally, previous works highlighted how different proxies contain complementary information, motivating the need for a ML model to identify useful combinations. To further enhance ZC-NAS, we therefore introduce LIBRA-NAS (Low Information gain and Bias Re-Alignment), a method that strategically combines proxies to best represent a specific benchmark. Integrated into the NAS search, LIBRA-NAS outperforms evolution and gradient-based NAS techniques by identifying an architecture with a 17.0% test error on ImageNet1k in just 0.1 GPU days.

