---
layout: default
title: SAMChat: Introducing Chain of Thought Reasoning and GRPO to a Multimodal Small Language Model for Small Scale Remote Sensing
---

# SAMChat: Introducing Chain of Thought Reasoning and GRPO to a Multimodal Small Language Model for Small Scale Remote Sensing

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.07984" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.07984v2</a>
  <a href="https://arxiv.org/pdf/2505.07984.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.07984v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.07984v2', 'SAMChat: Introducing Chain of Thought Reasoning and GRPO to a Multimodal Small Language Model for Small Scale Remote Sensing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Aybora Koksal, A. Aydin Alatan

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-12 (æ›´æ–°: 2025-11-27)

**å¤‡æ³¨**: Accepted to Journal of Selected Topics in Applied Earth Observations and Remote Sensing (JSTARS) Special Issue on Foundation and Large Vision Models for Remote Sensing. Code and dataset are available at https://github.com/aybora/SAMChat

**DOI**: [10.1109/JSTARS.2025.3637115](https://doi.org/10.1109/JSTARS.2025.3637115)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSAMChatä»¥è§£å†³å°è§„æ¨¡é¥æ„Ÿå›¾åƒåˆ†æé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ¨¡å‹` `é¥æ„Ÿåˆ†æ` `é“¾å¼æ€ç»´æ¨ç†` `ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–` `å†›äº‹è®¾æ–½è¯†åˆ«` `æ•°æ®é›†æ„å»º` `ç²¾ç¡®åˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸåº”ç”¨æ—¶ï¼Œå°¤å…¶æ˜¯èµ„æºæœ‰é™çš„é¥æ„Ÿå›¾åƒåˆ†æä¸­ï¼Œæ•ˆæœä¸ä½³ã€‚
2. æœ¬ç ”ç©¶æå‡ºSAMChatæ¨¡å‹ï¼Œç»“åˆé“¾å¼æ€ç»´æ¨ç†å’Œç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼Œä¸“æ³¨äºé¥æ„Ÿå›¾åƒçš„ç²¾å‡†åˆ†æã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSAMChatåœ¨æ–°æå‡ºçš„SAMDataåŸºå‡†ä¸Šå®ç°äº†è¶…è¿‡80%çš„å¬å›ç‡å’Œ98%çš„ç²¾ç¡®ç‡ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨ç†è§£å’Œç”Ÿæˆæ–‡æœ¬-å›¾åƒå†…å®¹æ–¹é¢å±•ç°äº†æ˜¾è‘—èƒ½åŠ›ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸï¼Œå°¤å…¶æ˜¯éœ€è¦èµ„æºé«˜æ•ˆå’Œé¢†åŸŸç‰¹å®šé€‚åº”çš„åœºæ™¯ä¸­ï¼Œæ•ˆæœä»ç„¶æœ‰é™ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§è½»é‡çº§çš„å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹SAMChatï¼Œä¸“é—¨ç”¨äºåˆ†æåè¿œåœ°åŒºçš„é¥æ„Ÿå›¾åƒï¼ŒåŒ…æ‹¬å…·æœ‰æŒ‘æˆ˜æ€§çš„å¯¼å¼¹å‘å°„åœºã€‚é€šè¿‡ä¸“å®¶å®¡æ ¸éªŒè¯çš„æ•°ç™¾å¼ èˆªç©ºå›¾åƒï¼Œæ„å»ºäº†æ–°çš„æ•°æ®é›†SAMDataï¼Œå¹¶é€šè¿‡è¯¦ç»†çš„è¯´æ˜çªå‡ºå¾®å¦™çš„å†›äº‹è®¾æ–½ã€‚å¯¹ä¸€ä¸ªå…·æœ‰20äº¿å‚æ•°çš„å¼€æºå¤šæ¨¡æ€æ¨¡å‹è¿›è¡Œäº†ç›‘ç£å¾®è°ƒï¼Œç»“åˆé“¾å¼æ€ç»´æ¨ç†æ³¨é‡Šï¼Œæå‡äº†æ¨¡å‹çš„å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ã€‚æ­¤å¤–ï¼Œåˆ©ç”¨ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰å¢å¼ºäº†æ¨¡å‹æ£€æµ‹å…³é”®é¢†åŸŸç‰¹å¾çš„èƒ½åŠ›ï¼ŒåŒæ—¶å‡å°‘å¯¹å¹³æ°‘åœºæ™¯çš„è¯¯æŠ¥ã€‚å®éªŒè¯æ˜ï¼ŒSAMChatåœ¨å¼€æ”¾å¼æè¿°å’Œåˆ†ç±»æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºæ›´å¤§çš„ä¸€èˆ¬å¤šæ¨¡æ€æ¨¡å‹åŠç°æœ‰çš„é¥æ„Ÿé€‚åº”æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³ç°æœ‰å¤šæ¨¡æ€æ¨¡å‹åœ¨é¥æ„Ÿå›¾åƒåˆ†æä¸­çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨èµ„æºå—é™å’Œé¢†åŸŸç‰¹å®šçš„åº”ç”¨åœºæ™¯ä¸­ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•æœ‰æ•ˆè¯†åˆ«å’Œåˆ†æå†›äº‹è®¾æ–½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„SAMChatæ¨¡å‹é€šè¿‡å¼•å…¥é“¾å¼æ€ç»´æ¨ç†ï¼ˆCoTï¼‰å’Œç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰ï¼Œå®ç°äº†å¯¹é¥æ„Ÿå›¾åƒçš„ç²¾ç¡®åˆ†æå’Œè§£é‡Šï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰é¢†åŸŸç‰¹å®šçš„çº¿ç´¢ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSAMChatçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€æ¨¡å‹å¾®è°ƒå’Œè¯„ä¼°ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚é¦–å…ˆï¼Œæ„å»ºäº†åŒ…å«ä¸“å®¶å®¡æ ¸çš„èˆªç©ºå›¾åƒæ•°æ®é›†SAMDataï¼›å…¶æ¬¡ï¼Œå¯¹ä¸€ä¸ª20äº¿å‚æ•°çš„å¼€æºå¤šæ¨¡æ€æ¨¡å‹è¿›è¡Œç›‘ç£å¾®è°ƒï¼›æœ€åï¼Œé€šè¿‡å®éªŒè¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„æ ¸å¿ƒåˆ›æ–°åœ¨äºç»“åˆé“¾å¼æ€ç»´æ¨ç†å’ŒGRPOï¼Œæå‡äº†æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸçš„è¡¨ç°ï¼Œå°¤å…¶æ˜¯åœ¨å‡å°‘è¯¯æŠ¥æ–¹é¢ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†ä¸“é—¨è®¾è®¡çš„æŸå¤±å‡½æ•°å’Œå‚æ•°è®¾ç½®ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨è¯†åˆ«å†›äº‹è®¾æ–½æ—¶çš„é«˜ç²¾åº¦å’Œé«˜å¬å›ç‡ï¼ŒåŒæ—¶ä¼˜åŒ–äº†ç½‘ç»œç»“æ„ä»¥é€‚åº”å¤šæ¨¡æ€è¾“å…¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼ŒSAMChatåœ¨æ–°æå‡ºçš„SAMDataåŸºå‡†ä¸Šå–å¾—äº†è¶…è¿‡80%çš„å¬å›ç‡å’Œ98%çš„ç²¾ç¡®ç‡ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰çš„å¤šæ¨¡æ€æ¨¡å‹å’Œé¥æ„Ÿé€‚åº”æ–¹æ³•ã€‚è¿™ä¸€ç»“æœè¡¨æ˜ï¼Œé’ˆå¯¹ç‰¹å®šé¢†åŸŸçš„å¾®è°ƒå’Œå¼ºåŒ–å­¦ä¹ ç­–ç•¥èƒ½å¤Ÿæ˜¾è‘—æå‡æ¨¡å‹æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SAMChatæ¨¡å‹çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å†›äº‹ä¾¦å¯Ÿã€ç¾åè¯„ä¼°å’Œç¯å¢ƒç›‘æµ‹ç­‰ã€‚é€šè¿‡ç²¾å‡†åˆ†æé¥æ„Ÿå›¾åƒï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿä¸ºå†³ç­–è€…æä¾›é‡è¦çš„æƒ…æŠ¥æ”¯æŒï¼Œæå‡åº”å¯¹çªå‘äº‹ä»¶çš„èƒ½åŠ›ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›æ‰©å±•åˆ°æ›´å¤šé¢†åŸŸï¼Œå¦‚åŸå¸‚è§„åˆ’å’Œèµ„æºç®¡ç†ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Remarkable capabilities in understanding and generating text-image content have been demonstrated by recent advancements in multimodal large language models (MLLMs). However, their effectiveness in specialized domains-particularly those requiring resource-efficient and domain-specific adaptations-has remained limited. In this work, a lightweight multimodal language model termed SAMChat is introduced, specifically adapted to analyze remote sensing imagery in secluded areas, including challenging missile launch sites. A new dataset, SAMData, was compiled by verifying hundreds of aerial images through expert review, and subtle military installations were highlighted via detailed captions. Supervised fine-tuning on a 2B parameter open-source MLLM with chain-of-thought (CoT) reasoning annotations was performed, enabling more accurate and interpretable explanations. Additionally, Group Relative Policy Optimization (GRPO) was leveraged to enhance the model's ability to detect critical domain-specific cues-such as defensive layouts and key military structures-while minimizing false positives on civilian scenes. Through empirical evaluations, it has been shown that SAMChat significantly outperforms both larger, general-purpose multimodal models and existing remote sensing adapted approaches on open-ended captioning and classification metrics. Over 80% recall and 98% precision were achieved on the newly proposed SAMData benchmark, underscoring the potency of targeted fine-tuning and reinforcement learning in specialized real-world applications.

