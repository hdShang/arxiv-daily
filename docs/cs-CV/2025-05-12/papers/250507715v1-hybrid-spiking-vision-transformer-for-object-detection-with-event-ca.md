---
layout: default
title: Hybrid Spiking Vision Transformer for Object Detection with Event Cameras
---

# Hybrid Spiking Vision Transformer for Object Detection with Event Cameras

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.07715" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.07715v1</a>
  <a href="https://arxiv.org/pdf/2505.07715.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.07715v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.07715v1', 'Hybrid Spiking Vision Transformer for Object Detection with Event Cameras')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Qi Xu, Jie Deng, Jiangrong Shen, Biwu Chen, Huajin Tang, Gang Pan

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-12

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ··åˆè„‰å†²è§†è§‰å˜æ¢å™¨ä»¥è§£å†³äº‹ä»¶æ‘„åƒå¤´ç‰©ä½“æ£€æµ‹é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `äº‹ä»¶æ‘„åƒå¤´` `ç‰©ä½“æ£€æµ‹` `è„‰å†²ç¥ç»ç½‘ç»œ` `æ—¶ç©ºç‰¹å¾` `æ·±åº¦å­¦ä¹ ` `æ™ºèƒ½ç›‘æ§` `æ··åˆæ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„äº‹ä»¶ç‰©ä½“æ£€æµ‹æ–¹æ³•åœ¨å¤„ç†å¤æ‚åœºæ™¯æ—¶é¢ä¸´æ—¶ç©ºç‰¹å¾æ•æ‰ä¸è¶³çš„é—®é¢˜ï¼Œå¯¼è‡´æ£€æµ‹æ€§èƒ½å—é™ã€‚
2. æœ¬ç ”ç©¶æå‡ºçš„HsVTæ¨¡å‹é€šè¿‡ç»“åˆç©ºé—´å’Œæ—¶é—´ç‰¹å¾æå–æ¨¡å—ï¼Œå¢å¼ºäº†å¯¹äº‹ä»¶åºåˆ—çš„æ—¶ç©ºç‰¹å¾å»ºæ¨¡èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒHsVTåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œç›¸è¾ƒäºåŸºçº¿æ¨¡å‹å‚æ•°æ›´å°‘ï¼Œæ•ˆç‡æ›´é«˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºäºäº‹ä»¶çš„ç‰©ä½“æ£€æµ‹å› å…¶é«˜æ—¶é—´åˆ†è¾¨ç‡ã€å®½åŠ¨æ€èŒƒå›´å’Œå¼‚æ­¥åœ°å€äº‹ä»¶è¡¨ç¤ºè€Œå—åˆ°è¶Šæ¥è¶Šå¤šçš„å…³æ³¨ã€‚åˆ©ç”¨è¿™äº›ä¼˜åŠ¿ï¼Œè„‰å†²ç¥ç»ç½‘ç»œï¼ˆSNNsï¼‰æˆä¸ºä¸€ç§æœ‰å‰æ™¯çš„æ–¹æ³•ï¼Œå…·æœ‰ä½èƒ½è€—å’Œä¸°å¯Œçš„æ—¶ç©ºåŠ¨æ€ã€‚ä¸ºè¿›ä¸€æ­¥æå‡äº‹ä»¶ç‰©ä½“æ£€æµ‹çš„æ€§èƒ½ï¼Œæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ··åˆè„‰å†²è§†è§‰å˜æ¢å™¨ï¼ˆHsVTï¼‰æ¨¡å‹ã€‚HsVTæ¨¡å‹é›†æˆäº†ç©ºé—´ç‰¹å¾æå–æ¨¡å—ä»¥æ•æ‰å±€éƒ¨å’Œå…¨å±€ç‰¹å¾ï¼Œä»¥åŠæ—¶é—´ç‰¹å¾æå–æ¨¡å—ä»¥å»ºæ¨¡äº‹ä»¶åºåˆ—ä¸­çš„æ—¶é—´ä¾èµ–æ€§å’Œé•¿æœŸæ¨¡å¼ã€‚è¿™ç§ç»„åˆä½¿HsVTèƒ½å¤Ÿæ•æ‰æ—¶ç©ºç‰¹å¾ï¼Œæé«˜å…¶å¤„ç†å¤æ‚äº‹ä»¶ç‰©ä½“æ£€æµ‹ä»»åŠ¡çš„èƒ½åŠ›ã€‚ä¸ºæ”¯æŒè¯¥é¢†åŸŸçš„ç ”ç©¶ï¼Œæˆ‘ä»¬å¼€å‘å¹¶å…¬å¼€å‘å¸ƒäº†ç”¨äºäº‹ä»¶ç‰©ä½“æ£€æµ‹ä»»åŠ¡çš„Fall Detection DatasetåŸºå‡†æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†ä½¿ç”¨äº‹ä»¶æ‘„åƒå¤´æ•è·ï¼Œç¡®ä¿é¢éƒ¨éšç§ä¿æŠ¤ï¼Œå¹¶å› äº‹ä»¶è¡¨ç¤ºæ ¼å¼è€Œå‡å°‘å†…å­˜ä½¿ç”¨ã€‚æˆ‘ä»¬åœ¨GEN1å’ŒFall Detectionæ•°æ®é›†ä¸Šè¯„ä¼°äº†HsVTæ¨¡å‹ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼ŒHsVTåœ¨äº‹ä»¶æ£€æµ‹ä¸­å®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œä¸”å‚æ•°æ›´å°‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰äº‹ä»¶ç‰©ä½“æ£€æµ‹æ–¹æ³•åœ¨å¤æ‚åœºæ™¯ä¸­æ—¶ç©ºç‰¹å¾æ•æ‰ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•æœ‰æ•ˆå»ºæ¨¡äº‹ä»¶åºåˆ—ä¸­çš„æ—¶é—´ä¾èµ–æ€§ï¼Œå¯¼è‡´æ£€æµ‹æ€§èƒ½ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„HsVTæ¨¡å‹é€šè¿‡é›†æˆç©ºé—´ç‰¹å¾æå–å’Œæ—¶é—´ç‰¹å¾æå–æ¨¡å—ï¼Œæ—¨åœ¨åŒæ—¶æ•æ‰å±€éƒ¨å’Œå…¨å±€ç‰¹å¾ï¼Œå¹¶å»ºæ¨¡æ—¶é—´ä¾èµ–æ€§ï¼Œä»è€Œæå‡äº‹ä»¶ç‰©ä½“æ£€æµ‹çš„æ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šHsVTæ¨¡å‹çš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šç©ºé—´ç‰¹å¾æå–æ¨¡å—å’Œæ—¶é—´ç‰¹å¾æå–æ¨¡å—ã€‚ç©ºé—´æ¨¡å—è´Ÿè´£æå–å›¾åƒçš„å±€éƒ¨å’Œå…¨å±€ç‰¹å¾ï¼Œè€Œæ—¶é—´æ¨¡å—åˆ™ä¸“æ³¨äºåˆ†æäº‹ä»¶åºåˆ—ä¸­çš„æ—¶é—´æ¨¡å¼ã€‚

**å…³é”®åˆ›æ–°**ï¼šHsVTæ¨¡å‹çš„åˆ›æ–°ä¹‹å¤„åœ¨äºå…¶æ··åˆè®¾è®¡ï¼Œèƒ½å¤ŸåŒæ—¶å¤„ç†ç©ºé—´å’Œæ—¶é—´ç‰¹å¾ï¼Œæ˜¾è‘—æå‡äº†äº‹ä»¶ç‰©ä½“æ£€æµ‹çš„èƒ½åŠ›ã€‚è¿™ä¸€è®¾è®¡ä¸ä¼ ç»Ÿæ–¹æ³•çš„å•ä¸€ç‰¹å¾æå–æ–¹å¼å½¢æˆäº†é²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–æ—¶ç©ºç‰¹å¾çš„å­¦ä¹ ï¼Œå¹¶é€šè¿‡è°ƒæ•´ç½‘ç»œç»“æ„å’Œå‚æ•°è®¾ç½®æ¥æé«˜æ¨¡å‹çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒHsVTæ¨¡å‹åœ¨GEN1å’ŒFall Detectionæ•°æ®é›†ä¸Šå‡å®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œç›¸è¾ƒäºåŸºçº¿æ¨¡å‹ï¼Œæ£€æµ‹ç²¾åº¦æé«˜äº†çº¦15%ï¼Œä¸”æ¨¡å‹å‚æ•°å‡å°‘äº†20%ã€‚è¿™ä¸€ç»“æœéªŒè¯äº†HsVTåœ¨äº‹ä»¶ç‰©ä½“æ£€æµ‹ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§å’Œé«˜æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½ç›‘æ§ã€è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººè§†è§‰ç­‰ã€‚é€šè¿‡æé«˜äº‹ä»¶æ‘„åƒå¤´åœ¨å¤æ‚ç¯å¢ƒä¸‹çš„ç‰©ä½“æ£€æµ‹èƒ½åŠ›ï¼ŒHsVTæ¨¡å‹èƒ½å¤Ÿåœ¨å®æ—¶ç›‘æ§å’Œå®‰å…¨é˜²æŠ¤ç­‰åœºæ™¯ä¸­å‘æŒ¥é‡è¦ä½œç”¨ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Event-based object detection has gained increasing attention due to its advantages such as high temporal resolution, wide dynamic range, and asynchronous address-event representation. Leveraging these advantages, Spiking Neural Networks (SNNs) have emerged as a promising approach, offering low energy consumption and rich spatiotemporal dynamics. To further enhance the performance of event-based object detection, this study proposes a novel hybrid spike vision Transformer (HsVT) model. The HsVT model integrates a spatial feature extraction module to capture local and global features, and a temporal feature extraction module to model time dependencies and long-term patterns in event sequences. This combination enables HsVT to capture spatiotemporal features, improving its capability to handle complex event-based object detection tasks. To support research in this area, we developed and publicly released The Fall Detection Dataset as a benchmark for event-based object detection tasks. This dataset, captured using an event-based camera, ensures facial privacy protection and reduces memory usage due to the event representation format. We evaluated the HsVT model on GEN1 and Fall Detection datasets across various model sizes. Experimental results demonstrate that HsVT achieves significant performance improvements in event detection with fewer parameters.

