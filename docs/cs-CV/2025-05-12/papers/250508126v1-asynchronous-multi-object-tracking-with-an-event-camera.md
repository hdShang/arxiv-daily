---
layout: default
title: Asynchronous Multi-Object Tracking with an Event Camera
---

# Asynchronous Multi-Object Tracking with an Event Camera

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.08126" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.08126v1</a>
  <a href="https://arxiv.org/pdf/2505.08126.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.08126v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.08126v1', 'Asynchronous Multi-Object Tracking with an Event Camera')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Angus Apps, Ziwei Wang, Vladimir Perejogin, Timothy Molloy, Robert Mahony

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-12

**å¤‡æ³¨**: 7 pages, 5 figures, published in IEEE International Conference on Robotics and Automation (ICRA), 2025

**DOI**: [10.1109/ICRA55743.2025.11127984](https://doi.org/10.1109/ICRA55743.2025.11127984)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¼‚æ­¥äº‹ä»¶å¤šç›®æ ‡è·Ÿè¸ªç®—æ³•ä»¥è§£å†³åŠ¨æ€ç¯å¢ƒä¸‹çš„ç›®æ ‡æ£€æµ‹é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `äº‹ä»¶ç›¸æœº` `å¤šç›®æ ‡è·Ÿè¸ª` `åŠ¨æ€ç¯å¢ƒ` `å¼‚æ­¥å¤„ç†` `æœºå™¨å­¦ä¹ ` `ç›®æ ‡æ£€æµ‹` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç›®æ ‡æ£€æµ‹å’Œè·Ÿè¸ªæ–¹æ³•åœ¨åŠ¨æ€ç¯å¢ƒä¸­é¢ä¸´é«˜å»¶è¿Ÿå’Œä½æ—¶é—´åˆ†è¾¨ç‡çš„æŒ‘æˆ˜ï¼Œéš¾ä»¥å®æ—¶å“åº”å¿«é€Ÿå˜åŒ–çš„åœºæ™¯ã€‚
2. æœ¬æ–‡æå‡ºçš„AEMOTç®—æ³•é€šè¿‡å¼‚æ­¥å¤„ç†äº‹ä»¶ï¼Œåˆ©ç”¨æ´»åŠ¨æµæ–¹å‘åœºæ¥æ£€æµ‹å’Œè·Ÿè¸ªå¤šä¸ªç›®æ ‡ï¼Œæ˜¾è‘—æé«˜äº†åŠ¨æ€ç¯å¢ƒä¸‹çš„è·Ÿè¸ªç²¾åº¦ã€‚
3. åœ¨æ–°çš„èœœèœ‚ç¾¤ä½“æ•°æ®é›†ä¸Šï¼ŒAEMOTçš„ç²¾ç¡®åº¦å’Œå¬å›ç‡è¶…è¿‡äº†å…¶ä»–äº‹ä»¶åŸºç¡€ç®—æ³•37%ä»¥ä¸Šï¼Œå±•ç¤ºäº†å…¶ä¼˜è¶Šçš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äº‹ä»¶ç›¸æœºå› å…¶ä½å»¶è¿Ÿè¾“å‡ºã€é«˜æ—¶é—´åˆ†è¾¨ç‡å’Œé«˜åŠ¨æ€èŒƒå›´ï¼Œæˆä¸ºæœºå™¨äººåœ¨é«˜åº¦åŠ¨æ€ç¯å¢ƒä¸­æ£€æµ‹å’Œè·Ÿè¸ªç›®æ ‡çš„ç†æƒ³ä¼ æ„Ÿå™¨ã€‚æœ¬æ–‡æå‡ºäº†å¼‚æ­¥äº‹ä»¶å¤šç›®æ ‡è·Ÿè¸ªï¼ˆAEMOTï¼‰ç®—æ³•ï¼Œé€šè¿‡å¼‚æ­¥å¤„ç†å•ä¸ªåŸå§‹äº‹ä»¶æ¥æ£€æµ‹å’Œè·Ÿè¸ªå¤šä¸ªç›®æ ‡ã€‚AEMOTé€šè¿‡æ„å»ºæ´»åŠ¨äº‹ä»¶è¡¨é¢çš„æ´»åŠ¨æµæ–¹å‘åœºï¼Œè¯†åˆ«ä¸€è‡´å…‰æµåŒºåŸŸæ¥æ£€æµ‹æ˜¾è‘—çš„äº‹ä»¶æ–‘ç‚¹ç‰¹å¾ã€‚ä½¿ç”¨æ–°æå‡ºçš„å¼‚æ­¥äº‹ä»¶æ–‘ç‚¹ï¼ˆAEBï¼‰è·Ÿè¸ªå™¨è·Ÿè¸ªæ£€æµ‹åˆ°çš„ç‰¹å¾ï¼Œæ„å»ºæ¯ä¸ªå€™é€‰ç›®æ ‡çš„å°å¼ºåº¦è¡¥ä¸ã€‚ä¸€ä¸ªæ–°å­¦ä¹ çš„éªŒè¯é˜¶æ®µæ ¹æ®å¼ºåº¦è¡¥ä¸çš„åˆ†ç±»æ¥æå‡æˆ–ä¸¢å¼ƒå€™é€‰ç›®æ ‡ï¼Œæå‡çš„ç›®æ ‡åœ¨äº‹ä»¶é€Ÿç‡ä¸‹ä¼°è®¡å…¶ä½ç½®ã€é€Ÿåº¦ã€å¤§å°å’Œæ–¹å‘ã€‚æˆ‘ä»¬åœ¨æ–°çš„èœœèœ‚ç¾¤ä½“æ•°æ®é›†ä¸Šè¯„ä¼°AEMOTï¼Œè·Ÿè¸ªæ•°ååªå°èœœèœ‚ï¼Œå…¶ç²¾ç¡®åº¦å’Œå¬å›ç‡è¶…è¿‡å…¶ä»–åŸºäºäº‹ä»¶çš„æ£€æµ‹å’Œè·Ÿè¸ªç®—æ³•37%ä»¥ä¸Šã€‚æºä»£ç å’Œæ ‡è®°çš„äº‹ä»¶èœœèœ‚ç¾¤ä½“æ•°æ®é›†å°†å¼€æºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨åŠ¨æ€ç¯å¢ƒä¸­ç›®æ ‡æ£€æµ‹å’Œè·Ÿè¸ªçš„å®æ—¶æ€§å’Œç²¾ç¡®æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸å­˜åœ¨é«˜å»¶è¿Ÿå’Œä½æ—¶é—´åˆ†è¾¨ç‡ï¼Œéš¾ä»¥é€‚åº”å¿«é€Ÿå˜åŒ–çš„åœºæ™¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šAEMOTç®—æ³•é€šè¿‡å¼‚æ­¥å¤„ç†æ¯ä¸ªåŸå§‹äº‹ä»¶ï¼Œåˆ©ç”¨æ´»åŠ¨æµæ–¹å‘åœºæ¥æ£€æµ‹æ˜¾è‘—çš„äº‹ä»¶æ–‘ç‚¹ç‰¹å¾ï¼Œä»è€Œå®ç°é«˜æ•ˆçš„å¤šç›®æ ‡è·Ÿè¸ªã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—ç®—æ³•èƒ½å¤Ÿå¿«é€Ÿå“åº”åŠ¨æ€å˜åŒ–ï¼Œæå‡è·Ÿè¸ªç²¾åº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAEMOTçš„æ•´ä½“æ¶æ„åŒ…æ‹¬äº‹ä»¶æ£€æµ‹ã€ç‰¹å¾è·Ÿè¸ªå’Œå€™é€‰å¯¹è±¡éªŒè¯ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡æ´»åŠ¨æµæ–¹å‘åœºæ£€æµ‹äº‹ä»¶æ–‘ç‚¹ç‰¹å¾ï¼›ç„¶åï¼Œä½¿ç”¨AEBè·Ÿè¸ªå™¨å¯¹ç‰¹å¾è¿›è¡Œè·Ÿè¸ªï¼›æœ€åï¼Œé€šè¿‡å­¦ä¹ çš„éªŒè¯é˜¶æ®µå¯¹å€™é€‰å¯¹è±¡è¿›è¡Œåˆ†ç±»å’Œç­›é€‰ã€‚

**å…³é”®åˆ›æ–°**ï¼šAEMOTçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå¼‚æ­¥å¤„ç†äº‹ä»¶å’Œä½¿ç”¨æ´»åŠ¨æµæ–¹å‘åœºè¿›è¡Œç‰¹å¾æ£€æµ‹ï¼Œè¿™ä¸ä¼ ç»Ÿçš„åŒæ­¥å¤„ç†æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ï¼Œæ˜¾è‘—æé«˜äº†åŠ¨æ€ç¯å¢ƒä¸‹çš„è·Ÿè¸ªæ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç®—æ³•è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†æ–°çš„å­¦ä¹ éªŒè¯é˜¶æ®µï¼Œé€šè¿‡å¯¹å¼ºåº¦è¡¥ä¸çš„åˆ†ç±»æ¥å†³å®šå€™é€‰å¯¹è±¡çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œç®—æ³•è¿˜åœ¨äº‹ä»¶é€Ÿç‡ä¸‹ä¼°è®¡ç›®æ ‡çš„ä½ç½®ä¿¡æ¯ã€é€Ÿåº¦ã€å¤§å°å’Œæ–¹å‘ï¼Œç¡®ä¿äº†è·Ÿè¸ªçš„å®æ—¶æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨æ–°çš„èœœèœ‚ç¾¤ä½“æ•°æ®é›†ä¸Šï¼ŒAEMOTç®—æ³•çš„ç²¾ç¡®åº¦å’Œå¬å›ç‡è¶…è¿‡äº†å…¶ä»–åŸºäºäº‹ä»¶çš„æ£€æµ‹å’Œè·Ÿè¸ªç®—æ³•37%ä»¥ä¸Šï¼Œå±•ç¤ºäº†å…¶åœ¨åŠ¨æ€ç¯å¢ƒä¸‹çš„ä¼˜è¶Šæ€§èƒ½ï¼Œå…·æœ‰æ˜¾è‘—çš„å®éªŒäº®ç‚¹ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ— äººæœºç›‘æ§ã€æœºå™¨äººå¯¼èˆªå’Œè‡ªåŠ¨é©¾é©¶ç­‰åŠ¨æ€ç¯å¢ƒä¸‹çš„ç›®æ ‡è·Ÿè¸ªä»»åŠ¡ã€‚é€šè¿‡æé«˜ç›®æ ‡æ£€æµ‹å’Œè·Ÿè¸ªçš„ç²¾åº¦å’Œå®æ—¶æ€§ï¼ŒAEMOTç®—æ³•èƒ½å¤Ÿä¸ºè¿™äº›é¢†åŸŸæä¾›æ›´å¯é çš„æŠ€æœ¯æ”¯æŒï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„è¿›æ­¥ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Events cameras are ideal sensors for enabling robots to detect and track objects in highly dynamic environments due to their low latency output, high temporal resolution, and high dynamic range. In this paper, we present the Asynchronous Event Multi-Object Tracking (AEMOT) algorithm for detecting and tracking multiple objects by processing individual raw events asynchronously. AEMOT detects salient event blob features by identifying regions of consistent optical flow using a novel Field of Active Flow Directions built from the Surface of Active Events. Detected features are tracked as candidate objects using the recently proposed Asynchronous Event Blob (AEB) tracker in order to construct small intensity patches of each candidate object. A novel learnt validation stage promotes or discards candidate objects based on classification of their intensity patches, with promoted objects having their position, velocity, size, and orientation estimated at their event rate. We evaluate AEMOT on a new Bee Swarm Dataset, where it tracks dozens of small bees with precision and recall performance exceeding that of alternative event-based detection and tracking algorithms by over 37%. Source code and the labelled event Bee Swarm Dataset will be open sourced

