---
layout: default
title: Self-Supervised Event Representations: Towards Accurate, Real-Time Perception on SoC FPGAs
---

# Self-Supervised Event Representations: Towards Accurate, Real-Time Perception on SoC FPGAs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.07556" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.07556v1</a>
  <a href="https://arxiv.org/pdf/2505.07556.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.07556v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.07556v1', 'Self-Supervised Event Representations: Towards Accurate, Real-Time Perception on SoC FPGAs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kamil Jeziorek, Tomasz Kryjak

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-12

**å¤‡æ³¨**: Presented at the Real-time Processing of Image, Depth and Video Information 2025 workshop and to be considered for publication is the SPIE Proceedings

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/vision-agh/RecRepEvent)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè‡ªç›‘ç£äº‹ä»¶è¡¨ç¤ºæ–¹æ³•ä»¥è§£å†³äº‹ä»¶æ•°æ®å¤„ç†æŒ‘æˆ˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `äº‹ä»¶ç›¸æœº` `è‡ªç›‘ç£å­¦ä¹ ` `GRUç½‘ç»œ` `ç‰©ä½“æ£€æµ‹` `FPGAå®ç°` `ä½åŠŸè€—` `å®æ—¶æ„ŸçŸ¥`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤„ç†äº‹ä»¶ç›¸æœºç”Ÿæˆçš„ç¨€ç–ã€å¼‚æ­¥æ•°æ®æ—¶ï¼Œå¾€å¾€é¢ä¸´æ€§èƒ½å’Œæ—¶é—´ä¿çœŸåº¦ä¹‹é—´çš„æƒè¡¡ã€‚
2. æœ¬æ–‡æå‡ºçš„è‡ªç›‘ç£äº‹ä»¶è¡¨ç¤ºæ–¹æ³•ï¼ˆSSERï¼‰é€šè¿‡GRUç½‘ç»œå®ç°äº‹ä»¶æ—¶é—´æˆ³å’Œææ€§çš„ç²¾ç¡®ç¼–ç ï¼Œé¿å…äº†æ—¶é—´ç¦»æ•£åŒ–å¸¦æ¥çš„ä¿¡æ¯æŸå¤±ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSSERåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¶…è¶Šäº†åŸºäºèšåˆçš„åŸºçº¿ï¼Œæå‡äº†æ£€æµ‹ç²¾åº¦ï¼Œå¹¶åœ¨FPGAä¸Šå®ç°äº†ä½å»¶è¿Ÿå’Œä½åŠŸè€—çš„ç¡¬ä»¶å®ç°ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äº‹ä»¶ç›¸æœºç›¸è¾ƒäºä¼ ç»Ÿå¸§åŸºä¼ æ„Ÿå™¨å…·æœ‰å¾®ç§’çº§æ—¶é—´åˆ†è¾¨ç‡ã€åœ¨ä¸åŒå…‰ç…§æ¡ä»¶ä¸‹çš„é²æ£’æ€§ä»¥åŠä½åŠŸè€—ç­‰æ˜¾è‘—ä¼˜åŠ¿ã€‚ç„¶è€Œï¼Œå¦‚ä½•æœ‰æ•ˆå¤„ç†å…¶ç¨€ç–ã€å¼‚æ­¥çš„äº‹ä»¶æµä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦åˆ†ä¸ºä¸¤ç±»ï¼šç›´æ¥å¤„ç†äº‹ä»¶æ•°æ®çš„ç¥ç»æ¨¡å‹å’Œå°†äº‹ä»¶è½¬æ¢ä¸ºå¯†é›†è¡¨ç¤ºçš„æ‰‹å·¥èšåˆå‡½æ•°ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„è‡ªç›‘ç£äº‹ä»¶è¡¨ç¤ºæ–¹æ³•ï¼ˆSSERï¼‰ï¼Œåˆ©ç”¨é—¨æ§é€’å½’å•å…ƒï¼ˆGRUï¼‰ç½‘ç»œå®ç°äº‹ä»¶æ—¶é—´æˆ³å’Œææ€§çš„é€åƒç´ ç²¾ç¡®ç¼–ç ï¼Œè€Œæ— éœ€æ—¶é—´ç¦»æ•£åŒ–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSSERåœ¨Gen1å’Œ1 Mpxç‰©ä½“æ£€æµ‹æ•°æ®é›†ä¸Šåˆ†åˆ«æé«˜äº†2.4%çš„mAPå’Œ0.6%ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡é¦–æ¬¡åœ¨ç³»ç»Ÿçº§èŠ¯ç‰‡FPGAä¸Šå®ç°äº†é€’å½’è¡¨ç¤ºï¼Œè¾¾åˆ°äº†äºšå¾®ç§’å»¶è¿Ÿå’Œ1-2Wçš„åŠŸè€—ï¼Œé€‚ç”¨äºå®æ—¶ã€ä½åŠŸè€—åº”ç”¨ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³äº‹ä»¶ç›¸æœºç”Ÿæˆçš„ç¨€ç–ã€å¼‚æ­¥äº‹ä»¶æµçš„æœ‰æ•ˆå¤„ç†é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨æ€§èƒ½å’Œæ—¶é—´ä¿çœŸåº¦ä¹‹é—´å­˜åœ¨å¦¥åï¼Œå¯¼è‡´æ— æ³•å……åˆ†åˆ©ç”¨äº‹ä»¶ç›¸æœºçš„ä¼˜åŠ¿ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„è‡ªç›‘ç£äº‹ä»¶è¡¨ç¤ºæ–¹æ³•ï¼ˆSSERï¼‰é€šè¿‡ä½¿ç”¨GRUç½‘ç»œï¼Œèƒ½å¤Ÿé€åƒç´ ç²¾ç¡®ç¼–ç äº‹ä»¶çš„æ—¶é—´æˆ³å’Œææ€§ï¼Œè€Œä¸éœ€è¦è¿›è¡Œæ—¶é—´ç¦»æ•£åŒ–ï¼Œä»è€Œä¿æŒäº†äº‹ä»¶æ•°æ®çš„é«˜ä¿çœŸåº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSSERçš„æ•´ä½“æ¶æ„åŒ…æ‹¬è¾“å…¥å±‚ï¼ˆæ¥æ”¶äº‹ä»¶æ•°æ®ï¼‰ã€GRUç½‘ç»œï¼ˆè¿›è¡Œè‡ªç›‘ç£è®­ç»ƒä»¥ä¼˜åŒ–ç¼–ç ï¼‰ã€è¾“å‡ºå±‚ï¼ˆç”Ÿæˆäº‹ä»¶è¡¨ç¤ºï¼‰ã€‚è¯¥æ–¹æ³•æ”¯æŒå¼‚æ­¥ç”Ÿæˆäº‹ä»¶è¡¨ç¤ºï¼Œç¡®ä¿ä¸é«˜ååé‡ä¼ æ„Ÿå™¨çš„å…¼å®¹æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šSSERçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶è‡ªç›‘ç£è®­ç»ƒæœºåˆ¶å’ŒGRUç½‘ç»œçš„åº”ç”¨ï¼Œä½¿å¾—äº‹ä»¶æ—¶é—´ç¼–ç çš„ä¿çœŸåº¦æ˜¾è‘—æé«˜ã€‚è¿™ä¸ä¼ ç»Ÿçš„èšåˆæ–¹æ³•å½¢æˆé²œæ˜å¯¹æ¯”ï¼Œåè€…å¾€å¾€ç‰ºç‰²äº†æ—¶é—´ä¿¡æ¯çš„å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒGRUç½‘ç»œçš„å‚æ•°è®¾ç½®ç»è¿‡ç²¾å¿ƒè°ƒæ•´ï¼Œä»¥æœ€å¤§åŒ–äº‹ä»¶æ—¶é—´ç¼–ç çš„ä¿çœŸåº¦ã€‚æŸå¤±å‡½æ•°é‡‡ç”¨è‡ªç›‘ç£å­¦ä¹ ç­–ç•¥ï¼Œç¡®ä¿ç½‘ç»œèƒ½å¤Ÿæœ‰æ•ˆå­¦ä¹ äº‹ä»¶æ•°æ®çš„ç‰¹å¾ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒSSERåœ¨Gen1å’Œ1 Mpxç‰©ä½“æ£€æµ‹æ•°æ®é›†ä¸Šåˆ†åˆ«æé«˜äº†2.4%çš„mAPå’Œ0.6%ã€‚æ­¤å¤–ï¼Œé¦–æ¬¡åœ¨FPGAä¸Šå®ç°çš„é€’å½’è¡¨ç¤ºè¾¾åˆ°äº†äºšå¾®ç§’å»¶è¿Ÿå’Œ1-2Wçš„åŠŸè€—ï¼Œå±•ç¤ºäº†å…¶åœ¨å®æ—¶åº”ç”¨ä¸­çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººè§†è§‰ã€ç›‘æ§ç³»ç»Ÿç­‰éœ€è¦é«˜æ—¶é—´åˆ†è¾¨ç‡å’Œä½åŠŸè€—çš„å®æ—¶æ„ŸçŸ¥ä»»åŠ¡ã€‚é€šè¿‡æé«˜äº‹ä»¶æ•°æ®å¤„ç†çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ï¼ŒSSERèƒ½å¤Ÿæ¨åŠ¨è¿™äº›é¢†åŸŸçš„æŠ€æœ¯è¿›æ­¥ï¼Œä¿ƒè¿›æ›´æ™ºèƒ½çš„ç³»ç»Ÿå¼€å‘ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Event cameras offer significant advantages over traditional frame-based sensors. These include microsecond temporal resolution, robustness under varying lighting conditions and low power consumption. Nevertheless, the effective processing of their sparse, asynchronous event streams remains challenging. Existing approaches to this problem can be categorised into two distinct groups. The first group involves the direct processing of event data with neural models, such as Spiking Neural Networks or Graph Convolutional Neural Networks. However, this approach is often accompanied by a compromise in terms of qualitative performance. The second group involves the conversion of events into dense representations with handcrafted aggregation functions, which can boost accuracy at the cost of temporal fidelity. This paper introduces a novel Self-Supervised Event Representation (SSER) method leveraging Gated Recurrent Unit (GRU) networks to achieve precise per-pixel encoding of event timestamps and polarities without temporal discretisation. The recurrent layers are trained in a self-supervised manner to maximise the fidelity of event-time encoding. The inference is performed with event representations generated asynchronously, thus ensuring compatibility with high-throughput sensors. The experimental validation demonstrates that SSER outperforms aggregation-based baselines, achieving improvements of 2.4% mAP and 0.6% on the Gen1 and 1 Mpx object detection datasets. Furthermore, the paper presents the first hardware implementation of recurrent representation for event data on a System-on-Chip FPGA, achieving sub-microsecond latency and power consumption between 1-2 W, suitable for real-time, power-efficient applications. Code is available at https://github.com/vision-agh/RecRepEvent.

