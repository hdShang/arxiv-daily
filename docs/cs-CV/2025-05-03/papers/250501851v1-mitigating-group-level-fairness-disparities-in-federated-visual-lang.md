---
layout: default
title: Mitigating Group-Level Fairness Disparities in Federated Visual Language Models
---

# Mitigating Group-Level Fairness Disparities in Federated Visual Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.01851" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.01851v1</a>
  <a href="https://arxiv.org/pdf/2505.01851.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.01851v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.01851v1', 'Mitigating Group-Level Fairness Disparities in Federated Visual Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chaomeng Chen, Zitong Yu, Junhao Dong, Sen Su, Linlin Shen, Shutao Xia, Xiaochun Cao

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-03

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFVL-FPæ¡†æ¶ä»¥è§£å†³è”é‚¦è§†è§‰è¯­è¨€æ¨¡å‹ä¸­çš„ç¾¤ä½“å…¬å¹³æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡å‹` `è”é‚¦å­¦ä¹ ` `ç¾¤ä½“å…¬å¹³æ€§` `å¤šæ¨¡æ€ä»»åŠ¡` `å…¬å¹³æç¤ºè°ƒä¼˜` `äººå£åè§` `éç‹¬ç«‹åŒåˆ†å¸ƒ` `æ¨¡å‹æ€§èƒ½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è”é‚¦å­¦ä¹ æ–¹æ³•åœ¨å¤„ç†è§†è§‰è¯­è¨€æ¨¡å‹æ—¶ï¼Œéš¾ä»¥å…¼é¡¾ä¸åŒäººå£ç¾¤ä½“çš„å…¬å¹³æ€§ï¼Œå¯¼è‡´æ½œåœ¨çš„åè§é—®é¢˜ã€‚
2. æœ¬æ–‡æå‡ºFVL-FPæ¡†æ¶ï¼Œé€šè¿‡ç»“åˆå…¬å¹³æç¤ºè°ƒä¼˜æŠ€æœ¯ä¸è”é‚¦å­¦ä¹ ï¼Œæ—¨åœ¨å‡å°‘äººå£åè§ï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹çš„æ•´ä½“æ€§èƒ½ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒFVL-FPåœ¨å››ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå¹³å‡å‡å°‘äº†45%çš„ç¾¤ä½“å·®å¼‚ï¼Œä¸”ä»»åŠ¡æ€§èƒ½ä¸æœ€å…ˆè¿›ç»“æœç›¸å·®ä¸è¶…è¿‡6%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨å¤šæ¨¡æ€ä»»åŠ¡ä¸­å±•ç°äº†å“è¶Šçš„èƒ½åŠ›ï¼Œä½†åœ¨è”é‚¦å­¦ä¹ ï¼ˆFLï¼‰ç¯å¢ƒä¸­ç»´æŠ¤ä¸åŒäººå£ç¾¤ä½“çš„å…¬å¹³æ€§é¢ä¸´æŒ‘æˆ˜ã€‚æœ¬æ–‡é€šè¿‡å¼•å…¥FVL-FPæ¡†æ¶ï¼Œç»“åˆFLä¸å…¬å¹³æç¤ºè°ƒä¼˜æŠ€æœ¯ï¼Œè§£å†³äº†è”é‚¦VLMä¸­çš„ç¾¤ä½“å…¬å¹³æ€§é—®é¢˜ã€‚æˆ‘ä»¬æå‡ºäº†ä¸‰é¡¹åˆ›æ–°ç»„ä»¶ï¼šäº¤å‰å±‚äººå£å…¬å¹³æç¤ºï¼ˆCDFPï¼‰ã€äººå£å­ç©ºé—´æ­£äº¤æŠ•å½±ï¼ˆDSOPï¼‰å’Œå…¬å¹³æ„ŸçŸ¥æç¤ºèåˆï¼ˆFPFï¼‰ï¼Œä»¥å‡å°‘äººå£åè§å¹¶ä¿æŒæ¨¡å‹æ€§èƒ½ã€‚é€šè¿‡åœ¨å››ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å¹¿æ³›è¯„ä¼°ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å‡å°‘äººå£å·®å¼‚æ–¹é¢å¹³å‡æå‡äº†45%ï¼ŒåŒæ—¶ä»»åŠ¡æ€§èƒ½ä¿æŒåœ¨æœ€å…ˆè¿›ç»“æœçš„6%ä»¥å†…ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è”é‚¦è§†è§‰è¯­è¨€æ¨¡å‹ä¸­ç¾¤ä½“å…¬å¹³æ€§ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†éç‹¬ç«‹åŒåˆ†å¸ƒï¼ˆnon-IIDï¼‰æ•°æ®æ—¶ï¼Œå®¹æ˜“å¯¼è‡´ä¸åŒäººå£ç¾¤ä½“ä¹‹é—´çš„æ€§èƒ½å·®å¼‚å’Œåè§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šFVL-FPæ¡†æ¶é€šè¿‡å¼•å…¥å…¬å¹³æç¤ºè°ƒä¼˜æŠ€æœ¯ï¼Œæ—¨åœ¨åœ¨ä¿æŒæ¨¡å‹æ€§èƒ½çš„åŒæ—¶ï¼Œå‡å°‘äººå£åè§ã€‚å…·ä½“è€Œè¨€ï¼Œæ¡†æ¶è®¾è®¡äº†ä¸‰é¡¹åˆ›æ–°ç»„ä»¶ï¼Œä»¥å®ç°è¿™ä¸€ç›®æ ‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFVL-FPæ¡†æ¶ä¸»è¦åŒ…æ‹¬ä¸‰ä¸ªæ¨¡å—ï¼šäº¤å‰å±‚äººå£å…¬å¹³æç¤ºï¼ˆCDFPï¼‰ã€äººå£å­ç©ºé—´æ­£äº¤æŠ•å½±ï¼ˆDSOPï¼‰å’Œå…¬å¹³æ„ŸçŸ¥æç¤ºèåˆï¼ˆFPFï¼‰ã€‚CDFPé€šè¿‡åäº‹å®æ­£åˆ™åŒ–è°ƒæ•´æ½œåœ¨åè§çš„åµŒå…¥ï¼ŒDSOPåˆ™é€šè¿‡å°†å…¬å¹³æç¤ºæ–‡æœ¬æ˜ å°„åˆ°ç¾¤ä½“å­ç©ºé—´æ¥æ¶ˆé™¤å›¾åƒè¡¨ç¤ºä¸­çš„äººå£åè§ï¼ŒFPFåŠ¨æ€å¹³è¡¡å®¢æˆ·ç«¯è´¡çŒ®ã€‚

**å…³é”®åˆ›æ–°**ï¼šFVL-FPçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶ç»“åˆäº†å…¬å¹³æç¤ºè°ƒä¼˜ä¸è”é‚¦å­¦ä¹ çš„æ€æƒ³ï¼Œå°¤å…¶æ˜¯CDFPå’ŒDSOPçš„è®¾è®¡ï¼Œä½¿å¾—æ¨¡å‹åœ¨å¤„ç†ä¸åŒäººå£ç¾¤ä½“æ—¶èƒ½å¤Ÿæœ‰æ•ˆå‡å°‘åè§ï¼Œè€Œä¸æ˜¾è‘—å¢åŠ è®¡ç®—å¼€é”€ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒCDFPä½¿ç”¨åäº‹å®æ­£åˆ™åŒ–ä½œä¸ºæŸå¤±å‡½æ•°ï¼ŒDSOPé€šè¿‡æ­£äº¤æŠ•å½±å®ç°äººå£å­ç©ºé—´çš„æ˜ å°„ï¼ŒFPFåˆ™æ ¹æ®æ€§èƒ½å’Œå…¬å¹³æ€§æŒ‡æ ‡åŠ¨æ€è°ƒæ•´å®¢æˆ·ç«¯çš„è´¡çŒ®æƒé‡ã€‚è¿™äº›è®¾è®¡ç¡®ä¿äº†æ¨¡å‹åœ¨å…¬å¹³æ€§å’Œæ€§èƒ½ä¹‹é—´çš„è‰¯å¥½å¹³è¡¡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒFVL-FPåœ¨å››ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå¹³å‡å‡å°‘äº†45%çš„ç¾¤ä½“å·®å¼‚ï¼Œç›¸è¾ƒäºæ ‡å‡†è”é‚¦å­¦ä¹ æ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†å…¬å¹³æ€§ã€‚åŒæ—¶ï¼Œæ¨¡å‹çš„ä»»åŠ¡æ€§èƒ½ä¸æœ€å…ˆè¿›ç»“æœçš„å·®è·ä»…ä¸º6%ï¼Œå±•ç¤ºäº†å…¶æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŒ»ç–—å½±åƒåˆ†æã€ç¤¾äº¤åª’ä½“å†…å®¹å®¡æ ¸å’Œè‡ªåŠ¨é©¾é©¶ç­‰å¤šæ¨¡æ€ç³»ç»Ÿã€‚åœ¨è¿™äº›é¢†åŸŸï¼Œç¡®ä¿ä¸åŒäººå£ç¾¤ä½“çš„å…¬å¹³æ€§è‡³å…³é‡è¦ï¼ŒFVL-FPæ¡†æ¶èƒ½å¤Ÿåœ¨ä¿æŠ¤éšç§çš„åŒæ—¶ï¼Œæå‡æ¨¡å‹çš„å…¬å¹³æ€§å’Œæ€§èƒ½ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Visual language models (VLMs) have shown remarkable capabilities in multimodal tasks but face challenges in maintaining fairness across demographic groups, particularly when deployed in federated learning (FL) environments. This paper addresses the critical issue of group fairness in federated VLMs by introducing FVL-FP, a novel framework that combines FL with fair prompt tuning techniques. We focus on mitigating demographic biases while preserving model performance through three innovative components: (1) Cross-Layer Demographic Fair Prompting (CDFP), which adjusts potentially biased embeddings through counterfactual regularization; (2) Demographic Subspace Orthogonal Projection (DSOP), which removes demographic bias in image representations by mapping fair prompt text to group subspaces; and (3) Fair-aware Prompt Fusion (FPF), which dynamically balances client contributions based on both performance and fairness metrics. Extensive evaluations across four benchmark datasets demonstrate that our approach reduces demographic disparity by an average of 45\% compared to standard FL approaches, while maintaining task performance within 6\% of state-of-the-art results. FVL-FP effectively addresses the challenges of non-IID data distributions in federated settings and introduces minimal computational overhead while providing significant fairness benefits. Our work presents a parameter-efficient solution to the critical challenge of ensuring equitable performance across demographic groups in privacy-preserving multimodal systems.

