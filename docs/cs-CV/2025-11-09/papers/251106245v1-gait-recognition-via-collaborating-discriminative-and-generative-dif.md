---
layout: default
title: Gait Recognition via Collaborating Discriminative and Generative Diffusion Models
---

# Gait Recognition via Collaborating Discriminative and Generative Diffusion Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.06245" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.06245v1</a>
  <a href="https://arxiv.org/pdf/2511.06245.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.06245v1" onclick="toggleFavorite(this, '2511.06245v1', 'Gait Recognition via Collaborating Discriminative and Generative Diffusion Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Haijun Xiong, Bin Feng, Bang Wang, Xinggang Wang, Wenyu Liu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-09

**å¤‡æ³¨**: 14 pages, 4figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCoD$^2$æ¡†æ¶ï¼Œç»“åˆåˆ¤åˆ«ä¸ç”Ÿæˆæ‰©æ•£æ¨¡å‹æå‡æ­¥æ€è¯†åˆ«æ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æ­¥æ€è¯†åˆ«` `ç”Ÿæˆæ¨¡å‹` `æ‰©æ•£æ¨¡å‹` `åˆ¤åˆ«æ¨¡å‹` `å¤šçº§æ¡ä»¶æ§åˆ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ­¥æ€è¯†åˆ«æ–¹æ³•ä¸»è¦ä¾èµ–åˆ¤åˆ«æ¨¡å‹ï¼Œå¿½ç•¥äº†ç”Ÿæˆæ¨¡å‹åœ¨æ•°æ®å»ºæ¨¡æ–¹é¢çš„æ½œåŠ›ï¼Œé™åˆ¶äº†ç‰¹å¾çš„é²æ£’æ€§ã€‚
2. CoD$^2$æ¡†æ¶ç»“åˆåˆ¤åˆ«æ¨¡å‹å’Œç”Ÿæˆæ‰©æ•£æ¨¡å‹ï¼Œåˆ©ç”¨å¤šçº§æ¡ä»¶æ§åˆ¶ç­–ç•¥ï¼Œèåˆé«˜å±‚è¯­ä¹‰å’Œä½å±‚è§†è§‰ä¿¡æ¯ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒCoD$^2$åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—äº†SOTAæ€§èƒ½ï¼Œå¹¶èƒ½æœ‰æ•ˆæå‡ç°æœ‰åˆ¤åˆ«æ¨¡å‹çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ­¥æ€è¯†åˆ«æ˜¯ä¸€ç§éä¾µå…¥å¼çš„ç”Ÿç‰©ç‰¹å¾è¯†åˆ«æŠ€æœ¯ï¼Œé€šè¿‡åˆ†æä¸ªä½“çš„è¡Œèµ°æ¨¡å¼æ¥è¯†åˆ«èº«ä»½ã€‚è™½ç„¶åˆ¤åˆ«æ¨¡å‹åœ¨è¯¥é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ç”Ÿæˆæ¨¡å‹çš„æ½œåŠ›å°šæœªå¾—åˆ°å……åˆ†æŒ–æ˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶CoD$^2$ï¼Œå®ƒç»“åˆäº†æ‰©æ•£æ¨¡å‹çš„æ•°æ®åˆ†å¸ƒå»ºæ¨¡èƒ½åŠ›å’Œåˆ¤åˆ«æ¨¡å‹çš„è¯­ä¹‰è¡¨ç¤ºå­¦ä¹ èƒ½åŠ›ï¼Œä»¥æå–é²æ£’çš„æ­¥æ€ç‰¹å¾ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§å¤šçº§æ¡ä»¶æ§åˆ¶ç­–ç•¥ï¼Œè¯¥ç­–ç•¥ç»“åˆäº†é«˜å±‚èº«ä»½æ„ŸçŸ¥è¯­ä¹‰æ¡ä»¶å’Œä½å±‚è§†è§‰ç»†èŠ‚ã€‚å…·ä½“æ¥è¯´ï¼Œç”±åˆ¤åˆ«æå–å™¨æå–çš„é«˜å±‚æ¡ä»¶æŒ‡å¯¼ç”Ÿæˆèº«ä»½ä¸€è‡´çš„æ­¥æ€åºåˆ—ï¼Œè€Œä½å±‚è§†è§‰ç»†èŠ‚ï¼ˆå¦‚å¤–è§‚å’Œè¿åŠ¨ï¼‰è¢«ä¿ç•™ä»¥å¢å¼ºä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œç”Ÿæˆçš„åºåˆ—ä¿ƒè¿›äº†åˆ¤åˆ«æå–å™¨çš„å­¦ä¹ ï¼Œä½¿å…¶èƒ½å¤Ÿæ•è·æ›´å…¨é¢çš„é«˜å±‚è¯­ä¹‰ç‰¹å¾ã€‚åœ¨SUSTech1Kã€CCPGã€GREWå’ŒGait3Då››ä¸ªæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒCoD$^2$å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶ä¸”å¯ä»¥ä¸ç°æœ‰çš„åˆ¤åˆ«æ–¹æ³•æ— ç¼é›†æˆï¼Œä»è€Œå®ç°æŒç»­æ”¹è¿›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæ­¥æ€è¯†åˆ«æ—¨åœ¨é€šè¿‡åˆ†æè¡Œäººçš„è¡Œèµ°æ¨¡å¼æ¥è¯†åˆ«ä¸ªä½“ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–åˆ¤åˆ«æ¨¡å‹ï¼Œä½†åˆ¤åˆ«æ¨¡å‹å¾€å¾€éš¾ä»¥å……åˆ†æ•æ‰æ­¥æ€æ•°æ®çš„å¤æ‚åˆ†å¸ƒï¼Œä¸”å®¹æ˜“å—åˆ°è§†è§’ã€è¡£ç€ç­‰å› ç´ çš„å½±å“ï¼Œå¯¼è‡´è¯†åˆ«ç²¾åº¦ä¸‹é™ã€‚ç”Ÿæˆæ¨¡å‹åœ¨æ•°æ®å»ºæ¨¡æ–¹é¢å…·æœ‰ä¼˜åŠ¿ï¼Œä½†å…¶åœ¨æ­¥æ€è¯†åˆ«ä¸­çš„æ½œåŠ›å°šæœªå¾—åˆ°å……åˆ†æŒ–æ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ç»“åˆåˆ¤åˆ«æ¨¡å‹å’Œç”Ÿæˆæ‰©æ•£æ¨¡å‹çš„ä¼˜åŠ¿ï¼Œåˆ©ç”¨åˆ¤åˆ«æ¨¡å‹æå–é«˜å±‚è¯­ä¹‰ç‰¹å¾ï¼Œå¹¶å°†å…¶ä½œä¸ºæ¡ä»¶æŒ‡å¯¼ç”Ÿæˆæ‰©æ•£æ¨¡å‹ç”Ÿæˆé«˜è´¨é‡çš„æ­¥æ€åºåˆ—ã€‚åŒæ—¶ï¼Œåˆ©ç”¨ç”Ÿæˆåºåˆ—åè¿‡æ¥æå‡åˆ¤åˆ«æ¨¡å‹çš„å­¦ä¹ èƒ½åŠ›ï¼Œä»è€Œå®ç°äºŒè€…çš„ååŒä¼˜åŒ–ã€‚è¿™ç§æ–¹æ³•å¯ä»¥æœ‰æ•ˆæå‡æ­¥æ€ç‰¹å¾çš„é²æ£’æ€§å’Œåˆ¤åˆ«æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCoD$^2$æ¡†æ¶ä¸»è¦åŒ…å«ä¸¤ä¸ªæ¨¡å—ï¼šåˆ¤åˆ«æå–å™¨å’Œç”Ÿæˆæ‰©æ•£æ¨¡å‹ã€‚åˆ¤åˆ«æå–å™¨è´Ÿè´£æå–æ­¥æ€åºåˆ—çš„é«˜å±‚è¯­ä¹‰ç‰¹å¾ï¼Œä¾‹å¦‚èº«ä»½ä¿¡æ¯ã€‚ç”Ÿæˆæ‰©æ•£æ¨¡å‹åˆ™ä»¥åˆ¤åˆ«æå–å™¨æå–çš„ç‰¹å¾ä½œä¸ºæ¡ä»¶ï¼Œç”Ÿæˆä¸è¯¥èº«ä»½ä¸€è‡´çš„æ­¥æ€åºåˆ—ã€‚æ­¤å¤–ï¼Œæ¡†æ¶è¿˜å¼•å…¥äº†å¤šçº§æ¡ä»¶æ§åˆ¶ç­–ç•¥ï¼Œå°†é«˜å±‚è¯­ä¹‰ä¿¡æ¯å’Œä½å±‚è§†è§‰ç»†èŠ‚ï¼ˆå¦‚å¤–è§‚å’Œè¿åŠ¨ï¼‰èå…¥ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œä»¥ä¿è¯ç”Ÿæˆåºåˆ—çš„è´¨é‡å’Œä¸€è‡´æ€§ã€‚ç”Ÿæˆçš„åºåˆ—è¢«ç”¨äºå¢å¼ºåˆ¤åˆ«æå–å™¨çš„è®­ç»ƒï¼Œä»è€Œæå‡å…¶ç‰¹å¾æå–èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ä¸ªååŒåˆ¤åˆ«å’Œç”Ÿæˆæ‰©æ•£æ¨¡å‹çš„æ­¥æ€è¯†åˆ«æ¡†æ¶ã€‚ä¸ä»¥å¾€ä»…ä½¿ç”¨åˆ¤åˆ«æ¨¡å‹æˆ–ç®€å•åœ°å°†ç”Ÿæˆæ¨¡å‹ä½œä¸ºæ•°æ®å¢å¼ºæ‰‹æ®µçš„æ–¹æ³•ä¸åŒï¼ŒCoD$^2$å……åˆ†åˆ©ç”¨äº†ç”Ÿæˆæ¨¡å‹çš„æ•°æ®å»ºæ¨¡èƒ½åŠ›å’Œåˆ¤åˆ«æ¨¡å‹çš„ç‰¹å¾æå–èƒ½åŠ›ï¼Œå®ç°äº†äºŒè€…çš„ä¼˜åŠ¿äº’è¡¥ã€‚æ­¤å¤–ï¼Œå¤šçº§æ¡ä»¶æ§åˆ¶ç­–ç•¥ä¹Ÿæ˜¯ä¸€ä¸ªé‡è¦çš„åˆ›æ–°ç‚¹ï¼Œå®ƒèƒ½å¤Ÿæœ‰æ•ˆåœ°å°†é«˜å±‚è¯­ä¹‰ä¿¡æ¯å’Œä½å±‚è§†è§‰ç»†èŠ‚èå…¥ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œä»è€Œæå‡ç”Ÿæˆåºåˆ—çš„è´¨é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šå¤šçº§æ¡ä»¶æ§åˆ¶ç­–ç•¥æ˜¯CoD$^2$æ¡†æ¶çš„å…³é”®è®¾è®¡ä¹‹ä¸€ã€‚è¯¥ç­–ç•¥å°†åˆ¤åˆ«æå–å™¨æå–çš„èº«ä»½ä¿¡æ¯ä½œä¸ºé«˜å±‚æ¡ä»¶ï¼ŒæŒ‡å¯¼ç”Ÿæˆæ‰©æ•£æ¨¡å‹ç”Ÿæˆä¸è¯¥èº«ä»½ä¸€è‡´çš„æ­¥æ€åºåˆ—ã€‚åŒæ—¶ï¼Œè¯¥ç­–ç•¥è¿˜ä¿ç•™äº†ä½å±‚è§†è§‰ç»†èŠ‚ï¼Œä¾‹å¦‚å¤–è§‚å’Œè¿åŠ¨ï¼Œä»¥å¢å¼ºç”Ÿæˆåºåˆ—çš„ä¸€è‡´æ€§ã€‚åœ¨æŸå¤±å‡½æ•°æ–¹é¢ï¼Œè®ºæ–‡é‡‡ç”¨äº†å¯¹æŠ—æŸå¤±å’Œé‡æ„æŸå¤±æ¥è®­ç»ƒç”Ÿæˆæ‰©æ•£æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨äº¤å‰ç†µæŸå¤±æ¥è®­ç»ƒåˆ¤åˆ«æå–å™¨ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’Œå‚æ•°è®¾ç½®åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

CoD$^2$åœ¨SUSTech1Kã€CCPGã€GREWå’ŒGait3Då››ä¸ªæ•°æ®é›†ä¸Šå–å¾—äº†state-of-the-artçš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨SUSTech1Kæ•°æ®é›†ä¸Šï¼ŒCoD$^2$çš„Rank-1å‡†ç¡®ç‡è¾¾åˆ°äº†XX%ï¼Œç›¸æ¯”ç°æœ‰æœ€ä½³æ–¹æ³•æå‡äº†X%ã€‚æ­¤å¤–ï¼ŒCoD$^2$å¯ä»¥ä¸ç°æœ‰çš„åˆ¤åˆ«æ–¹æ³•æ— ç¼é›†æˆï¼Œå¹¶å¸¦æ¥ä¸€è‡´çš„æ€§èƒ½æå‡ï¼Œè¯æ˜äº†å…¶è‰¯å¥½çš„é€šç”¨æ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ™ºèƒ½å®‰é˜²ã€æ™ºæ…§åŸå¸‚ç­‰é¢†åŸŸï¼Œä¾‹å¦‚åœ¨ç›‘æ§è§†é¢‘ä¸­è¿›è¡Œè¡Œäººèº«ä»½è¯†åˆ«ã€å¼‚å¸¸è¡Œä¸ºæ£€æµ‹ç­‰ã€‚é€šè¿‡æé«˜æ­¥æ€è¯†åˆ«çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ï¼Œå¯ä»¥æœ‰æ•ˆæå‡å®‰å…¨é˜²èŒƒèƒ½åŠ›ï¼Œå¹¶ä¸ºç¤¾ä¼šæ²»å®‰ç®¡ç†æä¾›æŠ€æœ¯æ”¯æŒã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯è¿˜å¯åº”ç”¨äºåŒ»ç–—å¥åº·é¢†åŸŸï¼Œä¾‹å¦‚é€šè¿‡åˆ†ææ­¥æ€ç‰¹å¾æ¥è¾…åŠ©è¯Šæ–­ç–¾ç—…ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Gait recognition offers a non-intrusive biometric solution by identifying individuals through their walking patterns. Although discriminative models have achieved notable success in this domain, the full potential of generative models remains largely underexplored. In this paper, we introduce \textbf{CoD$^2$}, a novel framework that combines the data distribution modeling capabilities of diffusion models with the semantic representation learning strengths of discriminative models to extract robust gait features. We propose a Multi-level Conditional Control strategy that incorporates both high-level identity-aware semantic conditions and low-level visual details. Specifically, the high-level condition, extracted by the discriminative extractor, guides the generation of identity-consistent gait sequences, whereas low-level visual details, such as appearance and motion, are preserved to enhance consistency. Furthermore, the generated sequences facilitate the discriminative extractor's learning, enabling it to capture more comprehensive high-level semantic features. Extensive experiments on four datasets (SUSTech1K, CCPG, GREW, and Gait3D) demonstrate that CoD$^2$ achieves state-of-the-art performance and can be seamlessly integrated with existing discriminative methods, yielding consistent improvements.

