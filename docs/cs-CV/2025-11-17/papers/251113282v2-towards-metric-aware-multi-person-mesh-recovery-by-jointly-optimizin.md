---
layout: default
title: Towards Metric-Aware Multi-Person Mesh Recovery by Jointly Optimizing Human Crowd in Camera Space
---

# Towards Metric-Aware Multi-Person Mesh Recovery by Jointly Optimizing Human Crowd in Camera Space

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.13282" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.13282v2</a>
  <a href="https://arxiv.org/pdf/2511.13282.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.13282v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.13282v2', 'Towards Metric-Aware Multi-Person Mesh Recovery by Jointly Optimizing Human Crowd in Camera Space')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kaiwen Wang, Kaili Zheng, Yiming Shi, Chenyi Guo, Ji Wu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-17 (æ›´æ–°: 2025-11-20)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/gouba2333/MA-HMR)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ·±åº¦æ¡ä»¶å¹³ç§»ä¼˜åŒ–ä¸åº¦é‡æ„ŸçŸ¥ç½‘ç»œï¼Œå®ç°ç›¸æœºç©ºé—´å¤šäººç½‘æ ¼é‡å»º**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)** **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction & Matching)**

**å…³é”®è¯**: `å¤šäººäººä½“ç½‘æ ¼é‡å»º` `åœºæ™¯ä¸€è‡´æ€§` `æ·±åº¦æ¡ä»¶å¹³ç§»ä¼˜åŒ–` `åº¦é‡æ„ŸçŸ¥å­¦ä¹ ` `ä¼ªçœŸå€¼ç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å•äººäººä½“ç½‘æ ¼é‡å»ºæ–¹æ³•åœ¨å¤šäººåœºæ™¯ä¸­ç¼ºä¹åœºæ™¯ä¸€è‡´æ€§ï¼Œå¯¼è‡´æ·±åº¦å’Œå°ºåº¦å†²çªã€‚
2. æå‡ºæ·±åº¦æ¡ä»¶å¹³ç§»ä¼˜åŒ–(DTO)æ–¹æ³•ï¼Œè”åˆä¼˜åŒ–äººç¾¤ä¸­ä¸ªä½“çš„ç›¸æœºç©ºé—´ä½ç½®ï¼Œä¿è¯åœºæ™¯ä¸€è‡´æ€§ã€‚
3. æ„å»ºå¤§è§„æ¨¡ä¼ªçœŸå€¼æ•°æ®é›†DTO-Humansï¼Œå¹¶æå‡ºåº¦é‡æ„ŸçŸ¥HMRç½‘ç»œï¼Œå®éªŒè¡¨æ˜æ€§èƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å•å›¾åƒå¤šäººäººä½“ç½‘æ ¼é‡å»ºæå…·æŒ‘æˆ˜ï¼Œä¸»è¦éšœç¢åœ¨äºç¼ºä¹çœŸå®åœºæ™¯çš„è®­ç»ƒæ•°æ®ã€‚ç›®å‰æµè¡Œçš„åœºæ™¯äººä½“ç½‘æ ¼ä¼ªçœŸå€¼(pGT)ç”Ÿæˆæµç¨‹ä»¥å•äººä¸ºä¸­å¿ƒï¼Œç‹¬ç«‹å¤„ç†æ¯ä¸ªäººï¼Œç¼ºä¹è”åˆä¼˜åŒ–ã€‚è¿™å¯¼è‡´åœºæ™¯çº§ä¸ä¸€è‡´ï¼Œä¸ªä½“æ·±åº¦å’Œå°ºåº¦å†²çªã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥æ·±åº¦æ¡ä»¶å¹³ç§»ä¼˜åŒ–(DTO)ï¼Œä¸€ç§åŸºäºä¼˜åŒ–çš„æ–¹æ³•ï¼Œè”åˆä¼˜åŒ–äººç¾¤ä¸­æ‰€æœ‰ä¸ªä½“çš„ç›¸æœºç©ºé—´å¹³ç§»ã€‚DTOåˆ©ç”¨äººä½“æµ‹é‡å­¦å…ˆéªŒå’Œå•ç›®æ·±åº¦ä¼°è®¡å™¨çš„æ·±åº¦çº¿ç´¢ï¼Œåœ¨æœ€å¤§åéªŒ(MAP)æ¡†æ¶ä¸‹æ±‚è§£åœºæ™¯ä¸€è‡´çš„ä¸ªä½“ä½ç½®ã€‚æˆ‘ä»¬å°†DTOåº”ç”¨äº4D-Humansæ•°æ®é›†ï¼Œæ„å»ºäº†DTO-Humansï¼Œä¸€ä¸ªåŒ…å«0.56Mé«˜è´¨é‡ã€åœºæ™¯ä¸€è‡´çš„å¤šäººå›¾åƒçš„å¤§è§„æ¨¡pGTæ•°æ®é›†ï¼Œå›¾åƒå¹³å‡åŒ…å«4.8äººã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºåº¦é‡æ„ŸçŸ¥HMRï¼Œä¸€ä¸ªç«¯åˆ°ç«¯ç½‘ç»œï¼Œç›´æ¥ä¼°è®¡åº¦é‡å°ºåº¦çš„äººä½“ç½‘æ ¼å’Œç›¸æœºå‚æ•°ã€‚è¿™é€šè¿‡ç›¸æœºåˆ†æ”¯å’Œç›¸å¯¹åº¦é‡æŸå¤±å®ç°ï¼Œè¯¥æŸå¤±å¼ºåˆ¶æ‰§è¡Œåˆç†çš„ç›¸å¯¹å°ºåº¦ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ç›¸å¯¹æ·±åº¦æ¨ç†å’Œäººä½“ç½‘æ ¼é‡å»ºæ–¹é¢å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å•å¼ å›¾åƒä¸­å¤šäººäººä½“ç½‘æ ¼é‡å»ºé—®é¢˜ï¼Œç°æœ‰æ–¹æ³•ä¸»è¦åŸºäºå•äººé‡å»ºï¼Œå¿½ç•¥äº†åœºæ™¯ä¸­å¤šäººä¹‹é—´çš„ç›¸äº’å…³ç³»ï¼Œå¯¼è‡´é‡å»ºç»“æœåœ¨æ·±åº¦å’Œå°ºåº¦ä¸Šä¸ä¸€è‡´ï¼Œç¼ºä¹åœºæ™¯çº§çš„åˆç†æ€§ã€‚ç°æœ‰ä¼ªçœŸå€¼ç”Ÿæˆæµç¨‹ä¹Ÿå­˜åœ¨åŒæ ·çš„é—®é¢˜ï¼Œé™åˆ¶äº†æ¨¡å‹åœ¨çœŸå®åœºæ™¯ä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯è”åˆä¼˜åŒ–åœºæ™¯ä¸­æ‰€æœ‰äººçš„ç›¸æœºç©ºé—´ä½ç½®ï¼Œä¿è¯é‡å»ºç»“æœçš„åœºæ™¯ä¸€è‡´æ€§ã€‚é€šè¿‡å¼•å…¥äººä½“æµ‹é‡å­¦å…ˆéªŒï¼ˆå¦‚èº«é«˜ï¼‰å’Œå•ç›®æ·±åº¦ä¼°è®¡å™¨çš„æ·±åº¦ä¿¡æ¯ï¼Œæ„å»ºä¸€ä¸ªèƒ½é‡å‡½æ•°ï¼Œå¹¶é€šè¿‡ä¼˜åŒ–ç®—æ³•æ±‚è§£æœ€ä¼˜çš„ä¸ªä½“ä½ç½®ã€‚åŒæ—¶ï¼Œè®¾è®¡ä¸€ä¸ªåº¦é‡æ„ŸçŸ¥çš„äººä½“ç½‘æ ¼é‡å»ºç½‘ç»œï¼Œç›´æ¥é¢„æµ‹åº¦é‡å°ºåº¦ä¸‹çš„ç½‘æ ¼å’Œç›¸æœºå‚æ•°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦éƒ¨åˆ†ï¼š1) åŸºäºæ·±åº¦æ¡ä»¶å¹³ç§»ä¼˜åŒ–(DTO)çš„ä¼ªçœŸå€¼ç”Ÿæˆæµç¨‹ï¼›2) åº¦é‡æ„ŸçŸ¥çš„äººä½“ç½‘æ ¼é‡å»ºç½‘ç»œ(Metric-Aware HMR)ã€‚DTOæµç¨‹é¦–å…ˆä½¿ç”¨å•äººHMRæ–¹æ³•åˆå§‹åŒ–æ¯ä¸ªäººçš„ç½‘æ ¼ï¼Œç„¶ååˆ©ç”¨å•ç›®æ·±åº¦ä¼°è®¡å™¨æä¾›æ·±åº¦ä¿¡æ¯ï¼Œæœ€åé€šè¿‡ä¼˜åŒ–ç®—æ³•è°ƒæ•´æ¯ä¸ªäººçš„ç›¸æœºç©ºé—´å¹³ç§»ï¼Œç”Ÿæˆåœºæ™¯ä¸€è‡´çš„ä¼ªçœŸå€¼ã€‚Metric-Aware HMRæ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯ç½‘ç»œï¼ŒåŒ…å«ä¸€ä¸ªæ ‡å‡†çš„HMRä¸»å¹²ç½‘ç»œå’Œä¸€ä¸ªç›¸æœºåˆ†æ”¯ï¼Œç”¨äºé¢„æµ‹ç›¸æœºå‚æ•°ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†æ·±åº¦æ¡ä»¶å¹³ç§»ä¼˜åŒ–(DTO)æ–¹æ³•ï¼Œèƒ½å¤Ÿç”Ÿæˆåœºæ™¯ä¸€è‡´çš„å¤šäººäººä½“ç½‘æ ¼ä¼ªçœŸå€¼ï¼›2) æå‡ºäº†åº¦é‡æ„ŸçŸ¥çš„äººä½“ç½‘æ ¼é‡å»ºç½‘ç»œ(Metric-Aware HMR)ï¼Œèƒ½å¤Ÿç›´æ¥é¢„æµ‹åº¦é‡å°ºåº¦ä¸‹çš„ç½‘æ ¼å’Œç›¸æœºå‚æ•°ï¼›3) æ„å»ºäº†å¤§è§„æ¨¡çš„åœºæ™¯ä¸€è‡´å¤šäººäººä½“ç½‘æ ¼ä¼ªçœŸå€¼æ•°æ®é›†DTO-Humansã€‚

**å…³é”®è®¾è®¡**ï¼šDTOæ–¹æ³•ä¸­ï¼Œèƒ½é‡å‡½æ•°åŒ…å«ä¸¤éƒ¨åˆ†ï¼šä¸€æ˜¯åŸºäºäººä½“èº«é«˜å…ˆéªŒçš„æ­£åˆ™é¡¹ï¼Œé¼“åŠ±ä¸ªä½“èº«é«˜æ¥è¿‘çœŸå®å€¼ï¼›äºŒæ˜¯åŸºäºå•ç›®æ·±åº¦ä¼°è®¡çš„æ·±åº¦ä¸€è‡´æ€§é¡¹ï¼Œé¼“åŠ±ä¸ªä½“æ·±åº¦ä¸ä¼°è®¡æ·±åº¦ä¸€è‡´ã€‚Metric-Aware HMRç½‘ç»œä¸­ï¼Œç›¸æœºåˆ†æ”¯é¢„æµ‹ç›¸æœºå‚æ•°ï¼Œå¹¶å¼•å…¥ç›¸å¯¹åº¦é‡æŸå¤±ï¼Œé¼“åŠ±é¢„æµ‹çš„ç›¸å¯¹å°ºåº¦ä¸çœŸå®ç›¸å¯¹å°ºåº¦ä¸€è‡´ã€‚ç›¸å¯¹åº¦é‡æŸå¤±è®¡ç®—æ–¹å¼ä¸ºé¢„æµ‹èº«é«˜ä¸çœŸå®èº«é«˜çš„æ¯”å€¼ï¼Œå¹¶æœ€å°åŒ–å…¶ä¸1çš„å·®è·ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„DTOæ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆæå‡å¤šäººäººä½“ç½‘æ ¼é‡å»ºçš„åœºæ™¯ä¸€è‡´æ€§ï¼Œç”Ÿæˆçš„DTO-Humansæ•°æ®é›†èƒ½å¤Ÿæ˜¾è‘—æå‡ç°æœ‰HMRæ¨¡å‹çš„æ€§èƒ½ã€‚Metric-Aware HMRç½‘ç»œåœ¨benchmarkæ•°æ®é›†ä¸Šå–å¾—äº†state-of-the-artçš„ç»“æœï¼Œåœ¨ç›¸å¯¹æ·±åº¦æ¨ç†å’Œäººä½“ç½‘æ ¼é‡å»ºæ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ã€æ™ºèƒ½ç›‘æ§ã€äººæœºäº¤äº’ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨è™šæ‹Ÿç°å®ä¸­ï¼Œå¯ä»¥åˆ©ç”¨è¯¥æŠ€æœ¯é‡å»ºè™šæ‹Ÿåœºæ™¯ä¸­çš„å¤šäººè§’è‰²ï¼Œå¹¶ä¿è¯è§’è‰²ä¹‹é—´çš„ç›¸å¯¹ä½ç½®å’Œå°ºåº¦å…³ç³»åˆç†ã€‚åœ¨æ™ºèƒ½ç›‘æ§ä¸­ï¼Œå¯ä»¥ç”¨äºäººç¾¤è¡Œä¸ºåˆ†æå’Œå¼‚å¸¸äº‹ä»¶æ£€æµ‹ã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºæå‡ç›¸å…³åº”ç”¨çš„ç”¨æˆ·ä½“éªŒå’Œæ™ºèƒ½åŒ–æ°´å¹³ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multi-person human mesh recovery from a single image is a challenging task, hindered by the scarcity of in-the-wild training data. Prevailing in-the-wild human mesh pseudo-ground-truth (pGT) generation pipelines are single-person-centric, where each human is processed individually without joint optimization. This oversight leads to a lack of scene-level consistency, producing individuals with conflicting depths and scales within the same image. To address this, we introduce Depth-conditioned Translation Optimization (DTO), a novel optimization-based method that jointly refines the camera-space translations of all individuals in a crowd. By leveraging anthropometric priors on human height and depth cues from a monocular depth estimator, DTO solves for a scene-consistent placement of all subjects within a principled Maximum a posteriori (MAP) framework. Applying DTO to the 4D-Humans dataset, we construct DTO-Humans, a new large-scale pGT dataset of 0.56M high-quality, scene-consistent multi-person images, featuring dense crowds with an average of 4.8 persons per image. Furthermore, we propose Metric-Aware HMR, an end-to-end network that directly estimates human mesh and camera parameters in metric scale. This is enabled by a camera branch and a relative metric loss that enforces plausible relative scales. Extensive experiments demonstrate that our method achieves state-of-the-art performance on relative depth reasoning and human mesh recovery. Code is available at: https://github.com/gouba2333/MA-HMR.

