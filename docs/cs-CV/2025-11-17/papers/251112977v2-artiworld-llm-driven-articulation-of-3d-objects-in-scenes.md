---
layout: default
title: ArtiWorld: LLM-Driven Articulation of 3D Objects in Scenes
---

# ArtiWorld: LLM-Driven Articulation of 3D Objects in Scenes

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.12977" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.12977v2</a>
  <a href="https://arxiv.org/pdf/2511.12977.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.12977v2" onclick="toggleFavorite(this, '2511.12977v2', 'ArtiWorld: LLM-Driven Articulation of 3D Objects in Scenes')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yixuan Yang, Luyang Xie, Zhen Luo, Zixiang Zhao, Tongsheng Ding, Mingqi Gao, Feng Zheng

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-17 (æ›´æ–°: 2025-11-18)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ArtiWorldï¼šæå‡ºLLMé©±åŠ¨çš„3Dåœºæ™¯ç‰©ä½“å¯åŠ¨æ€§è‡ªåŠ¨ç”Ÿæˆæ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `å¯åŠ¨æ€§ç”Ÿæˆ` `å¤§å‹è¯­è¨€æ¨¡å‹` `URDF` `3Dåœºæ™¯ç†è§£` `æœºå™¨äººå­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰3Dæ¨¡æ‹Ÿèµ„äº§å¤šä¸ºåˆšæ€§ï¼Œæ‰‹åŠ¨è½¬æ¢ä¸ºå¯åŠ¨å¯¹è±¡æˆæœ¬é«˜æ˜‚ï¼Œç¼ºä¹è‡ªåŠ¨åŒ–çš„å¯åŠ¨æ€§ç”Ÿæˆæ–¹æ³•ã€‚
2. ArtiWorldåˆ©ç”¨LLMçš„å…ˆéªŒçŸ¥è¯†ï¼Œç»“åˆ3Dç‚¹äº‘å’ŒURDFå¯¼å‘çš„æç¤ºï¼Œè‡ªåŠ¨å°†åˆšæ€§ç‰©ä½“è½¬æ¢ä¸ºå¯äº¤äº’çš„URDFæ¨¡å‹ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒArtiWorldåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®åœºæ™¯ä¸­å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œèƒ½æœ‰æ•ˆç”Ÿæˆé«˜è´¨é‡çš„å¯åŠ¨æ¨¡å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ„å»ºäº¤äº’å¼æ¨¡æ‹Ÿå™¨å’Œå¯æ‰©å±•çš„æœºå™¨äººå­¦ä¹ ç¯å¢ƒéœ€è¦å¤§é‡å¯åŠ¨èµ„äº§ã€‚ç„¶è€Œï¼Œç›®å‰æ¨¡æ‹Ÿä¸­çš„å¤§å¤šæ•°3Dèµ„äº§æ˜¯åˆšæ€§çš„ï¼Œæ‰‹åŠ¨å°†å…¶è½¬æ¢ä¸ºå¯åŠ¨å¯¹è±¡éœ€è¦å¤§é‡çš„äººåŠ›å’Œæˆæœ¬ã€‚æœ¬æ–‡æå‡ºäº†ArtiWorldï¼Œä¸€ä¸ªåœºæ™¯æ„ŸçŸ¥çš„æµæ°´çº¿ï¼Œå¯ä»¥ä»æ–‡æœ¬åœºæ™¯æè¿°ä¸­å®šä½å€™é€‰çš„å¯åŠ¨å¯¹è±¡ï¼Œå¹¶é‡å»ºä¿ç•™åŸå§‹å‡ ä½•å½¢çŠ¶çš„å¯æ‰§è¡ŒURDFæ¨¡å‹ã€‚è¯¥æµæ°´çº¿çš„æ ¸å¿ƒæ˜¯Arti4URDFï¼Œå®ƒåˆ©ç”¨3Dç‚¹äº‘ã€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å…ˆéªŒçŸ¥è¯†å’Œé¢å‘URDFçš„æç¤ºè®¾è®¡ï¼Œå¿«é€Ÿå°†åˆšæ€§å¯¹è±¡è½¬æ¢ä¸ºåŸºäºURDFçš„äº¤äº’å¼å¯åŠ¨å¯¹è±¡ï¼ŒåŒæ—¶ä¿æŒå…¶3Då½¢çŠ¶ã€‚åœ¨3Dæ¨¡æ‹Ÿå¯¹è±¡ã€å®Œæ•´3Dæ¨¡æ‹Ÿåœºæ™¯å’ŒçœŸå®ä¸–ç•Œæ‰«æåœºæ™¯ä¸‰ä¸ªå±‚é¢ä¸Šè¯„ä¼°äº†ArtiWorldã€‚åœ¨æ‰€æœ‰ä¸‰ä¸ªè®¾ç½®ä¸­ï¼Œè¯¥æ–¹æ³•å§‹ç»ˆä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶ä¿ç•™äº†å¯¹è±¡å‡ ä½•å½¢çŠ¶å¹¶æ­£ç¡®æ•è·äº†å¯¹è±¡äº¤äº’æ€§ï¼Œä»è€Œç”Ÿæˆäº†å¯ç”¨çš„åŸºäºURDFçš„å¯åŠ¨æ¨¡å‹ã€‚è¿™ä¸ºç›´æ¥ä»ç°æœ‰3Dèµ„äº§æ„å»ºäº¤äº’å¼çš„ã€æœºå™¨äººå°±ç»ªçš„æ¨¡æ‹Ÿç¯å¢ƒæä¾›äº†ä¸€æ¡å®ç”¨çš„é€”å¾„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¦‚ä½•è‡ªåŠ¨åœ°å°†3Dåœºæ™¯ä¸­çš„åˆšæ€§ç‰©ä½“è½¬æ¢ä¸ºå¯åŠ¨æ¨¡å‹çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•éœ€è¦å¤§é‡äººå·¥å¹²é¢„ï¼Œæˆæœ¬é«˜ä¸”æ•ˆç‡ä½ï¼Œéš¾ä»¥æ»¡è¶³æ„å»ºå¤§è§„æ¨¡äº¤äº’å¼æ¨¡æ‹Ÿç¯å¢ƒçš„éœ€æ±‚ã€‚ç°æœ‰æ–¹æ³•åœ¨å‡ ä½•å½¢çŠ¶ä¿æŒå’Œäº¤äº’æ€§æ•è·æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å…ˆéªŒçŸ¥è¯†æ¥æŒ‡å¯¼å¯åŠ¨æ€§ç”Ÿæˆè¿‡ç¨‹ã€‚é€šè¿‡ç»“åˆ3Dç‚¹äº‘ä¿¡æ¯å’ŒURDFï¼ˆUnified Robot Description Formatï¼‰å¯¼å‘çš„æç¤ºï¼ŒLLMå¯ä»¥æ›´å¥½åœ°ç†è§£ç‰©ä½“çš„ç»“æ„å’Œæ½œåœ¨çš„è¿åŠ¨æ–¹å¼ï¼Œä»è€Œç”Ÿæˆæ›´åˆç†çš„å¯åŠ¨æ¨¡å‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šArtiWorldåŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) åœºæ™¯ç†è§£æ¨¡å—ï¼šä»æ–‡æœ¬æè¿°ä¸­è¯†åˆ«æ½œåœ¨çš„å¯åŠ¨å¯¹è±¡ã€‚2) Arti4URDFæ¨¡å—ï¼šåˆ©ç”¨3Dç‚¹äº‘ã€LLMå’ŒURDFæç¤ºï¼Œå°†åˆšæ€§å¯¹è±¡è½¬æ¢ä¸ºURDFæ¨¡å‹ã€‚3) è¯„ä¼°æ¨¡å—ï¼šåœ¨ä¸åŒåœºæ™¯ä¸‹è¯„ä¼°ç”Ÿæˆçš„å¯åŠ¨æ¨¡å‹çš„è´¨é‡ã€‚Arti4URDFæ˜¯æ ¸å¿ƒæ¨¡å—ï¼Œè´Ÿè´£å°†åˆšæ€§å¯¹è±¡è½¬æ¢ä¸ºå¯åŠ¨å¯¹è±¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå°†LLMå¼•å…¥åˆ°å¯åŠ¨æ€§ç”Ÿæˆè¿‡ç¨‹ä¸­ã€‚é€šè¿‡åˆ©ç”¨LLMçš„çŸ¥è¯†ï¼Œå¯ä»¥æ›´å¥½åœ°ç†è§£ç‰©ä½“çš„ç»“æ„å’ŒåŠŸèƒ½ï¼Œä»è€Œç”Ÿæˆæ›´åˆç†çš„å¯åŠ¨æ¨¡å‹ã€‚æ­¤å¤–ï¼ŒURDFå¯¼å‘çš„æç¤ºè®¾è®¡ä¹Ÿæé«˜äº†ç”Ÿæˆæ¨¡å‹çš„è´¨é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šArti4URDFçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨é¢„è®­ç»ƒçš„LLMï¼Œä¾‹å¦‚GPT-3ï¼Œä½œä¸ºçŸ¥è¯†æ¥æºã€‚2) è®¾è®¡URDFå¯¼å‘çš„æç¤ºï¼Œå¼•å¯¼LLMç”Ÿæˆç¬¦åˆURDFè§„èŒƒçš„æ¨¡å‹ã€‚3) ä½¿ç”¨3Dç‚¹äº‘ä¿¡æ¯æ¥çº¦æŸç”Ÿæˆæ¨¡å‹çš„å‡ ä½•å½¢çŠ¶ã€‚4) ä½¿ç”¨æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–ç”Ÿæˆæ¨¡å‹çš„å‚æ•°ï¼Œä¾‹å¦‚å…³èŠ‚ä½ç½®å’Œè¿åŠ¨èŒƒå›´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ArtiWorldåœ¨3Dæ¨¡æ‹Ÿå¯¹è±¡ã€å®Œæ•´3Dæ¨¡æ‹Ÿåœºæ™¯å’ŒçœŸå®ä¸–ç•Œæ‰«æåœºæ™¯ä¸‰ä¸ªå±‚é¢ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒArtiWorldèƒ½å¤Ÿæœ‰æ•ˆåœ°ç”Ÿæˆé«˜è´¨é‡çš„å¯åŠ¨æ¨¡å‹ï¼ŒåŒæ—¶ä¿æŒå¯¹è±¡çš„å‡ ä½•å½¢çŠ¶å’Œäº¤äº’æ€§ã€‚å…·ä½“æ€§èƒ½æ•°æ®æœªçŸ¥ï¼Œä½†è®ºæ–‡å¼ºè°ƒå…¶åœ¨æ‰€æœ‰æµ‹è¯•åœºæ™¯ä¸­å‡å–å¾—äº†state-of-the-artçš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºæœºå™¨äººå­¦ä¹ ã€è™šæ‹Ÿç°å®ã€æ¸¸æˆå¼€å‘ç­‰é¢†åŸŸã€‚é€šè¿‡è‡ªåŠ¨ç”Ÿæˆå¯åŠ¨æ¨¡å‹ï¼Œå¯ä»¥å¤§å¤§é™ä½æ„å»ºäº¤äº’å¼æ¨¡æ‹Ÿç¯å¢ƒçš„æˆæœ¬ï¼ŒåŠ é€Ÿæœºå™¨äººç®—æ³•çš„å¼€å‘å’ŒéªŒè¯ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥ç”¨äºåˆ›å»ºæ›´é€¼çœŸçš„è™šæ‹Ÿç°å®ä½“éªŒå’Œæ›´å…·äº’åŠ¨æ€§çš„æ¸¸æˆã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Building interactive simulators and scalable robot-learning environments requires a large number of articulated assets. However, most existing 3D assets in simulation are rigid, and manually converting them into articulated objects is extremely labor- and cost-intensive. This raises a natural question: can we automatically identify articulable objects in a scene and convert them into articulated assets directly? In this paper, we present ArtiWorld, a scene-aware pipeline that localizes candidate articulable objects from textual scene descriptions and reconstructs executable URDF models that preserve the original geometry. At the core of this pipeline is Arti4URDF, which leverages 3D point cloud, prior knowledge of a large language model (LLM), and a URDF-oriented prompt design to rapidly convert rigid objects into interactive URDF-based articulated objects while maintaining their 3D shape. We evaluate ArtiWorld at three levels: 3D simulated objects, full 3D simulated scenes, and real-world scan scenes. Across all three settings, our method consistently outperforms existing approaches and achieves state-of-the-art performance, while preserving object geometry and correctly capturing object interactivity to produce usable URDF-based articulated models. This provides a practical path toward building interactive, robot-ready simulation environments directly from existing 3D assets. Code and data will be released.

