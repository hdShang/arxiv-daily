---
layout: default
title: Robust Defense Strategies for Multimodal Contrastive Learning: Efficient Fine-tuning Against Backdoor Attacks
---

# Robust Defense Strategies for Multimodal Contrastive Learning: Efficient Fine-tuning Against Backdoor Attacks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.13545" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.13545v1</a>
  <a href="https://arxiv.org/pdf/2511.13545.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.13545v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.13545v1', 'Robust Defense Strategies for Multimodal Contrastive Learning: Efficient Fine-tuning Against Backdoor Attacks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Md. Iqbal Hossain, Afia Sajeeda, Neeresh Kumar Perla, Ming Shao

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-17

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§é«˜æ•ˆå¾®è°ƒç­–ç•¥ï¼Œå¢å¼ºå¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ æ¨¡å‹æŠµæŠ—åé—¨æ”»å‡»çš„é²æ£’æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `å¯¹æ¯”å­¦ä¹ ` `åé—¨æ”»å‡»` `å¯¹æŠ—é˜²å¾¡` `æ¨¡å‹é²æ£’æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤šæ¨¡æ€æ¨¡å‹æ˜“å—åé—¨æ”»å‡»ï¼Œç°æœ‰é˜²å¾¡æ–¹æ³•è®¡ç®—æˆæœ¬é«˜ï¼Œä¸”éš¾ä»¥å®šä½å—å½±å“çš„æ ‡ç­¾ã€‚
2. åˆ©ç”¨å›¾åƒåˆ†å‰²â€œoracleâ€ä½œä¸ºç›‘ç£ï¼ŒåŒºåˆ†CLIPå’Œoracleçš„çŸ¥è¯†ï¼Œå®šä½åé—¨è§¦å‘å™¨å’Œå—å½±å“çš„æ ·æœ¬ã€‚
3. é€šè¿‡ç²¾ç¡®å®šä½å—å½±å“çš„æ ‡ç­¾å’Œæ ·æœ¬ï¼Œæ„å»ºå°å‹å¾®è°ƒæ•°æ®é›†ï¼Œæœ‰æ•ˆçº æ­£è¢«æ±¡æŸ“çš„CLIPæ¨¡å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå¦‚CLIPï¼Œåœ¨å›¾åƒ-æ–‡æœ¬ç†è§£å’Œåˆ†ç±»ä»»åŠ¡ç­‰é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹å®¹æ˜“å—åˆ°å¯¹æŠ—æ€§æ”»å‡»ï¼Œç‰¹åˆ«æ˜¯åé—¨æ”»å‡»ï¼Œè¿™ç§æ”»å‡»ä¼šå¾®å¦™åœ°æ“çºµæ¨¡å‹è¡Œä¸ºã€‚ç°æœ‰çš„é˜²å¾¡æ–¹æ³•é€šå¸¸éœ€è¦ä»å¤´å¼€å§‹è®­ç»ƒæˆ–ä½¿ç”¨å¤§å‹æ•°æ®é›†è¿›è¡Œå¾®è°ƒï¼Œè€Œæ— æ³•ç²¾ç¡®å®šä½å—å½±å“çš„æ ‡ç­¾ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åˆ›æ–°ç­–ç•¥ï¼Œä»¥å¢å¼ºå¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ æ¨¡å‹æŠµæŠ—æ­¤ç±»æ”»å‡»çš„é²æ£’æ€§ã€‚å…·ä½“è€Œè¨€ï¼Œå¯¹äºä¸€ä¸ªè¢«æ±¡æŸ“çš„CLIPæ¨¡å‹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿé«˜æ•ˆåœ°è¯†åˆ«åé—¨è§¦å‘å™¨å¹¶ç²¾ç¡®å®šä½å—å®³è€…æ ·æœ¬å’Œæ ‡ç­¾ã€‚ä¸ºæ­¤ï¼Œå¼•å…¥äº†ä¸€ä¸ªå›¾åƒåˆ†å‰²â€œoracleâ€ä½œä¸ºè¢«æ±¡æŸ“CLIPè¾“å‡ºçš„ç›‘ç£ã€‚æˆ‘ä»¬å¼€å‘äº†ä¸¤ç§ç®—æ³•æ¥çº æ­£è¢«æ±¡æŸ“çš„æ¨¡å‹ï¼šï¼ˆ1ï¼‰åŒºåˆ†CLIPå’ŒOracleçš„çŸ¥è¯†ä»¥è¯†åˆ«æ½œåœ¨çš„è§¦å‘å™¨ï¼›ï¼ˆ2ï¼‰ç²¾ç¡®å®šä½å—å½±å“çš„æ ‡ç­¾å’Œå—å®³è€…æ ·æœ¬ï¼Œå¹¶ç­–åˆ’ä¸€ä¸ªç´§å‡‘çš„å¾®è°ƒæ•°æ®é›†ã€‚æœ‰äº†è¿™äº›çŸ¥è¯†ï¼Œæˆ‘ä»¬å°±å¯ä»¥çº æ­£è¢«æ±¡æŸ“çš„CLIPæ¨¡å‹ï¼Œæ¶ˆé™¤åé—¨æ•ˆåº”ã€‚åœ¨è§†è§‰è¯†åˆ«åŸºå‡†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„ç­–ç•¥åœ¨åŸºäºCLIPçš„åé—¨é˜²å¾¡ä¸­æ˜¯æœ‰æ•ˆçš„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ æ¨¡å‹ï¼ˆå¦‚CLIPï¼‰åœ¨åé—¨æ”»å‡»ä¸‹çš„è„†å¼±æ€§é—®é¢˜ã€‚ç°æœ‰çš„é˜²å¾¡æ–¹æ³•é€šå¸¸éœ€è¦ä»å¤´å¼€å§‹è®­ç»ƒæ¨¡å‹æˆ–ä½¿ç”¨å¤§é‡æ•°æ®è¿›è¡Œå¾®è°ƒï¼Œè¿™ä¸ä»…è®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œè€Œä¸”éš¾ä»¥ç²¾ç¡®å®šä½å—åˆ°æ”»å‡»å½±å“çš„ç‰¹å®šæ ‡ç­¾å’Œæ ·æœ¬ï¼Œå¯¼è‡´é˜²å¾¡æ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨ä¸€ä¸ªå›¾åƒåˆ†å‰²â€œoracleâ€ä½œä¸ºç›‘ç£ä¿¡å·ï¼Œé€šè¿‡æ¯”è¾ƒè¢«æ±¡æŸ“çš„CLIPæ¨¡å‹å’Œoracleçš„è¾“å‡ºæ¥è¯†åˆ«æ½œåœ¨çš„åé—¨è§¦å‘å™¨ã€‚ç„¶åï¼ŒåŸºäºè¯†åˆ«å‡ºçš„è§¦å‘å™¨ï¼Œç²¾ç¡®å®šä½å—åˆ°åé—¨æ”»å‡»å½±å“çš„æ ‡ç­¾å’Œæ ·æœ¬ã€‚æœ€åï¼Œä½¿ç”¨è¿™äº›ç²¾ç¡®å®šä½çš„æ ·æœ¬æ„å»ºä¸€ä¸ªå°å‹ã€é«˜æ•ˆçš„å¾®è°ƒæ•°æ®é›†ï¼Œä»¥çº æ­£è¢«æ±¡æŸ“çš„CLIPæ¨¡å‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) **è§¦å‘å™¨è¯†åˆ«**ï¼šåˆ©ç”¨å›¾åƒåˆ†å‰²oracleï¼Œé€šè¿‡æ¯”è¾ƒCLIPæ¨¡å‹å’Œoracleçš„è¾“å‡ºæ¥è¯†åˆ«æ½œåœ¨çš„åé—¨è§¦å‘å™¨ã€‚2) **å—å®³è€…æ ·æœ¬å’Œæ ‡ç­¾å®šä½**ï¼šåŸºäºè¯†åˆ«å‡ºçš„è§¦å‘å™¨ï¼Œç²¾ç¡®å®šä½å—åˆ°åé—¨æ”»å‡»å½±å“çš„æ ‡ç­¾å’Œæ ·æœ¬ã€‚3) **æ•°æ®é›†æ„å»º**ï¼šä½¿ç”¨ç²¾ç¡®å®šä½çš„å—å®³è€…æ ·æœ¬å’Œæ ‡ç­¾ï¼Œæ„å»ºä¸€ä¸ªå°å‹ã€é«˜æ•ˆçš„å¾®è°ƒæ•°æ®é›†ã€‚4) **æ¨¡å‹çº æ­£**ï¼šä½¿ç”¨æ„å»ºçš„å¾®è°ƒæ•°æ®é›†å¯¹è¢«æ±¡æŸ“çš„CLIPæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»¥æ¶ˆé™¤åé—¨æ•ˆåº”ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥äº†å›¾åƒåˆ†å‰²â€œoracleâ€ä½œä¸ºç›‘ç£ä¿¡å·ï¼Œå¹¶åˆ©ç”¨è¯¥oracleæ¥æŒ‡å¯¼åé—¨è§¦å‘å™¨çš„è¯†åˆ«å’Œå—å®³è€…æ ·æœ¬çš„å®šä½ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´ç²¾ç¡®åœ°å®šä½å—å½±å“çš„æ ·æœ¬å’Œæ ‡ç­¾ï¼Œä»è€Œå®ç°æ›´é«˜æ•ˆçš„åé—¨é˜²å¾¡ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) **Oracleçš„é€‰æ‹©**ï¼šé€‰æ‹©åˆé€‚çš„å›¾åƒåˆ†å‰²æ¨¡å‹ä½œä¸ºoracleï¼Œä¿è¯å…¶åˆ†å‰²æ€§èƒ½ä¼˜è‰¯ä¸”ä¸CLIPæ¨¡å‹å…·æœ‰ä¸€å®šçš„äº’è¡¥æ€§ã€‚2) **è§¦å‘å™¨è¯†åˆ«ç®—æ³•**ï¼šè®¾è®¡æœ‰æ•ˆçš„ç®—æ³•æ¥æ¯”è¾ƒCLIPæ¨¡å‹å’Œoracleçš„è¾“å‡ºï¼Œä»è€Œå‡†ç¡®è¯†åˆ«åé—¨è§¦å‘å™¨ã€‚3) **å¾®è°ƒæ•°æ®é›†æ„å»ºç­–ç•¥**ï¼šè®¾è®¡åˆç†çš„ç­–ç•¥æ¥é€‰æ‹©å—å®³è€…æ ·æœ¬ï¼Œå¹¶å¹³è¡¡å¾®è°ƒæ•°æ®é›†çš„ç±»åˆ«åˆ†å¸ƒï¼Œä»¥æé«˜å¾®è°ƒæ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡åœ¨è§†è§‰è¯†åˆ«åŸºå‡†ä¸Šè¿›è¡Œäº†å¤§é‡å®éªŒï¼Œè¯æ˜äº†æ‰€æå‡ºçš„ç­–ç•¥åœ¨åŸºäºCLIPçš„åé—¨é˜²å¾¡ä¸­æ˜¯æœ‰æ•ˆçš„ã€‚å…·ä½“æ€§èƒ½æ•°æ®æœªçŸ¥ï¼Œä½†æ‘˜è¦å¼ºè°ƒè¯¥æ–¹æ³•èƒ½å¤Ÿé«˜æ•ˆåœ°è¯†åˆ«åé—¨è§¦å‘å™¨å¹¶ç²¾ç¡®å®šä½å—å®³è€…æ ·æœ¬å’Œæ ‡ç­¾ï¼Œä»è€Œå®ç°æœ‰æ•ˆçš„æ¨¡å‹çº æ­£ï¼Œä¼˜äºéœ€è¦ä»å¤´è®­ç»ƒæˆ–ä½¿ç”¨å¤§å‹æ•°æ®é›†å¾®è°ƒçš„ç°æœ‰æ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§ä¾èµ–å¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ æ¨¡å‹çš„åº”ç”¨åœºæ™¯ï¼Œä¾‹å¦‚å›¾åƒæ£€ç´¢ã€é›¶æ ·æœ¬åˆ†ç±»ã€è§†è§‰é—®ç­”ç­‰ã€‚é€šè¿‡æé«˜æ¨¡å‹æŠµæŠ—åé—¨æ”»å‡»çš„é²æ£’æ€§ï¼Œå¯ä»¥å¢å¼ºè¿™äº›åº”ç”¨çš„å®‰å…¨æ€§å’Œå¯é æ€§ï¼Œé˜²æ­¢æ¶æ„æ”»å‡»è€…åˆ©ç”¨åé—¨æ¼æ´æ“çºµæ¨¡å‹è¡Œä¸ºï¼Œé€ æˆæ½œåœ¨çš„å±å®³ã€‚è¯¥ç ”ç©¶å¯¹äºæ¨åŠ¨å¤šæ¨¡æ€æ·±åº¦å­¦ä¹ æ¨¡å‹çš„å®‰å…¨åº”ç”¨å…·æœ‰é‡è¦æ„ä¹‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The advent of multimodal deep learning models, such as CLIP, has unlocked new frontiers in a wide range of applications, from image-text understanding to classification tasks. However, these models are not safe for adversarial attacks, particularly backdoor attacks, which can subtly manipulate model behavior. Moreover, existing defense methods typically involve training from scratch or fine-tuning using a large dataset without pinpointing the specific labels that are affected. In this study, we introduce an innovative strategy to enhance the robustness of multimodal contrastive learning models against such attacks. In particular, given a poisoned CLIP model, our approach can identify the backdoor trigger and pinpoint the victim samples and labels in an efficient manner. To that end, an image segmentation ``oracle'' is introduced as the supervisor for the output of the poisoned CLIP. We develop two algorithms to rectify the poisoned model: (1) differentiating between CLIP and Oracle's knowledge to identify potential triggers; (2) pinpointing affected labels and victim samples, and curating a compact fine-tuning dataset. With this knowledge, we are allowed to rectify the poisoned CLIP model to negate backdoor effects. Extensive experiments on visual recognition benchmarks demonstrate our strategy is effective in CLIP-based backdoor defense.

