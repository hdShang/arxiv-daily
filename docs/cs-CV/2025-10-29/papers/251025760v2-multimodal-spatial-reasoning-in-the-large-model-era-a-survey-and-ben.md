---
layout: default
title: "Multimodal Spatial Reasoning in the Large Model Era: A Survey and Benchmarks"
---

# Multimodal Spatial Reasoning in the Large Model Era: A Survey and Benchmarks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.25760" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.25760v2</a>
  <a href="https://arxiv.org/pdf/2510.25760.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.25760v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.25760v2', 'Multimodal Spatial Reasoning in the Large Model Era: A Survey and Benchmarks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xu Zheng, Zihao Dongfang, Lutao Jiang, Boyuan Zheng, Yulong Guo, Zhenquan Zhang, Giuliano Albanese, Runyi Yang, Mengjiao Ma, Zixin Zhang, Chenfei Liao, Dingcheng Zhen, Yuanhuiyi Lyu, Yuqian Fu, Bin Ren, Linfeng Zhang, Danda Pani Paudel, Nicu Sebe, Luc Van Gool, Xuming Hu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-29 (æ›´æ–°: 2025-11-02)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/zhengxuJosh/Awesome-Spatial-Reasoning)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç»¼è¿°å¤šæ¨¡æ€ç©ºé—´æ¨ç†å¤§æ¨¡å‹ï¼Œå¹¶æ„å»ºå¼€æ”¾åŸºå‡†è¯„æµ‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)** **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `ç©ºé—´æ¨ç†` `å¤§å‹è¯­è¨€æ¨¡å‹` `å…·èº«æ™ºèƒ½` `è§†è§‰è¯­è¨€å¯¼èˆª` `å¼€æ”¾åŸºå‡†` `åœºæ™¯ç†è§£` `ä¸‰ç»´ç©ºé—´`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹å¤šæ¨¡æ€æ¨¡å‹åœ¨ç©ºé—´æ¨ç†ä»»åŠ¡ä¸Šç¼ºä¹ç³»ç»Ÿçš„è¯„æµ‹åŸºå‡†ï¼Œé˜»ç¢äº†è¯¥é¢†åŸŸçš„å‘å±•å’Œæ¨¡å‹æ€§èƒ½çš„æœ‰æ•ˆæ¯”è¾ƒã€‚
2. æœ¬ç ”ç©¶é€šè¿‡å¯¹å¤šæ¨¡æ€ç©ºé—´æ¨ç†ä»»åŠ¡è¿›è¡Œå…¨é¢çš„ç»¼è¿°ï¼Œå¹¶æ„å»ºå¼€æ”¾åŸºå‡†ï¼Œæ—¨åœ¨ä¿ƒè¿›è¯¥é¢†åŸŸçš„ç ”ç©¶å’Œå‘å±•ã€‚
3. è¯¥ç»¼è¿°æ¶µç›–äº†2Dã€3Dç©ºé—´æ¨ç†ã€å…·èº«æ™ºèƒ½ä»¥åŠæ–°å…´æ¨¡æ€å¦‚éŸ³é¢‘å’Œè‡ªä¸­å¿ƒè§†é¢‘ï¼Œä¸ºç ”ç©¶è€…æä¾›äº†å…¨é¢çš„å‚è€ƒã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äººç±»å…·å¤‡ç©ºé—´æ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥é€šè¿‡è§†è§‰å’Œå¬è§‰ç­‰å¤šæ¨¡æ€è§‚å¯Ÿæ¥ç†è§£ç©ºé—´ã€‚å¤§å‹å¤šæ¨¡æ€æ¨ç†æ¨¡å‹é€šè¿‡å­¦ä¹ æ„ŸçŸ¥å’Œæ¨ç†æ‰©å±•äº†è¿™äº›èƒ½åŠ›ï¼Œå¹¶åœ¨å„ç§ç©ºé—´ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰¯å¥½çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œé’ˆå¯¹è¿™äº›æ¨¡å‹çš„ç³»ç»Ÿæ€§ç»¼è¿°å’Œå…¬å¼€åŸºå‡†ä»ç„¶æœ‰é™ã€‚æœ¬ç»¼è¿°å…¨é¢å›é¡¾äº†ä½¿ç”¨å¤§å‹æ¨¡å‹è¿›è¡Œå¤šæ¨¡æ€ç©ºé—´æ¨ç†çš„ä»»åŠ¡ï¼Œå¯¹å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰çš„æœ€æ–°è¿›å±•è¿›è¡Œäº†åˆ†ç±»ï¼Œå¹¶ä»‹ç»äº†ç”¨äºè¯„ä¼°çš„å¼€æ”¾åŸºå‡†ã€‚æˆ‘ä»¬é¦–å…ˆæ¦‚è¿°äº†ä¸€èˆ¬çš„ç©ºé—´æ¨ç†ï¼Œé‡ç‚¹å…³æ³¨åè®­ç»ƒæŠ€æœ¯ã€å¯è§£é‡Šæ€§å’Œæ¶æ„ã€‚é™¤äº†ç»å…¸çš„2Dä»»åŠ¡å¤–ï¼Œæˆ‘ä»¬è¿˜ç ”ç©¶äº†ç©ºé—´å…³ç³»æ¨ç†ã€åœºæ™¯å’Œå¸ƒå±€ç†è§£ï¼Œä»¥åŠ3Dç©ºé—´ä¸­çš„è§†è§‰é—®ç­”å’Œå®šä½ã€‚æˆ‘ä»¬è¿˜å›é¡¾äº†å…·èº«æ™ºèƒ½çš„è¿›å±•ï¼ŒåŒ…æ‹¬è§†è§‰è¯­è¨€å¯¼èˆªå’ŒåŠ¨ä½œæ¨¡å‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è€ƒè™‘äº†æ–°å…´çš„æ¨¡æ€ï¼Œå¦‚éŸ³é¢‘å’Œä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„è§†é¢‘ï¼Œè¿™äº›æ¨¡æ€é€šè¿‡æ–°çš„ä¼ æ„Ÿå™¨ä¿ƒè¿›äº†æ–°çš„ç©ºé—´ç†è§£ã€‚æˆ‘ä»¬ç›¸ä¿¡æœ¬ç»¼è¿°ä¸ºå¤šæ¨¡æ€ç©ºé—´æ¨ç†è¿™ä¸€ä¸æ–­å‘å±•çš„é¢†åŸŸå¥ å®šäº†åšå®çš„åŸºç¡€ï¼Œå¹¶æä¾›äº†æ·±åˆ»çš„è§è§£ã€‚å…³äºæœ¬ç»¼è¿°çš„æ›´æ–°ä¿¡æ¯ã€ä»£ç å’Œå¼€æ”¾åŸºå‡†çš„å®ç°å¯ä»¥åœ¨https://github.com/zhengxuJosh/Awesome-Spatial-Reasoningæ‰¾åˆ°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„å¤§å‹å¤šæ¨¡æ€æ¨¡å‹åœ¨ç©ºé—´æ¨ç†ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ç¼ºä¹ç»Ÿä¸€çš„è¯„ä¼°æ ‡å‡†å’Œå…¬å¼€å¯ç”¨çš„åŸºå‡†æ•°æ®é›†ã€‚è¿™ä½¿å¾—ç ”ç©¶äººå‘˜éš¾ä»¥å®¢è§‚åœ°æ¯”è¾ƒä¸åŒæ¨¡å‹çš„æ€§èƒ½ï¼Œä¹Ÿé™åˆ¶äº†è¯¥é¢†åŸŸçš„è¿›ä¸€æ­¥å‘å±•ã€‚æ­¤å¤–ï¼Œç°æœ‰çš„ç ”ç©¶å¾€å¾€é›†ä¸­åœ¨è§†è§‰æ¨¡æ€ä¸Šï¼Œå¿½ç•¥äº†å…¶ä»–æ¨¡æ€ï¼ˆå¦‚éŸ³é¢‘ã€è§¦è§‰ç­‰ï¼‰åœ¨ç©ºé—´æ¨ç†ä¸­çš„ä½œç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬ç ”ç©¶çš„æ ¸å¿ƒæ€è·¯æ˜¯ç³»ç»Ÿæ€§åœ°æ¢³ç†å¤šæ¨¡æ€ç©ºé—´æ¨ç†ä»»åŠ¡ï¼Œå¹¶æ„å»ºä¸€ä¸ªå…¨é¢çš„å¼€æ”¾åŸºå‡†ï¼Œç”¨äºè¯„ä¼°å’Œæ¯”è¾ƒä¸åŒæ¨¡å‹çš„æ€§èƒ½ã€‚é€šè¿‡å¯¹ç°æœ‰ç ”ç©¶è¿›è¡Œåˆ†ç±»å’Œæ€»ç»“ï¼Œæœ¬ç ”ç©¶æ—¨åœ¨ä¸ºç ”ç©¶äººå‘˜æä¾›ä¸€ä¸ªæ¸…æ™°çš„æ¡†æ¶ï¼Œå¹¶ä¿ƒè¿›å¤šæ¨¡æ€ç©ºé—´æ¨ç†é¢†åŸŸçš„å‘å±•ã€‚åŒæ—¶ï¼Œæœ¬ç ”ç©¶ä¹Ÿå…³æ³¨æ–°å…´æ¨¡æ€åœ¨ç©ºé—´æ¨ç†ä¸­çš„ä½œç”¨ï¼Œå¹¶æ¢è®¨å¦‚ä½•å°†è¿™äº›æ¨¡æ€èå…¥åˆ°ç°æœ‰çš„æ¨¡å‹ä¸­ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæœ¬ç ”ç©¶çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼š1) å¯¹å¤šæ¨¡æ€ç©ºé—´æ¨ç†ä»»åŠ¡è¿›è¡Œåˆ†ç±»ï¼ŒåŒ…æ‹¬ç©ºé—´å…³ç³»æ¨ç†ã€åœºæ™¯å’Œå¸ƒå±€ç†è§£ã€è§†è§‰é—®ç­”å’Œå®šä½ç­‰ï¼›2) å›é¡¾ç°æœ‰çš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ï¼Œå¹¶åˆ†æå…¶åœ¨ç©ºé—´æ¨ç†ä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼›3) æ„å»ºä¸€ä¸ªå¼€æ”¾åŸºå‡†ï¼ŒåŒ…æ‹¬å¤šä¸ªæ•°æ®é›†å’Œè¯„ä¼°æŒ‡æ ‡ï¼Œç”¨äºè¯„ä¼°ä¸åŒæ¨¡å‹çš„æ€§èƒ½ï¼›4) æ¢è®¨æ–°å…´æ¨¡æ€ï¼ˆå¦‚éŸ³é¢‘ã€è‡ªä¸­å¿ƒè§†é¢‘ï¼‰åœ¨ç©ºé—´æ¨ç†ä¸­çš„ä½œç”¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) é¦–æ¬¡å¯¹å¤šæ¨¡æ€ç©ºé—´æ¨ç†ä»»åŠ¡è¿›è¡Œäº†å…¨é¢çš„ç»¼è¿°ï¼Œå¹¶æä¾›äº†ä¸€ä¸ªæ¸…æ™°çš„åˆ†ç±»æ¡†æ¶ï¼›2) æ„å»ºäº†ä¸€ä¸ªå¼€æ”¾åŸºå‡†ï¼Œä¸ºç ”ç©¶äººå‘˜æä¾›äº†ä¸€ä¸ªç»Ÿä¸€çš„è¯„ä¼°å¹³å°ï¼›3) å…³æ³¨æ–°å…´æ¨¡æ€åœ¨ç©ºé—´æ¨ç†ä¸­çš„ä½œç”¨ï¼Œå¹¶æ¢è®¨å¦‚ä½•å°†è¿™äº›æ¨¡æ€èå…¥åˆ°ç°æœ‰çš„æ¨¡å‹ä¸­ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæœ¬ç ”ç©¶æ›´åŠ ç³»ç»Ÿå’Œå…¨é¢ï¼Œå¹¶å…³æ³¨äº†æ–°å…´æ¨¡æ€åœ¨ç©ºé—´æ¨ç†ä¸­çš„ä½œç”¨ã€‚

**å…³é”®è®¾è®¡**ï¼šæœ¬ç ”ç©¶çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) æ•°æ®é›†çš„é€‰æ‹©ï¼šé€‰æ‹©äº†æ¶µç›–ä¸åŒç©ºé—´æ¨ç†ä»»åŠ¡å’Œæ¨¡æ€çš„æ•°æ®é›†ï¼Œä»¥ä¿è¯åŸºå‡†çš„å…¨é¢æ€§ï¼›2) è¯„ä¼°æŒ‡æ ‡çš„é€‰æ‹©ï¼šé€‰æ‹©äº†èƒ½å¤Ÿåæ˜ æ¨¡å‹åœ¨ä¸åŒæ–¹é¢çš„æ€§èƒ½çš„è¯„ä¼°æŒ‡æ ‡ï¼Œå¦‚å‡†ç¡®ç‡ã€å¬å›ç‡ã€F1å€¼ç­‰ï¼›3) æ¨¡å‹é€‰æ‹©ï¼šé€‰æ‹©äº†å…·æœ‰ä»£è¡¨æ€§çš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ï¼Œä»¥ä¿è¯è¯„ä¼°çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥ç»¼è¿°æ•´ç†äº†å¤šæ¨¡æ€ç©ºé—´æ¨ç†é¢†åŸŸçš„æœ€æ–°è¿›å±•ï¼Œå¹¶æ„å»ºäº†å¼€æ”¾åŸºå‡†ï¼Œä¸ºç ”ç©¶äººå‘˜æä¾›äº†ä¸€ä¸ªç»Ÿä¸€çš„è¯„ä¼°å¹³å°ã€‚é€šè¿‡è¯¥åŸºå‡†ï¼Œç ”ç©¶äººå‘˜å¯ä»¥æ›´æ–¹ä¾¿åœ°æ¯”è¾ƒä¸åŒæ¨¡å‹çš„æ€§èƒ½ï¼Œå¹¶ä¿ƒè¿›è¯¥é¢†åŸŸçš„å‘å±•ã€‚è¯¥ç»¼è¿°è¿˜å…³æ³¨äº†æ–°å…´æ¨¡æ€åœ¨ç©ºé—´æ¨ç†ä¸­çš„ä½œç”¨ï¼Œä¸ºæœªæ¥çš„ç ”ç©¶æ–¹å‘æä¾›äº†æ–°çš„æ€è·¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºæœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ã€è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ç­‰é¢†åŸŸã€‚é€šè¿‡æå‡æ¨¡å‹å¯¹å¤šæ¨¡æ€ç©ºé—´ä¿¡æ¯çš„ç†è§£èƒ½åŠ›ï¼Œå¯ä»¥ä½¿æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­æ›´å¥½åœ°æ„ŸçŸ¥å’Œäº¤äº’ï¼Œä»è€Œå®ç°æ›´æ™ºèƒ½åŒ–çš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Humans possess spatial reasoning abilities that enable them to understand spaces through multimodal observations, such as vision and sound. Large multimodal reasoning models extend these abilities by learning to perceive and reason, showing promising performance across diverse spatial tasks. However, systematic reviews and publicly available benchmarks for these models remain limited. In this survey, we provide a comprehensive review of multimodal spatial reasoning tasks with large models, categorizing recent progress in multimodal large language models (MLLMs) and introducing open benchmarks for evaluation. We begin by outlining general spatial reasoning, focusing on post-training techniques, explainability, and architecture. Beyond classical 2D tasks, we examine spatial relationship reasoning, scene and layout understanding, as well as visual question answering and grounding in 3D space. We also review advances in embodied AI, including vision-language navigation and action models. Additionally, we consider emerging modalities such as audio and egocentric video, which contribute to novel spatial understanding through new sensors. We believe this survey establishes a solid foundation and offers insights into the growing field of multimodal spatial reasoning. Updated information about this survey, codes and implementation of the open benchmarks can be found at https://github.com/zhengxuJosh/Awesome-Spatial-Reasoning.

