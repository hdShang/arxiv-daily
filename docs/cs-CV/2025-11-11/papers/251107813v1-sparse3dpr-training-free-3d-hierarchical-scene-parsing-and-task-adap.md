---
layout: default
title: "Sparse3DPR: Training-Free 3D Hierarchical Scene Parsing and Task-Adaptive Subgraph Reasoning from Sparse RGB Views"
---

# Sparse3DPR: Training-Free 3D Hierarchical Scene Parsing and Task-Adaptive Subgraph Reasoning from Sparse RGB Views

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.07813" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.07813v1</a>
  <a href="https://arxiv.org/pdf/2511.07813.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.07813v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.07813v1', 'Sparse3DPR: Training-Free 3D Hierarchical Scene Parsing and Task-Adaptive Subgraph Reasoning from Sparse RGB Views')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Haida Feng, Hao Wei, Zewen Xu, Haolin Wang, Chade Li, Yihong Wu

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-11

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Sparse3DPRï¼šä¸€ç§åŸºäºç¨€ç–RGBè§†å›¾çš„æ— è®­ç»ƒ3Dåœºæ™¯åˆ†å±‚è§£æä¸ä»»åŠ¡è‡ªé€‚åº”å­å›¾æ¨ç†æ¡†æ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `3Dåœºæ™¯ç†è§£` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ— è®­ç»ƒå­¦ä¹ ` `åœºæ™¯å›¾` `å¹³é¢ç»“æ„`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„3Dåœºæ™¯ç†è§£æ–¹æ³•ï¼Œå°¤å…¶æ˜¯æ— è®­ç»ƒæ–¹æ³•ï¼Œåœ¨å‡†ç¡®æ€§å’Œæ•ˆç‡æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ï¼Œé™åˆ¶äº†å®é™…éƒ¨ç½²ã€‚
2. Sparse3DPRé€šè¿‡å¼•å…¥åˆ†å±‚å¹³é¢å¢å¼ºåœºæ™¯å›¾å’Œä»»åŠ¡è‡ªé€‚åº”å­å›¾æå–ï¼Œæå‡äº†æ¨ç†é“¾çš„æ¸…æ™°åº¦ï¼Œå¹¶å‡å°‘äº†ä¸Šä¸‹æ–‡å™ªå£°ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒSparse3DPRåœ¨Space3D-Benchä¸Šæ˜¾è‘—æå‡äº†æ€§èƒ½å’Œæ•ˆç‡ï¼Œå¹¶åœ¨ScanQAä¸Šå–å¾—äº†ä¸è®­ç»ƒæ–¹æ³•ç›¸å½“çš„ç»“æœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºSparse3DPRï¼Œä¸€ç§æ–°é¢–çš„æ— è®­ç»ƒæ¡†æ¶ï¼Œç”¨äºå¼€æ”¾å¼åœºæ™¯ç†è§£ã€‚è¯¥æ¡†æ¶åˆ©ç”¨é¢„è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›ï¼Œä»…éœ€ç¨€ç–è§†è§’çš„RGBè¾“å…¥ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åˆ†å±‚å¹³é¢å¢å¼ºåœºæ™¯å›¾ï¼Œæ”¯æŒå¼€æ”¾è¯æ±‡è¡¨ï¼Œå¹¶é‡‡ç”¨ä¸»è¦å¹³é¢ç»“æ„ä½œä¸ºç©ºé—´é”šç‚¹ï¼Œä»è€Œå®ç°æ›´æ¸…æ™°çš„æ¨ç†é“¾å’Œæ›´å¯é çš„é«˜çº§æ¨æ–­ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§ä»»åŠ¡è‡ªé€‚åº”å­å›¾æå–æ–¹æ³•ï¼Œä»¥åŠ¨æ€è¿‡æ»¤ä¸æŸ¥è¯¢æ— å…³çš„ä¿¡æ¯ï¼Œå‡å°‘ä¸Šä¸‹æ–‡å™ªå£°ï¼Œæé«˜3Dåœºæ™¯æ¨ç†çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSparse3DPRå…·æœ‰ä¼˜è¶Šæ€§ï¼Œåœ¨Space3D-Benchä¸Šï¼ŒEM@1æŒ‡æ ‡æå‡äº†28.7%ï¼Œé€Ÿåº¦æå‡äº†78.2%ï¼ˆä¸ConceptGraphsç›¸æ¯”ï¼‰ã€‚æ­¤å¤–ï¼ŒSparse3DPRåœ¨ScanQAä¸Šè·å¾—äº†ä¸åŸºäºè®­ç»ƒçš„æ–¹æ³•ç›¸å½“çš„æ€§èƒ½ï¼Œå¹¶é€šè¿‡é¢å¤–çš„çœŸå®ä¸–ç•Œå®éªŒè¯å®äº†å…¶é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰åŸºäºLLMçš„æ— è®­ç»ƒ3Dåœºæ™¯ç†è§£æ–¹æ³•ï¼Œè™½ç„¶å…·æœ‰çµæ´»æ€§å’Œæ³›åŒ–æ€§ï¼Œä½†åœ¨å®é™…åº”ç”¨ä¸­é¢ä¸´å‡†ç¡®ç‡ä½å’Œæ•ˆç‡ä¸è¶³çš„é—®é¢˜ã€‚è¿™äº›æ–¹æ³•éš¾ä»¥æœ‰æ•ˆåœ°ä»ç¨€ç–çš„RGBè§†å›¾ä¸­æå–å…³é”®ä¿¡æ¯ï¼Œå¹¶è¿›è¡Œå¯é çš„æ¨ç†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSparse3DPRçš„æ ¸å¿ƒåœ¨äºåˆ©ç”¨é¢„è®­ç»ƒLLMçš„å¼ºå¤§æ¨ç†èƒ½åŠ›ï¼Œå¹¶ç»“åˆç²¾å¿ƒè®¾è®¡çš„åœºæ™¯å›¾è¡¨ç¤ºå’Œä»»åŠ¡è‡ªé€‚åº”å­å›¾æå–ç­–ç•¥ã€‚é€šè¿‡å°†åœºæ™¯è¡¨ç¤ºä¸ºåˆ†å±‚ã€å¹³é¢å¢å¼ºçš„å›¾ç»“æ„ï¼Œå¹¶åŠ¨æ€è¿‡æ»¤æ— å…³ä¿¡æ¯ï¼Œä»è€Œæé«˜æ¨ç†çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSparse3DPRæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) **åœºæ™¯å›¾æ„å»º**ï¼šä»ç¨€ç–RGBè§†å›¾ä¸­æå–å¹³é¢ç»“æ„ï¼Œå¹¶æ„å»ºåˆ†å±‚åœºæ™¯å›¾ï¼Œå…¶ä¸­å¹³é¢ä½œä¸ºç©ºé—´é”šç‚¹ã€‚2) **å¼€æ”¾è¯æ±‡è¡¨æ”¯æŒ**ï¼šåˆ©ç”¨LLMæ”¯æŒå¼€æ”¾è¯æ±‡è¡¨ï¼Œå…è®¸å¯¹åœºæ™¯ä¸­çš„å¯¹è±¡å’Œå…³ç³»è¿›è¡Œçµæ´»çš„æè¿°ã€‚3) **ä»»åŠ¡è‡ªé€‚åº”å­å›¾æå–**ï¼šæ ¹æ®ç”¨æˆ·æŸ¥è¯¢ï¼ŒåŠ¨æ€æå–ä¸ä»»åŠ¡ç›¸å…³çš„å­å›¾ï¼Œå‡å°‘ä¸Šä¸‹æ–‡å™ªå£°ã€‚4) **LLMæ¨ç†**ï¼šåˆ©ç”¨é¢„è®­ç»ƒLLMå¯¹æå–çš„å­å›¾è¿›è¡Œæ¨ç†ï¼Œç”Ÿæˆæœ€ç»ˆçš„åœºæ™¯ç†è§£ç»“æœã€‚

**å…³é”®åˆ›æ–°**ï¼šSparse3DPRçš„å…³é”®åˆ›æ–°åœ¨äºå…¶åˆ†å±‚å¹³é¢å¢å¼ºåœºæ™¯å›¾å’Œä»»åŠ¡è‡ªé€‚åº”å­å›¾æå–æ–¹æ³•ã€‚ä¼ ç»Ÿçš„åœºæ™¯å›¾è¡¨ç¤ºå¯èƒ½ç¼ºä¹æ˜ç¡®çš„ç©ºé—´ç»“æ„ï¼Œè€ŒSparse3DPRé€šè¿‡å¼•å…¥å¹³é¢ç»“æ„ä½œä¸ºç©ºé—´é”šç‚¹ï¼Œå¢å¼ºäº†æ¨ç†é“¾çš„æ¸…æ™°åº¦ã€‚æ­¤å¤–ï¼Œä»»åŠ¡è‡ªé€‚åº”å­å›¾æå–èƒ½å¤Ÿæœ‰æ•ˆåœ°è¿‡æ»¤æ— å…³ä¿¡æ¯ï¼Œæé«˜æ¨ç†æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨åœºæ™¯å›¾æ„å»ºé˜¶æ®µï¼Œéœ€è¦ç²¾ç¡®åœ°æå–åœºæ™¯ä¸­çš„å¹³é¢ç»“æ„ï¼Œå¹¶å°†å…¶ä½œä¸ºèŠ‚ç‚¹æ·»åŠ åˆ°åœºæ™¯å›¾ä¸­ã€‚å­å›¾æå–ç­–ç•¥éœ€è¦æ ¹æ®ä¸åŒçš„ä»»åŠ¡è¿›è¡Œè°ƒæ•´ï¼Œä»¥ç¡®ä¿æå–çš„å­å›¾åŒ…å«è¶³å¤Ÿçš„ä¿¡æ¯ï¼ŒåŒæ—¶é¿å…å¼•å…¥è¿‡å¤šçš„å™ªå£°ã€‚LLMçš„é€‰æ‹©å’Œpromptè®¾è®¡ä¹Ÿä¼šå½±å“æœ€ç»ˆçš„æ¨ç†ç»“æœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

Sparse3DPRåœ¨Space3D-Benchæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼ŒEM@1æŒ‡æ ‡æé«˜äº†28.7%ï¼Œé€Ÿåº¦æé«˜äº†78.2%ï¼ˆä¸ConceptGraphsç›¸æ¯”ï¼‰ã€‚æ­¤å¤–ï¼ŒSparse3DPRåœ¨ScanQAæ•°æ®é›†ä¸Šè·å¾—äº†ä¸åŸºäºè®­ç»ƒçš„æ–¹æ³•ç›¸å½“çš„æ€§èƒ½ï¼ŒåŒæ—¶åœ¨çœŸå®ä¸–ç•Œå®éªŒä¸­è¡¨ç°å‡ºè‰¯å¥½çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒSparse3DPRæ˜¯ä¸€ç§é«˜æ•ˆä¸”å‡†ç¡®çš„æ— è®­ç»ƒ3Dåœºæ™¯ç†è§£æ¡†æ¶ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Sparse3DPRåœ¨æœºå™¨äººå¯¼èˆªã€æ™ºèƒ½å®¶å±…ã€è™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥å¸®åŠ©æœºå™¨äººç†è§£å‘¨å›´ç¯å¢ƒï¼Œè¿›è¡Œè‡ªä¸»å¯¼èˆªï¼›å¯ä»¥ç”¨äºæ™ºèƒ½å®¶å±…åœºæ™¯ä¸­çš„ç‰©ä½“è¯†åˆ«å’Œäº¤äº’ï¼›è¿˜å¯ä»¥ä¸ºVR/ARåº”ç”¨æä¾›æ›´é€¼çœŸçš„3Dåœºæ™¯ç†è§£èƒ½åŠ›ã€‚è¯¥ç ”ç©¶æœ‰æœ›æ¨åŠ¨3Dåœºæ™¯ç†è§£æŠ€æœ¯çš„å‘å±•ï¼Œå¹¶ä¿ƒè¿›å…¶åœ¨å„ä¸ªé¢†åŸŸçš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recently, large language models (LLMs) have been explored widely for 3D scene understanding. Among them, training-free approaches are gaining attention for their flexibility and generalization over training-based methods. However, they typically struggle with accuracy and efficiency in practical deployment. To address the problems, we propose Sparse3DPR, a novel training-free framework for open-ended scene understanding, which leverages the reasoning capabilities of pre-trained LLMs and requires only sparse-view RGB inputs. Specifically, we introduce a hierarchical plane-enhanced scene graph that supports open vocabulary and adopts dominant planar structures as spatial anchors, which enables clearer reasoning chains and more reliable high-level inferences. Furthermore, we design a task-adaptive subgraph extraction method to filter query-irrelevant information dynamically, reducing contextual noise and improving 3D scene reasoning efficiency and accuracy. Experimental results demonstrate the superiority of Sparse3DPR, which achieves a 28.7% EM@1 improvement and a 78.2% speedup compared with ConceptGraphs on the Space3D-Bench. Moreover, Sparse3DPR obtains comparable performance to training-based methods on ScanQA, with additional real-world experiments confirming its robustness and generalization capability.

