---
layout: default
title: DT-NVS: Diffusion Transformers for Novel View Synthesis
---

# DT-NVS: Diffusion Transformers for Novel View Synthesis

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.08823" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.08823v1</a>
  <a href="https://arxiv.org/pdf/2511.08823.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.08823v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.08823v1', 'DT-NVS: Diffusion Transformers for Novel View Synthesis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wonbong Jang, Jonathan Tremblay, Lourdes Agapito

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-11

**å¤‡æ³¨**: 14 pages

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDT-NVSï¼Œåˆ©ç”¨Transformerçš„3Dæ‰©æ•£æ¨¡å‹å®ç°çœŸå®åœºæ™¯çš„æ–°è§†è§’åˆæˆ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `æ–°è§†è§’åˆæˆ` `æ‰©æ•£æ¨¡å‹` `Transformer` `3Dæ„ŸçŸ¥` `å•ç›®è§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŸºäºæ‰©æ•£æ¨¡å‹çš„æ–°è§†è§’åˆæˆæ–¹æ³•ä¸»è¦é›†ä¸­äºå°èŒƒå›´ç›¸æœºè¿åŠ¨æˆ–éè‡ªç„¶ç‰©ä½“ä¸­å¿ƒåœºæ™¯ï¼Œé™åˆ¶äº†å…¶åœ¨çœŸå®åœºæ™¯ä¸­çš„åº”ç”¨ã€‚
2. DT-NVSåˆ©ç”¨Transformeræ¶æ„ï¼Œæ„å»º3Dæ„ŸçŸ¥çš„æ‰©æ•£æ¨¡å‹ï¼Œå¹¶è®¾è®¡äº†ç›¸æœºæ¡ä»¶ç­–ç•¥ï¼Œä»¥é€‚åº”çœŸå®ä¸–ç•Œæœªå¯¹é½çš„æ•°æ®é›†ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒDT-NVSåœ¨å•è§†è§’å›¾åƒç”Ÿæˆæ–°è§†è§’ä»»åŠ¡ä¸Šï¼Œè¶…è¶Šäº†ç°æœ‰3Dæ„ŸçŸ¥æ‰©æ•£æ¨¡å‹å’Œç¡®å®šæ€§æ–¹æ³•ï¼Œå¹¶èƒ½ç”Ÿæˆå¤šæ ·åŒ–ç»“æœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡é’ˆå¯¹ä»å•è§†è§’å›¾åƒç”Ÿæˆè‡ªç„¶åœºæ™¯æ–°è§†è§’è¿™ä¸€æœªè¢«å……åˆ†æ¢ç´¢çš„é—®é¢˜ï¼Œæå‡ºäº†DT-NVSï¼Œä¸€ç§åŸºäºTransformeræ¶æ„çš„3Dæ„ŸçŸ¥æ‰©æ•£æ¨¡å‹ï¼Œç”¨äºå¹¿ä¹‰æ–°è§†è§’åˆæˆã€‚è¯¥æ¨¡å‹åœ¨åŒ…å«çœŸå®ä¸–ç•Œã€å¤šç±»åˆ«ã€æœªå¯¹é½ä¸”éšæ„æ‹æ‘„çš„æ—¥å¸¸åœºæ™¯è§†é¢‘çš„å¤§è§„æ¨¡æ•°æ®é›†ä¸Šï¼Œä»…ä½¿ç”¨å›¾åƒæŸå¤±è¿›è¡Œè®­ç»ƒã€‚è®ºæ–‡å¯¹Transformerå’Œè‡ªæ³¨æ„åŠ›æœºåˆ¶è¿›è¡Œäº†é‡è¦æ”¹è¿›ï¼Œä»¥å°†å›¾åƒè½¬æ¢ä¸º3Dè¡¨ç¤ºï¼Œå¹¶æå‡ºäº†æ–°çš„ç›¸æœºæ¡ä»¶ç­–ç•¥ï¼Œä»è€Œå¯ä»¥åœ¨çœŸå®ä¸–ç•Œæœªå¯¹é½çš„æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†ä¸€ç§æ–°é¢–çš„è®­ç»ƒèŒƒå¼ï¼Œå³åœ¨æ¡ä»¶å›¾åƒå’Œé‡‡æ ·çš„å™ªå£°è¾“å…¥ä¹‹é—´äº¤æ¢å‚è€ƒå¸§çš„è§’è‰²ã€‚åœ¨å¹¿ä¹‰æ–°è§†è§’åˆæˆä»»åŠ¡ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºæœ€å…ˆè¿›çš„3Dæ„ŸçŸ¥æ‰©æ•£æ¨¡å‹å’Œç¡®å®šæ€§æ–¹æ³•ï¼Œå¹¶èƒ½ç”Ÿæˆå¤šæ ·åŒ–çš„è¾“å‡ºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ä»å•å¼ å›¾åƒç”ŸæˆçœŸå®ä¸–ç•Œå¤æ‚åœºæ™¯çš„æ–°è§†è§’å›¾åƒçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åŸºäºæ‰©æ•£æ¨¡å‹çš„æ–¹æ³•ï¼Œé€šå¸¸å—é™äºå°èŒƒå›´çš„ç›¸æœºè¿åŠ¨æˆ–è€…ä»…é€‚ç”¨äºç‰©ä½“ä¸­å¿ƒåœºæ™¯ï¼Œæ— æ³•å¾ˆå¥½åœ°å¤„ç†çœŸå®ä¸–ç•Œä¸­å¤šç±»åˆ«ã€æœªå¯¹é½çš„æ—¥å¸¸åœºæ™¯è§†é¢‘ã€‚è¿™äº›é™åˆ¶é˜»ç¢äº†æ–°è§†è§’åˆæˆæŠ€æœ¯åœ¨æ›´å¹¿æ³›çš„å®é™…åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨3Dæ„ŸçŸ¥çš„æ‰©æ•£æ¨¡å‹ï¼Œç»“åˆTransformeræ¶æ„çš„å¼ºå¤§è¡¨ç¤ºèƒ½åŠ›ï¼Œå­¦ä¹ ä»å•å¼ å›¾åƒåˆ°3Dåœºæ™¯è¡¨ç¤ºçš„æ˜ å°„ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šç”Ÿæˆæ–°çš„è§†è§’ã€‚é€šè¿‡å¼•å…¥ç›¸æœºæ¡ä»¶ç­–ç•¥å’Œåˆ›æ–°çš„è®­ç»ƒèŒƒå¼ï¼Œæ¨¡å‹èƒ½å¤Ÿé€‚åº”çœŸå®ä¸–ç•Œæœªå¯¹é½çš„æ•°æ®é›†ï¼Œä»è€Œå®ç°æ›´å¹¿ä¹‰çš„æ–°è§†è§’åˆæˆã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDT-NVSçš„æ•´ä½“æ¡†æ¶æ˜¯ä¸€ä¸ªåŸºäºTransformerçš„3Dæ‰©æ•£æ¨¡å‹ã€‚ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) å›¾åƒç¼–ç å™¨ï¼šå°†è¾“å…¥å›¾åƒç¼–ç æˆç‰¹å¾è¡¨ç¤ºã€‚2) 3Dè¡¨ç¤ºæ¨¡å—ï¼šåˆ©ç”¨æ”¹è¿›çš„Transformerå’Œè‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œå°†å›¾åƒç‰¹å¾è½¬æ¢ä¸º3Dåœºæ™¯è¡¨ç¤ºã€‚3) ç›¸æœºæ¡ä»¶æ¨¡å—ï¼šå°†ç›®æ ‡ç›¸æœºçš„ä½å§¿ä¿¡æ¯èå…¥åˆ°æ¨¡å‹ä¸­ï¼ŒæŒ‡å¯¼æ–°è§†è§’çš„ç”Ÿæˆã€‚4) æ‰©æ•£æ¨¡å‹ï¼šé€šè¿‡é€æ­¥å»å™ªçš„è¿‡ç¨‹ï¼Œä»å™ªå£°ä¸­ç”Ÿæˆæ–°è§†è§’çš„å›¾åƒã€‚è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†å›¾åƒæŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š1) é’ˆå¯¹Transformerå’Œè‡ªæ³¨æ„åŠ›æœºåˆ¶çš„æ”¹è¿›ï¼Œä½¿å…¶æ›´é€‚åˆäºå›¾åƒåˆ°3Dè¡¨ç¤ºçš„è½¬æ¢ã€‚2) æ–°çš„ç›¸æœºæ¡ä»¶ç­–ç•¥ï¼Œå…è®¸æ¨¡å‹åœ¨çœŸå®ä¸–ç•Œæœªå¯¹é½çš„æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒã€‚3) åˆ›æ–°çš„è®­ç»ƒèŒƒå¼ï¼Œå³åœ¨æ¡ä»¶å›¾åƒå’Œé‡‡æ ·çš„å™ªå£°è¾“å…¥ä¹‹é—´äº¤æ¢å‚è€ƒå¸§çš„è§’è‰²ï¼Œå¢å¼ºäº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œç»“æ„æ–¹é¢ï¼Œè®ºæ–‡å¯èƒ½é‡‡ç”¨äº†æŸç§å½¢å¼çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œä¾‹å¦‚Sparse Attentionæˆ–è€…Axial Attentionï¼Œä»¥é™ä½è®¡ç®—å¤æ‚åº¦ã€‚åœ¨æŸå¤±å‡½æ•°æ–¹é¢ï¼Œé™¤äº†å¸¸è§çš„L1æˆ–L2æŸå¤±å¤–ï¼Œå¯èƒ½è¿˜ä½¿ç”¨äº†æ„ŸçŸ¥æŸå¤±æˆ–å¯¹æŠ—æŸå¤±ï¼Œä»¥æé«˜ç”Ÿæˆå›¾åƒçš„è´¨é‡ã€‚ç›¸æœºæ¡ä»¶æ¨¡å—çš„è®¾è®¡ä¹Ÿè‡³å…³é‡è¦ï¼Œéœ€è¦æœ‰æ•ˆåœ°å°†ç›¸æœºä½å§¿ä¿¡æ¯èå…¥åˆ°æ¨¡å‹ä¸­ï¼Œä¾‹å¦‚é€šè¿‡ç‰¹å¾èåˆæˆ–æ¡ä»¶å½’ä¸€åŒ–ç­‰æ–¹å¼ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

DT-NVSåœ¨å¹¿ä¹‰æ–°è§†è§’åˆæˆä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¶…è¶Šäº†ç°æœ‰çš„3Dæ„ŸçŸ¥æ‰©æ•£æ¨¡å‹å’Œç¡®å®šæ€§æ–¹æ³•ã€‚å…·ä½“æ€§èƒ½æ•°æ®æœªçŸ¥ï¼Œä½†æ‘˜è¦å¼ºè°ƒäº†å…¶åœ¨ç”Ÿæˆå¤šæ ·åŒ–è¾“å‡ºæ–¹é¢çš„ä¼˜åŠ¿ã€‚è¯¥æ–¹æ³•åœ¨å¤„ç†çœŸå®ä¸–ç•Œã€å¤šç±»åˆ«ã€æœªå¯¹é½çš„æ—¥å¸¸åœºæ™¯è§†é¢‘æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œè¯æ˜äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ã€æœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨æœºå™¨äººå¯¼èˆªä¸­ï¼Œæœºå™¨äººå¯ä»¥åˆ©ç”¨å•ç›®æ‘„åƒå¤´æ‹æ‘„çš„å›¾åƒï¼Œç”Ÿæˆå‘¨å›´ç¯å¢ƒçš„æ–°è§†è§’å›¾åƒï¼Œä»è€Œæ›´å¥½åœ°ç†è§£ç¯å¢ƒå¹¶è§„åˆ’è·¯å¾„ã€‚åœ¨è™šæ‹Ÿç°å®ä¸­ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡å•å¼ ç…§ç‰‡ç”Ÿæˆé€¼çœŸçš„3Dåœºæ™¯ï¼Œä»è€Œè·å¾—æ›´æ²‰æµ¸å¼çš„ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Generating novel views of a natural scene, e.g., every-day scenes both indoors and outdoors, from a single view is an under-explored problem, even though it is an organic extension to the object-centric novel view synthesis. Existing diffusion-based approaches focus rather on small camera movements in real scenes or only consider unnatural object-centric scenes, limiting their potential applications in real-world settings. In this paper we move away from these constrained regimes and propose a 3D diffusion model trained with image-only losses on a large-scale dataset of real-world, multi-category, unaligned, and casually acquired videos of everyday scenes. We propose DT-NVS, a 3D-aware diffusion model for generalized novel view synthesis that exploits a transformer-based architecture backbone. We make significant contributions to transformer and self-attention architectures to translate images to 3d representations, and novel camera conditioning strategies to allow training on real-world unaligned datasets. In addition, we introduce a novel training paradigm swapping the role of reference frame between the conditioning image and the sampled noisy input. We evaluate our approach on the 3D task of generalized novel view synthesis from a single input image and show improvements over state-of-the-art 3D aware diffusion models and deterministic approaches, while generating diverse outputs.

