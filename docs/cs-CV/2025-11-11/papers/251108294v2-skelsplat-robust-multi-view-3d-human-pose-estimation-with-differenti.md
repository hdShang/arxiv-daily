---
layout: default
title: SkelSplat: Robust Multi-view 3D Human Pose Estimation with Differentiable Gaussian Rendering
---

# SkelSplat: Robust Multi-view 3D Human Pose Estimation with Differentiable Gaussian Rendering

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.08294" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.08294v2</a>
  <a href="https://arxiv.org/pdf/2511.08294.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.08294v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.08294v2', 'SkelSplat: Robust Multi-view 3D Human Pose Estimation with Differentiable Gaussian Rendering')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Laura Bragagnolo, Leonardo Barcellona, Stefano Ghidoni

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-11 (æ›´æ–°: 2025-12-02)

**å¤‡æ³¨**: WACV 2026

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**SkelSplatï¼šåŸºäºå¯å¾®é«˜æ–¯æ¸²æŸ“çš„é²æ£’å¤šè§†è§’3Däººä½“å§¿æ€ä¼°è®¡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `3Däººä½“å§¿æ€ä¼°è®¡` `å¤šè§†è§’å­¦ä¹ ` `å¯å¾®æ¸²æŸ“` `é«˜æ–¯æº…å°„` `æ— ç›‘ç£å­¦ä¹ ` `é²æ£’æ€§` `é®æŒ¡å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰3Däººä½“å§¿æ€ä¼°è®¡æ–¹æ³•ä¾èµ–å¤§é‡æ ‡æ³¨æ•°æ®ï¼Œåœ¨æµ‹è¯•åœºæ™¯å˜åŒ–æ—¶æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚
2. SkelSplatå°†äººä½“å§¿æ€å»ºæ¨¡ä¸º3Dé«˜æ–¯éª¨æ¶ï¼Œé€šè¿‡å¯å¾®æ¸²æŸ“ä¼˜åŒ–ï¼Œå®ç°å¤šè§†è§’èåˆï¼Œæ— éœ€3DçœŸå€¼ç›‘ç£ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒSkelSplatåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶å¯¹é®æŒ¡å…·æœ‰é²æ£’æ€§ï¼Œä¸”è·¨æ•°æ®é›†è¯¯å·®æ˜¾è‘—é™ä½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºSkelSplatï¼Œä¸€ç§åŸºäºå¯å¾®é«˜æ–¯æ¸²æŸ“çš„å¤šè§†è§’3Däººä½“å§¿æ€ä¼°è®¡æ–°æ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•ä¾èµ–å¤§é‡æ ‡æ³¨æ•°æ®è®­ç»ƒï¼Œå¯¼è‡´æµ‹è¯•åœºæ™¯æ³›åŒ–æ€§å·®çš„é—®é¢˜ï¼ŒSkelSplatå°†äººä½“å§¿æ€å»ºæ¨¡ä¸º3Dé«˜æ–¯éª¨æ¶ï¼ˆæ¯ä¸ªå…³èŠ‚ä¸€ä¸ªé«˜æ–¯ï¼‰ï¼Œé€šè¿‡å¯å¾®æ¸²æŸ“è¿›è¡Œä¼˜åŒ–ï¼Œä»è€Œåœ¨æ— éœ€3DçœŸå€¼ç›‘ç£çš„æƒ…å†µä¸‹ï¼Œå®ç°ä»»æ„ç›¸æœºè§†è§’çš„æ— ç¼èåˆã€‚é’ˆå¯¹é«˜æ–¯æº…å°„åŸæœ¬ä¸ºç¨ å¯†åœºæ™¯é‡å»ºè®¾è®¡ï¼Œæœ¬æ–‡æå‡ºä¸€ç§æ–°é¢–çš„one-hotç¼–ç æ–¹æ¡ˆï¼Œå®ç°äººä½“å…³èŠ‚çš„ç‹¬ç«‹ä¼˜åŒ–ã€‚åœ¨Human3.6Må’ŒCMUæ•°æ®é›†ä¸Šï¼ŒSkelSplatä¼˜äºä¸ä¾èµ–3DçœŸå€¼çš„æ–¹æ³•ï¼Œå¹¶ä¸”ç›¸æ¯”äºåŸºäºå­¦ä¹ çš„æ–¹æ³•ï¼Œè·¨æ•°æ®é›†è¯¯å·®é™ä½é«˜è¾¾47.8%ã€‚åœ¨Human3.6M-Occå’ŒOcclusion-Personæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å¯¹é®æŒ¡å…·æœ‰é²æ£’æ€§ï¼Œæ— éœ€é’ˆå¯¹ç‰¹å®šåœºæ™¯è¿›è¡Œå¾®è°ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰åŸºäºå­¦ä¹ çš„å¤šè§†è§’3Däººä½“å§¿æ€ä¼°è®¡æ–¹æ³•ä¾èµ–äºå¤§é‡çš„3Dæ ‡æ³¨æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åœ¨å®é™…åº”ç”¨ä¸­çš„æ³›åŒ–èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨æµ‹è¯•åœºæ™¯ä¸è®­ç»ƒåœºæ™¯å­˜åœ¨å·®å¼‚æ—¶ã€‚æ­¤å¤–ï¼Œé®æŒ¡é—®é¢˜ä¹Ÿæ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œéœ€è¦é’ˆå¯¹ç‰¹å®šåœºæ™¯è¿›è¡Œå¾®è°ƒæ‰èƒ½è·å¾—è¾ƒå¥½çš„æ•ˆæœã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSkelSplatçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†äººä½“å§¿æ€è¡¨ç¤ºä¸º3Dé«˜æ–¯åˆ†å¸ƒçš„é›†åˆï¼Œæ¯ä¸ªå…³èŠ‚å¯¹åº”ä¸€ä¸ªé«˜æ–¯åˆ†å¸ƒã€‚é€šè¿‡å¯å¾®é«˜æ–¯æ¸²æŸ“ï¼Œå¯ä»¥å°†è¿™äº›é«˜æ–¯åˆ†å¸ƒæŠ•å½±åˆ°ä¸åŒçš„ç›¸æœºè§†è§’ï¼Œå¹¶è®¡ç®—æ¸²æŸ“å›¾åƒä¸å®é™…å›¾åƒä¹‹é—´çš„å·®å¼‚ã€‚é€šè¿‡ä¼˜åŒ–é«˜æ–¯åˆ†å¸ƒçš„å‚æ•°ï¼Œå¯ä»¥ä½¿å¾—æ¸²æŸ“å›¾åƒä¸å®é™…å›¾åƒå°½å¯èƒ½ä¸€è‡´ï¼Œä»è€Œå®ç°3Däººä½“å§¿æ€çš„ä¼°è®¡ã€‚è¿™ç§æ–¹æ³•ä¸éœ€è¦3DçœŸå€¼ç›‘ç£ï¼Œå¹¶ä¸”å¯ä»¥è‡ªç„¶åœ°èåˆæ¥è‡ªä¸åŒè§†è§’çš„è§‚æµ‹ä¿¡æ¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSkelSplatçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ­¥éª¤ï¼š1) ä»å¤šä¸ªç›¸æœºè§†è§’è·å–å›¾åƒï¼›2) åˆå§‹åŒ–äººä½“éª¨éª¼çš„3Dé«˜æ–¯è¡¨ç¤ºï¼Œæ¯ä¸ªå…³èŠ‚å¯¹åº”ä¸€ä¸ªé«˜æ–¯åˆ†å¸ƒï¼›3) ä½¿ç”¨å¯å¾®é«˜æ–¯æ¸²æŸ“å°†3Dé«˜æ–¯åˆ†å¸ƒæŠ•å½±åˆ°æ¯ä¸ªç›¸æœºè§†è§’ï¼Œç”Ÿæˆæ¸²æŸ“å›¾åƒï¼›4) è®¡ç®—æ¸²æŸ“å›¾åƒä¸å®é™…å›¾åƒä¹‹é—´çš„æŸå¤±ï¼Œä¾‹å¦‚å…‰åº¦æŸå¤±ï¼›5) ä½¿ç”¨æ¢¯åº¦ä¸‹é™ä¼˜åŒ–3Dé«˜æ–¯åˆ†å¸ƒçš„å‚æ•°ï¼Œä½¿å¾—æ¸²æŸ“å›¾åƒä¸å®é™…å›¾åƒå°½å¯èƒ½ä¸€è‡´ï¼›6) ä»ä¼˜åŒ–åçš„3Dé«˜æ–¯åˆ†å¸ƒä¸­æå–3Däººä½“å§¿æ€ã€‚

**å…³é”®åˆ›æ–°**ï¼šSkelSplatçš„å…³é”®åˆ›æ–°åœ¨äºä½¿ç”¨å¯å¾®é«˜æ–¯æ¸²æŸ“è¿›è¡Œå¤šè§†è§’3Däººä½“å§¿æ€ä¼°è®¡ï¼Œé¿å…äº†å¯¹3DçœŸå€¼ç›‘ç£çš„ä¾èµ–ã€‚æ­¤å¤–ï¼Œé’ˆå¯¹é«˜æ–¯æº…å°„åŸæœ¬ä¸ºç¨ å¯†åœºæ™¯é‡å»ºè®¾è®¡ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„one-hotç¼–ç æ–¹æ¡ˆï¼Œä½¿å¾—å¯ä»¥ç‹¬ç«‹ä¼˜åŒ–æ¯ä¸ªäººä½“å…³èŠ‚çš„é«˜æ–¯åˆ†å¸ƒï¼Œä»è€Œæé«˜å§¿æ€ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šSkelSplatçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨3Dé«˜æ–¯åˆ†å¸ƒè¡¨ç¤ºäººä½“å…³èŠ‚ï¼Œæ¯ä¸ªé«˜æ–¯åˆ†å¸ƒçš„å‚æ•°åŒ…æ‹¬å‡å€¼ã€æ–¹å·®å’Œé¢œè‰²ï¼›2) ä½¿ç”¨å¯å¾®é«˜æ–¯æ¸²æŸ“å°†3Dé«˜æ–¯åˆ†å¸ƒæŠ•å½±åˆ°ç›¸æœºè§†è§’ï¼Œæ¸²æŸ“è¿‡ç¨‹æ˜¯å¯å¾®çš„ï¼Œå¯ä»¥è®¡ç®—æ¢¯åº¦ï¼›3) ä½¿ç”¨å…‰åº¦æŸå¤±ä½œä¸ºä¼˜åŒ–ç›®æ ‡ï¼Œä½¿å¾—æ¸²æŸ“å›¾åƒä¸å®é™…å›¾åƒå°½å¯èƒ½ä¸€è‡´ï¼›4) ä½¿ç”¨Adamä¼˜åŒ–å™¨ä¼˜åŒ–3Dé«˜æ–¯åˆ†å¸ƒçš„å‚æ•°ï¼›5) one-hotç¼–ç æ–¹æ¡ˆï¼Œç¡®ä¿æ¯ä¸ªå…³èŠ‚çš„ä¼˜åŒ–ç‹¬ç«‹è¿›è¡Œã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

SkelSplatåœ¨Human3.6Må’ŒCMUæ•°æ®é›†ä¸Šå–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼Œä¼˜äºä¸ä¾èµ–3DçœŸå€¼çš„æ–¹æ³•ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œç›¸æ¯”äºåŸºäºå­¦ä¹ çš„æ–¹æ³•ï¼ŒSkelSplatåœ¨è·¨æ•°æ®é›†æµ‹è¯•ä¸­ï¼Œè¯¯å·®é™ä½é«˜è¾¾47.8%ï¼Œè¡¨æ˜å…¶å…·æœ‰æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œåœ¨Human3.6M-Occå’ŒOcclusion-Personæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒSkelSplatå¯¹é®æŒ¡å…·æœ‰é²æ£’æ€§ï¼Œæ— éœ€é’ˆå¯¹ç‰¹å®šåœºæ™¯è¿›è¡Œå¾®è°ƒã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SkelSplatåœ¨å¢å¼ºç°å®ã€äººæœºäº¤äº’ã€è¿åŠ¨åˆ†æã€è™šæ‹Ÿç°å®ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚è¯¥æ–¹æ³•æ— éœ€3DçœŸå€¼ç›‘ç£ï¼Œé™ä½äº†æ•°æ®æ ‡æ³¨æˆæœ¬ï¼Œæé«˜äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚é€šè¿‡èåˆå¤šè§†è§’ä¿¡æ¯ï¼Œå¯ä»¥å®ç°æ›´å‡†ç¡®ã€æ›´é²æ£’çš„3Däººä½“å§¿æ€ä¼°è®¡ï¼Œä¸ºç›¸å…³åº”ç”¨æä¾›æ›´å¯é çš„åŸºç¡€ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Accurate 3D human pose estimation is fundamental for applications such as augmented reality and human-robot interaction. State-of-the-art multi-view methods learn to fuse predictions across views by training on large annotated datasets, leading to poor generalization when the test scenario differs. To overcome these limitations, we propose SkelSplat, a novel framework for multi-view 3D human pose estimation based on differentiable Gaussian rendering. Human pose is modeled as a skeleton of 3D Gaussians, one per joint, optimized via differentiable rendering to enable seamless fusion of arbitrary camera views without 3D ground-truth supervision. Since Gaussian Splatting was originally designed for dense scene reconstruction, we propose a novel one-hot encoding scheme that enables independent optimization of human joints. SkelSplat outperforms approaches that do not rely on 3D ground truth in Human3.6M and CMU, while reducing the cross-dataset error up to 47.8% compared to learning-based methods. Experiments on Human3.6M-Occ and Occlusion-Person demonstrate robustness to occlusions, without scenario-specific fine-tuning. Our project page is available here: https://skelsplat.github.io.

