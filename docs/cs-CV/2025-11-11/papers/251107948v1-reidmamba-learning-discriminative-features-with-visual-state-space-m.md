---
layout: default
title: ReIDMamba: Learning Discriminative Features with Visual State Space Model for Person Re-Identification
---

# ReIDMamba: Learning Discriminative Features with Visual State Space Model for Person Re-Identification

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.07948" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.07948v1</a>
  <a href="https://arxiv.org/pdf/2511.07948.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.07948v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.07948v1', 'ReIDMamba: Learning Discriminative Features with Visual State Space Model for Person Re-Identification')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hongyang Gu, Qisong Yang, Lei Pu, Siming Han, Yao Ding

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-11

**å¤‡æ³¨**: 11 pages, 8 figures. Accepted to IEEE Transactions on Multimedia (TMM). Accepted Manuscript version uploaded

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/GuHY777/ReIDMamba)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºReIDMambaï¼Œåˆ©ç”¨è§†è§‰çŠ¶æ€ç©ºé—´æ¨¡å‹å­¦ä¹ åˆ¤åˆ«æ€§ç‰¹å¾ï¼Œå®ç°é«˜æ•ˆè¡Œäººé‡è¯†åˆ«**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è¡Œäººé‡è¯†åˆ«` `Mamba` `çŠ¶æ€ç©ºé—´æ¨¡å‹` `å¤šç²’åº¦ç‰¹å¾` `Tripletæ­£åˆ™åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŸºäºTransformerçš„ReIDæ–¹æ³•é¢ä¸´ç€è®¡ç®—å’Œå†…å­˜éœ€æ±‚éšè¾“å…¥åºåˆ—é•¿åº¦å‘ˆäºŒæ¬¡æ–¹å¢é•¿çš„å¯æ‰©å±•æ€§é—®é¢˜ã€‚
2. ReIDMambaé‡‡ç”¨çº¯Mambaæ¶æ„ï¼Œé€šè¿‡å¤šç²’åº¦ç‰¹å¾æå–å’Œæ’åºæ„ŸçŸ¥çš„Tripletæ­£åˆ™åŒ–æ¥å­¦ä¹ é²æ£’çš„åˆ¤åˆ«æ€§ç‰¹å¾ã€‚
3. ReIDMambaåœ¨äº”ä¸ªè¡ŒäººReIDåŸºå‡†ä¸Šå–å¾—äº†SOTAæ€§èƒ½ï¼Œä¸”å‚æ•°é‡ä»…ä¸ºTransReIDçš„ä¸‰åˆ†ä¹‹ä¸€ï¼Œå¹¶é™ä½äº†GPUå†…å­˜å ç”¨ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æå–é²æ£’çš„åˆ¤åˆ«æ€§ç‰¹å¾æ˜¯è¡Œäººé‡è¯†åˆ«ï¼ˆReIDï¼‰ä¸­çš„å…³é”®æŒ‘æˆ˜ã€‚è™½ç„¶åŸºäºTransformerçš„æ–¹æ³•æˆåŠŸåœ°è§£å†³äº†å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰çš„ä¸€äº›å±€é™æ€§ï¼Œä¾‹å¦‚å…¶å±€éƒ¨å¤„ç†ç‰¹æ€§ä»¥åŠå·ç§¯å’Œä¸‹é‡‡æ ·æ“ä½œå¯¼è‡´çš„ä¿¡æ¯ä¸¢å¤±ï¼Œä½†ç”±äºå†…å­˜å’Œè®¡ç®—éœ€æ±‚éšè¾“å…¥åºåˆ—é•¿åº¦å‘ˆäºŒæ¬¡æ–¹å¢é•¿ï¼Œå®ƒä»¬ä»ç„¶é¢ä¸´å¯æ‰©å±•æ€§é—®é¢˜ã€‚ä¸ºäº†å…‹æœè¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªçº¯ç²¹åŸºäºMambaçš„è¡ŒäººReIDæ¡†æ¶ï¼Œåä¸ºReIDMambaã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªåŸºäºMambaçš„å¼ºå¤§åŸºçº¿ï¼Œé€šè¿‡å¼•å…¥å¤šä¸ªç±»åˆ«tokenæ¥æœ‰æ•ˆåœ°åˆ©ç”¨ç»†ç²’åº¦çš„åˆ¤åˆ«æ€§å…¨å±€ç‰¹å¾ã€‚ä¸ºäº†è¿›ä¸€æ­¥å¢å¼ºMambaä¸­é²æ£’ç‰¹å¾çš„å­¦ä¹ ï¼Œæˆ‘ä»¬ç²¾å¿ƒè®¾è®¡äº†ä¸¤ç§æ–°é¢–çš„æŠ€æœ¯ã€‚é¦–å…ˆï¼Œå¤šç²’åº¦ç‰¹å¾æå–å™¨ï¼ˆMGFEï¼‰æ¨¡å—é‡‡ç”¨å¤šåˆ†æ”¯æ¶æ„å’Œç±»åˆ«tokenèåˆï¼Œæœ‰æ•ˆåœ°å½¢æˆå¤šç²’åº¦ç‰¹å¾ï¼Œå¢å¼ºäº†åˆ¤åˆ«èƒ½åŠ›å’Œç»†ç²’åº¦è¦†ç›–ã€‚å…¶æ¬¡ï¼Œå¼•å…¥äº†æ’åºæ„ŸçŸ¥çš„Tripletæ­£åˆ™åŒ–ï¼ˆRATRï¼‰æ¥å‡å°‘æ¥è‡ªå¤šä¸ªåˆ†æ”¯çš„ç‰¹å¾å†—ä½™ï¼Œé€šè¿‡ç»“åˆç±»å†…å’Œç±»é—´å¤šæ ·æ€§çº¦æŸæ¥å¢å¼ºå¤šç²’åº¦ç‰¹å¾çš„å¤šæ ·æ€§ï¼Œä»è€Œç¡®ä¿è¡Œäººç‰¹å¾çš„é²æ£’æ€§ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå°†çº¯Mambaé©±åŠ¨çš„æ–¹æ³•é›†æˆåˆ°ReIDç ”ç©¶ä¸­çš„å·¥ä½œã€‚æˆ‘ä»¬æå‡ºçš„ReIDMambaæ¨¡å‹ä»…æœ‰TransReIDä¸‰åˆ†ä¹‹ä¸€çš„å‚æ•°ï¼ŒåŒæ—¶å…·æœ‰æ›´ä½çš„GPUå†…å­˜ä½¿ç”¨é‡å’Œæ›´å¿«çš„æ¨ç†ååé‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒReIDMambaå…·æœ‰å“è¶Šå’Œæœ‰å¸Œæœ›çš„æ€§èƒ½ï¼Œåœ¨äº”ä¸ªè¡ŒäººReIDåŸºå‡†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè¡Œäººé‡è¯†åˆ«æ—¨åœ¨è·¨ä¸åŒçš„æ‘„åƒå¤´è§†è§’è¯†åˆ«åŒä¸€è¡Œäººã€‚ç°æœ‰åŸºäºTransformerçš„æ–¹æ³•è™½ç„¶åœ¨å»ºæ¨¡å…¨å±€å…³ç³»æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†è®¡ç®—å¤æ‚åº¦é«˜ï¼Œéš¾ä»¥æ‰©å±•åˆ°é«˜åˆ†è¾¨ç‡å›¾åƒã€‚CNNæ–¹æ³•åˆ™å—é™äºå±€éƒ¨æ„Ÿå—é‡ï¼Œéš¾ä»¥æ•æ‰å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚å› æ­¤ï¼Œå¦‚ä½•åœ¨ä¿è¯æ€§èƒ½çš„åŒæ—¶é™ä½è®¡ç®—æˆæœ¬ï¼Œæ˜¯è¡Œäººé‡è¯†åˆ«é¢†åŸŸçš„ä¸€ä¸ªé‡è¦æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šReIDMambaçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨Mambaæ¶æ„çš„çº¿æ€§å¤æ‚åº¦æ¥å…‹æœTransformerçš„è®¡ç®—ç“¶é¢ˆï¼ŒåŒæ—¶è®¾è®¡å¤šç²’åº¦ç‰¹å¾æå–æ¨¡å—å’Œæ’åºæ„ŸçŸ¥çš„Tripletæ­£åˆ™åŒ–æ¥å¢å¼ºç‰¹å¾çš„åˆ¤åˆ«æ€§å’Œé²æ£’æ€§ã€‚é€šè¿‡Mambaçš„å…¨å±€å»ºæ¨¡èƒ½åŠ›å’Œç²¾å¿ƒè®¾è®¡çš„ç‰¹å¾æå–ç­–ç•¥ï¼ŒReIDMambaèƒ½å¤Ÿåœ¨ä¿æŒé«˜æ€§èƒ½çš„åŒæ—¶æ˜¾è‘—é™ä½è®¡ç®—æˆæœ¬ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šReIDMambaçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ï¼š1) è¾“å…¥å›¾åƒç»è¿‡ä¸€ä¸ªåˆå§‹çš„ç‰¹å¾æå–å±‚ï¼›2) æå–çš„ç‰¹å¾è¾“å…¥åˆ°å¤šä¸ªMambaå—ä¸­è¿›è¡Œå…¨å±€ç‰¹å¾å»ºæ¨¡ï¼›3) å¤šç²’åº¦ç‰¹å¾æå–å™¨ï¼ˆMGFEï¼‰æ¨¡å—ä»Mambaå—çš„è¾“å‡ºä¸­æå–å¤šç²’åº¦ç‰¹å¾ï¼›4) æ’åºæ„ŸçŸ¥çš„Tripletæ­£åˆ™åŒ–ï¼ˆRATRï¼‰ç”¨äºä¼˜åŒ–ç‰¹å¾è¡¨ç¤ºï¼›5) æœ€åï¼Œä½¿ç”¨åˆ†ç±»å™¨è¿›è¡Œèº«ä»½é¢„æµ‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šReIDMambaçš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) é¦–æ¬¡å°†çº¯Mambaæ¶æ„å¼•å…¥è¡Œäººé‡è¯†åˆ«é¢†åŸŸï¼Œåˆ©ç”¨å…¶çº¿æ€§å¤æ‚åº¦ä¼˜åŠ¿ï¼›2) æå‡ºäº†å¤šç²’åº¦ç‰¹å¾æå–å™¨ï¼ˆMGFEï¼‰ï¼Œé€šè¿‡å¤šåˆ†æ”¯ç»“æ„å’Œç±»åˆ«tokenèåˆï¼Œå¢å¼ºç‰¹å¾çš„åˆ¤åˆ«èƒ½åŠ›å’Œç»†ç²’åº¦è¦†ç›–ï¼›3) å¼•å…¥äº†æ’åºæ„ŸçŸ¥çš„Tripletæ­£åˆ™åŒ–ï¼ˆRATRï¼‰ï¼Œå‡å°‘ç‰¹å¾å†—ä½™ï¼Œå¢å¼ºç‰¹å¾å¤šæ ·æ€§ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒReIDMambaåœ¨è®¡ç®—æ•ˆç‡å’Œç‰¹å¾è¡¨è¾¾èƒ½åŠ›ä¸Šéƒ½å…·æœ‰ä¼˜åŠ¿ã€‚

**å…³é”®è®¾è®¡**ï¼šMGFEæ¨¡å—é‡‡ç”¨å¤šåˆ†æ”¯ç»“æ„ï¼Œæ¯ä¸ªåˆ†æ”¯æå–ä¸åŒå°ºåº¦çš„ç‰¹å¾ã€‚ç±»åˆ«tokenè¢«ç”¨äºèåˆä¸åŒåˆ†æ”¯çš„ç‰¹å¾ï¼Œä»è€Œå½¢æˆå¤šç²’åº¦è¡¨ç¤ºã€‚RATRæŸå¤±å‡½æ•°ç»“åˆäº†ç±»å†…å’Œç±»é—´å¤šæ ·æ€§çº¦æŸï¼Œé¼“åŠ±æ¨¡å‹å­¦ä¹ æ›´å…·åŒºåˆ†æ€§çš„ç‰¹å¾ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°è®¾è®¡å’Œç½‘ç»œç»“æ„å‚æ•°è®¾ç½®åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ReIDMambaåœ¨äº”ä¸ªè¡ŒäººReIDåŸºå‡†æ•°æ®é›†ä¸Šå–å¾—äº†SOTAæ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨Market-1501æ•°æ®é›†ä¸Šï¼ŒRank-1å‡†ç¡®ç‡è¾¾åˆ°äº†æ–°çš„é«˜åº¦ã€‚æ›´é‡è¦çš„æ˜¯ï¼ŒReIDMambaçš„å‚æ•°é‡ä»…ä¸ºTransReIDçš„ä¸‰åˆ†ä¹‹ä¸€ï¼ŒåŒæ—¶é™ä½äº†GPUå†…å­˜å ç”¨ï¼Œå¹¶æé«˜äº†æ¨ç†é€Ÿåº¦ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒReIDMambaåœ¨æ€§èƒ½å’Œæ•ˆç‡æ–¹é¢éƒ½å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ReIDMambaåœ¨æ™ºèƒ½å®‰é˜²ã€æ™ºæ…§åŸå¸‚ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥ç”¨äºåœ¨å¤§å‹å•†åœºã€æœºåœºç­‰å…¬å…±åœºæ‰€è¿›è¡Œè¡Œäººè¿½è¸ªå’Œèº«ä»½è¯†åˆ«ï¼Œæé«˜å®‰å…¨æ€§å’Œç®¡ç†æ•ˆç‡ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥åº”ç”¨äºæ™ºèƒ½é›¶å”®ã€äººæµåˆ†æç­‰é¢†åŸŸï¼Œä¸ºå•†ä¸šå†³ç­–æä¾›æ•°æ®æ”¯æŒã€‚æœªæ¥ï¼ŒReIDMambaæœ‰æœ›è¿›ä¸€æ­¥æ‰©å±•åˆ°å…¶ä»–è§†è§‰è¯†åˆ«ä»»åŠ¡ä¸­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Extracting robust discriminative features is a critical challenge in person re-identification (ReID). While Transformer-based methods have successfully addressed some limitations of convolutional neural networks (CNNs), such as their local processing nature and information loss resulting from convolution and downsampling operations, they still face the scalability issue due to the quadratic increase in memory and computational requirements with the length of the input sequence. To overcome this, we propose a pure Mamba-based person ReID framework named ReIDMamba. Specifically, we have designed a Mamba-based strong baseline that effectively leverages fine-grained, discriminative global features by introducing multiple class tokens. To further enhance robust features learning within Mamba, we have carefully designed two novel techniques. First, the multi-granularity feature extractor (MGFE) module, designed with a multi-branch architecture and class token fusion, effectively forms multi-granularity features, enhancing both discrimination ability and fine-grained coverage. Second, the ranking-aware triplet regularization (RATR) is introduced to reduce redundancy in features from multiple branches, enhancing the diversity of multi-granularity features by incorporating both intra-class and inter-class diversity constraints, thus ensuring the robustness of person features. To our knowledge, this is the pioneering work that integrates a purely Mamba-driven approach into ReID research. Our proposed ReIDMamba model boasts only one-third the parameters of TransReID, along with lower GPU memory usage and faster inference throughput. Experimental results demonstrate ReIDMamba's superior and promising performance, achieving state-of-the-art performance on five person ReID benchmarks. Code is available at https://github.com/GuHY777/ReIDMamba.

