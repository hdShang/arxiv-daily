---
layout: default
title: Smart-GRPO: Smartly Sampling Noise for Efficient RL of Flow-Matching Models
---

# Smart-GRPO: Smartly Sampling Noise for Efficient RL of Flow-Matching Models

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.02654" target="_blank" class="toolbar-btn">arXiv: 2510.02654v1</a>
    <a href="https://arxiv.org/pdf/2510.02654.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.02654v1" 
            onclick="toggleFavorite(this, '2510.02654v1', 'Smart-GRPO: Smartly Sampling Noise for Efficient RL of Flow-Matching Models')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Benjamin Yu, Jackie Liu, Justin Cui

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-03

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**Smart-GRPOÔºö‰ºòÂåñÂô™Â£∞ÈááÊ†∑ÔºåÊèêÂçáFlow-MatchingÊ®°ÂûãÂº∫ÂåñÂ≠¶‰π†ÊïàÁéá**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Flow-MatchingÊ®°Âûã` `Âº∫ÂåñÂ≠¶‰π†` `Âô™Â£∞‰ºòÂåñ` `ÂõæÂÉèÁîüÊàê` `ÊñáÊú¨Âà∞ÂõæÂÉèÁîüÊàê`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Flow-MatchingÊ®°ÂûãÁöÑÁ°ÆÂÆöÊÄß‰ΩøÂÖ∂Èöæ‰ª•Áõ¥Êé•Â∫îÁî®Âº∫ÂåñÂ≠¶‰π†ËøõË°å‰ºòÂåñÔºåÈôêÂà∂‰∫ÜÂõæÂÉèË¥®ÈáèÂíå‰∫∫Á±ªÂØπÈΩêÁöÑÊèêÂçá„ÄÇ
2. Smart-GRPOÈÄöËøáËø≠‰ª£ÊêúÁ¥¢Âíå‰ºòÂåñÂô™Â£∞Êâ∞Âä®ÔºåÂºïÂØºÂô™Â£∞ÂàÜÂ∏ÉÂêëÊõ¥È´òÂ•ñÂä±Âå∫ÂüüÁßªÂä®Ôºå‰ªéËÄåÂÆûÁé∞Êõ¥ÊúâÊïàÁöÑÂº∫ÂåñÂ≠¶‰π†„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåSmart-GRPOÂú®Â•ñÂä±‰ºòÂåñÂíåËßÜËßâË¥®ÈáèÊñπÈù¢Âùá‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºå‰∏∫Flow-MatchingÊ®°ÂûãÁöÑÂº∫ÂåñÂ≠¶‰π†Êèê‰æõ‰∫ÜÊñ∞ÊÄùË∑Ø„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËøëÂπ¥Êù•ÔºåFlow-MatchingÊ®°ÂûãÂú®È´òË¥®ÈáèÊñáÊú¨Âà∞ÂõæÂÉèÁîüÊàêÊñπÈù¢ÂèñÂæó‰∫ÜÊòæËëóËøõÂ±ï„ÄÇÁÑ∂ËÄåÔºåFlow-MatchingÊ®°ÂûãÁöÑÁ°ÆÂÆöÊÄßÁâπÊÄß‰ΩøÂÖ∂‰∏çÂ§™ÈÄÇÂêàÂº∫ÂåñÂ≠¶‰π†ÔºåËÄåÂº∫ÂåñÂ≠¶‰π†ÊòØÊèêÈ´òÂõæÂÉèË¥®ÈáèÂíå‰∫∫Á±ªÂØπÈΩêÁöÑÂÖ≥ÈîÆÂ∑•ÂÖ∑„ÄÇÂÖàÂâçÁöÑÂ∑•‰ΩúÈÄöËøáÁî®ÈöèÊú∫Âô™Â£∞Êâ∞Âä®ÊΩúÂú®ÂèòÈáèÊù•ÂºïÂÖ•ÈöèÊú∫ÊÄßÔºå‰ΩÜËøôÁßçÊâ∞Âä®ÊïàÁéá‰Ωé‰∏ã‰∏î‰∏çÁ®≥ÂÆö„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫ÜSmart-GRPOÔºåËøôÊòØÁ¨¨‰∏Ä‰∏™‰ºòÂåñFlow-MatchingÊ®°Âûã‰∏≠Âº∫ÂåñÂ≠¶‰π†Âô™Â£∞Êâ∞Âä®ÁöÑÊñπÊ≥ï„ÄÇSmart-GRPOÈááÁî®Ëø≠‰ª£ÊêúÁ¥¢Á≠ñÁï•ÔºåËß£Á†ÅÂÄôÈÄâÊâ∞Âä®Ôºå‰ΩøÁî®Â•ñÂä±ÂáΩÊï∞ËØÑ‰º∞ÂÆÉ‰ª¨ÔºåÂπ∂Â∞ÜÂô™Â£∞ÂàÜÂ∏ÉÁªÜÂåñÂà∞Êõ¥È´òÂ•ñÂä±ÁöÑÂå∫Âüü„ÄÇÂÆûÈ™åË°®ÊòéÔºå‰∏éÂü∫Á∫øÊñπÊ≥ïÁõ∏ÊØîÔºåSmart-GRPOÊèêÈ´ò‰∫ÜÂ•ñÂä±‰ºòÂåñÂíåËßÜËßâË¥®Èáè„ÄÇÊàë‰ª¨ÁöÑÁªìÊûúË°®ÊòéÔºåÂú®Flow-MatchingÊ°ÜÊû∂‰∏≠ÔºåÂº∫ÂåñÂ≠¶‰π†ÊòØ‰∏ÄÊù°ÂèØË°åÁöÑÈÄîÂæÑÔºåÂº•Âêà‰∫ÜÈ´òÊïàËÆ≠ÁªÉÂíå‰∫∫Á±ªÂØπÈΩêÁîüÊàê‰πãÈó¥ÁöÑÂ∑ÆË∑ù„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöFlow-MatchingÊ®°ÂûãÂú®ÂõæÂÉèÁîüÊàêÈ¢ÜÂüüË°®Áé∞Âá∫Ëâ≤Ôºå‰ΩÜÂÖ∂Á°ÆÂÆöÊÄßÁâπÊÄß‰ΩøÂÖ∂Èöæ‰ª•Áõ¥Êé•Â∫îÁî®Âº∫ÂåñÂ≠¶‰π†ËøõË°å‰ºòÂåñÔºåËÄåÂº∫ÂåñÂ≠¶‰π†ÂØπ‰∫éÊèêÂçáÂõæÂÉèË¥®ÈáèÂíå‰∏é‰∫∫Á±ªÂÅèÂ•ΩÂØπÈΩêËá≥ÂÖ≥ÈáçË¶Å„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöËøáÊ∑ªÂä†ÈöèÊú∫Âô™Â£∞Êù•ÂºïÂÖ•ÈöèÊú∫ÊÄßÔºå‰ΩÜËøôÁßçÊñπÂºèÊïàÁéá‰Ωé‰∏ãÔºåÂÆπÊòìÂØºËá¥ËÆ≠ÁªÉ‰∏çÁ®≥ÂÆöÔºåÈöæ‰ª•ÊúâÊïàÊé¢Á¥¢È´òÂ•ñÂä±Âå∫Âüü„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöSmart-GRPOÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØ‰ºòÂåñÂô™Â£∞ÁöÑÈááÊ†∑Á≠ñÁï•Ôºå‰ΩøÂÖ∂ËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞Êé¢Á¥¢È´òÂ•ñÂä±Âå∫Âüü„ÄÇÈÄöËøáÂ≠¶‰π†‰∏Ä‰∏™Âô™Â£∞ÂàÜÂ∏ÉÔºåËØ•ÂàÜÂ∏ÉËÉΩÂ§üÁîüÊàêÊõ¥ÊúâÂà©‰∫éÂº∫ÂåñÂ≠¶‰π†ÁöÑÊâ∞Âä®Ôºå‰ªéËÄåÊèêÈ´òËÆ≠ÁªÉÊïàÁéáÂíåÊúÄÁªàÊÄßËÉΩ„ÄÇËøôÁßçÊñπÊ≥ïÊó®Âú®ÂÖãÊúçÈöèÊú∫Âô™Â£∞Êâ∞Âä®ÁöÑ‰ΩéÊïàÊÄßÂíå‰∏çÁ®≥ÂÆöÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöSmart-GRPOÈááÁî®Ëø≠‰ª£ÊêúÁ¥¢Á≠ñÁï•„ÄÇÈ¶ñÂÖàÔºå‰ªéÂΩìÂâçÁöÑÂô™Â£∞ÂàÜÂ∏É‰∏≠ÈááÊ†∑ÂÄôÈÄâÊâ∞Âä®„ÄÇÁÑ∂ÂêéÔºåÂ∞ÜËøô‰∫õÊâ∞Âä®Â∫îÁî®‰∫éFlow-MatchingÊ®°ÂûãÔºåÁîüÊàêÁõ∏Â∫îÁöÑÂõæÂÉè„ÄÇÊé•‰∏ãÊù•Ôºå‰ΩøÁî®Â•ñÂä±ÂáΩÊï∞ËØÑ‰º∞Ëøô‰∫õÂõæÂÉèÁöÑË¥®Èáè„ÄÇÊúÄÂêéÔºåÊ†πÊçÆÂ•ñÂä±ÂÄºÊõ¥Êñ∞Âô™Â£∞ÂàÜÂ∏ÉÔºå‰ΩøÂÖ∂ÂêëÊõ¥È´òÂ•ñÂä±ÁöÑÂå∫ÂüüÁßªÂä®„ÄÇËøô‰∏™ËøáÁ®ã‰∏çÊñ≠Ëø≠‰ª£ÔºåÁõ¥Âà∞Âô™Â£∞ÂàÜÂ∏ÉÊî∂ÊïõÂà∞ÊúÄ‰ºòÁä∂ÊÄÅ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöSmart-GRPOÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÆÉ‰∏çÊòØÁÆÄÂçïÂú∞Ê∑ªÂä†ÈöèÊú∫Âô™Â£∞ÔºåËÄåÊòØÂ≠¶‰π†‰∏Ä‰∏™Âô™Â£∞ÂàÜÂ∏ÉÔºåÂπ∂‰ºòÂåñËøô‰∏™ÂàÜÂ∏É‰ª•ÊúÄÂ§ßÂåñÂº∫ÂåñÂ≠¶‰π†ÁöÑÂ•ñÂä±„ÄÇËøôÁßçÊñπÊ≥ïËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞Êé¢Á¥¢Áä∂ÊÄÅÁ©∫Èó¥ÔºåÂπ∂ÊâæÂà∞Êõ¥ÊúâÂà©‰∫éÊèêÈ´òÂõæÂÉèË¥®ÈáèÁöÑÊâ∞Âä®„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåSmart-GRPOËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞Âà©Áî®Âº∫ÂåñÂ≠¶‰π†ÁöÑÂèçÈ¶à‰ø°Âè∑„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöSmart-GRPOÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ‰ΩøÁî®ÂèÇÊï∞ÂåñÁöÑÂô™Â£∞ÂàÜÂ∏ÉÔºà‰æãÂ¶ÇÈ´òÊñØÂàÜÂ∏ÉÔºâÊù•Ë°®Á§∫Âô™Â£∞Ôºõ2) ‰ΩøÁî®Â•ñÂä±ÂáΩÊï∞Êù•ËØÑ‰º∞ÁîüÊàêÂõæÂÉèÁöÑË¥®ÈáèÔºõ3) ‰ΩøÁî®‰ºòÂåñÁÆóÊ≥ïÔºà‰æãÂ¶ÇÊ¢ØÂ∫¶‰∏ãÈôçÔºâÊù•Êõ¥Êñ∞Âô™Â£∞ÂàÜÂ∏ÉÁöÑÂèÇÊï∞„ÄÇÂ•ñÂä±ÂáΩÊï∞ÁöÑËÆæËÆ°Ëá≥ÂÖ≥ÈáçË¶ÅÔºåÈúÄË¶ÅËÉΩÂ§üÂáÜÁ°ÆÂèçÊò†ÂõæÂÉèÁöÑË¥®ÈáèÂíå‰∏é‰∫∫Á±ªÂÅèÂ•ΩÁöÑÂØπÈΩêÁ®ãÂ∫¶„ÄÇÂô™Â£∞ÂàÜÂ∏ÉÁöÑÂèÇÊï∞ÂåñÂΩ¢ÂºèÂíå‰ºòÂåñÁÆóÊ≥ïÁöÑÈÄâÊã©‰πü‰ºöÂΩ±ÂìçÊúÄÁªàÁöÑÊÄßËÉΩ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåSmart-GRPOÂú®Â•ñÂä±‰ºòÂåñÂíåËßÜËßâË¥®ÈáèÊñπÈù¢Âùá‰ºò‰∫éÂü∫Á∫øÊñπÊ≥ï„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåSmart-GRPOËÉΩÂ§üÊõ¥Âø´Âú∞Êî∂ÊïõÂà∞Êõ¥È´òÁöÑÂ•ñÂä±ÂÄºÔºåÂπ∂‰∏îÁîüÊàêÁöÑÂõæÂÉèÂÖ∑ÊúâÊõ¥È´òÁöÑËßÜËßâË¥®Èáè„ÄÇ‰∏éÈöèÊú∫Âô™Â£∞Êâ∞Âä®Áõ∏ÊØîÔºåSmart-GRPOËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞Êé¢Á¥¢Áä∂ÊÄÅÁ©∫Èó¥ÔºåÂπ∂ÊâæÂà∞Êõ¥ÊúâÂà©‰∫éÊèêÈ´òÂõæÂÉèË¥®ÈáèÁöÑÊâ∞Âä®„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

Smart-GRPOÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂèØÁî®‰∫éÊîπËøõÂêÑÁßçÂü∫‰∫éFlow-MatchingÊ®°ÂûãÁöÑÂõæÂÉèÁîüÊàê‰ªªÂä°Ôºå‰æãÂ¶ÇÊñáÊú¨Âà∞ÂõæÂÉèÁîüÊàê„ÄÅÂõæÂÉè‰øÆÂ§çÂíåÂõæÂÉèÁºñËæë„ÄÇÈÄöËøá‰ºòÂåñÂô™Â£∞ÈááÊ†∑Á≠ñÁï•ÔºåÂèØ‰ª•ÊèêÈ´òÁîüÊàêÂõæÂÉèÁöÑË¥®ÈáèÂíå‰∏é‰∫∫Á±ªÂÅèÂ•ΩÁöÑÂØπÈΩêÁ®ãÂ∫¶„ÄÇËØ•ÊñπÊ≥ïËøòÂèØ‰ª•Â∫îÁî®‰∫éÂÖ∂‰ªñÁîüÊàêÊ®°ÂûãÔºå‰∏∫Âº∫ÂåñÂ≠¶‰π†Âú®ÁîüÊàêÊ®°Âûã‰∏≠ÁöÑÂ∫îÁî®ÂºÄËæü‰∫ÜÊñ∞ÁöÑÈÄîÂæÑ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Recent advancements in flow-matching have enabled high-quality text-to-image generation. However, the deterministic nature of flow-matching models makes them poorly suited for reinforcement learning, a key tool for improving image quality and human alignment. Prior work has introduced stochasticity by perturbing latents with random noise, but such perturbations are inefficient and unstable. We propose Smart-GRPO, the first method to optimize noise perturbations for reinforcement learning in flow-matching models. Smart-GRPO employs an iterative search strategy that decodes candidate perturbations, evaluates them with a reward function, and refines the noise distribution toward higher-reward regions. Experiments demonstrate that Smart-GRPO improves both reward optimization and visual quality compared to baseline methods. Our results suggest a practical path toward reinforcement learning in flow-matching frameworks, bridging the gap between efficient training and human-aligned generation.

