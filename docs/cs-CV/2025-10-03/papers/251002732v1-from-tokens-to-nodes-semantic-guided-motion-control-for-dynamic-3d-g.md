---
layout: default
title: From Tokens to Nodes: Semantic-Guided Motion Control for Dynamic 3D Gaussian Splatting
---

# From Tokens to Nodes: Semantic-Guided Motion Control for Dynamic 3D Gaussian Splatting

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.02732" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.02732v1</a>
  <a href="https://arxiv.org/pdf/2510.02732.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.02732v1" onclick="toggleFavorite(this, '2510.02732v1', 'From Tokens to Nodes: Semantic-Guided Motion Control for Dynamic 3D Gaussian Splatting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jianing Chen, Zehao Li, Yujun Cai, Hao Jiang, Shuqin Gao, Honglong Zhao, Tianlu Mao, Yucheng Zhang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-03

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè¯­ä¹‰å¼•å¯¼çš„åŠ¨æ€3Dé«˜æ–¯æº…å°„è¿åŠ¨æ§åˆ¶æ–¹æ³•ï¼Œè§£å†³å•ç›®è§†é¢‘åŠ¨æ€é‡å»ºä¸­çš„æ§åˆ¶ç‚¹åˆ†é…éš¾é¢˜ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åŠ¨æ€3Dé‡å»º` `é«˜æ–¯æº…å°„` `è¿åŠ¨æ§åˆ¶` `è¯­ä¹‰å¼•å¯¼` `è¿åŠ¨è‡ªé€‚åº”` `å•ç›®è§†é¢‘` `è§†è§‰åŸºç¡€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŠ¨æ€3Dé«˜æ–¯æº…å°„æ–¹æ³•åœ¨æ§åˆ¶ç‚¹åˆ†é…ä¸Šå­˜åœ¨ä¸è¶³ï¼Œä»…ä¾èµ–å‡ ä½•ä¿¡æ¯å¯¼è‡´é™æ€åŒºåŸŸå†—ä½™ï¼ŒåŠ¨æ€åŒºåŸŸä¸è¶³ã€‚
2. è®ºæ–‡æå‡ºä¸€ç§è¿åŠ¨è‡ªé€‚åº”æ¡†æ¶ï¼Œåˆ©ç”¨è¯­ä¹‰å’Œè¿åŠ¨å…ˆéªŒï¼Œå®ç°æ§åˆ¶ç‚¹å¯†åº¦ä¸è¿åŠ¨å¤æ‚åº¦çš„å¯¹é½ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é‡å»ºè´¨é‡å’Œæ•ˆç‡ä¸Šå‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå®ç°äº†æ›´å¹³æ»‘å’Œç¨³å®šçš„è¿åŠ¨è¡¨ç¤ºã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§è¿åŠ¨è‡ªé€‚åº”æ¡†æ¶ï¼Œç”¨äºè§£å†³å•ç›®è§†é¢‘åŠ¨æ€3Dé‡å»ºä¸­çš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•é€šè¿‡å‡å°‘é«˜æ–¯åˆ†å¸ƒçš„æ•°é‡æ¥ç¼“è§£è®¡ç®—è´Ÿæ‹…ï¼Œä½†å…¶æ§åˆ¶ç‚¹åˆ†é…çº¯ç²¹åŸºäºå‡ ä½•ä¿¡æ¯ï¼Œå¯¼è‡´é™æ€å†—ä½™å’ŒåŠ¨æ€ä¸è¶³ã€‚æœ¬æ–‡åˆ©ç”¨è§†è§‰åŸºç¡€æ¨¡å‹çš„è¯­ä¹‰å’Œè¿åŠ¨å…ˆéªŒï¼Œå»ºç«‹patch-token-nodeå¯¹åº”å…³ç³»ï¼Œå¹¶åº”ç”¨è¿åŠ¨è‡ªé€‚åº”å‹ç¼©ï¼Œå°†æ§åˆ¶ç‚¹é›†ä¸­åœ¨åŠ¨æ€åŒºåŸŸï¼ŒåŒæ—¶æŠ‘åˆ¶é™æ€èƒŒæ™¯ä¸­çš„å†—ä½™ã€‚é€šè¿‡è¿­ä»£ä½“ç´ åŒ–å’Œè¿åŠ¨è¶‹åŠ¿è¯„åˆ†ï¼Œå®ç°çµæ´»çš„è¡¨å¾å¯†åº¦è‡ªé€‚åº”ï¼Œç›´æ¥è§£å†³æ§åˆ¶ç‚¹åˆ†é…ä¸è¿åŠ¨å¤æ‚åº¦ä¸åŒ¹é…çš„é—®é¢˜ã€‚æ­¤å¤–ï¼Œå¼•å…¥ç”±2Dè½¨è¿¹åˆå§‹åŒ–çš„æ ·æ¡æ›²çº¿è½¨è¿¹å‚æ•°åŒ–ï¼Œæ›¿ä»£åŸºäºMLPçš„å˜å½¢åœºï¼Œä»¥å®ç°æ›´å¹³æ»‘çš„è¿åŠ¨è¡¨ç¤ºå’Œæ›´ç¨³å®šçš„ä¼˜åŒ–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é‡å»ºè´¨é‡å’Œæ•ˆç‡æ–¹é¢å‡ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šåŠ¨æ€3Dé‡å»ºæ—¨åœ¨ä»å•ç›®è§†é¢‘ä¸­æ¢å¤åœºæ™¯çš„åŠ¨æ€3Dç»“æ„ã€‚ç°æœ‰çš„åŸºäº3Dé«˜æ–¯æº…å°„çš„æ–¹æ³•è™½ç„¶å–å¾—äº†è¿›å±•ï¼Œä½†å…¶æ§åˆ¶ç‚¹çš„åˆ†é…ä¸»è¦ä¾èµ–äºå‡ ä½•ä¿¡æ¯ï¼Œå¯¼è‡´åœ¨é™æ€åŒºåŸŸå­˜åœ¨å†—ä½™çš„æ§åˆ¶ç‚¹ï¼Œè€Œåœ¨åŠ¨æ€åŒºåŸŸæ§åˆ¶ç‚¹ä¸è¶³ï¼Œæ— æ³•å……åˆ†æ•æ‰è¿åŠ¨ç»†èŠ‚ã€‚è¿™é™åˆ¶äº†é‡å»ºè´¨é‡å’Œæ•ˆç‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ ¹æ®åœºæ™¯ä¸­ç‰©ä½“çš„è¿åŠ¨å¤æ‚ç¨‹åº¦è‡ªé€‚åº”åœ°åˆ†é…æ§åˆ¶ç‚¹ã€‚é€šè¿‡å¼•å…¥è¯­ä¹‰å’Œè¿åŠ¨å…ˆéªŒï¼Œå°†æ§åˆ¶ç‚¹é›†ä¸­åœ¨åŠ¨æ€åŒºåŸŸï¼ŒåŒæ—¶å‡å°‘é™æ€åŒºåŸŸçš„å†—ä½™ã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨è§£å†³æ§åˆ¶ç‚¹åˆ†é…ä¸è¿åŠ¨å¤æ‚åº¦ä¸åŒ¹é…çš„é—®é¢˜ï¼Œä»è€Œæé«˜é‡å»ºè´¨é‡å’Œæ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) åˆ©ç”¨è§†è§‰åŸºç¡€æ¨¡å‹æå–è¯­ä¹‰å’Œè¿åŠ¨ä¿¡æ¯ï¼›2) å»ºç«‹patch-token-nodeçš„å¯¹åº”å…³ç³»ï¼Œå°†å›¾åƒpatchã€è§†è§‰tokenå’Œ3Dæ§åˆ¶ç‚¹å…³è”èµ·æ¥ï¼›3) åº”ç”¨è¿åŠ¨è‡ªé€‚åº”å‹ç¼©ï¼Œæ ¹æ®è¿åŠ¨è¶‹åŠ¿è¯„åˆ†è°ƒæ•´æ§åˆ¶ç‚¹å¯†åº¦ï¼›4) ä½¿ç”¨æ ·æ¡æ›²çº¿å‚æ•°åŒ–è½¨è¿¹ï¼Œæ›¿ä»£MLPå˜å½¢åœºï¼Œå®ç°æ›´å¹³æ»‘çš„è¿åŠ¨è¡¨ç¤ºã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºè¿åŠ¨è‡ªé€‚åº”çš„æ§åˆ¶ç‚¹åˆ†é…ç­–ç•¥ã€‚ä¸ç°æœ‰æ–¹æ³•ä¸åŒï¼Œè¯¥æ–¹æ³•ä¸å†ä»…ä»…ä¾èµ–å‡ ä½•ä¿¡æ¯ï¼Œè€Œæ˜¯ç»“åˆäº†è¯­ä¹‰å’Œè¿åŠ¨å…ˆéªŒï¼Œå®ç°äº†æ§åˆ¶ç‚¹å¯†åº¦ä¸è¿åŠ¨å¤æ‚åº¦çš„å¯¹é½ã€‚æ­¤å¤–ï¼Œä½¿ç”¨æ ·æ¡æ›²çº¿å‚æ•°åŒ–è½¨è¿¹ä¹Ÿæé«˜äº†è¿åŠ¨è¡¨ç¤ºçš„å¹³æ»‘æ€§å’Œä¼˜åŒ–ç¨³å®šæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šè¯¥æ–¹æ³•ä½¿ç”¨è¿­ä»£ä½“ç´ åŒ–å’Œè¿åŠ¨è¶‹åŠ¿è¯„åˆ†æ¥è°ƒæ•´æ§åˆ¶ç‚¹å¯†åº¦ã€‚è¿åŠ¨è¶‹åŠ¿è¯„åˆ†åŸºäºè§†è§‰åŸºç¡€æ¨¡å‹æå–çš„è¿åŠ¨ä¿¡æ¯ï¼Œç”¨äºè¡¡é‡æ¯ä¸ªåŒºåŸŸçš„è¿åŠ¨å¤æ‚åº¦ã€‚æ ·æ¡æ›²çº¿çš„æ§åˆ¶ç‚¹ç”±2Dè½¨è¿¹åˆå§‹åŒ–ï¼Œå¹¶é€šè¿‡ä¼˜åŒ–æŸå¤±å‡½æ•°æ¥æ‹Ÿåˆ3Dè¿åŠ¨è½¨è¿¹ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°è®¾è®¡å’Œå‚æ•°è®¾ç½®åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ï¼Œä½†å…·ä½“æ•°å€¼æœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡é€šè¿‡å®éªŒéªŒè¯äº†æ‰€æå‡ºæ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é‡å»ºè´¨é‡å’Œæ•ˆç‡æ–¹é¢å‡ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦åœ¨è®ºæ–‡ä¸­ç»™å‡ºï¼Œä½†å…·ä½“æ•°å€¼æœªçŸ¥ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿæ›´å‡†ç¡®åœ°æ•æ‰åŠ¨æ€åœºæ™¯ä¸­çš„è¿åŠ¨ç»†èŠ‚ï¼Œå¹¶å‡å°‘é™æ€åŒºåŸŸçš„å†—ä½™è®¡ç®—ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ã€æœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸã€‚é€šè¿‡æ›´å‡†ç¡®å’Œé«˜æ•ˆåœ°é‡å»ºåŠ¨æ€3Dåœºæ™¯ï¼Œå¯ä»¥æå‡ç”¨æˆ·ä½“éªŒï¼Œå¢å¼ºæœºå™¨äººçš„ç¯å¢ƒæ„ŸçŸ¥èƒ½åŠ›ï¼Œå¹¶ä¸ºè‡ªåŠ¨é©¾é©¶æä¾›æ›´å¯é çš„åœºæ™¯ç†è§£ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Dynamic 3D reconstruction from monocular videos remains difficult due to the ambiguity inferring 3D motion from limited views and computational demands of modeling temporally varying scenes. While recent sparse control methods alleviate computation by reducing millions of Gaussians to thousands of control points, they suffer from a critical limitation: they allocate points purely by geometry, leading to static redundancy and dynamic insufficiency. We propose a motion-adaptive framework that aligns control density with motion complexity. Leveraging semantic and motion priors from vision foundation models, we establish patch-token-node correspondences and apply motion-adaptive compression to concentrate control points in dynamic regions while suppressing redundancy in static backgrounds. Our approach achieves flexible representational density adaptation through iterative voxelization and motion tendency scoring, directly addressing the fundamental mismatch between control point allocation and motion complexity. To capture temporal evolution, we introduce spline-based trajectory parameterization initialized by 2D tracklets, replacing MLP-based deformation fields to achieve smoother motion representation and more stable optimization. Extensive experiments demonstrate significant improvements in reconstruction quality and efficiency over existing state-of-the-art methods.

