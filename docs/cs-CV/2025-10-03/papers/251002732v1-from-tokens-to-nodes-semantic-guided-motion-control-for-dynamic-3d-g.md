---
layout: default
title: From Tokens to Nodes: Semantic-Guided Motion Control for Dynamic 3D Gaussian Splatting
---

# From Tokens to Nodes: Semantic-Guided Motion Control for Dynamic 3D Gaussian Splatting

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.02732" target="_blank" class="toolbar-btn">arXiv: 2510.02732v1</a>
    <a href="https://arxiv.org/pdf/2510.02732.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.02732v1" 
            onclick="toggleFavorite(this, '2510.02732v1', 'From Tokens to Nodes: Semantic-Guided Motion Control for Dynamic 3D Gaussian Splatting')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Jianing Chen, Zehao Li, Yujun Cai, Hao Jiang, Shuqin Gao, Honglong Zhao, Tianlu Mao, Yucheng Zhang

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-03

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫ËØ≠‰πâÂºïÂØºÁöÑÂä®ÊÄÅ3DÈ´òÊñØÊ∫ÖÂ∞ÑËøêÂä®ÊéßÂà∂ÊñπÊ≥ïÔºåËß£ÂÜ≥ÂçïÁõÆËßÜÈ¢ëÂä®ÊÄÅÈáçÂª∫‰∏≠ÁöÑÊéßÂà∂ÁÇπÂàÜÈÖçÈöæÈ¢ò„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Âä®ÊÄÅ3DÈáçÂª∫` `È´òÊñØÊ∫ÖÂ∞Ñ` `ËøêÂä®ÊéßÂà∂` `ËØ≠‰πâÂºïÂØº` `ËøêÂä®Ëá™ÈÄÇÂ∫î` `ÂçïÁõÆËßÜÈ¢ë` `ËßÜËßâÂü∫Á°ÄÊ®°Âûã`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂä®ÊÄÅ3DÈ´òÊñØÊ∫ÖÂ∞ÑÊñπÊ≥ïÂú®ÊéßÂà∂ÁÇπÂàÜÈÖç‰∏äÂ≠òÂú®‰∏çË∂≥Ôºå‰ªÖ‰æùËµñÂá†‰Ωï‰ø°ÊÅØÂØºËá¥ÈùôÊÄÅÂå∫ÂüüÂÜó‰ΩôÔºåÂä®ÊÄÅÂå∫Âüü‰∏çË∂≥„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫‰∏ÄÁßçËøêÂä®Ëá™ÈÄÇÂ∫îÊ°ÜÊû∂ÔºåÂà©Áî®ËØ≠‰πâÂíåËøêÂä®ÂÖàÈ™åÔºåÂÆûÁé∞ÊéßÂà∂ÁÇπÂØÜÂ∫¶‰∏éËøêÂä®Â§çÊùÇÂ∫¶ÁöÑÂØπÈΩê„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®ÈáçÂª∫Ë¥®ÈáèÂíåÊïàÁéá‰∏äÂùá‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÂÆûÁé∞‰∫ÜÊõ¥Âπ≥ÊªëÂíåÁ®≥ÂÆöÁöÑËøêÂä®Ë°®Á§∫„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçËøêÂä®Ëá™ÈÄÇÂ∫îÊ°ÜÊû∂ÔºåÁî®‰∫éËß£ÂÜ≥ÂçïÁõÆËßÜÈ¢ëÂä®ÊÄÅ3DÈáçÂª∫‰∏≠ÁöÑÊåëÊàò„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöËøáÂáèÂ∞ëÈ´òÊñØÂàÜÂ∏ÉÁöÑÊï∞ÈáèÊù•ÁºìËß£ËÆ°ÁÆóË¥üÊãÖÔºå‰ΩÜÂÖ∂ÊéßÂà∂ÁÇπÂàÜÈÖçÁ∫ØÁ≤πÂü∫‰∫éÂá†‰Ωï‰ø°ÊÅØÔºåÂØºËá¥ÈùôÊÄÅÂÜó‰ΩôÂíåÂä®ÊÄÅ‰∏çË∂≥„ÄÇÊú¨ÊñáÂà©Áî®ËßÜËßâÂü∫Á°ÄÊ®°ÂûãÁöÑËØ≠‰πâÂíåËøêÂä®ÂÖàÈ™åÔºåÂª∫Á´ãpatch-token-nodeÂØπÂ∫îÂÖ≥Á≥ªÔºåÂπ∂Â∫îÁî®ËøêÂä®Ëá™ÈÄÇÂ∫îÂéãÁº©ÔºåÂ∞ÜÊéßÂà∂ÁÇπÈõÜ‰∏≠Âú®Âä®ÊÄÅÂå∫ÂüüÔºåÂêåÊó∂ÊäëÂà∂ÈùôÊÄÅËÉåÊôØ‰∏≠ÁöÑÂÜó‰Ωô„ÄÇÈÄöËøáËø≠‰ª£‰ΩìÁ¥†ÂåñÂíåËøêÂä®Ë∂ãÂäøËØÑÂàÜÔºåÂÆûÁé∞ÁÅµÊ¥ªÁöÑË°®ÂæÅÂØÜÂ∫¶Ëá™ÈÄÇÂ∫îÔºåÁõ¥Êé•Ëß£ÂÜ≥ÊéßÂà∂ÁÇπÂàÜÈÖç‰∏éËøêÂä®Â§çÊùÇÂ∫¶‰∏çÂåπÈÖçÁöÑÈóÆÈ¢ò„ÄÇÊ≠§Â§ñÔºåÂºïÂÖ•Áî±2DËΩ®ËøπÂàùÂßãÂåñÁöÑÊ†∑Êù°Êõ≤Á∫øËΩ®ËøπÂèÇÊï∞ÂåñÔºåÊõø‰ª£Âü∫‰∫éMLPÁöÑÂèòÂΩ¢Âú∫Ôºå‰ª•ÂÆûÁé∞Êõ¥Âπ≥ÊªëÁöÑËøêÂä®Ë°®Á§∫ÂíåÊõ¥Á®≥ÂÆöÁöÑ‰ºòÂåñ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®ÈáçÂª∫Ë¥®ÈáèÂíåÊïàÁéáÊñπÈù¢Âùá‰ºò‰∫éÁé∞ÊúâÊäÄÊúØ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÂä®ÊÄÅ3DÈáçÂª∫Êó®Âú®‰ªéÂçïÁõÆËßÜÈ¢ë‰∏≠ÊÅ¢Â§çÂú∫ÊôØÁöÑÂä®ÊÄÅ3DÁªìÊûÑ„ÄÇÁé∞ÊúâÁöÑÂü∫‰∫é3DÈ´òÊñØÊ∫ÖÂ∞ÑÁöÑÊñπÊ≥ïËôΩÁÑ∂ÂèñÂæó‰∫ÜËøõÂ±ïÔºå‰ΩÜÂÖ∂ÊéßÂà∂ÁÇπÁöÑÂàÜÈÖç‰∏ªË¶Å‰æùËµñ‰∫éÂá†‰Ωï‰ø°ÊÅØÔºåÂØºËá¥Âú®ÈùôÊÄÅÂå∫ÂüüÂ≠òÂú®ÂÜó‰ΩôÁöÑÊéßÂà∂ÁÇπÔºåËÄåÂú®Âä®ÊÄÅÂå∫ÂüüÊéßÂà∂ÁÇπ‰∏çË∂≥ÔºåÊó†Ê≥ïÂÖÖÂàÜÊçïÊçâËøêÂä®ÁªÜËäÇ„ÄÇËøôÈôêÂà∂‰∫ÜÈáçÂª∫Ë¥®ÈáèÂíåÊïàÁéá„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÊ†πÊçÆÂú∫ÊôØ‰∏≠Áâ©‰ΩìÁöÑËøêÂä®Â§çÊùÇÁ®ãÂ∫¶Ëá™ÈÄÇÂ∫îÂú∞ÂàÜÈÖçÊéßÂà∂ÁÇπ„ÄÇÈÄöËøáÂºïÂÖ•ËØ≠‰πâÂíåËøêÂä®ÂÖàÈ™åÔºåÂ∞ÜÊéßÂà∂ÁÇπÈõÜ‰∏≠Âú®Âä®ÊÄÅÂå∫ÂüüÔºåÂêåÊó∂ÂáèÂ∞ëÈùôÊÄÅÂå∫ÂüüÁöÑÂÜó‰Ωô„ÄÇËøôÁßçÊñπÊ≥ïÊó®Âú®Ëß£ÂÜ≥ÊéßÂà∂ÁÇπÂàÜÈÖç‰∏éËøêÂä®Â§çÊùÇÂ∫¶‰∏çÂåπÈÖçÁöÑÈóÆÈ¢òÔºå‰ªéËÄåÊèêÈ´òÈáçÂª∫Ë¥®ÈáèÂíåÊïàÁéá„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•ÊñπÊ≥ï‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Èò∂ÊÆµÔºö1) Âà©Áî®ËßÜËßâÂü∫Á°ÄÊ®°ÂûãÊèêÂèñËØ≠‰πâÂíåËøêÂä®‰ø°ÊÅØÔºõ2) Âª∫Á´ãpatch-token-nodeÁöÑÂØπÂ∫îÂÖ≥Á≥ªÔºåÂ∞ÜÂõæÂÉèpatch„ÄÅËßÜËßâtokenÂíå3DÊéßÂà∂ÁÇπÂÖ≥ËÅîËµ∑Êù•Ôºõ3) Â∫îÁî®ËøêÂä®Ëá™ÈÄÇÂ∫îÂéãÁº©ÔºåÊ†πÊçÆËøêÂä®Ë∂ãÂäøËØÑÂàÜË∞ÉÊï¥ÊéßÂà∂ÁÇπÂØÜÂ∫¶Ôºõ4) ‰ΩøÁî®Ê†∑Êù°Êõ≤Á∫øÂèÇÊï∞ÂåñËΩ®ËøπÔºåÊõø‰ª£MLPÂèòÂΩ¢Âú∫ÔºåÂÆûÁé∞Êõ¥Âπ≥ÊªëÁöÑËøêÂä®Ë°®Á§∫„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ÊñπÊ≥ïÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éËøêÂä®Ëá™ÈÄÇÂ∫îÁöÑÊéßÂà∂ÁÇπÂàÜÈÖçÁ≠ñÁï•„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ï‰∏çÂêåÔºåËØ•ÊñπÊ≥ï‰∏çÂÜç‰ªÖ‰ªÖ‰æùËµñÂá†‰Ωï‰ø°ÊÅØÔºåËÄåÊòØÁªìÂêà‰∫ÜËØ≠‰πâÂíåËøêÂä®ÂÖàÈ™åÔºåÂÆûÁé∞‰∫ÜÊéßÂà∂ÁÇπÂØÜÂ∫¶‰∏éËøêÂä®Â§çÊùÇÂ∫¶ÁöÑÂØπÈΩê„ÄÇÊ≠§Â§ñÔºå‰ΩøÁî®Ê†∑Êù°Êõ≤Á∫øÂèÇÊï∞ÂåñËΩ®Ëøπ‰πüÊèêÈ´ò‰∫ÜËøêÂä®Ë°®Á§∫ÁöÑÂπ≥ÊªëÊÄßÂíå‰ºòÂåñÁ®≥ÂÆöÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËØ•ÊñπÊ≥ï‰ΩøÁî®Ëø≠‰ª£‰ΩìÁ¥†ÂåñÂíåËøêÂä®Ë∂ãÂäøËØÑÂàÜÊù•Ë∞ÉÊï¥ÊéßÂà∂ÁÇπÂØÜÂ∫¶„ÄÇËøêÂä®Ë∂ãÂäøËØÑÂàÜÂü∫‰∫éËßÜËßâÂü∫Á°ÄÊ®°ÂûãÊèêÂèñÁöÑËøêÂä®‰ø°ÊÅØÔºåÁî®‰∫éË°°ÈáèÊØè‰∏™Âå∫ÂüüÁöÑËøêÂä®Â§çÊùÇÂ∫¶„ÄÇÊ†∑Êù°Êõ≤Á∫øÁöÑÊéßÂà∂ÁÇπÁî±2DËΩ®ËøπÂàùÂßãÂåñÔºåÂπ∂ÈÄöËøá‰ºòÂåñÊçüÂ§±ÂáΩÊï∞Êù•ÊãüÂêà3DËøêÂä®ËΩ®Ëøπ„ÄÇÂÖ∑‰ΩìÁöÑÊçüÂ§±ÂáΩÊï∞ËÆæËÆ°ÂíåÂèÇÊï∞ËÆæÁΩÆÂú®ËÆ∫Êñá‰∏≠ÊúâËØ¶ÁªÜÊèèËø∞Ôºå‰ΩÜÂÖ∑‰ΩìÊï∞ÂÄºÊú™Áü•„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ËÆ∫ÊñáÈÄöËøáÂÆûÈ™åÈ™åËØÅ‰∫ÜÊâÄÊèêÂá∫ÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®ÈáçÂª∫Ë¥®ÈáèÂíåÊïàÁéáÊñπÈù¢Âùá‰ºò‰∫éÁé∞ÊúâÊäÄÊúØ„ÄÇÂÖ∑‰ΩìÁöÑÊÄßËÉΩÊï∞ÊçÆÂíåÊèêÂçáÂπÖÂ∫¶Âú®ËÆ∫Êñá‰∏≠ÁªôÂá∫Ôºå‰ΩÜÂÖ∑‰ΩìÊï∞ÂÄºÊú™Áü•„ÄÇËØ•ÊñπÊ≥ïËÉΩÂ§üÊõ¥ÂáÜÁ°ÆÂú∞ÊçïÊçâÂä®ÊÄÅÂú∫ÊôØ‰∏≠ÁöÑËøêÂä®ÁªÜËäÇÔºåÂπ∂ÂáèÂ∞ëÈùôÊÄÅÂå∫ÂüüÁöÑÂÜó‰ΩôËÆ°ÁÆó„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éËôöÊãüÁé∞ÂÆû„ÄÅÂ¢ûÂº∫Áé∞ÂÆû„ÄÅÊú∫Âô®‰∫∫ÂØºËà™„ÄÅËá™Âä®È©æÈ©∂Á≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÊõ¥ÂáÜÁ°ÆÂíåÈ´òÊïàÂú∞ÈáçÂª∫Âä®ÊÄÅ3DÂú∫ÊôØÔºåÂèØ‰ª•ÊèêÂçáÁî®Êà∑‰ΩìÈ™åÔºåÂ¢ûÂº∫Êú∫Âô®‰∫∫ÁöÑÁéØÂ¢ÉÊÑüÁü•ËÉΩÂäõÔºåÂπ∂‰∏∫Ëá™Âä®È©æÈ©∂Êèê‰æõÊõ¥ÂèØÈù†ÁöÑÂú∫ÊôØÁêÜËß£„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Dynamic 3D reconstruction from monocular videos remains difficult due to the ambiguity inferring 3D motion from limited views and computational demands of modeling temporally varying scenes. While recent sparse control methods alleviate computation by reducing millions of Gaussians to thousands of control points, they suffer from a critical limitation: they allocate points purely by geometry, leading to static redundancy and dynamic insufficiency. We propose a motion-adaptive framework that aligns control density with motion complexity. Leveraging semantic and motion priors from vision foundation models, we establish patch-token-node correspondences and apply motion-adaptive compression to concentrate control points in dynamic regions while suppressing redundancy in static backgrounds. Our approach achieves flexible representational density adaptation through iterative voxelization and motion tendency scoring, directly addressing the fundamental mismatch between control point allocation and motion complexity. To capture temporal evolution, we introduce spline-based trajectory parameterization initialized by 2D tracklets, replacing MLP-based deformation fields to achieve smoother motion representation and more stable optimization. Extensive experiments demonstrate significant improvements in reconstruction quality and efficiency over existing state-of-the-art methods.

