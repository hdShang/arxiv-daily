---
layout: default
title: Training-Free Out-Of-Distribution Segmentation With Foundation Models
---

# Training-Free Out-Of-Distribution Segmentation With Foundation Models

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.02909" target="_blank" class="toolbar-btn">arXiv: 2510.02909v1</a>
    <a href="https://arxiv.org/pdf/2510.02909.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.02909v1" 
            onclick="toggleFavorite(this, '2510.02909v1', 'Training-Free Out-Of-Distribution Segmentation With Foundation Models')" title="æ”¶è—">
      â˜† æ”¶è—
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="å¤åˆ¶é“¾æ¥">
      ğŸ”— åˆ†äº«
    </button>
  </div>
</div>


**ä½œè€…**: Laith Nayal, Hadi Salloum, Ahmad Taha, Yaroslav Kholodov, Alexander Gasnikov

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-03

**å¤‡æ³¨**: 12 pages, 5 figures, 2 tables, ICOMP 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§å…è®­ç»ƒçš„å¼‚å¸¸åˆ†å‰²æ–¹æ³•ï¼Œåˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡ŒåŸŸå¤–æ£€æµ‹ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åŸŸå¤–æ£€æµ‹` `è¯­ä¹‰åˆ†å‰²` `é¢„è®­ç»ƒæ¨¡å‹` `å…è®­ç»ƒå­¦ä¹ ` `K-Meansèšç±»` `å¼‚å¸¸æ£€æµ‹` `è‡ªåŠ¨é©¾é©¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è¯­ä¹‰åˆ†å‰²æ–¹æ³•åœ¨æ£€æµ‹æœªçŸ¥ç‰©ä½“æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨å®‰å…¨æ”¸å…³çš„åº”ç”¨ä¸­ã€‚
2. è¯¥è®ºæ–‡æå‡ºä¸€ç§å…è®­ç»ƒçš„åŸŸå¤–åˆ†å‰²æ–¹æ³•ï¼Œåˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹çš„ç‰¹å¾å’ŒK-Meansèšç±»è¿›è¡Œå¼‚å¸¸æ£€æµ‹ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨RoadAnomalyå’ŒADE-OoDåŸºå‡†æµ‹è¯•ä¸Šä¼˜äºå…¶ä»–æœ‰ç›‘ç£å’Œæ— ç›‘ç£æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨è¯­ä¹‰åˆ†å‰²ä¸­æ£€æµ‹æœªçŸ¥å¯¹è±¡å¯¹äºè‡ªåŠ¨é©¾é©¶ç­‰å®‰å…¨å…³é”®åº”ç”¨è‡³å…³é‡è¦ã€‚å¤§å‹è§†è§‰åŸºç¡€æ¨¡å‹ï¼Œå¦‚DINOv2ã€InternImageå’ŒCLIPï¼Œé€šè¿‡æä¾›åœ¨å„ç§ä»»åŠ¡ä¸­æ³›åŒ–è‰¯å¥½çš„ä¸°å¯Œç‰¹å¾ï¼Œæ¨åŠ¨äº†è§†è§‰è¡¨å¾å­¦ä¹ çš„å‘å±•ã€‚è™½ç„¶å®ƒä»¬åœ¨é—­é›†è¯­ä¹‰ä»»åŠ¡ä¸­çš„ä¼˜åŠ¿å·²ç»ç¡®ç«‹ï¼Œä½†å®ƒä»¬åœ¨è¯­ä¹‰åˆ†å‰²ä¸­æ£€æµ‹åŸŸå¤–(OoD)åŒºåŸŸçš„èƒ½åŠ›ä»æœªè¢«å……åˆ†æ¢ç´¢ã€‚æœ¬æ–‡ç ”ç©¶äº†åœ¨åˆ†å‰²æ•°æ®é›†ä¸Šå¾®è°ƒçš„åŸºç¡€æ¨¡å‹æ˜¯å¦èƒ½å¤Ÿå›ºæœ‰åœ°åŒºåˆ†åŸŸå†…(ID)å’ŒOoDåŒºåŸŸï¼Œè€Œæ— éœ€ä»»ä½•å¼‚å¸¸å€¼ç›‘ç£ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•ã€å…è®­ç»ƒçš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨InternImageä¸»å¹²ç½‘ç»œçš„ç‰¹å¾ï¼Œå¹¶ç»“åˆK-Meansèšç±»å’ŒåŸå§‹è§£ç å™¨logitsä¸Šçš„ç½®ä¿¡åº¦é˜ˆå€¼æ¥è¯†åˆ«OoDèšç±»ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨ä½¿ç”¨InternImage-Læ—¶ï¼Œåœ¨RoadAnomalyåŸºå‡†æµ‹è¯•ä¸Šå®ç°äº†50.02çš„å¹³å‡ç²¾åº¦ï¼Œåœ¨ADE-OoDåŸºå‡†æµ‹è¯•ä¸Šå®ç°äº†48.77çš„å¹³å‡ç²¾åº¦ï¼Œè¶…è¿‡äº†å‡ ä¸ªæœ‰ç›‘ç£å’Œæ— ç›‘ç£çš„åŸºçº¿ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œé€šç”¨çš„OoDåˆ†å‰²æ–¹æ³•éœ€è¦æœ€å°çš„å‡è®¾æˆ–é¢å¤–æ•°æ®ï¼Œè¿™æ˜¯ä¸€ä¸ªå¾ˆæœ‰å¸Œæœ›çš„æ–¹å‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è¯­ä¹‰åˆ†å‰²ä¸­åŸŸå¤–(Out-of-Distribution, OoD)æ£€æµ‹é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦é¢å¤–çš„å¼‚å¸¸æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œæˆ–è€…ä¾èµ–äºç‰¹å®šçš„æ¨¡å‹ç»“æ„å’Œå‡è®¾ï¼Œæ³›åŒ–èƒ½åŠ›æœ‰é™ã€‚è¯¥è®ºæ–‡å…³æ³¨å¦‚ä½•åœ¨ä¸è¿›è¡Œé¢å¤–è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œåˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹çš„èƒ½åŠ›è¿›è¡ŒOoDæ£€æµ‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨é¢„è®­ç»ƒçš„è§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆå¦‚InternImageï¼‰æå–çš„ç‰¹å¾å…·æœ‰ä¸°å¯Œçš„è¯­ä¹‰ä¿¡æ¯ï¼Œèƒ½å¤ŸåŒºåˆ†åŸŸå†…å’ŒåŸŸå¤–åŒºåŸŸã€‚é€šè¿‡å¯¹è¿™äº›ç‰¹å¾è¿›è¡Œèšç±»ï¼Œå¹¶ç»“åˆç½®ä¿¡åº¦é˜ˆå€¼ï¼Œå¯ä»¥æœ‰æ•ˆåœ°è¯†åˆ«OoDåŒºåŸŸã€‚è¿™ç§æ–¹æ³•æ— éœ€é¢å¤–çš„è®­ç»ƒæ•°æ®ï¼Œé™ä½äº†éƒ¨ç½²æˆæœ¬ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1) ä½¿ç”¨é¢„è®­ç»ƒçš„InternImageæ¨¡å‹æå–å›¾åƒç‰¹å¾ï¼›2) åˆ©ç”¨è§£ç å™¨è¾“å‡ºçš„logitsè®¡ç®—ç½®ä¿¡åº¦ï¼›3) å¯¹æå–çš„ç‰¹å¾è¿›è¡ŒK-Meansèšç±»ï¼›4) ç»“åˆèšç±»ç»“æœå’Œç½®ä¿¡åº¦é˜ˆå€¼ï¼Œå°†åƒç´ åˆ’åˆ†ä¸ºåŸŸå†…æˆ–åŸŸå¤–ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€å¤§çš„åˆ›æ–°åœ¨äºå…¶å…è®­ç»ƒçš„ç‰¹æ€§ã€‚å®ƒå……åˆ†åˆ©ç”¨äº†é¢„è®­ç»ƒæ¨¡å‹å­¦ä¹ åˆ°çš„é€šç”¨è§†è§‰è¡¨å¾ï¼Œé¿å…äº†å¯¹ç‰¹å®šæ•°æ®é›†çš„è¿‡åº¦æ‹Ÿåˆï¼Œä»è€Œæé«˜äº†æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œç»“åˆK-Meansèšç±»å’Œç½®ä¿¡åº¦é˜ˆå€¼ï¼Œèƒ½å¤Ÿæ›´å‡†ç¡®åœ°è¯†åˆ«OoDåŒºåŸŸã€‚

**å…³é”®è®¾è®¡**ï¼šè¯¥æ–¹æ³•çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨InternImage-Lä½œä¸ºç‰¹å¾æå–å™¨ï¼Œå› ä¸ºå®ƒå…·æœ‰å¼ºå¤§çš„è¡¨å¾èƒ½åŠ›ï¼›2) ä½¿ç”¨K-Meansèšç±»ç®—æ³•å¯¹ç‰¹å¾è¿›è¡Œèšç±»ï¼Œå¹¶é€šè¿‡å®éªŒç¡®å®šæœ€ä½³çš„èšç±»æ•°é‡ï¼›3) é€šè¿‡å®éªŒç¡®å®šç½®ä¿¡åº¦é˜ˆå€¼ï¼Œä»¥åŒºåˆ†åŸŸå†…å’ŒåŸŸå¤–åŒºåŸŸã€‚å…·ä½“å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°æ²¡æœ‰æ¶‰åŠï¼Œå› ä¸ºè¯¥æ–¹æ³•æ˜¯å…è®­ç»ƒçš„ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥æ–¹æ³•åœ¨RoadAnomalyåŸºå‡†æµ‹è¯•ä¸Šå®ç°äº†50.02çš„å¹³å‡ç²¾åº¦ï¼Œåœ¨ADE-OoDåŸºå‡†æµ‹è¯•ä¸Šå®ç°äº†48.77çš„å¹³å‡ç²¾åº¦ï¼Œæ˜¾è‘—ä¼˜äºå…¶ä»–æœ‰ç›‘ç£å’Œæ— ç›‘ç£çš„åŸºçº¿æ–¹æ³•ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œåˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå…è®­ç»ƒçš„åŸŸå¤–åˆ†å‰²æ˜¯å¯è¡Œçš„ï¼Œå¹¶ä¸”å…·æœ‰å¾ˆé«˜çš„æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€åŒ»ç–—å›¾åƒåˆ†æç­‰é¢†åŸŸã€‚åœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼Œå¯ä»¥æ£€æµ‹é“è·¯ä¸Šçš„å¼‚å¸¸ç‰©ä½“ï¼Œæé«˜è¡Œè½¦å®‰å…¨æ€§ã€‚åœ¨æœºå™¨äººå¯¼èˆªä¸­ï¼Œå¯ä»¥è¯†åˆ«æœªçŸ¥ç¯å¢ƒï¼Œå¢å¼ºæœºå™¨äººçš„é€‚åº”æ€§ã€‚åœ¨åŒ»ç–—å›¾åƒåˆ†æä¸­ï¼Œå¯ä»¥è¾…åŠ©åŒ»ç”Ÿè¯Šæ–­ç—…ç¶ï¼Œæé«˜è¯Šæ–­å‡†ç¡®ç‡ã€‚è¯¥æ–¹æ³•æ— éœ€é¢å¤–è®­ç»ƒï¼Œæ˜“äºéƒ¨ç½²ï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Detecting unknown objects in semantic segmentation is crucial for safety-critical applications such as autonomous driving. Large vision foundation models, including DINOv2, InternImage, and CLIP, have advanced visual representation learning by providing rich features that generalize well across diverse tasks. While their strength in closed-set semantic tasks is established, their capability to detect out-of-distribution (OoD) regions in semantic segmentation remains underexplored. In this work, we investigate whether foundation models fine-tuned on segmentation datasets can inherently distinguish in-distribution (ID) from OoD regions without any outlier supervision. We propose a simple, training-free approach that utilizes features from the InternImage backbone and applies K-Means clustering alongside confidence thresholding on raw decoder logits to identify OoD clusters. Our method achieves 50.02 Average Precision on the RoadAnomaly benchmark and 48.77 on the benchmark of ADE-OoD with InternImage-L, surpassing several supervised and unsupervised baselines. These results suggest a promising direction for generic OoD segmentation methods that require minimal assumptions or additional data.

