---
layout: default
title: Test-Time Defense Against Adversarial Attacks via Stochastic Resonance of Latent Ensembles
---

# Test-Time Defense Against Adversarial Attacks via Stochastic Resonance of Latent Ensembles

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.03224" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.03224v1</a>
  <a href="https://arxiv.org/pdf/2510.03224.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.03224v1" onclick="toggleFavorite(this, '2510.03224v1', 'Test-Time Defense Against Adversarial Attacks via Stochastic Resonance of Latent Ensembles')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Dong Lao, Yuxiang Zhang, Haniyeh Ehsani Oskouie, Yangchao Wu, Alex Wong, Stefano Soatto

**åˆ†ç±»**: cs.CV, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-10-03

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºæ½œç©ºé—´é›†æˆçš„éšæœºå…±æŒ¯å¯¹æŠ—æ”»å‡»é˜²å¾¡æ–¹æ³•ï¼Œæ— éœ€è®­ç»ƒä¸”é€‚ç”¨å¤šç§ä»»åŠ¡ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `å¯¹æŠ—æ”»å‡»é˜²å¾¡` `éšæœºå…±æŒ¯` `æ½œç©ºé—´é›†æˆ` `æµ‹è¯•æ—¶é˜²å¾¡` `å›¾åƒåˆ†ç±»` `ç«‹ä½“åŒ¹é…` `å…‰æµä¼°è®¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¯¹æŠ—é˜²å¾¡æ–¹æ³•ä¾èµ–ç‰¹å¾è¿‡æ»¤æˆ–å¹³æ»‘ï¼Œæ˜“é€ æˆä¿¡æ¯æŸå¤±ï¼Œé²æ£’æ€§æå‡æœ‰é™ã€‚
2. åˆ©ç”¨éšæœºå…±æŒ¯åŸç†ï¼Œé€šè¿‡å¼•å…¥å¾®å°æ‰°åŠ¨å¹¶é›†æˆç‰¹å¾ï¼Œåœ¨ä¸æŸå¤±ä¿¡æ¯çš„å‰æä¸‹å¢å¼ºæ¨¡å‹é²æ£’æ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å›¾åƒåˆ†ç±»ã€ç«‹ä½“åŒ¹é…å’Œå…‰æµç­‰ä»»åŠ¡ä¸Šå‡å–å¾—äº†æ˜¾è‘—çš„é˜²å¾¡æ•ˆæœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§é’ˆå¯¹å¯¹æŠ—æ”»å‡»çš„æµ‹è¯•æ—¶é˜²å¾¡æœºåˆ¶ï¼Œè¯¥æœºåˆ¶é€šè¿‡ä¸å¯å¯Ÿè§‰çš„å›¾åƒæ‰°åŠ¨æ¥æ˜¾è‘—æ”¹å˜æ¨¡å‹çš„é¢„æµ‹ç»“æœã€‚ä¸ä¾èµ–ç‰¹å¾è¿‡æ»¤æˆ–å¹³æ»‘ï¼ˆå¯èƒ½å¯¼è‡´ä¿¡æ¯ä¸¢å¤±ï¼‰çš„ç°æœ‰æ–¹æ³•ä¸åŒï¼Œæˆ‘ä»¬æå‡ºé€šè¿‡åˆ©ç”¨éšæœºå…±æŒ¯æ¥â€œä»¥å™ªåˆ¶å™ªâ€ï¼Œä»è€Œåœ¨æœ€å°åŒ–ä¿¡æ¯æŸå¤±çš„åŒæ—¶å¢å¼ºé²æ£’æ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¯¹è¾“å…¥å›¾åƒå¼•å…¥å°çš„å¹³ç§»æ‰°åŠ¨ï¼Œå¯¹é½å˜æ¢åçš„ç‰¹å¾åµŒå…¥ï¼Œå¹¶åœ¨æ˜ å°„å›åŸå§‹å‚è€ƒå›¾åƒä¹‹å‰èšåˆå®ƒä»¬ã€‚è¿™å¯ä»¥ç”¨ä¸€ä¸ªé—­å¼å…¬å¼è¡¨ç¤ºï¼Œå¯ä»¥éƒ¨ç½²åœ¨å„ç§ç°æœ‰çš„ç½‘ç»œæ¶æ„ä¸Šï¼Œè€Œæ— éœ€å¼•å…¥é¢å¤–çš„ç½‘ç»œæ¨¡å—æˆ–é’ˆå¯¹ç‰¹å®šæ”»å‡»ç±»å‹è¿›è¡Œå¾®è°ƒã€‚è¯¥æ–¹æ³•å®Œå…¨æ— éœ€è®­ç»ƒï¼Œä¸æ¶æ„æ— å…³ï¼Œå¹¶ä¸”ä¸æ”»å‡»æ— å…³ã€‚ç»éªŒç»“æœè¡¨æ˜ï¼Œåœ¨å›¾åƒåˆ†ç±»æ–¹é¢å…·æœ‰æœ€å…ˆè¿›çš„é²æ£’æ€§ï¼Œå¹¶ä¸”é¦–æ¬¡ä¸ºå¯†é›†é¢„æµ‹ä»»åŠ¡ï¼ˆåŒ…æ‹¬ç«‹ä½“åŒ¹é…å’Œå…‰æµï¼‰å»ºç«‹äº†é€šç”¨çš„æµ‹è¯•æ—¶é˜²å¾¡ï¼Œçªå‡ºäº†è¯¥æ–¹æ³•çš„å¤šåŠŸèƒ½æ€§å’Œå®ç”¨æ€§ã€‚å…·ä½“è€Œè¨€ï¼Œç›¸å¯¹äºå¹²å‡€ï¼ˆæœªæ‰°åŠ¨ï¼‰çš„æ€§èƒ½ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å„ç§ç±»å‹çš„å¯¹æŠ—æ”»å‡»ä¸‹ï¼Œåœ¨å›¾åƒåˆ†ç±»ä¸Šæ¢å¤äº†é«˜è¾¾ 68.1% çš„å‡†ç¡®ç‡æŸå¤±ï¼Œåœ¨ç«‹ä½“åŒ¹é…ä¸Šæ¢å¤äº† 71.9% çš„å‡†ç¡®ç‡æŸå¤±ï¼Œåœ¨å…‰æµä¸Šæ¢å¤äº† 29.2% çš„å‡†ç¡®ç‡æŸå¤±ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå¯¹æŠ—æ”»å‡»é€šè¿‡å¯¹è¾“å…¥å›¾åƒæ·»åŠ å¾®å°æ‰°åŠ¨ï¼Œå¯¼è‡´æ·±åº¦å­¦ä¹ æ¨¡å‹äº§ç”Ÿé”™è¯¯çš„é¢„æµ‹ã€‚ç°æœ‰é˜²å¾¡æ–¹æ³•ï¼Œå¦‚ç‰¹å¾è¿‡æ»¤æˆ–å¹³æ»‘ï¼Œè™½ç„¶èƒ½é™ä½æ¨¡å‹å¯¹æ‰°åŠ¨çš„æ•æ„Ÿæ€§ï¼Œä½†å¾€å¾€ä¼šæŸå¤±å›¾åƒä¸­çš„å…³é”®ä¿¡æ¯ï¼Œå½±å“æ¨¡å‹åœ¨å¹²å‡€æ•°æ®ä¸Šçš„æ€§èƒ½ã€‚å› æ­¤ï¼Œå¦‚ä½•åœ¨é˜²å¾¡å¯¹æŠ—æ”»å‡»çš„åŒæ—¶ï¼Œä¿æŒæ¨¡å‹å¯¹åŸå§‹ä¿¡æ¯çš„æ•æ„Ÿæ€§æ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨éšæœºå…±æŒ¯çš„åŸç†ï¼Œå³é€‚é‡çš„å™ªå£°åè€Œå¯ä»¥å¢å¼ºä¿¡å·çš„å¼ºåº¦ã€‚é€šè¿‡å¯¹è¾“å…¥å›¾åƒå¼•å…¥ä¸€ç³»åˆ—å¾®å°çš„å¹³ç§»æ‰°åŠ¨ï¼Œå¹¶å°†è¿™äº›æ‰°åŠ¨åçš„ç‰¹å¾è¿›è¡Œé›†æˆï¼Œå¯ä»¥æœ‰æ•ˆåœ°æŠµå¾¡å¯¹æŠ—æ”»å‡»ï¼ŒåŒæ—¶ä¿ç•™åŸå§‹å›¾åƒçš„ä¿¡æ¯ã€‚è¿™ç§â€œä»¥å™ªåˆ¶å™ªâ€çš„æ–¹æ³•é¿å…äº†ä¼ ç»Ÿæ–¹æ³•ä¸­ä¿¡æ¯æŸå¤±çš„é—®é¢˜ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•çš„æ•´ä½“æµç¨‹å¦‚ä¸‹ï¼š1) å¯¹è¾“å…¥å›¾åƒè¿›è¡Œå¤šæ¬¡å¾®å°çš„å¹³ç§»æ‰°åŠ¨ï¼›2) å°†æ‰°åŠ¨åçš„å›¾åƒè¾“å…¥åˆ°é¢„è®­ç»ƒçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸­ï¼Œæå–ç‰¹å¾åµŒå…¥ï¼›3) å¯¹é½è¿™äº›ç‰¹å¾åµŒå…¥ï¼Œæ¶ˆé™¤æ‰°åŠ¨å¸¦æ¥çš„å½±å“ï¼›4) å°†å¯¹é½åçš„ç‰¹å¾åµŒå…¥è¿›è¡Œèšåˆï¼Œå¾—åˆ°æœ€ç»ˆçš„ç‰¹å¾è¡¨ç¤ºï¼›5) å°†æœ€ç»ˆçš„ç‰¹å¾è¡¨ç¤ºæ˜ å°„å›åŸå§‹å›¾åƒç©ºé—´ï¼Œè¿›è¡Œé¢„æµ‹ã€‚æ•´ä¸ªè¿‡ç¨‹æ— éœ€é¢å¤–çš„ç½‘ç»œæ¨¡å—æˆ–è®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºåˆ©ç”¨éšæœºå…±æŒ¯çš„åŸç†ï¼Œé€šè¿‡å¼•å…¥å¾®å°æ‰°åŠ¨å¹¶é›†æˆç‰¹å¾ï¼Œåœ¨ä¸æŸå¤±ä¿¡æ¯çš„å‰æä¸‹å¢å¼ºæ¨¡å‹é²æ£’æ€§ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•æ— éœ€è®­ç»ƒï¼Œä¸æ¨¡å‹æ¶æ„æ— å…³ï¼Œä¸”å¯¹ä¸åŒç±»å‹çš„å¯¹æŠ—æ”»å‡»å…·æœ‰é€šç”¨æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•é¦–æ¬¡å°†éšæœºå…±æŒ¯åº”ç”¨äºå¯†é›†é¢„æµ‹ä»»åŠ¡çš„å¯¹æŠ—é˜²å¾¡ã€‚

**å…³é”®è®¾è®¡**ï¼šè¯¥æ–¹æ³•çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) å¹³ç§»æ‰°åŠ¨çš„å¹…åº¦ï¼šéœ€è¦é€‰æ‹©åˆé€‚çš„æ‰°åŠ¨å¹…åº¦ï¼Œæ—¢èƒ½æœ‰æ•ˆåœ°æŠµå¾¡å¯¹æŠ—æ”»å‡»ï¼Œåˆä¸ä¼šå¯¹åŸå§‹å›¾åƒçš„ä¿¡æ¯é€ æˆè¿‡å¤§çš„å½±å“ï¼›2) ç‰¹å¾å¯¹é½æ–¹æ³•ï¼šéœ€è¦è®¾è®¡ä¸€ç§æœ‰æ•ˆçš„ç‰¹å¾å¯¹é½æ–¹æ³•ï¼Œæ¶ˆé™¤å¹³ç§»æ‰°åŠ¨å¸¦æ¥çš„å½±å“ï¼Œä¿è¯ç‰¹å¾çš„ä¸€è‡´æ€§ï¼›3) ç‰¹å¾èšåˆæ–¹æ³•ï¼šéœ€è¦é€‰æ‹©åˆé€‚çš„ç‰¹å¾èšåˆæ–¹æ³•ï¼Œå°†å¤šä¸ªæ‰°åŠ¨åçš„ç‰¹å¾è¿›è¡Œèåˆï¼Œå¾—åˆ°æœ€ç»ˆçš„ç‰¹å¾è¡¨ç¤ºã€‚è®ºæ–‡ä¸­é‡‡ç”¨äº†ä¸€ç§é—­å¼è§£çš„ç‰¹å¾èšåˆæ–¹æ³•ï¼Œè®¡ç®—æ•ˆç‡é«˜ï¼Œæ˜“äºå®ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥æ–¹æ³•åœ¨å›¾åƒåˆ†ç±»ã€ç«‹ä½“åŒ¹é…å’Œå…‰æµç­‰ä»»åŠ¡ä¸Šå‡å–å¾—äº†æ˜¾è‘—çš„é˜²å¾¡æ•ˆæœã€‚åœ¨å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸­ï¼Œç›¸å¯¹äºå¹²å‡€æ•°æ®ï¼Œè¯¥æ–¹æ³•åœ¨å„ç§å¯¹æŠ—æ”»å‡»ä¸‹æ¢å¤äº†é«˜è¾¾ 68.1% çš„å‡†ç¡®ç‡æŸå¤±ã€‚åœ¨ç«‹ä½“åŒ¹é…å’Œå…‰æµä»»åŠ¡ä¸­ï¼Œåˆ†åˆ«æ¢å¤äº† 71.9% å’Œ 29.2% çš„å‡†ç¡®ç‡æŸå¤±ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å…·æœ‰å¾ˆå¼ºçš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ï¼Œä¼˜äºç°æœ‰çš„å¯¹æŠ—é˜²å¾¡æ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºå„ç§éœ€è¦é«˜å®‰å…¨æ€§å’Œé²æ£’æ€§çš„å›¾åƒè¯†åˆ«å’Œç†è§£ç³»ç»Ÿï¼Œä¾‹å¦‚è‡ªåŠ¨é©¾é©¶ã€äººè„¸è¯†åˆ«ã€åŒ»ç–—å›¾åƒåˆ†æã€å®‰å…¨ç›‘æ§ç­‰é¢†åŸŸã€‚è¯¥æ–¹æ³•æ— éœ€è®­ç»ƒçš„ç‰¹æ€§ä½¿å…¶èƒ½å¤Ÿå¿«é€Ÿéƒ¨ç½²åˆ°ç°æœ‰ç³»ç»Ÿä¸­ï¼Œå…·æœ‰å¾ˆé«˜çš„å®é™…åº”ç”¨ä»·å€¼ã€‚æœªæ¥ï¼Œå¯ä»¥è¿›ä¸€æ­¥ç ”ç©¶å¦‚ä½•è‡ªé€‚åº”åœ°è°ƒæ•´æ‰°åŠ¨å¹…åº¦ï¼Œä»¥è·å¾—æ›´å¥½çš„é˜²å¾¡æ•ˆæœã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We propose a test-time defense mechanism against adversarial attacks: imperceptible image perturbations that significantly alter the predictions of a model. Unlike existing methods that rely on feature filtering or smoothing, which can lead to information loss, we propose to "combat noise with noise" by leveraging stochastic resonance to enhance robustness while minimizing information loss. Our approach introduces small translational perturbations to the input image, aligns the transformed feature embeddings, and aggregates them before mapping back to the original reference image. This can be expressed in a closed-form formula, which can be deployed on diverse existing network architectures without introducing additional network modules or fine-tuning for specific attack types. The resulting method is entirely training-free, architecture-agnostic, and attack-agnostic. Empirical results show state-of-the-art robustness on image classification and, for the first time, establish a generic test-time defense for dense prediction tasks, including stereo matching and optical flow, highlighting the method's versatility and practicality. Specifically, relative to clean (unperturbed) performance, our method recovers up to 68.1% of the accuracy loss on image classification, 71.9% on stereo matching, and 29.2% on optical flow under various types of adversarial attacks.

