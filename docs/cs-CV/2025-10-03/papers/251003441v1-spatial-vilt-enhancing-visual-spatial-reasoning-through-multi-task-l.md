---
layout: default
title: "Spatial-ViLT: Enhancing Visual Spatial Reasoning through Multi-Task Learning"
---

# Spatial-ViLT: Enhancing Visual Spatial Reasoning through Multi-Task Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.03441" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.03441v1</a>
  <a href="https://arxiv.org/pdf/2510.03441.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.03441v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.03441v1', 'Spatial-ViLT: Enhancing Visual Spatial Reasoning through Multi-Task Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chashi Mahiul Islam, Oteo Mamo, Samuel Jacob Chacko, Xiuwen Liu, Weikuan Yu

**åˆ†ç±»**: cs.CV, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-10-03

**å¤‡æ³¨**: 12 pages, 5 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Spatial-ViLTé€šè¿‡å¤šä»»åŠ¡å­¦ä¹ å¢å¼ºè§†è§‰ç©ºé—´æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€æ¨¡å‹` `ç©ºé—´æ¨ç†` `å¤šä»»åŠ¡å­¦ä¹ ` `æ·±åº¦å›¾` `3Dåæ ‡` `è¾¹ç¼˜å›¾` `å¤šæ¨¡æ€èåˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨ç©ºé—´æ¨ç†æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†3Dåœºæ™¯å’Œå¤æ‚ç‰©ä½“å…³ç³»æ—¶ã€‚
2. SpatialViLTé€šè¿‡å¤šä»»åŠ¡å­¦ä¹ èåˆæ·±åº¦å›¾ã€3Dåæ ‡å’Œè¾¹ç¼˜å›¾ç­‰ç©ºé—´ç‰¹å¾ï¼Œå¢å¼ºæ¨¡å‹å¯¹ç©ºé—´ä¿¡æ¯çš„ç†è§£ã€‚
3. SpatialEnsembleç»“åˆSpatialViLTå’ŒMaskedSpatialViLTï¼Œåœ¨VSRæ•°æ®é›†ä¸Šå–å¾—äº†state-of-the-artçš„ç²¾åº¦ï¼Œæå‡äº†ç©ºé—´æ¨ç†èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€æ¨¡å‹(VLMs)åœ¨å¤šæ¨¡æ€æ¨ç†æ–¹é¢å–å¾—äº†è¿›å±•ï¼Œä½†åœ¨3Dåœºæ™¯å’Œå¤æ‚ç‰©ä½“é…ç½®çš„ç©ºé—´æ¨ç†æ–¹é¢ä»ç„¶é¢ä¸´æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†SpatialViLTï¼Œè¿™æ˜¯ä¸€ç§å¢å¼ºçš„VLMï¼Œå®ƒé€šè¿‡å¤šä»»åŠ¡å­¦ä¹ æ¡†æ¶é›†æˆäº†æ·±åº¦å›¾ã€3Dåæ ‡å’Œè¾¹ç¼˜å›¾ç­‰ç©ºé—´ç‰¹å¾ã€‚è¿™ç§æ–¹æ³•åˆ©ç”¨ç©ºé—´ç†è§£æ¥ä¸°å¯Œå¤šæ¨¡æ€åµŒå…¥ã€‚æˆ‘ä»¬æå‡ºäº†ä¸¤ç§å˜ä½“ï¼šSpatialViLTå’ŒMaskedSpatialViLTï¼Œåˆ†åˆ«ä¾§é‡äºå®Œæ•´å’Œæ©ç çš„å¯¹è±¡åŒºåŸŸã€‚æ­¤å¤–ï¼ŒSpatialEnsembleç»“åˆäº†è¿™ä¸¤ç§æ–¹æ³•ï¼Œå®ç°äº†æœ€å…ˆè¿›çš„ç²¾åº¦ã€‚æˆ‘ä»¬çš„æ¨¡å‹åœ¨æ–¹å‘ã€æ‹“æ‰‘å’Œé‚»è¿‘å…³ç³»ç­‰ç©ºé—´æ¨ç†ç±»åˆ«ä¸­è¡¨ç°å‡ºè‰²ï¼Œè¿™å·²åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„è§†è§‰ç©ºé—´æ¨ç†(VSR)æ•°æ®é›†ä¸Šå¾—åˆ°è¯æ˜ã€‚è¿™é¡¹å·¥ä½œä»£è¡¨äº†åœ¨å¢å¼ºAIç³»ç»Ÿçš„ç©ºé—´æ™ºèƒ½æ–¹é¢çš„é‡è¦ä¸€æ­¥ï¼Œè¿™å¯¹äºé«˜çº§å¤šæ¨¡æ€ç†è§£å’Œå®é™…åº”ç”¨è‡³å…³é‡è¦ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨ç†è§£å›¾åƒæˆ–åœºæ™¯ä¸­çš„ç©ºé—´å…³ç³»æ–¹é¢å­˜åœ¨å±€é™æ€§ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†å¤æ‚çš„3Dåœºæ™¯å’Œç‰©ä½“é…ç½®æ—¶ã€‚å®ƒä»¬éš¾ä»¥å‡†ç¡®æ¨æ–­ç‰©ä½“ä¹‹é—´çš„æ–¹å‘ã€æ‹“æ‰‘å’Œé‚»è¿‘å…³ç³»ã€‚è¿™äº›å±€é™æ€§é˜»ç¢äº†VLMåœ¨éœ€è¦ç²¾ç¡®ç©ºé—´ç†è§£çš„å®é™…åº”ç”¨ä¸­çš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSpatialViLTçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¤šä»»åŠ¡å­¦ä¹ çš„æ–¹å¼ï¼Œå°†ç©ºé—´ä¿¡æ¯ï¼ˆå¦‚æ·±åº¦å›¾ã€3Dåæ ‡å’Œè¾¹ç¼˜å›¾ï¼‰æ˜¾å¼åœ°èå…¥åˆ°è§†è§‰-è¯­è¨€æ¨¡å‹çš„ç‰¹å¾è¡¨ç¤ºä¸­ã€‚é€šè¿‡è®©æ¨¡å‹åŒæ—¶å­¦ä¹ è§†è§‰ç‰¹å¾å’Œç©ºé—´ç‰¹å¾ï¼Œå¯ä»¥æ˜¾è‘—æå‡å…¶ç©ºé—´æ¨ç†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSpatialViLTçš„æ•´ä½“æ¡†æ¶åŸºäºViLTæ¨¡å‹ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œäº†æ‰©å±•ã€‚å®ƒåŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) è§†è§‰ç‰¹å¾æå–æ¨¡å—ï¼šç”¨äºæå–å›¾åƒçš„è§†è§‰ç‰¹å¾ã€‚2) ç©ºé—´ç‰¹å¾æå–æ¨¡å—ï¼šç”¨äºæå–æ·±åº¦å›¾ã€3Dåæ ‡å’Œè¾¹ç¼˜å›¾ç­‰ç©ºé—´ç‰¹å¾ã€‚3) å¤šæ¨¡æ€èåˆæ¨¡å—ï¼šå°†è§†è§‰ç‰¹å¾å’Œç©ºé—´ç‰¹å¾è¿›è¡Œèåˆï¼Œå¾—åˆ°èåˆåçš„å¤šæ¨¡æ€ç‰¹å¾è¡¨ç¤ºã€‚4) ä»»åŠ¡é¢„æµ‹æ¨¡å—ï¼šåŸºäºèåˆåçš„ç‰¹å¾è¡¨ç¤ºï¼Œè¿›è¡Œå„ç§ç©ºé—´æ¨ç†ä»»åŠ¡çš„é¢„æµ‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šSpatialViLTçš„å…³é”®åˆ›æ–°åœ¨äºå…¶å¤šä»»åŠ¡å­¦ä¹ æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆåœ°å°†ç©ºé—´ä¿¡æ¯èå…¥åˆ°è§†è§‰-è¯­è¨€æ¨¡å‹ä¸­ã€‚ä¸ä¼ ç»Ÿçš„VLMç›¸æ¯”ï¼ŒSpatialViLTèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å›¾åƒæˆ–åœºæ™¯ä¸­çš„ç©ºé—´å…³ç³»ï¼Œä»è€Œæå‡ç©ºé—´æ¨ç†èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒSpatialEnsembleé€šè¿‡ç»“åˆSpatialViLTå’ŒMaskedSpatialViLTï¼Œè¿›ä¸€æ­¥æå‡äº†æ¨¡å‹çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šSpatialViLTé‡‡ç”¨äº†å¤šä»»åŠ¡å­¦ä¹ çš„æ–¹å¼ï¼ŒåŒæ—¶è®­ç»ƒæ¨¡å‹è¿›è¡Œå¤šä¸ªç©ºé—´æ¨ç†ä»»åŠ¡çš„é¢„æµ‹ã€‚æŸå¤±å‡½æ•°æ˜¯å„ä¸ªä»»åŠ¡æŸå¤±çš„åŠ æƒå’Œã€‚SpatialViLTå’ŒMaskedSpatialViLTçš„åŒºåˆ«åœ¨äºï¼ŒMaskedSpatialViLTåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šéšæœºmaskæ‰ä¸€éƒ¨åˆ†å¯¹è±¡åŒºåŸŸï¼Œè¿«ä½¿æ¨¡å‹å­¦ä¹ æ›´é²æ£’çš„ç‰¹å¾è¡¨ç¤ºã€‚SpatialEnsembleåˆ™æ˜¯å°†SpatialViLTå’ŒMaskedSpatialViLTçš„é¢„æµ‹ç»“æœè¿›è¡Œèåˆï¼Œä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

SpatialViLTåŠå…¶å˜ä½“åœ¨Visual Spatial Reasoning (VSR) æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå¹¶åœ¨æ–¹å‘ã€æ‹“æ‰‘å’Œé‚»è¿‘å…³ç³»ç­‰ç©ºé—´æ¨ç†ç±»åˆ«ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚SpatialEnsemble æ¨¡å‹å®ç°äº† state-of-the-art çš„ç²¾åº¦ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•åœ¨å¢å¼ºè§†è§‰ç©ºé—´æ¨ç†æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚å…·ä½“æ€§èƒ½æ•°æ®æœªçŸ¥ï¼Œä½†æ‘˜è¦å¼ºè°ƒäº†å…¶ä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Spatial-ViLTåœ¨æœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ã€è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥å¸®åŠ©æœºå™¨äººæ›´å¥½åœ°ç†è§£å‘¨å›´ç¯å¢ƒï¼Œä»è€Œå®ç°æ›´æ™ºèƒ½çš„å¯¼èˆªå’Œäº¤äº’ã€‚åœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸï¼Œå®ƒå¯ä»¥æé«˜è½¦è¾†å¯¹å¤æ‚äº¤é€šåœºæ™¯çš„ç†è§£èƒ½åŠ›ï¼Œä»è€Œæå‡é©¾é©¶å®‰å…¨æ€§ã€‚åœ¨VR/ARé¢†åŸŸï¼Œå®ƒå¯ä»¥å¢å¼ºç”¨æˆ·ä¸è™šæ‹Ÿç¯å¢ƒçš„äº¤äº’ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision-language models (VLMs) have advanced multimodal reasoning but still face challenges in spatial reasoning for 3D scenes and complex object configurations. To address this, we introduce SpatialViLT, an enhanced VLM that integrates spatial features like depth maps, 3D coordinates, and edge maps through a multi-task learning framework. This approach enriches multimodal embeddings with spatial understanding. We propose two variants: SpatialViLT and MaskedSpatialViLT, focusing on full and masked object regions, respectively. Additionally, SpatialEnsemble combines both approaches, achieving state-of-the-art accuracy. Our models excel in spatial reasoning categories such as directional, topological, and proximity relations, as demonstrated on the challenging Visual Spatial Reasoning (VSR) dataset. This work represents a significant step in enhancing the spatial intelligence of AI systems, crucial for advanced multimodal understanding and real-world applications.

