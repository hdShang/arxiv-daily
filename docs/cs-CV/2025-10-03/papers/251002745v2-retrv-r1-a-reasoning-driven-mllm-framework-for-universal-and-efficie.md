---
layout: default
title: Retrv-R1: A Reasoning-Driven MLLM Framework for Universal and Efficient Multimodal Retrieval
---

# Retrv-R1: A Reasoning-Driven MLLM Framework for Universal and Efficient Multimodal Retrieval

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.02745" target="_blank" class="toolbar-btn">arXiv: 2510.02745v2</a>
    <a href="https://arxiv.org/pdf/2510.02745.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.02745v2" 
            onclick="toggleFavorite(this, '2510.02745v2', 'Retrv-R1: A Reasoning-Driven MLLM Framework for Universal and Efficient Multimodal Retrieval')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Lanyun Zhu, Deyi Ji, Tianrun Chen, Haiyang Wu, Shiqi Wang

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-03 (Êõ¥Êñ∞: 2025-10-25)

**Â§áÊ≥®**: NeurIPS 2025

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Retrv-R1Ôºå‰∏ÄÁßçÂü∫‰∫éÊé®ÁêÜÈ©±Âä®ÁöÑÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊ°ÜÊû∂ÔºåÁî®‰∫éÈÄöÁî®‰∏îÈ´òÊïàÁöÑÂ§öÊ®°ÊÄÅÊ£ÄÁ¥¢„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅÊ£ÄÁ¥¢` `Â§ßËØ≠Ë®ÄÊ®°Âûã` `Âº∫ÂåñÂ≠¶‰π†` `‰ø°ÊÅØÂéãÁº©` `Êé®ÁêÜÈ©±Âä®` `ËØæÁ®ãÂ≠¶‰π†` `ËßÜËßâËØ≠Ë®ÄÊ®°Âûã`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®Â§öÊ®°ÊÄÅÊ£ÄÁ¥¢‰∏≠Èù¢‰∏¥ËÆ°ÁÆóÊàêÊú¨È´òÂíåÂº∫ÂåñÂ≠¶‰π†ËÆ≠ÁªÉ‰∏çÁ®≥ÂÆöÁ≠âÊåëÊàòÔºåÈôêÂà∂‰∫ÜÊÄßËÉΩÊèêÂçá„ÄÇ
2. Retrv-R1ÈÄöËøá‰ø°ÊÅØÂéãÁº©Ê®°ÂùóÂíåÁªÜËäÇÊ£ÄÊü•Êú∫Âà∂ÔºåÊúâÊïàÈôç‰ΩétokenÊ∂àËÄóÔºåÂπ∂ÁªìÂêàÊ£ÄÁ¥¢ÂÆöÂà∂ÁöÑCoTÊï∞ÊçÆÈõÜÂíåËØæÁ®ãÂ•ñÂä±Âº∫ÂåñÂ≠¶‰π†Ôºå‰ºòÂåñËÆ≠ÁªÉËøáÁ®ã„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåRetrv-R1Âú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠ËææÂà∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÂêåÊó∂‰øùÊåÅ‰∫ÜÈ´òÊïàÁéáÂíåËâØÂ•ΩÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨Êñá‰ªãÁªçRetrv-R1ÔºåËøôÊòØÈ¶ñ‰∏™R1È£éÊ†ºÁöÑÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºå‰∏ì‰∏∫Â§öÊ®°ÊÄÅÈÄöÁî®Ê£ÄÁ¥¢ËÄåËÆæËÆ°„ÄÇÂÆÉÈÄöËøáÈááÁî®ÈÄêÊ≠•Êé®ÁêÜÊù•‰∫ßÁîüÊõ¥ÂáÜÁ°ÆÁöÑÊ£ÄÁ¥¢ÁªìÊûúÔºå‰ªéËÄåÂÆûÁé∞Êõ¥È´òÁöÑÊÄßËÉΩ„ÄÇÁõ¥Êé•Â∞ÜDeepSeek-R1ÁöÑÊñπÊ≥ïÂ∫îÁî®‰∫éÊ£ÄÁ¥¢‰ªªÂä°ÊòØ‰∏çÂèØË°åÁöÑÔºå‰∏ªË¶ÅÂéüÂõ†ÊòØÔºöÔºà1ÔºâÊé®ÁêÜËøáÁ®ã‰∏≠Â§ö‰∏™ÂÄôÈÄâÂØπË±°ÈúÄË¶ÅÊ∂àËÄóÂ§ßÈáètokenÔºåÂØºËá¥ËÆ°ÁÆóÊàêÊú¨È´òÊòÇÔºõÔºà2ÔºâÁõ¥Êé•Â∫îÁî®Âº∫ÂåñÂ≠¶‰π†ÔºàRLÔºâËÆ≠ÁªÉÊ£ÄÁ¥¢‰ªªÂä°Êó∂ÔºåÁªìÊûú‰∏çÁ®≥ÂÆö‰∏îÊïàÊûúÊ¨†‰Ω≥„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåRetrv-R1ÂºïÂÖ•‰∫Ü‰∏Ä‰∏™Â∏¶ÊúâÁªÜËäÇÊ£ÄÊü•Êú∫Âà∂ÁöÑ‰ø°ÊÅØÂéãÁº©Ê®°ÂùóÔºåÈÄöËøáÂáèÂ∞ëtokenÊï∞ÈáèÊù•ÊèêÈ´òËÆ°ÁÆóÊïàÁéáÔºåÂêåÊó∂Á°Æ‰øù‰øùÁïôÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÂÄôÈÄâÂØπË±°ÁöÑÂÖ≥ÈîÆ‰ø°ÊÅØ„ÄÇÊ≠§Â§ñÔºåËøòÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑËÆ≠ÁªÉËåÉÂºèÔºåÂåÖÊã¨‰ΩøÁî®Ê£ÄÁ¥¢ÂÆöÂà∂ÁöÑÂêàÊàêCoTÊï∞ÊçÆÈõÜËøõË°åÊøÄÊ¥ªÈò∂ÊÆµÔºå‰ª•ÂÆûÁé∞Êõ¥ÊúâÊïàÁöÑ‰ºòÂåñÔºåÁÑ∂Âêé‰ΩøÁî®ÂÖ∑ÊúâÊñ∞È¢ñËØæÁ®ãÂ•ñÂä±ÁöÑÂº∫ÂåñÂ≠¶‰π†Êù•ÊèêÈ´òÊÄßËÉΩÂíåÊïàÁéá„ÄÇÂÆûÈ™åË°®ÊòéÔºåRetrv-R1Âú®Â§ö‰∏™Âü∫ÂáÜÂíå‰ªªÂä°‰∏≠ÂÆûÁé∞‰∫ÜSOTAÊÄßËÉΩ„ÄÅÈ´òÊïàÁéáÂíåÂº∫Â§ßÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Â§öÊ®°ÊÄÅÈÄöÁî®Ê£ÄÁ¥¢‰ªªÂä°‰∏≠ÔºåÁé∞ÊúâÊñπÊ≥ïËÆ°ÁÆóÊàêÊú¨È´òÊòÇÂíåÂº∫ÂåñÂ≠¶‰π†ËÆ≠ÁªÉ‰∏çÁ®≥ÂÆöÂØºËá¥ÊÄßËÉΩÂèóÈôêÁöÑÈóÆÈ¢ò„ÄÇÁõ¥Êé•Â∞ÜDeepSeek-R1Á≠âÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõÂ∫îÁî®‰∫éÊ£ÄÁ¥¢‰ªªÂä°Êó∂ÔºåÁî±‰∫éÈúÄË¶ÅÂ§ÑÁêÜÂ§ßÈáèÂÄôÈÄâÂØπË±°ÔºåtokenÊ∂àËÄóÂ∑®Â§ßÔºåËÆ°ÁÆóËµÑÊ∫êÈúÄÊ±ÇÈ´òÔºåÈöæ‰ª•ÂÆûÈôÖÂ∫îÁî®„ÄÇÊ≠§Â§ñÔºåÁõ¥Êé•‰ΩøÁî®Âº∫ÂåñÂ≠¶‰π†ËÆ≠ÁªÉÊ£ÄÁ¥¢‰ªªÂä°Êó∂ÔºåÂÆπÊòìÂá∫Áé∞ËÆ≠ÁªÉ‰∏çÁ®≥ÂÆöÂíåÁªìÊûúÊ¨†‰Ω≥ÁöÑÊÉÖÂÜµÔºåÈöæ‰ª•ËææÂà∞ÁêÜÊÉ≥ÁöÑÊ£ÄÁ¥¢ÊïàÊûú„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöRetrv-R1ÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÔºåÂú®‰øùËØÅÊ£ÄÁ¥¢ÊÄßËÉΩÁöÑÂâçÊèê‰∏ãÔºåÈÄöËøá‰ø°ÊÅØÂéãÁº©Âíå‰ºòÂåñÁöÑËÆ≠ÁªÉÁ≠ñÁï•Êù•Èôç‰ΩéËÆ°ÁÆóÊàêÊú¨Âπ∂ÊèêÈ´òËÆ≠ÁªÉÁ®≥ÂÆöÊÄß„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÈ¶ñÂÖàÈÄöËøá‰ø°ÊÅØÂéãÁº©Ê®°ÂùóÂáèÂ∞ëtokenÊï∞ÈáèÔºåÈôç‰ΩéËÆ°ÁÆóË¥üÊãÖÔºõÁÑ∂ÂêéÔºåËÆæËÆ°Ê£ÄÁ¥¢ÂÆöÂà∂ÁöÑCoTÊï∞ÊçÆÈõÜÂíåËØæÁ®ãÂ•ñÂä±Âº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÔºåÊèêÈ´òËÆ≠ÁªÉÊïàÁéáÂíåÊïàÊûú„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöRetrv-R1ÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) ‰ø°ÊÅØÂéãÁº©Ê®°ÂùóÔºöÁî®‰∫éÂáèÂ∞ëËæìÂÖ•tokenÁöÑÊï∞ÈáèÔºåÈôç‰ΩéËÆ°ÁÆóÊàêÊú¨„ÄÇËØ•Ê®°ÂùóÂåÖÂê´ÁªÜËäÇÊ£ÄÊü•Êú∫Âà∂ÔºåÁ°Æ‰øùÂÖ≥ÈîÆ‰ø°ÊÅØ‰∏ç‰∏¢Â§±„ÄÇ2) Ê£ÄÁ¥¢ÂÆöÂà∂ÁöÑCoTÊï∞ÊçÆÈõÜÔºöÁî®‰∫éÊøÄÊ¥ªÈò∂ÊÆµÁöÑËÆ≠ÁªÉÔºåÊèê‰æõÊõ¥ÊúâÊïàÁöÑ‰ºòÂåñÊñπÂêë„ÄÇ3) ËØæÁ®ãÂ•ñÂä±Âº∫ÂåñÂ≠¶‰π†ÔºöÁî®‰∫éËøõ‰∏ÄÊ≠•ÊèêÂçáÊÄßËÉΩÂíåÊïàÁéáÔºåÈÄöËøáÈÄêÊ≠•Â¢ûÂä†ËÆ≠ÁªÉÈöæÂ∫¶ÔºåÊèêÈ´òÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöRetrv-R1ÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫é‰ª•‰∏ãÂá†‰∏™ÊñπÈù¢Ôºö1) ÈíàÂØπÊ£ÄÁ¥¢‰ªªÂä°ËÆæËÆ°ÁöÑ‰ø°ÊÅØÂéãÁº©Ê®°ÂùóÔºåËÉΩÂ§üÂú®Èôç‰ΩéËÆ°ÁÆóÊàêÊú¨ÁöÑÂêåÊó∂Ôºå‰øùÁïôÂÖ≥ÈîÆ‰ø°ÊÅØ„ÄÇ2) ÊèêÂá∫‰∫ÜÊ£ÄÁ¥¢ÂÆöÂà∂ÁöÑCoTÊï∞ÊçÆÈõÜÔºåËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞ÂºïÂØºÊ®°ÂûãËøõË°å‰ºòÂåñ„ÄÇ3) ËÆæËÆ°‰∫ÜËØæÁ®ãÂ•ñÂä±Âº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÔºåËÉΩÂ§üÊèêÈ´òËÆ≠ÁªÉÁöÑÁ®≥ÂÆöÊÄßÂíåÊïàÁéá„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**Ôºö‰ø°ÊÅØÂéãÁº©Ê®°ÂùóÈááÁî®‰∫Ü‰∏ÄÁßçÁªÜËäÇÊ£ÄÊü•Êú∫Âà∂ÔºåÁî®‰∫éËØÜÂà´Âíå‰øùÁïôÈáçË¶ÅÁöÑ‰ø°ÊÅØ„ÄÇÊ£ÄÁ¥¢ÂÆöÂà∂ÁöÑCoTÊï∞ÊçÆÈõÜÂåÖÂê´ÈíàÂØπÊ£ÄÁ¥¢‰ªªÂä°ËÆæËÆ°ÁöÑÊé®ÁêÜÈìæÔºåËÉΩÂ§üÂ∏ÆÂä©Ê®°ÂûãÊõ¥Â•ΩÂú∞ÁêÜËß£Ê£ÄÁ¥¢ÊÑèÂõæ„ÄÇËØæÁ®ãÂ•ñÂä±Âº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÈÄöËøáÈÄêÊ≠•Â¢ûÂä†ËÆ≠ÁªÉÈöæÂ∫¶ÔºåÊèêÈ´òÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÂÖ∑‰ΩìÁöÑÂ•ñÂä±ÂáΩÊï∞ËÆæËÆ°ÂíåÁΩëÁªúÁªìÊûÑÁªÜËäÇÂú®ËÆ∫Êñá‰∏≠ÊúâËØ¶ÁªÜÊèèËø∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Retrv-R1Âú®Â§ö‰∏™Â§öÊ®°ÊÄÅÊ£ÄÁ¥¢Âü∫ÂáÜÊµãËØï‰∏≠ÂèñÂæó‰∫ÜSOTAÊÄßËÉΩÔºåËØÅÊòé‰∫ÜÂÖ∂ÊúâÊïàÊÄßÂíå‰ºòË∂äÊÄß„ÄÇÈÄöËøá‰ø°ÊÅØÂéãÁº©Ê®°ÂùóÂíå‰ºòÂåñÁöÑËÆ≠ÁªÉÁ≠ñÁï•ÔºåRetrv-R1Âú®‰øùËØÅÊ£ÄÁ¥¢ÊÄßËÉΩÁöÑÂêåÊó∂ÔºåÊòæËëóÈôç‰Ωé‰∫ÜËÆ°ÁÆóÊàêÊú¨ÔºåÊèêÈ´ò‰∫ÜËÆ≠ÁªÉÊïàÁéá„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåRetrv-R1ÂÖ∑ÊúâÂº∫Â§ßÁöÑÊ≥õÂåñËÉΩÂäõÔºåËÉΩÂ§üÈÄÇÂ∫î‰∏çÂêåÁöÑÊ£ÄÁ¥¢‰ªªÂä°ÂíåÊï∞ÊçÆÈõÜ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

Retrv-R1ÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂèØÂ∫îÁî®‰∫éÂõæÂÉè„ÄÅËßÜÈ¢ë„ÄÅÊñáÊú¨Á≠âÂ§öÁßçÊ®°ÊÄÅÊï∞ÊçÆÁöÑÊ£ÄÁ¥¢‰ªªÂä°„ÄÇ‰æãÂ¶ÇÔºåÂú®ÁîµÂïÜÈ¢ÜÂüüÔºåÂèØ‰ª•Áî®‰∫éÂïÜÂìÅÂõæÂÉèÁöÑÁõ∏‰ººÂ∫¶ÊêúÁ¥¢ÔºõÂú®ËßÜÈ¢ëÂπ≥Âè∞ÔºåÂèØ‰ª•Áî®‰∫éËßÜÈ¢ëÂÜÖÂÆπÁöÑÊ£ÄÁ¥¢ÂíåÊé®ËçêÔºõÂú®Áü•ËØÜÂ∫ìÈóÆÁ≠îÁ≥ªÁªü‰∏≠ÔºåÂèØ‰ª•Áî®‰∫éÊ£ÄÁ¥¢Áõ∏ÂÖ≥ÁöÑÁü•ËØÜÊù°ÁõÆ„ÄÇËØ•Á†îÁ©∂ÁöÑÊàêÊûúÊúâÂä©‰∫éÊèêÂçáÂ§öÊ®°ÊÄÅÊ£ÄÁ¥¢ÁöÑÊïàÁéáÂíåÂáÜÁ°ÆÊÄßÔºå‰∏∫Áî®Êà∑Êèê‰æõÊõ¥Â•ΩÁöÑÊ£ÄÁ¥¢‰ΩìÈ™å„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> The success of DeepSeek-R1 demonstrates the immense potential of using reinforcement learning (RL) to enhance LLMs' reasoning capabilities. This paper introduces Retrv-R1, the first R1-style MLLM specifically designed for multimodal universal retrieval, achieving higher performance by employing step-by-step reasoning to produce more accurate retrieval results. We find that directly applying the methods of DeepSeek-R1 to retrieval tasks is not feasible, mainly due to (1) the high computational cost caused by the large token consumption required for multiple candidates with reasoning processes, and (2) the instability and suboptimal results when directly applying RL to train for retrieval tasks. To address these issues, Retrv-R1 introduces an information compression module with a details inspection mechanism, which enhances computational efficiency by reducing the number of tokens while ensuring that critical information for challenging candidates is preserved. Furthermore, a new training paradigm is proposed, including an activation stage using a retrieval-tailored synthetic CoT dataset for more effective optimization, followed by RL with a novel curriculum reward to improve both performance and efficiency. Incorporating these novel designs, Retrv-R1 achieves SOTA performance, high efficiency, and strong generalization ability, as demonstrated by experiments across multiple benchmarks and tasks.

