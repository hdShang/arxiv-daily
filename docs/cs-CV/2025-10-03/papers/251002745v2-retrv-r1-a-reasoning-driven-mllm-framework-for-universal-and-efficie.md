---
layout: default
title: "Retrv-R1: A Reasoning-Driven MLLM Framework for Universal and Efficient Multimodal Retrieval"
---

# Retrv-R1: A Reasoning-Driven MLLM Framework for Universal and Efficient Multimodal Retrieval

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.02745" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.02745v2</a>
  <a href="https://arxiv.org/pdf/2510.02745.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.02745v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.02745v2', 'Retrv-R1: A Reasoning-Driven MLLM Framework for Universal and Efficient Multimodal Retrieval')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Lanyun Zhu, Deyi Ji, Tianrun Chen, Haiyang Wu, Shiqi Wang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-03 (æ›´æ–°: 2025-10-25)

**å¤‡æ³¨**: NeurIPS 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRetrv-R1ï¼Œä¸€ç§åŸºäºæ¨ç†é©±åŠ¨çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹æ¡†æ¶ï¼Œç”¨äºé€šç”¨ä¸”é«˜æ•ˆçš„å¤šæ¨¡æ€æ£€ç´¢ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ£€ç´¢` `å¤§è¯­è¨€æ¨¡å‹` `å¼ºåŒ–å­¦ä¹ ` `ä¿¡æ¯å‹ç¼©` `æ¨ç†é©±åŠ¨` `è¯¾ç¨‹å­¦ä¹ ` `è§†è§‰è¯­è¨€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤šæ¨¡æ€æ£€ç´¢ä¸­é¢ä¸´è®¡ç®—æˆæœ¬é«˜å’Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒä¸ç¨³å®šç­‰æŒ‘æˆ˜ï¼Œé™åˆ¶äº†æ€§èƒ½æå‡ã€‚
2. Retrv-R1é€šè¿‡ä¿¡æ¯å‹ç¼©æ¨¡å—å’Œç»†èŠ‚æ£€æŸ¥æœºåˆ¶ï¼Œæœ‰æ•ˆé™ä½tokenæ¶ˆè€—ï¼Œå¹¶ç»“åˆæ£€ç´¢å®šåˆ¶çš„CoTæ•°æ®é›†å’Œè¯¾ç¨‹å¥–åŠ±å¼ºåŒ–å­¦ä¹ ï¼Œä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒRetrv-R1åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶ä¿æŒäº†é«˜æ•ˆç‡å’Œè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ä»‹ç»Retrv-R1ï¼Œè¿™æ˜¯é¦–ä¸ªR1é£æ ¼çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼Œä¸“ä¸ºå¤šæ¨¡æ€é€šç”¨æ£€ç´¢è€Œè®¾è®¡ã€‚å®ƒé€šè¿‡é‡‡ç”¨é€æ­¥æ¨ç†æ¥äº§ç”Ÿæ›´å‡†ç¡®çš„æ£€ç´¢ç»“æœï¼Œä»è€Œå®ç°æ›´é«˜çš„æ€§èƒ½ã€‚ç›´æ¥å°†DeepSeek-R1çš„æ–¹æ³•åº”ç”¨äºæ£€ç´¢ä»»åŠ¡æ˜¯ä¸å¯è¡Œçš„ï¼Œä¸»è¦åŸå› æ˜¯ï¼šï¼ˆ1ï¼‰æ¨ç†è¿‡ç¨‹ä¸­å¤šä¸ªå€™é€‰å¯¹è±¡éœ€è¦æ¶ˆè€—å¤§é‡tokenï¼Œå¯¼è‡´è®¡ç®—æˆæœ¬é«˜æ˜‚ï¼›ï¼ˆ2ï¼‰ç›´æ¥åº”ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è®­ç»ƒæ£€ç´¢ä»»åŠ¡æ—¶ï¼Œç»“æœä¸ç¨³å®šä¸”æ•ˆæœæ¬ ä½³ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼ŒRetrv-R1å¼•å…¥äº†ä¸€ä¸ªå¸¦æœ‰ç»†èŠ‚æ£€æŸ¥æœºåˆ¶çš„ä¿¡æ¯å‹ç¼©æ¨¡å—ï¼Œé€šè¿‡å‡å°‘tokenæ•°é‡æ¥æé«˜è®¡ç®—æ•ˆç‡ï¼ŒåŒæ—¶ç¡®ä¿ä¿ç•™å…·æœ‰æŒ‘æˆ˜æ€§çš„å€™é€‰å¯¹è±¡çš„å…³é”®ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºäº†ä¸€ç§æ–°çš„è®­ç»ƒèŒƒå¼ï¼ŒåŒ…æ‹¬ä½¿ç”¨æ£€ç´¢å®šåˆ¶çš„åˆæˆCoTæ•°æ®é›†è¿›è¡Œæ¿€æ´»é˜¶æ®µï¼Œä»¥å®ç°æ›´æœ‰æ•ˆçš„ä¼˜åŒ–ï¼Œç„¶åä½¿ç”¨å…·æœ‰æ–°é¢–è¯¾ç¨‹å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ æ¥æé«˜æ€§èƒ½å’Œæ•ˆç‡ã€‚å®éªŒè¡¨æ˜ï¼ŒRetrv-R1åœ¨å¤šä¸ªåŸºå‡†å’Œä»»åŠ¡ä¸­å®ç°äº†SOTAæ€§èƒ½ã€é«˜æ•ˆç‡å’Œå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€é€šç”¨æ£€ç´¢ä»»åŠ¡ä¸­ï¼Œç°æœ‰æ–¹æ³•è®¡ç®—æˆæœ¬é«˜æ˜‚å’Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒä¸ç¨³å®šå¯¼è‡´æ€§èƒ½å—é™çš„é—®é¢˜ã€‚ç›´æ¥å°†DeepSeek-R1ç­‰å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›åº”ç”¨äºæ£€ç´¢ä»»åŠ¡æ—¶ï¼Œç”±äºéœ€è¦å¤„ç†å¤§é‡å€™é€‰å¯¹è±¡ï¼Œtokenæ¶ˆè€—å·¨å¤§ï¼Œè®¡ç®—èµ„æºéœ€æ±‚é«˜ï¼Œéš¾ä»¥å®é™…åº”ç”¨ã€‚æ­¤å¤–ï¼Œç›´æ¥ä½¿ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ£€ç´¢ä»»åŠ¡æ—¶ï¼Œå®¹æ˜“å‡ºç°è®­ç»ƒä¸ç¨³å®šå’Œç»“æœæ¬ ä½³çš„æƒ…å†µï¼Œéš¾ä»¥è¾¾åˆ°ç†æƒ³çš„æ£€ç´¢æ•ˆæœã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šRetrv-R1çš„æ ¸å¿ƒæ€è·¯æ˜¯ï¼Œåœ¨ä¿è¯æ£€ç´¢æ€§èƒ½çš„å‰æä¸‹ï¼Œé€šè¿‡ä¿¡æ¯å‹ç¼©å’Œä¼˜åŒ–çš„è®­ç»ƒç­–ç•¥æ¥é™ä½è®¡ç®—æˆæœ¬å¹¶æé«˜è®­ç»ƒç¨³å®šæ€§ã€‚å…·ä½“æ¥è¯´ï¼Œé¦–å…ˆé€šè¿‡ä¿¡æ¯å‹ç¼©æ¨¡å—å‡å°‘tokenæ•°é‡ï¼Œé™ä½è®¡ç®—è´Ÿæ‹…ï¼›ç„¶åï¼Œè®¾è®¡æ£€ç´¢å®šåˆ¶çš„CoTæ•°æ®é›†å’Œè¯¾ç¨‹å¥–åŠ±å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œæé«˜è®­ç»ƒæ•ˆç‡å’Œæ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRetrv-R1çš„æ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) ä¿¡æ¯å‹ç¼©æ¨¡å—ï¼šç”¨äºå‡å°‘è¾“å…¥tokençš„æ•°é‡ï¼Œé™ä½è®¡ç®—æˆæœ¬ã€‚è¯¥æ¨¡å—åŒ…å«ç»†èŠ‚æ£€æŸ¥æœºåˆ¶ï¼Œç¡®ä¿å…³é”®ä¿¡æ¯ä¸ä¸¢å¤±ã€‚2) æ£€ç´¢å®šåˆ¶çš„CoTæ•°æ®é›†ï¼šç”¨äºæ¿€æ´»é˜¶æ®µçš„è®­ç»ƒï¼Œæä¾›æ›´æœ‰æ•ˆçš„ä¼˜åŒ–æ–¹å‘ã€‚3) è¯¾ç¨‹å¥–åŠ±å¼ºåŒ–å­¦ä¹ ï¼šç”¨äºè¿›ä¸€æ­¥æå‡æ€§èƒ½å’Œæ•ˆç‡ï¼Œé€šè¿‡é€æ­¥å¢åŠ è®­ç»ƒéš¾åº¦ï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šRetrv-R1çš„å…³é”®åˆ›æ–°åœ¨äºä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š1) é’ˆå¯¹æ£€ç´¢ä»»åŠ¡è®¾è®¡çš„ä¿¡æ¯å‹ç¼©æ¨¡å—ï¼Œèƒ½å¤Ÿåœ¨é™ä½è®¡ç®—æˆæœ¬çš„åŒæ—¶ï¼Œä¿ç•™å…³é”®ä¿¡æ¯ã€‚2) æå‡ºäº†æ£€ç´¢å®šåˆ¶çš„CoTæ•°æ®é›†ï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å¼•å¯¼æ¨¡å‹è¿›è¡Œä¼˜åŒ–ã€‚3) è®¾è®¡äº†è¯¾ç¨‹å¥–åŠ±å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œèƒ½å¤Ÿæé«˜è®­ç»ƒçš„ç¨³å®šæ€§å’Œæ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šä¿¡æ¯å‹ç¼©æ¨¡å—é‡‡ç”¨äº†ä¸€ç§ç»†èŠ‚æ£€æŸ¥æœºåˆ¶ï¼Œç”¨äºè¯†åˆ«å’Œä¿ç•™é‡è¦çš„ä¿¡æ¯ã€‚æ£€ç´¢å®šåˆ¶çš„CoTæ•°æ®é›†åŒ…å«é’ˆå¯¹æ£€ç´¢ä»»åŠ¡è®¾è®¡çš„æ¨ç†é“¾ï¼Œèƒ½å¤Ÿå¸®åŠ©æ¨¡å‹æ›´å¥½åœ°ç†è§£æ£€ç´¢æ„å›¾ã€‚è¯¾ç¨‹å¥–åŠ±å¼ºåŒ–å­¦ä¹ æ–¹æ³•é€šè¿‡é€æ­¥å¢åŠ è®­ç»ƒéš¾åº¦ï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚å…·ä½“çš„å¥–åŠ±å‡½æ•°è®¾è®¡å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

Retrv-R1åœ¨å¤šä¸ªå¤šæ¨¡æ€æ£€ç´¢åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†SOTAæ€§èƒ½ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚é€šè¿‡ä¿¡æ¯å‹ç¼©æ¨¡å—å’Œä¼˜åŒ–çš„è®­ç»ƒç­–ç•¥ï¼ŒRetrv-R1åœ¨ä¿è¯æ£€ç´¢æ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—æˆæœ¬ï¼Œæé«˜äº†è®­ç»ƒæ•ˆç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRetrv-R1å…·æœ‰å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œèƒ½å¤Ÿé€‚åº”ä¸åŒçš„æ£€ç´¢ä»»åŠ¡å’Œæ•°æ®é›†ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Retrv-R1å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯åº”ç”¨äºå›¾åƒã€è§†é¢‘ã€æ–‡æœ¬ç­‰å¤šç§æ¨¡æ€æ•°æ®çš„æ£€ç´¢ä»»åŠ¡ã€‚ä¾‹å¦‚ï¼Œåœ¨ç”µå•†é¢†åŸŸï¼Œå¯ä»¥ç”¨äºå•†å“å›¾åƒçš„ç›¸ä¼¼åº¦æœç´¢ï¼›åœ¨è§†é¢‘å¹³å°ï¼Œå¯ä»¥ç”¨äºè§†é¢‘å†…å®¹çš„æ£€ç´¢å’Œæ¨èï¼›åœ¨çŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿä¸­ï¼Œå¯ä»¥ç”¨äºæ£€ç´¢ç›¸å…³çš„çŸ¥è¯†æ¡ç›®ã€‚è¯¥ç ”ç©¶çš„æˆæœæœ‰åŠ©äºæå‡å¤šæ¨¡æ€æ£€ç´¢çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ï¼Œä¸ºç”¨æˆ·æä¾›æ›´å¥½çš„æ£€ç´¢ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The success of DeepSeek-R1 demonstrates the immense potential of using reinforcement learning (RL) to enhance LLMs' reasoning capabilities. This paper introduces Retrv-R1, the first R1-style MLLM specifically designed for multimodal universal retrieval, achieving higher performance by employing step-by-step reasoning to produce more accurate retrieval results. We find that directly applying the methods of DeepSeek-R1 to retrieval tasks is not feasible, mainly due to (1) the high computational cost caused by the large token consumption required for multiple candidates with reasoning processes, and (2) the instability and suboptimal results when directly applying RL to train for retrieval tasks. To address these issues, Retrv-R1 introduces an information compression module with a details inspection mechanism, which enhances computational efficiency by reducing the number of tokens while ensuring that critical information for challenging candidates is preserved. Furthermore, a new training paradigm is proposed, including an activation stage using a retrieval-tailored synthetic CoT dataset for more effective optimization, followed by RL with a novel curriculum reward to improve both performance and efficiency. Incorporating these novel designs, Retrv-R1 achieves SOTA performance, high efficiency, and strong generalization ability, as demonstrated by experiments across multiple benchmarks and tasks.

