---
layout: default
title: LEAML: Label-Efficient Adaptation to Out-of-Distribution Visual Tasks for Multimodal Large Language Models
---

# LEAML: Label-Efficient Adaptation to Out-of-Distribution Visual Tasks for Multimodal Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.03232" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.03232v1</a>
  <a href="https://arxiv.org/pdf/2510.03232.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.03232v1" onclick="toggleFavorite(this, '2510.03232v1', 'LEAML: Label-Efficient Adaptation to Out-of-Distribution Visual Tasks for Multimodal Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ci-Siang Lin, Min-Hung Chen, Yu-Yang Sheng, Yu-Chiang Frank Wang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-03

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**LEAMLï¼šé¢å‘å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼Œå®ç°æ ‡ç­¾é«˜æ•ˆçš„é¢†åŸŸå¤–è§†è§‰ä»»åŠ¡è‡ªé€‚åº”**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `é¢†åŸŸè‡ªé€‚åº”` `æ ‡ç­¾é«˜æ•ˆå­¦ä¹ ` `ä¼ªæ ‡ç­¾ç”Ÿæˆ` `é€‰æ‹©æ€§ç¥ç»å…ƒæ›´æ–°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸå¤–æ•°æ®ä¸Šè¡¨ç°ä¸ä½³ï¼Œä¸»è¦åŸå› æ˜¯ç¼ºä¹æ ‡æ³¨æ•°æ®ï¼Œè·å–æˆæœ¬é«˜æ˜‚ã€‚
2. LEAMLæ¡†æ¶åˆ©ç”¨å°‘é‡æ ‡æ³¨æ•°æ®å’Œå¤§é‡æœªæ ‡æ³¨æ•°æ®ï¼Œé€šè¿‡ä¼ªæ ‡ç­¾ç”Ÿæˆå’Œé€‰æ‹©æ€§ç¥ç»å…ƒæ›´æ–°å®ç°é«˜æ•ˆè‡ªé€‚åº”ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒLEAMLåœ¨èƒƒè‚ å†…çª¥é•œå’Œä½“è‚²VQAä»»åŠ¡ä¸Šä¼˜äºæ ‡å‡†å¾®è°ƒï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)åœ¨é€šç”¨è§†è§‰åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨åŒ»å­¦æˆåƒç­‰ä¸“ä¸šé¢†åŸŸçš„å¤–åˆ†å¸ƒ(OOD)ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ï¼Œè¿™äº›é¢†åŸŸçš„æ ‡æ³¨æ•°æ®æœ‰é™ä¸”æ˜‚è´µã€‚æˆ‘ä»¬æå‡ºäº†LEAMLï¼Œä¸€ä¸ªæ ‡ç­¾é«˜æ•ˆçš„è‡ªé€‚åº”æ¡†æ¶ï¼Œå®ƒåˆ©ç”¨ç¨€ç¼ºçš„æ ‡æ³¨VQAæ ·æœ¬å’Œå¤§é‡çš„æœªæ ‡æ³¨å›¾åƒã€‚æˆ‘ä»¬çš„æ–¹æ³•ä½¿ç”¨ç”±caption distillationæ­£åˆ™åŒ–çš„QAç”Ÿæˆå™¨ï¼Œä¸ºæœªæ ‡æ³¨æ•°æ®ç”Ÿæˆé¢†åŸŸç›¸å…³çš„ä¼ªé—®ç­”å¯¹ã€‚é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬é€‰æ‹©æ€§åœ°æ›´æ–°ä¸é—®ç­”æœ€ç›¸å…³çš„ç¥ç»å…ƒï¼Œä½¿QAç”Ÿæˆå™¨èƒ½å¤Ÿåœ¨è’¸é¦è¿‡ç¨‹ä¸­æœ‰æ•ˆåœ°è·å–é¢†åŸŸç‰¹å®šçŸ¥è¯†ã€‚åœ¨èƒƒè‚ å†…çª¥é•œå’Œä½“è‚²VQAä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒLEAMLåœ¨æœ€å°ç›‘ç£ä¸‹å§‹ç»ˆä¼˜äºæ ‡å‡†å¾®è°ƒï¼Œçªå‡ºäº†æˆ‘ä»¬æå‡ºçš„LEAMLæ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)åœ¨ç‰¹å®šé¢†åŸŸï¼Œç‰¹åˆ«æ˜¯æ ‡æ³¨æ•°æ®ç¨€ç¼ºçš„é¢†åŸŸï¼Œè¿›è¡Œè§†è§‰é—®ç­”(VQA)ä»»åŠ¡æ—¶ï¼Œæ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡çš„æ ‡æ³¨æ•°æ®è¿›è¡Œå¾®è°ƒï¼Œä½†åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè·å–è¿™äº›æ•°æ®çš„æˆæœ¬å¾ˆé«˜ï¼Œé™åˆ¶äº†MLLMsåœ¨è¿™äº›é¢†åŸŸçš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§é‡çš„æœªæ ‡æ³¨æ•°æ®ï¼Œé€šè¿‡ç”Ÿæˆä¼ªæ ‡ç­¾çš„æ–¹å¼æ¥æ‰©å……è®­ç»ƒæ•°æ®ï¼Œå¹¶é‡‡ç”¨é€‰æ‹©æ€§æ›´æ–°ç­–ç•¥ï¼Œåªæ›´æ–°ä¸é—®ç­”ä»»åŠ¡ç›¸å…³çš„ç¥ç»å…ƒï¼Œä»è€Œæé«˜è®­ç»ƒæ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚è¿™ç§æ–¹æ³•å¯ä»¥åœ¨å°‘é‡æ ‡æ³¨æ•°æ®çš„æ¡ä»¶ä¸‹ï¼Œä½¿æ¨¡å‹å¿«é€Ÿé€‚åº”æ–°çš„é¢†åŸŸã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLEAMLæ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) QAç”Ÿæˆå™¨ï¼šç”¨äºç”Ÿæˆä¼ªé—®ç­”å¯¹ï¼Œè¾“å…¥æ˜¯æœªæ ‡æ³¨å›¾åƒï¼Œè¾“å‡ºæ˜¯é—®é¢˜å’Œç­”æ¡ˆã€‚2) Caption Distillationï¼šä½¿ç”¨å›¾åƒæè¿°æ¨¡å‹ç”Ÿæˆå›¾åƒçš„æè¿°ï¼Œå¹¶ä»¥æ­¤æ¥æ­£åˆ™åŒ–QAç”Ÿæˆå™¨ï¼Œä¿è¯ç”Ÿæˆçš„é—®é¢˜å’Œç­”æ¡ˆä¸å›¾åƒå†…å®¹ç›¸å…³ã€‚3) é€‰æ‹©æ€§ç¥ç»å…ƒæ›´æ–°ï¼šåªæ›´æ–°ä¸é—®ç­”ä»»åŠ¡ç›¸å…³çš„ç¥ç»å…ƒï¼Œé¿å…æ— å…³ç¥ç»å…ƒçš„å¹²æ‰°ï¼Œæé«˜è®­ç»ƒæ•ˆç‡ã€‚æ•´ä½“æµç¨‹æ˜¯ï¼šé¦–å…ˆä½¿ç”¨Caption Distillationæ­£åˆ™åŒ–QAç”Ÿæˆå™¨ï¼Œç„¶åä½¿ç”¨QAç”Ÿæˆå™¨ä¸ºæœªæ ‡æ³¨æ•°æ®ç”Ÿæˆä¼ªé—®ç­”å¯¹ï¼Œæœ€åä½¿ç”¨æ ‡æ³¨æ•°æ®å’Œä¼ªé—®ç­”å¯¹å¾®è°ƒMLLMï¼Œå¹¶é‡‡ç”¨é€‰æ‹©æ€§ç¥ç»å…ƒæ›´æ–°ç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†é€‰æ‹©æ€§ç¥ç»å…ƒæ›´æ–°ç­–ç•¥ã€‚ä¼ ç»Ÿçš„å¾®è°ƒæ–¹æ³•ä¼šæ›´æ–°æ‰€æœ‰ç¥ç»å…ƒï¼Œä½†åœ¨é¢†åŸŸè‡ªé€‚åº”ä»»åŠ¡ä¸­ï¼Œå¾ˆå¤šç¥ç»å…ƒä¸ç›®æ ‡ä»»åŠ¡æ— å…³ï¼Œæ›´æ–°è¿™äº›ç¥ç»å…ƒåè€Œä¼šé™ä½æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚LEAMLé€šè¿‡é€‰æ‹©æ€§åœ°æ›´æ–°ä¸é—®ç­”ä»»åŠ¡ç›¸å…³çš„ç¥ç»å…ƒï¼Œå¯ä»¥æ›´æœ‰æ•ˆåœ°åˆ©ç”¨æœ‰é™çš„æ ‡æ³¨æ•°æ®ï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨Caption Distillationä¸­ï¼Œä½¿ç”¨äº†äº¤å‰ç†µæŸå¤±å‡½æ•°æ¥è¡¡é‡QAç”Ÿæˆå™¨ç”Ÿæˆçš„é—®é¢˜å’Œç­”æ¡ˆä¸å›¾åƒæè¿°ä¹‹é—´çš„å·®å¼‚ã€‚åœ¨é€‰æ‹©æ€§ç¥ç»å…ƒæ›´æ–°ä¸­ï¼Œä½¿ç”¨äº†L1æ­£åˆ™åŒ–æ¥é€‰æ‹©ä¸é—®ç­”ä»»åŠ¡ç›¸å…³çš„ç¥ç»å…ƒã€‚å…·ä½“æ¥è¯´ï¼Œå¯¹äºæ¯ä¸ªç¥ç»å…ƒï¼Œè®¡ç®—å…¶åœ¨é—®ç­”ä»»åŠ¡ä¸­çš„æ¿€æ´»ç¨‹åº¦ï¼Œå¹¶æ ¹æ®æ¿€æ´»ç¨‹åº¦çš„å¤§å°æ¥å†³å®šæ˜¯å¦æ›´æ–°è¯¥ç¥ç»å…ƒã€‚æ­¤å¤–ï¼Œè¿˜ä½¿ç”¨äº†dropoutç­‰æ­£åˆ™åŒ–æŠ€æœ¯æ¥é˜²æ­¢è¿‡æ‹Ÿåˆã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

LEAMLåœ¨èƒƒè‚ å†…çª¥é•œVQAå’Œä½“è‚²VQAä¸¤ä¸ªä»»åŠ¡ä¸Šè¿›è¡Œäº†å®éªŒï¼Œç»“æœè¡¨æ˜ï¼ŒLEAMLåœ¨å°‘é‡æ ‡æ³¨æ•°æ®çš„æƒ…å†µä¸‹ï¼Œæ˜¾è‘—ä¼˜äºæ ‡å‡†å¾®è°ƒæ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨èƒƒè‚ å†…çª¥é•œVQAä»»åŠ¡ä¸­ï¼ŒLEAMLåœ¨åªä½¿ç”¨10%æ ‡æ³¨æ•°æ®çš„æƒ…å†µä¸‹ï¼Œè¾¾åˆ°äº†ä¸ä½¿ç”¨å…¨éƒ¨æ ‡æ³¨æ•°æ®è¿›è¡Œæ ‡å‡†å¾®è°ƒç›¸å½“çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼ŒLEAMLè¿˜èƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨æœªæ ‡æ³¨æ•°æ®ï¼Œè¿›ä¸€æ­¥æé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

LEAMLæ¡†æ¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå°¤å…¶æ˜¯åœ¨åŒ»å­¦å½±åƒåˆ†æã€é¥æ„Ÿå›¾åƒè§£è¯‘ã€å·¥ä¸šè´¨æ£€ç­‰é¢†åŸŸï¼Œè¿™äº›é¢†åŸŸé€šå¸¸ç¼ºä¹å¤§é‡çš„æ ‡æ³¨æ•°æ®ã€‚é€šè¿‡åˆ©ç”¨æœªæ ‡æ³¨æ•°æ®å’Œå°‘é‡æ ‡æ³¨æ•°æ®ï¼ŒLEAMLå¯ä»¥å¸®åŠ©MLLMså¿«é€Ÿé€‚åº”è¿™äº›é¢†åŸŸçš„ä»»åŠ¡ï¼Œæé«˜è¯Šæ–­ç²¾åº¦ã€è§£è¯‘æ•ˆç‡å’Œäº§å“è´¨é‡ï¼Œå…·æœ‰é‡è¦çš„å®é™…åº”ç”¨ä»·å€¼å’Œæ½œåœ¨çš„ç¤¾ä¼šç»æµæ•ˆç›Šã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal Large Language Models (MLLMs) have achieved strong performance on general visual benchmarks but struggle with out-of-distribution (OOD) tasks in specialized domains such as medical imaging, where labeled data is limited and expensive. We introduce LEAML, a label-efficient adaptation framework that leverages both scarce labeled VQA samples and abundant unlabeled images. Our approach generates domain-relevant pseudo question-answer pairs for unlabeled data using a QA generator regularized by caption distillation. Importantly, we selectively update only those neurons most relevant to question-answering, enabling the QA Generator to efficiently acquire domain-specific knowledge during distillation. Experiments on gastrointestinal endoscopy and sports VQA demonstrate that LEAML consistently outperforms standard fine-tuning under minimal supervision, highlighting the effectiveness of our proposed LEAML framework.

