---
layout: default
title: MaskCD: Mitigating LVLM Hallucinations by Image Head Masked Contrastive Decoding
---

# MaskCD: Mitigating LVLM Hallucinations by Image Head Masked Contrastive Decoding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.02790" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.02790v1</a>
  <a href="https://arxiv.org/pdf/2510.02790.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.02790v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.02790v1', 'MaskCD: Mitigating LVLM Hallucinations by Image Head Masked Contrastive Decoding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jingyuan Deng, Yujiu Yang

**åˆ†ç±»**: cs.CV, cs.AI, cs.CL, cs.MM

**å‘å¸ƒæ—¥æœŸ**: 2025-10-03

**å¤‡æ³¨**: accepted to emnlp2025 findings

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Deng-Jingyuan/MaskCD)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMaskCDï¼Œé€šè¿‡å›¾åƒå¤´æ©ç å¯¹æ¯”è§£ç ç¼“è§£LVLMå¹»è§‰é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹` `å¹»è§‰ç¼“è§£` `å¯¹æ¯”è§£ç ` `å›¾åƒå¤´æ©ç ` `å¤šæ¨¡æ€å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LVLMå®¹æ˜“äº§ç”Ÿå¹»è§‰ï¼Œå³ç”Ÿæˆä¸è¾“å…¥è§†è§‰å’Œæ–‡æœ¬å†…å®¹çŸ›ç›¾çš„ä¿¡æ¯ï¼Œç°æœ‰å¯¹æ¯”è§£ç æ–¹æ³•éš¾ä»¥æ„å»ºåˆé€‚çš„å¯¹æ¯”æ ·æœ¬ï¼Œæ³¨æ„åŠ›æ“çºµæ–¹æ³•åˆ™ç¼ºä¹ç¨³å®šæ€§ã€‚
2. MaskCDçš„æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨LVLMä¸­çš„â€œå›¾åƒå¤´â€ï¼Œé€šè¿‡æ©ç å›¾åƒå¤´æ¥æ„å»ºå¯¹æ¯”æ ·æœ¬ï¼Œç”¨äºå¯¹æ¯”è§£ç ï¼Œä»è€ŒæŠ‘åˆ¶å¹»è§‰ã€‚
3. åœ¨LLaVA-1.5-7bå’ŒQwen-VL-7bä¸Šï¼ŒMaskCDåœ¨CHAIRã€POPEã€AMBERå’ŒMMEç­‰åŸºå‡†æµ‹è¯•ä¸­æœ‰æ•ˆç¼“è§£äº†å¹»è§‰ç°è±¡ï¼Œå¹¶ä¿æŒäº†LVLMçš„é€šç”¨èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹(LVLMs)åœ¨ä¸‹æ¸¸å¤šæ¨¡æ€ä»»åŠ¡çš„è§†è§‰è¯­è¨€ç†è§£æ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œéšç€èƒ½åŠ›çš„æå‡ï¼Œé—®é¢˜ä¹Ÿéšä¹‹å‡ºç°ã€‚å…¶ä¸­ï¼Œå¹»è§‰é—®é¢˜å¤‡å—å…³æ³¨ï¼ŒæŒ‡çš„æ˜¯LVLMsç”Ÿæˆä¸å…¶è¾“å…¥è§†è§‰å’Œæ–‡æœ¬å†…å®¹ç›¸çŸ›ç›¾çš„å†…å®¹çš„ç°è±¡ã€‚è®¸å¤šæ–¹æ³•è¢«æå‡ºä»¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä¾‹å¦‚å¯¹æ¯”è§£ç å’Œæ³¨æ„åŠ›æ“çºµã€‚ç„¶è€Œï¼Œå¯¹æ¯”è§£ç æ–¹æ³•åœ¨æ„å»ºåˆé€‚çš„å¯¹æ¯”æ ·æœ¬æ–¹é¢å­˜åœ¨å›°éš¾ï¼Œè€Œæ³¨æ„åŠ›æ“çºµæ–¹æ³•é«˜åº¦æ•æ„Ÿï¼Œç¼ºä¹ç¨³å®šæ€§ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†å›¾åƒå¤´æ©ç å¯¹æ¯”è§£ç (MaskCD)ã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨LVLMsä¸­çš„â€œå›¾åƒå¤´â€ï¼Œé€šè¿‡æ©ç›–å®ƒä»¬æ¥æ„å»ºå¯¹æ¯”è§£ç çš„å¯¹æ¯”æ ·æœ¬ã€‚æˆ‘ä»¬ä½¿ç”¨CHAIRã€POPEã€AMBERå’ŒMMEç­‰å„ç§åŸºå‡†åœ¨LLaVA-1.5-7bå’ŒQwen-VL-7bä¸Šè¯„ä¼°äº†MaskCDã€‚ç»“æœè¡¨æ˜ï¼ŒMaskCDæœ‰æ•ˆåœ°ç¼“è§£äº†å¹»è§‰ç°è±¡ï¼Œå¹¶ä¿ç•™äº†LVLMsçš„é€šç”¨èƒ½åŠ›ã€‚ç›¸åº”çš„èµ„æºå¯ä»¥åœ¨https://github.com/Deng-Jingyuan/MaskCD æ‰¾åˆ°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMï¼‰ä¸­å­˜åœ¨çš„å¹»è§‰é—®é¢˜ï¼Œå³æ¨¡å‹ç”Ÿæˆä¸è¾“å…¥å›¾åƒå’Œæ–‡æœ¬å†…å®¹ç›¸çŸ›ç›¾çš„ä¿¡æ¯ã€‚ç°æœ‰çš„å¯¹æ¯”è§£ç æ–¹æ³•éš¾ä»¥æ„å»ºæœ‰æ•ˆçš„å¯¹æ¯”æ ·æœ¬ï¼Œè€Œæ³¨æ„åŠ›æœºåˆ¶è°ƒæ•´æ–¹æ³•åˆè¿‡äºæ•æ„Ÿï¼Œç¼ºä¹ç¨³å®šæ€§ï¼Œå¯¼è‡´å¹»è§‰é—®é¢˜éš¾ä»¥æœ‰æ•ˆç¼“è§£ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMaskCDçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨LVLMä¸­è´Ÿè´£å¤„ç†å›¾åƒä¿¡æ¯çš„â€œå›¾åƒå¤´â€ï¼Œé€šè¿‡å¯¹è¿™äº›å›¾åƒå¤´è¿›è¡Œæ©ç æ“ä½œï¼Œç”Ÿæˆä¸åŸå§‹å›¾åƒä¿¡æ¯ç•¥æœ‰å·®å¼‚çš„å¯¹æ¯”æ ·æœ¬ã€‚ç„¶åï¼Œåˆ©ç”¨è¿™äº›å¯¹æ¯”æ ·æœ¬è¿›è¡Œå¯¹æ¯”è§£ç ï¼Œé¼“åŠ±æ¨¡å‹ç”Ÿæˆä¸åŸå§‹å›¾åƒä¿¡æ¯ä¸€è‡´çš„æ–‡æœ¬æè¿°ï¼Œä»è€ŒæŠ‘åˆ¶å¹»è§‰ã€‚è¿™ç§æ–¹æ³•é¿å…äº†æ‰‹åŠ¨è®¾è®¡å¯¹æ¯”æ ·æœ¬çš„å›°éš¾ï¼Œå¹¶é™ä½äº†å¯¹æ³¨æ„åŠ›æœºåˆ¶çš„è¿‡åº¦ä¾èµ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMaskCDçš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1) è¾“å…¥å›¾åƒå’Œæ–‡æœ¬æç¤ºï¼›2) é€šè¿‡LVLMçš„å›¾åƒç¼–ç å™¨æå–å›¾åƒç‰¹å¾ï¼›3) å¯¹å›¾åƒç¼–ç å™¨çš„â€œå›¾åƒå¤´â€è¿›è¡Œæ©ç æ“ä½œï¼Œç”Ÿæˆå¯¹æ¯”å›¾åƒç‰¹å¾ï¼›4) å°†åŸå§‹å›¾åƒç‰¹å¾å’Œå¯¹æ¯”å›¾åƒç‰¹å¾åˆ†åˆ«è¾“å…¥åˆ°LVLMçš„æ–‡æœ¬è§£ç å™¨ä¸­ï¼›5) åˆ©ç”¨å¯¹æ¯”è§£ç æŸå¤±å‡½æ•°ï¼Œé¼“åŠ±æ¨¡å‹ç”Ÿæˆä¸åŸå§‹å›¾åƒç‰¹å¾ä¸€è‡´çš„æ–‡æœ¬æè¿°ï¼ŒæŠ‘åˆ¶ä¸å¯¹æ¯”å›¾åƒç‰¹å¾ç›¸å…³çš„å¹»è§‰ä¿¡æ¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šMaskCDçš„å…³é”®åˆ›æ–°åœ¨äºåˆ©ç”¨â€œå›¾åƒå¤´æ©ç â€æ¥è‡ªåŠ¨ç”Ÿæˆå¯¹æ¯”æ ·æœ¬ã€‚ä¸æ‰‹åŠ¨æ„å»ºæˆ–ä½¿ç”¨å¯¹æŠ—æ”»å‡»ç”Ÿæˆå¯¹æ¯”æ ·æœ¬çš„æ–¹æ³•ç›¸æ¯”ï¼Œè¿™ç§æ–¹æ³•æ›´åŠ é«˜æ•ˆä¸”æ˜“äºå®ç°ã€‚æ­¤å¤–ï¼ŒMaskCDç›´æ¥ä½œç”¨äºLVLMçš„å†…éƒ¨ç»“æ„ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨æ¨¡å‹è‡ªèº«çš„çŸ¥è¯†æ¥æŠ‘åˆ¶å¹»è§‰ã€‚

**å…³é”®è®¾è®¡**ï¼šMaskCDçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) å›¾åƒå¤´æ©ç ç­–ç•¥ï¼šå¦‚ä½•é€‰æ‹©éœ€è¦æ©ç çš„å›¾åƒå¤´ï¼Œä»¥åŠæ©ç çš„æ¯”ä¾‹ï¼›2) å¯¹æ¯”è§£ç æŸå¤±å‡½æ•°ï¼šå¦‚ä½•è®¾è®¡æŸå¤±å‡½æ•°æ¥æœ‰æ•ˆåœ°é¼“åŠ±æ¨¡å‹ç”Ÿæˆä¸åŸå§‹å›¾åƒä¿¡æ¯ä¸€è‡´çš„æ–‡æœ¬æè¿°ï¼›3) è¶…å‚æ•°è®¾ç½®ï¼šä¾‹å¦‚ï¼Œå¯¹æ¯”è§£ç çš„æ¸©åº¦ç³»æ•°ç­‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

MaskCD åœ¨ LLaVA-1.5-7b å’Œ Qwen-VL-7b æ¨¡å‹ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå¹¶åœ¨ CHAIRã€POPEã€AMBER å’Œ MME ç­‰å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMaskCD èƒ½å¤Ÿæœ‰æ•ˆç¼“è§£ LVLM çš„å¹»è§‰é—®é¢˜ï¼ŒåŒæ—¶ä¿æŒäº†æ¨¡å‹åŸæœ‰çš„é€šç”¨èƒ½åŠ›ã€‚å…·ä½“æå‡å¹…åº¦åœ¨ä¸åŒæ•°æ®é›†å’Œæ¨¡å‹ä¸Šæœ‰æ‰€ä¸åŒï¼Œä½†æ€»ä½“è¶‹åŠ¿æ˜¯æ­£å‘çš„ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MaskCD æœ‰æ½œåŠ›åº”ç”¨äºå„ç§éœ€è¦å¯é è§†è§‰è¯­è¨€ç†è§£çš„åœºæ™¯ï¼Œä¾‹å¦‚ï¼šåŒ»ç–—å½±åƒè¯Šæ–­ï¼Œè‡ªåŠ¨é©¾é©¶ï¼Œæ™ºèƒ½å®¢æœï¼Œä»¥åŠè§†è§‰è¾…åŠ©å·¥å…·ç­‰ã€‚é€šè¿‡å‡å°‘LVLMçš„å¹»è§‰ï¼Œå¯ä»¥æé«˜è¿™äº›åº”ç”¨çš„å¯ä¿¡åº¦å’Œå®‰å…¨æ€§ï¼Œå¹¶æœ€ç»ˆæå‡ç”¨æˆ·ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯å¯ä»¥è¿›ä¸€æ­¥æ‰©å±•åˆ°å…¶ä»–å¤šæ¨¡æ€ä»»åŠ¡ï¼Œä¾‹å¦‚è§†é¢‘ç†è§£å’Œè¯­éŸ³è¯†åˆ«ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large vision-language models (LVLMs) have shown remarkable performance in visual-language understanding for downstream multimodal tasks. While their capabilities are improving, problems emerge simultaneously. Among those problems, the hallucinations have attracted much attention, which stands for the phenomenon where LVLMs generate contradictory content to their input visual and text contents. Many approaches have been proposed to deal with this issue, such as contrastive decoding and attention manipulation. However, contrastive decoding methods struggle in constructing appropriate contrastive samples, and attention manipulation methods are highly sensitive, lacking stability. In this work, we propose image head Masked Contrastive Decoding (MaskCD). Our approach utilizes the "image heads" in LVLMs, masking them to construct contrastive samples for contrastive decoding. We evaluated MaskCD on LLaVA-1.5-7b and Qwen-VL-7b, using various benchmarks such as CHAIR, POPE, AMBER and MME. The results demonstrate that MaskCD effectively alleviates the phenomenon of hallucinations and retains the general capabilities of LVLMs. Corresponding resources could be found at: https://github.com/Deng-Jingyuan/MaskCD .

