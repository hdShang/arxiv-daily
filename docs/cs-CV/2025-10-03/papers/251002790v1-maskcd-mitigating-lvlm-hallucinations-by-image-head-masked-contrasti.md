---
layout: default
title: MaskCD: Mitigating LVLM Hallucinations by Image Head Masked Contrastive Decoding
---

# MaskCD: Mitigating LVLM Hallucinations by Image Head Masked Contrastive Decoding

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.02790" target="_blank" class="toolbar-btn">arXiv: 2510.02790v1</a>
    <a href="https://arxiv.org/pdf/2510.02790.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.02790v1" 
            onclick="toggleFavorite(this, '2510.02790v1', 'MaskCD: Mitigating LVLM Hallucinations by Image Head Masked Contrastive Decoding')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Jingyuan Deng, Yujiu Yang

**ÂàÜÁ±ª**: cs.CV, cs.AI, cs.CL, cs.MM

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-03

**Â§áÊ≥®**: accepted to emnlp2025 findings

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/Deng-Jingyuan/MaskCD)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫MaskCDÔºåÈÄöËøáÂõæÂÉèÂ§¥Êé©Á†ÅÂØπÊØîËß£Á†ÅÁºìËß£LVLMÂπªËßâÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§ßÂûãËßÜËßâËØ≠Ë®ÄÊ®°Âûã` `ÂπªËßâÁºìËß£` `ÂØπÊØîËß£Á†Å` `ÂõæÂÉèÂ§¥Êé©Á†Å` `Â§öÊ®°ÊÄÅÂ≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâLVLMÂÆπÊòì‰∫ßÁîüÂπªËßâÔºåÂç≥ÁîüÊàê‰∏éËæìÂÖ•ËßÜËßâÂíåÊñáÊú¨ÂÜÖÂÆπÁüõÁõæÁöÑ‰ø°ÊÅØÔºåÁé∞ÊúâÂØπÊØîËß£Á†ÅÊñπÊ≥ïÈöæ‰ª•ÊûÑÂª∫ÂêàÈÄÇÁöÑÂØπÊØîÊ†∑Êú¨ÔºåÊ≥®ÊÑèÂäõÊìçÁ∫µÊñπÊ≥ïÂàôÁº∫‰πèÁ®≥ÂÆöÊÄß„ÄÇ
2. MaskCDÁöÑÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÂà©Áî®LVLM‰∏≠ÁöÑ‚ÄúÂõæÂÉèÂ§¥‚ÄùÔºåÈÄöËøáÊé©Á†ÅÂõæÂÉèÂ§¥Êù•ÊûÑÂª∫ÂØπÊØîÊ†∑Êú¨ÔºåÁî®‰∫éÂØπÊØîËß£Á†ÅÔºå‰ªéËÄåÊäëÂà∂ÂπªËßâ„ÄÇ
3. Âú®LLaVA-1.5-7bÂíåQwen-VL-7b‰∏äÔºåMaskCDÂú®CHAIR„ÄÅPOPE„ÄÅAMBERÂíåMMEÁ≠âÂü∫ÂáÜÊµãËØï‰∏≠ÊúâÊïàÁºìËß£‰∫ÜÂπªËßâÁé∞Ë±°ÔºåÂπ∂‰øùÊåÅ‰∫ÜLVLMÁöÑÈÄöÁî®ËÉΩÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§ßÂûãËßÜËßâËØ≠Ë®ÄÊ®°Âûã(LVLMs)Âú®‰∏ãÊ∏∏Â§öÊ®°ÊÄÅ‰ªªÂä°ÁöÑËßÜËßâËØ≠Ë®ÄÁêÜËß£ÊñπÈù¢Ë°®Áé∞Âá∫ÂçìË∂äÁöÑÊÄßËÉΩ„ÄÇÁÑ∂ËÄåÔºåÈöèÁùÄËÉΩÂäõÁöÑÊèêÂçáÔºåÈóÆÈ¢ò‰πüÈöè‰πãÂá∫Áé∞„ÄÇÂÖ∂‰∏≠ÔºåÂπªËßâÈóÆÈ¢òÂ§áÂèóÂÖ≥Ê≥®ÔºåÊåáÁöÑÊòØLVLMsÁîüÊàê‰∏éÂÖ∂ËæìÂÖ•ËßÜËßâÂíåÊñáÊú¨ÂÜÖÂÆπÁõ∏ÁüõÁõæÁöÑÂÜÖÂÆπÁöÑÁé∞Ë±°„ÄÇËÆ∏Â§öÊñπÊ≥ïË¢´ÊèêÂá∫‰ª•Ëß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºå‰æãÂ¶ÇÂØπÊØîËß£Á†ÅÂíåÊ≥®ÊÑèÂäõÊìçÁ∫µ„ÄÇÁÑ∂ËÄåÔºåÂØπÊØîËß£Á†ÅÊñπÊ≥ïÂú®ÊûÑÂª∫ÂêàÈÄÇÁöÑÂØπÊØîÊ†∑Êú¨ÊñπÈù¢Â≠òÂú®Âõ∞ÈöæÔºåËÄåÊ≥®ÊÑèÂäõÊìçÁ∫µÊñπÊ≥ïÈ´òÂ∫¶ÊïèÊÑüÔºåÁº∫‰πèÁ®≥ÂÆöÊÄß„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜÂõæÂÉèÂ§¥Êé©Á†ÅÂØπÊØîËß£Á†Å(MaskCD)„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÂà©Áî®LVLMs‰∏≠ÁöÑ‚ÄúÂõæÂÉèÂ§¥‚ÄùÔºåÈÄöËøáÊé©ÁõñÂÆÉ‰ª¨Êù•ÊûÑÂª∫ÂØπÊØîËß£Á†ÅÁöÑÂØπÊØîÊ†∑Êú¨„ÄÇÊàë‰ª¨‰ΩøÁî®CHAIR„ÄÅPOPE„ÄÅAMBERÂíåMMEÁ≠âÂêÑÁßçÂü∫ÂáÜÂú®LLaVA-1.5-7bÂíåQwen-VL-7b‰∏äËØÑ‰º∞‰∫ÜMaskCD„ÄÇÁªìÊûúË°®ÊòéÔºåMaskCDÊúâÊïàÂú∞ÁºìËß£‰∫ÜÂπªËßâÁé∞Ë±°ÔºåÂπ∂‰øùÁïô‰∫ÜLVLMsÁöÑÈÄöÁî®ËÉΩÂäõ„ÄÇÁõ∏Â∫îÁöÑËµÑÊ∫êÂèØ‰ª•Âú®https://github.com/Deng-Jingyuan/MaskCD ÊâæÂà∞„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Â§ßÂûãËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÔºàLVLMÔºâ‰∏≠Â≠òÂú®ÁöÑÂπªËßâÈóÆÈ¢òÔºåÂç≥Ê®°ÂûãÁîüÊàê‰∏éËæìÂÖ•ÂõæÂÉèÂíåÊñáÊú¨ÂÜÖÂÆπÁõ∏ÁüõÁõæÁöÑ‰ø°ÊÅØ„ÄÇÁé∞ÊúâÁöÑÂØπÊØîËß£Á†ÅÊñπÊ≥ïÈöæ‰ª•ÊûÑÂª∫ÊúâÊïàÁöÑÂØπÊØîÊ†∑Êú¨ÔºåËÄåÊ≥®ÊÑèÂäõÊú∫Âà∂Ë∞ÉÊï¥ÊñπÊ≥ïÂèàËøá‰∫éÊïèÊÑüÔºåÁº∫‰πèÁ®≥ÂÆöÊÄßÔºåÂØºËá¥ÂπªËßâÈóÆÈ¢òÈöæ‰ª•ÊúâÊïàÁºìËß£„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöMaskCDÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®LVLM‰∏≠Ë¥üË¥£Â§ÑÁêÜÂõæÂÉè‰ø°ÊÅØÁöÑ‚ÄúÂõæÂÉèÂ§¥‚ÄùÔºåÈÄöËøáÂØπËøô‰∫õÂõæÂÉèÂ§¥ËøõË°åÊé©Á†ÅÊìç‰ΩúÔºåÁîüÊàê‰∏éÂéüÂßãÂõæÂÉè‰ø°ÊÅØÁï•ÊúâÂ∑ÆÂºÇÁöÑÂØπÊØîÊ†∑Êú¨„ÄÇÁÑ∂ÂêéÔºåÂà©Áî®Ëøô‰∫õÂØπÊØîÊ†∑Êú¨ËøõË°åÂØπÊØîËß£Á†ÅÔºåÈºìÂä±Ê®°ÂûãÁîüÊàê‰∏éÂéüÂßãÂõæÂÉè‰ø°ÊÅØ‰∏ÄËá¥ÁöÑÊñáÊú¨ÊèèËø∞Ôºå‰ªéËÄåÊäëÂà∂ÂπªËßâ„ÄÇËøôÁßçÊñπÊ≥ïÈÅøÂÖç‰∫ÜÊâãÂä®ËÆæËÆ°ÂØπÊØîÊ†∑Êú¨ÁöÑÂõ∞ÈöæÔºåÂπ∂Èôç‰Ωé‰∫ÜÂØπÊ≥®ÊÑèÂäõÊú∫Âà∂ÁöÑËøáÂ∫¶‰æùËµñ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöMaskCDÁöÑÊäÄÊúØÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Ê≠•È™§Ôºö1) ËæìÂÖ•ÂõæÂÉèÂíåÊñáÊú¨ÊèêÁ§∫Ôºõ2) ÈÄöËøáLVLMÁöÑÂõæÂÉèÁºñÁ†ÅÂô®ÊèêÂèñÂõæÂÉèÁâπÂæÅÔºõ3) ÂØπÂõæÂÉèÁºñÁ†ÅÂô®ÁöÑ‚ÄúÂõæÂÉèÂ§¥‚ÄùËøõË°åÊé©Á†ÅÊìç‰ΩúÔºåÁîüÊàêÂØπÊØîÂõæÂÉèÁâπÂæÅÔºõ4) Â∞ÜÂéüÂßãÂõæÂÉèÁâπÂæÅÂíåÂØπÊØîÂõæÂÉèÁâπÂæÅÂàÜÂà´ËæìÂÖ•Âà∞LVLMÁöÑÊñáÊú¨Ëß£Á†ÅÂô®‰∏≠Ôºõ5) Âà©Áî®ÂØπÊØîËß£Á†ÅÊçüÂ§±ÂáΩÊï∞ÔºåÈºìÂä±Ê®°ÂûãÁîüÊàê‰∏éÂéüÂßãÂõæÂÉèÁâπÂæÅ‰∏ÄËá¥ÁöÑÊñáÊú¨ÊèèËø∞ÔºåÊäëÂà∂‰∏éÂØπÊØîÂõæÂÉèÁâπÂæÅÁõ∏ÂÖ≥ÁöÑÂπªËßâ‰ø°ÊÅØ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöMaskCDÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂà©Áî®‚ÄúÂõæÂÉèÂ§¥Êé©Á†Å‚ÄùÊù•Ëá™Âä®ÁîüÊàêÂØπÊØîÊ†∑Êú¨„ÄÇ‰∏éÊâãÂä®ÊûÑÂª∫Êàñ‰ΩøÁî®ÂØπÊäóÊîªÂáªÁîüÊàêÂØπÊØîÊ†∑Êú¨ÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåËøôÁßçÊñπÊ≥ïÊõ¥Âä†È´òÊïà‰∏îÊòì‰∫éÂÆûÁé∞„ÄÇÊ≠§Â§ñÔºåMaskCDÁõ¥Êé•‰ΩúÁî®‰∫éLVLMÁöÑÂÜÖÈÉ®ÁªìÊûÑÔºåËÉΩÂ§üÊõ¥Â•ΩÂú∞Âà©Áî®Ê®°ÂûãËá™Ë∫´ÁöÑÁü•ËØÜÊù•ÊäëÂà∂ÂπªËßâ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöMaskCDÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ÂõæÂÉèÂ§¥Êé©Á†ÅÁ≠ñÁï•ÔºöÂ¶Ç‰ΩïÈÄâÊã©ÈúÄË¶ÅÊé©Á†ÅÁöÑÂõæÂÉèÂ§¥Ôºå‰ª•ÂèäÊé©Á†ÅÁöÑÊØî‰æãÔºõ2) ÂØπÊØîËß£Á†ÅÊçüÂ§±ÂáΩÊï∞ÔºöÂ¶Ç‰ΩïËÆæËÆ°ÊçüÂ§±ÂáΩÊï∞Êù•ÊúâÊïàÂú∞ÈºìÂä±Ê®°ÂûãÁîüÊàê‰∏éÂéüÂßãÂõæÂÉè‰ø°ÊÅØ‰∏ÄËá¥ÁöÑÊñáÊú¨ÊèèËø∞Ôºõ3) Ë∂ÖÂèÇÊï∞ËÆæÁΩÆÔºö‰æãÂ¶ÇÔºåÂØπÊØîËß£Á†ÅÁöÑÊ∏©Â∫¶Á≥ªÊï∞Á≠â„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

MaskCD Âú® LLaVA-1.5-7b Âíå Qwen-VL-7b Ê®°Âûã‰∏äËøõË°å‰∫ÜËØÑ‰º∞ÔºåÂπ∂Âú® CHAIR„ÄÅPOPE„ÄÅAMBER Âíå MME Á≠âÂ§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠ÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåMaskCD ËÉΩÂ§üÊúâÊïàÁºìËß£ LVLM ÁöÑÂπªËßâÈóÆÈ¢òÔºåÂêåÊó∂‰øùÊåÅ‰∫ÜÊ®°ÂûãÂéüÊúâÁöÑÈÄöÁî®ËÉΩÂäõ„ÄÇÂÖ∑‰ΩìÊèêÂçáÂπÖÂ∫¶Âú®‰∏çÂêåÊï∞ÊçÆÈõÜÂíåÊ®°Âûã‰∏äÊúâÊâÄ‰∏çÂêåÔºå‰ΩÜÊÄª‰ΩìË∂ãÂäøÊòØÊ≠£ÂêëÁöÑ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

MaskCD ÊúâÊΩúÂäõÂ∫îÁî®‰∫éÂêÑÁßçÈúÄË¶ÅÂèØÈù†ËßÜËßâËØ≠Ë®ÄÁêÜËß£ÁöÑÂú∫ÊôØÔºå‰æãÂ¶ÇÔºöÂåªÁñóÂΩ±ÂÉèËØäÊñ≠ÔºåËá™Âä®È©æÈ©∂ÔºåÊô∫ËÉΩÂÆ¢ÊúçÔºå‰ª•ÂèäËßÜËßâËæÖÂä©Â∑•ÂÖ∑Á≠â„ÄÇÈÄöËøáÂáèÂ∞ëLVLMÁöÑÂπªËßâÔºåÂèØ‰ª•ÊèêÈ´òËøô‰∫õÂ∫îÁî®ÁöÑÂèØ‰ø°Â∫¶ÂíåÂÆâÂÖ®ÊÄßÔºåÂπ∂ÊúÄÁªàÊèêÂçáÁî®Êà∑‰ΩìÈ™å„ÄÇÊú™Êù•ÔºåËØ•ÊäÄÊúØÂèØ‰ª•Ëøõ‰∏ÄÊ≠•Êâ©Â±ïÂà∞ÂÖ∂‰ªñÂ§öÊ®°ÊÄÅ‰ªªÂä°Ôºå‰æãÂ¶ÇËßÜÈ¢ëÁêÜËß£ÂíåËØ≠Èü≥ËØÜÂà´„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Large vision-language models (LVLMs) have shown remarkable performance in visual-language understanding for downstream multimodal tasks. While their capabilities are improving, problems emerge simultaneously. Among those problems, the hallucinations have attracted much attention, which stands for the phenomenon where LVLMs generate contradictory content to their input visual and text contents. Many approaches have been proposed to deal with this issue, such as contrastive decoding and attention manipulation. However, contrastive decoding methods struggle in constructing appropriate contrastive samples, and attention manipulation methods are highly sensitive, lacking stability. In this work, we propose image head Masked Contrastive Decoding (MaskCD). Our approach utilizes the "image heads" in LVLMs, masking them to construct contrastive samples for contrastive decoding. We evaluated MaskCD on LLaVA-1.5-7b and Qwen-VL-7b, using various benchmarks such as CHAIR, POPE, AMBER and MME. The results demonstrate that MaskCD effectively alleviates the phenomenon of hallucinations and retains the general capabilities of LVLMs. Corresponding resources could be found at: https://github.com/Deng-Jingyuan/MaskCD .

