---
layout: default
title: "Mask2IV: Interaction-Centric Video Generation via Mask Trajectories"
---

# Mask2IV: Interaction-Centric Video Generation via Mask Trajectories

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.03135" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.03135v2</a>
  <a href="https://arxiv.org/pdf/2510.03135.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.03135v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.03135v2', 'Mask2IV: Interaction-Centric Video Generation via Mask Trajectories')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Gen Li, Bo Zhao, Jianfei Yang, Laura Sevilla-Lara

**åˆ†ç±»**: cs.CV, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-10-03 (æ›´æ–°: 2025-11-21)

**å¤‡æ³¨**: AAAI 2026. Project page: https://reagan1311.github.io/mask2iv

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Mask2IVï¼šé€šè¿‡Maskè½¨è¿¹å®ç°äº¤äº’ä¸­å¿ƒè§†é¢‘ç”Ÿæˆï¼Œæ— éœ€å¯†é›†Maskæ ‡æ³¨ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction)**

**å…³é”®è¯**: `è§†é¢‘ç”Ÿæˆ` `äº¤äº’è§†é¢‘` `è½¨è¿¹é¢„æµ‹` `æœºå™¨äººå­¦ä¹ ` `å…·èº«æ™ºèƒ½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰äº¤äº’è§†é¢‘ç”Ÿæˆæ–¹æ³•éš¾ä»¥å»ºæ¨¡å¤æ‚åŠ¨æ€äº¤äº’ï¼Œä¸”ä¾èµ–å¯†é›†Maskæ ‡æ³¨ï¼Œé™åˆ¶äº†å®é™…åº”ç”¨ã€‚
2. Mask2IVé€šè¿‡è§£è€¦Actorå’ŒObjectçš„è¿åŠ¨è½¨è¿¹é¢„æµ‹ï¼Œå†è¿›è¡Œè§†é¢‘ç”Ÿæˆï¼Œæ— éœ€å¯†é›†Maskè¾“å…¥ï¼Œæå‡çµæ´»æ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒMask2IVåœ¨è§†è§‰çœŸå®æ„Ÿå’Œå¯æ§æ€§æ–¹é¢ä¼˜äºç°æœ‰åŸºçº¿ï¼Œå¹¶æ„å»ºäº†äºº-ç‰©äº¤äº’å’Œæœºå™¨äººæ“ä½œæ•°æ®é›†ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºMask2IVçš„æ–°æ¡†æ¶ï¼Œä¸“é—¨ç”¨äºç”Ÿæˆäº¤äº’ä¸­å¿ƒè§†é¢‘ï¼Œä¾‹å¦‚äººç±»æˆ–æœºå™¨äººä¸ç‰©ä½“äº¤äº’çš„è§†é¢‘ã€‚è¿™ç±»è§†é¢‘å¯¹äºå…·èº«æ™ºèƒ½è‡³å…³é‡è¦ï¼Œå› ä¸ºå®ƒä»¬ä¸ºæœºå™¨äººå­¦ä¹ ã€æ“ä½œç­–ç•¥è®­ç»ƒå’Œå¯ä¾›æ€§æ¨ç†æä¾›äº†ä¸°å¯Œå¤šæ ·çš„è§†è§‰å…ˆéªŒã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥å»ºæ¨¡è¿™ç§å¤æ‚å’ŒåŠ¨æ€çš„äº¤äº’ã€‚è™½ç„¶æœ€è¿‘çš„ç ”ç©¶è¡¨æ˜ï¼ŒMaskå¯ä»¥ä½œä¸ºæœ‰æ•ˆçš„æ§åˆ¶ä¿¡å·å¹¶æé«˜ç”Ÿæˆè´¨é‡ï¼Œä½†è·å¾—å¯†é›†å’Œç²¾ç¡®çš„Maskæ ‡æ³¨ä»ç„¶æ˜¯å®é™…åº”ç”¨ä¸­çš„ä¸€ä¸ªä¸»è¦æŒ‘æˆ˜ã€‚Mask2IVé‡‡ç”¨è§£è€¦çš„ä¸¤é˜¶æ®µæµç¨‹ï¼Œé¦–å…ˆé¢„æµ‹Actorå’ŒObjectçš„åˆç†è¿åŠ¨è½¨è¿¹ï¼Œç„¶åæ ¹æ®è¿™äº›è½¨è¿¹ç”Ÿæˆè§†é¢‘ã€‚è¿™ç§è®¾è®¡æ¶ˆé™¤äº†å¯¹ç”¨æˆ·å¯†é›†Maskè¾“å…¥çš„éœ€æ±‚ï¼ŒåŒæ—¶ä¿ç•™äº†æ“çºµäº¤äº’è¿‡ç¨‹çš„çµæ´»æ€§ã€‚æ­¤å¤–ï¼ŒMask2IVæ”¯æŒé€šç”¨ä¸”ç›´è§‚çš„æ§åˆ¶ï¼Œå…è®¸ç”¨æˆ·æŒ‡å®šäº¤äº’çš„ç›®æ ‡å¯¹è±¡ï¼Œå¹¶é€šè¿‡åŠ¨ä½œæè¿°æˆ–ç©ºé—´ä½ç½®çº¿ç´¢æ¥å¼•å¯¼è¿åŠ¨è½¨è¿¹ã€‚ä¸ºäº†æ”¯æŒç³»ç»Ÿçš„è®­ç»ƒå’Œè¯„ä¼°ï¼Œæˆ‘ä»¬ç­–åˆ’äº†ä¸¤ä¸ªåŸºå‡†æ•°æ®é›†ï¼Œæ¶µç›–äº†äºº-ç‰©äº¤äº’å’Œæœºå™¨äººæ“ä½œåœºæ™¯ä¸­çš„å„ç§åŠ¨ä½œå’Œå¯¹è±¡ç±»åˆ«ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸ç°æœ‰åŸºçº¿ç›¸æ¯”ï¼Œå®ç°äº†å“è¶Šçš„è§†è§‰çœŸå®æ„Ÿå’Œå¯æ§æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰äº¤äº’è§†é¢‘ç”Ÿæˆæ–¹æ³•çš„ä¸»è¦ç—›ç‚¹åœ¨äºéš¾ä»¥åŒæ—¶å»ºæ¨¡Actorå’ŒObjectä¹‹é—´å¤æ‚çš„åŠ¨æ€äº¤äº’ï¼Œå¹¶ä¸”é€šå¸¸éœ€è¦å¯†é›†çš„Maskæ ‡æ³¨ä½œä¸ºè¾“å…¥ï¼Œè¿™åœ¨å®é™…åº”ç”¨ä¸­è·å–æˆæœ¬é«˜æ˜‚ï¼Œé™åˆ¶äº†æ–¹æ³•çš„å¯ç”¨æ€§ã€‚è¿™äº›æ–¹æ³•éš¾ä»¥çµæ´»æ§åˆ¶äº¤äº’è¿‡ç¨‹ï¼Œä¾‹å¦‚æŒ‡å®šäº¤äº’å¯¹è±¡æˆ–å¼•å¯¼è¿åŠ¨è½¨è¿¹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMask2IVçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†äº¤äº’è§†é¢‘ç”Ÿæˆè¿‡ç¨‹è§£è€¦ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šé¦–å…ˆï¼Œé¢„æµ‹Actorå’ŒObjectçš„è¿åŠ¨è½¨è¿¹ï¼›ç„¶åï¼ŒåŸºäºè¿™äº›è½¨è¿¹ç”Ÿæˆè§†é¢‘ã€‚è¿™ç§è§£è€¦çš„è®¾è®¡ä½¿å¾—æ¨¡å‹å¯ä»¥ç‹¬ç«‹åœ°å­¦ä¹ Actorå’ŒObjectçš„è¿åŠ¨æ¨¡å¼ï¼Œä»è€Œæ›´å¥½åœ°å»ºæ¨¡å¤æ‚çš„äº¤äº’å…³ç³»ã€‚åŒæ—¶ï¼Œé€šè¿‡è½¨è¿¹ä½œä¸ºä¸­é—´è¡¨ç¤ºï¼Œå¯ä»¥é¿å…ç›´æ¥ä¾èµ–å¯†é›†çš„Maskæ ‡æ³¨ï¼Œé™ä½äº†å¯¹è¾“å…¥æ•°æ®çš„è¦æ±‚ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMask2IVæ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šè½¨è¿¹é¢„æµ‹é˜¶æ®µå’Œè§†é¢‘ç”Ÿæˆé˜¶æ®µã€‚åœ¨è½¨è¿¹é¢„æµ‹é˜¶æ®µï¼Œæ¨¡å‹æ¥æ”¶ç”¨æˆ·æŒ‡å®šçš„äº¤äº’å¯¹è±¡å’ŒåŠ¨ä½œæè¿°æˆ–ç©ºé—´ä½ç½®çº¿ç´¢ä½œä¸ºè¾“å…¥ï¼Œé¢„æµ‹Actorå’ŒObjectçš„è¿åŠ¨è½¨è¿¹ã€‚è¿™äº›è½¨è¿¹å¯ä»¥è¡¨ç¤ºä¸ºActorå’ŒObjectåœ¨è§†é¢‘å¸§ä¸­çš„ä½ç½®å’Œå§¿æ€åºåˆ—ã€‚åœ¨è§†é¢‘ç”Ÿæˆé˜¶æ®µï¼Œæ¨¡å‹ä»¥é¢„æµ‹çš„è½¨è¿¹ä½œä¸ºæ¡ä»¶ï¼Œç”Ÿæˆä¸è½¨è¿¹ä¸€è‡´çš„è§†é¢‘ã€‚è¯¥é˜¶æ®µé€šå¸¸é‡‡ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰æˆ–å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEï¼‰ç­‰ç”Ÿæˆæ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šMask2IVçš„å…³é”®åˆ›æ–°åœ¨äºå…¶è§£è€¦çš„ä¸¤é˜¶æ®µæµç¨‹ï¼Œä»¥åŠå¯¹è½¨è¿¹ä½œä¸ºä¸­é—´è¡¨ç¤ºçš„ä½¿ç”¨ã€‚è¿™ç§è®¾è®¡ä½¿å¾—æ¨¡å‹å¯ä»¥ç‹¬ç«‹åœ°å­¦ä¹ Actorå’ŒObjectçš„è¿åŠ¨æ¨¡å¼ï¼Œä»è€Œæ›´å¥½åœ°å»ºæ¨¡å¤æ‚çš„äº¤äº’å…³ç³»ã€‚æ­¤å¤–ï¼Œé€šè¿‡è½¨è¿¹ä½œä¸ºä¸­é—´è¡¨ç¤ºï¼Œå¯ä»¥é¿å…ç›´æ¥ä¾èµ–å¯†é›†çš„Maskæ ‡æ³¨ï¼Œé™ä½äº†å¯¹è¾“å…¥æ•°æ®çš„è¦æ±‚ï¼Œå¹¶æé«˜äº†æ¨¡å‹çš„å¯æ§æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è½¨è¿¹é¢„æµ‹é˜¶æ®µï¼Œå¯ä»¥ä½¿ç”¨å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰æˆ–Transformerç­‰åºåˆ—æ¨¡å‹æ¥é¢„æµ‹è¿åŠ¨è½¨è¿¹ã€‚æŸå¤±å‡½æ•°å¯ä»¥åŒ…æ‹¬è½¨è¿¹é¢„æµ‹è¯¯å·®ã€åŠ¨ä½œä¸€è‡´æ€§æŸå¤±ç­‰ã€‚åœ¨è§†é¢‘ç”Ÿæˆé˜¶æ®µï¼Œå¯ä»¥ä½¿ç”¨3Då·ç§¯ç¥ç»ç½‘ç»œï¼ˆ3D CNNï¼‰æˆ–æ—¶ç©ºå›¾å·ç§¯ç½‘ç»œï¼ˆST-GCNï¼‰ç­‰æ¨¡å‹æ¥ç”Ÿæˆè§†é¢‘ã€‚å…³é”®å‚æ•°åŒ…æ‹¬è½¨è¿¹çš„è¡¨ç¤ºæ–¹å¼ï¼ˆä¾‹å¦‚ï¼Œä½ç½®ã€å§¿æ€ã€é€Ÿåº¦ç­‰ï¼‰ã€ç”Ÿæˆæ¨¡å‹çš„ç½‘ç»œç»“æ„å’ŒæŸå¤±å‡½æ•°ç­‰ã€‚æ•°æ®é›†æ–¹é¢ï¼Œè®ºæ–‡æ„å»ºäº†åŒ…å«äºº-ç‰©äº¤äº’å’Œæœºå™¨äººæ“ä½œåœºæ™¯çš„ä¸¤ä¸ªæ•°æ®é›†ï¼Œç”¨äºè®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒMask2IVåœ¨è§†è§‰çœŸå®æ„Ÿå’Œå¯æ§æ€§æ–¹é¢ä¼˜äºç°æœ‰åŸºçº¿æ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼ŒMask2IVç”Ÿæˆçš„è§†é¢‘åœ¨FIDï¼ˆFrÃ©chet Inception Distanceï¼‰å’Œç”¨æˆ·ç ”ç©¶ç­‰æŒ‡æ ‡ä¸Šå‡å–å¾—äº†æ˜¾è‘—æå‡ã€‚æ­¤å¤–ï¼Œå®éªŒè¿˜éªŒè¯äº†Mask2IVåœ¨ä¸åŒåŠ¨ä½œå’Œå¯¹è±¡ç±»åˆ«ä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Mask2IVåœ¨æœºå™¨äººå­¦ä¹ ã€æ“ä½œç­–ç•¥è®­ç»ƒå’Œå¯ä¾›æ€§æ¨ç†ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥ç”¨äºç”Ÿæˆå¤§é‡é€¼çœŸçš„äº¤äº’è§†é¢‘ï¼Œä¸ºæœºå™¨äººæä¾›ä¸°å¯Œçš„è§†è§‰å…ˆéªŒçŸ¥è¯†ï¼Œå¸®åŠ©æœºå™¨äººæ›´å¥½åœ°ç†è§£å’Œå­¦ä¹ ä¸ç¯å¢ƒçš„äº¤äº’ã€‚æ­¤å¤–ï¼ŒMask2IVè¿˜å¯ä»¥ç”¨äºè™šæ‹Ÿç°å®å’Œæ¸¸æˆç­‰é¢†åŸŸï¼Œç”Ÿæˆæ›´åŠ é€¼çœŸå’Œå¯æ§çš„äº¤äº’åœºæ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Generating interaction-centric videos, such as those depicting humans or robots interacting with objects, is crucial for embodied intelligence, as they provide rich and diverse visual priors for robot learning, manipulation policy training, and affordance reasoning. However, existing methods often struggle to model such complex and dynamic interactions. While recent studies show that masks can serve as effective control signals and enhance generation quality, obtaining dense and precise mask annotations remains a major challenge for real-world use. To overcome this limitation, we introduce Mask2IV, a novel framework specifically designed for interaction-centric video generation. It adopts a decoupled two-stage pipeline that first predicts plausible motion trajectories for both actor and object, then generates a video conditioned on these trajectories. This design eliminates the need for dense mask inputs from users while preserving the flexibility to manipulate the interaction process. Furthermore, Mask2IV supports versatile and intuitive control, allowing users to specify the target object of interaction and guide the motion trajectory through action descriptions or spatial position cues. To support systematic training and evaluation, we curate two benchmarks covering diverse action and object categories across both human-object interaction and robotic manipulation scenarios. Extensive experiments demonstrate that our method achieves superior visual realism and controllability compared to existing baselines.

