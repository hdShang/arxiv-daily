---
layout: default
title: STORM: Segment, Track, and Object Re-Localization from a Single Image
---

# STORM: Segment, Track, and Object Re-Localization from a Single Image

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.09771" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.09771v2</a>
  <a href="https://arxiv.org/pdf/2511.09771.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.09771v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.09771v2', 'STORM: Segment, Track, and Object Re-Localization from a Single Image')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yu Deng, Teng Cao, Hikaru Shindo, Jiahong Xue, Quentin Delfosse, Kristian Kersting

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-12 (æ›´æ–°: 2025-12-01)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSTORMï¼Œæ— éœ€äººå·¥æ ‡æ³¨ï¼Œå®ç°å•å›¾åƒçš„ç‰©ä½“åˆ†å‰²ã€è·Ÿè¸ªå’Œé‡å®šä½ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)** **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction & Matching)**

**å…³é”®è¯**: `6Dä½å§¿ä¼°è®¡` `ç‰©ä½“åˆ†å‰²` `ç‰©ä½“è·Ÿè¸ª` `è§†è§‰è¯­è¨€ç†è§£` `ç‰¹å¾åŒ¹é…`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰6Dä½å§¿ä¼°è®¡æ–¹æ³•é€šå¸¸éœ€è¦é¢„å®šä¹‰çš„3Dæ¨¡å‹å’Œé¦–å¸§æ‰‹åŠ¨æ ‡æ³¨çš„åˆ†å‰²æ©ç ï¼Œè¿™è€—æ—¶è´¹åŠ›ï¼Œä¸”åœ¨é®æŒ¡æˆ–å¿«é€Ÿè¿åŠ¨ä¸‹æ€§èƒ½ä¸‹é™ã€‚
2. STORMç»“åˆè§†è§‰-è¯­è¨€ç†è§£å’Œç‰¹å¾åŒ¹é…ï¼Œåˆ©ç”¨ä¸Šä¸‹æ–‡å¯¹è±¡æè¿°å¼•å¯¼å®šä½ï¼Œè‡ª-äº¤å‰æ³¨æ„åŠ›æœºåˆ¶è¯†åˆ«åŒºåŸŸï¼Œå¹¶ç”Ÿæˆç²¾ç¡®æ©ç å’Œ3Dæ¨¡å‹ã€‚
3. STORMåœ¨å·¥ä¸šæ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„ç²¾åº¦ï¼Œå¹¶å…·æœ‰å®æ—¶æ€§ï¼Œæ— éœ€é¢å¤–è®­ç»ƒï¼Œä¸”å…·å¤‡è‡ªåŠ¨é‡æ³¨å†Œæœºåˆ¶ä»¥åº”å¯¹è·Ÿè¸ªå¤±è´¥ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºSTORMï¼ˆSegment, Track, and Object Re-localization from a single iMageï¼‰ï¼Œä¸€ä¸ªå¼€æºçš„ã€é²æ£’çš„å®æ—¶6Dä½å§¿ä¼°è®¡ç³»ç»Ÿï¼Œæ— éœ€äººå·¥æ ‡æ³¨ã€‚STORMé‡‡ç”¨äº†ä¸€ç§æ–°é¢–çš„ä¸‰é˜¶æ®µæµç¨‹ï¼Œç»“åˆäº†è§†è§‰-è¯­è¨€ç†è§£ä¸ç‰¹å¾åŒ¹é…ï¼šä¸Šä¸‹æ–‡å¯¹è±¡æè¿°å¼•å¯¼å®šä½ï¼Œè‡ª-äº¤å‰æ³¨æ„åŠ›æœºåˆ¶è¯†åˆ«å€™é€‰åŒºåŸŸï¼Œå¹¶ç”Ÿæˆç²¾ç¡®çš„æ©ç å’Œ3Dæ¨¡å‹ä»¥è¿›è¡Œå‡†ç¡®çš„ä½å§¿ä¼°è®¡ã€‚å¦ä¸€ä¸ªå…³é”®åˆ›æ–°æ˜¯è‡ªåŠ¨é‡æ³¨å†Œæœºåˆ¶ï¼Œé€šè¿‡ç‰¹å¾ç›¸ä¼¼æ€§ç›‘æ§æ£€æµ‹è·Ÿè¸ªå¤±è´¥ï¼Œå¹¶ä»ä¸¥é‡çš„é®æŒ¡æˆ–å¿«é€Ÿè¿åŠ¨ä¸­æ¢å¤ã€‚STORMåœ¨å…·æœ‰å¤šå¯¹è±¡é®æŒ¡ã€é«˜é€Ÿè¿åŠ¨å’Œå˜åŒ–å…‰ç…§ç­‰æŒ‘æˆ˜æ€§å·¥ä¸šæ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„ç²¾åº¦ï¼ŒåŒæ—¶ä»¥å®æ—¶é€Ÿåº¦è¿è¡Œï¼Œæ— éœ€é¢å¤–è®­ç»ƒã€‚è¿™ç§æ— æ ‡æ³¨æ–¹æ³•æ˜¾è‘—é™ä½äº†éƒ¨ç½²å¼€é”€ï¼Œä¸ºæŸ”æ€§åˆ¶é€ å’Œæ™ºèƒ½è´¨é‡æ§åˆ¶ç­‰ç°ä»£åº”ç”¨æä¾›äº†å®ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰6Dä½å§¿ä¼°è®¡æ–¹æ³•ä¾èµ–äºé¢„å®šä¹‰çš„3Dæ¨¡å‹å’Œäººå·¥æ ‡æ³¨çš„åˆ†å‰²æ©ç ï¼Œè¿™é™åˆ¶äº†å…¶åœ¨å®é™…å·¥ä¸šåœºæ™¯ä¸­çš„åº”ç”¨ã€‚äººå·¥æ ‡æ³¨æˆæœ¬é«˜æ˜‚ï¼Œä¸”å½“ç‰©ä½“å‘ç”Ÿé®æŒ¡æˆ–å¿«é€Ÿè¿åŠ¨æ—¶ï¼ŒåŸºäºäººå·¥æ ‡æ³¨çš„æ–¹æ³•å®¹æ˜“å¤±æ•ˆï¼Œå¯¼è‡´ä½å§¿ä¼°è®¡ç²¾åº¦ä¸‹é™ã€‚å› æ­¤ï¼Œå¦‚ä½•åœ¨æ— éœ€äººå·¥æ ‡æ³¨çš„æƒ…å†µä¸‹ï¼Œå®ç°é²æ£’ä¸”å®æ—¶çš„6Dä½å§¿ä¼°è®¡æ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSTORMçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è§†è§‰-è¯­è¨€ç†è§£èƒ½åŠ›ï¼Œç»“åˆç‰¹å¾åŒ¹é…ï¼Œå®ç°æ— éœ€äººå·¥æ ‡æ³¨çš„ç‰©ä½“åˆ†å‰²ã€è·Ÿè¸ªå’Œé‡å®šä½ã€‚é€šè¿‡ä¸Šä¸‹æ–‡å¯¹è±¡æè¿°å¼•å¯¼å®šä½ï¼Œåˆ©ç”¨è‡ª-äº¤å‰æ³¨æ„åŠ›æœºåˆ¶è¯†åˆ«å€™é€‰åŒºåŸŸï¼Œå¹¶ç”Ÿæˆç²¾ç¡®çš„æ©ç å’Œ3Dæ¨¡å‹ï¼Œä»è€Œå®ç°å‡†ç¡®çš„ä½å§¿ä¼°è®¡ã€‚æ­¤å¤–ï¼ŒSTORMè¿˜å¼•å…¥äº†è‡ªåŠ¨é‡æ³¨å†Œæœºåˆ¶ï¼Œä»¥åº”å¯¹è·Ÿè¸ªå¤±è´¥çš„æƒ…å†µã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSTORMé‡‡ç”¨ä¸‰é˜¶æ®µæµç¨‹ï¼š1) ä¸Šä¸‹æ–‡å¯¹è±¡æè¿°å¼•å¯¼å®šä½ï¼šåˆ©ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹ç†è§£åœºæ™¯ä¸­çš„ç‰©ä½“ï¼Œå¹¶æ ¹æ®ä¸Šä¸‹æ–‡ä¿¡æ¯åˆæ­¥å®šä½ç›®æ ‡ç‰©ä½“ã€‚2) è‡ª-äº¤å‰æ³¨æ„åŠ›æœºåˆ¶è¯†åˆ«å€™é€‰åŒºåŸŸï¼šåˆ©ç”¨è‡ª-äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œåœ¨å›¾åƒä¸­è¯†åˆ«å‡ºå¯èƒ½åŒ…å«ç›®æ ‡ç‰©ä½“çš„å€™é€‰åŒºåŸŸã€‚3) ç²¾ç¡®æ©ç å’Œ3Dæ¨¡å‹ç”Ÿæˆï¼šå¯¹å€™é€‰åŒºåŸŸè¿›è¡Œåˆ†å‰²ï¼Œç”Ÿæˆç²¾ç¡®çš„æ©ç ï¼Œå¹¶åˆ©ç”¨æ©ç å’Œå›¾åƒä¿¡æ¯ç”Ÿæˆ3Dæ¨¡å‹ï¼Œç”¨äºä½å§¿ä¼°è®¡ã€‚æ­¤å¤–ï¼Œç³»ç»Ÿè¿˜åŒ…å«ä¸€ä¸ªè‡ªåŠ¨é‡æ³¨å†Œæ¨¡å—ï¼Œç”¨äºæ£€æµ‹è·Ÿè¸ªå¤±è´¥å¹¶è¿›è¡Œæ¢å¤ã€‚

**å…³é”®åˆ›æ–°**ï¼šSTORMçš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æ— éœ€äººå·¥æ ‡æ³¨ï¼šé€šè¿‡è§†è§‰-è¯­è¨€ç†è§£å’Œç‰¹å¾åŒ¹é…ï¼Œå®ç°äº†æ— éœ€äººå·¥æ ‡æ³¨çš„ç‰©ä½“åˆ†å‰²ã€è·Ÿè¸ªå’Œé‡å®šä½ã€‚2) è‡ªåŠ¨é‡æ³¨å†Œæœºåˆ¶ï¼šé€šè¿‡ç‰¹å¾ç›¸ä¼¼æ€§ç›‘æ§æ£€æµ‹è·Ÿè¸ªå¤±è´¥ï¼Œå¹¶ä»ä¸¥é‡çš„é®æŒ¡æˆ–å¿«é€Ÿè¿åŠ¨ä¸­æ¢å¤ã€‚3) ä¸‰é˜¶æ®µæµç¨‹ï¼šç»“åˆä¸Šä¸‹æ–‡ä¿¡æ¯ã€æ³¨æ„åŠ›æœºåˆ¶å’Œ3Dæ¨¡å‹ç”Ÿæˆï¼Œå®ç°äº†å‡†ç¡®ä¸”é²æ£’çš„ä½å§¿ä¼°è®¡ã€‚

**å…³é”®è®¾è®¡**ï¼šSTORMçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) è§†è§‰-è¯­è¨€æ¨¡å‹çš„é€‰æ‹©å’Œè®­ç»ƒï¼šé€‰æ‹©åˆé€‚çš„è§†è§‰-è¯­è¨€æ¨¡å‹ï¼Œå¹¶é’ˆå¯¹ç‰¹å®šåœºæ™¯è¿›è¡Œå¾®è°ƒï¼Œä»¥æé«˜ç‰©ä½“è¯†åˆ«å’Œå®šä½çš„å‡†ç¡®æ€§ã€‚2) è‡ª-äº¤å‰æ³¨æ„åŠ›æœºåˆ¶çš„è®¾è®¡ï¼šè®¾è®¡æœ‰æ•ˆçš„è‡ª-äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œä»¥å‡†ç¡®è¯†åˆ«å€™é€‰åŒºåŸŸã€‚3) æŸå¤±å‡½æ•°çš„è®¾è®¡ï¼šè®¾è®¡åˆé€‚çš„æŸå¤±å‡½æ•°ï¼Œç”¨äºè®­ç»ƒåˆ†å‰²ç½‘ç»œå’Œ3Dæ¨¡å‹ç”Ÿæˆç½‘ç»œï¼Œä»¥æé«˜åˆ†å‰²å’Œ3Dæ¨¡å‹ç”Ÿæˆçš„ç²¾åº¦ã€‚4) ç‰¹å¾ç›¸ä¼¼æ€§ç›‘æ§çš„é˜ˆå€¼è®¾ç½®ï¼šè®¾ç½®åˆé€‚çš„ç‰¹å¾ç›¸ä¼¼æ€§ç›‘æ§é˜ˆå€¼ï¼Œä»¥å‡†ç¡®æ£€æµ‹è·Ÿè¸ªå¤±è´¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

STORMåœ¨å…·æœ‰å¤šå¯¹è±¡é®æŒ¡ã€é«˜é€Ÿè¿åŠ¨å’Œå˜åŒ–å…‰ç…§ç­‰æŒ‘æˆ˜æ€§å·¥ä¸šæ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„ç²¾åº¦ï¼ŒåŒæ—¶ä»¥å®æ—¶é€Ÿåº¦è¿è¡Œï¼Œæ— éœ€é¢å¤–è®­ç»ƒã€‚å…·ä½“æ€§èƒ½æ•°æ®æœªçŸ¥ï¼Œä½†è®ºæ–‡å¼ºè°ƒå…¶åœ¨å¤æ‚åœºæ™¯ä¸‹çš„é²æ£’æ€§å’Œå®æ—¶æ€§ï¼Œä»¥åŠæ— éœ€äººå·¥æ ‡æ³¨çš„ä¼˜åŠ¿ï¼Œä½¿å…¶åœ¨å®é™…åº”ç”¨ä¸­å…·æœ‰æ›´é«˜çš„ä»·å€¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

STORMå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå°¤å…¶æ˜¯åœ¨æŸ”æ€§åˆ¶é€ å’Œæ™ºèƒ½è´¨é‡æ§åˆ¶ç­‰é¢†åŸŸã€‚å®ƒå¯ä»¥ç”¨äºæœºå™¨äººæŠ“å–ã€è£…é…ã€æ£€æµ‹ç­‰ä»»åŠ¡ï¼Œæé«˜ç”Ÿäº§æ•ˆç‡å’Œè‡ªåŠ¨åŒ–æ°´å¹³ã€‚æ­¤å¤–ï¼ŒSTORMè¿˜å¯ä»¥åº”ç”¨äºå¢å¼ºç°å®ã€è™šæ‹Ÿç°å®ç­‰é¢†åŸŸï¼Œä¸ºç”¨æˆ·æä¾›æ›´è‡ªç„¶ã€æ›´çœŸå®çš„äº¤äº’ä½“éªŒã€‚æœªæ¥ï¼ŒSTORMæœ‰æœ›æˆä¸ºç‰©ç†AIç³»ç»Ÿçš„æ ¸å¿ƒç»„æˆéƒ¨åˆ†ï¼Œæ¨åŠ¨äººå·¥æ™ºèƒ½æŠ€æœ¯åœ¨å·¥ä¸šé¢†åŸŸçš„å¹¿æ³›åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Accurate 6D pose estimation and tracking are fundamental capabilities for physical AI systems such as robots. However, existing approaches typically require a pre-defined 3D model of the target and rely on a manually annotated segmentation mask in the first frame, which is labor-intensive and leads to reduced performance when faced with occlusions or rapid movement. To address these limitations, we propose STORM (Segment, Track, and Object Re-localization from a single iMage), an open-source robust real-time 6D pose estimation system that requires no manual annotation. STORM employs a novel three-stage pipeline combining vision-language understanding with feature matching: contextual object descriptions guide localization, self-cross-attention mechanisms identify candidate regions, and produce precise masks and 3D models for accurate pose estimation. Another key innovation is our automatic re-registration mechanism that detects tracking failures through feature similarity monitoring and recovers from severe occlusions or rapid motion. STORM achieves state-of-the-art accuracy on challenging industrial datasets featuring multi-object occlusions, high-speed motion, and varying illumination, while operating at real-time speeds without additional training. This annotation-free approach significantly reduces deployment overhead, providing a practical solution for modern applications, such as flexible manufacturing and intelligent quality control.

