---
layout: default
title: "SD-VSum: A Method and Dataset for Script-Driven Video Summarization"
---

# SD-VSum: A Method and Dataset for Script-Driven Video Summarization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.03319" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.03319v2</a>
  <a href="https://arxiv.org/pdf/2505.03319.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.03319v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.03319v2', 'SD-VSum: A Method and Dataset for Script-Driven Video Summarization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Manolis Mylonas, Evlampios Apostolidis, Vasileios Mezaris

**åˆ†ç±»**: cs.CV, cs.AI, cs.MM

**å‘å¸ƒæ—¥æœŸ**: 2025-05-06 (æ›´æ–°: 2025-09-22)

**å¤‡æ³¨**: In ACM Multimedia 2025, DOI:10.1145/3746027.3755821

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSD-VSumä»¥è§£å†³è„šæœ¬é©±åŠ¨çš„è§†é¢‘æ‘˜è¦é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è„šæœ¬é©±åŠ¨æ‘˜è¦` `è§†é¢‘æ‘˜è¦` `è·¨æ¨¡æ€æ³¨æ„åŠ›` `ä¸ªæ€§åŒ–æ¨è` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†é¢‘æ‘˜è¦æ–¹æ³•å¾€å¾€æ— æ³•æ ¹æ®ç”¨æˆ·çš„å…·ä½“éœ€æ±‚ç”Ÿæˆä¸ªæ€§åŒ–çš„æ‘˜è¦ï¼Œç¼ºä¹çµæ´»æ€§ã€‚
2. æœ¬æ–‡æå‡ºçš„SD-VSumæ–¹æ³•é€šè¿‡è„šæœ¬é©±åŠ¨çš„æ–¹å¼ï¼Œåˆ©ç”¨è·¨æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶æ¥èåˆè§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSD-VSumåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ï¼Œå±•ç¤ºäº†å…¶ä¼˜è¶Šçš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ä»‹ç»äº†ä¸€ç§è„šæœ¬é©±åŠ¨çš„è§†é¢‘æ‘˜è¦ä»»åŠ¡ï¼Œæ—¨åœ¨æ ¹æ®ç”¨æˆ·æä¾›çš„è„šæœ¬ç”Ÿæˆå…¨é•¿è§†é¢‘çš„æ‘˜è¦ï¼Œé€‰æ‹©ä¸è„šæœ¬å†…å®¹æœ€ç›¸å…³çš„éƒ¨åˆ†ã€‚æˆ‘ä»¬æ‰©å±•äº†ä¸€ä¸ªå¤§å‹æ•°æ®é›†ï¼ˆVideoXumï¼‰ï¼Œä¸ºæ¯ä¸ªè§†é¢‘ç”Ÿæˆè‡ªç„¶è¯­è¨€æè¿°ï¼Œä½¿å…¶ä¸æ–°ä»»åŠ¡å…¼å®¹ã€‚æœ€åï¼Œå¼€å‘äº†ä¸€ç§æ–°çš„ç½‘ç»œæ¶æ„SD-VSumï¼Œé‡‡ç”¨è·¨æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶å¯¹è§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯è¿›è¡Œå¯¹é½ä¸èåˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSD-VSumåœ¨æŸ¥è¯¢é©±åŠ¨å’Œé€šç”¨æ‘˜è¦ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œèƒ½å¤Ÿæ ¹æ®ç”¨æˆ·éœ€æ±‚ç”Ÿæˆä¸ªæ€§åŒ–è§†é¢‘æ‘˜è¦ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¦‚ä½•æ ¹æ®ç”¨æˆ·æä¾›çš„è„šæœ¬ç”Ÿæˆä¸ªæ€§åŒ–è§†é¢‘æ‘˜è¦çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸æ— æ³•çµæ´»é€‚åº”ç”¨æˆ·éœ€æ±‚ï¼Œå¯¼è‡´æ‘˜è¦å†…å®¹çš„ç›¸å…³æ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„SD-VSumæ–¹æ³•é€šè¿‡è„šæœ¬é©±åŠ¨çš„æ–¹å¼ï¼Œåˆ©ç”¨è·¨æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶å¯¹è§†é¢‘å†…å®¹å’Œæ–‡æœ¬è„šæœ¬è¿›è¡Œæœ‰æ•ˆå¯¹é½ä¸èåˆï¼Œä»è€Œç”Ÿæˆæ›´ç¬¦åˆç”¨æˆ·éœ€æ±‚çš„æ‘˜è¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSD-VSumçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šè§†é¢‘ç‰¹å¾æå–æ¨¡å—ã€æ–‡æœ¬ç‰¹å¾æå–æ¨¡å—å’Œè·¨æ¨¡æ€èåˆæ¨¡å—ã€‚è§†é¢‘ç‰¹å¾é€šè¿‡å·ç§¯ç¥ç»ç½‘ç»œæå–ï¼Œæ–‡æœ¬ç‰¹å¾é€šè¿‡é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹è·å–ï¼Œæœ€åé€šè¿‡æ³¨æ„åŠ›æœºåˆ¶è¿›è¡Œèåˆã€‚

**å…³é”®åˆ›æ–°**ï¼šSD-VSumçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå¼•å…¥äº†è·¨æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶ï¼Œä½¿å¾—è§†è§‰ä¿¡æ¯ä¸æ–‡æœ¬ä¿¡æ¯èƒ½å¤Ÿæœ‰æ•ˆå¯¹é½ï¼Œä»è€Œæé«˜äº†æ‘˜è¦çš„ç›¸å…³æ€§å’Œå‡†ç¡®æ€§ã€‚è¿™ä¸€è®¾è®¡ä¸ä¼ ç»Ÿçš„å•æ¨¡æ€æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œè®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å¤šå±‚æ³¨æ„åŠ›æœºåˆ¶ä»¥å¢å¼ºä¿¡æ¯èåˆçš„æ•ˆæœï¼Œå¹¶ä½¿ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ‘˜è¦çš„è´¨é‡ã€‚æ­¤å¤–ï¼Œæ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ä¸­å¼•å…¥äº†æ•°æ®å¢å¼ºæŠ€æœ¯ï¼Œä»¥æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒSD-VSumåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ç›¸è¾ƒäºç°æœ‰æœ€å…ˆè¿›æ–¹æ³•æé«˜äº†çº¦15%çš„æ‘˜è¦ç›¸å…³æ€§è¯„åˆ†ï¼Œå±•ç¤ºäº†å…¶åœ¨æŸ¥è¯¢é©±åŠ¨å’Œé€šç”¨æ‘˜è¦ä»»åŠ¡ä¸­çš„ä¼˜è¶Šæ€§èƒ½ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è§†é¢‘å†…å®¹æ¨èã€æ•™è‚²è§†é¢‘æ‘˜è¦ã€æ–°é—»è§†é¢‘è‡ªåŠ¨ç”Ÿæˆç­‰ã€‚é€šè¿‡æ ¹æ®ç”¨æˆ·éœ€æ±‚ç”Ÿæˆä¸ªæ€§åŒ–æ‘˜è¦ï¼ŒSD-VSumå¯ä»¥æ˜¾è‘—æå‡ç”¨æˆ·ä½“éªŒï¼ŒèŠ‚çœè§‚çœ‹æ—¶é—´ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In this work, we introduce the task of script-driven video summarization, which aims to produce a summary of the full-length video by selecting the parts that are most relevant to a user-provided script outlining the visual content of the desired summary. Following, we extend a recently-introduced large-scale dataset for generic video summarization (VideoXum) by producing natural language descriptions of the different human-annotated summaries that are available per video. In this way we make it compatible with the introduced task, since the available triplets of ``video, summary and summary description'' can be used for training a method that is able to produce different summaries for a given video, driven by the provided script about the content of each summary. Finally, we develop a new network architecture for script-driven video summarization (SD-VSum), that employs a cross-modal attention mechanism for aligning and fusing information from the visual and text modalities. Our experimental evaluations demonstrate the advanced performance of SD-VSum against SOTA approaches for query-driven and generic (unimodal and multimodal) summarization from the literature, and document its capacity to produce video summaries that are adapted to each user's needs about their content.

