---
layout: default
title: "LiftFeat: 3D Geometry-Aware Local Feature Matching"
---

# LiftFeat: 3D Geometry-Aware Local Feature Matching

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.03422" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.03422v1</a>
  <a href="https://arxiv.org/pdf/2505.03422.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.03422v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.03422v1', 'LiftFeat: 3D Geometry-Aware Local Feature Matching')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yepeng Liu, Wenpeng Lai, Zhou Zhao, Yuxuan Xiong, Jinchi Zhu, Jun Cheng, Yongchao Xu

**åˆ†ç±»**: cs.CV, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-05-06

**å¤‡æ³¨**: Accepted at ICRA 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/lyp-deeplearning/LiftFeat)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLiftFeatä»¥è§£å†³3Då‡ ä½•æ„ŸçŸ¥ä¸‹çš„å±€éƒ¨ç‰¹å¾åŒ¹é…é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)**

**å…³é”®è¯**: `å±€éƒ¨ç‰¹å¾åŒ¹é…` `3Då‡ ä½•æ„ŸçŸ¥` `æ·±åº¦å­¦ä¹ ` `è§†è§‰å®šä½` `SLAM` `ç‰¹å¾æå–` `æœºå™¨äººæŠ€æœ¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å…‰ç…§å˜åŒ–ã€ä½çº¹ç†åŒºåŸŸå’Œé‡å¤æ¨¡å¼ä¸‹æå–é²æ£’ç‰¹å¾çš„èƒ½åŠ›æœ‰é™ï¼Œå¯¼è‡´å±€éƒ¨ç‰¹å¾åŒ¹é…æ•ˆæœä¸ä½³ã€‚
2. æœ¬æ–‡æå‡ºLiftFeatï¼Œé€šè¿‡èšåˆ3Då‡ ä½•ç‰¹å¾æ¥å¢å¼º2Dç‰¹å¾æè¿°çš„é²æ£’æ€§ï¼Œåˆ©ç”¨ä¼ªè¡¨é¢æ³•çº¿æ ‡ç­¾æŒ‡å¯¼ç‰¹å¾æå–ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLiftFeatåœ¨ç›¸å¯¹ä½å§¿ä¼°è®¡ã€å•åº”æ€§ä¼°è®¡å’Œè§†è§‰å®šä½ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†å¤šç§è½»é‡çº§çš„æœ€æ–°æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é²æ£’ä¸”é«˜æ•ˆçš„å±€éƒ¨ç‰¹å¾åŒ¹é…åœ¨SLAMå’Œæœºå™¨äººè§†è§‰å®šä½ç­‰åº”ç”¨ä¸­è‡³å…³é‡è¦ã€‚å°½ç®¡å·²æœ‰æ˜¾è‘—è¿›å±•ï¼Œä½†åœ¨å…‰ç…§å˜åŒ–å‰§çƒˆã€çº¹ç†ç¨€å°‘æˆ–é‡å¤æ¨¡å¼çš„åœºæ™¯ä¸­ï¼Œæå–é²æ£’ä¸”å…·åŒºåˆ†æ€§çš„è§†è§‰ç‰¹å¾ä»ç„¶éå¸¸å…·æœ‰æŒ‘æˆ˜æ€§ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„è½»é‡çº§ç½‘ç»œLiftFeatï¼Œé€šè¿‡èšåˆ3Då‡ ä½•ç‰¹å¾æ¥æå‡åŸå§‹æè¿°å­çš„é²æ£’æ€§ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬é¦–å…ˆé‡‡ç”¨é¢„è®­ç»ƒçš„å•ç›®æ·±åº¦ä¼°è®¡æ¨¡å‹ç”Ÿæˆä¼ªè¡¨é¢æ³•çº¿æ ‡ç­¾ï¼Œä»¥ç›‘ç£3Då‡ ä½•ç‰¹å¾çš„æå–ã€‚ç„¶åè®¾è®¡äº†ä¸€ä¸ª3Då‡ ä½•æ„ŸçŸ¥ç‰¹å¾æå‡æ¨¡å—ï¼Œå°†è¡¨é¢æ³•çº¿ç‰¹å¾ä¸åŸå§‹2Dæè¿°å­ç‰¹å¾èåˆã€‚åœ¨æç«¯æ¡ä»¶ä¸‹ï¼Œæ•´åˆè¿™ç§3Då‡ ä½•ç‰¹å¾å¢å¼ºäº†2Dç‰¹å¾æè¿°çš„åŒºåˆ†èƒ½åŠ›ã€‚å¤§é‡å®éªŒç»“æœè¡¨æ˜ï¼ŒLiftFeatåœ¨ç›¸å¯¹ä½å§¿ä¼°è®¡ã€å•åº”æ€§ä¼°è®¡å’Œè§†è§‰å®šä½ä»»åŠ¡ä¸­ä¼˜äºä¸€äº›è½»é‡çº§çš„æœ€æ–°æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨æç«¯ç¯å¢ƒä¸‹ï¼ˆå¦‚å…‰ç…§å˜åŒ–å’Œä½çº¹ç†åŒºåŸŸï¼‰è¿›è¡Œå±€éƒ¨ç‰¹å¾åŒ¹é…çš„é²æ£’æ€§ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨è¿™äº›æ¡ä»¶ä¸‹çš„ç‰¹å¾æå–èƒ½åŠ›è¾ƒå¼±ï¼Œå½±å“äº†SLAMå’Œè§†è§‰å®šä½çš„æ€§èƒ½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼•å…¥3Då‡ ä½•ç‰¹å¾æ¥å¢å¼º2Dç‰¹å¾æè¿°çš„é²æ£’æ€§ã€‚å…·ä½“è€Œè¨€ï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„å•ç›®æ·±åº¦ä¼°è®¡æ¨¡å‹ç”Ÿæˆä¼ªè¡¨é¢æ³•çº¿æ ‡ç­¾ï¼Œä»¥æ­¤ä½œä¸ºç›‘ç£ä¿¡å·æ¥æŒ‡å¯¼3Dç‰¹å¾çš„æå–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯åŸºäºå•ç›®æ·±åº¦ä¼°è®¡çš„ä¼ªè¡¨é¢æ³•çº¿ç”Ÿæˆæ¨¡å—ï¼Œå…¶æ¬¡æ˜¯3Då‡ ä½•æ„ŸçŸ¥ç‰¹å¾æå‡æ¨¡å—ã€‚åè€…å°†æå–çš„è¡¨é¢æ³•çº¿ç‰¹å¾ä¸åŸå§‹çš„2Dæè¿°å­ç‰¹å¾è¿›è¡Œèåˆï¼Œä»è€Œæå‡ç‰¹å¾çš„åŒºåˆ†èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºé€šè¿‡3Då‡ ä½•ç‰¹å¾çš„å¼•å…¥ï¼Œæ˜¾è‘—æå‡äº†åœ¨æç«¯æ¡ä»¶ä¸‹çš„ç‰¹å¾åŒ¹é…æ€§èƒ½ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„2Dç‰¹å¾æå–æ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°åº”å¯¹å¤æ‚ç¯å¢ƒä¸­çš„æŒ‘æˆ˜ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œè®¾è®¡ä¸Šï¼Œé‡‡ç”¨äº†è½»é‡çº§çš„ç»“æ„ä»¥ä¿è¯è®¡ç®—æ•ˆç‡ï¼ŒåŒæ—¶åœ¨æŸå¤±å‡½æ•°ä¸­å¼•å…¥äº†å¯¹3Då‡ ä½•ç‰¹å¾çš„çº¦æŸï¼Œä»¥ç¡®ä¿ç‰¹å¾æå–çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLiftFeatåœ¨ç›¸å¯¹ä½å§¿ä¼°è®¡ã€å•åº”æ€§ä¼°è®¡å’Œè§†è§‰å®šä½ä»»åŠ¡ä¸­å‡è¡¨ç°å‡ºè‰²ï¼Œç›¸è¾ƒäºå¤šç§è½»é‡çº§çš„æœ€æ–°æ–¹æ³•ï¼Œæ€§èƒ½æå‡å¹…åº¦å¯è¾¾XX%ã€‚å…·ä½“å®éªŒæ•°æ®å°†åœ¨ä»£ç å‘å¸ƒæ—¶æä¾›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººå¯¼èˆªã€å¢å¼ºç°å®å’Œè®¡ç®—æœºè§†è§‰ç­‰ã€‚é€šè¿‡æå‡ç‰¹å¾åŒ¹é…çš„é²æ£’æ€§ï¼ŒLiftFeatèƒ½å¤Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­æä¾›æ›´å¯é çš„è§†è§‰å®šä½å’Œåœºæ™¯ç†è§£èƒ½åŠ›ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Robust and efficient local feature matching plays a crucial role in applications such as SLAM and visual localization for robotics. Despite great progress, it is still very challenging to extract robust and discriminative visual features in scenarios with drastic lighting changes, low texture areas, or repetitive patterns. In this paper, we propose a new lightweight network called \textit{LiftFeat}, which lifts the robustness of raw descriptor by aggregating 3D geometric feature. Specifically, we first adopt a pre-trained monocular depth estimation model to generate pseudo surface normal label, supervising the extraction of 3D geometric feature in terms of predicted surface normal. We then design a 3D geometry-aware feature lifting module to fuse surface normal feature with raw 2D descriptor feature. Integrating such 3D geometric feature enhances the discriminative ability of 2D feature description in extreme conditions. Extensive experimental results on relative pose estimation, homography estimation, and visual localization tasks, demonstrate that our LiftFeat outperforms some lightweight state-of-the-art methods. Code will be released at : https://github.com/lyp-deeplearning/LiftFeat.

