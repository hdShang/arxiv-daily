---
layout: default
title: "seq-JEPA: Autoregressive Predictive Learning of Invariant-Equivariant World Models"
---

# seq-JEPA: Autoregressive Predictive Learning of Invariant-Equivariant World Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.03176" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.03176v2</a>
  <a href="https://arxiv.org/pdf/2505.03176.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.03176v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.03176v2', 'seq-JEPA: Autoregressive Predictive Learning of Invariant-Equivariant World Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hafez Ghaemi, Eilif Muller, Shahab Bakhtiari

**åˆ†ç±»**: cs.CV, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-06 (æ›´æ–°: 2025-05-22)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºseq-JEPAä»¥è§£å†³è‡ªç›‘ç£å­¦ä¹ ä¸­çš„è¡¨ç¤ºçµæ´»æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è‡ªç›‘ç£å­¦ä¹ ` `è§†è§‰è¡¨ç¤º` `ç­‰å˜æ€§` `ä¸å˜æ€§` `Transformer` `åºåˆ—å»ºæ¨¡` `è·¯å¾„æ•´åˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•åœ¨å­¦ä¹ è§†è§‰è¡¨ç¤ºæ—¶ï¼Œå¾€å¾€é¢ä¸´é«˜å±‚ä¸å˜æ€§ä¸ç»†ç²’åº¦ç­‰å˜æ€§ä»»åŠ¡ä¹‹é—´çš„æ€§èƒ½æƒè¡¡é—®é¢˜ã€‚
2. æœ¬æ–‡æå‡ºçš„seq-JEPAæ¡†æ¶é€šè¿‡å¼•å…¥æ¶æ„å½’çº³åç½®ï¼Œèƒ½å¤ŸåŒæ—¶å­¦ä¹ å¯¹å˜æ¢ç­‰å˜å’Œä¸å˜çš„è¡¨ç¤ºï¼Œé¿å…äº†åŒé‡é¢„æµ‹å™¨çš„ä¾èµ–ã€‚
3. å®éªŒè¯æ˜ï¼Œseq-JEPAåœ¨ç­‰å˜å’Œä¸å˜åŸºå‡†ä¸Šå‡è¡¨ç°ä¼˜å¼‚ï¼Œä¸”åœ¨è·¯å¾„æ•´åˆå’Œé¢„æµ‹å­¦ä¹ ç­‰ä»»åŠ¡ä¸­å±•ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å½“å‰çš„è‡ªç›‘ç£ç®—æ³•é€šå¸¸ä¾èµ–äºæ•°æ®å¢å¼ºå’Œæ©è”½ç­‰å˜æ¢æ¥å­¦ä¹ è§†è§‰è¡¨ç¤ºã€‚è¿™äº›æ–¹æ³•é€šè¿‡å¯¹å›¾åƒçš„ä¸¤ä¸ªè§†å›¾æ–½åŠ ä¸å˜æ€§æˆ–ç­‰å˜æ€§æ¥å®ç°ã€‚ç„¶è€Œï¼Œè¿™ç§ä¸»æµçš„åŒè§†å›¾èŒƒå¼é™åˆ¶äº†æ‰€å­¦è¡¨ç¤ºåœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­çš„çµæ´»æ€§ï¼Œå¯¼è‡´é«˜å±‚ä¸å˜æ€§ä»»åŠ¡ä¸ç»†ç²’åº¦ç­‰å˜æ€§ä»»åŠ¡ä¹‹é—´çš„æ€§èƒ½æƒè¡¡ã€‚æœ¬æ–‡æå‡ºäº†seq-JEPAï¼Œä¸€ä¸ªä¸–ç•Œå»ºæ¨¡æ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥æ¶æ„å½’çº³åç½®åˆ°è”åˆåµŒå…¥é¢„æµ‹æ¶æ„ä¸­ï¼Œè§£å†³äº†è¿™ä¸€æƒè¡¡é—®é¢˜ã€‚seq-JEPAåŒæ—¶å­¦ä¹ äº†ä¸¤ä¸ªæ¶æ„ä¸Šåˆ†éš”çš„è¡¨ç¤ºï¼šä¸€ä¸ªå¯¹æŒ‡å®šå˜æ¢ç­‰å˜ï¼Œå¦ä¸€ä¸ªå¯¹å…¶ä¸å˜ã€‚è¯¥æ¨¡å‹å¤„ç†ä¸åŒè§†å›¾çš„çŸ­åºåˆ—ï¼Œå¹¶é€šè¿‡å˜æ¢åµŒå…¥æ¥é¢„æµ‹ä¸‹ä¸€ä¸ªè§‚å¯Ÿçš„è¡¨ç¤ºã€‚å®éªŒè¯æ˜ï¼Œseq-JEPAåœ¨ç­‰å˜å’Œä¸å˜åŸºå‡†ä¸Šå‡è¡¨ç°å‡ºè‰²ï¼Œä¸”åœ¨éœ€è¦èšåˆè§‚å¯Ÿåºåˆ—çš„ä»»åŠ¡ä¸­è¡¨ç°å°¤ä¸ºçªå‡ºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•åœ¨å¤„ç†è§†è§‰è¡¨ç¤ºæ—¶çš„çµæ´»æ€§ä¸è¶³é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨é«˜å±‚ä¸å˜æ€§ä¸ç»†ç²’åº¦ç­‰å˜æ€§ä»»åŠ¡ä¹‹é—´çš„æ€§èƒ½æƒè¡¡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šseq-JEPAé€šè¿‡å¼•å…¥æ¶æ„å½’çº³åç½®ï¼Œè®¾è®¡äº†ä¸€ä¸ªèƒ½å¤ŸåŒæ—¶å­¦ä¹ ç­‰å˜å’Œä¸å˜è¡¨ç¤ºçš„æ¡†æ¶ï¼Œé¿å…äº†å¯¹åŒé‡ç­‰å˜æ€§é¢„æµ‹å™¨æˆ–æŸå¤±é¡¹çš„ä¾èµ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¨¡å‹å¤„ç†ä¸åŒè§†å›¾çš„çŸ­åºåˆ—ï¼Œæ¯ä¸ªç¼–ç è§†å›¾ä¸äº§ç”Ÿä¸‹ä¸€ä¸ªè§‚å¯Ÿçš„ç›¸å¯¹å˜æ¢åµŒå…¥è¿æ¥ã€‚ç»è¿‡Transformerç¼–ç å™¨åï¼Œè¾“å‡ºä¸€ä¸ªèšåˆè¡¨ç¤ºï¼Œå¹¶é€šè¿‡é¢„æµ‹å¤´æ¡ä»¶åŒ–è¯¥è¡¨ç¤ºä»¥é¢„æµ‹ä¸‹ä¸€ä¸ªè§‚å¯Ÿçš„è¡¨ç¤ºã€‚

**å…³é”®åˆ›æ–°**ï¼šseq-JEPAçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶æ¶æ„è®¾è®¡ï¼Œèƒ½å¤Ÿåœ¨ä¸ç‰ºç‰²ç­‰å˜æ€§å’Œä¸å˜æ€§ä¹‹é—´çš„æ€§èƒ½çš„æƒ…å†µä¸‹ï¼Œå­¦ä¹ åˆ°ä¸¤ç§ä¸åŒçš„è¡¨ç¤ºã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„åŒè§†å›¾èŒƒå¼å½¢æˆäº†æ˜¾è‘—å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡å‹é€šè¿‡å¤„ç†è§†å›¾-åŠ¨ä½œå¯¹æ¥å­¦ä¹ ï¼Œé‡‡ç”¨Transformerç¼–ç å™¨è¿›è¡Œèšåˆï¼Œå…³é”®å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡æœªåœ¨æ‘˜è¦ä¸­è¯¦ç»†è¯´æ˜ï¼Œå…·ä½“ç»†èŠ‚æœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼Œseq-JEPAåœ¨ç­‰å˜å’Œä¸å˜åŸºå‡†ä¸Šå‡è¡¨ç°å‡ºè‰²ï¼Œå…·ä½“æ€§èƒ½æ•°æ®æœªåœ¨æ‘˜è¦ä¸­æä¾›ã€‚è¯¥æ¨¡å‹åœ¨è·¯å¾„æ•´åˆå’Œé¢„æµ‹å­¦ä¹ ç­‰ä»»åŠ¡ä¸­å±•ç°äº†å¼ºå¤§çš„èƒ½åŠ›ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨å¤„ç†è§‚å¯Ÿåºåˆ—æ–¹é¢çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

seq-JEPAçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ï¼ŒåŒ…æ‹¬æœºå™¨äººå¯¼èˆªã€è§†é¢‘ç†è§£å’Œäººæœºäº¤äº’ç­‰ã€‚å…¶èƒ½å¤Ÿæœ‰æ•ˆå¤„ç†åºåˆ—æ•°æ®çš„èƒ½åŠ›ï¼Œä½¿å…¶åœ¨éœ€è¦èšåˆå¤šæ¬¡è§‚å¯Ÿçš„ä¿¡æ¯çš„ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨è‡ªç›‘ç£å­¦ä¹ åœ¨æ›´å¤æ‚åœºæ™¯ä¸­çš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Current self-supervised algorithms commonly rely on transformations such as data augmentation and masking to learn visual representations. This is achieved by enforcing invariance or equivariance with respect to these transformations after encoding two views of an image. This dominant two-view paradigm often limits the flexibility of learned representations for downstream adaptation by creating performance trade-offs between high-level invariance-demanding tasks such as image classification and more fine-grained equivariance-related tasks. In this work, we proposes \emph{seq-JEPA}, a world modeling framework that introduces architectural inductive biases into joint-embedding predictive architectures to resolve this trade-off. Without relying on dual equivariance predictors or loss terms, seq-JEPA simultaneously learns two architecturally segregated representations: one equivariant to specified transformations and another invariant to them. To do so, our model processes short sequences of different views (observations) of inputs. Each encoded view is concatenated with an embedding of the relative transformation (action) that produces the next observation in the sequence. These view-action pairs are passed through a transformer encoder that outputs an aggregate representation. A predictor head then conditions this aggregate representation on the upcoming action to predict the representation of the next observation. Empirically, seq-JEPA demonstrates strong performance on both equivariant and invariant benchmarks without sacrificing one for the other. Furthermore, it excels at tasks that inherently require aggregating a sequence of observations, such as path integration across actions and predictive learning across eye movements.

