---
layout: default
title: Real-Time Person Image Synthesis Using a Flow Matching Model
---

# Real-Time Person Image Synthesis Using a Flow Matching Model

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.03562" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.03562v1</a>
  <a href="https://arxiv.org/pdf/2505.03562.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.03562v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.03562v1', 'Real-Time Person Image Synthesis Using a Flow Matching Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiwoo Jeong, Kirok Kim, Wooju Kim, Nam-Joon Kim

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-06

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºæµåŒ¹é…æ¨¡å‹çš„å®æ—¶äººç‰©å›¾åƒåˆæˆæ–¹æ³•ä»¥è§£å†³ç”Ÿæˆé€Ÿåº¦é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å®æ—¶å›¾åƒåˆæˆ` `æµåŒ¹é…æ¨¡å‹` `å§¿æ€å¼•å¯¼` `ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ` `æ·±åº¦å­¦ä¹ ` `è®¡ç®—æœºè§†è§‰` `æ‰‹è¯­è§†é¢‘ç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒåˆæˆè´¨é‡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä½†å…¶æ…¢é€Ÿé‡‡æ ·é™åˆ¶äº†å®æ—¶åº”ç”¨çš„å¯è¡Œæ€§ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæµåŒ¹é…çš„ç”Ÿæˆæ¨¡å‹ï¼Œæ—¨åœ¨æé«˜å›¾åƒåˆæˆçš„é€Ÿåº¦å’Œç¨³å®šæ€§ï¼Œé€‚ç”¨äºå®æ—¶äº¤äº’ç³»ç»Ÿã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRPFMåœ¨ç”Ÿæˆé€Ÿåº¦ä¸Šæå‡è¶…è¿‡ä¸¤å€ï¼ŒåŒæ—¶ä¿æŒä¸æœ€å…ˆè¿›æ¨¡å‹ç›¸å½“çš„æ€§èƒ½ï¼Œç¡®ä¿å®æ—¶æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å§¿æ€å¼•å¯¼çš„äººç‰©å›¾åƒåˆæˆï¼ˆPGPISï¼‰æ—¨åœ¨æ ¹æ®ç›®æ ‡å§¿æ€å’Œæºå›¾åƒç”Ÿæˆé€¼çœŸçš„äººç‰©å›¾åƒã€‚è¿™ä¸€ä»»åŠ¡åœ¨æ‰‹è¯­è§†é¢‘ç”Ÿæˆã€å¢å¼ºç°å®/è™šæ‹Ÿç°å®ã€æ¸¸æˆå’Œç›´æ’­ç­‰å¤šç§ç°å®åº”ç”¨ä¸­è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œå®ç°å®æ—¶æ€§èƒ½ä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ï¼Œå› ä¸ºä»å¤šæ ·åŒ–å’ŒåŠ¨æ€çš„äººä½“å§¿æ€åˆæˆé«˜ä¿çœŸå›¾åƒçš„å¤æ‚æ€§ä½¿å¾—é€Ÿåº¦å—åˆ°é™åˆ¶ã€‚å°½ç®¡æœ€è¿‘çš„æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒè´¨é‡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†å…¶è¾ƒæ…¢çš„é‡‡æ ·é€Ÿåº¦é™åˆ¶äº†åœ¨æ—¶é—´æ•æ„Ÿåº”ç”¨ä¸­çš„éƒ¨ç½²ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæµåŒ¹é…çš„ç”Ÿæˆæ¨¡å‹ï¼ˆRPFMï¼‰ï¼Œè¯¥æ¨¡å‹åœ¨ä¿æŒå›¾åƒè´¨é‡çš„åŒæ—¶ï¼Œå®ç°äº†æ›´å¿«ã€æ›´ç¨³å®šçš„è®­ç»ƒå’Œé‡‡æ ·ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRPFMåœ¨DeepFashionæ•°æ®é›†ä¸Šå®ç°äº†æ¥è¿‘å®æ—¶çš„é‡‡æ ·é€Ÿåº¦ï¼Œä¸”æ€§èƒ½ä¸ç°æœ‰æœ€å…ˆè¿›æ¨¡å‹ç›¸å½“ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å®æ—¶äººç‰©å›¾åƒåˆæˆä¸­çš„é€Ÿåº¦ç“¶é¢ˆé—®é¢˜ï¼Œç°æœ‰çš„æ‰©æ•£æ¨¡å‹è™½ç„¶åœ¨å›¾åƒè´¨é‡ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†å…¶æ…¢é€Ÿé‡‡æ ·ä½¿å¾—åœ¨æ—¶é—´æ•æ„Ÿçš„åº”ç”¨ä¸­éš¾ä»¥éƒ¨ç½²ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºåŸºäºæµåŒ¹é…çš„ç”Ÿæˆæ¨¡å‹ï¼ˆRPFMï¼‰ï¼Œé€šè¿‡ä¼˜åŒ–è®­ç»ƒå’Œé‡‡æ ·è¿‡ç¨‹ï¼Œå®ç°æ›´å¿«çš„ç”Ÿæˆé€Ÿåº¦å’Œæ›´é«˜çš„ç¨³å®šæ€§ï¼Œç‰¹åˆ«é€‚åˆå®æ—¶åº”ç”¨ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¨¡å‹çš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æµåŒ¹é…ç”Ÿæˆæ¨¡å—å’Œåå¤„ç†é˜¶æ®µã€‚æµåŒ¹é…æ¨¡å—è´Ÿè´£åœ¨æ½œåœ¨ç©ºé—´ä¸­è¿›è¡Œæ¡ä»¶ç”Ÿæˆï¼Œä»¥æé«˜ç”Ÿæˆæ•ˆç‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šRPFMçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºæµåŒ¹é…æœºåˆ¶çš„å¼•å…¥ï¼Œä½¿å¾—æ¨¡å‹åœ¨ç”Ÿæˆé€Ÿåº¦ä¸Šæ˜¾è‘—æå‡ï¼ŒåŒæ—¶ä¿æŒå›¾åƒè´¨é‡ï¼ŒåŒºåˆ«äºä¼ ç»Ÿçš„æ‰©æ•£æ¨¡å‹ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥å¹³è¡¡ç”Ÿæˆé€Ÿåº¦ä¸å›¾åƒè´¨é‡ï¼Œå¹¶ä¼˜åŒ–äº†ç½‘ç»œç»“æ„ä»¥é€‚åº”æ½œåœ¨ç©ºé—´çš„æ“ä½œã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒRPFMåœ¨DeepFashionæ•°æ®é›†ä¸Šå®ç°äº†æ¥è¿‘å®æ—¶çš„é‡‡æ ·é€Ÿåº¦ï¼Œç”Ÿæˆé€Ÿåº¦æå‡è¶…è¿‡ä¸¤å€ï¼ŒåŒæ—¶ä¿æŒä¸æœ€å…ˆè¿›æ¨¡å‹ç›¸å½“çš„æ€§èƒ½ï¼Œç¡®ä¿åœ¨å®æ—¶åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ‰‹è¯­è§†é¢‘ç”Ÿæˆã€å¢å¼ºç°å®å’Œè™šæ‹Ÿç°å®ç­‰å®æ—¶äº¤äº’ç³»ç»Ÿã€‚é€šè¿‡æé«˜å›¾åƒåˆæˆçš„é€Ÿåº¦å’Œè´¨é‡ï¼ŒRPFMèƒ½å¤Ÿä¸ºç”¨æˆ·æä¾›æ›´æµç•…çš„è§†è§‰ä½“éªŒï¼Œå¢å¼ºæ²‰æµ¸æ„Ÿï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Pose-Guided Person Image Synthesis (PGPIS) generates realistic person images conditioned on a target pose and a source image. This task plays a key role in various real-world applications, such as sign language video generation, AR/VR, gaming, and live streaming. In these scenarios, real-time PGPIS is critical for providing immediate visual feedback and maintaining user immersion.However, achieving real-time performance remains a significant challenge due to the complexity of synthesizing high-fidelity images from diverse and dynamic human poses. Recent diffusion-based methods have shown impressive image quality in PGPIS, but their slow sampling speeds hinder deployment in time-sensitive applications. This latency is particularly problematic in tasks like generating sign language videos during live broadcasts, where rapid image updates are required. Therefore, developing a fast and reliable PGPIS model is a crucial step toward enabling real-time interactive systems. To address this challenge, we propose a generative model based on flow matching (FM). Our approach enables faster, more stable, and more efficient training and sampling. Furthermore, the proposed model supports conditional generation and can operate in latent space, making it especially suitable for real-time PGPIS applications where both speed and quality are critical. We evaluate our proposed method, Real-Time Person Image Synthesis Using a Flow Matching Model (RPFM), on the widely used DeepFashion dataset for PGPIS tasks. Our results show that RPFM achieves near-real-time sampling speeds while maintaining performance comparable to the state-of-the-art models. Our methodology trades off a slight, acceptable decrease in generated-image accuracy for over a twofold increase in generation speed, thereby ensuring real-time performance.

