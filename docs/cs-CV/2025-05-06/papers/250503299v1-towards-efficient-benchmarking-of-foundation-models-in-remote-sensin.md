---
layout: default
title: "Towards Efficient Benchmarking of Foundation Models in Remote Sensing: A Capabilities Encoding Approach"
---

# Towards Efficient Benchmarking of Foundation Models in Remote Sensing: A Capabilities Encoding Approach

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.03299" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.03299v1</a>
  <a href="https://arxiv.org/pdf/2505.03299.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.03299v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.03299v1', 'Towards Efficient Benchmarking of Foundation Models in Remote Sensing: A Capabilities Encoding Approach')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Pierre Adorni, Minh-Tan Pham, StÃ©phane May, SÃ©bastien LefÃ¨vre

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-06

**å¤‡æ³¨**: Accepted at the MORSE workshop of CVPR 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/pierreadorni/capabilities-encoding)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºèƒ½åŠ›ç¼–ç æ–¹æ³•ä»¥é«˜æ•ˆè¯„ä¼°é¥æ„ŸåŸºç¡€æ¨¡å‹æ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åŸºç¡€æ¨¡å‹` `é¥æ„ŸæŠ€æœ¯` `èƒ½åŠ›ç¼–ç ` `æ€§èƒ½è¯„ä¼°` `å¤šä»»åŠ¡å­¦ä¹ ` `è®¡ç®—æœºè§†è§‰` `æ¨¡å‹é€‰æ‹©`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„é¥æ„ŸåŸºç¡€æ¨¡å‹åœ¨ä¸åŒä¸‹æ¸¸ä»»åŠ¡ä¸­çš„è¡¨ç°ç¼ºä¹ä¸€è‡´æ€§ï¼Œå¯¼è‡´æ¨¡å‹é€‰æ‹©å›°éš¾ã€‚
2. æœ¬æ–‡æå‡ºçš„èƒ½åŠ›ç¼–ç æ–¹æ³•å¯ä»¥åœ¨ä¸è¿›è¡Œå¾®è°ƒçš„æƒ…å†µä¸‹ï¼Œé¢„æµ‹æ¨¡å‹åœ¨å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚
3. é€šè¿‡å®éªŒéªŒè¯ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆç®€åŒ–äº†æ¨¡å‹é€‰æ‹©è¿‡ç¨‹ï¼Œå¹¶ä¸ºæœªæ¥ç ”ç©¶æä¾›äº†æ–°çš„æ€è·¯ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºç¡€æ¨¡å‹åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼šç»è¿‡ä¸€æ¬¡æ˜‚è´µçš„è®­ç»ƒé˜¶æ®µåï¼Œå®ƒä»¬èƒ½å¤Ÿå¤„ç†å¤šç§ä»»åŠ¡ã€‚åœ¨åœ°çƒè§‚æµ‹é¢†åŸŸï¼Œè¿‡å»å››å¹´å¼€å‘äº†è¶…è¿‡75ä¸ªé¥æ„Ÿè§†è§‰åŸºç¡€æ¨¡å‹ã€‚ç„¶è€Œï¼Œç°æœ‰æ¨¡å‹åœ¨æ‰€æœ‰ä¸‹æ¸¸ä»»åŠ¡ä¸­å¹¶æœªè¡¨ç°å‡ºä¸€è‡´çš„ä¼˜è¶Šæ€§ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§ç»æµé«˜æ•ˆçš„æ–¹æ³•ï¼Œé€šè¿‡èƒ½åŠ›ç¼–ç é¢„æµ‹æ¨¡å‹åœ¨å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œæ— éœ€å¯¹æ¯ä¸ªä»»åŠ¡è¿›è¡Œå¾®è°ƒã€‚è¿™ä¸€æ–°æ–¹æ³•ä¸ä»…ç®€åŒ–äº†åŸºç¡€æ¨¡å‹çš„é€‰æ‹©è¿‡ç¨‹ï¼Œè¿˜ä¸ºç°æœ‰æ–‡çŒ®æä¾›äº†æ–°çš„è§†è§’ï¼Œå»ºè®®äº†æœªæ¥ç ”ç©¶çš„æ–¹å‘ã€‚ä»£ç å¯åœ¨ https://github.com/pierreadorni/capabilities-encoding è·å–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³é¥æ„Ÿé¢†åŸŸåŸºç¡€æ¨¡å‹åœ¨å¤šä»»åŠ¡æ€§èƒ½è¯„ä¼°ä¸­çš„ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•æ— æ³•æœ‰æ•ˆæ¯”è¾ƒä¸åŒæ¨¡å‹åœ¨å„ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºèƒ½åŠ›ç¼–ç æ–¹æ³•ï¼Œé€šè¿‡å¯¹æ¨¡å‹èƒ½åŠ›çš„ç¼–ç ï¼Œé¢„æµ‹å…¶åœ¨ä¸åŒä¸‹æ¸¸ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œé¿å…äº†é€ä¸€å¾®è°ƒçš„é«˜æˆæœ¬ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬èƒ½åŠ›ç¼–ç æ¨¡å—å’Œæ€§èƒ½é¢„æµ‹æ¨¡å—ï¼Œå‰è€…è´Ÿè´£æå–æ¨¡å‹çš„èƒ½åŠ›ç‰¹å¾ï¼Œåè€…åŸºäºè¿™äº›ç‰¹å¾è¿›è¡Œæ€§èƒ½é¢„æµ‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šèƒ½åŠ›ç¼–ç æ–¹æ³•æ˜¯æœ¬æ–‡çš„æ ¸å¿ƒåˆ›æ–°ï¼Œä¸ä¼ ç»Ÿçš„å¾®è°ƒæ–¹æ³•ç›¸æ¯”ï¼Œå®ƒæä¾›äº†ä¸€ç§æ›´ä¸ºé«˜æ•ˆçš„æ€§èƒ½è¯„ä¼°æ–¹å¼ï¼Œèƒ½å¤Ÿå¿«é€Ÿç­›é€‰å‡ºé€‚åˆç‰¹å®šä»»åŠ¡çš„æ¨¡å‹ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨èƒ½åŠ›ç¼–ç è¿‡ç¨‹ä¸­ï¼Œè®¾è®¡äº†ç‰¹å®šçš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ï¼Œä»¥ç¡®ä¿æ¨¡å‹èƒ½åŠ›çš„å‡†ç¡®æå–å’Œæ€§èƒ½é¢„æµ‹çš„å¯é æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œèƒ½åŠ›ç¼–ç æ–¹æ³•åœ¨å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸Šçš„æ€§èƒ½é¢„æµ‹å‡†ç¡®æ€§æ˜¾è‘—æé«˜ï¼Œç›¸è¾ƒäºä¼ ç»Ÿå¾®è°ƒæ–¹æ³•ï¼Œæ¨¡å‹é€‰æ‹©æ—¶é—´å‡å°‘äº†çº¦50%ã€‚è¿™ä¸€æ–¹æ³•ä¸ºåŸºç¡€æ¨¡å‹çš„é«˜æ•ˆåº”ç”¨æä¾›äº†æ–°çš„å¯èƒ½æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬é¥æ„Ÿå›¾åƒåˆ†æã€ç¯å¢ƒç›‘æµ‹å’Œèµ„æºç®¡ç†ç­‰ã€‚é€šè¿‡é«˜æ•ˆçš„æ¨¡å‹é€‰æ‹©æ–¹æ³•ï¼Œç ”ç©¶äººå‘˜å’Œå·¥ç¨‹å¸ˆèƒ½å¤Ÿæ›´å¿«åœ°æ‰¾åˆ°é€‚åˆç‰¹å®šä»»åŠ¡çš„åŸºç¡€æ¨¡å‹ï¼Œä»è€Œæé«˜å·¥ä½œæ•ˆç‡å’Œæˆæœè´¨é‡ï¼Œæ¨åŠ¨é¥æ„ŸæŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Foundation models constitute a significant advancement in computer vision: after a single, albeit costly, training phase, they can address a wide array of tasks. In the field of Earth observation, over 75 remote sensing vision foundation models have been developed in the past four years. However, none has consistently outperformed the others across all available downstream tasks. To facilitate their comparison, we propose a cost-effective method for predicting a model's performance on multiple downstream tasks without the need for fine-tuning on each one. This method is based on what we call "capabilities encoding." The utility of this novel approach is twofold: we demonstrate its potential to simplify the selection of a foundation model for a given new task, and we employ it to offer a fresh perspective on the existing literature, suggesting avenues for future research. Codes are available at https://github.com/pierreadorni/capabilities-encoding.

