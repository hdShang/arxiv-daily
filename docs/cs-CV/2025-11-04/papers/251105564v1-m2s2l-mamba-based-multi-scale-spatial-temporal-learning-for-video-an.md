---
layout: default
title: "M2S2L: Mamba-based Multi-Scale Spatial-temporal Learning for Video Anomaly Detection"
---

# M2S2L: Mamba-based Multi-Scale Spatial-temporal Learning for Video Anomaly Detection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.05564" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.05564v1</a>
  <a href="https://arxiv.org/pdf/2511.05564.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.05564v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.05564v1', 'M2S2L: Mamba-based Multi-Scale Spatial-temporal Learning for Video Anomaly Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yang Liu, Boan Chen, Xiaoguang Zhu, Jing Liu, Peng Sun, Wei Zhou

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-04

**å¤‡æ³¨**: IEEE VCIP 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºMambaçš„å¤šå°ºåº¦æ—¶ç©ºå­¦ä¹ æ¡†æ¶M2S2Lï¼Œç”¨äºæå‡è§†é¢‘å¼‚å¸¸æ£€æµ‹çš„ç²¾åº¦å’Œæ•ˆç‡ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è§†é¢‘å¼‚å¸¸æ£€æµ‹` `Mamba` `å¤šå°ºåº¦å­¦ä¹ ` `æ—¶ç©ºå»ºæ¨¡` `ç‰¹å¾åˆ†è§£` `è§†é¢‘ç›‘æ§` `åºåˆ—å»ºæ¨¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†é¢‘å¼‚å¸¸æ£€æµ‹æ–¹æ³•éš¾ä»¥å…¼é¡¾å¤æ‚åœºæ™¯ä¸‹çš„æ£€æµ‹ç²¾åº¦å’Œå®æ—¶æ€§éœ€æ±‚ï¼Œç¼ºä¹æœ‰æ•ˆçš„æ—¶ç©ºå»ºæ¨¡èƒ½åŠ›ã€‚
2. M2S2Læ¡†æ¶åˆ©ç”¨Mambaæ¶æ„ï¼Œé€šè¿‡å¤šå°ºåº¦ç©ºé—´ç¼–ç å’Œå¤šæ—¶é—´å°ºåº¦è¿åŠ¨å»ºæ¨¡ï¼Œå®ç°æ›´å…¨é¢çš„æ—¶ç©ºç‰¹å¾æå–ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒM2S2Låœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå–å¾—äº†ä¼˜å¼‚çš„å¼‚å¸¸æ£€æµ‹æ€§èƒ½ï¼Œå¹¶ä¿æŒäº†è¾ƒé«˜çš„æ¨ç†é€Ÿåº¦ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†é¢‘å¼‚å¸¸æ£€æµ‹(VAD)æ˜¯å›¾åƒå¤„ç†é¢†åŸŸçš„ä¸€é¡¹é‡è¦ä»»åŠ¡ï¼Œåœ¨è§†é¢‘ç›‘æ§æ–¹é¢å…·æœ‰å¹¿é˜”å‰æ™¯ï¼Œä½†å…¶åœ¨æ£€æµ‹ç²¾åº¦å’Œè®¡ç®—æ•ˆç‡ä¹‹é—´å–å¾—å¹³è¡¡é¢ä¸´ç€æ ¹æœ¬æ€§æŒ‘æˆ˜ã€‚éšç€è§†é¢‘å†…å®¹æ—¥ç›Šå¤æ‚ï¼Œè¡Œä¸ºæ¨¡å¼å’Œä¸Šä¸‹æ–‡åœºæ™¯å¤šæ ·åŒ–ï¼Œä¼ ç»Ÿçš„VADæ–¹æ³•éš¾ä»¥å¯¹ç°ä»£ç›‘æ§ç³»ç»Ÿæä¾›ç¨³å¥çš„è¯„ä¼°ã€‚ç°æœ‰æ–¹æ³•è¦ä¹ˆç¼ºä¹å…¨é¢çš„æ—¶ç©ºå»ºæ¨¡ï¼Œè¦ä¹ˆéœ€è¦è¿‡å¤šçš„è®¡ç®—èµ„æºæ‰èƒ½å®ç°å®æ—¶åº”ç”¨ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºMambaçš„å¤šå°ºåº¦æ—¶ç©ºå­¦ä¹ (M2S2L)æ¡†æ¶ã€‚è¯¥æ–¹æ³•é‡‡ç”¨åœ¨å¤šä¸ªç²’åº¦ä¸Šè¿è¡Œçš„åˆ†å±‚ç©ºé—´ç¼–ç å™¨å’Œè·¨ä¸åŒæ—¶é—´å°ºåº¦æ•è·è¿åŠ¨åŠ¨æ€çš„å¤šæ—¶é—´ç¼–ç å™¨ã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ç§ç‰¹å¾åˆ†è§£æœºåˆ¶ï¼Œä»¥å®ç°é’ˆå¯¹å¤–è§‚å’Œè¿åŠ¨é‡å»ºçš„ä»»åŠ¡ç‰¹å®šä¼˜åŒ–ï¼Œä»è€Œä¿ƒè¿›æ›´ç»†è‡´çš„è¡Œä¸ºå»ºæ¨¡å’Œè´¨é‡æ„ŸçŸ¥çš„å¼‚å¸¸è¯„ä¼°ã€‚åœ¨ä¸‰ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒM2S2Læ¡†æ¶åœ¨UCSD Ped2ã€CUHK Avenueå’ŒShanghaiTechä¸Šåˆ†åˆ«å®ç°äº†98.5%ã€92.1%å’Œ77.9%çš„å¸§çº§åˆ«AUCï¼ŒåŒæ—¶ä¿æŒäº†20.1G FLOPsçš„æ•ˆç‡å’Œ45 FPSçš„æ¨ç†é€Ÿåº¦ï¼Œä½¿å…¶é€‚ç”¨äºå®é™…çš„ç›‘æ§éƒ¨ç½²ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè§†é¢‘å¼‚å¸¸æ£€æµ‹æ—¨åœ¨è¯†åˆ«è§†é¢‘åºåˆ—ä¸­ä¸æ­£å¸¸æ¨¡å¼æ˜¾è‘—ä¸åŒçš„äº‹ä»¶ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éš¾ä»¥åœ¨å¤æ‚åœºæ™¯ä¸‹è¿›è¡Œç²¾ç¡®çš„æ—¶ç©ºå»ºæ¨¡ï¼Œå¯¼è‡´æ£€æµ‹ç²¾åº¦ä¸‹é™ã€‚åŒæ—¶ï¼Œä¸€äº›æ–¹æ³•è®¡ç®—å¤æ‚åº¦é«˜ï¼Œéš¾ä»¥æ»¡è¶³å®æ—¶æ€§è¦æ±‚ï¼Œé™åˆ¶äº†å®é™…åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šM2S2Lçš„æ ¸å¿ƒåœ¨äºåˆ©ç”¨Mambaæ¶æ„å¼ºå¤§çš„åºåˆ—å»ºæ¨¡èƒ½åŠ›ï¼ŒåŒæ—¶ç»“åˆå¤šå°ºåº¦ç©ºé—´ä¿¡æ¯å’Œå¤šæ—¶é—´å°ºåº¦è¿åŠ¨ä¿¡æ¯ï¼Œä»è€Œæ›´å…¨é¢åœ°æ•æ‰è§†é¢‘ä¸­çš„å¼‚å¸¸è¡Œä¸ºã€‚é€šè¿‡ç‰¹å¾åˆ†è§£æœºåˆ¶ï¼Œé’ˆå¯¹å¤–è§‚å’Œè¿åŠ¨è¿›è¡Œä»»åŠ¡ç‰¹å®šçš„ä¼˜åŒ–ï¼Œè¿›ä¸€æ­¥æå‡æ£€æµ‹ç²¾åº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šM2S2Læ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) å¤šå°ºåº¦ç©ºé—´ç¼–ç å™¨ï¼šé‡‡ç”¨åˆ†å±‚ç»“æ„ï¼Œåœ¨ä¸åŒç²’åº¦ä¸Šæå–ç©ºé—´ç‰¹å¾ã€‚2) å¤šæ—¶é—´å°ºåº¦è¿åŠ¨ç¼–ç å™¨ï¼šæ•æ‰ä¸åŒæ—¶é—´è·¨åº¦çš„è¿åŠ¨åŠ¨æ€ã€‚3) ç‰¹å¾åˆ†è§£æ¨¡å—ï¼šå°†ç‰¹å¾åˆ†è§£ä¸ºå¤–è§‚å’Œè¿åŠ¨åˆ†é‡ï¼Œåˆ†åˆ«è¿›è¡Œé‡å»ºã€‚4) å¼‚å¸¸è¯„åˆ†æ¨¡å—ï¼šåŸºäºé‡å»ºè¯¯å·®è¯„ä¼°å¼‚å¸¸ç¨‹åº¦ã€‚

**å…³é”®åˆ›æ–°**ï¼šM2S2Lçš„å…³é”®åˆ›æ–°åœ¨äºå°†Mambaæ¶æ„å¼•å…¥è§†é¢‘å¼‚å¸¸æ£€æµ‹é¢†åŸŸï¼Œå¹¶ç»“åˆå¤šå°ºåº¦æ—¶ç©ºå»ºæ¨¡å’Œç‰¹å¾åˆ†è§£æœºåˆ¶ã€‚ä¸ä¼ ç»Ÿçš„åŸºäºCNNæˆ–RNNçš„æ–¹æ³•ç›¸æ¯”ï¼ŒMambaå…·æœ‰æ›´å¼ºçš„åºåˆ—å»ºæ¨¡èƒ½åŠ›å’Œæ›´é«˜çš„è®¡ç®—æ•ˆç‡ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰è§†é¢‘ä¸­çš„é•¿ç¨‹ä¾èµ–å…³ç³»ã€‚

**å…³é”®è®¾è®¡**ï¼šå¤šå°ºåº¦ç©ºé—´ç¼–ç å™¨é‡‡ç”¨å·ç§¯ç¥ç»ç½‘ç»œå®ç°ï¼Œä¸åŒå±‚çº§çš„å·ç§¯æ ¸å¤§å°å’Œæ­¥é•¿ä¸åŒï¼Œä»¥æå–ä¸åŒå°ºåº¦çš„ç©ºé—´ç‰¹å¾ã€‚å¤šæ—¶é—´å°ºåº¦è¿åŠ¨ç¼–ç å™¨é‡‡ç”¨Mambaæ¶æ„å®ç°ï¼Œé€šè¿‡è°ƒæ•´çŠ¶æ€ç©ºé—´æ¨¡å‹çš„å‚æ•°ï¼Œæ•æ‰ä¸åŒæ—¶é—´è·¨åº¦çš„è¿åŠ¨ä¿¡æ¯ã€‚ç‰¹å¾åˆ†è§£æ¨¡å—é‡‡ç”¨çº¿æ€§å˜æ¢å®ç°ï¼Œå°†ç‰¹å¾åˆ†è§£ä¸ºå¤–è§‚å’Œè¿åŠ¨åˆ†é‡ã€‚å¼‚å¸¸è¯„åˆ†æ¨¡å—é‡‡ç”¨é‡å»ºè¯¯å·®ä½œä¸ºå¼‚å¸¸æŒ‡æ ‡ï¼Œé€šè¿‡è®¾å®šé˜ˆå€¼åˆ¤æ–­æ˜¯å¦ä¸ºå¼‚å¸¸äº‹ä»¶ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

M2S2Læ¡†æ¶åœ¨ä¸‰ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚åœ¨UCSD Ped2æ•°æ®é›†ä¸Šï¼Œå¸§çº§åˆ«AUCè¾¾åˆ°äº†98.5%ï¼›åœ¨CUHK Avenueæ•°æ®é›†ä¸Šï¼Œè¾¾åˆ°äº†92.1%ï¼›åœ¨ShanghaiTechæ•°æ®é›†ä¸Šï¼Œè¾¾åˆ°äº†77.9%ã€‚åŒæ—¶ï¼Œè¯¥æ–¹æ³•ä¿æŒäº†è¾ƒé«˜çš„æ¨ç†é€Ÿåº¦ï¼Œè¾¾åˆ°äº†45 FPSï¼Œè®¡ç®—å¤æ‚åº¦ä¸º20.1G FLOPsï¼Œä¼˜äºè®¸å¤šç°æœ‰æ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºæ™ºèƒ½è§†é¢‘ç›‘æ§é¢†åŸŸï¼Œä¾‹å¦‚å…¬å…±å®‰å…¨ã€äº¤é€šç®¡ç†ã€å·¥ä¸šç”Ÿäº§ç­‰ã€‚é€šè¿‡å®æ—¶æ£€æµ‹å¼‚å¸¸äº‹ä»¶ï¼Œå¯ä»¥åŠæ—¶é¢„è­¦å’Œé‡‡å–æªæ–½ï¼Œæœ‰æ•ˆé™ä½å®‰å…¨é£é™©å’ŒæŸå¤±ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–è§†é¢‘åˆ†æä»»åŠ¡ï¼Œå¦‚è¡Œä¸ºè¯†åˆ«ã€äº‹ä»¶æ£€æµ‹ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Video anomaly detection (VAD) is an essential task in the image processing community with prospects in video surveillance, which faces fundamental challenges in balancing detection accuracy with computational efficiency. As video content becomes increasingly complex with diverse behavioral patterns and contextual scenarios, traditional VAD approaches struggle to provide robust assessment for modern surveillance systems. Existing methods either lack comprehensive spatial-temporal modeling or require excessive computational resources for real-time applications. In this regard, we present a Mamba-based multi-scale spatial-temporal learning (M2S2L) framework in this paper. The proposed method employs hierarchical spatial encoders operating at multiple granularities and multi-temporal encoders capturing motion dynamics across different time scales. We also introduce a feature decomposition mechanism to enable task-specific optimization for appearance and motion reconstruction, facilitating more nuanced behavioral modeling and quality-aware anomaly assessment. Experiments on three benchmark datasets demonstrate that M2S2L framework achieves 98.5%, 92.1%, and 77.9% frame-level AUCs on UCSD Ped2, CUHK Avenue, and ShanghaiTech respectively, while maintaining efficiency with 20.1G FLOPs and 45 FPS inference speed, making it suitable for practical surveillance deployment.

