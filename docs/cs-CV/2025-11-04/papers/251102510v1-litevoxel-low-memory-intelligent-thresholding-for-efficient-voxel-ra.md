---
layout: default
title: "LiteVoxel: Low-memory Intelligent Thresholding for Efficient Voxel Rasterization"
---

# LiteVoxel: Low-memory Intelligent Thresholding for Efficient Voxel Rasterization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.02510" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.02510v1</a>
  <a href="https://arxiv.org/pdf/2511.02510.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.02510v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.02510v1', 'LiteVoxel: Low-memory Intelligent Thresholding for Efficient Voxel Rasterization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jee Won Lee, Jongseong Brad Choi

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-04

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLiteVoxelä»¥è§£å†³ç¨€ç–ä½“ç´ å…‰æ …åŒ–ä¸­çš„ä½é¢‘å†…å®¹ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `ç¨€ç–ä½“ç´ å…‰æ …åŒ–` `ä½é¢‘å†…å®¹å¤„ç†` `æ˜¾å­˜ä¼˜åŒ–` `è‡ªè°ƒèŠ‚è®­ç»ƒ` `è®¡ç®—æœºè§†è§‰` `è™šæ‹Ÿç°å®` `åœºæ™¯é‡å»º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç¨€ç–ä½“ç´ å…‰æ …åŒ–æ–¹æ³•åœ¨å¤„ç†ä½é¢‘å†…å®¹æ—¶å®¹æ˜“å‡ºç°ä¸è¶³ï¼Œä¸”æ˜¾å­˜ä½¿ç”¨ä¸å¤Ÿé«˜æ•ˆã€‚
2. LiteVoxelé€šè¿‡è‡ªè°ƒèŠ‚è®­ç»ƒç®¡é“å’Œé€†Sobelé‡åŠ æƒï¼Œå¢å¼ºäº†å¯¹ä½é¢‘å†…å®¹çš„æ•æ„Ÿæ€§ï¼Œå¹¶ä¼˜åŒ–äº†æ˜¾å­˜ä½¿ç”¨ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLiteVoxelåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå‡å°‘äº†ä½é¢‘åŒºåŸŸçš„é”™è¯¯ï¼ŒåŒæ—¶ä¿æŒäº†ä¸å¼ºSVRasterç®¡é“ç›¸å½“çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç¨€ç–ä½“ç´ å…‰æ …åŒ–æ˜¯ä¸€ç§å¿«é€Ÿä¸”å¯å¾®åˆ†çš„åœºæ™¯é‡å»ºæ›¿ä»£æ–¹æ¡ˆï¼Œä½†åœ¨å¤„ç†ä½é¢‘å†…å®¹æ—¶è¡¨ç°ä¸ä½³ï¼Œå¹¶ä¸”ä¾èµ–è„†å¼±çš„ä¿®å‰ªå¯å‘å¼æ–¹æ³•ï¼Œå¯èƒ½å¯¼è‡´æ˜¾å­˜è†¨èƒ€ã€‚æœ¬æ–‡æå‡ºLiteVoxelï¼Œä¸€ä¸ªè‡ªè°ƒèŠ‚çš„è®­ç»ƒç®¡é“ï¼Œä½¿å¾—ç¨€ç–ä½“ç´ å…‰æ …åŒ–æ›´åŠ ç¨³å®šä¸”å†…å­˜å ç”¨æ›´ä½ã€‚é€šè¿‡é€†Sobelé‡åŠ æƒå’Œä¸­æœŸè®­ç»ƒçš„ä¼½é©¬æ–œå¡ï¼Œä½¿æŸå¤±å‡½æ•°å¯¹ä½é¢‘å†…å®¹æ›´åŠ æ•æ„Ÿï¼Œç¡®ä¿å‡ ä½•ä½“ç¨³å®šåå†è°ƒæ•´æ¢¯åº¦é¢„ç®—ã€‚é‡‡ç”¨æ·±åº¦åˆ†ä½æ•°ä¿®å‰ªé€»è¾‘æ›¿ä»£å›ºå®šé˜ˆå€¼ï¼Œå¹¶é€šè¿‡EMA-æ»åä¿æŠ¤å’ŒåŸºäºå…‰çº¿è¶³è¿¹çš„ä¼˜å…ˆçº§é©±åŠ¨ç»†åˆ†æ¥ä¼˜åŒ–ç»“æ„ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLiteVoxelåœ¨ä¿æŒPSNR/SSIMã€è®­ç»ƒæ—¶é—´å’ŒFPSä¸å¼ºSVRasterç®¡é“ç›¸å½“çš„åŒæ—¶ï¼Œæ˜¾è‘—å‡å°‘äº†40%-60%çš„å³°å€¼æ˜¾å­˜ï¼Œå¹¶ä¿ç•™äº†ä½é¢‘ç»†èŠ‚ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç¨€ç–ä½“ç´ å…‰æ …åŒ–åœ¨å¤„ç†ä½é¢‘å†…å®¹æ—¶çš„ä¸è¶³ï¼Œä»¥åŠæ˜¾å­˜ä½¿ç”¨ä¸å½“çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºè„†å¼±çš„ä¿®å‰ªå¯å‘å¼ï¼Œå®¹æ˜“å¯¼è‡´æ˜¾å­˜è†¨èƒ€å’Œè¾¹ç•Œä¸ç¨³å®šã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šLiteVoxelçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è‡ªè°ƒèŠ‚çš„è®­ç»ƒç®¡é“å’Œé€†Sobelé‡åŠ æƒï¼Œä½¿å¾—æŸå¤±å‡½æ•°å¯¹ä½é¢‘å†…å®¹æ›´åŠ æ•æ„Ÿï¼Œä»è€Œåœ¨å‡ ä½•ä½“ç¨³å®šåå†è¿›è¡Œæ¢¯åº¦é¢„ç®—çš„è°ƒæ•´ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLiteVoxelçš„æ•´ä½“æ¶æ„åŒ…æ‹¬è‡ªè°ƒèŠ‚è®­ç»ƒç®¡é“ã€é€†Sobelé‡åŠ æƒã€æ·±åº¦åˆ†ä½æ•°ä¿®å‰ªé€»è¾‘ã€EMA-æ»åä¿æŠ¤å’ŒåŸºäºå…‰çº¿è¶³è¿¹çš„ç»†åˆ†æ¨¡å—ã€‚æ¯ä¸ªæ¨¡å—ååŒå·¥ä½œï¼Œä»¥å®ç°æ›´é«˜æ•ˆçš„å…‰æ …åŒ–è¿‡ç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šLiteVoxelçš„ä¸»è¦åˆ›æ–°åœ¨äºå¼•å…¥äº†æ·±åº¦åˆ†ä½æ•°ä¿®å‰ªé€»è¾‘å’Œé€†Sobelé‡åŠ æƒï¼Œä½¿å¾—å…‰æ …åŒ–è¿‡ç¨‹æ›´åŠ ç¨³å®šï¼Œå¹¶æ˜¾è‘—é™ä½äº†æ˜¾å­˜ä½¿ç”¨ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒLiteVoxelåœ¨å¤„ç†ä½é¢‘å†…å®¹æ—¶è¡¨ç°æ›´ä½³ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŸå¤±å‡½æ•°è®¾è®¡ä¸Šï¼Œé‡‡ç”¨é€†Sobelé‡åŠ æƒï¼Œå¹¶ç»“åˆä¸­æœŸè®­ç»ƒçš„ä¼½é©¬æ–œå¡ã€‚æ·±åº¦åˆ†ä½æ•°ä¿®å‰ªé€»è¾‘æ›¿ä»£äº†å›ºå®šé˜ˆå€¼ï¼Œç¡®ä¿äº†åœ¨æœ€å¤§æ··åˆæƒé‡ä¸‹çš„ç¨³å®šæ€§ã€‚åŒæ—¶ï¼ŒEMA-æ»åä¿æŠ¤å’Œå…‰çº¿è¶³è¿¹ä¼˜å…ˆçº§é©±åŠ¨ç»†åˆ†è¿›ä¸€æ­¥ä¼˜åŒ–äº†ç»“æ„ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

LiteVoxelåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ˜¾å­˜å³°å€¼å‡å°‘äº†çº¦40%-60%ï¼ŒåŒæ—¶åœ¨ä½é¢‘åŒºåŸŸçš„é”™è¯¯å¾—åˆ°äº†æ˜¾è‘—ç¼“è§£ã€‚ä¸å¼ºSVRasterç®¡é“ç›¸æ¯”ï¼ŒLiteVoxelåœ¨PSNR/SSIMã€è®­ç»ƒæ—¶é—´å’ŒFPSç­‰æ€§èƒ½æŒ‡æ ‡ä¸Šä¿æŒäº†ç›¸å½“çš„æ°´å¹³ï¼Œå±•ç°äº†å…¶åœ¨å†…å­˜æ•ˆç‡å’Œæ„ŸçŸ¥è´¨é‡ä¸Šçš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

LiteVoxelçš„ç ”ç©¶æˆæœåœ¨è®¡ç®—æœºè§†è§‰ã€è™šæ‹Ÿç°å®å’Œæ¸¸æˆå¼€å‘ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æé«˜ç¨€ç–ä½“ç´ å…‰æ …åŒ–çš„æ•ˆç‡å’Œç¨³å®šæ€§ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ”¯æŒæ›´å¤æ‚çš„åœºæ™¯é‡å»ºä»»åŠ¡ï¼Œå‡å°‘æ˜¾å­˜éœ€æ±‚ï¼Œä»è€Œä½¿å¾—é«˜è´¨é‡çš„å®æ—¶æ¸²æŸ“æˆä¸ºå¯èƒ½ã€‚æœªæ¥ï¼ŒLiteVoxelå¯èƒ½æ¨åŠ¨æ›´å¤šåŸºäºä½“ç´ çš„æŠ€æœ¯è¿›æ­¥ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Sparse-voxel rasterization is a fast, differentiable alternative for optimization-based scene reconstruction, but it tends to underfit low-frequency content, depends on brittle pruning heuristics, and can overgrow in ways that inflate VRAM. We introduce LiteVoxel, a self-tuning training pipeline that makes SV rasterization both steadier and lighter. Our loss is made low-frequency aware via an inverse-Sobel reweighting with a mid-training gamma-ramp, shifting gradient budget to flat regions only after geometry stabilize. Adaptation replaces fixed thresholds with a depth-quantile pruning logic on maximum blending weight, stabilized by EMA-hysteresis guards and refines structure through ray-footprint-based, priority-driven subdivision under an explicit growth budget. Ablations and full-system results across Mip-NeRF 360 (6scenes) and Tanks & Temples (3scenes) datasets show mitigation of errors in low-frequency regions and boundary instability while keeping PSNR/SSIM, training time, and FPS comparable to a strong SVRaster pipeline. Crucially, LiteVoxel reduces peak VRAM by ~40%-60% and preserves low-frequency detail that prior setups miss, enabling more predictable, memory-efficient training without sacrificing perceptual quality.

