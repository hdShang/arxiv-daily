---
layout: default
title: OLATverse: A Large-scale Real-world Object Dataset with Precise Lighting Control
---

# OLATverse: A Large-scale Real-world Object Dataset with Precise Lighting Control

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.02483" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.02483v3</a>
  <a href="https://arxiv.org/pdf/2511.02483.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.02483v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.02483v3', 'OLATverse: A Large-scale Real-world Object Dataset with Precise Lighting Control')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xilong Zhou, Jianchun Chen, Pramod Rao, Timo Teufel, Linjie Lyu, Tigran Minasian, Oleksandr Sotnychenko, Xiao-Xiao Long, Marc Habermann, Christian Theobalt

**åˆ†ç±»**: cs.CV, cs.GR

**å‘å¸ƒæ—¥æœŸ**: 2025-11-04 (æ›´æ–°: 2025-12-16)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOLATverseæ•°æ®é›†ä»¥è§£å†³çœŸå®ä¸–ç•Œç‰©ä½“æ¸²æŸ“çš„å±€é™æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `é€†å‘æ¸²æŸ“` `é‡å…‰ç…§` `çœŸå®æ•°æ®é›†` `è®¡ç®—æœºè§†è§‰` `ç‰©ä½“è¯†åˆ«` `å›¾åƒåˆæˆ` `å…‰ç…§æ§åˆ¶` `æ•°æ®é›†æ„å»º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç‰©ä½“ä¸­å¿ƒé€†å‘æ¸²æŸ“æŠ€æœ¯å¤§å¤šä¾èµ–åˆæˆæ•°æ®é›†ï¼Œç¼ºä¹çœŸå®ä¸–ç•Œæ•°æ®çš„æ”¯æŒï¼Œå¯¼è‡´å…¶æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚
2. OLATverseæ•°æ®é›†é€šè¿‡æä¾›765ç§çœŸå®ç‰©ä½“åœ¨å¤šç§ç…§æ˜æ¡ä»¶ä¸‹çš„é«˜è´¨é‡å›¾åƒï¼Œå¡«è¡¥äº†çœŸå®æ•°æ®é›†çš„ç©ºç™½ã€‚
3. è¯¥æ•°æ®é›†å»ºç«‹äº†é¦–ä¸ªå…¨é¢çš„çœŸå®ä¸–ç•Œç‰©ä½“ä¸­å¿ƒåŸºå‡†ï¼Œä¸ºé€†å‘æ¸²æŸ“å’Œæ³•çº¿ä¼°è®¡æä¾›äº†ä¸°å¯Œçš„è¯„ä¼°èµ„æºã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬ä»‹ç»äº†OLATverseï¼Œè¿™æ˜¯ä¸€ä¸ªå¤§è§„æ¨¡æ•°æ®é›†ï¼ŒåŒ…å«çº¦900ä¸‡å¼ 765ç§çœŸå®ç‰©ä½“çš„å›¾åƒï¼Œè¿™äº›å›¾åƒåœ¨å¤šç§è§†è§’å’Œç²¾ç¡®æ§åˆ¶çš„ç…§æ˜æ¡ä»¶ä¸‹æ•è·ã€‚å°½ç®¡è¿‘å¹´æ¥ç‰©ä½“ä¸­å¿ƒçš„é€†å‘æ¸²æŸ“ã€è§†å›¾åˆæˆå’Œé‡å…‰ç…§æŠ€æœ¯å–å¾—äº†è‰¯å¥½è¿›å±•ï¼Œä½†å¤§å¤šæ•°æ–¹æ³•ä»ä¾èµ–äºåˆæˆæ•°æ®é›†è¿›è¡Œè®­ç»ƒå’Œå°è§„æ¨¡çœŸå®æ•°æ®é›†è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œè¿™é™åˆ¶äº†å…¶çœŸå®æ„Ÿå’Œæ³›åŒ–èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼ŒOLATverseåœ¨ç°æœ‰æ•°æ®é›†çš„åŸºç¡€ä¸Šæä¾›äº†ä¸¤ä¸ªå…³é”®ä¼˜åŠ¿ï¼šå¯¹çœŸå®ç‰©ä½“çš„å¤§è§„æ¨¡è¦†ç›–å’Œåœ¨ç²¾ç¡®æ§åˆ¶çš„ç…§æ˜ä¸‹çš„é«˜ä¿çœŸå¤–è§‚ã€‚è¯¥æ•°æ®é›†å°†å…¬å¼€å‘å¸ƒï¼Œæ¨åŠ¨ä¸‹ä¸€ä»£é€†å‘æ¸²æŸ“å’Œé‡å…‰ç…§æ–¹æ³•ä¸çœŸå®ä¸–ç•Œæ•°æ®çš„ç»“åˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰ç‰©ä½“ä¸­å¿ƒé€†å‘æ¸²æŸ“æ–¹æ³•å¯¹çœŸå®æ•°æ®é›†ä¾èµ–ä¸è¶³çš„é—®é¢˜ï¼Œå¯¼è‡´å…¶åœ¨çœŸå®åœºæ™¯ä¸­çš„åº”ç”¨å—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šOLATverseé€šè¿‡å¤§è§„æ¨¡æ”¶é›†çœŸå®ç‰©ä½“å›¾åƒï¼Œå¹¶åœ¨ç²¾ç¡®æ§åˆ¶çš„ç…§æ˜æ¡ä»¶ä¸‹è¿›è¡Œæ‹æ‘„ï¼Œæä¾›äº†ä¸°å¯Œçš„çœŸå®æ•°æ®ï¼Œä»¥å¢å¼ºæ¨¡å‹çš„çœŸå®æ„Ÿå’Œæ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ•°æ®é›†ä½¿ç”¨35å°å•åç›¸æœºå’Œ331ä¸ªç‹¬ç«‹æ§åˆ¶çš„å…‰æºï¼Œæ•è·765ç§ç‰©ä½“çš„å›¾åƒï¼Œæ¶µç›–å¤šç§ææ–™ç±»åˆ«ã€‚æ•°æ®é›†è¿˜æä¾›äº†æ ¡å‡†çš„ç›¸æœºå‚æ•°ã€å‡†ç¡®çš„ç‰©ä½“æ©è†œã€å…‰åº¦è¡¨é¢æ³•çº¿å’Œæ¼«åå°„åç…§ç‡ç­‰è¾…åŠ©èµ„æºã€‚

**å…³é”®åˆ›æ–°**ï¼šOLATverseçš„åˆ›æ–°åœ¨äºå…¶å¤§è§„æ¨¡çš„çœŸå®ç‰©ä½“è¦†ç›–å’Œåœ¨ç²¾ç¡®ç…§æ˜æ¡ä»¶ä¸‹çš„é«˜ä¿çœŸå¤–è§‚ï¼Œè¿™åœ¨ç°æœ‰æ•°æ®é›†ä¸­æ˜¯å‰æ‰€æœªæœ‰çš„ã€‚

**å…³é”®è®¾è®¡**ï¼šæ•°æ®é›†ä¸­çš„æ¯ä¸ªç‰©ä½“éƒ½ç»è¿‡ç²¾ç¡®çš„ç…§æ˜æ§åˆ¶ï¼Œç¡®ä¿äº†ä¸åŒå…‰ç…§æ¡ä»¶ä¸‹çš„å›¾åƒè´¨é‡ï¼ŒåŒæ—¶æä¾›äº†ä¸°å¯Œçš„è¾…åŠ©ä¿¡æ¯ï¼Œæ”¯æŒåç»­çš„ç ”ç©¶å’Œåº”ç”¨ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

OLATverseæ•°æ®é›†çš„å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨è¯¥æ•°æ®é›†è¿›è¡Œè®­ç»ƒçš„æ¨¡å‹åœ¨é€†å‘æ¸²æŸ“å’Œæ³•çº¿ä¼°è®¡ä»»åŠ¡ä¸Šè¡¨ç°å‡ºæ˜¾è‘—æå‡ï¼Œç›¸è¾ƒäºä¼ ç»Ÿå°è§„æ¨¡æ•°æ®é›†ï¼Œæ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œå±•ç¤ºäº†å…¶åœ¨çœŸå®ä¸–ç•Œåº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

OLATverseæ•°æ®é›†å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨è®¡ç®—æœºè§†è§‰ã€æœºå™¨äººå’Œå¢å¼ºç°å®ç­‰é¢†åŸŸã€‚å®ƒå¯ä»¥ç”¨äºè®­ç»ƒå’Œè¯„ä¼°é€†å‘æ¸²æŸ“ã€é‡å…‰ç…§å’Œè§†å›¾åˆæˆç­‰ç®—æ³•ï¼Œæ¨åŠ¨è¿™äº›æŠ€æœ¯åœ¨çœŸå®åœºæ™¯ä¸­çš„åº”ç”¨ã€‚æœªæ¥ï¼ŒOLATverseå¯èƒ½æˆä¸ºç ”ç©¶äººå‘˜å’Œå¼€å‘è€…çš„é‡è¦èµ„æºï¼Œä¿ƒè¿›ç›¸å…³é¢†åŸŸçš„è¿›æ­¥ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We introduce OLATverse, a large-scale dataset comprising around 9M images of 765 real-world objects, captured from multiple viewpoints under a diverse set of precisely controlled lighting conditions. While recent advances in object-centric inverse rendering, novel view synthesis and relighting have shown promising results, most techniques still heavily rely on the synthetic datasets for training and small-scale real-world datasets for benchmarking, which limits their realism and generalization. To address this gap, OLATverse offers two key advantages over existing datasets: large-scale coverage of real objects and high-fidelity appearance under precisely controlled illuminations. Specifically, OLATverse contains 765 common and uncommon real-world objects, spanning a wide range of material categories. Each object is captured using 35 DSLR cameras and 331 individually controlled light sources, enabling the simulation of diverse illumination conditions. In addition, for each object, we provide well-calibrated camera parameters, accurate object masks, photometric surface normals, and diffuse albedo as auxiliary resources. We also construct an extensive evaluation set, establishing the first comprehensive real-world object-centric benchmark for inverse rendering and normal estimation. We believe that OLATverse represents a pivotal step toward integrating the next generation of inverse rendering and relighting methods with real-world data. The full dataset, along with all post-processing workflows, will be publicly released at https://vcai.mpi-inf.mpg.de/projects/OLATverse/.

