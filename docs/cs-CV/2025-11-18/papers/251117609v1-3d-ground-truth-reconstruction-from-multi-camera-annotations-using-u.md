---
layout: default
title: 3D Ground Truth Reconstruction from Multi-Camera Annotations Using UKF
---

# 3D Ground Truth Reconstruction from Multi-Camera Annotations Using UKF

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.17609" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.17609v1</a>
  <a href="https://arxiv.org/pdf/2511.17609.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.17609v1" onclick="toggleFavorite(this, '2511.17609v1', '3D Ground Truth Reconstruction from Multi-Camera Annotations Using UKF')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Linh Van Ma, Unse Fatima, Tepy Sokun Chriv, Haroon Imran, Moongu Jeon

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-18

**å¤‡æ³¨**: International Conference on Control, Automation and Information Sciences (ICCAIS) 2025, October 27 - 29, 2025 \| Jeju, Korea

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§åŸºäºUKFçš„å¤šç›¸æœº2Dæ ‡æ³¨èåˆ3Dé‡å»ºæ–¹æ³•ï¼Œç”¨äºè‡ªåŠ¨é©¾é©¶ç­‰åœºæ™¯ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `3Dé‡å»º` `å¤šç›¸æœºç³»ç»Ÿ` `Unscented Kalman Filter` `2Dæ ‡æ³¨` `ç›®æ ‡è·Ÿè¸ª`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•éš¾ä»¥ä»å¤šç›¸æœº2Dæ ‡æ³¨ä¸­å‡†ç¡®é‡å»º3D ground truthï¼Œå°¤å…¶æ˜¯åœ¨å­˜åœ¨é®æŒ¡çš„æƒ…å†µä¸‹ã€‚
2. è¯¥æ–¹æ³•åˆ©ç”¨UKFèåˆå¤šç›¸æœº2Dæ ‡æ³¨ï¼Œé€šè¿‡å•åº”æ€§æŠ•å½±å°†2Dåæ ‡è½¬æ¢ä¸ºé²æ£’çš„3Dä¸–ç•Œåæ ‡ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨3Då®šä½æ–¹é¢å…·æœ‰é«˜ç²¾åº¦ï¼Œå¹¶èƒ½è¾“å‡ºç‰©ä½“çš„å®Œæ•´3Då½¢çŠ¶ï¼Œä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œåˆ©ç”¨Unscented Kalman Filter (UKF) å°†æ¥è‡ªå¤šä¸ªæ ¡å‡†ç›¸æœºçš„2D bounding boxæˆ–å§¿æ€å…³é”®ç‚¹æ ‡æ³¨èåˆä¸ºç²¾ç¡®çš„3D ground truthã€‚è¯¥æ–¹æ³•åˆ©ç”¨äººå·¥æ ‡æ³¨çš„2D ground truthï¼Œé€šè¿‡åŸºäºå•åº”æ€§çš„æŠ•å½±å’ŒåŸºäºUKFçš„èåˆï¼Œå°†2Då›¾åƒåæ ‡è½¬æ¢ä¸ºé²æ£’çš„3Dä¸–ç•Œåæ ‡ï¼Œå®ç°å¤šç›¸æœºå•ç›®æ ‡è·Ÿè¸ªã€‚è¯¥ç®—æ³•å¤„ç†å¤šè§†è§’æ•°æ®ä»¥ä¼°è®¡ç‰©ä½“çš„ä½ç½®å’Œå½¢çŠ¶ï¼ŒåŒæ—¶æœ‰æ•ˆå¤„ç†é®æŒ¡ç­‰æŒ‘æˆ˜ã€‚æˆ‘ä»¬åœ¨CMCã€Wildtrackå’ŒPanopticæ•°æ®é›†ä¸Šè¯„ä¼°äº†è¯¥æ–¹æ³•ï¼Œç»“æœè¡¨æ˜ï¼Œä¸ç°æœ‰çš„3D ground truthç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨3Då®šä½æ–¹é¢å…·æœ‰å¾ˆé«˜çš„ç²¾åº¦ã€‚ä¸ä»…æä¾›åœ°é¢ä¿¡æ¯çš„ç°æœ‰æ–¹æ³•ä¸åŒï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¿˜è¾“å‡ºæ¯ä¸ªç‰©ä½“çš„å®Œæ•´3Då½¢çŠ¶ã€‚æ­¤å¤–ï¼Œè¯¥ç®—æ³•ä¸ºå¤šç›¸æœºç³»ç»Ÿæä¾›äº†ä¸€ä¸ªå¯æ‰©å±•ä¸”å®Œå…¨è‡ªåŠ¨åŒ–çš„è§£å†³æ–¹æ¡ˆï¼Œä»…ä½¿ç”¨2Då›¾åƒæ ‡æ³¨ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ä»å¤šç›¸æœºç³»ç»Ÿçš„2Då›¾åƒæ ‡æ³¨ä¸­å‡†ç¡®é‡å»º3D ground truthçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸åªæä¾›åœ°é¢ä¿¡æ¯ï¼Œæ— æ³•æä¾›ç‰©ä½“çš„å®Œæ•´3Då½¢çŠ¶ï¼Œå¹¶ä¸”åœ¨å¤„ç†é®æŒ¡ç­‰é—®é¢˜æ—¶è¡¨ç°ä¸ä½³ã€‚æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•å¯èƒ½éœ€è¦å¤æ‚çš„æ ‡å®šæˆ–äººå·¥å¹²é¢„ï¼Œéš¾ä»¥å®ç°è‡ªåŠ¨åŒ–å’Œæ‰©å±•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨Unscented Kalman Filter (UKF) èåˆæ¥è‡ªå¤šä¸ªæ ¡å‡†ç›¸æœºçš„2Dæ ‡æ³¨ä¿¡æ¯ï¼Œä»è€Œä¼°è®¡å‡ºç²¾ç¡®çš„3Dç‰©ä½“ä½ç½®å’Œå½¢çŠ¶ã€‚é€šè¿‡å°†2Då›¾åƒåæ ‡æŠ•å½±åˆ°3Dä¸–ç•Œåæ ‡ç³»ï¼Œå¹¶åˆ©ç”¨UKFè¿›è¡ŒçŠ¶æ€ä¼°è®¡å’Œå™ªå£°æŠ‘åˆ¶ï¼Œå¯ä»¥æœ‰æ•ˆåœ°å¤„ç†å¤šè§†è§’æ•°æ®ä¸­çš„ä¸ç¡®å®šæ€§å’Œé®æŒ¡é—®é¢˜ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) 2Dæ ‡æ³¨è·å–ï¼šä»å¤šä¸ªæ ¡å‡†ç›¸æœºè·å–2D bounding boxæˆ–å§¿æ€å…³é”®ç‚¹æ ‡æ³¨ã€‚2) å•åº”æ€§æŠ•å½±ï¼šåˆ©ç”¨ç›¸æœºå†…å¤–å‚æ•°å’Œå•åº”æ€§çŸ©é˜µï¼Œå°†2Då›¾åƒåæ ‡æŠ•å½±åˆ°3Dä¸–ç•Œåæ ‡ç³»ã€‚3) UKFèåˆï¼šä½¿ç”¨UKFå°†æ¥è‡ªä¸åŒç›¸æœºçš„3Dåæ ‡ä¼°è®¡è¿›è¡Œèåˆï¼Œå¾—åˆ°æœ€ç»ˆçš„3Dç‰©ä½“ä½ç½®å’Œå½¢çŠ¶ä¼°è®¡ã€‚4) çŠ¶æ€æ›´æ–°ï¼šæ ¹æ®UKFçš„é¢„æµ‹å’Œæ›´æ–°æ­¥éª¤ï¼Œä¸æ–­ä¼˜åŒ–3Dç‰©ä½“çŠ¶æ€ä¼°è®¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•çš„ä¸»è¦åˆ›æ–°åœ¨äºåˆ©ç”¨UKFæ¡†æ¶æœ‰æ•ˆåœ°èåˆäº†å¤šç›¸æœº2Dæ ‡æ³¨ä¿¡æ¯ï¼Œä»è€Œå®ç°äº†ç²¾ç¡®çš„3D ground truthé‡å»ºã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•ä¸ä»…å¯ä»¥æä¾›ç‰©ä½“çš„3Dä½ç½®ï¼Œè¿˜å¯ä»¥ä¼°è®¡ç‰©ä½“çš„å®Œæ•´3Då½¢çŠ¶ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•å…·æœ‰å¯æ‰©å±•æ€§å’Œè‡ªåŠ¨åŒ–ç‰¹æ€§ï¼Œåªéœ€2Då›¾åƒæ ‡æ³¨å³å¯å®ç°å¤šç›¸æœºç³»ç»Ÿçš„3Dé‡å»ºã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨UKFæ¡†æ¶ä¸­ï¼Œéœ€è¦é€‰æ‹©åˆé€‚çš„çŠ¶æ€å‘é‡ã€è¿‡ç¨‹å™ªå£°å’Œè§‚æµ‹å™ªå£°ã€‚çŠ¶æ€å‘é‡å¯ä»¥åŒ…å«ç‰©ä½“çš„ä½ç½®ã€é€Ÿåº¦å’Œå½¢çŠ¶å‚æ•°ã€‚è¿‡ç¨‹å™ªå£°ç”¨äºæ¨¡æ‹Ÿç‰©ä½“è¿åŠ¨çš„ä¸ç¡®å®šæ€§ï¼Œè§‚æµ‹å™ªå£°ç”¨äºæ¨¡æ‹Ÿ2Dæ ‡æ³¨çš„è¯¯å·®ã€‚æ­¤å¤–ï¼Œå•åº”æ€§çŸ©é˜µçš„è®¡ç®—ç²¾åº¦ä¹Ÿä¼šå½±å“æœ€ç»ˆçš„3Dé‡å»ºç»“æœã€‚è®ºæ–‡å¯èƒ½è¿˜æ¶‰åŠä¸€äº›å‚æ•°è°ƒä¼˜ï¼Œä¾‹å¦‚UKFçš„å‚æ•°è®¾ç½®ï¼Œä»¥åŠå•åº”æ€§çŸ©é˜µçš„é²æ£’ä¼°è®¡æ–¹æ³•ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥æ–¹æ³•åœ¨CMCã€Wildtrackå’ŒPanopticæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼Œä¸ç°æœ‰çš„3D ground truthç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨3Då®šä½æ–¹é¢å…·æœ‰å¾ˆé«˜çš„ç²¾åº¦ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿè¾“å‡ºç‰©ä½“çš„å®Œæ•´3Då½¢çŠ¶ï¼Œè€Œä¸ä»…ä»…æ˜¯åœ°é¢ä¿¡æ¯ï¼Œè¿™ä¸ºåç»­çš„åº”ç”¨æä¾›äº†æ›´ä¸°å¯Œçš„ä¿¡æ¯ã€‚å®éªŒç»“æœéªŒè¯äº†è¯¥æ–¹æ³•åœ¨å¤šç›¸æœº3Dé‡å»ºæ–¹é¢çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½ç›‘æ§ã€æœºå™¨äººç­‰é¢†åŸŸã€‚åœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼Œå¯ä»¥åˆ©ç”¨è¯¥æ–¹æ³•ä»å¤šç›¸æœºæ•°æ®ä¸­é‡å»ºå‘¨å›´ç¯å¢ƒçš„3Dæ¨¡å‹ï¼Œæé«˜è½¦è¾†çš„æ„ŸçŸ¥èƒ½åŠ›å’Œå®‰å…¨æ€§ã€‚åœ¨æ™ºèƒ½ç›‘æ§ä¸­ï¼Œå¯ä»¥ç”¨äºè·Ÿè¸ªå’Œè¯†åˆ«äººç¾¤ä¸­çš„ç›®æ ‡ï¼Œå®ç°æ›´æ™ºèƒ½çš„ç›‘æ§ç³»ç»Ÿã€‚åœ¨æœºå™¨äººé¢†åŸŸï¼Œå¯ä»¥å¸®åŠ©æœºå™¨äººæ›´å¥½åœ°ç†è§£å’Œæ“ä½œå‘¨å›´ç¯å¢ƒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Accurate 3D ground truth estimation is critical for applications such as autonomous navigation, surveillance, and robotics. This paper introduces a novel method that uses an Unscented Kalman Filter (UKF) to fuse 2D bounding box or pose keypoint ground truth annotations from multiple calibrated cameras into accurate 3D ground truth. By leveraging human-annotated ground-truth 2D, our proposed method, a multi-camera single-object tracking algorithm, transforms 2D image coordinates into robust 3D world coordinates through homography-based projection and UKF-based fusion. Our proposed algorithm processes multi-view data to estimate object positions and shapes while effectively handling challenges such as occlusion. We evaluate our method on the CMC, Wildtrack, and Panoptic datasets, demonstrating high accuracy in 3D localization compared to the available 3D ground truth. Unlike existing approaches that provide only ground-plane information, our method also outputs the full 3D shape of each object. Additionally, the algorithm offers a scalable and fully automatic solution for multi-camera systems using only 2D image annotations.

