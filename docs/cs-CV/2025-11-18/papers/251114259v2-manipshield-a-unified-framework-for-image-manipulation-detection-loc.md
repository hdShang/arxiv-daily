---
layout: default
title: ManipShield: A Unified Framework for Image Manipulation Detection, Localization and Explanation
---

# ManipShield: A Unified Framework for Image Manipulation Detection, Localization and Explanation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.14259" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.14259v2</a>
  <a href="https://arxiv.org/pdf/2511.14259.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.14259v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.14259v2', 'ManipShield: A Unified Framework for Image Manipulation Detection, Localization and Explanation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zitong Xu, Huiyu Duan, Xiaoyu Wang, Zhaolin Cai, Kaiwei Zhang, Qiang Hu, Jing Liu, Xiongkuo Min, Guangtao Zhai

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-18 (æ›´æ–°: 2025-11-25)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºManipShieldï¼Œä¸€ä¸ªç»Ÿä¸€çš„å›¾åƒç¯¡æ”¹æ£€æµ‹ã€å®šä½å’Œè§£é‡Šæ¡†æ¶ï¼Œå¹¶æ„å»ºå¤§è§„æ¨¡åŸºå‡†æµ‹è¯•é›†ManipBenchã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `å›¾åƒç¯¡æ”¹æ£€æµ‹` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `å¯¹æ¯”å­¦ä¹ ` `LoRAå¾®è°ƒ` `å¯è§£é‡Šæ€§` `ManipBench` `å›¾åƒå®šä½` `æ•°å­—å–è¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å›¾åƒç¯¡æ”¹æ£€æµ‹æ–¹æ³•åœ¨å†…å®¹å¤šæ ·æ€§ã€æ¨¡å‹è¦†ç›–å’Œå¯è§£é‡Šæ€§æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œé™åˆ¶äº†å…¶æ³›åŒ–èƒ½åŠ›ã€‚
2. æå‡ºManipShieldï¼Œåˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼Œé€šè¿‡å¯¹æ¯”LoRAå¾®è°ƒå’Œä»»åŠ¡ç‰¹å®šè§£ç å™¨ï¼Œå®ç°ç¯¡æ”¹æ£€æµ‹ã€å®šä½å’Œè§£é‡Šçš„ç»Ÿä¸€ã€‚
3. åœ¨ManipBenchå’Œå…¬å…±æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒManipShieldè¾¾åˆ°äº†SOTAæ€§èƒ½ï¼Œå¹¶å¯¹æœªè§è¿‡çš„ç¯¡æ”¹æ¨¡å‹å…·æœ‰è‰¯å¥½çš„æ³›åŒ–æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€ç”Ÿæˆæ¨¡å‹çš„å¿«é€Ÿå‘å±•ï¼Œå¼ºå¤§çš„å›¾åƒç¼–è¾‘æ–¹æ³•èƒ½å¤Ÿå®ç°å¤šæ ·ä¸”é«˜åº¦é€¼çœŸçš„å›¾åƒç¯¡æ”¹ï¼Œè¿™ç»™ç¯¡æ”¹æ£€æµ‹å¸¦æ¥äº†æ–°çš„æŒ‘æˆ˜ï¼Œè¿œè¶…ä¼ ç»Ÿçš„æ·±åº¦ä¼ªé€ æŠ€æœ¯ã€‚ç°æœ‰çš„å›¾åƒç¯¡æ”¹æ£€æµ‹å’Œå®šä½(IMDL)åŸºå‡†æµ‹è¯•åœ¨å†…å®¹å¤šæ ·æ€§ã€ç”Ÿæˆæ¨¡å‹è¦†ç›–èŒƒå›´å’Œå¯è§£é‡Šæ€§æ–¹é¢å­˜åœ¨å±€é™æ€§ï¼Œé˜»ç¢äº†å½“å‰ç¯¡æ”¹æ£€æµ‹æ–¹æ³•çš„æ³›åŒ–å’Œè§£é‡Šèƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†ManipBenchï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“æ³¨äºAIç¼–è¾‘å›¾åƒçš„å¤§è§„æ¨¡å›¾åƒç¯¡æ”¹æ£€æµ‹å’Œå®šä½åŸºå‡†ã€‚ManipBenchåŒ…å«è¶…è¿‡45ä¸‡å¼ ç”±25ä¸ªæœ€å…ˆè¿›çš„å›¾åƒç¼–è¾‘æ¨¡å‹ç”Ÿæˆçš„ç¯¡æ”¹å›¾åƒï¼Œæ¶µç›–12ä¸ªç¯¡æ”¹ç±»åˆ«ï¼Œå…¶ä¸­10ä¸‡å¼ å›¾åƒè¿˜æ ‡æ³¨äº†è¾¹ç•Œæ¡†ã€åˆ¤æ–­çº¿ç´¢å’Œæ–‡æœ¬è§£é‡Šï¼Œä»¥æ”¯æŒå¯è§£é‡Šçš„æ£€æµ‹ã€‚åŸºäºManipBenchï¼Œæˆ‘ä»¬æå‡ºäº†ManipShieldï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹(MLLM)çš„ä¸€ä½“åŒ–æ¨¡å‹ï¼Œå®ƒåˆ©ç”¨å¯¹æ¯”LoRAå¾®è°ƒå’Œç‰¹å®šä»»åŠ¡è§£ç å™¨æ¥å®ç°ç»Ÿä¸€çš„å›¾åƒç¯¡æ”¹æ£€æµ‹ã€å®šä½å’Œè§£é‡Šã€‚åœ¨ManipBenchå’Œå¤šä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒManipShieldå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶å¯¹æœªè§è¿‡çš„ç¯¡æ”¹æ¨¡å‹è¡¨ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚ManipBenchå’ŒManipShieldå°†åœ¨å‘è¡¨åå‘å¸ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰å›¾åƒç¯¡æ”¹æ£€æµ‹æ–¹æ³•éš¾ä»¥åº”å¯¹æ–°å‹AIç¼–è¾‘å·¥å…·ç”Ÿæˆçš„é«˜åº¦é€¼çœŸç¯¡æ”¹å›¾åƒï¼Œä¸”ç¼ºä¹è¶³å¤Ÿçš„å†…å®¹å¤šæ ·æ€§å’Œå¯è§£é‡Šæ€§ï¼Œå¯¼è‡´æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚ç°æœ‰çš„æ•°æ®é›†ä¹Ÿéš¾ä»¥è¦†ç›–å„ç§ç¯¡æ”¹ç±»å‹å’Œç”Ÿæˆæ¨¡å‹ï¼Œé™åˆ¶äº†ç®—æ³•çš„è®­ç»ƒå’Œè¯„ä¼°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šåˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰çš„å¼ºå¤§èƒ½åŠ›ï¼Œå°†å›¾åƒç¯¡æ”¹æ£€æµ‹ã€å®šä½å’Œè§£é‡Šç»Ÿä¸€åˆ°ä¸€ä¸ªæ¡†æ¶ä¸­ã€‚é€šè¿‡å¯¹æ¯”å­¦ä¹ å¢å¼ºæ¨¡å‹å¯¹ç¯¡æ”¹åŒºåŸŸçš„æ„ŸçŸ¥èƒ½åŠ›ï¼Œå¹¶åˆ©ç”¨LoRAè¿›è¡Œé«˜æ•ˆå¾®è°ƒï¼Œä½¿å…¶é€‚åº”ç‰¹å®šçš„ç¯¡æ”¹æ£€æµ‹ä»»åŠ¡ã€‚ä»»åŠ¡ç‰¹å®šçš„è§£ç å™¨åˆ™è´Ÿè´£è¾“å‡ºæ£€æµ‹ç»“æœã€å®šä½ä¿¡æ¯å’Œè§£é‡Šæ–‡æœ¬ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šManipShieldçš„æ ¸å¿ƒæ˜¯ä¸€ä¸ªå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼Œè¾“å…¥åŒ…æ‹¬å›¾åƒå’Œæ–‡æœ¬æç¤ºã€‚æ•´ä½“æµç¨‹åŒ…æ‹¬ï¼š1) å›¾åƒç¼–ç å™¨æå–å›¾åƒç‰¹å¾ï¼›2) æ–‡æœ¬ç¼–ç å™¨å¤„ç†æ–‡æœ¬æç¤ºï¼›3) å¤šæ¨¡æ€èåˆæ¨¡å—å°†å›¾åƒå’Œæ–‡æœ¬ç‰¹å¾èåˆï¼›4) å¯¹æ¯”LoRAå¾®è°ƒæ¨¡å—ï¼Œå¢å¼ºæ¨¡å‹å¯¹ç¯¡æ”¹åŒºåŸŸçš„æ„ŸçŸ¥ï¼›5) ä»»åŠ¡ç‰¹å®šè§£ç å™¨ï¼Œåˆ†åˆ«ç”¨äºç¯¡æ”¹æ£€æµ‹ã€å®šä½å’Œè§£é‡Šã€‚

**å…³é”®åˆ›æ–°**ï¼šManipShieldçš„å…³é”®åˆ›æ–°åœ¨äºå°†å›¾åƒç¯¡æ”¹æ£€æµ‹ã€å®šä½å’Œè§£é‡Šç»Ÿä¸€åˆ°ä¸€ä¸ªåŸºäºMLLMçš„æ¡†æ¶ä¸­ï¼Œå¹¶åˆ©ç”¨å¯¹æ¯”LoRAå¾®è°ƒæ¥æé«˜æ¨¡å‹å¯¹ç¯¡æ”¹åŒºåŸŸçš„æ•æ„Ÿæ€§ã€‚ä¸ä¼ ç»Ÿçš„å›¾åƒç¯¡æ”¹æ£€æµ‹æ–¹æ³•ç›¸æ¯”ï¼ŒManipShieldèƒ½å¤Ÿæä¾›æ›´å…¨é¢çš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬ç¯¡æ”¹ç±»å‹ã€ä½ç½®å’ŒåŸå› ï¼Œä»è€Œæé«˜æ£€æµ‹çš„å¯ä¿¡åº¦å’Œå¯è§£é‡Šæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šå¯¹æ¯”LoRAå¾®è°ƒæ¨¡å—ä½¿ç”¨å¯¹æ¯”æŸå¤±å‡½æ•°ï¼Œé¼“åŠ±æ¨¡å‹åŒºåˆ†åŸå§‹å›¾åƒå’Œç¯¡æ”¹å›¾åƒã€‚ä»»åŠ¡ç‰¹å®šè§£ç å™¨åŒ…æ‹¬ï¼š1) åˆ†ç±»å™¨ï¼Œç”¨äºåˆ¤æ–­å›¾åƒæ˜¯å¦è¢«ç¯¡æ”¹ï¼›2) å›å½’å™¨ï¼Œç”¨äºé¢„æµ‹ç¯¡æ”¹åŒºåŸŸçš„è¾¹ç•Œæ¡†ï¼›3) æ–‡æœ¬ç”Ÿæˆå™¨ï¼Œç”¨äºç”Ÿæˆç¯¡æ”¹è§£é‡Šæ–‡æœ¬ã€‚å…·ä½“ç½‘ç»œç»“æ„å’Œå‚æ•°è®¾ç½®åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ManipShieldåœ¨ManipBenchå’Œå¤šä¸ªå…¬å…±æ•°æ®é›†ä¸Šå–å¾—äº†SOTAæ€§èƒ½ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒManipShieldèƒ½å¤Ÿå‡†ç¡®æ£€æµ‹å’Œå®šä½å„ç§ç±»å‹çš„å›¾åƒç¯¡æ”¹ï¼Œå¹¶æä¾›æœ‰æ„ä¹‰çš„è§£é‡Šã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒManipShieldåœ¨æ£€æµ‹ç²¾åº¦ã€å®šä½å‡†ç¡®æ€§å’Œè§£é‡Šè´¨é‡æ–¹é¢å‡æœ‰æ˜¾è‘—æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ManipShieldå¯åº”ç”¨äºæ•°å­—å–è¯ã€ç¤¾äº¤åª’ä½“å†…å®¹å®¡æ ¸ã€æ–°é—»çœŸå®æ€§éªŒè¯ç­‰é¢†åŸŸã€‚å®ƒå¯ä»¥å¸®åŠ©è¯†åˆ«å’Œå®šä½è¢«ç¯¡æ”¹çš„å›¾åƒï¼Œé˜²æ­¢è™šå‡ä¿¡æ¯çš„ä¼ æ’­ï¼Œç»´æŠ¤ç½‘ç»œå®‰å…¨å’Œä¿¡æ¯å®‰å…¨ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯å¯ä»¥è¿›ä¸€æ­¥æ‰©å±•åˆ°è§†é¢‘ç¯¡æ”¹æ£€æµ‹ï¼Œå¹¶ä¸å…¶ä»–å®‰å…¨æŠ€æœ¯ç›¸ç»“åˆï¼Œæ„å»ºæ›´å¼ºå¤§çš„å®‰å…¨é˜²æŠ¤ä½“ç³»ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> With the rapid advancement of generative models, powerful image editing methods now enable diverse and highly realistic image manipulations that far surpass traditional deepfake techniques, posing new challenges for manipulation detection. Existing image manipulation detection and localization (IMDL) benchmarks suffer from limited content diversity, narrow generative-model coverage, and insufficient interpretability, which hinders the generalization and explanation capabilities of current manipulation detection methods. To address these limitations, we introduce \textbf{ManipBench}, a large-scale benchmark for image manipulation detection and localization focusing on AI-edited images. ManipBench contains over 450K manipulated images produced by 25 state-of-the-art image editing models across 12 manipulation categories, among which 100K images are further annotated with bounding boxes, judgment cues, and textual explanations to support interpretable detection. Building upon ManipBench, we propose \textbf{ManipShield}, an all-in-one model based on a Multimodal Large Language Model (MLLM) that leverages contrastive LoRA fine-tuning and task-specific decoders to achieve unified image manipulation detection, localization, and explanation. Extensive experiments on ManipBench and several public datasets demonstrate that ManipShield achieves state-of-the-art performance and exhibits strong generality to unseen manipulation models. Both ManipBench and ManipShield will be released upon publication.

