---
layout: default
title: Learning Depth from Past Selves: Self-Evolution Contrast for Robust Depth Estimation
---

# Learning Depth from Past Selves: Self-Evolution Contrast for Robust Depth Estimation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.15167" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.15167v1</a>
  <a href="https://arxiv.org/pdf/2511.15167.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.15167v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.15167v1', 'Learning Depth from Past Selves: Self-Evolution Contrast for Robust Depth Estimation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jing Cao, Kui Jiang, Shenyi Li, Xiaocheng Feng, Yong Huang

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-19

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè‡ªè¿›åŒ–å¯¹æ¯”å­¦ä¹ æ¡†æ¶SEC-Depthï¼Œæå‡æ¶åŠ£å¤©æ°”ä¸‹è‡ªç›‘ç£æ·±åº¦ä¼°è®¡çš„é²æ£’æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `è‡ªç›‘ç£æ·±åº¦ä¼°è®¡` `é²æ£’æ€§` `å¯¹æ¯”å­¦ä¹ ` `æ¶åŠ£å¤©æ°”` `è‡ªè¿›åŒ–å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è‡ªç›‘ç£æ·±åº¦ä¼°è®¡æ–¹æ³•åœ¨æ¶åŠ£å¤©æ°”ä¸‹æ€§èƒ½å¤§å¹…ä¸‹é™ï¼ŒåŸå› æ˜¯èƒ½è§åº¦é™ä½å¯¼è‡´æ·±åº¦é¢„æµ‹å›°éš¾ã€‚
2. è®ºæ–‡æå‡ºè‡ªè¿›åŒ–å¯¹æ¯”å­¦ä¹ æ¡†æ¶SEC-Depthï¼Œåˆ©ç”¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„ä¸­é—´å‚æ•°æ„å»ºæ—¶é—´æ¼”åŒ–çš„æ½œåœ¨æ¨¡å‹ï¼Œæå‡é²æ£’æ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½æ— ç¼é›†æˆåˆ°å¤šç§åŸºçº¿æ¨¡å‹ä¸­ï¼Œå¹¶åœ¨é›¶æ ·æœ¬è¯„ä¼°ä¸­æ˜¾è‘—æå‡æ¶åŠ£å¤©æ°”ä¸‹çš„æ·±åº¦ä¼°è®¡æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è‡ªç›‘ç£æ·±åº¦ä¼°è®¡åœ¨è‡ªåŠ¨é©¾é©¶å’Œæœºå™¨äººé¢†åŸŸå¤‡å—å…³æ³¨ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•åœ¨é›¨ã€é›¾ç­‰æ¶åŠ£å¤©æ°”æ¡ä»¶ä¸‹æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œèƒ½è§åº¦é™ä½ä¸¥é‡å½±å“æ·±åº¦é¢„æµ‹ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„è‡ªè¿›åŒ–å¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œç§°ä¸ºSEC-Depthï¼Œç”¨äºè‡ªç›‘ç£é²æ£’æ·±åº¦ä¼°è®¡ä»»åŠ¡ã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨è®­ç»ƒè¿‡ç¨‹ä¸­ç”Ÿæˆçš„ä¸­é—´å‚æ•°æ¥æ„å»ºæ—¶é—´æ¼”åŒ–çš„æ½œåœ¨æ¨¡å‹ã€‚åˆ©ç”¨è¿™äº›æ¨¡å‹ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§è‡ªè¿›åŒ–å¯¹æ¯”æ–¹æ¡ˆï¼Œä»¥å‡è½»åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ¡ä»¶ä¸‹çš„æ€§èƒ½æŸå¤±ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬é¦–å…ˆä¸ºæ·±åº¦ä¼°è®¡ä»»åŠ¡è®¾è®¡äº†ä¸€ç§æ½œåœ¨æ¨¡å‹çš„åŠ¨æ€æ›´æ–°ç­–ç•¥ï¼Œä»¥æ•è·è·¨è®­ç»ƒé˜¶æ®µçš„ä¼˜åŒ–çŠ¶æ€ã€‚ä¸ºäº†æœ‰æ•ˆåœ°åˆ©ç”¨æ½œåœ¨æ¨¡å‹ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§è‡ªè¿›åŒ–å¯¹æ¯”æŸå¤±ï¼ˆSECLï¼‰ï¼Œå°†å†å²æ½œåœ¨æ¨¡å‹çš„è¾“å‡ºè§†ä¸ºè´Ÿæ ·æœ¬ã€‚è¿™ç§æœºåˆ¶è‡ªé€‚åº”åœ°è°ƒæ•´å­¦ä¹ ç›®æ ‡ï¼ŒåŒæ—¶éšå¼åœ°æ„ŸçŸ¥å¤©æ°”é€€åŒ–ç¨‹åº¦ï¼Œå‡å°‘äº†æ‰‹åŠ¨å¹²é¢„çš„éœ€æ±‚ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥æ— ç¼é›†æˆåˆ°ä¸åŒçš„åŸºçº¿æ¨¡å‹ä¸­ï¼Œå¹¶æ˜¾è‘—æé«˜é›¶æ ·æœ¬è¯„ä¼°çš„é²æ£’æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰è‡ªç›‘ç£æ·±åº¦ä¼°è®¡æ–¹æ³•åœ¨æ¶åŠ£å¤©æ°”ï¼ˆå¦‚é›¨ã€é›¾ï¼‰ä¸‹æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚è¿™äº›å¤©æ°”æ¡ä»¶é™ä½äº†å›¾åƒçš„èƒ½è§åº¦ï¼Œä½¿å¾—æ·±åº¦é¢„æµ‹å˜å¾—æ›´åŠ å›°éš¾ï¼Œä¸¥é‡å½±å“äº†è‡ªåŠ¨é©¾é©¶å’Œæœºå™¨äººç­‰åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­çš„å†å²çŠ¶æ€ï¼ˆå³ä¸­é—´å‚æ•°ï¼‰æ„å»ºä¸€ç³»åˆ—â€œæ½œåœ¨æ¨¡å‹â€ï¼Œå¹¶å°†è¿™äº›æ½œåœ¨æ¨¡å‹çš„è¾“å‡ºä½œä¸ºè´Ÿæ ·æœ¬ï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ çš„æ–¹å¼ï¼Œæå‡æ¨¡å‹åœ¨æ¶åŠ£å¤©æ°”ä¸‹çš„é²æ£’æ€§ã€‚è¿™ç§æ–¹æ³•æ¨¡æ‹Ÿäº†æ¨¡å‹åœ¨ä¸åŒè®­ç»ƒé˜¶æ®µå¯¹æ¶åŠ£å¤©æ°”çš„é€‚åº”è¿‡ç¨‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSEC-Depthæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªå…³é”®æ¨¡å—ï¼š1) åŠ¨æ€æ›´æ–°çš„æ½œåœ¨æ¨¡å‹ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå®šæœŸä¿å­˜æ¨¡å‹çš„ä¸­é—´å‚æ•°ï¼Œå½¢æˆä¸€ç³»åˆ—æ½œåœ¨æ¨¡å‹ã€‚2) è‡ªè¿›åŒ–å¯¹æ¯”æŸå¤±ï¼ˆSECLï¼‰ï¼šå°†å½“å‰æ¨¡å‹çš„è¾“å‡ºä¸å†å²æ½œåœ¨æ¨¡å‹çš„è¾“å‡ºè¿›è¡Œå¯¹æ¯”ï¼Œæ„å»ºå¯¹æ¯”æŸå¤±ï¼Œä¿ƒä½¿æ¨¡å‹å­¦ä¹ å¯¹æ¶åŠ£å¤©æ°”æ›´é²æ£’çš„ç‰¹å¾è¡¨ç¤ºã€‚3) é›†æˆåˆ°ç°æœ‰åŸºçº¿æ¨¡å‹ï¼šSEC-Depthå¯ä»¥ä½œä¸ºä¸€ä¸ªæ¨¡å—ï¼Œæ— ç¼é›†æˆåˆ°ç°æœ‰çš„è‡ªç›‘ç£æ·±åº¦ä¼°è®¡æ¨¡å‹ä¸­ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºåˆ©ç”¨æ¨¡å‹è‡ªèº«çš„å†å²çŠ¶æ€è¿›è¡Œå¯¹æ¯”å­¦ä¹ ï¼Œè€Œä¸æ˜¯ä¾èµ–äºé¢å¤–çš„æ•°æ®å¢å¼ºæˆ–é¢†åŸŸè‡ªé€‚åº”æŠ€æœ¯ã€‚é€šè¿‡è¿™ç§è‡ªè¿›åŒ–å¯¹æ¯”çš„æ–¹å¼ï¼Œæ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°å­¦ä¹ åˆ°å¯¹æ¶åŠ£å¤©æ°”ä¸æ•æ„Ÿçš„ç‰¹å¾è¡¨ç¤ºï¼Œä»è€Œæå‡é²æ£’æ€§ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒSEC-Depthä¸éœ€è¦æ‰‹åŠ¨å¹²é¢„æˆ–è°ƒæ•´å‚æ•°ï¼Œèƒ½å¤Ÿè‡ªé€‚åº”åœ°æ„ŸçŸ¥å¤©æ°”é€€åŒ–ç¨‹åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼š1) æ½œåœ¨æ¨¡å‹çš„åŠ¨æ€æ›´æ–°ç­–ç•¥ï¼šè®ºæ–‡è®¾è®¡äº†ä¸€ç§åŠ¨æ€æ›´æ–°ç­–ç•¥ï¼Œç”¨äºé€‰æ‹©åˆé€‚çš„ä¸­é—´å‚æ•°ä½œä¸ºæ½œåœ¨æ¨¡å‹ã€‚2) è‡ªè¿›åŒ–å¯¹æ¯”æŸå¤±ï¼ˆSECLï¼‰ï¼šSECLçš„è®¾è®¡è€ƒè™‘äº†ä¸åŒæ½œåœ¨æ¨¡å‹çš„è¾“å‡ºä¹‹é—´çš„ç›¸ä¼¼æ€§ï¼Œå¹¶æ ¹æ®ç›¸ä¼¼æ€§è°ƒæ•´å¯¹æ¯”æŸå¤±çš„æƒé‡ã€‚3) æŸå¤±å‡½æ•°çš„æƒé‡ï¼šè®ºæ–‡å¯èƒ½ä½¿ç”¨äº†é¢å¤–çš„æƒé‡æ¥å¹³è¡¡SECLå’Œå…¶ä»–æŸå¤±å‡½æ•°ï¼ˆå¦‚å…‰åº¦ä¸€è‡´æ€§æŸå¤±ï¼‰ä¹‹é—´çš„è´¡çŒ®ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒSEC-Depthèƒ½å¤Ÿæ˜¾è‘—æå‡è‡ªç›‘ç£æ·±åº¦ä¼°è®¡æ¨¡å‹åœ¨æ¶åŠ£å¤©æ°”ä¸‹çš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨é›¶æ ·æœ¬è¯„ä¼°ä¸­ï¼ŒSEC-Depthèƒ½å¤Ÿå°†æ·±åº¦ä¼°è®¡çš„è¯¯å·®é™ä½XX%ï¼ˆå…·ä½“æ•°å€¼éœ€è¦åœ¨è®ºæ–‡ä¸­æŸ¥æ‰¾ï¼‰ï¼Œå¹¶ä¸”èƒ½å¤Ÿä¸å¤šç§åŸºçº¿æ¨¡å‹æ— ç¼é›†æˆï¼Œå±•ç°äº†è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€æ— äººæœºç­‰é¢†åŸŸï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚å’Œæ¶åŠ£å¤©æ°”æ¡ä»¶ä¸‹ã€‚é€šè¿‡æé«˜æ·±åº¦ä¼°è®¡çš„é²æ£’æ€§ï¼Œå¯ä»¥å¢å¼ºè¿™äº›ç³»ç»Ÿåœ¨å„ç§ç¯å¢ƒä¸‹çš„æ„ŸçŸ¥èƒ½åŠ›å’Œå®‰å…¨æ€§ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›è¿›ä¸€æ­¥æ‰©å±•åˆ°å…¶ä»–æ„ŸçŸ¥ä»»åŠ¡ï¼Œå¦‚è¯­ä¹‰åˆ†å‰²å’Œç›®æ ‡æ£€æµ‹ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Self-supervised depth estimation has gained significant attention in autonomous driving and robotics. However, existing methods exhibit substantial performance degradation under adverse weather conditions such as rain and fog, where reduced visibility critically impairs depth prediction. To address this issue, we propose a novel self-evolution contrastive learning framework called SEC-Depth for self-supervised robust depth estimation tasks. Our approach leverages intermediate parameters generated during training to construct temporally evolving latency models. Using these, we design a self-evolution contrastive scheme to mitigate performance loss under challenging conditions. Concretely, we first design a dynamic update strategy of latency models for the depth estimation task to capture optimization states across training stages. To effectively leverage latency models, we introduce a self-evolution contrastive Loss (SECL) that treats outputs from historical latency models as negative samples. This mechanism adaptively adjusts learning objectives while implicitly sensing weather degradation severity, reducing the needs for manual intervention. Experiments show that our method integrates seamlessly into diverse baseline models and significantly enhances robustness in zero-shot evaluations.

