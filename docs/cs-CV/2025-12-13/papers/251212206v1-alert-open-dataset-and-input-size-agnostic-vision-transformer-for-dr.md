---
layout: default
title: ALERT Open Dataset and Input-Size-Agnostic Vision Transformer for Driver Activity Recognition using IR-UWB
---

# ALERT Open Dataset and Input-Size-Agnostic Vision Transformer for Driver Activity Recognition using IR-UWB

**arXiv**: [2512.12206v1](https://arxiv.org/abs/2512.12206) | [PDF](https://arxiv.org/pdf/2512.12206.pdf)

**ä½œè€…**: Jeongjun Park, Sunwook Hwang, Hyeonho Noh, Jin Mo Yang, Hyun Jong Yang, Saewoong Bahk

**åˆ†ç±»**: cs.CV, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-12-13

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºISA-ViTå’ŒALERTæ•°æ®é›†ï¼Œç”¨äºŽè§£å†³åŸºäºŽIR-UWBé›·è¾¾çš„é©¾é©¶å‘˜è¡Œä¸ºè¯†åˆ«é—®é¢˜**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `é©¾é©¶å‘˜è¡Œä¸ºè¯†åˆ«` `IR-UWBé›·è¾¾` `Vision Transformer` `è¾“å…¥å°ºå¯¸æ— å…³` `é¢†åŸŸèžåˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰åŸºäºŽIR-UWBé›·è¾¾çš„é©¾é©¶å‘˜è¡Œä¸ºè¯†åˆ«æ–¹æ³•ç¼ºä¹å¤§è§„æ¨¡çœŸå®žæ•°æ®é›†ï¼Œä¸”å›ºå®šè¾“å…¥å°ºå¯¸çš„ViTéš¾ä»¥é€‚åº”éžæ ‡å‡†å°ºå¯¸çš„UWBé›·è¾¾æ•°æ®ã€‚
2. è®ºæ–‡æå‡ºISA-ViTæ¡†æž¶ï¼Œé€šè¿‡è°ƒæ•´patché…ç½®å’Œåˆ©ç”¨é¢„è®­ç»ƒçš„ä½ç½®åµŒå…¥å‘é‡ï¼Œä½¿ViTèƒ½å¤Ÿå¤„ç†ä»»æ„å°ºå¯¸çš„UWBé›·è¾¾æ•°æ®ï¼Œå¹¶èžåˆè·ç¦»åŸŸå’Œé¢‘çŽ‡åŸŸç‰¹å¾ã€‚
3. å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒISA-ViTåœ¨UWBé›·è¾¾é©¾é©¶å‘˜è¡Œä¸ºè¯†åˆ«ä»»åŠ¡ä¸Šï¼Œç›¸æ¯”çŽ°æœ‰ViTæ–¹æ³•ï¼Œå‡†ç¡®çŽ‡æå‡äº†22.68%ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åˆ†å¿ƒé©¾é©¶æ˜¯å…¨çƒè‡´å‘½è½¦ç¥¸çš„é‡è¦åŽŸå› ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œç ”ç©¶äººå‘˜æ­£åœ¨ä½¿ç”¨åŸºäºŽè„‰å†²æ— çº¿ç”µè¶…å®½å¸¦(IR-UWB)é›·è¾¾çš„é©¾é©¶å‘˜è¡Œä¸ºè¯†åˆ«(DAR)æŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯å…·æœ‰æŠ—å¹²æ‰°ã€ä½ŽåŠŸè€—å’Œä¿æŠ¤éšç§ç­‰ä¼˜ç‚¹ã€‚ç„¶è€Œï¼Œä¸¤ä¸ªæŒ‘æˆ˜é™åˆ¶äº†å®ƒçš„åº”ç”¨ï¼šç¼ºä¹æ¶µç›–å„ç§åˆ†å¿ƒé©¾é©¶è¡Œä¸ºçš„å¤§è§„æ¨¡çœŸå®žUWBæ•°æ®é›†ï¼Œä»¥åŠéš¾ä»¥å°†å›ºå®šè¾“å…¥çš„Vision Transformers (ViTs)åº”ç”¨äºŽå…·æœ‰éžæ ‡å‡†å°ºå¯¸çš„UWBé›·è¾¾æ•°æ®ã€‚æœ¬ç ”ç©¶æ—¨åœ¨è§£å†³è¿™ä¸¤ä¸ªæŒ‘æˆ˜ã€‚æˆ‘ä»¬æå‡ºäº†ALERTæ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«åœ¨çœŸå®žé©¾é©¶æ¡ä»¶ä¸‹æ”¶é›†çš„ä¸ƒç§åˆ†å¿ƒé©¾é©¶æ´»åŠ¨çš„10220ä¸ªé›·è¾¾æ ·æœ¬ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§è¾“å…¥å°ºå¯¸æ— å…³çš„Vision Transformer (ISA-ViT)æ¡†æž¶ï¼Œä¸“ä¸ºåŸºäºŽé›·è¾¾çš„DARè®¾è®¡ã€‚æ‰€æå‡ºçš„æ–¹æ³•è°ƒæ•´UWBæ•°æ®çš„å¤§å°ä»¥æ»¡è¶³ViTè¾“å…¥è¦æ±‚ï¼ŒåŒæ—¶ä¿ç•™é›·è¾¾ç‰¹å®šçš„ä¿¡æ¯ï¼Œå¦‚å¤šæ™®å‹’é¢‘ç§»å’Œç›¸ä½ç‰¹æ€§ã€‚é€šè¿‡è°ƒæ•´patché…ç½®å’Œåˆ©ç”¨é¢„è®­ç»ƒçš„ä½ç½®åµŒå…¥å‘é‡(PEV)ï¼ŒISA-ViTå…‹æœäº†æœ´ç´ è°ƒæ•´å¤§å°æ–¹æ³•çš„å±€é™æ€§ã€‚æ­¤å¤–ï¼Œé¢†åŸŸèžåˆç­–ç•¥ç»“åˆäº†è·ç¦»åŸŸå’Œé¢‘çŽ‡åŸŸç‰¹å¾ï¼Œä»¥è¿›ä¸€æ­¥æé«˜åˆ†ç±»æ€§èƒ½ã€‚ç»¼åˆå®žéªŒè¡¨æ˜Žï¼ŒISA-ViTåœ¨åŸºäºŽUWBçš„DARä¸Šï¼Œæ¯”çŽ°æœ‰çš„åŸºäºŽViTçš„æ–¹æ³•æé«˜äº†22.68%çš„å‡†ç¡®çŽ‡ã€‚é€šè¿‡å…¬å¼€å‘å¸ƒALERTæ•°æ®é›†å¹¶è¯¦ç»†ä»‹ç»æˆ‘ä»¬çš„è¾“å…¥å°ºå¯¸æ— å…³ç­–ç•¥ï¼Œè¿™é¡¹å·¥ä½œä¿ƒè¿›äº†æ›´é²æ£’å’Œå¯æ‰©å±•çš„åˆ†å¿ƒé©¾é©¶æ£€æµ‹ç³»ç»Ÿçš„å¼€å‘ï¼Œä»¥ç”¨äºŽå®žé™…éƒ¨ç½²ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰åŸºäºŽIR-UWBé›·è¾¾çš„é©¾é©¶å‘˜è¡Œä¸ºè¯†åˆ«æ–¹æ³•é¢ä¸´ä¸¤ä¸ªä¸»è¦é—®é¢˜ï¼šä¸€æ˜¯ç¼ºä¹å¤§è§„æ¨¡ã€çœŸå®žåœºæ™¯ä¸‹çš„UWBæ•°æ®é›†ï¼Œè¿™é™åˆ¶äº†æ¨¡åž‹çš„æ³›åŒ–èƒ½åŠ›ï¼›äºŒæ˜¯ä¼ ç»Ÿçš„Vision Transformer (ViT) éœ€è¦å›ºå®šå°ºå¯¸çš„è¾“å…¥ï¼Œè€ŒUWBé›·è¾¾æ•°æ®é€šå¸¸å…·æœ‰éžæ ‡å‡†å°ºå¯¸ï¼Œç›´æŽ¥resizeä¼šæŸå¤±é›·è¾¾ä¿¡å·çš„ç‰¹æœ‰ä¿¡æ¯ï¼Œä¾‹å¦‚å¤šæ™®å‹’é¢‘ç§»å’Œç›¸ä½ç‰¹å¾ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯è®¾è®¡ä¸€ä¸ªè¾“å…¥å°ºå¯¸æ— å…³çš„Vision Transformer (ISA-ViT)ï¼Œä½¿å…¶èƒ½å¤Ÿå¤„ç†ä»»æ„å°ºå¯¸çš„UWBé›·è¾¾æ•°æ®ï¼ŒåŒæ—¶å°½å¯èƒ½ä¿ç•™é›·è¾¾ä¿¡å·çš„åŽŸå§‹ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œé€šè¿‡èžåˆè·ç¦»åŸŸå’Œé¢‘çŽ‡åŸŸçš„ç‰¹å¾ï¼Œè¿›ä¸€æ­¥æå‡æ¨¡åž‹çš„è¯†åˆ«æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šISA-ViTæ¡†æž¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) æ•°æ®é¢„å¤„ç†ï¼šå¯¹åŽŸå§‹UWBé›·è¾¾æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼ŒåŒ…æ‹¬é™å™ªã€æ»¤æ³¢ç­‰æ“ä½œã€‚2) æ•°æ®å°ºå¯¸è°ƒæ•´ï¼šé€šè¿‡ç‰¹å®šçš„resizeç­–ç•¥ï¼Œå°†UWBæ•°æ®è°ƒæ•´ä¸ºé€‚åˆViTè¾“å…¥çš„å°ºå¯¸ï¼ŒåŒæ—¶å°½é‡ä¿ç•™é›·è¾¾ä¿¡å·çš„ç‰¹å¾ã€‚3) ç‰¹å¾æå–ï¼šä½¿ç”¨ViTæå–é›·è¾¾æ•°æ®çš„ç‰¹å¾ã€‚4) é¢†åŸŸèžåˆï¼šå°†è·ç¦»åŸŸå’Œé¢‘çŽ‡åŸŸçš„ç‰¹å¾è¿›è¡Œèžåˆï¼Œä»¥èŽ·å¾—æ›´å…¨é¢çš„ä¿¡æ¯ã€‚5) åˆ†ç±»ï¼šä½¿ç”¨åˆ†ç±»å™¨å¯¹èžåˆåŽçš„ç‰¹å¾è¿›è¡Œåˆ†ç±»ï¼Œå¾—åˆ°é©¾é©¶å‘˜çš„è¡Œä¸ºç±»åˆ«ã€‚

**å…³é”®åˆ›æ–°**ï¼šISA-ViTçš„å…³é”®åˆ›æ–°åœ¨äºŽå…¶è¾“å…¥å°ºå¯¸æ— å…³æ€§ã€‚ä¼ ç»Ÿçš„ViTéœ€è¦å›ºå®šå°ºå¯¸çš„è¾“å…¥ï¼Œè€ŒISA-ViTé€šè¿‡è°ƒæ•´patché…ç½®å’Œåˆ©ç”¨é¢„è®­ç»ƒçš„ä½ç½®åµŒå…¥å‘é‡ï¼Œä½¿å…¶èƒ½å¤Ÿå¤„ç†ä»»æ„å°ºå¯¸çš„è¾“å…¥ã€‚æ­¤å¤–ï¼Œé¢†åŸŸèžåˆç­–ç•¥ä¹Ÿæ˜¯ä¸€ä¸ªé‡è¦çš„åˆ›æ–°ï¼Œå®ƒèƒ½å¤Ÿå°†è·ç¦»åŸŸå’Œé¢‘çŽ‡åŸŸçš„ç‰¹å¾è¿›è¡Œæœ‰æ•ˆèžåˆï¼Œä»Žè€Œæå‡æ¨¡åž‹çš„è¯†åˆ«æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®å°ºå¯¸è°ƒæ•´æ–¹é¢ï¼Œè®ºæ–‡æ²¡æœ‰é‡‡ç”¨ç®€å•çš„resizeæ–¹æ³•ï¼Œè€Œæ˜¯è®¾è®¡äº†ä¸€ç§èƒ½å¤Ÿä¿ç•™é›·è¾¾ä¿¡å·ç‰¹å¾çš„resizeç­–ç•¥ã€‚åœ¨patché…ç½®æ–¹é¢ï¼Œè®ºæ–‡æ ¹æ®UWBæ•°æ®çš„ç‰¹ç‚¹ï¼Œé€‰æ‹©äº†åˆé€‚çš„patch sizeå’Œstrideã€‚åœ¨ä½ç½®åµŒå…¥å‘é‡æ–¹é¢ï¼Œè®ºæ–‡åˆ©ç”¨é¢„è®­ç»ƒçš„ä½ç½®åµŒå…¥å‘é‡ï¼ŒåŠ é€Ÿäº†æ¨¡åž‹çš„è®­ç»ƒè¿‡ç¨‹ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜è®¾è®¡äº†ä¸€ç§æœ‰æ•ˆçš„é¢†åŸŸèžåˆç­–ç•¥ï¼Œå°†è·ç¦»åŸŸå’Œé¢‘çŽ‡åŸŸçš„ç‰¹å¾è¿›è¡Œæœ‰æ•ˆèžåˆã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

ISA-ViTåœ¨ALERTæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œç›¸æ¯”äºŽçŽ°æœ‰çš„åŸºäºŽViTçš„æ–¹æ³•ï¼Œå‡†ç¡®çŽ‡æé«˜äº†22.68%ã€‚è¿™ä¸€ç»“æžœè¡¨æ˜Žï¼ŒISA-ViTèƒ½å¤Ÿæœ‰æ•ˆåœ°å¤„ç†ä»»æ„å°ºå¯¸çš„UWBé›·è¾¾æ•°æ®ï¼Œå¹¶èƒ½å¤Ÿå……åˆ†åˆ©ç”¨é›·è¾¾ä¿¡å·çš„ç‰¹å¾ä¿¡æ¯ã€‚åŒæ—¶ï¼ŒALERTæ•°æ®é›†çš„å‘å¸ƒä¸ºè¯¥é¢†åŸŸçš„ç ”ç©¶æä¾›äº†å®è´µçš„æ•°æ®èµ„æºã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽæ™ºèƒ½æ±½è½¦ã€è¾…åŠ©é©¾é©¶ç³»ç»Ÿç­‰é¢†åŸŸï¼Œé€šè¿‡å®žæ—¶ç›‘æµ‹é©¾é©¶å‘˜çš„è¡Œä¸ºçŠ¶æ€ï¼ŒåŠæ—¶å‘å‡ºé¢„è­¦ï¼Œä»Žè€Œé™ä½Žå› åˆ†å¿ƒé©¾é©¶å¯¼è‡´äº¤é€šäº‹æ•…çš„é£Žé™©ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯åº”ç”¨äºŽå…¶ä»–é›·è¾¾ä¿¡å·å¤„ç†é¢†åŸŸï¼Œä¾‹å¦‚äººä½“å§¿æ€è¯†åˆ«ã€æ‰‹åŠ¿è¯†åˆ«ç­‰ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Distracted driving contributes to fatal crashes worldwide. To address this, researchers are using driver activity recognition (DAR) with impulse radio ultra-wideband (IR-UWB) radar, which offers advantages such as interference resistance, low power consumption, and privacy preservation. However, two challenges limit its adoption: the lack of large-scale real-world UWB datasets covering diverse distracted driving behaviors, and the difficulty of adapting fixed-input Vision Transformers (ViTs) to UWB radar data with non-standard dimensions.
>   This work addresses both challenges. We present the ALERT dataset, which contains 10,220 radar samples of seven distracted driving activities collected in real driving conditions. We also propose the input-size-agnostic Vision Transformer (ISA-ViT), a framework designed for radar-based DAR. The proposed method resizes UWB data to meet ViT input requirements while preserving radar-specific information such as Doppler shifts and phase characteristics. By adjusting patch configurations and leveraging pre-trained positional embedding vectors (PEVs), ISA-ViT overcomes the limitations of naive resizing approaches. In addition, a domain fusion strategy combines range- and frequency-domain features to further improve classification performance.
>   Comprehensive experiments demonstrate that ISA-ViT achieves a 22.68% accuracy improvement over an existing ViT-based approach for UWB-based DAR. By publicly releasing the ALERT dataset and detailing our input-size-agnostic strategy, this work facilitates the development of more robust and scalable distracted driving detection systems for real-world deployment.

