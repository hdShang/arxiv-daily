---
layout: default
title: A Graph Attention Network-Based Framework for Reconstructing Missing LiDAR Beams
---

# A Graph Attention Network-Based Framework for Reconstructing Missing LiDAR Beams

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.12410" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.12410v1</a>
  <a href="https://arxiv.org/pdf/2512.12410.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.12410v1" onclick="toggleFavorite(this, '2512.12410v1', 'A Graph Attention Network-Based Framework for Reconstructing Missing LiDAR Beams')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Khalfalla Awedat, Mohamed Abidalrekab, Mohammad El-Yabroudi

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-13

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå›¾æ³¨æ„åŠ›ç½‘ç»œçš„LiDARç¼ºå¤±æ³¢æŸé‡å»ºæ¡†æ¶ï¼Œæå‡è‡ªåŠ¨é©¾é©¶ç¯å¢ƒæ„ŸçŸ¥èƒ½åŠ›ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `LiDARç‚¹äº‘` `ç¼ºå¤±æ³¢æŸé‡å»º` `å›¾æ³¨æ„åŠ›ç½‘ç»œ` `è‡ªåŠ¨é©¾é©¶` `ä¸‰ç»´æ„ŸçŸ¥`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ—‹è½¬å¼LiDARä¼ æ„Ÿå™¨æ˜“å—ç¯å¢ƒå› ç´ å’Œç¡¬ä»¶è€åŒ–çš„å½±å“ï¼Œå¯¼è‡´å‚ç›´æ³¢æŸç¼ºå¤±ï¼Œä¸¥é‡é™ä½äº†è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„3Dæ„ŸçŸ¥èƒ½åŠ›ã€‚
2. è¯¥è®ºæ–‡æå‡ºä¸€ç§åŸºäºå›¾æ³¨æ„åŠ›ç½‘ç»œï¼ˆGATï¼‰çš„æ¡†æ¶ï¼Œç›´æ¥ä»å•å¸§LiDARæ•°æ®ä¸­é‡å»ºç¼ºå¤±çš„å‚ç›´é€šé“ï¼Œæ— éœ€é¢å¤–çš„ç›¸æœºæˆ–æ—¶é—´ä¿¡æ¯ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨KITTIæ•°æ®é›†ä¸Šå–å¾—äº†è‰¯å¥½çš„é‡å»ºæ•ˆæœï¼Œå¹³å‡é«˜åº¦RMSEä¸º11.67å˜ç±³ï¼Œä¸”å¤§éƒ¨åˆ†é‡å»ºç‚¹è¯¯å·®åœ¨10å˜ç±³ä»¥å†…ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå›¾æ³¨æ„åŠ›ç½‘ç»œï¼ˆGATï¼‰çš„æ¡†æ¶ï¼Œç”¨äºé‡å»ºæ—‹è½¬å¼LiDARä¼ æ„Ÿå™¨ä¸­å› ç¡¬ä»¶è€åŒ–ã€ç°å°˜ã€é›ªã€é›¾æˆ–å¼ºåå°„å¼•èµ·çš„å‚ç›´æ³¢æŸç¼ºå¤±ã€‚è¯¥æ–¹æ³•ä»…ä½¿ç”¨å½“å‰çš„LiDARå¸§ï¼Œæ— éœ€ç›¸æœºå›¾åƒæˆ–æ—¶é—´ä¿¡æ¯ã€‚æ¯ä¸ªLiDARæ‰«æè¢«è¡¨ç¤ºä¸ºä¸€ä¸ªéç»“æ„åŒ–çš„ç©ºé—´å›¾ï¼šç‚¹æ˜¯èŠ‚ç‚¹ï¼Œè¾¹è¿æ¥é™„è¿‘çš„ç‚¹ï¼ŒåŒæ—¶ä¿ç•™åŸå§‹çš„æ³¢æŸç´¢å¼•é¡ºåºã€‚å¤šå±‚GATå­¦ä¹ å±€éƒ¨å‡ ä½•é‚»åŸŸä¸Šçš„è‡ªé€‚åº”æ³¨æ„åŠ›æƒé‡ï¼Œå¹¶ç›´æ¥å›å½’ç¼ºå¤±ä½ç½®çš„é«˜åº¦ï¼ˆzï¼‰å€¼ã€‚åœ¨æ¨¡æ‹Ÿé€šé“ç¼ºå¤±çš„1065ä¸ªåŸå§‹KITTIåºåˆ—ä¸Šè¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ï¼Œè¯¥æ–¹æ³•å®ç°äº†11.67å˜ç±³çš„å¹³å‡é«˜åº¦RMSEï¼Œå¹¶ä¸”87.98%çš„é‡å»ºç‚¹è½åœ¨10å˜ç±³çš„è¯¯å·®é˜ˆå€¼å†…ã€‚åœ¨å•ä¸ªGPUä¸Šï¼Œæ¯å¸§çš„æ¨ç†æ—¶é—´ä¸º14.65ç§’ï¼Œé‡å»ºè´¨é‡å¯¹äºä¸åŒçš„é‚»åŸŸå¤§å°kä¿æŒç¨³å®šã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œçº¯ç²¹çš„å›¾æ³¨æ„åŠ›æ¨¡å‹ä»…åœ¨åŸå§‹ç‚¹äº‘å‡ ä½•ä¸Šè¿è¡Œï¼Œå¯ä»¥æœ‰æ•ˆåœ°æ¢å¤çœŸå®ä¼ æ„Ÿå™¨é€€åŒ–ä¸‹çš„ç¼ºå¤±å‚ç›´æ³¢æŸã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æ—‹è½¬å¼LiDARä¼ æ„Ÿå™¨ä¸­å¸¸è§çš„å‚ç›´æ³¢æŸç¼ºå¤±é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¯èƒ½ä¾èµ–äºé¢å¤–çš„ä¼ æ„Ÿå™¨ä¿¡æ¯ï¼ˆå¦‚ç›¸æœºå›¾åƒï¼‰æˆ–æ—¶é—´ä¿¡æ¯ï¼Œå¢åŠ äº†ç³»ç»Ÿçš„å¤æ‚æ€§å’Œæˆæœ¬ã€‚æ­¤å¤–ï¼Œç›´æ¥å¤„ç†åŸå§‹ç‚¹äº‘æ•°æ®å¹¶æœ‰æ•ˆåˆ©ç”¨å…¶ç©ºé—´ç»“æ„ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†LiDARç‚¹äº‘æ•°æ®è¡¨ç¤ºä¸ºå›¾ç»“æ„ï¼Œå¹¶åˆ©ç”¨å›¾æ³¨æ„åŠ›ç½‘ç»œï¼ˆGATï¼‰å­¦ä¹ ç‚¹ä¹‹é—´çš„å…³ç³»ï¼Œä»è€Œå®ç°ç¼ºå¤±æ³¢æŸçš„é‡å»ºã€‚GATèƒ½å¤Ÿè‡ªé€‚åº”åœ°å­¦ä¹ é‚»åŸŸå†…ä¸åŒç‚¹çš„æƒé‡ï¼Œæ›´å¥½åœ°æ•æ‰å±€éƒ¨å‡ ä½•ç‰¹å¾ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1) å°†LiDARç‚¹äº‘è½¬æ¢ä¸ºå›¾ç»“æ„ï¼Œå…¶ä¸­ç‚¹ä½œä¸ºèŠ‚ç‚¹ï¼Œç›¸é‚»ç‚¹ä¹‹é—´å»ºç«‹è¾¹ï¼Œå¹¶ä¿ç•™åŸå§‹æ³¢æŸç´¢å¼•ä¿¡æ¯ã€‚2) ä½¿ç”¨å¤šå±‚GATç½‘ç»œå­¦ä¹ æ¯ä¸ªèŠ‚ç‚¹çš„ç‰¹å¾è¡¨ç¤ºï¼ŒGATå±‚é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶èšåˆé‚»åŸŸä¿¡æ¯ã€‚3) ä½¿ç”¨å›å½’å±‚é¢„æµ‹ç¼ºå¤±ç‚¹çš„é«˜åº¦ï¼ˆzï¼‰å€¼ã€‚4) ä½¿ç”¨å‡æ–¹æ ¹è¯¯å·®ï¼ˆRMSEï¼‰ä½œä¸ºæŸå¤±å‡½æ•°ï¼Œä¼˜åŒ–ç½‘ç»œå‚æ•°ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•çš„ä¸»è¦åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†ä¸€ç§çº¯ç²¹åŸºäºå›¾æ³¨æ„åŠ›ç½‘ç»œçš„ç‚¹äº‘é‡å»ºæ–¹æ³•ï¼Œæ— éœ€é¢å¤–çš„ä¼ æ„Ÿå™¨ä¿¡æ¯æˆ–æ—¶é—´ä¿¡æ¯ã€‚2) åˆ©ç”¨GATçš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œè‡ªé€‚åº”åœ°å­¦ä¹ é‚»åŸŸå†…ä¸åŒç‚¹çš„æƒé‡ï¼Œæ›´å¥½åœ°æ•æ‰å±€éƒ¨å‡ ä½•ç‰¹å¾ã€‚3) å°†åŸå§‹æ³¢æŸç´¢å¼•ä¿¡æ¯èå…¥å›¾ç»“æ„ä¸­ï¼Œæœ‰åŠ©äºä¿æŒç‚¹äº‘çš„ç©ºé—´ç»“æ„ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å›¾æ„å»ºæ–¹é¢ï¼Œé‡‡ç”¨äº†kè¿‘é‚»ç®—æ³•ç¡®å®šæ¯ä¸ªèŠ‚ç‚¹çš„é‚»åŸŸã€‚GATç½‘ç»œé‡‡ç”¨äº†å¤šå±‚ç»“æ„ï¼Œæ¯å±‚åŒ…å«å¤šä¸ªæ³¨æ„åŠ›å¤´ï¼Œä»¥å¢å¼ºæ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚æŸå¤±å‡½æ•°é‡‡ç”¨é«˜åº¦ï¼ˆzï¼‰å€¼çš„å‡æ–¹æ ¹è¯¯å·®ï¼ˆRMSEï¼‰ã€‚å®éªŒä¸­ï¼Œé‚»åŸŸå¤§å°kæ˜¯ä¸€ä¸ªé‡è¦çš„å‚æ•°ï¼Œè®ºæ–‡åˆ†æäº†ä¸åŒkå€¼å¯¹é‡å»ºæ•ˆæœçš„å½±å“ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨KITTIæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„é‡å»ºæ•ˆæœï¼Œå¹³å‡é«˜åº¦RMSEä¸º11.67å˜ç±³ï¼Œ87.98%çš„é‡å»ºç‚¹è½åœ¨10å˜ç±³çš„è¯¯å·®é˜ˆå€¼å†…ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨å•ä¸ªGPUä¸Šçš„æ¨ç†æ—¶é—´ä¸º14.65ç§’æ¯å¸§ï¼Œå…·æœ‰ä¸€å®šçš„å®æ—¶æ€§ã€‚å®éªŒè¿˜è¡¨æ˜ï¼Œé‡å»ºè´¨é‡å¯¹äºä¸åŒçš„é‚»åŸŸå¤§å°kä¿æŒç¨³å®šï¼Œè¡¨æ˜è¯¥æ–¹æ³•å…·æœ‰è¾ƒå¼ºçš„é²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€ä¸‰ç»´é‡å»ºç­‰é¢†åŸŸã€‚é€šè¿‡é‡å»ºç¼ºå¤±çš„LiDARæ³¢æŸï¼Œå¯ä»¥æé«˜ç¯å¢ƒæ„ŸçŸ¥çš„å®Œæ•´æ€§å’Œå‡†ç¡®æ€§ï¼Œä»è€Œæå‡è‡ªåŠ¨é©¾é©¶è½¦è¾†çš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºä¿®å¤å—æŸçš„LiDARæ•°æ®ï¼Œå»¶é•¿ä¼ æ„Ÿå™¨çš„ä½¿ç”¨å¯¿å‘½ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vertical beam dropout in spinning LiDAR sensors triggered by hardware aging, dust, snow, fog, or bright reflections removes entire vertical slices from the point cloud and severely degrades 3D perception in autonomous vehicles. This paper proposes a Graph Attention Network (GAT)-based framework that reconstructs these missing vertical channels using only the current LiDAR frame, with no camera images or temporal information required. Each LiDAR sweep is represented as an unstructured spatial graph: points are nodes and edges connect nearby points while preserving the original beam-index ordering. A multi-layer GAT learns adaptive attention weights over local geometric neighborhoods and directly regresses the missing elevation (z) values at dropout locations. Trained and evaluated on 1,065 raw KITTI sequences with simulated channel dropout, the method achieves an average height RMSE of 11.67 cm, with 87.98% of reconstructed points falling within a 10 cm error threshold. Inference takes 14.65 seconds per frame on a single GPU, and reconstruction quality remains stable for different neighborhood sizes k. These results show that a pure graph attention model operating solely on raw point-cloud geometry can effectively recover dropped vertical beams under realistic sensor degradation.

