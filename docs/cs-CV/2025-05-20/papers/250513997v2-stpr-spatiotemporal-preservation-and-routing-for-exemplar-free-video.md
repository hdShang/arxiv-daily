---
layout: default
title: StPR: Spatiotemporal Preservation and Routing for Exemplar-Free Video Class-Incremental Learning
---

# StPR: Spatiotemporal Preservation and Routing for Exemplar-Free Video Class-Incremental Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.13997" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.13997v2</a>
  <a href="https://arxiv.org/pdf/2505.13997.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.13997v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.13997v2', 'StPR: Spatiotemporal Preservation and Routing for Exemplar-Free Video Class-Incremental Learning')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Huaijie Wang, De Cheng, Guozhang Li, Zhipeng Xu, Lingfeng He, Jie Li, Nannan Wang, Xinbo Gao

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-20 (Êõ¥Êñ∞: 2025-09-30)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫StPRÊ°ÜÊû∂‰ª•Ëß£ÂÜ≥ËßÜÈ¢ëÁ±ªÂ¢ûÈáèÂ≠¶‰π†‰∏≠ÁöÑÈÅóÂøòÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±ÂÖ´ÔºöÁâ©ÁêÜÂä®Áîª (Physics-based Animation)**

**ÂÖ≥ÈîÆËØç**: `ËßÜÈ¢ëÁ±ªÂ¢ûÈáèÂ≠¶‰π†` `Êó∂Á©∫Âª∫Ê®°` `Êó†Á§∫‰æãÂ≠¶‰π†` `Â∏ßÂÖ±‰∫´ËØ≠‰πâ` `‰∏ìÂÆ∂Ê∑∑ÂêàÊ®°Âûã` `ÁÅæÈöæÊÄßÈÅóÂøò` `Âä®ÊÄÅË∑ØÁî±` `Ê∑±Â∫¶Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËßÜÈ¢ëÁ±ªÂ¢ûÈáèÂ≠¶‰π†ÊñπÊ≥ï‰æùËµñÁ§∫‰æãÈáçÊºîÊàñÈùôÊÄÅÂõæÂÉèÊñπÊ≥ïÔºåÂØºËá¥ÂÜÖÂ≠òÂíåÈöêÁßÅÈóÆÈ¢òÔºå‰∏îÊó†Ê≥ïÊúâÊïàÊçïÊçâÊó∂Á©∫Âä®ÊÄÅ„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫ÁöÑStPRÊ°ÜÊû∂ÈÄöËøáÂ∏ßÂÖ±‰∫´ËØ≠‰πâËí∏È¶èÂíåÊó∂Èó¥ÂàÜËß£ÁöÑ‰∏ìÂÆ∂Ê∑∑ÂêàÊ®°ÂûãÔºåËß£ÂÜ≥‰∫ÜÊó∂Á©∫‰ø°ÊÅØÁöÑ‰øùÁïô‰∏éË∑ØÁî±ÈóÆÈ¢ò„ÄÇ
3. Âú®UCF101„ÄÅHMDB51ÂíåKinetics400Êï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åË°®ÊòéÔºåStPRÂú®ÊÄßËÉΩ‰∏äË∂ÖË∂ä‰∫ÜÁé∞ÊúâÂü∫Á∫øÔºåÂπ∂ÊèêÈ´ò‰∫ÜÂèØËß£ÈáäÊÄßÂíåÊïàÁéá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËßÜÈ¢ëÁ±ªÂ¢ûÈáèÂ≠¶‰π†ÔºàVCILÔºâÊó®Âú®ÂºÄÂèëËÉΩÂ§üÊåÅÁª≠Â≠¶‰π†Êñ∞Âä®‰ΩúÁ±ªÂà´ÁöÑÊ®°ÂûãÔºåËÄå‰∏çÈÅóÂøòÂÖàÂâçËé∑ÂæóÁöÑÁü•ËØÜ„ÄÇ‰∏é‰º†ÁªüÁöÑÁ±ªÂ¢ûÈáèÂ≠¶‰π†ÔºàCILÔºâ‰∏çÂêåÔºåVCILÂºïÂÖ•‰∫ÜÊó∂Á©∫ÁªìÊûÑÁöÑÂ§çÊùÇÊÄßÔºå‰ΩøÂæóÂú®ÊúâÊïàÊçïÊçâÂ∏ßÂÖ±‰∫´ËØ≠‰πâÂíåÊó∂Èó¥Âä®ÊÄÅÁöÑÂêåÊó∂ÔºåÂáèËΩªÁÅæÈöæÊÄßÈÅóÂøòÂèòÂæóÂ∞§‰∏∫Âõ∞Èöæ„ÄÇÁé∞ÊúâÊñπÊ≥ï‰æùËµñ‰∫éÁ§∫‰æãÈáçÊºîÔºåÂ≠òÂú®ÂÜÖÂ≠òÂíåÈöêÁßÅÈóÆÈ¢òÔºåÊàñÈááÁî®ÈùôÊÄÅÂõæÂÉèÊñπÊ≥ïÔºåÂøΩËßÜ‰∫ÜÊó∂Èó¥Âª∫Ê®°„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÂ±ÄÈôêÊÄßÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜÊó∂Á©∫‰øùÁïô‰∏éË∑ØÁî±ÔºàStPRÔºâÊ°ÜÊû∂ÔºåÊòéÁ°ÆËß£ËÄ¶Âπ∂‰øùÁïôÊó∂Á©∫‰ø°ÊÅØ„ÄÇÊàë‰ª¨ÂºïÂÖ•‰∫ÜÂ∏ßÂÖ±‰∫´ËØ≠‰πâËí∏È¶èÔºàFSSDÔºâÔºåÈÄöËøáËÅîÂêàËÄÉËôëËØ≠‰πâÊïèÊÑüÊÄßÂíåÂàÜÁ±ªË¥°ÁåÆÔºåËØÜÂà´Âá∫ËØ≠‰πâÁ®≥ÂÆöÁöÑÈáçË¶ÅÈÄöÈÅì„ÄÇÂÖ∂Ê¨°ÔºåÊàë‰ª¨ËÆæËÆ°‰∫ÜÂü∫‰∫éÊó∂Èó¥ÂàÜËß£ÁöÑ‰∏ìÂÆ∂Ê∑∑ÂêàÊ®°ÂûãÔºàTD-MoEÔºâÔºåÊ†πÊçÆÊó∂Èó¥Âä®ÊÄÅÂä®ÊÄÅË∑ØÁî±‰ªªÂä°ÁâπÂÆö‰∏ìÂÆ∂ÔºåÂÆûÁé∞Êó†‰ªªÂä°IDÊàñÂ≠òÂÇ®Á§∫‰æãÁöÑÊé®ÁêÜ„ÄÇStPRÊúâÊïàÂà©Áî®Á©∫Èó¥ËØ≠‰πâÂíåÊó∂Èó¥Âä®ÊÄÅÔºåËææÊàêÁªü‰∏ÄÁöÑÊó†Á§∫‰æãVCILÊ°ÜÊû∂„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáË¶ÅËß£ÂÜ≥ÁöÑÈóÆÈ¢òÊòØËßÜÈ¢ëÁ±ªÂ¢ûÈáèÂ≠¶‰π†‰∏≠ÁöÑÁÅæÈöæÊÄßÈÅóÂøòÔºåÁé∞ÊúâÊñπÊ≥ïÂæÄÂæÄ‰æùËµñÁ§∫‰æãÈáçÊºîÊàñÈùôÊÄÅÂõæÂÉèÊñπÊ≥ïÔºåÊó†Ê≥ïÊúâÊïàÊçïÊçâÊó∂Á©∫Âä®ÊÄÅÔºåÂØºËá¥Áü•ËØÜÈÅóÂøòÂíåÈöêÁßÅÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÊèêÂá∫‰∏Ä‰∏™Áªü‰∏ÄÁöÑÊó†Á§∫‰æãVCILÊ°ÜÊû∂StPRÔºåÈÄöËøáÂ∏ßÂÖ±‰∫´ËØ≠‰πâËí∏È¶èÂíåÊó∂Èó¥ÂàÜËß£ÁöÑ‰∏ìÂÆ∂Ê∑∑ÂêàÊ®°ÂûãÔºåÊòéÁ°ÆËß£ËÄ¶Âπ∂‰øùÁïôÊó∂Á©∫‰ø°ÊÅØÔºå‰ªéËÄåÊúâÊïàÂ∫îÂØπÁÅæÈöæÊÄßÈÅóÂøò„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏§‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÂ∏ßÂÖ±‰∫´ËØ≠‰πâËí∏È¶èÔºàFSSDÔºâÁî®‰∫éËØÜÂà´Âíå‰øùÁïôÈáçË¶ÅÁöÑËØ≠‰πâÈÄöÈÅìÔºåÊó∂Èó¥ÂàÜËß£ÁöÑ‰∏ìÂÆ∂Ê∑∑ÂêàÊ®°ÂûãÔºàTD-MoEÔºâÁî®‰∫éÂä®ÊÄÅË∑ØÁî±‰ªªÂä°ÁâπÂÆö‰∏ìÂÆ∂„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÊó†Á§∫‰æãÁöÑÂ≠¶‰π†ÊñπÂºèÔºåFSSDÂíåTD-MoEÁöÑÁªìÂêà‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üÂú®‰∏ç‰æùËµñÂ≠òÂÇ®Á§∫‰æãÁöÑÊÉÖÂÜµ‰∏ãÔºåÁÅµÊ¥ªÈÄÇÂ∫îÊñ∞‰ªªÂä°Âπ∂‰øùÁïôÊóßÁü•ËØÜ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨ÂØπFSSDÁöÑÊ≠£ÂàôÂåñÁ≠ñÁï•Ôºå‰ª•‰øùÊåÅËØ≠‰πâÈÄöÈÅìÁöÑÁ®≥ÂÆöÊÄßÔºå‰ª•ÂèäTD-MoEÁöÑÂä®ÊÄÅË∑ØÁî±Êú∫Âà∂ÔºåÁ°Æ‰øùÊ†πÊçÆÊó∂Èó¥Âä®ÊÄÅÈÄâÊã©ÊúÄÂêàÈÄÇÁöÑ‰∏ìÂÆ∂ËøõË°åÊé®ÁêÜ„ÄÇÂÖ∑‰ΩìÁöÑÊçüÂ§±ÂáΩÊï∞ÂíåÁΩëÁªúÁªìÊûÑÁªÜËäÇÂú®ËÆ∫Êñá‰∏≠ÊúâËØ¶ÁªÜÊèèËø∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåStPRÂú®UCF101„ÄÅHMDB51ÂíåKinetics400Êï∞ÊçÆÈõÜ‰∏äÂùáË∂ÖË∂ä‰∫ÜÁé∞ÊúâÂü∫Á∫øÔºåÂÖ∑‰ΩìÊèêÂçáÂπÖÂ∫¶ËææÂà∞XX%ÔºåÂêåÊó∂Âú®ÂèØËß£ÈáäÊÄßÂíåÊïàÁéáÊñπÈù¢‰πüÊúâÊòæËëóÊîπÂñÑÔºåÈ™åËØÅ‰∫ÜÂÖ∂ÊúâÊïàÊÄßÂíåÂÆûÁî®ÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Êô∫ËÉΩÁõëÊéß„ÄÅËøêÂä®ÂàÜÊûêÂíå‰∫∫Êú∫‰∫§‰∫íÁ≠âÂú∫ÊôØÔºåËÉΩÂ§üÂ∏ÆÂä©Á≥ªÁªüÂú®‰∏çÊñ≠ÂèòÂåñÁöÑÁéØÂ¢É‰∏≠ÊåÅÁª≠Â≠¶‰π†Êñ∞Âä®‰ΩúÁ±ªÂà´ÔºåÊèêÂçáÊô∫ËÉΩÁ≥ªÁªüÁöÑÈÄÇÂ∫îËÉΩÂäõÂíåÂÆûÁî®ÊÄß„ÄÇÊú™Êù•ÔºåStPRÊ°ÜÊû∂ÊúâÊúõÊé®Âä®ËßÜÈ¢ëÁêÜËß£ÂíåÂ¢ûÈáèÂ≠¶‰π†ÊäÄÊúØÁöÑËøõ‰∏ÄÊ≠•ÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Video Class-Incremental Learning (VCIL) seeks to develop models that continuously learn new action categories over time without forgetting previously acquired knowledge. Unlike traditional Class-Incremental Learning (CIL), VCIL introduces the added complexity of spatiotemporal structures, making it particularly challenging to mitigate catastrophic forgetting while effectively capturing both frame-shared semantics and temporal dynamics. Existing approaches either rely on exemplar rehearsal, raising concerns over memory and privacy, or adapt static image-based methods that neglect temporal modeling. To address these limitations, we propose Spatiotemporal Preservation and Routing (StPR), a unified and exemplar-free VCIL framework that explicitly disentangles and preserves spatiotemporal information. First, we introduce Frame-Shared Semantics Distillation (FSSD), which identifies semantically stable and meaningful channels by jointly considering semantic sensitivity and classification contribution. These important semantic channels are selectively regularized to maintain prior knowledge while allowing for adaptation. Second, we design a Temporal Decomposition-based Mixture-of-Experts (TD-MoE), which dynamically routes task-specific experts based on their temporal dynamics, enabling inference without task ID or stored exemplars. Together, StPR effectively leverages spatial semantics and temporal dynamics, achieving a unified, exemplar-free VCIL framework. Extensive experiments on UCF101, HMDB51, and Kinetics400 show that our method outperforms existing baselines while offering improved interpretability and efficiency in VCIL. Code is available in the supplementary materials.

