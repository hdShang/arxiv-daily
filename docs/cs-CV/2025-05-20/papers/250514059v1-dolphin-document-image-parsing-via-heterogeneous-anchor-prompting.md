---
layout: default
title: "Dolphin: Document Image Parsing via Heterogeneous Anchor Prompting"
---

# Dolphin: Document Image Parsing via Heterogeneous Anchor Prompting

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14059" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14059v1</a>
  <a href="https://arxiv.org/pdf/2505.14059.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14059v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14059v1', 'Dolphin: Document Image Parsing via Heterogeneous Anchor Prompting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hao Feng, Shu Wei, Xiang Fei, Wei Shi, Yingdong Han, Lei Liao, Jinghui Lu, Binghong Wu, Qi Liu, Chunhui Lin, Jingqun Tang, Hao Liu, Can Huang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20

**å¤‡æ³¨**: Accepted to ACL 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/ByteDance/Dolphin)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDolphinä»¥è§£å†³æ–‡æ¡£å›¾åƒè§£æä¸­çš„å¤æ‚å…ƒç´ é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ–‡æ¡£å›¾åƒè§£æ` `å¤šæ¨¡æ€æ¨¡å‹` `å¹¶è¡Œè§£æ` `å¸ƒå±€å…ƒç´ ` `ä¿¡æ¯æå–` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–‡æ¡£å›¾åƒè§£ææ–¹æ³•é¢ä¸´æ•´åˆå¼€é”€å’Œæ•ˆç‡ç“¶é¢ˆï¼Œä¸”å¸ƒå±€ç»“æ„æ˜“é€€åŒ–ã€‚
2. Dolphinæ¨¡å‹é‡‡ç”¨åˆ†æ-å†è§£æçš„èŒƒå¼ï¼Œç”Ÿæˆå¸ƒå±€å…ƒç´ å¹¶è¿›è¡Œå¹¶è¡Œå†…å®¹è§£æã€‚
3. Dolphinåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œä¸”æ•ˆç‡æ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ–‡æ¡£å›¾åƒè§£æå› æ–‡æœ¬æ®µè½ã€å›¾å½¢ã€å…¬å¼å’Œè¡¨æ ¼ç­‰å¤æ‚å…ƒç´ çš„äº¤ç»‡è€Œå…·æœ‰æŒ‘æˆ˜æ€§ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºä¸“ä¸šæ¨¡å‹çš„ç»„åˆæˆ–ç›´æ¥ç”Ÿæˆé¡µé¢å†…å®¹ï¼Œé¢ä¸´æ•´åˆå¼€é”€ã€æ•ˆç‡ç“¶é¢ˆå’Œå¸ƒå±€ç»“æ„é€€åŒ–ç­‰é—®é¢˜ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæœ¬æ–‡æå‡ºäº†Dolphinï¼Œä¸€ç§æ–°é¢–çš„å¤šæ¨¡æ€æ–‡æ¡£å›¾åƒè§£ææ¨¡å‹ï¼Œé‡‡ç”¨åˆ†æ-å†è§£æçš„èŒƒå¼ã€‚Dolphinåœ¨ç¬¬ä¸€é˜¶æ®µç”Ÿæˆé˜…è¯»é¡ºåºçš„å¸ƒå±€å…ƒç´ ï¼Œå¹¶åœ¨ç¬¬äºŒé˜¶æ®µé€šè¿‡ä»»åŠ¡ç‰¹å®šçš„æç¤ºè¿›è¡Œå¹¶è¡Œå†…å®¹è§£æã€‚é€šè¿‡æ„å»ºè¶…è¿‡3000ä¸‡æ ·æœ¬çš„å¤§è§„æ¨¡æ•°æ®é›†ï¼ŒDolphinåœ¨å¤šç§é¡µé¢çº§å’Œå…ƒç´ çº§è®¾ç½®ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶é€šè¿‡è½»é‡æ¶æ„å’Œå¹¶è¡Œè§£ææœºåˆ¶ç¡®ä¿äº†é«˜æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæ–‡æ¡£å›¾åƒè§£æéœ€è¦å¤„ç†å¤æ‚çš„å…ƒç´ äº¤ç»‡ï¼Œç°æœ‰æ–¹æ³•åœ¨æ•´åˆå’Œæ•ˆç‡ä¸Šå­˜åœ¨æ˜æ˜¾ä¸è¶³ï¼Œå¯¼è‡´æ€§èƒ½å—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDolphiné€šè¿‡åˆ†æ-å†è§£æçš„æµç¨‹ï¼Œé¦–å…ˆç”Ÿæˆå¸ƒå±€å…ƒç´ ï¼Œç„¶ååˆ©ç”¨è¿™äº›å…ƒç´ è¿›è¡Œå¹¶è¡Œè§£æï¼Œæ—¨åœ¨æé«˜æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDolphinçš„æ•´ä½“æ¶æ„åˆ†ä¸ºä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µç”Ÿæˆé˜…è¯»é¡ºåºçš„å¸ƒå±€å…ƒç´ ï¼Œç¬¬äºŒé˜¶æ®µåˆ©ç”¨è¿™äº›å…ƒç´ å’Œä»»åŠ¡ç‰¹å®šæç¤ºè¿›è¡Œå†…å®¹è§£æã€‚

**å…³é”®åˆ›æ–°**ï¼šDolphinçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå¼•å…¥å¼‚æ„é”šç‚¹æç¤ºï¼Œå…è®¸æ¨¡å‹åœ¨è§£æè¿‡ç¨‹ä¸­å¹¶è¡Œå¤„ç†å¤šç§å…ƒç´ ï¼Œæ˜¾è‘—æå‡äº†è§£ææ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒDolphinä½¿ç”¨äº†è¶…è¿‡3000ä¸‡æ ·æœ¬çš„æ•°æ®é›†ï¼Œè®¾è®¡äº†è½»é‡çº§ç½‘ç»œç»“æ„ï¼Œå¹¶é‡‡ç”¨äº†é€‚åº”æ€§æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–è§£ææ•ˆæœã€‚é€šè¿‡è¿™äº›è®¾è®¡ï¼ŒDolphinåœ¨å¤šç§è§£æä»»åŠ¡ä¸­å±•ç°äº†ä¼˜è¶Šçš„æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

Dolphinåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå°¤å…¶åœ¨é¡µé¢çº§å’Œå…ƒç´ çº§è§£æä»»åŠ¡ä¸Šï¼Œæ€§èƒ½æå‡å¹…åº¦è¶…è¿‡äº†ç°æœ‰ä¸»æµæ–¹æ³•ï¼Œå±•ç¤ºäº†å…¶é«˜æ•ˆçš„è§£æèƒ½åŠ›å’Œå‡†ç¡®æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Dolphinæ¨¡å‹åœ¨æ–‡æ¡£å›¾åƒè§£æé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¤„ç†å„ç§å¤æ‚æ–‡æ¡£æ ¼å¼ï¼Œå¦‚å­¦æœ¯è®ºæ–‡ã€è´¢åŠ¡æŠ¥è¡¨å’Œç”µå­ä¹¦ç­‰ã€‚å…¶é«˜æ•ˆçš„è§£æèƒ½åŠ›å°†ä¸ºä¿¡æ¯æå–ã€æ–‡æ¡£è‡ªåŠ¨åŒ–å¤„ç†å’Œæ™ºèƒ½æœç´¢ç­‰åº”ç”¨æä¾›æ”¯æŒï¼Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„æŠ€æœ¯è¿›æ­¥å’Œå•†ä¸šä»·å€¼æå‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Document image parsing is challenging due to its complexly intertwined elements such as text paragraphs, figures, formulas, and tables. Current approaches either assemble specialized expert models or directly generate page-level content autoregressively, facing integration overhead, efficiency bottlenecks, and layout structure degradation despite their decent performance. To address these limitations, we present \textit{Dolphin} (\textit{\textbf{Do}cument Image \textbf{P}arsing via \textbf{H}eterogeneous Anchor Prompt\textbf{in}g}), a novel multimodal document image parsing model following an analyze-then-parse paradigm. In the first stage, Dolphin generates a sequence of layout elements in reading order. These heterogeneous elements, serving as anchors and coupled with task-specific prompts, are fed back to Dolphin for parallel content parsing in the second stage. To train Dolphin, we construct a large-scale dataset of over 30 million samples, covering multi-granularity parsing tasks. Through comprehensive evaluations on both prevalent benchmarks and self-constructed ones, Dolphin achieves state-of-the-art performance across diverse page-level and element-level settings, while ensuring superior efficiency through its lightweight architecture and parallel parsing mechanism. The code and pre-trained models are publicly available at https://github.com/ByteDance/Dolphin

