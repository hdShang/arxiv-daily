---
layout: default
title: "Scaling and Enhancing LLM-based AVSR: A Sparse Mixture of Projectors Approach"
---

# Scaling and Enhancing LLM-based AVSR: A Sparse Mixture of Projectors Approach

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14336" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14336v2</a>
  <a href="https://arxiv.org/pdf/2505.14336.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14336v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14336v2', 'Scaling and Enhancing LLM-based AVSR: A Sparse Mixture of Projectors Approach')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Umberto Cappellazzo, Minsu Kim, Stavros Petridis, Daniele Falavigna, Alessio Brutti

**åˆ†ç±»**: eess.AS, cs.CV, cs.MM, cs.SD

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20 (æ›´æ–°: 2025-05-21)

**å¤‡æ³¨**: Interspeech 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLlama-SMoPä»¥è§£å†³èµ„æºå—é™ç¯å¢ƒä¸‹çš„AVSRé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `éŸ³é¢‘-è§†è§‰è¯­éŸ³è¯†åˆ«` `å¤§å‹è¯­è¨€æ¨¡å‹` `ç¨€ç–æ··åˆæŠ•å½±å™¨` `å¤šæ¨¡æ€å­¦ä¹ ` `å™ªå£°é²æ£’æ€§` `è®¡ç®—æ•ˆç‡` `ä¸“å®¶æ··åˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„éŸ³é¢‘-è§†è§‰è¯­éŸ³è¯†åˆ«æ–¹æ³•åœ¨èµ„æºå—é™ç¯å¢ƒä¸­é¢ä¸´é«˜è®¡ç®—æˆæœ¬çš„æŒ‘æˆ˜ï¼Œé™åˆ¶äº†å…¶å®é™…åº”ç”¨ã€‚
2. æœ¬æ–‡æå‡ºLlama-SMoPï¼Œé€šè¿‡ç¨€ç–æ··åˆæŠ•å½±å™¨æ¨¡å—ï¼Œæå‡æ¨¡å‹å®¹é‡è€Œä¸å¢åŠ æ¨ç†æˆæœ¬ï¼Œé€‚åº”èµ„æºå—é™åœºæ™¯ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒLlama-SMoP DEDRé…ç½®åœ¨å¤šé¡¹ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶åœ¨å™ªå£°ç¯å¢ƒä¸‹çš„é²æ£’æ€§æ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éŸ³é¢‘-è§†è§‰è¯­éŸ³è¯†åˆ«ï¼ˆAVSRï¼‰é€šè¿‡æ•´åˆè§†è§‰çº¿ç´¢å¢å¼ºäº†åœ¨å˜ˆæ‚ç¯å¢ƒä¸­çš„é²æ£’æ€§ã€‚å°½ç®¡è¿‘æœŸçš„ç ”ç©¶å°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é›†æˆåˆ°AVSRä¸­ï¼Œä½†å…¶é«˜è®¡ç®—æˆæœ¬é™åˆ¶äº†åœ¨èµ„æºå—é™ç¯å¢ƒä¸­çš„åº”ç”¨ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†Llama-SMoPï¼Œä¸€ç§é«˜æ•ˆçš„å¤šæ¨¡æ€LLMï¼Œé‡‡ç”¨ç¨€ç–æ··åˆæŠ•å½±å™¨ï¼ˆSMoPï¼‰æ¨¡å—ï¼Œåœ¨ä¸å¢åŠ æ¨ç†æˆæœ¬çš„æƒ…å†µä¸‹æ‰©å±•æ¨¡å‹å®¹é‡ã€‚é€šè¿‡å¼•å…¥ç¨€ç–é—¨æ§çš„ä¸“å®¶æ··åˆï¼ˆMoEï¼‰æŠ•å½±å™¨ï¼ŒLlama-SMoPèƒ½å¤Ÿä½¿ç”¨è¾ƒå°çš„LLMï¼ŒåŒæ—¶ä¿æŒå¼ºå¤§çš„æ€§èƒ½ã€‚æˆ‘ä»¬æ¢ç´¢äº†ä¸‰ç§SMoPé…ç½®ï¼Œå‘ç°Llama-SMoP DEDRï¼ˆä¸ç›¸äº¤ä¸“å®¶ï¼Œä¸ç›¸äº¤è·¯ç”±å™¨ï¼‰åœ¨ASRã€VSRå’ŒAVSRä»»åŠ¡ä¸Šè¡¨ç°ä¼˜è¶Šã€‚æ¶ˆèç ”ç©¶è¯å®äº†å…¶åœ¨ä¸“å®¶æ¿€æ´»ã€å¯æ‰©å±•æ€§å’Œå™ªå£°é²æ£’æ€§æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨èµ„æºå—é™ç¯å¢ƒä¸­ï¼Œç°æœ‰éŸ³é¢‘-è§†è§‰è¯­éŸ³è¯†åˆ«ï¼ˆAVSRï¼‰æ–¹æ³•å› é«˜è®¡ç®—æˆæœ¬è€Œéš¾ä»¥éƒ¨ç½²çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å˜ˆæ‚ç¯å¢ƒä¸‹çš„é²æ£’æ€§å’Œæ•ˆç‡ä¸è¶³ï¼Œé™åˆ¶äº†å…¶å®é™…åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„Llama-SMoPé€šè¿‡å¼•å…¥ç¨€ç–æ··åˆæŠ•å½±å™¨ï¼ˆSMoPï¼‰æ¨¡å—ï¼Œåˆ©ç”¨ç¨€ç–é—¨æ§çš„ä¸“å®¶æ··åˆï¼ˆMoEï¼‰è®¾è®¡ï¼Œå…è®¸ä½¿ç”¨è¾ƒå°çš„LLMï¼ŒåŒæ—¶ä¿æŒå¼ºå¤§çš„æ€§èƒ½ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨é™ä½è®¡ç®—å¼€é”€ï¼Œæé«˜æ¨¡å‹çš„å¯æ‰©å±•æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLlama-SMoPçš„æ•´ä½“æ¶æ„åŒ…æ‹¬è¾“å…¥éŸ³é¢‘å’Œè§†è§‰ä¿¡æ¯ï¼Œé€šè¿‡ç¨€ç–æ··åˆæŠ•å½±å™¨æ¨¡å—è¿›è¡Œå¤„ç†ï¼Œæœ€ç»ˆè¾“å‡ºè¯†åˆ«ç»“æœã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒåœ¨äºä½¿ç”¨ä¸ç›¸äº¤çš„ä¸“å®¶å’Œè·¯ç”±å™¨ï¼Œä»¥å®ç°æ›´é«˜æ•ˆçš„ä¿¡æ¯å¤„ç†ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥äº†ç¨€ç–æ··åˆæŠ•å½±å™¨ï¼ˆSMoPï¼‰ï¼Œä½¿å¾—æ¨¡å‹åœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—æˆæœ¬ã€‚è¿™ç§æ–¹æ³•ä¸ä¼ ç»Ÿçš„å…¨è¿æ¥æ¨¡å‹ç›¸æ¯”ï¼Œèƒ½å¤Ÿåœ¨æ›´å°çš„æ¨¡å‹è§„æ¨¡ä¸‹å®ç°æ›´å¥½çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç¨€ç–é—¨æ§æœºåˆ¶æ¥æ¿€æ´»ä¸“å®¶ï¼Œç¡®ä¿åªæœ‰ç›¸å…³çš„ä¸“å®¶å‚ä¸è®¡ç®—ã€‚æ­¤å¤–ï¼Œæ¨¡å‹çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œä»¥ä¼˜åŒ–åœ¨å¤šæ¨¡æ€è¾“å…¥ä¸‹çš„è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLlama-SMoP DEDRé…ç½®åœ¨ASRã€VSRå’ŒAVSRä»»åŠ¡ä¸Šå‡ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œå°¤å…¶åœ¨å™ªå£°ç¯å¢ƒä¸‹çš„é²æ£’æ€§æ˜¾è‘—æå‡ï¼Œå…·ä½“æ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°XX%ã€‚æ¶ˆèç ”ç©¶è¿›ä¸€æ­¥éªŒè¯äº†å…¶åœ¨ä¸“å®¶æ¿€æ´»å’Œå¯æ‰©å±•æ€§æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½åŠ©ç†ã€è‡ªåŠ¨å­—å¹•ç”Ÿæˆå’Œäººæœºäº¤äº’ç­‰åœºæ™¯ï¼Œå°¤å…¶æ˜¯åœ¨å™ªå£°ç¯å¢ƒä¸‹çš„è¯­éŸ³è¯†åˆ«ä»»åŠ¡ä¸­å…·æœ‰é‡è¦ä»·å€¼ã€‚Llama-SMoPçš„é«˜æ•ˆæ€§ä½¿å…¶é€‚ç”¨äºç§»åŠ¨è®¾å¤‡å’Œè¾¹ç¼˜è®¡ç®—ç­‰èµ„æºå—é™çš„åº”ç”¨åœºæ™¯ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨AVSRæŠ€æœ¯çš„å¹¿æ³›åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Audio-Visual Speech Recognition (AVSR) enhances robustness in noisy environments by integrating visual cues. While recent advances integrate Large Language Models (LLMs) into AVSR, their high computational cost hinders deployment in resource-constrained settings. To address this, we propose Llama-SMoP, an efficient Multimodal LLM that employs a Sparse Mixture of Projectors (SMoP) module to scale model capacity without increasing inference costs. By incorporating sparsely-gated mixture-of-experts (MoE) projectors, Llama-SMoP enables the use of smaller LLMs while maintaining strong performance. We explore three SMoP configurations and show that Llama-SMoP DEDR (Disjoint-Experts, Disjoint-Routers), which uses modality-specific routers and experts, achieves superior performance on ASR, VSR, and AVSR tasks. Ablation studies confirm its effectiveness in expert activation, scalability, and noise robustness.

