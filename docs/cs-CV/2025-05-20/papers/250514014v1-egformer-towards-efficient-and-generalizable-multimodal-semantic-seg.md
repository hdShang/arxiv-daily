---
layout: default
title: "EGFormer: Towards Efficient and Generalizable Multimodal Semantic Segmentation"
---

# EGFormer: Towards Efficient and Generalizable Multimodal Semantic Segmentation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14014" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14014v1</a>
  <a href="https://arxiv.org/pdf/2505.14014.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14014v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14014v1', 'EGFormer: Towards Efficient and Generalizable Multimodal Semantic Segmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zelin Zhang, Tao Zhang, KediLI, Xu Zheng

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEGFormerä»¥è§£å†³å¤šæ¨¡æ€è¯­ä¹‰åˆ†å‰²çš„æ•ˆç‡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€è¯­ä¹‰åˆ†å‰²` `è®¡ç®—æ•ˆç‡` `åŠ¨æ€æ¨¡æ€é€‰æ‹©` `æ·±åº¦å­¦ä¹ ` `è¿ç§»å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤šæ¨¡æ€è¯­ä¹‰åˆ†å‰²æ–¹æ³•å¤§å¤šä¸“æ³¨äºæé«˜å‡†ç¡®æ€§ï¼Œè®¡ç®—æ•ˆç‡å´æœªå¾—åˆ°å……åˆ†ç ”ç©¶ã€‚
2. EGFormeré€šè¿‡å¼•å…¥ASMå’ŒMDMæ¨¡å—ï¼ŒåŠ¨æ€è¯„ä¼°æ¨¡æ€é‡è¦æ€§å¹¶è¿‡æ»¤å†—ä½™ä¿¡æ¯ï¼Œä»è€Œæé«˜äº†æ•ˆç‡ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒEGFormeråœ¨å‚æ•°å’Œè®¡ç®—é‡ä¸Šæ˜¾è‘—å‡å°‘ï¼ŒåŒæ—¶åœ¨è¿ç§»å­¦ä¹ ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œç ”ç©¶è€…ä»¬æ¢ç´¢äº†å¤šæ¨¡æ€è¯­ä¹‰åˆ†å‰²ï¼Œé‡‡ç”¨äº†å¤šç§ä¸»å¹²æ¶æ„ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°æ–¹æ³•è™½ç„¶æé«˜äº†å‡†ç¡®æ€§ï¼Œä½†åœ¨è®¡ç®—æ•ˆç‡æ–¹é¢çš„ç ”ç©¶ä»æ˜¾ä¸è¶³ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†EGFormerï¼Œä¸€ä¸ªé«˜æ•ˆçš„å¤šæ¨¡æ€è¯­ä¹‰åˆ†å‰²æ¡†æ¶ï¼Œçµæ´»æ•´åˆä»»æ„æ•°é‡çš„æ¨¡æ€ï¼ŒåŒæ—¶æ˜¾è‘—å‡å°‘æ¨¡å‹å‚æ•°å’Œæ¨ç†æ—¶é—´ï¼Œè€Œä¸ç‰ºç‰²æ€§èƒ½ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†ä¸¤ä¸ªæ–°æ¨¡å—ï¼šä»»ä½•æ¨¡æ€è¯„åˆ†æ¨¡å—ï¼ˆASMï¼‰å’Œæ¨¡æ€ä¸¢å¼ƒæ¨¡å—ï¼ˆMDMï¼‰ï¼Œå‰è€…ä¸ºæ¯ä¸ªæ¨¡æ€ç‹¬ç«‹åˆ†é…é‡è¦æ€§è¯„åˆ†ï¼Œåè€…åœ¨æ¯ä¸ªé˜¶æ®µè¿‡æ»¤æ‰ä¿¡æ¯é‡è¾ƒå°‘çš„æ¨¡æ€ã€‚é€šè¿‡è¿™äº›è®¾è®¡ï¼ŒEGFormerèƒ½å¤Ÿåˆ©ç”¨æ‰€æœ‰å¯ç”¨æ¨¡æ€çš„ä¿¡æ¯ï¼ŒåŒæ—¶å»é™¤å†—ä½™ï¼Œç¡®ä¿é«˜è´¨é‡çš„åˆ†å‰²ã€‚æ­¤å¤–ï¼ŒEGFormeråœ¨åˆæˆåˆ°çœŸå®çš„è¿ç§»ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒEGFormeråœ¨å‚æ•°ä¸Šå‡å°‘äº†å¤šè¾¾88%ï¼ŒGFLOPså‡å°‘äº†50%ï¼Œåœ¨æ— ç›‘ç£é¢†åŸŸé€‚åº”è®¾ç½®ä¸‹ï¼Œè¿›ä¸€æ­¥å®ç°äº†é¢†å…ˆçš„è¿ç§»æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€è¯­ä¹‰åˆ†å‰²ä¸­çš„è®¡ç®—æ•ˆç‡é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨æé«˜å‡†ç¡®æ€§çš„åŒæ—¶ï¼Œå¾€å¾€å¿½è§†äº†æ¨¡å‹çš„è®¡ç®—å¼€é”€ï¼Œå¯¼è‡´å®é™…åº”ç”¨ä¸­çš„æ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šEGFormeré€šè¿‡å¼•å…¥ä¸¤ä¸ªæ–°æ¨¡å—ï¼ŒASMå’ŒMDMï¼Œæ¥åŠ¨æ€è¯„ä¼°å’Œé€‰æ‹©æ¨¡æ€ï¼Œä»è€Œå‡å°‘å†—ä½™ä¿¡æ¯å¹¶æé«˜æ¨¡å‹æ•ˆç‡ã€‚ASMä¸ºæ¯ä¸ªæ¨¡æ€åˆ†é…é‡è¦æ€§è¯„åˆ†ï¼ŒMDMåˆ™åœ¨æ¯ä¸ªé˜¶æ®µè¿‡æ»¤æ‰ä¿¡æ¯é‡è¾ƒå°‘çš„æ¨¡æ€ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEGFormerçš„æ•´ä½“æ¶æ„åŒ…æ‹¬è¾“å…¥å¤šæ¨¡æ€æ•°æ®ã€é€šè¿‡ASMè¿›è¡Œæ¨¡æ€è¯„åˆ†ã€ä½¿ç”¨MDMè¿›è¡Œæ¨¡æ€é€‰æ‹©å’Œä¿¡æ¯èšåˆï¼Œæœ€ç»ˆè¾“å‡ºé«˜è´¨é‡çš„è¯­ä¹‰åˆ†å‰²ç»“æœã€‚è¯¥æ¡†æ¶çµæ´»æ”¯æŒä»»æ„æ•°é‡çš„æ¨¡æ€è¾“å…¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šEGFormerçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶åŠ¨æ€æ¨¡æ€é€‰æ‹©æœºåˆ¶ï¼Œé€šè¿‡ASMå’ŒMDMæ¨¡å—çš„ç»“åˆï¼Œæœ‰æ•ˆå‡å°‘äº†æ¨¡å‹å‚æ•°å’Œè®¡ç®—é‡ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—æé«˜äº†æ•ˆç‡å’Œæ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸Šï¼ŒASMæ¨¡å—é‡‡ç”¨ç‹¬ç«‹è¯„åˆ†æœºåˆ¶ï¼ŒMDMæ¨¡å—åˆ™é€šè¿‡è®¾å®šé˜ˆå€¼æ¥è¿‡æ»¤æ¨¡æ€ã€‚æ¨¡å‹çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç»è¿‡ä¼˜åŒ–ï¼Œä»¥ç¡®ä¿åœ¨å‡å°‘è®¡ç®—é‡çš„åŒæ—¶ä¿æŒåˆ†å‰²ç²¾åº¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

EGFormeråœ¨å®éªŒä¸­è¡¨ç°å‡ºè‰²ï¼Œå‚æ•°å‡å°‘é«˜è¾¾88%ï¼ŒGFLOPså‡å°‘50%ã€‚åœ¨æ— ç›‘ç£é¢†åŸŸé€‚åº”ä»»åŠ¡ä¸­ï¼Œå…¶è¿ç§»æ€§èƒ½è¾¾åˆ°å½“å‰æœ€ä¼˜æ°´å¹³ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤šæ¨¡æ€è¯­ä¹‰åˆ†å‰²é¢†åŸŸçš„å¼ºå¤§èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

EGFormeråœ¨è‡ªåŠ¨é©¾é©¶ã€åŒ»å­¦å½±åƒåˆ†æå’Œæœºå™¨äººè§†è§‰ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚å…¶é«˜æ•ˆçš„å¤šæ¨¡æ€å¤„ç†èƒ½åŠ›èƒ½å¤Ÿå¸®åŠ©ç³»ç»Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­å¿«é€Ÿåšå‡ºå†³ç­–ï¼Œæå‡æ™ºèƒ½ç³»ç»Ÿçš„å®ç”¨æ€§å’Œå“åº”é€Ÿåº¦ã€‚æœªæ¥ï¼ŒEGFormeræœ‰æœ›åœ¨å®æ—¶å¤„ç†å’Œå¤§è§„æ¨¡æ•°æ®åˆ†æä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent efforts have explored multimodal semantic segmentation using various backbone architectures. However, while most methods aim to improve accuracy, their computational efficiency remains underexplored. To address this, we propose EGFormer, an efficient multimodal semantic segmentation framework that flexibly integrates an arbitrary number of modalities while significantly reducing model parameters and inference time without sacrificing performance. Our framework introduces two novel modules. First, the Any-modal Scoring Module (ASM) assigns importance scores to each modality independently, enabling dynamic ranking based on their feature maps. Second, the Modal Dropping Module (MDM) filters out less informative modalities at each stage, selectively preserving and aggregating only the most valuable features. This design allows the model to leverage useful information from all available modalities while discarding redundancy, thus ensuring high segmentation quality. In addition to efficiency, we evaluate EGFormer on a synthetic-to-real transfer task to demonstrate its generalizability. Extensive experiments show that EGFormer achieves competitive performance with up to 88 percent reduction in parameters and 50 percent fewer GFLOPs. Under unsupervised domain adaptation settings, it further achieves state-of-the-art transfer performance compared to existing methods.

