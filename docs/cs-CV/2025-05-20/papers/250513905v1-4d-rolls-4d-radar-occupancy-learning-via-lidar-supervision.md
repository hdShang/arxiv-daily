---
layout: default
title: 4D-ROLLS: 4D Radar Occupancy Learning via LiDAR Supervision
---

# 4D-ROLLS: 4D Radar Occupancy Learning via LiDAR Supervision

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.13905" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.13905v1</a>
  <a href="https://arxiv.org/pdf/2505.13905.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.13905v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.13905v1', '4D-ROLLS: 4D Radar Occupancy Learning via LiDAR Supervision')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ruihan Liu, Xiaoyi Wu, Xijun Chen, Liang Hu, Yunjiang Lou

**åˆ†ç±»**: cs.CV, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/CLASS-Lab/4D-ROLLS)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡º4D-ROLLSä»¥è§£å†³4Dé›·è¾¾å ç”¨ä¼°è®¡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `4Dé›·è¾¾` `å ç”¨ä¼°è®¡` `å¼±ç›‘ç£å­¦ä¹ ` `LiDAR` `è‡ªåŠ¨é©¾é©¶` `æ·±åº¦å­¦ä¹ ` `å¤šæ¨¡æ€èåˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å ç”¨ä¼°è®¡æ–¹æ³•å¤šä¾èµ–äºLiDARæˆ–æ‘„åƒå¤´ï¼Œä¸”åœ¨æ¶åŠ£ç¯å¢ƒä¸‹è¡¨ç°ä¸ä½³ï¼Œé™åˆ¶äº†å…¶åº”ç”¨ã€‚
2. æœ¬æ–‡æå‡º4D-ROLLSï¼Œé€šè¿‡LiDARç‚¹äº‘ç”Ÿæˆä¼ªæ ‡ç­¾ï¼Œè¿›è¡Œå¼±ç›‘ç£è®­ç»ƒï¼Œæå‡4Dé›·è¾¾çš„å ç”¨ä¼°è®¡èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œ4D-ROLLSåœ¨æ¶åŠ£ç¯å¢ƒä¸‹è¡¨ç°ä¼˜å¼‚ï¼Œä¸”åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­å…·æœ‰è‰¯å¥½çš„è¿ç§»æ€§ï¼Œæ¨å‘æ›´å¹¿æ³›çš„åº”ç”¨ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å…¨é¢ç†è§£3Dåœºæ™¯å¯¹äºè‡ªåŠ¨é©¾é©¶æ±½è½¦è‡³å…³é‡è¦ï¼Œè€Œå ç”¨ä¼°è®¡åœ¨æä¾›å¯é©¾é©¶å’Œè¢«å ç©ºé—´çš„é€šç”¨è¡¨ç¤ºä¸­æ‰®æ¼”æ ¸å¿ƒè§’è‰²ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å¤šä¾èµ–äºLiDARæˆ–æ‘„åƒå¤´ï¼Œåœ¨çƒŸé›¾ã€é›¨é›ªå’Œé›¾éœ¾ç­‰æ¶åŠ£ç¯å¢ƒä¸­è¡¨ç°ä¸ä½³ã€‚æœ¬æ–‡æå‡ºäº†4D-ROLLSï¼Œè¿™æ˜¯é¦–ä¸ªä½¿ç”¨LiDARç‚¹äº‘ä½œä¸ºç›‘ç£ä¿¡å·çš„å¼±ç›‘ç£4Dé›·è¾¾å ç”¨ä¼°è®¡æ–¹æ³•ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ç”Ÿæˆä¼ªLiDARæ ‡ç­¾çš„æ–¹æ³•ï¼ŒåŒ…æ‹¬å ç”¨æŸ¥è¯¢å’ŒLiDARé«˜åº¦å›¾ï¼Œä½œä¸ºå¤šé˜¶æ®µç›‘ç£æ¥è®­ç»ƒ4Dé›·è¾¾å ç”¨ä¼°è®¡æ¨¡å‹ã€‚é€šè¿‡ä¸LiDARç”Ÿæˆçš„å ç”¨å›¾å¯¹é½ï¼Œæ¨¡å‹çš„å ç”¨ä¼°è®¡ç²¾åº¦å¾—åˆ°äº†æå‡ã€‚å¤§é‡å®éªŒéªŒè¯äº†4D-ROLLSçš„å“è¶Šæ€§èƒ½ï¼Œå±•ç¤ºäº†å…¶åœ¨æ¶åŠ£ç¯å¢ƒä¸­çš„é²æ£’æ€§å’Œè·¨æ•°æ®é›†è®­ç»ƒçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å ç”¨ä¼°è®¡æ–¹æ³•åœ¨æ¶åŠ£ç¯å¢ƒä¸‹çš„æ€§èƒ½ä¸è¶³ï¼Œå°¤å…¶æ˜¯ä¾èµ–äºLiDARå’Œæ‘„åƒå¤´çš„å±€é™æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡º4D-ROLLSï¼Œé€šè¿‡ç”Ÿæˆä¼ªLiDARæ ‡ç­¾æ¥è¿›è¡Œå¼±ç›‘ç£è®­ç»ƒï¼Œä½¿4Dé›·è¾¾èƒ½å¤Ÿæ›´å‡†ç¡®åœ°è¿›è¡Œå ç”¨ä¼°è®¡ã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—æ¨¡å‹åœ¨ç¼ºä¹é«˜è´¨é‡æ ‡æ³¨çš„æƒ…å†µä¸‹ä»èƒ½å­¦ä¹ åˆ°æœ‰æ•ˆçš„ç‰¹å¾ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¼ªæ ‡ç­¾ç”Ÿæˆæ¨¡å—å’Œå ç”¨ä¼°è®¡æ¨¡å‹ã€‚ä¼ªæ ‡ç­¾ç”Ÿæˆæ¨¡å—è´Ÿè´£ç”Ÿæˆå ç”¨æŸ¥è¯¢å’ŒLiDARé«˜åº¦å›¾ï¼Œä½œä¸ºå¤šé˜¶æ®µç›‘ç£ä¿¡å·ï¼›å ç”¨ä¼°è®¡æ¨¡å‹åˆ™é€šè¿‡ä¸LiDARç”Ÿæˆçš„å ç”¨å›¾å¯¹é½è¿›è¡Œè®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼š4D-ROLLSçš„åˆ›æ–°åœ¨äºé¦–æ¬¡å°†LiDARç‚¹äº‘ä½œä¸ºå¼±ç›‘ç£ä¿¡å·ç”¨äº4Dé›·è¾¾çš„å ç”¨ä¼°è®¡ï¼Œæ˜¾è‘—æå‡äº†åœ¨æ¶åŠ£ç¯å¢ƒä¸‹çš„é²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡å‹é‡‡ç”¨è½»é‡çº§ç½‘ç»œç»“æ„ï¼Œç¡®ä¿åœ¨4060 GPUä¸Šä»¥çº¦30 Hzçš„é€Ÿåº¦è¿›è¡Œå¿«é€Ÿæ¨ç†ã€‚æŸå¤±å‡½æ•°è®¾è®¡ä¸ºå¤šé˜¶æ®µæŸå¤±ï¼Œç»“åˆå ç”¨æŸ¥è¯¢å’Œé«˜åº¦å›¾ä¿¡æ¯ï¼Œä¼˜åŒ–æ¨¡å‹çš„å­¦ä¹ è¿‡ç¨‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œ4D-ROLLSåœ¨æ¶åŠ£ç¯å¢ƒä¸­çš„å ç”¨ä¼°è®¡æ€§èƒ½æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨è·¨æ•°æ®é›†è®­ç»ƒä¸­è¡¨ç°å‡ºè‰²ï¼ŒéªŒè¯äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§å’Œé²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½äº¤é€šç³»ç»Ÿå’Œæœºå™¨äººå¯¼èˆªç­‰é¢†åŸŸã€‚é€šè¿‡æé«˜4Dé›·è¾¾åœ¨å¤æ‚ç¯å¢ƒä¸­çš„å ç”¨ä¼°è®¡èƒ½åŠ›ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„å®‰å…¨æ€§å’Œå¯é æ€§ï¼Œæ¨åŠ¨æ™ºèƒ½äº¤é€šæŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> A comprehensive understanding of 3D scenes is essential for autonomous vehicles (AVs), and among various perception tasks, occupancy estimation plays a central role by providing a general representation of drivable and occupied space. However, most existing occupancy estimation methods rely on LiDAR or cameras, which perform poorly in degraded environments such as smoke, rain, snow, and fog. In this paper, we propose 4D-ROLLS, the first weakly supervised occupancy estimation method for 4D radar using the LiDAR point cloud as the supervisory signal. Specifically, we introduce a method for generating pseudo-LiDAR labels, including occupancy queries and LiDAR height maps, as multi-stage supervision to train the 4D radar occupancy estimation model. Then the model is aligned with the occupancy map produced by LiDAR, fine-tuning its accuracy in occupancy estimation. Extensive comparative experiments validate the exceptional performance of 4D-ROLLS. Its robustness in degraded environments and effectiveness in cross-dataset training are qualitatively demonstrated. The model is also seamlessly transferred to downstream tasks BEV segmentation and point cloud occupancy prediction, highlighting its potential for broader applications. The lightweight network enables 4D-ROLLS model to achieve fast inference speeds at about 30 Hz on a 4060 GPU. The code of 4D-ROLLS will be made available at https://github.com/CLASS-Lab/4D-ROLLS.

