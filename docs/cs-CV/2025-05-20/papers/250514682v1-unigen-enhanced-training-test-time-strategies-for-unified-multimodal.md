---
layout: default
title: "UniGen: Enhanced Training & Test-Time Strategies for Unified Multimodal Understanding and Generation"
---

# UniGen: Enhanced Training & Test-Time Strategies for Unified Multimodal Understanding and Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14682" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14682v1</a>
  <a href="https://arxiv.org/pdf/2505.14682.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14682v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14682v1', 'UniGen: Enhanced Training & Test-Time Strategies for Unified Multimodal Understanding and Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Rui Tian, Mingfei Gao, Mingze Xu, Jiaming Hu, Jiasen Lu, Zuxuan Wu, Yinfei Yang, Afshin Dehghan

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20

**å¤‡æ³¨**: Technical report

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºUniGenä»¥è§£å†³å¤šæ¨¡æ€ç†è§£ä¸ç”Ÿæˆçš„æŒ‘æˆ˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ¨¡å‹` `å›¾åƒç”Ÿæˆ` `é“¾å¼æ€ç»´éªŒè¯` `è¯­ä¹‰å¯¹é½` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤šæ¨¡æ€æ¨¡å‹åœ¨å›¾åƒç†è§£ä¸ç”Ÿæˆçš„è´¨é‡å’Œä¸€è‡´æ€§ä¸Šå­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥æœ‰æ•ˆè¯„ä¼°ç”Ÿæˆç»“æœä¸æ–‡æœ¬æç¤ºä¹‹é—´çš„è¯­ä¹‰å¯¹é½ã€‚
2. è®ºæ–‡æå‡ºäº†UniGenæ¨¡å‹ï¼Œç»“åˆå¤šé˜¶æ®µé¢„è®­ç»ƒå’Œé“¾å¼æ€ç»´éªŒè¯ç­–ç•¥ï¼Œåœ¨æµ‹è¯•æ—¶æå‡ç”Ÿæˆè´¨é‡ï¼Œç¡®ä¿å›¾åƒä¸æ–‡æœ¬çš„è¯­ä¹‰ä¸€è‡´æ€§ã€‚
3. UniGenåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼ŒGenEvalå¾—åˆ†0.78ï¼ŒDPG-Benchå¾—åˆ†85.19ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤šæ¨¡æ€ä»»åŠ¡ä¸­çš„å¼ºå¤§èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬ä»‹ç»äº†UniGenï¼Œè¿™æ˜¯ä¸€ç§ç»Ÿä¸€çš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ï¼Œèƒ½å¤Ÿè¿›è¡Œå›¾åƒç†è§£å’Œç”Ÿæˆã€‚æˆ‘ä»¬ä»æ•°æ®ä¸­å¿ƒçš„è§’åº¦ç ”ç©¶äº†UniGençš„å®Œæ•´è®­ç»ƒæµç¨‹ï¼ŒåŒ…æ‹¬å¤šé˜¶æ®µé¢„è®­ç»ƒã€ç›‘ç£å¾®è°ƒå’Œç›´æ¥åå¥½ä¼˜åŒ–ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„é“¾å¼æ€ç»´éªŒè¯ï¼ˆCoT-Vï¼‰ç­–ç•¥ï¼Œç”¨äºæµ‹è¯•æ—¶æ‰©å±•ï¼Œæ˜¾è‘—æå‡äº†UniGençš„å›¾åƒç”Ÿæˆè´¨é‡ã€‚UniGenåœ¨æ‰€æœ‰é˜¶æ®µå®Œå…¨åŸºäºå¼€æºæ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œåœ¨ä¸€ç³»åˆ—å›¾åƒç†è§£å’Œç”ŸæˆåŸºå‡†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œæœ€ç»ˆåœ¨GenEvalä¸Šå¾—åˆ†0.78ï¼Œåœ¨DPG-Benchä¸Šå¾—åˆ†85.19ã€‚é€šè¿‡å¹¿æ³›çš„æ¶ˆèç ”ç©¶ï¼Œæˆ‘ä»¬çš„å·¥ä½œæä¾›äº†å¯æ“ä½œçš„è§è§£ï¼Œå¹¶è§£å†³äº†æ„å»ºç»Ÿä¸€MLLMçš„å…¨ç”Ÿå‘½å‘¨æœŸä¸­çš„å…³é”®æŒ‘æˆ˜ï¼Œä¸ºæœªæ¥ç ”ç©¶è´¡çŒ®äº†æœ‰æ„ä¹‰çš„æ–¹å‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¤šæ¨¡æ€æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆä¸ç†è§£ä¸­çš„è´¨é‡ä¸è¶³åŠå…¶ä¸æ–‡æœ¬æç¤ºçš„è¯­ä¹‰å¯¹é½é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•æœ‰æ•ˆè¯„ä¼°ç”Ÿæˆç»“æœçš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ï¼Œå¯¼è‡´ç”Ÿæˆå›¾åƒä¸æ–‡æœ¬æç¤ºä¹‹é—´å­˜åœ¨è¾ƒå¤§å·®è·ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„UniGenæ¨¡å‹é€šè¿‡å¼•å…¥é“¾å¼æ€ç»´éªŒè¯ï¼ˆCoT-Vï¼‰ç­–ç•¥ï¼Œåœ¨æµ‹è¯•é˜¶æ®µå®ç°å›¾åƒç”Ÿæˆä¸éªŒè¯çš„åŒé‡åŠŸèƒ½ï¼Œé€æ­¥è¯„ä¼°ç”Ÿæˆå›¾åƒä¸æ–‡æœ¬æç¤ºçš„è¯­ä¹‰ä¸€è‡´æ€§ï¼Œä»è€Œæå‡ç”Ÿæˆè´¨é‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šUniGençš„æ•´ä½“æ¶æ„åŒ…æ‹¬å¤šé˜¶æ®µé¢„è®­ç»ƒã€ç›‘ç£å¾®è°ƒå’Œç›´æ¥åå¥½ä¼˜åŒ–ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚é¢„è®­ç»ƒé˜¶æ®µåˆ©ç”¨å¼€æºæ•°æ®é›†è¿›è¡Œå¤§è§„æ¨¡è®­ç»ƒï¼Œå¾®è°ƒé˜¶æ®µåˆ™é’ˆå¯¹ç‰¹å®šä»»åŠ¡è¿›è¡Œä¼˜åŒ–ï¼Œæœ€åé€šè¿‡åå¥½ä¼˜åŒ–è¿›ä¸€æ­¥æå‡æ¨¡å‹æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºæå‡ºçš„CoT-Vç­–ç•¥ï¼Œä½¿å¾—æ¨¡å‹åœ¨ç”Ÿæˆå›¾åƒçš„åŒæ—¶èƒ½å¤Ÿè¿›è¡Œè¯­ä¹‰éªŒè¯ã€‚è¿™ä¸€ç­–ç•¥ä¸ä¼ ç»Ÿçš„ç”Ÿæˆæ¨¡å‹ä¸åŒï¼Œå¼ºè°ƒäº†ç”Ÿæˆä¸éªŒè¯çš„ååŒä½œç”¨ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼ŒUniGené‡‡ç”¨äº†å¤šå±‚æ¬¡çš„ç½‘ç»œç»“æ„ï¼Œç»“åˆäº†è‡ªæ³¨æ„åŠ›æœºåˆ¶å’Œå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ï¼Œå¹¶åœ¨æŸå¤±å‡½æ•°ä¸­å¼•å…¥äº†è¯­ä¹‰ä¸€è‡´æ€§æŸå¤±ï¼Œä»¥ç¡®ä¿ç”Ÿæˆå›¾åƒä¸æ–‡æœ¬æç¤ºä¹‹é—´çš„é«˜åŒ¹é…åº¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

UniGenåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼ŒGenEvalå¾—åˆ†è¾¾åˆ°0.78ï¼ŒDPG-Benchå¾—åˆ†85.19ï¼Œå‡ä¸ºå½“å‰æœ€å…ˆè¿›çš„æ°´å¹³ã€‚é€šè¿‡å¼•å…¥CoT-Vç­–ç•¥ï¼Œæ¨¡å‹åœ¨å›¾åƒç”Ÿæˆè´¨é‡ä¸Šæ˜¾è‘—æå‡ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤šæ¨¡æ€ä»»åŠ¡ä¸­çš„å¼ºå¤§èƒ½åŠ›å’Œåº”ç”¨æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

UniGençš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼ŒåŒ…æ‹¬æ™ºèƒ½å›¾åƒç”Ÿæˆã€è‡ªåŠ¨åŒ–å†…å®¹åˆ›ä½œã€è™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®ç­‰ã€‚å…¶å¼ºå¤§çš„å¤šæ¨¡æ€ç†è§£èƒ½åŠ›å¯ä»¥ä¸ºäººæœºäº¤äº’ã€æ•™è‚²å’Œå¨±ä¹ç­‰è¡Œä¸šå¸¦æ¥æ–°çš„åˆ›æ–°å’Œä»·å€¼ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We introduce UniGen, a unified multimodal large language model (MLLM) capable of image understanding and generation. We study the full training pipeline of UniGen from a data-centric perspective, including multi-stage pre-training, supervised fine-tuning, and direct preference optimization. More importantly, we propose a new Chain-of-Thought Verification (CoT-V) strategy for test-time scaling, which significantly boosts UniGen's image generation quality using a simple Best-of-N test-time strategy. Specifically, CoT-V enables UniGen to act as both image generator and verifier at test time, assessing the semantic alignment between a text prompt and its generated image in a step-by-step CoT manner. Trained entirely on open-source datasets across all stages, UniGen achieves state-of-the-art performance on a range of image understanding and generation benchmarks, with a final score of 0.78 on GenEval and 85.19 on DPG-Bench. Through extensive ablation studies, our work provides actionable insights and addresses key challenges in the full life cycle of building unified MLLMs, contributing meaningful directions to the future research.

