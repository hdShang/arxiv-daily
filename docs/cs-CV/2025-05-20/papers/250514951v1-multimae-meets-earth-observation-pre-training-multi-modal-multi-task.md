---
layout: default
title: "MultiMAE Meets Earth Observation: Pre-training Multi-modal Multi-task Masked Autoencoders for Earth Observation Tasks"
---

# MultiMAE Meets Earth Observation: Pre-training Multi-modal Multi-task Masked Autoencoders for Earth Observation Tasks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14951" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14951v1</a>
  <a href="https://arxiv.org/pdf/2505.14951.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14951v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14951v1', 'MultiMAE Meets Earth Observation: Pre-training Multi-modal Multi-task Masked Autoencoders for Earth Observation Tasks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jose Sosa, Danila Rukhovich, Anis Kacem, Djamila Aouada

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/josesosajs/multimae-meets-eo)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMultiMAEä»¥è§£å†³å¤šæ¨¡æ€åœ°çƒè§‚æµ‹ä»»åŠ¡çš„é¢„è®­ç»ƒé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `åœ°çƒè§‚æµ‹` `è¿ç§»å­¦ä¹ ` `è‡ªç¼–ç å™¨` `æ·±åº¦å­¦ä¹ ` `é¥æ„Ÿæ•°æ®` `åˆ†ç±»ä»»åŠ¡` `åˆ†å‰²ä»»åŠ¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å°†å¤šæ¨¡æ€åœ°çƒè§‚æµ‹æ•°æ®çš„å­¦ä¹ æœ‰æ•ˆè½¬ç§»åˆ°ä¸‹æ¸¸ä»»åŠ¡æ—¶é¢ä¸´ç»“æ„å·®å¼‚å¸¦æ¥çš„æŒ‘æˆ˜ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€å¤šä»»åŠ¡æ©ç è‡ªç¼–ç å™¨ï¼ˆMultiMAEï¼‰ï¼Œé€šè¿‡é‡æ„å¤šç§è¾“å…¥æ¨¡æ€è¿›è¡Œé¢„è®­ç»ƒï¼Œå¢å¼ºæ¨¡å‹çš„çµæ´»æ€§ã€‚
3. é¢„è®­ç»ƒæ¨¡å‹åœ¨å¤šä¸ªEOæ•°æ®é›†çš„åˆ†ç±»å’Œåˆ†å‰²ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†å½“å‰çš„æœ€å…ˆè¿›æ–¹æ³•ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„è¿ç§»å­¦ä¹ èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€æ•°æ®åœ¨åœ°çƒè§‚æµ‹ï¼ˆEOï¼‰ä¸­ä¸ºæ·±åº¦å­¦ä¹ æ¨¡å‹çš„è¿ç§»å­¦ä¹ èƒ½åŠ›æå‡æä¾›äº†å·¨å¤§æœºä¼šã€‚å°½ç®¡ä»¥å¾€çš„ç ”ç©¶å¸¸å¸¸å¿½è§†å¤šæ¨¡æ€EOæ•°æ®ï¼Œä½†è¿‘æœŸæ–¹æ³•å¼€å§‹çº³å…¥è¿™äº›æ•°æ®ï¼Œä»è€Œå½¢æˆæ›´æœ‰æ•ˆçš„é¢„è®­ç»ƒç­–ç•¥ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•åœ¨å°†å­¦ä¹ æœ‰æ•ˆè½¬ç§»åˆ°ä¸‹æ¸¸ä»»åŠ¡æ—¶å¸¸é¢ä¸´æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯å½“å¯ç”¨æ•°æ®çš„ç»“æ„ä¸é¢„è®­ç»ƒæ—¶ä¸åŒã€‚æœ¬æ–‡é€šè¿‡æ¢ç´¢æ›´çµæ´»çš„å¤šæ¨¡æ€ã€å¤šä»»åŠ¡é¢„è®­ç»ƒç­–ç•¥æ¥è§£å†³è¿™ä¸€é™åˆ¶ï¼Œé‡‡ç”¨å¤šæ¨¡æ€å¤šä»»åŠ¡æ©ç è‡ªç¼–ç å™¨ï¼ˆMultiMAEï¼‰ï¼Œé€šè¿‡é‡æ„å¤šæ ·çš„è¾“å…¥æ¨¡æ€ï¼ˆåŒ…æ‹¬å…‰è°±ã€é«˜ç¨‹å’Œåˆ†å‰²æ•°æ®ï¼‰è¿›è¡Œé¢„è®­ç»ƒã€‚é¢„è®­ç»ƒæ¨¡å‹åœ¨åˆ†ç±»å’Œåˆ†å‰²ä»»åŠ¡ä¸Šå±•ç°å‡ºå¼ºå¤§çš„è¿ç§»å­¦ä¹ èƒ½åŠ›ï¼Œè¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¤šæ¨¡æ€åœ°çƒè§‚æµ‹æ•°æ®é¢„è®­ç»ƒæ–¹æ³•åœ¨è¿ç§»å­¦ä¹ æ—¶é¢ä¸´çš„ç»“æ„å·®å¼‚é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•æœ‰æ•ˆé€‚åº”ä¸‹æ¸¸ä»»åŠ¡çš„æ•°æ®ç»“æ„ï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€å¤šä»»åŠ¡æ©ç è‡ªç¼–ç å™¨ï¼ˆMultiMAEï¼‰ï¼Œé€šè¿‡é‡æ„å¤šç§è¾“å…¥æ¨¡æ€ï¼ˆå¦‚å…‰è°±ã€é«˜ç¨‹å’Œåˆ†å‰²æ•°æ®ï¼‰è¿›è¡Œé¢„è®­ç»ƒï¼Œä»è€Œå¢å¼ºæ¨¡å‹çš„çµæ´»æ€§å’Œè¿ç§»èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®è¾“å…¥æ¨¡å—ã€æ©ç è‡ªç¼–ç å™¨æ¨¡å—å’Œè¾“å‡ºé‡æ„æ¨¡å—ã€‚æ•°æ®è¾“å…¥æ¨¡å—è´Ÿè´£æ¥æ”¶å¤šæ¨¡æ€æ•°æ®ï¼Œæ©ç è‡ªç¼–ç å™¨æ¨¡å—è¿›è¡Œç‰¹å¾å­¦ä¹ ï¼Œè¾“å‡ºé‡æ„æ¨¡å—åˆ™ç”Ÿæˆé‡æ„ç»“æœä»¥ä¼˜åŒ–æ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºMultiMAEçš„è®¾è®¡ï¼Œä½¿å…¶èƒ½å¤Ÿå¤„ç†å¤šç§è¾“å…¥é…ç½®ï¼Œè€Œæ— éœ€é’ˆå¯¹æ¯ç§æ¨¡æ€è¿›è¡Œç‰¹å®šçš„é¢„è®­ç»ƒï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„é€‚åº”æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å¤šæ¨¡æ€è¾“å…¥å’Œæ©ç ç­–ç•¥ï¼ŒæŸå¤±å‡½æ•°ç»“åˆäº†é‡æ„æŸå¤±å’Œåˆ†ç±»æŸå¤±ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹åœ¨å¤šä»»åŠ¡å­¦ä¹ ä¸­çš„è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å¤šä¸ªåœ°çƒè§‚æµ‹æ•°æ®é›†ä¸Šï¼Œé¢„è®­ç»ƒçš„MultiMAEæ¨¡å‹åœ¨åˆ†ç±»å’Œåˆ†å‰²ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ï¼Œå…·ä½“æ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°äº†XX%ã€‚è¿™ä¸€ç»“æœè¡¨æ˜è¯¥æ–¹æ³•åœ¨è¿ç§»å­¦ä¹ ä¸­çš„æœ‰æ•ˆæ€§å’Œçµæ´»æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬é¥æ„Ÿå›¾åƒåˆ†æã€ç¯å¢ƒç›‘æµ‹å’ŒåŸå¸‚è§„åˆ’ç­‰ã€‚é€šè¿‡æå‡å¤šæ¨¡æ€æ•°æ®çš„å¤„ç†èƒ½åŠ›ï¼ŒMultiMAEèƒ½å¤Ÿä¸ºå®é™…åº”ç”¨æä¾›æ›´å‡†ç¡®çš„åˆ†æç»“æœï¼Œæ¨åŠ¨åœ°çƒè§‚æµ‹æŠ€æœ¯çš„å‘å±•ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multi-modal data in Earth Observation (EO) presents a huge opportunity for improving transfer learning capabilities when pre-training deep learning models. Unlike prior work that often overlooks multi-modal EO data, recent methods have started to include it, resulting in more effective pre-training strategies. However, existing approaches commonly face challenges in effectively transferring learning to downstream tasks where the structure of available data differs from that used during pre-training. This paper addresses this limitation by exploring a more flexible multi-modal, multi-task pre-training strategy for EO data. Specifically, we adopt a Multi-modal Multi-task Masked Autoencoder (MultiMAE) that we pre-train by reconstructing diverse input modalities, including spectral, elevation, and segmentation data. The pre-trained model demonstrates robust transfer learning capabilities, outperforming state-of-the-art methods on various EO datasets for classification and segmentation tasks. Our approach exhibits significant flexibility, handling diverse input configurations without requiring modality-specific pre-trained models. Code will be available at: https://github.com/josesosajs/multimae-meets-eo.

