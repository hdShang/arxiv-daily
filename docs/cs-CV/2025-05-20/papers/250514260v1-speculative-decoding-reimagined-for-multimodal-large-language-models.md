---
layout: default
title: Speculative Decoding Reimagined for Multimodal Large Language Models
---

# Speculative Decoding Reimagined for Multimodal Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.14260" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.14260v1</a>
  <a href="https://arxiv.org/pdf/2505.14260.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.14260v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.14260v1', 'Speculative Decoding Reimagined for Multimodal Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Luxi Lin, Zhihang Lin, Zhanpeng Zeng, Rongrong Ji

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20

**å¤‡æ³¨**: 12 pages

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Lyn-Lucy/MSD)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šæ¨¡æ€æ¨æµ‹è§£ç ä»¥åŠ é€Ÿå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹æ¨ç†**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ¨æµ‹è§£ç ` `å¤§è¯­è¨€æ¨¡å‹` `æ¨ç†åŠ é€Ÿ` `è§†è§‰æ„ŸçŸ¥` `è¯­è¨€å»ºæ¨¡` `æ¨¡å‹è®­ç»ƒ` `æ–‡æœ¬å¤„ç†` `è§†è§‰å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€æ¨æµ‹è§£ç æ–¹æ³•æœªèƒ½å®ç°ä¸å•æ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ç›¸åŒçš„æ¨ç†åŠ é€Ÿæ•ˆæœï¼Œé™åˆ¶äº†å…¶åº”ç”¨æ½œåŠ›ã€‚
2. æœ¬æ–‡æå‡ºçš„å¤šæ¨¡æ€æ¨æµ‹è§£ç ï¼ˆMSDï¼‰æ–¹æ³•ï¼Œé€šè¿‡åˆ†ç¦»æ–‡æœ¬å’Œè§†è§‰æ ‡è®°çš„å¤„ç†ï¼Œæå‡äº†å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†é€Ÿåº¦ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMSDåœ¨å¤šæ¨¡æ€åŸºå‡†ä¸Šæ˜¾è‘—æé«˜äº†LLaVAæ¨¡å‹çš„æ¨ç†é€Ÿåº¦ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ä»‹ç»äº†å¤šæ¨¡æ€æ¨æµ‹è§£ç ï¼ˆMSDï¼‰ï¼Œæ—¨åœ¨åŠ é€Ÿå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„æ¨ç†ã€‚å°½ç®¡æ¨æµ‹è§£ç å·²è¢«è¯æ˜å¯ä»¥åŠ é€Ÿå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è€Œä¸ç‰ºç‰²å‡†ç¡®æ€§ï¼Œä½†ç°æœ‰çš„å¤šæ¨¡æ€æ¨æµ‹è§£ç æ–¹æ³•æœªèƒ½å®ç°ä¸LLMsç›¸åŒçš„åŠ é€Ÿæ•ˆæœã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡ä¸“é—¨ä¸ºMLLMsé‡æ–°æ„æƒ³äº†æ¨æµ‹è§£ç ã€‚é€šè¿‡å¯¹MLLMç‰¹æ€§çš„åˆ†æï¼Œæå‡ºäº†MSDçš„ä¸¤ä¸ªå…³é”®è®¾è®¡åŸåˆ™ï¼šæ–‡æœ¬å’Œè§†è§‰æ ‡è®°å…·æœ‰æ ¹æœ¬ä¸åŒçš„ç‰¹æ€§ï¼Œéœ€åœ¨è‰æ‹Ÿè¿‡ç¨‹ä¸­åˆ†å¼€å¤„ç†ï¼›è¯­è¨€å»ºæ¨¡èƒ½åŠ›å’Œè§†è§‰æ„ŸçŸ¥èƒ½åŠ›å¯¹è‰æ‹Ÿæ¨¡å‹è‡³å…³é‡è¦ã€‚å®éªŒè¡¨æ˜ï¼ŒMSDåœ¨å¤šæ¨¡æ€åŸºå‡†ä¸Šä½¿LLaVA-1.5-7Bçš„æ¨ç†é€Ÿåº¦æé«˜äº†2.29å€ï¼ŒLLaVA-1.5-13Bçš„æ¨ç†é€Ÿåº¦æé«˜äº†2.46å€ï¼Œå±•ç¤ºäº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¤šæ¨¡æ€æ¨æµ‹è§£ç æ–¹æ³•åœ¨æ¨ç†é€Ÿåº¦ä¸Šçš„ä¸è¶³ï¼Œç‰¹åˆ«æ˜¯ä¸å•æ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ç›¸æ¯”ï¼Œæœªèƒ½å®ç°ç›¸åŒçš„åŠ é€Ÿæ•ˆæœã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é‡æ–°æ„æƒ³æ¨æµ‹è§£ç ï¼Œé’ˆå¯¹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„ç‰¹æ€§ï¼Œæå‡ºåˆ†ç¦»å¤„ç†æ–‡æœ¬å’Œè§†è§‰æ ‡è®°çš„æ–¹æ¡ˆï¼Œä»¥ä¾¿æ›´å¥½åœ°åˆ©ç”¨å„è‡ªçš„ç‰¹æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªé˜¶æ®µçš„è®­ç»ƒç­–ç•¥ï¼šç¬¬ä¸€é˜¶æ®µï¼Œè‰æ‹Ÿæ¨¡å‹åœ¨ä»…æ–‡æœ¬çš„æŒ‡ä»¤è°ƒä¼˜æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œä»¥æå‡è¯­è¨€å»ºæ¨¡èƒ½åŠ›ï¼›ç¬¬äºŒé˜¶æ®µï¼Œé€æ­¥å¼•å…¥å¤šæ¨¡æ€æ•°æ®ï¼Œå¢å¼ºè§†è§‰æ„ŸçŸ¥èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†æ–‡æœ¬å’Œè§†è§‰æ ‡è®°çš„å¤„ç†è§£è€¦ï¼Œå…è®¸æ ¹æ®å„è‡ªç‰¹æ€§è¿›è¡Œä¼˜åŒ–ï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„æ•´ä½“å¤„ç†æ–¹å¼å½¢æˆäº†æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†åˆ†é˜¶æ®µçš„ç­–ç•¥ï¼Œç¬¬ä¸€é˜¶æ®µä¸“æ³¨äºæ–‡æœ¬æ•°æ®ï¼Œç¬¬äºŒé˜¶æ®µå¼•å…¥è§†è§‰æ•°æ®ï¼Œç¡®ä¿æ¨¡å‹åœ¨è¯­è¨€å’Œè§†è§‰ç†è§£èƒ½åŠ›ä¸Šå‡è¡¡æå‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒMSDåœ¨å¤šæ¨¡æ€åŸºå‡†ä¸Šæ˜¾è‘—æå‡äº†æ¨ç†é€Ÿåº¦ï¼ŒLLaVA-1.5-7Bçš„æ¨ç†é€Ÿåº¦æé«˜äº†2.29å€ï¼ŒLLaVA-1.5-13Bçš„æ¨ç†é€Ÿåº¦æé«˜äº†2.46å€ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤šæ¨¡æ€ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½åŠ©æ‰‹ã€è‡ªåŠ¨å†…å®¹ç”Ÿæˆã€å›¾åƒæè¿°ç”Ÿæˆç­‰å¤šæ¨¡æ€ä»»åŠ¡ã€‚é€šè¿‡åŠ é€Ÿæ¨ç†è¿‡ç¨‹ï¼ŒMSDèƒ½å¤Ÿåœ¨å®é™…åº”ç”¨ä¸­æä¾›æ›´å¿«é€Ÿçš„å“åº”ï¼Œæå‡ç”¨æˆ·ä½“éªŒï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper introduces Multimodal Speculative Decoding (MSD) to accelerate Multimodal Large Language Models (MLLMs) inference. Speculative decoding has been shown to accelerate Large Language Models (LLMs) without sacrificing accuracy. However, current speculative decoding methods for MLLMs fail to achieve the same speedup as they do for LLMs. To address this, we reimagine speculative decoding specifically for MLLMs. Our analysis of MLLM characteristics reveals two key design principles for MSD: (1) Text and visual tokens have fundamentally different characteristics and need to be processed separately during drafting. (2) Both language modeling ability and visual perception capability are crucial for the draft model. For the first principle, MSD decouples text and visual tokens in the draft model, allowing each to be handled based on its own characteristics. For the second principle, MSD uses a two-stage training strategy: In stage one, the draft model is trained on text-only instruction-tuning datasets to improve its language modeling ability. In stage two, MSD gradually introduces multimodal data to enhance the visual perception capability of the draft model. Experiments show that MSD boosts inference speed by up to $2.29\times$ for LLaVA-1.5-7B and up to $2.46\times$ for LLaVA-1.5-13B on multimodal benchmarks, demonstrating its effectiveness. Our code is available at https://github.com/Lyn-Lucy/MSD.

