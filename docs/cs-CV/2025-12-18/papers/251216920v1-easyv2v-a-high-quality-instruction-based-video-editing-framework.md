---
layout: default
title: EasyV2V: A High-quality Instruction-based Video Editing Framework
---

# EasyV2V: A High-quality Instruction-based Video Editing Framework

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.16920" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.16920v1</a>
  <a href="https://arxiv.org/pdf/2512.16920.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.16920v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.16920v1', 'EasyV2V: A High-quality Instruction-based Video Editing Framework')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jinjie Mai, Chaoyang Wang, Guocheng Gordon Qian, Willi Menapace, Sergey Tulyakov, Bernard Ghanem, Peter Wonka, Ashkan Mirzaei

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-18

**å¤‡æ³¨**: Project page: https://snap-research.github.io/easyv2v/

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://snap-research.github.io/easyv2v/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**EasyV2Vï¼šé«˜è´¨é‡çš„åŸºäºæŒ‡ä»¤çš„è§†é¢‘ç¼–è¾‘æ¡†æ¶ï¼Œå®ç°çµæ´»å¯æ§çš„è§†é¢‘ç¼–è¾‘ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `è§†é¢‘ç¼–è¾‘` `æŒ‡ä»¤é©±åŠ¨` `æ–‡æœ¬åˆ°è§†é¢‘` `é¢„è®­ç»ƒæ¨¡å‹` `LoRAå¾®è°ƒ` `æ—¶ç©ºæ§åˆ¶` `æ•°æ®å¢å¼º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†é¢‘ç¼–è¾‘æ–¹æ³•åœ¨ä¸€è‡´æ€§ã€æ§åˆ¶æ€§å’Œæ³›åŒ–æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥æ»¡è¶³é«˜è´¨é‡çš„ç¼–è¾‘éœ€æ±‚ã€‚
2. EasyV2Våˆ©ç”¨é¢„è®­ç»ƒæ–‡æœ¬åˆ°è§†é¢‘æ¨¡å‹çš„ç¼–è¾‘èƒ½åŠ›ï¼Œé€šè¿‡ç®€å•æœ‰æ•ˆçš„åºåˆ—è¿æ¥å’ŒLoRAå¾®è°ƒå®ç°æŒ‡ä»¤é©±åŠ¨çš„è§†é¢‘ç¼–è¾‘ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒEasyV2Våœ¨è§†é¢‘ç¼–è¾‘ä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œè¶…è¶Šäº†ç°æœ‰çš„å•†ä¸šç³»ç»Ÿå’ŒåŒæœŸçš„ç ”ç©¶å·¥ä½œã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†é¢‘ç¼–è¾‘ç›¸è¾ƒäºå›¾åƒç¼–è¾‘å‘å±•ç¼“æ…¢ï¼Œé¢ä¸´ç€ä¸€è‡´æ€§ã€æ§åˆ¶æ€§å’Œæ³›åŒ–æ€§æ–¹é¢çš„æŒ‘æˆ˜ã€‚æœ¬æ–‡ç ”ç©¶äº†æ•°æ®ã€æ¶æ„å’Œæ§åˆ¶çš„è®¾è®¡ç©ºé—´ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªç®€å•æœ‰æ•ˆçš„åŸºäºæŒ‡ä»¤çš„è§†é¢‘ç¼–è¾‘æ¡†æ¶EasyV2Vã€‚åœ¨æ•°æ®æ–¹é¢ï¼Œæˆ‘ä»¬åˆ©ç”¨å…·æœ‰å¿«é€Ÿé€†è¿‡ç¨‹çš„ç°æœ‰ä¸“å®¶æ¨¡å‹æ„å»ºå¤šæ ·åŒ–çš„è§†é¢‘å¯¹ï¼Œé€šè¿‡å•å¸§ç›‘ç£å°†å›¾åƒç¼–è¾‘å¯¹æå‡ä¸ºè§†é¢‘ï¼Œåˆ©ç”¨å…±äº«ä»¿å°„è¿åŠ¨ç”Ÿæˆä¼ªè§†é¢‘å¯¹ï¼ŒæŒ–æ˜å¯†é›†å­—å¹•ç‰‡æ®µä»¥æ„å»ºè§†é¢‘å¯¹ï¼Œå¹¶æ·»åŠ è¿‡æ¸¡ç›‘ç£ä»¥å­¦ä¹ ç¼–è¾‘å¦‚ä½•å±•å¼€ã€‚åœ¨æ¨¡å‹æ–¹é¢ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°è§†é¢‘æ¨¡å‹å…·æœ‰ç¼–è¾‘èƒ½åŠ›ï¼Œè¿™ä¿ƒä½¿æˆ‘ä»¬é‡‡ç”¨ç®€åŒ–çš„è®¾è®¡ã€‚ç®€å•çš„åºåˆ—è¿æ¥ä¸è½»é‡çº§çš„LoRAå¾®è°ƒè¶³ä»¥è®­ç»ƒå‡ºä¸€ä¸ªå¼ºå¤§çš„æ¨¡å‹ã€‚åœ¨æ§åˆ¶æ–¹é¢ï¼Œæˆ‘ä»¬é€šè¿‡å•ä¸€çš„æ©ç æœºåˆ¶ç»Ÿä¸€äº†æ—¶ç©ºæ§åˆ¶ï¼Œå¹¶æ”¯æŒå¯é€‰çš„å‚è€ƒå›¾åƒã€‚æ€»è€Œè¨€ä¹‹ï¼ŒEasyV2Vå¯ä»¥å¤„ç†çµæ´»çš„è¾“å…¥ï¼Œä¾‹å¦‚è§†é¢‘+æ–‡æœ¬ã€è§†é¢‘+æ©ç +æ–‡æœ¬ã€è§†é¢‘+æ©ç +å‚è€ƒ+æ–‡æœ¬ï¼Œå¹¶å®ç°äº†æœ€å…ˆè¿›çš„è§†é¢‘ç¼–è¾‘æ•ˆæœï¼Œè¶…è¶Šäº†ç°æœ‰çš„å’Œå•†ä¸šç³»ç»Ÿã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå½“å‰è§†é¢‘ç¼–è¾‘æŠ€æœ¯åœ¨ä¿æŒè§†é¢‘å†…å®¹çš„æ—¶ç©ºä¸€è‡´æ€§ã€ç²¾ç¡®æ§åˆ¶ç¼–è¾‘è¿‡ç¨‹ä»¥åŠæ³›åŒ–åˆ°ä¸åŒåœºæ™¯æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éš¾ä»¥åœ¨å¤æ‚åœºæ™¯ä¸‹ç”Ÿæˆé«˜è´¨é‡çš„ç¼–è¾‘ç»“æœï¼Œå¹¶ä¸”ç¼ºä¹å¯¹ç¼–è¾‘è¿‡ç¨‹çš„ç²¾ç»†æ§åˆ¶èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šEasyV2Vçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°è§†é¢‘æ¨¡å‹æ‰€å…·å¤‡çš„æ½œåœ¨ç¼–è¾‘èƒ½åŠ›ï¼Œé€šè¿‡ç®€å•æœ‰æ•ˆçš„å¾®è°ƒç­–ç•¥ï¼Œå°†å…¶è½¬åŒ–ä¸ºä¸€ä¸ªé«˜è´¨é‡çš„ã€åŸºäºæŒ‡ä»¤çš„è§†é¢‘ç¼–è¾‘æ¡†æ¶ã€‚è¯¥æ–¹æ³•æ—¨åœ¨é€šè¿‡ç»Ÿä¸€çš„æ¡†æ¶å¤„ç†å¤šç§è¾“å…¥å½¢å¼ï¼Œå¹¶æä¾›çµæ´»çš„æ—¶ç©ºæ§åˆ¶ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEasyV2Vçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬æ•°æ®æ„å»ºå’Œæ¨¡å‹è®­ç»ƒä¸¤ä¸ªä¸»è¦éƒ¨åˆ†ã€‚æ•°æ®æ„å»ºé˜¶æ®µï¼Œä½œè€…åˆ©ç”¨å¤šç§ç­–ç•¥ç”Ÿæˆé«˜è´¨é‡çš„è§†é¢‘ç¼–è¾‘å¯¹ï¼ŒåŒ…æ‹¬åˆ©ç”¨ç°æœ‰å›¾åƒç¼–è¾‘æ¨¡å‹ç”Ÿæˆè§†é¢‘ã€é€šè¿‡å•å¸§ç›‘ç£æå‡å›¾åƒç¼–è¾‘å¯¹ã€åˆ©ç”¨å…±äº«ä»¿å°„è¿åŠ¨ç”Ÿæˆä¼ªè§†é¢‘å¯¹ã€æŒ–æ˜å¯†é›†å­—å¹•ç‰‡æ®µä»¥åŠæ·»åŠ è¿‡æ¸¡ç›‘ç£ã€‚æ¨¡å‹è®­ç»ƒé˜¶æ®µï¼Œä½œè€…é‡‡ç”¨ç®€å•çš„åºåˆ—è¿æ¥æ–¹å¼å°†è§†é¢‘å’Œæ–‡æœ¬æŒ‡ä»¤è¾“å…¥åˆ°é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°è§†é¢‘æ¨¡å‹ä¸­ï¼Œå¹¶é€šè¿‡è½»é‡çº§çš„LoRAå¾®è°ƒæ¥ä¼˜åŒ–æ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šEasyV2Vçš„å…³é”®åˆ›æ–°åœ¨äºå…¶ç®€å•è€Œæœ‰æ•ˆçš„æ¡†æ¶è®¾è®¡ï¼Œä»¥åŠå¯¹æ•°æ®æ„å»ºå’Œæ¨¡å‹è®­ç»ƒç­–ç•¥çš„ä¼˜åŒ–ã€‚é€šè¿‡å……åˆ†åˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹çš„å…ˆéªŒçŸ¥è¯†ï¼Œå¹¶ç»“åˆå¤šæ ·åŒ–çš„æ•°æ®å¢å¼ºæ–¹æ³•ï¼ŒEasyV2Vèƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„è§†é¢‘ç¼–è¾‘ç»“æœï¼Œå¹¶æä¾›çµæ´»çš„æ—¶ç©ºæ§åˆ¶ã€‚æ­¤å¤–ï¼Œç»Ÿä¸€çš„æ©ç æœºåˆ¶ç®€åŒ–äº†æ—¶ç©ºæ§åˆ¶çš„å®ç°ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®æ„å»ºæ–¹é¢ï¼Œä½œè€…è®¾è®¡äº†å¤šç§æ•°æ®å¢å¼ºç­–ç•¥ï¼Œä»¥æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚åœ¨æ¨¡å‹è®­ç»ƒæ–¹é¢ï¼Œä½œè€…é‡‡ç”¨äº†è½»é‡çº§çš„LoRAå¾®è°ƒç­–ç•¥ï¼Œä»¥é¿å…å¯¹é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œè¿‡åº¦ä¿®æ”¹ã€‚æ­¤å¤–ï¼Œä½œè€…è¿˜è®¾è®¡äº†ä¸€ä¸ªç»Ÿä¸€çš„æ©ç æœºåˆ¶ï¼Œç”¨äºå®ç°å¯¹è§†é¢‘å†…å®¹çš„æ—¶ç©ºæ§åˆ¶ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœªè¯¦ç»†è¯´æ˜ï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

EasyV2Våœ¨è§†é¢‘ç¼–è¾‘ä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œè¶…è¶Šäº†ç°æœ‰çš„å•†ä¸šç³»ç»Ÿå’ŒåŒæœŸçš„ç ”ç©¶å·¥ä½œã€‚å…·ä½“æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿åœ¨è®ºæ–‡ä¸­æœ‰æ‰€å±•ç¤ºï¼Œä½†æœªåœ¨æ‘˜è¦ä¸­æ˜ç¡®æåŠã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿå¤„ç†å¤šç§è¾“å…¥å½¢å¼ï¼Œå¹¶æä¾›çµæ´»çš„æ—¶ç©ºæ§åˆ¶ï¼Œä¸ºç”¨æˆ·æä¾›æ›´åŠ ä¾¿æ·å’Œé«˜æ•ˆçš„è§†é¢‘ç¼–è¾‘ä½“éªŒã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

EasyV2Vå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯åº”ç”¨äºç”µå½±åˆ¶ä½œã€å¹¿å‘Šè®¾è®¡ã€ç¤¾äº¤åª’ä½“å†…å®¹åˆ›ä½œç­‰é¢†åŸŸã€‚è¯¥æ¡†æ¶å¯ä»¥å¸®åŠ©ç”¨æˆ·å¿«é€Ÿç”Ÿæˆé«˜è´¨é‡çš„è§†é¢‘ç¼–è¾‘å†…å®¹ï¼Œé™ä½è§†é¢‘ç¼–è¾‘çš„é—¨æ§›ï¼Œå¹¶ä¸ºåˆ›æ„è¡¨è¾¾æä¾›æ›´å¤šå¯èƒ½æ€§ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›è¿›ä¸€æ­¥å‘å±•ï¼Œå®ç°æ›´åŠ æ™ºèƒ½å’Œè‡ªåŠ¨åŒ–çš„è§†é¢‘ç¼–è¾‘ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While image editing has advanced rapidly, video editing remains less explored, facing challenges in consistency, control, and generalization. We study the design space of data, architecture, and control, and introduce \emph{EasyV2V}, a simple and effective framework for instruction-based video editing. On the data side, we compose existing experts with fast inverses to build diverse video pairs, lift image edit pairs into videos via single-frame supervision and pseudo pairs with shared affine motion, mine dense-captioned clips for video pairs, and add transition supervision to teach how edits unfold. On the model side, we observe that pretrained text-to-video models possess editing capability, motivating a simplified design. Simple sequence concatenation for conditioning with light LoRA fine-tuning suffices to train a strong model. For control, we unify spatiotemporal control via a single mask mechanism and support optional reference images. Overall, EasyV2V works with flexible inputs, e.g., video+text, video+mask+text, video+mask+reference+text, and achieves state-of-the-art video editing results, surpassing concurrent and commercial systems. Project page: https://snap-research.github.io/easyv2v/

