---
layout: default
title: SegGraph: Leveraging Graphs of SAM Segments for Few-Shot 3D Part Segmentation
---

# SegGraph: Leveraging Graphs of SAM Segments for Few-Shot 3D Part Segmentation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.16143" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.16143v1</a>
  <a href="https://arxiv.org/pdf/2512.16143.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.16143v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.16143v1', 'SegGraph: Leveraging Graphs of SAM Segments for Few-Shot 3D Part Segmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yueyang Hu, Haiyong Jiang, Haoxuan Song, Jun Xiao, Hao Pan

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-18

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/YueyangHu2000/SegGraph)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**SegGraphï¼šåˆ©ç”¨SAMåˆ†å‰²å›¾è¿›è¡Œå°‘æ ·æœ¬3Déƒ¨ä»¶åˆ†å‰²**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å°‘æ ·æœ¬å­¦ä¹ ` `3Déƒ¨ä»¶åˆ†å‰²` `å›¾ç¥ç»ç½‘ç»œ` `SAMåˆ†å‰²` `å‡ ä½•ç‰¹å¾å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å°‘æ ·æœ¬3Déƒ¨ä»¶åˆ†å‰²æ–¹æ³•æœªèƒ½æœ‰æ•ˆèšåˆ2DåŸºç¡€æ¨¡å‹çš„çŸ¥è¯†åˆ°3Dï¼Œå¿½ç•¥äº†å‡ ä½•ç»“æ„æˆ–SAMåˆ†ç»„çº¿ç´¢ã€‚
2. SegGraphé€šè¿‡æ„å»ºSAMåˆ†å‰²å›¾ï¼Œæ˜¾å¼å­¦ä¹ åˆ†å‰²æ©ç ä¸­çš„å‡ ä½•ç‰¹å¾ï¼Œå¹¶ä¿æŒæ®µå†…è¯­ä¹‰ä¸€è‡´æ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒSegGraphåœ¨PartNet-Eæ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå°¤å…¶åœ¨å°ç»„ä»¶å’Œéƒ¨ä»¶è¾¹ç•Œä¸Šè¡¨ç°å‡ºè‰²ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„å°‘æ ·æœ¬3Déƒ¨ä»¶åˆ†å‰²æ¡†æ¶ã€‚æœ€è¿‘çš„ç ”ç©¶è¡¨æ˜ï¼Œ2DåŸºç¡€æ¨¡å‹åœ¨ä½æ ·æœ¬3Déƒ¨ä»¶åˆ†å‰²æ–¹é¢å…·æœ‰å·¨å¤§çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œå¦‚ä½•æœ‰æ•ˆåœ°å°†æ¥è‡ªåŸºç¡€æ¨¡å‹çš„2DçŸ¥è¯†èšåˆåˆ°3Dä»ç„¶æ˜¯ä¸€ä¸ªå¼€æ”¾çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•è¦ä¹ˆå¿½ç•¥3Dç‰¹å¾å­¦ä¹ çš„å‡ ä½•ç»“æ„ï¼Œè¦ä¹ˆå¿½ç•¥æ¥è‡ªSAMçš„é«˜è´¨é‡åˆ†ç»„çº¿ç´¢ï¼Œå¯¼è‡´åˆ†å‰²ä¸è¶³å’Œéƒ¨ä»¶æ ‡ç­¾ä¸ä¸€è‡´ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ç§æ–°é¢–çš„åŸºäºSAMåˆ†å‰²å›¾çš„ä¼ æ’­æ–¹æ³•ï¼Œåä¸ºSegGraphï¼Œä»¥æ˜¾å¼åœ°å­¦ä¹ SAMåˆ†å‰²æ©ç ä¸­ç¼–ç çš„å‡ ä½•ç‰¹å¾ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡å»ºæ¨¡æ®µä¹‹é—´çš„ç›¸äº’é‡å å’Œé‚»æ¥å…³ç³»æ¥ç¼–ç å‡ ä½•ç‰¹å¾ï¼ŒåŒæ—¶ä¿æŒæ®µå†…è¯­ä¹‰ä¸€è‡´æ€§ã€‚æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªåˆ†å‰²å›¾ï¼Œåœ¨æ¦‚å¿µä¸Šç±»ä¼¼äºåœ°å›¾é›†ï¼Œå…¶ä¸­èŠ‚ç‚¹ä»£è¡¨åˆ†å‰²ï¼Œè¾¹ä»£è¡¨å®ƒä»¬ä¹‹é—´çš„ç©ºé—´å…³ç³»ï¼ˆé‡å /é‚»æ¥ï¼‰ã€‚æ¯ä¸ªèŠ‚ç‚¹è‡ªé€‚åº”åœ°è°ƒèŠ‚2DåŸºç¡€æ¨¡å‹ç‰¹å¾ï¼Œç„¶åé€šè¿‡å›¾ç¥ç»ç½‘ç»œä¼ æ’­ä»¥å­¦ä¹ å…¨å±€å‡ ä½•ç»“æ„ã€‚ä¸ºäº†åŠ å¼ºæ®µå†…è¯­ä¹‰ä¸€è‡´æ€§ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ç§æ–°é¢–çš„è§†è§’æ–¹å‘åŠ æƒèåˆå°†æ®µç‰¹å¾æ˜ å°„åˆ°3Dç‚¹ï¼Œä»è€Œè¡°å‡æ¥è‡ªä½è´¨é‡æ®µçš„è´¡çŒ®ã€‚åœ¨PartNet-Eä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºæ‰€æœ‰ç«äº‰åŸºçº¿è‡³å°‘6.9ä¸ªç™¾åˆ†ç‚¹çš„mIoUã€‚è¿›ä¸€æ­¥çš„åˆ†æè¡¨æ˜ï¼ŒSegGraphåœ¨å°ç»„ä»¶å’Œéƒ¨ä»¶è¾¹ç•Œä¸Šå®ç°äº†ç‰¹åˆ«å¼ºå¤§çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶å“è¶Šçš„å‡ ä½•ç†è§£èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å°‘æ ·æœ¬3Déƒ¨ä»¶åˆ†å‰²é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨åˆ©ç”¨2DåŸºç¡€æ¨¡å‹çŸ¥è¯†æ—¶ï¼Œè¦ä¹ˆå¿½ç•¥äº†3Då‡ ä½•ç»“æ„çš„å­¦ä¹ ï¼Œè¦ä¹ˆæœªèƒ½å……åˆ†åˆ©ç”¨SAMåˆ†å‰²æä¾›çš„é«˜è´¨é‡åˆ†ç»„ä¿¡æ¯ï¼Œå¯¼è‡´åˆ†å‰²ç»“æœä¸å®Œæ•´ï¼Œéƒ¨ä»¶æ ‡ç­¾ä¸ä¸€è‡´ã€‚è¿™äº›æ–¹æ³•æ— æ³•æœ‰æ•ˆæ•æ‰éƒ¨ä»¶ä¹‹é—´çš„ç©ºé—´å…³ç³»ï¼Œå°¤å…¶æ˜¯åœ¨å°éƒ¨ä»¶å’Œéƒ¨ä»¶è¾¹ç•Œå¤„è¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªåŸºäºSAMåˆ†å‰²çš„å›¾ç»“æ„ï¼ˆSegGraphï¼‰ï¼Œæ˜¾å¼åœ°å­¦ä¹ å’Œåˆ©ç”¨åˆ†å‰²åŒºåŸŸä¹‹é—´çš„å‡ ä½•å…³ç³»ã€‚é€šè¿‡å›¾ç¥ç»ç½‘ç»œè¿›è¡Œä¿¡æ¯ä¼ æ’­ï¼Œå¯ä»¥æœ‰æ•ˆåœ°èšåˆæ¥è‡ªä¸åŒåˆ†å‰²åŒºåŸŸçš„ç‰¹å¾ï¼Œå¹¶å¢å¼ºå¯¹å…¨å±€å‡ ä½•ç»“æ„çš„ç†è§£ã€‚åŒæ—¶ï¼Œé€šè¿‡è§†è§’æ–¹å‘åŠ æƒèåˆï¼Œä¿è¯äº†æ®µå†…è¯­ä¹‰ä¸€è‡´æ€§ï¼Œå‡å°‘äº†ä½è´¨é‡åˆ†å‰²çš„å½±å“ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSegGraphæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) åˆ©ç”¨SAMç”Ÿæˆ2Dåˆ†å‰²æ©ç ï¼›2) æ„å»ºåˆ†å‰²å›¾ï¼ŒèŠ‚ç‚¹ä»£è¡¨åˆ†å‰²åŒºåŸŸï¼Œè¾¹è¡¨ç¤ºåˆ†å‰²åŒºåŸŸä¹‹é—´çš„ç©ºé—´å…³ç³»ï¼ˆé‡å å’Œé‚»æ¥ï¼‰ï¼›3) ä½¿ç”¨å›¾ç¥ç»ç½‘ç»œåœ¨åˆ†å‰²å›¾ä¸Šè¿›è¡Œç‰¹å¾ä¼ æ’­ï¼Œæ¯ä¸ªèŠ‚ç‚¹è‡ªé€‚åº”åœ°è°ƒèŠ‚2DåŸºç¡€æ¨¡å‹ç‰¹å¾ï¼›4) é€šè¿‡è§†è§’æ–¹å‘åŠ æƒèåˆï¼Œå°†åˆ†å‰²åŒºåŸŸç‰¹å¾æ˜ å°„åˆ°3Dç‚¹äº‘ï¼Œè¿›è¡Œæœ€ç»ˆçš„éƒ¨ä»¶åˆ†å‰²ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•çš„æ ¸å¿ƒåˆ›æ–°åœ¨äºåˆ©ç”¨SAMåˆ†å‰²å›¾æ¥æ˜¾å¼åœ°å»ºæ¨¡å’Œå­¦ä¹ 3Då‡ ä½•ç‰¹å¾ã€‚ä¸ä»¥å¾€æ–¹æ³•ç›¸æ¯”ï¼ŒSegGraphèƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰éƒ¨ä»¶ä¹‹é—´çš„ç©ºé—´å…³ç³»ï¼Œå°¤å…¶æ˜¯åœ¨å°éƒ¨ä»¶å’Œéƒ¨ä»¶è¾¹ç•Œå¤„ã€‚æ­¤å¤–ï¼Œè§†è§’æ–¹å‘åŠ æƒèåˆæœºåˆ¶èƒ½å¤Ÿæœ‰æ•ˆæŠ‘åˆ¶ä½è´¨é‡åˆ†å‰²çš„å½±å“ï¼Œæé«˜åˆ†å‰²çš„é²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåˆ†å‰²å›¾çš„æ„å»ºæ–¹å¼æ˜¯å…³é”®ã€‚è®ºæ–‡è€ƒè™‘äº†åˆ†å‰²åŒºåŸŸä¹‹é—´çš„é‡å å’Œé‚»æ¥å…³ç³»ï¼Œä½¿ç”¨ä¸åŒçš„æƒé‡æ¥è¡¨ç¤ºè¿™äº›å…³ç³»ã€‚å›¾ç¥ç»ç½‘ç»œçš„å…·ä½“ç»“æ„ï¼ˆä¾‹å¦‚ï¼Œä½¿ç”¨çš„å›¾å·ç§¯ç®—å­ï¼‰ä»¥åŠè§†è§’æ–¹å‘åŠ æƒèåˆçš„æƒé‡è®¡ç®—æ–¹å¼ä¹Ÿæ˜¯é‡è¦çš„è®¾è®¡ç»†èŠ‚ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿéœ€è¦è€ƒè™‘å¦‚ä½•å¹³è¡¡åˆ†å‰²ç²¾åº¦å’Œéƒ¨ä»¶ä¸€è‡´æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

SegGraphåœ¨PartNet-Eæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼ŒmIoUæŒ‡æ ‡è¶…è¿‡æ‰€æœ‰åŸºçº¿æ–¹æ³•è‡³å°‘6.9%ã€‚å°¤å…¶åœ¨å°ç»„ä»¶å’Œéƒ¨ä»¶è¾¹ç•Œä¸Šçš„åˆ†å‰²æ•ˆæœæå‡æ˜æ˜¾ï¼Œè¯æ˜äº†å…¶å¯¹å‡ ä½•ç»“æ„çš„å“è¶Šç†è§£èƒ½åŠ›ã€‚æ¶ˆèå®éªŒéªŒè¯äº†åˆ†å‰²å›¾ç»“æ„å’Œè§†è§’æ–¹å‘åŠ æƒèåˆçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæœºå™¨äººæ„ŸçŸ¥ã€è‡ªåŠ¨é©¾é©¶ã€ä¸‰ç»´åœºæ™¯ç†è§£ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œæœºå™¨äººå¯ä»¥åˆ©ç”¨è¯¥æŠ€æœ¯æ›´å‡†ç¡®åœ°è¯†åˆ«å’Œåˆ†å‰²ç‰©ä½“éƒ¨ä»¶ï¼Œä»è€Œæ›´å¥½åœ°è¿›è¡Œæ“ä½œå’Œäº¤äº’ã€‚åœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸï¼Œå¯ä»¥ç”¨äºç²¾ç¡®è¯†åˆ«è½¦è¾†ã€è¡Œäººç­‰ç›®æ ‡çš„ä¸åŒéƒ¨ä»¶ï¼Œæé«˜å®‰å…¨æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ç”¨äºCADæ¨¡å‹åˆ†æã€è™šæ‹Ÿç°å®ç­‰é¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This work presents a novel framework for few-shot 3D part segmentation. Recent advances have demonstrated the significant potential of 2D foundation models for low-shot 3D part segmentation. However, it is still an open problem that how to effectively aggregate 2D knowledge from foundation models to 3D. Existing methods either ignore geometric structures for 3D feature learning or neglects the high-quality grouping clues from SAM, leading to under-segmentation and inconsistent part labels. We devise a novel SAM segment graph-based propagation method, named SegGraph, to explicitly learn geometric features encoded within SAM's segmentation masks. Our method encodes geometric features by modeling mutual overlap and adjacency between segments while preserving intra-segment semantic consistency. We construct a segment graph, conceptually similar to an atlas, where nodes represent segments and edges capture their spatial relationships (overlap/adjacency). Each node adaptively modulates 2D foundation model features, which are then propagated via a graph neural network to learn global geometric structures. To enforce intra-segment semantic consistency, we map segment features to 3D points with a novel view-direction-weighted fusion attenuating contributions from low-quality segments. Extensive experiments on PartNet-E demonstrate that our method outperforms all competing baselines by at least 6.9 percent mIoU. Further analysis reveals that SegGraph achieves particularly strong performance on small components and part boundaries, demonstrating its superior geometric understanding. The code is available at: https://github.com/YueyangHu2000/SegGraph.

