---
layout: default
title: Occlusion-Aware Diffusion Model for Pedestrian Intention Prediction
---

# Occlusion-Aware Diffusion Model for Pedestrian Intention Prediction

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.00858" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.00858v1</a>
  <a href="https://arxiv.org/pdf/2511.00858.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.00858v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.00858v1', 'Occlusion-Aware Diffusion Model for Pedestrian Intention Prediction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yu Liu, Zhijie Liu, Zedong Yang, You-Fu Li, He Kong

**åˆ†ç±»**: cs.CV, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-11-02

**å¤‡æ³¨**: This manuscript has been accepted to the IEEE Transactions on Intelligent Transportation Systems as a regular paper

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé®æŒ¡æ„ŸçŸ¥æ‰©æ•£æ¨¡å‹ï¼Œè§£å†³è¡Œäººæ„å›¾é¢„æµ‹ä¸­é®æŒ¡åœºæ™¯ä¸‹çš„ä¸å®Œæ•´è§‚æµ‹é—®é¢˜ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `è¡Œäººæ„å›¾é¢„æµ‹` `é®æŒ¡æ„ŸçŸ¥` `æ‰©æ•£æ¨¡å‹` `è¿åŠ¨è½¨è¿¹é‡å»º` `Transformer`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è¡Œäººæ„å›¾é¢„æµ‹æ¨¡å‹åœ¨é®æŒ¡åœºæ™¯ä¸‹ï¼Œç”±äºè§‚æµ‹ä¿¡æ¯ä¸å®Œæ•´ï¼Œé¢„æµ‹ç²¾åº¦æ˜¾è‘—ä¸‹é™ã€‚
2. æå‡ºé®æŒ¡æ„ŸçŸ¥æ‰©æ•£æ¨¡å‹ï¼ˆODMï¼‰ï¼Œé€šè¿‡é‡å»ºè¢«é®æŒ¡çš„è¿åŠ¨æ¨¡å¼æ¥æå‡é¢„æµ‹æ€§èƒ½ã€‚
3. å®éªŒè¡¨æ˜ï¼Œåœ¨PIEå’ŒJAADæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•åœ¨å„ç§é®æŒ¡åœºæ™¯ä¸‹å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§é®æŒ¡æ„ŸçŸ¥æ‰©æ•£æ¨¡å‹ï¼ˆODMï¼‰ï¼Œç”¨äºé¢„æµ‹è¡Œäººçš„è¿‡é©¬è·¯æ„å›¾ï¼Œå°¤å…¶æ˜¯åœ¨å­˜åœ¨é®æŒ¡çš„æƒ…å†µä¸‹ã€‚è¯¥æ¨¡å‹æ—¨åœ¨é‡å»ºè¢«é®æŒ¡çš„è¿åŠ¨æ¨¡å¼ï¼Œå¹¶åˆ©ç”¨è¿™äº›æ¨¡å¼æ¥æŒ‡å¯¼æœªæ¥çš„æ„å›¾é¢„æµ‹ã€‚åœ¨å»å™ªé˜¶æ®µï¼Œå¼•å…¥äº†é®æŒ¡æ„ŸçŸ¥æ‰©æ•£Transformeræ¶æ„ï¼Œä»¥ä¼°è®¡ä¸é®æŒ¡æ¨¡å¼ç›¸å…³çš„å™ªå£°ç‰¹å¾ï¼Œä»è€Œå¢å¼ºæ¨¡å‹åœ¨é®æŒ¡è¯­ä¹‰åœºæ™¯ä¸­æ•è·ä¸Šä¸‹æ–‡å…³ç³»çš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†ä¸€ç§é®æŒ¡æ©ç å¼•å¯¼çš„åå‘è¿‡ç¨‹ï¼Œä»¥æœ‰æ•ˆåˆ©ç”¨è§‚æµ‹ä¿¡æ¯ï¼Œå‡å°‘é¢„æµ‹è¯¯å·®çš„ç´¯ç§¯ï¼Œå¹¶æé«˜é‡å»ºè¿åŠ¨ç‰¹å¾çš„å‡†ç¡®æ€§ã€‚åœ¨PIEå’ŒJAADç­‰å¸¸ç”¨åŸºå‡†æ•°æ®é›†ä¸Šï¼Œå¯¹è¯¥æ–¹æ³•åœ¨å„ç§é®æŒ¡åœºæ™¯ä¸‹çš„æ€§èƒ½è¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œå¹¶ä¸ç°æœ‰æ–¹æ³•è¿›è¡Œäº†æ¯”è¾ƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ¯”ç°æœ‰æ–¹æ³•å…·æœ‰æ›´å¼ºçš„é²æ£’æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè¡Œäººæ„å›¾é¢„æµ‹å¯¹äºç§»åŠ¨æœºå™¨äººå’Œæ™ºèƒ½è½¦è¾†çš„å¯¼èˆªè‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†é®æŒ¡åœºæ™¯æ—¶ï¼Œç”±äºè¡Œäººè¿åŠ¨è½¨è¿¹ä¿¡æ¯ä¸å®Œæ•´ï¼Œå¯¼è‡´é¢„æµ‹ç²¾åº¦ä¸‹é™ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆåˆ©ç”¨ä¸Šä¸‹æ–‡ä¿¡æ¯æ¥æ¨æ–­è¢«é®æŒ¡çš„è¿åŠ¨æ¨¡å¼ï¼Œä»è€Œå½±å“äº†æ„å›¾é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ‰©æ•£æ¨¡å‹å¼ºå¤§çš„ç”Ÿæˆèƒ½åŠ›ï¼Œé‡å»ºè¢«é®æŒ¡çš„è¡Œäººè¿åŠ¨è½¨è¿¹ã€‚é€šè¿‡å­¦ä¹ è¿åŠ¨æ¨¡å¼çš„å…ˆéªŒåˆ†å¸ƒï¼Œæ¨¡å‹å¯ä»¥æ ¹æ®å·²è§‚æµ‹åˆ°çš„ä¿¡æ¯æ¨æ–­å‡ºè¢«é®æŒ¡çš„éƒ¨åˆ†ï¼Œä»è€Œè·å¾—æ›´å®Œæ•´çš„è¿åŠ¨è½¨è¿¹è¡¨ç¤ºï¼Œè¿›è€Œæé«˜æ„å›¾é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚é®æŒ¡æ„ŸçŸ¥æœºåˆ¶èƒ½å¤Ÿä½¿æ¨¡å‹æ›´åŠ å…³æ³¨æœªè¢«é®æŒ¡çš„ä¿¡æ¯ï¼Œå¹¶å‡å°‘é®æŒ¡åŒºåŸŸå¯¹é¢„æµ‹çš„å½±å“ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•ä¸»è¦åŒ…å«ä¸¤ä¸ªé˜¶æ®µï¼šæ‰©æ•£é˜¶æ®µå’Œåå‘æ‰©æ•£é˜¶æ®µã€‚åœ¨æ‰©æ•£é˜¶æ®µï¼Œé€æ­¥å‘è§‚æµ‹åˆ°çš„è¡Œäººè¿åŠ¨è½¨è¿¹æ·»åŠ å™ªå£°ï¼Œç›´åˆ°è½¨è¿¹å®Œå…¨è¢«å™ªå£°æ·¹æ²¡ã€‚åœ¨åå‘æ‰©æ•£é˜¶æ®µï¼Œä»çº¯å™ªå£°å¼€å§‹ï¼Œé€æ­¥å»é™¤å™ªå£°ï¼Œå¹¶åˆ©ç”¨é®æŒ¡æ„ŸçŸ¥æ‰©æ•£Transformeræ¶æ„é‡å»ºè¢«é®æŒ¡çš„è¿åŠ¨è½¨è¿¹ã€‚æœ€ç»ˆï¼Œåˆ©ç”¨é‡å»ºåçš„å®Œæ•´è½¨è¿¹è¿›è¡Œæ„å›¾é¢„æµ‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†é®æŒ¡æ„ŸçŸ¥æ‰©æ•£Transformeræ¶æ„å’Œé®æŒ¡æ©ç å¼•å¯¼çš„åå‘è¿‡ç¨‹ã€‚é®æŒ¡æ„ŸçŸ¥æ‰©æ•£Transformeræ¶æ„èƒ½å¤Ÿæœ‰æ•ˆåœ°æå–ä¸é®æŒ¡æ¨¡å¼ç›¸å…³çš„å™ªå£°ç‰¹å¾ï¼Œä»è€Œæ›´å¥½åœ°é‡å»ºè¢«é®æŒ¡çš„è¿åŠ¨è½¨è¿¹ã€‚é®æŒ¡æ©ç å¼•å¯¼çš„åå‘è¿‡ç¨‹èƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨è§‚æµ‹ä¿¡æ¯ï¼Œå‡å°‘é¢„æµ‹è¯¯å·®çš„ç´¯ç§¯ã€‚

**å…³é”®è®¾è®¡**ï¼šé®æŒ¡æ„ŸçŸ¥æ‰©æ•£Transformeræ¶æ„é‡‡ç”¨Transformerç»“æ„ï¼Œå¹¶å¼•å…¥äº†é®æŒ¡æ©ç æœºåˆ¶ï¼Œä»¥åŒºåˆ†è§‚æµ‹åˆ°çš„ä¿¡æ¯å’Œè¢«é®æŒ¡çš„ä¿¡æ¯ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬é‡å»ºæŸå¤±å’Œæ„å›¾é¢„æµ‹æŸå¤±ï¼Œå…¶ä¸­é‡å»ºæŸå¤±ç”¨äºçº¦æŸé‡å»ºè¿åŠ¨è½¨è¿¹çš„å‡†ç¡®æ€§ï¼Œæ„å›¾é¢„æµ‹æŸå¤±ç”¨äºçº¦æŸæ„å›¾é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚é®æŒ¡æ©ç çš„è®¾è®¡æ ¹æ®å®é™…çš„é®æŒ¡æƒ…å†µè¿›è¡Œè°ƒæ•´ï¼Œä»¥é€‚åº”ä¸åŒçš„é®æŒ¡åœºæ™¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨PIEå’ŒJAADæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å„ç§é®æŒ¡åœºæ™¯ä¸‹å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨é®æŒ¡æ¯”ä¾‹è¾ƒé«˜çš„æƒ…å†µä¸‹ï¼Œè¯¥æ–¹æ³•çš„æ„å›¾é¢„æµ‹å‡†ç¡®ç‡æ¯”ç°æœ‰æ–¹æ³•æé«˜äº†5%-10%ã€‚å®éªŒè¿˜è¡¨æ˜ï¼Œé®æŒ¡æ„ŸçŸ¥æ‰©æ•£Transformeræ¶æ„å’Œé®æŒ¡æ©ç å¼•å¯¼çš„åå‘è¿‡ç¨‹èƒ½å¤Ÿæœ‰æ•ˆåœ°æé«˜é‡å»ºè¿åŠ¨è½¨è¿¹çš„å‡†ç¡®æ€§ï¼Œä»è€Œæé«˜æ„å›¾é¢„æµ‹çš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ã€ç§»åŠ¨æœºå™¨äººå¯¼èˆªã€æ™ºèƒ½ç›‘æ§ç­‰é¢†åŸŸã€‚é€šè¿‡å‡†ç¡®é¢„æµ‹è¡Œäººçš„è¿‡é©¬è·¯æ„å›¾ï¼Œå¯ä»¥æé«˜è‡ªåŠ¨é©¾é©¶è½¦è¾†çš„å®‰å…¨æ€§ï¼Œå‡å°‘äº¤é€šäº‹æ•…çš„å‘ç”Ÿã€‚åœ¨ç§»åŠ¨æœºå™¨äººå¯¼èˆªä¸­ï¼Œå¯ä»¥å¸®åŠ©æœºå™¨äººæ›´å¥½åœ°ç†è§£å‘¨å›´ç¯å¢ƒï¼Œå¹¶åšå‡ºæ›´åˆç†çš„å†³ç­–ã€‚åœ¨æ™ºèƒ½ç›‘æ§ä¸­ï¼Œå¯ä»¥ç”¨äºå¼‚å¸¸è¡Œä¸ºæ£€æµ‹ï¼Œä¾‹å¦‚è¡Œäººé—¯çº¢ç¯ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Predicting pedestrian crossing intentions is crucial for the navigation of mobile robots and intelligent vehicles. Although recent deep learning-based models have shown significant success in forecasting intentions, few consider incomplete observation under occlusion scenarios. To tackle this challenge, we propose an Occlusion-Aware Diffusion Model (ODM) that reconstructs occluded motion patterns and leverages them to guide future intention prediction. During the denoising stage, we introduce an occlusion-aware diffusion transformer architecture to estimate noise features associated with occluded patterns, thereby enhancing the model's ability to capture contextual relationships in occluded semantic scenarios. Furthermore, an occlusion mask-guided reverse process is introduced to effectively utilize observation information, reducing the accumulation of prediction errors and enhancing the accuracy of reconstructed motion features. The performance of the proposed method under various occlusion scenarios is comprehensively evaluated and compared with existing methods on popular benchmarks, namely PIE and JAAD. Extensive experimental results demonstrate that the proposed method achieves more robust performance than existing methods in the literature.

