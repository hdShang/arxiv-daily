---
layout: default
title: Deep Learning-Powered Visual SLAM Aimed at Assisting Visually Impaired Navigation
---

# Deep Learning-Powered Visual SLAM Aimed at Assisting Visually Impaired Navigation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.20549" target="_blank" class="toolbar-btn">arXiv: 2510.20549v1</a>
    <a href="https://arxiv.org/pdf/2510.20549.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.20549v1" 
            onclick="toggleFavorite(this, '2510.20549v1', 'Deep Learning-Powered Visual SLAM Aimed at Assisting Visually Impaired Navigation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Marziyeh Bamdad, Hans-Peter Hutter, Alireza Darvishy

**ÂàÜÁ±ª**: cs.CV, cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-23

**Â§áÊ≥®**: 8 pages, 7 figures, 4 tables

**DOI**: [10.5220/0013338200003912](https://doi.org/10.5220/0013338200003912)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫SELM-SLAM3ÔºåÂà©Áî®Ê∑±Â∫¶Â≠¶‰π†Â¢ûÂº∫ËßÜËßâSLAMÔºåËæÖÂä©ËßÜÈöú‰∫∫Â£´ÂØºËà™„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâSLAM` `Ê∑±Â∫¶Â≠¶‰π†` `ÁâπÂæÅÊèêÂèñ` `ÁâπÂæÅÂåπÈÖç` `ËßÜÈöúËæÖÂä©ÂØºËà™` `Êú∫Âô®‰∫∫ÂØºËà™` `SuperPoint` `LightGlue`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâSLAMÊäÄÊúØÂú®‰ΩéÁ∫πÁêÜ„ÄÅËøêÂä®Ê®°Á≥äÁ≠âÂ§çÊùÇÁéØÂ¢É‰∏ãÈ≤ÅÊ£íÊÄß‰∏çË∂≥ÔºåÈôêÂà∂‰∫ÜÂÖ∂Âú®ËßÜÈöúËæÖÂä©ÂØºËà™Á≠âÈ¢ÜÂüüÁöÑÂ∫îÁî®„ÄÇ
2. SELM-SLAM3ÈÄöËøáÈõÜÊàêSuperPointÂíåLightGlueÔºåÂà©Áî®Ê∑±Â∫¶Â≠¶‰π†ÊèêÂçáÁâπÂæÅÊèêÂèñÂíåÂåπÈÖçÁöÑÈ≤ÅÊ£íÊÄßÔºå‰ªéËÄåÊèêÈ´òSLAMÁöÑÊï¥‰ΩìÊÄßËÉΩ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåSELM-SLAM3Âú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äÊòæËëó‰ºò‰∫éORB-SLAM3ÂíåÂÖ∂‰ªñÂÖàËøõÁöÑRGB-D SLAMÁ≥ªÁªüÔºåÂ∞§ÂÖ∂ÊòØÂú®ÊåëÊàòÊÄßÂú∫ÊôØ‰∏ã„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÊ∑±Â∫¶Â≠¶‰π†ÁöÑËßÜËßâSLAMÊ°ÜÊû∂SELM-SLAM3ÔºåÊó®Âú®Ëß£ÂÜ≥‰ΩéÁ∫πÁêÜ„ÄÅËøêÂä®Ê®°Á≥äÊàñÂ§çÊùÇÂÖâÁÖßÁ≠âÊåëÊàòÊÄßÊù°‰ª∂‰∏ãSLAMÁöÑÈ≤ÅÊ£íÊÄßÈóÆÈ¢ò„ÄÇËøô‰∫õÈóÆÈ¢òÂú®ËßÜÈöú‰∫∫Â£´ËæÖÂä©ÂØºËà™Á≠âÂ∫îÁî®‰∏≠Â∞§‰∏∫Â∏∏ËßÅÔºå‰ºöÈôç‰ΩéÂÆö‰ΩçÁ≤æÂ∫¶ÂíåË∑üË∏™Á®≥ÂÆöÊÄßÔºå‰ªéËÄåÂΩ±ÂìçÂØºËà™ÁöÑÂèØÈù†ÊÄßÂíåÂÆâÂÖ®ÊÄß„ÄÇSELM-SLAM3ÈõÜÊàê‰∫ÜSuperPointÂíåLightGlueÔºå‰ª•ÂÆûÁé∞Á®≥ÂÅ•ÁöÑÁâπÂæÅÊèêÂèñÂíåÂåπÈÖç„ÄÇÂú®TUM RGB-D„ÄÅICL-NUIMÂíåTartanAirÊï∞ÊçÆÈõÜ‰∏äÁöÑËØÑ‰º∞ÁªìÊûúË°®ÊòéÔºåSELM-SLAM3ÁöÑÊÄßËÉΩ‰ºò‰∫é‰º†ÁªüÁöÑORB-SLAM3ÔºåÂπ≥ÂùáÊèêÂçá87.84%ÔºåÂπ∂‰∏îË∂ÖËøá‰∫ÜÊúÄÂÖàËøõÁöÑRGB-D SLAMÁ≥ªÁªü36.77%„ÄÇËØ•Ê°ÜÊû∂Âú®‰ΩéÁ∫πÁêÜÂú∫ÊôØÂíåÂø´ÈÄüËøêÂä®Á≠âÊåëÊàòÊÄßÊù°‰ª∂‰∏ãË°®Áé∞Âá∫Â¢ûÂº∫ÁöÑÊÄßËÉΩÔºå‰∏∫ÂºÄÂèëËßÜÈöú‰∫∫Â£´ÂØºËà™ËæÖÂä©Â∑•ÂÖ∑Êèê‰æõ‰∫Ü‰∏Ä‰∏™ÂèØÈù†ÁöÑÂπ≥Âè∞„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥ËßÜËßâSLAMÂú®ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÁéØÂ¢ÉÊù°‰ª∂‰∏ãÁöÑÈ≤ÅÊ£íÊÄßÈóÆÈ¢òÔºåÂ∞§ÂÖ∂ÊòØÂú®‰ΩéÁ∫πÁêÜ„ÄÅËøêÂä®Ê®°Á≥äÂíåÂ§çÊùÇÂÖâÁÖßÁ≠âÂú∫ÊôØ‰∏≠„ÄÇÁé∞ÊúâÁöÑSLAMÊñπÊ≥ïÂú®Ëøô‰∫õÊù°‰ª∂‰∏ãÂÆπÊòìÂá∫Áé∞ÂÆö‰ΩçÁ≤æÂ∫¶‰∏ãÈôçÂíåË∑üË∏™‰∏çÁ®≥ÂÆöÁöÑÈóÆÈ¢òÔºå‰ªéËÄåÂΩ±ÂìçÂØºËà™ÁöÑÂèØÈù†ÊÄßÂíåÂÆâÂÖ®ÊÄß„ÄÇËøô‰∫õÈóÆÈ¢òÂØπ‰∫éËßÜÈöú‰∫∫Â£´ËæÖÂä©ÂØºËà™Á≠âÂ∫îÁî®Êù•ËØ¥Â∞§‰∏∫ÂÖ≥ÈîÆ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Ê∑±Â∫¶Â≠¶‰π†Êù•Â¢ûÂº∫ËßÜËßâSLAMÁöÑÁâπÂæÅÊèêÂèñÂíåÂåπÈÖçËÉΩÂäõ„ÄÇÈÄöËøá‰ΩøÁî®SuperPointËøõË°åÁâπÂæÅÁÇπÊ£ÄÊµãÔºåÂπ∂‰ΩøÁî®LightGlueËøõË°åÁâπÂæÅÂåπÈÖçÔºåÂèØ‰ª•ÊèêÈ´òSLAMÁ≥ªÁªüÂú®ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÁéØÂ¢ÉÊù°‰ª∂‰∏ãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇËøôÁßçÊñπÊ≥ïÊó®Âú®ÂÖãÊúç‰º†ÁªüÁâπÂæÅÊèêÂèñÂíåÂåπÈÖçÁÆóÊ≥ïÂú®Ëøô‰∫õÊù°‰ª∂‰∏ãÁöÑÂ±ÄÈôêÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöSELM-SLAM3ÁöÑÊï¥‰ΩìÊ°ÜÊû∂Âü∫‰∫éËßÜËßâSLAMÁ≥ªÁªüÔºåÂπ∂ÈõÜÊàê‰∫ÜÊ∑±Â∫¶Â≠¶‰π†Ê®°Âùó„ÄÇËØ•Ê°ÜÊû∂ÂåÖÂê´‰ª•‰∏ã‰∏ªË¶ÅÊ®°ÂùóÔºö1) ‰ΩøÁî®SuperPointËøõË°åÁâπÂæÅÁÇπÊ£ÄÊµãÔºõ2) ‰ΩøÁî®LightGlueËøõË°åÁâπÂæÅÂåπÈÖçÔºõ3) Âü∫‰∫éÊèêÂèñÁöÑÁâπÂæÅÂíåÂåπÈÖçÁªìÊûúËøõË°å‰ΩçÂßø‰º∞ËÆ°ÂíåÂú∞ÂõæÊûÑÂª∫„ÄÇÊï¥‰∏™ÊµÅÁ®ãÊó®Âú®ÂÆûÁé∞Êõ¥ÂáÜÁ°ÆÂíåÈ≤ÅÊ£íÁöÑSLAMÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜSuperPointÂíåLightGlueÈõÜÊàêÂà∞ËßÜËßâSLAMÁ≥ªÁªü‰∏≠Ôºå‰ª•ÊèêÈ´òÁâπÂæÅÊèêÂèñÂíåÂåπÈÖçÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ‰∏é‰º†ÁªüÁöÑÂü∫‰∫éÊâãÂ∑•ËÆæËÆ°ÁöÑÁâπÂæÅÊèêÂèñÂô®ÔºàÂ¶ÇORBÔºâÁõ∏ÊØîÔºåSuperPointËÉΩÂ§üÂ≠¶‰π†Âà∞Êõ¥ÂÖ∑Âà§Âà´ÊÄßÁöÑÁâπÂæÅÔºå‰ªéËÄåÂú®‰ΩéÁ∫πÁêÜÂíåÂÖâÁÖßÂèòÂåñÁ≠âÊù°‰ª∂‰∏ãË°®Áé∞Êõ¥Â•Ω„ÄÇLightGlueÂàôÂà©Áî®ÂõæÁ•ûÁªèÁΩëÁªúËøõË°åÁâπÂæÅÂåπÈÖçÔºåËÉΩÂ§üÊõ¥Â•ΩÂú∞Â§ÑÁêÜÂô™Â£∞ÂíåÂºÇÂ∏∏ÂÄº„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËÆ∫Êñá‰∏≠Ê≤°ÊúâËØ¶ÁªÜËØ¥ÊòéÂÖ≥ÈîÆÁöÑÂèÇÊï∞ËÆæÁΩÆ„ÄÅÊçüÂ§±ÂáΩÊï∞ÊàñÁΩëÁªúÁªìÊûÑÁ≠âÊäÄÊúØÁªÜËäÇ„ÄÇSuperPointÂíåLightGlueÊòØÈ¢ÑËÆ≠ÁªÉÂ•ΩÁöÑÊ®°ÂûãÔºåÁõ¥Êé•Â∫îÁî®‰∫éSLAMÊ°ÜÊû∂‰∏≠„ÄÇÂÖ∑‰ΩìÂ¶Ç‰ΩïÂ∞ÜËøô‰∫õÊ®°Âùó‰∏éSLAMÁ≥ªÁªüÁöÑÂÖ∂‰ªñÈÉ®ÂàÜÈõÜÊàêÔºå‰ª•ÂèäÂ¶Ç‰Ωï‰ºòÂåñÊï¥‰∏™Á≥ªÁªüÁöÑÊÄßËÉΩÔºåÈúÄË¶ÅÂú®ÂêéÁª≠Á†îÁ©∂‰∏≠Ëøõ‰∏ÄÊ≠•Êé¢Á¥¢„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

SELM-SLAM3Âú®TUM RGB-D„ÄÅICL-NUIMÂíåTartanAirÊï∞ÊçÆÈõÜ‰∏äËøõË°å‰∫ÜËØÑ‰º∞ÔºåÁªìÊûúË°®ÊòéÂÖ∂ÊÄßËÉΩÊòæËëó‰ºò‰∫é‰º†ÁªüÁöÑORB-SLAM3ÔºåÂπ≥ÂùáÊèêÂçá87.84%ÔºåÂπ∂‰∏îË∂ÖËøá‰∫ÜÊúÄÂÖàËøõÁöÑRGB-D SLAMÁ≥ªÁªü36.77%„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéÔºåSELM-SLAM3Âú®ÊåëÊàòÊÄßÊù°‰ª∂‰∏ãÂÖ∑ÊúâÊõ¥Âº∫ÁöÑÈ≤ÅÊ£íÊÄßÂíåÊõ¥È´òÁöÑÁ≤æÂ∫¶„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éËßÜÈöú‰∫∫Â£´ËæÖÂä©ÂØºËà™Á≥ªÁªüÔºåÊèêÂçáÂÖ∂Âú®Â§çÊùÇÁéØÂ¢É‰∏ãÁöÑÂÆö‰ΩçÂíåÂØºËà™ËÉΩÂäõÔºåÂ¢ûÂº∫Âá∫Ë°åÂÆâÂÖ®ÊÄßÂíå‰æøÂà©ÊÄß„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïËøòÂèØÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫ÂØºËà™„ÄÅËá™Âä®È©æÈ©∂Á≠âÈ¢ÜÂüüÔºåÊèêÈ´òÊú∫Âô®‰∫∫Âú®ÂÖâÁÖß‰∏çË∂≥„ÄÅÁ∫πÁêÜÁº∫Â§±Á≠âÊåëÊàòÊÄßÁéØÂ¢É‰∏ãÁöÑËá™‰∏ªÂØºËà™ËÉΩÂäõ„ÄÇÊú™Êù•ÔºåËØ•ÊäÄÊúØÊúâÊúõÂú®Êô∫ËÉΩÂÆ∂Â±Ö„ÄÅÂ∑•‰∏öËá™Âä®ÂåñÁ≠âÈ¢ÜÂüüÂèëÊå•ÈáçË¶Å‰ΩúÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Despite advancements in SLAM technologies, robust operation under challenging conditions such as low-texture, motion-blur, or challenging lighting remains an open challenge. Such conditions are common in applications such as assistive navigation for the visually impaired. These challenges undermine localization accuracy and tracking stability, reducing navigation reliability and safety. To overcome these limitations, we present SELM-SLAM3, a deep learning-enhanced visual SLAM framework that integrates SuperPoint and LightGlue for robust feature extraction and matching. We evaluated our framework using TUM RGB-D, ICL-NUIM, and TartanAir datasets, which feature diverse and challenging scenarios. SELM-SLAM3 outperforms conventional ORB-SLAM3 by an average of 87.84% and exceeds state-of-the-art RGB-D SLAM systems by 36.77%. Our framework demonstrates enhanced performance under challenging conditions, such as low-texture scenes and fast motion, providing a reliable platform for developing navigation aids for the visually impaired.

