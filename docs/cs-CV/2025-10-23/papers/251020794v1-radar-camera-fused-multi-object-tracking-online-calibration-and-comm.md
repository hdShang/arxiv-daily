---
layout: default
title: Radar-Camera Fused Multi-Object Tracking: Online Calibration and Common Feature
---

# Radar-Camera Fused Multi-Object Tracking: Online Calibration and Common Feature

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.20794" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.20794v1</a>
  <a href="https://arxiv.org/pdf/2510.20794.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.20794v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.20794v1', 'Radar-Camera Fused Multi-Object Tracking: Online Calibration and Common Feature')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Lei Cheng, Siyang Cao

**åˆ†ç±»**: cs.CV, eess.SP

**å‘å¸ƒæ—¥æœŸ**: 2025-10-23

**å¤‡æ³¨**: accepted to IEEE Transactions on Intelligent Transportation Systems (T-ITS)

**DOI**: [10.1109/TITS.2025.3624716](https://doi.org/10.1109/TITS.2025.3624716)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/radar-lab/Radar_Camera_MOT)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§é›·è¾¾-ç›¸æœºèåˆçš„å¤šç›®æ ‡è·Ÿè¸ªæ¡†æ¶ï¼Œå®ç°åœ¨çº¿æ ‡å®šå’Œé€šç”¨ç‰¹å¾åˆ©ç”¨ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)**

**å…³é”®è¯**: `é›·è¾¾ç›¸æœºèåˆ` `å¤šç›®æ ‡è·Ÿè¸ª` `åœ¨çº¿æ ‡å®š` `é€šç”¨ç‰¹å¾` `ä¼ æ„Ÿå™¨èåˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰é›·è¾¾-ç›¸æœºèåˆæ–¹æ³•é€šå¸¸ä½ä¼°é›·è¾¾çš„æ·±åº¦ä¿¡æ¯ä¼˜åŠ¿ï¼Œä¸”ä¾èµ–äººå·¥æ ‡å®šï¼Œé™åˆ¶äº†è·Ÿè¸ªæ•ˆç‡ã€‚
2. è¯¥æ–¹æ³•æå‡ºä¸€ç§é›·è¾¾-ç›¸æœºèåˆæ¡†æ¶ï¼Œåˆ©ç”¨é€šç”¨ç‰¹å¾å®ç°é›·è¾¾-ç›¸æœºçš„åœ¨çº¿æ ‡å®šï¼Œç®€åŒ–ä¼ æ„Ÿå™¨æ•°æ®èåˆã€‚
3. é€šè¿‡ç‰¹å¾åŒ¹é…å’Œç±»åˆ«ä¸€è‡´æ€§æ£€æŸ¥ï¼Œæå‡ä¼ æ„Ÿå™¨å…³è”ç²¾åº¦ï¼Œå®éªŒè¡¨æ˜è¯¥æ¡†æ¶èƒ½æœ‰æ•ˆæé«˜è·Ÿè¸ªç²¾åº¦ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§é›·è¾¾-ç›¸æœºèåˆçš„å¤šç›®æ ‡è·Ÿè¸ª(MOT)æ¡†æ¶ï¼Œæ—¨åœ¨æé«˜è·Ÿè¸ªæ•ˆç‡å¹¶æœ€å¤§é™åº¦åœ°å‡å°‘äººå·¥å¹²é¢„ã€‚ä¸è®¸å¤šç ”ç©¶ä½ä¼°é›·è¾¾ä½œç”¨ï¼ˆå°½ç®¡é›·è¾¾èƒ½å¤Ÿæä¾›ç›®æ ‡åœ¨ä¸–ç•Œ3Dåæ ‡ç³»ä¸­çš„ç²¾ç¡®è·ç¦»/æ·±åº¦ä¿¡æ¯ï¼‰å¹¶å°†å…¶ä½œä¸ºè¾…åŠ©æ‰‹æ®µä¸åŒï¼Œæˆ‘ä»¬çš„æ–¹æ³•å°†é›·è¾¾ç½®äºå…³é”®ä½ç½®ã€‚åŒæ—¶ï¼Œæœ¬æ–‡åˆ©ç”¨é€šç”¨ç‰¹å¾æ¥å®ç°åœ¨çº¿æ ‡å®šï¼Œä»è€Œè‡ªä¸»å…³è”æ¥è‡ªé›·è¾¾å’Œç›¸æœºçš„æ£€æµ‹ç»“æœã€‚æœ¬å·¥ä½œçš„ä¸»è¦è´¡çŒ®åŒ…æ‹¬ï¼š(1)å¼€å‘äº†ä¸€ç§é›·è¾¾-ç›¸æœºèåˆçš„MOTæ¡†æ¶ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨åœ¨çº¿é›·è¾¾-ç›¸æœºæ ‡å®šæ¥ç®€åŒ–æ¥è‡ªè¿™ä¸¤ç§ä¼ æ„Ÿå™¨çš„æ£€æµ‹ç»“æœçš„é›†æˆï¼›(2)åˆ©ç”¨é›·è¾¾å’Œç›¸æœºæ•°æ®ä¹‹é—´çš„é€šç”¨ç‰¹å¾æ¥å‡†ç¡®æ¨å¯¼æ£€æµ‹åˆ°çš„ç‰©ä½“çš„çœŸå®ä¸–ç•Œä½ç½®ï¼›(3)é‡‡ç”¨ç‰¹å¾åŒ¹é…å’Œç±»åˆ«ä¸€è‡´æ€§æ£€æŸ¥æ¥è¶…è¶Šå•çº¯çš„ä½ç½®åŒ¹é…çš„å±€é™æ€§ï¼Œä»è€Œæé«˜ä¼ æ„Ÿå™¨å…³è”çš„å‡†ç¡®æ€§ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œæˆ‘ä»¬æ˜¯ç¬¬ä¸€ä¸ªç ”ç©¶é›·è¾¾-ç›¸æœºé€šç”¨ç‰¹å¾çš„é›†æˆåŠå…¶åœ¨åœ¨çº¿æ ‡å®šä¸­ç”¨äºå®ç°MOTçš„ç ”ç©¶ã€‚æˆ‘ä»¬çš„æ¡†æ¶çš„æœ‰æ•ˆæ€§é€šè¿‡å…¶ç®€åŒ–é›·è¾¾-ç›¸æœºæ˜ å°„è¿‡ç¨‹å’Œæé«˜è·Ÿè¸ªç²¾åº¦çš„èƒ½åŠ›å¾—åˆ°è¯æ˜ï¼Œè¿™å·²é€šè¿‡åœ¨å—æ§ç¯å¢ƒå’Œå®é™…äº¤é€šåœºæ™¯ä¸­è¿›è¡Œçš„çœŸå®ä¸–ç•Œå®éªŒå¾—åˆ°è¯å®ã€‚ä»£ç å¯åœ¨https://github.com/radar-lab/Radar_Camera_MOTè·å–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„é›·è¾¾-ç›¸æœºèåˆå¤šç›®æ ‡è·Ÿè¸ªæ–¹æ³•é€šå¸¸å°†é›·è¾¾ä½œä¸ºè¾…åŠ©ä¼ æ„Ÿå™¨ï¼Œæœªèƒ½å……åˆ†åˆ©ç”¨é›·è¾¾æä¾›çš„ç²¾ç¡®æ·±åº¦ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œè®¸å¤šæ–¹æ³•ä¾èµ–äºæ‰‹åŠ¨æ ‡å®šé›·è¾¾å’Œç›¸æœºï¼Œè¿™æ—¢è€—æ—¶åˆå®¹æ˜“å‡ºé”™ï¼Œé™åˆ¶äº†ç³»ç»Ÿçš„è‡ªåŠ¨åŒ–å’Œå¯æ‰©å±•æ€§ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§èƒ½å¤Ÿè‡ªåŠ¨æ ‡å®šé›·è¾¾å’Œç›¸æœºï¼Œå¹¶æœ‰æ•ˆèåˆä¸¤ç§ä¼ æ„Ÿå™¨æ•°æ®çš„å¤šç›®æ ‡è·Ÿè¸ªæ¡†æ¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨é›·è¾¾å’Œç›¸æœºä¹‹é—´çš„é€šç”¨ç‰¹å¾ï¼Œå®ç°é›·è¾¾-ç›¸æœºçš„åœ¨çº¿æ ‡å®šã€‚é€šè¿‡æå–ä¸¤ç§ä¼ æ„Ÿå™¨æ•°æ®ä¸­å…±åŒå­˜åœ¨çš„ç‰¹å¾ï¼Œä¾‹å¦‚ç‰©ä½“çš„å¤§å°ã€å½¢çŠ¶ç­‰ï¼Œå¯ä»¥å»ºç«‹é›·è¾¾å’Œç›¸æœºä¹‹é—´çš„å¯¹åº”å…³ç³»ï¼Œä»è€Œè‡ªåŠ¨ä¼°è®¡å®ƒä»¬çš„ç›¸å¯¹ä½å§¿ã€‚è¿™ç§åœ¨çº¿æ ‡å®šæ–¹æ³•å¯ä»¥å‡å°‘äººå·¥å¹²é¢„ï¼Œæé«˜ç³»ç»Ÿçš„é²æ£’æ€§å’Œé€‚åº”æ€§ã€‚åŒæ—¶ï¼Œå°†é›·è¾¾ç½®äºæ›´é‡è¦çš„ä½ç½®ï¼Œå……åˆ†åˆ©ç”¨å…¶æ·±åº¦ä¿¡æ¯ï¼Œå¯ä»¥æé«˜è·Ÿè¸ªçš„å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥é›·è¾¾-ç›¸æœºèåˆMOTæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) é›·è¾¾å’Œç›¸æœºæ•°æ®é‡‡é›†ï¼›2) ç›®æ ‡æ£€æµ‹ï¼šåˆ†åˆ«ä½¿ç”¨é›·è¾¾å’Œç›¸æœºæ£€æµ‹åœºæ™¯ä¸­çš„ç›®æ ‡ï¼›3) ç‰¹å¾æå–ï¼šæå–é›·è¾¾å’Œç›¸æœºæ£€æµ‹ç»“æœä¸­çš„é€šç”¨ç‰¹å¾ï¼›4) åœ¨çº¿æ ‡å®šï¼šåˆ©ç”¨é€šç”¨ç‰¹å¾è¿›è¡Œé›·è¾¾-ç›¸æœºåœ¨çº¿æ ‡å®šï¼Œä¼°è®¡é›·è¾¾å’Œç›¸æœºçš„ç›¸å¯¹ä½å§¿ï¼›5) æ•°æ®å…³è”ï¼šå°†é›·è¾¾å’Œç›¸æœºçš„æ£€æµ‹ç»“æœè¿›è¡Œå…³è”ï¼Œå¾—åˆ°èåˆåçš„ç›®æ ‡ä¿¡æ¯ï¼›6) ç›®æ ‡è·Ÿè¸ªï¼šä½¿ç”¨å¡å°”æ›¼æ»¤æ³¢å™¨ç­‰æ–¹æ³•å¯¹ç›®æ ‡è¿›è¡Œè·Ÿè¸ªã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºåˆ©ç”¨é›·è¾¾å’Œç›¸æœºä¹‹é—´çš„é€šç”¨ç‰¹å¾è¿›è¡Œåœ¨çº¿æ ‡å®šã€‚ä¸ä¼ ç»Ÿçš„ä¾èµ–äºäººå·¥æ ‡å®šçš„æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•å¯ä»¥è‡ªåŠ¨ä¼°è®¡é›·è¾¾å’Œç›¸æœºçš„ç›¸å¯¹ä½å§¿ï¼Œå‡å°‘äººå·¥å¹²é¢„ï¼Œæé«˜ç³»ç»Ÿçš„é²æ£’æ€§å’Œé€‚åº”æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜é‡‡ç”¨äº†ç‰¹å¾åŒ¹é…å’Œç±»åˆ«ä¸€è‡´æ€§æ£€æŸ¥ç­‰ç­–ç•¥ï¼Œè¿›ä¸€æ­¥æé«˜äº†ä¼ æ„Ÿå™¨å…³è”çš„å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç‰¹å¾æå–æ–¹é¢ï¼Œå¯ä»¥é‡‡ç”¨ä¸åŒçš„ç‰¹å¾æå–å™¨ï¼Œä¾‹å¦‚HOGã€SIFTç­‰ã€‚åœ¨çº¿æ ‡å®šå¯ä»¥é‡‡ç”¨è¿­ä»£æœ€è¿‘ç‚¹(ICP)ç®—æ³•æˆ–æ‰©å±•å¡å°”æ›¼æ»¤æ³¢å™¨(EKF)ç­‰æ–¹æ³•ã€‚æ•°æ®å…³è”å¯ä»¥é‡‡ç”¨åŒˆç‰™åˆ©ç®—æ³•æˆ–è”åˆæ¦‚ç‡æ•°æ®å…³è”(JPDA)ç­‰æ–¹æ³•ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡éœ€è¦è€ƒè™‘æ ‡å®šç²¾åº¦å’Œè·Ÿè¸ªç²¾åº¦ï¼Œå¯ä»¥é‡‡ç”¨åŠ æƒæŸå¤±å‡½æ•°ï¼Œæ ¹æ®å®é™…æƒ…å†µè°ƒæ•´æƒé‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥æ¡†æ¶é€šè¿‡åœ¨çœŸå®äº¤é€šåœºæ™¯å’Œå—æ§ç¯å¢ƒä¸­è¿›è¡Œå®éªŒï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç®€åŒ–é›·è¾¾-ç›¸æœºçš„æ˜ å°„è¿‡ç¨‹ï¼Œå¹¶æ˜¾è‘—æé«˜è·Ÿè¸ªç²¾åº¦ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®ï¼ˆä¾‹å¦‚è·Ÿè¸ªç²¾åº¦æå‡ç™¾åˆ†æ¯”ã€æ ‡å®šè¯¯å·®é™ä½é‡ç­‰ï¼‰éœ€è¦åœ¨è®ºæ–‡ä¸­æŸ¥æ‰¾ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½äº¤é€šã€æœºå™¨äººç­‰é¢†åŸŸã€‚åœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼Œé›·è¾¾-ç›¸æœºèåˆå¯ä»¥æé«˜ç¯å¢ƒæ„ŸçŸ¥çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ï¼Œä»è€Œæé«˜é©¾é©¶å®‰å…¨æ€§ã€‚åœ¨æ™ºèƒ½äº¤é€šä¸­ï¼Œè¯¥æŠ€æœ¯å¯ä»¥ç”¨äºäº¤é€šæµé‡ç›‘æµ‹ã€è½¦è¾†è¡Œä¸ºåˆ†æç­‰ã€‚åœ¨æœºå™¨äººé¢†åŸŸï¼Œè¯¥æŠ€æœ¯å¯ä»¥ç”¨äºæœºå™¨äººå¯¼èˆªã€ç›®æ ‡è¯†åˆ«ç­‰ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åœ¨æ›´å¤šé¢†åŸŸå¾—åˆ°åº”ç”¨ï¼Œä¸ºäººä»¬çš„ç”Ÿæ´»å¸¦æ¥ä¾¿åˆ©ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper presents a Multi-Object Tracking (MOT) framework that fuses radar and camera data to enhance tracking efficiency while minimizing manual interventions. Contrary to many studies that underutilize radar and assign it a supplementary role--despite its capability to provide accurate range/depth information of targets in a world 3D coordinate system--our approach positions radar in a crucial role. Meanwhile, this paper utilizes common features to enable online calibration to autonomously associate detections from radar and camera. The main contributions of this work include: (1) the development of a radar-camera fusion MOT framework that exploits online radar-camera calibration to simplify the integration of detection results from these two sensors, (2) the utilization of common features between radar and camera data to accurately derive real-world positions of detected objects, and (3) the adoption of feature matching and category-consistency checking to surpass the limitations of mere position matching in enhancing sensor association accuracy. To the best of our knowledge, we are the first to investigate the integration of radar-camera common features and their use in online calibration for achieving MOT. The efficacy of our framework is demonstrated by its ability to streamline the radar-camera mapping process and improve tracking precision, as evidenced by real-world experiments conducted in both controlled environments and actual traffic scenarios. Code is available at https://github.com/radar-lab/Radar_Camera_MOT

