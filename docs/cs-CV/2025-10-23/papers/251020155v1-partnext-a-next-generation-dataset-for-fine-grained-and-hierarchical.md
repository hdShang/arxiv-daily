---
layout: default
title: PartNeXt: A Next-Generation Dataset for Fine-Grained and Hierarchical 3D Part Understanding
---

# PartNeXt: A Next-Generation Dataset for Fine-Grained and Hierarchical 3D Part Understanding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.20155" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.20155v1</a>
  <a href="https://arxiv.org/pdf/2510.20155.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.20155v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.20155v1', 'PartNeXt: A Next-Generation Dataset for Fine-Grained and Hierarchical 3D Part Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Penghao Wang, Yiyang He, Xin Lv, Yukai Zhou, Lan Xu, Jingyi Yu, Jiayuan Gu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-23

**å¤‡æ³¨**: NeurIPS 2025 DB Track. Project page: https://authoritywang.github.io/partnext

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPartNeXtæ•°æ®é›†ï¼Œç”¨äºç»†ç²’åº¦åˆ†å±‚3Déƒ¨ä»¶ç†è§£ï¼Œæå‡æ¨¡å‹æ€§èƒ½ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `3Déƒ¨ä»¶ç†è§£` `ç»†ç²’åº¦åˆ†å‰²` `åˆ†å±‚æ ‡æ³¨` `çº¹ç†æ¨¡å‹` `3Dé—®ç­”`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰3Déƒ¨ä»¶ç†è§£æ•°æ®é›†ä¾èµ–æ— çº¹ç†å‡ ä½•ä½“å’Œä¸“å®¶æ ‡æ³¨ï¼Œé™åˆ¶äº†å¯æ‰©å±•æ€§å’Œå¯ç”¨æ€§ã€‚
2. PartNeXtæ•°æ®é›†æä¾›å¸¦çº¹ç†çš„3Dæ¨¡å‹å’Œç»†ç²’åº¦åˆ†å±‚éƒ¨ä»¶æ ‡ç­¾ï¼Œæ”¯æŒå¤šä»»åŠ¡è¯„ä¼°ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒPartNeXtèƒ½æœ‰æ•ˆæå‡éƒ¨ä»¶åˆ†å‰²å’Œ3Déƒ¨ä»¶ä¸­å¿ƒé—®ç­”ç­‰ä»»åŠ¡çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†PartNeXtï¼Œä¸€ä¸ªç”¨äºç»†ç²’åº¦åˆ†å±‚3Déƒ¨ä»¶ç†è§£çš„æ–°ä¸€ä»£æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†åŒ…å«è¶…è¿‡23,000ä¸ªé«˜è´¨é‡ã€å¸¦çº¹ç†çš„3Dæ¨¡å‹ï¼Œå¹¶æ ‡æ³¨äº†50ä¸ªç±»åˆ«ä¸­ç»†ç²’åº¦ã€åˆ†å±‚ç»“æ„çš„éƒ¨ä»¶æ ‡ç­¾ã€‚ç°æœ‰æ•°æ®é›†å¦‚PartNetä¾èµ–äºæ— çº¹ç†å‡ ä½•ä½“å’Œä¸“å®¶æ ‡æ³¨ï¼Œé™åˆ¶äº†å…¶å¯æ‰©å±•æ€§å’Œå¯ç”¨æ€§ã€‚PartNeXtåœ¨ä¸¤ä¸ªä»»åŠ¡ä¸Šè¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼š(1) ç±»æ— å…³éƒ¨ä»¶åˆ†å‰²ï¼Œç°æœ‰æ–¹æ³•ï¼ˆå¦‚PartFieldã€SAMPart3Dï¼‰éš¾ä»¥å¤„ç†ç»†ç²’åº¦å’Œå¶å­çº§åˆ«çš„éƒ¨ä»¶ï¼›(2) 3Déƒ¨ä»¶ä¸­å¿ƒé—®ç­”ï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹3D-LLMçš„æ–°åŸºå‡†ï¼Œæ­ç¤ºäº†å¼€æ”¾è¯æ±‡éƒ¨ä»¶ grounding æ–¹é¢çš„æ˜¾è‘—å·®è·ã€‚æ­¤å¤–ï¼Œåœ¨PartNeXtä¸Šè®­ç»ƒPoint-SAMæ¯”åœ¨PartNetä¸Šè®­ç»ƒæ•ˆæœæ›´å¥½ï¼Œçªæ˜¾äº†è¯¥æ•°æ®é›†çš„å“è¶Šè´¨é‡å’Œå¤šæ ·æ€§ã€‚PartNeXtç»“åˆäº†å¯æ‰©å±•çš„æ ‡æ³¨ã€çº¹ç†æ„ŸçŸ¥æ ‡ç­¾å’Œå¤šä»»åŠ¡è¯„ä¼°ï¼Œä¸ºç»“æ„åŒ–3Dç†è§£çš„ç ”ç©¶å¼€è¾Ÿäº†æ–°é€”å¾„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰3Déƒ¨ä»¶ç†è§£æ•°æ®é›†ï¼Œå¦‚PartNetï¼Œä¸»è¦ä¾èµ–äºæ— çº¹ç†çš„å‡ ä½•æ¨¡å‹ï¼Œå¹¶ä¸”æ ‡æ³¨è¿‡ç¨‹ä¾èµ–äºä¸“å®¶çŸ¥è¯†ï¼Œè¿™é™åˆ¶äº†æ•°æ®é›†çš„è§„æ¨¡å’Œæ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†ç»†ç²’åº¦å’Œå¶å­çº§åˆ«çš„éƒ¨ä»¶åˆ†å‰²æ—¶è¡¨ç°ä¸ä½³ï¼Œå¹¶ä¸”ç¼ºä¹é’ˆå¯¹3Déƒ¨ä»¶çš„å¼€æ”¾è¯æ±‡ grounding èƒ½åŠ›çš„è¯„ä¼°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šPartNeXtçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼•å…¥å¸¦çº¹ç†çš„3Dæ¨¡å‹å’Œå¯æ‰©å±•çš„æ ‡æ³¨æ–¹æ³•ï¼Œæ„å»ºä¸€ä¸ªæ›´å¤§ã€æ›´ç»†ç²’åº¦ã€æ›´å…·å¤šæ ·æ€§çš„3Déƒ¨ä»¶ç†è§£æ•°æ®é›†ã€‚åŒæ—¶ï¼Œè®¾è®¡æ–°çš„åŸºå‡†æµ‹è¯•ä»»åŠ¡ï¼Œä¾‹å¦‚3Déƒ¨ä»¶ä¸­å¿ƒé—®ç­”ï¼Œæ¥è¯„ä¼°æ¨¡å‹åœ¨å¼€æ”¾è¯æ±‡ç¯å¢ƒä¸‹çš„éƒ¨ä»¶ç†è§£èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPartNeXtæ•°æ®é›†åŒ…å«è¶…è¿‡23,000ä¸ª3Dæ¨¡å‹ï¼Œæ¶µç›–50ä¸ªç±»åˆ«ã€‚æ¯ä¸ªæ¨¡å‹éƒ½å¸¦æœ‰ç»†ç²’åº¦çš„åˆ†å±‚éƒ¨ä»¶æ ‡ç­¾å’Œçº¹ç†ä¿¡æ¯ã€‚æ•°æ®é›†è¢«ç”¨äºè¯„ä¼°ä¸¤ä¸ªä»»åŠ¡ï¼šç±»æ— å…³éƒ¨ä»¶åˆ†å‰²å’Œ3Déƒ¨ä»¶ä¸­å¿ƒé—®ç­”ã€‚ç ”ç©¶äººå‘˜ä½¿ç”¨ç°æœ‰çš„éƒ¨ä»¶åˆ†å‰²æ–¹æ³•ï¼ˆå¦‚PartFieldã€SAMPart3Dï¼‰å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨PartNeXtä¸Šè¿›è¡Œå®éªŒï¼Œå¹¶åˆ†æå…¶æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šPartNeXtçš„å…³é”®åˆ›æ–°åœ¨äºå…¶é«˜è´¨é‡ã€å¸¦çº¹ç†çš„3Dæ¨¡å‹å’Œç»†ç²’åº¦çš„åˆ†å±‚éƒ¨ä»¶æ ‡ç­¾ã€‚ä¸ç°æœ‰æ•°æ®é›†ç›¸æ¯”ï¼ŒPartNeXtæä¾›äº†æ›´ä¸°å¯Œçš„è§†è§‰ä¿¡æ¯å’Œæ›´ç²¾ç»†çš„éƒ¨ä»¶åˆ’åˆ†ï¼Œè¿™æœ‰åŠ©äºæé«˜æ¨¡å‹å¯¹3Déƒ¨ä»¶çš„ç†è§£èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œ3Déƒ¨ä»¶ä¸­å¿ƒé—®ç­”ä»»åŠ¡æ˜¯ä¸€ä¸ªæ–°çš„åŸºå‡†ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹åœ¨å¼€æ”¾è¯æ±‡ç¯å¢ƒä¸‹çš„éƒ¨ä»¶ grounding èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šPartNeXtæ•°æ®é›†çš„æ ‡æ³¨è¿‡ç¨‹é‡‡ç”¨äº†å¯æ‰©å±•çš„æ–¹æ³•ï¼Œå…·ä½“ç»†èŠ‚æœªçŸ¥ã€‚åœ¨å®éªŒä¸­ï¼Œç ”ç©¶äººå‘˜ä½¿ç”¨äº†Point-SAMæ¨¡å‹ï¼Œå¹¶åœ¨PartNeXtä¸Šè¿›è¡Œäº†è®­ç»ƒï¼Œä»¥éªŒè¯æ•°æ®é›†çš„æœ‰æ•ˆæ€§ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç­‰æŠ€æœ¯ç»†èŠ‚åœ¨è®ºæ–‡ä¸­å¯èƒ½æœ‰æ‰€æè¿°ï¼Œä½†æ‘˜è¦ä¸­æœªæåŠã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œç°æœ‰æ–¹æ³•åœ¨PartNeXtæ•°æ®é›†ä¸Šè¿›è¡Œç±»æ— å…³éƒ¨ä»¶åˆ†å‰²æ—¶ï¼Œéš¾ä»¥å¤„ç†ç»†ç²’åº¦å’Œå¶å­çº§åˆ«çš„éƒ¨ä»¶ã€‚åœ¨3Déƒ¨ä»¶ä¸­å¿ƒé—®ç­”ä»»åŠ¡ä¸­ï¼Œ3D-LLMåœ¨å¼€æ”¾è¯æ±‡éƒ¨ä»¶ grounding æ–¹é¢å­˜åœ¨æ˜¾è‘—å·®è·ã€‚æ­¤å¤–ï¼Œåœ¨PartNeXtä¸Šè®­ç»ƒPoint-SAMæ¯”åœ¨PartNetä¸Šè®­ç»ƒæ•ˆæœæ›´å¥½ï¼ŒéªŒè¯äº†PartNeXtæ•°æ®é›†çš„ä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

PartNeXtæ•°æ®é›†å¯å¹¿æ³›åº”ç”¨äºè®¡ç®—æœºè§†è§‰ã€æœºå™¨äººå’Œå›¾å½¢å­¦ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œå¯ç”¨äºè®­ç»ƒæœºå™¨äººè¿›è¡Œç²¾ç»†æ“ä½œï¼Œæå‡3Dåœºæ™¯ç†è§£èƒ½åŠ›ï¼Œæ”¹è¿›CADæ¨¡å‹æ£€ç´¢å’Œç¼–è¾‘ï¼Œä»¥åŠå¼€å‘æ›´æ™ºèƒ½çš„3Dé—®ç­”ç³»ç»Ÿã€‚è¯¥æ•°æ®é›†æœ‰æœ›æ¨åŠ¨ç›¸å…³é¢†åŸŸçš„ç ”ç©¶è¿›å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Understanding objects at the level of their constituent parts is fundamental to advancing computer vision, graphics, and robotics. While datasets like PartNet have driven progress in 3D part understanding, their reliance on untextured geometries and expert-dependent annotation limits scalability and usability. We introduce PartNeXt, a next-generation dataset addressing these gaps with over 23,000 high-quality, textured 3D models annotated with fine-grained, hierarchical part labels across 50 categories. We benchmark PartNeXt on two tasks: (1) class-agnostic part segmentation, where state-of-the-art methods (e.g., PartField, SAMPart3D) struggle with fine-grained and leaf-level parts, and (2) 3D part-centric question answering, a new benchmark for 3D-LLMs that reveals significant gaps in open-vocabulary part grounding. Additionally, training Point-SAM on PartNeXt yields substantial gains over PartNet, underscoring the dataset's superior quality and diversity. By combining scalable annotation, texture-aware labels, and multi-task evaluation, PartNeXt opens new avenues for research in structured 3D understanding.

