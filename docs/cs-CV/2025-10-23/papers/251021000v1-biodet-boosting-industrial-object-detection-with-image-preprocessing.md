---
layout: default
title: BioDet: Boosting Industrial Object Detection with Image Preprocessing Strategies
---

# BioDet: Boosting Industrial Object Detection with Image Preprocessing Strategies

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.21000" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.21000v1</a>
  <a href="https://arxiv.org/pdf/2510.21000.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.21000v1" onclick="toggleFavorite(this, '2510.21000v1', 'BioDet: Boosting Industrial Object Detection with Image Preprocessing Strategies')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiaqi Hu, Hongli Xu, Junwen Huang, Peter KT Yu, Slobodan Ilic, Benjamin Busam

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-23

**å¤‡æ³¨**: 8 pages, accepted by ICCV 2025 R6D

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**BioDetï¼šåˆ©ç”¨å›¾åƒé¢„å¤„ç†ç­–ç•¥æå‡å·¥ä¸šç›®æ ‡æ£€æµ‹æ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å·¥ä¸šç›®æ ‡æ£€æµ‹` `å›¾åƒé¢„å¤„ç†` `ä½å…‰å¢å¼º` `èƒŒæ™¯å»é™¤` `å¼€æ”¾è¯æ±‡æ£€æµ‹` `æœºå™¨äººæ“ä½œ` `6Dä½å§¿ä¼°è®¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å·¥ä¸šåœºæ™¯ä¸‹æœºå™¨äººæ“ä½œä¾èµ–ç²¾ç¡®6Dä½å§¿ä¼°è®¡ï¼Œè€Œç°æœ‰æ£€æµ‹å™¨åœ¨å¤æ‚ç¯å¢ƒä¸‹æ€§èƒ½å—é™ï¼Œæˆä¸ºç“¶é¢ˆã€‚
2. BioDeté€šè¿‡ä½å…‰å¢å¼ºå’ŒåŸºäºå¼€æ”¾è¯æ±‡æ£€æµ‹çš„èƒŒæ™¯å»é™¤ï¼Œå‡å°‘é¢†åŸŸåç§»å’Œå‡é˜³æ€§ï¼Œæå‡æ£€æµ‹å¯é æ€§ã€‚
3. åœ¨çœŸå®å·¥ä¸šæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒBioDetæ˜¾è‘—æå‡äº†æ£€æµ‹ç²¾åº¦ï¼Œä¸”æ¨ç†å¼€é”€å¯å¿½ç•¥ä¸è®¡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç²¾ç¡®çš„6Dä½å§¿ä¼°è®¡å¯¹äºå·¥ä¸šç¯å¢ƒä¸­çš„æœºå™¨äººæ“ä½œè‡³å…³é‡è¦ã€‚ç°æœ‰çš„æ–¹æ³•é€šå¸¸ä¾èµ–äºç°æˆçš„ç›®æ ‡æ£€æµ‹å™¨ï¼Œç„¶åè¿›è¡Œè£å‰ªå’Œä½å§¿ä¼˜åŒ–ï¼Œä½†åœ¨æ‚ä¹±ã€å…‰çº¿ä¸è¶³å’Œå¤æ‚èƒŒæ™¯ç­‰å…·æœ‰æŒ‘æˆ˜æ€§çš„æ¡ä»¶ä¸‹ï¼Œå…¶æ€§èƒ½ä¼šä¸‹é™ï¼Œä½¿å¾—æ£€æµ‹æˆä¸ºå…³é”®ç“¶é¢ˆã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ ‡å‡†åŒ–çš„ã€å¯æ’æ‹”çš„æµæ°´çº¿ï¼Œç”¨äºå·¥ä¸šç¯å¢ƒä¸­æœªè§ç‰©ä½“çš„2Dæ£€æµ‹ã€‚åŸºäºå½“å‰SOTAåŸºçº¿ï¼Œæˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡ä½å…‰å›¾åƒå¢å¼ºå’ŒåŸºäºå¼€æ”¾è¯æ±‡æ£€æµ‹ä¸åŸºç¡€æ¨¡å‹çš„èƒŒæ™¯å»é™¤æ¥å‡å°‘é¢†åŸŸåç§»å’ŒèƒŒæ™¯ä¼ªå½±ã€‚è¿™ç§è®¾è®¡æŠ‘åˆ¶äº†åŸå§‹SAMè¾“å‡ºä¸­å¸¸è§çš„å‡é˜³æ€§ï¼Œä»è€Œä¸ºä¸‹æ¸¸ä½å§¿ä¼°è®¡äº§ç”Ÿæ›´å¯é çš„æ£€æµ‹ç»“æœã€‚åœ¨BOPæä¾›çš„çœŸå®å·¥ä¸šåˆ†æ‹£åŸºå‡†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜¾è‘—æé«˜äº†æ£€æµ‹ç²¾åº¦ï¼ŒåŒæ—¶äº§ç”Ÿçš„æ¨ç†å¼€é”€å¯ä»¥å¿½ç•¥ä¸è®¡ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å·¥ä¸šç¯å¢ƒä¸­ç›®æ ‡æ£€æµ‹åœ¨å¤æ‚æ¡ä»¶ä¸‹çš„æ€§èƒ½ç“¶é¢ˆé—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å…‰ç…§ä¸è¶³ã€èƒŒæ™¯æ‚ä¹±ç­‰æƒ…å†µä¸‹ï¼Œæ£€æµ‹ç²¾åº¦æ˜¾è‘—ä¸‹é™ï¼Œä¸¥é‡å½±å“ä¸‹æ¸¸çš„6Dä½å§¿ä¼°è®¡ä»»åŠ¡ã€‚ç°æœ‰çš„ç›®æ ‡æ£€æµ‹å™¨éš¾ä»¥é€‚åº”å·¥ä¸šåœºæ™¯ä¸­æœªè§è¿‡çš„ç‰©ä½“ï¼Œæ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å›¾åƒé¢„å¤„ç†æ¥å‡å°‘é¢†åŸŸåç§»å’ŒèƒŒæ™¯å¹²æ‰°ï¼Œä»è€Œæå‡ç›®æ ‡æ£€æµ‹å™¨çš„æ€§èƒ½ã€‚å…·ä½“æ¥è¯´ï¼Œåˆ©ç”¨ä½å…‰å›¾åƒå¢å¼ºæ¥æ”¹å–„å…‰ç…§æ¡ä»¶ï¼Œå¹¶åˆ©ç”¨å¼€æ”¾è¯æ±‡æ£€æµ‹å’ŒåŸºç¡€æ¨¡å‹è¿›è¡ŒèƒŒæ™¯å»é™¤ï¼Œä»¥å‡å°‘èƒŒæ™¯å™ªå£°ã€‚è¿™ç§é¢„å¤„ç†æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°æŠ‘åˆ¶å‡é˜³æ€§ï¼Œæé«˜æ£€æµ‹çš„å¯é æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šBioDetçš„æ•´ä½“æ¡†æ¶æ˜¯ä¸€ä¸ªå¯æ’æ‹”çš„æµæ°´çº¿ï¼ŒåŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦é˜¶æ®µï¼š1) ä½å…‰å›¾åƒå¢å¼ºï¼šä½¿ç”¨å›¾åƒå¢å¼ºç®—æ³•æ¥æ”¹å–„å…‰ç…§æ¡ä»¶ï¼Œæé«˜å›¾åƒçš„å¯¹æ¯”åº¦å’Œäº®åº¦ã€‚2) åŸºäºå¼€æ”¾è¯æ±‡æ£€æµ‹çš„èƒŒæ™¯å»é™¤ï¼šåˆ©ç”¨å¼€æ”¾è¯æ±‡æ£€æµ‹æ¨¡å‹ï¼ˆå¦‚SAMï¼‰æ¥è¯†åˆ«å›¾åƒä¸­çš„ç‰©ä½“å’ŒèƒŒæ™¯åŒºåŸŸï¼Œç„¶åå»é™¤èƒŒæ™¯åŒºåŸŸï¼Œçªå‡ºç›®æ ‡ç‰©ä½“ã€‚3) ç›®æ ‡æ£€æµ‹ï¼šä½¿ç”¨ç°æœ‰çš„ç›®æ ‡æ£€æµ‹å™¨ï¼ˆå¦‚Faster R-CNNï¼‰æ¥æ£€æµ‹é¢„å¤„ç†åçš„å›¾åƒä¸­çš„ç›®æ ‡ç‰©ä½“ã€‚4) ä½å§¿ä¼°è®¡ï¼šåˆ©ç”¨æ£€æµ‹åˆ°çš„ç›®æ ‡ç‰©ä½“è¿›è¡Œ6Dä½å§¿ä¼°è®¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†å›¾åƒé¢„å¤„ç†æŠ€æœ¯ä¸å¼€æ”¾è¯æ±‡æ£€æµ‹ç›¸ç»“åˆï¼Œç”¨äºæå‡å·¥ä¸šç›®æ ‡æ£€æµ‹çš„æ€§èƒ½ã€‚é€šè¿‡ä½å…‰å›¾åƒå¢å¼ºå’ŒèƒŒæ™¯å»é™¤ï¼Œæœ‰æ•ˆåœ°å‡å°‘äº†é¢†åŸŸåç§»å’ŒèƒŒæ™¯å¹²æ‰°ï¼Œæé«˜äº†æ£€æµ‹çš„å¯é æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•æ˜¯ä¸€ä¸ªå¯æ’æ‹”çš„æµæ°´çº¿ï¼Œå¯ä»¥æ–¹ä¾¿åœ°é›†æˆåˆ°ç°æœ‰çš„ç›®æ ‡æ£€æµ‹ç³»ç»Ÿä¸­ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ä½å…‰å›¾åƒå¢å¼ºæ–¹é¢ï¼Œè®ºæ–‡å¯èƒ½é‡‡ç”¨äº†å¤šç§å›¾åƒå¢å¼ºç®—æ³•ï¼Œä¾‹å¦‚ç›´æ–¹å›¾å‡è¡¡åŒ–ã€Retinexç®—æ³•ç­‰ã€‚åœ¨èƒŒæ™¯å»é™¤æ–¹é¢ï¼Œè®ºæ–‡åˆ©ç”¨SAMæ¨¡å‹ç”Ÿæˆmaskï¼Œç„¶åä½¿ç”¨maskå¯¹å›¾åƒè¿›è¡Œåˆ†å‰²ï¼Œå»é™¤èƒŒæ™¯åŒºåŸŸã€‚åœ¨ç›®æ ‡æ£€æµ‹æ–¹é¢ï¼Œè®ºæ–‡å¯èƒ½é‡‡ç”¨äº†Faster R-CNNã€YOLOç­‰å¸¸ç”¨çš„ç›®æ ‡æ£€æµ‹å™¨ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„å¯èƒ½æ ¹æ®å…·ä½“çš„åº”ç”¨åœºæ™¯è¿›è¡Œè°ƒæ•´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒBioDetåœ¨çœŸå®å·¥ä¸šåˆ†æ‹£åŸºå‡†ä¸Šæ˜¾è‘—æé«˜äº†æ£€æµ‹ç²¾åº¦ï¼ŒåŒæ—¶æ¨ç†å¼€é”€å¯ä»¥å¿½ç•¥ä¸è®¡ã€‚ä¸ç°æœ‰SOTAæ–¹æ³•ç›¸æ¯”ï¼ŒBioDetåœ¨æ£€æµ‹ç²¾åº¦æ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æå‡ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦éœ€è¦åœ¨è®ºæ–‡ä¸­æŸ¥æ‰¾ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

BioDetå¯å¹¿æ³›åº”ç”¨äºå·¥ä¸šæœºå™¨äººã€è‡ªåŠ¨åŒ–ç”Ÿäº§çº¿ã€æ™ºèƒ½ä»“å‚¨ç­‰é¢†åŸŸã€‚é€šè¿‡æé«˜ç›®æ ‡æ£€æµ‹çš„ç²¾åº¦å’Œå¯é æ€§ï¼Œå¯ä»¥æå‡æœºå™¨äººæ“ä½œçš„æ•ˆç‡å’Œå‡†ç¡®æ€§ï¼Œé™ä½ç”Ÿäº§æˆæœ¬ï¼Œæé«˜äº§å“è´¨é‡ã€‚è¯¥ç ”ç©¶å¯¹äºæ¨åŠ¨å·¥ä¸šè‡ªåŠ¨åŒ–å’Œæ™ºèƒ½åŒ–å…·æœ‰é‡è¦æ„ä¹‰ï¼Œå¹¶ä¸ºæœªæ¥çš„å·¥ä¸šæœºå™¨äººåº”ç”¨æä¾›äº†æ–°çš„æ€è·¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Accurate 6D pose estimation is essential for robotic manipulation in industrial environments. Existing pipelines typically rely on off-the-shelf object detectors followed by cropping and pose refinement, but their performance degrades under challenging conditions such as clutter, poor lighting, and complex backgrounds, making detection the critical bottleneck. In this work, we introduce a standardized and plug-in pipeline for 2D detection of unseen objects in industrial settings. Based on current SOTA baselines, our approach reduces domain shift and background artifacts through low-light image enhancement and background removal guided by open-vocabulary detection with foundation models. This design suppresses the false positives prevalent in raw SAM outputs, yielding more reliable detections for downstream pose estimation. Extensive experiments on real-world industrial bin-picking benchmarks from BOP demonstrate that our method significantly boosts detection accuracy while incurring negligible inference overhead, showing the effectiveness and practicality of the proposed method.

