---
layout: default
title: "HCC-3D: Hierarchical Compensatory Compression for 98% 3D Token Reduction in Vision-Language Models"
---

# HCC-3D: Hierarchical Compensatory Compression for 98% 3D Token Reduction in Vision-Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.09883" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.09883v1</a>
  <a href="https://arxiv.org/pdf/2511.09883.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.09883v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.09883v1', 'HCC-3D: Hierarchical Compensatory Compression for 98% 3D Token Reduction in Vision-Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Liheng Zhang, Jin Wang, Hui Li, Bingfeng Zhang, Weifeng Liu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-13

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHCC-3Dï¼Œé€šè¿‡åˆ†å±‚è¡¥å¿å‹ç¼©å®ç°3Dè§†è§‰è¯­è¨€æ¨¡å‹ä¸­98%çš„Tokenç¼©å‡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `3Dè§†è§‰è¯­è¨€æ¨¡å‹` `ç‚¹äº‘å¤„ç†` `Tokenå‹ç¼©` `åˆ†å±‚å‹ç¼©` `è‡ªé€‚åº”ç»†èŠ‚æŒ–æ˜`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰3D-VLMsç›´æ¥å¤„ç†å¤§é‡3D tokenså¯¼è‡´è®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œé™åˆ¶äº†å…¶åº”ç”¨ï¼ŒäºŸéœ€é«˜æ•ˆçš„3D tokenå‹ç¼©æ–¹æ³•ã€‚
2. HCC-3Dé€šè¿‡å…¨å±€ç»“æ„å‹ç¼©ä¿ç•™æ•´ä½“ç»“æ„ä¿¡æ¯ï¼Œå¹¶åˆ©ç”¨è‡ªé€‚åº”ç»†èŠ‚æŒ–æ˜è¡¥å¿å‹ç¼©è¿‡ç¨‹ä¸­çš„ä¿¡æ¯æŸå¤±ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒHCC-3Då®ç°äº†98%çš„tokenå‹ç¼©ç‡ï¼Œå¹¶åœ¨å¤šä¸ªä»»åŠ¡ä¸Šå–å¾—äº†state-of-the-artçš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºåˆ†å±‚è¡¥å¿å‹ç¼©ï¼ˆHCC-3Dï¼‰çš„æ–¹æ³•ï¼Œæ—¨åœ¨é«˜æ•ˆå‹ç¼©3Dè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰ä¸­çš„3D tokensï¼ŒåŒæ—¶ä¿ç•™å…³é”®ç»†èŠ‚ä¿¡æ¯ã€‚ç°æœ‰3D-VLMsç›´æ¥å°†3Dç‚¹äº‘åµŒå…¥åˆ°3D tokensä¸­ï¼Œè®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œé™åˆ¶äº†å…¶åº”ç”¨ã€‚HCC-3Dé¦–å…ˆé‡‡ç”¨å…¨å±€ç»“æ„å‹ç¼©ï¼ˆGSCï¼‰ï¼Œè®¾è®¡å…¨å±€æŸ¥è¯¢å°†æ‰€æœ‰3D tokenså‹ç¼©ä¸ºå°‘é‡å…³é”®tokensï¼Œä¿ç•™æ•´ä½“ç»“æ„ä¿¡æ¯ã€‚ç„¶åï¼Œä¸ºäº†è¡¥å¿GSCä¸­çš„ä¿¡æ¯æŸå¤±ï¼Œè¿›ä¸€æ­¥æå‡ºè‡ªé€‚åº”ç»†èŠ‚æŒ–æ˜ï¼ˆADMï¼‰æ¨¡å—ï¼Œé€šè¿‡äº’è¡¥è¯„åˆ†é€‰æ‹©æ€§åœ°é‡æ–°å‹ç¼©æ˜¾è‘—ä½†æœªå……åˆ†å…³æ³¨çš„ç‰¹å¾ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒHCC-3Dä¸ä»…å®ç°äº†æé«˜çš„å‹ç¼©ç‡ï¼ˆçº¦98%ï¼‰ï¼Œè€Œä¸”è¾¾åˆ°äº†æ–°çš„state-of-the-artæ€§èƒ½ï¼Œåœ¨æ•ˆç‡å’Œæ€§èƒ½ä¸Šå‡æœ‰æ˜¾è‘—æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰3Dè§†è§‰è¯­è¨€æ¨¡å‹ç›´æ¥å°†3Dç‚¹äº‘è½¬æ¢ä¸ºå¤§é‡çš„3D tokensï¼Œç„¶åè¾“å…¥åˆ°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­è¿›è¡Œå¤„ç†ã€‚è¿™ç§æ–¹æ³•è®¡ç®—æˆæœ¬éå¸¸é«˜ï¼Œä¸¥é‡é™åˆ¶äº†3D-VLMsçš„åº”ç”¨ã€‚ä¸»è¦çš„ç—›ç‚¹åœ¨äºLLMéœ€è¦å¤„ç†å¤§é‡çš„3D tokensï¼Œå¯¼è‡´è®¡ç®—ç“¶é¢ˆã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡åˆ†å±‚å‹ç¼©çš„æ–¹å¼ï¼Œåœ¨å°½å¯èƒ½ä¿ç•™å…³é”®ä¿¡æ¯çš„å‰æä¸‹ï¼Œå¤§å¹…åº¦å‡å°‘3D tokensçš„æ•°é‡ã€‚é¦–å…ˆè¿›è¡Œå…¨å±€ç»“æ„å‹ç¼©ï¼Œä¿ç•™æ•´ä½“çš„ç»“æ„ä¿¡æ¯ï¼›ç„¶åï¼Œé’ˆå¯¹å‹ç¼©è¿‡ç¨‹ä¸­å¯èƒ½ä¸¢å¤±çš„ç»†èŠ‚ä¿¡æ¯ï¼Œè¿›è¡Œè‡ªé€‚åº”çš„ç»†èŠ‚æŒ–æ˜å’Œè¡¥å¿ã€‚è¿™æ ·æ—¢èƒ½é™ä½è®¡ç®—é‡ï¼Œåˆèƒ½ä¿è¯æ¨¡å‹çš„æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šHCC-3DåŒ…å«ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šå…¨å±€ç»“æ„å‹ç¼©ï¼ˆGSCï¼‰å’Œè‡ªé€‚åº”ç»†èŠ‚æŒ–æ˜ï¼ˆADMï¼‰ã€‚GSCæ¨¡å—ä½¿ç”¨å…¨å±€æŸ¥è¯¢æ¥å‹ç¼©æ‰€æœ‰3D tokensï¼Œæå–å°‘é‡å…³é”®tokensï¼Œä¿ç•™æ•´ä½“ç»“æ„ä¿¡æ¯ã€‚ADMæ¨¡å—åˆ™é€šè¿‡äº’è¡¥è¯„åˆ†æœºåˆ¶ï¼Œé€‰æ‹©æ€§åœ°é‡æ–°å‹ç¼©æ˜¾è‘—ä½†æœªè¢«å……åˆ†å…³æ³¨çš„ç‰¹å¾ï¼Œä»¥è¡¥å¿GSCä¸­å¯èƒ½ä¸¢å¤±çš„ç»†èŠ‚ä¿¡æ¯ã€‚æ•´ä¸ªæµç¨‹æ˜¯å…ˆè¿›è¡Œå…¨å±€å‹ç¼©ï¼Œå†è¿›è¡Œå±€éƒ¨ç»†èŠ‚è¡¥å¿ï¼Œä»è€Œå®ç°é«˜æ•ˆçš„tokenå‹ç¼©ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºåˆ†å±‚è¡¥å¿å‹ç¼©çš„ç­–ç•¥ã€‚ä¼ ç»Ÿçš„å‹ç¼©æ–¹æ³•å¾€å¾€ä¼šé€ æˆä¿¡æ¯æŸå¤±ï¼Œè€ŒHCC-3Dé€šè¿‡å…¨å±€ç»“æ„å‹ç¼©å’Œè‡ªé€‚åº”ç»†èŠ‚æŒ–æ˜ç›¸ç»“åˆï¼Œèƒ½å¤Ÿåœ¨å¤§å¹…åº¦å‹ç¼©tokensçš„åŒæ—¶ï¼Œå°½å¯èƒ½åœ°ä¿ç•™å…³é”®ä¿¡æ¯ã€‚è¿™ç§åˆ†å±‚è¡¥å¿çš„ç­–ç•¥æ˜¯ä¸ç°æœ‰æ–¹æ³•æœ€æœ¬è´¨çš„åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šGSCæ¨¡å—ä¸­ï¼Œå…¨å±€æŸ¥è¯¢çš„è®¾è®¡è‡³å…³é‡è¦ï¼Œéœ€è¦èƒ½å¤Ÿæœ‰æ•ˆåœ°æå–å…¨å±€ç»“æ„ä¿¡æ¯ã€‚ADMæ¨¡å—ä¸­ï¼Œäº’è¡¥è¯„åˆ†æœºåˆ¶çš„è®¾è®¡éœ€è¦èƒ½å¤Ÿå‡†ç¡®åœ°è¯†åˆ«å‡ºæ˜¾è‘—ä½†æœªè¢«å……åˆ†å…³æ³¨çš„ç‰¹å¾ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’ŒæŸå¤±å‡½æ•°ç»†èŠ‚è®ºæ–‡ä¸­æœªæ˜ç¡®ç»™å‡ºï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚æ¨æµ‹å¯èƒ½ä½¿ç”¨äº†æ³¨æ„åŠ›æœºåˆ¶ç›¸å…³çš„ç½‘ç»œç»“æ„ï¼ŒæŸå¤±å‡½æ•°å¯èƒ½åŒ…å«é‡å»ºæŸå¤±å’Œå¯¹æ¯”æŸå¤±ç­‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

HCC-3Då®ç°äº†é«˜è¾¾98%çš„3D tokenå‹ç¼©ç‡ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—æˆæœ¬ã€‚åŒæ—¶ï¼Œåœ¨å¤šä¸ª3Dè§†è§‰è¯­è¨€ä»»åŠ¡ä¸Šå–å¾—äº†state-of-the-artçš„æ€§èƒ½ï¼Œè¡¨æ˜è¯¥æ–¹æ³•åœ¨æ•ˆç‡å’Œæ€§èƒ½ä¸Šå‡æœ‰æ˜¾è‘—æå‡ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿åœ¨æ‘˜è¦ä¸­æœªç»™å‡ºï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

HCC-3Då…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚åœ¨è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€ä¸‰ç»´åœºæ™¯ç†è§£ç­‰é¢†åŸŸã€‚é€šè¿‡é™ä½3D-VLMsçš„è®¡ç®—æˆæœ¬ï¼Œå¯ä»¥ä½¿å…¶æ›´å®¹æ˜“éƒ¨ç½²åœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šï¼Œä»è€ŒåŠ é€Ÿè¿™äº›æŠ€æœ¯çš„è½åœ°å’Œåº”ç”¨ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥åº”ç”¨äºå…¶ä»–éœ€è¦å¤„ç†å¤§é‡tokensçš„å¤šæ¨¡æ€ä»»åŠ¡ä¸­ï¼Œå…·æœ‰ä¸€å®šçš„é€šç”¨æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> 3D understanding has drawn significant attention recently, leveraging Vision-Language Models (VLMs) to enable multi-modal reasoning between point cloud and text data. Current 3D-VLMs directly embed the 3D point clouds into 3D tokens, following large 2D-VLMs with powerful reasoning capabilities. However, this framework has a great computational cost limiting its application, where we identify that the bottleneck lies in processing all 3D tokens in the Large Language Model (LLM) part. This raises the question: how can we reduce the computational overhead introduced by 3D tokens while preserving the integrity of their essential information? To address this question, we introduce Hierarchical Compensatory Compression (HCC-3D) to efficiently compress 3D tokens while maintaining critical detail retention. Specifically, we first propose a global structure compression (GSC), in which we design global queries to compress all 3D tokens into a few key tokens while keeping overall structural information. Then, to compensate for the information loss in GSC, we further propose an adaptive detail mining (ADM) module that selectively recompresses salient but under-attended features through complementary scoring. Extensive experiments demonstrate that HCC-3D not only achieves extreme compression ratios (approximately 98%) compared to previous 3D-VLMs, but also achieves new state-of-the-art performance, showing the great improvements on both efficiency and performance.

