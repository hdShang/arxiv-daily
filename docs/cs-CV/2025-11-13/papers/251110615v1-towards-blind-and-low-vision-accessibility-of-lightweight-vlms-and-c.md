---
layout: default
title: Towards Blind and Low-Vision Accessibility of Lightweight VLMs and Custom LLM-Evals
---

# Towards Blind and Low-Vision Accessibility of Lightweight VLMs and Custom LLM-Evals

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.10615" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.10615v1</a>
  <a href="https://arxiv.org/pdf/2511.10615.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.10615v1" onclick="toggleFavorite(this, '2511.10615v1', 'Towards Blind and Low-Vision Accessibility of Lightweight VLMs and Custom LLM-Evals')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shruti Singh Baghel, Yash Pratap Singh Rathore, Sushovan Jena, Anurag Pradhan, Amit Shukla, Arnav Bhavsar, Pawan Goyal

**åˆ†ç±»**: cs.CV, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-11-13

**å¤‡æ³¨**: 8 pages

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é’ˆå¯¹è§†éšœäººå£«ï¼Œè¯„ä¼°è½»é‡çº§VLMåœ¨è§†é¢‘ç†è§£ä¸­çš„å¯è®¿é—®æ€§ï¼Œå¹¶æå‡ºå®šåˆ¶åŒ–è¯„ä¼°æ¡†æ¶ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)** **æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction)**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡å‹` `å¯è®¿é—®æ€§` `ç›²äººè¾…åŠ©` `è§†é¢‘ç†è§£` `è½»é‡çº§æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰VLMæ¨¡å‹ä½“ç§¯åºå¤§ï¼Œéš¾ä»¥åœ¨èµ„æºå—é™è®¾å¤‡ä¸Šéƒ¨ç½²ï¼Œé™åˆ¶äº†å…¶åœ¨è§†éšœäººå£«è¾…åŠ©åº”ç”¨ä¸­çš„åº”ç”¨ã€‚
2. è®ºæ–‡æå‡ºé’ˆå¯¹è§†éšœäººå£«çš„è§†é¢‘ç†è§£è¯„ä¼°æ¡†æ¶ï¼Œå¹¶ç ”ç©¶ä¸åŒå¤§å°çš„è½»é‡çº§VLMæ¨¡å‹åœ¨å¯è®¿é—®æ€§æ–¹é¢çš„è¡¨ç°ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè½»é‡çº§VLMåœ¨ç§»åŠ¨è®¾å¤‡ä¸Šå…·æœ‰å¯è¡Œæ€§ï¼Œå¹¶ä¸ºæœªæ¥çš„æ¨¡å‹ä¼˜åŒ–æä¾›äº†æŒ‡å¯¼ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹(VLM)åœ¨ç†è§£å’Œç”Ÿæˆè§†é¢‘æè¿°æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶é«˜å†…å­˜ã€è®¡ç®—å’Œéƒ¨ç½²éœ€æ±‚é˜»ç¢äº†å®é™…åº”ç”¨ï¼Œç‰¹åˆ«æ˜¯å¯¹äºä¾èµ–è¯¦ç»†ã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥æè¿°çš„ç›²äººå’Œä½è§†åŠ›(BLV)ç”¨æˆ·ã€‚ä¸ºäº†ç ”ç©¶æ¨¡å‹å¤§å°å¯¹ä»¥å¯è®¿é—®æ€§ä¸ºä¸­å¿ƒçš„æè¿°è´¨é‡çš„å½±å“ï¼Œæˆ‘ä»¬è¯„ä¼°äº†å‚æ•°é‡åˆ†åˆ«ä¸º500Må’Œ2.2Bçš„SmolVLM2å˜ä½“ï¼Œæ•°æ®é›†åŒ…æ‹¬AVCaps(å®¤å¤–)å’ŒCharades(å®¤å†…)ã€‚æˆ‘ä»¬æå‡ºäº†ä¸¤ä¸ªä¸“é—¨ä¸ºBLVå¯è®¿é—®æ€§è¯„ä¼°è€Œè®¾è®¡çš„æ–°å‹è¯„ä¼°æ¡†æ¶ï¼šå¤šä¸Šä¸‹æ–‡BLVæ¡†æ¶ï¼Œè¯„ä¼°ç©ºé—´å®šä½ã€ç¤¾äº¤äº’åŠ¨ã€åŠ¨ä½œäº‹ä»¶å’Œç¯å¢ƒä¸Šä¸‹æ–‡ï¼›å¯¼èˆªè¾…åŠ©æ¡†æ¶ï¼Œä¾§é‡äºç§»åŠ¨å…³é”®ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ç³»ç»Ÿåœ°è¯„ä¼°äº†å››ç§ä¸åŒçš„æç¤ºè®¾è®¡ç­–ç•¥ï¼Œå¹¶åœ¨æ™ºèƒ½æ‰‹æœºä¸Šéƒ¨ç½²äº†è¿™ä¸¤ä¸ªæ¨¡å‹ï¼Œè¯„ä¼°FP32å’ŒINT8ç²¾åº¦å˜ä½“ï¼Œä»¥è¯„ä¼°èµ„æºå—é™çš„ç§»åŠ¨è®¾å¤‡ä¸Šçš„å®é™…æ€§èƒ½çº¦æŸã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰è™½ç„¶åœ¨è§†é¢‘æè¿°æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶åºå¤§çš„æ¨¡å‹ä½“ç§¯å’Œè®¡ç®—éœ€æ±‚ä½¿å…¶éš¾ä»¥åœ¨èµ„æºå—é™çš„ç§»åŠ¨è®¾å¤‡ä¸Šéƒ¨ç½²ã€‚è¿™å¯¹äºä¾èµ–VLMæä¾›è§†é¢‘ç†è§£å’Œæè¿°çš„ç›²äººå’Œä½è§†åŠ›ï¼ˆBLVï¼‰ç”¨æˆ·æ¥è¯´æ˜¯ä¸€ä¸ªæ˜¾è‘—çš„æŒ‘æˆ˜ï¼Œå› ä¸ºä»–ä»¬éœ€è¦èƒ½å¤Ÿéšæ—¶éšåœ°è®¿é—®è¿™äº›åŠŸèƒ½ã€‚å› æ­¤ï¼Œå¦‚ä½•è¯„ä¼°å’Œä¼˜åŒ–è½»é‡çº§VLMåœ¨BLVè¾…åŠ©åº”ç”¨ä¸­çš„æ€§èƒ½ï¼Œæ˜¯ä¸€ä¸ªäºŸå¾…è§£å†³çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è¯„ä¼°ä¸åŒå¤§å°çš„è½»é‡çº§VLMï¼ˆSmolVLM2ï¼‰åœ¨ä¸¤ä¸ªä¸“é—¨è®¾è®¡çš„BLVå¯è®¿é—®æ€§è¯„ä¼°æ¡†æ¶ä¸Šçš„è¡¨ç°ï¼Œæ¥ç ”ç©¶æ¨¡å‹å¤§å°å¯¹æè¿°è´¨é‡çš„å½±å“ã€‚åŒæ—¶ï¼Œæ¢ç´¢ä¸åŒçš„æç¤ºè®¾è®¡ç­–ç•¥å’Œé‡åŒ–æ–¹æ³•ï¼ˆFP32å’ŒINT8ï¼‰ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹åœ¨ç§»åŠ¨è®¾å¤‡ä¸Šçš„éƒ¨ç½²å’Œæ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥ç ”ç©¶çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼š1) é€‰æ‹©è½»é‡çº§VLMæ¨¡å‹SmolVLM2ï¼Œå¹¶ä½¿ç”¨ä¸åŒå‚æ•°é‡çš„å˜ä½“ï¼ˆ500Må’Œ2.2Bï¼‰ã€‚2) æ„å»ºä¸¤ä¸ªæ–°çš„è¯„ä¼°æ¡†æ¶ï¼šå¤šä¸Šä¸‹æ–‡BLVæ¡†æ¶å’Œå¯¼èˆªè¾…åŠ©æ¡†æ¶ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹åœ¨ç©ºé—´å®šä½ã€ç¤¾äº¤äº’åŠ¨ã€åŠ¨ä½œäº‹ä»¶ã€ç¯å¢ƒä¸Šä¸‹æ–‡å’Œç§»åŠ¨å…³é”®ä¿¡æ¯ç­‰æ–¹é¢çš„ç†è§£èƒ½åŠ›ã€‚3) è®¾è®¡å››ç§ä¸åŒçš„æç¤ºç­–ç•¥ï¼Œä»¥æ¢ç´¢æœ€ä½³çš„æç¤ºæ–¹å¼ã€‚4) åœ¨æ™ºèƒ½æ‰‹æœºä¸Šéƒ¨ç½²æ¨¡å‹ï¼Œå¹¶è¯„ä¼°FP32å’ŒINT8ç²¾åº¦ä¸‹çš„æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸¤ä¸ªä¸“é—¨é’ˆå¯¹BLVå¯è®¿é—®æ€§è¯„ä¼°çš„æ¡†æ¶ï¼šå¤šä¸Šä¸‹æ–‡BLVæ¡†æ¶å’Œå¯¼èˆªè¾…åŠ©æ¡†æ¶ã€‚è¿™äº›æ¡†æ¶èƒ½å¤Ÿæ›´å…¨é¢åœ°è¯„ä¼°VLMåœ¨ç†è§£å’Œæè¿°è§†é¢‘å†…å®¹ï¼Œå¹¶ä¸ºBLVç”¨æˆ·æä¾›æœ‰ä»·å€¼ä¿¡æ¯æ–¹é¢çš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜ç³»ç»Ÿåœ°è¯„ä¼°äº†ä¸åŒæç¤ºç­–ç•¥å’Œé‡åŒ–æ–¹æ³•å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ï¼Œä¸ºè½»é‡çº§VLMåœ¨ç§»åŠ¨è®¾å¤‡ä¸Šçš„éƒ¨ç½²æä¾›äº†æŒ‡å¯¼ã€‚

**å…³é”®è®¾è®¡**ï¼šå¤šä¸Šä¸‹æ–‡BLVæ¡†æ¶è¯„ä¼°å››ä¸ªå…³é”®ä¸Šä¸‹æ–‡ï¼šç©ºé—´å®šä½ã€ç¤¾äº¤äº’åŠ¨ã€åŠ¨ä½œäº‹ä»¶å’Œç¯å¢ƒã€‚å¯¼èˆªè¾…åŠ©æ¡†æ¶åˆ™ä¾§é‡äºè¯„ä¼°æ¨¡å‹æå–ç§»åŠ¨å…³é”®ä¿¡æ¯çš„èƒ½åŠ›ï¼Œä¾‹å¦‚éšœç¢ç‰©ã€æ–¹å‘æŒ‡ç¤ºç­‰ã€‚æç¤ºç­–ç•¥åŒ…æ‹¬ä¸åŒçš„æŒ‡ä»¤å’Œä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»¥å¼•å¯¼æ¨¡å‹ç”Ÿæˆæ›´å‡†ç¡®å’Œæœ‰ç”¨çš„æè¿°ã€‚é‡åŒ–æ–¹æ³•åŒ…æ‹¬FP32å’ŒINT8ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹åœ¨ä¸åŒç²¾åº¦ä¸‹çš„æ€§èƒ½å’Œèµ„æºæ¶ˆè€—ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒSmolVLM2æ¨¡å‹åœ¨ä¸¤ä¸ªè¯„ä¼°æ¡†æ¶ä¸Šå‡è¡¨ç°å‡ºè‰¯å¥½çš„æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨ç†è§£ç©ºé—´å®šä½å’ŒåŠ¨ä½œäº‹ä»¶æ–¹é¢ã€‚é€šè¿‡å¯¹æ¯”ä¸åŒæç¤ºç­–ç•¥ï¼Œå‘ç°ç‰¹å®šçš„æç¤ºæ–¹å¼èƒ½å¤Ÿæ˜¾è‘—æé«˜æ¨¡å‹çš„æè¿°è´¨é‡ã€‚æ­¤å¤–ï¼ŒINT8é‡åŒ–åœ¨ä¿è¯æ¨¡å‹æ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½äº†æ¨¡å‹ä½“ç§¯å’Œè®¡ç®—éœ€æ±‚ï¼Œä½¿å…¶æ›´é€‚åˆåœ¨ç§»åŠ¨è®¾å¤‡ä¸Šéƒ¨ç½²ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¼€å‘é¢å‘è§†éšœäººå£«çš„æ™ºèƒ½è¾…åŠ©è®¾å¤‡å’Œåº”ç”¨ï¼Œä¾‹å¦‚æ™ºèƒ½çœ¼é•œã€æ‰‹æœºåº”ç”¨ç­‰ï¼Œå¸®åŠ©ä»–ä»¬æ›´å¥½åœ°ç†è§£å‘¨å›´ç¯å¢ƒï¼Œæé«˜ç”Ÿæ´»è´¨é‡å’Œå‡ºè¡Œå®‰å…¨ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶æå‡ºçš„è¯„ä¼°æ¡†æ¶ä¹Ÿå¯ç”¨äºè¯„ä¼°å…¶ä»–VLMæ¨¡å‹åœ¨å¯è®¿é—®æ€§æ–¹é¢çš„è¡¨ç°ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Vision-Language Models (VLMs) excel at understanding and generating video descriptions but their high memory, computation, and deployment demands hinder practical use particularly for blind and low-vision (BLV) users who depend on detailed, context-aware descriptions. To study the effect of model size on accessibility-focused description quality, we evaluate SmolVLM2 variants with 500M and 2.2B parameters across two diverse datasets: AVCaps (outdoor), and Charades (indoor). In this work, we introduce two novel evaluation frameworks specifically designed for BLV accessibility assessment: the Multi-Context BLV Framework evaluating spatial orientation, social interaction, action events, and ambience contexts; and the Navigational Assistance Framework focusing on mobility-critical information. Additionally, we conduct a systematic evaluation of four different prompt design strategies and deploy both models on a smartphone, evaluating FP32 and INT8 precision variants to assess real-world performance constraints on resource-limited mobile devices.

