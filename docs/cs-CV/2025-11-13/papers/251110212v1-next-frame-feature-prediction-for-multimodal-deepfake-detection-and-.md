---
layout: default
title: Next-Frame Feature Prediction for Multimodal Deepfake Detection and Temporal Localization
---

# Next-Frame Feature Prediction for Multimodal Deepfake Detection and Temporal Localization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.10212" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.10212v1</a>
  <a href="https://arxiv.org/pdf/2511.10212.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.10212v1" onclick="toggleFavorite(this, '2511.10212v1', 'Next-Frame Feature Prediction for Multimodal Deepfake Detection and Temporal Localization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ashutosh Anshul, Shreyas Gopal, Deepu Rajan, Eng Siong Chng

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-13

**å¤‡æ³¨**: Under Review, Multimodal Deepfake detection

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºä¸‹ä¸€å¸§ç‰¹å¾é¢„æµ‹çš„å¤šæ¨¡æ€Deepfakeæ£€æµ‹ä¸æ—¶åºå®šä½æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `Deepfakeæ£€æµ‹` `å¤šæ¨¡æ€å­¦ä¹ ` `ä¸‹ä¸€å¸§é¢„æµ‹` `æ—¶åºå®šä½` `æ³¨æ„åŠ›æœºåˆ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰Deepfakeæ£€æµ‹æ–¹æ³•æ³›åŒ–æ€§ä¸è¶³ï¼Œä¸”ä¾§é‡éŸ³è§†é¢‘ä¸ä¸€è‡´ï¼Œå¿½ç•¥äº†æ¨¡æ€å†…éƒ¨çš„ä¼ªé€ ã€‚
2. è®ºæ–‡æå‡ºå•é˜¶æ®µè®­ç»ƒæ¡†æ¶ï¼Œèåˆå•æ¨¡æ€å’Œè·¨æ¨¡æ€çš„ä¸‹ä¸€å¸§é¢„æµ‹ï¼Œå¢å¼ºæ¨¡å‹æ³›åŒ–èƒ½åŠ›ã€‚
3. å¼•å…¥çª—å£æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ•æ‰é¢„æµ‹å¸§ä¸å®é™…å¸§å·®å¼‚ï¼Œå®ç°å±€éƒ¨ä¼ªé€ ç—•è¿¹æ£€æµ‹ä¸æ—¶åºå®šä½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°æœ‰çš„å¤šæ¨¡æ€Deepfakeæ£€æµ‹æ–¹æ³•ä¸ºäº†æå‡æ³›åŒ–èƒ½åŠ›ï¼Œé€šå¸¸é‡‡ç”¨é¢„è®­ç»ƒç­–ç•¥ï¼Œå¹¶ä¸”ä¸»è¦å…³æ³¨éŸ³è§†é¢‘ä¸ä¸€è‡´æ€§ï¼Œå®¹æ˜“å¿½ç•¥æ¨¡æ€å†…éƒ¨çš„ä¼ªé€ ç—•è¿¹ï¼Œå¯¼è‡´åœ¨éŸ³è§†é¢‘å¯¹é½çš„ç¯¡æ”¹æ ·æœ¬ä¸Šå¤±æ•ˆã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§å•é˜¶æ®µè®­ç»ƒæ¡†æ¶ï¼Œé€šè¿‡æ•´åˆå•æ¨¡æ€å’Œè·¨æ¨¡æ€çš„ä¸‹ä¸€å¸§é¢„æµ‹æ¥å¢å¼ºæ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œå¼•å…¥çª—å£çº§åˆ«çš„æ³¨æ„åŠ›æœºåˆ¶æ¥æ•æ‰é¢„æµ‹å¸§å’Œå®é™…å¸§ä¹‹é—´çš„å·®å¼‚ï¼Œä»è€Œæ£€æµ‹æ¯ä¸ªå¸§å‘¨å›´çš„å±€éƒ¨ä¼ªé€ ç—•è¿¹ã€‚è¿™å¯¹äºå‡†ç¡®åˆ†ç±»å®Œå…¨ç¯¡æ”¹çš„è§†é¢‘å’Œæœ‰æ•ˆå®šä½éƒ¨åˆ†ç¯¡æ”¹æ ·æœ¬ä¸­çš„Deepfakeç‰‡æ®µè‡³å…³é‡è¦ã€‚åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ¨¡å‹å…·æœ‰å¾ˆå¼ºçš„æ³›åŒ–èƒ½åŠ›å’Œç²¾ç¡®çš„æ—¶åºå®šä½èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰Deepfakeæ£€æµ‹æ–¹æ³•åœ¨æ³›åŒ–æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨é¢å¯¹æœªè§è¿‡çš„ç¯¡æ”¹ç±»å‹å’Œæ•°æ®é›†æ—¶ã€‚æ­¤å¤–ï¼Œè®¸å¤šæ–¹æ³•ä¸»è¦å…³æ³¨éŸ³è§†é¢‘ä¹‹é—´çš„ä¸ä¸€è‡´æ€§ï¼Œè€Œå¿½ç•¥äº†å•ä¸ªæ¨¡æ€å†…éƒ¨çš„ä¼ªé€ ç—•è¿¹ã€‚è¿™å¯¼è‡´è¿™äº›æ–¹æ³•åœ¨å¤„ç†éŸ³è§†é¢‘å¯¹é½çš„Deepfakeè§†é¢‘æ—¶è¡¨ç°ä¸ä½³ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§èƒ½å¤Ÿæ›´å¥½åœ°æ³›åŒ–å¹¶èƒ½æ£€æµ‹æ¨¡æ€å†…éƒ¨ä¼ªé€ ç—•è¿¹çš„Deepfakeæ£€æµ‹æ–¹æ³•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨ä¸‹ä¸€å¸§ç‰¹å¾é¢„æµ‹ä½œä¸ºä¸€ç§è‡ªç›‘ç£å­¦ä¹ çš„æ–¹å¼ï¼Œæ¥å­¦ä¹ çœŸå®è§†é¢‘çš„å†…åœ¨è¡¨ç¤ºã€‚é€šè¿‡é¢„æµ‹ä¸‹ä¸€å¸§çš„ç‰¹å¾ï¼Œæ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£è§†é¢‘çš„æ—¶åºåŠ¨æ€å’Œæ¨¡æ€é—´çš„å…³ç³»ã€‚åŒæ—¶ï¼Œé€šè¿‡æ¯”è¾ƒé¢„æµ‹çš„ç‰¹å¾å’Œå®é™…çš„ç‰¹å¾ï¼Œå¯ä»¥æ£€æµ‹å‡ºè§†é¢‘ä¸­å­˜åœ¨çš„å¼‚å¸¸ï¼Œä»è€Œåˆ¤æ–­è§†é¢‘æ˜¯å¦è¢«ç¯¡æ”¹ã€‚è¿™ç§æ–¹æ³•ä¸ä»…å¯ä»¥æ£€æµ‹éŸ³è§†é¢‘ä¸ä¸€è‡´çš„æƒ…å†µï¼Œè¿˜å¯ä»¥æ£€æµ‹æ¨¡æ€å†…éƒ¨çš„ä¼ªé€ ç—•è¿¹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¨¡å‹é‡‡ç”¨å•é˜¶æ®µè®­ç»ƒæ¡†æ¶ï¼ŒåŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) ç‰¹å¾æå–æ¨¡å—ï¼šåˆ†åˆ«æå–éŸ³è§†é¢‘ç‰¹å¾ã€‚2) ä¸‹ä¸€å¸§é¢„æµ‹æ¨¡å—ï¼šåŸºäºå½“å‰å¸§çš„ç‰¹å¾é¢„æµ‹ä¸‹ä¸€å¸§çš„ç‰¹å¾ï¼ŒåŒ…æ‹¬å•æ¨¡æ€å’Œè·¨æ¨¡æ€çš„é¢„æµ‹ã€‚3) æ³¨æ„åŠ›æ¨¡å—ï¼šå¼•å…¥çª—å£çº§åˆ«çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œè®¡ç®—é¢„æµ‹å¸§å’Œå®é™…å¸§ä¹‹é—´çš„å·®å¼‚ï¼Œå¹¶æå–å…³é”®çš„ä¼ªé€ åŒºåŸŸã€‚4) åˆ†ç±»æ¨¡å—ï¼šåŸºäºæå–çš„ç‰¹å¾å’Œæ³¨æ„åŠ›æƒé‡ï¼Œåˆ¤æ–­è§†é¢‘æ˜¯å¦ä¸ºDeepfakeï¼Œå¹¶è¿›è¡Œæ—¶åºå®šä½ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†åŸºäºä¸‹ä¸€å¸§ç‰¹å¾é¢„æµ‹çš„Deepfakeæ£€æµ‹æ–¹æ³•ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚2) å¼•å…¥äº†çª—å£çº§åˆ«çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œèƒ½å¤Ÿç²¾ç¡®å®šä½Deepfakeè§†é¢‘ä¸­çš„ç¯¡æ”¹ç‰‡æ®µã€‚3) é‡‡ç”¨å•é˜¶æ®µè®­ç»ƒæ¡†æ¶ï¼Œé¿å…äº†é¢„è®­ç»ƒå¸¦æ¥çš„é¢å¤–å¼€é”€ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ä¸‹ä¸€å¸§é¢„æµ‹æ¨¡å—ä¸­ï¼Œé‡‡ç”¨äº†LSTMç½‘ç»œæ¥å»ºæ¨¡æ—¶åºå…³ç³»ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬é¢„æµ‹æŸå¤±å’Œåˆ†ç±»æŸå¤±ï¼Œå…¶ä¸­é¢„æµ‹æŸå¤±ç”¨äºçº¦æŸä¸‹ä¸€å¸§ç‰¹å¾é¢„æµ‹çš„å‡†ç¡®æ€§ï¼Œåˆ†ç±»æŸå¤±ç”¨äºçº¦æŸDeepfakeåˆ†ç±»çš„å‡†ç¡®æ€§ã€‚çª—å£å¤§å°å’Œæ³¨æ„åŠ›æƒé‡æ˜¯å½±å“æ¨¡å‹æ€§èƒ½çš„å…³é”®å‚æ•°ï¼Œéœ€è¦æ ¹æ®å…·ä½“æ•°æ®é›†è¿›è¡Œè°ƒæ•´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥æ¨¡å‹åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼ŒåŒ…æ‹¬FaceForensics++ã€DFDCç­‰ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨æ³›åŒ–èƒ½åŠ›å’Œæ—¶åºå®šä½ç²¾åº¦æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨FaceForensics++æ•°æ®é›†ä¸Šï¼Œè¯¥æ¨¡å‹çš„åˆ†ç±»å‡†ç¡®ç‡æé«˜äº†5%ä»¥ä¸Šï¼Œæ—¶åºå®šä½çš„IoUæé«˜äº†10%ä»¥ä¸Šã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹å…·æœ‰å¾ˆå¼ºçš„å®ç”¨ä»·å€¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºç¤¾äº¤åª’ä½“å¹³å°ã€æ–°é—»åª’ä½“æœºæ„ç­‰ï¼Œç”¨äºæ£€æµ‹å’Œè¯†åˆ«Deepfakeè§†é¢‘ï¼Œé˜²æ­¢è™šå‡ä¿¡æ¯çš„ä¼ æ’­å’Œæ¶æ„æ”»å‡»ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥åº”ç”¨äºå®‰å…¨ç›‘æ§é¢†åŸŸï¼Œç”¨äºæ£€æµ‹è§†é¢‘ä¸­çš„å¼‚å¸¸è¡Œä¸ºï¼Œæé«˜å®‰å…¨é˜²èŒƒèƒ½åŠ›ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›ä¸åŒºå—é“¾ç­‰æŠ€æœ¯ç»“åˆï¼Œå®ç°Deepfakeè§†é¢‘çš„å¯ä¿¡æº¯æºã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent multimodal deepfake detection methods designed for generalization conjecture that single-stage supervised training struggles to generalize across unseen manipulations and datasets. However, such approaches that target generalization require pretraining over real samples. Additionally, these methods primarily focus on detecting audio-visual inconsistencies and may overlook intra-modal artifacts causing them to fail against manipulations that preserve audio-visual alignment. To address these limitations, we propose a single-stage training framework that enhances generalization by incorporating next-frame prediction for both uni-modal and cross-modal features. Additionally, we introduce a window-level attention mechanism to capture discrepancies between predicted and actual frames, enabling the model to detect local artifacts around every frame, which is crucial for accurately classifying fully manipulated videos and effectively localizing deepfake segments in partially spoofed samples. Our model, evaluated on multiple benchmark datasets, demonstrates strong generalization and precise temporal localization.

