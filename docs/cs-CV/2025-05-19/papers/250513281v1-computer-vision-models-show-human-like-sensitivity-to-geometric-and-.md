---
layout: default
title: Computer Vision Models Show Human-Like Sensitivity to Geometric and Topological Concepts
---

# Computer Vision Models Show Human-Like Sensitivity to Geometric and Topological Concepts

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.13281" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.13281v1</a>
  <a href="https://arxiv.org/pdf/2505.13281.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.13281v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.13281v1', 'Computer Vision Models Show Human-Like Sensitivity to Geometric and Topological Concepts')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zekun Wang, Sashank Varma

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-19

**å¤‡æ³¨**: 10 pages, 4 figures, CosSci 2025

**æœŸåˆŠ**: Cognitive Science Society 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ©ç”¨è®¡ç®—æœºè§†è§‰æ¨¡å‹æ¢è®¨äººç±»å¯¹å‡ ä½•ä¸æ‹“æ‰‘æ¦‚å¿µçš„æ•æ„Ÿæ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è®¡ç®—æœºè§†è§‰` `å‡ ä½•æ¦‚å¿µ` `æ‹“æ‰‘æ¦‚å¿µ` `å˜æ¢å™¨æ¨¡å‹` `å¤šæ¨¡æ€å­¦ä¹ ` `è®¤çŸ¥ç§‘å­¦` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è®¤çŸ¥ç§‘å­¦ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨å‡ ä½•å’Œæ‹“æ‰‘æ¦‚å¿µçš„å…ˆå¤©æ€§ï¼Œè€Œç¼ºä¹å¯¹åå¤©å­¦ä¹ çš„æ¢è®¨ã€‚
2. æœ¬æ–‡é€šè¿‡è®¡ç®—æœºè§†è§‰æ¨¡å‹ï¼Œæ¢è®¨GTæ¦‚å¿µæ˜¯å¦å¯ä»¥é€šè¿‡ä¸ç¯å¢ƒçš„äº’åŠ¨è€Œè·å¾—ï¼Œæå‡ºäº†æ–°çš„ç ”ç©¶è§†è§’ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŸºäºå˜æ¢å™¨çš„æ¨¡å‹åœ¨GTæ¦‚å¿µçš„è¯†åˆ«ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¿‡äº†å¹¼å„¿çš„è¡¨ç°ï¼Œå¹¶ä¸å„¿ç«¥çš„éš¾æ˜“ç¨‹åº¦ä¸€è‡´ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€æœºå™¨å­¦ä¹ æ¨¡å‹çš„å¿«é€Ÿå‘å±•ï¼Œè®¤çŸ¥ç§‘å­¦å®¶è¶Šæ¥è¶Šå…³æ³¨è¿™äº›æ¨¡å‹ä¸äººç±»æ€ç»´çš„å¯¹é½ç¨‹åº¦ã€‚æœ¬æ–‡ç ”ç©¶äº†è®¡ç®—æœºè§†è§‰æ¨¡å‹åœ¨å‡ ä½•å’Œæ‹“æ‰‘ï¼ˆGTï¼‰æ¦‚å¿µä¸Šçš„è¡¨ç°ï¼Œæå‡ºè¿™äº›æ¦‚å¿µå¯èƒ½é€šè¿‡æ—¥å¸¸ç¯å¢ƒäº¤äº’â€œå…è´¹â€å­¦ä¹ ã€‚é€šè¿‡å¯¹å·ç§¯ç¥ç»ç½‘ç»œã€åŸºäºå˜æ¢å™¨çš„æ¨¡å‹å’Œè§†è§‰-è¯­è¨€æ¨¡å‹çš„æ¯”è¾ƒï¼Œå‘ç°åŸºäºå˜æ¢å™¨çš„æ¨¡å‹åœ¨å‡†ç¡®æ€§ä¸Šè¶…è¶Šäº†å¹¼å„¿ï¼Œå¹¶ä¸å„¿ç«¥çš„è¡¨ç°é«˜åº¦ä¸€è‡´ã€‚ç›¸å¯¹è€Œè¨€ï¼Œè§†è§‰-è¯­è¨€æ¨¡å‹çš„è¡¨ç°ä¸ä½³ï¼Œè¡¨æ˜ç®€å•çš„å¤šæ¨¡æ€èåˆå¯èƒ½ä¼šå‰Šå¼±å¯¹æŠ½è±¡å‡ ä½•çš„æ•æ„Ÿæ€§ã€‚è¿™äº›å‘ç°æ”¯æŒä½¿ç”¨è®¡ç®—æœºè§†è§‰æ¨¡å‹æ¥è¯„ä¼°å­¦ä¹ ç†è®ºåœ¨è§£é‡Šäººç±»GTæ¦‚å¿µæ•æ„Ÿæ€§æ–¹é¢çš„å……åˆ†æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨æ¢è®¨è®¡ç®—æœºè§†è§‰æ¨¡å‹åœ¨å‡ ä½•å’Œæ‹“æ‰‘æ¦‚å¿µä¸Šçš„æ•æ„Ÿæ€§ï¼Œç°æœ‰ç ”ç©¶ä¸»è¦è®¤ä¸ºè¿™äº›æ¦‚å¿µæ˜¯å…ˆå¤©çš„ï¼Œè€Œç¼ºä¹å¯¹åå¤©å­¦ä¹ çš„å®è¯æ”¯æŒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¯¹æ¯”ä¸åŒç±»å‹çš„è®¡ç®—æœºè§†è§‰æ¨¡å‹ï¼ŒéªŒè¯GTæ¦‚å¿µæ˜¯å¦å¯ä»¥é€šè¿‡ç¯å¢ƒäº¤äº’å­¦ä¹ ï¼Œæå‡ºäº†æ–°çš„è§†è§’æ¥ç†è§£äººç±»çš„è®¤çŸ¥èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶ä½¿ç”¨ä¸‰ç±»æ¨¡å‹ï¼šå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ã€åŸºäºå˜æ¢å™¨çš„æ¨¡å‹å’Œè§†è§‰-è¯­è¨€æ¨¡å‹ï¼Œè¿›è¡Œâ€œå¥‡å¼‚ç‰©ä½“â€ä»»åŠ¡ï¼Œè¯„ä¼°å…¶åœ¨43ä¸ªGTæ¦‚å¿µä¸Šçš„è¡¨ç°ã€‚

**å…³é”®åˆ›æ–°**ï¼šåŸºäºå˜æ¢å™¨çš„æ¨¡å‹åœ¨å‡†ç¡®æ€§ä¸Šè¶…è¶Šäº†å¹¼å„¿ï¼Œä¸”ä¸å„¿ç«¥çš„è¡¨ç°é«˜åº¦ä¸€è‡´ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨ç†è§£GTæ¦‚å¿µä¸Šçš„æ½œåŠ›ã€‚ç›¸è¾ƒä¹‹ä¸‹ï¼Œè§†è§‰-è¯­è¨€æ¨¡å‹çš„è¡¨ç°è¾ƒå·®ï¼Œæ­ç¤ºäº†å¤šæ¨¡æ€èåˆçš„æ½œåœ¨é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡å‹è®­ç»ƒä½¿ç”¨äº†å¤§è§„æ¨¡å›¾åƒæ•°æ®é›†ï¼Œä»»åŠ¡è®¾è®¡ä¸ºâ€œå¥‡å¼‚ç‰©ä½“â€é€‰æ‹©ï¼Œè¯„ä¼°æ¨¡å‹åœ¨ä¸åŒGTæ¦‚å¿µä¸Šçš„è¡¨ç°ï¼Œå…³é”®å‚æ•°å’ŒæŸå¤±å‡½æ•°çš„é€‰æ‹©æ—¨åœ¨ä¼˜åŒ–æ¨¡å‹çš„å­¦ä¹ èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŸºäºå˜æ¢å™¨çš„æ¨¡å‹åœ¨GTæ¦‚å¿µçš„è¯†åˆ«ä¸Šè¾¾åˆ°äº†æœ€é«˜å‡†ç¡®ç‡ï¼Œè¶…è¿‡äº†å¹¼å„¿çš„è¡¨ç°ï¼Œå¹¶ä¸”åœ¨éš¾æ˜“ç¨‹åº¦ä¸Šä¸å„¿ç«¥çš„è¡¨ç°é«˜åº¦ä¸€è‡´ã€‚è¿™ä¸€å‘ç°è¡¨æ˜ï¼Œè®¡ç®—æœºè§†è§‰æ¨¡å‹åœ¨ç†è§£å¤æ‚æ¦‚å¿µæ–¹é¢å…·æœ‰æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨å‡ ä½•å’Œæ‹“æ‰‘é¢†åŸŸã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²æŠ€æœ¯ã€äººå·¥æ™ºèƒ½è¾…åŠ©å­¦ä¹ ä»¥åŠè®¤çŸ¥ç§‘å­¦ç ”ç©¶ã€‚é€šè¿‡ç†è§£è®¡ç®—æœºè§†è§‰æ¨¡å‹å¦‚ä½•å­¦ä¹ å‡ ä½•å’Œæ‹“æ‰‘æ¦‚å¿µï¼Œå¯ä»¥ä¸ºå¼€å‘æ›´æ™ºèƒ½çš„æ•™è‚²å·¥å…·æä¾›ç†è®ºæ”¯æŒï¼Œä¿ƒè¿›äººæœºäº¤äº’çš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> With the rapid improvement of machine learning (ML) models, cognitive scientists are increasingly asking about their alignment with how humans think. Here, we ask this question for computer vision models and human sensitivity to geometric and topological (GT) concepts. Under the core knowledge account, these concepts are innate and supported by dedicated neural circuitry. In this work, we investigate an alternative explanation, that GT concepts are learned ``for free'' through everyday interaction with the environment. We do so using computer visions models, which are trained on large image datasets. We build on prior studies to investigate the overall performance and human alignment of three classes of models -- convolutional neural networks (CNNs), transformer-based models, and vision-language models -- on an odd-one-out task testing 43 GT concepts spanning seven classes. Transformer-based models achieve the highest overall accuracy, surpassing that of young children. They also show strong alignment with children's performance, finding the same classes of concepts easy vs. difficult. By contrast, vision-language models underperform their vision-only counterparts and deviate further from human profiles, indicating that naÃ¯ve multimodality might compromise abstract geometric sensitivity. These findings support the use of computer vision models to evaluate the sufficiency of the learning account for explaining human sensitivity to GT concepts, while also suggesting that integrating linguistic and visual representations might have unpredicted deleterious consequences.

