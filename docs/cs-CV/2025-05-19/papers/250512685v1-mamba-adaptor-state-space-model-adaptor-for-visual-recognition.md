---
layout: default
title: "Mamba-Adaptor: State Space Model Adaptor for Visual Recognition"
---

# Mamba-Adaptor: State Space Model Adaptor for Visual Recognition

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.12685" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.12685v1</a>
  <a href="https://arxiv.org/pdf/2505.12685.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.12685v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.12685v1', 'Mamba-Adaptor: State Space Model Adaptor for Visual Recognition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Fei Xie, Jiahao Nie, Yujin Tang, Wenkang Zhang, Hongshen Zhao

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-19

**å¤‡æ³¨**: CVPR paper

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMamba-Adaptorä»¥è§£å†³è§†è§‰è¯†åˆ«ä¸­çš„é•¿ç¨‹é—å¿˜å’Œç©ºé—´å»ºæ¨¡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `çŠ¶æ€ç©ºé—´æ¨¡å‹` `è§†è§‰è¯†åˆ«` `é•¿ç¨‹é—å¿˜` `ç©ºé—´å»ºæ¨¡` `å¤šå°ºåº¦å·ç§¯` `è¿ç§»å­¦ä¹ ` `å›¾åƒåˆ†ç±»`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„Mambaæ¨¡å‹åœ¨è§†è§‰ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ï¼Œä¸»è¦ç”±äºå› æœè®¡ç®—æ— æ³•è·å–å…¨å±€ä¸Šä¸‹æ–‡å’Œé•¿ç¨‹é—å¿˜é—®é¢˜ã€‚
2. æœ¬æ–‡æå‡ºäº†Mamba-Adaptorï¼Œåˆ©ç”¨Adaptor-Tå’ŒAdaptor-Sæ¨¡å—æ¥å¢å¼ºæ¨¡å‹çš„è®°å¿†èƒ½åŠ›å’Œç©ºé—´å»ºæ¨¡èƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒMamba-Adaptoråœ¨å¤šä¸ªè§†è§‰ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶åœ¨ImageNetå’ŒCOCOåŸºå‡†ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼ŒçŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMï¼‰ï¼Œå°¤å…¶æ˜¯Mambaï¼Œåœ¨è§†è§‰å»ºæ¨¡æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨è§†è§‰ä»»åŠ¡ä¸­çš„åº”ç”¨å—åˆ°ä¸‰ä¸ªä¸»è¦é™åˆ¶çš„å½±å“ï¼š1ï¼‰å› æœè®¡ç®—æ— æ³•è®¿é—®å…¨å±€ä¸Šä¸‹æ–‡ï¼›2ï¼‰åœ¨è®¡ç®—å½“å‰éšè—çŠ¶æ€æ—¶å­˜åœ¨é•¿ç¨‹é—å¿˜ï¼›3ï¼‰ç”±äºè¾“å…¥çš„åºåˆ—è½¬æ¢ï¼Œç©ºé—´ç»“æ„å»ºæ¨¡è¾ƒå¼±ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§ç®€å•è€Œå¼ºå¤§çš„è§†è§‰ä»»åŠ¡é€‚é…å™¨Mamba-Adaptorï¼ŒåŒ…å«ä¸¤ä¸ªåŠŸèƒ½æ¨¡å—ï¼šAdaptor-Tå’ŒAdaptor-Sã€‚é€šè¿‡è¿™ä¸¤ä¸ªæ¨¡å—ï¼ŒMamba-Adaptorèƒ½å¤Ÿå¢å¼ºä¸Šä¸‹æ–‡å»ºæ¨¡ï¼Œæ˜¾è‘—æé«˜åœ¨ImageNetå’ŒCOCOåŸºå‡†ä¸Šçš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³Mambaæ¨¡å‹åœ¨è§†è§‰ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³çš„é—®é¢˜ï¼Œä¸»è¦ç—›ç‚¹åŒ…æ‹¬å› æœè®¡ç®—æ— æ³•è®¿é—®å…¨å±€ä¸Šä¸‹æ–‡ã€é•¿ç¨‹é—å¿˜ä»¥åŠç©ºé—´ç»“æ„å»ºæ¨¡ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºMamba-Adaptorï¼Œé€šè¿‡ä¸¤ä¸ªæ¨¡å—ï¼ˆAdaptor-Tå’ŒAdaptor-Sï¼‰æ¥å¢å¼ºæ¨¡å‹çš„è®°å¿†èƒ½åŠ›å’Œç©ºé—´å»ºæ¨¡èƒ½åŠ›ï¼Œä»¥å…‹æœç°æœ‰æ¨¡å‹çš„å±€é™æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMamba-Adaptorç”±ä¸¤ä¸ªä¸»è¦æ¨¡å—ç»„æˆï¼šAdaptor-Tç”¨äºé€‰æ‹©å¯å­¦ä¹ çš„ä½ç½®ä½œä¸ºè®°å¿†å¢å¼ºï¼ŒAdaptor-Såˆ©ç”¨å¤šå°ºåº¦è†¨èƒ€å·ç§¯æ ¸æ¥æå‡ç©ºé—´å»ºæ¨¡èƒ½åŠ›ã€‚æ•´ä½“æµç¨‹åŒ…æ‹¬è¾“å…¥å¤„ç†ã€ç‰¹å¾æå–å’Œè¾“å‡ºå¢å¼ºã€‚

**å…³é”®åˆ›æ–°**ï¼šMamba-Adaptorçš„åˆ›æ–°åœ¨äºå¼•å…¥äº†è½»é‡çº§çš„é¢„æµ‹æ¨¡å—å’Œå¤šå°ºåº¦å·ç§¯ç»“æ„ï¼Œæ˜¾è‘—æé«˜äº†ä¸Šä¸‹æ–‡å»ºæ¨¡èƒ½åŠ›ï¼Œä¸ä¼ ç»Ÿçš„å› æœè®¡ç®—æ–¹æ³•å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒAdaptor-Tæ¨¡å—é€šè¿‡é€‰æ‹©ç‰¹å®šä½ç½®æ¥ç¼“è§£é•¿ç¨‹é—å¿˜ï¼Œè€ŒAdaptor-Sæ¨¡å—åˆ™é€šè¿‡å¤šå°ºåº¦å·ç§¯æ ¸å¢å¼ºç©ºé—´ç‰¹å¾è¾“å‡ºï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰å›¾åƒçš„ç»“æ„ä¿¡æ¯ã€‚å®éªŒä¸­ä½¿ç”¨äº†æ ‡å‡†çš„æŸå¤±å‡½æ•°å’Œä¼˜åŒ–ç­–ç•¥ï¼Œä»¥ç¡®ä¿æ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼ŒMamba-Adaptoråœ¨ImageNetå’ŒCOCOåŸºå‡†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ¨¡å‹ï¼Œæ€§èƒ½æå‡å¹…åº¦æ˜¾è‘—ï¼ŒéªŒè¯äº†å…¶åœ¨è§†è§‰ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Mamba-Adaptorçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªè§†è§‰ä»»åŠ¡ä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼ŒåŒ…æ‹¬å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹å’Œè¿ç§»å­¦ä¹ ç­‰é¢†åŸŸã€‚å…¶é«˜æ•ˆçš„æ¨¡å‹è®¾è®¡å’Œä¼˜è¶Šçš„æ€§èƒ½ä½¿å…¶åœ¨å®é™…åº”ç”¨ä¸­èƒ½å¤Ÿæ˜¾è‘—æå‡è§†è§‰ç³»ç»Ÿçš„è¯†åˆ«èƒ½åŠ›ï¼Œæ¨åŠ¨è®¡ç®—æœºè§†è§‰æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent State Space Models (SSM), especially Mamba, have demonstrated impressive performance in visual modeling and possess superior model efficiency. However, the application of Mamba to visual tasks suffers inferior performance due to three main constraints existing in the sequential model: 1) Casual computing is incapable of accessing global context; 2) Long-range forgetting when computing the current hidden states; 3) Weak spatial structural modeling due to the transformed sequential input. To address these issues, we investigate a simple yet powerful vision task Adaptor for Mamba models, which consists of two functional modules: Adaptor-T and Adaptor-S. When solving the hidden states for SSM, we apply a lightweight prediction module Adaptor-T to select a set of learnable locations as memory augmentations to ease long-range forgetting issues. Moreover, we leverage Adapator-S, composed of multi-scale dilated convolutional kernels, to enhance the spatial modeling and introduce the image inductive bias into the feature output. Both modules can enlarge the context modeling in casual computing, as the output is enhanced by the inaccessible features. We explore three usages of Mamba-Adaptor: A general visual backbone for various vision tasks; A booster module to raise the performance of pretrained backbones; A highly efficient fine-tuning module that adapts the base model for transfer learning tasks. Extensive experiments verify the effectiveness of Mamba-Adaptor in three settings. Notably, our Mamba-Adaptor achieves state-of the-art performance on the ImageNet and COCO benchmarks.

