---
layout: default
title: Event-Driven Dynamic Scene Depth Completion
---

# Event-Driven Dynamic Scene Depth Completion

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.13279" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.13279v2</a>
  <a href="https://arxiv.org/pdf/2505.13279.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.13279v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.13279v2', 'Event-Driven Dynamic Scene Depth Completion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhiqiang Yan, Jianhao Jiao, Zhengxue Wang, Gim Hee Lee

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-19 (æ›´æ–°: 2025-05-20)

**å¤‡æ³¨**: 9 pages

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEventDCä»¥è§£å†³åŠ¨æ€åœºæ™¯æ·±åº¦è¡¥å…¨é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `æ·±åº¦è¡¥å…¨` `åŠ¨æ€åœºæ™¯` `äº‹ä»¶ç›¸æœº` `å·ç§¯ç¥ç»ç½‘ç»œ` `è¿åŠ¨æ„ŸçŸ¥` `æ·±åº¦å­¦ä¹ ` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. åŠ¨æ€åœºæ™¯ä¸­çš„æ·±åº¦è¡¥å…¨é¢ä¸´å¿«é€Ÿè¿åŠ¨å¯¼è‡´çš„è¾“å…¥æ¨¡æ€è´¨é‡ä¸‹é™ï¼Œä¼ ç»Ÿæ–¹æ³•éš¾ä»¥æœ‰æ•ˆå¤„ç†ã€‚
2. æå‡ºEventDCæ¡†æ¶ï¼Œé€šè¿‡äº‹ä»¶è°ƒåˆ¶å¯¹é½å’Œå±€éƒ¨æ·±åº¦è¿‡æ»¤ï¼Œåˆ©ç”¨äº‹ä»¶ç›¸æœºçš„é«˜æ—¶é—´åˆ†è¾¨ç‡è¿›è¡Œæ·±åº¦è¡¥å…¨ã€‚
3. åœ¨æ–°å»ºç«‹çš„åŸºå‡†æµ‹è¯•ä¸Šï¼ŒEventDCå±•ç¤ºäº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¯æ˜äº†å…¶åœ¨åŠ¨æ€åœºæ™¯ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŠ¨æ€åœºæ™¯ä¸­çš„æ·±åº¦è¡¥å…¨é¢ä¸´ç€å¿«é€Ÿè‡ªæˆ‘è¿åŠ¨å’Œç‰©ä½“è¿åŠ¨å¸¦æ¥çš„é‡å¤§æŒ‘æˆ˜ï¼Œè¿™ä¼šä¸¥é‡å½±å“RGBå›¾åƒå’ŒLiDARæµ‹é‡çš„è´¨é‡ã€‚ä¼ ç»Ÿçš„RGB-Dä¼ æ„Ÿå™¨åœ¨è¿™ç§æƒ…å†µä¸‹å¾€å¾€éš¾ä»¥ç²¾ç¡®å¯¹é½å¹¶æ•è·å¯é çš„æ·±åº¦ä¿¡æ¯ã€‚ä¸æ­¤ç›¸æ¯”ï¼Œäº‹ä»¶ç›¸æœºå› å…¶é«˜æ—¶é—´åˆ†è¾¨ç‡å’Œå¯¹åƒç´ çº§è¿åŠ¨çš„æ•æ„Ÿæ€§ï¼Œæä¾›äº†åœ¨åŠ¨æ€ç¯å¢ƒä¸­ç‰¹åˆ«æœ‰ç›Šçš„è¡¥å……çº¿ç´¢ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†EventDCï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªäº‹ä»¶é©±åŠ¨çš„æ·±åº¦è¡¥å…¨æ¡†æ¶ï¼ŒåŒ…å«äº‹ä»¶è°ƒåˆ¶å¯¹é½ï¼ˆEMAï¼‰å’Œå±€éƒ¨æ·±åº¦è¿‡æ»¤ï¼ˆLDFï¼‰ä¸¤ä¸ªå…³é”®ç»„ä»¶ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒEventDCåœ¨æ·±åº¦è¡¥å…¨ä»»åŠ¡ä¸­è¡¨ç°ä¼˜è¶Šã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³åŠ¨æ€åœºæ™¯ä¸­çš„æ·±åº¦è¡¥å…¨é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¿«é€Ÿè‡ªæˆ‘è¿åŠ¨å’Œç‰©ä½“è¿åŠ¨ä¸‹éš¾ä»¥ä¿æŒæ·±åº¦ä¿¡æ¯çš„å‡†ç¡®æ€§ï¼Œå¯¼è‡´RGB-Dä¼ æ„Ÿå™¨çš„å¯¹é½å’Œæ·±åº¦æ•è·æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºEventDCæ¡†æ¶ï¼Œåˆ©ç”¨äº‹ä»¶ç›¸æœºçš„é«˜æ—¶é—´åˆ†è¾¨ç‡å’Œå¯¹è¿åŠ¨çš„æ•æ„Ÿæ€§ï¼Œé€šè¿‡äº‹ä»¶è°ƒåˆ¶å¯¹é½å’Œå±€éƒ¨æ·±åº¦è¿‡æ»¤æ¥æ”¹å–„æ·±åº¦è¡¥å…¨çš„è´¨é‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEventDCæ¡†æ¶ä¸»è¦ç”±ä¸¤ä¸ªæ¨¡å—ç»„æˆï¼šäº‹ä»¶è°ƒåˆ¶å¯¹é½ï¼ˆEMAï¼‰å’Œå±€éƒ¨æ·±åº¦è¿‡æ»¤ï¼ˆLDFï¼‰ã€‚EMAåœ¨ç¼–ç å™¨ä¸­åˆ©ç”¨äº‹ä»¶ä¿¡æ¯è°ƒåˆ¶RGB-Dç‰¹å¾çš„é‡‡æ ·ä½ç½®ï¼Œè€ŒLDFåœ¨è§£ç å™¨ä¸­é€šè¿‡å­¦ä¹ è¿åŠ¨æ„ŸçŸ¥çš„æ©ç æ¥ä¼˜åŒ–ç§»åŠ¨ç‰©ä½“å‘¨å›´çš„æ·±åº¦ä¼°è®¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šEventDCçš„åˆ›æ–°åœ¨äºé¦–æ¬¡å°†äº‹ä»¶é©±åŠ¨çš„æœºåˆ¶åº”ç”¨äºæ·±åº¦è¡¥å…¨ä»»åŠ¡ï¼Œç‰¹åˆ«æ˜¯é€šè¿‡åŠ¨æ€è°ƒæ•´å·ç§¯æ“ä½œçš„åç§»é‡å’Œæƒé‡æ¥é€‚åº”è¿åŠ¨æ•æ„Ÿçš„äº‹ä»¶æµï¼Œä»è€Œå®ç°æ›´å¥½çš„å¯¹é½å’Œèåˆã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŸå¤±å‡½æ•°è®¾è®¡ä¸Šï¼ŒEventDCå¼•å…¥äº†ä¸¤ä¸ªæŸå¤±é¡¹ï¼Œä»¥è¿›ä¸€æ­¥ä¿ƒè¿›å…¨å±€å¯¹é½å’Œå±€éƒ¨æ·±åº¦æ¢å¤ï¼Œç¡®ä¿æ·±åº¦ä¼°è®¡çš„å‡†ç¡®æ€§å’Œç¨³å®šæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨æ–°å»ºç«‹çš„äº‹ä»¶åŸºç¡€æ·±åº¦è¡¥å…¨åŸºå‡†æµ‹è¯•ä¸Šï¼ŒEventDCå±•ç¤ºäº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå°¤å…¶æ˜¯åœ¨åŠ¨æ€åœºæ™¯ä¸­ï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•ï¼Œæ·±åº¦ä¼°è®¡çš„å‡†ç¡®æ€§æé«˜äº†XX%ï¼Œå¹¶åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå‡è¡¨ç°å‡ºä¼˜è¶Šçš„é²æ£’æ€§å’Œç²¾ç¡®æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªå’Œå¢å¼ºç°å®ç­‰åŠ¨æ€åœºæ™¯ä¸‹çš„æ·±åº¦æ„ŸçŸ¥ä»»åŠ¡ã€‚é€šè¿‡æé«˜åŠ¨æ€ç¯å¢ƒä¸­çš„æ·±åº¦è¡¥å…¨ç²¾åº¦ï¼ŒEventDCèƒ½å¤Ÿæ˜¾è‘—æå‡ç›¸å…³æŠ€æœ¯çš„å¯é æ€§å’Œå®ç”¨æ€§ï¼Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­çš„åº”ç”¨ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶æœ‰æœ›åœ¨æ›´å¤šå®æ—¶å¤„ç†å’Œé«˜ç²¾åº¦éœ€æ±‚çš„åœºæ™¯ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Depth completion in dynamic scenes poses significant challenges due to rapid ego-motion and object motion, which can severely degrade the quality of input modalities such as RGB images and LiDAR measurements. Conventional RGB-D sensors often struggle to align precisely and capture reliable depth under such conditions. In contrast, event cameras with their high temporal resolution and sensitivity to motion at the pixel level provide complementary cues that are %particularly beneficial in dynamic environments.To this end, we propose EventDC, the first event-driven depth completion framework. It consists of two key components: Event-Modulated Alignment (EMA) and Local Depth Filtering (LDF). Both modules adaptively learn the two fundamental components of convolution operations: offsets and weights conditioned on motion-sensitive event streams. In the encoder, EMA leverages events to modulate the sampling positions of RGB-D features to achieve pixel redistribution for improved alignment and fusion. In the decoder, LDF refines depth estimations around moving objects by learning motion-aware masks from events. Additionally, EventDC incorporates two loss terms to further benefit global alignment and enhance local depth recovery. Moreover, we establish the first benchmark for event-based depth completion comprising one real-world and two synthetic datasets to facilitate future research. Extensive experiments on this benchmark demonstrate the superiority of our EventDC.

