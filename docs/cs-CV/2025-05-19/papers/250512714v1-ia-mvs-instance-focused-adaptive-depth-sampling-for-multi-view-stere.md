---
layout: default
title: IA-MVS: Instance-Focused Adaptive Depth Sampling for Multi-View Stereo
---

# IA-MVS: Instance-Focused Adaptive Depth Sampling for Multi-View Stereo

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.12714" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.12714v1</a>
  <a href="https://arxiv.org/pdf/2505.12714.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.12714v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.12714v1', 'IA-MVS: Instance-Focused Adaptive Depth Sampling for Multi-View Stereo')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yinzhe Wang, Yiwen Xiao, Hu Wang, Yiping Xu, Yan Tian

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-19

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/KevinWang73106/IA-MVS)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºIA-MVSä»¥è§£å†³å¤šè§†è§’ç«‹ä½“è§†è§‰ä¸­çš„æ·±åº¦ä¼°è®¡ç²¾åº¦é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `å¤šè§†è§’ç«‹ä½“è§†è§‰` `æ·±åº¦ä¼°è®¡` `å®ä¾‹è‡ªé€‚åº”` `é²æ£’æ€§å¢å¼º` `ç½®ä¿¡åº¦ä¼°è®¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤šè§†è§’ç«‹ä½“è§†è§‰æ–¹æ³•æœªèƒ½å……åˆ†åˆ©ç”¨å•ä¸ªå®ä¾‹çš„æ·±åº¦è¦†ç›–èŒƒå›´ï¼Œå¯¼è‡´æ·±åº¦ä¼°è®¡ç²¾åº¦ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºIA-MVSï¼Œé€šè¿‡ç¼©å°æ·±åº¦å‡è®¾èŒƒå›´å¹¶å¯¹æ¯ä¸ªå®ä¾‹è¿›è¡Œç»†åŒ–ï¼Œæå‡æ·±åº¦ä¼°è®¡çš„ç²¾åº¦å’Œé²æ£’æ€§ã€‚
3. åœ¨DTUåŸºå‡†æµ‹è¯•ä¸­ï¼ŒIA-MVSå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå±•ç¤ºäº†å…¶åœ¨æ·±åº¦ä¼°è®¡é¢†åŸŸçš„æ˜¾è‘—ä¼˜åŠ¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šè§†è§’ç«‹ä½“è§†è§‰ï¼ˆMVSï¼‰æ¨¡å‹åœ¨é€æ­¥æ·±åº¦å‡è®¾æ”¶æ•›æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†åˆ©ç”¨å•ä¸ªå®ä¾‹çš„æ·±åº¦è¦†ç›–èŒƒå›´å°äºæ•´ä¸ªåœºæ™¯çš„æ½œåŠ›ï¼Œé™åˆ¶äº†æ·±åº¦ä¼°è®¡ç²¾åº¦çš„è¿›ä¸€æ­¥æå‡ã€‚æ­¤å¤–ï¼Œåˆå§‹é˜¶æ®µçš„ä¸å¯é¿å…åå·®åœ¨åç»­è¿‡ç¨‹ä¸­ä¼šç´¯ç§¯ã€‚æœ¬æ–‡æå‡ºäº†å®ä¾‹è‡ªé€‚åº”MVSï¼ˆIA-MVSï¼‰ï¼Œé€šè¿‡ç¼©å°æ·±åº¦å‡è®¾èŒƒå›´å¹¶å¯¹æ¯ä¸ªå®ä¾‹è¿›è¡Œç»†åŒ–æ¥æé«˜æ·±åº¦ä¼°è®¡çš„ç²¾åº¦ã€‚åŒæ—¶ï¼Œå¼•å…¥åŸºäºå®ä¾‹å†…æ·±åº¦è¿ç»­æ€§å…ˆéªŒçš„è¿‡æ»¤æœºåˆ¶ä»¥å¢å¼ºé²æ£’æ€§ã€‚æ­¤å¤–ï¼Œé’ˆå¯¹ç°æœ‰ç½®ä¿¡åº¦ä¼°è®¡å¯èƒ½é™ä½IA-MVSåœ¨ç‚¹äº‘ä¸Šçš„æ€§èƒ½ï¼Œæœ¬æ–‡å¼€å‘äº†åŸºäºæ¡ä»¶æ¦‚ç‡çš„è¯¦ç»†æ•°å­¦æ¨¡å‹ã€‚è¯¥æ–¹æ³•å¯å¹¿æ³›åº”ç”¨äºåŸºäºMVSNetçš„æ¨¡å‹ï¼Œè€Œæ— éœ€é¢å¤–çš„è®­ç»ƒè´Ÿæ‹…ã€‚æˆ‘ä»¬çš„ç®—æ³•åœ¨DTUåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œæºä»£ç å¯åœ¨https://github.com/KevinWang73106/IA-MVSè·å–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¤šè§†è§’ç«‹ä½“è§†è§‰æ–¹æ³•åœ¨æ·±åº¦ä¼°è®¡ç²¾åº¦ä¸Šçš„ä¸è¶³ï¼Œç‰¹åˆ«æ˜¯æœªèƒ½å……åˆ†åˆ©ç”¨å•ä¸ªå®ä¾‹çš„æ·±åº¦è¦†ç›–èŒƒå›´å°äºæ•´ä¸ªåœºæ™¯çš„é—®é¢˜ã€‚åŒæ—¶ï¼Œåˆå§‹é˜¶æ®µçš„åå·®åœ¨åç»­è¿‡ç¨‹ä¸­ä¼šå¯¼è‡´ç´¯ç§¯è¯¯å·®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šIA-MVSçš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡å®ä¾‹è‡ªé€‚åº”çš„æ–¹å¼ç¼©å°æ·±åº¦å‡è®¾èŒƒå›´ï¼Œå¹¶å¯¹æ¯ä¸ªå®ä¾‹è¿›è¡Œç»†åŒ–å¤„ç†ï¼Œä»è€Œæé«˜æ·±åº¦ä¼°è®¡çš„ç²¾åº¦ã€‚æ­¤å¤–ï¼Œé‡‡ç”¨åŸºäºå®ä¾‹å†…æ·±åº¦è¿ç»­æ€§å…ˆéªŒçš„è¿‡æ»¤æœºåˆ¶æ¥å¢å¼ºæ¨¡å‹çš„é²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šIA-MVSçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ·±åº¦å‡è®¾ç”Ÿæˆã€å®ä¾‹ç»†åŒ–å’Œç½®ä¿¡åº¦ä¼°è®¡ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆç”Ÿæˆåˆæ­¥çš„æ·±åº¦å‡è®¾ï¼Œç„¶åå¯¹æ¯ä¸ªå®ä¾‹è¿›è¡Œç»†åŒ–ï¼Œæœ€åé€šè¿‡ç½®ä¿¡åº¦ä¼°è®¡æ¥ä¼˜åŒ–ç»“æœã€‚

**å…³é”®åˆ›æ–°**ï¼šIA-MVSçš„ä¸»è¦åˆ›æ–°åœ¨äºå¼•å…¥äº†å®ä¾‹è‡ªé€‚åº”çš„æ·±åº¦å‡è®¾ç¼©å°æœºåˆ¶å’ŒåŸºäºæ¡ä»¶æ¦‚ç‡çš„ç½®ä¿¡åº¦ä¼°è®¡æ¨¡å‹ï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„é€šç”¨æ·±åº¦å‡è®¾å¤„ç†æ–¹å¼å½¢æˆäº†é²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å…³é”®è®¾è®¡æ–¹é¢ï¼ŒIA-MVSé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ·±åº¦ä¼°è®¡ï¼ŒåŒæ—¶åœ¨ç½®ä¿¡åº¦ä¼°è®¡ä¸­å¼•å…¥äº†æ¡ä»¶æ¦‚ç‡æ¨¡å‹ï¼Œä»¥æé«˜å¯¹ç‚¹äº‘çš„å¤„ç†æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨DTUåŸºå‡†æµ‹è¯•ä¸­ï¼ŒIA-MVSå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œç›¸è¾ƒäºç°æœ‰åŸºçº¿æ–¹æ³•ï¼Œæ·±åº¦ä¼°è®¡ç²¾åº¦æå‡äº†æ˜¾è‘—çš„ç™¾åˆ†æ¯”ï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§å’Œä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

IA-MVSåœ¨å¤šè§†è§’ç«‹ä½“è§†è§‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¸‰ç»´é‡å»ºã€æœºå™¨äººå¯¼èˆªå’Œå¢å¼ºç°å®ç­‰åœºæ™¯ä¸­ã€‚å…¶é«˜ç²¾åº¦çš„æ·±åº¦ä¼°è®¡èƒ½åŠ›èƒ½å¤Ÿæ˜¾è‘—æå‡ç›¸å…³åº”ç”¨çš„æ€§èƒ½å’Œå¯é æ€§ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multi-view stereo (MVS) models based on progressive depth hypothesis narrowing have made remarkable advancements. However, existing methods haven't fully utilized the potential that the depth coverage of individual instances is smaller than that of the entire scene, which restricts further improvements in depth estimation precision. Moreover, inevitable deviations in the initial stage accumulate as the process advances. In this paper, we propose Instance-Adaptive MVS (IA-MVS). It enhances the precision of depth estimation by narrowing the depth hypothesis range and conducting refinement on each instance. Additionally, a filtering mechanism based on intra-instance depth continuity priors is incorporated to boost robustness. Furthermore, recognizing that existing confidence estimation can degrade IA-MVS performance on point clouds. We have developed a detailed mathematical model for confidence estimation based on conditional probability. The proposed method can be widely applied in models based on MVSNet without imposing extra training burdens. Our method achieves state-of-the-art performance on the DTU benchmark. The source code is available at https://github.com/KevinWang73106/IA-MVS.

