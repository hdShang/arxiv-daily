---
layout: default
title: "Sat2Sound: A Unified Framework for Zero-Shot Soundscape Mapping"
---

# Sat2Sound: A Unified Framework for Zero-Shot Soundscape Mapping

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.13777" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.13777v1</a>
  <a href="https://arxiv.org/pdf/2505.13777.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.13777v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.13777v1', 'Sat2Sound: A Unified Framework for Zero-Shot Soundscape Mapping')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Subash Khanal, Srikumar Sastry, Aayush Dhakal, Adeel Ahmad, Nathan Jacobs

**åˆ†ç±»**: cs.CV, cs.AI, cs.SD

**å‘å¸ƒæ—¥æœŸ**: 2025-05-19

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSat2Soundæ¡†æ¶ä»¥è§£å†³å£°éŸ³æ™¯è§‚æ˜ å°„é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å£°éŸ³æ™¯è§‚æ˜ å°„` `å¤šæ¨¡æ€å­¦ä¹ ` `è§†è§‰-è¯­è¨€æ¨¡å‹` `å¯¹æ¯”å­¦ä¹ ` `ç¯å¢ƒç›‘æµ‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å£°éŸ³æ™¯è§‚æ˜ å°„æ–¹æ³•ä¾èµ–äºå«æ˜Ÿå›¾åƒå’Œåœ°ç†æ ‡è®°éŸ³é¢‘æ ·æœ¬ï¼Œæ— æ³•å……åˆ†æ•æ‰å£°éŸ³æºçš„å¤šæ ·æ€§ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡è§†è§‰-è¯­è¨€æ¨¡å‹ç”Ÿæˆä¸°å¯Œçš„å£°éŸ³æ™¯è§‚æè¿°ï¼Œå¹¶ç»“åˆå¯¹æ¯”å­¦ä¹ æ¥æå‡æ¨¡å‹æ€§èƒ½ã€‚
3. Sat2Soundåœ¨GeoSoundå’ŒSoundingEarthæ•°æ®é›†ä¸Šå®ç°äº†è·¨æ¨¡æ€æ£€ç´¢çš„æœ€æ–°æ€§èƒ½ï¼Œå¹¶å¼•å…¥äº†å£°éŸ³æ™¯è§‚åˆæˆçš„æ–°åº”ç”¨ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬æå‡ºäº†Sat2Soundï¼Œä¸€ä¸ªå¤šæ¨¡æ€è¡¨ç¤ºå­¦ä¹ æ¡†æ¶ï¼Œç”¨äºå£°éŸ³æ™¯è§‚æ˜ å°„ï¼Œæ—¨åœ¨é¢„æµ‹åœ°çƒä¸Šä»»æ„ä½ç½®çš„å£°éŸ³åˆ†å¸ƒã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºå«æ˜Ÿå›¾åƒå’Œé…å¯¹çš„åœ°ç†æ ‡è®°éŸ³é¢‘æ ·æœ¬ï¼Œå¸¸å¸¸æ— æ³•æ•æ‰ç‰¹å®šä½ç½®å£°éŸ³æºçš„å¤šæ ·æ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬é€šè¿‡åˆ©ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰å¢å¼ºç°æœ‰æ•°æ®é›†ï¼Œä¸ºå«æ˜Ÿå›¾åƒæ‰€æç»˜çš„ä½ç½®ç”Ÿæˆè¯­ä¹‰ä¸°å¯Œçš„å£°éŸ³æ™¯è§‚æè¿°ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç»“åˆäº†éŸ³é¢‘ã€éŸ³é¢‘æ ‡é¢˜ã€å«æ˜Ÿå›¾åƒå’Œå«æ˜Ÿå›¾åƒæ ‡é¢˜ä¹‹é—´çš„å¯¹æ¯”å­¦ä¹ ã€‚æˆ‘ä»¬å‡è®¾åœ¨ä¸åŒæ¨¡æ€ä¹‹é—´å­˜åœ¨ä¸€ç»„å›ºå®šçš„å…±äº«å£°éŸ³æ™¯è§‚æ¦‚å¿µã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å­¦ä¹ äº†ä¸€ä¸ªå…±äº«çš„å£°éŸ³æ™¯è§‚æ¦‚å¿µä»£ç æœ¬ï¼Œå¹¶å°†æ¯ä¸ªæ ·æœ¬è¡¨ç¤ºä¸ºè¿™äº›æ¦‚å¿µçš„åŠ æƒå¹³å‡ã€‚Sat2Soundåœ¨ä¸¤ä¸ªæ•°æ®é›†GeoSoundå’ŒSoundingEarthä¸Šå®ç°äº†å«æ˜Ÿå›¾åƒä¸éŸ³é¢‘ä¹‹é—´çš„è·¨æ¨¡æ€æ£€ç´¢çš„æœ€æ–°æ€§èƒ½ã€‚æ­¤å¤–ï¼ŒåŸºäºSat2Soundæ£€ç´¢è¯¦ç»†å£°éŸ³æ™¯è§‚æ ‡é¢˜çš„èƒ½åŠ›ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°åº”ç”¨ï¼šåŸºäºä½ç½®çš„å£°éŸ³æ™¯è§‚åˆæˆï¼Œèƒ½å¤Ÿæä¾›æ²‰æµ¸å¼çš„å£°å­¦ä½“éªŒã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ¨¡å‹å°†å…¬å¼€å¯ç”¨ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å£°éŸ³æ™¯è§‚æ˜ å°„ä¸­çš„å£°éŸ³æºå¤šæ ·æ€§æ•æ‰ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºå«æ˜Ÿå›¾åƒå’Œé…å¯¹éŸ³é¢‘æ ·æœ¬ï¼Œå¸¸å¸¸æ— æ³•å…¨é¢åæ˜ ç‰¹å®šä½ç½®çš„å£°éŸ³ç‰¹å¾ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹ç”Ÿæˆè¯­ä¹‰ä¸°å¯Œçš„å£°éŸ³æ™¯è§‚æè¿°ï¼Œå¹¶é€šè¿‡å¯¹æ¯”å­¦ä¹ å®ç°éŸ³é¢‘ä¸å›¾åƒä¹‹é—´çš„æœ‰æ•ˆæ˜ å°„ã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨å¢å¼ºæ¨¡å‹å¯¹ä¸åŒæ¨¡æ€ä¹‹é—´å…±äº«æ¦‚å¿µçš„ç†è§£ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†å¢å¼ºã€å¯¹æ¯”å­¦ä¹ æ¨¡å—å’Œå…±äº«ä»£ç æœ¬çš„å­¦ä¹ ã€‚é¦–å…ˆï¼Œé€šè¿‡VLMç”Ÿæˆå£°éŸ³æ™¯è§‚æè¿°ï¼Œç„¶åè¿›è¡Œå¯¹æ¯”å­¦ä¹ ä»¥ä¼˜åŒ–éŸ³é¢‘å’Œå›¾åƒçš„è¡¨ç¤ºï¼Œæœ€ååˆ©ç”¨å…±äº«ä»£ç æœ¬å°†æ ·æœ¬è¡¨ç¤ºä¸ºæ¦‚å¿µçš„åŠ æƒå¹³å‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥äº†å…±äº«å£°éŸ³æ™¯è§‚æ¦‚å¿µçš„ä»£ç æœ¬ï¼Œä½¿å¾—ä¸åŒæ¨¡æ€ä¹‹é—´çš„å£°éŸ³æ™¯è§‚æ˜ å°„æ›´åŠ å‡†ç¡®ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿä¾èµ–äºå•ä¸€æ¨¡æ€çš„æŠ€æœ¯æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å¯¹æ¯”æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–éŸ³é¢‘å’Œå›¾åƒçš„ç›¸ä¼¼æ€§ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šç»“åˆäº†å¤šæ¨¡æ€è¾“å…¥ï¼Œä»¥å¢å¼ºæ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨GeoSoundå’ŒSoundingEarthæ•°æ®é›†ä¸Šï¼ŒSat2Soundå®ç°äº†è·¨æ¨¡æ€æ£€ç´¢çš„æœ€æ–°æ€§èƒ½ï¼Œæ˜¾è‘—æå‡äº†éŸ³é¢‘ä¸å«æ˜Ÿå›¾åƒä¹‹é—´çš„åŒ¹é…ç²¾åº¦ã€‚å…·ä½“è€Œè¨€ï¼Œæ¨¡å‹åœ¨æ£€ç´¢ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ¯”ç°æœ‰åŸºçº¿æ–¹æ³•æ›´é«˜çš„å‡†ç¡®ç‡å’Œå¬å›ç‡ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¯å¢ƒç›‘æµ‹ã€åŸå¸‚è§„åˆ’å’Œè™šæ‹Ÿç°å®ç­‰ã€‚é€šè¿‡å‡†ç¡®çš„å£°éŸ³æ™¯è§‚æ˜ å°„ï¼Œèƒ½å¤Ÿä¸ºç”¨æˆ·æä¾›æ›´ä¸°å¯Œçš„æ²‰æµ¸å¼ä½“éªŒï¼Œä¿ƒè¿›å¯¹ç¯å¢ƒçš„ç†è§£ä¸ä¿æŠ¤ã€‚æœªæ¥ï¼ŒSat2Soundå¯èƒ½åœ¨æ™ºèƒ½åŸå¸‚å’Œç”Ÿæ€ç ”ç©¶ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present Sat2Sound, a multimodal representation learning framework for soundscape mapping, designed to predict the distribution of sounds at any location on Earth. Existing methods for this task rely on satellite image and paired geotagged audio samples, which often fail to capture the diversity of sound sources at a given location. To address this limitation, we enhance existing datasets by leveraging a Vision-Language Model (VLM) to generate semantically rich soundscape descriptions for locations depicted in satellite images. Our approach incorporates contrastive learning across audio, audio captions, satellite images, and satellite image captions. We hypothesize that there is a fixed set of soundscape concepts shared across modalities. To this end, we learn a shared codebook of soundscape concepts and represent each sample as a weighted average of these concepts. Sat2Sound achieves state-of-the-art performance in cross-modal retrieval between satellite image and audio on two datasets: GeoSound and SoundingEarth. Additionally, building on Sat2Sound's ability to retrieve detailed soundscape captions, we introduce a novel application: location-based soundscape synthesis, which enables immersive acoustic experiences. Our code and models will be publicly available.

