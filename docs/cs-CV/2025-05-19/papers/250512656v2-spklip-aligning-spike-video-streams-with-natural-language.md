---
layout: default
title: "SPKLIP: Aligning Spike Video Streams with Natural Language"
---

# SPKLIP: Aligning Spike Video Streams with Natural Language

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.12656" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.12656v2</a>
  <a href="https://arxiv.org/pdf/2505.12656.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.12656v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.12656v2', 'SPKLIP: Aligning Spike Video Streams with Natural Language')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yongchang Gao, Meiling Jin, Zhaofei Yu, Tiejun Huang, Guozhang Chen

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-19 (æ›´æ–°: 2025-05-26)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSPKLIPä»¥è§£å†³Spikeè§†é¢‘ä¸è‡ªç„¶è¯­è¨€å¯¹é½é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `Spikeè§†é¢‘` `è‡ªç„¶è¯­è¨€å¤„ç†` `å¤šæ¨¡æ€å¯¹é½` `å°‘æ ·æœ¬å­¦ä¹ ` `ç¥ç»å½¢æ€è®¡ç®—`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰Spikeè§†é¢‘-è¯­è¨€å¯¹é½æ–¹æ³•é¢ä¸´ç¨€ç–å’Œå¼‚æ­¥è¾“å‡ºçš„æŒ‘æˆ˜ï¼Œå¯¼è‡´è¯­ä¹‰ç†è§£ä¸è¶³ã€‚
2. SPKLIPé€šè¿‡åˆ†å±‚Spikeç‰¹å¾æå–å™¨å’ŒSpike-æ–‡æœ¬å¯¹æ¯”å­¦ä¹ ï¼Œç›´æ¥å¯¹é½Spikeè§†é¢‘ä¸è¯­è¨€ï¼Œæ”¯æŒå°‘æ ·æœ¬å­¦ä¹ ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºSPKLIPåœ¨åŸºå‡†Spikeæ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶åœ¨çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šå±•ç°äº†å¼ºå¤§çš„å°‘æ ·æœ¬æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

Spikeç›¸æœºæä¾›äº†ç‹¬ç‰¹çš„æ„ŸçŸ¥èƒ½åŠ›ï¼Œä½†å…¶ç¨€ç–å’Œå¼‚æ­¥è¾“å‡ºå¯¹è¯­ä¹‰ç†è§£æ„æˆæŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨Spikeè§†é¢‘-è¯­è¨€å¯¹é½ï¼ˆSpike-VLAï¼‰ä»»åŠ¡ä¸­ï¼Œç°æœ‰æ¨¡å‹å¦‚CLIPè¡¨ç°ä¸ä½³ã€‚æˆ‘ä»¬æå‡ºäº†SPKLIPï¼Œè¿™æ˜¯é¦–ä¸ªä¸“é—¨é’ˆå¯¹Spike-VLAçš„æ¶æ„ã€‚SPKLIPé‡‡ç”¨åˆ†å±‚çš„Spikeç‰¹å¾æå–å™¨ï¼Œè‡ªé€‚åº”å»ºæ¨¡äº‹ä»¶æµä¸­çš„å¤šå°ºåº¦æ—¶é—´åŠ¨æ€ï¼Œå¹¶ä½¿ç”¨Spike-æ–‡æœ¬å¯¹æ¯”å­¦ä¹ ç›´æ¥å¯¹é½Spikeè§†é¢‘ä¸è¯­è¨€ï¼Œå®ç°æœ‰æ•ˆçš„å°‘æ ·æœ¬å­¦ä¹ ã€‚å…¨è„‰å†²è§†è§‰ç¼–ç å™¨å˜ä½“å°†SNNç»„ä»¶æ•´åˆåˆ°æˆ‘ä»¬çš„æµç¨‹ä¸­ï¼Œå±•ç¤ºäº†å¢å¼ºçš„èƒ½æ•ˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨åŸºå‡†Spikeæ•°æ®é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶åœ¨æ–°è´¡çŒ®çš„çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šå±•ç°äº†å¼ºå¤§çš„å°‘æ ·æœ¬æ³›åŒ–èƒ½åŠ›ã€‚SPKLIPçš„èƒ½æ•ˆçªæ˜¾äº†å…¶åœ¨ç¥ç»å½¢æ€éƒ¨ç½²ä¸­çš„æ½œåŠ›ï¼Œæ¨åŠ¨äº†åŸºäºäº‹ä»¶çš„å¤šæ¨¡æ€ç ”ç©¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³Spikeè§†é¢‘ä¸è‡ªç„¶è¯­è¨€ä¹‹é—´çš„å¯¹é½é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å¦‚CLIPç”±äºæ¨¡æ€ä¸åŒ¹é…è€Œè¡¨ç°ä¸ä½³ï¼Œéš¾ä»¥æœ‰æ•ˆå¤„ç†Spikeç›¸æœºçš„ç¨€ç–å’Œå¼‚æ­¥è¾“å‡ºã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSPKLIPçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡åˆ†å±‚çš„Spikeç‰¹å¾æå–å™¨è‡ªé€‚åº”å»ºæ¨¡å¤šå°ºåº¦æ—¶é—´åŠ¨æ€ï¼Œå¹¶åˆ©ç”¨Spike-æ–‡æœ¬å¯¹æ¯”å­¦ä¹ ç›´æ¥å®ç°Spikeè§†é¢‘ä¸è¯­è¨€çš„å¯¹é½ï¼Œä»è€Œæå‡å°‘æ ·æœ¬å­¦ä¹ çš„æ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSPKLIPçš„æ•´ä½“æ¶æ„åŒ…æ‹¬åˆ†å±‚Spikeç‰¹å¾æå–å™¨ã€Spike-æ–‡æœ¬å¯¹æ¯”å­¦ä¹ æ¨¡å—å’Œå…¨è„‰å†²è§†è§‰ç¼–ç å™¨ã€‚åˆ†å±‚ç‰¹å¾æå–å™¨è´Ÿè´£æ•æ‰äº‹ä»¶æµä¸­çš„æ—¶é—´åŠ¨æ€ï¼Œè€Œå¯¹æ¯”å­¦ä¹ æ¨¡å—åˆ™ç”¨äºå¯¹é½è§†é¢‘å’Œæ–‡æœ¬ä¿¡æ¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šSPKLIPçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶ä¸“é—¨é’ˆå¯¹Spike-VLAçš„è®¾è®¡ï¼Œé‡‡ç”¨äº†åˆ†å±‚ç‰¹å¾æå–å’Œå¯¹æ¯”å­¦ä¹ çš„ç»“åˆï¼Œæ˜¾è‘—æå‡äº†å¯¹é½æ•ˆæœå’Œèƒ½æ•ˆï¼ŒåŒºåˆ«äºä¼ ç»Ÿçš„å¤šæ¨¡æ€å­¦ä¹ æ–¹æ³•ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒSPKLIPä½¿ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–å¯¹æ¯”å­¦ä¹ è¿‡ç¨‹ï¼Œå¹¶åœ¨ç½‘ç»œç»“æ„ä¸­é›†æˆäº†SNNç»„ä»¶ï¼Œä»¥æé«˜èƒ½æ•ˆå’Œå¤„ç†èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

SPKLIPåœ¨åŸºå‡†Spikeæ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨Spike-VLAä»»åŠ¡ä¸­ç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•æå‡äº†XX%çš„å‡†ç¡®ç‡ã€‚æ­¤å¤–ï¼Œåœ¨æ–°è´¡çŒ®çš„çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šï¼ŒSPKLIPå±•ç°äº†å¼ºå¤§çš„å°‘æ ·æœ¬æ³›åŒ–èƒ½åŠ›ï¼Œè¿›ä¸€æ­¥éªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SPKLIPçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ï¼ŒåŒ…æ‹¬æ™ºèƒ½ç›‘æ§ã€è‡ªåŠ¨é©¾é©¶å’Œæœºå™¨äººè§†è§‰ç­‰ã€‚å…¶é«˜æ•ˆçš„Spikeè§†é¢‘å¤„ç†èƒ½åŠ›å’Œå¯¹è‡ªç„¶è¯­è¨€çš„ç†è§£èƒ½åŠ›ï¼Œèƒ½å¤Ÿæ¨åŠ¨è¿™äº›é¢†åŸŸçš„æ™ºèƒ½åŒ–è¿›ç¨‹ï¼Œæå‡ç³»ç»Ÿçš„äº¤äº’æ€§å’Œå“åº”èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Spike cameras offer unique sensing capabilities but their sparse, asynchronous output challenges semantic understanding, especially for Spike Video-Language Alignment (Spike-VLA) where models like CLIP underperform due to modality mismatch. We introduce SPKLIP, the first architecture specifically for Spike-VLA. SPKLIP employs a hierarchical spike feature extractor that adaptively models multi-scale temporal dynamics in event streams, and uses spike-text contrastive learning to directly align spike video with language, enabling effective few-shot learning. A full-spiking visual encoder variant, integrating SNN components into our pipeline, demonstrates enhanced energy efficiency. Experiments show state-of-the-art performance on benchmark spike datasets and strong few-shot generalization on a newly contributed real-world dataset. SPKLIP's energy efficiency highlights its potential for neuromorphic deployment, advancing event-based multimodal research. The source code and dataset are available at [link removed for anonymity].

