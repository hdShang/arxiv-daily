---
layout: default
title: Coarse Attribute Prediction with Task Agnostic Distillation for Real World Clothes Changing ReID
---

# Coarse Attribute Prediction with Task Agnostic Distillation for Real World Clothes Changing ReID

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.12580" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.12580v2</a>
  <a href="https://arxiv.org/pdf/2505.12580.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.12580v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.12580v2', 'Coarse Attribute Prediction with Task Agnostic Distillation for Real World Clothes Changing ReID')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Priyank Pathak, Yogesh S Rawat

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-19 (æ›´æ–°: 2025-11-03)

**å¤‡æ³¨**: The 36th British Machine Vision Conference (BMVC)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRLQæ¡†æ¶ä»¥è§£å†³ä½è´¨é‡å›¾åƒä¸‹çš„æœè£…å˜åŒ–é‡è¯†åˆ«é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æœè£…å˜åŒ–é‡è¯†åˆ«` `ä½è´¨é‡å›¾åƒ` `ç²—ç•¥å±æ€§é¢„æµ‹` `ä»»åŠ¡æ— å…³è’¸é¦` `æ·±åº¦å­¦ä¹ ` `ç‰¹å¾è¡¨ç¤º` `è‡ªç›‘ç£å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æœè£…å˜åŒ–é‡è¯†åˆ«æ–¹æ³•åœ¨ä½è´¨é‡å›¾åƒä¸Šè¡¨ç°ä¸ä½³ï¼Œå¯¼è‡´ç‰¹å¾èšç±»å›°éš¾å’ŒåŒ¹é…é”™è¯¯ã€‚
2. æœ¬æ–‡æå‡ºçš„RLQæ¡†æ¶ç»“åˆç²—ç•¥å±æ€§é¢„æµ‹å’Œä»»åŠ¡æ— å…³è’¸é¦ï¼Œæ—¨åœ¨æé«˜æ¨¡å‹å¯¹ä½è´¨é‡å›¾åƒçš„é²æ£’æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒRLQåœ¨å¤šä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šå‡æ˜¾è‘—æå‡äº†è¯†åˆ«å‡†ç¡®ç‡ï¼Œå°¤å…¶åœ¨PRCCæ•°æ®é›†ä¸Šè¡¨ç°å°¤ä¸ºçªå‡ºã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶èšç„¦äºç°å®ä¸–ç•Œä¸­çš„æœè£…å˜åŒ–é‡è¯†åˆ«ï¼ˆCC-ReIDï¼‰ã€‚ç°æœ‰æ–¹æ³•åœ¨é«˜è´¨é‡å›¾åƒä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨ä½è´¨é‡å›¾åƒï¼ˆå¦‚åƒç´ åŒ–ã€æ¨¡ç³Šç­‰ï¼‰ä¸­æ•ˆæœä¸ä½³ï¼Œå¯¼è‡´ç‰¹å¾èšç±»å›°éš¾ï¼ŒåŒ¹é…é”™è¯¯ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶â€”â€”æŠ—ä½è´¨é‡é²æ£’æ€§ï¼ˆRLQï¼‰ï¼Œé€šè¿‡ç²—ç•¥å±æ€§é¢„æµ‹ï¼ˆCAPï¼‰å’Œä»»åŠ¡æ— å…³è’¸é¦ï¼ˆTADï¼‰äº¤æ›¿è¿›è¡Œè®­ç»ƒï¼Œæå‡æ¨¡å‹åœ¨çœŸå®æ•°æ®ä¸Šçš„è¡¨ç°ã€‚CAPé€šè¿‡ç²—ç•¥é¢„æµ‹ä¸°å¯Œæ¨¡å‹çš„å¤–éƒ¨ç»†ç²’åº¦å±æ€§ï¼Œå‡å°‘å™ªå£°å½±å“ï¼›è€ŒTADåˆ™é€šè¿‡ä»»åŠ¡æ— å…³çš„è‡ªç›‘ç£å’Œè’¸é¦ï¼Œå¢å¼ºæ¨¡å‹çš„å†…éƒ¨ç‰¹å¾è¡¨ç¤ºã€‚RLQåœ¨LaSTå’ŒDeepChangeç­‰çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šæå‡äº†1.6%-2.9%çš„Top-1å‡†ç¡®ç‡ï¼Œåœ¨PRCCä¸Šæ›´æ˜¯æå‡äº†5.3%-6%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³ä½è´¨é‡å›¾åƒä¸‹çš„æœè£…å˜åŒ–é‡è¯†åˆ«ï¼ˆCC-ReIDï¼‰é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨é«˜è´¨é‡å›¾åƒä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨ä½è´¨é‡å›¾åƒä¸­ï¼Œç”±äºåƒç´ åŒ–ã€æ¨¡ç³Šç­‰å™ªå£°å½±å“ï¼Œå¯¼è‡´ç‰¹å¾èšç±»å›°éš¾ï¼ŒåŒ¹é…é”™è¯¯é¢‘å‘ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„æŠ—ä½è´¨é‡é²æ£’æ€§ï¼ˆRLQï¼‰æ¡†æ¶ï¼Œé€šè¿‡äº¤æ›¿ä½¿ç”¨ç²—ç•¥å±æ€§é¢„æµ‹ï¼ˆCAPï¼‰å’Œä»»åŠ¡æ— å…³è’¸é¦ï¼ˆTADï¼‰ï¼Œæ—¨åœ¨å¢å¼ºæ¨¡å‹å¯¹ä½è´¨é‡å›¾åƒçš„é²æ£’æ€§ã€‚CAPé€šè¿‡ç²—ç•¥é¢„æµ‹å¼•å…¥å¤–éƒ¨ç»†ç²’åº¦å±æ€§ï¼Œé™ä½å™ªå£°å½±å“ï¼›è€ŒTADåˆ™é€šè¿‡è‡ªç›‘ç£å­¦ä¹ å’Œè’¸é¦æŠ€æœ¯ï¼Œæå‡æ¨¡å‹çš„å†…éƒ¨ç‰¹å¾è¡¨ç¤ºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRLQæ¡†æ¶ä¸»è¦åŒ…å«ä¸¤ä¸ªæ¨¡å—ï¼šç²—ç•¥å±æ€§é¢„æµ‹ï¼ˆCAPï¼‰å’Œä»»åŠ¡æ— å…³è’¸é¦ï¼ˆTADï¼‰ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œè¿™ä¸¤ä¸ªæ¨¡å—äº¤æ›¿è¿›è¡Œï¼ŒCAPè´Ÿè´£æå–å¤–éƒ¨å±æ€§ä¿¡æ¯ï¼Œè€ŒTADåˆ™é€šè¿‡è‡ªç›‘ç£å­¦ä¹ å¢å¼ºç‰¹å¾è¡¨ç¤ºã€‚

**å…³é”®åˆ›æ–°**ï¼šRLQæ¡†æ¶çš„åˆ›æ–°ä¹‹å¤„åœ¨äºç»“åˆäº†ç²—ç•¥å±æ€§é¢„æµ‹å’Œä»»åŠ¡æ— å…³è’¸é¦ï¼Œå½¢æˆäº†ä¸€ç§æ–°çš„è®­ç»ƒæœºåˆ¶ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨ä½è´¨é‡å›¾åƒä¸Šçš„è¡¨ç°ã€‚è¿™ç§è®¾è®¡ä¸ç°æœ‰æ–¹æ³•çš„å•ä¸€ç‰¹å¾æå–æˆ–è’¸é¦æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡CAPå’ŒTADçš„è®­ç»ƒæ•ˆæœï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†ä¼˜åŒ–ï¼Œä»¥é€‚åº”ä½è´¨é‡å›¾åƒç‰¹å¾çš„æå–å’Œè¡¨ç¤ºã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRLQæ¡†æ¶åœ¨LaSTå’ŒDeepChangeç­‰çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šæå‡äº†1.6%-2.9%çš„Top-1å‡†ç¡®ç‡ï¼Œåœ¨PRCCæ•°æ®é›†ä¸Šæ›´æ˜¯å®ç°äº†5.3%-6%çš„æ˜¾è‘—æå‡ï¼Œå±•ç°å‡ºå¼ºå¤§çš„é²æ£’æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½ç›‘æ§ã€æœè£…é›¶å”®å’Œç¤¾äº¤åª’ä½“ç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡åœ¨å¤æ‚ç¯å¢ƒä¸‹çš„æœè£…è¯†åˆ«èƒ½åŠ›ã€‚éšç€æŠ€æœ¯çš„è¿›æ­¥ï¼ŒRLQæ¡†æ¶æœ‰æœ›åœ¨å®é™…åº”ç”¨ä¸­æä¾›æ›´é«˜çš„è¯†åˆ«å‡†ç¡®ç‡ï¼Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This work focuses on Clothes Changing Re-IDentification (CC-ReID) for the real world. Existing works perform well with high-quality (HQ) images, but struggle with low-quality (LQ) where we can have artifacts like pixelation, out-of-focus blur, and motion blur. These artifacts introduce noise to not only external biometric attributes (e.g. pose, body shape, etc.) but also corrupt the model's internal feature representation. Models usually cluster LQ image features together, making it difficult to distinguish between them, leading to incorrect matches. We propose a novel framework Robustness against Low-Quality (RLQ) to improve CC-ReID model on real-world data. RLQ relies on Coarse Attributes Prediction (CAP) and Task Agnostic Distillation (TAD) operating in alternate steps in a novel training mechanism. CAP enriches the model with external fine-grained attributes via coarse predictions, thereby reducing the effect of noisy inputs. On the other hand, TAD enhances the model's internal feature representation by bridging the gap between HQ and LQ features, via an external dataset through task-agnostic self-supervision and distillation. RLQ outperforms the existing approaches by 1.6%-2.9% Top-1 on real-world datasets like LaST, and DeepChange, while showing consistent improvement of 5.3%-6% Top-1 on PRCC with competitive performance on LTCC. *The code will be made public soon.*

