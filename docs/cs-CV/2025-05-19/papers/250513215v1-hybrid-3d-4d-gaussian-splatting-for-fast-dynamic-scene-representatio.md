---
layout: default
title: Hybrid 3D-4D Gaussian Splatting for Fast Dynamic Scene Representation
---

# Hybrid 3D-4D Gaussian Splatting for Fast Dynamic Scene Representation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.13215" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.13215v1</a>
  <a href="https://arxiv.org/pdf/2505.13215.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.13215v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.13215v1', 'Hybrid 3D-4D Gaussian Splatting for Fast Dynamic Scene Representation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Seungjun Oh, Younggeun Lee, Hyejin Jeon, Eunbyung Park

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-19

**å¤‡æ³¨**: https://ohsngjun.github.io/3D-4DGS/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ··åˆ3D-4Dé«˜æ–¯ç‚¹äº‘ä»¥è§£å†³åŠ¨æ€åœºæ™¯è¡¨ç¤ºé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `åŠ¨æ€åœºæ™¯é‡å»º` `é«˜æ–¯ç‚¹äº‘` `è®¡ç®—æ•ˆç‡` `è§†è§‰è´¨é‡` `è™šæ‹Ÿç°å®` `å¢å¼ºç°å®`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„4Dé«˜æ–¯ç‚¹äº‘æ–¹æ³•åœ¨é™æ€åŒºåŸŸçš„å†—ä½™åˆ†é…å¯¼è‡´è®¡ç®—å’Œå†…å­˜å¼€é”€å¤§ï¼Œå½±å“å›¾åƒè´¨é‡ã€‚
2. æœ¬æ–‡æå‡ºçš„3D-4Dé«˜æ–¯ç‚¹äº‘æ¡†æ¶ï¼Œé€šè¿‡å°†é™æ€åŒºåŸŸç”¨3Dé«˜æ–¯è¡¨ç¤ºï¼ŒåŠ¨æ€åŒºåŸŸç”¨4Dé«˜æ–¯è¡¨ç¤ºï¼Œä¼˜åŒ–äº†èµ„æºä½¿ç”¨ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œ3D-4Dé«˜æ–¯ç‚¹äº‘åœ¨è®­ç»ƒæ—¶é—´ä¸Šæ˜¾è‘—å¿«äºä¼ ç»Ÿ4Dé«˜æ–¯ç‚¹äº‘æ–¹æ³•ï¼ŒåŒæ—¶è§†è§‰è´¨é‡å¾—åˆ°äº†ä¿æŒæˆ–æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼ŒåŠ¨æ€3Dåœºæ™¯é‡å»ºå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œèƒ½å¤Ÿå®ç°é«˜ä¿çœŸåº¦çš„3Dæ–°è§†è§’åˆæˆï¼Œå¹¶æ”¹å–„æ—¶é—´ä¸€è‡´æ€§ã€‚å…¶ä¸­ï¼Œ4Dé«˜æ–¯ç‚¹äº‘ï¼ˆ4DGSï¼‰å› å…¶å»ºæ¨¡é«˜ä¿çœŸç©ºé—´å’Œæ—¶é—´å˜åŒ–çš„èƒ½åŠ›è€Œå—åˆ°å…³æ³¨ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•åœ¨é™æ€åŒºåŸŸå†—ä½™åˆ†é…4Dé«˜æ–¯æ—¶ï¼Œé¢ä¸´æ˜¾è‘—çš„è®¡ç®—å’Œå†…å­˜å¼€é”€ï¼Œä¸”å¯èƒ½é™ä½å›¾åƒè´¨é‡ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ··åˆ3D-4Dé«˜æ–¯ç‚¹äº‘ï¼ˆ3D-4DGSï¼‰æ¡†æ¶ï¼Œèƒ½å¤Ÿè‡ªé€‚åº”åœ°ç”¨3Dé«˜æ–¯è¡¨ç¤ºé™æ€åŒºåŸŸï¼ŒåŒæ—¶ä¸ºåŠ¨æ€å…ƒç´ ä¿ç•™4Dé«˜æ–¯ã€‚è¯¥æ–¹æ³•ä»å®Œå…¨çš„4Dé«˜æ–¯è¡¨ç¤ºå¼€å§‹ï¼Œè¿­ä»£åœ°å°†æ—¶é—´ä¸å˜çš„é«˜æ–¯è½¬æ¢ä¸º3Dï¼Œæ˜¾è‘—å‡å°‘å‚æ•°æ•°é‡ï¼Œæé«˜è®¡ç®—æ•ˆç‡ã€‚åŠ¨æ€é«˜æ–¯åˆ™ä¿ç•™å…¶å®Œæ•´çš„4Dè¡¨ç¤ºï¼Œæ•æ‰å¤æ‚è¿åŠ¨ï¼Œä¿æŒé«˜ä¿çœŸåº¦ã€‚æˆ‘ä»¬çš„æ–¹æ¡ˆåœ¨è®­ç»ƒæ—¶é—´ä¸Šæ˜¾è‘—å¿«äºåŸºçº¿4Dé«˜æ–¯ç‚¹äº‘æ–¹æ³•ï¼ŒåŒæ—¶ä¿æŒæˆ–æ”¹å–„è§†è§‰è´¨é‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰4Dé«˜æ–¯ç‚¹äº‘æ–¹æ³•åœ¨é™æ€åŒºåŸŸå†—ä½™åˆ†é…å¯¼è‡´çš„è®¡ç®—å’Œå†…å­˜å¼€é”€è¿‡å¤§ï¼Œä»¥åŠå›¾åƒè´¨é‡ä¸‹é™çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºæ··åˆ3D-4Dé«˜æ–¯ç‚¹äº‘æ¡†æ¶ï¼Œé€šè¿‡è‡ªé€‚åº”åœ°ç”¨3Dé«˜æ–¯è¡¨ç¤ºé™æ€åŒºåŸŸï¼Œä¿ç•™åŠ¨æ€å…ƒç´ çš„4Dé«˜æ–¯è¡¨ç¤ºï¼Œä»è€Œæé«˜è®¡ç®—æ•ˆç‡å’Œè§†è§‰è´¨é‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•é¦–å…ˆä½¿ç”¨å®Œå…¨çš„4Dé«˜æ–¯è¡¨ç¤ºï¼Œç„¶åè¿­ä»£å°†æ—¶é—´ä¸å˜çš„é«˜æ–¯è½¬æ¢ä¸º3Dï¼Œä¸»è¦æ¨¡å—åŒ…æ‹¬é«˜æ–¯è½¬æ¢ã€åŠ¨æ€é«˜æ–¯ä¿ç•™å’Œå‚æ•°ä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†é™æ€å’ŒåŠ¨æ€åŒºåŸŸçš„é«˜æ–¯è¡¨ç¤ºè¿›è¡Œæ··åˆï¼Œæ˜¾è‘—å‡å°‘äº†å‚æ•°æ•°é‡ï¼Œæå‡äº†è®¡ç®—æ•ˆç‡ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”å…·æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†åŠ¨æ€å’Œé™æ€é«˜æ–¯çš„è‡ªé€‚åº”è½¬æ¢æœºåˆ¶ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸Šå¼ºè°ƒäº†æ—¶é—´ä¸€è‡´æ€§å’Œç©ºé—´ä¿çœŸåº¦ï¼Œç½‘ç»œç»“æ„åˆ™æ”¯æŒé«˜æ•ˆçš„é«˜æ–¯è¡¨ç¤ºè½¬æ¢ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œ3D-4Dé«˜æ–¯ç‚¹äº‘æ–¹æ³•åœ¨è®­ç»ƒæ—¶é—´ä¸Šæ¯”åŸºçº¿4Dé«˜æ–¯ç‚¹äº‘æ–¹æ³•å¿«äº†æ˜¾è‘—çš„æ¯”ä¾‹ï¼ŒåŒæ—¶åœ¨è§†è§‰è´¨é‡ä¸Šä¿æŒæˆ–æå‡äº†æ•ˆæœï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨åŠ¨æ€åœºæ™¯é‡å»ºã€è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æé«˜åŠ¨æ€åœºæ™¯çš„è¡¨ç¤ºæ•ˆç‡å’Œè´¨é‡ï¼Œèƒ½å¤Ÿä¸ºå®æ—¶æ¸²æŸ“å’Œäº¤äº’å¼åº”ç”¨æä¾›æ›´å¥½çš„æ”¯æŒï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advancements in dynamic 3D scene reconstruction have shown promising results, enabling high-fidelity 3D novel view synthesis with improved temporal consistency. Among these, 4D Gaussian Splatting (4DGS) has emerged as an appealing approach due to its ability to model high-fidelity spatial and temporal variations. However, existing methods suffer from substantial computational and memory overhead due to the redundant allocation of 4D Gaussians to static regions, which can also degrade image quality. In this work, we introduce hybrid 3D-4D Gaussian Splatting (3D-4DGS), a novel framework that adaptively represents static regions with 3D Gaussians while reserving 4D Gaussians for dynamic elements. Our method begins with a fully 4D Gaussian representation and iteratively converts temporally invariant Gaussians into 3D, significantly reducing the number of parameters and improving computational efficiency. Meanwhile, dynamic Gaussians retain their full 4D representation, capturing complex motions with high fidelity. Our approach achieves significantly faster training times compared to baseline 4D Gaussian Splatting methods while maintaining or improving the visual quality.

