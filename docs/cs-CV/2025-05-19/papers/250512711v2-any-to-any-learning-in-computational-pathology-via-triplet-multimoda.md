---
layout: default
title: Any-to-Any Learning in Computational Pathology via Triplet Multimodal Pretraining
---

# Any-to-Any Learning in Computational Pathology via Triplet Multimodal Pretraining

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.12711" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.12711v2</a>
  <a href="https://arxiv.org/pdf/2505.12711.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.12711v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.12711v2', 'Any-to-Any Learning in Computational Pathology via Triplet Multimodal Pretraining')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Qichen Sun, Zhengrui Guo, Rui Peng, Hao Chen, Jinzhuo Wang

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-19 (æ›´æ–°: 2025-05-20)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºALTERæ¡†æ¶ä»¥è§£å†³è®¡ç®—ç—…ç†ä¸­çš„å¤šæ¨¡æ€èåˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è®¡ç®—ç—…ç†` `å¤šæ¨¡æ€å­¦ä¹ ` `æ·±åº¦å­¦ä¹ ` `åŸºå› ç»„å­¦` `ç—…ç†æŠ¥å‘Š` `ç”Ÿå­˜é¢„æµ‹` `ç™Œç—‡åˆ†ç±»`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¼‚æ„æ•°æ®èåˆã€ç¼ºå¤±æ¨¡æ€å¤„ç†å’Œå¤šæ ·åŒ–ä¸‹æ¸¸ä»»åŠ¡ä¸Šå­˜åœ¨æ˜¾è‘—æŒ‘æˆ˜ã€‚
2. è®ºæ–‡æå‡ºALTERæ¡†æ¶ï¼Œé€šè¿‡ä¸‰æ¨¡æ€é¢„è®­ç»ƒï¼Œæ”¯æŒçµæ´»çš„æ¨¡æ€ç»„åˆå’Œç¨³å¥çš„è·¨æ¨¡æ€å­¦ä¹ ã€‚
3. åœ¨å¤šä¸ªä¸´åºŠä»»åŠ¡ä¸­ï¼ŒALTERæ¡†æ¶è¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ï¼Œå±•ç¤ºäº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œè®¡ç®—ç—…ç†å­¦å’Œäººå·¥æ™ºèƒ½çš„è¿›å±•æ˜¾è‘—æå‡äº†å¯¹åƒå…†åƒç´ å…¨åˆ‡ç‰‡å›¾åƒåŠå…¶ä»–æ¨¡æ€ï¼ˆå¦‚åŸºå› ç»„å­¦ï¼‰åœ¨ç—…ç†è¯Šæ–­ä¸­çš„åˆ©ç”¨ã€‚å°½ç®¡æ·±åº¦å­¦ä¹ åœ¨ç—…ç†å­¦ä¸­å±•ç°å‡ºå¼ºå¤§æ½œåŠ›ï¼Œä½†ä»é¢ä¸´ä¸€äº›å…³é”®æŒ‘æˆ˜ï¼šå¼‚æ„æ•°æ®ç±»å‹çš„èåˆéœ€è¦è¶…è¶Šç®€å•æ‹¼æ¥çš„å¤æ‚ç­–ç•¥ï¼›ç¼ºå¤±æ¨¡æ€çš„å¸¸è§åœºæ™¯è¦æ±‚çµæ´»çš„ç­–ç•¥ä»¥åœ¨ç¼ºå¤±æŸäº›æ¨¡æ€æ—¶ä»èƒ½ç¨³å¥å­¦ä¹ ï¼›CPathä¸­çš„ä¸‹æ¸¸ä»»åŠ¡å¤šæ ·ï¼Œéœ€ç»Ÿä¸€æ¨¡å‹å¤„ç†æ‰€æœ‰æ¨¡æ€ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºALTERï¼Œä¸€ä¸ªä»»ä½•åˆ°ä»»ä½•çš„ä¸‰æ¨¡æ€é¢„è®­ç»ƒæ¡†æ¶ï¼Œæ•´åˆWSIã€åŸºå› ç»„å­¦å’Œç—…ç†æŠ¥å‘Šã€‚ALTERçš„â€œä»»ä½•â€å¼ºè°ƒå…¶æ¨¡æ€è‡ªé€‚åº”è®¾è®¡ï¼Œæ”¯æŒçµæ´»çš„é¢„è®­ç»ƒï¼Œå¹¶èƒ½å­¦ä¹ è¶…è¶Šä»¥WSIä¸ºä¸­å¿ƒçš„ç¨³å¥è·¨æ¨¡æ€è¡¨ç¤ºã€‚æˆ‘ä»¬åœ¨ç”Ÿå­˜é¢„æµ‹ã€ç™Œç—‡äºšå‹åˆ†ç±»ã€åŸºå› çªå˜é¢„æµ‹å’ŒæŠ¥å‘Šç”Ÿæˆç­‰å¤šä¸ªä¸´åºŠä»»åŠ¡ä¸Šè¯„ä¼°ALTERï¼Œå–å¾—äº†ä¼˜äºæˆ–å¯æ¯”äºæœ€å…ˆè¿›åŸºçº¿çš„è¡¨ç°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³è®¡ç®—ç—…ç†ä¸­å¼‚æ„æ•°æ®èåˆçš„å¤æ‚æ€§ã€ç¼ºå¤±æ¨¡æ€çš„çµæ´»å¤„ç†ä»¥åŠå¤šæ ·åŒ–ä¸‹æ¸¸ä»»åŠ¡çš„ç»Ÿä¸€å»ºæ¨¡é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–äºç®€å•æ‹¼æ¥ï¼Œæ— æ³•æœ‰æ•ˆåº”å¯¹è¿™äº›æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šALTERæ¡†æ¶çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ä¸‰æ¨¡æ€é¢„è®­ç»ƒï¼Œæ”¯æŒä»»æ„æ¨¡æ€ç»„åˆçš„çµæ´»å­¦ä¹ ï¼Œå¼ºè°ƒæ¨¡æ€è‡ªé€‚åº”æ€§ï¼Œèƒ½å¤Ÿåœ¨ç¼ºå¤±æŸäº›æ¨¡æ€æ—¶ä»ç„¶ä¿æŒæ¨¡å‹çš„ç¨³å¥æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šALTERæ¡†æ¶åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šå…¨åˆ‡ç‰‡å›¾åƒï¼ˆWSIï¼‰ã€åŸºå› ç»„æ•°æ®å’Œç—…ç†æŠ¥å‘Šçš„é›†æˆã€‚é€šè¿‡é¢„è®­ç»ƒé˜¶æ®µï¼Œæ¨¡å‹èƒ½å¤Ÿå­¦ä¹ åˆ°è·¨æ¨¡æ€çš„å…±äº«è¡¨ç¤ºï¼Œéšååœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­è¿›è¡Œå¾®è°ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šALTERçš„å…³é”®åˆ›æ–°åœ¨äºå…¶æ¨¡æ€è‡ªé€‚åº”è®¾è®¡ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿçµæ´»å¤„ç†ä¸åŒçš„æ¨¡æ€ç»„åˆï¼Œè¶…è¶Šäº†ä¼ ç»Ÿçš„ä»¥WSIä¸ºä¸­å¿ƒçš„æ–¹æ³•ï¼Œæä¾›äº†æ›´å¹¿æ³›çš„åº”ç”¨å¯èƒ½æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸Šï¼ŒALTERé‡‡ç”¨äº†å¤šå±‚æ¬¡çš„ç‰¹å¾æå–ç½‘ç»œï¼Œç»“åˆäº†é€‚åº”æ€§æŸå¤±å‡½æ•°ï¼Œä»¥ä¼˜åŒ–ä¸åŒæ¨¡æ€é—´çš„ååŒå­¦ä¹ æ•ˆæœã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨ç”Ÿå­˜é¢„æµ‹ã€ç™Œç—‡äºšå‹åˆ†ç±»ã€åŸºå› çªå˜é¢„æµ‹å’ŒæŠ¥å‘Šç”Ÿæˆç­‰ä»»åŠ¡ä¸­ï¼ŒALTERæ¡†æ¶çš„è¡¨ç°ä¼˜äºæˆ–å¯æ¯”äºç°æœ‰æœ€å…ˆè¿›çš„åŸºçº¿æ–¹æ³•ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤šæ¨¡æ€å­¦ä¹ ä¸­çš„æœ‰æ•ˆæ€§å’Œçµæ´»æ€§ã€‚å…·ä½“æ€§èƒ½æ•°æ®è¡¨æ˜ï¼ŒALTERåœ¨å¤šä¸ªä»»åŠ¡ä¸Šå®ç°äº†æ˜¾è‘—çš„æå‡ï¼ŒéªŒè¯äº†å…¶åˆ›æ–°è®¾è®¡çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç™Œç—‡è¯Šæ–­ã€ä¸ªæ€§åŒ–åŒ»ç–—å’Œç”Ÿç‰©ä¿¡æ¯å­¦ç­‰ã€‚é€šè¿‡æ•´åˆå¤šç§æ¨¡æ€æ•°æ®ï¼ŒALTERæ¡†æ¶èƒ½å¤Ÿæå‡ç—…ç†å­¦çš„è¯Šæ–­ç²¾åº¦å’Œæ•ˆç‡ï¼Œæ¨åŠ¨ä¸´åºŠå†³ç­–çš„æ™ºèƒ½åŒ–ã€‚æœªæ¥ï¼ŒALTERæœ‰æœ›åœ¨æ›´å¹¿æ³›çš„åŒ»ç–—æ•°æ®åˆ†æä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in computational pathology and artificial intelligence have significantly enhanced the utilization of gigapixel whole-slide images and and additional modalities (e.g., genomics) for pathological diagnosis. Although deep learning has demonstrated strong potential in pathology, several key challenges persist: (1) fusing heterogeneous data types requires sophisticated strategies beyond simple concatenation due to high computational costs; (2) common scenarios of missing modalities necessitate flexible strategies that allow the model to learn robustly in the absence of certain modalities; (3) the downstream tasks in CPath are diverse, ranging from unimodal to multimodal, cnecessitating a unified model capable of handling all modalities. To address these challenges, we propose ALTER, an any-to-any tri-modal pretraining framework that integrates WSIs, genomics, and pathology reports. The term "any" emphasizes ALTER's modality-adaptive design, enabling flexible pretraining with any subset of modalities, and its capacity to learn robust, cross-modal representations beyond WSI-centric approaches. We evaluate ALTER across extensive clinical tasks including survival prediction, cancer subtyping, gene mutation prediction, and report generation, achieving superior or comparable performance to state-of-the-art baselines.

