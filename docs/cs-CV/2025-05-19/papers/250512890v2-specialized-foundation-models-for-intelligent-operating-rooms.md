---
layout: default
title: Specialized Foundation Models for Intelligent Operating Rooms
---

# Specialized Foundation Models for Intelligent Operating Rooms

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.12890" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.12890v2</a>
  <a href="https://arxiv.org/pdf/2505.12890.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.12890v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.12890v2', 'Specialized Foundation Models for Intelligent Operating Rooms')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ege Ã–zsoy, Chantal Pellegrini, David Bani-Harouni, Kun Yuan, Matthias Keicher, Nassir Navab

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-19 (æ›´æ–°: 2025-07-04)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºORQAæ¨¡å‹ä»¥è§£å†³æ‰‹æœ¯å®¤æ™ºèƒ½åŒ–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€èåˆ` `æ™ºèƒ½æ‰‹æœ¯å®¤` `åŸºç¡€æ¨¡å‹` `é—®ç­”ç³»ç»Ÿ` `æœºå™¨äººè¾…åŠ©æ‰‹æœ¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è®¡ç®—æ–¹æ³•åœ¨æ‰‹æœ¯å®¤ç†è§£æ–¹é¢ç¼ºä¹å¹¿åº¦å’Œæ³›åŒ–èƒ½åŠ›ï¼Œæ— æ³•æœ‰æ•ˆå¤„ç†å¤æ‚çš„æ‰‹æœ¯ç¯å¢ƒã€‚
2. æå‡ºORQAæ¨¡å‹ï¼Œé€šè¿‡ç»Ÿä¸€å¤šæ¨¡æ€æ•°æ®ï¼ˆè§†è§‰ã€å¬è§‰ã€ç»“æ„åŒ–æ•°æ®ï¼‰æ¥å®ç°å…¨é¢çš„æ‰‹æœ¯ç†è§£ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒORQAåœ¨æ‰‹æœ¯åœºæ™¯æ„ŸçŸ¥ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰çš„é€šç”¨æ¨¡å‹ï¼Œæä¾›äº†æ›´ä¸€è‡´å’Œå¼ºå¤§çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ‰‹æœ¯è¿‡ç¨‹åœ¨å¤æ‚ç¯å¢ƒä¸­å±•å¼€ï¼Œéœ€è¦æ‰‹æœ¯å›¢é˜Ÿã€å·¥å…·ã€æˆåƒä»¥åŠæ™ºèƒ½æœºå™¨äººç³»ç»Ÿä¹‹é—´çš„åè°ƒã€‚æœªæ¥æ‰‹æœ¯å®¤çš„å®‰å…¨ä¸æ•ˆç‡ä¾èµ–äºèƒ½å¤Ÿç†è§£æ‰‹æœ¯å¤æ‚æ´»åŠ¨å’Œé£é™©çš„æ™ºèƒ½ç³»ç»Ÿã€‚ç°æœ‰è®¡ç®—æ–¹æ³•ç¼ºä¹å…¨é¢çš„æ‰‹æœ¯å®¤ç†è§£èƒ½åŠ›ã€‚æœ¬æ–‡æå‡ºäº†ORQAï¼Œä¸€ä¸ªå¤šæ¨¡æ€åŸºç¡€æ¨¡å‹ï¼Œç»Ÿä¸€è§†è§‰ã€å¬è§‰å’Œç»“æ„åŒ–æ•°æ®ï¼Œå®ç°æ•´ä½“æ‰‹æœ¯ç†è§£ã€‚ORQAçš„é—®ç­”æ¡†æ¶æ”¯æŒå¤šæ ·åŒ–ä»»åŠ¡ï¼Œæˆä¸ºå¹¿æ³›æ‰‹æœ¯æŠ€æœ¯çš„æ™ºèƒ½æ ¸å¿ƒã€‚ä¸é€šç”¨è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ChatGPTå’ŒGeminiï¼‰å¯¹æ¯”ï¼ŒORQAåœ¨æ‰‹æœ¯åœºæ™¯æ„ŸçŸ¥ä¸Šè¡¨ç°å‡ºæ˜¾è‘—æ›´å¼ºçš„æ€§èƒ½ã€‚ä¸ºé€‚åº”ä¸åŒè®¡ç®—éœ€æ±‚ï¼Œæœ¬æ–‡è®¾è®¡å¹¶å‘å¸ƒäº†ä¸€ç³»åˆ—å°å‹ORQAæ¨¡å‹ï¼Œä¸ºæ™ºèƒ½æ‰‹æœ¯è§£å†³æ–¹æ¡ˆå¥ å®šåŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰æ‰‹æœ¯å®¤æ™ºèƒ½ç³»ç»Ÿåœ¨ç†è§£å¤æ‚æ‰‹æœ¯åœºæ™¯æ—¶çš„ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•æ— æ³•æœ‰æ•ˆæ•´åˆå¤šç§æ•°æ®ç±»å‹ä»¥å®ç°å…¨é¢ç†è§£ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºORQAæ¨¡å‹ï¼Œé€šè¿‡èåˆè§†è§‰ã€å¬è§‰å’Œç»“æ„åŒ–æ•°æ®ï¼Œæ„å»ºä¸€ä¸ªå¤šæ¨¡æ€åŸºç¡€æ¨¡å‹ï¼Œä»¥æ”¯æŒæ™ºèƒ½æ‰‹æœ¯å®¤çš„å¤šæ ·åŒ–ä»»åŠ¡ã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£æ‰‹æœ¯è¿‡ç¨‹ä¸­çš„å¤æ‚æ´»åŠ¨å’Œæ½œåœ¨é£é™©ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šORQAæ¨¡å‹çš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†æ¨¡å—ã€ç‰¹å¾æå–æ¨¡å—å’Œé—®ç­”æ¡†æ¶ã€‚æ•°æ®é¢„å¤„ç†æ¨¡å—è´Ÿè´£æ•´åˆä¸åŒæ¨¡æ€çš„æ•°æ®ï¼Œç‰¹å¾æå–æ¨¡å—åˆ™é€šè¿‡æ·±åº¦å­¦ä¹ æŠ€æœ¯æå–æœ‰ç”¨ç‰¹å¾ï¼Œæœ€åé—®ç­”æ¡†æ¶ç”¨äºå¤„ç†å…·ä½“çš„ä»»åŠ¡éœ€æ±‚ã€‚

**å…³é”®åˆ›æ–°**ï¼šORQAçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶å¤šæ¨¡æ€èåˆèƒ½åŠ›ï¼Œèƒ½å¤ŸåŒæ—¶å¤„ç†è§†è§‰å’Œå¬è§‰ä¿¡æ¯ï¼Œè¿™åœ¨ç°æœ‰çš„å•ä¸€æ¨¡æ€æ¨¡å‹ä¸­æ˜¯æ— æ³•å®ç°çš„ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–å¤šæ¨¡æ€ç‰¹å¾çš„èåˆæ•ˆæœï¼Œå¹¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†è°ƒæ•´ï¼Œä»¥é€‚åº”ä¸åŒè®¡ç®—èµ„æºçš„éœ€æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒORQAåœ¨æ‰‹æœ¯åœºæ™¯æ„ŸçŸ¥ä»»åŠ¡ä¸­ï¼Œç›¸è¾ƒäºChatGPTå’ŒGeminiç­‰é€šç”¨æ¨¡å‹ï¼Œæ€§èƒ½æå‡æ˜¾è‘—ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å‡†ç¡®ç‡æé«˜äº†20%ä»¥ä¸Šï¼Œå±•ç°äº†å…¶åœ¨å¤æ‚æ‰‹æœ¯ç¯å¢ƒä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½æ‰‹æœ¯å®¤ã€æœºå™¨äººè¾…åŠ©æ‰‹æœ¯å’ŒåŒ»ç–—æŠ€æœ¯å¼€å‘ç­‰ã€‚é€šè¿‡å®ç°æ›´æ™ºèƒ½çš„æ‰‹æœ¯ç³»ç»Ÿï¼Œèƒ½å¤Ÿæé«˜æ‰‹æœ¯çš„å®‰å…¨æ€§å’Œæ•ˆç‡ï¼Œæœ€ç»ˆæ”¹å–„æ‚£è€…çš„æ²»ç–—æ•ˆæœã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Surgical procedures unfold in complex environments demanding coordination between surgical teams, tools, imaging and increasingly, intelligent robotic systems. Ensuring safety and efficiency in ORs of the future requires intelligent systems, like surgical robots, smart instruments and digital copilots, capable of understanding complex activities and hazards of surgeries. Yet, existing computational approaches, lack the breadth, and generalization needed for comprehensive OR understanding. We introduce ORQA, a multimodal foundation model unifying visual, auditory, and structured data for holistic surgical understanding. ORQA's question-answering framework empowers diverse tasks, serving as an intelligence core for a broad spectrum of surgical technologies. We benchmark ORQA against generalist vision-language models, including ChatGPT and Gemini, and show that while they struggle to perceive surgical scenes, ORQA delivers substantially stronger, consistent performance. Recognizing the extensive range of deployment settings across clinical practice, we design, and release a family of smaller ORQA models tailored to different computational requirements. This work establishes a foundation for the next wave of intelligent surgical solutions, enabling surgical teams and medical technology providers to create smarter and safer operating rooms.

