---
layout: default
title: Just Dance with $Ï€$! A Poly-modal Inductor for Weakly-supervised Video Anomaly Detection
---

# Just Dance with $Ï€$! A Poly-modal Inductor for Weakly-supervised Video Anomaly Detection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.13123" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.13123v1</a>
  <a href="https://arxiv.org/pdf/2505.13123.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.13123v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.13123v1', 'Just Dance with $Ï€$! A Poly-modal Inductor for Weakly-supervised Video Anomaly Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Snehashis Majhi, Giacomo D'Amicantonio, Antitza Dantcheva, Quan Kong, Lorenzo Garattoni, Gianpiero Francesca, Egor Bondarev, Francois Bremond

**åˆ†ç±»**: cs.CV, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-19

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPI-VADä»¥è§£å†³å¼±ç›‘ç£è§†é¢‘å¼‚å¸¸æ£€æµ‹ä¸­çš„æ¨¡æ€ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `è§†é¢‘å¼‚å¸¸æ£€æµ‹` `å¼±ç›‘ç£å­¦ä¹ ` `å¤šæ¨¡æ€èåˆ` `æ·±åº¦å­¦ä¹ ` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¼±ç›‘ç£è§†é¢‘å¼‚å¸¸æ£€æµ‹æ–¹æ³•ä»…ä¾èµ–RGBç‰¹å¾ï¼Œéš¾ä»¥æœ‰æ•ˆåŒºåˆ†ç›¸ä¼¼äº‹ä»¶ï¼Œå¯¼è‡´æ£€æµ‹å¯é æ€§ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºçš„PI-VADæ¡†æ¶é€šè¿‡å¼•å…¥äº”ç§é¢å¤–æ¨¡æ€ï¼Œå¢å¼ºäº†RGBç‰¹å¾çš„è¡¨è¾¾èƒ½åŠ›ï¼Œä»¥æé«˜å¼‚å¸¸æ£€æµ‹çš„å‡†ç¡®æ€§ã€‚
3. PI-VADåœ¨å¤šä¸ªçœŸå®åœºæ™¯æ•°æ®é›†ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§å’Œä¼˜åŠ¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¼±ç›‘ç£è§†é¢‘å¼‚å¸¸æ£€æµ‹ï¼ˆVADï¼‰æ–¹æ³•é€šå¸¸ä»…ä¾èµ–äºRGBæ—¶ç©ºç‰¹å¾ï¼Œè¿™é™åˆ¶äº†å…¶åœ¨ç°å®åœºæ™¯ä¸­çš„å¯é æ€§ã€‚RGBç‰¹å¾åœ¨åŒºåˆ†å¦‚ç›—çªƒç­‰ç±»åˆ«æ—¶å¹¶ä¸å¤Ÿæ˜æ˜¾ã€‚å› æ­¤ï¼Œä¸ºäº†å®ç°æ›´å¼ºçš„VADï¼Œå¿…é¡»é€šè¿‡é¢å¤–æ¨¡æ€å¢å¼ºRGBç‰¹å¾ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†å¤šæ¨¡æ€è¯±å¯¼æ¡†æ¶PI-VADï¼Œè¯¥æ–¹æ³•é€šè¿‡äº”ç§é¢å¤–æ¨¡æ€å¢å¼ºRGBè¡¨ç¤ºï¼ŒåŒ…æ‹¬ç»†ç²’åº¦è¿åŠ¨ï¼ˆå§¿æ€ï¼‰ã€ä¸‰ç»´åœºæ™¯å’Œå®ä½“è¡¨ç¤ºï¼ˆæ·±åº¦ï¼‰ã€å‘¨å›´ç‰©ä½“ï¼ˆå…¨æ™¯æ©ç ï¼‰ã€å…¨å±€è¿åŠ¨ï¼ˆå…‰æµï¼‰ä»¥åŠè¯­è¨€çº¿ç´¢ï¼ˆVLMï¼‰ã€‚PI-VADåŒ…å«ä¸¤ä¸ªæ’ä»¶æ¨¡å—ï¼Œåˆ†åˆ«ä¸ºä¼ªæ¨¡æ€ç”Ÿæˆæ¨¡å—å’Œè·¨æ¨¡æ€è¯±å¯¼æ¨¡å—ï¼Œèƒ½å¤Ÿç”Ÿæˆæ¨¡æ€ç‰¹å®šçš„åŸå‹è¡¨ç¤ºï¼Œä»è€Œå°†å¤šæ¨¡æ€ä¿¡æ¯å¼•å…¥RGBçº¿ç´¢ã€‚PI-VADåœ¨ä¸‰ä¸ªä¸»è¦VADæ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„å‡†ç¡®æ€§ï¼Œè€Œåœ¨æ¨ç†æ—¶ä¸éœ€è¦äº”ä¸ªæ¨¡æ€éª¨å¹²çš„è®¡ç®—å¼€é”€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¼±ç›‘ç£è§†é¢‘å¼‚å¸¸æ£€æµ‹æ–¹æ³•ä¸­ä»…ä¾èµ–RGBç‰¹å¾å¯¼è‡´çš„æ£€æµ‹å¯é æ€§ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨åŒºåˆ†è§†è§‰ç›¸ä¼¼äº‹ä»¶ï¼ˆå¦‚ç›—çªƒï¼‰æ—¶è¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šPI-VADæ¡†æ¶é€šè¿‡å¼•å…¥äº”ç§é¢å¤–æ¨¡æ€ï¼ˆå§¿æ€ã€æ·±åº¦ã€å…¨æ™¯æ©ç ã€å…‰æµå’Œè¯­è¨€çº¿ç´¢ï¼‰ï¼Œå¢å¼ºRGBè¡¨ç¤ºçš„ç‰¹å¾ï¼Œä»è€Œæå‡å¼‚å¸¸æ£€æµ‹çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPI-VADæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šä¼ªæ¨¡æ€ç”Ÿæˆæ¨¡å—å’Œè·¨æ¨¡æ€è¯±å¯¼æ¨¡å—ã€‚ä¼ªæ¨¡æ€ç”Ÿæˆæ¨¡å—è´Ÿè´£ç”Ÿæˆæ¨¡æ€ç‰¹å®šçš„åŸå‹è¡¨ç¤ºï¼Œè€Œè·¨æ¨¡æ€è¯±å¯¼æ¨¡å—åˆ™å°†å¤šæ¨¡æ€ä¿¡æ¯æ•´åˆåˆ°RGBç‰¹å¾ä¸­ã€‚è¿™äº›æ¨¡å—åœ¨è®­ç»ƒé˜¶æ®µä½¿ç”¨äº”ä¸ªæ¨¡æ€éª¨å¹²è¿›è¡Œè¾…åŠ©ä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šPI-VADçš„ä¸»è¦åˆ›æ–°åœ¨äºé€šè¿‡å¤šæ¨¡æ€èåˆæå‡äº†RGBç‰¹å¾çš„è¡¨è¾¾èƒ½åŠ›ï¼Œæ˜¾è‘—æé«˜äº†è§†é¢‘å¼‚å¸¸æ£€æµ‹çš„æ€§èƒ½ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿä»…ä¾èµ–RGBç‰¹å¾çš„æ£€æµ‹æ–¹æ³•æœ¬è´¨ä¸Šä¸åŒã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒPI-VADé‡‡ç”¨äº†å¤šæ¨¡æ€éª¨å¹²ç½‘ç»œï¼Œç»“åˆäº†ä¸åŒæ¨¡æ€çš„ç‰¹å¾ï¼Œé€šè¿‡ç‰¹å®šçš„æŸå¤±å‡½æ•°ä¼˜åŒ–æ¨¡æ€é—´çš„ååŒä½œç”¨ï¼Œç¡®ä¿åœ¨æ¨ç†æ—¶ä¸å¢åŠ è®¡ç®—å¼€é”€ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

PI-VADåœ¨ä¸‰ä¸ªä¸»è¦è§†é¢‘å¼‚å¸¸æ£€æµ‹æ•°æ®é›†ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„å‡†ç¡®æ€§ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿æ–¹æ³•ï¼Œå±•ç¤ºäº†å…¶åœ¨çœŸå®åœºæ™¯ä¸­çš„æœ‰æ•ˆæ€§ã€‚å…·ä½“è€Œè¨€ï¼ŒPI-VADåœ¨æŸäº›æ•°æ®é›†ä¸Šæé«˜äº†æ£€æµ‹å‡†ç¡®ç‡è¶…è¿‡10%ï¼Œè¯æ˜äº†å¤šæ¨¡æ€èåˆçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç›‘æ§è§†é¢‘åˆ†æã€å…¬å…±å®‰å…¨ã€äº¤é€šç›‘æ§ç­‰ã€‚é€šè¿‡æé«˜è§†é¢‘å¼‚å¸¸æ£€æµ‹çš„å‡†ç¡®æ€§ï¼ŒPI-VADèƒ½å¤Ÿæœ‰æ•ˆæ”¯æŒå®æ—¶ç›‘æ§ç³»ç»Ÿï¼Œå¸®åŠ©è¯†åˆ«å’Œé¢„é˜²æ½œåœ¨çš„å®‰å…¨å¨èƒï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œç¤¾ä¼šå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Weakly-supervised methods for video anomaly detection (VAD) are conventionally based merely on RGB spatio-temporal features, which continues to limit their reliability in real-world scenarios. This is due to the fact that RGB-features are not sufficiently distinctive in setting apart categories such as shoplifting from visually similar events. Therefore, towards robust complex real-world VAD, it is essential to augment RGB spatio-temporal features by additional modalities. Motivated by this, we introduce the Poly-modal Induced framework for VAD: "PI-VAD", a novel approach that augments RGB representations by five additional modalities. Specifically, the modalities include sensitivity to fine-grained motion (Pose), three dimensional scene and entity representation (Depth), surrounding objects (Panoptic masks), global motion (optical flow), as well as language cues (VLM). Each modality represents an axis of a polygon, streamlined to add salient cues to RGB. PI-VAD includes two plug-in modules, namely Pseudo-modality Generation module and Cross Modal Induction module, which generate modality-specific prototypical representation and, thereby, induce multi-modal information into RGB cues. These modules operate by performing anomaly-aware auxiliary tasks and necessitate five modality backbones -- only during training. Notably, PI-VAD achieves state-of-the-art accuracy on three prominent VAD datasets encompassing real-world scenarios, without requiring the computational overhead of five modality backbones at inference.

