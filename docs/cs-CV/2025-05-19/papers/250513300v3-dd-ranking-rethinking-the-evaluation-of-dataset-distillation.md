---
layout: default
title: "DD-Ranking: Rethinking the Evaluation of Dataset Distillation"
---

# DD-Ranking: Rethinking the Evaluation of Dataset Distillation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.13300" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.13300v3</a>
  <a href="https://arxiv.org/pdf/2505.13300.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.13300v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.13300v3', 'DD-Ranking: Rethinking the Evaluation of Dataset Distillation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zekai Li, Xinhao Zhong, Samir Khaki, Zhiyuan Liang, Yuhao Zhou, Mingjia Shi, Ziqiao Wang, Xuanlei Zhao, Wangbo Zhao, Ziheng Qin, Mengxuan Wu, Pengfei Zhou, Haonan Wang, David Junhao Zhang, Jia-Wei Liu, Shaobo Wang, Dai Liu, Linfeng Zhang, Guang Li, Kun Wang, Zheng Zhu, Zhiheng Ma, Joey Tianyi Zhou, Jiancheng Lv, Yaochu Jin, Peihao Wang, Kaipeng Zhang, Lingjuan Lyu, Yiran Huang, Zeynep Akata, Zhiwei Deng, Xindi Wu, George Cazenavette, Yuzhang Shang, Justin Cui, Jindong Gu, Qian Zheng, Hao Ye, Shuo Wang, Xiaobo Wang, Yan Yan, Angela Yao, Mike Zheng Shou, Tianlong Chen, Hakan Bilen, Baharan Mirzasoleiman, Manolis Kellis, Konstantinos N. Plataniotis, Zhangyang Wang, Bo Zhao, Yang You, Kai Wang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-19 (æ›´æ–°: 2025-09-21)

**å¤‡æ³¨**: 20 pages, 4 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDD-Rankingä»¥è§£å†³æ•°æ®é›†è’¸é¦è¯„ä¼°ä¸å‡†ç¡®çš„é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æ•°æ®é›†è’¸é¦` `è¯„ä¼°æ¡†æ¶` `åˆæˆæ•°æ®é›†` `æœºå™¨å­¦ä¹ ` `è®¡ç®—æœºè§†è§‰` `ä¿¡æ¯å¢ç›Š` `æ•°æ®è´¨é‡è¯„åˆ†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ•°æ®é›†è’¸é¦æ–¹æ³•åœ¨è¯„ä¼°æ—¶è¿‡äºä¾èµ–å‡†ç¡®ç‡ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœä¸å›¾åƒè´¨é‡ä¸åŒ¹é…ã€‚
2. æœ¬æ–‡æå‡ºDD-Rankingè¯„ä¼°æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡æ–°çš„è¯„ä¼°æŒ‡æ ‡æ›´å‡†ç¡®åœ°åæ˜ åˆæˆæ•°æ®é›†çš„çœŸå®æ€§èƒ½æå‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒDD-Rankingèƒ½å¤Ÿæ›´å¥½åœ°æ­ç¤ºä¸åŒè’¸é¦æ–¹æ³•çš„å®é™…æ•ˆæœï¼Œæ¨åŠ¨è¯¥é¢†åŸŸçš„å‘å±•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œæ•°æ®é›†è’¸é¦ä¸ºæ•°æ®å‹ç¼©æä¾›äº†å¯é çš„è§£å†³æ–¹æ¡ˆï¼Œè®­ç»ƒäºè¾ƒå°åˆæˆæ•°æ®é›†çš„æ¨¡å‹åœ¨æ€§èƒ½ä¸Šå¯ä¸åŸå§‹æ•°æ®é›†ç›¸åª²ç¾ã€‚ä¸ºè¿›ä¸€æ­¥æå‡åˆæˆæ•°æ®é›†çš„æ€§èƒ½ï¼Œæå‡ºäº†å¤šç§è®­ç»ƒæµç¨‹å’Œä¼˜åŒ–ç›®æ ‡ã€‚ç„¶è€Œï¼Œç°æœ‰çš„è¯„ä¼°æ–¹æ³•å¸¸å¸¸ä¾èµ–äºå‡†ç¡®ç‡ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœä¸å›¾åƒæœ¬èº«çš„è´¨é‡ä¸ä¸€è‡´ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†DD-Rankingï¼Œä¸€ä¸ªç»Ÿä¸€çš„è¯„ä¼°æ¡†æ¶å’Œæ–°çš„è¯„ä¼°æŒ‡æ ‡ï¼Œä»¥æ­ç¤ºä¸åŒæ–¹æ³•æ‰€å®ç°çš„çœŸå®æ€§èƒ½æå‡ï¼Œä»è€Œä¸ºæœªæ¥çš„ç ”ç©¶æä¾›æ›´å…¨é¢å’Œå…¬æ­£çš„è¯„ä¼°æ ‡å‡†ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„æ•°æ®é›†è’¸é¦æ–¹æ³•åœ¨è¯„ä¼°æ—¶å¸¸å¸¸ä¾èµ–äºå‡†ç¡®ç‡ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœæ— æ³•çœŸå®åæ˜ åˆæˆæ•°æ®é›†çš„è´¨é‡ï¼Œç”šè‡³éšæœºé‡‡æ ·çš„å›¾åƒä¹Ÿèƒ½è·å¾—è¾ƒé«˜çš„å‡†ç¡®ç‡ï¼Œè¿™ä¸¥é‡é˜»ç¢äº†æ•°æ®é›†è’¸é¦çš„è¿›å±•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡æå‡ºçš„DD-Rankingæ¡†æ¶æ—¨åœ¨é€šè¿‡å¼•å…¥æ–°çš„è¯„ä¼°æŒ‡æ ‡ï¼Œèšç„¦äºåˆæˆæ•°æ®é›†çš„ä¿¡æ¯å¢å¼ºï¼Œä»è€Œæä¾›æ›´å…¨é¢å’Œå…¬æ­£çš„è¯„ä¼°æ ‡å‡†ï¼Œå¸®åŠ©ç ”ç©¶è€…æ›´å¥½åœ°ç†è§£ä¸åŒè’¸é¦æ–¹æ³•çš„å®é™…æ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDD-Rankingçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†è’¸é¦çš„è®­ç»ƒé˜¶æ®µå’Œè¯„ä¼°é˜¶æ®µã€‚åœ¨è®­ç»ƒé˜¶æ®µï¼Œé‡‡ç”¨æ–°çš„ä¼˜åŒ–ç›®æ ‡å’Œè®­ç»ƒæµç¨‹ï¼›åœ¨è¯„ä¼°é˜¶æ®µï¼Œä½¿ç”¨æ–°çš„è¯„ä¼°æŒ‡æ ‡æ¥è¡¡é‡åˆæˆæ•°æ®é›†çš„æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šDD-Rankingçš„ä¸»è¦åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€å¥—æ–°çš„è¯„ä¼°æŒ‡æ ‡ï¼Œèƒ½å¤Ÿæ›´å‡†ç¡®åœ°åæ˜ åˆæˆæ•°æ®é›†çš„çœŸå®æ€§èƒ½æå‡ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œé¿å…äº†å¯¹å‡†ç¡®ç‡çš„è¿‡åº¦ä¾èµ–ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒDD-Rankingå¼•å…¥äº†å¤šç§è¯„ä¼°æŒ‡æ ‡ï¼Œå¦‚ä¿¡æ¯å¢ç›Šå’Œæ•°æ®è´¨é‡è¯„åˆ†ï¼Œç¡®ä¿è¯„ä¼°ç»“æœèƒ½å¤ŸçœŸå®åæ˜ åˆæˆæ•°æ®é›†çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨DD-Rankingè¯„ä¼°æ¡†æ¶åï¼Œå¤šä¸ªæ•°æ®é›†è’¸é¦æ–¹æ³•çš„æ€§èƒ½æå‡å¾—åˆ°äº†æ›´å‡†ç¡®çš„åæ˜ ï¼Œå°¤å…¶æ˜¯åœ¨ImageNet-1Kç­‰å¤§å‹æ•°æ®é›†ä¸Šï¼Œæ€§èƒ½æå‡å¹…åº¦æ˜¾è‘—ï¼ŒéªŒè¯äº†æ–°è¯„ä¼°æŒ‡æ ‡çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è®¡ç®—æœºè§†è§‰ã€æœºå™¨å­¦ä¹ å’Œæ•°æ®å‹ç¼©ç­‰é¢†åŸŸã€‚é€šè¿‡æä¾›æ›´å‡†ç¡®çš„è¯„ä¼°æ ‡å‡†ï¼ŒDD-Rankingèƒ½å¤Ÿå¸®åŠ©ç ”ç©¶è€…å’Œå·¥ç¨‹å¸ˆæ›´å¥½åœ°ç†è§£å’Œä¼˜åŒ–æ•°æ®é›†è’¸é¦æŠ€æœ¯ï¼Œä»è€Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å®é™…åº”ç”¨å’Œå‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In recent years, dataset distillation has provided a reliable solution for data compression, where models trained on the resulting smaller synthetic datasets achieve performance comparable to those trained on the original datasets. To further improve the performance of synthetic datasets, various training pipelines and optimization objectives have been proposed, greatly advancing the field of dataset distillation. Recent decoupled dataset distillation methods introduce soft labels and stronger data augmentation during the post-evaluation phase and scale dataset distillation up to larger datasets (e.g., ImageNet-1K). However, this raises a question: Is accuracy still a reliable metric to fairly evaluate dataset distillation methods? Our empirical findings suggest that the performance improvements of these methods often stem from additional techniques rather than the inherent quality of the images themselves, with even randomly sampled images achieving superior results. Such misaligned evaluation settings severely hinder the development of DD. Therefore, we propose DD-Ranking, a unified evaluation framework, along with new general evaluation metrics to uncover the true performance improvements achieved by different methods. By refocusing on the actual information enhancement of distilled datasets, DD-Ranking provides a more comprehensive and fair evaluation standard for future research advancements.

