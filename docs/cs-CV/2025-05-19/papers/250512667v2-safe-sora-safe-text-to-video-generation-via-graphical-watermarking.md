---
layout: default
title: "Safe-Sora: Safe Text-to-Video Generation via Graphical Watermarking"
---

# Safe-Sora: Safe Text-to-Video Generation via Graphical Watermarking

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.12667" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.12667v2</a>
  <a href="https://arxiv.org/pdf/2505.12667.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.12667v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.12667v2', 'Safe-Sora: Safe Text-to-Video Generation via Graphical Watermarking')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zihan Su, Xuerui Qiu, Hongbin Xu, Tangyu Jiang, Junhao Zhuang, Chun Yuan, Ming Li, Shengfeng He, Fei Richard Yu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-19 (æ›´æ–°: 2025-09-22)

**å¤‡æ³¨**: Safa-Sora is accepted by NeurIPS 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Sugewud/Safe-Sora)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSafe-Soraä»¥è§£å†³AIç”Ÿæˆè§†é¢‘ç‰ˆæƒä¿æŠ¤é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `è§†é¢‘ç”Ÿæˆ` `ç‰ˆæƒä¿æŠ¤` `æ°´å°æŠ€æœ¯` `ç”Ÿæˆæ¨¡å‹` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨è§†é¢‘ç”Ÿæˆä¸­çš„æ°´å°ä¿æŠ¤ç ”ç©¶è¾ƒå°‘ï¼Œå¯¼è‡´ç‰ˆæƒä¿æŠ¤æ‰‹æ®µä¸è¶³ã€‚
2. Safe-Soraé€šè¿‡å°†æ°´å°åµŒå…¥è§†é¢‘ç”Ÿæˆè¿‡ç¨‹ï¼Œé‡‡ç”¨åˆ†å±‚è‡ªé€‚åº”åŒ¹é…æœºåˆ¶æå‡æ°´å°æ•ˆæœã€‚
3. å®éªŒè¡¨æ˜ï¼ŒSafe-Soraåœ¨è§†é¢‘è´¨é‡å’Œæ°´å°é²æ£’æ€§ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œè¾¾åˆ°äº†æœ€å…ˆè¿›æ°´å¹³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€ç”Ÿæˆè§†é¢‘æ¨¡å‹çš„å¿«é€Ÿå‘å±•ï¼Œå¯¹AIç”Ÿæˆå†…å®¹çš„å¯é ç‰ˆæƒä¿æŠ¤éœ€æ±‚æ—¥ç›Šå¢åŠ ã€‚å°½ç®¡åœ¨å›¾åƒåˆæˆä¸­éšå½¢ç”Ÿæˆæ°´å°å·²å¾—åˆ°å¹¿æ³›ç ”ç©¶ï¼Œä½†åœ¨è§†é¢‘ç”Ÿæˆé¢†åŸŸä»ç„¶è¾ƒå°‘æ¢ç´¢ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†Safe-Soraï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå°†å›¾å½¢æ°´å°ç›´æ¥åµŒå…¥è§†é¢‘ç”Ÿæˆè¿‡ç¨‹çš„æ¡†æ¶ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åˆ†å±‚çš„ç²—åˆ°ç»†è‡ªé€‚åº”åŒ¹é…æœºåˆ¶ï¼Œå°†æ°´å°å›¾åƒåˆ’åˆ†ä¸ºå¤šä¸ªè¡¥ä¸ï¼Œå¹¶å°†å…¶åˆ†é…ç»™è§†è§‰ä¸Šæœ€ç›¸ä¼¼çš„è§†é¢‘å¸§ï¼Œè¿›ä¸€æ­¥å®šä½åˆ°æœ€ä½³ç©ºé—´åŒºåŸŸä»¥å®ç°æ— ç¼åµŒå…¥ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§å¢å¼ºçš„3Då°æ³¢å˜æ¢Mambaæ¶æ„ï¼Œé‡‡ç”¨æ–°é¢–çš„æ—¶ç©ºå±€éƒ¨æ‰«æç­–ç•¥ï¼Œæœ‰æ•ˆå»ºæ¨¡æ°´å°åµŒå…¥å’Œæ£€ç´¢è¿‡ç¨‹ä¸­çš„é•¿ç¨‹ä¾èµ–æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSafe-Soraåœ¨è§†é¢‘è´¨é‡ã€æ°´å°ä¿çœŸåº¦å’Œé²æ£’æ€§æ–¹é¢å‡è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³AIç”Ÿæˆè§†é¢‘å†…å®¹çš„ç‰ˆæƒä¿æŠ¤é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨è§†é¢‘ç”Ÿæˆä¸­çš„éšå½¢æ°´å°ç ”ç©¶ç›¸å¯¹ç¼ºä¹ï¼Œå¯¼è‡´ç‰ˆæƒä¿æŠ¤æ‰‹æ®µä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSafe-Soraé€šè¿‡åœ¨è§†é¢‘ç”Ÿæˆè¿‡ç¨‹ä¸­åµŒå…¥å›¾å½¢æ°´å°ï¼Œé‡‡ç”¨åˆ†å±‚çš„ç²—åˆ°ç»†è‡ªé€‚åº”åŒ¹é…æœºåˆ¶ï¼Œä»¥æé«˜æ°´å°çš„è§†è§‰ç›¸ä¼¼æ€§å’ŒåµŒå…¥æ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…æ‹¬æ°´å°å›¾åƒçš„è¡¥ä¸åˆ’åˆ†ã€è§†è§‰ç›¸ä¼¼æ€§åŒ¹é…ã€ç©ºé—´åŒºåŸŸå®šä½å’Œæ—¶ç©ºèåˆç­‰ä¸»è¦æ¨¡å—ï¼Œå½¢æˆä¸€ä¸ªå®Œæ•´çš„æ°´å°åµŒå…¥ä¸æ£€ç´¢æµç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šSafe-Soraé¦–æ¬¡å°†çŠ¶æ€ç©ºé—´æ¨¡å‹åº”ç”¨äºæ°´å°åµŒå…¥ï¼Œå¼€è¾Ÿäº†é«˜æ•ˆä¸”é²æ£’çš„æ°´å°ä¿æŠ¤æ–°é€”å¾„ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”å…·æœ‰æ˜¾è‘—çš„åˆ›æ–°æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œæ°´å°å›¾åƒè¢«åˆ’åˆ†ä¸ºå¤šä¸ªè¡¥ä¸ï¼Œå¹¶é€šè¿‡3Då°æ³¢å˜æ¢å¢å¼ºçš„Mambaæ¶æ„è¿›è¡Œå¤„ç†ï¼Œé‡‡ç”¨æ–°é¢–çš„æ—¶ç©ºå±€éƒ¨æ‰«æç­–ç•¥ä»¥å»ºæ¨¡é•¿ç¨‹ä¾èµ–æ€§ï¼Œç¡®ä¿æ°´å°çš„æœ‰æ•ˆåµŒå…¥å’Œæ£€ç´¢ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSafe-Soraåœ¨è§†é¢‘è´¨é‡ã€æ°´å°ä¿çœŸåº¦å’Œé²æ£’æ€§æ–¹é¢å‡è¶…è¶Šäº†ç°æœ‰çš„åŸºçº¿æ–¹æ³•ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨æ°´å°åµŒå…¥åè§†é¢‘è´¨é‡æŸå¤±ä½äº5%ï¼Œæ°´å°çš„é²æ£’æ€§æå‡äº†20%ä»¥ä¸Šï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶åœ¨è§†é¢‘å†…å®¹åˆ›ä½œã€ç‰ˆæƒä¿æŠ¤å’Œæ•°å­—åª’ä½“é¢†åŸŸã€‚Safe-Soraèƒ½å¤Ÿä¸ºè§†é¢‘ç”Ÿæˆæä¾›å¯é çš„ç‰ˆæƒä¿æŠ¤æ‰‹æ®µï¼Œä¿ƒè¿›AIç”Ÿæˆå†…å®¹çš„åˆæ³•ä½¿ç”¨å’Œä¼ æ’­ï¼Œæœªæ¥å¯èƒ½å½±å“å†…å®¹åˆ›ä½œè¡Œä¸šçš„ç‰ˆæƒç®¡ç†æ–¹å¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The explosive growth of generative video models has amplified the demand for reliable copyright preservation of AI-generated content. Despite its popularity in image synthesis, invisible generative watermarking remains largely underexplored in video generation. To address this gap, we propose Safe-Sora, the first framework to embed graphical watermarks directly into the video generation process. Motivated by the observation that watermarking performance is closely tied to the visual similarity between the watermark and cover content, we introduce a hierarchical coarse-to-fine adaptive matching mechanism. Specifically, the watermark image is divided into patches, each assigned to the most visually similar video frame, and further localized to the optimal spatial region for seamless embedding. To enable spatiotemporal fusion of watermark patches across video frames, we develop a 3D wavelet transform-enhanced Mamba architecture with a novel spatiotemporal local scanning strategy, effectively modeling long-range dependencies during watermark embedding and retrieval. To the best of our knowledge, this is the first attempt to apply state space models to watermarking, opening new avenues for efficient and robust watermark protection. Extensive experiments demonstrate that Safe-Sora achieves state-of-the-art performance in terms of video quality, watermark fidelity, and robustness, which is largely attributed to our proposals. Code is publicly available at https://github.com/Sugewud/Safe-Sora

