---
layout: default
title: VLC Fusion: Vision-Language Conditioned Sensor Fusion for Robust Object Detection
---

# VLC Fusion: Vision-Language Conditioned Sensor Fusion for Robust Object Detection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.12715" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.12715v1</a>
  <a href="https://arxiv.org/pdf/2505.12715.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.12715v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.12715v1', 'VLC Fusion: Vision-Language Conditioned Sensor Fusion for Robust Object Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Aditya Taparia, Noel Ngu, Mario Leiva, Joshua Shay Kricheli, John Corcoran, Nathaniel D. Bastian, Gerardo Simari, Paulo Shakarian, Ransalu Senanayake

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-19

**å¤‡æ³¨**: 12 pages, 19 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVLC Fusionä»¥è§£å†³å¤šæ¨¡æ€ä¼ æ„Ÿå™¨èåˆä¸­çš„ç¯å¢ƒé€‚åº”æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€èåˆ` `è§†è§‰è¯­è¨€æ¨¡å‹` `ç‰©ä½“æ£€æµ‹` `ç¯å¢ƒé€‚åº”æ€§` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€èåˆæ–¹æ³•åœ¨åº”å¯¹ç¯å¢ƒå˜åŒ–æ—¶ï¼Œéš¾ä»¥è‡ªé€‚åº”åœ°è°ƒæ•´å„æ¨¡æ€çš„æƒé‡ï¼Œå¯¼è‡´æ£€æµ‹æ€§èƒ½ä¸‹é™ã€‚
2. æœ¬æ–‡æå‡ºçš„VLC Fusionæ¡†æ¶åˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œæ ¹æ®ç¯å¢ƒçº¿ç´¢åŠ¨æ€è°ƒæ•´æ¨¡æ€æƒé‡ï¼Œä»è€Œæå‡ç‰©ä½“æ£€æµ‹çš„é²æ£’æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒVLC Fusionåœ¨è‡ªåŠ¨é©¾é©¶å’Œå†›äº‹ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸­ï¼Œæ£€æµ‹ç²¾åº¦æ˜¾è‘—é«˜äºä¼ ç»Ÿèåˆæ–¹æ³•ï¼Œè¡¨ç°å‡ºæ›´å¼ºçš„é€‚åº”æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡èåˆå¤šç§ä¼ æ„Ÿå™¨æ¨¡æ€å¯ä»¥æå‡ç‰©ä½“æ£€æµ‹æ€§èƒ½ï¼Œä½†ç°æœ‰çš„èåˆæ–¹æ³•å¾€å¾€å¿½è§†ç¯å¢ƒæ¡ä»¶å’Œä¼ æ„Ÿå™¨è¾“å…¥çš„å¾®å¦™å˜åŒ–ï¼Œå› æ­¤éš¾ä»¥åœ¨è¿™äº›å˜åŒ–ä¸‹è‡ªé€‚åº”åœ°è°ƒæ•´å„æ¨¡æ€çš„æƒé‡ã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„èåˆæ¡†æ¶â€”â€”è§†è§‰è¯­è¨€æ¡ä»¶èåˆï¼ˆVLC Fusionï¼‰ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰æ ¹æ®ç»†å¾®çš„ç¯å¢ƒçº¿ç´¢æ¥è°ƒèŠ‚èåˆè¿‡ç¨‹ã€‚é€šè¿‡æ•æ‰é«˜å±‚æ¬¡çš„ç¯å¢ƒä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¦‚é»‘æš—ã€é™é›¨å’Œç›¸æœºæ¨¡ç³Šï¼ŒVLMæŒ‡å¯¼æ¨¡å‹æ ¹æ®å½“å‰åœºæ™¯åŠ¨æ€è°ƒæ•´æ¨¡æ€æƒé‡ã€‚æˆ‘ä»¬åœ¨çœŸå®çš„è‡ªåŠ¨é©¾é©¶å’Œå†›äº‹ç›®æ ‡æ£€æµ‹æ•°æ®é›†ä¸Šè¯„ä¼°äº†VLC Fusionï¼Œç»“æœè¡¨æ˜è¯¥æ–¹æ³•åœ¨å·²è§å’Œæœªè§åœºæ™¯ä¸­å‡ä¼˜äºä¼ ç»Ÿçš„èåˆåŸºçº¿ï¼Œæ£€æµ‹ç²¾åº¦å¾—åˆ°äº†æ˜¾è‘—æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¤šæ¨¡æ€ä¼ æ„Ÿå™¨èåˆæ–¹æ³•åœ¨ç¯å¢ƒæ¡ä»¶å˜åŒ–æ—¶ï¼Œæ— æ³•è‡ªé€‚åº”è°ƒæ•´æ¨¡æ€æƒé‡çš„é—®é¢˜ã€‚è¿™ç§ä¸è¶³å¯¼è‡´äº†ç‰©ä½“æ£€æµ‹æ€§èƒ½çš„ä¸‹é™ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚æˆ–æœªçŸ¥åœºæ™¯ä¸­ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šVLC Fusionçš„æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰æ¥æ•æ‰ç¯å¢ƒçš„é«˜å±‚æ¬¡ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»è€ŒæŒ‡å¯¼æ¨¡æ€æƒé‡çš„åŠ¨æ€è°ƒæ•´ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”ä¸åŒçš„ç¯å¢ƒæ¡ä»¶ï¼Œæé«˜æ£€æµ‹çš„é²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVLC Fusionçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®è¾“å…¥æ¨¡å—ã€è§†è§‰è¯­è¨€æ¨¡å‹æ¨¡å—å’Œèåˆå†³ç­–æ¨¡å—ã€‚æ•°æ®è¾“å…¥æ¨¡å—è´Ÿè´£æ¥æ”¶æ¥è‡ªä¸åŒä¼ æ„Ÿå™¨ï¼ˆå¦‚å›¾åƒã€æ¿€å…‰é›·è¾¾å’Œä¸­æ³¢çº¢å¤–ï¼‰çš„æ•°æ®ï¼ŒVLMæ¨¡å—åˆ™åˆ†æç¯å¢ƒä¸Šä¸‹æ–‡ï¼Œæœ€åèåˆå†³ç­–æ¨¡å—æ ¹æ®VLMçš„è¾“å‡ºåŠ¨æ€è°ƒæ•´å„æ¨¡æ€çš„æƒé‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šVLC Fusionçš„ä¸»è¦åˆ›æ–°åœ¨äºå¼•å…¥è§†è§‰è¯­è¨€æ¨¡å‹æ¥æŒ‡å¯¼æ¨¡æ€èåˆè¿‡ç¨‹ï¼Œè¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„å›ºå®šæƒé‡æˆ–ç®€å•åŠ æƒæ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ ¹æ®å®æ—¶ç¯å¢ƒå˜åŒ–è¿›è¡Œçµæ´»è°ƒæ•´ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒVLC Fusioné‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ¨¡æ€æƒé‡çš„è°ƒæ•´è¿‡ç¨‹ï¼Œå¹¶ä½¿ç”¨äº†æ·±åº¦ç¥ç»ç½‘ç»œç»“æ„æ¥å®ç°VLMçš„åŠŸèƒ½ã€‚æ­¤å¤–ï¼Œæ¨¡å‹çš„å‚æ•°è®¾ç½®ç»è¿‡ç²¾å¿ƒè°ƒè¯•ï¼Œä»¥ç¡®ä¿åœ¨ä¸åŒåœºæ™¯ä¸‹çš„æœ€ä½³æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼ŒVLC Fusionåœ¨è‡ªåŠ¨é©¾é©¶å’Œå†›äº‹ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸Šå‡è¡¨ç°å‡ºè‰²ï¼Œç›¸è¾ƒäºä¼ ç»ŸèåˆåŸºçº¿ï¼Œæ£€æµ‹ç²¾åº¦æå‡å¹…åº¦è¾¾åˆ°10%ä»¥ä¸Šï¼Œå°¤å…¶åœ¨å¤æ‚ç¯å¢ƒä¸‹çš„é€‚åº”æ€§æ˜¾è‘—å¢å¼ºï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

VLC Fusionçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨è‡ªåŠ¨é©¾é©¶ã€æ— äººæœºç›‘æ§å’Œå†›äº‹ç›®æ ‡è¯†åˆ«ç­‰åœºæ™¯ä¸­ã€‚é€šè¿‡æé«˜ç‰©ä½“æ£€æµ‹çš„é²æ£’æ€§ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ˜¾è‘—æå‡ç³»ç»Ÿåœ¨å¤æ‚ç¯å¢ƒä¸‹çš„å®‰å…¨æ€§å’Œå¯é æ€§ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ™ºèƒ½äº¤é€šå’Œå®‰å…¨ç›‘æ§æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Although fusing multiple sensor modalities can enhance object detection performance, existing fusion approaches often overlook subtle variations in environmental conditions and sensor inputs. As a result, they struggle to adaptively weight each modality under such variations. To address this challenge, we introduce Vision-Language Conditioned Fusion (VLC Fusion), a novel fusion framework that leverages a Vision-Language Model (VLM) to condition the fusion process on nuanced environmental cues. By capturing high-level environmental context such as as darkness, rain, and camera blurring, the VLM guides the model to dynamically adjust modality weights based on the current scene. We evaluate VLC Fusion on real-world autonomous driving and military target detection datasets that include image, LIDAR, and mid-wave infrared modalities. Our experiments show that VLC Fusion consistently outperforms conventional fusion baselines, achieving improved detection accuracy in both seen and unseen scenarios.

