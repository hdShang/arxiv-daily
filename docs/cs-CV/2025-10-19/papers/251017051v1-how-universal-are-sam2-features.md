---
layout: default
title: How Universal Are SAM2 Features?
---

# How Universal Are SAM2 Features?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.17051" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.17051v1</a>
  <a href="https://arxiv.org/pdf/2510.17051.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.17051v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.17051v1', 'How Universal Are SAM2 Features?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Masoud Khairi Atani, Alon Harell, Hyomin Choi, Runyu Yang, Fabien Racape, Ivan V. Bajic

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-19

**å¤‡æ³¨**: This work has been accepted for publication in IEEE Picture Coding Symposium (PCS) 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é‡åŒ–é€šç”¨è§†è§‰æ¨¡å‹ä¸åˆ†å‰²ä¸“ç”¨æ¨¡å‹ç‰¹å¾çš„æ³›åŒ–èƒ½åŠ›å·®å¼‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `è§†è§‰åŸºç¡€æ¨¡å‹` `ç‰¹å¾é€šç”¨æ€§` `ç‰¹å¾ä¸“ä¸šåŒ–` `ä¿¡æ¯è®º` `è¡¨å¾å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰é€šç”¨è§†è§‰æ¨¡å‹ä¸ä¸“ç”¨æ¨¡å‹åœ¨ç‰¹å¾ç¼–ç æ•ˆç‡ä¸Šå­˜åœ¨æƒè¡¡ï¼Œä½†å…¶å†…åœ¨æœºåˆ¶å°šæœªå……åˆ†ç†è§£ã€‚
2. è®ºæ–‡æ ¸å¿ƒæ€æƒ³æ˜¯é‡åŒ–é€šç”¨æ¨¡å‹Hieraä¸åˆ†å‰²ä¸“ç”¨æ¨¡å‹SAM2åœ¨ä¸åŒä»»åŠ¡ä¸Šçš„æ€§èƒ½å·®å¼‚ï¼Œä»¥æ­¤è¯„ä¼°ç‰¹å¾ä¸“ä¸šåŒ–çš„ä»£ä»·ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒSAM2åœ¨ç©ºé—´ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨è¯­ä¹‰ä»»åŠ¡ä¸Šä¸å¦‚Hieraï¼Œæ­ç¤ºäº†ç‰¹å¾ä¸“ä¸šåŒ–å¸¦æ¥çš„ä¿¡æ¯æŸå¤±ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ç ”ç©¶äº†é€šç”¨è§†è§‰åŸºç¡€æ¨¡å‹å’Œä¸“ç”¨æ¨¡å‹ä¹‹é—´çš„æƒè¡¡ï¼Œè¿™å¯¹é«˜æ•ˆçš„ç‰¹å¾ç¼–ç è®¾è®¡è‡³å…³é‡è¦ï¼Œä½†å°šæœªè¢«å®Œå…¨ç†è§£ã€‚é€šè¿‡æ¯”è¾ƒé€šç”¨Hieraç¼–ç å™¨å’Œåˆ†å‰²ä¸“ç”¨æ¨¡å‹SAM2çš„ç‰¹å¾é€šç”¨æ€§ï¼Œæˆ‘ä»¬æ¢è®¨äº†è¿™ç§æƒè¡¡ã€‚ä½¿ç”¨è½»é‡çº§å¯è®­ç»ƒé¢ˆéƒ¨ç½‘ç»œæ¥æ¢æµ‹å…¶å†»ç»“ç‰¹å¾çš„é€‚åº”æ€§ï¼Œæˆ‘ä»¬é‡åŒ–äº†ä¸“ä¸šåŒ–çš„ä¿¡æ¯è®ºæˆæœ¬ã€‚ç»“æœè¡¨æ˜ï¼Œè™½ç„¶SAM2çš„ä¸“ä¸šåŒ–åœ¨æ·±åº¦ä¼°è®¡ç­‰ç©ºé—´ç›¸å…³ä»»åŠ¡ä¸­éå¸¸æœ‰æ•ˆï¼Œä½†è¿™æ˜¯æœ‰ä»£ä»·çš„ã€‚åœ¨å§¿æ€ä¼°è®¡å’Œå›¾åƒæè¿°ç­‰æ¦‚å¿µä¸Šè¾ƒè¿œçš„ä»»åŠ¡ä¸­ï¼ŒSAM2ç¼–ç å™¨çš„æ€§èƒ½ä¸å¦‚å…¶é€šç”¨å‰è¾ˆHieraï¼Œè¿™è¡¨æ˜æ›´å¹¿æ³›çš„è¯­ä¹‰ä¿¡æ¯å­˜åœ¨å¯è¡¡é‡çš„æŸå¤±ã€‚å¯¹SAM2çš„æ–°å‹è·¨é¢ˆéƒ¨åˆ†æè¡¨æ˜ï¼Œæ¯ä¸ªçº§åˆ«çš„é€‚åº”éƒ½ä¼šäº§ç”Ÿè¿›ä¸€æ­¥çš„è¡¨å¾ç“¶é¢ˆã€‚æˆ‘ä»¬çš„åˆ†æé˜æ˜äº†ç‰¹å¾é€šç”¨æ€§ä¸­çš„è¿™äº›æƒè¡¡ï¼Œä¸ºè®¾è®¡ç”¨äºå„ç§ä¸‹æ¸¸åº”ç”¨çš„é«˜æ•ˆç‰¹å¾ç¼–ç å’Œé€‚åº”ç­–ç•¥æä¾›äº†é‡åŒ–åŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³é€šç”¨è§†è§‰æ¨¡å‹å’Œåˆ†å‰²ä¸“ç”¨æ¨¡å‹åœ¨ç‰¹å¾è¡¨è¾¾èƒ½åŠ›ä¸Šçš„å·®å¼‚é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹å¯¹è¿™ç§å·®å¼‚çš„é‡åŒ–åˆ†æï¼Œæ— æ³•æŒ‡å¯¼é«˜æ•ˆçš„ç‰¹å¾ç¼–ç è®¾è®¡ã€‚å…·ä½“æ¥è¯´ï¼Œé€šç”¨æ¨¡å‹è™½ç„¶é€‚ç”¨èŒƒå›´å¹¿ï¼Œä½†åœ¨ç‰¹å®šä»»åŠ¡ä¸Šå¯èƒ½æ•ˆç‡ä¸é«˜ï¼›è€Œä¸“ç”¨æ¨¡å‹è™½ç„¶åœ¨ç‰¹å®šä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†æ³›åŒ–èƒ½åŠ›å—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ä¿¡æ¯è®ºçš„æ–¹æ³•ï¼Œé‡åŒ–é€šç”¨æ¨¡å‹å’Œä¸“ç”¨æ¨¡å‹åœ¨ä¸åŒä»»åŠ¡ä¸Šçš„æ€§èƒ½å·®å¼‚ï¼Œä»¥æ­¤è¯„ä¼°ç‰¹å¾ä¸“ä¸šåŒ–çš„ä»£ä»·ã€‚é€šè¿‡è®¾è®¡è½»é‡çº§çš„å¯è®­ç»ƒé¢ˆéƒ¨ç½‘ç»œï¼Œæ¢æµ‹å†»ç»“ç‰¹å¾çš„é€‚åº”æ€§ï¼Œä»è€Œè¡¡é‡æ¨¡å‹åœ¨ä¸åŒä»»åŠ¡ä¸Šçš„ä¿¡æ¯æŸå¤±ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦çš„ç¼–ç å™¨ï¼šé€šç”¨ç¼–ç å™¨Hieraå’Œåˆ†å‰²ä¸“ç”¨ç¼–ç å™¨SAM2ã€‚è¿™ä¸¤ä¸ªç¼–ç å™¨çš„è¾“å‡ºç‰¹å¾è¢«è¾“å…¥åˆ°ä¸åŒçš„è½»é‡çº§é¢ˆéƒ¨ç½‘ç»œä¸­ï¼Œè¿™äº›é¢ˆéƒ¨ç½‘ç»œé’ˆå¯¹ä¸åŒçš„ä¸‹æ¸¸ä»»åŠ¡è¿›è¡Œè®­ç»ƒï¼Œä¾‹å¦‚æ·±åº¦ä¼°è®¡ã€å§¿æ€ä¼°è®¡å’Œå›¾åƒæè¿°ã€‚é€šè¿‡æ¯”è¾ƒä¸åŒç¼–ç å™¨åœ¨ä¸åŒä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œå¯ä»¥è¯„ä¼°å…¶ç‰¹å¾çš„é€šç”¨æ€§å’Œä¸“ä¸šæ€§ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜è¿›è¡Œäº†è·¨é¢ˆéƒ¨åˆ†æï¼Œä»¥ç ”ç©¶ä¸åŒçº§åˆ«çš„é€‚åº”å¦‚ä½•å½±å“è¡¨å¾èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºé‡åŒ–äº†é€šç”¨æ¨¡å‹å’Œä¸“ç”¨æ¨¡å‹ä¹‹é—´çš„ç‰¹å¾å·®å¼‚ï¼Œå¹¶æ­ç¤ºäº†ç‰¹å¾ä¸“ä¸šåŒ–å¸¦æ¥çš„ä¿¡æ¯æŸå¤±ã€‚é€šè¿‡è®¾è®¡è½»é‡çº§çš„é¢ˆéƒ¨ç½‘ç»œï¼Œå¯ä»¥æœ‰æ•ˆåœ°æ¢æµ‹å†»ç»“ç‰¹å¾çš„é€‚åº”æ€§ï¼Œä»è€Œè¯„ä¼°æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè·¨é¢ˆéƒ¨åˆ†æä¹Ÿä¸ºç†è§£ä¸åŒçº§åˆ«çš„é€‚åº”å¦‚ä½•å½±å“è¡¨å¾èƒ½åŠ›æä¾›äº†æ–°çš„è§†è§’ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨è½»é‡çº§çš„å¯è®­ç»ƒé¢ˆéƒ¨ç½‘ç»œï¼Œä»¥å‡å°‘å¯¹åŸå§‹ç‰¹å¾çš„å¹²æ‰°ï¼›2) é€‰æ‹©å…·æœ‰ä»£è¡¨æ€§çš„ä¸‹æ¸¸ä»»åŠ¡ï¼ŒåŒ…æ‹¬ç©ºé—´ç›¸å…³çš„ä»»åŠ¡ï¼ˆå¦‚æ·±åº¦ä¼°è®¡ï¼‰å’Œè¯­ä¹‰ç›¸å…³çš„ä»»åŠ¡ï¼ˆå¦‚å§¿æ€ä¼°è®¡å’Œå›¾åƒæè¿°ï¼‰ï¼›3) è®¾è®¡è·¨é¢ˆéƒ¨åˆ†æï¼Œä»¥ç ”ç©¶ä¸åŒçº§åˆ«çš„é€‚åº”å¦‚ä½•å½±å“è¡¨å¾èƒ½åŠ›ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ï¼ˆæœªçŸ¥ï¼‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒSAM2åœ¨æ·±åº¦ä¼°è®¡ç­‰ç©ºé—´ç›¸å…³ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨å§¿æ€ä¼°è®¡å’Œå›¾åƒæè¿°ç­‰æ¦‚å¿µä¸Šè¾ƒè¿œçš„ä»»åŠ¡ä¸­ï¼Œå…¶æ€§èƒ½ä¸å¦‚é€šç”¨æ¨¡å‹Hieraã€‚è¿™è¡¨æ˜SAM2çš„ä¸“ä¸šåŒ–æ˜¯ä»¥ç‰ºç‰²æ›´å¹¿æ³›çš„è¯­ä¹‰ä¿¡æ¯ä¸ºä»£ä»·çš„ã€‚æ­¤å¤–ï¼Œè·¨é¢ˆéƒ¨åˆ†æè¡¨æ˜ï¼Œæ¯ä¸ªçº§åˆ«çš„é€‚åº”éƒ½ä¼šäº§ç”Ÿè¿›ä¸€æ­¥çš„è¡¨å¾ç“¶é¢ˆã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ï¼ˆæœªçŸ¥ï¼‰ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæŒ‡å¯¼è§†è§‰åŸºç¡€æ¨¡å‹çš„é€‰æ‹©å’Œè®¾è®¡ï¼Œä¾‹å¦‚ï¼Œåœ¨èµ„æºå—é™çš„åœºæ™¯ä¸‹ï¼Œå¯ä»¥æ ¹æ®å…·ä½“ä»»åŠ¡é€‰æ‹©åˆé€‚çš„æ¨¡å‹ï¼Œé¿å…è¿‡åº¦ä¸“ä¸šåŒ–å¸¦æ¥çš„ä¿¡æ¯æŸå¤±ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å¯ä»¥ç”¨äºè®¾è®¡æ›´é«˜æ•ˆçš„ç‰¹å¾ç¼–ç å’Œé€‚åº”ç­–ç•¥ï¼Œä»è€Œæé«˜è§†è§‰æ¨¡å‹çš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶å¯ä»¥æ‰©å±•åˆ°å…¶ä»–ç±»å‹çš„æ¨¡å‹å’Œä»»åŠ¡ï¼Œä¾‹å¦‚ï¼Œè‡ªç„¶è¯­è¨€å¤„ç†å’Œè¯­éŸ³è¯†åˆ«ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The trade-off between general-purpose foundation vision models and their specialized counterparts is critical for efficient feature coding design and is not yet fully understood. We investigate this trade-off by comparing the feature versatility of the general-purpose Hiera encoder against the segmentation-specialized Segment Anything Model 2 (SAM2). Using a lightweight, trainable neck to probe the adaptability of their frozen features, we quantify the information-theoretic cost of specialization. Our results reveal that while SAM2's specialization is highly effective for spatially-related tasks like depth estimation, it comes at a cost. The specialized SAM2 encoder underperforms its generalist predecessor, Hiera, on conceptually distant tasks such as pose estimation and image captioning, demonstrating a measurable loss of broader semantic information. A novel cross-neck analysis on SAM2 reveals that each level of adaptation creates a further representational bottleneck. Our analysis illuminates these trade-offs in feature universality, providing a quantitative foundation for designing efficient feature coding and adaptation strategies for diverse downstream applications.

