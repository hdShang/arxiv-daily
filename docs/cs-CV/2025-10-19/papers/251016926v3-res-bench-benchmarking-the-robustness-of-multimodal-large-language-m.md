---
layout: default
title: Res-Bench: Benchmarking the Robustness of Multimodal Large Language Models to Dynamic Resolution Input
---

# Res-Bench: Benchmarking the Robustness of Multimodal Large Language Models to Dynamic Resolution Input

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.16926" target="_blank" class="toolbar-btn">arXiv: 2510.16926v3</a>
    <a href="https://arxiv.org/pdf/2510.16926.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.16926v3" 
            onclick="toggleFavorite(this, '2510.16926v3', 'Res-Bench: Benchmarking the Robustness of Multimodal Large Language Models to Dynamic Resolution Input')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Chenxu Li, Zhicai Wang, Yuan Sheng, Xingyu Zhu, Yanbin Hao, Xiang Wang

**ÂàÜÁ±ª**: cs.CV, cs.CL

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-19 (Êõ¥Êñ∞: 2025-11-14)

**Â§áÊ≥®**: 23 pages

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Res-BenchÔºåËØÑ‰º∞Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÂú®Âä®ÊÄÅÂàÜËæ®ÁéáËæìÂÖ•‰∏ãÁöÑÈ≤ÅÊ£íÊÄß**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã` `ÂàÜËæ®ÁéáÈ≤ÅÊ£íÊÄß` `Âü∫ÂáÜÊµãËØï` `ÊÄßËÉΩËØÑ‰º∞` `Âä®ÊÄÅÂàÜËæ®Áéá` `È≤ÅÊ£íÊÄßÊåáÊ†á` `Ê®°ÂûãÂæÆË∞É`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâMLLMËØÑ‰º∞‰æßÈáçËØ≠‰πâÊÄßËÉΩÔºåÂøΩÁï•‰∫ÜÊ®°ÂûãÂú®‰∏çÂêåÂàÜËæ®Áéá‰∏ãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ
2. Res-BenchÂü∫ÂáÜÂíåËØÑ‰º∞Ê°ÜÊû∂ÔºåÈÄöËøáÈ≤ÅÊ£íÊÄßÊåáÊ†áËØÑ‰º∞Ê®°ÂûãÂú®‰∏çÂêåÂàÜËæ®Áéá‰∏ãÁöÑÊÄßËÉΩÁ®≥ÂÆöÊÄß„ÄÇ
3. ÂÆûÈ™åÂàÜÊûê‰∫ÜÊ®°ÂûãÂíå‰ªªÂä°ÁöÑÈ≤ÅÊ£íÊÄßÔºå‰ª•ÂèäÈ¢ÑÂ§ÑÁêÜÂíåÂæÆË∞ÉÂØπÁ®≥ÂÆöÊÄßÁöÑÂΩ±Âìç„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã(MLLM)Ë∂äÊù•Ë∂äÂ§öÂú∞ÊîØÊåÅÂä®ÊÄÅÂõæÂÉèÂàÜËæ®Áéá„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑËØÑ‰º∞ËåÉÂºè‰∏ªË¶ÅËØÑ‰º∞ËØ≠‰πâÊÄßËÉΩÔºåÂøΩÁï•‰∫Ü‰∏Ä‰∏™ÂÖ≥ÈîÆÈóÆÈ¢òÔºåÂç≥ÂàÜËæ®ÁéáÈ≤ÅÊ£íÊÄß‚Äî‚ÄîÊÄßËÉΩÂú®‰∏çÂêåËæìÂÖ•ÂàÜËæ®Áéá‰∏ãÊòØÂê¶‰øùÊåÅÁ®≥ÂÆö„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™Â∑ÆË∑ùÔºåÊàë‰ª¨ÂºïÂÖ•‰∫ÜRes-BenchÔºåËøôÊòØ‰∏Ä‰∏™ÂÖ®Èù¢ÁöÑÂü∫ÂáÜÔºåÂåÖÂê´14,400‰∏™Ê†∑Êú¨ÔºåË∑®Ë∂ä12‰∏™ÂàÜËæ®ÁéáÁ∫ßÂà´ÂíåÂÖ≠‰∏™Ê†∏ÂøÉËÉΩÂäõÁª¥Â∫¶„ÄÇÊàë‰ª¨ËÆæËÆ°‰∫Ü‰∏Ä‰∏™Êñ∞È¢ñÁöÑËØÑ‰º∞Ê°ÜÊû∂ÔºåË∂ÖË∂ä‰∫Ü‰º†ÁªüÁöÑÂáÜÁ°ÆÊÄßÊåáÊ†áÔºå‰ª•ÊçïÊçâÊÄßËÉΩÁ®≥ÂÆöÊÄß„ÄÇËØ•Ê°ÜÊû∂ÂºïÂÖ•‰∫ÜÂ§ö‰∏™È≤ÅÊ£íÊÄßÊåáÊ†áÔºöSpearmanÁõ∏ÂÖ≥ÊÄßÁî®‰∫éËØÑ‰º∞ÂàÜËæ®Áéá-ÊÄßËÉΩË∂ãÂäøÔºå‰ª•ÂèäÁªùÂØπ/Áõ∏ÂØπËøûÁª≠ËØØÂ∑Æ(ACE/RCE)Áî®‰∫éÊµãÈáèÊÄßËÉΩÊ≥¢Âä®„ÄÇ‰ΩøÁî®Ëøô‰∫õÊåáÊ†áÔºåÊàë‰ª¨ÂØπÈ¢ÜÂÖàÁöÑMLLMËøõË°å‰∫ÜÂ§ßËßÑÊ®°ËØÑ‰º∞„ÄÇÊàë‰ª¨ÁöÑÂàÜÊûêÂåÖÊã¨Ôºö(1)‰ª•Ê®°Âûã‰∏∫‰∏≠ÂøÉÂíå‰ª•‰ªªÂä°‰∏∫‰∏≠ÂøÉÁöÑÈ≤ÅÊ£íÊÄßÊ£ÄÊü•Ôºå(2)ÂØπÂåÖÊã¨Â°´ÂÖÖÂíåË∂ÖÂàÜËæ®ÁéáÂú®ÂÜÖÁöÑÈ¢ÑÂ§ÑÁêÜÁ≠ñÁï•ÁöÑË∞ÉÊü•Ôºå‰ª•Âèä(3)ÂØπÁî®‰∫éÂ¢ûÂº∫Á®≥ÂÆöÊÄßÁöÑÂæÆË∞ÉÁöÑÊé¢Á¥¢„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÁöÑÂ§ßÂûãÂ§öÊ®°ÊÄÅÊ®°ÂûãÔºàMLLMÔºâÂú®Â§ÑÁêÜÂõæÂÉèÊó∂ÔºåËôΩÁÑ∂ÊîØÊåÅÂä®ÊÄÅÂàÜËæ®ÁéáËæìÂÖ•Ôºå‰ΩÜÁº∫‰πèÂØπÊ®°ÂûãÂú®‰∏çÂêåÂàÜËæ®Áéá‰∏ãÊÄßËÉΩÁ®≥ÂÆöÊÄßÁöÑÁ≥ªÁªüËØÑ‰º∞„ÄÇÁé∞ÊúâÁöÑËØÑ‰º∞ÊñπÊ≥ï‰∏ªË¶ÅÂÖ≥Ê≥®ËØ≠‰πâÁêÜËß£ÁöÑÂáÜÁ°ÆÊÄßÔºåÂøΩÁï•‰∫ÜÂàÜËæ®ÁéáÂèòÂåñÂØπÊ®°ÂûãÊÄßËÉΩÁöÑÂΩ±ÂìçÔºåËøôÂèØËÉΩÂØºËá¥Ê®°ÂûãÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠Ë°®Áé∞‰∏çÁ®≥ÂÆö„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöRes-BenchÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÊûÑÂª∫‰∏Ä‰∏™ÂÖ®Èù¢ÁöÑÂü∫ÂáÜÊµãËØïÈõÜÔºåÂπ∂ËÆæËÆ°Áõ∏Â∫îÁöÑËØÑ‰º∞ÊåáÊ†áÔºå‰ª•ÈáèÂåñMLLMÂú®‰∏çÂêåÂàÜËæ®ÁéáËæìÂÖ•‰∏ãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇÈÄöËøáÂàÜÊûêÊ®°ÂûãÂú®‰∏çÂêåÂàÜËæ®Áéá‰∏ãÁöÑÊÄßËÉΩÂèòÂåñË∂ãÂäøÂíåÊ≥¢Âä®Á®ãÂ∫¶Ôºå‰ªéËÄåÂÖ®Èù¢ËØÑ‰º∞Ê®°ÂûãÂØπÂàÜËæ®ÁéáÂèòÂåñÁöÑÊïèÊÑüÁ®ãÂ∫¶„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöRes-BenchÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÁªÑÊàêÈÉ®ÂàÜÔºö1)ÂåÖÂê´14,400‰∏™Ê†∑Êú¨ÁöÑÂü∫ÂáÜÊï∞ÊçÆÈõÜÔºåË¶ÜÁõñ12‰∏™ÂàÜËæ®ÁéáÁ∫ßÂà´Âíå6‰∏™Ê†∏ÂøÉËÉΩÂäõÁª¥Â∫¶Ôºõ2)ËØÑ‰º∞Ê°ÜÊû∂ÔºåÂåÖÊã¨SpearmanÁõ∏ÂÖ≥ÊÄßÔºàËØÑ‰º∞ÂàÜËæ®Áéá-ÊÄßËÉΩË∂ãÂäøÔºâÂíåÁªùÂØπ/Áõ∏ÂØπËøûÁª≠ËØØÂ∑ÆACE/RCEÔºàËØÑ‰º∞ÊÄßËÉΩÊ≥¢Âä®ÔºâÁ≠âÈ≤ÅÊ£íÊÄßÊåáÊ†áÔºõ3)ÂÆûÈ™åÂàÜÊûêÔºåÂåÖÊã¨Ê®°ÂûãÂíå‰ªªÂä°ÁöÑÈ≤ÅÊ£íÊÄßÂàÜÊûêÔºåÈ¢ÑÂ§ÑÁêÜÁ≠ñÁï•ÔºàÂ°´ÂÖÖ„ÄÅË∂ÖÂàÜËæ®ÁéáÔºâÁöÑÂΩ±ÂìçÔºå‰ª•ÂèäÂæÆË∞ÉÂØπÁ®≥ÂÆöÊÄßÁöÑÊèêÂçáÊïàÊûú„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöRes-BenchÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1)È¶ñÊ¨°ÂÖ≥Ê≥®MLLMÂú®Âä®ÊÄÅÂàÜËæ®ÁéáËæìÂÖ•‰∏ãÁöÑÈ≤ÅÊ£íÊÄßÈóÆÈ¢òÔºõ2)ÊèêÂá∫‰∫ÜSpearmanÁõ∏ÂÖ≥ÊÄßÂíåACE/RCEÁ≠âÈ≤ÅÊ£íÊÄßÊåáÊ†áÔºåÁî®‰∫éÈáèÂåñÊ®°ÂûãÂú®‰∏çÂêåÂàÜËæ®Áéá‰∏ãÁöÑÊÄßËÉΩÁ®≥ÂÆöÊÄßÔºõ3)ÊûÑÂª∫‰∫Ü‰∏Ä‰∏™Â§ßËßÑÊ®°ÁöÑÂü∫ÂáÜÊµãËØïÈõÜÔºå‰∏∫MLLMÁöÑÈ≤ÅÊ£íÊÄßËØÑ‰º∞Êèê‰æõ‰∫ÜÊ†áÂáÜÂåñÁöÑÂπ≥Âè∞„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Âü∫ÂáÜÊï∞ÊçÆÈõÜÊûÑÂª∫ÊñπÈù¢ÔºåËÆ∫Êñá‰ΩúËÄÖÁ≤æÂøÉÈÄâÊã©‰∫ÜË¶ÜÁõñ‰∏çÂêåÂàÜËæ®ÁéáÁ∫ßÂà´ÂíåÊ†∏ÂøÉËÉΩÂäõÁöÑÊ†∑Êú¨Ôºå‰ª•‰øùËØÅËØÑ‰º∞ÁöÑÂÖ®Èù¢ÊÄß„ÄÇÂú®ËØÑ‰º∞ÊåáÊ†áËÆæËÆ°ÊñπÈù¢ÔºåSpearmanÁõ∏ÂÖ≥ÊÄßÁî®‰∫éË°°ÈáèÂàÜËæ®Áéá‰∏éÊÄßËÉΩ‰πãÈó¥ÁöÑÂçïË∞ÉÂÖ≥Á≥ªÔºåACE/RCEÁî®‰∫éË°°ÈáèÊÄßËÉΩÁöÑÊ≥¢Âä®Á®ãÂ∫¶„ÄÇÊ≠§Â§ñÔºåËÆ∫ÊñáËøòÁ†îÁ©∂‰∫ÜÂ°´ÂÖÖ„ÄÅË∂ÖÂàÜËæ®ÁéáÁ≠âÈ¢ÑÂ§ÑÁêÜÊñπÊ≥ïÔºå‰ª•ÂèäÂæÆË∞ÉÂØπÊ®°ÂûãÈ≤ÅÊ£íÊÄßÁöÑÂΩ±Âìç„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Res-BenchÂØπÂ§ö‰∏™È¢ÜÂÖàÁöÑMLLMËøõË°å‰∫ÜÂ§ßËßÑÊ®°ËØÑ‰º∞ÔºåÁªìÊûúË°®ÊòéÔºå‰∏çÂêåÊ®°ÂûãÂú®ÂàÜËæ®ÁéáÈ≤ÅÊ£íÊÄßÊñπÈù¢Â≠òÂú®ÊòæËëóÂ∑ÆÂºÇ„ÄÇÂÆûÈ™åËøòÂèëÁé∞ÔºåÊüê‰∫õÈ¢ÑÂ§ÑÁêÜÁ≠ñÁï•ÔºàÂ¶ÇË∂ÖÂàÜËæ®ÁéáÔºâÂèØ‰ª•ÊèêÂçáÊ®°ÂûãÁöÑÈ≤ÅÊ£íÊÄßÔºåËÄåÈÄöËøáÂæÆË∞É‰πüÂèØ‰ª•ÊúâÊïàÂ¢ûÂº∫Ê®°ÂûãÂú®‰∏çÂêåÂàÜËæ®Áéá‰∏ãÁöÑÊÄßËÉΩÁ®≥ÂÆöÊÄß„ÄÇÂÖ∑‰ΩìÊÄßËÉΩÊï∞ÊçÆÂíåÂØπÊØîÂü∫Á∫øÂú®ËÆ∫Êñá‰∏≠ÊúâËØ¶ÁªÜÂëàÁé∞„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

Res-BenchÁöÑÁ†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éËØÑ‰º∞ÂíåÊèêÂçáÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÂèØÈù†ÊÄßÔºå‰æãÂ¶ÇÂú®Ëá™Âä®È©æÈ©∂„ÄÅÊô∫ËÉΩÂÆâÈò≤„ÄÅÂåªÁñóÂΩ±ÂÉèÂàÜÊûêÁ≠âÈ¢ÜÂüüÔºåÁ°Æ‰øùÊ®°ÂûãÂú®‰∏çÂêåÂõæÂÉèÂàÜËæ®Áéá‰∏ãÈÉΩËÉΩÁ®≥ÂÆöÂèØÈù†Âú∞Â∑•‰Ωú„ÄÇËØ•Âü∫ÂáÜÊµãËØïÈõÜÂíåËØÑ‰º∞ÊñπÊ≥ïÂèØ‰ª•‰øÉËøõÁõ∏ÂÖ≥È¢ÜÂüüÁöÑÁ†îÁ©∂ËøõÂ±ïÔºåÊé®Âä®Êõ¥È≤ÅÊ£íÁöÑÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Multimodal Large Language Models (MLLMs) increasingly support dynamic image resolutions. However, current evaluation paradigms primarily assess semantic performance, overlooking the critical question of resolution robustness - whether performance remains stable across varying input resolutions. To address this gap, we introduce \textbf{Res-Bench}, a comprehensive benchmark comprising 14,400 samples across 12 resolution levels and six core capability dimensions. We designed a novel evaluation framework that goes beyond traditional accuracy metrics to capture performance stability. This framework introduces multiple robustness metrics: Spearman's correlation for assessing resolution-performance trends, and Absolute/Relative Continuous Error (ACE/RCE) for measuring performance volatility. Using these metrics, we conducted a large-scale evaluation of leading MLLMs. Our analysis encompasses: (1) model-centric and task-centric robustness examination, (2) investigation of preprocessing strategies including padding and super-resolution, and (3) exploration of fine-tuning for stability enhancement.

