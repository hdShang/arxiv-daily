---
layout: default
title: Where, Not What: Compelling Video LLMs to Learn Geometric Causality for 3D-Grounding
---

# Where, Not What: Compelling Video LLMs to Learn Geometric Causality for 3D-Grounding

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.17034" target="_blank" class="toolbar-btn">arXiv: 2510.17034v1</a>
    <a href="https://arxiv.org/pdf/2510.17034.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.17034v1" 
            onclick="toggleFavorite(this, '2510.17034v1', 'Where, Not What: Compelling Video LLMs to Learn Geometric Causality for 3D-Grounding')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yutong Zhong

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-19

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫W2R2Ê°ÜÊû∂ÔºåËß£ÂÜ≥ËßÜÈ¢ëLLM‰∏≠3D groundingÁöÑ2DËØ≠‰πâÂÅèËßÅÈóÆÈ¢ò„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `3D Grounding` `ËßÜËßâ-ËØ≠Ë®ÄÊ®°Âûã` `Â§öÊ®°ÊÄÅËûçÂêà` `Ë°®Á§∫Â≠¶‰π†` `Âá†‰ΩïÊé®ÁêÜ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâVLMÂú®3D grounding‰∏≠ËøáÂ∫¶‰æùËµñ2DÂõæÂÉèÁâπÂæÅÔºåÂøΩÁï•3DÂá†‰Ωï‰ø°ÊÅØÔºåÂØºËá¥‚Äú2DËØ≠‰πâÂÅèËßÅ‚ÄùÂíåÂÆö‰ΩçÁ≤æÂ∫¶‰∏ãÈôç„ÄÇ
2. W2R2Ê°ÜÊû∂ÈÄöËøáËß£ËÄ¶2DÂíå3DÁâπÂæÅË°®Á§∫ÔºåÂàÜÂà´‰Ωú‰∏∫ËØ≠‰πâ‰ø°Ê†áÂíåÁ©∫Èó¥ÈîöÁÇπÔºå‰ªéËÄåÊäëÂà∂2DËØ≠‰πâÂÅèËßÅ„ÄÇ
3. Âú®ScanReferÂíåScanQAÊï∞ÊçÆÈõÜ‰∏äÔºåW2R2ÊòæËëóÊèêÂçá‰∫Ü3D groundingÁöÑÂÆö‰ΩçÁ≤æÂ∫¶ÂíåÈ≤ÅÊ£íÊÄßÔºåÂ∞§ÂÖ∂Âú®Â§çÊùÇÂú∫ÊôØ‰∏≠„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§öÊ®°ÊÄÅ3D groundingÂú®ËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÔºàVLMÔºâ‰∏≠Â§áÂèóÂÖ≥Ê≥®ÔºåÊó®Âú®ÊèêÂçáÂ§çÊùÇÁéØÂ¢É‰∏≠ÁöÑÁ©∫Èó¥Êé®ÁêÜËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåËøô‰∫õÊ®°ÂûãÂ≠òÂú®‰∏•ÈáçÁöÑ‚Äú2DËØ≠‰πâÂÅèËßÅ‚ÄùÔºåËøáÂ∫¶‰æùËµñ2DÂõæÂÉèÁâπÂæÅËøõË°åÁ≤óÁï•ÂÆö‰ΩçÔºåÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂøΩÁï•‰∫Ü3DÂá†‰ΩïËæìÂÖ•ÔºåÂØºËá¥ËûçÂêàÊÄßËÉΩÊ¨†‰Ω≥„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫What-Where Representation Re-Forming (W2R2) ÁöÑÊñ∞ÂûãËÆ≠ÁªÉÊ°ÜÊû∂ÔºåÈÄöËøáËß£ËÄ¶Ë°®Á§∫Â≠¶‰π†ÂíåÊúâÈíàÂØπÊÄßÁöÑÊç∑ÂæÑÊäëÂà∂Êù•Ëß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢ò„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ï‰ªéÊ†πÊú¨‰∏äÈáçÂ°ë‰∫ÜÊ®°ÂûãÁöÑÂÜÖÈÉ®Á©∫Èó¥ÔºåÂ∞Ü2DÁâπÂæÅÊåáÂÆö‰∏∫‚ÄúWhat‚ÄùËØÜÂà´ÁöÑËØ≠‰πâ‰ø°Ê†áÔºåÂ∞Ü3DÁâπÂæÅÊåáÂÆö‰∏∫‚ÄúWhere‚ÄùÂÆö‰ΩçÁöÑÁ©∫Èó¥ÈîöÁÇπÔºå‰ªéËÄåÂú®‰∏ç‰øÆÊîπÊé®ÁêÜÊû∂ÊûÑÁöÑÊÉÖÂÜµ‰∏ãÂÆûÁé∞Á≤æÁ°ÆÁöÑ3D grounding„ÄÇÂÖ≥ÈîÆÁªÑ‰ª∂ÂåÖÊã¨‰∏Ä‰∏™ÂèåÁõÆÊ†áÊçüÂ§±ÂáΩÊï∞ÔºåÂÖ∂‰∏≠ÂåÖÂê´‰∏Ä‰∏™ÂØπÈΩêÊçüÂ§±ÔºåËØ•ÊçüÂ§±‰ΩøÁî®ÈÄÇÂ∫îÁöÑ‰∫§ÂèâÁÜµÊù•ÁõëÁù£ËûçÂêàÈ¢ÑÊµãÔºå‰ª•ÂÆûÁé∞Â§öÊ®°ÊÄÅÂçèÂêåÔºõ‰ª•Âèä‰∏Ä‰∏™‰º™Ê†áÁ≠æÊçüÂ§±ÔºåËØ•ÊçüÂ§±ÈÄöËøáÂü∫‰∫éËæπÈôÖÁöÑÊú∫Âà∂ÊÉ©ÁΩöËøá‰∫éÊúâÊïàÁöÑ2D‰∏ªÂØº‰º™ËæìÂá∫„ÄÇÂú®ScanReferÂíåScanQA‰∏äËøõË°åÁöÑÂÆûÈ™åËØÅÊòé‰∫ÜW2R2ÁöÑÊúâÊïàÊÄßÔºåÂú®ÂÆö‰ΩçÁ≤æÂ∫¶ÂíåÈ≤ÅÊ£íÊÄßÊñπÈù¢ÂèñÂæó‰∫ÜÊòæËëóÊèêÂçáÔºåÂ∞§ÂÖ∂ÊòØÂú®ÊùÇ‰π±ÁöÑÊà∑Â§ñÂú∫ÊôØ‰∏≠„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÂú®ËøõË°å3D groundingÊó∂ÔºåËøáÂ∫¶‰æùËµñ2DÂõæÂÉèÁöÑËØ≠‰πâ‰ø°ÊÅØÔºåËÄåÂøΩÁï•‰∫Ü3DÂá†‰Ωï‰ø°ÊÅØÊèê‰æõÁöÑÁ©∫Èó¥Á∫øÁ¥¢„ÄÇËøôÁßç‚Äú2DËØ≠‰πâÂÅèËßÅ‚ÄùÂØºËá¥Ê®°ÂûãÂú®Â§çÊùÇÂú∫ÊôØ‰∏ãÂÆö‰ΩçÁ≤æÂ∫¶‰∏ãÈôçÔºåÊó†Ê≥ïÂÖÖÂàÜÂà©Áî®Â§öÊ®°ÊÄÅ‰ø°ÊÅØÁöÑ‰ºòÂäø„ÄÇÁé∞ÊúâÊñπÊ≥ïÈöæ‰ª•ÊúâÊïàËûçÂêà2DËØ≠‰πâÂíå3DÂá†‰Ωï‰ø°ÊÅØÔºåÂØºËá¥Ê¨°‰ºòÁöÑ3D groundingÊÄßËÉΩ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöW2R2ÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáËß£ËÄ¶2DÂíå3DÁâπÂæÅÁöÑË°®Á§∫ÔºåÂº∫Âà∂Ê®°ÂûãÂ≠¶‰π†Â∞Ü2DÁâπÂæÅ‰Ωú‰∏∫‚ÄúWhat‚ÄùÁöÑËØ≠‰πâ‰ø°ÊÅØÊù•Ê∫êÔºåÂ∞Ü3DÁâπÂæÅ‰Ωú‰∏∫‚ÄúWhere‚ÄùÁöÑÁ©∫Èó¥‰ø°ÊÅØÊù•Ê∫ê„ÄÇÈÄöËøáËøôÁßçÊñπÂºèÔºåÊ®°ÂûãÂèØ‰ª•Êõ¥Â•ΩÂú∞Âà©Áî®3DÂá†‰Ωï‰ø°ÊÅØËøõË°åÁ≤æÁ°ÆÂÆö‰ΩçÔºå‰ªéËÄåÂÖãÊúç2DËØ≠‰πâÂÅèËßÅ„ÄÇËøôÁßçËß£ËÄ¶ÊòØÈÄöËøáÁâπÂÆöÁöÑÊçüÂ§±ÂáΩÊï∞ÂíåËÆ≠ÁªÉÁ≠ñÁï•Êù•ÂÆûÁé∞ÁöÑ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöW2R2Ê°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Èò∂ÊÆµÔºöÈ¶ñÂÖàÔºåÊ®°ÂûãÊé•Êî∂ËßÜËßâÂíåËØ≠Ë®ÄËæìÂÖ•ÔºåÊèêÂèñ2DÂõæÂÉèÁâπÂæÅÂíå3DÂá†‰ΩïÁâπÂæÅ„ÄÇÁÑ∂ÂêéÔºåÈÄöËøáÁâπÂæÅËûçÂêàÊ®°ÂùóÂ∞ÜÂ§öÊ®°ÊÄÅÁâπÂæÅËøõË°åËûçÂêà„ÄÇÊé•‰∏ãÊù•ÔºåÊ®°ÂûãÂü∫‰∫éËûçÂêàÂêéÁöÑÁâπÂæÅËøõË°å3D groundingÈ¢ÑÊµã„ÄÇÊúÄÂêéÔºåÈÄöËøáÂèåÁõÆÊ†áÊçüÂ§±ÂáΩÊï∞ÂØπÊ®°ÂûãËøõË°åËÆ≠ÁªÉÔºåÂåÖÊã¨ÂØπÈΩêÊçüÂ§±Âíå‰º™Ê†áÁ≠æÊçüÂ§±„ÄÇÊï¥‰∏™Ê°ÜÊû∂Âú®ËÆ≠ÁªÉÈò∂ÊÆµËøõË°å‰ºòÂåñÔºåÊé®ÁêÜÈò∂ÊÆµ‰øùÊåÅ‰∏çÂèò„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöW2R2ÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÂÖ∂Ëß£ËÄ¶Ë°®Á§∫Â≠¶‰π†ÂíåÊúâÈíàÂØπÊÄßÁöÑÊç∑ÂæÑÊäëÂà∂Á≠ñÁï•„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ï‰∏çÂêåÔºåW2R2‰∏çÊòØÁÆÄÂçïÂú∞Â∞Ü2DÂíå3DÁâπÂæÅËøõË°åËûçÂêàÔºåËÄåÊòØÈÄöËøáÁâπÂÆöÁöÑÊçüÂ§±ÂáΩÊï∞ÂíåËÆ≠ÁªÉÁ≠ñÁï•ÔºåÂº∫Âà∂Ê®°ÂûãÂ≠¶‰π†Â∞Ü2DÂíå3DÁâπÂæÅÂàÜÂà´‰Ωú‰∏∫ËØ≠‰πâÂíåÁ©∫Èó¥‰ø°ÊÅØÁöÑÊù•Ê∫ê„ÄÇËøôÁßçËß£ËÄ¶Ë°®Á§∫Â≠¶‰π†ÂèØ‰ª•ÊúâÊïàÊäëÂà∂2DËØ≠‰πâÂÅèËßÅÔºåÊèêÈ´ò3D groundingÁöÑÁ≤æÂ∫¶ÂíåÈ≤ÅÊ£íÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöW2R2ÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ÂØπÈΩêÊçüÂ§±Ôºö‰ΩøÁî®ÈÄÇÂ∫îÁöÑ‰∫§ÂèâÁÜµÊçüÂ§±Êù•ÁõëÁù£ËûçÂêàÈ¢ÑÊµãÔºåÈºìÂä±Â§öÊ®°ÊÄÅÁâπÂæÅÁöÑÂçèÂêå‰ΩúÁî®„ÄÇ2) ‰º™Ê†áÁ≠æÊçüÂ§±ÔºöÈÄöËøáÂü∫‰∫éËæπÈôÖÁöÑÊú∫Âà∂ÊÉ©ÁΩöËøá‰∫éÊúâÊïàÁöÑ2D‰∏ªÂØº‰º™ËæìÂá∫Ôºå‰ªéËÄåÊäëÂà∂2DËØ≠‰πâÂÅèËßÅ„ÄÇ3) ÂèåÁõÆÊ†áÊçüÂ§±ÂáΩÊï∞ÔºöÂ∞ÜÂØπÈΩêÊçüÂ§±Âíå‰º™Ê†áÁ≠æÊçüÂ§±ÁªìÂêàËµ∑Êù•ÔºåÂÖ±Âêå‰ºòÂåñÊ®°Âûã„ÄÇÂÖ∑‰ΩìÁöÑÊçüÂ§±ÂáΩÊï∞ÊùÉÈáçÂíåËæπÈôÖÂèÇÊï∞ÈúÄË¶ÅÊ†πÊçÆÂÆûÈ™åËøõË°åË∞ÉÊï¥„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåW2R2Âú®ScanReferÂíåScanQAÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇÂú®ScanReferÊï∞ÊçÆÈõÜ‰∏äÔºåW2R2ÁöÑÂÆö‰ΩçÁ≤æÂ∫¶ÊèêÈ´ò‰∫ÜX%ÔºåÂú®ScanQAÊï∞ÊçÆÈõÜ‰∏äÔºåW2R2ÁöÑÈ≤ÅÊ£íÊÄßÊèêÈ´ò‰∫ÜY%„ÄÇÂ∞§ÂÖ∂ÊòØÂú®ÊùÇ‰π±ÁöÑÊà∑Â§ñÂú∫ÊôØ‰∏≠ÔºåW2R2ÁöÑÊÄßËÉΩÊèêÂçáÊõ¥‰∏∫ÊòéÊòæÔºåËØÅÊòé‰∫ÜÂÖ∂ÊúâÊïàÊäëÂà∂2DËØ≠‰πâÂÅèËßÅÁöÑËÉΩÂäõ„ÄÇÂÖ∑‰ΩìÊï∞ÂÄºXÂíåYÈúÄË¶ÅÂú®ËÆ∫Êñá‰∏≠Êü•Êâæ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫ÂØºËà™„ÄÅËá™Âä®È©æÈ©∂„ÄÅÂ¢ûÂº∫Áé∞ÂÆûÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÊèêÂçá3D groundingÁöÑÁ≤æÂ∫¶ÂíåÈ≤ÅÊ£íÊÄßÔºåÂèØ‰ª•‰ΩøÊú∫Âô®‰∫∫Âú®Â§çÊùÇÁéØÂ¢É‰∏≠Êõ¥Â•ΩÂú∞ÁêÜËß£ÂíåÂÆö‰ΩçÁâ©‰ΩìÔºå‰ªéËÄåÂÆûÁé∞Êõ¥Êô∫ËÉΩÁöÑ‰∫§‰∫íÂíåÂÜ≥Á≠ñ„ÄÇÊú™Êù•ÔºåËØ•ÊäÄÊúØÊúâÊúõÂ∫îÁî®‰∫éÊô∫ËÉΩÂÆ∂Â±Ö„ÄÅÂ∑•‰∏öËá™Âä®ÂåñÁ≠âÈ¢ÜÂüüÔºåÊèêÂçá‰∫∫Êú∫Âçè‰ΩúÊïàÁéá„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Multimodal 3D grounding has garnered considerable interest in Vision-Language Models (VLMs) \cite{yin2025spatial} for advancing spatial reasoning in complex environments. However, these models suffer from a severe "2D semantic bias" that arises from over-reliance on 2D image features for coarse localization, largely disregarding 3D geometric inputs and resulting in suboptimal fusion performance. In this paper, we propose a novel training framework called What-Where Representation Re-Forming (W2R2) to tackle this issue via disentangled representation learning and targeted shortcut suppression. Our approach fundamentally reshapes the model's internal space by designating 2D features as semantic beacons for "What" identification and 3D features as spatial anchors for "Where" localization, enabling precise 3D grounding without modifying inference architecture. Key components include a dual-objective loss function with an Alignment Loss that supervises fused predictions using adapted cross-entropy for multimodal synergy, and a Pseudo-Label Loss that penalizes overly effective 2D-dominant pseudo-outputs via a margin-based mechanism. Experiments conducted on ScanRefer and ScanQA demonstrate the effectiveness of W2R2, with significant gains in localization accuracy and robustness, particularly in cluttered outdoor scenes.

