---
layout: default
title: Segmentation as A Plug-and-Play Capability for Frozen Multimodal LLMs
---

# Segmentation as A Plug-and-Play Capability for Frozen Multimodal LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.16785" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.16785v1</a>
  <a href="https://arxiv.org/pdf/2510.16785.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.16785v1" onclick="toggleFavorite(this, '2510.16785v1', 'Segmentation as A Plug-and-Play Capability for Frozen Multimodal LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiazhen Liu, Long Chen

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-19

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**LENSï¼šä¸ºå†»ç»“å¤šæ¨¡æ€LLMæä¾›å³æ’å³ç”¨çš„åˆ†å‰²èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `å›¾åƒåˆ†å‰²` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ³¨æ„åŠ›æœºåˆ¶` `å…³é”®ç‚¹æ£€æµ‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•é€šè¿‡å¾®è°ƒMLLMä»¥è·å¾—åˆ†å‰²èƒ½åŠ›ï¼Œä½†ç‰ºç‰²äº†æ¨¡å‹çš„æ³›åŒ–æ€§èƒ½ï¼Œä¸æ„å»ºç»Ÿä¸€æ¨¡å‹çš„ç›®æ ‡ç›¸æ‚–ã€‚
2. LENSæå‡ºäº†ä¸€ç§å³æ’å³ç”¨çš„è§£å†³æ–¹æ¡ˆï¼Œé€šè¿‡æå–å’Œæè¿°å…³é”®ç‚¹ï¼Œä½¿å†»ç»“çš„MLLMå…·å¤‡åˆ†å‰²èƒ½åŠ›ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒLENSåœ¨ä¿æŒMLLMæ³›åŒ–èƒ½åŠ›çš„åŒæ—¶ï¼Œå®ç°äº†ä¸å¾®è°ƒæ–¹æ³•ç›¸å½“ç”šè‡³æ›´ä¼˜è¶Šçš„åˆ†å‰²æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°†å¤šæ ·åŒ–çš„è§†è§‰èƒ½åŠ›é›†æˆåˆ°ç»Ÿä¸€æ¨¡å‹ä¸­æ˜¯å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰çš„é‡è¦è¶‹åŠ¿ã€‚å…¶ä¸­ï¼ŒåŒ…å«åˆ†å‰²èƒ½åŠ›å¸¦æ¥äº†ä¸€ç³»åˆ—ç‹¬ç‰¹çš„æŒ‘æˆ˜ã€‚ä¸ºäº†ä½¿MLLMå…·å¤‡åƒç´ çº§åˆ†å‰²èƒ½åŠ›ï¼Œç›®å‰çš„æ–¹æ³•é€šå¸¸éœ€è¦å¾®è°ƒæ¨¡å‹ï¼Œä½¿å…¶äº§ç”Ÿä¸æ©ç è§£ç å™¨å…¼å®¹çš„ç‰¹å®šè¾“å‡ºã€‚è¿™ä¸ªè¿‡ç¨‹é€šå¸¸ä¼šæ”¹å˜æ¨¡å‹çš„è¾“å‡ºç©ºé—´ï¼Œå¹¶æŸå®³å…¶å†…åœ¨çš„æ³›åŒ–èƒ½åŠ›ï¼Œè¿™ä¸æ„å»ºç»Ÿä¸€æ¨¡å‹çš„ç›®æ ‡èƒŒé“è€Œé©°ã€‚æˆ‘ä»¬æå‡ºäº†LENSï¼ˆåˆ©ç”¨å…³é”®ç‚¹è¿›è¡ŒMLLMåˆ†å‰²ï¼‰ï¼Œä¸€ç§æ–°é¢–çš„å³æ’å³ç”¨è§£å†³æ–¹æ¡ˆã€‚LENSå°†ä¸€ä¸ªè½»é‡çº§çš„ã€å¯è®­ç»ƒçš„å¤´éƒ¨è¿æ¥åˆ°ä¸€ä¸ªå®Œå…¨å†»ç»“çš„MLLMä¸Šã€‚é€šè¿‡ç»†åŒ–æ³¨æ„åŠ›å›¾ä¸­åµŒå…¥çš„ç©ºé—´çº¿ç´¢ï¼ŒLENSæå–å…³é”®ç‚¹ï¼Œå¹¶å°†å®ƒä»¬æè¿°ä¸ºä¸æ©ç è§£ç å™¨ç›´æ¥å…¼å®¹çš„é€ç‚¹ç‰¹å¾ã€‚å¤§é‡çš„å®éªŒéªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼šLENSå®ç°äº†ä¸åŸºäºé‡è®­ç»ƒçš„æ–¹æ³•ç›¸å½“ç”šè‡³æ›´ä¼˜è¶Šçš„åˆ†å‰²æ€§èƒ½ã€‚è‡³å…³é‡è¦çš„æ˜¯ï¼Œå®ƒåœ¨å®Œå…¨ä¿ç•™MLLMçš„æ³›åŒ–èƒ½åŠ›çš„åŒæ—¶å®ç°äº†è¿™ä¸€ç‚¹ï¼Œè€Œæ³›åŒ–èƒ½åŠ›ä¼šè¢«å¾®è°ƒæ–¹æ³•æ˜¾è‘—é™ä½ã€‚å› æ­¤ï¼ŒLENSçš„å¯é™„åŠ è®¾è®¡ä¸ºæ‰©å±•MLLMå»ºç«‹äº†ä¸€ç§é«˜æ•ˆè€Œå¼ºå¤§çš„èŒƒä¾‹ï¼Œä¸ºçœŸæ­£å¤šæ‰å¤šè‰ºçš„ç»Ÿä¸€æ¨¡å‹é“ºå¹³äº†é“è·¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¦‚ä½•ä¸ºå†»ç»“çš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰èµ‹äºˆåƒç´ çº§åˆ«çš„å›¾åƒåˆ†å‰²èƒ½åŠ›ï¼ŒåŒæ—¶é¿å…å¾®è°ƒå¸¦æ¥çš„æ³›åŒ–æ€§èƒ½ä¸‹é™é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦å¯¹MLLMè¿›è¡Œå¾®è°ƒï¼Œä»¥ä½¿å…¶è¾“å‡ºä¸ç‰¹å®šçš„æ©ç è§£ç å™¨å…¼å®¹ï¼Œä½†è¿™ä¼šæ”¹å˜æ¨¡å‹çš„è¾“å‡ºç©ºé—´ï¼ŒæŸå®³å…¶å›ºæœ‰çš„æ³›åŒ–èƒ½åŠ›ï¼Œé˜»ç¢äº†æ„å»ºçœŸæ­£ç»Ÿä¸€çš„å¤šæ¨¡æ€æ¨¡å‹çš„è¿›ç¨‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šLENSçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ³¨æ„åŠ›æœºåˆ¶ä¸­è•´å«çš„ç©ºé—´ä¿¡æ¯ï¼Œæå–å›¾åƒçš„å…³é”®ç‚¹ï¼Œå¹¶å°†è¿™äº›å…³é”®ç‚¹è½¬åŒ–ä¸ºä¸æ©ç è§£ç å™¨å…¼å®¹çš„ç‰¹å¾è¡¨ç¤ºã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒLENSé¿å…äº†å¯¹MLLMçš„ç›´æ¥å¾®è°ƒï¼Œä»è€Œä¿ç•™äº†å…¶åŸæœ‰çš„æ³›åŒ–èƒ½åŠ›ã€‚LENSçš„è®¾è®¡ç†å¿µæ˜¯â€œå³æ’å³ç”¨â€ï¼Œå³å¯ä»¥è½»æ¾åœ°æ·»åŠ åˆ°ç°æœ‰çš„å†»ç»“MLLMä¸Šï¼Œè€Œæ— éœ€ä¿®æ”¹å…¶å†…éƒ¨ç»“æ„ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLENSçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) **æ³¨æ„åŠ›å›¾æå–æ¨¡å—**ï¼šä»å†»ç»“çš„MLLMä¸­æå–æ³¨æ„åŠ›å›¾ï¼Œè¿™äº›æ³¨æ„åŠ›å›¾åŒ…å«äº†å›¾åƒçš„ç©ºé—´ä¿¡æ¯ã€‚2) **å…³é”®ç‚¹æå–æ¨¡å—**ï¼šåˆ©ç”¨æ³¨æ„åŠ›å›¾ä¸­çš„ç©ºé—´çº¿ç´¢ï¼Œæå–å›¾åƒçš„å…³é”®ç‚¹ã€‚3) **ç‰¹å¾æè¿°æ¨¡å—**ï¼šå°†æå–çš„å…³é”®ç‚¹æè¿°ä¸ºä¸æ©ç è§£ç å™¨å…¼å®¹çš„é€ç‚¹ç‰¹å¾ã€‚4) **æ©ç è§£ç å™¨**ï¼šåˆ©ç”¨å…³é”®ç‚¹ç‰¹å¾ç”Ÿæˆæœ€ç»ˆçš„åˆ†å‰²æ©ç ã€‚æ•´ä¸ªæµç¨‹æ— éœ€å¯¹MLLMè¿›è¡Œä»»ä½•ä¿®æ”¹ã€‚

**å…³é”®åˆ›æ–°**ï¼šLENSæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå…¶â€œå³æ’å³ç”¨â€çš„è®¾è®¡ç†å¿µï¼Œä»¥åŠåˆ©ç”¨æ³¨æ„åŠ›å›¾æå–å…³é”®ç‚¹çš„æ–¹å¼ã€‚ä¸ä¼ ç»Ÿçš„å¾®è°ƒæ–¹æ³•ç›¸æ¯”ï¼ŒLENSé¿å…äº†å¯¹MLLMçš„ç›´æ¥ä¿®æ”¹ï¼Œä»è€Œä¿ç•™äº†å…¶åŸæœ‰çš„æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒLENSé€šè¿‡æå–å…³é”®ç‚¹ï¼Œæœ‰æ•ˆåœ°åˆ©ç”¨äº†æ³¨æ„åŠ›å›¾ä¸­è•´å«çš„ç©ºé—´ä¿¡æ¯ï¼Œå®ç°äº†é«˜æ•ˆçš„å›¾åƒåˆ†å‰²ã€‚

**å…³é”®è®¾è®¡**ï¼šLENSçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) **è½»é‡çº§å¯è®­ç»ƒå¤´éƒ¨**ï¼šLENSä½¿ç”¨ä¸€ä¸ªè½»é‡çº§çš„å¯è®­ç»ƒå¤´éƒ¨æ¥æå–å’Œæè¿°å…³é”®ç‚¹ï¼Œè¯¥å¤´éƒ¨å¯ä»¥å¾ˆå®¹æ˜“åœ°æ·»åŠ åˆ°ç°æœ‰çš„MLLMä¸Šã€‚2) **æ³¨æ„åŠ›å›¾é€‰æ‹©ç­–ç•¥**ï¼šLENSéœ€è¦é€‰æ‹©åˆé€‚çš„æ³¨æ„åŠ›å›¾æ¥æå–å…³é”®ç‚¹ï¼Œè¿™éœ€è¦ä»”ç»†çš„å®éªŒå’Œåˆ†æã€‚3) **å…³é”®ç‚¹æè¿°ç¬¦è®¾è®¡**ï¼šLENSéœ€è¦è®¾è®¡ä¸€ç§æœ‰æ•ˆçš„å…³é”®ç‚¹æè¿°ç¬¦ï¼Œä»¥ä¾¿å°†å…³é”®ç‚¹è½¬åŒ–ä¸ºä¸æ©ç è§£ç å™¨å…¼å®¹çš„ç‰¹å¾è¡¨ç¤ºã€‚4) **æŸå¤±å‡½æ•°è®¾è®¡**ï¼šLENSä½¿ç”¨æ ‡å‡†çš„åˆ†å‰²æŸå¤±å‡½æ•°æ¥è®­ç»ƒå¯è®­ç»ƒå¤´éƒ¨ï¼Œä¾‹å¦‚äº¤å‰ç†µæŸå¤±æˆ–DiceæŸå¤±ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

LENSåœ¨å¤šä¸ªåˆ†å‰²æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼ŒLENSåœ¨ä¿æŒMLLMæ³›åŒ–èƒ½åŠ›çš„åŒæ—¶ï¼Œå®ç°äº†ä¸åŸºäºé‡è®­ç»ƒçš„æ–¹æ³•ç›¸å½“ç”šè‡³æ›´ä¼˜è¶Šçš„åˆ†å‰²æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨Cityscapesæ•°æ®é›†ä¸Šï¼ŒLENSçš„åˆ†å‰²ç²¾åº¦ä¸å¾®è°ƒåçš„æ¨¡å‹ç›¸å½“ï¼Œä½†åœ¨æ³›åŒ–èƒ½åŠ›æ–¹é¢æ˜æ˜¾ä¼˜äºå¾®è°ƒåçš„æ¨¡å‹ã€‚è¿™äº›ç»“æœéªŒè¯äº†LENSçš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

LENSå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚æ™ºèƒ½äº¤é€šã€åŒ»ç–—å½±åƒåˆ†æã€é¥æ„Ÿå›¾åƒå¤„ç†ç­‰é¢†åŸŸã€‚å®ƒå¯ä»¥ç”¨äºè‡ªåŠ¨é©¾é©¶ä¸­çš„é“è·¯åˆ†å‰²ã€åŒ»å­¦å›¾åƒä¸­çš„ç—…ç¶æ£€æµ‹ã€é¥æ„Ÿå›¾åƒä¸­çš„åœ°ç‰©åˆ†ç±»ç­‰ä»»åŠ¡ã€‚LENSçš„å³æ’å³ç”¨ç‰¹æ€§ä½¿å…¶èƒ½å¤Ÿå¿«é€Ÿé›†æˆåˆ°ç°æœ‰çš„å¤šæ¨¡æ€ç³»ç»Ÿä¸­ï¼Œä»è€Œæé«˜ç³»ç»Ÿçš„æ™ºèƒ½åŒ–æ°´å¹³ã€‚æœªæ¥ï¼ŒLENSæœ‰æœ›æˆä¸ºå¤šæ¨¡æ€äººå·¥æ™ºèƒ½é¢†åŸŸçš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Integrating diverse visual capabilities into a unified model is a significant trend in Multimodal Large Language Models (MLLMs). Among these, the inclusion of segmentation poses a distinct set of challenges. To equip MLLMs with pixel-level segmentation abilities, prevailing methods require finetuning the model to produce specific outputs compatible with a mask decoder. This process typically alters the model's output space and compromises its intrinsic generalization, which undermines the goal of building a unified model. We introduce LENS (Leveraging kEypoiNts for MLLMs' Segmentation), a novel plug-and-play solution. LENS attaches a lightweight, trainable head to a completely frozen MLLM. By refining the spatial cues embedded in attention maps, LENS extracts keypoints and describes them into point-wise features directly compatible with the mask decoder. Extensive experiments validate our approach: LENS achieves segmentation performance competitive with or superior to that of retraining-based methods. Crucially, it does so while fully preserving the MLLM's generalization capabilities, which are significantly degraded by finetuning approaches. As such, the attachable design of LENS establishes an efficient and powerful paradigm for extending MLLMs, paving the way for truly multi-talented, unified models.

