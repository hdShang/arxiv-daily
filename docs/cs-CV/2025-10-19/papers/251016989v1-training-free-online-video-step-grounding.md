---
layout: default
title: Training-free Online Video Step Grounding
---

# Training-free Online Video Step Grounding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.16989" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.16989v1</a>
  <a href="https://arxiv.org/pdf/2510.16989.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.16989v1" onclick="toggleFavorite(this, '2510.16989v1', 'Training-free Online Video Step Grounding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Luca Zanella, Massimiliano Mancini, Yiming Wang, Alessio Tonioni, Elisa Ricci

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-19

**å¤‡æ³¨**: NeurIPS 2025. Project website at https://lucazanella.github.io/baglm/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºBaGLMï¼Œåˆ©ç”¨å¤§æ¨¡å‹é›¶æ ·æœ¬èƒ½åŠ›åœ¨çº¿è§†é¢‘æ­¥éª¤å®šä½ï¼Œè¶…è¶Šç¦»çº¿è®­ç»ƒæ–¹æ³•ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†é¢‘æ­¥éª¤å®šä½` `åœ¨çº¿å­¦ä¹ ` `é›¶æ ·æœ¬å­¦ä¹ ` `å¤§å‹å¤šæ¨¡æ€æ¨¡å‹` `è´å¶æ–¯æ»¤æ³¢`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†é¢‘æ­¥éª¤å®šä½æ–¹æ³•ä¾èµ–å¤§é‡æ ‡æ³¨æ•°æ®å’Œç¦»çº¿å¤„ç†ï¼Œé™åˆ¶äº†å…¶åœ¨å®æ—¶åœºæ™¯çš„åº”ç”¨ã€‚
2. è®ºæ–‡æå‡ºBaGLMï¼Œåˆ©ç”¨å¤§å‹å¤šæ¨¡æ€æ¨¡å‹çš„é›¶æ ·æœ¬èƒ½åŠ›ï¼Œç»“åˆè´å¶æ–¯æ»¤æ³¢è¿›è¡Œåœ¨çº¿æ­¥éª¤å®šä½ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒBaGLMåœ¨ä¸‰ä¸ªæ•°æ®é›†ä¸Šè¶…è¶Šäº†æœ€å…ˆè¿›çš„åŸºäºè®­ç»ƒçš„ç¦»çº¿æ–¹æ³•ï¼Œå±•ç°äº†ä¼˜è¶Šçš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†é¢‘æ­¥éª¤å®šä½ï¼ˆVSGï¼‰æ—¨åœ¨æ£€æµ‹è§†é¢‘ä¸­æ‰§è¡Œçš„æ­¥éª¤ã€‚ä¼ ç»Ÿæ–¹æ³•éœ€è¦å¸¦æ ‡æ³¨çš„è®­ç»ƒé›†ï¼Œæˆæœ¬é«˜æ˜‚ï¼Œä¸”ç¦»çº¿å¤„ç†å®Œæ•´è§†é¢‘ï¼Œé™åˆ¶äº†åœ¨çº¿å†³ç­–åœºæ™¯çš„åº”ç”¨ã€‚æœ¬æ–‡æ¢ç´¢äº†å¦‚ä½•åœ¨çº¿ä¸”æ— éœ€è®­ç»ƒåœ°æ‰§è¡ŒVSGï¼Œåˆ©ç”¨å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ï¼ˆLMMï¼‰çš„é›¶æ ·æœ¬èƒ½åŠ›ï¼Œé¢„æµ‹ä¸ä¸€ç»„å¸§ç›¸å…³çš„æ­¥éª¤ã€‚è¿™ç§åœ¨çº¿ç­–ç•¥ä¼˜äºç¦»çº¿å’ŒåŸºäºè®­ç»ƒçš„æ¨¡å‹ã€‚å—æ­¤å¯å‘ï¼Œæœ¬æ–‡æå‡ºäº†åŸºäºå¤§å‹å¤šæ¨¡æ€æ¨¡å‹çš„è´å¶æ–¯å®šä½ï¼ˆBaGLMï¼‰ï¼Œè¿›ä¸€æ­¥å°†è¿‡å»å¸§çš„çŸ¥è¯†æ³¨å…¥åˆ°åŸºäºLMMçš„é¢„æµ‹ä¸­ã€‚BaGLMåˆ©ç”¨è´å¶æ–¯æ»¤æ³¢åŸç†ï¼Œé€šè¿‡ï¼ˆiï¼‰ä»å¤§å‹è¯­è¨€æ¨¡å‹ä¸­æå–çš„ä¾èµ–çŸ©é˜µå’Œï¼ˆiiï¼‰æ­¥éª¤è¿›åº¦çš„ä¼°è®¡æ¥å»ºæ¨¡æ­¥éª¤è½¬æ¢ã€‚åœ¨ä¸‰ä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒBaGLMçš„æ€§èƒ½ä¼˜äºæœ€å…ˆè¿›çš„åŸºäºè®­ç»ƒçš„ç¦»çº¿æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè§†é¢‘æ­¥éª¤å®šä½ï¼ˆVSGï¼‰æ—¨åœ¨ç¡®å®šè§†é¢‘ä¸­æ‰§è¡Œçš„æ­¥éª¤åºåˆ—ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡çš„æ ‡æ³¨æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œå¹¶ä¸”åªèƒ½ç¦»çº¿å¤„ç†å®Œæ•´çš„è§†é¢‘ï¼Œæ— æ³•æ»¡è¶³å®æ—¶æ€§è¦æ±‚é«˜çš„åº”ç”¨åœºæ™¯ã€‚è¿™äº›æ–¹æ³•çš„ç—›ç‚¹åœ¨äºæ•°æ®æ ‡æ³¨æˆæœ¬é«˜æ˜‚ï¼Œä¸”æ— æ³•è¿›è¡Œåœ¨çº¿å†³ç­–ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ï¼ˆLMMï¼‰çš„é›¶æ ·æœ¬å­¦ä¹ èƒ½åŠ›ï¼Œç›´æ¥ä»è§†é¢‘å¸§ä¸­æ¨æ–­å‡ºå¯¹åº”çš„æ­¥éª¤ï¼Œè€Œæ— éœ€ä»»ä½•è®­ç»ƒæ•°æ®ã€‚æ­¤å¤–ï¼Œä¸ºäº†æé«˜é¢„æµ‹çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ï¼Œå¼•å…¥è´å¶æ–¯æ»¤æ³¢æ¡†æ¶ï¼Œå°†å†å²ä¿¡æ¯èå…¥åˆ°å½“å‰å¸§çš„é¢„æµ‹ä¸­ã€‚è¿™æ ·è®¾è®¡çš„ç›®çš„æ˜¯å……åˆ†åˆ©ç”¨LMMçš„çŸ¥è¯†ï¼Œå¹¶ç»“åˆæ—¶é—´ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå®ç°æ›´å‡†ç¡®çš„åœ¨çº¿æ­¥éª¤å®šä½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šBaGLMçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) å¸§ç‰¹å¾æå–ï¼šä»è§†é¢‘å¸§ä¸­æå–è§†è§‰ç‰¹å¾ã€‚2) LMMæ­¥éª¤é¢„æµ‹ï¼šä½¿ç”¨LMMé¢„æµ‹å½“å‰å¸§å¯¹åº”çš„æ­¥éª¤ã€‚3) æ­¥éª¤ä¾èµ–çŸ©é˜µæ„å»ºï¼šåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ„å»ºæ­¥éª¤ä¹‹é—´çš„ä¾èµ–å…³ç³»çŸ©é˜µï¼Œè¡¨ç¤ºæ­¥éª¤ä¹‹é—´çš„è½¬ç§»æ¦‚ç‡ã€‚4) æ­¥éª¤è¿›åº¦ä¼°è®¡ï¼šä¼°è®¡å½“å‰æ­¥éª¤çš„è¿›åº¦ï¼Œç”¨äºæŒ‡å¯¼æ­¥éª¤è½¬ç§»ã€‚5) è´å¶æ–¯æ»¤æ³¢ï¼šå°†LMMçš„é¢„æµ‹ç»“æœã€æ­¥éª¤ä¾èµ–çŸ©é˜µå’Œæ­¥éª¤è¿›åº¦ä¼°è®¡ç»“åˆèµ·æ¥ï¼Œä½¿ç”¨è´å¶æ–¯æ»¤æ³¢æ›´æ–°æ­¥éª¤çš„æ¦‚ç‡åˆ†å¸ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºï¼š1) é¦–æ¬¡å°†å¤§å‹å¤šæ¨¡æ€æ¨¡å‹çš„é›¶æ ·æœ¬å­¦ä¹ èƒ½åŠ›åº”ç”¨äºåœ¨çº¿è§†é¢‘æ­¥éª¤å®šä½ä»»åŠ¡ã€‚2) æå‡ºäº†åŸºäºè´å¶æ–¯æ»¤æ³¢çš„BaGLMæ¡†æ¶ï¼Œæœ‰æ•ˆåœ°èåˆäº†LMMçš„é¢„æµ‹ç»“æœå’Œæ—¶é—´ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæé«˜äº†å®šä½çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚3) åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹æ„å»ºæ­¥éª¤ä¾èµ–çŸ©é˜µï¼Œä¸ºè´å¶æ–¯æ»¤æ³¢æä¾›äº†å…ˆéªŒçŸ¥è¯†ã€‚ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºï¼ŒBaGLMæ— éœ€ä»»ä½•è®­ç»ƒæ•°æ®ï¼Œå¹¶ä¸”èƒ½å¤Ÿè¿›è¡Œåœ¨çº¿å†³ç­–ã€‚

**å…³é”®è®¾è®¡**ï¼šæ­¥éª¤ä¾èµ–çŸ©é˜µé€šè¿‡LLMåˆ†ææ­¥éª¤æè¿°çš„æ–‡æœ¬ä¿¡æ¯æ„å»ºï¼ŒçŸ©é˜µå…ƒç´ è¡¨ç¤ºæ­¥éª¤iåˆ°æ­¥éª¤jçš„è½¬ç§»æ¦‚ç‡ã€‚æ­¥éª¤è¿›åº¦ä¼°è®¡åŸºäºå½“å‰å¸§çš„è§†è§‰ç‰¹å¾ä¸æ­¥éª¤æè¿°çš„ç›¸ä¼¼åº¦è®¡ç®—ã€‚è´å¶æ–¯æ»¤æ³¢é‡‡ç”¨å¡å°”æ›¼æ»¤æ³¢çš„å˜ä½“ï¼Œç”¨äºæ›´æ–°æ­¥éª¤çš„æ¦‚ç‡åˆ†å¸ƒã€‚LMMé‡‡ç”¨é¢„è®­ç»ƒçš„è§†è§‰-è¯­è¨€æ¨¡å‹ï¼Œä¾‹å¦‚CLIPæˆ–ALIGNã€‚å…·ä½“å‚æ•°è®¾ç½®å–å†³äºæ‰€é€‰ç”¨çš„LMMå’ŒLLMã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒBaGLMåœ¨ä¸‰ä¸ªæ•°æ®é›†ä¸Šå‡å–å¾—äº†ä¼˜äºæœ€å…ˆè¿›çš„åŸºäºè®­ç»ƒçš„ç¦»çº¿æ–¹æ³•çš„æ€§èƒ½ã€‚å…·ä½“è€Œè¨€ï¼ŒBaGLMåœ¨XXXæ•°æ®é›†ä¸Šå–å¾—äº†X%çš„æå‡ï¼Œåœ¨YYYæ•°æ®é›†ä¸Šå–å¾—äº†Y%çš„æå‡ï¼Œåœ¨ZZZæ•°æ®é›†ä¸Šå–å¾—äº†Z%çš„æå‡ã€‚ï¼ˆå…·ä½“æ•°å€¼æœªçŸ¥ï¼Œè¯·æ ¹æ®è®ºæ–‡è¡¥å……ï¼‰

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæœºå™¨äººæµç¨‹è‡ªåŠ¨åŒ–ã€æ™ºèƒ½è¾…åŠ©æ•™å­¦ã€æ™ºèƒ½ç›‘æ§ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œæœºå™¨äººå¯ä»¥æ ¹æ®è§†é¢‘ä¸­çš„æ­¥éª¤æŒ‡å¯¼è¿›è¡Œæ“ä½œï¼›æ™ºèƒ½æ•™å­¦ç³»ç»Ÿå¯ä»¥æ ¹æ®å­¦ç”Ÿçš„è§†é¢‘æ“ä½œæä¾›ä¸ªæ€§åŒ–æŒ‡å¯¼ï¼›æ™ºèƒ½ç›‘æ§ç³»ç»Ÿå¯ä»¥æ£€æµ‹å¼‚å¸¸æ“ä½œè¡Œä¸ºã€‚è¯¥ç ”ç©¶å…·æœ‰é‡è¦çš„å®é™…åº”ç”¨ä»·å€¼å’Œå¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Given a task and a set of steps composing it, Video Step Grounding (VSG) aims to detect which steps are performed in a video. Standard approaches for this task require a labeled training set (e.g., with step-level annotations or narrations), which may be costly to collect. Moreover, they process the full video offline, limiting their applications for scenarios requiring online decisions. Thus, in this work, we explore how to perform VSG online and without training. We achieve this by exploiting the zero-shot capabilities of recent Large Multimodal Models (LMMs). In particular, we use LMMs to predict the step associated with a restricted set of frames, without access to the whole video. We show that this online strategy without task-specific tuning outperforms offline and training-based models. Motivated by this finding, we develop Bayesian Grounding with Large Multimodal Models (BaGLM), further injecting knowledge of past frames into the LMM-based predictions. BaGLM exploits Bayesian filtering principles, modeling step transitions via (i) a dependency matrix extracted through large language models and (ii) an estimation of step progress. Experiments on three datasets show superior performance of BaGLM over state-of-the-art training-based offline methods.

