---
layout: default
title: "HumanCM: One Step Human Motion Prediction"
---

# HumanCM: One Step Human Motion Prediction

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.16709" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.16709v2</a>
  <a href="https://arxiv.org/pdf/2510.16709.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.16709v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.16709v2', 'HumanCM: One Step Human Motion Prediction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Liu Haojie, Gao Suixiang

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-10-19 (æ›´æ–°: 2025-10-23)

**å¤‡æ³¨**: 6 pages, 3 figures, 2 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHumanCMï¼Œä¸€ç§åŸºäºä¸€è‡´æ€§æ¨¡å‹çš„äººä½“è¿åŠ¨å•æ­¥é¢„æµ‹æ¡†æ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `äººä½“è¿åŠ¨é¢„æµ‹` `ä¸€è‡´æ€§æ¨¡å‹` `å•æ­¥ç”Ÿæˆ` `Transformer` `æ—¶ç©ºå»ºæ¨¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŸºäºæ‰©æ•£æ¨¡å‹çš„äººä½“è¿åŠ¨é¢„æµ‹ä¾èµ–å¤šæ­¥å»å™ªï¼Œè®¡ç®—æˆæœ¬é«˜ï¼Œæ¨ç†é€Ÿåº¦æ…¢ã€‚
2. HumanCMé€šè¿‡å­¦ä¹ å™ªå£°å’Œå¹²å‡€è¿åŠ¨çŠ¶æ€é—´çš„è‡ªæ´½æ˜ å°„ï¼Œå®ç°å•æ­¥ç”Ÿæˆï¼Œæ˜¾è‘—æå‡æ•ˆç‡ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒHumanCMåœ¨ç²¾åº¦ä¸Šå¯ä¸SOTAæ‰©æ•£æ¨¡å‹åª²ç¾ï¼ŒåŒæ—¶æ¨ç†é€Ÿåº¦æå‡æ˜¾è‘—ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºHumanCMï¼Œä¸€ä¸ªåŸºäºä¸€è‡´æ€§æ¨¡å‹çš„äººä½“è¿åŠ¨å•æ­¥é¢„æµ‹æ¡†æ¶ã€‚ä¸åŸºäºæ‰©æ•£æ¨¡å‹çš„å¤šæ­¥å»å™ªæ–¹æ³•ä¸åŒï¼ŒHumanCMé€šè¿‡å­¦ä¹ å™ªå£°è¿åŠ¨çŠ¶æ€å’Œå¹²å‡€è¿åŠ¨çŠ¶æ€ä¹‹é—´çš„è‡ªæ´½æ˜ å°„ï¼Œå®ç°é«˜æ•ˆçš„å•æ­¥ç”Ÿæˆã€‚è¯¥æ¡†æ¶é‡‡ç”¨åŸºäºTransformerçš„æ—¶ç©ºæ¶æ„ï¼Œå¹¶ç»“åˆæ—¶é—´åµŒå…¥æ¥å»ºæ¨¡é•¿ç¨‹ä¾èµ–å…³ç³»å¹¶ä¿æŒè¿åŠ¨è¿è´¯æ€§ã€‚åœ¨Human3.6Må’ŒHumanEva-Iæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒHumanCMåœ¨å®ç°ä¸æœ€å…ˆè¿›çš„æ‰©æ•£æ¨¡å‹ç›¸å½“æˆ–æ›´ä¼˜çš„ç²¾åº¦çš„åŒæ—¶ï¼Œå°†æ¨ç†æ­¥éª¤å‡å°‘äº†é«˜è¾¾ä¸¤ä¸ªæ•°é‡çº§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šäººä½“è¿åŠ¨é¢„æµ‹æ—¨åœ¨æ ¹æ®è¿‡å»ä¸€æ®µæ—¶é—´çš„è¿åŠ¨è½¨è¿¹é¢„æµ‹æœªæ¥ä¸€æ®µæ—¶é—´çš„è¿åŠ¨è½¨è¿¹ã€‚ç°æœ‰çš„åŸºäºæ‰©æ•£æ¨¡å‹çš„æ–¹æ³•é€šå¸¸éœ€è¦è¿›è¡Œå¤šæ­¥å»å™ªï¼Œè®¡ç®—é‡å¤§ï¼Œæ¨ç†é€Ÿåº¦æ…¢ï¼Œéš¾ä»¥æ»¡è¶³å®æ—¶æ€§è¦æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šHumanCMçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨ä¸€è‡´æ€§æ¨¡å‹ï¼Œç›´æ¥å­¦ä¹ å™ªå£°è¿åŠ¨çŠ¶æ€å’Œå¹²å‡€è¿åŠ¨çŠ¶æ€ä¹‹é—´çš„æ˜ å°„å…³ç³»ã€‚é€šè¿‡è®­ç»ƒä¸€ä¸ªèƒ½å¤Ÿå°†ä»»æ„å™ªå£°çŠ¶æ€æ˜ å°„åˆ°åŒä¸€å¹²å‡€çŠ¶æ€çš„æ¨¡å‹ï¼Œå®ç°å•æ­¥ç”Ÿæˆï¼Œä»è€Œé¿å…äº†å¤šæ­¥è¿­ä»£å»å™ªçš„è¿‡ç¨‹ã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨æé«˜é¢„æµ‹é€Ÿåº¦ï¼ŒåŒæ—¶ä¿æŒé¢„æµ‹ç²¾åº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šHumanCMçš„æ•´ä½“æ¶æ„åŸºäºTransformerï¼Œç”¨äºå»ºæ¨¡äººä½“è¿åŠ¨çš„æ—¶ç©ºä¾èµ–å…³ç³»ã€‚è¯¥æ¡†æ¶åŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1ï¼‰è¾“å…¥åµŒå…¥å±‚ï¼šå°†è¾“å…¥çš„å†å²è¿åŠ¨åºåˆ—åµŒå…¥åˆ°é«˜ç»´ç©ºé—´ï¼›2ï¼‰Transformerç¼–ç å™¨ï¼šæå–è¿åŠ¨åºåˆ—çš„æ—¶ç©ºç‰¹å¾ï¼›3ï¼‰æ—¶é—´åµŒå…¥ï¼šå°†æ—¶é—´ä¿¡æ¯ç¼–ç åˆ°ç‰¹å¾ä¸­ï¼Œä»¥åŒºåˆ†ä¸åŒæ—¶é—´æ­¥çš„è¿åŠ¨çŠ¶æ€ï¼›4ï¼‰ä¸€è‡´æ€§æ¨¡å‹ï¼šå­¦ä¹ å™ªå£°å’Œå¹²å‡€è¿åŠ¨çŠ¶æ€ä¹‹é—´çš„æ˜ å°„å…³ç³»ï¼Œå®ç°å•æ­¥é¢„æµ‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šHumanCMæœ€å…³é”®çš„åˆ›æ–°åœ¨äºä½¿ç”¨ä¸€è‡´æ€§æ¨¡å‹è¿›è¡Œäººä½“è¿åŠ¨é¢„æµ‹ã€‚ä¸ä¼ ç»Ÿçš„æ‰©æ•£æ¨¡å‹ç›¸æ¯”ï¼Œä¸€è‡´æ€§æ¨¡å‹åªéœ€è¦ä¸€æ­¥æ¨ç†å³å¯ç”Ÿæˆé¢„æµ‹ç»“æœï¼Œå¤§å¤§æé«˜äº†é¢„æµ‹é€Ÿåº¦ã€‚æ­¤å¤–ï¼ŒHumanCMè¿˜é‡‡ç”¨äº†Transformeræ¶æ„å’Œæ—¶é—´åµŒå…¥ï¼Œæœ‰æ•ˆåœ°å»ºæ¨¡äº†äººä½“è¿åŠ¨çš„æ—¶ç©ºä¾èµ–å…³ç³»ï¼Œæé«˜äº†é¢„æµ‹ç²¾åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œç»“æ„æ–¹é¢ï¼ŒHumanCMé‡‡ç”¨äº†å¤šå±‚Transformerç¼–ç å™¨ï¼Œä»¥æå–æ›´ä¸°å¯Œçš„æ—¶ç©ºç‰¹å¾ã€‚åœ¨æŸå¤±å‡½æ•°æ–¹é¢ï¼ŒHumanCMä½¿ç”¨äº†ä¸€è‡´æ€§æŸå¤±å‡½æ•°ï¼Œé¼“åŠ±æ¨¡å‹å°†ä¸åŒçš„å™ªå£°çŠ¶æ€æ˜ å°„åˆ°åŒä¸€å¹²å‡€çŠ¶æ€ã€‚æ­¤å¤–ï¼ŒHumanCMè¿˜ä½¿ç”¨äº†æ•°æ®å¢å¼ºæŠ€æœ¯ï¼Œä¾‹å¦‚éšæœºæ—‹è½¬å’Œç¿»è½¬ï¼Œä»¥æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

HumanCMåœ¨Human3.6Må’ŒHumanEva-Iæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼ŒHumanCMåœ¨ç²¾åº¦ä¸Šå¯ä»¥è¾¾åˆ°æˆ–è¶…è¿‡æœ€å…ˆè¿›çš„æ‰©æ•£æ¨¡å‹ï¼ŒåŒæ—¶æ¨ç†é€Ÿåº¦æé«˜äº†ä¸¤ä¸ªæ•°é‡çº§ã€‚ä¾‹å¦‚ï¼Œåœ¨Human3.6Mæ•°æ®é›†ä¸Šï¼ŒHumanCMåœ¨3Då…³èŠ‚ä½ç½®è¯¯å·®æŒ‡æ ‡ä¸Šå–å¾—äº†ä¸ProFillç›¸å½“çš„æ€§èƒ½ï¼Œä½†æ¨ç†æ—¶é—´ç¼©çŸ­äº†è¿‘100å€ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

HumanCMåœ¨äººæœºäº¤äº’ã€è™šæ‹Ÿç°å®ã€æ¸¸æˆå¼€å‘ã€åŠ¨ç”»åˆ¶ä½œç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚ä¾‹å¦‚ï¼Œåœ¨è™šæ‹Ÿç°å®ä¸­ï¼Œå¯ä»¥åˆ©ç”¨HumanCMé¢„æµ‹ç”¨æˆ·çš„è¿åŠ¨è½¨è¿¹ï¼Œä»è€Œå®ç°æ›´è‡ªç„¶çš„äº¤äº’ä½“éªŒã€‚åœ¨æ¸¸æˆå¼€å‘ä¸­ï¼Œå¯ä»¥åˆ©ç”¨HumanCMç”Ÿæˆé€¼çœŸçš„äººä½“è¿åŠ¨åŠ¨ç”»ï¼Œæé«˜æ¸¸æˆçš„æ²‰æµ¸æ„Ÿã€‚æ­¤å¤–ï¼ŒHumanCMè¿˜å¯ä»¥åº”ç”¨äºè¿åŠ¨åˆ†æã€åº·å¤è®­ç»ƒç­‰é¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present HumanCM, a one-step human motion prediction framework built upon consistency models. Instead of relying on multi-step denoising as in diffusion-based methods, HumanCM performs efficient single-step generation by learning a self-consistent mapping between noisy and clean motion states. The framework adopts a Transformer-based spatiotemporal architecture with temporal embeddings to model long-range dependencies and preserve motion coherence. Experiments on Human3.6M and HumanEva-I demonstrate that HumanCM achieves comparable or superior accuracy to state-of-the-art diffusion models while reducing inference steps by up to two orders of magnitude.

