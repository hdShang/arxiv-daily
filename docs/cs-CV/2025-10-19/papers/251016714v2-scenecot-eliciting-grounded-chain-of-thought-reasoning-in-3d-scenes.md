---
layout: default
title: SceneCOT: Eliciting Grounded Chain-of-Thought Reasoning in 3D Scenes
---

# SceneCOT: Eliciting Grounded Chain-of-Thought Reasoning in 3D Scenes

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.16714" target="_blank" class="toolbar-btn">arXiv: 2510.16714v2</a>
    <a href="https://arxiv.org/pdf/2510.16714.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.16714v2" 
            onclick="toggleFavorite(this, '2510.16714v2', 'SceneCOT: Eliciting Grounded Chain-of-Thought Reasoning in 3D Scenes')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Xiongkun Linghu, Jiangyong Huang, Ziyu Zhu, Baoxiong Jia, Siyuan Huang

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-19 (Êõ¥Êñ∞: 2025-10-21)

**Â§áÊ≥®**: Project page: https://scenecot.github.io/

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**SceneCOTÔºöÊèêÂá∫3DÂú∫ÊôØ‰∏≠Âü∫‰∫éÂ∏∏ËØÜÈìæÁöÑÊé®ÁêÜÊ°ÜÊû∂ÔºåÊèêÂçáÂÖ∑Ë∫´ÈóÆÁ≠îÊÄßËÉΩ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `3DÂú∫ÊôØÁêÜËß£` `Â∏∏ËØÜÈìæÊé®ÁêÜ` `ÂÖ∑Ë∫´ÈóÆÁ≠î` `Â§öÊ®°ÊÄÅËûçÂêà` `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `Êú∫Âô®‰∫∫` `ËßÜËßâÊé®ÁêÜ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞Êúâ3D LLMÂú®ÂÖ∑Ë∫´ÈóÆÁ≠îÊñπÈù¢Ë°®Áé∞‰∏ç‰Ω≥ÔºåÁº∫‰πèÂØπÂú∫ÊôØ-ÂØπË±°Èó¥Á±ª‰∫∫Êé®ÁêÜÊú∫Âà∂ÁöÑÊúâÊïàÂà©Áî®„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫SCENECOTÊ°ÜÊû∂ÔºåÈÄöËøáÂ∏∏ËØÜÈìæÊé®ÁêÜÂ∞ÜÂ§çÊùÇ‰ªªÂä°ÂàÜËß£ÔºåÂπ∂ÁªìÂêàÂ§öÊ®°ÊÄÅ‰∏ìÂÆ∂Ê®°ÂùóÊèê‰æõËßÜËßâÁ∫øÁ¥¢„ÄÇ
3. ÊûÑÂª∫‰∫ÜÂ§ßËßÑÊ®°Êï∞ÊçÆÈõÜSCENECOT-185KÔºåÂÆûÈ™åËØÅÊòéËØ•Ê°ÜÊû∂Âú®3DÂú∫ÊôØÊé®ÁêÜÂü∫ÂáÜ‰∏äË°®Áé∞Âá∫Ëâ≤ÔºåÊèêÂçá‰∫ÜÂÖ∑Ë∫´ÈóÆÁ≠îÁöÑ‰∏ÄËá¥ÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Áé∞ÊúâÁöÑ3DÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÂú®ÂÆûÁé∞ÂÖ∑Ë∫´ÈóÆÁ≠îÊñπÈù¢‰ªçÁÑ∂Èù¢‰∏¥ÊåëÊàòÔºåËøô‰∏ªË¶ÅÊòØÁî±‰∫éÂØπÁ±ª‰∫∫Âú∫ÊôØ-ÂØπË±°ÂÖ∑Ë∫´Êé®ÁêÜÊú∫Âà∂ÁöÑÊé¢Á¥¢‰∏çË∂≥„ÄÇÊú¨ÊñáÈÄöËøáÊèêÂá∫‰∏ÄÁßçÊñ∞È¢ñÁöÑÊ°ÜÊû∂Êù•Âº•Ë°•Ëøô‰∏ÄÂ∑ÆË∑ù„ÄÇÊàë‰ª¨È¶ñÂÖàÂºïÂÖ•‰∫Ü‰∏ÄÁßç3DÂú∫ÊôØ‰∏≠Âü∫‰∫éÂ∏∏ËØÜÈìæÔºàChain-of-Thought, CoTÔºâÁöÑÂÖ∑Ë∫´Êé®ÁêÜÊñπÊ≥ïÔºàSCENECOTÔºâÔºåÂ∞ÜÂ§çÊùÇÁöÑÊé®ÁêÜ‰ªªÂä°ÂàÜËß£‰∏∫Êõ¥ÁÆÄÂçï„ÄÅÊõ¥Êòì‰∫éÁÆ°ÁêÜÁöÑÈóÆÈ¢òÔºåÂπ∂Âü∫‰∫éÂ§öÊ®°ÊÄÅ‰∏ìÂÆ∂Ê®°ÂùóÊûÑÂª∫Áõ∏Â∫îÁöÑËßÜËßâÁ∫øÁ¥¢„ÄÇ‰∏∫‰∫ÜÊîØÊåÅËøôÁßçÊñπÊ≥ïÔºåÊàë‰ª¨ÂºÄÂèë‰∫ÜSCENECOT-185KÔºåËøôÊòØÁ¨¨‰∏Ä‰∏™Â§ßËßÑÊ®°ÁöÑÂÖ∑Ë∫´CoTÊé®ÁêÜÊï∞ÊçÆÈõÜÔºåÂåÖÂê´185K‰∏™È´òË¥®ÈáèÂÆû‰æã„ÄÇÂú®ÂêÑÁßçÂ§çÊùÇÁöÑ3DÂú∫ÊôØÊé®ÁêÜÂü∫ÂáÜ‰∏äÁöÑÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåÊàë‰ª¨ÁöÑÊñ∞Ê°ÜÊû∂ÂÆûÁé∞‰∫ÜÂº∫Â§ßÁöÑÊÄßËÉΩÔºåÂπ∂ÂÖ∑ÊúâÈ´òÂ∫¶ÁöÑÂÖ∑Ë∫´-ÈóÆÁ≠î‰∏ÄËá¥ÊÄß„ÄÇÊçÆÊàë‰ª¨ÊâÄÁü•ÔºåËøôÊòØCoTÊé®ÁêÜÈ¶ñÊ¨°ÊàêÂäüÂ∫îÁî®‰∫é3DÂú∫ÊôØÁêÜËß£ÔºåÂÆûÁé∞‰∫ÜÈÄêÊ≠•ÁöÑÁ±ª‰∫∫Êé®ÁêÜÔºåÂπ∂ÊòæÁ§∫Âá∫Êâ©Â±ïÂà∞Êõ¥ÂπøÊ≥õÁöÑ3DÂú∫ÊôØÁêÜËß£Âú∫ÊôØÁöÑÊΩúÂäõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞Êúâ3DÂú∫ÊôØÁêÜËß£‰∏≠ÁöÑÈóÆÁ≠î‰ªªÂä°ÔºåÁâπÂà´ÊòØÂÖ∑Ë∫´ÈóÆÁ≠îÔºåÈù¢‰∏¥ÁùÄÁº∫‰πèÊúâÊïàÊé®ÁêÜÊú∫Âà∂ÁöÑÊåëÊàò„ÄÇÁé∞ÊúâÁöÑ3DÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÈöæ‰ª•ÂÉè‰∫∫Á±ª‰∏ÄÊ†∑ËøõË°åÈÄêÊ≠•Êé®ÁêÜÔºå‰ªéËÄåÂØºËá¥ÈóÆÁ≠îÁªìÊûú‰∏éÂú∫ÊôØÁöÑÂÖ≥ËÅîÊÄßËæÉÂº±ÔºåÂç≥‚Äú‰∏çÂÖ∑Ë∫´‚Äù„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂºïÂÖ•Â∏∏ËØÜÈìæÔºàChain-of-Thought, CoTÔºâÊé®ÁêÜÂà∞3DÂú∫ÊôØÁêÜËß£‰∏≠„ÄÇÈÄöËøáÂ∞ÜÂ§çÊùÇÁöÑÊé®ÁêÜ‰ªªÂä°ÂàÜËß£‰∏∫‰∏ÄÁ≥ªÂàóÊõ¥Â∞èÁöÑ„ÄÅÂèØÁÆ°ÁêÜÁöÑÊ≠•È™§ÔºåÂπ∂‰∏∫ÊØè‰∏™Ê≠•È™§Êèê‰æõÁõ∏Â∫îÁöÑËßÜËßâÁ∫øÁ¥¢ÔºåÊ®°ÂûãÂèØ‰ª•ÈÄêÊ≠•Êé®ÁêÜÂπ∂ÁîüÊàêÊõ¥ÂáÜÁ°Æ„ÄÅÊõ¥ÂÖ∑Ë∫´ÁöÑÁ≠îÊ°à„ÄÇËøôÁßçÊñπÊ≥ïÊ®°Êãü‰∫Ü‰∫∫Á±ªÂú®ÁêÜËß£Âú∫ÊôØÂíåÂõûÁ≠îÈóÆÈ¢òÊó∂ÁöÑÊÄùËÄÉËøáÁ®ã„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöSCENECOTÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ã‰∏ªË¶ÅÊ®°ÂùóÔºö1) **ÈóÆÈ¢òËß£ÊûêÊ®°Âùó**ÔºöÂ∞ÜÂ§çÊùÇÈóÆÈ¢òÂàÜËß£‰∏∫‰∏ÄÁ≥ªÂàóÂ≠êÈóÆÈ¢ò„ÄÇ2) **ËßÜËßâÁ∫øÁ¥¢ÁîüÊàêÊ®°Âùó**ÔºöÂà©Áî®Â§öÊ®°ÊÄÅ‰∏ìÂÆ∂Ê®°ÂùóÔºà‰æãÂ¶ÇÔºåÁõÆÊ†áÊ£ÄÊµã„ÄÅËØ≠‰πâÂàÜÂâ≤Ôºâ‰∏∫ÊØè‰∏™Â≠êÈóÆÈ¢òÁîüÊàêÁõ∏Â∫îÁöÑËßÜËßâÁ∫øÁ¥¢„ÄÇ3) **Â∏∏ËØÜÈìæÊé®ÁêÜÊ®°Âùó**ÔºöÂà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÁªìÂêàËßÜËßâÁ∫øÁ¥¢ËøõË°åÈÄêÊ≠•Êé®ÁêÜÔºåÁîüÊàêÊúÄÁªàÁ≠îÊ°à„ÄÇ4) **ÂÖ∑Ë∫´‰∏ÄËá¥ÊÄßËØÑ‰º∞Ê®°Âùó**ÔºöËØÑ‰º∞Á≠îÊ°à‰∏éÂú∫ÊôØÁöÑÂÖ≥ËÅîÊÄßÔºåÁ°Æ‰øùÁ≠îÊ°àÁöÑÂÖ∑Ë∫´ÊÄß„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜÂ∏∏ËØÜÈìæÊé®ÁêÜÊàêÂäüÂ∫îÁî®‰∫é3DÂú∫ÊôØÁêÜËß£„ÄÇ‰∏é‰ª•ÂæÄÊñπÊ≥ïÁõ¥Êé•Â∞Ü3DÂú∫ÊôØ‰Ωú‰∏∫ËæìÂÖ•Âπ∂ÁîüÊàêÁ≠îÊ°à‰∏çÂêåÔºåSCENECOTÈÄöËøáÂàÜËß£Êé®ÁêÜËøáÁ®ãÂπ∂ÁªìÂêàËßÜËßâÁ∫øÁ¥¢ÔºåÂÆûÁé∞‰∫ÜÊõ¥ÁªÜÁ≤íÂ∫¶ÁöÑÊé®ÁêÜÂíåÊõ¥Âº∫ÁöÑÂÖ∑Ë∫´ÊÄß„ÄÇÊ≠§Â§ñÔºåSCENECOT-185KÊï∞ÊçÆÈõÜÁöÑÊûÑÂª∫‰πü‰∏∫ËØ•È¢ÜÂüüÁöÑÁ†îÁ©∂Êèê‰æõ‰∫ÜÈáçË¶ÅËµÑÊ∫ê„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöSCENECOTÊ°ÜÊû∂ÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) Â§öÊ®°ÊÄÅ‰∏ìÂÆ∂Ê®°ÂùóÁöÑÈÄâÊã©ÂíåÈõÜÊàêÔºåÁ°Æ‰øùËÉΩÂ§üÊèê‰æõÂáÜÁ°ÆÁöÑËßÜËßâÁ∫øÁ¥¢„ÄÇ2) Â∏∏ËØÜÈìæÊé®ÁêÜÊ®°Âùó‰∏≠LLMÁöÑÈÄâÊã©ÂíåÂæÆË∞ÉÔºå‰ΩøÂÖ∂ËÉΩÂ§üÊúâÊïàÂà©Áî®ËßÜËßâÁ∫øÁ¥¢ËøõË°åÊé®ÁêÜ„ÄÇ3) ÂÖ∑Ë∫´‰∏ÄËá¥ÊÄßËØÑ‰º∞Ê®°ÂùóÁöÑËÆæËÆ°ÔºåÁî®‰∫éË°°ÈáèÁ≠îÊ°à‰∏éÂú∫ÊôØÁöÑÂÖ≥ËÅîÊÄß„ÄÇÂÖ∑‰ΩìÂèÇÊï∞ËÆæÁΩÆÂíåÁΩëÁªúÁªìÊûÑÁªÜËäÇÂú®ËÆ∫Êñá‰∏≠ËøõË°å‰∫ÜËØ¶ÁªÜÊèèËø∞ÔºàÊú™Áü•Ôºâ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåSCENECOTÊ°ÜÊû∂Âú®Â§ö‰∏™3DÂú∫ÊôØÊé®ÁêÜÂü∫ÂáÜ‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåÂú®ÂÖ∑Ë∫´ÈóÆÁ≠î‰ªªÂä°‰∏äÔºåSCENECOTÊ°ÜÊû∂ÁöÑÊÄßËÉΩË∂ÖËøá‰∫ÜÁé∞ÊúâÊñπÊ≥ïÔºåÂπ∂ÂÆûÁé∞‰∫ÜÊõ¥È´òÁöÑÂÖ∑Ë∫´-ÈóÆÁ≠î‰∏ÄËá¥ÊÄß„ÄÇSCENECOT-185KÊï∞ÊçÆÈõÜÁöÑÂèëÂ∏É‰πü‰∏∫ËØ•È¢ÜÂüüÁöÑÁ†îÁ©∂Êèê‰æõ‰∫ÜÂÆùË¥µËµÑÊ∫êÔºå‰øÉËøõ‰∫ÜÁõ∏ÂÖ≥ÊäÄÊúØÁöÑÂèëÂ±ï„ÄÇÔºàÂÖ∑‰ΩìÊÄßËÉΩÊï∞ÊçÆÂíåÂØπÊØîÂü∫Á∫øÊú™Áü•Ôºâ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂπøÊ≥õÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫ÂØºËà™„ÄÅÊô∫ËÉΩÂÆ∂Â±Ö„ÄÅËá™Âä®È©æÈ©∂Á≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÊèêÂçá3DÂú∫ÊôØÁêÜËß£ÁöÑÂáÜÁ°ÆÊÄßÂíåÂÖ∑Ë∫´ÊÄßÔºåÂèØ‰ª•‰ΩøÊú∫Âô®‰∫∫Êõ¥Â•ΩÂú∞ÁêÜËß£Âë®Âõ¥ÁéØÂ¢ÉÔºåÂπ∂ÂÅöÂá∫Êõ¥ÂêàÁêÜÁöÑÂÜ≥Á≠ñ„ÄÇ‰æãÂ¶ÇÔºåÂú®Êô∫ËÉΩÂÆ∂Â±Ö‰∏≠ÔºåÊú∫Âô®‰∫∫ÂèØ‰ª•Ê†πÊçÆÁî®Êà∑ÁöÑÊåá‰ª§ÔºåÁªìÂêàÂØπÂú∫ÊôØÁöÑÁêÜËß£ÔºåÂÆåÊàêÊõ¥Â§çÊùÇÁöÑ‰ªªÂä°ÔºåÂ¶ÇÂØªÊâæÁâπÂÆöÁâ©ÂìÅ„ÄÅÊï¥ÁêÜÊàøÈó¥Á≠â„ÄÇÊú™Êù•ÔºåËØ•ÊäÄÊúØÊúâÊúõÊé®Âä®3DÂú∫ÊôØÁêÜËß£ÂíåÂÖ∑Ë∫´Êô∫ËÉΩÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Existing research on 3D Large Language Models (LLMs) still struggles to achieve grounded question-answering, primarily due to the under-exploration of the mechanism of human-like scene-object grounded reasoning. This paper bridges the gap by presenting a novel framework. We first introduce a grounded Chain-of-Thought reasoning method in 3D scenes (SCENECOT), decoupling a complex reasoning task into simpler and manageable problems, and building corresponding visual clues based on multimodal expert modules. To enable such a method, we develop SCENECOT-185K, the first large-scale grounded CoT reasoning dataset, consisting of 185K high-quality instances. Extensive experiments across various complex 3D scene reasoning benchmarks demonstrate that our new framework achieves strong performance with high grounding-QA coherence. To the best of our knowledge, this is the first successful application of CoT reasoning to 3D scene understanding, enabling step-by-step human-like reasoning and showing potential for extension to broader 3D scene understanding scenarios.

