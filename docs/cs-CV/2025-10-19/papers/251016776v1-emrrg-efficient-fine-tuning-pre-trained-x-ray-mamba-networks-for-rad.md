---
layout: default
title: "EMRRG: Efficient Fine-Tuning Pre-trained X-ray Mamba Networks for Radiology Report Generation"
---

# EMRRG: Efficient Fine-Tuning Pre-trained X-ray Mamba Networks for Radiology Report Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.16776" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.16776v1</a>
  <a href="https://arxiv.org/pdf/2510.16776.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.16776v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.16776v1', 'EMRRG: Efficient Fine-Tuning Pre-trained X-ray Mamba Networks for Radiology Report Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mingzheng Zhang, Jinfeng Gao, Dan Xu, Jiangrui Yu, Yuhan Qiao, Lan Chen, Jin Tang, Xiao Wang

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-10-19

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Event-AHU/Medical_Image_Analysis)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**EMRRGï¼šé«˜æ•ˆå¾®è°ƒé¢„è®­ç»ƒMamba Xå°„çº¿ç½‘ç»œï¼Œç”¨äºæ”¾å°„æŠ¥å‘Šç”Ÿæˆ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åŒ»å­¦æŠ¥å‘Šç”Ÿæˆ` `Xå°„çº¿å›¾åƒ` `Mambaç½‘ç»œ` `å‚æ•°é«˜æ•ˆå¾®è°ƒ` `Partial LoRA`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŒ»å­¦æŠ¥å‘Šç”Ÿæˆæ¨¡å‹è¿‡åº¦ä¾èµ–å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¿½ç•¥äº†é¢„è®­ç»ƒè§†è§‰æ¨¡å‹å’Œé«˜æ•ˆå¾®è°ƒæŠ€æœ¯çš„æ½œåŠ›ã€‚
2. EMRRGæ¡†æ¶é€šè¿‡å‚æ•°é«˜æ•ˆçš„å¾®è°ƒæ–¹æ³•ï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„Mambaç½‘ç»œä½œä¸ºè§†è§‰éª¨å¹²ï¼Œæå–Xå°„çº¿å›¾åƒç‰¹å¾ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒEMRRGåœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ï¼ŒéªŒè¯äº†æ‰€æå‡ºç­–ç•¥åœ¨Xå°„çº¿åŒ»å­¦æŠ¥å‘Šç”Ÿæˆä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºäºXå°„çº¿å›¾åƒçš„åŒ»å­¦æŠ¥å‘Šç”Ÿæˆï¼ˆMRGï¼‰æ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸçš„ä¸€ä¸ªå…³é”®æ–¹å‘ï¼Œå¯ä»¥æ˜¾è‘—å‡è½»ä¸´åºŠåŒ»ç”Ÿçš„è¯Šæ–­è´Ÿæ‹…å¹¶ç¼©çŸ­æ‚£è€…çš„ç­‰å¾…æ—¶é—´ã€‚ç°æœ‰çš„MRGæ¨¡å‹ä¸»è¦ä¾èµ–äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥æ”¹è¿›æŠ¥å‘Šç”Ÿæˆï¼Œè€Œå¯¹é¢„è®­ç»ƒè§†è§‰åŸºç¡€æ¨¡å‹æˆ–é«˜çº§å¾®è°ƒæŠ€æœ¯çš„æ¢ç´¢æœ‰é™ã€‚ä¸»æµæ¡†æ¶è¦ä¹ˆé¿å…å¾®è°ƒï¼Œè¦ä¹ˆä½¿ç”¨åƒLoRAè¿™æ ·ç®€å•çš„æ–¹æ³•ï¼Œå¸¸å¸¸å¿½ç•¥äº†å¢å¼ºäº¤å‰æ³¨æ„åŠ›æœºåˆ¶çš„æ½œåŠ›ã€‚æ­¤å¤–ï¼Œè™½ç„¶åŸºäºTransformerçš„æ¨¡å‹åœ¨è§†è§‰-è¯­è¨€ä»»åŠ¡ä¸­å æ®ä¸»å¯¼åœ°ä½ï¼Œä½†åƒMambaç½‘ç»œè¿™æ ·çš„éTransformeræ¶æ„åœ¨åŒ»å­¦æŠ¥å‘Šç”Ÿæˆæ–¹é¢çš„ç ”ç©¶ä»ç„¶ä¸è¶³ï¼Œè¿™ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†ä¸€ä¸ªæœ‰å¸Œæœ›çš„æ–¹å‘ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†EMRRGï¼Œä¸€ç§æ–°é¢–çš„Xå°„çº¿æŠ¥å‘Šç”Ÿæˆæ¡†æ¶ï¼Œè¯¥æ¡†æ¶ä½¿ç”¨å‚æ•°é«˜æ•ˆçš„æ–¹æ³•å¾®è°ƒé¢„è®­ç»ƒçš„Mambaç½‘ç»œã€‚å…·ä½“æ¥è¯´ï¼ŒXå°„çº¿å›¾åƒè¢«åˆ†æˆpatchesï¼Œè¿›è¡ŒtokenåŒ–ï¼Œå¹¶é€šè¿‡åŸºäºSSMçš„è§†è§‰éª¨å¹²ç½‘ç»œè¿›è¡Œç‰¹å¾æå–ï¼Œå…¶ä¸­Partial LoRAäº§ç”Ÿæœ€ä½³æ€§èƒ½ã€‚å…·æœ‰æ··åˆè§£ç å™¨çš„LLMç”ŸæˆåŒ»å­¦æŠ¥å‘Šï¼Œå®ç°ç«¯åˆ°ç«¯è®­ç»ƒï¼Œå¹¶åœ¨åŸºå‡†æ•°æ®é›†ä¸Šå–å¾—å¼ºå¤§çš„ç»“æœã€‚åœ¨ä¸‰ä¸ªå¹¿æ³›ä½¿ç”¨çš„åŸºå‡†æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒå……åˆ†éªŒè¯äº†æˆ‘ä»¬æå‡ºçš„Xå°„çº¿MRGç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³Xå°„çº¿å›¾åƒåŒ»å­¦æŠ¥å‘Šè‡ªåŠ¨ç”Ÿæˆé—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–Transformeræ¶æ„å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œè®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œä¸”å¯¹éTransformeræ¶æ„ï¼ˆå¦‚Mambaï¼‰çš„æ¢ç´¢ä¸è¶³ã€‚æ­¤å¤–ï¼Œç°æœ‰å¾®è°ƒæ–¹æ³•ï¼ˆå¦‚LoRAï¼‰å¯èƒ½æ— æ³•å……åˆ†ä¼˜åŒ–è§†è§‰ç‰¹å¾æå–è¿‡ç¨‹ï¼Œé™åˆ¶äº†æŠ¥å‘Šç”Ÿæˆçš„è´¨é‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨Mambaæ¶æ„ä½œä¸ºè§†è§‰éª¨å¹²ç½‘ç»œï¼Œå¹¶é‡‡ç”¨å‚æ•°é«˜æ•ˆçš„å¾®è°ƒæ–¹æ³•ï¼ˆPartial LoRAï¼‰æ¥ä¼˜åŒ–ç‰¹å¾æå–è¿‡ç¨‹ã€‚Mambaæ¶æ„å…·æœ‰çº¿æ€§å¤æ‚åº¦ï¼Œå¯ä»¥æ›´é«˜æ•ˆåœ°å¤„ç†é•¿åºåˆ—æ•°æ®ï¼Œä»è€Œé™ä½è®¡ç®—æˆæœ¬ã€‚Partial LoRAä¸“æ³¨äºå¾®è°ƒéƒ¨åˆ†ç½‘ç»œå‚æ•°ï¼Œè¿›ä¸€æ­¥æé«˜å¾®è°ƒæ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEMRRGæ¡†æ¶åŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) Xå°„çº¿å›¾åƒé¢„å¤„ç†ï¼šå°†å›¾åƒåˆ†å‰²æˆpatcheså¹¶è¿›è¡ŒtokenåŒ–ã€‚2) åŸºäºSSMçš„è§†è§‰éª¨å¹²ç½‘ç»œï¼šä½¿ç”¨Mambaæ¶æ„æå–å›¾åƒç‰¹å¾ã€‚3) Partial LoRAå¾®è°ƒï¼šä¼˜åŒ–è§†è§‰éª¨å¹²ç½‘ç»œçš„å‚æ•°ã€‚4) æ··åˆè§£ç å™¨çš„LLMï¼šç”ŸæˆåŒ»å­¦æŠ¥å‘Šã€‚æ•´ä¸ªæ¡†æ¶é‡‡ç”¨ç«¯åˆ°ç«¯è®­ç»ƒæ–¹å¼ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) å°†Mambaæ¶æ„å¼•å…¥Xå°„çº¿åŒ»å­¦æŠ¥å‘Šç”Ÿæˆä»»åŠ¡ï¼Œæ¢ç´¢äº†éTransformeræ¶æ„çš„æ½œåŠ›ã€‚2) æå‡ºäº†Partial LoRAå¾®è°ƒæ–¹æ³•ï¼Œæ›´æœ‰æ•ˆåœ°ä¼˜åŒ–è§†è§‰ç‰¹å¾æå–è¿‡ç¨‹ã€‚3) é‡‡ç”¨äº†æ··åˆè§£ç å™¨çš„LLMï¼Œæé«˜äº†æŠ¥å‘Šç”Ÿæˆçš„è´¨é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šXå°„çº¿å›¾åƒè¢«åˆ†å‰²æˆå›ºå®šå¤§å°çš„patchesï¼Œç„¶åé€šè¿‡çº¿æ€§æŠ•å½±å±‚è¿›è¡ŒtokenåŒ–ã€‚Mambaæ¶æ„çš„è§†è§‰éª¨å¹²ç½‘ç»œé‡‡ç”¨å¤šå±‚SSMæ¨¡å—å †å è€Œæˆã€‚Partial LoRAé€‰æ‹©æ€§åœ°å¾®è°ƒéƒ¨åˆ†SSMæ¨¡å—çš„å‚æ•°ã€‚æŸå¤±å‡½æ•°é‡‡ç”¨äº¤å‰ç†µæŸå¤±ï¼Œç”¨äºä¼˜åŒ–æŠ¥å‘Šç”Ÿæˆçš„å‡†ç¡®æ€§ã€‚æ··åˆè§£ç å™¨çš„LLMç»“åˆäº†è‡ªå›å½’è§£ç å™¨å’Œéè‡ªå›å½’è§£ç å™¨ï¼Œä»¥æé«˜ç”Ÿæˆæ•ˆç‡å’Œè´¨é‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡åœ¨ä¸‰ä¸ªå¹¿æ³›ä½¿ç”¨çš„åŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼ŒéªŒè¯äº†EMRRGæ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒEMRRGåœ¨æŠ¥å‘Šç”Ÿæˆè´¨é‡æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶ä¸”å…·æœ‰æ›´é«˜çš„è®¡ç®—æ•ˆç‡ã€‚Partial LoRAå¾®è°ƒæ–¹æ³•èƒ½å¤Ÿæ˜¾è‘—æé«˜æ¨¡å‹çš„æ€§èƒ½ï¼Œå¹¶ä¸”é™ä½äº†å¾®è°ƒæˆæœ¬ã€‚å…·ä½“æ€§èƒ½æ•°æ®åœ¨è®ºæ–‡ä¸­è¯¦ç»†å±•ç¤ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè¾…åŠ©æ”¾å°„ç§‘åŒ»ç”Ÿè¿›è¡ŒXå°„çº¿å›¾åƒè¯Šæ–­ï¼Œè‡ªåŠ¨ç”Ÿæˆåˆæ­¥çš„åŒ»å­¦æŠ¥å‘Šï¼Œä»è€Œå‡è½»åŒ»ç”Ÿçš„å·¥ä½œè´Ÿæ‹…ï¼Œç¼©çŸ­æ‚£è€…çš„ç­‰å¾…æ—¶é—´ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥ç”¨äºè¿œç¨‹åŒ»ç–—å’Œç§»åŠ¨åŒ»ç–—åº”ç”¨ï¼Œä¸ºç¼ºä¹åŒ»ç–—èµ„æºçš„åœ°åŒºæä¾›æ”¯æŒã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶å¯ä»¥æ‰©å±•åˆ°å…¶ä»–åŒ»å­¦å½±åƒæ¨¡æ€ï¼Œå¦‚CTå’ŒMRIï¼Œå®ç°æ›´å…¨é¢çš„åŒ»å­¦æŠ¥å‘Šè‡ªåŠ¨ç”Ÿæˆã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> X-ray image-based medical report generation (MRG) is a pivotal area in artificial intelligence that can significantly reduce diagnostic burdens for clinicians and patient wait times. Existing MRG models predominantly rely on Large Language Models (LLMs) to improve report generation, with limited exploration of pre-trained vision foundation models or advanced fine-tuning techniques. Mainstream frameworks either avoid fine-tuning or utilize simplistic methods like LoRA, often neglecting the potential of enhancing cross-attention mechanisms. Additionally, while Transformer-based models dominate vision-language tasks, non-Transformer architectures, such as the Mamba network, remain underexplored for medical report generation, presenting a promising avenue for future research. In this paper, we propose EMRRG, a novel X-ray report generation framework that fine-tunes pre-trained Mamba networks using parameter-efficient methods. Specifically, X-ray images are divided into patches, tokenized, and processed by an SSM-based vision backbone for feature extraction, with Partial LoRA yielding optimal performance. An LLM with a hybrid decoder generates the medical report, enabling end-to-end training and achieving strong results on benchmark datasets. Extensive experiments on three widely used benchmark datasets fully validated the effectiveness of our proposed strategies for the X-ray MRG. The source code of this paper will be released on https://github.com/Event-AHU/Medical_Image_Analysis.

