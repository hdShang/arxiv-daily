---
layout: default
title: MambaScope: Coarse-to-Fine Scoping for Efficient Vision Mamba
---

# MambaScope: Coarse-to-Fine Scoping for Efficient Vision Mamba

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.00647" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.00647v2</a>
  <a href="https://arxiv.org/pdf/2512.00647.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.00647v2" onclick="toggleFavorite(this, '2512.00647v2', 'MambaScope: Coarse-to-Fine Scoping for Efficient Vision Mamba')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shanhui Liu, Rui Xu, Yunke Wang

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-29 (æ›´æ–°: 2025-12-03)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**MambaScopeï¼šç”¨äºé«˜æ•ˆVision Mambaçš„ç²—åˆ°ç»†è‡ªé€‚åº”æ¨ç†æ¡†æ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `Vision Mamba` `é«˜æ•ˆæ¨ç†` `è‡ªé€‚åº”è®¡ç®—` `åŠ¨æ€åˆ†è¾¨ç‡` `è§†è§‰ä»»åŠ¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰Vision Mambaçš„tokenç¼©å‡æ–¹æ³•ä¼šå› ä¸¢å¼ƒæˆ–å‹ç¼©tokenè¡¨ç¤ºè€Œå¯¼è‡´ä¿¡æ¯æŸå¤±ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†ä¸åŒå¤æ‚åº¦çš„å›¾åƒæ—¶ã€‚
2. MambaScopeé€šè¿‡ç²—ç²’åº¦æ¨ç†å¿«é€Ÿå¤„ç†ç®€å•å›¾åƒï¼Œä»…å¯¹å¤æ‚åŒºåŸŸè¿›è¡Œç»†ç²’åº¦å¤„ç†ï¼Œä»è€Œè‡ªé€‚åº”åœ°åˆ†é…è®¡ç®—èµ„æºã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒMambaScopeåœ¨å¤šç§è§†è§‰ä»»åŠ¡ä¸­ï¼Œç›¸æ¯”åŸºçº¿Vision Mambaå’Œç°æœ‰tokenç¼©å‡æŠ€æœ¯ï¼Œå®ç°äº†æ›´é«˜çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

Vision Mambaä½œä¸ºVision Transformerçš„ä¸€ç§æœ‰å‰æ™¯ä¸”é«˜æ•ˆçš„æ›¿ä»£æ–¹æ¡ˆå·²ç»å‡ºç°ï¼Œä½†å…¶æ•ˆç‡ä»ç„¶å—åˆ°è¾“å…¥tokenæ•°é‡çš„æ ¹æœ¬é™åˆ¶ã€‚ç°æœ‰çš„tokenç¼©å‡æ–¹æ³•é€šå¸¸é‡‡ç”¨tokenå‰ªææˆ–åˆå¹¶æ¥å‡å°‘è®¡ç®—é‡ã€‚ç„¶è€Œï¼Œå®ƒä»¬å›ºæœ‰åœ°å¯¼è‡´ä¿¡æ¯ä¸¢å¤±ï¼Œå› ä¸ºå®ƒä»¬ä¸¢å¼ƒæˆ–å‹ç¼©tokenè¡¨ç¤ºã€‚å½“ç›¸åŒçš„ç»†ç²’åº¦tokenå¤„ç†è¢«ç»Ÿä¸€åº”ç”¨äºæ‰€æœ‰å›¾åƒæ—¶ï¼Œæ— è®ºè§†è§‰å¤æ‚æ€§å¦‚ä½•ï¼Œè¿™ä¸ªé—®é¢˜éƒ½ä¼šè¿›ä¸€æ­¥åŠ å‰§ã€‚æˆ‘ä»¬è§‚å¯Ÿåˆ°å¹¶éæ‰€æœ‰è¾“å…¥éƒ½éœ€è¦ç»†ç²’åº¦å¤„ç†ï¼šç®€å•çš„å›¾åƒå¯ä»¥åœ¨ç²—åˆ†è¾¨ç‡ä¸‹æœ‰æ•ˆåœ°å¤„ç†ï¼Œè€Œåªæœ‰å¤æ‚çš„å›¾åƒæ‰éœ€è¦ç»†åŒ–ã€‚åŸºäºè¿™ç§æ´å¯Ÿï¼Œæˆ‘ä»¬æå‡ºäº†MambaScopeï¼Œä¸€ç§ç”¨äºé«˜æ•ˆVision Mambaæ¨ç†çš„è‡ªé€‚åº”æ¡†æ¶ã€‚MambaScopeé¦–å…ˆé€šè¿‡å°†è¾“å…¥å›¾åƒåˆ’åˆ†ä¸ºå¤§patchæ¥æ‰§è¡Œç²—ç²’åº¦æ¨ç†ï¼Œä»è€Œæ˜¾è‘—å‡å°‘tokené•¿åº¦å’Œè®¡ç®—é‡ã€‚å½“æ¨¡å‹çš„é¢„æµ‹ç½®ä¿¡åº¦è¾ƒä½æ—¶ï¼Œé€‰æ‹©çš„åŒºåŸŸä»¥æ›´ç²¾ç»†çš„åˆ†è¾¨ç‡é‡æ–°å¤„ç†ï¼Œä»¥æœ€å°çš„é¢å¤–æˆæœ¬æ¢å¤å¿…è¦çš„è§†è§‰ç»†èŠ‚ã€‚è¿™ç§åŠ¨æ€åˆ†è¾¨ç‡åˆ†é…ç­–ç•¥å…è®¸MambaScopeæ ¹æ®å›¾åƒå¤æ‚æ€§è‡ªé€‚åº”åœ°åˆ†é…è®¡ç®—é‡ï¼Œä»è€Œåœ¨ä¸å½±å“å‡†ç¡®æ€§çš„æƒ…å†µä¸‹å®ç°é«˜æ•ˆå¤„ç†ã€‚è·¨å„ç§è§†è§‰ä»»åŠ¡çš„å®éªŒè¡¨æ˜ï¼ŒMambaScopeåœ¨å‡†ç¡®æ€§å’Œæ•ˆç‡æ–¹é¢å‡ä¼˜äºåŸºçº¿Vision Mambaå’Œæœ€å…ˆè¿›çš„tokenç¼©å‡æŠ€æœ¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³Vision Mambaåœ¨å¤„ç†ä¸åŒå¤æ‚åº¦çš„å›¾åƒæ—¶ï¼Œè®¡ç®—èµ„æºåˆ†é…ä¸å‡çš„é—®é¢˜ã€‚ç°æœ‰tokenç¼©å‡æ–¹æ³•ï¼Œå¦‚å‰ªæå’Œåˆå¹¶ï¼Œä¼šä¸å¯é¿å…åœ°é€ æˆä¿¡æ¯æŸå¤±ï¼Œå¹¶ä¸”æ— æ³•æ ¹æ®å›¾åƒå†…å®¹è‡ªé€‚åº”åœ°è°ƒæ•´è®¡ç®—é‡ï¼Œå¯¼è‡´æ•ˆç‡ç“¶é¢ˆã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€æƒ³æ˜¯æ ¹æ®å›¾åƒçš„è§†è§‰å¤æ‚æ€§ï¼ŒåŠ¨æ€åœ°è°ƒæ•´æ¨ç†çš„åˆ†è¾¨ç‡ã€‚å¯¹äºç®€å•çš„å›¾åƒï¼Œé‡‡ç”¨ç²—ç²’åº¦çš„æ¨ç†æ–¹å¼ï¼Œå‡å°‘tokenæ•°é‡ï¼Œé™ä½è®¡ç®—æˆæœ¬ï¼›å¯¹äºå¤æ‚çš„å›¾åƒï¼Œåˆ™åœ¨éœ€è¦ç²¾ç»†ä¿¡æ¯çš„åŒºåŸŸé‡‡ç”¨ç»†ç²’åº¦çš„æ¨ç†æ–¹å¼ï¼Œä»¥ä¿è¯å‡†ç¡®æ€§ã€‚è¿™ç§è‡ªé€‚åº”çš„ç­–ç•¥å¯ä»¥åœ¨ä¿è¯æ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—æé«˜è®¡ç®—æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMambaScopeæ¡†æ¶ä¸»è¦åŒ…å«ä¸¤ä¸ªé˜¶æ®µï¼šç²—ç²’åº¦æ¨ç†é˜¶æ®µå’Œç»†ç²’åº¦æ¨ç†é˜¶æ®µã€‚åœ¨ç²—ç²’åº¦æ¨ç†é˜¶æ®µï¼Œè¾“å…¥å›¾åƒè¢«åˆ’åˆ†ä¸ºè¾ƒå¤§çš„patchï¼Œå‡å°‘tokenæ•°é‡ï¼Œå¹¶ä½¿ç”¨Vision Mambaè¿›è¡Œåˆæ­¥é¢„æµ‹ã€‚å¦‚æœæ¨¡å‹çš„é¢„æµ‹ç½®ä¿¡åº¦è¾ƒä½ï¼Œåˆ™è¿›å…¥ç»†ç²’åº¦æ¨ç†é˜¶æ®µã€‚åœ¨ç»†ç²’åº¦æ¨ç†é˜¶æ®µï¼Œé€‰æ‹©ç½®ä¿¡åº¦è¾ƒä½çš„åŒºåŸŸï¼Œä»¥æ›´ç²¾ç»†çš„åˆ†è¾¨ç‡é‡æ–°å¤„ç†ï¼Œä»è€Œæ¢å¤å¿…è¦çš„è§†è§‰ç»†èŠ‚ã€‚

**å…³é”®åˆ›æ–°**ï¼šMambaScopeçš„å…³é”®åˆ›æ–°åœ¨äºå…¶åŠ¨æ€åˆ†è¾¨ç‡åˆ†é…ç­–ç•¥ã€‚ä¸ç°æœ‰æ–¹æ³•ä¸åŒï¼ŒMambaScopeä¸æ˜¯å¯¹æ‰€æœ‰å›¾åƒéƒ½é‡‡ç”¨ç›¸åŒçš„å¤„ç†æ–¹å¼ï¼Œè€Œæ˜¯æ ¹æ®å›¾åƒçš„å¤æ‚æ€§è‡ªé€‚åº”åœ°è°ƒæ•´è®¡ç®—é‡ã€‚è¿™ç§ç­–ç•¥å¯ä»¥åœ¨ä¿è¯å‡†ç¡®æ€§çš„å‰æä¸‹ï¼Œæ˜¾è‘—æé«˜è®¡ç®—æ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šMambaScopeçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨é¢„æµ‹ç½®ä¿¡åº¦ä½œä¸ºé€‰æ‹©éœ€è¦ç»†ç²’åº¦å¤„ç†åŒºåŸŸçš„æŒ‡æ ‡ï¼›2) é‡‡ç”¨ç²—åˆ°ç»†çš„åˆ†è¾¨ç‡ç­–ç•¥ï¼Œå…ˆè¿›è¡Œç²—ç²’åº¦æ¨ç†ï¼Œå†æ ¹æ®éœ€è¦è¿›è¡Œç»†ç²’åº¦æ¨ç†ï¼›3) æ¡†æ¶å¯ä»¥çµæ´»åœ°ä¸ä¸åŒçš„Vision Mambaæ¨¡å‹ç»“åˆä½¿ç”¨ï¼Œå…·æœ‰è¾ƒå¼ºçš„é€šç”¨æ€§ã€‚å…·ä½“å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœªæ˜ç¡®æåŠï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒMambaScopeåœ¨å¤šä¸ªè§†è§‰ä»»åŠ¡ä¸Šå‡ä¼˜äºåŸºçº¿Vision Mambaå’Œç°æœ‰çš„tokenç¼©å‡æŠ€æœ¯ã€‚å…·ä½“æ€§èƒ½æ•°æ®åœ¨æ‘˜è¦ä¸­æœ‰æ‰€æåŠï¼Œä½†æœªç»™å‡ºå…·ä½“æ•°å€¼ã€‚æ€»ä½“è€Œè¨€ï¼ŒMambaScopeåœ¨ä¿è¯æˆ–æå‡å‡†ç¡®ç‡çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—æˆæœ¬ï¼ŒéªŒè¯äº†å…¶é«˜æ•ˆæ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MambaScopeå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚åœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šéƒ¨ç½²è§†è§‰æ¨¡å‹ï¼Œå¦‚ç§»åŠ¨è®¾å¤‡å’ŒåµŒå…¥å¼ç³»ç»Ÿã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥åº”ç”¨äºå®æ—¶è§†é¢‘åˆ†æã€è‡ªåŠ¨é©¾é©¶ç­‰éœ€è¦é«˜æ•ˆæ¨ç†çš„åœºæ™¯ï¼Œé™ä½è®¡ç®—æˆæœ¬ï¼Œæé«˜å“åº”é€Ÿåº¦ã€‚æœªæ¥ï¼ŒMambaScopeçš„è‡ªé€‚åº”æ¨ç†æ€æƒ³å¯ä»¥æ¨å¹¿åˆ°å…¶ä»–è§†è§‰æ¨¡å‹å’Œä»»åŠ¡ä¸­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision Mamba has emerged as a promising and efficient alternative to Vision Transformers, yet its efficiency remains fundamentally constrained by the number of input tokens. Existing token reduction approaches typically adopt token pruning or merging to reduce computation. However, they inherently lead to information loss as they discard or compress token representations. This problem is further exacerbated when the same fine-grained token processing is uniformly applied across all images regardless of visual complexity. We observe that not all inputs require fine-grained processing: simple images can be effectively handled at a coarse resolution, while only complex ones require refinement. Based on this insight, we propose MambaScope, an adaptive framework for efficient inference for Vision Mamba. MambaScope first performs coarse-grained inference by dividing the input image into large patches, significantly reducing token length and computation. When the model's prediction confidence is low, selected regions are re-processed at a finer resolution to recover essential visual details with minimal additional cost. This dynamic resolution assignment strategy allows MambaScope to allocate computation adaptively according to image complexity, achieving efficient processing without compromising accuracy. Experiments across various vision tasks demonstrate that MambaScope outperforms both the baseline Vision Mamba and state-of-the-art token reduction techniques in terms of accuracy and efficiency.

