---
layout: default
title: PRISM-Bench: A Benchmark of Puzzle-Based Visual Tasks with CoT Error Detection
---

# PRISM-Bench: A Benchmark of Puzzle-Based Visual Tasks with CoT Error Detection

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.23594" target="_blank" class="toolbar-btn">arXiv: 2510.23594v4</a>
    <a href="https://arxiv.org/pdf/2510.23594.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.23594v4" 
            onclick="toggleFavorite(this, '2510.23594v4', 'PRISM-Bench: A Benchmark of Puzzle-Based Visual Tasks with CoT Error Detection')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yusu Qian, Cheng Wan, Chao Jia, Yinfei Yang, Qingyu Zhao, Zhe Gan

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-27 (Êõ¥Êñ∞: 2025-12-01)

**Â§áÊ≥®**: This paper's first error detection task's ground truth data contains hallucination introduced by gpt and needs to be withdrawn

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**PRISM-BenchÔºö‰∏Ä‰∏™Âü∫‰∫éË∞úÈ¢òÁöÑÂèØËß£ÈáäÂ§öÊ®°ÊÄÅÊé®ÁêÜËØÑÊµãÂü∫ÂáÜ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `ËßÜËßâÊé®ÁêÜ` `Êé®ÁêÜËØäÊñ≠` `ÈîôËØØÊ£ÄÊµã` `ËØÑÊµãÂü∫ÂáÜ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâMLLMÂú®ËßÜËßâÊé®ÁêÜ‰∏≠Â≠òÂú®Êé®ÁêÜËøáÁ®ã‰∏çÂèØÈù†ÁöÑÈóÆÈ¢òÔºåÁº∫‰πèÂØπÊé®ÁêÜËøáÁ®ãÁöÑÁªÜÁ≤íÂ∫¶ËØÑ‰º∞„ÄÇ
2. PRISM-BenchÈÄöËøáËÆæËÆ°Ë∞úÈ¢òÂíåÈîôËØØËØäÊñ≠‰ªªÂä°ÔºåËØÑ‰º∞Ê®°ÂûãÊé®ÁêÜÁöÑÈÄªËæë‰∏ÄËá¥ÊÄß„ÄÅÈîôËØØÊ£ÄÊµãÂíåËßÜËßâÊé®ÁêÜËÉΩÂäõ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåÁé∞ÊúâMLLMÂú®ÊµÅÁïÖÁîüÊàêCoTÁöÑÂêåÊó∂ÔºåÈöæ‰ª•ÂÆö‰ΩçÊé®ÁêÜËøáÁ®ã‰∏≠ÁöÑÈÄªËæëÈîôËØØÔºåÊè≠Á§∫‰∫ÜÁîüÊàê‰∏éÈ™åËØÅ‰πãÈó¥ÁöÑÂ∑ÆË∑ù„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã(MLLM)Âú®ËßÜËßâ-ËØ≠Ë®Ä‰ªªÂä°‰∏äÂèñÂæó‰∫ÜÊòæËëóËøõÂ±ïÔºå‰ΩÜÂÖ∂Êé®ÁêÜËøáÁ®ãÊúâÊó∂‰ªç‰∏çÂèØÈù†„ÄÇÊàë‰ª¨Êé®Âá∫‰∫ÜPRISM-BenchÔºåËøôÊòØ‰∏Ä‰∏™Âü∫‰∫éË∞úÈ¢òÁöÑËßÜËßâÊåëÊàòÂü∫ÂáÜÔºåÊó®Âú®ËØÑ‰º∞Ê®°ÂûãÊòØÂê¶ËÉΩËß£ÂÜ≥ÈóÆÈ¢òÔºå‰ª•ÂèäÂÆÉ‰ª¨ÁöÑÊé®ÁêÜÂ¶Ç‰ΩïÂ±ïÂºÄ„ÄÇ‰∏é‰ª•ÂæÄ‰ªÖË°°ÈáèÊúÄÁªàÁ≠îÊ°àÂáÜÁ°ÆÊÄßÁöÑËØÑ‰º∞‰∏çÂêåÔºåPRISM-BenchÂºïÂÖ•‰∫Ü‰∏ÄÈ°πËØäÊñ≠‰ªªÂä°ÔºöÁªôÂÆö‰∏Ä‰∏™ËßÜËßâË∞úÈ¢òÂíå‰∏Ä‰∏™ÂåÖÂê´ÊÅ∞Â•Ω‰∏Ä‰∏™ÈîôËØØÁöÑÈÄêÊ≠•ÊÄùÁª¥Èìæ(CoT)ÔºåÊ®°ÂûãÂøÖÈ°ªËØÜÂà´Á¨¨‰∏Ä‰∏™‰∏çÊ≠£Á°ÆÁöÑÊ≠•È™§„ÄÇËøôÁßçËÆæÁΩÆËÉΩÂ§üÂØπÈÄªËæë‰∏ÄËá¥ÊÄß„ÄÅÈîôËØØÊ£ÄÊµãÂíåËßÜËßâÊé®ÁêÜËøõË°åÁªÜÁ≤íÂ∫¶ËØÑ‰º∞„ÄÇPRISM-Bench‰∏≠ÁöÑË∞úÈ¢òÈúÄË¶ÅÂ§öÊ≠•È™§ÁöÑÁ¨¶Âè∑„ÄÅÂá†‰ΩïÂíåÁ±ªÊØîÊé®ÁêÜÔºåÊäµÂà∂Âü∫‰∫éË°®Èù¢Ê®°ÂºèÂåπÈÖçÁöÑÊç∑ÂæÑ„ÄÇÂØπÊúÄÂÖàËøõÁöÑMLLMÁöÑËØÑ‰º∞Êè≠Á§∫‰∫ÜÊµÅÁïÖÁîüÊàêÂíåÂø†ÂÆûÊé®ÁêÜ‰πãÈó¥ÊåÅÁª≠Â≠òÂú®ÁöÑÂ∑ÆË∑ùÔºö‰∫ßÁîüÁúã‰ººÂêàÁêÜÁöÑCoTÁöÑÊ®°ÂûãÂ∏∏Â∏∏Êó†Ê≥ïÂÆö‰ΩçÁÆÄÂçïÁöÑÈÄªËæëÈîôËØØ„ÄÇÈÄöËøáÂ∞ÜÁ≠îÊ°àÁîüÊàê‰∏éÊé®ÁêÜÈ™åËØÅÂàÜÁ¶ªÔºåPRISM-Bench‰∏∫Â§öÊ®°ÊÄÅÊé®ÁêÜËÉΩÂäõÊèê‰æõ‰∫Ü‰∏Ä‰∏™Êõ¥Ê∏ÖÊô∞ÁöÑËßÜËßíÔºåÂπ∂Âº∫Ë∞É‰∫ÜÂú®ÂèØ‰ø°MLLMÁöÑÂºÄÂèë‰∏≠ËØäÊñ≠ËØÑ‰º∞ÂçèËÆÆÁöÑÂøÖË¶ÅÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Â§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMÔºâÂú®ËßÜËßâÊé®ÁêÜ‰ªªÂä°‰∏≠Êé®ÁêÜËøáÁ®ã‰∏çÂèØÈù†ÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ï‰∏ªË¶ÅÂÖ≥Ê≥®ÊúÄÁªàÁ≠îÊ°àÁöÑÂáÜÁ°ÆÊÄßÔºåÂøΩÁï•‰∫ÜÂØπÊ®°ÂûãÊé®ÁêÜËøáÁ®ãÁöÑËØÑ‰º∞ÔºåÂØºËá¥Ê®°ÂûãÂèØËÉΩÈÄöËøáË°®Èù¢Ê®°ÂºèÂåπÈÖçÁ≠âÊç∑ÂæÑËé∑ÂæóÊ≠£Á°ÆÁ≠îÊ°àÔºåËÄåÊó†Ê≥ïÁúüÊ≠£ÁêÜËß£ÂíåËß£ÂÜ≥ÈóÆÈ¢ò„ÄÇÂõ†Ê≠§ÔºåÈúÄË¶Å‰∏ÄÁßçËÉΩÂ§üËØÑ‰º∞Ê®°ÂûãÊé®ÁêÜËøáÁ®ãÁöÑÂü∫ÂáÜÔºå‰ª•ËØäÊñ≠Ê®°ÂûãÁöÑÈÄªËæë‰∏ÄËá¥ÊÄß„ÄÅÈîôËØØÊ£ÄÊµãÂíåËßÜËßâÊé®ÁêÜËÉΩÂäõ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáËÆæËÆ°Âü∫‰∫éË∞úÈ¢òÁöÑËßÜËßâÊåëÊàòÔºåÂπ∂ÂºïÂÖ•ÈîôËØØËØäÊñ≠‰ªªÂä°ÔºåÊù•ËØÑ‰º∞MLLMÁöÑÊé®ÁêÜËøáÁ®ã„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÁªôÂÆö‰∏Ä‰∏™ËßÜËßâË∞úÈ¢òÂíå‰∏Ä‰∏™ÂåÖÂê´‰∏Ä‰∏™ÈîôËØØÁöÑÈÄêÊ≠•ÊÄùÁª¥ÈìæÔºàCoTÔºâÔºåÊ®°ÂûãÈúÄË¶ÅËØÜÂà´Âá∫Á¨¨‰∏Ä‰∏™‰∏çÊ≠£Á°ÆÁöÑÊ≠•È™§„ÄÇËøôÁßçÊñπÊ≥ïÂ∞ÜÁ≠îÊ°àÁîüÊàê‰∏éÊé®ÁêÜÈ™åËØÅÂàÜÁ¶ªÔºå‰ªéËÄåËÉΩÂ§üÊõ¥Ê∏ÖÊô∞Âú∞ËØÑ‰º∞Ê®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöPRISM-BenchÂü∫ÂáÜÂåÖÂê´‰∏ÄÁ≥ªÂàóÂü∫‰∫éË∞úÈ¢òÁöÑËßÜËßâÊåëÊàòÔºåÊØè‰∏™ÊåëÊàòÈÉΩÂåÖÂê´‰∏Ä‰∏™ËßÜËßâË∞úÈ¢òÂíå‰∏Ä‰∏™ÈÄêÊ≠•ÊÄùÁª¥ÈìæÔºàCoTÔºâ„ÄÇCoT‰∏≠ÂåÖÂê´‰∏Ä‰∏™ÈîôËØØÊ≠•È™§„ÄÇÊ®°ÂûãÁöÑ‰ªªÂä°ÊòØËØÜÂà´CoT‰∏≠ÁöÑÁ¨¨‰∏Ä‰∏™ÈîôËØØÊ≠•È™§„ÄÇÊï¥‰∏™ËØÑ‰º∞ÊµÅÁ®ãÂåÖÊã¨Ôºö1ÔºâÂêëÊ®°ÂûãÂ±ïÁ§∫ËßÜËßâË∞úÈ¢òÂíåCoTÔºõ2ÔºâÊ®°ÂûãÂàÜÊûêCoTÔºåÂπ∂Â∞ùËØïËØÜÂà´ÈîôËØØÊ≠•È™§Ôºõ3ÔºâËØÑ‰º∞Ê®°ÂûãËØÜÂà´ÈîôËØØÊ≠•È™§ÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöPRISM-BenchÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂºïÂÖ•‰∫ÜÈîôËØØËØäÊñ≠‰ªªÂä°ÔºåËÉΩÂ§üÂØπMLLMÁöÑÊé®ÁêÜËøáÁ®ãËøõË°åÁªÜÁ≤íÂ∫¶ËØÑ‰º∞„ÄÇ‰∏é‰ª•ÂæÄ‰ªÖÂÖ≥Ê≥®ÊúÄÁªàÁ≠îÊ°àÂáÜÁ°ÆÊÄßÁöÑËØÑ‰º∞ÊñπÊ≥ï‰∏çÂêåÔºåPRISM-BenchËÉΩÂ§üËØÑ‰º∞Ê®°ÂûãÁöÑÈÄªËæë‰∏ÄËá¥ÊÄß„ÄÅÈîôËØØÊ£ÄÊµãÂíåËßÜËßâÊé®ÁêÜËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåPRISM-Bench‰∏≠ÁöÑË∞úÈ¢òËÆæËÆ°ÈúÄË¶ÅÂ§öÊ≠•È™§ÁöÑÁ¨¶Âè∑„ÄÅÂá†‰ΩïÂíåÁ±ªÊØîÊé®ÁêÜÔºåËÉΩÂ§üÊúâÊïàÊäµÂà∂Âü∫‰∫éË°®Èù¢Ê®°ÂºèÂåπÈÖçÁöÑÊç∑ÂæÑ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöPRISM-Bench‰∏≠ÁöÑË∞úÈ¢òÊ∂µÁõñÂ§öÁßçÁ±ªÂûãÔºåÂåÖÊã¨Á¨¶Âè∑Êé®ÁêÜ„ÄÅÂá†‰ΩïÊé®ÁêÜÂíåÁ±ªÊØîÊé®ÁêÜ„ÄÇCoTÁöÑÁîüÊàêÊñπÂºè‰øùËØÅÊØè‰∏™CoT‰∏≠ÊÅ∞Â•ΩÂåÖÂê´‰∏Ä‰∏™ÈîôËØØÊ≠•È™§ÔºåÂπ∂‰∏îÈîôËØØÊ≠•È™§ÁöÑ‰ΩçÁΩÆÊòØÈöèÊú∫ÁöÑ„ÄÇËØÑ‰º∞ÊåáÊ†á‰∏ªË¶ÅÂåÖÊã¨ÈîôËØØËØäÊñ≠ÁöÑÂáÜÁ°ÆÁéáÔºåÂç≥Ê®°ÂûãÊ≠£Á°ÆËØÜÂà´ÈîôËØØÊ≠•È™§ÁöÑÊØî‰æã„ÄÇÊ≤°ÊúâÊ∂âÂèäÂÖ∑‰ΩìÁöÑÁΩëÁªúÁªìÊûÑÊàñÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°ÔºåÈáçÁÇπÂú®‰∫éÂü∫ÂáÜÊï∞ÊçÆÈõÜÂíåËØÑ‰º∞ÊñπÂºèÁöÑËÆæËÆ°„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÁé∞ÊúâÁöÑÊúÄÂÖàËøõMLLMÂú®PRISM-Bench‰∏äË°®Áé∞Âá∫ÊòæËëóÁöÑÂ∑ÆË∑ùÔºåÂç≥Ê®°ÂûãÂèØ‰ª•ÁîüÊàêÁúã‰ººÂêàÁêÜÁöÑCoTÔºå‰ΩÜÂç¥Èöæ‰ª•ÂÆö‰ΩçCoT‰∏≠ÁöÑÁÆÄÂçïÈÄªËæëÈîôËØØ„ÄÇËøôË°®ÊòéÁé∞ÊúâÊ®°ÂûãÂú®ÊµÅÁïÖÁîüÊàêÂíåÂø†ÂÆûÊé®ÁêÜ‰πãÈó¥Â≠òÂú®ËÑ±ËäÇ„ÄÇ‰æãÂ¶ÇÔºå‰∏Ä‰∫õÊ®°ÂûãÂú®ÈîôËØØËØäÊñ≠‰ªªÂä°‰∏äÁöÑÂáÜÁ°ÆÁéáËøú‰Ωé‰∫éÂÖ∂Âú®‰º†ÁªüËßÜËßâ-ËØ≠Ë®Ä‰ªªÂä°‰∏äÁöÑÂáÜÁ°ÆÁéáÔºåÁ™ÅÂá∫‰∫ÜËØäÊñ≠ËØÑ‰º∞ÂçèËÆÆÁöÑÂøÖË¶ÅÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

PRISM-BenchÂèØÁî®‰∫éËØÑ‰º∞ÂíåÊîπËøõÂ§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõÔºåÂ∞§ÂÖ∂ÊòØÂú®ÈúÄË¶ÅÂèØ‰ø°ËµñÊé®ÁêÜÁöÑÂú∫ÊôØ‰∏≠Ôºå‰æãÂ¶ÇÂåªÁñóËØäÊñ≠„ÄÅËá™Âä®È©æÈ©∂ÂíåÈáëËûçÂàÜÊûê„ÄÇÈÄöËøáËØäÊñ≠Ê®°ÂûãÊé®ÁêÜËøáÁ®ã‰∏≠ÁöÑÈîôËØØÔºåÂèØ‰ª•Â∏ÆÂä©Á†îÁ©∂‰∫∫ÂëòÂºÄÂèëÊõ¥È≤ÅÊ£í„ÄÅÊõ¥ÂèØÈù†ÁöÑMLLMÔºå‰ªéËÄåÊèêÈ´òËøô‰∫õÊ®°ÂûãÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÂÆâÂÖ®ÊÄßÂíåÊúâÊïàÊÄß„ÄÇÊ≠§Â§ñÔºåËØ•Âü∫ÂáÜËøòÂèØ‰ª•‰øÉËøõÂØπ‰∫∫Á±ªËÆ§Áü•ÂíåÊé®ÁêÜËøáÁ®ãÁöÑÁêÜËß£„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Multimodal large language models (MLLMs) have achieved remarkable progress on vision-language tasks, yet their reasoning processes remain sometimes unreliable. We introduce PRISM-Bench, a benchmark of puzzle-based visual challenges designed to evaluate not only whether models can solve problems, but how their reasoning unfolds. Unlike prior evaluations that measure only final-answer accuracy, PRISM-Bench introduces a diagnostic task: given a visual puzzle and a step-by-step chain-of-thought (CoT) containing exactly one error, models must identify the first incorrect step. This setting enables fine-grained assessment of logical consistency, error detection, and visual reasoning. The puzzles in PRISM-Bench require multi-step symbolic, geometric, and analogical reasoning, resisting shortcuts based on superficial pattern matching. Evaluations across state-of-the-art MLLMs reveal a persistent gap between fluent generation and faithful reasoning: models that produce plausible CoTs often fail to locate simple logical faults. By disentangling answer generation from reasoning verification, PRISM-Bench offers a sharper lens on multimodal reasoning competence and underscores the need for diagnostic evaluation protocols in the development of trustworthy MLLMs.

