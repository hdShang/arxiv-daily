---
layout: default
title: "VR-Drive: Viewpoint-Robust End-to-End Driving with Feed-Forward 3D Gaussian Splatting"
---

# VR-Drive: Viewpoint-Robust End-to-End Driving with Feed-Forward 3D Gaussian Splatting

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.23205" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.23205v1</a>
  <a href="https://arxiv.org/pdf/2510.23205.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.23205v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.23205v1', 'VR-Drive: Viewpoint-Robust End-to-End Driving with Feed-Forward 3D Gaussian Splatting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hoonhee Cho, Jae-Young Kang, Giwon Lee, Hyemin Yang, Heejun Park, Seokwoo Jung, Kuk-Jin Yoon

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-27

**å¤‡æ³¨**: Accepted by NeurIPS2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**VR-Driveï¼šåˆ©ç”¨å‰é¦ˆ3Dé«˜æ–¯æº…å°„å®ç°è§†è§’é²æ£’çš„ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶` `è§†è§’æ³›åŒ–` `3Dé«˜æ–¯æº…å°„` `è§†å›¾åˆæˆ` `é¢†åŸŸè‡ªé€‚åº”`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶æ–¹æ³•åœ¨ä¸åŒç›¸æœºè§†è§’ä¸‹çš„æ³›åŒ–èƒ½åŠ›ä¸è¶³ï¼Œéš¾ä»¥é€‚åº”çœŸå®ä¸–ç•Œä¸­è½¦è¾†é…ç½®çš„å¤šæ ·æ€§ã€‚
2. VR-Driveé€šè¿‡è”åˆå­¦ä¹ 3Dåœºæ™¯é‡å»ºå’Œè§„åˆ’æ„ŸçŸ¥çš„è§†å›¾åˆæˆï¼Œå®ç°è§†è§’æ³›åŒ–ï¼Œæ— éœ€é¢å¤–æ ‡æ³¨å³å¯è¿›è¡Œåœ¨çº¿è®­ç»ƒæ—¶å¢å¼ºã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒVR-Driveèƒ½æœ‰æ•ˆå‡è½»åˆæˆå™ªå£°ï¼Œæé«˜è§†è§’å˜åŒ–ä¸‹çš„è§„åˆ’æ€§èƒ½ï¼Œå¹¶åœ¨æ–°åŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œäº†å…¨é¢è¯„ä¼°ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶(E2E-AD)å·²æˆä¸ºä¸€ç§æœ‰å‰æ™¯çš„èŒƒä¾‹ï¼Œå®ƒå°†æ„ŸçŸ¥ã€é¢„æµ‹å’Œè§„åˆ’ç»Ÿä¸€åˆ°ä¸€ä¸ªæ•´ä½“çš„ã€æ•°æ®é©±åŠ¨çš„æ¡†æ¶ä¸­ã€‚ç„¶è€Œï¼Œç”±äºè½¦è¾†é…ç½®çš„å¤šæ ·æ€§ï¼Œå®ç°å¯¹ä¸åŒç›¸æœºè§†è§’çš„é²æ£’æ€§ä»ç„¶æ˜¯ä¸€ä¸ªå¼€æ”¾çš„é—®é¢˜ã€‚æœ¬æ–‡æå‡ºäº†VR-Driveï¼Œä¸€ç§æ–°é¢–çš„E2E-ADæ¡†æ¶ï¼Œé€šè¿‡è”åˆå­¦ä¹ 3Dåœºæ™¯é‡å»ºä½œä¸ºè¾…åŠ©ä»»åŠ¡æ¥å®ç°è§†è§’æ³›åŒ–ï¼Œä»è€Œå®ç°è§„åˆ’æ„ŸçŸ¥çš„è§†å›¾åˆæˆã€‚ä¸ä»¥å¾€ç‰¹å®šäºåœºæ™¯çš„åˆæˆæ–¹æ³•ä¸åŒï¼ŒVR-Driveé‡‡ç”¨å‰é¦ˆæ¨ç†ç­–ç•¥ï¼Œæ”¯æŒæ¥è‡ªç¨€ç–è§†è§’çš„åœ¨çº¿è®­ç»ƒæ—¶å¢å¼ºï¼Œè€Œæ— éœ€é¢å¤–çš„æ³¨é‡Šã€‚ä¸ºäº†è¿›ä¸€æ­¥æé«˜è§†è§’ä¸€è‡´æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªè§†è§’æ··åˆçš„è®°å¿†åº“ï¼Œä»¥ä¿ƒè¿›è·¨å¤šä¸ªè§†è§’çš„æ—¶åºäº¤äº’ï¼Œä»¥åŠä¸€ç§è§†è§’ä¸€è‡´çš„è’¸é¦ç­–ç•¥ï¼Œå°†çŸ¥è¯†ä»åŸå§‹è§†å›¾è½¬ç§»åˆ°åˆæˆè§†å›¾ã€‚VR-Driveä»¥å®Œå…¨ç«¯åˆ°ç«¯çš„æ–¹å¼è¿›è¡Œè®­ç»ƒï¼Œæœ‰æ•ˆåœ°å‡è½»äº†åˆæˆå¼•èµ·çš„å™ªå£°ï¼Œå¹¶æé«˜äº†è§†è§’å˜åŒ–ä¸‹çš„è§„åˆ’èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘å¸ƒäº†ä¸€ä¸ªæ–°çš„åŸºå‡†æ•°æ®é›†ï¼Œç”¨äºè¯„ä¼°E2E-ADåœ¨æ–°çš„ç›¸æœºè§†è§’ä¸‹çš„æ€§èƒ½ï¼Œä»è€Œå®ç°å…¨é¢çš„åˆ†æã€‚ç»“æœè¡¨æ˜ï¼ŒVR-Driveæ˜¯ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿå®é™…éƒ¨ç½²çš„å¯æ‰©å±•ä¸”é²æ£’çš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿä¸­ï¼Œç”±äºç›¸æœºè§†è§’å˜åŒ–å¯¼è‡´çš„æ€§èƒ½ä¸‹é™é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥æ³›åŒ–åˆ°æ–°çš„è§†è§’ï¼Œé™åˆ¶äº†å…¶åœ¨çœŸå®ä¸–ç•Œä¸­çš„éƒ¨ç½²ã€‚ç—›ç‚¹åœ¨äºç¼ºä¹æœ‰æ•ˆçš„è§†è§’ä¸å˜æ€§å­¦ä¹ æœºåˆ¶ï¼Œä»¥åŠå¯¹åˆæˆè§†å›¾å™ªå£°çš„é²æ£’æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨3Dé«˜æ–¯æº…å°„è¿›è¡Œåœºæ™¯é‡å»ºï¼Œå¹¶å°†å…¶ä½œä¸ºè¾…åŠ©ä»»åŠ¡æ¥æå‡ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶æ¨¡å‹çš„è§†è§’æ³›åŒ–èƒ½åŠ›ã€‚é€šè¿‡å­¦ä¹ åœºæ™¯çš„3Dè¡¨ç¤ºï¼Œæ¨¡å‹å¯ä»¥åˆæˆä»»æ„è§†è§’çš„å›¾åƒï¼Œä»è€Œåœ¨è®­ç»ƒé˜¶æ®µå¢å¼ºæ•°æ®çš„å¤šæ ·æ€§ï¼Œæé«˜æ¨¡å‹å¯¹è§†è§’å˜åŒ–çš„é²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVR-Driveæ¡†æ¶åŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) 3Dé«˜æ–¯æº…å°„æ¨¡å—ï¼Œç”¨äºä»åŸå§‹å›¾åƒé‡å»º3Dåœºæ™¯ï¼›2) è§†å›¾åˆæˆæ¨¡å—ï¼Œç”¨äºä»é‡å»ºçš„3Dåœºæ™¯ä¸­åˆæˆæ–°çš„è§†è§’å›¾åƒï¼›3) ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶æ¨¡å—ï¼Œç”¨äºæ ¹æ®åŸå§‹å›¾åƒå’Œåˆæˆå›¾åƒè¿›è¡Œè§„åˆ’ã€‚æ­¤å¤–ï¼Œè¿˜åŒ…æ‹¬ä¸€ä¸ªè§†è§’æ··åˆçš„è®°å¿†åº“å’Œä¸€ä¸ªè§†è§’ä¸€è‡´çš„è’¸é¦ç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šä¸»è¦åˆ›æ–°ç‚¹åœ¨äºï¼š1) æå‡ºäº†ä¸€ç§å‰é¦ˆçš„3Dé«˜æ–¯æº…å°„æ–¹æ³•ï¼Œå¯ä»¥è¿›è¡Œåœ¨çº¿è®­ç»ƒæ—¶å¢å¼ºï¼Œæ— éœ€é¢å¤–æ ‡æ³¨ï¼›2) å¼•å…¥äº†è§†è§’æ··åˆçš„è®°å¿†åº“ï¼Œç”¨äºä¿ƒè¿›è·¨å¤šä¸ªè§†è§’çš„æ—¶åºäº¤äº’ï¼›3) æå‡ºäº†ä¸€ç§è§†è§’ä¸€è‡´çš„è’¸é¦ç­–ç•¥ï¼Œç”¨äºå°†çŸ¥è¯†ä»åŸå§‹è§†å›¾è½¬ç§»åˆ°åˆæˆè§†å›¾ã€‚

**å…³é”®è®¾è®¡**ï¼šè§†è§’æ··åˆè®°å¿†åº“çš„è®¾è®¡å…è®¸æ¨¡å‹å­¦ä¹ ä¸åŒè§†è§’ä¸‹çš„åœºæ™¯è¡¨ç¤ºï¼Œä»è€Œæé«˜è§†è§’ä¸€è‡´æ€§ã€‚è§†è§’ä¸€è‡´æ€§è’¸é¦ç­–ç•¥é€šè¿‡æœ€å°åŒ–åŸå§‹è§†å›¾å’Œåˆæˆè§†å›¾ä¹‹é—´çš„ç‰¹å¾å·®å¼‚ï¼Œæ¥å‡å°‘åˆæˆå™ªå£°çš„å½±å“ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬é‡å»ºæŸå¤±ã€è§„åˆ’æŸå¤±å’Œè’¸é¦æŸå¤±ã€‚ç½‘ç»œç»“æ„ç»†èŠ‚æœªæ˜ç¡®ç»™å‡ºï¼Œä½†å¼ºè°ƒäº†ç«¯åˆ°ç«¯çš„è®­ç»ƒæ–¹å¼ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„åŸºå‡†æ•°æ®é›†ï¼Œç”¨äºè¯„ä¼°ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶åœ¨æ–°çš„ç›¸æœºè§†è§’ä¸‹çš„æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒVR-Driveåœ¨è§†è§’æ³›åŒ–æ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æå‡ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°å‡è½»åˆæˆå¼•èµ·çš„å™ªå£°ï¼Œå¹¶æé«˜è§†è§’å˜åŒ–ä¸‹çš„è§„åˆ’èƒ½åŠ›ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿æœªåœ¨æ‘˜è¦ä¸­æ˜ç¡®ç»™å‡ºï¼Œéœ€è¦åœ¨è®ºæ–‡æ­£æ–‡ä¸­æŸ¥æ‰¾ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§è‡ªåŠ¨é©¾é©¶åœºæ™¯ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦é€‚åº”ä¸åŒè½¦è¾†é…ç½®å’Œç›¸æœºè§†è§’çš„åœºæ™¯ä¸­ï¼Œä¾‹å¦‚è‡ªåŠ¨é©¾é©¶å‡ºç§Ÿè½¦ã€ç‰©æµé…é€è½¦è¾†ç­‰ã€‚é€šè¿‡æé«˜è§†è§’é²æ£’æ€§ï¼Œå¯ä»¥é™ä½å¯¹ä¼ æ„Ÿå™¨æ ‡å®šçš„ç²¾åº¦è¦æ±‚ï¼Œå¹¶æé«˜è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ‰©å±•åˆ°å…¶ä»–éœ€è¦è§†è§’æ³›åŒ–çš„æœºå™¨äººåº”ç”¨ä¸­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> End-to-end autonomous driving (E2E-AD) has emerged as a promising paradigm that unifies perception, prediction, and planning into a holistic, data-driven framework. However, achieving robustness to varying camera viewpoints, a common real-world challenge due to diverse vehicle configurations, remains an open problem. In this work, we propose VR-Drive, a novel E2E-AD framework that addresses viewpoint generalization by jointly learning 3D scene reconstruction as an auxiliary task to enable planning-aware view synthesis. Unlike prior scene-specific synthesis approaches, VR-Drive adopts a feed-forward inference strategy that supports online training-time augmentation from sparse views without additional annotations. To further improve viewpoint consistency, we introduce a viewpoint-mixed memory bank that facilitates temporal interaction across multiple viewpoints and a viewpoint-consistent distillation strategy that transfers knowledge from original to synthesized views. Trained in a fully end-to-end manner, VR-Drive effectively mitigates synthesis-induced noise and improves planning under viewpoint shifts. In addition, we release a new benchmark dataset to evaluate E2E-AD performance under novel camera viewpoints, enabling comprehensive analysis. Our results demonstrate that VR-Drive is a scalable and robust solution for the real-world deployment of end-to-end autonomous driving systems.

