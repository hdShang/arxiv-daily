---
layout: default
title: Survey of Multimodal Geospatial Foundation Models: Techniques, Applications, and Challenges
---

# Survey of Multimodal Geospatial Foundation Models: Techniques, Applications, and Challenges

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.22964" target="_blank" class="toolbar-btn">arXiv: 2510.22964v1</a>
    <a href="https://arxiv.org/pdf/2510.22964.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.22964v1" 
            onclick="toggleFavorite(this, '2510.22964v1', 'Survey of Multimodal Geospatial Foundation Models: Techniques, Applications, and Challenges')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Liling Yang, Ning Chen, Jun Yue, Yidan Liu, Jiayi Ma, Pedram Ghamisi, Antonio Plaza, Leyuan Fang

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-27

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÁªºËø∞Â§öÊ®°ÊÄÅÂú∞ÁêÜÁ©∫Èó¥Âü∫Á°ÄÊ®°ÂûãÔºåÂ∫îÂØπÈÅ•ÊÑüÂõæÂÉèÂàÜÊûêÁöÑÊåëÊàò„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `Âú∞ÁêÜÁ©∫Èó¥Âü∫Á°ÄÊ®°Âûã` `ÈÅ•ÊÑüÂõæÂÉèÂàÜÊûê` `ËøÅÁßªÂ≠¶‰π†` `Ê®°ÊÄÅÂØπÈΩê`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ÈÅ•ÊÑüÊï∞ÊçÆÂÖ∑ÊúâÂ§öÊ®°ÊÄÅ„ÄÅÂ§öÂàÜËæ®ÁéáÂíåÂ§öÊó∂Áõ∏ÁâπÊÄßÔºåÁé∞ÊúâÊñπÊ≥ïÈöæ‰ª•ÊúâÊïàÂà©Áî®Ëøô‰∫õ‰ø°ÊÅØ„ÄÇ
2. Êú¨Êñá‰ªéÊ®°ÊÄÅÈ©±Âä®ÁöÑËßíÂ∫¶ÔºåÁªºËø∞‰∫ÜÂ§öÊ®°ÊÄÅÂú∞ÁêÜÁ©∫Èó¥Âü∫Á°ÄÊ®°ÂûãÔºàGFMÔºâÁöÑÂÖ≥ÈîÆÊäÄÊúØÔºåÂåÖÊã¨ÂØπÈΩê„ÄÅÈõÜÊàêÂíåÁü•ËØÜËøÅÁßª„ÄÇ
3. ÈÄöËøáÊ°à‰æãÁ†îÁ©∂ÔºåÂ±ïÁ§∫‰∫ÜGFMÂú®ÂúüÂú∞Ë¶ÜÁõñÂà∂Âõæ„ÄÅÂÜú‰∏öÁõëÊµã„ÄÅÁÅæÂÆ≥ÂìçÂ∫îÁ≠âÈ¢ÜÂüüÁöÑÂÆûÈôÖÂ∫îÁî®ÊΩúÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Âü∫Á°ÄÊ®°ÂûãÂ∑≤ÁªèÂèòÈù©‰∫ÜËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂíåËÆ°ÁÆóÊú∫ËßÜËßâÈ¢ÜÂüüÔºåÁé∞Âú®ÂÆÉ‰ª¨ÁöÑÂΩ±ÂìçÊ≠£Âú®ÈáçÂ°ëÈÅ•ÊÑüÂõæÂÉèÂàÜÊûê„ÄÇÂá≠ÂÄüÂº∫Â§ßÁöÑÊ≥õÂåñÂíåËøÅÁßªÂ≠¶‰π†ËÉΩÂäõÔºåÂÆÉ‰ª¨‰∏éÈÅ•ÊÑüÊï∞ÊçÆÁöÑÂ§öÊ®°ÊÄÅ„ÄÅÂ§öÂàÜËæ®ÁéáÂíåÂ§öÊó∂Áõ∏ÁâπÊÄßËá™ÁÑ∂Â•ëÂêà„ÄÇ‰∏∫‰∫ÜÂ∫îÂØπËØ•È¢ÜÂüü‰∏≠ÁöÑÁã¨ÁâπÊåëÊàòÔºåÂ§öÊ®°ÊÄÅÂú∞ÁêÜÁ©∫Èó¥Âü∫Á°ÄÊ®°ÂûãÔºàGFMÔºâÂ∑≤ÁªèÊàê‰∏∫‰∏Ä‰∏™‰∏ìÈó®ÁöÑÁ†îÁ©∂ÂâçÊ≤ø„ÄÇÊú¨ÁªºËø∞‰ªéÊ®°ÊÄÅÈ©±Âä®ÁöÑËßíÂ∫¶ÂÖ®Èù¢ÂõûÈ°æ‰∫ÜÂ§öÊ®°ÊÄÅGFMÔºåÊ∂µÁõñ‰∫Ü‰∫î‰∏™Ê†∏ÂøÉÁöÑËßÜËßâÂíåËßÜËßâ-ËØ≠Ë®ÄÊ®°ÊÄÅ„ÄÇÊàë‰ª¨Á†îÁ©∂‰∫ÜÊàêÂÉèÁâ©ÁêÜÂíåÊï∞ÊçÆË°®Á§∫ÁöÑÂ∑ÆÂºÇÂ¶Ç‰ΩïÂΩ±Âìç‰∫§‰∫íËÆæËÆ°ÔºåÂπ∂ÂàÜÊûê‰∫ÜÁî®‰∫éÂØπÈΩê„ÄÅÈõÜÊàêÂíåÁü•ËØÜËøÅÁßªÁöÑÂÖ≥ÈîÆÊäÄÊúØÔºå‰ª•Ëß£ÂÜ≥Ê®°ÊÄÅÂºÇË¥®ÊÄß„ÄÅÂàÜÂ∏ÉÂÅèÁßªÂíåËØ≠‰πâÈ∏øÊ≤ü„ÄÇÈô§‰∫ÜÂ§ßÈáèÊñ∞ÂÖ¥ÁöÑÂü∫ÂáÜ‰πãÂ§ñÔºåËøòÁ≥ªÁªüÂú∞ËØÑ‰º∞‰∫ÜËÆ≠ÁªÉËåÉÂºè„ÄÅÊû∂ÊûÑÂíåÁâπÂÆö‰∫é‰ªªÂä°ÁöÑËá™ÈÄÇÂ∫îÁ≠ñÁï•ÁöÑËøõÂ±ï„ÄÇ‰ª£Ë°®ÊÄßÁöÑÂ§öÊ®°ÊÄÅËßÜËßâÂíåËßÜËßâ-ËØ≠Ë®ÄGFMÂú®ÂçÅ‰∏™‰∏ãÊ∏∏‰ªªÂä°‰∏≠ËøõË°å‰∫ÜËØÑ‰º∞ÔºåÊ∑±ÂÖ•‰∫ÜËß£‰∫ÜÂÆÉ‰ª¨ÁöÑÊû∂ÊûÑ„ÄÅÊÄßËÉΩÂíåÂ∫îÁî®Âú∫ÊôØ„ÄÇÊ∂µÁõñÂúüÂú∞Ë¶ÜÁõñÂà∂Âõæ„ÄÅÂÜú‰∏öÁõëÊµã„ÄÅÁÅæÂÆ≥ÂìçÂ∫î„ÄÅÊ∞îÂÄôÁ†îÁ©∂ÂíåÂú∞ÁêÜÁ©∫Èó¥ÊÉÖÊä•ÁöÑÁúüÂÆûÊ°à‰æãÁ†îÁ©∂ËØÅÊòé‰∫ÜGFMÁöÑÂÆûÈôÖÊΩúÂäõ„ÄÇÊúÄÂêéÔºåÊàë‰ª¨Ê¶ÇËø∞‰∫ÜÈ¢ÜÂüüÊ≥õÂåñ„ÄÅÂèØËß£ÈáäÊÄß„ÄÅÊïàÁéáÂíåÈöêÁßÅÊñπÈù¢ÁöÑÁ¥ßËø´ÊåëÊàòÔºåÂπ∂‰∏∫Êú™Êù•ÁöÑÁ†îÁ©∂ËßÑÂàí‰∫ÜÊúâÂ∏åÊúõÁöÑÈÄîÂæÑ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÈÅ•ÊÑüÂõæÂÉèÂàÜÊûêÈù¢‰∏¥ÁùÄÊ®°ÊÄÅÂºÇË¥®ÊÄß„ÄÅÂàÜÂ∏ÉÂÅèÁßªÂíåËØ≠‰πâÈ∏øÊ≤üÁ≠âÊåëÊàò„ÄÇÁé∞ÊúâÁöÑÊñπÊ≥ïÈöæ‰ª•ÊúâÊïàÂú∞ËûçÂêàÊù•Ëá™‰∏çÂêå‰º†ÊÑüÂô®ÂíåÊï∞ÊçÆÊ∫êÁöÑ‰ø°ÊÅØÔºåÂπ∂‰∏îÊ≥õÂåñËÉΩÂäõÊúâÈôê„ÄÇÊ≠§Â§ñÔºåÈÅ•ÊÑüÊï∞ÊçÆÁöÑÊ†áÊ≥®ÊàêÊú¨È´òÊòÇÔºå‰ΩøÂæóËÆ≠ÁªÉÂ§ßËßÑÊ®°Ê®°ÂûãÂèòÂæóÂõ∞Èöæ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊú¨ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÁªºËø∞Â§öÊ®°ÊÄÅÂú∞ÁêÜÁ©∫Èó¥Âü∫Á°ÄÊ®°ÂûãÔºàGFMÔºâÔºåËøô‰∫õÊ®°ÂûãÊó®Âú®Âà©Áî®Â§ßËßÑÊ®°Êú™Ê†áÊ≥®Êï∞ÊçÆËøõË°åÈ¢ÑËÆ≠ÁªÉÔºåÁÑ∂ÂêéÈÄöËøáËøÅÁßªÂ≠¶‰π†ÈÄÇÂ∫îÂêÑÁßç‰∏ãÊ∏∏‰ªªÂä°„ÄÇÈÄöËøáÂØπÈΩê„ÄÅÈõÜÊàêÂíåÁü•ËØÜËøÅÁßªÁ≠âÊäÄÊúØÔºåGFMËÉΩÂ§üÊúâÊïàÂú∞ËûçÂêàÊù•Ëá™‰∏çÂêåÊ®°ÊÄÅÁöÑ‰ø°ÊÅØÔºåÂπ∂ÊèêÈ´òÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊú¨Êñá‰ªéÊ®°ÊÄÅÈ©±Âä®ÁöÑËßíÂ∫¶ÂØπÂ§öÊ®°ÊÄÅGFMËøõË°å‰∫ÜÁªºËø∞ÔºåÊ∂µÁõñ‰∫Ü‰∫î‰∏™Ê†∏ÂøÉÁöÑËßÜËßâÂíåËßÜËßâ-ËØ≠Ë®ÄÊ®°ÊÄÅ„ÄÇÊñáÁ´†È¶ñÂÖà‰ªãÁªç‰∫Ü‰∏çÂêåÊ®°ÊÄÅÁöÑÊàêÂÉèÁâ©ÁêÜÂíåÊï∞ÊçÆË°®Á§∫ÔºåÁÑ∂ÂêéÂàÜÊûê‰∫ÜÁî®‰∫éÂØπÈΩê„ÄÅÈõÜÊàêÂíåÁü•ËØÜËøÅÁßªÁöÑÂÖ≥ÈîÆÊäÄÊúØ„ÄÇÊ≠§Â§ñÔºåÊñáÁ´†ËøòËØÑ‰º∞‰∫ÜËÆ≠ÁªÉËåÉÂºè„ÄÅÊû∂ÊûÑÂíåÁâπÂÆö‰∫é‰ªªÂä°ÁöÑËá™ÈÄÇÂ∫îÁ≠ñÁï•ÁöÑËøõÂ±ï„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊú¨ÊñáÁöÑÂàõÊñ∞‰πãÂ§ÑÂú®‰∫éÂØπÂ§öÊ®°ÊÄÅGFMËøõË°å‰∫ÜÂÖ®Èù¢ÁöÑÁªºËø∞ÔºåÂπ∂‰ªéÊ®°ÊÄÅÈ©±Âä®ÁöÑËßíÂ∫¶ÂàÜÊûê‰∫ÜËøô‰∫õÊ®°Âûã„ÄÇÊñáÁ´†Ê∑±ÂÖ•Êé¢ËÆ®‰∫Ü‰∏çÂêåÊ®°ÊÄÅ‰πãÈó¥ÁöÑ‰∫§‰∫íËÆæËÆ°Ôºå‰ª•ÂèäÂ¶Ç‰ΩïÂà©Áî®ÂØπÈΩê„ÄÅÈõÜÊàêÂíåÁü•ËØÜËøÅÁßªÁ≠âÊäÄÊúØÊù•Ëß£ÂÜ≥Ê®°ÊÄÅÂºÇË¥®ÊÄß„ÄÅÂàÜÂ∏ÉÂÅèÁßªÂíåËØ≠‰πâÈ∏øÊ≤üÁ≠âÈóÆÈ¢ò„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÊú¨ÊñáÈáçÁÇπÂÖ≥Ê≥®‰∫ÜÂ§öÊ®°ÊÄÅGFM‰∏≠ÁöÑÂÖ≥ÈîÆÊäÄÊúØÔºå‰æãÂ¶ÇÔºö(1)Ê®°ÊÄÅÂØπÈΩêÔºöÂ¶Ç‰ΩïÂ∞ÜÊù•Ëá™‰∏çÂêåÊ®°ÊÄÅÁöÑÊï∞ÊçÆÊò†Â∞ÑÂà∞Âêå‰∏Ä‰∏™ÁâπÂæÅÁ©∫Èó¥Ôºõ(2)Ê®°ÊÄÅÈõÜÊàêÔºöÂ¶Ç‰ΩïÊúâÊïàÂú∞ËûçÂêàÊù•Ëá™‰∏çÂêåÊ®°ÊÄÅÁöÑ‰ø°ÊÅØÔºõ(3)Áü•ËØÜËøÅÁßªÔºöÂ¶Ç‰ΩïÂ∞Ü‰ªéÂ§ßËßÑÊ®°Êú™Ê†áÊ≥®Êï∞ÊçÆ‰∏≠Â≠¶Âà∞ÁöÑÁü•ËØÜËøÅÁßªÂà∞‰∏ãÊ∏∏‰ªªÂä°„ÄÇÊñáÁ´†ËøòËÆ®ËÆ∫‰∫Ü‰∏çÂêåÊû∂ÊûÑÂíåËÆ≠ÁªÉËåÉÂºèÁöÑÈÄâÊã©Ôºå‰ª•ÂèäÂ¶Ç‰ΩïÊ†πÊçÆÁâπÂÆö‰ªªÂä°ËøõË°åËá™ÈÄÇÂ∫î„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ËØ•ÁªºËø∞ËØÑ‰º∞‰∫Ü‰ª£Ë°®ÊÄßÁöÑÂ§öÊ®°ÊÄÅËßÜËßâÂíåËßÜËßâ-ËØ≠Ë®ÄGFMÂú®ÂçÅ‰∏™‰∏ãÊ∏∏‰ªªÂä°‰∏≠ÁöÑË°®Áé∞ÔºåÂπ∂Êèê‰æõ‰∫ÜÂÖ≥‰∫éÂÆÉ‰ª¨ÁöÑÊû∂ÊûÑ„ÄÅÊÄßËÉΩÂíåÂ∫îÁî®Âú∫ÊôØÁöÑÊ∑±ÂÖ•ËßÅËß£„ÄÇÈÄöËøáÊ°à‰æãÁ†îÁ©∂ÔºåÂ±ïÁ§∫‰∫ÜGFMÂú®ÂúüÂú∞Ë¶ÜÁõñÂà∂Âõæ„ÄÅÂÜú‰∏öÁõëÊµãÂíåÁÅæÂÆ≥ÂìçÂ∫îÁ≠âÈ¢ÜÂüüÁöÑÂÆûÈôÖÂ∫îÁî®ÊΩúÂäõ„ÄÇËøô‰∫õÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåGFMËÉΩÂ§üÊúâÊïàÂú∞ÊèêÈ´òÈÅ•ÊÑüÂõæÂÉèÂàÜÊûêÁöÑÁ≤æÂ∫¶ÂíåÊïàÁéá„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂπøÊ≥õÂ∫îÁî®‰∫éÈÅ•ÊÑüÂõæÂÉèÂàÜÊûêÈ¢ÜÂüüÔºå‰æãÂ¶ÇÂúüÂú∞Ë¶ÜÁõñÂà∂Âõæ„ÄÅÂÜú‰∏öÁõëÊµã„ÄÅÁÅæÂÆ≥ÂìçÂ∫î„ÄÅÊ∞îÂÄôÁ†îÁ©∂ÂíåÂú∞ÁêÜÁ©∫Èó¥ÊÉÖÊä•Á≠â„ÄÇÈÄöËøáÂà©Áî®Â§öÊ®°ÊÄÅGFMÔºåÂèØ‰ª•ÊèêÈ´òÈÅ•ÊÑüÂõæÂÉèÂàÜÊûêÁöÑÁ≤æÂ∫¶ÂíåÊïàÁéáÔºå‰∏∫Áõ∏ÂÖ≥È¢ÜÂüüÁöÑÂÜ≥Á≠ñÊèê‰æõÊõ¥ÂèØÈù†ÁöÑÊîØÊåÅ„ÄÇÊú™Êù•ÔºåGFMÊúâÊúõÂú®Êô∫ÊÖßÂüéÂ∏Ç„ÄÅÁéØÂ¢ÉÁõëÊµãÂíåËµÑÊ∫êÁÆ°ÁêÜÁ≠âÈ¢ÜÂüüÂèëÊå•Êõ¥Â§ßÁöÑ‰ΩúÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Foundation models have transformed natural language processing and computer vision, and their impact is now reshaping remote sensing image analysis. With powerful generalization and transfer learning capabilities, they align naturally with the multimodal, multi-resolution, and multi-temporal characteristics of remote sensing data. To address unique challenges in the field, multimodal geospatial foundation models (GFMs) have emerged as a dedicated research frontier. This survey delivers a comprehensive review of multimodal GFMs from a modality-driven perspective, covering five core visual and vision-language modalities. We examine how differences in imaging physics and data representation shape interaction design, and we analyze key techniques for alignment, integration, and knowledge transfer to tackle modality heterogeneity, distribution shifts, and semantic gaps. Advances in training paradigms, architectures, and task-specific adaptation strategies are systematically assessed alongside a wealth of emerging benchmarks. Representative multimodal visual and vision-language GFMs are evaluated across ten downstream tasks, with insights into their architectures, performance, and application scenarios. Real-world case studies, spanning land cover mapping, agricultural monitoring, disaster response, climate studies, and geospatial intelligence, demonstrate the practical potential of GFMs. Finally, we outline pressing challenges in domain generalization, interpretability, efficiency, and privacy, and chart promising avenues for future research.

