---
layout: default
title: "Survey of Multimodal Geospatial Foundation Models: Techniques, Applications, and Challenges"
---

# Survey of Multimodal Geospatial Foundation Models: Techniques, Applications, and Challenges

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.22964" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.22964v1</a>
  <a href="https://arxiv.org/pdf/2510.22964.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.22964v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.22964v1', 'Survey of Multimodal Geospatial Foundation Models: Techniques, Applications, and Challenges')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Liling Yang, Ning Chen, Jun Yue, Yidan Liu, Jiayi Ma, Pedram Ghamisi, Antonio Plaza, Leyuan Fang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç»¼è¿°å¤šæ¨¡æ€åœ°ç†ç©ºé—´åŸºç¡€æ¨¡å‹ï¼Œåº”å¯¹é¥æ„Ÿå›¾åƒåˆ†æçš„æŒ‘æˆ˜ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `åœ°ç†ç©ºé—´åŸºç¡€æ¨¡å‹` `é¥æ„Ÿå›¾åƒåˆ†æ` `è¿ç§»å­¦ä¹ ` `æ¨¡æ€å¯¹é½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. é¥æ„Ÿæ•°æ®å…·æœ‰å¤šæ¨¡æ€ã€å¤šåˆ†è¾¨ç‡å’Œå¤šæ—¶ç›¸ç‰¹æ€§ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆåˆ©ç”¨è¿™äº›ä¿¡æ¯ã€‚
2. æœ¬æ–‡ä»æ¨¡æ€é©±åŠ¨çš„è§’åº¦ï¼Œç»¼è¿°äº†å¤šæ¨¡æ€åœ°ç†ç©ºé—´åŸºç¡€æ¨¡å‹ï¼ˆGFMï¼‰çš„å…³é”®æŠ€æœ¯ï¼ŒåŒ…æ‹¬å¯¹é½ã€é›†æˆå’ŒçŸ¥è¯†è¿ç§»ã€‚
3. é€šè¿‡æ¡ˆä¾‹ç ”ç©¶ï¼Œå±•ç¤ºäº†GFMåœ¨åœŸåœ°è¦†ç›–åˆ¶å›¾ã€å†œä¸šç›‘æµ‹ã€ç¾å®³å“åº”ç­‰é¢†åŸŸçš„å®é™…åº”ç”¨æ½œåŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºç¡€æ¨¡å‹å·²ç»å˜é©äº†è‡ªç„¶è¯­è¨€å¤„ç†å’Œè®¡ç®—æœºè§†è§‰é¢†åŸŸï¼Œç°åœ¨å®ƒä»¬çš„å½±å“æ­£åœ¨é‡å¡‘é¥æ„Ÿå›¾åƒåˆ†æã€‚å‡­å€Ÿå¼ºå¤§çš„æ³›åŒ–å’Œè¿ç§»å­¦ä¹ èƒ½åŠ›ï¼Œå®ƒä»¬ä¸é¥æ„Ÿæ•°æ®çš„å¤šæ¨¡æ€ã€å¤šåˆ†è¾¨ç‡å’Œå¤šæ—¶ç›¸ç‰¹æ€§è‡ªç„¶å¥‘åˆã€‚ä¸ºäº†åº”å¯¹è¯¥é¢†åŸŸä¸­çš„ç‹¬ç‰¹æŒ‘æˆ˜ï¼Œå¤šæ¨¡æ€åœ°ç†ç©ºé—´åŸºç¡€æ¨¡å‹ï¼ˆGFMï¼‰å·²ç»æˆä¸ºä¸€ä¸ªä¸“é—¨çš„ç ”ç©¶å‰æ²¿ã€‚æœ¬ç»¼è¿°ä»æ¨¡æ€é©±åŠ¨çš„è§’åº¦å…¨é¢å›é¡¾äº†å¤šæ¨¡æ€GFMï¼Œæ¶µç›–äº†äº”ä¸ªæ ¸å¿ƒçš„è§†è§‰å’Œè§†è§‰-è¯­è¨€æ¨¡æ€ã€‚æˆ‘ä»¬ç ”ç©¶äº†æˆåƒç‰©ç†å’Œæ•°æ®è¡¨ç¤ºçš„å·®å¼‚å¦‚ä½•å½±å“äº¤äº’è®¾è®¡ï¼Œå¹¶åˆ†æäº†ç”¨äºå¯¹é½ã€é›†æˆå’ŒçŸ¥è¯†è¿ç§»çš„å…³é”®æŠ€æœ¯ï¼Œä»¥è§£å†³æ¨¡æ€å¼‚è´¨æ€§ã€åˆ†å¸ƒåç§»å’Œè¯­ä¹‰é¸¿æ²Ÿã€‚é™¤äº†å¤§é‡æ–°å…´çš„åŸºå‡†ä¹‹å¤–ï¼Œè¿˜ç³»ç»Ÿåœ°è¯„ä¼°äº†è®­ç»ƒèŒƒå¼ã€æ¶æ„å’Œç‰¹å®šäºä»»åŠ¡çš„è‡ªé€‚åº”ç­–ç•¥çš„è¿›å±•ã€‚ä»£è¡¨æ€§çš„å¤šæ¨¡æ€è§†è§‰å’Œè§†è§‰-è¯­è¨€GFMåœ¨åä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸­è¿›è¡Œäº†è¯„ä¼°ï¼Œæ·±å…¥äº†è§£äº†å®ƒä»¬çš„æ¶æ„ã€æ€§èƒ½å’Œåº”ç”¨åœºæ™¯ã€‚æ¶µç›–åœŸåœ°è¦†ç›–åˆ¶å›¾ã€å†œä¸šç›‘æµ‹ã€ç¾å®³å“åº”ã€æ°”å€™ç ”ç©¶å’Œåœ°ç†ç©ºé—´æƒ…æŠ¥çš„çœŸå®æ¡ˆä¾‹ç ”ç©¶è¯æ˜äº†GFMçš„å®é™…æ½œåŠ›ã€‚æœ€åï¼Œæˆ‘ä»¬æ¦‚è¿°äº†é¢†åŸŸæ³›åŒ–ã€å¯è§£é‡Šæ€§ã€æ•ˆç‡å’Œéšç§æ–¹é¢çš„ç´§è¿«æŒ‘æˆ˜ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶è§„åˆ’äº†æœ‰å¸Œæœ›çš„é€”å¾„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šé¥æ„Ÿå›¾åƒåˆ†æé¢ä¸´ç€æ¨¡æ€å¼‚è´¨æ€§ã€åˆ†å¸ƒåç§»å’Œè¯­ä¹‰é¸¿æ²Ÿç­‰æŒ‘æˆ˜ã€‚ç°æœ‰çš„æ–¹æ³•éš¾ä»¥æœ‰æ•ˆåœ°èåˆæ¥è‡ªä¸åŒä¼ æ„Ÿå™¨å’Œæ•°æ®æºçš„ä¿¡æ¯ï¼Œå¹¶ä¸”æ³›åŒ–èƒ½åŠ›æœ‰é™ã€‚æ­¤å¤–ï¼Œé¥æ„Ÿæ•°æ®çš„æ ‡æ³¨æˆæœ¬é«˜æ˜‚ï¼Œä½¿å¾—è®­ç»ƒå¤§è§„æ¨¡æ¨¡å‹å˜å¾—å›°éš¾ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ç»¼è¿°å¤šæ¨¡æ€åœ°ç†ç©ºé—´åŸºç¡€æ¨¡å‹ï¼ˆGFMï¼‰ï¼Œè¿™äº›æ¨¡å‹æ—¨åœ¨åˆ©ç”¨å¤§è§„æ¨¡æœªæ ‡æ³¨æ•°æ®è¿›è¡Œé¢„è®­ç»ƒï¼Œç„¶åé€šè¿‡è¿ç§»å­¦ä¹ é€‚åº”å„ç§ä¸‹æ¸¸ä»»åŠ¡ã€‚é€šè¿‡å¯¹é½ã€é›†æˆå’ŒçŸ¥è¯†è¿ç§»ç­‰æŠ€æœ¯ï¼ŒGFMèƒ½å¤Ÿæœ‰æ•ˆåœ°èåˆæ¥è‡ªä¸åŒæ¨¡æ€çš„ä¿¡æ¯ï¼Œå¹¶æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæœ¬æ–‡ä»æ¨¡æ€é©±åŠ¨çš„è§’åº¦å¯¹å¤šæ¨¡æ€GFMè¿›è¡Œäº†ç»¼è¿°ï¼Œæ¶µç›–äº†äº”ä¸ªæ ¸å¿ƒçš„è§†è§‰å’Œè§†è§‰-è¯­è¨€æ¨¡æ€ã€‚æ–‡ç« é¦–å…ˆä»‹ç»äº†ä¸åŒæ¨¡æ€çš„æˆåƒç‰©ç†å’Œæ•°æ®è¡¨ç¤ºï¼Œç„¶ååˆ†æäº†ç”¨äºå¯¹é½ã€é›†æˆå’ŒçŸ¥è¯†è¿ç§»çš„å…³é”®æŠ€æœ¯ã€‚æ­¤å¤–ï¼Œæ–‡ç« è¿˜è¯„ä¼°äº†è®­ç»ƒèŒƒå¼ã€æ¶æ„å’Œç‰¹å®šäºä»»åŠ¡çš„è‡ªé€‚åº”ç­–ç•¥çš„è¿›å±•ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„åˆ›æ–°ä¹‹å¤„åœ¨äºå¯¹å¤šæ¨¡æ€GFMè¿›è¡Œäº†å…¨é¢çš„ç»¼è¿°ï¼Œå¹¶ä»æ¨¡æ€é©±åŠ¨çš„è§’åº¦åˆ†æäº†è¿™äº›æ¨¡å‹ã€‚æ–‡ç« æ·±å…¥æ¢è®¨äº†ä¸åŒæ¨¡æ€ä¹‹é—´çš„äº¤äº’è®¾è®¡ï¼Œä»¥åŠå¦‚ä½•åˆ©ç”¨å¯¹é½ã€é›†æˆå’ŒçŸ¥è¯†è¿ç§»ç­‰æŠ€æœ¯æ¥è§£å†³æ¨¡æ€å¼‚è´¨æ€§ã€åˆ†å¸ƒåç§»å’Œè¯­ä¹‰é¸¿æ²Ÿç­‰é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šæœ¬æ–‡é‡ç‚¹å…³æ³¨äº†å¤šæ¨¡æ€GFMä¸­çš„å…³é”®æŠ€æœ¯ï¼Œä¾‹å¦‚ï¼š(1)æ¨¡æ€å¯¹é½ï¼šå¦‚ä½•å°†æ¥è‡ªä¸åŒæ¨¡æ€çš„æ•°æ®æ˜ å°„åˆ°åŒä¸€ä¸ªç‰¹å¾ç©ºé—´ï¼›(2)æ¨¡æ€é›†æˆï¼šå¦‚ä½•æœ‰æ•ˆåœ°èåˆæ¥è‡ªä¸åŒæ¨¡æ€çš„ä¿¡æ¯ï¼›(3)çŸ¥è¯†è¿ç§»ï¼šå¦‚ä½•å°†ä»å¤§è§„æ¨¡æœªæ ‡æ³¨æ•°æ®ä¸­å­¦åˆ°çš„çŸ¥è¯†è¿ç§»åˆ°ä¸‹æ¸¸ä»»åŠ¡ã€‚æ–‡ç« è¿˜è®¨è®ºäº†ä¸åŒæ¶æ„å’Œè®­ç»ƒèŒƒå¼çš„é€‰æ‹©ï¼Œä»¥åŠå¦‚ä½•æ ¹æ®ç‰¹å®šä»»åŠ¡è¿›è¡Œè‡ªé€‚åº”ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥ç»¼è¿°è¯„ä¼°äº†ä»£è¡¨æ€§çš„å¤šæ¨¡æ€è§†è§‰å’Œè§†è§‰-è¯­è¨€GFMåœ¨åä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œå¹¶æä¾›äº†å…³äºå®ƒä»¬çš„æ¶æ„ã€æ€§èƒ½å’Œåº”ç”¨åœºæ™¯çš„æ·±å…¥è§è§£ã€‚é€šè¿‡æ¡ˆä¾‹ç ”ç©¶ï¼Œå±•ç¤ºäº†GFMåœ¨åœŸåœ°è¦†ç›–åˆ¶å›¾ã€å†œä¸šç›‘æµ‹å’Œç¾å®³å“åº”ç­‰é¢†åŸŸçš„å®é™…åº”ç”¨æ½œåŠ›ã€‚è¿™äº›å®éªŒç»“æœè¡¨æ˜ï¼ŒGFMèƒ½å¤Ÿæœ‰æ•ˆåœ°æé«˜é¥æ„Ÿå›¾åƒåˆ†æçš„ç²¾åº¦å’Œæ•ˆç‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºé¥æ„Ÿå›¾åƒåˆ†æé¢†åŸŸï¼Œä¾‹å¦‚åœŸåœ°è¦†ç›–åˆ¶å›¾ã€å†œä¸šç›‘æµ‹ã€ç¾å®³å“åº”ã€æ°”å€™ç ”ç©¶å’Œåœ°ç†ç©ºé—´æƒ…æŠ¥ç­‰ã€‚é€šè¿‡åˆ©ç”¨å¤šæ¨¡æ€GFMï¼Œå¯ä»¥æé«˜é¥æ„Ÿå›¾åƒåˆ†æçš„ç²¾åº¦å’Œæ•ˆç‡ï¼Œä¸ºç›¸å…³é¢†åŸŸçš„å†³ç­–æä¾›æ›´å¯é çš„æ”¯æŒã€‚æœªæ¥ï¼ŒGFMæœ‰æœ›åœ¨æ™ºæ…§åŸå¸‚ã€ç¯å¢ƒç›‘æµ‹å’Œèµ„æºç®¡ç†ç­‰é¢†åŸŸå‘æŒ¥æ›´å¤§çš„ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Foundation models have transformed natural language processing and computer vision, and their impact is now reshaping remote sensing image analysis. With powerful generalization and transfer learning capabilities, they align naturally with the multimodal, multi-resolution, and multi-temporal characteristics of remote sensing data. To address unique challenges in the field, multimodal geospatial foundation models (GFMs) have emerged as a dedicated research frontier. This survey delivers a comprehensive review of multimodal GFMs from a modality-driven perspective, covering five core visual and vision-language modalities. We examine how differences in imaging physics and data representation shape interaction design, and we analyze key techniques for alignment, integration, and knowledge transfer to tackle modality heterogeneity, distribution shifts, and semantic gaps. Advances in training paradigms, architectures, and task-specific adaptation strategies are systematically assessed alongside a wealth of emerging benchmarks. Representative multimodal visual and vision-language GFMs are evaluated across ten downstream tasks, with insights into their architectures, performance, and application scenarios. Real-world case studies, spanning land cover mapping, agricultural monitoring, disaster response, climate studies, and geospatial intelligence, demonstrate the practical potential of GFMs. Finally, we outline pressing challenges in domain generalization, interpretability, efficiency, and privacy, and chart promising avenues for future research.

