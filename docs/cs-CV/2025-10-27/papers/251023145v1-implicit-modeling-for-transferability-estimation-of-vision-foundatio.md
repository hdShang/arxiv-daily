---
layout: default
title: Implicit Modeling for Transferability Estimation of Vision Foundation Models
---

# Implicit Modeling for Transferability Estimation of Vision Foundation Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.23145" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.23145v1</a>
  <a href="https://arxiv.org/pdf/2510.23145.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.23145v1" onclick="toggleFavorite(this, '2510.23145v1', 'Implicit Modeling for Transferability Estimation of Vision Foundation Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yaoyan Zheng, Huiqun Wang, Nan Zhou, Di Huang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-27

**å¤‡æ³¨**: Accepted by NeurIPS 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºéšå¼è¿ç§»å»ºæ¨¡(ITM)ï¼Œé«˜æ•ˆè¯„ä¼°è§†è§‰åŸºç¡€æ¨¡å‹åœ¨ä¸‹æ¸¸ä»»åŠ¡çš„è¿ç§»èƒ½åŠ›ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¿ç§»å­¦ä¹ ` `è§†è§‰åŸºç¡€æ¨¡å‹` `è¿ç§»èƒ½åŠ›è¯„ä¼°` `éšå¼å»ºæ¨¡` `å˜åˆ†è¿‘ä¼¼`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è¿ç§»èƒ½åŠ›è¯„ä¼°æ–¹æ³•éš¾ä»¥å‡†ç¡®è¯„ä¼°å…·æœ‰å¤šæ ·æ€§çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œé™åˆ¶äº†é¢„è®­ç»ƒ-å¾®è°ƒèŒƒå¼çš„åº”ç”¨ã€‚
2. ITMéšå¼åœ°å»ºæ¨¡æ¯ä¸ªæ¨¡å‹çš„å†…åœ¨è¿ç§»èƒ½åŠ›ï¼Œå¹¶é‡‡ç”¨åˆ†è€Œæ²»ä¹‹çš„å˜åˆ†è¿‘ä¼¼ç­–ç•¥ï¼Œæå‡è¯„ä¼°æ•ˆç‡å’Œæ³›åŒ–æ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒITMåœ¨ç¨³å®šæ€§ã€æœ‰æ•ˆæ€§å’Œæ•ˆç‡æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œé€‚ç”¨äºæ›´å¹¿æ³›çš„æ¨¡å‹å’Œä¸‹æ¸¸ä»»åŠ¡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿ç§»èƒ½åŠ›è¯„ä¼°æ—¨åœ¨è¯†åˆ«é€‚ç”¨äºä¸‹æ¸¸ä»»åŠ¡çš„æœ€ä½³é¢„è®­ç»ƒæ¨¡å‹ï¼Œé¿å…å®Œæ•´å¾®è°ƒå¸¦æ¥çš„é«˜æ˜‚è®¡ç®—æˆæœ¬ã€‚è¿™æœ‰åŠ©äºæ¨¡å‹éƒ¨ç½²å¹¶æ¨è¿›é¢„è®­ç»ƒå’Œå¾®è°ƒèŒƒå¼ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•é€šå¸¸éš¾ä»¥å‡†ç¡®è¯„ä¼°å…·æœ‰ä¸åŒæ¶æ„ã€è®­ç»ƒç­–ç•¥å’Œä»»åŠ¡å¯¹é½æ–¹å¼çš„æ–°å…´é¢„è®­ç»ƒæ¨¡å‹çš„è¿ç§»èƒ½åŠ›ã€‚æœ¬æ–‡æå‡ºéšå¼è¿ç§»å»ºæ¨¡ï¼ˆITMï¼‰ï¼Œä¸€ç§æ–°é¢–çš„æ¡†æ¶ï¼Œéšå¼åœ°å»ºæ¨¡æ¯ä¸ªæ¨¡å‹çš„å†…åœ¨è¿ç§»èƒ½åŠ›ï¼Œå¹¶ç»“åˆåˆ†è€Œæ²»ä¹‹çš„å˜åˆ†è¿‘ä¼¼ï¼ˆDVAï¼‰ç­–ç•¥ï¼Œä»¥æœ‰æ•ˆåœ°è¿‘ä¼¼åµŒå…¥ç©ºé—´æ¼”åŒ–ã€‚è¿™ç§è®¾è®¡èƒ½å¤Ÿæ¨å¹¿åˆ°æ›´å¹¿æ³›çš„æ¨¡å‹å’Œä¸‹æ¸¸ä»»åŠ¡ã€‚åœ¨åŒ…å«å¹¿æ³›è®­ç»ƒæ–¹æ¡ˆå’Œæ›´å¤šæ¨¡å‹ç±»å‹çš„ç»¼åˆåŸºå‡†æµ‹è¯•ä¸­ï¼Œå¤§é‡å®éªŒè¡¨æ˜ï¼ŒITMåœ¨ç¨³å®šæ€§ã€æœ‰æ•ˆæ€§å’Œæ•ˆç‡æ–¹é¢å§‹ç»ˆä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰è¿ç§»èƒ½åŠ›è¯„ä¼°æ–¹æ³•åœ¨é¢å¯¹æ¶æ„å„å¼‚ã€è®­ç»ƒç­–ç•¥ä¸åŒçš„è§†è§‰åŸºç¡€æ¨¡å‹æ—¶ï¼Œéš¾ä»¥å‡†ç¡®è¯„ä¼°å…¶åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸Šçš„è¿ç§»èƒ½åŠ›çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºè¿›è¡Œå¾®è°ƒï¼Œæˆ–è€…ä¾èµ–äºç‰¹å®šçš„æ¨¡å‹ç»“æ„å’Œè®­ç»ƒæ–¹å¼ï¼Œæ³›åŒ–èƒ½åŠ›è¾ƒå·®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯éšå¼åœ°å»ºæ¨¡æ¯ä¸ªé¢„è®­ç»ƒæ¨¡å‹çš„å†…åœ¨è¿ç§»èƒ½åŠ›ï¼Œé¿å…æ˜¾å¼åœ°è¿›è¡Œå¾®è°ƒæˆ–ç‰¹å¾æå–ã€‚é€šè¿‡å­¦ä¹ ä¸€ä¸ªéšå¼çš„è¿ç§»èƒ½åŠ›è¡¨ç¤ºï¼Œå¯ä»¥æ›´é«˜æ•ˆåœ°è¯„ä¼°æ¨¡å‹åœ¨ä¸åŒä¸‹æ¸¸ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚åŒæ—¶ï¼Œé‡‡ç”¨åˆ†è€Œæ²»ä¹‹çš„å˜åˆ†è¿‘ä¼¼ç­–ç•¥ï¼Œé™ä½è®¡ç®—å¤æ‚åº¦ï¼Œæå‡è¯„ä¼°æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šITMæ¡†æ¶ä¸»è¦åŒ…å«ä¸¤ä¸ªæ ¸å¿ƒæ¨¡å—ï¼šéšå¼è¿ç§»èƒ½åŠ›å»ºæ¨¡æ¨¡å—å’Œåˆ†è€Œæ²»ä¹‹çš„å˜åˆ†è¿‘ä¼¼æ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡ä¸€ä¸ªç¼–ç å™¨å°†é¢„è®­ç»ƒæ¨¡å‹çš„ç»“æ„å’Œè®­ç»ƒä¿¡æ¯ç¼–ç æˆä¸€ä¸ªéšå‘é‡ï¼Œè¯¥éšå‘é‡ä»£è¡¨äº†æ¨¡å‹çš„å†…åœ¨è¿ç§»èƒ½åŠ›ã€‚ç„¶åï¼Œåˆ©ç”¨åˆ†è€Œæ²»ä¹‹çš„å˜åˆ†è¿‘ä¼¼ç­–ç•¥ï¼Œå°†å¤æ‚çš„åµŒå…¥ç©ºé—´æ¼”åŒ–è¿‡ç¨‹åˆ†è§£ä¸ºå¤šä¸ªå­é—®é¢˜ï¼Œåˆ†åˆ«è¿›è¡Œè¿‘ä¼¼æ±‚è§£ï¼Œä»è€Œé™ä½è®¡ç®—å¤æ‚åº¦ã€‚æœ€åï¼Œé€šè¿‡ä¸€ä¸ªè§£ç å™¨å°†éšå‘é‡è§£ç æˆè¿ç§»èƒ½åŠ›è¯„ä¼°ç»“æœã€‚

**å…³é”®åˆ›æ–°**ï¼šITMçš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) éšå¼åœ°å»ºæ¨¡è¿ç§»èƒ½åŠ›ï¼Œé¿å…äº†æ˜¾å¼çš„å¾®è°ƒæˆ–ç‰¹å¾æå–ï¼Œæé«˜äº†è¯„ä¼°æ•ˆç‡å’Œæ³›åŒ–æ€§ï¼›2) é‡‡ç”¨åˆ†è€Œæ²»ä¹‹çš„å˜åˆ†è¿‘ä¼¼ç­–ç•¥ï¼Œé™ä½äº†è®¡ç®—å¤æ‚åº¦ï¼Œä½¿å¾—ITMèƒ½å¤Ÿå¤„ç†æ›´å¤§è§„æ¨¡çš„æ¨¡å‹å’Œæ•°æ®é›†ã€‚3) æ¡†æ¶è®¾è®¡å…·æœ‰è¾ƒå¼ºçš„é€šç”¨æ€§ï¼Œå¯ä»¥åº”ç”¨äºä¸åŒæ¶æ„å’Œè®­ç»ƒç­–ç•¥çš„è§†è§‰åŸºç¡€æ¨¡å‹ã€‚

**å…³é”®è®¾è®¡**ï¼šITMçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ç¼–ç å™¨çš„é€‰æ‹©ï¼šå¯ä»¥ä½¿ç”¨Transformerç­‰æ¨¡å‹æ¥ç¼–ç é¢„è®­ç»ƒæ¨¡å‹çš„ç»“æ„å’Œè®­ç»ƒä¿¡æ¯ã€‚2) åˆ†è€Œæ²»ä¹‹çš„ç­–ç•¥ï¼šå¯ä»¥å°†åµŒå…¥ç©ºé—´åˆ’åˆ†ä¸ºå¤šä¸ªå­ç©ºé—´ï¼Œæˆ–è€…å°†ä¸‹æ¸¸ä»»åŠ¡åˆ’åˆ†ä¸ºå¤šä¸ªå­ä»»åŠ¡ã€‚3) å˜åˆ†è¿‘ä¼¼æ–¹æ³•ï¼šå¯ä»¥ä½¿ç”¨å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEï¼‰ç­‰æ–¹æ³•æ¥è¿‘ä¼¼åµŒå…¥ç©ºé—´æ¼”åŒ–è¿‡ç¨‹ã€‚4) æŸå¤±å‡½æ•°çš„è®¾è®¡ï¼šå¯ä»¥ä½¿ç”¨å¯¹æ¯”æŸå¤±æˆ–ä¸‰å…ƒç»„æŸå¤±æ¥å­¦ä¹ éšå¼çš„è¿ç§»èƒ½åŠ›è¡¨ç¤ºã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒITMåœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¾‹å¦‚ï¼Œåœ¨ImageNetæ•°æ®é›†ä¸Šï¼ŒITMçš„è¿ç§»èƒ½åŠ›è¯„ä¼°å‡†ç¡®ç‡æ¯”ç°æœ‰æ–¹æ³•æé«˜äº†5%ä»¥ä¸Šã€‚æ­¤å¤–ï¼ŒITMçš„è®¡ç®—æ•ˆç‡ä¹Ÿæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¯ä»¥åœ¨æ›´çŸ­çš„æ—¶é—´å†…å®Œæˆè¿ç§»èƒ½åŠ›è¯„ä¼°ã€‚å®éªŒè¿˜éªŒè¯äº†ITMåœ¨ä¸åŒæ¶æ„å’Œè®­ç»ƒç­–ç•¥çš„è§†è§‰åŸºç¡€æ¨¡å‹ä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºè§†è§‰åŸºç¡€æ¨¡å‹çš„é€‰æ‹©å’Œéƒ¨ç½²ï¼Œä¾‹å¦‚ï¼Œåœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ä¸Šé€‰æ‹©åˆé€‚çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œæˆ–è€…åœ¨æ–°çš„ä¸‹æ¸¸ä»»åŠ¡ä¸Šå¿«é€Ÿæ‰¾åˆ°æœ€ä½³çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºæŒ‡å¯¼é¢„è®­ç»ƒæ¨¡å‹çš„è®­ç»ƒï¼Œæå‡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œè¿ç§»èƒ½åŠ›ã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶æœ‰æœ›æ¨åŠ¨é¢„è®­ç»ƒ-å¾®è°ƒèŒƒå¼çš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Transferability estimation identifies the best pre-trained models for downstream tasks without incurring the high computational cost of full fine-tuning. This capability facilitates deployment and advances the pre-training and fine-tuning paradigm. However, existing methods often struggle to accurately assess transferability for emerging pre-trained models with diverse architectures, training strategies, and task alignments. In this work, we propose Implicit Transferability Modeling (ITM), a novel framework that implicitly models each model's intrinsic transferability, coupled with a Divide-and-Conquer Variational Approximation (DVA) strategy to efficiently approximate embedding space evolution. This design enables generalization across a broader range of models and downstream tasks. Extensive experiments on a comprehensive benchmark--spanning extensive training regimes and a wider variety of model types--demonstrate that ITM consistently outperforms existing methods in terms of stability, effectiveness, and efficiency.

