---
layout: default
title: "DecoDINO: 3D Human-Scene Contact Prediction with Semantic Classification"
---

# DecoDINO: 3D Human-Scene Contact Prediction with Semantic Classification

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.23203" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.23203v1</a>
  <a href="https://arxiv.org/pdf/2510.23203.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.23203v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.23203v1', 'DecoDINO: 3D Human-Scene Contact Prediction with Semantic Classification')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Lukas Bierling, Davide Pasero, Fleur Dolmans, Helia Ghasemi, Angelo Broere

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-27

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/DavidePasero/deco/tree)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDecoDINOä»¥è§£å†³äººç±»ä¸åœºæ™¯æ¥è§¦é¢„æµ‹é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction)**

**å…³é”®è¯**: `æ¥è§¦é¢„æµ‹` `ä¸‰åˆ†æ”¯ç½‘ç»œ` `DINOv2` `è¯­ä¹‰æ ‡ç­¾` `æœºå™¨äººæŠ€æœ¯` `å¢å¼ºç°å®` `è™šæ‹Ÿç°å®`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•DECOåœ¨å¤„ç†äººç±»ä¸ç‰©ä½“çš„æ¥è§¦é¢„æµ‹æ—¶å­˜åœ¨å±€é™ï¼Œå°¤å…¶åœ¨è½¯è¡¨é¢å’Œé®æŒ¡ç‰©çš„æƒ…å†µä¸‹è¡¨ç°ä¸ä½³ã€‚
2. DecoDINOé€šè¿‡å¼•å…¥ä¸‰åˆ†æ”¯ç½‘ç»œç»“æ„å’ŒDINOv2ç¼–ç å™¨ï¼Œç»“åˆå¹³è¡¡æŸå¤±å’Œäº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œæå‡äº†æ¥è§¦é¢„æµ‹çš„ç²¾åº¦ã€‚
3. åœ¨DAMONåŸºå‡†æµ‹è¯•ä¸­ï¼ŒDecoDINOçš„äºŒå…ƒæ¥è§¦F1åˆ†æ•°æé«˜äº†7%ï¼Œå‡ ä½•è¯¯å·®å‡åŠï¼Œå¹¶å¢å¼ºäº†å¯¹è±¡çº§è¯­ä¹‰æ ‡ç­¾çš„é¢„æµ‹èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å‡†ç¡®çš„é¡¶ç‚¹çº§æ¥è§¦é¢„æµ‹æ˜¯é«˜ä¿çœŸäººä½“ä¸ç‰©ä½“äº¤äº’æ¨¡å‹çš„å‰æï¼Œå¹¿æ³›åº”ç”¨äºæœºå™¨äººã€å¢å¼ºç°å®/è™šæ‹Ÿç°å®å’Œè¡Œä¸ºæ¨¡æ‹Ÿç­‰é¢†åŸŸã€‚DECOæ˜¯é¦–ä¸ªç”¨äºæ­¤ä»»åŠ¡çš„é‡å¤–ä¼°è®¡å™¨ï¼Œä½†å­˜åœ¨å±€é™æ€§ï¼Œå¦‚åªèƒ½ç”ŸæˆäºŒå…ƒæ¥è§¦å›¾ã€å¯¹è½¯è¡¨é¢å’Œé®æŒ¡ç‰©çš„å¤„ç†ä¸ä½³ï¼Œä»¥åŠåœ¨å„¿ç«¥å’Œå‡é˜³æ€§è„šæ¥è§¦æ–¹é¢çš„æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†DecoDINOï¼Œä¸€ä¸ªåŸºäºDECOæ¡†æ¶çš„ä¸‰åˆ†æ”¯ç½‘ç»œï¼Œé‡‡ç”¨äº†ä¸¤ä¸ªDINOv2 ViT-g/14ç¼–ç å™¨ã€å¹³è¡¡æŸå¤±åŠ æƒä»¥å‡å°‘åå·®ï¼Œå¹¶é€šè¿‡è¡¥ä¸çº§äº¤å‰æ³¨æ„åŠ›æ¥æ”¹å–„å±€éƒ¨æ¨ç†ã€‚æœ€ç»ˆï¼Œé¡¶ç‚¹ç‰¹å¾é€šè¿‡è½»é‡çº§å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰å’Œsoftmaxåˆ†é…è¯­ä¹‰æ¥è§¦æ ‡ç­¾ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDecoDINOåœ¨DAMONåŸºå‡†ä¸Šæ˜¾è‘—æå‡äº†æ¥è§¦é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³äººç±»ä¸å‘¨å›´ç‰©ä½“ä¹‹é—´çš„é¡¶ç‚¹çº§æ¥è§¦é¢„æµ‹é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•DECOåœ¨å¤„ç†è½¯è¡¨é¢ã€é®æŒ¡ç‰©å’Œå„¿ç«¥ç­‰æƒ…å†µæ—¶å­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œå¯¼è‡´å‡é˜³æ€§æ¥è§¦çš„äº§ç”Ÿã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDecoDINOé€šè¿‡å¼•å…¥ä¸‰åˆ†æ”¯ç½‘ç»œç»“æ„ï¼Œåˆ©ç”¨DINOv2 ViT-g/14ç¼–ç å™¨è¿›è¡Œç‰¹å¾æå–ï¼Œå¹¶é‡‡ç”¨å¹³è¡¡æŸå¤±åŠ æƒæ¥å‡å°‘æ¨¡å‹åå·®ï¼Œä»è€Œæå‡æ¥è§¦é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šä¸¤ä¸ªDINOv2ç¼–ç å™¨ç”¨äºç‰¹å¾æå–ï¼Œä¸€ä¸ªè½»é‡çº§å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰ç”¨äºè¯­ä¹‰æ ‡ç­¾çš„åˆ†é…ã€‚è¡¥ä¸çº§äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ç”¨äºå¢å¼ºå±€éƒ¨æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šDecoDINOçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶ä¸‰åˆ†æ”¯ç½‘ç»œç»“æ„å’Œä½¿ç”¨çš„DINOv2ç¼–ç å™¨ï¼Œè¿™ä½¿å¾—æ¨¡å‹åœ¨å¤„ç†å¤æ‚åœºæ™¯æ—¶è¡¨ç°æ›´ä¸ºä¼˜è¶Šï¼Œå°¤å…¶æ˜¯åœ¨è½¯è¡¨é¢å’Œé®æŒ¡ç‰©çš„æƒ…å†µä¸‹ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŸå¤±å‡½æ•°è®¾è®¡ä¸Šï¼Œé‡‡ç”¨äº†å¹³è¡¡æŸå¤±åŠ æƒç­–ç•¥ï¼Œä»¥å‡å°‘æ¨¡å‹åœ¨ä¸åŒç±»åˆ«ä¸Šçš„åå·®ã€‚æ­¤å¤–ï¼ŒLoRAå¾®è°ƒå’ŒåŒç¼–ç å™¨çš„è®¾è®¡è¢«è¯æ˜æ˜¯æå‡æ¨¡å‹æ€§èƒ½çš„å…³é”®å› ç´ ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

DecoDINOåœ¨DAMONåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼ŒäºŒå…ƒæ¥è§¦F1åˆ†æ•°æå‡äº†7%ï¼Œå‡ ä½•è¯¯å·®å‡åŠï¼Œå¹¶ä¸”æˆåŠŸå¢å¼ºäº†å¯¹è±¡çº§è¯­ä¹‰æ ‡ç­¾çš„é¢„æµ‹èƒ½åŠ›ï¼Œè¶…è¶Šäº†æŒ‘æˆ˜åŸºçº¿çš„è¡¨ç°ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæŠ€æœ¯ã€å¢å¼ºç°å®å’Œè™šæ‹Ÿç°å®ç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡äººæœºäº¤äº’çš„è‡ªç„¶æ€§å’Œå‡†ç¡®æ€§ã€‚é€šè¿‡å‡†ç¡®çš„æ¥è§¦é¢„æµ‹ï¼Œèƒ½å¤Ÿæ”¹å–„è™šæ‹Ÿç¯å¢ƒä¸­çš„ç‰©ä½“äº¤äº’ä½“éªŒï¼Œæ¨åŠ¨è¡Œä¸ºæ¨¡æ‹Ÿå’Œæ™ºèƒ½æœºå™¨äººæŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Accurate vertex-level contact prediction between humans and surrounding objects is a prerequisite for high fidelity human object interaction models used in robotics, AR/VR, and behavioral simulation. DECO was the first in the wild estimator for this task but is limited to binary contact maps and struggles with soft surfaces, occlusions, children, and false-positive foot contacts. We address these issues and introduce DecoDINO, a three-branch network based on DECO's framework. It uses two DINOv2 ViT-g/14 encoders, class-balanced loss weighting to reduce bias, and patch-level cross-attention for improved local reasoning. Vertex features are finally passed through a lightweight MLP with a softmax to assign semantic contact labels. We also tested a vision-language model (VLM) to integrate text features, but the simpler architecture performed better and was used instead. On the DAMON benchmark, DecoDINO (i) raises the binary-contact F1 score by 7$\%$, (ii) halves the geodesic error, and (iii) augments predictions with object-level semantic labels. Ablation studies show that LoRA fine-tuning and the dual encoders are key to these improvements. DecoDINO outperformed the challenge baseline in both tasks of the DAMON Challenge. Our code is available at https://github.com/DavidePasero/deco/tree/main.

