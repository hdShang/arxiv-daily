---
layout: default
title: DecoDINO: 3D Human-Scene Contact Prediction with Semantic Classification
---

# DecoDINO: 3D Human-Scene Contact Prediction with Semantic Classification

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.23203" target="_blank" class="toolbar-btn">arXiv: 2510.23203v1</a>
    <a href="https://arxiv.org/pdf/2510.23203.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.23203v1" 
            onclick="toggleFavorite(this, '2510.23203v1', 'DecoDINO: 3D Human-Scene Contact Prediction with Semantic Classification')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Lukas Bierling, Davide Pasero, Fleur Dolmans, Helia Ghasemi, Angelo Broere

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-27

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/DavidePasero/deco/tree)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫DecoDINO‰ª•Ëß£ÂÜ≥‰∫∫Á±ª‰∏éÂú∫ÊôØÊé•Ëß¶È¢ÑÊµãÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫îÔºö‰∫§‰∫í‰∏éÂèçÂ∫î (Interaction & Reaction)**

**ÂÖ≥ÈîÆËØç**: `Êé•Ëß¶È¢ÑÊµã` `‰∏âÂàÜÊîØÁΩëÁªú` `DINOv2` `ËØ≠‰πâÊ†áÁ≠æ` `Êú∫Âô®‰∫∫ÊäÄÊúØ` `Â¢ûÂº∫Áé∞ÂÆû` `ËôöÊãüÁé∞ÂÆû`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïDECOÂú®Â§ÑÁêÜ‰∫∫Á±ª‰∏éÁâ©‰ΩìÁöÑÊé•Ëß¶È¢ÑÊµãÊó∂Â≠òÂú®Â±ÄÈôêÔºåÂ∞§ÂÖ∂Âú®ËΩØË°®Èù¢ÂíåÈÅÆÊå°Áâ©ÁöÑÊÉÖÂÜµ‰∏ãË°®Áé∞‰∏ç‰Ω≥„ÄÇ
2. DecoDINOÈÄöËøáÂºïÂÖ•‰∏âÂàÜÊîØÁΩëÁªúÁªìÊûÑÂíåDINOv2ÁºñÁ†ÅÂô®ÔºåÁªìÂêàÂπ≥Ë°°ÊçüÂ§±Âíå‰∫§ÂèâÊ≥®ÊÑèÂäõÊú∫Âà∂ÔºåÊèêÂçá‰∫ÜÊé•Ëß¶È¢ÑÊµãÁöÑÁ≤æÂ∫¶„ÄÇ
3. Âú®DAMONÂü∫ÂáÜÊµãËØï‰∏≠ÔºåDecoDINOÁöÑ‰∫åÂÖÉÊé•Ëß¶F1ÂàÜÊï∞ÊèêÈ´ò‰∫Ü7%ÔºåÂá†‰ΩïËØØÂ∑ÆÂáèÂçäÔºåÂπ∂Â¢ûÂº∫‰∫ÜÂØπË±°Á∫ßËØ≠‰πâÊ†áÁ≠æÁöÑÈ¢ÑÊµãËÉΩÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÂáÜÁ°ÆÁöÑÈ°∂ÁÇπÁ∫ßÊé•Ëß¶È¢ÑÊµãÊòØÈ´ò‰øùÁúü‰∫∫‰Ωì‰∏éÁâ©‰Ωì‰∫§‰∫íÊ®°ÂûãÁöÑÂâçÊèêÔºåÂπøÊ≥õÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫„ÄÅÂ¢ûÂº∫Áé∞ÂÆû/ËôöÊãüÁé∞ÂÆûÂíåË°å‰∏∫Ê®°ÊãüÁ≠âÈ¢ÜÂüü„ÄÇDECOÊòØÈ¶ñ‰∏™Áî®‰∫éÊ≠§‰ªªÂä°ÁöÑÈáéÂ§ñ‰º∞ËÆ°Âô®Ôºå‰ΩÜÂ≠òÂú®Â±ÄÈôêÊÄßÔºåÂ¶ÇÂè™ËÉΩÁîüÊàê‰∫åÂÖÉÊé•Ëß¶Âõæ„ÄÅÂØπËΩØË°®Èù¢ÂíåÈÅÆÊå°Áâ©ÁöÑÂ§ÑÁêÜ‰∏ç‰Ω≥Ôºå‰ª•ÂèäÂú®ÂÑøÁ´•ÂíåÂÅáÈò≥ÊÄßËÑöÊé•Ëß¶ÊñπÈù¢ÁöÑÊåëÊàò„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåÊú¨ÊñáÊèêÂá∫‰∫ÜDecoDINOÔºå‰∏Ä‰∏™Âü∫‰∫éDECOÊ°ÜÊû∂ÁöÑ‰∏âÂàÜÊîØÁΩëÁªúÔºåÈááÁî®‰∫Ü‰∏§‰∏™DINOv2 ViT-g/14ÁºñÁ†ÅÂô®„ÄÅÂπ≥Ë°°ÊçüÂ§±Âä†ÊùÉ‰ª•ÂáèÂ∞ëÂÅèÂ∑ÆÔºåÂπ∂ÈÄöËøáË°•‰∏ÅÁ∫ß‰∫§ÂèâÊ≥®ÊÑèÂäõÊù•ÊîπÂñÑÂ±ÄÈÉ®Êé®ÁêÜ„ÄÇÊúÄÁªàÔºåÈ°∂ÁÇπÁâπÂæÅÈÄöËøáËΩªÈáèÁ∫ßÂ§öÂ±ÇÊÑüÁü•Êú∫ÔºàMLPÔºâÂíåsoftmaxÂàÜÈÖçËØ≠‰πâÊé•Ëß¶Ê†áÁ≠æ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåDecoDINOÂú®DAMONÂü∫ÂáÜ‰∏äÊòæËëóÊèêÂçá‰∫ÜÊé•Ëß¶È¢ÑÊµãÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥‰∫∫Á±ª‰∏éÂë®Âõ¥Áâ©‰Ωì‰πãÈó¥ÁöÑÈ°∂ÁÇπÁ∫ßÊé•Ëß¶È¢ÑÊµãÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïDECOÂú®Â§ÑÁêÜËΩØË°®Èù¢„ÄÅÈÅÆÊå°Áâ©ÂíåÂÑøÁ´•Á≠âÊÉÖÂÜµÊó∂Â≠òÂú®ÊòæËëó‰∏çË∂≥ÔºåÂØºËá¥ÂÅáÈò≥ÊÄßÊé•Ëß¶ÁöÑ‰∫ßÁîü„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöDecoDINOÈÄöËøáÂºïÂÖ•‰∏âÂàÜÊîØÁΩëÁªúÁªìÊûÑÔºåÂà©Áî®DINOv2 ViT-g/14ÁºñÁ†ÅÂô®ËøõË°åÁâπÂæÅÊèêÂèñÔºåÂπ∂ÈááÁî®Âπ≥Ë°°ÊçüÂ§±Âä†ÊùÉÊù•ÂáèÂ∞ëÊ®°ÂûãÂÅèÂ∑ÆÔºå‰ªéËÄåÊèêÂçáÊé•Ëß¶È¢ÑÊµãÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö‰∏§‰∏™DINOv2ÁºñÁ†ÅÂô®Áî®‰∫éÁâπÂæÅÊèêÂèñÔºå‰∏Ä‰∏™ËΩªÈáèÁ∫ßÂ§öÂ±ÇÊÑüÁü•Êú∫ÔºàMLPÔºâÁî®‰∫éËØ≠‰πâÊ†áÁ≠æÁöÑÂàÜÈÖç„ÄÇË°•‰∏ÅÁ∫ß‰∫§ÂèâÊ≥®ÊÑèÂäõÊú∫Âà∂Áî®‰∫éÂ¢ûÂº∫Â±ÄÈÉ®Êé®ÁêÜËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöDecoDINOÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÂÖ∂‰∏âÂàÜÊîØÁΩëÁªúÁªìÊûÑÂíå‰ΩøÁî®ÁöÑDINOv2ÁºñÁ†ÅÂô®ÔºåËøô‰ΩøÂæóÊ®°ÂûãÂú®Â§ÑÁêÜÂ§çÊùÇÂú∫ÊôØÊó∂Ë°®Áé∞Êõ¥‰∏∫‰ºòË∂äÔºåÂ∞§ÂÖ∂ÊòØÂú®ËΩØË°®Èù¢ÂíåÈÅÆÊå°Áâ©ÁöÑÊÉÖÂÜµ‰∏ã„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÊçüÂ§±ÂáΩÊï∞ËÆæËÆ°‰∏äÔºåÈááÁî®‰∫ÜÂπ≥Ë°°ÊçüÂ§±Âä†ÊùÉÁ≠ñÁï•Ôºå‰ª•ÂáèÂ∞ëÊ®°ÂûãÂú®‰∏çÂêåÁ±ªÂà´‰∏äÁöÑÂÅèÂ∑Æ„ÄÇÊ≠§Â§ñÔºåLoRAÂæÆË∞ÉÂíåÂèåÁºñÁ†ÅÂô®ÁöÑËÆæËÆ°Ë¢´ËØÅÊòéÊòØÊèêÂçáÊ®°ÂûãÊÄßËÉΩÁöÑÂÖ≥ÈîÆÂõ†Á¥†„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

DecoDINOÂú®DAMONÂü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞Âá∫Ëâ≤Ôºå‰∫åÂÖÉÊé•Ëß¶F1ÂàÜÊï∞ÊèêÂçá‰∫Ü7%ÔºåÂá†‰ΩïËØØÂ∑ÆÂáèÂçäÔºåÂπ∂‰∏îÊàêÂäüÂ¢ûÂº∫‰∫ÜÂØπË±°Á∫ßËØ≠‰πâÊ†áÁ≠æÁöÑÈ¢ÑÊµãËÉΩÂäõÔºåË∂ÖË∂ä‰∫ÜÊåëÊàòÂü∫Á∫øÁöÑË°®Áé∞„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Êú∫Âô®‰∫∫ÊäÄÊúØ„ÄÅÂ¢ûÂº∫Áé∞ÂÆûÂíåËôöÊãüÁé∞ÂÆûÁ≠âÂú∫ÊôØÔºåËÉΩÂ§üÊòæËëóÊèêÂçá‰∫∫Êú∫‰∫§‰∫íÁöÑËá™ÁÑ∂ÊÄßÂíåÂáÜÁ°ÆÊÄß„ÄÇÈÄöËøáÂáÜÁ°ÆÁöÑÊé•Ëß¶È¢ÑÊµãÔºåËÉΩÂ§üÊîπÂñÑËôöÊãüÁéØÂ¢É‰∏≠ÁöÑÁâ©‰Ωì‰∫§‰∫í‰ΩìÈ™åÔºåÊé®Âä®Ë°å‰∏∫Ê®°ÊãüÂíåÊô∫ËÉΩÊú∫Âô®‰∫∫ÊäÄÊúØÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Accurate vertex-level contact prediction between humans and surrounding objects is a prerequisite for high fidelity human object interaction models used in robotics, AR/VR, and behavioral simulation. DECO was the first in the wild estimator for this task but is limited to binary contact maps and struggles with soft surfaces, occlusions, children, and false-positive foot contacts. We address these issues and introduce DecoDINO, a three-branch network based on DECO's framework. It uses two DINOv2 ViT-g/14 encoders, class-balanced loss weighting to reduce bias, and patch-level cross-attention for improved local reasoning. Vertex features are finally passed through a lightweight MLP with a softmax to assign semantic contact labels. We also tested a vision-language model (VLM) to integrate text features, but the simpler architecture performed better and was used instead. On the DAMON benchmark, DecoDINO (i) raises the binary-contact F1 score by 7$\%$, (ii) halves the geodesic error, and (iii) augments predictions with object-level semantic labels. Ablation studies show that LoRA fine-tuning and the dual encoders are key to these improvements. DecoDINO outperformed the challenge baseline in both tasks of the DAMON Challenge. Our code is available at https://github.com/DavidePasero/deco/tree/main.

