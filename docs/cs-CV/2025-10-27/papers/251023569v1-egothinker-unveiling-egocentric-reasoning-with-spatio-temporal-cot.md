---
layout: default
title: EgoThinker: Unveiling Egocentric Reasoning with Spatio-Temporal CoT
---

# EgoThinker: Unveiling Egocentric Reasoning with Spatio-Temporal CoT

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.23569" target="_blank" class="toolbar-btn">arXiv: 2510.23569v1</a>
    <a href="https://arxiv.org/pdf/2510.23569.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.23569v1" 
            onclick="toggleFavorite(this, '2510.23569v1', 'EgoThinker: Unveiling Egocentric Reasoning with Spatio-Temporal CoT')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Baoqi Pei, Yifei Huang, Jilan Xu, Yuping He, Guo Chen, Fei Wu, Yu Qiao, Jiangmiao Pang

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-27

**Â§áÊ≥®**: Accepted at NeurIPS 2025

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/InternRobotics/EgoThinker)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**EgoThinkerÔºöÂà©Áî®Êó∂Á©∫CoTÊè≠Á§∫‰ª•Ëá™Êàë‰∏∫‰∏≠ÂøÉÁöÑÊé®ÁêÜËÉΩÂäõ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±ÂÖ≠ÔºöËßÜÈ¢ëÊèêÂèñ‰∏éÂåπÈÖç (Video Extraction)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `‰ª•Ëá™Êàë‰∏∫‰∏≠ÂøÉËßÜÈ¢ëÁêÜËß£` `Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã` `ÊÄùÁª¥ÈìæÊé®ÁêÜ` `Êó∂Á©∫ÂÆö‰Ωç` `Âº∫ÂåñÂ≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâMLLMÂú®‰ª•Ëá™Êàë‰∏∫‰∏≠ÂøÉÁöÑËßÜÈ¢ëÊé®ÁêÜ‰∏≠ÔºåÁº∫‰πèÂØπÈöêËóèÊÑèÂõæÂíåÁªÜÁ≤íÂ∫¶‰∫§‰∫íÁöÑÁêÜËß£ÔºåÈôêÂà∂‰∫ÜÂÖ∂Â∫îÁî®„ÄÇ
2. EgoThinkerÈÄöËøáÊó∂Á©∫CoTÁõëÁù£Âíå‰∏§Èò∂ÊÆµÂ≠¶‰π†ÔºåËµã‰∫àMLLMÂº∫Â§ßÁöÑ‰ª•Ëá™Êàë‰∏∫‰∏≠ÂøÉÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇ
3. EgoThinkerÂú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠Ë∂ÖË∂äÁé∞ÊúâÊñπÊ≥ïÔºåÂπ∂Âú®ÁªÜÁ≤íÂ∫¶Êó∂Á©∫ÂÆö‰Ωç‰ªªÂä°‰∏≠ÂèñÂæóÊòæËëóÊèêÂçá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

‰ª•Ëá™Êàë‰∏∫‰∏≠ÂøÉÁöÑËßÜÈ¢ëÊé®ÁêÜÂÖ≥Ê≥®ÁöÑÊòØÁõ∏Êú∫ËÉåÂêé‰∏çÂèØËßÅÁöÑÊô∫ËÉΩ‰ΩìÔºåËØ•Êô∫ËÉΩ‰ΩìÂä®ÊÄÅÂú∞Â°ëÈÄ†ÁéØÂ¢ÉÔºåÈúÄË¶ÅÊé®Êñ≠ÈöêËóèÁöÑÊÑèÂõæÂπ∂ËØÜÂà´ÁªÜÁ≤íÂ∫¶ÁöÑ‰∫§‰∫í„ÄÇËøô‰∏ÄÊ†∏ÂøÉÊåëÊàòÈôêÂà∂‰∫ÜÂΩìÂâçÁöÑÂ§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMÔºâÔºåËøô‰∫õÊ®°ÂûãÊìÖÈïøÂèØËßÅ‰∫ã‰ª∂ÁöÑÊé®ÁêÜÔºå‰ΩÜÁº∫‰πèÂÖ∑Ë∫´ÁöÑÁ¨¨‰∏Ä‰∫∫Áß∞ÁêÜËß£„ÄÇ‰∏∫‰∫ÜÂº•ÂêàËøô‰∏ÄÂ∑ÆË∑ùÔºåÊàë‰ª¨ÂºïÂÖ•‰∫ÜEgoThinkerÔºåËøôÊòØ‰∏Ä‰∏™Êñ∞È¢ñÁöÑÊ°ÜÊû∂ÔºåÈÄöËøáÊó∂Á©∫ÊÄùÁª¥ÈìæÔºàCoTÔºâÁõëÁù£Âíå‰∏§Èò∂ÊÆµÂ≠¶‰π†ËØæÁ®ãÔºåËµã‰∫àMLLMÂº∫Â§ßÁöÑ‰ª•Ëá™Êàë‰∏∫‰∏≠ÂøÉÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇÈ¶ñÂÖàÔºåÊàë‰ª¨ÂºïÂÖ•‰∫ÜEgoRe-5MÔºåËøôÊòØ‰∏Ä‰∏™Â§ßËßÑÊ®°ÁöÑ‰ª•Ëá™Êàë‰∏∫‰∏≠ÂøÉÁöÑQAÊï∞ÊçÆÈõÜÔºåÁî±1300‰∏á‰∏™‰∏çÂêåÁöÑ‰ª•Ëá™Êàë‰∏∫‰∏≠ÂøÉÁöÑËßÜÈ¢ëÁâáÊÆµÊûÑÂª∫ËÄåÊàê„ÄÇËØ•Êï∞ÊçÆÈõÜÂåÖÂê´Â§öÂàÜÈíüÁöÑÁâáÊÆµÔºåÂπ∂Â∏¶ÊúâËØ¶ÁªÜÁöÑCoTÁêÜÁî±ÂíåÂØÜÈõÜÁöÑhand-object grounding„ÄÇÂÖ∂Ê¨°ÔºåÊàë‰ª¨Âú®EgoRe-5M‰∏äÈááÁî®SFTÊù•ÁÅåËæìÊé®ÁêÜÊäÄËÉΩÔºåÁÑ∂ÂêéËøõË°åÂº∫ÂåñÂæÆË∞ÉRFTÔºå‰ª•Ëøõ‰∏ÄÊ≠•Â¢ûÂº∫Êó∂Á©∫ÂÆö‰Ωç„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåEgoThinkerÂú®Â§ö‰∏™‰ª•Ëá™Êàë‰∏∫‰∏≠ÂøÉÁöÑÂü∫ÂáÜÊµãËØï‰∏≠‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÂêåÊó∂Âú®ÁªÜÁ≤íÂ∫¶ÁöÑÊó∂Á©∫ÂÆö‰Ωç‰ªªÂä°‰∏≠ÂèñÂæó‰∫ÜÊòæËëóÁöÑÊîπËøõ„ÄÇÂÆåÊï¥ÁöÑ‰ª£Á†ÅÂíåÊï∞ÊçÆÂ∑≤Âú®https://github.com/InternRobotics/EgoThinker‰∏äÂèëÂ∏É„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMÔºâÂú®‰ª•Ëá™Êàë‰∏∫‰∏≠ÂøÉÁöÑËßÜÈ¢ëÁêÜËß£‰∏≠Êé®ÁêÜËÉΩÂäõ‰∏çË∂≥ÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÁöÑMLLMËôΩÁÑ∂Âú®ÂèØËßÅ‰∫ã‰ª∂Êé®ÁêÜÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤Ôºå‰ΩÜÁº∫‰πèÂØπÁ¨¨‰∏Ä‰∫∫Áß∞ËßÜËßí‰∏ãÈöêËóèÊÑèÂõæÂíåÁªÜÁ≤íÂ∫¶‰∫§‰∫íÁöÑÁêÜËß£ÔºåÊó†Ê≥ïÊúâÊïàÂ§ÑÁêÜ‰ª•Ëá™Êàë‰∏∫‰∏≠ÂøÉÁöÑËßÜÈ¢ëÊé®ÁêÜ‰ªªÂä°„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÂºïÂÖ•Êó∂Á©∫ÊÄùÁª¥ÈìæÔºàCoTÔºâÁõëÁù£Âíå‰∏§Èò∂ÊÆµÂ≠¶‰π†ËØæÁ®ãÔºåÊù•Â¢ûÂº∫MLLMÁöÑ‰ª•Ëá™Êàë‰∏∫‰∏≠ÂøÉÊé®ÁêÜËÉΩÂäõ„ÄÇCoTÁõëÁù£Êó®Âú®Êèê‰æõÊõ¥ËØ¶ÁªÜÁöÑÊé®ÁêÜËøáÁ®ãÔºåÂ∏ÆÂä©Ê®°ÂûãÁêÜËß£ËßÜÈ¢ë‰∏≠ÁöÑÂõ†ÊûúÂÖ≥Á≥ªÂíåÊÑèÂõæ„ÄÇ‰∏§Èò∂ÊÆµÂ≠¶‰π†ËØæÁ®ãÂàôÂàÜÂà´‰æßÈáç‰∫éÊé®ÁêÜÊäÄËÉΩÁöÑÁÅåËæìÂíåÊó∂Á©∫ÂÆö‰ΩçÁöÑÂ¢ûÂº∫„ÄÇËøôÊ†∑ËÆæËÆ°ÁöÑÁõÆÁöÑÊòØËÆ©Ê®°Âûã‰∏ç‰ªÖËÉΩ‚ÄúÁúãÂà∞‚ÄùÂèëÁîü‰∫Ü‰ªÄ‰πàÔºåËøòËÉΩ‚ÄúÁêÜËß£‚Äù‰∏∫‰ªÄ‰πà‰ºöÂèëÁîüÔºå‰ª•ÂèäÂú®Âì™ÈáåÂèëÁîü„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöEgoThinkerÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰∏§‰∏™Èò∂ÊÆµÔºö1) Âü∫‰∫éEgoRe-5MÊï∞ÊçÆÈõÜÁöÑÁõëÁù£ÂæÆË∞ÉÔºàSFTÔºâÔºåÁî®‰∫éÂ≠¶‰π†Êé®ÁêÜËÉΩÂäõÔºõ2) Âº∫ÂåñÂæÆË∞ÉÔºàRFTÔºâÔºåÁî®‰∫éÂ¢ûÂº∫Êó∂Á©∫ÂÆö‰ΩçËÉΩÂäõ„ÄÇEgoRe-5MÊï∞ÊçÆÈõÜÂåÖÂê´Â§ßÈáèÁöÑ‰ª•Ëá™Êàë‰∏∫‰∏≠ÂøÉÁöÑËßÜÈ¢ëÁâáÊÆµÔºåÂπ∂Â∏¶ÊúâËØ¶ÁªÜÁöÑCoTÁêÜÁî±Âíåhand-object grounding„ÄÇSFTÈò∂ÊÆµÂà©Áî®Ëøô‰∫õÊï∞ÊçÆÊù•ËÆ≠ÁªÉÊ®°ÂûãÁîüÊàêCoTÊé®ÁêÜËøáÁ®ãÔºåRFTÈò∂ÊÆµÂàôËøõ‰∏ÄÊ≠•‰ºòÂåñÊ®°ÂûãÁöÑÊó∂Á©∫ÂÆö‰ΩçËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫ÜEgoThinkerÊ°ÜÊû∂ÔºåËØ•Ê°ÜÊû∂ÈÄöËøáÂºïÂÖ•Êó∂Á©∫CoTÁõëÁù£Âíå‰∏§Èò∂ÊÆµÂ≠¶‰π†ËØæÁ®ãÔºåÊòæËëóÊèêÂçá‰∫ÜMLLMÂú®‰ª•Ëá™Êàë‰∏∫‰∏≠ÂøÉÁöÑËßÜÈ¢ëÊé®ÁêÜÊñπÈù¢ÁöÑËÉΩÂäõ„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåEgoThinkerÊõ¥Ê≥®ÈáçÂØπËßÜÈ¢ë‰∏≠ÈöêËóèÊÑèÂõæÂíåÁªÜÁ≤íÂ∫¶‰∫§‰∫íÁöÑÁêÜËß£Ôºå‰ªéËÄåÂÆûÁé∞‰∫ÜÊõ¥ÂáÜÁ°ÆÁöÑÊé®ÁêÜÂíåÂÆö‰Ωç„ÄÇÊ≠§Â§ñÔºåEgoRe-5MÊï∞ÊçÆÈõÜÁöÑÊûÑÂª∫‰πü‰∏∫‰ª•Ëá™Êàë‰∏∫‰∏≠ÂøÉÁöÑËßÜÈ¢ëÊé®ÁêÜÁ†îÁ©∂Êèê‰æõ‰∫ÜÂÆùË¥µÁöÑÊï∞ÊçÆËµÑÊ∫ê„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöEgoRe-5MÊï∞ÊçÆÈõÜÂåÖÂê´13M‰∏™ËßÜÈ¢ëÁâáÊÆµÔºåÊØè‰∏™ÁâáÊÆµÈÉΩÊ†áÊ≥®‰∫ÜËØ¶ÁªÜÁöÑCoTÁêÜÁî±Âíåhand-object grounding‰ø°ÊÅØ„ÄÇÂú®SFTÈò∂ÊÆµÔºåÊ®°ÂûãË¢´ËÆ≠ÁªÉÁîüÊàê‰∏éËßÜÈ¢ëÂÜÖÂÆπÁõ∏ÂÖ≥ÁöÑCoTÊé®ÁêÜËøáÁ®ã„ÄÇÂú®RFTÈò∂ÊÆµÔºå‰ΩøÁî®‰∫ÜÁâπÂÆöÁöÑÂ•ñÂä±ÂáΩÊï∞Êù•ÈºìÂä±Ê®°ÂûãÊõ¥ÂáÜÁ°ÆÂú∞ËøõË°åÊó∂Á©∫ÂÆö‰Ωç„ÄÇÂÖ∑‰ΩìÁöÑÁΩëÁªúÁªìÊûÑÂíåÂèÇÊï∞ËÆæÁΩÆÂú®ËÆ∫Êñá‰∏≠Â∫îËØ•ÊúâËØ¶ÁªÜÊèèËø∞Ôºå‰ΩÜÊëòË¶Å‰∏≠Êú™ÊèêÂèä„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

EgoThinkerÂú®Â§ö‰∏™‰ª•Ëá™Êàë‰∏∫‰∏≠ÂøÉÁöÑÂü∫ÂáÜÊµãËØï‰∏≠Ë∂ÖË∂ä‰∫ÜÁé∞ÊúâÊñπÊ≥ïÔºåÂπ∂Âú®ÁªÜÁ≤íÂ∫¶ÁöÑÊó∂Á©∫ÂÆö‰Ωç‰ªªÂä°‰∏≠ÂèñÂæó‰∫ÜÊòæËëóÁöÑÊîπËøõ„ÄÇÂÖ∑‰ΩìÊÄßËÉΩÊï∞ÊçÆÂíåÂØπÊØîÂü∫Á∫øÈúÄË¶ÅÂú®ËÆ∫Êñá‰∏≠Êü•ÊâæÔºåÊëòË¶Å‰∏≠Âè™ÊèêÂà∞‚Äúsubstantial improvements‚ÄùÔºåË°®ÊòéÊèêÂçáÂπÖÂ∫¶ËæÉÂ§ß„ÄÇEgoRe-5MÊï∞ÊçÆÈõÜÁöÑÂèëÂ∏É‰πü‰∏∫ÂêéÁª≠Á†îÁ©∂Êèê‰æõ‰∫ÜÈáçË¶ÅËµÑÊ∫ê„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

EgoThinkerÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºå‰æãÂ¶ÇÂú®Êô∫ËÉΩÂä©Êâã„ÄÅ‰∫∫Êú∫‰∫§‰∫í„ÄÅÊú∫Âô®‰∫∫ÂØºËà™„ÄÅËôöÊãüÁé∞ÂÆûÂíåÂ¢ûÂº∫Áé∞ÂÆûÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÁêÜËß£‰ª•Ëá™Êàë‰∏∫‰∏≠ÂøÉÁöÑËßÜËßíÔºåEgoThinkerÂèØ‰ª•Â∏ÆÂä©Êô∫ËÉΩ‰ΩìÊõ¥Â•ΩÂú∞ÁêÜËß£‰∫∫Á±ªÁöÑÊÑèÂõæÂíåË°å‰∏∫Ôºå‰ªéËÄåÂÆûÁé∞Êõ¥Ëá™ÁÑ∂„ÄÅÊõ¥ÊúâÊïàÁöÑ‰∫§‰∫í„ÄÇÊ≠§Â§ñÔºåËØ•ÊäÄÊúØËøòÂèØ‰ª•Áî®‰∫éÂàÜÊûêÂíåÁêÜËß£‰∫∫Á±ªÊ¥ªÂä®Ôºå‰æãÂ¶ÇÂú®ÂåªÁñó‰øùÂÅ•„ÄÅÂÆâÂÖ®ÁõëÊéßÂíåËøêÂä®ÂàÜÊûêÁ≠âÈ¢ÜÂüü„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Egocentric video reasoning centers on an unobservable agent behind the camera who dynamically shapes the environment, requiring inference of hidden intentions and recognition of fine-grained interactions. This core challenge limits current multimodal large language models MLLMs, which excel at visible event reasoning but lack embodied, first-person understanding. To bridge this gap, we introduce EgoThinker, a novel framework that endows MLLMs with robust egocentric reasoning capabilities through spatio-temporal chain-of-thought supervision and a two-stage learning curriculum. First, we introduce EgoRe-5M, a large-scale egocentric QA dataset constructed from 13M diverse egocentric video clips. This dataset features multi-minute segments annotated with detailed CoT rationales and dense hand-object grounding. Second, we employ SFT on EgoRe-5M to instill reasoning skills, followed by reinforcement fine-tuning RFT to further enhance spatio-temporal localization. Experimental results show that EgoThinker outperforms existing methods across multiple egocentric benchmarks, while achieving substantial improvements in fine-grained spatio-temporal localization tasks. Full code and data are released at https://github.com/InternRobotics/EgoThinker.

