---
layout: default
title: CountFormer: A Transformer Framework for Learning Visual Repetition and Structure in Class-Agnostic Object Counting
---

# CountFormer: A Transformer Framework for Learning Visual Repetition and Structure in Class-Agnostic Object Counting

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.23785" target="_blank" class="toolbar-btn">arXiv: 2510.23785v1</a>
    <a href="https://arxiv.org/pdf/2510.23785.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.23785v1" 
            onclick="toggleFavorite(this, '2510.23785v1', 'CountFormer: A Transformer Framework for Learning Visual Repetition and Structure in Class-Agnostic Object Counting')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Md Tanvir Hossain, Akif Islam, Mohd Ruhul Ameen

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-27

**Â§áÊ≥®**: 6 pages, 2 tables, 6 figures. Submitted to IEEE 5th International Conference on Electrical, Computer and Telecommunication Engineering (ICECTE 2025)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**CountFormerÔºöTransformerÊ°ÜÊû∂Â≠¶‰π†ËßÜËßâÈáçÂ§ç‰∏éÁªìÊûÑÔºåÂÆûÁé∞Á±ªÂà´Êó†ÂÖ≥ÁöÑÁõÆÊ†áËÆ°Êï∞**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÁõÆÊ†áËÆ°Êï∞` `Transformer` `DINOv2` `ËßÜËßâÈáçÂ§ç` `ÁªìÊûÑ‰∏ÄËá¥ÊÄß` `Á±ªÂà´Êó†ÂÖ≥` `ÂØÜÂ∫¶Âõæ` `Ëá™ÁõëÁù£Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËÆ°Êï∞Ê®°ÂûãÂú®Â§ÑÁêÜÂÖ∑ÊúâÂ§çÊùÇÂΩ¢Áä∂„ÄÅÂÜÖÈÉ®ÂØπÁß∞ÊàñÈáçÂè†ÁöÑÂØπË±°Êó∂ÔºåËÆ°Êï∞ÂáÜÁ°ÆÁéáËæÉ‰ΩéÔºåÊó†Ê≥ïÊúâÊïàÊ®°‰ªø‰∫∫Á±ªÁöÑËÆ°Êï∞ËÉΩÂäõ„ÄÇ
2. CountFormerÂà©Áî®TransformerÊû∂ÊûÑÔºåÈÄöËøáÂ≠¶‰π†ËßÜËßâÈáçÂ§çÂíåÁªìÊûÑ‰∏ÄËá¥ÊÄßÊù•ËøõË°åÁ±ªÂà´Êó†ÂÖ≥ÁöÑÁõÆÊ†áËÆ°Êï∞ÔºåÊõ¥Êé•Ëøë‰∫∫Á±ªÁöÑËÆ°Êï∞ÊñπÂºè„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåCountFormerÂú®FSC-147Êï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫Ü‰∏éSOTAÊñπÊ≥ïÁõ∏ÂΩìÁöÑÊÄßËÉΩÔºåÂπ∂Âú®ÁªìÊûÑÂ§çÊùÇÊàñÂØÜÈõÜÂú∫ÊôØ‰∏≠Ë°®Áé∞Âá∫Êõ¥‰ºòÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫CountFormerÔºå‰∏Ä‰∏™Âü∫‰∫éTransformerÁöÑÊ°ÜÊû∂ÔºåÁî®‰∫éÂ≠¶‰π†ËßÜËßâÈáçÂ§çÂíåÁªìÊûÑ‰∏ÄËá¥ÊÄßÔºå‰ªéËÄåÂÆûÁé∞Á±ªÂà´Êó†ÂÖ≥ÁöÑÁõÆÊ†áËÆ°Êï∞„ÄÇ‰∏é‰æùËµñÁ±ªÂà´‰ø°ÊÅØ‰∏çÂêåÔºå‰∫∫Á±ªÈÄöËøáÊÑüÁü•ËßÜËßâÈáçÂ§çÂíåÁªìÊûÑÂÖ≥Á≥ªÊù•ËÆ°Êï∞„ÄÇÁé∞ÊúâÊ®°ÂûãÈöæ‰ª•Â§çÂà∂ËøôÁßçËÉΩÂäõÔºåÂú®Â§ÑÁêÜÂ§çÊùÇÂΩ¢Áä∂„ÄÅÂÜÖÈÉ®ÂØπÁß∞ÊàñÈáçÂè†ÂØπË±°Êó∂ÂÆπÊòìÂá∫Èîô„ÄÇCountFormerÂü∫‰∫éCounTRÊû∂ÊûÑÔºåÁî®Ëá™ÁõëÁù£È¢ÑËÆ≠ÁªÉÊ®°ÂûãDINOv2ÊõøÊç¢ËßÜËßâÁºñÁ†ÅÂô®Ôºå‰ª•‰∫ßÁîüÊõ¥‰∏∞ÂØåÂíåÁ©∫Èó¥‰∏ÄËá¥ÁöÑÁâπÂæÅË°®Á§∫„ÄÇÊ≠§Â§ñÔºåÊ®°ÂûãËøòËûçÂêà‰∫Ü‰ΩçÁΩÆÂµåÂÖ•Ôºå‰ª•‰øùÁïôÂá†‰ΩïÂÖ≥Á≥ªÔºåÁÑ∂ÂêéÈÄöËøáËΩªÈáèÁ∫ßÂç∑ÁßØËß£Á†ÅÂô®Â∞ÜËøô‰∫õÁâπÂæÅËß£Á†Å‰∏∫ÂØÜÂ∫¶Âõæ„ÄÇÂú®FSC-147Êï∞ÊçÆÈõÜ‰∏äÁöÑËØÑ‰º∞Ë°®ÊòéÔºåËØ•Ê®°ÂûãËææÂà∞‰∫Ü‰∏éÂΩìÂâçÊúÄÂÖàËøõÊñπÊ≥ïÁõ∏ÂΩìÁöÑÊÄßËÉΩÔºåÂπ∂Âú®ÁªìÊûÑÂ§çÊùÇÊàñÂØÜÈõÜÂú∫ÊôØ‰∏≠Ë°®Áé∞Âá∫Êõ¥È´òÁöÑÂáÜÁ°ÆÊÄß„ÄÇÁ†îÁ©∂ÁªìÊûúË°®ÊòéÔºåÈõÜÊàêDINOv2Á≠âÈ¢ÑËÆ≠ÁªÉÊ®°Âûã‰ΩøËÆ°Êï∞Á≥ªÁªüËÉΩÂ§üÊé•Ëøë‰∫∫Á±ªËà¨ÁöÑÁªìÊûÑÊÑüÁü•Ôºå‰ªéËÄåÊúùÁùÄÁúüÊ≠£ÈÄöÁî®ÂíåÊó†Ê†∑Êú¨ÁöÑËÆ°Êï∞ËåÉÂºèËøàËøõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Á±ªÂà´Êó†ÂÖ≥ÁöÑÁõÆÊ†áËÆ°Êï∞ÈóÆÈ¢òÔºåÂç≥Âú®‰∏ç‰æùËµñÂØπË±°Á±ªÂà´‰ø°ÊÅØÁöÑÊÉÖÂÜµ‰∏ãÔºåÂáÜÁ°Æ‰º∞ËÆ°ÂõæÂÉè‰∏≠ÁâπÂÆöÁõÆÊ†áÁöÑÊï∞Èáè„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®Â§ÑÁêÜÂÖ∑ÊúâÂ§çÊùÇÂΩ¢Áä∂„ÄÅÂÜÖÈÉ®ÂØπÁß∞ÊÄßÊàñÂØÜÈõÜÂ†ÜÂè†ÁöÑÂØπË±°Êó∂ÔºåÂæÄÂæÄË°®Áé∞‰∏ç‰Ω≥ÔºåÂõ†‰∏∫ÂÆÉ‰ª¨Èöæ‰ª•ÊçïÊçâÂà∞ÁõÆÊ†á‰πãÈó¥ÁöÑÁªìÊûÑÂÖ≥Á≥ªÂíåÈáçÂ§çÊ®°Âºè„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®TransformerÊû∂ÊûÑÂ≠¶‰π†ÂõæÂÉè‰∏≠ÁõÆÊ†áÁöÑËßÜËßâÈáçÂ§çÊ®°ÂºèÂíåÁªìÊûÑ‰∏ÄËá¥ÊÄßÔºå‰ªéËÄåÂÆûÁé∞Êõ¥ÂáÜÁ°ÆÁöÑËÆ°Êï∞„ÄÇÈÄöËøáÂºïÂÖ•Ëá™ÁõëÁù£È¢ÑËÆ≠ÁªÉÊ®°ÂûãDINOv2‰Ωú‰∏∫ËßÜËßâÁºñÁ†ÅÂô®ÔºåÂèØ‰ª•ÊèêÂèñÊõ¥‰∏∞ÂØåÂíåÁ©∫Èó¥‰∏ÄËá¥ÁöÑÁâπÂæÅË°®Á§∫Ôºå‰ªéËÄåÊõ¥Â•ΩÂú∞ÊçïÊçâÁõÆÊ†áÁöÑÁªìÊûÑ‰ø°ÊÅØ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöCountFormerÁöÑÊï¥‰ΩìÊû∂ÊûÑÂü∫‰∫éCounTRÔºå‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Ê®°ÂùóÔºö1) DINOv2ËßÜËßâÁºñÁ†ÅÂô®ÔºöÁî®‰∫éÊèêÂèñÂõæÂÉèÁöÑËßÜËßâÁâπÂæÅÔºõ2) ‰ΩçÁΩÆÂµåÂÖ•ËûçÂêàÔºöÁî®‰∫é‰øùÁïôÁâπÂæÅÁöÑÁ©∫Èó¥Âá†‰ΩïÂÖ≥Á≥ªÔºõ3) ËΩªÈáèÁ∫ßÂç∑ÁßØËß£Á†ÅÂô®ÔºöÂ∞ÜÁâπÂæÅËß£Á†Å‰∏∫ÂØÜÂ∫¶ÂõæÔºåÂØÜÂ∫¶Âõæ‰∏äÁöÑÁßØÂàÜÂç≥‰∏∫ÁõÆÊ†áÊï∞ÈáèÁöÑ‰º∞ËÆ°ÂÄº„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöCountFormerÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫é‰ΩøÁî®DINOv2‰Ωú‰∏∫ËßÜËßâÁºñÁ†ÅÂô®ÔºåÂπ∂ÁªìÂêà‰ΩçÁΩÆÂµåÂÖ•ËûçÂêàÔºå‰ªéËÄåËÉΩÂ§üÊõ¥Â•ΩÂú∞Â≠¶‰π†ÁõÆÊ†áÁöÑÁªìÊûÑ‰ø°ÊÅØÂíåÈáçÂ§çÊ®°Âºè„ÄÇ‰∏é‰º†ÁªüÁöÑÂç∑ÁßØÁ•ûÁªèÁΩëÁªúÁõ∏ÊØîÔºåTransformerÊû∂ÊûÑÂÖ∑ÊúâÊõ¥Âº∫ÁöÑÂÖ®Â±ÄÂª∫Ê®°ËÉΩÂäõÔºåËÉΩÂ§üÊõ¥Â•ΩÂú∞ÊçïÊçâÁõÆÊ†á‰πãÈó¥ÁöÑÈïøÁ®ã‰æùËµñÂÖ≥Á≥ª„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöDINOv2ÁöÑÈÄâÊã©ÊòØÂõ†‰∏∫ÂÖ∂Ëá™ÁõëÁù£Â≠¶‰π†ÁöÑÁâπÊÄßÔºå‰ΩøÂÖ∂ËÉΩÂ§üÂ≠¶‰π†Âà∞Êõ¥ÈÄöÁî®ÁöÑËßÜËßâÁâπÂæÅË°®Á§∫„ÄÇ‰ΩçÁΩÆÂµåÂÖ•ËûçÂêàÈááÁî®‰∫Ü‰∏ÄÁßçÁÆÄÂçïËÄåÊúâÊïàÁöÑÊñπÂºèÔºåÂ∞Ü‰ΩçÁΩÆ‰ø°ÊÅØËûçÂÖ•Âà∞ÁâπÂæÅ‰∏≠Ôºå‰ªéËÄå‰øùÁïô‰∫ÜÁõÆÊ†áÁöÑÁ©∫Èó¥Âá†‰ΩïÂÖ≥Á≥ª„ÄÇËΩªÈáèÁ∫ßÂç∑ÁßØËß£Á†ÅÂô®ÁöÑËÆæËÆ°Êó®Âú®ÂáèÂ∞ëËÆ°ÁÆóÈáèÔºåÂêåÊó∂‰øùËØÅËß£Á†ÅÁöÑÂáÜÁ°ÆÊÄß„ÄÇÊçüÂ§±ÂáΩÊï∞ÈááÁî®Ê†áÂáÜÁöÑÂØÜÂ∫¶ÂõæÂõûÂΩíÊçüÂ§±„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

CountFormerÂú®FSC-147Êï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫Ü‰∏éÂΩìÂâçÊúÄÂÖàËøõÊñπÊ≥ïÁõ∏ÂΩìÁöÑÊÄßËÉΩÔºåÂπ∂Âú®ÁªìÊûÑÂ§çÊùÇÊàñÂØÜÈõÜÂú∫ÊôØ‰∏≠Ë°®Áé∞Âá∫Êõ¥È´òÁöÑÂáÜÁ°ÆÊÄß„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåCountFormerÂú®Â§ÑÁêÜÂÖ∑ÊúâÂ§çÊùÇÂΩ¢Áä∂„ÄÅÂÜÖÈÉ®ÂØπÁß∞ÊÄßÊàñÂØÜÈõÜÂ†ÜÂè†ÁöÑÂØπË±°Êó∂ÔºåËÆ°Êï∞ÂáÜÁ°ÆÁéáÊòæËëóÊèêÂçáÔºåË°®ÊòéÂÖ∂ËÉΩÂ§üÊõ¥Â•ΩÂú∞Â≠¶‰π†ÁõÆÊ†áÁöÑÁªìÊûÑ‰ø°ÊÅØÂíåÈáçÂ§çÊ®°Âºè„ÄÇËØ•Ê®°ÂûãËØÅÊòé‰∫ÜÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãÂú®ÁõÆÊ†áËÆ°Êï∞‰ªªÂä°‰∏≠ÁöÑÊúâÊïàÊÄßÔºåÂπ∂‰∏∫Êú™Êù•ÁöÑÁ†îÁ©∂Êèê‰æõ‰∫ÜÊñ∞ÁöÑÊÄùË∑Ø„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

CountFormerÂú®Êô∫ËÉΩÁõëÊéß„ÄÅËá™Âä®È©æÈ©∂„ÄÅÈõ∂ÂîÆÂàÜÊûê„ÄÅÂåªÂ≠¶ÂõæÂÉèÂàÜÊûêÁ≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇ‰æãÂ¶ÇÔºåÂú®Êô∫ËÉΩÁõëÊéß‰∏≠ÔºåÂèØ‰ª•Áî®‰∫éÁªüËÆ°‰∫∫Áæ§ÂØÜÂ∫¶ÊàñËΩ¶ËæÜÊï∞ÈáèÔºõÂú®Ëá™Âä®È©æÈ©∂‰∏≠ÔºåÂèØ‰ª•Áî®‰∫éÊ£ÄÊµãÂíåËÆ°Êï∞ÈÅìË∑Ø‰∏äÁöÑË°å‰∫∫ÊàñËΩ¶ËæÜÔºõÂú®Èõ∂ÂîÆÂàÜÊûê‰∏≠ÔºåÂèØ‰ª•Áî®‰∫éÁªüËÆ°Ë¥ßÊû∂‰∏äÁöÑÂïÜÂìÅÊï∞ÈáèÔºõÂú®ÂåªÂ≠¶ÂõæÂÉèÂàÜÊûê‰∏≠ÔºåÂèØ‰ª•Áî®‰∫éËÆ°Êï∞ÁªÜËÉûÊï∞Èáè„ÄÇËØ•Á†îÁ©∂ÊúâÂä©‰∫éÊé®Âä®ÈÄöÁî®ËÆ°Êï∞ÊäÄÊúØÁöÑÂèëÂ±ïÔºåÂÆûÁé∞Êõ¥Êô∫ËÉΩ„ÄÅÊõ¥È´òÊïàÁöÑËßÜËßâÂàÜÊûê„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Humans can effortlessly count diverse objects by perceiving visual repetition and structural relationships rather than relying on class identity. However, most existing counting models fail to replicate this ability; they often miscount when objects exhibit complex shapes, internal symmetry, or overlapping components. In this work, we introduce CountFormer, a transformer-based framework that learns to recognize repetition and structural coherence for class-agnostic object counting. Built upon the CounTR architecture, our model replaces its visual encoder with the self-supervised foundation model DINOv2, which produces richer and spatially consistent feature representations. We further incorporate positional embedding fusion to preserve geometric relationships before decoding these features into density maps through a lightweight convolutional decoder. Evaluated on the FSC-147 dataset, our model achieves performance comparable to current state-of-the-art methods while demonstrating superior accuracy on structurally intricate or densely packed scenes. Our findings indicate that integrating foundation models such as DINOv2 enables counting systems to approach human-like structural perception, advancing toward a truly general and exemplar-free counting paradigm.

