---
layout: default
title: Finding 3D Scene Analogies with Multimodal Foundation Models
---

# Finding 3D Scene Analogies with Multimodal Foundation Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.23184" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.23184v1</a>
  <a href="https://arxiv.org/pdf/2510.23184.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.23184v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.23184v1', 'Finding 3D Scene Analogies with Multimodal Foundation Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Junho Kim, Young Min Kim

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-27

**å¤‡æ³¨**: Accepted to FM4RoboPlan workshop at RSS 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ©ç”¨å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹å®ç°é›¶æ ·æœ¬ä¸‰ç»´åœºæ™¯ç±»æ¯”ï¼Œç”¨äºæœºå™¨äººè½¨è¿¹å’Œè·¯å¾„ç‚¹è¿ç§»ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `3Dåœºæ™¯ç±»æ¯”` `å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹` `é›¶æ ·æœ¬å­¦ä¹ ` `æœºå™¨äººå¯¼èˆª` `è½¨è¿¹è¿ç§»`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰3Dåœºæ™¯ç±»æ¯”æ–¹æ³•éœ€è¦é¢å¤–è®­ç»ƒå’Œå›ºå®šè¯æ±‡è¡¨ï¼Œé™åˆ¶äº†å…¶åœ¨å¼€æ”¾ç¯å¢ƒä¸­çš„åº”ç”¨ã€‚
2. æå‡ºä¸€ç§åŸºäºå¤šæ¨¡æ€åŸºç¡€æ¨¡å‹çš„æ··åˆç¥ç»è¡¨ç¤ºæ–¹æ³•ï¼Œå®ç°é›¶æ ·æœ¬ã€å¼€æ”¾è¯æ±‡çš„3Dåœºæ™¯ç±»æ¯”ã€‚
3. å®éªŒè¯æ˜è¯¥æ–¹æ³•èƒ½å‡†ç¡®å»ºç«‹å¤æ‚åœºæ™¯é—´çš„å¯¹åº”å…³ç³»ï¼Œå¹¶æˆåŠŸåº”ç”¨äºè½¨è¿¹å’Œè·¯å¾„ç‚¹è¿ç§»ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ©ç”¨å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹åœ¨é›¶æ ·æœ¬ã€å¼€æ”¾è¯æ±‡ç¯å¢ƒä¸­å¯»æ‰¾3Dåœºæ™¯ç±»æ¯”çš„æ–¹æ³•ï¼Œæ—¨åœ¨å¸®åŠ©æœºå™¨äººåœ¨æ–°çš„ã€æœªè§è¿‡çš„3Dç¯å¢ƒä¸­è¿›è¡Œé€‚åº”å’Œè§„åˆ’ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦é¢å¤–çš„è®­ç»ƒå’Œå›ºå®šçš„å¯¹è±¡è¯æ±‡è¡¨ã€‚è¯¥æ–¹æ³•çš„æ ¸å¿ƒæ˜¯ä¸€ç§æ··åˆç¥ç»åœºæ™¯è¡¨ç¤ºï¼Œå®ƒç”±åŸºäºè§†è§‰-è¯­è¨€æ¨¡å‹ç‰¹å¾çš„ç¨€ç–å›¾å’Œä»3Då½¢çŠ¶åŸºç¡€æ¨¡å‹å¯¼å‡ºçš„ç‰¹å¾åœºç»„æˆã€‚é€šè¿‡ç²—åˆ°ç²¾çš„æ–¹å¼å¯»æ‰¾3Dåœºæ™¯ç±»æ¯”ï¼Œé¦–å…ˆå¯¹é½å›¾ï¼Œç„¶åä½¿ç”¨ç‰¹å¾åœºç»†åŒ–å¯¹åº”å…³ç³»ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å¯ä»¥åœ¨å¤æ‚åœºæ™¯ä¹‹é—´å»ºç«‹å‡†ç¡®çš„å¯¹åº”å…³ç³»ï¼Œå¹¶åº”ç”¨äºè½¨è¿¹å’Œè·¯å¾„ç‚¹è¿ç§»ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰3Dåœºæ™¯ç±»æ¯”æ–¹æ³•éœ€è¦é’ˆå¯¹ç‰¹å®šåœºæ™¯è¿›è¡Œé¢å¤–è®­ç»ƒï¼Œå¹¶ä¸”ä¾èµ–äºå›ºå®šçš„ç‰©ä½“è¯æ±‡è¡¨ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åœ¨æœªçŸ¥å’ŒåŠ¨æ€ç¯å¢ƒä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚è®ºæ–‡æ—¨åœ¨è§£å†³åœ¨é›¶æ ·æœ¬ã€å¼€æ”¾è¯æ±‡çš„æ¡ä»¶ä¸‹ï¼Œå¦‚ä½•é«˜æ•ˆå‡†ç¡®åœ°å»ºç«‹ä¸åŒ3Dåœºæ™¯ä¹‹é—´çš„å¯¹åº”å…³ç³»ï¼Œä»è€Œå®ç°çŸ¥è¯†è¿ç§»çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹å¼ºå¤§çš„è¯­ä¹‰ç†è§£èƒ½åŠ›å’Œ3Då½¢çŠ¶è¡¨å¾èƒ½åŠ›ï¼Œæ„å»ºä¸€ç§æ··åˆç¥ç»åœºæ™¯è¡¨ç¤ºã€‚è¯¥è¡¨ç¤ºç»“åˆäº†è§†è§‰-è¯­è¨€æ¨¡å‹çš„å…¨å±€è¯­ä¹‰ä¿¡æ¯å’Œ3Då½¢çŠ¶åŸºç¡€æ¨¡å‹çš„å±€éƒ¨å‡ ä½•ä¿¡æ¯ï¼Œä»è€Œèƒ½å¤Ÿåœ¨æ²¡æœ‰é¢å¤–è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œå®ç°åœºæ™¯ä¹‹é—´çš„æœ‰æ•ˆå¯¹é½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•é‡‡ç”¨ç²—åˆ°ç²¾çš„ç­–ç•¥ã€‚é¦–å…ˆï¼Œåˆ©ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹æå–åœºæ™¯ä¸­å…³é”®åŒºåŸŸçš„è¯­ä¹‰ç‰¹å¾ï¼Œæ„å»ºç¨€ç–å›¾ï¼Œå¹¶é€šè¿‡å›¾åŒ¹é…ç®—æ³•å®ç°ç²—ç•¥çš„åœºæ™¯å¯¹é½ã€‚ç„¶åï¼Œåˆ©ç”¨3Då½¢çŠ¶åŸºç¡€æ¨¡å‹æå–åœºæ™¯çš„å±€éƒ¨å‡ ä½•ç‰¹å¾ï¼Œæ„å»ºç‰¹å¾åœºï¼Œå¹¶é€šè¿‡ä¼˜åŒ–ç®—æ³•ç»†åŒ–åœºæ™¯å¯¹åº”å…³ç³»ã€‚æ•´ä½“æµç¨‹åŒ…æ‹¬ï¼š1) åœºæ™¯è¡¨ç¤ºæ„å»ºï¼›2) åŸºäºå›¾åŒ¹é…çš„ç²—ç•¥å¯¹é½ï¼›3) åŸºäºç‰¹å¾åœºä¼˜åŒ–çš„ç²¾ç»†å¯¹é½ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå°†å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹å¼•å…¥åˆ°3Dåœºæ™¯ç±»æ¯”ä»»åŠ¡ä¸­ï¼Œå¹¶æå‡ºäº†ä¸€ç§æ··åˆç¥ç»åœºæ™¯è¡¨ç¤ºã€‚è¿™ç§è¡¨ç¤ºæ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°èåˆå…¨å±€è¯­ä¹‰ä¿¡æ¯å’Œå±€éƒ¨å‡ ä½•ä¿¡æ¯ï¼Œä»è€Œåœ¨é›¶æ ·æœ¬ã€å¼€æ”¾è¯æ±‡çš„æ¡ä»¶ä¸‹å®ç°å‡†ç¡®çš„åœºæ™¯å¯¹é½ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•æ— éœ€é¢å¤–è®­ç»ƒï¼Œå¹¶ä¸”èƒ½å¤Ÿå¤„ç†å…·æœ‰ä¸åŒç‰©ä½“è¯æ±‡è¡¨çš„åœºæ™¯ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­å…³é”®çš„è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨CLIPç­‰è§†è§‰-è¯­è¨€æ¨¡å‹æå–åœºæ™¯ä¸­å…³é”®åŒºåŸŸçš„è¯­ä¹‰ç‰¹å¾ï¼›2) ä½¿ç”¨3Då½¢çŠ¶åŸºç¡€æ¨¡å‹ï¼ˆä¾‹å¦‚ShapeNetï¼‰æå–åœºæ™¯çš„å±€éƒ¨å‡ ä½•ç‰¹å¾ï¼›3) è®¾è®¡äº†ä¸€ç§åŸºäºå›¾åŒ¹é…å’Œç‰¹å¾åœºä¼˜åŒ–çš„ä¸¤é˜¶æ®µå¯¹é½ç®—æ³•ï¼›4) æŸå¤±å‡½æ•°çš„è®¾è®¡å¯èƒ½åŒ…æ‹¬å›¾åŒ¹é…çš„ç›¸ä¼¼åº¦æŸå¤±å’Œç‰¹å¾åœºå¯¹åº”å…³ç³»çš„å‡ ä½•ä¸€è‡´æ€§æŸå¤±ï¼ˆå…·ä½“ç»†èŠ‚æœªçŸ¥ï¼‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨å¤æ‚åœºæ™¯ä¹‹é—´å»ºç«‹å‡†ç¡®çš„å¯¹åº”å…³ç³»ï¼Œå¹¶ä¸”åœ¨è½¨è¿¹å’Œè·¯å¾„ç‚¹è¿ç§»ä»»åŠ¡ä¸­å–å¾—äº†è‰¯å¥½çš„æ•ˆæœã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•æ— éœ€é¢å¤–è®­ç»ƒï¼Œå¹¶ä¸”èƒ½å¤Ÿå¤„ç†å…·æœ‰ä¸åŒç‰©ä½“è¯æ±‡è¡¨çš„åœºæ™¯ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†çš„å±•ç¤ºï¼ˆå…·ä½“æ•°å€¼æœªçŸ¥ï¼‰ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæœºå™¨äººå¯¼èˆªã€æ¨¡ä»¿å­¦ä¹ ã€ä»»åŠ¡è§„åˆ’ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œæœºå™¨äººå¯ä»¥é€šè¿‡åœºæ™¯ç±»æ¯”ï¼Œå°†å·²çŸ¥çš„å¯¼èˆªç­–ç•¥è¿ç§»åˆ°æ–°çš„ç¯å¢ƒä¸­ï¼›å¯ä»¥é€šè¿‡æ¨¡ä»¿å­¦ä¹ ï¼Œå°†äººç±»åœ¨ç›¸ä¼¼åœºæ™¯ä¸­çš„æ“ä½œç»éªŒè¿ç§»åˆ°æœºå™¨äººèº«ä¸Šï¼›è¿˜å¯ä»¥é€šè¿‡ä»»åŠ¡è§„åˆ’ï¼Œå°†å·²çŸ¥çš„ä»»åŠ¡æµç¨‹è¿ç§»åˆ°æ–°çš„åœºæ™¯ä¸­ã€‚è¯¥ç ”ç©¶å…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Connecting current observations with prior experiences helps robots adapt and plan in new, unseen 3D environments. Recently, 3D scene analogies have been proposed to connect two 3D scenes, which are smooth maps that align scene regions with common spatial relationships. These maps enable detailed transfer of trajectories or waypoints, potentially supporting demonstration transfer for imitation learning or task plan transfer across scenes. However, existing methods for the task require additional training and fixed object vocabularies. In this work, we propose to use multimodal foundation models for finding 3D scene analogies in a zero-shot, open-vocabulary setting. Central to our approach is a hybrid neural representation of scenes that consists of a sparse graph based on vision-language model features and a feature field derived from 3D shape foundation models. 3D scene analogies are then found in a coarse-to-fine manner, by first aligning the graph and refining the correspondence with feature fields. Our method can establish accurate correspondences between complex scenes, and we showcase applications in trajectory and waypoint transfer.

