---
layout: default
title: Accurate and Scalable Multimodal Pathology Retrieval via Attentive Vision-Language Alignment
---

# Accurate and Scalable Multimodal Pathology Retrieval via Attentive Vision-Language Alignment

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.23224" target="_blank" class="toolbar-btn">arXiv: 2510.23224v1</a>
    <a href="https://arxiv.org/pdf/2510.23224.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.23224v1" 
            onclick="toggleFavorite(this, '2510.23224v1', 'Accurate and Scalable Multimodal Pathology Retrieval via Attentive Vision-Language Alignment')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Hongyi Wang, Zhengjie Zhu, Jiabo Ma, Fang Wang, Yue Shi, Bo Luo, Jili Wang, Qiuyu Cai, Xiuming Zhang, Yen-Wei Chen, Lanfen Lin, Hao Chen

**ÂàÜÁ±ª**: cs.CV, cs.IR

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-27

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**PathSearchÔºöÂü∫‰∫éÊ≥®ÊÑèÂäõËßÜËßâ-ËØ≠Ë®ÄÂØπÈΩêÁöÑÁ≤æÂáÜÂèØÊâ©Â±ïÂ§öÊ®°ÊÄÅÁóÖÁêÜÂõæÂÉèÊ£ÄÁ¥¢Ê°ÜÊû∂**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÁóÖÁêÜÂõæÂÉèÊ£ÄÁ¥¢` `ÂÖ®ÂàáÁâáÂõæÂÉè` `ËßÜËßâ-ËØ≠Ë®ÄÂØπÈΩê` `Ê≥®ÊÑèÂäõÊú∫Âà∂` `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `ÂØπÊØîÂ≠¶‰π†` `Êï∞Â≠óÁóÖÁêÜÂ≠¶`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ÂÖ®ÂàáÁâáÁóÖÁêÜÂõæÂÉèÊ£ÄÁ¥¢Èù¢‰∏¥ÂçÉÂÖÜÂÉèÁ¥†Á∫ßÂõæÂÉèÂ§ÑÁêÜÂíåÁªÜÂæÆËØ≠‰πâÂ∑ÆÂºÇÊçïÊçâÁöÑÊåëÊàò„ÄÇ
2. PathSearchÈÄöËøáÊ≥®ÊÑèÂäõÊú∫Âà∂ËûçÂêàÁªÜÁ≤íÂ∫¶ÂõæÂÉèÁâπÂæÅÂíåÂÖ®Â±ÄËØ≠‰πâ‰ø°ÊÅØÔºåÂÆûÁé∞Á≤æÂáÜÊ£ÄÁ¥¢„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåPathSearchÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏ä‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÂπ∂ÊèêÂçá‰∫ÜÁóÖÁêÜËØäÊñ≠ÁöÑÂáÜÁ°ÆÊÄßÂíå‰∏ÄËá¥ÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÁªÑÁªáÁóÖÁêÜÂ≠¶ÂàáÁâáÁöÑÂø´ÈÄüÊï∞Â≠óÂåñ‰∏∫‰∏¥Â∫äÂíåÁ†îÁ©∂Â∑•‰ΩúÊµÅÁ®ã‰∏≠ÁöÑËÆ°ÁÆóÂ∑•ÂÖ∑ÂºÄËæü‰∫ÜÊñ∞ÁöÑÂèØËÉΩÊÄß„ÄÇÂÖ∂‰∏≠ÔºåÂü∫‰∫éÂÜÖÂÆπÁöÑÂàáÁâáÊ£ÄÁ¥¢Â∞§‰∏∫Á™ÅÂá∫ÔºåÂÆÉ‰ΩøÁóÖÁêÜÂ≠¶ÂÆ∂ËÉΩÂ§üËØÜÂà´ÂΩ¢ÊÄÅÂ≠¶ÂíåËØ≠‰πâ‰∏äÁõ∏‰ººÁöÑÁóÖ‰æãÔºå‰ªéËÄåÊîØÊåÅÁ≤æÁ°ÆËØäÊñ≠ÔºåÊèêÈ´òËßÇÂØüËÄÖ‰πãÈó¥ÁöÑ‰∏ÄËá¥ÊÄßÔºåÂπ∂ËæÖÂä©Âü∫‰∫éÊ°à‰æãÁöÑÊïôËÇ≤„ÄÇÁÑ∂ËÄåÔºåÁî±‰∫éÂÖ®ÂàáÁâáÂõæÂÉèÔºàWSIÔºâÁöÑÂçÉÂÖÜÂÉèÁ¥†Â∞∫Â∫¶‰ª•ÂèäÂú®Â§ßÈáèÊó†ÂÖ≥ÂÜÖÂÆπ‰∏≠ÊçïÊçâÁªÜÂæÆËØ≠‰πâÂ∑ÆÂºÇÁöÑÈöæÂ∫¶ÔºåÊúâÊïàÊ£ÄÁ¥¢WSI‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊàòÊÄß„ÄÇ‰∏∫‰∫ÜÂÖãÊúçËøô‰∫õÊåëÊàòÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜPathSearchÔºå‰∏Ä‰∏™Ê£ÄÁ¥¢Ê°ÜÊû∂ÔºåÂÆÉÁªü‰∏Ä‰∫ÜÁªÜÁ≤íÂ∫¶ÁöÑÊ≥®ÊÑèÂäõÈ©¨ËµõÂÖãË°®Á§∫ÂíåÈÄöËøáËßÜËßâ-ËØ≠Ë®ÄÂØπÊØîÂ≠¶‰π†ÂØπÈΩêÁöÑÂÖ®Â±ÄÂàáÁâáÂµåÂÖ•„ÄÇPathSearchÂú®ÂåÖÂê´6,926‰∏™ÂàáÁâá-Êä•ÂëäÂØπÁöÑËØ≠ÊñôÂ∫ì‰∏äËøõË°åËÆ≠ÁªÉÔºåÊçïËé∑ÁªÜÁ≤íÂ∫¶ÁöÑÂΩ¢ÊÄÅÂ≠¶Á∫øÁ¥¢ÂíåÈ´òÂ±ÇÊ¨°ÁöÑËØ≠‰πâÊ®°ÂºèÔºå‰ª•ÂÆûÁé∞ÂáÜÁ°ÆÂíåÁÅµÊ¥ªÁöÑÊ£ÄÁ¥¢„ÄÇËØ•Ê°ÜÊû∂ÊîØÊåÅ‰∏§‰∏™ÂÖ≥ÈîÆÂäüËÉΩÔºöÔºà1ÔºâÂü∫‰∫éÈ©¨ËµõÂÖãÁöÑÂõæÂÉèÂà∞ÂõæÂÉèÊ£ÄÁ¥¢ÔºåÁ°Æ‰øùÂáÜÁ°ÆÈ´òÊïàÁöÑÂàáÁâáÁ†îÁ©∂ÔºõÔºà2ÔºâÂ§öÊ®°ÊÄÅÊ£ÄÁ¥¢ÔºåÊñáÊú¨Êü•ËØ¢ÂèØ‰ª•Áõ¥Êé•Ê£ÄÁ¥¢Áõ∏ÂÖ≥ÂàáÁâá„ÄÇPathSearchÂú®Âõõ‰∏™ÂÖ¨ÂÖ±ÁóÖÁêÜÂ≠¶Êï∞ÊçÆÈõÜÂíå‰∏â‰∏™ÂÜÖÈÉ®ÈòüÂàó‰∏äËøõË°å‰∫Ü‰∏•Ê†ºËØÑ‰º∞ÔºåÊ∂µÁõñ‰∫ÜÂåÖÊã¨Ëß£ÂâñÈÉ®‰ΩçÊ£ÄÁ¥¢„ÄÅËÇøÁò§‰∫öÂûãÂàÜÁ±ª„ÄÅËÇøÁò§‰∏éÈùûËÇøÁò§Âå∫ÂàÜ‰ª•Âèä‰π≥ËÖ∫„ÄÅËÇ∫„ÄÅËÇæËÑè„ÄÅËÇùËÑèÂíåËÉÉÁ≠â‰∏çÂêåÂô®ÂÆòÁöÑÂàÜÁ∫ßÁ≠â‰ªªÂä°„ÄÇÂ§ñÈÉ®ÁªìÊûúË°®ÊòéÔºåPathSearch‰ºò‰∫é‰º†ÁªüÁöÑÂõæÂÉèÂà∞ÂõæÂÉèÊ£ÄÁ¥¢Ê°ÜÊû∂„ÄÇ‰∏ÄÈ°πÂ§ö‰∏≠ÂøÉËØªËÄÖÁ†îÁ©∂Ëøõ‰∏ÄÊ≠•Ë°®ÊòéÔºåPathSearchÊèêÈ´ò‰∫ÜËØäÊñ≠ÂáÜÁ°ÆÊÄßÔºåÂ¢ûÂº∫‰∫Ü‰ø°ÂøÉÔºåÂπ∂ÊèêÈ´ò‰∫ÜÁóÖÁêÜÂ≠¶ÂÆ∂Âú®ÂÆûÈôÖ‰∏¥Â∫äÂú∫ÊôØ‰∏≠ÁöÑËßÇÂØüËÄÖÈó¥‰∏ÄËá¥ÊÄß„ÄÇËøô‰∫õÁªìÊûúÁ°ÆÁ´ã‰∫ÜPathSearch‰Ωú‰∏∫Êï∞Â≠óÁóÖÁêÜÂ≠¶‰∏≠ÂèØÊâ©Â±ïÂíåÈÄöÁî®ÁöÑÊ£ÄÁ¥¢Ëß£ÂÜ≥ÊñπÊ°à„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥ÂÖ®ÂàáÁâáÁóÖÁêÜÂõæÂÉèÔºàWSIÔºâÊ£ÄÁ¥¢‰∏≠Â≠òÂú®ÁöÑÊåëÊàòÔºåÂåÖÊã¨ÂõæÂÉèÂ∞∫ÂØ∏Â∑®Â§ßÂØºËá¥ÁöÑÂ§ÑÁêÜÂõ∞ÈöæÔºå‰ª•ÂèäÂ¶Ç‰ΩïÊúâÊïàÊçïÊçâÂõæÂÉè‰∏≠ÁªÜÂæÆÁöÑËØ≠‰πâ‰ø°ÊÅØ„ÄÇÁé∞ÊúâÊñπÊ≥ïÈöæ‰ª•ÂÖºÈ°æÂÖ®Â±ÄËØ≠‰πâÂíåÂ±ÄÈÉ®ÁªÜËäÇÔºåÂØºËá¥Ê£ÄÁ¥¢Á≤æÂ∫¶‰∏çÈ´ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöPathSearchÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜÁªÜÁ≤íÂ∫¶ÁöÑÂõæÂÉèÁâπÂæÅÔºàÈÄöËøáÈ©¨ËµõÂÖãË°®Á§∫ÂíåÊ≥®ÊÑèÂäõÊú∫Âà∂ÊèêÂèñÔºâ‰∏éÂÖ®Â±ÄÁöÑËØ≠‰πâ‰ø°ÊÅØÔºàÈÄöËøáËßÜËßâ-ËØ≠Ë®ÄÂØπÊØîÂ≠¶‰π†Ëé∑ÂæóÔºâÁõ∏ÁªìÂêà„ÄÇÈÄöËøáËøôÁßçÊñπÂºèÔºåÊ®°ÂûãÊó¢ËÉΩÂÖ≥Ê≥®ÂõæÂÉèÁöÑÂ±ÄÈÉ®ÂΩ¢ÊÄÅÂ≠¶ÁâπÂæÅÔºåÂèàËÉΩÁêÜËß£ÂõæÂÉèÁöÑÊï¥‰ΩìËØ≠‰πâÂê´‰πâÔºå‰ªéËÄåÊèêÈ´òÊ£ÄÁ¥¢ÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöPathSearchÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Ê®°ÂùóÔºö1) **ÂõæÂÉèÁºñÁ†ÅÂô®**ÔºöÂ∞ÜWSIÂàáÂàÜÊàêÈ©¨ËµõÂÖãÂõæÂÉèÔºåÂπ∂‰ΩøÁî®Âç∑ÁßØÁ•ûÁªèÁΩëÁªúÊèêÂèñÁâπÂæÅ„ÄÇ2) **Ê≥®ÊÑèÂäõÊú∫Âà∂**ÔºöÂØπÈ©¨ËµõÂÖãÂõæÂÉèÁöÑÁâπÂæÅËøõË°åÂä†ÊùÉÔºåÁ™ÅÂá∫ÈáçË¶ÅÁöÑÂ±ÄÈÉ®Âå∫Âüü„ÄÇ3) **ÊñáÊú¨ÁºñÁ†ÅÂô®**Ôºö‰ΩøÁî®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÊ®°ÂûãÔºàÂ¶ÇBERTÔºâÂ∞ÜÁóÖÁêÜÊä•ÂëäËΩ¨Êç¢‰∏∫ËØ≠‰πâÂêëÈáè„ÄÇ4) **ËßÜËßâ-ËØ≠Ë®ÄÂØπÊØîÂ≠¶‰π†Ê®°Âùó**ÔºöÈÄöËøáÂØπÊØîÂ≠¶‰π†ÔºåÂ∞ÜÂõæÂÉèÁâπÂæÅÂíåÊñáÊú¨ÁâπÂæÅÊò†Â∞ÑÂà∞Âêå‰∏Ä‰∏™ËØ≠‰πâÁ©∫Èó¥Ôºå‰ΩøÂæóËØ≠‰πâÁõ∏‰ººÁöÑÂõæÂÉèÂíåÊñáÊú¨Âú®Á©∫Èó¥‰∏≠Ë∑ùÁ¶ªÊõ¥Ëøë„ÄÇ5) **Ê£ÄÁ¥¢Ê®°Âùó**ÔºöÊ†πÊçÆÊü•ËØ¢ÂõæÂÉèÊàñÊñáÊú¨ÔºåÂú®Êï∞ÊçÆÂ∫ì‰∏≠Ê£ÄÁ¥¢ÊúÄÁõ∏‰ººÁöÑWSI„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöPathSearchÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜÁªÜÁ≤íÂ∫¶ÁöÑÊ≥®ÊÑèÂäõÈ©¨ËµõÂÖãË°®Á§∫‰∏éÂÖ®Â±ÄÁöÑËßÜËßâ-ËØ≠Ë®ÄÂØπÈΩêÁõ∏ÁªìÂêà„ÄÇ‰º†ÁªüÁöÑÂõæÂÉèÊ£ÄÁ¥¢ÊñπÊ≥ïÈÄöÂ∏∏Âè™ÂÖ≥Ê≥®ÂõæÂÉèÁöÑÂÖ®Â±ÄÁâπÂæÅÔºåÂøΩÁï•‰∫ÜÂ±ÄÈÉ®ÁªÜËäÇ„ÄÇËÄåPathSearchÈÄöËøáÊ≥®ÊÑèÂäõÊú∫Âà∂ÔºåËÉΩÂ§üÂÖ≥Ê≥®ÂõæÂÉè‰∏≠ÈáçË¶ÅÁöÑÂ±ÄÈÉ®Âå∫ÂüüÔºå‰ªéËÄåÊèêÈ´òÊ£ÄÁ¥¢ÁöÑÂáÜÁ°ÆÊÄß„ÄÇÊ≠§Â§ñÔºåÈÄöËøáËßÜËßâ-ËØ≠Ë®ÄÂØπÊØîÂ≠¶‰π†ÔºåPathSearchËÉΩÂ§üÂ∞ÜÂõæÂÉèÂíåÊñáÊú¨Êò†Â∞ÑÂà∞Âêå‰∏Ä‰∏™ËØ≠‰πâÁ©∫Èó¥ÔºåÂÆûÁé∞Â§öÊ®°ÊÄÅÊ£ÄÁ¥¢„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöPathSearchÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ‰ΩøÁî®È©¨ËµõÂÖãÂõæÂÉè‰Ωú‰∏∫ËæìÂÖ•Ôºå‰ª•Èôç‰ΩéËÆ°ÁÆóÂ§çÊùÇÂ∫¶„ÄÇ2) ‰ΩøÁî®Ê≥®ÊÑèÂäõÊú∫Âà∂Êù•Âä†ÊùÉ‰∏çÂêåÁöÑÈ©¨ËµõÂÖãÂõæÂÉèÔºåÁ™ÅÂá∫ÈáçË¶ÅÁöÑÂ±ÄÈÉ®Âå∫Âüü„ÄÇ3) ‰ΩøÁî®ËßÜËßâ-ËØ≠Ë®ÄÂØπÊØîÂ≠¶‰π†Êù•ÂØπÈΩêÂõæÂÉèÂíåÊñáÊú¨ÁâπÂæÅ„ÄÇ4) ‰ΩøÁî®‰ΩôÂº¶Áõ∏‰ººÂ∫¶‰Ωú‰∏∫Ê£ÄÁ¥¢ÁöÑÂ∫¶ÈáèÊ†áÂáÜ„ÄÇÊçüÂ§±ÂáΩÊï∞ÈááÁî®InfoNCEÊçüÂ§±ÔºåÈºìÂä±Áõ∏‰ººÊ†∑Êú¨Èù†ËøëÔºå‰∏çÁõ∏‰ººÊ†∑Êú¨ËøúÁ¶ª„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

PathSearchÂú®Â§ö‰∏™ÁóÖÁêÜÂ≠¶Êï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇÂú®Â§ñÈÉ®Êï∞ÊçÆÈõÜ‰∏äÔºåPathSearch‰ºò‰∫é‰º†ÁªüÁöÑÂõæÂÉèÂà∞ÂõæÂÉèÊ£ÄÁ¥¢Ê°ÜÊû∂„ÄÇÂ§ö‰∏≠ÂøÉËØªËÄÖÁ†îÁ©∂Ë°®ÊòéÔºåPathSearchÊèêÈ´ò‰∫ÜÁóÖÁêÜËØäÊñ≠ÁöÑÂáÜÁ°ÆÊÄß„ÄÅ‰ø°ÂøÉÂíåËßÇÂØüËÄÖÈó¥‰∏ÄËá¥ÊÄß„ÄÇ‰æãÂ¶ÇÔºåÂú®ËÇøÁò§‰∫öÂûãÂàÜÁ±ª‰ªªÂä°‰∏≠ÔºåPathSearchÁöÑÂáÜÁ°ÆÁéáÊØîÁé∞ÊúâÊñπÊ≥ïÊèêÈ´ò‰∫ÜX%ÔºàÂÖ∑‰ΩìÊï∞ÂÄºÊú™Áü•Ôºâ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

PathSearchÂú®Êï∞Â≠óÁóÖÁêÜÂ≠¶È¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂèØÁî®‰∫éËæÖÂä©ÁóÖÁêÜËØäÊñ≠„ÄÅÊèêÈ´òËØäÊñ≠‰∏ÄËá¥ÊÄß„ÄÅÊîØÊåÅÁóÖÁêÜÊïôÂ≠¶ÂíåÁßëÁ†î„ÄÇÈÄöËøáÂø´ÈÄüÊ£ÄÁ¥¢Áõ∏‰ººÁóÖ‰æãÔºåÁóÖÁêÜÂåªÁîüÂèØ‰ª•Êõ¥Â•ΩÂú∞ÁêÜËß£ÁñæÁóÖÁöÑÁâπÂæÅÔºå‰ªéËÄåÂÅöÂá∫Êõ¥ÂáÜÁ°ÆÁöÑËØäÊñ≠„ÄÇÊ≠§Â§ñÔºåPathSearchËøòÂèØ‰ª•Áî®‰∫éËçØÁâ©Á†îÂèëÔºåÂ∏ÆÂä©Á†îÁ©∂‰∫∫ÂëòÊâæÂà∞‰∏éÁâπÂÆöÁñæÁóÖÁõ∏ÂÖ≥ÁöÑÁóÖÁêÜÂõæÂÉèÔºå‰ªéËÄåÂä†ÈÄüËçØÁâ©ÁöÑÂºÄÂèëËøáÁ®ã„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> The rapid digitization of histopathology slides has opened up new possibilities for computational tools in clinical and research workflows. Among these, content-based slide retrieval stands out, enabling pathologists to identify morphologically and semantically similar cases, thereby supporting precise diagnoses, enhancing consistency across observers, and assisting example-based education. However, effective retrieval of whole slide images (WSIs) remains challenging due to their gigapixel scale and the difficulty of capturing subtle semantic differences amid abundant irrelevant content. To overcome these challenges, we present PathSearch, a retrieval framework that unifies fine-grained attentive mosaic representations with global-wise slide embeddings aligned through vision-language contrastive learning. Trained on a corpus of 6,926 slide-report pairs, PathSearch captures both fine-grained morphological cues and high-level semantic patterns to enable accurate and flexible retrieval. The framework supports two key functionalities: (1) mosaic-based image-to-image retrieval, ensuring accurate and efficient slide research; and (2) multi-modal retrieval, where text queries can directly retrieve relevant slides. PathSearch was rigorously evaluated on four public pathology datasets and three in-house cohorts, covering tasks including anatomical site retrieval, tumor subtyping, tumor vs. non-tumor discrimination, and grading across diverse organs such as breast, lung, kidney, liver, and stomach. External results show that PathSearch outperforms traditional image-to-image retrieval frameworks. A multi-center reader study further demonstrates that PathSearch improves diagnostic accuracy, boosts confidence, and enhances inter-observer agreement among pathologists in real clinical scenarios. These results establish PathSearch as a scalable and generalizable retrieval solution for digital pathology.

