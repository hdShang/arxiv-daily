---
layout: default
title: PISA-Bench: The PISA Index as a Multilingual and Multimodal Metric for the Evaluation of Vision-Language Models
---

# PISA-Bench: The PISA Index as a Multilingual and Multimodal Metric for the Evaluation of Vision-Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.24792" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.24792v2</a>
  <a href="https://arxiv.org/pdf/2510.24792.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.24792v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.24792v2', 'PISA-Bench: The PISA Index as a Multilingual and Multimodal Metric for the Evaluation of Vision-Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Patrick Haller, Fabio Barth, Jonas Golde, Georg Rehm, Alan Akbik

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-10-27 (æ›´æ–°: 2025-11-12)

**å¤‡æ³¨**: 8 pages, 11 tables and figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**PISA-Benchï¼šä¸€ä¸ªå¤šè¯­è¨€å¤šæ¨¡æ€åŸºå‡†ï¼Œç”¨äºè¯„ä¼°è§†è§‰-è¯­è¨€æ¨¡å‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€æ¨¡å‹` `å¤šæ¨¡æ€å­¦ä¹ ` `å¤šè¯­è¨€` `åŸºå‡†æµ‹è¯•` `PISA` `æ•™è‚²` `æ¨ç†èƒ½åŠ›`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰-è¯­è¨€æ¨¡å‹åŸºå‡†æµ‹è¯•æ•°æ®é›†ç¼ºä¹é«˜è´¨é‡ã€äººå·¥éªŒè¯çš„å¤šè¯­è¨€ç¤ºä¾‹ï¼Œä¸”ä¾èµ–äºåˆæˆæ•°æ®ï¼Œé™åˆ¶äº†æ¨¡å‹è¯„ä¼°çš„å¯é æ€§ã€‚
2. PISA-Benchåˆ©ç”¨ä¸“å®¶è®¾è®¡çš„PISAæµ‹è¯•é¢˜ï¼Œæ„å»ºäº†ä¸€ä¸ªåŒ…å«å…­ç§è¯­è¨€çš„å¹³è¡Œè¯­æ–™åº“ï¼Œä¸ºå¤šè¯­è¨€å¤šæ¨¡æ€æ¨ç†æä¾›æ›´å¯é çš„è¯„ä¼°ã€‚
3. å®éªŒè¡¨æ˜ï¼Œç°æœ‰è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨PISA-Benchä¸Šè¡¨ç°ä¸ä½³ï¼Œå°¤å…¶æ˜¯åœ¨éè‹±è¯­è¯­ç§å’Œç©ºé—´å‡ ä½•æ¨ç†ä»»åŠ¡ä¸­ï¼Œçªæ˜¾äº†è¿›ä¸€æ­¥ç ”ç©¶çš„å¿…è¦æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨å¤šæ¨¡æ€æ¨ç†æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŸºå‡†æµ‹è¯•åœ¨é«˜è´¨é‡ã€äººå·¥éªŒè¯çš„ç¤ºä¾‹æ–¹é¢ä»ç„¶æœ‰é™ã€‚è®¸å¤šå½“å‰çš„æ•°æ®é›†ä¾èµ–äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åˆæˆç”Ÿæˆçš„å†…å®¹ã€‚æ­¤å¤–ï¼Œå¤§å¤šæ•°æ•°æ®é›†ä»…é™äºè‹±è¯­ï¼Œå› ä¸ºç¿»è¯‘æ ·æœ¬çš„æ‰‹åŠ¨è´¨é‡ä¿è¯æ—¢è€—æ—¶åˆæ˜‚è´µã€‚ä¸ºäº†å¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬æ¨å‡ºäº†PISA-Benchï¼Œè¿™æ˜¯ä¸€ä¸ªå¤šè¯­è¨€åŸºå‡†ï¼Œæºè‡ªä¸“å®¶åˆ›å»ºçš„PISAæµ‹è¯•çš„è‹±è¯­ç¤ºä¾‹ï¼ŒPISAæµ‹è¯•æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ï¼Œç”¨äºè¯„ä¼°å…«åå¤šä¸ªå›½å®¶å­¦ç”Ÿçš„èƒœä»»åŠ›ã€‚æ¯ä¸ªç¤ºä¾‹éƒ½åŒ…å«äººå·¥æå–çš„æŒ‡ä»¤ã€é—®é¢˜ã€ç­”æ¡ˆé€‰é¡¹å’Œå›¾åƒï¼Œå¹¶ä¸°å¯Œäº†é—®é¢˜ç±»å‹ç±»åˆ«ï¼Œå¹¶ä¸”å·²ä»è‹±è¯­ç¿»è¯‘æˆå…¶ä»–äº”ç§è¯­è¨€ï¼ˆè¥¿ç­ç‰™è¯­ã€å¾·è¯­ã€ä¸­æ–‡ã€æ³•è¯­å’Œæ„å¤§åˆ©è¯­ï¼‰ï¼Œä»è€Œå½¢æˆäº†ä¸€ä¸ªæ¶µç›–å…­ç§è¯­è¨€çš„å®Œå…¨å¹³è¡Œçš„è¯­æ–™åº“ã€‚æˆ‘ä»¬è¯„ä¼°äº†PISA-Benchä¸Šæœ€å…ˆè¿›çš„è§†è§‰-è¯­è¨€æ¨¡å‹ï¼Œå‘ç°ç‰¹åˆ«æ˜¯å°å‹æ¨¡å‹ï¼ˆ<20Bå‚æ•°ï¼‰æœªèƒ½è·å¾—é«˜æµ‹è¯•åˆ†æ•°ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥å‘ç°éè‹±è¯­æ‹†åˆ†æ—¶çš„æ€§èƒ½æ˜¾ç€ä¸‹é™ï¼Œä»¥åŠå½“æ¨¡å‹æ‰§è¡Œç©ºé—´å’Œå‡ ä½•æ¨ç†ä»»åŠ¡æ—¶çš„é«˜é”™è¯¯ç‡ã€‚é€šè¿‡å‘å¸ƒæ•°æ®é›†å’Œè¯„ä¼°æ¡†æ¶ï¼Œæˆ‘ä»¬ä¸ºæ¨è¿›å¤šè¯­è¨€å¤šæ¨¡æ€æ¨ç†ç ”ç©¶æä¾›èµ„æºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰çš„è¯„ä¼°åŸºå‡†å­˜åœ¨ä»¥ä¸‹ç—›ç‚¹ï¼šä¸€æ˜¯æ•°æ®é›†è´¨é‡ä¸é«˜ï¼Œä¾èµ–å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åˆæˆæ•°æ®ï¼Œç¼ºä¹äººå·¥éªŒè¯ï¼›äºŒæ˜¯æ•°æ®é›†è¯­ç§å•ä¸€ï¼Œä¸»è¦é›†ä¸­åœ¨è‹±è¯­ï¼Œç¼ºä¹å¤šè¯­è¨€æ”¯æŒï¼Œé™åˆ¶äº†æ¨¡å‹åœ¨ä¸åŒè¯­è¨€ç¯å¢ƒä¸‹çš„æ³›åŒ–èƒ½åŠ›ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ä¸ªé«˜è´¨é‡ã€å¤šè¯­è¨€çš„åŸºå‡†æ•°æ®é›†æ¥æ›´å…¨é¢åœ°è¯„ä¼°VLMçš„æ€§èƒ½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨PISAï¼ˆå›½é™…å­¦ç”Ÿè¯„ä¼°é¡¹ç›®ï¼‰æµ‹è¯•é¢˜ä½œä¸ºæ„å»ºåŸºå‡†æ•°æ®é›†çš„åŸºç¡€ã€‚PISAæµ‹è¯•é¢˜ç”±ä¸“å®¶è®¾è®¡ï¼Œå…·æœ‰é«˜è´¨é‡ã€äººå·¥éªŒè¯çš„ç‰¹ç‚¹ï¼Œå¹¶ä¸”æ¶µç›–å¤šç§è¯­è¨€ã€‚é€šè¿‡å°†PISAæµ‹è¯•é¢˜è½¬åŒ–ä¸ºè§†è§‰-è¯­è¨€ä»»åŠ¡ï¼Œå¯ä»¥æ„å»ºä¸€ä¸ªæ›´å¯é ã€æ›´å…·æŒ‘æˆ˜æ€§çš„å¤šè¯­è¨€VLMè¯„ä¼°åŸºå‡†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPISA-Benchçš„æ„å»ºæµç¨‹ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1) ä»PISAæµ‹è¯•é¢˜ä¸­æå–è‹±è¯­ç¤ºä¾‹ï¼ŒåŒ…æ‹¬æŒ‡ä»¤ã€é—®é¢˜ã€ç­”æ¡ˆé€‰é¡¹å’Œå›¾åƒï¼›2) å¯¹æå–çš„ç¤ºä¾‹è¿›è¡Œæ ‡æ³¨ï¼Œæ·»åŠ é—®é¢˜ç±»å‹ç±»åˆ«ç­‰ä¿¡æ¯ï¼›3) å°†è‹±è¯­ç¤ºä¾‹ç¿»è¯‘æˆäº”ç§å…¶ä»–è¯­è¨€ï¼ˆè¥¿ç­ç‰™è¯­ã€å¾·è¯­ã€ä¸­æ–‡ã€æ³•è¯­å’Œæ„å¤§åˆ©è¯­ï¼‰ï¼Œå½¢æˆä¸€ä¸ªå®Œå…¨å¹³è¡Œçš„å…­ç§è¯­è¨€è¯­æ–™åº“ï¼›4) æ„å»ºè¯„ä¼°æ¡†æ¶ï¼Œç”¨äºè¯„ä¼°VLMåœ¨PISA-Benchä¸Šçš„æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šPISA-Benchçš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æ•°æ®é›†è´¨é‡é«˜ï¼šä½¿ç”¨ä¸“å®¶è®¾è®¡çš„PISAæµ‹è¯•é¢˜ï¼Œé¿å…äº†LLMåˆæˆæ•°æ®å¸¦æ¥çš„è´¨é‡é—®é¢˜ï¼›2) å¤šè¯­è¨€æ”¯æŒï¼šæä¾›å…­ç§è¯­è¨€çš„å¹³è¡Œè¯­æ–™åº“ï¼Œå¯ä»¥è¯„ä¼°VLMåœ¨ä¸åŒè¯­è¨€ç¯å¢ƒä¸‹çš„æ€§èƒ½ï¼›3) ä»»åŠ¡å¤šæ ·æ€§ï¼šPISAæµ‹è¯•é¢˜æ¶µç›–å¤šç§é—®é¢˜ç±»å‹ï¼Œå¯ä»¥è¯„ä¼°VLMåœ¨ä¸åŒä»»åŠ¡ä¸Šçš„èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šPISA-Benchçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) é—®é¢˜çš„ç±»å‹æ ‡æ³¨ï¼Œæ–¹ä¾¿é’ˆå¯¹ç‰¹å®šç±»å‹çš„æ¨ç†èƒ½åŠ›è¿›è¡Œè¯„ä¼°ï¼›2) ä¸¥æ ¼çš„ç¿»è¯‘æµç¨‹ï¼Œä¿è¯å¤šè¯­è¨€ç‰ˆæœ¬çš„ä¸€è‡´æ€§å’Œå‡†ç¡®æ€§ï¼›3) è¯„ä¼°æŒ‡æ ‡çš„é€‰æ‹©ï¼Œèƒ½å¤Ÿå…¨é¢åæ˜ VLMåœ¨ä¸åŒè¯­è¨€å’Œä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œç°æœ‰è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨PISA-Benchä¸Šçš„è¡¨ç°ä¸æ¨¡å‹è§„æ¨¡ç›¸å…³ï¼Œå°æ¨¡å‹ï¼ˆ<20Bå‚æ•°ï¼‰è¡¨ç°è¾ƒå·®ã€‚éè‹±è¯­è¯­ç§çš„æ€§èƒ½æ˜æ˜¾ä½äºè‹±è¯­ï¼Œä¸”åœ¨ç©ºé—´å’Œå‡ ä½•æ¨ç†ä»»åŠ¡ä¸­é”™è¯¯ç‡è¾ƒé«˜ã€‚è¿™äº›ç»“æœçªæ˜¾äº†ç°æœ‰æ¨¡å‹åœ¨å¤šè¯­è¨€å’Œå¤æ‚æ¨ç†æ–¹é¢çš„ä¸è¶³ï¼Œä¸ºæœªæ¥çš„ç ”ç©¶æ–¹å‘æä¾›äº†é‡è¦å‚è€ƒã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

PISA-Benchå¯ç”¨äºè¯„ä¼°å’Œæå‡è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸‹çš„æ¨ç†èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨æ•™è‚²ã€ä¿¡æ¯æ£€ç´¢å’Œè·¨æ–‡åŒ–äº¤æµç­‰é¢†åŸŸã€‚é«˜è´¨é‡çš„å¤šè¯­è¨€ç†è§£èƒ½åŠ›æœ‰åŠ©äºå¼€å‘æ›´æ™ºèƒ½çš„æ•™è‚²è¾…åŠ©å·¥å…·ï¼Œæå‡è·¨è¯­è¨€ä¿¡æ¯æ£€ç´¢çš„å‡†ç¡®æ€§ï¼Œå¹¶ä¿ƒè¿›ä¸åŒæ–‡åŒ–èƒŒæ™¯ä¸‹çš„æœ‰æ•ˆæ²Ÿé€šã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision-language models (VLMs) have demonstrated remarkable progress in multimodal reasoning. However, existing benchmarks remain limited in terms of high-quality, human-verified examples. Many current datasets rely on synthetically generated content by large language models (LLMs). Furthermore, most datasets are limited to English, as manual quality assurance of translated samples is time-consuming and costly. To fill this gap, we introduce PISA-Bench, a multilingual benchmark derived from English examples of the expert-created PISA tests, a unified framework for the assessment of student competencies in over eighty countries. Each example consists of human-extracted instructions, questions, answer options, and images, enriched with question type categories, and has been translated from English into five additional languages (Spanish, German, Chinese, French, and Italian), resulting in a fully parallel corpus covering six languages. We evaluate state-of-the-art vision-language models on PISA-Bench and find that especially small models (<20B parameters) fail to achieve high test scores. We further find substantial performance degradation on non-English splits as well as high error-rates when models are tasked with spatial and geometric reasoning. By releasing the dataset and evaluation framework, we provide a resource for advancing research on multilingual multimodal reasoning.

