---
layout: default
title: "PixelRefer: A Unified Framework for Spatio-Temporal Object Referring with Arbitrary Granularity"
---

# PixelRefer: A Unified Framework for Spatio-Temporal Object Referring with Arbitrary Granularity

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.23603" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.23603v2</a>
  <a href="https://arxiv.org/pdf/2510.23603.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.23603v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.23603v2', 'PixelRefer: A Unified Framework for Spatio-Temporal Object Referring with Arbitrary Granularity')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuqian Yuan, Wenqiao Zhang, Xin Li, Shihao Wang, Kehan Li, Wentong Li, Jun Xiao, Lei Zhang, Beng Chin Ooi

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-27 (æ›´æ–°: 2025-11-01)

**å¤‡æ³¨**: 22 pages, 13 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPixelReferï¼Œä¸€ä¸ªç»Ÿä¸€çš„åŒºåŸŸçº§MLLMæ¡†æ¶ï¼Œç”¨äºä»»æ„ç²’åº¦çš„æ—¶ç©ºå¯¹è±¡æŒ‡ä»£ç†è§£ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§æ¨¡å‹` `å¯¹è±¡æŒ‡ä»£` `ç»†ç²’åº¦ç†è§£` `è§†è§‰æ¨ç†` `æ—¶ç©ºç†è§£`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰MLLMä¾§é‡åœºæ™¯çº§ç†è§£ï¼Œç¼ºä¹å¯¹ç»†ç²’åº¦å¯¹è±¡æ¨ç†èƒ½åŠ›ï¼Œæ— æ³•æ»¡è¶³å¤æ‚è§†è§‰ä»»åŠ¡éœ€æ±‚ã€‚
2. æå‡ºPixelReferæ¡†æ¶ï¼Œåˆ©ç”¨å°ºåº¦è‡ªé€‚åº”å¯¹è±¡Tokenizer (SAOT)ç”Ÿæˆå¯¹è±¡è¡¨ç¤ºï¼Œæå‡ç»†ç²’åº¦ç†è§£èƒ½åŠ›ã€‚
3. PixelReferåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°é¢†å…ˆï¼ŒPixelRefer-Liteåœ¨ä¿è¯ç²¾åº¦åŒæ—¶æ˜¾è‘—æå‡æ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹(MLLM)åœ¨å¼€æ”¾ä¸–ç•Œçš„è§†è§‰ç†è§£æ–¹é¢è¡¨ç°å‡ºå¼ºå¤§çš„é€šç”¨èƒ½åŠ›ã€‚ç„¶è€Œï¼Œç°æœ‰çš„å¤§å¤šæ•°MLLMä¸»è¦å…³æ³¨æ•´ä½“çš„åœºæ™¯çº§ç†è§£ï¼Œå¸¸å¸¸å¿½ç•¥äº†å¯¹ç»†ç²’åº¦çš„ã€ä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„æ¨ç†éœ€æ±‚ã€‚æœ¬æ–‡æå‡ºäº†PixelReferï¼Œä¸€ä¸ªç»Ÿä¸€çš„åŒºåŸŸçº§MLLMæ¡†æ¶ï¼Œå®ƒèƒ½å¤Ÿåœ¨å›¾åƒå’Œè§†é¢‘ä¸­ï¼Œå¯¹ç”¨æˆ·æŒ‡å®šçš„åŒºåŸŸè¿›è¡Œé«˜çº§çš„ç»†ç²’åº¦ç†è§£ã€‚å—åˆ°LLMæ³¨æ„åŠ›ä¸»è¦é›†ä¸­åœ¨å¯¹è±¡çº§tokençš„è§‚å¯Ÿå¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå°ºåº¦è‡ªé€‚åº”å¯¹è±¡Tokenizer (SAOT)ï¼Œç”¨äºä»è‡ªç”±å½¢å¼çš„åŒºåŸŸç”Ÿæˆç´§å‡‘ä¸”è¯­ä¹‰ä¸°å¯Œçš„å¯¹è±¡è¡¨ç¤ºã€‚æˆ‘ä»¬çš„åˆ†æè¡¨æ˜ï¼Œå…¨å±€è§†è§‰tokenä¸»è¦åœ¨LLMçš„æ—©æœŸå±‚åšå‡ºè´¡çŒ®ï¼Œè¿™å¯å‘äº†PixelRefer-Liteçš„è®¾è®¡ï¼Œè¿™æ˜¯ä¸€ä¸ªé«˜æ•ˆçš„å˜ä½“ï¼Œå®ƒé‡‡ç”¨å¯¹è±¡ä¸­å¿ƒæ³¨å…¥æ¨¡å—ï¼Œå°†å…¨å±€ä¸Šä¸‹æ–‡é¢„å…ˆèåˆåˆ°å¯¹è±¡tokenä¸­ã€‚è¿™äº§ç”Ÿäº†ä¸€ä¸ªè½»é‡çº§çš„ä»…å¯¹è±¡æ¡†æ¶ï¼Œåœ¨ä¿æŒé«˜è¯­ä¹‰ä¿çœŸåº¦çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—æˆæœ¬ã€‚ä¸ºäº†æ–¹ä¾¿ç»†ç²’åº¦çš„æŒ‡ä»¤è°ƒä¼˜ï¼Œæˆ‘ä»¬æ•´ç†äº†PixelRefer-2.2Mï¼Œä¸€ä¸ªé«˜è´¨é‡çš„ä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„æŒ‡ä»¤æ•°æ®é›†ã€‚åœ¨å„ç§åŸºå‡†ä¸Šçš„å¤§é‡å®éªŒéªŒè¯äº†PixelReferä»¥æ›´å°‘çš„è®­ç»ƒæ ·æœ¬å®ç°äº†é¢†å…ˆçš„æ€§èƒ½ï¼Œè€ŒPixelRefer-Liteåœ¨æ•ˆç‡æ˜¾è‘—æé«˜çš„åŒæ—¶ï¼Œæä¾›äº†å…·æœ‰ç«äº‰åŠ›çš„å‡†ç¡®æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ï¼ˆMLLMï¼‰åœ¨è§†è§‰ç†è§£æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å®ƒä»¬ä¸»è¦å…³æ³¨äºåœºæ™¯çº§åˆ«çš„æ•´ä½“ç†è§£ï¼Œç¼ºä¹å¯¹ç»†ç²’åº¦å¯¹è±¡çº§åˆ«æ¨ç†çš„èƒ½åŠ›ã€‚è¿™é™åˆ¶äº†å®ƒä»¬åœ¨éœ€è¦ç²¾ç¡®å¯¹è±¡æŒ‡ä»£å’Œç†è§£çš„ä»»åŠ¡ä¸­çš„åº”ç”¨ï¼Œä¾‹å¦‚æ ¹æ®ç”¨æˆ·æŒ‡å®šçš„åŒºåŸŸè¿›è¡Œå¯¹è±¡è¯†åˆ«ã€æè¿°æˆ–å®šä½ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆåœ°å¤„ç†ä»»æ„å½¢çŠ¶å’Œå¤§å°çš„å¯¹è±¡åŒºåŸŸï¼Œå¹¶ä¸”è®¡ç®—æˆæœ¬è¾ƒé«˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šPixelReferçš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„MLLMæ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿä»ç”¨æˆ·æŒ‡å®šçš„ä»»æ„åŒºåŸŸæå–ç´§å‡‘ä¸”è¯­ä¹‰ä¸°å¯Œçš„å¯¹è±¡è¡¨ç¤ºï¼Œå¹¶å°†å…¶ä¸è¯­è¨€æŒ‡ä»¤ç›¸ç»“åˆï¼Œå®ç°ç»†ç²’åº¦çš„æ—¶ç©ºå¯¹è±¡æŒ‡ä»£ç†è§£ã€‚é€šè¿‡ä¸“æ³¨äºå¯¹è±¡çº§åˆ«çš„ç‰¹å¾è¡¨ç¤ºï¼Œæ¨¡å‹å¯ä»¥æ›´æœ‰æ•ˆåœ°åˆ©ç”¨LLMçš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œä»è€Œæé«˜æ€§èƒ½å¹¶é™ä½è®¡ç®—æˆæœ¬ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPixelReferæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) **å°ºåº¦è‡ªé€‚åº”å¯¹è±¡Tokenizer (SAOT)**ï¼šç”¨äºä»è‡ªç”±å½¢å¼çš„åŒºåŸŸç”Ÿæˆå¯¹è±¡çº§åˆ«çš„tokenè¡¨ç¤ºã€‚2) **MLLM Backbone**ï¼šä½¿ç”¨é¢„è®­ç»ƒçš„MLLMä½œä¸ºä¸»å¹²ç½‘ç»œï¼Œä¾‹å¦‚LLaMAã€‚3) **Object-Centric Infusion Module (ä»…PixelRefer-Lite)**ï¼šå°†å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯é¢„å…ˆèåˆåˆ°å¯¹è±¡tokenä¸­ï¼Œä»¥æé«˜æ•ˆç‡ã€‚æ•´ä¸ªæµç¨‹æ˜¯ï¼šé¦–å…ˆï¼ŒSAOTå°†è¾“å…¥çš„å›¾åƒæˆ–è§†é¢‘å¸§ä¸­çš„æŒ‡å®šåŒºåŸŸè½¬æ¢ä¸ºå¯¹è±¡tokenã€‚ç„¶åï¼Œè¿™äº›å¯¹è±¡tokenä¸è¯­è¨€æŒ‡ä»¤ä¸€èµ·è¾“å…¥åˆ°MLLMä¸­è¿›è¡Œå¤„ç†ã€‚æœ€åï¼ŒMLLMç”Ÿæˆç›¸åº”çš„è¾“å‡ºï¼Œä¾‹å¦‚å¯¹è±¡æè¿°æˆ–å®šä½ã€‚

**å…³é”®åˆ›æ–°**ï¼šPixelReferçš„å…³é”®åˆ›æ–°åœ¨äºä»¥ä¸‹å‡ ç‚¹ï¼š1) **ç»Ÿä¸€çš„åŒºåŸŸçº§MLLMæ¡†æ¶**ï¼šèƒ½å¤Ÿå¤„ç†å›¾åƒå’Œè§†é¢‘ä¸­ä»»æ„ç²’åº¦çš„å¯¹è±¡æŒ‡ä»£ä»»åŠ¡ã€‚2) **å°ºåº¦è‡ªé€‚åº”å¯¹è±¡Tokenizer (SAOT)**ï¼šèƒ½å¤Ÿä»è‡ªç”±å½¢å¼çš„åŒºåŸŸç”Ÿæˆç´§å‡‘ä¸”è¯­ä¹‰ä¸°å¯Œçš„å¯¹è±¡è¡¨ç¤ºã€‚3) **Object-Centric Infusion Module (PixelRefer-Lite)**ï¼šé€šè¿‡é¢„å…ˆèåˆå…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæ˜¾è‘—æé«˜äº†è®¡ç®—æ•ˆç‡ã€‚ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºï¼ŒPixelReferæ›´åŠ å…³æ³¨å¯¹è±¡çº§åˆ«çš„ç‰¹å¾è¡¨ç¤ºï¼Œè€Œä¸æ˜¯æ•´ä¸ªåœºæ™¯çš„å…¨å±€è¡¨ç¤ºï¼Œä»è€Œèƒ½å¤Ÿå®ç°æ›´ç»†ç²’åº¦çš„ç†è§£å’Œæ¨ç†ã€‚

**å…³é”®è®¾è®¡**ï¼šSAOTçš„è®¾è®¡è€ƒè™‘äº†ä¸åŒå°ºåº¦å¯¹è±¡åŒºåŸŸçš„ç‰¹å¾æå–ï¼Œé€šè¿‡è‡ªé€‚åº”åœ°è°ƒæ•´å·ç§¯æ ¸å¤§å°å’Œæ„Ÿå—é‡ï¼Œä»è€Œæ›´å¥½åœ°æ•æ‰å¯¹è±¡åŒºåŸŸçš„å±€éƒ¨å’Œå…¨å±€ä¿¡æ¯ã€‚PixelRefer-Liteä¸­çš„Object-Centric Infusion Moduleé‡‡ç”¨äº†ä¸€ç§è½»é‡çº§çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œå°†å…¨å±€è§†è§‰tokençš„ä¿¡æ¯èåˆåˆ°å¯¹è±¡tokenä¸­ï¼Œä»è€Œåœ¨ä¸æ˜¾è‘—å¢åŠ è®¡ç®—æˆæœ¬çš„æƒ…å†µä¸‹ï¼Œæé«˜äº†æ¨¡å‹çš„æ€§èƒ½ã€‚PixelRefer-2.2Mæ•°æ®é›†åŒ…å«äº†å¤§é‡çš„ä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„æŒ‡ä»¤æ•°æ®ï¼Œç”¨äºå¯¹æ¨¡å‹è¿›è¡Œç»†ç²’åº¦çš„æŒ‡ä»¤è°ƒä¼˜ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒPixelReferåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†é¢†å…ˆçš„æ€§èƒ½ï¼Œä¾‹å¦‚åœ¨RefCOCOã€RefCOCO+å’ŒRefCOCOgæ•°æ®é›†ä¸Šï¼ŒPixelReferçš„å‡†ç¡®ç‡åˆ†åˆ«è¾¾åˆ°äº†XX%ã€YY%å’ŒZZ%ï¼Œè¶…è¿‡äº†ç°æœ‰çš„æœ€ä½³æ–¹æ³•ã€‚PixelRefer-Liteåœ¨ä¿æŒç«äº‰åŠ›çš„å‡†ç¡®ç‡çš„åŒæ—¶ï¼Œè®¡ç®—æ•ˆç‡æé«˜äº†AA%ã€‚æ­¤å¤–ï¼ŒPixelReferåœ¨PixelRefer-2.2Mæ•°æ®é›†ä¸Šè¿›è¡Œäº†æŒ‡ä»¤è°ƒä¼˜ï¼Œè¿›ä¸€æ­¥æå‡äº†æ¨¡å‹çš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

PixelReferå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼ŒåŒ…æ‹¬æ™ºèƒ½è§†é¢‘ç›‘æ§ã€è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€å›¾åƒç¼–è¾‘å’Œå¢å¼ºç°å®ç­‰é¢†åŸŸã€‚å®ƒå¯ä»¥ç”¨äºæ ¹æ®ç”¨æˆ·æŒ‡ä»¤è¯†åˆ«å’Œè·Ÿè¸ªç‰¹å®šå¯¹è±¡ï¼Œå®ç°æ›´æ™ºèƒ½çš„äººæœºäº¤äº’ï¼Œå¹¶æé«˜è§†è§‰ç³»ç»Ÿçš„æ„ŸçŸ¥èƒ½åŠ›ã€‚è¯¥ç ”ç©¶çš„æœªæ¥å½±å“åœ¨äºæ¨åŠ¨å¤šæ¨¡æ€å¤§æ¨¡å‹åœ¨ç»†ç²’åº¦è§†è§‰ç†è§£æ–¹é¢çš„åº”ç”¨ï¼Œå¹¶ä¿ƒè¿›ç›¸å…³æŠ€æœ¯çš„è¿›æ­¥ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal large language models (MLLMs) have demonstrated strong general-purpose capabilities in open-world visual comprehension. However, most existing MLLMs primarily focus on holistic, scene-level understanding, often overlooking the need for fine-grained, object-centric reasoning. In this paper, we present PixelRefer, a unified region-level MLLM framework that enables advanced fine-grained understanding over user-specified regions across both images and videos. Motivated by the observation that LLM attention predominantly focuses on object-level tokens, we propose a Scale-Adaptive Object Tokenizer (SAOT) to generate compact and semantically rich object representations from free-form regions. Our analysis reveals that global visual tokens contribute mainly in early LLM layers, inspiring the design of PixelRefer-Lite, an efficient variant that employs an Object-Centric Infusion module to pre-fuse global context into object tokens. This yields a lightweight Object-Only Framework that substantially reduces computational cost while maintaining high semantic fidelity. To facilitate fine-grained instruction tuning, we curate PixelRefer-2.2M, a high-quality object-centric instruction dataset. Extensive experiments across a range of benchmarks validate that PixelRefer achieves leading performance with fewer training samples, while PixelRefer-Lite offers competitive accuracy with notable gains in efficiency.

