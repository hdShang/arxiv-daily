---
layout: default
title: AG-Fusion: adaptive gated multimodal fusion for 3d object detection in complex scenes
---

# AG-Fusion: adaptive gated multimodal fusion for 3d object detection in complex scenes

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.23151" target="_blank" class="toolbar-btn">arXiv: 2510.23151v1</a>
    <a href="https://arxiv.org/pdf/2510.23151.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.23151v1" 
            onclick="toggleFavorite(this, '2510.23151v1', 'AG-Fusion: adaptive gated multimodal fusion for 3d object detection in complex scenes')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Sixian Liu, Chen Xu, Qiang Wang, Donghai Shi, Yiwen Li

**ÂàÜÁ±ª**: cs.CV, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-27

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Ëá™ÈÄÇÂ∫îÈó®ÊéßËûçÂêàÊñπÊ≥ï‰ª•Ëß£ÂÜ≥Â§çÊùÇÂú∫ÊôØ‰∏≠ÁöÑ3DÁâ©‰ΩìÊ£ÄÊµãÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Ëá™ÈÄÇÂ∫îÈó®ÊéßËûçÂêà` `Â§öÊ®°ÊÄÅËûçÂêà` `3DÁâ©‰ΩìÊ£ÄÊµã` `Â§çÊùÇÂú∫ÊôØ` `ÊøÄÂÖâÈõ∑Ëææ` `È∏üÁû∞ËßÜÂõæ` `Ë∑®Ê®°ÊÄÅÊ≥®ÊÑèÂäõ` `ÊåñÊéòÊú∫Êìç‰Ωú`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂ§öÊ®°ÊÄÅËûçÂêàÊñπÊ≥ïÂú®‰º†ÊÑüÂô®ÈÄÄÂåñÂíåÁéØÂ¢ÉÂπ≤Êâ∞Á≠âÂ§çÊùÇÂú∫ÊôØ‰∏≠Ë°®Áé∞‰∏ç‰Ω≥ÔºåÂØºËá¥ÊÄßËÉΩÊòæËëó‰∏ãÈôç„ÄÇ
2. Êú¨ÊñáÊèêÂá∫Ëá™ÈÄÇÂ∫îÈó®ÊéßËûçÂêàÔºàAG-FusionÔºâÊñπÊ≥ïÔºåÈÄöËøáËØÜÂà´ÂèØÈù†Ê®°ÂºèÊù•ÈÄâÊã©ÊÄßÊï¥ÂêàË∑®Ê®°ÊÄÅÁü•ËØÜÔºåÂ¢ûÂº∫Ê£ÄÊµãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ
3. Âú®KITTIÊï∞ÊçÆÈõÜ‰∏äÔºåÊú¨ÊñáÊñπÊ≥ïËææÂà∞93.92%ÁöÑÂáÜÁ°ÆÁéáÔºåËÄåÂú®E3DÊï∞ÊçÆÈõÜ‰∏äË∂ÖË∂äÂü∫Á∫ø24.88%ÔºåÊòæÁ§∫Âá∫ÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§öÊ®°ÊÄÅÁõ∏Êú∫-ÊøÄÂÖâÈõ∑ËææËûçÂêàÊäÄÊúØÂú®3DÁâ©‰ΩìÊ£ÄÊµã‰∏≠ÂæóÂà∞‰∫ÜÂπøÊ≥õÂ∫îÁî®ÔºåË°®Áé∞Âá∫ËâØÂ•ΩÁöÑÊÄßËÉΩ„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÊñπÊ≥ïÂú®‰º†ÊÑüÂô®ÈÄÄÂåñÊàñÁéØÂ¢ÉÂπ≤Êâ∞Á≠âÊåëÊàòÊÄßÂú∫ÊôØ‰∏≠ÊÄßËÉΩÊòæËëó‰∏ãÈôç„ÄÇ‰∏∫Ê≠§ÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑËá™ÈÄÇÂ∫îÈó®ÊéßËûçÂêàÔºàAG-FusionÔºâÊñπÊ≥ïÔºåÈÄöËøáËØÜÂà´ÂèØÈù†Ê®°ÂºèÈÄâÊã©ÊÄßÂú∞Êï¥ÂêàË∑®Ê®°ÊÄÅÁü•ËØÜÔºå‰ª•ÂÆûÁé∞Â§çÊùÇÂú∫ÊôØ‰∏≠ÁöÑÁ®≥ÂÅ•Ê£ÄÊµã„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåÊàë‰ª¨È¶ñÂÖàÂ∞ÜÊØèÁßçÊ®°ÊÄÅÁöÑÁâπÂæÅÊäïÂΩ±Âà∞Áªü‰∏ÄÁöÑÈ∏üÁû∞ËßÜÂõæÔºàBEVÔºâÁ©∫Èó¥ÔºåÂπ∂Âà©Áî®Âü∫‰∫éÁ™óÂè£ÁöÑÊ≥®ÊÑèÂäõÊú∫Âà∂Â¢ûÂº∫Ëøô‰∫õÁâπÂæÅ„ÄÇÈöèÂêéÔºåËÆæËÆ°‰∫Ü‰∏Ä‰∏™Âü∫‰∫éË∑®Ê®°ÊÄÅÊ≥®ÊÑèÂäõÁöÑËá™ÈÄÇÂ∫îÈó®ÊéßËûçÂêàÊ®°ÂùóÔºåÂ∞ÜËøô‰∫õÁâπÂæÅÊï¥Âêà‰∏∫ÂØπÂ§çÊùÇÁéØÂ¢ÉÂÖ∑ÊúâÈ≤ÅÊ£íÊÄßÁöÑÂèØÈù†BEVË°®Á§∫„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÊûÑÂª∫‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑÊï∞ÊçÆÈõÜExcavator3DÔºàE3DÔºâÔºå‰∏ìÊ≥®‰∫éÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÊåñÊéòÊú∫Êìç‰ΩúÂú∫ÊôØÔºå‰ª•Âü∫ÂáÜÊµãËØïÂ§çÊùÇÊù°‰ª∂‰∏ãÁöÑÊÄßËÉΩ„ÄÇÊàë‰ª¨ÁöÑÁÆóÊ≥ïÂú®Ê†áÂáÜKITTIÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫Ü93.92%ÁöÑÂáÜÁ°ÆÁéáÔºåÂπ∂Âú®ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑE3DÊï∞ÊçÆÈõÜ‰∏äÊòæËëóË∂ÖË∂äÂü∫Á∫ø24.88%ÔºåÂ±ïÁé∞Âá∫ÂØπÂ§çÊùÇÂ∑•‰∏öÂú∫ÊôØ‰∏≠‰∏çÂèØÈù†Ê®°ÊÄÅ‰ø°ÊÅØÁöÑ‰ºòË∂äÈ≤ÅÊ£íÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâÂ§öÊ®°ÊÄÅÁõ∏Êú∫-ÊøÄÂÖâÈõ∑ËææËûçÂêàÊäÄÊúØÂú®Â§çÊùÇÂú∫ÊôØ‰∏≠ÊÄßËÉΩ‰∏ãÈôçÁöÑÈóÆÈ¢òÔºåÂ∞§ÂÖ∂ÊòØÂú®‰º†ÊÑüÂô®ÈÄÄÂåñÂíåÁéØÂ¢ÉÂπ≤Êâ∞ÁöÑÊÉÖÂÜµ‰∏ã„ÄÇÁé∞ÊúâÊñπÊ≥ïÂæÄÂæÄÊó†Ê≥ïÊúâÊïàÂ§ÑÁêÜËøô‰∫õÊåëÊàòÔºåÂØºËá¥Ê£ÄÊµãÁªìÊûú‰∏çÂèØÈù†„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÊèêÂá∫ÁöÑAG-FusionÊñπÊ≥ïÈÄöËøáËá™ÈÄÇÂ∫îÂú∞ÈÄâÊã©ÂíåÊï¥ÂêàË∑®Ê®°ÊÄÅÁâπÂæÅÔºåËØÜÂà´Âá∫ÂèØÈù†ÁöÑÊ®°ÂºèÔºå‰ª•Â¢ûÂº∫Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑÊ£ÄÊµãËÉΩÂäõ„ÄÇËøôÁßçËÆæËÆ°Êó®Âú®ÊèêÈ´òÂØπ‰∏çÂèØÈù†Ê®°ÊÄÅ‰ø°ÊÅØÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨ÁâπÂæÅÊäïÂΩ±„ÄÅÁ™óÂè£Ê≥®ÊÑèÂäõÊú∫Âà∂ÂíåËá™ÈÄÇÂ∫îÈó®ÊéßËûçÂêàÊ®°Âùó„ÄÇÈ¶ñÂÖàÔºåÂ∞Ü‰∏çÂêåÊ®°ÊÄÅÁöÑÁâπÂæÅÊäïÂΩ±Âà∞Áªü‰∏ÄÁöÑBEVÁ©∫Èó¥ÔºåÁÑ∂ÂêéÈÄöËøáÁ™óÂè£Ê≥®ÊÑèÂäõÊú∫Âà∂Â¢ûÂº∫ÁâπÂæÅÔºåÊúÄÂêéÂà©Áî®Ëá™ÈÄÇÂ∫îÈó®ÊéßËûçÂêàÊ®°ÂùóÊï¥ÂêàËøô‰∫õÁâπÂæÅÔºåÂΩ¢ÊàêÂèØÈù†ÁöÑBEVË°®Á§∫„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éËá™ÈÄÇÂ∫îÈó®ÊéßËûçÂêàÊ®°ÂùóÁöÑËÆæËÆ°ÔºåÂÆÉÂü∫‰∫éË∑®Ê®°ÊÄÅÊ≥®ÊÑèÂäõÊú∫Âà∂ÔºåËÉΩÂ§üÊúâÊïàËØÜÂà´ÂíåÊï¥Âêà‰∏çÂêåÊ®°ÊÄÅÁöÑÁâπÂæÅÔºå‰ªéËÄåÊòæËëóÊèêÂçáÂú®Â§çÊùÇÂú∫ÊôØ‰∏≠ÁöÑÊ£ÄÊµãÊÄßËÉΩ„ÄÇËøô‰∏é‰º†ÁªüÊñπÊ≥ïÁöÑÂõ∫ÂÆöËûçÂêàÁ≠ñÁï•ÂΩ¢ÊàêÈ≤úÊòéÂØπÊØî„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÊäÄÊúØÁªÜËäÇ‰∏äÔºåÈááÁî®‰∫ÜÁ™óÂè£Ê≥®ÊÑèÂäõÊú∫Âà∂Êù•Â¢ûÂº∫ÁâπÂæÅË°®Á§∫ÔºåÈó®ÊéßËûçÂêàÊ®°ÂùóÂàôÈÄöËøáÂ≠¶‰π†‰∏çÂêåÊ®°ÊÄÅÁöÑÊùÉÈáçÊù•ÂÆûÁé∞Ëá™ÈÄÇÂ∫îËûçÂêà„ÄÇÊ≠§Â§ñÔºåÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°‰πüËÄÉËôë‰∫ÜÂ§öÊ®°ÊÄÅÁâπÂæÅÁöÑÂçèÂêå‰ΩúÁî®Ôºå‰ª•Ëøõ‰∏ÄÊ≠•ÊèêÂçáÊ£ÄÊµãÁ≤æÂ∫¶„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåAG-FusionÊñπÊ≥ïÂú®Ê†áÂáÜKITTIÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó93.92%ÁöÑÂáÜÁ°ÆÁéáÔºåËÄåÂú®ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑE3DÊï∞ÊçÆÈõÜ‰∏äË∂ÖË∂äÂü∫Á∫ø24.88%„ÄÇËøô‰∏ÄÊòæËëóÊèêÂçáË°®ÊòéËØ•ÊñπÊ≥ïÂú®Â§çÊùÇÂ∑•‰∏öÂú∫ÊôØ‰∏≠ÂØπ‰∏çÂèØÈù†Ê®°ÊÄÅ‰ø°ÊÅØÂÖ∑ÊúâÊõ¥Âº∫ÁöÑÈ≤ÅÊ£íÊÄßÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÊΩúÂäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Ëá™Âä®È©æÈ©∂„ÄÅÂ∑•‰∏öÊú∫Âô®‰∫∫ÂíåÊô∫ËÉΩÁõëÊéßÁ≠âÂú∫ÊôØÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§çÊùÇÁéØÂ¢É‰∏≠ÂØπÁâ©‰ΩìÊ£ÄÊµãÁöÑÈúÄÊ±ÇÊó•ÁõäÂ¢ûÂä†„ÄÇÈÄöËøáÊèêÈ´òÂ§öÊ®°ÊÄÅËûçÂêàÁöÑÈ≤ÅÊ£íÊÄßÔºåAG-FusionÊñπÊ≥ïËÉΩÂ§üÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÊòæËëóÊèêÂçáÁ≥ªÁªüÁöÑÂèØÈù†ÊÄßÂíåÂÆâÂÖ®ÊÄßÔºåÊú™Êù•ÂèØËÉΩÊé®Âä®Áõ∏ÂÖ≥ÊäÄÊúØÁöÑÂπøÊ≥õÂ∫îÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Multimodal camera-LiDAR fusion technology has found extensive application in 3D object detection, demonstrating encouraging performance. However, existing methods exhibit significant performance degradation in challenging scenarios characterized by sensor degradation or environmental disturbances. We propose a novel Adaptive Gated Fusion (AG-Fusion) approach that selectively integrates cross-modal knowledge by identifying reliable patterns for robust detection in complex scenes. Specifically, we first project features from each modality into a unified BEV space and enhance them using a window-based attention mechanism. Subsequently, an adaptive gated fusion module based on cross-modal attention is designed to integrate these features into reliable BEV representations robust to challenging environments. Furthermore, we construct a new dataset named Excavator3D (E3D) focusing on challenging excavator operation scenarios to benchmark performance in complex conditions. Our method not only achieves competitive performance on the standard KITTI dataset with 93.92% accuracy, but also significantly outperforms the baseline by 24.88% on the challenging E3D dataset, demonstrating superior robustness to unreliable modal information in complex industrial scenes.

