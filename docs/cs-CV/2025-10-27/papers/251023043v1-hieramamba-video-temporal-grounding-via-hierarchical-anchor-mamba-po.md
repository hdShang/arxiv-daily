---
layout: default
title: HieraMamba: Video Temporal Grounding via Hierarchical Anchor-Mamba Pooling
---

# HieraMamba: Video Temporal Grounding via Hierarchical Anchor-Mamba Pooling

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.23043" target="_blank" class="toolbar-btn">arXiv: 2510.23043v1</a>
    <a href="https://arxiv.org/pdf/2510.23043.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.23043v1" 
            onclick="toggleFavorite(this, '2510.23043v1', 'HieraMamba: Video Temporal Grounding via Hierarchical Anchor-Mamba Pooling')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Joungbin An, Kristen Grauman

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-27

**Â§áÊ≥®**: Project Page: https://vision.cs.utexas.edu/projects/hieramamba/

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**HieraMambaÔºöÈÄöËøáÂàÜÂ±ÇAnchor-MambaÊ±†ÂåñÂÆûÁé∞ËßÜÈ¢ëÊó∂Â∫èÂÆö‰Ωç**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±ÂÖ≠ÔºöËßÜÈ¢ëÊèêÂèñ‰∏éÂåπÈÖç (Video Extraction)** **ÊîØÊü±ÂÖ´ÔºöÁâ©ÁêÜÂä®Áîª (Physics-based Animation)**

**ÂÖ≥ÈîÆËØç**: `ËßÜÈ¢ëÊó∂Â∫èÂÆö‰Ωç` `ÈïøËßÜÈ¢ëÁêÜËß£` `MambaÊ®°Âûã` `ÂàÜÂ±ÇÊû∂ÊûÑ` `ÂØπÊØîÂ≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËßÜÈ¢ëÊó∂Â∫èÂÆö‰ΩçÊñπÊ≥ïÂú®Â§ÑÁêÜÈïøËßÜÈ¢ëÊó∂ÔºåÂ∏∏Âõ†ËøáÂ∫¶‰∏ãÈááÊ†∑ÊàñÂõ∫ÂÆöÁ™óÂè£ËÄåÊçüÂ§±Êó∂Èó¥Á≤æÂ∫¶„ÄÇ
2. HieraMambaÂà©Áî®ÂàÜÂ±ÇÊû∂ÊûÑÂíåAnchor-MambaÊ±†ÂåñÔºåÂú®‰∏çÂêåÂ∞∫Â∫¶‰∏ä‰øùÁïôÊó∂Èó¥ÁªìÊûÑÂíåËØ≠‰πâ‰ø°ÊÅØ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåHieraMambaÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äËææÂà∞SOTAÔºåÂÆûÁé∞‰∫ÜÊõ¥Á≤æÁ°ÆÁöÑÊó∂Â∫èÂÆö‰Ωç„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËßÜÈ¢ëÊó∂Â∫èÂÆö‰ΩçÊó®Âú®Êú™Ë£ÅÂâ™ËßÜÈ¢ë‰∏≠ÂÆö‰ΩçËá™ÁÑ∂ËØ≠Ë®ÄÊü•ËØ¢ÂØπÂ∫îÁöÑËµ∑ÂßãÂíåÁªìÊùüÊó∂Èó¥„ÄÇËØ•‰ªªÂä°ÈúÄË¶ÅÊçïÊçâÂÖ®Â±Ä‰∏ä‰∏ãÊñáÂíåÁ≤æÁªÜÁöÑÊó∂Èó¥ÁªÜËäÇ„ÄÇÂú®ÈïøËßÜÈ¢ë‰∏≠ÔºåËøô‰∏ÄÊåëÊàòÂ∞§‰∏∫Á™ÅÂá∫ÔºåÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏ÈÄöËøáËøáÂ∫¶‰∏ãÈááÊ†∑Êàñ‰æùËµñÂõ∫ÂÆöÁ™óÂè£Êù•Áâ∫Áâ≤Êó∂Èó¥‰øùÁúüÂ∫¶„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫ÜHieraMambaÔºå‰∏ÄÁßçÂàÜÂ±ÇÊû∂ÊûÑÔºåÂèØÂú®‰∏çÂêåÂ∞∫Â∫¶‰∏ä‰øùÁïôÊó∂Èó¥ÁªìÊûÑÂíåËØ≠‰πâ‰∏∞ÂØåÊÄß„ÄÇÂÖ∂Ê†∏ÂøÉÊòØAnchor-MambaÊ±†ÂåñÔºàAMPÔºâÂùóÔºåÂÆÉÂà©Áî®MambaÁöÑÈÄâÊã©ÊÄßÊâ´ÊèèÊù•ÁîüÊàêÁ¥ßÂáëÁöÑanchor tokenÔºå‰ª•ÊÄªÁªìÂ§ö‰∏™Á≤íÂ∫¶ÁöÑËßÜÈ¢ëÂÜÖÂÆπ„ÄÇ‰∏§‰∏™‰∫íË°•ÁöÑÁõÆÊ†áÔºåÂç≥anchorÊù°‰ª∂ÂØπÊØîÊçüÂ§±ÂíåÂàÜÊÆµÊ±†ÂåñÂØπÊØîÊçüÂ§±ÔºåÈºìÂä±anchor‰øùÁïôÂ±ÄÈÉ®ÁªÜËäÇÔºåÂêåÊó∂‰øùÊåÅÂÖ®Â±ÄÂå∫ÂàÜÊÄß„ÄÇHieraMambaÂú®Ego4D-NLQ„ÄÅMADÂíåTACoS‰∏äÂèñÂæó‰∫ÜÊñ∞ÁöÑstate-of-the-artÔºåÂ±ïÁ§∫‰∫ÜÂú®ÈïøÊú™Ë£ÅÂâ™ËßÜÈ¢ë‰∏≠Á≤æÁ°Æ„ÄÅÊó∂Èó¥‰øùÁúüÁöÑÂÆö‰Ωç„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËßÜÈ¢ëÊó∂Â∫èÂÆö‰ΩçÊó®Âú®ÁªôÂÆö‰∏Ä‰∏™Êú™Ë£ÅÂâ™ÁöÑÈïøËßÜÈ¢ëÂíå‰∏Ä‰∏™Ëá™ÁÑ∂ËØ≠Ë®ÄÊü•ËØ¢ÔºåÈ¢ÑÊµãËßÜÈ¢ë‰∏≠‰∏éÊü•ËØ¢Áõ∏ÂÖ≥ÁöÑÁâáÊÆµÁöÑËµ∑ÂßãÂíåÁªìÊùüÊó∂Èó¥„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®Â§ÑÁêÜÈïøËßÜÈ¢ëÊó∂Ôºå‰∏∫‰∫ÜÈôç‰ΩéËÆ°ÁÆóÂ§çÊùÇÂ∫¶ÔºåÈÄöÂ∏∏‰ºöËøõË°åËøáÂ∫¶‰∏ãÈááÊ†∑ÔºåÂØºËá¥Êó∂Èó¥ÂàÜËæ®ÁéáÈôç‰ΩéÔºåÊàñËÄÖ‰ΩøÁî®Âõ∫ÂÆöÂ§ßÂ∞èÁöÑÁ™óÂè£ÔºåÊó†Ê≥ïÈÄÇÂ∫î‰∏çÂêåÈïøÂ∫¶ÁöÑÊü•ËØ¢ÁâáÊÆµÔºå‰ªéËÄåÂΩ±ÂìçÂÆö‰ΩçÁ≤æÂ∫¶„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöHieraMambaÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®ÂàÜÂ±ÇÊû∂ÊûÑÂíåAnchor-MambaÊ±†ÂåñÔºàAMPÔºâÂùóÔºåÂú®‰∏çÂêåÂ∞∫Â∫¶‰∏äÊèêÂèñËßÜÈ¢ëÁâπÂæÅÔºå‰ªéËÄåÂêåÊó∂ÊçïÊçâÂÖ®Â±Ä‰∏ä‰∏ãÊñáÂíåÁ≤æÁªÜÁöÑÊó∂Èó¥ÁªÜËäÇ„ÄÇÈÄöËøáÈÄâÊã©ÊÄßÊâ´ÊèèÊú∫Âà∂ÔºåAMPÂùóËÉΩÂ§üÁîüÊàêÁ¥ßÂáëÁöÑanchor tokenÔºåËøô‰∫õtokenÊó¢ËÉΩ‰øùÁïôÂ±ÄÈÉ®ÁªÜËäÇÔºåÂèàËÉΩÂÖ∑Â§áÂÖ®Â±ÄÂå∫ÂàÜÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöHieraMambaÁöÑÊï¥‰ΩìÊû∂ÊûÑÊòØ‰∏Ä‰∏™ÂàÜÂ±ÇÁªìÊûÑÔºåÂåÖÂê´Â§ö‰∏™Anchor-MambaÊ±†ÂåñÔºàAMPÔºâÂùó„ÄÇÊØè‰∏™AMPÂùóÊé•Êî∂‰∏ä‰∏ÄÂ±ÇÁöÑÁâπÂæÅ‰Ωú‰∏∫ËæìÂÖ•ÔºåÂπ∂ËæìÂá∫Êõ¥È´òÁ∫ßÂà´ÁöÑÁâπÂæÅË°®Á§∫„ÄÇAMPÂùóÁöÑÊ†∏ÂøÉÊòØMambaÊ®°ÂûãÔºåÂÆÉÈÄöËøáÈÄâÊã©ÊÄßÊâ´ÊèèÊú∫Âà∂ÔºåÂØπËæìÂÖ•ÁâπÂæÅËøõË°åÂ§ÑÁêÜÔºåÁîüÊàêanchor token„ÄÇËøô‰∫õanchor tokenË¢´Áî®‰∫éÂêéÁª≠ÁöÑÂØπÊØîÂ≠¶‰π†Ôºå‰ª•ÊèêÈ´òÊ®°ÂûãÁöÑÂÆö‰ΩçÁ≤æÂ∫¶„ÄÇÊï¥‰∏™ÊµÅÁ®ãÂåÖÊã¨ËßÜÈ¢ëÁâπÂæÅÊèêÂèñ„ÄÅÂàÜÂ±ÇÁâπÂæÅÁºñÁ†ÅÂíåÊó∂Â∫èËæπÁïåÈ¢ÑÊµã‰∏â‰∏™Èò∂ÊÆµ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöHieraMambaÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éAnchor-MambaÊ±†ÂåñÔºàAMPÔºâÂùóÁöÑËÆæËÆ°„ÄÇAMPÂùóÂà©Áî®MambaÁöÑÈÄâÊã©ÊÄßÊâ´ÊèèÊú∫Âà∂ÔºåËÉΩÂ§üÊúâÊïàÂú∞Â§ÑÁêÜÈïøÂ∫èÂàóÊï∞ÊçÆÔºåÂπ∂ÁîüÊàêÂÖ∑ÊúâÂÖ®Â±Ä‰∏ä‰∏ãÊñá‰ø°ÊÅØÁöÑanchor token„ÄÇÊ≠§Â§ñÔºåHieraMambaËøòÊèêÂá∫‰∫ÜanchorÊù°‰ª∂ÂØπÊØîÊçüÂ§±ÂíåÂàÜÊÆµÊ±†ÂåñÂØπÊØîÊçüÂ§±ÔºåËøô‰∏§ÁßçÊçüÂ§±ÂáΩÊï∞ËÉΩÂ§üÊúâÊïàÂú∞ÊèêÈ´òanchor tokenÁöÑÂå∫ÂàÜÊÄßÂíåÂÆö‰ΩçÁ≤æÂ∫¶„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåHieraMambaËÉΩÂ§üÂú®‰øùÊåÅÊó∂Èó¥ÂàÜËæ®ÁéáÁöÑÂêåÊó∂ÔºåÊúâÊïàÂú∞ÊçïÊçâÂÖ®Â±Ä‰∏ä‰∏ãÊñá‰ø°ÊÅØ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöAnchor-MambaÊ±†ÂåñÔºàAMPÔºâÂùóÂåÖÂê´MambaÂ±ÇÂíåÊ±†ÂåñÂ±Ç„ÄÇMambaÂ±ÇË¥üË¥£ÂØπËæìÂÖ•ÁâπÂæÅËøõË°åÈÄâÊã©ÊÄßÊâ´ÊèèÔºåÁîüÊàêanchor token„ÄÇÊ±†ÂåñÂ±ÇË¥üË¥£ÂØπanchor tokenËøõË°åÈôçÁª¥Ôºå‰ª•ÂáèÂ∞ëËÆ°ÁÆóÂ§çÊùÇÂ∫¶„ÄÇAnchorÊù°‰ª∂ÂØπÊØîÊçüÂ§±ÈÄöËøáÂØπÊØîanchor tokenÂíåÂØπÂ∫îÁöÑËßÜÈ¢ëÁâáÊÆµÁâπÂæÅÔºåÊù•ÊèêÈ´òanchor tokenÁöÑÂå∫ÂàÜÊÄß„ÄÇÂàÜÊÆµÊ±†ÂåñÂØπÊØîÊçüÂ§±ÈÄöËøáÂØπÊØî‰∏çÂêåËßÜÈ¢ëÁâáÊÆµÁöÑÁâπÂæÅÔºåÊù•ÊèêÈ´òÊ®°ÂûãÁöÑÂÆö‰ΩçÁ≤æÂ∫¶„ÄÇÂÖ∑‰ΩìÂèÇÊï∞ËÆæÁΩÆÂåÖÊã¨MambaÂ±ÇÁöÑÂ±ÇÊï∞„ÄÅÈöêËóèÂ±ÇÁª¥Â∫¶„ÄÅÊ±†ÂåñÂ±ÇÁöÑÊ±†ÂåñÂ§ßÂ∞èÁ≠â„ÄÇÊçüÂ§±ÂáΩÊï∞ÁöÑÊùÉÈáç‰πüÈúÄË¶ÅÊ†πÊçÆÂÖ∑‰Ωì‰ªªÂä°ËøõË°åË∞ÉÊï¥„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

HieraMambaÂú®Ego4D-NLQ„ÄÅMADÂíåTACoS‰∏â‰∏™ËßÜÈ¢ëÊó∂Â∫èÂÆö‰ΩçÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜÊñ∞ÁöÑstate-of-the-art„ÄÇÂú®Ego4D-NLQÊï∞ÊçÆÈõÜ‰∏äÔºåHieraMambaÁöÑÊÄßËÉΩÊòæËëó‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåËØÅÊòé‰∫ÜÂÖ∂Âú®ÈïøËßÜÈ¢ëÊó∂Â∫èÂÆö‰ΩçÊñπÈù¢ÁöÑ‰ºòÂäø„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåHieraMambaËÉΩÂ§üÊúâÊïàÂú∞ÊçïÊçâÂÖ®Â±Ä‰∏ä‰∏ãÊñáÂíåÁ≤æÁªÜÁöÑÊó∂Èó¥ÁªÜËäÇÔºå‰ªéËÄåÂÆûÁé∞Êõ¥Á≤æÁ°ÆÁöÑÂÆö‰Ωç„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

HieraMambaÂú®ËßÜÈ¢ëÂÜÖÂÆπÁêÜËß£„ÄÅËßÜÈ¢ëÊ£ÄÁ¥¢„ÄÅÊô∫ËÉΩÁõëÊéßÁ≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇÂÆÉÂèØ‰ª•Áî®‰∫éÂú®Êµ∑ÈáèËßÜÈ¢ëÊï∞ÊçÆ‰∏≠Âø´ÈÄüÂÆö‰ΩçÁî®Êà∑ÊÑüÂÖ¥Ë∂£ÁöÑÁâáÊÆµÔºåÊèêÈ´òËßÜÈ¢ëÊ£ÄÁ¥¢ÁöÑÊïàÁéáÂíåÂáÜÁ°ÆÊÄß„ÄÇÊ≠§Â§ñÔºåHieraMambaËøòÂèØ‰ª•Â∫îÁî®‰∫éÊô∫ËÉΩÁõëÊéßÁ≥ªÁªü‰∏≠ÔºåÁî®‰∫éÊ£ÄÊµãÂºÇÂ∏∏‰∫ã‰ª∂ÂíåË°å‰∏∫ÔºåÊèêÈ´òÂÆâÂÖ®Èò≤ËåÉËÉΩÂäõ„ÄÇÊú™Êù•ÔºåËØ•ÊäÄÊúØÊúâÊúõÂú®Êõ¥Â§öËßÜÈ¢ëÁõ∏ÂÖ≥ÁöÑÂ∫îÁî®‰∏≠ÂèëÊå•ÈáçË¶Å‰ΩúÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Video temporal grounding, the task of localizing the start and end times of a natural language query in untrimmed video, requires capturing both global context and fine-grained temporal detail. This challenge is particularly pronounced in long videos, where existing methods often compromise temporal fidelity by over-downsampling or relying on fixed windows. We present HieraMamba, a hierarchical architecture that preserves temporal structure and semantic richness across scales. At its core are Anchor-MambaPooling (AMP) blocks, which utilize Mamba's selective scanning to produce compact anchor tokens that summarize video content at multiple granularities. Two complementary objectives, anchor-conditioned and segment-pooled contrastive losses, encourage anchors to retain local detail while remaining globally discriminative. HieraMamba sets a new state-of-the-art on Ego4D-NLQ, MAD, and TACoS, demonstrating precise, temporally faithful localization in long, untrimmed videos.

