---
layout: default
title: Video-Thinker: Sparking "Thinking with Videos" via Reinforcement Learning
---

# Video-Thinker: Sparking "Thinking with Videos" via Reinforcement Learning

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.23473" target="_blank" class="toolbar-btn">arXiv: 2510.23473v1</a>
    <a href="https://arxiv.org/pdf/2510.23473.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.23473v1" 
            onclick="toggleFavorite(this, '2510.23473v1', 'Video-Thinker: Sparking \"Thinking with Videos\" via Reinforcement Learning')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Shijian Wang, Jiarui Jin, Xingjian Wang, Linxin Song, Runhao Fu, Hecheng Wang, Zongyuan Ge, Yuan Lu, Xuelian Cheng

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-27

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Video-ThinkerÔºåÈÄöËøáÂº∫ÂåñÂ≠¶‰π†ËµãËÉΩMLLMËøõË°åËßÜÈ¢ëÊé®ÁêÜ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËßÜÈ¢ëÊé®ÁêÜ` `Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã` `Âº∫ÂåñÂ≠¶‰π†` `ÊÄùÁª¥Èìæ` `Ëá™‰∏ªÊé®ÁêÜ` `ËßÜÈ¢ëÁêÜËß£` `ÂÆö‰Ωç` `ÊèèËø∞`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÁº∫‰πèÂä®ÊÄÅÊé®ÁêÜËÉΩÂäõÔºåÊó†Ê≥ïÊúâÊïàÂà©Áî®ËßÜÈ¢ë‰ø°ÊÅØËøõË°åÂ§çÊùÇÊé®ÁêÜ„ÄÇ
2. Video-ThinkerÂà©Áî®MLLMËá™Ë∫´ËÉΩÂäõÔºåÈÄöËøáÂº∫ÂåñÂ≠¶‰π†Ëá™‰∏ªÁîüÊàêÊé®ÁêÜÁ∫øÁ¥¢ÔºåÊó†ÈúÄÂ§ñÈÉ®Â∑•ÂÖ∑„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåVideo-ThinkerÂú®Â§ö‰∏™ËßÜÈ¢ëÊé®ÁêÜÂü∫ÂáÜÊµãËØï‰∏≠ÊòæËëó‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåËææÂà∞SOTA„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫Video-ThinkerÔºåÊó®Âú®ÈÄöËøáÂº∫ÂåñÂ≠¶‰π†ËµãËÉΩÂ§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMÔºâËøõË°åËßÜÈ¢ëÊé®ÁêÜÔºå‰ΩøÂÖ∂ËÉΩÂ§üËá™‰∏ªÂà©Áî®ÂÖ∂ÂÜÖÂú®ÁöÑ‚ÄúÂÆö‰Ωç‚ÄùÂíå‚ÄúÊèèËø∞‚ÄùËÉΩÂäõÔºåÂú®Êé®ÁêÜËøáÁ®ã‰∏≠ÁîüÊàêÊé®ÁêÜÁ∫øÁ¥¢„ÄÇ‰∏∫‰∫ÜÊøÄÂèëËøôÁßçËÉΩÂäõÔºåÊàë‰ª¨ÊûÑÂª∫‰∫Ü‰∏Ä‰∏™Âêç‰∏∫Video-Thinker-10KÁöÑÊï∞ÊçÆÈõÜÔºåËØ•Êï∞ÊçÆÈõÜÂåÖÂê´Âú®ÊÄùÁª¥ÈìæÊé®ÁêÜÂ∫èÂàó‰∏≠Ëá™‰∏ªÂ∑•ÂÖ∑‰ΩøÁî®ÁöÑÁ§∫‰æã„ÄÇÊàë‰ª¨ÁöÑËÆ≠ÁªÉÁ≠ñÁï•È¶ñÂÖà‰ΩøÁî®ÁõëÁù£ÂæÆË∞ÉÔºàSFTÔºâÊù•Â≠¶‰π†Êé®ÁêÜÊ†ºÂºèÔºåÁÑ∂Âêé‰ΩøÁî®ÁªÑÁõ∏ÂØπÁ≠ñÁï•‰ºòÂåñÔºàGRPOÔºâÊù•Âä†Âº∫ËøôÁßçÊé®ÁêÜËÉΩÂäõ„ÄÇÈÄöËøáËøôÁßçÊñπÊ≥ïÔºåVideo-Thinker‰ΩøMLLMËÉΩÂ§üËá™‰∏ªÂú∞ËøõË°åËßÜÈ¢ëÊé®ÁêÜÁöÑÂÆö‰ΩçÂíåÊèèËø∞‰ªªÂä°ÔºåËÄåÊó†ÈúÄÊûÑÂª∫ÂíåË∞ÉÁî®Â§ñÈÉ®Â∑•ÂÖ∑„ÄÇÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåVideo-ThinkerÂú®È¢ÜÂüüÂÜÖ‰ªªÂä°ÂíåÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÈ¢ÜÂüüÂ§ñËßÜÈ¢ëÊé®ÁêÜÂü∫ÂáÜÔºàÂåÖÊã¨Video-Holmes„ÄÅCG-Bench-ReasoningÂíåVRBenchÔºâ‰∏äÈÉΩÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇÊàë‰ª¨ÁöÑVideo-Thinker-7BÊòæËëó‰ºò‰∫éÁé∞ÊúâÁöÑÂü∫Á∫øÊ®°ÂûãÔºàÂ¶ÇVideo-R1ÔºâÔºåÂπ∂Âú®7BÂ§ßÂ∞èÁöÑMLLM‰∏≠Âª∫Á´ã‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÁöÑÂ§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂú®ÂõæÂÉèÊé®ÁêÜÊñπÈù¢ÂèñÂæó‰∫ÜÊòæËëóËøõÂ±ïÔºå‰ΩÜÁº∫‰πèÂØπËßÜÈ¢ëËøõË°åÂä®ÊÄÅÊé®ÁêÜÁöÑËÉΩÂäõ„ÄÇÂÆÉ‰ª¨Èöæ‰ª•ÊúâÊïàÂú∞Âà©Áî®ËßÜÈ¢ë‰∏≠ÁöÑÊó∂Â∫è‰ø°ÊÅØÂíåÂä®ÊÄÅÂèòÂåñÔºå‰ªéËÄåÈôêÂà∂‰∫ÜÂÖ∂Âú®Â§çÊùÇËßÜÈ¢ëÁêÜËß£‰ªªÂä°‰∏≠ÁöÑÂ∫îÁî®„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏‰æùËµñ‰∫éÈ¢ÑÂÆö‰πâÁöÑÂ§ñÈÉ®Â∑•ÂÖ∑ÊàñÊ®°ÂùóÔºåÁº∫‰πèËá™‰∏ªÊÄßÂíåÁÅµÊ¥ªÊÄß„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöVideo-ThinkerÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØËµã‰∫àMLLMËá™‰∏ª‚ÄúÊÄùËÄÉ‚ÄùËßÜÈ¢ëÁöÑËÉΩÂäõÔºå‰ΩøÂÖ∂ËÉΩÂ§üÂÉè‰∫∫Á±ª‰∏ÄÊ†∑ÔºåÈÄöËøáËßÇÂØüÂíåÂàÜÊûêËßÜÈ¢ëÂÜÖÂÆπÔºåÈÄêÊ≠•ÁîüÊàêÊé®ÁêÜÁ∫øÁ¥¢ÔºåÊúÄÁªàÂÆåÊàêÊé®ÁêÜ‰ªªÂä°„ÄÇËøôÁßçÊñπÊ≥ïÈÅøÂÖç‰∫ÜÂØπÂ§ñÈÉ®Â∑•ÂÖ∑ÁöÑ‰æùËµñÔºåÂÖÖÂàÜÂà©Áî®‰∫ÜMLLMËá™Ë∫´ÊâÄÂÖ∑Â§áÁöÑ‚ÄúÂÆö‰Ωç‚ÄùÂíå‚ÄúÊèèËø∞‚ÄùËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöVideo-ThinkerÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÈò∂ÊÆµÔºöÈ¶ñÂÖàÔºå‰ΩøÁî®ÁõëÁù£ÂæÆË∞ÉÔºàSFTÔºâÂú®Video-Thinker-10KÊï∞ÊçÆÈõÜ‰∏äËÆ≠ÁªÉMLLMÔºå‰ΩøÂÖ∂Â≠¶‰π†ËßÜÈ¢ëÊé®ÁêÜÁöÑÂü∫Êú¨Ê†ºÂºèÂíåÊµÅÁ®ã„ÄÇÁÑ∂ÂêéÔºå‰ΩøÁî®ÁªÑÁõ∏ÂØπÁ≠ñÁï•‰ºòÂåñÔºàGRPOÔºâËøõ‰∏ÄÊ≠•ÊèêÂçáMLLMÁöÑÊé®ÁêÜËÉΩÂäõÔºå‰ΩøÂÖ∂ËÉΩÂ§üÊõ¥Â•ΩÂú∞Âà©Áî®ËßÜÈ¢ë‰ø°ÊÅØÁîüÊàêÊúâÊïàÁöÑÊé®ÁêÜÁ∫øÁ¥¢„ÄÇÂú®Êé®ÁêÜËøáÁ®ã‰∏≠ÔºåMLLMËá™‰∏ªÂú∞ËøõË°åÂÆö‰ΩçÂíåÊèèËø∞‰ªªÂä°ÔºåÁîüÊàê‰∏≠Èó¥Êé®ÁêÜÊ≠•È™§ÔºåÊúÄÁªàÂæóÂà∞Êé®ÁêÜÁªìÊûú„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöVideo-ThinkerÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÂÖ∂Ëá™‰∏ªÊé®ÁêÜÁöÑÊ®°Âºè„ÄÇ‰∏é‰º†ÁªüÊñπÊ≥ï‰∏çÂêåÔºåVideo-Thinker‰∏ç‰æùËµñ‰∫éÈ¢ÑÂÆö‰πâÁöÑÂ§ñÈÉ®Â∑•ÂÖ∑ÊàñÊ®°ÂùóÔºåËÄåÊòØÈÄöËøáÂº∫ÂåñÂ≠¶‰π†Ëµã‰∫àMLLMËá™‰∏ªÁîüÊàêÊé®ÁêÜÁ∫øÁ¥¢ÁöÑËÉΩÂäõ„ÄÇËøôÁßçÊñπÊ≥ï‰ΩøÂæóMLLMËÉΩÂ§üÊõ¥Âä†ÁÅµÊ¥ªÂú∞ÈÄÇÂ∫î‰∏çÂêåÁöÑËßÜÈ¢ëÊé®ÁêÜ‰ªªÂä°ÔºåÂπ∂ËÉΩÂ§üÊõ¥Â•ΩÂú∞Âà©Áî®ËßÜÈ¢ë‰∏≠ÁöÑÂä®ÊÄÅ‰ø°ÊÅØ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöVideo-ThinkerÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) Video-Thinker-10KÊï∞ÊçÆÈõÜÔºåËØ•Êï∞ÊçÆÈõÜÂåÖÂê´Âú®ÊÄùÁª¥ÈìæÊé®ÁêÜÂ∫èÂàó‰∏≠Ëá™‰∏ªÂ∑•ÂÖ∑‰ΩøÁî®ÁöÑÁ§∫‰æãÔºåÁî®‰∫éËÆ≠ÁªÉMLLMÁöÑÊé®ÁêÜËÉΩÂäõÔºõ2) ÁªÑÁõ∏ÂØπÁ≠ñÁï•‰ºòÂåñÔºàGRPOÔºâÔºåÁî®‰∫éËøõ‰∏ÄÊ≠•ÊèêÂçáMLLMÁöÑÊé®ÁêÜËÉΩÂäõÔºå‰ΩøÂÖ∂ËÉΩÂ§üÊõ¥Â•ΩÂú∞Âà©Áî®ËßÜÈ¢ë‰ø°ÊÅØÁîüÊàêÊúâÊïàÁöÑÊé®ÁêÜÁ∫øÁ¥¢Ôºõ3) Ëá™‰∏ªÂÆö‰ΩçÂíåÊèèËø∞‰ªªÂä°ÔºåMLLMÂú®Êé®ÁêÜËøáÁ®ã‰∏≠Ëá™‰∏ªÂú∞ËøõË°åÂÆö‰ΩçÂíåÊèèËø∞‰ªªÂä°ÔºåÁîüÊàê‰∏≠Èó¥Êé®ÁêÜÊ≠•È™§ÔºåÊúÄÁªàÂæóÂà∞Êé®ÁêÜÁªìÊûú„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Video-Thinker-7BÂú®Â§ö‰∏™ËßÜÈ¢ëÊé®ÁêÜÂü∫ÂáÜÊµãËØï‰∏≠ÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºå‰æãÂ¶ÇÂú®Video-Holmes‰∏äÔºåVideo-Thinker-7BÁöÑÊÄßËÉΩÊòæËëó‰ºò‰∫éÁé∞ÊúâÁöÑÂü∫Á∫øÊ®°ÂûãÔºàÂ¶ÇVideo-R1ÔºâÔºåÂπ∂Âú®7BÂ§ßÂ∞èÁöÑMLLM‰∏≠Âª∫Á´ã‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩ„ÄÇÂú®CG-Bench-ReasoningÂíåVRBenchÁ≠âÂÖ∂‰ªñÂü∫ÂáÜÊµãËØï‰∏≠ÔºåVideo-Thinker‰πüË°®Áé∞Âá∫‰∫Ü‰ºòÂºÇÁöÑÊÄßËÉΩ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

Video-ThinkerÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºå‰æãÂ¶ÇÊô∫ËÉΩÁõëÊéß„ÄÅËßÜÈ¢ëÂÜÖÂÆπÂàÜÊûê„ÄÅËá™Âä®È©æÈ©∂„ÄÅÊú∫Âô®‰∫∫ÂØºËà™Á≠âÈ¢ÜÂüü„ÄÇÂÆÉÂèØ‰ª•Áî®‰∫éËØÜÂà´ÂºÇÂ∏∏Ë°å‰∏∫„ÄÅÁêÜËß£ËßÜÈ¢ëÂÜÖÂÆπ„ÄÅËæÖÂä©È©æÈ©∂ÂÜ≥Á≠ñ„ÄÅ‰ª•ÂèäÊåáÂØºÊú∫Âô®‰∫∫ÂÆåÊàêÂ§çÊùÇ‰ªªÂä°„ÄÇÈÄöËøáËµã‰∫àÊú∫Âô®Ëá™‰∏ªÊÄùËÄÉËßÜÈ¢ëÁöÑËÉΩÂäõÔºåVideo-ThinkerÊúâÊúõÊé®Âä®‰∫∫Â∑•Êô∫ËÉΩÊäÄÊúØÂú®ËßÜÈ¢ëÁêÜËß£È¢ÜÂüüÁöÑËøõ‰∏ÄÊ≠•ÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Recent advances in image reasoning methods, particularly "Thinking with Images", have demonstrated remarkable success in Multimodal Large Language Models (MLLMs); however, this dynamic reasoning paradigm has not yet been extended to video reasoning tasks. In this paper, we propose Video-Thinker, which empowers MLLMs to think with videos by autonomously leveraging their intrinsic "grounding" and "captioning" capabilities to generate reasoning clues throughout the inference process. To spark this capability, we construct Video-Thinker-10K, a curated dataset featuring autonomous tool usage within chain-of-thought reasoning sequences. Our training strategy begins with Supervised Fine-Tuning (SFT) to learn the reasoning format, followed by Group Relative Policy Optimization (GRPO) to strengthen this reasoning capability. Through this approach, Video-Thinker enables MLLMs to autonomously navigate grounding and captioning tasks for video reasoning, eliminating the need for constructing and calling external tools. Extensive experiments demonstrate that Video-Thinker achieves significant performance gains on both in-domain tasks and challenging out-of-domain video reasoning benchmarks, including Video-Holmes, CG-Bench-Reasoning, and VRBench. Our Video-Thinker-7B substantially outperforms existing baselines such as Video-R1 and establishes state-of-the-art performance among 7B-sized MLLMs.

