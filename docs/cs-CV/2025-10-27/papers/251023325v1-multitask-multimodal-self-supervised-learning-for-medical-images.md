---
layout: default
title: Multitask Multimodal Self-Supervised Learning for Medical Images
---

# Multitask Multimodal Self-Supervised Learning for Medical Images

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.23325" target="_blank" class="toolbar-btn">arXiv: 2510.23325v1</a>
    <a href="https://arxiv.org/pdf/2510.23325.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.23325v1" 
            onclick="toggleFavorite(this, '2510.23325v1', 'Multitask Multimodal Self-Supervised Learning for Medical Images')" title="æ”¶è—">
      â˜† æ”¶è—
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="å¤åˆ¶é“¾æ¥">
      ğŸ”— åˆ†äº«
    </button>
  </div>
</div>


**ä½œè€…**: Cristian Simionescu

**åˆ†ç±»**: cs.CV, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-10-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMedformerï¼Œç”¨äºåŒ»å­¦å›¾åƒå¤šä»»åŠ¡å¤šæ¨¡æ€è‡ªç›‘ç£å­¦ä¹ ï¼Œå‡å°‘å¯¹æ ‡æ³¨æ•°æ®çš„ä¾èµ–ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åŒ»å­¦å›¾åƒåˆ†æ` `è‡ªç›‘ç£å­¦ä¹ ` `å¤šä»»åŠ¡å­¦ä¹ ` `é¢†åŸŸè‡ªé€‚åº”` `Transformer` `MedMNIST`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. åŒ»å­¦å›¾åƒåˆ†æä¸¥é‡ä¾èµ–å¤§é‡æ ‡æ³¨æ•°æ®ï¼Œä½†è·å–è¿™äº›æ•°æ®æˆæœ¬é«˜æ˜‚ä¸”å—éšç§é™åˆ¶ã€‚
2. æå‡ºMedformeræ¨¡å‹ï¼Œé€šè¿‡å¤šä»»åŠ¡å­¦ä¹ å’Œé¢†åŸŸè‡ªé€‚åº”ï¼Œå®ç°åŒ»å­¦å›¾åƒçš„è‡ªç›‘ç£é¢„è®­ç»ƒã€‚
3. é€šè¿‡MedMNISTæ•°æ®é›†éªŒè¯ï¼Œè¯æ˜Medformerèƒ½æœ‰æ•ˆå­¦ä¹ é€šç”¨ç‰¹å¾ï¼Œé€‚ç”¨äºå¤šç§ä¸‹æ¸¸ä»»åŠ¡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶æ—¨åœ¨è§£å†³åŒ»å­¦å›¾åƒåˆ†æä¸­å¯¹å¤§é‡æ ‡æ³¨æ•°æ®çš„ä¾èµ–é—®é¢˜ï¼Œè¿™äº›æ•°æ®å¾€å¾€å› ä¸“å®¶æ ‡æ³¨éœ€æ±‚ã€éšç§å’Œæ³•å¾‹é—®é¢˜è€Œå—é™ã€‚é€šè¿‡å¼€å‘è‡ªç›‘ç£å­¦ä¹ æŠ€æœ¯å’Œé¢†åŸŸè‡ªé€‚åº”æ–¹æ³•ï¼Œæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•ï¼Œæ—¨åœ¨æé«˜æ·±åº¦å­¦ä¹ åœ¨åŒ»å­¦æˆåƒä¸­çš„æ•ˆç”¨å’Œæ•ˆç‡ã€‚æ ¸å¿ƒæ˜¯Medformerçš„å¼€å‘ï¼Œè¿™æ˜¯ä¸€ç§åˆ›æ–°çš„ç¥ç»ç½‘ç»œæ¶æ„ï¼Œä¸“ä¸ºå¤šä»»åŠ¡å­¦ä¹ å’Œæ·±åº¦é¢†åŸŸè‡ªé€‚åº”è€Œè®¾è®¡ã€‚è¯¥æ¨¡å‹æ“…é•¿åœ¨ä¸åŒçš„åŒ»å­¦å›¾åƒæ•°æ®é›†ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œå¤„ç†ä¸åŒçš„å¤§å°å’Œæ¨¡æ€ï¼Œå¹¶é…å¤‡äº†åŠ¨æ€è¾“å…¥-è¾“å‡ºè‡ªé€‚åº”æœºåˆ¶ã€‚è¿™ä½¿å¾—èƒ½å¤Ÿé«˜æ•ˆåœ°å¤„ç†å’Œé›†æˆå„ç§åŒ»å­¦å›¾åƒç±»å‹ï¼Œä»2D Xå°„çº¿åˆ°å¤æ‚çš„3D MRIï¼Œä»è€Œå‡è½»å¯¹å¤§å‹æ ‡æ³¨æ•°æ®é›†çš„ä¾èµ–ã€‚æ­¤å¤–ï¼Œæœ¬ç ”ç©¶è¿˜æ¢è®¨äº†åŒ»å­¦æˆåƒä¸­è‡ªç›‘ç£å­¦ä¹ çš„ç°çŠ¶ï¼Œå¹¶å¼•å…¥äº†æ–°çš„pretextä»»åŠ¡ï¼Œèƒ½å¤Ÿä»æ— æ ‡ç­¾æ•°æ®ä¸­æå–æœ‰æ„ä¹‰çš„ä¿¡æ¯ï¼Œæ˜¾è‘—æé«˜æ¨¡å‹çš„å¯è§£é‡Šèƒ½åŠ›ã€‚é€šè¿‡åŒ…æ‹¬MedMNISTæ•°æ®é›†åœ¨å†…çš„ä¸¥æ ¼å®éªŒéªŒè¯äº†è¯¥æ–¹æ³•ï¼Œè¯æ˜äº†æ¨¡å‹åœ¨å­¦ä¹ é€‚ç”¨äºå„ç§ä¸‹æ¸¸ä»»åŠ¡çš„é€šç”¨ç‰¹å¾æ–¹é¢çš„èƒ½åŠ›ã€‚æ€»ä¹‹ï¼Œæœ¬ç ”ç©¶é€šè¿‡æä¾›ä¸€ä¸ªå¯æ‰©å±•ã€é€‚åº”æ€§å¼ºçš„æ¡†æ¶æ¥å‡å°‘å¯¹æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œä»è€Œæ¨åŠ¨äº†åŒ»å­¦å›¾åƒåˆ†æçš„å‘å±•ï¼Œä¸ºåŒ»ç–—ä¿å¥é¢†åŸŸæ›´å‡†ç¡®ã€æ›´é«˜æ•ˆçš„è¯Šæ–­å·¥å…·é“ºå¹³äº†é“è·¯ï¼Œæ ‡å¿—ç€æ·±åº¦å­¦ä¹ åœ¨åŒ»å­¦æˆåƒåº”ç”¨æ–¹é¢è¿ˆå‡ºäº†ä¸€å¤§æ­¥ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šåŒ»å­¦å›¾åƒåˆ†æé¢†åŸŸé¢ä¸´ç€å¯¹å¤§é‡æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œè€ŒåŒ»å­¦å›¾åƒçš„æ ‡æ³¨éœ€è¦ä¸“ä¸šçŸ¥è¯†ï¼Œæˆæœ¬é«˜æ˜‚ï¼Œä¸”æ¶‰åŠæ‚£è€…éšç§ï¼Œéš¾ä»¥è·å–ã€‚ç°æœ‰æ–¹æ³•åœ¨å°æ ·æœ¬æˆ–æ— æ ‡ç­¾æ•°æ®ä¸‹çš„è¡¨ç°ä¸ä½³ï¼Œé™åˆ¶äº†æ·±åº¦å­¦ä¹ åœ¨åŒ»å­¦å›¾åƒåˆ†æä¸­çš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬ç ”ç©¶çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è‡ªç›‘ç£å­¦ä¹ ï¼Œé€šè¿‡è®¾è®¡åˆé€‚çš„pretextä»»åŠ¡ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿä»å¤§é‡çš„æ— æ ‡ç­¾åŒ»å­¦å›¾åƒæ•°æ®ä¸­å­¦ä¹ åˆ°æœ‰ç”¨çš„ç‰¹å¾è¡¨ç¤ºã€‚ç„¶åï¼Œå°†è¿™äº›å­¦ä¹ åˆ°çš„ç‰¹å¾è¿ç§»åˆ°ä¸‹æ¸¸ä»»åŠ¡ä¸­ï¼Œä»è€Œå‡å°‘å¯¹æ ‡æ³¨æ•°æ®çš„éœ€æ±‚ã€‚åŒæ—¶ï¼Œé€šè¿‡å¤šä»»åŠ¡å­¦ä¹ å’Œé¢†åŸŸè‡ªé€‚åº”ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿå¤„ç†ä¸åŒæ¨¡æ€å’Œä¸åŒæ¥æºçš„åŒ»å­¦å›¾åƒã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMedformerçš„æ•´ä½“æ¶æ„æ˜¯ä¸€ä¸ªåŸºäºTransformerçš„ç¼–ç å™¨-è§£ç å™¨ç»“æ„ã€‚ç¼–ç å™¨è´Ÿè´£æå–åŒ»å­¦å›¾åƒçš„ç‰¹å¾è¡¨ç¤ºï¼Œè§£ç å™¨è´Ÿè´£å®Œæˆå„ç§ä¸‹æ¸¸ä»»åŠ¡ï¼Œå¦‚å›¾åƒåˆ†ç±»ã€åˆ†å‰²ç­‰ã€‚æ¨¡å‹åŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) è¾“å…¥é€‚é…æ¨¡å—ï¼šç”¨äºå¤„ç†ä¸åŒå¤§å°å’Œæ¨¡æ€çš„åŒ»å­¦å›¾åƒï¼›2) Transformerç¼–ç å™¨ï¼šç”¨äºæå–å›¾åƒç‰¹å¾ï¼›3) å¤šä»»åŠ¡å­¦ä¹ æ¨¡å—ï¼šç”¨äºåŒæ—¶å®Œæˆå¤šä¸ªä¸‹æ¸¸ä»»åŠ¡ï¼›4) é¢†åŸŸè‡ªé€‚åº”æ¨¡å—ï¼šç”¨äºé€‚åº”ä¸åŒæ¥æºçš„åŒ»å­¦å›¾åƒã€‚

**å…³é”®åˆ›æ–°**ï¼šMedformerçš„å…³é”®åˆ›æ–°åœ¨äºå…¶åŠ¨æ€è¾“å…¥-è¾“å‡ºè‡ªé€‚åº”æœºåˆ¶å’Œå¤šä»»åŠ¡å­¦ä¹ æ¡†æ¶ã€‚åŠ¨æ€è¾“å…¥-è¾“å‡ºè‡ªé€‚åº”æœºåˆ¶å…è®¸æ¨¡å‹å¤„ç†ä¸åŒå¤§å°å’Œæ¨¡æ€çš„åŒ»å­¦å›¾åƒï¼Œè€Œæ— éœ€è¿›è¡Œå¤æ‚çš„é¢„å¤„ç†ã€‚å¤šä»»åŠ¡å­¦ä¹ æ¡†æ¶å…è®¸æ¨¡å‹åŒæ—¶å­¦ä¹ å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜è®¾è®¡äº†æ–°çš„pretextä»»åŠ¡ï¼Œèƒ½å¤Ÿä»æ— æ ‡ç­¾æ•°æ®ä¸­æå–æ›´æœ‰æ•ˆçš„ç‰¹å¾ã€‚

**å…³é”®è®¾è®¡**ï¼šMedformerçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨Transformerä½œä¸ºç‰¹å¾æå–å™¨ï¼Œåˆ©ç”¨å…¶å¼ºå¤§çš„è¡¨ç¤ºèƒ½åŠ›ï¼›2) è®¾è®¡äº†å¤šç§pretextä»»åŠ¡ï¼Œå¦‚å›¾åƒä¿®å¤ã€å›¾åƒç€è‰²ç­‰ï¼Œä»¥é¼“åŠ±æ¨¡å‹å­¦ä¹ å›¾åƒçš„ç»“æ„ä¿¡æ¯å’Œè¯­ä¹‰ä¿¡æ¯ï¼›3) ä½¿ç”¨å¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ åˆ°å¯¹ä¸åŒå˜æ¢å…·æœ‰ä¸å˜æ€§çš„ç‰¹å¾è¡¨ç¤ºï¼›4) ä½¿ç”¨é¢†åŸŸå¯¹æŠ—è®­ç»ƒï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿé€‚åº”ä¸åŒæ¥æºçš„åŒ»å­¦å›¾åƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡åœ¨MedMNISTæ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Œç»“æœè¡¨æ˜ï¼ŒMedformeråœ¨å¤šç§åŒ»å­¦å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œç›¸æ¯”äºä¼ ç»Ÿçš„ç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œåœ¨æ ‡æ³¨æ•°æ®è¾ƒå°‘çš„æƒ…å†µä¸‹ï¼Œä»èƒ½è¾¾åˆ°ç”šè‡³è¶…è¿‡å…¶æ€§èƒ½ã€‚è¿™éªŒè¯äº†Medformeråœ¨è‡ªç›‘ç£å­¦ä¹ æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œä»¥åŠå…¶åœ¨åŒ»å­¦å›¾åƒåˆ†æé¢†åŸŸçš„æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¤šç§åŒ»å­¦å›¾åƒåˆ†æä»»åŠ¡ï¼Œå¦‚ç–¾ç—…è¯Šæ–­ã€ç—…ç¶åˆ†å‰²ã€å›¾åƒé…å‡†ç­‰ã€‚é€šè¿‡å‡å°‘å¯¹æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œå¯ä»¥é™ä½åŒ»å­¦å›¾åƒåˆ†æçš„æˆæœ¬ï¼Œæé«˜æ•ˆç‡ï¼Œå¹¶ä¿ƒè¿›æ·±åº¦å­¦ä¹ åœ¨åŒ»ç–—é¢†åŸŸçš„å¹¿æ³›åº”ç”¨ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›åº”ç”¨äºè¿œç¨‹åŒ»ç–—ã€æ™ºèƒ½è¯Šæ–­ç­‰é¢†åŸŸï¼Œä¸ºæ‚£è€…æä¾›æ›´ä¾¿æ·ã€æ›´å‡†ç¡®çš„åŒ»ç–—æœåŠ¡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This thesis works to address a pivotal challenge in medical image analysis: the reliance on extensive labeled datasets, which are often limited due to the need for expert annotation and constrained by privacy and legal issues. By focusing on the development of self-supervised learning techniques and domain adaptation methods, this research aims to circumvent these limitations, presenting a novel approach to enhance the utility and efficacy of deep learning in medical imaging.
>   Central to this thesis is the development of the Medformer, an innovative neural network architecture designed for multitask learning and deep domain adaptation. This model is adept at pre-training on diverse medical image datasets, handling varying sizes and modalities, and is equipped with a dynamic input-output adaptation mechanism. This enables efficient processing and integration of a wide range of medical image types, from 2D X-rays to complex 3D MRIs, thus mitigating the dependency on large labeled datasets.
>   Further, the thesis explores the current state of self-supervised learning in medical imaging. It introduces novel pretext tasks that are capable of extracting meaningful information from unlabeled data, significantly advancing the model's interpretative abilities. This approach is validated through rigorous experimentation, including the use of the MedMNIST dataset, demonstrating the model's proficiency in learning generalized features applicable to various downstream tasks.
>   In summary, this thesis contributes to the advancement of medical image analysis by offering a scalable, adaptable framework that reduces reliance on labeled data. It paves the way for more accurate, efficient diagnostic tools in healthcare, signifying a major step forward in the application of deep learning in medical imaging.

