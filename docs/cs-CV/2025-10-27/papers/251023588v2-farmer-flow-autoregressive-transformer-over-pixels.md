---
layout: default
title: FARMER: Flow AutoRegressive Transformer over Pixels
---

# FARMER: Flow AutoRegressive Transformer over Pixels

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.23588" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.23588v2</a>
  <a href="https://arxiv.org/pdf/2510.23588.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.23588v2" onclick="toggleFavorite(this, '2510.23588v2', 'FARMER: Flow AutoRegressive Transformer over Pixels')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Guangting Zheng, Qinyu Zhao, Tao Yang, Fei Xiao, Zhijie Lin, Jie Wu, Jiajun Deng, Yanyong Zhang, Rui Zhu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-27 (æ›´æ–°: 2025-10-30)

**å¤‡æ³¨**: Bytedance Seed Technical Report

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**FARMERï¼šæå‡ºä¸€ç§åŸºäºæµè‡ªå›å½’Transformerçš„åƒç´ ç”Ÿæˆæ¨¡å‹ï¼Œå®ç°ç²¾ç¡®ä¼¼ç„¶ä¼°è®¡å’Œé«˜è´¨é‡å›¾åƒåˆæˆã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å›¾åƒç”Ÿæˆ` `è‡ªå›å½’æ¨¡å‹` `å½’ä¸€åŒ–æµ` `åƒç´ å»ºæ¨¡` `è‡ªç›‘ç£å­¦ä¹ ` `è’¸é¦è®­ç»ƒ` `æ— åˆ†ç±»å™¨å¼•å¯¼` `å¯é€†ç¥ç»ç½‘ç»œ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰åƒç´ æ•°æ®çš„è¿ç»­è‡ªå›å½’å»ºæ¨¡é¢ä¸´åºåˆ—è¿‡é•¿å’Œé«˜ç»´ç©ºé—´çš„æŒ‘æˆ˜ã€‚
2. FARMERç»“åˆå½’ä¸€åŒ–æµå’Œè‡ªå›å½’æ¨¡å‹ï¼Œé€šè¿‡å¯é€†è‡ªå›å½’æµå°†å›¾åƒè½¬æ¢ä¸ºæ½œåœ¨åºåˆ—ã€‚
3. é€šè¿‡è‡ªç›‘ç£é™ç»´å’Œå•æ­¥è’¸é¦ç­‰æŠ€æœ¯ï¼ŒFARMERåœ¨ä¿è¯æ€§èƒ½çš„åŒæ—¶ï¼Œæé«˜äº†è®­ç»ƒå’Œæ¨ç†æ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºFARMERçš„ç«¯åˆ°ç«¯ç”Ÿæˆæ¡†æ¶ï¼Œå®ƒç»Ÿä¸€äº†å½’ä¸€åŒ–æµï¼ˆNFï¼‰å’Œè‡ªå›å½’ï¼ˆARï¼‰æ¨¡å‹ï¼Œå¯ä»¥ç›´æ¥ä»åŸå§‹åƒç´ è¿›è¡Œå¯è¿½è¸ªçš„ä¼¼ç„¶ä¼°è®¡å’Œé«˜è´¨é‡çš„å›¾åƒåˆæˆã€‚FARMERé‡‡ç”¨å¯é€†çš„è‡ªå›å½’æµå°†å›¾åƒè½¬æ¢ä¸ºæ½œåœ¨åºåˆ—ï¼Œå…¶åˆ†å¸ƒç”±è‡ªå›å½’æ¨¡å‹éšå¼å»ºæ¨¡ã€‚ä¸ºäº†è§£å†³åƒç´ çº§å»ºæ¨¡ä¸­çš„å†—ä½™å’Œå¤æ‚æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è‡ªç›‘ç£çš„é™ç»´æ–¹æ¡ˆï¼Œå°†NFæ½œåœ¨é€šé“åˆ’åˆ†ä¸ºä¿¡æ¯æ€§å’Œå†—ä½™ç»„ï¼Œä»è€Œå®ç°æ›´æœ‰æ•ˆå’Œé«˜æ•ˆçš„ARå»ºæ¨¡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§å•æ­¥è’¸é¦æ–¹æ¡ˆï¼Œä»¥æ˜¾è‘—åŠ å¿«æ¨ç†é€Ÿåº¦ï¼Œå¹¶å¼•å…¥äº†ä¸€ç§åŸºäºé‡é‡‡æ ·çš„æ— åˆ†ç±»å™¨å¼•å¯¼ç®—æ³•ï¼Œä»¥æé«˜å›¾åƒç”Ÿæˆè´¨é‡ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œä¸ç°æœ‰çš„åŸºäºåƒç´ çš„ç”Ÿæˆæ¨¡å‹ç›¸æ¯”ï¼ŒFARMERå®ç°äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼ŒåŒæ—¶æä¾›äº†ç²¾ç¡®çš„ä¼¼ç„¶æ€§å’Œå¯æ‰©å±•çš„è®­ç»ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç›´æ¥å¯¹åŸå§‹æ•°æ®åˆ†å¸ƒè¿›è¡Œæ˜¾å¼ä¼¼ç„¶å»ºæ¨¡æ˜¯æœºå™¨å­¦ä¹ é¢†åŸŸçš„ä¸€ä¸ªå…³é”®é—®é¢˜ï¼Œè‡ªå›å½’å»ºæ¨¡å·²åœ¨å¤§è¯­è¨€æ¨¡å‹ä¸­å–å¾—äº†å·¨å¤§æˆåŠŸã€‚ç„¶è€Œï¼Œåœ¨è§†è§‰åƒç´ æ•°æ®ä¸Šè¿›è¡Œè¿ç»­è‡ªå›å½’å»ºæ¨¡é¢ä¸´ç€åºåˆ—è¿‡é•¿å’Œé«˜ç»´ç©ºé—´çš„æŒ‘æˆ˜ã€‚ç°æœ‰çš„åƒç´ ç”Ÿæˆæ¨¡å‹é€šå¸¸éš¾ä»¥å…¼é¡¾ç²¾ç¡®çš„ä¼¼ç„¶ä¼°è®¡ã€é«˜è´¨é‡çš„å›¾åƒåˆæˆä»¥åŠé«˜æ•ˆçš„è®­ç»ƒå’Œæ¨ç†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šFARMERçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†å½’ä¸€åŒ–æµï¼ˆNormalizing Flow, NFï¼‰å’Œè‡ªå›å½’ï¼ˆAutoregressive, ARï¼‰æ¨¡å‹ç»“åˆèµ·æ¥ã€‚NFè´Ÿè´£å°†åŸå§‹åƒç´ ç©ºé—´æ˜ å°„åˆ°æ½œåœ¨ç©ºé—´ï¼ŒARæ¨¡å‹åˆ™è´Ÿè´£å¯¹æ½œåœ¨ç©ºé—´çš„åˆ†å¸ƒè¿›è¡Œå»ºæ¨¡ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå¯ä»¥åˆ©ç”¨NFçš„å¯é€†æ€§è¿›è¡Œç²¾ç¡®çš„ä¼¼ç„¶ä¼°è®¡ï¼ŒåŒæ—¶åˆ©ç”¨ARæ¨¡å‹çš„å¼ºå¤§ç”Ÿæˆèƒ½åŠ›è¿›è¡Œé«˜è´¨é‡çš„å›¾åƒåˆæˆã€‚æ­¤å¤–ï¼Œé€šè¿‡è‡ªç›‘ç£é™ç»´å’Œè’¸é¦ç­‰æŠ€æœ¯ï¼Œå¯ä»¥æé«˜æ¨¡å‹çš„æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFARMERçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) å¯é€†è‡ªå›å½’æµï¼ˆInvertible Autoregressive Flowï¼‰ï¼šå°†åŸå§‹å›¾åƒåƒç´ è½¬æ¢ä¸ºæ½œåœ¨åºåˆ—ã€‚2) è‡ªç›‘ç£é™ç»´æ¨¡å—ï¼šå°†NFæ½œåœ¨é€šé“åˆ’åˆ†ä¸ºä¿¡æ¯æ€§å’Œå†—ä½™ç»„ã€‚3) è‡ªå›å½’æ¨¡å‹ï¼šå¯¹æ½œåœ¨åºåˆ—çš„åˆ†å¸ƒè¿›è¡Œå»ºæ¨¡ã€‚4) å•æ­¥è’¸é¦æ¨¡å—ï¼šåŠ é€Ÿæ¨ç†é€Ÿåº¦ã€‚5) åŸºäºé‡é‡‡æ ·çš„æ— åˆ†ç±»å™¨å¼•å¯¼ç®—æ³•ï¼šæå‡å›¾åƒç”Ÿæˆè´¨é‡ã€‚æ•´ä¸ªæµç¨‹æ˜¯ç«¯åˆ°ç«¯å¯è®­ç»ƒçš„ã€‚

**å…³é”®åˆ›æ–°**ï¼šFARMERçš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) ç»Ÿä¸€äº†NFå’ŒARæ¨¡å‹ï¼Œå®ç°äº†ç²¾ç¡®ä¼¼ç„¶ä¼°è®¡å’Œé«˜è´¨é‡å›¾åƒåˆæˆã€‚2) æå‡ºäº†è‡ªç›‘ç£é™ç»´æ–¹æ¡ˆï¼Œæœ‰æ•ˆé™ä½äº†åƒç´ çº§å»ºæ¨¡çš„å†—ä½™å’Œå¤æ‚æ€§ã€‚3) è®¾è®¡äº†å•æ­¥è’¸é¦æ–¹æ¡ˆï¼Œæ˜¾è‘—åŠ å¿«äº†æ¨ç†é€Ÿåº¦ã€‚4) å¼•å…¥äº†åŸºäºé‡é‡‡æ ·çš„æ— åˆ†ç±»å™¨å¼•å¯¼ç®—æ³•ï¼Œæå‡äº†å›¾åƒç”Ÿæˆè´¨é‡ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒFARMERåœ¨æ€§èƒ½ã€æ•ˆç‡å’Œå¯è§£é‡Šæ€§æ–¹é¢éƒ½å…·æœ‰ä¼˜åŠ¿ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å¯é€†è‡ªå›å½’æµä¸­ï¼Œä½¿ç”¨äº†ç‰¹å®šçš„å¯é€†ç¥ç»ç½‘ç»œç»“æ„ï¼Œä¾‹å¦‚Glowæˆ–RealNVPã€‚è‡ªç›‘ç£é™ç»´æ¨¡å—é€šè¿‡èšç±»ç­‰æ–¹æ³•å°†NFæ½œåœ¨é€šé“åˆ’åˆ†ä¸ºä¿¡æ¯æ€§å’Œå†—ä½™ç»„ã€‚è‡ªå›å½’æ¨¡å‹å¯ä»¥ä½¿ç”¨Transformeræˆ–RNNç­‰ç»“æ„ã€‚å•æ­¥è’¸é¦æ¨¡å—é€šè¿‡æœ€å°åŒ–æ•™å¸ˆæ¨¡å‹å’Œå­¦ç”Ÿæ¨¡å‹ä¹‹é—´çš„KLæ•£åº¦æ¥å®ç°ã€‚åŸºäºé‡é‡‡æ ·çš„æ— åˆ†ç±»å™¨å¼•å¯¼ç®—æ³•é€šè¿‡è°ƒæ•´é‡‡æ ·åˆ†å¸ƒæ¥æå‡ç”Ÿæˆè´¨é‡ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬ä¼¼ç„¶æŸå¤±å’Œè’¸é¦æŸå¤±ç­‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒFARMERåœ¨å›¾åƒç”Ÿæˆä»»åŠ¡ä¸Šå–å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼ŒåŒæ—¶æä¾›äº†ç²¾ç¡®çš„ä¼¼ç„¶ä¼°è®¡ã€‚ä¸ç°æœ‰åŸºäºåƒç´ çš„ç”Ÿæˆæ¨¡å‹ç›¸æ¯”ï¼ŒFARMERåœ¨FIDï¼ˆFrÃ©chet Inception Distanceï¼‰ç­‰æŒ‡æ ‡ä¸Šå–å¾—äº†æ˜¾è‘—æå‡ã€‚æ­¤å¤–ï¼Œå•æ­¥è’¸é¦æ–¹æ¡ˆæ˜¾è‘—åŠ å¿«äº†æ¨ç†é€Ÿåº¦ï¼Œä½¿å¾—FARMERåœ¨å®é™…åº”ç”¨ä¸­æ›´å…·ä¼˜åŠ¿ã€‚åŸºäºé‡é‡‡æ ·çš„æ— åˆ†ç±»å™¨å¼•å¯¼ç®—æ³•è¿›ä¸€æ­¥æå‡äº†å›¾åƒç”Ÿæˆè´¨é‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

FARMERå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼ŒåŒ…æ‹¬å›¾åƒç”Ÿæˆã€å›¾åƒä¿®å¤ã€å›¾åƒç¼–è¾‘ã€å¼‚å¸¸æ£€æµ‹ç­‰ã€‚è¯¥æ¨¡å‹å¯ä»¥ç”¨äºç”Ÿæˆé€¼çœŸçš„äººè„¸ã€é£æ™¯ã€ç‰©ä½“ç­‰å›¾åƒï¼Œä¹Ÿå¯ä»¥ç”¨äºä¿®å¤å›¾åƒä¸­çš„ç¼ºå¤±éƒ¨åˆ†æˆ–ç¼–è¾‘å›¾åƒçš„å†…å®¹ã€‚æ­¤å¤–ï¼ŒFARMERè¿˜å¯ä»¥ç”¨äºæ£€æµ‹å›¾åƒä¸­çš„å¼‚å¸¸æƒ…å†µï¼Œä¾‹å¦‚åŒ»ç–—å›¾åƒä¸­çš„ç—…ç¶æˆ–å·¥ä¸šå›¾åƒä¸­çš„ç¼ºé™·ã€‚æœªæ¥ï¼ŒFARMERæœ‰æœ›åœ¨è®¡ç®—æœºè§†è§‰ã€äººå·¥æ™ºèƒ½å’Œæœºå™¨å­¦ä¹ ç­‰é¢†åŸŸå‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Directly modeling the explicit likelihood of the raw data distribution is key topic in the machine learning area, which achieves the scaling successes in Large Language Models by autoregressive modeling. However, continuous AR modeling over visual pixel data suffer from extremely long sequences and high-dimensional spaces. In this paper, we present FARMER, a novel end-to-end generative framework that unifies Normalizing Flows (NF) and Autoregressive (AR) models for tractable likelihood estimation and high-quality image synthesis directly from raw pixels. FARMER employs an invertible autoregressive flow to transform images into latent sequences, whose distribution is modeled implicitly by an autoregressive model. To address the redundancy and complexity in pixel-level modeling, we propose a self-supervised dimension reduction scheme that partitions NF latent channels into informative and redundant groups, enabling more effective and efficient AR modeling. Furthermore, we design a one-step distillation scheme to significantly accelerate inference speed and introduce a resampling-based classifier-free guidance algorithm to boost image generation quality. Extensive experiments demonstrate that FARMER achieves competitive performance compared to existing pixel-based generative models while providing exact likelihoods and scalable training.

