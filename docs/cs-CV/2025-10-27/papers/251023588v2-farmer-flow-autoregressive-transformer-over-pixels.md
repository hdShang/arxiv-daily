---
layout: default
title: FARMER: Flow AutoRegressive Transformer over Pixels
---

# FARMER: Flow AutoRegressive Transformer over Pixels

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.23588" target="_blank" class="toolbar-btn">arXiv: 2510.23588v2</a>
    <a href="https://arxiv.org/pdf/2510.23588.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.23588v2" 
            onclick="toggleFavorite(this, '2510.23588v2', 'FARMER: Flow AutoRegressive Transformer over Pixels')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Guangting Zheng, Qinyu Zhao, Tao Yang, Fei Xiao, Zhijie Lin, Jie Wu, Jiajun Deng, Yanyong Zhang, Rui Zhu

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-27 (Êõ¥Êñ∞: 2025-10-30)

**Â§áÊ≥®**: Bytedance Seed Technical Report

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**FARMERÔºöÊèêÂá∫‰∏ÄÁßçÂü∫‰∫éÊµÅËá™ÂõûÂΩíTransformerÁöÑÂÉèÁ¥†ÁîüÊàêÊ®°ÂûãÔºåÂÆûÁé∞Á≤æÁ°Æ‰ººÁÑ∂‰º∞ËÆ°ÂíåÈ´òË¥®ÈáèÂõæÂÉèÂêàÊàê„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±ÂõõÔºöÁîüÊàêÂºèÂä®‰Ωú (Generative Motion)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÂõæÂÉèÁîüÊàê` `Ëá™ÂõûÂΩíÊ®°Âûã` `ÂΩí‰∏ÄÂåñÊµÅ` `ÂÉèÁ¥†Âª∫Ê®°` `Ëá™ÁõëÁù£Â≠¶‰π†` `Ëí∏È¶èËÆ≠ÁªÉ` `Êó†ÂàÜÁ±ªÂô®ÂºïÂØº` `ÂèØÈÄÜÁ•ûÁªèÁΩëÁªú`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËßÜËßâÂÉèÁ¥†Êï∞ÊçÆÁöÑËøûÁª≠Ëá™ÂõûÂΩíÂª∫Ê®°Èù¢‰∏¥Â∫èÂàóËøáÈïøÂíåÈ´òÁª¥Á©∫Èó¥ÁöÑÊåëÊàò„ÄÇ
2. FARMERÁªìÂêàÂΩí‰∏ÄÂåñÊµÅÂíåËá™ÂõûÂΩíÊ®°ÂûãÔºåÈÄöËøáÂèØÈÄÜËá™ÂõûÂΩíÊµÅÂ∞ÜÂõæÂÉèËΩ¨Êç¢‰∏∫ÊΩúÂú®Â∫èÂàó„ÄÇ
3. ÈÄöËøáËá™ÁõëÁù£ÈôçÁª¥ÂíåÂçïÊ≠•Ëí∏È¶èÁ≠âÊäÄÊúØÔºåFARMERÂú®‰øùËØÅÊÄßËÉΩÁöÑÂêåÊó∂ÔºåÊèêÈ´ò‰∫ÜËÆ≠ÁªÉÂíåÊé®ÁêÜÊïàÁéá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫FARMERÁöÑÁ´ØÂà∞Á´ØÁîüÊàêÊ°ÜÊû∂ÔºåÂÆÉÁªü‰∏Ä‰∫ÜÂΩí‰∏ÄÂåñÊµÅÔºàNFÔºâÂíåËá™ÂõûÂΩíÔºàARÔºâÊ®°ÂûãÔºåÂèØ‰ª•Áõ¥Êé•‰ªéÂéüÂßãÂÉèÁ¥†ËøõË°åÂèØËøΩË∏™ÁöÑ‰ººÁÑ∂‰º∞ËÆ°ÂíåÈ´òË¥®ÈáèÁöÑÂõæÂÉèÂêàÊàê„ÄÇFARMERÈááÁî®ÂèØÈÄÜÁöÑËá™ÂõûÂΩíÊµÅÂ∞ÜÂõæÂÉèËΩ¨Êç¢‰∏∫ÊΩúÂú®Â∫èÂàóÔºåÂÖ∂ÂàÜÂ∏ÉÁî±Ëá™ÂõûÂΩíÊ®°ÂûãÈöêÂºèÂª∫Ê®°„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥ÂÉèÁ¥†Á∫ßÂª∫Ê®°‰∏≠ÁöÑÂÜó‰ΩôÂíåÂ§çÊùÇÊÄßÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçËá™ÁõëÁù£ÁöÑÈôçÁª¥ÊñπÊ°àÔºåÂ∞ÜNFÊΩúÂú®ÈÄöÈÅìÂàíÂàÜ‰∏∫‰ø°ÊÅØÊÄßÂíåÂÜó‰ΩôÁªÑÔºå‰ªéËÄåÂÆûÁé∞Êõ¥ÊúâÊïàÂíåÈ´òÊïàÁöÑARÂª∫Ê®°„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ËÆæËÆ°‰∫Ü‰∏ÄÁßçÂçïÊ≠•Ëí∏È¶èÊñπÊ°àÔºå‰ª•ÊòæËëóÂä†Âø´Êé®ÁêÜÈÄüÂ∫¶ÔºåÂπ∂ÂºïÂÖ•‰∫Ü‰∏ÄÁßçÂü∫‰∫éÈáçÈááÊ†∑ÁöÑÊó†ÂàÜÁ±ªÂô®ÂºïÂØºÁÆóÊ≥ïÔºå‰ª•ÊèêÈ´òÂõæÂÉèÁîüÊàêË¥®Èáè„ÄÇÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºå‰∏éÁé∞ÊúâÁöÑÂü∫‰∫éÂÉèÁ¥†ÁöÑÁîüÊàêÊ®°ÂûãÁõ∏ÊØîÔºåFARMERÂÆûÁé∞‰∫ÜÂÖ∑ÊúâÁ´û‰∫âÂäõÁöÑÊÄßËÉΩÔºåÂêåÊó∂Êèê‰æõ‰∫ÜÁ≤æÁ°ÆÁöÑ‰ººÁÑ∂ÊÄßÂíåÂèØÊâ©Â±ïÁöÑËÆ≠ÁªÉ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁõ¥Êé•ÂØπÂéüÂßãÊï∞ÊçÆÂàÜÂ∏ÉËøõË°åÊòæÂºè‰ººÁÑ∂Âª∫Ê®°ÊòØÊú∫Âô®Â≠¶‰π†È¢ÜÂüüÁöÑ‰∏Ä‰∏™ÂÖ≥ÈîÆÈóÆÈ¢òÔºåËá™ÂõûÂΩíÂª∫Ê®°Â∑≤Âú®Â§ßËØ≠Ë®ÄÊ®°Âûã‰∏≠ÂèñÂæó‰∫ÜÂ∑®Â§ßÊàêÂäü„ÄÇÁÑ∂ËÄåÔºåÂú®ËßÜËßâÂÉèÁ¥†Êï∞ÊçÆ‰∏äËøõË°åËøûÁª≠Ëá™ÂõûÂΩíÂª∫Ê®°Èù¢‰∏¥ÁùÄÂ∫èÂàóËøáÈïøÂíåÈ´òÁª¥Á©∫Èó¥ÁöÑÊåëÊàò„ÄÇÁé∞ÊúâÁöÑÂÉèÁ¥†ÁîüÊàêÊ®°ÂûãÈÄöÂ∏∏Èöæ‰ª•ÂÖºÈ°æÁ≤æÁ°ÆÁöÑ‰ººÁÑ∂‰º∞ËÆ°„ÄÅÈ´òË¥®ÈáèÁöÑÂõæÂÉèÂêàÊàê‰ª•ÂèäÈ´òÊïàÁöÑËÆ≠ÁªÉÂíåÊé®ÁêÜ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöFARMERÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜÂΩí‰∏ÄÂåñÊµÅÔºàNormalizing Flow, NFÔºâÂíåËá™ÂõûÂΩíÔºàAutoregressive, ARÔºâÊ®°ÂûãÁªìÂêàËµ∑Êù•„ÄÇNFË¥üË¥£Â∞ÜÂéüÂßãÂÉèÁ¥†Á©∫Èó¥Êò†Â∞ÑÂà∞ÊΩúÂú®Á©∫Èó¥ÔºåARÊ®°ÂûãÂàôË¥üË¥£ÂØπÊΩúÂú®Á©∫Èó¥ÁöÑÂàÜÂ∏ÉËøõË°åÂª∫Ê®°„ÄÇÈÄöËøáËøôÁßçÊñπÂºèÔºåÂèØ‰ª•Âà©Áî®NFÁöÑÂèØÈÄÜÊÄßËøõË°åÁ≤æÁ°ÆÁöÑ‰ººÁÑ∂‰º∞ËÆ°ÔºåÂêåÊó∂Âà©Áî®ARÊ®°ÂûãÁöÑÂº∫Â§ßÁîüÊàêËÉΩÂäõËøõË°åÈ´òË¥®ÈáèÁöÑÂõæÂÉèÂêàÊàê„ÄÇÊ≠§Â§ñÔºåÈÄöËøáËá™ÁõëÁù£ÈôçÁª¥ÂíåËí∏È¶èÁ≠âÊäÄÊúØÔºåÂèØ‰ª•ÊèêÈ´òÊ®°ÂûãÁöÑÊïàÁéá„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöFARMERÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) ÂèØÈÄÜËá™ÂõûÂΩíÊµÅÔºàInvertible Autoregressive FlowÔºâÔºöÂ∞ÜÂéüÂßãÂõæÂÉèÂÉèÁ¥†ËΩ¨Êç¢‰∏∫ÊΩúÂú®Â∫èÂàó„ÄÇ2) Ëá™ÁõëÁù£ÈôçÁª¥Ê®°ÂùóÔºöÂ∞ÜNFÊΩúÂú®ÈÄöÈÅìÂàíÂàÜ‰∏∫‰ø°ÊÅØÊÄßÂíåÂÜó‰ΩôÁªÑ„ÄÇ3) Ëá™ÂõûÂΩíÊ®°ÂûãÔºöÂØπÊΩúÂú®Â∫èÂàóÁöÑÂàÜÂ∏ÉËøõË°åÂª∫Ê®°„ÄÇ4) ÂçïÊ≠•Ëí∏È¶èÊ®°ÂùóÔºöÂä†ÈÄüÊé®ÁêÜÈÄüÂ∫¶„ÄÇ5) Âü∫‰∫éÈáçÈááÊ†∑ÁöÑÊó†ÂàÜÁ±ªÂô®ÂºïÂØºÁÆóÊ≥ïÔºöÊèêÂçáÂõæÂÉèÁîüÊàêË¥®Èáè„ÄÇÊï¥‰∏™ÊµÅÁ®ãÊòØÁ´ØÂà∞Á´ØÂèØËÆ≠ÁªÉÁöÑ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöFARMERÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1) Áªü‰∏Ä‰∫ÜNFÂíåARÊ®°ÂûãÔºåÂÆûÁé∞‰∫ÜÁ≤æÁ°Æ‰ººÁÑ∂‰º∞ËÆ°ÂíåÈ´òË¥®ÈáèÂõæÂÉèÂêàÊàê„ÄÇ2) ÊèêÂá∫‰∫ÜËá™ÁõëÁù£ÈôçÁª¥ÊñπÊ°àÔºåÊúâÊïàÈôç‰Ωé‰∫ÜÂÉèÁ¥†Á∫ßÂª∫Ê®°ÁöÑÂÜó‰ΩôÂíåÂ§çÊùÇÊÄß„ÄÇ3) ËÆæËÆ°‰∫ÜÂçïÊ≠•Ëí∏È¶èÊñπÊ°àÔºåÊòæËëóÂä†Âø´‰∫ÜÊé®ÁêÜÈÄüÂ∫¶„ÄÇ4) ÂºïÂÖ•‰∫ÜÂü∫‰∫éÈáçÈááÊ†∑ÁöÑÊó†ÂàÜÁ±ªÂô®ÂºïÂØºÁÆóÊ≥ïÔºåÊèêÂçá‰∫ÜÂõæÂÉèÁîüÊàêË¥®Èáè„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåFARMERÂú®ÊÄßËÉΩ„ÄÅÊïàÁéáÂíåÂèØËß£ÈáäÊÄßÊñπÈù¢ÈÉΩÂÖ∑Êúâ‰ºòÂäø„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÂèØÈÄÜËá™ÂõûÂΩíÊµÅ‰∏≠Ôºå‰ΩøÁî®‰∫ÜÁâπÂÆöÁöÑÂèØÈÄÜÁ•ûÁªèÁΩëÁªúÁªìÊûÑÔºå‰æãÂ¶ÇGlowÊàñRealNVP„ÄÇËá™ÁõëÁù£ÈôçÁª¥Ê®°ÂùóÈÄöËøáËÅöÁ±ªÁ≠âÊñπÊ≥ïÂ∞ÜNFÊΩúÂú®ÈÄöÈÅìÂàíÂàÜ‰∏∫‰ø°ÊÅØÊÄßÂíåÂÜó‰ΩôÁªÑ„ÄÇËá™ÂõûÂΩíÊ®°ÂûãÂèØ‰ª•‰ΩøÁî®TransformerÊàñRNNÁ≠âÁªìÊûÑ„ÄÇÂçïÊ≠•Ëí∏È¶èÊ®°ÂùóÈÄöËøáÊúÄÂ∞èÂåñÊïôÂ∏àÊ®°ÂûãÂíåÂ≠¶ÁîüÊ®°Âûã‰πãÈó¥ÁöÑKLÊï£Â∫¶Êù•ÂÆûÁé∞„ÄÇÂü∫‰∫éÈáçÈááÊ†∑ÁöÑÊó†ÂàÜÁ±ªÂô®ÂºïÂØºÁÆóÊ≥ïÈÄöËøáË∞ÉÊï¥ÈááÊ†∑ÂàÜÂ∏ÉÊù•ÊèêÂçáÁîüÊàêË¥®Èáè„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨‰ººÁÑ∂ÊçüÂ§±ÂíåËí∏È¶èÊçüÂ§±Á≠â„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåFARMERÂú®ÂõæÂÉèÁîüÊàê‰ªªÂä°‰∏äÂèñÂæó‰∫ÜÂÖ∑ÊúâÁ´û‰∫âÂäõÁöÑÊÄßËÉΩÔºåÂêåÊó∂Êèê‰æõ‰∫ÜÁ≤æÁ°ÆÁöÑ‰ººÁÑ∂‰º∞ËÆ°„ÄÇ‰∏éÁé∞ÊúâÂü∫‰∫éÂÉèÁ¥†ÁöÑÁîüÊàêÊ®°ÂûãÁõ∏ÊØîÔºåFARMERÂú®FIDÔºàFr√©chet Inception DistanceÔºâÁ≠âÊåáÊ†á‰∏äÂèñÂæó‰∫ÜÊòæËëóÊèêÂçá„ÄÇÊ≠§Â§ñÔºåÂçïÊ≠•Ëí∏È¶èÊñπÊ°àÊòæËëóÂä†Âø´‰∫ÜÊé®ÁêÜÈÄüÂ∫¶Ôºå‰ΩøÂæóFARMERÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠Êõ¥ÂÖ∑‰ºòÂäø„ÄÇÂü∫‰∫éÈáçÈááÊ†∑ÁöÑÊó†ÂàÜÁ±ªÂô®ÂºïÂØºÁÆóÊ≥ïËøõ‰∏ÄÊ≠•ÊèêÂçá‰∫ÜÂõæÂÉèÁîüÊàêË¥®Èáè„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

FARMERÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂåÖÊã¨ÂõæÂÉèÁîüÊàê„ÄÅÂõæÂÉè‰øÆÂ§ç„ÄÅÂõæÂÉèÁºñËæë„ÄÅÂºÇÂ∏∏Ê£ÄÊµãÁ≠â„ÄÇËØ•Ê®°ÂûãÂèØ‰ª•Áî®‰∫éÁîüÊàêÈÄºÁúüÁöÑ‰∫∫ËÑ∏„ÄÅÈ£éÊôØ„ÄÅÁâ©‰ΩìÁ≠âÂõæÂÉèÔºå‰πüÂèØ‰ª•Áî®‰∫é‰øÆÂ§çÂõæÂÉè‰∏≠ÁöÑÁº∫Â§±ÈÉ®ÂàÜÊàñÁºñËæëÂõæÂÉèÁöÑÂÜÖÂÆπ„ÄÇÊ≠§Â§ñÔºåFARMERËøòÂèØ‰ª•Áî®‰∫éÊ£ÄÊµãÂõæÂÉè‰∏≠ÁöÑÂºÇÂ∏∏ÊÉÖÂÜµÔºå‰æãÂ¶ÇÂåªÁñóÂõæÂÉè‰∏≠ÁöÑÁóÖÁÅ∂ÊàñÂ∑•‰∏öÂõæÂÉè‰∏≠ÁöÑÁº∫Èô∑„ÄÇÊú™Êù•ÔºåFARMERÊúâÊúõÂú®ËÆ°ÁÆóÊú∫ËßÜËßâ„ÄÅ‰∫∫Â∑•Êô∫ËÉΩÂíåÊú∫Âô®Â≠¶‰π†Á≠âÈ¢ÜÂüüÂèëÊå•ÈáçË¶Å‰ΩúÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Directly modeling the explicit likelihood of the raw data distribution is key topic in the machine learning area, which achieves the scaling successes in Large Language Models by autoregressive modeling. However, continuous AR modeling over visual pixel data suffer from extremely long sequences and high-dimensional spaces. In this paper, we present FARMER, a novel end-to-end generative framework that unifies Normalizing Flows (NF) and Autoregressive (AR) models for tractable likelihood estimation and high-quality image synthesis directly from raw pixels. FARMER employs an invertible autoregressive flow to transform images into latent sequences, whose distribution is modeled implicitly by an autoregressive model. To address the redundancy and complexity in pixel-level modeling, we propose a self-supervised dimension reduction scheme that partitions NF latent channels into informative and redundant groups, enabling more effective and efficient AR modeling. Furthermore, we design a one-step distillation scheme to significantly accelerate inference speed and introduce a resampling-based classifier-free guidance algorithm to boost image generation quality. Extensive experiments demonstrate that FARMER achieves competitive performance compared to existing pixel-based generative models while providing exact likelihoods and scalable training.

