---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CV - 2025-12-16
---

# cs.CVï¼ˆ2025-12-16ï¼‰

ğŸ“Š å…± **58** ç¯‡è®ºæ–‡
 | ğŸ”— **6** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (40 ğŸ”—6)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (8)</a>
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (6)</a>
<a href="#æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion" class="interest-badge">æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (4)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (40 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251214095v1-anchorhoi-zero-shot-generation-of-4d-human-object-interaction-via-an.html">AnchorHOI: Zero-shot Generation of 4D Human-Object Interaction via Anchor-based Prior Distillation</a></td>
  <td>AnchorHOIï¼šåŸºäºé”šç‚¹çš„å…ˆéªŒçŸ¥è¯†è’¸é¦å®ç°é›¶æ ·æœ¬4Däºº-ç‰©äº¤äº’ç”Ÿæˆ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14095v1" onclick="toggleFavorite(this, '2512.14095v1', 'AnchorHOI: Zero-shot Generation of 4D Human-Object Interaction via Anchor-based Prior Distillation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251214352v1-hgs-hybrid-gaussian-splatting-with-static-dynamic-decomposition-for-.html">HGS: Hybrid Gaussian Splatting with Static-Dynamic Decomposition for Compact Dynamic View Synthesis</a></td>
  <td>æå‡ºHGSæ··åˆé«˜æ–¯æº…å°„ï¼Œé€šè¿‡é™æ€-åŠ¨æ€åˆ†è§£å®ç°ç´§å‡‘çš„åŠ¨æ€è§†è§’åˆæˆ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14352v1" onclick="toggleFavorite(this, '2512.14352v1', 'HGS: Hybrid Gaussian Splatting with Static-Dynamic Decomposition for Compact Dynamic View Synthesis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251214200v1-beyond-a-single-light-a-large-scale-aerial-dataset-for-urban-scene-r.html">Beyond a Single Light: A Large-Scale Aerial Dataset for Urban Scene Reconstruction Under Varying Illumination</a></td>
  <td>SkyLumeï¼šä¸€ä¸ªå¤§è§„æ¨¡å¤šå…‰ç…§åŸå¸‚é‡å»ºèˆªæ‹æ•°æ®é›†ï¼Œç”¨äºè§£å†³å…‰ç…§å˜åŒ–ä¸‹çš„ä¸‰ç»´é‡å»ºé—®é¢˜ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14200v1" onclick="toggleFavorite(this, '2512.14200v1', 'Beyond a Single Light: A Large-Scale Aerial Dataset for Urban Scene Reconstruction Under Varying Illumination')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251214020v1-deep-learning-perspective-of-scene-understanding-in-autonomous-robot.html">Deep Learning Perspective of Scene Understanding in Autonomous Robots</a></td>
  <td>ç»¼è¿°æ·±åº¦å­¦ä¹ åœ¨è‡ªä¸»æœºå™¨äººåœºæ™¯ç†è§£ä¸­çš„åº”ç”¨ï¼Œæå‡æœºå™¨äººæ„ŸçŸ¥ä¸å†³ç­–èƒ½åŠ›</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14020v1" onclick="toggleFavorite(this, '2512.14020v1', 'Deep Learning Perspective of Scene Understanding in Autonomous Robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251214536v1-dasp-self-supervised-nighttime-monocular-depth-estimation-with-domai.html">DASP: Self-supervised Nighttime Monocular Depth Estimation with Domain Adaptation of Spatiotemporal Priors</a></td>
  <td>DASPï¼šåˆ©ç”¨æ—¶ç©ºå…ˆéªŒåŸŸé€‚åº”çš„è‡ªç›‘ç£å¤œé—´å•ç›®æ·±åº¦ä¼°è®¡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14536v1" onclick="toggleFavorite(this, '2512.14536v1', 'DASP: Self-supervised Nighttime Monocular Depth Estimation with Domain Adaptation of Spatiotemporal Priors')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251214406v1-broadening-view-synthesis-of-dynamic-scenes-from-constrained-monocul.html">Broadening View Synthesis of Dynamic Scenes from Constrained Monocular Videos</a></td>
  <td>ExpanDyNeRFï¼šæ‰©å±•åŠ¨æ€åœºæ™¯è§†è§’åˆæˆï¼Œè§£å†³å•ç›®è§†é¢‘å¤§è§’åº¦æ¸²æŸ“å¤±çœŸé—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14406v1" onclick="toggleFavorite(this, '2512.14406v1', 'Broadening View Synthesis of Dynamic Scenes from Constrained Monocular Videos')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/251214087v1-gaussianplant-structure-aligned-gaussian-splatting-for-3d-reconstruc.html">GaussianPlant: Structure-aligned Gaussian Splatting for 3D Reconstruction of Plants</a></td>
  <td>GaussianPlantï¼šæå‡ºç»“æ„å¯¹é½çš„é«˜æ–¯æº…å°„æ–¹æ³•ï¼Œç”¨äºæ¤ç‰©ä¸‰ç»´é‡å»º</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14087v1" onclick="toggleFavorite(this, '2512.14087v1', 'GaussianPlant: Structure-aligned Gaussian Splatting for 3D Reconstruction of Plants')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251214032v1-ace-slam-scene-coordinate-regression-for-neural-implicit-real-time-s.html">ACE-SLAM: Scene Coordinate Regression for Neural Implicit Real-Time SLAM</a></td>
  <td>ACE-SLAMï¼šåŸºäºåœºæ™¯åæ ‡å›å½’çš„ç¥ç»éšå¼å®æ—¶SLAMç³»ç»Ÿ</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14032v1" onclick="toggleFavorite(this, '2512.14032v1', 'ACE-SLAM: Scene Coordinate Regression for Neural Implicit Real-Time SLAM')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/251214560v1-clnet-cross-view-correspondence-makes-a-stronger-geo-localizationer.html">CLNet: Cross-View Correspondence Makes a Stronger Geo-Localizationer</a></td>
  <td>æå‡ºCLNetï¼Œé€šè¿‡è·¨è§†è§’å¯¹åº”å…³ç³»å¢å¼ºåœ°ç†å®šä½èƒ½åŠ›</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14560v1" onclick="toggleFavorite(this, '2512.14560v1', 'CLNet: Cross-View Correspondence Makes a Stronger Geo-Localizationer')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/251214364v1-unified-semantic-transformer-for-3d-scene-understanding.html">Unified Semantic Transformer for 3D Scene Understanding</a></td>
  <td>æå‡ºUNITEï¼šç”¨äº3Dåœºæ™¯ç†è§£çš„ç»Ÿä¸€è¯­ä¹‰Transformeræ¨¡å‹</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14364v1" onclick="toggleFavorite(this, '2512.14364v1', 'Unified Semantic Transformer for 3D Scene Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/251214235v1-4d-radiff-latent-diffusion-for-4d-radar-point-cloud-generation.html">4D-RaDiff: Latent Diffusion for 4D Radar Point Cloud Generation</a></td>
  <td>æå‡º4D-RaDiffï¼Œåˆ©ç”¨æ½œåœ¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆ4Dé›·è¾¾ç‚¹äº‘ï¼Œæå‡ç›®æ ‡æ£€æµ‹æ€§èƒ½ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14235v1" onclick="toggleFavorite(this, '2512.14235v1', '4D-RaDiff: Latent Diffusion for 4D Radar Point Cloud Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/251214222v1-history-enhanced-two-stage-transformer-for-aerial-vision-and-languag.html">History-Enhanced Two-Stage Transformer for Aerial Vision-and-Language Navigation</a></td>
  <td>æå‡ºå†å²å¢å¼ºå‹ä¸¤é˜¶æ®µTransformerï¼ˆHETTï¼‰æ¡†æ¶ï¼Œè§£å†³æ— äººæœºè§†è§‰-è¯­è¨€å¯¼èˆªä¸­çš„å…¨å±€æ¨ç†ä¸å±€éƒ¨ç†è§£å¹³è¡¡é—®é¢˜ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14222v1" onclick="toggleFavorite(this, '2512.14222v1', 'History-Enhanced Two-Stage Transformer for Aerial Vision-and-Language Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/251214180v1-spherical-voronoi-directional-appearance-as-a-differentiable-partiti.html">Spherical Voronoi: Directional Appearance as a Differentiable Partition of the Sphere</a></td>
  <td>æå‡ºçƒVoronoiå›¾ï¼Œç”¨äº3Dé«˜æ–¯æº…å°„ä¸­å¯å¾®çš„æ–¹å‘å¤–è§‚å»ºæ¨¡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14180v1" onclick="toggleFavorite(this, '2512.14180v1', 'Spherical Voronoi: Directional Appearance as a Differentiable Partition of the Sphere')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/251214162v1-fastddhpose-towards-unified-efficient-and-disentangled-3d-human-pose.html">FastDDHPose: Towards Unified, Efficient, and Disentangled 3D Human Pose Estimation</a></td>
  <td>FastDDHPoseï¼šæå‡ºç»Ÿä¸€ã€é«˜æ•ˆä¸”è§£è€¦çš„å•ç›®3Däººä½“å§¿æ€ä¼°è®¡æ¡†æ¶</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14162v1" onclick="toggleFavorite(this, '2512.14162v1', 'FastDDHPose: Towards Unified, Efficient, and Disentangled 3D Human Pose Estimation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/251214126v1-consistent-instance-field-for-dynamic-scene-understanding.html">Consistent Instance Field for Dynamic Scene Understanding</a></td>
  <td>æå‡ºä¸€è‡´æ€§å®ä¾‹åœºï¼Œç”¨äºåŠ¨æ€åœºæ™¯ç†è§£ä¸­çš„æ—¶ç©ºè¿ç»­æ¦‚ç‡å»ºæ¨¡ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14126v1" onclick="toggleFavorite(this, '2512.14126v1', 'Consistent Instance Field for Dynamic Scene Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/251214028v1-robust-single-shot-structured-light-3d-imaging-via-neural-feature-de.html">Robust Single-shot Structured Light 3D Imaging via Neural Feature Decoding</a></td>
  <td>æå‡ºåŸºäºç¥ç»ç‰¹å¾è§£ç çš„é²æ£’å•ç›®ç»“æ„å…‰3Dæˆåƒæ–¹æ³•ï¼Œæå‡åœ¨å¤æ‚åœºæ™¯ä¸‹çš„æ€§èƒ½ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14028v1" onclick="toggleFavorite(this, '2512.14028v1', 'Robust Single-shot Structured Light 3D Imaging via Neural Feature Decoding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/251214039v1-asap-textured-gaussians-enhancing-textured-gaussians-with-adaptive-s.html">ASAP-Textured Gaussians: Enhancing Textured Gaussians with Adaptive Sampling and Anisotropic Parameterization</a></td>
  <td>ASAP-Textured Gaussiansï¼šé€šè¿‡è‡ªé€‚åº”é‡‡æ ·å’Œå„å‘å¼‚æ€§å‚æ•°åŒ–å¢å¼ºçº¹ç†é«˜æ–¯æ¨¡å‹</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14039v1" onclick="toggleFavorite(this, '2512.14039v1', 'ASAP-Textured Gaussians: Enhancing Textured Gaussians with Adaptive Sampling and Anisotropic Parameterization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/251214274v1-tun-detecting-significant-points-in-persistence-diagrams-with-deep-l.html">TUN: Detecting Significant Points in Persistence Diagrams with Deep Learning</a></td>
  <td>æå‡ºæ‹“æ‰‘ç†è§£ç½‘ç»œTUNï¼Œç”¨äºè‡ªåŠ¨æ£€æµ‹æŒä¹…åŒ–å›¾ä¸­æ˜¾è‘—ç‚¹ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14274v1" onclick="toggleFavorite(this, '2512.14274v1', 'TUN: Detecting Significant Points in Persistence Diagrams with Deep Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/251214273v1-zoom-zero-reinforced-coarse-to-fine-video-understanding-via-temporal.html">Zoom-Zero: Reinforced Coarse-to-Fine Video Understanding via Temporal Zoom-in</a></td>
  <td>Zoom-Zeroï¼šé€šè¿‡æ—¶åºç¼©æ”¾å¢å¼ºçš„ç²—åˆ°ç»†è§†é¢‘ç†è§£æ¡†æ¶ï¼Œæå‡GVQAä»»åŠ¡æ€§èƒ½ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14273v1" onclick="toggleFavorite(this, '2512.14273v1', 'Zoom-Zero: Reinforced Coarse-to-Fine Video Understanding via Temporal Zoom-in')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/251214236v1-elastic3d-controllable-stereo-video-conversion-with-guided-latent-de.html">Elastic3D: Controllable Stereo Video Conversion with Guided Latent Decoding</a></td>
  <td>Elastic3Dï¼šåŸºäºå¼•å¯¼å¼æ½œåœ¨è§£ç çš„å¯æ§ç«‹ä½“è§†é¢‘è½¬æ¢æ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14236v1" onclick="toggleFavorite(this, '2512.14236v1', 'Elastic3D: Controllable Stereo Video Conversion with Guided Latent Decoding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>21</td>
  <td><a href="./papers/251214095v1-anchorhoi-zero-shot-generation-of-4d-human-object-interaction-via-an.html">AnchorHOI: Zero-shot Generation of 4D Human-Object Interaction via Anchor-based Prior Distillation</a></td>
  <td>AnchorHOIï¼šåŸºäºé”šç‚¹çš„å…ˆéªŒçŸ¥è¯†è’¸é¦å®ç°é›¶æ ·æœ¬4Däºº-ç‰©äº¤äº’ç”Ÿæˆ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14095v1" onclick="toggleFavorite(this, '2512.14095v1', 'AnchorHOI: Zero-shot Generation of 4D Human-Object Interaction via Anchor-based Prior Distillation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>22</td>
  <td><a href="./papers/251214352v1-hgs-hybrid-gaussian-splatting-with-static-dynamic-decomposition-for-.html">HGS: Hybrid Gaussian Splatting with Static-Dynamic Decomposition for Compact Dynamic View Synthesis</a></td>
  <td>æå‡ºHGSæ··åˆé«˜æ–¯æº…å°„æ–¹æ³•ï¼Œé€šè¿‡é™æ€-åŠ¨æ€è§£è€¦å®ç°ç´§å‡‘çš„åŠ¨æ€åœºæ™¯æ–°è§†è§’åˆæˆã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14352v1" onclick="toggleFavorite(this, '2512.14352v1', 'HGS: Hybrid Gaussian Splatting with Static-Dynamic Decomposition for Compact Dynamic View Synthesis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>23</td>
  <td><a href="./papers/251214200v1-beyond-a-single-light-a-large-scale-aerial-dataset-for-urban-scene-r.html">Beyond a Single Light: A Large-Scale Aerial Dataset for Urban Scene Reconstruction Under Varying Illumination</a></td>
  <td>SkyLumeï¼šä¸€ä¸ªå¤§è§„æ¨¡å¤šå…‰ç…§åŸå¸‚é‡å»ºèˆªæ‹æ•°æ®é›†ï¼Œç”¨äºè§£å†³å…‰ç…§å˜åŒ–ä¸‹çš„ä¸‰ç»´é‡å»ºé—®é¢˜ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14200v1" onclick="toggleFavorite(this, '2512.14200v1', 'Beyond a Single Light: A Large-Scale Aerial Dataset for Urban Scene Reconstruction Under Varying Illumination')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>24</td>
  <td><a href="./papers/251214020v1-deep-learning-perspective-of-scene-understanding-in-autonomous-robot.html">Deep Learning Perspective of Scene Understanding in Autonomous Robots</a></td>
  <td>ç»¼è¿°æ·±åº¦å­¦ä¹ åœ¨è‡ªä¸»æœºå™¨äººåœºæ™¯ç†è§£ä¸­çš„åº”ç”¨ï¼Œæå‡æœºå™¨äººæ„ŸçŸ¥ä¸å†³ç­–èƒ½åŠ›</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14020v1" onclick="toggleFavorite(this, '2512.14020v1', 'Deep Learning Perspective of Scene Understanding in Autonomous Robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>25</td>
  <td><a href="./papers/251214536v1-dasp-self-supervised-nighttime-monocular-depth-estimation-with-domai.html">DASP: Self-supervised Nighttime Monocular Depth Estimation with Domain Adaptation of Spatiotemporal Priors</a></td>
  <td>DASPï¼šåˆ©ç”¨æ—¶ç©ºå…ˆéªŒåŸŸé€‚åº”çš„è‡ªç›‘ç£å¤œé—´å•ç›®æ·±åº¦ä¼°è®¡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14536v1" onclick="toggleFavorite(this, '2512.14536v1', 'DASP: Self-supervised Nighttime Monocular Depth Estimation with Domain Adaptation of Spatiotemporal Priors')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>26</td>
  <td><a href="./papers/251214406v1-broadening-view-synthesis-of-dynamic-scenes-from-constrained-monocul.html">Broadening View Synthesis of Dynamic Scenes from Constrained Monocular Videos</a></td>
  <td>ExpanDyNeRFï¼šæ‰©å±•åŠ¨æ€åœºæ™¯è§†è§’åˆæˆï¼Œè§£å†³å•ç›®è§†é¢‘å¤§è§’åº¦æ¸²æŸ“å¤±çœŸé—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14406v1" onclick="toggleFavorite(this, '2512.14406v1', 'Broadening View Synthesis of Dynamic Scenes from Constrained Monocular Videos')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>27</td>
  <td><a href="./papers/251214087v1-gaussianplant-structure-aligned-gaussian-splatting-for-3d-reconstruc.html">GaussianPlant: Structure-aligned Gaussian Splatting for 3D Reconstruction of Plants</a></td>
  <td>æå‡ºGaussianPlantä»¥è§£å†³æ¤ç‰©3Dé‡å»ºä¸­çš„ç»“æ„ä¸å¤–è§‚åˆ†ç¦»é—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14087v1" onclick="toggleFavorite(this, '2512.14087v1', 'GaussianPlant: Structure-aligned Gaussian Splatting for 3D Reconstruction of Plants')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>28</td>
  <td><a href="./papers/251214032v1-ace-slam-scene-coordinate-regression-for-neural-implicit-real-time-s.html">ACE-SLAM: Scene Coordinate Regression for Neural Implicit Real-Time SLAM</a></td>
  <td>ACE-SLAMï¼šåŸºäºåœºæ™¯åæ ‡å›å½’çš„ç¥ç»éšå¼å®æ—¶SLAMç³»ç»Ÿ</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14032v1" onclick="toggleFavorite(this, '2512.14032v1', 'ACE-SLAM: Scene Coordinate Regression for Neural Implicit Real-Time SLAM')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>29</td>
  <td><a href="./papers/251214560v1-clnet-cross-view-correspondence-makes-a-stronger-geo-localizationer.html">CLNet: Cross-View Correspondence Makes a Stronger Geo-Localizationer</a></td>
  <td>æå‡ºCLNetï¼Œé€šè¿‡è·¨è§†è§’å¯¹åº”å…³ç³»å¢å¼ºå›¾åƒæ£€ç´¢åœ°ç†å®šä½</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14560v1" onclick="toggleFavorite(this, '2512.14560v1', 'CLNet: Cross-View Correspondence Makes a Stronger Geo-Localizationer')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>30</td>
  <td><a href="./papers/251214364v1-unified-semantic-transformer-for-3d-scene-understanding.html">Unified Semantic Transformer for 3D Scene Understanding</a></td>
  <td>æå‡ºUNITEï¼šç”¨äº3Dåœºæ™¯ç†è§£çš„ç»Ÿä¸€è¯­ä¹‰Transformeræ¨¡å‹</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14364v1" onclick="toggleFavorite(this, '2512.14364v1', 'Unified Semantic Transformer for 3D Scene Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>31</td>
  <td><a href="./papers/251214235v1-4d-radiff-latent-diffusion-for-4d-radar-point-cloud-generation.html">4D-RaDiff: Latent Diffusion for 4D Radar Point Cloud Generation</a></td>
  <td>æå‡º4D-RaDiffï¼Œåˆ©ç”¨æ½œåœ¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆ4Dé›·è¾¾ç‚¹äº‘ï¼Œæå‡ç›®æ ‡æ£€æµ‹æ€§èƒ½ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14235v1" onclick="toggleFavorite(this, '2512.14235v1', '4D-RaDiff: Latent Diffusion for 4D Radar Point Cloud Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>32</td>
  <td><a href="./papers/251214222v1-history-enhanced-two-stage-transformer-for-aerial-vision-and-languag.html">History-Enhanced Two-Stage Transformer for Aerial Vision-and-Language Navigation</a></td>
  <td>æå‡ºå†å²å¢å¼ºå‹ä¸¤é˜¶æ®µTransformerï¼Œè§£å†³æ— äººæœºè§†è§‰è¯­è¨€å¯¼èˆªä¸­å…¨å±€æ¨ç†ä¸å±€éƒ¨ç†è§£çš„å¹³è¡¡é—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14222v1" onclick="toggleFavorite(this, '2512.14222v1', 'History-Enhanced Two-Stage Transformer for Aerial Vision-and-Language Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>33</td>
  <td><a href="./papers/251214180v1-spherical-voronoi-directional-appearance-as-a-differentiable-partiti.html">Spherical Voronoi: Directional Appearance as a Differentiable Partition of the Sphere</a></td>
  <td>æå‡ºçƒé¢Voronoiæ–¹æ³•ï¼Œç”¨äº3Dé«˜æ–¯æº…å°„ä¸­é«˜æ•ˆå¯å¾®çš„æ–¹å‘å¤–è§‚å»ºæ¨¡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14180v1" onclick="toggleFavorite(this, '2512.14180v1', 'Spherical Voronoi: Directional Appearance as a Differentiable Partition of the Sphere')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>34</td>
  <td><a href="./papers/251214162v1-fastddhpose-towards-unified-efficient-and-disentangled-3d-human-pose.html">FastDDHPose: Towards Unified, Efficient, and Disentangled 3D Human Pose Estimation</a></td>
  <td>FastDDHPoseï¼šç»Ÿä¸€ã€é«˜æ•ˆã€è§£è€¦çš„3Däººä½“å§¿æ€ä¼°è®¡æ–¹æ³•</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14162v1" onclick="toggleFavorite(this, '2512.14162v1', 'FastDDHPose: Towards Unified, Efficient, and Disentangled 3D Human Pose Estimation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>35</td>
  <td><a href="./papers/251214126v1-consistent-instance-field-for-dynamic-scene-understanding.html">Consistent Instance Field for Dynamic Scene Understanding</a></td>
  <td>æå‡ºä¸€è‡´æ€§å®ä¾‹åœºï¼Œç”¨äºåŠ¨æ€åœºæ™¯ç†è§£ä¸­çš„æ—¶ç©ºä¸€è‡´æ€§åˆ†å‰²ä¸æŸ¥è¯¢ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14126v1" onclick="toggleFavorite(this, '2512.14126v1', 'Consistent Instance Field for Dynamic Scene Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>36</td>
  <td><a href="./papers/251214028v1-robust-single-shot-structured-light-3d-imaging-via-neural-feature-de.html">Robust Single-shot Structured Light 3D Imaging via Neural Feature Decoding</a></td>
  <td>æå‡ºåŸºäºç¥ç»ç‰¹å¾è§£ç çš„é²æ£’å•ç›®ç»“æ„å…‰3Dæˆåƒæ–¹æ³•ï¼Œæå‡å¤æ‚åœºæ™¯ä¸‹çš„æ·±åº¦ä¼°è®¡ç²¾åº¦ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14028v1" onclick="toggleFavorite(this, '2512.14028v1', 'Robust Single-shot Structured Light 3D Imaging via Neural Feature Decoding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>37</td>
  <td><a href="./papers/251214039v1-asap-textured-gaussians-enhancing-textured-gaussians-with-adaptive-s.html">ASAP-Textured Gaussians: Enhancing Textured Gaussians with Adaptive Sampling and Anisotropic Parameterization</a></td>
  <td>ASAP-Textured Gaussiansï¼šé€šè¿‡è‡ªé€‚åº”é‡‡æ ·å’Œå„å‘å¼‚æ€§å‚æ•°åŒ–å¢å¼ºçº¹ç†é«˜æ–¯æ¨¡å‹</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14039v1" onclick="toggleFavorite(this, '2512.14039v1', 'ASAP-Textured Gaussians: Enhancing Textured Gaussians with Adaptive Sampling and Anisotropic Parameterization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>38</td>
  <td><a href="./papers/251214274v1-tun-detecting-significant-points-in-persistence-diagrams-with-deep-l.html">TUN: Detecting Significant Points in Persistence Diagrams with Deep Learning</a></td>
  <td>æå‡ºTUNç½‘ç»œï¼Œåˆ©ç”¨æ·±åº¦å­¦ä¹ è‡ªåŠ¨æ£€æµ‹æŒä¹…åŒè°ƒå›¾ä¸­æ˜¾è‘—ç‰¹å¾ç‚¹ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14274v1" onclick="toggleFavorite(this, '2512.14274v1', 'TUN: Detecting Significant Points in Persistence Diagrams with Deep Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>39</td>
  <td><a href="./papers/251214273v1-zoom-zero-reinforced-coarse-to-fine-video-understanding-via-temporal.html">Zoom-Zero: Reinforced Coarse-to-Fine Video Understanding via Temporal Zoom-in</a></td>
  <td>Zoom-Zeroï¼šé€šè¿‡æ—¶é—´åŸŸç¼©æ”¾å¢å¼ºè§†é¢‘ç†è§£ï¼Œè§£å†³GVQAä¸­æ—¶åºå®šä½ä¸å‡†é—®é¢˜ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14273v1" onclick="toggleFavorite(this, '2512.14273v1', 'Zoom-Zero: Reinforced Coarse-to-Fine Video Understanding via Temporal Zoom-in')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>40</td>
  <td><a href="./papers/251214236v1-elastic3d-controllable-stereo-video-conversion-with-guided-latent-de.html">Elastic3D: Controllable Stereo Video Conversion with Guided Latent Decoding</a></td>
  <td>Elastic3Dï¼šåŸºäºå¼•å¯¼å¼æ½œåœ¨è§£ç çš„å¯æ§ç«‹ä½“è§†é¢‘è½¬æ¢æ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14236v1" onclick="toggleFavorite(this, '2512.14236v1', 'Elastic3D: Controllable Stereo Video Conversion with Guided Latent Decoding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (8 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>41</td>
  <td><a href="./papers/251214614v1-worldplay-towards-long-term-geometric-consistency-for-real-time-inte.html">WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling</a></td>
  <td>WorldPlayï¼šæå‡ºä¸€ç§å…·æœ‰é•¿æœŸå‡ ä½•ä¸€è‡´æ€§çš„å®æ—¶äº¤äº’å¼ä¸–ç•Œå»ºæ¨¡æ–¹æ³•ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14614v1" onclick="toggleFavorite(this, '2512.14614v1', 'WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>42</td>
  <td><a href="./papers/251214309v1-psmamba-progressive-self-supervised-vision-mamba-for-plant-disease-r.html">PSMamba: Progressive Self-supervised Vision Mamba for Plant Disease Recognition</a></td>
  <td>PSMambaï¼šä¸€ç§ç”¨äºæ¤ç‰©ç—…å®³è¯†åˆ«çš„æ¸è¿›å¼è‡ªç›‘ç£è§†è§‰Mambaæ¡†æ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14309v1" onclick="toggleFavorite(this, '2512.14309v1', 'PSMamba: Progressive Self-supervised Vision Mamba for Plant Disease Recognition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>43</td>
  <td><a href="./papers/251214442v1-a4-agent-an-agentic-framework-for-zero-shot-affordance-reasoning.html">A4-Agent: An Agentic Framework for Zero-Shot Affordance Reasoning</a></td>
  <td>æå‡ºA4-Agentï¼Œä¸€ä¸ªé›¶æ ·æœ¬å¯ä¾›æ€§æ¨ç†çš„Agentæ¡†æ¶ï¼Œæå‡æ³›åŒ–èƒ½åŠ›ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14442v1" onclick="toggleFavorite(this, '2512.14442v1', 'A4-Agent: An Agentic Framework for Zero-Shot Affordance Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>44</td>
  <td><a href="./papers/251214056v1-facedit-unified-talking-face-editing-and-generation-via-facial-motio.html">FacEDiT: Unified Talking Face Editing and Generation via Facial Motion Infilling</a></td>
  <td>FacEDiTï¼šé€šè¿‡é¢éƒ¨è¿åŠ¨å¡«å……å®ç°ç»Ÿä¸€çš„è¯´è¯äººè„¸ç¼–è¾‘ä¸ç”Ÿæˆ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14056v1" onclick="toggleFavorite(this, '2512.14056v1', 'FacEDiT: Unified Talking Face Editing and Generation via Facial Motion Infilling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>45</td>
  <td><a href="./papers/251214614v1-worldplay-towards-long-term-geometric-consistency-for-real-time-inte.html">WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling</a></td>
  <td>WorldPlayï¼šæå‡ºä¸€ç§å…·æœ‰é•¿æœŸå‡ ä½•ä¸€è‡´æ€§çš„å®æ—¶äº¤äº’å¼ä¸–ç•Œå»ºæ¨¡æ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14614v1" onclick="toggleFavorite(this, '2512.14614v1', 'WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>46</td>
  <td><a href="./papers/251214309v1-psmamba-progressive-self-supervised-vision-mamba-for-plant-disease-r.html">PSMamba: Progressive Self-supervised Vision Mamba for Plant Disease Recognition</a></td>
  <td>PSMambaï¼šä¸€ç§ç”¨äºæ¤ç‰©ç—…å®³è¯†åˆ«çš„æ¸è¿›å¼è‡ªç›‘ç£è§†è§‰Mambaæ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14309v1" onclick="toggleFavorite(this, '2512.14309v1', 'PSMamba: Progressive Self-supervised Vision Mamba for Plant Disease Recognition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>47</td>
  <td><a href="./papers/251214442v1-a4-agent-an-agentic-framework-for-zero-shot-affordance-reasoning.html">A4-Agent: An Agentic Framework for Zero-Shot Affordance Reasoning</a></td>
  <td>æå‡ºA4-Agentï¼šä¸€ç§ç”¨äºé›¶æ ·æœ¬å¯ä¾›æ€§æ¨ç†çš„Agentæ¡†æ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14442v1" onclick="toggleFavorite(this, '2512.14442v1', 'A4-Agent: An Agentic Framework for Zero-Shot Affordance Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>48</td>
  <td><a href="./papers/251214056v1-facedit-unified-talking-face-editing-and-generation-via-facial-motio.html">FacEDiT: Unified Talking Face Editing and Generation via Facial Motion Infilling</a></td>
  <td>FacEDiTï¼šé€šè¿‡é¢éƒ¨è¿åŠ¨å¡«å……å®ç°ç»Ÿä¸€çš„è¯´è¯äººè„¸ç¼–è¾‘ä¸ç”Ÿæˆ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14056v1" onclick="toggleFavorite(this, '2512.14056v1', 'FacEDiT: Unified Talking Face Editing and Generation via Facial Motion Infilling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (6 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>49</td>
  <td><a href="./papers/251214696v1-crisp-contact-guided-real2sim-from-monocular-video-with-planar-scene.html">CRISP: Contact-Guided Real2Sim from Monocular Video with Planar Scene Primitives</a></td>
  <td>CRISPï¼šåŸºäºå•ç›®è§†é¢‘å’Œå¹³é¢åœºæ™¯åŸè¯­çš„æ¥è§¦å¼•å¯¼Real2Simæ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14696v1" onclick="toggleFavorite(this, '2512.14696v1', 'CRISP: Contact-Guided Real2Sim from Monocular Video with Planar Scene Primitives')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>50</td>
  <td><a href="./papers/251214336v1-vector-prism-animating-vector-graphics-by-stratifying-semantic-struc.html">Vector Prism: Animating Vector Graphics by Stratifying Semantic Structure</a></td>
  <td>Vector Prismï¼šé€šè¿‡åˆ†å±‚è¯­ä¹‰ç»“æ„å®ç°çŸ¢é‡å›¾å½¢åŠ¨ç”»</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14336v1" onclick="toggleFavorite(this, '2512.14336v1', 'Vector Prism: Animating Vector Graphics by Stratifying Semantic Structure')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>51</td>
  <td><a href="./papers/251214217v1-draw2act-turning-depth-encoded-trajectories-into-robotic-demonstrati.html">DRAW2ACT: Turning Depth-Encoded Trajectories into Robotic Demonstration Videos</a></td>
  <td>DRAW2ACTï¼šæå‡ºæ·±åº¦æ„ŸçŸ¥çš„è½¨è¿¹æ¡ä»¶è§†é¢‘ç”Ÿæˆæ¡†æ¶ï¼Œç”¨äºæœºå™¨äººæ“ä½œæ¼”ç¤ºè§†é¢‘ç”Ÿæˆã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14217v1" onclick="toggleFavorite(this, '2512.14217v1', 'DRAW2ACT: Turning Depth-Encoded Trajectories into Robotic Demonstration Videos')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>52</td>
  <td><a href="./papers/251214696v1-crisp-contact-guided-real2sim-from-monocular-video-with-planar-scene.html">CRISP: Contact-Guided Real2Sim from Monocular Video with Planar Scene Primitives</a></td>
  <td>CRISPï¼šåŸºäºå•ç›®è§†é¢‘å’Œå¹³é¢åœºæ™¯åŸè¯­çš„æ¥è§¦å¼•å¯¼Real2Simæ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14696v1" onclick="toggleFavorite(this, '2512.14696v1', 'CRISP: Contact-Guided Real2Sim from Monocular Video with Planar Scene Primitives')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>53</td>
  <td><a href="./papers/251214336v1-vector-prism-animating-vector-graphics-by-stratifying-semantic-struc.html">Vector Prism: Animating Vector Graphics by Stratifying Semantic Structure</a></td>
  <td>æå‡ºVector Prismï¼Œé€šè¿‡åˆ†å±‚è¯­ä¹‰ç»“æ„å®ç°çŸ¢é‡å›¾å½¢åŠ¨ç”»</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14336v1" onclick="toggleFavorite(this, '2512.14336v1', 'Vector Prism: Animating Vector Graphics by Stratifying Semantic Structure')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>54</td>
  <td><a href="./papers/251214217v1-draw2act-turning-depth-encoded-trajectories-into-robotic-demonstrati.html">DRAW2ACT: Turning Depth-Encoded Trajectories into Robotic Demonstration Videos</a></td>
  <td>æå‡ºDRAW2ACTä»¥è§£å†³æœºå™¨äººæ¼”ç¤ºè§†é¢‘ç”Ÿæˆçš„å¯æ§æ€§é—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14217v1" onclick="toggleFavorite(this, '2512.14217v1', 'DRAW2ACT: Turning Depth-Encoded Trajectories into Robotic Demonstration Videos')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion">ğŸ”¬ æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (4 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>55</td>
  <td><a href="./papers/251214234v1-vibes-a-conversational-agent-with-behaviorally-intelligent-3d-virtua.html">ViBES: A Conversational Agent with Behaviorally-Intelligent 3D Virtual Body</a></td>
  <td>ViBESï¼šæå‡ºä¸€ç§å…·æœ‰è¡Œä¸ºæ™ºèƒ½çš„3Dè™šæ‹ŸåŒ–èº«å¯¹è¯ä»£ç†ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14234v1" onclick="toggleFavorite(this, '2512.14234v1', 'ViBES: A Conversational Agent with Behaviorally-Intelligent 3D Virtual Body')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>56</td>
  <td><a href="./papers/251214677v1-vasa-3d-lifelike-audio-driven-gaussian-head-avatars-from-a-single-im.html">VASA-3D: Lifelike Audio-Driven Gaussian Head Avatars from a Single Image</a></td>
  <td>VASA-3Dï¼šåŸºäºå•å¼ å›¾åƒçš„é€¼çœŸéŸ³é¢‘é©±åŠ¨é«˜æ–¯å¤´éƒ¨åŒ–èº«ç”Ÿæˆ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14677v1" onclick="toggleFavorite(this, '2512.14677v1', 'VASA-3D: Lifelike Audio-Driven Gaussian Head Avatars from a Single Image')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>57</td>
  <td><a href="./papers/251214234v1-vibes-a-conversational-agent-with-behaviorally-intelligent-3d-virtua.html">ViBES: A Conversational Agent with Behaviorally-Intelligent 3D Virtual Body</a></td>
  <td>ViBESï¼šä¸€ç§å…·æœ‰è¡Œä¸ºæ™ºèƒ½çš„3Dè™šæ‹ŸåŒ–èº«å¯¹è¯ä»£ç†</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14234v1" onclick="toggleFavorite(this, '2512.14234v1', 'ViBES: A Conversational Agent with Behaviorally-Intelligent 3D Virtual Body')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>58</td>
  <td><a href="./papers/251214677v1-vasa-3d-lifelike-audio-driven-gaussian-head-avatars-from-a-single-im.html">VASA-3D: Lifelike Audio-Driven Gaussian Head Avatars from a Single Image</a></td>
  <td>VASA-3Dï¼šåŸºäºå•å¼ å›¾åƒçš„é€¼çœŸéŸ³é¢‘é©±åŠ¨é«˜æ–¯å¤´éƒ¨åŒ–èº«ç”Ÿæˆ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14677v1" onclick="toggleFavorite(this, '2512.14677v1', 'VASA-3D: Lifelike Audio-Driven Gaussian Head Avatars from a Single Image')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CV é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)