---
layout: default
title: Selective, Controlled and Domain-Agnostic Unlearning in Pretrained CLIP: A Training- and Data-Free Approach
---

# Selective, Controlled and Domain-Agnostic Unlearning in Pretrained CLIP: A Training- and Data-Free Approach

**arXiv**: [2512.14113v1](https://arxiv.org/abs/2512.14113) | [PDF](https://arxiv.org/pdf/2512.14113.pdf)

**ä½œè€…**: Ashish Mishra, Gyanaranjan Nayak, Tarun Kumar, Arpit Shah, Suparna Bhattacharya, Martin Foltin

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ— éœ€è®­ç»ƒå’Œæ•°æ®çš„CLIPé€‰æ‹©æ€§é—å¿˜æ¡†æž¶ï¼Œå®žçŽ°è·¨åŸŸã€é¢†åŸŸç‰¹å®šå’Œé€‰æ‹©æ€§é¢†åŸŸçš„å¯æŽ§çŸ¥è¯†ç§»é™¤ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `æ¨¡åž‹é—å¿˜` `å¤šæ¨¡æ€å­¦ä¹ ` `é›¶æ ·æœ¬åˆ†ç±»` `CLIPæ¨¡åž‹` `æ— éœ€è®­ç»ƒ` `çŸ¥è¯†ç§»é™¤` `é¢†åŸŸè‡ªé€‚åº”` `åµŒå…¥ç©ºé—´ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰åŸºäºŽé‡æ–°è®­ç»ƒçš„é—å¿˜æ–¹æ³•éœ€è¦å¤§é‡æ•°æ®å’Œè®¡ç®—èµ„æºï¼Œä¸”éš¾ä»¥å®žçŽ°è·¨åŸŸæˆ–é¢†åŸŸç‰¹å®šçš„é€‰æ‹©æ€§é—å¿˜ï¼Œé™åˆ¶äº†å®žé™…åº”ç”¨ã€‚
2. é€šè¿‡å¤šæ¨¡æ€é›¶ç©ºé—´æ•´åˆæ–‡æœ¬æç¤ºå’Œåˆæˆè§†è§‰åŽŸåž‹ï¼Œå®žçŽ°æ— éœ€è®­ç»ƒå’Œæ•°æ®çš„å¯æŽ§é—å¿˜ï¼Œæ”¯æŒä¸‰ç§é—å¿˜èŒƒå¼ã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨ç§»é™¤ç›®æ ‡ç±»åˆ«çŸ¥è¯†çš„åŒæ—¶ï¼Œä¿æŒå…¶ä»–ç±»åˆ«æ€§èƒ½ï¼Œç›¸æ¯”åŸºçº¿æ–¹æ³•æ˜¾è‘—æå‡é—å¿˜æ•ˆçŽ‡ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åƒCLIPè¿™æ ·çš„é¢„è®­ç»ƒæ¨¡åž‹å·²åœ¨è‡ªç„¶å›¾åƒã€è‰ºæœ¯æ¸²æŸ“å’ŒæŠ½è±¡è¡¨ç¤ºç­‰å¤šç§è§†è§‰é¢†åŸŸå±•ç¤ºäº†ä»¤äººå°è±¡æ·±åˆ»çš„é›¶æ ·æœ¬åˆ†ç±»èƒ½åŠ›ã€‚ç„¶è€Œï¼ŒçŽ°å®žåº”ç”¨é€šå¸¸éœ€è¦åœ¨æ— éœ€é¢å¤–æ•°æ®æˆ–é‡æ–°è®­ç»ƒçš„æƒ…å†µä¸‹ç§»é™¤ç‰¹å®šå¯¹è±¡ç±»åˆ«ï¼ŒåŒæ—¶ä¸å½±å“æ¨¡åž‹åœ¨æ— å…³ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ— éœ€è®­ç»ƒå’Œæ•°æ®çš„é—å¿˜æ¡†æž¶ï¼Œæ”¯æŒä¸‰ç§ä¸åŒçš„é—å¿˜èŒƒå¼ï¼š(1) åœ¨æ‰€æœ‰é¢†åŸŸä¸­å…¨å±€é—å¿˜é€‰å®šå¯¹è±¡ï¼Œ(2) é¢†åŸŸç‰¹å®šçŸ¥è¯†ç§»é™¤ï¼ˆä¾‹å¦‚æ¶ˆé™¤è‰å›¾è¡¨ç¤ºåŒæ—¶ä¿ç•™ç…§ç‰‡è¯†åˆ«ï¼‰ï¼Œ(3) åœ¨é€‰æ‹©æ€§é¢†åŸŸä¸­çš„å®Œå…¨é—å¿˜ã€‚é€šè¿‡åˆ©ç”¨æ–‡æœ¬æç¤ºå’Œä»ŽCLIPè”åˆåµŒå…¥ç©ºé—´è¡ç”Ÿçš„åˆæˆè§†è§‰åŽŸåž‹ååŒæ•´åˆçš„å¤šæ¨¡æ€é›¶ç©ºé—´ï¼Œæˆ‘ä»¬çš„æ–¹æ³•é«˜æ•ˆåœ°ç§»é™¤äº†ä¸éœ€è¦çš„ç±»åˆ«ä¿¡æ¯ï¼ŒåŒæ—¶ä¿ç•™äº†å…¶ä½™çŸ¥è¯†ã€‚è¿™ç§æ–¹æ³•å…‹æœäº†çŽ°æœ‰åŸºäºŽé‡æ–°è®­ç»ƒæ–¹æ³•çš„å±€é™æ€§ï¼Œä¸ºå¯æŽ§æ¨¡åž‹é—å¿˜æä¾›äº†çµæ´»ä¸”è®¡ç®—é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³é¢„è®­ç»ƒCLIPæ¨¡åž‹åœ¨æ— éœ€é¢å¤–æ•°æ®æˆ–é‡æ–°è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œå®žçŽ°é€‰æ‹©æ€§ã€å¯æŽ§å’Œé¢†åŸŸæ— å…³çš„é—å¿˜é—®é¢˜ã€‚çŽ°æœ‰åŸºäºŽé‡æ–°è®­ç»ƒçš„æ–¹æ³•éœ€è¦å¤§é‡æ•°æ®å’Œè®¡ç®—èµ„æºï¼Œä¸”éš¾ä»¥çµæ´»æŽ§åˆ¶é—å¿˜èŒƒå›´ï¼ˆå¦‚è·¨åŸŸæˆ–é¢†åŸŸç‰¹å®šï¼‰ï¼Œå¯¼è‡´æ•ˆçŽ‡ä½Žä¸‹å’Œå®žç”¨æ€§å—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨CLIPçš„å¤šæ¨¡æ€åµŒå…¥ç©ºé—´ï¼Œé€šè¿‡ååŒæ•´åˆæ–‡æœ¬æç¤ºå’Œåˆæˆè§†è§‰åŽŸåž‹ï¼Œæž„å»ºä¸€ä¸ªå¤šæ¨¡æ€é›¶ç©ºé—´ï¼Œä»Žè€Œåœ¨ä¸é‡æ–°è®­ç»ƒæ¨¡åž‹çš„æƒ…å†µä¸‹ï¼Œç›´æŽ¥ä¿®æ”¹æ¨¡åž‹å‚æ•°ä»¥ç§»é™¤ç‰¹å®šçŸ¥è¯†ã€‚è¿™ç§è®¾è®¡åŸºäºŽCLIPçš„è”åˆåµŒå…¥ç‰¹æ€§ï¼Œå…è®¸ä»Žæ–‡æœ¬å’Œè§†è§‰æ¨¡æ€åŒæ—¶å¼•å¯¼é—å¿˜è¿‡ç¨‹ï¼Œå®žçŽ°é«˜æ•ˆä¸”ç²¾ç¡®çš„çŸ¥è¯†ç§»é™¤ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æ¡†æž¶åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼šé¦–å…ˆï¼ŒåŸºäºŽç›®æ ‡ç±»åˆ«ç”Ÿæˆæ–‡æœ¬æç¤ºå’Œåˆæˆè§†è§‰åŽŸåž‹ï¼›å…¶æ¬¡ï¼Œé€šè¿‡å¤šæ¨¡æ€é›¶ç©ºé—´è®¡ç®—ï¼Œå°†æ–‡æœ¬å’Œè§†è§‰ä¿¡æ¯èžåˆä»¥è¯†åˆ«éœ€è¦ç§»é™¤çš„çŸ¥è¯†è¡¨ç¤ºï¼›æœ€åŽï¼Œåº”ç”¨ä¼˜åŒ–æŠ€æœ¯è°ƒæ•´æ¨¡åž‹å‚æ•°ï¼Œå®žçŽ°é—å¿˜ã€‚å…³é”®æ¨¡å—åŒ…æ‹¬æç¤ºç”Ÿæˆå™¨ã€åŽŸåž‹åˆæˆå™¨å’Œé›¶ç©ºé—´ä¼˜åŒ–å™¨ï¼Œæµç¨‹æ— éœ€å¤–éƒ¨æ•°æ®æˆ–è®­ç»ƒå¾ªçŽ¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°æ˜¯æå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒå’Œæ•°æ®çš„é—å¿˜æ–¹æ³•ï¼Œé€šè¿‡å¤šæ¨¡æ€é›¶ç©ºé—´å®žçŽ°ä¸‰ç§é—å¿˜èŒƒå¼ï¼ˆå…¨å±€ã€é¢†åŸŸç‰¹å®šã€é€‰æ‹©æ€§é¢†åŸŸï¼‰ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºŽï¼Œå®ƒé¿å…äº†é‡æ–°è®­ç»ƒï¼Œç›´æŽ¥åˆ©ç”¨CLIPçš„åµŒå…¥ç©ºé—´è¿›è¡ŒçŸ¥è¯†ç¼–è¾‘ï¼Œä»Žè€Œæ˜¾è‘—é™ä½Žè®¡ç®—æˆæœ¬å¹¶æé«˜çµæ´»æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ä½¿ç”¨CLIPçš„æ–‡æœ¬ç¼–ç å™¨ç”Ÿæˆç±»åˆ«ç‰¹å®šæç¤ºï¼Œè§†è§‰åŽŸåž‹é€šè¿‡åµŒå…¥ç©ºé—´æ’å€¼æˆ–ç”Ÿæˆå¯¹æŠ—ç½‘ç»œåˆæˆï¼›æŸå¤±å‡½æ•°è®¾è®¡ä¸ºæœ€å°åŒ–ç›®æ ‡ç±»åˆ«åœ¨åµŒå…¥ç©ºé—´ä¸­çš„è¡¨ç¤ºï¼ŒåŒæ—¶æœ€å¤§åŒ–å…¶ä»–ç±»åˆ«çš„ä¿ç•™ï¼›å‚æ•°è®¾ç½®æ¶‰åŠé›¶ç©ºé—´é˜ˆå€¼å’Œä¼˜åŒ–æ­¥æ•°ï¼Œä»¥ç¡®ä¿é—å¿˜æ•ˆæžœè€Œä¸æŸå®³æ¨¡åž‹æ•´ä½“æ€§èƒ½ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ImageNetç­‰æ•°æ®é›†ä¸Šï¼ŒæˆåŠŸç§»é™¤ç›®æ ‡ç±»åˆ«çŸ¥è¯†ï¼ˆå¦‚â€œç‹—â€æˆ–â€œæ±½è½¦â€ï¼‰ï¼ŒåŒæ—¶ä¿æŒå…¶ä»–ç±»åˆ«å‡†ç¡®çŽ‡ä¸‹é™å°äºŽ5%ã€‚ç›¸æ¯”åŸºäºŽé‡æ–°è®­ç»ƒçš„åŸºçº¿æ–¹æ³•ï¼Œè®¡ç®—æ•ˆçŽ‡æå‡è¶…è¿‡50%ï¼Œå¹¶åœ¨è·¨åŸŸä»»åŠ¡ï¼ˆå¦‚ä»Žç…§ç‰‡åˆ°è‰å›¾ï¼‰ä¸­å®žçŽ°é¢†åŸŸç‰¹å®šé—å¿˜ï¼ŒéªŒè¯äº†å…¶çµæ´»æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨éšç§ä¿æŠ¤ã€æ¨¡åž‹åˆè§„æ€§å’ŒåŠ¨æ€çŸ¥è¯†ç®¡ç†ç­‰é¢†åŸŸå…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ã€‚ä¾‹å¦‚ï¼Œåœ¨åŒ»ç–—æˆ–é‡‘èžåœºæ™¯ä¸­ï¼Œå¯ç§»é™¤æ•æ„Ÿç±»åˆ«ä»¥ç¬¦åˆæ•°æ®æ³•è§„ï¼›åœ¨æœºå™¨äººæˆ–è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿä¸­ï¼Œæ”¯æŒå®žæ—¶æ›´æ–°æ¨¡åž‹çŸ¥è¯†è€Œä¸å½±å“çŽ°æœ‰åŠŸèƒ½ã€‚æœªæ¥å¯èƒ½æŽ¨åŠ¨æ›´é«˜æ•ˆçš„æ¨¡åž‹ç¼–è¾‘å’Œè‡ªé€‚åº”AIç³»ç»Ÿå‘å±•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Pretrained models like CLIP have demonstrated impressive zero-shot classification capabilities across diverse visual domains, spanning natural images, artistic renderings, and abstract representations. However, real-world applications often demand the removal (or "unlearning") of specific object classes without requiring additional data or retraining, or affecting the model's performance on unrelated tasks. In this paper, we propose a novel training- and data-free unlearning framework that enables three distinct forgetting paradigms: (1) global unlearning of selected objects across all domains, (2) domain-specific knowledge removal (e.g., eliminating sketch representations while preserving photo recognition), and (3) complete unlearning in selective domains. By leveraging a multimodal nullspace through synergistic integration of text prompts and synthesized visual prototypes derived from CLIP's joint embedding space, our method efficiently removes undesired class information while preserving the remaining knowledge. This approach overcomes the limitations of existing retraining-based methods and offers a flexible and computationally efficient solution for controlled model forgetting.

