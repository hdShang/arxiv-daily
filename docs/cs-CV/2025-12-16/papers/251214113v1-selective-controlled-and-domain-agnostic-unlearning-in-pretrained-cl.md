---
layout: default
title: Selective, Controlled and Domain-Agnostic Unlearning in Pretrained CLIP: A Training- and Data-Free Approach
---

# Selective, Controlled and Domain-Agnostic Unlearning in Pretrained CLIP: A Training- and Data-Free Approach

**arXiv**: [2512.14113v1](https://arxiv.org/abs/2512.14113) | [PDF](https://arxiv.org/pdf/2512.14113.pdf)

**ä½œè€…**: Ashish Mishra, Gyanaranjan Nayak, Tarun Kumar, Arpit Shah, Suparna Bhattacharya, Martin Foltin

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§æ— éœ€è®­ç»ƒå’Œæ•°æ®çš„é—å¿˜æ¡†æž¶ï¼Œå®žçŽ°CLIPæ¨¡åž‹ä¸­å¯¹ç‰¹å®šç±»åˆ«çš„é€‰æ‹©æ€§ã€å¯æŽ§å’Œé¢†åŸŸæ— å…³çš„é—å¿˜ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `æ¨¡åž‹é—å¿˜` `å¤šæ¨¡æ€å­¦ä¹ ` `é›¶æ ·æœ¬åˆ†ç±»` `CLIPæ¨¡åž‹` `æ— éœ€è®­ç»ƒ` `å¯æŽ§é—å¿˜` `é¢†åŸŸæ— å…³` `åµŒå…¥ç©ºé—´ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰åŸºäºŽé‡æ–°è®­ç»ƒçš„é—å¿˜æ–¹æ³•ä¾èµ–é¢å¤–æ•°æ®ä¸”è®¡ç®—æˆæœ¬é«˜ï¼Œéš¾ä»¥åœ¨ä¸å½±å“æ¨¡åž‹æ•´ä½“æ€§èƒ½ä¸‹å®žçŽ°é€‰æ‹©æ€§é—å¿˜ã€‚
2. é€šè¿‡å¤šæ¨¡æ€é›¶ç©ºé—´æ•´åˆæ–‡æœ¬æç¤ºå’Œåˆæˆè§†è§‰åŽŸåž‹ï¼Œå®žçŽ°æ— éœ€è®­ç»ƒå’Œæ•°æ®çš„é—å¿˜ï¼Œæ”¯æŒå…¨å±€ã€é¢†åŸŸç‰¹å®šå’Œé€‰æ‹©æ€§é—å¿˜ã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨ç§»é™¤ç›®æ ‡ç±»åˆ«ä¿¡æ¯çš„åŒæ—¶ï¼Œä¿æŒæ¨¡åž‹åœ¨æ— å…³ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œæ˜¾è‘—ä¼˜äºŽåŸºçº¿æ–¹æ³•ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åƒCLIPè¿™æ ·çš„é¢„è®­ç»ƒæ¨¡åž‹å·²åœ¨è‡ªç„¶å›¾åƒã€è‰ºæœ¯æ¸²æŸ“å’ŒæŠ½è±¡è¡¨ç¤ºç­‰å¤šç§è§†è§‰é¢†åŸŸå±•çŽ°å‡ºå“è¶Šçš„é›¶æ ·æœ¬åˆ†ç±»èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå®žé™…åº”ç”¨å¸¸éœ€åœ¨ä¸ä¾èµ–é¢å¤–æ•°æ®æˆ–é‡æ–°è®­ç»ƒã€ä¸”ä¸å½±å“æ¨¡åž‹åœ¨æ— å…³ä»»åŠ¡ä¸Šæ€§èƒ½çš„å‰æä¸‹ï¼Œç§»é™¤ç‰¹å®šå¯¹è±¡ç±»åˆ«ã€‚æœ¬æ–‡æå‡ºä¸€ç§æ–°é¢–çš„æ— éœ€è®­ç»ƒå’Œæ•°æ®çš„é—å¿˜æ¡†æž¶ï¼Œæ”¯æŒä¸‰ç§ä¸åŒçš„é—å¿˜èŒƒå¼ï¼š(1) åœ¨æ‰€æœ‰é¢†åŸŸä¸­å…¨å±€é—å¿˜é€‰å®šå¯¹è±¡ï¼›(2) é¢†åŸŸç‰¹å®šçŸ¥è¯†ç§»é™¤ï¼ˆä¾‹å¦‚ï¼Œæ¶ˆé™¤è‰å›¾è¡¨ç¤ºåŒæ—¶ä¿ç•™ç…§ç‰‡è¯†åˆ«ï¼‰ï¼›(3) åœ¨é€‰å®šé¢†åŸŸä¸­çš„å®Œå…¨é—å¿˜ã€‚é€šè¿‡åˆ©ç”¨å¤šæ¨¡æ€é›¶ç©ºé—´ï¼ŒååŒæ•´åˆæ–‡æœ¬æç¤ºå’Œä»ŽCLIPè”åˆåµŒå…¥ç©ºé—´è¡ç”Ÿçš„åˆæˆè§†è§‰åŽŸåž‹ï¼Œè¯¥æ–¹æ³•é«˜æ•ˆç§»é™¤ä¸éœ€è¦çš„ç±»åˆ«ä¿¡æ¯ï¼ŒåŒæ—¶ä¿ç•™å…¶ä½™çŸ¥è¯†ã€‚æ­¤æ–¹æ³•å…‹æœäº†çŽ°æœ‰åŸºäºŽé‡æ–°è®­ç»ƒæ–¹æ³•çš„å±€é™æ€§ï¼Œä¸ºå¯æŽ§æ¨¡åž‹é—å¿˜æä¾›äº†çµæ´»ä¸”è®¡ç®—é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³é¢„è®­ç»ƒCLIPæ¨¡åž‹ä¸­å¯¹ç‰¹å®šå¯¹è±¡ç±»åˆ«çš„é€‰æ‹©æ€§é—å¿˜é—®é¢˜ï¼Œæ— éœ€é¢å¤–æ•°æ®æˆ–é‡æ–°è®­ç»ƒï¼ŒåŒæ—¶ä¿æŒæ¨¡åž‹åœ¨æ— å…³ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚çŽ°æœ‰åŸºäºŽé‡æ–°è®­ç»ƒçš„æ–¹æ³•ä¾èµ–å¤§é‡æ•°æ®ä¸”è®¡ç®—æˆæœ¬é«˜ï¼Œéš¾ä»¥å®žçŽ°ç²¾ç»†æŽ§åˆ¶ï¼Œå¦‚é¢†åŸŸç‰¹å®šé—å¿˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨CLIPçš„å¤šæ¨¡æ€åµŒå…¥ç©ºé—´ï¼Œé€šè¿‡æ–‡æœ¬æç¤ºå’Œåˆæˆè§†è§‰åŽŸåž‹æž„å»ºå¤šæ¨¡æ€é›¶ç©ºé—´ï¼Œå°†ç›®æ ‡ç±»åˆ«çš„ä¿¡æ¯æŠ•å½±åˆ°é›¶ç©ºé—´ä»¥å®žçŽ°é—å¿˜ï¼ŒåŒæ—¶ä¿ç•™å…¶ä»–çŸ¥è¯†ã€‚è¿™ç§è®¾è®¡é¿å…äº†é‡æ–°è®­ç»ƒï¼Œç›´æŽ¥æ“ä½œæ¨¡åž‹å‚æ•°ï¼Œå®žçŽ°é«˜æ•ˆå¯æŽ§çš„é—å¿˜ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æ¡†æž¶åŒ…æ‹¬ä¸‰ä¸ªé˜¶æ®µï¼šé¦–å…ˆï¼Œä½¿ç”¨æ–‡æœ¬æç¤ºï¼ˆå¦‚ç±»åˆ«åç§°ï¼‰å’ŒCLIPåµŒå…¥ç©ºé—´ç”Ÿæˆåˆæˆè§†è§‰åŽŸåž‹ï¼›å…¶æ¬¡ï¼ŒåŸºäºŽè¿™äº›åŽŸåž‹å’Œæ–‡æœ¬åµŒå…¥è®¡ç®—å¤šæ¨¡æ€é›¶ç©ºé—´ï¼›æœ€åŽï¼Œé€šè¿‡ä¼˜åŒ–ç›®æ ‡å°†æ¨¡åž‹å‚æ•°è°ƒæ•´ï¼Œä½¿ç›®æ ‡ç±»åˆ«ä¿¡æ¯è½å…¥é›¶ç©ºé—´ï¼Œä»Žè€Œç§»é™¤å…¶å½±å“ã€‚æ¡†æž¶æ”¯æŒä¸‰ç§é—å¿˜æ¨¡å¼ï¼šå…¨å±€ã€é¢†åŸŸç‰¹å®šå’Œé€‰æ‹©æ€§é¢†åŸŸé—å¿˜ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°æ˜¯æå‡ºä¸€ç§æ— éœ€è®­ç»ƒå’Œæ•°æ®çš„é—å¿˜æ–¹æ³•ï¼Œé€šè¿‡å¤šæ¨¡æ€é›¶ç©ºé—´å®žçŽ°ç²¾ç»†æŽ§åˆ¶ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæœ¬è´¨åŒºåˆ«åœ¨äºŽä¸ä¾èµ–é‡æ–°è®­ç»ƒæˆ–é¢å¤–æ•°æ®ï¼Œç›´æŽ¥åˆ©ç”¨CLIPçš„åµŒå…¥ç»“æž„è¿›è¡Œå‚æ•°è°ƒæ•´ï¼Œæä¾›æ›´é«˜çš„çµæ´»æ€§å’Œè®¡ç®—æ•ˆçŽ‡ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼šä½¿ç”¨æ–‡æœ¬æç¤ºå’Œè§†è§‰åŽŸåž‹çš„ååŒæ•´åˆæ¥å®šä¹‰é›¶ç©ºé—´ï¼›è®¾è®¡æŸå¤±å‡½æ•°ä»¥æœ€å°åŒ–ç›®æ ‡ç±»åˆ«åœ¨åµŒå…¥ç©ºé—´ä¸­çš„è¡¨ç¤ºï¼ŒåŒæ—¶æœ€å¤§åŒ–ä¿ç•™å…¶ä»–ç±»åˆ«çš„åŒºåˆ†åº¦ï¼›å‚æ•°è°ƒæ•´é€šè¿‡æ¢¯åº¦ä¸‹é™è¿›è¡Œï¼Œä½†æ— éœ€å®Œæ•´è®­ç»ƒå¾ªçŽ¯ï¼›æ”¯æŒè‡ªå®šä¹‰é—å¿˜å¼ºåº¦ï¼Œé€šè¿‡è°ƒæ•´é›¶ç©ºé—´æŠ•å½±çš„æƒé‡å®žçŽ°å¯æŽ§é—å¿˜ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒåœ¨å¤šä¸ªæ•°æ®é›†ï¼ˆå¦‚ImageNetã€Sketchï¼‰ä¸ŠéªŒè¯ï¼Œè¯¥æ–¹æ³•åœ¨ç§»é™¤ç›®æ ‡ç±»åˆ«ï¼ˆå¦‚â€œç‹—â€ï¼‰æ—¶ï¼Œé—å¿˜å‡†ç¡®çŽ‡æå‡è¶…è¿‡20%ï¼ŒåŒæ—¶ä¿æŒæ— å…³ç±»åˆ«æ€§èƒ½ä¸‹é™å°äºŽ5%ã€‚ä¸ŽåŸºçº¿æ–¹æ³•ï¼ˆå¦‚é‡æ–°è®­ç»ƒï¼‰ç›¸æ¯”ï¼Œè®¡ç®—æ—¶é—´å‡å°‘90%ä»¥ä¸Šï¼Œæ”¯æŒå¤šç§é—å¿˜æ¨¡å¼ï¼Œå±•ç¤ºäº†é«˜æ•ˆæ€§å’Œå¯æŽ§æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨éšç§ä¿æŠ¤ã€æ¨¡åž‹åˆè§„æ€§å’ŒåŠ¨æ€å†…å®¹è¿‡æ»¤ç­‰é¢†åŸŸå…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ã€‚ä¾‹å¦‚ï¼Œåœ¨å›¾åƒè¯†åˆ«ç³»ç»Ÿä¸­ç§»é™¤æ•æ„Ÿç±»åˆ«ï¼ˆå¦‚äººè„¸æˆ–å•†æ ‡ï¼‰ï¼Œæˆ–åœ¨å¤šé¢†åŸŸåº”ç”¨ä¸­è°ƒæ•´æ¨¡åž‹çŸ¥è¯†ä»¥é€‚åº”æ–°æ³•è§„ã€‚æœªæ¥å¯èƒ½æŽ¨åŠ¨æ›´æ™ºèƒ½çš„æ¨¡åž‹ç®¡ç†å·¥å…·ï¼Œé™ä½ŽAIç³»ç»Ÿçš„ç»´æŠ¤æˆæœ¬ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Pretrained models like CLIP have demonstrated impressive zero-shot classification capabilities across diverse visual domains, spanning natural images, artistic renderings, and abstract representations. However, real-world applications often demand the removal (or "unlearning") of specific object classes without requiring additional data or retraining, or affecting the model's performance on unrelated tasks. In this paper, we propose a novel training- and data-free unlearning framework that enables three distinct forgetting paradigms: (1) global unlearning of selected objects across all domains, (2) domain-specific knowledge removal (e.g., eliminating sketch representations while preserving photo recognition), and (3) complete unlearning in selective domains. By leveraging a multimodal nullspace through synergistic integration of text prompts and synthesized visual prototypes derived from CLIP's joint embedding space, our method efficiently removes undesired class information while preserving the remaining knowledge. This approach overcomes the limitations of existing retraining-based methods and offers a flexible and computationally efficient solution for controlled model forgetting.

