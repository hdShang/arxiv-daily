---
layout: default
title: ViBES: A Conversational Agent with Behaviorally-Intelligent 3D Virtual Body
---

# ViBES: A Conversational Agent with Behaviorally-Intelligent 3D Virtual Body

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.14234" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.14234</a>
  <a href="https://arxiv.org/pdf/2512.14234.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14234" onclick="toggleFavorite(this, '2512.14234', 'ViBES: A Conversational Agent with Behaviorally-Intelligent 3D Virtual Body')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Juze Zhang, Changan Chen, Xin Chen, Heng Yu, Tiange Xiang, Ali Sartaz Khan, Shrinidhi K. Lakshmikanth, Ehsan Adeli

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-18

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ViBESï¼šä¸€ä¸ªå…·æœ‰è¡Œä¸ºæ™ºèƒ½çš„3Dè™šæ‹ŸåŒ–èº«å¯¹è¯ä»£ç†**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¯¹è¯ä»£ç†` `3Dè™šæ‹ŸåŒ–èº«` `è¡Œä¸ºæ™ºèƒ½` `å¤šæ¨¡æ€èåˆ` `è¯­éŸ³è¯­è¨€è¡Œä¸ºæ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¯¹è¯ç³»ç»Ÿåœ¨æ¨¡æ‹Ÿäººç±»äº¤æµæ—¶ï¼Œéš¾ä»¥å®ç°è¯­è¨€ã€éŸµå¾‹å’Œè‚¢ä½“è¯­è¨€çš„è‡ªç„¶åŒæ­¥ï¼Œç¼ºä¹è‡ªä¸»å†³ç­–èƒ½åŠ›ã€‚
2. ViBESé€šè¿‡ä¸€ä¸ªè¯­éŸ³-è¯­è¨€-è¡Œä¸ºï¼ˆSLBï¼‰æ¨¡å‹ï¼Œè”åˆè§„åˆ’è¯­è¨€å’Œè¿åŠ¨ï¼Œå®ç°å¯¹è¯é©±åŠ¨çš„èº«ä½“åŠ¨ä½œã€‚
3. å®éªŒè¡¨æ˜ï¼ŒViBESåœ¨å¤šè½®å¯¹è¯ä¸­ï¼Œå¯¹è¯-è¿åŠ¨å¯¹é½å’Œè¡Œä¸ºè´¨é‡æ–¹é¢ï¼Œä¼˜äºç°æœ‰çš„è¯­éŸ³ååŒå’Œæ–‡æœ¬åˆ°è¿åŠ¨åŸºçº¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äººç±»äº¤æµæœ¬è´¨ä¸Šæ˜¯å¤šæ¨¡æ€å’Œç¤¾äº¤çš„ï¼šè¯­è¨€ã€éŸµå¾‹å’Œè‚¢ä½“è¯­è¨€å…±åŒä¼ é€’æ„å›¾ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰ç³»ç»Ÿå°†äººç±»è¡Œä¸ºå»ºæ¨¡ä¸ºç¿»è¯‘ä»»åŠ¡ï¼Œä¾‹å¦‚è¯­éŸ³ååŒæ‰‹åŠ¿æˆ–æ–‡æœ¬åˆ°åŠ¨ä½œï¼Œå°†å›ºå®šçš„è¯­å¥æ˜ å°„åˆ°åŠ¨ä½œç‰‡æ®µï¼Œè€Œä¸éœ€è¦ä»£ç†è‡ªä¸»å†³ç­–ä½•æ—¶ç§»åŠ¨ã€åšä»€ä¹ˆæˆ–å¦‚ä½•åœ¨å¤šè½®å¯¹è¯ä¸­é€‚åº”ã€‚è¿™å¯¼è‡´äº†è„†å¼±çš„æ—¶åºã€è–„å¼±çš„ç¤¾äº¤åŸºç¡€ä»¥åŠç¢ç‰‡åŒ–çš„å †æ ˆï¼Œå…¶ä¸­è¯­éŸ³ã€æ–‡æœ¬å’ŒåŠ¨ä½œè¢«å­¤ç«‹åœ°è®­ç»ƒæˆ–æ¨æ–­ã€‚æˆ‘ä»¬ä»‹ç»äº†ViBESï¼ˆè¯­éŸ³è¡Œä¸ºè¡¨è¾¾å’ŒåŒæ­¥ï¼‰ï¼Œä¸€ä¸ªå¯¹è¯å¼3Dä»£ç†ï¼Œå®ƒè”åˆè§„åˆ’è¯­è¨€å’Œè¿åŠ¨ï¼Œå¹¶æ‰§è¡Œå¯¹è¯æ¡ä»¶ä¸‹çš„èº«ä½“åŠ¨ä½œã€‚å…·ä½“æ¥è¯´ï¼ŒViBESæ˜¯ä¸€ä¸ªå…·æœ‰æ··åˆæ¨¡æ€ä¸“å®¶ï¼ˆMoMEï¼‰ä¸»å¹²çš„è¯­éŸ³-è¯­è¨€-è¡Œä¸ºï¼ˆSLBï¼‰æ¨¡å‹ï¼šç”¨äºè¯­éŸ³ã€é¢éƒ¨è¡¨æƒ…å’Œèº«ä½“è¿åŠ¨çš„æ¨¡æ€åˆ’åˆ†Transformerä¸“å®¶ã€‚è¯¥æ¨¡å‹å¤„ç†äº¤é”™çš„å¤šæ¨¡æ€tokenæµï¼Œå¹¶é€šè¿‡æ¨¡æ€è¿›è¡Œç¡¬è·¯ç”±ï¼ˆå‚æ•°æŒ‰ä¸“å®¶åˆ’åˆ†ï¼‰ï¼ŒåŒæ—¶é€šè¿‡è·¨ä¸“å®¶æ³¨æ„åŠ›å…±äº«ä¿¡æ¯ã€‚é€šè¿‡åˆ©ç”¨å¼ºå¤§çš„é¢„è®­ç»ƒè¯­éŸ³è¯­è¨€æ¨¡å‹ï¼Œè¯¥ä»£ç†æ”¯æŒæ··åˆä¸»åŠ¨äº¤äº’ï¼šç”¨æˆ·å¯ä»¥åœ¨å¯¹è¯ä¸­è¯´è¯ã€æ‰“å­—æˆ–å‘å‡ºèº«ä½“åŠ¨ä½œæŒ‡ä»¤ï¼Œå¹¶ä¸”ç³»ç»Ÿå…¬å¼€å¯æ§çš„è¡Œä¸ºé’©å­ä»¥è¿›è¡Œæµå¼å“åº”ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥åœ¨å¤šè½®å¯¹è¯ä¸­ä»¥å¯¹è¯-è¿åŠ¨å¯¹é½å’Œè¡Œä¸ºè´¨é‡çš„è‡ªåŠ¨æŒ‡æ ‡è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œå¹¶è§‚å¯Ÿåˆ°ç›¸å¯¹äºå¼ºå¤§çš„è¯­éŸ³ååŒå’Œæ–‡æœ¬åˆ°è¿åŠ¨åŸºçº¿çš„æŒç»­æå‡ã€‚ViBESè¶…è¶Šäº†â€œè¯­éŸ³æ¡ä»¶è¿åŠ¨ç”Ÿæˆâ€ï¼Œæœç€ä»£ç†è™šæ‹ŸåŒ–èº«å‘å±•ï¼Œå…¶ä¸­è¯­è¨€ã€éŸµå¾‹å’Œè¿åŠ¨è¢«è”åˆç”Ÿæˆï¼Œä»è€Œå®ç°å¯æ§çš„ã€å…·æœ‰ç¤¾äº¤èƒ½åŠ›çš„3Däº¤äº’ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰å¯¹è¯ç³»ç»Ÿé€šå¸¸å°†äººç±»è¡Œä¸ºå»ºæ¨¡ä¸ºç®€å•çš„ç¿»è¯‘ä»»åŠ¡ï¼Œä¾‹å¦‚è¯­éŸ³åˆ°æ‰‹åŠ¿æˆ–æ–‡æœ¬åˆ°åŠ¨ä½œçš„æ˜ å°„ï¼Œç¼ºä¹å¯¹ä½•æ—¶ç§»åŠ¨ã€åšä»€ä¹ˆä»¥åŠå¦‚ä½•é€‚åº”å¤šè½®å¯¹è¯çš„è‡ªä¸»å†³ç­–èƒ½åŠ›ã€‚è¿™å¯¼è‡´ç”ŸæˆåŠ¨ä½œçš„æ—¶åºä¸è‡ªç„¶ï¼Œç¤¾äº¤äº’åŠ¨èƒ½åŠ›å¼±ï¼Œå¹¶ä¸”è¯­éŸ³ã€æ–‡æœ¬å’ŒåŠ¨ä½œçš„è®­ç»ƒæ˜¯å­¤ç«‹çš„ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šViBESçš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªèƒ½å¤Ÿè”åˆè§„åˆ’è¯­è¨€å’Œè¿åŠ¨çš„å¯¹è¯ä»£ç†ï¼Œä½¿å…¶èƒ½å¤Ÿæ ¹æ®å¯¹è¯å†…å®¹è‡ªä¸»åœ°ç”Ÿæˆåˆé€‚çš„èº«ä½“åŠ¨ä½œã€‚é€šè¿‡å°†è¯­éŸ³ã€è¯­è¨€å’Œè¡Œä¸ºæ•´åˆåˆ°ä¸€ä¸ªç»Ÿä¸€çš„æ¨¡å‹ä¸­ï¼ŒViBESèƒ½å¤Ÿæ›´å¥½åœ°æ¨¡æ‹Ÿäººç±»äº¤æµçš„è‡ªç„¶æ€§å’Œæµç•…æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šViBESé‡‡ç”¨äº†ä¸€ä¸ªè¯­éŸ³-è¯­è¨€-è¡Œä¸ºï¼ˆSLBï¼‰æ¨¡å‹ï¼Œå…¶ä¸»å¹²æ˜¯ä¸€ä¸ªæ··åˆæ¨¡æ€ä¸“å®¶ï¼ˆMoMEï¼‰æ¶æ„ã€‚è¯¥æ¶æ„åŒ…å«é’ˆå¯¹è¯­éŸ³ã€é¢éƒ¨è¡¨æƒ…å’Œèº«ä½“è¿åŠ¨çš„æ¨¡æ€åˆ’åˆ†Transformerä¸“å®¶ã€‚æ¨¡å‹å¤„ç†äº¤é”™çš„å¤šæ¨¡æ€tokenæµï¼Œå¹¶é€šè¿‡æ¨¡æ€è¿›è¡Œç¡¬è·¯ç”±ï¼ŒåŒæ—¶é€šè¿‡è·¨ä¸“å®¶æ³¨æ„åŠ›æœºåˆ¶å…±äº«ä¿¡æ¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šViBESçš„å…³é”®åˆ›æ–°åœ¨äºå…¶è”åˆè§„åˆ’è¯­è¨€å’Œè¿åŠ¨çš„èƒ½åŠ›ï¼Œä»¥åŠå…¶æ··åˆæ¨¡æ€ä¸“å®¶ï¼ˆMoMEï¼‰æ¶æ„ã€‚MoMEæ¶æ„å…è®¸æ¨¡å‹é’ˆå¯¹ä¸åŒçš„æ¨¡æ€ä½¿ç”¨ä¸åŒçš„ä¸“å®¶ç½‘ç»œï¼Œä»è€Œæ›´å¥½åœ°æ•æ‰ä¸åŒæ¨¡æ€çš„ç‰¹å¾ã€‚åŒæ—¶ï¼Œè·¨ä¸“å®¶æ³¨æ„åŠ›æœºåˆ¶ä½¿å¾—ä¸åŒæ¨¡æ€ä¹‹é—´å¯ä»¥ç›¸äº’å½±å“ï¼Œä»è€Œå®ç°æ›´è‡ªç„¶çš„å¯¹è¯å’ŒåŠ¨ä½œç”Ÿæˆã€‚

**å…³é”®è®¾è®¡**ï¼šViBESåˆ©ç”¨äº†å¼ºå¤§çš„é¢„è®­ç»ƒè¯­éŸ³è¯­è¨€æ¨¡å‹ï¼Œä»¥æ”¯æŒæ··åˆä¸»åŠ¨äº¤äº’ã€‚ç”¨æˆ·å¯ä»¥é€šè¿‡è¯­éŸ³ã€æ–‡æœ¬æˆ–èº«ä½“åŠ¨ä½œæŒ‡ä»¤ä¸ä»£ç†è¿›è¡Œäº¤äº’ã€‚ç³»ç»Ÿå…¬å¼€å¯æ§çš„è¡Œä¸ºé’©å­ï¼Œä»¥è¿›è¡Œæµå¼å“åº”ã€‚æ¨¡å‹çš„è®­ç»ƒç›®æ ‡æ˜¯æœ€å¤§åŒ–å¯¹è¯-è¿åŠ¨å¯¹é½å’Œè¡Œä¸ºè´¨é‡ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.14234/x1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.14234/x2.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.14234/x3.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

ViBESåœ¨å¤šè½®å¯¹è¯ä¸­è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼Œå¹¶ä½¿ç”¨è‡ªåŠ¨æŒ‡æ ‡è¯„ä¼°äº†å¯¹è¯-è¿åŠ¨å¯¹é½å’Œè¡Œä¸ºè´¨é‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒViBESåœ¨è¿™äº›æŒ‡æ ‡ä¸Šå‡ä¼˜äºç°æœ‰çš„è¯­éŸ³ååŒå’Œæ–‡æœ¬åˆ°è¿åŠ¨åŸºçº¿ã€‚è¿™è¡¨æ˜ViBESèƒ½å¤Ÿç”Ÿæˆæ›´è‡ªç„¶ã€æ›´å…·ç¤¾äº¤èƒ½åŠ›çš„å¯¹è¯å’ŒåŠ¨ä½œã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ViBESå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚è™šæ‹ŸåŠ©æ‰‹ã€åœ¨çº¿æ•™è‚²ã€æ¸¸æˆå’Œå¨±ä¹ç­‰é¢†åŸŸã€‚å®ƒå¯ä»¥ç”¨äºåˆ›å»ºæ›´å…·å¸å¼•åŠ›å’Œäº’åŠ¨æ€§çš„è™šæ‹Ÿè§’è‰²ï¼Œä»è€Œæ”¹å–„ç”¨æˆ·ä½“éªŒã€‚æ­¤å¤–ï¼ŒViBESè¿˜å¯ä»¥ç”¨äºç ”ç©¶äººç±»äº¤æµçš„æœ¬è´¨ï¼Œå¹¶ä¸ºå¼€å‘æ›´æ™ºèƒ½çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿæä¾›æ–°çš„æ€è·¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Human communication is inherently multimodal and social: words, prosody, and body language jointly carry intent. Yet most prior systems model human behavior as a translation task co-speech gesture or text-to-motion that maps a fixed utterance to motion clips-without requiring agentic decision-making about when to move, what to do, or how to adapt across multi-turn dialogue. This leads to brittle timing, weak social grounding, and fragmented stacks where speech, text, and motion are trained or inferred in isolation. We introduce ViBES (Voice in Behavioral Expression and Synchrony), a conversational 3D agent that jointly plans language and movement and executes dialogue-conditioned body actions. Concretely, ViBES is a speech-language-behavior (SLB) model with a mixture-of-modality-experts (MoME) backbone: modality-partitioned transformer experts for speech, facial expression, and body motion. The model processes interleaved multimodal token streams with hard routing by modality (parameters are split per expert), while sharing information through cross-expert attention. By leveraging strong pretrained speech-language models, the agent supports mixed-initiative interaction: users can speak, type, or issue body-action directives mid-conversation, and the system exposes controllable behavior hooks for streaming responses. We further benchmark on multi-turn conversation with automatic metrics of dialogue-motion alignment and behavior quality, and observe consistent gains over strong co-speech and text-to-motion baselines. ViBES goes beyond "speech-conditioned motion generation" toward agentic virtual bodies where language, prosody, and movement are jointly generated, enabling controllable, socially competent 3D interaction. Code and data will be made available at:this http URL

