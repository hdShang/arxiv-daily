---
layout: default
title: Improving Semantic Uncertainty Quantification in LVLMs with Semantic Gaussian Processes
---

# Improving Semantic Uncertainty Quantification in LVLMs with Semantic Gaussian Processes

**arXiv**: [2512.14177v1](https://arxiv.org/abs/2512.14177) | [PDF](https://arxiv.org/pdf/2512.14177.pdf)

**ä½œè€…**: Joseph Hoche, Andrei Bursuc, David Brellmann, Gilles Louppe, Pavel Izmailov, Angela Yao, Gianni Franchi

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè¯­ä¹‰é«˜æ–¯è¿‡ç¨‹ä¸ç¡®å®šæ€§(SGPU)æ–¹æ³•ï¼Œæå‡LVLMä¸­è¯­ä¹‰ä¸ç¡®å®šæ€§é‡åŒ–çš„å¯é æ€§ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **åŠ¨ä½œç”Ÿæˆä¸Žç‰©ç†åŠ¨ç”» (Animation & Physics)**

**å…³é”®è¯**: `è¯­ä¹‰ä¸ç¡®å®šæ€§é‡åŒ–` `å¤§åž‹è§†è§‰-è¯­è¨€æ¨¡åž‹` `é«˜æ–¯è¿‡ç¨‹` `ç‰¹å¾è°±åˆ†æž` `ä¸ç¡®å®šæ€§ä¼°è®¡` `è´å¶æ–¯æ–¹æ³•` `è¯­ä¹‰åµŒå…¥`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è¯­ä¹‰ä¸ç¡®å®šæ€§é‡åŒ–æ–¹æ³•ä¾èµ–è„†å¼±çš„èšç±»ï¼Œæ˜“å—æŽªè¾žå˜åŒ–å½±å“ï¼Œå¯¼è‡´ä¸å‡†ç¡®çš„è¯­ä¹‰ä¸€è‡´æ€§è¯„ä¼°ã€‚
2. SGPUé€šè¿‡åˆ†æžç­”æ¡ˆåµŒå…¥çš„å‡ ä½•ç»“æž„ï¼Œé¿å…äº†æ˜¾å¼çš„èšç±»ï¼Œåˆ©ç”¨é«˜æ–¯è¿‡ç¨‹å­¦ä¹ è¯­ä¹‰ä¸€è‡´æ€§ä¸Žä¸ç¡®å®šæ€§çš„æ˜ å°„å…³ç³»ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒSGPUåœ¨å¤šä¸ªæ•°æ®é›†å’Œæ¨¡åž‹ä¸Šå®žçŽ°äº†æœ€å…ˆè¿›çš„æ ¡å‡†å’ŒåŒºåˆ†æ€§èƒ½ï¼Œå¹¶å…·æœ‰è·¨æ¨¡åž‹å’Œæ¨¡æ€çš„è¿ç§»èƒ½åŠ›ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§åž‹è§†è§‰-è¯­è¨€æ¨¡åž‹(LVLMs)ç»å¸¸äº§ç”Ÿçœ‹ä¼¼åˆç†ä½†ä¸å¯é çš„è¾“å‡ºï¼Œå› æ­¤é²æ£’çš„ä¸ç¡®å®šæ€§ä¼°è®¡è‡³å…³é‡è¦ã€‚ç›®å‰è¯­ä¹‰ä¸ç¡®å®šæ€§ä¼°è®¡çš„ç ”ç©¶ä¾èµ–äºŽå¤–éƒ¨æ¨¡åž‹æ¥èšç±»å¤šä¸ªé‡‡æ ·å“åº”ï¼Œå¹¶æµ‹é‡å®ƒä»¬çš„è¯­ä¹‰ä¸€è‡´æ€§ã€‚ç„¶è€Œï¼Œè¿™äº›èšç±»æ–¹æ³•é€šå¸¸å¾ˆè„†å¼±ï¼Œå¯¹ç»†å¾®çš„æŽªè¾žå˜åŒ–é«˜åº¦æ•æ„Ÿï¼Œå¹¶ä¸”å¯èƒ½é”™è¯¯åœ°åˆ†ç»„æˆ–åˆ†ç¦»è¯­ä¹‰ç›¸ä¼¼çš„ç­”æ¡ˆï¼Œå¯¼è‡´ä¸å¯é çš„ä¸ç¡®å®šæ€§ä¼°è®¡ã€‚æˆ‘ä»¬æå‡ºäº†è¯­ä¹‰é«˜æ–¯è¿‡ç¨‹ä¸ç¡®å®šæ€§(SGPU)ï¼Œè¿™æ˜¯ä¸€ä¸ªè´å¶æ–¯æ¡†æž¶ï¼Œé€šè¿‡åˆ†æžç­”æ¡ˆåµŒå…¥çš„å‡ ä½•ç»“æž„æ¥é‡åŒ–è¯­ä¹‰ä¸ç¡®å®šæ€§ï¼Œé¿å…äº†è„†å¼±çš„èšç±»ã€‚SGPUå°†ç”Ÿæˆçš„ç­”æ¡ˆæ˜ å°„åˆ°å¯†é›†çš„è¯­ä¹‰ç©ºé—´ä¸­ï¼Œè®¡ç®—å…¶åµŒå…¥çš„GramçŸ©é˜µï¼Œå¹¶é€šè¿‡ç‰¹å¾è°±æ€»ç»“å…¶è¯­ä¹‰é…ç½®ã€‚ç„¶åŽï¼Œå°†è¯¥é¢‘è°±è¡¨ç¤ºè¾“å…¥åˆ°é«˜æ–¯è¿‡ç¨‹åˆ†ç±»å™¨ä¸­ï¼Œè¯¥åˆ†ç±»å™¨å­¦ä¹ å°†è¯­ä¹‰ä¸€è‡´æ€§æ¨¡å¼æ˜ å°„åˆ°é¢„æµ‹ä¸ç¡®å®šæ€§ï¼Œå¹¶ä¸”å¯ä»¥åº”ç”¨äºŽé»‘ç›’å’Œç™½ç›’è®¾ç½®ã€‚åœ¨VQAã€å›¾åƒåˆ†ç±»å’Œæ–‡æœ¬QAçš„å…«ä¸ªæ•°æ®é›†ä¸Šï¼Œå¯¹å…­ä¸ªLLMå’ŒLVLMè¿›è¡Œè¯„ä¼°ï¼ŒSGPUå§‹ç»ˆå¦‚ä¸€åœ°å®žçŽ°äº†æœ€å…ˆè¿›çš„æ ¡å‡†(ECE)å’ŒåŒºåˆ†(AUROC, AUARC)æ€§èƒ½ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥è¡¨æ˜Žï¼ŒSGPUå¯ä»¥åœ¨æ¨¡åž‹å’Œæ¨¡æ€ä¹‹é—´è¿ç§»ï¼Œè¡¨æ˜Žå…¶é¢‘è°±è¡¨ç¤ºæ•èŽ·äº†è¯­ä¹‰ä¸ç¡®å®šæ€§çš„ä¸€èˆ¬æ¨¡å¼ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰çš„å¤§åž‹è§†è§‰-è¯­è¨€æ¨¡åž‹ï¼ˆLVLMsï¼‰åœ¨ç”Ÿæˆç­”æ¡ˆæ—¶ï¼Œè™½ç„¶è¾“å‡ºçœ‹èµ·æ¥åˆç†ï¼Œä½†å…¶å¯é æ€§éš¾ä»¥ä¿è¯ã€‚çŽ°æœ‰çš„è¯­ä¹‰ä¸ç¡®å®šæ€§é‡åŒ–æ–¹æ³•ä¾èµ–äºŽå¯¹å¤šä¸ªé‡‡æ ·ç­”æ¡ˆè¿›è¡Œèšç±»ï¼Œç„¶åŽè¯„ä¼°è¿™äº›ç°‡çš„è¯­ä¹‰ä¸€è‡´æ€§ã€‚ç„¶è€Œï¼Œè¿™äº›èšç±»æ–¹æ³•å¯¹æŽªè¾žçš„ç»†å¾®å˜åŒ–éžå¸¸æ•æ„Ÿï¼Œå®¹æ˜“å°†è¯­ä¹‰ç›¸ä¼¼çš„ç­”æ¡ˆé”™è¯¯åœ°åˆ†ç¦»ï¼Œæˆ–è€…å°†è¯­ä¹‰ä¸åŒçš„ç­”æ¡ˆé”™è¯¯åœ°èšç±»åœ¨ä¸€èµ·ï¼Œå¯¼è‡´ä¸å‡†ç¡®çš„ä¸ç¡®å®šæ€§ä¼°è®¡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é¿å…æ˜¾å¼çš„èšç±»è¿‡ç¨‹ï¼Œè€Œæ˜¯å°†ç­”æ¡ˆåµŒå…¥åˆ°é«˜ç»´è¯­ä¹‰ç©ºé—´ä¸­ï¼Œå¹¶åˆ†æžè¿™äº›åµŒå…¥çš„å‡ ä½•ç»“æž„æ¥æŽ¨æ–­è¯­ä¹‰ä¸ç¡®å®šæ€§ã€‚é€šè¿‡è®¡ç®—åµŒå…¥çš„GramçŸ©é˜µï¼Œå¹¶æå–å…¶ç‰¹å¾è°±ï¼Œå¯ä»¥æ•æ‰ç­”æ¡ˆä¹‹é—´çš„è¯­ä¹‰å…³ç³»ï¼Œè€Œæ— éœ€è¿›è¡Œç¡¬èšç±»ã€‚ç„¶åŽï¼Œåˆ©ç”¨é«˜æ–¯è¿‡ç¨‹å­¦ä¹ è¿™äº›ç‰¹å¾è°±ä¸Žé¢„æµ‹ä¸ç¡®å®šæ€§ä¹‹é—´çš„æ˜ å°„å…³ç³»ã€‚è¿™ç§æ–¹æ³•æ›´åŠ é²æ£’ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†æŽªè¾žå˜åŒ–å¸¦æ¥çš„å½±å“ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šSGPUæ–¹æ³•ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) **ç­”æ¡ˆç”Ÿæˆ**ï¼šä½¿ç”¨LVLMç”Ÿæˆå¤šä¸ªå€™é€‰ç­”æ¡ˆã€‚2) **è¯­ä¹‰åµŒå…¥**ï¼šå°†æ¯ä¸ªç­”æ¡ˆåµŒå…¥åˆ°é«˜ç»´è¯­ä¹‰ç©ºé—´ä¸­ï¼Œä¾‹å¦‚ä½¿ç”¨é¢„è®­ç»ƒçš„å¥å­åµŒå…¥æ¨¡åž‹ã€‚3) **GramçŸ©é˜µè®¡ç®—**ï¼šè®¡ç®—æ‰€æœ‰ç­”æ¡ˆåµŒå…¥ä¹‹é—´çš„GramçŸ©é˜µï¼Œè¯¥çŸ©é˜µåæ˜ äº†ç­”æ¡ˆä¹‹é—´çš„è¯­ä¹‰ç›¸ä¼¼æ€§ã€‚4) **ç‰¹å¾è°±æå–**ï¼šå¯¹GramçŸ©é˜µè¿›è¡Œç‰¹å¾åˆ†è§£ï¼Œæå–å…¶ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡ï¼Œå½¢æˆç‰¹å¾è°±ã€‚5) **é«˜æ–¯è¿‡ç¨‹åˆ†ç±»**ï¼šå°†ç‰¹å¾è°±ä½œä¸ºè¾“å…¥ï¼Œè®­ç»ƒä¸€ä¸ªé«˜æ–¯è¿‡ç¨‹åˆ†ç±»å™¨ï¼Œç”¨äºŽé¢„æµ‹æ¯ä¸ªç­”æ¡ˆçš„ä¸ç¡®å®šæ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šSGPUæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºŽä½¿ç”¨GramçŸ©é˜µçš„ç‰¹å¾è°±æ¥è¡¨ç¤ºç­”æ¡ˆçš„è¯­ä¹‰ç»“æž„ï¼Œä»Žè€Œé¿å…äº†å¯¹ç­”æ¡ˆè¿›è¡Œæ˜¾å¼èšç±»ã€‚è¿™ç§æ–¹æ³•æ›´åŠ é²æ£’ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†æŽªè¾žå˜åŒ–å¸¦æ¥çš„å½±å“ã€‚æ­¤å¤–ï¼Œä½¿ç”¨é«˜æ–¯è¿‡ç¨‹åˆ†ç±»å™¨æ¥å­¦ä¹ ç‰¹å¾è°±ä¸Žä¸ç¡®å®šæ€§ä¹‹é—´çš„æ˜ å°„å…³ç³»ï¼Œä½¿å¾—æ¨¡åž‹èƒ½å¤Ÿæ›´å¥½åœ°æ³›åŒ–åˆ°æ–°çš„æ•°æ®å’Œæ¨¡åž‹ä¸Šã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è¯­ä¹‰åµŒå…¥é˜¶æ®µï¼Œå¯ä»¥ä½¿ç”¨å„ç§é¢„è®­ç»ƒçš„å¥å­åµŒå…¥æ¨¡åž‹ï¼Œä¾‹å¦‚Sentence-BERTã€‚GramçŸ©é˜µçš„è®¡ç®—å¯ä»¥ä½¿ç”¨ä¸åŒçš„æ ¸å‡½æ•°ï¼Œä¾‹å¦‚çº¿æ€§æ ¸æˆ–RBFæ ¸ã€‚é«˜æ–¯è¿‡ç¨‹åˆ†ç±»å™¨çš„å‚æ•°éœ€è¦æ ¹æ®å…·ä½“çš„æ•°æ®é›†è¿›è¡Œè°ƒæ•´ï¼Œä¾‹å¦‚æ ¸å‡½æ•°çš„å‚æ•°å’Œå™ªå£°æ°´å¹³ã€‚æŸå¤±å‡½æ•°é€šå¸¸é‡‡ç”¨è´Ÿå¯¹æ•°ä¼¼ç„¶å‡½æ•°ï¼Œå¹¶å¯ä»¥ä½¿ç”¨æ¢¯åº¦ä¸‹é™ç­‰ä¼˜åŒ–ç®—æ³•è¿›è¡Œè®­ç»ƒã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

SGPUåœ¨å…«ä¸ªæ•°æ®é›†ä¸Šï¼Œå¯¹å…­ä¸ªLLMå’ŒLVLMè¿›è¡Œäº†è¯„ä¼°ï¼Œåœ¨VQAã€å›¾åƒåˆ†ç±»å’Œæ–‡æœ¬QAç­‰ä»»åŠ¡ä¸Šï¼ŒSGPUå§‹ç»ˆå¦‚ä¸€åœ°å®žçŽ°äº†æœ€å…ˆè¿›çš„æ ¡å‡†(ECE)å’ŒåŒºåˆ†(AUROC, AUARC)æ€§èƒ½ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒSGPUèƒ½å¤Ÿæœ‰æ•ˆåœ°é‡åŒ–LVLMçš„è¯­ä¹‰ä¸ç¡®å®šæ€§ï¼Œå¹¶ä¸”å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

SGPUå¯åº”ç”¨äºŽä»»ä½•éœ€è¦å¯é ä¸ç¡®å®šæ€§ä¼°è®¡çš„LVLMåº”ç”¨ä¸­ï¼Œä¾‹å¦‚è‡ªåŠ¨é©¾é©¶ã€åŒ»ç–—è¯Šæ–­å’Œé‡‘èžé£Žé™©è¯„ä¼°ã€‚é€šè¿‡æä¾›æ›´å‡†ç¡®çš„ä¸ç¡®å®šæ€§é‡åŒ–ï¼ŒSGPUå¯ä»¥å¸®åŠ©ç”¨æˆ·æ›´å¥½åœ°ç†è§£å’Œä¿¡ä»»LVLMçš„è¾“å‡ºï¼Œä»Žè€Œåšå‡ºæ›´æ˜Žæ™ºçš„å†³ç­–ã€‚æ­¤å¤–ï¼ŒSGPUçš„è·¨æ¨¡åž‹å’Œæ¨¡æ€è¿ç§»èƒ½åŠ›ä½¿å…¶èƒ½å¤Ÿå¿«é€Ÿéƒ¨ç½²åˆ°æ–°çš„åº”ç”¨åœºæ™¯ä¸­ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Large Vision-Language Models (LVLMs) often produce plausible but unreliable outputs, making robust uncertainty estimation essential. Recent work on semantic uncertainty estimates relies on external models to cluster multiple sampled responses and measure their semantic consistency. However, these clustering methods are often fragile, highly sensitive to minor phrasing variations, and can incorrectly group or separate semantically similar answers, leading to unreliable uncertainty estimates. We propose Semantic Gaussian Process Uncertainty (SGPU), a Bayesian framework that quantifies semantic uncertainty by analyzing the geometric structure of answer embeddings, avoiding brittle clustering. SGPU maps generated answers into a dense semantic space, computes the Gram matrix of their embeddings, and summarizes their semantic configuration via the eigenspectrum. This spectral representation is then fed into a Gaussian Process Classifier that learns to map patterns of semantic consistency to predictive uncertainty, and that can be applied in both black-box and white-box settings. Across six LLMs and LVLMs on eight datasets spanning VQA, image classification, and textual QA, SGPU consistently achieves state-of-the-art calibration (ECE) and discriminative (AUROC, AUARC) performance. We further show that SGPU transfers across models and modalities, indicating that its spectral representation captures general patterns of semantic uncertainty.

