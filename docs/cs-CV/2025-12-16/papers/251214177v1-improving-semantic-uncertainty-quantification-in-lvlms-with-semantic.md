---
layout: default
title: Improving Semantic Uncertainty Quantification in LVLMs with Semantic Gaussian Processes
---

# Improving Semantic Uncertainty Quantification in LVLMs with Semantic Gaussian Processes

**arXiv**: [2512.14177v1](https://arxiv.org/abs/2512.14177) | [PDF](https://arxiv.org/pdf/2512.14177.pdf)

**ä½œè€…**: Joseph Hoche, Andrei Bursuc, David Brellmann, Gilles Louppe, Pavel Izmailov, Angela Yao, Gianni Franchi

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè¯­ä¹‰é«˜æ–¯è¿‡ç¨‹ä¸ç¡®å®šæ€§æ¡†æž¶ï¼Œä»¥è§£å†³å¤§åž‹è§†è§‰è¯­è¨€æ¨¡åž‹è¯­ä¹‰ä¸ç¡®å®šæ€§é‡åŒ–ä¸­çš„èšç±»è„†å¼±æ€§é—®é¢˜ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **è§†è§‰é‡Œç¨‹è®¡**

**å…³é”®è¯**: `è¯­ä¹‰ä¸ç¡®å®šæ€§é‡åŒ–` `å¤§åž‹è§†è§‰è¯­è¨€æ¨¡åž‹` `é«˜æ–¯è¿‡ç¨‹åˆ†ç±»å™¨` `ç‰¹å¾è°±åˆ†æž` `è´å¶æ–¯æ¡†æž¶` `å¤šæ¨¡æ€è¿ç§»` `æ¨¡åž‹æ ¡å‡†` `åµŒå…¥å‡ ä½•ç»“æž„`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•ä¾èµ–å¤–éƒ¨èšç±»æ¨¡åž‹ï¼Œå¯¹æŽªè¾žå˜åŒ–æ•æ„Ÿï¼Œæ˜“é”™è¯¯åˆ†ç»„è¯­ä¹‰ç›¸ä¼¼ç­”æ¡ˆï¼Œå¯¼è‡´ä¸ç¡®å®šæ€§ä¼°è®¡ä¸å¯é ã€‚
2. æå‡ºSGPUæ¡†æž¶ï¼Œé€šè¿‡åˆ†æžç­”æ¡ˆåµŒå…¥çš„å‡ ä½•ç»“æž„ï¼Œé¿å…èšç±»ï¼Œä½¿ç”¨ç‰¹å¾è°±å’Œé«˜æ–¯è¿‡ç¨‹åˆ†ç±»å™¨é‡åŒ–è¯­ä¹‰ä¸ç¡®å®šæ€§ã€‚
3. åœ¨å¤šä¸ªæ•°æ®é›†å’Œæ¨¡åž‹ä¸Šï¼ŒSGPUåœ¨æ ‡å®šå’Œåˆ¤åˆ«æ€§èƒ½æ–¹é¢è¾¾åˆ°æœ€å…ˆè¿›æ°´å¹³ï¼Œå¹¶å±•ç¤ºè·¨æ¨¡åž‹å’Œæ¨¡æ€çš„è¿ç§»èƒ½åŠ›ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§åž‹è§†è§‰è¯­è¨€æ¨¡åž‹å¸¸äº§ç”Ÿçœ‹ä¼¼åˆç†ä½†ä¸å¯é çš„è¾“å‡ºï¼Œå› æ­¤ç¨³å¥çš„ä¸ç¡®å®šæ€§ä¼°è®¡è‡³å…³é‡è¦ã€‚çŽ°æœ‰çš„è¯­ä¹‰ä¸ç¡®å®šæ€§ä¼°è®¡æ–¹æ³•ä¾èµ–å¤–éƒ¨æ¨¡åž‹å¯¹å¤šä¸ªé‡‡æ ·å“åº”è¿›è¡Œèšç±»å¹¶æµ‹é‡å…¶è¯­ä¹‰ä¸€è‡´æ€§ï¼Œä½†è¿™äº›èšç±»æ–¹æ³•å¾€å¾€è„†å¼±ï¼Œå¯¹ç»†å¾®çš„æŽªè¾žå˜åŒ–é«˜åº¦æ•æ„Ÿï¼Œå¯èƒ½é”™è¯¯åœ°åˆ†ç»„æˆ–åˆ†ç¦»è¯­ä¹‰ç›¸ä¼¼çš„ç­”æ¡ˆï¼Œå¯¼è‡´ä¸å¯é çš„ä¸ç¡®å®šæ€§ä¼°è®¡ã€‚æˆ‘ä»¬æå‡ºäº†è¯­ä¹‰é«˜æ–¯è¿‡ç¨‹ä¸ç¡®å®šæ€§ï¼Œè¿™æ˜¯ä¸€ä¸ªè´å¶æ–¯æ¡†æž¶ï¼Œé€šè¿‡åˆ†æžç­”æ¡ˆåµŒå…¥çš„å‡ ä½•ç»“æž„æ¥é‡åŒ–è¯­ä¹‰ä¸ç¡®å®šæ€§ï¼Œé¿å…äº†è„†å¼±çš„èšç±»ã€‚SGPUå°†ç”Ÿæˆçš„ç­”æ¡ˆæ˜ å°„åˆ°å¯†é›†çš„è¯­ä¹‰ç©ºé—´ï¼Œè®¡ç®—å…¶åµŒå…¥çš„GramçŸ©é˜µï¼Œå¹¶é€šè¿‡ç‰¹å¾è°±æ€»ç»“å…¶è¯­ä¹‰é…ç½®ã€‚è¿™ç§è°±è¡¨ç¤ºéšåŽè¢«è¾“å…¥åˆ°é«˜æ–¯è¿‡ç¨‹åˆ†ç±»å™¨ä¸­ï¼Œè¯¥åˆ†ç±»å™¨å­¦ä¹ å°†è¯­ä¹‰ä¸€è‡´æ€§æ¨¡å¼æ˜ å°„åˆ°é¢„æµ‹ä¸ç¡®å®šæ€§ï¼Œå¹¶å¯åœ¨é»‘ç›’å’Œç™½ç›’è®¾ç½®ä¸­åº”ç”¨ã€‚åœ¨æ¶µç›–VQAã€å›¾åƒåˆ†ç±»å’Œæ–‡æœ¬QAçš„å…«ä¸ªæ•°æ®é›†ä¸Šï¼Œå¯¹å…­ä¸ªLLMå’ŒLVLMè¿›è¡Œæµ‹è¯•ï¼ŒSGPUåœ¨æ ‡å®šå’Œåˆ¤åˆ«æ€§èƒ½æ–¹é¢å‡è¾¾åˆ°æœ€å…ˆè¿›æ°´å¹³ã€‚æˆ‘ä»¬è¿˜å±•ç¤ºäº†SGPUèƒ½å¤Ÿè·¨æ¨¡åž‹å’Œæ¨¡æ€è¿ç§»ï¼Œè¡¨æ˜Žå…¶è°±è¡¨ç¤ºæ•æ‰äº†è¯­ä¹‰ä¸ç¡®å®šæ€§çš„ä¸€èˆ¬æ¨¡å¼ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

SGPUæ˜¯ä¸€ä¸ªè´å¶æ–¯æ¡†æž¶ï¼Œæ•´ä½“æµç¨‹åŒ…æ‹¬ï¼šå°†æ¨¡åž‹ç”Ÿæˆçš„å¤šä¸ªç­”æ¡ˆæ˜ å°„åˆ°è¯­ä¹‰ç©ºé—´ï¼Œè®¡ç®—å…¶åµŒå…¥çš„GramçŸ©é˜µï¼Œæå–ç‰¹å¾è°±ä½œä¸ºè¯­ä¹‰é…ç½®çš„ç´§å‡‘è¡¨ç¤ºã€‚å…³é”®åˆ›æ–°åœ¨äºŽé¿å…è„†å¼±çš„èšç±»æ­¥éª¤ï¼Œç›´æŽ¥åˆ©ç”¨åµŒå…¥çš„å‡ ä½•ç»“æž„ï¼Œé€šè¿‡é«˜æ–¯è¿‡ç¨‹åˆ†ç±»å™¨å­¦ä¹ ä»Žè°±æ¨¡å¼åˆ°é¢„æµ‹ä¸ç¡®å®šæ€§çš„æ˜ å°„ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºŽï¼Œå®ƒä¸ä¾èµ–å¤–éƒ¨èšç±»æ¨¡åž‹ï¼Œè€Œæ˜¯åŸºäºŽåµŒå…¥çš„ç»Ÿè®¡ç‰¹æ€§ï¼Œæé«˜äº†é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ï¼Œé€‚ç”¨äºŽé»‘ç›’å’Œç™½ç›’è®¾ç½®ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨å…«ä¸ªæ•°æ®é›†å’Œå…­ä¸ªæ¨¡åž‹ä¸Šï¼ŒSGPUåœ¨æ ‡å®šè¯¯å·®å’Œåˆ¤åˆ«æŒ‡æ ‡æ–¹é¢å‡è¾¾åˆ°æœ€å…ˆè¿›æ€§èƒ½ï¼Œä¾‹å¦‚åœ¨VQAä»»åŠ¡ä¸­æ˜¾è‘—é™ä½Žé”™è¯¯çŽ‡ï¼Œå¹¶æˆåŠŸè¿ç§»åˆ°ä¸åŒæ¨¡æ€ä»»åŠ¡ï¼ŒéªŒè¯äº†å…¶é€šç”¨æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å¯åº”ç”¨äºŽéœ€è¦é«˜å¯é æ€§çš„å¤§åž‹è§†è§‰è¯­è¨€æ¨¡åž‹åœºæ™¯ï¼Œå¦‚è‡ªåŠ¨é©¾é©¶ä¸­çš„è§†è§‰é—®ç­”ã€åŒ»ç–—å›¾åƒåˆ†æžã€å†…å®¹å®¡æ ¸å’Œæ™ºèƒ½å®¢æœï¼Œé€šè¿‡æ”¹è¿›ä¸ç¡®å®šæ€§ä¼°è®¡ï¼Œæå‡æ¨¡åž‹è¾“å‡ºçš„å¯ä¿¡åº¦å’Œå®‰å…¨æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Large Vision-Language Models (LVLMs) often produce plausible but unreliable outputs, making robust uncertainty estimation essential. Recent work on semantic uncertainty estimates relies on external models to cluster multiple sampled responses and measure their semantic consistency. However, these clustering methods are often fragile, highly sensitive to minor phrasing variations, and can incorrectly group or separate semantically similar answers, leading to unreliable uncertainty estimates. We propose Semantic Gaussian Process Uncertainty (SGPU), a Bayesian framework that quantifies semantic uncertainty by analyzing the geometric structure of answer embeddings, avoiding brittle clustering. SGPU maps generated answers into a dense semantic space, computes the Gram matrix of their embeddings, and summarizes their semantic configuration via the eigenspectrum. This spectral representation is then fed into a Gaussian Process Classifier that learns to map patterns of semantic consistency to predictive uncertainty, and that can be applied in both black-box and white-box settings. Across six LLMs and LVLMs on eight datasets spanning VQA, image classification, and textual QA, SGPU consistently achieves state-of-the-art calibration (ECE) and discriminative (AUROC, AUARC) performance. We further show that SGPU transfers across models and modalities, indicating that its spectral representation captures general patterns of semantic uncertainty.

