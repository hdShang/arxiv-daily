---
layout: default
title: AMD-HookNet++: Evolution of AMD-HookNet with Hybrid CNN-Transformer Feature Enhancement for Glacier Calving Front Segmentation
---

# AMD-HookNet++: Evolution of AMD-HookNet with Hybrid CNN-Transformer Feature Enhancement for Glacier Calving Front Segmentation

**arXiv**: [2512.14639v1](https://arxiv.org/abs/2512.14639) | [PDF](https://arxiv.org/pdf/2512.14639.pdf)

**ä½œè€…**: Fei Wu, Marcel Dreier, Nora Gourmelon, Sebastian Wind, Jianlin Zhang, Thorsten Seehaus, Matthias Braun, Andreas Maier, Vincent Christlein

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**æœŸåˆŠ**: IEEE Transactions on Geoscience and Remote Sensing (2025)

**DOI**: [10.1109/TGRS.2025.3642764](https://doi.org/10.1109/TGRS.2025.3642764)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAMD-HookNet++æ··åˆCNN-Transformerç‰¹å¾å¢žå¼ºæ–¹æ³•ï¼Œç”¨äºŽåˆæˆå­”å¾„é›·è¾¾å›¾åƒä¸­çš„å†°å·å´©è§£å‰ç¼˜åˆ†å‰²ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **è§†è§‰é‡Œç¨‹è®¡**

**å…³é”®è¯**: `å†°å·åˆ†å‰²` `åˆæˆå­”å¾„é›·è¾¾å›¾åƒ` `æ··åˆCNN-Transformer` `ç‰¹å¾å¢žå¼º` `æ³¨æ„åŠ›æœºåˆ¶` `åƒç´ çº§å¯¹æ¯”å­¦ä¹ ` `å´©è§£å‰ç¼˜æ£€æµ‹` `é¥æ„Ÿå›¾åƒåˆ†æž`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçº¯CNNæ–¹æ³•åœ¨å†°å·åˆ†å‰²ä¸­éš¾ä»¥æ•èŽ·é•¿è·ç¦»ä¾èµ–å…³ç³»ï¼Œå¯¼è‡´å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯ä¸è¶³ï¼Œå½±å“å´©è§£å‰ç¼˜çš„å‡†ç¡®æç»˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæå‡ºæ··åˆCNN-Transformeræž¶æž„ï¼Œç»“åˆTransformeråˆ†æ”¯æ•èŽ·å…¨å±€ä¸Šä¸‹æ–‡å’ŒCNNåˆ†æ”¯ä¿ç•™å±€éƒ¨ç»†èŠ‚ï¼Œå¹¶å¼•å…¥å¢žå¼ºæ³¨æ„åŠ›æ¨¡å—ä¼˜åŒ–ç‰¹å¾äº¤äº’ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨CaFFeæ•°æ®é›†ä¸Šå®žçŽ°78.2 IoUå’Œ1,318ç±³HD95ï¼Œä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œå¹¶ç”Ÿæˆæ›´å¹³æ»‘çš„å‰ç¼˜åˆ†å‰²ç»“æžœã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å†°å·å’Œå†°æž¶å‰ç¼˜çš„åŠ¨æ€å˜åŒ–æ˜¾è‘—å½±å“å†°ç›–è´¨é‡å¹³è¡¡å’Œæ²¿æµ·æµ·å¹³é¢ã€‚ä¸ºæœ‰æ•ˆç›‘æµ‹å†°å·çŠ¶å†µï¼ŒæŒç»­ä¼°è®¡å†°å·å´©è§£å‰ç¼˜çš„ä½ç½®å˜åŒ–è‡³å…³é‡è¦ã€‚AMD-HookNeté¦–æ¬¡å¼•å…¥äº†çº¯åŒåˆ†æ”¯å·ç§¯ç¥žç»ç½‘ç»œï¼ˆCNNï¼‰è¿›è¡Œå†°å·åˆ†å‰²ã€‚ç„¶è€Œï¼Œå·ç§¯æ“ä½œçš„å±€éƒ¨æ€§å’Œå¹³ç§»ä¸å˜æ€§è™½ç„¶æœ‰åˆ©äºŽæ•æ‰ä½Žçº§ç»†èŠ‚ï¼Œä½†é™åˆ¶äº†æ¨¡åž‹ä¿æŒé•¿è·ç¦»ä¾èµ–å…³ç³»çš„èƒ½åŠ›ã€‚æœ¬ç ”ç©¶æå‡ºAMD-HookNet++ï¼Œä¸€ç§æ–°é¢–çš„å…ˆè¿›æ··åˆCNN-Transformerç‰¹å¾å¢žå¼ºæ–¹æ³•ï¼Œç”¨äºŽåˆ†å‰²åˆæˆå­”å¾„é›·è¾¾å›¾åƒä¸­çš„å†°å·å¹¶æç»˜å´©è§£å‰ç¼˜ã€‚æˆ‘ä»¬çš„æ··åˆç»“æž„åŒ…æ‹¬ä¸¤ä¸ªåˆ†æ”¯ï¼šä¸€ä¸ªåŸºäºŽTransformerçš„ä¸Šä¸‹æ–‡åˆ†æ”¯ä»¥æ•èŽ·é•¿è·ç¦»ä¾èµ–å…³ç³»ï¼Œåœ¨æ›´å¤§è§†å›¾ä¸­æä¾›å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼›ä¸€ä¸ªåŸºäºŽCNNçš„ç›®æ ‡åˆ†æ”¯ä»¥ä¿ç•™å±€éƒ¨ç»†èŠ‚ã€‚ä¸ºå¢žå¼ºè¿žæŽ¥æ··åˆç‰¹å¾çš„è¡¨ç¤ºï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªå¢žå¼ºçš„ç©ºé—´é€šé“æ³¨æ„åŠ›æ¨¡å—ï¼Œé€šè¿‡ä»Žç©ºé—´å’Œé€šé“è§’åº¦åŠ¨æ€è°ƒæ•´ä»¤ç‰Œå…³ç³»ï¼Œä¿ƒè¿›æ··åˆCNN-Transformeråˆ†æ”¯ä¹‹é—´çš„äº¤äº’ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼€å‘äº†åƒç´ åˆ°åƒç´ å¯¹æ¯”æ·±åº¦ç›‘ç£ï¼Œé€šè¿‡å°†åƒç´ çº§åº¦é‡å­¦ä¹ é›†æˆåˆ°å†°å·åˆ†å‰²ä¸­ï¼Œä¼˜åŒ–æˆ‘ä»¬çš„æ··åˆæ¨¡åž‹ã€‚é€šè¿‡åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„å†°å·åˆ†å‰²åŸºå‡†æ•°æ®é›†CaFFeä¸Šè¿›è¡Œå¹¿æ³›å®žéªŒå’Œå…¨é¢çš„å®šé‡ä¸Žå®šæ€§åˆ†æžï¼Œæˆ‘ä»¬è¡¨æ˜ŽAMD-HookNet++ä»¥78.2çš„IoUå’Œ1,318ç±³çš„HD95è®¾å®šäº†æ–°çš„æœ€å…ˆè¿›æ°´å¹³ï¼ŒåŒæ—¶ä¿æŒäº†367ç±³çš„ç«žäº‰æ€§MDEã€‚æ›´é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬çš„æ··åˆæ¨¡åž‹äº§ç”Ÿäº†æ›´å¹³æ»‘çš„å´©è§£å‰ç¼˜æç»˜ï¼Œè§£å†³äº†çº¯åŸºäºŽTransformeræ–¹æ³•ä¸­å¸¸è§çš„é”¯é½¿è¾¹ç¼˜é—®é¢˜ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

AMD-HookNet++é‡‡ç”¨åŒåˆ†æ”¯æ··åˆæž¶æž„ï¼šä¸€ä¸ªåŸºäºŽTransformerçš„ä¸Šä¸‹æ–‡åˆ†æ”¯ç”¨äºŽæ•èŽ·å…¨å±€é•¿è·ç¦»ä¾èµ–å…³ç³»ï¼Œæä¾›å¤§è§†å›¾ä¸‹çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼›ä¸€ä¸ªåŸºäºŽCNNçš„ç›®æ ‡åˆ†æ”¯ç”¨äºŽä¿ç•™å±€éƒ¨ç»†èŠ‚ç‰¹å¾ã€‚å…³é”®æŠ€æœ¯åˆ›æ–°åŒ…æ‹¬å¢žå¼ºçš„ç©ºé—´é€šé“æ³¨æ„åŠ›æ¨¡å—ï¼Œè¯¥æ¨¡å—é€šè¿‡åŠ¨æ€è°ƒæ•´ç©ºé—´å’Œé€šé“ç»´åº¦çš„ä»¤ç‰Œå…³ç³»ï¼Œä¿ƒè¿›ä¸¤ä¸ªåˆ†æ”¯ä¹‹é—´çš„ç‰¹å¾äº¤äº’ï¼Œä»Žè€Œä¼˜åŒ–æ··åˆç‰¹å¾çš„è¡¨ç¤ºã€‚æ­¤å¤–ï¼Œå¼•å…¥äº†åƒç´ åˆ°åƒç´ å¯¹æ¯”æ·±åº¦ç›‘ç£ï¼Œå°†åƒç´ çº§åº¦é‡å­¦ä¹ é›†æˆåˆ°è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œè¿›ä¸€æ­¥æå‡åˆ†å‰²ç²¾åº¦ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºŽï¼šç›¸æ¯”çº¯CNNçš„AMD-HookNetï¼Œæœ¬æ–¹æ³•é€šè¿‡Transformeråˆ†æ”¯å¼¥è¡¥äº†é•¿è·ç¦»ä¾èµ–çš„ä¸è¶³ï¼›ç›¸æ¯”çº¯Transformeræ–¹æ³•ï¼Œæœ¬æ–¹æ³•é€šè¿‡CNNåˆ†æ”¯é¿å…äº†é”¯é½¿è¾¹ç¼˜é—®é¢˜ï¼Œå®žçŽ°äº†æ›´å¹³æ»‘çš„åˆ†å‰²ç»“æžœã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨CaFFeåŸºå‡†æ•°æ®é›†ä¸Šï¼ŒAMD-HookNet++å®žçŽ°äº†78.2çš„IoUå’Œ1,318ç±³çš„HD95ï¼Œæ˜¾è‘—ä¼˜äºŽå…ˆå‰æ–¹æ³•ï¼ŒåŒæ—¶ä¿æŒ367ç±³çš„MDEï¼›å®šæ€§åˆ†æžæ˜¾ç¤ºï¼Œæ¨¡åž‹èƒ½ç”Ÿæˆæ›´å¹³æ»‘çš„å´©è§£å‰ç¼˜åˆ†å‰²ï¼Œæœ‰æ•ˆè§£å†³äº†çº¯Transformeræ–¹æ³•çš„é”¯é½¿è¾¹ç¼˜é—®é¢˜ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶ä¸»è¦åº”ç”¨äºŽå†°å·ç›‘æµ‹å’Œæ°”å€™å˜åŒ–ç ”ç©¶é¢†åŸŸï¼Œé€šè¿‡é«˜ç²¾åº¦åˆ†å‰²åˆæˆå­”å¾„é›·è¾¾å›¾åƒä¸­çš„å†°å·å´©è§£å‰ç¼˜ï¼Œæ”¯æŒå†°å·åŠ¨æ€å˜åŒ–åˆ†æžã€å†°ç›–è´¨é‡å¹³è¡¡è¯„ä¼°å’Œæ²¿æµ·æµ·å¹³é¢é¢„æµ‹ï¼Œå…·æœ‰é‡è¦çš„çŽ¯å¢ƒç§‘å­¦å’Œåœ°çƒè§‚æµ‹ä»·å€¼ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The dynamics of glaciers and ice shelf fronts significantly impact the mass balance of ice sheets and coastal sea levels. To effectively monitor glacier conditions, it is crucial to consistently estimate positional shifts of glacier calving fronts. AMD-HookNet firstly introduces a pure two-branch convolutional neural network (CNN) for glacier segmentation. Yet, the local nature and translational invariance of convolution operations, while beneficial for capturing low-level details, restricts the model ability to maintain long-range dependencies. In this study, we propose AMD-HookNet++, a novel advanced hybrid CNN-Transformer feature enhancement method for segmenting glaciers and delineating calving fronts in synthetic aperture radar images. Our hybrid structure consists of two branches: a Transformer-based context branch to capture long-range dependencies, which provides global contextual information in a larger view, and a CNN-based target branch to preserve local details. To strengthen the representation of the connected hybrid features, we devise an enhanced spatial-channel attention module to foster interactions between the hybrid CNN-Transformer branches through dynamically adjusting the token relationships from both spatial and channel perspectives. Additionally, we develop a pixel-to-pixel contrastive deep supervision to optimize our hybrid model by integrating pixelwise metric learning into glacier segmentation. Through extensive experiments and comprehensive quantitative and qualitative analyses on the challenging glacier segmentation benchmark dataset CaFFe, we show that AMD-HookNet++ sets a new state of the art with an IoU of 78.2 and a HD95 of 1,318 m, while maintaining a competitive MDE of 367 m. More importantly, our hybrid model produces smoother delineations of calving fronts, resolving the issue of jagged edges typically seen in pure Transformer-based approaches.

