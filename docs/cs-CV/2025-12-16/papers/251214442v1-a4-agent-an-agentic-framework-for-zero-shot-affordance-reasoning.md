---
layout: default
title: A4-Agent: An Agentic Framework for Zero-Shot Affordance Reasoning
---

# A4-Agent: An Agentic Framework for Zero-Shot Affordance Reasoning

**arXiv**: [2512.14442v1](https://arxiv.org/abs/2512.14442) | [PDF](https://arxiv.org/pdf/2512.14442.pdf)

**ä½œè€…**: Zixin Zhang, Kanghao Chen, Hanqing Wang, Hongfei Zhang, Harold Haodong Chen, Chenfei Liao, Litao Guo, Ying-Cong Chen

**åˆ†ç±»**: cs.CV, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºA4-Agentï¼Œä¸€ä¸ªç”¨äºŽé›¶æ ·æœ¬å¯ä¾›æ€§æŽ¨ç†çš„Agentæ¡†æž¶ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å…·èº«æ™ºèƒ½ä¸Žè¡¨å¾å­¦ä¹  (Embodied AI & Representation)** **ä¸–ç•Œæ¨¡åž‹ä¸Žé¢„æµ‹ (World Models)**

**å…³é”®è¯**: `å¯ä¾›æ€§é¢„æµ‹` `å…·èº«æ™ºèƒ½` `é›¶æ ·æœ¬å­¦ä¹ ` `Agentæ¡†æž¶` `è§†è§‰-è¯­è¨€æ¨¡åž‹` `ç”Ÿæˆæ¨¡åž‹` `åŸºç¡€æ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰å¯ä¾›æ€§é¢„æµ‹æ¨¡åž‹æ³›åŒ–æ€§å·®ï¼Œä¸»è¦å› ä¸ºç«¯åˆ°ç«¯ç»“æž„è€¦åˆäº†é«˜å±‚æŽ¨ç†å’Œä½Žå±‚èƒ½åŠ›ï¼Œä¾èµ–å¤§é‡æ ‡æ³¨æ•°æ®ã€‚
2. A4-Agentæ¡†æž¶è§£è€¦å¯ä¾›æ€§é¢„æµ‹ä¸ºä¸‰ä¸ªé˜¶æ®µï¼Œåˆ†åˆ«ç”±Dreamerã€Thinkerå’ŒSpotterä¸‰ä¸ªæ¨¡å—å®žçŽ°ã€‚
3. A4-Agentæ— éœ€è®­ç»ƒï¼Œåˆ©ç”¨é¢„è®­ç»ƒæ¨¡åž‹çš„ä¼˜åŠ¿ï¼Œåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†çŽ°æœ‰ç›‘ç£æ–¹æ³•ï¼Œæ³›åŒ–æ€§æ›´å¼ºã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¯ä¾›æ€§é¢„æµ‹ï¼Œå³åŸºäºŽè¯­è¨€æŒ‡ä»¤è¯†åˆ«ç‰©ä½“ä¸Šçš„äº¤äº’åŒºåŸŸï¼Œå¯¹äºŽå…·èº«æ™ºèƒ½è‡³å…³é‡è¦ã€‚ç›®å‰ä¸»æµçš„ç«¯åˆ°ç«¯æ¨¡åž‹å°†é«˜å±‚æŽ¨ç†å’Œä½Žå±‚åŸºç¡€èƒ½åŠ›è€¦åˆåˆ°ä¸€ä¸ªå•ä¸€çš„pipelineä¸­ï¼Œå¹¶ä¾èµ–äºŽåœ¨æ ‡æ³¨æ•°æ®é›†ä¸Šçš„è®­ç»ƒï¼Œè¿™å¯¼è‡´äº†å¯¹æ–°ç‰©ä½“å’Œæœªè§çŽ¯å¢ƒçš„æ³›åŒ–èƒ½åŠ›è¾ƒå·®ã€‚æœ¬æ–‡æå‡ºA4-Agentï¼Œä¸€ä¸ªæ— éœ€è®­ç»ƒçš„agentæ¡†æž¶ï¼Œå°†å¯ä¾›æ€§é¢„æµ‹è§£è€¦ä¸ºä¸€ä¸ªä¸‰é˜¶æ®µçš„pipelineã€‚è¯¥æ¡†æž¶åœ¨æµ‹è¯•æ—¶åè°ƒä¸“é—¨çš„åŸºç¡€æ¨¡åž‹ï¼šï¼ˆ1ï¼‰$	extbf{Dreamer}$ï¼Œåˆ©ç”¨ç”Ÿæˆæ¨¡åž‹æ¥å¯è§†åŒ–äº¤äº’çš„$	extit{æ ·å­}$ï¼›ï¼ˆ2ï¼‰$	extbf{Thinker}$ï¼Œåˆ©ç”¨å¤§åž‹è§†è§‰-è¯­è¨€æ¨¡åž‹æ¥å†³å®šä¸Ž$	extit{ä»€ä¹ˆ}$ç‰©ä½“éƒ¨åˆ†è¿›è¡Œäº¤äº’ï¼›ï¼ˆ3ï¼‰$	extbf{Spotter}$ï¼Œåè°ƒè§†è§‰åŸºç¡€æ¨¡åž‹æ¥ç²¾ç¡®å®šä½äº¤äº’åŒºåŸŸçš„$	extit{ä½ç½®}$ã€‚é€šè¿‡åˆ©ç”¨é¢„è®­ç»ƒæ¨¡åž‹çš„äº’è¡¥ä¼˜åŠ¿ï¼Œæ— éœ€ä»»ä½•ç‰¹å®šä»»åŠ¡çš„å¾®è°ƒï¼Œæˆ‘ä»¬çš„é›¶æ ·æœ¬æ¡†æž¶åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºŽæœ€å…ˆè¿›çš„ç›‘ç£æ–¹æ³•ï¼Œå¹¶å±•ç¤ºäº†å¯¹çœŸå®žä¸–ç•ŒçŽ¯å¢ƒçš„é²æ£’æ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¯ä¾›æ€§é¢„æµ‹é—®é¢˜ï¼Œå³æ ¹æ®è¯­è¨€æŒ‡ä»¤ç¡®å®šç‰©ä½“ä¸Šå¯äº¤äº’çš„åŒºåŸŸã€‚çŽ°æœ‰ç«¯åˆ°ç«¯æ¨¡åž‹å­˜åœ¨æ³›åŒ–æ€§å·®çš„é—®é¢˜ï¼Œå› ä¸ºå®ƒä»¬å°†é«˜å±‚æŽ¨ç†å’Œä½Žå±‚è§†è§‰æ„ŸçŸ¥è€¦åˆåœ¨ä¸€èµ·ï¼Œå¹¶ä¸”ä¾èµ–äºŽå¤§é‡æ ‡æ³¨æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œéš¾ä»¥é€‚åº”æ–°çš„ç‰©ä½“å’ŒçŽ¯å¢ƒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†å¯ä¾›æ€§é¢„æµ‹ä»»åŠ¡è§£è€¦ä¸ºä¸‰ä¸ªç‹¬ç«‹çš„é˜¶æ®µï¼Œæ¯ä¸ªé˜¶æ®µç”±ä¸“é—¨çš„é¢„è®­ç»ƒæ¨¡åž‹è´Ÿè´£ã€‚è¿™ç§è§£è€¦ä½¿å¾—æ¯ä¸ªæ¨¡å—å¯ä»¥ä¸“æ³¨äºŽç‰¹å®šçš„å­ä»»åŠ¡ï¼Œå¹¶åˆ©ç”¨é¢„è®­ç»ƒæ¨¡åž‹çš„ä¼˜åŠ¿ï¼Œä»Žè€Œæé«˜æ•´ä½“çš„æ³›åŒ–èƒ½åŠ›ã€‚é€šè¿‡agentæ¡†æž¶åè°ƒè¿™äº›æ¨¡å—ï¼Œå®žçŽ°é›¶æ ·æœ¬çš„å¯ä¾›æ€§æŽ¨ç†ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šA4-Agentæ¡†æž¶åŒ…å«ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šDreamerã€Thinkerå’ŒSpotterã€‚Dreamerä½¿ç”¨ç”Ÿæˆæ¨¡åž‹å¯è§†åŒ–äº¤äº’æ•ˆæžœï¼ŒThinkerä½¿ç”¨è§†è§‰-è¯­è¨€æ¨¡åž‹å†³å®šä¸Žå“ªä¸ªç‰©ä½“éƒ¨åˆ†äº¤äº’ï¼ŒSpotterä½¿ç”¨è§†è§‰åŸºç¡€æ¨¡åž‹ç²¾ç¡®å®šä½äº¤äº’åŒºåŸŸã€‚æ•´ä¸ªæµç¨‹æ˜¯ï¼šé¦–å…ˆï¼ŒDreameræ ¹æ®æŒ‡ä»¤ç”Ÿæˆäº¤äº’çš„è§†è§‰æ•ˆæžœï¼›ç„¶åŽï¼ŒThinkeråˆ†æžè§†è§‰æ•ˆæžœï¼Œç¡®å®šéœ€è¦äº¤äº’çš„ç‰©ä½“éƒ¨åˆ†ï¼›æœ€åŽï¼ŒSpotteråœ¨åŽŸå§‹å›¾åƒä¸­å®šä½è¯¥éƒ¨åˆ†çš„ç²¾ç¡®ä½ç½®ã€‚

**å…³é”®åˆ›æ–°**ï¼šA4-Agentçš„å…³é”®åˆ›æ–°åœ¨äºŽå…¶è§£è€¦çš„agentæ¡†æž¶å’Œé›¶æ ·æœ¬å­¦ä¹ èƒ½åŠ›ã€‚ä¸Žä¼ ç»Ÿçš„ç«¯åˆ°ç«¯æ¨¡åž‹ä¸åŒï¼ŒA4-Agentå°†å¯ä¾›æ€§é¢„æµ‹åˆ†è§£ä¸ºä¸‰ä¸ªç‹¬ç«‹çš„å­ä»»åŠ¡ï¼Œå¹¶åˆ©ç”¨é¢„è®­ç»ƒæ¨¡åž‹çš„ä¼˜åŠ¿ï¼Œæ— éœ€ä»»ä½•ç‰¹å®šä»»åŠ¡çš„å¾®è°ƒã€‚è¿™ç§è§£è€¦å’Œé›¶æ ·æœ¬å­¦ä¹ èƒ½åŠ›ä½¿å¾—A4-Agentå…·æœ‰æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›å’Œé€‚åº”æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šDreameræ¨¡å—ä½¿ç”¨é¢„è®­ç»ƒçš„ç”Ÿæˆæ¨¡åž‹ï¼ˆä¾‹å¦‚ï¼ŒStable Diffusionï¼‰æ ¹æ®è¯­è¨€æŒ‡ä»¤ç”Ÿæˆäº¤äº’çš„è§†è§‰æ•ˆæžœã€‚Thinkeræ¨¡å—ä½¿ç”¨å¤§åž‹è§†è§‰-è¯­è¨€æ¨¡åž‹ï¼ˆä¾‹å¦‚ï¼ŒCLIPï¼‰åˆ†æžè§†è§‰æ•ˆæžœï¼Œå¹¶ç¡®å®šéœ€è¦äº¤äº’çš„ç‰©ä½“éƒ¨åˆ†ã€‚Spotteræ¨¡å—ä½¿ç”¨è§†è§‰åŸºç¡€æ¨¡åž‹ï¼ˆä¾‹å¦‚ï¼ŒSAMï¼‰åœ¨åŽŸå§‹å›¾åƒä¸­å®šä½è¯¥éƒ¨åˆ†çš„ç²¾ç¡®ä½ç½®ã€‚è®ºæ–‡æ²¡æœ‰æåŠå…·ä½“çš„å‚æ•°è®¾ç½®æˆ–æŸå¤±å‡½æ•°ï¼Œå› ä¸ºè¯¥æ¡†æž¶æ˜¯é›¶æ ·æœ¬çš„ï¼Œä¸éœ€è¦è®­ç»ƒã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

A4-Agentåœ¨å¤šä¸ªå¯ä¾›æ€§é¢„æµ‹åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºŽæœ€å…ˆè¿›çš„ç›‘ç£æ–¹æ³•ï¼Œæ— éœ€ä»»ä½•ç‰¹å®šä»»åŠ¡çš„å¾®è°ƒã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒA4-Agentå…·æœ‰å¼ºå¤§çš„é›¶æ ·æœ¬å­¦ä¹ èƒ½åŠ›å’Œæ³›åŒ–èƒ½åŠ›ï¼Œèƒ½å¤Ÿé€‚åº”æ–°çš„ç‰©ä½“å’ŒçŽ¯å¢ƒã€‚å…·ä½“æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦åœ¨è®ºæ–‡ä¸­è¯¦ç»†ç»™å‡ºã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

A4-Agentå¯åº”ç”¨äºŽæœºå™¨äººæ“ä½œã€è™šæ‹ŸåŠ©æ‰‹ã€å¢žå¼ºçŽ°å®žç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œæœºå™¨äººå¯ä»¥æ ¹æ®ç”¨æˆ·çš„è¯­è¨€æŒ‡ä»¤ï¼Œè‡ªåŠ¨è¯†åˆ«å¹¶æ“ä½œç‰©ä½“ï¼›è™šæ‹ŸåŠ©æ‰‹å¯ä»¥æ ¹æ®ç”¨æˆ·çš„éœ€æ±‚ï¼Œæä¾›æ›´æ™ºèƒ½çš„äº¤äº’ä½“éªŒï¼›å¢žå¼ºçŽ°å®žåº”ç”¨å¯ä»¥æ ¹æ®ç”¨æˆ·çš„è§†çº¿ï¼Œæä¾›æ›´ç²¾å‡†çš„ç‰©ä½“äº¤äº’æç¤ºã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºŽæå‡äººæœºäº¤äº’çš„æ™ºèƒ½åŒ–æ°´å¹³ï¼ŒæŽ¨åŠ¨å…·èº«æ™ºèƒ½çš„å‘å±•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Affordance prediction, which identifies interaction regions on objects based on language instructions, is critical for embodied AI. Prevailing end-to-end models couple high-level reasoning and low-level grounding into a single monolithic pipeline and rely on training over annotated datasets, which leads to poor generalization on novel objects and unseen environments. In this paper, we move beyond this paradigm by proposing A4-Agent, a training-free agentic framework that decouples affordance prediction into a three-stage pipeline. Our framework coordinates specialized foundation models at test time: (1) a $\textbf{Dreamer}$ that employs generative models to visualize $\textit{how}$ an interaction would look; (2) a $\textbf{Thinker}$ that utilizes large vision-language models to decide $\textit{what}$ object part to interact with; and (3) a $\textbf{Spotter}$ that orchestrates vision foundation models to precisely locate $\textit{where}$ the interaction area is. By leveraging the complementary strengths of pre-trained models without any task-specific fine-tuning, our zero-shot framework significantly outperforms state-of-the-art supervised methods across multiple benchmarks and demonstrates robust generalization to real-world settings.

