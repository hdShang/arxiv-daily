---
layout: default
title: A4-Agent: An Agentic Framework for Zero-Shot Affordance Reasoning
---

# A4-Agent: An Agentic Framework for Zero-Shot Affordance Reasoning

**arXiv**: [2512.14442v1](https://arxiv.org/abs/2512.14442) | [PDF](https://arxiv.org/pdf/2512.14442.pdf)

**ä½œè€…**: Zixin Zhang, Kanghao Chen, Hanqing Wang, Hongfei Zhang, Harold Haodong Chen, Chenfei Liao, Litao Guo, Ying-Cong Chen

**åˆ†ç±»**: cs.CV, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºA4-Agentï¼Œä¸€ä¸ªç”¨äºŽé›¶æ ·æœ¬å¯ä¾›æ€§æŽ¨ç†çš„Agentæ¡†æž¶ï¼Œæ— éœ€è®­ç»ƒå³å¯è¶…è¶ŠçŽ°æœ‰ç›‘ç£æ–¹æ³•ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **Sim2Realä¸Žç­–ç•¥å­¦ä¹  (Sim2Real & Policy Learning)** **å…·èº«æ™ºèƒ½ (Embodied AI)**

**å…³é”®è¯**: `å¯ä¾›æ€§é¢„æµ‹` `é›¶æ ·æœ¬å­¦ä¹ ` `å…·èº«æ™ºèƒ½` `Agentæ¡†æž¶` `é¢„è®­ç»ƒæ¨¡åž‹` `è§†è§‰-è¯­è¨€æ¨¡åž‹` `ç‰©ä½“äº¤äº’`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰å¯ä¾›æ€§é¢„æµ‹æ¨¡åž‹ä¾èµ–ç«¯åˆ°ç«¯è®­ç»ƒï¼Œæ³›åŒ–æ€§å·®ï¼Œéš¾ä»¥é€‚åº”æ–°ç‰©ä½“å’ŒçŽ¯å¢ƒã€‚
2. A4-Agentå°†å¯ä¾›æ€§é¢„æµ‹è§£è€¦ä¸ºä¸‰ä¸ªé˜¶æ®µï¼Œåˆ†åˆ«ç”±Dreamerã€Thinkerå’ŒSpotterä¸‰ä¸ªæ¨¡å—å®žçŽ°ã€‚
3. A4-Agentæ— éœ€è®­ç»ƒï¼Œåˆ©ç”¨é¢„è®­ç»ƒæ¨¡åž‹ä¼˜åŠ¿äº’è¡¥ï¼Œåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†çŽ°æœ‰ç›‘ç£æ–¹æ³•ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºA4-Agentï¼Œä¸€ä¸ªç”¨äºŽå¯ä¾›æ€§é¢„æµ‹çš„å…è®­ç»ƒAgentæ¡†æž¶ã€‚å¯ä¾›æ€§é¢„æµ‹æ—¨åœ¨æ ¹æ®è¯­è¨€æŒ‡ä»¤è¯†åˆ«ç‰©ä½“ä¸Šçš„äº¤äº’åŒºåŸŸï¼Œå¯¹å…·èº«æ™ºèƒ½è‡³å…³é‡è¦ã€‚çŽ°æœ‰çš„ç«¯åˆ°ç«¯æ¨¡åž‹å°†é«˜å±‚æŽ¨ç†å’Œä½Žå±‚åŸºç¡€è€¦åˆåˆ°ä¸€ä¸ªå•ä¸€çš„pipelineä¸­ï¼Œå¹¶ä¾èµ–äºŽå¸¦æ³¨é‡Šæ•°æ®é›†çš„è®­ç»ƒï¼Œå¯¼è‡´å¯¹æ–°ç‰©ä½“å’Œæœªè§çŽ¯å¢ƒçš„æ³›åŒ–èƒ½åŠ›è¾ƒå·®ã€‚A4-Agentå°†å¯ä¾›æ€§é¢„æµ‹è§£è€¦ä¸ºä¸€ä¸ªä¸‰é˜¶æ®µpipelineï¼Œåœ¨æµ‹è¯•æ—¶åè°ƒä¸“é—¨çš„åŸºç¡€æ¨¡åž‹ï¼š(1) Dreamerï¼Œåˆ©ç”¨ç”Ÿæˆæ¨¡åž‹æ¥å¯è§†åŒ–äº¤äº’çš„æ ·å­ï¼›(2) Thinkerï¼Œåˆ©ç”¨å¤§åž‹è§†è§‰-è¯­è¨€æ¨¡åž‹æ¥å†³å®šä¸Žå“ªä¸ªç‰©ä½“éƒ¨åˆ†è¿›è¡Œäº¤äº’ï¼›(3) Spotterï¼Œåè°ƒè§†è§‰åŸºç¡€æ¨¡åž‹æ¥ç²¾ç¡®å®šä½äº¤äº’åŒºåŸŸã€‚è¯¥é›¶æ ·æœ¬æ¡†æž¶åˆ©ç”¨é¢„è®­ç»ƒæ¨¡åž‹çš„äº’è¡¥ä¼˜åŠ¿ï¼Œæ— éœ€ä»»ä½•ç‰¹å®šäºŽä»»åŠ¡çš„å¾®è°ƒï¼Œåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºŽæœ€å…ˆè¿›çš„ç›‘ç£æ–¹æ³•ï¼Œå¹¶å±•ç¤ºäº†å¯¹çœŸå®žä¸–ç•ŒçŽ¯å¢ƒçš„é²æ£’æ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¯ä¾›æ€§é¢„æµ‹é—®é¢˜ï¼Œå³æ ¹æ®è¯­è¨€æŒ‡ä»¤ç¡®å®šç‰©ä½“ä¸Šå¯äº¤äº’çš„åŒºåŸŸã€‚çŽ°æœ‰ç«¯åˆ°ç«¯æ¨¡åž‹å°†é«˜å±‚æŽ¨ç†å’Œä½Žå±‚æ„ŸçŸ¥è€¦åˆï¼Œä¾èµ–å¤§é‡æ ‡æ³¨æ•°æ®è®­ç»ƒï¼Œå¯¼è‡´åœ¨æ–°ç‰©ä½“å’Œæœªè§çŽ¯å¢ƒä¸‹çš„æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚è¿™äº›æ¨¡åž‹éš¾ä»¥æœ‰æ•ˆåˆ©ç”¨é¢„è®­ç»ƒæ¨¡åž‹çš„çŸ¥è¯†ï¼Œéœ€è¦ä¸ºç‰¹å®šä»»åŠ¡è¿›è¡Œå¾®è°ƒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†å¯ä¾›æ€§é¢„æµ‹ä»»åŠ¡è§£è€¦ä¸ºä¸‰ä¸ªç‹¬ç«‹çš„é˜¶æ®µï¼Œåˆ†åˆ«å¯¹åº”äº¤äº’çš„å¯è§†åŒ–ï¼ˆDreamerï¼‰ã€äº¤äº’å¯¹è±¡éƒ¨ä»¶çš„å†³ç­–ï¼ˆThinkerï¼‰å’Œäº¤äº’åŒºåŸŸçš„ç²¾ç¡®å®šä½ï¼ˆSpotterï¼‰ã€‚æ¯ä¸ªé˜¶æ®µåˆ©ç”¨ä¸åŒçš„é¢„è®­ç»ƒæ¨¡åž‹ï¼Œå‘æŒ¥å„è‡ªçš„ä¼˜åŠ¿ï¼Œå¹¶é€šè¿‡Agentæ¡†æž¶è¿›è¡Œåè°ƒã€‚è¿™ç§è§£è€¦çš„è®¾è®¡ä½¿å¾—æ¨¡åž‹èƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨é¢„è®­ç»ƒçŸ¥è¯†ï¼Œå®žçŽ°é›¶æ ·æœ¬æ³›åŒ–ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šA4-Agentæ¡†æž¶åŒ…å«ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šDreamerã€Thinkerå’ŒSpotterã€‚Dreamerä½¿ç”¨ç”Ÿæˆæ¨¡åž‹ï¼ˆå¦‚Stable Diffusionï¼‰æ ¹æ®è¯­è¨€æŒ‡ä»¤ç”Ÿæˆäº¤äº’çš„è§†è§‰æ•ˆæžœã€‚Thinkerä½¿ç”¨å¤§åž‹è§†è§‰-è¯­è¨€æ¨¡åž‹ï¼ˆå¦‚CLIPï¼‰æ¥åˆ¤æ–­åº”è¯¥ä¸Žç‰©ä½“çš„å“ªä¸ªéƒ¨åˆ†è¿›è¡Œäº¤äº’ã€‚Spotterä½¿ç”¨è§†è§‰åŸºç¡€æ¨¡åž‹ï¼ˆå¦‚SAMï¼‰æ¥ç²¾ç¡®å®šä½äº¤äº’åŒºåŸŸã€‚è¿™ä¸‰ä¸ªæ¨¡å—æŒ‰é¡ºåºæ‰§è¡Œï¼Œå½¢æˆä¸€ä¸ªpipelineã€‚

**å…³é”®åˆ›æ–°**ï¼šA4-Agentçš„å…³é”®åˆ›æ–°åœ¨äºŽå…¶Agenticæ¡†æž¶å’Œè§£è€¦çš„è®¾è®¡ã€‚é€šè¿‡å°†å¯ä¾›æ€§é¢„æµ‹åˆ†è§£ä¸ºä¸‰ä¸ªç‹¬ç«‹çš„å­ä»»åŠ¡ï¼Œå¹¶åˆ©ç”¨ä¸åŒçš„é¢„è®­ç»ƒæ¨¡åž‹æ¥è§£å†³è¿™äº›å­ä»»åŠ¡ï¼ŒA4-Agentèƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨é¢„è®­ç»ƒçŸ¥è¯†ï¼Œå®žçŽ°é›¶æ ·æœ¬æ³›åŒ–ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æž¶æ— éœ€ä»»ä½•ç‰¹å®šäºŽä»»åŠ¡çš„å¾®è°ƒï¼Œé™ä½Žäº†è®­ç»ƒæˆæœ¬ã€‚

**å…³é”®è®¾è®¡**ï¼šDreameræ¨¡å—ä½¿ç”¨Stable Diffusionç­‰æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡åž‹ï¼Œæ ¹æ®è¯­è¨€æŒ‡ä»¤ç”Ÿæˆäº¤äº’å›¾åƒã€‚Thinkeræ¨¡å—ä½¿ç”¨CLIPç­‰è§†è§‰-è¯­è¨€æ¨¡åž‹ï¼Œè®¡ç®—å›¾åƒå’Œæ–‡æœ¬ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œé€‰æ‹©æœ€ç›¸å…³çš„ç‰©ä½“éƒ¨ä»¶ã€‚Spotteræ¨¡å—ä½¿ç”¨SAMç­‰åˆ†å‰²æ¨¡åž‹ï¼Œæ ¹æ®Thinkerçš„è¾“å‡ºï¼Œåˆ†å‰²å‡ºäº¤äº’åŒºåŸŸã€‚å…·ä½“å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°å–å†³äºŽæ‰€ä½¿ç”¨çš„é¢„è®­ç»ƒæ¨¡åž‹ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

A4-Agentåœ¨å¤šä¸ªå¯ä¾›æ€§é¢„æµ‹åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºŽæœ€å…ˆè¿›çš„ç›‘ç£æ–¹æ³•ï¼Œå®žçŽ°äº†é›¶æ ·æœ¬æ³›åŒ–ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒA4-Agentåœ¨ unseen çš„ç‰©ä½“å’ŒçŽ¯å¢ƒä¸­è¡¨çŽ°å‡ºå¼ºå¤§çš„é²æ£’æ€§ã€‚å…·ä½“æ€§èƒ½æ•°æ®åœ¨è®ºæ–‡ä¸­ç»™å‡ºï¼Œç›¸è¾ƒäºŽéœ€è¦å¤§é‡è®­ç»ƒæ•°æ®çš„ç›‘ç£å­¦ä¹ æ–¹æ³•ï¼ŒA4-Agentæ— éœ€è®­ç»ƒå³å¯è¾¾åˆ°ç”šè‡³è¶…è¶Šå…¶æ€§èƒ½ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

A4-Agentåœ¨æœºå™¨äººæ“ä½œã€è™šæ‹ŸåŠ©æ‰‹å’Œå¢žå¼ºçŽ°å®žç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥å¸®åŠ©æœºå™¨äººç†è§£äººç±»æŒ‡ä»¤ï¼Œå¹¶ä¸ŽçŽ¯å¢ƒä¸­çš„ç‰©ä½“è¿›è¡Œäº¤äº’ã€‚ä¾‹å¦‚ï¼Œæœºå™¨äººå¯ä»¥æ ¹æ®â€œæ‰“å¼€æŠ½å±‰â€çš„æŒ‡ä»¤ï¼Œè‡ªåŠ¨è¯†åˆ«æŠ½å±‰çš„ä½ç½®å¹¶æ‰§è¡Œæ‰“å¼€æ“ä½œã€‚è¯¥ç ”ç©¶è¿˜å¯ä»¥ç”¨äºŽå¼€å‘æ›´æ™ºèƒ½çš„è™šæ‹ŸåŠ©æ‰‹ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ç”¨æˆ·çš„æ„å›¾å¹¶æä¾›ç›¸åº”çš„æœåŠ¡ã€‚åœ¨å¢žå¼ºçŽ°å®žä¸­ï¼ŒA4-Agentå¯ä»¥å¸®åŠ©ç”¨æˆ·è¯†åˆ«ç‰©ä½“ä¸Šçš„å¯äº¤äº’åŒºåŸŸï¼Œå¹¶æä¾›ç›¸åº”çš„æ“ä½œæç¤ºã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Affordance prediction, which identifies interaction regions on objects based on language instructions, is critical for embodied AI. Prevailing end-to-end models couple high-level reasoning and low-level grounding into a single monolithic pipeline and rely on training over annotated datasets, which leads to poor generalization on novel objects and unseen environments. In this paper, we move beyond this paradigm by proposing A4-Agent, a training-free agentic framework that decouples affordance prediction into a three-stage pipeline. Our framework coordinates specialized foundation models at test time: (1) a $\textbf{Dreamer}$ that employs generative models to visualize $\textit{how}$ an interaction would look; (2) a $\textbf{Thinker}$ that utilizes large vision-language models to decide $\textit{what}$ object part to interact with; and (3) a $\textbf{Spotter}$ that orchestrates vision foundation models to precisely locate $\textit{where}$ the interaction area is. By leveraging the complementary strengths of pre-trained models without any task-specific fine-tuning, our zero-shot framework significantly outperforms state-of-the-art supervised methods across multiple benchmarks and demonstrates robust generalization to real-world settings.

