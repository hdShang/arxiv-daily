---
layout: default
title: OUSAC: Optimized Guidance Scheduling with Adaptive Caching for DiT Acceleration
---

# OUSAC: Optimized Guidance Scheduling with Adaptive Caching for DiT Acceleration

**arXiv**: [2512.14096v1](https://arxiv.org/abs/2512.14096) | [PDF](https://arxiv.org/pdf/2512.14096.pdf)

**ä½œè€…**: Ruitong Sun, Tianze Yang, Wei Niu, Jin Sun

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: 29 pages

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**OUSACï¼šé€šè¿‡è‡ªé€‚åº”ç¼“å­˜ä¼˜åŒ–æŒ‡å¯¼è°ƒåº¦ï¼ŒåŠ é€Ÿæ‰©æ•£Transformeræ¨¡åž‹DiT**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å¼ºåŒ–å­¦ä¹ ä¸Žæ¨¡ä»¿å­¦ä¹  (RL & IL)** **åŠ¨ä½œç”Ÿæˆä¸Žç‰©ç†åŠ¨ç”» (Animation & Physics)**

**å…³é”®è¯**: `æ‰©æ•£æ¨¡åž‹` `å›¾åƒç”Ÿæˆ` `æ¨¡åž‹åŠ é€Ÿ` `æ— åˆ†ç±»å™¨æŒ‡å¯¼` `è‡ªé€‚åº”ç¼“å­˜`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ‰©æ•£æ¨¡åž‹è®¡ç®—å¼€é”€å¤§ï¼Œæ— åˆ†ç±»å™¨æŒ‡å¯¼(CFG)è™½èƒ½æå‡è´¨é‡ï¼Œä½†è®¡ç®—é‡ç¿»å€ï¼Œæˆä¸ºåŠ é€Ÿç“¶é¢ˆã€‚
2. OUSACé€šè¿‡ä¼˜åŒ–æŒ‡å¯¼è°ƒåº¦ï¼Œåˆ©ç”¨å¯å˜æŒ‡å¯¼å°ºåº¦å®žçŽ°ç¨€ç–è®¡ç®—ï¼Œå‡å°‘CFGæ­¥éª¤ï¼ŒåŒæ—¶ä¿æŒç”Ÿæˆè´¨é‡ã€‚
3. OUSACåœ¨DiT-XL/2ã€PixArt-alphaå’ŒFLUXä¸Šå‡å–å¾—æ˜¾è‘—åŠ é€Ÿå’Œè´¨é‡æå‡ï¼Œä¼˜äºŽçŽ°æœ‰åŠ é€Ÿæ–¹æ³•ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ‰©æ•£æ¨¡åž‹å·²æˆä¸ºé«˜è´¨é‡å›¾åƒç”Ÿæˆçš„ä¸»æµèŒƒå¼ï¼Œä½†ç”±äºŽè¿­ä»£åŽ»å™ªï¼Œå…¶è®¡ç®—æˆæœ¬ä»ç„¶å¾ˆé«˜ã€‚æ— åˆ†ç±»å™¨æŒ‡å¯¼ï¼ˆCFGï¼‰é€šè¿‡åœ¨æ¯ä¸ªæ—¶é—´æ­¥éœ€è¦æ¡ä»¶å’Œæ— æ¡ä»¶å‰å‘ä¼ é€’ï¼Œæ˜¾è‘—æé«˜ç”Ÿæˆè´¨é‡å’Œå¯æŽ§æ€§ï¼Œä½†ä¹Ÿä½¿è®¡ç®—é‡ç¿»å€ã€‚æˆ‘ä»¬æå‡ºäº†OUSACï¼ˆOptimized gUidance Scheduling with Adaptive Cachingï¼‰ï¼Œä¸€ä¸ªé€šè¿‡ç³»ç»Ÿä¼˜åŒ–åŠ é€Ÿæ‰©æ•£Transformerï¼ˆDiTï¼‰çš„æ¡†æž¶ã€‚æˆ‘ä»¬çš„å…³é”®è§è§£æ˜¯ï¼Œå¯å˜çš„æŒ‡å¯¼å°ºåº¦èƒ½å¤Ÿå®žçŽ°ç¨€ç–è®¡ç®—ï¼šåœ¨æŸäº›æ—¶é—´æ­¥è°ƒæ•´å°ºåº¦å¯ä»¥è¡¥å¿åœ¨å…¶ä»–æ—¶é—´æ­¥è·³è¿‡CFGï¼Œä»Žè€Œåœ¨ä¿æŒè´¨é‡çš„åŒæ—¶å‡å°‘æ€»é‡‡æ ·æ­¥æ•°å’ŒCFGæ­¥æ•°ã€‚ç„¶è€Œï¼Œå¯å˜çš„æŒ‡å¯¼æ¨¡å¼ä¼šå¼•å…¥åŽ»å™ªåå·®ï¼Œç ´åäº†æ ‡å‡†ç¼“å­˜æ–¹æ³•ï¼Œå› ä¸ºæ ‡å‡†ç¼“å­˜æ–¹æ³•å‡è®¾è·¨æ­¥éª¤çš„CFGå°ºåº¦ä¸å˜ã€‚æ­¤å¤–ï¼Œä¸åŒçš„Transformerå—åœ¨åŠ¨æ€æ¡ä»¶ä¸‹å—åˆ°ä¸åŒç¨‹åº¦çš„å½±å“ã€‚æœ¬æ–‡å¼€å‘äº†ä¸€ç§åˆ©ç”¨è¿™äº›è§è§£çš„ä¸¤é˜¶æ®µæ–¹æ³•ã€‚ç¬¬ä¸€é˜¶æ®µé‡‡ç”¨è¿›åŒ–ç®—æ³•æ¥è”åˆä¼˜åŒ–è·³è¿‡å“ªäº›æ—¶é—´æ­¥ä»¥åŠä½¿ç”¨ä»€ä¹ˆæŒ‡å¯¼å°ºåº¦ï¼Œæœ€å¤šå¯æ¶ˆé™¤82%çš„æ— æ¡ä»¶ä¼ é€’ã€‚ç¬¬äºŒé˜¶æ®µå¼•å…¥è‡ªé€‚åº”ç§©åˆ†é…ï¼Œä¸ºæ¯ä¸ªTransformerå—å®šåˆ¶æ ¡å‡†å·¥ä½œï¼Œä»Žè€Œåœ¨å¯å˜æŒ‡å¯¼ä¸‹ä¿æŒç¼“å­˜æœ‰æ•ˆæ€§ã€‚å®žéªŒè¡¨æ˜Žï¼ŒOUSACæ˜¾è‘—ä¼˜äºŽæœ€å…ˆè¿›çš„åŠ é€Ÿæ–¹æ³•ï¼Œåœ¨DiT-XL/2ï¼ˆImageNet 512x512ï¼‰ä¸Šå®žçŽ°äº†53%çš„è®¡ç®—èŠ‚çœå’Œ15%çš„è´¨é‡æå‡ï¼Œåœ¨PixArt-alphaï¼ˆMSCOCOï¼‰ä¸Šå®žçŽ°äº†60%çš„èŠ‚çœå’Œ16.1%çš„æå‡ï¼Œåœ¨FLUXä¸Šå®žçŽ°äº†5å€çš„åŠ é€Ÿï¼ŒåŒæ—¶æé«˜äº†CLIP Scoreï¼Œè¶…è¿‡äº†50æ­¥çš„åŸºçº¿ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæ‰©æ•£æ¨¡åž‹ï¼Œç‰¹åˆ«æ˜¯DiTï¼Œåœ¨å›¾åƒç”Ÿæˆé¢†åŸŸè¡¨çŽ°å‡ºè‰²ï¼Œä½†å…¶è®¡ç®—å¤æ‚åº¦é«˜ï¼Œé™åˆ¶äº†åº”ç”¨ã€‚æ— åˆ†ç±»å™¨æŒ‡å¯¼(CFG)è™½ç„¶èƒ½æé«˜ç”Ÿæˆè´¨é‡ï¼Œä½†éœ€è¦åŒæ—¶è¿›è¡Œæ¡ä»¶å’Œæ— æ¡ä»¶çš„å‰å‘ä¼ æ’­ï¼Œå¯¼è‡´è®¡ç®—é‡åŠ å€ã€‚çŽ°æœ‰åŠ é€Ÿæ–¹æ³•éš¾ä»¥åœ¨ä¿è¯ç”Ÿæˆè´¨é‡çš„å‰æä¸‹ï¼Œæœ‰æ•ˆå‡å°‘CFGå¸¦æ¥çš„è®¡ç®—è´Ÿæ‹…ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¯å˜çš„æŒ‡å¯¼å°ºåº¦æ¥å®žçŽ°ç¨€ç–è®¡ç®—ã€‚é€šè¿‡åœ¨æŸäº›æ—¶é—´æ­¥è°ƒæ•´æŒ‡å¯¼å°ºåº¦ï¼Œå¯ä»¥è¡¥å¿åœ¨å…¶ä»–æ—¶é—´æ­¥è·³è¿‡CFGå¸¦æ¥çš„å½±å“ï¼Œä»Žè€Œåœ¨å‡å°‘æ€»é‡‡æ ·æ­¥æ•°å’ŒCFGæ­¥éª¤çš„åŒæ—¶ï¼Œç»´æŒç”šè‡³æå‡ç”Ÿæˆè´¨é‡ã€‚è¿™ç§æ–¹æ³•çš„æ ¸å¿ƒåœ¨äºŽæ‰¾åˆ°æœ€ä¼˜çš„æŒ‡å¯¼å°ºåº¦è°ƒåº¦æ–¹æ¡ˆã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šOUSACæ¡†æž¶åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼š1. æŒ‡å¯¼è°ƒåº¦ä¼˜åŒ–ï¼šä½¿ç”¨è¿›åŒ–ç®—æ³•è”åˆä¼˜åŒ–éœ€è¦è·³è¿‡CFGçš„æ—¶é—´æ­¥ä»¥åŠå¯¹åº”çš„æŒ‡å¯¼å°ºåº¦ã€‚ç›®æ ‡æ˜¯åœ¨å‡å°‘è®¡ç®—é‡çš„åŒæ—¶ï¼Œä¿æŒç”Ÿæˆè´¨é‡ã€‚2. è‡ªé€‚åº”ç¼“å­˜ï¼šé’ˆå¯¹ä¸åŒTransformerå—åœ¨åŠ¨æ€æŒ‡å¯¼æ¡ä»¶ä¸‹å—åˆ°çš„ä¸åŒå½±å“ï¼Œå¼•å…¥è‡ªé€‚åº”ç§©åˆ†é…ï¼Œä¸ºæ¯ä¸ªå—å®šåˆ¶æ ¡å‡†å·¥ä½œï¼Œä»¥ä¿æŒç¼“å­˜çš„æœ‰æ•ˆæ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šOUSACçš„å…³é”®åˆ›æ–°åœ¨äºŽï¼š1. æå‡ºäº†å¯å˜æŒ‡å¯¼å°ºåº¦çš„æ¦‚å¿µï¼Œå¹¶åˆ©ç”¨è¿›åŒ–ç®—æ³•è‡ªåŠ¨æœç´¢æœ€ä¼˜çš„è°ƒåº¦æ–¹æ¡ˆã€‚2. é’ˆå¯¹å¯å˜æŒ‡å¯¼å°ºåº¦ä¸‹çš„ç¼“å­˜å¤±æ•ˆé—®é¢˜ï¼Œæå‡ºäº†è‡ªé€‚åº”ç§©åˆ†é…æ–¹æ³•ï¼Œèƒ½å¤Ÿæ ¹æ®ä¸åŒTransformerå—çš„ç‰¹æ€§è¿›è¡Œæ ¡å‡†ï¼Œä¿è¯ç¼“å­˜çš„æœ‰æ•ˆæ€§ã€‚è¿™ä¸Žä¼ ç»Ÿç¼“å­˜æ–¹æ³•å‡è®¾CFGå°ºåº¦ä¸å˜æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŒ‡å¯¼è°ƒåº¦ä¼˜åŒ–é˜¶æ®µï¼Œä½¿ç”¨è¿›åŒ–ç®—æ³•æœç´¢æœ€ä¼˜çš„è·³è¿‡CFGçš„æ—¶é—´æ­¥å’Œå¯¹åº”çš„æŒ‡å¯¼å°ºåº¦ã€‚è¿›åŒ–ç®—æ³•çš„ç›®æ ‡å‡½æ•°éœ€è¦ç»¼åˆè€ƒè™‘ç”Ÿæˆè´¨é‡ï¼ˆå¦‚FIDã€CLIP Scoreï¼‰å’Œè®¡ç®—é‡ã€‚åœ¨è‡ªé€‚åº”ç¼“å­˜é˜¶æ®µï¼Œæ ¹æ®æ¯ä¸ªTransformerå—çš„æ¿€æ´»å€¼å˜åŒ–æƒ…å†µï¼ŒåŠ¨æ€è°ƒæ•´ç¼“å­˜çš„ç§©åˆ†é…ï¼Œä»¥æ›´å¥½åœ°æ•æ‰å¯å˜æŒ‡å¯¼å°ºåº¦ä¸‹çš„ç‰¹å¾å˜åŒ–ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

OUSACåœ¨DiT-XL/2 (ImageNet 512x512)ä¸Šå®žçŽ°äº†53%çš„è®¡ç®—èŠ‚çœå’Œ15%çš„è´¨é‡æå‡ï¼Œåœ¨PixArt-alpha (MSCOCO)ä¸Šå®žçŽ°äº†60%çš„èŠ‚çœå’Œ16.1%çš„æå‡ï¼Œåœ¨FLUXä¸Šå®žçŽ°äº†5å€çš„åŠ é€Ÿï¼ŒåŒæ—¶æé«˜äº†CLIP Scoreï¼Œè¶…è¿‡äº†50æ­¥çš„åŸºçº¿ã€‚è¿™äº›ç»“æžœè¡¨æ˜ŽOUSACæ˜¾è‘—ä¼˜äºŽçŽ°æœ‰çš„åŠ é€Ÿæ–¹æ³•ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

OUSACå¯åº”ç”¨äºŽå„ç§åŸºäºŽæ‰©æ•£æ¨¡åž‹çš„å›¾åƒç”Ÿæˆä»»åŠ¡ï¼Œå°¤å…¶é€‚ç”¨äºŽå¯¹è®¡ç®—èµ„æºæœ‰é™åˆ¶æˆ–å¯¹ç”Ÿæˆé€Ÿåº¦æœ‰è¾ƒé«˜è¦æ±‚çš„åœºæ™¯ã€‚ä¾‹å¦‚ï¼Œç§»åŠ¨è®¾å¤‡ä¸Šçš„å›¾åƒç”Ÿæˆã€å®žæ—¶å›¾åƒç¼–è¾‘ã€ä»¥åŠå¤§è§„æ¨¡å›¾åƒæ•°æ®é›†çš„ç”Ÿæˆç­‰ã€‚è¯¥ç ”ç©¶æœ‰æœ›æŽ¨åŠ¨æ‰©æ•£æ¨¡åž‹åœ¨æ›´å¹¿æ³›é¢†åŸŸçš„åº”ç”¨ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Diffusion models have emerged as the dominant paradigm for high-quality image generation, yet their computational expense remains substantial due to iterative denoising. Classifier-Free Guidance (CFG) significantly enhances generation quality and controllability but doubles the computation by requiring both conditional and unconditional forward passes at every timestep. We present OUSAC (Optimized gUidance Scheduling with Adaptive Caching), a framework that accelerates diffusion transformers (DiT) through systematic optimization. Our key insight is that variable guidance scales enable sparse computation: adjusting scales at certain timesteps can compensate for skipping CFG at others, enabling both fewer total sampling steps and fewer CFG steps while maintaining quality. However, variable guidance patterns introduce denoising deviations that undermine standard caching methods, which assume constant CFG scales across steps. Moreover, different transformer blocks are affected at different levels under dynamic conditions. This paper develops a two-stage approach leveraging these insights. Stage-1 employs evolutionary algorithms to jointly optimize which timesteps to skip and what guidance scale to use, eliminating up to 82% of unconditional passes. Stage-2 introduces adaptive rank allocation that tailors calibration efforts per transformer block, maintaining caching effectiveness under variable guidance. Experiments demonstrate that OUSAC significantly outperforms state-of-the-art acceleration methods, achieving 53% computational savings with 15% quality improvement on DiT-XL/2 (ImageNet 512x512), 60% savings with 16.1% improvement on PixArt-alpha (MSCOCO), and 5x speedup on FLUX while improving CLIP Score over the 50-step baseline.

