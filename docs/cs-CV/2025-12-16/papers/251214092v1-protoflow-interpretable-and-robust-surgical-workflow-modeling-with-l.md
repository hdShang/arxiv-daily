---
layout: default
title: ProtoFlow: Interpretable and Robust Surgical Workflow Modeling with Learned Dynamic Scene Graph Prototypes
---

# ProtoFlow: Interpretable and Robust Surgical Workflow Modeling with Learned Dynamic Scene Graph Prototypes

**arXiv**: [2512.14092v1](https://arxiv.org/abs/2512.14092) | [PDF](https://arxiv.org/pdf/2512.14092.pdf)

**ä½œè€…**: Felix Holm, Ghazal Ghazaei, Nassir Navab

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ProtoFlowï¼šåˆ©ç”¨åŠ¨æ€åœºæ™¯å›¾åŽŸåž‹ï¼Œå®žçŽ°å¯è§£é‡Šä¸”é²æ£’çš„æ‰‹æœ¯å·¥ä½œæµå»ºæ¨¡**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å¼ºåŒ–å­¦ä¹ ä¸Žæ¨¡ä»¿å­¦ä¹  (RL & IL)** **åŠ¨ä½œç”Ÿæˆä¸Žç‰©ç†åŠ¨ç”» (Animation & Physics)** **å…·èº«æ™ºèƒ½ä¸Žè¡¨å¾å­¦ä¹  (Embodied AI & Representation)**

**å…³é”®è¯**: `æ‰‹æœ¯å·¥ä½œæµå»ºæ¨¡` `åŠ¨æ€åœºæ™¯å›¾` `å›¾ç¥žç»ç½‘ç»œ` `åŽŸåž‹å­¦ä¹ ` `è‡ªç›‘ç£å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ‰‹æœ¯è¯†åˆ«é¢ä¸´æ•°æ®ç¨€ç¼ºã€æ ‡æ³¨æˆæœ¬é«˜æ˜‚ä»¥åŠæ¨¡åž‹ç¼ºä¹å¯è§£é‡Šæ€§çš„æŒ‘æˆ˜ï¼Œé˜»ç¢äº†AIè¾…åŠ©æ‰‹æœ¯çš„å‘å±•ã€‚
2. ProtoFlowé€šè¿‡å­¦ä¹ åŠ¨æ€åœºæ™¯å›¾åŽŸåž‹æ¥å»ºæ¨¡æ‰‹æœ¯å·¥ä½œæµï¼Œåˆ©ç”¨å›¾ç¥žç»ç½‘ç»œå’Œè‡ªç›‘ç£å­¦ä¹ æå‡æ¨¡åž‹é²æ£’æ€§ä¸Žå¯è§£é‡Šæ€§ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒProtoFlowåœ¨å‡†ç¡®æ€§å’Œé²æ£’æ€§ä¸Šä¼˜äºŽä¼ ç»ŸGNNï¼Œå°¤å…¶åœ¨å°‘æ ·æœ¬æƒ…å†µä¸‹è¡¨çŽ°å‡ºè‰²ï¼Œå¹¶èƒ½æœ‰æ•ˆè¯†åˆ«æ‰‹æœ¯å­æŠ€æœ¯ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºProtoFlowï¼Œä¸€ä¸ªæ–°é¢–çš„æ¡†æž¶ï¼Œé€šè¿‡å­¦ä¹ åŠ¨æ€åœºæ™¯å›¾åŽŸåž‹æ¥å»ºæ¨¡å¤æ‚çš„æ‰‹æœ¯å·¥ä½œæµï¼Œæ—¨åœ¨è§£å†³æ‰‹æœ¯è¯†åˆ«ä¸­æ•°æ®ç¨€ç¼ºã€æ ‡æ³¨æˆæœ¬é«˜å’Œç¼ºä¹å¯è§£é‡Šæ€§æ¨¡åž‹çš„é—®é¢˜ã€‚ProtoFlowåˆ©ç”¨å›¾ç¥žç»ç½‘ç»œï¼ˆGNNï¼‰ç¼–ç å™¨-è§£ç å™¨æž¶æž„ï¼Œç»“åˆè‡ªç›‘ç£é¢„è®­ç»ƒä»¥å­¦ä¹ ä¸°å¯Œçš„è¡¨ç¤ºï¼Œä»¥åŠåŸºäºŽåŽŸåž‹çš„å¾®è°ƒé˜¶æ®µã€‚è¯¥è¿‡ç¨‹å‘çŽ°å¹¶ä¼˜åŒ–æ ¸å¿ƒåŽŸåž‹ï¼Œè¿™äº›åŽŸåž‹å°è£…äº†æ‰‹æœ¯äº¤äº’ä¸­é‡å¤å‡ºçŽ°çš„ã€å…·æœ‰ä¸´åºŠæ„ä¹‰çš„æ¨¡å¼ï¼Œä¸ºå·¥ä½œæµåˆ†æžå¥ å®šäº†å¯è§£é‡Šçš„åŸºç¡€ã€‚åœ¨CAT-SGæ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜Žï¼ŒProtoFlowä¸ä»…åœ¨æ•´ä½“å‡†ç¡®æ€§ä¸Šä¼˜äºŽæ ‡å‡†GNNåŸºçº¿ï¼Œè€Œä¸”åœ¨æœ‰é™æ•°æ®å’Œå°‘æ ·æœ¬åœºæ™¯ä¸­è¡¨çŽ°å‡ºå“è¶Šçš„é²æ£’æ€§ï¼Œå³ä½¿ä»…ç”¨ä¸€ä¸ªæ‰‹æœ¯è§†é¢‘è¿›è¡Œè®­ç»ƒä¹Ÿèƒ½ä¿æŒå¼ºå¤§çš„æ€§èƒ½ã€‚å®šæ€§åˆ†æžè¿›ä¸€æ­¥è¡¨æ˜Žï¼Œå­¦ä¹ åˆ°çš„åŽŸåž‹æˆåŠŸè¯†åˆ«äº†ä¸åŒçš„æ‰‹æœ¯å­æŠ€æœ¯ï¼Œå¹¶ä¸ºå·¥ä½œæµåå·®å’Œç½•è§å¹¶å‘ç—‡æä¾›äº†æ¸…æ™°ã€å¯è§£é‡Šçš„è§è§£ã€‚ProtoFlowå°†é²æ£’çš„è¡¨ç¤ºå­¦ä¹ ä¸Žå›ºæœ‰çš„å¯è§£é‡Šæ€§ç›¸ç»“åˆï¼Œä»£è¡¨ç€æœç€å¼€å‘æ›´é€æ˜Žã€å¯é å’Œæ•°æ®é«˜æ•ˆçš„AIç³»ç»Ÿè¿ˆå‡ºçš„é‡è¦ä¸€æ­¥ï¼ŒåŠ é€Ÿäº†å…¶åœ¨æ‰‹æœ¯åŸ¹è®­ã€å®žæ—¶å†³ç­–æ”¯æŒå’Œå·¥ä½œæµä¼˜åŒ–ä¸­çš„ä¸´åºŠåº”ç”¨æ½œåŠ›ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æ‰‹æœ¯å·¥ä½œæµå»ºæ¨¡ä¸­æ•°æ®ç¨€ç¼ºã€æ ‡æ³¨æˆæœ¬é«˜æ˜‚ä»¥åŠæ¨¡åž‹ç¼ºä¹å¯è§£é‡Šæ€§çš„é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•éš¾ä»¥åœ¨æ•°æ®æœ‰é™çš„æƒ…å†µä¸‹è¿›è¡Œæœ‰æ•ˆçš„å­¦ä¹ ï¼Œå¹¶ä¸”ç¼ºä¹å¯¹æ‰‹æœ¯è¿‡ç¨‹çš„æ¸…æ™°è§£é‡Šï¼Œé™åˆ¶äº†å…¶åœ¨ä¸´åºŠçŽ¯å¢ƒä¸­çš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šProtoFlowçš„æ ¸å¿ƒæ€è·¯æ˜¯å­¦ä¹ ä¸€ç»„å…·æœ‰ä»£è¡¨æ€§çš„â€œåŽŸåž‹â€åœºæ™¯å›¾ï¼Œè¿™äº›åŽŸåž‹èƒ½å¤Ÿæ•æ‰æ‰‹æœ¯è¿‡ç¨‹ä¸­çš„å…³é”®äº¤äº’æ¨¡å¼ã€‚é€šè¿‡å°†æ–°çš„æ‰‹æœ¯åœºæ™¯ä¸Žè¿™äº›åŽŸåž‹è¿›è¡Œæ¯”è¾ƒï¼Œæ¨¡åž‹å¯ä»¥è¯†åˆ«æ‰‹æœ¯é˜¶æ®µã€æ£€æµ‹å¼‚å¸¸æƒ…å†µï¼Œå¹¶æä¾›å¯¹æ‰‹æœ¯è¿‡ç¨‹çš„è§£é‡Šã€‚è¿™ç§åŸºäºŽåŽŸåž‹çš„æ–¹æ³•æé«˜äº†æ¨¡åž‹çš„é²æ£’æ€§å’Œå¯è§£é‡Šæ€§ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šProtoFlowé‡‡ç”¨å›¾ç¥žç»ç½‘ç»œï¼ˆGNNï¼‰ç¼–ç å™¨-è§£ç å™¨æž¶æž„ã€‚é¦–å…ˆï¼Œä½¿ç”¨è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•å¯¹GNNç¼–ç å™¨è¿›è¡Œé¢„è®­ç»ƒï¼Œä½¿å…¶èƒ½å¤Ÿå­¦ä¹ åˆ°ä¸°å¯Œçš„åœºæ™¯å›¾è¡¨ç¤ºã€‚ç„¶åŽï¼Œé€šè¿‡åŽŸåž‹å­¦ä¹ æ¨¡å—ï¼Œä»Žé¢„è®­ç»ƒçš„è¡¨ç¤ºä¸­æå–ä¸€ç»„å…·æœ‰ä»£è¡¨æ€§çš„åŽŸåž‹ã€‚æœ€åŽï¼Œä½¿ç”¨è§£ç å™¨å°†è¿™äº›åŽŸåž‹æ˜ å°„å›žåœºæ™¯å›¾ï¼Œå¹¶è¿›è¡Œæ‰‹æœ¯å·¥ä½œæµçš„åˆ†æžå’Œé¢„æµ‹ã€‚æ•´ä¸ªæ¡†æž¶åŒ…å«é¢„è®­ç»ƒã€åŽŸåž‹å­¦ä¹ å’Œå¾®è°ƒä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚

**å…³é”®åˆ›æ–°**ï¼šProtoFlowçš„å…³é”®åˆ›æ–°åœ¨äºŽå°†åŽŸåž‹å­¦ä¹ ä¸ŽåŠ¨æ€åœºæ™¯å›¾å»ºæ¨¡ç›¸ç»“åˆã€‚é€šè¿‡å­¦ä¹ ä¸€ç»„å…·æœ‰ä»£è¡¨æ€§çš„åŽŸåž‹ï¼Œæ¨¡åž‹èƒ½å¤Ÿæ›´å¥½åœ°æ³›åŒ–åˆ°æ–°çš„æ‰‹æœ¯åœºæ™¯ï¼Œå¹¶ä¸”æä¾›å¯¹æ‰‹æœ¯è¿‡ç¨‹çš„æ¸…æ™°è§£é‡Šã€‚æ­¤å¤–ï¼Œè‡ªç›‘ç£é¢„è®­ç»ƒæ–¹æ³•ä¹Ÿæé«˜äº†æ¨¡åž‹åœ¨æ•°æ®æœ‰é™æƒ…å†µä¸‹çš„å­¦ä¹ èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šProtoFlowä½¿ç”¨å¯¹æ¯”å­¦ä¹ ä½œä¸ºè‡ªç›‘ç£é¢„è®­ç»ƒçš„ç›®æ ‡ï¼Œé¼“åŠ±æ¨¡åž‹å­¦ä¹ åˆ°åŒºåˆ†ä¸åŒåœºæ™¯å›¾çš„èƒ½åŠ›ã€‚åŽŸåž‹å­¦ä¹ æ¨¡å—ä½¿ç”¨k-meansèšç±»ç®—æ³•ä»Žé¢„è®­ç»ƒçš„åœºæ™¯å›¾è¡¨ç¤ºä¸­æå–åŽŸåž‹ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬é‡æž„æŸå¤±å’Œå¯¹æ¯”æŸå¤±ï¼Œç”¨äºŽä¼˜åŒ–åŽŸåž‹å’Œè§£ç å™¨ã€‚GNNé‡‡ç”¨Graph Attention Network (GAT)ç»“æž„ï¼Œä»¥æ›´å¥½åœ°æ•æ‰èŠ‚ç‚¹ä¹‹é—´çš„å…³ç³»ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

ProtoFlowåœ¨CAT-SGæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æˆæžœï¼Œåœ¨æ•´ä½“å‡†ç¡®æ€§ä¸Šä¼˜äºŽæ ‡å‡†GNNåŸºçº¿ã€‚æ›´é‡è¦çš„æ˜¯ï¼ŒProtoFlowåœ¨æœ‰é™æ•°æ®å’Œå°‘æ ·æœ¬åœºæ™¯ä¸­è¡¨çŽ°å‡ºå“è¶Šçš„é²æ£’æ€§ï¼Œå³ä½¿ä»…ç”¨ä¸€ä¸ªæ‰‹æœ¯è§†é¢‘è¿›è¡Œè®­ç»ƒä¹Ÿèƒ½ä¿æŒå¼ºå¤§çš„æ€§èƒ½ã€‚å®šæ€§åˆ†æžè¡¨æ˜Žï¼Œå­¦ä¹ åˆ°çš„åŽŸåž‹èƒ½å¤ŸæˆåŠŸè¯†åˆ«ä¸åŒçš„æ‰‹æœ¯å­æŠ€æœ¯ï¼Œå¹¶ä¸ºå·¥ä½œæµåå·®å’Œç½•è§å¹¶å‘ç—‡æä¾›æ¸…æ™°ã€å¯è§£é‡Šçš„è§è§£ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

ProtoFlowå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼ŒåŒ…æ‹¬æ‰‹æœ¯åŸ¹è®­ã€å®žæ—¶å†³ç­–æ”¯æŒå’Œå·¥ä½œæµä¼˜åŒ–ã€‚å®ƒå¯ä»¥å¸®åŠ©åŒ»ç”Ÿæ›´å¥½åœ°ç†è§£æ‰‹æœ¯è¿‡ç¨‹ï¼Œæé«˜æ‰‹æœ¯è´¨é‡å’Œå®‰å…¨æ€§ã€‚åœ¨æ‰‹æœ¯åŸ¹è®­ä¸­ï¼ŒProtoFlowå¯ä»¥ç”¨äºŽè¯„ä¼°å­¦å‘˜çš„æ‰‹æœ¯æŠ€èƒ½ï¼Œå¹¶æä¾›ä¸ªæ€§åŒ–çš„åé¦ˆã€‚åœ¨å®žæ—¶å†³ç­–æ”¯æŒä¸­ï¼Œå®ƒå¯ä»¥å¸®åŠ©åŒ»ç”Ÿæ£€æµ‹æ‰‹æœ¯ä¸­çš„å¼‚å¸¸æƒ…å†µï¼Œå¹¶æä¾›ç›¸åº”çš„å»ºè®®ã€‚åœ¨å·¥ä½œæµä¼˜åŒ–ä¸­ï¼Œå®ƒå¯ä»¥ç”¨äºŽåˆ†æžæ‰‹æœ¯æµç¨‹ï¼Œå‘çŽ°ç“¶é¢ˆå¹¶è¿›è¡Œæ”¹è¿›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Purpose: Detailed surgical recognition is critical for advancing AI-assisted surgery, yet progress is hampered by high annotation costs, data scarcity, and a lack of interpretable models. While scene graphs offer a structured abstraction of surgical events, their full potential remains untapped. In this work, we introduce ProtoFlow, a novel framework that learns dynamic scene graph prototypes to model complex surgical workflows in an interpretable and robust manner.
>   Methods: ProtoFlow leverages a graph neural network (GNN) encoder-decoder architecture that combines self-supervised pretraining for rich representation learning with a prototype-based fine-tuning stage. This process discovers and refines core prototypes that encapsulate recurring, clinically meaningful patterns of surgical interaction, forming an explainable foundation for workflow analysis.
>   Results: We evaluate our approach on the fine-grained CAT-SG dataset. ProtoFlow not only outperforms standard GNN baselines in overall accuracy but also demonstrates exceptional robustness in limited-data, few-shot scenarios, maintaining strong performance when trained on as few as one surgical video. Our qualitative analyses further show that the learned prototypes successfully identify distinct surgical sub-techniques and provide clear, interpretable insights into workflow deviations and rare complications.
>   Conclusion: By uniting robust representation learning with inherent explainability, ProtoFlow represents a significant step toward developing more transparent, reliable, and data-efficient AI systems, accelerating their potential for clinical adoption in surgical training, real-time decision support, and workflow optimization.

