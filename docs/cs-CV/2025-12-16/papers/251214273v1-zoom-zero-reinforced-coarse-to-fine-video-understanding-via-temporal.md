---
layout: default
title: Zoom-Zero: Reinforced Coarse-to-Fine Video Understanding via Temporal Zoom-in
---

# Zoom-Zero: Reinforced Coarse-to-Fine Video Understanding via Temporal Zoom-in

**arXiv**: [2512.14273v1](https://arxiv.org/abs/2512.14273) | [PDF](https://arxiv.org/pdf/2512.14273.pdf)

**ä½œè€…**: Xiaoqian Shen, Min-Hung Chen, Yu-Chiang Frank Wang, Mohamed Elhoseiny, Ryo Hachiuma

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: Project page: https://xiaoqian-shen.github.io/Zoom-Zero/

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Zoom-Zeroï¼šé€šè¿‡æ—¶é—´åŸŸç¼©æ”¾å¢žå¼ºè§†é¢‘ç†è§£ï¼Œè§£å†³GVQAä¸­æ—¶åºå®šä½ä¸å‡†é—®é¢˜ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `è§†é¢‘ç†è§£` `Grounded Video Question Answering` `æ—¶é—´åŸŸç¼©æ”¾` `å¼ºåŒ–å­¦ä¹ ` `å¤šæ¨¡æ€å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰GVQAæ¨¡åž‹æ—¶åºæ„ŸçŸ¥èƒ½åŠ›æœ‰é™ï¼Œéš¾ä»¥å‡†ç¡®åœ°å°†ç­”æ¡ˆå®šä½åˆ°è§†é¢‘ç‰‡æ®µï¼Œå¯¼è‡´æ—¶åºè¯¯åˆ¤ã€‚
2. Zoom-Zeroé‡‡ç”¨ç”±ç²—åˆ°ç²¾çš„ç­–ç•¥ï¼Œå…ˆç²—ç•¥å®šä½ç›¸å…³ç‰‡æ®µï¼Œå†ç²¾ç»†ç¼©æ”¾å…³é”®å¸§ï¼Œè¿›è¡Œè§†è§‰éªŒè¯ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒZoom-Zeroåœ¨æ—¶åºå®šä½å’Œç­”æ¡ˆå‡†ç¡®çŽ‡ä¸Šå‡æœ‰æ˜¾è‘—æå‡ï¼Œå°¤å…¶åœ¨é•¿è§†é¢‘ç†è§£æ–¹é¢ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºZoom-Zeroï¼Œä¸€ä¸ªç”±ç²—åˆ°ç²¾çš„æ¡†æž¶ï¼Œæ—¨åœ¨æå‡Grounded Video Question Answering (GVQA) ä»»åŠ¡çš„æ€§èƒ½ã€‚çŽ°æœ‰çš„å¤§åž‹è§†é¢‘è¯­è¨€æ¨¡åž‹(LVLMs)åœ¨æ—¶åºæ„ŸçŸ¥æ–¹é¢å­˜åœ¨å±€é™æ€§ï¼Œè€ŒåŸºäºŽGroup Relative Policy Optimization (GRPO)çš„æ–¹æ³•éš¾ä»¥å‡†ç¡®åœ°å°†ç­”æ¡ˆå®šä½åˆ°ç›¸å…³çš„è§†é¢‘ç‰‡æ®µï¼Œå¯¼è‡´æ—¶åºè¯¯åˆ¤å’Œå¹»è§‰ã€‚Zoom-Zeroé¦–å…ˆå®šä½ä¸ŽæŸ¥è¯¢ç›¸å…³çš„ç‰‡æ®µï¼Œç„¶åŽè¿›è¡Œæ—¶é—´åŸŸç¼©æ”¾ï¼Œèšç„¦äºŽæœ€æ˜¾è‘—çš„å¸§ï¼Œä»¥è¿›è¡Œæ›´ç²¾ç»†çš„è§†è§‰éªŒè¯ã€‚è¯¥æ–¹æ³•é€šè¿‡å¼•å…¥ç¼©æ”¾ç²¾åº¦å¥–åŠ±æ¥éªŒè¯æ—¶åºå®šä½çš„å‡†ç¡®æ€§ï¼Œå¹¶ä¿ƒè¿›å¯¹å®šä½å¸§çš„ç»†ç²’åº¦è§†è§‰éªŒè¯ï¼›åŒæ—¶é‡‡ç”¨tokené€‰æ‹©æ€§ä¿¡ç”¨åˆ†é…ï¼Œå°†å¥–åŠ±åˆ†é…ç»™è´Ÿè´£æ—¶åºå®šä½æˆ–ç­”æ¡ˆç”Ÿæˆçš„tokenï¼Œä»Žè€Œç¼“è§£GRPOåœ¨å¤„ç†å¤šæ–¹é¢å¥–åŠ±ä¿¡å·æ—¶çš„é—®é¢˜ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨NExT-GQAå’ŒReXTimeæ•°æ®é›†ä¸Šåˆ†åˆ«å°†æ—¶åºå®šä½ç²¾åº¦æé«˜äº†5.2%å’Œ4.6%ï¼Œå¹¶å°†å¹³å‡ç­”æ¡ˆå‡†ç¡®çŽ‡æé«˜äº†2.4%ã€‚æ­¤å¤–ï¼Œåœ¨æŽ¨ç†è¿‡ç¨‹ä¸­é‡‡ç”¨ç”±ç²—åˆ°ç²¾çš„ç¼©æ”¾æ–¹æ³•ï¼Œåœ¨ä¸å½±å“å…¨å±€ä¸Šä¸‹æ–‡çš„æƒ…å†µä¸‹ä¿ç•™äº†å…³é”®çš„è§†è§‰ç»†èŠ‚ï¼Œä»Žè€Œè¿›ä¸€æ­¥æå‡äº†é•¿è§†é¢‘ç†è§£èƒ½åŠ›ï¼Œåœ¨é•¿è§†é¢‘åŸºå‡†æµ‹è¯•ä¸­å¹³å‡æé«˜äº†6.4%ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³Grounded Video Question Answering (GVQA)ä»»åŠ¡ä¸­ï¼ŒçŽ°æœ‰å¤§åž‹è§†é¢‘è¯­è¨€æ¨¡åž‹(LVLMs)æ—¶åºæ„ŸçŸ¥èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•ï¼Œå¦‚åŸºäºŽGroup Relative Policy Optimization (GRPO)çš„æ–¹æ³•ï¼Œéš¾ä»¥å‡†ç¡®åœ°å°†ç­”æ¡ˆå®šä½åˆ°ç›¸å…³çš„è§†é¢‘ç‰‡æ®µï¼Œå¯¼è‡´æ—¶åºè¯¯åˆ¤å’Œå¹»è§‰ï¼Œå½±å“ç­”æ¡ˆçš„å‡†ç¡®æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é‡‡ç”¨ä¸€ç§ç”±ç²—åˆ°ç²¾çš„æ—¶é—´åŸŸç¼©æ”¾ç­–ç•¥ã€‚é¦–å…ˆï¼Œç²—ç•¥åœ°å®šä½ä¸Žé—®é¢˜ç›¸å…³çš„è§†é¢‘ç‰‡æ®µï¼›ç„¶åŽï¼Œå¯¹è¿™äº›ç‰‡æ®µè¿›è¡Œæ—¶é—´åŸŸçš„â€œæ”¾å¤§â€ï¼Œèšç„¦äºŽæœ€å…³é”®çš„å¸§ï¼Œè¿›è¡Œæ›´ç»†è‡´çš„è§†è§‰éªŒè¯ã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨æé«˜æ¨¡åž‹å¯¹è§†é¢‘å†…å®¹çš„æ—¶åºæ„ŸçŸ¥èƒ½åŠ›ï¼Œä»Žè€Œæ›´å‡†ç¡®åœ°å®šä½ç­”æ¡ˆã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šZoom-Zeroæ¡†æž¶åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šç²—ç•¥å®šä½é˜¶æ®µå’Œç²¾ç»†ç¼©æ”¾é˜¶æ®µã€‚åœ¨ç²—ç•¥å®šä½é˜¶æ®µï¼Œæ¨¡åž‹é¦–å…ˆæ ¹æ®é—®é¢˜å®šä½åˆ°è‹¥å¹²ä¸ªå€™é€‰çš„è§†é¢‘ç‰‡æ®µã€‚åœ¨ç²¾ç»†ç¼©æ”¾é˜¶æ®µï¼Œæ¨¡åž‹å¯¹è¿™äº›ç‰‡æ®µè¿›è¡Œæ—¶é—´åŸŸçš„æ”¾å¤§ï¼Œæå–å…³é”®å¸§ï¼Œå¹¶è¿›è¡Œæ›´ç»†è‡´çš„è§†è§‰éªŒè¯ã€‚æ•´ä¸ªæ¡†æž¶åˆ©ç”¨å¼ºåŒ–å­¦ä¹ è¿›è¡Œè®­ç»ƒï¼Œé€šè¿‡å¥–åŠ±æœºåˆ¶æ¥ä¼˜åŒ–æ¨¡åž‹çš„æ—¶åºå®šä½èƒ½åŠ›å’Œç­”æ¡ˆç”Ÿæˆèƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°ç‚¹åœ¨äºŽä¸¤ä¸ªæ–¹é¢ï¼šä¸€æ˜¯å¼•å…¥äº†â€œç¼©æ”¾ç²¾åº¦å¥–åŠ±â€ï¼Œç”¨äºŽéªŒè¯æ—¶åºå®šä½çš„å‡†ç¡®æ€§ï¼Œå¹¶ä¿ƒè¿›å¯¹å®šä½å¸§çš„ç»†ç²’åº¦è§†è§‰éªŒè¯ï¼›äºŒæ˜¯é‡‡ç”¨äº†â€œtokené€‰æ‹©æ€§ä¿¡ç”¨åˆ†é…â€ï¼Œå°†å¥–åŠ±åˆ†é…ç»™è´Ÿè´£æ—¶åºå®šä½æˆ–ç­”æ¡ˆç”Ÿæˆçš„tokenï¼Œä»Žè€Œç¼“è§£GRPOåœ¨å¤„ç†å¤šæ–¹é¢å¥–åŠ±ä¿¡å·æ—¶çš„é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç¼©æ”¾ç²¾åº¦å¥–åŠ±æ–¹é¢ï¼Œè®ºæ–‡è®¾è®¡äº†ä¸€ç§åŸºäºŽIoUï¼ˆIntersection over Unionï¼‰çš„å¥–åŠ±å‡½æ•°ï¼Œç”¨äºŽè¡¡é‡æ¨¡åž‹é¢„æµ‹çš„æ—¶åºç‰‡æ®µä¸ŽçœŸå®žç­”æ¡ˆç‰‡æ®µä¹‹é—´çš„é‡å ç¨‹åº¦ã€‚åœ¨tokené€‰æ‹©æ€§ä¿¡ç”¨åˆ†é…æ–¹é¢ï¼Œè®ºæ–‡ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶æ¥ç¡®å®šæ¯ä¸ªtokenå¯¹æ—¶åºå®šä½å’Œç­”æ¡ˆç”Ÿæˆçš„è´¡çŒ®ç¨‹åº¦ï¼Œå¹¶æ ¹æ®è´¡çŒ®ç¨‹åº¦åˆ†é…å¥–åŠ±ã€‚å…·ä½“çš„ç½‘ç»œç»“æž„å’Œå‚æ•°è®¾ç½®åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ï¼Œä½†æœªåœ¨æ­¤å¤„è¯¦ç»†å±•å¼€ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

Zoom-Zeroåœ¨NExT-GQAå’ŒReXTimeæ•°æ®é›†ä¸Šåˆ†åˆ«å°†æ—¶åºå®šä½ç²¾åº¦æé«˜äº†5.2%å’Œ4.6%ï¼Œå¹¶å°†å¹³å‡ç­”æ¡ˆå‡†ç¡®çŽ‡æé«˜äº†2.4%ã€‚æ­¤å¤–ï¼Œåœ¨é•¿è§†é¢‘åŸºå‡†æµ‹è¯•ä¸­ï¼ŒZoom-Zeroå¹³å‡æé«˜äº†6.4%ï¼Œè¡¨æ˜Žå…¶åœ¨å¤„ç†é•¿è§†é¢‘ç†è§£ä»»åŠ¡æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚è¿™äº›ç»“æžœè¡¨æ˜Žï¼ŒZoom-Zeroåœ¨GVQAä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

Zoom-ZeroæŠ€æœ¯å¯åº”ç”¨äºŽæ™ºèƒ½è§†é¢‘åˆ†æžã€è§†é¢‘æœç´¢ã€æ™ºèƒ½å®¢æœç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨è§†é¢‘æœç´¢ä¸­ï¼Œå¯ä»¥å¸®åŠ©ç”¨æˆ·å¿«é€Ÿå®šä½åˆ°è§†é¢‘ä¸­åŒ…å«ç‰¹å®šä¿¡æ¯çš„ç‰‡æ®µï¼›åœ¨æ™ºèƒ½å®¢æœä¸­ï¼Œå¯ä»¥æ ¹æ®ç”¨æˆ·æå‡ºçš„é—®é¢˜ï¼Œå‡†ç¡®åœ°ä»Žè§†é¢‘çŸ¥è¯†åº“ä¸­æ‰¾åˆ°ç­”æ¡ˆã€‚è¯¥ç ”ç©¶çš„æœªæ¥å½±å“åœ¨äºŽæå‡è§†é¢‘ç†è§£çš„å‡†ç¡®æ€§å’Œæ•ˆçŽ‡ï¼ŒæŽ¨åŠ¨è§†é¢‘æ™ºèƒ½åŒ–åº”ç”¨çš„å‘å±•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Grounded video question answering (GVQA) aims to localize relevant temporal segments in videos and generate accurate answers to a given question; however, large video-language models (LVLMs) exhibit limited temporal awareness. Although existing approaches based on Group Relative Policy Optimization (GRPO) attempt to improve temporal grounding, they still struggle to faithfully ground their answers in the relevant video evidence, leading to temporal mislocalization and hallucinations. In this work, we present Zoom-Zero, a coarse-to-fine framework that first localizes query-relevant segments and then temporally zooms into the most salient frames for finer-grained visual verification. Our method addresses the limits of GRPO for the GVQA task with two key innovations: (i) a zoom-in accuracy reward that validates the fidelity of temporal grounding prediction and facilitates fine-grained visual verification on grounded frames; (ii) token-selective credit assignment, which attributes rewards to the tokens responsible for temporal localization or answer generation, mitigating GRPO's issue in handling multi-faceted reward signals. Our proposed method advances grounded video question answering, improving temporal grounding by 5.2\% on NExT-GQA and 4.6\% on ReXTime, while also enhancing average answer accuracy by 2.4\%. Additionally, the coarse-to-fine zoom-in during inference further benefits long-form video understanding by preserving critical visual details without compromising global context, yielding an average improvement of 6.4\% on long-video benchmarks.

