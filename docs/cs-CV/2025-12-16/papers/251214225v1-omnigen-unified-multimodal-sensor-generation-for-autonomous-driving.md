---
layout: default
title: OmniGen: Unified Multimodal Sensor Generation for Autonomous Driving
---

# OmniGen: Unified Multimodal Sensor Generation for Autonomous Driving

**arXiv**: [2512.14225v1](https://arxiv.org/abs/2512.14225) | [PDF](https://arxiv.org/pdf/2512.14225.pdf)

**ä½œè€…**: Tao Tang, Enhui Ma, xia zhou, Letian Wang, Tianyi Yan, Xueyang Zhang, Kun Zhan, Peng Jia, XianPeng Lang, Jia-Wang Bian, Kaicheng Yu, Xiaodan Liang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: ACM MM 2025

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOmniGenç»Ÿä¸€æ¡†æž¶ä»¥è§£å†³è‡ªåŠ¨é©¾é©¶ä¸­å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®ç”Ÿæˆæ•ˆçŽ‡ä½Žã€å¯¹é½éš¾çš„é—®é¢˜**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **è‡ªåŠ¨é©¾é©¶** **è§†è§‰é‡Œç¨‹è®¡** **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `å¤šæ¨¡æ€ä¼ æ„Ÿå™¨ç”Ÿæˆ` `è‡ªåŠ¨é©¾é©¶æ•°æ®åˆæˆ` `é¸Ÿçž°å›¾ç©ºé—´` `ä½“æ¸²æŸ“` `æ‰©æ•£å˜æ¢å™¨` `å¯æŽ§ç”Ÿæˆ` `æ¿€å…‰é›·è¾¾ä¸Žç›¸æœºèžåˆ` `ç»Ÿä¸€æ¡†æž¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨å•æ¨¡æ€ç”Ÿæˆï¼Œå¯¼è‡´å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®æ•ˆçŽ‡ä½Žä¸‹å’Œå¯¹é½ä¸å‡†ç¡®ï¼Œé™åˆ¶äº†è‡ªåŠ¨é©¾é©¶æ•°æ®åˆæˆçš„å®žç”¨æ€§ã€‚
2. æå‡ºOmniGenç»Ÿä¸€æ¡†æž¶ï¼Œåˆ©ç”¨å…±äº«BEVç©ºé—´ç»Ÿä¸€å¤šæ¨¡æ€ç‰¹å¾ï¼Œå¹¶è®¾è®¡UAEæ–¹æ³•é€šè¿‡ä½“æ¸²æŸ“è”åˆè§£ç æ¿€å…‰é›·è¾¾å’Œç›¸æœºæ•°æ®ï¼Œç»“åˆDiTå’ŒControlNetå®žçŽ°å¯æŽ§ç”Ÿæˆã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒOmniGenåœ¨å¤šæ¨¡æ€ä¸€è‡´æ€§å’Œçµæ´»ä¼ æ„Ÿå™¨è°ƒæ•´æ–¹é¢å®žçŽ°äº†æœŸæœ›æ€§èƒ½ï¼ŒéªŒè¯äº†å…¶åœ¨ç»Ÿä¸€å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®ç”Ÿæˆä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è‡ªåŠ¨é©¾é©¶çš„æ˜¾è‘—è¿›æ­¥å¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–äºŽå¤§é‡çœŸå®žä¸–ç•Œæ•°æ®çš„æ”¶é›†ï¼Œä½†èŽ·å–å¤šæ ·åŒ–å’Œæžç«¯æ¡ˆä¾‹æ•°æ®ä»ç„¶æˆæœ¬é«˜æ˜‚ä¸”æ•ˆçŽ‡ä½Žä¸‹ã€‚ç”Ÿæˆæ¨¡åž‹é€šè¿‡åˆæˆé€¼çœŸçš„ä¼ æ„Ÿå™¨æ•°æ®æˆä¸ºä¸€ç§æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆã€‚ç„¶è€Œï¼ŒçŽ°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨å•æ¨¡æ€ç”Ÿæˆï¼Œå¯¼è‡´å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®æ•ˆçŽ‡ä½Žä¸‹å’Œå¯¹é½ä¸å‡†ç¡®ã€‚ä¸ºè§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†OmniGenï¼Œåœ¨ä¸€ä¸ªç»Ÿä¸€æ¡†æž¶ä¸­ç”Ÿæˆå¯¹é½çš„å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®ã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨å…±äº«çš„é¸Ÿçž°å›¾ç©ºé—´æ¥ç»Ÿä¸€å¤šæ¨¡æ€ç‰¹å¾ï¼Œå¹¶è®¾è®¡äº†ä¸€ç§æ–°é¢–çš„å¯æ³›åŒ–å¤šæ¨¡æ€é‡å»ºæ–¹æ³•UAEï¼Œä»¥è”åˆè§£ç æ¿€å…‰é›·è¾¾å’Œå¤šè§†è§’ç›¸æœºæ•°æ®ã€‚UAEé€šè¿‡ä½“æ¸²æŸ“å®žçŽ°å¤šæ¨¡æ€ä¼ æ„Ÿå™¨è§£ç ï¼Œä»Žè€Œå®žçŽ°å‡†ç¡®å’Œçµæ´»çš„é‡å»ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ç»“åˆäº†å¸¦æœ‰ControlNetåˆ†æ”¯çš„æ‰©æ•£å˜æ¢å™¨ï¼Œä»¥å®žçŽ°å¯æŽ§çš„å¤šæ¨¡æ€ä¼ æ„Ÿå™¨ç”Ÿæˆã€‚æˆ‘ä»¬çš„å…¨é¢å®žéªŒè¡¨æ˜Žï¼ŒOmniGenåœ¨å¤šæ¨¡æ€ä¸€è‡´æ€§å’Œçµæ´»ä¼ æ„Ÿå™¨è°ƒæ•´æ–¹é¢ï¼Œåœ¨ç»Ÿä¸€å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®ç”Ÿæˆä¸­å®žçŽ°äº†æœŸæœ›çš„æ€§èƒ½ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

OmniGençš„æ•´ä½“æ¡†æž¶æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®ç”Ÿæˆç³»ç»Ÿã€‚å…¶æ ¸å¿ƒåˆ›æ–°ç‚¹åŒ…æ‹¬ï¼šåˆ©ç”¨å…±äº«çš„é¸Ÿçž°å›¾ç©ºé—´æ¥ç»Ÿä¸€å¤šæ¨¡æ€ç‰¹å¾è¡¨ç¤ºï¼Œè®¾è®¡äº†ä¸€ç§æ–°é¢–çš„å¯æ³›åŒ–å¤šæ¨¡æ€é‡å»ºæ–¹æ³•UAEï¼Œè¯¥æ–¹æ³•é€šè¿‡ä½“æ¸²æŸ“æŠ€æœ¯è”åˆè§£ç æ¿€å…‰é›·è¾¾å’Œå¤šè§†è§’ç›¸æœºæ•°æ®ï¼Œå®žçŽ°å‡†ç¡®å’Œçµæ´»çš„é‡å»ºã€‚æ­¤å¤–ï¼Œæ¡†æž¶ç»“åˆäº†æ‰©æ•£å˜æ¢å™¨ä¸ŽControlNetåˆ†æ”¯ï¼Œä»¥æ”¯æŒå¯æŽ§çš„å¤šæ¨¡æ€ä¼ æ„Ÿå™¨ç”Ÿæˆã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºŽï¼ŒOmniGenä¸å†å±€é™äºŽå•æ¨¡æ€ç”Ÿæˆï¼Œè€Œæ˜¯é€šè¿‡ç»Ÿä¸€çš„BEVç©ºé—´å’ŒUAEè§£ç å™¨ï¼Œå®žçŽ°äº†å¤šæ¨¡æ€æ•°æ®çš„å¯¹é½å’ŒååŒç”Ÿæˆï¼Œæé«˜äº†æ•°æ®åˆæˆçš„æ•ˆçŽ‡å’Œä¸€è‡´æ€§ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœæ˜¾ç¤ºï¼ŒOmniGenåœ¨ç»Ÿä¸€å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®ç”Ÿæˆä¸­å®žçŽ°äº†å¤šæ¨¡æ€ä¸€è‡´æ€§å’Œçµæ´»ä¼ æ„Ÿå™¨è°ƒæ•´çš„æœŸæœ›æ€§èƒ½ï¼ŒéªŒè¯äº†å…¶æ¡†æž¶çš„æœ‰æ•ˆæ€§ï¼Œå…·ä½“æ€§èƒ½æå‡æ•°æ®æœªçŸ¥ï¼Œä½†å¼ºè°ƒäº†å…¶åœ¨è§£å†³çŽ°æœ‰æ–¹æ³•ä¸è¶³æ–¹é¢çš„ä¼˜åŠ¿ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶ä¸»è¦åº”ç”¨äºŽè‡ªåŠ¨é©¾é©¶é¢†åŸŸï¼Œé€šè¿‡ç”Ÿæˆå¤šæ ·åŒ–å’Œå¯¹é½çš„å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®ï¼Œå¯ä»¥é«˜æ•ˆåˆæˆæžç«¯æ¡ˆä¾‹æ•°æ®ï¼Œç”¨äºŽè®­ç»ƒå’Œæµ‹è¯•è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿï¼Œé™ä½Žæ•°æ®é‡‡é›†æˆæœ¬ï¼Œæå‡æ¨¡åž‹é²æ£’æ€§å’Œå®‰å…¨æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Autonomous driving has seen remarkable advancements, largely driven by extensive real-world data collection. However, acquiring diverse and corner-case data remains costly and inefficient. Generative models have emerged as a promising solution by synthesizing realistic sensor data. However, existing approaches primarily focus on single-modality generation, leading to inefficiencies and misalignment in multimodal sensor data. To address these challenges, we propose OminiGen, which generates aligned multimodal sensor data in a unified framework. Our approach leverages a shared Bird\u2019s Eye View (BEV) space to unify multimodal features and designs a novel generalizable multimodal reconstruction method, UAE, to jointly decode LiDAR and multi-view camera data. UAE achieves multimodal sensor decoding through volume rendering, enabling accurate and flexible reconstruction. Furthermore, we incorporate a Diffusion Transformer (DiT) with a ControlNet branch to enable controllable multimodal sensor generation. Our comprehensive experiments demonstrate that OminiGen achieves desired performances in unified multimodal sensor data generation with multimodal consistency and flexible sensor adjustments.

