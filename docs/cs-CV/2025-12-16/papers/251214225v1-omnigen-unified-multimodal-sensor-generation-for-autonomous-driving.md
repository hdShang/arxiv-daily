---
layout: default
title: OmniGen: Unified Multimodal Sensor Generation for Autonomous Driving
---

# OmniGen: Unified Multimodal Sensor Generation for Autonomous Driving

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.14225" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.14225v1</a>
  <a href="https://arxiv.org/pdf/2512.14225.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14225v1" onclick="toggleFavorite(this, '2512.14225v1', 'OmniGen: Unified Multimodal Sensor Generation for Autonomous Driving')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Tao Tang, Enhui Ma, xia zhou, Letian Wang, Tianyi Yan, Xueyang Zhang, Kun Zhan, Peng Jia, XianPeng Lang, Jia-Wang Bian, Kaicheng Yu, Xiaodan Liang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: ACM MM 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**OmniGenï¼šæå‡ºç»Ÿä¸€çš„å¤šæ¨¡æ€ä¼ æ„Ÿå™¨ç”Ÿæˆæ¡†æ¶ï¼Œç”¨äºè‡ªåŠ¨é©¾é©¶åœºæ™¯æ•°æ®å¢å¼ºã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è‡ªåŠ¨é©¾é©¶` `å¤šæ¨¡æ€æ•°æ®ç”Ÿæˆ` `ä¼ æ„Ÿå™¨èåˆ` `é¸Ÿç°å›¾` `æ‰©æ•£æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è‡ªåŠ¨é©¾é©¶æ•°æ®ç”Ÿæˆæ–¹æ³•ä¸»è¦é›†ä¸­äºå•æ¨¡æ€ï¼Œå¯¼è‡´å¤šæ¨¡æ€æ•°æ®ç”Ÿæˆæ•ˆç‡ä½ä¸”æ¨¡æ€é—´ä¸å¯¹é½ã€‚
2. OmniGenåˆ©ç”¨å…±äº«BEVç©ºé—´ç»Ÿä¸€å¤šæ¨¡æ€ç‰¹å¾ï¼Œå¹¶æå‡ºé€šç”¨å¤šæ¨¡æ€é‡å»ºæ–¹æ³•UAEè”åˆè§£ç æ¿€å…‰é›·è¾¾å’Œç›¸æœºæ•°æ®ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒOmniGenåœ¨å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®ç”Ÿæˆä¸­è¡¨ç°å‡ºè‰²ï¼Œä¿è¯äº†å¤šæ¨¡æ€ä¸€è‡´æ€§å¹¶æ”¯æŒçµæ´»çš„ä¼ æ„Ÿå™¨è°ƒæ•´ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è‡ªåŠ¨é©¾é©¶é¢†åŸŸçš„å‘å±•å¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–äºå¤§é‡çš„çœŸå®ä¸–ç•Œæ•°æ®ã€‚ç„¶è€Œï¼Œè·å–å¤šæ ·åŒ–å’Œæç«¯åœºæ™¯çš„æ•°æ®ä»ç„¶æˆæœ¬é«˜æ˜‚ä¸”æ•ˆç‡ä½ä¸‹ã€‚ç”Ÿæˆæ¨¡å‹é€šè¿‡åˆæˆé€¼çœŸçš„ä¼ æ„Ÿå™¨æ•°æ®æä¾›äº†ä¸€ä¸ªæœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆã€‚ä½†æ˜¯ï¼Œç°æœ‰çš„æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨å•æ¨¡æ€ç”Ÿæˆä¸Šï¼Œå¯¼è‡´å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®æ•ˆç‡ä½ä¸‹å’Œä¸å¯¹é½ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†OmniGenï¼Œå®ƒåœ¨ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ä¸­ç”Ÿæˆå¯¹é½çš„å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®ã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨å…±äº«çš„é¸Ÿç°å›¾ï¼ˆBEVï¼‰ç©ºé—´æ¥ç»Ÿä¸€å¤šæ¨¡æ€ç‰¹å¾ï¼Œå¹¶è®¾è®¡äº†ä¸€ç§æ–°é¢–çš„é€šç”¨å¤šæ¨¡æ€é‡å»ºæ–¹æ³•UAEï¼Œä»¥è”åˆè§£ç æ¿€å…‰é›·è¾¾å’Œå¤šè§†è§’ç›¸æœºæ•°æ®ã€‚UAEé€šè¿‡ä½“æ¸²æŸ“å®ç°å¤šæ¨¡æ€ä¼ æ„Ÿå™¨è§£ç ï¼Œä»è€Œå®ç°å‡†ç¡®è€Œçµæ´»çš„é‡å»ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ç»“åˆäº†å¸¦æœ‰ControlNetåˆ†æ”¯çš„Diffusion Transformerï¼ˆDiTï¼‰ï¼Œä»¥å®ç°å¯æ§çš„å¤šæ¨¡æ€ä¼ æ„Ÿå™¨ç”Ÿæˆã€‚æˆ‘ä»¬å…¨é¢çš„å®éªŒè¡¨æ˜ï¼ŒOminiGenåœ¨ç»Ÿä¸€çš„å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®ç”Ÿæˆä¸­å®ç°äº†æ‰€éœ€çš„æ€§èƒ½ï¼Œå…·æœ‰å¤šæ¨¡æ€ä¸€è‡´æ€§å’Œçµæ´»çš„ä¼ æ„Ÿå™¨è°ƒæ•´ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰è‡ªåŠ¨é©¾é©¶æ•°æ®ç”Ÿæˆæ–¹æ³•ä¸»è¦é›†ä¸­äºå•æ¨¡æ€ï¼Œæ— æ³•æœ‰æ•ˆç”Ÿæˆå¯¹é½çš„å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®ï¼Œå¯¼è‡´è®­ç»ƒæ•°æ®ä¸è¶³ï¼Œæ¨¡å‹æ³›åŒ–èƒ½åŠ›å—é™ã€‚è·å–çœŸå®ä¸–ç•Œçš„å¤šæ¨¡æ€æ•°æ®æˆæœ¬é«˜æ˜‚ï¼Œä¸”éš¾ä»¥è¦†ç›–æ‰€æœ‰corner caseåœºæ™¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šOmniGençš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å…±äº«çš„é¸Ÿç°å›¾ï¼ˆBEVï¼‰ç©ºé—´ä½œä¸ºå¤šæ¨¡æ€ç‰¹å¾çš„ç»Ÿä¸€è¡¨ç¤ºï¼Œä»è€Œå®ç°å¤šæ¨¡æ€æ•°æ®çš„å¯¹é½å’Œèåˆã€‚é€šè¿‡è®¾è®¡é€šç”¨çš„å¤šæ¨¡æ€é‡å»ºæ–¹æ³•ï¼Œå¯ä»¥ä»BEVè¡¨ç¤ºä¸­è§£ç å‡ºæ¿€å…‰é›·è¾¾å’Œå¤šè§†è§’ç›¸æœºæ•°æ®ï¼Œå®ç°å¤šæ¨¡æ€æ•°æ®çš„ç”Ÿæˆã€‚åŒæ—¶ï¼Œå¼•å…¥å¯æ§çš„æ‰©æ•£æ¨¡å‹ï¼Œå®ç°å¯¹ç”Ÿæˆæ•°æ®çš„çµæ´»æ§åˆ¶ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šOmniGençš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) å¤šæ¨¡æ€ç‰¹å¾ç¼–ç å™¨ï¼šå°†ä¸åŒæ¨¡æ€çš„ä¼ æ„Ÿå™¨æ•°æ®ï¼ˆå¦‚æ¿€å…‰é›·è¾¾ç‚¹äº‘å’Œå¤šè§†è§’å›¾åƒï¼‰ç¼–ç åˆ°å…±äº«çš„BEVç©ºé—´ä¸­ã€‚2) é€šç”¨å¤šæ¨¡æ€é‡å»ºæ¨¡å—ï¼ˆUAEï¼‰ï¼šä»BEVè¡¨ç¤ºä¸­è§£ç å‡ºæ¿€å…‰é›·è¾¾ç‚¹äº‘å’Œå¤šè§†è§’å›¾åƒã€‚UAEé‡‡ç”¨ä½“æ¸²æŸ“æŠ€æœ¯ï¼Œå®ç°å‡†ç¡®è€Œçµæ´»çš„é‡å»ºã€‚3) å¯æ§çš„æ‰©æ•£æ¨¡å‹ï¼šä½¿ç”¨Diffusion Transformerï¼ˆDiTï¼‰ä½œä¸ºç”Ÿæˆå™¨ï¼Œå¹¶ç»“åˆControlNetåˆ†æ”¯ï¼Œå®ç°å¯¹ç”Ÿæˆæ•°æ®çš„å¯æ§æ€§ï¼Œä¾‹å¦‚æ§åˆ¶åœºæ™¯çš„å¸ƒå±€å’Œå¯¹è±¡çš„å±æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šOmniGençš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„å¤šæ¨¡æ€ä¼ æ„Ÿå™¨ç”Ÿæˆæ¡†æ¶ï¼Œèƒ½å¤ŸåŒæ—¶ç”Ÿæˆå¯¹é½çš„æ¿€å…‰é›·è¾¾å’Œç›¸æœºæ•°æ®ã€‚2) è®¾è®¡äº†ä¸€ç§é€šç”¨çš„å¤šæ¨¡æ€é‡å»ºæ–¹æ³•UAEï¼Œé€šè¿‡ä½“æ¸²æŸ“å®ç°å¤šæ¨¡æ€æ•°æ®çš„è§£ç ï¼Œå…·æœ‰å¾ˆå¼ºçš„çµæ´»æ€§å’Œå‡†ç¡®æ€§ã€‚3) å¼•å…¥äº†å¯æ§çš„æ‰©æ•£æ¨¡å‹ï¼Œå¯ä»¥çµæ´»åœ°æ§åˆ¶ç”Ÿæˆæ•°æ®çš„å±æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šUAEæ¨¡å—ä½¿ç”¨ä½“æ¸²æŸ“æŠ€æœ¯ï¼Œå°†BEVç‰¹å¾è½¬æ¢ä¸ºä½“ç´ è¡¨ç¤ºï¼Œç„¶åé€šè¿‡å¯å¾®åˆ†çš„æ¸²æŸ“è¿‡ç¨‹ç”Ÿæˆæ¿€å…‰é›·è¾¾ç‚¹äº‘å’Œå¤šè§†è§’å›¾åƒã€‚æ‰©æ•£æ¨¡å‹é‡‡ç”¨Diffusion Transformer (DiT) æ¶æ„ï¼Œå¹¶ä½¿ç”¨ControlNetåˆ†æ”¯æ¥æ§åˆ¶ç”Ÿæˆè¿‡ç¨‹ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬é‡å»ºæŸå¤±ï¼ˆç”¨äºä¿è¯ç”Ÿæˆæ•°æ®çš„å‡†ç¡®æ€§ï¼‰å’Œå¯¹æŠ—æŸå¤±ï¼ˆç”¨äºæé«˜ç”Ÿæˆæ•°æ®çš„çœŸå®æ„Ÿï¼‰ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚æœªåœ¨æ‘˜è¦ä¸­è¯¦ç»†è¯´æ˜ï¼Œéœ€è¦å‚è€ƒè®ºæ–‡å…¨æ–‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡é€šè¿‡å®éªŒéªŒè¯äº†OmniGenåœ¨ç»Ÿä¸€å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®ç”Ÿæˆæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒOmniGenèƒ½å¤Ÿç”Ÿæˆå…·æœ‰å¤šæ¨¡æ€ä¸€è‡´æ€§å’Œçµæ´»ä¼ æ„Ÿå™¨è°ƒæ•´èƒ½åŠ›çš„æ•°æ®ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®ã€å¯¹æ¯”åŸºçº¿å’Œæå‡å¹…åº¦ç­‰ä¿¡æ¯éœ€è¦åœ¨è®ºæ–‡å…¨æ–‡ä¸­æŸ¥æ‰¾ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

OmniGenå¯åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ä»¿çœŸå¹³å°ï¼Œç”¨äºç”Ÿæˆå¤§è§„æ¨¡ã€å¤šæ ·åŒ–çš„è®­ç»ƒæ•°æ®ï¼Œä»è€Œæé«˜è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„æ„ŸçŸ¥ã€å†³ç­–å’Œæ§åˆ¶èƒ½åŠ›ã€‚è¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºæ•°æ®å¢å¼ºï¼Œæé«˜æ¨¡å‹åœ¨corner caseåœºæ™¯ä¸‹çš„é²æ£’æ€§ã€‚æ­¤å¤–ï¼ŒOmniGenè¿˜å¯ç”¨äºè‡ªåŠ¨é©¾é©¶ç®—æ³•çš„éªŒè¯å’Œè¯„ä¼°ï¼Œé™ä½å®è½¦æµ‹è¯•çš„æˆæœ¬å’Œé£é™©ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Autonomous driving has seen remarkable advancements, largely driven by extensive real-world data collection. However, acquiring diverse and corner-case data remains costly and inefficient. Generative models have emerged as a promising solution by synthesizing realistic sensor data. However, existing approaches primarily focus on single-modality generation, leading to inefficiencies and misalignment in multimodal sensor data. To address these challenges, we propose OminiGen, which generates aligned multimodal sensor data in a unified framework. Our approach leverages a shared Bird\u2019s Eye View (BEV) space to unify multimodal features and designs a novel generalizable multimodal reconstruction method, UAE, to jointly decode LiDAR and multi-view camera data. UAE achieves multimodal sensor decoding through volume rendering, enabling accurate and flexible reconstruction. Furthermore, we incorporate a Diffusion Transformer (DiT) with a ControlNet branch to enable controllable multimodal sensor generation. Our comprehensive experiments demonstrate that OminiGen achieves desired performances in unified multimodal sensor data generation with multimodal consistency and flexible sensor adjustments.

