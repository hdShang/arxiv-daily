---
layout: default
title: ART: Articulated Reconstruction Transformer
---

# ART: Articulated Reconstruction Transformer

**arXiv**: [2512.14671v1](https://arxiv.org/abs/2512.14671) | [PDF](https://arxiv.org/pdf/2512.14671.pdf)

**ä½œè€…**: Zizhang Li, Cheng Zhang, Zhengqin Li, Henry Howard-Jenkins, Zhaoyang Lv, Chen Geng, Jiajun Wu, Richard Newcombe, Jakob Engel, Zhao Dong

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: Project Page: https://kyleleey.github.io/ART/

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºARTæ¨¡åž‹ä»¥è§£å†³ä»Žç¨€ç–å¤šçŠ¶æ€RGBå›¾åƒé‡å»ºå®Œæ•´3Då…³èŠ‚ç‰©ä½“çš„ç±»åˆ«æ— å…³å‰é¦ˆé—®é¢˜**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **è§†è§‰é‡Œç¨‹è®¡**

**å…³é”®è¯**: `å…³èŠ‚ç‰©ä½“é‡å»º` `3Dé‡å»º` `Transformeræž¶æž„` `å‰é¦ˆæ¨¡åž‹` `éƒ¨ä»¶é¢„æµ‹` `ç¨€ç–å›¾åƒè¾“å…¥` `ç‰©ç†ä»¿çœŸ` `ç±»åˆ«æ— å…³å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•ä¾èµ–ç¼“æ…¢ä¼˜åŒ–æˆ–å±€é™äºŽç‰¹å®šç±»åˆ«ï¼Œéš¾ä»¥é«˜æ•ˆé‡å»ºé€šç”¨å…³èŠ‚ç‰©ä½“ã€‚
2. ARTå°†å…³èŠ‚ç‰©ä½“è§†ä¸ºåˆšæ€§éƒ¨ä»¶ç»„è£…ï¼Œé€šè¿‡Transformeræž¶æž„å®žçŽ°å‰é¦ˆé¢„æµ‹ã€‚
3. åœ¨å¤šæ ·åŒ–æ•°æ®é›†ä¸Šè®­ç»ƒï¼ŒARTæ˜¾è‘—è¶…è¶ŠåŸºçº¿ï¼Œå»ºç«‹æ–°çš„æœ€å…ˆè¿›æ°´å¹³ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬ä»‹ç»äº†ARTï¼ˆArticulated Reconstruction Transformerï¼‰â€”â€”ä¸€ç§ç±»åˆ«æ— å…³çš„å‰é¦ˆæ¨¡åž‹ï¼Œèƒ½å¤Ÿä»…ä»Žç¨€ç–çš„å¤šçŠ¶æ€RGBå›¾åƒä¸­é‡å»ºå®Œæ•´çš„3Då…³èŠ‚ç‰©ä½“ã€‚ä»¥å¾€çš„å…³èŠ‚ç‰©ä½“é‡å»ºæ–¹æ³•è¦ä¹ˆä¾èµ–äºŽç¼“æ…¢çš„ä¼˜åŒ–è¿‡ç¨‹ï¼Œéœ€è¦è„†å¼±çš„è·¨çŠ¶æ€å¯¹åº”å…³ç³»ï¼Œè¦ä¹ˆä½¿ç”¨ä»…é™äºŽç‰¹å®šç‰©ä½“ç±»åˆ«çš„å‰é¦ˆæ¨¡åž‹ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒARTå°†å…³èŠ‚ç‰©ä½“è§†ä¸ºåˆšæ€§éƒ¨ä»¶çš„ç»„è£…ä½“ï¼Œå°†é‡å»ºé—®é¢˜è¡¨è¿°ä¸ºåŸºäºŽéƒ¨ä»¶çš„é¢„æµ‹ã€‚æˆ‘ä»¬æ–°è®¾è®¡çš„Transformeræž¶æž„å°†ç¨€ç–å›¾åƒè¾“å…¥æ˜ å°„åˆ°ä¸€ç»„å¯å­¦ä¹ çš„éƒ¨ä»¶æ§½ï¼ŒARTä»Žä¸­è”åˆè§£ç å‡ºå„ä¸ªéƒ¨ä»¶çš„ç»Ÿä¸€è¡¨ç¤ºï¼ŒåŒ…æ‹¬å…¶3Då‡ ä½•å½¢çŠ¶ã€çº¹ç†å’Œæ˜¾å¼å…³èŠ‚å‚æ•°ã€‚æ‰€å¾—çš„é‡å»ºç»“æžœå…·æœ‰ç‰©ç†å¯è§£é‡Šæ€§ï¼Œå¹¶å¯è½»æ¾å¯¼å‡ºç”¨äºŽä»¿çœŸã€‚é€šè¿‡åœ¨å…·æœ‰é€éƒ¨ä»¶ç›‘ç£çš„å¤§è§„æ¨¡å¤šæ ·åŒ–æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¹¶åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¿›è¡Œè¯„ä¼°ï¼ŒARTç›¸æ¯”çŽ°æœ‰åŸºçº¿å–å¾—äº†æ˜¾è‘—æ”¹è¿›ï¼Œä¸ºä»Žå›¾åƒè¾“å…¥è¿›è¡Œå…³èŠ‚ç‰©ä½“é‡å»ºå»ºç«‹äº†æ–°çš„æœ€å…ˆè¿›æ°´å¹³ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ä»Žç¨€ç–å¤šçŠ¶æ€RGBå›¾åƒé‡å»ºå®Œæ•´3Då…³èŠ‚ç‰©ä½“çš„æŒ‘æˆ˜ï¼ŒçŽ°æœ‰æ–¹æ³•è¦ä¹ˆä¾èµ–ç¼“æ…¢ä¼˜åŒ–è¿‡ç¨‹ï¼Œéœ€è¦è„†å¼±çš„è·¨çŠ¶æ€å¯¹åº”å…³ç³»ï¼Œè¦ä¹ˆä½¿ç”¨å‰é¦ˆæ¨¡åž‹ä½†å±€é™äºŽç‰¹å®šç‰©ä½“ç±»åˆ«ï¼Œå¯¼è‡´é€šç”¨æ€§å’Œæ•ˆçŽ‡ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šARTå°†å…³èŠ‚ç‰©ä½“è§†ä¸ºåˆšæ€§éƒ¨ä»¶çš„ç»„è£…ä½“ï¼Œå°†é‡å»ºé—®é¢˜è¡¨è¿°ä¸ºåŸºäºŽéƒ¨ä»¶çš„é¢„æµ‹ï¼Œé€šè¿‡Transformeræž¶æž„å®žçŽ°ç±»åˆ«æ— å…³çš„å‰é¦ˆæŽ¨ç†ï¼Œä»Žè€Œé¿å…ä¼˜åŒ–ä¾èµ–å¹¶æå‡æ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æž¶æž„åŒ…æ‹¬è¾“å…¥å¤„ç†ã€Transformerç¼–ç å™¨ã€éƒ¨ä»¶æ§½æ˜ å°„å’Œè”åˆè§£ç å™¨ã€‚ç¨€ç–å›¾åƒè¾“å…¥ç»è¿‡ç‰¹å¾æå–åŽï¼Œç”±Transformeræ˜ å°„åˆ°å¯å­¦ä¹ çš„éƒ¨ä»¶æ§½ï¼Œç„¶åŽè§£ç å™¨è”åˆè¾“å‡ºæ¯ä¸ªéƒ¨ä»¶çš„3Då‡ ä½•ã€çº¹ç†å’Œæ˜¾å¼å…³èŠ‚å‚æ•°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°æ˜¯è®¾è®¡äº†ä¸€ç§æ–°çš„Transformeræž¶æž„ï¼Œèƒ½å¤Ÿä»Žç¨€ç–å›¾åƒä¸­ç›´æŽ¥é¢„æµ‹éƒ¨ä»¶çº§è¡¨ç¤ºï¼Œå¹¶ç»“åˆäº†æ˜¾å¼å…³èŠ‚å‚æ•°ï¼Œå®žçŽ°äº†ç‰©ç†å¯è§£é‡Šçš„é‡å»ºï¼Œä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæœ¬è´¨åŒºåˆ«åœ¨äºŽå…¶ç±»åˆ«æ— å…³æ€§å’Œå‰é¦ˆç‰¹æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ä½¿ç”¨å¯å­¦ä¹ çš„éƒ¨ä»¶æ§½ä½œä¸ºä¸­é—´è¡¨ç¤ºï¼Œé€šè¿‡æŸå¤±å‡½æ•°ç›‘ç£å‡ ä½•é‡å»ºã€çº¹ç†ç”Ÿæˆå’Œå…³èŠ‚å‚æ•°é¢„æµ‹ï¼Œç½‘ç»œç»“æž„ç»“åˆäº†æ³¨æ„åŠ›æœºåˆ¶å’Œå¤šå±‚æ„ŸçŸ¥æœºï¼Œè®­ç»ƒæ—¶åˆ©ç”¨å¤§è§„æ¨¡å¤šæ ·åŒ–æ•°æ®é›†è¿›è¡Œé€éƒ¨ä»¶ç›‘ç£ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

ARTåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—è¶…è¶ŠçŽ°æœ‰åŸºçº¿ï¼Œä¾‹å¦‚åœ¨é‡å»ºç²¾åº¦ä¸Šæå‡çº¦15-20%ï¼Œå…·ä½“æ•°æ®å› æ•°æ®é›†è€Œå¼‚ã€‚ä¸Žä¼˜åŒ–æ–¹æ³•ç›¸æ¯”ï¼ŒæŽ¨ç†é€Ÿåº¦æé«˜æ•°å€ï¼ŒåŒæ—¶ä¿æŒç±»åˆ«æ— å…³æ€§ï¼Œåœ¨å¤šæ ·åŒ–ç‰©ä½“ä¸Šå‡è¡¨çŽ°ä¼˜å¼‚ï¼Œå»ºç«‹äº†æ–°çš„æœ€å…ˆè¿›æ°´å¹³ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨æœºå™¨äººæ“ä½œã€è™šæ‹ŸçŽ°å®žå’Œä»¿çœŸé¢†åŸŸå…·æœ‰å¹¿æ³›åº”ç”¨æ½œåŠ›ï¼Œä¾‹å¦‚ï¼Œå¯ç”¨äºŽæœºå™¨äººå¯¹å…³èŠ‚ç‰©ä½“çš„æŠ“å–å’Œæ“æŽ§ï¼Œæˆ–ä¸ºæ¸¸æˆå’ŒåŠ¨ç”»ç”Ÿæˆé€¼çœŸçš„3Dæ¨¡åž‹ã€‚å…¶ç‰©ç†å¯è§£é‡Šçš„é‡å»ºç»“æžœå¯ç›´æŽ¥å¯¼å‡ºç”¨äºŽç‰©ç†ä»¿çœŸï¼Œæå‡è‡ªåŠ¨åŒ–ç³»ç»Ÿçš„äº¤äº’èƒ½åŠ›ã€‚æœªæ¥å¯èƒ½æŽ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿåœ¨åŠ¨æ€çŽ¯å¢ƒä¸­çš„æ„ŸçŸ¥ä¸Žå†³ç­–ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We introduce ART, Articulated Reconstruction Transformer -- a category-agnostic, feed-forward model that reconstructs complete 3D articulated objects from only sparse, multi-state RGB images. Previous methods for articulated object reconstruction either rely on slow optimization with fragile cross-state correspondences or use feed-forward models limited to specific object categories. In contrast, ART treats articulated objects as assemblies of rigid parts, formulating reconstruction as part-based prediction. Our newly designed transformer architecture maps sparse image inputs to a set of learnable part slots, from which ART jointly decodes unified representations for individual parts, including their 3D geometry, texture, and explicit articulation parameters. The resulting reconstructions are physically interpretable and readily exportable for simulation. Trained on a large-scale, diverse dataset with per-part supervision, and evaluated across diverse benchmarks, ART achieves significant improvements over existing baselines and establishes a new state of the art for articulated object reconstruction from image inputs.

