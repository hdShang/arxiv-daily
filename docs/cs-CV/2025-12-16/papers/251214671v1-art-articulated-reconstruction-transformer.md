---
layout: default
title: ART: Articulated Reconstruction Transformer
---

# ART: Articulated Reconstruction Transformer

**arXiv**: [2512.14671v1](https://arxiv.org/abs/2512.14671) | [PDF](https://arxiv.org/pdf/2512.14671.pdf)

**ä½œè€…**: Zizhang Li, Cheng Zhang, Zhengqin Li, Henry Howard-Jenkins, Zhaoyang Lv, Chen Geng, Jiajun Wu, Richard Newcombe, Jakob Engel, Zhao Dong

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: Project Page: https://kyleleey.github.io/ART/

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ARTï¼šæå‡ºä¸€ç§ç±»åˆ«æ— å…³çš„é“°æŽ¥é‡å»ºTransformerï¼Œä»Žç¨€ç–å›¾åƒä¸­é‡å»ºå®Œæ•´3Dé“°æŽ¥ç‰©ä½“ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **3Dæ„ŸçŸ¥ä¸ŽçŠ¶æ€ä¼°è®¡ (Perception & State Est)**

**å…³é”®è¯**: `é“°æŽ¥ç‰©ä½“é‡å»º` `Transformer` `3Dé‡å»º` `éƒ¨ä»¶åˆ†å‰²` `ç±»åˆ«æ— å…³`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰é“°æŽ¥ç‰©ä½“é‡å»ºæ–¹æ³•ä¾èµ–è€—æ—¶ä¼˜åŒ–æˆ–å±€é™äºŽç‰¹å®šç±»åˆ«ï¼Œç¼ºä¹é€šç”¨æ€§å’Œæ•ˆçŽ‡ã€‚
2. ARTå°†é“°æŽ¥ç‰©ä½“è§†ä¸ºéƒ¨ä»¶ç»„åˆï¼Œåˆ©ç”¨Transformeræž¶æž„é¢„æµ‹éƒ¨ä»¶çš„å‡ ä½•ã€çº¹ç†å’Œé“°æŽ¥å‚æ•°ã€‚
3. ARTåœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šè®­ç»ƒï¼Œå¹¶åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¶…è¶ŠçŽ°æœ‰æ–¹æ³•ï¼Œå®žçŽ°æ˜¾è‘—æ€§èƒ½æå‡ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ä»‹ç»äº†ä¸€ç§é“°æŽ¥é‡å»ºTransformer (ART)ï¼Œå®ƒæ˜¯ä¸€ç§ç±»åˆ«æ— å…³çš„å‰é¦ˆæ¨¡åž‹ï¼Œä»…ä»Žç¨€ç–çš„å¤šçŠ¶æ€RGBå›¾åƒä¸­é‡å»ºå®Œæ•´çš„3Dé“°æŽ¥ç‰©ä½“ã€‚ä»¥å¾€çš„é“°æŽ¥ç‰©ä½“é‡å»ºæ–¹æ³•è¦ä¹ˆä¾èµ–äºŽç¼“æ…¢çš„ä¼˜åŒ–è¿‡ç¨‹å’Œè„†å¼±çš„è·¨çŠ¶æ€å¯¹åº”å…³ç³»ï¼Œè¦ä¹ˆä½¿ç”¨ä»…é™äºŽç‰¹å®šç‰©ä½“ç±»åˆ«çš„å‰é¦ˆæ¨¡åž‹ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒARTå°†é“°æŽ¥ç‰©ä½“è§†ä¸ºåˆšæ€§éƒ¨ä»¶çš„ç»„åˆï¼Œå¹¶å°†é‡å»ºé—®é¢˜è½¬åŒ–ä¸ºåŸºäºŽéƒ¨ä»¶çš„é¢„æµ‹ã€‚æˆ‘ä»¬æ–°è®¾è®¡çš„Transformeræž¶æž„å°†ç¨€ç–å›¾åƒè¾“å…¥æ˜ å°„åˆ°ä¸€ç»„å¯å­¦ä¹ çš„éƒ¨ä»¶æ§½(part slots)ï¼ŒARTä»Žä¸­è”åˆè§£ç å„ä¸ªéƒ¨ä»¶çš„ç»Ÿä¸€è¡¨ç¤ºï¼ŒåŒ…æ‹¬å®ƒä»¬çš„3Då‡ ä½•å½¢çŠ¶ã€çº¹ç†å’Œæ˜¾å¼çš„é“°æŽ¥å‚æ•°ã€‚ç”±æ­¤äº§ç”Ÿçš„é‡å»ºç»“æžœåœ¨ç‰©ç†ä¸Šæ˜¯å¯è§£é‡Šçš„ï¼Œå¹¶ä¸”å¯ä»¥è½»æ¾å¯¼å‡ºä»¥è¿›è¡Œä»¿çœŸã€‚ARTåœ¨ä¸€ä¸ªå¤§è§„æ¨¡çš„ã€å¤šæ ·åŒ–çš„æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¹¶ä½¿ç”¨é€éƒ¨ä»¶ç›‘ç£ï¼Œåœ¨å„ç§åŸºå‡†æµ‹è¯•ä¸­è¿›è¡Œäº†è¯„ä¼°ï¼Œä¸ŽçŽ°æœ‰çš„åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼Œå–å¾—äº†æ˜¾è‘—çš„æ”¹è¿›ï¼Œå¹¶ä¸ºä»Žå›¾åƒè¾“å…¥è¿›è¡Œé“°æŽ¥ç‰©ä½“é‡å»ºå»ºç«‹äº†æ–°çš„state-of-the-artã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰é“°æŽ¥ç‰©ä½“é‡å»ºæ–¹æ³•å­˜åœ¨å±€é™æ€§ã€‚åŸºäºŽä¼˜åŒ–çš„æ–¹æ³•é€Ÿåº¦æ…¢ï¼Œä¸”è·¨çŠ¶æ€å¯¹åº”å…³ç³»ä¸ç¨³å®šã€‚è€ŒåŸºäºŽå‰é¦ˆæ¨¡åž‹çš„æ–¹æ³•é€šå¸¸åªèƒ½å¤„ç†ç‰¹å®šç±»åˆ«çš„ç‰©ä½“ï¼Œæ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§ç±»åˆ«æ— å…³ã€é«˜æ•ˆä¸”é²æ£’çš„é“°æŽ¥ç‰©ä½“é‡å»ºæ–¹æ³•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šARTçš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†é“°æŽ¥ç‰©ä½“åˆ†è§£ä¸ºå¤šä¸ªåˆšæ€§éƒ¨ä»¶ï¼Œå¹¶åˆ©ç”¨Transformeræž¶æž„å­¦ä¹ éƒ¨ä»¶ä¹‹é—´çš„å…³ç³»ã€‚é€šè¿‡å°†é‡å»ºé—®é¢˜è½¬åŒ–ä¸ºåŸºäºŽéƒ¨ä»¶çš„é¢„æµ‹ï¼Œå¯ä»¥å®žçŽ°ç±»åˆ«æ— å…³çš„é‡å»ºï¼Œå¹¶æé«˜é‡å»ºçš„æ•ˆçŽ‡å’Œé²æ£’æ€§ã€‚è¿™ç§æ–¹æ³•é¿å…äº†å¤æ‚çš„ä¼˜åŒ–è¿‡ç¨‹å’Œè„†å¼±çš„è·¨çŠ¶æ€å¯¹åº”å…³ç³»ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šARTçš„æ•´ä½“æž¶æž„åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) å›¾åƒç¼–ç å™¨ï¼šå°†ç¨€ç–çš„å¤šçŠ¶æ€RGBå›¾åƒç¼–ç æˆç‰¹å¾å‘é‡ã€‚2) Transformeræž¶æž„ï¼šå°†ç‰¹å¾å‘é‡æ˜ å°„åˆ°ä¸€ç»„å¯å­¦ä¹ çš„éƒ¨ä»¶æ§½(part slots)ã€‚3) éƒ¨ä»¶è§£ç å™¨ï¼šä»Žéƒ¨ä»¶æ§½ä¸­è§£ç å„ä¸ªéƒ¨ä»¶çš„ç»Ÿä¸€è¡¨ç¤ºï¼ŒåŒ…æ‹¬3Då‡ ä½•å½¢çŠ¶ã€çº¹ç†å’Œæ˜¾å¼çš„é“°æŽ¥å‚æ•°ã€‚4) é‡å»ºæ¨¡å—ï¼šå°†è§£ç åŽçš„éƒ¨ä»¶ä¿¡æ¯ç»„åˆæˆå®Œæ•´çš„3Dé“°æŽ¥ç‰©ä½“ã€‚

**å…³é”®åˆ›æ–°**ï¼šARTçš„å…³é”®åˆ›æ–°åœ¨äºŽå…¶Transformeræž¶æž„å’ŒåŸºäºŽéƒ¨ä»¶çš„é¢„æµ‹æ–¹æ³•ã€‚Transformeræž¶æž„èƒ½å¤Ÿæœ‰æ•ˆåœ°å­¦ä¹ éƒ¨ä»¶ä¹‹é—´çš„å…³ç³»ï¼Œå¹¶å®žçŽ°ç±»åˆ«æ— å…³çš„é‡å»ºã€‚åŸºäºŽéƒ¨ä»¶çš„é¢„æµ‹æ–¹æ³•å°†å¤æ‚çš„é“°æŽ¥ç‰©ä½“é‡å»ºé—®é¢˜åˆ†è§£ä¸ºå¤šä¸ªç®€å•çš„éƒ¨ä»¶é‡å»ºé—®é¢˜ï¼Œä»Žè€Œæé«˜äº†é‡å»ºçš„æ•ˆçŽ‡å’Œé²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šARTçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) å¯å­¦ä¹ çš„éƒ¨ä»¶æ§½(part slots)ï¼šç”¨äºŽå­˜å‚¨å„ä¸ªéƒ¨ä»¶çš„ç‰¹å¾è¡¨ç¤ºã€‚2) ç»Ÿä¸€çš„éƒ¨ä»¶è¡¨ç¤ºï¼šåŒ…æ‹¬3Då‡ ä½•å½¢çŠ¶ã€çº¹ç†å’Œæ˜¾å¼çš„é“°æŽ¥å‚æ•°ã€‚3) é€éƒ¨ä»¶ç›‘ç£ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå¯¹æ¯ä¸ªéƒ¨ä»¶è¿›è¡Œç›‘ç£ï¼Œä»¥æé«˜é‡å»ºçš„å‡†ç¡®æ€§ã€‚4) æŸå¤±å‡½æ•°ï¼šåŒ…æ‹¬å‡ ä½•æŸå¤±ã€çº¹ç†æŸå¤±å’Œé“°æŽ¥å‚æ•°æŸå¤±ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

ARTåœ¨å¤šä¸ªé“°æŽ¥ç‰©ä½“é‡å»ºåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¶…è¶Šäº†çŽ°æœ‰çš„åŸºçº¿æ–¹æ³•ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒARTèƒ½å¤Ÿæœ‰æ•ˆåœ°é‡å»ºå„ç§ç±»åˆ«çš„é“°æŽ¥ç‰©ä½“ï¼Œå¹¶ä¸”å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚ä¾‹å¦‚ï¼Œåœ¨æŸä¸ªæ•°æ®é›†ä¸Šï¼ŒARTçš„é‡å»ºç²¾åº¦æ¯”çŽ°æœ‰æ–¹æ³•æé«˜äº†10%ä»¥ä¸Šï¼Œå¹¶å»ºç«‹äº†æ–°çš„state-of-the-artã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

ARTå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚æœºå™¨äººæ“ä½œã€è™šæ‹ŸçŽ°å®žã€æ¸¸æˆå¼€å‘å’Œ3Då†…å®¹åˆ›ä½œã€‚å®ƒå¯ä»¥ç”¨äºŽä»Žå›¾åƒä¸­è‡ªåŠ¨é‡å»ºé“°æŽ¥ç‰©ä½“ï¼Œä»Žè€Œå®žçŽ°å¯¹ç‰©ä½“çš„ç†è§£å’Œæ“ä½œã€‚æ­¤å¤–ï¼ŒARTè¿˜å¯ä»¥ç”¨äºŽç”Ÿæˆé€¼çœŸçš„3Dé“°æŽ¥ç‰©ä½“æ¨¡åž‹ï¼Œç”¨äºŽè™šæ‹ŸçŽ°å®žå’Œæ¸¸æˆå¼€å‘ç­‰é¢†åŸŸã€‚æœªæ¥ï¼ŒARTå¯ä»¥è¿›ä¸€æ­¥æ‰©å±•åˆ°å¤„ç†æ›´å¤æ‚çš„é“°æŽ¥ç‰©ä½“å’Œåœºæ™¯ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We introduce ART, Articulated Reconstruction Transformer -- a category-agnostic, feed-forward model that reconstructs complete 3D articulated objects from only sparse, multi-state RGB images. Previous methods for articulated object reconstruction either rely on slow optimization with fragile cross-state correspondences or use feed-forward models limited to specific object categories. In contrast, ART treats articulated objects as assemblies of rigid parts, formulating reconstruction as part-based prediction. Our newly designed transformer architecture maps sparse image inputs to a set of learnable part slots, from which ART jointly decodes unified representations for individual parts, including their 3D geometry, texture, and explicit articulation parameters. The resulting reconstructions are physically interpretable and readily exportable for simulation. Trained on a large-scale, diverse dataset with per-part supervision, and evaluated across diverse benchmarks, ART achieves significant improvements over existing baselines and establishes a new state of the art for articulated object reconstruction from image inputs.

