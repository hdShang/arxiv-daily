---
layout: default
title: Quality-Aware Framework for Video-Derived Respiratory Signals
---

# Quality-Aware Framework for Video-Derived Respiratory Signals

**arXiv**: [2512.14093v1](https://arxiv.org/abs/2512.14093) | [PDF](https://arxiv.org/pdf/2512.14093.pdf)

**ä½œè€…**: Nhi Nguyen, Constantino Ãlvarez Casado, Le Nguyen, Manuel Lage CaÃ±ellas, Miguel Bordallo LÃ³pez

**åˆ†ç±»**: cs.CV, eess.SP

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: 6 pages, 1 figure, 2 tables, conference

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§è´¨é‡æ„ŸçŸ¥çš„è§†é¢‘å‘¼å¸ä¿¡å·åˆ†æžæ¡†æž¶ï¼Œæå‡å‘¼å¸çŽ‡ä¼°è®¡çš„å¯é æ€§ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **ä¸–ç•Œæ¨¡åž‹ä¸Žé¢„æµ‹ (World Models)**

**å…³é”®è¯**: `è§†é¢‘åˆ†æž` `å‘¼å¸çŽ‡ä¼°è®¡` `è¿œç¨‹å…‰ç”µå®¹ç§¯è„‰ææ³¢` `ä¿¡å·è´¨é‡è¯„ä¼°` `æœºå™¨å­¦ä¹ ` `ä¿¡å·èžåˆ` `ç”Ÿç†ç›‘æµ‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è§†é¢‘å‘¼å¸çŽ‡ä¼°è®¡æ–¹æ³•æ˜“å—ä¿¡å·è´¨é‡ä¸ä¸€è‡´çš„å½±å“ï¼Œå¯¼è‡´ç»“æžœä¸å¯é ï¼Œç¼ºä¹é²æ£’æ€§ã€‚
2. è¯¥è®ºæ–‡æå‡ºä¸€ç§è´¨é‡æ„ŸçŸ¥çš„æ¡†æž¶ï¼Œé€šè¿‡åŠ¨æ€è¯„ä¼°ä¸åŒä¿¡å·æºçš„å¯é æ€§ï¼Œè‡ªé€‚åº”èžåˆä¿¡å·å¹¶è¿‡æ»¤ä½Žè´¨é‡ç‰‡æ®µã€‚
3. å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥æ¡†æž¶åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šä¼˜äºŽå•ç‹¬çš„ä¿¡å·æå–æ–¹æ³•ï¼ŒéªŒè¯äº†è´¨é‡é©±åŠ¨å»ºæ¨¡çš„æœ‰æ•ˆæ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§è´¨é‡æ„ŸçŸ¥çš„è§†é¢‘å‘¼å¸çŽ‡ï¼ˆRRï¼‰ä¼°è®¡æ¡†æž¶ï¼Œæ—¨åœ¨è§£å†³å› ä¸åŒä¿¡å·æå–æ–¹æ³•å¯¼è‡´ä¿¡å·è´¨é‡ä¸ä¸€è‡´çš„é—®é¢˜ã€‚è¯¥æ¡†æž¶é›†æˆäº†æ¥è‡ªé¢éƒ¨è¿œç¨‹å…‰ç”µå®¹ç§¯è„‰ææ³¢ï¼ˆrPPGï¼‰ã€ä¸ŠåŠèº«è¿åŠ¨å’Œæ·±åº¦å­¦ä¹ ç®¡é“çš„åç§ä¿¡å·æºï¼Œå¹¶ä½¿ç”¨å››ç§é¢‘è°±ä¼°è®¡å™¨ï¼ˆWelchæ–¹æ³•ã€MUSICã€FFTå’Œå³°å€¼æ£€æµ‹ï¼‰è¿›è¡Œåˆ†æžã€‚é€šè¿‡ç‰‡æ®µçº§åˆ«çš„è´¨é‡æŒ‡æ ‡è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡åž‹ï¼Œä»¥é¢„æµ‹å‡†ç¡®æ€§æˆ–é€‰æ‹©æœ€å¯é çš„ä¿¡å·ï¼Œä»Žè€Œå®žçŽ°è‡ªé€‚åº”ä¿¡å·èžåˆå’ŒåŸºäºŽè´¨é‡çš„ç‰‡æ®µè¿‡æ»¤ã€‚åœ¨ä¸‰ä¸ªå…¬å…±æ•°æ®é›†ï¼ˆOMuSense-23ã€COHFACEã€MAHNOB-HCIï¼‰ä¸Šçš„å®žéªŒè¡¨æ˜Žï¼Œæ‰€æå‡ºçš„æ¡†æž¶åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹å®žçŽ°äº†æ¯”å•ç‹¬æ–¹æ³•æ›´ä½Žçš„RRä¼°è®¡è¯¯å·®ï¼Œæ€§èƒ½æå‡å–å†³äºŽæ•°æ®é›†çš„ç‰¹å¾ã€‚è¿™äº›å‘çŽ°çªå‡ºäº†è´¨é‡é©±åŠ¨çš„é¢„æµ‹å»ºæ¨¡åœ¨æä¾›å¯æ‰©å±•å’Œé€šç”¨çš„è§†é¢‘å‘¼å¸ç›‘æµ‹è§£å†³æ–¹æ¡ˆæ–¹é¢çš„æ½œåŠ›ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè§†é¢‘å‘¼å¸çŽ‡ä¼°è®¡é¢ä¸´çš„æŒ‘æˆ˜æ˜¯ï¼Œä»Žä¸åŒæ¥æºï¼ˆå¦‚é¢éƒ¨rPPGã€èº«ä½“è¿åŠ¨ç­‰ï¼‰æå–çš„ä¿¡å·è´¨é‡å‚å·®ä¸é½ï¼Œå¯¼è‡´æœ€ç»ˆçš„å‘¼å¸çŽ‡ä¼°è®¡ç»“æžœä¸ç¨³å®šä¸”ç²¾åº¦ä¸é«˜ã€‚çŽ°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºŽå•ä¸€ä¿¡å·æºæˆ–ç®€å•èžåˆï¼Œæ— æ³•æœ‰æ•ˆåº”å¯¹ä¿¡å·è´¨é‡å˜åŒ–å¸¦æ¥çš„å½±å“ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè¯¥è®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å¼•å…¥è´¨é‡æ„ŸçŸ¥æœºåˆ¶ï¼Œå¯¹ä¸åŒä¿¡å·æºçš„è´¨é‡è¿›è¡ŒåŠ¨æ€è¯„ä¼°ï¼Œå¹¶æ ¹æ®è´¨é‡è¯„ä¼°ç»“æžœè‡ªé€‚åº”åœ°èžåˆä¿¡å·æˆ–è¿‡æ»¤ä½Žè´¨é‡ç‰‡æ®µã€‚é€šè¿‡é¢„æµ‹ä¿¡å·çš„å‡†ç¡®æ€§æˆ–é€‰æ‹©æœ€å¯é çš„ä¿¡å·ï¼Œæé«˜æ•´ä½“å‘¼å¸çŽ‡ä¼°è®¡çš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šè¯¥æ¡†æž¶åŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) ä¿¡å·æå–ï¼šä»Žè§†é¢‘ä¸­æå–10ç§ä¸åŒçš„å‘¼å¸ç›¸å…³ä¿¡å·ï¼ŒåŒ…æ‹¬é¢éƒ¨rPPGã€ä¸ŠåŠèº«è¿åŠ¨å’Œæ·±åº¦å­¦ä¹ ç®¡é“è¾“å‡ºï¼›2) é¢‘è°±ä¼°è®¡ï¼šä½¿ç”¨å››ç§é¢‘è°±ä¼°è®¡å™¨ï¼ˆWelch's method, MUSIC, FFT, peak detectionï¼‰å¯¹æå–çš„ä¿¡å·è¿›è¡Œåˆ†æžï¼›3) è´¨é‡è¯„ä¼°ï¼šè®¡ç®—ç‰‡æ®µçº§åˆ«çš„è´¨é‡æŒ‡æ ‡ï¼Œç”¨äºŽè¯„ä¼°æ¯ä¸ªä¿¡å·ç‰‡æ®µçš„å¯é æ€§ï¼›4) è´¨é‡é¢„æµ‹/é€‰æ‹©ï¼šä½¿ç”¨æœºå™¨å­¦ä¹ æ¨¡åž‹ï¼ŒåŸºäºŽè´¨é‡æŒ‡æ ‡é¢„æµ‹ä¿¡å·ç‰‡æ®µçš„å‡†ç¡®æ€§ï¼Œæˆ–ç›´æŽ¥é€‰æ‹©æœ€å¯é çš„ä¿¡å·ï¼›5) ä¿¡å·èžåˆ/è¿‡æ»¤ï¼šæ ¹æ®è´¨é‡é¢„æµ‹ç»“æžœï¼Œè‡ªé€‚åº”åœ°èžåˆä¸åŒä¿¡å·æºçš„ä¼°è®¡ç»“æžœï¼Œæˆ–è¿‡æ»¤æŽ‰ä½Žè´¨é‡çš„ä¿¡å·ç‰‡æ®µã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽå¼•å…¥äº†è´¨é‡æ„ŸçŸ¥çš„é¢„æµ‹å»ºæ¨¡æ–¹æ³•ï¼Œå°†ä¿¡å·è´¨é‡è¯„ä¼°ä¸Žå‘¼å¸çŽ‡ä¼°è®¡è¿‡ç¨‹ç´§å¯†ç»“åˆã€‚é€šè¿‡å­¦ä¹ ä¿¡å·è´¨é‡ä¸Žä¼°è®¡å‡†ç¡®æ€§ä¹‹é—´çš„å…³ç³»ï¼Œå®žçŽ°äº†è‡ªé€‚åº”çš„ä¿¡å·èžåˆå’Œè¿‡æ»¤ï¼Œä»Žè€Œæé«˜äº†å‘¼å¸çŽ‡ä¼°è®¡çš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ¡†æž¶èƒ½å¤Ÿæ›´å¥½åœ°åº”å¯¹ä¿¡å·è´¨é‡å˜åŒ–å¸¦æ¥çš„æŒ‘æˆ˜ã€‚

**å…³é”®è®¾è®¡**ï¼šè´¨é‡è¯„ä¼°æŒ‡æ ‡çš„è®¾è®¡æ˜¯å…³é”®ã€‚è®ºæ–‡ä¸­ä½¿ç”¨çš„è´¨é‡æŒ‡æ ‡çš„å…·ä½“å½¢å¼æœªçŸ¥ï¼Œä½†å¯ä»¥æŽ¨æµ‹å¯èƒ½åŒ…æ‹¬ä¿¡å·çš„ä¿¡å™ªæ¯”ã€å‘¨æœŸæ€§ã€å¹…åº¦ç¨³å®šæ€§ç­‰ã€‚æœºå™¨å­¦ä¹ æ¨¡åž‹çš„é€‰æ‹©å’Œè®­ç»ƒä¹Ÿè‡³å…³é‡è¦ï¼Œéœ€è¦é€‰æ‹©åˆé€‚çš„æ¨¡åž‹ç»“æž„å’Œè®­ç»ƒç­–ç•¥ï¼Œä»¥å‡†ç¡®é¢„æµ‹ä¿¡å·ç‰‡æ®µçš„å‡†ç¡®æ€§æˆ–å¯é æ€§ã€‚æ­¤å¤–ï¼Œä¿¡å·èžåˆç­–ç•¥ä¹Ÿéœ€è¦ä»”ç»†è®¾è®¡ï¼Œä¾‹å¦‚å¯ä»¥é‡‡ç”¨åŠ æƒå¹³å‡çš„æ–¹å¼ï¼Œæ ¹æ®è´¨é‡é¢„æµ‹ç»“æžœè°ƒæ•´ä¸åŒä¿¡å·æºçš„æƒé‡ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥æ¡†æž¶åœ¨ OMuSense-23ã€COHFACE å’Œ MAHNOB-HCI ä¸‰ä¸ªå…¬å…±æ•°æ®é›†ä¸Šå‡å–å¾—äº†è¾ƒå¥½çš„æ€§èƒ½ã€‚åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œè¯¥æ¡†æž¶çš„å‘¼å¸çŽ‡ä¼°è®¡è¯¯å·®ä½ŽäºŽå•ç‹¬ä½¿ç”¨å„ä¸ªä¿¡å·æå–æ–¹æ³•çš„ç»“æžœã€‚å…·ä½“çš„æ€§èƒ½æå‡å¹…åº¦å–å†³äºŽæ•°æ®é›†çš„ç‰¹æ€§ï¼Œè¡¨æ˜Žè¯¥æ¡†æž¶å…·æœ‰ä¸€å®šçš„æ³›åŒ–èƒ½åŠ›ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽè¿œç¨‹åŒ»ç–—ã€æ™ºèƒ½å¥åº·ç›‘æµ‹ã€è¿åŠ¨ç”Ÿç†ç›‘æµ‹ç­‰é¢†åŸŸã€‚é€šè¿‡è§†é¢‘åˆ†æžå®žçŽ°éžæŽ¥è§¦å¼çš„å‘¼å¸çŽ‡ç›‘æµ‹ï¼Œå…·æœ‰ä¾¿æ·ã€èˆ’é€‚çš„ä¼˜ç‚¹ï¼Œå°¤å…¶é€‚ç”¨äºŽç¡çœ ç›‘æµ‹ã€å©´å„¿ç›‘æŠ¤ç­‰åœºæ™¯ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›é›†æˆåˆ°æ™ºèƒ½æ‰‹æœºã€å¯ç©¿æˆ´è®¾å¤‡ç­‰å¹³å°ï¼Œå®žçŽ°éšæ—¶éšåœ°çš„å‘¼å¸å¥åº·ç®¡ç†ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Video-based respiratory rate (RR) estimation is often unreliable due to inconsistent signal quality across extraction methods. We present a predictive, quality-aware framework that integrates heterogeneous signal sources with dynamic assessment of reliability. Ten signals are extracted from facial remote photoplethysmography (rPPG), upper-body motion, and deep learning pipelines, and analyzed using four spectral estimators: Welch's method, Multiple Signal Classification (MUSIC), Fast Fourier Transform (FFT), and peak detection. Segment-level quality indices are then used to train machine learning models that predict accuracy or select the most reliable signal. This enables adaptive signal fusion and quality-based segment filtering. Experiments on three public datasets (OMuSense-23, COHFACE, MAHNOB-HCI) show that the proposed framework achieves lower RR estimation errors than individual methods in most cases, with performance gains depending on dataset characteristics. These findings highlight the potential of quality-driven predictive modeling to deliver scalable and generalizable video-based respiratory monitoring solutions.

