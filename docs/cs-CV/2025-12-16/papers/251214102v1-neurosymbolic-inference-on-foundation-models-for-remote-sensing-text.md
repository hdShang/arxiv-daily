---
layout: default
title: Neurosymbolic Inference On Foundation Models For Remote Sensing Text-to-image Retrieval With Complex Queries
---

# Neurosymbolic Inference On Foundation Models For Remote Sensing Text-to-image Retrieval With Complex Queries

**arXiv**: [2512.14102v1](https://arxiv.org/abs/2512.14102) | [PDF](https://arxiv.org/pdf/2512.14102.pdf)

**ä½œè€…**: Emanuele Mezzi, Gertjan Burghouts, Maarten Kruithof

**åˆ†ç±»**: cs.CV, cs.AI, cs.IR

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRUNEæ–¹æ³•ï¼Œç»“åˆå¤§è¯­è¨€æ¨¡åž‹ä¸Žç¥žç»ç¬¦å·æŽ¨ç†ï¼Œè§£å†³é¥æ„Ÿæ–‡æœ¬-å›¾åƒæ£€ç´¢ä¸­å¤æ‚ç©ºé—´å…³ç³»å¤„ç†ä¸Žå¯è§£é‡Šæ€§ä¸è¶³çš„é—®é¢˜ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `é¥æ„Ÿæ–‡æœ¬-å›¾åƒæ£€ç´¢` `ç¥žç»ç¬¦å·æŽ¨ç†` `å¤§è¯­è¨€æ¨¡åž‹` `ç¬¬ä¸€é˜¶é€»è¾‘` `å¤æ‚ç©ºé—´å…³ç³»` `å¯è§£é‡Šæ€§AI` `å¤šæ¨¡æ€æ£€ç´¢` `å«æ˜Ÿå›¾åƒåˆ†æž`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰é¥æ„Ÿæ–‡æœ¬-å›¾åƒæ£€ç´¢æ–¹æ³•ï¼ˆå¦‚RS-LVLMsï¼‰å­˜åœ¨å¯è§£é‡Šæ€§å·®ã€éš¾ä»¥å¤„ç†å¤æ‚ç©ºé—´å…³ç³»ç­‰æŒ‘æˆ˜ï¼Œé™åˆ¶äº†å®žé™…åº”ç”¨ã€‚
2. è®ºæ–‡æå‡ºRUNEæ–¹æ³•ï¼Œç»“åˆå¤§è¯­è¨€æ¨¡åž‹ç”Ÿæˆç¬¬ä¸€é˜¶é€»è¾‘è¡¨è¾¾å¼ï¼Œå¹¶åˆ©ç”¨ç¥žç»ç¬¦å·æŽ¨ç†æ¨¡å—è¿›è¡Œæ˜¾å¼æŽ¨ç†ï¼Œæå‡æ£€ç´¢æ€§èƒ½ä¸Žå¯è§£é‡Šæ€§ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒRUNEåœ¨å¤æ‚æŸ¥è¯¢ä»»åŠ¡ä¸­ä¼˜äºŽçŽ°æœ‰RS-LVLMsï¼Œå¹¶å¼•å…¥æ–°æŒ‡æ ‡è¯„ä¼°é²æ£’æ€§ï¼Œå±•ç¤ºäº†åœ¨æ´ªæ°´åŽå«æ˜Ÿå›¾åƒæ£€ç´¢ç­‰åœºæ™¯çš„åº”ç”¨æ½œåŠ›ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é¥æ„Ÿé¢†åŸŸçš„æ–‡æœ¬-å›¾åƒæ£€ç´¢éšç€é’ˆå¯¹èˆªç©ºå’Œå«æ˜Ÿå½±åƒå®šåˆ¶çš„å¤§åž‹è§†è§‰è¯­è¨€æ¨¡åž‹ï¼ˆLVLMsï¼‰çš„å…´èµ·è€Œè¿…é€Ÿå‘å±•ï¼Œå½¢æˆäº†é¥æ„Ÿå¤§åž‹è§†è§‰è¯­è¨€æ¨¡åž‹ï¼ˆRS-LVLMsï¼‰ã€‚ç„¶è€Œï¼Œæœ‰é™çš„å¯è§£é‡Šæ€§å’Œå¯¹å¤æ‚ç©ºé—´å…³ç³»çš„å¤„ç†èƒ½åŠ›å·®ä»ç„¶æ˜¯å®žé™…åº”ç”¨ä¸­çš„å…³é”®æŒ‘æˆ˜ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†RUNEï¼ˆä½¿ç”¨ç¥žç»ç¬¦å·å®žä½“è¿›è¡ŒæŽ¨ç†ï¼‰ï¼Œè¯¥æ–¹æ³•å°†å¤§è¯­è¨€æ¨¡åž‹ï¼ˆLLMsï¼‰ä¸Žç¥žç»ç¬¦å·AIç›¸ç»“åˆï¼Œé€šè¿‡æŽ¨ç†æ£€æµ‹åˆ°çš„å®žä½“ä¸Žä»Žæ–‡æœ¬æŸ¥è¯¢å¯¼å‡ºçš„ç¬¬ä¸€é˜¶é€»è¾‘ï¼ˆFOLï¼‰è¡¨è¾¾å¼ä¹‹é—´çš„å…¼å®¹æ€§æ¥æ£€ç´¢å›¾åƒã€‚ä¸Žä¾èµ–éšå¼è”åˆåµŒå…¥çš„RS-LVLMsä¸åŒï¼ŒRUNEæ‰§è¡Œæ˜¾å¼æŽ¨ç†ï¼Œæé«˜äº†æ€§èƒ½å’Œå¯è§£é‡Šæ€§ã€‚ä¸ºäº†å¯æ‰©å±•æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é€»è¾‘åˆ†è§£ç­–ç•¥ï¼Œè¯¥ç­–ç•¥åœ¨æ£€æµ‹åˆ°çš„å®žä½“çš„æ¡ä»¶å­é›†ä¸Šæ“ä½œï¼Œä¿è¯äº†æ¯”ç¥žç»æ–¹æ³•æ›´çŸ­çš„æ‰§è¡Œæ—¶é—´ã€‚æˆ‘ä»¬ä¸æ˜¯å°†åŸºç¡€æ¨¡åž‹ç”¨äºŽç«¯åˆ°ç«¯æ£€ç´¢ï¼Œè€Œæ˜¯ä»…åˆ©ç”¨å®ƒä»¬ç”ŸæˆFOLè¡¨è¾¾å¼ï¼Œå°†æŽ¨ç†å§”æ‰˜ç»™ç¥žç»ç¬¦å·æŽ¨ç†æ¨¡å—ã€‚ä¸ºäº†è¯„ä¼°ï¼Œæˆ‘ä»¬é‡æ–°åˆ©ç”¨äº†åŽŸæœ¬è®¾è®¡ç”¨äºŽç›®æ ‡æ£€æµ‹çš„DOTAæ•°æ®é›†ï¼Œé€šè¿‡æ·»åŠ æ¯”çŽ°æœ‰åŸºå‡†æ›´å¤æ‚çš„æŸ¥è¯¢æ¥å¢žå¼ºå®ƒã€‚æˆ‘ä»¬å±•ç¤ºäº†LLMåœ¨æ–‡æœ¬åˆ°é€»è¾‘ç¿»è¯‘ä¸­çš„æœ‰æ•ˆæ€§ï¼Œå¹¶å°†RUNEä¸Žæœ€å…ˆè¿›çš„RS-LVLMsè¿›è¡Œæ¯”è¾ƒï¼Œè¯æ˜Žäº†å…¶ä¼˜è¶Šæ€§èƒ½ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸¤ä¸ªæŒ‡æ ‡ï¼šæ£€ç´¢å¯¹æŸ¥è¯¢å¤æ‚æ€§çš„é²æ£’æ€§ï¼ˆRRQCï¼‰å’Œæ£€ç´¢å¯¹å›¾åƒä¸ç¡®å®šæ€§çš„é²æ£’æ€§ï¼ˆRRIUï¼‰ï¼Œç”¨äºŽè¯„ä¼°ç›¸å¯¹äºŽæŸ¥è¯¢å¤æ‚æ€§å’Œå›¾åƒä¸ç¡®å®šæ€§çš„æ€§èƒ½ã€‚RUNEåœ¨å¤æ‚é¥æ„Ÿæ£€ç´¢ä»»åŠ¡ä¸­ä¼˜äºŽè”åˆåµŒå…¥æ¨¡åž‹ï¼Œåœ¨æ€§èƒ½ã€é²æ£’æ€§å’Œå¯è§£é‡Šæ€§æ–¹é¢æä¾›äº†å¢žç›Šã€‚æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªå…³äºŽæ´ªæ°´åŽå«æ˜Ÿå›¾åƒæ£€ç´¢çš„ç”¨ä¾‹å±•ç¤ºäº†RUNEåœ¨çŽ°å®žä¸–ç•Œé¥æ„Ÿåº”ç”¨ä¸­çš„æ½œåŠ›ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡è§£å†³é¥æ„Ÿæ–‡æœ¬-å›¾åƒæ£€ç´¢ä¸­ï¼ŒçŽ°æœ‰æ–¹æ³•ï¼ˆå¦‚RS-LVLMsï¼‰ä¾èµ–éšå¼è”åˆåµŒå…¥å¯¼è‡´å¯è§£é‡Šæ€§å·®ã€éš¾ä»¥å¤„ç†å¤æ‚ç©ºé—´å…³ç³»ï¼ˆå¦‚é€»è¾‘ç»„åˆæŸ¥è¯¢ï¼‰çš„é—®é¢˜ï¼Œè¿™é™åˆ¶äº†åœ¨çœŸå®žä¸–ç•Œåº”ç”¨ä¸­çš„å¯é æ€§å’Œæ€§èƒ½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæ ¸å¿ƒæ€è·¯æ˜¯ç»“åˆå¤§è¯­è¨€æ¨¡åž‹ï¼ˆLLMsï¼‰ä¸Žç¥žç»ç¬¦å·AIï¼Œå°†æ–‡æœ¬æŸ¥è¯¢è½¬æ¢ä¸ºç¬¬ä¸€é˜¶é€»è¾‘ï¼ˆFOLï¼‰è¡¨è¾¾å¼ï¼Œç„¶åŽé€šè¿‡æ˜¾å¼æŽ¨ç†æ£€æµ‹åˆ°çš„å®žä½“ä¸ŽFOLè¡¨è¾¾å¼çš„å…¼å®¹æ€§æ¥æ£€ç´¢å›¾åƒï¼Œä»Žè€Œæ›¿ä»£ç«¯åˆ°ç«¯çš„ç¥žç»æ£€ç´¢ï¼Œæå‡å¯è§£é‡Šæ€§å’Œå¤„ç†å¤æ‚å…³ç³»çš„èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æž¶æž„åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šé¦–å…ˆï¼Œä½¿ç”¨å¤§è¯­è¨€æ¨¡åž‹å°†æ–‡æœ¬æŸ¥è¯¢ç¿»è¯‘ä¸ºç¬¬ä¸€é˜¶é€»è¾‘è¡¨è¾¾å¼ï¼›å…¶æ¬¡ï¼Œé€šè¿‡ç¥žç»ç¬¦å·æŽ¨ç†æ¨¡å—ï¼Œåœ¨é¥æ„Ÿå›¾åƒä¸­æ£€æµ‹å®žä½“ï¼ˆå¦‚ç‰©ä½“ï¼‰ï¼Œå¹¶åŸºäºŽé€»è¾‘åˆ†è§£ç­–ç•¥è¯„ä¼°å®žä½“ä¸ŽFOLè¡¨è¾¾å¼çš„åŒ¹é…åº¦ï¼Œæœ€ç»ˆè¾“å‡ºæ£€ç´¢ç»“æžœã€‚æŽ¨ç†æ¨¡å—å¯èƒ½æ¶‰åŠç¬¦å·æŽ¨ç†å¼•æ“Žæˆ–è§„åˆ™ç³»ç»Ÿï¼Œå…·ä½“å®žçŽ°ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœªè¯¦ç»†è¯´æ˜Žã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°æ˜¯å¼•å…¥ç¥žç»ç¬¦å·æŽ¨ç†æ¡†æž¶ï¼Œå°†åŸºç¡€æ¨¡åž‹ä»…ç”¨äºŽé€»è¾‘ç”Ÿæˆï¼Œè€Œå°†æŽ¨ç†ä»»åŠ¡å§”æ‰˜ç»™ä¸“é—¨çš„ç¥žç»ç¬¦å·æ¨¡å—ï¼Œè¿™å®žçŽ°äº†æ˜¾å¼æŽ¨ç†ï¼Œä¸ŽçŽ°æœ‰RS-LVLMsçš„éšå¼åµŒå…¥æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ï¼Œä»Žè€Œæé«˜äº†å¯è§£é‡Šæ€§å’Œå¯¹å¤æ‚æŸ¥è¯¢çš„å¤„ç†èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬é€»è¾‘åˆ†è§£ç­–ç•¥ï¼Œè¯¥ç­–ç•¥åœ¨æ£€æµ‹åˆ°çš„å®žä½“çš„æ¡ä»¶å­é›†ä¸Šæ“ä½œï¼Œä»¥å‡å°‘è®¡ç®—å¤æ‚åº¦å¹¶ä¿è¯æ›´çŸ­çš„æ‰§è¡Œæ—¶é—´ï¼›æ­¤å¤–ï¼Œè®ºæ–‡é‡æ–°åˆ©ç”¨DOTAæ•°æ®é›†ï¼Œé€šè¿‡æ·»åŠ å¤æ‚æŸ¥è¯¢æ¥æž„å»ºè¯„ä¼°åŸºå‡†ï¼Œå…·ä½“å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°åœ¨æ‘˜è¦ä¸­æœªæåŠï¼Œå¯èƒ½æ¶‰åŠæ ‡å‡†æ£€ç´¢æŒ‡æ ‡æˆ–è‡ªå®šä¹‰æŽ¨ç†è§„åˆ™ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœæ˜¾ç¤ºï¼ŒRUNEåœ¨å¤æ‚é¥æ„Ÿæ£€ç´¢ä»»åŠ¡ä¸­ä¼˜äºŽæœ€å…ˆè¿›çš„RS-LVLMsï¼Œå…·ä½“æ€§èƒ½æ•°æ®æœªåœ¨æ‘˜è¦ä¸­æä¾›ï¼Œä½†è®ºæ–‡é€šè¿‡å¼•å…¥RRQCå’ŒRRIUæŒ‡æ ‡è¯„ä¼°äº†é²æ£’æ€§ï¼Œå¹¶å±•ç¤ºäº†åœ¨DOTAæ•°æ®é›†å¢žå¼ºç‰ˆæœ¬ä¸Šçš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œç”¨ä¾‹åˆ†æžè¡¨æ˜ŽRUNEåœ¨æ´ªæ°´åŽå«æ˜Ÿå›¾åƒæ£€ç´¢ä¸­å…·æœ‰å®žé™…åº”ç”¨ä»·å€¼ï¼Œæå‡äº†æ£€ç´¢ç²¾åº¦å’Œå¯è§£é‡Šæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨é¥æ„Ÿé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œä¾‹å¦‚ç¾å®³å“åº”ï¼ˆå¦‚æ´ªæ°´åŽå«æ˜Ÿå›¾åƒæ£€ç´¢ï¼‰ã€çŽ¯å¢ƒç›‘æµ‹ã€åŸŽå¸‚è§„åˆ’ç­‰éœ€è¦å¤„ç†å¤æ‚ç©ºé—´å…³ç³»å’Œé€»è¾‘æŸ¥è¯¢çš„åœºæ™¯ã€‚é€šè¿‡æå‡å¯è§£é‡Šæ€§å’Œé²æ£’æ€§ï¼ŒRUNEæ–¹æ³•å¯ä»¥å¢žå¼ºé¥æ„Ÿæ•°æ®åˆ†æžçš„å¯é æ€§ï¼Œæ”¯æŒå†³ç­–åˆ¶å®šå’Œè‡ªåŠ¨åŒ–ä»»åŠ¡ï¼Œæœªæ¥å¯èƒ½æ‰©å±•åˆ°å…¶ä»–å¤šæ¨¡æ€æ£€ç´¢æˆ–æŽ¨ç†ä»»åŠ¡ä¸­ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Text-to-image retrieval in remote sensing (RS) has advanced rapidly with the rise of large vision-language models (LVLMs) tailored for aerial and satellite imagery, culminating in remote sensing large vision-language models (RS-LVLMS). However, limited explainability and poor handling of complex spatial relations remain key challenges for real-world use. To address these issues, we introduce RUNE (Reasoning Using Neurosymbolic Entities), an approach that combines Large Language Models (LLMs) with neurosymbolic AI to retrieve images by reasoning over the compatibility between detected entities and First-Order Logic (FOL) expressions derived from text queries. Unlike RS-LVLMs that rely on implicit joint embeddings, RUNE performs explicit reasoning, enhancing performance and interpretability. For scalability, we propose a logic decomposition strategy that operates on conditioned subsets of detected entities, guaranteeing shorter execution time compared to neural approaches. Rather than using foundation models for end-to-end retrieval, we leverage them only to generate FOL expressions, delegating reasoning to a neurosymbolic inference module. For evaluation we repurpose the DOTA dataset, originally designed for object detection, by augmenting it with more complex queries than in existing benchmarks. We show the LLM's effectiveness in text-to-logic translation and compare RUNE with state-of-the-art RS-LVLMs, demonstrating superior performance. We introduce two metrics, Retrieval Robustness to Query Complexity (RRQC) and Retrieval Robustness to Image Uncertainty (RRIU), which evaluate performance relative to query complexity and image uncertainty. RUNE outperforms joint-embedding models in complex RS retrieval tasks, offering gains in performance, robustness, and explainability. We show RUNE's potential for real-world RS applications through a use case on post-flood satellite image retrieval.

