---
layout: default
title: Unleashing the Power of Image-Tabular Self-Supervised Learning via Breaking Cross-Tabular Barriers
---

# Unleashing the Power of Image-Tabular Self-Supervised Learning via Breaking Cross-Tabular Barriers

**arXiv**: [2512.14026v1](https://arxiv.org/abs/2512.14026) | [PDF](https://arxiv.org/pdf/2512.14026.pdf)

**ä½œè€…**: Yibing Fu, Yunpeng Zhao, Zhitao Zeng, Cheng Chen, Yueming Jin

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**CITabï¼šé€šè¿‡æ‰“ç ´è·¨è¡¨æ ¼éšœç¢ï¼Œé‡Šæ”¾å›¾åƒ-è¡¨æ ¼è‡ªç›‘ç£å­¦ä¹ çš„æ½œåŠ›**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å…·èº«æ™ºèƒ½ä¸Žè¡¨å¾å­¦ä¹  (Embodied AI & Representation)**

**å…³é”®è¯**: `è‡ªç›‘ç£å­¦ä¹ ` `å¤šæ¨¡æ€å­¦ä¹ ` `å›¾åƒ-è¡¨æ ¼æ•°æ®` `è·¨è¡¨æ ¼å­¦ä¹ ` `åŒ»å­¦å›¾åƒåˆ†æž` `é˜¿å°”èŒ¨æµ·é»˜ç—…è¯Šæ–­` `åŽŸåž‹å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰å›¾åƒ-è¡¨æ ¼è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•åœ¨å¤„ç†å¼‚æž„è¡¨æ ¼æ•°æ®æ—¶å­˜åœ¨å±€é™æ€§ï¼Œéš¾ä»¥è·¨ä¸åŒæ•°æ®é˜Ÿåˆ—è¿ç§»çŸ¥è¯†ã€‚
2. CITabæ¡†æž¶é€šè¿‡å¼•å…¥è¯­ä¹‰æ„ŸçŸ¥çš„è¡¨æ ¼å»ºæ¨¡æœºåˆ¶å’ŒåŽŸåž‹å¼•å¯¼çš„æ··åˆçº¿æ€§å±‚ï¼Œå®žçŽ°è·¨è¡¨æ ¼çŸ¥è¯†è¿ç§»å’Œå¼‚æž„æ•°æ®å¤„ç†ã€‚
3. åœ¨é˜¿å°”èŒ¨æµ·é»˜ç—…è¯Šæ–­ä»»åŠ¡ä¸­ï¼ŒCITabåœ¨ä¸‰ä¸ªå…¬å¼€æ•°æ®é›†ä¸Šè¶…è¶Šäº†çŽ°æœ‰æ–¹æ³•ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œå¯æ‰©å±•æ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œç»“åˆåŒ»å­¦å›¾åƒå’Œè¡¨æ ¼æ•°æ®çš„å¤šæ¨¡æ€å­¦ä¹ æ˜¾è‘—æŽ¨åŠ¨äº†ä¸´åºŠå†³ç­–ã€‚è‡ªç›‘ç£å­¦ä¹ ï¼ˆSSLï¼‰å·²æˆä¸ºä¸€ç§å¼ºå¤§çš„èŒƒä¾‹ï¼Œç”¨äºŽåœ¨å¤§è§„æ¨¡æœªæ ‡è®°çš„å›¾åƒ-è¡¨æ ¼æ•°æ®ä¸Šé¢„è®­ç»ƒæ¨¡åž‹ï¼Œæ—¨åœ¨å­¦ä¹ åˆ¤åˆ«æ€§è¡¨ç¤ºã€‚ç„¶è€Œï¼ŒçŽ°æœ‰çš„å›¾åƒ-è¡¨æ ¼è¡¨ç¤ºå­¦ä¹ çš„SSLæ–¹æ³•é€šå¸¸å±€é™äºŽç‰¹å®šçš„æ•°æ®é˜Ÿåˆ—ï¼Œè¿™ä¸»è¦æ˜¯ç”±äºŽå®ƒä»¬åœ¨å»ºæ¨¡å¼‚æž„è¡¨æ ¼æ•°æ®æ—¶é‡‡ç”¨çš„åˆšæ€§è¡¨æ ¼å»ºæ¨¡æœºåˆ¶ã€‚è¿™ç§è·¨è¡¨æ ¼éšœç¢é˜»ç¢äº†å¤šæ¨¡æ€SSLæ–¹æ³•æœ‰æ•ˆåœ°å­¦ä¹ åœ¨ä¸åŒé˜Ÿåˆ—ä¹‹é—´å…±äº«çš„å¯è½¬ç§»åŒ»å­¦çŸ¥è¯†ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„SSLæ¡†æž¶ï¼Œå³CITabï¼Œæ—¨åœ¨ä»¥è·¨è¡¨æ ¼çš„æ–¹å¼å­¦ä¹ å¼ºå¤§çš„å¤šæ¨¡æ€ç‰¹å¾è¡¨ç¤ºã€‚æˆ‘ä»¬ä»Žè¯­ä¹‰æ„ŸçŸ¥çš„è§’åº¦è®¾è®¡äº†è¡¨æ ¼å»ºæ¨¡æœºåˆ¶ï¼Œé€šè¿‡æ•´åˆåˆ—æ ‡é¢˜ä½œä¸ºè¯­ä¹‰çº¿ç´¢ï¼Œä»Žè€Œä¿ƒè¿›å¯è½¬ç§»çŸ¥è¯†çš„å­¦ä¹ å’Œåˆ©ç”¨å¤šä¸ªæ•°æ®æºè¿›è¡Œé¢„è®­ç»ƒçš„å¯æ‰©å±•æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåŽŸåž‹å¼•å¯¼çš„æ··åˆçº¿æ€§å±‚ï¼ˆP-MoLinï¼‰æ¨¡å—ï¼Œç”¨äºŽè¡¨æ ¼ç‰¹å¾ä¸“ä¸šåŒ–ï¼Œä½¿æ¨¡åž‹èƒ½å¤Ÿæœ‰æ•ˆåœ°å¤„ç†è¡¨æ ¼æ•°æ®çš„å¼‚æž„æ€§å¹¶æŽ¢ç´¢æ½œåœ¨çš„åŒ»å­¦æ¦‚å¿µã€‚æˆ‘ä»¬å¯¹åŒ…å«4,461åå—è¯•è€…çš„ä¸‰ä¸ªå…¬å¼€å¯ç”¨çš„æ•°æ®é˜Ÿåˆ—è¿›è¡Œäº†é˜¿å°”èŒ¨æµ·é»˜ç—…è¯Šæ–­ä»»åŠ¡çš„å…¨é¢è¯„ä¼°ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒCITabä¼˜äºŽæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œä¸ºæœ‰æ•ˆä¸”å¯æ‰©å±•çš„è·¨è¡¨æ ¼å¤šæ¨¡æ€å­¦ä¹ é“ºå¹³äº†é“è·¯ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰çš„å›¾åƒ-è¡¨æ ¼è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•åœ¨å¤„ç†æ¥è‡ªä¸åŒæ•°æ®é˜Ÿåˆ—çš„è¡¨æ ¼æ•°æ®æ—¶ï¼Œç”±äºŽè¡¨æ ¼æ•°æ®çš„å¼‚æž„æ€§ï¼Œå¾€å¾€éš¾ä»¥å­¦ä¹ åˆ°é€šç”¨çš„ã€å¯è¿ç§»çš„ç‰¹å¾è¡¨ç¤ºã€‚è¿™äº›æ–¹æ³•é€šå¸¸é‡‡ç”¨å›ºå®šçš„è¡¨æ ¼å»ºæ¨¡æœºåˆ¶ï¼Œæ— æ³•æœ‰æ•ˆåˆ©ç”¨ä¸åŒè¡¨æ ¼æ•°æ®ä¹‹é—´çš„è¯­ä¹‰ä¿¡æ¯ï¼Œå¯¼è‡´æ¨¡åž‹æ³›åŒ–èƒ½åŠ›å—é™ã€‚å› æ­¤ï¼Œå¦‚ä½•æ‰“ç ´è·¨è¡¨æ ¼éšœç¢ï¼Œå®žçŽ°è·¨ä¸åŒæ•°æ®é˜Ÿåˆ—çš„çŸ¥è¯†è¿ç§»ï¼Œæ˜¯æœ¬æ–‡è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ä»Žè¯­ä¹‰æ„ŸçŸ¥çš„è§’åº¦è®¾è®¡è¡¨æ ¼å»ºæ¨¡æœºåˆ¶ï¼Œå°†è¡¨æ ¼çš„åˆ—æ ‡é¢˜ä½œä¸ºè¯­ä¹‰çº¿ç´¢ï¼Œå¼•å¯¼æ¨¡åž‹å­¦ä¹ æ›´å…·æ³›åŒ–èƒ½åŠ›çš„è¡¨æ ¼ç‰¹å¾è¡¨ç¤ºã€‚æ­¤å¤–ï¼Œé€šè¿‡å¼•å…¥åŽŸåž‹å¼•å¯¼çš„æ··åˆçº¿æ€§å±‚ï¼ˆP-MoLinï¼‰æ¨¡å—ï¼Œå¢žå¼ºæ¨¡åž‹å¯¹è¡¨æ ¼æ•°æ®å¼‚æž„æ€§çš„å¤„ç†èƒ½åŠ›ï¼Œä»Žè€Œå®žçŽ°è·¨è¡¨æ ¼çš„çŸ¥è¯†è¿ç§»å’Œå…±äº«ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šCITabæ¡†æž¶ä¸»è¦åŒ…å«å›¾åƒç¼–ç å™¨ã€è¡¨æ ¼ç¼–ç å™¨å’Œå¤šæ¨¡æ€èžåˆæ¨¡å—ã€‚å›¾åƒç¼–ç å™¨è´Ÿè´£æå–åŒ»å­¦å›¾åƒçš„è§†è§‰ç‰¹å¾ï¼›è¡¨æ ¼ç¼–ç å™¨åˆ™åˆ©ç”¨åˆ—æ ‡é¢˜ä½œä¸ºè¯­ä¹‰çº¿ç´¢ï¼Œå¯¹è¡¨æ ¼æ•°æ®è¿›è¡Œç¼–ç ï¼Œç”Ÿæˆè¡¨æ ¼ç‰¹å¾è¡¨ç¤ºï¼›å¤šæ¨¡æ€èžåˆæ¨¡å—å°†å›¾åƒç‰¹å¾å’Œè¡¨æ ¼ç‰¹å¾è¿›è¡Œèžåˆï¼Œå¾—åˆ°æœ€ç»ˆçš„å¤šæ¨¡æ€ç‰¹å¾è¡¨ç¤ºã€‚æ•´ä¸ªæ¡†æž¶é‡‡ç”¨è‡ªç›‘ç£å­¦ä¹ çš„æ–¹å¼è¿›è¡Œé¢„è®­ç»ƒï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ ç­‰æ–¹æ³•ï¼Œå­¦ä¹ å›¾åƒå’Œè¡¨æ ¼æ•°æ®ä¹‹é—´çš„å…³è”æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šCITabçš„å…³é”®åˆ›æ–°åœ¨äºŽä»¥ä¸‹ä¸¤ç‚¹ï¼šä¸€æ˜¯æå‡ºäº†è¯­ä¹‰æ„ŸçŸ¥çš„è¡¨æ ¼å»ºæ¨¡æœºåˆ¶ï¼Œé€šè¿‡å°†åˆ—æ ‡é¢˜ä½œä¸ºè¯­ä¹‰çº¿ç´¢ï¼Œå¼•å¯¼æ¨¡åž‹å­¦ä¹ æ›´å…·æ³›åŒ–èƒ½åŠ›çš„è¡¨æ ¼ç‰¹å¾è¡¨ç¤ºï¼›äºŒæ˜¯å¼•å…¥äº†åŽŸåž‹å¼•å¯¼çš„æ··åˆçº¿æ€§å±‚ï¼ˆP-MoLinï¼‰æ¨¡å—ï¼Œå¢žå¼ºæ¨¡åž‹å¯¹è¡¨æ ¼æ•°æ®å¼‚æž„æ€§çš„å¤„ç†èƒ½åŠ›ã€‚è¿™ä¸¤ä¸ªåˆ›æ–°ç‚¹ä½¿å¾—CITabèƒ½å¤Ÿæœ‰æ•ˆåœ°æ‰“ç ´è·¨è¡¨æ ¼éšœç¢ï¼Œå®žçŽ°è·¨ä¸åŒæ•°æ®é˜Ÿåˆ—çš„çŸ¥è¯†è¿ç§»ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è¡¨æ ¼ç¼–ç å™¨ä¸­ï¼Œåˆ—æ ‡é¢˜é¦–å…ˆè¢«åµŒå…¥åˆ°å‘é‡ç©ºé—´ä¸­ï¼Œç„¶åŽä¸Žè¡¨æ ¼æ•°æ®è¿›è¡Œèžåˆï¼Œå½¢æˆè¯­ä¹‰å¢žå¼ºçš„è¡¨æ ¼ç‰¹å¾è¡¨ç¤ºã€‚P-MoLinæ¨¡å—åŒ…å«å¤šä¸ªçº¿æ€§å±‚ï¼Œæ¯ä¸ªçº¿æ€§å±‚å¯¹åº”ä¸€ä¸ªåŽŸåž‹ï¼Œæ¨¡åž‹æ ¹æ®è¾“å…¥æ•°æ®çš„ç‰¹å¾ï¼Œé€‰æ‹©åˆé€‚çš„çº¿æ€§å±‚è¿›è¡Œå¤„ç†ã€‚æŸå¤±å‡½æ•°é‡‡ç”¨å¯¹æ¯”å­¦ä¹ æŸå¤±ï¼Œé¼“åŠ±æ¨¡åž‹å­¦ä¹ å›¾åƒå’Œè¡¨æ ¼æ•°æ®ä¹‹é—´çš„å…³è”æ€§ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æž„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒCITabåœ¨é˜¿å°”èŒ¨æµ·é»˜ç—…è¯Šæ–­ä»»åŠ¡ä¸­ï¼Œåœ¨ä¸‰ä¸ªå…¬å¼€æ•°æ®é›†ä¸Šå‡å–å¾—äº†ä¼˜äºŽçŽ°æœ‰æ–¹æ³•çš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨ADNIæ•°æ®é›†ä¸Šï¼ŒCITabçš„å‡†ç¡®çŽ‡æ¯”æœ€å…ˆè¿›çš„æ–¹æ³•æé«˜äº†3%ä»¥ä¸Šã€‚è¿™äº›ç»“æžœéªŒè¯äº†CITabæ¡†æž¶çš„æœ‰æ•ˆæ€§å’Œå¯æ‰©å±•æ€§ï¼Œè¡¨æ˜Žå…¶åœ¨è·¨è¡¨æ ¼å¤šæ¨¡æ€å­¦ä¹ æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

CITabæ¡†æž¶å¯åº”ç”¨äºŽå¤šç§åŒ»å­¦è¯Šæ–­å’Œé¢„æµ‹ä»»åŠ¡ï¼Œä¾‹å¦‚é˜¿å°”èŒ¨æµ·é»˜ç—…è¯Šæ–­ã€ç™Œç—‡é£Žé™©é¢„æµ‹ç­‰ã€‚é€šè¿‡åˆ©ç”¨å¤§è§„æ¨¡æœªæ ‡è®°çš„å›¾åƒ-è¡¨æ ¼æ•°æ®è¿›è¡Œé¢„è®­ç»ƒï¼Œå¯ä»¥æ˜¾è‘—æé«˜æ¨¡åž‹çš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚è¯¥ç ”ç©¶æˆæžœæœ‰åŠ©äºŽæŽ¨åŠ¨åŒ»å­¦äººå·¥æ™ºèƒ½çš„å‘å±•ï¼Œä¸ºä¸´åºŠå†³ç­–æä¾›æ›´å‡†ç¡®ã€å¯é çš„ä¾æ®ï¼Œå¹¶æœ‰æœ›é™ä½ŽåŒ»ç–—æˆæœ¬ï¼Œæé«˜åŒ»ç–—æ•ˆçŽ‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multi-modal learning integrating medical images and tabular data has significantly advanced clinical decision-making in recent years. Self-Supervised Learning (SSL) has emerged as a powerful paradigm for pretraining these models on large-scale unlabeled image-tabular data, aiming to learn discriminative representations. However, existing SSL methods for image-tabular representation learning are often confined to specific data cohorts, mainly due to their rigid tabular modeling mechanisms when modeling heterogeneous tabular data. This inter-tabular barrier hinders the multi-modal SSL methods from effectively learning transferrable medical knowledge shared across diverse cohorts. In this paper, we propose a novel SSL framework, namely CITab, designed to learn powerful multi-modal feature representations in a cross-tabular manner. We design the tabular modeling mechanism from a semantic-awareness perspective by integrating column headers as semantic cues, which facilitates transferrable knowledge learning and the scalability in utilizing multiple data sources for pretraining. Additionally, we propose a prototype-guided mixture-of-linear layer (P-MoLin) module for tabular feature specialization, empowering the model to effectively handle the heterogeneity of tabular data and explore the underlying medical concepts. We conduct comprehensive evaluations on Alzheimer's disease diagnosis task across three publicly available data cohorts containing 4,461 subjects. Experimental results demonstrate that CITab outperforms state-of-the-art approaches, paving the way for effective and scalable cross-tabular multi-modal learning.

