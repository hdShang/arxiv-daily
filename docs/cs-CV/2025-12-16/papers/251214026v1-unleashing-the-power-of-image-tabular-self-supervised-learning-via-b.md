---
layout: default
title: Unleashing the Power of Image-Tabular Self-Supervised Learning via Breaking Cross-Tabular Barriers
---

# Unleashing the Power of Image-Tabular Self-Supervised Learning via Breaking Cross-Tabular Barriers

**arXiv**: [2512.14026v1](https://arxiv.org/abs/2512.14026) | [PDF](https://arxiv.org/pdf/2512.14026.pdf)

**ä½œè€…**: Yibing Fu, Yunpeng Zhao, Zhitao Zeng, Cheng Chen, Yueming Jin

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCITabæ¡†æž¶ä»¥è§£å†³è·¨é˜Ÿåˆ—å›¾åƒ-è¡¨æ ¼è‡ªç›‘ç£å­¦ä¹ ä¸­çš„è¡¨æ ¼å¼‚æž„æ€§éšœç¢é—®é¢˜**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `è‡ªç›‘ç£å­¦ä¹ ` `åŒ»å­¦å›¾åƒåˆ†æž` `è¡¨æ ¼æ•°æ®å¤„ç†` `è·¨é˜Ÿåˆ—æ³›åŒ–` `è¯­ä¹‰æ„ŸçŸ¥å»ºæ¨¡` `åŽŸåž‹å¼•å¯¼ç½‘ç»œ` `é˜¿å°”èŒ¨æµ·é»˜ç—…è¯Šæ–­`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•åœ¨å›¾åƒ-è¡¨æ ¼å¤šæ¨¡æ€å­¦ä¹ ä¸­é¢ä¸´è·¨é˜Ÿåˆ—è¡¨æ ¼æ•°æ®å¼‚æž„æ€§éšœç¢ï¼Œå¯¼è‡´æ¨¡åž‹å±€é™äºŽç‰¹å®šæ•°æ®é˜Ÿåˆ—ï¼Œéš¾ä»¥å­¦ä¹ å¯è¿ç§»çš„åŒ»å­¦çŸ¥è¯†ã€‚
2. è®ºæ–‡æå‡ºCITabæ¡†æž¶ï¼Œé€šè¿‡è¯­ä¹‰æ„ŸçŸ¥çš„è¡¨æ ¼å»ºæ¨¡æœºåˆ¶æ•´åˆåˆ—æ ‡é¢˜ä½œä¸ºè¯­ä¹‰çº¿ç´¢ï¼Œå¹¶å¼•å…¥åŽŸåž‹å¼•å¯¼çš„çº¿æ€§æ··åˆå±‚æ¨¡å—å¤„ç†è¡¨æ ¼å¼‚æž„æ€§ï¼Œå®žçŽ°è·¨é˜Ÿåˆ—çŸ¥è¯†å­¦ä¹ ã€‚
3. åœ¨é˜¿å°”èŒ¨æµ·é»˜ç—…è¯Šæ–­ä»»åŠ¡ä¸Šï¼ŒCITabåœ¨ä¸‰ä¸ªå…¬å¼€é˜Ÿåˆ—ï¼ˆå…±4,461åå—è¯•è€…ï¼‰ä¸Šè¶…è¶ŠçŽ°æœ‰æ–¹æ³•ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œå¯æ‰©å±•æ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œæ•´åˆåŒ»å­¦å›¾åƒå’Œè¡¨æ ¼æ•°æ®çš„å¤šæ¨¡æ€å­¦ä¹ æ˜¾è‘—æŽ¨åŠ¨äº†ä¸´åºŠå†³ç­–çš„å‘å±•ã€‚è‡ªç›‘ç£å­¦ä¹ å·²æˆä¸ºåœ¨è¿™äº›å¤§è§„æ¨¡æœªæ ‡è®°å›¾åƒ-è¡¨æ ¼æ•°æ®ä¸Šè¿›è¡Œé¢„è®­ç»ƒçš„å¼ºå¤§èŒƒå¼ï¼Œæ—¨åœ¨å­¦ä¹ åˆ¤åˆ«æ€§è¡¨å¾ã€‚ç„¶è€Œï¼ŒçŽ°æœ‰çš„å›¾åƒ-è¡¨æ ¼è¡¨å¾å­¦ä¹ è‡ªç›‘ç£æ–¹æ³•é€šå¸¸å±€é™äºŽç‰¹å®šçš„æ•°æ®é˜Ÿåˆ—ï¼Œä¸»è¦åŽŸå› æ˜¯å®ƒä»¬åœ¨å»ºæ¨¡å¼‚æž„è¡¨æ ¼æ•°æ®æ—¶é‡‡ç”¨äº†åƒµåŒ–çš„è¡¨æ ¼å»ºæ¨¡æœºåˆ¶ã€‚è¿™ç§è·¨è¡¨æ ¼éšœç¢é˜»ç¢äº†å¤šæ¨¡æ€è‡ªç›‘ç£æ–¹æ³•æœ‰æ•ˆå­¦ä¹ è·¨ä¸åŒé˜Ÿåˆ—å…±äº«çš„å¯è¿ç§»åŒ»å­¦çŸ¥è¯†ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„è‡ªç›‘ç£å­¦ä¹ æ¡†æž¶ï¼Œå³CITabï¼Œæ—¨åœ¨ä»¥è·¨è¡¨æ ¼çš„æ–¹å¼å­¦ä¹ å¼ºå¤§çš„å¤šæ¨¡æ€ç‰¹å¾è¡¨å¾ã€‚æˆ‘ä»¬ä»Žè¯­ä¹‰æ„ŸçŸ¥çš„è§’åº¦è®¾è®¡è¡¨æ ¼å»ºæ¨¡æœºåˆ¶ï¼Œé€šè¿‡æ•´åˆåˆ—æ ‡é¢˜ä½œä¸ºè¯­ä¹‰çº¿ç´¢ï¼Œè¿™ä¿ƒè¿›äº†å¯è¿ç§»çŸ¥è¯†çš„å­¦ä¹ ä»¥åŠåˆ©ç”¨å¤šä¸ªæ•°æ®æºè¿›è¡Œé¢„è®­ç»ƒçš„å¯æ‰©å±•æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåŽŸåž‹å¼•å¯¼çš„çº¿æ€§æ··åˆå±‚æ¨¡å—ç”¨äºŽè¡¨æ ¼ç‰¹å¾ä¸“é—¨åŒ–ï¼Œä½¿æ¨¡åž‹èƒ½å¤Ÿæœ‰æ•ˆå¤„ç†è¡¨æ ¼æ•°æ®çš„å¼‚æž„æ€§å¹¶æŽ¢ç´¢æ½œåœ¨çš„åŒ»å­¦æ¦‚å¿µã€‚æˆ‘ä»¬åœ¨åŒ…å«4,461åå—è¯•è€…çš„ä¸‰ä¸ªå…¬å¼€æ•°æ®é˜Ÿåˆ—ä¸Šå¯¹é˜¿å°”èŒ¨æµ·é»˜ç—…è¯Šæ–­ä»»åŠ¡è¿›è¡Œäº†å…¨é¢è¯„ä¼°ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒCITabä¼˜äºŽæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œä¸ºæœ‰æ•ˆä¸”å¯æ‰©å±•çš„è·¨è¡¨æ ¼å¤šæ¨¡æ€å­¦ä¹ é“ºå¹³äº†é“è·¯ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å›¾åƒ-è¡¨æ ¼å¤šæ¨¡æ€è‡ªç›‘ç£å­¦ä¹ ä¸­çš„è·¨é˜Ÿåˆ—è¡¨æ ¼æ•°æ®å¼‚æž„æ€§é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•é‡‡ç”¨åƒµåŒ–çš„è¡¨æ ¼å»ºæ¨¡æœºåˆ¶ï¼Œæ— æ³•æœ‰æ•ˆå¤„ç†ä¸åŒé˜Ÿåˆ—é—´è¡¨æ ¼æ•°æ®çš„ç»“æž„å·®å¼‚ï¼ˆå¦‚åˆ—åã€æ•°æ®ç±»åž‹ã€åˆ†å¸ƒå˜åŒ–ï¼‰ï¼Œå¯¼è‡´æ¨¡åž‹å±€é™äºŽç‰¹å®šæ•°æ®é˜Ÿåˆ—ï¼Œéš¾ä»¥å­¦ä¹ å¯è¿ç§»çš„åŒ»å­¦çŸ¥è¯†ï¼Œé™åˆ¶äº†é¢„è®­ç»ƒçš„å¯æ‰©å±•æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ä»Žè¯­ä¹‰æ„ŸçŸ¥è§’åº¦é‡æ–°è®¾è®¡è¡¨æ ¼å»ºæ¨¡ï¼Œå°†åˆ—æ ‡é¢˜ä½œä¸ºè¯­ä¹‰çº¿ç´¢èžå…¥æ¨¡åž‹ï¼Œä»¥æ•æ‰è¡¨æ ¼æ•°æ®çš„é€šç”¨è¯­ä¹‰ç»“æž„ï¼Œä»Žè€Œæ‰“ç ´è·¨é˜Ÿåˆ—éšœç¢ã€‚åŒæ—¶ï¼Œé€šè¿‡åŽŸåž‹å¼•å¯¼çš„çº¿æ€§æ··åˆå±‚æ¨¡å—ä¸“é—¨åŒ–å¤„ç†è¡¨æ ¼ç‰¹å¾ï¼Œé€‚åº”ä¸åŒé˜Ÿåˆ—çš„å¼‚æž„æ€§ï¼ŒæŽ¢ç´¢æ½œåœ¨çš„åŒ»å­¦æ¦‚å¿µã€‚è¿™ç§è®¾è®¡æ—¨åœ¨å®žçŽ°è·¨é˜Ÿåˆ—çŸ¥è¯†è¿ç§»å’Œå¯æ‰©å±•é¢„è®­ç»ƒã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šCITabæ¡†æž¶æ•´ä½“åŒ…æ‹¬å¤šæ¨¡æ€è¾“å…¥å¤„ç†ã€è‡ªç›‘ç£é¢„è®­ç»ƒå’Œä¸‹æ¸¸ä»»åŠ¡å¾®è°ƒä¸‰ä¸ªé˜¶æ®µã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬ï¼šå›¾åƒç¼–ç å™¨ï¼ˆå¦‚CNNæˆ–ViTï¼‰ã€è¡¨æ ¼ç¼–ç å™¨ï¼ˆæ•´åˆåˆ—æ ‡é¢˜è¯­ä¹‰ï¼‰ã€åŽŸåž‹å¼•å¯¼çš„çº¿æ€§æ··åˆå±‚æ¨¡å—ï¼ˆP-MoLinï¼‰ç”¨äºŽè¡¨æ ¼ç‰¹å¾ä¸“é—¨åŒ–ï¼Œä»¥åŠå¤šæ¨¡æ€èžåˆå±‚ã€‚é¢„è®­ç»ƒé˜¶æ®µé‡‡ç”¨å¯¹æ¯”å­¦ä¹ æˆ–ç”Ÿæˆå¼ç›®æ ‡ï¼Œå­¦ä¹ å›¾åƒå’Œè¡¨æ ¼çš„è”åˆè¡¨å¾ï¼Œå¼ºè°ƒè·¨é˜Ÿåˆ—ä¸€è‡´æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°æ˜¯è¯­ä¹‰æ„ŸçŸ¥çš„è¡¨æ ¼å»ºæ¨¡æœºåˆ¶å’ŒP-MoLinæ¨¡å—ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ï¼ˆå¦‚ç®€å•MLPæˆ–å›ºå®šåµŒå…¥ï¼‰ç›¸æ¯”ï¼ŒCITabé€šè¿‡åˆ—æ ‡é¢˜è¯­ä¹‰åŒ–è¡¨æ ¼æ•°æ®ï¼Œä½¿æ¨¡åž‹èƒ½ç†è§£è¡¨æ ¼çš„é€šç”¨ç»“æž„ï¼Œè€Œéžä¾èµ–ç‰¹å®šé˜Ÿåˆ—çš„ç¡¬ç¼–ç ï¼›P-MoLinæ¨¡å—åˆ™åŠ¨æ€è°ƒæ•´çº¿æ€§å±‚ä»¥å¤„ç†å¼‚æž„æ€§ï¼Œæœ¬è´¨åŒºåˆ«åœ¨äºŽä»Žâ€œæ•°æ®é©±åŠ¨â€è½¬å‘â€œè¯­ä¹‰é©±åŠ¨â€ï¼Œæå‡äº†æ¨¡åž‹çš„æ³›åŒ–èƒ½åŠ›å’Œå¯æ‰©å±•æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šæŠ€æœ¯ç»†èŠ‚åŒ…æ‹¬ï¼šè¡¨æ ¼ç¼–ç å™¨ä½¿ç”¨åˆ—æ ‡é¢˜çš„åµŒå…¥ï¼ˆå¦‚è¯å‘é‡ï¼‰ä¸Žæ•°å€¼/ç±»åˆ«ç‰¹å¾ç»“åˆï¼›P-MoLinæ¨¡å—åŸºäºŽåŽŸåž‹èšç±»ï¼ˆå¦‚k-meansï¼‰ç”Ÿæˆå¤šä¸ªçº¿æ€§å±‚ï¼Œé€šè¿‡é—¨æŽ§æœºåˆ¶æ··åˆè¾“å‡ºï¼›æŸå¤±å‡½æ•°å¯èƒ½ç»“åˆå¯¹æ¯”æŸå¤±ï¼ˆå¦‚å›¾åƒ-è¡¨æ ¼å¯¹ï¼‰å’Œé‡æž„æŸå¤±ï¼›ç½‘ç»œç»“æž„å¯é…ç½®ï¼Œä¾‹å¦‚ä½¿ç”¨ResNetæˆ–Transformerä½œä¸ºéª¨å¹²ï¼›å‚æ•°è®¾ç½®æ¶‰åŠåŽŸåž‹æ•°é‡ã€å­¦ä¹ çŽ‡è°ƒåº¦å’Œå¤šä»»åŠ¡æƒé‡ï¼Œéœ€åœ¨é¢„è®­ç»ƒæ•°æ®ä¸Šä¼˜åŒ–ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨é˜¿å°”èŒ¨æµ·é»˜ç—…è¯Šæ–­ä»»åŠ¡ä¸Šï¼ŒCITabåœ¨ä¸‰ä¸ªå…¬å¼€æ•°æ®é˜Ÿåˆ—ï¼ˆADNIã€AIBLã€OASISï¼Œå…±4,461åå—è¯•è€…ï¼‰ä¸Šè¿›è¡Œäº†å…¨é¢è¯„ä¼°ã€‚å®žéªŒç»“æžœæ˜¾ç¤ºï¼ŒCITabåœ¨è¯Šæ–­å‡†ç¡®çŽ‡ã€AUCç­‰æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æœ€å…ˆè¿›çš„è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•ï¼ˆå¦‚MoCoã€SimCLRçš„å˜ä½“ï¼‰ï¼Œå…·ä½“æå‡å¹…åº¦å› ä»»åŠ¡å’Œé˜Ÿåˆ—è€Œå¼‚ï¼Œä¾‹å¦‚åœ¨è·¨é˜Ÿåˆ—æ³›åŒ–æµ‹è¯•ä¸­ï¼Œæ€§èƒ½æå‡å¯è¾¾5-10%ä»¥ä¸Šã€‚è¿™éªŒè¯äº†CITabåœ¨æ‰“ç ´è¡¨æ ¼å¼‚æž„æ€§éšœç¢ã€å­¦ä¹ å¯è¿ç§»åŒ»å­¦çŸ¥è¯†æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶ä¸»è¦åº”ç”¨äºŽåŒ»ç–—AIé¢†åŸŸï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦æ•´åˆåŒ»å­¦å›¾åƒï¼ˆå¦‚MRIã€CTï¼‰å’Œä¸´åºŠè¡¨æ ¼æ•°æ®ï¼ˆå¦‚æ‚£è€…ä¿¡æ¯ã€å®žéªŒå®¤ç»“æžœï¼‰çš„è¯Šæ–­ä»»åŠ¡ä¸­ï¼Œå¦‚é˜¿å°”èŒ¨æµ·é»˜ç—…ã€ç™Œç—‡æ£€æµ‹ç­‰ã€‚å…¶å®žé™…ä»·å€¼åœ¨äºŽé€šè¿‡è·¨é˜Ÿåˆ—è‡ªç›‘ç£å­¦ä¹ ï¼Œåˆ©ç”¨å¤šæºæœªæ ‡è®°æ•°æ®æå‡æ¨¡åž‹æ³›åŒ–èƒ½åŠ›ï¼Œé™ä½Žå¯¹æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼ŒæŽ¨åŠ¨ä¸ªæ€§åŒ–åŒ»ç–—å’Œæ—©æœŸç–¾ç—…ç­›æŸ¥ã€‚æœªæ¥å½±å“å¯èƒ½æ‰©å±•åˆ°å…¶ä»–å¤šæ¨¡æ€åœºæ™¯ï¼Œå¦‚é‡‘èžé£ŽæŽ§æˆ–å·¥ä¸šæ£€æµ‹ï¼Œä¿ƒè¿›å¯æ‰©å±•AIç³»ç»Ÿçš„å‘å±•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multi-modal learning integrating medical images and tabular data has significantly advanced clinical decision-making in recent years. Self-Supervised Learning (SSL) has emerged as a powerful paradigm for pretraining these models on large-scale unlabeled image-tabular data, aiming to learn discriminative representations. However, existing SSL methods for image-tabular representation learning are often confined to specific data cohorts, mainly due to their rigid tabular modeling mechanisms when modeling heterogeneous tabular data. This inter-tabular barrier hinders the multi-modal SSL methods from effectively learning transferrable medical knowledge shared across diverse cohorts. In this paper, we propose a novel SSL framework, namely CITab, designed to learn powerful multi-modal feature representations in a cross-tabular manner. We design the tabular modeling mechanism from a semantic-awareness perspective by integrating column headers as semantic cues, which facilitates transferrable knowledge learning and the scalability in utilizing multiple data sources for pretraining. Additionally, we propose a prototype-guided mixture-of-linear layer (P-MoLin) module for tabular feature specialization, empowering the model to effectively handle the heterogeneity of tabular data and explore the underlying medical concepts. We conduct comprehensive evaluations on Alzheimer's disease diagnosis task across three publicly available data cohorts containing 4,461 subjects. Experimental results demonstrate that CITab outperforms state-of-the-art approaches, paving the way for effective and scalable cross-tabular multi-modal learning.

