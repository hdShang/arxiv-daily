---
layout: default
title: Unleashing the Power of Image-Tabular Self-Supervised Learning via Breaking Cross-Tabular Barriers
---

# Unleashing the Power of Image-Tabular Self-Supervised Learning via Breaking Cross-Tabular Barriers

**arXiv**: [2512.14026v1](https://arxiv.org/abs/2512.14026) | [PDF](https://arxiv.org/pdf/2512.14026.pdf)

**ä½œè€…**: Yibing Fu, Yunpeng Zhao, Zhitao Zeng, Cheng Chen, Yueming Jin

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCITabæ¡†æž¶ä»¥è§£å†³è·¨é˜Ÿåˆ—å›¾åƒ-è¡¨æ ¼è‡ªç›‘ç£å­¦ä¹ ä¸­çš„è¡¨æ ¼å¼‚æž„æ€§éšœç¢é—®é¢˜**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `è‡ªç›‘ç£å­¦ä¹ ` `å¤šæ¨¡æ€èžåˆ` `åŒ»å­¦å›¾åƒåˆ†æž` `è¡¨æ ¼æ•°æ®å¤„ç†` `è·¨é˜Ÿåˆ—å­¦ä¹ ` `è¡¨å¾å­¦ä¹ ` `é˜¿å°”èŒ¨æµ·é»˜ç—…è¯Šæ–­` `è¯­ä¹‰æ„ŸçŸ¥å»ºæ¨¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•å› åƒµåŒ–çš„è¡¨æ ¼å»ºæ¨¡æœºåˆ¶ï¼Œéš¾ä»¥å¤„ç†å¼‚æž„è¡¨æ ¼æ•°æ®ï¼Œå¯¼è‡´è·¨é˜Ÿåˆ—çŸ¥è¯†è¿ç§»å—é™ã€‚
2. æå‡ºCITabæ¡†æž¶ï¼Œé€šè¿‡è¯­ä¹‰æ„ŸçŸ¥çš„è¡¨æ ¼å»ºæ¨¡å’ŒåŽŸåž‹å¼•å¯¼çš„çº¿æ€§æ··åˆå±‚ï¼Œå®žçŽ°è·¨è¡¨æ ¼å¤šæ¨¡æ€è¡¨å¾å­¦ä¹ ã€‚
3. åœ¨é˜¿å°”èŒ¨æµ·é»˜ç—…è¯Šæ–­ä»»åŠ¡ä¸­ï¼ŒCITabåœ¨ä¸‰ä¸ªå…¬å¼€é˜Ÿåˆ—ä¸Šè¶…è¶ŠçŽ°æœ‰æ–¹æ³•ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œå¯æ‰©å±•æ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œæ•´åˆåŒ»å­¦å›¾åƒå’Œè¡¨æ ¼æ•°æ®çš„å¤šæ¨¡æ€å­¦ä¹ æ˜¾è‘—æŽ¨åŠ¨äº†ä¸´åºŠå†³ç­–çš„è¿›æ­¥ã€‚è‡ªç›‘ç£å­¦ä¹ å·²æˆä¸ºåœ¨è¿™äº›å¤§è§„æ¨¡æœªæ ‡è®°å›¾åƒ-è¡¨æ ¼æ•°æ®ä¸Šè¿›è¡Œé¢„è®­ç»ƒçš„å¼ºå¤§èŒƒå¼ï¼Œæ—¨åœ¨å­¦ä¹ åˆ¤åˆ«æ€§è¡¨å¾ã€‚ç„¶è€Œï¼ŒçŽ°æœ‰çš„å›¾åƒ-è¡¨æ ¼è¡¨å¾å­¦ä¹ è‡ªç›‘ç£æ–¹æ³•é€šå¸¸å±€é™äºŽç‰¹å®šæ•°æ®é˜Ÿåˆ—ï¼Œä¸»è¦åŽŸå› æ˜¯å…¶å»ºæ¨¡å¼‚æž„è¡¨æ ¼æ•°æ®æ—¶é‡‡ç”¨åƒµåŒ–çš„è¡¨æ ¼å»ºæ¨¡æœºåˆ¶ã€‚è¿™ç§è·¨è¡¨æ ¼éšœç¢é˜»ç¢äº†å¤šæ¨¡æ€è‡ªç›‘ç£æ–¹æ³•æœ‰æ•ˆå­¦ä¹ è·¨ä¸åŒé˜Ÿåˆ—å…±äº«çš„å¯è¿ç§»åŒ»å­¦çŸ¥è¯†ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„è‡ªç›‘ç£å­¦ä¹ æ¡†æž¶CITabï¼Œæ—¨åœ¨ä»¥è·¨è¡¨æ ¼æ–¹å¼å­¦ä¹ å¼ºå¤§çš„å¤šæ¨¡æ€ç‰¹å¾è¡¨å¾ã€‚æˆ‘ä»¬ä»Žè¯­ä¹‰æ„ŸçŸ¥çš„è§’åº¦è®¾è®¡è¡¨æ ¼å»ºæ¨¡æœºåˆ¶ï¼Œé€šè¿‡æ•´åˆåˆ—æ ‡é¢˜ä½œä¸ºè¯­ä¹‰çº¿ç´¢ï¼Œä¿ƒè¿›å¯è¿ç§»çŸ¥è¯†å­¦ä¹ ä»¥åŠåˆ©ç”¨å¤šä¸ªæ•°æ®æºè¿›è¡Œé¢„è®­ç»ƒçš„å¯æ‰©å±•æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†åŽŸåž‹å¼•å¯¼çš„çº¿æ€§æ··åˆå±‚æ¨¡å—ç”¨äºŽè¡¨æ ¼ç‰¹å¾ä¸“ä¸šåŒ–ï¼Œä½¿æ¨¡åž‹èƒ½å¤Ÿæœ‰æ•ˆå¤„ç†è¡¨æ ¼æ•°æ®çš„å¼‚æž„æ€§å¹¶æŽ¢ç´¢æ½œåœ¨çš„åŒ»å­¦æ¦‚å¿µã€‚æˆ‘ä»¬åœ¨åŒ…å«4,461åå—è¯•è€…çš„ä¸‰ä¸ªå…¬å¼€æ•°æ®é˜Ÿåˆ—ä¸Šå¯¹é˜¿å°”èŒ¨æµ·é»˜ç—…è¯Šæ–­ä»»åŠ¡è¿›è¡Œäº†å…¨é¢è¯„ä¼°ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒCITabä¼˜äºŽæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œä¸ºæœ‰æ•ˆä¸”å¯æ‰©å±•çš„è·¨è¡¨æ ¼å¤šæ¨¡æ€å­¦ä¹ é“ºå¹³äº†é“è·¯ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

CITabæ˜¯ä¸€ä¸ªè·¨è¡¨æ ¼è‡ªç›‘ç£å­¦ä¹ æ¡†æž¶ï¼Œæ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š1ï¼‰è¯­ä¹‰æ„ŸçŸ¥çš„è¡¨æ ¼å»ºæ¨¡æœºåˆ¶ï¼Œå°†åˆ—æ ‡é¢˜ä½œä¸ºè¯­ä¹‰çº¿ç´¢æ•´åˆï¼Œå¢žå¼ºæ¨¡åž‹å¯¹è¡¨æ ¼ç»“æž„çš„ç†è§£ï¼›2ï¼‰åŽŸåž‹å¼•å¯¼çš„çº¿æ€§æ··åˆå±‚æ¨¡å—ï¼Œé€šè¿‡åŽŸåž‹èšç±»å’Œçº¿æ€§ç»„åˆå®žçŽ°è¡¨æ ¼ç‰¹å¾ä¸“ä¸šåŒ–ï¼Œä»¥å¤„ç†æ•°æ®å¼‚æž„æ€§ã€‚æ•´ä½“æ¡†æž¶ç»“åˆå›¾åƒå’Œè¡¨æ ¼æ¨¡æ€ï¼Œé€šè¿‡è‡ªç›‘ç£é¢„è®­ç»ƒå­¦ä¹ å…±äº«è¡¨å¾ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒCITabçªç ´äº†è·¨è¡¨æ ¼éšœç¢ï¼Œæ”¯æŒå¤šæ•°æ®æºé¢„è®­ç»ƒï¼Œæå‡äº†å¯è¿ç§»æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨åŒ…å«4,461åå—è¯•è€…çš„ä¸‰ä¸ªå…¬å¼€é˜¿å°”èŒ¨æµ·é»˜ç—…æ•°æ®é˜Ÿåˆ—ä¸Šï¼ŒCITabåœ¨è¯Šæ–­ä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æœ€å…ˆè¿›æ–¹æ³•ï¼Œè¯æ˜Žäº†å…¶åœ¨è·¨è¡¨æ ¼å¤šæ¨¡æ€å­¦ä¹ ä¸­çš„æœ‰æ•ˆæ€§å’Œæ€§èƒ½æå‡ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶ä¸»è¦åº”ç”¨äºŽåŒ»å­¦é¢†åŸŸï¼Œç‰¹åˆ«æ˜¯é˜¿å°”èŒ¨æµ·é»˜ç—…ç­‰ç–¾ç—…çš„è¯Šæ–­å’Œé¢„æµ‹ï¼Œé€šè¿‡æ•´åˆåŒ»å­¦å›¾åƒå’Œä¸´åºŠè¡¨æ ¼æ•°æ®ï¼Œæå‡ä¸´åºŠå†³ç­–çš„å‡†ç¡®æ€§å’Œæ•ˆçŽ‡ã€‚å…¶è·¨é˜Ÿåˆ—å­¦ä¹ èƒ½åŠ›å¯æ‰©å±•åˆ°å…¶ä»–å¤šæ¨¡æ€åŒ»ç–—æ•°æ®åˆ†æžä»»åŠ¡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multi-modal learning integrating medical images and tabular data has significantly advanced clinical decision-making in recent years. Self-Supervised Learning (SSL) has emerged as a powerful paradigm for pretraining these models on large-scale unlabeled image-tabular data, aiming to learn discriminative representations. However, existing SSL methods for image-tabular representation learning are often confined to specific data cohorts, mainly due to their rigid tabular modeling mechanisms when modeling heterogeneous tabular data. This inter-tabular barrier hinders the multi-modal SSL methods from effectively learning transferrable medical knowledge shared across diverse cohorts. In this paper, we propose a novel SSL framework, namely CITab, designed to learn powerful multi-modal feature representations in a cross-tabular manner. We design the tabular modeling mechanism from a semantic-awareness perspective by integrating column headers as semantic cues, which facilitates transferrable knowledge learning and the scalability in utilizing multiple data sources for pretraining. Additionally, we propose a prototype-guided mixture-of-linear layer (P-MoLin) module for tabular feature specialization, empowering the model to effectively handle the heterogeneity of tabular data and explore the underlying medical concepts. We conduct comprehensive evaluations on Alzheimer's disease diagnosis task across three publicly available data cohorts containing 4,461 subjects. Experimental results demonstrate that CITab outperforms state-of-the-art approaches, paving the way for effective and scalable cross-tabular multi-modal learning.

