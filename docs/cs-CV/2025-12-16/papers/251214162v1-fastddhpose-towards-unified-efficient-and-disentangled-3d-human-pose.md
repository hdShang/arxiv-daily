---
layout: default
title: FastDDHPose: Towards Unified, Efficient, and Disentangled 3D Human Pose Estimation
---

# FastDDHPose: Towards Unified, Efficient, and Disentangled 3D Human Pose Estimation

**arXiv**: [2512.14162v1](https://arxiv.org/abs/2512.14162) | [PDF](https://arxiv.org/pdf/2512.14162.pdf)

**ä½œè€…**: Qingyuan Cai, Linxin Zhang, Xuecai Hu, Saihui Hou, Yongzhen Huang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**ðŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Andyen512/Fast3DHPE)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFastDDHPoseï¼Œä¸€ä¸ªåŸºäºŽè§£è€¦æ‰©æ•£çš„3Däººä½“å§¿æ€ä¼°è®¡æ–¹æ³•ï¼Œä»¥è§£å†³çŽ°æœ‰æ–¹æ³•ç¼ºä¹ç»Ÿä¸€æ¡†æž¶å’Œè¯¯å·®ç´¯ç§¯é—®é¢˜ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **è§†è§‰é‡Œç¨‹è®¡** **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `3Däººä½“å§¿æ€ä¼°è®¡` `æ‰©æ•£æ¨¡åž‹` `è§£è€¦å»ºæ¨¡` `è¿åŠ¨å­¦å±‚æ¬¡` `ç»Ÿä¸€æ¡†æž¶` `è®­ç»ƒæ•ˆçŽ‡` `æ³›åŒ–èƒ½åŠ›` `å•ç›®è§†è§‰`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰3Däººä½“å§¿æ€ä¼°è®¡æ–¹æ³•ç¼ºä¹ç»Ÿä¸€è®­ç»ƒå’Œè¯„ä¼°æ¡†æž¶ï¼Œå¯¼è‡´å…¬å¹³æ¯”è¾ƒå›°éš¾ï¼Œä¸”è®­ç»ƒæ•ˆçŽ‡ä½Žä¸‹ã€‚
2. æå‡ºFastDDHPoseï¼ŒåŸºäºŽè§£è€¦æ‰©æ•£æ¨¡åž‹æ˜¾å¼å»ºæ¨¡éª¨éª¼é•¿åº¦å’Œæ–¹å‘åˆ†å¸ƒï¼Œå¹¶è®¾è®¡é«˜æ•ˆåŽ»å™ªå™¨ä»¥å‡å°‘è¯¯å·®ç´¯ç§¯ã€‚
3. åœ¨Human3.6Må’ŒMPI-INF-3DHPæ•°æ®é›†ä¸Šï¼ŒFastDDHPoseå®žçŽ°æœ€å…ˆè¿›æ€§èƒ½ï¼Œæå‡è®­ç»ƒæ•ˆçŽ‡å¹¶å¢žå¼ºæ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘æœŸå•ç›®3Däººä½“å§¿æ€ä¼°è®¡æ–¹æ³•é€šè¿‡ä»Ž2Då…³é”®ç‚¹åºåˆ—ç›´æŽ¥å›žå½’3Då§¿æ€å–å¾—äº†é¢†å…ˆæ€§èƒ½ï¼Œä½†çŽ°æœ‰æ–¹æ³•é€šå¸¸åœ¨åˆ†æ•£çš„æ¡†æž¶ä¸‹è®­ç»ƒå’Œè¯„ä¼°ï¼Œç¼ºä¹ç»Ÿä¸€æ¡†æž¶è¿›è¡Œå…¬å¹³æ¯”è¾ƒã€‚ä¸ºåº”å¯¹è¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºFast3DHPEï¼Œä¸€ä¸ªæ¨¡å—åŒ–æ¡†æž¶ï¼Œä¿ƒè¿›æ–°æ–¹æ³•çš„å¿«é€Ÿå¤çŽ°å’Œçµæ´»å¼€å‘ã€‚é€šè¿‡æ ‡å‡†åŒ–è®­ç»ƒå’Œè¯„ä¼°åè®®ï¼ŒFast3DHPEå®žçŽ°äº†3Däººä½“å§¿æ€ä¼°è®¡æ–¹æ³•çš„å…¬å¹³æ¯”è¾ƒï¼ŒåŒæ—¶æ˜¾è‘—æå‡è®­ç»ƒæ•ˆçŽ‡ã€‚åœ¨æ­¤æ¡†æž¶å†…ï¼Œæˆ‘ä»¬å¼•å…¥FastDDHPoseï¼Œä¸€ç§åŸºäºŽè§£è€¦æ‰©æ•£çš„3Däººä½“å§¿æ€ä¼°è®¡æ–¹æ³•ï¼Œåˆ©ç”¨æ‰©æ•£æ¨¡åž‹çš„å¼ºå¤§æ½œåœ¨åˆ†å¸ƒå»ºæ¨¡èƒ½åŠ›ï¼Œæ˜¾å¼å»ºæ¨¡éª¨éª¼é•¿åº¦å’Œéª¨éª¼æ–¹å‘çš„åˆ†å¸ƒï¼ŒåŒæ—¶é¿å…è¿›ä¸€æ­¥æ”¾å¤§å±‚æ¬¡è¯¯å·®ç´¯ç§¯ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªé«˜æ•ˆçš„åŸºäºŽè¿åŠ¨å­¦å±‚æ¬¡çš„ç©ºé—´å’Œæ—¶é—´åŽ»å™ªå™¨ï¼Œé¼“åŠ±æ¨¡åž‹å…³æ³¨è¿åŠ¨å­¦å…³èŠ‚å±‚æ¬¡ï¼ŒåŒæ—¶é¿å…å¯¹è¿‡äºŽå¤æ‚çš„å…³èŠ‚æ‹“æ‰‘è¿›è¡Œä¸å¿…è¦çš„å»ºæ¨¡ã€‚åœ¨Human3.6Må’ŒMPI-INF-3DHPä¸Šçš„å¤§é‡å®žéªŒè¡¨æ˜Žï¼ŒFast3DHPEæ¡†æž¶å®žçŽ°äº†æ‰€æœ‰æ–¹æ³•çš„å…¬å¹³æ¯”è¾ƒï¼ŒåŒæ—¶æ˜¾è‘—æå‡è®­ç»ƒæ•ˆçŽ‡ã€‚åœ¨æ­¤ç»Ÿä¸€æ¡†æž¶å†…ï¼ŒFastDDHPoseåœ¨é‡Žå¤–åœºæ™¯ä¸­å®žçŽ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå…·æœ‰å¼ºå¤§çš„æ³›åŒ–æ€§å’Œé²æ£’æ€§ã€‚æ¡†æž¶å’Œæ¨¡åž‹å°†åœ¨https://github.com/Andyen512/Fast3DHPEå‘å¸ƒã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

FastDDHPoseåŸºäºŽFast3DHPEç»Ÿä¸€æ¡†æž¶ï¼Œæ ¸å¿ƒæ–¹æ³•é‡‡ç”¨è§£è€¦æ‰©æ•£æ¨¡åž‹è¿›è¡Œ3Däººä½“å§¿æ€ä¼°è®¡ã€‚å…³é”®åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼šåˆ©ç”¨æ‰©æ•£æ¨¡åž‹å»ºæ¨¡éª¨éª¼é•¿åº¦å’Œæ–¹å‘çš„æ½œåœ¨åˆ†å¸ƒï¼Œé¿å…å±‚æ¬¡è¯¯å·®ç´¯ç§¯ï¼›è®¾è®¡åŸºäºŽè¿åŠ¨å­¦å±‚æ¬¡çš„ç©ºé—´å’Œæ—¶é—´åŽ»å™ªå™¨ï¼Œä¼˜åŒ–å…³èŠ‚å±‚æ¬¡å»ºæ¨¡ï¼Œå‡å°‘å¤æ‚æ‹“æ‰‘çš„å†—ä½™è®¡ç®—ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºŽï¼Œå®ƒé€šè¿‡è§£è€¦æ–¹å¼æ˜¾å¼å¤„ç†éª¨éª¼å±žæ€§ï¼Œè€Œéžç›´æŽ¥å›žå½’æ•´ä½“å§¿æ€ï¼Œä»Žè€Œæå‡ç²¾åº¦å’Œæ•ˆçŽ‡ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨Human3.6Må’ŒMPI-INF-3DHPæ•°æ®é›†ä¸Šï¼ŒFastDDHPoseå®žçŽ°æœ€å…ˆè¿›æ€§èƒ½ï¼Œæ˜¾è‘—æå‡è®­ç»ƒæ•ˆçŽ‡ï¼Œå¹¶åœ¨é‡Žå¤–åœºæ™¯ä¸­å±•ç¤ºå¼ºå¤§çš„æ³›åŒ–æ€§å’Œé²æ£’æ€§ï¼ŒéªŒè¯äº†ç»Ÿä¸€æ¡†æž¶çš„æœ‰æ•ˆæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å¯åº”ç”¨äºŽè™šæ‹ŸçŽ°å®žã€å¢žå¼ºçŽ°å®žã€äººæœºäº¤äº’å’Œè¿åŠ¨åˆ†æžç­‰é¢†åŸŸï¼Œä¸ºå®žæ—¶3Då§¿æ€ä¼°è®¡æä¾›é«˜æ•ˆè§£å†³æ–¹æ¡ˆï¼Œæå‡åœ¨å¤æ‚åœºæ™¯ä¸‹çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent approaches for monocular 3D human pose estimation (3D HPE) have achieved leading performance by directly regressing 3D poses from 2D keypoint sequences. Despite the rapid progress in 3D HPE, existing methods are typically trained and evaluated under disparate frameworks, lacking a unified framework for fair comparison. To address these limitations, we propose Fast3DHPE, a modular framework that facilitates rapid reproduction and flexible development of new methods. By standardizing training and evaluation protocols, Fast3DHPE enables fair comparison across 3D human pose estimation methods while significantly improving training efficiency. Within this framework, we introduce FastDDHPose, a Disentangled Diffusion-based 3D Human Pose Estimation method which leverages the strong latent distribution modeling capability of diffusion models to explicitly model the distributions of bone length and bone direction while avoiding further amplification of hierarchical error accumulation. Moreover, we design an efficient Kinematic-Hierarchical Spatial and Temporal Denoiser that encourages the model to focus on kinematic joint hierarchies while avoiding unnecessary modeling of overly complex joint topologies. Extensive experiments on Human3.6M and MPI-INF-3DHP show that the Fast3DHPE framework enables fair comparison of all methods while significantly improving training efficiency. Within this unified framework, FastDDHPose achieves state-of-the-art performance with strong generalization and robustness in in-the-wild scenarios. The framework and models will be released at: https://github.com/Andyen512/Fast3DHPE

