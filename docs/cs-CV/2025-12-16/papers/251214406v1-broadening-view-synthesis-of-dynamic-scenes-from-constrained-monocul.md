---
layout: default
title: Broadening View Synthesis of Dynamic Scenes from Constrained Monocular Videos
---

# Broadening View Synthesis of Dynamic Scenes from Constrained Monocular Videos

**arXiv**: [2512.14406v1](https://arxiv.org/abs/2512.14406) | [PDF](https://arxiv.org/pdf/2512.14406.pdf)

**ä½œè€…**: Le Jiang, Shaotong Zhu, Yedi Luo, Shayda Moezzi, Sarah Ostadabbas

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºExpanDyNeRFæ¡†æž¶ï¼Œåˆ©ç”¨é«˜æ–¯å…ˆéªŒå’Œä¼ªçœŸå€¼ç”Ÿæˆç­–ç•¥ï¼Œè§£å†³åŠ¨æ€NeRFåœ¨å¤§è§†è§’åç§»ä¸‹æ¸²æŸ“ä¸ç¨³å®šçš„é—®é¢˜ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `åŠ¨æ€ç¥žç»è¾å°„åœº` `æ–°è§†è§’åˆæˆ` `å•ç›®è§†é¢‘` `é«˜æ–¯å…ˆéªŒ` `ä¼ªçœŸå€¼ç”Ÿæˆ` `åˆæˆæ•°æ®é›†` `æ¸²æŸ“ä¿çœŸåº¦` `è§†è§’æ³›åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰åŠ¨æ€NeRFæ–¹æ³•åœ¨å¤§è§†è§’åç§»ä¸‹æ¸²æŸ“ä¸ç¨³å®šï¼Œå¯¼è‡´æ–°è§†è§’åˆæˆå¤±è´¥å’Œå¤±çœŸã€‚
2. ExpanDyNeRFç»“åˆé«˜æ–¯å…ˆéªŒå’Œä¼ªçœŸå€¼ç”Ÿæˆï¼Œä¼˜åŒ–ç‰¹å¾ä»¥æå‡é‡å»ºè´¨é‡ã€‚
3. åœ¨SynDMå’ŒçœŸå®žæ•°æ®é›†ä¸Šï¼ŒExpanDyNeRFåœ¨æžç«¯è§†è§’ä¸‹æ¸²æŸ“ä¿çœŸåº¦æ˜¾è‘—è¶…è¶ŠçŽ°æœ‰æ–¹æ³•ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨åŠ¨æ€ç¥žç»è¾å°„åœºï¼ˆNeRFï¼‰ç³»ç»Ÿä¸­ï¼Œå½“å‰æœ€å…ˆè¿›çš„æ–°è§†è§’åˆæˆæ–¹æ³•åœ¨æ˜¾è‘—è§†è§’åå·®ä¸‹å¸¸å¤±æ•ˆï¼Œäº§ç”Ÿä¸ç¨³å®šå’Œä¸çœŸå®žçš„æ¸²æŸ“ç»“æžœã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†æ‰©å±•åŠ¨æ€NeRFï¼ˆExpanDyNeRFï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªå•ç›®NeRFæ¡†æž¶ï¼Œåˆ©ç”¨é«˜æ–¯æº…å°„å…ˆéªŒå’Œä¼ªçœŸå€¼ç”Ÿæˆç­–ç•¥ï¼Œä»¥å®žçŽ°å¤§è§’åº¦æ—‹è½¬ä¸‹çš„çœŸå®žåˆæˆã€‚ExpanDyNeRFä¼˜åŒ–å¯†åº¦å’Œé¢œè‰²ç‰¹å¾ï¼Œä»¥æ”¹è¿›ä»ŽæŒ‘æˆ˜æ€§è§†è§’çš„åœºæ™¯é‡å»ºã€‚æˆ‘ä»¬è¿˜æå‡ºäº†åˆæˆåŠ¨æ€å¤šè§†è§’ï¼ˆSynDMï¼‰æ•°æ®é›†ï¼Œè¿™æ˜¯é¦–ä¸ªç”¨äºŽåŠ¨æ€åœºæ™¯çš„åˆæˆå¤šè§†è§’æ•°æ®é›†ï¼Œå…·æœ‰æ˜Žç¡®çš„ä¾§è§†è§’ç›‘ç£ï¼Œé€šè¿‡åŸºäºŽGTA Vçš„è‡ªå®šä¹‰æ¸²æŸ“ç®¡çº¿åˆ›å»ºã€‚åœ¨SynDMå’ŒçœŸå®žä¸–ç•Œæ•°æ®é›†ä¸Šçš„å®šé‡å’Œå®šæ€§ç»“æžœè¡¨æ˜Žï¼ŒExpanDyNeRFåœ¨æžç«¯è§†è§’åç§»ä¸‹çš„æ¸²æŸ“ä¿çœŸåº¦æ˜¾è‘—ä¼˜äºŽçŽ°æœ‰åŠ¨æ€NeRFæ–¹æ³•ã€‚æ›´å¤šç»†èŠ‚è§è¡¥å……ææ–™ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

ExpanDyNeRFæ˜¯ä¸€ä¸ªåŸºäºŽå•ç›®è§†é¢‘çš„åŠ¨æ€NeRFæ¡†æž¶ï¼Œæ•´ä½“æž¶æž„åŒ…æ‹¬é«˜æ–¯æº…å°„å…ˆéªŒæ¨¡å—å’Œä¼ªçœŸå€¼ç”Ÿæˆç­–ç•¥ã€‚å…³é”®æŠ€æœ¯åˆ›æ–°åœ¨äºŽåˆ©ç”¨é«˜æ–¯å…ˆéªŒå¢žå¼ºåœºæ™¯è¡¨ç¤ºç¨³å®šæ€§ï¼Œå¹¶é€šè¿‡ä¼ªçœŸå€¼ç”Ÿæˆæä¾›é¢å¤–ç›‘ç£ï¼Œä¼˜åŒ–å¯†åº¦å’Œé¢œè‰²ç‰¹å¾ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºŽå…¶èƒ½å¤„ç†å¤§è§’åº¦æ—‹è½¬ï¼Œé€šè¿‡å…ˆéªŒå’Œç­–ç•¥æ”¹è¿›è§†è§’æ³›åŒ–èƒ½åŠ›ï¼Œè€Œä¼ ç»ŸåŠ¨æ€NeRFå¸¸ä¾èµ–æœ‰é™è§†è§’æ•°æ®å¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨SynDMæ•°æ®é›†ä¸Šï¼ŒExpanDyNeRFåœ¨æžç«¯è§†è§’åç§»ä¸‹æ¸²æŸ“ä¿çœŸåº¦æ˜¾è‘—ä¼˜äºŽåŸºçº¿æ–¹æ³•ï¼Œå®šé‡æŒ‡æ ‡å¦‚PSNRå’ŒSSIMæœ‰æ˜¾è‘—æå‡ï¼Œå®šæ€§ç»“æžœå±•ç¤ºæ›´ç¨³å®šå’ŒçœŸå®žçš„åˆæˆæ•ˆæžœã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å¯åº”ç”¨äºŽè™šæ‹ŸçŽ°å®žã€å¢žå¼ºçŽ°å®žå’Œæœºå™¨äººå¯¼èˆªï¼Œé€šè¿‡æå‡åŠ¨æ€åœºæ™¯åœ¨æ–°è§†è§’ä¸‹çš„æ¸²æŸ“è´¨é‡ï¼Œæ”¯æŒæ›´çœŸå®žçš„æ²‰æµ¸å¼ä½“éªŒå’Œç²¾ç¡®çŽ¯å¢ƒæ„ŸçŸ¥ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In dynamic Neural Radiance Fields (NeRF) systems, state-of-the-art novel view synthesis methods often fail under significant viewpoint deviations, producing unstable and unrealistic renderings. To address this, we introduce Expanded Dynamic NeRF (ExpanDyNeRF), a monocular NeRF framework that leverages Gaussian splatting priors and a pseudo-ground-truth generation strategy to enable realistic synthesis under large-angle rotations. ExpanDyNeRF optimizes density and color features to improve scene reconstruction from challenging perspectives. We also present the Synthetic Dynamic Multiview (SynDM) dataset, the first synthetic multiview dataset for dynamic scenes with explicit side-view supervision-created using a custom GTA V-based rendering pipeline. Quantitative and qualitative results on SynDM and real-world datasets demonstrate that ExpanDyNeRF significantly outperforms existing dynamic NeRF methods in rendering fidelity under extreme viewpoint shifts. Further details are provided in the supplementary materials.

