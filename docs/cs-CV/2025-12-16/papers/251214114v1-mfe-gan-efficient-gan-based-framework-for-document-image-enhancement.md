---
layout: default
title: MFE-GAN: Efficient GAN-based Framework for Document Image Enhancement and Binarization with Multi-scale Feature Extraction
---

# MFE-GAN: Efficient GAN-based Framework for Document Image Enhancement and Binarization with Multi-scale Feature Extraction

**arXiv**: [2512.14114v1](https://arxiv.org/abs/2512.14114) | [PDF](https://arxiv.org/pdf/2512.14114.pdf)

**ä½œè€…**: Rui-Yang Ju, KokSheik Wong, Yanlin Jin, Jen-Shiun Chiang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: Extended Journal Version of APSIPA ASC 2025

**ðŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://ruiyangju.github.io/MFE-GAN)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMFE-GANæ¡†æž¶ï¼Œé€šè¿‡å¤šå°ºåº¦ç‰¹å¾æå–æå‡æ–‡æ¡£å›¾åƒå¢žå¼ºä¸ŽäºŒå€¼åŒ–æ•ˆçŽ‡ï¼Œå‡å°‘è®­ç»ƒå’ŒæŽ¨ç†æ—¶é—´ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `æ–‡æ¡£å›¾åƒå¢žå¼º` `å›¾åƒäºŒå€¼åŒ–` `ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ` `å¤šå°ºåº¦ç‰¹å¾æå–` `å“ˆå°”å°æ³¢å˜æ¢` `å…‰å­¦å­—ç¬¦è¯†åˆ«` `é«˜æ•ˆè®­ç»ƒ` `æ¨¡åž‹ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•ä½¿ç”¨å¤šä¸ªç‹¬ç«‹GANå¤„ç†ä¸åŒé¢œè‰²é€šé“ï¼Œå¯¼è‡´è®­ç»ƒå’ŒæŽ¨ç†æ—¶é—´è¿‡é•¿ï¼Œæ•ˆçŽ‡ä½Žä¸‹ã€‚
2. æå‡ºMFE-GANæ¡†æž¶ï¼Œé›†æˆå¤šå°ºåº¦ç‰¹å¾æå–ï¼ˆMFEï¼‰å’Œå“ˆå°”å°æ³¢å˜æ¢ï¼Œä¼˜åŒ–å›¾åƒé¢„å¤„ç†å’ŒGANæž¶æž„ã€‚
3. å®žéªŒæ˜¾ç¤ºMFE-GANåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæ˜¾è‘—å‡å°‘æ—¶é—´æ¶ˆè€—ï¼ŒåŒæ—¶æ€§èƒ½ä¸ŽSOTAæ–¹æ³•ç›¸å½“ï¼ŒéªŒè¯äº†å…¶é«˜æ•ˆæ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ–‡æ¡£å›¾åƒå¢žå¼ºå’ŒäºŒå€¼åŒ–é€šå¸¸åœ¨æ–‡æ¡£åˆ†æžä¸Žè¯†åˆ«ä»»åŠ¡å‰æ‰§è¡Œï¼Œä»¥æé«˜å…‰å­¦å­—ç¬¦è¯†åˆ«ï¼ˆOCRï¼‰ç³»ç»Ÿçš„æ•ˆçŽ‡å’Œå‡†ç¡®æ€§ã€‚è¿™æ˜¯å› ä¸ºç›´æŽ¥è¯†åˆ«é€€åŒ–æ–‡æ¡£ï¼ˆå°¤å…¶æ˜¯å½©è‰²å›¾åƒï¼‰ä¸­çš„æ–‡æœ¬å¾€å¾€å¯¼è‡´ä¸ç†æƒ³çš„è¯†åˆ«æ€§èƒ½ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼ŒçŽ°æœ‰æ–¹æ³•è®­ç»ƒç‹¬ç«‹çš„ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰å¤„ç†ä¸åŒé¢œè‰²é€šé“ä»¥åŽ»é™¤é˜´å½±å’Œå™ªå£°ï¼Œä»Žè€Œä¿ƒè¿›é«˜æ•ˆçš„æ–‡æœ¬ä¿¡æ¯æå–ã€‚ç„¶è€Œï¼Œéƒ¨ç½²å¤šä¸ªGANä¼šå¯¼è‡´è¾ƒé•¿çš„è®­ç»ƒå’ŒæŽ¨ç†æ—¶é—´ã€‚ä¸ºå‡å°‘æ–‡æ¡£å›¾åƒå¢žå¼ºå’ŒäºŒå€¼åŒ–æ¨¡åž‹çš„è®­ç»ƒå’ŒæŽ¨ç†æ—¶é—´ï¼Œæˆ‘ä»¬æå‡ºäº†MFE-GANï¼Œè¿™æ˜¯ä¸€ç§åŸºäºŽGANçš„é«˜æ•ˆæ¡†æž¶ï¼Œé‡‡ç”¨å¤šå°ºåº¦ç‰¹å¾æå–ï¼ˆMFEï¼‰ï¼Œç»“åˆå“ˆå°”å°æ³¢å˜æ¢ï¼ˆHWTï¼‰å’Œå½’ä¸€åŒ–å¤„ç†æ–‡æ¡£å›¾åƒï¼Œç„¶åŽè¾“å…¥GANè¿›è¡Œè®­ç»ƒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†æ–°é¢–çš„ç”Ÿæˆå™¨ã€åˆ¤åˆ«å™¨å’ŒæŸå¤±å‡½æ•°ä»¥æå‡æ¨¡åž‹æ€§èƒ½ï¼Œå¹¶é€šè¿‡æ¶ˆèžç ”ç©¶éªŒè¯å…¶æœ‰æ•ˆæ€§ã€‚åœ¨Benchmarkã€Nabucoå’ŒCMATERdbæ•°æ®é›†ä¸Šçš„å®žéªŒç»“æžœè¡¨æ˜Žï¼Œæ‰€æå‡ºçš„MFE-GANæ˜¾è‘—å‡å°‘äº†æ€»è®­ç»ƒå’ŒæŽ¨ç†æ—¶é—´ï¼ŒåŒæ—¶ä¿æŒäº†ä¸Žæœ€å…ˆè¿›ï¼ˆSOTAï¼‰æ–¹æ³•ç›¸å½“çš„æ€§èƒ½ã€‚æœ¬å·¥ä½œçš„å®žçŽ°å¯åœ¨https://ruiyangju.github.io/MFE-GANèŽ·å–ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

MFE-GANæ˜¯ä¸€ä¸ªåŸºäºŽç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰çš„é«˜æ•ˆæ¡†æž¶ï¼Œç”¨äºŽæ–‡æ¡£å›¾åƒå¢žå¼ºå’ŒäºŒå€¼åŒ–ã€‚æ•´ä½“æ¡†æž¶åŒ…æ‹¬å¤šå°ºåº¦ç‰¹å¾æå–ï¼ˆMFEï¼‰æ¨¡å—ï¼Œè¯¥æ¨¡å—åˆ©ç”¨å“ˆå°”å°æ³¢å˜æ¢ï¼ˆHWTï¼‰å’Œå½’ä¸€åŒ–å¯¹è¾“å…¥å›¾åƒè¿›è¡Œé¢„å¤„ç†ï¼Œæå–å¤šå°ºåº¦ç‰¹å¾åŽè¾“å…¥åˆ°GANä¸­è¿›è¡Œè®­ç»ƒã€‚å…³é”®æŠ€æœ¯åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼šæ–°é¢–çš„ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨è®¾è®¡ï¼Œä»¥åŠä¼˜åŒ–çš„æŸå¤±å‡½æ•°ï¼Œè¿™äº›æ”¹è¿›æå‡äº†æ¨¡åž‹å¤„ç†é€€åŒ–æ–‡æ¡£çš„èƒ½åŠ›ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºŽï¼ŒMFE-GANé€šè¿‡é›†æˆMFEæ¨¡å—é¿å…äº†ä½¿ç”¨å¤šä¸ªç‹¬ç«‹GANï¼Œä»Žè€Œå‡å°‘äº†æ¨¡åž‹å¤æ‚åº¦å’Œè®¡ç®—å¼€é”€ï¼Œå®žçŽ°äº†æ›´å¿«çš„è®­ç»ƒå’ŒæŽ¨ç†é€Ÿåº¦ï¼ŒåŒæ—¶ä¿æŒäº†å›¾åƒå¢žå¼ºå’ŒäºŒå€¼åŒ–çš„è´¨é‡ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨Benchmarkã€Nabucoå’ŒCMATERdbæ•°æ®é›†ä¸Šçš„å®žéªŒè¡¨æ˜Žï¼ŒMFE-GANæ˜¾è‘—å‡å°‘äº†æ€»è®­ç»ƒå’ŒæŽ¨ç†æ—¶é—´ï¼ŒåŒæ—¶æ€§èƒ½ä¸Žæœ€å…ˆè¿›æ–¹æ³•ç›¸å½“ï¼Œæ¶ˆèžç ”ç©¶éªŒè¯äº†å…¶æ–°é¢–ç»„ä»¶ï¼ˆå¦‚ç”Ÿæˆå™¨ã€åˆ¤åˆ«å™¨å’ŒæŸå¤±å‡½æ•°ï¼‰çš„æœ‰æ•ˆæ€§ï¼Œçªå‡ºäº†æ¡†æž¶çš„é«˜æ•ˆæ€§å’Œå®žç”¨æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶ä¸»è¦åº”ç”¨äºŽæ–‡æ¡£åˆ†æžä¸Žè¯†åˆ«é¢†åŸŸï¼Œç‰¹åˆ«æ˜¯å…‰å­¦å­—ç¬¦è¯†åˆ«ï¼ˆOCRï¼‰ç³»ç»Ÿã€‚é€šè¿‡é«˜æ•ˆå¢žå¼ºå’ŒäºŒå€¼åŒ–é€€åŒ–æ–‡æ¡£å›¾åƒï¼Œå¦‚åŽ»é™¤é˜´å½±å’Œå™ªå£°ï¼Œå¯ä»¥æå‡OCRçš„å‡†ç¡®æ€§å’Œæ•ˆçŽ‡ï¼Œé€‚ç”¨äºŽæ•°å­—åŒ–æ¡£æ¡ˆå¤„ç†ã€åŽ†å²æ–‡æ¡£ä¿®å¤ã€è‡ªåŠ¨åŒ–åŠžå…¬ç­‰å®žé™…åœºæ™¯ï¼Œå…·æœ‰é‡è¦çš„å·¥ä¸šåº”ç”¨ä»·å€¼ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Document image enhancement and binarization are commonly performed prior to document analysis and recognition tasks for improving the efficiency and accuracy of optical character recognition (OCR) systems. This is because directly recognizing text in degraded documents, particularly in color images, often results in unsatisfactory recognition performance. To address these issues, existing methods train independent generative adversarial networks (GANs) for different color channels to remove shadows and noise, which, in turn, facilitates efficient text information extraction. However, deploying multiple GANs results in long training and inference times. To reduce both training and inference times of document image enhancement and binarization models, we propose MFE-GAN, an efficient GAN-based framework with multi-scale feature extraction (MFE), which incorporates Haar wavelet transformation (HWT) and normalization to process document images before feeding them into GANs for training. In addition, we present novel generators, discriminators, and loss functions to improve the model's performance, and we conduct ablation studies to demonstrate their effectiveness. Experimental results on the Benchmark, Nabuco, and CMATERdb datasets demonstrate that the proposed MFE-GAN significantly reduces the total training and inference times while maintaining comparable performance with respect to state-of-the-art (SOTA) methods. The implementation of this work is available at https://ruiyangju.github.io/MFE-GAN.

