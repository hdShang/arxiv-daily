---
layout: default
title: MFE-GAN: Efficient GAN-based Framework for Document Image Enhancement and Binarization with Multi-scale Feature Extraction
---

# MFE-GAN: Efficient GAN-based Framework for Document Image Enhancement and Binarization with Multi-scale Feature Extraction

**arXiv**: [2512.14114v1](https://arxiv.org/abs/2512.14114) | [PDF](https://arxiv.org/pdf/2512.14114.pdf)

**ä½œè€…**: Rui-Yang Ju, KokSheik Wong, Yanlin Jin, Jen-Shiun Chiang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: Extended Journal Version of APSIPA ASC 2025

**ðŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://ruiyangju.github.io/MFE-GAN)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMFE-GANæ¡†æž¶ï¼Œé€šè¿‡å¤šå°ºåº¦ç‰¹å¾æå–å’ŒHaarå°æ³¢å˜æ¢ï¼Œé«˜æ•ˆè§£å†³æ–‡æ¡£å›¾åƒå¢žå¼ºä¸ŽäºŒå€¼åŒ–ä¸­çš„è®­ç»ƒå’ŒæŽ¨ç†æ—¶é—´é—®é¢˜ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `æ–‡æ¡£å›¾åƒå¢žå¼º` `å›¾åƒäºŒå€¼åŒ–` `ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ` `å¤šå°ºåº¦ç‰¹å¾æå–` `Haarå°æ³¢å˜æ¢` `å…‰å­¦å­—ç¬¦è¯†åˆ«` `é«˜æ•ˆè®­ç»ƒ` `æ¶ˆèžç ”ç©¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•ä½¿ç”¨å¤šä¸ªç‹¬ç«‹GANå¤„ç†ä¸åŒé¢œè‰²é€šé“ï¼Œå¯¼è‡´è®­ç»ƒå’ŒæŽ¨ç†æ—¶é—´è¿‡é•¿ï¼Œæ•ˆçŽ‡ä½Žä¸‹ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæå‡ºMFE-GANæ¡†æž¶ï¼Œé›†æˆå¤šå°ºåº¦ç‰¹å¾æå–å’ŒHaarå°æ³¢å˜æ¢ï¼Œä¼˜åŒ–å›¾åƒé¢„å¤„ç†ï¼Œå‡å°‘æ¨¡åž‹å¤æ‚åº¦ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªæ•°æ®é›†ä¸ŠéªŒè¯ï¼ŒMFE-GANæ˜¾è‘—é™ä½Žæ—¶é—´æˆæœ¬ï¼ŒåŒæ—¶æ€§èƒ½ä¸ŽSOTAæ–¹æ³•ç›¸å½“ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ–‡æ¡£å›¾åƒå¢žå¼ºå’ŒäºŒå€¼åŒ–é€šå¸¸åœ¨æ–‡æ¡£åˆ†æžå’Œè¯†åˆ«ä»»åŠ¡ä¹‹å‰è¿›è¡Œï¼Œä»¥æé«˜å…‰å­¦å­—ç¬¦è¯†åˆ«ï¼ˆOCRï¼‰ç³»ç»Ÿçš„æ•ˆçŽ‡å’Œå‡†ç¡®æ€§ã€‚è¿™æ˜¯å› ä¸ºç›´æŽ¥è¯†åˆ«é€€åŒ–æ–‡æ¡£ï¼ˆå°¤å…¶æ˜¯å½©è‰²å›¾åƒï¼‰ä¸­çš„æ–‡æœ¬å¾€å¾€å¯¼è‡´ä¸ç†æƒ³çš„è¯†åˆ«æ€§èƒ½ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼ŒçŽ°æœ‰æ–¹æ³•è®­ç»ƒç‹¬ç«‹çš„ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰ç”¨äºŽä¸åŒé¢œè‰²é€šé“ï¼Œä»¥åŽ»é™¤é˜´å½±å’Œå™ªå£°ï¼Œä»Žè€Œä¿ƒè¿›é«˜æ•ˆçš„æ–‡æœ¬ä¿¡æ¯æå–ã€‚ç„¶è€Œï¼Œéƒ¨ç½²å¤šä¸ªGANä¼šå¯¼è‡´è®­ç»ƒå’ŒæŽ¨ç†æ—¶é—´è¾ƒé•¿ã€‚ä¸ºå‡å°‘æ–‡æ¡£å›¾åƒå¢žå¼ºå’ŒäºŒå€¼åŒ–æ¨¡åž‹çš„è®­ç»ƒå’ŒæŽ¨ç†æ—¶é—´ï¼Œæˆ‘ä»¬æå‡ºäº†MFE-GANï¼Œè¿™æ˜¯ä¸€ç§åŸºäºŽGANçš„é«˜æ•ˆæ¡†æž¶ï¼Œå…·æœ‰å¤šå°ºåº¦ç‰¹å¾æå–ï¼ˆMFEï¼‰ï¼Œå®ƒç»“åˆäº†Haarå°æ³¢å˜æ¢ï¼ˆHWTï¼‰å’Œå½’ä¸€åŒ–ï¼Œåœ¨å°†æ–‡æ¡£å›¾åƒè¾“å…¥GANè¿›è¡Œè®­ç»ƒä¹‹å‰è¿›è¡Œå¤„ç†ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†æ–°é¢–çš„ç”Ÿæˆå™¨ã€åˆ¤åˆ«å™¨å’ŒæŸå¤±å‡½æ•°ä»¥æé«˜æ¨¡åž‹æ€§èƒ½ï¼Œå¹¶è¿›è¡Œäº†æ¶ˆèžç ”ç©¶ä»¥è¯æ˜Žå…¶æœ‰æ•ˆæ€§ã€‚åœ¨Benchmarkã€Nabucoå’ŒCMATERdbæ•°æ®é›†ä¸Šçš„å®žéªŒç»“æžœè¡¨æ˜Žï¼Œæ‰€æå‡ºçš„MFE-GANæ˜¾è‘—å‡å°‘äº†æ€»è®­ç»ƒå’ŒæŽ¨ç†æ—¶é—´ï¼ŒåŒæ—¶ä¿æŒäº†ä¸Žæœ€å…ˆè¿›ï¼ˆSOTAï¼‰æ–¹æ³•ç›¸å½“çš„æ€§èƒ½ã€‚æœ¬å·¥ä½œçš„å®žçŽ°å¯åœ¨https://ruiyangju.github.io/MFE-GANèŽ·å–ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æ–‡æ¡£å›¾åƒå¢žå¼ºå’ŒäºŒå€¼åŒ–ä»»åŠ¡ä¸­ï¼ŒçŽ°æœ‰åŸºäºŽGANçš„æ–¹æ³•å› ä½¿ç”¨å¤šä¸ªç‹¬ç«‹ç½‘ç»œå¤„ç†ä¸åŒé¢œè‰²é€šé“è€Œå¯¼è‡´çš„è®­ç»ƒå’ŒæŽ¨ç†æ—¶é—´è¿‡é•¿é—®é¢˜ã€‚è¿™é™åˆ¶äº†å®žé™…éƒ¨ç½²çš„æ•ˆçŽ‡ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†å¤§è§„æ¨¡æˆ–å®žæ—¶æ–‡æ¡£æ—¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼•å…¥å¤šå°ºåº¦ç‰¹å¾æå–ï¼ˆMFEï¼‰å’ŒHaarå°æ³¢å˜æ¢ï¼ˆHWTï¼‰ï¼Œåœ¨GANè®­ç»ƒå‰å¯¹æ–‡æ¡£å›¾åƒè¿›è¡Œé¢„å¤„ç†ï¼Œä»Žè€Œå‡å°‘æ¨¡åž‹å¤æ‚åº¦å¹¶åŠ é€Ÿå¤„ç†ã€‚è¿™æ ·è®¾è®¡æ˜¯å› ä¸ºå¤šå°ºåº¦ç‰¹å¾èƒ½æ›´å¥½åœ°æ•æ‰å›¾åƒç»†èŠ‚ï¼Œè€Œå°æ³¢å˜æ¢æœ‰åŠ©äºŽåˆ†ç¦»å™ªå£°å’Œé˜´å½±ï¼Œä½¿å¾—åŽç»­GANæ›´é«˜æ•ˆåœ°å­¦ä¹ ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æ¡†æž¶åŒ…æ‹¬é¢„å¤„ç†ã€ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨ä¸‰é˜¶æ®µã€‚é¢„å¤„ç†é˜¶æ®µä½¿ç”¨Haarå°æ³¢å˜æ¢å’Œå½’ä¸€åŒ–å¤„ç†è¾“å…¥å›¾åƒï¼Œæå–å¤šå°ºåº¦ç‰¹å¾ï¼›ç”Ÿæˆå™¨åŸºäºŽè¿™äº›ç‰¹å¾ç”Ÿæˆå¢žå¼ºå’ŒäºŒå€¼åŒ–å›¾åƒï¼›åˆ¤åˆ«å™¨è¯„ä¼°ç”Ÿæˆå›¾åƒçš„çœŸå®žæ€§ã€‚æ¡†æž¶é€šè¿‡ç«¯åˆ°ç«¯è®­ç»ƒä¼˜åŒ–æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°æ˜¯é›†æˆå¤šå°ºåº¦ç‰¹å¾æå–å’ŒHaarå°æ³¢å˜æ¢åˆ°GANæ¡†æž¶ä¸­ï¼Œé¿å…äº†å¤šä¸ªç‹¬ç«‹GANçš„ä½¿ç”¨ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºŽï¼Œå®ƒé€šè¿‡é¢„å¤„ç†æ­¥éª¤ç»Ÿä¸€å¤„ç†å›¾åƒï¼Œå‡å°‘äº†æ¨¡åž‹å‚æ•°å’Œè®¡ç®—å¼€é”€ï¼Œä»Žè€Œæ˜¾è‘—æå‡æ•ˆçŽ‡ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼šä½¿ç”¨Haarå°æ³¢å˜æ¢è¿›è¡Œå›¾åƒåˆ†è§£ï¼Œç”Ÿæˆå¤šå°ºåº¦ç‰¹å¾å›¾ï¼›è®¾è®¡æ–°é¢–çš„ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨ç½‘ç»œç»“æž„ï¼Œå¯èƒ½åŸºäºŽå·ç§¯ç¥žç»ç½‘ç»œï¼ˆCNNï¼‰æˆ–ç±»ä¼¼æž¶æž„ï¼›æŸå¤±å‡½æ•°ç»“åˆå¯¹æŠ—æŸå¤±ã€å†…å®¹æŸå¤±ï¼ˆå¦‚L1æˆ–L2æŸå¤±ï¼‰å’Œå¯èƒ½çš„æ„ŸçŸ¥æŸå¤±ï¼Œä»¥å¹³è¡¡å›¾åƒè´¨é‡å’ŒäºŒå€¼åŒ–å‡†ç¡®æ€§ï¼›å‚æ•°è®¾ç½®å¦‚å­¦ä¹ çŽ‡ã€æ‰¹é‡å¤§å°ç­‰é€šè¿‡å®žéªŒä¼˜åŒ–ï¼Œå…·ä½“æ•°å€¼æœªåœ¨æ‘˜è¦ä¸­æä¾›ï¼Œä½†æ¶ˆèžç ”ç©¶éªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒåœ¨Benchmarkã€Nabucoå’ŒCMATERdbæ•°æ®é›†ä¸Šè¿›è¡Œï¼Œç»“æžœæ˜¾ç¤ºMFE-GANæ˜¾è‘—å‡å°‘äº†æ€»è®­ç»ƒå’ŒæŽ¨ç†æ—¶é—´ï¼Œå…·ä½“æå‡å¹…åº¦æœªåœ¨æ‘˜è¦ä¸­é‡åŒ–ï¼Œä½†å¼ºè°ƒä¸Žæœ€å…ˆè¿›ï¼ˆSOTAï¼‰æ–¹æ³•æ€§èƒ½ç›¸å½“ã€‚æ¶ˆèžç ”ç©¶è¯æ˜Žäº†å¤šå°ºåº¦ç‰¹å¾æå–å’ŒHaarå°æ³¢å˜æ¢çš„æœ‰æ•ˆæ€§ï¼ŒéªŒè¯äº†æ¡†æž¶åœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶ä¼˜åŒ–æ•ˆçŽ‡çš„ä¼˜åŠ¿ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶ä¸»è¦åº”ç”¨äºŽæ–‡æ¡£åˆ†æžå’Œå…‰å­¦å­—ç¬¦è¯†åˆ«ï¼ˆOCRï¼‰é¢†åŸŸï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†é€€åŒ–æ–‡æ¡£ï¼ˆå¦‚æ‰«æä»¶ã€åŽ†å²æ¡£æ¡ˆæˆ–ä½Žè´¨é‡å›¾åƒï¼‰æ—¶ã€‚å…¶å®žé™…ä»·å€¼åœ¨äºŽé€šè¿‡é«˜æ•ˆå¢žå¼ºå’ŒäºŒå€¼åŒ–ï¼Œæå‡OCRç³»ç»Ÿçš„å‡†ç¡®æ€§å’Œé€Ÿåº¦ï¼Œé€‚ç”¨äºŽæ•°å­—åŒ–å›¾ä¹¦é¦†ã€è‡ªåŠ¨åŒ–åŠžå…¬ã€æ¡£æ¡ˆç®¡ç†ç­‰åœºæ™¯ã€‚æœªæ¥å¯èƒ½æ‰©å±•åˆ°å…¶ä»–å›¾åƒå¤„ç†ä»»åŠ¡ï¼Œå¦‚åŒ»å­¦å›¾åƒå¢žå¼ºæˆ–è§†é¢‘æ–‡æœ¬è¯†åˆ«ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Document image enhancement and binarization are commonly performed prior to document analysis and recognition tasks for improving the efficiency and accuracy of optical character recognition (OCR) systems. This is because directly recognizing text in degraded documents, particularly in color images, often results in unsatisfactory recognition performance. To address these issues, existing methods train independent generative adversarial networks (GANs) for different color channels to remove shadows and noise, which, in turn, facilitates efficient text information extraction. However, deploying multiple GANs results in long training and inference times. To reduce both training and inference times of document image enhancement and binarization models, we propose MFE-GAN, an efficient GAN-based framework with multi-scale feature extraction (MFE), which incorporates Haar wavelet transformation (HWT) and normalization to process document images before feeding them into GANs for training. In addition, we present novel generators, discriminators, and loss functions to improve the model's performance, and we conduct ablation studies to demonstrate their effectiveness. Experimental results on the Benchmark, Nabuco, and CMATERdb datasets demonstrate that the proposed MFE-GAN significantly reduces the total training and inference times while maintaining comparable performance with respect to state-of-the-art (SOTA) methods. The implementation of this work is available at https://ruiyangju.github.io/MFE-GAN.

