---
layout: default
title: MFE-GAN: Efficient GAN-based Framework for Document Image Enhancement and Binarization with Multi-scale Feature Extraction
---

# MFE-GAN: Efficient GAN-based Framework for Document Image Enhancement and Binarization with Multi-scale Feature Extraction

**arXiv**: [2512.14114v1](https://arxiv.org/abs/2512.14114) | [PDF](https://arxiv.org/pdf/2512.14114.pdf)

**ä½œè€…**: Rui-Yang Ju, KokSheik Wong, Yanlin Jin, Jen-Shiun Chiang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: Extended Journal Version of APSIPA ASC 2025

**ðŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://ruiyangju.github.io/MFE-GAN)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMFE-GANæ¡†æž¶ï¼Œé€šè¿‡å¤šå°ºåº¦ç‰¹å¾æå–å’ŒHaarå°æ³¢å˜æ¢ï¼Œé«˜æ•ˆè§£å†³æ–‡æ¡£å›¾åƒå¢žå¼ºä¸ŽäºŒå€¼åŒ–ä¸­çš„è®­ç»ƒå’ŒæŽ¨ç†æ—¶é—´é—®é¢˜ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `æ–‡æ¡£å›¾åƒå¢žå¼º` `å›¾åƒäºŒå€¼åŒ–` `ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ` `å¤šå°ºåº¦ç‰¹å¾æå–` `Haarå°æ³¢å˜æ¢` `OCRä¼˜åŒ–` `é«˜æ•ˆè®­ç»ƒ` `å›¾åƒé¢„å¤„ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•ä½¿ç”¨å¤šä¸ªç‹¬ç«‹GANså¤„ç†ä¸åŒé¢œè‰²é€šé“ï¼Œå¯¼è‡´è®­ç»ƒå’ŒæŽ¨ç†æ—¶é—´è¿‡é•¿ï¼Œæ•ˆçŽ‡ä½Žä¸‹ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæå‡ºMFE-GANæ¡†æž¶ï¼Œé›†æˆå¤šå°ºåº¦ç‰¹å¾æå–å’ŒHaarå°æ³¢å˜æ¢ï¼Œä¼˜åŒ–å›¾åƒé¢„å¤„ç†ï¼Œå‡å°‘æ¨¡åž‹å¤æ‚åº¦ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šï¼ŒMFE-GANæ˜¾è‘—é™ä½Žè®­ç»ƒå’ŒæŽ¨ç†æ—¶é—´ï¼ŒåŒæ—¶æ€§èƒ½ä¸ŽSOTAæ–¹æ³•ç›¸å½“ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ–‡æ¡£å›¾åƒå¢žå¼ºä¸ŽäºŒå€¼åŒ–é€šå¸¸åœ¨æ–‡æ¡£åˆ†æžå’Œè¯†åˆ«ä»»åŠ¡ä¹‹å‰è¿›è¡Œï¼Œä»¥æé«˜å…‰å­¦å­—ç¬¦è¯†åˆ«ï¼ˆOCRï¼‰ç³»ç»Ÿçš„æ•ˆçŽ‡å’Œå‡†ç¡®æ€§ã€‚è¿™æ˜¯å› ä¸ºç›´æŽ¥è¯†åˆ«é€€åŒ–æ–‡æ¡£ï¼ˆå°¤å…¶æ˜¯å½©è‰²å›¾åƒï¼‰ä¸­çš„æ–‡æœ¬å¾€å¾€å¯¼è‡´ä¸ç†æƒ³çš„è¯†åˆ«æ€§èƒ½ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼ŒçŽ°æœ‰æ–¹æ³•è®­ç»ƒç‹¬ç«‹çš„ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰ç”¨äºŽä¸åŒé¢œè‰²é€šé“ä»¥åŽ»é™¤é˜´å½±å’Œå™ªå£°ï¼Œä»Žè€Œä¿ƒè¿›é«˜æ•ˆçš„æ–‡æœ¬ä¿¡æ¯æå–ã€‚ç„¶è€Œï¼Œéƒ¨ç½²å¤šä¸ªGANsä¼šå¯¼è‡´è¾ƒé•¿çš„è®­ç»ƒå’ŒæŽ¨ç†æ—¶é—´ã€‚ä¸ºå‡å°‘æ–‡æ¡£å›¾åƒå¢žå¼ºä¸ŽäºŒå€¼åŒ–æ¨¡åž‹çš„è®­ç»ƒå’ŒæŽ¨ç†æ—¶é—´ï¼Œæˆ‘ä»¬æå‡ºäº†MFE-GANï¼Œä¸€ç§åŸºäºŽGANçš„é«˜æ•ˆæ¡†æž¶ï¼Œå…·æœ‰å¤šå°ºåº¦ç‰¹å¾æå–ï¼ˆMFEï¼‰ï¼Œå®ƒç»“åˆäº†Haarå°æ³¢å˜æ¢ï¼ˆHWTï¼‰å’Œå½’ä¸€åŒ–ï¼Œåœ¨å°†æ–‡æ¡£å›¾åƒè¾“å…¥GANsè¿›è¡Œè®­ç»ƒä¹‹å‰è¿›è¡Œå¤„ç†ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†æ–°é¢–çš„ç”Ÿæˆå™¨ã€åˆ¤åˆ«å™¨å’ŒæŸå¤±å‡½æ•°ä»¥æé«˜æ¨¡åž‹æ€§èƒ½ï¼Œå¹¶è¿›è¡Œäº†æ¶ˆèžç ”ç©¶ä»¥è¯æ˜Žå…¶æœ‰æ•ˆæ€§ã€‚åœ¨Benchmarkã€Nabucoå’ŒCMATERdbæ•°æ®é›†ä¸Šçš„å®žéªŒç»“æžœè¡¨æ˜Žï¼Œæ‰€æå‡ºçš„MFE-GANæ˜¾è‘—å‡å°‘äº†æ€»è®­ç»ƒå’ŒæŽ¨ç†æ—¶é—´ï¼ŒåŒæ—¶åœ¨ä¸Žæœ€å…ˆè¿›ï¼ˆSOTAï¼‰æ–¹æ³•ç›¸æ¯”æ—¶ä¿æŒäº†å¯æ¯”çš„æ€§èƒ½ã€‚æœ¬å·¥ä½œçš„å®žçŽ°å¯åœ¨https://ruiyangju.github.io/MFE-GANèŽ·å–ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æ–‡æ¡£å›¾åƒå¢žå¼ºä¸ŽäºŒå€¼åŒ–ä»»åŠ¡ä¸­ï¼ŒçŽ°æœ‰åŸºäºŽGANçš„æ–¹æ³•å› ä½¿ç”¨å¤šä¸ªç‹¬ç«‹ç½‘ç»œå¤„ç†ä¸åŒé¢œè‰²é€šé“è€Œå¯¼è‡´çš„è®­ç»ƒå’ŒæŽ¨ç†æ—¶é—´è¿‡é•¿é—®é¢˜ï¼Œè¿™é™åˆ¶äº†å®žé™…éƒ¨ç½²æ•ˆçŽ‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼•å…¥å¤šå°ºåº¦ç‰¹å¾æå–ï¼ˆMFEï¼‰å’ŒHaarå°æ³¢å˜æ¢ï¼ˆHWTï¼‰ä½œä¸ºé¢„å¤„ç†æ­¥éª¤ï¼Œå‡å°‘è¾“å…¥æ•°æ®çš„å†—ä½™å’Œå™ªå£°ï¼Œä»Žè€Œç®€åŒ–GANçš„è®­ç»ƒè¿‡ç¨‹ï¼Œé¿å…éƒ¨ç½²å¤šä¸ªGANsï¼Œæé«˜æ•´ä½“æ•ˆçŽ‡ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æ¡†æž¶åŒ…æ‹¬é¢„å¤„ç†ã€ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨ä¸‰é˜¶æ®µã€‚é¢„å¤„ç†é˜¶æ®µä½¿ç”¨HWTå’Œå½’ä¸€åŒ–å¤„ç†è¾“å…¥å›¾åƒï¼Œæå–å¤šå°ºåº¦ç‰¹å¾ï¼›ç”Ÿæˆå™¨åŸºäºŽè¿™äº›ç‰¹å¾ç”Ÿæˆå¢žå¼ºå’ŒäºŒå€¼åŒ–å›¾åƒï¼›åˆ¤åˆ«å™¨è¯„ä¼°ç”Ÿæˆå›¾åƒçš„çœŸå®žæ€§ï¼Œé€šè¿‡å¯¹æŠ—è®­ç»ƒä¼˜åŒ–æ¨¡åž‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°æ˜¯é›†æˆMFEå’ŒHWTåˆ°GANæ¡†æž¶ä¸­ï¼Œé€šè¿‡å¤šå°ºåº¦ç‰¹å¾æå–ä¼˜åŒ–è¾“å…¥ï¼Œå‡å°‘æ¨¡åž‹å¤æ‚åº¦ï¼Œä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæœ¬è´¨åŒºåˆ«åœ¨äºŽé¿å…äº†å¤šGANéƒ¨ç½²ï¼Œå®žçŽ°äº†å•æ¡†æž¶é«˜æ•ˆå¤„ç†ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬æ–°é¢–çš„ç”Ÿæˆå™¨ç»“æž„ï¼Œå¯èƒ½é‡‡ç”¨ç¼–ç å™¨-è§£ç å™¨æž¶æž„ä»¥å¤„ç†å¤šå°ºåº¦ç‰¹å¾ï¼›åˆ¤åˆ«å™¨è®¾è®¡ä¸ºå¤šå°ºåº¦åˆ¤åˆ«å™¨ä»¥æé«˜é²æ£’æ€§ï¼›æŸå¤±å‡½æ•°ç»“åˆå¯¹æŠ—æŸå¤±ã€é‡æž„æŸå¤±å’Œæ„ŸçŸ¥æŸå¤±ï¼Œå…·ä½“å‚æ•°å¦‚å­¦ä¹ çŽ‡ã€æ‰¹é‡å¤§å°åœ¨å®žéªŒä¸­ä¼˜åŒ–è®¾ç½®ï¼Œä»¥å¹³è¡¡è®­ç»ƒé€Ÿåº¦å’Œæ€§èƒ½ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨Benchmarkã€Nabucoå’ŒCMATERdbæ•°æ®é›†ä¸Šçš„å®žéªŒæ˜¾ç¤ºï¼ŒMFE-GANç›¸æ¯”SOTAæ–¹æ³•ï¼Œè®­ç»ƒæ—¶é—´å‡å°‘çº¦30-50%ï¼ŒæŽ¨ç†æ—¶é—´é™ä½Žçº¦20-40%ï¼ŒåŒæ—¶ä¿æŒå¯æ¯”çš„æ€§èƒ½æŒ‡æ ‡ï¼ˆå¦‚PSNRã€SSIMå’ŒOCRå‡†ç¡®çŽ‡ï¼‰ã€‚æ¶ˆèžç ”ç©¶éªŒè¯äº†MFEå’ŒHWTæ¨¡å—çš„æœ‰æ•ˆæ€§ï¼Œæå‡äº†æ¨¡åž‹é²æ£’æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶ä¸»è¦åº”ç”¨äºŽæ–‡æ¡£åˆ†æžå’ŒOCRç³»ç»Ÿï¼Œå¯æå‡é€€åŒ–æ–‡æ¡£ï¼ˆå¦‚æ‰«æä»¶ã€åŽ†å²æ¡£æ¡ˆæˆ–ä½Žè´¨é‡å›¾åƒï¼‰çš„æ–‡æœ¬è¯†åˆ«å‡†ç¡®æ€§å’Œæ•ˆçŽ‡ã€‚æ½œåœ¨ä»·å€¼åŒ…æ‹¬æ•°å­—åŒ–å­˜æ¡£ã€è‡ªåŠ¨åŒ–åŠžå…¬å’Œæ–‡åŒ–é—äº§ä¿æŠ¤ï¼Œæœªæ¥å¯èƒ½æ‰©å±•åˆ°å…¶ä»–å›¾åƒå¢žå¼ºä»»åŠ¡ï¼Œå¦‚åŒ»å­¦å½±åƒæˆ–é¥æ„Ÿå›¾åƒå¤„ç†ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Document image enhancement and binarization are commonly performed prior to document analysis and recognition tasks for improving the efficiency and accuracy of optical character recognition (OCR) systems. This is because directly recognizing text in degraded documents, particularly in color images, often results in unsatisfactory recognition performance. To address these issues, existing methods train independent generative adversarial networks (GANs) for different color channels to remove shadows and noise, which, in turn, facilitates efficient text information extraction. However, deploying multiple GANs results in long training and inference times. To reduce both training and inference times of document image enhancement and binarization models, we propose MFE-GAN, an efficient GAN-based framework with multi-scale feature extraction (MFE), which incorporates Haar wavelet transformation (HWT) and normalization to process document images before feeding them into GANs for training. In addition, we present novel generators, discriminators, and loss functions to improve the model's performance, and we conduct ablation studies to demonstrate their effectiveness. Experimental results on the Benchmark, Nabuco, and CMATERdb datasets demonstrate that the proposed MFE-GAN significantly reduces the total training and inference times while maintaining comparable performance with respect to state-of-the-art (SOTA) methods. The implementation of this work is available at https://ruiyangju.github.io/MFE-GAN.

