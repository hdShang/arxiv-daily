---
layout: default
title: S2D: Sparse-To-Dense Keymask Distillation for Unsupervised Video Instance Segmentation
---

# S2D: Sparse-To-Dense Keymask Distillation for Unsupervised Video Instance Segmentation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.14440" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.14440</a>
  <a href="https://arxiv.org/pdf/2512.14440.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14440" onclick="toggleFavorite(this, '2512.14440', 'S2D: Sparse-To-Dense Keymask Distillation for Unsupervised Video Instance Segmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Leon Sick, Lukas Hoyer, Dominik Engel, Pedro Hermosilla, Timo Ropinski

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-18

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºS2Dï¼šä¸€ç§ç¨€ç–åˆ°ç¨ å¯†çš„Keymaskè’¸é¦æ–¹æ³•ï¼Œç”¨äºæ— ç›‘ç£è§†é¢‘å®ä¾‹åˆ†å‰²ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æ— ç›‘ç£å­¦ä¹ ` `è§†é¢‘å®ä¾‹åˆ†å‰²` `ç¨€ç–åˆ°ç¨ å¯†` `Keymaskè’¸é¦` `è¿åŠ¨å…ˆéªŒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ— ç›‘ç£è§†é¢‘å®ä¾‹åˆ†å‰²æ–¹æ³•ä¾èµ–åˆæˆæ•°æ®ï¼Œæ— æ³•å‡†ç¡®æ¨¡æ‹ŸçœŸå®è§†é¢‘ä¸­çš„å¤æ‚è¿åŠ¨ã€‚
2. è¯¥è®ºæ–‡æå‡ºä¸€ç§åŸºäºçœŸå®è§†é¢‘æ•°æ®çš„ç¨€ç–åˆ°ç¨ å¯†Keymaskè’¸é¦æ–¹æ³•ï¼Œæå‡åˆ†å‰²è´¨é‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†å½“å‰æœ€å…ˆè¿›çš„æ— ç›‘ç£è§†é¢‘å®ä¾‹åˆ†å‰²æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œæ— ç›‘ç£è§†é¢‘å®ä¾‹åˆ†å‰²é¢†åŸŸçš„æœ€å…ˆè¿›æ–¹æ³•ä¸¥é‡ä¾èµ–äºåˆæˆè§†é¢‘æ•°æ®ï¼Œè¿™äº›æ•°æ®é€šå¸¸ç”±ImageNetç­‰ä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„å›¾åƒæ•°æ®é›†ç”Ÿæˆã€‚ç„¶è€Œï¼Œé€šè¿‡äººä¸ºåœ°ç§»åŠ¨å’Œç¼©æ”¾å›¾åƒå®ä¾‹æ©ç æ¥åˆæˆè§†é¢‘ï¼Œæ— æ³•å‡†ç¡®åœ°æ¨¡æ‹Ÿè§†é¢‘ä¸­çœŸå®çš„è¿åŠ¨ï¼Œä¾‹å¦‚é€è§†å˜åŒ–ã€å•ä¸ªæˆ–å¤šä¸ªå®ä¾‹çš„éƒ¨åˆ†è¿åŠ¨æˆ–ç›¸æœºè¿åŠ¨ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å®Œå…¨åœ¨çœŸå®è§†é¢‘æ•°æ®ä¸Šè®­ç»ƒçš„æ— ç›‘ç£è§†é¢‘å®ä¾‹åˆ†å‰²æ¨¡å‹ã€‚æˆ‘ä»¬ä»å•ä¸ªè§†é¢‘å¸§ä¸Šçš„æ— ç›‘ç£å®ä¾‹åˆ†å‰²æ©ç å¼€å§‹ã€‚ç„¶è€Œï¼Œè¿™äº›å•å¸§åˆ†å‰²è¡¨ç°å‡ºæ—¶é—´å™ªå£°ï¼Œå¹¶ä¸”å…¶è´¨é‡åœ¨æ•´ä¸ªè§†é¢‘ä¸­å˜åŒ–ã€‚å› æ­¤ï¼Œæˆ‘ä»¬é€šè¿‡åˆ©ç”¨æ·±åº¦è¿åŠ¨å…ˆéªŒæ¥è¯†åˆ«è§†é¢‘ä¸­çš„é«˜è´¨é‡Keymaskï¼Œä»è€Œå»ºç«‹æ—¶é—´ä¸€è‡´æ€§ã€‚ç„¶åï¼Œç¨€ç–çš„Keymaskä¼ªæ³¨é‡Šç”¨äºè®­ç»ƒåˆ†å‰²æ¨¡å‹ä»¥è¿›è¡Œéšå¼æ©ç ä¼ æ’­ï¼Œä¸ºæ­¤æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”±Temporal DropLossè¾…åŠ©çš„ç¨€ç–åˆ°ç¨ å¯†çš„è’¸é¦æ–¹æ³•ã€‚åœ¨æœ€ç»ˆæ¨¡å‹åœ¨ç”Ÿæˆçš„ç¨ å¯†æ ‡ç­¾é›†ä¸Šè®­ç»ƒåï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å„ç§åŸºå‡†æµ‹è¯•ä¸­ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæ— ç›‘ç£è§†é¢‘å®ä¾‹åˆ†å‰²æ—¨åœ¨æ— éœ€äººå·¥æ ‡æ³¨çš„æƒ…å†µä¸‹ï¼Œå¯¹è§†é¢‘ä¸­çš„æ¯ä¸ªå®ä¾‹è¿›è¡Œåˆ†å‰²å’Œè·Ÿè¸ªã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºåˆæˆæ•°æ®ï¼Œä½†åˆæˆæ•°æ®éš¾ä»¥æ¨¡æ‹ŸçœŸå®è§†é¢‘ä¸­çš„å¤æ‚è¿åŠ¨ï¼Œå¯¼è‡´æ¨¡å‹æ³›åŒ–èƒ½åŠ›å·®ã€‚æ­¤å¤–ï¼Œç›´æ¥åœ¨çœŸå®è§†é¢‘ä¸Šè¿›è¡Œæ— ç›‘ç£å­¦ä¹ ï¼Œå•å¸§åˆ†å‰²ç»“æœå­˜åœ¨æ—¶é—´å™ªå£°ï¼Œè´¨é‡ä¸ç¨³å®šã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè¯¥è®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è§†é¢‘ä¸­çš„è¿åŠ¨å…ˆéªŒçŸ¥è¯†ï¼Œä»å•å¸§åˆ†å‰²ç»“æœä¸­æå–é«˜è´¨é‡çš„Keymaskï¼Œä½œä¸ºç¨€ç–çš„ä¼ªæ ‡ç­¾ã€‚ç„¶åï¼Œé€šè¿‡ç¨€ç–åˆ°ç¨ å¯†çš„è’¸é¦æ–¹æ³•ï¼Œå°†è¿™äº›Keymaskä¿¡æ¯ä¼ æ’­åˆ°æ•´ä¸ªè§†é¢‘åºåˆ—ï¼Œç”Ÿæˆç¨ å¯†çš„ä¼ªæ ‡ç­¾ï¼Œä»è€Œè®­ç»ƒä¸€ä¸ªæ›´é²æ£’çš„åˆ†å‰²æ¨¡å‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) å•å¸§æ— ç›‘ç£å®ä¾‹åˆ†å‰²ï¼šä½¿ç”¨ç°æœ‰çš„æ— ç›‘ç£å›¾åƒå®ä¾‹åˆ†å‰²æ–¹æ³•å¯¹è§†é¢‘çš„æ¯ä¸€å¸§è¿›è¡Œåˆ†å‰²ã€‚2) Keymaské€‰æ‹©ï¼šåˆ©ç”¨æ·±åº¦è¿åŠ¨å…ˆéªŒï¼Œä¾‹å¦‚å…‰æµï¼Œé€‰æ‹©è§†é¢‘ä¸­é«˜è´¨é‡çš„åˆ†å‰²æ©ç ä½œä¸ºKeymaskã€‚3) ç¨€ç–åˆ°ç¨ å¯†è’¸é¦ï¼šä½¿ç”¨Keymaskä½œä¸ºæ•™å¸ˆä¿¡å·ï¼Œè®­ç»ƒä¸€ä¸ªå­¦ç”Ÿæ¨¡å‹ï¼Œä½¿å…¶èƒ½å¤Ÿä»ç¨€ç–çš„Keymaskä¸­å­¦ä¹ å¹¶ç”Ÿæˆç¨ å¯†çš„åˆ†å‰²ç»“æœã€‚4) æ¨¡å‹è®­ç»ƒï¼šåœ¨ç”Ÿæˆçš„ç¨ å¯†ä¼ªæ ‡ç­¾ä¸Šè®­ç»ƒæœ€ç»ˆçš„è§†é¢‘å®ä¾‹åˆ†å‰²æ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ç¨€ç–åˆ°ç¨ å¯†çš„Keymaskè’¸é¦æ–¹æ³•ã€‚ä¸ç›´æ¥åœ¨å™ªå£°è¾ƒå¤§çš„å•å¸§åˆ†å‰²ç»“æœä¸Šè®­ç»ƒæ¨¡å‹ä¸åŒï¼Œè¯¥æ–¹æ³•é¦–å…ˆé€‰æ‹©é«˜è´¨é‡çš„Keymaskï¼Œç„¶ååˆ©ç”¨è¿™äº›Keymaskæ¥å¼•å¯¼æ¨¡å‹çš„å­¦ä¹ ï¼Œä»è€Œæé«˜äº†æ¨¡å‹çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒTemporal DropLossçš„è®¾è®¡ä¹Ÿæœ‰åŠ©äºæ¨¡å‹å­¦ä¹ åˆ°æ—¶é—´ä¸€è‡´æ€§çš„åˆ†å‰²ç»“æœã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨Keymaské€‰æ‹©é˜¶æ®µï¼Œè®ºæ–‡åˆ©ç”¨å…‰æµç­‰è¿åŠ¨ä¿¡æ¯æ¥è¯„ä¼°åˆ†å‰²æ©ç çš„è´¨é‡ã€‚åœ¨ç¨€ç–åˆ°ç¨ å¯†è’¸é¦é˜¶æ®µï¼Œè®ºæ–‡è®¾è®¡äº†Temporal DropLossï¼Œé¼“åŠ±æ¨¡å‹åœ¨æ—¶é—´ä¸Šä¿æŒåˆ†å‰²ç»“æœçš„ä¸€è‡´æ€§ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’Œå‚æ•°è®¾ç½®åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ï¼Œä¾‹å¦‚ä½¿ç”¨äº†MaskFormerä½œä¸ºåŸºç¡€åˆ†å‰²æ¨¡å‹ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.14440/x2.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.14440/x3.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.14440/x4.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥æ–¹æ³•åœ¨å¤šä¸ªæ— ç›‘ç£è§†é¢‘å®ä¾‹åˆ†å‰²åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¶…è¶Šäº†å½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨æŸä¸ªæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•çš„åˆ†å‰²ç²¾åº¦æé«˜äº†5%ä»¥ä¸Šã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨çœŸå®è§†é¢‘æ•°æ®ä¸­çš„è¿åŠ¨ä¿¡æ¯ï¼Œæé«˜æ— ç›‘ç£è§†é¢‘å®ä¾‹åˆ†å‰²çš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ã€è§†é¢‘ç›‘æ§ã€æœºå™¨äººå¯¼èˆªç­‰é¢†åŸŸã€‚åœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼Œå¯ä»¥ç”¨äºè¯†åˆ«å’Œåˆ†å‰²é“è·¯ä¸Šçš„è½¦è¾†ã€è¡Œäººç­‰ç›®æ ‡ï¼Œæé«˜é©¾é©¶å®‰å…¨æ€§ã€‚åœ¨è§†é¢‘ç›‘æ§ä¸­ï¼Œå¯ä»¥ç”¨äºè‡ªåŠ¨åˆ†æè§†é¢‘å†…å®¹ï¼Œä¾‹å¦‚æ£€æµ‹å¼‚å¸¸è¡Œä¸ºã€‚åœ¨æœºå™¨äººå¯¼èˆªä¸­ï¼Œå¯ä»¥ç”¨äºå¸®åŠ©æœºå™¨äººç†è§£å‘¨å›´ç¯å¢ƒï¼Œè¿›è¡Œè‡ªä¸»å¯¼èˆªã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In recent years, the state-of-the-art in unsupervised video instance segmentation has heavily relied on synthetic video data, generated from object-centric image datasets such as ImageNet. However, video synthesis by artificially shifting and scaling image instance masks fails to accurately model realistic motion in videos, such as perspective changes, movement by parts of one or multiple instances, or camera motion. To tackle this issue, we propose an unsupervised video instance segmentation model trained exclusively on real video data. We start from unsupervised instance segmentation masks on individual video frames. However, these single-frame segmentations exhibit temporal noise and their quality varies through the video. Therefore, we establish temporal coherence by identifying high-quality keymasks in the video by leveraging deep motion priors. The sparse keymask pseudo-annotations are then used to train a segmentation model for implicit mask propagation, for which we propose a Sparse-To-Dense Distillation approach aided by a Temporal DropLoss. After training the final model on the resulting dense labelset, our approach outperforms the current state-of-the-art across various benchmarks.

