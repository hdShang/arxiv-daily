---
layout: default
title: FacEDiT: Unified Talking Face Editing and Generation via Facial Motion Infilling
---

# FacEDiT: Unified Talking Face Editing and Generation via Facial Motion Infilling

**arXiv**: [2512.14056v1](https://arxiv.org/abs/2512.14056) | [PDF](https://arxiv.org/pdf/2512.14056.pdf)

**ä½œè€…**: Kim Sung-Bin, Joohyun Chang, David Harwath, Tae-Hyun Oh

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: Project page: https://facedit.github.io/

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**FacEDiTï¼šé€šè¿‡é¢éƒ¨è¿åŠ¨å¡«å……å®žçŽ°ç»Ÿä¸€çš„è¯´è¯äººè„¸ç¼–è¾‘ä¸Žç”Ÿæˆ**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å…·èº«æ™ºèƒ½ä¸Žè¡¨å¾å­¦ä¹  (Embodied AI & Representation)**

**å…³é”®è¯**: `è¯´è¯äººè„¸ç¼–è¾‘` `è¯´è¯äººè„¸ç”Ÿæˆ` `é¢éƒ¨è¿åŠ¨å¡«å……` `æ‰©æ•£æ¨¡åž‹` `Transformer`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è¯´è¯äººè„¸ç¼–è¾‘å’Œç”Ÿæˆæ–¹æ³•é€šå¸¸è¢«è§†ä¸ºç‹¬ç«‹ä»»åŠ¡ï¼Œå¿½ç•¥äº†å®ƒä»¬ä¹‹é—´çš„å†…åœ¨è”ç³»ã€‚
2. FacEDiTå°†äºŒè€…ç»Ÿä¸€ä¸ºè¯­éŸ³æ¡ä»¶ä¸‹çš„é¢éƒ¨è¿åŠ¨å¡«å……é—®é¢˜ï¼Œåˆ©ç”¨æ‰©æ•£Transformerå­¦ä¹ åˆæˆå’Œç¼–è¾‘é¢éƒ¨è¿åŠ¨ã€‚
3. FacEDiTåœ¨FacEDiTBenchæ•°æ®é›†ä¸ŠéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ï¼Œå®žçŽ°äº†å‡†ç¡®çš„è¯­éŸ³å¯¹é½ç¼–è¾‘å’Œæµç•…çš„è§†è§‰æ•ˆæžœã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„è§†è§’æ¥å¤„ç†è¯´è¯äººè„¸ç¼–è¾‘å’Œç”Ÿæˆé—®é¢˜ï¼Œå°†å…¶è§†ä¸ºè¯­éŸ³æ¡ä»¶ä¸‹çš„é¢éƒ¨è¿åŠ¨å¡«å……çš„å­ä»»åŠ¡ã€‚æˆ‘ä»¬æŽ¢ç´¢äº†é¢éƒ¨è¿åŠ¨å¡«å……ä½œä¸ºä¸€ç§è‡ªç›‘ç£çš„é¢„è®­ç»ƒä»»åŠ¡ï¼Œå®ƒåŒæ—¶ä¹Ÿæ˜¯åŠ¨æ€è¯´è¯äººè„¸åˆæˆçš„ç»Ÿä¸€å…¬å¼ã€‚ä¸ºäº†å®žçŽ°è¿™ä¸€æƒ³æ³•ï¼Œæˆ‘ä»¬æå‡ºäº†FacEDiTï¼Œä¸€ä¸ªä½¿ç”¨æµåŒ¹é…è®­ç»ƒçš„è¯­éŸ³æ¡ä»¶æ‰©æ•£Transformerã€‚å—åˆ°æŽ©ç è‡ªç¼–ç å™¨çš„å¯å‘ï¼ŒFacEDiTå­¦ä¹ åœ¨å‘¨å›´è¿åŠ¨å’Œè¯­éŸ³çš„æ¡ä»¶ä¸‹åˆæˆè¢«æŽ©ç›–çš„é¢éƒ¨è¿åŠ¨ã€‚è¿™ç§å…¬å¼èƒ½å¤Ÿå®žçŽ°å±€éƒ¨ç”Ÿæˆå’Œç¼–è¾‘ï¼Œä¾‹å¦‚æ›¿æ¢ã€æ’å…¥å’Œåˆ é™¤ï¼ŒåŒæ—¶ç¡®ä¿ä¸Žæœªç¼–è¾‘åŒºåŸŸçš„æ— ç¼è¿‡æ¸¡ã€‚æ­¤å¤–ï¼Œæœ‰åæ³¨æ„åŠ›æœºåˆ¶å’Œæ—¶é—´å¹³æ»‘çº¦æŸå¢žå¼ºäº†è¾¹ç•Œè¿žç»­æ€§å’Œå”‡éƒ¨åŒæ­¥ã€‚ä¸ºäº†è§£å†³ç¼ºä¹æ ‡å‡†ç¼–è¾‘åŸºå‡†çš„é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†FacEDiTBenchï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªç”¨äºŽè¯´è¯äººè„¸ç¼–è¾‘çš„æ•°æ®é›†ï¼Œå…·æœ‰å¤šæ ·åŒ–çš„ç¼–è¾‘ç±»åž‹å’Œé•¿åº¦ï¼Œä»¥åŠæ–°çš„è¯„ä¼°æŒ‡æ ‡ã€‚å¤§é‡çš„å®žéªŒéªŒè¯äº†è¯´è¯äººè„¸ç¼–è¾‘å’Œç”Ÿæˆæ˜¯è¯­éŸ³æ¡ä»¶è¿åŠ¨å¡«å……çš„å­ä»»åŠ¡ï¼›FacEDiTäº§ç”Ÿå‡†ç¡®çš„ã€è¯­éŸ³å¯¹é½çš„é¢éƒ¨ç¼–è¾‘ï¼Œå…·æœ‰å¼ºå¤§çš„èº«ä»½ä¿æŒå’Œå¹³æ»‘çš„è§†è§‰è¿žç»­æ€§ï¼ŒåŒæ—¶æœ‰æ•ˆåœ°æŽ¨å¹¿åˆ°è¯´è¯äººè„¸ç”Ÿæˆã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰æ–¹æ³•é€šå¸¸å°†è¯´è¯äººè„¸ç¼–è¾‘å’Œç”Ÿæˆè§†ä¸ºç‹¬ç«‹çš„ä»»åŠ¡ï¼Œç¼ºä¹ç»Ÿä¸€çš„æ¡†æž¶ã€‚è¿™å¯¼è‡´äº†æ¨¡åž‹éš¾ä»¥åœ¨ç¼–è¾‘å’Œç”Ÿæˆä¹‹é—´æ³›åŒ–ï¼Œå¹¶ä¸”ç¼ºä¹ä¸“é—¨ç”¨äºŽè¯´è¯äººè„¸ç¼–è¾‘çš„åŸºå‡†æ•°æ®é›†ï¼Œéš¾ä»¥è¯„ä¼°ç¼–è¾‘æ•ˆæžœã€‚çŽ°æœ‰æ–¹æ³•åœ¨å¤„ç†ç¼–è¾‘è¾¹ç•Œçš„å¹³æ»‘è¿‡æ¸¡ä»¥åŠä¿æŒèº«ä»½ä¸€è‡´æ€§æ–¹é¢ä¹Ÿå­˜åœ¨æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†è¯´è¯äººè„¸ç¼–è¾‘å’Œç”Ÿæˆç»Ÿä¸€å»ºæ¨¡ä¸ºè¯­éŸ³æ¡ä»¶ä¸‹çš„é¢éƒ¨è¿åŠ¨å¡«å……é—®é¢˜ã€‚é€šè¿‡å­¦ä¹ å¦‚ä½•æ ¹æ®è¯­éŸ³å’Œå‘¨å›´çš„é¢éƒ¨è¿åŠ¨æ¥å¡«å……ç¼ºå¤±æˆ–éœ€è¦ä¿®æ”¹çš„é¢éƒ¨è¿åŠ¨ï¼Œæ¨¡åž‹å¯ä»¥åŒæ—¶å®žçŽ°ç¼–è¾‘å’Œç”Ÿæˆçš„åŠŸèƒ½ã€‚è¿™ç§æ–¹æ³•å€Ÿé‰´äº†æŽ©ç è‡ªç¼–ç å™¨çš„æ€æƒ³ï¼Œé€šè¿‡è‡ªç›‘ç£å­¦ä¹ æ¥æé«˜æ¨¡åž‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šFacEDiTçš„æ•´ä½“æ¡†æž¶æ˜¯ä¸€ä¸ªè¯­éŸ³æ¡ä»¶æ‰©æ•£Transformerï¼Œå®ƒç”±ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ç»„æˆï¼š1) è¯­éŸ³ç¼–ç å™¨ï¼šå°†è¾“å…¥çš„è¯­éŸ³è½¬æ¢ä¸ºè¯­éŸ³ç‰¹å¾å‘é‡ã€‚2) é¢éƒ¨è¿åŠ¨ç¼–ç å™¨ï¼šå°†è¾“å…¥çš„é¢éƒ¨è¿åŠ¨åºåˆ—è½¬æ¢ä¸ºè¿åŠ¨ç‰¹å¾å‘é‡ã€‚3) æ‰©æ•£Transformerï¼šæ ¹æ®è¯­éŸ³ç‰¹å¾å’Œå‘¨å›´çš„è¿åŠ¨ç‰¹å¾ï¼Œé¢„æµ‹è¢«æŽ©ç›–çš„é¢éƒ¨è¿åŠ¨ã€‚4) æµåŒ¹é…æ¨¡å—ï¼šç”¨äºŽè®­ç»ƒæ‰©æ•£Transformerï¼Œä½¿å…¶èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„é¢éƒ¨è¿åŠ¨åºåˆ—ã€‚

**å…³é”®åˆ›æ–°**ï¼šFacEDiTçš„å…³é”®åˆ›æ–°ç‚¹åœ¨äºŽï¼š1) ç»Ÿä¸€çš„å»ºæ¨¡æ¡†æž¶ï¼šå°†è¯´è¯äººè„¸ç¼–è¾‘å’Œç”Ÿæˆç»Ÿä¸€ä¸ºé¢éƒ¨è¿åŠ¨å¡«å……é—®é¢˜ã€‚2) åŸºäºŽæ‰©æ•£Transformerçš„ç”Ÿæˆæ¨¡åž‹ï¼šåˆ©ç”¨æ‰©æ•£æ¨¡åž‹ç”Ÿæˆé«˜è´¨é‡çš„é¢éƒ¨è¿åŠ¨åºåˆ—ã€‚3) æœ‰åæ³¨æ„åŠ›æœºåˆ¶å’Œæ—¶é—´å¹³æ»‘çº¦æŸï¼šå¢žå¼ºäº†ç¼–è¾‘è¾¹ç•Œçš„è¿žç»­æ€§å’Œå”‡éƒ¨åŒæ­¥æ•ˆæžœã€‚4) FacEDiTBenchæ•°æ®é›†ï¼šä¸ºè¯´è¯äººè„¸ç¼–è¾‘æä¾›äº†ä¸€ä¸ªæ ‡å‡†åŒ–çš„è¯„ä¼°åŸºå‡†ã€‚

**å…³é”®è®¾è®¡**ï¼šFacEDiTä½¿ç”¨äº†ä»¥ä¸‹å…³é”®è®¾è®¡ï¼š1) æŽ©ç ç­–ç•¥ï¼šéšæœºæŽ©ç›–éƒ¨åˆ†é¢éƒ¨è¿åŠ¨ï¼Œè¿«ä½¿æ¨¡åž‹å­¦ä¹ æ ¹æ®å‘¨å›´çš„è¿åŠ¨å’Œè¯­éŸ³æ¥å¡«å……ç¼ºå¤±çš„éƒ¨åˆ†ã€‚2) æœ‰åæ³¨æ„åŠ›æœºåˆ¶ï¼šåœ¨Transformerçš„æ³¨æ„åŠ›æœºåˆ¶ä¸­å¼•å…¥åç½®ï¼Œä½¿å¾—æ¨¡åž‹æ›´åŠ å…³æ³¨ç¼–è¾‘è¾¹ç•Œé™„è¿‘çš„åŒºåŸŸã€‚3) æ—¶é—´å¹³æ»‘çº¦æŸï¼šåœ¨æŸå¤±å‡½æ•°ä¸­åŠ å…¥æ—¶é—´å¹³æ»‘é¡¹ï¼Œé¼“åŠ±æ¨¡åž‹ç”Ÿæˆå¹³æ»‘çš„é¢éƒ¨è¿åŠ¨åºåˆ—ã€‚4) æµåŒ¹é…è®­ç»ƒï¼šä½¿ç”¨æµåŒ¹é…æ–¹æ³•è®­ç»ƒæ‰©æ•£Transformerï¼Œæé«˜äº†ç”Ÿæˆé€Ÿåº¦å’Œè´¨é‡ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒFacEDiTåœ¨FacEDiTBenchæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œèƒ½å¤Ÿç”Ÿæˆå‡†ç¡®çš„ã€è¯­éŸ³å¯¹é½çš„é¢éƒ¨ç¼–è¾‘ï¼ŒåŒæ—¶ä¿æŒäº†è¾ƒå¥½çš„èº«ä»½ä¸€è‡´æ€§å’Œè§†è§‰è¿žç»­æ€§ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒFacEDiTåœ¨ç¼–è¾‘è´¨é‡å’Œç”Ÿæˆæ•ˆæžœä¸Šå‡æœ‰æ˜Žæ˜¾ä¼˜åŠ¿ï¼Œå¹¶ä¸”èƒ½å¤Ÿæœ‰æ•ˆåœ°æ³›åŒ–åˆ°è¯´è¯äººè„¸ç”Ÿæˆä»»åŠ¡ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

FacEDiTå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼ŒåŒ…æ‹¬ï¼šè§†é¢‘ä¼šè®®ä¸­çš„å®žæ—¶äººè„¸ç¼–è¾‘ã€ç”µå½±å’Œæ¸¸æˆä¸­çš„è§’è‰²åŠ¨ç”»ç”Ÿæˆã€è¯­éŸ³é©±åŠ¨çš„è™šæ‹Ÿå½¢è±¡å®šåˆ¶ã€ä»¥åŠå¸®åŠ©è¨€è¯­éšœç¢äººå£«è¿›è¡Œäº¤æµç­‰ã€‚è¯¥ç ”ç©¶çš„æˆæžœæœ‰åŠ©äºŽæå‡äººæœºäº¤äº’çš„è‡ªç„¶æ€§å’ŒçœŸå®žæ„Ÿï¼Œå¹¶ä¸ºç›¸å…³é¢†åŸŸå¸¦æ¥åˆ›æ–°ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Talking face editing and face generation have often been studied as distinct problems. In this work, we propose viewing both not as separate tasks but as subtasks of a unifying formulation, speech-conditional facial motion infilling. We explore facial motion infilling as a self-supervised pretext task that also serves as a unifying formulation of dynamic talking face synthesis. To instantiate this idea, we propose FacEDiT, a speech-conditional Diffusion Transformer trained with flow matching. Inspired by masked autoencoders, FacEDiT learns to synthesize masked facial motions conditioned on surrounding motions and speech. This formulation enables both localized generation and edits, such as substitution, insertion, and deletion, while ensuring seamless transitions with unedited regions. In addition, biased attention and temporal smoothness constraints enhance boundary continuity and lip synchronization. To address the lack of a standard editing benchmark, we introduce FacEDiTBench, the first dataset for talking face editing, featuring diverse edit types and lengths, along with new evaluation metrics. Extensive experiments validate that talking face editing and generation emerge as subtasks of speech-conditional motion infilling; FacEDiT produces accurate, speech-aligned facial edits with strong identity preservation and smooth visual continuity while generalizing effectively to talking face generation.

