---
layout: default
title: EVOLVE-VLA: Test-Time Training from Environment Feedback for Vision-Language-Action Models
---

# EVOLVE-VLA: Test-Time Training from Environment Feedback for Vision-Language-Action Models

**arXiv**: [2512.14666v1](https://arxiv.org/abs/2512.14666) | [PDF](https://arxiv.org/pdf/2512.14666.pdf)

**ä½œè€…**: Zechen Bai, Chen Gao, Mike Zheng Shou

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: 15 pages

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEVOLVE-VLAæµ‹è¯•æ—¶è®­ç»ƒæ¡†æž¶ï¼Œä½¿è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹é€šè¿‡çŽ¯å¢ƒåé¦ˆå®žçŽ°æŒç»­è‡ªé€‚åº”ï¼Œå‡å°‘ä»»åŠ¡ç‰¹å®šæ¼”ç¤ºéœ€æ±‚ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **è§†è§‰é‡Œç¨‹è®¡** **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `æµ‹è¯•æ—¶è®­ç»ƒ` `è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹` `çŽ¯å¢ƒåé¦ˆ` `è‡ªé€‚åº”å­¦ä¹ ` `æœºå™¨äººæ“ä½œ` `è¿›åº¦ä¼°è®¡` `è·¨ä»»åŠ¡æ³›åŒ–` `å…·èº«æ™ºèƒ½`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰VLAæ¨¡åž‹ä¾èµ–ç›‘ç£å¾®è°ƒï¼Œéœ€å¤§é‡ä»»åŠ¡æ¼”ç¤ºï¼Œéƒ¨ç½²æ¡ä»¶å˜åŒ–æ—¶æ— æ³•é€‚åº”ï¼Œé™åˆ¶äº†è‡ªé€‚åº”èƒ½åŠ›ã€‚
2. æå‡ºEVOLVE-VLAæ¡†æž¶ï¼Œé€šè¿‡çŽ¯å¢ƒåé¦ˆå®žçŽ°æµ‹è¯•æ—¶è®­ç»ƒï¼Œç”¨å­¦ä¹ è¿›åº¦ä¼°è®¡å™¨æ›¿ä»£å¥–åŠ±ä¿¡å·ï¼Œå¹¶è®¾è®¡æœºåˆ¶é©¯æœå™ªå£°ã€‚
3. å®žéªŒæ˜¾ç¤ºåœ¨é•¿è§†é‡Žä»»åŠ¡æå‡8.6%ï¼Œå•æ ·æœ¬å­¦ä¹ æå‡22.0%ï¼Œè·¨ä»»åŠ¡æ³›åŒ–è¾¾20.8%æˆåŠŸçŽ‡ï¼Œæ¶ŒçŽ°é”™è¯¯æ¢å¤ç­‰èƒ½åŠ›ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å®žçŽ°çœŸæ­£çš„è‡ªé€‚åº”å…·èº«æ™ºèƒ½éœ€è¦æ™ºèƒ½ä½“é€šè¿‡çŽ¯å¢ƒäº¤äº’æŒç»­å­¦ä¹ ï¼Œè€Œéžä»…æ¨¡ä»¿é™æ€æ¼”ç¤ºã€‚è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹è™½é€šè¿‡å¤§è¯­è¨€æ¨¡åž‹æŽ¨åŠ¨äº†æœºå™¨äººæ“ä½œï¼Œä½†ä»å—é™äºŽç›‘ç£å¾®è°ƒï¼šæ¯ä»»åŠ¡éœ€æ•°ç™¾æ¼”ç¤ºã€åƒµåŒ–è®°å¿†è½¨è¿¹ã€éƒ¨ç½²æ¡ä»¶åç¦»è®­ç»ƒæ—¶æ— æ³•é€‚åº”ã€‚æœ¬æ–‡æå‡ºEVOLVE-VLAï¼Œä¸€ä¸ªæµ‹è¯•æ—¶è®­ç»ƒæ¡†æž¶ï¼Œä½¿VLAæ¨¡åž‹èƒ½ä»¥æœ€å°‘æˆ–é›¶ä»»åŠ¡ç‰¹å®šæ¼”ç¤ºé€šè¿‡çŽ¯å¢ƒäº¤äº’æŒç»­é€‚åº”ã€‚å…³é”®æŠ€æœ¯æŒ‘æˆ˜æ˜¯ç”¨è‡ªä¸»åé¦ˆæ›¿ä»£æµ‹è¯•æ—¶ä¸å¯ç”¨çš„oracleå¥–åŠ±ä¿¡å·ã€‚æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªæä¾›å¯†é›†åé¦ˆçš„å­¦ä¹ è¿›åº¦ä¼°è®¡å™¨è§£å†³æ­¤é—®é¢˜ï¼Œå¹¶è®¾è®¡æ¡†æž¶é€šè¿‡ä¸¤ç§æœºåˆ¶â€œé©¯æœâ€è¿™ä¸€å›ºæœ‰å™ªå£°ä¿¡å·ï¼š(1)ç´¯ç§¯è¿›åº¦ä¼°è®¡æœºåˆ¶å¹³æ»‘å™ªå£°ç‚¹ä¼°è®¡ï¼Œ(2)æ¸è¿›è§†é‡Žæ‰©å±•ç­–ç•¥å®žçŽ°é€æ­¥ç­–ç•¥æ¼”åŒ–ã€‚EVOLVE-VLAå–å¾—æ˜¾è‘—æå‡ï¼šé•¿è§†é‡Žä»»åŠ¡+8.6%ï¼Œå•æ ·æœ¬å­¦ä¹ +22.0%ï¼Œå¹¶å®žçŽ°è·¨ä»»åŠ¡æ³›åŒ–â€”â€”åœ¨æœªè§ä»»åŠ¡ä¸Šæ— ä»»åŠ¡ç‰¹å®šæ¼”ç¤ºè®­ç»ƒè¾¾åˆ°20.8%æˆåŠŸçŽ‡ï¼ˆçº¯SFTä¸º0%ï¼‰ã€‚å®šæ€§åˆ†æžæ­ç¤ºäº†æ¼”ç¤ºä¸­æœªå‡ºçŽ°çš„æ¶ŒçŽ°èƒ½åŠ›ï¼ŒåŒ…æ‹¬é”™è¯¯æ¢å¤å’Œæ–°ç­–ç•¥ã€‚è¿™é¡¹å·¥ä½œä»£è¡¨äº†VLAæ¨¡åž‹å‘çœŸæ­£å­¦ä¹ å’Œé€‚åº”è¿ˆå‡ºçš„å…³é”®ä¸€æ­¥ï¼Œä»Žé™æ€æ¨¡ä»¿è½¬å‘æŒç»­è‡ªæˆ‘æ”¹è¿›ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡è§£å†³VLAæ¨¡åž‹åœ¨æœºå™¨äººæ“ä½œä¸­ä¾èµ–ç›‘ç£å¾®è°ƒçš„é—®é¢˜ï¼ŒåŒ…æ‹¬éœ€è¦å¤§é‡ä»»åŠ¡ç‰¹å®šæ¼”ç¤ºã€è½¨è¿¹è®°å¿†åƒµåŒ–ã€éƒ¨ç½²æ¡ä»¶åç¦»è®­ç»ƒæ—¶æ— æ³•è‡ªé€‚åº”ã€‚çŽ°æœ‰æ–¹æ³•ç—›ç‚¹åœ¨äºŽæµ‹è¯•æ—¶ç¼ºä¹oracleå¥–åŠ±ä¿¡å·ï¼Œå¯¼è‡´æ¨¡åž‹æ— æ³•é€šè¿‡çŽ¯å¢ƒäº¤äº’æŒç»­æ”¹è¿›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæ ¸å¿ƒæ€è·¯æ˜¯å¼•å…¥æµ‹è¯•æ—¶è®­ç»ƒæ¡†æž¶ï¼Œä½¿VLAæ¨¡åž‹èƒ½åœ¨éƒ¨ç½²åŽé€šè¿‡çŽ¯å¢ƒåé¦ˆè‡ªä¸»å­¦ä¹ å’Œé€‚åº”ï¼Œå‡å°‘å¯¹æ¼”ç¤ºæ•°æ®çš„ä¾èµ–ã€‚è®¾è®¡åŸºäºŽå­¦ä¹ è¿›åº¦ä¼°è®¡å™¨æä¾›å¯†é›†åé¦ˆï¼Œå¹¶é‡‡ç”¨æœºåˆ¶é©¯æœåé¦ˆå™ªå£°ï¼Œå®žçŽ°ç¨³å®šç­–ç•¥æ¼”åŒ–ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æ¡†æž¶åŒ…æ‹¬çŽ¯å¢ƒäº¤äº’æ¨¡å—ã€å­¦ä¹ è¿›åº¦ä¼°è®¡å™¨æ¨¡å—å’Œç­–ç•¥æ›´æ–°æ¨¡å—ã€‚æµç¨‹ä¸ºï¼šæ¨¡åž‹åœ¨æµ‹è¯•æ—¶ä¸ŽçŽ¯å¢ƒäº¤äº’ï¼Œæ”¶é›†çŠ¶æ€-åŠ¨ä½œæ•°æ®ï¼›å­¦ä¹ è¿›åº¦ä¼°è®¡å™¨åŸºäºŽäº¤äº’åŽ†å²ç”Ÿæˆå¯†é›†åé¦ˆä¿¡å·ï¼›é€šè¿‡ç´¯ç§¯ä¼°è®¡å’Œæ¸è¿›è§†é‡Žæ‰©å±•æœºåˆ¶å¤„ç†å™ªå£°ï¼›ç­–ç•¥åŸºäºŽåé¦ˆè¿›è¡Œåœ¨çº¿å¾®è°ƒï¼Œé€æ­¥ä¼˜åŒ–è¡Œä¸ºã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°æ˜¯æå‡ºæµ‹è¯•æ—¶è®­ç»ƒèŒƒå¼ï¼Œç”¨è‡ªä¸»çŽ¯å¢ƒåé¦ˆæ›¿ä»£ä¼ ç»Ÿå¥–åŠ±ä¿¡å·ï¼Œå®žçŽ°VLAæ¨¡åž‹çš„æŒç»­è‡ªé€‚åº”ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºŽæ‘†è„±äº†å¯¹é™æ€æ¼”ç¤ºæ•°æ®çš„ä¾èµ–ï¼Œä½¿æ¨¡åž‹èƒ½åœ¨æœªçŸ¥æ¡ä»¶ä¸‹é€šè¿‡äº¤äº’å­¦ä¹ ï¼Œæå‡æ³›åŒ–èƒ½åŠ›å’Œé€‚åº”æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬å­¦ä¹ è¿›åº¦ä¼°è®¡å™¨çš„ç½‘ç»œç»“æž„ï¼ˆå¯èƒ½åŸºäºŽTransformeræˆ–RNNï¼Œå…·ä½“æœªçŸ¥ï¼‰ï¼ŒæŸå¤±å‡½æ•°ç”¨äºŽè®­ç»ƒä¼°è®¡å™¨ï¼ˆå¦‚å‡æ–¹è¯¯å·®æŸå¤±ï¼‰ï¼Œä»¥åŠç´¯ç§¯ä¼°è®¡æœºåˆ¶ï¼ˆå¦‚æ»‘åŠ¨å¹³å‡æˆ–ç§¯åˆ†æ–¹æ³•ï¼‰å’Œæ¸è¿›è§†é‡Žæ‰©å±•ç­–ç•¥ï¼ˆé€æ­¥å¢žåŠ é¢„æµ‹æ­¥é•¿ï¼‰ã€‚å‚æ•°è®¾ç½®æ¶‰åŠåé¦ˆå¹³æ»‘ç³»æ•°å’Œè§†é‡Žæ‰©å±•é€ŸçŽ‡ï¼Œéœ€å¹³è¡¡å™ªå£°æŠ‘åˆ¶å’Œå­¦ä¹ æ•ˆçŽ‡ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

EVOLVE-VLAåœ¨å®žéªŒä¸­è¡¨çŽ°ä¼˜å¼‚ï¼šé•¿è§†é‡Žä»»åŠ¡æˆåŠŸçŽ‡æå‡8.6%ï¼Œå•æ ·æœ¬å­¦ä¹ æå‡22.0%ï¼Œè·¨ä»»åŠ¡æ³›åŒ–åœ¨æœªè§ä»»åŠ¡ä¸Šè¾¾åˆ°20.8%æˆåŠŸçŽ‡ï¼ˆå¯¹æ¯”çº¯SFTçš„0%ï¼‰ã€‚å®šæ€§åˆ†æžæ˜¾ç¤ºæ¨¡åž‹æ¶ŒçŽ°å‡ºé”™è¯¯æ¢å¤å’Œæ–°ç­–ç•¥ç­‰èƒ½åŠ›ï¼ŒéªŒè¯äº†æ¡†æž¶çš„æœ‰æ•ˆæ€§å’Œé€‚åº”æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨æœºå™¨äººæ“ä½œã€è‡ªåŠ¨é©¾é©¶å’Œæ™ºèƒ½å®¶å±…ç­‰é¢†åŸŸæœ‰æ½œåœ¨åº”ç”¨ï¼Œèƒ½æå‡æ™ºèƒ½ä½“åœ¨åŠ¨æ€çŽ¯å¢ƒä¸­çš„è‡ªé€‚åº”èƒ½åŠ›ï¼Œå‡å°‘äººå·¥æ¼”ç¤ºæˆæœ¬ï¼ŒæŽ¨åŠ¨å…·èº«æ™ºèƒ½å‘æ›´è‡ªä¸»ã€çµæ´»çš„æ–¹å‘å‘å±•ï¼Œå¯¹æœªæ¥è‡ªé€‚åº”AIç³»ç»Ÿå…·æœ‰é‡è¦ä»·å€¼ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Achieving truly adaptive embodied intelligence requires agents that learn not just by imitating static demonstrations, but by continuously improving through environmental interaction, which is akin to how humans master skills through practice. Vision-Language-Action (VLA) models have advanced robotic manipulation by leveraging large language models, yet remain fundamentally limited by Supervised Finetuning (SFT): requiring hundreds of demonstrations per task, rigidly memorizing trajectories, and failing to adapt when deployment conditions deviate from training. We introduce EVOLVE-VLA, a test-time training framework enabling VLAs to continuously adapt through environment interaction with minimal or zero task-specific demonstrations. The key technical challenge is replacing oracle reward signals (unavailable at test time) with autonomous feedback. We address this through a learned progress estimator providing dense feedback, and critically, we design our framework to ``tame'' this inherently noisy signal via two mechanisms: (1) an accumulative progress estimation mechanism smoothing noisy point-wise estimates, and (2) a progressive horizon extension strategy enabling gradual policy evolution. EVOLVE-VLA achieves substantial gains: +8.6\% on long-horizon tasks, +22.0\% in 1-shot learning, and enables cross-task generalization -- achieving 20.8\% success on unseen tasks without task-specific demonstrations training (vs. 0\% for pure SFT). Qualitative analysis reveals emergent capabilities absent in demonstrations, including error recovery and novel strategies. This work represents a critical step toward VLAs that truly learn and adapt, moving beyond static imitation toward continuous self-improvements.

