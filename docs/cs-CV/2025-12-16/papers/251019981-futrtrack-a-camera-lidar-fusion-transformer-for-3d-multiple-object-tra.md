---
layout: default
title: FutrTrack: A Camera-LiDAR Fusion Transformer for 3D Multiple Object Tracking
---

# FutrTrack: A Camera-LiDAR Fusion Transformer for 3D Multiple Object Tracking

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.19981" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.19981</a>
  <a href="https://arxiv.org/pdf/2510.19981.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.19981" onclick="toggleFavorite(this, '2510.19981', 'FutrTrack: A Camera-LiDAR Fusion Transformer for 3D Multiple Object Tracking')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Martha Teiko Teye, Ori Maoz, Matthias Rottmann

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-18

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**FutrTrackï¼šä¸€ç§ç”¨äº3Då¤šç›®æ ‡è·Ÿè¸ªçš„ç›¸æœº-æ¿€å…‰é›·è¾¾èåˆTransformer**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `3Då¤šç›®æ ‡è·Ÿè¸ª` `å¤šæ¨¡æ€èåˆ` `Transformer` `ç›¸æœº-æ¿€å…‰é›·è¾¾èåˆ` `ç›®æ ‡è·Ÿè¸ª`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰3Då¤šç›®æ ‡è·Ÿè¸ªæ–¹æ³•åœ¨é®æŒ¡å’Œè§†ç‚¹å˜åŒ–ä¸‹é²æ£’æ€§ä¸è¶³ï¼Œä¸”å¯¹å¤šæ¨¡æ€ä¿¡æ¯çš„æœ‰æ•ˆèåˆä»å…·æŒ‘æˆ˜ã€‚
2. FutrTrackåˆ©ç”¨Transformeræ¶æ„ï¼Œé€šè¿‡å¤šæ¨¡æ€èåˆç‰¹å¾å’Œæ—¶é—´å¹³æ»‘ï¼Œæå‡è·Ÿè¸ªçš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒFutrTrackåœ¨nuSceneså’ŒKITTIæ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ï¼Œå°¤å…¶åœ¨å‡å°‘èº«ä»½åˆ‡æ¢æ–¹é¢æœ‰æ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬æå‡ºäº†FutrTrackï¼Œä¸€ä¸ªæ¨¡å—åŒ–çš„ç›¸æœº-æ¿€å…‰é›·è¾¾å¤šç›®æ ‡è·Ÿè¸ªæ¡†æ¶ï¼Œå®ƒå»ºç«‹åœ¨ç°æœ‰çš„3Dæ£€æµ‹å™¨ä¹‹ä¸Šï¼Œå¼•å…¥äº†ä¸€ä¸ªåŸºäºTransformerçš„å¹³æ»‘å™¨å’Œä¸€ä¸ªèåˆé©±åŠ¨çš„è·Ÿè¸ªå™¨ã€‚å—åˆ°åŸºäºæŸ¥è¯¢çš„è·Ÿè¸ªæ¡†æ¶çš„å¯å‘ï¼ŒFutrTracké‡‡ç”¨äº†ä¸€ç§å¤šæ¨¡æ€ä¸¤é˜¶æ®µTransformerç»†åŒ–å’Œè·Ÿè¸ªæµç¨‹ã€‚æˆ‘ä»¬çš„èåˆè·Ÿè¸ªå™¨é›†æˆäº†æ¥è‡ªå¤šä¸ªç›¸æœºå’Œæ¿€å…‰é›·è¾¾çš„è¾¹ç•Œæ¡†ä¸å¤šæ¨¡æ€é¸Ÿç°å›¾ï¼ˆBEVï¼‰èåˆç‰¹å¾ï¼Œè€Œæ— éœ€æ˜¾å¼çš„è¿åŠ¨æ¨¡å‹ã€‚è¯¥è·Ÿè¸ªå™¨åœ¨å¸§ä¹‹é—´åˆ†é…å’Œä¼ æ’­èº«ä»½ï¼Œåˆ©ç”¨å‡ ä½•å’Œè¯­ä¹‰çº¿ç´¢æ¥å®ç°é®æŒ¡å’Œè§†ç‚¹å˜åŒ–ä¸‹çš„é²æ£’é‡è¯†åˆ«ã€‚åœ¨è·Ÿè¸ªä¹‹å‰ï¼Œæˆ‘ä»¬ä½¿ç”¨ç§»åŠ¨çª—å£ä¸Šçš„æ—¶é—´å¹³æ»‘å™¨æ¥ç»†åŒ–è¾¹ç•Œæ¡†åºåˆ—ï¼Œä»¥ç»†åŒ–è½¨è¿¹ï¼Œå‡å°‘æŠ–åŠ¨å¹¶æé«˜ç©ºé—´ä¸€è‡´æ€§ã€‚åœ¨nuSceneså’ŒKITTIä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œä¸ä¹‹å‰çš„å•ä¼ æ„Ÿå™¨æ–¹æ³•ç›¸æ¯”ï¼ŒåŸºäºæŸ¥è¯¢çš„Transformerè·Ÿè¸ªæ–¹æ³•ä»å¤šæ¨¡æ€ä¼ æ„Ÿå™¨ç‰¹å¾ä¸­è·ç›ŠåŒªæµ…ã€‚åœ¨nuScenesæµ‹è¯•é›†ä¸Šï¼ŒFutrTrackçš„aMOTAä¸º74.7ï¼Œåœ¨3D MOTåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œåœ¨ä¿æŒç«äº‰åŠ›çš„åŒæ—¶å‡å°‘äº†èº«ä»½åˆ‡æ¢ã€‚æˆ‘ä»¬çš„æ–¹æ³•æä¾›äº†ä¸€ä¸ªé«˜æ•ˆçš„æ¡†æ¶ï¼Œç”¨äºæ”¹è¿›åŸºäºTransformerçš„è·Ÿè¸ªå™¨ï¼Œå³ä½¿åœ¨æ•°æ®æœ‰é™ä¸”æ²¡æœ‰é¢„è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œä¹Ÿèƒ½ä¸å…¶ä»–åŸºäºç¥ç»ç½‘ç»œçš„æ–¹æ³•ç«äº‰ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³3Då¤šç›®æ ‡è·Ÿè¸ªï¼ˆMOTï¼‰é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤æ‚åœºæ™¯ä¸‹ï¼Œç”±äºé®æŒ¡ã€è§†ç‚¹å˜åŒ–ä»¥åŠä¼ æ„Ÿå™¨å™ªå£°ç­‰å› ç´ ï¼Œå¯¼è‡´è·Ÿè¸ªæ€§èƒ½ä¸‹é™çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºæ˜¾å¼çš„è¿åŠ¨æ¨¡å‹ï¼Œå¯¹è¿åŠ¨çŠ¶æ€å‡è®¾è¾ƒå¼ºï¼Œä¸”éš¾ä»¥æœ‰æ•ˆèåˆæ¥è‡ªä¸åŒæ¨¡æ€ï¼ˆç›¸æœºå’Œæ¿€å…‰é›·è¾¾ï¼‰çš„ä¿¡æ¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šFutrTrackçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨Transformeræ¶æ„å¼ºå¤§çš„ç‰¹å¾æå–å’Œå…³è”èƒ½åŠ›ï¼Œé€šè¿‡å¤šæ¨¡æ€èåˆå’Œæ—¶é—´å¹³æ»‘æ¥æå‡è·Ÿè¸ªçš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚è¯¥æ–¹æ³•é¿å…äº†å¯¹è¿åŠ¨æ¨¡å‹çš„æ˜¾å¼ä¾èµ–ï¼Œè€Œæ˜¯é€šè¿‡å­¦ä¹ æ•°æ®ä¸­çš„æ½œåœ¨å…³è”æ¥å®ç°è·Ÿè¸ªã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFutrTrackåŒ…å«ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š3Dç›®æ ‡æ£€æµ‹å™¨ï¼ˆä½¿ç”¨ç°æœ‰æ–¹æ³•ï¼‰ã€åŸºäºTransformerçš„æ—¶é—´å¹³æ»‘å™¨å’Œèåˆé©±åŠ¨çš„è·Ÿè¸ªå™¨ã€‚é¦–å…ˆï¼Œä½¿ç”¨3Dæ£€æµ‹å™¨æå–æ¯ä¸€å¸§çš„ç‰©ä½“è¾¹ç•Œæ¡†ã€‚ç„¶åï¼Œæ—¶é—´å¹³æ»‘å™¨åˆ©ç”¨Transformerå¯¹ä¸€æ®µæ—¶é—´å†…çš„è¾¹ç•Œæ¡†åºåˆ—è¿›è¡Œä¼˜åŒ–ï¼Œå‡å°‘æŠ–åŠ¨å¹¶æé«˜ç©ºé—´ä¸€è‡´æ€§ã€‚æœ€åï¼Œèåˆé©±åŠ¨çš„è·Ÿè¸ªå™¨å°†ç›¸æœºå’Œæ¿€å…‰é›·è¾¾çš„å¤šæ¨¡æ€BEVç‰¹å¾ä¸è¾¹ç•Œæ¡†ä¿¡æ¯èåˆï¼Œåˆ©ç”¨Transformerè¿›è¡Œç›®æ ‡å…³è”å’Œèº«ä»½ä¼ æ’­ã€‚

**å…³é”®åˆ›æ–°**ï¼šFutrTrackçš„å…³é”®åˆ›æ–°åœ¨äºå…¶èåˆé©±åŠ¨çš„è·Ÿè¸ªå™¨ï¼Œå®ƒèƒ½å¤Ÿæœ‰æ•ˆåœ°èåˆæ¥è‡ªå¤šä¸ªç›¸æœºå’Œæ¿€å…‰é›·è¾¾çš„å¤šæ¨¡æ€BEVç‰¹å¾ï¼Œè€Œæ— éœ€æ˜¾å¼çš„è¿åŠ¨æ¨¡å‹ã€‚æ­¤å¤–ï¼Œä½¿ç”¨Transformerè¿›è¡Œæ—¶é—´å¹³æ»‘ä¹Ÿæé«˜äº†è½¨è¿¹çš„è´¨é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šæ—¶é—´å¹³æ»‘å™¨ä½¿ç”¨Transformerç¼–ç å™¨-è§£ç å™¨ç»“æ„ï¼Œå°†ä¸€æ®µæ—¶é—´å†…çš„è¾¹ç•Œæ¡†åºåˆ—ä½œä¸ºè¾“å…¥ï¼Œè¾“å‡ºä¼˜åŒ–åçš„è¾¹ç•Œæ¡†åºåˆ—ã€‚èåˆé©±åŠ¨çš„è·Ÿè¸ªå™¨ä½¿ç”¨Transformerè¿›è¡Œç›®æ ‡å…³è”ï¼ŒæŸå¤±å‡½æ•°åŒ…æ‹¬åˆ†ç±»æŸå¤±å’Œå›å½’æŸå¤±ï¼Œç”¨äºä¼˜åŒ–ç›®æ ‡å…³è”å’Œè¾¹ç•Œæ¡†é¢„æµ‹ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2510.19981/images/page1img.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2510.19981/images/overall_fig1.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2510.19981/images/vis_futrtrack3.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

FutrTrackåœ¨nuScenesæµ‹è¯•é›†ä¸Šå–å¾—äº†74.7çš„aMOTAï¼Œæ˜¾è‘—ä¼˜äºä¹‹å‰çš„å•ä¼ æ„Ÿå™¨æ–¹æ³•ã€‚ä¸ç°æœ‰æŠ€æœ¯ç›¸æ¯”ï¼ŒFutrTrackåœ¨ä¿æŒç«äº‰åŠ›çš„åŒæ—¶ï¼Œæ˜¾è‘—å‡å°‘äº†èº«ä»½åˆ‡æ¢çš„æ¬¡æ•°ï¼Œè¡¨æ˜å…¶åœ¨å¤æ‚åœºæ™¯ä¸‹çš„è·Ÿè¸ªé²æ£’æ€§æ›´å¼ºã€‚å®éªŒç»“æœéªŒè¯äº†å¤šæ¨¡æ€èåˆå’ŒTransformeræ¶æ„åœ¨3Då¤šç›®æ ‡è·Ÿè¸ªä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

FutrTrackåœ¨è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€æ™ºèƒ½äº¤é€šç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥ç”¨äºæé«˜è½¦è¾†å’Œæœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸‹çš„æ„ŸçŸ¥èƒ½åŠ›ï¼Œå®ç°æ›´å®‰å…¨ã€æ›´å¯é çš„è‡ªä¸»å¯¼èˆªå’Œå†³ç­–ã€‚è¯¥ç ”ç©¶å¯¹äºæå‡å¤šä¼ æ„Ÿå™¨èåˆå’Œç›®æ ‡è·Ÿè¸ªæŠ€æœ¯æ°´å¹³å…·æœ‰é‡è¦æ„ä¹‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We propose FutrTrack, a modular camera-LiDAR multi-object tracking framework that builds on existing 3D detectors by introducing a transformer-based smoother and a fusion-driven tracker. Inspired by query-based tracking frameworks, FutrTrack employs a multimodal two-stage transformer refinement and tracking pipeline. Our fusion tracker integrates bounding boxes with multimodal bird's-eye-view (BEV) fusion features from multiple cameras and LiDAR without the need for an explicit motion model. The tracker assigns and propagates identities across frames, leveraging both geometric and semantic cues for robust re-identification under occlusion and viewpoint changes. Prior to tracking, we refine sequences of bounding boxes with a temporal smoother over a moving window to refine trajectories, reduce jitter, and improve spatial consistency. Evaluated on nuScenes and KITTI, FutrTrack demonstrates that query-based transformer tracking methods benefit significantly from multimodal sensor features compared with previous single-sensor approaches. With an aMOTA of 74.7 on the nuScenes test set, FutrTrack achieves strong performance on 3D MOT benchmarks, reducing identity switches while maintaining competitive accuracy. Our approach provides an efficient framework for improving transformer-based trackers to compete with other neural-network-based methods even with limited data and without pretraining.

