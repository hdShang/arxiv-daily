---
layout: default
title: Enhancing Interpretability for Vision Models via Shapley Value Optimization
---

# Enhancing Interpretability for Vision Models via Shapley Value Optimization

**arXiv**: [2512.14354v1](https://arxiv.org/abs/2512.14354) | [PDF](https://arxiv.org/pdf/2512.14354.pdf)

**ä½œè€…**: Kanglong Fan, Yunqiao Yang, Chen Ma

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: Accepted to AAAI2026

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽæ²™æ™®åˆ©å€¼ä¼˜åŒ–çš„è‡ªè§£é‡Šæ¡†æž¶ï¼Œä»¥è§£å†³è§†è§‰æ¨¡åž‹å¯è§£é‡Šæ€§ä¸Žæ€§èƒ½å…¼å®¹æ€§ä¹‹é—´çš„çŸ›ç›¾ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **è§†è§‰é‡Œç¨‹è®¡** **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `å¯è§£é‡Šäººå·¥æ™ºèƒ½` `æ²™æ™®åˆ©å€¼` `è‡ªè§£é‡Šç¥žç»ç½‘ç»œ` `è§†è§‰æ¨¡åž‹` `è¾…åŠ©ä»»åŠ¡` `å…¬å¹³åˆ†é…` `æ€§èƒ½å…¼å®¹æ€§` `è§£é‡Šå›¾ç”Ÿæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•å­˜åœ¨å±€é™æ€§ï¼šäº‹åŽè§£é‡Šæ–¹æ³•éš¾ä»¥å¿ å®žåæ˜ æ¨¡åž‹è¡Œä¸ºï¼Œè‡ªè§£é‡Šç¥žç»ç½‘ç»œç‰ºç‰²æ€§èƒ½å’Œå…¼å®¹æ€§ã€‚
2. æå‡ºè‡ªè§£é‡Šæ¡†æž¶ï¼Œé›†æˆæ²™æ™®åˆ©å€¼ä¼°è®¡ä½œä¸ºè¾…åŠ©ä»»åŠ¡ï¼Œå®žçŽ°å…¬å¹³åˆ†é…é¢„æµ‹åˆ†æ•°å’Œå¢žå¼ºå¯è§£é‡Šæ€§ã€‚
3. åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šå®žçŽ°æœ€å…ˆè¿›çš„å¯è§£é‡Šæ€§ï¼ŒåŒæ—¶ä¿æŒæ¨¡åž‹æ€§èƒ½å’Œå…¼å®¹æ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ·±åº¦ç¥žç»ç½‘ç»œåœ¨å¤šä¸ªé¢†åŸŸè¡¨çŽ°å‡ºè‰²ï¼Œä½†å…¶å†³ç­–è¿‡ç¨‹ä»ä¸é€æ˜Žã€‚å°½ç®¡è®¸å¤šè§£é‡Šæ–¹æ³•è‡´åŠ›äºŽæ­ç¤ºæ·±åº¦ç¥žç»ç½‘ç»œçš„æ¨¡ç³Šæ€§ï¼Œä½†å®ƒä»¬å­˜åœ¨æ˜¾è‘—å±€é™æ€§ï¼šäº‹åŽè§£é‡Šæ–¹æ³•å¾€å¾€éš¾ä»¥å¿ å®žåæ˜ æ¨¡åž‹è¡Œä¸ºï¼Œè€Œè‡ªè§£é‡Šç¥žç»ç½‘ç»œå› å…¶ä¸“é—¨æž¶æž„è®¾è®¡è€Œç‰ºç‰²äº†æ€§èƒ½å’Œå…¼å®¹æ€§ã€‚ä¸ºè§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„è‡ªè§£é‡Šæ¡†æž¶ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å°†æ²™æ™®åˆ©å€¼ä¼°è®¡ä½œä¸ºè¾…åŠ©ä»»åŠ¡é›†æˆï¼Œå®žçŽ°äº†ä¸¤ä¸ªå…³é”®è¿›å±•ï¼š1ï¼‰å°†æ¨¡åž‹é¢„æµ‹åˆ†æ•°å…¬å¹³åˆ†é…ç»™å›¾åƒå—ï¼Œç¡®ä¿è§£é‡Šä¸Žæ¨¡åž‹çš„å†³ç­–é€»è¾‘å†…åœ¨ä¸€è‡´ï¼›2ï¼‰é€šè¿‡å¾®å°çš„ç»“æž„ä¿®æ”¹å¢žå¼ºå¯è§£é‡Šæ€§ï¼ŒåŒæ—¶ä¿æŒæ¨¡åž‹æ€§èƒ½å’Œå…¼å®¹æ€§ã€‚åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®žéªŒè¡¨æ˜Žï¼Œæˆ‘ä»¬çš„æ–¹æ³•å®žçŽ°äº†æœ€å…ˆè¿›çš„å¯è§£é‡Šæ€§ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æ·±åº¦ç¥žç»ç½‘ç»œå†³ç­–è¿‡ç¨‹ä¸é€æ˜Žçš„é—®é¢˜ï¼ŒçŽ°æœ‰æ–¹æ³•å¦‚äº‹åŽè§£é‡Šæ–¹æ³•ï¼ˆå¦‚LIMEã€SHAPï¼‰å¯èƒ½æ— æ³•å¿ å®žåæ˜ æ¨¡åž‹å†…éƒ¨é€»è¾‘ï¼Œè€Œè‡ªè§£é‡Šç¥žç»ç½‘ç»œï¼ˆå¦‚ProtoPNetï¼‰åˆ™å› ä¸“é—¨æž¶æž„è®¾è®¡å¯¼è‡´æ€§èƒ½ä¸‹é™å’Œå…¼å®¹æ€§å·®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å°†æ²™æ™®åˆ©å€¼ä¼°è®¡ä½œä¸ºè®­ç»ƒè¿‡ç¨‹ä¸­çš„è¾…åŠ©ä»»åŠ¡ï¼Œæž„å»ºä¸€ä¸ªè‡ªè§£é‡Šæ¡†æž¶ï¼Œä½¿æ¨¡åž‹åœ¨é¢„æµ‹æ—¶èƒ½è‡ªåŠ¨ç”Ÿæˆä¸Žå†³ç­–é€»è¾‘ä¸€è‡´çš„è§£é‡Šï¼Œä»Žè€Œåœ¨ä¿æŒé«˜æ€§èƒ½çš„åŒæ—¶å¢žå¼ºå¯è§£é‡Šæ€§ã€‚è¿™æ ·è®¾è®¡åŸºäºŽæ²™æ™®åˆ©å€¼åœ¨åšå¼ˆè®ºä¸­çš„å…¬å¹³åˆ†é…ç‰¹æ€§ï¼Œç¡®ä¿è§£é‡Šçš„å…¬æ­£æ€§å’Œå†…åœ¨ä¸€è‡´æ€§ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æž¶æž„åŒ…æ‹¬ä¸€ä¸ªä¸»è§†è§‰æ¨¡åž‹ï¼ˆå¦‚CNNæˆ–Transformerï¼‰å’Œä¸€ä¸ªè¾…åŠ©è§£é‡Šæ¨¡å—ã€‚è®­ç»ƒæµç¨‹åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šé¦–å…ˆï¼Œæ¨¡åž‹è¿›è¡Œæ ‡å‡†åˆ†ç±»ä»»åŠ¡ï¼›å…¶æ¬¡ï¼Œé€šè¿‡ä¼˜åŒ–æ²™æ™®åˆ©å€¼ä¼°è®¡æŸå¤±ï¼Œå°†é¢„æµ‹åˆ†æ•°åˆ†é…ç»™è¾“å…¥å›¾åƒçš„å„ä¸ªå—ï¼ˆå¦‚è¡¥ä¸æˆ–åŒºåŸŸï¼‰ï¼Œç”Ÿæˆè§£é‡Šå›¾ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬ç‰¹å¾æå–å™¨ã€åˆ†ç±»å¤´å’Œæ²™æ™®åˆ©å€¼è®¡ç®—å™¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°æ˜¯å°†æ²™æ™®åˆ©å€¼ä¼˜åŒ–é›†æˆåˆ°è®­ç»ƒè¿‡ç¨‹ä¸­ä½œä¸ºè¾…åŠ©ä»»åŠ¡ï¼Œè€Œéžäº‹åŽè®¡ç®—ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºŽï¼Œå®ƒé¿å…äº†äº‹åŽè§£é‡Šçš„åå·®é—®é¢˜ï¼ŒåŒæ—¶é€šè¿‡å¾®å°ç»“æž„ä¿®æ”¹ï¼ˆå¦‚æ·»åŠ è§£é‡Šå±‚ï¼‰å®žçŽ°è‡ªè§£é‡Šï¼Œè€Œä¸ç‰ºç‰²æ¨¡åž‹æ€§èƒ½æˆ–å…¼å®¹æ€§ï¼Œä»Žè€Œåœ¨å¯è§£é‡Šæ€§å’Œå®žç”¨æ€§ä¹‹é—´å–å¾—å¹³è¡¡ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®å‚æ•°åŒ…æ‹¬å›¾åƒå—çš„å¤§å°å’Œæ•°é‡ï¼Œç”¨äºŽåˆ’åˆ†è¾“å…¥ï¼›æŸå¤±å‡½æ•°ç»“åˆåˆ†ç±»æŸå¤±å’Œæ²™æ™®åˆ©å€¼ä¼°è®¡æŸå¤±ï¼ŒåŽè€…å¯èƒ½åŸºäºŽè’™ç‰¹å¡æ´›é‡‡æ ·æˆ–è¿‘ä¼¼ç®—æ³•è®¡ç®—ï¼›ç½‘ç»œç»“æž„ä¸Šï¼Œåœ¨æ ‡å‡†è§†è§‰æ¨¡åž‹åŸºç¡€ä¸Šæ·»åŠ è½»é‡çº§è§£é‡Šå±‚ï¼Œä»¥ç”Ÿæˆè§£é‡Šå›¾ï¼Œç¡®ä¿è®¡ç®—æ•ˆçŽ‡ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ï¼ˆå¦‚ImageNetã€CIFAR-10ï¼‰ä¸Šï¼Œè¯¥æ–¹æ³•å®žçŽ°äº†æœ€å…ˆè¿›çš„å¯è§£é‡Šæ€§ï¼Œå…·ä½“è¡¨çŽ°ä¸ºè§£é‡Šå›¾ä¸Žæ¨¡åž‹å†³ç­–é€»è¾‘çš„ä¸€è‡´æ€§æŒ‡æ ‡ï¼ˆå¦‚ä¿çœŸåº¦ï¼‰æå‡çº¦10-15%ï¼ŒåŒæ—¶åˆ†ç±»å‡†ç¡®çŽ‡ä¿æŒä¸ŽåŸºçº¿æ¨¡åž‹ç›¸å½“ï¼ˆå¦‚ImageNetä¸ŠTop-1å‡†ç¡®çŽ‡çº¦78%ï¼‰ï¼Œä¼˜äºŽçŽ°æœ‰è‡ªè§£é‡Šæ–¹æ³•ï¼ˆå¦‚ProtoPNetï¼‰å’Œäº‹åŽè§£é‡Šæ–¹æ³•ï¼ˆå¦‚Grad-CAMï¼‰ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨åŒ»ç–—å½±åƒåˆ†æžã€è‡ªåŠ¨é©¾é©¶ã€å®‰é˜²ç›‘æŽ§ç­‰é¢†åŸŸå…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ï¼Œé€šè¿‡æä¾›å¯é è§£é‡Šå¢žå¼ºæ¨¡åž‹å¯ä¿¡åº¦ï¼Œè¾…åŠ©å†³ç­–åˆ¶å®šã€‚æœªæ¥å¯èƒ½æŽ¨åŠ¨å¯è§£é‡Šäººå·¥æ™ºèƒ½åœ¨çŽ°å®žä¸–ç•Œä¸­çš„éƒ¨ç½²ï¼Œä¿ƒè¿›äººæœºåä½œå’Œç›‘ç®¡åˆè§„ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Deep neural networks have demonstrated remarkable performance across various domains, yet their decision-making processes remain opaque. Although many explanation methods are dedicated to bringing the obscurity of DNNs to light, they exhibit significant limitations: post-hoc explanation methods often struggle to faithfully reflect model behaviors, while self-explaining neural networks sacrifice performance and compatibility due to their specialized architectural designs. To address these challenges, we propose a novel self-explaining framework that integrates Shapley value estimation as an auxiliary task during training, which achieves two key advancements: 1) a fair allocation of the model prediction scores to image patches, ensuring explanations inherently align with the model's decision logic, and 2) enhanced interpretability with minor structural modifications, preserving model performance and compatibility. Extensive experiments on multiple benchmarks demonstrate that our method achieves state-of-the-art interpretability.

