---
layout: default
title: Enhancing Interpretability for Vision Models via Shapley Value Optimization
---

# Enhancing Interpretability for Vision Models via Shapley Value Optimization

**arXiv**: [2512.14354v1](https://arxiv.org/abs/2512.14354) | [PDF](https://arxiv.org/pdf/2512.14354.pdf)

**ä½œè€…**: Kanglong Fan, Yunqiao Yang, Chen Ma

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: Accepted to AAAI2026

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽæ²™æ™®åˆ©å€¼ä¼˜åŒ–çš„è‡ªè§£é‡Šæ¡†æž¶ï¼Œä»¥è§£å†³è§†è§‰æ¨¡åž‹å¯è§£é‡Šæ€§ä¸Žæ€§èƒ½å…¼å®¹æ€§çš„å¹³è¡¡é—®é¢˜**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **è§†è§‰é‡Œç¨‹è®¡** **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `å¯è§£é‡Šäººå·¥æ™ºèƒ½` `æ²™æ™®åˆ©å€¼` `è‡ªè§£é‡Šç¥žç»ç½‘ç»œ` `è§†è§‰æ¨¡åž‹` `è¾…åŠ©ä»»åŠ¡å­¦ä¹ ` `å›¾åƒå—åˆ†é…` `æ¨¡åž‹é€æ˜Žåº¦` `æ€§èƒ½å…¼å®¹æ€§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•å­˜åœ¨å±€é™æ€§ï¼šäº‹åŽè§£é‡Šæ–¹æ³•éš¾ä»¥å¿ å®žåæ˜ æ¨¡åž‹è¡Œä¸ºï¼Œè‡ªè§£é‡Šç¥žç»ç½‘ç»œç‰ºç‰²æ€§èƒ½ä¸Žå…¼å®¹æ€§ã€‚
2. æå‡ºè‡ªè§£é‡Šæ¡†æž¶ï¼Œé›†æˆæ²™æ™®åˆ©å€¼ä¼°è®¡ä½œä¸ºè¾…åŠ©ä»»åŠ¡ï¼Œå®žçŽ°é¢„æµ‹åˆ†æ•°å…¬å¹³åˆ†é…ä¸Žç»“æž„å¾®è°ƒã€‚
3. åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å®žçŽ°æœ€å…ˆè¿›çš„å¯è§£é‡Šæ€§ï¼ŒåŒæ—¶ä¿æŒæ¨¡åž‹æ€§èƒ½ä¸Žå…¼å®¹æ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ·±åº¦ç¥žç»ç½‘ç»œåœ¨å„ç§é¢†åŸŸè¡¨çŽ°å‡ºè‰²ï¼Œä½†å…¶å†³ç­–è¿‡ç¨‹ä»ä¸é€æ˜Žã€‚å°½ç®¡è®¸å¤šè§£é‡Šæ–¹æ³•è‡´åŠ›äºŽæ­ç¤ºæ·±åº¦ç¥žç»ç½‘ç»œçš„æ¨¡ç³Šæ€§ï¼Œä½†å®ƒä»¬å­˜åœ¨æ˜¾è‘—å±€é™æ€§ï¼šäº‹åŽè§£é‡Šæ–¹æ³•å¾€å¾€éš¾ä»¥å¿ å®žåæ˜ æ¨¡åž‹è¡Œä¸ºï¼Œè€Œè‡ªè§£é‡Šç¥žç»ç½‘ç»œå› å…¶ä¸“é—¨æž¶æž„è®¾è®¡è€Œç‰ºç‰²äº†æ€§èƒ½å’Œå…¼å®¹æ€§ã€‚ä¸ºè§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„è‡ªè§£é‡Šæ¡†æž¶ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å°†æ²™æ™®åˆ©å€¼ä¼°è®¡ä½œä¸ºè¾…åŠ©ä»»åŠ¡é›†æˆï¼Œå®žçŽ°äº†ä¸¤ä¸ªå…³é”®è¿›å±•ï¼š1ï¼‰å°†æ¨¡åž‹é¢„æµ‹åˆ†æ•°å…¬å¹³åˆ†é…ç»™å›¾åƒå—ï¼Œç¡®ä¿è§£é‡Šä¸Žæ¨¡åž‹çš„å†³ç­–é€»è¾‘å†…åœ¨ä¸€è‡´ï¼›2ï¼‰é€šè¿‡å¾®å°çš„ç»“æž„ä¿®æ”¹å¢žå¼ºå¯è§£é‡Šæ€§ï¼ŒåŒæ—¶ä¿æŒæ¨¡åž‹æ€§èƒ½å’Œå…¼å®¹æ€§ã€‚åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®žéªŒè¡¨æ˜Žï¼Œæˆ‘ä»¬çš„æ–¹æ³•å®žçŽ°äº†æœ€å…ˆè¿›çš„å¯è§£é‡Šæ€§ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æ·±åº¦ç¥žç»ç½‘ç»œå†³ç­–è¿‡ç¨‹ä¸é€æ˜Žçš„é—®é¢˜ï¼ŒçŽ°æœ‰æ–¹æ³•å­˜åœ¨ä¸¤å¤§ç—›ç‚¹ï¼šäº‹åŽè§£é‡Šæ–¹æ³•ï¼ˆå¦‚LIMEã€SHAPï¼‰éš¾ä»¥å¿ å®žåæ˜ æ¨¡åž‹å†…éƒ¨é€»è¾‘ï¼Œå¯èƒ½å¯¼è‡´è¯¯å¯¼æ€§è§£é‡Šï¼›è‡ªè§£é‡Šç¥žç»ç½‘ç»œï¼ˆå¦‚æ³¨æ„åŠ›æœºåˆ¶æ¨¡åž‹ï¼‰é€šè¿‡ä¸“é—¨æž¶æž„å®žçŽ°å¯è§£é‡Šæ€§ï¼Œä½†å¾€å¾€ç‰ºç‰²æ¨¡åž‹æ€§èƒ½ï¼ˆå¦‚å‡†ç¡®çŽ‡ä¸‹é™ï¼‰å’Œå…¼å®¹æ€§ï¼ˆéš¾ä»¥é›†æˆåˆ°çŽ°æœ‰æ¨¡åž‹ä¸­ï¼‰ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºå°†æ²™æ™®åˆ©å€¼ä¼°è®¡ä½œä¸ºè®­ç»ƒè¿‡ç¨‹ä¸­çš„è¾…åŠ©ä»»åŠ¡ï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨æ²™æ™®åˆ©å€¼çš„å…¬å¹³åˆ†é…ç‰¹æ€§ï¼Œå°†æ¨¡åž‹é¢„æµ‹åˆ†æ•°åˆç†åˆ†é…ç»™è¾“å…¥å›¾åƒå—ï¼Œä»Žè€Œç¡®ä¿è§£é‡Šä¸Žæ¨¡åž‹å†³ç­–é€»è¾‘å†…åœ¨ä¸€è‡´ã€‚è¿™æ ·è®¾è®¡æ˜¯å› ä¸ºæ²™æ™®åˆ©å€¼åŸºäºŽåˆä½œåšå¼ˆè®ºï¼Œèƒ½å®¢è§‚è¡¡é‡æ¯ä¸ªç‰¹å¾å¯¹é¢„æµ‹çš„è´¡çŒ®ï¼Œé¿å…äº†äº‹åŽè§£é‡Šçš„åå·®ï¼ŒåŒæ—¶é€šè¿‡è¾…åŠ©ä»»åŠ¡è€Œéžä¸“é—¨æž¶æž„ï¼Œæœ€å°åŒ–å¯¹æ€§èƒ½çš„å½±å“ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æž¶æž„åŒ…æ‹¬ä¸€ä¸ªä¸»ä»»åŠ¡ç½‘ç»œï¼ˆå¦‚CNNç”¨äºŽå›¾åƒåˆ†ç±»ï¼‰å’Œä¸€ä¸ªè¾…åŠ©è§£é‡Šæ¨¡å—ã€‚æµç¨‹åˆ†ä¸ºä¸‰ä¸ªé˜¶æ®µï¼šé¦–å…ˆï¼Œè¾“å…¥å›¾åƒè¢«åˆ†å‰²æˆå¤šä¸ªå—ï¼ˆpatchesï¼‰ï¼›å…¶æ¬¡ï¼Œä¸»ç½‘ç»œè¿›è¡Œç‰¹å¾æå–å’Œé¢„æµ‹ï¼ŒåŒæ—¶è¾…åŠ©æ¨¡å—ä¼°è®¡æ¯ä¸ªå›¾åƒå—çš„æ²™æ™®åˆ©å€¼ï¼›æœ€åŽï¼Œé€šè¿‡è”åˆä¼˜åŒ–ä¸»ä»»åŠ¡æŸå¤±å’Œæ²™æ™®åˆ©å€¼ä¼°è®¡æŸå¤±ï¼Œè®­ç»ƒæ¨¡åž‹ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬ç‰¹å¾æå–å™¨ã€é¢„æµ‹å¤´å’Œæ²™æ™®åˆ©å€¼ä¼°è®¡å™¨ï¼ŒåŽè€…å¯èƒ½åŸºäºŽé‡‡æ ·æˆ–è¿‘ä¼¼ç®—æ³•å®žçŽ°é«˜æ•ˆè®¡ç®—ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°æ˜¯å°†æ²™æ™®åˆ©å€¼ä¼°è®¡é›†æˆåˆ°è®­ç»ƒè¿‡ç¨‹ä¸­ä½œä¸ºè¾…åŠ©ä»»åŠ¡ï¼Œè€Œéžäº‹åŽåº”ç”¨ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºŽï¼šç›¸æ¯”äº‹åŽè§£é‡Šæ–¹æ³•ï¼Œå®ƒç¡®ä¿äº†è§£é‡Šçš„å¿ å®žæ€§ï¼ˆfaithfulnessï¼‰ï¼Œå› ä¸ºè§£é‡Šæ˜¯æ¨¡åž‹è®­ç»ƒçš„ä¸€éƒ¨åˆ†ï¼›ç›¸æ¯”è‡ªè§£é‡Šç¥žç»ç½‘ç»œï¼Œå®ƒé€šè¿‡å¾®å°ç»“æž„ä¿®æ”¹ï¼ˆå¦‚æ·»åŠ è¾…åŠ©æ¨¡å—ï¼‰è€Œéžå½»åº•æž¶æž„æ”¹å˜ï¼Œä¿æŒäº†é«˜æ€§èƒ½å’Œå…¼å®¹æ€§ï¼Œæ˜“äºŽéƒ¨ç½²åˆ°çŽ°æœ‰è§†è§‰æ¨¡åž‹ä¸­ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®å‚æ•°åŒ…æ‹¬å›¾åƒå—çš„å¤§å°å’Œæ•°é‡ï¼Œå½±å“è§£é‡Šçš„ç²’åº¦ï¼›æŸå¤±å‡½æ•°ç»“åˆäº†ä¸»ä»»åŠ¡æŸå¤±ï¼ˆå¦‚äº¤å‰ç†µæŸå¤±ï¼‰å’Œæ²™æ™®åˆ©å€¼ä¼°è®¡æŸå¤±ï¼ˆå¦‚å‡æ–¹è¯¯å·®æŸå¤±ï¼‰ï¼Œé€šè¿‡æƒé‡å‚æ•°å¹³è¡¡å¯è§£é‡Šæ€§ä¸Žæ€§èƒ½ï¼›ç½‘ç»œç»“æž„ä¸Šï¼Œä¸»ç½‘ç»œå¯åŸºäºŽæ ‡å‡†CNNï¼ˆå¦‚ResNetï¼‰ï¼Œè¾…åŠ©æ¨¡å—å¯èƒ½ä½¿ç”¨è½»é‡çº§ç½‘ç»œæˆ–é‡‡æ ·ç­–ç•¥æ¥ä¼°è®¡æ²™æ™®åˆ©å€¼ï¼Œä»¥å‡å°‘è®¡ç®—å¼€é”€ã€‚å…·ä½“ç»†èŠ‚å¦‚æŸå¤±å‡½æ•°æƒé‡å’Œæ²™æ™®åˆ©å€¼ä¼°è®¡ç®—æ³•åœ¨è®ºæ–‡ä¸­æœªè¯¦ç»†è¯´æ˜Žï¼Œéœ€å‚è€ƒå®žéªŒéƒ¨åˆ†ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ï¼ˆå¦‚ImageNetã€CIFAR-10ï¼‰ä¸Šï¼Œè¯¥æ–¹æ³•å®žçŽ°äº†æœ€å…ˆè¿›çš„å¯è§£é‡Šæ€§ï¼Œå…·ä½“æ€§èƒ½æ•°æ®æœªçŸ¥ï¼Œä½†è®ºæ–‡æåˆ°é€šè¿‡å¾®å°ç»“æž„ä¿®æ”¹ï¼Œåœ¨ä¿æŒæ¨¡åž‹å‡†ç¡®çŽ‡ï¼ˆä¸ŽåŸºçº¿æ¨¡åž‹ç›¸æ¯”æ— æ˜Žæ˜¾ä¸‹é™ï¼‰çš„åŒæ—¶ï¼Œæ˜¾è‘—æå‡è§£é‡Šå¿ å®žæ€§ã€‚å¯¹æ¯”åŸºçº¿åŒ…æ‹¬äº‹åŽè§£é‡Šæ–¹æ³•ï¼ˆå¦‚Grad-CAMï¼‰å’Œè‡ªè§£é‡Šç¥žç»ç½‘ç»œï¼Œæå‡å¹…åº¦ä½“çŽ°åœ¨è§£é‡Šè´¨é‡æŒ‡æ ‡ï¼ˆå¦‚ä¿çœŸåº¦åˆ†æ•°ï¼‰ä¸Šè¾¾åˆ°æœ€ä¼˜ï¼Œå…·ä½“æ•°å€¼éœ€å‚è€ƒè®ºæ–‡å®žéªŒéƒ¨åˆ†ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨åŒ»ç–—å½±åƒåˆ†æžã€è‡ªåŠ¨é©¾é©¶ã€å®‰é˜²ç›‘æŽ§ç­‰é¢†åŸŸå…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ï¼Œä¾‹å¦‚å¸®åŠ©åŒ»ç”Ÿç†è§£AIè¯Šæ–­ä¾æ®ã€æå‡è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„é€æ˜Žå†³ç­–ã€å¢žå¼ºç›‘æŽ§æ¨¡åž‹çš„å¯ä¿¡åº¦ã€‚å®žé™…ä»·å€¼åœ¨äºŽå¹³è¡¡æ¨¡åž‹æ€§èƒ½ä¸Žå¯è§£é‡Šæ€§ï¼ŒæŽ¨åŠ¨å¯ä¿¡AIå‘å±•ï¼Œæœªæ¥å¯èƒ½å½±å“æ¨¡åž‹éƒ¨ç½²æ ‡å‡†ï¼Œä¿ƒè¿›å¯è§£é‡Šæ€§æˆä¸ºè§†è§‰æ¨¡åž‹è®¾è®¡çš„æ ¸å¿ƒè¦ç´ ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Deep neural networks have demonstrated remarkable performance across various domains, yet their decision-making processes remain opaque. Although many explanation methods are dedicated to bringing the obscurity of DNNs to light, they exhibit significant limitations: post-hoc explanation methods often struggle to faithfully reflect model behaviors, while self-explaining neural networks sacrifice performance and compatibility due to their specialized architectural designs. To address these challenges, we propose a novel self-explaining framework that integrates Shapley value estimation as an auxiliary task during training, which achieves two key advancements: 1) a fair allocation of the model prediction scores to image patches, ensuring explanations inherently align with the model's decision logic, and 2) enhanced interpretability with minor structural modifications, preserving model performance and compatibility. Extensive experiments on multiple benchmarks demonstrate that our method achieves state-of-the-art interpretability.

