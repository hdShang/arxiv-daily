---
layout: default
title: Robust Single-shot Structured Light 3D Imaging via Neural Feature Decoding
---

# Robust Single-shot Structured Light 3D Imaging via Neural Feature Decoding

**arXiv**: [2512.14028v1](https://arxiv.org/abs/2512.14028) | [PDF](https://arxiv.org/pdf/2512.14028.pdf)

**ä½œè€…**: Jiaheng Li, Qiyu Dai, Lihan Li, Praneeth Chakravarthula, He Sun, Baoquan Chen, Wenzheng Chen

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**ðŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://namisntimpot.github.io/NSLweb/)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽç¥žç»ç‰¹å¾è§£ç çš„é²æ£’å•ç›®ç»“æž„å…‰3Dæˆåƒæ–¹æ³•ï¼Œæå‡å¤æ‚åœºæ™¯ä¸‹çš„æ·±åº¦ä¼°è®¡ç²¾åº¦ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)** **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸ŽåŒ¹é… (Video Extraction & Matching)**

**å…³é”®è¯**: `ç»“æž„å…‰ä¸‰ç»´æˆåƒ` `ç¥žç»ç‰¹å¾è§£ç ` `ç‰¹å¾ç©ºé—´åŒ¹é…` `æ·±åº¦ä¼°è®¡` `å•ç›®è§†è§‰`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿç»“æž„å…‰æ–¹æ³•åœ¨å¤æ‚åœºæ™¯ä¸‹é²æ£’æ€§ä¸è¶³ï¼Œä¾èµ–åƒç´ åŸŸåŒ¹é…æ˜“å—é®æŒ¡å’Œè¡¨é¢å±žæ€§å½±å“ã€‚
2. æå‡ºåŸºäºŽç¥žç»ç‰¹å¾è§£ç çš„æ¡†æž¶ï¼Œåœ¨ç‰¹å¾ç©ºé—´è¿›è¡Œå¯¹åº”å…³ç³»åŒ¹é…ï¼Œèžå…¥å‡ ä½•å…ˆéªŒï¼Œæå‡é²æ£’æ€§ã€‚
3. åˆ©ç”¨åˆæˆæ•°æ®è®­ç»ƒï¼Œæ— éœ€çœŸå®žæ•°æ®ï¼Œå®žéªŒè¡¨æ˜Žä¼˜äºŽå•†ä¸šç³»ç»Ÿå’Œè¢«åŠ¨ç«‹ä½“æ–¹æ³•ï¼Œæ³›åŒ–æ€§å¼ºã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ç ”ç©¶äº†ä½¿ç”¨å•ç›®ç»“æž„å…‰ç³»ç»Ÿè¿›è¡Œä¸»åŠ¨3Dæˆåƒçš„é—®é¢˜ï¼Œè¯¥ç³»ç»Ÿå¹¿æ³›åº”ç”¨äºŽå•†ä¸š3Dä¼ æ„Ÿè®¾å¤‡ï¼Œå¦‚Apple Face IDå’ŒIntel RealSenseã€‚ä¼ ç»Ÿçš„ç»“æž„å…‰æ–¹æ³•é€šå¸¸é€šè¿‡åƒç´ åŸŸåŒ¹é…ç®—æ³•è§£ç æ·±åº¦å¯¹åº”å…³ç³»ï¼Œå¯¼è‡´åœ¨é®æŒ¡ã€ç²¾ç»†ç»“æž„ç»†èŠ‚å’Œéžæœ—ä¼¯è¡¨é¢ç­‰å…·æœ‰æŒ‘æˆ˜æ€§çš„åœºæ™¯ä¸‹é²æ£’æ€§æœ‰é™ã€‚å—ç¥žç»ç‰¹å¾åŒ¹é…æœ€æ–°è¿›å±•çš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºŽå­¦ä¹ çš„ç»“æž„å…‰è§£ç æ¡†æž¶ï¼Œè¯¥æ¡†æž¶åœ¨ç‰¹å¾ç©ºé—´è€Œéžè„†å¼±çš„åƒç´ åŸŸä¸­æ‰§è¡Œé²æ£’çš„å¯¹åº”å…³ç³»åŒ¹é…ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä»ŽæŠ•å½±å›¾æ¡ˆå’Œæ•èŽ·çš„çº¢å¤–ï¼ˆIRï¼‰å›¾åƒä¸­æå–ç¥žç»ç‰¹å¾ï¼Œé€šè¿‡åœ¨ç‰¹å¾ç©ºé—´ä¸­æž„å»ºä»£ä»·ä½“æ¥æ˜¾å¼åœ°ç»“åˆå®ƒä»¬çš„å‡ ä½•å…ˆéªŒï¼Œä»Žè€Œå®žçŽ°æ¯”åƒç´ åŸŸè§£ç æ–¹æ³•æ›´å¥½çš„æ€§èƒ½ã€‚ä¸ºäº†è¿›ä¸€æ­¥æé«˜æ·±åº¦è´¨é‡ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªæ·±åº¦ç»†åŒ–æ¨¡å—ï¼Œè¯¥æ¨¡å—åˆ©ç”¨æ¥è‡ªå¤§è§„æ¨¡å•ç›®æ·±åº¦ä¼°è®¡æ¨¡åž‹çš„å¼ºå¤§å…ˆéªŒï¼Œæ”¹å–„äº†ç²¾ç»†ç»†èŠ‚æ¢å¤å’Œå…¨å±€ç»“æž„ä¸€è‡´æ€§ã€‚ä¸ºäº†ä¿ƒè¿›æœ‰æ•ˆçš„å­¦ä¹ ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªåŸºäºŽç‰©ç†çš„ç»“æž„å…‰æ¸²æŸ“ç®¡çº¿ï¼Œç”Ÿæˆäº†è¿‘ä¸€ç™¾ä¸‡ä¸ªå…·æœ‰ä¸åŒç‰©ä½“å’Œææ–™çš„åˆæˆå›¾æ¡ˆ-å›¾åƒå¯¹ï¼Œç”¨äºŽå®¤å†…çŽ¯å¢ƒã€‚å®žéªŒè¡¨æ˜Žï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä»…åœ¨å…·æœ‰å¤šä¸ªç»“æž„å…‰å›¾æ¡ˆçš„åˆæˆæ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¯ä»¥å¾ˆå¥½åœ°æŽ¨å¹¿åˆ°çœŸå®žä¸–ç•Œçš„å®¤å†…çŽ¯å¢ƒï¼Œæœ‰æ•ˆåœ°å¤„ç†å„ç§å›¾æ¡ˆç±»åž‹è€Œæ— éœ€é‡æ–°è®­ç»ƒï¼Œå¹¶ä¸”å§‹ç»ˆä¼˜äºŽå•†ä¸šç»“æž„å…‰ç³»ç»Ÿå’ŒåŸºäºŽè¢«åŠ¨ç«‹ä½“RGBçš„æ·±åº¦ä¼°è®¡æ–¹æ³•ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å•ç›®ç»“æž„å…‰3Dæˆåƒåœ¨å¤æ‚åœºæ™¯ä¸‹ï¼Œç”±äºŽé®æŒ¡ã€ç²¾ç»†ç»“æž„å’Œéžæœ—ä¼¯è¡¨é¢ç­‰å› ç´ å¯¼è‡´çš„æ·±åº¦ä¼°è®¡ç²¾åº¦ä¸‹é™é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•ä¾èµ–åƒç´ åŸŸçš„åŒ¹é…ï¼Œå®¹æ˜“å—åˆ°å™ªå£°å’Œå…‰ç…§å˜åŒ–çš„å½±å“ï¼Œé²æ£’æ€§è¾ƒå·®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†åƒç´ åŸŸçš„åŒ¹é…é—®é¢˜è½¬åŒ–ä¸ºç‰¹å¾ç©ºé—´çš„åŒ¹é…é—®é¢˜ã€‚é€šè¿‡æå–æŠ•å½±å›¾æ¡ˆå’Œçº¢å¤–å›¾åƒçš„ç¥žç»ç‰¹å¾ï¼Œå¹¶åœ¨ç‰¹å¾ç©ºé—´æž„å»ºä»£ä»·ä½“ï¼Œåˆ©ç”¨å­¦ä¹ åˆ°çš„ç‰¹å¾è¡¨ç¤ºè¿›è¡Œé²æ£’çš„å¯¹åº”å…³ç³»åŒ¹é…ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨å›¾åƒçš„å‡ ä½•å…ˆéªŒä¿¡æ¯ï¼Œä»Žè€Œæé«˜æ·±åº¦ä¼°è®¡çš„ç²¾åº¦å’Œé²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šè¯¥æ–¹æ³•ä¸»è¦åŒ…å«ä¸‰ä¸ªæ¨¡å—ï¼šç‰¹å¾æå–æ¨¡å—ã€ç‰¹å¾ç©ºé—´ä»£ä»·ä½“æž„å»ºæ¨¡å—å’Œæ·±åº¦ç»†åŒ–æ¨¡å—ã€‚é¦–å…ˆï¼Œä½¿ç”¨ç¥žç»ç½‘ç»œæå–æŠ•å½±å›¾æ¡ˆå’Œçº¢å¤–å›¾åƒçš„ç¥žç»ç‰¹å¾ã€‚ç„¶åŽï¼Œåœ¨ç‰¹å¾ç©ºé—´ä¸­æž„å»ºä»£ä»·ä½“ï¼Œç”¨äºŽè¡¡é‡ä¸åŒåƒç´ ä¹‹é—´çš„å¯¹åº”å…³ç³»ã€‚æœ€åŽï¼Œåˆ©ç”¨æ·±åº¦ç»†åŒ–æ¨¡å—ï¼Œç»“åˆå•ç›®æ·±åº¦ä¼°è®¡æ¨¡åž‹çš„å…ˆéªŒçŸ¥è¯†ï¼Œè¿›ä¸€æ­¥æé«˜æ·±åº¦å›¾çš„è´¨é‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºŽå°†ç»“æž„å…‰è§£ç é—®é¢˜ä»Žåƒç´ åŸŸè½¬ç§»åˆ°ç‰¹å¾åŸŸã€‚é€šè¿‡å­¦ä¹ åˆ°çš„ç¥žç»ç‰¹å¾ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰å›¾åƒçš„ç»“æž„ä¿¡æ¯å’Œå‡ ä½•å…³ç³»ï¼Œä»Žè€Œå®žçŽ°æ›´é²æ£’çš„å¯¹åº”å…³ç³»åŒ¹é…ã€‚æ­¤å¤–ï¼Œåˆ©ç”¨å•ç›®æ·±åº¦ä¼°è®¡æ¨¡åž‹çš„å…ˆéªŒçŸ¥è¯†è¿›è¡Œæ·±åº¦ç»†åŒ–ï¼Œä¹Ÿè¿›ä¸€æ­¥æé«˜äº†æ·±åº¦å›¾çš„è´¨é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä½¿ç”¨åŸºäºŽç‰©ç†çš„æ¸²æŸ“ç®¡çº¿ç”Ÿæˆå¤§è§„æ¨¡åˆæˆæ•°æ®é›†ï¼Œç”¨äºŽè®­ç»ƒç¥žç»ç½‘ç»œã€‚ä»£ä»·ä½“æž„å»ºæ¨¡å—é‡‡ç”¨å¤šå°ºåº¦ç‰¹å¾èžåˆçš„æ–¹å¼ï¼Œæé«˜åŒ¹é…çš„å‡†ç¡®æ€§ã€‚æ·±åº¦ç»†åŒ–æ¨¡å—åˆ©ç”¨é¢„è®­ç»ƒçš„å•ç›®æ·±åº¦ä¼°è®¡æ¨¡åž‹ä½œä¸ºå…ˆéªŒï¼Œå¹¶è®¾è®¡äº†ä¸“é—¨çš„æŸå¤±å‡½æ•°æ¥çº¦æŸæ·±åº¦å›¾çš„å¹³æ»‘æ€§å’Œä¸€è‡´æ€§ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

è¯¥æ–¹æ³•åœ¨åˆæˆæ•°æ®ä¸Šè®­ç»ƒï¼Œå¹¶åœ¨çœŸå®žä¸–ç•Œçš„å®¤å†…çŽ¯å¢ƒä¸­è¿›è¡Œäº†æµ‹è¯•ï¼Œç»“æžœè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨å„ç§ç»“æž„å…‰å›¾æ¡ˆç±»åž‹ä¸Šéƒ½è¡¨çŽ°è‰¯å¥½ï¼Œæ— éœ€é‡æ–°è®­ç»ƒã€‚ä¸Žå•†ä¸šç»“æž„å…‰ç³»ç»Ÿå’ŒåŸºäºŽè¢«åŠ¨ç«‹ä½“RGBçš„æ·±åº¦ä¼°è®¡æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨æ·±åº¦ä¼°è®¡ç²¾åº¦å’Œé²æ£’æ€§æ–¹é¢å‡æœ‰æ˜¾è‘—æå‡ã€‚å…·ä½“æ€§èƒ½æ•°æ®æœªçŸ¥ï¼Œä½†è®ºæ–‡å¼ºè°ƒå…¶ä¸€è‡´æ€§ä¼˜äºŽå…¶ä»–æ–¹æ³•ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯å¹¿æ³›åº”ç”¨äºŽäººè„¸è¯†åˆ«ã€ä¸‰ç»´é‡å»ºã€æœºå™¨äººå¯¼èˆªã€å·¥ä¸šæ£€æµ‹ç­‰é¢†åŸŸã€‚å°¤å…¶åœ¨å¯¹ç²¾åº¦å’Œé²æ£’æ€§è¦æ±‚è¾ƒé«˜çš„åœºæ™¯ä¸‹ï¼Œä¾‹å¦‚ç§»åŠ¨è®¾å¤‡çš„3Däººè„¸è§£é”ã€å®¤å†…æœåŠ¡æœºå™¨äººçš„çŽ¯å¢ƒæ„ŸçŸ¥ç­‰ï¼Œå…·æœ‰é‡è¦çš„åº”ç”¨ä»·å€¼ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›è¿›ä¸€æ­¥æ‰©å±•åˆ°å®¤å¤–çŽ¯å¢ƒï¼Œå¹¶ä¸Žå…¶ä»–ä¼ æ„Ÿå™¨èžåˆï¼Œå®žçŽ°æ›´ç²¾ç¡®ã€æ›´å¯é çš„ä¸‰ç»´æ„ŸçŸ¥ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We consider the problem of active 3D imaging using single-shot structured light systems, which are widely employed in commercial 3D sensing devices such as Apple Face ID and Intel RealSense. Traditional structured light methods typically decode depth correspondences through pixel-domain matching algorithms, resulting in limited robustness under challenging scenarios like occlusions, fine-structured details, and non-Lambertian surfaces. Inspired by recent advances in neural feature matching, we propose a learning-based structured light decoding framework that performs robust correspondence matching within feature space rather than the fragile pixel domain. Our method extracts neural features from the projected patterns and captured infrared (IR) images, explicitly incorporating their geometric priors by building cost volumes in feature space, achieving substantial performance improvements over pixel-domain decoding approaches. To further enhance depth quality, we introduce a depth refinement module that leverages strong priors from large-scale monocular depth estimation models, improving fine detail recovery and global structural coherence. To facilitate effective learning, we develop a physically-based structured light rendering pipeline, generating nearly one million synthetic pattern-image pairs with diverse objects and materials for indoor settings. Experiments demonstrate that our method, trained exclusively on synthetic data with multiple structured light patterns, generalizes well to real-world indoor environments, effectively processes various pattern types without retraining, and consistently outperforms both commercial structured light systems and passive stereo RGB-based depth estimation methods. Project page: https://namisntimpot.github.io/NSLweb/.

