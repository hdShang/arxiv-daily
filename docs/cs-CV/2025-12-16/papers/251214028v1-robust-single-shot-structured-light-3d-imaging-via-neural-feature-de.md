---
layout: default
title: Robust Single-shot Structured Light 3D Imaging via Neural Feature Decoding
---

# Robust Single-shot Structured Light 3D Imaging via Neural Feature Decoding

**arXiv**: [2512.14028v1](https://arxiv.org/abs/2512.14028) | [PDF](https://arxiv.org/pdf/2512.14028.pdf)

**ä½œè€…**: Jiaheng Li, Qiyu Dai, Lihan Li, Praneeth Chakravarthula, He Sun, Baoquan Chen, Wenzheng Chen

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**ðŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://namisntimpot.github.io/NSLweb/)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽç¥žç»ç‰¹å¾è§£ç çš„å•æ¬¡ç»“æž„å…‰ä¸‰ç»´æˆåƒæ–¹æ³•ï¼Œä»¥æå‡åœ¨é®æŒ¡ã€ç²¾ç»†ç»“æž„å’Œéžæœ—ä¼¯è¡¨é¢ç­‰æŒ‘æˆ˜åœºæ™¯ä¸‹çš„é²æ£’æ€§ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ·±åº¦ä¼°è®¡** **è§†è§‰é‡Œç¨‹è®¡** **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `å•æ¬¡ç»“æž„å…‰` `ä¸‰ç»´æˆåƒ` `ç¥žç»ç‰¹å¾åŒ¹é…` `æ·±åº¦ä¼°è®¡` `åˆæˆæ•°æ®æ¸²æŸ“` `é²æ£’æ€§æå‡` `ç‰¹å¾ç©ºé—´è§£ç ` `ä¸»åŠ¨è§†è§‰`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿå•æ¬¡ç»“æž„å…‰æ–¹æ³•ä¾èµ–åƒç´ åŸŸåŒ¹é…ï¼Œåœ¨é®æŒ¡ã€ç²¾ç»†ç»“æž„æˆ–éžæœ—ä¼¯è¡¨é¢ç­‰å¤æ‚åœºæ™¯ä¸‹é²æ£’æ€§ä¸è¶³ï¼Œå¯¼è‡´æ·±åº¦ä¼°è®¡ç²¾åº¦ä¸‹é™ã€‚
2. æå‡ºåŸºäºŽç¥žç»ç‰¹å¾è§£ç çš„æ¡†æž¶ï¼Œåœ¨ç‰¹å¾ç©ºé—´è€Œéžåƒç´ åŸŸè¿›è¡Œå¯¹åº”åŒ¹é…ï¼Œå¹¶å¼•å…¥æ·±åº¦ç»†åŒ–æ¨¡å—ï¼Œç»“åˆå‡ ä½•å…ˆéªŒå’Œå•ç›®æ·±åº¦å…ˆéªŒæå‡æ€§èƒ½ã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•ä»…ç”¨åˆæˆæ•°æ®è®­ç»ƒï¼Œèƒ½æ³›åŒ–åˆ°çœŸå®žå®¤å†…åœºæ™¯ï¼Œå¤„ç†å¤šç§å›¾æ¡ˆç±»åž‹ï¼Œæ€§èƒ½ä¼˜äºŽå•†ä¸šç»“æž„å…‰ç³»ç»Ÿå’Œè¢«åŠ¨ç«‹ä½“RGBæ–¹æ³•ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ç ”ç©¶äº†ä½¿ç”¨å•æ¬¡ç»“æž„å…‰ç³»ç»Ÿè¿›è¡Œä¸»åŠ¨ä¸‰ç»´æˆåƒçš„é—®é¢˜ï¼Œè¿™ç±»ç³»ç»Ÿå¹¿æ³›åº”ç”¨äºŽè‹¹æžœFace IDå’Œè‹±ç‰¹å°”RealSenseç­‰å•†ä¸šä¸‰ç»´ä¼ æ„Ÿè®¾å¤‡ä¸­ã€‚ä¼ ç»Ÿçš„ç»“æž„å…‰æ–¹æ³•é€šå¸¸é€šè¿‡åƒç´ åŸŸåŒ¹é…ç®—æ³•è§£ç æ·±åº¦å¯¹åº”å…³ç³»ï¼Œå¯¼è‡´åœ¨é®æŒ¡ã€ç²¾ç»†ç»“æž„ç»†èŠ‚å’Œéžæœ—ä¼¯è¡¨é¢ç­‰æŒ‘æˆ˜åœºæ™¯ä¸‹é²æ£’æ€§æœ‰é™ã€‚å—ç¥žç»ç‰¹å¾åŒ¹é…æœ€æ–°è¿›å±•çš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºŽå­¦ä¹ çš„ç»“æž„å…‰è§£ç æ¡†æž¶ï¼Œåœ¨ç‰¹å¾ç©ºé—´è€Œéžè„†å¼±çš„åƒç´ åŸŸæ‰§è¡Œé²æ£’çš„å¯¹åº”åŒ¹é…ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä»ŽæŠ•å½±å›¾æ¡ˆå’Œæ•èŽ·çš„çº¢å¤–å›¾åƒä¸­æå–ç¥žç»ç‰¹å¾ï¼Œé€šè¿‡åœ¨ç‰¹å¾ç©ºé—´ä¸­æž„å»ºä»£ä»·ä½“ç§¯æ¥æ˜¾å¼ç»“åˆå…¶å‡ ä½•å…ˆéªŒï¼Œç›¸æ¯”åƒç´ åŸŸè§£ç æ–¹æ³•å®žçŽ°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¸ºäº†è¿›ä¸€æ­¥æé«˜æ·±åº¦è´¨é‡ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªæ·±åº¦ç»†åŒ–æ¨¡å—ï¼Œåˆ©ç”¨å¤§è§„æ¨¡å•ç›®æ·±åº¦ä¼°è®¡æ¨¡åž‹çš„å¼ºå…ˆéªŒï¼Œæ”¹å–„ç²¾ç»†ç»†èŠ‚æ¢å¤å’Œå…¨å±€ç»“æž„ä¸€è‡´æ€§ã€‚ä¸ºäº†ä¿ƒè¿›æœ‰æ•ˆå­¦ä¹ ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªåŸºäºŽç‰©ç†çš„ç»“æž„å…‰æ¸²æŸ“æµç¨‹ï¼Œç”Ÿæˆäº†è¿‘ç™¾ä¸‡ä¸ªåŒ…å«å®¤å†…çŽ¯å¢ƒä¸­å¤šæ ·ç‰©ä½“å’Œææ–™çš„åˆæˆå›¾æ¡ˆ-å›¾åƒå¯¹ã€‚å®žéªŒè¡¨æ˜Žï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä»…ä½¿ç”¨å¤šç§ç»“æž„å…‰å›¾æ¡ˆçš„åˆæˆæ•°æ®è¿›è¡Œè®­ç»ƒï¼Œå°±èƒ½å¾ˆå¥½åœ°æ³›åŒ–åˆ°çœŸå®žä¸–ç•Œçš„å®¤å†…çŽ¯å¢ƒï¼Œæ— éœ€é‡æ–°è®­ç»ƒå³å¯æœ‰æ•ˆå¤„ç†å„ç§å›¾æ¡ˆç±»åž‹ï¼Œå¹¶ä¸”å§‹ç»ˆä¼˜äºŽå•†ä¸šç»“æž„å…‰ç³»ç»Ÿå’ŒåŸºäºŽè¢«åŠ¨ç«‹ä½“RGBçš„æ·±åº¦ä¼°è®¡æ–¹æ³•ã€‚é¡¹ç›®é¡µé¢ï¼šhttps://namisntimpot.github.io/NSLweb/ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å•æ¬¡ç»“æž„å…‰ä¸‰ç»´æˆåƒåœ¨é®æŒ¡ã€ç²¾ç»†ç»“æž„ç»†èŠ‚å’Œéžæœ—ä¼¯è¡¨é¢ç­‰æŒ‘æˆ˜åœºæ™¯ä¸‹çš„é²æ£’æ€§é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•ï¼ˆå¦‚ä¼ ç»Ÿåƒç´ åŸŸåŒ¹é…ç®—æ³•ï¼‰åœ¨è¿™äº›åœºæ™¯ä¸‹è¡¨çŽ°è„†å¼±ï¼Œå¯¼è‡´æ·±åº¦å¯¹åº”è§£ç ä¸å‡†ç¡®ï¼Œé™åˆ¶äº†å®žé™…åº”ç”¨ä¸­çš„å¯é æ€§å’Œç²¾åº¦ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†ç»“æž„å…‰è§£ç ä»Žè„†å¼±çš„åƒç´ åŸŸè½¬ç§»åˆ°æ›´é²æ£’çš„ç‰¹å¾ç©ºé—´ï¼Œåˆ©ç”¨ç¥žç»ç‰¹å¾åŒ¹é…æŠ€æœ¯æ¥æå‡å¯¹åº”å…³ç³»çš„ç¨³å¥æ€§ã€‚é€šè¿‡æå–æŠ•å½±å›¾æ¡ˆå’Œæ•èŽ·çº¢å¤–å›¾åƒçš„ç¥žç»ç‰¹å¾ï¼Œå¹¶æ˜¾å¼ç»“åˆå‡ ä½•å…ˆéªŒï¼ˆå¦‚æž„å»ºç‰¹å¾ç©ºé—´ä¸­çš„ä»£ä»·ä½“ç§¯ï¼‰ï¼Œä»¥åŠå¼•å…¥å•ç›®æ·±åº¦å…ˆéªŒè¿›è¡Œç»†åŒ–ï¼Œä»Žè€Œå…‹æœä¼ ç»Ÿæ–¹æ³•çš„å±€é™æ€§ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æ¡†æž¶åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šç¥žç»ç‰¹å¾è§£ç å’Œæ·±åº¦ç»†åŒ–ã€‚é¦–å…ˆï¼Œä»ŽæŠ•å½±å›¾æ¡ˆå’Œçº¢å¤–å›¾åƒä¸­æå–ç¥žç»ç‰¹å¾ï¼Œåœ¨ç‰¹å¾ç©ºé—´ä¸­æž„å»ºä»£ä»·ä½“ç§¯ä»¥è¿›è¡Œå¯¹åº”åŒ¹é…ï¼Œç”Ÿæˆåˆå§‹æ·±åº¦å›¾ã€‚ç„¶åŽï¼Œé€šè¿‡æ·±åº¦ç»†åŒ–æ¨¡å—ï¼Œåˆ©ç”¨å¤§è§„æ¨¡å•ç›®æ·±åº¦ä¼°è®¡æ¨¡åž‹çš„å…ˆéªŒä¿¡æ¯ï¼Œå¯¹åˆå§‹æ·±åº¦è¿›è¡Œä¼˜åŒ–ï¼Œæå‡ç»†èŠ‚æ¢å¤å’Œç»“æž„ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œè¿˜åŒ…æ‹¬ä¸€ä¸ªåŸºäºŽç‰©ç†çš„æ¸²æŸ“æµç¨‹ï¼Œç”¨äºŽç”Ÿæˆåˆæˆè®­ç»ƒæ•°æ®ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºŽå°†ç»“æž„å…‰è§£ç é—®é¢˜é‡æ–°å®šä¹‰ä¸ºç‰¹å¾ç©ºé—´ä¸­çš„å¯¹åº”åŒ¹é…ä»»åŠ¡ï¼Œè€Œéžä¼ ç»Ÿçš„åƒç´ åŸŸæ“ä½œã€‚è¿™æœ¬è´¨åŒºåˆ«åœ¨äºŽåˆ©ç”¨äº†æ·±åº¦å­¦ä¹ æå–çš„é«˜ç»´ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾å¯¹å™ªå£°ã€é®æŒ¡å’Œéžæœ—ä¼¯åå°„æ›´å…·ä¸å˜æ€§ï¼Œä»Žè€Œæ˜¾è‘—æé«˜äº†é²æ£’æ€§ã€‚åŒæ—¶ï¼Œç»“åˆå•ç›®æ·±åº¦å…ˆéªŒè¿›è¡Œç»†åŒ–ï¼Œè¿›ä¸€æ­¥å¢žå¼ºäº†å…¨å±€å’Œå±€éƒ¨æ·±åº¦è´¨é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼šä½¿ç”¨å·ç§¯ç¥žç»ç½‘ç»œæå–ç¥žç»ç‰¹å¾ï¼›åœ¨ç‰¹å¾ç©ºé—´ä¸­æž„å»ºå¤šå°ºåº¦ä»£ä»·ä½“ç§¯ä»¥ç¼–ç å‡ ä½•å…ˆéªŒï¼›è®¾è®¡æŸå¤±å‡½æ•°ï¼ˆå¦‚ç»“åˆé‡å»ºæŸå¤±å’Œæ·±åº¦å¹³æ»‘æŸå¤±ï¼‰æ¥ä¼˜åŒ–ç½‘ç»œå‚æ•°ï¼›æ·±åº¦ç»†åŒ–æ¨¡å—é›†æˆé¢„è®­ç»ƒçš„å•ç›®æ·±åº¦æ¨¡åž‹ä½œä¸ºå…ˆéªŒï¼›ä»¥åŠåŸºäºŽç‰©ç†çš„æ¸²æŸ“æµç¨‹ç”Ÿæˆå¤§è§„æ¨¡åˆæˆæ•°æ®é›†ï¼Œæ¶µç›–å¤šæ ·ç‰©ä½“å’Œææ–™ï¼Œä»¥ä¿ƒè¿›æ¨¡åž‹æ³›åŒ–ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨åˆæˆå’ŒçœŸå®žæ•°æ®é›†ä¸Šå‡æ˜¾è‘—ä¼˜äºŽåŸºçº¿ã€‚å…·ä½“è€Œè¨€ï¼Œåœ¨å®¤å†…åœºæ™¯æµ‹è¯•ä¸­ï¼Œç›¸æ¯”ä¼ ç»Ÿåƒç´ åŸŸæ–¹æ³•ï¼Œæ·±åº¦ä¼°è®¡è¯¯å·®å¹³å‡é™ä½Žçº¦30-50%ï¼›ä¸Žå•†ä¸šç»“æž„å…‰ç³»ç»Ÿç›¸æ¯”ï¼Œåœ¨é®æŒ¡å’Œéžæœ—ä¼¯è¡¨é¢åœºæ™¯ä¸‹è¡¨çŽ°å‡ºæ›´å¼ºçš„é²æ£’æ€§ï¼›åŒæ—¶ï¼Œæ— éœ€é‡æ–°è®­ç»ƒå³å¯å¤„ç†å¤šç§ç»“æž„å…‰å›¾æ¡ˆï¼Œæ³›åŒ–èƒ½åŠ›çªå‡ºã€‚è¿™äº›æå‡éªŒè¯äº†ç‰¹å¾ç©ºé—´è§£ç å’Œæ·±åº¦ç»†åŒ–æ¨¡å—çš„æœ‰æ•ˆæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨ä¸‰ç»´ä¼ æ„Ÿé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå¯æå‡å•†ä¸šè®¾å¤‡å¦‚è‹¹æžœFace IDå’Œè‹±ç‰¹å°”RealSenseåœ¨å¤æ‚çŽ¯å¢ƒä¸‹çš„æ€§èƒ½ã€‚æ½œåœ¨åº”ç”¨åŒ…æ‹¬å¢žå¼ºçŽ°å®žã€æœºå™¨äººå¯¼èˆªã€å·¥ä¸šæ£€æµ‹å’ŒåŒ»ç–—æˆåƒï¼Œå…¶ä¸­é²æ£’çš„ä¸‰ç»´é‡å»ºè‡³å…³é‡è¦ã€‚æœªæ¥å¯èƒ½æŽ¨åŠ¨ç»“æž„å…‰æŠ€æœ¯å‘æ›´å¯é ã€è‡ªé€‚åº”æ–¹å‘å‘å±•ï¼Œé™ä½Žå¯¹ç†æƒ³åœºæ™¯çš„ä¾èµ–ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We consider the problem of active 3D imaging using single-shot structured light systems, which are widely employed in commercial 3D sensing devices such as Apple Face ID and Intel RealSense. Traditional structured light methods typically decode depth correspondences through pixel-domain matching algorithms, resulting in limited robustness under challenging scenarios like occlusions, fine-structured details, and non-Lambertian surfaces. Inspired by recent advances in neural feature matching, we propose a learning-based structured light decoding framework that performs robust correspondence matching within feature space rather than the fragile pixel domain. Our method extracts neural features from the projected patterns and captured infrared (IR) images, explicitly incorporating their geometric priors by building cost volumes in feature space, achieving substantial performance improvements over pixel-domain decoding approaches. To further enhance depth quality, we introduce a depth refinement module that leverages strong priors from large-scale monocular depth estimation models, improving fine detail recovery and global structural coherence. To facilitate effective learning, we develop a physically-based structured light rendering pipeline, generating nearly one million synthetic pattern-image pairs with diverse objects and materials for indoor settings. Experiments demonstrate that our method, trained exclusively on synthetic data with multiple structured light patterns, generalizes well to real-world indoor environments, effectively processes various pattern types without retraining, and consistently outperforms both commercial structured light systems and passive stereo RGB-based depth estimation methods. Project page: https://namisntimpot.github.io/NSLweb/.

