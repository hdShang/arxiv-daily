---
layout: default
title: LLM-driven Knowledge Enhancement for Multimodal Cancer Survival Prediction
---

# LLM-driven Knowledge Enhancement for Multimodal Cancer Survival Prediction

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.14594" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.14594v1</a>
  <a href="https://arxiv.org/pdf/2512.14594.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14594v1" onclick="toggleFavorite(this, '2512.14594v1', 'LLM-driven Knowledge Enhancement for Multimodal Cancer Survival Prediction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chenyu Zhao, Yingxue Xu, Fengtao Zhou, Yihui Wang, Hao Chen

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºKEMMæ¨¡å‹ï¼Œåˆ©ç”¨LLMå¢å¼ºçŸ¥è¯†çš„å¤šæ¨¡æ€ç™Œç—‡ç”Ÿå­˜é¢„æµ‹ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `ç™Œç—‡ç”Ÿå­˜é¢„æµ‹` `å¤§å‹è¯­è¨€æ¨¡å‹` `çŸ¥è¯†å¢å¼º` `è·¨æ¨¡æ€æ³¨æ„åŠ›`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•éš¾ä»¥ä»é«˜ç»´å†—ä½™çš„ç—…ç†å›¾åƒå’ŒåŸºå› ç»„æ•°æ®ä¸­æå–æœ‰æ•ˆç‰¹å¾ï¼Œä¸”ç¼ºä¹å……åˆ†çš„ç›‘ç£ä¿¡æ¯ã€‚
2. KEMMæ¨¡å‹åˆ©ç”¨LLMå¤„ç†ä¸“å®¶æŠ¥å‘Šå’Œç”Ÿæˆé¢„åèƒŒæ™¯çŸ¥è¯†ï¼Œå¢å¼ºæ¨¡å‹å¯¹ç”Ÿå­˜é¢„æµ‹ç›¸å…³ç‰¹å¾çš„å…³æ³¨ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒKEMMåœ¨äº”ä¸ªæ•°æ®é›†ä¸Šå–å¾—äº†state-of-the-artçš„æ€§èƒ½ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å½“å‰çš„å¤šæ¨¡æ€ç”Ÿå­˜é¢„æµ‹æ–¹æ³•é€šå¸¸ä¾èµ–äºç—…ç†å›¾åƒï¼ˆWSIsï¼‰å’ŒåŸºå› ç»„æ•°æ®ï¼Œè¿™äº›æ•°æ®ç»´åº¦é«˜ä¸”å†—ä½™ï¼Œéš¾ä»¥æå–åˆ¤åˆ«æ€§ç‰¹å¾å¹¶å¯¹é½ä¸åŒæ¨¡æ€ã€‚æ­¤å¤–ï¼Œä½¿ç”¨ç®€å•çš„ç”Ÿå­˜éšè®¿æ ‡ç­¾ä¸è¶³ä»¥ç›‘ç£å¦‚æ­¤å¤æ‚çš„ä»»åŠ¡ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†KEMMï¼Œä¸€ç§ç”±LLMé©±åŠ¨çš„çŸ¥è¯†å¢å¼ºå¤šæ¨¡æ€æ¨¡å‹ï¼Œç”¨äºç™Œç—‡ç”Ÿå­˜é¢„æµ‹ï¼Œå®ƒé›†æˆäº†ä¸“å®¶æŠ¥å‘Šå’Œé¢„åèƒŒæ™¯çŸ¥è¯†ã€‚1) ä¸“å®¶æŠ¥å‘Šç”±ç—…ç†å­¦å®¶é€ä¸ªæ¡ˆä¾‹æä¾›ï¼Œå¹¶ç”±å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æç‚¼ï¼Œæä¾›ç®€æ´ä¸”ä¸´åºŠé‡ç‚¹æ˜ç¡®çš„è¯Šæ–­é™ˆè¿°ã€‚è¿™äº›ä¿¡æ¯é€šå¸¸æš—ç¤ºä¸åŒçš„ç”Ÿå­˜ç»“æœã€‚2) é¢„åèƒŒæ™¯çŸ¥è¯†ï¼ˆPBKï¼‰ç”±LLMç®€æ´åœ°ç”Ÿæˆï¼Œæä¾›å…³äºä¸åŒç™Œç—‡ç±»å‹çš„æœ‰ä»·å€¼çš„é¢„åèƒŒæ™¯çŸ¥è¯†ï¼Œè¿™ä¹Ÿå¢å¼ºäº†ç”Ÿå­˜é¢„æµ‹ã€‚ä¸ºäº†åˆ©ç”¨è¿™äº›çŸ¥è¯†ï¼Œæˆ‘ä»¬å¼•å…¥äº†çŸ¥è¯†å¢å¼ºçš„è·¨æ¨¡æ€ï¼ˆKECMï¼‰æ³¨æ„åŠ›æ¨¡å—ã€‚KECMå¯ä»¥æœ‰æ•ˆåœ°å¼•å¯¼ç½‘ç»œå…³æ³¨æ¥è‡ªé«˜åº¦å†—ä½™æ¨¡æ€çš„åˆ¤åˆ«æ€§å’Œç”Ÿå­˜ç›¸å…³ç‰¹å¾ã€‚åœ¨äº”ä¸ªæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒKEMMå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ä»£ç å°†åœ¨æ¥æ”¶åå‘å¸ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€ç™Œç—‡ç”Ÿå­˜é¢„æµ‹ä¸­ï¼Œç—…ç†å›¾åƒå’ŒåŸºå› ç»„æ•°æ®ç»´åº¦é«˜ã€å†—ä½™ï¼Œéš¾ä»¥æå–åˆ¤åˆ«æ€§ç‰¹å¾ï¼Œä»¥åŠç°æœ‰æ–¹æ³•ç¼ºä¹å……åˆ†ç›‘ç£ä¿¡æ¯çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆå¯¹é½ä¸åŒæ¨¡æ€çš„æ•°æ®ï¼Œå¹¶å¿½ç•¥äº†ä¸“å®¶çŸ¥è¯†å’Œé¢„åèƒŒæ™¯çŸ¥è¯†çš„ä»·å€¼ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¤„ç†ä¸“å®¶æŠ¥å‘Šï¼Œæå–å…³é”®è¯Šæ–­ä¿¡æ¯ï¼Œå¹¶ç”Ÿæˆé¢„åèƒŒæ™¯çŸ¥è¯†ï¼Œä»è€Œä¸ºå¤šæ¨¡æ€ç”Ÿå­˜é¢„æµ‹æ¨¡å‹æä¾›æ›´ä¸°å¯Œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚é€šè¿‡çŸ¥è¯†å¢å¼ºçš„è·¨æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶ï¼Œå¼•å¯¼æ¨¡å‹å…³æ³¨ä¸ç”Ÿå­˜é¢„æµ‹ç›¸å…³çš„åˆ¤åˆ«æ€§ç‰¹å¾ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šKEMMæ¨¡å‹ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) LLMé©±åŠ¨çš„çŸ¥è¯†æå–æ¨¡å—ï¼Œç”¨äºå¤„ç†ä¸“å®¶æŠ¥å‘Šå’Œç”Ÿæˆé¢„åèƒŒæ™¯çŸ¥è¯†ï¼›2) çŸ¥è¯†å¢å¼ºçš„è·¨æ¨¡æ€ï¼ˆKECMï¼‰æ³¨æ„åŠ›æ¨¡å—ï¼Œç”¨äºèåˆç—…ç†å›¾åƒã€åŸºå› ç»„æ•°æ®å’ŒçŸ¥è¯†ä¿¡æ¯ï¼›3) ç”Ÿå­˜é¢„æµ‹æ¨¡å—ï¼Œç”¨äºé¢„æµ‹æ‚£è€…çš„ç”Ÿå­˜æ¦‚ç‡ã€‚æ•´ä½“æµç¨‹æ˜¯ï¼šé¦–å…ˆï¼Œåˆ©ç”¨LLMæå–ä¸“å®¶æŠ¥å‘Šä¸­çš„å…³é”®ä¿¡æ¯ï¼Œå¹¶ç”Ÿæˆé¢„åèƒŒæ™¯çŸ¥è¯†ã€‚ç„¶åï¼Œå°†è¿™äº›çŸ¥è¯†ä¸ç—…ç†å›¾åƒå’ŒåŸºå› ç»„æ•°æ®ä¸€èµ·è¾“å…¥åˆ°KECMæ³¨æ„åŠ›æ¨¡å—ä¸­ï¼Œä»¥å¢å¼ºç‰¹å¾è¡¨ç¤ºã€‚æœ€åï¼Œä½¿ç”¨ç”Ÿå­˜é¢„æµ‹æ¨¡å—é¢„æµ‹æ‚£è€…çš„ç”Ÿå­˜æ¦‚ç‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) å¼•å…¥äº†LLMæ¥å¤„ç†ä¸“å®¶æŠ¥å‘Šå’Œç”Ÿæˆé¢„åèƒŒæ™¯çŸ¥è¯†ï¼Œä»è€Œä¸ºå¤šæ¨¡æ€ç”Ÿå­˜é¢„æµ‹æä¾›äº†æ›´ä¸°å¯Œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼›2) æå‡ºäº†çŸ¥è¯†å¢å¼ºçš„è·¨æ¨¡æ€ï¼ˆKECMï¼‰æ³¨æ„åŠ›æ¨¡å—ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°å¼•å¯¼ç½‘ç»œå…³æ³¨ä¸ç”Ÿå­˜é¢„æµ‹ç›¸å…³çš„åˆ¤åˆ«æ€§ç‰¹å¾ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒKEMMæ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨ä¸“å®¶çŸ¥è¯†å’Œé¢„åèƒŒæ™¯çŸ¥è¯†ï¼Œä»è€Œæé«˜ç”Ÿå­˜é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šKECMæ³¨æ„åŠ›æ¨¡å—çš„å…·ä½“å®ç°ç»†èŠ‚æœªçŸ¥ï¼Œè®ºæ–‡ä¸­å¯èƒ½åŒ…å«å…³äºLLMé€‰æ‹©ã€promptè®¾è®¡ã€æŸå¤±å‡½æ•°ä»¥åŠç½‘ç»œç»“æ„çš„å…·ä½“å‚æ•°è®¾ç½®ã€‚è¿™äº›ç»†èŠ‚å¯¹äºå¤ç°å’Œè¿›ä¸€æ­¥æ”¹è¿›è¯¥æ–¹æ³•è‡³å…³é‡è¦ï¼Œä½†æ‘˜è¦ä¸­æœªæä¾›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

KEMMæ¨¡å‹åœ¨äº”ä¸ªç™Œç—‡æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œç»“æœè¡¨æ˜ï¼ŒKEMMæ¨¡å‹å–å¾—äº†state-of-the-artçš„æ€§èƒ½ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®ã€å¯¹æ¯”åŸºçº¿å’Œæå‡å¹…åº¦éœ€è¦åœ¨è®ºæ–‡å…¨æ–‡ä¸­æŸ¥æ‰¾ã€‚è¯¥ç»“æœéªŒè¯äº†åˆ©ç”¨LLMå¢å¼ºçŸ¥è¯†çš„å¤šæ¨¡æ€èåˆæ–¹æ³•åœ¨ç™Œç—‡ç”Ÿå­˜é¢„æµ‹ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºä¸´åºŠè¾…åŠ©è¯Šæ–­ï¼Œå¸®åŠ©åŒ»ç”Ÿæ›´å‡†ç¡®åœ°é¢„æµ‹ç™Œç—‡æ‚£è€…çš„ç”Ÿå­˜æ¦‚ç‡ï¼Œä»è€Œåˆ¶å®šæ›´ä¸ªæ€§åŒ–çš„æ²»ç–—æ–¹æ¡ˆã€‚é€šè¿‡æ•´åˆå¤šæ¨¡æ€æ•°æ®å’Œä¸“å®¶çŸ¥è¯†ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æé«˜ç™Œç—‡æ²»ç–—çš„æœ‰æ•ˆæ€§å’Œæ‚£è€…çš„ç”Ÿå­˜ç‡ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–ç–¾ç—…çš„ç”Ÿå­˜é¢„æµ‹å’Œé£é™©è¯„ä¼°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Current multimodal survival prediction methods typically rely on pathology images (WSIs) and genomic data, both of which are high-dimensional and redundant, making it difficult to extract discriminative features from them and align different modalities. Moreover, using a simple survival follow-up label is insufficient to supervise such a complex task. To address these challenges, we propose KEMM, an LLM-driven Knowledge-Enhanced Multimodal Model for cancer survival prediction, which integrates expert reports and prognostic background knowledge. 1) Expert reports, provided by pathologists on a case-by-case basis and refined by large language model (LLM), offer succinct and clinically focused diagnostic statements. This information may typically suggest different survival outcomes. 2) Prognostic background knowledge (PBK), generated concisely by LLM, provides valuable prognostic background knowledge on different cancer types, which also enhances survival prediction. To leverage these knowledge, we introduce the knowledge-enhanced cross-modal (KECM) attention module. KECM can effectively guide the network to focus on discriminative and survival-relevant features from highly redundant modalities. Extensive experiments on five datasets demonstrate that KEMM achieves state-of-the-art performance. The code will be released upon acceptance.

