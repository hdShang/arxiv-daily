---
layout: default
title: DASP: Self-supervised Nighttime Monocular Depth Estimation with Domain Adaptation of Spatiotemporal Priors
---

# DASP: Self-supervised Nighttime Monocular Depth Estimation with Domain Adaptation of Spatiotemporal Priors

**arXiv**: [2512.14536v1](https://arxiv.org/abs/2512.14536) | [PDF](https://arxiv.org/pdf/2512.14536.pdf)

**ä½œè€…**: Yiheng Huang, Junhong Chen, Anqi Ning, Zhanhong Liang, Nick Michiels, Luc Claesen, Wenyin Liu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: 8 pages, 7 figures

**DOI**: [10.1109/LRA.2025.3644148](https://doi.org/10.1109/LRA.2025.3644148)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**DASPï¼šåˆ©ç”¨æ—¶ç©ºå…ˆéªŒåŸŸé€‚åº”çš„è‡ªç›‘ç£å¤œé—´å•ç›®æ·±åº¦ä¼°è®¡**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `è‡ªç›‘ç£å­¦ä¹ ` `æ·±åº¦ä¼°è®¡` `å¤œé—´åœºæ™¯` `æ—¶ç©ºå…ˆéªŒ` `åŸŸé€‚åº”`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤œé—´åœºæ™¯å…‰ç…§ä¸è¶³ã€åŠ¨æ€æ¨¡ç³Šç­‰é—®é¢˜å¯¼è‡´çŽ°æœ‰è‡ªç›‘ç£æ·±åº¦ä¼°è®¡æ–¹æ³•æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚
2. DASPæ¡†æž¶åˆ©ç”¨å¯¹æŠ—åˆ†æ”¯æå–ç™½å¤©åœºæ™¯çš„æ—¶ç©ºå…ˆéªŒçŸ¥è¯†ï¼Œå¹¶å°†å…¶è¿ç§»åˆ°å¤œé—´åœºæ™¯çš„æ·±åº¦ä¼°è®¡ä¸­ã€‚
3. å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒDASPåœ¨å¤œé—´æ·±åº¦ä¼°è®¡ä»»åŠ¡ä¸Šå–å¾—äº†state-of-the-artçš„æ€§èƒ½ï¼Œå¹¶éªŒè¯äº†å„æ¨¡å—çš„æœ‰æ•ˆæ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è‡ªç›‘ç£å•ç›®æ·±åº¦ä¼°è®¡åœ¨ç™½å¤©æ¡ä»¶ä¸‹å–å¾—äº†æ˜¾è‘—æˆåŠŸã€‚ç„¶è€Œï¼Œç”±äºŽä½Žèƒ½è§åº¦å’Œå˜åŒ–çš„å…‰ç…§ï¼Œå…¶åœ¨å¤œé—´çš„æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œä¾‹å¦‚ï¼Œå…‰çº¿ä¸è¶³å¯¼è‡´æ— çº¹ç†åŒºåŸŸï¼Œç§»åŠ¨ç‰©ä½“å¸¦æ¥æ¨¡ç³ŠåŒºåŸŸã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåä¸ºDASPçš„è‡ªç›‘ç£æ¡†æž¶ï¼Œè¯¥æ¡†æž¶åˆ©ç”¨æ—¶ç©ºå…ˆéªŒè¿›è¡Œå¤œé—´æ·±åº¦ä¼°è®¡ã€‚å…·ä½“æ¥è¯´ï¼ŒDASPç”±ä¸€ä¸ªç”¨äºŽæå–æ—¶ç©ºå…ˆéªŒçš„å¯¹æŠ—åˆ†æ”¯å’Œä¸€ä¸ªç”¨äºŽå­¦ä¹ çš„è‡ªç›‘ç£åˆ†æ”¯ç»„æˆã€‚åœ¨å¯¹æŠ—åˆ†æ”¯ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆè®¾è®¡ä¸€ä¸ªå¯¹æŠ—ç½‘ç»œï¼Œå…¶ä¸­åˆ¤åˆ«å™¨ç”±å››ä¸ªè®¾è®¡çš„æ—¶ç©ºå…ˆéªŒå­¦ä¹ å—ï¼ˆSPLBï¼‰ç»„æˆï¼Œä»¥åˆ©ç”¨ç™½å¤©å…ˆéªŒã€‚ç‰¹åˆ«æ˜¯ï¼ŒSPLBåŒ…å«ä¸€ä¸ªåŸºäºŽç©ºé—´çš„æ—¶åºå­¦ä¹ æ¨¡å—ï¼ˆSTLMï¼‰ï¼Œè¯¥æ¨¡å—ä½¿ç”¨æ­£äº¤å·®åˆ†æ¥æå–æ²¿æ—¶é—´è½´çš„è¿åŠ¨ç›¸å…³å˜åŒ–ï¼Œä»¥åŠä¸€ä¸ªè½´å‘ç©ºé—´å­¦ä¹ æ¨¡å—ï¼ˆASLMï¼‰ï¼Œè¯¥æ¨¡å—é‡‡ç”¨å…·æœ‰å…¨å±€è½´å‘æ³¨æ„åŠ›çš„å±€éƒ¨éžå¯¹ç§°å·ç§¯æ¥æ•èŽ·å¤šå°ºåº¦ç»“æž„ä¿¡æ¯ã€‚é€šè¿‡ç»“åˆSTLMå’ŒASLMï¼Œæˆ‘ä»¬çš„æ¨¡åž‹å¯ä»¥èŽ·å¾—è¶³å¤Ÿçš„æ—¶ç©ºç‰¹å¾æ¥æ¢å¤æ— çº¹ç†åŒºåŸŸå¹¶ä¼°è®¡ç”±åŠ¨æ€å¯¹è±¡å¼•èµ·çš„æ¨¡ç³ŠåŒºåŸŸã€‚åœ¨è‡ªç›‘ç£åˆ†æ”¯ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ª3Dä¸€è‡´æ€§æŠ•å½±æŸå¤±ï¼Œä»¥åŒè¾¹åœ°å°†ç›®æ ‡å¸§å’Œæºå¸§æŠ•å½±åˆ°å…±äº«çš„3Dç©ºé—´ä¸­ï¼Œå¹¶è®¡ç®—ä¸¤ä¸ªæŠ•å½±å¸§ä¹‹é—´çš„3Då·®å¼‚ä½œä¸ºæŸå¤±ï¼Œä»¥ä¼˜åŒ–3Dç»“æž„ä¸€è‡´æ€§å’Œç™½å¤©å…ˆéªŒã€‚åœ¨Oxford RobotCarå’ŒnuScenesæ•°æ®é›†ä¸Šçš„å¤§é‡å®žéªŒè¡¨æ˜Žï¼Œæˆ‘ä»¬çš„æ–¹æ³•å®žçŽ°äº†æœ€å…ˆè¿›çš„å¤œé—´æ·±åº¦ä¼°è®¡æ€§èƒ½ã€‚æ¶ˆèžç ”ç©¶è¿›ä¸€æ­¥éªŒè¯äº†æ¯ä¸ªç»„ä»¶çš„æœ‰æ•ˆæ€§ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤œé—´å•ç›®æ·±åº¦ä¼°è®¡é—®é¢˜ã€‚çŽ°æœ‰è‡ªç›‘ç£æ–¹æ³•åœ¨ç™½å¤©è¡¨çŽ°è‰¯å¥½ï¼Œä½†åœ¨å¤œé—´ç”±äºŽå…‰ç…§ä¸è¶³ã€åŠ¨æ€ç‰©ä½“æ¨¡ç³Šç­‰å› ç´ ï¼Œå¯¼è‡´æ·±åº¦ä¼°è®¡ç²¾åº¦å¤§å¹…ä¸‹é™ã€‚çŽ°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆåˆ©ç”¨å¤œé—´åœºæ™¯çš„æ—¶ç©ºä¿¡æ¯ï¼Œå¹¶ä¸”ç¼ºä¹å¯¹ç™½å¤©åœºæ™¯å…ˆéªŒçŸ¥è¯†çš„æœ‰æ•ˆè¿ç§»ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¯¹æŠ—å­¦ä¹ æ¡†æž¶ï¼Œå°†ç™½å¤©åœºæ™¯çš„æ—¶ç©ºå…ˆéªŒçŸ¥è¯†è¿ç§»åˆ°å¤œé—´åœºæ™¯çš„æ·±åº¦ä¼°è®¡ä¸­ã€‚é€šè¿‡è®¾è®¡ç‰¹å®šçš„æ—¶ç©ºå…ˆéªŒå­¦ä¹ æ¨¡å—ï¼Œæ¨¡åž‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å¤œé—´åœºæ™¯ä¸­çš„ç»“æž„ä¿¡æ¯å’Œè¿åŠ¨ä¿¡æ¯ï¼Œä»Žè€Œæé«˜æ·±åº¦ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚åŒæ—¶ï¼Œåˆ©ç”¨3Dä¸€è‡´æ€§æŠ•å½±æŸå¤±ï¼Œè¿›ä¸€æ­¥çº¦æŸæ·±åº¦ä¼°è®¡ç»“æžœçš„å‡ ä½•ä¸€è‡´æ€§ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šDASPæ¡†æž¶åŒ…å«ä¸¤ä¸ªä¸»è¦åˆ†æ”¯ï¼šå¯¹æŠ—åˆ†æ”¯å’Œè‡ªç›‘ç£åˆ†æ”¯ã€‚å¯¹æŠ—åˆ†æ”¯è´Ÿè´£æå–ç™½å¤©åœºæ™¯çš„æ—¶ç©ºå…ˆéªŒçŸ¥è¯†ï¼Œå¹¶å°†å…¶ä½œä¸ºæŒ‡å¯¼ä¿¡æ¯ä¼ é€’ç»™è‡ªç›‘ç£åˆ†æ”¯ã€‚è‡ªç›‘ç£åˆ†æ”¯åˆ™åˆ©ç”¨é‡æŠ•å½±è¯¯å·®å’Œ3Dä¸€è‡´æ€§æŠ•å½±æŸå¤±è¿›è¡Œæ·±åº¦ä¼°è®¡å­¦ä¹ ã€‚å¯¹æŠ—åˆ†æ”¯åŒ…å«ä¸€ä¸ªç”Ÿæˆå™¨å’Œä¸€ä¸ªåˆ¤åˆ«å™¨ï¼Œåˆ¤åˆ«å™¨ç”±å¤šä¸ªæ—¶ç©ºå…ˆéªŒå­¦ä¹ å—ï¼ˆSPLBï¼‰ç»„æˆã€‚SPLBåŒ…å«ç©ºé—´æ—¶åºå­¦ä¹ æ¨¡å—ï¼ˆSTLMï¼‰å’Œè½´å‘ç©ºé—´å­¦ä¹ æ¨¡å—ï¼ˆASLMï¼‰ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽæå‡ºäº†æ—¶ç©ºå…ˆéªŒå­¦ä¹ å—ï¼ˆSPLBï¼‰ï¼Œè¯¥æ¨¡å—èƒ½å¤Ÿæœ‰æ•ˆåœ°æå–å’Œåˆ©ç”¨ç™½å¤©åœºæ™¯çš„æ—¶ç©ºå…ˆéªŒçŸ¥è¯†ã€‚SPLBé€šè¿‡ç»“åˆSTLMå’ŒASLMï¼Œèƒ½å¤ŸåŒæ—¶æ•æ‰æ—¶é—´è½´ä¸Šçš„è¿åŠ¨ä¿¡æ¯å’Œç©ºé—´ä¸Šçš„ç»“æž„ä¿¡æ¯ï¼Œä»Žè€Œæ›´å¥½åœ°å¤„ç†å¤œé—´åœºæ™¯ä¸­çš„æ— çº¹ç†åŒºåŸŸå’ŒåŠ¨æ€æ¨¡ç³Šé—®é¢˜ã€‚æ­¤å¤–ï¼Œ3Dä¸€è‡´æ€§æŠ•å½±æŸå¤±çš„å¼•å…¥ï¼Œè¿›ä¸€æ­¥æå‡äº†æ·±åº¦ä¼°è®¡çš„å‡ ä½•ä¸€è‡´æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šSTLMä½¿ç”¨æ­£äº¤å·®åˆ†æå–æ—¶é—´è½´ä¸Šçš„è¿åŠ¨ç›¸å…³å˜åŒ–ï¼›ASLMé‡‡ç”¨å±€éƒ¨éžå¯¹ç§°å·ç§¯å’Œå…¨å±€è½´å‘æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ•èŽ·å¤šå°ºåº¦ç»“æž„ä¿¡æ¯ã€‚å¯¹æŠ—æŸå¤±ç”¨äºŽä¿ƒä½¿ç”Ÿæˆå™¨ç”Ÿæˆçš„æ·±åº¦å›¾å…·æœ‰ä¸Žç™½å¤©åœºæ™¯ç›¸ä¼¼çš„æ—¶ç©ºç‰¹å¾ã€‚3Dä¸€è‡´æ€§æŠ•å½±æŸå¤±é€šè¿‡åŒè¾¹æŠ•å½±ç›®æ ‡å¸§å’Œæºå¸§åˆ°3Dç©ºé—´ï¼Œå¹¶è®¡ç®—3Då·®å¼‚æ¥ä¼˜åŒ–ç»“æž„ä¸€è‡´æ€§ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨Oxford RobotCarå’ŒnuScenesæ•°æ®é›†ä¸Šçš„å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒDASPæ–¹æ³•åœ¨å¤œé—´æ·±åº¦ä¼°è®¡ä»»åŠ¡ä¸Šå–å¾—äº†state-of-the-artçš„æ€§èƒ½ã€‚ç›¸è¾ƒäºŽçŽ°æœ‰æ–¹æ³•ï¼ŒDASPèƒ½å¤Ÿæ›´å‡†ç¡®åœ°ä¼°è®¡å¤œé—´åœºæ™¯çš„æ·±åº¦ä¿¡æ¯ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†æ— çº¹ç†åŒºåŸŸå’ŒåŠ¨æ€æ¨¡ç³ŠåŒºåŸŸæ—¶è¡¨çŽ°æ›´ä½³ã€‚æ¶ˆèžå®žéªŒéªŒè¯äº†SPLBã€STLMã€ASLMä»¥åŠ3Dä¸€è‡´æ€§æŠ•å½±æŸå¤±ç­‰å„ä¸ªæ¨¡å—çš„æœ‰æ•ˆæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽå¤œé—´è‡ªåŠ¨é©¾é©¶ã€å¤œé—´æœºå™¨äººå¯¼èˆªã€å¤œé—´å®‰é˜²ç›‘æŽ§ç­‰é¢†åŸŸã€‚é€šè¿‡æé«˜å¤œé—´æ·±åº¦ä¼°è®¡çš„å‡†ç¡®æ€§ï¼Œå¯ä»¥æå‡ç›¸å…³ç³»ç»Ÿåœ¨ä½Žå…‰ç…§çŽ¯å¢ƒä¸‹çš„æ„ŸçŸ¥èƒ½åŠ›å’Œå†³ç­–èƒ½åŠ›ï¼Œä»Žè€Œå¢žå¼ºå…¶å®‰å…¨æ€§å’Œå¯é æ€§ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯ä»¥è¿›ä¸€æ­¥æ‰©å±•åˆ°å…¶ä»–å¤œé—´è§†è§‰ä»»åŠ¡ï¼Œå¦‚ç›®æ ‡æ£€æµ‹ã€è¯­ä¹‰åˆ†å‰²ç­‰ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Self-supervised monocular depth estimation has achieved notable success under daytime conditions. However, its performance deteriorates markedly at night due to low visibility and varying illumination, e.g., insufficient light causes textureless areas, and moving objects bring blurry regions. To this end, we propose a self-supervised framework named DASP that leverages spatiotemporal priors for nighttime depth estimation. Specifically, DASP consists of an adversarial branch for extracting spatiotemporal priors and a self-supervised branch for learning. In the adversarial branch, we first design an adversarial network where the discriminator is composed of four devised spatiotemporal priors learning blocks (SPLB) to exploit the daytime priors. In particular, the SPLB contains a spatial-based temporal learning module (STLM) that uses orthogonal differencing to extract motion-related variations along the time axis and an axial spatial learning module (ASLM) that adopts local asymmetric convolutions with global axial attention to capture the multiscale structural information. By combining STLM and ASLM, our model can acquire sufficient spatiotemporal features to restore textureless areas and estimate the blurry regions caused by dynamic objects. In the self-supervised branch, we propose a 3D consistency projection loss to bilaterally project the target frame and source frame into a shared 3D space, and calculate the 3D discrepancy between the two projected frames as a loss to optimize the 3D structural consistency and daytime priors. Extensive experiments on the Oxford RobotCar and nuScenes datasets demonstrate that our approach achieves state-of-the-art performance for nighttime depth estimation. Ablation studies further validate the effectiveness of each component.

