---
layout: default
title: DRAW2ACT: Turning Depth-Encoded Trajectories into Robotic Demonstration Videos
---

# DRAW2ACT: Turning Depth-Encoded Trajectories into Robotic Demonstration Videos

**arXiv**: [2512.14217v1](https://arxiv.org/abs/2512.14217) | [PDF](https://arxiv.org/pdf/2512.14217.pdf)

**ä½œè€…**: Yang Bai, Liudi Yang, George Eskandar, Fengyi Shen, Mohammad Altillawi, Ziyuan Liu, Gitta Kutyniok

**åˆ†ç±»**: cs.CV, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDRAW2ACTæ¡†æž¶ï¼Œé€šè¿‡æ·±åº¦æ„ŸçŸ¥è½¨è¿¹æ¡ä»¶è§†é¢‘ç”Ÿæˆè§£å†³æœºå™¨äººæ¼”ç¤ºå¯æŽ§æ€§å’Œä¸€è‡´æ€§é—®é¢˜**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **ä¸–ç•Œæ¨¡åž‹** **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `æ·±åº¦æ„ŸçŸ¥è§†é¢‘ç”Ÿæˆ` `è½¨è¿¹æ¡ä»¶ç”Ÿæˆ` `å¤šæ¨¡æ€èžåˆ` `æœºå™¨äººæ¼”ç¤º` `æ‰©æ•£æ¨¡åž‹` `æ—¶ç©ºä¸€è‡´æ€§` `è·¨æ¨¡æ€æ³¨æ„åŠ›` `å…·èº«AI`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è§†é¢‘æ‰©æ•£æ¨¡åž‹åœ¨æœºå™¨äººæ“ä½œä¸­å¯æŽ§æ€§ä¸è¶³ï¼Œä¾èµ–2Dè½¨è¿¹æˆ–å•æ¨¡æ€æ¡ä»¶é™åˆ¶äº†æ¼”ç¤ºçš„ä¸€è‡´æ€§å’Œå¯æŽ§æ€§ã€‚
2. DRAW2ACTæ¡†æž¶ä»Žè½¨è¿¹æå–æ·±åº¦ã€è¯­ä¹‰ç­‰å¤šæ¨¡æ€è¡¨ç¤ºï¼Œå¹¶è”åˆç”ŸæˆRGBå’Œæ·±åº¦è§†é¢‘ä»¥å¢žå¼ºæ—¶ç©ºä¸€è‡´æ€§ã€‚
3. å®žéªŒåœ¨å¤šä¸ªåŸºå‡†ä¸ŠéªŒè¯äº†DRAW2ACTçš„è§†è§‰ä¿çœŸåº¦å’Œæ“ä½œæˆåŠŸçŽ‡å‡ä¼˜äºŽçŽ°æœ‰åŸºçº¿ï¼Œæå‡äº†æœºå™¨äººæ¼”ç¤ºè´¨é‡ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†é¢‘æ‰©æ•£æ¨¡åž‹ä¸ºå…·èº«AIæä¾›äº†å¼ºå¤§çš„çœŸå®žä¸–ç•Œæ¨¡æ‹Ÿå™¨ï¼Œä½†åœ¨æœºå™¨äººæ“ä½œçš„å¯æŽ§æ€§æ–¹é¢ä»å­˜åœ¨å±€é™ã€‚æœ€è¿‘å…³äºŽè½¨è¿¹æ¡ä»¶è§†é¢‘ç”Ÿæˆçš„ç ”ç©¶è¯•å›¾å¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œä½†é€šå¸¸ä¾èµ–äºŽ2Dè½¨è¿¹æˆ–å•æ¨¡æ€æ¡ä»¶ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬ç”Ÿæˆå¯æŽ§ä¸”ä¸€è‡´çš„æœºå™¨äººæ¼”ç¤ºçš„èƒ½åŠ›ã€‚æˆ‘ä»¬æå‡ºäº†DRAW2ACTï¼Œè¿™æ˜¯ä¸€ä¸ªæ·±åº¦æ„ŸçŸ¥è½¨è¿¹æ¡ä»¶è§†é¢‘ç”Ÿæˆæ¡†æž¶ï¼Œå®ƒä»Žè¾“å…¥è½¨è¿¹ä¸­æå–å¤šä¸ªæ­£äº¤è¡¨ç¤ºï¼Œæ•æ‰æ·±åº¦ã€è¯­ä¹‰ã€å½¢çŠ¶å’Œè¿åŠ¨ï¼Œå¹¶å°†å®ƒä»¬æ³¨å…¥æ‰©æ•£æ¨¡åž‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºè”åˆç”Ÿæˆç©ºé—´å¯¹é½çš„RGBå’Œæ·±åº¦è§†é¢‘ï¼Œåˆ©ç”¨è·¨æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶å’Œæ·±åº¦ç›‘ç£æ¥å¢žå¼ºæ—¶ç©ºä¸€è‡´æ€§ã€‚æœ€åŽï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªåŸºäºŽç”Ÿæˆçš„RGBå’Œæ·±åº¦åºåˆ—çš„å¤šæ¨¡æ€ç­–ç•¥æ¨¡åž‹ï¼Œä»¥å›žå½’æœºå™¨äººçš„å…³èŠ‚è§’åº¦ã€‚åœ¨Bridge V2ã€Berkeley Autolabå’Œä»¿çœŸåŸºå‡†ä¸Šçš„å®žéªŒè¡¨æ˜Žï¼Œä¸ŽçŽ°æœ‰åŸºçº¿ç›¸æ¯”ï¼ŒDRAW2ACTå®žçŽ°äº†æ›´ä¼˜çš„è§†è§‰ä¿çœŸåº¦å’Œä¸€è‡´æ€§ï¼ŒåŒæ—¶èŽ·å¾—äº†æ›´é«˜çš„æ“ä½œæˆåŠŸçŽ‡ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è§†é¢‘æ‰©æ•£æ¨¡åž‹åœ¨æœºå™¨äººæ“ä½œæ¼”ç¤ºç”Ÿæˆä¸­å¯æŽ§æ€§ä¸è¶³çš„é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•é€šå¸¸åŸºäºŽ2Dè½¨è¿¹æˆ–å•æ¨¡æ€æ¡ä»¶ï¼Œå¯¼è‡´ç”Ÿæˆçš„è§†é¢‘åœ¨æ·±åº¦ä¿¡æ¯å’Œæ—¶ç©ºä¸€è‡´æ€§æ–¹é¢å—é™ï¼Œéš¾ä»¥äº§ç”Ÿé«˜è´¨é‡ã€å¯æŽ§çš„æœºå™¨äººæ¼”ç¤ºè§†é¢‘ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡ä»Žè¾“å…¥è½¨è¿¹ä¸­æå–å¤šæ¨¡æ€è¡¨ç¤ºï¼ˆåŒ…æ‹¬æ·±åº¦ã€è¯­ä¹‰ã€å½¢çŠ¶å’Œè¿åŠ¨ï¼‰ï¼Œå¹¶å°†è¿™äº›è¡¨ç¤ºæ³¨å…¥æ‰©æ•£æ¨¡åž‹ï¼Œä»¥å¢žå¼ºç”Ÿæˆè§†é¢‘çš„å¯æŽ§æ€§å’Œä¸€è‡´æ€§ã€‚åŒæ—¶ï¼Œè”åˆç”ŸæˆRGBå’Œæ·±åº¦è§†é¢‘ï¼Œåˆ©ç”¨è·¨æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶å’Œæ·±åº¦ç›‘ç£æ¥ä¼˜åŒ–æ—¶ç©ºå¯¹é½ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æ¡†æž¶åŒ…æ‹¬è½¨è¿¹ç¼–ç æ¨¡å—ã€å¤šæ¨¡æ€è¡¨ç¤ºæå–æ¨¡å—ã€è§†é¢‘ç”Ÿæˆæ¨¡å—å’Œå¤šæ¨¡æ€ç­–ç•¥æ¨¡å—ã€‚é¦–å…ˆï¼Œä»Žè¾“å…¥è½¨è¿¹ä¸­æå–æ·±åº¦ç¼–ç ä¿¡æ¯ï¼›ç„¶åŽï¼Œå°†è¿™äº›ä¿¡æ¯è½¬åŒ–ä¸ºå¤šä¸ªæ­£äº¤è¡¨ç¤ºï¼›æŽ¥ç€ï¼Œé€šè¿‡æ‰©æ•£æ¨¡åž‹ç”Ÿæˆç©ºé—´å¯¹é½çš„RGBå’Œæ·±åº¦è§†é¢‘åºåˆ—ï¼›æœ€åŽï¼ŒåŸºäºŽç”Ÿæˆçš„è§†é¢‘åºåˆ—è®­ç»ƒç­–ç•¥æ¨¡åž‹æ¥å›žå½’æœºå™¨äººå…³èŠ‚è§’åº¦ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºŽæ·±åº¦æ„ŸçŸ¥è½¨è¿¹æ¡ä»¶è§†é¢‘ç”Ÿæˆï¼Œé€šè¿‡æå–å’Œæ³¨å…¥å¤šæ¨¡æ€è¡¨ç¤ºï¼Œç»“åˆè·¨æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ˜¾è‘—æå‡äº†ç”Ÿæˆè§†é¢‘çš„æ·±åº¦ä¸€è‡´æ€§å’Œå¯æŽ§æ€§ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæœ¬è´¨åŒºåˆ«åœ¨äºŽåŒæ—¶å¤„ç†RGBå’Œæ·±åº¦ä¿¡æ¯ï¼Œå¹¶åˆ©ç”¨æ·±åº¦ç›‘ç£å¢žå¼ºæ—¶ç©ºå¯¹é½ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ä½¿ç”¨æ‰©æ•£æ¨¡åž‹ä½œä¸ºè§†é¢‘ç”Ÿæˆå™¨ï¼Œå¼•å…¥è·¨æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶æ¥èžåˆRGBå’Œæ·±åº¦ä¿¡æ¯ï¼Œè®¾è®¡æŸå¤±å‡½æ•°ä»¥ç›‘ç£æ·±åº¦ä¸€è‡´æ€§ï¼Œä»¥åŠé‡‡ç”¨å¤šæ¨¡æ€ç­–ç•¥æ¨¡åž‹è¿›è¡Œå…³èŠ‚è§’åº¦å›žå½’ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æž„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœªè¯¦ç»†è¯´æ˜Žï¼Œä½†å¼ºè°ƒäº†æ·±åº¦ç›‘ç£å’Œè”åˆè®­ç»ƒçš„é‡è¦æ€§ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨Bridge V2ã€Berkeley Autolabå’Œä»¿çœŸåŸºå‡†ä¸Šçš„å®žéªŒè¡¨æ˜Žï¼ŒDRAW2ACTåœ¨è§†è§‰ä¿çœŸåº¦å’Œä¸€è‡´æ€§æ–¹é¢ä¼˜äºŽçŽ°æœ‰åŸºçº¿ï¼Œå…·ä½“æ€§èƒ½æ•°æ®æœªè¯¦ç»†æä¾›ï¼Œä½†æŠ¥å‘Šäº†æ›´é«˜çš„æ“ä½œæˆåŠŸçŽ‡ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨æœºå™¨äººæ¼”ç¤ºç”Ÿæˆé¢†åŸŸå…·æœ‰é‡è¦åº”ç”¨ä»·å€¼ï¼Œå¯ç”¨äºŽæœºå™¨äººæ“ä½œä»»åŠ¡çš„æ¨¡æ‹Ÿè®­ç»ƒã€è™šæ‹ŸçŽ°å®žäº¤äº’å’Œè‡ªåŠ¨åŒ–ç³»ç»Ÿå¼€å‘ã€‚é€šè¿‡ç”Ÿæˆé«˜è´¨é‡ã€å¯æŽ§çš„æ¼”ç¤ºè§†é¢‘ï¼Œèƒ½æå‡æœºå™¨äººå­¦ä¹ æ•ˆçŽ‡å’Œå®žé™…éƒ¨ç½²çš„å¯é æ€§ï¼Œæœªæ¥å¯èƒ½æŽ¨åŠ¨å…·èº«AIå’Œæ™ºèƒ½æœºå™¨äººæŠ€æœ¯çš„è¿›æ­¥ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Video diffusion models provide powerful real-world simulators for embodied AI but remain limited in controllability for robotic manipulation. Recent works on trajectory-conditioned video generation address this gap but often rely on 2D trajectories or single modality conditioning, which restricts their ability to produce controllable and consistent robotic demonstrations. We present DRAW2ACT, a depth-aware trajectory-conditioned video generation framework that extracts multiple orthogonal representations from the input trajectory, capturing depth, semantics, shape and motion, and injects them into the diffusion model. Moreover, we propose to jointly generate spatially aligned RGB and depth videos, leveraging cross-modality attention mechanisms and depth supervision to enhance the spatio-temporal consistency. Finally, we introduce a multimodal policy model conditioned on the generated RGB and depth sequences to regress the robot's joint angles. Experiments on Bridge V2, Berkeley Autolab, and simulation benchmarks show that DRAW2ACT achieves superior visual fidelity and consistency while yielding higher manipulation success rates compared to existing baselines.

