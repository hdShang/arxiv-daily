---
layout: default
title: Incentivizing Tool-augmented Thinking with Images for Medical Image Analysis
---

# Incentivizing Tool-augmented Thinking with Images for Medical Image Analysis

**arXiv**: [2512.14157v1](https://arxiv.org/abs/2512.14157) | [PDF](https://arxiv.org/pdf/2512.14157.pdf)

**ä½œè€…**: Yankai Jiang, Yujie Zhang, Peng Zhang, Yichen Li, Jintai Chen, Xiaoming Shi, Shihui Zhen

**åˆ†ç±»**: cs.AI, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOphiuchusæ¡†æž¶ï¼Œé€šè¿‡å·¥å…·å¢žå¼ºçš„æ€ç»´é“¾è§£å†³åŒ»å­¦å›¾åƒåˆ†æžä¸­å¤æ‚ä»»åŠ¡çš„åŠ¨æ€è§†è§‰èšç„¦é—®é¢˜ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **è§†è§‰é‡Œç¨‹è®¡** **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `åŒ»å­¦å›¾åƒåˆ†æž` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹` `å·¥å…·å¢žå¼ºæŽ¨ç†` `åŠ¨æ€è§†è§‰èšç„¦` `æ€ç»´é“¾` `å¼ºåŒ–å­¦ä¹ ` `è‡ªæˆ‘åæ€å¾®è°ƒ` `åŒ»å­¦AIä»£ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰åŒ»å­¦å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹åœ¨å¤æ‚ä»»åŠ¡ä¸­éš¾ä»¥åŠ¨æ€èšç„¦ç»†ç²’åº¦è§†è§‰åŒºåŸŸï¼Œå¯¼è‡´å®šä½å’Œè¯Šæ–­ç²¾åº¦ä¸è¶³ã€‚
2. æå‡ºOphiuchusæ¡†æž¶ï¼Œé€šè¿‡å·¥å…·å¢žå¼ºçš„æ€ç»´é“¾ï¼Œç»“åˆæ¨¡åž‹èƒ½åŠ›ä¸Žå¤–éƒ¨å·¥å…·ï¼Œå®žçŽ°åŠ¨æ€è§†è§‰è¯æ®èŽ·å–å’Œé›†æˆã€‚
3. å®žéªŒæ˜¾ç¤ºOphiuchusåœ¨VQAã€æ£€æµ‹å’Œåˆ†å‰²ç­‰åŒ»å­¦åŸºå‡†ä¸Šè¶…è¶ŠSOTAæ–¹æ³•ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œé€šç”¨æ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼ŒåŸºäºŽæŽ¨ç†çš„åŒ»å­¦å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹åœ¨ç”Ÿæˆé€æ­¥æ–‡æœ¬æŽ¨ç†é“¾æ–¹é¢å–å¾—äº†è¿›å±•ã€‚ç„¶è€Œï¼Œå®ƒä»¬ä»ç„¶éš¾ä»¥å¤„ç†éœ€è¦åŠ¨æ€å’Œè¿­ä»£åœ°èšç„¦äºŽç»†ç²’åº¦è§†è§‰åŒºåŸŸä»¥å®žçŽ°ç²¾ç¡®å®šä½å’Œè¯Šæ–­çš„å¤æ‚ä»»åŠ¡ã€‚æˆ‘ä»¬å¼•å…¥äº†Ophiuchusï¼Œè¿™æ˜¯ä¸€ä¸ªå¤šåŠŸèƒ½ã€å·¥å…·å¢žå¼ºçš„æ¡†æž¶ï¼Œå®ƒä½¿MLLMèƒ½å¤Ÿï¼š(i)å†³å®šä½•æ—¶éœ€è¦é¢å¤–çš„è§†è§‰è¯æ®ï¼Œ(ii)ç¡®å®šåœ¨åŒ»å­¦å›¾åƒä¸­æŽ¢æµ‹å’Œå®šä½çš„ä½ç½®ï¼Œä»¥åŠ(iii)å°†ç›¸å…³çš„å­å›¾åƒå†…å®¹æ— ç¼åœ°ç¼–ç»‡æˆäº¤é”™çš„å¤šæ¨¡æ€æ€ç»´é“¾ã€‚ä¸Žå…ˆå‰å—é™äºŽä¸“ç”¨å·¥å…·æ€§èƒ½ä¸Šé™çš„æ–¹æ³•ä¸åŒï¼ŒOphiuchuså°†æ¨¡åž‹å›ºæœ‰çš„å®šä½å’Œæ„ŸçŸ¥èƒ½åŠ›ä¸Žå¤–éƒ¨å·¥å…·ç›¸ç»“åˆï¼Œä»Žè€Œä¿ƒè¿›æ›´é«˜å±‚æ¬¡çš„æŽ¨ç†ã€‚æˆ‘ä»¬æ–¹æ³•çš„æ ¸å¿ƒæ˜¯ä¸€ä¸ªä¸‰é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼šä½¿ç”¨å·¥å…·é›†æˆæŽ¨ç†æ•°æ®è¿›è¡Œå†·å¯åŠ¨è®­ç»ƒï¼Œä»¥å®žçŽ°å¯¹å…³é”®åŒºåŸŸæ£€æŸ¥çš„åŸºæœ¬å·¥å…·é€‰æ‹©å’Œé€‚åº”ï¼›è‡ªæˆ‘åæ€å¾®è°ƒï¼Œä»¥åŠ å¼ºåæ€æ€§æŽ¨ç†å¹¶é¼“åŠ±é‡æ–°å®¡è§†å·¥å…·è¾“å‡ºï¼›ä»¥åŠä»£ç†å·¥å…·å¼ºåŒ–å­¦ä¹ ï¼Œä»¥ç›´æŽ¥ä¼˜åŒ–ç‰¹å®šä»»åŠ¡çš„å¥–åŠ±å¹¶æ¨¡æ‹Ÿç±»ä¼¼ä¸“å®¶çš„è¯Šæ–­è¡Œä¸ºã€‚å¤§é‡å®žéªŒè¡¨æ˜Žï¼ŒOphiuchusåœ¨åŒ…æ‹¬VQAã€æ£€æµ‹å’ŒåŸºäºŽæŽ¨ç†çš„åˆ†å‰²åœ¨å†…çš„å¤šç§åŒ»å­¦åŸºå‡†æµ‹è¯•ä¸­ï¼Œå§‹ç»ˆä¼˜äºŽé—­æºå’Œå¼€æºçš„æœ€å…ˆè¿›æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸ºåŒ»å­¦AIä»£ç†æŒ‡æ˜Žäº†ä¸€æ¡é€šè¿‡å·¥å…·é›†æˆæŽ¨ç†çœŸæ­£â€œç”¨å›¾åƒæ€è€ƒâ€çš„é“è·¯ã€‚æ•°æ®é›†ã€ä»£ç å’Œè®­ç»ƒæ¨¡åž‹å°†å…¬å¼€å‘å¸ƒã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åŒ»å­¦å›¾åƒåˆ†æžä¸­å¤æ‚ä»»åŠ¡ï¼ˆå¦‚ç²¾ç¡®å®šä½å’Œè¯Šæ–­ï¼‰çš„æŒ‘æˆ˜ï¼ŒçŽ°æœ‰åŸºäºŽæŽ¨ç†çš„åŒ»å­¦å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹è™½èƒ½ç”Ÿæˆæ–‡æœ¬æŽ¨ç†é“¾ï¼Œä½†éš¾ä»¥åŠ¨æ€ã€è¿­ä»£åœ°èšç„¦ç»†ç²’åº¦è§†è§‰åŒºåŸŸï¼Œå¯¼è‡´æ€§èƒ½å—é™ï¼Œç—›ç‚¹åœ¨äºŽç¼ºä¹é«˜æ•ˆçš„å·¥å…·é›†æˆå’Œè§†è§‰è¯æ®ç®¡ç†æœºåˆ¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯è®¾è®¡ä¸€ä¸ªå·¥å…·å¢žå¼ºçš„æ¡†æž¶Ophiuchusï¼Œé€šè¿‡ç»“åˆæ¨¡åž‹å›ºæœ‰èƒ½åŠ›å’Œå¤–éƒ¨å·¥å…·ï¼Œå®žçŽ°åŠ¨æ€å†³ç­–ä½•æ—¶éœ€è¦è§†è§‰è¯æ®ã€ç¡®å®šæŽ¢æµ‹ä½ç½®ï¼Œå¹¶å°†å­å›¾åƒå†…å®¹é›†æˆåˆ°å¤šæ¨¡æ€æ€ç»´é“¾ä¸­ï¼Œä»¥æå‡æŽ¨ç†ç²¾åº¦å’Œé€‚åº”æ€§ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æž¶æž„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼šå†·å¯åŠ¨è®­ç»ƒé˜¶æ®µï¼Œä½¿ç”¨å·¥å…·é›†æˆæŽ¨ç†æ•°æ®è®­ç»ƒæ¨¡åž‹è¿›è¡ŒåŸºæœ¬å·¥å…·é€‰æ‹©å’Œå…³é”®åŒºåŸŸæ£€æŸ¥ï¼›è‡ªæˆ‘åæ€å¾®è°ƒé˜¶æ®µï¼ŒåŠ å¼ºåæ€æ€§æŽ¨ç†ï¼Œé¼“åŠ±æ¨¡åž‹é‡æ–°è¯„ä¼°å·¥å…·è¾“å‡ºï¼›ä»£ç†å·¥å…·å¼ºåŒ–å­¦ä¹ é˜¶æ®µï¼Œç›´æŽ¥ä¼˜åŒ–ä»»åŠ¡ç‰¹å®šå¥–åŠ±ï¼Œæ¨¡æ‹Ÿä¸“å®¶è¯Šæ–­è¡Œä¸ºï¼Œå½¢æˆç«¯åˆ°ç«¯çš„å·¥å…·å¢žå¼ºæŽ¨ç†æµç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°æ˜¯æå‡ºä¸‰é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼Œå°†å·¥å…·é›†æˆä¸Žæ¨¡åž‹æŽ¨ç†æ·±åº¦èžåˆï¼ŒåŒºåˆ«äºŽçŽ°æœ‰æ–¹æ³•ä»…ä¾èµ–ä¸“ç”¨å·¥å…·æˆ–å•ä¸€æ¨¡åž‹èƒ½åŠ›ï¼Œæœ¬è´¨åŒºåˆ«åœ¨äºŽå®žçŽ°äº†åŠ¨æ€è§†è§‰èšç„¦å’Œå·¥å…·è¾“å‡ºçš„è¿­ä»£ä¼˜åŒ–ï¼Œä»Žè€Œçªç ´æ€§èƒ½ä¸Šé™ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼šä½¿ç”¨å·¥å…·é›†æˆæŽ¨ç†æ•°æ®è¿›è¡Œå†·å¯åŠ¨è®­ç»ƒï¼Œä»¥åˆå§‹åŒ–æ¨¡åž‹å·¥å…·é€‚åº”èƒ½åŠ›ï¼›å¼•å…¥è‡ªæˆ‘åæ€æœºåˆ¶ï¼Œé€šè¿‡å¾®è°ƒå¢žå¼ºæ¨¡åž‹å¯¹å·¥å…·è¾“å‡ºçš„æ‰¹åˆ¤æ€§è¯„ä¼°ï¼›é‡‡ç”¨å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–ä»»åŠ¡å¥–åŠ±å‡½æ•°ï¼Œå…·ä½“å‚æ•°è®¾ç½®å¦‚å¥–åŠ±å‡½æ•°è®¾è®¡ã€ç½‘ç»œç»“æž„çš„å¤šæ¨¡æ€èžåˆæ¨¡å—ç­‰ç»†èŠ‚æœªåœ¨æ‘˜è¦ä¸­è¯¦è¿°ï¼Œä½†æ•´ä½“å¼ºè°ƒç«¯åˆ°ç«¯ä¼˜åŒ–å’Œå·¥å…·ååŒã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒOphiuchusåœ¨å¤šç§åŒ»å­¦åŸºå‡†æµ‹è¯•ä¸­å‡ä¼˜äºŽå½“å‰æœ€å…ˆè¿›æ–¹æ³•ï¼ŒåŒ…æ‹¬é—­æºå’Œå¼€æºæ¨¡åž‹ã€‚å…·ä½“æ€§èƒ½æ•°æ®æœªåœ¨æ‘˜è¦ä¸­æä¾›ï¼Œä½†å¼ºè°ƒäº†åœ¨VQAã€æ£€æµ‹å’ŒåŸºäºŽæŽ¨ç†çš„åˆ†å‰²ä»»åŠ¡ä¸Šçš„æ˜¾è‘—æå‡ï¼ŒéªŒè¯äº†æ¡†æž¶åœ¨åŠ¨æ€è§†è§‰èšç„¦å’Œå·¥å…·é›†æˆæ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œä¸ºåŒ»å­¦AIä»£ç†çš„å®žç”¨åŒ–æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨åŒ»å­¦å›¾åƒåˆ†æžé¢†åŸŸå…·æœ‰å¹¿æ³›æ½œåœ¨åº”ç”¨ï¼ŒåŒ…æ‹¬åŒ»å­¦è§†è§‰é—®ç­”ã€ç—…å˜æ£€æµ‹å’ŒåŸºäºŽæŽ¨ç†çš„å›¾åƒåˆ†å‰²ç­‰ä»»åŠ¡ã€‚å…¶å®žé™…ä»·å€¼åœ¨äºŽæå‡AIç³»ç»Ÿåœ¨å¤æ‚åŒ»ç–—åœºæ™¯ä¸­çš„è¯Šæ–­ç²¾åº¦å’Œè‡ªåŠ¨åŒ–æ°´å¹³ï¼Œæœªæ¥å¯èƒ½æŽ¨åŠ¨åŒ»å­¦AIä»£ç†çš„å‘å±•ï¼Œå®žçŽ°æ›´æ™ºèƒ½ã€äº¤äº’å¼çš„è¾…åŠ©è¯Šæ–­å·¥å…·ï¼Œå¯¹åŒ»ç–—å½±åƒåˆ†æžå’Œä¸´åºŠå†³ç­–æ”¯æŒäº§ç”Ÿç§¯æžå½±å“ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent reasoning based medical MLLMs have made progress in generating step by step textual reasoning chains. However, they still struggle with complex tasks that necessitate dynamic and iterative focusing on fine-grained visual regions to achieve precise grounding and diagnosis. We introduce Ophiuchus, a versatile, tool-augmented framework that equips an MLLM to (i) decide when additional visual evidence is needed, (ii) determine where to probe and ground within the medical image, and (iii) seamlessly weave the relevant sub-image content back into an interleaved, multimodal chain of thought. In contrast to prior approaches limited by the performance ceiling of specialized tools, Ophiuchus integrates the model's inherent grounding and perception capabilities with external tools, thereby fostering higher-level reasoning. The core of our method is a three-stage training strategy: cold-start training with tool-integrated reasoning data to achieve basic tool selection and adaptation for inspecting key regions; self-reflection fine-tuning to strengthen reflective reasoning and encourage revisiting tool outputs; and Agentic Tool Reinforcement Learning to directly optimize task-specific rewards and emulate expert-like diagnostic behavior. Extensive experiments show that Ophiuchus consistently outperforms both closed-source and open-source SOTA methods across diverse medical benchmarks, including VQA, detection, and reasoning-based segmentation. Our approach illuminates a path toward medical AI agents that can genuinely "think with images" through tool-integrated reasoning. Datasets, codes, and trained models will be released publicly.

