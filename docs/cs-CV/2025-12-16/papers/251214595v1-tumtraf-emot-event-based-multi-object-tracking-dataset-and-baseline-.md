---
layout: default
title: TUMTraf EMOT: Event-Based Multi-Object Tracking Dataset and Baseline for Traffic Scenarios
---

# TUMTraf EMOT: Event-Based Multi-Object Tracking Dataset and Baseline for Traffic Scenarios

**arXiv**: [2512.14595v1](https://arxiv.org/abs/2512.14595) | [PDF](https://arxiv.org/pdf/2512.14595.pdf)

**ä½œè€…**: Mengyu Li, Xingcheng Zhou, Guang Chen, Alois Knoll, Hu Cao

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: 10 pages, 9 figures

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTUMTraf EMOTæ•°æ®é›†å’ŒåŸºå‡†æ–¹æ³•ï¼Œä»¥è§£å†³æ™ºèƒ½äº¤é€šç³»ç»Ÿä¸­åŸºäºŽäº‹ä»¶ç›¸æœºçš„å¤šç›®æ ‡è·Ÿè¸ªé—®é¢˜ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **è‡ªåŠ¨é©¾é©¶** **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `äº‹ä»¶ç›¸æœº` `å¤šç›®æ ‡è·Ÿè¸ª` `æ™ºèƒ½äº¤é€šç³»ç»Ÿ` `æ•°æ®é›†` `ç‰¹å¾æå–` `æ£€æµ‹-è·Ÿè¸ª` `å¼±å…‰æ¡ä»¶` `é«˜é€Ÿåº¦è¿åŠ¨`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¸§å¼ç›¸æœºåœ¨å¼±å…‰å’Œé«˜é€Ÿåº¦è¿åŠ¨æ¡ä»¶ä¸‹æ€§èƒ½ä¸ä½³ï¼Œé™åˆ¶äº†æ™ºèƒ½äº¤é€šç³»ç»Ÿä¸­å¤šç›®æ ‡è·Ÿè¸ªçš„å¯é æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæå‡ºTUMTraf EMOTæ•°æ®é›†å’ŒåŸºå‡†æ–¹æ³•ï¼Œåˆ©ç”¨äº‹ä»¶ç›¸æœºçš„ä¼˜åŠ¿ï¼Œé€šè¿‡ä¸“é—¨çš„ç‰¹å¾æå–å™¨æå‡è·Ÿè¸ªæ€§èƒ½ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåŸºäºŽæ–°æ•°æ®é›†å»ºç«‹åŸºå‡†ï¼Œå®žçŽ°äº†ä¼˜å¼‚çš„è·Ÿè¸ªæ€§èƒ½ï¼ŒéªŒè¯äº†äº‹ä»¶ç›¸æœºåœ¨äº¤é€šåœºæ™¯ä¸­çš„æ½œåŠ›ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨æ™ºèƒ½äº¤é€šç³»ç»Ÿä¸­ï¼Œå¤šç›®æ ‡è·Ÿè¸ªä¸»è¦åŸºäºŽå¸§å¼ç›¸æœºï¼Œä½†è¿™äº›ç›¸æœºåœ¨å¼±å…‰å’Œé«˜é€Ÿåº¦è¿åŠ¨æ¡ä»¶ä¸‹æ€§èƒ½è¾ƒå·®ã€‚äº‹ä»¶ç›¸æœºå…·æœ‰ä½Žå»¶è¿Ÿã€é«˜åŠ¨æ€èŒƒå›´å’Œé«˜æ—¶é—´åˆ†è¾¨çŽ‡çš„ç‰¹ç‚¹ï¼Œæœ‰æ½œåŠ›ç¼“è§£è¿™äº›é—®é¢˜ã€‚ä¸ŽåŸºäºŽå¸§çš„è§†è§‰ç›¸æ¯”ï¼ŒåŸºäºŽäº‹ä»¶çš„è§†è§‰ç ”ç©¶è¾ƒå°‘ã€‚ä¸ºå¡«è¡¥è¿™ä¸€ç ”ç©¶ç©ºç™½ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªä¸“ä¸ºåŸºäºŽäº‹ä»¶çš„æ™ºèƒ½äº¤é€šç³»ç»Ÿè®¾è®¡çš„åˆå§‹è¯•ç‚¹æ•°æ®é›†ï¼Œæ¶µç›–è½¦è¾†å’Œè¡Œäººçš„æ£€æµ‹ä¸Žè·Ÿè¸ªã€‚åŸºäºŽæ­¤æ•°æ®é›†ï¼Œæˆ‘ä»¬å»ºç«‹äº†ä¸€ä¸ªæ£€æµ‹-è·Ÿè¸ªåŸºå‡†ï¼Œå¹¶é‡‡ç”¨ä¸“é—¨çš„ç‰¹å¾æå–å™¨ï¼Œå®žçŽ°äº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

è®ºæ–‡é‡‡ç”¨æ£€æµ‹-è·Ÿè¸ªæ¡†æž¶ï¼Œæ ¸å¿ƒæ–¹æ³•åŒ…æ‹¬åŸºäºŽTUMTraf EMOTæ•°æ®é›†çš„ä¸“é—¨ç‰¹å¾æå–å™¨ã€‚æ•´ä½“æ¡†æž¶ç»“åˆäº‹ä»¶ç›¸æœºçš„ä½Žå»¶è¿Ÿå’Œé«˜æ—¶é—´åˆ†è¾¨çŽ‡ç‰¹æ€§ï¼Œé€šè¿‡ä¼˜åŒ–ç‰¹å¾è¡¨ç¤ºæ¥æå‡å¤šç›®æ ‡è·Ÿè¸ªçš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚å…³é”®æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽé’ˆå¯¹äº‹ä»¶æ•°æ®è®¾è®¡ç‰¹å¾æå–å™¨ï¼Œä»¥å¤„ç†åŠ¨æ€äº¤é€šåœºæ™¯ä¸­çš„æŒ‘æˆ˜ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºŽä¸“æ³¨äºŽäº‹ä»¶ç›¸æœºæ•°æ®ï¼Œè€Œéžä¼ ç»Ÿå¸§å¼ç›¸æœºï¼Œä»Žè€Œåœ¨å¼±å…‰å’Œé«˜é€Ÿåº¦æ¡ä»¶ä¸‹æä¾›æ›´ä¼˜æ€§èƒ½ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœæ˜¾ç¤ºï¼ŒåŸºäºŽTUMTraf EMOTæ•°æ®é›†çš„åŸºå‡†æ–¹æ³•åœ¨è½¦è¾†å’Œè¡Œäººè·Ÿè¸ªä»»åŠ¡ä¸­å®žçŽ°äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼ŒéªŒè¯äº†äº‹ä»¶ç›¸æœºåœ¨äº¤é€šåœºæ™¯ä¸­çš„æœ‰æ•ˆæ€§ï¼Œå°¤å…¶åœ¨æŒ‘æˆ˜æ€§æ¡ä»¶ä¸‹ç›¸æ¯”å¸§å¼ç›¸æœºæœ‰æ˜¾è‘—æå‡ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å¯åº”ç”¨äºŽæ™ºèƒ½äº¤é€šç³»ç»Ÿï¼Œå¦‚è‡ªåŠ¨é©¾é©¶ã€äº¤é€šç›‘æŽ§å’Œè¡Œäººå®‰å…¨ï¼Œç‰¹åˆ«æ˜¯åœ¨å¼±å…‰ã€é«˜åŠ¨æ€èŒƒå›´æˆ–é«˜é€Ÿè¿åŠ¨åœºæ™¯ä¸­ï¼Œæå‡å¤šç›®æ ‡è·Ÿè¸ªçš„å¯é æ€§å’Œå®žæ—¶æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In Intelligent Transportation Systems (ITS), multi-object tracking is primarily based on frame-based cameras. However, these cameras tend to perform poorly under dim lighting and high-speed motion conditions. Event cameras, characterized by low latency, high dynamic range and high temporal resolution, have considerable potential to mitigate these issues. Compared to frame-based vision, there are far fewer studies on event-based vision. To address this research gap, we introduce an initial pilot dataset tailored for event-based ITS, covering vehicle and pedestrian detection and tracking. We establish a tracking-by-detection benchmark with a specialized feature extractor based on this dataset, achieving excellent performance.

