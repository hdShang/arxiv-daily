---
layout: default
title: MMGR: Multi-Modal Generative Reasoning
---

# MMGR: Multi-Modal Generative Reasoning

**arXiv**: [2512.14691v1](https://arxiv.org/abs/2512.14691) | [PDF](https://arxiv.org/pdf/2512.14691.pdf)

**ä½œè€…**: Zefan Cai, Haoyi Qiu, Tianyi Ma, Haozhe Zhao, Gengze Zhou, Kung-Hsiang Huang, Parisa Kordjamshidi, Minjia Zhang, Xiao Wen, Jiuxiang Gu, Nanyun Peng, Junjie Hu

**åˆ†ç±»**: cs.CL, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: work in progress

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMMGRå¤šæ¨¡æ€ç”ŸæˆæŽ¨ç†è¯„ä¼°æ¡†æž¶ï¼Œä»¥è§£å†³è§†é¢‘åŸºç¡€æ¨¡åž‹åœ¨ç‰©ç†ã€é€»è¾‘å’Œç©ºé—´çº¦æŸä¸Šçš„æŽ¨ç†èƒ½åŠ›ä¸è¶³é—®é¢˜ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **è§†è§‰é‡Œç¨‹è®¡** **ä¸–ç•Œæ¨¡åž‹** **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `å¤šæ¨¡æ€ç”ŸæˆæŽ¨ç†` `è§†é¢‘åŸºç¡€æ¨¡åž‹è¯„ä¼°` `ç‰©ç†é€»è¾‘çº¦æŸ` `æŠ½è±¡æŽ¨ç†åŸºå‡†` `å…·èº«å¯¼èˆª` `å…¨å±€ä¸€è‡´æ€§` `å› æžœæ­£ç¡®æ€§` `ä¸–ç•Œæ¨¡æ‹Ÿå™¨`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è§†é¢‘åŸºç¡€æ¨¡åž‹è¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚FVDï¼‰è¿‡äºŽå…³æ³¨æ„ŸçŸ¥è´¨é‡ï¼Œå¿½ç•¥äº†ç‰©ç†ã€é€»è¾‘å’Œç©ºé—´æŽ¨ç†å¤±è´¥ï¼Œå¯¼è‡´æ¨¡åž‹ä½œä¸ºä¸–ç•Œæ¨¡æ‹Ÿå™¨çš„å¯é æ€§ä¸è¶³ã€‚
2. è®ºæ–‡æå‡ºMMGRæ¡†æž¶ï¼ŒåŸºäºŽäº”ç§æŽ¨ç†èƒ½åŠ›ï¼ˆç‰©ç†ã€é€»è¾‘ã€3Dç©ºé—´ã€2Dç©ºé—´ã€æ—¶åºï¼‰æž„å»ºåŽŸåˆ™æ€§è¯„ä¼°ï¼Œè¦†ç›–æŠ½è±¡æŽ¨ç†ã€å…·èº«å¯¼èˆªå’Œç‰©ç†å¸¸è¯†ä¸‰ä¸ªé¢†åŸŸã€‚
3. å®žéªŒæ˜¾ç¤ºï¼Œä¸»æµæ¨¡åž‹åœ¨ç‰©ç†å¸¸è¯†ä»»åŠ¡ä¸Šè¡¨çŽ°ä¸­ç­‰ï¼Œä½†åœ¨æŠ½è±¡æŽ¨ç†ï¼ˆå¦‚ARC-AGIå‡†ç¡®çŽ‡ä½ŽäºŽ10%ï¼‰å’Œé•¿æ—¶ç¨‹ç©ºé—´è§„åˆ’ä¸Šè¡¨çŽ°å·®ï¼Œæ­ç¤ºäº†æ¨¡åž‹çš„å…³é”®å±€é™æ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†é¢‘åŸºç¡€æ¨¡åž‹èƒ½å¤Ÿç”Ÿæˆè§†è§‰é€¼çœŸä¸”æ—¶åºè¿žè´¯çš„å†…å®¹ï¼Œä½†å…¶ä½œä¸ºä¸–ç•Œæ¨¡æ‹Ÿå™¨çš„å¯é æ€§å–å†³äºŽæ˜¯å¦æ•æ‰äº†ç‰©ç†ã€é€»è¾‘å’Œç©ºé—´çº¦æŸã€‚çŽ°æœ‰æŒ‡æ ‡å¦‚å¼—é›·æ­‡è§†é¢‘è·ç¦»ï¼ˆFVDï¼‰å¼ºè°ƒæ„ŸçŸ¥è´¨é‡è€Œå¿½è§†äº†æŽ¨ç†å¤±è´¥ï¼ŒåŒ…æ‹¬è¿åå› æžœæ€§ã€ç‰©ç†è§„å¾‹å’Œå…¨å±€ä¸€è‡´æ€§ã€‚æˆ‘ä»¬å¼•å…¥äº†MMGRï¼ˆå¤šæ¨¡æ€ç”ŸæˆæŽ¨ç†è¯„ä¼°ä¸ŽåŸºå‡†ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºŽäº”ç§æŽ¨ç†èƒ½åŠ›çš„åŽŸåˆ™æ€§è¯„ä¼°æ¡†æž¶ï¼šç‰©ç†ã€é€»è¾‘ã€3Dç©ºé—´ã€2Dç©ºé—´å’Œæ—¶åºæŽ¨ç†ã€‚MMGRåœ¨ä¸‰ä¸ªé¢†åŸŸè¯„ä¼°ç”ŸæˆæŽ¨ç†ï¼šæŠ½è±¡æŽ¨ç†ï¼ˆARC-AGIã€æ•°ç‹¬ï¼‰ã€å…·èº«å¯¼èˆªï¼ˆçœŸå®žä¸–ç•Œ3Då¯¼èˆªå’Œå®šä½ï¼‰ä»¥åŠç‰©ç†å¸¸è¯†ï¼ˆè¿åŠ¨å’Œç»„åˆäº¤äº’ï¼‰ã€‚MMGRåº”ç”¨ç»†ç²’åº¦æŒ‡æ ‡ï¼Œè¦æ±‚è§†é¢‘å’Œå›¾åƒç”Ÿæˆåœ¨æ•´ä½“ä¸Šæ­£ç¡®ã€‚æˆ‘ä»¬åŸºå‡†æµ‹è¯•äº†é¢†å…ˆçš„è§†é¢‘æ¨¡åž‹ï¼ˆVeo-3ã€Sora-2ã€Wan-2.2ï¼‰å’Œå›¾åƒæ¨¡åž‹ï¼ˆNano-bananaã€Nano-banana Proã€GPT-4o-imageã€Qwen-imageï¼‰ï¼Œæ­ç¤ºäº†è·¨é¢†åŸŸçš„æ˜¾è‘—æ€§èƒ½å·®è·ã€‚æ¨¡åž‹åœ¨ç‰©ç†å¸¸è¯†ä»»åŠ¡ä¸Šè¡¨çŽ°ä¸­ç­‰ï¼Œä½†åœ¨æŠ½è±¡æŽ¨ç†ä¸Šè¡¨çŽ°ä¸ä½³ï¼ˆARC-AGIå‡†ç¡®çŽ‡ä½ŽäºŽ10%ï¼‰ï¼Œå¹¶åœ¨å…·èº«è®¾ç½®ä¸­çš„é•¿æ—¶ç¨‹ç©ºé—´è§„åˆ’ä¸Šé‡åˆ°å›°éš¾ã€‚æˆ‘ä»¬çš„åˆ†æžçªå‡ºäº†å½“å‰æ¨¡åž‹çš„å…³é”®å±€é™æ€§ï¼ŒåŒ…æ‹¬è¿‡åº¦ä¾èµ–æ„ŸçŸ¥æ•°æ®ã€å…¨å±€çŠ¶æ€ä¸€è‡´æ€§å¼±ï¼Œä»¥åŠç›®æ ‡å‡½æ•°å¥–åŠ±è§†è§‰åˆç†æ€§è€Œéžå› æžœæ­£ç¡®æ€§ã€‚MMGRæä¾›äº†ä¸€ä¸ªç»Ÿä¸€çš„è¯Šæ–­åŸºå‡†å’Œä¸€æ¡é€šå‘æŽ¨ç†æ„ŸçŸ¥ç”Ÿæˆä¸–ç•Œæ¨¡åž‹çš„è·¯å¾„ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è§†é¢‘åŸºç¡€æ¨¡åž‹åœ¨ç”Ÿæˆå†…å®¹æ—¶ç¼ºä¹ç‰©ç†ã€é€»è¾‘å’Œç©ºé—´æŽ¨ç†èƒ½åŠ›çš„é—®é¢˜ï¼ŒçŽ°æœ‰æ–¹æ³•å¦‚FVDç­‰æŒ‡æ ‡ä»…è¯„ä¼°æ„ŸçŸ¥è´¨é‡ï¼Œå¿½è§†äº†å› æžœæ€§ã€ç‰©ç†è§„å¾‹å’Œå…¨å±€ä¸€è‡´æ€§çš„è¿åï¼Œå¯¼è‡´æ¨¡åž‹ä½œä¸ºä¸–ç•Œæ¨¡æ‹Ÿå™¨ä¸å¯é ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯è®¾è®¡ä¸€ä¸ªå¤šæ¨¡æ€ç”ŸæˆæŽ¨ç†è¯„ä¼°æ¡†æž¶ï¼ˆMMGRï¼‰ï¼Œé€šè¿‡å®šä¹‰äº”ç§æŽ¨ç†èƒ½åŠ›ï¼ˆç‰©ç†ã€é€»è¾‘ã€3Dç©ºé—´ã€2Dç©ºé—´ã€æ—¶åºï¼‰å’Œä¸‰ä¸ªè¯„ä¼°é¢†åŸŸï¼ˆæŠ½è±¡æŽ¨ç†ã€å…·èº«å¯¼èˆªã€ç‰©ç†å¸¸è¯†ï¼‰ï¼Œæ¥ç³»ç»Ÿæ€§åœ°é‡åŒ–æ¨¡åž‹çš„æŽ¨ç†æ€§èƒ½ï¼Œä»Žè€Œè¯Šæ–­å’Œæå‡æ¨¡åž‹çš„ç”Ÿæˆè´¨é‡ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šMMGRçš„æ•´ä½“æž¶æž„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼šé¦–å…ˆï¼Œå®šä¹‰äº”ç§æŽ¨ç†èƒ½åŠ›ä½œä¸ºè¯„ä¼°ç»´åº¦ï¼›å…¶æ¬¡ï¼Œæž„å»ºä¸‰ä¸ªè¯„ä¼°é¢†åŸŸï¼Œæ¯ä¸ªé¢†åŸŸåŒ…å«å…·ä½“ä»»åŠ¡ï¼ˆå¦‚ARC-AGIã€æ•°ç‹¬ã€3Då¯¼èˆªã€ä½“è‚²äº¤äº’ï¼‰ï¼›ç„¶åŽï¼Œåº”ç”¨ç»†ç²’åº¦æŒ‡æ ‡ï¼Œè¦æ±‚è§†é¢‘å’Œå›¾åƒç”Ÿæˆåœ¨æ•´ä½“ä¸Šæ­£ç¡®ï¼Œä»¥è¯„ä¼°æ¨¡åž‹åœ¨è¿™äº›ä»»åŠ¡ä¸Šçš„è¡¨çŽ°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹æ˜¯æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„ã€åŸºäºŽæŽ¨ç†èƒ½åŠ›çš„è¯„ä¼°æ¡†æž¶ï¼Œä¸ŽçŽ°æœ‰æ–¹æ³•ï¼ˆå¦‚FVDï¼‰çš„æœ¬è´¨åŒºåˆ«åœ¨äºŽï¼ŒMMGRå¼ºè°ƒå› æžœæ­£ç¡®æ€§å’Œå…¨å±€ä¸€è‡´æ€§ï¼Œè€Œéžä»…è§†è§‰åˆç†æ€§ï¼Œä»Žè€Œæ›´å…¨é¢åœ°è¯„ä¼°æ¨¡åž‹ä½œä¸ºä¸–ç•Œæ¨¡æ‹Ÿå™¨çš„èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼šäº”ç§æŽ¨ç†èƒ½åŠ›çš„ç²¾ç¡®å®šä¹‰ï¼ˆä¾‹å¦‚ï¼Œç‰©ç†æŽ¨ç†æ¶‰åŠè¿åŠ¨è§„å¾‹ï¼Œé€»è¾‘æŽ¨ç†æ¶‰åŠè§„åˆ™éµå¾ªï¼‰ï¼Œä¸‰ä¸ªè¯„ä¼°é¢†åŸŸçš„ä»»åŠ¡é€‰æ‹©ï¼ˆå¦‚æŠ½è±¡æŽ¨ç†ä½¿ç”¨ARC-AGIå’Œæ•°ç‹¬ï¼Œå…·èº«å¯¼èˆªä½¿ç”¨çœŸå®žä¸–ç•Œ3Dåœºæ™¯ï¼‰ï¼Œä»¥åŠç»†ç²’åº¦æŒ‡æ ‡çš„åº”ç”¨ï¼ˆè¦æ±‚ç”Ÿæˆå†…å®¹åœ¨è§†é¢‘å’Œå›¾åƒå±‚é¢éƒ½ç¬¦åˆæŽ¨ç†çº¦æŸï¼‰ï¼Œå…·ä½“å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°åœ¨è®ºæ–‡ä¸­æœªè¯¦ç»†è¯´æ˜Žï¼Œå¯èƒ½ä¾èµ–äºŽä»»åŠ¡ç‰¹å®šçš„è¯„ä¼°æ ‡å‡†ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœæ˜¾ç¤ºï¼Œä¸»æµè§†é¢‘æ¨¡åž‹ï¼ˆå¦‚Veo-3ã€Sora-2ã€Wan-2.2ï¼‰å’Œå›¾åƒæ¨¡åž‹ï¼ˆå¦‚Nano-bananaã€GPT-4o-imageï¼‰åœ¨MMGRåŸºå‡†ä¸Šè¡¨çŽ°å·®å¼‚æ˜¾è‘—ï¼šåœ¨ç‰©ç†å¸¸è¯†ä»»åŠ¡ä¸Šå‡†ç¡®çŽ‡ä¸­ç­‰ï¼Œä½†åœ¨æŠ½è±¡æŽ¨ç†ä»»åŠ¡ï¼ˆå¦‚ARC-AGIï¼‰ä¸Šå‡†ç¡®çŽ‡ä½ŽäºŽ10%ï¼Œå…·èº«å¯¼èˆªä¸­çš„é•¿æ—¶ç¨‹ç©ºé—´è§„åˆ’è¡¨çŽ°å·®ï¼Œæ­ç¤ºäº†æ¨¡åž‹åœ¨æŽ¨ç†èƒ½åŠ›ä¸Šçš„å…³é”®çŸ­æ¿ï¼Œå¯¹æ¯”çŽ°æœ‰æŒ‡æ ‡å¦‚FVDï¼ŒMMGRæ›´å…¨é¢åœ°æš´éœ²äº†æ¨¡åž‹å±€é™æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨äººå·¥æ™ºèƒ½å’Œæœºå™¨å­¦ä¹ é¢†åŸŸå…·æœ‰å¹¿æ³›æ½œåœ¨åº”ç”¨ï¼Œå¯ç”¨äºŽè¯„ä¼°å’Œæå‡è§†é¢‘ç”Ÿæˆæ¨¡åž‹ã€æœºå™¨äººå¯¼èˆªç³»ç»Ÿã€è™šæ‹ŸçŽ°å®žæ¨¡æ‹Ÿå™¨çš„æŽ¨ç†èƒ½åŠ›ï¼ŒæŽ¨åŠ¨ç”Ÿæˆå¼AIå‘æ›´å¯é çš„ä¸–ç•Œæ¨¡æ‹Ÿå™¨å‘å±•ï¼Œæœªæ¥å¯èƒ½å½±å“è‡ªåŠ¨é©¾é©¶ã€æ¸¸æˆå¼€å‘ã€æ•™è‚²æ¨¡æ‹Ÿç­‰å®žé™…åœºæ™¯ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Video foundation models generate visually realistic and temporally coherent content, but their reliability as world simulators depends on whether they capture physical, logical, and spatial constraints. Existing metrics such as Frechet Video Distance (FVD) emphasize perceptual quality and overlook reasoning failures, including violations of causality, physics, and global consistency. We introduce MMGR (Multi-Modal Generative Reasoning Evaluation and Benchmark), a principled evaluation framework based on five reasoning abilities: Physical, Logical, 3D Spatial, 2D Spatial, and Temporal. MMGR evaluates generative reasoning across three domains: Abstract Reasoning (ARC-AGI, Sudoku), Embodied Navigation (real-world 3D navigation and localization), and Physical Commonsense (sports and compositional interactions). MMGR applies fine-grained metrics that require holistic correctness across both video and image generation. We benchmark leading video models (Veo-3, Sora-2, Wan-2.2) and image models (Nano-banana, Nano-banana Pro, GPT-4o-image, Qwen-image), revealing strong performance gaps across domains. Models show moderate success on Physical Commonsense tasks but perform poorly on Abstract Reasoning (below 10 percent accuracy on ARC-AGI) and struggle with long-horizon spatial planning in embodied settings. Our analysis highlights key limitations in current models, including overreliance on perceptual data, weak global state consistency, and objectives that reward visual plausibility over causal correctness. MMGR offers a unified diagnostic benchmark and a path toward reasoning-aware generative world models.

