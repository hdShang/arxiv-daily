---
layout: default
title: Sparse-LaViDa: Sparse Multimodal Discrete Diffusion Language Models
---

# Sparse-LaViDa: Sparse Multimodal Discrete Diffusion Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.14008" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.14008v1</a>
  <a href="https://arxiv.org/pdf/2512.14008.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14008v1" onclick="toggleFavorite(this, '2512.14008v1', 'Sparse-LaViDa: Sparse Multimodal Discrete Diffusion Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shufan Li, Jiuxiang Gu, Kangning Liu, Zhe Lin, Zijun Wei, Aditya Grover, Jason Kuen

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: 18 pages (12 pages for the main paper and 6 pages for the appendix), 9 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Sparse-LaViDaï¼šé€šè¿‡ç¨€ç–åŒ–é‡‡æ ·åŠ é€Ÿå¤šæ¨¡æ€ç¦»æ•£æ‰©æ•£è¯­è¨€æ¨¡å‹æ¨ç†ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ‰©æ•£æ¨¡å‹` `ç¨€ç–é‡‡æ ·` `æ¨¡å‹åŠ é€Ÿ` `å›¾åƒç”Ÿæˆ` `å›¾åƒç¼–è¾‘`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. MDMæ¨ç†é€Ÿåº¦å—é™äºé‡å¤å¤„ç†å†—ä½™masked tokensï¼Œæ•ˆç‡æœ‰å¾…æå‡ã€‚
2. Sparse-LaViDaåŠ¨æ€æˆªæ–­ä¸å¿…è¦çš„masked tokensï¼Œå¹¶ç”¨register tokensä¿æŒç”Ÿæˆè´¨é‡ã€‚
3. é€šè¿‡ä¸“é—¨è®¾è®¡çš„attention maskï¼ŒSparse-LaViDaä¿è¯è®­ç»ƒä¸æ¨ç†è¿‡ç¨‹çš„ä¸€è‡´æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºSparse-LaViDaçš„æ–°å»ºæ¨¡æ¡†æ¶ï¼Œæ—¨åœ¨åŠ é€ŸMasked Discrete Diffusion Models (MDMs)çš„æ¨ç†è¿‡ç¨‹ã€‚MDMsåœ¨å›¾åƒç†è§£ã€ç”Ÿæˆå’Œç¼–è¾‘ç­‰å¤šç§å¤šæ¨¡æ€ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†ç”±äºéœ€è¦åœ¨æ¯ä¸ªé‡‡æ ·æ­¥éª¤ä¸­é‡å¤å¤„ç†å†—ä½™çš„masked tokensï¼Œå…¶æ¨ç†é€Ÿåº¦ä»æœ‰ä¼˜åŒ–ç©ºé—´ã€‚Sparse-LaViDaé€šè¿‡åœ¨æ¯ä¸ªæ¨ç†æ­¥éª¤ä¸­åŠ¨æ€æˆªæ–­ä¸å¿…è¦çš„masked tokensæ¥åŠ é€ŸMDMé‡‡æ ·ã€‚ä¸ºäº†ä¿æŒç”Ÿæˆè´¨é‡ï¼Œå¼•å…¥äº†ä¸“é—¨çš„register tokensï¼Œä½œä¸ºè¢«æˆªæ–­tokensçš„ç´§å‡‘è¡¨ç¤ºã€‚æ­¤å¤–ï¼Œä¸ºäº†ç¡®ä¿è®­ç»ƒå’Œæ¨ç†ä¹‹é—´çš„ä¸€è‡´æ€§ï¼Œè®¾è®¡äº†ä¸€ç§ä¸“é—¨çš„attention maskï¼Œåœ¨è®­ç»ƒæœŸé—´å¿ å®åœ°åŒ¹é…æˆªæ–­çš„é‡‡æ ·è¿‡ç¨‹ã€‚åŸºäºæœ€å…ˆè¿›çš„ç»Ÿä¸€MDM LaViDa-Oï¼ŒSparse-LaViDaåœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€å›¾åƒç¼–è¾‘å’Œæ•°å­¦æ¨ç†ç­‰å¤šç§ä»»åŠ¡ä¸­å®ç°äº†é«˜è¾¾2å€çš„åŠ é€Ÿï¼ŒåŒæ—¶ä¿æŒäº†ç”Ÿæˆè´¨é‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šMasked Discrete Diffusion Models (MDMs) åœ¨å¤šæ¨¡æ€ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†æ¨ç†é€Ÿåº¦è¾ƒæ…¢ï¼Œä¸»è¦åŸå› æ˜¯éœ€è¦åœ¨æ¯ä¸ªé‡‡æ ·æ­¥éª¤ä¸­é‡å¤å¤„ç†å¤§é‡çš„masked tokensã€‚è¿™äº›masked tokensåœ¨æ—©æœŸé˜¶æ®µå¯èƒ½å¯¹æœ€ç»ˆç»“æœè´¡çŒ®ä¸å¤§ï¼Œä½†ä»ç„¶éœ€è¦æ¶ˆè€—è®¡ç®—èµ„æºã€‚å› æ­¤ï¼Œå¦‚ä½•å‡å°‘å†—ä½™è®¡ç®—ï¼ŒåŠ é€ŸMDMçš„æ¨ç†è¿‡ç¨‹æ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSparse-LaViDaçš„æ ¸å¿ƒæ€è·¯æ˜¯åœ¨æ¨ç†è¿‡ç¨‹ä¸­åŠ¨æ€åœ°æˆªæ–­é‚£äº›å¯¹ç”Ÿæˆç»“æœå½±å“è¾ƒå°çš„masked tokensï¼Œä»è€Œå‡å°‘è®¡ç®—é‡ã€‚ä¸ºäº†å¼¥è¡¥æˆªæ–­tokenså¸¦æ¥çš„ä¿¡æ¯æŸå¤±ï¼Œå¼•å…¥äº†register tokensä½œä¸ºè¢«æˆªæ–­tokensçš„ç´§å‡‘è¡¨ç¤ºã€‚è¿™äº›register tokensèƒ½å¤Ÿä¿ç•™è¢«æˆªæ–­tokensçš„å…³é”®ä¿¡æ¯ï¼Œä»è€Œä¿è¯ç”Ÿæˆè´¨é‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSparse-LaViDaå»ºç«‹åœ¨ç°æœ‰çš„MDMæ¡†æ¶LaViDa-Oä¹‹ä¸Šã€‚å…¶ä¸»è¦æµç¨‹å¦‚ä¸‹ï¼š1) åœ¨æ¯ä¸ªé‡‡æ ·æ­¥éª¤ä¸­ï¼Œæ¨¡å‹é¦–å…ˆè¯„ä¼°æ¯ä¸ªmasked tokençš„é‡è¦æ€§ã€‚2) æ ¹æ®é‡è¦æ€§è¯„ä¼°ç»“æœï¼Œæˆªæ–­ä¸€éƒ¨åˆ†ä¸é‡è¦çš„masked tokensã€‚3) ä½¿ç”¨register tokensæ¥è¡¨ç¤ºè¢«æˆªæ–­çš„tokensã€‚4) ä½¿ç”¨ä¿®æ”¹åçš„attentionæœºåˆ¶ï¼Œå°†register tokensçš„ä¿¡æ¯èå…¥åˆ°å‰©ä½™çš„tokensä¸­ã€‚5) é‡å¤ä»¥ä¸Šæ­¥éª¤ï¼Œç›´åˆ°ç”Ÿæˆæœ€ç»ˆç»“æœã€‚

**å…³é”®åˆ›æ–°**ï¼šSparse-LaViDaçš„å…³é”®åˆ›æ–°åœ¨äºåŠ¨æ€æˆªæ–­æœºåˆ¶å’Œregister tokensçš„ä½¿ç”¨ã€‚åŠ¨æ€æˆªæ–­æœºåˆ¶èƒ½å¤Ÿæœ‰æ•ˆåœ°å‡å°‘è®¡ç®—é‡ï¼Œè€Œregister tokensèƒ½å¤Ÿä¿è¯ç”Ÿæˆè´¨é‡ã€‚æ­¤å¤–ï¼Œä¸ºäº†ä¿è¯è®­ç»ƒå’Œæ¨ç†çš„ä¸€è‡´æ€§ï¼Œè®ºæ–‡è¿˜è®¾è®¡äº†ä¸€ç§ä¸“é—¨çš„attention maskï¼Œåœ¨è®­ç»ƒæœŸé—´æ¨¡æ‹Ÿæˆªæ–­è¿‡ç¨‹ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­register tokensçš„è®¾è®¡æ˜¯ä¸€ä¸ªå…³é”®ç»†èŠ‚ã€‚register tokenséœ€è¦èƒ½å¤Ÿæœ‰æ•ˆåœ°è¡¨ç¤ºè¢«æˆªæ–­tokensçš„ä¿¡æ¯ï¼ŒåŒæ—¶ä¸èƒ½å¼•å…¥è¿‡å¤šçš„è®¡ç®—è´Ÿæ‹…ã€‚è®ºæ–‡ä¸­å¯èƒ½é‡‡ç”¨äº†æŸç§poolingæˆ–è€…attentionæœºåˆ¶æ¥ç”Ÿæˆregister tokensã€‚æ­¤å¤–ï¼Œattention maskçš„è®¾è®¡ä¹Ÿè‡³å…³é‡è¦ï¼Œå®ƒéœ€è¦ä¿è¯æ¨¡å‹åœ¨è®­ç»ƒæœŸé—´èƒ½å¤Ÿå­¦ä¹ åˆ°å¦‚ä½•å¤„ç†è¢«æˆªæ–­çš„tokensã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

Sparse-LaViDaåœ¨å¤šç§ä»»åŠ¡ä¸Šå®ç°äº†æ˜¾è‘—çš„åŠ é€Ÿæ•ˆæœï¼ŒåŒæ—¶ä¿æŒäº†ç”Ÿæˆè´¨é‡ã€‚ä¾‹å¦‚ï¼Œåœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä»»åŠ¡ä¸­ï¼ŒSparse-LaViDaå®ç°äº†é«˜è¾¾2å€çš„åŠ é€Ÿã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSparse-LaViDaèƒ½å¤Ÿæœ‰æ•ˆåœ°å‡å°‘å†—ä½™è®¡ç®—ï¼Œæé«˜MDMçš„æ¨ç†æ•ˆç‡ï¼Œè€Œä¸ä¼šæ˜¾è‘—é™ä½ç”Ÿæˆè´¨é‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Sparse-LaViDaå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼ŒåŒ…æ‹¬æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€å›¾åƒç¼–è¾‘ã€è§†é¢‘ç”Ÿæˆã€æœºå™¨äººæ§åˆ¶ç­‰ã€‚é€šè¿‡åŠ é€ŸMDMçš„æ¨ç†è¿‡ç¨‹ï¼ŒSparse-LaViDaå¯ä»¥é™ä½è®¡ç®—æˆæœ¬ï¼Œæé«˜ç”¨æˆ·ä½“éªŒï¼Œå¹¶ä¿ƒè¿›å¤šæ¨¡æ€äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å‘å±•ã€‚è¯¥æ–¹æ³•åœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šéƒ¨ç½²å¤§å‹å¤šæ¨¡æ€æ¨¡å‹å…·æœ‰é‡è¦æ„ä¹‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Masked Discrete Diffusion Models (MDMs) have achieved strong performance across a wide range of multimodal tasks, including image understanding, generation, and editing. However, their inference speed remains suboptimal due to the need to repeatedly process redundant masked tokens at every sampling step. In this work, we propose Sparse-LaViDa, a novel modeling framework that dynamically truncates unnecessary masked tokens at each inference step to accelerate MDM sampling. To preserve generation quality, we introduce specialized register tokens that serve as compact representations for the truncated tokens. Furthermore, to ensure consistency between training and inference, we design a specialized attention mask that faithfully matches the truncated sampling procedure during training. Built upon the state-of-the-art unified MDM LaViDa-O, Sparse-LaViDa achieves up to a 2x speedup across diverse tasks including text-to-image generation, image editing, and mathematical reasoning, while maintaining generation quality.

