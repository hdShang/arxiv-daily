---
layout: default
title: AfroBeats Dance Movement Analysis Using Computer Vision: A Proof-of-Concept Framework Combining YOLO and Segment Anything Model
---

# AfroBeats Dance Movement Analysis Using Computer Vision: A Proof-of-Concept Framework Combining YOLO and Segment Anything Model

**arXiv**: [2512.03509v1](https://arxiv.org/abs/2512.03509) | [PDF](https://arxiv.org/pdf/2512.03509.pdf)

**ä½œè€…**: Kwaku Opoku-Ware, Gideon Opoku

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-03

**DOI**: [10.48550/arXiv.2512.03509](https://doi.org/10.48550/arXiv.2512.03509)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»“åˆYOLOå’ŒSAMçš„AfroBeatsèˆžè¹ˆåŠ¨ä½œåˆ†æžæ¡†æž¶ï¼Œæ— éœ€ä¸“ä¸šè®¾å¤‡ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `èˆžè¹ˆåŠ¨ä½œåˆ†æž` `è®¡ç®—æœºè§†è§‰` `YOLO` `Segment Anything Model` `ç›®æ ‡æ£€æµ‹` `å›¾åƒåˆ†å‰²` `AfroBeatsèˆžè¹ˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰èˆžè¹ˆåŠ¨ä½œåˆ†æžæ–¹æ³•ä¾èµ–ä¸“ä¸šè®¾å¤‡æˆ–æ ‡è®°ï¼Œæˆæœ¬é«˜ä¸”ä¸ä¾¿æºï¼Œé™åˆ¶äº†å…¶åº”ç”¨èŒƒå›´ã€‚
2. æœ¬ç ”ç©¶æå‡ºç»“åˆYOLOå’ŒSAMçš„æ¡†æž¶ï¼Œå®žçŽ°æ— éœ€æ ‡è®°çš„èˆžè¹ˆåŠ¨ä½œåˆ†æžï¼Œé™ä½Žäº†ä½¿ç”¨é—¨æ§›ã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ¡†æž¶åœ¨AfroBeatsèˆžè¹ˆè§†é¢‘ä¸Šå…·æœ‰è‰¯å¥½çš„æ£€æµ‹å’Œåˆ†å‰²æ€§èƒ½ï¼Œä¸ºå®šé‡èˆžè¹ˆåˆ†æžæä¾›åŸºç¡€ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡åˆæ­¥ç ”ç©¶äº†ä½¿ç”¨çŽ°ä»£è®¡ç®—æœºè§†è§‰æŠ€æœ¯è¿›è¡Œè‡ªåŠ¨èˆžè¹ˆåŠ¨ä½œåˆ†æžã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ¦‚å¿µéªŒè¯æ¡†æž¶ï¼Œè¯¥æ¡†æž¶é›†æˆäº†YOLOv8å’Œv11è¿›è¡Œèˆžè€…æ£€æµ‹ï¼Œå¹¶ç»“åˆSegment Anything Model (SAM) è¿›è¡Œç²¾ç¡®åˆ†å‰²ï¼Œä»Žè€Œèƒ½å¤Ÿåœ¨æ— éœ€ä¸“ç”¨è®¾å¤‡æˆ–æ ‡è®°çš„æƒ…å†µä¸‹ï¼Œè·Ÿè¸ªå’Œé‡åŒ–è§†é¢‘è®°å½•ä¸­çš„èˆžè€…åŠ¨ä½œã€‚æˆ‘ä»¬çš„æ–¹æ³•è¯†åˆ«è§†é¢‘å¸§ä¸­çš„èˆžè€…ï¼Œè®¡ç®—ç¦»æ•£çš„èˆžæ­¥ï¼Œè®¡ç®—ç©ºé—´è¦†ç›–æ¨¡å¼ï¼Œå¹¶æµ‹é‡è¡¨æ¼”åºåˆ—ä¸­çš„èŠ‚å¥ä¸€è‡´æ€§ã€‚åœ¨ä¸€æ®µ49ç§’çš„åŠ çº³AfroBeatsèˆžè¹ˆå½•åƒä¸Šæµ‹è¯•è¯¥æ¡†æž¶ï¼Œè¯æ˜Žäº†æŠ€æœ¯å¯è¡Œæ€§ï¼Œç³»ç»Ÿåœ¨æ‰‹åŠ¨æ£€æŸ¥çš„æ ·æœ¬ä¸Šå®žçŽ°äº†çº¦94%çš„æ£€æµ‹ç²¾åº¦å’Œ89%çš„å¬å›žçŽ‡ã€‚SAMæä¾›çš„åƒç´ çº§åˆ†å‰²ï¼Œä¸Žè§†è§‰æ£€æŸ¥ç›¸æ¯”å®žçŽ°äº†çº¦83%çš„äº¤å¹¶æ¯”ï¼Œèƒ½å¤Ÿé‡åŒ–è¶…å‡ºè¾¹ç•Œæ¡†æ–¹æ³•æ‰€èƒ½è¡¨ç¤ºçš„èº«ä½“å§¿æ€å˜åŒ–ã€‚åˆæ­¥æ¡ˆä¾‹ç ”ç©¶åˆ†æžè¡¨æ˜Žï¼Œæˆ‘ä»¬çš„ç³»ç»Ÿåˆ†ç±»ä¸ºä¸»è¦çš„èˆžè€…æ¯”åˆ†ç±»ä¸ºæ¬¡è¦çš„èˆžè€…å¤šæ‰§è¡Œäº†23%çš„æ­¥æ•°ï¼Œè¿åŠ¨å¼ºåº¦é«˜å‡º37%ï¼Œå¹¶ä¸”ä½¿ç”¨çš„è¡¨æ¼”ç©ºé—´å¤šå‡º42%ã€‚ç„¶è€Œï¼Œè¿™é¡¹å·¥ä½œä»£è¡¨äº†ä¸€ä¸ªæ—©æœŸé˜¶æ®µçš„ç ”ç©¶ï¼Œå­˜åœ¨å¾ˆå¤§çš„å±€é™æ€§ï¼ŒåŒ…æ‹¬å•è§†é¢‘éªŒè¯ã€ç¼ºä¹ç³»ç»Ÿçš„ground truthæ ‡æ³¨ä»¥åŠç¼ºä¹ä¸ŽçŽ°æœ‰å§¿æ€ä¼°è®¡æ–¹æ³•çš„æ¯”è¾ƒã€‚æˆ‘ä»¬æå‡ºè¿™ä¸ªæ¡†æž¶æ˜¯ä¸ºäº†è¯æ˜ŽæŠ€æœ¯å¯è¡Œæ€§ï¼Œç¡®å®šå®šé‡èˆžè¹ˆæŒ‡æ ‡çš„æœ‰å¸Œæœ›çš„æ–¹å‘ï¼Œå¹¶ä¸ºæœªæ¥çš„ç³»ç»ŸéªŒè¯ç ”ç©¶å¥ å®šåŸºç¡€ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³èˆžè¹ˆåŠ¨ä½œåˆ†æžä¸­å¯¹ä¸“ä¸šè®¾å¤‡æˆ–æ ‡è®°çš„ä¾èµ–é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•æˆæœ¬é«˜æ˜‚ä¸”è®¾ç½®å¤æ‚ï¼Œé™åˆ¶äº†å…¶åœ¨æ›´å¹¿æ³›åœºæ™¯ä¸‹çš„åº”ç”¨ï¼Œä¾‹å¦‚éžä¸“ä¸šèˆžè¹ˆæ•™å­¦ã€åŠ¨ä½œæ•æ‰åˆ†æžç­‰ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§æ— éœ€ç‰¹æ®Šè®¾å¤‡ï¼Œä»…é€šè¿‡è§†é¢‘å³å¯è¿›è¡Œèˆžè¹ˆåŠ¨ä½œåˆ†æžçš„æ–¹æ³•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è®¡ç®—æœºè§†è§‰æŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯ç›®æ ‡æ£€æµ‹å’Œå›¾åƒåˆ†å‰²ï¼Œè‡ªåŠ¨è¯†åˆ«å’Œåˆ†å‰²è§†é¢‘ä¸­çš„èˆžè€…ï¼Œè¿›è€Œåˆ†æžå…¶åŠ¨ä½œã€‚é€šè¿‡YOLOè¿›è¡Œå¿«é€Ÿå‡†ç¡®çš„èˆžè€…æ£€æµ‹ï¼Œå†åˆ©ç”¨SAMè¿›è¡Œåƒç´ çº§åˆ«çš„ç²¾ç¡®åˆ†å‰²ï¼Œä»Žè€Œèƒ½å¤Ÿæ›´ç²¾ç»†åœ°æ•æ‰èˆžè€…çš„èº«ä½“å§¿æ€å’ŒåŠ¨ä½œå˜åŒ–ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šè¯¥æ¡†æž¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) èˆžè€…æ£€æµ‹ï¼šä½¿ç”¨YOLOv8æˆ–v11æ£€æµ‹è§†é¢‘å¸§ä¸­çš„èˆžè€…ï¼Œå¾—åˆ°èˆžè€…çš„è¾¹ç•Œæ¡†ã€‚2) èˆžè€…åˆ†å‰²ï¼šåˆ©ç”¨SAMå¯¹æ£€æµ‹åˆ°çš„èˆžè€…è¿›è¡Œåƒç´ çº§åˆ«çš„åˆ†å‰²ï¼Œå¾—åˆ°èˆžè€…çš„ç²¾ç¡®è½®å»“ã€‚3) åŠ¨ä½œé‡åŒ–ï¼šåŸºäºŽåˆ†å‰²ç»“æžœï¼Œè®¡ç®—èˆžæ­¥æ•°é‡ã€ç©ºé—´è¦†ç›–æ¨¡å¼å’ŒèŠ‚å¥ä¸€è‡´æ€§ç­‰æŒ‡æ ‡ã€‚4) ç»“æžœåˆ†æžï¼šå¯¹é‡åŒ–åŽçš„åŠ¨ä½œæŒ‡æ ‡è¿›è¡Œåˆ†æžï¼Œæ¯”è¾ƒä¸åŒèˆžè€…çš„åŠ¨ä½œç‰¹å¾ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶çš„å…³é”®åˆ›æ–°åœ¨äºŽå°†YOLOå’ŒSAMç»“åˆåº”ç”¨äºŽèˆžè¹ˆåŠ¨ä½œåˆ†æžã€‚YOLOæä¾›å¿«é€Ÿå‡†ç¡®çš„èˆžè€…æ£€æµ‹ï¼Œè€ŒSAMæä¾›åƒç´ çº§åˆ«çš„ç²¾ç¡®åˆ†å‰²ï¼Œä¸¤è€…ç»“åˆèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°æ•æ‰èˆžè€…çš„åŠ¨ä½œç»†èŠ‚ï¼Œå…‹æœäº†ä¼ ç»ŸåŸºäºŽè¾¹ç•Œæ¡†çš„æ–¹æ³•çš„å±€é™æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­æœªæ˜Žç¡®è¯´æ˜ŽYOLOå’ŒSAMçš„å…·ä½“å‚æ•°è®¾ç½®ã€‚ä½†æåˆ°ä½¿ç”¨YOLOv8å’Œv11è¿›è¡Œå®žéªŒï¼Œå¹¶ä½¿ç”¨SAMè¿›è¡Œåƒç´ çº§åˆ†å‰²ï¼Œé€šè¿‡è®¡ç®—äº¤å¹¶æ¯”ï¼ˆIoUï¼‰è¯„ä¼°åˆ†å‰²æ•ˆæžœã€‚åŠ¨ä½œé‡åŒ–æ–¹é¢ï¼Œé€šè¿‡ç»Ÿè®¡åƒç´ å˜åŒ–æ¥ä¼°è®¡èˆžæ­¥æ•°é‡å’Œè¿åŠ¨å¼ºåº¦ï¼Œé€šè¿‡è®¡ç®—èˆžè€…åœ¨è§†é¢‘å¸§ä¸­çš„ä½ç½®å˜åŒ–æ¥ä¼°è®¡ç©ºé—´è¦†ç›–æ¨¡å¼ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

è¯¥æ¡†æž¶åœ¨AfroBeatsèˆžè¹ˆè§†é¢‘ä¸Šè¿›è¡Œäº†åˆæ­¥éªŒè¯ï¼Œå®žçŽ°äº†çº¦94%çš„æ£€æµ‹ç²¾åº¦å’Œ89%çš„å¬å›žçŽ‡ã€‚SAMæä¾›çš„åƒç´ çº§åˆ†å‰²ä¸Žè§†è§‰æ£€æŸ¥ç›¸æ¯”å®žçŽ°äº†çº¦83%çš„äº¤å¹¶æ¯”ã€‚æ¡ˆä¾‹ç ”ç©¶è¡¨æ˜Žï¼Œä¸»è¦èˆžè€…æ¯”æ¬¡è¦èˆžè€…å¤šæ‰§è¡Œäº†23%çš„æ­¥æ•°ï¼Œè¿åŠ¨å¼ºåº¦é«˜å‡º37%ï¼Œå¹¶ä¸”ä½¿ç”¨çš„è¡¨æ¼”ç©ºé—´å¤šå‡º42%ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽèˆžè¹ˆæ•™å­¦ã€åŠ¨ä½œæ•æ‰åˆ†æžã€è¿åŠ¨åº·å¤ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨èˆžè¹ˆæ•™å­¦ä¸­ï¼Œå¯ä»¥åˆ©ç”¨è¯¥ç³»ç»Ÿè‡ªåŠ¨è¯„ä¼°å­¦ç”Ÿçš„åŠ¨ä½œè§„èŒƒæ€§ï¼Œæä¾›ä¸ªæ€§åŒ–çš„æŒ‡å¯¼ã€‚åœ¨è¿åŠ¨åº·å¤ä¸­ï¼Œå¯ä»¥ç”¨äºŽç›‘æµ‹æ‚£è€…çš„åº·å¤è¿›åº¦ï¼Œè¯„ä¼°æ²»ç–—æ•ˆæžœã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ç”¨äºŽæ¸¸æˆå¼€å‘ã€è™šæ‹ŸçŽ°å®žç­‰é¢†åŸŸï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> This paper presents a preliminary investigation into automated dance movement analysis using contemporary computer vision techniques. We propose a proof-of-concept framework that integrates YOLOv8 and v11 for dancer detection with the Segment Anything Model (SAM) for precise segmentation, enabling the tracking and quantification of dancer movements in video recordings without specialized equipment or markers. Our approach identifies dancers within video frames, counts discrete dance steps, calculates spatial coverage patterns, and measures rhythm consistency across performance sequences. Testing this framework on a single 49-second recording of Ghanaian AfroBeats dance demonstrates technical feasibility, with the system achieving approximately 94% detection precision and 89% recall on manually inspected samples. The pixel-level segmentation provided by SAM, achieving approximately 83% intersection-over-union with visual inspection, enables motion quantification that captures body configuration changes beyond what bounding-box approaches can represent. Analysis of this preliminary case study indicates that the dancer classified as primary by our system executed 23% more steps with 37% higher motion intensity and utilized 42% more performance space compared to dancers classified as secondary. However, this work represents an early-stage investigation with substantial limitations including single-video validation, absence of systematic ground truth annotations, and lack of comparison with existing pose estimation methods. We present this framework to demonstrate technical feasibility, identify promising directions for quantitative dance metrics, and establish a foundation for future systematic validation studies.

