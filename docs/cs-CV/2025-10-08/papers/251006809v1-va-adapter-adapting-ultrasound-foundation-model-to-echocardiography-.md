---
layout: default
title: VA-Adapter: Adapting Ultrasound Foundation Model to Echocardiography Probe Guidance
---

# VA-Adapter: Adapting Ultrasound Foundation Model to Echocardiography Probe Guidance

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.06809" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.06809v1</a>
  <a href="https://arxiv.org/pdf/2510.06809.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.06809v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.06809v1', 'VA-Adapter: Adapting Ultrasound Foundation Model to Echocardiography Probe Guidance')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Teng Wang, Haojun Jiang, Yuxuan Wang, Zhenguo Sun, Shiji Song, Gao Huang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-08

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVA-Adapterï¼Œå°†è¶…å£°åŸºç¡€æ¨¡å‹åº”ç”¨äºè¶…å£°å¿ƒåŠ¨å›¾æ¢å¤´å¼•å¯¼ï¼Œæå‡å›¾åƒè´¨é‡ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¶…å£°å¿ƒåŠ¨å›¾` `æ¢å¤´å¼•å¯¼` `åŸºç¡€æ¨¡å‹` `è§†è§‰-åŠ¨ä½œé€‚é…å™¨` `åºåˆ—æ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¿ƒè„è¶…å£°æ“ä½œéš¾åº¦å¤§ï¼Œé«˜è´¨é‡å›¾åƒè·å–ä¾èµ–ç†Ÿç»ƒæŠ€å¸ˆï¼Œå¯¼è‡´åŒ»ç–—èµ„æºç´§å¼ ï¼Œæ‚£è€…éš¾ä»¥è·å¾—åŠæ—¶è¯Šæ–­ã€‚
2. æå‡ºVision-Action Adapter (VA-Adapter)ï¼Œä½¿è¶…å£°åŸºç¡€æ¨¡å‹å…·å¤‡è§†è§‰-åŠ¨ä½œåºåˆ—ç¼–ç èƒ½åŠ›ï¼Œæå‡æ¢å¤´å¼•å¯¼æ€§èƒ½ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒVA-Adapterä»…éœ€å¾®è°ƒå°‘é‡å‚æ•°ï¼Œå³å¯è¶…è¶Šç°æœ‰æ¢å¤´å¼•å¯¼æ¨¡å‹ï¼Œå®ç°æ›´ç²¾ç¡®çš„æ¢å¤´è°ƒæ•´ç­–ç•¥ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¶…å£°å¿ƒåŠ¨å›¾æ˜¯æ£€æµ‹å¿ƒè„ç–¾ç—…çš„å…³é”®å·¥å…·ã€‚è¿‘å¹´æ¥ï¼Œè¶…å£°åŸºç¡€æ¨¡å‹åœ¨å¿ƒè„è¶…å£°å›¾åƒåˆ†æä¸­è¡¨ç°å‡ºå“è¶Šçš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œè·å¾—é«˜è´¨é‡çš„è¶…å£°å›¾åƒæ˜¯å‡†ç¡®è¯Šæ–­çš„å‰æã€‚ç”±äºå¿ƒè„è¶…å£°æ“ä½œéš¾åº¦æé«˜ï¼Œç†Ÿç»ƒäººå‘˜çŸ­ç¼ºï¼Œé˜»ç¢äº†æ‚£è€…åŠæ—¶è·å¾—æ£€æŸ¥æœåŠ¡ã€‚æœ¬æ–‡æ—¨åœ¨å°†åŸºç¡€æ¨¡å‹ä»æµ·é‡æ•°æ®é›†ä¸­å­¦åˆ°çš„åŒ»å­¦çŸ¥è¯†åº”ç”¨äºæ¢å¤´å¼•å¯¼ä»»åŠ¡ï¼Œä¸ºåˆçº§è¶…å£°åŒ»å¸ˆæä¾›å®æ—¶æ“ä½œå»ºè®®ï¼Œä»¥è·å–é«˜è´¨é‡çš„è¶…å£°å›¾åƒã€‚æ­¤å¤–ï¼Œå—åˆ°ä¸“å®¶åŸºäºè¿‡å¾€æ¢ç´¢ä¼˜åŒ–è¡ŒåŠ¨å†³ç­–çš„å¯å‘ï¼Œæˆ‘ä»¬ç²¾å¿ƒè®¾è®¡äº†ä¸€ç§å‚æ•°é«˜æ•ˆçš„Vision-Action Adapter (VA-Adapter)ï¼Œä½¿åŸºç¡€æ¨¡å‹çš„å›¾åƒç¼–ç å™¨èƒ½å¤Ÿç¼–ç è§†è§‰-åŠ¨ä½œåºåˆ—ï¼Œä»è€Œæé«˜å¼•å¯¼æ€§èƒ½ã€‚VA-Adapterä»¥ç´§å‡‘çš„è®¾è®¡å†…ç½®äº†åºåˆ—æ¨ç†èƒ½åŠ›ï¼Œä½¿é¢„è®­ç»ƒçš„è¶…å£°åŸºç¡€æ¨¡å‹ä»…é€šè¿‡å¾®è°ƒä¸€å°éƒ¨åˆ†å‚æ•°å³å¯å­¦ä¹ ç²¾ç¡®çš„æ¢å¤´è°ƒæ•´ç­–ç•¥ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒVA-Adapterå¯ä»¥è¶…è¶Šå¼ºå¤§çš„æ¢å¤´å¼•å¯¼æ¨¡å‹ã€‚ä»£ç å°†åœ¨æ¥æ”¶åå‘å¸ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¿ƒè„è¶…å£°æ¢å¤´å¼•å¯¼é—®é¢˜ï¼Œå³å¦‚ä½•å¸®åŠ©åˆçº§è¶…å£°åŒ»å¸ˆå¿«é€ŸæŒæ¡æ¢å¤´æ“ä½œæŠ€å·§ï¼Œè·å–é«˜è´¨é‡çš„å¿ƒè„è¶…å£°å›¾åƒã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºä¸“å®¶ç»éªŒæˆ–å¼ºåŒ–å­¦ä¹ ï¼Œä½†å‰è€…éš¾ä»¥æ¨å¹¿ï¼Œåè€…è®­ç»ƒæˆæœ¬é«˜æ˜‚ä¸”æ³›åŒ–èƒ½åŠ›æœ‰é™ã€‚å› æ­¤ï¼Œå¦‚ä½•åˆ©ç”¨å·²æœ‰çš„è¶…å£°åŸºç¡€æ¨¡å‹çŸ¥è¯†ï¼Œé«˜æ•ˆåœ°å®ç°æ¢å¤´å¼•å¯¼ï¼Œæ˜¯ä¸€ä¸ªäºŸå¾…è§£å†³çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨é¢„è®­ç»ƒçš„è¶…å£°åŸºç¡€æ¨¡å‹ï¼Œå¹¶å¼•å…¥ä¸€ä¸ªè½»é‡çº§çš„Vision-Action Adapter (VA-Adapter)ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿç†è§£è§†è§‰è¾“å…¥å’Œæ¢å¤´è°ƒæ•´åŠ¨ä½œä¹‹é—´çš„å…³ç³»ã€‚VA-Adapterçš„è®¾è®¡çµæ„Ÿæ¥æºäºä¸“å®¶æ ¹æ®è¿‡å¾€ç»éªŒä¼˜åŒ–æ“ä½œçš„å®è·µï¼Œé€šè¿‡ç¼–ç è§†è§‰-åŠ¨ä½œåºåˆ—ï¼Œä½¿æ¨¡å‹å…·å¤‡åºåˆ—æ¨ç†èƒ½åŠ›ï¼Œä»è€Œæ›´å¥½åœ°é¢„æµ‹ä¸‹ä¸€æ­¥çš„æ¢å¤´è°ƒæ•´æ–¹å‘ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä¸€ä¸ªé¢„è®­ç»ƒçš„è¶…å£°åŸºç¡€æ¨¡å‹å’Œä¸€ä¸ªVA-Adapterã€‚é¦–å…ˆï¼Œè¶…å£°å›¾åƒé€šè¿‡åŸºç¡€æ¨¡å‹çš„å›¾åƒç¼–ç å™¨æå–ç‰¹å¾ã€‚ç„¶åï¼ŒVA-Adapterå°†å›¾åƒç‰¹å¾å’Œæ¢å¤´è°ƒæ•´åŠ¨ä½œåºåˆ—ä½œä¸ºè¾“å…¥ï¼Œé€šè¿‡ä¸€ç³»åˆ—çš„å˜æ¢å’Œèåˆï¼Œè¾“å‡ºä¸‹ä¸€æ­¥çš„æ¢å¤´è°ƒæ•´å»ºè®®ã€‚æ•´ä¸ªè¿‡ç¨‹å¯ä»¥çœ‹ä½œæ˜¯ä¸€ä¸ªåºåˆ—åˆ°åºåˆ—çš„å­¦ä¹ è¿‡ç¨‹ï¼Œç›®æ ‡æ˜¯æœ€å°åŒ–é¢„æµ‹åŠ¨ä½œå’ŒçœŸå®åŠ¨ä½œä¹‹é—´çš„å·®å¼‚ã€‚

**å…³é”®åˆ›æ–°**ï¼šVA-Adapterçš„å…³é”®åˆ›æ–°åœ¨äºå…¶å‚æ•°é«˜æ•ˆçš„è®¾è®¡å’Œå†…ç½®çš„åºåˆ—æ¨ç†èƒ½åŠ›ã€‚ä¸ç›´æ¥å¾®è°ƒæ•´ä¸ªåŸºç¡€æ¨¡å‹ç›¸æ¯”ï¼ŒVA-Adapteråªå¼•å…¥äº†å°‘é‡å¯è®­ç»ƒå‚æ•°ï¼Œå¤§å¤§é™ä½äº†è®­ç»ƒæˆæœ¬ã€‚åŒæ—¶ï¼ŒVA-Adapteré€šè¿‡ç¼–ç è§†è§‰-åŠ¨ä½œåºåˆ—ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ åˆ°æ¢å¤´è°ƒæ•´çš„åŠ¨æ€è¿‡ç¨‹ï¼Œä»è€Œæ›´å¥½åœ°é€‚åº”ä¸åŒçš„è¶…å£°å›¾åƒå’Œæ“ä½œåœºæ™¯ã€‚

**å…³é”®è®¾è®¡**ï¼šVA-Adapterçš„å…·ä½“ç»“æ„åŒ…æ‹¬ä¸€ä¸ªè§†è§‰ç¼–ç å™¨ã€ä¸€ä¸ªåŠ¨ä½œç¼–ç å™¨å’Œä¸€ä¸ªèåˆæ¨¡å—ã€‚è§†è§‰ç¼–ç å™¨è´Ÿè´£æå–å›¾åƒç‰¹å¾ï¼ŒåŠ¨ä½œç¼–ç å™¨è´Ÿè´£ç¼–ç æ¢å¤´è°ƒæ•´åŠ¨ä½œåºåˆ—ã€‚èåˆæ¨¡å—å°†å›¾åƒç‰¹å¾å’ŒåŠ¨ä½œç¼–ç è¿›è¡Œèåˆï¼Œå¹¶è¾“å‡ºä¸‹ä¸€æ­¥çš„æ¢å¤´è°ƒæ•´å»ºè®®ã€‚è®ºæ–‡ä¸­ä½¿ç”¨äº†Transformerç»“æ„æ¥å®ç°è§†è§‰ç¼–ç å™¨å’ŒåŠ¨ä½œç¼–ç å™¨ï¼Œå¹¶ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶æ¥å®ç°ç‰¹å¾èåˆã€‚æŸå¤±å‡½æ•°é‡‡ç”¨å‡æ–¹è¯¯å·®æŸå¤±ï¼Œç”¨äºè¡¡é‡é¢„æµ‹åŠ¨ä½œå’ŒçœŸå®åŠ¨ä½œä¹‹é—´çš„å·®å¼‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒVA-Adapteråœ¨æ¢å¤´å¼•å¯¼ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¶…è¶Šäº†ç°æœ‰çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼ŒVA-Adapteråœ¨å¤šä¸ªè¯„ä¼°æŒ‡æ ‡ä¸Šéƒ½å–å¾—äº†æœ€ä½³ç»“æœï¼Œä¾‹å¦‚ï¼Œåœ¨æˆåŠŸç‡æ–¹é¢ï¼ŒVA-Adapteræ¯”æœ€å¼ºçš„åŸºçº¿æ¨¡å‹æå‡äº†è¶…è¿‡10%ã€‚æ­¤å¤–ï¼ŒVA-Adapterä»…éœ€å¾®è°ƒå°‘é‡å‚æ•°ï¼Œå³å¯è¾¾åˆ°åª²ç¾ç”šè‡³è¶…è¶Šå…¨å‚æ•°å¾®è°ƒçš„æ•ˆæœï¼Œè¯æ˜äº†å…¶å‚æ•°é«˜æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ™ºèƒ½è¶…å£°è¯Šæ–­ç³»ç»Ÿï¼Œè¾…åŠ©åˆçº§åŒ»å¸ˆè¿›è¡Œå¿ƒè„è¶…å£°æ£€æŸ¥ï¼Œæé«˜è¯Šæ–­æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚åŒæ—¶ï¼Œå¯ä»¥é™ä½å¯¹é«˜çº§æŠ€å¸ˆçš„ä¾èµ–ï¼Œç¼“è§£åŒ»ç–—èµ„æºç´§å¼ çš„å±€é¢ï¼Œä½¿æ›´å¤šæ‚£è€…èƒ½å¤ŸåŠæ—¶è·å¾—é«˜è´¨é‡çš„è¶…å£°æ£€æŸ¥æœåŠ¡ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›æ¨å¹¿åˆ°å…¶ä»–ç±»å‹çš„è¶…å£°æ£€æŸ¥å’ŒåŒ»ç–—å½±åƒå¼•å¯¼æ‰‹æœ¯ä¸­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Echocardiography is a critical tool for detecting heart diseases. Recently, ultrasound foundation models have demonstrated remarkable capabilities in cardiac ultrasound image analysis. However, obtaining high-quality ultrasound images is a prerequisite for accurate diagnosis. Due to the exceptionally high operational difficulty of cardiac ultrasound, there is a shortage of highly skilled personnel, which hinders patients from receiving timely examination services. In this paper, we aim to adapt the medical knowledge learned by foundation models from vast datasets to the probe guidance task, which is designed to provide real-time operational recommendations for junior sonographers to acquire high-quality ultrasound images. Moreover, inspired by the practice where experts optimize action decisions based on past explorations, we meticulously design a parameter-efficient Vision-Action Adapter (VA-Adapter) to enable foundation model's image encoder to encode vision-action sequences, thereby enhancing guidance performance. With built-in sequential reasoning capabilities in a compact design, the VA-Adapter enables a pre-trained ultrasound foundation model to learn precise probe adjustment strategies by fine-tuning only a small subset of parameters. Extensive experiments demonstrate that the VA-Adapter can surpass strong probe guidance models. Our code will be released after acceptance.

