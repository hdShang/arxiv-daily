---
layout: default
title: TRAVL: A Recipe for Making Video-Language Models Better Judges of Physics Implausibility
---

# TRAVL: A Recipe for Making Video-Language Models Better Judges of Physics Implausibility

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.07550" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.07550v1</a>
  <a href="https://arxiv.org/pdf/2510.07550.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.07550v1" onclick="toggleFavorite(this, '2510.07550v1', 'TRAVL: A Recipe for Making Video-Language Models Better Judges of Physics Implausibility')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Saman Motamed, Minghao Chen, Luc Van Gool, Iro Laina

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-10-08

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**TRAVLï¼šæå‡è§†é¢‘-è¯­è¨€æ¨¡å‹å¯¹ç‰©ç†åˆç†æ€§åˆ¤æ–­èƒ½åŠ›çš„æ–¹æ¡ˆ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†é¢‘-è¯­è¨€æ¨¡å‹` `ç‰©ç†åˆç†æ€§` `è§†é¢‘ç”Ÿæˆ` `è½¨è¿¹æ„ŸçŸ¥æ³¨æ„åŠ›` `å¤šæ¨¡æ€å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†é¢‘ç”Ÿæˆæ¨¡å‹å¸¸è¿åç‰©ç†å®šå¾‹ï¼Œä½†ç¼ºä¹å®šé‡è¯„ä¼°ç‰©ç†åˆç†æ€§çš„æ–¹æ³•ã€‚
2. TRAVLé€šè¿‡å¹³è¡¡æ•°æ®é›†å’Œè½¨è¿¹æ„ŸçŸ¥æ³¨æ„åŠ›æ¨¡å—ï¼Œæå‡VLMå¯¹è¿åŠ¨ç¼–ç å’Œç‰©ç†åˆç†æ€§çš„åˆ¤æ–­èƒ½åŠ›ã€‚
3. ImplausiBenchåŸºå‡†æµ‹è¯•é›†ï¼Œç»“åˆäººå·¥å’ŒLLMè¯„ä¼°ï¼Œæ›´ä¸¥æ ¼åœ°è¯„ä¼°ç‰©ç†æ¨ç†èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡è§†é¢‘ç”Ÿæˆæ¨¡å‹åœ¨è§†è§‰é€¼çœŸåº¦æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å®ƒä»¬ç»å¸¸ç”Ÿæˆè¿åç›´è§‚ç‰©ç†å®šå¾‹çš„åºåˆ—ï¼Œä¾‹å¦‚ç‰©ä½“æ¼‚æµ®ã€ç¬ç§»æˆ–ä»¥è¿åå› æœå…³ç³»çš„æ–¹å¼å˜å½¢ã€‚è™½ç„¶äººç±»å¯ä»¥è½»æ¾æ£€æµ‹åˆ°è¿™äº›ä¸åˆç†ä¹‹å¤„ï¼Œä½†ç›®å‰è¿˜æ²¡æœ‰å¯é çš„æ–¹æ³•æ¥å®šé‡è¯„ä¼°è§†é¢‘ä¸­çš„ç‰©ç†çœŸå®æ€§ã€‚æœ¬æ–‡æ¢è®¨äº†æ˜¯å¦å¯ä»¥è®­ç»ƒè§†é¢‘-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰ä½œä¸ºç‰©ç†åˆç†æ€§çš„å¯é åˆ¤æ–­è€…ã€‚ç ”ç©¶å‘ç°ï¼Œç°æœ‰çš„VLMséš¾ä»¥è¯†åˆ«ç‰©ç†è¿è§„è¡Œä¸ºï¼Œæš´éœ²äº†å…¶åœ¨æ—¶é—´å’Œå› æœæ¨ç†æ–¹é¢çš„æ ¹æœ¬å±€é™æ€§ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†TRAVLï¼Œè¿™æ˜¯ä¸€ç§å¾®è°ƒæ–¹æ¡ˆï¼Œå®ƒç»“åˆäº†å¹³è¡¡çš„è®­ç»ƒæ•°æ®é›†å’Œä¸€ä¸ªè½¨è¿¹æ„ŸçŸ¥æ³¨æ„åŠ›æ¨¡å—ï¼Œä»¥æé«˜VLMsä¸­çš„è¿åŠ¨ç¼–ç å’Œåˆ¤åˆ«èƒ½åŠ›ã€‚ä¸ºäº†æ›´ä¸¥æ ¼åœ°è¯„ä¼°ç‰©ç†æ¨ç†ï¼Œæˆ‘ä»¬æå‡ºäº†ImplausiBenchï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«300ä¸ªè§†é¢‘ï¼ˆ150ä¸ªçœŸå®è§†é¢‘ï¼Œ150ä¸ªç”Ÿæˆè§†é¢‘ï¼‰çš„åŸºå‡†ï¼Œå®ƒæ¶ˆé™¤äº†è¯­è¨€åå·®å¹¶éš”ç¦»äº†è§†è§‰-æ—¶é—´ç†è§£ã€‚æ€§èƒ½æŠ¥å‘Šæ—¢åŒ…æ‹¬é»„é‡‘æ ‡å‡†çš„çš„äººå·¥åˆ¤æ–­ï¼Œä¹ŸåŒ…æ‹¬æ›´ä¸¥æ ¼çš„LLM-as-judgeæŒ‡æ ‡ã€‚TRAVLå’ŒImplausiBenchå…±åŒæä¾›äº†ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ï¼Œç”¨äºæ¢æµ‹å’Œæ”¹è¿›å¤šæ¨¡æ€æ¨¡å‹ä¸­çš„ç‰©ç†åˆç†æ€§ï¼Œä»è€Œæ­ç¤ºäº†è§†è§‰-æ—¶é—´ç†è§£ä¸­ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§ä¸”æœªè¢«å……åˆ†æ¢ç´¢çš„æ–¹é¢ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è§†é¢‘ç”Ÿæˆæ¨¡å‹ç”Ÿæˆçš„è§†é¢‘å†…å®¹ä¸ç¬¦åˆç‰©ç†è§„å¾‹çš„é—®é¢˜ï¼Œä¾‹å¦‚ç‰©ä½“æ¼‚æµ®ã€ç¬ç§»ç­‰ã€‚ç°æœ‰è§†é¢‘-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨è¯†åˆ«è¿™äº›ç‰©ç†è¿è§„è¡Œä¸ºæ–¹é¢è¡¨ç°ä¸ä½³ï¼Œç¼ºä¹è¶³å¤Ÿçš„æ—¶é—´å’Œå› æœæ¨ç†èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¾®è°ƒVLMsï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œåˆ¤æ–­è§†é¢‘ä¸­çš„ç‰©ç†åˆç†æ€§ã€‚å…·ä½“æ¥è¯´ï¼Œé€šè¿‡æ„å»ºå¹³è¡¡çš„è®­ç»ƒæ•°æ®é›†å’Œå¼•å…¥è½¨è¿¹æ„ŸçŸ¥æ³¨æ„åŠ›æ¨¡å—ï¼Œæ¥å¢å¼ºVLMså¯¹è¿åŠ¨è½¨è¿¹çš„ç†è§£å’Œå¯¹ç‰©ç†è¿è§„è¡Œä¸ºçš„åˆ¤åˆ«èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTRAVLçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªå…³é”®éƒ¨åˆ†ï¼šé¦–å…ˆï¼Œæ„å»ºä¸€ä¸ªå¹³è¡¡çš„è®­ç»ƒæ•°æ®é›†ï¼ŒåŒ…å«ç‰©ç†åˆç†å’Œä¸åˆç†çš„è§†é¢‘æ ·æœ¬ã€‚å…¶æ¬¡ï¼Œåœ¨VLMä¸­å¼•å…¥è½¨è¿¹æ„ŸçŸ¥æ³¨æ„åŠ›æ¨¡å—ï¼Œè¯¥æ¨¡å—èƒ½å¤Ÿæ•æ‰è§†é¢‘ä¸­ç‰©ä½“çš„è¿åŠ¨è½¨è¿¹ä¿¡æ¯ã€‚æœ€åï¼Œä½¿ç”¨æ„å»ºçš„æ•°æ®é›†å¯¹VLMè¿›è¡Œå¾®è°ƒï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°åˆ¤æ–­è§†é¢‘çš„ç‰©ç†åˆç†æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†TRAVLå¾®è°ƒæ–¹æ¡ˆï¼Œè¯¥æ–¹æ¡ˆç»“åˆäº†å¹³è¡¡æ•°æ®é›†å’Œè½¨è¿¹æ„ŸçŸ¥æ³¨æ„åŠ›æ¨¡å—ï¼Œæœ‰æ•ˆåœ°æé«˜äº†VLMså¯¹ç‰©ç†åˆç†æ€§çš„åˆ¤æ–­èƒ½åŠ›ã€‚è½¨è¿¹æ„ŸçŸ¥æ³¨æ„åŠ›æ¨¡å—èƒ½å¤Ÿæ˜¾å¼åœ°å»ºæ¨¡è§†é¢‘ä¸­ç‰©ä½“çš„è¿åŠ¨è½¨è¿¹ï¼Œä»è€Œæ›´å¥½åœ°æ•æ‰ç‰©ç†è¿è§„è¡Œä¸ºã€‚

**å…³é”®è®¾è®¡**ï¼šè½¨è¿¹æ„ŸçŸ¥æ³¨æ„åŠ›æ¨¡å—çš„å…·ä½“å®ç°æ–¹å¼æœªçŸ¥ï¼Œè®ºæ–‡ä¸­å¯èƒ½æ²¡æœ‰è¯¦ç»†æè¿°å…¶ç½‘ç»œç»“æ„å’Œå‚æ•°è®¾ç½®ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡å¯èƒ½åŒ…æ‹¬äºŒå…ƒäº¤å‰ç†µæŸå¤±ï¼Œç”¨äºåŒºåˆ†ç‰©ç†åˆç†å’Œä¸åˆç†çš„è§†é¢‘æ ·æœ¬ã€‚å¹³è¡¡æ•°æ®é›†çš„æ„å»ºéœ€è¦ä»”ç»†é€‰æ‹©å’Œç”Ÿæˆè§†é¢‘æ ·æœ¬ï¼Œä»¥é¿å…å¼•å…¥åå·®ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡æå‡ºäº†ImplausiBenchåŸºå‡†æµ‹è¯•é›†ï¼Œå¹¶ä½¿ç”¨äººå·¥å’ŒLLMä¸¤ç§æ–¹å¼è¿›è¡Œè¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTRAVLèƒ½å¤Ÿæ˜¾è‘—æé«˜VLMså¯¹ç‰©ç†åˆç†æ€§çš„åˆ¤æ–­èƒ½åŠ›ã€‚å…·ä½“çš„æ€§èƒ½æå‡æ•°æ®æœªçŸ¥ï¼Œä½†è®ºæ–‡å¼ºè°ƒäº†TRAVLåœ¨è§†è§‰-æ—¶é—´ç†è§£æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè§†é¢‘ç”Ÿæˆæ¨¡å‹çš„æ”¹è¿›ï¼Œæé«˜ç”Ÿæˆè§†é¢‘çš„çœŸå®æ„Ÿå’Œç‰©ç†åˆç†æ€§ã€‚æ­¤å¤–ï¼Œè¿˜å¯ç”¨äºè§†é¢‘ç›‘æ§ã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸï¼Œå¸®åŠ©ç³»ç»Ÿè¯†åˆ«å’Œç†è§£åœºæ™¯ä¸­çš„å¼‚å¸¸è¡Œä¸ºå’Œç‰©ç†è¿è§„äº‹ä»¶ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›æ¨åŠ¨äººå·¥æ™ºèƒ½åœ¨ç‰©ç†ä¸–ç•Œç†è§£æ–¹é¢çš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Despite impressive visual fidelity, modern video generative models frequently produce sequences that violate intuitive physical laws, such as objects floating, teleporting, or morphing in ways that defy causality. While humans can easily detect such implausibilities, there remains no robust method for quantitatively assessing physical realism in video. In this work, we explore whether Video-Language Models (VLMs) can be trained to serve as reliable judges of physical plausibility. We find that existing VLMs struggle to identify physics violations, exposing fundamental limitations in their temporal and causal reasoning. To address this, we introduce TRAVL, a fine-tuning recipe that combines a balanced training dataset with a trajectory-aware attention module to improve motion encoding and discrimination in VLMs. To evaluate physical reasoning more rigorously, we propose ImplausiBench, a benchmark of 300 videos (150 real, 150 generated) that removes linguistic biases and isolates visual-temporal understanding. Performance is reported both with gold-standard human judgments and stricter LLM-as-judge metrics. Together, TRAVL and ImplausiBench offer a unified framework for probing and improving physical plausibility in multimodal models, shedding light on a challenging and underexplored aspect of visual-temporal understanding.

