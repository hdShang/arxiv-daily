---
layout: default
title: TRAVL: A Recipe for Making Video-Language Models Better Judges of Physics Implausibility
---

# TRAVL: A Recipe for Making Video-Language Models Better Judges of Physics Implausibility

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.07550" target="_blank" class="toolbar-btn">arXiv: 2510.07550v1</a>
    <a href="https://arxiv.org/pdf/2510.07550.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.07550v1" 
            onclick="toggleFavorite(this, '2510.07550v1', 'TRAVL: A Recipe for Making Video-Language Models Better Judges of Physics Implausibility')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Saman Motamed, Minghao Chen, Luc Van Gool, Iro Laina

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-08

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**TRAVLÔºöÊèêÂçáËßÜÈ¢ë-ËØ≠Ë®ÄÊ®°ÂûãÂØπÁâ©ÁêÜÂêàÁêÜÊÄßÂà§Êñ≠ËÉΩÂäõÁöÑÊñπÊ°à**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËßÜÈ¢ë-ËØ≠Ë®ÄÊ®°Âûã` `Áâ©ÁêÜÂêàÁêÜÊÄß` `ËßÜÈ¢ëÁîüÊàê` `ËΩ®ËøπÊÑüÁü•Ê≥®ÊÑèÂäõ` `Â§öÊ®°ÊÄÅÂ≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËßÜÈ¢ëÁîüÊàêÊ®°ÂûãÂ∏∏ËøùÂèçÁâ©ÁêÜÂÆöÂæãÔºå‰ΩÜÁº∫‰πèÂÆöÈáèËØÑ‰º∞Áâ©ÁêÜÂêàÁêÜÊÄßÁöÑÊñπÊ≥ï„ÄÇ
2. TRAVLÈÄöËøáÂπ≥Ë°°Êï∞ÊçÆÈõÜÂíåËΩ®ËøπÊÑüÁü•Ê≥®ÊÑèÂäõÊ®°ÂùóÔºåÊèêÂçáVLMÂØπËøêÂä®ÁºñÁ†ÅÂíåÁâ©ÁêÜÂêàÁêÜÊÄßÁöÑÂà§Êñ≠ËÉΩÂäõ„ÄÇ
3. ImplausiBenchÂü∫ÂáÜÊµãËØïÈõÜÔºåÁªìÂêà‰∫∫Â∑•ÂíåLLMËØÑ‰º∞ÔºåÊõ¥‰∏•Ê†ºÂú∞ËØÑ‰º∞Áâ©ÁêÜÊé®ÁêÜËÉΩÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â∞ΩÁÆ°ËßÜÈ¢ëÁîüÊàêÊ®°ÂûãÂú®ËßÜËßâÈÄºÁúüÂ∫¶ÊñπÈù¢ÂèñÂæó‰∫ÜÊòæËëóËøõÂ±ïÔºå‰ΩÜÂÆÉ‰ª¨ÁªèÂ∏∏ÁîüÊàêËøùÂèçÁõ¥ËßÇÁâ©ÁêÜÂÆöÂæãÁöÑÂ∫èÂàóÔºå‰æãÂ¶ÇÁâ©‰ΩìÊºÇÊµÆ„ÄÅÁû¨ÁßªÊàñ‰ª•ËøùÂèçÂõ†ÊûúÂÖ≥Á≥ªÁöÑÊñπÂºèÂèòÂΩ¢„ÄÇËôΩÁÑ∂‰∫∫Á±ªÂèØ‰ª•ËΩªÊùæÊ£ÄÊµãÂà∞Ëøô‰∫õ‰∏çÂêàÁêÜ‰πãÂ§ÑÔºå‰ΩÜÁõÆÂâçËøòÊ≤°ÊúâÂèØÈù†ÁöÑÊñπÊ≥ïÊù•ÂÆöÈáèËØÑ‰º∞ËßÜÈ¢ë‰∏≠ÁöÑÁâ©ÁêÜÁúüÂÆûÊÄß„ÄÇÊú¨ÊñáÊé¢ËÆ®‰∫ÜÊòØÂê¶ÂèØ‰ª•ËÆ≠ÁªÉËßÜÈ¢ë-ËØ≠Ë®ÄÊ®°ÂûãÔºàVLMsÔºâ‰Ωú‰∏∫Áâ©ÁêÜÂêàÁêÜÊÄßÁöÑÂèØÈù†Âà§Êñ≠ËÄÖ„ÄÇÁ†îÁ©∂ÂèëÁé∞ÔºåÁé∞ÊúâÁöÑVLMsÈöæ‰ª•ËØÜÂà´Áâ©ÁêÜËøùËßÑË°å‰∏∫ÔºåÊö¥Èú≤‰∫ÜÂÖ∂Âú®Êó∂Èó¥ÂíåÂõ†ÊûúÊé®ÁêÜÊñπÈù¢ÁöÑÊ†πÊú¨Â±ÄÈôêÊÄß„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨ÂºïÂÖ•‰∫ÜTRAVLÔºåËøôÊòØ‰∏ÄÁßçÂæÆË∞ÉÊñπÊ°àÔºåÂÆÉÁªìÂêà‰∫ÜÂπ≥Ë°°ÁöÑËÆ≠ÁªÉÊï∞ÊçÆÈõÜÂíå‰∏Ä‰∏™ËΩ®ËøπÊÑüÁü•Ê≥®ÊÑèÂäõÊ®°ÂùóÔºå‰ª•ÊèêÈ´òVLMs‰∏≠ÁöÑËøêÂä®ÁºñÁ†ÅÂíåÂà§Âà´ËÉΩÂäõ„ÄÇ‰∏∫‰∫ÜÊõ¥‰∏•Ê†ºÂú∞ËØÑ‰º∞Áâ©ÁêÜÊé®ÁêÜÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜImplausiBenchÔºåËøôÊòØ‰∏Ä‰∏™ÂåÖÂê´300‰∏™ËßÜÈ¢ëÔºà150‰∏™ÁúüÂÆûËßÜÈ¢ëÔºå150‰∏™ÁîüÊàêËßÜÈ¢ëÔºâÁöÑÂü∫ÂáÜÔºåÂÆÉÊ∂àÈô§‰∫ÜËØ≠Ë®ÄÂÅèÂ∑ÆÂπ∂ÈöîÁ¶ª‰∫ÜËßÜËßâ-Êó∂Èó¥ÁêÜËß£„ÄÇÊÄßËÉΩÊä•ÂëäÊó¢ÂåÖÊã¨ÈªÑÈáëÊ†áÂáÜÁöÑÁöÑ‰∫∫Â∑•Âà§Êñ≠Ôºå‰πüÂåÖÊã¨Êõ¥‰∏•Ê†ºÁöÑLLM-as-judgeÊåáÊ†á„ÄÇTRAVLÂíåImplausiBenchÂÖ±ÂêåÊèê‰æõ‰∫Ü‰∏Ä‰∏™Áªü‰∏ÄÁöÑÊ°ÜÊû∂ÔºåÁî®‰∫éÊé¢ÊµãÂíåÊîπËøõÂ§öÊ®°ÊÄÅÊ®°Âûã‰∏≠ÁöÑÁâ©ÁêÜÂêàÁêÜÊÄßÔºå‰ªéËÄåÊè≠Á§∫‰∫ÜËßÜËßâ-Êó∂Èó¥ÁêÜËß£‰∏≠‰∏Ä‰∏™ÂÖ∑ÊúâÊåëÊàòÊÄß‰∏îÊú™Ë¢´ÂÖÖÂàÜÊé¢Á¥¢ÁöÑÊñπÈù¢„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥ËßÜÈ¢ëÁîüÊàêÊ®°ÂûãÁîüÊàêÁöÑËßÜÈ¢ëÂÜÖÂÆπ‰∏çÁ¨¶ÂêàÁâ©ÁêÜËßÑÂæãÁöÑÈóÆÈ¢òÔºå‰æãÂ¶ÇÁâ©‰ΩìÊºÇÊµÆ„ÄÅÁû¨ÁßªÁ≠â„ÄÇÁé∞ÊúâËßÜÈ¢ë-ËØ≠Ë®ÄÊ®°ÂûãÔºàVLMsÔºâÂú®ËØÜÂà´Ëøô‰∫õÁâ©ÁêÜËøùËßÑË°å‰∏∫ÊñπÈù¢Ë°®Áé∞‰∏ç‰Ω≥ÔºåÁº∫‰πèË∂≥Â§üÁöÑÊó∂Èó¥ÂíåÂõ†ÊûúÊé®ÁêÜËÉΩÂäõ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÂæÆË∞ÉVLMsÔºå‰ΩøÂÖ∂ËÉΩÂ§üÊõ¥Â•ΩÂú∞ÁêÜËß£ÂíåÂà§Êñ≠ËßÜÈ¢ë‰∏≠ÁöÑÁâ©ÁêÜÂêàÁêÜÊÄß„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÈÄöËøáÊûÑÂª∫Âπ≥Ë°°ÁöÑËÆ≠ÁªÉÊï∞ÊçÆÈõÜÂíåÂºïÂÖ•ËΩ®ËøπÊÑüÁü•Ê≥®ÊÑèÂäõÊ®°ÂùóÔºåÊù•Â¢ûÂº∫VLMsÂØπËøêÂä®ËΩ®ËøπÁöÑÁêÜËß£ÂíåÂØπÁâ©ÁêÜËøùËßÑË°å‰∏∫ÁöÑÂà§Âà´ËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöTRAVLÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™ÂÖ≥ÈîÆÈÉ®ÂàÜÔºöÈ¶ñÂÖàÔºåÊûÑÂª∫‰∏Ä‰∏™Âπ≥Ë°°ÁöÑËÆ≠ÁªÉÊï∞ÊçÆÈõÜÔºåÂåÖÂê´Áâ©ÁêÜÂêàÁêÜÂíå‰∏çÂêàÁêÜÁöÑËßÜÈ¢ëÊ†∑Êú¨„ÄÇÂÖ∂Ê¨°ÔºåÂú®VLM‰∏≠ÂºïÂÖ•ËΩ®ËøπÊÑüÁü•Ê≥®ÊÑèÂäõÊ®°ÂùóÔºåËØ•Ê®°ÂùóËÉΩÂ§üÊçïÊçâËßÜÈ¢ë‰∏≠Áâ©‰ΩìÁöÑËøêÂä®ËΩ®Ëøπ‰ø°ÊÅØ„ÄÇÊúÄÂêéÔºå‰ΩøÁî®ÊûÑÂª∫ÁöÑÊï∞ÊçÆÈõÜÂØπVLMËøõË°åÂæÆË∞ÉÔºå‰ΩøÂÖ∂ËÉΩÂ§üÊõ¥Â•ΩÂú∞Âà§Êñ≠ËßÜÈ¢ëÁöÑÁâ©ÁêÜÂêàÁêÜÊÄß„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫ÜTRAVLÂæÆË∞ÉÊñπÊ°àÔºåËØ•ÊñπÊ°àÁªìÂêà‰∫ÜÂπ≥Ë°°Êï∞ÊçÆÈõÜÂíåËΩ®ËøπÊÑüÁü•Ê≥®ÊÑèÂäõÊ®°ÂùóÔºåÊúâÊïàÂú∞ÊèêÈ´ò‰∫ÜVLMsÂØπÁâ©ÁêÜÂêàÁêÜÊÄßÁöÑÂà§Êñ≠ËÉΩÂäõ„ÄÇËΩ®ËøπÊÑüÁü•Ê≥®ÊÑèÂäõÊ®°ÂùóËÉΩÂ§üÊòæÂºèÂú∞Âª∫Ê®°ËßÜÈ¢ë‰∏≠Áâ©‰ΩìÁöÑËøêÂä®ËΩ®ËøπÔºå‰ªéËÄåÊõ¥Â•ΩÂú∞ÊçïÊçâÁâ©ÁêÜËøùËßÑË°å‰∏∫„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËΩ®ËøπÊÑüÁü•Ê≥®ÊÑèÂäõÊ®°ÂùóÁöÑÂÖ∑‰ΩìÂÆûÁé∞ÊñπÂºèÊú™Áü•ÔºåËÆ∫Êñá‰∏≠ÂèØËÉΩÊ≤°ÊúâËØ¶ÁªÜÊèèËø∞ÂÖ∂ÁΩëÁªúÁªìÊûÑÂíåÂèÇÊï∞ËÆæÁΩÆ„ÄÇÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°ÂèØËÉΩÂåÖÊã¨‰∫åÂÖÉ‰∫§ÂèâÁÜµÊçüÂ§±ÔºåÁî®‰∫éÂå∫ÂàÜÁâ©ÁêÜÂêàÁêÜÂíå‰∏çÂêàÁêÜÁöÑËßÜÈ¢ëÊ†∑Êú¨„ÄÇÂπ≥Ë°°Êï∞ÊçÆÈõÜÁöÑÊûÑÂª∫ÈúÄË¶Å‰ªîÁªÜÈÄâÊã©ÂíåÁîüÊàêËßÜÈ¢ëÊ†∑Êú¨Ôºå‰ª•ÈÅøÂÖçÂºïÂÖ•ÂÅèÂ∑Æ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ËÆ∫ÊñáÊèêÂá∫‰∫ÜImplausiBenchÂü∫ÂáÜÊµãËØïÈõÜÔºåÂπ∂‰ΩøÁî®‰∫∫Â∑•ÂíåLLM‰∏§ÁßçÊñπÂºèËøõË°åËØÑ‰º∞„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåTRAVLËÉΩÂ§üÊòæËëóÊèêÈ´òVLMsÂØπÁâ©ÁêÜÂêàÁêÜÊÄßÁöÑÂà§Êñ≠ËÉΩÂäõ„ÄÇÂÖ∑‰ΩìÁöÑÊÄßËÉΩÊèêÂçáÊï∞ÊçÆÊú™Áü•Ôºå‰ΩÜËÆ∫ÊñáÂº∫Ë∞É‰∫ÜTRAVLÂú®ËßÜËßâ-Êó∂Èó¥ÁêÜËß£ÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éËßÜÈ¢ëÁîüÊàêÊ®°ÂûãÁöÑÊîπËøõÔºåÊèêÈ´òÁîüÊàêËßÜÈ¢ëÁöÑÁúüÂÆûÊÑüÂíåÁâ©ÁêÜÂêàÁêÜÊÄß„ÄÇÊ≠§Â§ñÔºåËøòÂèØÁî®‰∫éËßÜÈ¢ëÁõëÊéß„ÄÅËá™Âä®È©æÈ©∂Á≠âÈ¢ÜÂüüÔºåÂ∏ÆÂä©Á≥ªÁªüËØÜÂà´ÂíåÁêÜËß£Âú∫ÊôØ‰∏≠ÁöÑÂºÇÂ∏∏Ë°å‰∏∫ÂíåÁâ©ÁêÜËøùËßÑ‰∫ã‰ª∂„ÄÇÊú™Êù•ÔºåËØ•ÊäÄÊúØÊúâÊúõÊé®Âä®‰∫∫Â∑•Êô∫ËÉΩÂú®Áâ©ÁêÜ‰∏ñÁïåÁêÜËß£ÊñπÈù¢ÁöÑËøõ‰∏ÄÊ≠•ÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Despite impressive visual fidelity, modern video generative models frequently produce sequences that violate intuitive physical laws, such as objects floating, teleporting, or morphing in ways that defy causality. While humans can easily detect such implausibilities, there remains no robust method for quantitatively assessing physical realism in video. In this work, we explore whether Video-Language Models (VLMs) can be trained to serve as reliable judges of physical plausibility. We find that existing VLMs struggle to identify physics violations, exposing fundamental limitations in their temporal and causal reasoning. To address this, we introduce TRAVL, a fine-tuning recipe that combines a balanced training dataset with a trajectory-aware attention module to improve motion encoding and discrimination in VLMs. To evaluate physical reasoning more rigorously, we propose ImplausiBench, a benchmark of 300 videos (150 real, 150 generated) that removes linguistic biases and isolates visual-temporal understanding. Performance is reported both with gold-standard human judgments and stricter LLM-as-judge metrics. Together, TRAVL and ImplausiBench offer a unified framework for probing and improving physical plausibility in multimodal models, shedding light on a challenging and underexplored aspect of visual-temporal understanding.

