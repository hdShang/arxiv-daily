---
layout: default
title: Evaluating LLMs for Historical Document OCR: A Methodological Framework for Digital Humanities
---

# Evaluating LLMs for Historical Document OCR: A Methodological Framework for Digital Humanities

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.06743" class="toolbar-btn" target="_blank">üìÑ arXiv: 2510.06743v1</a>
  <a href="https://arxiv.org/pdf/2510.06743.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.06743v1" onclick="toggleFavorite(this, '2510.06743v1', 'Evaluating LLMs for Historical Document OCR: A Methodological Framework for Digital Humanities')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Maria Levchenko

**ÂàÜÁ±ª**: cs.CV, cs.AI, cs.CL

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-08

**Â§áÊ≥®**: The First Workshop on Natural Language Processing and Language Models for Digital Humanities (LM4DH 2025). RANLP 2025

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫ÂéÜÂè≤ÊñáÊ°£OCRÁöÑLLMËØÑ‰º∞Ê°ÜÊû∂ÔºåËß£ÂÜ≥Êó∂Â∫èÂÅèÂ∑ÆÂíåÁâπÂÆöÊó∂ÊúüÈîôËØØÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÂéÜÂè≤ÊñáÊ°£OCR` `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `ËØÑ‰º∞Ê°ÜÊû∂` `Êï∞Â≠ó‰∫∫Êñá` `Â≠óÁ¨¶ËØÜÂà´`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâOCRËØÑ‰º∞ÊåáÊ†áÊó†Ê≥ïÊúâÊïàË°°ÈáèÂéÜÂè≤ÊñáÊ°£Êï∞Â≠óÂåñ‰∏≠LLMÁöÑÊó∂Â∫èÂÅèÂ∑ÆÂíåÁâπÂÆöÊó∂ÊúüÈîôËØØ„ÄÇ
2. ÊèêÂá∫‰∏ÄÁßçÊñ∞ÁöÑËØÑ‰º∞ÊñπÊ≥ïÔºåÂåÖÂê´ÂéÜÂè≤Â≠óÁ¨¶‰øùÁïôÁéáÔºàHCPRÔºâÂíåÂè§ËØ≠ÊèíÂÖ•ÁéáÔºàAIRÔºâÁ≠âÊåáÊ†áÔºåÂπ∂ÊéßÂà∂Ê±°ÊüìÈ£éÈô©„ÄÇ
3. ÂÆûÈ™åË°®ÊòéGeminiÂíåQwenÊ®°Âûã‰ºò‰∫é‰º†ÁªüOCRÔºå‰ΩÜÂ≠òÂú®ËøáÂ∫¶ÂéÜÂè≤ÂåñÈóÆÈ¢òÔºå‰∏îÂêéÂ§ÑÁêÜÊ†°Ê≠£ÊïàÊûú‰∏ç‰Ω≥„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êï∞Â≠ó‰∫∫ÊñáÈ¢ÜÂüüÁöÑÂ≠¶ËÄÖË∂äÊù•Ë∂äÂ§öÂú∞‰ΩøÁî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãËøõË°åÂéÜÂè≤ÊñáÊ°£Êï∞Â≠óÂåñÔºå‰ΩÜÁº∫‰πèÈíàÂØπÂü∫‰∫éLLMÁöÑOCRÁöÑÈÄÇÂΩìËØÑ‰º∞Ê°ÜÊû∂„ÄÇ‰º†ÁªüÁöÑËØÑ‰º∞ÊåáÊ†áÊó†Ê≥ïÊçïÊçâÂà∞Êó∂Èó¥ÂÅèÂ∑ÆÂíåÁâπÂÆöÊó∂ÊúüÁöÑÈîôËØØÔºåËÄåËøô‰∫õÂØπ‰∫éÂéÜÂè≤ËØ≠ÊñôÂ∫ìÁöÑÂàõÂª∫Ëá≥ÂÖ≥ÈáçË¶Å„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÈíàÂØπÂü∫‰∫éLLMÁöÑÂéÜÂè≤OCRÁöÑËØÑ‰º∞ÊñπÊ≥ïÔºåËß£ÂÜ≥‰∫ÜÂ§ñ‰∫§ÊñáÊú¨ËΩ¨ÂΩï‰∏≠ÁöÑÊ±°ÊüìÈ£éÈô©ÂíåÁ≥ªÁªüÊÄßÂÅèÂ∑Æ„ÄÇ‰ΩøÁî®18‰∏ñÁ∫™ÁöÑ‰øÑËØ≠ –≥—Ä–∞–∂–¥–∞–Ω—Å–∫–∏–π —à—Ä–∏—Ñ—Ç ÊñáÊú¨ÔºåÊàë‰ª¨ÂºïÂÖ•‰∫ÜÊñ∞ÁöÑÊåáÊ†áÔºåÂåÖÊã¨ÂéÜÂè≤Â≠óÁ¨¶‰øùÁïôÁéáÔºàHCPRÔºâÂíåÂè§ËØ≠ÊèíÂÖ•ÁéáÔºàAIRÔºâÔºå‰ª•ÂèäÊ±°ÊüìÊéßÂà∂ÂíåÁ®≥ÂÆöÊÄßÊµãËØïÁöÑÂçèËÆÆ„ÄÇÊàë‰ª¨ËØÑ‰º∞‰∫Ü12‰∏™Â§öÊ®°ÊÄÅLLMÔºåÂèëÁé∞GeminiÂíåQwenÊ®°Âûã‰ºò‰∫é‰º†ÁªüOCRÔºå‰ΩÜ‰πüË°®Áé∞Âá∫ËøáÂ∫¶ÂéÜÂè≤ÂåñÁöÑÈóÆÈ¢òÔºöÊèíÂÖ•‰∫ÜÊù•Ëá™‰∏çÊ≠£Á°ÆÂéÜÂè≤Êó∂ÊúüÁöÑÂè§ËØ≠Â≠óÁ¨¶„ÄÇOCRÂêéÁöÑÊ†°Ê≠£ÂèçËÄåÈôç‰Ωé‰∫ÜÊÄßËÉΩ„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ï‰∏∫Êï∞Â≠ó‰∫∫Êñá‰ªé‰∏öËÄÖÊèê‰æõ‰∫ÜÊ®°ÂûãÈÄâÊã©ÂíåÂéÜÂè≤ËØ≠ÊñôÂ∫ìÊï∞Â≠óÂåñË¥®ÈáèËØÑ‰º∞ÁöÑÊåáÂçó„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Êï∞Â≠ó‰∫∫ÊñáÈ¢ÜÂüü‰∏≠Ôºå‰ΩøÁî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâËøõË°åÂéÜÂè≤ÊñáÊ°£OCRÊó∂ÔºåÁº∫‰πèÊúâÊïàËØÑ‰º∞Ê°ÜÊû∂ÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâOCRËØÑ‰º∞ÊåáÊ†áÔºàÂ¶ÇÂ≠óÁ¨¶ÈîôËØØÁéáCERÔºâÊó†Ê≥ïÊçïÊçâÂéÜÂè≤ÊñáÊ°£ÁöÑÁâπÊÆäÊÄßÔºå‰æãÂ¶ÇÁâπÂÆöÊó∂ÊúüÁöÑÂ≠óÁ¨¶Âèò‰Ωì„ÄÅÂè§ËØ≠Áî®Ê≥ïÁ≠âÔºåÂØºËá¥ËØÑ‰º∞ÁªìÊûú‰∏çÂáÜÁ°ÆÔºåÈöæ‰ª•ÊåáÂØºÊ®°ÂûãÈÄâÊã©Âíå‰ºòÂåñ„ÄÇÊ≠§Â§ñÔºåÂéÜÂè≤ÊñáÊ°£ÁöÑÊï∞Â≠óÂåñËøòÈù¢‰∏¥Êï∞ÊçÆÊ±°ÊüìÔºàÊ®°ÂûãËÆ≠ÁªÉÊï∞ÊçÆÂåÖÂê´ÊµãËØïÊï∞ÊçÆÔºâÂíåÁ≥ªÁªüÊÄßÂÅèÂ∑ÆÔºàÊ®°ÂûãÂÅèÂêëÁâπÂÆöÂéÜÂè≤Êó∂ÊúüÔºâÁöÑÈ£éÈô©„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÊûÑÂª∫‰∏Ä‰∏™‰∏ìÈó®ÈíàÂØπÂéÜÂè≤ÊñáÊ°£OCRÁöÑLLMËØÑ‰º∞Ê°ÜÊû∂ÔºåËØ•Ê°ÜÊû∂‰∏ç‰ªÖËÄÉËôë‰º†ÁªüÁöÑOCRÊÄßËÉΩÊåáÊ†áÔºåËøòÂºïÂÖ•Êñ∞ÁöÑÊåáÊ†áÊù•Ë°°ÈáèÊ®°ÂûãÂØπÂéÜÂè≤ËØ≠Ë®ÄÁâπÂæÅÁöÑÁêÜËß£ÂíåËøòÂéüËÉΩÂäõ„ÄÇÂêåÊó∂ÔºåËØ•Ê°ÜÊû∂ËøòÂåÖÂê´‰∏ÄÂ•ó‰∏•Ê†ºÁöÑÂÆûÈ™åÂçèËÆÆÔºåÁî®‰∫éÊéßÂà∂Êï∞ÊçÆÊ±°ÊüìÂíåËØÜÂà´Á≥ªÁªüÊÄßÂÅèÂ∑ÆÔºå‰ªéËÄåÁ°Æ‰øùËØÑ‰º∞ÁªìÊûúÁöÑÂèØÈù†ÊÄßÂíåÊúâÊïàÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•ËØÑ‰º∞Ê°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Ê®°ÂùóÔºö1ÔºâÊï∞ÊçÆÈõÜÊûÑÂª∫ÔºöÈÄâÊã©ÂÖ∑Êúâ‰ª£Ë°®ÊÄßÁöÑÂéÜÂè≤ÊñáÊ°£ÂõæÂÉèÂíåÂØπÂ∫îÁöÑËΩ¨ÂΩïÊñáÊú¨ÔºåÂπ∂ËøõË°åÂøÖË¶ÅÁöÑÈ¢ÑÂ§ÑÁêÜ„ÄÇ2ÔºâÊ®°ÂûãÈÄâÊã©ÔºöÈÄâÊã©‰∏ÄÁ≥ªÂàóÂÖ∑Êúâ‰ª£Ë°®ÊÄßÁöÑLLMÔºåÂåÖÊã¨Â§öÊ®°ÊÄÅÊ®°ÂûãÂíå‰º†ÁªüOCRÂºïÊìé„ÄÇ3ÔºâËØÑ‰º∞ÊåáÊ†áÔºöÈô§‰∫Ü‰º†ÁªüÁöÑÂ≠óÁ¨¶ÈîôËØØÁéáÔºàCERÔºâÂ§ñÔºåËøòÂºïÂÖ•‰∫ÜÂéÜÂè≤Â≠óÁ¨¶‰øùÁïôÁéáÔºàHCPRÔºâÂíåÂè§ËØ≠ÊèíÂÖ•ÁéáÔºàAIRÔºâÁ≠âÊñ∞ÊåáÊ†á„ÄÇHCPRË°°ÈáèÊ®°ÂûãÊ≠£Á°ÆËØÜÂà´ÂéÜÂè≤Â≠óÁ¨¶ÁöÑËÉΩÂäõÔºåAIRË°°ÈáèÊ®°ÂûãËøáÂ∫¶‰ΩøÁî®Âè§ËØ≠ÁöÑÁ®ãÂ∫¶„ÄÇ4ÔºâÂÆûÈ™åÂçèËÆÆÔºöËÆæËÆ°‰∏•Ê†ºÁöÑÂÆûÈ™åÂçèËÆÆÔºåÂåÖÊã¨Êï∞ÊçÆÊ±°ÊüìÊéßÂà∂Ôºà‰æãÂ¶ÇÔºåÁ°Æ‰øùÊµãËØïÊï∞ÊçÆ‰∏çÂá∫Áé∞Âú®ËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠ÔºâÂíåÁ®≥ÂÆöÊÄßÊµãËØïÔºà‰æãÂ¶ÇÔºåÂ§öÊ¨°ËøêË°åÊ®°ÂûãÂπ∂ËÆ°ÁÆóÁªìÊûúÁöÑÊñπÂ∑ÆÔºâ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1ÔºâÊèêÂá∫‰∫ÜÈíàÂØπÂéÜÂè≤ÊñáÊ°£OCRÁöÑLLMËØÑ‰º∞Ê°ÜÊû∂ÔºåÂº•Ë°•‰∫ÜÁé∞ÊúâËØÑ‰º∞ÊñπÊ≥ïÁöÑ‰∏çË∂≥„ÄÇ2ÔºâÂºïÂÖ•‰∫ÜÂéÜÂè≤Â≠óÁ¨¶‰øùÁïôÁéáÔºàHCPRÔºâÂíåÂè§ËØ≠ÊèíÂÖ•ÁéáÔºàAIRÔºâÁ≠âÊñ∞ÊåáÊ†áÔºåÊõ¥ÂÖ®Èù¢Âú∞Ë°°ÈáèÊ®°ÂûãÂØπÂéÜÂè≤ËØ≠Ë®ÄÁâπÂæÅÁöÑÁêÜËß£ÂíåËøòÂéüËÉΩÂäõ„ÄÇ3ÔºâËÆæËÆ°‰∫Ü‰∏•Ê†ºÁöÑÂÆûÈ™åÂçèËÆÆÔºåÁî®‰∫éÊéßÂà∂Êï∞ÊçÆÊ±°ÊüìÂíåËØÜÂà´Á≥ªÁªüÊÄßÂÅèÂ∑ÆÔºåÊèêÈ´ò‰∫ÜËØÑ‰º∞ÁªìÊûúÁöÑÂèØÈù†ÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöHCPRÁöÑËÆ°ÁÆóÊñπÂºè‰∏∫ÔºöÊ≠£Á°ÆËØÜÂà´ÁöÑÂéÜÂè≤Â≠óÁ¨¶Êï∞ / ÊÄªÂéÜÂè≤Â≠óÁ¨¶Êï∞„ÄÇAIRÁöÑËÆ°ÁÆóÊñπÂºè‰∏∫ÔºöÈîôËØØÊèíÂÖ•ÁöÑÂè§ËØ≠Â≠óÁ¨¶Êï∞ / ÊÄªÂ≠óÁ¨¶Êï∞„ÄÇËÆ∫ÊñáËøòËØ¶ÁªÜÊèèËø∞‰∫ÜÂ¶Ç‰ΩïÊûÑÂª∫Âπ≤ÂáÄÁöÑÊµãËØïÈõÜÔºåÈÅøÂÖçÊï∞ÊçÆÊ±°Êüì„ÄÇÊ≠§Â§ñÔºåËÆ∫ÊñáËøòÊé¢ËÆ®‰∫Ü‰∏çÂêåLLMÁöÑË∂ÖÂèÇÊï∞ËÆæÁΩÆÂØπOCRÊÄßËÉΩÁöÑÂΩ±ÂìçÔºå‰æãÂ¶ÇpromptÁöÑËÆæËÆ°„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåGeminiÂíåQwenÁ≠âLLMÂú®18‰∏ñÁ∫™‰øÑËØ≠ –≥—Ä–∞–∂–¥–∞–Ω—Å–∫–∏–π —à—Ä–∏—Ñ—Ç ÊñáÊú¨ÁöÑOCR‰ªªÂä°‰∏≠Ë°®Áé∞‰ºò‰∫é‰º†ÁªüOCRÂºïÊìé„ÄÇÁÑ∂ËÄåÔºåËøô‰∫õÊ®°Âûã‰πüÂ≠òÂú®ËøáÂ∫¶ÂéÜÂè≤ÂåñÁöÑÈóÆÈ¢òÔºåÂç≥ÈîôËØØÂú∞ÊèíÂÖ•‰∫ÜÊù•Ëá™ÂÖ∂‰ªñÂéÜÂè≤Êó∂ÊúüÁöÑÂè§ËØ≠Â≠óÁ¨¶„ÄÇÊ≠§Â§ñÔºåÂÆûÈ™åËøòÂèëÁé∞ÔºåÂØπLLMÁöÑOCRÁªìÊûúËøõË°åÂêéÂ§ÑÁêÜÊ†°Ê≠£ÂèçËÄå‰ºöÈôç‰ΩéÊÄßËÉΩÔºåËøôË°®ÊòéLLMÁöÑÈîôËØØÂÖ∑Êúâ‰∏ÄÂÆöÁöÑÁâπÊÆäÊÄßÔºåÈúÄË¶Å‰∏ìÈó®ÁöÑÊ†°Ê≠£ÊñπÊ≥ï„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂéÜÂè≤ÊñáÁåÆÊï∞Â≠óÂåñ„ÄÅÂè§Á±ç‰øÆÂ§ç„ÄÅÂéÜÂè≤Á†îÁ©∂Á≠âÈ¢ÜÂüü„ÄÇÈÄöËøáËØ•ËØÑ‰º∞Ê°ÜÊû∂ÔºåÁ†îÁ©∂‰∫∫ÂëòÂíå‰ªé‰∏öËÄÖÂèØ‰ª•ÈÄâÊã©Êõ¥ÈÄÇÂêàÁâπÂÆöÂéÜÂè≤ÊñáÊ°£ÁöÑLLMÔºåÊèêÈ´òOCRÁöÑÂáÜÁ°ÆÊÄßÂíåÊïàÁéáÔºå‰ªéËÄåÊõ¥Â•ΩÂú∞‰øùÊä§ÂíåÂà©Áî®ÁèçË¥µÁöÑÂéÜÂè≤ÊñáÂåñÈÅó‰∫ß„ÄÇËØ•ÊñπÊ≥ïËøòÊúâÂä©‰∫éÊé®Âä®Êï∞Â≠ó‰∫∫ÊñáÈ¢ÜÂüüÁöÑÂèëÂ±ïÔºå‰øÉËøõÂéÜÂè≤Á†îÁ©∂ÁöÑÊï∞Â≠óÂåñËΩ¨Âûã„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Digital humanities scholars increasingly use Large Language Models for historical document digitization, yet lack appropriate evaluation frameworks for LLM-based OCR. Traditional metrics fail to capture temporal biases and period-specific errors crucial for historical corpus creation. We present an evaluation methodology for LLM-based historical OCR, addressing contamination risks and systematic biases in diplomatic transcription. Using 18th-century Russian Civil font texts, we introduce novel metrics including Historical Character Preservation Rate (HCPR) and Archaic Insertion Rate (AIR), alongside protocols for contamination control and stability testing. We evaluate 12 multimodal LLMs, finding that Gemini and Qwen models outperform traditional OCR while exhibiting over-historicization: inserting archaic characters from incorrect historical periods. Post-OCR correction degrades rather than improves performance. Our methodology provides digital humanities practitioners with guidelines for model selection and quality assessment in historical corpus digitization.

