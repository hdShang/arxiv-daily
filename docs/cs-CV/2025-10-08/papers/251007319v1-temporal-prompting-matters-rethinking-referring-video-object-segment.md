---
layout: default
title: Temporal Prompting Matters: Rethinking Referring Video Object Segmentation
---

# Temporal Prompting Matters: Rethinking Referring Video Object Segmentation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.07319" target="_blank" class="toolbar-btn">arXiv: 2510.07319v1</a>
    <a href="https://arxiv.org/pdf/2510.07319.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.07319v1" 
            onclick="toggleFavorite(this, '2510.07319v1', 'Temporal Prompting Matters: Rethinking Referring Video Object Segmentation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Ci-Siang Lin, Min-Hung Chen, I-Jieh Liu, Chien-Yi Wang, Sifei Liu, Yu-Chiang Frank Wang

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-08

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫TenetÊ°ÜÊû∂ÔºåÂà©Áî®Êó∂Â∫èPromptÈ´òÊïàËß£ÂÜ≥Referring Video Object SegmentationÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Referring Video Object Segmentation` `Êó∂Â∫èPrompt` `PromptÂ≠¶‰π†` `ËßÜÈ¢ëÁêÜËß£` `ÁõÆÊ†áÂàÜÂâ≤`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâRVOSÊñπÊ≥ï‰æùËµñÁ´ØÂà∞Á´ØËÆ≠ÁªÉÂíåÂØÜÈõÜÊ†áÊ≥®ÔºåËÆ°ÁÆóÊàêÊú¨È´ò‰∏îÈöæ‰ª•Êâ©Â±ï„ÄÇ
2. TenetÊ°ÜÊû∂Â∞ÜRVOSÂàÜËß£‰∏∫Êåá‰ª£„ÄÅËßÜÈ¢ëÂíåÂàÜÂâ≤Âõ†Á¥†ÔºåÂà©Áî®Êó∂Â∫èPromptËß£ÂÜ≥Êåá‰ª£ÂíåËßÜÈ¢ëÈóÆÈ¢ò„ÄÇ
3. ÈÄöËøáPrompt Preference LearningËØÑ‰º∞PromptË¥®ÈáèÔºåÊåáÂØºÂü∫Á°ÄÂàÜÂâ≤Ê®°ÂûãÔºåÂÆûÁé∞È´òÊïàÁöÑRVOS„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÈáçÊñ∞ÊÄùËÄÉ‰∫ÜReferring Video Object Segmentation (RVOS)‰ªªÂä°ÔºåÊó®Âú®Êé¢Á©∂ËØ•‰ªªÂä°ÁöÑÂÖ≥ÈîÆË¶ÅÁ¥†„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏ÈúÄË¶ÅÁ´ØÂà∞Á´ØÁöÑËÆ≠ÁªÉÔºåÂπ∂‰æùËµñÂØÜÈõÜÁöÑmaskÊ†áÊ≥®ÔºåËÆ°ÁÆóÊàêÊú¨È´ò‰∏îÊâ©Â±ïÊÄßÂ∑Æ„ÄÇÊú¨ÊñáÂ∞ÜRVOS‰ªªÂä°ÂàÜËß£‰∏∫Êåá‰ª£(referring)„ÄÅËßÜÈ¢ë(video)ÂíåÂàÜÂâ≤(segmentation)‰∏â‰∏™Âõ†Á¥†ÔºåÂπ∂ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Âêç‰∏∫Temporal Prompt Generation and Selection (Tenet)ÁöÑÊ°ÜÊû∂Ôºå‰ª•Ëß£ÂÜ≥Êåá‰ª£ÂíåËßÜÈ¢ëÂõ†Á¥†ÔºåËÄåÂ∞ÜÂàÜÂâ≤ÈóÆÈ¢ò‰∫§ÁªôÂü∫Á°ÄÂàÜÂâ≤Ê®°Âûã„ÄÇ‰∏∫‰∫ÜÊúâÊïàÂú∞Â∞ÜÂü∫‰∫éÂõæÂÉèÁöÑÂü∫Á°ÄÂàÜÂâ≤Ê®°ÂûãÂ∫îÁî®‰∫éRVOSÔºåÊú¨ÊñáÂà©Áî®Áé∞ÊàêÁöÑÁõÆÊ†áÊ£ÄÊµãÂô®ÂíåË∑üË∏™Âô®ÁîüÊàê‰∏éÊåá‰ª£ËØ≠Âè•Áõ∏ÂÖ≥ËÅîÁöÑÊó∂Â∫èPrompt„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥È´òË¥®ÈáèÊó∂Â∫èPromptÈöæ‰ª•ÈÄöËøáÁΩÆ‰ø°Â∫¶ÂàÜÊï∞ËØÜÂà´ÁöÑÈóÆÈ¢òÔºåÊú¨ÊñáÊèêÂá∫‰∫ÜPrompt Preference LearningÊù•ËØÑ‰º∞ÁîüÊàêÁöÑÊó∂Â∫èPromptÁöÑË¥®Èáè„ÄÇÈÄöËøá‰ΩøÁî®Ëøô‰∫õPromptÊù•ÊåáÂØºÂü∫‰∫éÂõæÂÉèÁöÑÂü∫Á°ÄÂàÜÂâ≤Ê®°ÂûãÔºåÂèØ‰ª•‰∏∫Ë¢´ÊåáÂØπË±°ÁîüÊàêÈ´òË¥®ÈáèÁöÑmaskÔºå‰ªéËÄåÂÆûÁé∞Ê®°ÂûãÂØπRVOSÁöÑÊúâÊïàÈÄÇÂ∫î„ÄÇÂú®RVOSÂü∫ÂáÜ‰∏äÁöÑÂÆûÈ™åËØÅÊòé‰∫ÜTenetÊ°ÜÊû∂ÁöÑÊúâÊïàÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöReferring Video Object Segmentation (RVOS)Êó®Âú®Ê†πÊçÆÁªôÂÆöÁöÑÊñáÊú¨ÊèèËø∞ÔºåÂú®ËßÜÈ¢ë‰∏≠ÂàÜÂâ≤Âá∫ÁõÆÊ†áÂØπË±°„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏ÈááÁî®Á´ØÂà∞Á´ØËÆ≠ÁªÉÔºåÈúÄË¶ÅÂ§ßÈáèÁöÑmaskÊ†áÊ≥®Êï∞ÊçÆÔºåÂØºËá¥ËÆ°ÁÆóËµÑÊ∫êÊ∂àËÄóÂ∑®Â§ßÔºåÂπ∂‰∏îÊ®°ÂûãÊ≥õÂåñËÉΩÂäõÂèóÈôêÔºåÈöæ‰ª•ÈÄÇÂ∫îÊñ∞ÁöÑÂú∫ÊôØÂíåÂØπË±°„ÄÇÊ≠§Â§ñÔºåÂ¶Ç‰ΩïÊúâÊïàÂà©Áî®ËßÜÈ¢ë‰∏≠ÁöÑÊó∂Â∫è‰ø°ÊÅØ‰πüÊòØ‰∏Ä‰∏™ÊåëÊàò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊú¨ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜRVOS‰ªªÂä°Ëß£ËÄ¶‰∏∫‰∏â‰∏™ÂÖ≥ÈîÆÂõ†Á¥†ÔºöÊåá‰ª£ÁêÜËß£„ÄÅËßÜÈ¢ëÊó∂Â∫èÂª∫Ê®°ÂíåÂØπË±°ÂàÜÂâ≤„ÄÇÈÄöËøáÂà©Áî®È¢ÑËÆ≠ÁªÉÁöÑÂõæÂÉèÂàÜÂâ≤Ê®°Âûã‰Ωú‰∏∫Âü∫Á°ÄÂàÜÂâ≤ËÉΩÂäõÔºåÈáçÁÇπËß£ÂÜ≥Êåá‰ª£ÁêÜËß£ÂíåËßÜÈ¢ëÊó∂Â∫èÂª∫Ê®°ÈóÆÈ¢ò„ÄÇÈÄöËøáÁîüÊàêÂíåÈÄâÊã©È´òË¥®ÈáèÁöÑÊó∂Â∫èPromptÔºåÂºïÂØºÂü∫Á°ÄÂàÜÂâ≤Ê®°ÂûãÂÆåÊàêÊúÄÁªàÁöÑÂàÜÂâ≤‰ªªÂä°Ôºå‰ªéËÄåÈÅøÂÖç‰∫ÜÁ´ØÂà∞Á´ØËÆ≠ÁªÉÁöÑÈúÄË¶Å„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöTenetÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Ê®°ÂùóÔºö1) **Êó∂Â∫èPromptÁîüÊàêÊ®°Âùó**ÔºöÂà©Áî®Áé∞ÊàêÁöÑÁõÆÊ†áÊ£ÄÊµãÂô®ÂíåË∑üË∏™Âô®ÔºåÁªìÂêàÊåá‰ª£ËØ≠Âè•ÔºåÂú®ËßÜÈ¢ëÂ∏ß‰∏≠ÁîüÊàêÂÄôÈÄâÁöÑPrompt„ÄÇ2) **Prompt Preference LearningÊ®°Âùó**ÔºöËÆæËÆ°‰∏Ä‰∏™Â≠¶‰π†Êú∫Âà∂ÔºåÁî®‰∫éËØÑ‰º∞ÂíåÈÄâÊã©È´òË¥®ÈáèÁöÑPrompt„ÄÇËØ•Ê®°ÂùóÊó®Âú®Ëß£ÂÜ≥‰ªÖ‰æùÈù†Ê£ÄÊµãÂô®ÂíåË∑üË∏™Âô®ÁöÑÁΩÆ‰ø°Â∫¶ÂàÜÊï∞Èöæ‰ª•Âå∫ÂàÜÈ´òË¥®ÈáèPromptÁöÑÈóÆÈ¢ò„ÄÇ3) **ÂàÜÂâ≤Ê®°Âùó**Ôºö‰ΩøÁî®ÈÄâÂÆöÁöÑPromptÊù•ÊåáÂØºÈ¢ÑËÆ≠ÁªÉÁöÑÂõæÂÉèÂàÜÂâ≤Ê®°ÂûãÔºåÁîüÊàêÊúÄÁªàÁöÑÂàÜÂâ≤ÁªìÊûú„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊú¨ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫ÜTemporal Prompt Generation and Selection (Tenet)Ê°ÜÊû∂ÔºåÂ∞ÜRVOS‰ªªÂä°ÂàÜËß£‰∏∫Êåá‰ª£„ÄÅËßÜÈ¢ëÂíåÂàÜÂâ≤‰∏â‰∏™Âõ†Á¥†ÔºåÂπ∂Âà©Áî®Êó∂Â∫èPromptÊù•Ê°•Êé•Êåá‰ª£ÁêÜËß£ÂíåËßÜÈ¢ëÊó∂Â∫èÂª∫Ê®°„ÄÇPrompt Preference LearningÊ®°ÂùóÊòØÂè¶‰∏Ä‰∏™ÂàõÊñ∞ÁÇπÔºåÂÆÉËÉΩÂ§üÊúâÊïàÂú∞ËØÑ‰º∞ÂíåÈÄâÊã©È´òË¥®ÈáèÁöÑPromptÔºå‰ªéËÄåÊèêÈ´òÂàÜÂâ≤Á≤æÂ∫¶„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöPrompt Preference LearningÊ®°ÂùóÁöÑÂÖ∑‰ΩìËÆæËÆ°ÁªÜËäÇÊú™Áü•ÔºåËÆ∫Êñá‰∏≠ÂèØËÉΩÊ∂âÂèäÁâπÂÆöÁöÑÊçüÂ§±ÂáΩÊï∞ÊàñÁΩëÁªúÁªìÊûÑÊù•Â≠¶‰π†PromptÁöÑË¥®ÈáèËØÑ‰º∞„ÄÇÊó∂Â∫èPromptÁöÑÂÖ∑‰ΩìÂΩ¢ÂºèÔºà‰æãÂ¶ÇÔºåbounding box, maskÁ≠âÔºâ‰ª•ÂèäÂ¶Ç‰ΩïÂ∞ÜÂÖ∂ËûçÂÖ•Âà∞Âü∫Á°ÄÂàÜÂâ≤Ê®°Âûã‰∏≠‰πüÂèØËÉΩÊòØÂÖ≥ÈîÆÁöÑËÆæËÆ°ÁªÜËäÇ„ÄÇÊ≠§Â§ñÔºåÂ¶Ç‰ΩïÊúâÊïàÂú∞Âà©Áî®ÁõÆÊ†áÊ£ÄÊµãÂô®ÂíåË∑üË∏™Âô®ÁöÑËæìÂá∫ÔºåÁîüÊàê‰∏éÊåá‰ª£ËØ≠Âè•Áõ∏ÂÖ≥ÁöÑPromptÔºå‰πüÊòØ‰∏Ä‰∏™ÈáçË¶ÅÁöÑËÄÉËôëÂõ†Á¥†„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ËÆ∫ÊñáÂú®RVOSÂü∫ÂáÜÊï∞ÊçÆÈõÜ‰∏äËøõË°å‰∫ÜÂÆûÈ™åÔºåËØÅÊòé‰∫ÜTenetÊ°ÜÊû∂ÁöÑÊúâÊïàÊÄß„ÄÇÂÖ∑‰ΩìÁöÑÊÄßËÉΩÊï∞ÊçÆ„ÄÅÂØπÊØîÂü∫Á∫ø‰ª•ÂèäÊèêÂçáÂπÖÂ∫¶ÈúÄË¶ÅÂú®ËÆ∫Êñá‰∏≠Êü•Êâæ„ÄÇËØ•Ê°ÜÊû∂ËÉΩÂ§üÂà©Áî®È¢ÑËÆ≠ÁªÉÁöÑÂõæÂÉèÂàÜÂâ≤Ê®°ÂûãÔºåÈÅøÂÖç‰∫ÜÁ´ØÂà∞Á´ØËÆ≠ÁªÉÔºåÈôç‰Ωé‰∫ÜËÆ°ÁÆóÊàêÊú¨ÔºåÂπ∂ÊèêÈ´ò‰∫ÜÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇPrompt Preference LearningÊ®°ÂùóËÉΩÂ§üÊúâÊïàÂú∞ÈÄâÊã©È´òË¥®ÈáèÁöÑPromptÔºå‰ªéËÄåÊèêÈ´òÂàÜÂâ≤Á≤æÂ∫¶„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éËßÜÈ¢ëÁõëÊéß„ÄÅËá™Âä®È©æÈ©∂„ÄÅËßÜÈ¢ëÁºñËæë„ÄÅ‰∫∫Êú∫‰∫§‰∫íÁ≠âÈ¢ÜÂüü„ÄÇ‰æãÂ¶ÇÔºåÂú®ËßÜÈ¢ëÁõëÊéß‰∏≠ÔºåÂèØ‰ª•ÈÄöËøáËá™ÁÑ∂ËØ≠Ë®ÄÊèèËø∞Âø´ÈÄüÂÆö‰ΩçÂíåÂàÜÂâ≤ÁõÆÊ†áÂØπË±°ÔºõÂú®Ëá™Âä®È©æÈ©∂‰∏≠ÔºåÂèØ‰ª•Ê†πÊçÆËØ≠Èü≥Êåá‰ª§ËØÜÂà´ÂíåË∑üË∏™ÁâπÂÆöËΩ¶ËæÜÊàñË°å‰∫∫ÔºõÂú®ËßÜÈ¢ëÁºñËæë‰∏≠ÔºåÂèØ‰ª•Êñπ‰æøÂú∞ÂØπËßÜÈ¢ë‰∏≠ÁöÑÁâπÂÆöÂØπË±°ËøõË°åÁºñËæëÂíåÂ§ÑÁêÜ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Referring Video Object Segmentation (RVOS) aims to segment the object referred to by the query sentence in the video. Most existing methods require end-to-end training with dense mask annotations, which could be computation-consuming and less scalable. In this work, we rethink the RVOS problem and aim to investigate the key to this task. Based on existing foundation segmentation models, we decompose the RVOS task into referring, video, and segmentation factors, and propose a Temporal Prompt Generation and Selection (Tenet) framework to address the referring and video factors while leaving the segmentation problem to foundation models. To efficiently adapt image-based foundation segmentation models to referring video object segmentation, we leverage off-the-shelf object detectors and trackers to produce temporal prompts associated with the referring sentence. While high-quality temporal prompts could be produced, they can not be easily identified from confidence scores. To tackle this issue, we propose Prompt Preference Learning to evaluate the quality of the produced temporal prompts. By taking such prompts to instruct image-based foundation segmentation models, we would be able to produce high-quality masks for the referred object, enabling efficient model adaptation to referring video object segmentation. Experiments on RVOS benchmarks demonstrate the effectiveness of the Tenet framework.

