---
layout: default
title: TalkCuts: A Large-Scale Dataset for Multi-Shot Human Speech Video Generation
---

# TalkCuts: A Large-Scale Dataset for Multi-Shot Human Speech Video Generation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.07249" target="_blank" class="toolbar-btn">arXiv: 2510.07249v2</a>
    <a href="https://arxiv.org/pdf/2510.07249.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.07249v2" 
            onclick="toggleFavorite(this, '2510.07249v2', 'TalkCuts: A Large-Scale Dataset for Multi-Shot Human Speech Video Generation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Jiaben Chen, Zixin Wang, Ailing Zeng, Yang Fu, Xueyang Yu, Siyuan Cen, Julian Tanke, Yihang Chen, Koichi Saito, Yuki Mitsufuji, Chuang Gan

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-08 (Êõ¥Êñ∞: 2025-10-13)

**Â§áÊ≥®**: Project page: https://talkcuts.github.io/

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫TalkCutsÂ§ßËßÑÊ®°Êï∞ÊçÆÈõÜÔºåÁî®‰∫éÂ§öÈïúÂ§¥‰∫∫Â£∞ËßÜÈ¢ëÁîüÊàêÁ†îÁ©∂**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±ÂÖ≠ÔºöËßÜÈ¢ëÊèêÂèñ‰∏éÂåπÈÖç (Video Extraction)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÈïúÂ§¥ËßÜÈ¢ëÁîüÊàê` `‰∫∫Â£∞ËßÜÈ¢ëÁîüÊàê` `Â§ßËßÑÊ®°Êï∞ÊçÆÈõÜ` `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `ËØ≠Ë®ÄÊ®°ÂûãÂºïÂØº` `ËßÜÈ¢ëÂêàÊàê` `ÂßøÂäøÂºïÂØº` `Èü≥È¢ëÈ©±Âä®`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊï∞ÊçÆÈõÜÁº∫‰πèÂ§öÈïúÂ§¥ÂíåÂ§öÊ†∑ÂåñËßÜËßíÔºåÈôêÂà∂‰∫ÜÂ§öÈïúÂ§¥‰∫∫Â£∞ËßÜÈ¢ëÁîüÊàêÁöÑÁ†îÁ©∂„ÄÇ
2. ÊèêÂá∫TalkCutsÊï∞ÊçÆÈõÜÔºåÂåÖÂê´È´òË¥®Èáè„ÄÅÂ§öÈïúÂ§¥„ÄÅÂ§öËßÜËßíÁöÑ‰∫∫Â£∞ËßÜÈ¢ëÔºåÂπ∂Êèê‰æõËØ¶ÁªÜÊ†áÊ≥®„ÄÇ
3. ÊûÑÂª∫LLMÂºïÂØºÁöÑÂ§öÊ®°ÊÄÅÁîüÊàêÊ°ÜÊû∂OratorÔºåÂÆûÈ™åËØÅÊòéÂú®TalkCuts‰∏äËÆ≠ÁªÉËÉΩÊòæËëóÊèêÂçáËßÜÈ¢ëË¥®Èáè„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫ÜTalkCutsÔºå‰∏Ä‰∏™Â§ßËßÑÊ®°Êï∞ÊçÆÈõÜÔºåÊó®Âú®‰øÉËøõÂ§öÈïúÂ§¥‰∫∫Â£∞ËßÜÈ¢ëÁîüÊàêÁöÑÁ†îÁ©∂„ÄÇ‰∏éÁé∞Êúâ‰∏ìÊ≥®‰∫éÂçïÈïúÂ§¥„ÄÅÈùôÊÄÅËßÜËßíÁöÑÊï∞ÊçÆÈõÜ‰∏çÂêåÔºåTalkCutsÊèê‰æõË∂ÖËøá500Â∞èÊó∂ÁöÑÈ´òË¥®Èáè‰∫∫Â£∞ËßÜÈ¢ëÔºåÂåÖÂê´16.4‰∏á‰∏™ÁâáÊÆµÔºåÂÖ∑ÊúâÂ§öÊ†∑ÂåñÁöÑÈïúÂ§¥ÔºåÂåÖÊã¨ÁâπÂÜô„ÄÅÂçäË∫´ÂíåÂÖ®Ë∫´ËßÜÂõæ„ÄÇËØ•Êï∞ÊçÆÈõÜÂåÖÊã¨ËØ¶ÁªÜÁöÑÊñáÊú¨ÊèèËø∞„ÄÅ2DÂÖ≥ÈîÆÁÇπÂíå3D SMPL-X ËøêÂä®Ê†áÊ≥®ÔºåË¶ÜÁõñË∂ÖËøá1‰∏á‰∏™Ë∫´‰ªΩÔºåÊîØÊåÅÂ§öÊ®°ÊÄÅÂ≠¶‰π†ÂíåËØÑ‰º∞„ÄÇ‰Ωú‰∏∫Â±ïÁ§∫Êï∞ÊçÆÈõÜ‰ª∑ÂÄºÁöÑÂàùÊ≠•Â∞ùËØïÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜOratorÔºå‰∏Ä‰∏™Áî±LLMÂºïÂØºÁöÑÂ§öÊ®°ÊÄÅÁîüÊàêÊ°ÜÊû∂‰Ωú‰∏∫ÁÆÄÂçïÂü∫Á∫øÔºåÂÖ∂‰∏≠ËØ≠Ë®ÄÊ®°ÂûãÂÖÖÂΩìÂ§öÊñπÈù¢ÁöÑÂØºÊºîÔºåÂçèË∞ÉÁõ∏Êú∫ËøáÊ∏°„ÄÅËØ¥ËØùËÄÖÊâãÂäøÂíåÂ£∞Èü≥Ë∞ÉÂà∂Á≠âËØ¶ÁªÜËßÑËåÉ„ÄÇËØ•Êû∂ÊûÑÈÄöËøáÊàë‰ª¨ÈõÜÊàêÁöÑÂ§öÊ®°ÊÄÅËßÜÈ¢ëÁîüÊàêÊ®°ÂùóÔºåËÉΩÂ§üÂêàÊàêËøûË¥ØÁöÑÈïøËßÜÈ¢ë„ÄÇÂú®ÂßøÂäøÂºïÂØºÂíåÈü≥È¢ëÈ©±Âä®ÁöÑËÆæÁΩÆ‰∏ãËøõË°åÁöÑÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåÂú®TalkCuts‰∏äËÆ≠ÁªÉÂèØ‰ª•ÊòæËëóÊèêÈ´òÁîüÊàêÁöÑÂ§öÈïúÂ§¥ËØ≠Èü≥ËßÜÈ¢ëÁöÑÁîµÂΩ±ËøûË¥ØÊÄßÂíåËßÜËßâÂê∏ÂºïÂäõ„ÄÇÊàë‰ª¨Áõ∏‰ø°TalkCuts‰∏∫ÂèØÊéßÁöÑÂ§öÈïúÂ§¥ËØ≠Èü≥ËßÜÈ¢ëÁîüÊàêÂíåÊõ¥ÂπøÊ≥õÁöÑÂ§öÊ®°ÊÄÅÂ≠¶‰π†ÁöÑÊú™Êù•Â∑•‰ΩúÊèê‰æõ‰∫ÜÂùöÂÆûÁöÑÂü∫Á°Ä„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÁöÑ‰∫∫Â£∞ËßÜÈ¢ëÁîüÊàêÊï∞ÊçÆÈõÜÈÄöÂ∏∏ÈõÜ‰∏≠‰∫éÂçïÈïúÂ§¥ÂíåÈùôÊÄÅËßÜËßíÔºåÁº∫‰πèÂØπÂ§öÈïúÂ§¥ÂàáÊç¢ÂíåÂä®ÊÄÅÂú∫ÊôØÁöÑÂª∫Ê®°ËÉΩÂäõ„ÄÇËøôÈôêÂà∂‰∫ÜÁîüÊàêÊõ¥ÂÖ∑ÁîµÂΩ±ÊÑüÂíåÁúüÂÆûÊÑüÁöÑ‰∫∫Â£∞ËßÜÈ¢ë„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÊûÑÂª∫‰∏Ä‰∏™Â§ßËßÑÊ®°„ÄÅÂ§öÈïúÂ§¥„ÄÅÂ§öËßÜËßíÁöÑ‰∫∫Â£∞ËßÜÈ¢ëÊï∞ÊçÆÈõÜÔºåÂπ∂Âà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâ‰Ωú‰∏∫ÂØºÊºîÔºåÊåáÂØºÂ§öÊ®°ÊÄÅÁîüÊàêÊ°ÜÊû∂Ôºå‰ªéËÄåÂÆûÁé∞ÂØπÁõ∏Êú∫ËøáÊ∏°„ÄÅËØ¥ËØùËÄÖÊâãÂäøÂíåÂ£∞Èü≥Ë∞ÉÂà∂ÁöÑÁ≤æÁªÜÊéßÂà∂„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊ°ÜÊû∂OratorÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) LLMÂØºÊºîÊ®°ÂùóÔºöÂà©Áî®LLMÁîüÊàêÁõ∏Êú∫ËøáÊ∏°„ÄÅÊâãÂäøÂíåÂ£∞Èü≥Ë∞ÉÂà∂ÁöÑÊåá‰ª§„ÄÇ2) Â§öÊ®°ÊÄÅËßÜÈ¢ëÁîüÊàêÊ®°ÂùóÔºöÊ†πÊçÆLLMÁöÑÊåá‰ª§ÔºåÁªìÂêàÂßøÂäøÊàñÈü≥È¢ë‰ø°ÊÅØÔºåÁîüÊàêÁõ∏Â∫îÁöÑËßÜÈ¢ëÁâáÊÆµ„ÄÇ3) ÈõÜÊàêÊ®°ÂùóÔºöÂ∞ÜÁîüÊàêÁöÑËßÜÈ¢ëÁâáÊÆµÊãºÊé•ÊàêËøûË¥ØÁöÑÈïøËßÜÈ¢ë„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1) ÊûÑÂª∫‰∫ÜÂ§ßËßÑÊ®°Â§öÈïúÂ§¥‰∫∫Â£∞ËßÜÈ¢ëÊï∞ÊçÆÈõÜTalkCutsÔºå‰∏∫Â§öÈïúÂ§¥ËßÜÈ¢ëÁîüÊàêÊèê‰æõ‰∫ÜÊï∞ÊçÆÂü∫Á°Ä„ÄÇ2) ÊèêÂá∫‰∫ÜLLMÂºïÂØºÁöÑÂ§öÊ®°ÊÄÅÁîüÊàêÊ°ÜÊû∂OratorÔºåÂà©Áî®LLMÁöÑÂº∫Â§ßËÉΩÂäõÊù•ÊéßÂà∂ËßÜÈ¢ëÁöÑÁîüÊàêËøáÁ®ãÔºåÂÆûÁé∞‰∫ÜÊõ¥Á≤æÁªÜÁöÑÊéßÂà∂ÂíåÊõ¥È´òÁöÑÁîüÊàêË¥®Èáè„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöOratorÊ°ÜÊû∂‰∏≠ÔºåLLMË¢´ËÆæËÆ°‰∏∫‚ÄúÂØºÊºî‚ÄùÔºåË¥üË¥£ÁîüÊàêËØ¶ÁªÜÁöÑÊåá‰ª§ÔºåÂåÖÊã¨Áõ∏Êú∫ËßíÂ∫¶„ÄÅ‰∫∫Áâ©ÂßøÂäø„ÄÅËØ≠Èü≥ËØ≠Ë∞ÉÁ≠â„ÄÇËøô‰∫õÊåá‰ª§Ë¢´‰º†ÈÄíÁªôÂ§öÊ®°ÊÄÅËßÜÈ¢ëÁîüÊàêÊ®°ÂùóÔºåËØ•Ê®°ÂùóÊ†πÊçÆÊåá‰ª§ÁîüÊàêÁõ∏Â∫îÁöÑËßÜÈ¢ëÁâáÊÆµ„ÄÇÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°Êó®Âú®‰øùËØÅÁîüÊàêËßÜÈ¢ëÁöÑËøûË¥ØÊÄßÂíåÁúüÂÆûÊÑüÔºåÂÖ∑‰ΩìÁªÜËäÇÊú™Áü•„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÂú®TalkCutsÊï∞ÊçÆÈõÜ‰∏äËÆ≠ÁªÉÁöÑOratorÊ°ÜÊû∂ÔºåÂú®ÂßøÂäøÂºïÂØºÂíåÈü≥È¢ëÈ©±Âä®ÁöÑËÆæÁΩÆ‰∏ãÔºåËÉΩÂ§üÊòæËëóÊèêÈ´òÁîüÊàêÁöÑÂ§öÈïúÂ§¥ËØ≠Èü≥ËßÜÈ¢ëÁöÑÁîµÂΩ±ËøûË¥ØÊÄßÂíåËßÜËßâÂê∏ÂºïÂäõ„ÄÇÂÖ∑‰ΩìÊÄßËÉΩÊï∞ÊçÆÊú™Áü•Ôºå‰ΩÜÁõ∏ËæÉ‰∫éÂÖ∂‰ªñÂü∫Á∫øÊñπÊ≥ïÔºåOratorÂú®‰∏ªËßÇËØÑ‰ª∑‰∏äË°®Áé∞Êõ¥‰Ω≥„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éËôöÊãü‰∏ªÊí≠„ÄÅËøúÁ®ã‰ºöËÆÆ„ÄÅÁîµÂΩ±Âà∂‰ΩúÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáTalkCutsÊï∞ÊçÆÈõÜÂíåOratorÊ°ÜÊû∂ÔºåÂèØ‰ª•ÁîüÊàêÊõ¥ÂÖ∑Ë°®Áé∞ÂäõÂíåÁúüÂÆûÊÑüÁöÑ‰∫∫Â£∞ËßÜÈ¢ëÔºåÊèêÂçáÁî®Êà∑‰ΩìÈ™åÂíåÊ≤üÈÄöÊïàÁéá„ÄÇÊú™Êù•ÔºåËØ•ÊäÄÊúØÊúâÊúõÂ∫îÁî®‰∫é‰∏™ÊÄßÂåñËßÜÈ¢ëÁîüÊàê„ÄÅËôöÊãüÁé∞ÂÆûÂíåÂ¢ûÂº∫Áé∞ÂÆûÁ≠âÈ¢ÜÂüü„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> In this work, we present TalkCuts, a large-scale dataset designed to facilitate the study of multi-shot human speech video generation. Unlike existing datasets that focus on single-shot, static viewpoints, TalkCuts offers 164k clips totaling over 500 hours of high-quality human speech videos with diverse camera shots, including close-up, half-body, and full-body views. The dataset includes detailed textual descriptions, 2D keypoints and 3D SMPL-X motion annotations, covering over 10k identities, enabling multimodal learning and evaluation. As a first attempt to showcase the value of the dataset, we present Orator, an LLM-guided multi-modal generation framework as a simple baseline, where the language model functions as a multi-faceted director, orchestrating detailed specifications for camera transitions, speaker gesticulations, and vocal modulation. This architecture enables the synthesis of coherent long-form videos through our integrated multi-modal video generation module. Extensive experiments in both pose-guided and audio-driven settings show that training on TalkCuts significantly enhances the cinematographic coherence and visual appeal of generated multi-shot speech videos. We believe TalkCuts provides a strong foundation for future work in controllable, multi-shot speech video generation and broader multimodal learning.

