---
layout: default
title: Control-Augmented Autoregressive Diffusion for Data Assimilation
---

# Control-Augmented Autoregressive Diffusion for Data Assimilation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.06637" target="_blank" class="toolbar-btn">arXiv: 2510.06637v1</a>
    <a href="https://arxiv.org/pdf/2510.06637.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.06637v1" 
            onclick="toggleFavorite(this, '2510.06637v1', 'Control-Augmented Autoregressive Diffusion for Data Assimilation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Prakhar Srivastava, Farrin Marouf Sofian, Francesco Immorlano, Kushagra Pandey, Stephan Mandt

**ÂàÜÁ±ª**: cs.LG, cs.AI, cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-08

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫ÊéßÂà∂Â¢ûÂº∫Ëá™ÂõûÂΩíÊâ©Êï£Ê®°ÂûãÔºåÁî®‰∫éËß£ÂÜ≥Êï∞ÊçÆÂêåÂåñ‰∏≠È¢ÑÊµãÊºÇÁßªÈóÆÈ¢ò„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±ÂÖ´ÔºöÁâ©ÁêÜÂä®Áîª (Physics-based Animation)**

**ÂÖ≥ÈîÆËØç**: `Ëá™ÂõûÂΩíÊâ©Êï£Ê®°Âûã` `Êï∞ÊçÆÂêåÂåñ` `ÊéßÂà∂Â¢ûÂº∫` `ÂÅèÂæÆÂàÜÊñπÁ®ã` `È¢ÑÊµãÊºÇÁßª`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊï∞ÊçÆÂêåÂåñÊñπÊ≥ïÂú®Â§ÑÁêÜÊ∑∑Ê≤åÂÅèÂæÆÂàÜÊñπÁ®ãÊó∂ÔºåËÆ°ÁÆóÊàêÊú¨È´òÊòÇÔºå‰∏îÂú®Á®ÄÁñèËßÇÊµã‰∏ãÊòì‰∫ßÁîüÈ¢ÑÊµãÊºÇÁßª„ÄÇ
2. ÊèêÂá∫‰∏ÄÁßçÊéßÂà∂Â¢ûÂº∫Ëá™ÂõûÂΩíÊâ©Êï£Ê®°ÂûãÔºåÈÄöËøáËΩªÈáèÁ∫ßÊéßÂà∂Âô®ÁΩëÁªúÈ¢ÑÊµãÊú™Êù•ËßÇÊµãÔºåÂÆûÁé∞Âç≥Êó∂Ê†°Ê≠£„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®Á®≥ÂÆöÊÄß„ÄÅÂáÜÁ°ÆÊÄßÂíåÁâ©ÁêÜ‰øùÁúüÂ∫¶ÊñπÈù¢‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºå‰∏îÈÅøÂÖç‰∫ÜÊòÇË¥µÁöÑËÆ°ÁÆó„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â∞ΩÁÆ°Êâ©Êï£Ê®°ÂûãÂú®ÊµãËØïÊó∂Áº©ÊîæÂíåÂæÆË∞ÉÊñπÈù¢ÂèñÂæó‰∫ÜËøõÂ±ïÔºå‰ΩÜËá™ÂõûÂΩíÊâ©Êï£Ê®°ÂûãÔºàARDMÔºâ‰∏≠ÁöÑÂºïÂØº‰ªçÁÑ∂Êú™Ë¢´ÂÖÖÂàÜÊé¢Á¥¢„ÄÇÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏ÄÁßçÊëäÈîÄÊ°ÜÊû∂ÔºåÈÄöËøá‰∏Ä‰∏™ËΩªÈáèÁ∫ßÊéßÂà∂Âô®ÁΩëÁªúÊù•Â¢ûÂº∫È¢ÑËÆ≠ÁªÉÁöÑARDM„ÄÇËØ•ÊéßÂà∂Âô®ÁΩëÁªúÈÄöËøáÈ¢ÑËßàÊú™Êù•ÁöÑARDMÂ±ïÂºÄÂπ∂Â≠¶‰π†ÈÄêÊ≠•ÊéßÂà∂Êù•È¢ÑÊµãÂç≥Â∞ÜÂà∞Êù•ÁöÑËßÇÊµãÔºå‰ªéËÄåÂú®ÁªàÁ´ØÊàêÊú¨ÁõÆÊ†á‰∏ãËøõË°åÁ¶ªÁ∫øËÆ≠ÁªÉ„ÄÇÊàë‰ª¨Âú®Ê∑∑Ê≤åÊó∂Á©∫ÂÅèÂæÆÂàÜÊñπÁ®ãÔºàPDEÔºâÁöÑÊï∞ÊçÆÂêåÂåñÔºàDAÔºâËÉåÊôØ‰∏ãËØÑ‰º∞‰∫ÜËØ•Ê°ÜÊû∂ÔºåÂú®ËøôÁßçÊÉÖÂÜµ‰∏ãÔºåÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏Âú®ËÆ°ÁÆó‰∏äÊòØÁ¶ÅÊ≠¢ÁöÑÔºåÂπ∂‰∏îÂú®Á®ÄÁñèËßÇÊµã‰∏ãÂÆπÊòìÂá∫Áé∞È¢ÑÊµãÊºÇÁßª„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÂ∞ÜDAÊé®ÁêÜÁÆÄÂåñ‰∏∫ÂçïÊ¨°ÂâçÂêëÂ±ïÂºÄÂíåÂç≥Êó∂Ê†°Ê≠£ÔºåÈÅøÂÖç‰∫ÜÊé®ÁêÜÊúüÈó¥ÊòÇË¥µÁöÑ‰º¥ÈöèËÆ°ÁÆóÂíå/Êàñ‰ºòÂåñ„ÄÇÊàë‰ª¨ËØÅÊòé‰∫ÜÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®‰∏§‰∏™ÂÖ∏ÂûãÁöÑPDEÂíåÂÖ≠‰∏™ËßÇÊµãÊñπÊ°à‰∏≠ÔºåÂú®Á®≥ÂÆöÊÄß„ÄÅÂáÜÁ°ÆÊÄßÂíåÁâ©ÁêÜ‰øùÁúüÂ∫¶ÊñπÈù¢ÂßãÁªà‰ºò‰∫éÂõõÁßçÊúÄÂÖàËøõÁöÑÂü∫Á∫øÊñπÊ≥ï„ÄÇÊàë‰ª¨Â∞ÜÂÖ¨ÂºÄÂèëÂ∏É‰ª£Á†ÅÂíåÊ£ÄÊü•ÁÇπ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Êï∞ÊçÆÂêåÂåñÔºàDAÔºâÈóÆÈ¢òÔºåÁâπÂà´ÊòØÂú®Ê∑∑Ê≤åÊó∂Á©∫ÂÅèÂæÆÂàÜÊñπÁ®ãÔºàPDEÔºâÁöÑËÉåÊôØ‰∏ã„ÄÇÁé∞ÊúâÁöÑDAÊñπÊ≥ïÔºåÂ¶ÇÂç°Â∞îÊõºÊª§Ê≥¢ÂèäÂÖ∂Âèò‰ΩìÔºåÂú®Â§ÑÁêÜÈ´òÁª¥„ÄÅÈùûÁ∫øÊÄßÁ≥ªÁªüÊó∂ËÆ°ÁÆóÊàêÊú¨ÈùûÂ∏∏È´òÊòÇ„ÄÇÊ≠§Â§ñÔºåÂú®ËßÇÊµãÊï∞ÊçÆÁ®ÄÁñèÁöÑÊÉÖÂÜµ‰∏ãÔºåËøô‰∫õÊñπÊ≥ïÂÆπÊòìÂá∫Áé∞È¢ÑÊµãÊºÇÁßªÔºåÂØºËá¥ÈïøÊúüÈ¢ÑÊµãÁªìÊûú‰∏éÁúüÂÆûÊÉÖÂÜµÂÅèÂ∑ÆËæÉÂ§ß„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Ëá™ÂõûÂΩíÊâ©Êï£Ê®°ÂûãÔºàARDMÔºâÁîüÊàêÈ´òË¥®ÈáèÁöÑÈ¢ÑÊµãÔºåÂπ∂ÂºïÂÖ•‰∏Ä‰∏™ËΩªÈáèÁ∫ßÁöÑÊéßÂà∂Âô®ÁΩëÁªúÊù•ÂØπARDMÁöÑÁîüÊàêËøáÁ®ãËøõË°åÂºïÂØº„ÄÇËØ•ÊéßÂà∂Âô®ÈÄöËøáËßÇÂØüARDMÁöÑ‰∏≠Èó¥Áä∂ÊÄÅÂíåÊú™Êù•ÁöÑËßÇÊµãÊï∞ÊçÆÔºåÂ≠¶‰π†Â¶Ç‰ΩïÈÄêÊ≠•Ë∞ÉÊï¥ARDMÁöÑÁîüÊàêËøáÁ®ãÔºå‰ªéËÄåÂÆûÁé∞ÂØπÈ¢ÑÊµãÁªìÊûúÁöÑÊ†°Ê≠£„ÄÇËøôÁßçÊñπÊ≥ïÈÅøÂÖç‰∫Ü‰º†ÁªüDAÊñπÊ≥ï‰∏≠ÊòÇË¥µÁöÑ‰º¥ÈöèËÆ°ÁÆóÂíå‰ºòÂåñËøáÁ®ã„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´‰∏§‰∏™‰∏ªË¶ÅÈÉ®ÂàÜÔºöÈ¢ÑËÆ≠ÁªÉÁöÑARDMÂíå‰∏Ä‰∏™ËΩªÈáèÁ∫ßÁöÑÊéßÂà∂Âô®ÁΩëÁªú„ÄÇARDMË¥üË¥£ÁîüÊàêÂàùÂßãÁöÑÈ¢ÑÊµãËΩ®ËøπÔºåÊéßÂà∂Âô®ÁΩëÁªúÂàôË¥üË¥£Ê†πÊçÆËßÇÊµãÊï∞ÊçÆÂØπARDMÁöÑÁîüÊàêËøáÁ®ãËøõË°åÂÆûÊó∂Ê†°Ê≠£„ÄÇÊéßÂà∂Âô®ÁΩëÁªúÈÄöËøáÈ¢ÑËßàARDMÊú™Êù•ÁöÑÂ±ïÂºÄËΩ®ËøπÔºåÂ≠¶‰π†Âú®ÊØè‰∏ÄÊ≠•ÈááÂèñ‰ΩïÁßçÊéßÂà∂Âä®‰ΩúÔºå‰ª•ÊúÄÂ∞èÂåñÁªàÁ´ØÊàêÊú¨„ÄÇÊï¥‰∏™ËøáÁ®ãÂèØ‰ª•Áúã‰ΩúÊòØ‰∏Ä‰∏™Âº∫ÂåñÂ≠¶‰π†ÈóÆÈ¢òÔºåÊéßÂà∂Âô®ÁΩëÁªúÂÖÖÂΩìÁ≠ñÁï•ÁΩëÁªúÔºåARDMÂÖÖÂΩìÁéØÂ¢É„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞Âú®‰∫éÂ∞ÜÊéßÂà∂ÁêÜËÆ∫‰∏éËá™ÂõûÂΩíÊâ©Êï£Ê®°ÂûãÁõ∏ÁªìÂêàÔºåÊèêÂá∫‰∫Ü‰∏ÄÁßçÊéßÂà∂Â¢ûÂº∫ÁöÑÊâ©Êï£Ê®°Âûã„ÄÇ‰∏é‰º†ÁªüÁöÑDAÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïÈÅøÂÖç‰∫ÜÊòÇË¥µÁöÑ‰º¥ÈöèËÆ°ÁÆóÂíå‰ºòÂåñËøáÁ®ãÔºåÂÆûÁé∞‰∫ÜÈ´òÊïàÁöÑÊï∞ÊçÆÂêåÂåñ„ÄÇÊ≠§Â§ñÔºåÈÄöËøáÁ¶ªÁ∫øËÆ≠ÁªÉÊéßÂà∂Âô®ÁΩëÁªúÔºåÂèØ‰ª•Âú®Êé®ÁêÜÈò∂ÊÆµÂÆûÁé∞Âø´ÈÄüÁöÑÂç≥Êó∂Ê†°Ê≠£„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÊéßÂà∂Âô®ÁΩëÁªúÊòØ‰∏Ä‰∏™ËΩªÈáèÁ∫ßÁöÑÁ•ûÁªèÁΩëÁªúÔºåËæìÂÖ•ÂåÖÊã¨ARDMÁöÑÂΩìÂâçÁä∂ÊÄÅÂíåÊú™Êù•ÁöÑËßÇÊµãÊï∞ÊçÆÔºåËæìÂá∫ÊòØÊéßÂà∂‰ø°Âè∑ÔºåÁî®‰∫éË∞ÉÊï¥ARDMÁöÑÁîüÊàêËøáÁ®ã„ÄÇÊçüÂ§±ÂáΩÊï∞ÈááÁî®ÁªàÁ´ØÊàêÊú¨ÁöÑÂΩ¢ÂºèÔºåÈºìÂä±ÊéßÂà∂Âô®ÁΩëÁªúÂú®Êï¥‰∏™È¢ÑÊµãËøáÁ®ã‰∏≠ÈÄêÊ≠•ÈÄºËøëÁúüÂÆûÁä∂ÊÄÅ„ÄÇÂÖ∑‰ΩìÁöÑÁΩëÁªúÁªìÊûÑÂíåÂèÇÊï∞ËÆæÁΩÆÈúÄË¶ÅÊ†πÊçÆÂÖ∑‰ΩìÁöÑPDEÈóÆÈ¢òËøõË°åË∞ÉÊï¥„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®‰∏§‰∏™ÂÖ∏ÂûãÁöÑÂÅèÂæÆÂàÜÊñπÁ®ãÔºàPDEÔºâÂíåÂÖ≠‰∏™ËßÇÊµãÊñπÊ°à‰∏≠ÔºåÂú®Á®≥ÂÆöÊÄß„ÄÅÂáÜÁ°ÆÊÄßÂíåÁâ©ÁêÜ‰øùÁúüÂ∫¶ÊñπÈù¢ÂßãÁªà‰ºò‰∫éÂõõÁßçÊúÄÂÖàËøõÁöÑÂü∫Á∫øÊñπÊ≥ï„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÊòæËëóÂáèÂ∞ëÈ¢ÑÊµãÊºÇÁßªÔºåÊèêÈ´òÈïøÊúüÈ¢ÑÊµãÁöÑÂáÜÁ°ÆÊÄßÔºåÂπ∂‰∏îÂú®ËÆ°ÁÆóÊïàÁéáÊñπÈù¢ÂÖ∑ÊúâÊòæËëó‰ºòÂäø„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊ∞îË±°È¢ÑÊä•„ÄÅÊµ∑Ê¥ãÁéØÂ¢ÉÁõëÊµã„ÄÅÈáëËûçÈ£éÈô©ÁÆ°ÁêÜÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÊõ¥ÂáÜÁ°ÆÂú∞ÂêåÂåñËßÇÊµãÊï∞ÊçÆÔºåÂèØ‰ª•ÊèêÈ´òÈ¢ÑÊµãÁöÑÂáÜÁ°ÆÊÄßÂíåÂèØÈù†ÊÄßÔºå‰∏∫ÂÜ≥Á≠ñÊèê‰æõÊõ¥ÂèØÈù†ÁöÑ‰æùÊçÆ„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïÊúâÊúõÊâ©Â±ïÂà∞ÂÖ∂‰ªñÁ±ªÂûãÁöÑÂä®ÊÄÅÁ≥ªÁªüÔºåÂπ∂‰∏éÂÖ∂‰ªñÊï∞ÊçÆÂêåÂåñÊäÄÊúØÁõ∏ÁªìÂêàÔºåËøõ‰∏ÄÊ≠•ÊèêÂçáÊï∞ÊçÆÂêåÂåñÁöÑÊÄßËÉΩ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Despite recent advances in test-time scaling and finetuning of diffusion models, guidance in Auto-Regressive Diffusion Models (ARDMs) remains underexplored. We introduce an amortized framework that augments pretrained ARDMs with a lightweight controller network, trained offline by previewing future ARDM rollouts and learning stepwise controls that anticipate upcoming observations under a terminal cost objective. We evaluate this framework in the context of data assimilation (DA) for chaotic spatiotemporal partial differential equations (PDEs), a setting where existing methods are often computationally prohibitive and prone to forecast drift under sparse observations. Our approach reduces DA inference to a single forward rollout with on-the-fly corrections, avoiding expensive adjoint computations and/or optimizations during inference. We demonstrate that our method consistently outperforms four state-of-the-art baselines in stability, accuracy, and physical fidelity across two canonical PDEs and six observation regimes. We will release code and checkpoints publicly.

