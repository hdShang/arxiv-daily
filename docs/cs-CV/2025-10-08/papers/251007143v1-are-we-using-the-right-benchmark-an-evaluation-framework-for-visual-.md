---
layout: default
title: Are We Using the Right Benchmark: An Evaluation Framework for Visual Token Compression Methods
---

# Are We Using the Right Benchmark: An Evaluation Framework for Visual Token Compression Methods

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.07143" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.07143v1</a>
  <a href="https://arxiv.org/pdf/2510.07143.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.07143v1" onclick="toggleFavorite(this, '2510.07143v1', 'Are We Using the Right Benchmark: An Evaluation Framework for Visual Token Compression Methods')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chenfei Liao, Wensong Wang, Zichen Wen, Xu Zheng, Yiyu Wang, Haocong He, Yuanhuiyi Lyu, Lutao Jiang, Xin Zou, Yuqian Fu, Bin Ren, Linfeng Zhang, Xuming Hu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-08

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Chenfei-Liao/VTC-Bench)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVTC-Benchï¼Œç”¨äºæ›´å‡†ç¡®è¯„ä¼°å¤šæ¨¡æ€å¤§æ¨¡å‹ä¸­è§†è§‰Tokenå‹ç¼©æ–¹æ³•çš„æ€§èƒ½ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰Tokenå‹ç¼©` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `è¯„ä¼°æ¡†æ¶` `åŸºå‡†æµ‹è¯•` `æ•°æ®è¿‡æ»¤` `å›¾åƒé™é‡‡æ ·` `æ€§èƒ½è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰Tokenå‹ç¼©æ–¹æ³•è¯„ä¼°ä¾èµ–çš„åŸºå‡†æµ‹è¯•ï¼Œä¸å‹ç¼©ä»»åŠ¡æœ¬èº«å­˜åœ¨ä¸åŒ¹é…ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœä¸å‡†ç¡®ã€‚
2. è®ºæ–‡æå‡ºVTC-Benchè¯„ä¼°æ¡†æ¶ï¼Œé€šè¿‡æ•°æ®è¿‡æ»¤æœºåˆ¶é™ä½åŸºå‡†æµ‹è¯•ä¸­çš„å™ªå£°ï¼Œä»è€Œå®ç°æ›´å…¬å¹³çš„è¯„ä¼°ã€‚
3. å®éªŒè¡¨æ˜ï¼Œç®€å•çš„å›¾åƒé™é‡‡æ ·åœ¨ç°æœ‰åŸºå‡†ä¸Šè¡¨ç°ä¼˜äºè®¸å¤šå…ˆè¿›çš„å‹ç¼©æ–¹æ³•ï¼Œçªæ˜¾äº†åŸºå‡†æµ‹è¯•çš„å±€é™æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸ºäº†åŠ é€Ÿå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰çš„æ¨ç†ï¼Œç›®å‰çš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨è§†è§‰tokenå‹ç¼©ä¸Šã€‚é€šå¸¸ï¼Œè¿™äº›æ–¹æ³•çš„æœ‰æ•ˆæ€§æ˜¯é€šè¿‡æµ‹é‡åœ¨æ—¢å®šåŸºå‡†ä¸Šçš„ç²¾åº¦ä¸‹é™æ¥è¯„ä¼°çš„ï¼Œå³æ¯”è¾ƒå‹ç¼©å‰åæ¨¡å‹çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œè¿™äº›åŸºå‡†æœ€åˆæ—¨åœ¨è¯„ä¼°MLLMçš„æ„ŸçŸ¥å’Œæ¨ç†èƒ½åŠ›ï¼Œè€Œä¸æ˜¯è¯„ä¼°å‹ç¼©æŠ€æœ¯ã€‚å› æ­¤ï¼Œç›´æ¥å°†å®ƒä»¬åº”ç”¨äºè§†è§‰tokenå‹ç¼©ä¼šå¼•å…¥ä»»åŠ¡ä¸åŒ¹é…çš„é—®é¢˜ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œæˆ‘ä»¬çš„ç ”ç©¶è¡¨æ˜ï¼Œç®€å•çš„å›¾åƒé™é‡‡æ ·åœ¨å¤šä¸ªå¹¿æ³›ä½¿ç”¨çš„åŸºå‡†æµ‹è¯•ä¸­å§‹ç»ˆä¼˜äºè®¸å¤šå…ˆè¿›çš„å‹ç¼©æ–¹æ³•ã€‚é€šè¿‡å¤§é‡çš„å®éªŒï¼Œæˆ‘ä»¬å¾—å‡ºä»¥ä¸‹è§‚å¯Ÿç»“æœï¼šï¼ˆiï¼‰å½“å‰çš„åŸºå‡†æµ‹è¯•å¯¹äºè§†è§‰tokenå‹ç¼©ä»»åŠ¡æ¥è¯´æ˜¯å˜ˆæ‚çš„ã€‚ï¼ˆiiï¼‰é™é‡‡æ ·å¯ä»¥ä½œä¸ºæ•°æ®è¿‡æ»¤å™¨æ¥è¯„ä¼°è§†è§‰tokenå‹ç¼©ä»»åŠ¡ä¸­æ ·æœ¬çš„éš¾åº¦ã€‚åŸºäºè¿™äº›å‘ç°ï¼Œæˆ‘ä»¬å¼•å…¥äº†VTC-Benchï¼Œè¿™æ˜¯ä¸€ä¸ªè¯„ä¼°æ¡†æ¶ï¼Œå®ƒç»“åˆäº†æ•°æ®è¿‡æ»¤æœºåˆ¶æ¥æ¶ˆé™¤ç°æœ‰åŸºå‡†æµ‹è¯•ä¸­çš„å™ªå£°ï¼Œä»è€Œèƒ½å¤Ÿæ›´å…¬å¹³ã€æ›´å‡†ç¡®åœ°è¯„ä¼°è§†è§‰tokenå‹ç¼©æ–¹æ³•ã€‚æ‰€æœ‰æ•°æ®å’Œä»£ç å‡å¯åœ¨https://github.com/Chenfei-Liao/VTC-Benchè·å–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰è§†è§‰Tokenå‹ç¼©æ–¹æ³•çš„è¯„ä¼°ä¸»è¦ä¾èµ–äºç°æœ‰çš„MLLMåŸºå‡†æµ‹è¯•ã€‚è¿™äº›åŸºå‡†æµ‹è¯•æœ€åˆè®¾è®¡ç”¨äºè¯„ä¼°MLLMçš„æ„ŸçŸ¥å’Œæ¨ç†èƒ½åŠ›ï¼Œè€Œéä¸“é—¨ç”¨äºè¯„ä¼°å‹ç¼©ç®—æ³•ã€‚å› æ­¤ï¼Œç›´æ¥ä½¿ç”¨è¿™äº›åŸºå‡†æµ‹è¯•æ¥è¯„ä¼°è§†è§‰Tokenå‹ç¼©æ–¹æ³•ä¼šå¯¼è‡´ä»»åŠ¡ä¸åŒ¹é…ï¼Œä½¿å¾—è¯„ä¼°ç»“æœä¸å¤Ÿå‡†ç¡®ï¼Œæ— æ³•çœŸå®åæ˜ å‹ç¼©ç®—æ³•çš„æ€§èƒ½ã€‚ç°æœ‰æ–¹æ³•çš„ç—›ç‚¹åœ¨äºæ— æ³•åŒºåˆ†å‹ç¼©ç®—æ³•å¸¦æ¥çš„æ€§èƒ½ä¸‹é™å’ŒåŸºå‡†æµ‹è¯•æœ¬èº«å›ºæœ‰çš„å™ªå£°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼•å…¥æ•°æ®è¿‡æ»¤æœºåˆ¶æ¥é™ä½ç°æœ‰åŸºå‡†æµ‹è¯•ä¸­çš„å™ªå£°ã€‚å…·ä½“æ¥è¯´ï¼Œè®ºæ–‡å‘ç°ç®€å•çš„å›¾åƒé™é‡‡æ ·å¯ä»¥ä½œä¸ºä¸€ç§æœ‰æ•ˆçš„æ•°æ®è¿‡æ»¤å™¨ï¼Œèƒ½å¤ŸåŒºåˆ†ä¸åŒæ ·æœ¬çš„éš¾åº¦ã€‚é€šè¿‡åˆ†æé™é‡‡æ ·åçš„æ€§èƒ½å˜åŒ–ï¼Œå¯ä»¥è¯†åˆ«å‡ºå¯¹å‹ç¼©ç®—æ³•è¯„ä¼°å…·æœ‰å¹²æ‰°æ€§çš„å™ªå£°æ ·æœ¬ï¼Œä»è€Œæé«˜è¯„ä¼°çš„å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVTC-Benchè¯„ä¼°æ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) æ•°æ®é›†é€‰æ‹©ï¼šé€‰æ‹©ç°æœ‰çš„MLLMåŸºå‡†æµ‹è¯•æ•°æ®é›†ã€‚2) æ•°æ®è¿‡æ»¤ï¼šä½¿ç”¨å›¾åƒé™é‡‡æ ·ä½œä¸ºæ•°æ®è¿‡æ»¤å™¨ï¼Œå¯¹æ•°æ®é›†ä¸­çš„å›¾åƒè¿›è¡Œå¤„ç†ã€‚3) æ€§èƒ½è¯„ä¼°ï¼šåœ¨åŸå§‹æ•°æ®é›†å’Œè¿‡æ»¤åçš„æ•°æ®é›†ä¸Šï¼Œåˆ†åˆ«è¯„ä¼°ä¸åŒçš„è§†è§‰Tokenå‹ç¼©æ–¹æ³•çš„æ€§èƒ½ã€‚4) ç»“æœåˆ†æï¼šæ¯”è¾ƒä¸åŒå‹ç¼©æ–¹æ³•åœ¨ä¸åŒæ•°æ®é›†ä¸Šçš„æ€§èƒ½è¡¨ç°ï¼Œåˆ†ææ•°æ®è¿‡æ»¤å¯¹è¯„ä¼°ç»“æœçš„å½±å“ã€‚

**å…³é”®åˆ›æ–°**ï¼šVTC-Benchçš„å…³é”®åˆ›æ–°åœ¨äºå¼•å…¥äº†æ•°æ®è¿‡æ»¤æœºåˆ¶ï¼Œé€šè¿‡å›¾åƒé™é‡‡æ ·æ¥é™ä½ç°æœ‰åŸºå‡†æµ‹è¯•ä¸­çš„å™ªå£°ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæ›´å‡†ç¡®åœ°è¯„ä¼°è§†è§‰Tokenå‹ç¼©æ–¹æ³•çš„æ€§èƒ½ï¼Œé¿å…äº†ä»»åŠ¡ä¸åŒ¹é…å¸¦æ¥çš„è¯„ä¼°åå·®ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒVTC-Benchèƒ½å¤Ÿæä¾›æ›´å¯é ã€æ›´å…¬å¹³çš„è¯„ä¼°ç»“æœã€‚

**å…³é”®è®¾è®¡**ï¼šVTC-Benchçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) é™é‡‡æ ·ç­–ç•¥çš„é€‰æ‹©ï¼šè®ºæ–‡å¯èƒ½æ¢ç´¢äº†ä¸åŒçš„é™é‡‡æ ·æ–¹æ³•å’Œå‚æ•°è®¾ç½®ï¼Œä»¥æ‰¾åˆ°æœ€ä½³çš„æ•°æ®è¿‡æ»¤æ•ˆæœã€‚2) æ€§èƒ½è¯„ä¼°æŒ‡æ ‡çš„é€‰æ‹©ï¼šè®ºæ–‡å¯èƒ½ä½¿ç”¨äº†å¤šç§æ€§èƒ½è¯„ä¼°æŒ‡æ ‡ï¼Œå¦‚ç²¾åº¦ã€å¬å›ç‡ç­‰ï¼Œæ¥å…¨é¢è¯„ä¼°å‹ç¼©æ–¹æ³•çš„æ€§èƒ½ã€‚3) æ•°æ®é›†åˆ’åˆ†ç­–ç•¥ï¼šè®ºæ–‡å¯èƒ½å°†æ•°æ®é›†åˆ’åˆ†ä¸ºä¸åŒçš„éš¾åº¦çº§åˆ«ï¼Œä»¥ä¾¿æ›´ç»†è‡´åœ°åˆ†æå‹ç¼©æ–¹æ³•åœ¨ä¸åŒéš¾åº¦æ ·æœ¬ä¸Šçš„è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œç®€å•çš„å›¾åƒé™é‡‡æ ·åœ¨å¤šä¸ªå¹¿æ³›ä½¿ç”¨çš„åŸºå‡†æµ‹è¯•ä¸­å§‹ç»ˆä¼˜äºè®¸å¤šå…ˆè¿›çš„å‹ç¼©æ–¹æ³•ï¼Œè¿™çªæ˜¾äº†ç°æœ‰åŸºå‡†æµ‹è¯•çš„å±€é™æ€§ã€‚VTC-Benché€šè¿‡æ•°æ®è¿‡æ»¤æœºåˆ¶ï¼Œèƒ½å¤Ÿæ›´å‡†ç¡®åœ°è¯„ä¼°è§†è§‰Tokenå‹ç¼©æ–¹æ³•çš„æ€§èƒ½ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›æ›´å¯é çš„è¯„ä¼°å¹³å°ã€‚å…·ä½“çš„æ€§èƒ½æå‡æ•°æ®æœªçŸ¥ï¼Œä½†è®ºæ–‡å¼ºè°ƒäº†è¯„ä¼°æ¡†æ¶çš„æ”¹è¿›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

VTC-Benchå¯ç”¨äºè¯„ä¼°å’Œæ¯”è¾ƒä¸åŒçš„è§†è§‰Tokenå‹ç¼©æ–¹æ³•ï¼Œå¸®åŠ©ç ”ç©¶äººå‘˜å’Œå·¥ç¨‹å¸ˆé€‰æ‹©æœ€é€‚åˆç‰¹å®šåº”ç”¨åœºæ™¯çš„å‹ç¼©ç®—æ³•ã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿæ¨åŠ¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨èµ„æºå—é™è®¾å¤‡ä¸Šçš„éƒ¨ç½²ï¼Œä¾‹å¦‚ç§»åŠ¨è®¾å¤‡å’ŒåµŒå…¥å¼ç³»ç»Ÿï¼Œä»è€Œæ‰©å±•MLLMçš„åº”ç”¨èŒƒå›´ã€‚æ­¤å¤–ï¼ŒVTC-Benchè¿˜å¯ä»¥ä¿ƒè¿›è§†è§‰Tokenå‹ç¼©ç®—æ³•çš„è¿›ä¸€æ­¥ç ”ç©¶å’Œå‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent endeavors to accelerate inference in Multimodal Large Language Models (MLLMs) have primarily focused on visual token compression. The effectiveness of these methods is typically assessed by measuring the accuracy drop on established benchmarks, comparing model performance before and after compression. However, these benchmarks are originally designed to assess the perception and reasoning capabilities of MLLMs, rather than to evaluate compression techniques. As a result, directly applying them to visual token compression introduces a task mismatch. Strikingly, our investigation reveals that simple image downsampling consistently outperforms many advanced compression methods across multiple widely used benchmarks. Through extensive experiments, we make the following observations: (i) Current benchmarks are noisy for the visual token compression task. (ii) Down-sampling is able to serve as a data filter to evaluate the difficulty of samples in the visual token compression task. Motivated by these findings, we introduce VTC-Bench, an evaluation framework that incorporates a data filtering mechanism to denoise existing benchmarks, thereby enabling fairer and more accurate assessment of visual token compression methods. All data and code are available at https://github.com/Chenfei-Liao/VTC-Bench.

