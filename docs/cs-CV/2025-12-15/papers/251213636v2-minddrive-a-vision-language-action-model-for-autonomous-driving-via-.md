---
layout: default
title: MindDrive: A Vision-Language-Action Model for Autonomous Driving via Online Reinforcement Learning
---

# MindDrive: A Vision-Language-Action Model for Autonomous Driving via Online Reinforcement Learning

**arXiv**: [2512.13636v2](https://arxiv.org/abs/2512.13636) | [PDF](https://arxiv.org/pdf/2512.13636.pdf)

**ä½œè€…**: Haoyu Fu, Diankun Zhang, Zongchuang Zhao, Jianfeng Cui, Hongwei Xie, Bing Wang, Guang Chen, Dingkang Liang, Xiang Bai

**åˆ†ç±»**: cs.CV, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-12-15 (æ›´æ–°: 2025-12-16)

**å¤‡æ³¨**: 16 pages, 12 figures, 6 tables; Project Page: https://xiaomi-mlab.github.io/MindDrive/

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**MindDriveï¼šæå‡ºåŸºäºŽåœ¨çº¿å¼ºåŒ–å­¦ä¹ çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹ï¼Œç”¨äºŽè‡ªåŠ¨é©¾é©¶ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `è‡ªåŠ¨é©¾é©¶` `è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹` `åœ¨çº¿å¼ºåŒ–å­¦ä¹ ` `å¤§è¯­è¨€æ¨¡åž‹` `æ¨¡ä»¿å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰VLAè‡ªåŠ¨é©¾é©¶æ–¹æ³•ä¾èµ–æ¨¡ä»¿å­¦ä¹ ï¼Œå­˜åœ¨åˆ†å¸ƒåç§»å’Œå› æžœæ··æ·†é—®é¢˜ï¼Œéš¾ä»¥é€‚åº”å¤æ‚åœºæ™¯ã€‚
2. MindDriveé€šè¿‡åœ¨çº¿å¼ºåŒ–å­¦ä¹ ï¼Œåˆ©ç”¨LLMè¿›è¡Œåœºæ™¯æŽ¨ç†å’Œå†³ç­–ï¼Œå¹¶åŠ¨æ€æ˜ å°„åˆ°å¯è¡Œè½¨è¿¹ï¼Œå®žçŽ°é«˜æ•ˆæŽ¢ç´¢ã€‚
3. MindDriveåœ¨Bench2DriveåŸºå‡†æµ‹è¯•ä¸Šå–å¾—äº†æ˜¾è‘—æˆæžœï¼Œé©¾é©¶è¯„åˆ†è¾¾åˆ°78.04ï¼ŒæˆåŠŸçŽ‡è¾¾åˆ°55.09%ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å½“å‰è‡ªåŠ¨é©¾é©¶ä¸­çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰èŒƒå¼ä¸»è¦ä¾èµ–äºŽæ¨¡ä»¿å­¦ä¹ ï¼ˆILï¼‰ï¼Œè¿™å¸¦æ¥äº†è¯¸å¦‚åˆ†å¸ƒåç§»å’Œå› æžœæ··æ·†ç­‰å†…åœ¨æŒ‘æˆ˜ã€‚åœ¨çº¿å¼ºåŒ–å­¦ä¹ é€šè¿‡è¯•é”™å­¦ä¹ ä¸ºè§£å†³è¿™äº›é—®é¢˜æä¾›äº†ä¸€æ¡æœ‰å¸Œæœ›çš„é€”å¾„ã€‚ç„¶è€Œï¼Œå°†åœ¨çº¿å¼ºåŒ–å­¦ä¹ åº”ç”¨äºŽè‡ªåŠ¨é©¾é©¶ä¸­çš„VLAæ¨¡åž‹å—åˆ°è¿žç»­åŠ¨ä½œç©ºé—´ä¸­ä½Žæ•ˆæŽ¢ç´¢çš„é˜»ç¢ã€‚ä¸ºäº†å…‹æœè¿™ä¸€é™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºäº†MindDriveï¼Œä¸€ä¸ªVLAæ¡†æž¶ï¼ŒåŒ…å«ä¸€ä¸ªå…·æœ‰ä¸¤ç»„ä¸åŒLoRAå‚æ•°çš„å¤§è¯­è¨€æ¨¡åž‹ï¼ˆLLMï¼‰ã€‚å…¶ä¸­ä¸€ä¸ªLLMä½œä¸ºå†³ç­–ä¸“å®¶ï¼Œç”¨äºŽåœºæ™¯æŽ¨ç†å’Œé©¾é©¶å†³ç­–ï¼Œè€Œå¦ä¸€ä¸ªä½œä¸ºåŠ¨ä½œä¸“å®¶ï¼ŒåŠ¨æ€åœ°å°†è¯­è¨€å†³ç­–æ˜ å°„åˆ°å¯è¡Œçš„è½¨è¿¹ã€‚é€šè¿‡å°†è½¨è¿¹çº§åˆ«çš„å¥–åŠ±åé¦ˆåˆ°æŽ¨ç†ç©ºé—´ï¼ŒMindDriveèƒ½å¤Ÿåœ¨æœ‰é™çš„ç¦»æ•£è¯­è¨€é©¾é©¶å†³ç­–é›†åˆä¸Šè¿›è¡Œè¯•é”™å­¦ä¹ ï¼Œè€Œä¸æ˜¯ç›´æŽ¥åœ¨è¿žç»­åŠ¨ä½œç©ºé—´ä¸­æ“ä½œã€‚è¿™ç§æ–¹æ³•æœ‰æ•ˆåœ°å¹³è¡¡äº†å¤æ‚åœºæ™¯ä¸­çš„æœ€ä¼˜å†³ç­–ã€ç±»äººé©¾é©¶è¡Œä¸ºä»¥åŠåœ¨çº¿å¼ºåŒ–å­¦ä¹ ä¸­çš„é«˜æ•ˆæŽ¢ç´¢ã€‚ä½¿ç”¨è½»é‡çº§çš„Qwen-0.5B LLMï¼ŒMindDriveåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„Bench2DriveåŸºå‡†æµ‹è¯•ä¸Šå®žçŽ°äº†78.04çš„é©¾é©¶è¯„åˆ†ï¼ˆDSï¼‰å’Œ55.09%çš„æˆåŠŸçŽ‡ï¼ˆSRï¼‰ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªè¯æ˜Žåœ¨çº¿å¼ºåŒ–å­¦ä¹ å¯¹è‡ªåŠ¨é©¾é©¶ä¸­VLAæ¨¡åž‹æœ‰æ•ˆæ€§çš„å·¥ä½œã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è‡ªåŠ¨é©¾é©¶ä¸­è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹ï¼ˆVLAï¼‰åœ¨å¤æ‚åœºæ™¯ä¸‹çš„å†³ç­–é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–æ¨¡ä»¿å­¦ä¹ ï¼Œå­˜åœ¨åˆ†å¸ƒåç§»å’Œå› æžœæ··æ·†çš„å›ºæœ‰ç¼ºé™·ï¼Œéš¾ä»¥æ³›åŒ–åˆ°æœªè§è¿‡çš„æƒ…å†µã€‚æ­¤å¤–ï¼Œç›´æŽ¥åœ¨è¿žç»­åŠ¨ä½œç©ºé—´ä¸­åº”ç”¨åœ¨çº¿å¼ºåŒ–å­¦ä¹ è¿›è¡ŒæŽ¢ç´¢æ•ˆçŽ‡ä½Žä¸‹ï¼Œé˜»ç¢äº†VLAæ¨¡åž‹çš„è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†è¿žç»­åŠ¨ä½œç©ºé—´ä¸­çš„æŽ¢ç´¢é—®é¢˜è½¬åŒ–ä¸ºç¦»æ•£çš„è¯­è¨€å†³ç­–ç©ºé—´ä¸­çš„æŽ¢ç´¢é—®é¢˜ã€‚é€šè¿‡å¤§è¯­è¨€æ¨¡åž‹ï¼ˆLLMï¼‰è¿›è¡Œåœºæ™¯ç†è§£å’Œå†³ç­–ï¼Œå¹¶å°†å†³ç­–æ˜ å°„åˆ°å…·ä½“çš„è½¨è¿¹åŠ¨ä½œã€‚åˆ©ç”¨åœ¨çº¿å¼ºåŒ–å­¦ä¹ ï¼Œæ ¹æ®è½¨è¿¹çº§åˆ«çš„å¥–åŠ±ä¿¡å·ï¼Œä¼˜åŒ–LLMçš„å†³ç­–èƒ½åŠ›ï¼Œä»Žè€Œå®žçŽ°é«˜æ•ˆçš„è¯•é”™å­¦ä¹ ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šMindDriveæ¡†æž¶åŒ…å«ä¸€ä¸ªLLMï¼Œå¹¶ä½¿ç”¨ä¸¤ç»„LoRAå‚æ•°åˆ†åˆ«ä½œä¸ºå†³ç­–ä¸“å®¶å’ŒåŠ¨ä½œä¸“å®¶ã€‚å†³ç­–ä¸“å®¶è´Ÿè´£æ ¹æ®è§†è§‰è¾“å…¥å’Œè¯­è¨€æŒ‡ä»¤è¿›è¡Œåœºæ™¯æŽ¨ç†å’Œé©¾é©¶å†³ç­–ï¼Œè¾“å‡ºç¦»æ•£çš„è¯­è¨€æŒ‡ä»¤ã€‚åŠ¨ä½œä¸“å®¶è´Ÿè´£å°†è¯­è¨€æŒ‡ä»¤è½¬åŒ–ä¸ºå…·ä½“çš„è½¦è¾†è½¨è¿¹ã€‚åœ¨çº¿å¼ºåŒ–å­¦ä¹ æ¨¡å—æ ¹æ®çŽ¯å¢ƒåé¦ˆçš„å¥–åŠ±ä¿¡å·ï¼Œæ›´æ–°å†³ç­–ä¸“å®¶çš„å‚æ•°ï¼Œä»Žè€Œä¼˜åŒ–é©¾é©¶ç­–ç•¥ã€‚æ•´ä½“æµç¨‹ä¸ºï¼šè§†è§‰è¾“å…¥ -> å†³ç­–ä¸“å®¶ï¼ˆLLMï¼‰-> è¯­è¨€æŒ‡ä»¤ -> åŠ¨ä½œä¸“å®¶ï¼ˆLLMï¼‰-> è½¦è¾†æŽ§åˆ¶ -> çŽ¯å¢ƒåé¦ˆ -> å¼ºåŒ–å­¦ä¹ æ›´æ–°å†³ç­–ä¸“å®¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºŽå°†è¿žç»­åŠ¨ä½œç©ºé—´ä¸­çš„å¼ºåŒ–å­¦ä¹ é—®é¢˜è½¬åŒ–ä¸ºç¦»æ•£è¯­è¨€å†³ç­–ç©ºé—´ä¸­çš„å¼ºåŒ–å­¦ä¹ é—®é¢˜ã€‚é€šè¿‡LLMçš„è¯­è¨€ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ï¼Œå°†å¤æ‚çš„é©¾é©¶ä»»åŠ¡åˆ†è§£ä¸ºä¸€ç³»åˆ—å¯è§£é‡Šçš„è¯­è¨€æŒ‡ä»¤ï¼Œä»Žè€Œé™ä½Žäº†å¼ºåŒ–å­¦ä¹ çš„éš¾åº¦ï¼Œæé«˜äº†æŽ¢ç´¢æ•ˆçŽ‡ã€‚æ­¤å¤–ï¼Œä½¿ç”¨ä¸¤ç»„LoRAå‚æ•°åˆ†åˆ«ä½œä¸ºå†³ç­–ä¸“å®¶å’ŒåŠ¨ä½œä¸“å®¶ï¼Œå®žçŽ°äº†å†³ç­–å’ŒåŠ¨ä½œçš„è§£è€¦ï¼Œæé«˜äº†æ¨¡åž‹çš„çµæ´»æ€§å’Œå¯æ‰©å±•æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä½¿ç”¨Qwen-0.5Bä½œä¸ºåŸºç¡€LLMã€‚ä½¿ç”¨LoRAï¼ˆLow-Rank Adaptationï¼‰æŠ€æœ¯ï¼Œä»…è®­ç»ƒå°‘é‡å‚æ•°ï¼Œé™ä½Žäº†è®¡ç®—æˆæœ¬ã€‚è½¨è¿¹çº§åˆ«çš„å¥–åŠ±å‡½æ•°è®¾è®¡è‡³å…³é‡è¦ï¼Œéœ€è¦ç»¼åˆè€ƒè™‘å®‰å…¨æ€§ã€èˆ’é€‚æ€§å’Œæ•ˆçŽ‡ã€‚å…·ä½“å¥–åŠ±å‡½æ•°çš„è®¾è®¡ç»†èŠ‚æœªçŸ¥ï¼Œä½†åº”åŒ…å«ç¢°æ’žæƒ©ç½šã€åç¦»é“è·¯æƒ©ç½šã€é€Ÿåº¦å¥–åŠ±ç­‰å› ç´ ã€‚è¯­è¨€æŒ‡ä»¤é›†çš„è®¾è®¡ä¹Ÿéœ€è¦ä»”ç»†è€ƒè™‘ï¼Œéœ€è¦è¦†ç›–å¸¸è§çš„é©¾é©¶è¡Œä¸ºï¼Œå¹¶å…·æœ‰ä¸€å®šçš„æ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

MindDriveåœ¨Bench2DriveåŸºå‡†æµ‹è¯•ä¸Šå–å¾—äº†æ˜¾è‘—çš„æˆæžœï¼Œé©¾é©¶è¯„åˆ†ï¼ˆDSï¼‰è¾¾åˆ°78.04ï¼ŒæˆåŠŸçŽ‡ï¼ˆSRï¼‰è¾¾åˆ°55.09%ã€‚è¿™äº›ç»“æžœè¡¨æ˜Žï¼ŒåŸºäºŽåœ¨çº¿å¼ºåŒ–å­¦ä¹ çš„VLAæ¨¡åž‹åœ¨è‡ªåŠ¨é©¾é©¶ä»»åŠ¡ä¸­å…·æœ‰å·¨å¤§çš„æ½œåŠ›ã€‚ä¸Žä¼ ç»Ÿçš„æ¨¡ä»¿å­¦ä¹ æ–¹æ³•ç›¸æ¯”ï¼ŒMindDriveèƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”æœªçŸ¥çš„çŽ¯å¢ƒå’Œåœºæ™¯ï¼Œæé«˜äº†è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„é²æ£’æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽå„ç§è‡ªåŠ¨é©¾é©¶åœºæ™¯ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚ã€åŠ¨æ€çš„åŸŽå¸‚çŽ¯å¢ƒä¸­ã€‚é€šè¿‡åœ¨çº¿å¼ºåŒ–å­¦ä¹ ä¸æ–­ä¼˜åŒ–é©¾é©¶ç­–ç•¥ï¼Œå¯ä»¥æé«˜è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„å®‰å…¨æ€§ã€å¯é æ€§å’Œé€‚åº”æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–æœºå™¨äººæŽ§åˆ¶é¢†åŸŸï¼Œä¾‹å¦‚æ— äººæœºã€æœåŠ¡æœºå™¨äººç­‰ï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Current Vision-Language-Action (VLA) paradigms in autonomous driving primarily rely on Imitation Learning (IL), which introduces inherent challenges such as distribution shift and causal confusion. Online Reinforcement Learning offers a promising pathway to address these issues through trial-and-error learning. However, applying online reinforcement learning to VLA models in autonomous driving is hindered by inefficient exploration in continuous action spaces. To overcome this limitation, we propose MindDrive, a VLA framework comprising a large language model (LLM) with two distinct sets of LoRA parameters. The one LLM serves as a Decision Expert for scenario reasoning and driving decision-making, while the other acts as an Action Expert that dynamically maps linguistic decisions into feasible trajectories. By feeding trajectory-level rewards back into the reasoning space, MindDrive enables trial-and-error learning over a finite set of discrete linguistic driving decisions, instead of operating directly in a continuous action space. This approach effectively balances optimal decision-making in complex scenarios, human-like driving behavior, and efficient exploration in online reinforcement learning. Using the lightweight Qwen-0.5B LLM, MindDrive achieves Driving Score (DS) of 78.04 and Success Rate (SR) of 55.09% on the challenging Bench2Drive benchmark. To the best of our knowledge, this is the first work to demonstrate the effectiveness of online reinforcement learning for the VLA model in autonomous driving.

