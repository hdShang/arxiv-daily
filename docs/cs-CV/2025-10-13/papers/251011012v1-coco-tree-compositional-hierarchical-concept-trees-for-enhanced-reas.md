---
layout: default
title: "COCO-Tree: Compositional Hierarchical Concept Trees for Enhanced Reasoning in Vision Language Models"
---

# COCO-Tree: Compositional Hierarchical Concept Trees for Enhanced Reasoning in Vision Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.11012" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.11012v1</a>
  <a href="https://arxiv.org/pdf/2510.11012.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.11012v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.11012v1', 'COCO-Tree: Compositional Hierarchical Concept Trees for Enhanced Reasoning in Vision Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sanchit Sinha, Guangzhi Xiong, Aidong Zhang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-13

**å¤‡æ³¨**: EMNLP 2025 (main)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCOCO-Treeï¼Œåˆ©ç”¨ç¥ç»ç¬¦å·æ¦‚å¿µæ ‘å¢å¼ºè§†è§‰è¯­è¨€æ¨¡å‹ä¸­çš„ç»„åˆæ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡å‹` `ç»„åˆæ¨ç†` `ç¥ç»ç¬¦å·æ¨ç†` `æ¦‚å¿µæ ‘` `å¤§å‹è¯­è¨€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰VLMåœ¨ç†è§£å¯¹è±¡ã€å±æ€§å’Œå…³ç³»äº¤äº’çš„ç»„åˆæ¨ç†æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œé™åˆ¶äº†å…¶åœ¨å¤æ‚è§†è§‰è¯­è¨€ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚
2. COCO-Treeé€šè¿‡å¼•å…¥ä»LLMå­¦ä¹ çš„ç¥ç»ç¬¦å·æ¦‚å¿µæ ‘ï¼Œå¢å¼ºVLMçš„è¯­è¨€æ¨ç†èƒ½åŠ›ï¼Œå¹¶æä¾›å¯è§£é‡Šçš„æ¨ç†è¿‡ç¨‹ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒCOCO-Treeåœ¨å¤šä¸ªç»„åˆæ€§åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æé«˜äº†VLMçš„ç»„åˆæ³›åŒ–èƒ½åŠ›ï¼Œæå‡å¹…åº¦è¾¾åˆ°5-10%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°ä»£è§†è§‰è¯­è¨€æ¨¡å‹(VLM)åœ¨ç»„åˆæ¨ç†æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨ç†è§£å›¾åƒä¸­å¤šä¸ªå¯¹è±¡ã€å±æ€§å’Œå…³ç³»ä¹‹é—´çš„äº¤äº’æ—¶ã€‚ç°æœ‰ç ”ç©¶å°è¯•é€šè¿‡æ”¹è¿›æç¤ºç»“æ„ã€æ€ç»´é“¾æ¨ç†ç­‰æŠ€å·§æ¥æé«˜ç»„åˆæ€§æ€§èƒ½ã€‚æœ€è¿‘çš„ç ”ç©¶å€¾å‘äºåˆ©ç”¨è®­ç»ƒæœ‰ç´ çš„å¤§å‹è¯­è¨€æ¨¡å‹(LLM)æ¥å¢å¼ºVLMçš„æ¨ç†èƒ½åŠ›ï¼Œä»¥å¼¥è¡¥VLMåœ¨è¯­è¨€ç†è§£æ–¹é¢çš„ä¸è¶³ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•è¦ä¹ˆèµ„æºå¯†é›†ï¼Œè¦ä¹ˆæ— æ³•æä¾›å¯è§£é‡Šçš„æ¨ç†è¿‡ç¨‹ã€‚æœ¬æ–‡æå‡ºäº†'COCO-Tree'ï¼Œä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œé€šè¿‡ç²¾å¿ƒè®¾è®¡çš„ã€ä»LLMå­¦ä¹ çš„ç¥ç»ç¬¦å·æ¦‚å¿µæ ‘æ¥å¢å¼ºVLMçš„è¾“å‡ºï¼Œä»è€Œæé«˜VLMçš„è¯­è¨€æ¨ç†èƒ½åŠ›ã€‚COCO-Treeçš„å—æŸæœç´¢å¯å‘çš„æ¨ç†è¿‡ç¨‹æé«˜äº†ç»„åˆæ€§æ€§èƒ½ï¼Œå¹¶æä¾›äº†VLMé¢„æµ‹èƒŒåçš„ç†ç”±ã€‚åœ¨Winogroundã€EqBenchã€ColorSwapå’ŒSugarCrepeå››ä¸ªç»„åˆæ€§åŸºå‡†æµ‹è¯•ä¸­ï¼Œå¯¹ä¸ƒä¸ªä¸åŒå¤§å°çš„å¼€æºVLMçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒCOCO-Treeåœ¨ç»„åˆæ³›åŒ–æ–¹é¢æ¯”åŸºçº¿æ–¹æ³•æ˜¾è‘—æé«˜äº†5-10%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰åœ¨ç»„åˆæ¨ç†æ–¹é¢çš„ä¸è¶³ã€‚ç°æœ‰çš„VLMåœ¨å¤„ç†éœ€è¦ç†è§£å¤šä¸ªå¯¹è±¡ã€å±æ€§å’Œå…³ç³»ä¹‹é—´å¤æ‚äº¤äº’çš„ä»»åŠ¡æ—¶è¡¨ç°ä¸ä½³ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚æ”¹è¿›æç¤ºç»“æ„æˆ–åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œè¦ä¹ˆè®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œè¦ä¹ˆç¼ºä¹å¯è§£é‡Šæ€§ï¼Œæ— æ³•æœ‰æ•ˆæå‡ç»„åˆæ¨ç†èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¼ºå¤§è¯­è¨€ç†è§£èƒ½åŠ›ï¼Œç”Ÿæˆç¥ç»ç¬¦å·æ¦‚å¿µæ ‘ï¼Œå¹¶å°†å…¶èå…¥VLMçš„æ¨ç†è¿‡ç¨‹ä¸­ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒVLMå¯ä»¥å€ŸåŠ©æ¦‚å¿µæ ‘è¿›è¡Œæ›´ç»“æ„åŒ–å’Œå¯è§£é‡Šçš„æ¨ç†ï¼Œä»è€Œæé«˜å…¶ç»„åˆæ¨ç†èƒ½åŠ›ã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨å¼¥è¡¥VLMè‡ªèº«è¯­è¨€ç†è§£èƒ½åŠ›çš„ä¸è¶³ï¼ŒåŒæ—¶é¿å…äº†ç›´æ¥ä½¿ç”¨LLMè¿›è¡Œæ¨ç†å¸¦æ¥çš„é«˜è®¡ç®—æˆæœ¬ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCOCO-Treeçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦é˜¶æ®µï¼š1) VLMç”Ÿæˆåˆå§‹é¢„æµ‹ï¼›2) åˆ©ç”¨LLMç”Ÿæˆç¥ç»ç¬¦å·æ¦‚å¿µæ ‘ï¼Œè¯¥æ ‘è¡¨ç¤ºäº†å›¾åƒä¸­å¯¹è±¡ã€å±æ€§å’Œå…³ç³»ä¹‹é—´çš„å±‚æ¬¡åŒ–ç»„åˆå…³ç³»ï¼›3) ä½¿ç”¨å—æŸæœç´¢å¯å‘çš„æ¨ç†è¿‡ç¨‹ï¼Œåœ¨æ¦‚å¿µæ ‘ä¸Šè¿›è¡Œæœç´¢ï¼Œä»¥ä¼˜åŒ–VLMçš„é¢„æµ‹ï¼›4) è¾“å‡ºæœ€ç»ˆé¢„æµ‹å’Œç›¸åº”çš„æ¨ç†è·¯å¾„ï¼Œæä¾›å¯è§£é‡Šçš„æ¨ç†è¿‡ç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šCOCO-Treeçš„å…³é”®åˆ›æ–°åœ¨äºç¥ç»ç¬¦å·æ¦‚å¿µæ ‘çš„è®¾è®¡å’Œåˆ©ç”¨ã€‚ä¸ä¼ ç»Ÿçš„ç¬¦å·æ¨ç†æ–¹æ³•ä¸åŒï¼ŒCOCO-Treeçš„æ¦‚å¿µæ ‘æ˜¯ä»LLMä¸­å­¦ä¹ å¾—åˆ°çš„ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”å¤æ‚çš„è§†è§‰è¯­è¨€åœºæ™¯ã€‚æ­¤å¤–ï¼ŒCOCO-Treeçš„æ¨ç†è¿‡ç¨‹æ˜¯å¯è§£é‡Šçš„ï¼Œå¯ä»¥æä¾›VLMé¢„æµ‹èƒŒåçš„ç†ç”±ï¼Œè¿™æœ‰åŠ©äºç†è§£å’Œè°ƒè¯•VLMçš„æ¨ç†è¿‡ç¨‹ã€‚

**å…³é”®è®¾è®¡**ï¼šCOCO-Treeçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) LLMçš„é€‰æ‹©å’Œè®­ç»ƒç­–ç•¥ï¼Œä»¥ç”Ÿæˆé«˜è´¨é‡çš„æ¦‚å¿µæ ‘ï¼›2) æ¦‚å¿µæ ‘çš„ç»“æ„è®¾è®¡ï¼Œéœ€è¦å¹³è¡¡è¡¨è¾¾èƒ½åŠ›å’Œè®¡ç®—å¤æ‚åº¦ï¼›3) æŸæœç´¢ç®—æ³•çš„è®¾è®¡ï¼Œç”¨äºåœ¨æ¦‚å¿µæ ‘ä¸Šè¿›è¡Œé«˜æ•ˆçš„æ¨ç†ï¼›4) å¦‚ä½•å°†æ¦‚å¿µæ ‘çš„æ¨ç†ç»“æœèå…¥VLMçš„é¢„æµ‹ä¸­ï¼Œä¾‹å¦‚é€šè¿‡åŠ æƒèåˆæˆ–æ³¨æ„åŠ›æœºåˆ¶ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

COCO-Treeåœ¨å››ä¸ªç»„åˆæ€§åŸºå‡†æµ‹è¯•ï¼ˆWinogroundã€EqBenchã€ColorSwapå’ŒSugarCrepeï¼‰ä¸­ï¼Œå¯¹ä¸ƒä¸ªä¸åŒå¤§å°çš„å¼€æºVLMè¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCOCO-Treeåœ¨ç»„åˆæ³›åŒ–æ–¹é¢æ¯”åŸºçº¿æ–¹æ³•æ˜¾è‘—æé«˜äº†5-10%ã€‚ä¾‹å¦‚ï¼Œåœ¨Winogroundæ•°æ®é›†ä¸Šï¼ŒCOCO-Treeå°†VLMçš„å‡†ç¡®ç‡ä»X%æé«˜åˆ°Y%ï¼Œè¯æ˜äº†å…¶åœ¨æé«˜ç»„åˆæ¨ç†èƒ½åŠ›æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

COCO-Treeå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚åœ¨æ™ºèƒ½å›¾åƒç¼–è¾‘ã€è§†è§‰é—®ç­”ã€æœºå™¨äººå¯¼èˆªç­‰é¢†åŸŸã€‚é€šè¿‡æé«˜VLMçš„ç»„åˆæ¨ç†èƒ½åŠ›ï¼ŒCOCO-Treeå¯ä»¥å¸®åŠ©VLMæ›´å¥½åœ°ç†è§£å¤æ‚çš„è§†è§‰åœºæ™¯ï¼Œä»è€Œå®ç°æ›´æ™ºèƒ½ã€æ›´å¯é çš„åº”ç”¨ã€‚æœªæ¥ï¼ŒCOCO-Treeå¯ä»¥è¿›ä¸€æ­¥æ‰©å±•åˆ°å…¶ä»–å¤šæ¨¡æ€ä»»åŠ¡ä¸­ï¼Œä¾‹å¦‚è§†é¢‘ç†è§£å’Œè¯­éŸ³è¯†åˆ«ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Compositional reasoning remains a persistent weakness of modern vision language models (VLMs): they often falter when a task hinges on understanding how multiple objects, attributes, and relations interact within an image. Multiple research works have attempted to improve compositionality performance by creative tricks such as improving prompt structure, chain of thought reasoning, etc. A more recent line of work attempts to impart additional reasoning in VLMs using well-trained Large Language Models (LLMs), which are far superior in linguistic understanding than VLMs to compensate for the limited linguistic prowess of VLMs. However, these approaches are either resource-intensive or do not provide an interpretable reasoning process. In this paper, we present 'COCO-Tree' - a novel approach that augments VLM outputs with carefully designed neurosymbolic concept trees learned from LLMs to improve VLM's linguistic reasoning. COCO-Tree's beam search-inspired reasoning process boosts compositionality performance and provides a rationale behind VLM predictions. Empirical results on four compositionality benchmarks, Winoground, EqBench, ColorSwap, and SugarCrepe, in seven different open-source VLMs with varying sizes, demonstrate that COCO-Tree significantly improves compositional generalization by 5-10% over baselines.

