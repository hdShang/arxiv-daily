---
layout: default
title: Topological Alignment of Shared Vision-Language Embedding Space
---

# Topological Alignment of Shared Vision-Language Embedding Space

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.10889" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.10889v1</a>
  <a href="https://arxiv.org/pdf/2510.10889.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.10889v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.10889v1', 'Topological Alignment of Shared Vision-Language Embedding Space')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Junwon You, Dasol Kang, Jae-Hun Jung

**åˆ†ç±»**: cs.CV, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-10-13

**å¤‡æ³¨**: 24 pages, 5 figures, 19 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºToMCLIPï¼Œé€šè¿‡æ‹“æ‰‘å¯¹é½å¢å¼ºå¤šè¯­è¨€è§†è§‰-è¯­è¨€æ¨¡å‹çš„å…±äº«åµŒå…¥ç©ºé—´ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šè¯­è¨€å­¦ä¹ ` `è§†è§‰-è¯­è¨€æ¨¡å‹` `æ‹“æ‰‘å¯¹é½` `æŒä¹…åŒè°ƒ` `è¡¨ç¤ºå­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰VLMæ¨¡å‹åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸‹å­˜åœ¨åå·®ï¼Œå¿½ç•¥äº†å…±äº«åµŒå…¥ç©ºé—´çš„å…¨å±€å‡ ä½•ç»“æ„ã€‚
2. ToMCLIPé€šè¿‡æ‹“æ‰‘å¯¹é½ï¼Œåˆ©ç”¨æŒä¹…åŒè°ƒå’Œå›¾ç¨€ç–åŒ–ç­–ç•¥ï¼Œä¿æŒåµŒå…¥ç©ºé—´çš„æ‹“æ‰‘ç»“æ„ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒToMCLIPå¢å¼ºäº†å¤šè¯­è¨€è¡¨ç¤ºçš„ç»“æ„è¿è´¯æ€§ï¼Œæé«˜äº†é›¶æ ·æœ¬å‡†ç¡®ç‡å’Œå¤šè¯­è¨€æ£€ç´¢æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¯¹æ¯”è§†è§‰-è¯­è¨€æ¨¡å‹(VLMs)å·²å±•ç¤ºå‡ºå¼ºå¤§çš„é›¶æ ·æœ¬èƒ½åŠ›ã€‚ç„¶è€Œï¼Œç”±äºå¤šè¯­è¨€å¤šæ¨¡æ€æ•°æ®çš„é™åˆ¶ï¼Œå®ƒä»¬çš„è·¨æ¨¡æ€å¯¹é½ä»ç„¶åå‘äºè‹±è¯­ã€‚æœ€è¿‘çš„å¤šè¯­è¨€æ‰©å±•ç¼“è§£äº†è¿™ä¸€å·®è·ï¼Œä½†å¼ºåˆ¶æ‰§è¡Œå®ä¾‹çº§åˆ«çš„å¯¹é½ï¼Œè€Œå¿½ç•¥äº†å…±äº«åµŒå…¥ç©ºé—´çš„å…¨å±€å‡ ä½•ç»“æ„ã€‚æˆ‘ä»¬é€šè¿‡å¼•å…¥ToMCLIPï¼ˆç”¨äºå¤šè¯­è¨€CLIPçš„æ‹“æ‰‘å¯¹é½ï¼‰ï¼Œä¸€ä¸ªæ‹“æ‰‘æ„ŸçŸ¥æ¡†æ¶ï¼Œç”¨ä¿æŒæ‹“æ‰‘ç»“æ„çš„çº¦æŸæ¥å¯¹é½åµŒå…¥ç©ºé—´ï¼Œä»è€Œè§£å†³è¿™ä¸ªé—®é¢˜ã€‚æ‰€æå‡ºçš„æ–¹æ³•åº”ç”¨æŒä¹…åŒè°ƒæ¥å®šä¹‰æ‹“æ‰‘å¯¹é½æŸå¤±ï¼Œå¹¶ä½¿ç”¨å›¾ç¨€ç–åŒ–ç­–ç•¥ï¼Œä»¥ç†è®ºè¯¯å·®ç•Œé™æ¥è¿‘ä¼¼æŒä¹…æ€§å›¾ã€‚è¿™é¡¹å·¥ä½œéªŒè¯äº†æ‰€æå‡ºçš„æ–¹æ³•ï¼Œå±•ç¤ºäº†å¤šè¯­è¨€è¡¨ç¤ºçš„å¢å¼ºçš„ç»“æ„è¿è´¯æ€§ï¼ŒCIFAR-100ä¸Šæ›´é«˜çš„é›¶æ ·æœ¬å‡†ç¡®ç‡ï¼Œä»¥åŠxFlickr&COä¸Šæ›´å¼ºçš„å¤šè¯­è¨€æ£€ç´¢æ€§èƒ½ã€‚é™¤äº†VLMsï¼Œæ‰€æå‡ºçš„æ–¹æ³•ä¸ºå°†æ‹“æ‰‘å¯¹é½çº³å…¥è¡¨ç¤ºå­¦ä¹ æä¾›äº†ä¸€ç§é€šç”¨æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„å¤šè¯­è¨€è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨è·¨æ¨¡æ€å¯¹é½æ–¹é¢å­˜åœ¨åå·®ï¼Œä¸»è¦åŸå› æ˜¯è®­ç»ƒæ•°æ®é›†ä¸­è‹±è¯­æ•°æ®å ä¸»å¯¼åœ°ä½ã€‚å³ä½¿æœ€è¿‘çš„å¤šè¯­è¨€æ‰©å±•å°è¯•ç¼“è§£è¿™ä¸ªé—®é¢˜ï¼Œå®ƒä»¬é€šå¸¸ä¾§é‡äºå®ä¾‹çº§åˆ«çš„å¯¹é½ï¼Œè€Œå¿½ç•¥äº†å…±äº«åµŒå…¥ç©ºé—´çš„å…¨å±€å‡ ä½•ç»“æ„ã€‚è¿™ç§å¿½ç•¥å¯¼è‡´æ¨¡å‹æ— æ³•æ•æ‰ä¸åŒè¯­è¨€ä¹‹é—´æ›´æ·±å±‚æ¬¡çš„è¯­ä¹‰å…³ç³»ï¼Œé™åˆ¶äº†å…¶åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šToMCLIPçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ‹“æ‰‘å¯¹é½æ¥å¢å¼ºå¤šè¯­è¨€VLMçš„å…±äº«åµŒå…¥ç©ºé—´ã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒåˆ©ç”¨æ‹“æ‰‘æ•°æ®åˆ†æä¸­çš„æŒä¹…åŒè°ƒï¼ˆPersistent Homologyï¼‰æ¥æ•æ‰åµŒå…¥ç©ºé—´çš„å…¨å±€å‡ ä½•ç»“æ„ï¼Œå¹¶è®¾è®¡ä¸€ä¸ªæ‹“æ‰‘å¯¹é½æŸå¤±å‡½æ•°ï¼Œä»¥ç¡®ä¿ä¸åŒè¯­è¨€çš„åµŒå…¥ç©ºé—´åœ¨æ‹“æ‰‘ç»“æ„ä¸Šä¿æŒä¸€è‡´ã€‚è¿™æ ·åšçš„ç›®çš„æ˜¯ä½¿æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ åˆ°æ›´é²æ£’ã€æ›´å…·æ³›åŒ–èƒ½åŠ›çš„å¤šè¯­è¨€è¡¨ç¤ºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šToMCLIPçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ­¥éª¤ï¼š1) ä½¿ç”¨é¢„è®­ç»ƒçš„VLMï¼ˆå¦‚CLIPï¼‰æå–è§†è§‰å’Œæ–‡æœ¬ç‰¹å¾ï¼›2) æ„å»ºåµŒå…¥ç©ºé—´çš„å›¾è¡¨ç¤ºï¼Œå…¶ä¸­èŠ‚ç‚¹ä»£è¡¨æ•°æ®ç‚¹ï¼Œè¾¹ä»£è¡¨æ•°æ®ç‚¹ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼›3) åº”ç”¨æŒä¹…åŒè°ƒè®¡ç®—åµŒå…¥ç©ºé—´çš„æŒä¹…æ€§å›¾ï¼ˆPersistence Diagramï¼‰ï¼Œè¯¥å›¾æ•æ‰äº†åµŒå…¥ç©ºé—´çš„æ‹“æ‰‘ç‰¹å¾ï¼›4) å®šä¹‰æ‹“æ‰‘å¯¹é½æŸå¤±å‡½æ•°ï¼Œè¯¥æŸå¤±å‡½æ•°è¡¡é‡ä¸åŒè¯­è¨€çš„åµŒå…¥ç©ºé—´åœ¨æŒä¹…æ€§å›¾ä¸Šçš„å·®å¼‚ï¼›5) ä½¿ç”¨æ¢¯åº¦ä¸‹é™ä¼˜åŒ–æ¨¡å‹å‚æ•°ï¼Œä»¥æœ€å°åŒ–æ‹“æ‰‘å¯¹é½æŸå¤±ã€‚

**å…³é”®åˆ›æ–°**ï¼šToMCLIPçš„å…³é”®åˆ›æ–°åœ¨äºå°†æ‹“æ‰‘æ•°æ®åˆ†æå¼•å…¥åˆ°å¤šè¯­è¨€VLMçš„è®­ç»ƒä¸­ã€‚ä¸ä¼ ç»Ÿçš„å®ä¾‹çº§åˆ«å¯¹é½æ–¹æ³•ä¸åŒï¼ŒToMCLIPå…³æ³¨çš„æ˜¯åµŒå…¥ç©ºé—´çš„å…¨å±€å‡ ä½•ç»“æ„ï¼Œè¿™ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ åˆ°æ›´é²æ£’ã€æ›´å…·æ³›åŒ–èƒ½åŠ›çš„å¤šè¯­è¨€è¡¨ç¤ºã€‚æ­¤å¤–ï¼ŒToMCLIPè¿˜æå‡ºäº†ä¸€ç§åŸºäºå›¾ç¨€ç–åŒ–çš„æ–¹æ³•æ¥è¿‘ä¼¼è®¡ç®—æŒä¹…æ€§å›¾ï¼Œä»è€Œé™ä½äº†è®¡ç®—å¤æ‚åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šToMCLIPçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦æ„å»ºåµŒå…¥ç©ºé—´çš„å›¾è¡¨ç¤ºï¼›2) ä½¿ç”¨Ripserç®—æ³•è®¡ç®—æŒä¹…åŒè°ƒï¼›3) å®šä¹‰æ‹“æ‰‘å¯¹é½æŸå¤±å‡½æ•°ä¸ºä¸åŒè¯­è¨€çš„æŒä¹…æ€§å›¾ä¹‹é—´çš„Wassersteinè·ç¦»ï¼›4) ä½¿ç”¨å›¾ç¨€ç–åŒ–ç­–ç•¥æ¥é™ä½è®¡ç®—å¤æ‚åº¦ï¼Œå…·ä½“æ¥è¯´ï¼Œåªä¿ç•™å›¾ä¸­æƒé‡æœ€å¤§çš„Kæ¡è¾¹ã€‚æŸå¤±å‡½æ•°çš„æƒé‡éœ€è¦æ ¹æ®å…·ä½“æ•°æ®é›†è¿›è¡Œè°ƒæ•´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒToMCLIPåœ¨CIFAR-100æ•°æ®é›†ä¸Šå®ç°äº†æ›´é«˜çš„é›¶æ ·æœ¬å‡†ç¡®ç‡ï¼Œå¹¶åœ¨xFlickr&COæ•°æ®é›†ä¸Šå–å¾—äº†æ›´å¼ºçš„å¤šè¯­è¨€æ£€ç´¢æ€§èƒ½ã€‚è¿™äº›ç»“æœéªŒè¯äº†ToMCLIPèƒ½å¤Ÿæœ‰æ•ˆå¢å¼ºå¤šè¯­è¨€è¡¨ç¤ºçš„ç»“æ„è¿è´¯æ€§ï¼Œå¹¶æå‡å¤šè¯­è¨€VLMçš„æ€§èƒ½ã€‚å…·ä½“æå‡å¹…åº¦åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æ•°æ®ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ToMCLIPå¯åº”ç”¨äºå¤šè¯­è¨€å›¾åƒæ£€ç´¢ã€è·¨è¯­è¨€æ–‡æœ¬ç†è§£ã€å¤šè¯­è¨€å†…å®¹æ¨èç­‰é¢†åŸŸã€‚é€šè¿‡æå‡å¤šè¯­è¨€VLMçš„æ€§èƒ½ï¼Œå¯ä»¥ä¿ƒè¿›ä¸åŒè¯­è¨€æ–‡åŒ–ä¹‹é—´çš„äº¤æµä¸ç†è§£ï¼Œå¹¶ä¸ºå…¨çƒåŒ–åº”ç”¨æä¾›æ›´å¼ºå¤§çš„æŠ€æœ¯æ”¯æŒã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æ‰©å±•åˆ°æ›´å¤šæ¨¡æ€å’Œæ›´å¤šè¯­è¨€ï¼Œè¿›ä¸€æ­¥æå‡å¤šæ¨¡æ€å¤šè¯­è¨€æ¨¡å‹çš„æ€§èƒ½ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Contrastive Vision-Language Models (VLMs) have demonstrated strong zero-shot capabilities. However, their cross-modal alignment remains biased toward English due to limited multilingual multimodal data. Recent multilingual extensions have alleviated this gap but enforce instance-level alignment while neglecting the global geometry of the shared embedding space. We address this problem by introducing ToMCLIP (Topological Alignment for Multilingual CLIP), a topology-aware framework aligning embedding spaces with topology-preserving constraints. The proposed method applies persistent homology to define a topological alignment loss and approximates persistence diagram with theoretical error bounds using graph sparsification strategy. This work validates the proposed approach, showing enhanced structural coherence of multilingual representations, higher zero-shot accuracy on the CIFAR-100, and stronger multilingual retrieval performance on the xFlickr&CO. Beyond VLMs, the proposed approach provides a general method for incorporating topological alignment into representation learning.

