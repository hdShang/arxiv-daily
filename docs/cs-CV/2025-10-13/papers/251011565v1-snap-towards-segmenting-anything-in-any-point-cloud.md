---
layout: default
title: SNAP: Towards Segmenting Anything in Any Point Cloud
---

# SNAP: Towards Segmenting Anything in Any Point Cloud

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.11565" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.11565v1</a>
  <a href="https://arxiv.org/pdf/2510.11565.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.11565v1" onclick="toggleFavorite(this, '2510.11565v1', 'SNAP: Towards Segmenting Anything in Any Point Cloud')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Aniket Gupta, Hanhui Wang, Charles Saunders, Aruni RoyChowdhury, Hanumant Singh, Huaizu Jiang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-13

**å¤‡æ³¨**: Project Page, https://neu-vi.github.io/SNAP/

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://neu-vi.github.io/SNAP/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSNAPï¼Œä¸€ä¸ªé€šç”¨çš„ç‚¹äº‘äº¤äº’å¼åˆ†å‰²æ¨¡å‹ï¼Œæ”¯æŒè·¨åŸŸå’Œå¤šç§æç¤ºæ–¹å¼ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `ç‚¹äº‘åˆ†å‰²` `äº¤äº’å¼åˆ†å‰²` `è·¨é¢†åŸŸæ³›åŒ–` `é¢†åŸŸè‡ªé€‚åº”` `æ–‡æœ¬æç¤º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰äº¤äº’å¼3Dç‚¹äº‘åˆ†å‰²æ–¹æ³•æ³›åŒ–æ€§ä¸è¶³ï¼Œé€šå¸¸å±€é™äºç‰¹å®šé¢†åŸŸå’Œæç¤ºæ–¹å¼ï¼Œé™åˆ¶äº†å…¶åº”ç”¨èŒƒå›´ã€‚
2. SNAPé€šè¿‡å¤šæ•°æ®é›†è®­ç»ƒå’Œé¢†åŸŸè‡ªé€‚åº”å½’ä¸€åŒ–ï¼Œå®ç°äº†è·¨é¢†åŸŸæ³›åŒ–ï¼Œå¹¶æ”¯æŒç©ºé—´å’Œæ–‡æœ¬ä¸¤ç§æç¤ºæ–¹å¼ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒSNAPåœ¨å¤šä¸ªzero-shotåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†SOTAæ€§èƒ½ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œé€šç”¨æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºSNAPï¼ˆSegment Anything in Any Point cloudï¼‰ï¼Œä¸€ä¸ªç»Ÿä¸€çš„äº¤äº’å¼3Dç‚¹äº‘åˆ†å‰²æ¨¡å‹ï¼Œæ”¯æŒè·¨é¢†åŸŸçš„ç‚¹äº‘åˆ†å‰²ï¼Œå¹¶èƒ½æ¥å—åŸºäºç‚¹çš„ç©ºé—´æç¤ºå’ŒåŸºäºæ–‡æœ¬çš„æç¤ºã€‚ç°æœ‰æ–¹æ³•é€šå¸¸å±€é™äºå•ä¸€é¢†åŸŸï¼ˆå®¤å†…æˆ–å®¤å¤–ï¼‰å’Œå•ä¸€äº¤äº’æ–¹å¼ï¼ˆç©ºé—´ç‚¹å‡»æˆ–æ–‡æœ¬æç¤ºï¼‰ã€‚æ­¤å¤–ï¼Œåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè®­ç»ƒé€šå¸¸ä¼šå¯¼è‡´è´Ÿè¿ç§»ï¼Œäº§ç”Ÿç¼ºä¹æ³›åŒ–èƒ½åŠ›çš„é¢†åŸŸç‰¹å®šå·¥å…·ã€‚SNAPé€šè¿‡åœ¨æ¶µç›–å®¤å†…ã€å®¤å¤–å’Œèˆªç©ºç¯å¢ƒçš„7ä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¹¶é‡‡ç”¨é¢†åŸŸè‡ªé€‚åº”å½’ä¸€åŒ–æ¥é˜²æ­¢è´Ÿè¿ç§»ï¼Œä»è€Œå®ç°è·¨é¢†åŸŸæ³›åŒ–ã€‚å¯¹äºæ–‡æœ¬æç¤ºåˆ†å‰²ï¼Œæˆ‘ä»¬è‡ªåŠ¨ç”Ÿæˆmask proposalï¼Œå¹¶å°†å…¶ä¸æ–‡æœ¬æŸ¥è¯¢çš„CLIPåµŒå…¥è¿›è¡ŒåŒ¹é…ï¼Œä»è€Œå®ç°å…¨æ™¯å’Œå¼€æ”¾è¯æ±‡åˆ†å‰²ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒSNAPå§‹ç»ˆæä¾›é«˜è´¨é‡çš„åˆ†å‰²ç»“æœã€‚åœ¨ç©ºé—´æç¤ºåˆ†å‰²çš„9ä¸ªzero-shotåŸºå‡†æµ‹è¯•ä¸­ï¼Œæˆ‘ä»¬åœ¨8ä¸ªä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶åœ¨æ‰€æœ‰5ä¸ªæ–‡æœ¬æç¤ºåŸºå‡†æµ‹è¯•ä¸­å±•ç¤ºäº†å…·æœ‰ç«äº‰åŠ›çš„ç»“æœã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œç»Ÿä¸€æ¨¡å‹å¯ä»¥åŒ¹é…æˆ–è¶…è¿‡ä¸“é—¨çš„é¢†åŸŸç‰¹å®šæ–¹æ³•ï¼Œä¸ºå¯æ‰©å±•çš„3Dæ³¨é‡Šæä¾›å®ç”¨çš„å·¥å…·ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰äº¤äº’å¼3Dç‚¹äº‘åˆ†å‰²æ–¹æ³•é€šå¸¸é’ˆå¯¹ç‰¹å®šé¢†åŸŸï¼ˆå¦‚å®¤å†…æˆ–å®¤å¤–ï¼‰è®¾è®¡ï¼Œå¹¶ä¸”ä»…æ”¯æŒå•ä¸€ç±»å‹çš„ç”¨æˆ·äº¤äº’ï¼ˆå¦‚ç©ºé—´ç‚¹å‡»æˆ–æ–‡æœ¬æç¤ºï¼‰ã€‚åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒæ—¶ï¼Œå®¹æ˜“å‡ºç°è´Ÿè¿ç§»ç°è±¡ï¼Œå¯¼è‡´æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨å…¶ä»–é¢†åŸŸæ€§èƒ½ä¸‹é™ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§èƒ½å¤Ÿè·¨é¢†åŸŸæ³›åŒ–ï¼Œå¹¶æ”¯æŒå¤šç§æç¤ºæ–¹å¼çš„ç»Ÿä¸€æ¨¡å‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSNAPçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¤šæ•°æ®é›†è”åˆè®­ç»ƒå’Œé¢†åŸŸè‡ªé€‚åº”å½’ä¸€åŒ–æ¥è§£å†³è·¨é¢†åŸŸæ³›åŒ–é—®é¢˜ã€‚åŒæ—¶ï¼Œé€šè¿‡ç»“åˆç©ºé—´æç¤ºå’Œæ–‡æœ¬æç¤ºï¼Œæä¾›æ›´çµæ´»çš„äº¤äº’æ–¹å¼ã€‚å¯¹äºæ–‡æœ¬æç¤ºï¼Œé‡‡ç”¨è‡ªåŠ¨mask proposalç”Ÿæˆå’ŒCLIPåµŒå…¥åŒ¹é…çš„æ–¹æ³•ï¼Œå®ç°å¼€æ”¾è¯æ±‡åˆ†å‰²ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSNAPçš„æ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) ç‚¹äº‘ç‰¹å¾æå–æ¨¡å—ï¼šç”¨äºæå–ç‚¹äº‘çš„å‡ ä½•ç‰¹å¾ã€‚2) æç¤ºç¼–ç æ¨¡å—ï¼šç”¨äºç¼–ç ç”¨æˆ·çš„ç©ºé—´æˆ–æ–‡æœ¬æç¤ºã€‚3) åˆ†å‰²é¢„æµ‹æ¨¡å—ï¼šå°†ç‚¹äº‘ç‰¹å¾å’Œæç¤ºç¼–ç èåˆï¼Œé¢„æµ‹åˆ†å‰²maskã€‚4) é¢†åŸŸè‡ªé€‚åº”å½’ä¸€åŒ–æ¨¡å—ï¼šç”¨äºå‡å°‘ä¸åŒé¢†åŸŸæ•°æ®ä¹‹é—´çš„å·®å¼‚ï¼Œé˜²æ­¢è´Ÿè¿ç§»ã€‚å¯¹äºæ–‡æœ¬æç¤ºï¼Œè¿˜åŒ…æ‹¬mask proposalç”Ÿæˆå’ŒCLIPåµŒå…¥åŒ¹é…æ¨¡å—ã€‚

**å…³é”®åˆ›æ–°**ï¼šSNAPçš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†é¢†åŸŸè‡ªé€‚åº”å½’ä¸€åŒ–æ–¹æ³•ï¼Œæœ‰æ•ˆç¼“è§£äº†å¤šæ•°æ®é›†è®­ç»ƒä¸­çš„è´Ÿè¿ç§»é—®é¢˜ã€‚2) å®ç°äº†ç©ºé—´å’Œæ–‡æœ¬æç¤ºçš„ç»Ÿä¸€å¤„ç†ï¼Œæä¾›äº†æ›´çµæ´»çš„äº¤äº’æ–¹å¼ã€‚3) é‡‡ç”¨è‡ªåŠ¨mask proposalç”Ÿæˆå’ŒCLIPåµŒå…¥åŒ¹é…çš„æ–¹æ³•ï¼Œå®ç°äº†å¼€æ”¾è¯æ±‡çš„æ–‡æœ¬æç¤ºåˆ†å‰²ã€‚

**å…³é”®è®¾è®¡**ï¼šé¢†åŸŸè‡ªé€‚åº”å½’ä¸€åŒ–é‡‡ç”¨Instance Normalizationï¼Œå¹¶ä¸ºæ¯ä¸ªé¢†åŸŸå­¦ä¹ ç‹¬ç«‹çš„ä»¿å°„å˜æ¢å‚æ•°ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬åˆ†å‰²æŸå¤±ï¼ˆå¦‚Dice Lossæˆ–Cross-Entropy Lossï¼‰å’Œå¯¹æ¯”å­¦ä¹ æŸå¤±ï¼ˆç”¨äºå¢å¼ºç‰¹å¾çš„åŒºåˆ†æ€§ï¼‰ã€‚æ–‡æœ¬æç¤ºçš„mask proposalç”Ÿæˆé‡‡ç”¨èšç±»ç®—æ³•æˆ–åŸºäºå‡ ä½•ç‰¹å¾çš„åˆ†å‰²æ–¹æ³•ã€‚CLIPåµŒå…¥åŒ¹é…é‡‡ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ä½œä¸ºåŒ¹é…åº¦é‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

SNAPåœ¨8/9ä¸ªç©ºé—´æç¤ºåˆ†å‰²çš„zero-shotåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†SOTAæ€§èƒ½ï¼Œå¹¶åœ¨æ‰€æœ‰5ä¸ªæ–‡æœ¬æç¤ºåˆ†å‰²åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„ç»“æœã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒSNAPèƒ½å¤Ÿæœ‰æ•ˆæ³›åŒ–åˆ°æœªè§è¿‡çš„é¢†åŸŸï¼Œå¹¶ä¸”åœ¨å¤šç§æç¤ºæ–¹å¼ä¸‹éƒ½èƒ½æä¾›é«˜è´¨é‡çš„åˆ†å‰²ç»“æœã€‚ç›¸æ¯”äºé¢†åŸŸç‰¹å®šçš„æ¨¡å‹ï¼ŒSNAPåœ¨æ€§èƒ½ä¸Šå…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SNAPå¯åº”ç”¨äºå¤šç§3Dåœºæ™¯ç†è§£ä»»åŠ¡ï¼Œå¦‚è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€åŸå¸‚å»ºæ¨¡ã€æ–‡ç‰©ä¿æŠ¤ç­‰ã€‚å®ƒèƒ½å¤Ÿé€šè¿‡ç”¨æˆ·äº¤äº’å¿«é€Ÿå‡†ç¡®åœ°åˆ†å‰²ç›®æ ‡ç‰©ä½“ï¼Œæé«˜3Dæ•°æ®çš„æ ‡æ³¨æ•ˆç‡ï¼Œé™ä½æ ‡æ³¨æˆæœ¬ã€‚æœªæ¥ï¼ŒSNAPæœ‰æœ›æˆä¸º3Dåœºæ™¯ç†è§£é¢†åŸŸçš„é‡è¦å·¥å…·ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Interactive 3D point cloud segmentation enables efficient annotation of complex 3D scenes through user-guided prompts. However, current approaches are typically restricted in scope to a single domain (indoor or outdoor), and to a single form of user interaction (either spatial clicks or textual prompts). Moreover, training on multiple datasets often leads to negative transfer, resulting in domain-specific tools that lack generalizability. To address these limitations, we present \textbf{SNAP} (\textbf{S}egment a\textbf{N}ything in \textbf{A}ny \textbf{P}oint cloud), a unified model for interactive 3D segmentation that supports both point-based and text-based prompts across diverse domains. Our approach achieves cross-domain generalizability by training on 7 datasets spanning indoor, outdoor, and aerial environments, while employing domain-adaptive normalization to prevent negative transfer. For text-prompted segmentation, we automatically generate mask proposals without human intervention and match them against CLIP embeddings of textual queries, enabling both panoptic and open-vocabulary segmentation. Extensive experiments demonstrate that SNAP consistently delivers high-quality segmentation results. We achieve state-of-the-art performance on 8 out of 9 zero-shot benchmarks for spatial-prompted segmentation and demonstrate competitive results on all 5 text-prompted benchmarks. These results show that a unified model can match or exceed specialized domain-specific approaches, providing a practical tool for scalable 3D annotation. Project page is at, https://neu-vi.github.io/SNAP/

