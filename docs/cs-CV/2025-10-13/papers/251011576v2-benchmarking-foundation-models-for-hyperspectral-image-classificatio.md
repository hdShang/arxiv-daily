---
layout: default
title: Benchmarking foundation models for hyperspectral image classification: Application to cereal crop type mapping
---

# Benchmarking foundation models for hyperspectral image classification: Application to cereal crop type mapping

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.11576" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.11576v2</a>
  <a href="https://arxiv.org/pdf/2510.11576.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.11576v2" onclick="toggleFavorite(this, '2510.11576v2', 'Benchmarking foundation models for hyperspectral image classification: Application to cereal crop type mapping')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Walid Elbarz, Mohamed Bourriz, Hicham Hajji, Hamd Ait Abdelali, FranÃ§ois Bourzeix

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-13 (æ›´æ–°: 2025-10-14)

**å¤‡æ³¨**: currently being reviewed for WHISPERS conference ( Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing )

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°åŸºç¡€æ¨¡å‹åœ¨ hyperspectral å›¾åƒåˆ†ç±»ä¸­çš„æ€§èƒ½ï¼Œåº”ç”¨äºè°·ç±»ä½œç‰©ç±»å‹è¯†åˆ«ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `hyperspectral å›¾åƒåˆ†ç±»` `åŸºç¡€æ¨¡å‹` `Vision Transformers` `ä½œç‰©ç±»å‹è¯†åˆ«` `SpectralEarth æ•°æ®é›†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ hyperspectral ä½œç‰©ç±»å‹è¯†åˆ«ä¸­æ³›åŒ–èƒ½åŠ›ä¸è¶³ï¼Œéš¾ä»¥é€‚åº”ä¸åŒåœ°ç†åŒºåŸŸå’Œä¼ æ„Ÿå™¨å¹³å°ã€‚
2. æœ¬ç ”ç©¶é€šè¿‡å¾®è°ƒåœ¨å¤§å‹ hyperspectral æ•°æ®é›†ä¸Šé¢„è®­ç»ƒçš„åŸºç¡€æ¨¡å‹ï¼Œæå‡æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚
3. å®éªŒè¡¨æ˜ï¼Œåœ¨ SpectralEarth æ•°æ®é›†ä¸Šé¢„è®­ç»ƒçš„ Vision Transformers åœ¨ä½œç‰©ç±»å‹è¯†åˆ«ä¸­è¡¨ç°æœ€ä½³ï¼ŒOA è¾¾åˆ° 93.5%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶è¯„ä¼°äº†åŸºç¡€æ¨¡å‹åœ¨ hyperspectral ä½œç‰©ç±»å‹è¯†åˆ«ä¸­çš„æ½œåŠ›ã€‚å…·ä½“åœ°ï¼Œç ”ç©¶å¯¹æ¯”äº†ä¸‰ä¸ªåŸºç¡€æ¨¡å‹ï¼šHyperSigmaã€DOFA å’Œåœ¨ SpectralEarth æ•°æ®é›†ï¼ˆä¸€ä¸ªå¤§å‹å¤šæ—¶ç›¸ hyperspectral æ¡£æ¡ˆï¼‰ä¸Šé¢„è®­ç»ƒçš„ Vision Transformersã€‚è¿™äº›æ¨¡å‹åœ¨äººå·¥æ ‡æ³¨çš„è®­ç»ƒåŒºåŸŸæ•°æ®ä¸Šè¿›è¡Œå¾®è°ƒï¼Œå¹¶åœ¨ç‹¬ç«‹çš„æµ‹è¯•åŒºåŸŸè¿›è¡Œè¯„ä¼°ã€‚æ€§èƒ½æŒ‡æ ‡åŒ…æ‹¬æ€»ä½“ç²¾åº¦ï¼ˆOAï¼‰ã€å¹³å‡ç²¾åº¦ï¼ˆAAï¼‰å’Œ F1 åˆ†æ•°ã€‚HyperSigma çš„ OA ä¸º 34.5% (+/- 1.8%)ï¼ŒDOFA ä¸º 62.6% (+/- 3.5%)ï¼ŒSpectralEarth æ¨¡å‹ä¸º 93.5% (+/- 0.8%)ã€‚ä»å¤´å¼€å§‹è®­ç»ƒçš„ç´§å‡‘å‹ SpectralEarth å˜ä½“è¾¾åˆ°äº† 91% çš„ OAï¼Œçªå‡ºäº†æ¨¡å‹æ¶æ„å¯¹äºè·¨åœ°ç†åŒºåŸŸå’Œä¼ æ„Ÿå™¨å¹³å°çš„æ³›åŒ–èƒ½åŠ›çš„é‡è¦æ€§ã€‚è¿™äº›ç»“æœä¸º hyperspectral ä½œç‰©ç±»å‹è¯†åˆ«çš„åŸºç¡€æ¨¡å‹æä¾›äº†ä¸€ä¸ªç³»ç»Ÿçš„è¯„ä¼°ï¼Œå¹¶ä¸ºæœªæ¥çš„æ¨¡å‹å¼€å‘æŒ‡æ˜äº†æ–¹å‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ hyperspectral å›¾åƒåˆ†ç±»åœ¨è°·ç±»ä½œç‰©ç±»å‹è¯†åˆ«ä¸­çš„åº”ç”¨é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨è·¨åŒºåŸŸã€è·¨ä¼ æ„Ÿå™¨å¹³å°ä¸Šçš„æ³›åŒ–èƒ½åŠ›è¾ƒå¼±ï¼Œéœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œæˆæœ¬è¾ƒé«˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨åœ¨å¤§è§„æ¨¡ hyperspectral æ•°æ®é›†ä¸Šé¢„è®­ç»ƒçš„åŸºç¡€æ¨¡å‹ï¼Œé€šè¿‡å¾®è°ƒçš„æ–¹å¼ï¼Œä½¿å…¶é€‚åº”ç‰¹å®šçš„ä½œç‰©ç±»å‹è¯†åˆ«ä»»åŠ¡ã€‚é¢„è®­ç»ƒæ¨¡å‹èƒ½å¤Ÿå­¦ä¹ åˆ°é€šç”¨çš„å…‰è°±ç‰¹å¾è¡¨ç¤ºï¼Œä»è€Œå‡å°‘å¯¹ç‰¹å®šä»»åŠ¡æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åŒ…æ‹¬ï¼š1) é€‰æ‹©ä¸‰ä¸ªåŸºç¡€æ¨¡å‹ï¼ˆHyperSigma, DOFA, SpectralEarth é¢„è®­ç»ƒçš„ Vision Transformersï¼‰ï¼›2) ä½¿ç”¨äººå·¥æ ‡æ³¨çš„è®­ç»ƒæ•°æ®å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼›3) åœ¨ç‹¬ç«‹çš„æµ‹è¯•åŒºåŸŸè¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ï¼Œä½¿ç”¨æ€»ä½“ç²¾åº¦ï¼ˆOAï¼‰ã€å¹³å‡ç²¾åº¦ï¼ˆAAï¼‰å’Œ F1 åˆ†æ•°ä½œä¸ºè¯„ä»·æŒ‡æ ‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºç³»ç»Ÿæ€§åœ°è¯„ä¼°äº†ä¸åŒç±»å‹çš„åŸºç¡€æ¨¡å‹åœ¨ hyperspectral å›¾åƒåˆ†ç±»ä¸­çš„æ€§èƒ½ï¼Œå¹¶éªŒè¯äº†åœ¨å¤§è§„æ¨¡ hyperspectral æ•°æ®é›†ä¸Šé¢„è®­ç»ƒçš„æ¨¡å‹åœ¨ä½œç‰©ç±»å‹è¯†åˆ«ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å‘ç°æ¨¡å‹æ¶æ„å¯¹äºè·¨åŒºåŸŸæ³›åŒ–èƒ½åŠ›è‡³å…³é‡è¦ã€‚

**å…³é”®è®¾è®¡**ï¼šç ”ç©¶ä¸­ä½¿ç”¨äº† Vision Transformers ä½œä¸ºåŸºç¡€æ¨¡å‹ä¹‹ä¸€ï¼Œå¹¶åœ¨ SpectralEarth æ•°æ®é›†ä¸Šè¿›è¡Œäº†é¢„è®­ç»ƒã€‚SpectralEarth æ•°æ®é›†æ˜¯ä¸€ä¸ªå¤§å‹å¤šæ—¶ç›¸ hyperspectral æ¡£æ¡ˆï¼ŒåŒ…å«äº†ä¸°å¯Œçš„å…‰è°±ä¿¡æ¯ã€‚æ¨¡å‹çš„å¾®è°ƒè¿‡ç¨‹ä½¿ç”¨äº†äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼Œå¹¶é‡‡ç”¨äº† Adam ä¼˜åŒ–å™¨ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®ï¼ˆå¦‚å­¦ä¹ ç‡ã€batch size ç­‰ï¼‰æœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ SpectralEarth æ•°æ®é›†ä¸Šé¢„è®­ç»ƒçš„ Vision Transformers æ¨¡å‹åœ¨è°·ç±»ä½œç‰©ç±»å‹è¯†åˆ«ä¸­è¡¨ç°æœ€ä½³ï¼Œæ€»ä½“ç²¾åº¦ï¼ˆOAï¼‰è¾¾åˆ° 93.5% (+/- 0.8%)ã€‚å³ä½¿æ˜¯ä»å¤´å¼€å§‹è®­ç»ƒçš„ç´§å‡‘å‹ SpectralEarth å˜ä½“ï¼Œä¹Ÿèƒ½è¾¾åˆ° 91% çš„ OAï¼Œè¿™çªå‡ºäº†æ¨¡å‹æ¶æ„çš„é‡è¦æ€§ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒHyperSigma å’Œ DOFA çš„æ€§èƒ½æ˜æ˜¾è¾ƒå·®ï¼ŒOA åˆ†åˆ«ä¸º 34.5% å’Œ 62.6%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºç²¾å‡†å†œä¸šé¢†åŸŸï¼Œå®ç°å¯¹å†œä½œç‰©ç±»å‹çš„è‡ªåŠ¨è¯†åˆ«å’Œé¢ç§¯ä¼°ç®—ï¼Œä¸ºå†œä¸šç”Ÿäº§ç®¡ç†æä¾›å†³ç­–æ”¯æŒã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥æ¨å¹¿åˆ°å…¶ä»–åœ°ç‰©ç±»å‹çš„è¯†åˆ«ï¼Œä¾‹å¦‚æ£®æ—ç±»å‹ã€åœŸåœ°åˆ©ç”¨ç±»å‹ç­‰ï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚æœªæ¥ï¼Œç»“åˆæ— äººæœºæˆ–å«æ˜Ÿé¥æ„Ÿæ•°æ®ï¼Œå¯ä»¥å®ç°å¤§èŒƒå›´ã€é«˜ç²¾åº¦çš„åœ°ç‰©ç±»å‹è¯†åˆ«ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Foundation models are transforming Earth observation, but their potential for hyperspectral crop mapping remains underexplored. This study benchmarks three foundation models for cereal crop mapping using hyperspectral imagery: HyperSigma, DOFA, and Vision Transformers pre-trained on the SpectralEarth dataset (a large multitemporal hyperspectral archive). Models were fine-tuned on manually labeled data from a training region and evaluated on an independent test region. Performance was measured with overall accuracy (OA), average accuracy (AA), and F1-score. HyperSigma achieved an OA of 34.5% (+/- 1.8%), DOFA reached 62.6% (+/- 3.5%), and the SpectralEarth model achieved an OA of 93.5% (+/- 0.8%). A compact SpectralEarth variant trained from scratch achieved 91%, highlighting the importance of model architecture for strong generalization across geographic regions and sensor platforms. These results provide a systematic evaluation of foundation models for operational hyperspectral crop mapping and outline directions for future model development.

