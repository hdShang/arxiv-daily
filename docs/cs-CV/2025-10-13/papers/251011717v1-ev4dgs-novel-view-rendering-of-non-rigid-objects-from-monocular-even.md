---
layout: default
title: Ev4DGS: Novel-view Rendering of Non-Rigid Objects from Monocular Event Streams
---

# Ev4DGS: Novel-view Rendering of Non-Rigid Objects from Monocular Event Streams

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.11717" target="_blank" class="toolbar-btn">arXiv: 2510.11717v1</a>
    <a href="https://arxiv.org/pdf/2510.11717.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.11717v1" 
            onclick="toggleFavorite(this, '2510.11717v1', 'Ev4DGS: Novel-view Rendering of Non-Rigid Objects from Monocular Event Streams')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Takuya Nakabayashi, Navami Kairanda, Hideo Saito, Vladislav Golyanik

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-13

**ÊúüÂàä**: British Machine Vision Conference (BMVC) 2025

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Ev4DGS‰ª•Ëß£ÂÜ≥ÂçïÁõÆ‰∫ã‰ª∂ÊµÅ‰∏ãÈùûÂàöÊÄßÁâ©‰ΩìÁöÑÊñ∞ËßÜËßíÊ∏≤ÊüìÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)**

**ÂÖ≥ÈîÆËØç**: `‰∫ã‰ª∂Áõ∏Êú∫` `Êñ∞ËßÜËßíÊ∏≤Êüì` `ÈùûÂàöÊÄßÁâ©‰Ωì` `ÂçïÁõÆ‰∫ã‰ª∂ÊµÅ` `3DÂèòÂΩ¢Ê®°Âûã` `ËÆ°ÁÆóÊú∫ËßÜËßâ` `Ê∑±Â∫¶Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®Â§ÑÁêÜÈùûÂàöÊÄßÁâ©‰ΩìÊó∂‰æùËµñÁ®ÄÁñèRGBËæìÂÖ•ÔºåÈôêÂà∂‰∫ÜÂÖ∂ÂÆûÈôÖÂ∫îÁî®„ÄÇ
2. Ev4DGSÈÄöËøáÂçïÁõÆ‰∫ã‰ª∂ÊµÅÁõ¥Êé•Ê∏≤ÊüìÈùûÂàöÊÄßÁâ©‰ΩìÔºåÈÅøÂÖç‰∫ÜÂØπRGBÂõæÂÉèÁöÑ‰æùËµñ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåEv4DGSÂú®ÂêàÊàêÂíåÁúüÂÆûÊï∞ÊçÆÈõÜ‰∏äÂùá‰ºò‰∫éÂ§ö‰∏™Âü∫Á∫øÊñπÊ≥ïÔºåÈ™åËØÅ‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

‰∫ã‰ª∂Áõ∏Êú∫Âú®Êñ∞ËßÜËßíÊ∏≤ÊüìÊñπÈù¢Áõ∏ËæÉ‰∫éÂêåÊ≠•Â∑•‰ΩúÁöÑRGBÁõ∏Êú∫ÂÖ∑ÊúâÂ§öÁßç‰ºòÂäø„ÄÇÂ∞ΩÁÆ°Â∑≤ÊúâÈíàÂØπÂàöÊÄßÂú∫ÊôØÁöÑÈ´òÊïà‰∫ã‰ª∂È©±Âä®ÊäÄÊúØÔºå‰ΩÜÂú®ÈùûÂàöÊÄßÁâ©‰ΩìÁöÑÊÉÖÂÜµ‰∏ãÔºåÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏ÈúÄË¶ÅÁ®ÄÁñèÁöÑRGBËæìÂÖ•ÔºåËøôÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠Â≠òÂú®ÊòæËëóÈôêÂà∂„ÄÇÊú¨ÊñáÊèêÂá∫Ev4DGSÔºåÈ¶ñÊ¨°ÂÆûÁé∞‰∫Ü‰ªéÂçïÁõÆ‰∫ã‰ª∂ÊµÅ‰∏≠Ê∏≤ÊüìÈùûÂàöÊÄßÂèòÂΩ¢Áâ©‰ΩìÁöÑRGBÊàñÁÅ∞Â∫¶ÂõæÂÉè„ÄÇËØ•ÊñπÊ≥ïÈÄöËøáÊçüÂ§±ÂáΩÊï∞Â∞Ü‰º∞ËÆ°Ê®°ÂûãÁöÑËæìÂá∫‰∏é2D‰∫ã‰ª∂ËßÇÊµãÁ©∫Èó¥ÂÖ≥ËÅîÔºåÂπ∂Âà©Áî®‰ªé‰∫ã‰ª∂ÁîüÊàêÁöÑ‰∫åËøõÂà∂Êé©ËÜúËÆ≠ÁªÉÁ≤óÁï•ÁöÑ3DÂèòÂΩ¢Ê®°Âûã„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåEv4DGSÂú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞‰ºòË∂äÔºåÈ™åËØÅ‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥‰ªéÂçïÁõÆ‰∫ã‰ª∂ÊµÅ‰∏≠Ê∏≤ÊüìÈùûÂàöÊÄßÂèòÂΩ¢Áâ©‰ΩìÁöÑÊåëÊàò„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏ÈúÄË¶ÅÁ®ÄÁñèÁöÑRGBËæìÂÖ•ÔºåËøôÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠Â≠òÂú®ÈôêÂà∂„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöEv4DGSÈÄöËøáÂõûÂΩíÂèØÂèòÂΩ¢ÁöÑ3DÈ´òÊñØÁÇπ‰∫ëË°®Á§∫ÔºåÂà©Áî®‰∫ã‰ª∂ÊµÅÁõ¥Êé•ÁîüÊàêRGBÊàñÁÅ∞Â∫¶ÂõæÂÉèÔºåÈÅøÂÖç‰∫ÜÂØπRGBÂõæÂÉèÁöÑ‰æùËµñ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•ÊñπÊ≥ï‰∏ªË¶ÅÂåÖÊã¨‰∏§‰∏™Ê®°ÂùóÔºö1) ÈÄöËøáÊçüÂ§±ÂáΩÊï∞Â∞ÜÊ®°ÂûãËæìÂá∫‰∏é2D‰∫ã‰ª∂ËßÇÊµãÁ©∫Èó¥ÂÖ≥ËÅîÔºõ2) ‰ªé‰∫ã‰ª∂ÁîüÊàêÁöÑ‰∫åËøõÂà∂Êé©ËÜú‰∏≠ËÆ≠ÁªÉÁ≤óÁï•ÁöÑ3DÂèòÂΩ¢Ê®°Âûã„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöEv4DGSÊòØÈ¶ñ‰∏™‰ªÖÂü∫‰∫éÂçïÁõÆ‰∫ã‰ª∂ÊµÅÂÆûÁé∞ÈùûÂàöÊÄßÁâ©‰ΩìÊñ∞ËßÜËßíÊ∏≤ÊüìÁöÑÊñπÊ≥ïÔºåÁ™ÅÁ†¥‰∫ÜÂØπRGBËæìÂÖ•ÁöÑ‰æùËµñÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÁêÜËÆ∫ÂíåÂÆûË∑µÊÑè‰πâ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÊçüÂ§±ÂáΩÊï∞ËÆæËÆ°‰∏∫Â∞ÜÊ®°ÂûãËæìÂá∫‰∏é2D‰∫ã‰ª∂ËßÇÊµãÁ©∫Èó¥ËøõË°åÊúâÊïàÂÖ≥ËÅîÔºåÁ°Æ‰øùÁîüÊàêÁöÑÂõæÂÉè‰∏éÂÆûÈôÖËßÇÊµãÁõ∏Á¨¶„ÄÇÂêåÊó∂ÔºåÈááÁî®‰ªé‰∫ã‰ª∂ÁîüÊàêÁöÑ‰∫åËøõÂà∂Êé©ËÜúÊù•ËÆ≠ÁªÉ3DÂèòÂΩ¢Ê®°ÂûãÔºåÂ¢ûÂº∫‰∫ÜÊ®°ÂûãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåEv4DGSÂú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞‰ºòË∂äÔºåÁõ∏ËæÉ‰∫éÂ§ö‰∏™Âü∫Á∫øÊñπÊ≥ïÔºåÂÖ∂ÊÄßËÉΩÊèêÂçáÊòæËëóÔºåÂÖ∑‰ΩìÊèêÂçáÂπÖÂ∫¶Êú™Áü•„ÄÇËØ•ÊñπÊ≥ïÂú®ÂêàÊàêÂíåÁúüÂÆûÊï∞ÊçÆÈõÜ‰∏äÂùáÂ±ïÁ§∫‰∫ÜËâØÂ•ΩÁöÑÊïàÊûúÔºåÈ™åËØÅ‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõÔºåÁâπÂà´ÊòØÂú®Êú∫Âô®‰∫∫ËßÜËßâ„ÄÅÂ¢ûÂº∫Áé∞ÂÆûÂíåËôöÊãüÁé∞ÂÆûÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÂÆûÁé∞ÈùûÂàöÊÄßÁâ©‰ΩìÁöÑÊñ∞ËßÜËßíÊ∏≤ÊüìÔºåEv4DGSÂèØ‰ª•ÊèêÂçáËøô‰∫õÈ¢ÜÂüü‰∏≠ÁöÑÁâ©‰ΩìËØÜÂà´„ÄÅË∑üË∏™Âíå‰∫§‰∫íËÉΩÂäõÔºåÊé®Âä®Áõ∏ÂÖ≥ÊäÄÊúØÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Event cameras offer various advantages for novel view rendering compared to synchronously operating RGB cameras, and efficient event-based techniques supporting rigid scenes have been recently demonstrated in the literature. In the case of non-rigid objects, however, existing approaches additionally require sparse RGB inputs, which can be a substantial practical limitation; it remains unknown if similar models could be learned from event streams only. This paper sheds light on this challenging open question and introduces Ev4DGS, i.e., the first approach for novel view rendering of non-rigidly deforming objects in the explicit observation space (i.e., as RGB or greyscale images) from monocular event streams. Our method regresses a deformable 3D Gaussian Splatting representation through 1) a loss relating the outputs of the estimated model with the 2D event observation space, and 2) a coarse 3D deformation model trained from binary masks generated from events. We perform experimental comparisons on existing synthetic and newly recorded real datasets with non-rigid objects. The results demonstrate the validity of Ev4DGS and its superior performance compared to multiple naive baselines that can be applied in our setting. We will release our models and the datasets used in the evaluation for research purposes; see the project webpage: https://4dqv.mpi-inf.mpg.de/Ev4DGS/.

