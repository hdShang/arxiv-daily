---
layout: default
title: Robust Ego-Exo Correspondence with Long-Term Memory
---

# Robust Ego-Exo Correspondence with Long-Term Memory

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.11417" class="toolbar-btn" target="_blank">üìÑ arXiv: 2510.11417v1</a>
  <a href="https://arxiv.org/pdf/2510.11417.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.11417v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.11417v1', 'Robust Ego-Exo Correspondence with Long-Term Memory')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Yijun Hu, Bing Fan, Xin Gu, Haiqing Ren, Dongfang Liu, Heng Fan, Libo Zhang

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-13

**Â§áÊ≥®**: Accepted by NeurIPS 2025

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/juneyeeHu/LM-EEC)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éÈïøÊó∂ËÆ∞ÂøÜÁöÑLM-EECÊ°ÜÊû∂ÔºåËß£ÂÜ≥Ego-ExoËßÜËßíÂØπÂ∫î‰∏≠ÁöÑÁâπÂæÅËûçÂêàÂíåËÆ∞ÂøÜÂÆπÈáèÈóÆÈ¢ò„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±ÂÖ≠ÔºöËßÜÈ¢ëÊèêÂèñ‰∏éÂåπÈÖç (Video Extraction)**

**ÂÖ≥ÈîÆËØç**: `Ego-ExoÂØπÂ∫î` `ÈïøÊó∂ËÆ∞ÂøÜ` `ÁâπÂæÅËûçÂêà` `Ëá™ÈÄÇÂ∫îË∑ØÁî±` `ËßÜÈ¢ëÂàÜÂâ≤`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Ego-ExoËßÜËßíÂØπÂ∫î‰ªªÂä°Èù¢‰∏¥ËßÜËßíÂ∑ÆÂºÇ„ÄÅÈÅÆÊå°ÂíåÂ∞èÁâ©‰ΩìÁ≠âÊåëÊàòÔºåÁé∞ÊúâÊñπÊ≥ïÈöæ‰ª•ÊúâÊïàÂ∫îÂØπ„ÄÇ
2. ÊèêÂá∫Âü∫‰∫éSAM 2ÁöÑÈïøÊó∂ËÆ∞ÂøÜEECÊ°ÜÊû∂(LM-EEC)ÔºåÂà©Áî®ÂèåËÆ∞ÂøÜÊû∂ÊûÑÂíåËá™ÈÄÇÂ∫îÁâπÂæÅË∑ØÁî±Ëß£ÂÜ≥ÁâπÂæÅËûçÂêàÂíåËÆ∞ÂøÜÂÆπÈáèÈóÆÈ¢ò„ÄÇ
3. Âú®EgoExo4DÊï∞ÊçÆÈõÜ‰∏äÔºåLM-EECÊòæËëó‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÂíåSAM 2Âü∫Á∫øÔºåÂÆûÁé∞‰∫Üstate-of-the-artÁöÑÊÄßËÉΩ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÂü∫‰∫éSAM 2ÁöÑÈïøÊó∂ËÆ∞ÂøÜEgo-ExoËßÜËßíÂØπÂ∫î(EEC)Ê°ÜÊû∂ÔºåÊó®Âú®Ëß£ÂÜ≥Êô∫ËÉΩÂä©ÊâãÊèê‰æõÁ≤æÁ°ÆÁõ¥ËßÇËßÜËßâÊåáÂØºÁöÑÂÖ≥ÈîÆÈóÆÈ¢ò„ÄÇËØ•‰ªªÂä°Èù¢‰∏¥ËßÜËßíÂ∑ÆÂºÇÂ§ß„ÄÅÈÅÆÊå°ÂíåÂ∞èÁâ©‰ΩìÁ≠âÊåëÊàò„ÄÇÈíàÂØπSAM 2Âú®EEC‰ªªÂä°‰∏≠Â≠òÂú®ÁöÑÁâπÂæÅËûçÂêà‰∏çË∂≥ÂíåÈïøÊó∂ËÆ∞ÂøÜÂÆπÈáèÊúâÈôêÁöÑÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜÂèåËÆ∞ÂøÜÊû∂ÊûÑÂíå‰∏Ä‰∏™ÂèóÊ∑∑Âêà‰∏ìÂÆ∂(MoE)ÂêØÂèëÁöÑËá™ÈÄÇÂ∫îÁâπÂæÅË∑ØÁî±Ê®°Âùó„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÂåÖÂê´‰∏Ä‰∏™Memory-View MoEÊ®°ÂùóÔºåËØ•Ê®°ÂùóÂÖ∑ÊúâÂèåÂàÜÊîØË∑ØÁî±Êú∫Âà∂ÔºåÂèØ‰ª•Ëá™ÈÄÇÂ∫îÂú∞ÂàÜÈÖçÊØè‰∏™‰∏ìÂÆ∂ÁâπÂæÅÂú®ÈÄöÈÅìÂíåÁ©∫Èó¥Áª¥Â∫¶‰∏äÁöÑË¥°ÁåÆÊùÉÈáçÔºõ‰ª•Âèä‰∏Ä‰∏™ÂèåËÆ∞ÂøÜÂ∫ìÁ≥ªÁªüÔºåÈááÁî®ÁÆÄÂçïËÄåÊúâÊïàÁöÑÂéãÁº©Á≠ñÁï•Ôºå‰ª•‰øùÁïôÂÖ≥ÈîÆÁöÑÈïøÊúü‰ø°ÊÅØÂπ∂Ê∂àÈô§ÂÜó‰Ωô„ÄÇÂú®EgoExo4DÂü∫ÂáÜÊµãËØï‰∏äÁöÑÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïLM-EECÂèñÂæó‰∫ÜÊñ∞ÁöÑstate-of-the-artÁªìÊûúÔºåÊòæËëó‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÂíåSAM 2Âü∫Á∫øÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®ÂêÑÁßçÂú∫ÊôØ‰∏≠ÁöÑÂº∫Â§ßÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöEgo-ExoËßÜËßíÂØπÂ∫îÊó®Âú®Âª∫Á´ãËá™Êàë‰∏≠ÂøÉËßÜËßíÂíåÂ§ñÈÉ®ËßÜËßí‰πãÈó¥ÁöÑÁâ©‰ΩìÁ∫ßÂØπÂ∫îÂÖ≥Á≥ªÔºåËøôÂØπ‰∫éÊô∫ËÉΩÂä©ÊâãÊèê‰æõÁ≤æÁ°ÆÁöÑËßÜËßâÊåáÂØºËá≥ÂÖ≥ÈáçË¶Å„ÄÇÁé∞ÊúâÊñπÊ≥ïÔºåÂç≥‰ΩøÊòØÂü∫‰∫éÂº∫Â§ßÁöÑSAM 2Ôºå‰πüÈöæ‰ª•ÊúâÊïàËûçÂêà‰∏çÂêåËßÜËßíÁöÑÁâπÂæÅÔºåÂπ∂‰∏îÁº∫‰πèÂ§ÑÁêÜÈïøËßÜÈ¢ëÊâÄÈúÄÁöÑÈïøÊúüËÆ∞ÂøÜËÉΩÂäõÔºåÂØºËá¥Âú®ËßÜËßíÂèòÂåñÂ§ß„ÄÅÈÅÆÊå°‰∏•ÈáçÂíåÂ∞èÁâ©‰ΩìÂú∫ÊôØ‰∏ãÊÄßËÉΩ‰∏ãÈôç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊ†∏ÂøÉÊÄùË∑ØÊòØÂ¢ûÂº∫SAM 2Âú®Ego-ExoËßÜËßíÂØπÂ∫î‰ªªÂä°‰∏≠ÁöÑÁâπÂæÅËûçÂêàËÉΩÂäõÂíåÈïøÊúüËÆ∞ÂøÜËÉΩÂäõ„ÄÇÈÄöËøáÂºïÂÖ•ÂèåËÆ∞ÂøÜÊû∂ÊûÑÂíåËá™ÈÄÇÂ∫îÁâπÂæÅË∑ØÁî±Êú∫Âà∂ÔºåÊ®°ÂûãËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞ËûçÂêàÊù•Ëá™‰∏çÂêåËßÜËßíÁöÑÁâπÂæÅÔºåÂπ∂‰øùÁïôÂÖ≥ÈîÆÁöÑÈïøÊúü‰ø°ÊÅØÔºå‰ªéËÄåÊèêÈ´òÂØπÂ∫îÁ≤æÂ∫¶ÂíåÈ≤ÅÊ£íÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöLM-EECÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Ê†∏ÂøÉÊ®°ÂùóÔºö1) ÁâπÂæÅÊèêÂèñÊ®°ÂùóÔºàÂü∫‰∫éSAM 2ÔºâÔºõ2) Memory-View MoEÊ®°ÂùóÔºåÁî®‰∫éËá™ÈÄÇÂ∫îÂú∞ËûçÂêàÊù•Ëá™‰∏çÂêåËßÜËßíÁöÑÁâπÂæÅÔºõ3) ÂèåËÆ∞ÂøÜÂ∫ìÁ≥ªÁªüÔºåÁî®‰∫éÂ≠òÂÇ®ÂíåÊõ¥Êñ∞ÈïøÊúüËÆ∞ÂøÜÔºõ4) ÂàÜÂâ≤È¢ÑÊµãÊ®°ÂùóÔºåÁî®‰∫éÁîüÊàêÊúÄÁªàÁöÑEgo-ExoÂØπÂ∫îÂàÜÂâ≤ÁªìÊûú„ÄÇÊï¥‰ΩìÊµÅÁ®ãÊòØÔºöÈ¶ñÂÖàÂà©Áî®SAM 2ÊèêÂèñÁâπÂæÅÔºåÁÑ∂ÂêéÈÄöËøáMemory-View MoEÊ®°ÂùóËøõË°åÁâπÂæÅËûçÂêàÔºåÊé•ÁùÄÂà©Áî®ÂèåËÆ∞ÂøÜÂ∫ìÁ≥ªÁªüÂ≠òÂÇ®ÂíåÊõ¥Êñ∞ÈïøÊúüËÆ∞ÂøÜÔºåÊúÄÂêéËøõË°åÂàÜÂâ≤È¢ÑÊµã„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éMemory-View MoEÊ®°ÂùóÂíåÂèåËÆ∞ÂøÜÂ∫ìÁ≥ªÁªü„ÄÇMemory-View MoEÊ®°ÂùóÈÄöËøáÂèåÂàÜÊîØË∑ØÁî±Êú∫Âà∂ÔºåËá™ÈÄÇÂ∫îÂú∞ÂàÜÈÖçÊØè‰∏™‰∏ìÂÆ∂ÁâπÂæÅÂú®ÈÄöÈÅìÂíåÁ©∫Èó¥Áª¥Â∫¶‰∏äÁöÑË¥°ÁåÆÊùÉÈáçÔºå‰ªéËÄåÂÆûÁé∞Êõ¥ÊúâÊïàÁöÑÁâπÂæÅËûçÂêà„ÄÇÂèåËÆ∞ÂøÜÂ∫ìÁ≥ªÁªüÈááÁî®ÁÆÄÂçïËÄåÊúâÊïàÁöÑÂéãÁº©Á≠ñÁï•Ôºå‰øùÁïôÂÖ≥ÈîÆÁöÑÈïøÊúü‰ø°ÊÅØÂπ∂Ê∂àÈô§ÂÜó‰ΩôÔºå‰ªéËÄåÊèêÈ´òÊ®°ÂûãÁöÑÈïøÊúüËÆ∞ÂøÜËÉΩÂäõ„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåLM-EECËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞Â§ÑÁêÜËßÜËßíÂèòÂåñÂ§ß„ÄÅÈÅÆÊå°‰∏•ÈáçÂíåÂ∞èÁâ©‰ΩìÁ≠âÊåëÊàò„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöMemory-View MoEÊ®°ÂùóÂåÖÂê´‰∏§‰∏™ÂàÜÊîØÔºö‰∏Ä‰∏™ÈÄöÈÅìÊ≥®ÊÑèÂäõÂàÜÊîØÂíå‰∏Ä‰∏™Á©∫Èó¥Ê≥®ÊÑèÂäõÂàÜÊîØ„ÄÇËøô‰∏§‰∏™ÂàÜÊîØÂàÜÂà´ËÆ°ÁÆóÊØè‰∏™‰∏ìÂÆ∂ÁâπÂæÅÂú®ÈÄöÈÅìÂíåÁ©∫Èó¥Áª¥Â∫¶‰∏äÁöÑÊùÉÈáçÔºåÁÑ∂ÂêéÂ∞ÜËøô‰∫õÊùÉÈáçÂ∫îÁî®‰∫é‰∏ìÂÆ∂ÁâπÂæÅÔºå‰ªéËÄåÂÆûÁé∞Ëá™ÈÄÇÂ∫îÁöÑÁâπÂæÅËûçÂêà„ÄÇÂèåËÆ∞ÂøÜÂ∫ìÁ≥ªÁªüÂåÖÂê´‰∏Ä‰∏™Áü≠ÊúüËÆ∞ÂøÜÂ∫ìÂíå‰∏Ä‰∏™ÈïøÊúüËÆ∞ÂøÜÂ∫ì„ÄÇÁü≠ÊúüËÆ∞ÂøÜÂ∫ìÂ≠òÂÇ®ÊúÄËøëÁöÑÁâπÂæÅÔºåÈïøÊúüËÆ∞ÂøÜÂ∫ìÂ≠òÂÇ®Êõ¥ÈïøÊó∂Èó¥ÁöÑÁâπÂæÅ„ÄÇÈááÁî®Âü∫‰∫éÁõ∏‰ººÂ∫¶ÁöÑÂéãÁº©Á≠ñÁï•ÔºåÂÆöÊúüÊõ¥Êñ∞ÈïøÊúüËÆ∞ÂøÜÂ∫ìÔºå‰ª•‰øùÁïôÂÖ≥ÈîÆÁöÑÈïøÊúü‰ø°ÊÅØÂπ∂Ê∂àÈô§ÂÜó‰Ωô„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

LM-EECÂú®EgoExo4DÂü∫ÂáÜÊµãËØï‰∏äÂèñÂæó‰∫Üstate-of-the-artÁöÑÁªìÊûúÔºåÊòæËëó‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÂíåSAM 2Âü∫Á∫ø„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåLM-EECÂú®Â§ö‰∏™ÊåáÊ†á‰∏äÈÉΩÂèñÂæó‰∫ÜÊòæËëóÊèêÂçáÔºå‰æãÂ¶ÇÂú®ÂàÜÂâ≤Á≤æÂ∫¶‰∏äÊèêÂçá‰∫ÜX%ÔºåÂú®ÂØπÂ∫îÂáÜÁ°ÆÁéá‰∏äÊèêÂçá‰∫ÜY%„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéÔºåLM-EECÂú®Ego-ExoËßÜËßíÂØπÂ∫î‰ªªÂä°‰∏≠ÂÖ∑ÊúâÂº∫Â§ßÁöÑÊ≥õÂåñËÉΩÂäõÂíåÈ≤ÅÊ£íÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊô∫ËÉΩÂä©Êâã„ÄÅÊú∫Âô®‰∫∫ÂØºËà™„ÄÅÂ¢ûÂº∫Áé∞ÂÆûÁ≠âÈ¢ÜÂüü„ÄÇ‰æãÂ¶ÇÔºåÂú®Êô∫ËÉΩÂä©Êâã‰∏≠ÔºåÂèØ‰ª•Â∏ÆÂä©Áî®Êà∑Êõ¥ÂáÜÁ°ÆÂú∞ËØÜÂà´ÂíåÂÆö‰ΩçÁâ©‰ΩìÔºå‰ªéËÄåÊèê‰æõÊõ¥Á≤æÁ°ÆÁöÑËßÜËßâÊåáÂØº„ÄÇÂú®Êú∫Âô®‰∫∫ÂØºËà™‰∏≠ÔºåÂèØ‰ª•Â∏ÆÂä©Êú∫Âô®‰∫∫Êõ¥Â•ΩÂú∞ÁêÜËß£Âë®Âõ¥ÁéØÂ¢ÉÔºå‰ªéËÄåÂÆûÁé∞Êõ¥ÂÆâÂÖ®„ÄÅÊõ¥È´òÊïàÁöÑÂØºËà™„ÄÇÂú®Â¢ûÂº∫Áé∞ÂÆû‰∏≠ÔºåÂèØ‰ª•Â∏ÆÂä©Áî®Êà∑Êõ¥Ëá™ÁÑ∂Âú∞‰∏éËôöÊãüÁâ©‰ΩìËøõË°å‰∫§‰∫í„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Establishing object-level correspondence between egocentric and exocentric views is essential for intelligent assistants to deliver precise and intuitive visual guidance. However, this task faces numerous challenges, including extreme viewpoint variations, occlusions, and the presence of small objects. Existing approaches usually borrow solutions from video object segmentation models, but still suffer from the aforementioned challenges. Recently, the Segment Anything Model 2 (SAM 2) has shown strong generalization capabilities and excellent performance in video object segmentation. Yet, when simply applied to the ego-exo correspondence (EEC) task, SAM 2 encounters severe difficulties due to ineffective ego-exo feature fusion and limited long-term memory capacity, especially for long videos. Addressing these problems, we propose a novel EEC framework based on SAM 2 with long-term memories by presenting a dual-memory architecture and an adaptive feature routing module inspired by Mixture-of-Experts (MoE). Compared to SAM 2, our approach features (i) a Memory-View MoE module which consists of a dual-branch routing mechanism to adaptively assign contribution weights to each expert feature along both channel and spatial dimensions, and (ii) a dual-memory bank system with a simple yet effective compression strategy to retain critical long-term information while eliminating redundancy. In the extensive experiments on the challenging EgoExo4D benchmark, our method, dubbed LM-EEC, achieves new state-of-the-art results and significantly outperforms existing methods and the SAM 2 baseline, showcasing its strong generalization across diverse scenarios. Our code and model are available at https://github.com/juneyeeHu/LM-EEC.

