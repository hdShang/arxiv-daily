---
layout: default
title: Situat3DChange: Situated 3D Change Understanding Dataset for Multimodal Large Language Model
---

# Situat3DChange: Situated 3D Change Understanding Dataset for Multimodal Large Language Model

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.11509" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.11509v1</a>
  <a href="https://arxiv.org/pdf/2510.11509.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.11509v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.11509v1', 'Situat3DChange: Situated 3D Change Understanding Dataset for Multimodal Large Language Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ruiping Liu, Junwei Zheng, Yufan Chen, Zirui Wang, Kunyu Peng, Kailun Yang, Jiaming Zhang, Marc Pollefeys, Rainer Stiefelhagen

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-13

**å¤‡æ³¨**: Accepted to NeurIPS 2025 Datasets and Benchmarks Track. Dataset and Code: https://github.com/RuipingL/Situat3DChange

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSituat3DChangeæ•°æ®é›†ï¼Œç”¨äºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ç†è§£æƒ…å¢ƒåŒ–3Dåœºæ™¯å˜åŒ–**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `3Dåœºæ™¯ç†è§£` `æƒ…å¢ƒæ„ŸçŸ¥` `å¤šæ¨¡æ€å­¦ä¹ ` `å¤§è¯­è¨€æ¨¡å‹` `ç‚¹äº‘å¤„ç†` `æ•°æ®é›†æ„å»º` `æœºå™¨äºº` `äººæœºäº¤äº’`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰3Dæ•°æ®é›†å’Œè¯„ä¼°åŸºå‡†ä¾§é‡äºåŠ¨æ€åœºæ™¯æˆ–åŠ¨æ€æƒ…å¢ƒçš„å­¤ç«‹ç ”ç©¶ï¼Œç¼ºä¹å¯¹æƒ…å¢ƒåŒ–å˜åŒ–çš„å…¨é¢ç†è§£ã€‚
2. è®ºæ–‡æ„å»ºSituat3DChangeæ•°æ®é›†ï¼ŒåŒ…å«é—®ç­”ã€å˜åŒ–æè¿°å’Œé‡æ’æŒ‡ä»¤ï¼Œå¹¶åˆ©ç”¨LLMæ•´åˆå¤šè§†è§’ä¿¡æ¯ï¼Œä¿ƒè¿›äººç±»-AIåä½œã€‚
3. æå‡ºSCReasonerï¼Œä¸€ç§é«˜æ•ˆçš„3D MLLMæ–¹æ³•ï¼Œé€šè¿‡æœ€å°çš„å‚æ•°å¼€é”€å®ç°ç‚¹äº‘æ¯”è¾ƒï¼Œå¹¶åœ¨Situat3DChangeä¸ŠéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†Situat3DChangeï¼Œä¸€ä¸ªå¤§å‹æ•°æ®é›†ï¼Œæ—¨åœ¨æ”¯æŒä¸‰ç§æƒ…å¢ƒæ„ŸçŸ¥çš„å˜åŒ–ç†è§£ä»»åŠ¡ï¼Œéµå¾ªæ„ŸçŸ¥-è¡ŒåŠ¨æ¨¡å‹ã€‚è¯¥æ•°æ®é›†åŒ…å«12.1ä¸‡ä¸ªé—®ç­”å¯¹ã€3.6ä¸‡ä¸ªç”¨äºæ„ŸçŸ¥ä»»åŠ¡çš„å˜åŒ–æè¿°ä»¥åŠ1.7ä¸‡ä¸ªç”¨äºè¡ŒåŠ¨ä»»åŠ¡çš„é‡æ’æŒ‡ä»¤ã€‚Situat3DChangeåˆ©ç”¨äº†1.1ä¸‡ä¸ªäººç±»å¯¹ç¯å¢ƒå˜åŒ–çš„è§‚å¯Ÿï¼Œä»¥å»ºç«‹äººç±»-AIåä½œçš„å…±äº«å¿ƒæ™ºæ¨¡å‹å’Œæƒ…å¢ƒæ„ŸçŸ¥ã€‚è¿™äº›è§‚å¯Ÿç»“æœï¼Œé€šè¿‡è‡ªæˆ‘ä¸­å¿ƒå’Œä»¥åœºæ™¯ä¸ºä¸­å¿ƒçš„è§†è§’ä»¥åŠç±»åˆ«å’Œåæ ‡ç©ºé—´å…³ç³»è¿›è¡Œä¸°å¯Œï¼Œå¹¶ä½¿ç”¨LLMè¿›è¡Œæ•´åˆï¼Œä»¥æ”¯æŒå¯¹æƒ…å¢ƒåŒ–å˜åŒ–çš„ç†è§£ã€‚ä¸ºäº†è§£å†³æ¯”è¾ƒåŒä¸€åœºæ™¯ä¸­å…·æœ‰å¾®å°å˜åŒ–çš„ç‚¹äº‘å¯¹çš„æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„3D MLLMæ–¹æ³•SCReasonerï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿä»¥æœ€å°çš„å‚æ•°å¼€é”€å’Œæ— éœ€è¯­è¨€è§£ç å™¨é¢å¤–tokençš„æ–¹å¼å®ç°æœ‰æ•ˆçš„ç‚¹äº‘æ¯”è¾ƒã€‚åœ¨Situat3DChangeä»»åŠ¡ä¸Šçš„å…¨é¢è¯„ä¼°çªå‡ºäº†MLLMåœ¨åŠ¨æ€åœºæ™¯å’Œæƒ…å¢ƒç†è§£æ–¹é¢çš„è¿›å±•å’Œå±€é™æ€§ã€‚å…³äºæ•°æ®ç¼©æ”¾å’Œè·¨åŸŸè¿ç§»çš„é¢å¤–å®éªŒè¯æ˜äº†ä½¿ç”¨Situat3DChangeä½œä¸ºMLLMè®­ç»ƒæ•°æ®é›†çš„ä»»åŠ¡æ— å…³æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰3Dæ•°æ®é›†éš¾ä»¥å…¨é¢ç†è§£åŠ¨æ€åœºæ™¯ä¸­çš„æƒ…å¢ƒåŒ–å˜åŒ–ï¼Œç¼ºä¹å¯¹åœºæ™¯ä¸­ç‰©ä½“å…³ç³»ã€äººç±»æ„å›¾ç­‰å› ç´ çš„å»ºæ¨¡ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆæ¯”è¾ƒå…·æœ‰å¾®å°å·®å¼‚çš„ç‚¹äº‘ï¼Œå‚æ•°å¼€é”€å¤§ï¼Œæ•ˆç‡ä½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæ„å»ºå¤§è§„æ¨¡æ•°æ®é›†ï¼ŒåŒ…å«å¤šæ¨¡æ€ä¿¡æ¯ï¼ˆç‚¹äº‘ã€æ–‡æœ¬æè¿°ã€æŒ‡ä»¤ç­‰ï¼‰ï¼Œå¹¶åˆ©ç”¨LLMè¿›è¡Œæ•´åˆï¼Œä»è€Œä½¿æ¨¡å‹èƒ½å¤Ÿç†è§£æƒ…å¢ƒåŒ–å˜åŒ–ã€‚è®¾è®¡é«˜æ•ˆçš„3D MLLMæ–¹æ³•ï¼Œç›´æ¥æ¯”è¾ƒç‚¹äº‘ç‰¹å¾ï¼Œé¿å…å¼•å…¥é¢å¤–çš„è¯­è¨€tokenï¼Œé™ä½è®¡ç®—æˆæœ¬ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSituat3DChangeæ•°æ®é›†æ„å»ºæµç¨‹ï¼š1ï¼‰æ”¶é›†äººç±»å¯¹ç¯å¢ƒå˜åŒ–çš„è§‚å¯Ÿï¼›2ï¼‰ä»è‡ªæˆ‘ä¸­å¿ƒå’Œä»¥åœºæ™¯ä¸ºä¸­å¿ƒçš„è§†è§’æå–ç‰¹å¾ï¼›3ï¼‰åˆ©ç”¨LLMæ•´åˆç±»åˆ«å’Œåæ ‡ç©ºé—´å…³ç³»ç­‰ä¿¡æ¯ã€‚SCReasoneræ¨¡å‹æ¶æ„ï¼š1ï¼‰ç‚¹äº‘ç‰¹å¾æå–æ¨¡å—ï¼›2ï¼‰ç‰¹å¾æ¯”è¾ƒæ¨¡å—ï¼›3ï¼‰å¤šæ¨¡æ€èåˆæ¨¡å—ï¼›4ï¼‰ä»»åŠ¡é¢„æµ‹æ¨¡å—ã€‚

**å…³é”®åˆ›æ–°**ï¼š1ï¼‰Situat3DChangeæ•°æ®é›†ï¼šé¦–æ¬¡å…³æ³¨æƒ…å¢ƒåŒ–3Dåœºæ™¯å˜åŒ–ç†è§£ï¼Œæä¾›ä¸°å¯Œçš„å¤šæ¨¡æ€æ•°æ®ã€‚2ï¼‰SCReasoneræ¨¡å‹ï¼šé«˜æ•ˆçš„ç‚¹äº‘æ¯”è¾ƒæ–¹æ³•ï¼Œæ— éœ€é¢å¤–è¯­è¨€tokenï¼Œé™ä½è®¡ç®—æˆæœ¬ã€‚

**å…³é”®è®¾è®¡**ï¼šSituat3DChangeæ•°æ®é›†åŒ…å«ä¸‰ç§ä»»åŠ¡ï¼šé—®ç­”ã€å˜åŒ–æè¿°å’Œé‡æ’æŒ‡ä»¤ã€‚SCReasoneræ¨¡å‹ä½¿ç”¨å¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°ï¼Œé¼“åŠ±æ¨¡å‹å­¦ä¹ åŒºåˆ†ç›¸ä¼¼å’Œä¸åŒçš„ç‚¹äº‘ç‰¹å¾ã€‚å…·ä½“ç½‘ç»œç»“æ„å’Œå‚æ•°è®¾ç½®åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ï¼Œæ­¤å¤„æœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨Situat3DChangeæ•°æ®é›†ä¸Šè¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œç»“æœè¡¨æ˜æå‡ºçš„SCReasoneræ¨¡å‹åœ¨ç‚¹äº‘æ¯”è¾ƒä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œå‚æ•°å¼€é”€å°ï¼Œæ•ˆç‡é«˜ã€‚æ•°æ®ç¼©æ”¾å®éªŒè¡¨æ˜ï¼Œä½¿ç”¨Situat3DChangeä½œä¸ºè®­ç»ƒæ•°æ®é›†å¯ä»¥æœ‰æ•ˆæå‡MLLMçš„æ€§èƒ½ã€‚è·¨åŸŸè¿ç§»å®éªŒéªŒè¯äº†Situat3DChangeæ•°æ®é›†çš„ä»»åŠ¡æ— å…³æœ‰æ•ˆæ€§ï¼Œè¡¨æ˜å…¶å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚å…·ä½“æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ï¼Œæ­¤å¤„æœªçŸ¥ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæœºå™¨äººå¯¼èˆªã€æ™ºèƒ½å®¶å±…ã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸã€‚é€šè¿‡ç†è§£ç¯å¢ƒå˜åŒ–å’Œäººç±»æ„å›¾ï¼Œæœºå™¨äººå¯ä»¥æ›´å¥½åœ°é€‚åº”åŠ¨æ€ç¯å¢ƒï¼Œæ‰§è¡Œå¤æ‚ä»»åŠ¡ï¼Œä¾‹å¦‚ç‰©ä½“é‡æ’ã€åœºæ™¯é‡å»ºå’Œäººæœºåä½œã€‚è¯¥æ•°æ®é›†å’Œæ¨¡å‹ä¹Ÿæœ‰åŠ©äºæå‡è™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®åº”ç”¨çš„çœŸå®æ„Ÿå’Œäº¤äº’æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Physical environments and circumstances are fundamentally dynamic, yet current 3D datasets and evaluation benchmarks tend to concentrate on either dynamic scenarios or dynamic situations in isolation, resulting in incomplete comprehension. To overcome these constraints, we introduce Situat3DChange, an extensive dataset supporting three situation-aware change understanding tasks following the perception-action model: 121K question-answer pairs, 36K change descriptions for perception tasks, and 17K rearrangement instructions for the action task. To construct this large-scale dataset, Situat3DChange leverages 11K human observations of environmental changes to establish shared mental models and shared situational awareness for human-AI collaboration. These observations, enriched with egocentric and allocentric perspectives as well as categorical and coordinate spatial relations, are integrated using an LLM to support understanding of situated changes. To address the challenge of comparing pairs of point clouds from the same scene with minor changes, we propose SCReasoner, an efficient 3D MLLM approach that enables effective point cloud comparison with minimal parameter overhead and no additional tokens required for the language decoder. Comprehensive evaluation on Situat3DChange tasks highlights both the progress and limitations of MLLMs in dynamic scene and situation understanding. Additional experiments on data scaling and cross-domain transfer demonstrate the task-agnostic effectiveness of using Situat3DChange as a training dataset for MLLMs.

