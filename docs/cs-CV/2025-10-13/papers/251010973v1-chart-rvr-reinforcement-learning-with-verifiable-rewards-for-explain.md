---
layout: default
title: Chart-RVR: Reinforcement Learning with Verifiable Rewards for Explainable Chart Reasoning
---

# Chart-RVR: Reinforcement Learning with Verifiable Rewards for Explainable Chart Reasoning

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.10973" target="_blank" class="toolbar-btn">arXiv: 2510.10973v1</a>
    <a href="https://arxiv.org/pdf/2510.10973.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.10973v1" 
            onclick="toggleFavorite(this, '2510.10973v1', 'Chart-RVR: Reinforcement Learning with Verifiable Rewards for Explainable Chart Reasoning')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Sanchit Sinha, Oana Frunza, Kashif Rasul, Yuriy Nevmyvaka, Aidong Zhang

**ÂàÜÁ±ª**: cs.CV, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-13

**Â§áÊ≥®**: 23 pages

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Chart-RVRÊ°ÜÊû∂ÔºåÈÄöËøáÂèØÈ™åËØÅÂ•ñÂä±ÁöÑÂº∫ÂåñÂ≠¶‰π†ÊèêÂçáÂõæË°®Êé®ÁêÜÁöÑÂèØËß£ÈáäÊÄßÂíåÈ≤ÅÊ£íÊÄß**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÂõæË°®Êé®ÁêÜ` `ËßÜËßâËØ≠Ë®ÄÊ®°Âûã` `Âº∫ÂåñÂ≠¶‰π†` `ÂèØËß£ÈáäÊÄß` `Áæ§‰ΩìÁõ∏ÂØπÁ≠ñÁï•‰ºòÂåñ` `ÂèØÈ™åËØÅÂ•ñÂä±` `ÂàÜÂ∏ÉÂ§ñÊ≥õÂåñ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâLVLMsÂú®ÂõæË°®Êé®ÁêÜ‰∏≠Â≠òÂú®OODÊ≥õÂåñÊÄßÂ∑ÆÔºå‰∏îCoTÊé®ÁêÜÂèØËß£ÈáäÊÄß‰∏çË∂≥ÁöÑÈóÆÈ¢ò„ÄÇ
2. Chart-RVRÊ°ÜÊû∂ÁªìÂêàGRPO‰∏éÂèØÈ™åËØÅÂ•ñÂä±ÔºåÂæÆË∞ÉLVLMs‰ª•ÊèêÂçáÂõæË°®Êé®ÁêÜÁöÑÈ≤ÅÊ£íÊÄßÂíåÂèØËß£ÈáäÊÄß„ÄÇ
3. ÂÆûÈ™åË°®ÊòéChart-RVRÂú®Â§ö‰∏™ÂõæË°®Êé®ÁêÜÂü∫ÂáÜ‰∏äË∂ÖË∂äSFTÔºåÁº©Â∞èOODÊÄßËÉΩÂ∑ÆË∑ùÔºåÂπ∂ÊèêÂçáÊé®ÁêÜ‰øùÁúüÂ∫¶„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§ßÂûãËßÜËßâËØ≠Ë®ÄÊ®°Âûã(LVLMs)Âú®ËÆ∏Â§öËßÜËßâÊé®ÁêÜ‰ªªÂä°ÔºàÂåÖÊã¨ÂõæË°®Êé®ÁêÜÔºâ‰∏äËææÂà∞‰∫ÜÊúÄÂÖàËøõÁöÑÊ∞¥Âπ≥Ôºå‰ΩÜÂÆÉ‰ª¨Âú®ÂàÜÂ∏ÉÂ§ñ(OOD)Êï∞ÊçÆ‰∏ä‰ªçÁÑ∂Ë°®Áé∞‰∏ç‰Ω≥ÔºåÂπ∂‰∏îÂú®Ë¢´Ë¶ÅÊ±ÇÁîüÊàêÊÄùÁª¥Èìæ(CoT)Êé®ÁêÜÊó∂ÊÄßËÉΩËøõ‰∏ÄÊ≠•‰∏ãÈôçÔºåÈôêÂà∂‰∫ÜËß£ÈáäÊÄß„ÄÇÊú¨ÊñáÊèêÂá∫‰∫ÜChart-RVRÔºå‰∏Ä‰∏™ÈÄöÁî®Ê°ÜÊû∂ÔºåÈÄöËøáÂ∞ÜÁæ§‰ΩìÁõ∏ÂØπÁ≠ñÁï•‰ºòÂåñ(GRPO)‰∏éËá™Âä®ÂèØÈ™åËØÅÂ•ñÂä±Áõ∏ÁªìÂêàÔºåÂØπLVLMsËøõË°åÂæÆË∞ÉÔºå‰ΩøÂÖ∂Âú®ÂõæË°®Êé®ÁêÜÊñπÈù¢Êõ¥ÂÖ∑È≤ÅÊ£íÊÄßÂíåÂèØËß£ÈáäÊÄß„ÄÇËØ•Ê°ÜÊû∂ÂåÖÂê´‰∏â‰∏™Â•ñÂä±Ôºå‰ª•ÊúÄÂ§ßÂåñÔºö(i)Ê≠£Á°ÆÁöÑÂõæË°®Á±ªÂûãÂàÜÁ±ªÔºå(ii)Âø†ÂÆûÁöÑÂõæË°®Ë°®Ê†ºÈáçÂª∫Ôºå‰ª•Âèä(iii)ËøáÁ®ã‰∏ÄËá¥ÊÄß„ÄÇÂ∫îÁî®‰∫é30‰∫øÂèÇÊï∞ÁöÑLVLMsÔºåChart-RVRÂú®ÂêåÂàÜÂ∏ÉÂíåÂàÜÂ∏ÉÂ§ñÊï∞ÊçÆÈõÜ‰∏äÂßãÁªà‰ºò‰∫éÊ†áÂáÜÁõëÁù£ÂæÆË∞É(SFT)ÔºåÁº©Â∞è‰∫ÜOODÊÄßËÉΩÂ∑ÆË∑ùÔºåÂêåÊó∂ÊèêÈ´ò‰∫ÜÊé®ÁêÜÁöÑ‰øùÁúüÂ∫¶„ÄÇÁî±Ê≠§‰∫ßÁîüÁöÑÊ®°ÂûãChart-RVR-3BÁ≥ªÂàóÂú®Ê∂µÁõñÂêåÂàÜÂ∏ÉÂíåOODËÆæÁΩÆÁöÑÂÖ≠‰∏™ÂõæË°®Êé®ÁêÜÂü∫ÂáÜ‰∏äÂèñÂæó‰∫ÜÊúÄÂÖàËøõÁöÑÁªìÊûúÔºåË∂ÖËøá‰∫ÜÊâÄÊúâÁé∞ÊúâÂêåÁ≠âËßÑÊ®°ÁöÑÊ®°Âûã„ÄÇÈô§‰∫ÜÂáÜÁ°ÆÊÄß‰πãÂ§ñÔºåChart-RVRËøò‰∫ßÁîü‰∫ÜÊõ¥Êòì‰∫éËß£ÈáäÁöÑCoTÊé®ÁêÜÔºåÂ¢ûÂº∫‰∫Ü‰ø°‰ªªÂíåÂèØÈù†ÊÄß‚Äî‚ÄîÂ±ïÁ§∫‰∫ÜÂèØÈ™åËØÅÂ•ñÂä±‰∏éGRPOÂú®ËÆ≠ÁªÉÂèØÈù†„ÄÅÂèØËß£ÈáäÁöÑÂõæË°®Êé®ÁêÜÊ®°ÂûãÊñπÈù¢ÁöÑÂº∫Â§ßÂäüËÉΩ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Â§ßÂûãËßÜËßâËØ≠Ë®ÄÊ®°Âûã(LVLMs)Âú®ÂõæË°®Êé®ÁêÜ‰ªªÂä°‰∏≠ÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂàÜÂ∏ÉÂ§ñ(OOD)Êï∞ÊçÆ‰∏äÁöÑÊ≥õÂåñËÉΩÂäõ‰∏çË∂≥Ôºå‰ª•ÂèäÁîüÊàêÊÄùÁª¥Èìæ(CoT)Êé®ÁêÜÊó∂ÂèØËß£ÈáäÊÄßËæÉÂ∑ÆÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÔºåÂ¶ÇÁõëÁù£ÂæÆË∞É(SFT)ÔºåÈöæ‰ª•‰øùËØÅÊ®°ÂûãÂú®Èù¢ÂØπÊñ∞È¢ñÂõæË°®Êó∂ÁöÑÂáÜÁ°ÆÊÄßÂíåÂèØÈù†ÊÄßÔºåÂπ∂‰∏îÁº∫‰πèÂØπÊ®°ÂûãÊé®ÁêÜËøáÁ®ãÁöÑÊúâÊïàÁõëÁù£ÔºåÂØºËá¥Ëß£ÈáäÊÄß‰∏çË∂≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜÂº∫ÂåñÂ≠¶‰π†‰∏éÂèØÈ™åËØÅÂ•ñÂä±Áõ∏ÁªìÂêàÔºåÂà©Áî®Áæ§‰ΩìÁõ∏ÂØπÁ≠ñÁï•‰ºòÂåñ(GRPO)Êù•ÂæÆË∞ÉLVLMs„ÄÇÈÄöËøáËÆæËÆ°Â§ö‰∏™ÂèØÈ™åËØÅÁöÑÂ•ñÂä±ÂáΩÊï∞ÔºåÂºïÂØºÊ®°ÂûãÂ≠¶‰π†Ê≠£Á°ÆÁöÑÂõæË°®Á±ªÂûãÂàÜÁ±ª„ÄÅÂø†ÂÆûÁöÑÂõæË°®Ë°®Ê†ºÈáçÂª∫‰ª•ÂèäËøáÁ®ã‰∏ÄËá¥ÊÄß„ÄÇËøôÁßçÊñπÊ≥ïÊó®Âú®ÊèêÈ´òÊ®°ÂûãÂú®OODÊï∞ÊçÆ‰∏äÁöÑÈ≤ÅÊ£íÊÄßÔºåÂπ∂ÁîüÊàêÊõ¥Êòì‰∫éÁêÜËß£Âíå‰ø°‰ªªÁöÑCoTÊé®ÁêÜ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöChart-RVRÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Ê®°ÂùóÔºö1) LVLM backboneÔºö‰ΩøÁî®È¢ÑËÆ≠ÁªÉÁöÑLVLM‰Ωú‰∏∫Âü∫Á°ÄÊ®°Âûã„ÄÇ2) GRPOÔºöÂà©Áî®Áæ§‰ΩìÁõ∏ÂØπÁ≠ñÁï•‰ºòÂåñÁÆóÊ≥ïËøõË°åÊ®°ÂûãÂæÆË∞É„ÄÇ3) ÂèØÈ™åËØÅÂ•ñÂä±ÂáΩÊï∞ÔºöÂåÖÊã¨ÂõæË°®Á±ªÂûãÂàÜÁ±ªÂ•ñÂä±„ÄÅÂõæË°®Ë°®Ê†ºÈáçÂª∫Â•ñÂä±ÂíåËøáÁ®ã‰∏ÄËá¥ÊÄßÂ•ñÂä±„ÄÇÊï¥‰ΩìÊµÅÁ®ãÊòØÔºöËæìÂÖ•ÂõæË°®ÂõæÂÉèÔºåLVLMÁîüÊàêCoTÊé®ÁêÜÔºåÁÑ∂ÂêéÊ†πÊçÆÂ•ñÂä±ÂáΩÊï∞ËÆ°ÁÆóÂ•ñÂä±ÂÄºÔºåGRPOÂà©Áî®Â•ñÂä±ÂÄºÊõ¥Êñ∞Ê®°ÂûãÂèÇÊï∞„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫Ü‰∏Ä‰∏™Âü∫‰∫éÂèØÈ™åËØÅÂ•ñÂä±ÁöÑÂº∫ÂåñÂ≠¶‰π†Ê°ÜÊû∂ÔºåÁî®‰∫éÊèêÂçáLVLMsÂú®ÂõæË°®Êé®ÁêÜ‰∏≠ÁöÑÊÄßËÉΩÂíåÂèØËß£ÈáäÊÄß„ÄÇ‰∏é‰º†ÁªüÁöÑÁõëÁù£Â≠¶‰π†ÊñπÊ≥ï‰∏çÂêåÔºåChart-RVRÈÄöËøáÂ•ñÂä±ÂáΩÊï∞Áõ¥Êé•ÁõëÁù£Ê®°ÂûãÁöÑÊé®ÁêÜËøáÁ®ãÔºåÈºìÂä±Ê®°ÂûãÁîüÊàêÊõ¥ÂáÜÁ°Æ„ÄÅÊõ¥ÂèØÈù†ÁöÑCoTÊé®ÁêÜ„ÄÇÊ≠§Â§ñÔºåGRPOÁöÑ‰ΩøÁî®ÊúâÂä©‰∫éÊèêÈ´òÊ®°ÂûãÁöÑÊé¢Á¥¢ËÉΩÂäõÔºå‰ªéËÄåÊõ¥Â•ΩÂú∞Â∫îÂØπOODÊï∞ÊçÆ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËÆ∫ÊñáËÆæËÆ°‰∫Ü‰∏â‰∏™ÂÖ≥ÈîÆÁöÑÂ•ñÂä±ÂáΩÊï∞Ôºö1) ÂõæË°®Á±ªÂûãÂàÜÁ±ªÂ•ñÂä±ÔºöË°°ÈáèÊ®°ÂûãÈ¢ÑÊµãÁöÑÂõæË°®Á±ªÂûãÊòØÂê¶Ê≠£Á°Æ„ÄÇ2) ÂõæË°®Ë°®Ê†ºÈáçÂª∫Â•ñÂä±ÔºöË°°ÈáèÊ®°Âûã‰ªéÂõæË°®‰∏≠ÊèêÂèñÁöÑË°®Ê†ºÊï∞ÊçÆ‰∏éÁúüÂÆûÂÄº‰πãÈó¥ÁöÑÂ∑ÆÂºÇ„ÄÇ3) ËøáÁ®ã‰∏ÄËá¥ÊÄßÂ•ñÂä±ÔºöË°°ÈáèÊ®°ÂûãÁöÑÊé®ÁêÜËøáÁ®ãÊòØÂê¶Á¨¶ÂêàÈ¢ÑÂÆö‰πâÁöÑËßÑÂàôÂíåÁ∫¶Êùü„ÄÇËøô‰∫õÂ•ñÂä±ÂáΩÊï∞ÂÖ±ÂêåÂºïÂØºÊ®°ÂûãÂ≠¶‰π†Êõ¥ÂáÜÁ°Æ„ÄÅÊõ¥ÂèØÈù†ÁöÑÂõæË°®Êé®ÁêÜËÉΩÂäõ„ÄÇÂÖ∑‰ΩìÂÆûÁé∞‰∏äÔºåÂ•ñÂä±ÂáΩÊï∞ÂèØ‰ª•‰ΩøÁî®‰∫§ÂèâÁÜµÊçüÂ§±„ÄÅÂùáÊñπËØØÂ∑ÆÁ≠âÂ∏∏ËßÅÁöÑÊçüÂ§±ÂáΩÊï∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Chart-RVRÂú®ÂÖ≠‰∏™ÂõæË°®Êé®ÁêÜÂü∫ÂáÜ‰∏äÂèñÂæó‰∫ÜÊúÄÂÖàËøõÁöÑÁªìÊûúÔºåË∂ÖË∂ä‰∫ÜÊâÄÊúâÁé∞ÊúâÂêåÁ≠âËßÑÊ®°ÁöÑÊ®°Âûã„ÄÇÂú®OODÊï∞ÊçÆÈõÜ‰∏äÔºåChart-RVRÊòæËëóÁº©Â∞è‰∫Ü‰∏éÂêåÂàÜÂ∏ÉÊï∞ÊçÆÈõÜ‰πãÈó¥ÁöÑÊÄßËÉΩÂ∑ÆË∑ùÔºåË°®ÊòéÂÖ∂ÂÖ∑ÊúâÊõ¥Âº∫ÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåChart-RVRÁîüÊàêÁöÑCoTÊé®ÁêÜÊõ¥Êòì‰∫éËß£ÈáäÔºåÊèêÈ´ò‰∫ÜÊ®°ÂûãÁöÑÂèØ‰ø°Â∫¶„ÄÇ‰æãÂ¶ÇÔºåÂú®Êüê‰∏™Âü∫ÂáÜÊµãËØï‰∏≠ÔºåChart-RVRÁöÑÂáÜÁ°ÆÁéáÊØîSFTÊèêÈ´ò‰∫Ü10%‰ª•‰∏ä„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

Chart-RVRÊ°ÜÊû∂ÂèØÂ∫îÁî®‰∫éÈáëËûçÊä•ÂëäÂàÜÊûê„ÄÅÁßëÂ≠¶Êï∞ÊçÆÂèØËßÜÂåñ„ÄÅÂïÜ‰∏öÊô∫ËÉΩÁ≠âÈ¢ÜÂüüÔºåÂ∏ÆÂä©Áî®Êà∑Êõ¥ÂáÜÁ°ÆÂú∞ÁêÜËß£ÂíåÂàÜÊûêÂõæË°®Êï∞ÊçÆ„ÄÇËØ•Á†îÁ©∂ÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂú®‰∫éÊèêÈ´ò‰∫ÜÂõæË°®Êé®ÁêÜÁ≥ªÁªüÁöÑÂèØÈù†ÊÄßÂíåÂèØËß£ÈáäÊÄßÔºåÂ¢ûÂº∫‰∫ÜÁî®Êà∑ÂØπAIÁ≥ªÁªüÁöÑ‰ø°‰ªª„ÄÇÊú™Êù•ÔºåËØ•Ê°ÜÊû∂ÂèØ‰ª•Êâ©Â±ïÂà∞ÂÖ∂‰ªñËßÜËßâÊé®ÁêÜ‰ªªÂä°ÔºåÂπ∂‰∏éÂÖ∂‰ªñÊäÄÊúØÔºàÂ¶ÇÁü•ËØÜÂõæË∞±ÔºâÁõ∏ÁªìÂêàÔºå‰ª•ÂÆûÁé∞Êõ¥È´òÁ∫ßÁöÑÊô∫ËÉΩÂàÜÊûê„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> The capabilities of Large Vision-Language Models (LVLMs) have reached state-of-the-art on many visual reasoning tasks, including chart reasoning, yet they still falter on out-of-distribution (OOD) data, and degrade further when asked to produce their chain-of-thought (CoT) rationales, limiting explainability. We present Chart-RVR, a general framework that fine-tunes LVLMs to be more robust and explainable for chart reasoning by coupling Group Relative Policy Optimization (GRPO) with automatically verifiable rewards. Our framework comprises of three rewards that maximize: (i) correct chart-type classification, (ii) faithful chart table reconstruction, and (iii) process conformity. Applied to 3-billion-parameter LVLMs, Chart-RVR consistently outperforms standard supervised fine-tuning (SFT) on both in-distribution and out-of-distribution datasets, closing the OOD performance gap while improving rationale fidelity. The resulting models, the Chart-RVR-3B series, achieve state-of-the-art results on six chart-reasoning benchmarks spanning in-domain and OOD settings, surpassing all existing models of comparable size. Beyond accuracy, Chart-RVR yields more interpretable CoT rationales, strengthening trust and reliability - showcasing the power of verifiable rewards with GRPO for training reliable, interpretable chart-reasoning models.

