---
layout: default
title: "Chart-RVR: Reinforcement Learning with Verifiable Rewards for Explainable Chart Reasoning"
---

# Chart-RVR: Reinforcement Learning with Verifiable Rewards for Explainable Chart Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.10973" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.10973v1</a>
  <a href="https://arxiv.org/pdf/2510.10973.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.10973v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.10973v1', 'Chart-RVR: Reinforcement Learning with Verifiable Rewards for Explainable Chart Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sanchit Sinha, Oana Frunza, Kashif Rasul, Yuriy Nevmyvaka, Aidong Zhang

**åˆ†ç±»**: cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-10-13

**å¤‡æ³¨**: 23 pages

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºChart-RVRæ¡†æ¶ï¼Œé€šè¿‡å¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ æå‡å›¾è¡¨æ¨ç†çš„å¯è§£é‡Šæ€§å’Œé²æ£’æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å›¾è¡¨æ¨ç†` `è§†è§‰è¯­è¨€æ¨¡å‹` `å¼ºåŒ–å­¦ä¹ ` `å¯è§£é‡Šæ€§` `ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–` `å¯éªŒè¯å¥–åŠ±` `åˆ†å¸ƒå¤–æ³›åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LVLMsåœ¨å›¾è¡¨æ¨ç†ä¸­å­˜åœ¨OODæ³›åŒ–æ€§å·®ï¼Œä¸”CoTæ¨ç†å¯è§£é‡Šæ€§ä¸è¶³çš„é—®é¢˜ã€‚
2. Chart-RVRæ¡†æ¶ç»“åˆGRPOä¸å¯éªŒè¯å¥–åŠ±ï¼Œå¾®è°ƒLVLMsä»¥æå‡å›¾è¡¨æ¨ç†çš„é²æ£’æ€§å’Œå¯è§£é‡Šæ€§ã€‚
3. å®éªŒè¡¨æ˜Chart-RVRåœ¨å¤šä¸ªå›¾è¡¨æ¨ç†åŸºå‡†ä¸Šè¶…è¶ŠSFTï¼Œç¼©å°OODæ€§èƒ½å·®è·ï¼Œå¹¶æå‡æ¨ç†ä¿çœŸåº¦ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹(LVLMs)åœ¨è®¸å¤šè§†è§‰æ¨ç†ä»»åŠ¡ï¼ˆåŒ…æ‹¬å›¾è¡¨æ¨ç†ï¼‰ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ°´å¹³ï¼Œä½†å®ƒä»¬åœ¨åˆ†å¸ƒå¤–(OOD)æ•°æ®ä¸Šä»ç„¶è¡¨ç°ä¸ä½³ï¼Œå¹¶ä¸”åœ¨è¢«è¦æ±‚ç”Ÿæˆæ€ç»´é“¾(CoT)æ¨ç†æ—¶æ€§èƒ½è¿›ä¸€æ­¥ä¸‹é™ï¼Œé™åˆ¶äº†è§£é‡Šæ€§ã€‚æœ¬æ–‡æå‡ºäº†Chart-RVRï¼Œä¸€ä¸ªé€šç”¨æ¡†æ¶ï¼Œé€šè¿‡å°†ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–(GRPO)ä¸è‡ªåŠ¨å¯éªŒè¯å¥–åŠ±ç›¸ç»“åˆï¼Œå¯¹LVLMsè¿›è¡Œå¾®è°ƒï¼Œä½¿å…¶åœ¨å›¾è¡¨æ¨ç†æ–¹é¢æ›´å…·é²æ£’æ€§å’Œå¯è§£é‡Šæ€§ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸‰ä¸ªå¥–åŠ±ï¼Œä»¥æœ€å¤§åŒ–ï¼š(i)æ­£ç¡®çš„å›¾è¡¨ç±»å‹åˆ†ç±»ï¼Œ(ii)å¿ å®çš„å›¾è¡¨è¡¨æ ¼é‡å»ºï¼Œä»¥åŠ(iii)è¿‡ç¨‹ä¸€è‡´æ€§ã€‚åº”ç”¨äº30äº¿å‚æ•°çš„LVLMsï¼ŒChart-RVRåœ¨åŒåˆ†å¸ƒå’Œåˆ†å¸ƒå¤–æ•°æ®é›†ä¸Šå§‹ç»ˆä¼˜äºæ ‡å‡†ç›‘ç£å¾®è°ƒ(SFT)ï¼Œç¼©å°äº†OODæ€§èƒ½å·®è·ï¼ŒåŒæ—¶æé«˜äº†æ¨ç†çš„ä¿çœŸåº¦ã€‚ç”±æ­¤äº§ç”Ÿçš„æ¨¡å‹Chart-RVR-3Bç³»åˆ—åœ¨æ¶µç›–åŒåˆ†å¸ƒå’ŒOODè®¾ç½®çš„å…­ä¸ªå›¾è¡¨æ¨ç†åŸºå‡†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œè¶…è¿‡äº†æ‰€æœ‰ç°æœ‰åŒç­‰è§„æ¨¡çš„æ¨¡å‹ã€‚é™¤äº†å‡†ç¡®æ€§ä¹‹å¤–ï¼ŒChart-RVRè¿˜äº§ç”Ÿäº†æ›´æ˜“äºè§£é‡Šçš„CoTæ¨ç†ï¼Œå¢å¼ºäº†ä¿¡ä»»å’Œå¯é æ€§â€”â€”å±•ç¤ºäº†å¯éªŒè¯å¥–åŠ±ä¸GRPOåœ¨è®­ç»ƒå¯é ã€å¯è§£é‡Šçš„å›¾è¡¨æ¨ç†æ¨¡å‹æ–¹é¢çš„å¼ºå¤§åŠŸèƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹(LVLMs)åœ¨å›¾è¡¨æ¨ç†ä»»åŠ¡ä¸­ï¼Œå°¤å…¶æ˜¯åœ¨åˆ†å¸ƒå¤–(OOD)æ•°æ®ä¸Šçš„æ³›åŒ–èƒ½åŠ›ä¸è¶³ï¼Œä»¥åŠç”Ÿæˆæ€ç»´é“¾(CoT)æ¨ç†æ—¶å¯è§£é‡Šæ€§è¾ƒå·®çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚ç›‘ç£å¾®è°ƒ(SFT)ï¼Œéš¾ä»¥ä¿è¯æ¨¡å‹åœ¨é¢å¯¹æ–°é¢–å›¾è¡¨æ—¶çš„å‡†ç¡®æ€§å’Œå¯é æ€§ï¼Œå¹¶ä¸”ç¼ºä¹å¯¹æ¨¡å‹æ¨ç†è¿‡ç¨‹çš„æœ‰æ•ˆç›‘ç£ï¼Œå¯¼è‡´è§£é‡Šæ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†å¼ºåŒ–å­¦ä¹ ä¸å¯éªŒè¯å¥–åŠ±ç›¸ç»“åˆï¼Œåˆ©ç”¨ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–(GRPO)æ¥å¾®è°ƒLVLMsã€‚é€šè¿‡è®¾è®¡å¤šä¸ªå¯éªŒè¯çš„å¥–åŠ±å‡½æ•°ï¼Œå¼•å¯¼æ¨¡å‹å­¦ä¹ æ­£ç¡®çš„å›¾è¡¨ç±»å‹åˆ†ç±»ã€å¿ å®çš„å›¾è¡¨è¡¨æ ¼é‡å»ºä»¥åŠè¿‡ç¨‹ä¸€è‡´æ€§ã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨æé«˜æ¨¡å‹åœ¨OODæ•°æ®ä¸Šçš„é²æ£’æ€§ï¼Œå¹¶ç”Ÿæˆæ›´æ˜“äºç†è§£å’Œä¿¡ä»»çš„CoTæ¨ç†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šChart-RVRæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) LVLM backboneï¼šä½¿ç”¨é¢„è®­ç»ƒçš„LVLMä½œä¸ºåŸºç¡€æ¨¡å‹ã€‚2) GRPOï¼šåˆ©ç”¨ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ç®—æ³•è¿›è¡Œæ¨¡å‹å¾®è°ƒã€‚3) å¯éªŒè¯å¥–åŠ±å‡½æ•°ï¼šåŒ…æ‹¬å›¾è¡¨ç±»å‹åˆ†ç±»å¥–åŠ±ã€å›¾è¡¨è¡¨æ ¼é‡å»ºå¥–åŠ±å’Œè¿‡ç¨‹ä¸€è‡´æ€§å¥–åŠ±ã€‚æ•´ä½“æµç¨‹æ˜¯ï¼šè¾“å…¥å›¾è¡¨å›¾åƒï¼ŒLVLMç”ŸæˆCoTæ¨ç†ï¼Œç„¶åæ ¹æ®å¥–åŠ±å‡½æ•°è®¡ç®—å¥–åŠ±å€¼ï¼ŒGRPOåˆ©ç”¨å¥–åŠ±å€¼æ›´æ–°æ¨¡å‹å‚æ•°ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ä¸ªåŸºäºå¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºæå‡LVLMsåœ¨å›¾è¡¨æ¨ç†ä¸­çš„æ€§èƒ½å’Œå¯è§£é‡Šæ€§ã€‚ä¸ä¼ ç»Ÿçš„ç›‘ç£å­¦ä¹ æ–¹æ³•ä¸åŒï¼ŒChart-RVRé€šè¿‡å¥–åŠ±å‡½æ•°ç›´æ¥ç›‘ç£æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ï¼Œé¼“åŠ±æ¨¡å‹ç”Ÿæˆæ›´å‡†ç¡®ã€æ›´å¯é çš„CoTæ¨ç†ã€‚æ­¤å¤–ï¼ŒGRPOçš„ä½¿ç”¨æœ‰åŠ©äºæé«˜æ¨¡å‹çš„æ¢ç´¢èƒ½åŠ›ï¼Œä»è€Œæ›´å¥½åœ°åº”å¯¹OODæ•°æ®ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡è®¾è®¡äº†ä¸‰ä¸ªå…³é”®çš„å¥–åŠ±å‡½æ•°ï¼š1) å›¾è¡¨ç±»å‹åˆ†ç±»å¥–åŠ±ï¼šè¡¡é‡æ¨¡å‹é¢„æµ‹çš„å›¾è¡¨ç±»å‹æ˜¯å¦æ­£ç¡®ã€‚2) å›¾è¡¨è¡¨æ ¼é‡å»ºå¥–åŠ±ï¼šè¡¡é‡æ¨¡å‹ä»å›¾è¡¨ä¸­æå–çš„è¡¨æ ¼æ•°æ®ä¸çœŸå®å€¼ä¹‹é—´çš„å·®å¼‚ã€‚3) è¿‡ç¨‹ä¸€è‡´æ€§å¥–åŠ±ï¼šè¡¡é‡æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹æ˜¯å¦ç¬¦åˆé¢„å®šä¹‰çš„è§„åˆ™å’Œçº¦æŸã€‚è¿™äº›å¥–åŠ±å‡½æ•°å…±åŒå¼•å¯¼æ¨¡å‹å­¦ä¹ æ›´å‡†ç¡®ã€æ›´å¯é çš„å›¾è¡¨æ¨ç†èƒ½åŠ›ã€‚å…·ä½“å®ç°ä¸Šï¼Œå¥–åŠ±å‡½æ•°å¯ä»¥ä½¿ç”¨äº¤å‰ç†µæŸå¤±ã€å‡æ–¹è¯¯å·®ç­‰å¸¸è§çš„æŸå¤±å‡½æ•°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

Chart-RVRåœ¨å…­ä¸ªå›¾è¡¨æ¨ç†åŸºå‡†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œè¶…è¶Šäº†æ‰€æœ‰ç°æœ‰åŒç­‰è§„æ¨¡çš„æ¨¡å‹ã€‚åœ¨OODæ•°æ®é›†ä¸Šï¼ŒChart-RVRæ˜¾è‘—ç¼©å°äº†ä¸åŒåˆ†å¸ƒæ•°æ®é›†ä¹‹é—´çš„æ€§èƒ½å·®è·ï¼Œè¡¨æ˜å…¶å…·æœ‰æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒChart-RVRç”Ÿæˆçš„CoTæ¨ç†æ›´æ˜“äºè§£é‡Šï¼Œæé«˜äº†æ¨¡å‹çš„å¯ä¿¡åº¦ã€‚ä¾‹å¦‚ï¼Œåœ¨æŸä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒChart-RVRçš„å‡†ç¡®ç‡æ¯”SFTæé«˜äº†10%ä»¥ä¸Šã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Chart-RVRæ¡†æ¶å¯åº”ç”¨äºé‡‘èæŠ¥å‘Šåˆ†æã€ç§‘å­¦æ•°æ®å¯è§†åŒ–ã€å•†ä¸šæ™ºèƒ½ç­‰é¢†åŸŸï¼Œå¸®åŠ©ç”¨æˆ·æ›´å‡†ç¡®åœ°ç†è§£å’Œåˆ†æå›¾è¡¨æ•°æ®ã€‚è¯¥ç ”ç©¶çš„å®é™…ä»·å€¼åœ¨äºæé«˜äº†å›¾è¡¨æ¨ç†ç³»ç»Ÿçš„å¯é æ€§å’Œå¯è§£é‡Šæ€§ï¼Œå¢å¼ºäº†ç”¨æˆ·å¯¹AIç³»ç»Ÿçš„ä¿¡ä»»ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶å¯ä»¥æ‰©å±•åˆ°å…¶ä»–è§†è§‰æ¨ç†ä»»åŠ¡ï¼Œå¹¶ä¸å…¶ä»–æŠ€æœ¯ï¼ˆå¦‚çŸ¥è¯†å›¾è°±ï¼‰ç›¸ç»“åˆï¼Œä»¥å®ç°æ›´é«˜çº§çš„æ™ºèƒ½åˆ†æã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The capabilities of Large Vision-Language Models (LVLMs) have reached state-of-the-art on many visual reasoning tasks, including chart reasoning, yet they still falter on out-of-distribution (OOD) data, and degrade further when asked to produce their chain-of-thought (CoT) rationales, limiting explainability. We present Chart-RVR, a general framework that fine-tunes LVLMs to be more robust and explainable for chart reasoning by coupling Group Relative Policy Optimization (GRPO) with automatically verifiable rewards. Our framework comprises of three rewards that maximize: (i) correct chart-type classification, (ii) faithful chart table reconstruction, and (iii) process conformity. Applied to 3-billion-parameter LVLMs, Chart-RVR consistently outperforms standard supervised fine-tuning (SFT) on both in-distribution and out-of-distribution datasets, closing the OOD performance gap while improving rationale fidelity. The resulting models, the Chart-RVR-3B series, achieve state-of-the-art results on six chart-reasoning benchmarks spanning in-domain and OOD settings, surpassing all existing models of comparable size. Beyond accuracy, Chart-RVR yields more interpretable CoT rationales, strengthening trust and reliability - showcasing the power of verifiable rewards with GRPO for training reliable, interpretable chart-reasoning models.

