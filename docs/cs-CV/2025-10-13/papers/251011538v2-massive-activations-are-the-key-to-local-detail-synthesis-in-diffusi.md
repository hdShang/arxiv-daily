---
layout: default
title: Massive Activations are the Key to Local Detail Synthesis in Diffusion Transformers
---

# Massive Activations are the Key to Local Detail Synthesis in Diffusion Transformers

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.11538" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.11538v2</a>
  <a href="https://arxiv.org/pdf/2510.11538.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.11538v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.11538v2', 'Massive Activations are the Key to Local Detail Synthesis in Diffusion Transformers')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chaofan Gan, Zicheng Zhao, Yuanpeng Tu, Xi Chen, Ziran Qin, Tieyuan Chen, Mehrtash Harandi, Weiyao Lin

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-13 (æ›´æ–°: 2025-10-14)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDetail Guidanceï¼Œé€šè¿‡è°ƒæ§Diffusion Transformerä¸­çš„å¤§è§„æ¨¡æ¿€æ´»æå‡å›¾åƒç»†èŠ‚ç”Ÿæˆè´¨é‡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)**

**å…³é”®è¯**: `æ‰©æ•£æ¨¡å‹` `Diffusion Transformer` `å›¾åƒç”Ÿæˆ` `ç»†èŠ‚åˆæˆ` `å¤§è§„æ¨¡æ¿€æ´»`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆé¢†åŸŸè¡¨ç°å‡ºè‰²ï¼Œä½†Diffusion Transformerä¸­å¤§è§„æ¨¡æ¿€æ´»çš„ä½œç”¨å°šä¸æ˜ç¡®ã€‚
2. è®ºæ–‡æå‡ºDetail Guidanceç­–ç•¥ï¼Œé€šè¿‡æ‰°åŠ¨å¤§è§„æ¨¡æ¿€æ´»æ„å»ºç»†èŠ‚ç¼ºå¤±æ¨¡å‹ï¼Œå¼•å¯¼åŸå§‹ç½‘ç»œç”Ÿæˆæ›´ç²¾ç»†çš„å›¾åƒç»†èŠ‚ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒDetail Guidanceèƒ½æœ‰æ•ˆæå‡SD3ã€SD3.5å’ŒFluxç­‰æ¨¡å‹çš„ç»†èŠ‚ç”Ÿæˆè´¨é‡ï¼Œä¸”æ— éœ€é¢å¤–è®­ç»ƒã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ‰©æ•£Transformerï¼ˆDiTï¼‰æœ€è¿‘æˆä¸ºè§†è§‰ç”Ÿæˆé¢†åŸŸä¸€ä¸ªå¼ºå¤§çš„éª¨å¹²ç½‘ç»œã€‚è¿‘æœŸçš„ç ”ç©¶è¡¨æ˜ï¼ŒDiTçš„å†…éƒ¨ç‰¹å¾å›¾ä¸­å­˜åœ¨â€œå¤§è§„æ¨¡æ¿€æ´»â€ï¼ˆMAsï¼‰ï¼Œä½†å…¶ä½œç”¨æœºåˆ¶å°šä¸æ˜ç¡®ã€‚æœ¬æ–‡ç³»ç»Ÿåœ°ç ”ç©¶äº†è¿™äº›æ¿€æ´»ï¼Œä»¥é˜æ˜å®ƒä»¬åœ¨è§†è§‰ç”Ÿæˆä¸­çš„ä½œç”¨ã€‚ç ”ç©¶å‘ç°ï¼Œè¿™äº›å¤§è§„æ¨¡æ¿€æ´»å‡ºç°åœ¨æ‰€æœ‰ç©ºé—´tokenä¸­ï¼Œå¹¶ä¸”å®ƒä»¬çš„åˆ†å¸ƒå—åˆ°è¾“å…¥æ—¶é—´æ­¥åµŒå…¥çš„è°ƒèŠ‚ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œç ”ç©¶è¿›ä¸€æ­¥è¡¨æ˜ï¼Œè¿™äº›å¤§è§„æ¨¡æ¿€æ´»åœ¨å±€éƒ¨ç»†èŠ‚åˆæˆä¸­èµ·ç€å…³é”®ä½œç”¨ï¼Œè€Œå¯¹è¾“å‡ºçš„æ•´ä½“è¯­ä¹‰å†…å®¹å½±å“ç”šå¾®ã€‚åŸºäºè¿™äº›å‘ç°ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºâ€œç»†èŠ‚å¼•å¯¼â€ï¼ˆDGï¼‰çš„ã€ç”±MAsé©±åŠ¨çš„ã€æ— éœ€è®­ç»ƒçš„è‡ªå¼•å¯¼ç­–ç•¥ï¼Œä»¥æ˜¾å¼åœ°å¢å¼ºDiTçš„å±€éƒ¨ç»†èŠ‚ä¿çœŸåº¦ã€‚å…·ä½“æ¥è¯´ï¼ŒDGé€šè¿‡æ‰°ä¹±MAsæ„å»ºäº†ä¸€ä¸ªé™çº§çš„â€œç»†èŠ‚ç¼ºå¤±â€æ¨¡å‹ï¼Œå¹¶åˆ©ç”¨å®ƒæ¥å¼•å¯¼åŸå§‹ç½‘ç»œæœç€æ›´é«˜è´¨é‡çš„ç»†èŠ‚åˆæˆæ–¹å‘å‘å±•ã€‚æˆ‘ä»¬çš„DGå¯ä»¥ä¸æ— åˆ†ç±»å™¨å¼•å¯¼ï¼ˆCFGï¼‰æ— ç¼é›†æˆï¼Œä»è€Œè¿›ä¸€æ­¥æ”¹è¿›ç²¾ç»†ç»†èŠ‚ã€‚å¤§é‡çš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„DGèƒ½å¤ŸæŒç»­æé«˜å„ç§é¢„è®­ç»ƒDiTï¼ˆä¾‹å¦‚ï¼ŒSD3ã€SD3.5å’ŒFluxï¼‰çš„ç²¾ç»†ç»†èŠ‚è´¨é‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ç°æœ‰æ–¹æ³•åœ¨ç”Ÿæˆå›¾åƒçš„å±€éƒ¨ç»†èŠ‚æ–¹é¢ä»å­˜åœ¨ä¸è¶³ã€‚Diffusion Transformer (DiT) ä½œä¸ºä¸€ç§æ–°å…´çš„æ‰©æ•£æ¨¡å‹æ¶æ„ï¼Œå…¶å†…éƒ¨ç‰¹å¾å›¾ä¸­å­˜åœ¨å¤§è§„æ¨¡æ¿€æ´» (Massive Activations, MAs)ï¼Œä½†è¿™äº›æ¿€æ´»åœ¨å›¾åƒç”Ÿæˆè¿‡ç¨‹ä¸­çš„å…·ä½“ä½œç”¨å°šä¸æ˜ç¡®ï¼Œå¦‚ä½•åˆ©ç”¨è¿™äº›æ¿€æ´»æ¥æå‡å›¾åƒç»†èŠ‚ç”Ÿæˆè´¨é‡æ˜¯ä¸€ä¸ªå¾…è§£å†³çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ï¼Œé€šè¿‡åˆ†æå’Œè°ƒæ§DiTä¸­çš„å¤§è§„æ¨¡æ¿€æ´»ï¼Œæ¥æå‡ç”Ÿæˆå›¾åƒçš„å±€éƒ¨ç»†èŠ‚ã€‚å…·ä½“æ¥è¯´ï¼Œè®ºæ–‡å‘ç°å¤§è§„æ¨¡æ¿€æ´»åœ¨å±€éƒ¨ç»†èŠ‚åˆæˆä¸­èµ·ç€å…³é”®ä½œç”¨ï¼Œå› æ­¤å¯ä»¥é€šè¿‡æ‰°åŠ¨è¿™äº›æ¿€æ´»æ¥æ„å»ºä¸€ä¸ªâ€œç»†èŠ‚ç¼ºå¤±â€çš„æ¨¡å‹ã€‚ç„¶åï¼Œåˆ©ç”¨è¿™ä¸ªç»†èŠ‚ç¼ºå¤±çš„æ¨¡å‹æ¥å¼•å¯¼åŸå§‹æ¨¡å‹ï¼Œä½¿å…¶æ›´åŠ å…³æ³¨ç»†èŠ‚ä¿¡æ¯çš„ç”Ÿæˆã€‚è¿™ç§è‡ªå¼•å¯¼çš„æ–¹å¼ä¸éœ€è¦é¢å¤–çš„è®­ç»ƒï¼Œå¯ä»¥æ–¹ä¾¿åœ°é›†æˆåˆ°ç°æœ‰çš„DiTæ¨¡å‹ä¸­ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDetail Guidance (DG) ç­–ç•¥ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1) åˆ†æDiTæ¨¡å‹ä¸­å¤§è§„æ¨¡æ¿€æ´»çš„åˆ†å¸ƒå’Œä½œç”¨ï¼›2) é€šè¿‡æ‰°åŠ¨å¤§è§„æ¨¡æ¿€æ´»æ„å»ºä¸€ä¸ªâ€œç»†èŠ‚ç¼ºå¤±â€çš„æ¨¡å‹ï¼›3) åˆ©ç”¨ç»†èŠ‚ç¼ºå¤±æ¨¡å‹å’ŒåŸå§‹æ¨¡å‹ä¹‹é—´çš„å·®å¼‚ï¼Œè®¾è®¡ä¸€ä¸ªå¼•å¯¼ä¿¡å·ï¼›4) å°†å¼•å¯¼ä¿¡å·æ·»åŠ åˆ°åŸå§‹æ¨¡å‹çš„é¢„æµ‹ä¸­ï¼Œä»è€Œå¼•å¯¼å…¶ç”Ÿæˆæ›´ç²¾ç»†çš„ç»†èŠ‚ã€‚DGå¯ä»¥ä¸Classifier-Free Guidance (CFG) æ— ç¼é›†æˆï¼Œè¿›ä¸€æ­¥æå‡ç»†èŠ‚ç”Ÿæˆæ•ˆæœã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå‘ç°äº†Diffusion Transformerä¸­å¤§è§„æ¨¡æ¿€æ´»åœ¨å±€éƒ¨ç»†èŠ‚åˆæˆä¸­çš„é‡è¦ä½œç”¨ï¼Œå¹¶åŸºäºæ­¤æå‡ºäº†Detail Guidanceç­–ç•¥ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒDGä¸éœ€è¦é¢å¤–çš„è®­ç»ƒï¼Œå¯ä»¥ç›´æ¥åº”ç”¨äºå„ç§é¢„è®­ç»ƒçš„DiTæ¨¡å‹ï¼Œå…·æœ‰å¾ˆå¼ºçš„é€šç”¨æ€§å’Œå®ç”¨æ€§ã€‚æ­¤å¤–ï¼ŒDGé€šè¿‡è‡ªå¼•å¯¼çš„æ–¹å¼ï¼Œé¿å…äº†å¼•å…¥é¢å¤–çš„å™ªå£°æˆ–ä¼ªå½±ï¼Œä»è€Œä¿è¯äº†ç”Ÿæˆå›¾åƒçš„è´¨é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šDGçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) å¦‚ä½•æœ‰æ•ˆåœ°æ‰°åŠ¨å¤§è§„æ¨¡æ¿€æ´»ï¼Œä»¥æ„å»ºä¸€ä¸ªâ€œç»†èŠ‚ç¼ºå¤±â€çš„æ¨¡å‹ï¼›2) å¦‚ä½•è®¾è®¡å¼•å¯¼ä¿¡å·ï¼Œä»¥æœ‰æ•ˆåœ°å¼•å¯¼åŸå§‹æ¨¡å‹ç”Ÿæˆæ›´ç²¾ç»†çš„ç»†èŠ‚ã€‚è®ºæ–‡ä¸­é‡‡ç”¨äº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„æ‰°åŠ¨æ–¹æ³•ï¼Œå³å¯¹å¤§è§„æ¨¡æ¿€æ´»è¿›è¡Œéšæœºmaskingã€‚å¼•å¯¼ä¿¡å·çš„è®¾è®¡åˆ™åŸºäºç»†èŠ‚ç¼ºå¤±æ¨¡å‹å’ŒåŸå§‹æ¨¡å‹ä¹‹é—´çš„å·®å¼‚ï¼Œé€šè¿‡åŠ æƒçš„æ–¹å¼å°†å·®å¼‚æ·»åŠ åˆ°åŸå§‹æ¨¡å‹çš„é¢„æµ‹ä¸­ã€‚å…·ä½“çš„æƒé‡å‚æ•°å¯ä»¥é€šè¿‡å®éªŒè¿›è¡Œè°ƒæ•´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒDetail Guidance (DG) èƒ½å¤Ÿæ˜¾è‘—æå‡å„ç§é¢„è®­ç»ƒDiTæ¨¡å‹ï¼ˆå¦‚SD3ã€SD3.5å’ŒFluxï¼‰çš„ç»†èŠ‚ç”Ÿæˆè´¨é‡ã€‚åœ¨å®šæ€§ç»“æœä¸Šï¼ŒDGèƒ½å¤Ÿç”Ÿæˆæ›´åŠ æ¸…æ™°ã€é”åˆ©çš„å›¾åƒç»†èŠ‚ï¼Œä¾‹å¦‚æ›´é€¼çœŸçš„çº¹ç†å’Œè¾¹ç¼˜ã€‚åœ¨å®šé‡ç»“æœä¸Šï¼ŒDGåœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šéƒ½å–å¾—äº†æ˜¾è‘—çš„æå‡ï¼Œä¾‹å¦‚FIDåˆ†æ•°å’ŒLPIPSåˆ†æ•°ã€‚æ­¤å¤–ï¼ŒDGä¸Classifier-Free Guidance (CFG) çš„é›†æˆèƒ½å¤Ÿè¿›ä¸€æ­¥æå‡ç»†èŠ‚ç”Ÿæˆæ•ˆæœã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºå›¾åƒç”Ÿæˆã€å›¾åƒç¼–è¾‘ã€è¶…åˆ†è¾¨ç‡é‡å»ºç­‰é¢†åŸŸã€‚é€šè¿‡æå‡ç”Ÿæˆå›¾åƒçš„ç»†èŠ‚è´¨é‡ï¼Œå¯ä»¥æ”¹å–„ç”¨æˆ·ä½“éªŒï¼Œæé«˜å›¾åƒçš„çœŸå®æ„Ÿå’Œå¯ç”¨æ€§ã€‚ä¾‹å¦‚ï¼Œåœ¨æ¸¸æˆå¼€å‘ä¸­ï¼Œå¯ä»¥åˆ©ç”¨è¯¥æŠ€æœ¯ç”Ÿæˆæ›´åŠ ç²¾ç»†çš„æ¸¸æˆåœºæ™¯å’Œè§’è‰²ï¼›åœ¨åŒ»å­¦å½±åƒåˆ†æä¸­ï¼Œå¯ä»¥åˆ©ç”¨è¯¥æŠ€æœ¯æé«˜åŒ»å­¦å›¾åƒçš„åˆ†è¾¨ç‡ï¼Œä»è€Œè¾…åŠ©åŒ»ç”Ÿè¿›è¡Œè¯Šæ–­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Diffusion Transformers (DiTs) have recently emerged as a powerful backbone for visual generation. Recent observations reveal \emph{Massive Activations} (MAs) in their internal feature maps, yet their function remains poorly understood. In this work, we systematically investigate these activations to elucidate their role in visual generation. We found that these massive activations occur across all spatial tokens, and their distribution is modulated by the input timestep embeddings. Importantly, our investigations further demonstrate that these massive activations play a key role in local detail synthesis, while having minimal impact on the overall semantic content of output. Building on these insights, we propose \textbf{D}etail \textbf{G}uidance (\textbf{DG}), a MAs-driven, training-free self-guidance strategy to explicitly enhance local detail fidelity for DiTs. Specifically, DG constructs a degraded ``detail-deficient'' model by disrupting MAs and leverages it to guide the original network toward higher-quality detail synthesis. Our DG can seamlessly integrate with Classifier-Free Guidance (CFG), enabling further refinements of fine-grained details. Extensive experiments demonstrate that our DG consistently improves fine-grained detail quality across various pre-trained DiTs (\eg, SD3, SD3.5, and Flux).

