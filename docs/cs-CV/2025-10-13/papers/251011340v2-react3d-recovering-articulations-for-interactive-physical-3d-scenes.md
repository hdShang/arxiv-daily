---
layout: default
title: REACT3D: Recovering Articulations for Interactive Physical 3D Scenes
---

# REACT3D: Recovering Articulations for Interactive Physical 3D Scenes

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.11340" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.11340v2</a>
  <a href="https://arxiv.org/pdf/2510.11340.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.11340v2" onclick="toggleFavorite(this, '2510.11340v2', 'REACT3D: Recovering Articulations for Interactive Physical 3D Scenes')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhao Huang, Boyang Sun, Alexandros Delitzas, Jiaqi Chen, Marc Pollefeys

**åˆ†ç±»**: cs.CV, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-10-13 (æ›´æ–°: 2025-10-14)

**å¤‡æ³¨**: 8 pages

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**REACT3Dï¼šç”¨äºäº¤äº’å¼ç‰©ç†3Dåœºæ™¯çš„é“°æ¥ç»“æ„æ¢å¤æ¡†æ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `3Dåœºæ™¯ç†è§£` `é“°æ¥ç»“æ„æ¢å¤` `äº¤äº’å¼åœºæ™¯ç”Ÿæˆ` `é›¶æ ·æœ¬å­¦ä¹ ` `å…·èº«æ™ºèƒ½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰äº¤äº’å¼3Dåœºæ™¯æ•°æ®é›†ç¼ºä¹éƒ¨ä»¶åˆ†å‰²ã€è¿åŠ¨å­¦ç±»å‹å’Œè¿åŠ¨è½¨è¿¹çš„æ ‡æ³¨ï¼Œé™åˆ¶äº†å…·èº«æ™ºèƒ½çš„å‘å±•ã€‚
2. REACT3Dé€šè¿‡å¯æ‰“å¼€å¯¹è±¡æ£€æµ‹ã€é“°æ¥ä¼°è®¡ã€éšè—å‡ ä½•è¡¥å…¨å’Œäº¤äº’å¼å¯¹è±¡ç»„è£…ï¼Œå°†é™æ€3Dåœºæ™¯è½¬æ¢ä¸ºäº¤äº’å¼å‰¯æœ¬ã€‚
3. è¯¥æ¡†æ¶åœ¨å®¤å†…åœºæ™¯çš„æ£€æµ‹/åˆ†å‰²å’Œé“°æ¥æŒ‡æ ‡ä¸Šå–å¾—äº†é¢†å…ˆæ€§èƒ½ï¼Œä¸ºå¤§è§„æ¨¡äº¤äº’å¼åœºæ™¯ç”Ÿæˆç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äº¤äº’å¼3Dåœºæ™¯åœ¨å…·èº«æ™ºèƒ½ä¸­æ—¥ç›Šé‡è¦ï¼Œä½†ç°æœ‰æ•°æ®é›†åœ¨éƒ¨ä»¶åˆ†å‰²ã€è¿åŠ¨å­¦ç±»å‹å’Œè¿åŠ¨è½¨è¿¹çš„æ ‡æ³¨æ–¹é¢ä»ç„¶å—é™ï¼Œå› ä¸ºæ ‡æ³¨è¿‡ç¨‹éå¸¸è€—è´¹äººåŠ›ã€‚æˆ‘ä»¬æå‡ºäº†REACT3Dï¼Œä¸€ä¸ªå¯æ‰©å±•çš„é›¶æ ·æœ¬æ¡†æ¶ï¼Œå¯ä»¥å°†é™æ€3Dåœºæ™¯è½¬æ¢ä¸ºå¯ç”¨äºä»¿çœŸçš„äº¤äº’å¼å‰¯æœ¬ï¼Œå¹¶å…·æœ‰ä¸€è‡´çš„å‡ ä½•ç»“æ„ï¼Œä»è€Œå¯ä»¥ç›´æ¥ç”¨äºå„ç§ä¸‹æ¸¸ä»»åŠ¡ã€‚æˆ‘ä»¬çš„è´¡çŒ®åŒ…æ‹¬ï¼šï¼ˆiï¼‰å¯æ‰“å¼€å¯¹è±¡æ£€æµ‹å’Œåˆ†å‰²ï¼Œä»¥ä»é™æ€åœºæ™¯ä¸­æå–å€™é€‰å¯ç§»åŠ¨éƒ¨ä»¶ï¼›ï¼ˆiiï¼‰é“°æ¥ä¼°è®¡ï¼Œæ¨æ–­å…³èŠ‚ç±»å‹å’Œè¿åŠ¨å‚æ•°ï¼›ï¼ˆiiiï¼‰éšè—å‡ ä½•è¡¥å…¨ï¼Œç„¶åè¿›è¡Œäº¤äº’å¼å¯¹è±¡ç»„è£…ï¼›ï¼ˆivï¼‰åœ¨å¹¿æ³›æ”¯æŒçš„æ ¼å¼ä¸­è¿›è¡Œäº¤äº’å¼åœºæ™¯é›†æˆï¼Œä»¥ç¡®ä¿ä¸æ ‡å‡†ä»¿çœŸå¹³å°çš„å…¼å®¹æ€§ã€‚æˆ‘ä»¬åœ¨å„ç§å®¤å†…åœºæ™¯ä¸­çš„æ£€æµ‹/åˆ†å‰²å’Œé“°æ¥æŒ‡æ ‡ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè¯æ˜äº†æˆ‘ä»¬æ¡†æ¶çš„æœ‰æ•ˆæ€§ï¼Œå¹¶ä¸ºå¯æ‰©å±•çš„äº¤äº’å¼åœºæ™¯ç”Ÿæˆæä¾›äº†å®è·µåŸºç¡€ï¼Œä»è€Œé™ä½äº†å¯¹é“°æ¥åœºæ™¯ç†è§£è¿›è¡Œå¤§è§„æ¨¡ç ”ç©¶çš„é—¨æ§›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ä»é™æ€3Dåœºæ™¯ä¸­è‡ªåŠ¨ç”Ÿæˆå¯äº¤äº’çš„ã€å…·æœ‰é“°æ¥ç»“æ„çš„3Dåœºæ™¯çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•éœ€è¦å¤§é‡äººå·¥æ ‡æ³¨ï¼Œæˆæœ¬é«˜æ˜‚ï¼Œé™åˆ¶äº†æ•°æ®é›†çš„è§„æ¨¡å’Œå¤šæ ·æ€§ã€‚å› æ­¤ï¼Œå¦‚ä½•ä»¥é›¶æ ·æœ¬çš„æ–¹å¼ï¼Œè‡ªåŠ¨åœ°ä»é™æ€åœºæ™¯ä¸­æ¨æ–­å‡ºå¯ç§»åŠ¨éƒ¨ä»¶ã€å…³èŠ‚ç±»å‹å’Œè¿åŠ¨å‚æ•°ï¼Œæ˜¯æœ¬ç ”ç©¶è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šREACT3Dçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ä¸€ç³»åˆ—æ¨¡å—åŒ–çš„æ­¥éª¤ï¼Œé€æ­¥åœ°ä»é™æ€åœºæ™¯ä¸­æå–å’Œæ¨æ–­å‡ºäº¤äº’ä¿¡æ¯ã€‚é¦–å…ˆæ£€æµ‹å’Œåˆ†å‰²å¯ç§»åŠ¨çš„éƒ¨ä»¶ï¼Œç„¶åä¼°è®¡è¿™äº›éƒ¨ä»¶çš„é“°æ¥ç±»å‹å’Œè¿åŠ¨å‚æ•°ï¼Œæ¥ç€è¡¥å…¨éšè—çš„å‡ ä½•ä¿¡æ¯ï¼Œæœ€åå°†è¿™äº›éƒ¨ä»¶ç»„è£…æˆä¸€ä¸ªå¯äº¤äº’çš„åœºæ™¯ã€‚è¿™ç§æ¨¡å—åŒ–çš„è®¾è®¡ä½¿å¾—æ¯ä¸ªæ­¥éª¤éƒ½å¯ä»¥ç‹¬ç«‹ä¼˜åŒ–ï¼Œå¹¶ä¸”å¯ä»¥çµæ´»åœ°ç»„åˆä¸åŒçš„æ¨¡å—æ¥é€‚åº”ä¸åŒçš„åœºæ™¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šREACT3Dæ¡†æ¶åŒ…å«ä»¥ä¸‹å››ä¸ªä¸»è¦æ¨¡å—ï¼š(1) å¯æ‰“å¼€å¯¹è±¡æ£€æµ‹å’Œåˆ†å‰²ï¼šä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹æ£€æµ‹åœºæ™¯ä¸­æ½œåœ¨çš„å¯ç§»åŠ¨éƒ¨ä»¶ï¼Œå¹¶è¿›è¡Œç²¾ç¡®çš„åˆ†å‰²ã€‚(2) é“°æ¥ä¼°è®¡ï¼šæ ¹æ®åˆ†å‰²ç»“æœå’Œå‡ ä½•ä¿¡æ¯ï¼Œæ¨æ–­å‡ºæ¯ä¸ªéƒ¨ä»¶çš„å…³èŠ‚ç±»å‹ï¼ˆå¦‚æ—‹è½¬ã€å¹³ç§»ï¼‰å’Œè¿åŠ¨å‚æ•°ã€‚(3) éšè—å‡ ä½•è¡¥å…¨ï¼šè¡¥å…¨ç”±äºé®æŒ¡ç­‰åŸå› è€Œç¼ºå¤±çš„å‡ ä½•ä¿¡æ¯ï¼Œä¿è¯åœºæ™¯çš„å®Œæ•´æ€§ã€‚(4) äº¤äº’å¼å¯¹è±¡ç»„è£…ï¼šå°†å„ä¸ªéƒ¨ä»¶æŒ‰ç…§ä¼°è®¡çš„é“°æ¥å…³ç³»ç»„è£…æˆä¸€ä¸ªå®Œæ•´çš„ã€å¯äº¤äº’çš„3Dåœºæ™¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šREACT3Dçš„å…³é”®åˆ›æ–°åœ¨äºå…¶é›¶æ ·æœ¬çš„å­¦ä¹ èƒ½åŠ›ï¼Œå³ä¸éœ€è¦ä»»ä½•äººå·¥æ ‡æ³¨çš„é“°æ¥ä¿¡æ¯ï¼Œå°±å¯ä»¥è‡ªåŠ¨åœ°ä»é™æ€åœºæ™¯ä¸­æ¨æ–­å‡ºäº¤äº’ä¿¡æ¯ã€‚è¿™ç§é›¶æ ·æœ¬çš„å­¦ä¹ èƒ½åŠ›ä½¿å¾—REACT3Då¯ä»¥åº”ç”¨äºå¤§è§„æ¨¡çš„åœºæ™¯ç”Ÿæˆï¼Œå¤§å¤§é™ä½äº†æ•°æ®æ ‡æ³¨çš„æˆæœ¬ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å¯æ‰“å¼€å¯¹è±¡æ£€æµ‹å’Œåˆ†å‰²æ¨¡å—ä¸­ï¼Œä½¿ç”¨äº†åŸºäºæ·±åº¦å­¦ä¹ çš„åˆ†å‰²æ¨¡å‹ï¼Œå¹¶é’ˆå¯¹3Dåœºæ™¯çš„ç‰¹ç‚¹è¿›è¡Œäº†ä¼˜åŒ–ã€‚åœ¨é“°æ¥ä¼°è®¡æ¨¡å—ä¸­ï¼Œä½¿ç”¨äº†åŸºäºå‡ ä½•çº¦æŸå’Œè¿åŠ¨å­¦æ¨¡å‹çš„ä¼˜åŒ–ç®—æ³•ï¼Œä»¥ä¿è¯ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚åœ¨éšè—å‡ ä½•è¡¥å…¨æ¨¡å—ä¸­ï¼Œä½¿ç”¨äº†åŸºäºæ·±åº¦å­¦ä¹ çš„è¡¥å…¨æ¨¡å‹ï¼Œå¹¶ç»“åˆäº†åœºæ™¯çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚åœ¨äº¤äº’å¼å¯¹è±¡ç»„è£…æ¨¡å—ä¸­ï¼Œä½¿ç”¨äº†åŸºäºç‰©ç†å¼•æ“çš„ä»¿çœŸæŠ€æœ¯ï¼Œä»¥ä¿è¯åœºæ™¯çš„äº¤äº’æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

REACT3Dåœ¨å„ç§å®¤å†…åœºæ™¯ä¸­çš„æ£€æµ‹/åˆ†å‰²å’Œé“°æ¥æŒ‡æ ‡ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆåœ°ä»é™æ€3Dåœºæ™¯ä¸­æå–å¯ç§»åŠ¨éƒ¨ä»¶ï¼Œå¹¶å‡†ç¡®åœ°ä¼°è®¡å…¶é“°æ¥ç±»å‹å’Œè¿åŠ¨å‚æ•°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒREACT3Dåœ¨é›¶æ ·æœ¬å­¦ä¹ æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œèƒ½å¤Ÿå¤§å¤§é™ä½æ•°æ®æ ‡æ³¨çš„æˆæœ¬ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

REACT3DæŠ€æœ¯å¯å¹¿æ³›åº”ç”¨äºæœºå™¨äººä»¿çœŸã€è™šæ‹Ÿç°å®ã€æ¸¸æˆå¼€å‘ç­‰é¢†åŸŸã€‚å®ƒèƒ½å¤Ÿè‡ªåŠ¨ç”Ÿæˆé€¼çœŸçš„ã€å¯äº¤äº’çš„3Dåœºæ™¯ï¼Œä¸ºæœºå™¨äººæä¾›è®­ç»ƒç¯å¢ƒï¼Œä¸ºç”¨æˆ·æä¾›æ²‰æµ¸å¼çš„ä½“éªŒï¼Œå¹¶ä¸ºæ¸¸æˆå¼€å‘è€…æä¾›ä¸°å¯Œçš„èµ„æºã€‚è¯¥æŠ€æœ¯æœ‰æœ›åŠ é€Ÿå…·èº«æ™ºèƒ½çš„å‘å±•ï¼Œå¹¶æ¨åŠ¨äººæœºäº¤äº’çš„è¿›æ­¥ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Interactive 3D scenes are increasingly vital for embodied intelligence, yet existing datasets remain limited due to the labor-intensive process of annotating part segmentation, kinematic types, and motion trajectories. We present REACT3D, a scalable zero-shot framework that converts static 3D scenes into simulation-ready interactive replicas with consistent geometry, enabling direct use in diverse downstream tasks. Our contributions include: (i) openable-object detection and segmentation to extract candidate movable parts from static scenes, (ii) articulation estimation that infers joint types and motion parameters, (iii) hidden-geometry completion followed by interactive object assembly, and (iv) interactive scene integration in widely supported formats to ensure compatibility with standard simulation platforms. We achieve state-of-the-art performance on detection/segmentation and articulation metrics across diverse indoor scenes, demonstrating the effectiveness of our framework and providing a practical foundation for scalable interactive scene generation, thereby lowering the barrier to large-scale research on articulated scene understanding. Our project page is https://react3d.github.io/

