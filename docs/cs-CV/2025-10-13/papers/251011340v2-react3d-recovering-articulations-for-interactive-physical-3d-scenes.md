---
layout: default
title: REACT3D: Recovering Articulations for Interactive Physical 3D Scenes
---

# REACT3D: Recovering Articulations for Interactive Physical 3D Scenes

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.11340" target="_blank" class="toolbar-btn">arXiv: 2510.11340v2</a>
    <a href="https://arxiv.org/pdf/2510.11340.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.11340v2" 
            onclick="toggleFavorite(this, '2510.11340v2', 'REACT3D: Recovering Articulations for Interactive Physical 3D Scenes')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Zhao Huang, Boyang Sun, Alexandros Delitzas, Jiaqi Chen, Marc Pollefeys

**ÂàÜÁ±ª**: cs.CV, cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-13 (Êõ¥Êñ∞: 2025-10-14)

**Â§áÊ≥®**: 8 pages

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**REACT3DÔºöÁî®‰∫é‰∫§‰∫íÂºèÁâ©ÁêÜ3DÂú∫ÊôØÁöÑÈì∞Êé•ÁªìÊûÑÊÅ¢Â§çÊ°ÜÊû∂**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)**

**ÂÖ≥ÈîÆËØç**: `3DÂú∫ÊôØÁêÜËß£` `Èì∞Êé•ÁªìÊûÑÊÅ¢Â§ç` `‰∫§‰∫íÂºèÂú∫ÊôØÁîüÊàê` `Èõ∂Ê†∑Êú¨Â≠¶‰π†` `ÂÖ∑Ë∫´Êô∫ËÉΩ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞Êúâ‰∫§‰∫íÂºè3DÂú∫ÊôØÊï∞ÊçÆÈõÜÁº∫‰πèÈÉ®‰ª∂ÂàÜÂâ≤„ÄÅËøêÂä®Â≠¶Á±ªÂûãÂíåËøêÂä®ËΩ®ËøπÁöÑÊ†áÊ≥®ÔºåÈôêÂà∂‰∫ÜÂÖ∑Ë∫´Êô∫ËÉΩÁöÑÂèëÂ±ï„ÄÇ
2. REACT3DÈÄöËøáÂèØÊâìÂºÄÂØπË±°Ê£ÄÊµã„ÄÅÈì∞Êé•‰º∞ËÆ°„ÄÅÈöêËóèÂá†‰ΩïË°•ÂÖ®Âíå‰∫§‰∫íÂºèÂØπË±°ÁªÑË£ÖÔºåÂ∞ÜÈùôÊÄÅ3DÂú∫ÊôØËΩ¨Êç¢‰∏∫‰∫§‰∫íÂºèÂâØÊú¨„ÄÇ
3. ËØ•Ê°ÜÊû∂Âú®ÂÆ§ÂÜÖÂú∫ÊôØÁöÑÊ£ÄÊµã/ÂàÜÂâ≤ÂíåÈì∞Êé•ÊåáÊ†á‰∏äÂèñÂæó‰∫ÜÈ¢ÜÂÖàÊÄßËÉΩÔºå‰∏∫Â§ßËßÑÊ®°‰∫§‰∫íÂºèÂú∫ÊôØÁîüÊàêÁ†îÁ©∂Â•†ÂÆö‰∫ÜÂü∫Á°Ä„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

‰∫§‰∫íÂºè3DÂú∫ÊôØÂú®ÂÖ∑Ë∫´Êô∫ËÉΩ‰∏≠Êó•ÁõäÈáçË¶ÅÔºå‰ΩÜÁé∞ÊúâÊï∞ÊçÆÈõÜÂú®ÈÉ®‰ª∂ÂàÜÂâ≤„ÄÅËøêÂä®Â≠¶Á±ªÂûãÂíåËøêÂä®ËΩ®ËøπÁöÑÊ†áÊ≥®ÊñπÈù¢‰ªçÁÑ∂ÂèóÈôêÔºåÂõ†‰∏∫Ê†áÊ≥®ËøáÁ®ãÈùûÂ∏∏ËÄóË¥π‰∫∫Âäõ„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫ÜREACT3DÔºå‰∏Ä‰∏™ÂèØÊâ©Â±ïÁöÑÈõ∂Ê†∑Êú¨Ê°ÜÊû∂ÔºåÂèØ‰ª•Â∞ÜÈùôÊÄÅ3DÂú∫ÊôØËΩ¨Êç¢‰∏∫ÂèØÁî®‰∫é‰ªøÁúüÁöÑ‰∫§‰∫íÂºèÂâØÊú¨ÔºåÂπ∂ÂÖ∑Êúâ‰∏ÄËá¥ÁöÑÂá†‰ΩïÁªìÊûÑÔºå‰ªéËÄåÂèØ‰ª•Áõ¥Êé•Áî®‰∫éÂêÑÁßç‰∏ãÊ∏∏‰ªªÂä°„ÄÇÊàë‰ª¨ÁöÑË¥°ÁåÆÂåÖÊã¨ÔºöÔºàiÔºâÂèØÊâìÂºÄÂØπË±°Ê£ÄÊµãÂíåÂàÜÂâ≤Ôºå‰ª•‰ªéÈùôÊÄÅÂú∫ÊôØ‰∏≠ÊèêÂèñÂÄôÈÄâÂèØÁßªÂä®ÈÉ®‰ª∂ÔºõÔºàiiÔºâÈì∞Êé•‰º∞ËÆ°ÔºåÊé®Êñ≠ÂÖ≥ËäÇÁ±ªÂûãÂíåËøêÂä®ÂèÇÊï∞ÔºõÔºàiiiÔºâÈöêËóèÂá†‰ΩïË°•ÂÖ®ÔºåÁÑ∂ÂêéËøõË°å‰∫§‰∫íÂºèÂØπË±°ÁªÑË£ÖÔºõÔºàivÔºâÂú®ÂπøÊ≥õÊîØÊåÅÁöÑÊ†ºÂºè‰∏≠ËøõË°å‰∫§‰∫íÂºèÂú∫ÊôØÈõÜÊàêÔºå‰ª•Á°Æ‰øù‰∏éÊ†áÂáÜ‰ªøÁúüÂπ≥Âè∞ÁöÑÂÖºÂÆπÊÄß„ÄÇÊàë‰ª¨Âú®ÂêÑÁßçÂÆ§ÂÜÖÂú∫ÊôØ‰∏≠ÁöÑÊ£ÄÊµã/ÂàÜÂâ≤ÂíåÈì∞Êé•ÊåáÊ†á‰∏äÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåËØÅÊòé‰∫ÜÊàë‰ª¨Ê°ÜÊû∂ÁöÑÊúâÊïàÊÄßÔºåÂπ∂‰∏∫ÂèØÊâ©Â±ïÁöÑ‰∫§‰∫íÂºèÂú∫ÊôØÁîüÊàêÊèê‰æõ‰∫ÜÂÆûË∑µÂü∫Á°ÄÔºå‰ªéËÄåÈôç‰Ωé‰∫ÜÂØπÈì∞Êé•Âú∫ÊôØÁêÜËß£ËøõË°åÂ§ßËßÑÊ®°Á†îÁ©∂ÁöÑÈó®Êßõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥‰ªéÈùôÊÄÅ3DÂú∫ÊôØ‰∏≠Ëá™Âä®ÁîüÊàêÂèØ‰∫§‰∫íÁöÑ„ÄÅÂÖ∑ÊúâÈì∞Êé•ÁªìÊûÑÁöÑ3DÂú∫ÊôØÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÈúÄË¶ÅÂ§ßÈáè‰∫∫Â∑•Ê†áÊ≥®ÔºåÊàêÊú¨È´òÊòÇÔºåÈôêÂà∂‰∫ÜÊï∞ÊçÆÈõÜÁöÑËßÑÊ®°ÂíåÂ§öÊ†∑ÊÄß„ÄÇÂõ†Ê≠§ÔºåÂ¶Ç‰Ωï‰ª•Èõ∂Ê†∑Êú¨ÁöÑÊñπÂºèÔºåËá™Âä®Âú∞‰ªéÈùôÊÄÅÂú∫ÊôØ‰∏≠Êé®Êñ≠Âá∫ÂèØÁßªÂä®ÈÉ®‰ª∂„ÄÅÂÖ≥ËäÇÁ±ªÂûãÂíåËøêÂä®ÂèÇÊï∞ÔºåÊòØÊú¨Á†îÁ©∂Ë¶ÅËß£ÂÜ≥ÁöÑÊ†∏ÂøÉÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöREACT3DÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøá‰∏ÄÁ≥ªÂàóÊ®°ÂùóÂåñÁöÑÊ≠•È™§ÔºåÈÄêÊ≠•Âú∞‰ªéÈùôÊÄÅÂú∫ÊôØ‰∏≠ÊèêÂèñÂíåÊé®Êñ≠Âá∫‰∫§‰∫í‰ø°ÊÅØ„ÄÇÈ¶ñÂÖàÊ£ÄÊµãÂíåÂàÜÂâ≤ÂèØÁßªÂä®ÁöÑÈÉ®‰ª∂ÔºåÁÑ∂Âêé‰º∞ËÆ°Ëøô‰∫õÈÉ®‰ª∂ÁöÑÈì∞Êé•Á±ªÂûãÂíåËøêÂä®ÂèÇÊï∞ÔºåÊé•ÁùÄË°•ÂÖ®ÈöêËóèÁöÑÂá†‰Ωï‰ø°ÊÅØÔºåÊúÄÂêéÂ∞ÜËøô‰∫õÈÉ®‰ª∂ÁªÑË£ÖÊàê‰∏Ä‰∏™ÂèØ‰∫§‰∫íÁöÑÂú∫ÊôØ„ÄÇËøôÁßçÊ®°ÂùóÂåñÁöÑËÆæËÆ°‰ΩøÂæóÊØè‰∏™Ê≠•È™§ÈÉΩÂèØ‰ª•Áã¨Á´ã‰ºòÂåñÔºåÂπ∂‰∏îÂèØ‰ª•ÁÅµÊ¥ªÂú∞ÁªÑÂêà‰∏çÂêåÁöÑÊ®°ÂùóÊù•ÈÄÇÂ∫î‰∏çÂêåÁöÑÂú∫ÊôØ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöREACT3DÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ãÂõõ‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö(1) ÂèØÊâìÂºÄÂØπË±°Ê£ÄÊµãÂíåÂàÜÂâ≤Ôºö‰ΩøÁî®Ê∑±Â∫¶Â≠¶‰π†Ê®°ÂûãÊ£ÄÊµãÂú∫ÊôØ‰∏≠ÊΩúÂú®ÁöÑÂèØÁßªÂä®ÈÉ®‰ª∂ÔºåÂπ∂ËøõË°åÁ≤æÁ°ÆÁöÑÂàÜÂâ≤„ÄÇ(2) Èì∞Êé•‰º∞ËÆ°ÔºöÊ†πÊçÆÂàÜÂâ≤ÁªìÊûúÂíåÂá†‰Ωï‰ø°ÊÅØÔºåÊé®Êñ≠Âá∫ÊØè‰∏™ÈÉ®‰ª∂ÁöÑÂÖ≥ËäÇÁ±ªÂûãÔºàÂ¶ÇÊóãËΩ¨„ÄÅÂπ≥ÁßªÔºâÂíåËøêÂä®ÂèÇÊï∞„ÄÇ(3) ÈöêËóèÂá†‰ΩïË°•ÂÖ®ÔºöË°•ÂÖ®Áî±‰∫éÈÅÆÊå°Á≠âÂéüÂõ†ËÄåÁº∫Â§±ÁöÑÂá†‰Ωï‰ø°ÊÅØÔºå‰øùËØÅÂú∫ÊôØÁöÑÂÆåÊï¥ÊÄß„ÄÇ(4) ‰∫§‰∫íÂºèÂØπË±°ÁªÑË£ÖÔºöÂ∞ÜÂêÑ‰∏™ÈÉ®‰ª∂ÊåâÁÖß‰º∞ËÆ°ÁöÑÈì∞Êé•ÂÖ≥Á≥ªÁªÑË£ÖÊàê‰∏Ä‰∏™ÂÆåÊï¥ÁöÑ„ÄÅÂèØ‰∫§‰∫íÁöÑ3DÂú∫ÊôØ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöREACT3DÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂Èõ∂Ê†∑Êú¨ÁöÑÂ≠¶‰π†ËÉΩÂäõÔºåÂç≥‰∏çÈúÄË¶Å‰ªª‰Ωï‰∫∫Â∑•Ê†áÊ≥®ÁöÑÈì∞Êé•‰ø°ÊÅØÔºåÂ∞±ÂèØ‰ª•Ëá™Âä®Âú∞‰ªéÈùôÊÄÅÂú∫ÊôØ‰∏≠Êé®Êñ≠Âá∫‰∫§‰∫í‰ø°ÊÅØ„ÄÇËøôÁßçÈõ∂Ê†∑Êú¨ÁöÑÂ≠¶‰π†ËÉΩÂäõ‰ΩøÂæóREACT3DÂèØ‰ª•Â∫îÁî®‰∫éÂ§ßËßÑÊ®°ÁöÑÂú∫ÊôØÁîüÊàêÔºåÂ§ßÂ§ßÈôç‰Ωé‰∫ÜÊï∞ÊçÆÊ†áÊ≥®ÁöÑÊàêÊú¨„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÂèØÊâìÂºÄÂØπË±°Ê£ÄÊµãÂíåÂàÜÂâ≤Ê®°Âùó‰∏≠Ôºå‰ΩøÁî®‰∫ÜÂü∫‰∫éÊ∑±Â∫¶Â≠¶‰π†ÁöÑÂàÜÂâ≤Ê®°ÂûãÔºåÂπ∂ÈíàÂØπ3DÂú∫ÊôØÁöÑÁâπÁÇπËøõË°å‰∫Ü‰ºòÂåñ„ÄÇÂú®Èì∞Êé•‰º∞ËÆ°Ê®°Âùó‰∏≠Ôºå‰ΩøÁî®‰∫ÜÂü∫‰∫éÂá†‰ΩïÁ∫¶ÊùüÂíåËøêÂä®Â≠¶Ê®°ÂûãÁöÑ‰ºòÂåñÁÆóÊ≥ïÔºå‰ª•‰øùËØÅ‰º∞ËÆ°ÁöÑÂáÜÁ°ÆÊÄß„ÄÇÂú®ÈöêËóèÂá†‰ΩïË°•ÂÖ®Ê®°Âùó‰∏≠Ôºå‰ΩøÁî®‰∫ÜÂü∫‰∫éÊ∑±Â∫¶Â≠¶‰π†ÁöÑË°•ÂÖ®Ê®°ÂûãÔºåÂπ∂ÁªìÂêà‰∫ÜÂú∫ÊôØÁöÑ‰∏ä‰∏ãÊñá‰ø°ÊÅØ„ÄÇÂú®‰∫§‰∫íÂºèÂØπË±°ÁªÑË£ÖÊ®°Âùó‰∏≠Ôºå‰ΩøÁî®‰∫ÜÂü∫‰∫éÁâ©ÁêÜÂºïÊìéÁöÑ‰ªøÁúüÊäÄÊúØÔºå‰ª•‰øùËØÅÂú∫ÊôØÁöÑ‰∫§‰∫íÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

REACT3DÂú®ÂêÑÁßçÂÆ§ÂÜÖÂú∫ÊôØ‰∏≠ÁöÑÊ£ÄÊµã/ÂàÜÂâ≤ÂíåÈì∞Êé•ÊåáÊ†á‰∏äÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩ„ÄÇËØ•Ê°ÜÊû∂ËÉΩÂ§üÊúâÊïàÂú∞‰ªéÈùôÊÄÅ3DÂú∫ÊôØ‰∏≠ÊèêÂèñÂèØÁßªÂä®ÈÉ®‰ª∂ÔºåÂπ∂ÂáÜÁ°ÆÂú∞‰º∞ËÆ°ÂÖ∂Èì∞Êé•Á±ªÂûãÂíåËøêÂä®ÂèÇÊï∞„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåREACT3DÂú®Èõ∂Ê†∑Êú¨Â≠¶‰π†ÊñπÈù¢ÂÖ∑ÊúâÊòæËëó‰ºòÂäøÔºåËÉΩÂ§üÂ§ßÂ§ßÈôç‰ΩéÊï∞ÊçÆÊ†áÊ≥®ÁöÑÊàêÊú¨„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

REACT3DÊäÄÊúØÂèØÂπøÊ≥õÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫‰ªøÁúü„ÄÅËôöÊãüÁé∞ÂÆû„ÄÅÊ∏∏ÊàèÂºÄÂèëÁ≠âÈ¢ÜÂüü„ÄÇÂÆÉËÉΩÂ§üËá™Âä®ÁîüÊàêÈÄºÁúüÁöÑ„ÄÅÂèØ‰∫§‰∫íÁöÑ3DÂú∫ÊôØÔºå‰∏∫Êú∫Âô®‰∫∫Êèê‰æõËÆ≠ÁªÉÁéØÂ¢ÉÔºå‰∏∫Áî®Êà∑Êèê‰æõÊ≤âÊµ∏ÂºèÁöÑ‰ΩìÈ™åÔºåÂπ∂‰∏∫Ê∏∏ÊàèÂºÄÂèëËÄÖÊèê‰æõ‰∏∞ÂØåÁöÑËµÑÊ∫ê„ÄÇËØ•ÊäÄÊúØÊúâÊúõÂä†ÈÄüÂÖ∑Ë∫´Êô∫ËÉΩÁöÑÂèëÂ±ïÔºåÂπ∂Êé®Âä®‰∫∫Êú∫‰∫§‰∫íÁöÑËøõÊ≠•„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Interactive 3D scenes are increasingly vital for embodied intelligence, yet existing datasets remain limited due to the labor-intensive process of annotating part segmentation, kinematic types, and motion trajectories. We present REACT3D, a scalable zero-shot framework that converts static 3D scenes into simulation-ready interactive replicas with consistent geometry, enabling direct use in diverse downstream tasks. Our contributions include: (i) openable-object detection and segmentation to extract candidate movable parts from static scenes, (ii) articulation estimation that infers joint types and motion parameters, (iii) hidden-geometry completion followed by interactive object assembly, and (iv) interactive scene integration in widely supported formats to ensure compatibility with standard simulation platforms. We achieve state-of-the-art performance on detection/segmentation and articulation metrics across diverse indoor scenes, demonstrating the effectiveness of our framework and providing a practical foundation for scalable interactive scene generation, thereby lowering the barrier to large-scale research on articulated scene understanding. Our project page is https://react3d.github.io/

