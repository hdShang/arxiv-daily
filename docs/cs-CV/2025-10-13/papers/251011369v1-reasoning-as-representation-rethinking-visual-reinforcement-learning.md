---
layout: default
title: "Reasoning as Representation: Rethinking Visual Reinforcement Learning in Image Quality Assessment"
---

# Reasoning as Representation: Rethinking Visual Reinforcement Learning in Image Quality Assessment

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.11369" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.11369v1</a>
  <a href="https://arxiv.org/pdf/2510.11369.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.11369v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.11369v1', 'Reasoning as Representation: Rethinking Visual Reinforcement Learning in Image Quality Assessment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shijie Zhao, Xuanyu Zhang, Weiqi Li, Junlin Li, Li Zhang, Tianfan Xue, Jian Zhang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-13

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRALIç®—æ³•ï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ å¯¹é½å›¾åƒå’Œæ–‡æœ¬è¡¨å¾ï¼Œå®ç°é«˜æ•ˆå›¾åƒè´¨é‡è¯„ä¼°ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å›¾åƒè´¨é‡è¯„ä¼°` `å¼ºåŒ–å­¦ä¹ ` `å¯¹æ¯”å­¦ä¹ ` `æ–‡æœ¬è¡¨å¾` `æ³›åŒ–èƒ½åŠ›`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. åŸºäºæ¨ç†çš„å›¾åƒè´¨é‡è¯„ä¼°æ¨¡å‹æ³›åŒ–æ€§å¥½ï¼Œä½†æ¨ç†æˆæœ¬é«˜ï¼Œé™åˆ¶äº†éƒ¨ç½²ã€‚
2. æå‡ºRALIç®—æ³•ï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ å°†å›¾åƒä¸å¼ºåŒ–å­¦ä¹ å¾—åˆ°çš„æ–‡æœ¬è¡¨å¾å¯¹é½ï¼Œæ— éœ€æ¨ç†ã€‚
3. RALIåœ¨è´¨é‡è¯„ä¼°ä»»åŠ¡ä¸Šè¾¾åˆ°ä¸æ¨ç†æ¨¡å‹ç›¸å½“çš„æ³›åŒ–æ€§èƒ½ï¼Œä½†å‚æ•°é‡å’Œæ¨ç†æ—¶é—´å¤§å¹…é™ä½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºäºå¼ºåŒ–å­¦ä¹ çš„å›¾åƒè´¨é‡è¯„ä¼°(IQA)æ¨¡å‹å±•ç°å‡ºå“è¶Šçš„æ³›åŒ–èƒ½åŠ›ï¼Œä½†å…¶å†…åœ¨æœºåˆ¶å’Œå…³é”®é©±åŠ¨å› ç´ åœ¨å½“å‰ç ”ç©¶ä¸­ä»æœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚æ­¤å¤–ï¼Œå°½ç®¡è¿™äº›æ¨¡å‹æ€§èƒ½ä¼˜è¶Šï¼Œä½†å…¶æ¨ç†èƒ½è€—å’Œå»¶è¿Ÿæ¯”æ—©æœŸæ¨¡å‹é«˜å‡ºå‡ ä¸ªæ•°é‡çº§ï¼Œé™åˆ¶äº†å®ƒä»¬åœ¨ç‰¹å®šåœºæ™¯ä¸­çš„éƒ¨ç½²ã€‚æœ¬æ–‡é€šè¿‡å¤§é‡å®éªŒéªŒè¯å¹¶é˜è¿°ï¼ŒMLLMé€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼Œåˆ©ç”¨å…¶æ¨ç†èƒ½åŠ›å°†å†—ä½™çš„è§†è§‰è¡¨å¾è½¬æ¢ä¸ºç´§å‡‘çš„ã€è·¨åŸŸå¯¹é½çš„æ–‡æœ¬è¡¨å¾ã€‚è¿™ç§è½¬æ¢æ­£æ˜¯è¿™äº›åŸºäºæ¨ç†çš„IQAæ¨¡å‹æ³›åŒ–çš„æ¥æºã€‚åŸºäºè¿™ä¸€åŸºæœ¬æ´å¯Ÿï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„ç®—æ³•RALIï¼Œå®ƒé‡‡ç”¨å¯¹æ¯”å­¦ä¹ ç›´æ¥å°†å›¾åƒä¸å¼ºåŒ–å­¦ä¹ å­¦ä¹ åˆ°çš„è¿™äº›å¯æ³›åŒ–çš„æ–‡æœ¬è¡¨å¾å¯¹é½ã€‚è¿™ç§æ–¹æ³•æ¶ˆé™¤äº†å¯¹æ¨ç†è¿‡ç¨‹çš„ä¾èµ–ï¼Œç”šè‡³ä¸éœ€è¦åŠ è½½LLMã€‚å¯¹äºè´¨é‡è¯„åˆ†ä»»åŠ¡ï¼Œè¯¥æ¡†æ¶å®ç°äº†ä¸åŸºäºæ¨ç†çš„æ¨¡å‹ç›¸å½“çš„æ³›åŒ–æ€§èƒ½ï¼ŒåŒæ—¶ä»…éœ€è¦ä¸åˆ°5%çš„æ¨¡å‹å‚æ•°å’Œæ¨ç†æ—¶é—´ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰åŸºäºæ¨ç†çš„å›¾åƒè´¨é‡è¯„ä¼°æ¨¡å‹è™½ç„¶å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œä½†ç”±äºä¾èµ–å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œæ¨ç†ï¼Œå¯¼è‡´è®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œæ¨ç†å»¶è¿Ÿå¤§ï¼Œéš¾ä»¥åœ¨èµ„æºå—é™çš„åœºæ™¯ä¸­éƒ¨ç½²ã€‚å› æ­¤ï¼Œå¦‚ä½•é™ä½æ¨ç†æˆæœ¬ï¼Œæé«˜æ•ˆç‡ï¼ŒåŒæ—¶ä¿æŒç”šè‡³æå‡æ³›åŒ–æ€§èƒ½ï¼Œæ˜¯æœ¬æ–‡è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ ç›´æ¥å°†å›¾åƒä¸å¼ºåŒ–å­¦ä¹ è®­ç»ƒå¾—åˆ°çš„ã€å…·æœ‰è‰¯å¥½æ³›åŒ–èƒ½åŠ›çš„æ–‡æœ¬è¡¨å¾å¯¹é½ï¼Œä»è€Œç»•è¿‡LLMçš„æ¨ç†è¿‡ç¨‹ã€‚ä½œè€…è®¤ä¸ºï¼Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒä½¿å¾—LLMèƒ½å¤Ÿå°†å†—ä½™çš„è§†è§‰ä¿¡æ¯å‹ç¼©æˆç´§å‡‘çš„ã€è·¨åŸŸå¯¹é½çš„æ–‡æœ¬è¡¨å¾ï¼Œè€Œè¿™äº›æ–‡æœ¬è¡¨å¾æ‰æ˜¯æ³›åŒ–èƒ½åŠ›çš„å…³é”®ã€‚å› æ­¤ï¼Œç›´æ¥å­¦ä¹ å›¾åƒåˆ°è¿™äº›æ–‡æœ¬è¡¨å¾çš„æ˜ å°„ï¼Œå¯ä»¥é¿å…æ˜‚è´µçš„æ¨ç†è¿‡ç¨‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRALI (Reasoning-Aligned Learning with Images) ç®—æ³•ä¸»è¦åŒ…å«ä¸¤ä¸ªéƒ¨åˆ†ï¼šä¸€æ˜¯åˆ©ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒä¸€ä¸ªåŸºäºLLMçš„å›¾åƒè´¨é‡è¯„ä¼°æ¨¡å‹ï¼Œå¾—åˆ°é«˜è´¨é‡çš„æ–‡æœ¬è¡¨å¾ï¼›äºŒæ˜¯ä½¿ç”¨å¯¹æ¯”å­¦ä¹ ï¼Œè®­ç»ƒä¸€ä¸ªå›¾åƒç¼–ç å™¨ï¼Œä½¿å…¶è¾“å‡ºçš„å›¾åƒè¡¨å¾ä¸ç¬¬ä¸€æ­¥å¾—åˆ°çš„æ–‡æœ¬è¡¨å¾å°½å¯èƒ½æ¥è¿‘ã€‚å…·ä½“æµç¨‹ä¸ºï¼šé¦–å…ˆï¼Œä½¿ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒä¸€ä¸ªIQAæ¨¡å‹ï¼Œè¯¥æ¨¡å‹å°†å›¾åƒä½œä¸ºè¾“å…¥ï¼Œè¾“å‡ºä¸€ä¸ªæ–‡æœ¬æè¿°ï¼Œè¯¥æè¿°åæ˜ äº†å›¾åƒçš„è´¨é‡ã€‚ç„¶åï¼Œä½¿ç”¨å¯¹æ¯”å­¦ä¹ ï¼Œè®­ç»ƒä¸€ä¸ªå›¾åƒç¼–ç å™¨ï¼Œè¯¥ç¼–ç å™¨å°†å›¾åƒä½œä¸ºè¾“å…¥ï¼Œè¾“å‡ºä¸€ä¸ªå‘é‡ï¼Œè¯¥å‘é‡ä¸IQAæ¨¡å‹è¾“å‡ºçš„æ–‡æœ¬æè¿°çš„å‘é‡è¡¨ç¤ºå°½å¯èƒ½æ¥è¿‘ã€‚

**å…³é”®åˆ›æ–°**ï¼šRALIç®—æ³•çš„å…³é”®åˆ›æ–°åœ¨äºï¼Œå®ƒå°†å¼ºåŒ–å­¦ä¹ å’Œå¯¹æ¯”å­¦ä¹ ç»“åˆèµ·æ¥ï¼Œç”¨äºå›¾åƒè´¨é‡è¯„ä¼°ã€‚é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼Œå¯ä»¥å¾—åˆ°é«˜è´¨é‡çš„æ–‡æœ¬è¡¨å¾ï¼Œè¿™äº›è¡¨å¾å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚é€šè¿‡å¯¹æ¯”å­¦ä¹ ï¼Œå¯ä»¥å°†å›¾åƒä¸è¿™äº›æ–‡æœ¬è¡¨å¾å¯¹é½ï¼Œä»è€Œé¿å…äº†æ˜‚è´µçš„æ¨ç†è¿‡ç¨‹ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒRALIç®—æ³•ä¸éœ€è¦åŠ è½½LLMï¼Œå› æ­¤è®¡ç®—æˆæœ¬æ›´ä½ï¼Œæ¨ç†é€Ÿåº¦æ›´å¿«ã€‚

**å…³é”®è®¾è®¡**ï¼šRALIç®—æ³•çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒIQAæ¨¡å‹æ—¶ï¼Œéœ€è¦è®¾è®¡åˆé€‚çš„å¥–åŠ±å‡½æ•°ï¼Œä»¥é¼“åŠ±æ¨¡å‹ç”Ÿæˆé«˜è´¨é‡çš„æ–‡æœ¬æè¿°ã€‚2) ä½¿ç”¨å¯¹æ¯”å­¦ä¹ æ—¶ï¼Œéœ€è¦é€‰æ‹©åˆé€‚çš„å¯¹æ¯”æŸå¤±å‡½æ•°ï¼Œä»¥ç¡®ä¿å›¾åƒè¡¨å¾ä¸æ–‡æœ¬è¡¨å¾èƒ½å¤Ÿæœ‰æ•ˆå¯¹é½ã€‚3) å›¾åƒç¼–ç å™¨çš„ç½‘ç»œç»“æ„éœ€è¦æ ¹æ®å…·ä½“ä»»åŠ¡è¿›è¡Œé€‰æ‹©ï¼Œä»¥ç¡®ä¿èƒ½å¤Ÿæå–åˆ°å›¾åƒçš„å…³é”®ç‰¹å¾ã€‚è®ºæ–‡ä¸­ä½¿ç”¨äº†InfoNCEæŸå¤±ä½œä¸ºå¯¹æ¯”æŸå¤±å‡½æ•°ï¼Œå¹¶ä½¿ç”¨äº†ResNetä½œä¸ºå›¾åƒç¼–ç å™¨ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

RALIç®—æ³•åœ¨å›¾åƒè´¨é‡è¯„ä¼°ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRALIç®—æ³•åœ¨æ³›åŒ–æ€§èƒ½ä¸Šä¸åŸºäºæ¨ç†çš„æ¨¡å‹ç›¸å½“ï¼Œä½†æ¨¡å‹å‚æ•°é‡é™ä½åˆ°åŸæ¥çš„5%ä»¥ä¸‹ï¼Œæ¨ç†æ—¶é—´ä¹Ÿå¤§å¹…ç¼©çŸ­ã€‚è¿™è¡¨æ˜RALIç®—æ³•èƒ½å¤Ÿåœ¨ä¿è¯æ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½è®¡ç®—æˆæœ¬ï¼Œæé«˜æ•ˆç‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

RALIç®—æ³•å¯åº”ç”¨äºå„ç§éœ€è¦å¿«é€Ÿã€ä½æˆæœ¬å›¾åƒè´¨é‡è¯„ä¼°çš„åœºæ™¯ï¼Œä¾‹å¦‚ç§»åŠ¨è®¾å¤‡ä¸Šçš„å›¾åƒå¢å¼ºã€è§†é¢‘ç›‘æ§ç³»ç»Ÿä¸­çš„å›¾åƒè´¨é‡ç›‘æ§ã€ä»¥åŠå¤§è§„æ¨¡å›¾åƒæ•°æ®é›†çš„è´¨é‡æ§åˆ¶ç­‰ã€‚è¯¥æ–¹æ³•é™ä½äº†å¯¹é«˜æ€§èƒ½è®¡ç®—èµ„æºçš„éœ€æ±‚ï¼Œä½¿å¾—é«˜è´¨é‡å›¾åƒè¯„ä¼°èƒ½å¤Ÿéƒ¨ç½²åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Reasoning-based image quality assessment (IQA) models trained through reinforcement learning (RL) exhibit exceptional generalization, yet the underlying mechanisms and critical factors driving this capability remain underexplored in current research. Moreover, despite their superior performance, these models incur inference energy usage and latency orders of magnitude higher than their earlier counterparts, restricting their deployment in specific scenarios. Through extensive experiments, this paper verifies and elaborates that through RL training, MLLMs leverage their reasoning capability to convert redundant visual representations into compact, cross-domain aligned text representations. This conversion is precisely the source of the generalization exhibited by these reasoning-based IQA models. Building on this fundamental insight, we propose a novel algorithm, RALI, which employs contrastive learning to directly align images with these generalizable text representations learned by RL. This approach eliminates the reliance on reasoning processes and even obviates the need to load an LLM. For the quality scoring task, this framework achieves generalization performance comparable to reasoning-based models while requiring less than 5% of their model parameters and inference time.

