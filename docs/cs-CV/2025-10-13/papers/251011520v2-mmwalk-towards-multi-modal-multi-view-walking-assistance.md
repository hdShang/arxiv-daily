---
layout: default
title: mmWalk: Towards Multi-modal Multi-view Walking Assistance
---

# mmWalk: Towards Multi-modal Multi-view Walking Assistance

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.11520" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.11520v2</a>
  <a href="https://arxiv.org/pdf/2510.11520.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.11520v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.11520v2', 'mmWalk: Towards Multi-modal Multi-view Walking Assistance')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kedi Ying, Ruiping Liu, Chongyan Chen, Mingzhe Tao, Hao Shi, Kailun Yang, Jiaming Zhang, Rainer Stiefelhagen

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-13 (æ›´æ–°: 2025-10-23)

**å¤‡æ³¨**: Accepted by NeurIPS 2025 Datasets and Benchmarks Track. Data and Code: https://github.com/KediYing/mmWalk

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**mmWalkï¼šé¢å‘ç›²äººæˆ–ä½è§†åŠ›äººç¾¤çš„å¤šæ¨¡æ€å¤šè§†è§’æ­¥è¡Œè¾…åŠ©æ•°æ®é›†ä¸æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `æ­¥è¡Œè¾…åŠ©` `è§†è§‰éšœç¢` `æ•°æ®é›†æ„å»º` `è§†è§‰é—®ç­”`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç†è§£å¤æ‚ç¯å¢ƒæ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥æœ‰æ•ˆè¾…åŠ©ç›²äººæˆ–ä½è§†åŠ›äººç¾¤åœ¨æˆ·å¤–å®‰å…¨è¡Œèµ°ã€‚
2. mmWalkæ•°æ®é›†é€šè¿‡é›†æˆå¤šè§†è§’ä¼ æ„Ÿå™¨æ•°æ®å’Œå¯è®¿é—®æ€§ç‰¹å¾ï¼Œæ¨¡æ‹ŸçœŸå®ä¸–ç•Œåœºæ™¯ï¼Œä¸ºæ­¥è¡Œè¾…åŠ©æä¾›æ›´å…¨é¢çš„ä¿¡æ¯ã€‚
3. å®éªŒè¡¨æ˜ï¼Œåœ¨mmWalkä¸Šå¾®è°ƒçš„æ¨¡å‹åœ¨çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸­è¡¨ç°è‰¯å¥½ï¼ŒéªŒè¯äº†æ•°æ®é›†çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡é’ˆå¯¹ç›²äººæˆ–ä½è§†åŠ›(BLV)äººç¾¤åœ¨æç«¯æˆ–å¤æ‚ç¯å¢ƒä¸­è¡Œèµ°è¾…åŠ©çš„æŒ‘æˆ˜ï¼Œæ„å»ºäº†ä¸€ä¸ªåä¸ºmmWalkçš„æ¨¡æ‹Ÿå¤šæ¨¡æ€æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†é›†æˆäº†å¤šè§†è§’ä¼ æ„Ÿå™¨å’Œé¢å‘å¯è®¿é—®æ€§çš„ç‰¹å¾ï¼Œç”¨äºæˆ·å¤–å®‰å…¨å¯¼èˆªã€‚mmWalkåŒ…å«120æ¡æ‰‹åŠ¨æ§åˆ¶ã€åœºæ™¯åˆ†ç±»çš„è¡Œèµ°è½¨è¿¹ï¼Œå…±è®¡62kåŒæ­¥å¸§ï¼Œè¶…è¿‡559kå¼ RGBã€æ·±åº¦å’Œè¯­ä¹‰æ¨¡æ€çš„å…¨æ™¯å›¾åƒã€‚ä¸ºäº†å¼ºè°ƒçœŸå®ä¸–ç•Œçš„å…³è”æ€§ï¼Œæ¯æ¡è½¨è¿¹éƒ½åŒ…å«æˆ·å¤–æç«¯æƒ…å†µå’ŒBLVç”¨æˆ·çš„å¯è®¿é—®æ€§ç‰¹å®šåœ°æ ‡ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜ç”Ÿæˆäº†mmWalkVQAï¼Œä¸€ä¸ªåŒ…å«è¶…è¿‡69kä¸ªè§†è§‰é—®ç­”ä¸‰å…ƒç»„çš„VQAåŸºå‡†ï¼Œæ¶µç›–9ä¸ªç±»åˆ«ï¼Œä¸“ä¸ºå®‰å…¨å’ŒçŸ¥æƒ…çš„æ­¥è¡Œè¾…åŠ©è€Œå®šåˆ¶ã€‚é€šè¿‡é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬è®¾ç½®è¯„ä¼°äº†æœ€å…ˆè¿›çš„è§†è§‰è¯­è¨€æ¨¡å‹(VLM)ï¼Œå‘ç°å®ƒä»¬åœ¨é£é™©è¯„ä¼°å’Œå¯¼èˆªä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ã€‚æœ€åï¼Œåœ¨çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸ŠéªŒè¯äº†mmWalkå¾®è°ƒæ¨¡å‹çš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜äº†è¯¥æ•°æ®é›†åœ¨æ¨è¿›å¤šæ¨¡æ€æ­¥è¡Œè¾…åŠ©æ–¹é¢çš„ä»·å€¼ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æ­¥è¡Œè¾…åŠ©ç³»ç»Ÿç¼ºä¹å¯¹å¤æ‚ç¯å¢ƒçš„å…¨é¢ç†è§£ï¼Œå°¤å…¶æ˜¯åœ¨æç«¯æˆ–å¤æ‚åœºæ™¯ä¸‹ï¼Œæ— æ³•ä¸ºç›²äººæˆ–ä½è§†åŠ›äººç¾¤æä¾›å……åˆ†çš„å®‰å…¨ä¿éšœã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆæ•´åˆå¤šæ¨¡æ€ä¿¡æ¯ï¼Œå¹¶ç¼ºä¹é’ˆå¯¹BLVç”¨æˆ·çš„ç‰¹å®šåœºæ™¯å’Œåœ°æ ‡çš„è€ƒè™‘ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªåŒ…å«å¤šæ¨¡æ€ä¿¡æ¯ï¼ˆRGBã€æ·±åº¦ã€è¯­ä¹‰ï¼‰å’Œé’ˆå¯¹BLVç”¨æˆ·çš„ç‰¹å®šåœºæ™¯å’Œåœ°æ ‡çš„æ¨¡æ‹Ÿæ•°æ®é›†mmWalkï¼Œä»è€Œè®­ç»ƒæ›´æœ‰æ•ˆçš„æ­¥è¡Œè¾…åŠ©æ¨¡å‹ã€‚é€šè¿‡æ¨¡æ‹ŸçœŸå®ä¸–ç•Œçš„å¤æ‚åœºæ™¯ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œåº”å¯¹å®é™…æŒ‘æˆ˜ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šmmWalkæ•°æ®é›†åŒ…å«120æ¡æ‰‹åŠ¨æ§åˆ¶çš„è¡Œèµ°è½¨è¿¹ï¼Œæ¯æ¡è½¨è¿¹åŒ…å«åŒæ­¥çš„RGBã€æ·±åº¦å’Œè¯­ä¹‰å›¾åƒã€‚æ­¤å¤–ï¼Œè¿˜æ„å»ºäº†mmWalkVQAåŸºå‡†ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹åœ¨è§†è§‰é—®ç­”æ–¹é¢çš„èƒ½åŠ›ã€‚æ•´ä½“æµç¨‹åŒ…æ‹¬æ•°æ®é‡‡é›†ã€åœºæ™¯åˆ†ç±»ã€æ•°æ®æ ‡æ³¨ï¼ˆåŒ…æ‹¬è¯­ä¹‰åˆ†å‰²å’ŒVQAæ ‡æ³¨ï¼‰ä»¥åŠæ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šå…³é”®åˆ›æ–°åœ¨äºæ•°æ®é›†çš„è®¾è®¡ï¼Œå®ƒä¸ä»…åŒ…å«å¤šæ¨¡æ€ä¿¡æ¯ï¼Œè¿˜ç‰¹åˆ«å…³æ³¨äº†BLVç”¨æˆ·çš„éœ€æ±‚ï¼Œä¾‹å¦‚ï¼ŒåŒ…å«äº†å¯è®¿é—®æ€§ç‰¹å®šåœ°æ ‡å’Œæˆ·å¤–æç«¯æƒ…å†µã€‚æ­¤å¤–ï¼ŒmmWalkVQAåŸºå‡†çš„æ„å»ºä¹Ÿä¸ºè¯„ä¼°æ¨¡å‹åœ¨æ­¥è¡Œè¾…åŠ©æ–¹é¢çš„èƒ½åŠ›æä¾›äº†ä¸€ä¸ªæ–°çš„å¹³å°ã€‚

**å…³é”®è®¾è®¡**ï¼šæ•°æ®é›†åŒ…å«62kåŒæ­¥å¸§ï¼Œè¶…è¿‡559kå¼ å…¨æ™¯å›¾åƒã€‚mmWalkVQAåŒ…å«è¶…è¿‡69kä¸ªè§†è§‰é—®ç­”ä¸‰å…ƒç»„ï¼Œæ¶µç›–9ä¸ªç±»åˆ«ï¼Œä¾‹å¦‚â€œæ˜¯å¦å­˜åœ¨éšœç¢ç‰©ï¼Ÿâ€ã€â€œè¡Œäººé“æ˜¯å¦ç•…é€šï¼Ÿâ€ç­‰ã€‚åœ¨æ¨¡å‹è®­ç»ƒæ–¹é¢ï¼Œä½¿ç”¨äº†æ ‡å‡†çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œå¹¶åœ¨mmWalkæ•°æ®é›†ä¸Šè¿›è¡Œäº†å¾®è°ƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨mmWalkæ•°æ®é›†ä¸Šå¾®è°ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹åœ¨çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šè¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ï¼ŒéªŒè¯äº†mmWalkæ•°æ®é›†çš„æœ‰æ•ˆæ€§ã€‚å…·ä½“è€Œè¨€ï¼Œåœ¨é£é™©è¯„ä¼°å’Œå¯¼èˆªä»»åŠ¡ä¸­ï¼Œå¾®è°ƒåçš„æ¨¡å‹ç›¸æ¯”äºé›¶æ ·æœ¬å’Œå°‘æ ·æœ¬å­¦ä¹ æ–¹æ³•ï¼Œå–å¾—äº†æ˜æ˜¾çš„æ€§èƒ½æå‡ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒmmWalkæ•°æ®é›†èƒ½å¤Ÿæœ‰æ•ˆåœ°æå‡æ¨¡å‹åœ¨å¤šæ¨¡æ€æ­¥è¡Œè¾…åŠ©æ–¹é¢çš„èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¼€å‘æ›´æ™ºèƒ½ã€æ›´å®‰å…¨çš„æ­¥è¡Œè¾…åŠ©ç³»ç»Ÿï¼Œå¸®åŠ©ç›²äººæˆ–ä½è§†åŠ›äººç¾¤åœ¨æˆ·å¤–ç¯å¢ƒä¸­ç‹¬ç«‹è¡Œèµ°ã€‚é€šè¿‡ç»“åˆå¤šæ¨¡æ€ä¼ æ„Ÿå™¨ä¿¡æ¯å’Œå¯è®¿é—®æ€§ç‰¹å¾ï¼Œå¯ä»¥æé«˜æ­¥è¡Œè¾…åŠ©ç³»ç»Ÿçš„ç¯å¢ƒæ„ŸçŸ¥èƒ½åŠ›å’Œé£é™©è¯„ä¼°èƒ½åŠ›ï¼Œä»è€Œæå‡BLVç”¨æˆ·çš„å‡ºè¡Œä½“éªŒå’Œç”Ÿæ´»è´¨é‡ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–è¾…åŠ©æœºå™¨äººé¢†åŸŸï¼Œä¾‹å¦‚è€å¹´äººè¾…åŠ©å’Œæ®‹ç–¾äººè¾…åŠ©ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Walking assistance in extreme or complex environments remains a significant challenge for people with blindness or low vision (BLV), largely due to the lack of a holistic scene understanding. Motivated by the real-world needs of the BLV community, we build mmWalk, a simulated multi-modal dataset that integrates multi-view sensor and accessibility-oriented features for outdoor safe navigation. Our dataset comprises 120 manually controlled, scenario-categorized walking trajectories with 62k synchronized frames. It contains over 559k panoramic images across RGB, depth, and semantic modalities. Furthermore, to emphasize real-world relevance, each trajectory involves outdoor corner cases and accessibility-specific landmarks for BLV users. Additionally, we generate mmWalkVQA, a VQA benchmark with over 69k visual question-answer triplets across 9 categories tailored for safe and informed walking assistance. We evaluate state-of-the-art Vision-Language Models (VLMs) using zero- and few-shot settings and found they struggle with our risk assessment and navigational tasks. We validate our mmWalk-finetuned model on real-world datasets and show the effectiveness of our dataset for advancing multi-modal walking assistance.

