---
layout: default
title: A Survey on Agentic Multimodal Large Language Models
---

# A Survey on Agentic Multimodal Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.10991" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.10991v1</a>
  <a href="https://arxiv.org/pdf/2510.10991.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.10991v1" onclick="toggleFavorite(this, '2510.10991v1', 'A Survey on Agentic Multimodal Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Huanjin Yao, Ruifei Zhang, Jiaxing Huang, Jingyi Zhang, Yibo Wang, Bo Fang, Ruolin Zhu, Yongcheng Jing, Shunyu Liu, Guanbin Li, Dacheng Tao

**åˆ†ç±»**: cs.CV, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-10-13

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/HJYao00/Awesome-Agentic-MLLMs)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç»¼è¿°Agenticå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼Œæ¢ç´¢è‡ªä¸»æ™ºèƒ½ä½“åœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„åº”ç”¨ä¸å‘å±•ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `Agentic MLLM` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `è‡ªä¸»æ™ºèƒ½ä½“` `ç¯å¢ƒäº¤äº’` `å·¥å…·è°ƒç”¨` `æ¨ç†è§„åˆ’` `ç»¼è¿°` `äººå·¥æ™ºèƒ½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»ŸAIæ™ºèƒ½ä½“é™æ€è¢«åŠ¨ï¼ŒAgentic MLLMæ—¨åœ¨æ„å»ºæ›´åŠ¨æ€ã€ä¸»åŠ¨å’Œé€šç”¨çš„æ™ºèƒ½ä½“ï¼Œä»¥åº”å¯¹å¤æ‚ä»»åŠ¡ã€‚
2. è®ºæ–‡æ ¸å¿ƒåœ¨äºæ„å»ºAgentic MLLMçš„æ¦‚å¿µæ¡†æ¶ï¼Œæ¶µç›–å†…éƒ¨æ™ºèƒ½ã€å¤–éƒ¨å·¥å…·è°ƒç”¨å’Œç¯å¢ƒäº¤äº’ä¸‰ä¸ªç»´åº¦ã€‚
3. è®ºæ–‡æ•´ç†äº†å¼€æºè®­ç»ƒæ¡†æ¶ã€æ•°æ®é›†ï¼Œå¹¶åˆ†æäº†ä¸‹æ¸¸åº”ç”¨å’Œæœªæ¥æ–¹å‘ï¼Œæ—¨åœ¨ä¿ƒè¿›Agentic MLLMçš„ç ”ç©¶ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€é©å‘½æ€§çš„è‡ªä¸»æ™ºèƒ½ä½“ç³»ç»Ÿçš„å…´èµ·ï¼Œç ”ç©¶é¢†åŸŸæ­£ç»å†ç€ä»ä¼ ç»Ÿçš„é™æ€ã€è¢«åŠ¨å’Œç‰¹å®šé¢†åŸŸçš„AIæ™ºèƒ½ä½“å‘æ›´åŠ¨æ€ã€ä¸»åŠ¨å’Œé€šç”¨åŒ–çš„Agentic AIçš„é‡å¤§è½¬å˜ã€‚ é‰´äºäººä»¬å¯¹Agentic AIæ—¥ç›Šå¢é•¿çš„å…´è¶£åŠå…¶è¿ˆå‘AGIçš„æ½œåŠ›ï¼Œæœ¬æ–‡å¯¹Agenticå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆAgentic MLLMsï¼‰è¿›è¡Œäº†å…¨é¢çš„ç»¼è¿°ã€‚ æœ¬æ–‡æ¢è®¨äº†Agentic MLLMsçš„æ–°å…´èŒƒå¼ï¼Œé˜è¿°äº†å…¶æ¦‚å¿µåŸºç¡€ï¼Œå¹¶å°†å…¶ä¸ä¼ ç»Ÿçš„åŸºäºMLLMçš„æ™ºèƒ½ä½“åŒºåˆ†å¼€æ¥ã€‚ æˆ‘ä»¬å»ºç«‹äº†ä¸€ä¸ªæ¦‚å¿µæ¡†æ¶ï¼Œè¯¥æ¡†æ¶æ²¿ç€ä¸‰ä¸ªåŸºæœ¬ç»´åº¦ç»„ç»‡Agentic MLLMï¼šï¼ˆiï¼‰Agenticå†…éƒ¨æ™ºèƒ½åŠŸèƒ½ä½œä¸ºç³»ç»Ÿçš„æŒ‡æŒ¥è€…ï¼Œé€šè¿‡æ¨ç†ã€åæ€å’Œè®°å¿†å®ç°å‡†ç¡®çš„é•¿æœŸè§„åˆ’ï¼›ï¼ˆiiï¼‰Agenticå¤–éƒ¨å·¥å…·è°ƒç”¨ï¼Œæ¨¡å‹ä¸»åŠ¨ä½¿ç”¨å„ç§å¤–éƒ¨å·¥å…·æ¥æ‰©å±•å…¶è§£å†³é—®é¢˜çš„èƒ½åŠ›ï¼Œè¶…è¶Šå…¶å†…åœ¨çŸ¥è¯†ï¼›ï¼ˆiiiï¼‰Agenticç¯å¢ƒäº¤äº’è¿›ä¸€æ­¥å°†æ¨¡å‹ç½®äºè™šæ‹Ÿæˆ–ç‰©ç†ç¯å¢ƒä¸­ï¼Œä½¿å…¶èƒ½å¤Ÿé‡‡å–è¡ŒåŠ¨ã€è°ƒæ•´ç­–ç•¥å¹¶åœ¨åŠ¨æ€çš„çœŸå®åœºæ™¯ä¸­ç»´æŒç›®æ ‡å¯¼å‘çš„è¡Œä¸ºã€‚ ä¸ºäº†è¿›ä¸€æ­¥åŠ é€Ÿè¯¥é¢†åŸŸçš„ç ”ç©¶ï¼Œæˆ‘ä»¬æ•´ç†äº†ç”¨äºå¼€å‘Agentic MLLMçš„å¼€æºè®­ç»ƒæ¡†æ¶ã€è®­ç»ƒå’Œè¯„ä¼°æ•°æ®é›†ã€‚ æœ€åï¼Œæˆ‘ä»¬å›é¡¾äº†Agentic MLLMçš„ä¸‹æ¸¸åº”ç”¨ï¼Œå¹¶æ¦‚è¿°äº†è¿™ä¸ªå¿«é€Ÿå‘å±•é¢†åŸŸçš„æœªæ¥ç ”ç©¶æ–¹å‘ã€‚ ä¸ºäº†æŒç»­è·Ÿè¸ªè¿™ä¸ªå¿«é€Ÿå‘å±•é¢†åŸŸçš„è¿›å±•ï¼Œæˆ‘ä»¬è¿˜å°†ç§¯ææ›´æ–°ä¸€ä¸ªå…¬å…±å­˜å‚¨åº“ï¼šhttps://github.com/HJYao00/Awesome-Agentic-MLLMsã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰åŸºäºMLLMçš„æ™ºèƒ½ä½“é€šå¸¸æ˜¯é™æ€å’Œè¢«åŠ¨çš„ï¼Œç¼ºä¹åœ¨å¤æ‚å’ŒåŠ¨æ€ç¯å¢ƒä¸­è‡ªä¸»è§„åˆ’å’Œæ‰§è¡Œä»»åŠ¡çš„èƒ½åŠ›ã€‚å®ƒä»¬éš¾ä»¥æœ‰æ•ˆåœ°åˆ©ç”¨å¤–éƒ¨å·¥å…·ï¼Œå¹¶ä¸”ç¼ºä¹é•¿æœŸè®°å¿†å’Œåæ€èƒ½åŠ›ï¼Œé™åˆ¶äº†å…¶åœ¨ç°å®ä¸–ç•Œä¸­çš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†Agenticèƒ½åŠ›èå…¥åˆ°MLLMä¸­ï¼Œä½¿å…¶èƒ½å¤Ÿåƒäººç±»ä¸€æ ·è¿›è¡Œæ¨ç†ã€è§„åˆ’ã€åæ€å’Œä¸ç¯å¢ƒäº¤äº’ã€‚é€šè¿‡èµ‹äºˆMLLMè‡ªä¸»æ€§ï¼Œä½¿å…¶èƒ½å¤Ÿä¸»åŠ¨åœ°åˆ©ç”¨å¤–éƒ¨å·¥å…·ï¼Œå¹¶æ ¹æ®ç¯å¢ƒåé¦ˆè°ƒæ•´ç­–ç•¥ï¼Œä»è€Œå®ç°æ›´å¼ºå¤§çš„é—®é¢˜è§£å†³èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAgentic MLLMçš„æ¡†æ¶ä¸»è¦åŒ…å«ä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—ï¼š1) Agenticå†…éƒ¨æ™ºèƒ½ï¼šè´Ÿè´£æ¨ç†ã€è§„åˆ’ã€è®°å¿†å’Œåæ€ï¼Œä½œä¸ºç³»ç»Ÿçš„æŒ‡æŒ¥è€…ã€‚2) Agenticå¤–éƒ¨å·¥å…·è°ƒç”¨ï¼šå…è®¸æ¨¡å‹ä¸»åŠ¨è°ƒç”¨å„ç§å¤–éƒ¨å·¥å…·ï¼Œæ‰©å±•å…¶çŸ¥è¯†å’Œèƒ½åŠ›ã€‚3) Agenticç¯å¢ƒäº¤äº’ï¼šä½¿æ¨¡å‹èƒ½å¤Ÿä¸è™šæ‹Ÿæˆ–ç‰©ç†ç¯å¢ƒäº¤äº’ï¼Œé‡‡å–è¡ŒåŠ¨å¹¶è§‚å¯Ÿç»“æœã€‚è¿™ä¸‰ä¸ªæ¨¡å—ååŒå·¥ä½œï¼Œä½¿Agentic MLLMèƒ½å¤Ÿåœ¨åŠ¨æ€ç¯å¢ƒä¸­å®ç°ç›®æ ‡å¯¼å‘çš„è¡Œä¸ºã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç»¼è¿°çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„Agentic MLLMæ¦‚å¿µæ¡†æ¶ï¼Œå¹¶ä»å†…éƒ¨æ™ºèƒ½ã€å¤–éƒ¨å·¥å…·è°ƒç”¨å’Œç¯å¢ƒäº¤äº’ä¸‰ä¸ªç»´åº¦å¯¹å…¶è¿›è¡Œäº†ç³»ç»Ÿæ€§çš„åˆ†æã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æ•´ç†äº†ç›¸å…³çš„èµ„æºï¼ŒåŒ…æ‹¬å¼€æºæ¡†æ¶ã€æ•°æ®é›†å’Œåº”ç”¨æ¡ˆä¾‹ï¼Œä¸ºç ”ç©¶äººå‘˜æä¾›äº†å®è´µçš„å‚è€ƒã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡æœ¬èº«æ˜¯ä¸€ä¸ªç»¼è¿°ï¼Œæ²¡æœ‰æå‡ºå…·ä½“çš„æ¨¡å‹è®¾è®¡ã€‚ä½†æ˜¯ï¼Œå®ƒå¼ºè°ƒäº†Agentic MLLMçš„å…³é”®è®¾è®¡è¦ç´ ï¼Œä¾‹å¦‚å¦‚ä½•è®¾è®¡æœ‰æ•ˆçš„æ¨ç†å’Œè§„åˆ’æœºåˆ¶ï¼Œå¦‚ä½•é€‰æ‹©å’Œåˆ©ç”¨å¤–éƒ¨å·¥å…·ï¼Œä»¥åŠå¦‚ä½•æ„å»ºèƒ½å¤Ÿä¸ç¯å¢ƒäº¤äº’çš„æ¥å£ã€‚è¿™äº›è®¾è®¡è¦ç´ å¯¹äºæ„å»ºå…·æœ‰å®é™…åº”ç”¨ä»·å€¼çš„Agentic MLLMè‡³å…³é‡è¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥è®ºæ–‡æ˜¯ä¸€ç¯‡ç»¼è¿°ï¼Œä¸»è¦è´¡çŒ®åœ¨äºå¯¹Agentic MLLMé¢†åŸŸè¿›è¡Œäº†å…¨é¢çš„æ¢³ç†å’Œæ€»ç»“ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„æ¦‚å¿µæ¡†æ¶ã€‚å®ƒæ•´ç†äº†å¤§é‡çš„ç›¸å…³èµ„æºï¼ŒåŒ…æ‹¬å¼€æºæ¡†æ¶ã€æ•°æ®é›†å’Œåº”ç”¨æ¡ˆä¾‹ï¼Œä¸ºç ”ç©¶äººå‘˜æä¾›äº†å®è´µçš„å‚è€ƒã€‚è¯¥ç»¼è¿°ä¸ºAgentic MLLMçš„æœªæ¥ç ”ç©¶æ–¹å‘æä¾›äº†æŒ‡å¯¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Agentic MLLMåœ¨æœºå™¨äººã€è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½åŠ©æ‰‹ã€æ¸¸æˆAIç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒä»¬å¯ä»¥ç”¨äºè§£å†³å¤æ‚çš„ä»»åŠ¡ï¼Œä¾‹å¦‚è‡ªä¸»å¯¼èˆªã€æ™ºèƒ½å†³ç­–ã€äººæœºåä½œç­‰ã€‚é€šè¿‡ä¸æ–­å­¦ä¹ å’Œé€‚åº”ç¯å¢ƒï¼ŒAgentic MLLMæœ‰æœ›åœ¨æœªæ¥å®ç°æ›´é«˜çº§åˆ«çš„è‡ªä¸»æ™ºèƒ½ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> With the recent emergence of revolutionary autonomous agentic systems, research community is witnessing a significant shift from traditional static, passive, and domain-specific AI agents toward more dynamic, proactive, and generalizable agentic AI. Motivated by the growing interest in agentic AI and its potential trajectory toward AGI, we present a comprehensive survey on Agentic Multimodal Large Language Models (Agentic MLLMs). In this survey, we explore the emerging paradigm of agentic MLLMs, delineating their conceptual foundations and distinguishing characteristics from conventional MLLM-based agents. We establish a conceptual framework that organizes agentic MLLMs along three fundamental dimensions: (i) Agentic internal intelligence functions as the system's commander, enabling accurate long-horizon planning through reasoning, reflection, and memory; (ii) Agentic external tool invocation, whereby models proactively use various external tools to extend their problem-solving capabilities beyond their intrinsic knowledge; and (iii) Agentic environment interaction further situates models within virtual or physical environments, allowing them to take actions, adapt strategies, and sustain goal-directed behavior in dynamic real-world scenarios. To further accelerate research in this area for the community, we compile open-source training frameworks, training and evaluation datasets for developing agentic MLLMs. Finally, we review the downstream applications of agentic MLLMs and outline future research directions for this rapidly evolving field. To continuously track developments in this rapidly evolving field, we will also actively update a public repository at https://github.com/HJYao00/Awesome-Agentic-MLLMs.

