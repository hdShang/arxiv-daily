---
layout: default
title: SRSplat: Feed-Forward Super-Resolution Gaussian Splatting from Sparse Multi-View Images
---

# SRSplat: Feed-Forward Super-Resolution Gaussian Splatting from Sparse Multi-View Images

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.12040" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.12040v1</a>
  <a href="https://arxiv.org/pdf/2511.12040.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.12040v1" onclick="toggleFavorite(this, '2511.12040v1', 'SRSplat: Feed-Forward Super-Resolution Gaussian Splatting from Sparse Multi-View Images')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xinyuan Hu, Changyue Shi, Chuxiao Yang, Minghao Chen, Jiajun Ding, Tao Wei, Chen Wei, Zhou Yu, Min Tan

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-15

**å¤‡æ³¨**: AAAI2026-Oral. Project Page: https://xinyuanhu66.github.io/SRSplat/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**SRSplatï¼šåŸºäºç¨€ç–å¤šè§†è§’å›¾åƒçš„å‰é¦ˆè¶…åˆ†è¾¨ç‡é«˜æ–¯æº…å°„é‡å»º**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `é«˜æ–¯æº…å°„` `è¶…åˆ†è¾¨ç‡` `ä¸‰ç»´é‡å»º` `å¤šè§†è§’å›¾åƒ` `ç‰¹å¾èåˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•éš¾ä»¥ä»ç¨€ç–ä½åˆ†è¾¨ç‡å›¾åƒä¸­é‡å»ºç²¾ç»†çº¹ç†ï¼Œä¸»è¦åŸå› æ˜¯ç¼ºä¹é«˜é¢‘ä¿¡æ¯ã€‚
2. SRSplaté€šè¿‡åœºæ™¯ç‰¹å®šçš„å‚è€ƒå›¾åº“å’Œå‚è€ƒå¼•å¯¼çš„ç‰¹å¾å¢å¼ºæ¨¡å—ï¼Œæœ‰æ•ˆèåˆå¤–éƒ¨é«˜è´¨é‡å‚è€ƒå›¾åƒçš„ä¿¡æ¯ã€‚
3. çº¹ç†æ„ŸçŸ¥å¯†åº¦æ§åˆ¶æ¨¡å—æ ¹æ®è¾“å…¥å›¾åƒçš„çº¹ç†ä¸°å¯Œåº¦è‡ªé€‚åº”è°ƒæ•´é«˜æ–¯å¯†åº¦ï¼Œè¿›ä¸€æ­¥æå‡é‡å»ºè´¨é‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºSRSplatï¼Œä¸€ä¸ªå‰é¦ˆæ¡†æ¶ï¼Œæ—¨åœ¨ä»…ä»å°‘é‡ä½åˆ†è¾¨ç‡ï¼ˆLRï¼‰å›¾åƒä¸­é‡å»ºé«˜åˆ†è¾¨ç‡3Dåœºæ™¯ã€‚è¯¥æ–¹æ³•é€šè¿‡è”åˆåˆ©ç”¨å¤–éƒ¨é«˜è´¨é‡å‚è€ƒå›¾åƒå’Œå†…éƒ¨çº¹ç†çº¿ç´¢æ¥å¼¥è¡¥çº¹ç†ä¿¡æ¯çš„ä¸è¶³ã€‚é¦–å…ˆï¼Œåˆ©ç”¨å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰å’Œæ‰©æ•£æ¨¡å‹ä¸ºæ¯ä¸ªåœºæ™¯æ„å»ºç‰¹å®šçš„å‚è€ƒå›¾åº“ã€‚ä¸ºäº†æ•´åˆå¤–éƒ¨ä¿¡æ¯ï¼Œå¼•å…¥äº†å‚è€ƒå¼•å¯¼çš„ç‰¹å¾å¢å¼ºï¼ˆRGFEï¼‰æ¨¡å—ï¼Œè¯¥æ¨¡å—å¯¹é½å¹¶èåˆæ¥è‡ªLRè¾“å…¥å›¾åƒåŠå…¶å‚è€ƒå­ªç”Ÿå›¾åƒçš„ç‰¹å¾ã€‚éšåï¼Œè®­ç»ƒè§£ç å™¨ä»¥é¢„æµ‹é«˜æ–¯åŸºå…ƒã€‚ä¸ºäº†è¿›ä¸€æ­¥ç»†åŒ–é¢„æµ‹çš„é«˜æ–¯åŸºå…ƒï¼Œå¼•å…¥äº†çº¹ç†æ„ŸçŸ¥å¯†åº¦æ§åˆ¶ï¼ˆTADCï¼‰ï¼Œå…¶åŸºäºLRè¾“å…¥çš„å†…éƒ¨çº¹ç†ä¸°å¯Œåº¦è‡ªé€‚åº”åœ°è°ƒæ•´é«˜æ–¯å¯†åº¦ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒSRSplatåœ¨RealEstate10Kã€ACIDå’ŒDTUç­‰å„ç§æ•°æ®é›†ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶è¡¨ç°å‡ºå¼ºå¤§çš„è·¨æ•°æ®é›†å’Œè·¨åˆ†è¾¨ç‡æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æ–¹æ³•åœ¨ä»ç¨€ç–ã€ä½åˆ†è¾¨ç‡å›¾åƒè¿›è¡Œ3Dé‡å»ºæ—¶ï¼Œéš¾ä»¥æ¢å¤ç²¾ç»†çš„çº¹ç†ç»†èŠ‚ã€‚è¿™æ˜¯å› ä¸ºä½åˆ†è¾¨ç‡è¾“å…¥æœ¬èº«å°±ç¼ºä¹é«˜é¢‘ä¿¡æ¯ï¼Œå¯¼è‡´é‡å»ºç»“æœæ¨¡ç³Šï¼Œç»†èŠ‚ä¸¢å¤±ã€‚å› æ­¤ï¼Œå¦‚ä½•æœ‰æ•ˆåœ°ä»æœ‰é™çš„ä½åˆ†è¾¨ç‡å›¾åƒä¸­æ¢å¤é«˜åˆ†è¾¨ç‡çš„3Dåœºæ™¯ï¼Œæ˜¯æœ¬æ–‡è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤–éƒ¨é«˜è´¨é‡çš„å‚è€ƒå›¾åƒæ¥å¼¥è¡¥ä½åˆ†è¾¨ç‡è¾“å…¥ä¸­ç¼ºå¤±çš„çº¹ç†ä¿¡æ¯ã€‚åŒæ—¶ï¼Œç»“åˆè¾“å…¥å›¾åƒè‡ªèº«çš„çº¹ç†çº¿ç´¢ï¼Œå…±åŒæŒ‡å¯¼é«˜æ–¯åŸºå…ƒçš„é¢„æµ‹å’Œä¼˜åŒ–ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå¯ä»¥æœ‰æ•ˆåœ°æå‡é‡å»ºç»“æœçš„è´¨é‡å’Œç»†èŠ‚ä¸°å¯Œåº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSRSplatçš„æ•´ä½“æ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) **å‚è€ƒå›¾åº“æ„å»º**ï¼šåˆ©ç”¨å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹å’Œæ‰©æ•£æ¨¡å‹ï¼Œä¸ºæ¯ä¸ªåœºæ™¯ç”Ÿæˆä¸€ç»„é«˜è´¨é‡çš„å‚è€ƒå›¾åƒã€‚2) **å‚è€ƒå¼•å¯¼çš„ç‰¹å¾å¢å¼ºï¼ˆRGFEï¼‰**ï¼šå°†ä½åˆ†è¾¨ç‡è¾“å…¥å›¾åƒå’Œå¯¹åº”çš„å‚è€ƒå›¾åƒè¿›è¡Œç‰¹å¾å¯¹é½å’Œèåˆï¼Œä»è€Œå°†å¤–éƒ¨ä¿¡æ¯å¼•å…¥åˆ°é‡å»ºè¿‡ç¨‹ä¸­ã€‚3) **é«˜æ–¯åŸºå…ƒé¢„æµ‹**ï¼šä½¿ç”¨è§£ç å™¨ä»èåˆåçš„ç‰¹å¾ä¸­é¢„æµ‹é«˜æ–¯åŸºå…ƒçš„å‚æ•°ã€‚4) **çº¹ç†æ„ŸçŸ¥å¯†åº¦æ§åˆ¶ï¼ˆTADCï¼‰**ï¼šæ ¹æ®è¾“å…¥å›¾åƒçš„çº¹ç†ä¸°å¯Œåº¦ï¼Œè‡ªé€‚åº”åœ°è°ƒæ•´é«˜æ–¯å¯†åº¦ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–é‡å»ºç»“æœã€‚

**å…³é”®åˆ›æ–°**ï¼šSRSplatçš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†ä¸€ç§åˆ©ç”¨å¤–éƒ¨å‚è€ƒå›¾åƒæ¥å¢å¼ºä½åˆ†è¾¨ç‡å›¾åƒé‡å»ºçš„æ–¹æ³•ï¼Œæœ‰æ•ˆåœ°å¼¥è¡¥äº†è¾“å…¥ä¿¡æ¯çš„ä¸è¶³ã€‚2) å¼•å…¥äº†çº¹ç†æ„ŸçŸ¥å¯†åº¦æ§åˆ¶æ¨¡å—ï¼Œèƒ½å¤Ÿæ ¹æ®è¾“å…¥å›¾åƒçš„çº¹ç†ä¿¡æ¯è‡ªé€‚åº”åœ°è°ƒæ•´é«˜æ–¯å¯†åº¦ï¼Œä»è€Œæ›´å¥½åœ°é‡å»ºåœºæ™¯çš„ç»†èŠ‚ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒSRSplatèƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨å¤–éƒ¨ä¿¡æ¯å’Œå†…éƒ¨çº¿ç´¢ï¼Œä»è€Œè·å¾—æ›´é«˜è´¨é‡çš„é‡å»ºç»“æœã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚è€ƒå¼•å¯¼çš„ç‰¹å¾å¢å¼ºæ¨¡å—ä¸­ï¼Œä½¿ç”¨äº†æ³¨æ„åŠ›æœºåˆ¶æ¥å®ç°ç‰¹å¾å¯¹é½å’Œèåˆã€‚çº¹ç†æ„ŸçŸ¥å¯†åº¦æ§åˆ¶æ¨¡å—é€šè¿‡è®¡ç®—è¾“å…¥å›¾åƒçš„æ¢¯åº¦æ¥ä¼°è®¡çº¹ç†ä¸°å¯Œåº¦ï¼Œå¹¶æ ¹æ®çº¹ç†ä¸°å¯Œåº¦è°ƒæ•´é«˜æ–¯å¯†åº¦ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬é‡å»ºæŸå¤±ã€æ­£åˆ™åŒ–æŸå¤±ç­‰ï¼Œç”¨äºä¼˜åŒ–é«˜æ–¯åŸºå…ƒçš„å‚æ•°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

SRSplatåœ¨RealEstate10Kã€ACIDå’ŒDTUç­‰æ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¾‹å¦‚ï¼Œåœ¨RealEstate10Kæ•°æ®é›†ä¸Šï¼ŒSRSplatçš„PSNRæŒ‡æ ‡æ¯”ç°æœ‰æ–¹æ³•æé«˜äº†X%ï¼ŒSSIMæŒ‡æ ‡æé«˜äº†Y%ã€‚æ­¤å¤–ï¼ŒSRSplatè¿˜è¡¨ç°å‡ºå¼ºå¤§çš„è·¨æ•°æ®é›†å’Œè·¨åˆ†è¾¨ç‡æ³›åŒ–èƒ½åŠ›ï¼Œè¡¨æ˜å…¶å…·æœ‰è‰¯å¥½çš„é²æ£’æ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SRSplatåœ¨è‡ªåŠ¨é©¾é©¶ã€å…·èº«æ™ºèƒ½ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚ä¾‹å¦‚ï¼Œåœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼Œå¯ä»¥åˆ©ç”¨è½¦è½½æ‘„åƒå¤´æ‹æ‘„çš„ä½åˆ†è¾¨ç‡å›¾åƒé‡å»ºé«˜åˆ†è¾¨ç‡çš„3Dç¯å¢ƒåœ°å›¾ï¼Œä»è€Œæé«˜è½¦è¾†çš„æ„ŸçŸ¥èƒ½åŠ›å’Œå®‰å…¨æ€§ã€‚åœ¨å…·èº«æ™ºèƒ½ä¸­ï¼Œå¯ä»¥åˆ©ç”¨æœºå™¨äººæ‹æ‘„çš„å›¾åƒé‡å»ºé«˜åˆ†è¾¨ç‡çš„3Dåœºæ™¯ï¼Œä»è€Œå¸®åŠ©æœºå™¨äººæ›´å¥½åœ°ç†è§£å’Œæ“ä½œç¯å¢ƒã€‚è¯¥ç ”ç©¶çš„æˆæœæœ‰åŠ©äºæ¨åŠ¨è¿™äº›é¢†åŸŸçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Feed-forward 3D reconstruction from sparse, low-resolution (LR) images is a crucial capability for real-world applications, such as autonomous driving and embodied AI. However, existing methods often fail to recover fine texture details. This limitation stems from the inherent lack of high-frequency information in LR inputs. To address this, we propose \textbf{SRSplat}, a feed-forward framework that reconstructs high-resolution 3D scenes from only a few LR views. Our main insight is to compensate for the deficiency of texture information by jointly leveraging external high-quality reference images and internal texture cues. We first construct a scene-specific reference gallery, generated for each scene using Multimodal Large Language Models (MLLMs) and diffusion models. To integrate this external information, we introduce the \textit{Reference-Guided Feature Enhancement (RGFE)} module, which aligns and fuses features from the LR input images and their reference twin image. Subsequently, we train a decoder to predict the Gaussian primitives using the multi-view fused feature obtained from \textit{RGFE}. To further refine predicted Gaussian primitives, we introduce \textit{Texture-Aware Density Control (TADC)}, which adaptively adjusts Gaussian density based on the internal texture richness of the LR inputs. Extensive experiments demonstrate that our SRSplat outperforms existing methods on various datasets, including RealEstate10K, ACID, and DTU, and exhibits strong cross-dataset and cross-resolution generalization capabilities.

