---
layout: default
title: Constructing and Interpreting Digital Twin Representations for Visual Reasoning via Reinforcement Learning
---

# Constructing and Interpreting Digital Twin Representations for Visual Reasoning via Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.12365" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.12365v1</a>
  <a href="https://arxiv.org/pdf/2511.12365.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.12365v1" onclick="toggleFavorite(this, '2511.12365v1', 'Constructing and Interpreting Digital Twin Representations for Visual Reasoning via Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yiqing Shen, Mathias Unberath

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-15

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå¼ºåŒ–å­¦ä¹ çš„DT-R1æ¡†æ¶ï¼Œåˆ©ç”¨æ•°å­—å­ªç”Ÿè¡¨ç¤ºç»Ÿä¸€è§£å†³è§†è§‰æ¨ç†ä»»åŠ¡ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è§†è§‰æ¨ç†` `æ•°å­—å­ªç”Ÿ` `å¼ºåŒ–å­¦ä¹ ` `å¤§å‹è¯­è¨€æ¨¡å‹` `å¤šæ¨¡æ€å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰æ¨ç†æ–¹æ³•ä¾èµ–äºç‰¹å®šä»»åŠ¡çš„ç›‘ç£å¾®è°ƒï¼Œç¼ºä¹ç»Ÿä¸€æ€§å’Œè·¨ä»»åŠ¡æ³›åŒ–èƒ½åŠ›ã€‚
2. DT-R1åˆ©ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹æ„å»ºè§†è§‰è¾“å…¥çš„æ•°å­—å­ªç”Ÿè¡¨ç¤ºï¼Œå®ç°ç»Ÿä¸€çš„è§†è§‰æ¨ç†ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒDT-R1åœ¨å…­ä¸ªè§†è§‰æ¨ç†åŸºå‡†æµ‹è¯•ä¸­å§‹ç»ˆä¼˜äºæœ€å…ˆè¿›çš„ç‰¹å®šä»»åŠ¡æ¨¡å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰æ¨ç†éœ€è¦æ¨¡å‹ç†è§£å›¾åƒå’Œè§†é¢‘ï¼Œå¹¶å¯¹å„ç§è¾“å‡ºæ ¼å¼ï¼ˆä»åƒç´ çº§åˆ†å‰²æ©ç åˆ°è‡ªç„¶è¯­è¨€æè¿°ï¼‰çš„éšå¼æ–‡æœ¬æŸ¥è¯¢åšå‡ºå“åº”ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºé’ˆå¯¹ç‰¹å®šä»»åŠ¡æ¶æ„çš„ç›‘ç£å¾®è°ƒã€‚ä¾‹å¦‚ï¼Œæ¨ç†åˆ†å‰²ã€å®šä½ã€æ‘˜è¦å’Œè§†è§‰é—®ç­”éƒ½éœ€è¦ä¸åŒçš„æ¨¡å‹è®¾è®¡å’Œè®­ç»ƒï¼Œè¿™é˜»ç¢äº†ç»Ÿä¸€çš„è§£å†³æ–¹æ¡ˆï¼Œå¹¶é™åˆ¶äº†è·¨ä»»åŠ¡å’Œè·¨æ¨¡æ€çš„æ³›åŒ–ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†DT-R1ï¼Œä¸€ä¸ªå¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œå®ƒè®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹æ¥æ„å»ºå¤æ‚å¤šæ¨¡æ€è§†è§‰è¾“å…¥çš„æ•°å­—å­ªç”Ÿè¡¨ç¤ºï¼Œç„¶ååŸºäºè¿™äº›é«˜çº§è¡¨ç¤ºè¿›è¡Œæ¨ç†ï¼Œä½œä¸ºè§†è§‰æ¨ç†çš„ç»Ÿä¸€æ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä½¿ç”¨GRPOè®­ç»ƒDT-R1ï¼Œå¹¶ä½¿ç”¨ä¸€ç§æ–°é¢–çš„å¥–åŠ±ï¼Œè¯¥å¥–åŠ±éªŒè¯ç»“æ„å®Œæ•´æ€§å’Œè¾“å‡ºå‡†ç¡®æ€§ã€‚åœ¨æ¶µç›–ä¸¤ç§æ¨¡æ€å’Œå››ç§ä»»åŠ¡ç±»å‹çš„å…­ä¸ªè§†è§‰æ¨ç†åŸºå‡†æµ‹è¯•ä¸­è¿›è¡Œçš„è¯„ä¼°è¡¨æ˜ï¼ŒDT-R1å§‹ç»ˆä¼˜äºæœ€å…ˆè¿›çš„ç‰¹å®šä»»åŠ¡æ¨¡å‹ã€‚DT-R1å¼€è¾Ÿäº†ä¸€ä¸ªæ–°çš„æ–¹å‘ï¼Œå³è§†è§‰æ¨ç†æºäºä½¿ç”¨æ•°å­—å­ªç”Ÿè¡¨ç¤ºçš„å¼ºåŒ–å­¦ä¹ ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰è§†è§‰æ¨ç†æ–¹æ³•é’ˆå¯¹ä¸åŒä»»åŠ¡ï¼ˆå¦‚åˆ†å‰²ã€å®šä½ã€é—®ç­”ç­‰ï¼‰éœ€è¦è®¾è®¡ä¸åŒçš„æ¨¡å‹æ¶æ„å’Œè®­ç»ƒæµç¨‹ï¼Œå¯¼è‡´æ¨¡å‹éš¾ä»¥æ³›åŒ–åˆ°æ–°çš„ä»»åŠ¡å’Œæ¨¡æ€ä¸Šã€‚è¿™äº›æ–¹æ³•ç¼ºä¹ä¸€ä¸ªç»Ÿä¸€çš„è¡¨ç¤ºå­¦ä¹ æ¡†æ¶ï¼Œæ— æ³•æœ‰æ•ˆåœ°åˆ©ç”¨å¤šæ¨¡æ€ä¿¡æ¯è¿›è¡Œæ¨ç†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œä½¿å…¶èƒ½å¤Ÿå°†å¤æ‚çš„è§†è§‰è¾“å…¥è½¬åŒ–ä¸ºä¸€ç§é«˜å±‚æ¬¡çš„â€œæ•°å­—å­ªç”Ÿâ€è¡¨ç¤ºã€‚è¿™ç§è¡¨ç¤ºèƒ½å¤Ÿæ•æ‰è§†è§‰åœºæ™¯çš„å…³é”®ç»“æ„å’Œè¯­ä¹‰ä¿¡æ¯ï¼Œä»è€Œä¸ºåç»­çš„æ¨ç†ä»»åŠ¡æä¾›ä¸€ä¸ªç»Ÿä¸€çš„åŸºç¡€ã€‚é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼Œæ¨¡å‹å¯ä»¥å­¦ä¹ å¦‚ä½•æ„å»ºæ—¢èƒ½ä¿æŒç»“æ„å®Œæ•´æ€§åˆèƒ½ä¿è¯è¾“å‡ºå‡†ç¡®æ€§çš„æ•°å­—å­ªç”Ÿè¡¨ç¤ºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDT-R1æ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªå…³é”®æ¨¡å—ï¼š1) è§†è§‰è¾“å…¥ç¼–ç å™¨ï¼šå°†å›¾åƒæˆ–è§†é¢‘ç­‰è§†è§‰è¾“å…¥ç¼–ç æˆç‰¹å¾å‘é‡ã€‚2) å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼šä½œä¸ºæ™ºèƒ½ä½“ï¼Œè´Ÿè´£æ ¹æ®è§†è§‰ç‰¹å¾é€æ­¥æ„å»ºæ•°å­—å­ªç”Ÿè¡¨ç¤ºã€‚3) å¼ºåŒ–å­¦ä¹ ç¯å¢ƒï¼šå®šä¹‰äº†æ™ºèƒ½ä½“çš„åŠ¨ä½œç©ºé—´ï¼ˆä¾‹å¦‚ï¼Œæ·»åŠ ã€ä¿®æ”¹æ•°å­—å­ªç”Ÿè¡¨ç¤ºçš„èŠ‚ç‚¹å’Œå…³ç³»ï¼‰å’ŒçŠ¶æ€ç©ºé—´ï¼ˆä¾‹å¦‚ï¼Œå½“å‰çš„æ•°å­—å­ªç”Ÿè¡¨ç¤ºå’Œè§†è§‰ç‰¹å¾ï¼‰ã€‚4) å¥–åŠ±å‡½æ•°ï¼šç”¨äºè¯„ä¼°æ™ºèƒ½ä½“æ„å»ºçš„æ•°å­—å­ªç”Ÿè¡¨ç¤ºçš„è´¨é‡ï¼ŒåŒ…æ‹¬ç»“æ„å®Œæ•´æ€§å’Œè¾“å‡ºå‡†ç¡®æ€§ã€‚æ¡†æ¶ä½¿ç”¨GRPOï¼ˆGradient Ratio Policy Optimizationï¼‰ç®—æ³•è¿›è¡Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ä½¿ç”¨æ•°å­—å­ªç”Ÿè¡¨ç¤ºä½œä¸ºç»Ÿä¸€çš„è§†è§‰æ¨ç†æ¡†æ¶ã€‚ä¸ä»¥å¾€é’ˆå¯¹ç‰¹å®šä»»åŠ¡è®¾è®¡æ¨¡å‹ä¸åŒï¼ŒDT-R1é€šè¿‡å­¦ä¹ æ„å»ºé«˜å±‚æ¬¡çš„åœºæ™¯è¡¨ç¤ºï¼Œå®ç°äº†è·¨ä»»åŠ¡å’Œè·¨æ¨¡æ€çš„æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œä½¿ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒLLMæ¥æ„å»ºæ•°å­—å­ªç”Ÿè¡¨ç¤ºä¹Ÿæ˜¯ä¸€ä¸ªé‡è¦çš„åˆ›æ–°ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿè‡ªé€‚åº”åœ°å­¦ä¹ å¦‚ä½•æœ‰æ•ˆåœ°è¡¨ç¤ºè§†è§‰ä¿¡æ¯ã€‚

**å…³é”®è®¾è®¡**ï¼šå¥–åŠ±å‡½æ•°çš„è®¾è®¡æ˜¯å…³é”®ã€‚è®ºæ–‡è®¾è®¡äº†ä¸€ç§æ–°é¢–çš„å¥–åŠ±å‡½æ•°ï¼Œå®ƒåŒæ—¶è€ƒè™‘äº†æ•°å­—å­ªç”Ÿè¡¨ç¤ºçš„ç»“æ„å®Œæ•´æ€§å’Œè¾“å‡ºå‡†ç¡®æ€§ã€‚ç»“æ„å®Œæ•´æ€§å¥–åŠ±é¼“åŠ±æ™ºèƒ½ä½“æ„å»ºç¬¦åˆè§†è§‰åœºæ™¯ç»“æ„çš„è¡¨ç¤ºï¼Œä¾‹å¦‚ï¼Œä¿æŒå¯¹è±¡ä¹‹é—´çš„ç©ºé—´å…³ç³»ã€‚è¾“å‡ºå‡†ç¡®æ€§å¥–åŠ±åˆ™æ ¹æ®ä¸‹æ¸¸æ¨ç†ä»»åŠ¡çš„æ€§èƒ½æ¥è¯„ä¼°è¡¨ç¤ºçš„è´¨é‡ï¼Œä¾‹å¦‚ï¼Œåœ¨è§†è§‰é—®ç­”ä»»åŠ¡ä¸­ï¼Œå¥–åŠ±æ™ºèƒ½ä½“ç”Ÿæˆèƒ½å¤Ÿæ­£ç¡®å›ç­”é—®é¢˜çš„è¡¨ç¤ºã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœªè¯¦ç»†è¯´æ˜ï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

DT-R1åœ¨å…­ä¸ªè§†è§‰æ¨ç†åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œæ¶µç›–äº†ä¸¤ç§æ¨¡æ€ï¼ˆå›¾åƒå’Œè§†é¢‘ï¼‰å’Œå››ç§ä»»åŠ¡ç±»å‹ï¼ˆåˆ†å‰²ã€å®šä½ã€æ‘˜è¦å’Œé—®ç­”ï¼‰ã€‚ä¸æœ€å…ˆè¿›çš„ç‰¹å®šä»»åŠ¡æ¨¡å‹ç›¸æ¯”ï¼ŒDT-R1åœ¨æ‰€æœ‰åŸºå‡†æµ‹è¯•ä¸­éƒ½å–å¾—äº†æ›´å¥½çš„ç»“æœï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚å…·ä½“çš„æ€§èƒ½æå‡æ•°æ®åœ¨è®ºæ–‡ä¸­æœªè¯¦ç»†ç»™å‡ºï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

DT-R1æ¡†æ¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚æ™ºèƒ½æœºå™¨äººã€è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½ç›‘æ§ç­‰é¢†åŸŸã€‚å®ƒå¯ä»¥å¸®åŠ©æœºå™¨äººæ›´å¥½åœ°ç†è§£å‘¨å›´ç¯å¢ƒï¼Œä»è€Œå®ç°æ›´æ™ºèƒ½çš„å¯¼èˆªå’Œäº¤äº’ã€‚åœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸï¼ŒDT-R1å¯ä»¥ç”¨äºæ„å»ºè½¦è¾†å‘¨å›´ç¯å¢ƒçš„æ•°å­—å­ªç”Ÿæ¨¡å‹ï¼Œæé«˜é©¾é©¶å®‰å…¨æ€§ã€‚åœ¨æ™ºèƒ½ç›‘æ§é¢†åŸŸï¼ŒDT-R1å¯ä»¥ç”¨äºåˆ†æç›‘æ§è§†é¢‘ï¼Œè‡ªåŠ¨è¯†åˆ«å¼‚å¸¸äº‹ä»¶ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Visual reasoning may require models to interpret images and videos and respond to implicit text queries across diverse output formats, from pixel-level segmentation masks to natural language descriptions. Existing approaches rely on supervised fine-tuning with task-specific architectures. For example, reasoning segmentation, grounding, summarization, and visual question answering each demand distinct model designs and training, preventing unified solutions and limiting cross-task and cross-modality generalization. Hence, we propose DT-R1, a reinforcement learning framework that trains large language models to construct digital twin representations of complex multi-modal visual inputs and then reason over these high-level representations as a unified approach to visual reasoning. Specifically, we train DT-R1 using GRPO with a novel reward that validates both structural integrity and output accuracy. Evaluations in six visual reasoning benchmarks, covering two modalities and four task types, demonstrate that DT-R1 consistently achieves improvements over state-of-the-art task-specific models. DT-R1 opens a new direction where visual reasoning emerges from reinforcement learning with digital twin representations.

