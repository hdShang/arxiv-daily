---
layout: default
title: From Competition to Synergy: Unlocking Reinforcement Learning for Subject-Driven Image Generation
---

# From Competition to Synergy: Unlocking Reinforcement Learning for Subject-Driven Image Generation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.18263" target="_blank" class="toolbar-btn">arXiv: 2510.18263v1</a>
    <a href="https://arxiv.org/pdf/2510.18263.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.18263v1" 
            onclick="toggleFavorite(this, '2510.18263v1', 'From Competition to Synergy: Unlocking Reinforcement Learning for Subject-Driven Image Generation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Ziwei Huang, Ying Shu, Hao Fang, Quanyu Long, Wenya Wang, Qiushi Guo, Tiezheng Ge, Leilei Gan

**ÂàÜÁ±ª**: cs.LG, cs.CV, cs.GR

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-21

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Customized-GRPOÔºåËß£ÂÜ≥‰∏ª‰ΩìÈ©±Âä®ÂõæÂÉèÁîüÊàê‰∏≠‰øùÁúüÂ∫¶ÂíåÂèØÁºñËæëÊÄßÁöÑtrade-offÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `‰∏ª‰ΩìÈ©±Âä®ÂõæÂÉèÁîüÊàê` `Âº∫ÂåñÂ≠¶‰π†` `Êâ©Êï£Ê®°Âûã` `Â•ñÂä±Â°ëÈÄ†` `Âä®ÊÄÅÂä†ÊùÉ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ‰∏ª‰ΩìÈ©±Âä®ÂõæÂÉèÁîüÊàêÈúÄË¶ÅÂú®Ë∫´‰ªΩ‰øùÊåÅÂíåÊèêÁ§∫ÈÅµÂæ™‰πãÈó¥ÊùÉË°°ÔºåÁé∞ÊúâÊñπÊ≥ïÈöæ‰ª•ÂÖºÈ°æ„ÄÇ
2. Customized-GRPOÈÄöËøáÂçèÂêåÊÑüÁü•Â•ñÂä±Â°ëÈÄ†ÂíåÊó∂Èó¥ÊÑüÁü•Âä®ÊÄÅÂä†ÊùÉÔºå‰ºòÂåñÂº∫ÂåñÂ≠¶‰π†ËøáÁ®ã„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåËØ•ÊñπÊ≥ïÊòæËëó‰ºò‰∫éÁé∞ÊúâÂü∫Á∫øÔºåÂú®‰øùÁúüÂ∫¶ÂíåÂèØÁºñËæëÊÄß‰∏äÂèñÂæó‰∫ÜÊõ¥Â•ΩÁöÑÂπ≥Ë°°„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

‰∏ª‰ΩìÈ©±Âä®ÁöÑÂõæÂÉèÁîüÊàêÊ®°ÂûãÈù¢‰∏¥ÁùÄË∫´‰ªΩ‰øùÊåÅÔºà‰øùÁúüÂ∫¶ÔºâÂíåÊèêÁ§∫ÈÅµÂæ™ÔºàÂèØÁºñËæëÊÄßÔºâ‰πãÈó¥ÁöÑÊ†πÊú¨ÊùÉË°°„ÄÇÂú®Á∫øÂº∫ÂåñÂ≠¶‰π†ÔºàRLÔºâÔºåÁâπÂà´ÊòØGPROÔºå‰∏∫Ê≠§Êèê‰æõ‰∫Ü‰∏Ä‰∏™ÊúâÂ∏åÊúõÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇÁÑ∂ËÄåÔºåÊàë‰ª¨ÂèëÁé∞ÁÆÄÂçïÂú∞Â∫îÁî®GRPO‰ºöÂØºËá¥Á´û‰∫âÊÄßÈÄÄÂåñÔºåÂõ†‰∏∫ÂÖ∑ÊúâÈùôÊÄÅÊùÉÈáçÁöÑÂ•ñÂä±ÁöÑÁÆÄÂçïÁ∫øÊÄßËÅöÂêà‰ºöÂØºËá¥ÂÜ≤Á™ÅÁöÑÊ¢ØÂ∫¶‰ø°Âè∑ÔºåÂπ∂‰∏éÊâ©Êï£ËøáÁ®ãÁöÑÊó∂Èó¥Âä®ÊÄÅ‰∏ç‰∏ÄËá¥„ÄÇ‰∏∫‰∫ÜÂÖãÊúçËøô‰∫õÈôêÂà∂ÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜCustomized-GRPOÔºåËøôÊòØ‰∏Ä‰∏™Êñ∞È¢ñÁöÑÊ°ÜÊû∂ÔºåÂåÖÂê´‰∏§‰∏™ÂÖ≥ÈîÆÂàõÊñ∞ÔºöÔºàiÔºâÂçèÂêåÊÑüÁü•Â•ñÂä±Â°ëÈÄ†ÔºàSARSÔºâÔºå‰∏ÄÁßçÈùûÁ∫øÊÄßÊú∫Âà∂ÔºåÂÆÉÊòéÁ°ÆÂú∞ÊÉ©ÁΩöÂÜ≤Á™ÅÁöÑÂ•ñÂä±‰ø°Âè∑Âπ∂ÊîæÂ§ßÂçèÂêåÁöÑÂ•ñÂä±‰ø°Âè∑Ôºå‰ªéËÄåÊèê‰æõÊõ¥Ê∏ÖÊô∞ÂíåÊõ¥ÊûúÊñ≠ÁöÑÊ¢ØÂ∫¶„ÄÇÔºàiiÔºâÊó∂Èó¥ÊÑüÁü•Âä®ÊÄÅÂä†ÊùÉÔºàTDWÔºâÔºåÂÆÉÈÄöËøá‰ºòÂÖàËÄÉËôëÊó©ÊúüÈò∂ÊÆµÁöÑÊèêÁ§∫ÈÅµÂæ™ÂíåÂêéÊúüÈò∂ÊÆµÁöÑË∫´‰ªΩ‰øùÊåÅÔºå‰Ωø‰ºòÂåñÂéãÂäõ‰∏éÊ®°ÂûãÁöÑÊó∂Èó¥Âä®ÊÄÅ‰øùÊåÅ‰∏ÄËá¥„ÄÇÂ§ßÈáèÁöÑÂÆûÈ™åË°®ÊòéÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÊòéÊòæ‰ºò‰∫éÊú¥Á¥†ÁöÑGRPOÂü∫Á∫øÔºåÊàêÂäüÂú∞ÂáèËΩª‰∫ÜÁ´û‰∫âÊÄßÈÄÄÂåñ„ÄÇÊàë‰ª¨ÁöÑÊ®°ÂûãÂÆûÁé∞‰∫ÜÂçìË∂äÁöÑÂπ≥Ë°°ÔºåÁîüÊàêÊó¢‰øùÁïô‰∫ÜÂÖ≥ÈîÆË∫´‰ªΩÁâπÂæÅÂèàÂáÜÁ°ÆÂú∞ÈÅµÂæ™Â§çÊùÇÊñáÊú¨ÊèêÁ§∫ÁöÑÂõæÂÉè„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**Ôºö‰∏ª‰ΩìÈ©±Âä®ÂõæÂÉèÁîüÊàêÊó®Âú®Ê†πÊçÆÁªôÂÆöÁöÑ‰∏ª‰ΩìÂõæÂÉèÂíåÊñáÊú¨ÊèêÁ§∫ÁîüÊàêÊñ∞ÁöÑÂõæÂÉè„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®Ë∫´‰ªΩ‰øùÊåÅÔºà‰øùÁúüÂ∫¶ÔºâÂíåÊèêÁ§∫ÈÅµÂæ™ÔºàÂèØÁºñËæëÊÄßÔºâ‰πãÈó¥Â≠òÂú®trade-off„ÄÇÁÆÄÂçïÂú∞Â∫îÁî®Âº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÔºàÂ¶ÇGPROÔºâ‰ºöÂØºËá¥Ê¢ØÂ∫¶ÂÜ≤Á™ÅÂíå‰∏éÊâ©Êï£Ê®°ÂûãÊó∂Èó¥Âä®ÊÄÅÁöÑ‰∏çÂåπÈÖçÔºå‰ªéËÄåÂØºËá¥ÊÄßËÉΩ‰∏ãÈôç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöCustomized-GRPOÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÂÆöÂà∂ÂåñÁöÑÂ•ñÂä±Â°ëÈÄ†ÂíåÂä®ÊÄÅÊùÉÈáçË∞ÉÊï¥Ôºå‰ºòÂåñÂº∫ÂåñÂ≠¶‰π†ËøáÁ®ãÔºå‰ªéËÄåÂú®Ë∫´‰ªΩ‰øùÊåÅÂíåÊèêÁ§∫ÈÅµÂæ™‰πãÈó¥ÂèñÂæóÊõ¥Â•ΩÁöÑÂπ≥Ë°°„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÂÆÉÈÄöËøáÈùûÁ∫øÊÄßÊñπÂºèÂ§ÑÁêÜÂ•ñÂä±‰ø°Âè∑ÔºåÂπ∂Ê†πÊçÆÊâ©Êï£ËøáÁ®ãÁöÑÊó∂Èó¥Ê≠•Ë∞ÉÊï¥‰ºòÂåñÈáçÁÇπ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöCustomized-GRPOÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰∏§‰∏™ÂÖ≥ÈîÆÊ®°ÂùóÔºöÂçèÂêåÊÑüÁü•Â•ñÂä±Â°ëÈÄ†ÔºàSARSÔºâÂíåÊó∂Èó¥ÊÑüÁü•Âä®ÊÄÅÂä†ÊùÉÔºàTDWÔºâ„ÄÇSARSÊ®°ÂùóÁî®‰∫éÂ§ÑÁêÜÊù•Ëá™‰∏çÂêåÂ•ñÂä±ÂáΩÊï∞ÁöÑ‰ø°Âè∑ÔºåÈÄöËøáÈùûÁ∫øÊÄßÊñπÂºèÊîæÂ§ßÂçèÂêå‰ø°Âè∑Âπ∂ÊäëÂà∂ÂÜ≤Á™Å‰ø°Âè∑„ÄÇTDWÊ®°ÂùóÊ†πÊçÆÊâ©Êï£ËøáÁ®ãÁöÑÊó∂Èó¥Ê≠•Âä®ÊÄÅË∞ÉÊï¥Ë∫´‰ªΩ‰øùÊåÅÂíåÊèêÁ§∫ÈÅµÂæ™ÁöÑÊùÉÈáçÔºåÊó©ÊúüÊõ¥Ê≥®ÈáçÊèêÁ§∫ÈÅµÂæ™ÔºåÂêéÊúüÊõ¥Ê≥®ÈáçË∫´‰ªΩ‰øùÊåÅ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöCustomized-GRPOÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö(1) ÊèêÂá∫‰∫ÜÂçèÂêåÊÑüÁü•Â•ñÂä±Â°ëÈÄ†ÔºàSARSÔºâÔºåÂÆÉËÉΩÂ§üÊúâÊïàÂú∞Â§ÑÁêÜÊù•Ëá™‰∏çÂêåÂ•ñÂä±ÂáΩÊï∞ÁöÑÂÜ≤Á™Å‰ø°Âè∑ÔºåÂπ∂Êèê‰æõÊõ¥Ê∏ÖÊô∞ÁöÑÊ¢ØÂ∫¶„ÄÇ(2) ÊèêÂá∫‰∫ÜÊó∂Èó¥ÊÑüÁü•Âä®ÊÄÅÂä†ÊùÉÔºàTDWÔºâÔºåÂÆÉËÉΩÂ§üÊ†πÊçÆÊâ©Êï£ËøáÁ®ãÁöÑÊó∂Èó¥Ê≠•Âä®ÊÄÅË∞ÉÊï¥‰ºòÂåñÈáçÁÇπÔºå‰ªéËÄåÊõ¥Â•ΩÂú∞ÈÄÇÂ∫îÊâ©Êï£Ê®°ÂûãÁöÑÊó∂Èó¥Âä®ÊÄÅ„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåCustomized-GRPOËÉΩÂ§üÊõ¥Â•ΩÂú∞Âπ≥Ë°°Ë∫´‰ªΩ‰øùÊåÅÂíåÊèêÁ§∫ÈÅµÂæ™„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöSARSÊ®°Âùó‰ΩøÁî®ÈùûÁ∫øÊÄßÂáΩÊï∞Êù•Â§ÑÁêÜÂ•ñÂä±‰ø°Âè∑ÔºåÂÖ∑‰ΩìÂΩ¢ÂºèÊú™Áü•ÔºàËÆ∫ÊñáÊú™ÊòéÁ°ÆÁªôÂá∫Ôºâ„ÄÇTDWÊ®°Âùó‰ΩøÁî®Êó∂Èó¥Ê≠•ÁöÑÂáΩÊï∞Êù•Âä®ÊÄÅË∞ÉÊï¥ÊùÉÈáçÔºåÂÖ∑‰ΩìÂΩ¢ÂºèÊú™Áü•ÔºàËÆ∫ÊñáÊú™ÊòéÁ°ÆÁªôÂá∫Ôºâ„ÄÇÊçüÂ§±ÂáΩÊï∞ÊòØÂº∫ÂåñÂ≠¶‰π†‰∏≠ÁöÑÊ†áÂáÜÊçüÂ§±ÂáΩÊï∞Ôºå‰ΩÜÂ•ñÂä±‰ø°Âè∑ÁªèËøá‰∫ÜSARSÂ§ÑÁêÜÔºåÊùÉÈáçÁªèËøá‰∫ÜTDWË∞ÉÊï¥„ÄÇÁΩëÁªúÁªìÊûÑÂü∫‰∫éÁé∞ÊúâÁöÑÊâ©Êï£Ê®°ÂûãÊû∂ÊûÑÔºåÊ≤°ÊúâËøõË°åÊòæËëó‰øÆÊîπ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåCustomized-GRPOÊòæËëó‰ºò‰∫éÊú¥Á¥†ÁöÑGRPOÂü∫Á∫øÔºåÂú®Ë∫´‰ªΩ‰øùÊåÅÂíåÊèêÁ§∫ÈÅµÂæ™ÊñπÈù¢ÈÉΩÂèñÂæó‰∫ÜÊõ¥Â•ΩÁöÑÊÄßËÉΩ„ÄÇÂÖ∑‰ΩìÊÄßËÉΩÊï∞ÊçÆÊú™Áü•ÔºàËÆ∫ÊñáÊëòË¶ÅÊú™Êèê‰æõÂÖ∑‰ΩìÊï∞ÂÄºÔºâÔºå‰ΩÜÂº∫Ë∞É‰∫ÜËØ•ÊñπÊ≥ïÊàêÂäüÂáèËΩª‰∫ÜÁ´û‰∫âÊÄßÈÄÄÂåñÔºåÂÆûÁé∞‰∫ÜÂçìË∂äÁöÑÂπ≥Ë°°„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂõæÂÉèÁºñËæë„ÄÅÂÜÖÂÆπÂàõ‰Ωú„ÄÅËôöÊãü‰∫∫Áâ©ÁîüÊàêÁ≠âÈ¢ÜÂüü„ÄÇ‰æãÂ¶ÇÔºåÁî®Êà∑ÂèØ‰ª•‰∏ä‰º†‰∏ÄÂº†‰∫∫ËÑ∏ÁÖßÁâáÔºåÂπ∂ËæìÂÖ•‰∏ÄÊÆµÊñáÂ≠óÊèèËø∞ÔºåÁîüÊàêÂÖ∑ÊúâËØ•‰∫∫ËÑ∏ÁâπÂæÅÂπ∂Á¨¶ÂêàÊñáÂ≠óÊèèËø∞ÁöÑÊñ∞ÂõæÂÉè„ÄÇËØ•ÊäÄÊúØÂú®Ê∏∏ÊàèÂºÄÂèë„ÄÅÂπøÂëäËÆæËÆ°„ÄÅÁ§æ‰∫§Â™í‰ΩìÁ≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåËÉΩÂ§üÈôç‰ΩéÂàõ‰ΩúÊàêÊú¨ÔºåÊèêÈ´òÂàõ‰ΩúÊïàÁéá„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Subject-driven image generation models face a fundamental trade-off between identity preservation (fidelity) and prompt adherence (editability). While online reinforcement learning (RL), specifically GPRO, offers a promising solution, we find that a naive application of GRPO leads to competitive degradation, as the simple linear aggregation of rewards with static weights causes conflicting gradient signals and a misalignment with the temporal dynamics of the diffusion process. To overcome these limitations, we propose Customized-GRPO, a novel framework featuring two key innovations: (i) Synergy-Aware Reward Shaping (SARS), a non-linear mechanism that explicitly penalizes conflicted reward signals and amplifies synergistic ones, providing a sharper and more decisive gradient. (ii) Time-Aware Dynamic Weighting (TDW), which aligns the optimization pressure with the model's temporal dynamics by prioritizing prompt-following in the early, identity preservation in the later. Extensive experiments demonstrate that our method significantly outperforms naive GRPO baselines, successfully mitigating competitive degradation. Our model achieves a superior balance, generating images that both preserve key identity features and accurately adhere to complex textual prompts.

