---
layout: default
title: VLSU: Mapping the Limits of Joint Multimodal Understanding for AI Safety
---

# VLSU: Mapping the Limits of Joint Multimodal Understanding for AI Safety

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.18214" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.18214v2</a>
  <a href="https://arxiv.org/pdf/2510.18214.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.18214v2" onclick="toggleFavorite(this, '2510.18214v2', 'VLSU: Mapping the Limits of Joint Multimodal Understanding for AI Safety')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shruti Palaskar, Leon Gatys, Mona Abdelrahman, Mar Jacobo, Larry Lindsey, Rutika Moharir, Gunnar Lund, Yang Xu, Navid Shiee, Jeffrey Bigham, Charles Maalouf, Joseph Yitan Cheng

**åˆ†ç±»**: cs.CV, cs.AI, cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-10-21 (æ›´æ–°: 2025-12-03)

**å¤‡æ³¨**: 10 pages, 5 figures, 4 tables, detailed appendix. Under review

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**VLSUï¼šæ„å»ºå¤šæ¨¡æ€AIå®‰å…¨è¯„ä¼°æ¡†æ¶ï¼Œæ­ç¤ºè§†è§‰-è¯­è¨€è”åˆç†è§£çš„å±€é™æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å®‰å…¨` `è§†è§‰-è¯­è¨€ç†è§£` `AIå®‰å…¨è¯„ä¼°` `ç»„åˆæ¨ç†` `åŸºå‡†æ•°æ®é›†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨è¯„ä¼°å¤šæ¨¡æ€æ¨¡å‹å®‰å…¨æ€§æ—¶ï¼Œé€šå¸¸ç‹¬ç«‹å¤„ç†è§†è§‰å’Œè¯­è¨€è¾“å…¥ï¼Œå¿½ç•¥äº†è”åˆç†è§£å¯èƒ½å¸¦æ¥çš„é£é™©ã€‚
2. VLSUæ¡†æ¶é€šè¿‡ç»†ç²’åº¦çš„ä¸¥é‡ç¨‹åº¦åˆ†ç±»å’Œç»„åˆåˆ†æï¼Œç³»ç»Ÿæ€§åœ°è¯„ä¼°å¤šæ¨¡æ€AIçš„å®‰å…¨æ€§ï¼Œå¹¶æ„å»ºå¤§è§„æ¨¡åŸºå‡†ã€‚
3. å®éªŒè¡¨æ˜ï¼Œç°æœ‰æ¨¡å‹åœ¨è”åˆå›¾åƒ-æ–‡æœ¬æ¨ç†æ–¹é¢å­˜åœ¨æ˜¾è‘—ç¼ºé™·ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦ç»„åˆæ¨ç†æ—¶æ€§èƒ½å¤§å¹…ä¸‹é™ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†è§†è§‰-è¯­è¨€å®‰å…¨ç†è§£ï¼ˆVLSUï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨ç³»ç»Ÿæ€§åœ°è¯„ä¼°å¤šæ¨¡æ€AIçš„å®‰å…¨æ€§ï¼Œé€šè¿‡ç»†ç²’åº¦çš„ä¸¥é‡ç¨‹åº¦åˆ†ç±»å’Œè·¨17ç§ä¸åŒå®‰å…¨æ¨¡å¼çš„ç»„åˆåˆ†æã€‚è¯¥æ¡†æ¶åˆ©ç”¨çœŸå®ä¸–ç•Œçš„å›¾åƒå’Œäººå·¥æ ‡æ³¨ï¼Œæ„å»ºäº†ä¸€ä¸ªåŒ…å«8187ä¸ªæ ·æœ¬çš„å¤§è§„æ¨¡åŸºå‡†ï¼Œæ¶µç›–15ä¸ªå±å®³ç±»åˆ«ã€‚å¯¹11ä¸ªå…ˆè¿›æ¨¡å‹çš„è¯„ä¼°è¡¨æ˜ï¼Œæ¨¡å‹åœ¨è”åˆç†è§£æ–¹é¢å­˜åœ¨ç³»ç»Ÿæ€§ç¼ºé™·ï¼šåœ¨æ¸…æ™°çš„å•æ¨¡æ€å®‰å…¨ä¿¡å·ä¸Šï¼Œæ¨¡å‹å‡†ç¡®ç‡è¶…è¿‡90%ï¼Œä½†å½“éœ€è¦è”åˆå›¾åƒ-æ–‡æœ¬æ¨ç†æ¥ç¡®å®šå®‰å…¨æ ‡ç­¾æ—¶ï¼Œæ€§èƒ½æ˜¾è‘—ä¸‹é™åˆ°20-55%ã€‚æ›´å…³é”®çš„æ˜¯ï¼Œ34%çš„è”åˆå›¾åƒ-æ–‡æœ¬å®‰å…¨åˆ†ç±»é”™è¯¯å‘ç”Ÿåœ¨å„ä¸ªæ¨¡æ€éƒ½è¢«æ­£ç¡®åˆ†ç±»çš„æƒ…å†µä¸‹ï¼Œè¿›ä¸€æ­¥è¡¨æ˜æ¨¡å‹ç¼ºä¹ç»„åˆæ¨ç†èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œæ¨¡å‹éš¾ä»¥å¹³è¡¡æ‹’ç»ä¸å®‰å…¨å†…å®¹ä¸å“åº”è¾¹ç¼˜æ¡ˆä¾‹ã€‚ä¾‹å¦‚ï¼ŒæŒ‡ä»¤æ¡†æ¶å¯ä»¥å°†Gemini-1.5åœ¨è¾¹ç¼˜å†…å®¹ä¸Šçš„è¿‡åº¦å±è”½ç‡ä»62.4%é™ä½åˆ°10.4%ï¼Œä½†ä»£ä»·æ˜¯é™ä½äº†å¯¹ä¸å®‰å…¨å†…å®¹çš„æ‹’ç»ç‡ï¼Œä»90.8%é™è‡³53.9%ã€‚æ€»è€Œè¨€ä¹‹ï¼Œè¯¥æ¡†æ¶æ­ç¤ºäº†å½“å‰æ¨¡å‹åœ¨è”åˆå›¾åƒ-æ–‡æœ¬ç†è§£æ–¹é¢çš„å¼±ç‚¹å’Œå¯¹é½å·®è·ï¼Œå¹¶ä¸ºé²æ£’çš„è§†è§‰-è¯­è¨€å®‰å…¨ç ”ç©¶æä¾›äº†å…³é”®çš„æµ‹è¯•å¹³å°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€AIå®‰å…¨è¯„ä¼°ä¸­å­˜åœ¨çš„ä¸è¶³ï¼Œå³ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†è€ƒè™‘è§†è§‰å’Œè¯­è¨€ä¿¡æ¯è”åˆç†è§£å¸¦æ¥çš„å®‰å…¨é£é™©ï¼Œå¹¶ä¸”æ— æ³•æœ‰æ•ˆåŒºåˆ†æ˜ç¡®ä¸å®‰å…¨å†…å®¹å’Œè¾¹ç¼˜æ¡ˆä¾‹ï¼Œå¯¼è‡´è¿‡åº¦å±è”½æˆ–æœªèƒ½æ‹’ç»æœ‰å®³å†…å®¹ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨å•æ¨¡æ€çš„å®‰å…¨è¯„ä¼°ï¼Œå¿½ç•¥äº†æ¨¡æ€ä¹‹é—´çš„ç›¸äº’ä½œç”¨ï¼Œæ— æ³•å‡†ç¡®è¯„ä¼°æ¨¡å‹çš„æ•´ä½“å®‰å…¨æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªå…¨é¢çš„å¤šæ¨¡æ€å®‰å…¨è¯„ä¼°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿç³»ç»Ÿæ€§åœ°è¯„ä¼°æ¨¡å‹åœ¨å¤„ç†è§†è§‰å’Œè¯­è¨€ä¿¡æ¯æ—¶çš„å®‰å…¨æ€§ï¼Œå¹¶èƒ½å¤ŸåŒºåˆ†ä¸åŒä¸¥é‡ç¨‹åº¦çš„å®‰å…¨é—®é¢˜ã€‚é€šè¿‡æ„å»ºä¸€ä¸ªåŒ…å«å¤šç§å®‰å…¨æ¨¡å¼å’Œå±å®³ç±»åˆ«çš„å¤§è§„æ¨¡åŸºå‡†ï¼Œå¯ä»¥æ›´å…¨é¢åœ°è¯„ä¼°æ¨¡å‹çš„å®‰å…¨æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVLSUæ¡†æ¶åŒ…å«ä¸€ä¸ªå¤šé˜¶æ®µçš„æµæ°´çº¿ï¼ŒåŒ…æ‹¬æ•°æ®æ”¶é›†ã€äººå·¥æ ‡æ³¨å’Œæ¨¡å‹è¯„ä¼°ã€‚é¦–å…ˆï¼Œæ”¶é›†çœŸå®ä¸–ç•Œçš„å›¾åƒå’Œæ–‡æœ¬æ•°æ®ï¼Œå¹¶è¿›è¡Œäººå·¥æ ‡æ³¨ï¼Œæ ‡æ³¨å†…å®¹åŒ…æ‹¬å®‰å…¨ç±»åˆ«å’Œä¸¥é‡ç¨‹åº¦ã€‚ç„¶åï¼Œåˆ©ç”¨è¿™äº›æ ‡æ³¨æ•°æ®æ„å»ºä¸€ä¸ªå¤§è§„æ¨¡çš„åŸºå‡†æ•°æ®é›†ã€‚æœ€åï¼Œä½¿ç”¨è¯¥åŸºå‡†æ•°æ®é›†è¯„ä¼°ç°æœ‰æ¨¡å‹çš„å®‰å…¨æ€§èƒ½ï¼Œå¹¶åˆ†ææ¨¡å‹çš„é”™è¯¯ç±»å‹å’ŒåŸå› ã€‚

**å…³é”®åˆ›æ–°**ï¼šVLSUæ¡†æ¶çš„å…³é”®åˆ›æ–°åœ¨äºå…¶å…¨é¢æ€§å’Œç»†ç²’åº¦ã€‚å®ƒä¸ä»…è€ƒè™‘äº†å¤šç§å®‰å…¨æ¨¡å¼å’Œå±å®³ç±»åˆ«ï¼Œè¿˜å¯¹å®‰å…¨é—®é¢˜è¿›è¡Œäº†ç»†ç²’åº¦çš„ä¸¥é‡ç¨‹åº¦åˆ†ç±»ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶è¿˜å¼ºè°ƒäº†è”åˆå›¾åƒ-æ–‡æœ¬æ¨ç†çš„é‡è¦æ€§ï¼Œå¹¶æ­ç¤ºäº†ç°æœ‰æ¨¡å‹åœ¨ç»„åˆæ¨ç†æ–¹é¢çš„ä¸è¶³ã€‚

**å…³é”®è®¾è®¡**ï¼šVLSUæ¡†æ¶çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1ï¼‰ä½¿ç”¨çœŸå®ä¸–ç•Œçš„å›¾åƒå’Œæ–‡æœ¬æ•°æ®ï¼Œä»¥ç¡®ä¿è¯„ä¼°çš„çœŸå®æ€§å’Œå¯é æ€§ï¼›2ï¼‰é‡‡ç”¨äººå·¥æ ‡æ³¨ï¼Œä»¥ç¡®ä¿æ ‡æ³¨çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ï¼›3ï¼‰æ„å»ºä¸€ä¸ªåŒ…å«å¤šç§å®‰å…¨æ¨¡å¼å’Œå±å®³ç±»åˆ«çš„å¤§è§„æ¨¡åŸºå‡†æ•°æ®é›†ï¼Œä»¥ç¡®ä¿è¯„ä¼°çš„å…¨é¢æ€§ï¼›4ï¼‰å¯¹å®‰å…¨é—®é¢˜è¿›è¡Œç»†ç²’åº¦çš„ä¸¥é‡ç¨‹åº¦åˆ†ç±»ï¼Œä»¥ä¾¿æ›´å‡†ç¡®åœ°è¯„ä¼°æ¨¡å‹çš„å®‰å…¨æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œç°æœ‰æ¨¡å‹åœ¨è”åˆå›¾åƒ-æ–‡æœ¬æ¨ç†æ–¹é¢å­˜åœ¨æ˜¾è‘—ç¼ºé™·ã€‚åœ¨æ¸…æ™°çš„å•æ¨¡æ€å®‰å…¨ä¿¡å·ä¸Šï¼Œæ¨¡å‹å‡†ç¡®ç‡è¶…è¿‡90%ï¼Œä½†å½“éœ€è¦è”åˆå›¾åƒ-æ–‡æœ¬æ¨ç†æ—¶ï¼Œæ€§èƒ½ä¸‹é™åˆ°20-55%ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œ34%çš„è”åˆå›¾åƒ-æ–‡æœ¬å®‰å…¨åˆ†ç±»é”™è¯¯å‘ç”Ÿåœ¨å„ä¸ªæ¨¡æ€éƒ½è¢«æ­£ç¡®åˆ†ç±»çš„æƒ…å†µä¸‹ã€‚æ­¤å¤–ï¼ŒæŒ‡ä»¤æ¡†æ¶å¯ä»¥é™ä½Gemini-1.5åœ¨è¾¹ç¼˜å†…å®¹ä¸Šçš„è¿‡åº¦å±è”½ç‡ï¼Œä½†ä»£ä»·æ˜¯é™ä½äº†å¯¹ä¸å®‰å…¨å†…å®¹çš„æ‹’ç»ç‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæå‡å¤šæ¨¡æ€AIç³»ç»Ÿçš„å®‰å…¨æ€§ï¼Œä¾‹å¦‚å›¾åƒ-æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ã€è§†è§‰é—®ç­”ç³»ç»Ÿç­‰ã€‚é€šè¿‡ä½¿ç”¨VLSUæ¡†æ¶è¿›è¡Œå®‰å…¨è¯„ä¼°ï¼Œå¯ä»¥å‘ç°å¹¶ä¿®å¤æ¨¡å‹ä¸­å­˜åœ¨çš„å®‰å…¨æ¼æ´ï¼Œä»è€Œé™ä½æ¨¡å‹è¢«æ¶æ„åˆ©ç”¨çš„é£é™©ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å¯ä»¥ä¿ƒè¿›å¤šæ¨¡æ€å®‰å…¨é¢†åŸŸçš„ç ”ç©¶ï¼Œæ¨åŠ¨æ›´å®‰å…¨ã€æ›´å¯é çš„AIç³»ç»Ÿçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Safety evaluation of multimodal foundation models often treats vision and language inputs separately, missing risks from joint interpretation where benign content becomes harmful in combination. Existing approaches also fail to distinguish clearly unsafe content from borderline cases, leading to problematic over-blocking or under-refusal of genuinely harmful content. We present Vision Language Safety Understanding (VLSU), a comprehensive framework to systematically evaluate multimodal safety through fine-grained severity classification and combinatorial analysis across 17 distinct safety patterns. Using a multi-stage pipeline with real-world images and human annotation, we construct a large-scale benchmark of 8,187 samples spanning 15 harm categories. Our evaluation of eleven state-of-the-art models reveals systematic joint understanding failures: while models achieve 90%-plus accuracy on clear unimodal safety signals, performance degrades substantially to 20-55% when joint image-text reasoning is required to determine the safety label. Most critically, 34% of errors in joint image-text safety classification occur despite correct classification of the individual modalities, further demonstrating absent compositional reasoning capabilities. Additionally, we find that models struggle to balance refusing unsafe content while still responding to borderline cases that deserve engagement. For example, we find that instruction framing can reduce the over-blocking rate on borderline content from 62.4% to 10.4% in Gemini-1.5, but only at the cost of under-refusing on unsafe content with refusal rate dropping from 90.8% to 53.9%. Overall, our framework exposes weaknesses in joint image-text understanding and alignment gaps in current models, and provides a critical test bed to enable the next milestones in research on robust vision-language safety.

