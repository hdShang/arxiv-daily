---
layout: default
title: Latent-Info and Low-Dimensional Learning for Human Mesh Recovery and Parallel Optimization
---

# Latent-Info and Low-Dimensional Learning for Human Mesh Recovery and Parallel Optimization

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.18267" target="_blank" class="toolbar-btn">arXiv: 2510.18267v1</a>
    <a href="https://arxiv.org/pdf/2510.18267.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.18267v1" 
            onclick="toggleFavorite(this, '2510.18267v1', 'Latent-Info and Low-Dimensional Learning for Human Mesh Recovery and Parallel Optimization')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Xiang Zhang, Suping Wu, Sheng Yang

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-21

**Â§áÊ≥®**: Accepted by ICME2025

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éÊΩúÂú®‰ø°ÊÅØÂíå‰ΩéÁª¥Â≠¶‰π†ÁöÑ‰∫∫‰ΩìÁΩëÊ†ºÊÅ¢Â§ç‰∏éÂπ∂Ë°å‰ºòÂåñÊñπÊ≥ï**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±ÂÖ≠ÔºöËßÜÈ¢ëÊèêÂèñ‰∏éÂåπÈÖç (Video Extraction)**

**ÂÖ≥ÈîÆËØç**: `‰∫∫‰ΩìÁΩëÊ†ºÊÅ¢Â§ç` `3D‰∫∫‰ΩìÂßøÊÄÅ‰º∞ËÆ°` `ÊΩúÂú®‰ø°ÊÅØÊèêÂèñ` `‰ΩéÁª¥Â≠¶‰π†` `Âπ∂Ë°å‰ºòÂåñ` `È¢ëÂüüÁâπÂæÅ` `Ê∑±Â∫¶Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞Êúâ3D‰∫∫‰ΩìÁΩëÊ†ºÊÅ¢Â§çÊñπÊ≥ïÈöæ‰ª•ÂÖÖÂàÜÂà©Áî®ÊΩúÂú®‰ø°ÊÅØÔºåÂØºËá¥ÈáçÂª∫ÁªìÊûúÂ≠òÂú®ËÇ¢‰ΩìÈîô‰ΩçÂíåÁªÜËäÇ‰∏çË∂≥Á≠âÈóÆÈ¢ò„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫‰∏ÄÁßç‰∏§Èò∂ÊÆµÁΩëÁªúÔºåÈÄöËøáÊåñÊéòÂõæÂÉèÁâπÂæÅÁöÑÈ¢ëÂüü‰ø°ÊÅØÔºåÊèêÂèñÊ∑∑ÂêàÊΩúÂú®ÁâπÂæÅÔºåÂπ∂Áî®‰∫éÂ¢ûÂº∫2DÂà∞3DÁöÑÂßøÂäøÂ≠¶‰π†„ÄÇ
3. ËÆ∫ÊñáËÆæËÆ°‰∫Ü‰∏ÄÁßç‰ΩéÁª¥ÁΩëÊ†ºÂßøÂäø‰∫§‰∫íÊñπÊ≥ïÔºåÈÄöËøáÈôçÁª¥ÂíåÂπ∂Ë°å‰ºòÂåñÔºåÂú®Èôç‰ΩéËÆ°ÁÆóÊàêÊú¨ÁöÑÂêåÊó∂‰øùÊåÅ‰∫ÜÈáçÂª∫Á≤æÂ∫¶ÔºåÂÆûÈ™åÁªìÊûúË°®Êòé‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Áé∞ÊúâÁöÑ3D‰∫∫‰ΩìÁΩëÊ†ºÊÅ¢Â§çÊñπÊ≥ïÈÄöÂ∏∏Êú™ËÉΩÂÖÖÂàÜÂà©Áî®ÊΩúÂú®‰ø°ÊÅØÔºà‰æãÂ¶ÇÔºå‰∫∫‰ΩìËøêÂä®„ÄÅÂΩ¢Áä∂ÂØπÈΩêÔºâÔºåÂØºËá¥ÈáçÂª∫ÁöÑ‰∫∫‰ΩìÁΩëÊ†ºÂá∫Áé∞ËÇ¢‰ΩìÈîô‰ΩçÂíåÂ±ÄÈÉ®ÁªÜËäÇ‰∏çË∂≥ÁöÑÈóÆÈ¢òÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§çÊùÇÂú∫ÊôØ‰∏≠„ÄÇÊ≠§Â§ñÔºåÈÄöËøáÊ≥®ÊÑèÂäõÊú∫Âà∂Âª∫Ê®°ÁΩëÊ†ºÈ°∂ÁÇπÂíåÂßøÂäøËäÇÁÇπ‰∫§‰∫íÊâÄÂ∏¶Êù•ÁöÑÊÄßËÉΩÊèêÂçá‰º¥ÈöèÁùÄÈ´òÊòÇÁöÑËÆ°ÁÆóÊàêÊú¨„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÊΩúÂú®‰ø°ÊÅØÂíå‰ΩéÁª¥Â≠¶‰π†ÁöÑ‰∏§Èò∂ÊÆµ‰∫∫‰ΩìÁΩëÊ†ºÊÅ¢Â§çÁΩëÁªú„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåÁΩëÁªúÁöÑÁ¨¨‰∏ÄÈò∂ÊÆµÂÖÖÂàÜÊåñÊéòÂõæÂÉèÁâπÂæÅÁöÑ‰ΩéÈ¢ëÂíåÈ´òÈ¢ëÂàÜÈáè‰∏≠ÁöÑÂÖ®Â±ÄÔºà‰æãÂ¶ÇÔºåÊï¥‰ΩìÂΩ¢Áä∂ÂØπÈΩêÔºâÂíåÂ±ÄÈÉ®Ôºà‰æãÂ¶ÇÔºåÁ∫πÁêÜ„ÄÅÁªÜËäÇÔºâ‰ø°ÊÅØÔºåÂπ∂Â∞ÜËøô‰∫õ‰ø°ÊÅØËÅöÂêàÂà∞Ê∑∑ÂêàÊΩúÂú®È¢ëÂüüÁâπÂæÅ‰∏≠„ÄÇËøôÁßçÁ≠ñÁï•ÊúâÊïàÂú∞ÊèêÂèñ‰∫ÜÊΩúÂú®‰ø°ÊÅØ„ÄÇÈöèÂêéÔºåÂà©Áî®ÊèêÂèñÁöÑÊ∑∑ÂêàÊΩúÂú®È¢ëÂüüÁâπÂæÅÂçèÂêåÂ¢ûÂº∫2DÂßøÂäøÂà∞3DÁöÑÂ≠¶‰π†„ÄÇÂú®Á¨¨‰∫åÈò∂ÊÆµÔºåÂú®Ê∑∑ÂêàÊΩúÂú®ÁâπÂæÅÁöÑËæÖÂä©‰∏ãÔºåÊàë‰ª¨ÂØπÁ≤óÁ≥ôÁöÑ3D‰∫∫‰ΩìÁΩëÊ†ºÊ®°ÊùøÂíå3DÂßøÂäø‰πãÈó¥ÁöÑ‰∫§‰∫íÂ≠¶‰π†ËøõË°åÂª∫Ê®°Ôºå‰ºòÂåñ‰∫∫‰ΩìÁΩëÊ†ºÁöÑÂßøÂäøÂíåÂΩ¢Áä∂„ÄÇ‰∏éÁé∞ÊúâÁöÑÁΩëÊ†ºÂßøÂäø‰∫§‰∫íÊñπÊ≥ï‰∏çÂêåÔºåÊàë‰ª¨ËÆæËÆ°‰∫Ü‰∏ÄÁßçÈÄöËøáÈôçÁª¥ÂíåÂπ∂Ë°å‰ºòÂåñÂÆûÁé∞ÁöÑ‰ΩéÁª¥ÁΩëÊ†ºÂßøÂäø‰∫§‰∫íÊñπÊ≥ïÔºåËØ•ÊñπÊ≥ïÂú®‰∏çÁâ∫Áâ≤ÈáçÂª∫Á≤æÂ∫¶ÁöÑÂâçÊèê‰∏ãÊòæËëóÈôç‰Ωé‰∫ÜËÆ°ÁÆóÊàêÊú¨„ÄÇÂú®Â§ßÂûãÂÖ¨ÂºÄÊï∞ÊçÆÈõÜ‰∏äÁöÑÂ§ßÈáèÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ï‰ºò‰∫éÊúÄÂÖàËøõÁöÑÊñπÊ≥ï„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞Êúâ3D‰∫∫‰ΩìÁΩëÊ†ºÊÅ¢Â§çÊñπÊ≥ïÁöÑÁóõÁÇπÂú®‰∫éÊó†Ê≥ïÂÖÖÂàÜÂà©Áî®ÂõæÂÉè‰∏≠ÁöÑÊΩúÂú®‰ø°ÊÅØÔºå‰æãÂ¶Ç‰∫∫‰ΩìËøêÂä®ÂíåÂΩ¢Áä∂ÂØπÈΩêÁ≠âÔºåÂØºËá¥ÈáçÂª∫ÁöÑÁΩëÊ†ºÂú®ËÇ¢‰ΩìÂØπÈΩêÂíåÂ±ÄÈÉ®ÁªÜËäÇ‰∏äÂ≠òÂú®‰∏çË∂≥ÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§çÊùÇÂú∫ÊôØ‰∏ã„ÄÇÊ≠§Â§ñÔºåÂà©Áî®Ê≥®ÊÑèÂäõÊú∫Âà∂Âª∫Ê®°ÁΩëÊ†ºÈ°∂ÁÇπÂíåÂßøÂäøËäÇÁÇπ‰πãÈó¥ÁöÑ‰∫§‰∫íËôΩÁÑ∂ÂèØ‰ª•ÊèêÂçáÊÄßËÉΩÔºå‰ΩÜËÆ°ÁÆóÊàêÊú¨ÂæàÈ´ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÊèêÂèñÂõæÂÉèÁâπÂæÅ‰∏≠ÁöÑÊΩúÂú®‰ø°ÊÅØÔºåÂπ∂Â∞ÜÂÖ∂ËûçÂÖ•Âà∞ÁΩëÊ†ºÊÅ¢Â§çËøáÁ®ã‰∏≠Ôºå‰ªéËÄåÊèêÂçáÈáçÂª∫Ë¥®Èáè„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåËÆ∫ÊñáÂà©Áî®ÂõæÂÉèÁâπÂæÅÁöÑ‰ΩéÈ¢ëÂíåÈ´òÈ¢ëÂàÜÈáèÊù•ÂàÜÂà´ÊèêÂèñÂÖ®Â±ÄÂíåÂ±ÄÈÉ®‰ø°ÊÅØÔºåÂπ∂Â∞ÜËøô‰∫õ‰ø°ÊÅØËûçÂêàÂà∞Ê∑∑ÂêàÊΩúÂú®È¢ëÂüüÁâπÂæÅ‰∏≠„ÄÇÂêåÊó∂Ôºå‰∏∫‰∫ÜÈôç‰ΩéËÆ°ÁÆóÊàêÊú¨ÔºåËÆ∫ÊñáËÆæËÆ°‰∫Ü‰∏ÄÁßç‰ΩéÁª¥ÁöÑÁΩëÊ†ºÂßøÂäø‰∫§‰∫íÊñπÊ≥ïÔºåÈÄöËøáÈôçÁª¥ÂíåÂπ∂Ë°å‰ºòÂåñÊù•ÂÆûÁé∞„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•ÊñπÊ≥ïÈááÁî®‰∏§Èò∂ÊÆµÁΩëÁªúÁªìÊûÑ„ÄÇÁ¨¨‰∏ÄÈò∂ÊÆµÔºå‰ªéÂõæÂÉèÁâπÂæÅ‰∏≠ÊèêÂèñÊ∑∑ÂêàÊΩúÂú®È¢ëÂüüÁâπÂæÅÔºåÁî®‰∫éÂ¢ûÂº∫2DÂßøÂäøÂà∞3DÂßøÂäøÁöÑÂ≠¶‰π†„ÄÇÁ¨¨‰∫åÈò∂ÊÆµÔºåÂà©Áî®ÊèêÂèñÁöÑÊ∑∑ÂêàÊΩúÂú®ÁâπÂæÅÔºåÂØπÁ≤óÁ≥ôÁöÑ3D‰∫∫‰ΩìÁΩëÊ†ºÊ®°ÊùøÂíå3DÂßøÂäø‰πãÈó¥ÁöÑ‰∫§‰∫íËøõË°åÂª∫Ê®°ÔºåÂπ∂‰ºòÂåñ‰∫∫‰ΩìÁΩëÊ†ºÁöÑÂßøÂäøÂíåÂΩ¢Áä∂„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫é‰ª•‰∏ã‰∏§ÁÇπÔºö‰∏ÄÊòØÊèêÂá∫‰∫ÜÊ∑∑ÂêàÊΩúÂú®È¢ëÂüüÁâπÂæÅÔºåËÉΩÂ§üÊúâÊïàÂú∞ÊèêÂèñÂõæÂÉè‰∏≠ÁöÑÂÖ®Â±ÄÂíåÂ±ÄÈÉ®‰ø°ÊÅØÔºåÂπ∂Â∞ÜÂÖ∂Áî®‰∫éÂ¢ûÂº∫ÁΩëÊ†ºÊÅ¢Â§çËøáÁ®ã„ÄÇ‰∫åÊòØËÆæËÆ°‰∫Ü‰∏ÄÁßç‰ΩéÁª¥ÁΩëÊ†ºÂßøÂäø‰∫§‰∫íÊñπÊ≥ïÔºåÈÄöËøáÈôçÁª¥ÂíåÂπ∂Ë°å‰ºòÂåñÔºåÂú®Èôç‰ΩéËÆ°ÁÆóÊàêÊú¨ÁöÑÂêåÊó∂‰øùÊåÅ‰∫ÜÈáçÂª∫Á≤æÂ∫¶„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÂú®Êõ¥‰ΩéÁöÑËÆ°ÁÆóÊàêÊú¨‰∏ãÂÆûÁé∞Êõ¥È´òÁöÑÈáçÂª∫Ë¥®Èáè„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨ÔºöÊ∑∑ÂêàÊΩúÂú®È¢ëÂüüÁâπÂæÅÁöÑÊèêÂèñÊñπÂºèÔºåÂÖ∑‰ΩìÂ¶Ç‰ΩïËûçÂêà‰ΩéÈ¢ëÂíåÈ´òÈ¢ë‰ø°ÊÅØÔºõ‰ΩéÁª¥ÁΩëÊ†ºÂßøÂäø‰∫§‰∫íÊñπÊ≥ïÁöÑÂÖ∑‰ΩìÂÆûÁé∞ÔºåÂåÖÊã¨ÈôçÁª¥ÁöÑÊñπÂºèÂíåÂπ∂Ë°å‰ºòÂåñÁöÑÁ≠ñÁï•Ôºõ‰ª•ÂèäÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°ÔºåÂ¶Ç‰ΩïÂπ≥Ë°°ÂßøÂäøÂíåÂΩ¢Áä∂ÁöÑÈáçÂª∫ËØØÂ∑Æ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ËÆ∫ÊñáÂú®Â§ßÂûãÂÖ¨ÂºÄÊï∞ÊçÆÈõÜ‰∏äËøõË°å‰∫ÜÂ§ßÈáèÂÆûÈ™åÔºåÁªìÊûúË°®ÊòéËØ•ÊñπÊ≥ï‰ºò‰∫éÁõÆÂâçÊúÄÂÖàËøõÁöÑÊñπÊ≥ï„ÄÇÂÖ∑‰ΩìÊÄßËÉΩÊï∞ÊçÆÊú™Áü•Ôºå‰ΩÜÊëòË¶ÅÂº∫Ë∞É‰∫ÜËØ•ÊñπÊ≥ïÂú®Èôç‰ΩéËÆ°ÁÆóÊàêÊú¨ÁöÑÂêåÊó∂‰øùÊåÅÊàñÊèêÂçá‰∫ÜÈáçÂª∫Á≤æÂ∫¶„ÄÇÂÆûÈ™åÁªìÊûúÈ™åËØÅ‰∫ÜÊ∑∑ÂêàÊΩúÂú®È¢ëÂüüÁâπÂæÅÂíå‰ΩéÁª¥ÁΩëÊ†ºÂßøÂäø‰∫§‰∫íÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éËôöÊãüÁé∞ÂÆû„ÄÅÂ¢ûÂº∫Áé∞ÂÆû„ÄÅÊ∏∏ÊàèÂºÄÂèë„ÄÅÂä®ÁîªÂà∂‰Ωú„ÄÅËøêÂä®ÂàÜÊûê„ÄÅÊô∫ËÉΩÁõëÊéßÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÊõ¥ÂáÜÁ°Æ„ÄÅÊõ¥È´òÊïàÂú∞ÊÅ¢Â§ç‰∫∫‰ΩìÁΩëÊ†ºÔºåÂèØ‰ª•ÊèêÂçáÁî®Êà∑Âú®ËôöÊãüÁéØÂ¢É‰∏≠ÁöÑÊ≤âÊµ∏ÊÑüÂíå‰∫§‰∫í‰ΩìÈ™åÔºå‰πüÂèØ‰ª•‰∏∫ËøêÂä®ÂàÜÊûêÂíåÊô∫ËÉΩÁõëÊéßÊèê‰æõÊõ¥ÂèØÈù†ÁöÑÊï∞ÊçÆÊîØÊåÅ„ÄÇÊú™Êù•ÔºåËØ•ÊäÄÊúØÊúâÊúõÂú®‰∫∫Êú∫‰∫§‰∫í„ÄÅÊô∫ËÉΩÁ©øÊà¥ËÆæÂ§áÁ≠âÈ¢ÜÂüüÂèëÊå•Êõ¥Â§ßÁöÑ‰ΩúÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Existing 3D human mesh recovery methods often fail to fully exploit the latent information (e.g., human motion, shape alignment), leading to issues with limb misalignment and insufficient local details in the reconstructed human mesh (especially in complex scenes). Furthermore, the performance improvement gained by modelling mesh vertices and pose node interactions using attention mechanisms comes at a high computational cost. To address these issues, we propose a two-stage network for human mesh recovery based on latent information and low dimensional learning. Specifically, the first stage of the network fully excavates global (e.g., the overall shape alignment) and local (e.g., textures, detail) information from the low and high-frequency components of image features and aggregates this information into a hybrid latent frequency domain feature. This strategy effectively extracts latent information. Subsequently, utilizing extracted hybrid latent frequency domain features collaborates to enhance 2D poses to 3D learning. In the second stage, with the assistance of hybrid latent features, we model the interaction learning between the rough 3D human mesh template and the 3D pose, optimizing the pose and shape of the human mesh. Unlike existing mesh pose interaction methods, we design a low-dimensional mesh pose interaction method through dimensionality reduction and parallel optimization that significantly reduces computational costs without sacrificing reconstruction accuracy. Extensive experimental results on large publicly available datasets indicate superiority compared to the most state-of-the-art.

