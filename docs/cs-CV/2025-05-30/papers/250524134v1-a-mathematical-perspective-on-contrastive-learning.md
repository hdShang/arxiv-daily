---
layout: default
title: A Mathematical Perspective On Contrastive Learning
---

# A Mathematical Perspective On Contrastive Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.24134" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.24134v1</a>
  <a href="https://arxiv.org/pdf/2505.24134.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.24134v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.24134v1', 'A Mathematical Perspective On Contrastive Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ricardo Baptista, Andrew M. Stuart, Son Tran

**åˆ†ç±»**: stat.ML, cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-30

**å¤‡æ³¨**: 44 pages, 15 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§æ•°å­¦è§†è§’çš„å¯¹æ¯”å­¦ä¹ æ¡†æ¶ä»¥è§£å†³å¤šæ¨¡æ€æ•°æ®å¯¹é½é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¯¹æ¯”å­¦ä¹ ` `å¤šæ¨¡æ€å­¦ä¹ ` `æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒ` `è·¨æ¨¡æ€æ£€ç´¢` `ç”Ÿæˆæ¨¡å‹` `ä½ç§©çŸ©é˜µè¿‘ä¼¼` `æ•°æ®å¯¹é½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ æ–¹æ³•åœ¨å¤„ç†ä¸åŒæ¨¡æ€æ•°æ®å¯¹é½æ—¶å­˜åœ¨ä¸€å®šçš„å±€é™æ€§ï¼Œå°¤å…¶æ˜¯åœ¨æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒçš„å»ºæ¨¡ä¸Šã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶ï¼Œå°†å¯¹æ¯”å­¦ä¹ è§†ä¸ºä¼˜åŒ–æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒçš„ç¼–ç å™¨ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°å¯¹é½ä¸åŒæ¨¡æ€çš„è¡¨ç¤ºã€‚
3. é€šè¿‡åœ¨å¤šå…ƒé«˜æ–¯è®¾ç½®ä¸‹çš„å®éªŒï¼ŒéªŒè¯äº†æ–°æ¡†æ¶åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„æœ‰æ•ˆæ€§ï¼Œæ˜¾ç¤ºå‡ºç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•çš„æ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ æ˜¯ä¸€ç§å°†ä¸åŒæ•°æ®æ¨¡æ€è¿æ¥çš„æ–¹æ³•ï¼Œå…¸å‹ä¾‹å­æ˜¯å›¾åƒä¸æ–‡æœ¬æ•°æ®çš„å…³è”ã€‚æœ¬æ–‡èšç„¦äºåŒæ¨¡æ€è®¾ç½®ï¼Œå°†å¯¹æ¯”å­¦ä¹ è§†ä¸ºä¼˜åŒ–æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒçš„å‚æ•°åŒ–ç¼–ç å™¨ï¼Œä»¥ä¾¿åœ¨å…±åŒæ½œåœ¨ç©ºé—´ä¸­å¯¹é½è¡¨ç¤ºã€‚è¯¥æ¡†æ¶æ”¯æŒè·¨æ¨¡æ€æ£€ç´¢å’Œåˆ†ç±»ç­‰ç®—æ³•ï¼Œå¹¶å¼•å…¥æ–°çš„æ¦‚ç‡æŸå¤±å‡½æ•°å’Œæ›¿ä»£åº¦é‡æ¥æµ‹é‡æ½œåœ¨ç©ºé—´ä¸­çš„å¯¹é½ã€‚æˆ‘ä»¬åœ¨å¤šå…ƒé«˜æ–¯è®¾ç½®ä¸‹ç ”ç©¶è¿™äº›ç»å…¸æ–¹æ³•çš„æ¨å¹¿ï¼Œå¹¶é€šè¿‡æ•°å€¼å®éªŒéªŒè¯å…¶æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨ç‰¹å®šæ¨¡å¼å¯»æ±‚å’Œç”Ÿæˆä»»åŠ¡ä¸Šå…·æœ‰è‰¯å¥½çš„è¡¨ç°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ ä¸­ä¸åŒæ¨¡æ€æ•°æ®å¯¹é½çš„æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•åœ¨æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒå»ºæ¨¡ä¸Šå­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´å¯¹é½æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬å°†å¯¹æ¯”å­¦ä¹ è§†ä¸ºä¼˜åŒ–æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒçš„ç¼–ç å™¨ï¼Œé€šè¿‡è¿™ç§æ–¹å¼å®ç°æ¨¡æ€é—´çš„æœ‰æ•ˆå¯¹é½ï¼Œç¡®ä¿æ¯ä¸ªæ¨¡æ€çš„è¡¨ç¤ºèƒ½å¤Ÿåœ¨å…±åŒæ½œåœ¨ç©ºé—´ä¸­ä¸€è‡´ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ç¼–ç å™¨çš„å‚æ•°åŒ–è®¾è®¡ã€æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒçš„ä¼˜åŒ–ä»¥åŠæŸå¤±å‡½æ•°çš„å¼•å…¥ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ¨¡æ€ç¼–ç å™¨ã€å¯¹é½åº¦é‡å’ŒæŸå¤±è®¡ç®—ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„ä¸»è¦åˆ›æ–°åœ¨äºå¼•å…¥æ–°çš„æ¦‚ç‡æŸå¤±å‡½æ•°å’Œæ›¿ä»£åº¦é‡ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°è¡¡é‡æ½œåœ¨ç©ºé—´ä¸­çš„å¯¹é½æ•ˆæœï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†æ›´çµæ´»çš„å¯¹æ¯”å­¦ä¹ æ–¹å¼ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œé‡‡ç”¨äº†å¤šå…ƒé«˜æ–¯åˆ†å¸ƒçš„å‡è®¾ï¼Œè®¾è®¡äº†ä½ç§©çŸ©é˜µè¿‘ä¼¼çš„ç®—æ³•ï¼Œä¼˜åŒ–äº†æ¡ä»¶å‡å€¼å’Œåæ–¹å·®çš„ä¼°è®¡ï¼Œç¡®ä¿äº†å¯¹è‡ªç„¶ç»Ÿè®¡ç‰¹æ€§çš„è‰¯å¥½è¿‘ä¼¼ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ¡†æ¶åœ¨å¤šå…ƒé«˜æ–¯è®¾ç½®å’ŒMNISTæ•°æ®é›†ä¸Šå‡è¡¨ç°å‡ºè‰²ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•ï¼Œæ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œå°¤å…¶åœ¨ç‰¹å®šæ¨¡å¼å¯»æ±‚å’Œç”Ÿæˆä»»åŠ¡ä¸­å±•ç°äº†ä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è·¨æ¨¡æ€æ£€ç´¢ã€å›¾åƒä¸æ–‡æœ¬çš„å…³è”åˆ†æã€ä»¥åŠç”Ÿæˆæ¨¡å‹çš„è®­ç»ƒç­‰ã€‚é€šè¿‡æä¾›æ›´æœ‰æ•ˆçš„å¯¹é½æœºåˆ¶ï¼Œèƒ½å¤Ÿåœ¨å¤šæ¨¡æ€æ•°æ®å¤„ç†ã€ä¿¡æ¯æ£€ç´¢å’Œæ™ºèƒ½ç³»ç»Ÿä¸­å‘æŒ¥é‡è¦ä½œç”¨ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨ç›¸å…³é¢†åŸŸçš„æŠ€æœ¯è¿›æ­¥ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal contrastive learning is a methodology for linking different data modalities; the canonical example is linking image and text data. The methodology is typically framed as the identification of a set of encoders, one for each modality, that align representations within a common latent space. In this work, we focus on the bimodal setting and interpret contrastive learning as the optimization of (parameterized) encoders that define conditional probability distributions, for each modality conditioned on the other, consistent with the available data. This provides a framework for multimodal algorithms such as crossmodal retrieval, which identifies the mode of one of these conditional distributions, and crossmodal classification, which is similar to retrieval but includes a fine-tuning step to make it task specific.
>   The framework we adopt also gives rise to crossmodal generative models. This probabilistic perspective suggests two natural generalizations of contrastive learning: the introduction of novel probabilistic loss functions, and the use of alternative metrics for measuring alignment in the common latent space. We study these generalizations of the classical approach in the multivariate Gaussian setting. In this context we view the latent space identification as a low-rank matrix approximation problem. This allows us to characterize the capabilities of loss functions and alignment metrics to approximate natural statistics, such as conditional means and covariances; doing so yields novel variants on contrastive learning algorithms for specific mode-seeking and for generative tasks. The framework we introduce is also studied through numerical experiments on multivariate Gaussians, the labeled MNIST dataset, and on a data assimilation application arising in oceanography.

