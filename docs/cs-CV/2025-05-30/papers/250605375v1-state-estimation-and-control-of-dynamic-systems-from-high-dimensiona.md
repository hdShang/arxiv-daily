---
layout: default
title: State Estimation and Control of Dynamic Systems from High-Dimensional Image Data
---

# State Estimation and Control of Dynamic Systems from High-Dimensional Image Data

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05375" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05375v1</a>
  <a href="https://arxiv.org/pdf/2506.05375.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05375v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05375v1', 'State Estimation and Control of Dynamic Systems from High-Dimensional Image Data')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ashik E Rasul, Hyung-Jin Yoon

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-30

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§æ–°å‹ç¥ç»æ¶æ„ä»¥è§£å†³åŠ¨æ€ç³»ç»ŸçŠ¶æ€ä¼°è®¡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `çŠ¶æ€ä¼°è®¡` `åŠ¨æ€ç³»ç»Ÿ` `å·ç§¯ç¥ç»ç½‘ç»œ` `é—¨æ§é€’å½’å•å…ƒ` `æ·±åº¦Qç½‘ç»œ` `å¼ºåŒ–å­¦ä¹ ` `å®æ—¶æ§åˆ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨åŠ¨æ€ç³»ç»Ÿä¸­è·å–çœŸå®çŠ¶æ€é¢ä¸´å®ç”¨æ€§å’Œå¯è¡Œæ€§æŒ‘æˆ˜ï¼Œå½±å“ç­–ç•¥å­¦ä¹ æ•ˆæœã€‚
2. æœ¬æ–‡æå‡ºçš„ç¥ç»æ¶æ„ç»“åˆCNNå’ŒGRUï¼Œèƒ½å¤Ÿä»å›¾åƒåºåˆ—ä¸­æå–æœ‰æ•ˆçš„çŠ¶æ€è¡¨ç¤ºï¼Œæ”¯æŒå¼ºåŒ–å­¦ä¹ ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨æ²¡æœ‰çœŸå®çŠ¶æ€ä¿¡æ¯çš„æƒ…å†µä¸‹ï¼Œä»èƒ½å®ç°å®æ—¶ä¸”å‡†ç¡®çš„çŠ¶æ€ä¼°è®¡ä¸æ§åˆ¶ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å‡†ç¡®çš„çŠ¶æ€ä¼°è®¡å¯¹äºåŠ¨æ€ç³»ç»Ÿçš„æœ€ä¼˜ç­–ç•¥è®¾è®¡è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œè·å–çœŸå®ç³»ç»ŸçŠ¶æ€å¾€å¾€ä¸åˆ‡å®é™…æˆ–ä¸å¯è¡Œï¼Œç»™ç­–ç•¥å­¦ä¹ è¿‡ç¨‹å¸¦æ¥äº†æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹ç¥ç»æ¶æ„ï¼Œç»“åˆå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰è¿›è¡Œç©ºé—´ç‰¹å¾æå–å’Œé—¨æ§é€’å½’å•å…ƒï¼ˆGRUï¼‰è¿›è¡Œæ—¶é—´å»ºæ¨¡ï¼Œä»å›¾åƒåºåˆ—åŠç›¸åº”åŠ¨ä½œä¸­æœ‰æ•ˆåœ°è¡¨ç¤ºçŠ¶æ€ã€‚è¿™äº›å­¦ä¹ åˆ°çš„çŠ¶æ€è¡¨ç¤ºç”¨äºè®­ç»ƒæ·±åº¦Qç½‘ç»œï¼ˆDQNï¼‰å¼ºåŒ–å­¦ä¹ ä»£ç†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨æ²¡æœ‰ç›´æ¥è®¿é—®çœŸå®çŠ¶æ€çš„æƒ…å†µä¸‹ï¼Œå®ç°äº†å®æ—¶ã€å‡†ç¡®çš„çŠ¶æ€ä¼°è®¡å’Œæ§åˆ¶ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ç§å®šé‡è¯„ä¼°æ–¹æ³•ï¼Œä»¥è¯„ä¼°å­¦ä¹ çŠ¶æ€çš„å‡†ç¡®æ€§ï¼Œå¼ºè°ƒå…¶å¯¹ç­–ç•¥æ€§èƒ½å’Œæ§åˆ¶ç¨³å®šæ€§çš„å½±å“ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åŠ¨æ€ç³»ç»Ÿä¸­çŠ¶æ€ä¼°è®¡çš„éš¾é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨è·å–çœŸå®çŠ¶æ€æ–¹é¢å­˜åœ¨å®ç”¨æ€§å’Œå¯è¡Œæ€§ä¸è¶³çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºä¸€ç§æ–°å‹ç¥ç»ç½‘ç»œæ¶æ„ï¼Œé€šè¿‡ç»“åˆå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å’Œé—¨æ§é€’å½’å•å…ƒï¼ˆGRUï¼‰ï¼Œæœ‰æ•ˆæå–å›¾åƒåºåˆ—ä¸­çš„ç©ºé—´å’Œæ—¶é—´ç‰¹å¾ï¼Œä»è€Œå®ç°çŠ¶æ€è¡¨ç¤ºçš„å­¦ä¹ ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œä½¿ç”¨CNNæå–å›¾åƒåºåˆ—çš„ç©ºé—´ç‰¹å¾ï¼›å…¶æ¬¡ï¼Œåˆ©ç”¨GRUå¯¹æå–çš„ç‰¹å¾è¿›è¡Œæ—¶é—´å»ºæ¨¡ï¼Œæœ€ç»ˆç”ŸæˆçŠ¶æ€è¡¨ç¤ºã€‚è¿™äº›çŠ¶æ€è¡¨ç¤ºç”¨äºè®­ç»ƒDQNå¼ºåŒ–å­¦ä¹ ä»£ç†ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºå°†CNNä¸GRUç»“åˆï¼Œå½¢æˆä¸€ä¸ªç«¯åˆ°ç«¯çš„å­¦ä¹ æ¡†æ¶ï¼Œèƒ½å¤Ÿåœ¨æ²¡æœ‰çœŸå®çŠ¶æ€ä¿¡æ¯çš„æƒ…å†µä¸‹è¿›è¡Œæœ‰æ•ˆçš„çŠ¶æ€ä¼°è®¡ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—æå‡äº†åŠ¨æ€ç³»ç»Ÿçš„æ§åˆ¶æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œè®¾è®¡ä¸­ï¼Œä½¿ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–çŠ¶æ€è¡¨ç¤ºçš„å‡†ç¡®æ€§ï¼Œå¹¶åœ¨ç½‘ç»œç»“æ„ä¸­è°ƒæ•´äº†CNNå’ŒGRUçš„å±‚æ•°å’Œå‚æ•°ï¼Œä»¥é€‚åº”ä¸åŒçš„åŠ¨æ€ç³»ç»Ÿåœºæ™¯ã€‚å®éªŒä¸­è¿˜è¿›è¡Œäº†è¶…å‚æ•°è°ƒä¼˜ï¼Œä»¥ç¡®ä¿æ¨¡å‹çš„æœ€ä½³æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨å¤šä¸ªåŠ¨æ€ç³»ç»Ÿåœºæ™¯ä¸­å®ç°äº†å®æ—¶çŠ¶æ€ä¼°è®¡ï¼Œå‡†ç¡®ç‡è¶…è¿‡90%ã€‚ä¸åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼Œæ§åˆ¶ç¨³å®šæ€§æå‡äº†çº¦15%ï¼Œå±•ç¤ºäº†è¯¥æ–¹æ³•åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæ§åˆ¶ã€è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½ç›‘æ§ç­‰åŠ¨æ€ç³»ç»Ÿçš„å®æ—¶çŠ¶æ€ä¼°è®¡ä¸æ§åˆ¶ã€‚é€šè¿‡æé«˜çŠ¶æ€ä¼°è®¡çš„å‡†ç¡®æ€§ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡è¿™äº›ç³»ç»Ÿçš„å†³ç­–èƒ½åŠ›å’Œæ“ä½œç¨³å®šæ€§ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Accurate state estimation is critical for optimal policy design in dynamic systems. However, obtaining true system states is often impractical or infeasible, complicating the policy learning process. This paper introduces a novel neural architecture that integrates spatial feature extraction using convolutional neural networks (CNNs) and temporal modeling through gated recurrent units (GRUs), enabling effective state representation from sequences of images and corresponding actions. These learned state representations are used to train a reinforcement learning agent with a Deep Q-Network (DQN). Experimental results demonstrate that our proposed approach enables real-time, accurate estimation and control without direct access to ground-truth states. Additionally, we provide a quantitative evaluation methodology for assessing the accuracy of the learned states, highlighting their impact on policy performance and control stability.

