---
layout: default
title: Harnessing Foundation Models for Robust and Generalizable 6-DOF Bronchoscopy Localization
---

# Harnessing Foundation Models for Robust and Generalizable 6-DOF Bronchoscopy Localization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.24249" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.24249v1</a>
  <a href="https://arxiv.org/pdf/2505.24249.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.24249v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.24249v1', 'Harnessing Foundation Models for Robust and Generalizable 6-DOF Bronchoscopy Localization')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Qingyao Tian, Huai Liao, Xinyan Huang, Bingyu Yang, Hongbin Liu

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-30

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫PANSv2‰ª•Ëß£ÂÜ≥ÊîØÊ∞îÁÆ°ÈïúÂÆö‰ΩçÁöÑÈ≤ÅÊ£íÊÄß‰∏éÊ≥õÂåñÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÊîØÊ∞îÁÆ°ÈïúÂÆö‰Ωç` `Ê∑±Â∫¶‰º∞ËÆ°` `Âú∞Ê†áÊ£ÄÊµã` `ÂßøÊÄÅ‰ºòÂåñ` `È≤ÅÊ£íÊÄß` `Ê≥õÂåñËÉΩÂäõ` `ÂÜÖÁ™•ÈïúÂü∫Á°ÄÊ®°Âûã` `Ëá™Âä®ÈáçÂàùÂßãÂåñ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊîØÊ∞îÁÆ°ÈïúÂÆö‰ΩçÊñπÊ≥ïÂú®ÊÇ£ËÄÖÊ°à‰æãÈó¥ÁöÑÊ≥õÂåñËÉΩÂäõ‰∏çË∂≥Ôºå‰∏îÂú®ËßÜËßâÈÄÄÂåñÊÉÖÂÜµ‰∏ãË°®Áé∞‰∏ç‰Ω≥ÔºåÂΩ±Âìç‰∏¥Â∫äÂ∫îÁî®„ÄÇ
2. Êú¨ÊñáÊèêÂá∫ÁöÑPANSv2Ê°ÜÊû∂ÈÄöËøáÊï¥ÂêàÊ∑±Â∫¶‰º∞ËÆ°„ÄÅÂú∞Ê†áÊ£ÄÊµãÂíå‰∏≠ÂøÉÁ∫øÁ∫¶ÊùüÔºå‰ºòÂåñÂßøÊÄÅËØÑ‰º∞ÔºåÊèêÂçá‰∫ÜÈ≤ÅÊ£íÊÄßÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåPANSv2Âú®10‰∏™ÊÇ£ËÄÖÊ°à‰æãÁöÑÊï∞ÊçÆÈõÜ‰∏äÂÆûÁé∞‰∫ÜÊúÄÈ´òÁöÑË∑üË∏™ÊàêÂäüÁéáÔºåSR-5ÊåáÊ†áÊèêÂçá‰∫Ü18.1%„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Âü∫‰∫éËßÜËßâÁöÑ6Ëá™Áî±Â∫¶ÊîØÊ∞îÁÆ°ÈïúÂÆö‰Ωç‰∏∫Á≤æÂáÜ‰∏îÁªèÊµéÁöÑ‰ªãÂÖ•ÊåáÂØºÊèê‰æõ‰∫ÜÊúâÂâçÊôØÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÊñπÊ≥ïÂú®ÊÇ£ËÄÖÊ°à‰æãÈó¥ÁöÑÊ≥õÂåñËÉΩÂäõÊúâÈôêÔºå‰∏îÂú®ËßÜËßâÈÄÄÂåñÊÉÖÂÜµ‰∏ãË°®Áé∞‰∏ç‰Ω≥„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÊåëÊàòÔºåÊú¨ÊñáÊèêÂá∫‰∫ÜPANSv2Ê°ÜÊû∂ÔºåÈõÜÊàê‰∫ÜÊ∑±Â∫¶‰º∞ËÆ°„ÄÅÂú∞Ê†áÊ£ÄÊµãÂíå‰∏≠ÂøÉÁ∫øÁ∫¶ÊùüÔºåÂΩ¢ÊàêÁªü‰∏ÄÁöÑÂßøÊÄÅ‰ºòÂåñÊ°ÜÊû∂„ÄÇÈÄöËøáÂà©Áî®È¢ÑËÆ≠ÁªÉÁöÑÂÜÖÁ™•ÈïúÂü∫Á°ÄÊ®°ÂûãEndoOmniÂíåËßÜÈ¢ëÂü∫Á°ÄÊ®°ÂûãEndoMambaÔºåPANSv2Âú®Â§öÁßçÊîØÊ∞îÁÆ°ÈïúÂú∫ÊôØ‰∏≠Êèê‰æõ‰∫ÜÁ®≥ÂÆöÁöÑËßÜËßâË°®Á§∫„ÄÇÊ≠§Â§ñÔºåËá™Âä®ÈáçÂàùÂßãÂåñÊ®°ÂùóËÉΩÂ§üÂú®Ë∑üË∏™Â§±Ë¥•Êó∂ÈáçÊñ∞Âª∫Á´ãÂßøÊÄÅ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåPANSv2Âú®10‰∏™ÊÇ£ËÄÖÊ°à‰æãÁöÑÊï∞ÊçÆÈõÜ‰∏äÂÆûÁé∞‰∫ÜÊúÄÈ´òÁöÑË∑üË∏™ÊàêÂäüÁéáÔºåÁõ∏ËæÉ‰∫éÁé∞ÊúâÊñπÊ≥ïÂú®SR-5ÊåáÊ†á‰∏äÊèêÂçá‰∫Ü18.1%„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥ÊîØÊ∞îÁÆ°ÈïúÂÆö‰Ωç‰∏≠Â≠òÂú®ÁöÑÊ≥õÂåñËÉΩÂäõ‰∏çË∂≥ÂíåËßÜËßâÈÄÄÂåñ‰∏ãÁöÑÈ≤ÅÊ£íÊÄßÂ∑ÆÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®‰∏çÂêåÊÇ£ËÄÖÊ°à‰æã‰∏≠Ë°®Áé∞‰∏ç‰Ω≥Ôºå‰∏îÂú®ËßÜËßâ‰ø°ÊÅØÂèóÊçüÊó∂ÂÆπÊòìÂá∫Áé∞Ë∑üË∏™Â§±Ë¥•„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöPANSv2Ê°ÜÊû∂ÈÄöËøáÊï¥ÂêàÂ§öÁßçËßÜËßâÁ∫øÁ¥¢ÔºàÂ¶ÇÊ∑±Â∫¶‰º∞ËÆ°ÂíåÂú∞Ê†áÊ£ÄÊµãÔºâÊù•‰ºòÂåñÂßøÊÄÅËØÑ‰º∞ÔºåÊó®Âú®ÊèêÈ´òÂÆö‰ΩçÁöÑÈ≤ÅÊ£íÊÄßÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇËØ•ËÆæËÆ°‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üÂú®Â§öÁßç‰∏¥Â∫äÂú∫ÊôØ‰∏≠Á®≥ÂÆöËøêË°å„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöPANSv2ÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨Ê∑±Â∫¶‰º∞ËÆ°Ê®°Âùó„ÄÅÂú∞Ê†áÊ£ÄÊµãÊ®°ÂùóÂíå‰∏≠ÂøÉÁ∫øÁ∫¶ÊùüÊ®°ÂùóÔºåÊâÄÊúâÊ®°ÂùóÂÖ±Âêå‰ΩúÁî®‰∫éÂßøÊÄÅ‰ºòÂåñ„ÄÇÈÄöËøáËØÑ‰º∞ÂßøÊÄÅÊ¶ÇÁéáÔºåÊ®°ÂûãËÉΩÂ§üËÆ°ÁÆóÂá∫ÊúÄ‰ºòÁöÑÊîØÊ∞îÁÆ°ÈïúÂßøÊÄÅ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöPANSv2ÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÂºïÂÖ•‰∫ÜÂÜÖÁ™•ÈïúÂü∫Á°ÄÊ®°ÂûãEndoOmniÂíåËßÜÈ¢ëÂü∫Á°ÄÊ®°ÂûãEndoMambaÔºåËøô‰∫õÊ®°ÂûãÁªèËøáÂ§öÊ†∑ÂåñÂÜÖÁ™•ÈïúÊï∞ÊçÆÈõÜÁöÑÈ¢ÑËÆ≠ÁªÉÔºåÊèê‰æõ‰∫ÜÁ®≥ÂÆö‰∏îÂèØËøÅÁßªÁöÑËßÜËßâË°®Á§∫ÔºåÊòæËëóÊèêÂçá‰∫ÜÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Ê®°ÂûãËÆæËÆ°‰∏≠ÔºåÈááÁî®‰∫ÜËá™Âä®ÈáçÂàùÂßãÂåñÊ®°ÂùóÊù•Ê£ÄÊµãË∑üË∏™Â§±Ë¥•ÔºåÂπ∂Âú®ÂèØÁî®ÁöÑÊ∏ÖÊô∞ËßÜÂõæ‰∏ãÈáçÊñ∞Âª∫Á´ãÂßøÊÄÅ„ÄÇÊ≠§Â§ñÔºåÊçüÂ§±ÂáΩÊï∞ÂíåÁΩëÁªúÁªìÊûÑÁªèËøáÁ≤æÂøÉËÆæËÆ°Ôºå‰ª•Á°Æ‰øùÊ®°ÂûãÂú®‰∏çÂêåÂú∫ÊôØ‰∏ãÁöÑÁ®≥ÂÆöÊÄßÂíåÂáÜÁ°ÆÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåPANSv2Âú®10‰∏™ÊÇ£ËÄÖÊ°à‰æãÁöÑÊï∞ÊçÆÈõÜ‰∏äÂÆûÁé∞‰∫ÜÊúÄÈ´òÁöÑË∑üË∏™ÊàêÂäüÁéáÔºåÁõ∏ËæÉ‰∫éÁé∞ÊúâÊñπÊ≥ïÂú®SR-5ÊåáÊ†á‰∏äÊèêÂçá‰∫Ü18.1%„ÄÇËøô‰∏ÄÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáË°®ÊòéPANSv2Âú®ÂÆûÈôÖ‰∏¥Â∫äÂ∫îÁî®‰∏≠ÁöÑÊΩúÂäõÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§çÊùÇÂíåÂ§öÂèòÁöÑÂåªÁñóÁéØÂ¢É‰∏≠„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨ÂåªÁñóÂΩ±ÂÉèÂºïÂØºÁöÑ‰ªãÂÖ•ÊâãÊúØÔºåÂ∞§ÂÖ∂ÊòØÂú®ÊîØÊ∞îÁÆ°ÈïúÊ£ÄÊü•ÂíåÊ≤ªÁñó‰∏≠„ÄÇÈÄöËøáÊèêÈ´òÂÆö‰ΩçÁöÑÈ≤ÅÊ£íÊÄßÂíåÊ≥õÂåñËÉΩÂäõÔºåPANSv2ÊúâÊúõÂú®ÂÆûÈôÖ‰∏¥Â∫ä‰∏≠Êèê‰æõÊõ¥‰∏∫Á≤æÂáÜÁöÑÊåáÂØºÔºå‰ªéËÄåÊèêÂçáÊÇ£ËÄÖÁöÑÊ≤ªÁñóÊïàÊûúÂíåÂÆâÂÖ®ÊÄß„ÄÇÊú™Êù•ÔºåËØ•ÊäÄÊúØÂèØËÉΩÊâ©Â±ïÂà∞ÂÖ∂‰ªñÁ±ªÂûãÁöÑÂÜÖÁ™•ÈïúÊâãÊúØ‰∏≠ÔºåËøõ‰∏ÄÊ≠•Êé®Âä®ÂåªÁñóÊäÄÊúØÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Vision-based 6-DOF bronchoscopy localization offers a promising solution for accurate and cost-effective interventional guidance. However, existing methods struggle with 1) limited generalization across patient cases due to scarce labeled data, and 2) poor robustness under visual degradation, as bronchoscopy procedures frequently involve artifacts such as occlusions and motion blur that impair visual information. To address these challenges, we propose PANSv2, a generalizable and robust bronchoscopy localization framework. Motivated by PANS that leverages multiple visual cues for pose likelihood measurement, PANSv2 integrates depth estimation, landmark detection, and centerline constraints into a unified pose optimization framework that evaluates pose probability and solves for the optimal bronchoscope pose. To further enhance generalization capabilities, we leverage the endoscopic foundation model EndoOmni for depth estimation and the video foundation model EndoMamba for landmark detection, incorporating both spatial and temporal analyses. Pretrained on diverse endoscopic datasets, these models provide stable and transferable visual representations, enabling reliable performance across varied bronchoscopy scenarios. Additionally, to improve robustness to visual degradation, we introduce an automatic re-initialization module that detects tracking failures and re-establishes pose using landmark detections once clear views are available. Experimental results on bronchoscopy dataset encompassing 10 patient cases show that PANSv2 achieves the highest tracking success rate, with an 18.1% improvement in SR-5 (percentage of absolute trajectory error under 5 mm) compared to existing methods, showing potential towards real clinical usage.

