---
layout: default
title: PCIE_Interaction Solution for Ego4D Social Interaction Challenge
---

# PCIE_Interaction Solution for Ego4D Social Interaction Challenge

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.24404" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.24404v1</a>
  <a href="https://arxiv.org/pdf/2505.24404.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.24404v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.24404v1', 'PCIE_Interaction Solution for Ego4D Social Interaction Challenge')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kanokphan Lertniphonphan, Feng Chen, Junda Xu, Fengbu Lan, Jun Xie, Tao Zhang, Zhepeng Wang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-30

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/KanokphanL/PCIE_Ego4D_Social_Interaction)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPCIE_Interactionè§£å†³æ–¹æ¡ˆä»¥åº”å¯¹Ego4Dç¤¾äº¤äº’åŠ¨æŒ‘æˆ˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)**

**å…³é”®è¯**: `ç¤¾äº¤äº’åŠ¨æ£€æµ‹` `å¤šæ¨¡æ€èåˆ` `é¢éƒ¨è¯†åˆ«` `éŸ³é¢‘å¤„ç†` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç¤¾äº¤äº’åŠ¨æ£€æµ‹ä¸­é¢ä¸´å‡†ç¡®æ€§ä¸è¶³çš„æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚åœºæ™¯ä¸‹çš„é¢éƒ¨è¯†åˆ«å’ŒéŸ³é¢‘åŒæ­¥é—®é¢˜ã€‚
2. æˆ‘ä»¬æå‡ºçš„è§£å†³æ–¹æ¡ˆé€šè¿‡é¢éƒ¨è´¨é‡å¢å¼ºå’ŒéŸ³é¢‘è§†è§‰èåˆï¼Œæå‡äº†ç¤¾äº¤äº’åŠ¨çš„æ£€æµ‹ç²¾åº¦ï¼Œå°¤å…¶æ˜¯åœ¨LAMå’ŒTTMä»»åŠ¡ä¸­ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨LAMå’ŒTTMä»»åŠ¡ä¸­åˆ†åˆ«è¾¾åˆ°äº†0.81å’Œ0.71çš„mAPï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æŠ¥å‘Šäº†æˆ‘ä»¬å›¢é˜Ÿåœ¨CVPR 2025çš„Ego4Dç¤¾äº¤äº’åŠ¨æŒ‘æˆ˜ä¸­æå‡ºçš„PCIE_Interactionè§£å†³æ–¹æ¡ˆï¼Œé’ˆå¯¹Looking At Me (LAM)å’ŒTalking To Me (TTM)ä»»åŠ¡è¿›è¡Œç ”ç©¶ã€‚è¯¥æŒ‘æˆ˜è¦æ±‚å‡†ç¡®æ£€æµ‹ä¸»ä½“ä¸æ‘„åƒæœºä½©æˆ´è€…ä¹‹é—´çš„ç¤¾äº¤äº’åŠ¨ï¼ŒLAMä»»åŠ¡ä¾èµ–äºé¢éƒ¨è£å‰ªåºåˆ—ï¼Œè€ŒTTMä»»åŠ¡åˆ™ç»“åˆäº†è¯´è¯è€…çš„é¢éƒ¨è£å‰ªå’ŒåŒæ­¥éŸ³é¢‘ç‰‡æ®µã€‚åœ¨LAMè½¨é“ä¸­ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†é¢éƒ¨è´¨é‡å¢å¼ºå’Œé›†æˆæ–¹æ³•ï¼›åœ¨TTMä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡èåˆéŸ³é¢‘å’Œè§†è§‰çº¿ç´¢ï¼Œç»“åˆè§†è§‰è´¨é‡è¯„åˆ†ï¼Œæ‰©å±•äº†è§†è§‰äº’åŠ¨åˆ†æã€‚æˆ‘ä»¬çš„æ–¹æ¡ˆåœ¨LAMå’ŒTTMæŒ‘æˆ˜çš„æ’è¡Œæ¦œä¸Šåˆ†åˆ«å–å¾—äº†0.81å’Œ0.71çš„å¹³å‡ç²¾åº¦ï¼ˆmAPï¼‰ã€‚ä»£ç å¯åœ¨https://github.com/KanokphanL/PCIE_Ego4D_Social_Interactionè·å–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³Ego4Dç¤¾äº¤äº’åŠ¨æŒ‘æˆ˜ä¸­çš„ç¤¾äº¤äº’åŠ¨æ£€æµ‹é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤æ‚åœºæ™¯ä¸‹çš„é¢éƒ¨è¯†åˆ«å’ŒéŸ³é¢‘åŒæ­¥å­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´æ£€æµ‹ç²¾åº¦ä¸é«˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡é¢éƒ¨è´¨é‡å¢å¼ºå’ŒéŸ³é¢‘è§†è§‰èåˆæ¥æå‡ç¤¾äº¤äº’åŠ¨æ£€æµ‹çš„å‡†ç¡®æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨LAMå’ŒTTMä»»åŠ¡ä¸­ï¼Œåˆ©ç”¨è§†è§‰è´¨é‡è¯„åˆ†æ¥åŠ æƒèåˆä¸åŒæ¨¡æ€çš„ä¿¡æ¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šLAMæ¨¡å—ä¸“æ³¨äºé¢éƒ¨è£å‰ªåºåˆ—çš„å¤„ç†ï¼ŒTTMæ¨¡å—åˆ™ç»“åˆè¯´è¯è€…é¢éƒ¨è£å‰ªä¸éŸ³é¢‘ç‰‡æ®µï¼Œç¡®ä¿ä¿¡æ¯çš„åŒæ­¥ä¸å‡†ç¡®æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºé€šè¿‡è§†è§‰è´¨é‡è¯„åˆ†å¯¹éŸ³é¢‘å’Œè§†è§‰çº¿ç´¢è¿›è¡ŒåŠ æƒèåˆï¼Œè¿™ä¸€è®¾è®¡æ˜¾è‘—æå‡äº†ç¤¾äº¤äº’åŠ¨çš„æ£€æµ‹æ€§èƒ½ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”å…·æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œæˆ‘ä»¬é‡‡ç”¨äº†é›†æˆæ–¹æ³•æ¥å¢å¼ºé¢éƒ¨è´¨é‡ï¼Œå¹¶åœ¨TTMä»»åŠ¡ä¸­è®¾è®¡äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–éŸ³é¢‘ä¸è§†è§‰ä¿¡æ¯çš„èåˆæ•ˆæœã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’Œå‚æ•°è®¾ç½®åœ¨å®éªŒä¸­è¿›è¡Œäº†è¯¦ç»†è°ƒä¼˜ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨LAMå’ŒTTMä»»åŠ¡ä¸­åˆ†åˆ«å–å¾—äº†0.81å’Œ0.71çš„å¹³å‡ç²¾åº¦ï¼ˆmAPï¼‰ï¼Œæ˜¾è‘—é«˜äºç°æœ‰åŸºçº¿ï¼Œå±•ç¤ºäº†éŸ³é¢‘ä¸è§†è§‰ä¿¡æ¯èåˆçš„æœ‰æ•ˆæ€§ï¼Œæå‡å¹…åº¦æ˜æ˜¾ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾äº¤æœºå™¨äººã€æ™ºèƒ½ç›‘æ§å’Œäººæœºäº¤äº’ç­‰ï¼Œèƒ½å¤Ÿåœ¨å¤æ‚ç¤¾äº¤åœºæ™¯ä¸­å®ç°æ›´é«˜æ•ˆçš„äº’åŠ¨æ£€æµ‹ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åœ¨å¢å¼ºç°å®å’Œè™šæ‹Ÿç°å®ç­‰é¢†åŸŸå‘æŒ¥é‡è¦ä½œç”¨ï¼Œæ¨åŠ¨ç¤¾äº¤äº’åŠ¨çš„æ™ºèƒ½åŒ–å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This report presents our team's PCIE_Interaction solution for the Ego4D Social Interaction Challenge at CVPR 2025, addressing both Looking At Me (LAM) and Talking To Me (TTM) tasks. The challenge requires accurate detection of social interactions between subjects and the camera wearer, with LAM relying exclusively on face crop sequences and TTM combining speaker face crops with synchronized audio segments. In the LAM track, we employ face quality enhancement and ensemble methods. For the TTM task, we extend visual interaction analysis by fusing audio and visual cues, weighted by a visual quality score. Our approach achieved 0.81 and 0.71 mean average precision (mAP) on the LAM and TTM challenges leader board. Code is available at https://github.com/KanokphanL/PCIE_Ego4D_Social_Interaction

