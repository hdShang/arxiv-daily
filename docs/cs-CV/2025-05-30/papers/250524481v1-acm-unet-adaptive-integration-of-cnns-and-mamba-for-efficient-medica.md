---
layout: default
title: "ACM-UNet: Adaptive Integration of CNNs and Mamba for Efficient Medical Image Segmentation"
---

# ACM-UNet: Adaptive Integration of CNNs and Mamba for Efficient Medical Image Segmentation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.24481" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.24481v1</a>
  <a href="https://arxiv.org/pdf/2505.24481.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.24481v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.24481v1', 'ACM-UNet: Adaptive Integration of CNNs and Mamba for Efficient Medical Image Segmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jing Huang, Yongkang Zhao, Yuhan Li, Zhitao Dai, Cheng Chen, Qiying Lai

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-30

**å¤‡æ³¨**: 10 pages, 3 figures, 5 tables

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/zyklcode/ACM-UNet)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºACM-UNetä»¥è§£å†³åŒ»ç–—å›¾åƒåˆ†å‰²ä¸­çš„ç»“æ„ä¸åŒ¹é…é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `åŒ»ç–—å›¾åƒåˆ†å‰²` `å·ç§¯ç¥ç»ç½‘ç»œ` `Mambaæ¨¡å‹` `ç‰¹å¾èåˆ` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„åŒ»ç–—å›¾åƒåˆ†å‰²æ–¹æ³•åœ¨åˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹æ—¶å¸¸å› ç»“æ„ä¸åŒ¹é…è€Œæ— æ³•å……åˆ†å‘æŒ¥å…¶ä¼˜åŠ¿ã€‚
2. ACM-UNeté€šè¿‡è½»é‡çº§é€‚é…å™¨æœºåˆ¶æœ‰æ•ˆæ•´åˆCNNå’ŒMambaæ¨¡å‹ï¼Œè§£å†³äº†æ¶æ„ä¸å…¼å®¹é—®é¢˜ã€‚
3. åœ¨Synapseæ•°æ®é›†ä¸Šï¼ŒACM-UNetè¾¾åˆ°äº†85.12%çš„Dice Scoreå’Œ13.89mmçš„HD95ï¼Œå±•ç¤ºäº†å…¶ä¼˜è¶Šçš„æ€§èƒ½å’Œè®¡ç®—æ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

Uå‹ç¼–ç å™¨-è§£ç å™¨æ¶æ„å› å…¶ç®€å•æœ‰æ•ˆè€Œæˆä¸ºåŒ»ç–—å›¾åƒåˆ†å‰²çš„ä¸»æµèŒƒå¼ã€‚å°½ç®¡è®¸å¤šç ”ç©¶è‡´åŠ›äºé€šè¿‡è®¾è®¡æ›´å¼ºå¤§çš„ç¼–ç å™¨å’Œè§£ç å™¨æ¥æ”¹è¿›è¿™ä¸€æ¡†æ¶ï¼Œä½†ç°æœ‰æ–¹æ³•åœ¨å……åˆ†åˆ©ç”¨é¢„è®­ç»ƒè§†è§‰éª¨å¹²ç½‘ç»œï¼ˆå¦‚ResNetã€ViTã€VMambaï¼‰æ—¶å¸¸é¢ä¸´ç»“æ„ä¸åŒ¹é…çš„é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ACM-UNetï¼Œä¸€ä¸ªé€šç”¨çš„åˆ†å‰²æ¡†æ¶ï¼Œä¿ç•™äº†ç®€å•çš„UNetè®¾è®¡ï¼ŒåŒæ—¶é€šè¿‡è½»é‡çº§é€‚é…å™¨æœºåˆ¶æœ‰æ•ˆæ•´åˆé¢„è®­ç»ƒçš„CNNå’ŒMambaæ¨¡å‹ï¼Œè§£å†³äº†æ¶æ„ä¸å…¼å®¹é—®é¢˜ï¼Œå……åˆ†å‘æŒ¥äº†CNNå’ŒSSMçš„äº’è¡¥ä¼˜åŠ¿ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡åœ¨è§£ç å™¨ä¸­æå‡ºäº†åˆ†å±‚å¤šå°ºåº¦å°æ³¢å˜æ¢æ¨¡å—ï¼Œä»¥å¢å¼ºç‰¹å¾èåˆå’Œé‡å»ºç²¾åº¦ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒACM-UNetåœ¨Synapseå’ŒACDCåŸºå‡†æµ‹è¯•ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶ä¿æŒäº†è®¡ç®—æ•ˆç‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åŒ»ç–—å›¾åƒåˆ†å‰²ä¸­é¢„è®­ç»ƒæ¨¡å‹ä¸ç°æœ‰æ¶æ„ä¹‹é—´çš„ç»“æ„ä¸åŒ¹é…é—®é¢˜ï¼Œå¯¼è‡´æ— æ³•å……åˆ†åˆ©ç”¨å…¶ç‰¹å¾æå–èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šACM-UNeté€šè¿‡å¼•å…¥è½»é‡çº§é€‚é…å™¨æœºåˆ¶ï¼Œä¿ç•™UNetçš„ç®€å•è®¾è®¡ï¼ŒåŒæ—¶æœ‰æ•ˆæ•´åˆCNNå’ŒMambaæ¨¡å‹ï¼Œå……åˆ†å‘æŒ¥å®ƒä»¬åœ¨å±€éƒ¨ç»†èŠ‚æå–å’Œé•¿ç¨‹ä¾èµ–å»ºæ¨¡æ–¹é¢çš„äº’è¡¥ä¼˜åŠ¿ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šACM-UNetçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸€ä¸ªUå‹ç¼–ç å™¨-è§£ç å™¨ç»“æ„ï¼Œç»“åˆäº†è½»é‡çº§é€‚é…å™¨å’Œåˆ†å±‚å¤šå°ºåº¦å°æ³¢å˜æ¢æ¨¡å—ï¼Œä»¥å¢å¼ºç‰¹å¾èåˆå’Œé‡å»ºç²¾åº¦ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºè½»é‡çº§é€‚é…å™¨çš„è®¾è®¡ï¼Œä½¿å¾—é¢„è®­ç»ƒçš„CNNå’ŒMambaæ¨¡å‹èƒ½å¤Ÿæ— ç¼é›†æˆï¼Œå…‹æœäº†ä»¥å¾€æ–¹æ³•çš„ç»“æ„ä¸å…¼å®¹é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œç»“æ„ä¸­ï¼Œé€‚é…å™¨çš„å‚æ•°è®¾ç½®ç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨ä¿æŒè®¡ç®—æ•ˆç‡çš„åŒæ—¶ï¼Œèƒ½å¤Ÿå®ç°é«˜è´¨é‡çš„ç‰¹å¾æå–å’Œèåˆã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨Synapseæ•°æ®é›†ä¸Šï¼ŒACM-UNetè¾¾åˆ°äº†85.12%çš„Dice Scoreå’Œ13.89mmçš„HD95ï¼Œè®¡ç®—å¤æ‚åº¦ä¸º17.93G FLOPsï¼Œå±•ç°äº†å…¶åœ¨æ€§èƒ½å’Œæ•ˆç‡ä¸Šçš„æ˜¾è‘—ä¼˜åŠ¿ï¼Œè¶…è¶Šäº†ç°æœ‰çš„åŸºçº¿æ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ACM-UNetåœ¨åŒ»ç–—å›¾åƒåˆ†å‰²é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæé«˜åŒ»å­¦å½±åƒçš„å¤„ç†ç²¾åº¦ï¼Œè¾…åŠ©åŒ»ç”Ÿè¿›è¡Œè¯Šæ–­å’Œæ²»ç–—å†³ç­–ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•è¿˜å¯æ‰©å±•åˆ°å…¶ä»–å›¾åƒå¤„ç†ä»»åŠ¡ï¼Œå¦‚è‡ªåŠ¨é©¾é©¶ã€é¥æ„Ÿå›¾åƒåˆ†æç­‰ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The U-shaped encoder-decoder architecture with skip connections has become a prevailing paradigm in medical image segmentation due to its simplicity and effectiveness. While many recent works aim to improve this framework by designing more powerful encoders and decoders, employing advanced convolutional neural networks (CNNs) for local feature extraction, Transformers or state space models (SSMs) such as Mamba for global context modeling, or hybrid combinations of both, these methods often struggle to fully utilize pretrained vision backbones (e.g., ResNet, ViT, VMamba) due to structural mismatches. To bridge this gap, we introduce ACM-UNet, a general-purpose segmentation framework that retains a simple UNet-like design while effectively incorporating pretrained CNNs and Mamba models through a lightweight adapter mechanism. This adapter resolves architectural incompatibilities and enables the model to harness the complementary strengths of CNNs and SSMs-namely, fine-grained local detail extraction and long-range dependency modeling. Additionally, we propose a hierarchical multi-scale wavelet transform module in the decoder to enhance feature fusion and reconstruction fidelity. Extensive experiments on the Synapse and ACDC benchmarks demonstrate that ACM-UNet achieves state-of-the-art performance while remaining computationally efficient. Notably, it reaches 85.12% Dice Score and 13.89mm HD95 on the Synapse dataset with 17.93G FLOPs, showcasing its effectiveness and scalability. Code is available at: https://github.com/zyklcode/ACM-UNet.

