---
layout: default
title: "I Spy With My Model's Eye: Visual Search as a Behavioural Test for MLLMs"
---

# I Spy With My Model's Eye: Visual Search as a Behavioural Test for MLLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.19678" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.19678v1</a>
  <a href="https://arxiv.org/pdf/2510.19678.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.19678v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.19678v1', 'I Spy With My Model\'s Eye: Visual Search as a Behavioural Test for MLLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: John Burden, Jonathan Prunty, Ben Slater, Matthieu Tehenan, Greg Davis, Lucy Cheke

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-10-22

**å¤‡æ³¨**: Preprint

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ©ç”¨è§†è§‰æœç´¢è¡Œä¸ºæµ‹è¯•è¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLM)çš„è§†è§‰æ„ŸçŸ¥èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `è§†è§‰æœç´¢` `è·³å‡ºæ•ˆåº”` `è®¤çŸ¥å¿ƒç†å­¦` `è§†è§‰æ„ŸçŸ¥`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰MLLMçš„è§†è§‰å¤„ç†æœºåˆ¶ä¸é€æ˜ï¼Œä»…é€šè¿‡ä»»åŠ¡å‡†ç¡®æ€§è¯„ä¼°éš¾ä»¥æ·±å…¥äº†è§£å…¶å†…åœ¨å·¥ä½œåŸç†ã€‚
2. å€Ÿé‰´è®¤çŸ¥å¿ƒç†å­¦ä¸­çš„è§†è§‰æœç´¢èŒƒå¼ï¼Œé€šè¿‡æµ‹è¯•MLLMçš„â€œè·³å‡ºæ•ˆåº”â€æ¥è¯„ä¼°å…¶è§†è§‰æ„ŸçŸ¥èƒ½åŠ›ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒMLLMåœ¨å•ç‰¹å¾æœç´¢ä¸­è¡¨ç°å‡ºç±»ä¼¼äººç±»çš„è·³å‡ºæ•ˆåº”ï¼Œå¹¶åœ¨å¤šç‰¹å¾æœç´¢ä¸­å­˜åœ¨èƒ½åŠ›é™åˆ¶ï¼ŒåŒæ—¶èå…¥äº†è‡ªç„¶åœºæ™¯å…ˆéªŒçŸ¥è¯†ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLM)åœ¨è§†è§‰-è¯­è¨€ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶è§†è§‰å¤„ç†æœºåˆ¶ä»ç„¶ä¸é€æ˜ã€‚å¤§å¤šæ•°é»‘ç›’è¯„ä¼°ä¾§é‡äºä»»åŠ¡å‡†ç¡®æ€§ï¼Œå´å¾ˆå°‘æ­ç¤ºå…¶å†…åœ¨æœºåˆ¶ã€‚å€Ÿé‰´è®¤çŸ¥å¿ƒç†å­¦ï¼Œæœ¬æ–‡å°†ç»å…¸çš„è§†è§‰æœç´¢èŒƒå¼ï¼ˆæœ€åˆç”¨äºç ”ç©¶äººç±»æ„ŸçŸ¥ï¼‰åº”ç”¨äºæµ‹è¯•MLLMæ˜¯å¦è¡¨ç°å‡ºâ€œè·³å‡ºæ•ˆåº”â€ï¼Œå³æ˜¾è‘—çš„è§†è§‰ç‰¹å¾æ˜¯å¦èƒ½ç‹¬ç«‹äºå¹²æ‰°é¡¹çš„æ•°é‡è¢«æ£€æµ‹åˆ°ã€‚é€šè¿‡æ§åˆ¶é¢œè‰²ã€å¤§å°å’Œå…‰ç…§ç‰¹å¾çš„å®éªŒï¼Œæˆ‘ä»¬å‘ç°å…ˆè¿›çš„MLLMåœ¨åŸºäºé¢œè‰²æˆ–å¤§å°çš„åˆ†ç¦»ï¼ˆå•ç‰¹å¾ï¼‰æœç´¢ä¸­è¡¨ç°å‡ºç±»ä¼¼äººç±»çš„è·³å‡ºæ•ˆåº”ï¼Œå¹¶ä¸”åœ¨ç»“åˆï¼ˆå¤šç‰¹å¾ï¼‰æœç´¢ä¸­å­˜åœ¨èƒ½åŠ›é™åˆ¶ã€‚æˆ‘ä»¬è¿˜å‘ç°è¯æ®è¡¨æ˜ï¼ŒMLLMåƒäººç±»ä¸€æ ·ï¼Œå°†è‡ªç„¶åœºæ™¯å…ˆéªŒçŸ¥è¯†ï¼ˆå¦‚å…‰ç…§æ–¹å‘ï¼‰èå…¥åˆ°ç‰©ä½“è¡¨å¾ä¸­ã€‚æˆ‘ä»¬é€šè¿‡æœ‰é’ˆå¯¹æ€§çš„å¾®è°ƒå’Œæœºåˆ¶å¯è§£é‡Šæ€§åˆ†ææ¥å¼ºåŒ–æˆ‘ä»¬çš„å‘ç°ã€‚è¿™é¡¹å·¥ä½œè¡¨æ˜ï¼Œè§†è§‰æœç´¢å¯ä»¥ä½œä¸ºä¸€ç§è®¤çŸ¥åŸºç¡€çš„è¯Šæ–­å·¥å…·ï¼Œç”¨äºè¯„ä¼°MLLMçš„æ„ŸçŸ¥èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰è§†è§‰å¤„ç†æœºåˆ¶ä¸é€æ˜çš„é—®é¢˜ã€‚ç°æœ‰è¯„ä¼°æ–¹æ³•ä¸»è¦å…³æ³¨ä»»åŠ¡å‡†ç¡®æ€§ï¼Œæ— æ³•æ·±å…¥äº†è§£MLLMå¦‚ä½•è¿›è¡Œè§†è§‰æ„ŸçŸ¥å’Œè¡¨å¾ï¼Œä»¥åŠå…¶è§†è§‰å¤„ç†æ–¹å¼æ˜¯å¦ä¸äººç±»ç›¸ä¼¼ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§æ›´å…·è¯Šæ–­æ€§çš„æ–¹æ³•æ¥è¯„ä¼°MLLMçš„è§†è§‰èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†è®¤çŸ¥å¿ƒç†å­¦ä¸­ç”¨äºç ”ç©¶äººç±»è§†è§‰æ„ŸçŸ¥çš„è§†è§‰æœç´¢èŒƒå¼åº”ç”¨äºMLLMã€‚é€šè¿‡è§‚å¯ŸMLLMåœ¨ä¸åŒè§†è§‰æœç´¢ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œç‰¹åˆ«æ˜¯â€œè·³å‡ºæ•ˆåº”â€ï¼Œæ¥æ¨æ–­å…¶è§†è§‰å¤„ç†æœºåˆ¶ã€‚å¦‚æœMLLMè¡¨ç°å‡ºç±»ä¼¼äººç±»çš„è§†è§‰æœç´¢è¡Œä¸ºï¼Œåˆ™å¯ä»¥è®¤ä¸ºå…¶è§†è§‰æ„ŸçŸ¥æ–¹å¼ä¸äººç±»å­˜åœ¨ç›¸ä¼¼ä¹‹å¤„ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥ç ”ç©¶çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š
1.  **è®¾è®¡è§†è§‰æœç´¢ä»»åŠ¡**ï¼šè®¾è®¡é’ˆå¯¹é¢œè‰²ã€å¤§å°å’Œå…‰ç…§ç­‰ä¸åŒè§†è§‰ç‰¹å¾çš„è§†è§‰æœç´¢ä»»åŠ¡ï¼ŒåŒ…æ‹¬åˆ†ç¦»æœç´¢ï¼ˆå•ç‰¹å¾ï¼‰å’Œç»“åˆæœç´¢ï¼ˆå¤šç‰¹å¾ï¼‰ã€‚
2.  **ä½¿ç”¨MLLMè¿›è¡Œè§†è§‰æœç´¢**ï¼šå°†è®¾è®¡çš„è§†è§‰æœç´¢ä»»åŠ¡è¾“å…¥åˆ°MLLMä¸­ï¼Œè§‚å¯Ÿå…¶æœç´¢ç»“æœå’Œååº”æ—¶é—´ã€‚
3.  **åˆ†æMLLMçš„æœç´¢è¡Œä¸º**ï¼šåˆ†æMLLMæ˜¯å¦è¡¨ç°å‡ºâ€œè·³å‡ºæ•ˆåº”â€ï¼Œä»¥åŠå…¶æœç´¢æ•ˆç‡æ˜¯å¦å—åˆ°å¹²æ‰°é¡¹æ•°é‡çš„å½±å“ã€‚
4.  **å¾®è°ƒå’Œå¯è§£é‡Šæ€§åˆ†æ**ï¼šé€šè¿‡æœ‰é’ˆå¯¹æ€§çš„å¾®è°ƒæ¥éªŒè¯å‘ç°ï¼Œå¹¶ä½¿ç”¨æœºåˆ¶å¯è§£é‡Šæ€§åˆ†ææ¥è¿›ä¸€æ­¥ç†è§£MLLMçš„è§†è§‰å¤„ç†æœºåˆ¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶çš„å…³é”®åˆ›æ–°åœ¨äºå°†è®¤çŸ¥å¿ƒç†å­¦ä¸­çš„è§†è§‰æœç´¢èŒƒå¼å¼•å…¥åˆ°MLLMçš„è¯„ä¼°ä¸­ã€‚è¿™ç§æ–¹æ³•æä¾›äº†ä¸€ç§æ›´å…·è¯Šæ–­æ€§çš„æ–¹å¼æ¥è¯„ä¼°MLLMçš„è§†è§‰æ„ŸçŸ¥èƒ½åŠ›ï¼Œå¹¶æ­ç¤ºäº†å…¶è§†è§‰å¤„ç†æœºåˆ¶ä¸äººç±»è§†è§‰æ„ŸçŸ¥ä¹‹é—´çš„ç›¸ä¼¼ä¹‹å¤„ã€‚ä¸ä¼ ç»Ÿçš„é»‘ç›’è¯„ä¼°æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´æ·±å…¥åœ°äº†è§£MLLMçš„å†…åœ¨å·¥ä½œåŸç†ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒè®¾è®¡æ–¹é¢ï¼Œè®ºæ–‡é‡‡ç”¨äº†æ§åˆ¶å˜é‡çš„æ–¹æ³•ï¼Œç²¾å¿ƒè®¾è®¡äº†é’ˆå¯¹ä¸åŒè§†è§‰ç‰¹å¾çš„è§†è§‰æœç´¢ä»»åŠ¡ã€‚ä¾‹å¦‚ï¼Œåœ¨é¢œè‰²æœç´¢ä»»åŠ¡ä¸­ï¼Œç›®æ ‡ç‰©ä½“å’Œå¹²æ‰°é¡¹çš„é¢œè‰²å·®å¼‚è¢«ç²¾ç¡®æ§åˆ¶ï¼Œä»¥ç¡®ä¿å®éªŒç»“æœçš„å¯é æ€§ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜ä½¿ç”¨äº†ååº”æ—¶é—´ä½œä¸ºè¯„ä¼°æŒ‡æ ‡ï¼Œä»¥æ›´å‡†ç¡®åœ°è¡¡é‡MLLMçš„æœç´¢æ•ˆç‡ã€‚åœ¨å¾®è°ƒæ–¹é¢ï¼Œè®ºæ–‡é‡‡ç”¨äº†æœ‰é’ˆå¯¹æ€§çš„å¾®è°ƒç­–ç•¥ï¼Œä»¥éªŒè¯å‘ç°å¹¶æé«˜MLLMåœ¨ç‰¹å®šè§†è§‰æœç´¢ä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå…ˆè¿›çš„MLLMåœ¨é¢œè‰²å’Œå¤§å°çš„åˆ†ç¦»æœç´¢ä¸­è¡¨ç°å‡ºç±»ä¼¼äººç±»çš„â€œè·³å‡ºæ•ˆåº”â€ï¼Œå³æœç´¢æ—¶é—´ä¸å—å¹²æ‰°é¡¹æ•°é‡çš„å½±å“ã€‚ç„¶è€Œï¼Œåœ¨ç»“åˆæœç´¢ä¸­ï¼ŒMLLMçš„æœç´¢æ•ˆç‡å—åˆ°å¹²æ‰°é¡¹æ•°é‡çš„æ˜¾è‘—å½±å“ï¼Œè¡¨æ˜å…¶å­˜åœ¨èƒ½åŠ›é™åˆ¶ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å‘ç°MLLMèƒ½å¤Ÿåƒäººç±»ä¸€æ ·ï¼Œå°†è‡ªç„¶åœºæ™¯å…ˆéªŒçŸ¥è¯†ï¼ˆå¦‚å…‰ç…§æ–¹å‘ï¼‰èå…¥åˆ°ç‰©ä½“è¡¨å¾ä¸­ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè¯„ä¼°å’Œæ”¹è¿›MLLMçš„è§†è§‰æ„ŸçŸ¥èƒ½åŠ›ï¼Œä½¿å…¶åœ¨å›¾åƒè¯†åˆ«ã€ç›®æ ‡æ£€æµ‹ã€è§†è§‰é—®ç­”ç­‰ä»»åŠ¡ä¸­è¡¨ç°æ›´ä½³ã€‚é€šè¿‡ç†è§£MLLMçš„è§†è§‰å¤„ç†æœºåˆ¶ï¼Œå¯ä»¥æ›´å¥½åœ°è®¾è®¡å’Œä¼˜åŒ–æ¨¡å‹ï¼Œæé«˜å…¶é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶ä¹Ÿä¸ºå¼€å‘æ›´æ™ºèƒ½ã€æ›´äººæ€§åŒ–çš„AIç³»ç»Ÿæä¾›äº†æ–°çš„æ€è·¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal large language models (MLLMs) achieve strong performance on vision-language tasks, yet their visual processing is opaque. Most black-box evaluations measure task accuracy, but reveal little about underlying mechanisms. Drawing on cognitive psychology, we adapt classic visual search paradigms -- originally developed to study human perception -- to test whether MLLMs exhibit the ``pop-out'' effect, where salient visual features are detected independently of distractor set size. Using controlled experiments targeting colour, size and lighting features, we find that advanced MLLMs exhibit human-like pop-out effects in colour or size-based disjunctive (single feature) search, as well as capacity limits for conjunctive (multiple feature) search. We also find evidence to suggest that MLLMs, like humans, incorporate natural scene priors such as lighting direction into object representations. We reinforce our findings using targeted fine-tuning and mechanistic interpretability analyses. Our work shows how visual search can serve as a cognitively grounded diagnostic tool for evaluating perceptual capabilities in MLLMs.

