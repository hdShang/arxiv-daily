---
layout: default
title: PoseCrafter: Extreme Pose Estimation with Hybrid Video Synthesis
---

# PoseCrafter: Extreme Pose Estimation with Hybrid Video Synthesis

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.19527" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.19527v1</a>
  <a href="https://arxiv.org/pdf/2510.19527.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.19527v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.19527v1', 'PoseCrafter: Extreme Pose Estimation with Hybrid Video Synthesis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Qing Mao, Tianxin Huang, Yu Zhu, Jinqiu Sun, Yanning Zhang, Gim Hee Lee

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-22

**å¤‡æ³¨**: 39th Conference on Neural Information Processing Systems (NeurIPS 2025)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**PoseCrafterï¼šåˆ©ç”¨æ··åˆè§†é¢‘åˆæˆå¢å¼ºæç«¯ä½å§¿ä¼°è®¡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)**

**å…³é”®è¯**: `ä½å§¿ä¼°è®¡` `è§†é¢‘åˆæˆ` `æ–°è§†è§’åˆæˆ` `ç‰¹å¾åŒ¹é…` `ä¸‰ç»´é‡å»º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç¨€ç–é‡å æˆ–æ— é‡å å›¾åƒå¯¹çš„ä½å§¿ä¼°è®¡ä¸­é¢ä¸´æŒ‘æˆ˜ï¼Œç”Ÿæˆçš„ä¸­é—´å¸§æ¨¡ç³Šï¼Œé€‰æ‹©ç­–ç•¥æ•ˆç‡ä½ã€‚
2. æå‡ºæ··åˆè§†é¢‘ç”Ÿæˆï¼ˆHVGï¼‰æ¡†æ¶ï¼Œç»“åˆè§†é¢‘æ’å€¼å’Œä½å§¿æ¡ä»¶çš„æ–°è§†è§’åˆæˆï¼Œç”Ÿæˆæ›´æ¸…æ™°çš„ä¸­é—´å¸§ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒPoseCrafteråœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæ˜¾è‘—æå‡äº†ä½å§¿ä¼°è®¡æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨ä½é‡å åœºæ™¯ä¸‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨ä¸‰ç»´è§†è§‰ä¸­ï¼Œä»ç¨€ç–é‡å å›¾åƒå¯¹ä¸­è¿›è¡Œæˆå¯¹ç›¸æœºä½å§¿ä¼°è®¡ä»ç„¶æ˜¯ä¸€ä¸ªå…³é”®ä¸”æœªè§£å†³çš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†é‡å å°æˆ–æ— é‡å çš„å›¾åƒå¯¹æ—¶è¡¨ç°ä¸ä½³ã€‚æœ€è¿‘çš„æ–¹æ³•è¯•å›¾é€šè¿‡ä½¿ç”¨è§†é¢‘æ’å€¼åˆæˆä¸­é—´å¸§ï¼Œå¹¶é€šè¿‡è‡ªæ´½æ€§å¾—åˆ†é€‰æ‹©å…³é”®å¸§æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚ç„¶è€Œï¼Œç”±äºå°é‡å è¾“å…¥ï¼Œç”Ÿæˆçš„å¸§é€šå¸¸æ˜¯æ¨¡ç³Šçš„ï¼Œå¹¶ä¸”é€‰æ‹©ç­–ç•¥é€Ÿåº¦æ…¢ä¸”æœªä¸ä½å§¿ä¼°è®¡æ˜¾å¼å¯¹é½ã€‚ä¸ºäº†è§£å†³è¿™äº›æƒ…å†µï¼Œæˆ‘ä»¬æå‡ºäº†æ··åˆè§†é¢‘ç”Ÿæˆï¼ˆHVGï¼‰ï¼Œé€šè¿‡å°†è§†é¢‘æ’å€¼æ¨¡å‹ä¸ä½å§¿æ¡ä»¶çš„æ–°è§†è§’åˆæˆæ¨¡å‹ç›¸ç»“åˆæ¥åˆæˆæ›´æ¸…æ™°çš„ä¸­é—´å¸§ï¼ŒåŒæ—¶æˆ‘ä»¬è¿˜æå‡ºäº†åŸºäºç‰¹å¾å¯¹åº”å…³ç³»çš„ç‰¹å¾åŒ¹é…é€‰æ‹©å™¨ï¼ˆFMSï¼‰ï¼Œç”¨äºä»åˆæˆç»“æœä¸­é€‰æ‹©é€‚åˆä½å§¿ä¼°è®¡çš„ä¸­é—´å¸§ã€‚åœ¨Cambridge Landmarksã€ScanNetã€DL3DV-10Kå’ŒNAVIä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œä¸ç°æœ‰çš„SOTAæ–¹æ³•ç›¸æ¯”ï¼ŒPoseCrafterå¯ä»¥æ˜¾è‘—æé«˜ä½å§¿ä¼°è®¡æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨é‡å å°æˆ–æ— é‡å çš„ç¤ºä¾‹ä¸Šã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ä»ç¨€ç–é‡å å›¾åƒå¯¹ä¸­è¿›è¡Œç²¾ç¡®ç›¸æœºä½å§¿ä¼°è®¡çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†æ­¤ç±»å›¾åƒå¯¹æ—¶ï¼Œç”±äºç¼ºä¹è¶³å¤Ÿçš„è§†è§‰ä¿¡æ¯ï¼Œå¯¼è‡´ä½å§¿ä¼°è®¡ç²¾åº¦æ˜¾è‘—ä¸‹é™ã€‚ç°æœ‰çš„è§†é¢‘æ’å€¼æ–¹æ³•ç”Ÿæˆçš„ä¸­é—´å¸§é€šå¸¸æ¨¡ç³Šä¸æ¸…ï¼Œæ— æ³•æœ‰æ•ˆè¾…åŠ©ä½å§¿ä¼°è®¡ã€‚æ­¤å¤–ï¼Œç°æœ‰çš„å…³é”®å¸§é€‰æ‹©ç­–ç•¥æ•ˆç‡è¾ƒä½ï¼Œä¸”ä¸ä½å§¿ä¼°è®¡ä»»åŠ¡çš„å…³è”æ€§ä¸å¼ºã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ··åˆè§†é¢‘ç”Ÿæˆï¼ˆHVGï¼‰æ¥åˆæˆé«˜è´¨é‡çš„ä¸­é—´å¸§ï¼Œä»è€Œå¼¥è¡¥ç¨€ç–é‡å å›¾åƒå¯¹ä¹‹é—´çš„è§†è§‰ä¿¡æ¯ç¼ºå¤±ã€‚HVGç»“åˆäº†è§†é¢‘æ’å€¼å’Œä½å§¿æ¡ä»¶çš„æ–°è§†è§’åˆæˆï¼Œæ—¨åœ¨ç”Ÿæˆæ›´æ¸…æ™°ã€æ›´é€‚åˆä½å§¿ä¼°è®¡çš„ä¸­é—´å¸§ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æå‡ºäº†ç‰¹å¾åŒ¹é…é€‰æ‹©å™¨ï¼ˆFMSï¼‰ï¼Œç”¨äºä»åˆæˆçš„ä¸­é—´å¸§ä¸­é€‰æ‹©æœ€æœ‰åˆ©äºä½å§¿ä¼°è®¡çš„å¸§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPoseCrafterçš„æ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) è§†é¢‘æ’å€¼æ¨¡å—ï¼šç”¨äºç”Ÿæˆåˆå§‹çš„ä¸­é—´å¸§ï¼›2) ä½å§¿æ¡ä»¶çš„æ–°è§†è§’åˆæˆæ¨¡å—ï¼šåˆ©ç”¨ä¼°è®¡çš„ä½å§¿ä¿¡æ¯ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–ä¸­é—´å¸§çš„è´¨é‡ï¼›3) æ··åˆè§†é¢‘ç”Ÿæˆï¼ˆHVGï¼‰æ¨¡å—ï¼šå°†è§†é¢‘æ’å€¼å’Œæ–°è§†è§’åˆæˆçš„ç»“æœè¿›è¡Œèåˆï¼Œç”Ÿæˆæœ€ç»ˆçš„ä¸­é—´å¸§ï¼›4) ç‰¹å¾åŒ¹é…é€‰æ‹©å™¨ï¼ˆFMSï¼‰ï¼šåŸºäºç‰¹å¾å¯¹åº”å…³ç³»ï¼Œé€‰æ‹©æœ€é€‚åˆä½å§¿ä¼°è®¡çš„ä¸­é—´å¸§ï¼›5) ä½å§¿ä¼°è®¡æ¨¡å—ï¼šåˆ©ç”¨åŸå§‹å›¾åƒå¯¹å’Œé€‰æ‹©çš„ä¸­é—´å¸§ï¼Œè¿›è¡Œæœ€ç»ˆçš„ä½å§¿ä¼°è®¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†æ··åˆè§†é¢‘ç”Ÿæˆï¼ˆHVGï¼‰æ¡†æ¶å’Œç‰¹å¾åŒ¹é…é€‰æ‹©å™¨ï¼ˆFMSï¼‰ã€‚HVGé€šè¿‡ç»“åˆè§†é¢‘æ’å€¼å’Œä½å§¿æ¡ä»¶çš„æ–°è§†è§’åˆæˆï¼Œæœ‰æ•ˆåœ°æé«˜äº†ä¸­é—´å¸§çš„è´¨é‡ï¼Œä½¿å…¶æ›´é€‚åˆä½å§¿ä¼°è®¡ä»»åŠ¡ã€‚FMSåˆ™é€šè¿‡ç‰¹å¾å¯¹åº”å…³ç³»ï¼Œå®ç°äº†å¯¹ä¸­é—´å¸§çš„æœ‰æ•ˆé€‰æ‹©ï¼Œè¿›ä¸€æ­¥æå‡äº†ä½å§¿ä¼°è®¡çš„ç²¾åº¦ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒHVGå’ŒFMSèƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†ç¨€ç–é‡å å›¾åƒå¯¹ï¼Œä»è€Œæ˜¾è‘—æé«˜ä½å§¿ä¼°è®¡çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šHVGçš„å…³é”®è®¾è®¡åœ¨äºå¦‚ä½•æœ‰æ•ˆåœ°èåˆè§†é¢‘æ’å€¼å’Œæ–°è§†è§’åˆæˆçš„ç»“æœã€‚è®ºæ–‡å¯èƒ½é‡‡ç”¨äº†åŠ æƒå¹³å‡æˆ–å…¶ä»–èåˆç­–ç•¥ï¼Œä»¥å¹³è¡¡ä¸¤ç§æ–¹æ³•çš„ä¼˜ç‚¹ã€‚FMSçš„å…³é”®è®¾è®¡åœ¨äºå¦‚ä½•å®šä¹‰ç‰¹å¾å¯¹åº”å…³ç³»ï¼Œä»¥åŠå¦‚ä½•åˆ©ç”¨è¿™äº›å¯¹åº”å…³ç³»æ¥é€‰æ‹©æœ€ä½³çš„ä¸­é—´å¸§ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°ã€ç½‘ç»œç»“æ„å’Œå‚æ•°è®¾ç½®ç­‰æŠ€æœ¯ç»†èŠ‚æœªçŸ¥ï¼Œéœ€è¦æŸ¥é˜…è®ºæ–‡åŸæ–‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒPoseCrafteråœ¨Cambridge Landmarksã€ScanNetã€DL3DV-10Kå’ŒNAVIç­‰æ•°æ®é›†ä¸Šå‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†å°é‡å æˆ–æ— é‡å å›¾åƒå¯¹æ—¶ã€‚ä¸ç°æœ‰SOTAæ–¹æ³•ç›¸æ¯”ï¼ŒPoseCrafteråœ¨ä½å§¿ä¼°è®¡ç²¾åº¦æ–¹é¢æœ‰æ˜æ˜¾ä¼˜åŠ¿ï¼Œè¯æ˜äº†HVGå’ŒFMSçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºä¸‰ç»´é‡å»ºã€è§†è§‰å®šä½ã€å¢å¼ºç°å®ã€æœºå™¨äººå¯¼èˆªç­‰é¢†åŸŸã€‚å°¤å…¶æ˜¯åœ¨ç¼ºä¹è¶³å¤Ÿè§†è§‰ä¿¡æ¯çš„åœºæ™¯ä¸‹ï¼Œä¾‹å¦‚åœ¨å…‰ç…§æ¡ä»¶å·®ã€é®æŒ¡ä¸¥é‡æˆ–è§†ç‚¹å˜åŒ–å¤§çš„ç¯å¢ƒä¸­ï¼ŒPoseCrafterèƒ½å¤Ÿæ˜¾è‘—æé«˜ä½å§¿ä¼°è®¡çš„ç²¾åº¦å’Œé²æ£’æ€§ï¼Œä»è€Œä¸ºç›¸å…³åº”ç”¨æä¾›æ›´å¯é çš„åŸºç¡€ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Pairwise camera pose estimation from sparsely overlapping image pairs remains a critical and unsolved challenge in 3D vision. Most existing methods struggle with image pairs that have small or no overlap. Recent approaches attempt to address this by synthesizing intermediate frames using video interpolation and selecting key frames via a self-consistency score. However, the generated frames are often blurry due to small overlap inputs, and the selection strategies are slow and not explicitly aligned with pose estimation. To solve these cases, we propose Hybrid Video Generation (HVG) to synthesize clearer intermediate frames by coupling a video interpolation model with a pose-conditioned novel view synthesis model, where we also propose a Feature Matching Selector (FMS) based on feature correspondence to select intermediate frames appropriate for pose estimation from the synthesized results. Extensive experiments on Cambridge Landmarks, ScanNet, DL3DV-10K, and NAVI demonstrate that, compared to existing SOTA methods, PoseCrafter can obviously enhance the pose estimation performances, especially on examples with small or no overlap.

