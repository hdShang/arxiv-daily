---
layout: default
title: Transformed Multi-view 3D Shape Features with Contrastive Learning
---

# Transformed Multi-view 3D Shape Features with Contrastive Learning

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.19955" target="_blank" class="toolbar-btn">arXiv: 2510.19955v1</a>
    <a href="https://arxiv.org/pdf/2510.19955.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.19955v1" 
            onclick="toggleFavorite(this, '2510.19955v1', 'Transformed Multi-view 3D Shape Features with Contrastive Learning')" title="æ”¶è—">
      â˜† æ”¶è—
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="å¤åˆ¶é“¾æ¥">
      ğŸ”— åˆ†äº«
    </button>
  </div>
</div>


**ä½œè€…**: MÃ¡rcus VinÃ­cius Lobo Costa, Sherlon Almeida da Silva, BÃ¡rbara Caroline Benato, Leo Sampaio Ferraz Ribeiro, Moacir Antonelli Ponti

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-22

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå¯¹æ¯”å­¦ä¹ çš„Transformerå¤šè§†è§’3Då½¢çŠ¶ç‰¹å¾æå–æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `3Då½¢çŠ¶è¯†åˆ«` `å¤šè§†è§’å­¦ä¹ ` `Vision Transformer` `å¯¹æ¯”å­¦ä¹ ` `è¡¨ç¤ºå­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰3Då½¢çŠ¶è¯†åˆ«æ–¹æ³•ä¾èµ–å¤§é‡æ ‡æ³¨æ•°æ®ï¼Œä¸”CNNéš¾ä»¥æ•æ‰å…³é”®å½¢çŠ¶å…³ç³»ã€‚
2. åˆ©ç”¨ViTæå–å…¨å±€å½¢çŠ¶è¯­ä¹‰ï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ ä¼˜åŒ–å±€éƒ¨åˆ¤åˆ«ç‰¹å¾ï¼Œæå‡3Då½¢çŠ¶è¡¨ç¤ºã€‚
3. å®éªŒè¡¨æ˜ï¼ŒViTç»“åˆå¯¹æ¯”å­¦ä¹ åœ¨å¤šè§†è§’3Dåˆ†æä¸­è¡¨ç°å‡ºè‰²ï¼ŒModelNet10å‡†ç¡®ç‡è¾¾90.6%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æ—¨åœ¨è§£å†³3Då½¢çŠ¶ç‰¹å¾è¡¨ç¤ºå­¦ä¹ ä¸­çš„æŒ‘æˆ˜ï¼Œç ”ç©¶äº†æœ€å…ˆè¿›çš„éª¨å¹²ç½‘ç»œä¸å¯¹æ¯”ç›‘ç£å’Œè‡ªç›‘ç£å­¦ä¹ ç›®æ ‡ç›¸ç»“åˆçš„æ•ˆæœã€‚è®¡ç®—æœºè§†è§‰æ–¹æ³•åœ¨ä»2Då›¾åƒä¸­è¯†åˆ«3Då¯¹è±¡æ—¶é¢ä¸´å›°éš¾ï¼Œé€šå¸¸éœ€è¦å¤§é‡çš„æ ‡æ³¨æ•°æ®ï¼Œå¹¶ä¸”ä¾èµ–äºå·ç§¯ç¥ç»ç½‘ç»œ(CNN)ï¼Œè€ŒCNNå¯èƒ½å¿½ç•¥å…³é”®çš„å½¢çŠ¶å…³ç³»ã€‚æˆ‘ä»¬çš„å·¥ä½œè¡¨æ˜ï¼ŒåŸºäºVision Transformers (ViTs)çš„æ¶æ„ï¼Œå½“ä¸ç°ä»£å¯¹æ¯”ç›®æ ‡ç›¸ç»“åˆæ—¶ï¼Œåœ¨æˆ‘ä»¬çš„ä¸‹æ¸¸ä»»åŠ¡çš„å¤šè§†è§’3Dåˆ†æä¸­å–å¾—äº†æœ‰å¸Œæœ›çš„ç»“æœï¼Œç»Ÿä¸€äº†å¯¹æ¯”å­¦ä¹ å’Œ3Då½¢çŠ¶ç†è§£æµç¨‹ã€‚ä¾‹å¦‚ï¼Œç›‘ç£å¯¹æ¯”æŸå¤±åœ¨ModelNet10ä¸Šè¾¾åˆ°äº†çº¦90.6%çš„å‡†ç¡®ç‡ã€‚ViTså’Œå¯¹æ¯”å­¦ä¹ çš„ä½¿ç”¨ï¼Œåˆ©ç”¨äº†ViTsç†è§£æ•´ä½“å½¢çŠ¶çš„èƒ½åŠ›å’Œå¯¹æ¯”å­¦ä¹ çš„æœ‰æ•ˆæ€§ï¼Œå…‹æœäº†å¯¹å¤§é‡æ ‡æ³¨æ•°æ®çš„éœ€æ±‚ä»¥åŠCNNåœ¨æ•è·å…³é”®å½¢çŠ¶å…³ç³»æ–¹é¢çš„å±€é™æ€§ã€‚æˆåŠŸæºäºé€šè¿‡ViTsæ•è·å…¨å±€å½¢çŠ¶è¯­ä¹‰ï¼Œå¹¶é€šè¿‡å¯¹æ¯”ä¼˜åŒ–ç»†åŒ–å±€éƒ¨åˆ¤åˆ«ç‰¹å¾ã€‚é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜¯ç»éªŒæ€§çš„ï¼Œå› ä¸ºå®ƒåŸºäºå¹¿æ³›çš„å®éªŒè¯„ä¼°ï¼Œä»¥éªŒè¯å°†ViTsä¸å¯¹æ¯”ç›®æ ‡ç›¸ç»“åˆç”¨äº3Dè¡¨ç¤ºå­¦ä¹ çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æ–¹æ³•åœ¨3Då½¢çŠ¶ç‰¹å¾è¡¨ç¤ºå­¦ä¹ ä¸­é¢ä¸´æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨ä»2Då›¾åƒä¸­è¯†åˆ«3Då¯¹è±¡æ—¶ï¼Œéœ€è¦å¤§é‡çš„æ ‡æ³¨æ•°æ®ã€‚ä¼ ç»Ÿçš„å·ç§¯ç¥ç»ç½‘ç»œ(CNN)åœ¨æ•æ‰3Då½¢çŠ¶çš„å…³é”®å…³ç³»æ–¹é¢å­˜åœ¨å±€é™æ€§ï¼Œå¯¼è‡´è¯†åˆ«ç²¾åº¦ä¸é«˜ï¼Œæ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†Vision Transformers (ViTs)ä¸å¯¹æ¯”å­¦ä¹ ç›¸ç»“åˆï¼Œåˆ©ç”¨ViTså¼ºå¤§çš„å…¨å±€å»ºæ¨¡èƒ½åŠ›æ¥æ•è·3Då½¢çŠ¶çš„æ•´ä½“è¯­ä¹‰ä¿¡æ¯ï¼Œå¹¶é€šè¿‡å¯¹æ¯”å­¦ä¹ æ¥ä¼˜åŒ–å±€éƒ¨åˆ¤åˆ«ç‰¹å¾ï¼Œä»è€Œæå‡3Då½¢çŠ¶è¡¨ç¤ºçš„è´¨é‡å’Œé²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) å¤šè§†è§’å›¾åƒè¾“å…¥ï¼šä»å¤šä¸ªè§’åº¦è·å–3Då¯¹è±¡çš„2Då›¾åƒï¼›2) ViTç‰¹å¾æå–ï¼šä½¿ç”¨ViTæå–æ¯ä¸ªè§†è§’çš„å›¾åƒç‰¹å¾ï¼›3) å¯¹æ¯”å­¦ä¹ ï¼šä½¿ç”¨å¯¹æ¯”æŸå¤±å‡½æ•°ï¼Œä¾‹å¦‚ç›‘ç£å¯¹æ¯”æŸå¤±æˆ–è‡ªç›‘ç£å¯¹æ¯”æŸå¤±ï¼Œæ¥å­¦ä¹ å…·æœ‰åŒºåˆ†æ€§çš„3Då½¢çŠ¶è¡¨ç¤ºï¼›4) åˆ†ç±»å™¨ï¼šä½¿ç”¨å­¦ä¹ åˆ°çš„3Då½¢çŠ¶è¡¨ç¤ºè¿›è¡Œåˆ†ç±»æˆ–å…¶ä»–ä¸‹æ¸¸ä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†ViTå’Œå¯¹æ¯”å­¦ä¹ ç›¸ç»“åˆï¼Œç”¨äº3Då½¢çŠ¶ç‰¹å¾è¡¨ç¤ºå­¦ä¹ ã€‚ä¸ä¼ ç»Ÿçš„CNNæ–¹æ³•ç›¸æ¯”ï¼ŒViTèƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰å…¨å±€å½¢çŠ¶è¯­ä¹‰ï¼Œè€Œå¯¹æ¯”å­¦ä¹ èƒ½å¤Ÿæœ‰æ•ˆåœ°å­¦ä¹ å…·æœ‰åŒºåˆ†æ€§çš„å±€éƒ¨ç‰¹å¾ã€‚è¿™ç§ç»“åˆå…‹æœäº†CNNçš„å±€é™æ€§ï¼Œå¹¶å‡å°‘äº†å¯¹å¤§é‡æ ‡æ³¨æ•°æ®çš„ä¾èµ–ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä½¿ç”¨äº†Vision Transformer (ViT)ä½œä¸ºéª¨å¹²ç½‘ç»œï¼Œå¹¶é‡‡ç”¨äº†ç›‘ç£å¯¹æ¯”æŸå¤±å’Œè‡ªç›‘ç£å¯¹æ¯”æŸå¤±ã€‚ç›‘ç£å¯¹æ¯”æŸå¤±åˆ©ç”¨æ ‡æ³¨ä¿¡æ¯æ¥åŒºåˆ†ä¸åŒç±»åˆ«çš„3Då½¢çŠ¶ï¼Œè€Œè‡ªç›‘ç£å¯¹æ¯”æŸå¤±åˆ™é€šè¿‡æœ€å¤§åŒ–åŒä¸€3Då½¢çŠ¶ä¸åŒè§†è§’å›¾åƒç‰¹å¾ä¹‹é—´çš„ä¸€è‡´æ€§æ¥å­¦ä¹ è¡¨ç¤ºã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’Œå‚æ•°è®¾ç½®æ ¹æ®ä¸åŒçš„å®éªŒè¿›è¡Œäº†è°ƒæ•´ï¼Œä»¥è¾¾åˆ°æœ€ä½³æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºViTå’Œå¯¹æ¯”å­¦ä¹ çš„æ–¹æ³•åœ¨ModelNet10æ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œç›‘ç£å¯¹æ¯”æŸå¤±è¾¾åˆ°äº†çº¦90.6%çš„å‡†ç¡®ç‡ã€‚è¯¥æ–¹æ³•ä¼˜äºä¼ ç»Ÿçš„åŸºäºCNNçš„æ–¹æ³•ï¼Œå¹¶ä¸”åœ¨æ•°æ®é‡è¾ƒå°‘çš„æƒ…å†µä¸‹ä¹Ÿèƒ½å–å¾—è‰¯å¥½çš„æ•ˆæœï¼ŒéªŒè¯äº†ViTå’Œå¯¹æ¯”å­¦ä¹ åœ¨3Då½¢çŠ¶è¡¨ç¤ºå­¦ä¹ ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæœºå™¨äººè§†è§‰ã€è‡ªåŠ¨é©¾é©¶ã€ä¸‰ç»´é‡å»ºã€CADæ¨¡å‹æ£€ç´¢ç­‰é¢†åŸŸã€‚é€šè¿‡æå‡3Då½¢çŠ¶è¯†åˆ«çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ï¼Œå¯ä»¥æé«˜æœºå™¨äººå¯¹ç¯å¢ƒçš„æ„ŸçŸ¥èƒ½åŠ›ï¼Œå¢å¼ºè‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„å®‰å…¨æ€§ï¼Œå¹¶æ”¹å–„ä¸‰ç»´æ¨¡å‹çš„æ£€ç´¢æ•ˆç‡ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›åœ¨è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ç­‰é¢†åŸŸå‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper addresses the challenges in representation learning of 3D shape features by investigating state-of-the-art backbones paired with both contrastive supervised and self-supervised learning objectives. Computer vision methods struggle with recognizing 3D objects from 2D images, often requiring extensive labeled data and relying on Convolutional Neural Networks (CNNs) that may overlook crucial shape relationships. Our work demonstrates that Vision Transformers (ViTs) based architectures, when paired with modern contrastive objectives, achieve promising results in multi-view 3D analysis on our downstream tasks, unifying contrastive and 3D shape understanding pipelines. For example, supervised contrastive losses reached about 90.6% accuracy on ModelNet10. The use of ViTs and contrastive learning, leveraging ViTs' ability to understand overall shapes and contrastive learning's effectiveness, overcomes the need for extensive labeled data and the limitations of CNNs in capturing crucial shape relationships. The success stems from capturing global shape semantics via ViTs and refining local discriminative features through contrastive optimization. Importantly, our approach is empirical, as it is grounded on extensive experimental evaluation to validate the effectiveness of combining ViTs with contrastive objectives for 3D representation learning.

