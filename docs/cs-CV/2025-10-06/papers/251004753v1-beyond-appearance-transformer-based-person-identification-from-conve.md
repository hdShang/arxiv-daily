---
layout: default
title: Beyond Appearance: Transformer-based Person Identification from Conversational Dynamics
---

# Beyond Appearance: Transformer-based Person Identification from Conversational Dynamics

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.04753" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.04753v1</a>
  <a href="https://arxiv.org/pdf/2510.04753.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.04753v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.04753v1', 'Beyond Appearance: Transformer-based Person Identification from Conversational Dynamics')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Masoumeh Chapariniya, Teodora Vukovic, Sarah Ebling, Volker Dellwo

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-06

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºTransformerçš„å¯¹è¯åŠ¨æ€äººä½“è¯†åˆ«æ–¹æ³•ï¼Œæå‡è‡ªç„¶äº¤äº’åœºæ™¯ä¸‹èº«ä»½è¯†åˆ«ç²¾åº¦ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `äººä½“è¯†åˆ«` `Transformer` `åŒæµç½‘ç»œ` `æ—¶é—´å»ºæ¨¡` `ç©ºé—´å»ºæ¨¡` `å¤šå°ºåº¦åˆ†æ` `è‡ªç„¶äº¤äº’`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨è‡ªç„¶å¯¹è¯åœºæ™¯ä¸‹çš„äººä½“è¯†åˆ«ç²¾åº¦ä¸è¶³ï¼Œéš¾ä»¥æœ‰æ•ˆæ•æ‰å¤æ‚çš„äººä½“å§¿æ€å’ŒåŠ¨æ€ä¿¡æ¯ã€‚
2. æå‡ºåŒæµTransformeræ¡†æ¶ï¼Œåˆ†åˆ«å»ºæ¨¡äººä½“å…³é”®ç‚¹çš„ç©ºé—´é…ç½®å’Œæ—¶é—´è¿åŠ¨æ¨¡å¼ï¼Œå¹¶é‡‡ç”¨å¤šå°ºåº¦æ—¶é—´Transformerè¿›è¡Œåˆ†å±‚è¿åŠ¨å»ºæ¨¡ã€‚
3. å®éªŒè¡¨æ˜ï¼Œé¢†åŸŸç‰¹å®šè®­ç»ƒä¼˜äºè¿ç§»å­¦ä¹ ï¼Œç©ºé—´ä¿¡æ¯æ›´å…·åˆ¤åˆ«æ€§ï¼Œç‰¹å¾èåˆåå‡†ç¡®ç‡è¾¾åˆ°98.03%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ç ”ç©¶äº†åŸºäºTransformeræ¶æ„çš„äººä½“è¯†åˆ«åœ¨è‡ªç„¶ã€é¢å¯¹é¢ä¼šè¯åœºæ™¯ä¸­çš„æ€§èƒ½ã€‚æˆ‘ä»¬å®ç°å¹¶è¯„ä¼°äº†ä¸€ä¸ªåŒæµæ¡†æ¶ï¼Œè¯¥æ¡†æ¶åˆ†åˆ«å»ºæ¨¡ä»CANDORä¼šè¯è¯­æ–™åº“å­é›†ä¸­æå–çš„133ä¸ªCOCO WholeBodyå…³é”®ç‚¹çš„ç©ºé—´é…ç½®å’Œæ—¶é—´è¿åŠ¨æ¨¡å¼ã€‚æˆ‘ä»¬çš„å®éªŒæ¯”è¾ƒäº†é¢„è®­ç»ƒå’Œä»å¤´å¼€å§‹çš„è®­ç»ƒï¼Œç ”ç©¶äº†é€Ÿåº¦ç‰¹å¾çš„ä½¿ç”¨ï¼Œå¹¶å¼•å…¥äº†ç”¨äºåˆ†å±‚è¿åŠ¨å»ºæ¨¡çš„å¤šå°ºåº¦æ—¶é—´Transformerã€‚ç»“æœè¡¨æ˜ï¼Œç‰¹å®šé¢†åŸŸçš„è®­ç»ƒæ˜æ˜¾ä¼˜äºè¿ç§»å­¦ä¹ ï¼Œå¹¶ä¸”ç©ºé—´é…ç½®æ¯”æ—¶é—´åŠ¨æ€æºå¸¦æ›´å¤šçš„åˆ¤åˆ«ä¿¡æ¯ã€‚ç©ºé—´Transformerå®ç°äº†95.74%çš„å‡†ç¡®ç‡ï¼Œè€Œå¤šå°ºåº¦æ—¶é—´Transformerå®ç°äº†93.90%çš„å‡†ç¡®ç‡ã€‚ç‰¹å¾çº§èåˆå°†æ€§èƒ½æå‡è‡³98.03%ï¼Œè¯å®äº†å§¿åŠ¿å’ŒåŠ¨æ€ä¿¡æ¯çš„äº’è¡¥æ€§ã€‚è¿™äº›å‘ç°çªå‡ºäº†Transformeræ¶æ„åœ¨è‡ªç„¶äº¤äº’ä¸­è¿›è¡Œäººä½“è¯†åˆ«çš„æ½œåŠ›ï¼Œå¹¶ä¸ºæœªæ¥çš„å¤šæ¨¡æ€å’Œè·¨æ–‡åŒ–ç ”ç©¶æä¾›äº†è§è§£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è‡ªç„¶ã€é¢å¯¹é¢ä¼šè¯åœºæ™¯ä¸‹çš„äººä½“èº«ä»½è¯†åˆ«é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆæ•æ‰äººä½“åœ¨è‡ªç„¶äº¤äº’ä¸­çš„å¤æ‚å§¿æ€å˜åŒ–å’ŒåŠ¨æ€ä¿¡æ¯ï¼Œå¯¼è‡´è¯†åˆ«ç²¾åº¦ä¸é«˜ã€‚ç‰¹åˆ«æ˜¯åœ¨é®æŒ¡ã€å…‰ç…§å˜åŒ–ç­‰å¤æ‚ç¯å¢ƒä¸‹ï¼Œä¼ ç»Ÿæ–¹æ³•çš„é²æ£’æ€§è¾ƒå·®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨Transformeræ¶æ„å¼ºå¤§çš„å»ºæ¨¡èƒ½åŠ›ï¼Œåˆ†åˆ«å¯¹äººä½“å…³é”®ç‚¹çš„ç©ºé—´é…ç½®å’Œæ—¶é—´è¿åŠ¨æ¨¡å¼è¿›è¡Œå»ºæ¨¡ã€‚é€šè¿‡åŒæµç»“æ„ï¼Œåˆ†åˆ«æå–é™æ€å§¿æ€ç‰¹å¾å’ŒåŠ¨æ€è¿åŠ¨ç‰¹å¾ï¼Œå¹¶è¿›è¡Œèåˆï¼Œä»è€Œæ›´å…¨é¢åœ°æ•æ‰äººä½“èº«ä»½ä¿¡æ¯ã€‚åŒæ—¶ï¼Œé‡‡ç”¨å¤šå°ºåº¦æ—¶é—´Transformerï¼Œå¯¹ä¸åŒæ—¶é—´å°ºåº¦çš„è¿åŠ¨ä¿¡æ¯è¿›è¡Œåˆ†å±‚å»ºæ¨¡ï¼Œæå‡å¯¹å¤æ‚è¿åŠ¨æ¨¡å¼çš„è¯†åˆ«èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) äººä½“å…³é”®ç‚¹æå–ï¼šä½¿ç”¨COCO WholeBodyæ¨¡å‹æå–133ä¸ªäººä½“å…³é”®ç‚¹ã€‚2) åŒæµTransformerå»ºæ¨¡ï¼šåˆ†åˆ«ä½¿ç”¨ç©ºé—´Transformerå’Œæ—¶é—´Transformerå¯¹ç©ºé—´é…ç½®å’Œæ—¶é—´è¿åŠ¨æ¨¡å¼è¿›è¡Œå»ºæ¨¡ã€‚3) å¤šå°ºåº¦æ—¶é—´Transformerï¼šå¯¹æ—¶é—´è¿åŠ¨æ¨¡å¼è¿›è¡Œåˆ†å±‚å»ºæ¨¡ï¼Œæ•æ‰ä¸åŒæ—¶é—´å°ºåº¦çš„è¿åŠ¨ä¿¡æ¯ã€‚4) ç‰¹å¾èåˆï¼šå°†ç©ºé—´å’Œæ—¶é—´Transformeræå–çš„ç‰¹å¾è¿›è¡Œèåˆã€‚5) åˆ†ç±»å™¨ï¼šä½¿ç”¨åˆ†ç±»å™¨è¿›è¡Œäººä½“èº«ä»½è¯†åˆ«ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°ç‚¹åœ¨äºï¼š1) æå‡ºäº†ä¸€ç§åŒæµTransformeræ¡†æ¶ï¼Œåˆ†åˆ«å»ºæ¨¡äººä½“å…³é”®ç‚¹çš„ç©ºé—´é…ç½®å’Œæ—¶é—´è¿åŠ¨æ¨¡å¼ã€‚2) å¼•å…¥äº†å¤šå°ºåº¦æ—¶é—´Transformerï¼Œç”¨äºåˆ†å±‚å»ºæ¨¡æ—¶é—´è¿åŠ¨æ¨¡å¼ï¼Œæå‡å¯¹å¤æ‚è¿åŠ¨æ¨¡å¼çš„è¯†åˆ«èƒ½åŠ›ã€‚3) å®éªŒç»“æœè¡¨æ˜ï¼Œé¢†åŸŸç‰¹å®šè®­ç»ƒä¼˜äºè¿ç§»å­¦ä¹ ï¼Œè¿™ä¸ºåç»­ç ”ç©¶æä¾›äº†é‡è¦çš„æŒ‡å¯¼ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç©ºé—´Transformerä¸­ï¼Œä½¿ç”¨æ ‡å‡†Transformerç¼–ç å™¨å¯¹ç©ºé—´å…³é”®ç‚¹è¿›è¡Œå»ºæ¨¡ã€‚åœ¨æ—¶é—´Transformerä¸­ï¼Œä½¿ç”¨å¤šå°ºåº¦ç»“æ„ï¼Œåˆ†åˆ«å¯¹ä¸åŒæ—¶é—´çª—å£å†…çš„è¿åŠ¨ä¿¡æ¯è¿›è¡Œå»ºæ¨¡ã€‚é€Ÿåº¦ç‰¹å¾é€šè¿‡è®¡ç®—ç›¸é‚»å¸§å…³é”®ç‚¹åæ ‡çš„å·®å€¼å¾—åˆ°ã€‚æŸå¤±å‡½æ•°é‡‡ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°ã€‚ç½‘ç»œç»“æ„å‚æ•°ï¼ˆå¦‚Transformerå±‚æ•°ã€éšè—å±‚ç»´åº¦ç­‰ï¼‰é€šè¿‡å®éªŒè¿›è¡Œè°ƒæ•´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºç©ºé—´Transformerçš„æ¨¡å‹è¾¾åˆ°äº†95.74%çš„å‡†ç¡®ç‡ï¼ŒåŸºäºå¤šå°ºåº¦æ—¶é—´Transformerçš„æ¨¡å‹è¾¾åˆ°äº†93.90%çš„å‡†ç¡®ç‡ã€‚é€šè¿‡ç‰¹å¾çº§èåˆï¼Œæ•´ä½“å‡†ç¡®ç‡æå‡è‡³98.03%ï¼Œæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚æ­¤å¤–ï¼Œå®éªŒè¿˜å‘ç°ï¼Œé¢†åŸŸç‰¹å®šè®­ç»ƒæ˜æ˜¾ä¼˜äºè¿ç§»å­¦ä¹ ï¼Œè¿™ä¸ºåç»­ç ”ç©¶æä¾›äº†é‡è¦çš„æŒ‡å¯¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ™ºèƒ½ç›‘æ§ã€äººæœºäº¤äº’ã€è™šæ‹Ÿç°å®ã€ç¤¾äº¤æœºå™¨äººç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨æ™ºèƒ½ç›‘æ§ä¸­ï¼Œå¯ä»¥åˆ©ç”¨è¯¥æ–¹æ³•è¿›è¡Œäººç¾¤èº«ä»½è¯†åˆ«å’Œè¡Œä¸ºåˆ†æï¼›åœ¨äººæœºäº¤äº’ä¸­ï¼Œå¯ä»¥å®ç°æ›´è‡ªç„¶ã€æ›´æ™ºèƒ½çš„äººæœºå¯¹è¯ï¼›åœ¨è™šæ‹Ÿç°å®ä¸­ï¼Œå¯ä»¥æå‡è™šæ‹Ÿè§’è‰²çš„çœŸå®æ„Ÿå’Œäº¤äº’æ€§ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥æ‰©å±•åˆ°è·¨æ–‡åŒ–ç ”ç©¶ï¼Œåˆ†æä¸åŒæ–‡åŒ–èƒŒæ™¯ä¸‹çš„äººä½“å§¿æ€å’Œè¿åŠ¨æ¨¡å¼çš„å·®å¼‚ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper investigates the performance of transformer-based architectures for person identification in natural, face-to-face conversation scenario. We implement and evaluate a two-stream framework that separately models spatial configurations and temporal motion patterns of 133 COCO WholeBody keypoints, extracted from a subset of the CANDOR conversational corpus. Our experiments compare pre-trained and from-scratch training, investigate the use of velocity features, and introduce a multi-scale temporal transformer for hierarchical motion modeling. Results demonstrate that domain-specific training significantly outperforms transfer learning, and that spatial configurations carry more discriminative information than temporal dynamics. The spatial transformer achieves 95.74% accuracy, while the multi-scale temporal transformer achieves 93.90%. Feature-level fusion pushes performance to 98.03%, confirming that postural and dynamic information are complementary. These findings highlight the potential of transformer architectures for person identification in natural interactions and provide insights for future multimodal and cross-cultural studies.

