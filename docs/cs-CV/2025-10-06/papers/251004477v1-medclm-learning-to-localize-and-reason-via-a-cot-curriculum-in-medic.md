---
layout: default
title: MedCLM: Learning to Localize and Reason via a CoT-Curriculum in Medical Vision-Language Models
---

# MedCLM: Learning to Localize and Reason via a CoT-Curriculum in Medical Vision-Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.04477" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.04477v1</a>
  <a href="https://arxiv.org/pdf/2510.04477.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.04477v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.04477v1', 'MedCLM: Learning to Localize and Reason via a CoT-Curriculum in Medical Vision-Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Soo Yong Kim, Suin Cho, Vincent-Daniel Yun, Gyeongyeon Hwang

**åˆ†ç±»**: cs.CV, cs.AI, cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-10-06

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**MedCLMï¼šé€šè¿‡CoTè¯¾ç¨‹å­¦ä¹ åŒ»å­¦è§†è§‰è¯­è¨€æ¨¡å‹ä¸­çš„å®šä½å’Œæ¨ç†**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åŒ»å­¦è§†è§‰é—®ç­”` `æ€ç»´é“¾` `è¯¾ç¨‹å­¦ä¹ ` `åŒ»å­¦å½±åƒ` `è§†è§‰è¯­è¨€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. åŒ»å­¦å½±åƒè¯Šæ–­æ¨ç†é¢ä¸´AIç»“åˆçš„æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•ç¼ºä¹æœ‰æ•ˆçš„æ¨ç†èƒ½åŠ›ã€‚
2. MedCLMé€šè¿‡CoTè¯¾ç¨‹å­¦ä¹ ï¼Œå°†æ£€æµ‹æ•°æ®é›†è½¬åŒ–ä¸ºVQAæ•°æ®ï¼Œæå‡æ¨¡å‹æ¨ç†èƒ½åŠ›ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒMedCLMåœ¨åŒ»å­¦VQAåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°SOTAï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°†ä¸´åºŠè¯Šæ–­æ¨ç†ä¸AIç›¸ç»“åˆä»ç„¶æ˜¯åŒ»å­¦å½±åƒé¢†åŸŸçš„æ ¸å¿ƒæŒ‘æˆ˜ã€‚æˆ‘ä»¬æå‡ºäº†MedCLMï¼Œä¸€ä¸ªè‡ªåŠ¨åŒ–çš„æµç¨‹ï¼Œé€šè¿‡å°†ç—…ç¶æ¡†ä¸å™¨å®˜åˆ†å‰²å’Œç»“æ„åŒ–åŸç†ç›¸å…³è”ï¼Œå°†æ£€æµ‹æ•°æ®é›†è½¬æ¢ä¸ºå¤§è§„æ¨¡çš„åŒ»å­¦è§†è§‰é—®ç­”ï¼ˆVQAï¼‰æ•°æ®ï¼Œå¹¶å¸¦æœ‰æ€ç»´é“¾ï¼ˆCoTï¼‰æ¨ç†ã€‚è¿™äº›ä¸Šä¸‹æ–‡ä¿¡å·ä½¿åŒ»å­¦è§†è§‰è¯­è¨€æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆå¸¦æœ‰é€æ­¥æ¨ç†çš„é—®ç­”å¯¹ã€‚ä¸ºäº†æœ‰æ•ˆåœ°åˆ©ç”¨è¿™äº›æ•°æ®ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é›†æˆçš„CoTè¯¾ç¨‹ç­–ç•¥ï¼Œè¯¥ç­–ç•¥ç”±ä¸€ä¸ªå¸¦æœ‰æ˜¾å¼ç—…ç¶æ¡†çš„ç®€å•é˜¶æ®µï¼ˆç”¨äºè§†è§‰å®šä½ï¼‰ã€ä¸€ä¸ªé¼“åŠ±éšå¼å®šä½çš„ä¸­ç­‰é˜¶æ®µå’Œä¸€ä¸ªç”¨äºå¼±ç›‘ç£æ¨ç†çš„å›°éš¾é˜¶æ®µç»„æˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMedCLMåœ¨å¤šä¸ªåŒ»å­¦VQAåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œä¸ºå¼€å‘ä¸´åºŠå¯¹é½çš„åŒ»å­¦è§†è§‰è¯­è¨€æ¨¡å‹æä¾›äº†ä¸€ä¸ªå¯æ‰©å±•çš„æ¡†æ¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šåŒ»å­¦è§†è§‰é—®ç­”ï¼ˆVQAï¼‰æ—¨åœ¨è®©AIç³»ç»Ÿèƒ½å¤Ÿç†è§£åŒ»å­¦å›¾åƒå¹¶å›ç­”ç›¸å…³é—®é¢˜ã€‚ç°æœ‰çš„åŒ»å­¦VQAæ–¹æ³•é€šå¸¸ç¼ºä¹æœ‰æ•ˆçš„æ¨ç†èƒ½åŠ›ï¼Œéš¾ä»¥æ¨¡æ‹Ÿä¸´åºŠåŒ»ç”Ÿçš„è¯Šæ–­è¿‡ç¨‹ã€‚æ­¤å¤–ï¼Œæ„å»ºå¤§è§„æ¨¡ã€é«˜è´¨é‡çš„åŒ»å­¦VQAæ•°æ®é›†ä¹Ÿé¢ä¸´æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åŒ…å«è¯¦ç»†æ¨ç†æ­¥éª¤çš„æ•°æ®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMedCLMçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨ç°æœ‰çš„åŒ»å­¦å›¾åƒæ£€æµ‹æ•°æ®é›†ï¼Œé€šè¿‡è‡ªåŠ¨åŒ–çš„æµç¨‹ç”Ÿæˆå¸¦æœ‰æ€ç»´é“¾ï¼ˆCoTï¼‰æ¨ç†çš„VQAæ•°æ®ã€‚é€šè¿‡å°†ç—…ç¶æ¡†ä¸å™¨å®˜åˆ†å‰²å’Œç»“æ„åŒ–åŸç†ç›¸å…³è”ï¼Œæ¨¡å‹å¯ä»¥å­¦ä¹ é€æ­¥æ¨ç†ï¼Œä»è€Œæ›´å¥½åœ°ç†è§£åŒ»å­¦å›¾åƒå¹¶å›ç­”é—®é¢˜ã€‚åŒæ—¶ï¼Œé‡‡ç”¨CoTè¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼Œé€æ­¥æå‡æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMedCLMåŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) æ•°æ®ç”Ÿæˆæ¨¡å—ï¼šå°†æ£€æµ‹æ•°æ®é›†è½¬æ¢ä¸ºVQAæ•°æ®ï¼ŒåŒ…æ‹¬é—®é¢˜ç”Ÿæˆã€ç­”æ¡ˆç”Ÿæˆå’Œæ¨ç†æ­¥éª¤ç”Ÿæˆã€‚2) CoTè¯¾ç¨‹å­¦ä¹ æ¨¡å—ï¼šåŒ…å«ç®€å•ã€ä¸­ç­‰å’Œå›°éš¾ä¸‰ä¸ªé˜¶æ®µï¼Œåˆ†åˆ«å¯¹åº”æ˜¾å¼å®šä½ã€éšå¼å®šä½å’Œå¼±ç›‘ç£æ¨ç†ã€‚3) åŒ»å­¦è§†è§‰è¯­è¨€æ¨¡å‹ï¼šç”¨äºå­¦ä¹ VQAæ•°æ®å¹¶è¿›è¡Œæ¨ç†ã€‚

**å…³é”®åˆ›æ–°**ï¼šMedCLMçš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) è‡ªåŠ¨åŒ–VQAæ•°æ®ç”Ÿæˆæµç¨‹ï¼Œå¯ä»¥é«˜æ•ˆåœ°æ„å»ºå¤§è§„æ¨¡çš„åŒ»å­¦VQAæ•°æ®é›†ã€‚2) é›†æˆçš„CoTè¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼Œå¯ä»¥é€æ­¥æå‡æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚3) å°†ç—…ç¶æ¡†ä¸å™¨å®˜åˆ†å‰²å’Œç»“æ„åŒ–åŸç†ç›¸å…³è”ï¼Œä¸ºæ¨¡å‹æä¾›æ›´ä¸°å¯Œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®ç”Ÿæˆæ¨¡å—ä¸­ï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„å™¨å®˜åˆ†å‰²æ¨¡å‹å’ŒåŒ»å­¦çŸ¥è¯†åº“æ¥ç”Ÿæˆæ¨ç†æ­¥éª¤ã€‚åœ¨CoTè¯¾ç¨‹å­¦ä¹ æ¨¡å—ä¸­ï¼Œç®€å•é˜¶æ®µä½¿ç”¨æ˜¾å¼çš„ç—…ç¶æ¡†ä½œä¸ºè§†è§‰æç¤ºï¼Œä¸­ç­‰é˜¶æ®µç§»é™¤ç—…ç¶æ¡†ï¼Œé¼“åŠ±æ¨¡å‹è¿›è¡Œéšå¼å®šä½ï¼Œå›°éš¾é˜¶æ®µåˆ™åªæä¾›å›¾åƒå’Œé—®é¢˜ï¼Œè¿›è¡Œå¼±ç›‘ç£æ¨ç†ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ï¼ˆæœªçŸ¥ï¼‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

MedCLMåœ¨å¤šä¸ªåŒ»å­¦VQAåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚å…·ä½“æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ï¼ˆæœªçŸ¥ï¼‰ï¼Œä½†æ‘˜è¦ä¸­æ˜ç¡®æŒ‡å‡ºå…¶è¾¾åˆ°äº†SOTAæ°´å¹³ï¼Œè¡¨æ˜å…¶åœ¨åŒ»å­¦VQAä»»åŠ¡ä¸Šå…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MedCLMå¯åº”ç”¨äºè¾…åŠ©åŒ»å­¦è¯Šæ–­ã€åŒ»å­¦æ•™è‚²å’Œè¿œç¨‹åŒ»ç–—ç­‰é¢†åŸŸã€‚å®ƒå¯ä»¥å¸®åŠ©åŒ»ç”Ÿæ›´å‡†ç¡®åœ°è¯Šæ–­ç–¾ç—…ï¼Œä¸ºåŒ»å­¦ç”Ÿæä¾›æ›´æœ‰æ•ˆçš„å­¦ä¹ å·¥å…·ï¼Œå¹¶ä¸ºåè¿œåœ°åŒºçš„æ‚£è€…æä¾›é«˜è´¨é‡çš„åŒ»ç–—æœåŠ¡ã€‚è¯¥ç ”ç©¶ä¸ºå¼€å‘æ›´æ™ºèƒ½ã€æ›´å¯é çš„åŒ»å­¦AIç³»ç»Ÿå¥ å®šäº†åŸºç¡€ï¼Œæœ‰æœ›åœ¨æœªæ¥æ”¹å˜åŒ»ç–—ä¿å¥è¡Œä¸šã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Bridging clinical diagnostic reasoning with AI remains a central challenge in medical imaging. We introduce MedCLM, an automated pipeline that converts detection datasets into large-scale medical visual question answering (VQA) data with Chain-of-Thought (CoT) reasoning by linking lesion boxes to organ segmentation and structured rationales. These contextual signals enable medical vision-language models to generate question-answer pairs with step-by-step reasoning. To utilize this data effectively, we propose an Integrated CoT-Curriculum Strategy composed of an Easy stage with explicit lesion boxes for visual grounding, a Medium stage that encourages implicit localization, and a Hard stage for weakly supervised reasoning. Experimental results demonstrate that MedCLM attains state-of-the-art performance on several medical VQA benchmarks, providing a scalable framework for developing clinically aligned medical vision-language models.

