---
layout: default
title: MedCLM: Learning to Localize and Reason via a CoT-Curriculum in Medical Vision-Language Models
---

# MedCLM: Learning to Localize and Reason via a CoT-Curriculum in Medical Vision-Language Models

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.04477" target="_blank" class="toolbar-btn">arXiv: 2510.04477v1</a>
    <a href="https://arxiv.org/pdf/2510.04477.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.04477v1" 
            onclick="toggleFavorite(this, '2510.04477v1', 'MedCLM: Learning to Localize and Reason via a CoT-Curriculum in Medical Vision-Language Models')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Soo Yong Kim, Suin Cho, Vincent-Daniel Yun, Gyeongyeon Hwang

**ÂàÜÁ±ª**: cs.CV, cs.AI, cs.CL, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-06

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**MedCLMÔºöÈÄöËøáCoTËØæÁ®ãÂ≠¶‰π†ÂåªÂ≠¶ËßÜËßâËØ≠Ë®ÄÊ®°Âûã‰∏≠ÁöÑÂÆö‰ΩçÂíåÊé®ÁêÜ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÂåªÂ≠¶ËßÜËßâÈóÆÁ≠î` `ÊÄùÁª¥Èìæ` `ËØæÁ®ãÂ≠¶‰π†` `ÂåªÂ≠¶ÂΩ±ÂÉè` `ËßÜËßâËØ≠Ë®ÄÊ®°Âûã`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ÂåªÂ≠¶ÂΩ±ÂÉèËØäÊñ≠Êé®ÁêÜÈù¢‰∏¥AIÁªìÂêàÁöÑÊåëÊàòÔºåÁé∞ÊúâÊñπÊ≥ïÁº∫‰πèÊúâÊïàÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇ
2. MedCLMÈÄöËøáCoTËØæÁ®ãÂ≠¶‰π†ÔºåÂ∞ÜÊ£ÄÊµãÊï∞ÊçÆÈõÜËΩ¨Âåñ‰∏∫VQAÊï∞ÊçÆÔºåÊèêÂçáÊ®°ÂûãÊé®ÁêÜËÉΩÂäõ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåMedCLMÂú®ÂåªÂ≠¶VQAÂü∫ÂáÜÊµãËØï‰∏≠ËææÂà∞SOTAÔºåÈ™åËØÅ‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â∞Ü‰∏¥Â∫äËØäÊñ≠Êé®ÁêÜ‰∏éAIÁõ∏ÁªìÂêà‰ªçÁÑ∂ÊòØÂåªÂ≠¶ÂΩ±ÂÉèÈ¢ÜÂüüÁöÑÊ†∏ÂøÉÊåëÊàò„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫ÜMedCLMÔºå‰∏Ä‰∏™Ëá™Âä®ÂåñÁöÑÊµÅÁ®ãÔºåÈÄöËøáÂ∞ÜÁóÖÁÅ∂Ê°Ü‰∏éÂô®ÂÆòÂàÜÂâ≤ÂíåÁªìÊûÑÂåñÂéüÁêÜÁõ∏ÂÖ≥ËÅîÔºåÂ∞ÜÊ£ÄÊµãÊï∞ÊçÆÈõÜËΩ¨Êç¢‰∏∫Â§ßËßÑÊ®°ÁöÑÂåªÂ≠¶ËßÜËßâÈóÆÁ≠îÔºàVQAÔºâÊï∞ÊçÆÔºåÂπ∂Â∏¶ÊúâÊÄùÁª¥ÈìæÔºàCoTÔºâÊé®ÁêÜ„ÄÇËøô‰∫õ‰∏ä‰∏ãÊñá‰ø°Âè∑‰ΩøÂåªÂ≠¶ËßÜËßâËØ≠Ë®ÄÊ®°ÂûãËÉΩÂ§üÁîüÊàêÂ∏¶ÊúâÈÄêÊ≠•Êé®ÁêÜÁöÑÈóÆÁ≠îÂØπ„ÄÇ‰∏∫‰∫ÜÊúâÊïàÂú∞Âà©Áî®Ëøô‰∫õÊï∞ÊçÆÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÈõÜÊàêÁöÑCoTËØæÁ®ãÁ≠ñÁï•ÔºåËØ•Á≠ñÁï•Áî±‰∏Ä‰∏™Â∏¶ÊúâÊòæÂºèÁóÖÁÅ∂Ê°ÜÁöÑÁÆÄÂçïÈò∂ÊÆµÔºàÁî®‰∫éËßÜËßâÂÆö‰ΩçÔºâ„ÄÅ‰∏Ä‰∏™ÈºìÂä±ÈöêÂºèÂÆö‰ΩçÁöÑ‰∏≠Á≠âÈò∂ÊÆµÂíå‰∏Ä‰∏™Áî®‰∫éÂº±ÁõëÁù£Êé®ÁêÜÁöÑÂõ∞ÈöæÈò∂ÊÆµÁªÑÊàê„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåMedCLMÂú®Â§ö‰∏™ÂåªÂ≠¶VQAÂü∫ÂáÜÊµãËØï‰∏≠ÂèñÂæó‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºå‰∏∫ÂºÄÂèë‰∏¥Â∫äÂØπÈΩêÁöÑÂåªÂ≠¶ËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÊèê‰æõ‰∫Ü‰∏Ä‰∏™ÂèØÊâ©Â±ïÁöÑÊ°ÜÊû∂„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÂåªÂ≠¶ËßÜËßâÈóÆÁ≠îÔºàVQAÔºâÊó®Âú®ËÆ©AIÁ≥ªÁªüËÉΩÂ§üÁêÜËß£ÂåªÂ≠¶ÂõæÂÉèÂπ∂ÂõûÁ≠îÁõ∏ÂÖ≥ÈóÆÈ¢ò„ÄÇÁé∞ÊúâÁöÑÂåªÂ≠¶VQAÊñπÊ≥ïÈÄöÂ∏∏Áº∫‰πèÊúâÊïàÁöÑÊé®ÁêÜËÉΩÂäõÔºåÈöæ‰ª•Ê®°Êãü‰∏¥Â∫äÂåªÁîüÁöÑËØäÊñ≠ËøáÁ®ã„ÄÇÊ≠§Â§ñÔºåÊûÑÂª∫Â§ßËßÑÊ®°„ÄÅÈ´òË¥®ÈáèÁöÑÂåªÂ≠¶VQAÊï∞ÊçÆÈõÜ‰πüÈù¢‰∏¥ÊåëÊàòÔºåÂ∞§ÂÖ∂ÊòØÂåÖÂê´ËØ¶ÁªÜÊé®ÁêÜÊ≠•È™§ÁöÑÊï∞ÊçÆ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöMedCLMÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Áé∞ÊúâÁöÑÂåªÂ≠¶ÂõæÂÉèÊ£ÄÊµãÊï∞ÊçÆÈõÜÔºåÈÄöËøáËá™Âä®ÂåñÁöÑÊµÅÁ®ãÁîüÊàêÂ∏¶ÊúâÊÄùÁª¥ÈìæÔºàCoTÔºâÊé®ÁêÜÁöÑVQAÊï∞ÊçÆ„ÄÇÈÄöËøáÂ∞ÜÁóÖÁÅ∂Ê°Ü‰∏éÂô®ÂÆòÂàÜÂâ≤ÂíåÁªìÊûÑÂåñÂéüÁêÜÁõ∏ÂÖ≥ËÅîÔºåÊ®°ÂûãÂèØ‰ª•Â≠¶‰π†ÈÄêÊ≠•Êé®ÁêÜÔºå‰ªéËÄåÊõ¥Â•ΩÂú∞ÁêÜËß£ÂåªÂ≠¶ÂõæÂÉèÂπ∂ÂõûÁ≠îÈóÆÈ¢ò„ÄÇÂêåÊó∂ÔºåÈááÁî®CoTËØæÁ®ãÂ≠¶‰π†Á≠ñÁï•ÔºåÈÄêÊ≠•ÊèêÂçáÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöMedCLMÂåÖÂê´‰ª•‰∏ã‰∏ªË¶ÅÊ®°ÂùóÔºö1) Êï∞ÊçÆÁîüÊàêÊ®°ÂùóÔºöÂ∞ÜÊ£ÄÊµãÊï∞ÊçÆÈõÜËΩ¨Êç¢‰∏∫VQAÊï∞ÊçÆÔºåÂåÖÊã¨ÈóÆÈ¢òÁîüÊàê„ÄÅÁ≠îÊ°àÁîüÊàêÂíåÊé®ÁêÜÊ≠•È™§ÁîüÊàê„ÄÇ2) CoTËØæÁ®ãÂ≠¶‰π†Ê®°ÂùóÔºöÂåÖÂê´ÁÆÄÂçï„ÄÅ‰∏≠Á≠âÂíåÂõ∞Èöæ‰∏â‰∏™Èò∂ÊÆµÔºåÂàÜÂà´ÂØπÂ∫îÊòæÂºèÂÆö‰Ωç„ÄÅÈöêÂºèÂÆö‰ΩçÂíåÂº±ÁõëÁù£Êé®ÁêÜ„ÄÇ3) ÂåªÂ≠¶ËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÔºöÁî®‰∫éÂ≠¶‰π†VQAÊï∞ÊçÆÂπ∂ËøõË°åÊé®ÁêÜ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöMedCLMÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1) Ëá™Âä®ÂåñVQAÊï∞ÊçÆÁîüÊàêÊµÅÁ®ãÔºåÂèØ‰ª•È´òÊïàÂú∞ÊûÑÂª∫Â§ßËßÑÊ®°ÁöÑÂåªÂ≠¶VQAÊï∞ÊçÆÈõÜ„ÄÇ2) ÈõÜÊàêÁöÑCoTËØæÁ®ãÂ≠¶‰π†Á≠ñÁï•ÔºåÂèØ‰ª•ÈÄêÊ≠•ÊèêÂçáÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇ3) Â∞ÜÁóÖÁÅ∂Ê°Ü‰∏éÂô®ÂÆòÂàÜÂâ≤ÂíåÁªìÊûÑÂåñÂéüÁêÜÁõ∏ÂÖ≥ËÅîÔºå‰∏∫Ê®°ÂûãÊèê‰æõÊõ¥‰∏∞ÂØåÁöÑ‰∏ä‰∏ãÊñá‰ø°ÊÅØ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Êï∞ÊçÆÁîüÊàêÊ®°Âùó‰∏≠ÔºåÂà©Áî®È¢ÑËÆ≠ÁªÉÁöÑÂô®ÂÆòÂàÜÂâ≤Ê®°ÂûãÂíåÂåªÂ≠¶Áü•ËØÜÂ∫ìÊù•ÁîüÊàêÊé®ÁêÜÊ≠•È™§„ÄÇÂú®CoTËØæÁ®ãÂ≠¶‰π†Ê®°Âùó‰∏≠ÔºåÁÆÄÂçïÈò∂ÊÆµ‰ΩøÁî®ÊòæÂºèÁöÑÁóÖÁÅ∂Ê°Ü‰Ωú‰∏∫ËßÜËßâÊèêÁ§∫Ôºå‰∏≠Á≠âÈò∂ÊÆµÁßªÈô§ÁóÖÁÅ∂Ê°ÜÔºåÈºìÂä±Ê®°ÂûãËøõË°åÈöêÂºèÂÆö‰ΩçÔºåÂõ∞ÈöæÈò∂ÊÆµÂàôÂè™Êèê‰æõÂõæÂÉèÂíåÈóÆÈ¢òÔºåËøõË°åÂº±ÁõëÁù£Êé®ÁêÜ„ÄÇÂÖ∑‰ΩìÁöÑÊçüÂ§±ÂáΩÊï∞ÂíåÁΩëÁªúÁªìÊûÑÁªÜËäÇÂú®ËÆ∫Êñá‰∏≠ËøõË°å‰∫ÜËØ¶ÁªÜÊèèËø∞ÔºàÊú™Áü•Ôºâ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

MedCLMÂú®Â§ö‰∏™ÂåªÂ≠¶VQAÂü∫ÂáÜÊµãËØï‰∏≠ÂèñÂæó‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåËØÅÊòé‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇÂÖ∑‰ΩìÊÄßËÉΩÊï∞ÊçÆÂíåÂØπÊØîÂü∫Á∫øÂú®ËÆ∫Êñá‰∏≠ËøõË°å‰∫ÜËØ¶ÁªÜÊèèËø∞ÔºàÊú™Áü•ÔºâÔºå‰ΩÜÊëòË¶Å‰∏≠ÊòéÁ°ÆÊåáÂá∫ÂÖ∂ËææÂà∞‰∫ÜSOTAÊ∞¥Âπ≥ÔºåË°®ÊòéÂÖ∂Âú®ÂåªÂ≠¶VQA‰ªªÂä°‰∏äÂÖ∑ÊúâÊòæËëó‰ºòÂäø„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

MedCLMÂèØÂ∫îÁî®‰∫éËæÖÂä©ÂåªÂ≠¶ËØäÊñ≠„ÄÅÂåªÂ≠¶ÊïôËÇ≤ÂíåËøúÁ®ãÂåªÁñóÁ≠âÈ¢ÜÂüü„ÄÇÂÆÉÂèØ‰ª•Â∏ÆÂä©ÂåªÁîüÊõ¥ÂáÜÁ°ÆÂú∞ËØäÊñ≠ÁñæÁóÖÔºå‰∏∫ÂåªÂ≠¶ÁîüÊèê‰æõÊõ¥ÊúâÊïàÁöÑÂ≠¶‰π†Â∑•ÂÖ∑ÔºåÂπ∂‰∏∫ÂÅèËøúÂú∞Âå∫ÁöÑÊÇ£ËÄÖÊèê‰æõÈ´òË¥®ÈáèÁöÑÂåªÁñóÊúçÂä°„ÄÇËØ•Á†îÁ©∂‰∏∫ÂºÄÂèëÊõ¥Êô∫ËÉΩ„ÄÅÊõ¥ÂèØÈù†ÁöÑÂåªÂ≠¶AIÁ≥ªÁªüÂ•†ÂÆö‰∫ÜÂü∫Á°ÄÔºåÊúâÊúõÂú®Êú™Êù•ÊîπÂèòÂåªÁñó‰øùÂÅ•Ë°å‰∏ö„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Bridging clinical diagnostic reasoning with AI remains a central challenge in medical imaging. We introduce MedCLM, an automated pipeline that converts detection datasets into large-scale medical visual question answering (VQA) data with Chain-of-Thought (CoT) reasoning by linking lesion boxes to organ segmentation and structured rationales. These contextual signals enable medical vision-language models to generate question-answer pairs with step-by-step reasoning. To utilize this data effectively, we propose an Integrated CoT-Curriculum Strategy composed of an Easy stage with explicit lesion boxes for visual grounding, a Medium stage that encourages implicit localization, and a Hard stage for weakly supervised reasoning. Experimental results demonstrate that MedCLM attains state-of-the-art performance on several medical VQA benchmarks, providing a scalable framework for developing clinically aligned medical vision-language models.

