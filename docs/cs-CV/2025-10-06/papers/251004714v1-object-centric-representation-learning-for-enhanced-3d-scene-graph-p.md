---
layout: default
title: Object-Centric Representation Learning for Enhanced 3D Scene Graph Prediction
---

# Object-Centric Representation Learning for Enhanced 3D Scene Graph Prediction

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.04714" target="_blank" class="toolbar-btn">arXiv: 2510.04714v1</a>
    <a href="https://arxiv.org/pdf/2510.04714.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.04714v1" 
            onclick="toggleFavorite(this, '2510.04714v1', 'Object-Centric Representation Learning for Enhanced 3D Scene Graph Prediction')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: KunHo Heo, GiHyun Kim, SuYeon Kim, MyeongAh Cho

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-06

**Â§áÊ≥®**: Accepted by NeurIPS 2025. Code: https://github.com/VisualScienceLab-KHU/OCRL-3DSSG-Codes

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/VisualScienceLab-KHU/OCRL-3DSSG-Codes)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Èù¢ÂêëÂØπË±°ÁöÑË°®ÂæÅÂ≠¶‰π†ÊñπÊ≥ïÔºåÊèêÂçá3DÂú∫ÊôØÂõæÈ¢ÑÊµãÁ≤æÂ∫¶**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)**

**ÂÖ≥ÈîÆËØç**: `3DÂú∫ÊôØÂõæÈ¢ÑÊµã` `ÂØπË±°Ë°®ÂæÅÂ≠¶‰π†` `ÂØπÊØîÂ≠¶‰π†` `ÂõæÁ•ûÁªèÁΩëÁªú` `Êú∫Âô®‰∫∫` `AR/VR` `ËØ≠‰πâÁêÜËß£`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞Êúâ3DÂú∫ÊôØÂõæÈ¢ÑÊµãÊñπÊ≥ïËøáÂ∫¶‰æùËµñÂõæÁ•ûÁªèÁΩëÁªúÔºåÂøΩÁï•‰∫ÜÂØπË±°ÁâπÂæÅÁöÑÂà§Âà´ËÉΩÂäõÔºåÂØºËá¥ÊÄßËÉΩÁì∂È¢à„ÄÇ
2. Êú¨ÊñáÊèêÂá∫‰∏ÄÁßçÂØπÊØîÈ¢ÑËÆ≠ÁªÉÁ≠ñÁï•ÔºåËß£ËÄ¶ÂØπË±°Ë°®ÂæÅÂ≠¶‰π†‰∏éÂú∫ÊôØÂõæÈ¢ÑÊµãÔºåÊèêÂçáÂØπË±°ÁâπÂæÅÁöÑÂà§Âà´ÊÄß„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåËØ•ÊñπÊ≥ïÊòæËëóÊèêÂçá‰∫ÜÂØπË±°ÂàÜÁ±ªÂíåÂÖ≥Á≥ªÈ¢ÑÊµãÁöÑÁ≤æÂ∫¶ÔºåÂπ∂Âú®3DSSGÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜSOTAÊÄßËÉΩ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

3DËØ≠‰πâÂú∫ÊôØÂõæÈ¢ÑÊµãÊó®Âú®Ê£ÄÊµã3DÂú∫ÊôØ‰∏≠ÁöÑÂØπË±°ÂèäÂÖ∂ËØ≠‰πâÂÖ≥Á≥ªÔºåÊòØÊú∫Âô®‰∫∫ÂíåAR/VRÂ∫îÁî®ÁöÑÂÖ≥ÈîÆÊäÄÊúØ„ÄÇÁé∞ÊúâÁ†îÁ©∂ËôΩÂ∑≤ÂÖ≥Ê≥®Êï∞ÊçÆÈõÜÈôêÂà∂ÂíåÂºÄÊîæËØçÊ±áÁ≠âÈóÆÈ¢òÔºå‰ΩÜÂ∏∏Êú™ËÉΩ‰ºòÂåñÂØπË±°ÂíåÂÖ≥Á≥ªÁâπÂæÅÁöÑË°®ÂæÅËÉΩÂäõÔºåËøáÂ∫¶‰æùËµñÂõæÁ•ûÁªèÁΩëÁªúÔºåÁº∫‰πèË∂≥Â§üÁöÑÂà§Âà´ËÉΩÂäõ„ÄÇÊú¨ÊñáÈÄöËøáÂ§ßÈáèÂàÜÊûêË°®ÊòéÔºåÂØπË±°ÁâπÂæÅÁöÑË¥®ÈáèÂØπÊï¥‰ΩìÂú∫ÊôØÂõæÁ≤æÂ∫¶Ëá≥ÂÖ≥ÈáçË¶Å„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨ËÆæËÆ°‰∫Ü‰∏ÄÁßçÈ´òÂà§Âà´ÊÄßÁöÑÂØπË±°ÁâπÂæÅÁºñÁ†ÅÂô®ÔºåÂπ∂ÈááÁî®ÂØπÊØîÈ¢ÑËÆ≠ÁªÉÁ≠ñÁï•ÔºåÂ∞ÜÂØπË±°Ë°®ÂæÅÂ≠¶‰π†‰∏éÂú∫ÊôØÂõæÈ¢ÑÊµãËß£ËÄ¶„ÄÇËØ•ËÆæËÆ°‰∏ç‰ªÖÊèêÈ´ò‰∫ÜÂØπË±°ÂàÜÁ±ªÁ≤æÂ∫¶ÔºåËøòÁõ¥Êé•ÊîπÂñÑ‰∫ÜÂÖ≥Á≥ªÈ¢ÑÊµã„ÄÇÂ∞ÜÊàë‰ª¨ÁöÑÈ¢ÑËÆ≠ÁªÉÁºñÁ†ÅÂô®ÊèíÂÖ•Áé∞ÊúâÊ°ÜÊû∂ÂêéÔºåÊâÄÊúâËØÑ‰º∞ÊåáÊ†áÂùáÊúâÊòæËëóÊèêÂçá„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÊúâÊïàÁªìÂêà‰∫ÜÂá†‰ΩïÂíåËØ≠‰πâÁâπÂæÅÔºåÂÆûÁé∞‰∫ÜÂçìË∂äÁöÑÂÖ≥Á≥ªÈ¢ÑÊµãÔºå‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇÂú®3DSSGÊï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åË°®ÊòéÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÊòæËëó‰ºò‰∫éÁé∞ÊúâÊäÄÊúØ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**Ôºö3DÂú∫ÊôØÂõæÈ¢ÑÊµãÊó®Âú®‰ªé3DÂú∫ÊôØ‰∏≠Ê£ÄÊµãÂØπË±°ÂèäÂÖ∂ÂÖ≥Á≥ªÔºåÊòØÊú∫Âô®‰∫∫ÂíåAR/VRÁöÑÂÖ≥ÈîÆÊäÄÊúØ„ÄÇÁé∞ÊúâÊñπÊ≥ïÁöÑ‰∏Ä‰∏™‰∏ªË¶ÅÁóõÁÇπÊòØÔºåÂÆÉ‰ª¨ÂæÄÂæÄËøáÂ∫¶‰æùËµñÂõæÁ•ûÁªèÁΩëÁªúÊù•Â≠¶‰π†ÂØπË±°ÂíåÂÖ≥Á≥ª‰πãÈó¥ÁöÑÂ§çÊùÇ‰æùËµñÂÖ≥Á≥ªÔºåËÄåÂøΩÁï•‰∫ÜÂØπË±°Ëá™Ë∫´ÁâπÂæÅÁöÑË¥®Èáè„ÄÇËøôÊÑèÂë≥ÁùÄÂç≥‰ΩøÂõæÁ•ûÁªèÁΩëÁªúËÉΩÂ§üÂæàÂ•ΩÂú∞Âª∫Ê®°ÂÖ≥Á≥ªÔºåÂ¶ÇÊûúËæìÂÖ•ÁöÑÂØπË±°ÁâπÂæÅÊú¨Ë∫´‰∏çÂ§üÂÖ∑ÊúâÂå∫ÂàÜÊÄßÔºåÊúÄÁªàÁöÑÂú∫ÊôØÂõæÈ¢ÑÊµãÊÄßËÉΩ‰πü‰ºöÂèóÂà∞ÈôêÂà∂„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊú¨ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈ¶ñÂÖàÊèêÂçáÂØπË±°ÁâπÂæÅÁöÑË¥®ÈáèÔºåÁÑ∂ÂêéÂÜçËøõË°åÂú∫ÊôØÂõæÈ¢ÑÊµã„ÄÇÂÖ∑‰ΩìÊù•ËØ¥Ôºå‰ΩúËÄÖËÆ§‰∏∫Â∫îËØ•Â∞ÜÂØπË±°Ë°®ÂæÅÂ≠¶‰π†‰∏éÂú∫ÊôØÂõæÈ¢ÑÊµãËß£ËÄ¶ÔºåÈÄöËøáÂØπÊØîÂ≠¶‰π†ÁöÑÊñπÂºèÔºåÈ¢ÑËÆ≠ÁªÉ‰∏Ä‰∏™ÂÖ∑ÊúâÈ´òÂà§Âà´ÊÄßÁöÑÂØπË±°ÁâπÂæÅÁºñÁ†ÅÂô®„ÄÇËøôÊ†∑ÔºåÁºñÁ†ÅÂô®ÂèØ‰ª•Â≠¶‰π†Âà∞Êõ¥È≤ÅÊ£í„ÄÅÊõ¥ÂÖ∑Âå∫ÂàÜÊÄßÁöÑÂØπË±°ÁâπÂæÅÔºå‰ªéËÄå‰∏∫ÂêéÁª≠ÁöÑÂú∫ÊôØÂõæÈ¢ÑÊµãÊèê‰æõÊõ¥Â•ΩÁöÑÂü∫Á°Ä„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•ÊñπÊ≥ï‰∏ªË¶ÅÂåÖÂê´‰∏§‰∏™Èò∂ÊÆµÔºöÂØπË±°ÁâπÂæÅÁºñÁ†ÅÂô®È¢ÑËÆ≠ÁªÉÂíåÂú∫ÊôØÂõæÈ¢ÑÊµã„ÄÇÂú®ÂØπË±°ÁâπÂæÅÁºñÁ†ÅÂô®È¢ÑËÆ≠ÁªÉÈò∂ÊÆµÔºå‰ΩøÁî®ÂØπÊØîÂ≠¶‰π†Á≠ñÁï•ÔºåËÆ≠ÁªÉ‰∏Ä‰∏™ËÉΩÂ§üÂå∫ÂàÜ‰∏çÂêåÂØπË±°ÁöÑÁºñÁ†ÅÂô®„ÄÇÂú®Âú∫ÊôØÂõæÈ¢ÑÊµãÈò∂ÊÆµÔºåÂ∞ÜÈ¢ÑËÆ≠ÁªÉÂ•ΩÁöÑÂØπË±°ÁâπÂæÅÁºñÁ†ÅÂô®‰Ωú‰∏∫ÁâπÂæÅÊèêÂèñÂô®ÔºåÁÑ∂Âêé‰ΩøÁî®ÂõæÁ•ûÁªèÁΩëÁªúÊù•È¢ÑÊµãÂØπË±°‰πãÈó¥ÁöÑÂÖ≥Á≥ª„ÄÇÊ≠§Â§ñÔºå‰ΩúËÄÖËøòÁªìÂêà‰∫ÜÂá†‰ΩïÂíåËØ≠‰πâÁâπÂæÅÊù•ÊèêÂçáÂÖ≥Á≥ªÈ¢ÑÊµãÁöÑÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ÊñπÊ≥ïÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éÂ∞ÜÂØπË±°Ë°®ÂæÅÂ≠¶‰π†‰∏éÂú∫ÊôØÂõæÈ¢ÑÊµãËß£ËÄ¶ÔºåÂπ∂ÈÄöËøáÂØπÊØîÂ≠¶‰π†È¢ÑËÆ≠ÁªÉ‰∏Ä‰∏™È´òÂà§Âà´ÊÄßÁöÑÂØπË±°ÁâπÂæÅÁºñÁ†ÅÂô®„ÄÇËøôÁßçËß£ËÄ¶ÁöÑÊñπÂºè‰ΩøÂæóÂØπË±°ÁâπÂæÅÁöÑÂ≠¶‰π†‰∏çÂÜç‰æùËµñ‰∫éÂú∫ÊôØÂõæÁöÑ‰∏ä‰∏ãÊñá‰ø°ÊÅØÔºå‰ªéËÄåÂèØ‰ª•Â≠¶‰π†Âà∞Êõ¥ÈÄöÁî®ÁöÑÂØπË±°Ë°®ÂæÅ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÂØπÊØîÂ≠¶‰π†‰∏≠Ôºå‰ΩúËÄÖËÆæËÆ°‰∫Ü‰∏ÄÁßçÊçüÂ§±ÂáΩÊï∞ÔºåÈºìÂä±ÁºñÁ†ÅÂô®Â∞ÜÂêå‰∏ÄÂØπË±°ÁöÑ‰∏çÂêåËßÜËßíÊò†Â∞ÑÂà∞Áõ∏ËøëÁöÑÁâπÂæÅÁ©∫Èó¥ÔºåÂêåÊó∂Â∞Ü‰∏çÂêåÂØπË±°ÁöÑÁâπÂæÅÊò†Â∞ÑÂà∞‰∏çÂêåÁöÑÁâπÂæÅÁ©∫Èó¥„ÄÇÊ≠§Â§ñÔºåÂú®ÂÖ≥Á≥ªÈ¢ÑÊµã‰∏≠Ôºå‰ΩúËÄÖÁªìÂêà‰∫ÜÂá†‰ΩïÁâπÂæÅÔºà‰æãÂ¶ÇÔºåÂØπË±°‰πãÈó¥ÁöÑË∑ùÁ¶ªÂíåÊñπÂêëÔºâÂíåËØ≠‰πâÁâπÂæÅÔºà‰æãÂ¶ÇÔºåÂØπË±°Á±ªÂà´ÔºâÊù•ÊèêÂçáÂÖ≥Á≥ªÈ¢ÑÊµãÁöÑÂáÜÁ°ÆÊÄß„ÄÇÂÖ∑‰ΩìÁöÑÁΩëÁªúÁªìÊûÑÂíåÂèÇÊï∞ËÆæÁΩÆÂú®ËÆ∫Êñá‰∏≠ÊúâËØ¶ÁªÜÊèèËø∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®3DSSGÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÂ∞ÜÈ¢ÑËÆ≠ÁªÉÁöÑÁºñÁ†ÅÂô®ÊèíÂÖ•Âà∞Áé∞ÊúâÁöÑÂú∫ÊôØÂõæÈ¢ÑÊµãÊ°ÜÊû∂‰∏≠ÔºåÊâÄÊúâËØÑ‰º∞ÊåáÊ†áÂùáÊúâÊòæËëóÊèêÂçá„ÄÇ‰æãÂ¶ÇÔºåÂú®ÂØπË±°ÂàÜÁ±ªÁ≤æÂ∫¶ÊñπÈù¢ÔºåËØ•ÊñπÊ≥ïÊØîÁé∞ÊúâÊúÄ‰Ω≥ÊñπÊ≥ïÊèêÈ´ò‰∫ÜX%„ÄÇÂú®ÂÖ≥Á≥ªÈ¢ÑÊµãÁ≤æÂ∫¶ÊñπÈù¢ÔºåËØ•ÊñπÊ≥ï‰πüÂèñÂæó‰∫ÜÊòæËëóÁöÑÊèêÂçáÔºåË∂ÖËøá‰∫ÜÁé∞ÊúâÊñπÊ≥ïY%„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÊúâÊïàÂú∞ÊèêÂçá3DÂú∫ÊôØÂõæÈ¢ÑÊµãÁöÑÂáÜÁ°ÆÊÄßÂíåÈ≤ÅÊ£íÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂπøÊ≥õÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫ÂØºËà™„ÄÅÂú∫ÊôØÁêÜËß£„ÄÅÂ¢ûÂº∫Áé∞ÂÆûÂíåËôöÊãüÁé∞ÂÆûÁ≠âÈ¢ÜÂüü„ÄÇ‰æãÂ¶ÇÔºåÊú∫Âô®‰∫∫ÂèØ‰ª•Âà©Áî®Êõ¥ÂáÜÁ°ÆÁöÑ3DÂú∫ÊôØÂõæËøõË°åÊõ¥ÊúâÊïàÁöÑË∑ØÂæÑËßÑÂàíÂíåÁâ©‰Ωì‰∫§‰∫í„ÄÇAR/VRÂ∫îÁî®ÂèØ‰ª•Âà©Áî®ËØ•ÊäÄÊúØÂÆûÁé∞Êõ¥ÈÄºÁúüÁöÑÂú∫ÊôØÈáçÂª∫ÂíåÊõ¥Ëá™ÁÑ∂ÁöÑ‰∫§‰∫í‰ΩìÈ™å„ÄÇÊ≠§Â§ñÔºåËØ•ÊäÄÊúØËøòÂèØ‰ª•Â∫îÁî®‰∫éËá™Âä®È©æÈ©∂„ÄÅÊô∫ËÉΩÂÆ∂Â±ÖÁ≠âÈ¢ÜÂüüÔºåÂÖ∑ÊúâÂπøÈòîÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> 3D Semantic Scene Graph Prediction aims to detect objects and their semantic relationships in 3D scenes, and has emerged as a crucial technology for robotics and AR/VR applications. While previous research has addressed dataset limitations and explored various approaches including Open-Vocabulary settings, they frequently fail to optimize the representational capacity of object and relationship features, showing excessive reliance on Graph Neural Networks despite insufficient discriminative capability. In this work, we demonstrate through extensive analysis that the quality of object features plays a critical role in determining overall scene graph accuracy. To address this challenge, we design a highly discriminative object feature encoder and employ a contrastive pretraining strategy that decouples object representation learning from the scene graph prediction. This design not only enhances object classification accuracy but also yields direct improvements in relationship prediction. Notably, when plugging in our pretrained encoder into existing frameworks, we observe substantial performance improvements across all evaluation metrics. Additionally, whereas existing approaches have not fully exploited the integration of relationship information, we effectively combine both geometric and semantic features to achieve superior relationship prediction. Comprehensive experiments on the 3DSSG dataset demonstrate that our approach significantly outperforms previous state-of-the-art methods. Our code is publicly available at https://github.com/VisualScienceLab-KHU/OCRL-3DSSG-Codes.

