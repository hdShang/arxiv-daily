---
layout: default
title: Progressive Gaussian Transformer with Anisotropy-aware Sampling for Open Vocabulary Occupancy Prediction
---

# Progressive Gaussian Transformer with Anisotropy-aware Sampling for Open Vocabulary Occupancy Prediction

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.04759" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.04759v2</a>
  <a href="https://arxiv.org/pdf/2510.04759.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.04759v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.04759v2', 'Progressive Gaussian Transformer with Anisotropy-aware Sampling for Open Vocabulary Occupancy Prediction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chi Yan, Dan Xu

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-10-06 (æ›´æ–°: 2025-10-08)

**å¤‡æ³¨**: Project Page: https://yanchi-3dv.github.io/PG-Occ

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://yanchi-3dv.github.io/PG-Occ)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPG-Occæ¡†æ¶ï¼Œé€šè¿‡æ¸è¿›å¼é«˜æ–¯Transformerå®ç°å¼€æ”¾è¯æ±‡ä¸‰ç»´ occupancy é¢„æµ‹ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `ä¸‰ç»´ occupancy é¢„æµ‹` `å¼€æ”¾è¯æ±‡` `é«˜æ–¯è¡¨ç¤º` `Transformer` `è‡ªåŠ¨é©¾é©¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ä¸‰ç»´ occupancy é¢„æµ‹æ–¹æ³•åœ¨å¼€æ”¾è¯æ±‡åœºæ™¯ä¸­å­˜åœ¨ç¨€ç–è¡¨ç¤ºéš¾ä»¥æ•æ‰å°ç‰©ä½“ï¼Œå¯†é›†è¡¨ç¤ºè®¡ç®—å¼€é”€å¤§çš„é—®é¢˜ã€‚
2. PG-Occæ¡†æ¶é‡‡ç”¨æ¸è¿›å¼åœ¨çº¿å¯†é›†åŒ–ç­–ç•¥ï¼Œé€æ­¥å¢å¼ºé«˜æ–¯è¡¨ç¤ºï¼Œä»¥æ•æ‰ç²¾ç»†åœºæ™¯ç»†èŠ‚ï¼Œå®ç°æ›´ç²¾ç¡®çš„åœºæ™¯ç†è§£ã€‚
3. å¼•å…¥å„å‘å¼‚æ€§æ„ŸçŸ¥é‡‡æ ·ç­–ç•¥ï¼Œè‡ªé€‚åº”åœ°ä¸ºä¸åŒå°ºåº¦é«˜æ–¯åˆ†é…æ„Ÿå—é‡ï¼Œå®ç°æ›´æœ‰æ•ˆçš„ç‰¹å¾èšåˆï¼ŒmIoUç›¸å¯¹æå‡14.3%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œä¸‰ç»´ occupancy é¢„æµ‹ä»»åŠ¡å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œåœ¨åŸºäºè§†è§‰çš„è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿä¸­å‘æŒ¥ç€å…³é”®ä½œç”¨ã€‚ä¼ ç»Ÿæ–¹æ³•å±€é™äºå›ºå®šçš„è¯­ä¹‰ç±»åˆ«ï¼Œè€Œæœ€è¿‘çš„æ–¹æ³•è½¬å‘é¢„æµ‹æ–‡æœ¬å¯¹é½çš„ç‰¹å¾ï¼Œä»¥æ”¯æŒçœŸå®åœºæ™¯ä¸­çš„å¼€æ”¾è¯æ±‡æ–‡æœ¬æŸ¥è¯¢ã€‚ç„¶è€Œï¼Œæ–‡æœ¬å¯¹é½çš„åœºæ™¯å»ºæ¨¡å­˜åœ¨ä¸€ä¸ªæƒè¡¡ï¼šç¨€ç–é«˜æ–¯è¡¨ç¤ºéš¾ä»¥æ•æ‰åœºæ™¯ä¸­çš„å°ç‰©ä½“ï¼Œè€Œå¯†é›†è¡¨ç¤ºä¼šäº§ç”Ÿå·¨å¤§çš„è®¡ç®—å¼€é”€ã€‚ä¸ºäº†è§£å†³è¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºäº†PG-Occï¼Œä¸€ç§åˆ›æ–°çš„æ¸è¿›å¼é«˜æ–¯Transformeræ¡†æ¶ï¼Œç”¨äºå®ç°å¼€æ”¾è¯æ±‡ä¸‰ç»´ occupancy é¢„æµ‹ã€‚æˆ‘ä»¬çš„æ¡†æ¶é‡‡ç”¨æ¸è¿›å¼åœ¨çº¿å¯†é›†åŒ–ï¼Œè¿™æ˜¯ä¸€ç§å‰é¦ˆç­–ç•¥ï¼Œé€æ­¥å¢å¼ºä¸‰ç»´é«˜æ–¯è¡¨ç¤ºï¼Œä»¥æ•æ‰ç²¾ç»†çš„åœºæ™¯ç»†èŠ‚ã€‚é€šè¿‡è¿­ä»£å¢å¼ºè¡¨ç¤ºï¼Œè¯¥æ¡†æ¶å®ç°äº†è¶Šæ¥è¶Šç²¾ç¡®å’Œè¯¦ç»†çš„åœºæ™¯ç†è§£ã€‚å¦ä¸€ä¸ªå…³é”®è´¡çŒ®æ˜¯å¼•å…¥äº†å…·æœ‰æ—¶ç©ºèåˆçš„å„å‘å¼‚æ€§æ„ŸçŸ¥é‡‡æ ·ç­–ç•¥ï¼Œè¯¥ç­–ç•¥è‡ªé€‚åº”åœ°ä¸ºä¸åŒå°ºåº¦å’Œé˜¶æ®µçš„é«˜æ–¯åˆ†é…æ„Ÿå—é‡ï¼Œä»è€Œå®ç°æ›´æœ‰æ•ˆçš„ç‰¹å¾èšåˆå’Œæ›´ä¸°å¯Œçš„åœºæ™¯ä¿¡æ¯æ•è·ã€‚é€šè¿‡å¹¿æ³›çš„è¯„ä¼°ï¼Œæˆ‘ä»¬è¯æ˜äº†PG-Occå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œç›¸å¯¹äºä¹‹å‰è¡¨ç°æœ€ä½³çš„æ–¹æ³•ï¼ŒmIoUç›¸å¯¹æé«˜äº†14.3%ã€‚ä»£ç å’Œé¢„è®­ç»ƒæ¨¡å‹å°†åœ¨é¡¹ç›®é¡µé¢ä¸Šå‘å¸ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¼€æ”¾è¯æ±‡ä¸‰ç»´ occupancy é¢„æµ‹é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¼€æ”¾è¯æ±‡åœºæ™¯æ—¶ï¼Œé¢ä¸´ç€ç¨€ç–é«˜æ–¯è¡¨ç¤ºéš¾ä»¥æ•æ‰å°ç‰©ä½“ï¼Œè€Œå¯†é›†è¡¨ç¤ºè®¡ç®—å¼€é”€è¿‡å¤§çš„éš¾é¢˜ã€‚è¿™é™åˆ¶äº†ä¸‰ç»´åœºæ™¯ç†è§£çš„ç²¾åº¦å’Œæ•ˆç‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ¸è¿›å¼çš„é«˜æ–¯è¡¨ç¤ºæ¥å¹³è¡¡ç²¾åº¦å’Œæ•ˆç‡ã€‚ä»ç¨€ç–çš„é«˜æ–¯è¡¨ç¤ºå¼€å§‹ï¼Œé€æ­¥è¿›è¡Œåœ¨çº¿å¯†é›†åŒ–ï¼Œä»è€Œåœ¨è®¡ç®—èµ„æºå¯æ§çš„å‰æä¸‹ï¼Œé€æ­¥æå‡åœºæ™¯è¡¨ç¤ºçš„ç²¾ç»†ç¨‹åº¦ã€‚åŒæ—¶ï¼Œé€šè¿‡å„å‘å¼‚æ€§æ„ŸçŸ¥é‡‡æ ·ï¼Œè‡ªé€‚åº”åœ°è°ƒæ•´æ„Ÿå—é‡ï¼Œä»¥æ›´å¥½åœ°èšåˆç‰¹å¾ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPG-Occæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) åˆå§‹ç¨€ç–é«˜æ–¯è¡¨ç¤ºï¼šä½¿ç”¨å°‘é‡é«˜æ–¯åˆ†å¸ƒæ¥åˆæ­¥è¡¨ç¤ºåœºæ™¯ã€‚2) æ¸è¿›å¼åœ¨çº¿å¯†é›†åŒ–ï¼šé€šè¿‡å‰é¦ˆç­–ç•¥ï¼Œé€æ­¥å¢åŠ é«˜æ–¯åˆ†å¸ƒçš„æ•°é‡ï¼Œä»è€Œå¢å¼ºåœºæ™¯è¡¨ç¤ºçš„ç»†èŠ‚ã€‚3) å„å‘å¼‚æ€§æ„ŸçŸ¥é‡‡æ ·ï¼šæ ¹æ®é«˜æ–¯åˆ†å¸ƒçš„å°ºåº¦å’Œé˜¶æ®µï¼Œè‡ªé€‚åº”åœ°åˆ†é…æ„Ÿå—é‡ï¼Œè¿›è¡Œæ—¶ç©ºç‰¹å¾èåˆã€‚4) Occupancy é¢„æµ‹ï¼šåŸºäºå¢å¼ºçš„é«˜æ–¯è¡¨ç¤ºï¼Œé¢„æµ‹ä¸‰ç»´ç©ºé—´çš„ occupancy çŠ¶æ€ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºä»¥ä¸‹ä¸¤ç‚¹ï¼š1) æ¸è¿›å¼åœ¨çº¿å¯†é›†åŒ–ï¼šè¿™ç§ç­–ç•¥èƒ½å¤Ÿåœ¨è®¡ç®—èµ„æºæœ‰é™çš„æƒ…å†µä¸‹ï¼Œé€æ­¥æå‡åœºæ™¯è¡¨ç¤ºçš„ç²¾åº¦ã€‚2) å„å‘å¼‚æ€§æ„ŸçŸ¥é‡‡æ ·ï¼šè¿™ç§é‡‡æ ·ç­–ç•¥èƒ½å¤Ÿæ ¹æ®é«˜æ–¯åˆ†å¸ƒçš„ç‰¹æ€§ï¼Œè‡ªé€‚åº”åœ°è°ƒæ•´æ„Ÿå—é‡ï¼Œä»è€Œæ›´æœ‰æ•ˆåœ°èšåˆç‰¹å¾ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒPG-Occèƒ½å¤Ÿåœ¨ç²¾åº¦å’Œæ•ˆç‡ä¹‹é—´å–å¾—æ›´å¥½çš„å¹³è¡¡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¸è¿›å¼åœ¨çº¿å¯†é›†åŒ–è¿‡ç¨‹ä¸­ï¼Œè®ºæ–‡é‡‡ç”¨äº†ä¸€ç§å‰é¦ˆç­–ç•¥ï¼Œé¿å…äº†å¤æ‚çš„ä¼˜åŒ–è¿‡ç¨‹ã€‚åœ¨å„å‘å¼‚æ€§æ„ŸçŸ¥é‡‡æ ·ä¸­ï¼Œè®ºæ–‡è®¾è®¡äº†ä¸€ç§åŸºäºé«˜æ–¯åˆ†å¸ƒå°ºåº¦å’Œé˜¶æ®µçš„è‡ªé€‚åº”æ„Ÿå—é‡åˆ†é…æ–¹æ³•ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ï¼ˆæœªçŸ¥ï¼‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

PG-Occåœ¨å¼€æ”¾è¯æ±‡ä¸‰ç»´ occupancy é¢„æµ‹ä»»åŠ¡ä¸Šå–å¾—äº†state-of-the-artçš„æ€§èƒ½ï¼Œç›¸å¯¹äºä¹‹å‰è¡¨ç°æœ€ä½³çš„æ–¹æ³•ï¼ŒmIoUç›¸å¯¹æé«˜äº†14.3%ã€‚è¿™è¡¨æ˜PG-Occåœ¨ç²¾åº¦å’Œæ•ˆç‡æ–¹é¢éƒ½å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†å¤æ‚çš„çœŸå®åœºæ™¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€è™šæ‹Ÿç°å®ç­‰é¢†åŸŸã€‚é€šè¿‡å®ç°å¼€æ”¾è¯æ±‡çš„ä¸‰ç»´åœºæ™¯ç†è§£ï¼Œå¯ä»¥ä½¿è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿæ›´å¥½åœ°è¯†åˆ«å’Œç†è§£å¤æ‚çš„äº¤é€šç¯å¢ƒï¼Œæé«˜é©¾é©¶å®‰å…¨æ€§ã€‚åœ¨æœºå™¨äººå¯¼èˆªä¸­ï¼Œå¯ä»¥å¸®åŠ©æœºå™¨äººæ›´å¥½åœ°æ„ŸçŸ¥å‘¨å›´ç¯å¢ƒï¼Œå®ç°æ›´æ™ºèƒ½çš„è·¯å¾„è§„åˆ’ã€‚åœ¨è™šæ‹Ÿç°å®ä¸­ï¼Œå¯ä»¥åˆ›å»ºæ›´é€¼çœŸçš„ä¸‰ç»´åœºæ™¯ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The 3D occupancy prediction task has witnessed remarkable progress in recent years, playing a crucial role in vision-based autonomous driving systems. While traditional methods are limited to fixed semantic categories, recent approaches have moved towards predicting text-aligned features to enable open-vocabulary text queries in real-world scenes. However, there exists a trade-off in text-aligned scene modeling: sparse Gaussian representation struggles to capture small objects in the scene, while dense representation incurs significant computational overhead. To address these limitations, we present PG-Occ, an innovative Progressive Gaussian Transformer Framework that enables open-vocabulary 3D occupancy prediction. Our framework employs progressive online densification, a feed-forward strategy that gradually enhances the 3D Gaussian representation to capture fine-grained scene details. By iteratively enhancing the representation, the framework achieves increasingly precise and detailed scene understanding. Another key contribution is the introduction of an anisotropy-aware sampling strategy with spatio-temporal fusion, which adaptively assigns receptive fields to Gaussians at different scales and stages, enabling more effective feature aggregation and richer scene information capture. Through extensive evaluations, we demonstrate that PG-Occ achieves state-of-the-art performance with a relative 14.3% mIoU improvement over the previous best performing method. Code and pretrained models will be released upon publication on our project page: https://yanchi-3dv.github.io/PG-Occ

