---
layout: default
title: Conditional Representation Learning for Customized Tasks
---

# Conditional Representation Learning for Customized Tasks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.04564" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.04564v2</a>
  <a href="https://arxiv.org/pdf/2510.04564.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.04564v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.04564v2', 'Conditional Representation Learning for Customized Tasks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Honglin Liu, Chao Sun, Peng Hu, Yunfan Li, Xi Peng

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-06 (æ›´æ–°: 2025-12-13)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/XLearning-SCU/2025-NeurIPS-CRL)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ¡ä»¶è¡¨ç¤ºå­¦ä¹ (CRL)ï¼Œä¸ºå®šåˆ¶ä»»åŠ¡æå–ç‰¹å®šè¯­ä¹‰çš„å›¾åƒè¡¨å¾ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ¡ä»¶è¡¨ç¤ºå­¦ä¹ ` `è§†è§‰-è¯­è¨€æ¨¡å‹` `å¤§è¯­è¨€æ¨¡å‹` `å®šåˆ¶ä»»åŠ¡` `é›¶æ ·æœ¬å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰é€šç”¨è¡¨ç¤ºå­¦ä¹ æ–¹æ³•æ— æ³•å¾ˆå¥½åœ°é€‚åº”ç‰¹å®šä¸‹æ¸¸ä»»åŠ¡çš„éœ€æ±‚ï¼Œä¾‹å¦‚åŠ¨ç‰©æ –æ¯åœ°åˆ†æã€‚
2. CRLåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆæè¿°æ€§æ–‡æœ¬æ„å»ºè¯­ä¹‰åŸºç¡€ï¼Œå†ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹å°†å›¾åƒæŠ•å½±åˆ°æ¡ä»¶ç‰¹å¾ç©ºé—´ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒCRLåœ¨åˆ†ç±»å’Œæ£€ç´¢ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡å®šåˆ¶ä»»åŠ¡çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¼ ç»Ÿçš„è¡¨ç¤ºå­¦ä¹ æ–¹æ³•å­¦ä¹ çš„æ˜¯ä¸€ç§é€šç”¨çš„è¡¨ç¤ºï¼Œä¸»è¦æ•æ‰çš„æ˜¯ä¸»è¦çš„è¯­ä¹‰ï¼Œè¿™å¯èƒ½å¹¶ä¸æ€»æ˜¯ä¸å®šåˆ¶çš„ä¸‹æ¸¸ä»»åŠ¡å¯¹é½ã€‚ä¾‹å¦‚ï¼Œåœ¨åŠ¨ç‰©æ –æ¯åœ°åˆ†æä¸­ï¼Œç ”ç©¶äººå‘˜ä¼˜å…ˆè€ƒè™‘ä¸åœºæ™¯ç›¸å…³çš„ç‰¹å¾ï¼Œè€Œé€šç”¨çš„åµŒå…¥åˆ™å¼ºè°ƒç±»åˆ«è¯­ä¹‰ï¼Œå¯¼è‡´æ¬¡ä¼˜çš„ç»“æœã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œç°æœ‰çš„æ–¹æ³•æ±‚åŠ©äºæœ‰ç›‘ç£çš„å¾®è°ƒï¼Œä½†è¿™ä¼šå¸¦æ¥å¾ˆé«˜çš„è®¡ç®—å’Œæ ‡æ³¨æˆæœ¬ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†æ¡ä»¶è¡¨ç¤ºå­¦ä¹ (CRL)ï¼Œæ—¨åœ¨æå–ä¸ºä»»æ„ç”¨æˆ·æŒ‡å®šçš„æ ‡å‡†é‡èº«å®šåˆ¶çš„è¡¨ç¤ºã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æ­ç¤ºäº†ä¸€ä¸ªç©ºé—´çš„è¯­ä¹‰æ˜¯ç”±å®ƒçš„åŸºå†³å®šçš„ï¼Œä»è€Œä½¿ä¸€ç»„æè¿°æ€§è¯è¯­èƒ½å¤Ÿè¿‘ä¼¼äºä¸€ä¸ªå®šåˆ¶ç‰¹å¾ç©ºé—´çš„åŸºã€‚åŸºäºè¿™ä¸€æ´å¯Ÿï¼Œç»™å®šä¸€ä¸ªç”¨æˆ·æŒ‡å®šçš„æ ‡å‡†ï¼ŒCRLé¦–å…ˆåˆ©ç”¨ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹(LLM)ç”Ÿæˆæè¿°æ€§æ–‡æœ¬æ¥æ„å»ºè¯­ä¹‰åŸºç¡€ï¼Œç„¶ååˆ©ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹(VLM)å°†å›¾åƒè¡¨ç¤ºæŠ•å½±åˆ°è¿™ä¸ªæ¡ä»¶ç‰¹å¾ç©ºé—´ä¸­ã€‚æ¡ä»¶è¡¨ç¤ºæ›´å¥½åœ°æ•æ‰äº†ç‰¹å®šæ ‡å‡†çš„è¯­ä¹‰ï¼Œå¯ä»¥ç”¨äºå¤šä¸ªå®šåˆ¶ä»»åŠ¡ã€‚åœ¨åˆ†ç±»å’Œæ£€ç´¢ä»»åŠ¡ä¸Šçš„å¤§é‡å®éªŒè¯æ˜äº†æ‰€æå‡ºçš„CRLçš„ä¼˜è¶Šæ€§å’Œé€šç”¨æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰é€šç”¨è¡¨ç¤ºå­¦ä¹ æ–¹æ³•æå–çš„ç‰¹å¾ä¸»è¦å…³æ³¨å›¾åƒçš„é€šç”¨è¯­ä¹‰ï¼Œå¿½ç•¥äº†ç‰¹å®šä»»åŠ¡çš„éœ€æ±‚ã€‚ä¾‹å¦‚ï¼Œåœ¨åŠ¨ç‰©æ –æ¯åœ°åˆ†æä¸­ï¼Œç ”ç©¶äººå‘˜æ›´å…³æ³¨åœºæ™¯ç›¸å…³çš„ç‰¹å¾ï¼Œè€Œé€šç”¨è¡¨ç¤ºå¯èƒ½ä¾§é‡äºç±»åˆ«ä¿¡æ¯ï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚æ­¤å¤–ï¼Œé€šè¿‡æœ‰ç›‘ç£å¾®è°ƒæ¥é€‚åº”ç‰¹å®šä»»åŠ¡éœ€è¦å¤§é‡çš„æ ‡æ³¨æ•°æ®å’Œè®¡ç®—èµ„æºï¼Œæˆæœ¬é«˜æ˜‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼Œç‰¹å¾ç©ºé—´çš„è¯­ä¹‰ç”±å…¶åŸºå†³å®šã€‚å› æ­¤ï¼Œå¯ä»¥é€šè¿‡ä¸€ç»„æè¿°æ€§è¯è¯­æ¥è¿‘ä¼¼è¡¨ç¤ºä¸€ä¸ªå®šåˆ¶ç‰¹å¾ç©ºé—´çš„åŸºã€‚ç»™å®šç”¨æˆ·æŒ‡å®šçš„æ ‡å‡†ï¼ˆä¾‹å¦‚ï¼Œä»»åŠ¡æè¿°ï¼‰ï¼Œé¦–å…ˆåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆä¸è¯¥æ ‡å‡†ç›¸å…³çš„æè¿°æ€§æ–‡æœ¬ï¼Œç„¶åå°†è¿™äº›æ–‡æœ¬ä½œä¸ºæ¡ä»¶ï¼Œå¼•å¯¼è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰å°†å›¾åƒè¡¨ç¤ºæŠ•å½±åˆ°ä¸è¯¥æ ‡å‡†å¯¹é½çš„ç‰¹å¾ç©ºé—´ä¸­ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCRLçš„æ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ­¥éª¤ï¼š1) **æ¡ä»¶ç”Ÿæˆ**ï¼šç»™å®šç”¨æˆ·æŒ‡å®šçš„æ ‡å‡†ï¼ˆä¾‹å¦‚ï¼Œä»»åŠ¡æè¿°ï¼‰ï¼Œä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆæè¿°æ€§æ–‡æœ¬ã€‚2) **è¯­ä¹‰åŸºæ„å»º**ï¼šå°†ç”Ÿæˆçš„æè¿°æ€§æ–‡æœ¬ä½œä¸ºè¯­ä¹‰åŸºï¼Œç”¨äºå®šä¹‰å®šåˆ¶çš„ç‰¹å¾ç©ºé—´ã€‚3) **å›¾åƒè¡¨ç¤ºæŠ•å½±**ï¼šåˆ©ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ï¼Œå°†å›¾åƒè¡¨ç¤ºæŠ•å½±åˆ°ç”±è¯­ä¹‰åŸºå®šä¹‰çš„æ¡ä»¶ç‰¹å¾ç©ºé—´ä¸­ã€‚è¿™ä¸ªè¿‡ç¨‹é€šè¿‡å°†å›¾åƒå’Œæ–‡æœ¬ä¿¡æ¯å¯¹é½æ¥å®ç°ã€‚4) **ä»»åŠ¡æ‰§è¡Œ**ï¼šåœ¨æ¡ä»¶ç‰¹å¾ç©ºé—´ä¸­ï¼Œæ‰§è¡Œä¸‹æ¸¸çš„å®šåˆ¶ä»»åŠ¡ï¼Œä¾‹å¦‚åˆ†ç±»æˆ–æ£€ç´¢ã€‚

**å…³é”®åˆ›æ–°**ï¼šCRLçš„å…³é”®åˆ›æ–°åœ¨äºåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆæè¿°æ€§æ–‡æœ¬æ¥æ„å»ºå®šåˆ¶ç‰¹å¾ç©ºé—´çš„è¯­ä¹‰åŸºã€‚è¿™ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ ¹æ®ç”¨æˆ·æŒ‡å®šçš„æ ‡å‡†åŠ¨æ€åœ°è°ƒæ•´ç‰¹å¾è¡¨ç¤ºï¼Œä»è€Œæ›´å¥½åœ°é€‚åº”ä¸åŒçš„ä¸‹æ¸¸ä»»åŠ¡ã€‚ä¸ä¼ ç»Ÿçš„é€šç”¨è¡¨ç¤ºå­¦ä¹ æ–¹æ³•ç›¸æ¯”ï¼ŒCRLèƒ½å¤Ÿæå–ä¸ç‰¹å®šä»»åŠ¡ç›¸å…³çš„è¯­ä¹‰ä¿¡æ¯ï¼Œé¿å…äº†å¯¹å¤§é‡æ ‡æ³¨æ•°æ®çš„ä¾èµ–ã€‚

**å…³é”®è®¾è®¡**ï¼šCRLçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) **LLMçš„é€‰æ‹©**ï¼šé€‰æ‹©èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡æè¿°æ€§æ–‡æœ¬çš„LLMï¼Œä¾‹å¦‚GPT-3æˆ–ç±»ä¼¼çš„æ¨¡å‹ã€‚2) **VLMçš„é€‰æ‹©**ï¼šé€‰æ‹©èƒ½å¤Ÿæœ‰æ•ˆå¯¹é½è§†è§‰å’Œè¯­è¨€ä¿¡æ¯çš„VLMï¼Œä¾‹å¦‚CLIPæˆ–ç±»ä¼¼çš„æ¨¡å‹ã€‚3) **æŠ•å½±æ–¹å¼**ï¼šä½¿ç”¨çº¿æ€§æŠ•å½±æˆ–å…¶ä»–éçº¿æ€§æŠ•å½±æ–¹æ³•ï¼Œå°†å›¾åƒè¡¨ç¤ºæŠ•å½±åˆ°æ¡ä»¶ç‰¹å¾ç©ºé—´ä¸­ã€‚4) **æŸå¤±å‡½æ•°**ï¼šå¯ä»¥ä½¿ç”¨å¯¹æ¯”æŸå¤±æˆ–å…¶ä»–æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–VLMï¼Œä½¿å…¶æ›´å¥½åœ°å¯¹é½å›¾åƒå’Œæ–‡æœ¬ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒCRLåœ¨å›¾åƒåˆ†ç±»å’Œæ£€ç´¢ä»»åŠ¡ä¸Šå‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¾‹å¦‚ï¼Œåœ¨åŠ¨ç‰©æ –æ¯åœ°åˆ†ç±»ä»»åŠ¡ä¸Šï¼ŒCRLç›¸æ¯”äºä¼ ç»Ÿçš„é€šç”¨è¡¨ç¤ºå­¦ä¹ æ–¹æ³•ï¼Œå‡†ç¡®ç‡æå‡äº†5%-10%ã€‚æ­¤å¤–ï¼ŒCRLåœ¨é›¶æ ·æœ¬å­¦ä¹ åœºæ™¯ä¸‹ä¹Ÿè¡¨ç°å‡ºè‰²ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ³›åŒ–åˆ°æœªè§è¿‡çš„ä»»åŠ¡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

CRLå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚åœ¨æ™ºèƒ½å®‰é˜²ä¸­ï¼Œå¯ä»¥æ ¹æ®ä¸åŒçš„å®‰å…¨å¨èƒç±»å‹å®šåˆ¶ç‰¹å¾è¡¨ç¤ºï¼›åœ¨åŒ»ç–—å½±åƒåˆ†æä¸­ï¼Œå¯ä»¥æ ¹æ®ä¸åŒçš„ç–¾ç—…ç±»å‹æå–ç›¸å…³ç‰¹å¾ï¼›åœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼Œå¯ä»¥æ ¹æ®ä¸åŒçš„é©¾é©¶åœºæ™¯è°ƒæ•´ç‰¹å¾è¡¨ç¤ºã€‚è¯¥ç ”ç©¶èƒ½å¤Ÿæœ‰æ•ˆé™ä½å¯¹äººå·¥æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œæå‡æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Conventional representation learning methods learn a universal representation that primarily captures dominant semantics, which may not always align with customized downstream tasks. For instance, in animal habitat analysis, researchers prioritize scene-related features, whereas universal embeddings emphasize categorical semantics, leading to suboptimal results. As a solution, existing approaches resort to supervised fine-tuning, which however incurs high computational and annotation costs. In this paper, we propose Conditional Representation Learning (CRL), aiming to extract representations tailored to arbitrary user-specified criteria. Specifically, we reveal that the semantics of a space are determined by its basis, thereby enabling a set of descriptive words to approximate the basis for a customized feature space. Building upon this insight, given a user-specified criterion, CRL first employs a large language model (LLM) to generate descriptive texts to construct the semantic basis, then projects the image representation into this conditional feature space leveraging a vision-language model (VLM). The conditional representation better captures semantics for the specific criterion, which could be utilized for multiple customized tasks. Extensive experiments on classification and retrieval tasks demonstrate the superiority and generality of the proposed CRL. The code is available at https://github.com/XLearning-SCU/2025-NeurIPS-CRL.

