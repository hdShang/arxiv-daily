---
layout: default
title: "Eyes on Target: Gaze-Aware Object Detection in Egocentric Video"
---

# Eyes on Target: Gaze-Aware Object Detection in Egocentric Video

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.01237" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.01237v1</a>
  <a href="https://arxiv.org/pdf/2511.01237.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.01237v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.01237v1', 'Eyes on Target: Gaze-Aware Object Detection in Egocentric Video')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Vishakha Lall, Yisi Liu

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-03

**å¤‡æ³¨**: Accepted at RAAI 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Eyes on Targetï¼šæå‡ºæ·±åº¦æ„ŸçŸ¥å’Œæ³¨è§†å¼•å¯¼çš„ç›®æ ‡æ£€æµ‹æ¡†æ¶ï¼Œç”¨äºä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„è§†é¢‘åˆ†æã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `æ³¨è§†é¢„æµ‹` `ç›®æ ‡æ£€æµ‹` `ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒè§†é¢‘` `è§†è§‰æ³¨æ„åŠ›` `Vision Transformer` `æ·±åº¦å­¦ä¹ ` `äººæœºäº¤äº’`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç›®æ ‡æ£€æµ‹æ–¹æ³•å¿½ç•¥äº†äººçœ¼æ³¨è§†ä¿¡æ¯ï¼Œåœ¨ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„è§†é¢‘ä¸­è¡¨ç°ä¸ä½³ã€‚
2. Eyes on Targetæ¡†æ¶å°†æ³¨è§†ä¿¡æ¯èå…¥ViTçš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œä½¿æ¨¡å‹å…³æ³¨äººçœ¼æ³¨è§†åŒºåŸŸã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå‡ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºâ€œEyes on Targetâ€çš„æ–°å‹æ·±åº¦æ„ŸçŸ¥å’Œæ³¨è§†å¼•å¯¼çš„ç›®æ ‡æ£€æµ‹æ¡†æ¶ï¼Œä¸“ä¸ºä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„è§†é¢‘è®¾è®¡ã€‚è¯¥æ–¹æ³•å°†æ³¨è§†è¡ç”Ÿçš„ç‰¹å¾æ³¨å…¥åˆ°Vision Transformer (ViT)çš„æ³¨æ„åŠ›æœºåˆ¶ä¸­ï¼Œæœ‰æ•ˆåœ°å°†ç©ºé—´ç‰¹å¾é€‰æ‹©åå‘äºäººçœ¼å…³æ³¨çš„åŒºåŸŸã€‚ä¸ä¼ ç»Ÿçš„ç›®æ ‡æ£€æµ‹å™¨å¹³ç­‰å¯¹å¾…æ‰€æœ‰åŒºåŸŸä¸åŒï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¼ºè°ƒè§‚å¯Ÿè€…ä¼˜å…ˆè€ƒè™‘çš„åŒºåŸŸï¼Œä»¥å¢å¼ºç›®æ ‡æ£€æµ‹æ•ˆæœã€‚æˆ‘ä»¬åœ¨ä¸€ä¸ªä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„æ¨¡æ‹Ÿå™¨æ•°æ®é›†ä¸ŠéªŒè¯äº†è¯¥æ–¹æ³•ï¼Œå…¶ä¸­äººç±»è§†è§‰æ³¨æ„åŠ›å¯¹äºä»»åŠ¡è¯„ä¼°è‡³å…³é‡è¦ï¼Œå±•ç¤ºäº†å…¶åœ¨è¯„ä¼°æ¨¡æ‹Ÿåœºæ™¯ä¸­äººç±»è¡¨ç°æ–¹é¢çš„æ½œåŠ›ã€‚é€šè¿‡å¤§é‡çš„å®éªŒå’Œæ¶ˆèç ”ç©¶ï¼Œæˆ‘ä»¬è¯„ä¼°äº†é›†æˆæ³¨è§†ä¿¡æ¯çš„æ¨¡å‹çš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜äº†åœ¨è‡ªå®šä¹‰æ¨¡æ‹Ÿå™¨æ•°æ®é›†å’Œå…¬å…±åŸºå‡†ï¼ˆåŒ…æ‹¬Ego4D Ego-Motionå’ŒEgo-CH-Gazeæ•°æ®é›†ï¼‰ä¸Šï¼Œæ£€æµ‹ç²¾åº¦ç›¸å¯¹äºä¸æ³¨è§†æ— å…³çš„åŸºçº¿å§‹ç»ˆæœ‰æ‰€æé«˜ã€‚ä¸ºäº†è§£é‡Šæ¨¡å‹çš„è¡Œä¸ºï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ç§æ³¨è§†æ„ŸçŸ¥çš„æ³¨æ„åŠ›å¤´é‡è¦æ€§åº¦é‡ï¼Œæ­ç¤ºäº†æ³¨è§†çº¿ç´¢å¦‚ä½•è°ƒèŠ‚Transformerçš„æ³¨æ„åŠ›åŠ¨æ€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„ç›®æ ‡æ£€æµ‹æ–¹æ³•é€šå¸¸å¹³ç­‰åœ°å¯¹å¾…å›¾åƒæˆ–è§†é¢‘ä¸­çš„æ‰€æœ‰åŒºåŸŸï¼Œè€Œå¿½ç•¥äº†äººç±»è§†è§‰æ³¨æ„åŠ›çš„é‡è¦æ€§ã€‚åœ¨ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„è§†é¢‘ä¸­ï¼Œäººç±»çš„æ³¨è§†ç‚¹å¾€å¾€é›†ä¸­åœ¨ä¸å½“å‰ä»»åŠ¡ç›¸å…³çš„å¯¹è±¡æˆ–åŒºåŸŸä¸Šã€‚å› æ­¤ï¼Œå¦‚ä½•æœ‰æ•ˆåœ°åˆ©ç”¨äººç±»çš„æ³¨è§†ä¿¡æ¯æ¥æé«˜ç›®æ ‡æ£€æµ‹çš„å‡†ç¡®æ€§å’Œæ•ˆç‡æ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šEyes on Targetçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†äººç±»çš„æ³¨è§†ä¿¡æ¯ä½œä¸ºä¸€ç§å…ˆéªŒçŸ¥è¯†ï¼Œå¼•å¯¼ç›®æ ‡æ£€æµ‹æ¨¡å‹æ›´åŠ å…³æ³¨äººçœ¼æ³¨è§†çš„åŒºåŸŸã€‚é€šè¿‡å°†æ³¨è§†è¡ç”Ÿçš„ç‰¹å¾èå…¥åˆ°Vision Transformer (ViT)çš„æ³¨æ„åŠ›æœºåˆ¶ä¸­ï¼Œæ¨¡å‹å¯ä»¥æ›´å¥½åœ°é€‰æ‹©ä¸ä»»åŠ¡ç›¸å…³çš„ç©ºé—´ç‰¹å¾ï¼Œä»è€Œæé«˜ç›®æ ‡æ£€æµ‹çš„æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEyes on Targetæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) æ³¨è§†ç‰¹å¾æå–æ¨¡å—ï¼šä»æ³¨è§†æ•°æ®ä¸­æå–æœ‰ç”¨çš„ç‰¹å¾ï¼Œä¾‹å¦‚æ³¨è§†ä½ç½®ã€æ³¨è§†æŒç»­æ—¶é—´ç­‰ã€‚2) æ·±åº¦æ„ŸçŸ¥æ¨¡å—ï¼šåˆ©ç”¨æ·±åº¦ä¿¡æ¯æ¥å¢å¼ºå¯¹åœºæ™¯çš„ç†è§£ï¼Œå¹¶å¸®åŠ©æ¨¡å‹æ›´å¥½åœ°å®šä½ç›®æ ‡ã€‚3) æ³¨è§†å¼•å¯¼çš„æ³¨æ„åŠ›æœºåˆ¶ï¼šå°†æ³¨è§†ç‰¹å¾å’Œæ·±åº¦ä¿¡æ¯æ³¨å…¥åˆ°ViTçš„æ³¨æ„åŠ›æœºåˆ¶ä¸­ï¼Œå¼•å¯¼æ¨¡å‹å…³æ³¨äººçœ¼æ³¨è§†çš„åŒºåŸŸã€‚4) ç›®æ ‡æ£€æµ‹æ¨¡å—ï¼šåˆ©ç”¨ViTæå–çš„ç‰¹å¾è¿›è¡Œç›®æ ‡æ£€æµ‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†æ³¨è§†ä¿¡æ¯æœ‰æ•ˆåœ°èå…¥åˆ°Vision Transformerçš„æ³¨æ„åŠ›æœºåˆ¶ä¸­ã€‚ä¸ä¼ ç»Ÿçš„æ³¨æ„åŠ›æœºåˆ¶ä¸åŒï¼Œè¯¥æ–¹æ³•ä¸ä»…ä»…å…³æ³¨å›¾åƒæˆ–è§†é¢‘æœ¬èº«çš„å†…å®¹ï¼Œè¿˜è€ƒè™‘äº†äººç±»çš„è§†è§‰æ³¨æ„åŠ›ï¼Œä»è€Œä½¿æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£åœºæ™¯å¹¶æé«˜ç›®æ ‡æ£€æµ‹çš„å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œå¼•å…¥äº†æ·±åº¦æ„ŸçŸ¥æ¨¡å—ï¼Œè¿›ä¸€æ­¥æå‡äº†æ¨¡å‹å¯¹ä¸‰ç»´åœºæ™¯çš„ç†è§£èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­å…³é”®çš„è®¾è®¡åŒ…æ‹¬ï¼š1) å¦‚ä½•æœ‰æ•ˆåœ°æå–å’Œè¡¨ç¤ºæ³¨è§†ç‰¹å¾ï¼›2) å¦‚ä½•å°†æ³¨è§†ç‰¹å¾å’Œæ·±åº¦ä¿¡æ¯èå…¥åˆ°ViTçš„æ³¨æ„åŠ›æœºåˆ¶ä¸­ï¼›3) å¦‚ä½•è®¾è®¡æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ¨¡å‹çš„æ€§èƒ½ã€‚å…·ä½“çš„æŠ€æœ¯ç»†èŠ‚åŒ…æ‹¬æ³¨è§†ç‰¹å¾çš„ç¼–ç æ–¹å¼ã€æ³¨æ„åŠ›æœºåˆ¶çš„èåˆç­–ç•¥ä»¥åŠæŸå¤±å‡½æ•°çš„é€‰æ‹©ç­‰ã€‚è®ºæ–‡è¿˜æå‡ºäº†ä¸€ç§æ³¨è§†æ„ŸçŸ¥çš„æ³¨æ„åŠ›å¤´é‡è¦æ€§åº¦é‡ï¼Œç”¨äºè§£é‡Šæ¨¡å‹è¡Œä¸ºã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒEyes on Targetæ¡†æ¶åœ¨è‡ªå®šä¹‰æ¨¡æ‹Ÿå™¨æ•°æ®é›†å’Œå…¬å…±åŸºå‡†ï¼ˆåŒ…æ‹¬Ego4D Ego-Motionå’ŒEgo-CH-Gazeæ•°æ®é›†ï¼‰ä¸Šï¼Œæ£€æµ‹ç²¾åº¦ç›¸å¯¹äºä¸æ³¨è§†æ— å…³çš„åŸºçº¿å§‹ç»ˆæœ‰æ‰€æé«˜ã€‚å…·ä½“è€Œè¨€ï¼Œåœ¨Ego4Dæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•åœ¨ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºäººæœºäº¤äº’ã€æœºå™¨äººå¯¼èˆªã€æ™ºèƒ½è¾…åŠ©é©¾é©¶ç­‰é¢†åŸŸã€‚é€šè¿‡ç†è§£äººç±»çš„è§†è§‰æ³¨æ„åŠ›ï¼Œæœºå™¨å¯ä»¥æ›´å¥½åœ°ä¸äººç±»è¿›è¡Œåä½œï¼Œæé«˜å·¥ä½œæ•ˆç‡å’Œå®‰å…¨æ€§ã€‚ä¾‹å¦‚ï¼Œåœ¨æ™ºèƒ½è¾…åŠ©é©¾é©¶ä¸­ï¼Œç³»ç»Ÿå¯ä»¥æ ¹æ®é©¾é©¶å‘˜çš„æ³¨è§†ç‚¹æ¥é¢„æµ‹å…¶è¡Œä¸ºï¼Œå¹¶åŠæ—¶å‘å‡ºè­¦å‘Šæˆ–é‡‡å–æªæ–½ï¼Œä»è€Œé¿å…äº¤é€šäº‹æ•…çš„å‘ç”Ÿã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Human gaze offers rich supervisory signals for understanding visual attention in complex visual environments. In this paper, we propose Eyes on Target, a novel depth-aware and gaze-guided object detection framework designed for egocentric videos. Our approach injects gaze-derived features into the attention mechanism of a Vision Transformer (ViT), effectively biasing spatial feature selection toward human-attended regions. Unlike traditional object detectors that treat all regions equally, our method emphasises viewer-prioritised areas to enhance object detection. We validate our method on an egocentric simulator dataset where human visual attention is critical for task assessment, illustrating its potential in evaluating human performance in simulation scenarios. We evaluate the effectiveness of our gaze-integrated model through extensive experiments and ablation studies, demonstrating consistent gains in detection accuracy over gaze-agnostic baselines on both the custom simulator dataset and public benchmarks, including Ego4D Ego-Motion and Ego-CH-Gaze datasets. To interpret model behaviour, we also introduce a gaze-aware attention head importance metric, revealing how gaze cues modulate transformer attention dynamics.

