---
layout: default
title: "DINO-MX: A Modular & Flexible Framework for Self-Supervised Learning"
---

# DINO-MX: A Modular & Flexible Framework for Self-Supervised Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.01610" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.01610v1</a>
  <a href="https://arxiv.org/pdf/2511.01610.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.01610v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.01610v1', 'DINO-MX: A Modular & Flexible Framework for Self-Supervised Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mahmut Selman Gokmen, Cody Bumgardner

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-03

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**DINO-MXï¼šä¸€ä¸ªæ¨¡å—åŒ–è‡ªç›‘ç£å­¦ä¹ æ¡†æ¶ï¼Œé™ä½è®¡ç®—æˆæœ¬å¹¶æå‡çµæ´»æ€§ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `è‡ªç›‘ç£å­¦ä¹ ` `è§†è§‰åŸºç¡€æ¨¡å‹` `æ¨¡å—åŒ–æ¡†æ¶` `çŸ¥è¯†è’¸é¦` `åˆ†å¸ƒå¼è®­ç»ƒ` `Transformer` `è¡¨å¾å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è‡ªç›‘ç£å­¦ä¹ è®­ç»ƒæµç¨‹ç¼ºä¹çµæ´»æ€§ï¼Œè®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œé™åˆ¶äº†å…¶åœ¨ä¸åŒé¢†åŸŸå’Œèµ„æºç¯å¢ƒä¸‹çš„åº”ç”¨ã€‚
2. DINO-MXæ¡†æ¶é€šè¿‡æ¨¡å—åŒ–è®¾è®¡ï¼Œç»Ÿä¸€äº†DINOç³»åˆ—ç®—æ³•ï¼Œå¹¶æ”¯æŒå¤šç§è®­ç»ƒç­–ç•¥ï¼Œé™ä½è®¡ç®—æˆæœ¬ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒDINO-MXåœ¨é™ä½è®¡ç®—æˆæœ¬çš„åŒæ—¶ï¼Œä¿æŒäº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼Œå¹¶æä¾›äº†å¯è§£é‡Šæ€§å·¥å…·ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰åŸºç¡€æ¨¡å‹(VFMs)é€šè¿‡è‡ªç›‘ç£æ–¹æ³•æ˜¾è‘—æå‡äº†è¡¨å¾å­¦ä¹ ã€‚ç„¶è€Œï¼Œç°æœ‰çš„è®­ç»ƒæµç¨‹é€šå¸¸ç¼ºä¹çµæ´»æ€§ï¼Œé¢†åŸŸé’ˆå¯¹æ€§å¼ºï¼Œæˆ–è®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œé™åˆ¶äº†å®ƒä»¬åœ¨ä¸åŒé¢†åŸŸå’Œèµ„æºç¯å¢ƒä¸‹çš„å¯ç”¨æ€§ã€‚DINO-MXæ˜¯ä¸€ä¸ªæ¨¡å—åŒ–å’Œå¯æ‰©å±•çš„è®­ç»ƒæ¡†æ¶ï¼Œå®ƒåœ¨ä¸€ä¸ªç»Ÿä¸€çš„é…ç½®é©±åŠ¨ç³»ç»Ÿä¸­ç»“åˆäº†DINOã€DINOv2å’ŒDINOv3çš„æ ¸å¿ƒåŸåˆ™ã€‚å®ƒæ”¯æŒå„ç§åŸºäºTransformerçš„æ¶æ„ï¼Œå¹¶ä¸”å®Œå…¨å…¼å®¹Hugging Faceç”Ÿæ€ç³»ç»Ÿã€‚è¯¥æ¡†æ¶åŒ…æ‹¬å¤šç§è®­ç»ƒç­–ç•¥ï¼Œå¦‚ä½ç§©é€‚åº”(LoRA)ã€å±‚å†»ç»“å’ŒçŸ¥è¯†è’¸é¦ï¼Œä»¥åŠé€šè¿‡åˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œ(DDP)å’Œå®Œå…¨åˆ†ç‰‡æ•°æ®å¹¶è¡Œ(FSDP)å¯¹åˆ†å¸ƒå¼è®­ç»ƒçš„æ”¯æŒã€‚DINO-MXæ—¨åœ¨å¤„ç†è‡ªç„¶å’Œä¸“é—¨çš„æ•°æ®ç±»å‹ï¼ŒåŒ…æ‹¬å•é€šé“å’Œå¤šé€šé“å›¾åƒã€‚åœ¨ä¸åŒæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒDINO-MXåœ¨æ˜¾è‘—é™ä½è®¡ç®—æˆæœ¬çš„åŒæ—¶ï¼Œå®ç°äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜æä¾›äº†å¯è§£é‡Šæ€§å·¥å…·å’Œæ ‡ç­¾å¼•å¯¼çš„æ•°æ®å¢å¼ºæ–¹æ³•ï¼Œå¯ä»¥åœ¨ä¸éœ€è¦é¢å¤–çš„æ£€æµ‹æˆ–åˆ†å‰²å¤´çš„æƒ…å†µä¸‹æ”¹è¿›åŸºäºæ³¨æ„åŠ›çš„å®šä½ã€‚DINO-MXä¸ºåœ¨å„ç§ç ”ç©¶å’Œå®é™…åº”ç”¨ä¸­å¼€å‘ã€è°ƒæ•´å’ŒåŸºå‡†æµ‹è¯•è‡ªç›‘ç£è§†è§‰æ¨¡å‹æä¾›äº†ä¸€ä¸ªå¯å¤ç°å’Œå¯æ‰©å±•çš„åŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰è§†è§‰è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œå¦‚DINOç³»åˆ—ï¼Œè™½ç„¶æ•ˆæœæ˜¾è‘—ï¼Œä½†è®­ç»ƒæµç¨‹é€šå¸¸è¾ƒä¸ºå›ºå®šï¼Œéš¾ä»¥çµæ´»è°ƒæ•´ä»¥é€‚åº”ä¸åŒé¢†åŸŸå’Œè®¡ç®—èµ„æºã€‚é«˜æ˜‚çš„è®¡ç®—æˆæœ¬ä¹Ÿé™åˆ¶äº†å…¶åº”ç”¨èŒƒå›´ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ä¸ªæ›´åŠ çµæ´»ã€é«˜æ•ˆä¸”æ˜“äºæ‰©å±•çš„è‡ªç›‘ç£å­¦ä¹ æ¡†æ¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDINO-MXçš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªæ¨¡å—åŒ–çš„è®­ç»ƒæ¡†æ¶ï¼Œå°†DINOã€DINOv2å’ŒDINOv3ç­‰ç®—æ³•çš„æ ¸å¿ƒç»„ä»¶è¿›è¡Œè§£è€¦ï¼Œå¹¶é€šè¿‡ç»Ÿä¸€çš„é…ç½®ç³»ç»Ÿè¿›è¡Œç®¡ç†ã€‚è¿™ç§è®¾è®¡ä½¿å¾—ç”¨æˆ·å¯ä»¥æ ¹æ®è‡ªèº«éœ€æ±‚çµæ´»é€‰æ‹©å’Œç»„åˆä¸åŒçš„ç»„ä»¶ï¼Œä»è€Œå®šåˆ¶å‡ºæœ€é€‚åˆç‰¹å®šä»»åŠ¡çš„è®­ç»ƒæµç¨‹ã€‚åŒæ—¶ï¼Œæ¡†æ¶æ”¯æŒå¤šç§ä¼˜åŒ–ç­–ç•¥ï¼Œå¦‚LoRAã€å±‚å†»ç»“ç­‰ï¼Œä»¥é™ä½è®¡ç®—æˆæœ¬ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDINO-MXçš„æ•´ä½“æ¶æ„æ˜¯ä¸€ä¸ªé…ç½®é©±åŠ¨çš„ç³»ç»Ÿï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡é…ç½®æ–‡ä»¶æŒ‡å®šè®­ç»ƒæµç¨‹çš„å„ä¸ªç¯èŠ‚ï¼ŒåŒ…æ‹¬æ•°æ®åŠ è½½ã€æ¨¡å‹é€‰æ‹©ã€ä¼˜åŒ–å™¨è®¾ç½®ã€è®­ç»ƒç­–ç•¥ç­‰ã€‚æ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹æ¨¡å—ï¼šæ•°æ®å¤„ç†æ¨¡å—ï¼ˆæ”¯æŒå•é€šé“å’Œå¤šé€šé“å›¾åƒï¼‰ã€æ¨¡å‹æ¨¡å—ï¼ˆæ”¯æŒå¤šç§Transformeræ¶æ„ï¼‰ã€è®­ç»ƒç­–ç•¥æ¨¡å—ï¼ˆåŒ…æ‹¬LoRAã€å±‚å†»ç»“ã€çŸ¥è¯†è’¸é¦ç­‰ï¼‰ã€åˆ†å¸ƒå¼è®­ç»ƒæ¨¡å—ï¼ˆæ”¯æŒDDPå’ŒFSDPï¼‰ã€‚

**å…³é”®åˆ›æ–°**ï¼šDINO-MXçš„å…³é”®åˆ›æ–°åœ¨äºå…¶æ¨¡å—åŒ–å’Œå¯æ‰©å±•çš„è®¾è®¡ã€‚å®ƒå°†DINOç³»åˆ—ç®—æ³•çš„æ ¸å¿ƒç»„ä»¶è¿›è¡Œè§£è€¦ï¼Œå¹¶é€šè¿‡ç»Ÿä¸€çš„é…ç½®ç³»ç»Ÿè¿›è¡Œç®¡ç†ï¼Œä½¿å¾—ç”¨æˆ·å¯ä»¥çµæ´»å®šåˆ¶è®­ç»ƒæµç¨‹ã€‚æ­¤å¤–ï¼Œæ¡†æ¶è¿˜æä¾›äº†å¯è§£é‡Šæ€§å·¥å…·å’Œæ ‡ç­¾å¼•å¯¼çš„æ•°æ®å¢å¼ºæ–¹æ³•ï¼Œå¯ä»¥åœ¨ä¸éœ€è¦é¢å¤–æ£€æµ‹æˆ–åˆ†å‰²å¤´çš„æƒ…å†µä¸‹æ”¹è¿›åŸºäºæ³¨æ„åŠ›çš„å®šä½ã€‚

**å…³é”®è®¾è®¡**ï¼šDINO-MXçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ç»Ÿä¸€çš„é…ç½®æ–‡ä»¶ï¼Œç”¨äºç®¡ç†è®­ç»ƒæµç¨‹çš„å„ä¸ªç¯èŠ‚ï¼›2) æ¨¡å—åŒ–çš„ç»„ä»¶è®¾è®¡ï¼Œæ–¹ä¾¿ç”¨æˆ·è¿›è¡Œå®šåˆ¶å’Œæ‰©å±•ï¼›3) å¯¹å¤šç§è®­ç»ƒç­–ç•¥çš„æ”¯æŒï¼Œå¦‚LoRAã€å±‚å†»ç»“ç­‰ï¼Œä»¥é™ä½è®¡ç®—æˆæœ¬ï¼›4) å¯¹åˆ†å¸ƒå¼è®­ç»ƒçš„æ”¯æŒï¼ŒåŒ…æ‹¬DDPå’ŒFSDPï¼›5) æ ‡ç­¾å¼•å¯¼çš„æ•°æ®å¢å¼ºæ–¹æ³•ï¼Œç”¨äºæ”¹è¿›åŸºäºæ³¨æ„åŠ›çš„å®šä½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

DINO-MXåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼ŒåŒæ—¶æ˜¾è‘—é™ä½äº†è®¡ç®—æˆæœ¬ã€‚ä¾‹å¦‚ï¼Œåœ¨ImageNetæ•°æ®é›†ä¸Šï¼Œä½¿ç”¨DINO-MXè®­ç»ƒçš„æ¨¡å‹åœ¨ä¿æŒç›¸ä¼¼æ€§èƒ½çš„åŒæ—¶ï¼Œå¯ä»¥å°†è®­ç»ƒæ—¶é—´ç¼©çŸ­è‡³åŸæ¥çš„å‡ åˆ†ä¹‹ä¸€ã€‚æ­¤å¤–ï¼ŒDINO-MXæä¾›çš„å¯è§£é‡Šæ€§å·¥å…·å’Œæ ‡ç­¾å¼•å¯¼çš„æ•°æ®å¢å¼ºæ–¹æ³•ï¼Œå¯ä»¥åœ¨ä¸éœ€è¦é¢å¤–æ£€æµ‹æˆ–åˆ†å‰²å¤´çš„æƒ…å†µä¸‹æ”¹è¿›åŸºäºæ³¨æ„åŠ›çš„å®šä½ï¼Œè¿›ä¸€æ­¥æå‡äº†æ¨¡å‹çš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

DINO-MXæ¡†æ¶å¯å¹¿æ³›åº”ç”¨äºè®¡ç®—æœºè§†è§‰é¢†åŸŸçš„å„ç§è‡ªç›‘ç£å­¦ä¹ ä»»åŠ¡ï¼Œä¾‹å¦‚å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ã€è¯­ä¹‰åˆ†å‰²ç­‰ã€‚å®ƒå°¤å…¶é€‚ç”¨äºèµ„æºå—é™çš„ç¯å¢ƒï¼Œä¾‹å¦‚ç§»åŠ¨è®¾å¤‡æˆ–åµŒå…¥å¼ç³»ç»Ÿã€‚è¯¥æ¡†æ¶çš„æ¨¡å—åŒ–è®¾è®¡å’Œå¯æ‰©å±•æ€§ä½¿å…¶èƒ½å¤Ÿè½»æ¾é€‚åº”æ–°çš„æ•°æ®é›†å’Œæ¨¡å‹æ¶æ„ï¼Œä»è€ŒåŠ é€Ÿè‡ªç›‘ç£å­¦ä¹ ç®—æ³•çš„å¼€å‘å’Œéƒ¨ç½²ã€‚æœªæ¥ï¼ŒDINO-MXæœ‰æœ›æˆä¸ºè§†è§‰åŸºç¡€æ¨¡å‹ç ”ç©¶çš„é‡è¦å·¥å…·ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision Foundation Models (VFMs) have advanced representation learning through self-supervised methods. However, existing training pipelines are often inflexible, domain-specific, or computationally expensive, which limits their usability across different domains and resource settings. DINO-MX is a modular and extensible training framework that combines the core principles of DINO, DINOv2 and DINOv3 within a unified configuration-driven system. It supports a variety of transformer-based architectures and is fully compatible with the Hugging Face ecosystem. The framework includes multiple training strategies such as low-rank adaptation (LoRA), layer freezing, and knowledge distillation, along with support for distributed training through both Distributed Data Parallel (DDP) and Fully Sharded Data Parallel (FSDP). DINO-MX is designed to work with both natural and specialized data types, including single- and multi-channel images. Experimental results on diverse datasets show that DINO-MX achieves competitive performance while significantly reducing computational costs. Additionally, it offers interpretability tools and a label-guided data augmentation method that improves attention-based localization without the need for extra detection or segmentation heads. DINO-MX provides a reproducible and scalable foundation for developing, adapting, and benchmarking self-supervised vision models across a range of research and real-world applications.

