---
layout: default
title: "TIR-Bench: A Comprehensive Benchmark for Agentic Thinking-with-Images Reasoning"
---

# TIR-Bench: A Comprehensive Benchmark for Agentic Thinking-with-Images Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.01833" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.01833v2</a>
  <a href="https://arxiv.org/pdf/2511.01833.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.01833v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.01833v2', 'TIR-Bench: A Comprehensive Benchmark for Agentic Thinking-with-Images Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ming Li, Jike Zhong, Shitian Zhao, Haoquan Zhang, Shaoheng Lin, Yuxiang Lai, Chen Wei, Konstantinos Psounis, Kaipeng Zhang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-03 (æ›´æ–°: 2025-11-05)

**å¤‡æ³¨**: Preprint

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTIR-Benchï¼Œç”¨äºè¯„ä¼°Agenticå›¾åƒæ¨ç†ä¸­æ¨¡å‹åˆ©ç”¨å·¥å…·è¿›è¡Œå›¾åƒå¤„ç†çš„èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `Agenticå›¾åƒæ¨ç†` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `è§†è§‰æ¨ç†` `åŸºå‡†æµ‹è¯•` `å·¥å…·ä½¿ç”¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰æ¨ç†åŸºå‡†æµ‹è¯•æ— æ³•å……åˆ†è¯„ä¼°æ¨¡å‹åˆ©ç”¨å·¥å…·è¿›è¡Œå¤æ‚å›¾åƒå¤„ç†å’Œæ“ä½œçš„èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨æ€ç»´é“¾ä¸­ã€‚
2. TIR-Benché€šè¿‡13ä¸ªéœ€è¦æ–°å‹å·¥å…·ä½¿ç”¨çš„å›¾åƒå¤„ç†ä»»åŠ¡ï¼Œå…¨é¢è¯„ä¼°Agenticå›¾åƒæ¨ç†èƒ½åŠ›ï¼Œå¼¥è¡¥äº†ç°æœ‰åŸºå‡†çš„ä¸è¶³ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒTIR-Benchå¯¹ç°æœ‰æ¨¡å‹å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå¹¶åˆæ­¥ç ”ç©¶äº†ç›´æ¥å¾®è°ƒä¸Agenticå¾®è°ƒçš„å·®å¼‚ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰æ¨ç†çš„å‰æ²¿æ­£åœ¨è½¬å‘åƒOpenAI o3è¿™æ ·çš„æ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹å¯ä»¥æ™ºèƒ½åœ°åˆ›å»ºå’Œæ“ä½œå·¥å…·æ¥è½¬æ¢å›¾åƒä»¥è§£å†³é—®é¢˜ï¼Œå³åœ¨æ€ç»´é“¾ä¸­è¿›è¡Œâ€œå›¾åƒæ€è€ƒâ€ã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŸºå‡†æµ‹è¯•æœªèƒ½å®Œå…¨æ•æ‰åˆ°è¿™ç§é«˜çº§èƒ½åŠ›ã€‚å³ä½¿æ˜¯è§†è§‰æœç´¢ï¼Œä½œä¸ºå½“å‰â€œå›¾åƒæ€è€ƒâ€æ–¹æ³•æœ€å¸¸è§çš„åŸºå‡†æµ‹è¯•ï¼Œä¹Ÿåªæµ‹è¯•äº†è¯¸å¦‚å®šä½å’Œè£å‰ªç­‰åŸºæœ¬æ“ä½œï¼Œå¯¹äºæ›´å¤æ‚ã€åŠ¨æ€å’Œä¾èµ–äºå·¥å…·çš„æ¨ç†å‡ ä¹æ²¡æœ‰æä¾›ä»»ä½•è§è§£ã€‚æˆ‘ä»¬å¼•å…¥äº†TIR-Benchï¼Œè¿™æ˜¯ä¸€ä¸ªå…¨é¢çš„åŸºå‡†æµ‹è¯•ï¼Œç”¨äºè¯„ä¼°Agenticå›¾åƒæ¨ç†ï¼Œæ¶µç›–13ä¸ªä¸åŒçš„ä»»åŠ¡ï¼Œæ¯ä¸ªä»»åŠ¡éƒ½éœ€è¦ä½¿ç”¨æ–°çš„å·¥å…·åœ¨æ€ç»´é“¾ä¸­è¿›è¡Œå›¾åƒå¤„ç†å’Œæ“ä½œã€‚æˆ‘ä»¬è¯„ä¼°äº†22ä¸ªå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ï¼Œä»é¢†å…ˆçš„å¼€æºå’Œä¸“æœ‰æ¨¡å‹åˆ°é‚£äº›å…·æœ‰æ˜¾å¼å·¥å…·ä½¿ç”¨å¢å¼ºçš„æ¨¡å‹ã€‚ç»“æœè¡¨æ˜ï¼ŒTIR-Benchå…·æœ‰æ™®éçš„æŒ‘æˆ˜æ€§ï¼Œå¹¶ä¸”å¼ºå¤§çš„æ€§èƒ½éœ€è¦çœŸæ­£çš„å›¾åƒæ€è€ƒèƒ½åŠ›ã€‚æœ€åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ¯”è¾ƒç›´æ¥å¾®è°ƒä¸Agenticå¾®è°ƒçš„åˆæ­¥ç ”ç©¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰è§†è§‰æ¨ç†åŸºå‡†ï¼Œå¦‚è§†è§‰æœç´¢ï¼Œä¸»è¦æµ‹è¯•å®šä½å’Œè£å‰ªç­‰åŸºæœ¬æ“ä½œï¼Œæ— æ³•å……åˆ†è¯„ä¼°æ¨¡å‹åœ¨å¤æ‚ã€åŠ¨æ€å’Œå·¥å…·ä¾èµ–åœºæ™¯ä¸‹çš„â€œå›¾åƒæ€è€ƒâ€èƒ½åŠ›ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥æ¨¡æ‹Ÿäººç±»åˆ©ç”¨å·¥å…·è¿›è¡Œå›¾åƒå¤„ç†å’Œæ“ä½œä»¥è§£å†³é—®é¢˜çš„è¿‡ç¨‹ï¼Œç¼ºä¹å¯¹Agenticå›¾åƒæ¨ç†èƒ½åŠ›çš„æœ‰æ•ˆè¯„ä¼°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šTIR-Benchçš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªåŒ…å«å¤šæ ·åŒ–ä»»åŠ¡çš„åŸºå‡†æµ‹è¯•ï¼Œæ¯ä¸ªä»»åŠ¡éƒ½éœ€è¦æ¨¡å‹åˆ©ç”¨ç‰¹å®šçš„å›¾åƒå¤„ç†å·¥å…·ï¼Œå¹¶åœ¨æ€ç»´é“¾ä¸­è¿›è¡Œæ¨ç†ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå¯ä»¥æ›´å…¨é¢åœ°è¯„ä¼°æ¨¡å‹åœ¨å¤æ‚åœºæ™¯ä¸‹åˆ©ç”¨å·¥å…·è¿›è¡Œå›¾åƒæ“ä½œå’Œæ¨ç†çš„èƒ½åŠ›ï¼Œä»è€Œæ¨åŠ¨Agenticå›¾åƒæ¨ç†é¢†åŸŸçš„å‘å±•ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTIR-BenchåŒ…å«13ä¸ªä¸åŒçš„ä»»åŠ¡ï¼Œæ¯ä¸ªä»»åŠ¡éƒ½è®¾è®¡ä¸ºéœ€è¦ä½¿ç”¨ç‰¹å®šçš„å›¾åƒå¤„ç†å·¥å…·ã€‚æ¨¡å‹éœ€è¦é¦–å…ˆç†è§£ä»»åŠ¡ç›®æ ‡ï¼Œç„¶åé€‰æ‹©åˆé€‚çš„å·¥å…·ï¼Œå¹¶æŒ‰ç…§ä¸€å®šçš„æ­¥éª¤æ‰§è¡Œå›¾åƒå¤„ç†æ“ä½œï¼Œæœ€ç»ˆå¾—åˆ°ç»“æœã€‚æ•´ä¸ªè¿‡ç¨‹æ¨¡æ‹Ÿäº†äººç±»åˆ©ç”¨å·¥å…·è§£å†³é—®é¢˜çš„æ€ç»´è¿‡ç¨‹ã€‚åŸºå‡†æµ‹è¯•è¿˜æä¾›äº†ä¸€å¥—è¯„ä¼°æŒ‡æ ‡ï¼Œç”¨äºè¡¡é‡æ¨¡å‹åœ¨ä¸åŒä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šTIR-Benchçš„å…³é”®åˆ›æ–°åœ¨äºå…¶ä»»åŠ¡çš„å¤šæ ·æ€§å’Œå¯¹å·¥å…·ä½¿ç”¨çš„å¼ºè°ƒã€‚ä¸ç°æœ‰åŸºå‡†æµ‹è¯•ç›¸æ¯”ï¼ŒTIR-Benchçš„ä»»åŠ¡æ›´åŠ å¤æ‚ï¼Œéœ€è¦æ¨¡å‹å…·å¤‡æ›´å¼ºçš„æ¨ç†èƒ½åŠ›å’Œå·¥å…·ä½¿ç”¨èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒTIR-Benchè¿˜å¼•å…¥äº†Agenticå¾®è°ƒçš„æ¦‚å¿µï¼Œæ¢ç´¢å¦‚ä½•é€šè¿‡å¾®è°ƒæ¥æé«˜æ¨¡å‹åœ¨å·¥å…·ä½¿ç”¨æ–¹é¢çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šTIR-Benchçš„ä»»åŠ¡è®¾è®¡æ¶µç›–äº†å¤šç§å›¾åƒå¤„ç†æ“ä½œï¼Œä¾‹å¦‚å›¾åƒç¼–è¾‘ã€å›¾åƒå¢å¼ºã€å›¾åƒä¿®å¤ç­‰ã€‚æ¯ä¸ªä»»åŠ¡éƒ½é…å¤‡äº†ç›¸åº”çš„å·¥å…·ï¼Œæ¨¡å‹éœ€è¦å­¦ä¹ å¦‚ä½•ä½¿ç”¨è¿™äº›å·¥å…·æ¥å®Œæˆä»»åŠ¡ã€‚åŸºå‡†æµ‹è¯•è¿˜è€ƒè™‘äº†ä»»åŠ¡çš„éš¾åº¦ï¼Œä»ç®€å•åˆ°å¤æ‚ï¼Œé€æ­¥æé«˜å¯¹æ¨¡å‹çš„è¦æ±‚ã€‚è¯„ä¼°æŒ‡æ ‡åŒ…æ‹¬ä»»åŠ¡å®Œæˆç‡ã€å‡†ç¡®ç‡ç­‰ï¼Œç”¨äºå…¨é¢è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

TIR-Benchè¯„ä¼°äº†22ä¸ªå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œç»“æœè¡¨æ˜è¯¥åŸºå‡†æµ‹è¯•å…·æœ‰æ™®éçš„æŒ‘æˆ˜æ€§ï¼Œéœ€è¦æ¨¡å‹å…·å¤‡çœŸæ­£çš„å›¾åƒæ€è€ƒèƒ½åŠ›ã€‚åˆæ­¥ç ”ç©¶è¡¨æ˜ï¼ŒAgenticå¾®è°ƒå¯èƒ½ä¼˜äºç›´æ¥å¾®è°ƒï¼Œä¸ºæœªæ¥çš„æ¨¡å‹è®­ç»ƒæä¾›äº†æ–°çš„æ–¹å‘ã€‚å…·ä½“æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿æœªåœ¨æ‘˜è¦ä¸­ç»™å‡ºï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

TIR-Benchçš„ç ”ç©¶æˆæœå¯åº”ç”¨äºæ™ºèƒ½å›¾åƒç¼–è¾‘ã€è‡ªåŠ¨åŒ–å›¾åƒä¿®å¤ã€è§†è§‰è¾…åŠ©å·¥å…·ç­‰é¢†åŸŸã€‚é€šè¿‡æå‡æ¨¡å‹åˆ©ç”¨å·¥å…·è¿›è¡Œå›¾åƒæ¨ç†çš„èƒ½åŠ›ï¼Œå¯ä»¥å¼€å‘å‡ºæ›´æ™ºèƒ½ã€æ›´é«˜æ•ˆçš„å›¾åƒå¤„ç†ç³»ç»Ÿï¼Œä¸ºç”¨æˆ·æä¾›æ›´å¥½çš„ä½“éªŒï¼Œå¹¶æ¨åŠ¨è®¡ç®—æœºè§†è§‰æŠ€æœ¯åœ¨å®é™…åœºæ™¯ä¸­çš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The frontier of visual reasoning is shifting toward models like OpenAI o3, which can intelligently create and operate tools to transform images for problem-solving, also known as thinking-\textit{with}-images in chain-of-thought. Yet existing benchmarks fail to fully capture this advanced capability. Even Visual Search, the most common benchmark for current thinking-\textit{with}-images methods, tests only basic operations such as localization and cropping, offering little insight into more complex, dynamic, and tool-dependent reasoning. We introduce \textbf{TIR-Bench}, a comprehensive benchmark for evaluating agentic thinking-with-images across 13 diverse tasks, each requiring novel tool use for image processing and manipulation in chain-of-thought. We evaluate 22 multimodal large language models (MLLMs), from leading open-sourced and proprietary models to those with explicit tool-use augmentation. Results show that TIR-Bench is universally challenging, and strong performance requires genuine thinking-with-images capabilities. Finally, we present a pilot study comparing direct versus agentic fine-tuning.

