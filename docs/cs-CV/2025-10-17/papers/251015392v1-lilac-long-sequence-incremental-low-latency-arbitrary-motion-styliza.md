---
layout: default
title: LILAC: Long-sequence Incremental Low-latency Arbitrary Motion Stylization via Streaming VAE-Diffusion with Causal Decoding
---

# LILAC: Long-sequence Incremental Low-latency Arbitrary Motion Stylization via Streaming VAE-Diffusion with Causal Decoding

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.15392" target="_blank" class="toolbar-btn">arXiv: 2510.15392v1</a>
    <a href="https://arxiv.org/pdf/2510.15392.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.15392v1" 
            onclick="toggleFavorite(this, '2510.15392v1', 'LILAC: Long-sequence Incremental Low-latency Arbitrary Motion Stylization via Streaming VAE-Diffusion with Causal Decoding')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Peng Ren, Hai Yang

**ÂàÜÁ±ª**: cs.CV, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-17

**üîó ‰ª£Á†Å/È°πÁõÆ**: [PROJECT_PAGE](https://pren1.github.io/lilac/)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**LILACÔºöÂü∫‰∫éÊµÅÂºèVAE-DiffusionÂíåÂõ†ÊûúËß£Á†ÅÁöÑÈïøÂ∫èÂàóÂ¢ûÈáè‰ΩéÂª∂Ëøü‰ªªÊÑèÂä®‰ΩúÈ£éÊ†ºÂåñ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±ÂÖ´ÔºöÁâ©ÁêÜÂä®Áîª (Physics-based Animation)**

**ÂÖ≥ÈîÆËØç**: `Âä®‰ΩúÈ£éÊ†ºÂåñ` `ÊµÅÂºèÂ§ÑÁêÜ` `VAE-Diffusion` `‰ΩéÂª∂Ëøü` `ÈïøÂ∫èÂàó` `Âõ†ÊûúËß£Á†Å` `ËøêÂä®ÁîüÊàê`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊµÅÂºèÂä®‰ΩúÈ£éÊ†ºÂåñÊñπÊ≥ïËÆ°ÁÆóÂºÄÈîÄÂ§ßÔºåÈöæ‰ª•‰øùËØÅÊó∂Èó¥Á®≥ÂÆöÊÄßÔºåÈôêÂà∂‰∫ÜÂÆûÊó∂‰∫§‰∫íÂ∫îÁî®„ÄÇ
2. LILACÂà©Áî®ÊΩúÂú®Á©∫Èó¥ÊµÅÂºèVAE-DiffusionÊû∂ÊûÑÔºåÁªìÂêàÂõ†ÊûúÊªëÂä®Á™óÂè£ÂíåËß£Á†ÅËøêÂä®ÁâπÂæÅÊ≥®ÂÖ•ÔºåÂÆûÁé∞‰ΩéÂª∂ËøüÈïøÂ∫èÂàóÈ£éÊ†ºÂåñ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåLILACÂú®Âü∫ÂáÜÊï∞ÊçÆÈõÜ‰∏äÂÆûÁé∞‰∫ÜÈ´òË¥®ÈáèÁöÑÂÆûÊó∂Âä®‰ΩúÈ£éÊ†ºÂåñÔºåÂπ∂Âú®È£éÊ†ºÂåñË¥®ÈáèÂíåÂìçÂ∫îÊÄß‰πãÈó¥ÂèñÂæó‰∫ÜÂπ≥Ë°°„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫LILACÔºàLong-sequence Incremental Low-latency Arbitrary Motion Stylization via Streaming VAE-Diffusion with Causal DecodingÔºâÔºåÊó®Âú®Ëß£ÂÜ≥ÂÆûÊó∂ÁîüÊàêÈïøÂ∫èÂàóÈ£éÊ†ºÂåñ‰∫∫‰ΩìÂä®‰ΩúÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊµÅÂºèÊñπÊ≥ïÈÄöÂ∏∏Áõ¥Êé•Âú®ÂéüÂßãÂä®‰ΩúÁ©∫Èó¥Êìç‰ΩúÔºåËÆ°ÁÆóÂºÄÈîÄÂ§ß‰∏îÈöæ‰ª•‰øùÊåÅÊó∂Èó¥Á®≥ÂÆöÊÄß„ÄÇËôΩÁÑ∂Âü∫‰∫éÊΩúÂú®Á©∫Èó¥ÁöÑVAE-DiffusionÊ°ÜÊû∂ÂèØ‰ª•ÁºìËß£Ëøô‰∫õÈóÆÈ¢òÂπ∂ÂÆûÁé∞È´òË¥®ÈáèÁöÑÈ£éÊ†ºÂåñÔºå‰ΩÜÈÄöÂ∏∏‰ªÖÈôê‰∫éÁ¶ªÁ∫øÂ§ÑÁêÜ„ÄÇLILACÂü∫‰∫éÈ´òÊÄßËÉΩÁöÑÁ¶ªÁ∫ø‰ªªÊÑèÂä®‰ΩúÈ£éÊ†ºÂåñÊ°ÜÊû∂ÔºåÈÄöËøáÂÖ∑ÊúâÊªëÂä®Á™óÂè£Âõ†ÊûúËÆæËÆ°ÁöÑÊΩúÂú®Á©∫Èó¥ÊµÅÂºèÊû∂ÊûÑÔºåÂπ∂Ê≥®ÂÖ•Ëß£Á†ÅÁöÑËøêÂä®ÁâπÂæÅ‰ª•Á°Æ‰øùÂπ≥ÊªëÁöÑËøêÂä®ËøáÊ∏°ÔºåÂ∞ÜÂÖ∂Êâ©Â±ïÂà∞Âú®Á∫øËÆæÁΩÆ„ÄÇËØ•Êû∂ÊûÑÊó†ÈúÄ‰æùËµñÊú™Êù•Â∏ßÊàñ‰øÆÊîπÊâ©Êï£Ê®°ÂûãÊû∂ÊûÑÂç≥ÂèØÂÆûÁé∞ÈïøÂ∫èÂàóÂÆûÊó∂‰ªªÊÑèÈ£éÊ†ºÂåñÔºåÂú®È£éÊ†ºÂåñË¥®ÈáèÂíåÂìçÂ∫îÊÄß‰πãÈó¥ÂèñÂæó‰∫ÜËâØÂ•ΩÁöÑÂπ≥Ë°°ÔºåÂÆûÈ™åÁªìÊûúË°®Êòé‰∫ÜÂÖ∂Âú®Âü∫ÂáÜÊï∞ÊçÆÈõÜ‰∏äÁöÑÊúâÊïàÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥ÂÆûÊó∂ÁîüÊàêÈïøÂ∫èÂàóÈ£éÊ†ºÂåñ‰∫∫‰ΩìÂä®‰ΩúÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊµÅÂºèÊñπÊ≥ïÁõ¥Êé•Âú®ÂéüÂßãÂä®‰ΩúÁ©∫Èó¥ËøõË°åÊìç‰ΩúÔºåÂØºËá¥ËÆ°ÁÆóÈáèÂ∑®Â§ßÔºåÈöæ‰ª•‰øùËØÅÊó∂Èó¥‰∏äÁöÑËøûË¥ØÊÄßÂíåÁ®≥ÂÆöÊÄß„ÄÇËÄåÂü∫‰∫éVAE-DiffusionÁöÑÁ¶ªÁ∫øÊñπÊ≥ïËôΩÁÑ∂ËÉΩÂ§üÁîüÊàêÈ´òË¥®ÈáèÁöÑÈ£éÊ†ºÂåñÂä®‰ΩúÔºå‰ΩÜÊó†Ê≥ïÊª°Ë∂≥ÂÆûÊó∂ÊÄßÈúÄÊ±Ç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜÁ¶ªÁ∫øVAE-DiffusionÊ°ÜÊû∂Êâ©Â±ïÂà∞Âú®Á∫øÊµÅÂºèËÆæÁΩÆ„ÄÇÈÄöËøáÂú®ÊΩúÂú®Á©∫Èó¥‰∏≠ËøõË°åÊìç‰ΩúÔºåÈôç‰ΩéËÆ°ÁÆóÂ§çÊùÇÂ∫¶„ÄÇÂêåÊó∂ÔºåÈááÁî®ÊªëÂä®Á™óÂè£Âõ†ÊûúËÆæËÆ°ÔºåÈÅøÂÖç‰ΩøÁî®Êú™Êù•‰ø°ÊÅØÔºå‰øùËØÅÂÆûÊó∂ÊÄß„ÄÇÊ≠§Â§ñÔºåÈÄöËøáÊ≥®ÂÖ•Ëß£Á†ÅÁöÑËøêÂä®ÁâπÂæÅÔºåÁ°Æ‰øùËøêÂä®ËøáÊ∏°ÁöÑÂπ≥ÊªëÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöLILACÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) ÁºñÁ†ÅÂô®ÔºöÂ∞ÜÂéüÂßãËøêÂä®Â∫èÂàóÁºñÁ†ÅÂà∞ÊΩúÂú®Á©∫Èó¥Ôºõ2) ÊµÅÂºèÊâ©Êï£Ê®°ÂûãÔºöÂú®ÊΩúÂú®Á©∫Èó¥‰∏≠ËøõË°åÈ£éÊ†ºÂåñÔºåÈááÁî®ÊªëÂä®Á™óÂè£Âõ†ÊûúËÆæËÆ°Ôºõ3) Ëß£Á†ÅÂô®ÔºöÂ∞ÜÈ£éÊ†ºÂåñÂêéÁöÑÊΩúÂú®Ë°®Á§∫Ëß£Á†ÅÂõûËøêÂä®Á©∫Èó¥Ôºõ4) ËøêÂä®ÁâπÂæÅÊ≥®ÂÖ•Ê®°ÂùóÔºöÂ∞ÜËß£Á†ÅÂêéÁöÑËøêÂä®ÁâπÂæÅÊ≥®ÂÖ•Âà∞Êâ©Êï£Ê®°ÂûãÁöÑ‰∏≠Èó¥Â±ÇÔºå‰ª•‰øùËØÅËøêÂä®ÁöÑÂπ≥ÊªëËøáÊ∏°„ÄÇÊï¥‰∏™ÊµÅÁ®ãÊòØÂ¢ûÈáèÂºèÁöÑÔºåÊØèÂΩìÊúâÊñ∞ÁöÑËøêÂä®Êï∞ÊçÆËæìÂÖ•Êó∂ÔºåÈÉΩ‰ºöËøõË°å‰∏ÄÊ¨°È£éÊ†ºÂåñÂíåËß£Á†ÅÔºåÂπ∂ËæìÂá∫ÁªìÊûú„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöLILACÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜÁ¶ªÁ∫øVAE-DiffusionÊ°ÜÊû∂ÊàêÂäüÂú∞Êâ©Â±ïÂà∞‰∫ÜÂú®Á∫øÊµÅÂºèËÆæÁΩÆÔºåÂπ∂‰∏îÂú®‰øùËØÅÂÆûÊó∂ÊÄßÁöÑÂâçÊèê‰∏ãÔºåÂÆûÁé∞‰∫ÜÈ´òË¥®ÈáèÁöÑÂä®‰ΩúÈ£éÊ†ºÂåñ„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåLILAC‰∏çÈúÄË¶ÅËÆøÈóÆÊú™Êù•ÁöÑËøêÂä®Â∏ßÔºå‰πü‰∏çÈúÄË¶Å‰øÆÊîπÊâ©Êï£Ê®°ÂûãÁöÑÊû∂ÊûÑÔºå‰ªéËÄåÊõ¥Âä†ÁÅµÊ¥ªÂíåÈ´òÊïà„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöLILACÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ÊªëÂä®Á™óÂè£ÁöÑÂ§ßÂ∞èÔºöÈúÄË¶ÅÊ†πÊçÆÂÆûÈôÖÂ∫îÁî®Âú∫ÊôØËøõË°åË∞ÉÊï¥Ôºå‰ª•Âπ≥Ë°°ÂÆûÊó∂ÊÄßÂíåÈ£éÊ†ºÂåñË¥®ÈáèÔºõ2) ËøêÂä®ÁâπÂæÅÊ≥®ÂÖ•ÁöÑ‰ΩçÁΩÆÂíåÊñπÂºèÔºöÈúÄË¶Å‰ªîÁªÜËÆæËÆ°Ôºå‰ª•‰øùËØÅËøêÂä®ËøáÊ∏°ÁöÑÂπ≥ÊªëÊÄßÔºåÂêåÊó∂ÈÅøÂÖçÂºïÂÖ•ËøáÂ§öÁöÑËÆ°ÁÆóÂºÄÈîÄÔºõ3) ÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°ÔºöÈúÄË¶ÅÁªºÂêàËÄÉËôëÈ£éÊ†ºÂåñË¥®Èáè„ÄÅËøêÂä®Âπ≥ÊªëÊÄßÂíåÂÆûÊó∂ÊÄßÁ≠âÂõ†Á¥†„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

LILACÂú®Âü∫ÂáÜÊï∞ÊçÆÈõÜ‰∏äËøõË°å‰∫ÜÂÆûÈ™åÔºåÁªìÊûúË°®ÊòéÔºåLILACËÉΩÂ§üÂú®‰øùËØÅÂÆûÊó∂ÊÄßÁöÑÂâçÊèê‰∏ãÔºåÂÆûÁé∞È´òË¥®ÈáèÁöÑÂä®‰ΩúÈ£éÊ†ºÂåñ„ÄÇ‰∏éÁé∞ÊúâÁöÑÊµÅÂºèÊñπÊ≥ïÁõ∏ÊØîÔºåLILACÂú®È£éÊ†ºÂåñË¥®ÈáèÂíåËøêÂä®Âπ≥ÊªëÊÄßÊñπÈù¢ÈÉΩÊúâÊòæËëóÊèêÂçá„ÄÇÂÖ∑‰ΩìÊÄßËÉΩÊï∞ÊçÆÔºà‰æãÂ¶ÇÂª∂Ëøü„ÄÅÈ£éÊ†ºÂåñË¥®ÈáèÊåáÊ†áÁ≠âÔºâÂèØÂú®ËÆ∫Êñá‰∏≠ÊâæÂà∞„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

LILACÂèØÂ∫îÁî®‰∫éËôöÊãüÁé∞ÂÆû„ÄÅÊ∏∏Êàè„ÄÅÂä®ÁîªÂà∂‰ΩúÁ≠âÈ¢ÜÂüüÔºåÂÆûÁé∞ÂØπËôöÊãüËßíËâ≤ÁöÑÂÆûÊó∂Âä®‰ΩúÈ£éÊ†ºÂåñÊéßÂà∂„ÄÇ‰æãÂ¶ÇÔºåÁî®Êà∑ÂèØ‰ª•ÈÄöËøáLILACÂÆûÊó∂Ë∞ÉÊï¥ËôöÊãüËßíËâ≤ÁöÑÂä®‰ΩúÈ£éÊ†ºÔºå‰ΩøÂÖ∂Êõ¥Á¨¶ÂêàÁî®Êà∑ÁöÑ‰∏™ÊÄßÂåñÈúÄÊ±Ç„ÄÇÊ≠§Â§ñÔºåLILACËøòÂèØ‰ª•Áî®‰∫éÁîüÊàêÂêÑÁßçÈ£éÊ†ºÂåñÁöÑËøêÂä®Êï∞ÊçÆÔºåÁî®‰∫éËÆ≠ÁªÉÂÖ∂‰ªñÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÔºå‰æãÂ¶ÇÂä®‰ΩúËØÜÂà´Ê®°Âûã„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Generating long and stylized human motions in real time is critical for applications that demand continuous and responsive character control. Despite its importance, existing streaming approaches often operate directly in the raw motion space, leading to substantial computational overhead and making it difficult to maintain temporal stability. In contrast, latent-space VAE-Diffusion-based frameworks alleviate these issues and achieve high-quality stylization, but they are generally confined to offline processing. To bridge this gap, LILAC (Long-sequence Incremental Low-latency Arbitrary Motion Stylization via Streaming VAE-Diffusion with Causal Decoding) builds upon a recent high-performing offline framework for arbitrary motion stylization and extends it to an online setting through a latent-space streaming architecture with a sliding-window causal design and the injection of decoded motion features to ensure smooth motion transitions. This architecture enables long-sequence real-time arbitrary stylization without relying on future frames or modifying the diffusion model architecture, achieving a favorable balance between stylization quality and responsiveness as demonstrated by experiments on benchmark datasets. Supplementary video and examples are available at the project page: https://pren1.github.io/lilac/

