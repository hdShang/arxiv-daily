---
layout: default
title: "BLIP3o-NEXT: Next Frontier of Native Image Generation"
---

# BLIP3o-NEXT: Next Frontier of Native Image Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.15857" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.15857v1</a>
  <a href="https://arxiv.org/pdf/2510.15857.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.15857v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.15857v1', 'BLIP3o-NEXT: Next Frontier of Native Image Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiuhai Chen, Le Xue, Zhiyang Xu, Xichen Pan, Shusheng Yang, Can Qin, An Yan, Honglu Zhou, Zeyuan Chen, Lifu Huang, Tianyi Zhou, Junnan Li, Silvio Savarese, Caiming Xiong, Ran Xu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-17

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**BLIP3o-NEXTï¼šåŸç”Ÿå›¾åƒç”Ÿæˆçš„æ–°å‰æ²¿ï¼Œç»Ÿä¸€æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸å›¾åƒç¼–è¾‘**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ` `å›¾åƒç¼–è¾‘` `è‡ªå›å½’æ¨¡å‹` `æ‰©æ•£æ¨¡å‹` `å¤šæ¨¡æ€å­¦ä¹ ` `åŸç”Ÿå›¾åƒç”Ÿæˆ` `å¼ºåŒ–å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å›¾åƒç”Ÿæˆæ¨¡å‹åœ¨ç»Ÿä¸€æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆå’Œå›¾åƒç¼–è¾‘æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ï¼Œéš¾ä»¥å…¼é¡¾æŒ‡ä»¤éµå¾ªå’Œå›¾åƒè´¨é‡ã€‚
2. BLIP3o-NEXTé‡‡ç”¨è‡ªå›å½’+æ‰©æ•£æ¶æ„ï¼Œåˆ©ç”¨è‡ªå›å½’æ¨¡å‹è¿›è¡Œæ¨ç†å’ŒæŒ‡ä»¤éµå¾ªï¼Œæ‰©æ•£æ¨¡å‹ç”Ÿæˆé«˜ä¿çœŸå›¾åƒã€‚
3. å®éªŒè¡¨æ˜ï¼ŒBLIP3o-NEXTåœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆå’Œå›¾åƒç¼–è¾‘ä»»åŠ¡ä¸Šå‡ä¼˜äºç°æœ‰æ¨¡å‹ï¼Œå®ç°äº†æ›´å¥½çš„è¿è´¯æ€§å’ŒçœŸå®æ„Ÿã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

BLIP3o-NEXTæ˜¯BLIP3ç³»åˆ—ä¸­çš„ä¸€ä¸ªå®Œå…¨å¼€æºçš„åŸºç¡€æ¨¡å‹ï¼Œå®ƒæ¨è¿›äº†åŸç”Ÿå›¾åƒç”Ÿæˆçš„æ–°å‰æ²¿ã€‚BLIP3o-NEXTåœ¨ä¸€ä¸ªå•ä¸€æ¶æ„ä¸­ç»Ÿä¸€äº†æ–‡æœ¬åˆ°å›¾åƒçš„ç”Ÿæˆå’Œå›¾åƒç¼–è¾‘ï¼Œå±•ç¤ºäº†å¼ºå¤§çš„å›¾åƒç”Ÿæˆå’Œå›¾åƒç¼–è¾‘èƒ½åŠ›ã€‚åœ¨å¼€å‘æœ€å…ˆè¿›çš„åŸç”Ÿå›¾åƒç”Ÿæˆæ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬ç¡®å®šäº†å››ä¸ªå…³é”®è§è§£ï¼šï¼ˆ1ï¼‰å¤§å¤šæ•°æ¶æ„é€‰æ‹©äº§ç”Ÿç›¸å½“çš„æ€§èƒ½ï¼›åªè¦æ¶æ„èƒ½å¤Ÿæœ‰æ•ˆåœ°æ‰©å±•å¹¶æ”¯æŒå¿«é€Ÿæ¨ç†ï¼Œå°±å¯ä»¥è®¤ä¸ºæ˜¯æœ‰æ•ˆçš„ï¼›ï¼ˆ2ï¼‰å¼ºåŒ–å­¦ä¹ çš„æˆåŠŸåº”ç”¨å¯ä»¥è¿›ä¸€æ­¥æ¨åŠ¨åŸç”Ÿå›¾åƒç”Ÿæˆçš„å‰æ²¿ï¼›ï¼ˆ3ï¼‰å›¾åƒç¼–è¾‘ä»ç„¶æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œä½†é€šè¿‡åè®­ç»ƒå’Œæ•°æ®å¼•æ“ï¼Œå¯ä»¥æ˜¾è‘—æé«˜æŒ‡ä»¤éµå¾ªä»¥åŠç”Ÿæˆå›¾åƒå’Œå‚è€ƒå›¾åƒä¹‹é—´çš„ä¸€è‡´æ€§ï¼›ï¼ˆ4ï¼‰æ•°æ®è´¨é‡å’Œè§„æ¨¡ä»ç„¶æ˜¯å†³å®šæ¨¡å‹æ€§èƒ½ä¸Šé™çš„å†³å®šæ€§å› ç´ ã€‚åŸºäºè¿™äº›è§è§£ï¼ŒBLIP3o-NEXTåˆ©ç”¨è‡ªå›å½’+æ‰©æ•£æ¶æ„ï¼Œå…¶ä¸­è‡ªå›å½’æ¨¡å‹é¦–å…ˆç”Ÿæˆä»¥å¤šæ¨¡æ€è¾“å…¥ä¸ºæ¡ä»¶çš„ç¦»æ•£å›¾åƒtokensï¼Œç„¶åå°†å…¶éšè—çŠ¶æ€ç”¨ä½œæ‰©æ•£æ¨¡å‹ç”Ÿæˆé«˜ä¿çœŸå›¾åƒçš„æ¡ä»¶ä¿¡å·ã€‚è¿™ç§æ¶æ„é›†æˆäº†è‡ªå›å½’æ¨¡å‹çš„æ¨ç†èƒ½åŠ›å’ŒæŒ‡ä»¤éµå¾ªèƒ½åŠ›ï¼Œä»¥åŠæ‰©æ•£æ¨¡å‹çš„ç²¾ç»†ç»†èŠ‚æ¸²æŸ“èƒ½åŠ›ï¼Œä»è€Œå®ç°äº†æ–°çš„è¿è´¯æ€§å’ŒçœŸå®æ„Ÿã€‚å¯¹å„ç§æ–‡æœ¬åˆ°å›¾åƒå’Œå›¾åƒç¼–è¾‘åŸºå‡†çš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼ŒBLIP3o-NEXTä¼˜äºç°æœ‰æ¨¡å‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åŸç”Ÿå›¾åƒç”Ÿæˆé¢†åŸŸä¸­ï¼Œå¦‚ä½•æ„å»ºä¸€ä¸ªæ—¢èƒ½è¿›è¡Œé«˜è´¨é‡å›¾åƒç”Ÿæˆï¼Œåˆèƒ½è¿›è¡Œç²¾ç¡®å›¾åƒç¼–è¾‘çš„ç»Ÿä¸€æ¨¡å‹çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éš¾ä»¥åœ¨æŒ‡ä»¤éµå¾ªçš„å‡†ç¡®æ€§å’Œç”Ÿæˆå›¾åƒçš„çœŸå®æ„Ÿä¹‹é—´å–å¾—å¹³è¡¡ï¼Œå¹¶ä¸”å›¾åƒç¼–è¾‘ä»»åŠ¡ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šBLIP3o-NEXTçš„æ ¸å¿ƒæ€è·¯æ˜¯ç»“åˆè‡ªå›å½’æ¨¡å‹å’Œæ‰©æ•£æ¨¡å‹çš„ä¼˜åŠ¿ã€‚è‡ªå›å½’æ¨¡å‹æ“…é•¿æ¨ç†å’ŒæŒ‡ä»¤éµå¾ªï¼Œè€Œæ‰©æ•£æ¨¡å‹æ“…é•¿ç”Ÿæˆé«˜ä¿çœŸå›¾åƒã€‚é€šè¿‡å°†ä¸¤è€…ç»“åˆï¼Œæ¨¡å‹æ—¢èƒ½ç†è§£å¤æ‚çš„æ–‡æœ¬æŒ‡ä»¤ï¼Œåˆèƒ½ç”Ÿæˆç»†èŠ‚ä¸°å¯Œçš„å›¾åƒã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šBLIP3o-NEXTé‡‡ç”¨è‡ªå›å½’+æ‰©æ•£çš„æ¶æ„ã€‚é¦–å…ˆï¼Œè‡ªå›å½’æ¨¡å‹æ¥æ”¶å¤šæ¨¡æ€è¾“å…¥ï¼ˆä¾‹å¦‚æ–‡æœ¬æè¿°ï¼‰ï¼Œå¹¶ç”Ÿæˆç¦»æ•£çš„å›¾åƒtokensã€‚ç„¶åï¼Œè¿™äº›tokensçš„éšè—çŠ¶æ€è¢«ç”¨ä½œæ‰©æ•£æ¨¡å‹çš„æ¡ä»¶ä¿¡å·ï¼Œå¼•å¯¼æ‰©æ•£æ¨¡å‹ç”Ÿæˆæœ€ç»ˆçš„é«˜è´¨é‡å›¾åƒã€‚è¿™ç§ä¸¤é˜¶æ®µçš„æ¶æ„å…è®¸æ¨¡å‹åˆ†åˆ«å¤„ç†è¯­ä¹‰ç†è§£å’Œå›¾åƒç”Ÿæˆï¼Œä»è€Œæé«˜æ•´ä½“æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šBLIP3o-NEXTçš„å…³é”®åˆ›æ–°åœ¨äºå°†è‡ªå›å½’æ¨¡å‹çš„æ¨ç†èƒ½åŠ›å’Œæ‰©æ•£æ¨¡å‹çš„å›¾åƒç”Ÿæˆèƒ½åŠ›æœ‰æ•ˆåœ°ç»“åˆèµ·æ¥ã€‚é€šè¿‡è‡ªå›å½’æ¨¡å‹ç”Ÿæˆç¦»æ•£çš„å›¾åƒtokensï¼Œå¹¶å°†å…¶ä½œä¸ºæ‰©æ•£æ¨¡å‹çš„æ¡ä»¶ä¿¡å·ï¼Œæ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£æ–‡æœ¬æŒ‡ä»¤ï¼Œå¹¶ç”Ÿæˆä¸æŒ‡ä»¤ä¸€è‡´çš„å›¾åƒã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜å¼ºè°ƒäº†æ•°æ®è´¨é‡å’Œè§„æ¨¡çš„é‡è¦æ€§ï¼Œä»¥åŠå¼ºåŒ–å­¦ä¹ åœ¨æå‡å›¾åƒç”Ÿæˆè´¨é‡æ–¹é¢çš„æ½œåŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šå…·ä½“çš„æŠ€æœ¯ç»†èŠ‚åŒ…æ‹¬è‡ªå›å½’æ¨¡å‹çš„é€‰æ‹©ã€æ‰©æ•£æ¨¡å‹çš„æ¶æ„ã€ä»¥åŠå¦‚ä½•å°†è‡ªå›å½’æ¨¡å‹çš„è¾“å‡ºæœ‰æ•ˆåœ°ä¼ é€’ç»™æ‰©æ•£æ¨¡å‹ã€‚è®ºæ–‡è¿˜å¼ºè°ƒäº†åè®­ç»ƒå’Œæ•°æ®å¼•æ“åœ¨æé«˜æŒ‡ä»¤éµå¾ªå’Œå›¾åƒä¸€è‡´æ€§æ–¹é¢çš„é‡è¦æ€§ï¼Œä½†å…·ä½“å®ç°ç»†èŠ‚æœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

BLIP3o-NEXTåœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆå’Œå›¾åƒç¼–è¾‘çš„å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å‡å–å¾—äº†ä¼˜äºç°æœ‰æ¨¡å‹çš„æ€§èƒ½ã€‚å…·ä½“æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†å±•ç¤ºï¼Œè¡¨æ˜è¯¥æ¨¡å‹åœ¨å›¾åƒè´¨é‡ã€æŒ‡ä»¤éµå¾ªå’Œç¼–è¾‘èƒ½åŠ›æ–¹é¢å‡æœ‰æ˜¾è‘—æå‡ã€‚å¼ºåŒ–å­¦ä¹ çš„åº”ç”¨è¿›ä¸€æ­¥æå‡äº†å›¾åƒç”Ÿæˆçš„è´¨é‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

BLIP3o-NEXTå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼ŒåŒ…æ‹¬åˆ›æ„è®¾è®¡ã€å†…å®¹ç”Ÿæˆã€è™šæ‹Ÿç°å®ã€æ¸¸æˆå¼€å‘ç­‰é¢†åŸŸã€‚å®ƒå¯ä»¥æ ¹æ®ç”¨æˆ·çš„æ–‡æœ¬æè¿°ç”Ÿæˆå„ç§å›¾åƒï¼Œä¹Ÿå¯ä»¥å¯¹ç°æœ‰å›¾åƒè¿›è¡Œç¼–è¾‘å’Œä¿®æ”¹ã€‚è¯¥æ¨¡å‹æœ‰æœ›é™ä½å›¾åƒç”Ÿæˆå’Œç¼–è¾‘çš„é—¨æ§›ï¼Œä½¿æ›´å¤šäººèƒ½å¤Ÿå‚ä¸åˆ°åˆ›æ„å†…å®¹åˆ›ä½œä¸­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present BLIP3o-NEXT, a fully open-source foundation model in the BLIP3 series that advances the next frontier of native image generation. BLIP3o-NEXT unifies text-to-image generation and image editing within a single architecture, demonstrating strong image generation and image editing capabilities. In developing the state-of-the-art native image generation model, we identify four key insights: (1) Most architectural choices yield comparable performance; an architecture can be deemed effective provided it scales efficiently and supports fast inference; (2) The successful application of reinforcement learning can further push the frontier of native image generation; (3) Image editing still remains a challenging task, yet instruction following and the consistency between generated and reference images can be significantly enhanced through post-training and data engine; (4) Data quality and scale continue to be decisive factors that determine the upper bound of model performance. Building upon these insights, BLIP3o-NEXT leverages an Autoregressive + Diffusion architecture in which an autoregressive model first generates discrete image tokens conditioned on multimodal inputs, whose hidden states are then used as conditioning signals for a diffusion model to generate high-fidelity images. This architecture integrates the reasoning strength and instruction following of autoregressive models with the fine-detail rendering ability of diffusion models, achieving a new level of coherence and realism. Extensive evaluations of various text-to-image and image-editing benchmarks show that BLIP3o-NEXT achieves superior performance over existing models.

