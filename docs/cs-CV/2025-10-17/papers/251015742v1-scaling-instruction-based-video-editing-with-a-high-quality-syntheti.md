---
layout: default
title: Scaling Instruction-Based Video Editing with a High-Quality Synthetic Dataset
---

# Scaling Instruction-Based Video Editing with a High-Quality Synthetic Dataset

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.15742" target="_blank" class="toolbar-btn">arXiv: 2510.15742v1</a>
    <a href="https://arxiv.org/pdf/2510.15742.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.15742v1" 
            onclick="toggleFavorite(this, '2510.15742v1', 'Scaling Instruction-Based Video Editing with a High-Quality Synthetic Dataset')" title="æ”¶è—">
      â˜† æ”¶è—
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="å¤åˆ¶é“¾æ¥">
      ğŸ”— åˆ†äº«
    </button>
  </div>
</div>


**ä½œè€…**: Qingyan Bai, Qiuyu Wang, Hao Ouyang, Yue Yu, Hanlin Wang, Wen Wang, Ka Leong Cheng, Shuailei Ma, Yanhong Zeng, Zichen Liu, Yinghao Xu, Yujun Shen, Qifeng Chen

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-17

**å¤‡æ³¨**: Project page: https://ezioby.github.io/Ditto_page Code: https://github.com/EzioBy/Ditto

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDittoæ¡†æ¶ï¼Œé€šè¿‡é«˜è´¨é‡åˆæˆæ•°æ®é›†Editto-1Mï¼Œæ˜¾è‘—æå‡æŒ‡ä»¤é©±åŠ¨çš„è§†é¢‘ç¼–è¾‘èƒ½åŠ›ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æŒ‡ä»¤é©±åŠ¨è§†é¢‘ç¼–è¾‘` `åˆæˆæ•°æ®ç”Ÿæˆ` `æ•°æ®å¢å¼º` `è¯¾ç¨‹å­¦ä¹ ` `æ™ºèƒ½ä»£ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æŒ‡ä»¤é©±åŠ¨è§†é¢‘ç¼–è¾‘æ–¹æ³•ç¼ºä¹å¤§è§„æ¨¡é«˜è´¨é‡è®­ç»ƒæ•°æ®ï¼Œé™åˆ¶äº†æ¨¡å‹æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚
2. Dittoæ¡†æ¶é€šè¿‡ç»“åˆå›¾åƒç¼–è¾‘å™¨å’Œè§†é¢‘ç”Ÿæˆå™¨ï¼Œä»¥åŠæ™ºèƒ½ä»£ç†é©±åŠ¨çš„æ•°æ®ç”Ÿæˆå’Œè¿‡æ»¤ï¼Œæ„å»ºå¤§è§„æ¨¡é«˜è´¨é‡åˆæˆæ•°æ®é›†ã€‚
3. åœ¨Ditto-1Mæ•°æ®é›†ä¸Šè®­ç»ƒçš„Edittoæ¨¡å‹ï¼Œåœ¨æŒ‡ä»¤éµå¾ªèƒ½åŠ›ä¸Šè¡¨ç°å‡ºè‰²ï¼Œè¾¾åˆ°äº†æŒ‡ä»¤é©±åŠ¨è§†é¢‘ç¼–è¾‘é¢†åŸŸçš„æ–°é«˜åº¦ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æŒ‡ä»¤é©±åŠ¨çš„è§†é¢‘ç¼–è¾‘æœ‰æœ›æ™®åŠå†…å®¹åˆ›ä½œï¼Œä½†å…¶å‘å±•å—åˆ°å¤§è§„æ¨¡ã€é«˜è´¨é‡è®­ç»ƒæ•°æ®åŒ®ä¹çš„ä¸¥é‡é˜»ç¢ã€‚æˆ‘ä»¬æå‡ºäº†Dittoï¼Œä¸€ä¸ªæ—¨åœ¨è§£å†³è¿™ä¸€æ ¹æœ¬æŒ‘æˆ˜çš„æ•´ä½“æ¡†æ¶ã€‚Dittoçš„æ ¸å¿ƒæ˜¯ä¸€ä¸ªæ–°é¢–çš„æ•°æ®ç”Ÿæˆæµç¨‹ï¼Œå®ƒèåˆäº†é¢†å…ˆå›¾åƒç¼–è¾‘å™¨çš„åˆ›é€ æ€§å¤šæ ·æ€§å’Œä¸Šä¸‹æ–‡è§†é¢‘ç”Ÿæˆå™¨ï¼Œå…‹æœäº†ç°æœ‰æ¨¡å‹çš„å±€é™æ€§ã€‚ä¸ºäº†ä½¿è¿™ä¸€è¿‡ç¨‹å¯è¡Œï¼Œæˆ‘ä»¬çš„æ¡†æ¶é€šè¿‡é‡‡ç”¨é«˜æ•ˆçš„ã€ç»è¿‡è’¸é¦çš„æ¨¡å‹æ¶æ„ï¼Œå¹¶è¾…ä»¥æ—¶é—´å¢å¼ºå™¨ï¼Œè§£å†³äº†é«˜æ˜‚çš„æˆæœ¬-è´¨é‡æƒè¡¡é—®é¢˜ï¼Œä»è€ŒåŒæ—¶é™ä½äº†è®¡ç®—å¼€é”€å¹¶æé«˜äº†æ—¶é—´ä¸€è‡´æ€§ã€‚æœ€åï¼Œä¸ºäº†å®ç°å®Œå…¨çš„å¯æ‰©å±•æ€§ï¼Œæ•´ä¸ªæµç¨‹ç”±ä¸€ä¸ªæ™ºèƒ½ä»£ç†é©±åŠ¨ï¼Œè¯¥ä»£ç†ç”Ÿæˆå¤šæ ·åŒ–çš„æŒ‡ä»¤å¹¶ä¸¥æ ¼è¿‡æ»¤è¾“å‡ºï¼Œä»è€Œç¡®ä¿å¤§è§„æ¨¡çš„è´¨é‡æ§åˆ¶ã€‚åˆ©ç”¨è¯¥æ¡†æ¶ï¼Œæˆ‘ä»¬æŠ•å…¥äº†è¶…è¿‡12,000ä¸ªGPU-daysæ¥æ„å»ºDitto-1Mï¼Œä¸€ä¸ªåŒ…å«ä¸€ç™¾ä¸‡ä¸ªé«˜ä¿çœŸè§†é¢‘ç¼–è¾‘ç¤ºä¾‹çš„æ–°æ•°æ®é›†ã€‚æˆ‘ä»¬ä½¿ç”¨è¯¾ç¨‹å­¦ä¹ ç­–ç•¥åœ¨Ditto-1Mä¸Šè®­ç»ƒäº†æˆ‘ä»¬çš„æ¨¡å‹Edittoã€‚ç»“æœè¡¨æ˜ï¼ŒEdittoå…·æœ‰å“è¶Šçš„æŒ‡ä»¤éµå¾ªèƒ½åŠ›ï¼Œå¹¶åœ¨æŒ‡ä»¤é©±åŠ¨çš„è§†é¢‘ç¼–è¾‘é¢†åŸŸå»ºç«‹äº†æ–°çš„æœ€å…ˆè¿›æ°´å¹³ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æŒ‡ä»¤é©±åŠ¨è§†é¢‘ç¼–è¾‘ä»»åŠ¡ä¸­ï¼Œç¼ºä¹å¤§è§„æ¨¡ã€é«˜è´¨é‡è®­ç»ƒæ•°æ®çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºçœŸå®è§†é¢‘æ•°æ®ï¼Œä½†è·å–æˆæœ¬é«˜æ˜‚ä¸”éš¾ä»¥è¦†ç›–å„ç§ç¼–è¾‘æŒ‡ä»¤ã€‚å› æ­¤ï¼Œæ¨¡å‹è®­ç»ƒå—é™ï¼Œéš¾ä»¥æ³›åŒ–åˆ°å¤æ‚åœºæ™¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨åˆæˆæ•°æ®æ¥å¼¥è¡¥çœŸå®æ•°æ®çš„ä¸è¶³ã€‚é€šè¿‡æ„å»ºä¸€ä¸ªè‡ªåŠ¨åŒ–çš„æ•°æ®ç”Ÿæˆæµç¨‹ï¼Œå¯ä»¥ä½æˆæœ¬åœ°ç”Ÿæˆå¤§é‡é«˜è´¨é‡çš„è§†é¢‘ç¼–è¾‘ç¤ºä¾‹ï¼Œä»è€Œæœ‰æ•ˆè®­ç»ƒæŒ‡ä»¤é©±åŠ¨çš„è§†é¢‘ç¼–è¾‘æ¨¡å‹ã€‚å…³é”®åœ¨äºå¦‚ä½•ä¿è¯åˆæˆæ•°æ®çš„è´¨é‡å’Œå¤šæ ·æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDittoæ¡†æ¶åŒ…å«ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š1) æ•°æ®ç”Ÿæˆæµæ°´çº¿ï¼Œèåˆå›¾åƒç¼–è¾‘å™¨å’Œè§†é¢‘ç”Ÿæˆå™¨ï¼Œç”Ÿæˆåˆå§‹è§†é¢‘ç¼–è¾‘ç»“æœï¼›2) æ—¶é—´å¢å¼ºå™¨ï¼Œç”¨äºæé«˜è§†é¢‘çš„æ—¶é—´ä¸€è‡´æ€§ï¼›3) æ™ºèƒ½ä»£ç†ï¼Œè´Ÿè´£ç”Ÿæˆå¤šæ ·åŒ–çš„ç¼–è¾‘æŒ‡ä»¤ï¼Œå¹¶å¯¹ç”Ÿæˆç»“æœè¿›è¡Œè´¨é‡è¿‡æ»¤ã€‚æ•´ä¸ªæµç¨‹è‡ªåŠ¨åŒ–è¿è¡Œï¼Œå®ç°å¤§è§„æ¨¡æ•°æ®ç”Ÿæˆã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæ„å»ºäº†ä¸€ä¸ªå¯æ‰©å±•çš„ã€é«˜è´¨é‡çš„åˆæˆæ•°æ®ç”Ÿæˆæ¡†æ¶ã€‚é€šè¿‡ç»“åˆå›¾åƒç¼–è¾‘å™¨çš„åˆ›é€ æ€§å’Œè§†é¢‘ç”Ÿæˆå™¨çš„æ—¶åºæ€§ï¼Œä»¥åŠæ™ºèƒ½ä»£ç†çš„æ§åˆ¶ï¼Œå®ç°äº†ä½æˆæœ¬ã€é«˜è´¨é‡çš„æ•°æ®ç”Ÿæˆã€‚æ­¤å¤–ï¼Œæ—¶é—´å¢å¼ºå™¨çš„å¼•å…¥è¿›ä¸€æ­¥æå‡äº†è§†é¢‘çš„çœŸå®æ„Ÿã€‚

**å…³é”®è®¾è®¡**ï¼šæ•°æ®ç”Ÿæˆæµæ°´çº¿åˆ©ç”¨é¢„è®­ç»ƒçš„å›¾åƒç¼–è¾‘å™¨è¿›è¡Œåˆå§‹ç¼–è¾‘ï¼Œç„¶åä½¿ç”¨è§†é¢‘ç”Ÿæˆæ¨¡å‹è¿›è¡Œæ—¶åºæ‰©å±•ã€‚æ—¶é—´å¢å¼ºå™¨å¯èƒ½é‡‡ç”¨å…‰æµæˆ–ç±»ä¼¼æŠ€æœ¯æ¥å¹³æ»‘è§†é¢‘å¸§ä¹‹é—´çš„è¿‡æ¸¡ã€‚æ™ºèƒ½ä»£ç†ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æˆ–ç±»ä¼¼æ–¹æ³•æ¥å­¦ä¹ ç”Ÿæˆå¤šæ ·åŒ–çš„ç¼–è¾‘æŒ‡ä»¤ï¼Œå¹¶æ ¹æ®é¢„å®šä¹‰çš„æŒ‡æ ‡å¯¹ç”Ÿæˆç»“æœè¿›è¡Œè´¨é‡è¯„ä¼°å’Œè¿‡æ»¤ã€‚è¯¾ç¨‹å­¦ä¹ ç­–ç•¥ç”¨äºé€æ­¥æå‡æ¨¡å‹çš„è®­ç»ƒéš¾åº¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡æ„å»ºäº†åŒ…å«ä¸€ç™¾ä¸‡ä¸ªé«˜ä¿çœŸè§†é¢‘ç¼–è¾‘ç¤ºä¾‹çš„Ditto-1Mæ•°æ®é›†ï¼Œå¹¶åœ¨è¯¥æ•°æ®é›†ä¸Šè®­ç»ƒäº†Edittoæ¨¡å‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒEdittoæ¨¡å‹åœ¨æŒ‡ä»¤éµå¾ªèƒ½åŠ›ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶åœ¨æŒ‡ä»¤é©±åŠ¨çš„è§†é¢‘ç¼–è¾‘ä»»åŠ¡ä¸Šå–å¾—äº†æ–°çš„state-of-the-artã€‚å…·ä½“æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†å±•ç¤ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºè§†é¢‘å†…å®¹åˆ›ä½œã€è‡ªåŠ¨åŒ–è§†é¢‘ç¼–è¾‘ã€ä¸ªæ€§åŒ–è§†é¢‘ç”Ÿæˆç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡ç®€å•çš„æŒ‡ä»¤å¿«é€Ÿä¿®æ”¹è§†é¢‘å†…å®¹ï¼Œæ— éœ€ä¸“ä¸šçš„è§†é¢‘ç¼–è¾‘æŠ€èƒ½ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥ç”¨äºç”Ÿæˆå„ç§é£æ ¼çš„è§†é¢‘å†…å®¹ï¼Œæ»¡è¶³ä¸åŒç”¨æˆ·çš„éœ€æ±‚ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›æˆä¸ºè§†é¢‘å†…å®¹åˆ›ä½œçš„é‡è¦å·¥å…·ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Instruction-based video editing promises to democratize content creation, yet its progress is severely hampered by the scarcity of large-scale, high-quality training data. We introduce Ditto, a holistic framework designed to tackle this fundamental challenge. At its heart, Ditto features a novel data generation pipeline that fuses the creative diversity of a leading image editor with an in-context video generator, overcoming the limited scope of existing models. To make this process viable, our framework resolves the prohibitive cost-quality trade-off by employing an efficient, distilled model architecture augmented by a temporal enhancer, which simultaneously reduces computational overhead and improves temporal coherence. Finally, to achieve full scalability, this entire pipeline is driven by an intelligent agent that crafts diverse instructions and rigorously filters the output, ensuring quality control at scale. Using this framework, we invested over 12,000 GPU-days to build Ditto-1M, a new dataset of one million high-fidelity video editing examples. We trained our model, Editto, on Ditto-1M with a curriculum learning strategy. The results demonstrate superior instruction-following ability and establish a new state-of-the-art in instruction-based video editing.

