---
layout: default
title: MedBridge: Bridging Foundation Vision-Language Models to Medical Image Diagnosis in Chest X-Ray
---

# MedBridge: Bridging Foundation Vision-Language Models to Medical Image Diagnosis in Chest X-Ray

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21698" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21698v2</a>
  <a href="https://arxiv.org/pdf/2505.21698.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21698v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21698v2', 'MedBridge: Bridging Foundation Vision-Language Models to Medical Image Diagnosis in Chest X-Ray')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yitong Li, Morteza Ghahremani, Christian Wachinger

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27 (æ›´æ–°: 2025-11-24)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/ai-med/MedBridge)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMedBridgeä»¥è§£å†³åŒ»å­¦å½±åƒè¯Šæ–­ä¸­çš„é¢†åŸŸé€‚åº”é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åŒ»å­¦å½±åƒè¯Šæ–­` `è§†è§‰-è¯­è¨€æ¨¡å‹` `é¢†åŸŸé€‚åº”` `å¤šæ¨¡æ€å­¦ä¹ ` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨åŒ»å­¦å›¾åƒè¯Šæ–­ä¸­é¢ä¸´é¢†åŸŸè½¬ç§»çš„æŒ‘æˆ˜ï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚
2. MedBridgeé€šè¿‡Focal Samplingã€Query-Encoderå’ŒMixture of Expertsæœºåˆ¶ï¼Œçµæ´»é€‚åº”åŒ»å­¦å›¾åƒè¯Šæ–­ã€‚
3. åœ¨äº”ä¸ªèƒ¸éƒ¨æ”¾å°„å½±åƒåŸºå‡†æµ‹è¯•ä¸­ï¼ŒMedBridgeåœ¨å¤šæ ‡ç­¾èƒ¸éƒ¨ç–¾ç—…è¯Šæ–­ä¸­AUCæå‡6-15%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œè§†è§‰-è¯­è¨€åŸºç¡€æ¨¡å‹åœ¨è‡ªç„¶å›¾åƒåˆ†ç±»ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œä½†åœ¨åŒ»å­¦å›¾åƒé¢†åŸŸç”±äºæ˜¾è‘—çš„é¢†åŸŸè½¬ç§»è€Œè¡¨ç°ä¸ä½³ã€‚è®­ç»ƒåŒ»å­¦åŸºç¡€æ¨¡å‹éœ€è¦å¤§é‡çš„æ ‡æ³¨æ•°æ®å’Œé«˜è®¡ç®—èƒ½åŠ›ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†MedBridgeï¼Œä¸€ä¸ªè½»é‡çº§çš„å¤šæ¨¡æ€é€‚åº”æ¡†æ¶ï¼Œæ—¨åœ¨ä»¥æœ€å°çš„å¼€é”€çµæ´»åœ°é‡æ–°åˆ©ç”¨ä»»æ„é¢„è®­ç»ƒçš„åŸºç¡€è§†è§‰-è¯­è¨€æ¨¡å‹è¿›è¡ŒåŒ»å­¦å›¾åƒè¯Šæ–­ã€‚MedBridgeåŒ…å«ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ï¼šFocal Samplingæ¨¡å—ã€Query-Encoderæ¨¡å‹å’ŒMixture of Expertsæœºåˆ¶ã€‚æˆ‘ä»¬åœ¨äº”ä¸ªèƒ¸éƒ¨æ”¾å°„å½±åƒåŸºå‡†æµ‹è¯•ä¸Šè¯„ä¼°äº†MedBridgeï¼Œç»“æœæ˜¾ç¤ºå…¶åœ¨è·¨é¢†åŸŸå’Œé¢†åŸŸå†…é€‚åº”ä»»åŠ¡ä¸­å‡è¡¨ç°ä¼˜è¶Šï¼ŒAUCæå‡6-15%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³åŒ»å­¦å½±åƒè¯Šæ–­ä¸­è§†è§‰-è¯­è¨€æ¨¡å‹å› é¢†åŸŸè½¬ç§»è€Œå¯¼è‡´çš„æ€§èƒ½ä¸è¶³é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®å’Œé«˜è®¡ç®—èµ„æºï¼Œé™åˆ¶äº†å…¶åœ¨åŒ»å­¦é¢†åŸŸçš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMedBridgeçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è½»é‡çº§çš„é€‚åº”æ¡†æ¶ï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„è§†è§‰-è¯­è¨€æ¨¡å‹è¿›è¡ŒåŒ»å­¦å›¾åƒè¯Šæ–­ï¼Œè€Œæ— éœ€å¯¹åŸºç¡€æ¨¡å‹è¿›è¡Œé‡è®­ç»ƒã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMedBridgeçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šFocal Samplingæ¨¡å—ç”¨äºæå–é«˜åˆ†è¾¨ç‡å±€éƒ¨åŒºåŸŸï¼ŒQuery-Encoderæ¨¡å‹ç”¨äºå¯¹é½ç‰¹å¾å›¾ä¸åŒ»å­¦è¯­ä¹‰ï¼ŒMixture of Expertsæœºåˆ¶åˆ™é€šè¿‡å¯å­¦ä¹ æŸ¥è¯¢æ•´åˆå¤šç§æ¨¡å‹çš„ä¼˜åŠ¿ã€‚

**å…³é”®åˆ›æ–°**ï¼šMedBridgeçš„åˆ›æ–°ç‚¹åœ¨äºå…¶Focal Samplingå’ŒQuery-Encoderè®¾è®¡ï¼Œä½¿å¾—åœ¨ä¸é‡è®­ç»ƒåŸºç¡€å±‚çš„æƒ…å†µä¸‹ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ•æ‰åŒ»å­¦å›¾åƒä¸­çš„ç»†å¾®ç—…ç†ç‰¹å¾ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨Focal Samplingæ¨¡å—ä¸­ï¼Œé‡‡ç”¨äº†é«˜åˆ†è¾¨ç‡å±€éƒ¨åŒºåŸŸæå–æŠ€æœ¯ï¼›Query-Encoderä½¿ç”¨äº†ä¸€å°ç»„å¯å­¦ä¹ çš„æŸ¥è¯¢æ¥å¯¹é½ç‰¹å¾å›¾ï¼›Mixture of Expertsæœºåˆ¶åˆ™é€šè¿‡å¯å­¦ä¹ çš„æŸ¥è¯¢åŠ¨æ€é€‰æ‹©æœ€ä¼˜æ¨¡å‹ç»„åˆã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å’Œå‚æ•°è®¾ç½®åœ¨è®ºæ–‡ä¸­è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨äº”ä¸ªèƒ¸éƒ¨æ”¾å°„å½±åƒåŸºå‡†æµ‹è¯•ä¸­ï¼ŒMedBridgeåœ¨å¤šæ ‡ç­¾èƒ¸éƒ¨ç–¾ç—…è¯Šæ–­ä»»åŠ¡ä¸­ï¼Œç›¸è¾ƒäºæœ€å…ˆè¿›çš„è§†è§‰-è¯­è¨€æ¨¡å‹é€‚åº”æ–¹æ³•ï¼ŒAUCæå‡äº†6-15%ã€‚è¿™ä¸€ç»“æœè¡¨æ˜MedBridgeåœ¨è·¨é¢†åŸŸå’Œé¢†åŸŸå†…é€‚åº”ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŒ»å­¦å½±åƒè¯Šæ–­ã€ä¸´åºŠè¾…åŠ©å†³ç­–å’ŒåŒ»ç–—æ•°æ®åˆ†æã€‚MedBridgeçš„è®¾è®¡ä½¿å…¶èƒ½å¤Ÿåœ¨èµ„æºæœ‰é™çš„æƒ…å†µä¸‹ï¼Œåˆ©ç”¨ç°æœ‰çš„è§†è§‰-è¯­è¨€æ¨¡å‹è¿›è¡Œé«˜æ•ˆçš„åŒ»å­¦å›¾åƒåˆ†æï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent vision-language foundation models deliver state-of-the-art results in natural image classification, but falter in medical images due to pronounced domain shifts. Training a medical foundation model also requires substantial resources, including extensive annotated data and high computational capacity. To bridge this gap with minimal overhead, we introduce MedBridge, a lightweight multimodal adaptation framework that flexibly re-purposes arbitrary pre-trained foundation VLMs for medical image diagnosis. MedBridge comprises three novel core components. First, a Focal Sampling module that subsamples and extracts high-resolution local regions to capture subtle pathological features, compensating for the limited input resolution of foundation VLMs. Second, a Query-Encoder model with a small set of learnable queries to align the feature maps of frozen VLMs with medical semantics, without requiring retraining of the backbone layers. Third, a Mixture of Experts mechanism, driven by learnable queries, harnesses the complementary strength of various VLMs to maximize diagnostic performance. We evaluate MedBridge on five chest radiograph benchmarks in three key adaptation tasks, demonstrating its superior performance in both cross-domain and in-domain adaptation settings under varying levels of training data availability. MedBridge achieved an improvement of 6-15% in AUC compared to state-of-the-art VLM adaptation methods in multi-label thoracic disease diagnosis, underscoring its effectiveness in leveraging diverse foundation models for accurate and data-efficient medical diagnosis. Our project and code are available at https://github.com/ai-med/MedBridge.

