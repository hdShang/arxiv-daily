---
layout: default
title: DynamicVL: Benchmarking Multimodal Large Language Models for Dynamic City Understanding
---

# DynamicVL: Benchmarking Multimodal Large Language Models for Dynamic City Understanding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21076" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21076v2</a>
  <a href="https://arxiv.org/pdf/2505.21076.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21076v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21076v2', 'DynamicVL: Benchmarking Multimodal Large Language Models for Dynamic City Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Weihao Xuan, Junjue Wang, Heli Qi, Zihang Chen, Zhuo Zheng, Yanfei Zhong, Junshi Xia, Naoto Yokoya

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27 (æ›´æ–°: 2025-10-26)

**å¤‡æ³¨**: NeurIPS 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDVL-Suiteä»¥è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨åŸå¸‚åŠ¨æ€ç†è§£ä¸­çš„ä¸è¶³**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `åŸå¸‚åŠ¨æ€ç†è§£` `é¥æ„Ÿå½±åƒåˆ†æ` `æŒ‡ä»¤è°ƒä¼˜` `æ•°æ®é›†æ„å»º` `é•¿æœŸè§‚æµ‹` `æ¨¡å‹è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨é•¿æœŸåŸå¸‚åŠ¨æ€ç†è§£æ–¹é¢å­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œä¸»è¦é›†ä¸­äºå•ä¸€æ—¶é—´ç‚¹æˆ–åŒæ—¶é—´ç‚¹çš„å½±åƒåˆ†æã€‚
2. æœ¬æ–‡æå‡ºDVL-Suiteæ¡†æ¶ï¼ŒåŒ…å«DVL-Benchå’ŒDVL-Instructï¼Œæ—¨åœ¨é€šè¿‡å¤šæ—¶ç›¸é¥æ„Ÿå½±åƒæå‡åŸå¸‚åŠ¨æ€åˆ†æèƒ½åŠ›ã€‚
3. å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼Œ18ç§æœ€å…ˆè¿›çš„MLLMsåœ¨é•¿æœŸæ—¶é—´ç†è§£å’Œå®šé‡åˆ†ææ–¹é¢å­˜åœ¨å±€é™ï¼ŒDVLChatæ¨¡å‹åœ¨å›¾åƒé—®ç­”å’Œåƒç´ åˆ†å‰²ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨è§†è§‰ç†è§£æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨é•¿æœŸåœ°çƒè§‚æµ‹åˆ†æä¸­çš„åº”ç”¨ä»ç„¶æœ‰é™ï¼Œä¸»è¦é›†ä¸­äºå•æ—¶ç›¸æˆ–åŒæ—¶ç›¸å½±åƒã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡å¼•å…¥äº†DVL-Suiteï¼Œè¿™æ˜¯ä¸€ä¸ªå…¨é¢çš„æ¡†æ¶ï¼Œç”¨äºé€šè¿‡é¥æ„Ÿå½±åƒåˆ†æé•¿æœŸåŸå¸‚åŠ¨æ€ã€‚è¯¥æ¡†æ¶åŒ…å«14,871å¹…é«˜åˆ†è¾¨ç‡ï¼ˆ1.0ç±³ï¼‰å¤šæ—¶ç›¸å½±åƒï¼Œè¦†ç›–2005å¹´è‡³2023å¹´é—´ç¾å›½42ä¸ªä¸»è¦åŸå¸‚ï¼Œåˆ†ä¸ºDVL-Benchå’ŒDVL-Instructä¸¤ä¸ªéƒ¨åˆ†ã€‚DVL-BenchåŒ…æ‹¬å…­ä¸ªåŸå¸‚ç†è§£ä»»åŠ¡ï¼Œä»åŸºç¡€çš„å˜åŒ–æ£€æµ‹åˆ°å®šé‡åˆ†æå’Œå…¨é¢çš„åŸå¸‚å™äº‹ï¼Œæ•æ‰å¤šæ ·çš„åŸå¸‚åŠ¨æ€ã€‚æˆ‘ä»¬è¯„ä¼°äº†18ç§æœ€å…ˆè¿›çš„MLLMsï¼Œæ­ç¤ºäº†å®ƒä»¬åœ¨é•¿æœŸæ—¶é—´ç†è§£å’Œå®šé‡åˆ†æä¸­çš„å±€é™æ€§ã€‚è¿™äº›æŒ‘æˆ˜ä¿ƒä½¿æˆ‘ä»¬åˆ›å»ºäº†DVL-Instructï¼Œä¸€ä¸ªä¸“é—¨çš„æŒ‡ä»¤è°ƒä¼˜æ•°æ®é›†ï¼Œä»¥å¢å¼ºæ¨¡å‹åœ¨å¤šæ—¶ç›¸åœ°çƒè§‚æµ‹ä¸­çš„èƒ½åŠ›ã€‚åŸºäºè¯¥æ•°æ®é›†ï¼Œæˆ‘ä»¬å¼€å‘äº†DVLChatï¼Œä¸€ä¸ªèƒ½å¤Ÿè¿›è¡Œå›¾åƒçº§é—®ç­”å’Œåƒç´ çº§åˆ†å‰²çš„åŸºçº¿æ¨¡å‹ï¼Œä¿ƒè¿›é€šè¿‡è¯­è¨€äº¤äº’å¯¹åŸå¸‚åŠ¨æ€çš„å…¨é¢ç†è§£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨é•¿æœŸåŸå¸‚åŠ¨æ€ç†è§£ä¸­çš„ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­äºå•æ—¶ç›¸æˆ–åŒæ—¶ç›¸å½±åƒï¼Œç¼ºä¹å¯¹å¤šæ—¶ç›¸æ•°æ®çš„æœ‰æ•ˆåˆ†æèƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥DVL-Suiteæ¡†æ¶ï¼Œç»“åˆDVL-Benchå’ŒDVL-Instructï¼Œæä¾›ä¸€ä¸ªå…¨é¢çš„åˆ†æå·¥å…·ï¼Œæå‡æ¨¡å‹åœ¨å¤šæ—¶ç›¸é¥æ„Ÿå½±åƒåˆ†æä¸­çš„èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDVL-Suiteç”±ä¸¤ä¸ªä¸»è¦ç»„ä»¶ç»„æˆï¼šDVL-Benchç”¨äºè¯„ä¼°åŸå¸‚ç†è§£ä»»åŠ¡ï¼ŒDVL-Instructç”¨äºæŒ‡ä»¤è°ƒä¼˜ï¼Œæ•´ä½“æµç¨‹åŒ…æ‹¬æ•°æ®æ”¶é›†ã€ä»»åŠ¡è®¾è®¡ã€æ¨¡å‹è¯„ä¼°å’Œä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šDVL-Instructä½œä¸ºä¸“é—¨çš„æŒ‡ä»¤è°ƒä¼˜æ•°æ®é›†ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨å¤šæ—¶ç›¸åœ°çƒè§‚æµ‹ä¸­çš„è¡¨ç°ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†æ›´ä¸ºç³»ç»Ÿçš„åˆ†ææ¡†æ¶ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å¤šå±‚æ¬¡çš„ä»»åŠ¡ç»“æ„ï¼ŒåŒ…æ‹¬åƒç´ çº§å˜åŒ–æ£€æµ‹å’ŒåŒºåŸŸçº§å®šé‡åˆ†æï¼ŒåŒæ—¶ä¼˜åŒ–äº†æŸå¤±å‡½æ•°ä»¥é€‚åº”å¤šæ—¶ç›¸æ•°æ®çš„ç‰¹æ€§ã€‚é€šè¿‡è¿™äº›è®¾è®¡ï¼Œæ¨¡å‹åœ¨ç†è§£åŸå¸‚åŠ¨æ€æ–¹é¢è¡¨ç°å‡ºæ›´é«˜çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒDVLChatæ¨¡å‹åœ¨å›¾åƒçº§é—®ç­”å’Œåƒç´ çº§åˆ†å‰²ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ¨¡å‹ï¼Œå‡†ç¡®ç‡æå‡äº†15%ä»¥ä¸Šï¼Œå±•ç°äº†åœ¨å¤šæ—¶ç›¸é¥æ„Ÿå½±åƒåˆ†æä¸­çš„å¼ºå¤§èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŸå¸‚è§„åˆ’ã€ç¯å¢ƒç›‘æµ‹å’Œç¾å®³è¯„ä¼°ç­‰ã€‚é€šè¿‡å¯¹é•¿æœŸåŸå¸‚åŠ¨æ€çš„æ·±å…¥ç†è§£ï¼Œèƒ½å¤Ÿä¸ºæ”¿ç­–åˆ¶å®šè€…å’ŒåŸå¸‚ç®¡ç†è€…æä¾›ç§‘å­¦ä¾æ®ï¼Œä¿ƒè¿›å¯æŒç»­å‘å±•ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶è¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–é¢†åŸŸï¼Œå¦‚å†œä¸šç›‘æµ‹å’Œç”Ÿæ€ç¯å¢ƒä¿æŠ¤ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal large language models (MLLMs) have demonstrated remarkable capabilities in visual understanding, but their application to long-term Earth observation analysis remains limited, primarily focusing on single-temporal or bi-temporal imagery. To address this gap, we introduce DVL-Suite, a comprehensive framework for analyzing long-term urban dynamics through remote sensing imagery. Our suite comprises 14,871 high-resolution (1.0m) multi-temporal images spanning 42 major cities in the U.S. from 2005 to 2023, organized into two components: DVL-Bench and DVL-Instruct. The DVL-Bench includes six urban understanding tasks, from fundamental change detection (pixel-level) to quantitative analyses (regional-level) and comprehensive urban narratives (scene-level), capturing diverse urban dynamics including expansion/transformation patterns, disaster assessment, and environmental challenges. We evaluate 18 state-of-the-art MLLMs and reveal their limitations in long-term temporal understanding and quantitative analysis. These challenges motivate the creation of DVL-Instruct, a specialized instruction-tuning dataset designed to enhance models' capabilities in multi-temporal Earth observation. Building upon this dataset, we develop DVLChat, a baseline model capable of both image-level question-answering and pixel-level segmentation, facilitating a comprehensive understanding of city dynamics through language interactions.

