---
layout: default
title: FastFace: Tuning Identity Preservation in Distilled Diffusion via Guidance and Attention
---

# FastFace: Tuning Identity Preservation in Distilled Diffusion via Guidance and Attention

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21144" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21144v2</a>
  <a href="https://arxiv.org/pdf/2505.21144.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21144v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21144v2', 'FastFace: Tuning Identity Preservation in Distilled Diffusion via Guidance and Attention')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sergey Karpukhin, Vadim Titov, Andrey Kuznetsov, Aibek Alanov

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27 (æ›´æ–°: 2025-05-28)

**å¤‡æ³¨**: code available at https://github.com/ControlGenAI/FastFace

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFastFaceæ¡†æ¶ä»¥è§£å†³æ‰©æ•£æ¨¡å‹ä¸­èº«ä»½ä¿ç•™é€‚é…å™¨çš„è®­ç»ƒæ•ˆç‡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)**

**å…³é”®è¯**: `èº«ä»½ä¿ç•™` `æ‰©æ•£æ¨¡å‹` `ä¸ªæ€§åŒ–ç”Ÿæˆ` `æ— è®­ç»ƒé€‚åº”` `å¼•å¯¼æœºåˆ¶` `æ³¨æ„åŠ›æœºåˆ¶` `ç”Ÿæˆä¿çœŸåº¦` `å¿«é€Ÿæ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰èº«ä»½ä¿ç•™é€‚é…å™¨ä¸»è¦ä¸åŸºç¡€æ‰©æ•£æ¨¡å‹å…±åŒè®­ç»ƒï¼Œå¯¼è‡´æ¨ç†é€Ÿåº¦æ…¢ï¼Œå½±å“ç”Ÿæˆæ•ˆç‡ã€‚
2. æœ¬æ–‡æå‡ºFastFaceæ¡†æ¶ï¼Œé€šè¿‡æ— è®­ç»ƒé€‚åº”é¢„è®­ç»ƒèº«ä»½é€‚é…å™¨ï¼Œä¼˜åŒ–å¼•å¯¼å’Œæ³¨æ„åŠ›æœºåˆ¶ä»¥æå‡ç”Ÿæˆæ•ˆæœã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒFastFaceåœ¨èº«ä»½ç›¸ä¼¼æ€§å’Œç”Ÿæˆä¿çœŸåº¦ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸”æ¨ç†é€Ÿåº¦å¾—åˆ°æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œé’ˆå¯¹ä¸ªæ€§åŒ–ç”Ÿæˆçš„èº«ä»½ä¿ç•™é€‚é…å™¨åœ¨æ‰©æ•£æ¨¡å‹ä¸­å¾—åˆ°äº†å¹¿æ³›åº”ç”¨ã€‚ç„¶è€Œï¼Œè¿™äº›é€‚é…å™¨ä¸»è¦ä¸åŸºç¡€æ‰©æ•£æ¨¡å‹å…±åŒè®­ç»ƒï¼Œå¯¼è‡´å¤šæ­¥æ¨ç†é€Ÿåº¦ç¼“æ…¢ã€‚æœ¬æ–‡æ—¨åœ¨é€šè¿‡é‡æ–°è®¾è®¡æ— åˆ†ç±»å™¨å¼•å¯¼å’Œæ³¨æ„åŠ›æœºåˆ¶ï¼Œæå‡ºä¸€ç§æ— éœ€è®­ç»ƒçš„é¢„è®­ç»ƒèº«ä»½é€‚é…å™¨é€‚åº”æ–¹æ³•ï¼Œä»è€ŒåŠ é€Ÿæ‰©æ•£æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ã€‚æˆ‘ä»¬æå‡ºçš„FastFaceæ¡†æ¶èƒ½å¤Ÿåœ¨å°‘é‡æ­¥éª¤å†…å®ç°é£æ ¼ç”Ÿæˆï¼ŒåŒæ—¶æé«˜èº«ä»½ç›¸ä¼¼æ€§å’Œä¿çœŸåº¦ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼€å‘äº†ä¸€ç§è§£è€¦çš„å…¬å…±è¯„ä¼°åè®®ï¼Œç”¨äºè¯„ä¼°èº«ä»½ä¿ç•™é€‚é…å™¨çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è§£å†³çš„é—®é¢˜æ˜¯å¦‚ä½•åœ¨ä¸è¿›è¡Œè®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œå°†é¢„è®­ç»ƒçš„èº«ä»½é€‚é…å™¨æœ‰æ•ˆåœ°åº”ç”¨äºæ‰©æ•£æ¨¡å‹ä¸­ï¼Œä»¥å…‹æœç°æœ‰æ–¹æ³•åœ¨å¤šæ­¥æ¨ç†æ—¶çš„é€Ÿåº¦ç“¶é¢ˆã€‚ç°æœ‰æ–¹æ³•çš„ç—›ç‚¹åœ¨äºå…¶è®­ç»ƒè¿‡ç¨‹å¤æ‚ä¸”æ¨ç†æ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡é‡æ–°è®¾è®¡æ— åˆ†ç±»å™¨å¼•å¯¼å’Œæ³¨æ„åŠ›æœºåˆ¶ï¼Œæ¥å®ç°å¯¹èº«ä»½é€‚é…å™¨çš„å¿«é€Ÿé€‚åº”ã€‚é€šè¿‡è¿™ç§è®¾è®¡ï¼Œèƒ½å¤Ÿåœ¨å°‘é‡æ­¥éª¤å†…å®ç°é«˜è´¨é‡çš„ä¸ªæ€§åŒ–ç”Ÿæˆï¼ŒåŒæ—¶ä¿æŒèº«ä»½çš„ç›¸ä¼¼æ€§å’Œç”Ÿæˆçš„ä¿çœŸåº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFastFaceæ¡†æ¶çš„æ•´ä½“æ¶æ„åŒ…æ‹¬å‡ ä¸ªä¸»è¦æ¨¡å—ï¼šèº«ä»½é€‚é…å™¨ã€å¼•å¯¼æœºåˆ¶å’Œæ³¨æ„åŠ›æ“ä½œã€‚é€šè¿‡è§£è€¦è¿™äº›æ¨¡å—ï¼Œèƒ½å¤Ÿå®ç°æ›´çµæ´»çš„ç”Ÿæˆè¿‡ç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„é€‚åº”æ–¹æ³•ï¼Œå¹¶é€šè¿‡ä¼˜åŒ–å¼•å¯¼å’Œæ³¨æ„åŠ›æœºåˆ¶ï¼Œæ˜¾è‘—æé«˜äº†ç”Ÿæˆçš„æ•ˆç‡å’Œè´¨é‡ã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºï¼Œåè€…é€šå¸¸éœ€è¦å¤æ‚çš„è®­ç»ƒè¿‡ç¨‹ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å…³é”®è®¾è®¡æ–¹é¢ï¼Œæœ¬æ–‡å¯¹å¼•å¯¼æœºåˆ¶å’Œæ³¨æ„åŠ›æ“ä½œè¿›è¡Œäº†ç²¾ç»†è°ƒæ•´ï¼Œä»¥ç¡®ä¿åœ¨å°‘é‡æ­¥éª¤å†…å®ç°æœ€ä½³çš„ç”Ÿæˆæ•ˆæœã€‚åŒæ—¶ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–èº«ä»½ç›¸ä¼¼æ€§å’Œç”Ÿæˆä¿çœŸåº¦ã€‚é€šè¿‡è¿™äº›è®¾è®¡ï¼ŒFastFaceæ¡†æ¶èƒ½å¤Ÿåœ¨ä¿æŒç”Ÿæˆè´¨é‡çš„åŒæ—¶ï¼Œæ˜¾è‘—æé«˜æ¨ç†é€Ÿåº¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒFastFaceæ¡†æ¶åœ¨èº«ä»½ç›¸ä¼¼æ€§å’Œç”Ÿæˆä¿çœŸåº¦ä¸Šå‡ä¼˜äºç°æœ‰çš„èº«ä»½ä¿ç•™é€‚é…å™¨ï¼Œæ¨ç†é€Ÿåº¦æå‡å¹…åº¦è¾¾åˆ°50%ä»¥ä¸Šï¼Œæ˜¾è‘—æé«˜äº†ç”Ÿæˆæ•ˆç‡ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒFastFaceåœ¨å®é™…åº”ç”¨ä¸­å…·æœ‰è¾ƒå¼ºçš„ç«äº‰åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ä¸ªæ€§åŒ–å›¾åƒç”Ÿæˆã€è™šæ‹Ÿè§’è‰²åˆ›å»ºå’Œç¤¾äº¤åª’ä½“å†…å®¹ç”Ÿæˆç­‰ã€‚é€šè¿‡æé«˜ç”Ÿæˆæ•ˆç‡å’Œèº«ä»½ä¿ç•™èƒ½åŠ›ï¼ŒFastFaceæ¡†æ¶èƒ½å¤Ÿä¸ºç”¨æˆ·æä¾›æ›´é«˜è´¨é‡çš„ä¸ªæ€§åŒ–ä½“éªŒï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„å¸‚åœºå‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In latest years plethora of identity-preserving adapters for a personalized generation with diffusion models have been released. Their main disadvantage is that they are dominantly trained jointly with base diffusion models, which suffer from slow multi-step inference. This work aims to tackle the challenge of training-free adaptation of pretrained ID-adapters to diffusion models accelerated via distillation - through careful re-design of classifier-free guidance for few-step stylistic generation and attention manipulation mechanisms in decoupled blocks to improve identity similarity and fidelity, we propose universal FastFace framework. Additionally, we develop a disentangled public evaluation protocol for id-preserving adapters.

