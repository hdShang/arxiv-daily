---
layout: default
title: Advancing high-fidelity 3D and Texture Generation with 2.5D latents
---

# Advancing high-fidelity 3D and Texture Generation with 2.5D latents

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21050" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21050v2</a>
  <a href="https://arxiv.org/pdf/2505.21050.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21050v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21050v2', 'Advancing high-fidelity 3D and Texture Generation with 2.5D latents')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xin Yang, Jiantao Lin, Yingjie Xu, Haodong Li, Yingcong Chen

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27 (æ›´æ–°: 2025-05-28)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§æ–°æ¡†æ¶ä»¥è§£å†³3Då‡ ä½•ä¸çº¹ç†ç”Ÿæˆä¸ä¸€è‡´é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `3Dç”Ÿæˆ` `çº¹ç†ç”Ÿæˆ` `å‡ ä½•ä¸€è‡´æ€§` `2.5Dè¡¨ç¤º` `å¤šè§†è§’å›¾åƒ` `æ·±åº¦å­¦ä¹ ` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰3Dç”Ÿæˆæ–¹æ³•é€šå¸¸åœ¨å‡ ä½•å’Œçº¹ç†ç”Ÿæˆä¸Šé‡‡ç”¨ä¸åŒæ¨¡å‹ï¼Œå¯¼è‡´ç”Ÿæˆç»“æœç¼ºä¹ä¸€è‡´æ€§ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°æ¡†æ¶ï¼Œé€šè¿‡2.5Dè¡¨ç¤ºå®ç°3Då‡ ä½•å’Œçº¹ç†çš„è”åˆç”Ÿæˆï¼Œæå‡ç”Ÿæˆè´¨é‡ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ¨¡å‹åœ¨é«˜è´¨é‡3Då¯¹è±¡ç”Ÿæˆä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä¸”åœ¨çº¹ç†ç”Ÿæˆæ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡å·²æœ‰å¤§è§„æ¨¡3Dæ•°æ®é›†å’Œ3Dç”Ÿæˆæ¨¡å‹çš„è¿›å±•ï¼Œ3Då‡ ä½•å’Œçº¹ç†æ•°æ®çš„å¤æ‚æ€§åŠè´¨é‡ä¸å‡ä»ç„¶é˜»ç¢äº†3Dç”ŸæˆæŠ€æœ¯çš„æ€§èƒ½ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸åˆ†é˜¶æ®µç”Ÿæˆ3Då‡ ä½•å’Œçº¹ç†ï¼Œå¯¼è‡´ä¸¤è€…ä¹‹é—´ç¼ºä¹ä¸€è‡´æ€§ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶ï¼Œä¸“æ³¨äºè”åˆç”Ÿæˆ3Då‡ ä½•å’Œçº¹ç†ï¼Œåˆ©ç”¨å¯æ— ç¼è½¬æ¢çš„2.5Dè¡¨ç¤ºã€‚é€šè¿‡æ•´åˆå¤šè§†è§’RGBã€æ³•çº¿å’Œåæ ‡å›¾åƒä¸ºç»Ÿä¸€çš„2.5Dæ½œåœ¨è¡¨ç¤ºï¼Œå¹¶é€‚é…é¢„è®­ç»ƒçš„2DåŸºç¡€æ¨¡å‹ï¼Œæœ€ç»ˆå¼•å…¥è½»é‡çº§çš„2.5Dåˆ°3Dçš„ç²¾ç‚¼è§£ç å™¨æ¡†æ¶ï¼Œç”Ÿæˆé«˜ä¿çœŸ3Dè¡¨ç¤ºã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨ç”Ÿæˆé«˜è´¨é‡3Då¯¹è±¡æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œä¸”åœ¨å‡ ä½•æ¡ä»¶ä¸‹çš„çº¹ç†ç”Ÿæˆä¸Šæ˜¾è‘—è¶…è¶Šç°æœ‰æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰3Dç”ŸæˆæŠ€æœ¯ä¸­å‡ ä½•ä¸çº¹ç†ç”Ÿæˆä¸ä¸€è‡´çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸åˆ†é˜¶æ®µå¤„ç†ï¼Œå¯¼è‡´ç”Ÿæˆç»“æœçš„ç»“æ„å’Œé¢œè‰²ä¸åè°ƒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºä¸€ç§åŸºäº2.5Dè¡¨ç¤ºçš„è”åˆç”Ÿæˆæ¡†æ¶ï¼Œèƒ½å¤Ÿåœ¨2Dä¸3Dä¹‹é—´æ— ç¼è½¬æ¢ï¼Œä»è€Œæé«˜ç”Ÿæˆçš„ä¸€è‡´æ€§å’Œè´¨é‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ•´åˆå¤šè§†è§’RGBã€æ³•çº¿å’Œåæ ‡å›¾åƒä¸ºç»Ÿä¸€çš„2.5Dæ½œåœ¨è¡¨ç¤ºï¼›å…¶æ¬¡ï¼Œåˆ©ç”¨æ–‡æœ¬å’Œå›¾åƒæ¡ä»¶é€‚é…é¢„è®­ç»ƒçš„2DåŸºç¡€æ¨¡å‹è¿›è¡Œé«˜ä¿çœŸ2.5Dç”Ÿæˆï¼›æœ€åï¼Œé‡‡ç”¨è½»é‡çº§çš„2.5Dåˆ°3Dç²¾ç‚¼è§£ç å™¨æ¡†æ¶ç”Ÿæˆè¯¦ç»†çš„3Dè¡¨ç¤ºã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæå‡ºäº†2.5Dæ½œåœ¨è¡¨ç¤ºçš„æ¦‚å¿µï¼Œä½¿å¾—å‡ ä½•å’Œçº¹ç†çš„ç”Ÿæˆå¯ä»¥åœ¨åŒä¸€æ¡†æ¶ä¸‹è¿›è¡Œï¼Œä»è€Œå…‹æœäº†ä¼ ç»Ÿæ–¹æ³•çš„å±€é™æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ç¡®ä¿ç”Ÿæˆç»“æœçš„ç»“æ„å’Œé¢œè‰²ä¸€è‡´æ€§ï¼ŒåŒæ—¶ä¼˜åŒ–äº†ç½‘ç»œç»“æ„ä»¥æé«˜ç”Ÿæˆæ•ˆç‡å’Œè´¨é‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ¨¡å‹åœ¨ç”Ÿæˆé«˜è´¨é‡3Då¯¹è±¡æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œç”Ÿæˆçš„3Då¯¹è±¡åœ¨ç»“æ„å’Œé¢œè‰²ä¸€è‡´æ€§ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå°¤å…¶åœ¨å‡ ä½•æ¡ä»¶ä¸‹çš„çº¹ç†ç”Ÿæˆä¸Šï¼Œæ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°XX%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è™šæ‹Ÿç°å®ã€æ¸¸æˆå¼€å‘ã€ç”µå½±ç‰¹æ•ˆåˆ¶ä½œç­‰ï¼Œèƒ½å¤Ÿä¸º3Då†…å®¹åˆ›ä½œæä¾›æ›´é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯å¯èƒ½åœ¨è‡ªåŠ¨åŒ–è®¾è®¡ã€æ•°å­—å­ªç”Ÿç­‰é¢†åŸŸå‘æŒ¥é‡è¦ä½œç”¨ï¼Œæ¨åŠ¨3Dç”ŸæˆæŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Despite the availability of large-scale 3D datasets and advancements in 3D generative models, the complexity and uneven quality of 3D geometry and texture data continue to hinder the performance of 3D generation techniques. In most existing approaches, 3D geometry and texture are generated in separate stages using different models and non-unified representations, frequently leading to unsatisfactory coherence between geometry and texture. To address these challenges, we propose a novel framework for joint generation of 3D geometry and texture. Specifically, we focus in generate a versatile 2.5D representations that can be seamlessly transformed between 2D and 3D. Our approach begins by integrating multiview RGB, normal, and coordinate images into a unified representation, termed as 2.5D latents. Next, we adapt pre-trained 2D foundation models for high-fidelity 2.5D generation, utilizing both text and image conditions. Finally, we introduce a lightweight 2.5D-to-3D refiner-decoder framework that efficiently generates detailed 3D representations from 2.5D images. Extensive experiments demonstrate that our model not only excels in generating high-quality 3D objects with coherent structure and color from text and image inputs but also significantly outperforms existing methods in geometry-conditioned texture generation.

