---
layout: default
title: Paper2Poster: Towards Multimodal Poster Automation from Scientific Papers
---

# Paper2Poster: Towards Multimodal Poster Automation from Scientific Papers

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21497" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21497v2</a>
  <a href="https://arxiv.org/pdf/2505.21497.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21497v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21497v2', 'Paper2Poster: Towards Multimodal Poster Automation from Scientific Papers')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wei Pang, Kevin Qinghong Lin, Xiangru Jian, Xi He, Philip Torr

**åˆ†ç±»**: cs.CV, cs.AI, cs.CL, cs.MA

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27 (æ›´æ–°: 2025-10-30)

**å¤‡æ³¨**: Project Page: https://github.com/Paper2Poster/Paper2Poster

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Paper2Poster/Paper2Poster)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPaper2Posterä»¥è§£å†³å­¦æœ¯æµ·æŠ¥è‡ªåŠ¨ç”Ÿæˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å­¦æœ¯æµ·æŠ¥ç”Ÿæˆ` `å¤šæ¨¡æ€å­¦ä¹ ` `è§†è§‰è¯­è¨€æ¨¡å‹` `ä¿¡æ¯å‹ç¼©` `è‡ªåŠ¨åŒ–å·¥å…·`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å­¦æœ¯æµ·æŠ¥ç”Ÿæˆæ–¹æ³•åœ¨è§†è§‰è¿è´¯æ€§å’Œä¿¡æ¯ä¼ è¾¾ä¸Šå­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥æœ‰æ•ˆå‹ç¼©é•¿ç¯‡æ–‡æ¡£ã€‚
2. æœ¬æ–‡æå‡ºäº†PosterAgentï¼Œä¸€ä¸ªå¤šä»£ç†ç®¡é“ï¼Œé€šè¿‡è§£æã€è§„åˆ’å’Œç»˜åˆ¶æ¨¡å—å®ç°æµ·æŠ¥çš„è‡ªåŠ¨ç”Ÿæˆã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºQwen-2.5ç³»åˆ—çš„å¼€æºå˜ä½“åœ¨å¤šä¸ªè¯„ä¼°æŒ‡æ ‡ä¸Šä¼˜äºç°æœ‰ç³»ç»Ÿï¼Œä¸”ä½¿ç”¨çš„tokenæ•°é‡å‡å°‘äº†87%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å­¦æœ¯æµ·æŠ¥ç”Ÿæˆæ˜¯ç§‘å­¦ä¼ æ’­ä¸­çš„ä¸€é¡¹é‡è¦ä½†å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œéœ€å°†é•¿ç¯‡æ–‡æ¡£å‹ç¼©ä¸ºè§†è§‰ä¸Šè¿è´¯çš„å•é¡µã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡é¦–æ¬¡å¼•å…¥äº†æµ·æŠ¥ç”Ÿæˆçš„åŸºå‡†å’Œè¯„ä¼°æŒ‡æ ‡ï¼Œç»“åˆä¼šè®®è®ºæ–‡ä¸ä½œè€…è®¾è®¡çš„æµ·æŠ¥ï¼Œè¯„ä¼°è¾“å‡ºçš„è§†è§‰è´¨é‡ã€æ–‡æœ¬è¿è´¯æ€§ã€æ•´ä½“è¯„ä¼°åŠæµ·æŠ¥å†…å®¹ä¼ è¾¾èƒ½åŠ›ã€‚åŸºäºæ­¤åŸºå‡†ï¼Œæå‡ºäº†PosterAgentï¼Œä¸€ä¸ªè‡ªä¸Šè€Œä¸‹çš„å¤šä»£ç†ç®¡é“ï¼ŒåŒ…å«è§£æã€è§„åˆ’å’Œç»˜åˆ¶ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚ç»¼åˆè¯„ä¼°æ˜¾ç¤ºï¼ŒåŸºäºQwen-2.5ç³»åˆ—çš„å¼€æºå˜ä½“åœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šä¼˜äºç°æœ‰ç³»ç»Ÿï¼Œä¸”æˆæœ¬æä½ã€‚è¿™äº›å‘ç°ä¸ºä¸‹ä¸€ä»£å…¨è‡ªåŠ¨æµ·æŠ¥ç”Ÿæˆæ¨¡å‹æŒ‡æ˜äº†æ–¹å‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å­¦æœ¯æµ·æŠ¥ç”Ÿæˆä¸­çš„ä¿¡æ¯å‹ç¼©ä¸è§†è§‰è¿è´¯æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¸¸å¸¸åœ¨æ–‡æœ¬ä¸è§†è§‰å†…å®¹çš„å¯¹é½ä¸Šè¡¨ç°ä¸ä½³ï¼Œå¯¼è‡´ç”Ÿæˆçš„æµ·æŠ¥éš¾ä»¥æœ‰æ•ˆä¼ è¾¾æ ¸å¿ƒä¿¡æ¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºPosterAgentï¼Œé€šè¿‡è‡ªä¸Šè€Œä¸‹çš„å¤šä»£ç†ç®¡é“ï¼Œåˆ©ç”¨è§£æã€è§„åˆ’å’Œç»˜åˆ¶æ¨¡å—çš„ååŒå·¥ä½œï¼Œä¼˜åŒ–æµ·æŠ¥ç”Ÿæˆè¿‡ç¨‹ï¼Œç¡®ä¿ä¿¡æ¯çš„æœ‰æ•ˆä¼ è¾¾å’Œè§†è§‰çš„å¸å¼•åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šè§£æå™¨ï¼ˆParserï¼‰å°†è®ºæ–‡å†…å®¹æå–ä¸ºç»“æ„åŒ–èµ„äº§åº“ï¼›è§„åˆ’å™¨ï¼ˆPlannerï¼‰å°†æ–‡æœ¬ä¸è§†è§‰å¯¹é½ï¼Œå½¢æˆäºŒå‰æ ‘å¸ƒå±€ï¼›ç»˜åˆ¶-è¯„è®ºå¾ªç¯ï¼ˆPainter-Commenterï¼‰åˆ™é€šè¿‡æ‰§è¡Œæ¸²æŸ“ä»£ç å’Œåˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰åé¦ˆæ¥ä¼˜åŒ–æ¯ä¸ªé¢æ¿ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥äº†PaperQuizè¯„ä¼°æŒ‡æ ‡ï¼Œé‡åŒ–æµ·æŠ¥ä¼ è¾¾æ ¸å¿ƒå†…å®¹çš„èƒ½åŠ›ï¼ŒåŒæ—¶é€šè¿‡VLMä½œä¸ºè¯„åˆ¤æ ‡å‡†ï¼Œæå‡äº†è¯„ä¼°çš„å®¢è§‚æ€§å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å¤šç§æŸå¤±å‡½æ•°æ¥å¹³è¡¡è§†è§‰è´¨é‡ä¸æ–‡æœ¬è¿è´¯æ€§ï¼Œç¡®ä¿ç”Ÿæˆçš„æµ·æŠ¥åœ¨ç¾å­¦å’Œä¿¡æ¯ä¼ è¾¾ä¸Šéƒ½è¾¾åˆ°è¾ƒé«˜æ ‡å‡†ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŸºäºQwen-2.5ç³»åˆ—çš„å¼€æºå˜ä½“åœ¨è§†è§‰è´¨é‡å’Œä¿¡æ¯ä¼ è¾¾èƒ½åŠ›ä¸Šå‡ä¼˜äºç°æœ‰çš„GPT-4oé©±åŠ¨ç³»ç»Ÿï¼Œä¸”åœ¨å¤šä¸ªè¯„ä¼°æŒ‡æ ‡ä¸Šè¡¨ç°å‡º87%çš„tokenä½¿ç”¨æ•ˆç‡æå‡ï¼Œæˆæœ¬ä»…ä¸º0.005ç¾å…ƒã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å­¦æœ¯ä¼šè®®ã€ç§‘ç ”æˆæœå±•ç¤ºåŠæ•™è‚²é¢†åŸŸï¼Œèƒ½å¤Ÿæ˜¾è‘—æé«˜å­¦æœ¯æµ·æŠ¥çš„ç”Ÿæˆæ•ˆç‡ä¸è´¨é‡ã€‚æœªæ¥ï¼Œéšç€æŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ï¼Œå¯èƒ½ä¼šåœ¨æ›´å¹¿æ³›çš„ç§‘å­¦ä¼ æ’­å’Œä¿¡æ¯å¯è§†åŒ–åœºæ™¯ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Academic poster generation is a crucial yet challenging task in scientific communication, requiring the compression of long-context interleaved documents into a single, visually coherent page. To address this challenge, we introduce the first benchmark and metric suite for poster generation, which pairs recent conference papers with author-designed posters and evaluates outputs on (i)Visual Quality-semantic alignment with human posters, (ii)Textual Coherence-language fluency, (iii)Holistic Assessment-six fine-grained aesthetic and informational criteria scored by a VLM-as-judge, and notably (iv)PaperQuiz-the poster's ability to convey core paper content as measured by VLMs answering generated quizzes. Building on this benchmark, we propose PosterAgent, a top-down, visual-in-the-loop multi-agent pipeline: the (a)Parser distills the paper into a structured asset library; the (b)Planner aligns text-visual pairs into a binary-tree layout that preserves reading order and spatial balance; and the (c)Painter-Commenter loop refines each panel by executing rendering code and using VLM feedback to eliminate overflow and ensure alignment. In our comprehensive evaluation, we find that GPT-4o outputs-though visually appealing at first glance-often exhibit noisy text and poor PaperQuiz scores, and we find that reader engagement is the primary aesthetic bottleneck, as human-designed posters rely largely on visual semantics to convey meaning. Our fully open-source variants (e.g. based on the Qwen-2.5 series) outperform existing 4o-driven multi-agent systems across nearly all metrics, while using 87% fewer tokens. It transforms a 22-page paper into a finalized yet editable .pptx poster - all for just $0.005. These findings chart clear directions for the next generation of fully automated poster-generation models. The code and datasets are available at https://github.com/Paper2Poster/Paper2Poster.

