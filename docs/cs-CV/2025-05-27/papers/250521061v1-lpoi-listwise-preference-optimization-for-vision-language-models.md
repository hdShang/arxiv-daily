---
layout: default
title: LPOI: Listwise Preference Optimization for Vision Language Models
---

# LPOI: Listwise Preference Optimization for Vision Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21061" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21061v1</a>
  <a href="https://arxiv.org/pdf/2505.21061.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21061v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21061v1', 'LPOI: Listwise Preference Optimization for Vision Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Fatemeh Pesaran Zadeh, Yoojin Oh, Gunhee Kim

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27

**å¤‡æ³¨**: ACL 2025 Main. Code is released at https://github.com/fatemehpesaran310/lpoi

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/fatemehpesaran310/lpoi)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLPOIä»¥è§£å†³è§†è§‰è¯­è¨€æ¨¡å‹ä¸­çš„å¹»è§‰é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡å‹` `åå¥½ä¼˜åŒ–` `å¹»è§‰ç°è±¡` `å¯¹è±¡æ„ŸçŸ¥` `å¤šæ¨¡æ€å­¦ä¹ ` `å›¾åƒç†è§£` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¯¹é½è§†è§‰è¯­è¨€æ¨¡å‹ä¸äººç±»åå¥½çš„æ–¹æ³•å­˜åœ¨è¿‡æ‹Ÿåˆæ–‡æœ¬ä¿¡æ¯å’ŒåŠ å‰§å¹»è§‰çš„é—®é¢˜ã€‚
2. æœ¬æ–‡æå‡ºLPOIï¼Œé€šè¿‡å¯¹è±¡é®è”½å’Œæ’å€¼ç”Ÿæˆé€æ­¥å®Œæ•´çš„å›¾åƒåºåˆ—ï¼Œè®­ç»ƒæ¨¡å‹æŒ‰å¯è§æ€§æ’åºï¼Œä»è€Œå‡å°‘å¹»è§‰ã€‚
3. åœ¨MMHalBenchã€AMBERå’ŒObject HalBenchä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒLPOIåœ¨å‡å°‘å¹»è§‰å’Œæå‡æ¨¡å‹æ€§èƒ½æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¯¹é½å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰ä¸äººç±»åå¥½çš„ä»»åŠ¡å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œç°æœ‰æ–¹æ³•å¦‚RLHFå’ŒDPOå¸¸å¸¸è¿‡æ‹Ÿåˆæ–‡æœ¬ä¿¡æ¯æˆ–åŠ å‰§å¹»è§‰ç°è±¡ã€‚å°½ç®¡å¢å¼ºè´Ÿæ ·æœ¬éƒ¨åˆ†è§£å†³äº†è¿™äº›é—®é¢˜ï¼Œä½†å°šæ— ç ”ç©¶é‡‡ç”¨åˆ—è¡¨åå¥½ä¼˜åŒ–æ–¹æ³•ã€‚æœ¬æ–‡æå‡ºLPOIï¼Œè¿™æ˜¯é¦–ä¸ªé’ˆå¯¹VLMsçš„å¯¹è±¡æ„ŸçŸ¥åˆ—è¡¨åå¥½ä¼˜åŒ–æ–¹æ³•ï¼Œæ—¨åœ¨å‡å°‘å¹»è§‰ã€‚LPOIé€šè¿‡è¯†åˆ«å’Œé®è”½å›¾åƒä¸­çš„å…³é”®å¯¹è±¡ï¼Œå¹¶åœ¨æ­£è´Ÿæ ·æœ¬ä¹‹é—´æ’å€¼å½¢æˆé€æ­¥å®Œæ•´çš„å›¾åƒåºåˆ—ï¼Œè®­ç»ƒæ¨¡å‹æŒ‰å¯¹è±¡å¯è§æ€§å‡åºæ’åˆ—è¿™äº›å›¾åƒï¼Œä»è€Œæœ‰æ•ˆé™ä½å¹»è§‰å¹¶ä¿æŒè§†è§‰ä¿çœŸåº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLPOIåœ¨å‡å°‘å¹»è§‰å’Œæå‡VLMæ€§èƒ½æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨å¯¹é½äººç±»åå¥½æ—¶å‡ºç°çš„å¹»è§‰ç°è±¡ã€‚ç°æœ‰æ–¹æ³•å¦‚RLHFå’ŒDPOå¾€å¾€è¿‡äºä¾èµ–æ–‡æœ¬ä¿¡æ¯ï¼Œå¯¼è‡´æ¨¡å‹åœ¨å›¾åƒç†è§£ä¸Šå‡ºç°åå·®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šLPOIçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¯¹è±¡é®è”½å’Œæ’å€¼æŠ€æœ¯ï¼Œç”Ÿæˆä¸€ç³»åˆ—é€æ­¥å®Œæ•´çš„å›¾åƒï¼Œä»è€Œè®­ç»ƒæ¨¡å‹æŒ‰å¯¹è±¡å¯è§æ€§è¿›è¡Œæ’åºã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆå‡å°‘å¹»è§‰ï¼ŒåŒæ—¶ä¿æŒå›¾åƒçš„è§†è§‰ä¿çœŸåº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLPOIçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šå¯¹è±¡è¯†åˆ«ä¸é®è”½ã€å›¾åƒæ’å€¼ç”Ÿæˆå’Œæ’åºè®­ç»ƒã€‚é¦–å…ˆï¼Œè¯†åˆ«å›¾åƒä¸­çš„å…³é”®å¯¹è±¡å¹¶è¿›è¡Œé®è”½ï¼›ç„¶åï¼Œé€šè¿‡æ’å€¼ç”Ÿæˆä¸€ç³»åˆ—å›¾åƒï¼›æœ€åï¼Œè®­ç»ƒæ¨¡å‹å¯¹è¿™äº›å›¾åƒè¿›è¡Œæ’åºã€‚

**å…³é”®åˆ›æ–°**ï¼šLPOIçš„ä¸»è¦åˆ›æ–°åœ¨äºé¦–æ¬¡å¼•å…¥å¯¹è±¡æ„ŸçŸ¥çš„åˆ—è¡¨åå¥½ä¼˜åŒ–æ–¹æ³•ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•åœ¨æ„å»ºåˆ—è¡¨æ ·æœ¬æ—¶çš„å¤æ‚æ€§å’Œæˆæœ¬é—®é¢˜ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼ŒLPOIæ— éœ€é¢å¤–çš„æ³¨é‡Šæ•°æ®ï¼Œè‡ªåŠ¨ç”Ÿæˆæ’åºåˆ—è¡¨ã€‚

**å…³é”®è®¾è®¡**ï¼šLPOIé‡‡ç”¨æ ‡å‡†çš„æˆå¯¹åå¥½æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œè®¾è®¡äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ’åºç»“æœã€‚å…³é”®å‚æ•°åŒ…æ‹¬é®è”½åŒºåŸŸçš„é€‰æ‹©å’Œæ’å€¼ç­–ç•¥ï¼Œè¿™äº›è®¾è®¡ç¡®ä¿äº†æ¨¡å‹åœ¨å‡å°‘å¹»è§‰çš„åŒæ—¶ï¼Œä¿æŒå›¾åƒçš„è§†è§‰è´¨é‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLPOIåœ¨MMHalBenchã€AMBERå’ŒObject HalBenchä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰çš„åå¥½ä¼˜åŒ–æ–¹æ³•ï¼Œå‡å°‘å¹»è§‰ç°è±¡çš„åŒæ—¶ï¼Œæå‡äº†æ¨¡å‹æ€§èƒ½ã€‚å…·ä½“è€Œè¨€ï¼ŒLPOIåœ¨å‡å°‘å¹»è§‰æ–¹é¢çš„æå‡å¹…åº¦è¾¾åˆ°äº†XX%ï¼Œåœ¨VLMæ€§èƒ½è¯„ä¼°ä¸­è¡¨ç°å‡ºè‰²ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

LPOIçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨å›¾åƒç”Ÿæˆã€å›¾åƒç†è§£å’Œäººæœºäº¤äº’ç­‰é¢†åŸŸã€‚é€šè¿‡å‡å°‘å¹»è§‰ç°è±¡ï¼ŒLPOIå¯ä»¥æå‡è§†è§‰è¯­è¨€æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„å¯é æ€§å’Œç”¨æˆ·ä½“éªŒï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ›´æ™ºèƒ½çš„å¤šæ¨¡æ€ç³»ç»Ÿçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Aligning large VLMs with human preferences is a challenging task, as methods like RLHF and DPO often overfit to textual information or exacerbate hallucinations. Although augmenting negative image samples partially addresses these pitfalls, no prior work has employed listwise preference optimization for VLMs, due to the complexity and cost of constructing listwise image samples. In this work, we propose LPOI, the first object-aware listwise preference optimization developed for reducing hallucinations in VLMs. LPOI identifies and masks a critical object in the image, and then interpolates the masked region between the positive and negative images to form a sequence of incrementally more complete images. The model is trained to rank these images in ascending order of object visibility, effectively reducing hallucinations while retaining visual fidelity. LPOI requires no extra annotations beyond standard pairwise preference data, as it automatically constructs the ranked lists through object masking and interpolation. Comprehensive experiments on MMHalBench, AMBER, and Object HalBench confirm that LPOI outperforms existing preference optimization methods in reducing hallucinations and enhancing VLM performance. We make the code available at https://github.com/fatemehpesaran310/lpoi.

