---
layout: default
title: AVCD: Mitigating Hallucinations in Audio-Visual Large Language Models through Contrastive Decoding
---

# AVCD: Mitigating Hallucinations in Audio-Visual Large Language Models through Contrastive Decoding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20862" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.20862v2</a>
  <a href="https://arxiv.org/pdf/2505.20862.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20862v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20862v2', 'AVCD: Mitigating Hallucinations in Audio-Visual Large Language Models through Contrastive Decoding')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Chaeyoung Jung, Youngjoon Jang, Joon Son Chung

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-27 (Êõ¥Êñ∞: 2025-09-30)

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/kaistmm/AVCD)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫AVCD‰ª•Ëß£ÂÜ≥Èü≥ËßÜÈ¢ëÂ§ßËØ≠Ë®ÄÊ®°Âûã‰∏≠ÁöÑÂπªËßâÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã` `Èü≥ËßÜÈ¢ëÂ§ÑÁêÜ` `ÂØπÊØîËß£Á†Å` `ÂπªËßâÊäëÂà∂` `Ëá™ÈÄÇÂ∫îËß£Á†Å` `Ê≥®ÊÑèÂäõÊú∫Âà∂` `Ê®°ÂûãÈ≤ÅÊ£íÊÄß`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÂú®Â§ÑÁêÜÈü≥È¢ë„ÄÅËßÜÈ¢ëÂíåÊñáÊú¨Êó∂ÔºåÂ∏∏Â∏∏‰ºö‰∫ßÁîüÂπªËßâÁé∞Ë±°ÔºåÂΩ±ÂìçÊ®°ÂûãÁöÑÂèØÈù†ÊÄß„ÄÇ
2. Êú¨ÊñáÊèêÂá∫Èü≥ËßÜÈ¢ëÂØπÊØîËß£Á†ÅÔºàAVCDÔºâÔºåÈÄöËøáÂä®ÊÄÅËØÜÂà´Ê®°ÊÄÅÂπ∂Â∫îÁî®Ê≥®ÊÑèÂäõÊé©ËîΩÔºåÊù•ÊäëÂà∂Ê®°ÊÄÅÂºïËµ∑ÁöÑÂπªËßâÁé∞Ë±°„ÄÇ
3. Âú®AVHBenchÊï∞ÊçÆÈõÜ‰∏äÔºåAVCDÂú®VideoLLaMA2Âíåvideo-SALMONNÊ®°Âûã‰∏äÂàÜÂà´ÊèêÈ´ò‰∫Ü2%Âíå7%ÁöÑÂáÜÁ°ÆÁéáÔºåÂ±ïÁé∞Âá∫ËâØÂ•ΩÁöÑÈ≤ÅÊ£íÊÄßÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÂπªËßâÁé∞Ë±°‰ªçÁÑ∂ÊòØÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMsÔºâÈù¢‰∏¥ÁöÑ‰∏ªË¶ÅÊåëÊàò„ÄÇ‰∏∫Ê≠§ÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÈü≥ËßÜÈ¢ëÂØπÊØîËß£Á†ÅÔºàAVCDÔºâÊ°ÜÊû∂ÔºåÊó®Âú®Âª∫Ê®°‰∏âÊ®°ÊÄÅ‰∫§‰∫íÂπ∂ÊäëÂà∂Áî±Ê®°ÊÄÅÂºïËµ∑ÁöÑÂπªËßâ„ÄÇ‰∏é‰ª•ÂæÄÂú®ËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÔºàVLMsÔºâ‰∏≠ÈááÁî®Âõ∫ÂÆöÊ®°ÊÄÅÁöÑÂØπÊØîËß£Á†ÅÊñπÊ≥ï‰∏çÂêåÔºåAVCDÂà©Áî®Ê≥®ÊÑèÂäõÂàÜÂ∏ÉÂä®ÊÄÅËØÜÂà´ËæÉ‰∏çÂç†‰∏ªÂØºÂú∞‰ΩçÁöÑÊ®°ÊÄÅÔºåÂπ∂ÈÄöËøáÊ≥®ÊÑèÂäõÊé©ËîΩÁîüÊàêÊâ∞Âä®ËæìÂá∫logits„ÄÇÊ≠§Â§ñÔºåÊú¨ÊñáËøòÂºïÂÖ•‰∫ÜÂü∫‰∫éÁÜµÁöÑËá™ÈÄÇÂ∫îËß£Á†ÅÔºå‰ª•ÊèêÈ´òÊïàÁéá„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåAVCDÂú®Â§ö‰∏™Âü∫ÂáÜÊï∞ÊçÆÈõÜ‰∏äÂùá‰ºò‰∫éÁé∞ÊúâËß£Á†ÅÊñπÊ≥ïÔºåÂ∞§ÂÖ∂Âú®AVHBenchÊï∞ÊçÆÈõÜ‰∏äÔºåVideoLLaMA2ÁöÑÂáÜÁ°ÆÁéáÊèêÈ´ò‰∫Ü2%ÔºåËÄåvideo-SALMONNÁöÑÂáÜÁ°ÆÁéáÊèêÈ´ò‰∫Ü7%„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàAV-LLMsÔºâ‰∏≠ÁöÑÂπªËßâÁé∞Ë±°ÔºåÁé∞ÊúâÁöÑÂØπÊØîËß£Á†ÅÊñπÊ≥ïÂú®Â§ÑÁêÜÈü≥È¢ë„ÄÅËßÜÈ¢ëÂíåÊñáÊú¨ÁöÑÂ§çÊùÇ‰∫§‰∫íÊó∂ÊïàÊûú‰∏ç‰Ω≥ÔºåÂØºËá¥ÂπªËßâÈ¢ëÂèë„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöAVCDÊ°ÜÊû∂ÈÄöËøáÂä®ÊÄÅËØÜÂà´Ê®°ÊÄÅÁöÑ‰∏ªÂØºÊÄßÔºåÂà©Áî®Ê≥®ÊÑèÂäõÊú∫Âà∂ËøõË°åÊ®°ÊÄÅÊé©ËîΩÔºå‰ªéËÄåÁîüÊàêÊõ¥ÂáÜÁ°ÆÁöÑËæìÂá∫logitsÔºåÂáèÂ∞ëÂπªËßâÁöÑ‰∫ßÁîü„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöAVCDÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÊ®°ÊÄÅËØÜÂà´Ê®°Âùó„ÄÅÂØπÊØîËß£Á†ÅÊ®°ÂùóÂíåËá™ÈÄÇÂ∫îËß£Á†ÅÊ®°Âùó„ÄÇÊ®°ÊÄÅËØÜÂà´Ê®°ÂùóÈÄöËøáÊ≥®ÊÑèÂäõÂàÜÂ∏ÉËØÜÂà´‰∏ªÂØºÊ®°ÊÄÅÔºåÂØπÊØîËß£Á†ÅÊ®°ÂùóÁîüÊàêÊâ∞Âä®logitsÔºåËá™ÈÄÇÂ∫îËß£Á†ÅÊ®°ÂùóÊ†πÊçÆÊ®°Âûã‰ø°ÂøÉÈÄâÊã©Ëß£Á†ÅÊ≠•È™§„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöAVCDÁöÑÂàõÊñ∞‰πãÂ§ÑÂú®‰∫éÂÖ∂Âä®ÊÄÅÊ®°ÊÄÅËØÜÂà´ÂíåÊ≥®ÊÑèÂäõÊé©ËîΩÊú∫Âà∂Ôºå‰∏é‰º†ÁªüÁöÑÂõ∫ÂÆöÊ®°ÊÄÅÂØπÊØîËß£Á†ÅÊñπÊ≥ïÁõ∏ÊØîÔºåËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞Â∫îÂØπÂ§öÊ®°ÊÄÅ‰∫§‰∫í‰∏≠ÁöÑÂπªËßâÈóÆÈ¢ò„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°‰∏≠ÔºåAVCDÈááÁî®‰∫ÜÁÜµÂºïÂØºÁöÑËá™ÈÄÇÂ∫îËß£Á†ÅÁ≠ñÁï•ÔºåËÉΩÂ§üÊ†πÊçÆÊ®°ÂûãÂØπÈ¢ÑÊµãÁöÑ‰ø°ÂøÉÂä®ÊÄÅË∞ÉÊï¥Ëß£Á†ÅËøáÁ®ãÔºå‰ªéËÄåÊèêÈ´òËß£Á†ÅÊïàÁéáÂíåÂáÜÁ°ÆÊÄß„ÄÇÂÖ∑‰ΩìÁöÑÊçüÂ§±ÂáΩÊï∞ÂíåÁΩëÁªúÁªìÊûÑÁªÜËäÇÂú®ÂÆûÈ™åÈÉ®ÂàÜËøõË°å‰∫ÜËØ¶ÁªÜÊèèËø∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®AVHBenchÊï∞ÊçÆÈõÜ‰∏äÔºåAVCDÊòæËëóÊèêÈ´ò‰∫ÜVideoLLaMA2ÁöÑÂáÜÁ°ÆÁéá2%Âíåvideo-SALMONNÁöÑÂáÜÁ°ÆÁéá7%ÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®Â§öÊ®°ÊÄÅËß£Á†Å‰∏≠ÁöÑ‰ºòË∂äÊÄßÂíåÂº∫Â§ßÁöÑÈ≤ÅÊ£íÊÄßÔºåË∂ÖË∂ä‰∫ÜÁé∞ÊúâÁöÑËß£Á†ÅÊñπÊ≥ï„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

AVCDÊ°ÜÊû∂ÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõÔºåÂ∞§ÂÖ∂Âú®ÈúÄË¶ÅÂ§ÑÁêÜÈü≥È¢ë„ÄÅËßÜÈ¢ëÂíåÊñáÊú¨ÁöÑÂ§öÊ®°ÊÄÅ‰ªªÂä°‰∏≠ÔºåÂ¶ÇËßÜÈ¢ëÁêÜËß£„ÄÅËá™Âä®Â≠óÂπïÁîüÊàêÂíåÂ§öÊ®°ÊÄÅÊêúÁ¥¢Á≠âÈ¢ÜÂüü„ÄÇÂÖ∂ÊúâÊïàÊäëÂà∂ÂπªËßâÁé∞Ë±°ÁöÑËÉΩÂäõÔºåÂ∞ÜÊèêÂçáÁõ∏ÂÖ≥Â∫îÁî®ÁöÑÂèØÈù†ÊÄßÂíåÁî®Êà∑‰ΩìÈ™åÔºåÊé®Âä®Â§öÊ®°ÊÄÅ‰∫∫Â∑•Êô∫ËÉΩÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Hallucination remains a major challenge in multimodal large language models (MLLMs). To address this, various contrastive decoding (CD) methods have been proposed that contrasts original logits with hallucinated logits generated from perturbed inputs. While CD has shown promise in vision-language models (VLMs), it is not well-suited for AV-LLMs, where hallucinations often emerge from both unimodal and cross-modal combinations involving audio, video, and language. These intricate interactions call for a more adaptive and modality-aware decoding strategy. In this paper, we propose Audio-Visual Contrastive Decoding (AVCD)-a novel, training-free decoding framework designed to model trimodal interactions and suppress modality-induced hallucinations in AV-LLMs. Unlike previous CD methods in VLMs that corrupt a fixed modality, AVCD leverages attention distributions to dynamically identify less dominant modalities and applies attentive masking to generate perturbed output logits. To support CD in a trimodal setting, we also reformulate the original CD framework to jointly handle audio, visual, and textual inputs. Finally, to improve efficiency, we introduce entropy-guided adaptive decoding, which selectively skips unnecessary decoding steps based on the model's confidence in its predictions. Extensive experiments demonstrate that AVCD consistently outperforms existing decoding methods. Especially, on the AVHBench dataset, it improves accuracy by 2% for VideoLLaMA2 and 7% for video-SALMONN, demonstrating strong robustness and generalizability. Our code is available at https://github.com/kaistmm/AVCD.

