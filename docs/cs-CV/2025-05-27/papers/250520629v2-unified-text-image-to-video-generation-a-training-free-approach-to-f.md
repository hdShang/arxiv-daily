---
layout: default
title: Unified Text-Image-to-Video Generation: A Training-Free Approach to Flexible Visual Conditioning
---

# Unified Text-Image-to-Video Generation: A Training-Free Approach to Flexible Visual Conditioning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20629" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.20629v2</a>
  <a href="https://arxiv.org/pdf/2505.20629.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20629v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20629v2', 'Unified Text-Image-to-Video Generation: A Training-Free Approach to Flexible Visual Conditioning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Bolin Lai, Sangmin Lee, Xu Cao, Xiang Li, James M. Rehg

**åˆ†ç±»**: cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27 (æ›´æ–°: 2025-11-25)

**å¤‡æ³¨**: 18 pages, 10 figures, 8 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFlexTI2Vä»¥è§£å†³è®­ç»ƒæˆæœ¬é«˜å’Œæ¡ä»¶è®¾ç½®æœ‰é™çš„é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ–‡æœ¬-å›¾åƒ-è§†é¢‘ç”Ÿæˆ` `æ— è®­ç»ƒæ–¹æ³•` `çµæ´»è§†è§‰æ¡ä»¶` `éšæœºè¡¥ä¸äº¤æ¢` `åŠ¨æ€æ§åˆ¶æœºåˆ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆæ–¹æ³•åœ¨æ·»åŠ è§†è§‰æ¡ä»¶æ—¶é€šå¸¸éœ€è¦å¾®è°ƒï¼Œå¯¼è‡´èµ„æºæ¶ˆè€—é«˜ä¸”æ¡ä»¶è®¾ç½®å—é™ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºFlexTI2Vçš„æ— è®­ç»ƒæ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨ä»»æ„ä½ç½®å¯¹ä»»æ„æ•°é‡çš„å›¾åƒè¿›è¡Œçµæ´»çš„è§†è§‰æ¡ä»¶è®¾ç½®ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒFlexTI2Våœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰çš„æ— è®­ç»ƒå›¾åƒæ¡ä»¶æ–¹æ³•ï¼Œå…·æœ‰æ›´å¥½çš„ç”Ÿæˆæ•ˆæœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ–‡æœ¬-å›¾åƒ-è§†é¢‘ï¼ˆTI2Vï¼‰ç”Ÿæˆæ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ï¼Œæ¶‰åŠä½¿ç”¨è¯­ä¹‰å’Œè§†è§‰æ¡ä»¶è¿›è¡Œå¯æ§è§†é¢‘ç”Ÿæˆã€‚ç°æœ‰æ–¹æ³•é€šå¸¸é€šè¿‡å¾®è°ƒæ–‡æœ¬åˆ°è§†é¢‘ï¼ˆT2Vï¼‰åŸºç¡€æ¨¡å‹æ¥æ·»åŠ è§†è§‰æ¡ä»¶ï¼Œè¿™åœ¨èµ„æºä¸Šæˆæœ¬é«˜ä¸”ä»…é™äºå°‘æ•°é¢„å®šä¹‰çš„æ¡ä»¶è®¾ç½®ã€‚ä¸ºäº†è§£å†³è¿™äº›é™åˆ¶ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„TI2Vç”Ÿæˆå…¬å¼ï¼Œé‡‡ç”¨çµæ´»çš„è§†è§‰æ¡ä»¶ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ›æ–°çš„æ— è®­ç»ƒæ–¹æ³•FlexTI2Vï¼Œå¯ä»¥åœ¨ä»»æ„ä½ç½®å¯¹ä»»æ„æ•°é‡çš„å›¾åƒè¿›è¡Œæ¡ä»¶è®¾ç½®ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬é¦–å…ˆå°†æ¡ä»¶å›¾åƒåè½¬ä¸ºæ½œåœ¨ç©ºé—´ä¸­çš„å™ªå£°è¡¨ç¤ºã€‚åœ¨T2Væ¨¡å‹çš„å»å™ªè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä¸€ç§æ–°é¢–çš„éšæœºè¡¥ä¸äº¤æ¢ç­–ç•¥ï¼Œé€šè¿‡å±€éƒ¨å›¾åƒè¡¥ä¸å°†è§†è§‰ç‰¹å¾èå…¥è§†é¢‘è¡¨ç¤ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤šä¸ªæ–¹é¢è¶…è¶Šäº†ä¹‹å‰çš„æ— è®­ç»ƒå›¾åƒæ¡ä»¶æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ–‡æœ¬-å›¾åƒ-è§†é¢‘ç”Ÿæˆä¸­çš„é«˜èµ„æºæ¶ˆè€—å’Œæ¡ä»¶è®¾ç½®æœ‰é™çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºå¾®è°ƒï¼Œå¯¼è‡´çµæ´»æ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºçš„FlexTI2Væ–¹æ³•é€šè¿‡åœ¨æ½œåœ¨ç©ºé—´ä¸­åè½¬æ¡ä»¶å›¾åƒä¸ºå™ªå£°è¡¨ç¤ºï¼Œç»“åˆéšæœºè¡¥ä¸äº¤æ¢ç­–ç•¥ï¼Œå°†è§†è§‰ç‰¹å¾èå…¥è§†é¢‘ç”Ÿæˆè¿‡ç¨‹ï¼Œä»è€Œå®ç°çµæ´»çš„è§†è§‰æ¡ä»¶è®¾ç½®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼šé¦–å…ˆå°†æ¡ä»¶å›¾åƒè½¬æ¢ä¸ºæ½œåœ¨å™ªå£°è¡¨ç¤ºï¼›å…¶æ¬¡ï¼Œåœ¨å»å™ªè¿‡ç¨‹ä¸­åº”ç”¨éšæœºè¡¥ä¸äº¤æ¢ç­–ç•¥ï¼›æœ€åï¼Œé€šè¿‡åŠ¨æ€æ§åˆ¶æœºåˆ¶è°ƒæ•´æ¯å¸§çš„è§†è§‰æ¡ä»¶å¼ºåº¦ã€‚

**å…³é”®åˆ›æ–°**ï¼šFlexTI2Vçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶æ— è®­ç»ƒçš„ç‰¹æ€§å’Œçµæ´»çš„è§†è§‰æ¡ä»¶è®¾ç½®èƒ½åŠ›ï¼Œä½¿å¾—æ¨¡å‹å¯ä»¥å¤„ç†ä»»æ„æ•°é‡å’Œä½ç½®çš„å›¾åƒï¼Œè¿™ä¸ä¼ ç»Ÿæ–¹æ³•çš„å¾®è°ƒæ–¹å¼å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†åŠ¨æ€æ§åˆ¶æœºåˆ¶æ¥å¹³è¡¡åˆ›é€ æ€§ä¸ä¿çœŸåº¦ï¼Œå¹¶åœ¨å»å™ªè¿‡ç¨‹ä¸­å¼•å…¥éšæœºè¡¥ä¸äº¤æ¢ç­–ç•¥ï¼Œä»¥å¢å¼ºè§†è§‰ç‰¹å¾çš„æ•´åˆæ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒFlexTI2Våœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†ç°æœ‰çš„æ— è®­ç»ƒå›¾åƒæ¡ä»¶æ–¹æ³•ï¼Œå°¤å…¶åœ¨ç”Ÿæˆè´¨é‡å’Œçµæ´»æ€§æ–¹é¢ï¼Œæ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œæ˜¾ç¤ºå‡ºå…¶ä¼˜è¶Šæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç”µå½±åˆ¶ä½œã€æ¸¸æˆå¼€å‘å’Œè™šæ‹Ÿç°å®ç­‰ï¼Œèƒ½å¤Ÿä¸ºåˆ›ä½œè€…æä¾›æ›´é«˜æ•ˆçš„å·¥å…·æ¥ç”Ÿæˆç¬¦åˆç‰¹å®šè§†è§‰æ¡ä»¶çš„è§†é¢‘å†…å®¹ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½æ¨åŠ¨å¤šæ¨¡æ€ç”ŸæˆæŠ€æœ¯çš„å‘å±•ï¼Œæå‡è§†é¢‘ç”Ÿæˆçš„çµæ´»æ€§å’Œå¯æ§æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Text-image-to-video (TI2V) generation is a critical problem for controllable video generation using both semantic and visual conditions. Most existing methods typically add visual conditions to text-to-video (T2V) foundation models by finetuning, which is costly in resources and only limited to a few pre-defined conditioning settings. To tackle these constraints, we introduce a unified formulation for TI2V generation with flexible visual conditioning. Furthermore, we propose an innovative training-free approach, dubbed FlexTI2V, that can condition T2V foundation models on an arbitrary amount of images at arbitrary positions. Specifically, we firstly invert the condition images to noisy representation in a latent space. Then, in the denoising process of T2V models, our method uses a novel random patch swapping strategy to incorporate visual features into video representations through local image patches. To balance creativity and fidelity, we use a dynamic control mechanism to adjust the strength of visual conditioning to each video frame. Extensive experiments validate that our method surpasses previous training-free image conditioning methods by a notable margin. Our method can also generalize to both UNet-based and transformer-based architectures.

