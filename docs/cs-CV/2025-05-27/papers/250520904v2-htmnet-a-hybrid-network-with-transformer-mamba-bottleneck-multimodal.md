---
layout: default
title: "HTMNet: A Hybrid Network with Transformer-Mamba Bottleneck Multimodal Fusion for Transparent and Reflective Objects Depth Completion"
---

# HTMNet: A Hybrid Network with Transformer-Mamba Bottleneck Multimodal Fusion for Transparent and Reflective Objects Depth Completion

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20904" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.20904v2</a>
  <a href="https://arxiv.org/pdf/2505.20904.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20904v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20904v2', 'HTMNet: A Hybrid Network with Transformer-Mamba Bottleneck Multimodal Fusion for Transparent and Reflective Objects Depth Completion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Guanghu Xie, Yonglong Zhang, Zhiduo Jiang, Yang Liu, Zongwu Xie, Baoshi Cao, Hong Liu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27 (æ›´æ–°: 2025-05-28)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHTMNetä»¥è§£å†³é€æ˜å’Œåå°„ç‰©ä½“æ·±åº¦è¡¥å…¨é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ·±åº¦è¡¥å…¨` `é€æ˜ç‰©ä½“` `åå°„ç‰©ä½“` `å¤šæ¨¡æ€èåˆ` `Transformer` `CNN` `Mambaæ¶æ„` `æœºå™¨äººæ„ŸçŸ¥`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. é€æ˜å’Œåå°„ç‰©ä½“å¯¹æ·±åº¦ä¼ æ„Ÿå™¨çš„æŒ‘æˆ˜å¯¼è‡´æ·±åº¦ä¿¡æ¯ä¸å®Œæ•´ï¼Œå½±å“åç»­çš„æœºå™¨äººæ„ŸçŸ¥ä¸æ“ä½œã€‚
2. HTMNeté€šè¿‡ç»“åˆCNNã€Transformerå’ŒMambaæ¶æ„ï¼Œæå‡ºäº†ä¸€ç§æ–°é¢–çš„æ·±åº¦è¡¥å…¨è§£å†³æ–¹æ¡ˆï¼Œå¢å¼ºäº†æ¨¡å‹çš„èåˆèƒ½åŠ›ã€‚
3. åœ¨å¤šä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼ŒHTMNetåœ¨æ·±åº¦è¡¥å…¨ä»»åŠ¡ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é€æ˜å’Œåå°„ç‰©ä½“å¯¹æ·±åº¦ä¼ æ„Ÿå™¨é€ æˆæ˜¾è‘—æŒ‘æˆ˜ï¼Œå¯¼è‡´æ·±åº¦ä¿¡æ¯ä¸å®Œæ•´ï¼Œå½±å“æœºå™¨äººæ„ŸçŸ¥ä¸æ“ä½œä»»åŠ¡ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºHTMNetï¼Œä¸€ç§æ–°é¢–çš„æ··åˆæ¨¡å‹ï¼Œé›†æˆäº†Transformerã€CNNå’ŒMambaæ¶æ„ã€‚ç¼–ç å™¨åŸºäºåŒåˆ†æ”¯CNN-Transformeræ¡†æ¶ï¼Œç“¶é¢ˆèåˆæ¨¡å—é‡‡ç”¨Transformer-Mambaæ¶æ„ï¼Œè§£ç å™¨åˆ™å»ºç«‹åœ¨å¤šå°ºåº¦èåˆæ¨¡å—ä¹‹ä¸Šã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åŸºäºè‡ªæ³¨æ„åŠ›æœºåˆ¶å’ŒçŠ¶æ€ç©ºé—´æ¨¡å‹çš„æ–°å‹å¤šæ¨¡æ€èåˆæ¨¡å—ï¼Œé¦–æ¬¡åœ¨é€æ˜ç‰©ä½“æ·±åº¦è¡¥å…¨é¢†åŸŸåº”ç”¨Mambaæ¶æ„ï¼Œå±•ç°å…¶æ½œåŠ›ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾è®¡äº†åˆ›æ–°çš„å¤šå°ºåº¦èåˆæ¨¡å—ï¼Œç»“åˆé€šé“æ³¨æ„åŠ›ã€ç©ºé—´æ³¨æ„åŠ›å’Œå¤šå°ºåº¦ç‰¹å¾æå–æŠ€æœ¯ï¼Œé€šè¿‡ä¸‹èåˆç­–ç•¥æœ‰æ•ˆæ•´åˆå¤šå°ºåº¦ç‰¹å¾ã€‚å¤§é‡å…¬å…±æ•°æ®é›†çš„è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³é€æ˜å’Œåå°„ç‰©ä½“æ·±åº¦è¡¥å…¨ä¸­çš„ä¿¡æ¯ç¼ºå¤±é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†è¿™äº›ç‰©ä½“æ—¶å¸¸å¸¸æ— æ³•æä¾›å®Œæ•´çš„æ·±åº¦ä¿¡æ¯ï¼Œå¯¼è‡´æ„ŸçŸ¥å’Œæ“ä½œçš„å‡†ç¡®æ€§ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šHTMNeté€šè¿‡å¼•å…¥æ··åˆæ¨¡å‹ï¼Œç»“åˆCNNã€Transformerå’ŒMambaæ¶æ„ï¼Œåˆ©ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶å’ŒçŠ¶æ€ç©ºé—´æ¨¡å‹è¿›è¡Œå¤šæ¨¡æ€èåˆï¼Œä»è€Œæœ‰æ•ˆæå‡æ·±åº¦è¡¥å…¨çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šHTMNetçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šç¼–ç å™¨é‡‡ç”¨åŒåˆ†æ”¯CNN-Transformeræ¡†æ¶ï¼Œç“¶é¢ˆèåˆæ¨¡å—ä½¿ç”¨Transformer-Mambaæ¶æ„ï¼Œè§£ç å™¨åˆ™åŸºäºå¤šå°ºåº¦èåˆæ¨¡å—ï¼Œç»“åˆé€šé“å’Œç©ºé—´æ³¨æ„åŠ›æœºåˆ¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„ä¸»è¦åˆ›æ–°åœ¨äºé¦–æ¬¡å°†Mambaæ¶æ„åº”ç”¨äºé€æ˜ç‰©ä½“çš„æ·±åº¦è¡¥å…¨ï¼Œæå‡ºçš„å¤šæ¨¡æ€èåˆæ¨¡å—æœ‰æ•ˆæå‡äº†æ¨¡å‹å¯¹å¤æ‚åœºæ™¯çš„é€‚åº”èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡å‹è®¾è®¡ä¸­é‡‡ç”¨äº†å¤šå°ºåº¦ç‰¹å¾æå–æŠ€æœ¯ï¼Œç»“åˆé€šé“å’Œç©ºé—´æ³¨æ„åŠ›æœºåˆ¶ï¼Œä¼˜åŒ–äº†æŸå¤±å‡½æ•°ä»¥å¢å¼ºæ¨¡å‹çš„å­¦ä¹ èƒ½åŠ›ï¼Œç¡®ä¿äº†æ·±åº¦ä¿¡æ¯çš„å‡†ç¡®æ•´åˆã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å¤šä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒHTMNetåœ¨æ·±åº¦è¡¥å…¨ä»»åŠ¡ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œç›¸è¾ƒäºç°æœ‰åŸºçº¿æ¨¡å‹ï¼Œæ€§èƒ½æå‡å¹…åº¦è¶…è¿‡äº†10%ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººè§†è§‰ã€è‡ªåŠ¨é©¾é©¶ã€å¢å¼ºç°å®ç­‰ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡è¿™äº›é¢†åŸŸä¸­å¯¹é€æ˜å’Œåå°„ç‰©ä½“çš„æ·±åº¦æ„ŸçŸ¥èƒ½åŠ›ï¼Œè¿›è€Œæ”¹å–„ç›¸å…³ä»»åŠ¡çš„æ‰§è¡Œæ•ˆæœã€‚æœªæ¥ï¼ŒHTMNetæœ‰æœ›åœ¨æ›´å¹¿æ³›çš„åœºæ™¯ä¸­åº”ç”¨ï¼Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿçš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Transparent and reflective objects pose significant challenges for depth sensors, resulting in incomplete depth information that adversely affects downstream robotic perception and manipulation tasks. To address this issue, we propose HTMNet, a novel hybrid model integrating Transformer, CNN, and Mamba architectures. The encoder is based on a dual-branch CNN-Transformer framework, the bottleneck fusion module adopts a Transformer-Mamba architecture, and the decoder is built upon a multi-scale fusion module. We introduce a novel multimodal fusion module grounded in self-attention mechanisms and state space models, marking the first application of the Mamba architecture in the field of transparent object depth completion and revealing its promising potential. Additionally, we design an innovative multi-scale fusion module for the decoder that combines channel attention, spatial attention, and multi-scale feature extraction techniques to effectively integrate multi-scale features through a down-fusion strategy. Extensive evaluations on multiple public datasets demonstrate that our model achieves state-of-the-art(SOTA) performance, validating the effectiveness of our approach.

