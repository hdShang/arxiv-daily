---
layout: default
title: "Normalized Attention Guidance: Universal Negative Guidance for Diffusion Models"
---

# Normalized Attention Guidance: Universal Negative Guidance for Diffusion Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21179" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21179v3</a>
  <a href="https://arxiv.org/pdf/2505.21179.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21179v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21179v3', 'Normalized Attention Guidance: Universal Negative Guidance for Diffusion Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Dar-Yen Chen, Hmrishav Bandyopadhyay, Kai Zou, Yi-Zhe Song

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27 (æ›´æ–°: 2025-06-03)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå½’ä¸€åŒ–æ³¨æ„åŠ›å¼•å¯¼ä»¥è§£å†³æ‰©æ•£æ¨¡å‹ä¸­çš„è´Ÿå¼•å¯¼é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)**

**å…³é”®è¯**: `è´Ÿå¼•å¯¼` `æ‰©æ•£æ¨¡å‹` `æ³¨æ„åŠ›æœºåˆ¶` `æ— è®­ç»ƒæ–¹æ³•` `å›¾åƒç”Ÿæˆ` `è§†é¢‘åˆæˆ` `æ¨¡å‹æ³›åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ— åˆ†ç±»å™¨å¼•å¯¼æ–¹æ³•åœ¨æ¿€è¿›çš„é‡‡æ ·æ­¥éª¤å‹ç¼©ä¸‹è¡¨ç°ä¸ä½³ï¼Œå¯¼è‡´è´Ÿå¼•å¯¼æ•ˆæœä¸ç†æƒ³ã€‚
2. æå‡ºçš„å½’ä¸€åŒ–æ³¨æ„åŠ›å¼•å¯¼ï¼ˆNAGï¼‰é€šè¿‡åœ¨æ³¨æ„åŠ›ç©ºé—´ä¸­è¿›è¡ŒL1å½’ä¸€åŒ–å’Œå¤–æ¨ï¼Œæä¾›äº†ä¸€ç§é«˜æ•ˆçš„è´Ÿå¼•å¯¼æœºåˆ¶ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒNAGåœ¨æ–‡æœ¬å¯¹é½ã€ä¿çœŸåº¦å’Œäººç±»æ„ŸçŸ¥è´¨é‡ä¸Šå‡æœ‰æ˜¾è‘—æå‡ï¼Œç”¨æˆ·ç ”ç©¶ä¹Ÿè¡¨æ˜å¯¹NAGå¼•å¯¼è¾“å‡ºçš„åå¥½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è´Ÿå¼•å¯¼ï¼Œå³æ˜ç¡®æŠ‘åˆ¶ä¸éœ€è¦çš„å±æ€§ï¼Œä»ç„¶æ˜¯æ‰©æ•£æ¨¡å‹ä¸­çš„ä¸€ä¸ªåŸºæœ¬æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨å°‘æ­¥é‡‡æ ·çš„æƒ…å†µä¸‹ã€‚å°½ç®¡æ— åˆ†ç±»å™¨å¼•å¯¼ï¼ˆCFGï¼‰åœ¨æ ‡å‡†è®¾ç½®ä¸­è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨æ¿€è¿›çš„é‡‡æ ·æ­¥éª¤å‹ç¼©ä¸‹ï¼Œç”±äºæ­£è´Ÿåˆ†æ”¯ä¹‹é—´çš„é¢„æµ‹åå·®ï¼Œå®ƒçš„æ•ˆæœå´ä¸ç†æƒ³ã€‚æœ¬æ–‡æå‡ºäº†å½’ä¸€åŒ–æ³¨æ„åŠ›å¼•å¯¼ï¼ˆNAGï¼‰ï¼Œè¿™æ˜¯ä¸€ç§é«˜æ•ˆçš„ã€æ— è®­ç»ƒçš„æœºåˆ¶ï¼Œé€šè¿‡åœ¨æ³¨æ„åŠ›ç©ºé—´ä¸­åº”ç”¨åŸºäºL1çš„å½’ä¸€åŒ–å’Œç²¾ç‚¼æ¥å®ç°å¤–æ¨ã€‚NAGåœ¨CFGå¤±æ•ˆçš„æƒ…å†µä¸‹æ¢å¤äº†æœ‰æ•ˆçš„è´Ÿå¼•å¯¼ï¼ŒåŒæ—¶ä¿æŒäº†ä¿çœŸåº¦ã€‚ä¸ç°æœ‰æ–¹æ³•ä¸åŒï¼ŒNAGèƒ½å¤Ÿè·¨æ¶æ„ï¼ˆå¦‚UNetã€DiTï¼‰ã€é‡‡æ ·æ¨¡å¼ï¼ˆå°‘æ­¥ã€å¤šæ­¥ï¼‰å’Œæ¨¡æ€ï¼ˆå›¾åƒã€è§†é¢‘ï¼‰è¿›è¡Œæ³›åŒ–ï¼Œä½œä¸ºä¸€ç§é€šç”¨çš„æ’ä»¶ï¼Œè®¡ç®—å¼€é”€æå°ã€‚é€šè¿‡å¹¿æ³›çš„å®éªŒï¼Œæˆ‘ä»¬å±•ç¤ºäº†åœ¨æ–‡æœ¬å¯¹é½ï¼ˆCLIPè¯„åˆ†ï¼‰ã€ä¿çœŸåº¦ï¼ˆFIDã€PFIDï¼‰å’Œäººç±»æ„ŸçŸ¥è´¨é‡ï¼ˆImageRewardï¼‰æ–¹é¢çš„ä¸€è‡´æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ‰©æ•£æ¨¡å‹ä¸­çš„è´Ÿå¼•å¯¼é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨å°‘æ­¥é‡‡æ ·æƒ…å†µä¸‹ï¼Œç°æœ‰çš„æ— åˆ†ç±»å™¨å¼•å¯¼æ–¹æ³•ï¼ˆCFGï¼‰ç”±äºæ­£è´Ÿåˆ†æ”¯é¢„æµ‹çš„åå·®ï¼Œå¯¼è‡´è´Ÿå¼•å¯¼æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šå½’ä¸€åŒ–æ³¨æ„åŠ›å¼•å¯¼ï¼ˆNAGï¼‰é€šè¿‡åœ¨æ³¨æ„åŠ›ç©ºé—´ä¸­åº”ç”¨L1å½’ä¸€åŒ–å’Œå¤–æ¨ï¼Œæä¾›äº†ä¸€ç§æ— éœ€è®­ç»ƒçš„é«˜æ•ˆè´Ÿå¼•å¯¼æœºåˆ¶ï¼Œæ—¨åœ¨æ¢å¤åœ¨CFGå¤±æ•ˆæƒ…å†µä¸‹çš„æœ‰æ•ˆè´Ÿå¼•å¯¼ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šNAGçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ³¨æ„åŠ›æœºåˆ¶çš„å½’ä¸€åŒ–å¤„ç†å’Œå¤–æ¨è¿‡ç¨‹ï¼Œèƒ½å¤Ÿé€‚åº”ä¸åŒçš„æ¨¡å‹æ¶æ„ï¼ˆå¦‚UNetã€DiTï¼‰å’Œé‡‡æ ·æ¨¡å¼ï¼ˆå°‘æ­¥ã€å¤šæ­¥ï¼‰ï¼Œå¹¶æ”¯æŒå¤šç§æ¨¡æ€ï¼ˆå›¾åƒã€è§†é¢‘ï¼‰ã€‚

**å…³é”®åˆ›æ–°**ï¼šNAGçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶æ— è®­ç»ƒçš„ç‰¹æ€§å’Œè·¨æ¶æ„çš„é€‚ç”¨æ€§ï¼Œä½¿å…¶æˆä¸ºä¸€ç§é€šç”¨çš„è´Ÿå¼•å¯¼æ’ä»¶ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—å¼€é”€ã€‚

**å…³é”®è®¾è®¡**ï¼šNAGé‡‡ç”¨L1å½’ä¸€åŒ–æ¥å¤„ç†æ³¨æ„åŠ›æƒé‡ï¼Œå¹¶é€šè¿‡ç²¾ç‚¼è¿‡ç¨‹å¢å¼ºè´Ÿå¼•å¯¼æ•ˆæœï¼Œç¡®ä¿åœ¨ä¸åŒçš„æ¨¡å‹å’Œé‡‡æ ·æ¡ä»¶ä¸‹å‡èƒ½ä¿æŒé«˜æ•ˆçš„æ€§èƒ½ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡åœ¨é™„å½•ä¸­æä¾›äº†ä¼ªä»£ç ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒNAGåœ¨æ–‡æœ¬å¯¹é½ï¼ˆCLIPè¯„åˆ†ï¼‰ã€ä¿çœŸåº¦ï¼ˆFIDã€PFIDï¼‰å’Œäººç±»æ„ŸçŸ¥è´¨é‡ï¼ˆImageRewardï¼‰ä¸Šå‡æœ‰æ˜¾è‘—æå‡ï¼Œå…·ä½“æå‡å¹…åº¦åœ¨å„é¡¹æŒ‡æ ‡ä¸Šå‡è¶…è¿‡äº†ç°æœ‰åŸºçº¿ï¼Œç”¨æˆ·ç ”ç©¶æ˜¾ç¤ºå¯¹NAGå¼•å¯¼è¾“å‡ºçš„åå¥½æ˜¾è‘—ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å›¾åƒç”Ÿæˆã€è§†é¢‘åˆæˆä»¥åŠå…¶ä»–éœ€è¦æ§åˆ¶ç”Ÿæˆå†…å®¹å±æ€§çš„æ‰©æ•£æ¨¡å‹ã€‚NAGçš„æ— è®­ç»ƒç‰¹æ€§ä½¿å…¶èƒ½å¤Ÿè½»æ¾é›†æˆåˆ°ç°æœ‰çš„æ‰©æ•£æ¡†æ¶ä¸­ï¼Œæå‡ç”Ÿæˆè´¨é‡ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Negative guidance -- explicitly suppressing unwanted attributes -- remains a fundamental challenge in diffusion models, particularly in few-step sampling regimes. While Classifier-Free Guidance (CFG) works well in standard settings, it fails under aggressive sampling step compression due to divergent predictions between positive and negative branches. We present Normalized Attention Guidance (NAG), an efficient, training-free mechanism that applies extrapolation in attention space with L1-based normalization and refinement. NAG restores effective negative guidance where CFG collapses while maintaining fidelity. Unlike existing approaches, NAG generalizes across architectures (UNet, DiT), sampling regimes (few-step, multi-step), and modalities (image, video), functioning as a \textit{universal} plug-in with minimal computational overhead. Through extensive experimentation, we demonstrate consistent improvements in text alignment (CLIP Score), fidelity (FID, PFID), and human-perceived quality (ImageReward). Our ablation studies validate each design component, while user studies confirm significant preference for NAG-guided outputs. As a model-agnostic inference-time approach requiring no retraining, NAG provides effortless negative guidance for all modern diffusion frameworks -- pseudocode in the Appendix!

