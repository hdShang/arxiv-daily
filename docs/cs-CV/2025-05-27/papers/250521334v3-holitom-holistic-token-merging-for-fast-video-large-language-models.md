---
layout: default
title: "HoliTom: Holistic Token Merging for Fast Video Large Language Models"
---

# HoliTom: Holistic Token Merging for Fast Video Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21334" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.21334v3</a>
  <a href="https://arxiv.org/pdf/2505.21334.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21334v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21334v3', 'HoliTom: Holistic Token Merging for Fast Video Large Language Models')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Kele Shao, Keda Tao, Can Qin, Haoxuan You, Yang Sui, Huan Wang

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-27 (Êõ¥Êñ∞: 2025-10-10)

**Â§áÊ≥®**: code link: https://github.com/cokeshao/HoliTom

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫HoliTom‰ª•Ëß£ÂÜ≥ËßÜÈ¢ëÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑËÆ°ÁÆóÊïàÁéáÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËßÜÈ¢ëÁêÜËß£` `Â§ßËØ≠Ë®ÄÊ®°Âûã` `Ê†áËÆ∞ÂêàÂπ∂` `ËÆ°ÁÆóÊïàÁéá` `Êó∂Á©∫Â§ÑÁêÜ` `Â§öÊ®°ÊÄÅÂ≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËßÜÈ¢ëÂ§ßËØ≠Ë®ÄÊ®°ÂûãÂú®Â§ÑÁêÜÈïøËßÜÈ¢ëÊó∂Â≠òÂú®ÂÜó‰ΩôÊ†áËÆ∞ÂØºËá¥ÁöÑËÆ°ÁÆóÊïàÁéá‰Ωé‰∏ãÈóÆÈ¢ò„ÄÇ
2. HoliTomÈÄöËøáÂÖ®ÁêÉÂÜó‰ΩôÊÑüÁü•ÁöÑÊó∂Èó¥ÂàÜÂâ≤ÂíåÊó∂Á©∫ÂêàÂπ∂ÔºåÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÊó†ËÆ≠ÁªÉÁöÑÊï¥‰ΩìÊ†áËÆ∞ÂêàÂπ∂Ê°ÜÊû∂„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåHoliTomÂú®ËÆ°ÁÆóÊàêÊú¨‰∏äÈôç‰ΩéËá≥6.9% FLOPsÔºåÂêåÊó∂‰øùÊåÅ99.1%ÁöÑÊÄßËÉΩÔºåÊòæËëóÊèêÂçá‰∫ÜÊé®ÁêÜÊïàÁéá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËßÜÈ¢ëÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàËßÜÈ¢ëLLMsÔºâÂú®ËßÜÈ¢ëÁêÜËß£ÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤Ôºå‰ΩÜÁî±‰∫éÂÜó‰ΩôËßÜÈ¢ëÊ†áËÆ∞ÔºåÈù¢‰∏¥ÊòæËëóÁöÑËÆ°ÁÆóÊïàÁéáÈóÆÈ¢ò„ÄÇÁé∞ÊúâÁöÑÊ†áËÆ∞‰øÆÂâ™ÊñπÊ≥ïËôΩÁÑ∂Êèê‰æõ‰∫ÜËß£ÂÜ≥ÊñπÊ°àÔºå‰ΩÜÂú®LLMÂÜÖÈÉ®ËøõË°åÁöÑ‰øÆÂâ™ÊñπÊ≥ïÔºàÂ¶ÇFastVÔºâÂú®ÊµÖÂ±Ç‰∏≠ÂºïÂÖ•‰∫ÜÂõ∫ÊúâÁöÑËÆ°ÁÆóÂºÄÈîÄ„ÄÇÁõ∏ÂØπËÄåË®ÄÔºåÂ§ñÈÉ®LLM‰øÆÂâ™ÊñπÊ≥ï‰∏ªË¶ÅËß£ÂÜ≥ÂçïÂ∏ßÊàñÊúâÈôêÊó∂Èó¥Á™óÂè£ÂÜÖÁöÑÁ©∫Èó¥ÂÜó‰ΩôÔºåÂøΩËßÜ‰∫ÜÈïøËßÜÈ¢ëÂ∫èÂàó‰∏≠ÁöÑÂÖ®ÁêÉÊó∂Èó¥Âä®ÊÄÅÂíåÁõ∏ÂÖ≥ÊÄß„ÄÇ‰∏∫Ëøõ‰∏ÄÊ≠•ÂáèÂ∞ëÂÜó‰ΩôÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÊó†ËÆ≠ÁªÉÁöÑÊï¥‰ΩìÊ†áËÆ∞ÂêàÂπ∂Ê°ÜÊû∂HoliTomÔºåÈÄöËøáÂÖ®ÁêÉÂÜó‰ΩôÊÑüÁü•ÁöÑÊó∂Èó¥ÂàÜÂâ≤ËøõË°åÂ§ñÈÉ®LLM‰øÆÂâ™ÔºåÈöèÂêéËøõË°åÊó∂Á©∫ÂêàÂπ∂ÔºåÂáèÂ∞ëËßÜËßâÊ†áËÆ∞Ë∂ÖËøá90%ÔºåÊòæËëóÂáèËΩª‰∫ÜLLMÁöÑËÆ°ÁÆóË¥üÊãÖ„ÄÇËØÑ‰º∞ÁªìÊûúÊòæÁ§∫ÔºåËØ•ÊñπÊ≥ïÂú®LLaVA-OneVision-7B‰∏äÂÆûÁé∞‰∫Ü6.9%ÁöÑFLOPsËÆ°ÁÆóÊàêÊú¨ÔºåÂêåÊó∂‰øùÊåÅ99.1%ÁöÑÂéüÂßãÊÄßËÉΩ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥ËßÜÈ¢ëÂ§ßËØ≠Ë®ÄÊ®°ÂûãÂú®Â§ÑÁêÜÈïøËßÜÈ¢ëÊó∂Âõ†ÂÜó‰ΩôÊ†áËÆ∞ÂØºËá¥ÁöÑËÆ°ÁÆóÊïàÁéá‰Ωé‰∏ãÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®LLMÂÜÖÈÉ®‰øÆÂâ™Êó∂ÂºïÂÖ•‰∫ÜÈ¢ùÂ§ñÁöÑËÆ°ÁÆóÂºÄÈîÄÔºåËÄåÂ§ñÈÉ®‰øÆÂâ™ÊñπÊ≥ïÂàôÊú™ËÉΩÂÖÖÂàÜÂà©Áî®ËßÜÈ¢ëÁöÑÂÖ®Â±ÄÊó∂Èó¥Âä®ÊÄÅ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöHoliTomÁöÑÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÈÄöËøáÂÖ®ÁêÉÂÜó‰ΩôÊÑüÁü•ÁöÑÊó∂Èó¥ÂàÜÂâ≤ËøõË°åÂ§ñÈÉ®LLM‰øÆÂâ™ÔºåÁªìÂêàÊó∂Á©∫ÂêàÂπ∂ÊäÄÊúØÔºå‰ª•ÂáèÂ∞ëÂÜó‰ΩôÊ†áËÆ∞Ôºå‰ªéËÄåÊòæËëóÈôç‰ΩéËÆ°ÁÆóË¥üÊãÖ„ÄÇËØ•ÊñπÊ≥ï‰∏çÈúÄË¶ÅËÆ≠ÁªÉÔºå‰æø‰∫éÂø´ÈÄüÂ∫îÁî®„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöHoliTomÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏§‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÈ¶ñÂÖàÊòØÂÖ®ÁêÉÂÜó‰ΩôÊÑüÁü•ÁöÑÊó∂Èó¥ÂàÜÂâ≤ÔºåËØÜÂà´Âπ∂ÂéªÈô§ÂÜó‰ΩôÁöÑÊó∂Èó¥ÊÆµÔºõÂÖ∂Ê¨°ÊòØÊó∂Á©∫ÂêàÂπ∂ÔºåÈÄöËøáÂêàÂπ∂Áõ∏‰ººÁöÑÊ†áËÆ∞Êù•ÂáèÂ∞ëËßÜËßâÊ†áËÆ∞ÁöÑÊï∞Èáè„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöHoliTomÁöÑÂàõÊñ∞Âú®‰∫éÂ∞ÜÂ§ñÈÉ®LLM‰øÆÂâ™‰∏éÂÜÖÈÉ®LLMÊ†áËÆ∞Áõ∏‰ººÊÄßÂêàÂπ∂Áõ∏ÁªìÂêàÔºåÂÖÖÂàÜÂà©Áî®‰∫Ü‰∏§ËÄÖÁöÑ‰ºòÂäøÔºåÊòæËëóÊèêÂçá‰∫ÜÂ§ÑÁêÜÊïàÁéá„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïÂú®ÂáèÂ∞ëËÆ°ÁÆóÊàêÊú¨ÁöÑÂêåÊó∂‰øùÊåÅ‰∫ÜÈ´òÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°‰∏≠ÔºåHoliTomÈááÁî®‰∫ÜÂü∫‰∫éÁõ∏‰ººÊÄßÁöÑÊ†áËÆ∞ÂêàÂπ∂Á≠ñÁï•ÔºåÁ°Æ‰øùÂêàÂπ∂ÂêéÁöÑÊ†áËÆ∞‰ªçÁÑ∂ËÉΩÂ§üÊúâÊïà‰º†ÈÄíËßÜÈ¢ë‰ø°ÊÅØ„ÄÇÊ≠§Â§ñÔºåÂèÇÊï∞ËÆæÁΩÆÂíåÊçüÂ§±ÂáΩÊï∞ÁöÑÈÄâÊã©ÁªèËøáÁ≤æÂøÉË∞ÉÊï¥Ôºå‰ª•‰ºòÂåñÂêàÂπ∂ÊïàÊûúÂíåËÆ°ÁÆóÊïàÁéá„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåHoliTomÂú®LLaVA-OneVision-7B‰∏äÂÆûÁé∞‰∫Ü6.9%ÁöÑFLOPsËÆ°ÁÆóÊàêÊú¨ÔºåÂêåÊó∂‰øùÊåÅ99.1%ÁöÑÂéüÂßãÊÄßËÉΩ„ÄÇÊ≠§Â§ñÔºåÊó∂Èó¥Âà∞Á¨¨‰∏Ä‰∏™Ê†áËÆ∞ÔºàTTFTÔºâÂáèÂ∞ë‰∫Ü2.28ÂÄçÔºåËß£Á†ÅÂêûÂêêÈáèÂä†ÈÄü‰∫Ü1.32ÂÄçÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®Êé®ÁêÜÊïàÁéá‰∏äÁöÑÊòæËëóÊèêÂçá„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

HoliTomÁöÑÁ†îÁ©∂ÊàêÊûúÂú®ËßÜÈ¢ëÁêÜËß£„ÄÅËßÜÈ¢ëÁîüÊàêÂíåÂ§öÊ®°ÊÄÅÂ≠¶‰π†Á≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõ„ÄÇÈÄöËøáÊèêÈ´òËßÜÈ¢ëÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑËÆ°ÁÆóÊïàÁéáÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÂä†ÈÄüËßÜÈ¢ëÂàÜÊûêÂíåÂ§ÑÁêÜÔºå‰øÉËøõÂÆûÊó∂Â∫îÁî®ÁöÑÂèëÂ±ïÔºåÂ¶ÇÊô∫ËÉΩÁõëÊéß„ÄÅËá™Âä®È©æÈ©∂ÂíåÂÜÖÂÆπÊé®ËçêÁ≥ªÁªüÁ≠â„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Video large language models (video LLMs) excel at video comprehension but face significant computational inefficiency due to redundant video tokens. Existing token pruning methods offer solutions. However, approaches operating within the LLM (inner-LLM pruning), such as FastV, incur intrinsic computational overhead in shallow layers. In contrast, methods performing token pruning before the LLM (outer-LLM pruning) primarily address spatial redundancy within individual frames or limited temporal windows, neglecting the crucial global temporal dynamics and correlations across longer video sequences. This leads to sub-optimal spatio-temporal reduction and does not leverage video compressibility fully. Crucially, the synergistic potential and mutual influence of combining these strategies remain unexplored. To further reduce redundancy, we introduce HoliTom, a novel training-free holistic token merging framework. HoliTom employs outer-LLM pruning through global redundancy-aware temporal segmentation, followed by spatial-temporal merging to reduce visual tokens by over 90%, significantly alleviating the LLM's computational burden. Complementing this, we introduce a robust inner-LLM token similarity-based merging approach, designed for superior performance and compatibility with outer-LLM pruning. Evaluations demonstrate our method's promising efficiency-performance trade-off on LLaVA-OneVision-7B, reducing computational costs to 6.9% of FLOPs while maintaining 99.1% of the original performance. Furthermore, we achieve a 2.28x reduction in Time-To-First-Token (TTFT) and a 1.32x acceleration in decoding throughput, highlighting the practical benefits of our integrated pruning approach for efficient video LLMs inference.

