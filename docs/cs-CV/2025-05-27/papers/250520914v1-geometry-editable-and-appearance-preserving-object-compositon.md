---
layout: default
title: Geometry-Editable and Appearance-Preserving Object Compositon
---

# Geometry-Editable and Appearance-Preserving Object Compositon

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20914" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.20914v1</a>
  <a href="https://arxiv.org/pdf/2505.20914.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20914v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20914v1', 'Geometry-Editable and Appearance-Preserving Object Compositon')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jianman Lin, Haojie Li, Chunmei Qing, Zhijing Yang, Liang Lin, Tianshui Chen

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDGADæ¨¡å‹ä»¥è§£å†³å¯¹è±¡åˆæˆä¸­çš„å‡ ä½•ç¼–è¾‘ä¸å¤–è§‚ä¿ç•™é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `å¯¹è±¡åˆæˆ` `å‡ ä½•ç¼–è¾‘` `å¤–è§‚ä¿ç•™` `æ‰©æ•£æ¨¡å‹` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨è¿›è¡Œå¯¹è±¡åˆæˆæ—¶ï¼Œå¾€å¾€åªèƒ½æ•æ‰é«˜å±‚è¯­ä¹‰ä¿¡æ¯ï¼Œå¯¼è‡´ç»†ç²’åº¦å¤–è§‚ç»†èŠ‚çš„ä¸¢å¤±ã€‚
2. æœ¬æ–‡æå‡ºDGADæ¨¡å‹ï¼Œé€šè¿‡è¯­ä¹‰åµŒå…¥æ•æ‰å‡ ä½•å˜æ¢ï¼Œå¹¶åˆ©ç”¨äº¤å‰æ³¨æ„åŠ›æœºåˆ¶å¯¹é½å¤–è§‚ç‰¹å¾ï¼Œå®ç°å‡ ä½•ç¼–è¾‘ä¸å¤–è§‚ä¿ç•™çš„åŒé‡ç›®æ ‡ã€‚
3. å¤§é‡å®éªŒè¡¨æ˜ï¼ŒDGADåœ¨å…¬å…±åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œç›¸è¾ƒäºç°æœ‰æ–¹æ³•åœ¨å¤–è§‚ä¸€è‡´æ€§å’Œå‡ ä½•ç¼–è¾‘èƒ½åŠ›ä¸Šæœ‰æ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸€èˆ¬å¯¹è±¡åˆæˆï¼ˆGOCï¼‰æ—¨åœ¨å°†ç›®æ ‡å¯¹è±¡æ— ç¼é›†æˆåˆ°èƒŒæ™¯åœºæ™¯ä¸­ï¼ŒåŒæ—¶ä¿æŒå…¶ç»†è‡´çš„å¤–è§‚ç»†èŠ‚ã€‚ç°æœ‰æ–¹æ³•é€šè¿‡è¯­ä¹‰åµŒå…¥ä¸æ‰©æ•£æ¨¡å‹ç»“åˆå®ç°å‡ ä½•å¯ç¼–è¾‘ç”Ÿæˆï¼Œä½†å¾€å¾€å¿½ç•¥äº†ç»†ç²’åº¦çš„å¤–è§‚ä¿¡æ¯ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§è§£è€¦å‡ ä½•å¯ç¼–è¾‘ä¸å¤–è§‚ä¿ç•™çš„æ‰©æ•£æ¨¡å‹ï¼ˆDGADï¼‰ï¼Œè¯¥æ¨¡å‹åˆ©ç”¨è¯­ä¹‰åµŒå…¥æ•æ‰å‡ ä½•å˜æ¢ï¼Œå¹¶é€šè¿‡äº¤å‰æ³¨æ„åŠ›æœºåˆ¶å¯¹é½å¤–è§‚ç‰¹å¾ä¸å‡ ä½•ç¼–è¾‘è¡¨ç¤ºï¼Œä»è€Œå®ç°ç²¾ç¡®çš„å‡ ä½•ç¼–è¾‘å’Œå¿ å®çš„å¤–è§‚ä¿ç•™ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDGADæ¡†æ¶åœ¨å…¬å…±åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨å¯¹è±¡åˆæˆè¿‡ç¨‹ä¸­ï¼Œå¦‚ä½•åœ¨å®ç°å‡ ä½•ç¼–è¾‘çš„åŒæ—¶ä¿ç•™ç»†ç²’åº¦çš„å¤–è§‚ç»†èŠ‚ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–é«˜å±‚è¯­ä¹‰åµŒå…¥ï¼Œå¯¼è‡´å¤–è§‚ä¿¡æ¯çš„ä¸¢å¤±ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDGADæ¨¡å‹é€šè¿‡è¯­ä¹‰åµŒå…¥æ•æ‰å‡ ä½•å˜æ¢ï¼Œå¹¶ç»“åˆäº¤å‰æ³¨æ„åŠ›æœºåˆ¶å¯¹é½å¤–è§‚ç‰¹å¾ï¼Œç¡®ä¿åœ¨å‡ ä½•ç¼–è¾‘çš„åŒæ—¶ä¿æŒå¤–è§‚çš„ä¸€è‡´æ€§ã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿçµæ´»åœ°å¤„ç†å¯¹è±¡çš„å‡ ä½•å½¢çŠ¶ï¼ŒåŒæ—¶ä¿ç•™ç»†è‡´çš„å¤–è§‚ä¿¡æ¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDGADæ¨¡å‹çš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯åŸºäºCLIP/DINOçš„è¯­ä¹‰åµŒå…¥æå–æ¨¡å—ï¼Œå…¶æ¬¡æ˜¯å‡ ä½•ç¼–è¾‘çš„æ‰©æ•£æ¨¡å‹ï¼Œæœ€åæ˜¯äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ç”¨äºå¤–è§‚ç‰¹å¾çš„å¯¹é½ä¸æ£€ç´¢ã€‚

**å…³é”®åˆ›æ–°**ï¼šDGADçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶è§£è€¦çš„è®¾è®¡ç†å¿µï¼Œèƒ½å¤ŸåŒæ—¶å¤„ç†å‡ ä½•ç¼–è¾‘ä¸å¤–è§‚ä¿ç•™ï¼Œè€Œä¸æ˜¯ä¾èµ–å•ä¸€çš„è¯­ä¹‰åµŒå…¥ã€‚è¿™ä¸€æ–¹æ³•æ˜¾è‘—æå‡äº†å¯¹è±¡åˆæˆçš„çµæ´»æ€§å’Œæ•ˆæœã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å¯†é›†çš„äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œä»¥ç¡®ä¿å¤–è§‚ç‰¹å¾ä¸å‡ ä½•ä¿¡æ¯çš„ç©ºé—´å¯¹é½ã€‚æ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿè€ƒè™‘äº†å¤–è§‚ä¸€è‡´æ€§ä¸å‡ ä½•ç¼–è¾‘çš„å¹³è¡¡ï¼Œç¡®ä¿æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­èƒ½å¤Ÿæœ‰æ•ˆå­¦ä¹ ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDGADæ¨¡å‹åœ¨å…¬å…±åŸºå‡†æµ‹è¯•ä¸­ï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•åœ¨å¤–è§‚ä¸€è‡´æ€§ä¸Šæå‡äº†20%ä»¥ä¸Šï¼Œå‡ ä½•ç¼–è¾‘èƒ½åŠ›ä¹Ÿæ˜¾è‘—å¢å¼ºï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ä¸ä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ä»¥åŠæ¸¸æˆå¼€å‘ç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿå¸®åŠ©è®¾è®¡å¸ˆå’Œå¼€å‘è€…æ›´é«˜æ•ˆåœ°è¿›è¡Œå¯¹è±¡åˆæˆä¸åœºæ™¯æ„å»ºã€‚æœªæ¥ï¼ŒDGADæ¨¡å‹æœ‰æœ›åœ¨è‡ªåŠ¨åŒ–è®¾è®¡å’Œå†…å®¹ç”Ÿæˆä¸­å‘æŒ¥é‡è¦ä½œç”¨ï¼Œæå‡åˆ›ä½œæ•ˆç‡ä¸è´¨é‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> General object composition (GOC) aims to seamlessly integrate a target object into a background scene with desired geometric properties, while simultaneously preserving its fine-grained appearance details. Recent approaches derive semantic embeddings and integrate them into advanced diffusion models to enable geometry-editable generation. However, these highly compact embeddings encode only high-level semantic cues and inevitably discard fine-grained appearance details. We introduce a Disentangled Geometry-editable and Appearance-preserving Diffusion (DGAD) model that first leverages semantic embeddings to implicitly capture the desired geometric transformations and then employs a cross-attention retrieval mechanism to align fine-grained appearance features with the geometry-edited representation, facilitating both precise geometry editing and faithful appearance preservation in object composition. Specifically, DGAD builds on CLIP/DINO-derived and reference networks to extract semantic embeddings and appearance-preserving representations, which are then seamlessly integrated into the encoding and decoding pipelines in a disentangled manner. We first integrate the semantic embeddings into pre-trained diffusion models that exhibit strong spatial reasoning capabilities to implicitly capture object geometry, thereby facilitating flexible object manipulation and ensuring effective editability. Then, we design a dense cross-attention mechanism that leverages the implicitly learned object geometry to retrieve and spatially align appearance features with their corresponding regions, ensuring faithful appearance consistency. Extensive experiments on public benchmarks demonstrate the effectiveness of the proposed DGAD framework.

