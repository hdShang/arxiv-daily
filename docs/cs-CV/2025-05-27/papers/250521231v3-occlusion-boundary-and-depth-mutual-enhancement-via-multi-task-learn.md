---
layout: default
title: "Occlusion Boundary and Depth: Mutual Enhancement via Multi-Task Learning"
---

# Occlusion Boundary and Depth: Mutual Enhancement via Multi-Task Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21231" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.21231v3</a>
  <a href="https://arxiv.org/pdf/2505.21231.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21231v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21231v3', 'Occlusion Boundary and Depth: Mutual Enhancement via Multi-Task Learning')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Lintao Xu, Yinghao Wang, Chaohui Wang

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-27 (Êõ¥Êñ∞: 2025-11-26)

**Â§áÊ≥®**: WACV 2026

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/xul-ops/MoDOT)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫MoDOTÊ°ÜÊû∂‰ª•Ëß£ÂÜ≥ÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°‰∏éÈÅÆÊå°ËæπÁïå‰º∞ËÆ°ÁöÑ‰∫íË°•ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)** **ÊîØÊü±‰∏ÉÔºöÂä®‰ΩúÈáçÂÆöÂêë (Motion Retargeting)**

**ÂÖ≥ÈîÆËØç**: `ÈÅÆÊå°ËæπÁïå‰º∞ËÆ°` `ÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°` `Â§ö‰ªªÂä°Â≠¶‰π†` `ËÆ°ÁÆóÊú∫ËßÜËßâ` `Ê∑±Â∫¶Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®Â§ÑÁêÜÈÅÆÊå°ËæπÁïåÂíåÊ∑±Â∫¶‰º∞ËÆ°Êó∂ÔºåÂæÄÂæÄÊó†Ê≥ïÊúâÊïàÂà©Áî®‰∏§ËÄÖ‰πãÈó¥ÁöÑ‰∫íË°•‰ø°ÊÅØÔºåÂØºËá¥ÊÄßËÉΩ‰∏çË∂≥„ÄÇ
2. Êú¨ÊñáÊèêÂá∫MoDOTÊ°ÜÊû∂ÔºåÈÄöËøá‰∫§ÂèâÊ≥®ÊÑèÂäõÊú∫Âà∂ÂíåÁ∫¶ÊùüÊçüÂ§±ÂáΩÊï∞ÔºåËÅîÂêà‰ºòÂåñÊ∑±Â∫¶ÂíåÈÅÆÊå°ËæπÁïåÔºåÊèêÈ´ò‰º∞ËÆ°Á≤æÂ∫¶„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåMoDOTÂú®ÂêàÊàêÊï∞ÊçÆÈõÜÂíåNYUD-v2‰∏äÂùáË°®Áé∞‰ºòÂºÇÔºåÊ∑±Â∫¶ÂõæÁöÑËæπÁïåÊõ¥Âä†Ê∏ÖÊô∞ÔºåÂá†‰Ωï‰øùÁúüÂ∫¶ÊòæËëóÊèêÂçá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÈÅÆÊå°ËæπÁïå‰º∞ËÆ°ÔºàOBEÔºâËØÜÂà´Áî±Áâ©‰ΩìÈó¥ÈÅÆÊå°ÂíåËá™ÈÅÆÊå°ÂºïËµ∑ÁöÑËæπÁïåÔºå‰∏éÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°ÔºàMDEÔºâÂØÜÂàáÁõ∏ÂÖ≥„ÄÇÈÅÆÊå°ËæπÁïå‰∏∫Ëß£ÂÜ≥Ê∑±Â∫¶Ê®°Á≥äÊèê‰æõÂá†‰ΩïÁ∫øÁ¥¢ÔºåËÄåÊ∑±Â∫¶‰ø°ÊÅØÂèàËÉΩÊîπÂñÑÈÅÆÊå°Êé®ÁêÜ„ÄÇÊú¨ÊñáÊèêÂá∫MoDOTÊ°ÜÊû∂ÔºåÈÄöËøá‰∫§ÂèâÊ≥®ÊÑèÂäõÊù°Ê®°ÂùóÔºàCASMÔºâÂíåÈÅÆÊå°Ê∑±Â∫¶Á∫¶ÊùüÊçüÂ§±ÔºàOBDCLÔºâËÅîÂêà‰º∞ËÆ°Ê∑±Â∫¶ÂíåÈÅÆÊå°ËæπÁïå„ÄÇÊàë‰ª¨ËøòË¥°ÁåÆ‰∫ÜOB-HypersimÊï∞ÊçÆÈõÜÔºåÂåÖÂê´Á≤æÁ°ÆÁöÑÊ∑±Â∫¶ÂíåËá™ÈÅÆÊå°Â§ÑÁêÜÁöÑËæπÁïåÊ≥®Èáä„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåMoDOTÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äÊòæËëó‰ºò‰∫éÂçï‰ªªÂä°ÂíåÂ§ö‰ªªÂä°Âü∫Á∫øÔºå‰∏îÂú®ÁúüÂÆûÂú∫ÊôØ‰∏≠Ë°®Áé∞Âá∫ËâØÂ•ΩÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥ÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°‰∏éÈÅÆÊå°ËæπÁïå‰º∞ËÆ°‰πãÈó¥ÁöÑ‰∫íË°•ÊÄß‰∏çË∂≥ÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂæÄÂæÄÂøΩËßÜ‰∏§ËÄÖÁöÑÂÖ≥ËÅîÔºåÂØºËá¥Ê∑±Â∫¶Êé®ÁêÜÂíåÈÅÆÊå°ËæπÁïåËØÜÂà´ÁöÑÊÄßËÉΩ‰∏ãÈôç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÊèêÂá∫MoDOTÊ°ÜÊû∂ÔºåÈÄöËøáÂºïÂÖ•‰∫§ÂèâÊ≥®ÊÑèÂäõÊù°Ê®°ÂùóÔºàCASMÔºâÂíåÈÅÆÊå°Ê∑±Â∫¶Á∫¶ÊùüÊçüÂ§±ÔºàOBDCLÔºâÔºåÂÆûÁé∞Ê∑±Â∫¶ÂíåÈÅÆÊå°ËæπÁïåÁöÑËÅîÂêà‰º∞ËÆ°Ôºå‰ªéËÄåÂÖÖÂàÜÂà©Áî®‰∏§ËÄÖ‰πãÈó¥ÁöÑÂá†‰ΩïÂÖ≥Á≥ª„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöMoDOTÊ°ÜÊû∂ÂåÖÊã¨‰∏§‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöCASMÁî®‰∫éÊèêÂèñ‰∏≠Â±ÇÈÅÆÊå°ËæπÁïåÁâπÂæÅ‰ª•ËæÖÂä©Ê∑±Â∫¶È¢ÑÊµãÔºåOBDCLÁî®‰∫éÁ°Æ‰øùÊ∑±Â∫¶‰º∞ËÆ°‰∏éÈÅÆÊå°ËæπÁïå‰πãÈó¥ÁöÑÂá†‰Ωï‰∏ÄËá¥ÊÄß„ÄÇÊï¥‰ΩìÊµÅÁ®ã‰∏∫ÔºöËæìÂÖ•ÂõæÂÉè‚ÜíÁâπÂæÅÊèêÂèñ‚ÜíËÅîÂêà‰º∞ËÆ°‚ÜíÊçüÂ§±ËÆ°ÁÆó‚Üí‰ºòÂåñ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞Âú®‰∫éCASMÂíåOBDCLÁöÑÁªìÂêàÔºåÂâçËÄÖÈÄöËøáÊ≥®ÊÑèÂäõÊú∫Âà∂Â¢ûÂº∫‰∫ÜÁâπÂæÅÁöÑË°®ËææËÉΩÂäõÔºåÂêéËÄÖÂàôÁ°Æ‰øù‰∫ÜÊ∑±Â∫¶ÂíåÈÅÆÊå°ËæπÁïå‰πãÈó¥ÁöÑÂá†‰Ωï‰∏ÄËá¥ÊÄßÔºåËøôÂú®Áé∞ÊúâÊñπÊ≥ï‰∏≠ÊòØÊú™ÊõæÂÆûÁé∞ÁöÑ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÁΩëÁªúÁªìÊûÑ‰∏äÔºåCASMËÆæËÆ°‰∏∫Â§öÂ±ÇÊ¨°ÁöÑÊ≥®ÊÑèÂäõÊ®°ÂùóÔºå‰ª•‰æøÊõ¥Â•ΩÂú∞ÊçïÊçâÈÅÆÊå°ÁâπÂæÅÔºõOBDCLÂàôÈÄöËøáÂºïÂÖ•Âá†‰ΩïÁ∫¶ÊùüÔºåÁ°Æ‰øùÊ∑±Â∫¶‰º∞ËÆ°‰∏éÈÅÆÊå°ËæπÁïåÁöÑÁõ∏‰∫íÈ™åËØÅ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®ÂÆûÈ™å‰∏≠ÔºåMoDOTÂú®‰∏§‰∏™ÂêàÊàêÊï∞ÊçÆÈõÜÂíåNYUD-v2‰∏äÂùáÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåÁõ∏ËæÉ‰∫éÂçï‰ªªÂä°Âü∫Á∫øÔºåÊ∑±Â∫¶‰º∞ËÆ°ÁöÑÂáÜÁ°ÆÊÄßÊèêÈ´ò‰∫ÜXX%ÔºåËÄåÂú®Â§ö‰ªªÂä°Á´û‰∫âËÄÖ‰∏≠ÔºåÊÄßËÉΩÊèêÂçáÂπÖÂ∫¶ËææÂà∞YY%„ÄÇÊ≠§Â§ñÔºåÊ®°ÂûãÂú®ÁúüÂÆûÂú∫ÊôØ‰∏≠ÁöÑÊ≥õÂåñËÉΩÂäõÂº∫ÔºåÊó†ÈúÄÂæÆË∞ÉÂç≥ÂèØÁîüÊàêÊõ¥Ê∏ÖÊô∞ÁöÑÊ∑±Â∫¶Âõæ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Ëá™Âä®È©æÈ©∂„ÄÅÊú∫Âô®‰∫∫ÂØºËà™ÂíåÂ¢ûÂº∫Áé∞ÂÆûÁ≠âÂú∫ÊôØ„ÄÇÂú®Ëøô‰∫õÂ∫îÁî®‰∏≠ÔºåÂáÜÁ°ÆÁöÑÊ∑±Â∫¶‰ø°ÊÅØÂíåÈÅÆÊå°ËæπÁïåËØÜÂà´ÂØπ‰∫éÁéØÂ¢ÉÁêÜËß£ÂíåÂÜ≥Á≠ñËá≥ÂÖ≥ÈáçË¶Å„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïÊúâÊúõÊé®Âä®Êõ¥Êô∫ËÉΩÁöÑËßÜËßâÁ≥ªÁªüÁöÑÂèëÂ±ïÔºåÊèêÂçáÂÖ∂Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑË°®Áé∞„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Occlusion Boundary Estimation (OBE) identifies boundaries arising from both inter-object occlusions and self-occlusion within individual objects. This task is closely related to Monocular Depth Estimation (MDE), which infers depth from a single image, as Occlusion Boundaries (OBs) provide critical geometric cues for resolving depth ambiguities, while depth can conversely refine occlusion reasoning. In this paper, we aim to systematically model and exploit this mutually beneficial relationship. To this end, we propose MoDOT, a novel framework for joint estimation of depth and OBs, which incorporates a new Cross-Attention Strip Module (CASM) to leverage mid-level OB features for depth prediction, and a novel OB-Depth Constraint Loss (OBDCL) to enforce geometric consistency. To facilitate this study, we contribute OB-Hypersim, a large-scale photorealistic dataset with precise depth and self-occlusion-handled OB annotations. Extensive experiments on two synthetic datasets and NYUD-v2 demonstrate that MoDOT achieves significantly better performance than single-task baselines and multi-task competitors. Furthermore, models trained solely on our synthetic data demonstrate strong generalization to real-world scenes without fine-tuning, producing depth maps with sharper boundaries and improved geometric fidelity. Collectively, these results underscore the significant benefits of jointly modeling OBs and depth. Code and resources are available at https://github.com/xul-ops/MoDOT.

