---
layout: default
title: HCQA-1.5 @ Ego4D EgoSchema Challenge 2025
---

# HCQA-1.5 @ Ego4D EgoSchema Challenge 2025

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20644" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.20644v1</a>
  <a href="https://arxiv.org/pdf/2505.20644.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20644v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20644v1', 'HCQA-1.5 @ Ego4D EgoSchema Challenge 2025')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Haoyu Zhang, Yisen Feng, Qiaohui Chu, Meng Liu, Weili Guan, Yaowei Wang, Liqiang Nie

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27

**å¤‡æ³¨**: The third-place solution for the Ego4D EgoSchema Challenge at the CVPR EgoVis Workshop 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Hyu-Zhang/HCQA)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHCQAæ¡†æ¶æ‰©å±•ä»¥æå‡è‡ªæˆ‘ä¸­å¿ƒè§†é¢‘é—®ç­”çš„å¯é æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)**

**å…³é”®è¯**: `è‡ªæˆ‘ä¸­å¿ƒè§†é¢‘é—®ç­”` `å¤šæºèšåˆ` `ç½®ä¿¡åº¦è¿‡æ»¤` `ç»†ç²’åº¦æ¨ç†` `è§†è§‰åˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨è‡ªæˆ‘ä¸­å¿ƒè§†é¢‘é—®ç­”ä¸­é¢ä¸´ç­”æ¡ˆé¢„æµ‹å¯é æ€§ä¸è¶³çš„æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚åœºæ™¯ä¸‹ã€‚
2. æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§å¤šæºèšåˆç­–ç•¥å’Œç½®ä¿¡åº¦è¿‡æ»¤æœºåˆ¶ï¼Œç»“åˆç»†ç²’åº¦æ¨ç†æ¨¡å—æ¥æå‡ç­”æ¡ˆçš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚
3. åœ¨EgoSchemaç›²æµ‹é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¾¾åˆ°äº†77%çš„å‡†ç¡®ç‡ï¼Œè¶…è¶Šäº†å»å¹´çš„è·èƒœæ–¹æ¡ˆï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨æœ¬æŠ¥å‘Šä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†åœ¨2025å¹´CVPRçš„Ego4D EgoSchemaæŒ‘æˆ˜èµ›ä¸­è·å¾—ç¬¬ä¸‰åçš„æ–¹æ³•ã€‚ä¸ºäº†æé«˜è‡ªæˆ‘ä¸­å¿ƒè§†é¢‘é—®ç­”ä¸­ç­”æ¡ˆé¢„æµ‹çš„å¯é æ€§ï¼Œæˆ‘ä»¬å¯¹ä¹‹å‰æå‡ºçš„HCQAæ¡†æ¶è¿›è¡Œäº†æœ‰æ•ˆæ‰©å±•ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†ä¸€ç§å¤šæºèšåˆç­–ç•¥ï¼Œä»¥ç”Ÿæˆå¤šæ ·åŒ–çš„é¢„æµ‹ï¼Œéšåé‡‡ç”¨åŸºäºç½®ä¿¡åº¦çš„è¿‡æ»¤æœºåˆ¶ç›´æ¥é€‰æ‹©é«˜ç½®ä¿¡åº¦ç­”æ¡ˆã€‚å¯¹äºä½ç½®ä¿¡åº¦çš„æƒ…å†µï¼Œæˆ‘ä»¬ç»“åˆäº†ç»†ç²’åº¦æ¨ç†æ¨¡å—ï¼Œè¿›è¡Œé¢å¤–çš„è§†è§‰å’Œä¸Šä¸‹æ–‡åˆ†æï¼Œä»¥ç²¾ç‚¼é¢„æµ‹ã€‚åœ¨EgoSchemaç›²æµ‹é›†ä¸Šçš„è¯„ä¼°ä¸­ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨5000å¤šä¸ªäººå·¥ç­–åˆ’çš„å¤šé¡¹é€‰æ‹©é¢˜ä¸Šè¾¾åˆ°äº†77%çš„å‡†ç¡®ç‡ï¼Œè¶…è¶Šäº†å»å¹´çš„è·èƒœæ–¹æ¡ˆåŠå¤§å¤šæ•°å‚èµ›å›¢é˜Ÿã€‚æˆ‘ä»¬çš„ä»£ç å°†å‘å¸ƒåœ¨https://github.com/Hyu-Zhang/HCQAã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³è‡ªæˆ‘ä¸­å¿ƒè§†é¢‘é—®ç­”ä¸­ç­”æ¡ˆé¢„æµ‹çš„å¯é æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚åœºæ™¯æ—¶ï¼Œå¸¸å¸¸é¢ä¸´ä½ç½®ä¿¡åº¦é¢„æµ‹çš„æŒ‘æˆ˜ï¼Œå¯¼è‡´ç­”æ¡ˆçš„å‡†ç¡®æ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¤šæºèšåˆç­–ç•¥ï¼Œä»¥ç”Ÿæˆå¤šæ ·åŒ–çš„ç­”æ¡ˆé¢„æµ‹ï¼Œå¹¶é€šè¿‡ç½®ä¿¡åº¦è¿‡æ»¤æœºåˆ¶é€‰æ‹©é«˜ç½®ä¿¡åº¦ç­”æ¡ˆã€‚å¯¹äºä½ç½®ä¿¡åº¦çš„æƒ…å†µï¼Œé‡‡ç”¨ç»†ç²’åº¦æ¨ç†æ¨¡å—è¿›è¡Œè¿›ä¸€æ­¥çš„è§†è§‰å’Œä¸Šä¸‹æ–‡åˆ†æï¼Œä»¥æå‡é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¤šæºèšåˆæ¨¡å—ã€ç½®ä¿¡åº¦è¿‡æ»¤æœºåˆ¶å’Œç»†ç²’åº¦æ¨ç†æ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡å¤šæºèšåˆç”Ÿæˆå¤šæ ·åŒ–çš„ç­”æ¡ˆé¢„æµ‹ï¼Œç„¶ååº”ç”¨ç½®ä¿¡åº¦è¿‡æ»¤é€‰æ‹©é«˜ç½®ä¿¡åº¦ç­”æ¡ˆï¼Œæœ€åå¯¹ä½ç½®ä¿¡åº¦é¢„æµ‹è¿›è¡Œç»†ç²’åº¦æ¨ç†åˆ†æã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„ä¸»è¦åˆ›æ–°åœ¨äºå¼•å…¥äº†å¤šæºèšåˆç­–ç•¥å’Œç»†ç²’åº¦æ¨ç†æ¨¡å—ï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„å•ä¸€é¢„æµ‹æœºåˆ¶å½¢æˆäº†æœ¬è´¨åŒºåˆ«ï¼Œæ˜¾è‘—æå‡äº†ç­”æ¡ˆé¢„æµ‹çš„å¯é æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œæˆ‘ä»¬ä¼˜åŒ–äº†èšåˆç­–ç•¥çš„æƒé‡åˆ†é…ï¼Œå¹¶è®¾è®¡äº†é€‚åº”æ€§æŸå¤±å‡½æ•°ï¼Œä»¥å¹³è¡¡é«˜ç½®ä¿¡åº¦å’Œä½ç½®ä¿¡åº¦é¢„æµ‹çš„å½±å“ã€‚ç½‘ç»œç»“æ„æ–¹é¢ï¼Œç»†ç²’åº¦æ¨ç†æ¨¡å—ç»“åˆäº†è§†è§‰ç‰¹å¾å’Œä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¢å¼ºäº†æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨EgoSchemaç›²æµ‹é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¾¾åˆ°äº†77%çš„å‡†ç¡®ç‡ï¼Œè¶…è¶Šäº†å»å¹´çš„è·èƒœæ–¹æ¡ˆï¼Œè¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚è¿™ä¸€ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„å¤šæºèšåˆå’Œç»†ç²’åº¦æ¨ç†ç­–ç•¥åœ¨è‡ªæˆ‘ä¸­å¿ƒè§†é¢‘é—®ç­”ä»»åŠ¡ä¸­å…·æœ‰è‰¯å¥½çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½ç›‘æ§ã€è™šæ‹Ÿç°å®å’Œäººæœºäº¤äº’ç­‰åœºæ™¯ã€‚åœ¨è¿™äº›é¢†åŸŸä¸­ï¼Œèƒ½å¤Ÿå‡†ç¡®ç†è§£å’Œå›ç­”ç”¨æˆ·çš„é—®é¢˜å¯¹äºæå‡ç”¨æˆ·ä½“éªŒå’Œç³»ç»Ÿæ™ºèƒ½åŒ–æ°´å¹³å…·æœ‰é‡è¦ä»·å€¼ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›åœ¨æ›´å¹¿æ³›çš„è‡ªæˆ‘ä¸­å¿ƒè§†é¢‘åˆ†æä»»åŠ¡ä¸­å‘æŒ¥ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In this report, we present the method that achieves third place for Ego4D EgoSchema Challenge in CVPR 2025. To improve the reliability of answer prediction in egocentric video question answering, we propose an effective extension to the previously proposed HCQA framework. Our approach introduces a multi-source aggregation strategy to generate diverse predictions, followed by a confidence-based filtering mechanism that selects high-confidence answers directly. For low-confidence cases, we incorporate a fine-grained reasoning module that performs additional visual and contextual analysis to refine the predictions. Evaluated on the EgoSchema blind test set, our method achieves 77% accuracy on over 5,000 human-curated multiple-choice questions, outperforming last year's winning solution and the majority of participating teams. Our code will be added at https://github.com/Hyu-Zhang/HCQA.

