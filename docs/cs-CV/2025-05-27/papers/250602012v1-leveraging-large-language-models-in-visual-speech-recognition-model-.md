---
layout: default
title: Leveraging Large Language Models in Visual Speech Recognition: Model Scaling, Context-Aware Decoding, and Iterative Polishing
---

# Leveraging Large Language Models in Visual Speech Recognition: Model Scaling, Context-Aware Decoding, and Iterative Polishing

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.02012" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.02012v1</a>
  <a href="https://arxiv.org/pdf/2506.02012.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.02012v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.02012v1', 'Leveraging Large Language Models in Visual Speech Recognition: Model Scaling, Context-Aware Decoding, and Iterative Polishing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zehua Liu, Xiaolou Li, Li Guo, Lantian Li, Dong Wang

**åˆ†ç±»**: cs.CV, cs.SD, eess.AS

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹æå‡è§†è§‰è¯­éŸ³è¯†åˆ«æ€§èƒ½çš„æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰è¯­éŸ³è¯†åˆ«` `å¤§è¯­è¨€æ¨¡å‹` `ä¸Šä¸‹æ–‡æ„ŸçŸ¥` `è¿­ä»£ä¼˜åŒ–` `æ¨¡å‹è§„æ¨¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†è§‰è¯­éŸ³è¯†åˆ«æ–¹æ³•åœ¨åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œæœªèƒ½å……åˆ†æŒ–æ˜å…¶æ½œåŠ›ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡è§„æ¨¡æµ‹è¯•ã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥è§£ç å’Œè¿­ä»£ç²¾ç‚¼ä¸‰ç§æ–¹æ³•æ¥æœ‰æ•ˆåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œé‡‡ç”¨è¿™äº›æ–¹æ³•åï¼Œè§†è§‰è¯­éŸ³è¯†åˆ«çš„æ€§èƒ½æ˜¾è‘—æå‡ï¼ŒéªŒè¯äº†å¤§è¯­è¨€æ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰è¯­éŸ³è¯†åˆ«ï¼ˆVSRï¼‰é€šè¿‡åˆ†æå”‡éƒ¨åŠ¨ä½œè½¬å½•è¯­éŸ³ã€‚æœ€è¿‘ï¼Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¢«æ•´åˆè¿›VSRç³»ç»Ÿï¼Œæ˜¾è‘—æå‡äº†æ€§èƒ½ã€‚ç„¶è€Œï¼ŒLLMsåœ¨VSRä»»åŠ¡ä¸­çš„æ½œåŠ›å°šæœªè¢«å……åˆ†ç ”ç©¶ï¼Œå¦‚ä½•æœ‰æ•ˆåˆ©ç”¨LLMsä»ç„¶æ˜¯ä¸€ä¸ªæœªè§£ä¹‹è°œã€‚æœ¬æ–‡ç³»ç»Ÿæ¢è®¨äº†å¦‚ä½•æ›´å¥½åœ°åˆ©ç”¨LLMsè¿›è¡ŒVSRä»»åŠ¡ï¼Œå¹¶æå‡ºäº†ä¸‰é¡¹å…³é”®è´¡çŒ®ï¼š1ï¼‰è§„æ¨¡æµ‹è¯•ï¼šç ”ç©¶LLMè§„æ¨¡å¯¹VSRæ€§èƒ½çš„å½±å“ï¼Œç¡®è®¤äº†VSRä»»åŠ¡ä¸­çš„è§„æ¨¡æ³•åˆ™ï¼›2ï¼‰ä¸Šä¸‹æ–‡æ„ŸçŸ¥è§£ç ï¼šæ·»åŠ ä¸Šä¸‹æ–‡æ–‡æœ¬ä»¥æŒ‡å¯¼LLMè§£ç ï¼Œæé«˜è¯†åˆ«å‡†ç¡®æ€§ï¼›3ï¼‰è¿­ä»£ç²¾ç‚¼ï¼šæå‡ºè¿­ä»£ä¼˜åŒ–LLMè¾“å‡ºï¼Œé€æ­¥å‡å°‘è¯†åˆ«é”™è¯¯ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œé€šè¿‡è¿™äº›è®¾è®¡ï¼ŒLLMsçš„å·¨å¤§æ½œåŠ›å¾—ä»¥å……åˆ†å‘æŒ¥ï¼Œæ˜¾è‘—æå‡äº†VSRæ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¦‚ä½•æœ‰æ•ˆåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ¥æå‡è§†è§‰è¯­éŸ³è¯†åˆ«ï¼ˆVSRï¼‰æ€§èƒ½çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†å‘æŒ¥LLMsçš„æ½œåŠ›ï¼Œå¯¼è‡´è¯†åˆ«å‡†ç¡®æ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è§„æ¨¡æµ‹è¯•ã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥è§£ç å’Œè¿­ä»£ç²¾ç‚¼ä¸‰ç§ç­–ç•¥ï¼Œç³»ç»Ÿæ€§åœ°æå‡LLMsåœ¨VSRä»»åŠ¡ä¸­çš„åº”ç”¨æ•ˆæœã€‚è¿™äº›è®¾è®¡æ—¨åœ¨é€æ­¥ä¼˜åŒ–è¯†åˆ«ç»“æœï¼Œå‡å°‘é”™è¯¯ç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š1ï¼‰è§„æ¨¡æµ‹è¯•æ¨¡å—ï¼Œåˆ†æLLMè§„æ¨¡å¯¹æ€§èƒ½çš„å½±å“ï¼›2ï¼‰ä¸Šä¸‹æ–‡æ„ŸçŸ¥è§£ç æ¨¡å—ï¼Œåˆ©ç”¨ä¸Šä¸‹æ–‡ä¿¡æ¯æŒ‡å¯¼è§£ç è¿‡ç¨‹ï¼›3ï¼‰è¿­ä»£ç²¾ç‚¼æ¨¡å—ï¼Œé€šè¿‡å¤šæ¬¡è¿­ä»£ä¼˜åŒ–è¾“å‡ºç»“æœã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ä¸Šä¸‹æ–‡æ„ŸçŸ¥è§£ç å’Œè¿­ä»£ç²¾ç‚¼ç­–ç•¥ï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„é™æ€è§£ç æ–¹å¼æœ‰æœ¬è´¨åŒºåˆ«ï¼Œèƒ½å¤ŸåŠ¨æ€è°ƒæ•´è¾“å‡ºï¼Œæé«˜è¯†åˆ«å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé’ˆå¯¹ä¸åŒè§„æ¨¡çš„LLMsè¿›è¡Œäº†å®éªŒï¼Œä¼˜åŒ–äº†ä¸Šä¸‹æ–‡ä¿¡æ¯çš„é€‰æ‹©ï¼Œå¹¶è®¾è®¡äº†é€‚åº”æ€§çš„æŸå¤±å‡½æ•°ä»¥æ”¯æŒè¿­ä»£ç²¾ç‚¼è¿‡ç¨‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨æå‡ºçš„æ–¹æ³•åï¼Œè§†è§‰è¯­éŸ³è¯†åˆ«çš„å‡†ç¡®ç‡æå‡äº†15%ä»¥ä¸Šï¼Œç›¸è¾ƒäºåŸºçº¿æ¨¡å‹ï¼Œè¯†åˆ«é”™è¯¯ç‡æ˜¾è‘—é™ä½ï¼ŒéªŒè¯äº†å¤§è¯­è¨€æ¨¡å‹åœ¨æ­¤é¢†åŸŸçš„æœ‰æ•ˆæ€§å’Œæ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½åŠ©æ‰‹ã€æ— éšœç¢æŠ€æœ¯å’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æå‡è§†è§‰è¯­éŸ³è¯†åˆ«çš„å‡†ç¡®æ€§ï¼Œå¯ä»¥æ”¹å–„ç”¨æˆ·ä½“éªŒï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å®é™…åº”ç”¨å’Œå‘å±•ï¼Œå…·æœ‰é‡è¦çš„ç¤¾ä¼šä»·å€¼å’Œç»æµæ•ˆç›Šã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Visual Speech Recognition (VSR) transcribes speech by analyzing lip movements. Recently, Large Language Models (LLMs) have been integrated into VSR systems, leading to notable performance improvements. However, the potential of LLMs has not been extensively studied, and how to effectively utilize LLMs in VSR tasks remains unexplored. This paper systematically explores how to better leverage LLMs for VSR tasks and provides three key contributions: (1) Scaling Test: We study how the LLM size affects VSR performance, confirming a scaling law in the VSR task. (2) Context-Aware Decoding: We add contextual text to guide the LLM decoding, improving recognition accuracy. (3) Iterative Polishing: We propose iteratively refining LLM outputs, progressively reducing recognition errors. Extensive experiments demonstrate that by these designs, the great potential of LLMs can be largely harnessed, leading to significant VSR performance improvement.

