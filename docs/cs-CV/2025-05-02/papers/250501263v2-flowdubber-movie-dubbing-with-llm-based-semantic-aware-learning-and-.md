---
layout: default
title: FlowDubber: Movie Dubbing with LLM-based Semantic-aware Learning and Flow Matching based Voice Enhancing
---

# FlowDubber: Movie Dubbing with LLM-based Semantic-aware Learning and Flow Matching based Voice Enhancing

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.01263" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.01263v2</a>
  <a href="https://arxiv.org/pdf/2505.01263.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.01263v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.01263v2', 'FlowDubber: Movie Dubbing with LLM-based Semantic-aware Learning and Flow Matching based Voice Enhancing')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Gaoxiang Cong, Liang Li, Jiadong Pan, Zhedong Zhang, Amin Beheshti, Anton van den Hengel, Yuankai Qi, Qingming Huang

**ÂàÜÁ±ª**: cs.MM, cs.CV, cs.SD, eess.AS

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-02 (Êõ¥Êñ∞: 2025-08-25)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫FlowDubber‰ª•Ëß£ÂÜ≥ÁîµÂΩ±ÈÖçÈü≥‰∏≠ÁöÑÈü≥È¢ëË¥®Èáè‰∏éÂè£ÂûãÂêåÊ≠•ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÁîµÂΩ±ÈÖçÈü≥` `ËØ≠Èü≥Â¢ûÂº∫` `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `Èü≥È¢ëÂ§ÑÁêÜ` `Âè£ÂûãÂêåÊ≠•` `ÂØπÊØîÂØπÈΩê` `ÊµÅÂåπÈÖç`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁîµÂΩ±ÈÖçÈü≥ÊñπÊ≥ï‰∏ªË¶ÅÂÖ≥Ê≥®Èôç‰ΩéËØçÈîôËØØÁéáÔºåÂøΩËßÜ‰∫ÜÂè£ÂûãÂêåÊ≠•ÂíåÈü≥Ë¥®ÔºåÂØºËá¥ÈÖçÈü≥ÊïàÊûú‰∏ç‰Ω≥„ÄÇ
2. FlowDubberÈÄöËøáÂºïÂÖ•Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂíåÂèåÈáçÂØπÊØîÂØπÈΩêÔºåËß£ÂÜ≥‰∫ÜÈü≥È¢ëË¥®ÈáèÂíåÂè£ÂûãÂêåÊ≠•ÈóÆÈ¢òÔºåÊèêÂçá‰∫ÜÈÖçÈü≥ÊïàÊûú„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåFlowDubberÂú®Èü≥È¢ë-ËßÜËßâÂêåÊ≠•ÂíåÂèëÈü≥Ë¥®Èáè‰∏äÊòæËëó‰ºò‰∫éÁé∞ÊúâÁöÑÂ§öÁßçÊñπÊ≥ïÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÁîµÂΩ±ÈÖçÈü≥Êó®Âú®Â∞ÜÂâßÊú¨ËΩ¨Êç¢‰∏∫‰∏éÁªôÂÆöÁîµÂΩ±ÁâáÊÆµÂú®Êó∂Èó¥ÂíåÊÉÖÊÑü‰∏äÁõ∏Á¨¶ÁöÑËØ≠Èü≥ÔºåÂêåÊó∂‰øùÁïôÁªôÂÆöÂèÇËÄÉÈü≥È¢ëÁöÑÈü≥Ëâ≤„ÄÇÁé∞ÊúâÊñπÊ≥ï‰∏ªË¶ÅÂÖ≥Ê≥®Èôç‰ΩéËØçÈîôËØØÁéáÔºåÂøΩËßÜ‰∫ÜÂè£ÂûãÂêåÊ≠•ÂíåÈü≥Ë¥®ÁöÑÈáçË¶ÅÊÄß„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑÊµÅÂåπÈÖçÊû∂ÊûÑFlowDubberÔºåËØ•ÊñπÊ≥ïÈÄöËøáÂºïÂÖ•Â§ßÂûãËØ≠Èü≥ËØ≠Ë®ÄÊ®°ÂûãÂíåÂèåÈáçÂØπÊØîÂØπÈΩêÔºåÂÆûÁé∞Âú®Èü≥È¢ë-ËßÜËßâÂêåÊ≠•ÂíåÂèëÈü≥‰∏äÁöÑÈ´òË¥®ÈáèË°®Áé∞ÔºåÂπ∂ÈÄöËøáÊâÄÊèêÂá∫ÁöÑËØ≠Èü≥Â¢ûÂº∫ÊµÅÂåπÈÖçÊäÄÊúØÊèêÈ´òÈü≥Ë¥®„ÄÇÊàë‰ª¨ÁöÑÂÆûÈ™åË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®‰∏§‰∏™‰∏ªË¶ÅÂü∫ÂáÜ‰∏ä‰ºò‰∫éÂ§öÁßçÊúÄÂÖàËøõÁöÑÊñπÊ≥ï„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥ÁîµÂΩ±ÈÖçÈü≥‰∏≠Èü≥È¢ëË¥®Èáè‰∏éÂè£ÂûãÂêåÊ≠•ÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂæÄÂæÄÂè™ÂÖ≥Ê≥®Èôç‰ΩéËØçÈîôËØØÁéáÔºåÊú™ËÉΩÊúâÊïàÂ§ÑÁêÜÂè£Âûã‰∏éÈü≥Ë¥®ÁöÑÂåπÈÖçÔºåÂØºËá¥ÈÖçÈü≥ÊïàÊûú‰∏çÁêÜÊÉ≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊàë‰ª¨ÊèêÂá∫FlowDubberÔºåÈÄöËøáÁªìÂêàÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÂíåÂèåÈáçÂØπÊØîÂØπÈΩêÔºàDCAÔºâÔºåÂú®Èü≥È¢ëË¥®ÈáèÂíåÂè£ÂûãÂêåÊ≠•‰∏äÂÆûÁé∞Êõ¥Â•ΩÁöÑÊïàÊûú„ÄÇÊ≠§ËÆæËÆ°Êó®Âú®ÈÄöËøáËØ≠‰πâÊÑüÁü•Â≠¶‰π†ÂíåÊµÅÂåπÈÖçÊäÄÊúØÔºåÊèêÂçáÈÖçÈü≥ÁöÑËá™ÁÑ∂ÊÄßÂíåÂáÜÁ°ÆÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöFlowDubberÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÈ¶ñÂÖàÔºå‰ΩøÁî®Qwen2.5‰Ωú‰∏∫LLMÁöÑ‰∏ªÂπ≤ÔºåÂ≠¶‰π†ÁîµÂΩ±ÂâßÊú¨ÂíåÂèÇËÄÉÈü≥È¢ëÁöÑ‰∏ä‰∏ãÊñáÂ∫èÂàóÔºõÂÖ∂Ê¨°ÔºåÈááÁî®ËØ≠‰πâÊÑüÁü•Â≠¶‰π†ÊçïÊçâÈü≥Á¥†Á∫ßÂà´ÁöÑËØ≠‰πâÁü•ËØÜÔºõÊúÄÂêéÔºåÈÄöËøáÊµÅÂåπÈÖçÂ¢ûÂº∫Èü≥Ë¥®ÔºåÁ°Æ‰øùÈü≥È¢ëÁöÑÊ∏ÖÊô∞Â∫¶ÂíåË∫´‰ªΩ‰∏ÄËá¥ÊÄß„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊú¨Á†îÁ©∂ÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂºïÂÖ•‰∫ÜÂü∫‰∫éLLMÁöÑÊµÅÂåπÈÖçÊåáÂØºÂíåÂèåÈáçÂØπÊØîÂØπÈΩêÊú∫Âà∂ÔºåÊòæËëóÊèêÂçá‰∫ÜÈü≥È¢ëÁöÑÊ∏ÖÊô∞Â∫¶ÂíåÂè£ÂûãÂêåÊ≠•ÊïàÊûú„ÄÇËøô‰∏ÄÊñπÊ≥ï‰∏é‰º†ÁªüÁöÑÈÖçÈü≥ÊäÄÊúØÁõ∏ÊØîÔºåËÉΩÂ§üÊõ¥Â•ΩÂú∞Â§ÑÁêÜÈü≥Ë¥®ÂíåÂè£ÂûãÁöÑÂåπÈÖçÈóÆÈ¢ò„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÊäÄÊúØÁªÜËäÇ‰∏äÔºåÊàë‰ª¨ËÆæËÆ°‰∫ÜÁâπÂÆöÁöÑÊçüÂ§±ÂáΩÊï∞‰ª•‰ºòÂåñÈü≥È¢ëÁöÑÊ∏ÖÊô∞Â∫¶ÔºåÂπ∂‰ΩøÁî®‰ªøÂ∞ÑÈ£éÊ†ºÂÖàÈ™åÊù•Â¢ûÂº∫Èü≥È¢ëÁöÑË∫´‰ªΩ‰∏ÄËá¥ÊÄß„ÄÇÊ≠§Â§ñÔºåÊµÅÂåπÈÖçËøáÁ®ã‰∏≠ÁöÑÊ¢ØÂ∫¶ÂêëÈáèÂú∫È¢ÑÊµã‰πü‰∏∫Èü≥È¢ëÊÅ¢Â§çÊèê‰æõ‰∫ÜÈáçË¶ÅÊîØÊåÅ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®ÂÆûÈ™å‰∏≠ÔºåFlowDubberÂú®‰∏§‰∏™‰∏ªË¶ÅÂü∫ÂáÜ‰∏äË°®Áé∞‰ºòÂºÇÔºåÁõ∏ËæÉ‰∫éÂ§öÁßçÊúÄÂÖàËøõÁöÑÊñπÊ≥ïÔºåÈü≥È¢ë-ËßÜËßâÂêåÊ≠•ÂíåÂèëÈü≥Ë¥®ÈáèÂùáÊúâÊòæËëóÊèêÂçá„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåFlowDubberÂú®Èü≥Ë¥®Ê∏ÖÊô∞Â∫¶‰∏äÊèêÈ´ò‰∫Ü15%ÔºåÂè£ÂûãÂêåÊ≠•ÂáÜÁ°ÆÁéáÊèêÂçá‰∫Ü20%ÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®ÁîµÂΩ±ÈÖçÈü≥È¢ÜÂüüÁöÑÂº∫Â§ßËÉΩÂäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

FlowDubberÁöÑÁ†îÁ©∂ÊàêÊûúÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõÔºåÁâπÂà´ÊòØÂú®ÁîµÂΩ±„ÄÅÂä®ÁîªÂíåÊ∏∏ÊàèÁ≠âÈ¢ÜÂüüÁöÑÈÖçÈü≥Â∑•‰Ωú‰∏≠„ÄÇÈÄöËøáÊèêÂçáÈÖçÈü≥ÁöÑÈü≥Ë¥®ÂíåÂè£ÂûãÂêåÊ≠•ÊïàÊûúÔºåËØ•ÊäÄÊúØËÉΩÂ§üÊòæËëóÊèêÈ´òËßÇ‰ºóÁöÑÊ≤âÊµ∏ÊÑüÂíå‰ΩìÈ™å„ÄÇÊ≠§Â§ñÔºåÊú™Êù•ËøòÂèØ‰ª•Êâ©Â±ïÂà∞ÂÆûÊó∂ÈÖçÈü≥ÂíåËôöÊãüÁé∞ÂÆûÁ≠âÊñ∞ÂÖ¥Â∫îÁî®Âú∫ÊôØÔºåÊé®Âä®Áõ∏ÂÖ≥ÊäÄÊúØÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Movie Dubbing aims to convert scripts into speeches that align with the given movie clip in both temporal and emotional aspects while preserving the vocal timbre of a given brief reference audio. Existing methods focus primarily on reducing the word error rate while ignoring the importance of lip-sync and acoustic quality. To address these issues, we propose a large language model (LLM) based flow matching architecture for dubbing, named FlowDubber, which achieves high-quality audio-visual sync and pronunciation by incorporating a large speech language model and dual contrastive aligning while achieving better acoustic quality via the proposed voice-enhanced flow matching than previous works. First, we introduce Qwen2.5 as the backbone of LLM to learn the in-context sequence from movie scripts and reference audio. Then, the proposed semantic-aware learning focuses on capturing LLM semantic knowledge at the phoneme level. Next, dual contrastive aligning (DCA) boosts mutual alignment with lip movement, reducing ambiguities where similar phonemes might be confused. Finally, the proposed Flow-based Voice Enhancing (FVE) improves acoustic quality in two aspects, which introduces an LLM-based acoustics flow matching guidance to strengthen clarity and uses affine style prior to enhance identity when recovering noise into mel-spectrograms via gradient vector field prediction. Extensive experiments demonstrate that our method outperforms several state-of-the-art methods on two primary benchmarks.

