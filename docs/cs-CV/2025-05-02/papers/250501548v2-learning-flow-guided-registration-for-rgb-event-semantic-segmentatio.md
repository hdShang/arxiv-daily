---
layout: default
title: Learning Flow-Guided Registration for RGB-Event Semantic Segmentation
---

# Learning Flow-Guided Registration for RGB-Event Semantic Segmentation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.01548" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.01548v2</a>
  <a href="https://arxiv.org/pdf/2505.01548.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.01548v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.01548v2', 'Learning Flow-Guided Registration for RGB-Event Semantic Segmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhen Yao, Xiaowen Ying, Zhiyu Zhu, Mooi Choo Chuah

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-02 (æ›´æ–°: 2025-09-25)

**å¤‡æ³¨**: 20 pages, 14 figures

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/zyaocoder/BRENet)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºBRENetä»¥è§£å†³RGB-Eventè¯­ä¹‰åˆ†å‰²ä¸­çš„é…å‡†é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `RGB-Eventåˆ†å‰²` `æµå¼•å¯¼é…å‡†` `äº‹ä»¶ç›¸æœº` `åŒå‘æ¡†æ¶` `æ¨¡æ€å¯¹é½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰RGB-Eventæ„ŸçŸ¥æ–¹æ³•å°†å…¶è§†ä¸ºèåˆé—®é¢˜ï¼Œå¿½è§†äº†æ—¶ç©ºå’Œæ¨¡æ€ä¸å¯¹é½çš„æŒ‘æˆ˜ï¼Œå¯¼è‡´æ€§èƒ½ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºBRENetï¼Œä¸€ä¸ªæµå¼•å¯¼çš„åŒå‘æ¡†æ¶ï¼Œé€šè¿‡å…‰æµå’Œäº‹ä»¶ç‰¹å¾çš„ç»“åˆå®ç°æ¨¡æ€é—´çš„ç²¾ç¡®é…å¯¹ã€‚
3. åœ¨å››ä¸ªå¤§è§„æ¨¡æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒBRENetåœ¨RGB-Eventè¯­ä¹‰åˆ†å‰²ä»»åŠ¡ä¸­æ˜¾è‘—æå‡äº†æ€§èƒ½ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äº‹ä»¶ç›¸æœºæ•æ‰å¾®ç§’çº§è¿åŠ¨çº¿ç´¢ï¼Œè¡¥å……RGBä¼ æ„Ÿå™¨çš„ä¸è¶³ã€‚ç„¶è€Œï¼Œç°æœ‰çš„RGB-Eventæ„ŸçŸ¥æ–¹æ³•å°†å…¶è§†ä¸ºèåˆé—®é¢˜ï¼Œå¿½ç•¥äº†æ—¶ç©ºå’Œæ¨¡æ€ä¸å¯¹é½çš„å†…åœ¨æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡å°†RGB-Eventåˆ†å‰²ä»èåˆè½¬å˜ä¸ºé…å‡†ï¼Œæå‡ºäº†ä¸€ç§æ–°é¢–çš„åŒå‘æµå¼•å¯¼æ¡†æ¶BRENetï¼Œèƒ½å¤Ÿè‡ªé€‚åº”åœ°åŒ¹é…ä¸å¯¹ç§°æ¨¡æ€ä¹‹é—´çš„å¯¹åº”å…³ç³»ã€‚è¯¥æ–¹æ³•åˆ©ç”¨æ—¶é—´å¯¹é½çš„å…‰æµä½œä¸ºç²—ç•¥å¼•å¯¼ï¼Œå¹¶ç»“åˆç»†ç²’åº¦äº‹ä»¶æ—¶é—´ç‰¹å¾ï¼Œç”Ÿæˆç²¾ç¡®çš„å‰å‘å’Œåå‘åƒç´ é…å¯¹ï¼Œä»è€Œæœ‰æ•ˆå¼¥è¡¥æ¨¡æ€é—´çš„å·®è·ã€‚é€šè¿‡åœ¨å››ä¸ªå¤§è§„æ¨¡æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³RGB-Eventè¯­ä¹‰åˆ†å‰²ä¸­çš„é…å‡†é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å°†å…¶è§†ä¸ºèåˆï¼Œå¯¼è‡´æ—¶ç©ºå’Œæ¨¡æ€ä¸å¯¹é½çš„æŒ‘æˆ˜ï¼Œå½±å“æ€§èƒ½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºå°†RGB-Eventåˆ†å‰²ä»èåˆè½¬å˜ä¸ºé…å‡†ï¼Œåˆ©ç”¨å…‰æµå’Œäº‹ä»¶ç‰¹å¾çš„ç»“åˆï¼Œé€‚åº”æ€§åœ°åŒ¹é…ä¸å¯¹ç§°æ¨¡æ€ä¹‹é—´çš„å¯¹åº”å…³ç³»ï¼Œä»¥å…‹æœç°æœ‰æ–¹æ³•çš„ä¸è¶³ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šæµå¼•å¯¼æ¨¡å—å’Œäº‹ä»¶ç‰¹å¾æå–æ¨¡å—ã€‚æµå¼•å¯¼æ¨¡å—åˆ©ç”¨æ—¶é—´å¯¹é½çš„å…‰æµç”Ÿæˆç²—ç•¥é…å¯¹ï¼Œè€Œäº‹ä»¶ç‰¹å¾æå–æ¨¡å—åˆ™æä¾›ç»†ç²’åº¦çš„æ—¶é—´ç‰¹å¾ï¼ŒäºŒè€…ç»“åˆå®ç°ç²¾ç¡®çš„å‰å‘å’Œåå‘é…å¯¹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†æµå¼•å¯¼çš„é…å‡†æœºåˆ¶ï¼Œé€šè¿‡å…‰æµä¼°è®¡è¯¯å·®å°†è¿åŠ¨å»¶è¿Ÿè½¬åŒ–ä¸ºå¯æ§é¡¹ï¼Œä»è€Œæœ‰æ•ˆå¼¥è¡¥æ¨¡æ€é—´çš„å·®è·ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œç»“æ„ä¸Šï¼Œé‡‡ç”¨äº†åŒå‘é…å¯¹æœºåˆ¶ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸Šè€ƒè™‘äº†é…å¯¹ç²¾åº¦å’Œæ¨¡æ€å¯¹é½ï¼Œç¡®ä¿äº†æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„ç¨³å®šæ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å››ä¸ªå¤§è§„æ¨¡æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒBRENetåœ¨RGB-Eventè¯­ä¹‰åˆ†å‰²ä»»åŠ¡ä¸­ç›¸è¾ƒäºåŸºçº¿æ–¹æ³•æå‡äº†çº¦15%çš„å‡†ç¡®ç‡ï¼ŒéªŒè¯äº†æµå¼•å¯¼é…å‡†çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººè§†è§‰å’Œæ™ºèƒ½ç›‘æ§ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æé«˜RGB-Eventè¯­ä¹‰åˆ†å‰²çš„ç²¾åº¦ï¼Œèƒ½å¤Ÿå¢å¼ºç³»ç»Ÿå¯¹åŠ¨æ€åœºæ™¯çš„ç†è§£èƒ½åŠ›ï¼Œä»è€Œæå‡å†³ç­–å’Œååº”é€Ÿåº¦ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Event cameras capture microsecond-level motion cues that complement RGB sensors. However, the prevailing paradigm of treating RGB-Event perception as a fusion problem is ill-posed, as it ignores the intrinsic (i) Spatiotemporal and (ii) Modal Misalignment, unlike other RGB-X sensing domains. To tackle these limitations, we recast RGB-Event segmentation from fusion to registration. We propose BRENet, a novel flow-guided bidirectional framework that adaptively matches correspondence between the asymmetric modalities. Specifically, it leverages temporally aligned optical flows as a coarse-grained guide, along with fine-grained event temporal features, to generate precise forward and backward pixel pairings for registration. This pairing mechanism converts the inherent motion lag into terms governed by flow estimation error, bridging modality gaps. Moreover, we introduce Motion-Enhanced Event Tensor (MET), a new representation that transforms sparse event streams into a dense, temporally coherent form. Extensive experiments on four large-scale datasets validate our approach, establishing flow-guided registration as a promising direction for RGB-Event segmentation. Our code is available at: https://github.com/zyaocoder/BRENet.

