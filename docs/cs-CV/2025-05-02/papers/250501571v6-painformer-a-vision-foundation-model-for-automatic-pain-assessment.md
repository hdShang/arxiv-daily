---
layout: default
title: "PainFormer: a Vision Foundation Model for Automatic Pain Assessment"
---

# PainFormer: a Vision Foundation Model for Automatic Pain Assessment

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.01571" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.01571v6</a>
  <a href="https://arxiv.org/pdf/2505.01571.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.01571v6" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.01571v6', 'PainFormer: a Vision Foundation Model for Automatic Pain Assessment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Stefanos Gkikas, Raul Fernandez Rojas, Manolis Tsiknakis

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-02 (æ›´æ–°: 2025-10-09)

**æœŸåˆŠ**: IEEE Transactions on Affective Computing; 2025

**DOI**: [10.1109/TAFFC.2025.3605475](https://doi.org/10.1109/TAFFC.2025.3605475)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/GkikasStefanos/PainFormer)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPainFormerä»¥è§£å†³è‡ªåŠ¨ç–¼ç—›è¯„ä¼°é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è‡ªåŠ¨ç–¼ç—›è¯„ä¼°` `å¤šä»»åŠ¡å­¦ä¹ ` `å¤šæ¨¡æ€èåˆ` `å˜æ¢å™¨æ¨¡å‹` `ç‰¹å¾æå–` `ç”Ÿç†ä¿¡å·åˆ†æ` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç–¼ç—›è¯„ä¼°æ–¹æ³•å¾€å¾€ç¼ºä¹å‡†ç¡®æ€§å’Œå¯é æ€§ï¼Œéš¾ä»¥æ»¡è¶³ä¸´åºŠéœ€æ±‚ã€‚
2. PainFormeré€šè¿‡å¤šä»»åŠ¡å­¦ä¹ åŒæ—¶è®­ç»ƒå¤šä¸ªä»»åŠ¡ï¼Œä½œä¸ºåµŒå…¥æå–å™¨ï¼Œç»“åˆå˜æ¢å™¨æ¨¡å—è¿›è¡Œç–¼ç—›è¯„ä¼°ã€‚
3. åœ¨BioVidå’ŒAI4Painæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPainFormeråœ¨å¤šæ¨¡æ€è®¾ç½®ä¸‹å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè¶…è¶Šäº†75ç§åŸºçº¿æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç–¼ç—›æ˜¯ä¸€ç§å½±å“å¤§é‡äººç¾¤çš„å¤æ‚çŠ¶æ€ï¼Œå‡†ç¡®å¯é çš„ç–¼ç—›è¯„ä¼°å¯¹åˆ¶å®šæœ‰æ•ˆçš„ç–¼ç—›ç®¡ç†æ–¹æ¡ˆè‡³å…³é‡è¦ã€‚è‡ªåŠ¨ç–¼ç—›è¯„ä¼°ç³»ç»Ÿèƒ½å¤Ÿæä¾›æŒç»­ç›‘æµ‹å’Œæ”¯æŒå†³ç­–è¿‡ç¨‹ï¼Œæ—¨åœ¨å‡è½»ç—›è‹¦å¹¶é˜²æ­¢åŠŸèƒ½è¡°é€€ã€‚æœ¬ç ”ç©¶æå‡ºäº†PainFormerï¼Œä¸€ä¸ªåŸºäºå¤šä»»åŠ¡å­¦ä¹ åŸåˆ™çš„è§†è§‰åŸºç¡€æ¨¡å‹ï¼ŒåŒæ—¶åœ¨14ä¸ªä»»åŠ¡/æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œæ ·æœ¬æ€»æ•°è¾¾åˆ°1090ä¸‡ã€‚è¯¥æ¨¡å‹ä½œä¸ºå¤šç§è¾“å…¥æ¨¡æ€çš„åµŒå…¥æå–å™¨ï¼Œæä¾›ç‰¹å¾è¡¨ç¤ºç»™åµŒå…¥æ··åˆå™¨ï¼ˆEmbedding-Mixerï¼‰ï¼Œåè€…æ˜¯ä¸€ä¸ªåŸºäºå˜æ¢å™¨çš„æ¨¡å—ï¼Œæ‰§è¡Œæœ€ç»ˆçš„ç–¼ç—›è¯„ä¼°ã€‚é€šè¿‡RGBã€åˆæˆçƒ­æˆåƒå’Œä¼°è®¡æ·±åº¦è§†é¢‘ç­‰è¡Œä¸ºæ¨¡æ€ï¼Œä»¥åŠECGã€EMGã€GSRå’ŒfNIRSç­‰ç”Ÿç†æ¨¡æ€çš„å¹¿æ³›å®éªŒï¼ŒPainFormeræœ‰æ•ˆæå–äº†é«˜è´¨é‡çš„åµŒå…¥ç‰¹å¾ã€‚è¯¥æ¡†æ¶åœ¨BioVidå’ŒAI4Painä¸¤ä¸ªç–¼ç—›æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå¹¶ä¸æ–‡çŒ®ä¸­75ç§ä¸åŒçš„æ–¹æ³•è¿›è¡Œäº†ç›´æ¥æ¯”è¾ƒï¼Œå®éªŒç»“æœæ˜¾ç¤ºåœ¨å•æ¨¡æ€å’Œå¤šæ¨¡æ€è®¾ç½®ä¸‹å‡è¡¨ç°å‡ºæœ€å…ˆè¿›çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³è‡ªåŠ¨ç–¼ç—›è¯„ä¼°ä¸­çš„å‡†ç¡®æ€§å’Œå¯é æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤šæ¨¡æ€æ•°æ®å¤„ç†å’Œç‰¹å¾æå–æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥æœ‰æ•ˆæ”¯æŒä¸´åºŠå†³ç­–ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„PainFormeræ¨¡å‹åŸºäºå¤šä»»åŠ¡å­¦ä¹ çš„åŸåˆ™ï¼Œèƒ½å¤ŸåŒæ—¶å¤„ç†å¤šç§è¾“å…¥æ¨¡æ€ï¼Œæå–é«˜è´¨é‡çš„ç‰¹å¾è¡¨ç¤ºï¼Œä»è€Œæé«˜ç–¼ç—›è¯„ä¼°çš„å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPainFormerçš„æ•´ä½“æ¶æ„åŒ…æ‹¬åµŒå…¥æå–å™¨å’ŒåµŒå…¥æ··åˆå™¨ä¸¤ä¸ªä¸»è¦æ¨¡å—ã€‚åµŒå…¥æå–å™¨è´Ÿè´£ä»ä¸åŒæ¨¡æ€ï¼ˆå¦‚RGBã€çƒ­æˆåƒå’Œç”Ÿç†ä¿¡å·ï¼‰ä¸­æå–ç‰¹å¾ï¼Œè€ŒåµŒå…¥æ··åˆå™¨åˆ™ä½¿ç”¨å˜æ¢å™¨ç»“æ„è¿›è¡Œæœ€ç»ˆçš„ç–¼ç—›è¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶çš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå°†å¤šä»»åŠ¡å­¦ä¹ ä¸å˜æ¢å™¨æ¨¡å‹ç›¸ç»“åˆï¼Œèƒ½å¤Ÿåœ¨å¤šç§è¾“å…¥æ¨¡æ€ä¸‹å®ç°é«˜æ•ˆçš„ç‰¹å¾æå–å’Œè¯„ä¼°ï¼Œæ˜¾è‘—æå‡äº†è‡ªåŠ¨ç–¼ç—›è¯„ä¼°çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šPainFormerçš„è®¾è®¡åŒ…æ‹¬å¯¹14ä¸ªä»»åŠ¡çš„è”åˆè®­ç»ƒï¼Œä½¿ç”¨äº†1090ä¸‡æ ·æœ¬ï¼Œé‡‡ç”¨äº†é€‚åº”æ€§æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–å¤šæ¨¡æ€ç‰¹å¾çš„èåˆï¼Œç¡®ä¿äº†æ¨¡å‹åœ¨ä¸åŒè¾“å…¥æ¡ä»¶ä¸‹çš„é²æ£’æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

PainFormeråœ¨BioVidå’ŒAI4Painæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œå…¶åœ¨å¤šæ¨¡æ€è®¾ç½®ä¸‹çš„è¯„ä¼°æ€§èƒ½è¶…è¶Šäº†75ç§æ–‡çŒ®ä¸­çš„åŸºçº¿æ–¹æ³•ï¼Œå±•ç°å‡ºæœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå…·ä½“æå‡å¹…åº¦æœªçŸ¥ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

PainFormerçš„ç ”ç©¶æˆæœåœ¨åŒ»ç–—é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨ç–¼ç—›ç®¡ç†å’Œç›‘æµ‹æ–¹é¢ã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿä¸ºä¸´åºŠåŒ»ç”Ÿæä¾›å®æ—¶çš„ç–¼ç—›è¯„ä¼°æ”¯æŒï¼Œå¸®åŠ©æ”¹å–„æ‚£è€…çš„æ²»ç–—æ•ˆæœå’Œç”Ÿæ´»è´¨é‡ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›æ¨å¹¿åˆ°å…¶ä»–å¥åº·ç›‘æµ‹å’Œæƒ…æ„Ÿè¯†åˆ«é¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Pain is a manifold condition that impacts a significant percentage of the population. Accurate and reliable pain evaluation for the people suffering is crucial to developing effective and advanced pain management protocols. Automatic pain assessment systems provide continuous monitoring and support decision-making processes, ultimately aiming to alleviate distress and prevent functionality decline. This study introduces PainFormer, a vision foundation model based on multi-task learning principles trained simultaneously on 14 tasks/datasets with a total of 10.9 million samples. Functioning as an embedding extractor for various input modalities, the foundation model provides feature representations to the Embedding-Mixer, a transformer-based module that performs the final pain assessment. Extensive experiments employing behavioral modalities - including RGB, synthetic thermal, and estimated depth videos - and physiological modalities such as ECG, EMG, GSR, and fNIRS revealed that PainFormer effectively extracts high-quality embeddings from diverse input modalities. The proposed framework is evaluated on two pain datasets, BioVid and AI4Pain, and directly compared to 75 different methodologies documented in the literature. Experiments conducted in unimodal and multimodal settings demonstrate state-of-the-art performances across modalities and pave the way toward general-purpose models for automatic pain assessment. The foundation model's architecture (code) and weights are available at: https://github.com/GkikasStefanos/PainFormer.

