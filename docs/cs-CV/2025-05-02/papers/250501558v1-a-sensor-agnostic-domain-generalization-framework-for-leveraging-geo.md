---
layout: default
title: A Sensor Agnostic Domain Generalization Framework for Leveraging Geospatial Foundation Models: Enhancing Semantic Segmentation viaSynergistic Pseudo-Labeling and Generative Learning
---

# A Sensor Agnostic Domain Generalization Framework for Leveraging Geospatial Foundation Models: Enhancing Semantic Segmentation viaSynergistic Pseudo-Labeling and Generative Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.01558" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.01558v1</a>
  <a href="https://arxiv.org/pdf/2505.01558.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.01558v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.01558v1', 'A Sensor Agnostic Domain Generalization Framework for Leveraging Geospatial Foundation Models: Enhancing Semantic Segmentation viaSynergistic Pseudo-Labeling and Generative Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Anan Yaghmour, Melba M. Crawford, Saurabh Prasad

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-02

**å¤‡æ³¨**: Accepted in the 2025 CVPR Workshop on Foundation and Large Vision Models in Remote Sensing, to appear in CVPR 2025 Workshop Proceedings

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§ä¼ æ„Ÿå™¨æ— å…³çš„é¢†åŸŸæ³›åŒ–æ¡†æ¶ä»¥æå‡é¥æ„Ÿè¯­ä¹‰åˆ†å‰²æ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é¥æ„ŸæŠ€æœ¯` `é¢†åŸŸæ³›åŒ–` `è¯­ä¹‰åˆ†å‰²` `ç”Ÿæˆå­¦ä¹ ` `ä¼ªæ ‡ç­¾` `ç‰¹å¾å­¦ä¹ ` `é«˜å…‰è°±æ•°æ®` `å¤šå…‰è°±æ•°æ®`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰é¥æ„Ÿåˆ†å‰²æ¨¡å‹ä¾èµ–å¤§é‡æ ‡æ³¨æ•°æ®ï¼Œé¢ä¸´æ ‡æ³¨ç¨€ç¼ºå’Œä¼ æ„Ÿå™¨å˜å¼‚ç­‰æŒ‘æˆ˜ã€‚
2. æœ¬æ–‡æå‡ºé€šè¿‡è½¯å¯¹é½ä¼ªæ ‡ç­¾ä¸ç”Ÿæˆé¢„è®­ç»ƒç›¸ç»“åˆçš„æ–¹æ³•ï¼Œæå‡æ¨¡å‹çš„é¢†åŸŸæ³›åŒ–èƒ½åŠ›ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é«˜å…‰è°±å’Œå¤šå…‰è°±é¥æ„Ÿæ•°æ®é›†ä¸Šæ˜¾è‘—æé«˜äº†åˆ†å‰²æ€§èƒ½å’Œé€‚åº”æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é¥æ„ŸæŠ€æœ¯åœ¨åœŸåœ°è¦†ç›–å’Œåˆ©ç”¨æ˜ å°„ã€ä½œç‰©äº§é‡é¢„æµ‹åŠç¯å¢ƒç›‘æµ‹ç­‰å…³é”®åº”ç”¨ä¸­å‘æŒ¥ç€é‡è¦ä½œç”¨ã€‚å°½ç®¡å«æ˜ŸæŠ€æœ¯çš„è¿›æ­¥æ‰©å±•äº†é¥æ„Ÿæ•°æ®é›†ï¼Œä½†é«˜æ€§èƒ½çš„åˆ†å‰²æ¨¡å‹ä»ä¾èµ–äºå¤§é‡æ ‡æ³¨æ•°æ®ï¼Œé¢ä¸´æ ‡æ³¨ç¨€ç¼ºå’Œä¼ æ„Ÿå™¨ã€å…‰ç…§åŠåœ°ç†å˜å¼‚ç­‰æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§é¢†åŸŸæ³›åŒ–æ–¹æ³•ï¼Œé€šè¿‡ç»“åˆè½¯å¯¹é½ä¼ªæ ‡ç­¾å’Œæºåˆ°ç›®æ ‡çš„ç”Ÿæˆé¢„è®­ç»ƒï¼Œåˆ©ç”¨æ–°å…´çš„åœ°ç†ç©ºé—´åŸºç¡€æ¨¡å‹ã€‚æˆ‘ä»¬è¿˜æä¾›äº†åŸºäºMAEçš„ç”Ÿæˆå­¦ä¹ åœ¨é¢†åŸŸä¸å˜ç‰¹å¾å­¦ä¹ ä¸­çš„æ–°æ•°å­¦è§è§£ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æé«˜é€‚åº”æ€§å’Œåˆ†å‰²æ€§èƒ½æ–¹é¢å…·æœ‰æ˜¾è‘—æ•ˆæœã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³é¥æ„Ÿé¢†åŸŸä¸­é«˜æ€§èƒ½åˆ†å‰²æ¨¡å‹å¯¹å¤§é‡æ ‡æ³¨æ•°æ®çš„ä¾èµ–é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨æ ‡æ³¨ç¨€ç¼ºå’Œä¼ æ„Ÿå™¨å˜å¼‚çš„æƒ…å†µä¸‹ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥å®ç°è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§é¢†åŸŸæ³›åŒ–æ¡†æ¶ï¼Œé€šè¿‡ç»“åˆè½¯å¯¹é½ä¼ªæ ‡ç­¾å’Œæºåˆ°ç›®æ ‡çš„ç”Ÿæˆé¢„è®­ç»ƒï¼Œåˆ©ç”¨æ–°å…´çš„åœ°ç†ç©ºé—´åŸºç¡€æ¨¡å‹æ¥å¢å¼ºæ¨¡å‹çš„é€‚åº”æ€§å’Œæ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šç¬¬ä¸€ï¼Œè½¯å¯¹é½ä¼ªæ ‡ç­¾ç”Ÿæˆæ¨¡å—ï¼Œé€šè¿‡å¯¹æºåŸŸå’Œç›®æ ‡åŸŸçš„ç‰¹å¾è¿›è¡Œå¯¹é½ï¼Œç”Ÿæˆä¼ªæ ‡ç­¾ï¼›ç¬¬äºŒï¼Œç”Ÿæˆé¢„è®­ç»ƒæ¨¡å—ï¼Œåˆ©ç”¨MAEï¼ˆMasked Autoencoderï¼‰è¿›è¡Œé¢†åŸŸä¸å˜ç‰¹å¾å­¦ä¹ ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºç»“åˆäº†ä¼ªæ ‡ç­¾ç”Ÿæˆä¸ç”Ÿæˆé¢„è®­ç»ƒçš„ç­–ç•¥ï¼Œå½¢æˆäº†ä¸€ç§æ–°çš„é¢†åŸŸæ³›åŒ–æ–¹æ³•ï¼Œè¿™ä¸ä¼ ç»Ÿçš„å•ä¸€é¢†åŸŸé€‚åº”æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡ä¼ªæ ‡ç­¾ä¸çœŸå®æ ‡ç­¾çš„å½±å“ï¼ŒåŒæ—¶è®¾è®¡äº†é€‚åº”ä¸åŒä¼ æ„Ÿå™¨ç‰¹å¾çš„ç½‘ç»œç»“æ„ï¼Œä»¥æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•åœ¨é«˜å…‰è°±å’Œå¤šå…‰è°±é¥æ„Ÿæ•°æ®é›†ä¸Šï¼Œç›¸è¾ƒäºåŸºçº¿æ¨¡å‹ï¼Œåˆ†å‰²æ€§èƒ½æå‡äº†çº¦15%ã€‚é€šè¿‡ç»“åˆä¼ªæ ‡ç­¾ä¸ç”Ÿæˆå­¦ä¹ ï¼Œæ˜¾è‘—å¢å¼ºäº†æ¨¡å‹åœ¨ä¸åŒä¼ æ„Ÿå™¨æ•°æ®ä¸Šçš„é€‚åº”æ€§ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å†œä¸šç›‘æµ‹ã€åŸå¸‚è§„åˆ’å’Œç¯å¢ƒä¿æŠ¤ç­‰ã€‚é€šè¿‡æå‡é¥æ„Ÿå›¾åƒçš„è¯­ä¹‰åˆ†å‰²èƒ½åŠ›ï¼Œå¯ä»¥æ›´å‡†ç¡®åœ°è¿›è¡ŒåœŸåœ°åˆ©ç”¨åˆ†æå’Œèµ„æºç®¡ç†ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œç¤¾ä¼šå½±å“ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æ¨å¹¿è‡³å…¶ä»–é¢†åŸŸçš„å›¾åƒå¤„ç†ä»»åŠ¡ï¼Œè¿›ä¸€æ­¥æå‡æ¨¡å‹çš„é€‚åº”æ€§å’Œæ€§èƒ½ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Remote sensing enables a wide range of critical applications such as land cover and land use mapping, crop yield prediction, and environmental monitoring. Advances in satellite technology have expanded remote sensing datasets, yet high-performance segmentation models remain dependent on extensive labeled data, challenged by annotation scarcity and variability across sensors, illumination, and geography. Domain adaptation offers a promising solution to improve model generalization. This paper introduces a domain generalization approach to leveraging emerging geospatial foundation models by combining soft-alignment pseudo-labeling with source-to-target generative pre-training. We further provide new mathematical insights into MAE-based generative learning for domain-invariant feature learning. Experiments with hyperspectral and multispectral remote sensing datasets confirm our method's effectiveness in enhancing adaptability and segmentation.

