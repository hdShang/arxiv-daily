---
layout: default
title: SD-OVON: A Semantics-aware Dataset and Benchmark Generation Pipeline for Open-Vocabulary Object Navigation in Dynamic Scenes
---

# SD-OVON: A Semantics-aware Dataset and Benchmark Generation Pipeline for Open-Vocabulary Object Navigation in Dynamic Scenes

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.18881" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.18881v1</a>
  <a href="https://arxiv.org/pdf/2505.18881.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.18881v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.18881v1', 'SD-OVON: A Semantics-aware Dataset and Benchmark Generation Pipeline for Open-Vocabulary Object Navigation in Dynamic Scenes')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Dicong Qiu, Jiadi You, Zeying Gong, Ronghe Qiu, Hui Xiong, Junwei Liang

**åˆ†ç±»**: cs.CV, cs.AI, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-05-24

**å¤‡æ³¨**: Preprint. 21 pages

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSD-OVONä»¥è§£å†³åŠ¨æ€åœºæ™¯ä¸­çš„å¼€æ”¾è¯æ±‡ç‰©ä½“å¯¼èˆªé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¼€æ”¾è¯æ±‡å¯¼èˆª` `åŠ¨æ€åœºæ™¯` `å¤šæ¨¡æ€æ¨¡å‹` `æ•°æ®é›†ç”Ÿæˆ` `æœºå™¨äººå¯¼èˆª` `Habitatæ¨¡æ‹Ÿå™¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•é€šå¸¸å±€é™äºé™æ€ç¯å¢ƒï¼Œæ— æ³•æœ‰æ•ˆå¤„ç†åŠ¨æ€åœºæ™¯å’Œå¯æ“ä½œç‰©ä½“çš„å¯¼èˆªä»»åŠ¡ã€‚
2. SD-OVONé€šè¿‡åˆ©ç”¨å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹ç”ŸæˆçœŸå®åœºæ™¯å˜ä½“ï¼Œæä¾›äº†ä¸€ä¸ªå…¨é¢çš„å¼€æ”¾è¯æ±‡ç‰©ä½“å¯¼èˆªæ•°æ®é›†å’ŒåŸºå‡†ç”Ÿæˆç®¡é“ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒSD-OVONåœ¨å¤æ‚ç¯å¢ƒä¸­æ˜¾è‘—æå‡äº†å¯¼èˆªä»£ç†çš„è®­ç»ƒå’Œè¯„ä¼°æ•ˆæœï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬æå‡ºäº†ç”¨äºåŠ¨æ€åœºæ™¯ä¸­å¼€æ”¾è¯æ±‡ç‰©ä½“å¯¼èˆªçš„è¯­ä¹‰æ„ŸçŸ¥æ•°æ®é›†å’ŒåŸºå‡†ç”Ÿæˆç®¡é“ï¼ˆSD-OVONï¼‰ã€‚è¯¥æ–¹æ³•åˆ©ç”¨é¢„è®­ç»ƒçš„å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹ç”Ÿæˆç¬¦åˆç°å®ä¸–ç•Œè¯­ä¹‰å’Œæ—¥å¸¸å¸¸è¯†çš„æ— é™ç‹¬ç‰¹ç…§ç‰‡çœŸå®åœºæ™¯å˜ä½“ï¼Œä»¥ç”¨äºå¯¼èˆªä»£ç†çš„è®­ç»ƒå’Œè¯„ä¼°ï¼Œå¹¶é™„å¸¦ä¸€ä¸ªç”Ÿæˆä¸Habitatæ¨¡æ‹Ÿå™¨å…¼å®¹çš„ç‰©ä½“å¯¼èˆªä»»åŠ¡é›†æ’ä»¶ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æä¾›äº†ä¸¤ä¸ªé¢„ç”Ÿæˆçš„ç‰©ä½“å¯¼èˆªä»»åŠ¡æ•°æ®é›†ï¼Œåˆ†åˆ«åŒ…å«çº¦3kå’Œ10kä¸ªå¼€æ”¾è¯æ±‡ç‰©ä½“å¯¼èˆªä»»åŠ¡çš„é›†ï¼Œæ¥æºäºåŒ…å«2.5kä¸ªçœŸå®ç¯å¢ƒç…§ç‰‡æ‰«æçš„SD-OVON-Scenesæ•°æ®é›†å’ŒåŒ…å«0.9kä¸ªæ‰‹åŠ¨æ£€æŸ¥çš„å¯æ“ä½œç‰©ä½“æ¨¡å‹çš„SD-OVON-Objectsæ•°æ®é›†ã€‚ä¸ä»¥å¾€ä»…é™äºé™æ€ç¯å¢ƒçš„æ•°æ®é›†ä¸åŒï¼ŒSD-OVONæ¶µç›–åŠ¨æ€åœºæ™¯å’Œå¯æ“ä½œç‰©ä½“ï¼Œä¿ƒè¿›äº†çœŸå®åˆ°æ¨¡æ‹Ÿå’Œæ¨¡æ‹Ÿåˆ°çœŸå®çš„æœºå™¨äººåº”ç”¨ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¼€æ”¾è¯æ±‡ç‰©ä½“å¯¼èˆªä»»åŠ¡ä¸­ï¼Œç°æœ‰æ•°æ®é›†ä»…é™äºé™æ€ç¯å¢ƒçš„é—®é¢˜ï¼Œå¯¼è‡´å¯¼èˆªä»£ç†åœ¨åŠ¨æ€åœºæ™¯ä¸­çš„æ€§èƒ½ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºçš„SD-OVONæ–¹æ³•é€šè¿‡é¢„è®­ç»ƒçš„å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹ç”Ÿæˆç¬¦åˆç°å®ä¸–ç•Œè¯­ä¹‰çš„åŠ¨æ€åœºæ™¯å˜ä½“ï¼Œä»è€Œæä¾›ä¸°å¯Œçš„è®­ç»ƒæ•°æ®ï¼Œå¢å¼ºå¯¼èˆªä»£ç†çš„é€‚åº”èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSD-OVONçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šåœºæ™¯ç”Ÿæˆæ¨¡å—ã€ä»»åŠ¡ç”Ÿæˆæ’ä»¶å’Œæ•°æ®é›†æ„å»ºæ¨¡å—ã€‚åœºæ™¯ç”Ÿæˆæ¨¡å—è´Ÿè´£ç”Ÿæˆå¤šæ ·åŒ–çš„åŠ¨æ€åœºæ™¯ï¼Œä»»åŠ¡ç”Ÿæˆæ’ä»¶åˆ™åˆ›å»ºä¸Habitatæ¨¡æ‹Ÿå™¨å…¼å®¹çš„å¯¼èˆªä»»åŠ¡ï¼Œæœ€åæ•°æ®é›†æ„å»ºæ¨¡å—æ•´åˆç”Ÿæˆçš„æ•°æ®ã€‚

**å…³é”®åˆ›æ–°**ï¼šSD-OVONçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶èƒ½å¤Ÿç”ŸæˆåŠ¨æ€åœºæ™¯å’Œå¯æ“ä½œç‰©ä½“çš„èƒ½åŠ›ï¼Œè¿™ä¸ä»¥å¾€ä»…é™äºé™æ€ç¯å¢ƒçš„æ•°æ®é›†å½¢æˆäº†é²œæ˜å¯¹æ¯”ï¼Œæå¤§åœ°æå‡äº†å¯¼èˆªä»»åŠ¡çš„ç°å®æ„Ÿã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸Šï¼Œæˆ‘ä»¬é‡‡ç”¨äº†å¤šæ¨¡æ€æ¨¡å‹è¿›è¡Œåœºæ™¯ç”Ÿæˆï¼Œå¹¶å¯¹ç”Ÿæˆçš„åœºæ™¯è¿›è¡Œäº†ä¸¥æ ¼çš„è¯­ä¹‰å’Œç°å®æ€§æ£€æŸ¥ï¼Œä»¥ç¡®ä¿æ•°æ®é›†çš„è´¨é‡å’Œå¤šæ ·æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨SD-OVON-3kæ•°æ®é›†çš„å¯¼èˆªä»£ç†åœ¨å¤æ‚ç¯å¢ƒä¸­çš„è¡¨ç°ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›åŸºçº¿ï¼Œæå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼ŒéªŒè¯äº†è¯¥æ•°æ®é›†åœ¨å¼€æ”¾è¯æ±‡ç‰©ä½“å¯¼èˆªä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººå¯¼èˆªã€æ™ºèƒ½å®¶å±…ã€è™šæ‹Ÿç°å®ç­‰ã€‚é€šè¿‡æä¾›ä¸°å¯Œçš„åŠ¨æ€åœºæ™¯æ•°æ®ï¼ŒSD-OVONå¯ä»¥å¸®åŠ©ç ”ç©¶äººå‘˜å’Œå¼€å‘è€…è®­ç»ƒæ›´ä¸ºæ™ºèƒ½å’Œçµæ´»çš„å¯¼èˆªç³»ç»Ÿï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„è¿›æ­¥ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present the Semantics-aware Dataset and Benchmark Generation Pipeline for Open-vocabulary Object Navigation in Dynamic Scenes (SD-OVON). It utilizes pretraining multimodal foundation models to generate infinite unique photo-realistic scene variants that adhere to real-world semantics and daily commonsense for the training and the evaluation of navigation agents, accompanied with a plugin for generating object navigation task episodes compatible to the Habitat simulator. In addition, we offer two pre-generated object navigation task datasets, SD-OVON-3k and SD-OVON-10k, comprising respectively about 3k and 10k episodes of the open-vocabulary object navigation task, derived from the SD-OVON-Scenes dataset with 2.5k photo-realistic scans of real-world environments and the SD-OVON-Objects dataset with 0.9k manually inspected scanned and artist-created manipulatable object models. Unlike prior datasets limited to static environments, SD-OVON covers dynamic scenes and manipulatable objects, facilitating both real-to-sim and sim-to-real robotic applications. This approach enhances the realism of navigation tasks, the training and the evaluation of open-vocabulary object navigation agents in complex settings. To demonstrate the effectiveness of our pipeline and datasets, we propose two baselines and evaluate them along with state-of-the-art baselines on SD-OVON-3k. The datasets, benchmark and source code are publicly available.

