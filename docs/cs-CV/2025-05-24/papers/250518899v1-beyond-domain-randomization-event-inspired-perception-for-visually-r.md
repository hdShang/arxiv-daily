---
layout: default
title: "Beyond Domain Randomization: Event-Inspired Perception for Visually Robust Adversarial Imitation from Videos"
---

# Beyond Domain Randomization: Event-Inspired Perception for Visually Robust Adversarial Imitation from Videos

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.18899" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.18899v1</a>
  <a href="https://arxiv.org/pdf/2505.18899.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.18899v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.18899v1', 'Beyond Domain Randomization: Event-Inspired Perception for Visually Robust Adversarial Imitation from Videos')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Andrea Ramazzina, Vittorio Giammarino, Matteo El-Hariry, Mario Bijelic

**åˆ†ç±»**: cs.CV, cs.LG, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-05-24

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºäº‹ä»¶å¯å‘æ„ŸçŸ¥ä»¥è§£å†³è§†é¢‘æ¨¡ä»¿ä¸­çš„è§†è§‰é²æ£’æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `è§†é¢‘æ¨¡ä»¿` `äº‹ä»¶å¯å‘æ„ŸçŸ¥` `è§†è§‰é²æ£’æ€§` `é¢†åŸŸè½¬ç§»` `åŠ¨æ€æ§åˆ¶` `ç”Ÿç‰©å¯å‘` `ç¨€ç–è¡¨ç¤º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†é¢‘æ¨¡ä»¿æ–¹æ³•åœ¨é¢å¯¹é¢†åŸŸè½¬ç§»æ—¶è¡¨ç°ä¸ä½³ï¼Œå°¤å…¶æ˜¯åœ¨å…‰ç…§å’Œé¢œè‰²ç­‰æ–¹é¢çš„å·®å¼‚ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§äº‹ä»¶å¯å‘çš„æ„ŸçŸ¥æ–¹æ³•ï¼Œé€šè¿‡å°†RGBè§†é¢‘è½¬æ¢ä¸ºç¨€ç–çš„äº‹ä»¶è¡¨ç¤ºï¼Œæ¶ˆé™¤é™æ€å¤–è§‚ç‰¹å¾çš„å½±å“ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªå¹³å°ä¸Šå®ç°äº†é²æ£’çš„è§†è§‰æ¨¡ä»¿ï¼Œä¸”æ— éœ€å¤æ‚çš„æ•°æ®å¢å¼ºï¼Œæ˜¾è‘—æå‡äº†æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†é¢‘æ¨¡ä»¿åœ¨ä¸“å®¶æ¼”ç¤ºä¸å­¦ä¹ è€…ç¯å¢ƒä¹‹é—´å­˜åœ¨é¢†åŸŸè½¬ç§»æ—¶å¸¸å¸¸å¤±è´¥ï¼Œä¾‹å¦‚å…‰ç…§ã€é¢œè‰²æˆ–çº¹ç†çš„å·®å¼‚ã€‚è™½ç„¶è§†è§‰éšæœºåŒ–åœ¨ä¸€å®šç¨‹åº¦ä¸Šè§£å†³äº†è¿™ä¸€é—®é¢˜ï¼Œä½†å…¶è®¡ç®—æˆæœ¬é«˜ä¸”ååº”æ€§å¼ºï¼Œéš¾ä»¥åº”å¯¹æœªçŸ¥åœºæ™¯ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œé€šè¿‡é‡æ–°æ€è€ƒæ„ŸçŸ¥è¡¨ç¤ºï¼Œæ¶ˆé™¤å¤–è§‚çš„å½±å“ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§äº‹ä»¶å¯å‘çš„æ„ŸçŸ¥æ–¹æ³•ï¼Œå°†æ ‡å‡†RGBè§†é¢‘è½¬æ¢ä¸ºç¨€ç–çš„åŸºäºäº‹ä»¶çš„è¡¨ç¤ºï¼Œç¼–ç æ—¶é—´å¼ºåº¦æ¢¯åº¦ï¼Œèˆå¼ƒé™æ€å¤–è§‚ç‰¹å¾ã€‚è¿™ç§ç”Ÿç‰©å­¦åŸºç¡€çš„æ–¹æ³•å°†è¿åŠ¨åŠ¨æ€ä¸è§†è§‰é£æ ¼è§£è€¦ï¼Œä½¿å¾—å³ä½¿åœ¨ä¸“å®¶ä¸ä»£ç†ç¯å¢ƒä¹‹é—´å­˜åœ¨è§†è§‰ä¸åŒ¹é…çš„æƒ…å†µä¸‹ï¼Œä¹Ÿèƒ½å®ç°é²æ£’çš„è§†è§‰æ¨¡ä»¿ã€‚é€šè¿‡åœ¨äº‹ä»¶æµä¸Šè®­ç»ƒç­–ç•¥ï¼Œæˆ‘ä»¬å®ç°äº†å¯¹åŸºäºå¤–è§‚çš„å¹²æ‰°ç‰©çš„æ— å…³æ€§ï¼Œæ— éœ€è®¡ç®—å¯†é›†ä¸”ç‰¹å®šäºç¯å¢ƒçš„æ•°æ®å¢å¼ºæŠ€æœ¯ã€‚å®éªŒç»“æœè¡¨æ˜è¯¥æ–¹æ³•åœ¨DeepMind Control Suiteå’ŒAdroitå¹³å°ä¸Šè¡¨ç°å‡ºè‰²ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è§†é¢‘æ¨¡ä»¿ä¸­å› é¢†åŸŸè½¬ç§»å¯¼è‡´çš„è§†è§‰é²æ£’æ€§ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºè§†è§‰éšæœºåŒ–ï¼Œè®¡ç®—æˆæœ¬é«˜ä¸”éš¾ä»¥é€‚åº”æœªçŸ¥åœºæ™¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ„ŸçŸ¥è¡¨ç¤ºæ–¹æ³•ï¼Œçµæ„Ÿæ¥æºäºç”Ÿç‰©è§†è§‰ç³»ç»Ÿï¼Œé‡ç‚¹å…³æ³¨æ—¶é—´ç¬å˜è€Œéé™æ€å¤–è§‚ï¼Œä»è€Œæ¶ˆé™¤å¤–è§‚å¯¹æ¨¡ä»¿çš„å½±å“ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å°†æ ‡å‡†RGBè§†é¢‘è½¬æ¢ä¸ºç¨€ç–çš„äº‹ä»¶è¡¨ç¤ºï¼Œç¼–ç æ—¶é—´å¼ºåº¦æ¢¯åº¦ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šè®­ç»ƒç­–ç•¥ä»¥å®ç°é²æ£’çš„è§†è§‰æ¨¡ä»¿ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº‹ä»¶å¯å‘çš„æ„ŸçŸ¥æ–¹æ³•ï¼Œå½»åº•æ”¹å˜äº†ä¼ ç»Ÿæ¨¡ä»¿å­¦ä¹ ä¸­å¯¹å¤–è§‚çš„ä¾èµ–ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨è§†è§‰ä¸åŒ¹é…çš„æƒ…å†µä¸‹ä»ç„¶è¡¨ç°å‡ºè‰²ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œé‡‡ç”¨äº†åŸºäºäº‹ä»¶çš„è¡¨ç¤ºæ–¹æ³•ï¼Œè®¾è®¡äº†é€‚åº”æ€§å¼ºçš„æŸå¤±å‡½æ•°ï¼Œå¹¶ä¼˜åŒ–äº†ç½‘ç»œç»“æ„ä»¥æé«˜å¯¹åŠ¨æ€è¿åŠ¨çš„æ•æ„Ÿæ€§ã€‚é€šè¿‡è¿™äº›è®¾è®¡ï¼Œæ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåœ°è§£è€¦è¿åŠ¨ä¸è§†è§‰é£æ ¼ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨äº‹ä»¶å¯å‘æ„ŸçŸ¥çš„æ–¹æ³•åœ¨DeepMind Control Suiteå’ŒAdroitå¹³å°ä¸Šæ˜¾è‘—æé«˜äº†è§†è§‰æ¨¡ä»¿çš„é²æ£’æ€§ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨é¢å¯¹è§†è§‰å¹²æ‰°æ—¶è¡¨ç°å‡ºæ›´å¼ºçš„é€‚åº”æ€§ï¼Œæå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œæ˜¾ç¤ºå‡ºè¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæ§åˆ¶ã€è‡ªåŠ¨é©¾é©¶å’Œäººæœºäº¤äº’ç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿåœ¨å¤æ‚å’ŒåŠ¨æ€ç¯å¢ƒä¸­å®ç°æ›´é«˜æ•ˆçš„æ¨¡ä»¿å­¦ä¹ ã€‚æœªæ¥ï¼Œéšç€æŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ï¼Œè¯¥æ–¹æ³•æœ‰æœ›åœ¨æ›´å¤šå®é™…åº”ç”¨ä¸­å±•ç°å…¶ä»·å€¼ï¼Œæå‡æ™ºèƒ½ç³»ç»Ÿçš„é€‚åº”èƒ½åŠ›å’Œé²æ£’æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Imitation from videos often fails when expert demonstrations and learner environments exhibit domain shifts, such as discrepancies in lighting, color, or texture. While visual randomization partially addresses this problem by augmenting training data, it remains computationally intensive and inherently reactive, struggling with unseen scenarios. We propose a different approach: instead of randomizing appearances, we eliminate their influence entirely by rethinking the sensory representation itself. Inspired by biological vision systems that prioritize temporal transients (e.g., retinal ganglion cells) and by recent sensor advancements, we introduce event-inspired perception for visually robust imitation. Our method converts standard RGB videos into a sparse, event-based representation that encodes temporal intensity gradients, discarding static appearance features. This biologically grounded approach disentangles motion dynamics from visual style, enabling robust visual imitation from observations even in the presence of visual mismatches between expert and agent environments. By training policies on event streams, we achieve invariance to appearance-based distractors without requiring computationally expensive and environment-specific data augmentation techniques. Experiments across the DeepMind Control Suite and the Adroit platform for dynamic dexterous manipulation show the efficacy of our method. Our code is publicly available at Eb-LAIfO.

