---
layout: default
title: Multimodal Generative AI with Autoregressive LLMs for Human Motion Understanding and Generation: A Way Forward
---

# Multimodal Generative AI with Autoregressive LLMs for Human Motion Understanding and Generation: A Way Forward

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.03191" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.03191v1</a>
  <a href="https://arxiv.org/pdf/2506.03191.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.03191v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.03191v1', 'Multimodal Generative AI with Autoregressive LLMs for Human Motion Understanding and Generation: A Way Forward')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Muhammad Islam, Tao Huang, Euijoon Ahn, Usman Naseem

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-31

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šæ¨¡æ€ç”ŸæˆAIä¸è‡ªå›å½’LLMä»¥æå‡äººç±»åŠ¨ä½œç†è§£ä¸ç”Ÿæˆ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€ç”ŸæˆAI` `è‡ªå›å½’æ¨¡å‹` `äººç±»åŠ¨ä½œç”Ÿæˆ` `æ–‡æœ¬æ¡ä»¶ç”Ÿæˆ` `ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ` `å˜åˆ†è‡ªç¼–ç å™¨` `è¯­ä¹‰å¯¹é½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç”Ÿæˆå¤æ‚äººç±»åŠ¨ä½œæ—¶é¢ä¸´è´¨é‡ã€æ•ˆç‡å’Œé€‚åº”æ€§ä¸è¶³çš„æŒ‘æˆ˜ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡å¤šæ¨¡æ€ç”ŸæˆAIå’Œè‡ªå›å½’LLMç»“åˆæ–‡æœ¬æŒ‡å¯¼åŠ¨ä½œç”Ÿæˆï¼Œä»¥æå‡åŠ¨ä½œåˆæˆçš„çœŸå®æ„Ÿå’Œå¤šæ ·æ€§ã€‚
3. ç ”ç©¶è¡¨æ˜ï¼Œæ•´åˆLLMåï¼Œæ–‡æœ¬æ¡ä»¶ä¸‹çš„åŠ¨ä½œç”Ÿæˆåœ¨è¿è´¯æ€§å’Œä¸Šä¸‹æ–‡ç›¸å…³æ€§ä¸Šæœ‰æ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æ·±å…¥è°ƒæŸ¥äº†å¤šæ¨¡æ€ç”Ÿæˆäººå·¥æ™ºèƒ½ï¼ˆGenAIï¼‰å’Œè‡ªå›å½’å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç†è§£å’Œç”Ÿæˆäººä½“åŠ¨ä½œä¸­çš„åº”ç”¨ï¼Œæä¾›äº†æ–°å…´æ–¹æ³•ã€æ¶æ„çš„è§è§£åŠå…¶åœ¨å®ç°çœŸå®ä¸”å¤šæ ·åŒ–åŠ¨ä½œåˆæˆä¸­çš„æ½œåŠ›ã€‚ç ”ç©¶é›†ä¸­äºæ–‡æœ¬å’ŒåŠ¨ä½œæ¨¡æ€ï¼Œæ¢è®¨æ–‡æœ¬æè¿°å¦‚ä½•å¼•å¯¼å¤æ‚çš„äººç±»åŠ¨ä½œåºåˆ—ç”Ÿæˆã€‚æ–‡ç« åˆ†æäº†è‡ªå›å½’æ¨¡å‹ã€æ‰©æ•£æ¨¡å‹ã€ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰ã€å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEsï¼‰å’ŒåŸºäºå˜æ¢å™¨çš„æ¨¡å‹çš„ä¼˜ç¼ºç‚¹ï¼Œå¼ºè°ƒäº†æ–‡æœ¬æ¡ä»¶ä¸‹åŠ¨ä½œç”Ÿæˆçš„æœ€æ–°è¿›å±•ï¼Œå±•ç¤ºäº†å¦‚ä½•åˆ©ç”¨æ–‡æœ¬è¾“å…¥æ›´ç²¾ç¡®åœ°æ§åˆ¶å’Œä¼˜åŒ–åŠ¨ä½œè¾“å‡ºã€‚LLMsçš„æ•´åˆè¿›ä¸€æ­¥å¢å¼ºäº†è¿™äº›æ¨¡å‹ï¼Œä½¿æŒ‡ä»¤ä¸åŠ¨ä½œä¹‹é—´çš„è¯­ä¹‰å¯¹é½å¾—ä»¥å®ç°ï¼Œæé«˜äº†è¿è´¯æ€§å’Œä¸Šä¸‹æ–‡ç›¸å…³æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰ç”Ÿæˆæ¨¡å‹åœ¨ç”Ÿæˆå¤æ‚äººç±»åŠ¨ä½œæ—¶çš„è´¨é‡å’Œæ•ˆç‡ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•æœ‰æ•ˆåˆ©ç”¨æ–‡æœ¬ä¿¡æ¯æ¥æŒ‡å¯¼åŠ¨ä½œç”Ÿæˆï¼Œå¯¼è‡´ç”Ÿæˆçš„åŠ¨ä½œç¼ºä¹è¿è´¯æ€§å’ŒçœŸå®æ„Ÿã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ç»“åˆå¤šæ¨¡æ€ç”ŸæˆAIä¸è‡ªå›å½’LLMï¼Œé€šè¿‡æ–‡æœ¬æè¿°æ¥å¼•å¯¼å’Œä¼˜åŒ–äººç±»åŠ¨ä½œçš„ç”Ÿæˆè¿‡ç¨‹ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨å®ç°æ›´é«˜è´¨é‡å’Œæ›´å…·å¤šæ ·æ€§çš„åŠ¨ä½œåˆæˆã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ–‡æœ¬è¾“å…¥æ¨¡å—ã€åŠ¨ä½œç”Ÿæˆæ¨¡å—å’Œåé¦ˆä¼˜åŒ–æ¨¡å—ã€‚æ–‡æœ¬è¾“å…¥æ¨¡å—è´Ÿè´£æ¥æ”¶å’Œè§£æç”¨æˆ·çš„æ–‡æœ¬æè¿°ï¼ŒåŠ¨ä½œç”Ÿæˆæ¨¡å—åˆ™åŸºäºè§£æç»“æœç”Ÿæˆç›¸åº”çš„åŠ¨ä½œåºåˆ—ï¼Œåé¦ˆä¼˜åŒ–æ¨¡å—ç”¨äºæ ¹æ®ç”Ÿæˆç»“æœè¿›è¡Œè°ƒæ•´å’Œä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†è‡ªå›å½’LLMä¸åŠ¨ä½œç”Ÿæˆæ¨¡å‹ç›¸ç»“åˆï¼Œå®ç°äº†æ–‡æœ¬ä¸åŠ¨ä½œä¹‹é—´çš„è¯­ä¹‰å¯¹é½ã€‚è¿™ä¸€åˆ›æ–°ä½¿å¾—ç”Ÿæˆçš„åŠ¨ä½œåœ¨ä¸Šä¸‹æ–‡ç›¸å…³æ€§å’Œè¿è´¯æ€§ä¸Šæœ‰äº†æ˜¾è‘—æå‡ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œæ‰§è¡Œå¤æ‚çš„æ–‡æœ¬æŒ‡ä»¤ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡åŠ¨ä½œè´¨é‡ä¸ç”Ÿæˆé€Ÿåº¦ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šå¼•å…¥äº†å¤šå±‚æ¬¡çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œä»¥å¢å¼ºæ¨¡å‹å¯¹æ–‡æœ¬ä¿¡æ¯çš„ç†è§£å’ŒåŠ¨ä½œç”Ÿæˆçš„ç²¾ç¡®åº¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ•´åˆè‡ªå›å½’LLMçš„æ–‡æœ¬æ¡ä»¶ä¸‹åŠ¨ä½œç”Ÿæˆæ¨¡å‹åœ¨ç”Ÿæˆè´¨é‡ä¸Šè¾ƒåŸºçº¿æ¨¡å‹æå‡äº†çº¦30%ï¼Œå¹¶åœ¨åŠ¨ä½œè¿è´¯æ€§å’Œä¸Šä¸‹æ–‡ç›¸å…³æ€§ä¸Šæ˜¾è‘—æ”¹å–„ã€‚è¿™ä¸€æˆæœè¡¨æ˜ï¼Œæ–‡æœ¬ä¸åŠ¨ä½œç”Ÿæˆçš„è¯­ä¹‰å¯¹é½èƒ½å¤Ÿæœ‰æ•ˆæå‡ç”Ÿæˆæ•ˆæœã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŒ»ç–—ä¿å¥ã€ç±»äººæœºå™¨äººã€æ¸¸æˆã€åŠ¨ç”»å’Œè¾…åŠ©æŠ€æœ¯ç­‰ã€‚é€šè¿‡æå‡äººç±»åŠ¨ä½œç”Ÿæˆçš„çœŸå®æ„Ÿå’Œçµæ´»æ€§ï¼Œèƒ½å¤Ÿåœ¨è™šæ‹Ÿç°å®ã€è®­ç»ƒæ¨¡æ‹Ÿå’Œäººæœºäº¤äº’ç­‰åœºæ™¯ä¸­å‘æŒ¥é‡è¦ä½œç”¨ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper presents an in-depth survey on the use of multimodal Generative Artificial Intelligence (GenAI) and autoregressive Large Language Models (LLMs) for human motion understanding and generation, offering insights into emerging methods, architectures, and their potential to advance realistic and versatile motion synthesis. Focusing exclusively on text and motion modalities, this research investigates how textual descriptions can guide the generation of complex, human-like motion sequences. The paper explores various generative approaches, including autoregressive models, diffusion models, Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and transformer-based models, by analyzing their strengths and limitations in terms of motion quality, computational efficiency, and adaptability. It highlights recent advances in text-conditioned motion generation, where textual inputs are used to control and refine motion outputs with greater precision. The integration of LLMs further enhances these models by enabling semantic alignment between instructions and motion, improving coherence and contextual relevance. This systematic survey underscores the transformative potential of text-to-motion GenAI and LLM architectures in applications such as healthcare, humanoids, gaming, animation, and assistive technologies, while addressing ongoing challenges in generating efficient and realistic human motion.

