---
layout: default
title: Any4D: Unified Feed-Forward Metric 4D Reconstruction
---

# Any4D: Unified Feed-Forward Metric 4D Reconstruction

**arXiv**: [2512.10935v1](https://arxiv.org/abs/2512.10935) | [PDF](https://arxiv.org/pdf/2512.10935.pdf)

**ä½œè€…**: Jay Karhade, Nikhil Keetha, Yuchen Zhang, Tanisha Gupta, Akash Sharma, Sebastian Scherer, Deva Ramanan

**åˆ†ç±»**: cs.CV, cs.AI, cs.LG, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-12-11

**å¤‡æ³¨**: Project Website: https://any-4d.github.io/

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Any4Dï¼šç»Ÿä¸€å‰é¦ˆå¼åº¦é‡4Dé‡å»ºæ¡†æž¶**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `4Dé‡å»º` `å¤šè§†è§’å­¦ä¹ ` `Transformerç½‘ç»œ` `åœºæ™¯æµä¼°è®¡` `å¤šæ¨¡æ€èžåˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰4Dé‡å»ºæ–¹æ³•é€šå¸¸å±€é™äºŽåŒè§†è§’åœºæ™¯æµæˆ–ç¨€ç–ç‚¹è·Ÿè¸ªï¼Œä¸”éš¾ä»¥èžåˆå¤šç§ä¼ æ„Ÿå™¨æ•°æ®ã€‚
2. Any4Dé‡‡ç”¨æ¨¡å—åŒ–è¡¨ç¤ºï¼Œåˆ©ç”¨è‡ªä¸­å¿ƒå’Œæœ¬ä¸­å¿ƒå› ç´ ç¼–ç 4Dåœºæ™¯ï¼Œå®žçŽ°å¤šæ¨¡æ€æ•°æ®èžåˆã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒAny4Dåœ¨ç²¾åº¦ä¸Šæå‡2-3å€ï¼Œè®¡ç®—æ•ˆçŽ‡æå‡15å€ï¼Œä¸ºä¸‹æ¸¸åº”ç”¨æä¾›å¯èƒ½ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºAny4Dï¼Œä¸€ä¸ªå¯æ‰©å±•çš„å¤šè§†è§’Transformerï¼Œç”¨äºŽåº¦é‡å°ºåº¦ä¸‹çš„ç¨ å¯†å‰é¦ˆå¼4Dé‡å»ºã€‚Any4Dç›´æŽ¥ç”ŸæˆNå¸§çš„é€åƒç´ è¿åŠ¨å’Œå‡ ä½•é¢„æµ‹ï¼Œè¿™ä¸Žä»¥å¾€ä¸»è¦å…³æ³¨åŒè§†è§’ç¨ å¯†åœºæ™¯æµæˆ–ç¨€ç–3Dç‚¹è·Ÿè¸ªçš„å·¥ä½œä¸åŒã€‚æ­¤å¤–ï¼Œä¸Žå…¶ä»–æœ€è¿‘çš„å•ç›®RGBè§†é¢‘4Dé‡å»ºæ–¹æ³•ä¸åŒï¼ŒAny4Då¯ä»¥å¤„ç†é¢å¤–çš„æ¨¡æ€å’Œä¼ æ„Ÿå™¨æ•°æ®ï¼Œä¾‹å¦‚RGB-Då¸§ã€åŸºäºŽIMUçš„è‡ªè¿åŠ¨å’Œé›·è¾¾å¤šæ™®å‹’æµ‹é‡ï¼ˆå¦‚æžœå¯ç”¨ï¼‰ã€‚è¯¥æ¡†æž¶çš„å…³é”®åˆ›æ–°åœ¨äºŽ4Dåœºæ™¯çš„æ¨¡å—åŒ–è¡¨ç¤ºï¼›å…·ä½“æ¥è¯´ï¼Œæ¯ä¸ªè§†è§’çš„4Dé¢„æµ‹ä½¿ç”¨ä»¥å±€éƒ¨ç›¸æœºåæ ‡è¡¨ç¤ºçš„å„ç§è‡ªä¸­å¿ƒå› ç´ ï¼ˆæ·±åº¦å›¾å’Œç›¸æœºå†…å‚ï¼‰å’Œä»¥å…¨å±€ä¸–ç•Œåæ ‡è¡¨ç¤ºçš„æœ¬ä¸­å¿ƒå› ç´ ï¼ˆç›¸æœºå¤–å‚å’Œåœºæ™¯æµï¼‰è¿›è¡Œç¼–ç ã€‚æˆ‘ä»¬åœ¨å„ç§è®¾ç½®ä¸­å®žçŽ°äº†å“è¶Šçš„æ€§èƒ½â€”â€”åœ¨å‡†ç¡®æ€§ï¼ˆè¯¯å·®é™ä½Ž2-3å€ï¼‰å’Œè®¡ç®—æ•ˆçŽ‡ï¼ˆé€Ÿåº¦æé«˜15å€ï¼‰æ–¹é¢ï¼Œä¸ºå¤šä¸ªä¸‹æ¸¸åº”ç”¨å¼€è¾Ÿäº†é“è·¯ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰4Dé‡å»ºæ–¹æ³•ä¸»è¦é›†ä¸­åœ¨åŒè§†è§’ç¨ å¯†åœºæ™¯æµæˆ–ç¨€ç–3Dç‚¹è·Ÿè¸ªï¼Œéš¾ä»¥å¤„ç†å¤šè§†è§’å’Œå¤šæ¨¡æ€æ•°æ®ï¼Œä¾‹å¦‚RGB-Dã€IMUå’Œé›·è¾¾ä¿¡æ¯ã€‚è¿™äº›æ–¹æ³•åœ¨ç²¾åº¦ã€æ•ˆçŽ‡å’Œé€šç”¨æ€§æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šAny4Dçš„æ ¸å¿ƒæ€è·¯æ˜¯é‡‡ç”¨ä¸€ç§æ¨¡å—åŒ–çš„4Dåœºæ™¯è¡¨ç¤ºæ–¹æ³•ï¼Œå°†åœºæ™¯åˆ†è§£ä¸ºè‡ªä¸­å¿ƒå› ç´ ï¼ˆå¦‚æ·±åº¦å›¾å’Œç›¸æœºå†…å‚ï¼Œåœ¨å±€éƒ¨ç›¸æœºåæ ‡ç³»ä¸‹è¡¨ç¤ºï¼‰å’Œæœ¬ä¸­å¿ƒå› ç´ ï¼ˆå¦‚ç›¸æœºå¤–å‚å’Œåœºæ™¯æµï¼Œåœ¨å…¨å±€ä¸–ç•Œåæ ‡ç³»ä¸‹è¡¨ç¤ºï¼‰ã€‚è¿™ç§è§£è€¦çš„è®¾è®¡ä½¿å¾—Any4Dèƒ½å¤Ÿçµæ´»åœ°èžåˆæ¥è‡ªä¸åŒä¼ æ„Ÿå™¨çš„æ•°æ®ï¼Œå¹¶è¿›è¡Œé«˜æ•ˆçš„4Dé‡å»ºã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šAny4Dé‡‡ç”¨ä¸€ä¸ªå¤šè§†è§’Transformeræž¶æž„ï¼Œè¾“å…¥ä¸ºå¤šå¸§å›¾åƒä»¥åŠå¯é€‰çš„RGB-Dæ•°æ®ã€IMUæ•°æ®å’Œé›·è¾¾æ•°æ®ã€‚è¯¥ç½‘ç»œé¦–å…ˆæå–æ¯ä¸ªè§†è§’çš„ç‰¹å¾ï¼Œç„¶åŽåˆ©ç”¨Transformerè¿›è¡Œè·¨è§†è§’çš„ä¿¡æ¯èžåˆã€‚ç½‘ç»œè¾“å‡ºæ¯ä¸ªåƒç´ çš„è¿åŠ¨å’Œå‡ ä½•é¢„æµ‹ï¼ŒåŒ…æ‹¬æ·±åº¦å›¾ã€åœºæ™¯æµå’Œç›¸æœºä½å§¿ã€‚è¿™äº›é¢„æµ‹åˆ†åˆ«åœ¨å±€éƒ¨ç›¸æœºåæ ‡ç³»å’Œå…¨å±€ä¸–ç•Œåæ ‡ç³»ä¸‹è¡¨ç¤ºã€‚

**å…³é”®åˆ›æ–°**ï¼šAny4Dçš„å…³é”®åˆ›æ–°åœ¨äºŽå…¶æ¨¡å—åŒ–çš„4Dåœºæ™¯è¡¨ç¤ºæ–¹æ³•ï¼Œä»¥åŠèƒ½å¤Ÿå¤„ç†å¤šç§ä¼ æ„Ÿå™¨æ•°æ®çš„èƒ½åŠ›ã€‚é€šè¿‡å°†åœºæ™¯åˆ†è§£ä¸ºè‡ªä¸­å¿ƒå’Œæœ¬ä¸­å¿ƒå› ç´ ï¼ŒAny4Dèƒ½å¤Ÿæœ‰æ•ˆåœ°èžåˆæ¥è‡ªä¸åŒè§†è§’çš„å’Œä¸åŒæ¨¡æ€çš„ä¿¡æ¯ï¼Œä»Žè€Œå®žçŽ°æ›´å‡†ç¡®å’Œé²æ£’çš„4Dé‡å»ºã€‚æ­¤å¤–ï¼ŒAny4Dé‡‡ç”¨å‰é¦ˆå¼æž¶æž„ï¼Œé¿å…äº†è¿­ä»£ä¼˜åŒ–ï¼Œæé«˜äº†è®¡ç®—æ•ˆçŽ‡ã€‚

**å…³é”®è®¾è®¡**ï¼šAny4Dä½¿ç”¨Transformerè¿›è¡Œè·¨è§†è§’ä¿¡æ¯èžåˆï¼Œå¹¶è®¾è®¡äº†ä¸“é—¨çš„æŸå¤±å‡½æ•°æ¥çº¦æŸæ·±åº¦å›¾ã€åœºæ™¯æµå’Œç›¸æœºä½å§¿çš„é¢„æµ‹ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬å…‰åº¦ä¸€è‡´æ€§æŸå¤±ã€å‡ ä½•ä¸€è‡´æ€§æŸå¤±å’Œè¿åŠ¨ä¸€è‡´æ€§æŸå¤±ã€‚ç½‘ç»œç»“æž„å’Œå‚æ•°è®¾ç½®æ ¹æ®ä¸åŒçš„æ•°æ®é›†å’Œä»»åŠ¡è¿›è¡Œè°ƒæ•´ã€‚å…·ä½“ç»†èŠ‚æœªåœ¨æ‘˜è¦ä¸­è¯¦ç»†è¯´æ˜Žï¼Œéœ€è¦å‚è€ƒè®ºæ–‡å…¨æ–‡ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

Any4Dåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚æ‘˜è¦ä¸­æåˆ°ï¼ŒAny4Dåœ¨ç²¾åº¦ä¸Šæ¯”çŽ°æœ‰æ–¹æ³•æå‡äº†2-3å€ï¼ˆè¯¯å·®é™ä½Ž2-3å€ï¼‰ï¼Œè®¡ç®—æ•ˆçŽ‡æå‡äº†15å€ã€‚è¿™äº›ç»“æžœè¡¨æ˜ŽAny4Dåœ¨4Dé‡å»ºæ–¹é¢å…·æœ‰æ˜¾è‘—çš„ä¼˜åŠ¿ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

Any4Då…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼ŒåŒ…æ‹¬è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€å¢žå¼ºçŽ°å®žå’Œè™šæ‹ŸçŽ°å®žç­‰é¢†åŸŸã€‚å®ƒå¯ä»¥ç”¨äºŽæž„å»ºåŠ¨æ€åœºæ™¯çš„ä¸‰ç»´æ¨¡åž‹ï¼Œä¼°è®¡ç‰©ä½“çš„è¿åŠ¨è½¨è¿¹ï¼Œä»¥åŠè¿›è¡Œåœºæ™¯ç†è§£å’Œé¢„æµ‹ã€‚è¯¥ç ”ç©¶çš„å®žé™…ä»·å€¼åœ¨äºŽæé«˜äº†4Dé‡å»ºçš„ç²¾åº¦å’Œæ•ˆçŽ‡ï¼Œä¸ºä¸‹æ¸¸åº”ç”¨æä¾›äº†æ›´å¯é çš„æ•°æ®åŸºç¡€ã€‚æœªæ¥ï¼ŒAny4Då¯ä»¥è¿›ä¸€æ­¥æ‰©å±•åˆ°æ›´å¤§è§„æ¨¡çš„åœºæ™¯å’Œæ›´å¤æ‚çš„åŠ¨æ€çŽ¯å¢ƒã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We present Any4D, a scalable multi-view transformer for metric-scale, dense feed-forward 4D reconstruction. Any4D directly generates per-pixel motion and geometry predictions for N frames, in contrast to prior work that typically focuses on either 2-view dense scene flow or sparse 3D point tracking. Moreover, unlike other recent methods for 4D reconstruction from monocular RGB videos, Any4D can process additional modalities and sensors such as RGB-D frames, IMU-based egomotion, and Radar Doppler measurements, when available. One of the key innovations that allows for such a flexible framework is a modular representation of a 4D scene; specifically, per-view 4D predictions are encoded using a variety of egocentric factors (depthmaps and camera intrinsics) represented in local camera coordinates, and allocentric factors (camera extrinsics and scene flow) represented in global world coordinates. We achieve superior performance across diverse setups - both in terms of accuracy (2-3X lower error) and compute efficiency (15X faster), opening avenues for multiple downstream applications.

