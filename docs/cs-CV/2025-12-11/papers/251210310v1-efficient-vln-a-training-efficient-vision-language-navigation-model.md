---
layout: default
title: Efficient-VLN: A Training-Efficient Vision-Language Navigation Model
---

# Efficient-VLN: A Training-Efficient Vision-Language Navigation Model

**arXiv**: [2512.10310v1](https://arxiv.org/abs/2512.10310) | [PDF](https://arxiv.org/pdf/2512.10310.pdf)

**ä½œè€…**: Duo Zheng, Shijia Huang, Yanyang Li, Liwei Wang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-11

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Efficient-VLNï¼šä¸€ç§è®­ç»ƒé«˜æ•ˆçš„è§†è§‰-è¯­è¨€å¯¼èˆªæ¨¡åž‹ï¼Œæ˜¾è‘—é™ä½Žè®­ç»ƒå¼€é”€ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€å¯¼èˆª` `å¤šæ¨¡æ€å­¦ä¹ ` `é«˜æ•ˆè®­ç»ƒ` `è®°å¿†æœºåˆ¶` `æŽ¢ç´¢ç­–ç•¥`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰VLNæ–¹æ³•åœ¨å¤„ç†é•¿åºåˆ—åŽ†å²è§‚æµ‹æ—¶è®¡ç®—å¼€é”€å¤§ï¼Œä¸”DAggerè®­ç»ƒä¸­æŽ¢ç´¢æ•ˆçŽ‡ä¸Žè½¨è¿¹é•¿åº¦å­˜åœ¨æƒè¡¡ã€‚
2. Efficient-VLNé€šè¿‡æ¸è¿›å¼è®°å¿†å’Œå¯å­¦ä¹ é€’å½’è®°å¿†å‡å°‘tokenå¤„ç†è´Ÿæ‹…ï¼Œå¹¶ä½¿ç”¨åŠ¨æ€æ··åˆç­–ç•¥å¹³è¡¡æŽ¢ç´¢æ•ˆçŽ‡ã€‚
3. Efficient-VLNåœ¨R2R-CEå’ŒRxR-CEä¸Šå–å¾—SOTAæ€§èƒ½ï¼Œä¸”è®­ç»ƒæ—¶é—´å¤§å¹…ç¼©çŸ­è‡³282 H800 GPUå°æ—¶ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€å¤§åž‹è¯­è¨€æ¨¡åž‹(MLLMs)åœ¨è§†è§‰-è¯­è¨€å¯¼èˆª(VLN)ä¸­å±•çŽ°å‡ºå·¨å¤§çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œå…¶å·¨å¤§çš„è®­ç»ƒå¼€é”€ä¸¥é‡é˜»ç¢äº†å®žé™…åº”ç”¨ã€‚æˆ‘ä»¬å‘çŽ°å¯¼è‡´å¼€é”€çš„ä¸¤ä¸ªå…³é”®é—®é¢˜ï¼š(1)å¤„ç†é•¿æ—¶ç¨‹åŽ†å²è§‚æµ‹ä½œä¸ºå¤§é‡tokenåºåˆ—å¸¦æ¥çš„äºŒæ¬¡è®¡ç®—è´Ÿæ‹…ï¼Œä»¥åŠ(2)DAggerä¸­çš„æŽ¢ç´¢æ•ˆçŽ‡æƒè¡¡ï¼Œå³æ”¶é›†agentæŽ¢ç´¢è½¨è¿¹çš„æ•°æ®èšåˆè¿‡ç¨‹ã€‚æ›´å¤šçš„æŽ¢ç´¢è™½ç„¶èƒ½äº§ç”Ÿæœ‰æ•ˆçš„é”™è¯¯æ¢å¤è½¨è¿¹ä»¥å¤„ç†æµ‹è¯•æ—¶åˆ†å¸ƒåç§»ï¼Œä½†ä»£ä»·æ˜¯è®­ç»ƒå’ŒæŽ¨ç†çš„è½¨è¿¹é•¿åº¦æ›´é•¿ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†Efficient-VLNï¼Œä¸€ç§è®­ç»ƒé«˜æ•ˆçš„VLNæ¨¡åž‹ã€‚å…·ä½“æ¥è¯´ï¼Œä¸ºäº†å‡è½»tokenå¤„ç†è´Ÿæ‹…ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸¤ç§é«˜æ•ˆçš„è®°å¿†æœºåˆ¶ï¼šä¸€ç§åŠ¨æ€åœ°ä¸ºæœ€è¿‘çš„è§‚æµ‹åˆ†é…æ›´å¤štokençš„æ¸è¿›å¼è®°å¿†ï¼Œä»¥åŠä¸€ç§åˆ©ç”¨å¯å­¦ä¹ tokençš„é”®å€¼ç¼“å­˜ä½œä¸ºè®°å¿†çŠ¶æ€çš„å¯å­¦ä¹ é€’å½’è®°å¿†ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åŠ¨æ€æ··åˆç­–ç•¥æ¥å¹³è¡¡æŽ¢ç´¢æ•ˆçŽ‡çš„æƒè¡¡ã€‚å¤§é‡å®žéªŒè¡¨æ˜Žï¼ŒEfficient-VLNåœ¨R2R-CEï¼ˆ64.2% SRï¼‰å’ŒRxR-CEï¼ˆ67.0% SRï¼‰ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚å…³é”®çš„æ˜¯ï¼Œæˆ‘ä»¬çš„æ¨¡åž‹ä»…æ¶ˆè€—282 H800 GPUå°æ—¶ï¼Œä¸Žæœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼Œè®­ç»ƒå¼€é”€æ˜¾è‘—é™ä½Žã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰çš„è§†è§‰-è¯­è¨€å¯¼èˆªï¼ˆVLNï¼‰æ¨¡åž‹ï¼Œç‰¹åˆ«æ˜¯åŸºäºŽå¤šæ¨¡æ€å¤§åž‹è¯­è¨€æ¨¡åž‹ï¼ˆMLLMsï¼‰çš„æ¨¡åž‹ï¼Œåœ¨è®­ç»ƒæ—¶é¢ä¸´ç€å·¨å¤§çš„è®¡ç®—å¼€é”€ã€‚ä¸»è¦ç—›ç‚¹åœ¨äºŽå¤„ç†é•¿æ—¶ç¨‹çš„åŽ†å²è§‚æµ‹æ•°æ®æ—¶ï¼Œéœ€è¦å¤„ç†å¤§é‡çš„tokenåºåˆ—ï¼Œå¯¼è‡´è®¡ç®—å¤æ‚åº¦å‘ˆäºŒæ¬¡æ–¹å¢žé•¿ã€‚æ­¤å¤–ï¼Œåœ¨åˆ©ç”¨DAggerç®—æ³•è¿›è¡Œè®­ç»ƒæ—¶ï¼Œéœ€è¦å¹³è¡¡æŽ¢ç´¢çš„å……åˆ†æ€§å’Œè®­ç»ƒæ•ˆçŽ‡ï¼Œå³æ›´å¤šçš„æŽ¢ç´¢è™½ç„¶èƒ½æå‡æ¨¡åž‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œä½†ä¼šæ˜¾è‘—å¢žåŠ è®­ç»ƒè½¨è¿¹çš„é•¿åº¦ï¼Œä»Žè€Œå¢žåŠ è®¡ç®—è´Ÿæ‹…ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šEfficient-VLNçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è®¾è®¡é«˜æ•ˆçš„è®°å¿†æœºåˆ¶å’ŒåŠ¨æ€çš„æŽ¢ç´¢ç­–ç•¥æ¥é™ä½Žè®­ç»ƒå¼€é”€ã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒæ—¨åœ¨å‡å°‘éœ€è¦å¤„ç†çš„tokenæ•°é‡ï¼Œå¹¶ä¼˜åŒ–DAggerè®­ç»ƒè¿‡ç¨‹ä¸­çš„æŽ¢ç´¢ç­–ç•¥ï¼Œä»Žè€Œåœ¨ä¿è¯æ¨¡åž‹æ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½Žè®­ç»ƒæ‰€éœ€çš„è®¡ç®—èµ„æºã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šEfficient-VLNçš„æ•´ä½“æ¡†æž¶åŒ…æ‹¬è§†è§‰ç¼–ç å™¨ã€è¯­è¨€ç¼–ç å™¨ã€è®°å¿†æ¨¡å—å’ŒåŠ¨ä½œé¢„æµ‹æ¨¡å—ã€‚è§†è§‰ç¼–ç å™¨è´Ÿè´£æå–çŽ¯å¢ƒå›¾åƒçš„è§†è§‰ç‰¹å¾ï¼Œè¯­è¨€ç¼–ç å™¨è´Ÿè´£å¤„ç†å¯¼èˆªæŒ‡ä»¤ã€‚è®°å¿†æ¨¡å—ç”¨äºŽå­˜å‚¨å’Œæ›´æ–°åŽ†å²è§‚æµ‹ä¿¡æ¯ï¼Œå¹¶å°†å…¶ä¸Žå½“å‰è§‚æµ‹ä¿¡æ¯èžåˆã€‚åŠ¨ä½œé¢„æµ‹æ¨¡å—æ ¹æ®èžåˆåŽçš„ä¿¡æ¯é¢„æµ‹ä¸‹ä¸€æ­¥çš„å¯¼èˆªåŠ¨ä½œã€‚è¯¥æ¡†æž¶çš„å…³é”®åœ¨äºŽè®°å¿†æ¨¡å—çš„è®¾è®¡ï¼Œå®ƒé‡‡ç”¨äº†æ¸è¿›å¼è®°å¿†å’Œå¯å­¦ä¹ é€’å½’è®°å¿†ä¸¤ç§æœºåˆ¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šEfficient-VLNæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºŽå…¶é«˜æ•ˆçš„è®°å¿†æœºåˆ¶ã€‚æ¸è¿›å¼è®°å¿†åŠ¨æ€åœ°ä¸ºæœ€è¿‘çš„è§‚æµ‹åˆ†é…æ›´å¤šçš„tokenï¼Œä»Žè€Œæ›´å…³æ³¨å½“å‰çŽ¯å¢ƒä¿¡æ¯ã€‚å¯å­¦ä¹ é€’å½’è®°å¿†åˆ™åˆ©ç”¨å¯å­¦ä¹ çš„tokenä½œä¸ºè®°å¿†çŠ¶æ€ï¼Œé€šè¿‡é”®å€¼ç¼“å­˜çš„æ–¹å¼å­˜å‚¨åŽ†å²ä¿¡æ¯ï¼Œé¿å…äº†å¯¹æ‰€æœ‰åŽ†å²è§‚æµ‹è¿›è¡Œé‡å¤å¤„ç†ã€‚æ­¤å¤–ï¼ŒåŠ¨æ€æ··åˆç­–ç•¥èƒ½å¤Ÿæ ¹æ®è®­ç»ƒçš„è¿›å±•è‡ªé€‚åº”åœ°è°ƒæ•´æŽ¢ç´¢çš„ç¨‹åº¦ï¼Œä»Žè€Œå¹³è¡¡æŽ¢ç´¢æ•ˆçŽ‡å’Œæ¨¡åž‹æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¸è¿›å¼è®°å¿†é€šè¿‡åŠ¨æ€è°ƒæ•´tokenåˆ†é…æ¯”ä¾‹æ¥å…³æ³¨æœ€è¿‘çš„è§‚æµ‹ã€‚å¯å­¦ä¹ é€’å½’è®°å¿†ä½¿ç”¨å°‘é‡å¯å­¦ä¹ çš„tokenæ¥è¡¨ç¤ºåŽ†å²çŠ¶æ€ï¼Œå¹¶é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶å°†å½“å‰è§‚æµ‹ä¿¡æ¯ä¸ŽåŽ†å²çŠ¶æ€èžåˆã€‚åŠ¨æ€æ··åˆç­–ç•¥ä½¿ç”¨ä¸€ä¸ªå¯å­¦ä¹ çš„æƒé‡æ¥å¹³è¡¡ä¸“å®¶ç­–ç•¥å’ŒæŽ¢ç´¢ç­–ç•¥ï¼Œè¯¥æƒé‡æ ¹æ®è®­ç»ƒçš„è¿›å±•è¿›è¡Œè°ƒæ•´ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬å¯¼èˆªæŸå¤±å’Œè¾…åŠ©æŸå¤±ï¼Œå¯¼èˆªæŸå¤±ç”¨äºŽä¼˜åŒ–åŠ¨ä½œé¢„æµ‹ï¼Œè¾…åŠ©æŸå¤±ç”¨äºŽä¼˜åŒ–è®°å¿†æ¨¡å—çš„å­¦ä¹ ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

Efficient-VLNåœ¨R2R-CEä¸Šå–å¾—äº†64.2%çš„SRï¼Œåœ¨RxR-CEä¸Šå–å¾—äº†67.0%çš„SRï¼Œè¾¾åˆ°äº†state-of-the-artçš„æ€§èƒ½ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œè¯¥æ¨¡åž‹ä»…æ¶ˆè€—282 H800 GPUå°æ—¶è¿›è¡Œè®­ç»ƒï¼Œç›¸æ¯”äºŽå…¶ä»–SOTAæ–¹æ³•ï¼Œè®­ç»ƒå¼€é”€æ˜¾è‘—é™ä½Žï¼Œä½“çŽ°äº†å…¶é«˜æ•ˆæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

Efficient-VLNå¯åº”ç”¨äºŽæœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ã€è™šæ‹ŸçŽ°å®žç­‰é¢†åŸŸã€‚é€šè¿‡é™ä½Žè®­ç»ƒæˆæœ¬ï¼Œè¯¥æ¨¡åž‹èƒ½å¤Ÿæ›´å®¹æ˜“åœ°éƒ¨ç½²åˆ°èµ„æºå—é™çš„å¹³å°ä¸Šï¼Œå¹¶åŠ é€Ÿç›¸å…³æŠ€æœ¯çš„ç ”å‘å’Œåº”ç”¨ã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶æœ‰æœ›æŽ¨åŠ¨æ›´æ™ºèƒ½ã€æ›´é«˜æ•ˆçš„å¯¼èˆªç³»ç»Ÿå‘å±•ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multimodal large language models (MLLMs) have shown promising potential in Vision-Language Navigation (VLN). However, their practical development is severely hindered by the substantial training overhead. We recognize two key issues that contribute to the overhead: (1) the quadratic computational burden from processing long-horizon historical observations as massive sequences of tokens, and (2) the exploration-efficiency trade-off in DAgger, i.e., a data aggregation process of collecting agent-explored trajectories. While more exploration yields effective error-recovery trajectories for handling test-time distribution shifts, it comes at the cost of longer trajectory lengths for both training and inference. To address these challenges, we propose Efficient-VLN, a training-efficient VLN model. Specifically, to mitigate the token processing burden, we design two efficient memory mechanisms: a progressive memory that dynamically allocates more tokens to recent observations, and a learnable recursive memory that utilizes the key-value cache of learnable tokens as the memory state. Moreover, we introduce a dynamic mixed policy to balance the exploration-efficiency trade-off. Extensive experiments show that Efficient-VLN achieves state-of-the-art performance on R2R-CE (64.2% SR) and RxR-CE (67.0% SR). Critically, our model consumes merely 282 H800 GPU hours, demonstrating a dramatic reduction in training overhead compared to state-of-the-art methods.

