---
layout: default
title: Hybrid Transformer-Mamba Architecture for Weakly Supervised Volumetric Medical Segmentation
---

# Hybrid Transformer-Mamba Architecture for Weakly Supervised Volumetric Medical Segmentation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.10353" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.10353v1</a>
  <a href="https://arxiv.org/pdf/2512.10353.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.10353v1" onclick="toggleFavorite(this, '2512.10353v1', 'Hybrid Transformer-Mamba Architecture for Weakly Supervised Volumetric Medical Segmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yiheng Lyu, Lian Xu, Mohammed Bennamoun, Farid Boussaid, Coen Arrow, Girish Dwivedi

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-11

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/YihengLyu/TranSamba)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTranSambaï¼Œä¸€ç§æ··åˆTransformer-Mambaæ¶æ„ï¼Œç”¨äºå¼±ç›‘ç£ä½“ç§¯åŒ»å­¦å›¾åƒåˆ†å‰²ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `å¼±ç›‘ç£å­¦ä¹ ` `åŒ»å­¦å›¾åƒåˆ†å‰²` `Transformer` `Mamba` `ä½“ç§¯æ•°æ®` `3Dä¸Šä¸‹æ–‡å»ºæ¨¡` `çŠ¶æ€ç©ºé—´æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¼±ç›‘ç£åŒ»å­¦å›¾åƒåˆ†å‰²æ–¹æ³•å¿½ç•¥äº†ä½“ç§¯æ•°æ®çš„3Dç‰¹æ€§ï¼Œé™åˆ¶äº†åˆ†å‰²æ€§èƒ½ã€‚
2. TranSambaåˆ©ç”¨Cross-Plane Mambaå—å¢å¼ºTransformerï¼Œé«˜æ•ˆåœ°åœ¨åˆ‡ç‰‡é—´äº¤æ¢ä¿¡æ¯ï¼Œæå‡3Dä¸Šä¸‹æ–‡å»ºæ¨¡èƒ½åŠ›ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒTranSambaåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¶…è¶Šç°æœ‰æ–¹æ³•ï¼Œå®ç°äº†æœ€å…ˆè¿›çš„å¼±ç›‘ç£ä½“ç§¯åŒ»å­¦å›¾åƒåˆ†å‰²æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºTranSambaï¼Œä¸€ç§æ··åˆTransformer-Mambaæ¶æ„ï¼Œæ—¨åœ¨æ•è·3Dä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œç”¨äºå¼±ç›‘ç£ä½“ç§¯åŒ»å­¦å›¾åƒåˆ†å‰²ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äº2Dç¼–ç å™¨ï¼Œå¿½ç•¥äº†æ•°æ®çš„ä½“ç§¯ç‰¹æ€§ã€‚TranSambaé€šè¿‡Cross-Plane Mambaå—å¢å¼ºäº†æ ‡å‡†çš„Vision Transformeréª¨å¹²ç½‘ç»œï¼Œåˆ©ç”¨çŠ¶æ€ç©ºé—´æ¨¡å‹çš„çº¿æ€§å¤æ‚åº¦ï¼Œå®ç°ç›¸é‚»åˆ‡ç‰‡ä¹‹é—´çš„æœ‰æ•ˆä¿¡æ¯äº¤æ¢ã€‚è¿™ç§ä¿¡æ¯äº¤æ¢å¢å¼ºäº†Transformerå—è®¡ç®—çš„åˆ‡ç‰‡å†…æˆå¯¹è‡ªæ³¨æ„åŠ›ï¼Œç›´æ¥ä¿ƒè¿›äº†ç›®æ ‡å®šä½çš„æ³¨æ„åŠ›å›¾ç”Ÿæˆã€‚TranSambaå®ç°äº†æœ‰æ•ˆçš„ä½“ç§¯å»ºæ¨¡ï¼Œå…¶æ—¶é—´å¤æ‚åº¦éšè¾“å…¥ä½“ç§¯æ·±åº¦çº¿æ€§å¢é•¿ï¼Œå¹¶ä¿æŒæ‰¹é‡å¤„ç†çš„æ’å®šå†…å­˜ä½¿ç”¨ã€‚åœ¨ä¸‰ä¸ªæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒTranSambaå»ºç«‹äº†æ–°çš„state-of-the-artæ€§èƒ½ï¼Œåœ¨ä¸åŒçš„æ¨¡æ€å’Œç—…ç†æ¡ä»¶ä¸‹å§‹ç»ˆä¼˜äºç°æœ‰æ–¹æ³•ã€‚æºä»£ç å’Œè®­ç»ƒå¥½çš„æ¨¡å‹å·²å…¬å¼€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¼±ç›‘ç£ä½“ç§¯åŒ»å­¦å›¾åƒåˆ†å‰²é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦åŸºäº2Dç¼–ç å™¨ï¼Œæ— æ³•å……åˆ†åˆ©ç”¨ä½“ç§¯æ•°æ®çš„3Dç©ºé—´ä¿¡æ¯ï¼Œå¯¼è‡´åˆ†å‰²ç²¾åº¦å—é™ã€‚æ­¤å¤–ï¼Œç›´æ¥ä½¿ç”¨3Då·ç§¯æˆ–3D Transformerè®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œéš¾ä»¥åº”ç”¨äºå¤§è§„æ¨¡ä½“ç§¯æ•°æ®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ç»“åˆTransformerçš„å…¨å±€å»ºæ¨¡èƒ½åŠ›å’ŒMambaçŠ¶æ€ç©ºé—´æ¨¡å‹çš„åºåˆ—å»ºæ¨¡æ•ˆç‡ï¼Œè®¾è®¡ä¸€ç§æ··åˆæ¶æ„TranSambaï¼Œä»¥é«˜æ•ˆåœ°æ•è·3Dä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚é€šè¿‡Cross-Plane Mambaå—åœ¨ç›¸é‚»åˆ‡ç‰‡é—´è¿›è¡Œä¿¡æ¯äº¤æ¢ï¼Œå¢å¼ºTransformerçš„è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œä»è€Œæå‡åˆ†å‰²æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTranSambaçš„æ•´ä½“æ¶æ„åŸºäºVision Transformer (ViT)ã€‚é¦–å…ˆï¼Œå°†è¾“å…¥ä½“ç§¯æ•°æ®åˆ†å‰²æˆä¸€ç³»åˆ—2Dåˆ‡ç‰‡ã€‚ç„¶åï¼Œæ¯ä¸ªåˆ‡ç‰‡é€šè¿‡ViTè¿›è¡Œç‰¹å¾æå–ã€‚å…³é”®åœ¨äºï¼Œåœ¨ViTçš„æ¯ä¸ªTransformerå—ä¹‹é—´ï¼Œæ’å…¥Cross-Plane Mambaå—ï¼Œç”¨äºåœ¨ç›¸é‚»åˆ‡ç‰‡ä¹‹é—´ä¼ é€’ä¿¡æ¯ã€‚æœ€åï¼Œé€šè¿‡è§£ç å™¨å°†ç‰¹å¾æ˜ å°„æ¢å¤åˆ°åŸå§‹åˆ†è¾¨ç‡ï¼Œè¿›è¡Œåƒç´ çº§åˆ«çš„åˆ†å‰²é¢„æµ‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šTranSambaçš„å…³é”®åˆ›æ–°åœ¨äºCross-Plane Mambaå—çš„è®¾è®¡ã€‚è¯¥æ¨¡å—åˆ©ç”¨Mambaæ¨¡å‹çš„çº¿æ€§å¤æ‚åº¦ï¼Œé«˜æ•ˆåœ°åœ¨ç›¸é‚»åˆ‡ç‰‡ä¹‹é—´è¿›è¡Œä¿¡æ¯äº¤æ¢ï¼Œä»è€Œåœ¨è®¡ç®—æˆæœ¬å¯æ§çš„å‰æä¸‹ï¼Œå®ç°äº†æœ‰æ•ˆçš„3Dä¸Šä¸‹æ–‡å»ºæ¨¡ã€‚ä¸ç›´æ¥ä½¿ç”¨3Då·ç§¯æˆ–3D Transformerç›¸æ¯”ï¼ŒTranSambaåœ¨æ—¶é—´å’Œç©ºé—´å¤æ‚åº¦ä¸Šå…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚

**å…³é”®è®¾è®¡**ï¼šCross-Plane Mambaå—çš„å…·ä½“å®ç°ç»†èŠ‚åŒ…æ‹¬ï¼šé¦–å…ˆï¼Œå°†ç›¸é‚»åˆ‡ç‰‡çš„ç‰¹å¾æ˜ å°„æ²¿ç€åˆ‡ç‰‡æ–¹å‘å †å ã€‚ç„¶åï¼Œä½¿ç”¨Mambaæ¨¡å‹å¯¹å †å åçš„ç‰¹å¾è¿›è¡Œåºåˆ—å»ºæ¨¡ï¼Œä»è€Œå®ç°ä¿¡æ¯äº¤æ¢ã€‚Mambaæ¨¡å‹çš„å‚æ•°è®¾ç½®éµå¾ªåŸå§‹è®ºæ–‡ã€‚æŸå¤±å‡½æ•°é‡‡ç”¨Dice Losså’ŒCross-Entropy Lossçš„åŠ æƒç»„åˆï¼Œä»¥å¹³è¡¡åˆ†å‰²ç²¾åº¦å’Œç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

TranSambaåœ¨ä¸‰ä¸ªå…¬å¼€æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼ŒåŒ…æ‹¬è‚ºéƒ¨CTã€å¿ƒè„MRIå’Œå‰åˆ—è…ºMRIã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTranSambaåœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šå‡å–å¾—äº†state-of-the-artçš„æ€§èƒ½ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰çš„å¼±ç›‘ç£åˆ†å‰²æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨è‚ºéƒ¨CTæ•°æ®é›†ä¸Šï¼ŒTranSambaçš„Diceç³»æ•°æ¯”æœ€ä½³åŸºçº¿æé«˜äº†3-5ä¸ªç™¾åˆ†ç‚¹ã€‚æ­¤å¤–ï¼ŒTranSambaçš„è®¡ç®—æ•ˆç‡ä¹Ÿå¾ˆé«˜ï¼Œå¯ä»¥åœ¨åˆç†çš„æ—¶é—´å†…å¤„ç†å¤§è§„æ¨¡ä½“ç§¯æ•°æ®ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

TranSambaåœ¨åŒ»å­¦å½±åƒåˆ†æé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯ç”¨äºå„ç§æ¨¡æ€ï¼ˆå¦‚CTã€MRIï¼‰å’Œå™¨å®˜çš„åˆ†å‰²ï¼Œè¾…åŠ©åŒ»ç”Ÿè¿›è¡Œç–¾ç—…è¯Šæ–­ã€æ²»ç–—è®¡åˆ’å’Œé¢„åè¯„ä¼°ã€‚è¯¥æ–¹æ³•å°¤å…¶é€‚ç”¨äºéœ€è¦ç²¾ç¡®3Dåˆ†å‰²çš„åœºæ™¯ï¼Œä¾‹å¦‚è‚¿ç˜¤åˆ†å‰²ã€å™¨å®˜åˆ†å‰²å’Œè¡€ç®¡åˆ†å‰²ã€‚æœªæ¥ï¼ŒTranSambaå¯ä»¥æ‰©å±•åˆ°å…¶ä»–3Dæ•°æ®åˆ†æä»»åŠ¡ï¼Œä¾‹å¦‚ä¸‰ç»´é‡å»ºå’Œé…å‡†ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Weakly supervised semantic segmentation offers a label-efficient solution to train segmentation models for volumetric medical imaging. However, existing approaches often rely on 2D encoders that neglect the inherent volumetric nature of the data. We propose TranSamba, a hybrid Transformer-Mamba architecture designed to capture 3D context for weakly supervised volumetric medical segmentation. TranSamba augments a standard Vision Transformer backbone with Cross-Plane Mamba blocks, which leverage the linear complexity of state space models for efficient information exchange across neighboring slices. The information exchange enhances the pairwise self-attention within slices computed by the Transformer blocks, directly contributing to the attention maps for object localization. TranSamba achieves effective volumetric modeling with time complexity that scales linearly with the input volume depth and maintains constant memory usage for batch processing. Extensive experiments on three datasets demonstrate that TranSamba establishes new state-of-the-art performance, consistently outperforming existing methods across diverse modalities and pathologies. Our source code and trained models are openly accessible at: https://github.com/YihengLyu/TranSamba.

