---
layout: default
title: "Point2Pose: A Generative Framework for 3D Human Pose Estimation with Multi-View Point Cloud Dataset"
---

# Point2Pose: A Generative Framework for 3D Human Pose Estimation with Multi-View Point Cloud Dataset

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.10321" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.10321v1</a>
  <a href="https://arxiv.org/pdf/2512.10321.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.10321v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.10321v1', 'Point2Pose: A Generative Framework for 3D Human Pose Estimation with Multi-View Point Cloud Dataset')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hyunsoo Lee, Daeum Jeon, Hyeokjae Oh

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-11

**å¤‡æ³¨**: WACV 2026 camera ready

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Point2Poseï¼šæå‡ºä¸€ç§åŸºäºå¤šè§†è§’ç‚¹äº‘æ•°æ®é›†çš„3Däººä½“å§¿æ€ä¼°è®¡ç”Ÿæˆæ¡†æ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `3Däººä½“å§¿æ€ä¼°è®¡` `ç”Ÿæˆæ¨¡å‹` `ç‚¹äº‘å¤„ç†` `æ³¨æ„åŠ›æœºåˆ¶` `æ—¶ç©ºå»ºæ¨¡` `å¤šè§†è§’æ•°æ®` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. 3Däººä½“å§¿æ€ä¼°è®¡é¢ä¸´äººä½“å‡ ä½•å¤æ‚ã€å…³èŠ‚è‡ªé®æŒ¡ä»¥åŠç¼ºä¹å¤§è§„æ¨¡çœŸå®è¿åŠ¨æ•°æ®é›†ç­‰æŒ‘æˆ˜ã€‚
2. Point2Poseé€šè¿‡æ—¶ç©ºç‚¹äº‘ç¼–ç å™¨å’Œå§¿æ€ç‰¹å¾ç¼–ç å™¨æå–ç‰¹å¾ï¼Œå¹¶ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶çš„ç”Ÿæˆå¼å›å½’å™¨å»ºæ¨¡å§¿æ€åˆ†å¸ƒã€‚
3. æå‡ºçš„MVPose3Dæ•°æ®é›†åŒ…å«IMUæ•°æ®ã€å¤šè§†è§’ç‚¹äº‘å’ŒRGBå›¾åƒï¼Œå®éªŒç»“æœè¡¨æ˜è¯¥æ–¹æ³•ä¼˜äºç°æœ‰åŸºçº¿æ¨¡å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç”Ÿæˆå¼æ–¹æ³•ç”¨äº3Däººä½“å§¿æ€ä¼°è®¡ã€‚ç”±äºäººä½“å¤æ‚çš„å‡ ä½•ç»“æ„ã€å…³èŠ‚çš„è‡ªé®æŒ¡ä»¥åŠå¯¹å¤§è§„æ¨¡çœŸå®ä¸–ç•Œè¿åŠ¨æ•°æ®é›†çš„éœ€æ±‚ï¼Œ3Däººä½“å§¿æ€ä¼°è®¡é¢ä¸´ç€å‡ ä¸ªå…³é”®æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†Point2Poseï¼Œè¯¥æ¡†æ¶æœ‰æ•ˆåœ°å»ºæ¨¡äº†ä»¥è¿ç»­ç‚¹äº‘å’Œå§¿æ€å†å²ä¸ºæ¡ä»¶çš„äººä½“å§¿æ€åˆ†å¸ƒã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é‡‡ç”¨æ—¶ç©ºç‚¹äº‘ç¼–ç å™¨å’Œå§¿æ€ç‰¹å¾ç¼–ç å™¨æ¥æå–å…³èŠ‚ç›¸å…³çš„ç‰¹å¾ï¼Œç„¶åä½¿ç”¨åŸºäºæ³¨æ„åŠ›çš„ç”Ÿæˆå¼å›å½’å™¨ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå¤§è§„æ¨¡å®¤å†…æ•°æ®é›†MVPose3Dï¼Œå…¶ä¸­åŒ…å«å¤šç§æ¨¡æ€ï¼ŒåŒ…æ‹¬éå¹³å‡¡äººä½“è¿åŠ¨çš„IMUæ•°æ®ã€å¯†é›†çš„å¤šè§†è§’ç‚¹äº‘å’ŒRGBå›¾åƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œè¯æ˜äº†å…¶åœ¨å„ç§æ•°æ®é›†ä¸Šçš„å“è¶Šæ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³3Däººä½“å§¿æ€ä¼°è®¡é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥å¤„ç†äººä½“å¤æ‚çš„å‡ ä½•ç»“æ„ã€å…³èŠ‚è‡ªé®æŒ¡ä»¥åŠç¼ºä¹å¤§è§„æ¨¡çœŸå®ä¸–ç•Œè¿åŠ¨æ•°æ®é›†çš„é—®é¢˜ã€‚è¿™äº›é—®é¢˜å¯¼è‡´å§¿æ€ä¼°è®¡ç²¾åº¦ä¸é«˜ï¼Œé²æ£’æ€§è¾ƒå·®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨ç”Ÿæˆæ¨¡å‹ï¼Œå°†3Däººä½“å§¿æ€ä¼°è®¡é—®é¢˜è½¬åŒ–ä¸ºä¸€ä¸ªæ¡ä»¶ç”Ÿæˆé—®é¢˜ã€‚é€šè¿‡å»ºæ¨¡ä»¥è¿ç»­ç‚¹äº‘å’Œå§¿æ€å†å²ä¸ºæ¡ä»¶çš„äººä½“å§¿æ€åˆ†å¸ƒï¼Œå¯ä»¥æ›´å¥½åœ°åˆ©ç”¨æ—¶ç©ºä¿¡æ¯ï¼Œä»è€Œæé«˜å§¿æ€ä¼°è®¡çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPoint2Poseæ¡†æ¶ä¸»è¦åŒ…å«ä¸‰ä¸ªæ¨¡å—ï¼šæ—¶ç©ºç‚¹äº‘ç¼–ç å™¨ã€å§¿æ€ç‰¹å¾ç¼–ç å™¨å’ŒåŸºäºæ³¨æ„åŠ›çš„ç”Ÿæˆå¼å›å½’å™¨ã€‚é¦–å…ˆï¼Œæ—¶ç©ºç‚¹äº‘ç¼–ç å™¨ç”¨äºæå–ç‚¹äº‘åºåˆ—ä¸­çš„æ—¶ç©ºç‰¹å¾ï¼›ç„¶åï¼Œå§¿æ€ç‰¹å¾ç¼–ç å™¨ç”¨äºæå–å†å²å§¿æ€çš„ç‰¹å¾ï¼›æœ€åï¼ŒåŸºäºæ³¨æ„åŠ›çš„ç”Ÿæˆå¼å›å½’å™¨å°†æå–çš„ç‰¹å¾èåˆï¼Œå¹¶ç”Ÿæˆå½“å‰æ—¶åˆ»çš„3Däººä½“å§¿æ€ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•çš„ä¸»è¦åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ä¸ªåŸºäºç”Ÿæˆæ¨¡å‹çš„3Däººä½“å§¿æ€ä¼°è®¡æ¡†æ¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°å»ºæ¨¡äººä½“å§¿æ€çš„åˆ†å¸ƒï¼Œå¹¶åˆ©ç”¨æ—¶ç©ºä¿¡æ¯æé«˜ä¼°è®¡ç²¾åº¦ã€‚æ­¤å¤–ï¼Œæå‡ºçš„æ³¨æ„åŠ›æœºåˆ¶èƒ½å¤Ÿæ›´å¥½åœ°å…³æ³¨å…³é”®å…³èŠ‚ï¼Œä»è€Œæé«˜ä¼°è®¡çš„é²æ£’æ€§ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†è‡ªé®æŒ¡å’Œå™ªå£°ç­‰é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šæ—¶ç©ºç‚¹äº‘ç¼–ç å™¨é‡‡ç”¨PointNet++ç½‘ç»œç»“æ„ï¼Œç”¨äºæå–ç‚¹äº‘ç‰¹å¾ã€‚å§¿æ€ç‰¹å¾ç¼–ç å™¨é‡‡ç”¨LSTMç½‘ç»œç»“æ„ï¼Œç”¨äºæå–å†å²å§¿æ€çš„æ—¶åºç‰¹å¾ã€‚æ³¨æ„åŠ›æœºåˆ¶é‡‡ç”¨Transformerç»“æ„ï¼Œç”¨äºèåˆç‚¹äº‘ç‰¹å¾å’Œå§¿æ€ç‰¹å¾ã€‚æŸå¤±å‡½æ•°é‡‡ç”¨å‡æ–¹è¯¯å·®æŸå¤±å‡½æ•°ï¼Œç”¨äºè¡¡é‡ä¼°è®¡å§¿æ€ä¸çœŸå®å§¿æ€ä¹‹é—´çš„å·®å¼‚ã€‚æ•°æ®é›†MVPose3DåŒ…å«å¤šç§æ¨¡æ€æ•°æ®ï¼Œä¸ºæ¨¡å‹çš„è®­ç»ƒæä¾›äº†ä¸°å¯Œçš„ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒPoint2Poseåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šä¼˜äºç°æœ‰çš„åŸºçº¿æ¨¡å‹ã€‚å°¤å…¶æ˜¯åœ¨MVPose3Dæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¯æ˜äº†å…¶åœ¨å¤„ç†å¤æ‚åœºæ™¯å’Œå¤šæ¨¡æ€æ•°æ®æ–¹é¢çš„ä¼˜åŠ¿ã€‚å…·ä½“æ€§èƒ½æ•°æ®æœªçŸ¥ï¼Œä½†è®ºæ–‡å¼ºè°ƒäº†ä¼˜äºåŸºçº¿æ¨¡å‹ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºäººæœºäº¤äº’ã€è™šæ‹Ÿç°å®ã€è¿åŠ¨åˆ†æã€æ™ºèƒ½ç›‘æ§ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨è™šæ‹Ÿç°å®ä¸­ï¼Œå¯ä»¥åˆ©ç”¨è¯¥æ–¹æ³•å®ç°æ›´è‡ªç„¶ã€æ›´é€¼çœŸçš„äººä½“å§¿æ€æ•æ‰ï¼›åœ¨è¿åŠ¨åˆ†æä¸­ï¼Œå¯ä»¥åˆ©ç”¨è¯¥æ–¹æ³•åˆ†æè¿åŠ¨å‘˜çš„åŠ¨ä½œï¼Œæé«˜è®­ç»ƒæ•ˆæœï¼›åœ¨æ™ºèƒ½ç›‘æ§ä¸­ï¼Œå¯ä»¥åˆ©ç”¨è¯¥æ–¹æ³•è¯†åˆ«å¼‚å¸¸è¡Œä¸ºï¼Œæé«˜å®‰å…¨æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We propose a novel generative approach for 3D human pose estimation. 3D human pose estimation poses several key challenges due to the complex geometry of the human body, self-occluding joints, and the requirement for large-scale real-world motion datasets. To address these challenges, we introduce Point2Pose, a framework that effectively models the distribution of human poses conditioned on sequential point cloud and pose history. Specifically, we employ a spatio-temporal point cloud encoder and a pose feature encoder to extract joint-wise features, followed by an attention-based generative regressor. Additionally, we present a large-scale indoor dataset MVPose3D, which contains multiple modalities, including IMU data of non-trivial human motions, dense multi-view point clouds, and RGB images. Experimental results show that the proposed method outperforms the baseline models, demonstrating its superior performance across various datasets.

