---
layout: default
title: Breaking the Vicious Cycle: Coherent 3D Gaussian Splatting from Sparse and Motion-Blurred Views
---

# Breaking the Vicious Cycle: Coherent 3D Gaussian Splatting from Sparse and Motion-Blurred Views

**arXiv**: [2512.10369v1](https://arxiv.org/abs/2512.10369) | [PDF](https://arxiv.org/pdf/2512.10369.pdf)

**ä½œè€…**: Zhankuo Xu, Chaoran Feng, Yingtao Li, Jianbin Zhao, Jiashu Yang, Wangbo Yu, Li Yuan, Yonghong Tian

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-11

**å¤‡æ³¨**: 20 pages, 14 figures

**ðŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://potatobigroom.github.io/CoherentGS/)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCoherentGSï¼Œè§£å†³ç¨€ç–å’Œè¿åŠ¨æ¨¡ç³Šè§†å›¾ä¸‹çš„é«˜ä¿çœŸ3Dé«˜æ–¯é‡å»ºé—®é¢˜**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `3Dé«˜æ–¯æº…å°„` `æ–°è§†è§’åˆæˆ` `ç¨€ç–è§†å›¾` `è¿åŠ¨æ¨¡ç³Š` `å›¾åƒåŽ»æ¨¡ç³Š` `æ‰©æ•£æ¨¡åž‹` `å‡ ä½•å…ˆéªŒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰3Dé«˜æ–¯æº…å°„æ–¹æ³•ä¾èµ–äºŽé«˜è´¨é‡å¯†é›†è§†å›¾ï¼Œåœ¨ç¨€ç–å’Œè¿åŠ¨æ¨¡ç³Šåœºæ™¯ä¸‹æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œå¯¼è‡´é‡å»ºå¤±è´¥ã€‚
2. CoherentGSé‡‡ç”¨åŒé‡å…ˆéªŒç­–ç•¥ï¼Œç»“åˆåŽ»æ¨¡ç³Šç½‘ç»œçš„å…‰åº¦æŒ‡å¯¼å’Œæ‰©æ•£æ¨¡åž‹çš„å‡ ä½•å…ˆéªŒï¼Œè§£å†³ç¨€ç–å’Œæ¨¡ç³Šå›¾åƒé‡å»ºé—®é¢˜ã€‚
3. å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒCoherentGSåœ¨ç¨€ç–å’Œæ¨¡ç³Šè§†å›¾ä¸‹æ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œå¹¶åœ¨åˆæˆå’ŒçœŸå®žåœºæ™¯ä¸­å–å¾—äº†æ–°çš„SOTAã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

3Dé«˜æ–¯æº…å°„(3DGS)å·²æˆä¸ºæ–°è§†è§’åˆæˆçš„æœ€å…ˆè¿›æ–¹æ³•ã€‚ç„¶è€Œï¼Œå…¶æ€§èƒ½ä¸¥é‡ä¾èµ–äºŽå¯†é›†çš„ã€é«˜è´¨é‡çš„è¾“å…¥å›¾åƒï¼Œè¿™ä¸€å‡è®¾åœ¨å®žé™…åº”ç”¨ä¸­é€šå¸¸ä¸æˆç«‹ï¼Œå› ä¸ºæ•°æ®é€šå¸¸æ˜¯ç¨€ç–ä¸”è¿åŠ¨æ¨¡ç³Šçš„ã€‚è¿™ä¸¤ä¸ªé—®é¢˜å½¢æˆäº†ä¸€ä¸ªæ¶æ€§å¾ªçŽ¯ï¼šç¨€ç–è§†å›¾å¿½ç•¥äº†è§£æžè¿åŠ¨æ¨¡ç³Šæ‰€éœ€çš„å¤šè§†å›¾çº¦æŸï¼Œè€Œè¿åŠ¨æ¨¡ç³Šåˆ™æ¶ˆé™¤äº†å¯¹é½æœ‰é™è§†å›¾è‡³å…³é‡è¦çš„é«˜é¢‘ç»†èŠ‚ã€‚å› æ­¤ï¼Œé‡å»ºå¸¸å¸¸ä»¥ç¾éš¾æ€§çš„æ–¹å¼å¤±è´¥ï¼Œå‡ºçŽ°ç¢Žç‰‡åŒ–çš„è§†å›¾å’Œä½Žé¢‘åå·®ã€‚ä¸ºäº†æ‰“ç ´è¿™ä¸ªå¾ªçŽ¯ï¼Œæˆ‘ä»¬å¼•å…¥äº†CoherentGSï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºŽä»Žç¨€ç–å’Œæ¨¡ç³Šå›¾åƒä¸­è¿›è¡Œé«˜ä¿çœŸ3Dé‡å»ºçš„æ–°æ¡†æž¶ã€‚æˆ‘ä»¬çš„å…³é”®è§è§£æ˜¯ä½¿ç”¨åŒé‡å…ˆéªŒç­–ç•¥æ¥è§£å†³è¿™äº›å¤åˆé€€åŒ–ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ç»“åˆäº†ä¸¤ä¸ªé¢„è®­ç»ƒçš„ç”Ÿæˆæ¨¡åž‹ï¼šä¸€ä¸ªä¸“é—¨çš„åŽ»æ¨¡ç³Šç½‘ç»œï¼Œç”¨äºŽæ¢å¤æ¸…æ™°çš„ç»†èŠ‚å¹¶æä¾›å…‰åº¦æŒ‡å¯¼ï¼Œä»¥åŠä¸€ä¸ªæ‰©æ•£æ¨¡åž‹ï¼Œæä¾›å‡ ä½•å…ˆéªŒæ¥å¡«å……åœºæ™¯ä¸­æœªè§‚å¯Ÿåˆ°çš„åŒºåŸŸã€‚è¿™ç§åŒé‡å…ˆéªŒç­–ç•¥å¾—åˆ°äº†å‡ ä¸ªå…³é”®æŠ€æœ¯çš„æ”¯æŒï¼ŒåŒ…æ‹¬ä¸€ä¸ªä¸€è‡´æ€§å¼•å¯¼çš„ç›¸æœºæŽ¢ç´¢æ¨¡å—ï¼Œè¯¥æ¨¡å—è‡ªé€‚åº”åœ°å¼•å¯¼ç”Ÿæˆè¿‡ç¨‹ï¼Œä»¥åŠä¸€ä¸ªæ·±åº¦æ­£åˆ™åŒ–æŸå¤±ï¼Œç¡®ä¿äº†å‡ ä½•åˆç†æ€§ã€‚æˆ‘ä»¬é€šè¿‡åœ¨åˆæˆå’ŒçœŸå®žåœºæ™¯ä¸Šçš„å®šé‡å’Œå®šæ€§å®žéªŒè¯„ä¼°äº†CoherentGSï¼Œä½¿ç”¨äº†å°‘è‡³3ã€6å’Œ9ä¸ªè¾“å…¥è§†å›¾ã€‚æˆ‘ä»¬çš„ç»“æžœè¡¨æ˜Žï¼ŒCoherentGSæ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œä¸ºè¿™é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡è®¾å®šäº†æ–°çš„æœ€å…ˆè¿›æ°´å¹³ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ä»Žç¨€ç–ä¸”å…·æœ‰è¿åŠ¨æ¨¡ç³Šçš„å›¾åƒä¸­è¿›è¡Œé«˜è´¨é‡3Dé‡å»ºçš„é—®é¢˜ã€‚çŽ°æœ‰çš„3Dé«˜æ–¯æº…å°„æ–¹æ³•åœ¨å¤„ç†æ­¤ç±»æ•°æ®æ—¶ä¼šé‡åˆ°å›°éš¾ï¼Œå› ä¸ºç¨€ç–è§†å›¾æ— æ³•æä¾›è¶³å¤Ÿçš„å¤šè§†è§’çº¦æŸæ¥è§£å†³è¿åŠ¨æ¨¡ç³Šï¼Œè€Œè¿åŠ¨æ¨¡ç³Šåˆä¼šæ¶ˆé™¤å¯¹é½è§†å›¾æ‰€éœ€çš„é«˜é¢‘ç»†èŠ‚ï¼Œå¯¼è‡´é‡å»ºè´¨é‡ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨åŒé‡å…ˆéªŒæ¥è§£å†³ç¨€ç–æ€§å’Œè¿åŠ¨æ¨¡ç³Šå¸¦æ¥çš„é—®é¢˜ã€‚å…·ä½“æ¥è¯´ï¼Œè®ºæ–‡ç»“åˆäº†å›¾åƒåŽ»æ¨¡ç³Šçš„å…ˆéªŒçŸ¥è¯†å’Œåœºæ™¯å‡ ä½•ç»“æž„çš„å…ˆéªŒçŸ¥è¯†ï¼Œä»Žè€Œåœ¨ä¿¡æ¯ä¸è¶³çš„æƒ…å†µä¸‹ä¹Ÿèƒ½è¿›è¡Œæœ‰æ•ˆçš„3Dé‡å»ºã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå¯ä»¥æ‰“ç ´ç¨€ç–è§†å›¾å’Œè¿åŠ¨æ¨¡ç³Šä¹‹é—´çš„æ¶æ€§å¾ªçŽ¯ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šCoherentGSæ¡†æž¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) ä¸€ä¸ªé¢„è®­ç»ƒçš„åŽ»æ¨¡ç³Šç½‘ç»œï¼Œç”¨äºŽæ¢å¤å›¾åƒçš„æ¸…æ™°ç»†èŠ‚ï¼›2) ä¸€ä¸ªé¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡åž‹ï¼Œç”¨äºŽæä¾›åœºæ™¯çš„å‡ ä½•å…ˆéªŒï¼›3) ä¸€ä¸ªä¸€è‡´æ€§å¼•å¯¼çš„ç›¸æœºæŽ¢ç´¢æ¨¡å—ï¼Œç”¨äºŽè‡ªé€‚åº”åœ°å¼•å¯¼ç”Ÿæˆè¿‡ç¨‹ï¼›4) ä¸€ä¸ªæ·±åº¦æ­£åˆ™åŒ–æŸå¤±ï¼Œç”¨äºŽç¡®ä¿é‡å»ºç»“æžœçš„å‡ ä½•åˆç†æ€§ã€‚æ•´ä½“æµç¨‹æ˜¯é¦–å…ˆåˆ©ç”¨åŽ»æ¨¡ç³Šç½‘ç»œå¯¹è¾“å…¥å›¾åƒè¿›è¡Œå¤„ç†ï¼Œç„¶åŽç»“åˆæ‰©æ•£æ¨¡åž‹çš„å…ˆéªŒçŸ¥è¯†å’Œç›¸æœºæŽ¢ç´¢æ¨¡å—çš„å¼•å¯¼ï¼Œé€æ­¥ä¼˜åŒ–3Dé«˜æ–¯å‚æ•°ï¼Œæœ€åŽé€šè¿‡æ·±åº¦æ­£åˆ™åŒ–æŸå¤±æ¥çº¦æŸé‡å»ºç»“æžœã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡æœ€å…³é”®çš„åˆ›æ–°åœ¨äºŽæå‡ºäº†åŒé‡å…ˆéªŒç­–ç•¥ï¼Œå³å°†å›¾åƒåŽ»æ¨¡ç³Šçš„å…ˆéªŒçŸ¥è¯†å’Œåœºæ™¯å‡ ä½•ç»“æž„çš„å…ˆéªŒçŸ¥è¯†ç›¸ç»“åˆï¼Œç”¨äºŽè§£å†³ç¨€ç–å’Œè¿åŠ¨æ¨¡ç³Šå›¾åƒçš„3Dé‡å»ºé—®é¢˜ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨æœ‰é™çš„ä¿¡æ¯ï¼Œä»Žè€ŒèŽ·å¾—æ›´é«˜è´¨é‡çš„é‡å»ºç»“æžœã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œè®ºæ–‡é‡‡ç”¨äº†é¢„è®­ç»ƒçš„åŽ»æ¨¡ç³Šç½‘ç»œå’Œæ‰©æ•£æ¨¡åž‹ï¼Œå¹¶è®¾è®¡äº†ä¸€è‡´æ€§å¼•å¯¼çš„ç›¸æœºæŽ¢ç´¢æ¨¡å—å’Œæ·±åº¦æ­£åˆ™åŒ–æŸå¤±ã€‚ç›¸æœºæŽ¢ç´¢æ¨¡å—é€šè¿‡è¯„ä¼°ä¸åŒè§†è§’ä¸‹çš„ä¸€è‡´æ€§æ¥é€‰æ‹©æœ€ä½³çš„ç›¸æœºä½å§¿ï¼Œä»Žè€Œæé«˜é‡å»ºçš„å‡†ç¡®æ€§ã€‚æ·±åº¦æ­£åˆ™åŒ–æŸå¤±åˆ™é€šè¿‡çº¦æŸé‡å»ºç»“æžœçš„æ·±åº¦å›¾ï¼Œç¡®ä¿å…¶å‡ ä½•åˆç†æ€§ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

CoherentGSåœ¨åˆæˆå’ŒçœŸå®žæ•°æ®é›†ä¸Šéƒ½å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚åœ¨ç¨€ç–è§†å›¾ï¼ˆ3ã€6ã€9ä¸ªè§†å›¾ï¼‰å’Œè¿åŠ¨æ¨¡ç³Šçš„æ¡ä»¶ä¸‹ï¼ŒCoherentGSæ˜Žæ˜¾ä¼˜äºŽçŽ°æœ‰çš„3Dé‡å»ºæ–¹æ³•ï¼Œåœ¨å®šé‡æŒ‡æ ‡å’Œè§†è§‰è´¨é‡ä¸Šéƒ½å–å¾—äº†SOTAç»“æžœã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒCoherentGSèƒ½å¤Ÿæœ‰æ•ˆåœ°è§£å†³ç¨€ç–æ€§å’Œè¿åŠ¨æ¨¡ç³Šå¸¦æ¥çš„æŒ‘æˆ˜ï¼Œå®žçŽ°é«˜ä¿çœŸåº¦çš„3Dé‡å»ºã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽæœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ã€è™šæ‹ŸçŽ°å®žã€å¢žå¼ºçŽ°å®žç­‰é¢†åŸŸã€‚åœ¨è¿™äº›åº”ç”¨ä¸­ï¼Œå¸¸å¸¸éœ€è¦åœ¨èµ„æºå—é™çš„çŽ¯å¢ƒä¸‹ï¼Œåˆ©ç”¨æœ‰é™ä¸”è´¨é‡ä¸é«˜çš„å›¾åƒæ•°æ®è¿›è¡Œ3Dåœºæ™¯é‡å»ºã€‚CoherentGSçš„å‡ºçŽ°ï¼Œä¸ºè¿™äº›åº”ç”¨æä¾›äº†ä¸€ç§æ›´å¯é ã€æ›´é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼Œå…·æœ‰é‡è¦çš„å®žé™…ä»·å€¼å’Œå¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> 3D Gaussian Splatting (3DGS) has emerged as a state-of-the-art method for novel view synthesis. However, its performance heavily relies on dense, high-quality input imagery, an assumption that is often violated in real-world applications, where data is typically sparse and motion-blurred. These two issues create a vicious cycle: sparse views ignore the multi-view constraints necessary to resolve motion blur, while motion blur erases high-frequency details crucial for aligning the limited views. Thus, reconstruction often fails catastrophically, with fragmented views and a low-frequency bias. To break this cycle, we introduce CoherentGS, a novel framework for high-fidelity 3D reconstruction from sparse and blurry images. Our key insight is to address these compound degradations using a dual-prior strategy. Specifically, we combine two pre-trained generative models: a specialized deblurring network for restoring sharp details and providing photometric guidance, and a diffusion model that offers geometric priors to fill in unobserved regions of the scene. This dual-prior strategy is supported by several key techniques, including a consistency-guided camera exploration module that adaptively guides the generative process, and a depth regularization loss that ensures geometric plausibility. We evaluate CoherentGS through both quantitative and qualitative experiments on synthetic and real-world scenes, using as few as 3, 6, and 9 input views. Our results demonstrate that CoherentGS significantly outperforms existing methods, setting a new state-of-the-art for this challenging task. The code and video demos are available at https://potatobigroom.github.io/CoherentGS/.

