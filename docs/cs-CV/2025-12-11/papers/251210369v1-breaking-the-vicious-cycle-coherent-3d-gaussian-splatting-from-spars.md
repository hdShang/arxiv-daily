---
layout: default
title: Breaking the Vicious Cycle: Coherent 3D Gaussian Splatting from Sparse and Motion-Blurred Views
---

# Breaking the Vicious Cycle: Coherent 3D Gaussian Splatting from Sparse and Motion-Blurred Views

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.10369" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.10369v1</a>
  <a href="https://arxiv.org/pdf/2512.10369.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.10369v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.10369v1', 'Breaking the Vicious Cycle: Coherent 3D Gaussian Splatting from Sparse and Motion-Blurred Views')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhankuo Xu, Chaoran Feng, Yingtao Li, Jianbin Zhao, Jiashu Yang, Wangbo Yu, Li Yuan, Yonghong Tian

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-11

**å¤‡æ³¨**: 20 pages, 14 figures

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://potatobigroom.github.io/CoherentGS/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCoherentGSï¼Œè§£å†³ç¨€ç–å’Œè¿åŠ¨æ¨¡ç³Šè§†å›¾ä¸‹çš„é«˜ä¿çœŸ3Dé«˜æ–¯é‡å»ºé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `3Dé«˜æ–¯æº…å°„` `æ–°è§†è§’åˆæˆ` `ç¨€ç–è§†å›¾` `è¿åŠ¨æ¨¡ç³Š` `å›¾åƒå»æ¨¡ç³Š` `æ‰©æ•£æ¨¡å‹` `å‡ ä½•å…ˆéªŒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰3Dé«˜æ–¯æº…å°„æ–¹æ³•ä¾èµ–äºé«˜è´¨é‡å¯†é›†è§†å›¾ï¼Œåœ¨ç¨€ç–å’Œè¿åŠ¨æ¨¡ç³Šåœºæ™¯ä¸‹æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œå¯¼è‡´é‡å»ºå¤±è´¥ã€‚
2. CoherentGSé‡‡ç”¨åŒé‡å…ˆéªŒç­–ç•¥ï¼Œç»“åˆå»æ¨¡ç³Šç½‘ç»œçš„å…‰åº¦æŒ‡å¯¼å’Œæ‰©æ•£æ¨¡å‹çš„å‡ ä½•å…ˆéªŒï¼Œè§£å†³ç¨€ç–å’Œæ¨¡ç³Šå›¾åƒé‡å»ºé—®é¢˜ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒCoherentGSåœ¨ç¨€ç–å’Œæ¨¡ç³Šè§†å›¾ä¸‹æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶åœ¨åˆæˆå’ŒçœŸå®åœºæ™¯ä¸­å–å¾—äº†æ–°çš„SOTAã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

3Dé«˜æ–¯æº…å°„(3DGS)å·²æˆä¸ºæ–°è§†è§’åˆæˆçš„æœ€å…ˆè¿›æ–¹æ³•ã€‚ç„¶è€Œï¼Œå…¶æ€§èƒ½ä¸¥é‡ä¾èµ–äºå¯†é›†çš„ã€é«˜è´¨é‡çš„è¾“å…¥å›¾åƒï¼Œè¿™ä¸€å‡è®¾åœ¨å®é™…åº”ç”¨ä¸­é€šå¸¸ä¸æˆç«‹ï¼Œå› ä¸ºæ•°æ®é€šå¸¸æ˜¯ç¨€ç–ä¸”è¿åŠ¨æ¨¡ç³Šçš„ã€‚è¿™ä¸¤ä¸ªé—®é¢˜å½¢æˆäº†ä¸€ä¸ªæ¶æ€§å¾ªç¯ï¼šç¨€ç–è§†å›¾å¿½ç•¥äº†è§£æè¿åŠ¨æ¨¡ç³Šæ‰€éœ€çš„å¤šè§†å›¾çº¦æŸï¼Œè€Œè¿åŠ¨æ¨¡ç³Šåˆ™æ¶ˆé™¤äº†å¯¹é½æœ‰é™è§†å›¾è‡³å…³é‡è¦çš„é«˜é¢‘ç»†èŠ‚ã€‚å› æ­¤ï¼Œé‡å»ºå¸¸å¸¸ä»¥ç¾éš¾æ€§çš„æ–¹å¼å¤±è´¥ï¼Œå‡ºç°ç¢ç‰‡åŒ–çš„è§†å›¾å’Œä½é¢‘åå·®ã€‚ä¸ºäº†æ‰“ç ´è¿™ä¸ªå¾ªç¯ï¼Œæˆ‘ä»¬å¼•å…¥äº†CoherentGSï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºä»ç¨€ç–å’Œæ¨¡ç³Šå›¾åƒä¸­è¿›è¡Œé«˜ä¿çœŸ3Dé‡å»ºçš„æ–°æ¡†æ¶ã€‚æˆ‘ä»¬çš„å…³é”®è§è§£æ˜¯ä½¿ç”¨åŒé‡å…ˆéªŒç­–ç•¥æ¥è§£å†³è¿™äº›å¤åˆé€€åŒ–ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ç»“åˆäº†ä¸¤ä¸ªé¢„è®­ç»ƒçš„ç”Ÿæˆæ¨¡å‹ï¼šä¸€ä¸ªä¸“é—¨çš„å»æ¨¡ç³Šç½‘ç»œï¼Œç”¨äºæ¢å¤æ¸…æ™°çš„ç»†èŠ‚å¹¶æä¾›å…‰åº¦æŒ‡å¯¼ï¼Œä»¥åŠä¸€ä¸ªæ‰©æ•£æ¨¡å‹ï¼Œæä¾›å‡ ä½•å…ˆéªŒæ¥å¡«å……åœºæ™¯ä¸­æœªè§‚å¯Ÿåˆ°çš„åŒºåŸŸã€‚è¿™ç§åŒé‡å…ˆéªŒç­–ç•¥å¾—åˆ°äº†å‡ ä¸ªå…³é”®æŠ€æœ¯çš„æ”¯æŒï¼ŒåŒ…æ‹¬ä¸€ä¸ªä¸€è‡´æ€§å¼•å¯¼çš„ç›¸æœºæ¢ç´¢æ¨¡å—ï¼Œè¯¥æ¨¡å—è‡ªé€‚åº”åœ°å¼•å¯¼ç”Ÿæˆè¿‡ç¨‹ï¼Œä»¥åŠä¸€ä¸ªæ·±åº¦æ­£åˆ™åŒ–æŸå¤±ï¼Œç¡®ä¿äº†å‡ ä½•åˆç†æ€§ã€‚æˆ‘ä»¬é€šè¿‡åœ¨åˆæˆå’ŒçœŸå®åœºæ™¯ä¸Šçš„å®šé‡å’Œå®šæ€§å®éªŒè¯„ä¼°äº†CoherentGSï¼Œä½¿ç”¨äº†å°‘è‡³3ã€6å’Œ9ä¸ªè¾“å…¥è§†å›¾ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼ŒCoherentGSæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸ºè¿™é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡è®¾å®šäº†æ–°çš„æœ€å…ˆè¿›æ°´å¹³ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ä»ç¨€ç–ä¸”å…·æœ‰è¿åŠ¨æ¨¡ç³Šçš„å›¾åƒä¸­è¿›è¡Œé«˜è´¨é‡3Dé‡å»ºçš„é—®é¢˜ã€‚ç°æœ‰çš„3Dé«˜æ–¯æº…å°„æ–¹æ³•åœ¨å¤„ç†æ­¤ç±»æ•°æ®æ—¶ä¼šé‡åˆ°å›°éš¾ï¼Œå› ä¸ºç¨€ç–è§†å›¾æ— æ³•æä¾›è¶³å¤Ÿçš„å¤šè§†è§’çº¦æŸæ¥è§£å†³è¿åŠ¨æ¨¡ç³Šï¼Œè€Œè¿åŠ¨æ¨¡ç³Šåˆä¼šæ¶ˆé™¤å¯¹é½è§†å›¾æ‰€éœ€çš„é«˜é¢‘ç»†èŠ‚ï¼Œå¯¼è‡´é‡å»ºè´¨é‡ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨åŒé‡å…ˆéªŒæ¥è§£å†³ç¨€ç–æ€§å’Œè¿åŠ¨æ¨¡ç³Šå¸¦æ¥çš„é—®é¢˜ã€‚å…·ä½“æ¥è¯´ï¼Œè®ºæ–‡ç»“åˆäº†å›¾åƒå»æ¨¡ç³Šçš„å…ˆéªŒçŸ¥è¯†å’Œåœºæ™¯å‡ ä½•ç»“æ„çš„å…ˆéªŒçŸ¥è¯†ï¼Œä»è€Œåœ¨ä¿¡æ¯ä¸è¶³çš„æƒ…å†µä¸‹ä¹Ÿèƒ½è¿›è¡Œæœ‰æ•ˆçš„3Dé‡å»ºã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå¯ä»¥æ‰“ç ´ç¨€ç–è§†å›¾å’Œè¿åŠ¨æ¨¡ç³Šä¹‹é—´çš„æ¶æ€§å¾ªç¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCoherentGSæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) ä¸€ä¸ªé¢„è®­ç»ƒçš„å»æ¨¡ç³Šç½‘ç»œï¼Œç”¨äºæ¢å¤å›¾åƒçš„æ¸…æ™°ç»†èŠ‚ï¼›2) ä¸€ä¸ªé¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ï¼Œç”¨äºæä¾›åœºæ™¯çš„å‡ ä½•å…ˆéªŒï¼›3) ä¸€ä¸ªä¸€è‡´æ€§å¼•å¯¼çš„ç›¸æœºæ¢ç´¢æ¨¡å—ï¼Œç”¨äºè‡ªé€‚åº”åœ°å¼•å¯¼ç”Ÿæˆè¿‡ç¨‹ï¼›4) ä¸€ä¸ªæ·±åº¦æ­£åˆ™åŒ–æŸå¤±ï¼Œç”¨äºç¡®ä¿é‡å»ºç»“æœçš„å‡ ä½•åˆç†æ€§ã€‚æ•´ä½“æµç¨‹æ˜¯é¦–å…ˆåˆ©ç”¨å»æ¨¡ç³Šç½‘ç»œå¯¹è¾“å…¥å›¾åƒè¿›è¡Œå¤„ç†ï¼Œç„¶åç»“åˆæ‰©æ•£æ¨¡å‹çš„å…ˆéªŒçŸ¥è¯†å’Œç›¸æœºæ¢ç´¢æ¨¡å—çš„å¼•å¯¼ï¼Œé€æ­¥ä¼˜åŒ–3Dé«˜æ–¯å‚æ•°ï¼Œæœ€åé€šè¿‡æ·±åº¦æ­£åˆ™åŒ–æŸå¤±æ¥çº¦æŸé‡å»ºç»“æœã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡æœ€å…³é”®çš„åˆ›æ–°åœ¨äºæå‡ºäº†åŒé‡å…ˆéªŒç­–ç•¥ï¼Œå³å°†å›¾åƒå»æ¨¡ç³Šçš„å…ˆéªŒçŸ¥è¯†å’Œåœºæ™¯å‡ ä½•ç»“æ„çš„å…ˆéªŒçŸ¥è¯†ç›¸ç»“åˆï¼Œç”¨äºè§£å†³ç¨€ç–å’Œè¿åŠ¨æ¨¡ç³Šå›¾åƒçš„3Dé‡å»ºé—®é¢˜ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨æœ‰é™çš„ä¿¡æ¯ï¼Œä»è€Œè·å¾—æ›´é«˜è´¨é‡çš„é‡å»ºç»“æœã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œè®ºæ–‡é‡‡ç”¨äº†é¢„è®­ç»ƒçš„å»æ¨¡ç³Šç½‘ç»œå’Œæ‰©æ•£æ¨¡å‹ï¼Œå¹¶è®¾è®¡äº†ä¸€è‡´æ€§å¼•å¯¼çš„ç›¸æœºæ¢ç´¢æ¨¡å—å’Œæ·±åº¦æ­£åˆ™åŒ–æŸå¤±ã€‚ç›¸æœºæ¢ç´¢æ¨¡å—é€šè¿‡è¯„ä¼°ä¸åŒè§†è§’ä¸‹çš„ä¸€è‡´æ€§æ¥é€‰æ‹©æœ€ä½³çš„ç›¸æœºä½å§¿ï¼Œä»è€Œæé«˜é‡å»ºçš„å‡†ç¡®æ€§ã€‚æ·±åº¦æ­£åˆ™åŒ–æŸå¤±åˆ™é€šè¿‡çº¦æŸé‡å»ºç»“æœçš„æ·±åº¦å›¾ï¼Œç¡®ä¿å…¶å‡ ä½•åˆç†æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

CoherentGSåœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šéƒ½å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚åœ¨ç¨€ç–è§†å›¾ï¼ˆ3ã€6ã€9ä¸ªè§†å›¾ï¼‰å’Œè¿åŠ¨æ¨¡ç³Šçš„æ¡ä»¶ä¸‹ï¼ŒCoherentGSæ˜æ˜¾ä¼˜äºç°æœ‰çš„3Dé‡å»ºæ–¹æ³•ï¼Œåœ¨å®šé‡æŒ‡æ ‡å’Œè§†è§‰è´¨é‡ä¸Šéƒ½å–å¾—äº†SOTAç»“æœã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCoherentGSèƒ½å¤Ÿæœ‰æ•ˆåœ°è§£å†³ç¨€ç–æ€§å’Œè¿åŠ¨æ¨¡ç³Šå¸¦æ¥çš„æŒ‘æˆ˜ï¼Œå®ç°é«˜ä¿çœŸåº¦çš„3Dé‡å»ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ã€è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ç­‰é¢†åŸŸã€‚åœ¨è¿™äº›åº”ç”¨ä¸­ï¼Œå¸¸å¸¸éœ€è¦åœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸‹ï¼Œåˆ©ç”¨æœ‰é™ä¸”è´¨é‡ä¸é«˜çš„å›¾åƒæ•°æ®è¿›è¡Œ3Dåœºæ™¯é‡å»ºã€‚CoherentGSçš„å‡ºç°ï¼Œä¸ºè¿™äº›åº”ç”¨æä¾›äº†ä¸€ç§æ›´å¯é ã€æ›´é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> 3D Gaussian Splatting (3DGS) has emerged as a state-of-the-art method for novel view synthesis. However, its performance heavily relies on dense, high-quality input imagery, an assumption that is often violated in real-world applications, where data is typically sparse and motion-blurred. These two issues create a vicious cycle: sparse views ignore the multi-view constraints necessary to resolve motion blur, while motion blur erases high-frequency details crucial for aligning the limited views. Thus, reconstruction often fails catastrophically, with fragmented views and a low-frequency bias. To break this cycle, we introduce CoherentGS, a novel framework for high-fidelity 3D reconstruction from sparse and blurry images. Our key insight is to address these compound degradations using a dual-prior strategy. Specifically, we combine two pre-trained generative models: a specialized deblurring network for restoring sharp details and providing photometric guidance, and a diffusion model that offers geometric priors to fill in unobserved regions of the scene. This dual-prior strategy is supported by several key techniques, including a consistency-guided camera exploration module that adaptively guides the generative process, and a depth regularization loss that ensures geometric plausibility. We evaluate CoherentGS through both quantitative and qualitative experiments on synthetic and real-world scenes, using as few as 3, 6, and 9 input views. Our results demonstrate that CoherentGS significantly outperforms existing methods, setting a new state-of-the-art for this challenging task. The code and video demos are available at https://potatobigroom.github.io/CoherentGS/.

