---
layout: default
title: Latent Chain-of-Thought World Modeling for End-to-End Driving
---

# Latent Chain-of-Thought World Modeling for End-to-End Driving

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.10226" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.10226v1</a>
  <a href="https://arxiv.org/pdf/2512.10226.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.10226v1" onclick="toggleFavorite(this, '2512.10226v1', 'Latent Chain-of-Thought World Modeling for End-to-End Driving')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shuhan Tan, Kashyap Chitta, Yuxiao Chen, Ran Tian, Yurong You, Yan Wang, Wenjie Luo, Yulong Cao, Philipp Krahenbuhl, Marco Pavone, Boris Ivanovic

**åˆ†ç±»**: cs.CV, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-12-11

**å¤‡æ³¨**: Technical Report

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLatent-CoT-Driveï¼Œåˆ©ç”¨éšç©ºé—´æ€ç»´é“¾è¿›è¡Œç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶å†³ç­–ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è‡ªåŠ¨é©¾é©¶` `æ€ç»´é“¾` `éšç©ºé—´` `ä¸–ç•Œæ¨¡å‹` `ç«¯åˆ°ç«¯å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰VLAè‡ªåŠ¨é©¾é©¶æ¨¡å‹ä¾èµ–è‡ªç„¶è¯­è¨€è¿›è¡Œæ€ç»´é“¾æ¨ç†ï¼Œä½†æ–‡æœ¬å¹¶éæœ€é«˜æ•ˆçš„æ¨ç†è¡¨ç¤ºã€‚
2. LCDriveåœ¨éšç©ºé—´ä¸­è¿›è¡Œæ€ç»´é“¾æ¨ç†ï¼Œäº¤æ›¿ä½¿ç”¨åŠ¨ä½œæè®®å’Œä¸–ç•Œæ¨¡å‹tokensï¼Œç»Ÿä¸€æ¨ç†å’Œå†³ç­–ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒLCDriveåœ¨æ¨ç†é€Ÿåº¦ã€è½¨è¿¹è´¨é‡å’Œå¼ºåŒ–å­¦ä¹ æå‡æ–¹é¢ä¼˜äºæ–‡æœ¬æ¨ç†å’Œæ— æ¨ç†åŸºçº¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºLatent-CoT-Drive (LCDrive) çš„æ¨¡å‹ï¼Œç”¨äºç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶ã€‚è¯¥æ¨¡å‹ä½¿ç”¨éšç©ºé—´ä¸­çš„æ€ç»´é“¾ (CoT) æ¥æå‡é©¾é©¶æ€§èƒ½å’Œå®‰å…¨æ€§ã€‚ä¸ä»¥å¾€ä½¿ç”¨è‡ªç„¶è¯­è¨€è¿›è¡ŒCoTæ¨ç†çš„æ–¹æ³•ä¸åŒï¼ŒLCDrive ä½¿ç”¨ä¸€ç§éšå¼è¯­è¨€ï¼Œè¯¥è¯­è¨€èƒ½å¤Ÿæ•æ‰æ‰€è€ƒè™‘çš„é©¾é©¶è¡Œä¸ºçš„å¯èƒ½ç»“æœã€‚é€šè¿‡åœ¨ä¸åŠ¨ä½œå¯¹é½çš„éšç©ºé—´ä¸­è¡¨ç¤º CoT æ¨ç†å’Œå†³ç­–ï¼ŒLCDrive ç»Ÿä¸€äº†è¿™ä¸¤è€…ã€‚æ¨¡å‹é€šè¿‡äº¤æ›¿ä½¿ç”¨åŠ¨ä½œæè®® tokensï¼ˆä¸æ¨¡å‹è¾“å‡ºåŠ¨ä½œä½¿ç”¨ç›¸åŒçš„è¯æ±‡è¡¨ï¼‰å’Œä¸–ç•Œæ¨¡å‹ tokensï¼ˆåŸºäºå­¦ä¹ åˆ°çš„éšå¼ä¸–ç•Œæ¨¡å‹ï¼Œè¡¨è¾¾è¿™äº›åŠ¨ä½œçš„æœªæ¥ç»“æœï¼‰æ¥è¿›è¡Œæ¨ç†ã€‚LCDrive é€šè¿‡ç›‘ç£æ¨¡å‹åŸºäºåœºæ™¯çš„çœŸå®æœªæ¥è½¨è¿¹ç”ŸæˆåŠ¨ä½œæè®®å’Œä¸–ç•Œæ¨¡å‹ tokens æ¥è¿›è¡Œå†·å¯åŠ¨ï¼Œç„¶åé€šè¿‡é—­ç¯å¼ºåŒ–å­¦ä¹ è¿›è¡Œåè®­ç»ƒï¼Œä»¥å¢å¼ºæ¨ç†èƒ½åŠ›ã€‚åœ¨å¤§å‹ç«¯åˆ°ç«¯é©¾é©¶åŸºå‡†æµ‹è¯•ä¸­ï¼ŒLCDrive ç›¸æ¯”äºæ— æ¨ç†å’Œæ–‡æœ¬æ¨ç†çš„åŸºçº¿æ¨¡å‹ï¼Œå®ç°äº†æ›´å¿«çš„æ¨ç†é€Ÿåº¦ã€æ›´å¥½çš„è½¨è¿¹è´¨é‡ï¼Œä»¥åŠæ›´å¤§çš„äº¤äº’å¼å¼ºåŒ–å­¦ä¹ å¸¦æ¥çš„æ€§èƒ½æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯é‚£äº›åŸºäºVision-Language-Action (VLA) çš„æ¨¡å‹ï¼Œé€šå¸¸ä½¿ç”¨è‡ªç„¶è¯­è¨€æ¥è¡¨è¾¾æ€ç»´é“¾ (Chain-of-Thought, CoT) æ¨ç†è¿‡ç¨‹ã€‚ç„¶è€Œï¼Œè‡ªç„¶è¯­è¨€å¯èƒ½ä¸æ˜¯è¡¨ç¤ºæ¨ç†è¿‡ç¨‹çš„æœ€æœ‰æ•ˆæ–¹å¼ï¼Œå› ä¸ºå®ƒå¼•å…¥äº†é¢å¤–çš„å¤æ‚æ€§å’Œè®¡ç®—å¼€é”€ã€‚æ­¤å¤–ï¼Œè¯­è¨€çš„æ­§ä¹‰æ€§ä¹Ÿå¯èƒ½å¯¼è‡´æ¨¡å‹éš¾ä»¥å‡†ç¡®ç†è§£å’Œæ‰§è¡Œé©¾é©¶ä»»åŠ¡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šLCDrive çš„æ ¸å¿ƒæ€è·¯æ˜¯å°† CoT æ¨ç†è¿‡ç¨‹åµŒå…¥åˆ°ä¸€ä¸ªéšç©ºé—´ä¸­ï¼Œä½¿ç”¨ä¸€ç§éšå¼è¯­è¨€æ¥è¡¨ç¤ºã€‚è¿™ç§éšå¼è¯­è¨€ç”±åŠ¨ä½œæè®® tokens å’Œä¸–ç•Œæ¨¡å‹ tokens ç»„æˆï¼Œå‰è€…ä»£è¡¨æ¨¡å‹è€ƒè™‘çš„æ½œåœ¨é©¾é©¶åŠ¨ä½œï¼Œåè€…ä»£è¡¨è¿™äº›åŠ¨ä½œå¯èƒ½å¯¼è‡´çš„æœªæ¥ç»“æœã€‚é€šè¿‡åœ¨éšç©ºé—´ä¸­è¿›è¡Œæ¨ç†ï¼Œæ¨¡å‹å¯ä»¥é¿å…è‡ªç„¶è¯­è¨€å¸¦æ¥çš„é—®é¢˜ï¼Œå¹¶æ›´æœ‰æ•ˆåœ°è¿›è¡Œå†³ç­–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLCDrive çš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) æ„ŸçŸ¥æ¨¡å—ï¼šç”¨äºä»è¾“å…¥å›¾åƒä¸­æå–åœºæ™¯ç‰¹å¾ã€‚2) åŠ¨ä½œæè®®æ¨¡å—ï¼šæ ¹æ®åœºæ™¯ç‰¹å¾ï¼Œç”Ÿæˆä¸€ç³»åˆ—å¯èƒ½çš„é©¾é©¶åŠ¨ä½œæè®®ã€‚3) ä¸–ç•Œæ¨¡å‹æ¨¡å—ï¼šé¢„æµ‹æ¯ä¸ªåŠ¨ä½œæè®®å¯èƒ½å¯¼è‡´çš„æœªæ¥åœºæ™¯çŠ¶æ€ã€‚4) æ¨ç†æ¨¡å—ï¼šåœ¨éšç©ºé—´ä¸­ï¼Œäº¤æ›¿ä½¿ç”¨åŠ¨ä½œæè®® tokens å’Œä¸–ç•Œæ¨¡å‹ tokens è¿›è¡Œæ¨ç†ï¼Œç”Ÿæˆæœ€ç»ˆçš„é©¾é©¶åŠ¨ä½œã€‚5) å¼ºåŒ–å­¦ä¹ æ¨¡å—ï¼šä½¿ç”¨é—­ç¯å¼ºåŒ–å­¦ä¹ å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»¥è¿›ä¸€æ­¥æå‡å…¶æ¨ç†å’Œå†³ç­–èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šLCDrive æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºä½¿ç”¨éšç©ºé—´æ¥è¡¨ç¤º CoT æ¨ç†è¿‡ç¨‹ã€‚ä¸ä»¥å¾€ä½¿ç”¨è‡ªç„¶è¯­è¨€çš„æ–¹æ³•ç›¸æ¯”ï¼Œè¿™ç§æ–¹æ³•æ›´åŠ é«˜æ•ˆã€ç®€æ´ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰é©¾é©¶åœºæ™¯çš„å¤æ‚æ€§ã€‚æ­¤å¤–ï¼ŒLCDrive é€šè¿‡äº¤æ›¿ä½¿ç”¨åŠ¨ä½œæè®® tokens å’Œä¸–ç•Œæ¨¡å‹ tokensï¼Œå®ç°äº†æ¨ç†å’Œå†³ç­–çš„ç»Ÿä¸€ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£é©¾é©¶ä»»åŠ¡å¹¶åšå‡ºæ›´åˆç†çš„å†³ç­–ã€‚

**å…³é”®è®¾è®¡**ï¼šLCDrive çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) åŠ¨ä½œæè®® tokens å’Œä¸–ç•Œæ¨¡å‹ tokens çš„è¡¨ç¤ºæ–¹å¼ã€‚è®ºæ–‡ä½¿ç”¨ä¸æ¨¡å‹è¾“å‡ºåŠ¨ä½œç›¸åŒçš„è¯æ±‡è¡¨æ¥è¡¨ç¤ºåŠ¨ä½œæè®® tokensï¼Œå¹¶ä½¿ç”¨å­¦ä¹ åˆ°çš„éšå¼ä¸–ç•Œæ¨¡å‹æ¥è¡¨ç¤ºä¸–ç•Œæ¨¡å‹ tokensã€‚2) æŸå¤±å‡½æ•°çš„è®¾è®¡ã€‚è®ºæ–‡ä½¿ç”¨ç›‘ç£å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ç›¸ç»“åˆçš„æ–¹å¼æ¥è®­ç»ƒæ¨¡å‹ã€‚åœ¨ç›‘ç£å­¦ä¹ é˜¶æ®µï¼Œæ¨¡å‹é€šè¿‡æœ€å°åŒ–é¢„æµ‹åŠ¨ä½œå’ŒçœŸå®åŠ¨ä½œä¹‹é—´çš„å·®å¼‚æ¥å­¦ä¹ åŠ¨ä½œæè®®å’Œä¸–ç•Œæ¨¡å‹ tokens çš„è¡¨ç¤ºã€‚åœ¨å¼ºåŒ–å­¦ä¹ é˜¶æ®µï¼Œæ¨¡å‹é€šè¿‡æœ€å¤§åŒ–ç´¯ç§¯å¥–åŠ±æ¥æå‡å…¶æ¨ç†å’Œå†³ç­–èƒ½åŠ›ã€‚3) å¼ºåŒ–å­¦ä¹ ç®—æ³•çš„é€‰æ‹©ã€‚è®ºæ–‡ä½¿ç”¨äº†ä¸€ç§åŸºäºç­–ç•¥æ¢¯åº¦çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•æ¥è®­ç»ƒæ¨¡å‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

LCDrive åœ¨ä¸€ä¸ªå¤§å‹ç«¯åˆ°ç«¯é©¾é©¶åŸºå‡†æµ‹è¯•ä¸­è¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜ï¼Œä¸æ— æ¨ç†å’Œæ–‡æœ¬æ¨ç†çš„åŸºçº¿æ¨¡å‹ç›¸æ¯”ï¼ŒLCDrive å®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å…·ä½“æ¥è¯´ï¼ŒLCDrive å®ç°äº†æ›´å¿«çš„æ¨ç†é€Ÿåº¦ã€æ›´å¥½çš„è½¨è¿¹è´¨é‡ï¼Œä»¥åŠæ›´å¤§çš„äº¤äº’å¼å¼ºåŒ–å­¦ä¹ å¸¦æ¥çš„æ€§èƒ½æå‡ã€‚ä¾‹å¦‚ï¼ŒLCDrive åœ¨è½¨è¿¹è´¨é‡æ–¹é¢æ¯”æœ€ä½³åŸºçº¿æé«˜äº†çº¦10%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

LCDrive çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªåŠ¨é©¾é©¶æ±½è½¦ã€é«˜çº§é©¾é©¶è¾…åŠ©ç³»ç»Ÿ (ADAS) ä»¥åŠæœºå™¨äººå¯¼èˆªç­‰ã€‚è¯¥ç ”ç©¶çš„å®é™…ä»·å€¼åœ¨äºæé«˜è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„å®‰å…¨æ€§ã€å¯é æ€§å’Œæ•ˆç‡ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºæ›´å¤æ‚çš„é©¾é©¶åœºæ™¯ï¼Œä¾‹å¦‚åŸå¸‚é“è·¯å’Œé«˜é€Ÿå…¬è·¯ï¼Œå¹¶æœ€ç»ˆå®ç°å®Œå…¨è‡ªåŠ¨é©¾é©¶ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent Vision-Language-Action (VLA) models for autonomous driving explore inference-time reasoning as a way to improve driving performance and safety in challenging scenarios. Most prior work uses natural language to express chain-of-thought (CoT) reasoning before producing driving actions. However, text may not be the most efficient representation for reasoning. In this work, we present Latent-CoT-Drive (LCDrive): a model that expresses CoT in a latent language that captures possible outcomes of the driving actions being considered. Our approach unifies CoT reasoning and decision making by representing both in an action-aligned latent space. Instead of natural language, the model reasons by interleaving (1) action-proposal tokens, which use the same vocabulary as the model's output actions; and (2) world model tokens, which are grounded in a learned latent world model and express future outcomes of these actions. We cold start latent CoT by supervising the model's action proposals and world model tokens based on ground-truth future rollouts of the scene. We then post-train with closed-loop reinforcement learning to strengthen reasoning capabilities. On a large-scale end-to-end driving benchmark, LCDrive achieves faster inference, better trajectory quality, and larger improvements from interactive reinforcement learning compared to both non-reasoning and text-reasoning baselines.

