---
layout: default
title: OmniView: An All-Seeing Diffusion Model for 3D and 4D View Synthesis
---

# OmniView: An All-Seeing Diffusion Model for 3D and 4D View Synthesis

**arXiv**: [2512.10940v1](https://arxiv.org/abs/2512.10940) | [PDF](https://arxiv.org/pdf/2512.10940.pdf)

**ä½œè€…**: Xiang Fan, Sharath Girish, Vivek Ramanujan, Chaoyang Wang, Ashkan Mirzaei, Petr Sushko, Aliaksandr Siarohin, Sergey Tulyakov, Ranjay Krishna

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-11

**å¤‡æ³¨**: Project page: https://snap-research.github.io/OmniView/

**ðŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://snap-research.github.io/OmniView/)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**OmniViewï¼šç”¨äºŽ3Då’Œ4Dè§†å›¾åˆæˆçš„ç»Ÿä¸€æ‰©æ•£æ¨¡åž‹**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `æ‰©æ•£æ¨¡åž‹` `4Dè§†å›¾åˆæˆ` `æ–°è§†è§’åˆæˆ` `è§†é¢‘ç”Ÿæˆ` `ç›¸æœºæŽ§åˆ¶` `æ¡ä»¶ç”Ÿæˆ` `å¤šè§†å›¾å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•åœ¨4Dä¸€è‡´æ€§ä»»åŠ¡ä¸Šåˆ†æ•£ï¼Œç¼ºä¹ç»Ÿä¸€çš„è®­ç»ƒæ¡†æž¶ï¼Œå¯¼è‡´æ•°æ®åˆ©ç”¨çŽ‡ä½Žã€‚
2. OmniViewé€šè¿‡åˆ†ç¦»ç©ºé—´ã€æ—¶é—´å’Œè§†å›¾æ¡ä»¶ï¼Œå®žçŽ°å¯¹å„ç§4Dä»»åŠ¡çš„çµæ´»ç»„åˆå’Œæ³›åŒ–ã€‚
3. OmniViewåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¶…è¶Šç‰¹å®šä»»åŠ¡æ¨¡åž‹ï¼Œæ˜¾è‘—æå‡å›¾åƒè´¨é‡å’Œç›¸æœºæŽ§åˆ¶ç²¾åº¦ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

çŽ°æœ‰æ–¹æ³•å°†ç›¸æœºæŽ§åˆ¶èžå…¥æ‰©æ•£æ¨¡åž‹ï¼Œä½†å¾€å¾€ä¸“æ³¨äºŽ4Dä¸€è‡´æ€§ä»»åŠ¡çš„ç‰¹å®šå­é›†ï¼Œä¾‹å¦‚æ–°è§†è§’åˆæˆã€å¸¦ç›¸æœºæŽ§åˆ¶çš„æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆã€å›¾åƒåˆ°è§†é¢‘ç”Ÿæˆç­‰ã€‚è¿™äº›æ–¹æ³•åœ¨å¯ç”¨çš„3D/4Dæ•°æ®çš„ä¸ç›¸äº¤åˆ‡ç‰‡ä¸Šè¿›è¡Œè®­ç»ƒã€‚æœ¬æ–‡æå‡ºäº†OmniViewï¼Œä¸€ä¸ªç»Ÿä¸€çš„æ¡†æž¶ï¼Œå¯ä»¥æŽ¨å¹¿åˆ°å„ç§4Dä¸€è‡´æ€§ä»»åŠ¡ã€‚è¯¥æ–¹æ³•åˆ†åˆ«è¡¨ç¤ºç©ºé—´ã€æ—¶é—´å’Œè§†å›¾æ¡ä»¶ï¼Œä»Žè€Œèƒ½å¤Ÿçµæ´»åœ°ç»„åˆè¿™äº›è¾“å…¥ã€‚ä¾‹å¦‚ï¼ŒOmniViewå¯ä»¥ä»Žé™æ€ã€åŠ¨æ€å’Œå¤šè§†å›¾è¾“å…¥ä¸­åˆæˆæ–°è§†è§’ï¼Œåœ¨æ—¶é—´ä¸Šå‘å‰å’Œå‘åŽæŽ¨æ–­è½¨è¿¹ï¼Œå¹¶ä»Žæ–‡æœ¬æˆ–å›¾åƒæç¤ºåˆ›å»ºå…·æœ‰å®Œå…¨ç›¸æœºæŽ§åˆ¶çš„è§†é¢‘ã€‚OmniViewåœ¨ä¸åŒçš„åŸºå‡†å’ŒæŒ‡æ ‡ä¸Šä¸Žç‰¹å®šä»»åŠ¡æ¨¡åž‹ç›¸æ¯”å…·æœ‰ç«žäº‰åŠ›ï¼Œåœ¨å¤šè§†å›¾NVS LLFFæ•°æ®é›†ä¸­ï¼Œç›¸æœºæ¡ä»¶æ‰©æ•£æ¨¡åž‹çš„å›¾åƒè´¨é‡å¾—åˆ†æé«˜äº†33%ï¼Œåœ¨åŠ¨æ€NVS Neural 3D VideoåŸºå‡†ä¸­æé«˜äº†60%ï¼Œåœ¨RE-10Kä¸Šçš„é™æ€ç›¸æœºæŽ§åˆ¶æé«˜äº†20%ï¼Œåœ¨æ–‡æœ¬æ¡ä»¶è§†é¢‘ç”Ÿæˆä¸­ï¼Œç›¸æœºè½¨è¿¹è¯¯å·®é™ä½Žäº†4å€ã€‚å‡­å€Ÿåœ¨ä¸€ä¸ªæ¨¡åž‹ä¸­çš„å¼ºå¤§æ³›åŒ–èƒ½åŠ›ï¼ŒOmniViewå±•ç¤ºäº†é€šç”¨4Dè§†é¢‘æ¨¡åž‹çš„å¯è¡Œæ€§ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰æ–¹æ³•é’ˆå¯¹ä¸åŒçš„4Dä¸€è‡´æ€§ä»»åŠ¡ï¼ˆå¦‚æ–°è§†è§’åˆæˆã€æ–‡æœ¬åˆ°è§†é¢‘ç­‰ï¼‰è®¾è®¡ç‹¬ç«‹çš„æ¨¡åž‹ï¼Œå¯¼è‡´æ¨¡åž‹ç¢Žç‰‡åŒ–ï¼Œæ— æ³•å……åˆ†åˆ©ç”¨çŽ°æœ‰çš„3D/4Dæ•°æ®ã€‚æ¯ä¸ªæ¨¡åž‹åªåœ¨ç‰¹å®šçš„æ•°æ®åˆ‡ç‰‡ä¸Šè®­ç»ƒï¼Œæ³›åŒ–èƒ½åŠ›å—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šOmniViewçš„æ ¸å¿ƒåœ¨äºŽæž„å»ºä¸€ä¸ªç»Ÿä¸€çš„æ‰©æ•£æ¨¡åž‹ï¼Œèƒ½å¤Ÿå¤„ç†å¤šç§4Dä¸€è‡´æ€§ä»»åŠ¡ã€‚é€šè¿‡å°†ç©ºé—´ã€æ—¶é—´å’Œè§†å›¾æ¡ä»¶è§£è€¦ï¼Œæ¨¡åž‹å¯ä»¥çµæ´»åœ°ç»„åˆè¿™äº›æ¡ä»¶ï¼Œä»Žè€Œé€‚åº”ä¸åŒçš„è¾“å…¥å’Œè¾“å‡ºå½¢å¼ã€‚è¿™ç§è§£è€¦çš„è®¾è®¡ä½¿å¾—æ¨¡åž‹èƒ½å¤Ÿä»Žå„ç§æ•°æ®ä¸­å­¦ä¹ ï¼Œå¹¶æ³›åŒ–åˆ°æ–°çš„ä»»åŠ¡ä¸Šã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šOmniViewé‡‡ç”¨æ‰©æ•£æ¨¡åž‹çš„æ¡†æž¶ï¼Œå¹¶å¼•å…¥äº†ä¸‰ä¸ªå…³é”®çš„æ¡ä»¶è¾“å…¥ï¼šç©ºé—´æ¡ä»¶ï¼ˆä¾‹å¦‚ï¼Œå›¾åƒæˆ–å¤šè§†å›¾å›¾åƒï¼‰ã€æ—¶é—´æ¡ä»¶ï¼ˆä¾‹å¦‚ï¼Œæ—¶é—´æ­¥é•¿æˆ–è½¨è¿¹ï¼‰å’Œè§†å›¾æ¡ä»¶ï¼ˆä¾‹å¦‚ï¼Œç›¸æœºå§¿æ€ï¼‰ã€‚è¿™äº›æ¡ä»¶é€šè¿‡ç‹¬ç«‹çš„ç¼–ç å™¨è¿›è¡Œå¤„ç†ï¼Œç„¶åŽèžåˆåˆ°æ‰©æ•£æ¨¡åž‹çš„å™ªå£°é¢„æµ‹ç½‘ç»œä¸­ã€‚æ¨¡åž‹é€šè¿‡å­¦ä¹ å¦‚ä½•ä»Žå™ªå£°ä¸­ç”Ÿæˆç¬¦åˆè¿™äº›æ¡ä»¶çš„å›¾åƒæˆ–è§†é¢‘æ¥å®žçŽ°4Dè§†å›¾åˆæˆã€‚

**å…³é”®åˆ›æ–°**ï¼šOmniViewçš„å…³é”®åˆ›æ–°åœ¨äºŽå…¶ç»Ÿä¸€çš„æ¡†æž¶å’Œè§£è€¦çš„æ¡ä»¶è¡¨ç¤ºã€‚ä¸Žä»¥å¾€é’ˆå¯¹ç‰¹å®šä»»åŠ¡è®¾è®¡çš„æ¨¡åž‹ä¸åŒï¼ŒOmniViewèƒ½å¤Ÿå¤„ç†å¤šç§4Dä¸€è‡´æ€§ä»»åŠ¡ï¼Œå¹¶ä¸”å…·æœ‰æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚é€šè¿‡è§£è€¦ç©ºé—´ã€æ—¶é—´å’Œè§†å›¾æ¡ä»¶ï¼Œæ¨¡åž‹å¯ä»¥çµæ´»åœ°ç»„åˆè¿™äº›æ¡ä»¶ï¼Œä»Žè€Œé€‚åº”ä¸åŒçš„è¾“å…¥å’Œè¾“å‡ºå½¢å¼ã€‚

**å…³é”®è®¾è®¡**ï¼šOmniViewä½¿ç”¨Transformerç½‘ç»œæ¥ç¼–ç ç©ºé—´ã€æ—¶é—´å’Œè§†å›¾æ¡ä»¶ã€‚æ‰©æ•£æ¨¡åž‹é‡‡ç”¨U-Netæž¶æž„ï¼Œå¹¶ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶æ¥èžåˆæ¡ä»¶ç¼–ç ã€‚æŸå¤±å‡½æ•°é‡‡ç”¨æ ‡å‡†çš„æ‰©æ•£æ¨¡åž‹æŸå¤±ï¼Œå³é¢„æµ‹å™ªå£°ä¸ŽçœŸå®žå™ªå£°ä¹‹é—´çš„å‡æ–¹è¯¯å·®ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¨¡åž‹ä½¿ç”¨å¤šç§3D/4Dæ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œä»¥æé«˜å…¶æ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

OmniViewåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚åœ¨LLFFæ•°æ®é›†ä¸Šï¼Œå›¾åƒè´¨é‡å¾—åˆ†æé«˜äº†33%ã€‚åœ¨Neural 3D Videoæ•°æ®é›†ä¸Šï¼Œå›¾åƒè´¨é‡å¾—åˆ†æé«˜äº†60%ã€‚åœ¨RE-10Kæ•°æ®é›†ä¸Šï¼Œé™æ€ç›¸æœºæŽ§åˆ¶çš„å›¾åƒè´¨é‡å¾—åˆ†æé«˜äº†20%ã€‚åœ¨æ–‡æœ¬æ¡ä»¶è§†é¢‘ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œç›¸æœºè½¨è¿¹è¯¯å·®é™ä½Žäº†4å€ã€‚è¿™äº›ç»“æžœè¡¨æ˜Žï¼ŒOmniViewå…·æœ‰å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›å’Œä¼˜è¶Šçš„æ€§èƒ½ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

OmniViewå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼ŒåŒ…æ‹¬è™šæ‹ŸçŽ°å®žã€å¢žå¼ºçŽ°å®žã€æ¸¸æˆå¼€å‘ã€ç”µå½±åˆ¶ä½œç­‰é¢†åŸŸã€‚å®ƒå¯ä»¥ç”¨äºŽç”Ÿæˆé€¼çœŸçš„3Dåœºæ™¯å’ŒåŠ¨æ€è§†é¢‘ï¼Œå®žçŽ°æ²‰æµ¸å¼çš„ç”¨æˆ·ä½“éªŒã€‚æ­¤å¤–ï¼ŒOmniViewè¿˜å¯ä»¥ç”¨äºŽæœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸï¼Œå¸®åŠ©æœºå™¨äººç†è§£å’Œæ„ŸçŸ¥å‘¨å›´çŽ¯å¢ƒã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Prior approaches injecting camera control into diffusion models have focused on specific subsets of 4D consistency tasks: novel view synthesis, text-to-video with camera control, image-to-video, amongst others. Therefore, these fragmented approaches are trained on disjoint slices of available 3D/4D data. We introduce OmniView, a unified framework that generalizes across a wide range of 4D consistency tasks. Our method separately represents space, time, and view conditions, enabling flexible combinations of these inputs. For example, OmniView can synthesize novel views from static, dynamic, and multiview inputs, extrapolate trajectories forward and backward in time, and create videos from text or image prompts with full camera control. OmniView is competitive with task-specific models across diverse benchmarks and metrics, improving image quality scores among camera-conditioned diffusion models by up to 33\% in multiview NVS LLFF dataset, 60\% in dynamic NVS Neural 3D Video benchmark, 20\% in static camera control on RE-10K, and reducing camera trajectory errors by 4x in text-conditioned video generation. With strong generalizability in one model, OmniView demonstrates the feasibility of a generalist 4D video model. Project page is available at https://snap-research.github.io/OmniView/

