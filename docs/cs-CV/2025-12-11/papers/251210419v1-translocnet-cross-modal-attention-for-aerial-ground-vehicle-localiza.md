---
layout: default
title: TransLocNet: Cross-Modal Attention for Aerial-Ground Vehicle Localization with Contrastive Learning
---

# TransLocNet: Cross-Modal Attention for Aerial-Ground Vehicle Localization with Contrastive Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.10419" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.10419v1</a>
  <a href="https://arxiv.org/pdf/2512.10419.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.10419v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.10419v1', 'TransLocNet: Cross-Modal Attention for Aerial-Ground Vehicle Localization with Contrastive Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Phu Pham, Damon Conover, Aniket Bera

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-11

**å¤‡æ³¨**: 8 pages, 4 figures, 4 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**TransLocNetï¼šåŸºäºè·¨æ¨¡æ€æ³¨æ„åŠ›å’Œå¯¹æ¯”å­¦ä¹ çš„æ— äººæœº-åœ°é¢è½¦è¾†å®šä½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `æ— äººæœºå®šä½` `åœ°é¢è½¦è¾†å®šä½` `è·¨æ¨¡æ€èåˆ` `æ³¨æ„åŠ›æœºåˆ¶` `å¯¹æ¯”å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ— äººæœº-åœ°é¢è½¦è¾†å®šä½é¢ä¸´è§†è§’å’Œæ¨¡æ€å·®å¼‚å·¨å¤§çš„æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆèåˆå¼‚æ„æ•°æ®ã€‚
2. TransLocNetåˆ©ç”¨è·¨æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶ï¼Œå°†æ¿€å…‰é›·è¾¾å‡ ä½•ä¿¡æ¯ä¸èˆªæ‹è¯­ä¹‰ä¸Šä¸‹æ–‡è¿›è¡Œæœ‰æ•ˆèåˆã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒTransLocNetåœ¨å®šä½ç²¾åº¦ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶åœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šå‡è¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºTransLocNetï¼Œä¸€ä¸ªè·¨æ¨¡æ€æ³¨æ„åŠ›æ¡†æ¶ï¼Œç”¨äºèåˆæ¿€å…‰é›·è¾¾å‡ ä½•ä¿¡æ¯ä¸æ— äººæœºèˆªæ‹è¯­ä¹‰ä¸Šä¸‹æ–‡ï¼Œè§£å†³æ— äººæœº-åœ°é¢è½¦è¾†å®šä½éš¾é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡åŒå‘æ³¨æ„åŠ›æœºåˆ¶å°†æ¿€å…‰é›·è¾¾æ‰«ææŠ•å½±åˆ°é¸Ÿç°å›¾è¡¨ç¤ºï¼Œå¹¶ä¸èˆªæ‹ç‰¹å¾å¯¹é½ï¼Œç„¶åä½¿ç”¨ä¼¼ç„¶å›¾è§£ç å™¨è¾“å‡ºä½ç½®å’Œæ–¹å‘çš„ç©ºé—´æ¦‚ç‡åˆ†å¸ƒã€‚å¯¹æ¯”å­¦ä¹ æ¨¡å—ç”¨äºå¼ºåˆ¶æ‰§è¡Œå…±äº«åµŒå…¥ç©ºé—´ï¼Œä»¥æ”¹å–„è·¨æ¨¡æ€å¯¹é½ã€‚åœ¨CARLAå’ŒKITTIæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒTransLocNetä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œå®šä½è¯¯å·®æœ€å¤šå¯é™ä½63%ï¼Œå¹¶å®ç°äºšç±³çº§ã€äºšåº¦çº§çš„ç²¾åº¦ã€‚ç»“æœè¡¨æ˜ï¼ŒTransLocNetåœ¨åˆæˆå’ŒçœŸå®ç¯å¢ƒä¸­å‡èƒ½æä¾›é²æ£’ä¸”é€šç”¨çš„æ— äººæœº-åœ°é¢è½¦è¾†å®šä½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæ— äººæœºä¸åœ°é¢è½¦è¾†çš„å®šä½æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ï¼Œä¸»è¦ç—›ç‚¹åœ¨äºåœ°é¢æ¿€å…‰é›·è¾¾æ•°æ®å’Œç©ºä¸­å›¾åƒæ•°æ®ä¹‹é—´å­˜åœ¨å·¨å¤§çš„è§†è§’å·®å¼‚å’Œæ¨¡æ€å·®å¼‚ã€‚ç°æœ‰çš„æ–¹æ³•éš¾ä»¥æœ‰æ•ˆåœ°å°†è¿™ä¸¤ç§å¼‚æ„æ•°æ®èåˆèµ·æ¥ï¼Œå¯¼è‡´å®šä½ç²¾åº¦ä¸é«˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šTransLocNetçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è·¨æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶ï¼Œå°†æ¿€å…‰é›·è¾¾çš„å‡ ä½•ä¿¡æ¯å’Œèˆªæ‹å›¾åƒçš„è¯­ä¹‰ä¿¡æ¯è¿›è¡Œæœ‰æ•ˆèåˆã€‚é€šè¿‡å­¦ä¹ ä¸¤ç§æ¨¡æ€ä¹‹é—´çš„å…³è”æ€§ï¼Œä»è€Œæé«˜å®šä½çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚å¯¹æ¯”å­¦ä¹ çš„å¼•å…¥è¿›ä¸€æ­¥å¢å¼ºäº†è·¨æ¨¡æ€ç‰¹å¾çš„å¯¹é½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTransLocNetçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) æ¿€å…‰é›·è¾¾æ•°æ®é¢„å¤„ç†ï¼Œå°†æ¿€å…‰é›·è¾¾æ‰«ææ•°æ®æŠ•å½±åˆ°é¸Ÿç°å›¾ï¼ˆBEVï¼‰è¡¨ç¤ºï¼›2) ç‰¹å¾æå–ï¼Œåˆ†åˆ«ä»BEVæ¿€å…‰é›·è¾¾æ•°æ®å’Œèˆªæ‹å›¾åƒä¸­æå–ç‰¹å¾ï¼›3) è·¨æ¨¡æ€æ³¨æ„åŠ›æ¨¡å—ï¼Œåˆ©ç”¨åŒå‘æ³¨æ„åŠ›æœºåˆ¶å°†æ¿€å…‰é›·è¾¾ç‰¹å¾å’Œèˆªæ‹å›¾åƒç‰¹å¾è¿›è¡Œå¯¹é½å’Œèåˆï¼›4) ä¼¼ç„¶å›¾è§£ç å™¨ï¼Œæ ¹æ®èåˆåçš„ç‰¹å¾ç”Ÿæˆä½ç½®å’Œæ–¹å‘çš„æ¦‚ç‡åˆ†å¸ƒï¼›5) å¯¹æ¯”å­¦ä¹ æ¨¡å—ï¼Œé€šè¿‡æœ€å°åŒ–æ­£æ ·æœ¬å¯¹ä¹‹é—´çš„è·ç¦»ï¼Œæœ€å¤§åŒ–è´Ÿæ ·æœ¬å¯¹ä¹‹é—´çš„è·ç¦»ï¼Œæ¥å­¦ä¹ ä¸€ä¸ªå…±äº«çš„åµŒå…¥ç©ºé—´ã€‚

**å…³é”®åˆ›æ–°**ï¼šTransLocNetçš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†ä¸€ä¸ªè·¨æ¨¡æ€æ³¨æ„åŠ›æ¡†æ¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°èåˆæ¿€å…‰é›·è¾¾å‡ ä½•ä¿¡æ¯å’Œèˆªæ‹è¯­ä¹‰ä¸Šä¸‹æ–‡ï¼›2) å¼•å…¥äº†å¯¹æ¯”å­¦ä¹ æ¨¡å—ï¼Œè¿›ä¸€æ­¥æå‡äº†è·¨æ¨¡æ€ç‰¹å¾çš„å¯¹é½æ•ˆæœï¼›3) è®¾è®¡äº†ä¸€ä¸ªä¼¼ç„¶å›¾è§£ç å™¨ï¼Œèƒ½å¤Ÿè¾“å‡ºä½ç½®å’Œæ–¹å‘çš„æ¦‚ç‡åˆ†å¸ƒï¼Œä»è€Œæä¾›æ›´ä¸°å¯Œçš„å®šä½ä¿¡æ¯ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è·¨æ¨¡æ€æ³¨æ„åŠ›æ¨¡å—ä¸­ï¼Œä½¿ç”¨äº†åŒå‘æ³¨æ„åŠ›æœºåˆ¶ï¼Œåˆ†åˆ«ä»æ¿€å…‰é›·è¾¾ç‰¹å¾å’Œèˆªæ‹å›¾åƒç‰¹å¾çš„è§’åº¦è¿›è¡Œæ³¨æ„åŠ›è®¡ç®—ã€‚å¯¹æ¯”å­¦ä¹ æ¨¡å—ä½¿ç”¨äº†InfoNCEæŸå¤±å‡½æ•°ï¼Œç”¨äºå­¦ä¹ ä¸€ä¸ªå…±äº«çš„åµŒå…¥ç©ºé—´ã€‚ä¼¼ç„¶å›¾è§£ç å™¨ä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œæ¥ç”Ÿæˆä½ç½®å’Œæ–¹å‘çš„æ¦‚ç‡åˆ†å¸ƒã€‚å…·ä½“çš„å‚æ•°è®¾ç½®ï¼ˆå¦‚æ³¨æ„åŠ›å¤´çš„æ•°é‡ã€å·ç§¯æ ¸çš„å¤§å°ç­‰ï¼‰éœ€è¦æ ¹æ®å…·ä½“çš„æ•°æ®é›†è¿›è¡Œè°ƒæ•´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

TransLocNetåœ¨CARLAå’ŒKITTIæ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Œç»“æœè¡¨æ˜å…¶æ€§èƒ½ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚åœ¨CARLAæ•°æ®é›†ä¸Šï¼ŒTransLocNetå°†å®šä½è¯¯å·®é™ä½äº†é«˜è¾¾63%ï¼Œå¹¶åœ¨KITTIæ•°æ®é›†ä¸Šå®ç°äº†äºšç±³çº§ã€äºšåº¦çº§çš„å®šä½ç²¾åº¦ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒTransLocNetåœ¨åˆæˆå’ŒçœŸå®ç¯å¢ƒä¸­å‡èƒ½æä¾›é²æ£’ä¸”é€šç”¨çš„æ— äººæœº-åœ°é¢è½¦è¾†å®šä½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ã€æ— äººæœºå¯¼èˆªã€æœºå™¨äººå®šä½ç­‰é¢†åŸŸã€‚é€šè¿‡èåˆæ— äººæœºèˆªæ‹å›¾åƒå’Œåœ°é¢æ¿€å…‰é›·è¾¾æ•°æ®ï¼Œå¯ä»¥å®ç°æ›´ç²¾ç¡®ã€æ›´é²æ£’çš„å®šä½ï¼Œæé«˜ç³»ç»Ÿçš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åœ¨æ™ºæ…§åŸå¸‚ã€ç‰©æµé…é€ã€ç¾å®³æ•‘æ´ç­‰åœºæ™¯ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Aerial-ground localization is difficult due to large viewpoint and modality gaps between ground-level LiDAR and overhead imagery. We propose TransLocNet, a cross-modal attention framework that fuses LiDAR geometry with aerial semantic context. LiDAR scans are projected into a bird's-eye-view representation and aligned with aerial features through bidirectional attention, followed by a likelihood map decoder that outputs spatial probability distributions over position and orientation. A contrastive learning module enforces a shared embedding space to improve cross-modal alignment. Experiments on CARLA and KITTI show that TransLocNet outperforms state-of-the-art baselines, reducing localization error by up to 63% and achieving sub-meter, sub-degree accuracy. These results demonstrate that TransLocNet provides robust and generalizable aerial-ground localization in both synthetic and real-world settings.

