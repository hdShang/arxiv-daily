---
layout: default
title: TransLocNet: Cross-Modal Attention for Aerial-Ground Vehicle Localization with Contrastive Learning
---

# TransLocNet: Cross-Modal Attention for Aerial-Ground Vehicle Localization with Contrastive Learning

**arXiv**: [2512.10419v1](https://arxiv.org/abs/2512.10419) | [PDF](https://arxiv.org/pdf/2512.10419.pdf)

**ä½œè€…**: Phu Pham, Damon Conover, Aniket Bera

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-11

**å¤‡æ³¨**: 8 pages, 4 figures, 4 tables

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**TransLocNetï¼šåŸºäºŽè·¨æ¨¡æ€æ³¨æ„åŠ›å’Œå¯¹æ¯”å­¦ä¹ çš„æ— äººæœº-åœ°é¢è½¦è¾†å®šä½**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `æ— äººæœºå®šä½` `åœ°é¢è½¦è¾†å®šä½` `è·¨æ¨¡æ€èžåˆ` `æ³¨æ„åŠ›æœºåˆ¶` `å¯¹æ¯”å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ— äººæœº-åœ°é¢è½¦è¾†å®šä½é¢ä¸´è§†è§’å’Œæ¨¡æ€å·®å¼‚å·¨å¤§çš„æŒ‘æˆ˜ï¼ŒçŽ°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆèžåˆå¼‚æž„æ•°æ®ã€‚
2. TransLocNetåˆ©ç”¨è·¨æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶ï¼Œå°†æ¿€å…‰é›·è¾¾å‡ ä½•ä¿¡æ¯ä¸Žèˆªæ‹è¯­ä¹‰ä¸Šä¸‹æ–‡è¿›è¡Œæœ‰æ•ˆèžåˆã€‚
3. å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒTransLocNetåœ¨å®šä½ç²¾åº¦ä¸Šæ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œå¹¶åœ¨åˆæˆå’ŒçœŸå®žæ•°æ®é›†ä¸Šå‡è¡¨çŽ°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºTransLocNetï¼Œä¸€ä¸ªè·¨æ¨¡æ€æ³¨æ„åŠ›æ¡†æž¶ï¼Œç”¨äºŽèžåˆæ¿€å…‰é›·è¾¾å‡ ä½•ä¿¡æ¯ä¸Žæ— äººæœºèˆªæ‹è¯­ä¹‰ä¸Šä¸‹æ–‡ï¼Œè§£å†³æ— äººæœº-åœ°é¢è½¦è¾†å®šä½éš¾é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡åŒå‘æ³¨æ„åŠ›æœºåˆ¶å°†æ¿€å…‰é›·è¾¾æ‰«ææŠ•å½±åˆ°é¸Ÿçž°å›¾è¡¨ç¤ºï¼Œå¹¶ä¸Žèˆªæ‹ç‰¹å¾å¯¹é½ï¼Œç„¶åŽä½¿ç”¨ä¼¼ç„¶å›¾è§£ç å™¨è¾“å‡ºä½ç½®å’Œæ–¹å‘çš„ç©ºé—´æ¦‚çŽ‡åˆ†å¸ƒã€‚å¯¹æ¯”å­¦ä¹ æ¨¡å—ç”¨äºŽå¼ºåˆ¶æ‰§è¡Œå…±äº«åµŒå…¥ç©ºé—´ï¼Œä»¥æ”¹å–„è·¨æ¨¡æ€å¯¹é½ã€‚åœ¨CARLAå’ŒKITTIæ•°æ®é›†ä¸Šçš„å®žéªŒè¡¨æ˜Žï¼ŒTransLocNetä¼˜äºŽçŽ°æœ‰æŠ€æœ¯ï¼Œå®šä½è¯¯å·®æœ€å¤šå¯é™ä½Ž63%ï¼Œå¹¶å®žçŽ°äºšç±³çº§ã€äºšåº¦çº§çš„ç²¾åº¦ã€‚ç»“æžœè¡¨æ˜Žï¼ŒTransLocNetåœ¨åˆæˆå’ŒçœŸå®žçŽ¯å¢ƒä¸­å‡èƒ½æä¾›é²æ£’ä¸”é€šç”¨çš„æ— äººæœº-åœ°é¢è½¦è¾†å®šä½ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæ— äººæœºä¸Žåœ°é¢è½¦è¾†çš„å®šä½æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ï¼Œä¸»è¦ç—›ç‚¹åœ¨äºŽåœ°é¢æ¿€å…‰é›·è¾¾æ•°æ®å’Œç©ºä¸­å›¾åƒæ•°æ®ä¹‹é—´å­˜åœ¨å·¨å¤§çš„è§†è§’å·®å¼‚å’Œæ¨¡æ€å·®å¼‚ã€‚çŽ°æœ‰çš„æ–¹æ³•éš¾ä»¥æœ‰æ•ˆåœ°å°†è¿™ä¸¤ç§å¼‚æž„æ•°æ®èžåˆèµ·æ¥ï¼Œå¯¼è‡´å®šä½ç²¾åº¦ä¸é«˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šTransLocNetçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è·¨æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶ï¼Œå°†æ¿€å…‰é›·è¾¾çš„å‡ ä½•ä¿¡æ¯å’Œèˆªæ‹å›¾åƒçš„è¯­ä¹‰ä¿¡æ¯è¿›è¡Œæœ‰æ•ˆèžåˆã€‚é€šè¿‡å­¦ä¹ ä¸¤ç§æ¨¡æ€ä¹‹é—´çš„å…³è”æ€§ï¼Œä»Žè€Œæé«˜å®šä½çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚å¯¹æ¯”å­¦ä¹ çš„å¼•å…¥è¿›ä¸€æ­¥å¢žå¼ºäº†è·¨æ¨¡æ€ç‰¹å¾çš„å¯¹é½ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šTransLocNetçš„æ•´ä½“æ¡†æž¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) æ¿€å…‰é›·è¾¾æ•°æ®é¢„å¤„ç†ï¼Œå°†æ¿€å…‰é›·è¾¾æ‰«ææ•°æ®æŠ•å½±åˆ°é¸Ÿçž°å›¾ï¼ˆBEVï¼‰è¡¨ç¤ºï¼›2) ç‰¹å¾æå–ï¼Œåˆ†åˆ«ä»ŽBEVæ¿€å…‰é›·è¾¾æ•°æ®å’Œèˆªæ‹å›¾åƒä¸­æå–ç‰¹å¾ï¼›3) è·¨æ¨¡æ€æ³¨æ„åŠ›æ¨¡å—ï¼Œåˆ©ç”¨åŒå‘æ³¨æ„åŠ›æœºåˆ¶å°†æ¿€å…‰é›·è¾¾ç‰¹å¾å’Œèˆªæ‹å›¾åƒç‰¹å¾è¿›è¡Œå¯¹é½å’Œèžåˆï¼›4) ä¼¼ç„¶å›¾è§£ç å™¨ï¼Œæ ¹æ®èžåˆåŽçš„ç‰¹å¾ç”Ÿæˆä½ç½®å’Œæ–¹å‘çš„æ¦‚çŽ‡åˆ†å¸ƒï¼›5) å¯¹æ¯”å­¦ä¹ æ¨¡å—ï¼Œé€šè¿‡æœ€å°åŒ–æ­£æ ·æœ¬å¯¹ä¹‹é—´çš„è·ç¦»ï¼Œæœ€å¤§åŒ–è´Ÿæ ·æœ¬å¯¹ä¹‹é—´çš„è·ç¦»ï¼Œæ¥å­¦ä¹ ä¸€ä¸ªå…±äº«çš„åµŒå…¥ç©ºé—´ã€‚

**å…³é”®åˆ›æ–°**ï¼šTransLocNetçš„å…³é”®åˆ›æ–°åœ¨äºŽï¼š1) æå‡ºäº†ä¸€ä¸ªè·¨æ¨¡æ€æ³¨æ„åŠ›æ¡†æž¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°èžåˆæ¿€å…‰é›·è¾¾å‡ ä½•ä¿¡æ¯å’Œèˆªæ‹è¯­ä¹‰ä¸Šä¸‹æ–‡ï¼›2) å¼•å…¥äº†å¯¹æ¯”å­¦ä¹ æ¨¡å—ï¼Œè¿›ä¸€æ­¥æå‡äº†è·¨æ¨¡æ€ç‰¹å¾çš„å¯¹é½æ•ˆæžœï¼›3) è®¾è®¡äº†ä¸€ä¸ªä¼¼ç„¶å›¾è§£ç å™¨ï¼Œèƒ½å¤Ÿè¾“å‡ºä½ç½®å’Œæ–¹å‘çš„æ¦‚çŽ‡åˆ†å¸ƒï¼Œä»Žè€Œæä¾›æ›´ä¸°å¯Œçš„å®šä½ä¿¡æ¯ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è·¨æ¨¡æ€æ³¨æ„åŠ›æ¨¡å—ä¸­ï¼Œä½¿ç”¨äº†åŒå‘æ³¨æ„åŠ›æœºåˆ¶ï¼Œåˆ†åˆ«ä»Žæ¿€å…‰é›·è¾¾ç‰¹å¾å’Œèˆªæ‹å›¾åƒç‰¹å¾çš„è§’åº¦è¿›è¡Œæ³¨æ„åŠ›è®¡ç®—ã€‚å¯¹æ¯”å­¦ä¹ æ¨¡å—ä½¿ç”¨äº†InfoNCEæŸå¤±å‡½æ•°ï¼Œç”¨äºŽå­¦ä¹ ä¸€ä¸ªå…±äº«çš„åµŒå…¥ç©ºé—´ã€‚ä¼¼ç„¶å›¾è§£ç å™¨ä½¿ç”¨å·ç§¯ç¥žç»ç½‘ç»œæ¥ç”Ÿæˆä½ç½®å’Œæ–¹å‘çš„æ¦‚çŽ‡åˆ†å¸ƒã€‚å…·ä½“çš„å‚æ•°è®¾ç½®ï¼ˆå¦‚æ³¨æ„åŠ›å¤´çš„æ•°é‡ã€å·ç§¯æ ¸çš„å¤§å°ç­‰ï¼‰éœ€è¦æ ¹æ®å…·ä½“çš„æ•°æ®é›†è¿›è¡Œè°ƒæ•´ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

TransLocNetåœ¨CARLAå’ŒKITTIæ•°æ®é›†ä¸Šè¿›è¡Œäº†å®žéªŒï¼Œç»“æžœè¡¨æ˜Žå…¶æ€§èƒ½ä¼˜äºŽçŽ°æœ‰æŠ€æœ¯ã€‚åœ¨CARLAæ•°æ®é›†ä¸Šï¼ŒTransLocNetå°†å®šä½è¯¯å·®é™ä½Žäº†é«˜è¾¾63%ï¼Œå¹¶åœ¨KITTIæ•°æ®é›†ä¸Šå®žçŽ°äº†äºšç±³çº§ã€äºšåº¦çº§çš„å®šä½ç²¾åº¦ã€‚è¿™äº›ç»“æžœè¡¨æ˜Žï¼ŒTransLocNetåœ¨åˆæˆå’ŒçœŸå®žçŽ¯å¢ƒä¸­å‡èƒ½æä¾›é²æ£’ä¸”é€šç”¨çš„æ— äººæœº-åœ°é¢è½¦è¾†å®šä½ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽè‡ªåŠ¨é©¾é©¶ã€æ— äººæœºå¯¼èˆªã€æœºå™¨äººå®šä½ç­‰é¢†åŸŸã€‚é€šè¿‡èžåˆæ— äººæœºèˆªæ‹å›¾åƒå’Œåœ°é¢æ¿€å…‰é›·è¾¾æ•°æ®ï¼Œå¯ä»¥å®žçŽ°æ›´ç²¾ç¡®ã€æ›´é²æ£’çš„å®šä½ï¼Œæé«˜ç³»ç»Ÿçš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åœ¨æ™ºæ…§åŸŽå¸‚ã€ç‰©æµé…é€ã€ç¾å®³æ•‘æ´ç­‰åœºæ™¯ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Aerial-ground localization is difficult due to large viewpoint and modality gaps between ground-level LiDAR and overhead imagery. We propose TransLocNet, a cross-modal attention framework that fuses LiDAR geometry with aerial semantic context. LiDAR scans are projected into a bird's-eye-view representation and aligned with aerial features through bidirectional attention, followed by a likelihood map decoder that outputs spatial probability distributions over position and orientation. A contrastive learning module enforces a shared embedding space to improve cross-modal alignment. Experiments on CARLA and KITTI show that TransLocNet outperforms state-of-the-art baselines, reducing localization error by up to 63% and achieving sub-meter, sub-degree accuracy. These results demonstrate that TransLocNet provides robust and generalizable aerial-ground localization in both synthetic and real-world settings.

