---
layout: default
title: MIMO: A medical vision language model with visual referring multimodal input and pixel grounding multimodal output
---

# MIMO: A medical vision language model with visual referring multimodal input and pixel grounding multimodal output

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.10011" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.10011v1</a>
  <a href="https://arxiv.org/pdf/2510.10011.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.10011v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.10011v1', 'MIMO: A medical vision language model with visual referring multimodal input and pixel grounding multimodal output')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yanyuan Chen, Dexuan Xu, Yu Huang, Songkun Zhan, Hanpin Wang, Dongxue Chen, Xueping Wang, Meikang Qiu, Hang Li

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-11

**å¤‡æ³¨**: CVPR 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**MIMOï¼šä¸€ç§å…·æœ‰è§†è§‰æŒ‡ä»£å¤šæ¨¡æ€è¾“å…¥å’Œåƒç´ çº§å®šä½å¤šæ¨¡æ€è¾“å‡ºçš„åŒ»å­¦è§†è§‰è¯­è¨€æ¨¡å‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åŒ»å­¦è§†è§‰è¯­è¨€æ¨¡å‹` `å¤šæ¨¡æ€å­¦ä¹ ` `è§†è§‰æŒ‡ä»£` `åƒç´ çº§å®šä½` `åŒ»å­¦å½±åƒ` `è§†è§‰é—®ç­”` `Transformer` `MIMOSegæ•°æ®é›†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŒ»å­¦è§†è§‰è¯­è¨€æ¨¡å‹ä»…ä¾èµ–æ–‡æœ¬æŒ‡ä»¤ï¼Œå¿½ç•¥äº†å›¾åƒä¸­çš„è§†è§‰çº¿ç´¢ï¼Œé™åˆ¶äº†æ¨¡å‹å¯¹å¤æ‚åŒ»å­¦å›¾åƒçš„ç†è§£ã€‚
2. MIMOæ¨¡å‹é€šè¿‡å¼•å…¥è§†è§‰æŒ‡ä»£å¤šæ¨¡æ€è¾“å…¥å’Œåƒç´ çº§å®šä½å¤šæ¨¡æ€è¾“å‡ºï¼Œå¢å¼ºäº†æ¨¡å‹å¯¹åŒ»å­¦å›¾åƒçš„ç†è§£å’Œè§£é‡Šèƒ½åŠ›ã€‚
3. MIMOSegæ•°æ®é›†çš„æ„å»ºï¼Œä¸ºåŒ»å­¦å¤šæ¨¡æ€ä»»åŠ¡æä¾›äº†å¤§é‡æ•°æ®æ”¯æŒï¼Œå®éªŒç»“æœéªŒè¯äº†MIMOåœ¨è§†è§‰æŒ‡ä»£å’Œåƒç´ çº§å®šä½æ–¹é¢çš„ä¼˜åŠ¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç›®å‰ï¼ŒåŒ»å­¦è§†è§‰è¯­è¨€æ¨¡å‹è¢«å¹¿æ³›åº”ç”¨äºåŒ»å­¦è§†è§‰é—®ç­”ä»»åŠ¡ã€‚ç„¶è€Œï¼Œç°æœ‰æ¨¡å‹é¢ä¸´ä¸¤ä¸ªé—®é¢˜ï¼šå¯¹äºè¾“å…¥ï¼Œæ¨¡å‹ä»…ä¾èµ–äºæ–‡æœ¬æŒ‡ä»¤ï¼Œç¼ºä¹å¯¹å›¾åƒä¸­è§†è§‰çº¿ç´¢çš„ç›´æ¥ç†è§£ï¼›å¯¹äºè¾“å‡ºï¼Œæ¨¡å‹ä»…ç»™å‡ºæ–‡æœ¬ç­”æ¡ˆï¼Œç¼ºä¹ä¸å›¾åƒä¸­å…³é”®åŒºåŸŸçš„è”ç³»ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„åŒ»å­¦è§†è§‰è¯­è¨€æ¨¡å‹MIMOï¼Œå®ƒå…·æœ‰è§†è§‰æŒ‡ä»£å¤šæ¨¡æ€è¾“å…¥å’Œåƒç´ çº§å®šä½å¤šæ¨¡æ€è¾“å‡ºã€‚MIMOä¸ä»…å¯ä»¥ç»“åˆè§†è§‰çº¿ç´¢å’Œæ–‡æœ¬æŒ‡ä»¤æ¥ç†è§£å¤æ‚çš„åŒ»å­¦å›¾åƒå’Œè¯­ä¹‰ï¼Œè¿˜å¯ä»¥å°†æ–‡æœ¬è¾“å‡ºä¸­çš„åŒ»å­¦æœ¯è¯­å®šä½åˆ°å›¾åƒä¸­ã€‚ä¸ºäº†å…‹æœåŒ»å­¦é¢†åŸŸç›¸å…³æ•°æ®çš„ç¨€ç¼ºæ€§ï¼Œæˆ‘ä»¬æå‡ºäº†MIMOSegï¼Œä¸€ä¸ªåŒ…å«895Kæ ·æœ¬çš„ç»¼åˆåŒ»å­¦å¤šæ¨¡æ€æ•°æ®é›†ã€‚MIMOSegä»å››ä¸ªä¸åŒçš„è§’åº¦æ„å»ºï¼Œæ¶µç›–äº†å…·æœ‰å¤šæ¨¡æ€è¾“å…¥å’Œå¤šæ¨¡æ€è¾“å‡ºçš„åŸºæœ¬æŒ‡ä»¤è·Ÿéšå’Œå¤æ‚é—®é¢˜å›ç­”ã€‚æˆ‘ä»¬åœ¨å‡ ä¸ªä¸‹æ¸¸åŒ»å­¦å¤šæ¨¡æ€ä»»åŠ¡ä¸Šè¿›è¡Œäº†å®éªŒã€‚å¤§é‡çš„å®éªŒç»“æœéªŒè¯äº†MIMOå¯ä»¥ç‹¬ç‰¹åœ°ç»“åˆè§†è§‰æŒ‡ä»£å’Œåƒç´ çº§å®šä½èƒ½åŠ›ï¼Œè¿™æ˜¯ä»¥å‰çš„æ¨¡å‹æ‰€ä¸å…·å¤‡çš„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰åŒ»å­¦è§†è§‰è¯­è¨€æ¨¡å‹åœ¨å¤„ç†åŒ»å­¦è§†è§‰é—®ç­”ä»»åŠ¡æ—¶ï¼Œä¸»è¦ä¾èµ–æ–‡æœ¬æŒ‡ä»¤ä½œä¸ºè¾“å…¥ï¼Œå¿½ç•¥äº†åŒ»å­¦å›¾åƒæœ¬èº«åŒ…å«çš„ä¸°å¯Œè§†è§‰ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œæ¨¡å‹è¾“å‡ºé€šå¸¸ä»…ä¸ºæ–‡æœ¬ç­”æ¡ˆï¼Œæ— æ³•å°†ç­”æ¡ˆä¸å›¾åƒä¸­çš„å…·ä½“åŒºåŸŸå…³è”èµ·æ¥ï¼Œç¼ºä¹å¯è§£é‡Šæ€§ã€‚è¿™äº›é—®é¢˜é™åˆ¶äº†æ¨¡å‹åœ¨å®é™…åŒ»ç–—åœºæ™¯ä¸­çš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMIMOçš„æ ¸å¿ƒæ€è·¯æ˜¯åŒæ—¶åˆ©ç”¨è§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯ä½œä¸ºè¾“å…¥ï¼Œå¹¶ç”Ÿæˆæ—¢åŒ…å«æ–‡æœ¬ç­”æ¡ˆåˆåŒ…å«åƒç´ çº§å®šä½ä¿¡æ¯çš„è¾“å‡ºã€‚é€šè¿‡è§†è§‰æŒ‡ä»£å¤šæ¨¡æ€è¾“å…¥ï¼Œæ¨¡å‹å¯ä»¥æ›´å¥½åœ°ç†è§£å›¾åƒä¸­çš„è§†è§‰çº¿ç´¢ã€‚é€šè¿‡åƒç´ çº§å®šä½å¤šæ¨¡æ€è¾“å‡ºï¼Œæ¨¡å‹å¯ä»¥å°†æ–‡æœ¬ç­”æ¡ˆä¸­çš„åŒ»å­¦æœ¯è¯­ä¸å›¾åƒä¸­çš„å¯¹åº”åŒºåŸŸå…³è”èµ·æ¥ï¼Œæé«˜æ¨¡å‹çš„å¯è§£é‡Šæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMIMOæ¨¡å‹é‡‡ç”¨ç»Ÿä¸€çš„æ¶æ„ï¼ŒåŒ…å«è§†è§‰ç¼–ç å™¨ã€æ–‡æœ¬ç¼–ç å™¨å’Œå¤šæ¨¡æ€èåˆæ¨¡å—ã€‚è§†è§‰ç¼–ç å™¨è´Ÿè´£æå–åŒ»å­¦å›¾åƒçš„è§†è§‰ç‰¹å¾ï¼Œæ–‡æœ¬ç¼–ç å™¨è´Ÿè´£æå–æ–‡æœ¬æŒ‡ä»¤çš„è¯­ä¹‰ç‰¹å¾ã€‚å¤šæ¨¡æ€èåˆæ¨¡å—å°†è§†è§‰ç‰¹å¾å’Œè¯­ä¹‰ç‰¹å¾èåˆï¼Œç”Ÿæˆå¤šæ¨¡æ€è¡¨ç¤ºã€‚è§£ç å™¨æ ¹æ®å¤šæ¨¡æ€è¡¨ç¤ºç”Ÿæˆæ–‡æœ¬ç­”æ¡ˆå’Œåƒç´ çº§å®šä½ä¿¡æ¯ã€‚æ•´ä¸ªæµç¨‹å®ç°äº†ä»å¤šæ¨¡æ€è¾“å…¥åˆ°å¤šæ¨¡æ€è¾“å‡ºçš„ç«¯åˆ°ç«¯å­¦ä¹ ã€‚

**å…³é”®åˆ›æ–°**ï¼šMIMOçš„å…³é”®åˆ›æ–°åœ¨äºåŒæ—¶å¼•å…¥äº†è§†è§‰æŒ‡ä»£å¤šæ¨¡æ€è¾“å…¥å’Œåƒç´ çº§å®šä½å¤šæ¨¡æ€è¾“å‡ºã€‚è§†è§‰æŒ‡ä»£å¤šæ¨¡æ€è¾“å…¥ä½¿æ¨¡å‹èƒ½å¤Ÿç›´æ¥åˆ©ç”¨å›¾åƒä¸­çš„è§†è§‰ä¿¡æ¯ï¼Œè€Œåƒç´ çº§å®šä½å¤šæ¨¡æ€è¾“å‡ºä½¿æ¨¡å‹èƒ½å¤Ÿå°†æ–‡æœ¬ç­”æ¡ˆä¸å›¾åƒä¸­çš„å…·ä½“åŒºåŸŸå…³è”èµ·æ¥ã€‚è¿™ç§åŒé‡åˆ›æ–°ä½¿å¾—MIMOåœ¨åŒ»å­¦è§†è§‰è¯­è¨€ä»»åŠ¡ä¸­å…·æœ‰æ›´å¼ºçš„ç†è§£å’Œè§£é‡Šèƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šMIMOæ¨¡å‹ä½¿ç”¨äº†Transformeræ¶æ„ä½œä¸ºå…¶æ ¸å¿ƒç»„ä»¶ã€‚è§†è§‰ç¼–ç å™¨å’Œæ–‡æœ¬ç¼–ç å™¨å‡é‡‡ç”¨Transformerç¼–ç å™¨ï¼Œå¤šæ¨¡æ€èåˆæ¨¡å—é‡‡ç”¨Transformerè§£ç å™¨ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬æ–‡æœ¬ç­”æ¡ˆçš„äº¤å‰ç†µæŸå¤±å’Œåƒç´ çº§å®šä½çš„DiceæŸå¤±ã€‚MIMOSegæ•°æ®é›†çš„æ„å»ºè€ƒè™‘äº†ä¸åŒç±»å‹çš„åŒ»å­¦å›¾åƒå’Œé—®ç­”åœºæ™¯ï¼ŒåŒ…æ‹¬åŸºæœ¬æŒ‡ä»¤è·Ÿéšå’Œå¤æ‚é—®é¢˜å›ç­”ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥è®ºæ–‡æå‡ºäº†MIMOæ¨¡å‹ï¼Œå¹¶åœ¨è‡ªå»ºçš„MIMOSegæ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMIMOæ¨¡å‹åœ¨åŒ»å­¦è§†è§‰é—®ç­”ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¸ç°æœ‰æ¨¡å‹ç›¸æ¯”ï¼ŒMIMOæ¨¡å‹èƒ½å¤Ÿæ›´å‡†ç¡®åœ°ç†è§£åŒ»å­¦å›¾åƒå’Œæ–‡æœ¬æŒ‡ä»¤ï¼Œå¹¶ç”Ÿæˆæ›´å…·è§£é‡Šæ€§çš„ç­”æ¡ˆã€‚å…·ä½“æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦åœ¨è®ºæ–‡ä¸­è¯¦ç»†ç»™å‡ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MIMOæ¨¡å‹åœ¨åŒ»å­¦å½±åƒè¯Šæ–­ã€è¾…åŠ©å†³ç­–å’ŒåŒ»å­¦æ•™è‚²ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥å¸®åŠ©åŒ»ç”Ÿæ›´å‡†ç¡®åœ°ç†è§£åŒ»å­¦å›¾åƒï¼Œæä¾›æ›´å…¨é¢çš„è¯Šæ–­ä¿¡æ¯ï¼Œå¹¶ä¸ºæ‚£è€…æä¾›æ›´æ¸…æ™°çš„è§£é‡Šã€‚æ­¤å¤–ï¼ŒMIMOè¿˜å¯ä»¥ç”¨äºåŒ»å­¦æ•™è‚²ï¼Œå¸®åŠ©å­¦ç”Ÿæ›´å¥½åœ°ç†è§£åŒ»å­¦å›¾åƒå’Œç›¸å…³çŸ¥è¯†ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Currently, medical vision language models are widely used in medical vision question answering tasks. However, existing models are confronted with two issues: for input, the model only relies on text instructions and lacks direct understanding of visual clues in the image; for output, the model only gives text answers and lacks connection with key areas in the image. To address these issues, we propose a unified medical vision language model MIMO, with visual referring Multimodal Input and pixel grounding Multimodal Output. MIMO can not only combine visual clues and textual instructions to understand complex medical images and semantics, but can also ground medical terminologies in textual output within the image. To overcome the scarcity of relevant data in the medical field, we propose MIMOSeg, a comprehensive medical multimodal dataset including 895K samples. MIMOSeg is constructed from four different perspectives, covering basic instruction following and complex question answering with multimodal input and multimodal output. We conduct experiments on several downstream medical multimodal tasks. Extensive experimental results verify that MIMO can uniquely combine visual referring and pixel grounding capabilities, which are not available in previous models.

