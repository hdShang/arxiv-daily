---
layout: default
title: Ordinal Scale Traffic Congestion Classification with Multi-Modal Vision-Language and Motion Analysis
---

# Ordinal Scale Traffic Congestion Classification with Multi-Modal Vision-Language and Motion Analysis

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.10342" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.10342v1</a>
  <a href="https://arxiv.org/pdf/2510.10342.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.10342v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.10342v1', 'Ordinal Scale Traffic Congestion Classification with Multi-Modal Vision-Language and Motion Analysis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yu-Hsuan Lin

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-11

**å¤‡æ³¨**: 7 pages, 4 figures. Preprint submitted to arXiv in October 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šæ¨¡æ€èåˆæ¡†æ¶ï¼Œç”¨äºåºæ•°å°ºåº¦ä¸‹çš„äº¤é€šæ‹¥å µç­‰çº§åˆ†ç±»**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `äº¤é€šæ‹¥å µåˆ†ç±»` `å¤šæ¨¡æ€èåˆ` `è§†è§‰-è¯­è¨€æ¨ç†` `ç›®æ ‡æ£€æµ‹` `è¿åŠ¨åˆ†æ` `åºæ•°åˆ†ç±»` `æ™ºèƒ½äº¤é€šç³»ç»Ÿ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰äº¤é€šæ‹¥å µåˆ†ç±»æ–¹æ³•éš¾ä»¥æœ‰æ•ˆèåˆè§†è§‰è¯­ä¹‰ä¿¡æ¯å’Œæ—¶åºè¿åŠ¨ç‰¹å¾ï¼Œå¯¼è‡´åˆ†ç±»ç²¾åº¦å—é™ã€‚
2. è®ºæ–‡æå‡ºç»“åˆCLIPã€YOLO-Worldå’ŒMOG2è¿åŠ¨åˆ†æçš„å¤šæ¨¡æ€æ¡†æ¶ï¼Œå®ç°æ›´ç²¾ç¡®çš„æ‹¥å µç­‰çº§åˆ†ç±»ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å‡†ç¡®ç‡ã€F1åˆ†æ•°å’ŒQWKæŒ‡æ ‡ä¸Šå‡æ˜¾è‘—ä¼˜äºå•æ¨¡æ€åŸºçº¿æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€æ¡†æ¶ï¼Œç”¨äºäº¤é€šæ‹¥å µçš„ç²¾ç¡®åˆ†ç±»ï¼Œè¿™å¯¹äºæ™ºèƒ½äº¤é€šç³»ç»Ÿå’Œå®æ—¶åŸå¸‚äº¤é€šç®¡ç†è‡³å…³é‡è¦ã€‚è¯¥æ¡†æ¶ç»“åˆäº†å¼€æ”¾è¯æ±‡è§†è§‰-è¯­è¨€æ¨ç†ï¼ˆCLIPï¼‰ã€ç›®æ ‡æ£€æµ‹ï¼ˆYOLO-Worldï¼‰ä»¥åŠåŸºäºMOG2èƒŒæ™¯æ¶ˆå‡çš„è¿åŠ¨åˆ†æã€‚ç³»ç»Ÿé¢„æµ‹ä»1ï¼ˆç•…é€šï¼‰åˆ°5ï¼ˆä¸¥é‡æ‹¥å µï¼‰çš„åºæ•°å°ºåº¦ä¸Šçš„æ‹¥å µç­‰çº§ï¼Œä»è€Œå®ç°è¯­ä¹‰å¯¹é½å’Œæ—¶é—´ä¸€è‡´çš„åˆ†ç±»ã€‚ä¸ºäº†å¢å¼ºå¯è§£é‡Šæ€§ï¼Œæˆ‘ä»¬ç»“åˆäº†åŸºäºè¿åŠ¨çš„ç½®ä¿¡åº¦åŠ æƒå¹¶ç”Ÿæˆå¸¦æ³¨é‡Šçš„å¯è§†åŒ–è¾“å‡ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹å®ç°äº†76.7%çš„å‡†ç¡®ç‡ã€0.752çš„F1åˆ†æ•°å’Œ0.684çš„äºŒæ¬¡åŠ æƒKappaç³»æ•°ï¼ˆQWKï¼‰ï¼Œæ˜¾è‘—ä¼˜äºå•æ¨¡æ€åŸºçº¿ã€‚è¿™äº›ç»“æœè¯æ˜äº†è¯¥æ¡†æ¶åœ¨ä¿æŒåºæ•°ç»“æ„å’Œåˆ©ç”¨è§†è§‰-è¯­è¨€å’Œè¿åŠ¨æ¨¡æ€æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚æœªæ¥çš„æ”¹è¿›åŒ…æ‹¬æ•´åˆè½¦è¾†å°ºå¯¸å’Œæ”¹è¿›çš„å¯†åº¦æŒ‡æ ‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰äº¤é€šæ‹¥å µåˆ†ç±»æ–¹æ³•é€šå¸¸ä¾èµ–äºå•ä¸€æ¨¡æ€çš„ä¿¡æ¯ï¼Œä¾‹å¦‚ä»…ä½¿ç”¨å›¾åƒæˆ–è§†é¢‘æ•°æ®ï¼Œæˆ–è€…ä»…ä¾èµ–äºäº¤é€šæµé‡æ•°æ®ã€‚è¿™äº›æ–¹æ³•éš¾ä»¥å……åˆ†åˆ©ç”¨è§†è§‰è¯­ä¹‰ä¿¡æ¯ï¼ˆä¾‹å¦‚è½¦è¾†ç±»å‹ã€é“è·¯æ ‡å¿—ï¼‰å’Œæ—¶åºè¿åŠ¨ç‰¹å¾ï¼ˆä¾‹å¦‚è½¦è¾†é€Ÿåº¦ã€è¿åŠ¨æ–¹å‘ï¼‰ä¹‹é—´çš„å…³è”æ€§ï¼Œå¯¼è‡´åˆ†ç±»ç²¾åº¦å—é™ã€‚æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†ä¸åŒæ‹¥å µç­‰çº§ä¹‹é—´çš„åºæ•°å…³ç³»æ—¶å¯èƒ½ä¸å¤Ÿæœ‰æ•ˆï¼Œå¿½ç•¥äº†ç­‰çº§ä¹‹é—´çš„å†…åœ¨è”ç³»ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤šæ¨¡æ€èåˆçš„æ–¹æ³•ï¼Œå°†è§†è§‰è¯­ä¹‰ä¿¡æ¯ï¼ˆé€šè¿‡CLIPå’ŒYOLO-Worldæå–ï¼‰å’Œæ—¶åºè¿åŠ¨ç‰¹å¾ï¼ˆé€šè¿‡MOG2èƒŒæ™¯æ¶ˆå‡æå–ï¼‰ç›¸ç»“åˆï¼Œä»è€Œæ›´å…¨é¢åœ°ç†è§£äº¤é€šåœºæ™¯ã€‚åŒæ—¶ï¼Œé€šè¿‡åºæ•°åˆ†ç±»æ–¹æ³•ï¼Œæ›´å¥½åœ°åˆ©ç”¨æ‹¥å µç­‰çº§ä¹‹é—´çš„åºæ•°å…³ç³»ï¼Œæé«˜åˆ†ç±»ç²¾åº¦ã€‚æ­¤å¤–ï¼Œå¼•å…¥åŸºäºè¿åŠ¨çš„ç½®ä¿¡åº¦åŠ æƒï¼Œå¢å¼ºæ¨¡å‹çš„å¯è§£é‡Šæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶ä¸»è¦åŒ…å«ä¸‰ä¸ªæ¨¡å—ï¼š1) è§†è§‰-è¯­è¨€æ¨ç†æ¨¡å—ï¼ˆCLIPï¼‰ï¼šç”¨äºæå–å›¾åƒçš„å…¨å±€è¯­ä¹‰ç‰¹å¾ï¼›2) ç›®æ ‡æ£€æµ‹æ¨¡å—ï¼ˆYOLO-Worldï¼‰ï¼šç”¨äºæ£€æµ‹å›¾åƒä¸­çš„è½¦è¾†ç­‰ç›®æ ‡ï¼›3) è¿åŠ¨åˆ†ææ¨¡å—ï¼ˆMOG2ï¼‰ï¼šç”¨äºæå–è§†é¢‘ä¸­çš„è¿åŠ¨ä¿¡æ¯ã€‚è¿™ä¸‰ä¸ªæ¨¡å—æå–çš„ç‰¹å¾è¢«èåˆåœ¨ä¸€èµ·ï¼Œè¾“å…¥åˆ°åˆ†ç±»å™¨ä¸­ï¼Œé¢„æµ‹äº¤é€šæ‹¥å µç­‰çº§ã€‚ä¸ºäº†å¢å¼ºå¯è§£é‡Šæ€§ï¼Œè¿˜å¼•å…¥äº†åŸºäºè¿åŠ¨çš„ç½®ä¿¡åº¦åŠ æƒï¼Œå¹¶ç”Ÿæˆå¸¦æ³¨é‡Šçš„å¯è§†åŒ–è¾“å‡ºã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†ä¸€ä¸ªå¤šæ¨¡æ€èåˆæ¡†æ¶ï¼Œæœ‰æ•ˆåœ°ç»“åˆäº†è§†è§‰è¯­ä¹‰ä¿¡æ¯å’Œæ—¶åºè¿åŠ¨ç‰¹å¾ï¼›2) åˆ©ç”¨åºæ•°åˆ†ç±»æ–¹æ³•ï¼Œæ›´å¥½åœ°åˆ©ç”¨äº†æ‹¥å µç­‰çº§ä¹‹é—´çš„åºæ•°å…³ç³»ï¼›3) å¼•å…¥äº†åŸºäºè¿åŠ¨çš„ç½®ä¿¡åº¦åŠ æƒï¼Œå¢å¼ºäº†æ¨¡å‹çš„å¯è§£é‡Šæ€§ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´å…¨é¢åœ°ç†è§£äº¤é€šåœºæ™¯ï¼Œä»è€Œæé«˜åˆ†ç±»ç²¾åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è§†è§‰-è¯­è¨€æ¨ç†æ¨¡å—ä¸­ï¼Œä½¿ç”¨äº†é¢„è®­ç»ƒçš„CLIPæ¨¡å‹ï¼Œå¹¶é’ˆå¯¹äº¤é€šåœºæ™¯è¿›è¡Œäº†å¾®è°ƒã€‚åœ¨ç›®æ ‡æ£€æµ‹æ¨¡å—ä¸­ï¼Œä½¿ç”¨äº†YOLO-Worldæ¨¡å‹ï¼Œå¹¶é’ˆå¯¹è½¦è¾†æ£€æµ‹è¿›è¡Œäº†ä¼˜åŒ–ã€‚åœ¨è¿åŠ¨åˆ†ææ¨¡å—ä¸­ï¼Œä½¿ç”¨äº†MOG2èƒŒæ™¯æ¶ˆå‡ç®—æ³•ï¼Œå¹¶æ ¹æ®äº¤é€šåœºæ™¯çš„ç‰¹ç‚¹è°ƒæ•´äº†å‚æ•°ã€‚åœ¨åˆ†ç±»å™¨ä¸­ï¼Œä½¿ç”¨äº†å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰ï¼Œå¹¶é‡‡ç”¨äº†äº¤å‰ç†µæŸå¤±å‡½æ•°è¿›è¡Œè®­ç»ƒã€‚åŸºäºè¿åŠ¨çš„ç½®ä¿¡åº¦åŠ æƒæ˜¯æ ¹æ®MOG2æå–çš„è¿åŠ¨åŒºåŸŸçš„å¤§å°å’Œå¯†åº¦æ¥è®¡ç®—çš„ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹å®ç°äº†76.7%çš„å‡†ç¡®ç‡ï¼Œ0.752çš„F1åˆ†æ•°å’Œ0.684çš„äºŒæ¬¡åŠ æƒKappaç³»æ•°ï¼ˆQWKï¼‰ï¼Œæ˜¾è‘—ä¼˜äºå•æ¨¡æ€åŸºçº¿ã€‚ä¾‹å¦‚ï¼Œä¸ä»…ä½¿ç”¨è§†è§‰ä¿¡æ¯çš„åŸºçº¿ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•çš„å‡†ç¡®ç‡æé«˜äº†çº¦10%ã€‚è¿™äº›ç»“æœè¯æ˜äº†è¯¥æ¡†æ¶åœ¨ä¿æŒåºæ•°ç»“æ„å’Œåˆ©ç”¨è§†è§‰-è¯­è¨€å’Œè¿åŠ¨æ¨¡æ€æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ™ºèƒ½äº¤é€šç³»ç»Ÿã€å®æ—¶åŸå¸‚äº¤é€šç®¡ç†ã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸã€‚é€šè¿‡å‡†ç¡®çš„äº¤é€šæ‹¥å µç­‰çº§åˆ†ç±»ï¼Œå¯ä»¥ä¸ºäº¤é€šç®¡ç†è€…æä¾›å†³ç­–æ”¯æŒï¼Œä¼˜åŒ–äº¤é€šæµé‡ï¼Œå‡å°‘äº¤é€šæ‹¥å µï¼Œæé«˜é“è·¯é€šè¡Œæ•ˆç‡ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥åº”ç”¨äºè‡ªåŠ¨é©¾é©¶è½¦è¾†ï¼Œå¸®åŠ©è½¦è¾†æ›´å¥½åœ°ç†è§£äº¤é€šç¯å¢ƒï¼Œåšå‡ºæ›´å®‰å…¨çš„é©¾é©¶å†³ç­–ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Accurate traffic congestion classification is essential for intelligent transportation systems and real-time urban traffic management. This paper presents a multimodal framework combining open-vocabulary visual-language reasoning (CLIP), object detection (YOLO-World), and motion analysis via MOG2-based background subtraction. The system predicts congestion levels on an ordinal scale from 1 (free flow) to 5 (severe congestion), enabling semantically aligned and temporally consistent classification. To enhance interpretability, we incorporate motion-based confidence weighting and generate annotated visual outputs. Experimental results show the model achieves 76.7 percent accuracy, an F1 score of 0.752, and a Quadratic Weighted Kappa (QWK) of 0.684, significantly outperforming unimodal baselines. These results demonstrate the framework's effectiveness in preserving ordinal structure and leveraging visual-language and motion modalities. Future enhancements include incorporating vehicle sizing and refined density metrics.

