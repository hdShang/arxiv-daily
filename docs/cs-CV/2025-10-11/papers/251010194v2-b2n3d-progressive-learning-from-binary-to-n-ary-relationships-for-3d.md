---
layout: default
title: B2N3D: Progressive Learning from Binary to N-ary Relationships for 3D Object Grounding
---

# B2N3D: Progressive Learning from Binary to N-ary Relationships for 3D Object Grounding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.10194" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.10194v2</a>
  <a href="https://arxiv.org/pdf/2510.10194.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.10194v2" onclick="toggleFavorite(this, '2510.10194v2', 'B2N3D: Progressive Learning from Binary to N-ary Relationships for 3D Object Grounding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Feng Xiao, Hongbin Xu, Hai Ci, Wenxiong Kang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-11 (æ›´æ–°: 2025-12-01)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºB2N3Dæ¡†æ¶ï¼Œé€šè¿‡äºŒå…ƒåˆ°Nå…ƒå…³ç³»æ¸è¿›å­¦ä¹ å®ç°æ›´ç²¾ç¡®çš„3Dç‰©ä½“å®šä½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)**

**å…³é”®è¯**: `3Dç‰©ä½“å®šä½` `è‡ªç„¶è¯­è¨€ç†è§£` `Nå…ƒå…³ç³»å­¦ä¹ ` `å¤šæ¨¡æ€èåˆ` `åœºæ™¯å›¾`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰3Dç‰©ä½“å®šä½æ–¹æ³•ä»…å»ºæ¨¡æˆå¯¹ç‰©ä½“çš„å…³ç³»ï¼Œå¿½ç•¥äº†Nå…ƒå…³ç³»åœ¨å¤šæ¨¡æ€ç†è§£ä¸­çš„å…¨å±€é‡è¦æ€§ï¼Œå¯¼è‡´å®šä½ç²¾åº¦å—é™ã€‚
2. B2N3Dæ¡†æ¶é€šè¿‡æ¸è¿›å¼å­¦ä¹ ï¼Œå°†å…³ç³»å­¦ä¹ ä»äºŒå…ƒæ‰©å±•åˆ°Nå…ƒï¼Œä»è€Œæ›´å¥½åœ°æ•æ‰åœºæ™¯ä¸­ç‰©ä½“é—´çš„å¤æ‚å…³ç³»ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒB2N3Dåœ¨ReferIt3Då’ŒScanReferæ•°æ®é›†ä¸Šå‡å–å¾—äº†ä¼˜äºç°æœ‰æŠ€æœ¯çš„æ•ˆæœï¼ŒéªŒè¯äº†Nå…ƒå…³ç³»æ„ŸçŸ¥çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¸è¿›å¼å…³ç³»å­¦ä¹ æ¡†æ¶B2N3Dï¼Œç”¨äº3Dç‰©ä½“å®šä½ã€‚è¯¥æ–¹æ³•å°†å…³ç³»å­¦ä¹ ä»äºŒå…ƒæ‰©å±•åˆ°Nå…ƒï¼Œä»¥è¯†åˆ«ä¸å‚è€ƒæè¿°å…¨å±€åŒ¹é…çš„è§†è§‰å…³ç³»ï¼Œä»è€Œè§£å†³ç°æœ‰æ–¹æ³•ä»…å¯¹æˆå¯¹ç‰©ä½“å»ºæ¨¡å…³ç³»ï¼Œå¿½ç•¥Nå…ƒç»„åˆåœ¨å¤šæ¨¡æ€å…³ç³»ç†è§£ä¸­çš„å…¨å±€æ„ŸçŸ¥é‡è¦æ€§çš„é—®é¢˜ã€‚é’ˆå¯¹è®­ç»ƒæ•°æ®ä¸­ç¼ºä¹è¢«æŒ‡ä»£ç‰©ä½“çš„ç‰¹å®šæ ‡æ³¨ï¼Œè®¾è®¡äº†åˆ†ç»„ç›‘ç£æŸå¤±æ¥ä¿ƒè¿›Nå…ƒå…³ç³»å­¦ä¹ ã€‚åœ¨ç”±Nå…ƒå…³ç³»åˆ›å»ºçš„åœºæ™¯å›¾ä¸­ï¼Œä½¿ç”¨å…·æœ‰æ··åˆæ³¨æ„åŠ›æœºåˆ¶çš„å¤šæ¨¡æ€ç½‘ç»œæ¥è¿›ä¸€æ­¥å®šä½Nå…ƒç»„åˆä¸­çš„ç›®æ ‡ã€‚åœ¨ReferIt3Då’ŒScanReferåŸºå‡†ä¸Šçš„å®éªŒå’Œæ¶ˆèç ”ç©¶è¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œå¹¶è¯æ˜äº†Nå…ƒå…³ç³»æ„ŸçŸ¥åœ¨3Då®šä½ä¸­çš„ä¼˜åŠ¿ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰3Dç‰©ä½“å®šä½æ–¹æ³•ä¸»è¦ä¾èµ–äºäºŒå…ƒå…³ç³»å»ºæ¨¡ï¼Œå³ä»…è€ƒè™‘ç‰©ä½“ä¸¤ä¸¤ä¹‹é—´çš„å…³ç³»ã€‚ç„¶è€Œï¼Œè‡ªç„¶è¯­è¨€æè¿°é€šå¸¸æ¶‰åŠå¤šä¸ªç‰©ä½“ä¹‹é—´çš„å¤æ‚å…³ç³»ï¼ˆNå…ƒå…³ç³»ï¼‰ï¼Œä¾‹å¦‚â€œåœ¨çº¢è‰²æ²™å‘å·¦è¾¹ï¼Œé è¿‘è“è‰²æ¡Œå­çš„ç‰©ä½“â€ã€‚å¿½ç•¥è¿™äº›Nå…ƒå…³ç³»ä¼šå¯¼è‡´æ¨¡å‹æ— æ³•å……åˆ†ç†è§£åœºæ™¯ï¼Œä»è€Œå½±å“å®šä½ç²¾åº¦ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹å¯¹Nå…ƒå…³ç³»çš„æœ‰æ•ˆå»ºæ¨¡å’Œåˆ©ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†å…³ç³»å­¦ä¹ ä»ç®€å•çš„äºŒå…ƒå…³ç³»æ‰©å±•åˆ°æ›´å¤æ‚çš„Nå…ƒå…³ç³»ã€‚é€šè¿‡å­¦ä¹ Nå…ƒå…³ç³»ï¼Œæ¨¡å‹å¯ä»¥æ›´å¥½åœ°ç†è§£åœºæ™¯ä¸­ç‰©ä½“ä¹‹é—´çš„å…¨å±€å…³ç³»ï¼Œä»è€Œæ›´å‡†ç¡®åœ°å®šä½ç›®æ ‡ç‰©ä½“ã€‚æ­¤å¤–ï¼Œé‡‡ç”¨æ¸è¿›å¼å­¦ä¹ ç­–ç•¥ï¼Œä»äºŒå…ƒå…³ç³»å…¥æ‰‹ï¼Œé€æ­¥è¿‡æ¸¡åˆ°Nå…ƒå…³ç³»ï¼Œé™ä½å­¦ä¹ éš¾åº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šB2N3Dæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) **åœºæ™¯å›¾æ„å»º**ï¼šé¦–å…ˆï¼Œä»3Dåœºæ™¯ä¸­æå–ç‰©ä½“ï¼Œå¹¶æ„å»ºåŒ…å«äºŒå…ƒå’ŒNå…ƒå…³ç³»çš„åœºæ™¯å›¾ã€‚2) **å…³ç³»å­¦ä¹ **ï¼šåˆ©ç”¨åˆ†ç»„ç›‘ç£æŸå¤±ï¼Œå­¦ä¹ äºŒå…ƒå’ŒNå…ƒå…³ç³»ã€‚3) **å¤šæ¨¡æ€èåˆ**ï¼šä½¿ç”¨å…·æœ‰æ··åˆæ³¨æ„åŠ›æœºåˆ¶çš„å¤šæ¨¡æ€ç½‘ç»œï¼Œèåˆè§†è§‰ä¿¡æ¯å’Œè¯­è¨€ä¿¡æ¯ã€‚4) **ç›®æ ‡å®šä½**ï¼šåœ¨èåˆåçš„ç‰¹å¾åŸºç¡€ä¸Šï¼Œé¢„æµ‹ç›®æ ‡ç‰©ä½“çš„ä½ç½®ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥äº†Nå…ƒå…³ç³»å­¦ä¹ ï¼Œå¹¶è®¾è®¡äº†åˆ†ç»„ç›‘ç£æŸå¤±æ¥è§£å†³è®­ç»ƒæ•°æ®ä¸­ç¼ºä¹Nå…ƒå…³ç³»æ ‡æ³¨çš„é—®é¢˜ã€‚é€šè¿‡Nå…ƒå…³ç³»å­¦ä¹ ï¼Œæ¨¡å‹å¯ä»¥æ›´å¥½åœ°ç†è§£åœºæ™¯ä¸­ç‰©ä½“ä¹‹é—´çš„å¤æ‚å…³ç³»ï¼Œä»è€Œæé«˜å®šä½ç²¾åº¦ã€‚æ­¤å¤–ï¼Œæ··åˆæ³¨æ„åŠ›æœºåˆ¶èƒ½å¤Ÿæœ‰æ•ˆåœ°èåˆè§†è§‰ä¿¡æ¯å’Œè¯­è¨€ä¿¡æ¯ã€‚

**å…³é”®è®¾è®¡**ï¼šåˆ†ç»„ç›‘ç£æŸå¤±çš„è®¾è®¡æ˜¯å…³é”®ã€‚ç”±äºè®­ç»ƒæ•°æ®ä¸­æ²¡æœ‰æ˜ç¡®çš„Nå…ƒå…³ç³»æ ‡æ³¨ï¼Œå› æ­¤éœ€è¦è®¾è®¡ä¸€ç§è‡ªç›‘ç£çš„æ–¹å¼æ¥å­¦ä¹ Nå…ƒå…³ç³»ã€‚åˆ†ç»„ç›‘ç£æŸå¤±é€šè¿‡å°†ç›¸å…³çš„ç‰©ä½“åˆ†ç»„ï¼Œå¹¶é¼“åŠ±æ¨¡å‹é¢„æµ‹æ­£ç¡®çš„ç»„åˆ«ï¼Œä»è€Œå®ç°Nå…ƒå…³ç³»çš„å­¦ä¹ ã€‚æ··åˆæ³¨æ„åŠ›æœºåˆ¶åŒ…æ‹¬è‡ªæ³¨æ„åŠ›ï¼ˆself-attentionï¼‰å’Œäº¤å‰æ³¨æ„åŠ›ï¼ˆcross-attentionï¼‰ï¼Œç”¨äºåˆ†åˆ«æ•æ‰è§†è§‰ä¿¡æ¯å’Œè¯­è¨€ä¿¡æ¯å†…éƒ¨çš„ä¾èµ–å…³ç³»ï¼Œä»¥åŠè§†è§‰ä¿¡æ¯å’Œè¯­è¨€ä¿¡æ¯ä¹‹é—´çš„å…³è”ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

B2N3Dåœ¨ReferIt3Då’ŒScanReferæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚åœ¨ReferIt3Dæ•°æ®é›†ä¸Šï¼ŒB2N3Dçš„Acc@0.25æŒ‡æ ‡ç›¸æ¯”äºç°æœ‰æœ€ä½³æ–¹æ³•æå‡äº†è¶…è¿‡3%ã€‚åœ¨ScanReferæ•°æ®é›†ä¸Šï¼ŒB2N3Dä¹Ÿå–å¾—äº†ç±»ä¼¼çš„æå‡ï¼Œè¯æ˜äº†Nå…ƒå…³ç³»å­¦ä¹ çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæœºå™¨äººåœºæ™¯ç†è§£ã€æ™ºèƒ½å®¶å±…ã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨æœºå™¨äººåœºæ™¯ç†è§£ä¸­ï¼Œæœºå™¨äººå¯ä»¥æ ¹æ®è‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼Œåˆ©ç”¨è¯¥æ–¹æ³•å®šä½ç›®æ ‡ç‰©ä½“ï¼Œä»è€Œå®Œæˆè¯¸å¦‚â€œæŠŠçº¢è‰²çš„è‹¹æœæ”¾åœ¨æ¡Œå­ä¸Šâ€çš„ä»»åŠ¡ã€‚åœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸï¼Œè¯¥æ–¹æ³•å¯ä»¥å¸®åŠ©è½¦è¾†ç†è§£å‘¨å›´ç¯å¢ƒï¼Œä»è€Œæé«˜é©¾é©¶å®‰å…¨æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Localizing 3D objects using natural language is essential for robotic scene understanding. The descriptions often involve multiple spatial relationships to distinguish similar objects, making 3D-language alignment difficult. Current methods only model relationships for pairwise objects, ignoring the global perceptual significance of n-ary combinations in multi-modal relational understanding. To address this, we propose a novel progressive relational learning framework for 3D object grounding. We extend relational learning from binary to n-ary to identify visual relations that match the referential description globally. Given the absence of specific annotations for referred objects in the training data, we design a grouped supervision loss to facilitate n-ary relational learning. In the scene graph created with n-ary relationships, we use a multi-modal network with hybrid attention mechanisms to further localize the target within the n-ary combinations. Experiments and ablation studies on the ReferIt3D and ScanRefer benchmarks demonstrate that our method outperforms the state-of-the-art, and proves the advantages of the n-ary relational perception in 3D localization.

