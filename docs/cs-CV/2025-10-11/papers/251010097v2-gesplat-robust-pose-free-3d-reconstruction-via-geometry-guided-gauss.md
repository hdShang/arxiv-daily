---
layout: default
title: Gesplat: Robust Pose-Free 3D Reconstruction via Geometry-Guided Gaussian Splatting
---

# Gesplat: Robust Pose-Free 3D Reconstruction via Geometry-Guided Gaussian Splatting

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.10097" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.10097v2</a>
  <a href="https://arxiv.org/pdf/2510.10097.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.10097v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.10097v2', 'Gesplat: Robust Pose-Free 3D Reconstruction via Geometry-Guided Gaussian Splatting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiahui Lu, Haihong Xiao, Xueyan Zhao, Wenxiong Kang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-11 (æ›´æ–°: 2025-10-27)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Gesplatï¼šåŸºäºå‡ ä½•å¼•å¯¼é«˜æ–¯æº…å°„çš„é²æ£’æ— å§¿æ€3Dé‡å»º**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `3Dé‡å»º` `æ–°è§†è§’åˆæˆ` `é«˜æ–¯æº…å°„` `æ— å§¿æ€ä¼°è®¡` `ç¨€ç–è§†å›¾` `å‡ ä½•ä¸€è‡´æ€§` `æ·±åº¦æ­£åˆ™åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰NeRFå’Œ3DGSæ–¹æ³•ä¾èµ–ç²¾ç¡®ç›¸æœºå§¿æ€å’Œå¯†é›†è§†ç‚¹ï¼Œåœ¨ç¨€ç–è§†å›¾ä¸‹é‡å»ºæ•ˆæœå·®ï¼Œå§¿æ€ä¼°è®¡ä¸å¯é ã€‚
2. Gesplatåˆ©ç”¨VGGTæ¨¡å‹åˆå§‹åŒ–å§¿æ€å’Œç‚¹äº‘ï¼Œå¹¶æå‡ºæ··åˆé«˜æ–¯è¡¨ç¤ºã€å›¾å¼•å¯¼å±æ€§ç»†åŒ–å’ŒæµåŸºæ·±åº¦æ­£åˆ™åŒ–ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒGesplatåœ¨ç¨€ç–è§†å›¾ä¸‹ï¼Œç›¸æ¯”å…¶ä»–æ— å§¿æ€æ–¹æ³•ï¼Œåœ¨é‡å»ºè´¨é‡å’Œé²æ£’æ€§ä¸Šå‡æœ‰æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç¥ç»è¾å°„åœº(NeRF)å’Œ3Dé«˜æ–¯æº…å°„(3DGS)åœ¨3Dé‡å»ºå’Œæ–°è§†è§’åˆæˆæ–¹é¢å–å¾—äº†è¿›å±•ï¼Œä½†ä»ç„¶ä¸¥é‡ä¾èµ–äºç²¾ç¡®çš„ç›¸æœºå§¿æ€å’Œå¯†é›†çš„è§†ç‚¹è¦†ç›–ã€‚è¿™äº›è¦æ±‚é™åˆ¶äº†å®ƒä»¬åœ¨ç¨€ç–è§†å›¾è®¾ç½®ä¸­çš„é€‚ç”¨æ€§ï¼Œåœ¨è¿™äº›è®¾ç½®ä¸­ï¼Œå§¿æ€ä¼°è®¡å˜å¾—ä¸å¯é ï¼Œå¹¶ä¸”ç›‘ç£ä¸è¶³ã€‚ä¸ºäº†å…‹æœè¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†Gesplatï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäº3DGSçš„æ¡†æ¶ï¼Œå®ƒèƒ½å¤Ÿä»æ— å§¿æ€çš„ç¨€ç–å›¾åƒä¸­å®ç°é²æ£’çš„æ–°è§†è§’åˆæˆå’Œå‡ ä½•ä¸€è‡´çš„é‡å»ºã€‚ä¸å…ˆå‰ä¾èµ–COLMAPè¿›è¡Œç¨€ç–ç‚¹äº‘åˆå§‹åŒ–çš„å·¥ä½œä¸åŒï¼Œæˆ‘ä»¬åˆ©ç”¨VGGTåŸºç¡€æ¨¡å‹æ¥è·å¾—æ›´å¯é çš„åˆå§‹å§¿æ€å’Œå¯†é›†ç‚¹äº‘ã€‚æˆ‘ä»¬çš„æ–¹æ³•é›†æˆäº†å‡ ä¸ªå…³é”®åˆ›æ–°ï¼š1)ä¸€ç§æ··åˆé«˜æ–¯è¡¨ç¤ºï¼Œå…·æœ‰åŒä½ç½®-å½¢çŠ¶ä¼˜åŒ–ï¼Œå¹¶é€šè¿‡è§†å›¾é—´åŒ¹é…ä¸€è‡´æ€§å¢å¼ºï¼›2)ä¸€ä¸ªå›¾å¼•å¯¼å±æ€§ç»†åŒ–æ¨¡å—ï¼Œä»¥å¢å¼ºåœºæ™¯ç»†èŠ‚ï¼›3)åŸºäºæµçš„æ·±åº¦æ­£åˆ™åŒ–ï¼Œæé«˜äº†æ·±åº¦ä¼°è®¡çš„å‡†ç¡®æ€§ï¼Œä»è€Œå®ç°äº†æ›´æœ‰æ•ˆçš„ç›‘ç£ã€‚å…¨é¢çš„å®šé‡å’Œå®šæ€§å®éªŒè¡¨æ˜ï¼Œä¸å…¶ä»–æ— å§¿æ€æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å‰å‘å’Œå¤§è§„æ¨¡å¤æ‚æ•°æ®é›†ä¸Šéƒ½å®ç°äº†æ›´é²æ£’çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åœ¨ç¨€ç–è§†å›¾æ¡ä»¶ä¸‹ï¼Œç”±äºç›¸æœºå§¿æ€ä¼°è®¡ä¸å‡†ç¡®å’Œç›‘ç£ä¿¡æ¯ä¸è¶³ï¼Œå¯¼è‡´NeRFå’Œ3DGSç­‰æ–¹æ³•åœ¨3Dé‡å»ºå’Œæ–°è§†è§’åˆæˆä¸­æ€§èƒ½ä¸‹é™çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–COLMAPè¿›è¡Œåˆå§‹åŒ–ï¼Œä½†åœ¨ç¨€ç–è§†å›¾ä¸‹ï¼ŒCOLMAPç”Ÿæˆçš„ç‚¹äº‘è´¨é‡è¾ƒå·®ï¼Œå½±å“åç»­é‡å»ºæ•ˆæœã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨VGGTç­‰é¢„è®­ç»ƒæ¨¡å‹æä¾›æ›´å¯é çš„åˆå§‹å§¿æ€å’Œå¯†é›†ç‚¹äº‘ï¼Œå¹¶ç»“åˆå‡ ä½•çº¦æŸå’Œæ·±åº¦æ­£åˆ™åŒ–æ¥æé«˜é‡å»ºçš„é²æ£’æ€§å’Œå‡ ä½•ä¸€è‡´æ€§ã€‚é€šè¿‡å¼•å…¥æ–°çš„é«˜æ–¯è¡¨ç¤ºå’Œä¼˜åŒ–ç­–ç•¥ï¼Œä»¥åŠå›¾å¼•å¯¼çš„å±æ€§ç»†åŒ–æ¨¡å—ï¼Œå¢å¼ºåœºæ™¯ç»†èŠ‚çš„é‡å»ºèƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šGesplatæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) ä½¿ç”¨VGGTæ¨¡å‹è¿›è¡Œåˆå§‹å§¿æ€ä¼°è®¡å’Œå¯†é›†ç‚¹äº‘ç”Ÿæˆï¼›2) åˆå§‹åŒ–3Dé«˜æ–¯è¡¨ç¤ºï¼Œå¹¶è¿›è¡ŒåŒä½ç½®-å½¢çŠ¶ä¼˜åŒ–ï¼ŒåŒæ—¶åˆ©ç”¨è§†å›¾é—´åŒ¹é…ä¸€è‡´æ€§è¿›è¡Œå¢å¼ºï¼›3) ä½¿ç”¨å›¾å¼•å¯¼å±æ€§ç»†åŒ–æ¨¡å—æ¥å¢å¼ºåœºæ™¯ç»†èŠ‚ï¼›4) ä½¿ç”¨åŸºäºæµçš„æ·±åº¦æ­£åˆ™åŒ–æ¥æé«˜æ·±åº¦ä¼°è®¡çš„å‡†ç¡®æ€§ï¼Œä»è€Œæä¾›æ›´æœ‰æ•ˆçš„ç›‘ç£ä¿¡å·ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°ç‚¹åœ¨äºï¼š1) ä½¿ç”¨VGGTç­‰é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå§¿æ€åˆå§‹åŒ–ï¼Œé¿å…äº†å¯¹COLMAPçš„ä¾èµ–ï¼Œæé«˜äº†åœ¨ç¨€ç–è§†å›¾ä¸‹çš„é²æ£’æ€§ï¼›2) æå‡ºäº†æ··åˆé«˜æ–¯è¡¨ç¤ºï¼Œå¹¶ç»“åˆåŒä½ç½®-å½¢çŠ¶ä¼˜åŒ–å’Œè§†å›¾é—´åŒ¹é…ä¸€è‡´æ€§ï¼Œæé«˜äº†é‡å»ºè´¨é‡ï¼›3) å¼•å…¥äº†å›¾å¼•å¯¼å±æ€§ç»†åŒ–æ¨¡å—ï¼Œå¢å¼ºäº†åœºæ™¯ç»†èŠ‚çš„é‡å»ºèƒ½åŠ›ï¼›4) ä½¿ç”¨åŸºäºæµçš„æ·±åº¦æ­£åˆ™åŒ–ï¼Œæé«˜äº†æ·±åº¦ä¼°è®¡çš„å‡†ç¡®æ€§ï¼Œä»è€Œæä¾›äº†æ›´æœ‰æ•ˆçš„ç›‘ç£ä¿¡å·ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼šæ··åˆé«˜æ–¯è¡¨ç¤ºçš„å…·ä½“å½¢å¼ï¼ˆæœªçŸ¥ï¼‰ï¼ŒåŒä½ç½®-å½¢çŠ¶ä¼˜åŒ–çš„æŸå¤±å‡½æ•°è®¾è®¡ï¼ˆæœªçŸ¥ï¼‰ï¼Œå›¾å¼•å¯¼å±æ€§ç»†åŒ–æ¨¡å—çš„ç½‘ç»œç»“æ„å’Œè®­ç»ƒæ–¹å¼ï¼ˆæœªçŸ¥ï¼‰ï¼Œä»¥åŠåŸºäºæµçš„æ·±åº¦æ­£åˆ™åŒ–çš„å…·ä½“å®ç°æ–¹å¼ï¼ˆæœªçŸ¥ï¼‰ã€‚è¿™äº›ç»†èŠ‚å…±åŒæ„æˆäº†Gesplatæ¡†æ¶çš„æ ¸å¿ƒæŠ€æœ¯æ”¯æ’‘ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡é€šè¿‡å¤§é‡å®éªŒéªŒè¯äº†Gesplatçš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ç¨€ç–è§†å›¾æ¡ä»¶ä¸‹ï¼ŒGesplatç›¸æ¯”äºå…¶ä»–æ— å§¿æ€é‡å»ºæ–¹æ³•ï¼Œåœ¨é‡å»ºè´¨é‡å’Œé²æ£’æ€§ä¸Šå‡æœ‰æ˜¾è‘—æå‡ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦åœ¨æ‘˜è¦ä¸­æœªæ˜ç¡®ç»™å‡ºï¼Œéœ€è¦åœ¨è®ºæ–‡æ­£æ–‡ä¸­æŸ¥æ‰¾ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

GesplatæŠ€æœ¯å¯åº”ç”¨äºæœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ã€è™šæ‹Ÿç°å®/å¢å¼ºç°å®ç­‰é¢†åŸŸã€‚åœ¨è¿™äº›åœºæ™¯ä¸­ï¼Œé€šå¸¸éš¾ä»¥è·å–å¯†é›†çš„å›¾åƒæ•°æ®å’Œç²¾ç¡®çš„ç›¸æœºå§¿æ€ã€‚Gesplatçš„é²æ£’æ— å§¿æ€é‡å»ºèƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨è¿™äº›æŒ‘æˆ˜æ€§ç¯å¢ƒä¸­å®ç°é«˜è´¨é‡çš„3Dåœºæ™¯é‡å»ºå’Œæ–°è§†è§’åˆæˆï¼Œå…·æœ‰é‡è¦çš„å®é™…åº”ç”¨ä»·å€¼å’Œå¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) have advanced 3D reconstruction and novel view synthesis, but remain heavily dependent on accurate camera poses and dense viewpoint coverage. These requirements limit their applicability in sparse-view settings, where pose estimation becomes unreliable and supervision is insufficient. To overcome these challenges, we introduce Gesplat, a 3DGS-based framework that enables robust novel view synthesis and geometrically consistent reconstruction from unposed sparse images. Unlike prior works that rely on COLMAP for sparse point cloud initialization, we leverage the VGGT foundation model to obtain more reliable initial poses and dense point clouds. Our approach integrates several key innovations: 1) a hybrid Gaussian representation with dual position-shape optimization enhanced by inter-view matching consistency; 2) a graph-guided attribute refinement module to enhance scene details; and 3) flow-based depth regularization that improves depth estimation accuracy for more effective supervision. Comprehensive quantitative and qualitative experiments demonstrate that our approach achieves more robust performance on both forward-facing and large-scale complex datasets compared to other pose-free methods.

