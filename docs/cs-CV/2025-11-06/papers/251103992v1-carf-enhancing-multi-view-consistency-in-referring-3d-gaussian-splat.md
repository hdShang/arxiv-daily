---
layout: default
title: CaRF: Enhancing Multi-View Consistency in Referring 3D Gaussian Splatting Segmentation
---

# CaRF: Enhancing Multi-View Consistency in Referring 3D Gaussian Splatting Segmentation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.03992" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.03992v1</a>
  <a href="https://arxiv.org/pdf/2511.03992.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.03992v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.03992v1', 'CaRF: Enhancing Multi-View Consistency in Referring 3D Gaussian Splatting Segmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuwen Tao, Kanglei Zhou, Xin Tan, Yuan Xie

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-06

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**CaRFï¼šé€šè¿‡å¢å¼ºå¤šè§†è§’ä¸€è‡´æ€§æ”¹è¿›Referring 3Dé«˜æ–¯æº…å°„åˆ†å‰²**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `Referring 3Dåˆ†å‰²` `é«˜æ–¯æº…å°„` `å¤šè§†è§’ä¸€è‡´æ€§` `ç›¸æœºæ„ŸçŸ¥` `è·¨æ¨¡æ€å¯¹é½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰Referring 3Dé«˜æ–¯æº…å°„åˆ†å‰²æ–¹æ³•ä¾èµ–2Dæ¸²æŸ“ä¼ªç›‘ç£ï¼Œå¯¼è‡´è§†è§’ä¸ä¸€è‡´ï¼Œé™åˆ¶äº†åˆ†å‰²æ€§èƒ½ã€‚
2. CaRFé€šè¿‡å¼•å…¥ç›¸æœºæ„ŸçŸ¥çš„é«˜æ–¯åœºç¼–ç å’Œè®­ç»ƒæ—¶é…å¯¹è§†è§’ç›‘ç£ï¼Œç›´æ¥åœ¨3Dé«˜æ–¯ç©ºé—´ä¸­å®ç°å¤šè§†è§’ä¸€è‡´æ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒCaRFåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæ˜¾è‘—æå‡äº†Referring 3Dåˆ†å‰²çš„mIoUï¼Œä¼˜äºç°æœ‰æŠ€æœ¯æ°´å¹³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

Referring 3D Gaussian Splatting Segmentation (R3DGS) æ—¨åœ¨è§£æè‡ªç”±å½¢å¼çš„è¯­è¨€è¡¨è¾¾ï¼Œå¹¶åœ¨é«˜æ–¯åœºä¸­å®šä½ç›¸åº”çš„ 3D åŒºåŸŸã€‚å°½ç®¡æœ€è¿‘çš„ç ”ç©¶åœ¨è¯­è¨€å’Œ 3D å‡ ä½•ä¹‹é—´å¼•å…¥äº†è·¨æ¨¡æ€å¯¹é½ï¼Œä½†ç”±äºç°æœ‰æµç¨‹ä¾èµ–äº 2D æ¸²æŸ“çš„ä¼ªç›‘ç£å’Œç‰¹å®šè§†è§’çš„ç‰¹å¾å­¦ä¹ ï¼Œå› æ­¤ä»ç„¶éš¾ä»¥å®ç°è·¨è§†è§’ä¸€è‡´æ€§ã€‚æœ¬æ–‡æå‡ºäº† Camera Aware Referring Field (CaRF)ï¼Œè¿™æ˜¯ä¸€ä¸ªå®Œå…¨å¯å¾®çš„æ¡†æ¶ï¼Œç›´æ¥åœ¨é«˜æ–¯ 3D ç©ºé—´ä¸­è¿è¡Œå¹¶å®ç°å¤šè§†è§’ä¸€è‡´æ€§ã€‚å…·ä½“æ¥è¯´ï¼ŒCaRF å¼•å…¥äº† Gaussian Field Camera Encoding (GFCE)ï¼Œå®ƒå°†ç›¸æœºå‡ ä½•ä¿¡æ¯èå…¥é«˜æ–¯æ–‡æœ¬äº¤äº’ä¸­ï¼Œä»¥æ˜¾å¼åœ°å»ºæ¨¡è§†è§’ç›¸å…³çš„å˜åŒ–å¹¶å¢å¼ºå‡ ä½•æ¨ç†ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæå‡ºäº† In Training Paired View Supervision (ITPVS)ï¼Œç”¨äºåœ¨è®­ç»ƒæœŸé—´å¯¹é½æ ¡å‡†è§†è§’ä¹‹é—´çš„æ¯ä¸ªé«˜æ–¯é€»è¾‘å€¼ï¼Œä»è€Œæœ‰æ•ˆåœ°ç¼“è§£å•è§†è§’è¿‡æ‹Ÿåˆï¼Œå¹¶æš´éœ²è§†è§’é—´çš„å·®å¼‚ä»¥è¿›è¡Œä¼˜åŒ–ã€‚åœ¨ä¸‰ä¸ªä»£è¡¨æ€§åŸºå‡†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒCaRF åœ¨ Ref LERFã€LERF OVS å’Œ 3D OVS æ•°æ®é›†ä¸Šï¼Œç›¸å¯¹äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå¹³å‡ mIoU åˆ†åˆ«æé«˜äº† 16.8%ã€4.3% å’Œ 2.0%ã€‚æ­¤å¤–ï¼Œè¿™é¡¹å·¥ä½œä¿ƒè¿›äº†æ›´å¯é å’Œè§†è§’ä¸€è‡´çš„ 3D åœºæ™¯ç†è§£ï¼Œå¹¶ä¸ºå…·èº« AIã€AR/VR äº¤äº’å’Œè‡ªä¸»æ„ŸçŸ¥å¸¦æ¥äº†æ½œåœ¨çš„å¥½å¤„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰Referring 3Dé«˜æ–¯æº…å°„åˆ†å‰²æ–¹æ³•åœ¨å¤„ç†è·¨è§†è§’ä¸€è‡´æ€§æ–¹é¢å­˜åœ¨å›°éš¾ã€‚å®ƒä»¬ä¾èµ–äºä»2Dæ¸²æŸ“å›¾åƒè·å¾—çš„ä¼ªæ ‡ç­¾è¿›è¡Œè®­ç»ƒï¼Œè¿™å¯¼è‡´æ¨¡å‹å­¦ä¹ åˆ°è§†è§’ç›¸å…³çš„ç‰¹å¾ï¼Œä»è€Œåœ¨ä¸åŒè§†è§’ä¸‹äº§ç”Ÿä¸ä¸€è‡´çš„åˆ†å‰²ç»“æœã€‚è¿™ç§ä¸ä¸€è‡´æ€§é™åˆ¶äº†æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„å¯é æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šCaRFçš„æ ¸å¿ƒæ€è·¯æ˜¯åœ¨3Dé«˜æ–¯ç©ºé—´ä¸­ç›´æ¥è¿›è¡Œæ¨ç†å’Œå­¦ä¹ ï¼Œé¿å…ä¾èµ–2Dæ¸²æŸ“çš„ä¼ªæ ‡ç­¾ã€‚é€šè¿‡å¼•å…¥ç›¸æœºæ„ŸçŸ¥çš„ç¼–ç æ–¹å¼ï¼Œå°†ç›¸æœºå‡ ä½•ä¿¡æ¯èå…¥åˆ°é«˜æ–¯ç‰¹å¾ä¸­ï¼Œä»è€Œæ˜¾å¼åœ°å»ºæ¨¡è§†è§’ç›¸å…³çš„å˜åŒ–ã€‚æ­¤å¤–ï¼Œé€šè¿‡åœ¨è®­ç»ƒæ—¶å¯¹é½ä¸åŒè§†è§’ä¸‹çš„é«˜æ–¯ç‰¹å¾ï¼Œè¿›ä¸€æ­¥å¢å¼ºæ¨¡å‹çš„å¤šè§†è§’ä¸€è‡´æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCaRFæ¡†æ¶ä¸»è¦åŒ…å«ä¸¤ä¸ªæ ¸å¿ƒæ¨¡å—ï¼šGaussian Field Camera Encoding (GFCE) å’Œ In Training Paired View Supervision (ITPVS)ã€‚GFCEæ¨¡å—å°†ç›¸æœºå‚æ•°ï¼ˆå¦‚ä½ç½®å’Œæ–¹å‘ï¼‰ç¼–ç åˆ°æ¯ä¸ªé«˜æ–¯ç²’å­çš„ç‰¹å¾ä¸­ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ„ŸçŸ¥è§†è§’ä¿¡æ¯ã€‚ITPVSæ¨¡å—åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå¯¹æ¥è‡ªä¸åŒè§†è§’çš„åŒä¸€é«˜æ–¯ç²’å­çš„é¢„æµ‹ç»“æœè¿›è¡Œå¯¹é½ï¼Œä»è€Œå¢å¼ºæ¨¡å‹çš„å¤šè§†è§’ä¸€è‡´æ€§ã€‚æ•´ä½“æµç¨‹æ˜¯ï¼Œé¦–å…ˆä½¿ç”¨GFCEå¯¹é«˜æ–¯ç‰¹å¾è¿›è¡Œç¼–ç ï¼Œç„¶åä½¿ç”¨ITPVSè¿›è¡Œè®­ç»ƒï¼Œæœ€ç»ˆå¾—åˆ°å…·æœ‰å¤šè§†è§’ä¸€è‡´æ€§çš„åˆ†å‰²ç»“æœã€‚

**å…³é”®åˆ›æ–°**ï¼šCaRFçš„å…³é”®åˆ›æ–°åœ¨äºå…¶å®Œå…¨åœ¨3Dé«˜æ–¯ç©ºé—´ä¸­è¿›è¡Œæ¨ç†å’Œå­¦ä¹ ï¼Œé¿å…äº†å¯¹2Dæ¸²æŸ“çš„ä¾èµ–ã€‚GFCEæ¨¡å—æ˜¾å¼åœ°å»ºæ¨¡äº†è§†è§’ç›¸å…³çš„å˜åŒ–ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£3Dåœºæ™¯çš„å‡ ä½•ä¿¡æ¯ã€‚ITPVSæ¨¡å—é€šè¿‡å¯¹é½ä¸åŒè§†è§’çš„é¢„æµ‹ç»“æœï¼Œæœ‰æ•ˆåœ°å¢å¼ºäº†æ¨¡å‹çš„å¤šè§†è§’ä¸€è‡´æ€§ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒCaRFèƒ½å¤Ÿæ›´å‡†ç¡®åœ°åˆ†å‰²3Dåœºæ™¯ä¸­çš„ç›®æ ‡ç‰©ä½“ï¼Œå¹¶ä¸”åœ¨ä¸åŒè§†è§’ä¸‹å…·æœ‰æ›´é«˜çš„é²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šGFCEæ¨¡å—ä½¿ç”¨ä¸€ä¸ªå°å‹ç¥ç»ç½‘ç»œå°†ç›¸æœºå‚æ•°ç¼–ç ä¸ºé«˜æ–¯ç‰¹å¾çš„é™„åŠ å‘é‡ã€‚ITPVSæ¨¡å—ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°æ¥å¯¹é½ä¸åŒè§†è§’ä¸‹çš„é«˜æ–¯é€»è¾‘å€¼ã€‚å…·ä½“æ¥è¯´ï¼Œå¯¹äºæ¯ä¸ªé«˜æ–¯ç²’å­ï¼Œä»ä¸¤ä¸ªä¸åŒçš„è§†è§’æ¸²æŸ“å¾—åˆ°ä¸¤ä¸ªé€»è¾‘å€¼å‘é‡ï¼Œç„¶åè®¡ç®—è¿™ä¸¤ä¸ªå‘é‡ä¹‹é—´çš„äº¤å‰ç†µæŸå¤±ï¼Œå¹¶å°†å…¶ä½œä¸ºè®­ç»ƒç›®æ ‡ä¹‹ä¸€ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜ä½¿ç”¨äº†æ ‡å‡†çš„é«˜æ–¯æº…å°„æ¸²æŸ“æŠ€æœ¯å’Œè¯­è¨€ç¼–ç å™¨æ¥æå–æ–‡æœ¬ç‰¹å¾ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

CaRFåœ¨Ref LERFã€LERF OVSå’Œ3D OVSä¸‰ä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼ŒCaRFæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼ŒCaRFåœ¨Ref LERFæ•°æ®é›†ä¸Šå–å¾—äº†16.8%çš„mIoUæå‡ï¼Œåœ¨LERF OVSæ•°æ®é›†ä¸Šå–å¾—äº†4.3%çš„mIoUæå‡ï¼Œåœ¨3D OVSæ•°æ®é›†ä¸Šå–å¾—äº†2.0%çš„mIoUæå‡ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒCaRFèƒ½å¤Ÿæœ‰æ•ˆåœ°æé«˜Referring 3Dåˆ†å‰²çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

CaRFåœ¨å…·èº«AIã€AR/VRäº¤äº’å’Œè‡ªä¸»æ„ŸçŸ¥ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚ä¾‹å¦‚ï¼Œåœ¨æœºå™¨äººå¯¼èˆªä¸­ï¼Œæœºå™¨äººå¯ä»¥åˆ©ç”¨CaRFæ¥ç†è§£äººç±»çš„æŒ‡ä»¤ï¼Œå¹¶åœ¨3Dç¯å¢ƒä¸­å®šä½ç›®æ ‡ç‰©ä½“ã€‚åœ¨AR/VRåº”ç”¨ä¸­ï¼ŒCaRFå¯ä»¥ç”¨äºå¢å¼ºç”¨æˆ·ä¸è™šæ‹Ÿç¯å¢ƒçš„äº¤äº’ä½“éªŒï¼Œä¾‹å¦‚ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡è¯­éŸ³æŒ‡ä»¤æ¥æ“ä½œè™šæ‹Ÿç‰©ä½“ã€‚åœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼ŒCaRFå¯ä»¥ç”¨äºè¯†åˆ«å’Œåˆ†å‰²é“è·¯ä¸Šçš„äº¤é€šæ ‡å¿—å’Œè¡Œäººï¼Œä»è€Œæé«˜é©¾é©¶å®‰å…¨æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Referring 3D Gaussian Splatting Segmentation (R3DGS) aims to interpret free-form language expressions and localize the corresponding 3D regions in Gaussian fields. While recent advances have introduced cross-modal alignment between language and 3D geometry, existing pipelines still struggle with cross-view consistency due to their reliance on 2D rendered pseudo supervision and view specific feature learning. In this work, we present Camera Aware Referring Field (CaRF), a fully differentiable framework that operates directly in the 3D Gaussian space and achieves multi view consistency. Specifically, CaRF introduces Gaussian Field Camera Encoding (GFCE), which incorporates camera geometry into Gaussian text interactions to explicitly model view dependent variations and enhance geometric reasoning. Building on this, In Training Paired View Supervision (ITPVS) is proposed to align per Gaussian logits across calibrated views during training, effectively mitigating single view overfitting and exposing inter view discrepancies for optimization. Extensive experiments on three representative benchmarks demonstrate that CaRF achieves average improvements of 16.8%, 4.3%, and 2.0% in mIoU over state of the art methods on the Ref LERF, LERF OVS, and 3D OVS datasets, respectively. Moreover, this work promotes more reliable and view consistent 3D scene understanding, with potential benefits for embodied AI, AR/VR interaction, and autonomous perception.

