---
layout: default
title: IKMo: Image-Keyframed Motion Generation with Trajectory-Pose Conditioned Motion Diffusion Model
---

# IKMo: Image-Keyframed Motion Generation with Trajectory-Pose Conditioned Motion Diffusion Model

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21146" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21146v1</a>
  <a href="https://arxiv.org/pdf/2505.21146.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21146v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21146v1', 'IKMo: Image-Keyframed Motion Generation with Trajectory-Pose Conditioned Motion Diffusion Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yang Zhao, Yan Zhang, Xubo Yang

**åˆ†ç±»**: cs.GR, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºIKMoä»¥è§£å†³ç°æœ‰äººä½“åŠ¨ä½œç”Ÿæˆçš„å±€é™æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)**

**å…³é”®è¯**: `äººä½“åŠ¨ä½œç”Ÿæˆ` `æ‰©æ•£æ¨¡å‹` `å¤šæ¨¡æ€èåˆ` `è½¨è¿¹è§£è€¦` `å§¿æ€ç¼–ç ` `ç”¨æˆ·ç ”ç©¶` `åŠ¨ç”»åˆ¶ä½œ` `è™šæ‹Ÿç°å®`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤„ç†è½¨è¿¹å’Œå§¿æ€è¾“å…¥æ—¶ï¼Œé€šå¸¸é‡‡ç”¨å…¨å±€å¤„ç†ï¼Œå¯¼è‡´ç”Ÿæˆçš„åŠ¨ä½œè´¨é‡ä¸é«˜ã€‚
2. IKMoé€šè¿‡è§£è€¦è½¨è¿¹å’Œå§¿æ€è¾“å…¥ï¼Œé‡‡ç”¨ä¸¤é˜¶æ®µæ¡ä»¶æ¡†æ¶ï¼Œæå‡äº†åŠ¨ä½œç”Ÿæˆçš„ç²¾åº¦å’Œå¯æ§æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒIKMoåœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šè¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œä¸”ç”¨æˆ·ç ”ç©¶è¡¨æ˜ç”Ÿæˆç»“æœæ›´ç¬¦åˆç”¨æˆ·æœŸæœ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°æœ‰çš„äººä½“åŠ¨ä½œç”Ÿæˆæ–¹æ³•åœ¨å¤„ç†è½¨è¿¹å’Œå§¿æ€è¾“å…¥æ—¶ï¼Œé€šå¸¸å¯¹ä¸¤ç§æ¨¡æ€è¿›è¡Œå…¨å±€å¤„ç†ï¼Œå¯¼è‡´è¾“å‡ºæ•ˆæœä¸ä½³ã€‚æœ¬æ–‡æå‡ºIKMoï¼Œä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒå…³é”®å¸§åŠ¨ä½œç”Ÿæˆæ–¹æ³•ï¼Œé€šè¿‡è§£è€¦è½¨è¿¹å’Œå§¿æ€è¾“å…¥ï¼Œé‡‡ç”¨ä¸¤é˜¶æ®µæ¡ä»¶æ¡†æ¶è¿›è¡Œå¤„ç†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒIKMoåœ¨HumanML3Då’ŒKIT-MLæ•°æ®é›†ä¸Šï¼Œåœ¨æ‰€æœ‰æŒ‡æ ‡ä¸‹å‡ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚æ­¤å¤–ï¼ŒåŸºäºMLLMçš„ä»£ç†è¢«å®ç°ç”¨äºé¢„å¤„ç†æ¨¡å‹è¾“å…¥ï¼Œç”¨æˆ·æä¾›æ–‡æœ¬å’Œå…³é”®å¸§å›¾åƒåï¼Œä»£ç†æå–è¿åŠ¨æè¿°ã€å…³é”®å¸§å§¿æ€å’Œè½¨è¿¹ï¼Œä½œä¸ºä¼˜åŒ–è¾“å…¥ã€‚ç”¨æˆ·ç ”ç©¶æ˜¾ç¤ºï¼ŒMLLMä»£ç†çš„é¢„å¤„ç†ä½¿ç”Ÿæˆçš„åŠ¨ä½œæ›´ç¬¦åˆç”¨æˆ·æœŸæœ›ã€‚æˆ‘ä»¬ç›¸ä¿¡ï¼Œè¯¥æ–¹æ³•æé«˜äº†åŸºäºæ‰©æ•£æ¨¡å‹çš„åŠ¨ä½œç”Ÿæˆçš„ä¿çœŸåº¦å’Œå¯æ§æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰çš„äººä½“åŠ¨ä½œç”Ÿæˆæ–¹æ³•åœ¨è½¨è¿¹å’Œå§¿æ€è¾“å…¥å¤„ç†ä¸Šçš„å±€é™æ€§ï¼Œå°¤å…¶æ˜¯å…¨å±€å¤„ç†å¯¼è‡´çš„è¾“å‡ºè´¨é‡ä¸ä½³çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šIKMoé€šè¿‡è§£è€¦è½¨è¿¹å’Œå§¿æ€è¾“å…¥ï¼Œé‡‡ç”¨ä¸¤é˜¶æ®µæ¡ä»¶æ¡†æ¶ï¼Œåˆ†åˆ«ä¼˜åŒ–å’Œç¼–ç è¿™ä¸¤ç§è¾“å…¥ï¼Œä»¥æé«˜ç”ŸæˆåŠ¨ä½œçš„ç©ºé—´å’Œè¯­ä¹‰ä¿çœŸåº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µä½¿ç”¨ä¸“é—¨çš„ä¼˜åŒ–æ¨¡å—å¯¹è¾“å…¥è¿›è¡Œç²¾ç»†åŒ–å¤„ç†ï¼›ç¬¬äºŒé˜¶æ®µåˆ™é€šè¿‡è½¨è¿¹ç¼–ç å™¨å’Œå§¿æ€ç¼–ç å™¨å¹¶è¡Œç¼–ç è½¨è¿¹å’Œå§¿æ€æ•°æ®ï¼Œæœ€ç»ˆç”±è¿åŠ¨æ§åˆ¶ç½‘ç»œå¤„ç†èåˆåçš„æ•°æ®ç”ŸæˆåŠ¨ä½œã€‚

**å…³é”®åˆ›æ–°**ï¼šIKMoçš„ä¸»è¦åˆ›æ–°åœ¨äºå°†è½¨è¿¹å’Œå§¿æ€è¾“å…¥è§£è€¦ï¼Œå¹¶é€šè¿‡ä¸¤é˜¶æ®µçš„æ¡ä»¶æ¡†æ¶è¿›è¡Œå¤„ç†ï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„å…¨å±€å¤„ç†æ–¹å¼å½¢æˆäº†æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸Šï¼ŒIKMoå¼•å…¥äº†ä¸“é—¨çš„ä¼˜åŒ–æ¨¡å—å’Œä¸¤ä¸ªç‹¬ç«‹çš„ç¼–ç å™¨ï¼Œç¡®ä¿è½¨è¿¹å’Œå§¿æ€ä¿¡æ¯çš„ç‹¬ç«‹æ€§å’Œæœ‰æ•ˆæ€§ï¼ŒåŒæ—¶ä½¿ç”¨è¿åŠ¨æ§åˆ¶ç½‘ç»œæ¥æŒ‡å¯¼ç”Ÿæˆè¿‡ç¨‹ï¼Œæå‡äº†ç”ŸæˆåŠ¨ä½œçš„è´¨é‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒIKMoåœ¨HumanML3Då’ŒKIT-MLæ•°æ®é›†ä¸Šï¼Œåœ¨æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡ä¸Šå‡è¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå…·ä½“æå‡å¹…åº¦æœªçŸ¥ã€‚æ­¤å¤–ï¼Œç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼Œä½¿ç”¨MLLMä»£ç†è¿›è¡Œé¢„å¤„ç†åï¼Œç”Ÿæˆçš„åŠ¨ä½œæ›´ç¬¦åˆç”¨æˆ·çš„æœŸæœ›ï¼Œè¿›ä¸€æ­¥éªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨åŠ¨ç”»åˆ¶ä½œã€è™šæ‹Ÿç°å®å’Œæ¸¸æˆå¼€å‘ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æé«˜åŠ¨ä½œç”Ÿæˆçš„ä¿çœŸåº¦å’Œå¯æ§æ€§ï¼ŒIKMoå¯ä»¥å¸®åŠ©å¼€å‘è€…æ›´é«˜æ•ˆåœ°åˆ›å»ºè‡ªç„¶æµç•…çš„äººç‰©åŠ¨ä½œï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚æ­¤å¤–ï¼Œæœªæ¥å¯èƒ½åœ¨æœºå™¨äººæ§åˆ¶å’Œäººæœºäº¤äº’ç­‰é¢†åŸŸä¹Ÿèƒ½å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Existing human motion generation methods with trajectory and pose inputs operate global processing on both modalities, leading to suboptimal outputs. In this paper, we propose IKMo, an image-keyframed motion generation method based on the diffusion model with trajectory and pose being decoupled. The trajectory and pose inputs go through a two-stage conditioning framework. In the first stage, the dedicated optimization module is applied to refine inputs. In the second stage, trajectory and pose are encoded via a Trajectory Encoder and a Pose Encoder in parallel. Then, motion with high spatial and semantic fidelity is guided by a motion ControlNet, which processes the fused trajectory and pose data. Experiment results based on HumanML3D and KIT-ML datasets demonstrate that the proposed method outperforms state-of-the-art on all metrics under trajectory-keyframe constraints. In addition, MLLM-based agents are implemented to pre-process model inputs. Given texts and keyframe images from users, the agents extract motion descriptions, keyframe poses, and trajectories as the optimized inputs into the motion generation model. We conducts a user study with 10 participants. The experiment results prove that the MLLM-based agents pre-processing makes generated motion more in line with users' expectation. We believe that the proposed method improves both the fidelity and controllability of motion generation by the diffusion model.

