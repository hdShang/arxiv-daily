---
layout: default
title: MPMAvatar: Learning 3D Gaussian Avatars with Accurate and Robust Physics-Based Dynamics
---

# MPMAvatar: Learning 3D Gaussian Avatars with Accurate and Robust Physics-Based Dynamics

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.01619" target="_blank" class="toolbar-btn">arXiv: 2510.01619v1</a>
    <a href="https://arxiv.org/pdf/2510.01619.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.01619v1" 
            onclick="toggleFavorite(this, '2510.01619v1', 'MPMAvatar: Learning 3D Gaussian Avatars with Accurate and Robust Physics-Based Dynamics')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Changmin Lee, Jihyun Lee, Tae-Kyun Kim

**ÂàÜÁ±ª**: cs.GR, cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-02

**Â§áÊ≥®**: Accepted to NeurIPS 2025

**üîó ‰ª£Á†Å/È°πÁõÆ**: [PROJECT_PAGE](https://KAISTChangmin.github.io/MPMAvatar/)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**MPMAvatarÔºöÊèêÂá∫Âü∫‰∫éÁâ©ÁêÜÁöÑÁ≤æÁ°ÆÈ≤ÅÊ£í3DÈ´òÊñØAvatarÂ≠¶‰π†Ê°ÜÊû∂**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)** **ÊîØÊü±ÂõõÔºöÁîüÊàêÂºèÂä®‰Ωú (Generative Motion)**

**ÂÖ≥ÈîÆËØç**: `3D Avatar` `Áâ©ÁêÜÊ®°Êãü` `Material Point Method` `È´òÊñØÊ∫ÖÂ∞Ñ` `ÊúçË£ÖÂä®ÊÄÅ` `Â§öËßÜËßíÈáçÂª∫` `ËôöÊãüÁé∞ÂÆû`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®Ê®°Êãü‰∫∫‰ΩìÂèäÂÖ∂ÂÆΩÊùæÊúçË£ÖÁöÑÁâ©ÁêÜÂä®ÊÄÅÊñπÈù¢Â≠òÂú®Á≤æÂ∫¶ÂíåÈ≤ÅÊ£íÊÄß‰∏çË∂≥ÁöÑÊåëÊàò„ÄÇ
2. MPMAvatarÂà©Áî®Material Point MethodÊ®°ÊãüÂô®ÔºåÁªìÂêàÂêÑÂêëÂºÇÊÄßÊ®°ÂûãÂíåÁ¢∞ÊíûÂ§ÑÁêÜÔºåÂÆûÁé∞Á≤æÁ°ÆÁöÑÊúçË£ÖÂä®ÊÄÅÊ®°Êãü„ÄÇ
3. ÂÆûÈ™åËØÅÊòéMPMAvatarÂú®Âä®ÂäõÂ≠¶ÂíåÊ∏≤ÊüìÁ≤æÂ∫¶„ÄÅÈ≤ÅÊ£íÊÄßÂèäÊïàÁéá‰∏ä‰ºò‰∫éÁé∞ÊúâÊäÄÊúØÔºåÂπ∂ËÉΩÈõ∂Ê†∑Êú¨Ê≥õÂåñÂà∞Êñ∞ÁöÑ‰∫§‰∫í„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫MPMAvatarÔºå‰∏Ä‰∏™‰ªéÂ§öËßÜËßíËßÜÈ¢ëÂàõÂª∫3D‰∫∫‰ΩìAvatarÁöÑÊ°ÜÊû∂ÔºåÂÆÉÊîØÊåÅÈ´òÂ∫¶ÁúüÂÆû„ÄÅÈ≤ÅÊ£íÁöÑÂä®ÁîªÔºå‰ª•ÂèäËá™Áî±ËßÜËßíÁöÑÁÖßÁâáÁ∫ßÊ∏≤Êüì„ÄÇ‰∏∫‰∫ÜÂÆûÁé∞Á≤æÁ°ÆÂíåÈ≤ÅÊ£íÁöÑÂä®ÂäõÂ≠¶Âª∫Ê®°ÔºåÊ†∏ÂøÉÊÄùÊÉ≥ÊòØ‰ΩøÁî®Âü∫‰∫éMaterial Point Method (MPM) ÁöÑÊ®°ÊãüÂô®ÔºåÈÄöËøáÁªìÂêàÂêÑÂêëÂºÇÊÄßÊú¨ÊûÑÊ®°ÂûãÂíåÊñ∞È¢ñÁöÑÁ¢∞ÊíûÂ§ÑÁêÜÁÆóÊ≥ïÔºåÁ≤æÂøÉÂÆöÂà∂ËØ•Ê®°ÊãüÂô®‰ª•Ê®°ÊãüÂÖ∑ÊúâÂ§çÊùÇÂèòÂΩ¢ÁöÑÊúçË£Ö‰ª•Âèä‰∏éÂ∫ïÂ±ÇË∫´‰ΩìÁöÑÊé•Ëß¶„ÄÇÂ∞ÜÊ≠§Âä®ÂäõÂ≠¶Âª∫Ê®°ÊñπÊ°à‰∏é‰ΩøÁî®ÂÖ∑ÊúâÂáÜÈò¥ÂΩ±ÁöÑ3DÈ´òÊñØÊ∫ÖÂ∞ÑÊ∏≤ÊüìÁöÑËßÑËåÉAvatarÁõ∏ÁªìÂêàÔºå‰ªéËÄå‰∏∫Áâ©ÁêÜ‰∏äÈÄºÁúüÁöÑÂä®ÁîªÂÆûÁé∞È´ò‰øùÁúüÊ∏≤Êüì„ÄÇÂÆûÈ™åË°®ÊòéÔºåMPMAvatarÂú®Âä®ÂäõÂ≠¶Âª∫Ê®°Á≤æÂ∫¶„ÄÅÊ∏≤ÊüìÁ≤æÂ∫¶‰ª•ÂèäÈ≤ÅÊ£íÊÄßÂíåÊïàÁéáÊñπÈù¢ÊòæËëó‰ºò‰∫éÁé∞ÊúâÁöÑÊúÄÂÖàËøõÁöÑÂü∫‰∫éÁâ©ÁêÜÁöÑAvatar„ÄÇÊ≠§Â§ñÔºåÊú¨ÊñáËøòÂ±ïÁ§∫‰∫Ü‰∏Ä‰∏™Êñ∞È¢ñÁöÑÂ∫îÁî®ÔºåAvatarÂèØ‰ª•‰ª•Èõ∂Ê†∑Êú¨ÊñπÂºèÊé®ÂπøÂà∞Êú™ËßÅËøáÁöÑ‰∫§‰∫íÔºåËøôÂØπ‰∫é‰ª•ÂâçÂü∫‰∫éÂ≠¶‰π†ÁöÑÊñπÊ≥ïÊù•ËØ¥ÊòØÊó†Ê≥ïÂÆûÁé∞ÁöÑÔºåÂõ†‰∏∫ÂÆÉ‰ª¨ÂÖ∑ÊúâÊúâÈôêÁöÑÊ®°ÊãüÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÂü∫‰∫éËßÜËßâËßÇÊµãÁöÑ3D AvatarÂàõÂª∫ÊñπÊ≥ïÂú®Ê®°ÊãüÂÖ∑ÊúâÂÆΩÊùæÊúçË£ÖÁöÑ‰∫∫‰ΩìÁâ©ÁêÜÂä®ÊÄÅÊñπÈù¢Â≠òÂú®Âõ∞ÈöæÔºåÁ≤æÂ∫¶ÂíåÈ≤ÅÊ£íÊÄß‰∏çË∂≥ÔºåÈöæ‰ª•Ê≥õÂåñÂà∞Êñ∞ÁöÑÂä®ÁîªËæìÂÖ•„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÂà©Áî®Material Point Method (MPM) Ê®°ÊãüÂô®Êù•Á≤æÁ°ÆÂª∫Ê®°ÊúçË£ÖÁöÑÁâ©ÁêÜÂä®ÊÄÅ„ÄÇMPMËÉΩÂ§üÊúâÊïàÂ§ÑÁêÜÂ§çÊùÇÂΩ¢ÂèòÂíåÁ¢∞ÊíûÔºåÈÄöËøáÂÆöÂà∂ÂåñÁöÑMPMÊ®°ÊãüÂô®ÔºåÂèØ‰ª•Êõ¥ÁúüÂÆûÂú∞Ê®°ÊãüÊúçË£Ö‰∏é‰∫∫‰Ωì‰πãÈó¥ÁöÑ‰∫§‰∫í„ÄÇÁªìÂêàÈ´òÊñØÊ∫ÖÂ∞ÑÊ∏≤ÊüìÔºåÂÆûÁé∞ÈÄºÁúüÁöÑÊ∏≤ÊüìÊïàÊûú„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöMPMAvatarÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) Â§öËßÜËßíËßÜÈ¢ëËæìÂÖ•Ôºõ2) Âü∫‰∫éMPMÁöÑÁâ©ÁêÜÊ®°ÊãüÂô®ÔºåÁî®‰∫éÊ®°ÊãüÊúçË£ÖÁöÑÂä®ÊÄÅÔºõ3) 3DÈ´òÊñØÊ∫ÖÂ∞ÑÊ∏≤ÊüìÂô®ÔºåÁî®‰∫éÁîüÊàêÈÄºÁúüÁöÑÊ∏≤ÊüìÂõæÂÉèÔºõ4) ËßÑËåÉAvatarÊ®°ÂûãÔºå‰Ωú‰∏∫Áâ©ÁêÜÊ®°ÊãüÁöÑÂü∫Á°Ä„ÄÇÊï¥‰ΩìÊµÅÁ®ãÊòØ‰ªéÂ§öËßÜËßíËßÜÈ¢ë‰∏≠ÈáçÂª∫ËßÑËåÉAvatarÔºåÁÑ∂Âêé‰ΩøÁî®MPMÊ®°ÊãüÂô®Ê®°ÊãüÊúçË£ÖÁöÑÂä®ÊÄÅÔºåÊúÄÂêé‰ΩøÁî®È´òÊñØÊ∫ÖÂ∞ÑÊ∏≤ÊüìÂô®Ê∏≤ÊüìÊúÄÁªàÁöÑAvatarÂä®Áîª„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**Ôºö1) Â∞ÜMaterial Point MethodÂºïÂÖ•Âà∞3D AvatarÁöÑÊúçË£ÖÂä®ÊÄÅÊ®°Êãü‰∏≠ÔºåËÉΩÂ§üÊõ¥Á≤æÁ°ÆÂú∞Â§ÑÁêÜÊúçË£ÖÁöÑÂ§çÊùÇÂΩ¢ÂèòÂíåÁ¢∞Êíû„ÄÇ2) ÁªìÂêàÂêÑÂêëÂºÇÊÄßÊú¨ÊûÑÊ®°ÂûãÂíåÊñ∞È¢ñÁöÑÁ¢∞ÊíûÂ§ÑÁêÜÁÆóÊ≥ïÔºåËøõ‰∏ÄÊ≠•ÊèêÂçá‰∫ÜÁâ©ÁêÜÊ®°ÊãüÁöÑÁ≤æÂ∫¶ÂíåÈ≤ÅÊ£íÊÄß„ÄÇ3) ‰ΩøÁî®3DÈ´òÊñØÊ∫ÖÂ∞ÑÊ∏≤ÊüìÔºåÂÆûÁé∞‰∫ÜÈ´ò‰øùÁúüÂ∫¶ÁöÑÊ∏≤ÊüìÊïàÊûú„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåMPMAvatarÂú®Âä®ÂäõÂ≠¶Âª∫Ê®°ÂíåÊ∏≤ÊüìÊñπÈù¢ÈÉΩÂèñÂæó‰∫ÜÊòæËëóÁöÑÊèêÂçá„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®MPMÊ®°ÊãüÂô®‰∏≠Ôºå‰ΩøÁî®‰∫ÜÂêÑÂêëÂºÇÊÄßÊú¨ÊûÑÊ®°ÂûãÊù•Êõ¥ÂáÜÁ°ÆÂú∞ÊèèËø∞ÊúçË£ÖÊùêÊñôÁöÑÁâπÊÄß„ÄÇËÆæËÆ°‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÁ¢∞ÊíûÂ§ÑÁêÜÁÆóÊ≥ïÔºå‰ª•ÈÅøÂÖçÊ®°ÊãüËøáÁ®ã‰∏≠Âá∫Áé∞Á©øÈÄèÁé∞Ë±°„ÄÇÂú®Ê∏≤ÊüìÊñπÈù¢Ôºå‰ΩøÁî®‰∫ÜÂáÜÈò¥ÂΩ±ÊäÄÊúØÊù•Â¢ûÂº∫Ê∏≤ÊüìÁöÑÁúüÂÆûÊÑü„ÄÇÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°ÁõÆÊ†áÊòØÊúÄÂ∞èÂåñÈáçÂª∫ËØØÂ∑Æ„ÄÅÁâ©ÁêÜÊ®°ÊãüËØØÂ∑ÆÂíåÊ∏≤ÊüìËØØÂ∑Æ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

MPMAvatarÂú®Âä®ÂäõÂ≠¶Âª∫Ê®°Á≤æÂ∫¶„ÄÅÊ∏≤ÊüìÁ≤æÂ∫¶‰ª•ÂèäÈ≤ÅÊ£íÊÄßÂíåÊïàÁéáÊñπÈù¢ÊòæËëó‰ºò‰∫éÁé∞ÊúâÊäÄÊúØ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåMPMAvatarËÉΩÂ§üÁîüÊàêÊõ¥ÁúüÂÆûÁöÑÊúçË£ÖÂä®ÊÄÅÊïàÊûúÔºåÂπ∂‰∏îËÉΩÂ§ü‰ª•Èõ∂Ê†∑Êú¨ÊñπÂºèÊ≥õÂåñÂà∞Êú™ËßÅËøáÁöÑ‰∫§‰∫íÔºåËøôÂØπ‰∫é‰ª•ÂâçÂü∫‰∫éÂ≠¶‰π†ÁöÑÊñπÊ≥ïÊù•ËØ¥ÊòØÊó†Ê≥ïÂÆûÁé∞ÁöÑ„ÄÇÂÖ∑‰ΩìÊÄßËÉΩÊï∞ÊçÆÊú™Áü•Ôºå‰ΩÜÊëòË¶ÅÂº∫Ë∞É‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

MPMAvatarÂèØÂ∫îÁî®‰∫éËôöÊãüÁé∞ÂÆû„ÄÅÂ¢ûÂº∫Áé∞ÂÆû„ÄÅÊ∏∏Êàè„ÄÅÁîµÂΩ±Âà∂‰ΩúÁ≠âÈ¢ÜÂüüÔºåÂàõÂª∫ÈÄºÁúü‰∏îÂèØ‰∫§‰∫íÁöÑËôöÊãüËßíËâ≤„ÄÇËØ•ÊäÄÊúØËÉΩÂ§üÊ®°ÊãüÊúçË£ÖÁöÑÁúüÂÆûÁâ©ÁêÜË°å‰∏∫ÔºåÊèêÂçáÁî®Êà∑‰ΩìÈ™åÔºåÂπ∂‰∏∫ÊúçË£ÖËÆæËÆ°ÂíåËôöÊãüËØïÁ©øÊèê‰æõÊñ∞ÁöÑÂ∑•ÂÖ∑„ÄÇÊú™Êù•ÔºåËØ•ÊäÄÊúØÊúâÊúõÂ∫îÁî®‰∫éËøúÁ®ãÂçè‰Ωú„ÄÅËôöÊãüÂåñË∫´Á≠âÊõ¥ÂπøÊ≥õÁöÑÂú∫ÊôØ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> While there has been significant progress in the field of 3D avatar creation from visual observations, modeling physically plausible dynamics of humans with loose garments remains a challenging problem. Although a few existing works address this problem by leveraging physical simulation, they suffer from limited accuracy or robustness to novel animation inputs. In this work, we present MPMAvatar, a framework for creating 3D human avatars from multi-view videos that supports highly realistic, robust animation, as well as photorealistic rendering from free viewpoints. For accurate and robust dynamics modeling, our key idea is to use a Material Point Method-based simulator, which we carefully tailor to model garments with complex deformations and contact with the underlying body by incorporating an anisotropic constitutive model and a novel collision handling algorithm. We combine this dynamics modeling scheme with our canonical avatar that can be rendered using 3D Gaussian Splatting with quasi-shadowing, enabling high-fidelity rendering for physically realistic animations. In our experiments, we demonstrate that MPMAvatar significantly outperforms the existing state-of-the-art physics-based avatar in terms of (1) dynamics modeling accuracy, (2) rendering accuracy, and (3) robustness and efficiency. Additionally, we present a novel application in which our avatar generalizes to unseen interactions in a zero-shot manner-which was not achievable with previous learning-based methods due to their limited simulation generalizability. Our project page is at: https://KAISTChangmin.github.io/MPMAvatar/

