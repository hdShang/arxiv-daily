---
layout: default
title: MPMAvatar: Learning 3D Gaussian Avatars with Accurate and Robust Physics-Based Dynamics
---

# MPMAvatar: Learning 3D Gaussian Avatars with Accurate and Robust Physics-Based Dynamics

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.01619" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.01619v1</a>
  <a href="https://arxiv.org/pdf/2510.01619.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.01619v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.01619v1', 'MPMAvatar: Learning 3D Gaussian Avatars with Accurate and Robust Physics-Based Dynamics')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Changmin Lee, Jihyun Lee, Tae-Kyun Kim

**åˆ†ç±»**: cs.GR, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-02

**å¤‡æ³¨**: Accepted to NeurIPS 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://KAISTChangmin.github.io/MPMAvatar/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**MPMAvatarï¼šæå‡ºåŸºäºç‰©ç†çš„ç²¾ç¡®é²æ£’3Dé«˜æ–¯Avatarå­¦ä¹ æ¡†æ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)**

**å…³é”®è¯**: `3D Avatar` `ç‰©ç†æ¨¡æ‹Ÿ` `Material Point Method` `é«˜æ–¯æº…å°„` `æœè£…åŠ¨æ€` `å¤šè§†è§’é‡å»º` `è™šæ‹Ÿç°å®`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æ¨¡æ‹Ÿäººä½“åŠå…¶å®½æ¾æœè£…çš„ç‰©ç†åŠ¨æ€æ–¹é¢å­˜åœ¨ç²¾åº¦å’Œé²æ£’æ€§ä¸è¶³çš„æŒ‘æˆ˜ã€‚
2. MPMAvataråˆ©ç”¨Material Point Methodæ¨¡æ‹Ÿå™¨ï¼Œç»“åˆå„å‘å¼‚æ€§æ¨¡å‹å’Œç¢°æ’å¤„ç†ï¼Œå®ç°ç²¾ç¡®çš„æœè£…åŠ¨æ€æ¨¡æ‹Ÿã€‚
3. å®éªŒè¯æ˜MPMAvataråœ¨åŠ¨åŠ›å­¦å’Œæ¸²æŸ“ç²¾åº¦ã€é²æ£’æ€§åŠæ•ˆç‡ä¸Šä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œå¹¶èƒ½é›¶æ ·æœ¬æ³›åŒ–åˆ°æ–°çš„äº¤äº’ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºMPMAvatarï¼Œä¸€ä¸ªä»å¤šè§†è§’è§†é¢‘åˆ›å»º3Däººä½“Avatarçš„æ¡†æ¶ï¼Œå®ƒæ”¯æŒé«˜åº¦çœŸå®ã€é²æ£’çš„åŠ¨ç”»ï¼Œä»¥åŠè‡ªç”±è§†è§’çš„ç…§ç‰‡çº§æ¸²æŸ“ã€‚ä¸ºäº†å®ç°ç²¾ç¡®å’Œé²æ£’çš„åŠ¨åŠ›å­¦å»ºæ¨¡ï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯ä½¿ç”¨åŸºäºMaterial Point Method (MPM) çš„æ¨¡æ‹Ÿå™¨ï¼Œé€šè¿‡ç»“åˆå„å‘å¼‚æ€§æœ¬æ„æ¨¡å‹å’Œæ–°é¢–çš„ç¢°æ’å¤„ç†ç®—æ³•ï¼Œç²¾å¿ƒå®šåˆ¶è¯¥æ¨¡æ‹Ÿå™¨ä»¥æ¨¡æ‹Ÿå…·æœ‰å¤æ‚å˜å½¢çš„æœè£…ä»¥åŠä¸åº•å±‚èº«ä½“çš„æ¥è§¦ã€‚å°†æ­¤åŠ¨åŠ›å­¦å»ºæ¨¡æ–¹æ¡ˆä¸ä½¿ç”¨å…·æœ‰å‡†é˜´å½±çš„3Dé«˜æ–¯æº…å°„æ¸²æŸ“çš„è§„èŒƒAvatarç›¸ç»“åˆï¼Œä»è€Œä¸ºç‰©ç†ä¸Šé€¼çœŸçš„åŠ¨ç”»å®ç°é«˜ä¿çœŸæ¸²æŸ“ã€‚å®éªŒè¡¨æ˜ï¼ŒMPMAvataråœ¨åŠ¨åŠ›å­¦å»ºæ¨¡ç²¾åº¦ã€æ¸²æŸ“ç²¾åº¦ä»¥åŠé²æ£’æ€§å’Œæ•ˆç‡æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›çš„åŸºäºç‰©ç†çš„Avatarã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜å±•ç¤ºäº†ä¸€ä¸ªæ–°é¢–çš„åº”ç”¨ï¼ŒAvatarå¯ä»¥ä»¥é›¶æ ·æœ¬æ–¹å¼æ¨å¹¿åˆ°æœªè§è¿‡çš„äº¤äº’ï¼Œè¿™å¯¹äºä»¥å‰åŸºäºå­¦ä¹ çš„æ–¹æ³•æ¥è¯´æ˜¯æ— æ³•å®ç°çš„ï¼Œå› ä¸ºå®ƒä»¬å…·æœ‰æœ‰é™çš„æ¨¡æ‹Ÿæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰åŸºäºè§†è§‰è§‚æµ‹çš„3D Avataråˆ›å»ºæ–¹æ³•åœ¨æ¨¡æ‹Ÿå…·æœ‰å®½æ¾æœè£…çš„äººä½“ç‰©ç†åŠ¨æ€æ–¹é¢å­˜åœ¨å›°éš¾ï¼Œç²¾åº¦å’Œé²æ£’æ€§ä¸è¶³ï¼Œéš¾ä»¥æ³›åŒ–åˆ°æ–°çš„åŠ¨ç”»è¾“å…¥ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šåˆ©ç”¨Material Point Method (MPM) æ¨¡æ‹Ÿå™¨æ¥ç²¾ç¡®å»ºæ¨¡æœè£…çš„ç‰©ç†åŠ¨æ€ã€‚MPMèƒ½å¤Ÿæœ‰æ•ˆå¤„ç†å¤æ‚å½¢å˜å’Œç¢°æ’ï¼Œé€šè¿‡å®šåˆ¶åŒ–çš„MPMæ¨¡æ‹Ÿå™¨ï¼Œå¯ä»¥æ›´çœŸå®åœ°æ¨¡æ‹Ÿæœè£…ä¸äººä½“ä¹‹é—´çš„äº¤äº’ã€‚ç»“åˆé«˜æ–¯æº…å°„æ¸²æŸ“ï¼Œå®ç°é€¼çœŸçš„æ¸²æŸ“æ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMPMAvataræ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) å¤šè§†è§’è§†é¢‘è¾“å…¥ï¼›2) åŸºäºMPMçš„ç‰©ç†æ¨¡æ‹Ÿå™¨ï¼Œç”¨äºæ¨¡æ‹Ÿæœè£…çš„åŠ¨æ€ï¼›3) 3Dé«˜æ–¯æº…å°„æ¸²æŸ“å™¨ï¼Œç”¨äºç”Ÿæˆé€¼çœŸçš„æ¸²æŸ“å›¾åƒï¼›4) è§„èŒƒAvataræ¨¡å‹ï¼Œä½œä¸ºç‰©ç†æ¨¡æ‹Ÿçš„åŸºç¡€ã€‚æ•´ä½“æµç¨‹æ˜¯ä»å¤šè§†è§’è§†é¢‘ä¸­é‡å»ºè§„èŒƒAvatarï¼Œç„¶åä½¿ç”¨MPMæ¨¡æ‹Ÿå™¨æ¨¡æ‹Ÿæœè£…çš„åŠ¨æ€ï¼Œæœ€åä½¿ç”¨é«˜æ–¯æº…å°„æ¸²æŸ“å™¨æ¸²æŸ“æœ€ç»ˆçš„AvataråŠ¨ç”»ã€‚

**å…³é”®åˆ›æ–°**ï¼š1) å°†Material Point Methodå¼•å…¥åˆ°3D Avatarçš„æœè£…åŠ¨æ€æ¨¡æ‹Ÿä¸­ï¼Œèƒ½å¤Ÿæ›´ç²¾ç¡®åœ°å¤„ç†æœè£…çš„å¤æ‚å½¢å˜å’Œç¢°æ’ã€‚2) ç»“åˆå„å‘å¼‚æ€§æœ¬æ„æ¨¡å‹å’Œæ–°é¢–çš„ç¢°æ’å¤„ç†ç®—æ³•ï¼Œè¿›ä¸€æ­¥æå‡äº†ç‰©ç†æ¨¡æ‹Ÿçš„ç²¾åº¦å’Œé²æ£’æ€§ã€‚3) ä½¿ç”¨3Dé«˜æ–¯æº…å°„æ¸²æŸ“ï¼Œå®ç°äº†é«˜ä¿çœŸåº¦çš„æ¸²æŸ“æ•ˆæœã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒMPMAvataråœ¨åŠ¨åŠ›å­¦å»ºæ¨¡å’Œæ¸²æŸ“æ–¹é¢éƒ½å–å¾—äº†æ˜¾è‘—çš„æå‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨MPMæ¨¡æ‹Ÿå™¨ä¸­ï¼Œä½¿ç”¨äº†å„å‘å¼‚æ€§æœ¬æ„æ¨¡å‹æ¥æ›´å‡†ç¡®åœ°æè¿°æœè£…ææ–™çš„ç‰¹æ€§ã€‚è®¾è®¡äº†ä¸€ç§æ–°çš„ç¢°æ’å¤„ç†ç®—æ³•ï¼Œä»¥é¿å…æ¨¡æ‹Ÿè¿‡ç¨‹ä¸­å‡ºç°ç©¿é€ç°è±¡ã€‚åœ¨æ¸²æŸ“æ–¹é¢ï¼Œä½¿ç”¨äº†å‡†é˜´å½±æŠ€æœ¯æ¥å¢å¼ºæ¸²æŸ“çš„çœŸå®æ„Ÿã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡ç›®æ ‡æ˜¯æœ€å°åŒ–é‡å»ºè¯¯å·®ã€ç‰©ç†æ¨¡æ‹Ÿè¯¯å·®å’Œæ¸²æŸ“è¯¯å·®ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

MPMAvataråœ¨åŠ¨åŠ›å­¦å»ºæ¨¡ç²¾åº¦ã€æ¸²æŸ“ç²¾åº¦ä»¥åŠé²æ£’æ€§å’Œæ•ˆç‡æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMPMAvatarèƒ½å¤Ÿç”Ÿæˆæ›´çœŸå®çš„æœè£…åŠ¨æ€æ•ˆæœï¼Œå¹¶ä¸”èƒ½å¤Ÿä»¥é›¶æ ·æœ¬æ–¹å¼æ³›åŒ–åˆ°æœªè§è¿‡çš„äº¤äº’ï¼Œè¿™å¯¹äºä»¥å‰åŸºäºå­¦ä¹ çš„æ–¹æ³•æ¥è¯´æ˜¯æ— æ³•å®ç°çš„ã€‚å…·ä½“æ€§èƒ½æ•°æ®æœªçŸ¥ï¼Œä½†æ‘˜è¦å¼ºè°ƒäº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MPMAvatarå¯åº”ç”¨äºè™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ã€æ¸¸æˆã€ç”µå½±åˆ¶ä½œç­‰é¢†åŸŸï¼Œåˆ›å»ºé€¼çœŸä¸”å¯äº¤äº’çš„è™šæ‹Ÿè§’è‰²ã€‚è¯¥æŠ€æœ¯èƒ½å¤Ÿæ¨¡æ‹Ÿæœè£…çš„çœŸå®ç‰©ç†è¡Œä¸ºï¼Œæå‡ç”¨æˆ·ä½“éªŒï¼Œå¹¶ä¸ºæœè£…è®¾è®¡å’Œè™šæ‹Ÿè¯•ç©¿æä¾›æ–°çš„å·¥å…·ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºè¿œç¨‹åä½œã€è™šæ‹ŸåŒ–èº«ç­‰æ›´å¹¿æ³›çš„åœºæ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While there has been significant progress in the field of 3D avatar creation from visual observations, modeling physically plausible dynamics of humans with loose garments remains a challenging problem. Although a few existing works address this problem by leveraging physical simulation, they suffer from limited accuracy or robustness to novel animation inputs. In this work, we present MPMAvatar, a framework for creating 3D human avatars from multi-view videos that supports highly realistic, robust animation, as well as photorealistic rendering from free viewpoints. For accurate and robust dynamics modeling, our key idea is to use a Material Point Method-based simulator, which we carefully tailor to model garments with complex deformations and contact with the underlying body by incorporating an anisotropic constitutive model and a novel collision handling algorithm. We combine this dynamics modeling scheme with our canonical avatar that can be rendered using 3D Gaussian Splatting with quasi-shadowing, enabling high-fidelity rendering for physically realistic animations. In our experiments, we demonstrate that MPMAvatar significantly outperforms the existing state-of-the-art physics-based avatar in terms of (1) dynamics modeling accuracy, (2) rendering accuracy, and (3) robustness and efficiency. Additionally, we present a novel application in which our avatar generalizes to unseen interactions in a zero-shot manner-which was not achievable with previous learning-based methods due to their limited simulation generalizability. Our project page is at: https://KAISTChangmin.github.io/MPMAvatar/

