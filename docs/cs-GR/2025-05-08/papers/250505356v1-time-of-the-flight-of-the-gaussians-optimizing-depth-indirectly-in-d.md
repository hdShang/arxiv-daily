---
layout: default
title: Time of the Flight of the Gaussians: Optimizing Depth Indirectly in Dynamic Radiance Fields
---

# Time of the Flight of the Gaussians: Optimizing Depth Indirectly in Dynamic Radiance Fields

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.05356" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.05356v1</a>
  <a href="https://arxiv.org/pdf/2505.05356.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.05356v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.05356v1', 'Time of the Flight of the Gaussians: Optimizing Depth Indirectly in Dynamic Radiance Fields')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Runfeng Li, Mikhail Okunev, Zixuan Guo, Anh Ha Duong, Christian Richardt, Matthew O'Toole, James Tompkin

**åˆ†ç±»**: cs.GR, cs.AI, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-08

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§æ–¹æ³•ä»¥ä¼˜åŒ–åŠ¨æ€åœºæ™¯çš„æ·±åº¦é‡å»ºé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `åŠ¨æ€åœºæ™¯é‡å»º` `æ·±åº¦ä¼˜åŒ–` `C-ToFç›¸æœº` `é«˜æ–¯è¡¨ç¤º` `è®¡ç®—æœºè§†è§‰` `å®æ—¶å¤„ç†` `ä¸‰ç»´é‡å»º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. åŠ¨æ€3Dé‡å»ºçš„å‡†ç¡®æ€§å’Œé€Ÿåº¦æ˜¯è®¡ç®—æœºè§†è§‰ä¸­çš„é‡å¤§æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•åœ¨è¿™æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚
2. æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºC-ToFç›¸æœºçš„é‡å»ºæ–¹æ³•ï¼Œé€šè¿‡ä¼˜åŒ–é«˜æ–¯è¡¨ç¤ºæ¥é—´æ¥æé«˜æ·±åº¦é‡å»ºçš„å‡†ç¡®æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¿«é€Ÿè¿åŠ¨åœºæ™¯ä¸‹çš„é‡å»ºç²¾åº¦æ˜¾è‘—æé«˜ï¼Œä¸”é€Ÿåº¦æ¯”ç°æœ‰æ–¹æ³•å¿«100å€ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ©ç”¨å•ç›®è¿ç»­æ³¢é£è¡Œæ—¶é—´ï¼ˆC-ToFï¼‰ç›¸æœºçš„åŸå§‹ä¼ æ„Ÿå™¨æ ·æœ¬é‡å»ºåŠ¨æ€åœºæ™¯çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åœ¨å‡†ç¡®æ€§ä¸Šä¸ç¥ç»ä½“ç§¯æ–¹æ³•ç›¸å½“æˆ–æ›´ä¼˜ï¼Œå¹¶ä¸”é€Ÿåº¦å¿«100å€ã€‚åœ¨C-ToFè¾å°„åœºé‡å»ºä¸­ï¼Œæ·±åº¦è¿™ä¸€é‡è¦å±æ€§å¹¶æœªç›´æ¥æµ‹é‡ï¼Œç»™ä¼˜åŒ–å¸¦æ¥äº†é¢å¤–æŒ‘æˆ˜ã€‚æˆ‘ä»¬åœ¨ä¼˜åŒ–ä¸­å¼•å…¥äº†ä¸¤ç§å¯å‘å¼æ–¹æ³•ï¼Œä»¥æé«˜é«˜æ–¯è¡¨ç¤ºçš„åœºæ™¯å‡ ä½•çš„å‡†ç¡®æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨å—é™çš„C-ToFä¼ æ„Ÿæ¡ä»¶ä¸‹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿå‡†ç¡®é‡å»ºåŠ¨æ€åœºæ™¯ï¼ŒåŒ…æ‹¬å¿«é€Ÿè¿åŠ¨çš„ç‰©ä½“ï¼Œå¦‚æŒ¥åŠ¨çš„æ£’çƒæ£’ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³åŠ¨æ€åœºæ™¯çš„æ·±åº¦é‡å»ºé—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨ä½¿ç”¨C-ToFç›¸æœºæ—¶ï¼Œç”±äºæ·±åº¦æœªç›´æ¥æµ‹é‡ï¼Œå¯¼è‡´ä¼˜åŒ–æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬é€šè¿‡å¼•å…¥ä¸¤ç§å¯å‘å¼æ–¹æ³•æ¥ä¼˜åŒ–é«˜æ–¯è¡¨ç¤ºçš„åœºæ™¯å‡ ä½•ï¼Œä»è€Œé—´æ¥æé«˜æ·±åº¦é‡å»ºçš„å‡†ç¡®æ€§ã€‚è¿™æ ·çš„è®¾è®¡èƒ½å¤Ÿæœ‰æ•ˆåº”å¯¹C-ToFä¼ æ„Ÿå™¨çš„é™åˆ¶ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ–¹æ³•åŒ…æ‹¬æ•°æ®é‡‡é›†ã€é¢„å¤„ç†ã€ä¼˜åŒ–å’Œé‡å»ºå››ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆä½¿ç”¨C-ToFç›¸æœºè·å–åŸå§‹æ•°æ®ï¼Œç„¶åè¿›è¡Œé¢„å¤„ç†ä»¥æå–æœ‰æ•ˆä¿¡æ¯ï¼Œæ¥ç€é€šè¿‡ä¼˜åŒ–ç®—æ³•æ”¹è¿›é«˜æ–¯è¡¨ç¤ºï¼Œæœ€åç”Ÿæˆé«˜è´¨é‡çš„3Dé‡å»ºç»“æœã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„ä¸»è¦åˆ›æ–°åœ¨äºå°†å¯å‘å¼ä¼˜åŒ–æ–¹æ³•åº”ç”¨äºé«˜æ–¯è¡¨ç¤ºçš„åœºæ™¯å‡ ä½•ï¼Œæ˜¾è‘—æé«˜äº†é‡å»ºçš„å‡†ç¡®æ€§å’Œé€Ÿåº¦ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„å¤šè§†è§’æ•°æ®å¤„ç†æ–¹å¼ç›¸æ¯”ï¼Œå…·æœ‰æ›´å¥½çš„é€‚åº”æ€§å’Œæ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬è®¾ç½®äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥å¹³è¡¡é‡å»ºç²¾åº¦å’Œè®¡ç®—æ•ˆç‡ï¼ŒåŒæ—¶å¯¹é«˜æ–¯å‚æ•°è¿›è¡Œäº†ç²¾ç»†è°ƒèŠ‚ï¼Œä»¥ç¡®ä¿åœ¨åŠ¨æ€åœºæ™¯ä¸‹çš„ç¨³å®šæ€§å’Œå‡†ç¡®æ€§ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†è®¨è®ºã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨åŠ¨æ€åœºæ™¯é‡å»ºä¸­è¡¨ç°å‡ºè‰²ï¼Œé‡å»ºç²¾åº¦ä¸ç¥ç»ä½“ç§¯æ–¹æ³•ç›¸å½“ï¼Œä¸”é€Ÿåº¦æå‡è¾¾100å€ã€‚å°¤å…¶åœ¨å¿«é€Ÿè¿åŠ¨åœºæ™¯ä¸‹ï¼Œå¦‚æŒ¥åŠ¨çš„æ£’çƒæ£’ï¼Œé‡å»ºæ•ˆæœæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ä»¥åŠæœºå™¨äººå¯¼èˆªç­‰ã€‚é€šè¿‡å®ç°å¿«é€Ÿä¸”é«˜ç²¾åº¦çš„åŠ¨æ€åœºæ™¯é‡å»ºï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿä¸ºå®æ—¶äº¤äº’å’Œç¯å¢ƒç†è§£æä¾›æ”¯æŒï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„æœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present a method to reconstruct dynamic scenes from monocular continuous-wave time-of-flight (C-ToF) cameras using raw sensor samples that achieves similar or better accuracy than neural volumetric approaches and is 100x faster. Quickly achieving high-fidelity dynamic 3D reconstruction from a single viewpoint is a significant challenge in computer vision. In C-ToF radiance field reconstruction, the property of interest-depth-is not directly measured, causing an additional challenge. This problem has a large and underappreciated impact upon the optimization when using a fast primitive-based scene representation like 3D Gaussian splatting, which is commonly used with multi-view data to produce satisfactory results and is brittle in its optimization otherwise. We incorporate two heuristics into the optimization to improve the accuracy of scene geometry represented by Gaussians. Experimental results show that our approach produces accurate reconstructions under constrained C-ToF sensing conditions, including for fast motions like swinging baseball bats. https://visual.cs.brown.edu/gftorf

