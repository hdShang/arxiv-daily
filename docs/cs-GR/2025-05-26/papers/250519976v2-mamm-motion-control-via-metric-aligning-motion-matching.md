---
layout: default
title: "MAMM: Motion Control via Metric-Aligning Motion Matching"
---

# MAMM: Motion Control via Metric-Aligning Motion Matching

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.19976" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.19976v2</a>
  <a href="https://arxiv.org/pdf/2505.19976.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.19976v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.19976v2', 'MAMM: Motion Control via Metric-Aligning Motion Matching')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Naoki Agata, Takeo Igarashi

**åˆ†ç±»**: cs.GR

**å‘å¸ƒæ—¥æœŸ**: 2025-05-26 (æ›´æ–°: 2025-11-25)

**å¤‡æ³¨**: 12 pages, SIGGRAPH 2025 (Conference Track) Project Page: https://ataga101.github.io/mamm-project-page/

**DOI**: [10.1145/3721238.3730665](https://doi.org/10.1145/3721238.3730665)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåº¦é‡å¯¹é½è¿åŠ¨åŒ¹é…æ–¹æ³•ä»¥è§£å†³è¿åŠ¨æ§åˆ¶é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)**

**å…³é”®è¯**: `è¿åŠ¨æ§åˆ¶` `æ—¶é—´å¯¹é½` `åº¦é‡å¯¹é½` `è¿åŠ¨åŒ¹é…` `æ— ç›‘ç£å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºå¤§é‡çš„é…å¯¹æ•°æ®å’Œå¤æ‚çš„è®­ç»ƒè¿‡ç¨‹ï¼Œé™åˆ¶äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„çµæ´»æ€§å’Œæ•ˆç‡ã€‚
2. æå‡ºçš„åº¦é‡å¯¹é½è¿åŠ¨åŒ¹é…æ–¹æ³•é€šè¿‡ä»…è€ƒè™‘åŸŸå†…è·ç¦»ï¼Œå®ç°äº†è¿åŠ¨åºåˆ—ä¸æ§åˆ¶åºåˆ—çš„é«˜æ•ˆå¯¹é½ï¼Œé¿å…äº†æ‰‹åŠ¨æ˜ å°„çš„éœ€æ±‚ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§æ§åˆ¶åºåˆ—ä¸‹å‡è¡¨ç°å‡ºè‰²ï¼Œå±•ç¤ºäº†å…¶åœ¨è¿åŠ¨æ§åˆ¶é¢†åŸŸçš„å¹¿æ³›åº”ç”¨æ½œåŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬ä»‹ç»äº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œé€šè¿‡ä»»æ„æ—¶é—´æ§åˆ¶åºåˆ—æ§åˆ¶è¿åŠ¨åºåˆ—ï¼Œåˆ©ç”¨æ—¶é—´å¯¹é½æŠ€æœ¯ã€‚è¿åŠ¨çš„æ—¶é—´å¯¹é½å› å…¶åœ¨è¿åŠ¨æ§åˆ¶å’Œé‡å®šå‘ä¸­çš„åº”ç”¨è€Œå—åˆ°å¹¿æ³›å…³æ³¨ã€‚ä¼ ç»Ÿæ–¹æ³•ä¾èµ–äºåœ¨åŸå§‹å’Œæ§åˆ¶åŸŸä¹‹é—´çš„å­¦ä¹ æˆ–æ‰‹å·¥åˆ¶ä½œçš„è·¨åŸŸæ˜ å°„ï¼Œé€šå¸¸éœ€è¦å¤§é‡é…å¯¹æˆ–æ³¨é‡Šæ•°æ®ä»¥åŠè€—æ—¶çš„è®­ç»ƒã€‚æˆ‘ä»¬çš„æ–¹æ³•ï¼Œç§°ä¸ºåº¦é‡å¯¹é½è¿åŠ¨åŒ¹é…ï¼Œå•çº¯è€ƒè™‘åŸŸå†…è·ç¦»æ¥å®ç°å¯¹é½ã€‚å®ƒè®¡ç®—æ¯ä¸ªåŸŸä¸­è¡¥ä¸ä¹‹é—´çš„è·ç¦»ï¼Œå¹¶å¯»æ±‚æœ€ä½³åŒ¹é…ä»¥å¯¹é½ä¸¤ä¸ªåŸŸå†…çš„è·ç¦»ã€‚è¯¥æ¡†æ¶å…è®¸å°†è¿åŠ¨åºåˆ—å¯¹é½åˆ°å„ç§ç±»å‹çš„æ§åˆ¶åºåˆ—ï¼ŒåŒ…æ‹¬è‰å›¾ã€æ ‡ç­¾ã€éŸ³é¢‘å’Œå…¶ä»–è¿åŠ¨åºåˆ—ï¼Œä¸”æ— éœ€æ‰‹åŠ¨å®šä¹‰æ˜ å°„æˆ–ä½¿ç”¨æ³¨é‡Šæ•°æ®è¿›è¡Œè®­ç»ƒã€‚æˆ‘ä»¬é€šè¿‡é«˜æ•ˆçš„è¿åŠ¨æ§åˆ¶åº”ç”¨å±•ç¤ºäº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œçªæ˜¾å…¶åœ¨å®é™…åœºæ™¯ä¸­çš„æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ä¼ ç»Ÿè¿åŠ¨æ§åˆ¶æ–¹æ³•ä¸­å¯¹å¤§é‡é…å¯¹æ•°æ®å’Œå¤æ‚è®­ç»ƒçš„ä¾èµ–é—®é¢˜ï¼Œè¿™äº›æ–¹æ³•å¾€å¾€é™åˆ¶äº†å…¶çµæ´»æ€§å’Œæ•ˆç‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºçš„åº¦é‡å¯¹é½è¿åŠ¨åŒ¹é…æ–¹æ³•é€šè¿‡ä»…è€ƒè™‘åŸŸå†…çš„è·ç¦»æ¥å®ç°è¿åŠ¨åºåˆ—ä¸æ§åˆ¶åºåˆ—çš„å¯¹é½ï¼Œé¿å…äº†æ‰‹åŠ¨å®šä¹‰æ˜ å°„å’Œæ³¨é‡Šæ•°æ®çš„éœ€æ±‚ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•çš„æ•´ä½“æ¶æ„åŒ…æ‹¬è®¡ç®—æ¯ä¸ªåŸŸä¸­è¡¥ä¸ä¹‹é—´çš„è·ç¦»ï¼Œå¹¶é€šè¿‡ä¼˜åŒ–åŒ¹é…æ¥å¯¹é½ä¸¤ä¸ªåŸŸå†…çš„è·ç¦»ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬è·ç¦»è®¡ç®—æ¨¡å—å’ŒåŒ¹é…ä¼˜åŒ–æ¨¡å—ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºé€šè¿‡åŸŸå†…è·ç¦»çš„å¯¹é½å®ç°äº†è¿åŠ¨åºåˆ—ä¸æ§åˆ¶åºåˆ—çš„åŒ¹é…ï¼Œè¿™ä¸ä¼ ç»Ÿæ–¹æ³•ä¾èµ–äºè·¨åŸŸæ˜ å°„çš„æ–¹å¼æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œæˆ‘ä»¬è®¾è®¡äº†é«˜æ•ˆçš„è·ç¦»è®¡ç®—ç®—æ³•ï¼Œå¹¶é‡‡ç”¨äº†ä¼˜åŒ–åŒ¹é…çš„ç­–ç•¥ï¼Œç¡®ä¿äº†å¯¹é½è¿‡ç¨‹çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œåº¦é‡å¯¹é½è¿åŠ¨åŒ¹é…æ–¹æ³•åœ¨å¤šç§æ§åˆ¶åºåˆ—ä¸‹çš„å¯¹é½ç²¾åº¦æ˜¾è‘—æé«˜ï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•ï¼Œæ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŠ¨ç”»åˆ¶ä½œã€æ¸¸æˆå¼€å‘å’Œæœºå™¨äººæ§åˆ¶ç­‰ï¼Œèƒ½å¤Ÿä¸ºè¿™äº›é¢†åŸŸæä¾›æ›´çµæ´»ã€é«˜æ•ˆçš„è¿åŠ¨æ§åˆ¶è§£å†³æ–¹æ¡ˆã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æ¨åŠ¨äººæœºäº¤äº’å’Œè™šæ‹Ÿç°å®ç­‰æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We introduce a novel method for controlling a motion sequence using an arbitrary temporal control sequence using temporal alignment. Temporal alignment of motion has gained significant attention owing to its applications in motion control and retargeting. Traditional methods rely on either learned or hand-craft cross-domain mappings between frames in the original and control domains, which often require large, paired, or annotated datasets and time-consuming training. Our approach, named Metric-Aligning Motion Matching, achieves alignment by solely considering within-domain distances. It computes distances among patches in each domain and seeks a matching that optimally aligns the two within-domain distances. This framework allows for the alignment of a motion sequence to various types of control sequences, including sketches, labels, audio, and another motion sequence, all without the need for manually defined mappings or training with annotated data. We demonstrate the effectiveness of our approach through applications in efficient motion control, showcasing its potential in practical scenarios.

