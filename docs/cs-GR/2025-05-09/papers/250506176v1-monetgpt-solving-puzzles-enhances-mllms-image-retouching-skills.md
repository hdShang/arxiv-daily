---
layout: default
title: "MonetGPT: Solving Puzzles Enhances MLLMs' Image Retouching Skills"
---

# MonetGPT: Solving Puzzles Enhances MLLMs' Image Retouching Skills

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.06176" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.06176v1</a>
  <a href="https://arxiv.org/pdf/2505.06176.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.06176v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.06176v1', 'MonetGPT: Solving Puzzles Enhances MLLMs\' Image Retouching Skills')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Niladri Shekhar Dutt, Duygu Ceylan, Niloy J. Mitra

**åˆ†ç±»**: cs.GR, cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-09

**å¤‡æ³¨**: Accepted at SIGGRAPH 2025 [ACM Transactions on Graphics]; Project website: https://monetgpt.github.io

**DOI**: [10.1145/3730926](https://doi.org/10.1145/3730926)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMonetGPTä»¥æå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„å›¾åƒä¿®é¥°èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å›¾åƒä¿®é¥°` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `ç”Ÿæˆæ€§ç¼–è¾‘` `ç¨‹åºæ€§ç¼–è¾‘` `å¯è§£é‡Šæ€§` `èº«ä»½ä¿ç•™` `è§†è§‰éš¾é¢˜`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç”Ÿæˆæ€§ç¼–è¾‘æ–¹æ³•å®¹æ˜“åœ¨ä¸å¯é¢„æµ‹çš„æ–¹å¼ä¸‹æ”¹å˜å›¾åƒå¯¹è±¡çš„èº«ä»½ï¼Œç¼ºä¹ä¸“ä¸šæ€§å’Œå¯æ§æ€§ã€‚
2. æœ¬æ–‡æå‡ºé€šè¿‡è®­ç»ƒMLLMè§£å†³è§†è§‰éš¾é¢˜ï¼Œä½¿å…¶ç†è§£å›¾åƒå¤„ç†æ“ä½œï¼Œä»è€Œèƒ½å¤Ÿè§„åˆ’å’Œå»ºè®®ä¿®é¥°åºåˆ—ã€‚
3. å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨å¯è§£é‡Šæ€§å’Œå¯¹è±¡ç»†èŠ‚ä¿ç•™æ–¹é¢ä¼˜äºç°æœ‰çš„å›¾åƒç¼–è¾‘å·¥å…·ï¼Œå…·æœ‰æ˜¾è‘—çš„ä¼˜åŠ¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å›¾åƒä¿®é¥°æ˜¯åŸå§‹ç…§ç‰‡åæœŸå¤„ç†ä¸­çš„é‡è¦ä»»åŠ¡ã€‚ç”Ÿæˆæ€§ç¼–è¾‘è™½ç„¶ä¸ºç”¨æˆ·æä¾›äº†æ–°çš„å·¥å…·ï¼Œä½†å¯èƒ½ä¼šä»¥ä¸å¯æ¥å—çš„æ–¹å¼æ”¹å˜åŸå§‹å¯¹è±¡çš„èº«ä»½ã€‚ä¼ ç»Ÿçš„ç¨‹åºæ€§ç¼–è¾‘è™½ç„¶ä¿å®ˆï¼Œä½†ä»ç„¶å—åˆ°ä¸“ä¸šäººå£«çš„é’çã€‚æœ¬æ–‡æ¢è®¨äº†å¦‚ä½•é€šè¿‡è®­ç»ƒå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰æ¥æ‰¹è¯„åŸå§‹ç…§ç‰‡ã€å»ºè®®é€‚å½“çš„ä¿®æ­£æ–¹æ¡ˆï¼Œå¹¶åˆ©ç”¨é¢„å…ˆç¼–å†™çš„ç¨‹åºæ€§å›¾åƒæ“ä½œå®ç°è¿™äº›ä¿®æ­£ã€‚æˆ‘ä»¬é€šè¿‡è®¾è®¡è§†è§‰éš¾é¢˜æ¥è®©MLLMäº†è§£å›¾åƒå¤„ç†æ“ä½œï¼Œè¿›è€Œä½¿å…¶èƒ½å¤Ÿè§„åˆ’å’Œæå‡ºç¼–è¾‘åºåˆ—ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨å¯è§£é‡Šæ€§å’Œèº«ä»½ä¿ç•™æ–¹é¢ä¼˜äºç°æœ‰çš„ç”Ÿæˆæ€§å’Œå…¶ä»–ç¨‹åºæ€§æ›¿ä»£æ–¹æ¡ˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å›¾åƒä¿®é¥°ä¸­ç”Ÿæˆæ€§ç¼–è¾‘æ–¹æ³•çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯å…¶åœ¨èº«ä»½ä¿ç•™å’Œå¯æ§æ€§æ–¹é¢çš„æŒ‘æˆ˜ã€‚ç°æœ‰çš„ç¨‹åºæ€§ç¼–è¾‘è™½ç„¶ä¿å®ˆï¼Œä½†å¯¹äºæ–°æ‰‹æ¥è¯´éš¾ä»¥è§„åˆ’å’Œæ‰§è¡Œã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡è®­ç»ƒå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰è§£å†³è§†è§‰éš¾é¢˜ï¼Œä½¿å…¶ç†è§£å›¾åƒå¤„ç†æ“ä½œï¼Œä»è€Œèƒ½å¤Ÿæ‰¹è¯„åŸå§‹ç…§ç‰‡å¹¶å»ºè®®é€‚å½“çš„ä¿®æ­£æ–¹æ¡ˆã€‚è¯¥æ–¹æ³•ç»“åˆäº†ä¸“å®¶ç¼–è¾‘çš„çŸ¥è¯†ï¼Œæä¾›äº†ä¸€ç§å¯è§£é‡Šä¸”ç”¨æˆ·å‹å¥½çš„ä¿®é¥°æ–¹å¼ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼šé¦–å…ˆï¼Œè®¾è®¡è§†è§‰éš¾é¢˜ä»¥è®­ç»ƒMLLMç†è§£å›¾åƒå¤„ç†æ“ä½œï¼›å…¶æ¬¡ï¼Œåˆ©ç”¨ä¸“å®¶ç¼–è¾‘çš„ç…§ç‰‡åˆæˆæ¨ç†æ•°æ®é›†ï¼›æœ€åï¼ŒåŸºäºé¢„è®­ç»ƒçš„LLMè¿›è¡Œå¾®è°ƒï¼Œä»¥å®ç°å›¾åƒä¿®é¥°çš„è§„åˆ’å’Œå»ºè®®ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºé€šè¿‡è§†è§‰éš¾é¢˜è®­ç»ƒMLLMï¼Œä½¿å…¶å…·å¤‡æ“ä½œæ„è¯†ï¼Œèƒ½å¤Ÿåœ¨ä¿ç•™å¯¹è±¡ç»†èŠ‚çš„åŒæ—¶è¿›è¡Œæœ‰æ•ˆçš„å›¾åƒä¿®é¥°ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„ç”Ÿæˆæ€§ç¼–è¾‘æ–¹æ³•æœ¬è´¨ä¸Šä¸åŒï¼Œåè€…å¾€å¾€ç¼ºä¹å¯¹æ“ä½œçš„ç†è§£ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œè®¾è®¡äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œå‚æ•°è®¾ç½®ï¼Œä»¥ç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåœ°å­¦ä¹ å›¾åƒå¤„ç†æ“ä½œã€‚æ­¤å¤–ï¼Œé‡‡ç”¨äº†é¢„è®­ç»ƒçš„LLMä½œä¸ºåŸºç¡€ï¼Œç»“åˆè§†è§‰è°ƒæ•´è¿›è¡Œå¾®è°ƒï¼Œä»¥æå‡æ¨¡å‹çš„ä¿®é¥°èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMonetGPTåœ¨å¯è§£é‡Šæ€§å’Œèº«ä»½ä¿ç•™æ–¹é¢ä¼˜äºç°æœ‰çš„ç”Ÿæˆæ€§å’Œç¨‹åºæ€§ç¼–è¾‘æ–¹æ³•ã€‚å…·ä½“è€Œè¨€ï¼Œæ¨¡å‹åœ¨å¤šä¸ªæµ‹è¯•ç¤ºä¾‹ä¸­è¡¨ç°å‡ºæ›´é«˜çš„ç¼–è¾‘è´¨é‡å’Œç”¨æˆ·æ»¡æ„åº¦ï¼Œæ˜¾è‘—æå‡äº†å›¾åƒä¿®é¥°çš„æ•ˆæœã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ä¸“ä¸šæ‘„å½±ã€å¹¿å‘Šè®¾è®¡å’Œç¤¾äº¤åª’ä½“å†…å®¹åˆ›ä½œç­‰ã€‚é€šè¿‡æä¾›ä¸€ç§å¯è§£é‡Šä¸”ç”¨æˆ·å‹å¥½çš„å›¾åƒä¿®é¥°å·¥å…·ï¼ŒMonetGPTèƒ½å¤Ÿå¸®åŠ©ç”¨æˆ·æ›´é«˜æ•ˆåœ°è¿›è¡Œå›¾åƒç¼–è¾‘ï¼Œæå‡åˆ›ä½œè´¨é‡ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯å¯èƒ½ä¼šåœ¨è‡ªåŠ¨åŒ–å›¾åƒå¤„ç†å’Œä¸ªæ€§åŒ–ç¼–è¾‘å·¥å…·ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Retouching is an essential task in post-manipulation of raw photographs. Generative editing, guided by text or strokes, provides a new tool accessible to users but can easily change the identity of the original objects in unacceptable and unpredictable ways. In contrast, although traditional procedural edits, as commonly supported by photoediting tools (e.g., Gimp, Lightroom), are conservative, they are still preferred by professionals. Unfortunately, professional quality retouching involves many individual procedural editing operations that is challenging to plan for most novices. In this paper, we ask if a multimodal large language model (MLLM) can be taught to critique raw photographs, suggest suitable remedies, and finally realize them with a given set of pre-authored procedural image operations. We demonstrate that MLLMs can be first made aware of the underlying image processing operations, by training them to solve specially designed visual puzzles. Subsequently, such an operation-aware MLLM can both plan and propose edit sequences. To facilitate training, given a set of expert-edited photos, we synthesize a reasoning dataset by procedurally manipulating the expert edits and then grounding a pretrained LLM on the visual adjustments, to synthesize reasoning for finetuning. The proposed retouching operations are, by construction, understandable by the users, preserve object details and resolution, and can be optionally overridden. We evaluate our setup on a variety of test examples and show advantages, in terms of explainability and identity preservation, over existing generative and other procedural alternatives. Code, data, models, and supplementary results can be found via our project website at https://monetgpt.github.io.

