---
layout: default
title: Social Agent: Mastering Dyadic Nonverbal Behavior Generation via Conversational LLM Agents
---

# Social Agent: Mastering Dyadic Nonverbal Behavior Generation via Conversational LLM Agents

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.04637" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.04637v1</a>
  <a href="https://arxiv.org/pdf/2510.04637.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.04637v1" onclick="toggleFavorite(this, '2510.04637v1', 'Social Agent: Mastering Dyadic Nonverbal Behavior Generation via Conversational LLM Agents')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zeyi Zhang, Yanju Zhou, Heyuan Yao, Tenglong Ao, Xiaohang Zhan, Libin Liu

**åˆ†ç±»**: cs.GR, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-06

**å¤‡æ³¨**: SIGGRAPH ASIA 2025 (Conference Track); Project page: https://pku-mocca.github.io/Social-Agent-Page/

**DOI**: [10.1145/3757377.3763879](https://doi.org/10.1145/3757377.3763879)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Social Agentï¼šåŸºäºå¯¹è¯LLMæ™ºèƒ½ä½“å®ç°åŒäººéè¯­è¨€è¡Œä¸ºç”Ÿæˆ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `éè¯­è¨€è¡Œä¸ºç”Ÿæˆ` `åŒäººå¯¹è¯` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ‰©æ•£æ¨¡å‹` `äººæœºäº¤äº’`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•éš¾ä»¥ç”Ÿæˆè‡ªç„¶ä¸”å…·æœ‰ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›çš„åŒäººå¯¹è¯éè¯­è¨€è¡Œä¸ºï¼Œç¼ºä¹å¯¹äº¤äº’åŠ¨æ€çš„å»ºæ¨¡ã€‚
2. Social Agentåˆ©ç”¨LLMé©±åŠ¨çš„æ™ºèƒ½ä½“ç³»ç»Ÿï¼Œç»“åˆè‡ªå›å½’æ‰©æ•£æ¨¡å‹ï¼Œç”Ÿæˆé€¼çœŸä¸”ååŒçš„åŒäººéè¯­è¨€è¡Œä¸ºã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹æ˜¾è‘—æå‡äº†åŒäººäº’åŠ¨è´¨é‡ï¼Œç”Ÿæˆäº†è‡ªç„¶ä¸”åŒæ­¥çš„éè¯­è¨€è¡Œä¸ºï¼Œä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºSocial Agentçš„æ–°æ¡†æ¶ï¼Œç”¨äºåˆæˆåŒäººå¯¹è¯ä¸­é€¼çœŸä¸”ç¬¦åˆè¯­å¢ƒçš„ååŒéè¯­è¨€è¡Œä¸ºã€‚è¯¥æ¡†æ¶å¼€å‘äº†ä¸€ä¸ªç”±å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„æ™ºèƒ½ä½“ç³»ç»Ÿï¼Œä»¥æŒ‡å¯¼å¯¹è¯æµç¨‹å¹¶ç¡®å®šåŒæ–¹å‚ä¸è€…çš„é€‚å½“äº’åŠ¨è¡Œä¸ºã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ä¸€ç§åŸºäºè‡ªå›å½’æ‰©æ•£æ¨¡å‹çš„åŒäººæ‰‹åŠ¿ç”Ÿæˆæ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä»è¯­éŸ³ä¿¡å·ä¸­åˆæˆåè°ƒçš„åŠ¨ä½œã€‚æ™ºèƒ½ä½“ç³»ç»Ÿçš„è¾“å‡ºè¢«è½¬åŒ–ä¸ºæ‰‹åŠ¿ç”Ÿæˆå™¨çš„é«˜çº§æŒ‡å¯¼ï¼Œä»è€Œåœ¨è¡Œä¸ºå’Œè¿åŠ¨å±‚é¢äº§ç”Ÿé€¼çœŸçš„è¿åŠ¨ã€‚æ™ºèƒ½ä½“ç³»ç»Ÿè¿˜ä¼šå®šæœŸæ£€æŸ¥å¯¹è¯è€…çš„åŠ¨ä½œå¹¶æ¨æ–­ä»–ä»¬çš„æ„å›¾ï¼Œå½¢æˆä¸€ä¸ªæŒç»­çš„åé¦ˆå¾ªç¯ï¼Œä»è€Œå®ç°åŒæ–¹å‚ä¸è€…ä¹‹é—´åŠ¨æ€å’Œå“åº”å¼çš„äº’åŠ¨ã€‚ç”¨æˆ·ç ”ç©¶å’Œå®šé‡è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ¨¡å‹æ˜¾è‘—æé«˜äº†åŒäººäº’åŠ¨è´¨é‡ï¼Œäº§ç”Ÿäº†è‡ªç„¶ã€åŒæ­¥çš„éè¯­è¨€è¡Œä¸ºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æ–¹æ³•åœ¨ç”ŸæˆåŒäººå¯¹è¯åœºæ™¯ä¸‹çš„éè¯­è¨€è¡Œä¸ºæ—¶ï¼Œéš¾ä»¥ä¿è¯è¡Œä¸ºçš„è‡ªç„¶æ€§ã€åŒæ­¥æ€§å’Œä¸Šä¸‹æ–‡ç›¸å…³æ€§ã€‚å°¤å…¶æ˜¯åœ¨æ¨¡æ‹ŸçœŸå®å¯¹è¯çš„åŠ¨æ€äº¤äº’æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œæ— æ³•æ ¹æ®å¯¹æ–¹çš„è¡Œä¸ºå’Œæ„å›¾åšå‡ºå®æ—¶è°ƒæ•´ã€‚è¿™å¯¼è‡´ç”Ÿæˆçš„éè¯­è¨€è¡Œä¸ºæ˜¾å¾—åƒµç¡¬å’Œä¸çœŸå®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä½œä¸ºå¯¹è¯çš„é©±åŠ¨è€…ï¼Œæ¨¡æ‹Ÿäººç±»çš„å¯¹è¯è¿‡ç¨‹ï¼Œå¹¶æ ¹æ®å¯¹è¯å†…å®¹å’Œå‚ä¸è€…çš„çŠ¶æ€ï¼Œç”Ÿæˆç›¸åº”çš„éè¯­è¨€è¡Œä¸ºã€‚é€šè¿‡LLMçš„æ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥æ›´å¥½åœ°ç†è§£å¯¹è¯çš„ä¸Šä¸‹æ–‡ï¼Œå¹¶ç”Ÿæˆæ›´å…·è¡¨ç°åŠ›å’ŒçœŸå®æ„Ÿçš„éè¯­è¨€è¡Œä¸ºã€‚åŒæ—¶ï¼Œå¼•å…¥åé¦ˆæœºåˆ¶ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿæ ¹æ®å¯¹æ–¹çš„è¡Œä¸ºè¿›è¡Œè°ƒæ•´ï¼Œä»è€Œå®ç°åŠ¨æ€çš„äº¤äº’ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSocial Agentæ¡†æ¶ä¸»è¦åŒ…å«ä¸¤ä¸ªæ ¸å¿ƒæ¨¡å—ï¼šåŸºäºLLMçš„æ™ºèƒ½ä½“ç³»ç»Ÿå’ŒåŒäººæ‰‹åŠ¿ç”Ÿæˆæ¨¡å‹ã€‚é¦–å…ˆï¼ŒLLMæ™ºèƒ½ä½“ç³»ç»Ÿè´Ÿè´£ç®¡ç†å¯¹è¯æµç¨‹ï¼Œå†³å®šæ¯ä¸ªå‚ä¸è€…çš„å‘è¨€å†…å®¹å’Œé«˜å±‚è¡Œä¸ºæ„å›¾ã€‚ç„¶åï¼ŒåŒäººæ‰‹åŠ¿ç”Ÿæˆæ¨¡å‹æ¥æ”¶LLMæ™ºèƒ½ä½“çš„è¾“å‡ºï¼Œå¹¶æ ¹æ®è¯­éŸ³ä¿¡å·ç”Ÿæˆç›¸åº”çš„éè¯­è¨€è¡Œä¸ºã€‚è¯¥æ¨¡å‹åŸºäºè‡ªå›å½’æ‰©æ•£æ¨¡å‹ï¼Œèƒ½å¤Ÿç”Ÿæˆåè°ƒçš„åŠ¨ä½œã€‚æ­¤å¤–ï¼Œæ™ºèƒ½ä½“ç³»ç»Ÿä¼šå®šæœŸæ£€æŸ¥å¯¹è¯è€…çš„åŠ¨ä½œï¼Œå¹¶æ¨æ–­ä»–ä»¬çš„æ„å›¾ï¼Œå½¢æˆä¸€ä¸ªé—­ç¯åé¦ˆç³»ç»Ÿï¼Œä»è€Œå®ç°åŠ¨æ€äº¤äº’ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¼•å…¥åˆ°åŒäººéè¯­è¨€è¡Œä¸ºç”Ÿæˆä»»åŠ¡ä¸­ï¼Œåˆ©ç”¨LLMçš„å¼ºå¤§æ¨ç†èƒ½åŠ›æ¥é©±åŠ¨å¯¹è¯æµç¨‹å’ŒæŒ‡å¯¼éè¯­è¨€è¡Œä¸ºçš„ç”Ÿæˆã€‚æ­¤å¤–ï¼Œæå‡ºçš„åŒäººæ‰‹åŠ¿ç”Ÿæˆæ¨¡å‹èƒ½å¤Ÿç”Ÿæˆåè°ƒçš„åŠ¨ä½œï¼Œå¹¶ç»“åˆåé¦ˆæœºåˆ¶ï¼Œå®ç°äº†åŠ¨æ€å’Œå“åº”å¼çš„äº¤äº’ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆæ›´è‡ªç„¶ã€åŒæ­¥å’Œå…·æœ‰ä¸Šä¸‹æ–‡ç›¸å…³æ€§çš„éè¯­è¨€è¡Œä¸ºã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨LLMæ™ºèƒ½ä½“ç³»ç»Ÿä¸­ï¼Œä½¿ç”¨äº†ç‰¹å®šçš„promptå·¥ç¨‹æ¥å¼•å¯¼LLMç”Ÿæˆç¬¦åˆè¦æ±‚çš„å¯¹è¯å†…å®¹å’Œè¡Œä¸ºæ„å›¾ã€‚åœ¨åŒäººæ‰‹åŠ¿ç”Ÿæˆæ¨¡å‹ä¸­ï¼Œä½¿ç”¨äº†è‡ªå›å½’æ‰©æ•£æ¨¡å‹ï¼Œå¹¶è®¾è®¡äº†ç‰¹å®šçš„ç½‘ç»œç»“æ„æ¥æ•æ‰è¯­éŸ³ä¿¡å·å’Œè¡Œä¸ºæ„å›¾ä¹‹é—´çš„å…³ç³»ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿè€ƒè™‘äº†è¡Œä¸ºçš„è‡ªç„¶æ€§å’ŒåŒæ­¥æ€§ï¼Œä¾‹å¦‚ï¼Œä½¿ç”¨äº†å¯¹æŠ—æŸå¤±æ¥æé«˜ç”Ÿæˆè¡Œä¸ºçš„çœŸå®æ„Ÿï¼Œå¹¶ä½¿ç”¨äº†ååŒæŸå¤±æ¥ä¿è¯åŒäººè¡Œä¸ºçš„åŒæ­¥æ€§ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼ŒSocial Agentç”Ÿæˆçš„åŒäººéè¯­è¨€è¡Œä¸ºåœ¨è‡ªç„¶æ€§ã€åŒæ­¥æ€§å’Œä¸Šä¸‹æ–‡ç›¸å…³æ€§æ–¹é¢å‡æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚å®šé‡è¯„ä¼°ç»“æœä¹Ÿæ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹åœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šå–å¾—äº†æ˜¾è‘—æå‡ï¼Œä¾‹å¦‚ï¼Œåœ¨åŠ¨ä½œæµç•…åº¦ã€è¡Œä¸ºä¸€è‡´æ€§ç­‰æ–¹é¢å‡ä¼˜äºåŸºçº¿æ¨¡å‹ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”ç»“æœåœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†å±•ç¤ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºè™šæ‹Ÿç°å®ã€æ¸¸æˆã€åœ¨çº¿æ•™è‚²ã€äººæœºäº¤äº’ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œå¯ä»¥åˆ›å»ºæ›´å…·æ²‰æµ¸æ„Ÿå’Œäº’åŠ¨æ€§çš„è™šæ‹Ÿè§’è‰²ï¼Œæå‡åœ¨çº¿æ•™è‚²çš„å‚ä¸åº¦å’Œæ•ˆæœï¼Œæ”¹å–„äººæœºäº¤äº’çš„è‡ªç„¶æ€§å’Œæµç•…æ€§ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºç¤¾äº¤æœºå™¨äººã€æ™ºèƒ½åŠ©æ‰‹ç­‰é¢†åŸŸï¼Œå®ç°æ›´è‡ªç„¶å’Œäººæ€§åŒ–çš„äº¤äº’ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present Social Agent, a novel framework for synthesizing realistic and contextually appropriate co-speech nonverbal behaviors in dyadic conversations. In this framework, we develop an agentic system driven by a Large Language Model (LLM) to direct the conversation flow and determine appropriate interactive behaviors for both participants. Additionally, we propose a novel dual-person gesture generation model based on an auto-regressive diffusion model, which synthesizes coordinated motions from speech signals. The output of the agentic system is translated into high-level guidance for the gesture generator, resulting in realistic movement at both the behavioral and motion levels. Furthermore, the agentic system periodically examines the movements of interlocutors and infers their intentions, forming a continuous feedback loop that enables dynamic and responsive interactions between the two participants. User studies and quantitative evaluations show that our model significantly improves the quality of dyadic interactions, producing natural, synchronized nonverbal behaviors.

