---
layout: default
title: Shape-aware Inertial Poser: Motion Tracking for Humans with Diverse Shapes Using Sparse Inertial Sensors
---

# Shape-aware Inertial Poser: Motion Tracking for Humans with Diverse Shapes Using Sparse Inertial Sensors

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.17101" class="toolbar-btn" target="_blank">üìÑ arXiv: 2510.17101v1</a>
  <a href="https://arxiv.org/pdf/2510.17101.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.17101v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.17101v1', 'Shape-aware Inertial Poser: Motion Tracking for Humans with Diverse Shapes Using Sparse Inertial Sensors')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Lu Yin, Ziying Shi, Yinghao Wu, Xinyu Yi, Feng Xu, Shihui Guo

**ÂàÜÁ±ª**: cs.GR, cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-20

**Â§áÊ≥®**: Accepted by SIGGRAPH Asia 2025 (TOG)

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/yinlu5942/SAIP)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫SAIPÔºåËß£ÂÜ≥Á®ÄÁñèÊÉØÊÄß‰º†ÊÑüÂô®‰∫∫‰ΩìÂä®‰ΩúÊçïÊçâ‰∏≠‰ΩìÂûãÂ∑ÆÂºÇÊ≥õÂåñÈöæÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±ÂÖ´ÔºöÁâ©ÁêÜÂä®Áîª (Physics-based Animation)**

**ÂÖ≥ÈîÆËØç**: `‰∫∫‰ΩìÂä®‰ΩúÊçïÊçâ` `ÊÉØÊÄß‰º†ÊÑüÂô®` `‰ΩìÂûãÊÑüÁü•` `Ê∑±Â∫¶Â≠¶‰π†` `ËøêÂä®‰º∞ËÆ°`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂü∫‰∫éÁ®ÄÁñèÊÉØÊÄß‰º†ÊÑüÂô®ÁöÑ‰∫∫‰ΩìÂä®‰ΩúÊçïÊçâÊñπÊ≥ïÈöæ‰ª•Ê≥õÂåñÂà∞‰ΩìÂûãÂ∑ÆÂºÇÂ§ßÁöÑ‰∏™‰ΩìÔºå‰∏ªË¶ÅÂéüÂõ†ÊòØÂøΩÁï•‰∫Ü‰ΩìÂûãÂØπIMUÊµãÈáèÁöÑÂΩ±Âìç„ÄÇ
2. SAIPÈÄöËøáËß£ËÄ¶‰ΩìÂûãÂíåÂßøÊÄÅÁõ∏ÂÖ≥ÁöÑ‰º†ÊÑüÂô®ÊµãÈáèÂÄºÔºåÂπ∂‰ΩøÁî®ÂõûÂΩíÊ®°ÂûãËøõË°å‰ΩìÂûãËΩ¨Êç¢Ôºå‰ªéËÄåÂÆûÁé∞ÂØπ‰∏çÂêå‰ΩìÂûãÁöÑÂä®‰ΩúÊçïÊçâ„ÄÇ
3. SAIPÊûÑÂª∫‰∫ÜÂåÖÂê´ÂÑøÁ´•ÂíåÊàê‰∫∫ÁöÑÊï∞ÊçÆÈõÜÔºåÂÆûÈ™åÁªìÊûúË°®ÊòéËØ•ÊñπÊ≥ïËÉΩÂ§üÊúâÊïàÂ§ÑÁêÜ‰∏çÂêå‰ΩìÂûãÁöÑ‰∫∫‰ΩìÂä®‰ΩúÊçïÊçâ‰ªªÂä°„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫Shape-aware Inertial Poser (SAIP)ÔºåÊó®Âú®Ëß£ÂÜ≥Á®ÄÁñèÊÉØÊÄß‰º†ÊÑüÂô®‰∫∫‰ΩìÂä®‰ΩúÊçïÊçâ‰∏≠ÔºåÁé∞ÊúâÊñπÊ≥ïÈöæ‰ª•Ê≥õÂåñÂà∞‰∏çÂêå‰ΩìÂûãÔºàÂ¶ÇÂÑøÁ´•ÔºâÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ï‰∏ªË¶Å‰æùËµñ‰∫éÊ®°ÊùøÊàê‰∫∫‰ΩìÂûãÂª∫Ê®°ËÆ≠ÁªÉÊï∞ÊçÆÔºåÂøΩÁï•‰∫Ü‰ΩìÂûãÂ∑ÆÂºÇÂØºËá¥ÁöÑIMUÊµãÈáèÂä†ÈÄüÂ∫¶ÂèòÂåñ„ÄÇSAIPÈÄöËøáËß£ËÄ¶‰∏é‰ΩìÂûãÂíåÂßøÊÄÅÁõ∏ÂÖ≥ÁöÑ‰º†ÊÑüÂô®ÊµãÈáèÂÄºÔºåÊúâÊïàÂª∫Ê®°ÂÆÉ‰ª¨ÁöÑËÅîÂêàÁõ∏ÂÖ≥ÊÄß„ÄÇÈ¶ñÂÖàÔºåËÆ≠ÁªÉÂõûÂΩíÊ®°ÂûãÂ∞ÜÁúüÂÆû‰ΩìÂûãÁöÑIMUÂä†ÈÄüÂ∫¶ËΩ¨Êç¢‰∏∫Ê®°ÊùøÊàê‰∫∫‰ΩìÂûãÔºåË°•ÂÅø‰ΩìÂûãÁõ∏ÂÖ≥ÁöÑ‰º†ÊÑüÂô®ÊµãÈáèÂÄº„ÄÇÁÑ∂ÂêéÔºåÈááÁî®Áé∞ÊúâÊñπÊ≥ï‰º∞ËÆ°Ê®°Êùø‰ΩìÂûãÁöÑÂÖ®Ë∫´ËøêÂä®„ÄÇÊé•ÁùÄÔºåÂà©Áî®Á¨¨‰∫å‰∏™ÂõûÂΩíÊ®°ÂûãÂ∞ÜÂÖ≥ËäÇÈÄüÂ∫¶Êò†Â∞ÑÂõûÁúüÂÆû‰ΩìÂûãÔºåÂπ∂ÁªìÂêà‰ΩìÂûãÊÑüÁü•ÁöÑÁâ©ÁêÜ‰ºòÂåñÁ≠ñÁï•ËÆ°ÁÆóÂÖ®Â±ÄËøêÂä®„ÄÇÊ≠§Â§ñÔºåSAIPÂºïÂÖ•‰∫ÜÊÉØÊÄßÂΩ¢Áä∂‰º∞ËÆ°ÊñπÊ°àÔºåÈÄöËøáMLPÁΩëÁªúÂª∫Ê®°‰ΩìÂûãÊù°‰ª∂‰∏ãÁöÑIMU-ÂßøÊÄÅÁõ∏ÂÖ≥ÊÄß„ÄÇ‰∏∫‰∫ÜÈ™åËØÅSAIPÁöÑÊúâÊïàÊÄßÔºåÊú¨ÊñáÊûÑÂª∫‰∫ÜÂåÖÂê´‰∏çÂêå‰ΩìÂûã‰∏™‰ΩìÔºà10ÂêçÂÑøÁ´•Âíå10ÂêçÊàê‰∫∫ÔºåË∫´È´ò110cm-190cmÔºâÁöÑIMUËøêÂä®ÊçïÊçâÊï∞ÊçÆÈõÜÔºåÂÖ±ËÆ°400ÂàÜÈíüÁöÑÈÖçÂØπIMU-MotionÊ†∑Êú¨„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåSAIPËÉΩÂ§üÊúâÊïàÂ§ÑÁêÜ‰∏çÂêå‰ΩìÂûãÁöÑ‰∫∫‰ΩìÂä®‰ΩúÊçïÊçâ‰ªªÂä°„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÂü∫‰∫éÁ®ÄÁñèÊÉØÊÄß‰º†ÊÑüÂô®ÁöÑ‰∫∫‰ΩìÂä®‰ΩúÊçïÊçâÊñπÊ≥ïÔºå‰∏•Èáç‰æùËµñ‰∫éÊ®°ÊùøÊàê‰∫∫‰ΩìÂûãËøõË°åËÆ≠ÁªÉÔºåÂØºËá¥Ê®°ÂûãÈöæ‰ª•Ê≥õÂåñÂà∞‰ΩìÂûãÂ∑ÆÂºÇËæÉÂ§ßÁöÑ‰∏™‰ΩìÔºå‰æãÂ¶ÇÂÑøÁ´•„ÄÇËøôÊòØÂõ†‰∏∫‰∏çÂêå‰ΩìÂûã‰ºöÂØºËá¥IMU‰º†ÊÑüÂô®ÊµãÈáèÁöÑÂä†ÈÄüÂ∫¶ÂèëÁîüÂèòÂåñÔºå‰ªéËÄåÂΩ±ÂìçÂßøÊÄÅ‰º∞ËÆ°ÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöSAIPÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞Ü‰ΩìÂûãÂíåÂßøÊÄÅÁöÑÂΩ±ÂìçËøõË°åËß£ËÄ¶ÔºåÈÄöËøáÂ≠¶‰π†‰∏Ä‰∏™‰ΩìÂûãËΩ¨Êç¢Ê®°ÂûãÔºåÂ∞ÜÁúüÂÆû‰ΩìÂûãÁöÑIMUÊµãÈáèÂÄºËΩ¨Êç¢Âà∞Ê®°ÊùøÊàê‰∫∫‰ΩìÂûã‰∏äÔºå‰ªéËÄåÊ∂àÈô§‰ΩìÂûãÂ∑ÆÂºÇÂ∏¶Êù•ÁöÑÂΩ±Âìç„ÄÇÁÑ∂ÂêéÂÜçÂà©Áî®Áé∞ÊúâÁöÑÂä®‰ΩúÊçïÊçâÊñπÊ≥ï‰º∞ËÆ°Ê®°Êùø‰ΩìÂûãÁöÑÂßøÊÄÅÔºåÊúÄÂêéÂÜçÂ∞ÜÂßøÊÄÅÊò†Â∞ÑÂõûÁúüÂÆû‰ΩìÂûã„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöSAIPÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´‰∏â‰∏™‰∏ªË¶ÅÈò∂ÊÆµÔºö1) ‰ΩìÂûãËΩ¨Êç¢ÔºöËÆ≠ÁªÉ‰∏Ä‰∏™ÂõûÂΩíÊ®°ÂûãÔºåÂ∞ÜÁúüÂÆû‰ΩìÂûãÁöÑIMUÂä†ÈÄüÂ∫¶ËΩ¨Êç¢‰∏∫Ê®°ÊùøÊàê‰∫∫‰ΩìÂûãÂØπÂ∫îÁöÑÂä†ÈÄüÂ∫¶„ÄÇ2) ÂßøÊÄÅ‰º∞ËÆ°ÔºöÂà©Áî®ËΩ¨Êç¢ÂêéÁöÑÂä†ÈÄüÂ∫¶ÔºåÈááÁî®Áé∞ÊúâÁöÑÂä®‰ΩúÊçïÊçâÊñπÊ≥ï‰º∞ËÆ°Ê®°ÊùøÊàê‰∫∫‰ΩìÂûãÁöÑÂßøÊÄÅ„ÄÇ3) ÂßøÊÄÅÂèçÂêëÊò†Â∞Ñ‰∏é‰ºòÂåñÔºöËÆ≠ÁªÉÁ¨¨‰∫å‰∏™ÂõûÂΩíÊ®°ÂûãÔºåÂ∞ÜÊ®°Êùø‰ΩìÂûãÁöÑÂÖ≥ËäÇÈÄüÂ∫¶Êò†Â∞ÑÂõûÁúüÂÆû‰ΩìÂûãÔºåÂπ∂ÁªìÂêà‰ΩìÂûãÊÑüÁü•ÁöÑÁâ©ÁêÜ‰ºòÂåñÁ≠ñÁï•ÔºåËÆ°ÁÆóÁúüÂÆû‰ΩìÂûãÁöÑÂÖ®Â±ÄËøêÂä®„ÄÇÊ≠§Â§ñÔºåËøòÂåÖÂê´‰∏Ä‰∏™‰ΩìÂûã‰º∞ËÆ°Ê®°ÂùóÔºåÁî®‰∫é‰º∞ËÆ°‰∏™‰ΩìÁöÑ‰ΩìÂûãÂèÇÊï∞„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöSAIPÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1) ÊèêÂá∫‰∫Ü‰ΩìÂûãÊÑüÁü•ÁöÑÂä®‰ΩúÊçïÊçâÊ°ÜÊû∂ÔºåËÉΩÂ§üÊúâÊïàÂ§ÑÁêÜ‰∏çÂêå‰ΩìÂûãÁöÑ‰∫∫‰ΩìÂä®‰ΩúÊçïÊçâ‰ªªÂä°„ÄÇ2) ÊèêÂá∫‰∫Ü‰ΩìÂûãËΩ¨Êç¢Ê®°ÂûãÔºåËÉΩÂ§üÂ∞ÜÁúüÂÆû‰ΩìÂûãÁöÑIMUÊµãÈáèÂÄºËΩ¨Êç¢Âà∞Ê®°ÊùøÊàê‰∫∫‰ΩìÂûã‰∏äÔºå‰ªéËÄåÊ∂àÈô§‰ΩìÂûãÂ∑ÆÂºÇÁöÑÂΩ±Âìç„ÄÇ3) ÊèêÂá∫‰∫ÜÊÉØÊÄßÂΩ¢Áä∂‰º∞ËÆ°ÊñπÊ°àÔºåÈÄöËøáÂª∫Ê®°‰ΩìÂûãÊù°‰ª∂‰∏ãÁöÑIMU-ÂßøÊÄÅÁõ∏ÂÖ≥ÊÄßÔºåÂÆûÁé∞‰ΩìÂûã‰º∞ËÆ°„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**Ôºö‰ΩìÂûãËΩ¨Êç¢Ê®°ÂûãÈááÁî®MLPÁΩëÁªúÔºåËæìÂÖ•‰∏∫ÁúüÂÆû‰ΩìÂûãÁöÑIMUÂä†ÈÄüÂ∫¶ÔºåËæìÂá∫‰∏∫Ê®°ÊùøÊàê‰∫∫‰ΩìÂûãÂØπÂ∫îÁöÑÂä†ÈÄüÂ∫¶„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨ÈáçÊûÑÊçüÂ§±ÂíåÊ≠£ÂàôÂåñÈ°π„ÄÇÂßøÊÄÅÂèçÂêëÊò†Â∞ÑÊ®°Âûã‰πüÈááÁî®MLPÁΩëÁªúÔºåËæìÂÖ•‰∏∫Ê®°Êùø‰ΩìÂûãÁöÑÂÖ≥ËäÇÈÄüÂ∫¶ÔºåËæìÂá∫‰∏∫ÁúüÂÆû‰ΩìÂûãÁöÑÂÖ≥ËäÇÈÄüÂ∫¶„ÄÇ‰ΩìÂûã‰º∞ËÆ°Ê®°ÂùóÈááÁî®MLPÁΩëÁªúÔºåËæìÂÖ•‰∏∫IMUÊµãÈáèÂÄºÂíåÂßøÊÄÅ‰ø°ÊÅØÔºåËæìÂá∫‰∏∫‰ΩìÂûãÂèÇÊï∞„ÄÇÁâ©ÁêÜ‰ºòÂåñÁ≠ñÁï•ËÄÉËôë‰∫Ü‰ΩìÂûã‰ø°ÊÅØÔºå‰æãÂ¶ÇÈ™®È™ºÈïøÂ∫¶ÂíåË¥®ÈáèÂàÜÂ∏É„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

SAIPÂú®ÂåÖÂê´ÂÑøÁ´•ÂíåÊàê‰∫∫ÁöÑÊï∞ÊçÆÈõÜ‰∏äËøõË°å‰∫ÜËØÑ‰º∞ÔºåÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåSAIPËÉΩÂ§üÊòæËëóÊèêÈ´òÂä®‰ΩúÊçïÊçâÁöÑÂáÜÁ°ÆÊÄß„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåSAIPÂú®‰∏çÂêå‰ΩìÂûã‰∏™‰Ωì‰∏äÁöÑÂä®‰ΩúÊçïÊçâËØØÂ∑ÆÈôç‰Ωé‰∫Ü10%-20%„ÄÇÊ≠§Â§ñÔºåSAIPÊèêÂá∫ÁöÑÊÉØÊÄßÂΩ¢Áä∂‰º∞ËÆ°ÊñπÊ°àËÉΩÂ§üÊúâÊïàÂú∞‰º∞ËÆ°‰∏™‰ΩìÁöÑ‰ΩìÂûãÂèÇÊï∞Ôºå‰∏∫ÂêéÁª≠ÁöÑÂä®‰ΩúÊçïÊçâÂíåÂàÜÊûêÊèê‰æõ‰∫ÜÈáçË¶ÅÁöÑ‰ø°ÊÅØ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

SAIPÂú®ËôöÊãüÁé∞ÂÆû„ÄÅÊ∏∏Êàè„ÄÅÂä®ÁîªÂà∂‰Ωú„ÄÅËøêÂä®ÂàÜÊûê„ÄÅÂ∫∑Â§çËÆ≠ÁªÉÁ≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇËØ•ÊñπÊ≥ïËÉΩÂ§üÂÆûÁé∞ÂØπ‰∏çÂêå‰ΩìÂûã‰∏™‰ΩìÁöÑÁ≤æÁ°ÆÂä®‰ΩúÊçïÊçâÔºå‰ªéËÄåÊèêÈ´òÁî®Êà∑‰ΩìÈ™åÂíåÂ∫îÁî®ÊïàÊûú„ÄÇ‰æãÂ¶ÇÔºåÂú®VRÊ∏∏Êàè‰∏≠ÔºåÂÑøÁ´•ÂèØ‰ª•‰ΩøÁî®SAIPËøõË°åÂä®‰ΩúÊçïÊçâÔºå‰ªéËÄåËé∑ÂæóÊõ¥ÁúüÂÆûÁöÑÊ≤âÊµ∏Âºè‰ΩìÈ™å„ÄÇÂú®ËøêÂä®ÂàÜÊûê‰∏≠ÔºåSAIPÂèØ‰ª•Áî®‰∫éÂàÜÊûê‰∏çÂêå‰ΩìÂûãËøêÂä®ÂëòÁöÑËøêÂä®ÂßøÊÄÅÂíåÊäÄÊúØÁâπÁÇπ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Human motion capture with sparse inertial sensors has gained significant attention recently. However, existing methods almost exclusively rely on a template adult body shape to model the training data, which poses challenges when generalizing to individuals with largely different body shapes (such as a child). This is primarily due to the variation in IMU-measured acceleration caused by changes in body shape. To fill this gap, we propose Shape-aware Inertial Poser (SAIP), the first solution considering body shape differences in sparse inertial-based motion capture. Specifically, we decompose the sensor measurements related to shape and pose in order to effectively model their joint correlations. Firstly, we train a regression model to transfer the IMU-measured accelerations of a real body to match the template adult body model, compensating for the shape-related sensor measurements. Then, we can easily follow the state-of-the-art methods to estimate the full body motions of the template-shaped body. Finally, we utilize a second regression model to map the joint velocities back to the real body, combined with a shape-aware physical optimization strategy to calculate global motions on the subject. Furthermore, our method relies on body shape awareness, introducing the first inertial shape estimation scheme. This is accomplished by modeling the shape-conditioned IMU-pose correlation using an MLP-based network. To validate the effectiveness of SAIP, we also present the first IMU motion capture dataset containing individuals of different body sizes. This dataset features 10 children and 10 adults, with heights ranging from 110 cm to 190 cm, and a total of 400 minutes of paired IMU-Motion samples. Extensive experimental results demonstrate that SAIP can effectively handle motion capture tasks for diverse body shapes. The code and dataset are available at https://github.com/yinlu5942/SAIP.

