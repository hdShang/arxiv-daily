---
layout: default
title: X2Video: Adapting Diffusion Models for Multimodal Controllable Neural Video Rendering
---

# X2Video: Adapting Diffusion Models for Multimodal Controllable Neural Video Rendering

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.08530" class="toolbar-btn" target="_blank">üìÑ arXiv: 2510.08530v1</a>
  <a href="https://arxiv.org/pdf/2510.08530.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.08530v1" onclick="toggleFavorite(this, '2510.08530v1', 'X2Video: Adapting Diffusion Models for Multimodal Controllable Neural Video Rendering')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Zhitong Huang, Mohan Zhang, Renhan Wang, Rui Tang, Hao Zhu, Jing Liao

**ÂàÜÁ±ª**: cs.GR, cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-09

**Â§áÊ≥®**: Code, model, and dataset will be released at project page soon: https://luckyhzt.github.io/x2video

**üîó ‰ª£Á†Å/È°πÁõÆ**: [PROJECT_PAGE](https://luckyhzt.github.io/x2video)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫X2Video‰ª•Ëß£ÂÜ≥Â§öÊ®°ÊÄÅËßÜÈ¢ëÊ∏≤ÊüìÊéßÂà∂ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËßÜÈ¢ëÁîüÊàê` `Êâ©Êï£Ê®°Âûã` `Â§öÊ®°ÊÄÅÊéßÂà∂` `ÂÖâÁ∫øÁúüÂÆûÊÑü` `Ëá™Ê≥®ÊÑèÂäõÊú∫Âà∂` `ÈÄíÂΩíÈááÊ†∑` `ÂÜÖÂú®ÂºïÂØº` `ÂõæÂÉèÂ§ÑÁêÜ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËßÜÈ¢ëÁîüÊàêÊñπÊ≥ïÂú®Â§öÊ®°ÊÄÅÊéßÂà∂ÂíåÊó∂Èó¥‰∏ÄËá¥ÊÄßÊñπÈù¢Â≠òÂú®‰∏çË∂≥ÔºåÈöæ‰ª•ÂÆûÁé∞È´òË¥®ÈáèÁöÑÂÖâÁ∫øÁúüÂÆûÊÑüËßÜÈ¢ëÊ∏≤Êüì„ÄÇ
2. X2VideoÈÄöËøáÊâ©Êï£Ê®°ÂûãÁªìÂêàÂÜÖÂú®ÂºïÂØºÂíåÂ§öÊ®°ÊÄÅÊéßÂà∂ÔºåÈááÁî®Ê∑∑ÂêàËá™Ê≥®ÊÑèÂäõÊú∫Âà∂ÂíåÊé©ËîΩ‰∫§ÂèâÊ≥®ÊÑèÂäõÊú∫Âà∂ÔºåÊèêÂçáËßÜÈ¢ëÁîüÊàêÁöÑË¥®ÈáèÂíåÁÅµÊ¥ªÊÄß„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåX2VideoËÉΩÂ§üÁîüÊàêÈïøÊó∂Èó¥‰∏ÄËá¥‰∏îÂÖâÁ∫øÁúüÂÆûÊÑüÁöÑËßÜÈ¢ëÔºåÊîØÊåÅÂ§öÁßçÊéßÂà∂ÊñπÂºèÔºåÊòæËëóÊèêÂçá‰∫ÜÁîüÊàêÊïàÊûú„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êàë‰ª¨ÊèêÂá∫‰∫ÜX2VideoÔºåËøôÊòØÁ¨¨‰∏Ä‰∏™Âü∫‰∫éÊâ©Êï£Ê®°ÂûãÁöÑÂÖâÁ∫øÁúüÂÆûÊÑüËßÜÈ¢ëÊ∏≤ÊüìÊñπÊ≥ïÔºåËÉΩÂ§üÈÄöËøáÂÜÖÂú®ÈÄöÈÅìÔºàÂ¶ÇÂèçÁÖßÁéá„ÄÅÊ≥ïÁ∫ø„ÄÅÁ≤óÁ≥ôÂ∫¶„ÄÅÈáëÂ±ûÂ∫¶ÂíåËæêÁÖßÂ∫¶ÔºâËøõË°åÂºïÂØºÔºåÂêåÊó∂ÊîØÊåÅÈÄöËøáÂèÇËÄÉÂõæÂÉèÂíåÊñáÊú¨ÊèêÁ§∫ËøõË°åÁõ¥ËßÇÁöÑÂ§öÊ®°ÊÄÅÊéßÂà∂„ÄÇÂÜÖÂú®ÂºïÂØºÂÖÅËÆ∏ÂØπÈ¢úËâ≤„ÄÅÊùêÊñô„ÄÅÂá†‰ΩïÂΩ¢Áä∂ÂíåÂÖâÁÖßËøõË°åÂáÜÁ°ÆÊìçÊéßÔºåËÄåÂèÇËÄÉÂõæÂÉèÂíåÊñáÊú¨ÊèêÁ§∫ÂàôÂú®Áº∫‰πèÂÜÖÂú®‰ø°ÊÅØÊó∂Êèê‰æõÁõ¥ËßÇË∞ÉÊï¥„ÄÇ‰∏∫ÂÆûÁé∞Ëøô‰∫õÂäüËÉΩÔºåÊàë‰ª¨ÈÄöËøáÈááÁî®Êñ∞È¢ñÈ´òÊïàÁöÑÊ∑∑ÂêàËá™Ê≥®ÊÑèÂäõÊú∫Âà∂Â∞ÜÂÜÖÂú®ÂºïÂØºÂõæÂÉèÁîüÊàêÊ®°ÂûãXRGBÊâ©Â±ïÂà∞ËßÜÈ¢ëÁîüÊàêÔºåÁ°Æ‰øùËßÜÈ¢ëÂ∏ß‰πãÈó¥ÁöÑÊó∂Èó¥‰∏ÄËá¥ÊÄßÔºåÂπ∂Â¢ûÂº∫ÂØπÂèÇËÄÉÂõæÂÉèÁöÑ‰øùÁúüÂ∫¶„ÄÇÊàë‰ª¨ËøòÂºÄÂèë‰∫ÜÊé©ËîΩ‰∫§ÂèâÊ≥®ÊÑèÂäõÊú∫Âà∂Ôºå‰ª•ÊúâÊïàËß£ËÄ¶ÂÖ®Â±ÄÂíåÂ±ÄÈÉ®ÊñáÊú¨ÊèêÁ§∫ÔºåÂπ∂Â∞ÜÂÖ∂Â∫îÁî®‰∫éÁõ∏Â∫îÁöÑÂå∫Âüü„ÄÇÊàë‰ª¨ÁöÑÈÄíÂΩíÈááÊ†∑ÊñπÊ≥ïÁªìÂêàÂÖ≥ÈîÆÂ∏ßÈ¢ÑÊµãÂíåÂ∏ßÊèíÂÄºÔºåÊîØÊåÅÈïøËßÜÈ¢ëÁîüÊàêÔºå‰øùÊåÅÈïøÊó∂Èó¥ËåÉÂõ¥ÂÜÖÁöÑ‰∏ÄËá¥ÊÄßÂπ∂Èò≤Ê≠¢ÈîôËØØÁ¥ØÁßØ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâËßÜÈ¢ëÁîüÊàêÊñπÊ≥ïÂú®Â§öÊ®°ÊÄÅÊéßÂà∂ÂíåÊó∂Èó¥‰∏ÄËá¥ÊÄßÊñπÈù¢ÁöÑ‰∏çË∂≥ÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂÖâÁ∫øÁúüÂÆûÊÑüËßÜÈ¢ëÊ∏≤Êüì‰∏≠ÔºåÂ¶Ç‰ΩïÊúâÊïàÂà©Áî®ÂÜÖÂú®ÈÄöÈÅì‰ø°ÊÅØËøõË°åÂºïÂØº„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊàë‰ª¨ÊèêÂá∫X2VideoÔºåÈÄöËøáÊâ©Êï£Ê®°ÂûãÂÆûÁé∞ËßÜÈ¢ëÁîüÊàêÔºåÁªìÂêàÂÜÖÂú®ÂºïÂØºÂíåÂ§öÊ®°ÊÄÅÊéßÂà∂ÔºåÈááÁî®Ê∑∑ÂêàËá™Ê≥®ÊÑèÂäõÊú∫Âà∂Á°Æ‰øùÊó∂Èó¥‰∏ÄËá¥ÊÄßÔºåÂêåÊó∂ÂºïÂÖ•Êé©ËîΩ‰∫§ÂèâÊ≥®ÊÑèÂäõÊú∫Âà∂‰ª•Â§ÑÁêÜÂÖ®Â±ÄÂíåÂ±ÄÈÉ®ÊñáÊú¨ÊèêÁ§∫„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöX2VideoÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨ÂÜÖÂú®ÂºïÂØºÊ®°Âùó„ÄÅÊ∑∑ÂêàËá™Ê≥®ÊÑèÂäõÊ®°Âùó„ÄÅÊé©ËîΩ‰∫§ÂèâÊ≥®ÊÑèÂäõÊ®°ÂùóÂíåÈÄíÂΩíÈááÊ†∑Ê®°Âùó„ÄÇÂÜÖÂú®ÂºïÂØºÊ®°ÂùóË¥üË¥£ÊèêÂèñÂíåÂ§ÑÁêÜÂÜÖÂú®ÈÄöÈÅì‰ø°ÊÅØÔºåÊ∑∑ÂêàËá™Ê≥®ÊÑèÂäõÊ®°ÂùóÁ°Æ‰øùÂ∏ßÈó¥‰∏ÄËá¥ÊÄßÔºåÊé©ËîΩ‰∫§ÂèâÊ≥®ÊÑèÂäõÊ®°ÂùóÂ§ÑÁêÜÂ§öÊ®°ÊÄÅËæìÂÖ•ÔºåÈÄíÂΩíÈááÊ†∑Ê®°ÂùóÁî®‰∫éÈïøËßÜÈ¢ëÁîüÊàê„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöX2VideoÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÂ∞ÜÂÜÖÂú®ÂºïÂØº‰∏éÂ§öÊ®°ÊÄÅÊéßÂà∂Áõ∏ÁªìÂêàÔºåÈááÁî®Ê∑∑ÂêàËá™Ê≥®ÊÑèÂäõÊú∫Âà∂ÂíåÈÄíÂΩíÈááÊ†∑ÊñπÊ≥ïÔºåÊòæËëóÊèêÂçá‰∫ÜËßÜÈ¢ëÁîüÊàêÁöÑË¥®ÈáèÂíå‰∏ÄËá¥ÊÄßÔºåÂ∞§ÂÖ∂ÊòØÂú®ÈïøËßÜÈ¢ëÁîüÊàê‰∏≠„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°‰∏≠ÔºåÊàë‰ª¨ËÆæÁΩÆ‰∫ÜÁâπÂÆöÁöÑÊçüÂ§±ÂáΩÊï∞‰ª•‰ºòÂåñËßÜÈ¢ëË¥®ÈáèÔºåÈááÁî®‰∫ÜÈ´òÊïàÁöÑÁΩëÁªúÁªìÊûÑ‰ª•ÊîØÊåÅÂ§ßËßÑÊ®°ËßÜÈ¢ëÊï∞ÊçÆÁöÑÂ§ÑÁêÜÔºåÂπ∂ÈÄöËøáÈÄíÂΩíÈááÊ†∑Á≠ñÁï•ÂáèÂ∞ë‰∫ÜÈîôËØØÁ¥ØÁßØÔºåÁ°Æ‰øù‰∫ÜÈïøÊó∂Èó¥ËåÉÂõ¥ÂÜÖÁöÑ‰∏ÄËá¥ÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåX2VideoÂú®ÁîüÊàêÈïøËßÜÈ¢ëÊó∂ËÉΩÂ§ü‰øùÊåÅÊó∂Èó¥‰∏ÄËá¥ÊÄßÂíåÂÖâÁ∫øÁúüÂÆûÊÑüÔºåÁõ∏ËæÉ‰∫éÂü∫Á∫øÊñπÊ≥ïÔºåËßÜÈ¢ëË¥®ÈáèÊèêÂçáÊòæËëó„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåX2VideoÂú®Â§öÊ®°ÊÄÅÊéßÂà∂‰∏ãÁîüÊàêÁöÑÈïøËßÜÈ¢ëÂú®ËßÜËßâÊïàÊûú‰∏ä‰ºò‰∫éÁé∞ÊúâÊäÄÊúØÔºå‰∏îÂú®ÂèÇÊï∞Ë∞É‰ºòÊñπÈù¢Ë°®Áé∞Âá∫Êõ¥È´òÁöÑÁÅµÊ¥ªÊÄßÂíåÂáÜÁ°ÆÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

X2VideoÁöÑÁ†îÁ©∂ÊàêÊûúÂú®Â§ö‰∏™È¢ÜÂüüÂÖ∑ÊúâÊΩúÂú®Â∫îÁî®‰ª∑ÂÄºÔºåÂåÖÊã¨ÁîµÂΩ±Âà∂‰Ωú„ÄÅÊ∏∏ÊàèÂºÄÂèë„ÄÅËôöÊãüÁé∞ÂÆûÂíåÂ¢ûÂº∫Áé∞ÂÆûÁ≠â„ÄÇÈÄöËøáÂÆûÁé∞È´òË¥®ÈáèÁöÑÂÖâÁ∫øÁúüÂÆûÊÑüËßÜÈ¢ëÁîüÊàêÔºåËØ•ÊäÄÊúØËÉΩÂ§ü‰∏∫Âàõ‰ΩúËÄÖÊèê‰æõÊõ¥ÁÅµÊ¥ªÁöÑÂ∑•ÂÖ∑ÔºåÊèêÂçáËßÜËßâÂÜÖÂÆπÁöÑÂàõ‰ΩúÊïàÁéáÂíåË¥®ÈáèÔºåÊú™Êù•ÂèØËÉΩÂú®Êï∞Â≠óÂÜÖÂÆπÂàõ‰Ωú‰∏≠ÂèëÊå•ÈáçË¶Å‰ΩúÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> We present X2Video, the first diffusion model for rendering photorealistic videos guided by intrinsic channels including albedo, normal, roughness, metallicity, and irradiance, while supporting intuitive multi-modal controls with reference images and text prompts for both global and local regions. The intrinsic guidance allows accurate manipulation of color, material, geometry, and lighting, while reference images and text prompts provide intuitive adjustments in the absence of intrinsic information. To enable these functionalities, we extend the intrinsic-guided image generation model XRGB to video generation by employing a novel and efficient Hybrid Self-Attention, which ensures temporal consistency across video frames and also enhances fidelity to reference images. We further develop a Masked Cross-Attention to disentangle global and local text prompts, applying them effectively onto respective local and global regions. For generating long videos, our novel Recursive Sampling method incorporates progressive frame sampling, combining keyframe prediction and frame interpolation to maintain long-range temporal consistency while preventing error accumulation. To support the training of X2Video, we assembled a video dataset named InteriorVideo, featuring 1,154 rooms from 295 interior scenes, complete with reliable ground-truth intrinsic channel sequences and smooth camera trajectories. Both qualitative and quantitative evaluations demonstrate that X2Video can produce long, temporally consistent, and photorealistic videos guided by intrinsic conditions. Additionally, X2Video effectively accommodates multi-modal controls with reference images, global and local text prompts, and simultaneously supports editing on color, material, geometry, and lighting through parametric tuning. Project page: https://luckyhzt.github.io/x2video

