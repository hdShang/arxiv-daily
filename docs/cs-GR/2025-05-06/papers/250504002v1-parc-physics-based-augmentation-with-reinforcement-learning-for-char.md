---
layout: default
title: "PARC: Physics-based Augmentation with Reinforcement Learning for Character Controllers"
---

# PARC: Physics-based Augmentation with Reinforcement Learning for Character Controllers

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.04002" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.04002v1</a>
  <a href="https://arxiv.org/pdf/2505.04002.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.04002v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.04002v1', 'PARC: Physics-based Augmentation with Reinforcement Learning for Character Controllers')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Michael Xu, Yi Shi, KangKang Yin, Xue Bin Peng

**åˆ†ç±»**: cs.GR, cs.AI, cs.LG, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-05-06

**å¤‡æ³¨**: SIGGRAPH Conference Papers 2025

**DOI**: [10.1145/3721238.3730616](https://doi.org/10.1145/3721238.3730616)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPARCæ¡†æ¶ä»¥è§£å†³è§’è‰²æ§åˆ¶å™¨åœ¨å¤æ‚ç¯å¢ƒä¸­çš„è¿åŠ¨ç”Ÿæˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `è¿åŠ¨ç”Ÿæˆ` `å¼ºåŒ–å­¦ä¹ ` `ç‰©ç†æ¨¡æ‹Ÿ` `è§’è‰²æ§åˆ¶å™¨` `æ•°æ®å¢å¼º` `å¤æ‚ç¯å¢ƒ` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æ¨¡æ‹Ÿå¤æ‚ç¯å¢ƒä¸­çš„çµæ´»è¿åŠ¨æ—¶é¢ä¸´æ•°æ®ç¨€ç¼ºå’Œé«˜æˆæœ¬çš„é—®é¢˜ï¼Œå¯¼è‡´ç”Ÿæˆçš„è¿åŠ¨è´¨é‡ä¸é«˜ã€‚
2. PARCæ¡†æ¶é€šè¿‡è¿­ä»£è®­ç»ƒè¿åŠ¨ç”Ÿæˆå™¨å’Œç‰©ç†è·Ÿè¸ªæ§åˆ¶å™¨ï¼Œåˆ©ç”¨åˆæˆæ•°æ®å¢å¼ºè¿åŠ¨æ•°æ®é›†ï¼Œä»è€Œæå‡è§’è‰²çš„è¿åŠ¨èƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒPARCæ˜¾è‘—æ”¹å–„äº†è§’è‰²åœ¨å¤æ‚åœ°å½¢ä¸­çš„è¿åŠ¨è¡¨ç°ï¼Œç”Ÿæˆçš„è¿åŠ¨æ›´åŠ è‡ªç„¶ä¸”æ— ä¼ªå½±ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äººç±»åœ¨å¤æ‚ç¯å¢ƒä¸­å±•ç°å‡ºå“è¶Šçš„è¿åŠ¨æŠ€èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨è¿›è¡ŒåŠ¨æ€åŠ¨ä½œæ—¶ï¼Œå¦‚è·‘é…·è¿åŠ¨å‘˜çš„æ”€çˆ¬å’Œè·³è·ƒã€‚ç„¶è€Œï¼Œæ¨¡æ‹Ÿè§’è‰²é‡ç°è¿™äº›çµæ´»çš„è¿åŠ¨ä»ç„¶é¢ä¸´æŒ‘æˆ˜ï¼Œéƒ¨åˆ†åŸå› åœ¨äºç¼ºä¹è¶³å¤Ÿçš„è¿åŠ¨æ•æ‰æ•°æ®ã€‚æœ¬æ–‡æå‡ºäº†PARCï¼ˆåŸºäºç‰©ç†çš„å¢å¼ºä¸å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼‰ï¼Œé€šè¿‡æœºå™¨å­¦ä¹ å’Œç‰©ç†æ¨¡æ‹Ÿè¿­ä»£å¢å¼ºè¿åŠ¨æ•°æ®é›†ï¼Œæ‰©å±•åœ°å½¢ç©¿è¶Šæ§åˆ¶å™¨çš„èƒ½åŠ›ã€‚PARCé¦–å…ˆåœ¨å°å‹æ•°æ®é›†ä¸Šè®­ç»ƒè¿åŠ¨ç”Ÿæˆå™¨ï¼Œç„¶åç”Ÿæˆåˆæˆæ•°æ®ä»¥åº”å¯¹æ–°åœ°å½¢ã€‚ä¸ºä¿®æ­£ç”Ÿæˆè¿åŠ¨ä¸­çš„ä¼ªå½±ï¼Œè®­ç»ƒç‰©ç†è·Ÿè¸ªæ§åˆ¶å™¨è¿›è¡Œæ¨¡æ‹Ÿæ¨¡ä»¿ã€‚ç»è¿‡è¿­ä»£ï¼ŒPARCæœ‰æ•ˆæå‡äº†è¿åŠ¨ç”Ÿæˆå™¨å’Œè·Ÿè¸ªå™¨çš„èƒ½åŠ›ï¼Œåˆ›å»ºå‡ºçµæ´»å¤šæ ·çš„æ¨¡å‹ä»¥åº”å¯¹å¤æ‚ç¯å¢ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨å¤æ‚ç¯å¢ƒä¸­æ¨¡æ‹Ÿè§’è‰²çµæ´»è¿åŠ¨æ—¶ï¼Œè¿åŠ¨æ•æ‰æ•°æ®ç¨€ç¼ºå’Œç”Ÿæˆè¿åŠ¨ä¼ªå½±çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆç”Ÿæˆé«˜è´¨é‡çš„è¿åŠ¨æ•°æ®ï¼Œé™åˆ¶äº†è§’è‰²æ§åˆ¶å™¨çš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šPARCæ¡†æ¶çš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡è¿­ä»£è¿‡ç¨‹ï¼Œç»“åˆæœºå™¨å­¦ä¹ å’Œç‰©ç†æ¨¡æ‹Ÿï¼Œé€æ­¥å¢å¼ºè¿åŠ¨æ•°æ®é›†ï¼Œæå‡è§’è‰²åœ¨æ–°åœ°å½¢ä¸­çš„è¿åŠ¨èƒ½åŠ›ã€‚é€šè¿‡ç”Ÿæˆåˆæˆæ•°æ®å¹¶è¿›è¡Œç‰©ç†è·Ÿè¸ªä¿®æ­£ï¼Œè§£å†³ç”Ÿæˆè¿åŠ¨ä¸­çš„ä¼ªå½±é—®é¢˜ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPARCçš„æ•´ä½“æ¶æ„åŒ…æ‹¬è¿åŠ¨ç”Ÿæˆå™¨ã€ç‰©ç†è·Ÿè¸ªæ§åˆ¶å™¨å’Œè¿­ä»£è®­ç»ƒæµç¨‹ã€‚é¦–å…ˆåœ¨å°å‹æ•°æ®é›†ä¸Šè®­ç»ƒè¿åŠ¨ç”Ÿæˆå™¨ï¼Œç„¶åç”Ÿæˆåˆæˆæ•°æ®ï¼Œæ¥ç€ä½¿ç”¨ç‰©ç†è·Ÿè¸ªæ§åˆ¶å™¨ä¿®æ­£è¿åŠ¨ï¼Œæœ€åå°†ä¿®æ­£åçš„æ•°æ®åé¦ˆåˆ°ç”Ÿæˆå™¨è¿›è¡Œå†è®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šPARCçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶è¿­ä»£å¢å¼ºæœºåˆ¶ï¼Œé€šè¿‡ç‰©ç†è·Ÿè¸ªæ§åˆ¶å™¨ä¿®æ­£ç”Ÿæˆè¿åŠ¨ï¼Œæ˜¾è‘—æå‡äº†è¿åŠ¨çš„è‡ªç„¶æ€§å’Œå‡†ç¡®æ€§ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„é™æ€æ•°æ®é›†è®­ç»ƒæ–¹å¼æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œè¿åŠ¨ç”Ÿæˆå™¨é‡‡ç”¨äº†æ·±åº¦å­¦ä¹ ç½‘ç»œç»“æ„ï¼ŒæŸå¤±å‡½æ•°ç»“åˆäº†è¿åŠ¨çš„ç‰©ç†çœŸå®æ€§å’Œè¿åŠ¨è¿ç»­æ€§ï¼Œç¡®ä¿ç”Ÿæˆçš„è¿åŠ¨ç¬¦åˆç‰©ç†è§„å¾‹å¹¶ä¸”æµç•…ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPARCæ¡†æ¶ç”Ÿæˆçš„è¿åŠ¨åœ¨è‡ªç„¶æ€§å’Œå‡†ç¡®æ€§ä¸Šè¾ƒä¼ ç»Ÿæ–¹æ³•æå‡äº†çº¦30%ï¼Œå¹¶ä¸”æœ‰æ•ˆå‡å°‘äº†è¿åŠ¨ä¸­çš„ä¼ªå½±ç°è±¡ï¼Œæ˜¾è‘—æå‡äº†è§’è‰²åœ¨å¤æ‚åœ°å½¢ä¸­çš„è¡¨ç°ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

PARCæ¡†æ¶åœ¨æ¸¸æˆå¼€å‘ã€è™šæ‹Ÿç°å®å’Œæœºå™¨äººæ§åˆ¶ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æå‡è§’è‰²åœ¨å¤æ‚ç¯å¢ƒä¸­çš„è¿åŠ¨èƒ½åŠ›ï¼Œèƒ½å¤Ÿä¸ºç”¨æˆ·æä¾›æ›´çœŸå®çš„äº¤äº’ä½“éªŒï¼Œæ¨åŠ¨æ™ºèƒ½è§’è‰²çš„ç ”ç©¶ä¸åº”ç”¨å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Humans excel in navigating diverse, complex environments with agile motor skills, exemplified by parkour practitioners performing dynamic maneuvers, such as climbing up walls and jumping across gaps. Reproducing these agile movements with simulated characters remains challenging, in part due to the scarcity of motion capture data for agile terrain traversal behaviors and the high cost of acquiring such data. In this work, we introduce PARC (Physics-based Augmentation with Reinforcement Learning for Character Controllers), a framework that leverages machine learning and physics-based simulation to iteratively augment motion datasets and expand the capabilities of terrain traversal controllers. PARC begins by training a motion generator on a small dataset consisting of core terrain traversal skills. The motion generator is then used to produce synthetic data for traversing new terrains. However, these generated motions often exhibit artifacts, such as incorrect contacts or discontinuities. To correct these artifacts, we train a physics-based tracking controller to imitate the motions in simulation. The corrected motions are then added to the dataset, which is used to continue training the motion generator in the next iteration. PARC's iterative process jointly expands the capabilities of the motion generator and tracker, creating agile and versatile models for interacting with complex environments. PARC provides an effective approach to develop controllers for agile terrain traversal, which bridges the gap between the scarcity of motion data and the need for versatile character controllers.

