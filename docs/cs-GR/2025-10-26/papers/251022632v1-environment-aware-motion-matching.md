---
layout: default
title: Environment-aware Motion Matching
---

# Environment-aware Motion Matching

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.22632" target="_blank" class="toolbar-btn">arXiv: 2510.22632v1</a>
    <a href="https://arxiv.org/pdf/2510.22632.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.22632v1" 
            onclick="toggleFavorite(this, '2510.22632v1', 'Environment-aware Motion Matching')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Jose Luis Ponton, Sheldon Andrews, Carlos Andujar, Nuria Pelechano

**ÂàÜÁ±ª**: cs.GR, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-26

**Â§áÊ≥®**: Published in ACM TOG and presented in SIGGRAPH ASIA 2025. Project webpage: https://upc-virvig.github.io/Environment-aware-Motion-Matching/

**DOI**: [10.1145/3763334](https://doi.org/10.1145/3763334)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫ÁéØÂ¢ÉÊÑüÁü•ËøêÂä®ÂåπÈÖçÔºåËß£ÂÜ≥ËßíËâ≤‰∏éÂä®ÊÄÅÁéØÂ¢ÉËá™ÁÑ∂‰∫§‰∫íÁöÑÈöæÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±ÂÖ≠ÔºöËßÜÈ¢ëÊèêÂèñ‰∏éÂåπÈÖç (Video Extraction)** **ÊîØÊü±ÂÖ´ÔºöÁâ©ÁêÜÂä®Áîª (Physics-based Animation)**

**ÂÖ≥ÈîÆËØç**: `ËøêÂä®ÂåπÈÖç` `ËßíËâ≤Âä®Áîª` `ÁéØÂ¢ÉÊÑüÁü•` `‰∫∫Êú∫‰∫§‰∫í` `‰∫∫Áæ§Âä®Áîª`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËßíËâ≤Âä®ÁîªÊñπÊ≥ïÈöæ‰ª•Â§ÑÁêÜÂ§çÊùÇÂä®ÊÄÅÁéØÂ¢É‰∫§‰∫íÔºåÁº∫‰πèËá™ÁÑ∂ÊÄßÂíåÁÅµÊ¥ªÊÄß„ÄÇ
2. ÊèêÂá∫ÁéØÂ¢ÉÊÑüÁü•ËøêÂä®ÂåπÈÖçÔºåÈÄöËøáÂä®ÊÄÅË∞ÉÊï¥ÂßøÂäøÂíåËΩ®ËøπÔºå‰ΩøËßíËâ≤Ëá™ÁÑ∂ÈÄÇÂ∫îÁéØÂ¢É„ÄÇ
3. ËØ•ÊñπÊ≥ïÂú®ËøêË°åÊó∂È´òÊïàÊêúÁ¥¢ÂåπÈÖçÁî®Êà∑ËæìÂÖ•ÂíåÂΩìÂâçÂßøÂäøÔºåÂêåÊó∂ÈÅøÂÖç‰∏éÁéØÂ¢ÉÁ¢∞Êíû„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

‰∫§‰∫íÂºèÂ∫îÁî®ÈúÄË¶ÅËßíËâ≤ËÉΩÂ§üÂØπÂä®ÊÄÅÁéØÂ¢ÉÂÅöÂá∫Ëá™ÁÑ∂ÁöÑÂèçÂ∫î„ÄÇ‰º†ÁªüÁöÑËßíËâ≤Âä®ÁîªÊäÄÊúØÈöæ‰ª•Â§ÑÁêÜ‰ªªÊÑèÊÉÖÂÜµÔºåÂõ†Ê≠§Âä®ÊÄÅÈÄâÊã©ËøêÂä®ÊçïÊçâÂä®ÁîªÁöÑÊñπÊ≥ïÊó•ÁõäÊµÅË°åÔºåËøôÁßçÊñπÊ≥ïÂü∫‰∫éÈ¢ÑÂÆö‰πâÁöÑÁâπÂæÅ„ÄÇËøêÂä®ÂåπÈÖçÂú®ÂØπÈΩêÁõÆÊ†áËΩ®ËøπÁöÑËøêÂä®ÊñπÈù¢Â∑≤Ë¢´ËØÅÊòéÊòØÊúâÊïàÁöÑÔºå‰ΩÜÁî±‰∫éÈúÄË¶ÅËÄÉËôëÂë®Âõ¥ÁöÑÂÖÉÁ¥†ÔºåÂõ†Ê≠§Âä®ÁîªÁéØÂ¢É‰∫§‰∫íÂíå‰∫∫Áæ§Ë°å‰∏∫‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊàòÊÄß„ÄÇÁé∞ÊúâÁöÑÊñπÊ≥ïÈÄöÂ∏∏Ê∂âÂèäÊâãÂä®ËÆæÁΩÆÊàñÁº∫‰πèËøêÂä®ÊçïÊçâÁöÑËá™ÁÑ∂ÊÄß„ÄÇÊ≠§Â§ñÔºåÂú®‰∫∫Áæ§Âä®Áîª‰∏≠ÔºåË∫´‰ΩìÂä®ÁîªÈÄöÂ∏∏Ë¢´ËßÜ‰∏∫‰∏éËΩ®ËøπËßÑÂàíÂàÜÁ¶ªÁöÑËøáÁ®ãÔºåÂØºËá¥Ë∫´‰ΩìÂßøÂäøÂíåÊ†πËøêÂä®‰πãÈó¥ÁöÑ‰∏ç‰∏ÄËá¥„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈôêÂà∂ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÁéØÂ¢ÉÊÑüÁü•ËøêÂä®ÂåπÈÖçÔºåËøôÊòØ‰∏ÄÁßçÁî®‰∫éÂÖ®Ë∫´ËßíËâ≤Âä®ÁîªÁöÑÊñ∞ÂûãÂÆûÊó∂Á≥ªÁªüÔºåÂèØ‰ª•Âä®ÊÄÅÈÄÇÂ∫îÈöúÁ¢çÁâ©ÂíåÂÖ∂‰ªñÊô∫ËÉΩ‰ΩìÔºåÂº∫Ë∞ÉÂßøÂäøÂíåËΩ®Ëøπ‰πãÈó¥ÁöÑÂèåÂêëÂÖ≥Á≥ª„ÄÇÂú®È¢ÑÂ§ÑÁêÜÊ≠•È™§‰∏≠ÔºåÊàë‰ª¨‰ªéËøêÂä®ÊçïÊçâÊï∞ÊçÆÂ∫ì‰∏≠ÊèêÂèñÂΩ¢Áä∂„ÄÅÂßøÂäøÂíåËΩ®ËøπÁâπÂæÅ„ÄÇÂú®ËøêË°åÊó∂ÔºåÊàë‰ª¨ÊâßË°åÈ´òÊïàÁöÑÊêúÁ¥¢ÔºåËØ•ÊêúÁ¥¢ÂåπÈÖçÁî®Êà∑ËæìÂÖ•ÂíåÂΩìÂâçÂßøÂäøÔºåÂêåÊó∂ÊÉ©ÁΩö‰∏éÂä®ÊÄÅÁéØÂ¢ÉÁöÑÁ¢∞Êíû„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÂÖÅËÆ∏ËßíËâ≤Ëá™ÁÑ∂Âú∞Ë∞ÉÊï¥ÂÖ∂ÂßøÂäøÂíåËΩ®Ëøπ‰ª•Âú®Êã•Êå§ÁöÑÂú∫ÊôØ‰∏≠ÂØºËà™„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâËßíËâ≤Âä®ÁîªÊäÄÊúØÂú®Â§ÑÁêÜ‰∏éÂä®ÊÄÅÁéØÂ¢ÉÁöÑ‰∫§‰∫íÊó∂Â≠òÂú®Â±ÄÈôêÊÄß„ÄÇ‰º†ÁªüÁöÑËøêÂä®ÂåπÈÖçÊñπÊ≥ïËôΩÁÑ∂Âú®ËßíËâ≤ËøêÂä®ÊéßÂà∂ÊñπÈù¢Ë°®Áé∞ËâØÂ•ΩÔºå‰ΩÜÈöæ‰ª•Ëá™ÁÑ∂Âú∞Â§ÑÁêÜËßíËâ≤‰∏éÁéØÂ¢ÉÔºàÂ¶ÇÈöúÁ¢çÁâ©„ÄÅÂÖ∂‰ªñËßíËâ≤ÔºâÁöÑ‰∫§‰∫í„ÄÇÊ≠§Â§ñÔºå‰∫∫Áæ§Âä®Áîª‰∏≠ÔºåË∫´‰ΩìÂä®ÁîªÂíåËΩ®ËøπËßÑÂàíÈÄöÂ∏∏ÊòØÂàÜÁ¶ªÁöÑÔºåÂØºËá¥Âä®Áîª‰∏çËá™ÁÑ∂„ÄÇÁé∞ÊúâÊñπÊ≥ïË¶Å‰πàÈúÄË¶ÅÂ§ßÈáèÊâãÂä®ËÆæÁΩÆÔºåË¶Å‰πàÁº∫‰πèËøêÂä®ÊçïÊçâÁöÑËá™ÁÑ∂ÊÄß„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂª∫Á´ã‰∏Ä‰∏™ÁéØÂ¢ÉÊÑüÁü•ÁöÑËøêÂä®ÂåπÈÖçÁ≥ªÁªüÔºåËØ•Á≥ªÁªüËÉΩÂ§üÂêåÊó∂ËÄÉËôëËßíËâ≤ÁöÑÂßøÂäø„ÄÅËΩ®Ëøπ‰ª•ÂèäÂë®Âõ¥ÁéØÂ¢ÉÁöÑ‰ø°ÊÅØ„ÄÇÈÄöËøáÂú®ËøêÂä®ÂåπÈÖçËøáÁ®ã‰∏≠ÂºïÂÖ•ÁéØÂ¢ÉÂõ†Á¥†Ôºå‰ΩøËßíËâ≤ËÉΩÂ§üËá™ÁÑ∂Âú∞Ë∞ÉÊï¥ÂßøÂäøÂíåËΩ®ËøπÔºå‰ªéËÄåÂÆûÁé∞‰∏éÁéØÂ¢ÉÁöÑËá™ÁÑ∂‰∫§‰∫í„ÄÇËøôÁßçÊñπÊ≥ïÂº∫Ë∞ÉÂßøÂäøÂíåËΩ®Ëøπ‰πãÈó¥ÁöÑÂèåÂêëÂÖ≥Á≥ªÔºå‰ΩøÂæóËßíËâ≤ÁöÑËøêÂä®Êõ¥Âä†ÁúüÂÆûÂíåÂèØ‰ø°„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•Á≥ªÁªüÂåÖÂê´È¢ÑÂ§ÑÁêÜÂíåËøêË°åÊó∂‰∏§‰∏™‰∏ªË¶ÅÈò∂ÊÆµ„ÄÇÂú®È¢ÑÂ§ÑÁêÜÈò∂ÊÆµÔºå‰ªéËøêÂä®ÊçïÊçâÊï∞ÊçÆÂ∫ì‰∏≠ÊèêÂèñÂΩ¢Áä∂„ÄÅÂßøÂäøÂíåËΩ®ËøπÁâπÂæÅÔºåÂπ∂ÊûÑÂª∫Á¥¢ÂºïÁªìÊûÑ„ÄÇÂú®ËøêË°åÊó∂Èò∂ÊÆµÔºåÁ≥ªÁªüÊé•Êî∂Áî®Êà∑ËæìÂÖ•ÂíåÂΩìÂâçËßíËâ≤Áä∂ÊÄÅÔºåÁÑ∂ÂêéÊâßË°åÈ´òÊïàÁöÑÊêúÁ¥¢ÁÆóÊ≥ïÔºå‰ªéËøêÂä®ÊçïÊçâÊï∞ÊçÆÂ∫ì‰∏≠ÊâæÂà∞ÊúÄ‰Ω≥ÂåπÈÖçÁöÑÂä®ÁîªÁâáÊÆµ„ÄÇÊêúÁ¥¢ËøáÁ®ã‰∏≠ÔºåÁ≥ªÁªü‰ºöËÄÉËôëÁî®Êà∑ËæìÂÖ•„ÄÅÂΩìÂâçÂßøÂäø‰ª•ÂèäÁéØÂ¢É‰ø°ÊÅØÔºåÂπ∂ÂØπ‰∏éÁéØÂ¢ÉÁöÑÁ¢∞ÊíûËøõË°åÊÉ©ÁΩö„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ÊñπÊ≥ïÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éÂ∞ÜÁéØÂ¢É‰ø°ÊÅØËûçÂÖ•Âà∞ËøêÂä®ÂåπÈÖçËøáÁ®ã‰∏≠„ÄÇÈÄöËøáÊòæÂºèÂú∞ËÄÉËôëÁéØÂ¢ÉÂõ†Á¥†ÔºåÁ≥ªÁªüËÉΩÂ§üÁîüÊàêÊõ¥Âä†Ëá™ÁÑ∂ÂíåÁúüÂÆûÁöÑ‰∫§‰∫íÂä®Áîª„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïÂº∫Ë∞ÉÂßøÂäøÂíåËΩ®Ëøπ‰πãÈó¥ÁöÑÂèåÂêëÂÖ≥Á≥ªÔºå‰ΩøÂæóËßíËâ≤ÁöÑËøêÂä®Êõ¥Âä†ÂçèË∞ÉÂíå‰∏ÄËá¥„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®È¢ÑÂ§ÑÁêÜÈò∂ÊÆµÔºåÈúÄË¶ÅÈÄâÊã©ÂêàÈÄÇÁöÑÂΩ¢Áä∂„ÄÅÂßøÂäøÂíåËΩ®ËøπÁâπÂæÅ„ÄÇÂú®ËøêË°åÊó∂Èò∂ÊÆµÔºåÈúÄË¶ÅËÆæËÆ°È´òÊïàÁöÑÊêúÁ¥¢ÁÆóÊ≥ïÔºåÂπ∂ÂÆö‰πâÂêàÈÄÇÁöÑÁ¢∞ÊíûÊÉ©ÁΩöÂáΩÊï∞„ÄÇÂÖ∑‰ΩìÁöÑÂèÇÊï∞ËÆæÁΩÆÂíåÂáΩÊï∞ÂΩ¢ÂºèÈúÄË¶ÅÊ†πÊçÆÂÖ∑‰ΩìÁöÑÂ∫îÁî®Âú∫ÊôØËøõË°åË∞ÉÊï¥„ÄÇ‰æãÂ¶ÇÔºåÁ¢∞ÊíûÊÉ©ÁΩöÂáΩÊï∞ÂèØ‰ª•Ê†πÊçÆÁ¢∞ÊíûÁöÑ‰∏•ÈáçÁ®ãÂ∫¶ËøõË°åË∞ÉÊï¥Ôºå‰ª•ÊéßÂà∂ËßíËâ≤ÈÅøËÆ©ÈöúÁ¢çÁâ©ÁöÑÁ®ãÂ∫¶„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ËÆ∫ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÁéØÂ¢ÉÊÑüÁü•ÁöÑËøêÂä®ÂåπÈÖçÁ≥ªÁªüÔºåËÉΩÂ§ü‰ΩøËßíËâ≤Ëá™ÁÑ∂Âú∞‰∏éÂä®ÊÄÅÁéØÂ¢ÉËøõË°å‰∫§‰∫í„ÄÇÈÄöËøáÂú®ËøêÂä®ÂåπÈÖçËøáÁ®ã‰∏≠ËÄÉËôëÁéØÂ¢ÉÂõ†Á¥†ÔºåÁ≥ªÁªüËÉΩÂ§üÁîüÊàêÊõ¥Âä†Ëá™ÁÑ∂ÂíåÁúüÂÆûÁöÑ‰∫§‰∫íÂä®Áîª„ÄÇËôΩÁÑ∂ËÆ∫Êñá‰∏≠Ê≤°ÊúâÁªôÂá∫ÂÖ∑‰ΩìÁöÑÊÄßËÉΩÊï∞ÊçÆÔºå‰ΩÜÂÖ∂Ê†∏ÂøÉÊÄùÊÉ≥ÂíåÊñπÊ≥ïÂÖ∑ÊúâÈáçË¶ÅÁöÑÁêÜËÆ∫ÂíåÂÆûË∑µÊÑè‰πâ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊ∏∏Êàè„ÄÅËôöÊãüÁé∞ÂÆû„ÄÅÊú∫Âô®‰∫∫Á≠âÈ¢ÜÂüü„ÄÇÂú®Ê∏∏Êàè‰∏≠ÔºåÂèØ‰ª•‰ΩøÊ∏∏ÊàèËßíËâ≤Êõ¥Âä†Êô∫ËÉΩÂíåÈÄºÁúüÂú∞‰∏éÁéØÂ¢É‰∫íÂä®„ÄÇÂú®ËôöÊãüÁé∞ÂÆû‰∏≠ÔºåÂèØ‰ª•Â¢ûÂº∫Áî®Êà∑ÁöÑÊ≤âÊµ∏ÊÑüÂíå‰∫§‰∫í‰ΩìÈ™å„ÄÇÂú®Êú∫Âô®‰∫∫È¢ÜÂüüÔºåÂèØ‰ª•‰ΩøÊú∫Âô®‰∫∫Êõ¥Âä†ÁÅµÊ¥ªÂíåÂÆâÂÖ®Âú∞Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ËøêÂä®„ÄÇËØ•ÊäÄÊúØÊúâÊúõÊé®Âä®‰∫∫Êú∫‰∫§‰∫íÂíåÊô∫ËÉΩ‰ΩìÂä®ÁîªÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Interactive applications demand believable characters that respond naturally to dynamic environments. Traditional character animation techniques often struggle to handle arbitrary situations, leading to a growing trend of dynamically selecting motion-captured animations based on predefined features. While Motion Matching has proven effective for locomotion by aligning to target trajectories, animating environment interactions and crowd behaviors remains challenging due to the need to consider surrounding elements. Existing approaches often involve manual setup or lack the naturalism of motion capture. Furthermore, in crowd animation, body animation is frequently treated as a separate process from trajectory planning, leading to inconsistencies between body pose and root motion. To address these limitations, we present Environment-aware Motion Matching, a novel real-time system for full-body character animation that dynamically adapts to obstacles and other agents, emphasizing the bidirectional relationship between pose and trajectory. In a preprocessing step, we extract shape, pose, and trajectory features from a motion capture database. At runtime, we perform an efficient search that matches user input and current pose while penalizing collisions with a dynamic environment. Our method allows characters to naturally adjust their pose and trajectory to navigate crowded scenes.

