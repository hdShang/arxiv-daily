---
layout: default
title: Multi-Person Interaction Generation from Two-Person Motion Priors
---

# Multi-Person Interaction Generation from Two-Person Motion Priors

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.17860" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.17860v2</a>
  <a href="https://arxiv.org/pdf/2505.17860.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.17860v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.17860v2', 'Multi-Person Interaction Generation from Two-Person Motion Priors')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wenning Xu, Shiyu Fan, Paul Henderson, Edmond S. L. Ho

**åˆ†ç±»**: cs.GR, cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-23 (æ›´æ–°: 2025-07-26)

**å¤‡æ³¨**: SIGGRAPH 2025 Conference Papers, project page at http://wenningxu.github.io/multicharacter/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå›¾é©±åŠ¨äº¤äº’é‡‡æ ·ä»¥è§£å†³å¤šäººäººä½“äº¤äº’ç”Ÿæˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)** **æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction)**

**å…³é”®è¯**: `å¤šäººäººä½“äº¤äº’` `è¿åŠ¨ç”Ÿæˆ` `å›¾é©±åŠ¨æ–¹æ³•` `æ‰©æ•£æ¨¡å‹` `è¿åŠ¨æ•æ‰` `æœºå™¨äººæŠ€æœ¯` `è™šæ‹Ÿç°å®`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤šäººäººä½“äº¤äº’ç”Ÿæˆæ–¹é¢æ¢ç´¢ä¸è¶³ï¼Œå¯¼è‡´ç”Ÿæˆçš„åŠ¨ä½œç¼ºä¹å¤šæ ·æ€§å’ŒçœŸå®æ„Ÿã€‚
2. æœ¬æ–‡æå‡ºçš„å›¾é©±åŠ¨äº¤äº’é‡‡æ ·æ–¹æ³•ï¼Œé€šè¿‡å°†å¤æ‚äº¤äº’åˆ†è§£ä¸ºåŒäººäº¤äº’å›¾ï¼Œåˆ›æ–°æ€§åœ°å®ç°äº†å¤šäººäººä½“äº¤äº’çš„ç”Ÿæˆã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ç”Ÿæˆå¤šç§äº¤äº’æ—¶ï¼Œæ˜¾è‘—å‡å°‘äº†èº«ä½“éƒ¨ä½äº¤å‰ç­‰ä¼ªå½±ï¼Œè¶…è¶Šäº†ç°æœ‰æŠ€æœ¯ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç”Ÿæˆé€¼çœŸçš„äººç±»åŠ¨ä½œå¹¶è¿›è¡Œé«˜å±‚æ¬¡æ§åˆ¶æ˜¯ç¤¾ä¼šç†è§£ã€æœºå™¨äººæŠ€æœ¯å’ŒåŠ¨ç”»ä¸­çš„å…³é”®ä»»åŠ¡ã€‚å°½ç®¡é«˜è´¨é‡çš„è¿åŠ¨æ•æ‰æ•°æ®æ—¥ç›Šå¯ç”¨ï¼Œå»ºæ¨¡å¤šäººäººä½“äº¤äº’ä»ç„¶æ˜¯ä¸€ä¸ªè¾ƒå°‘æ¢ç´¢çš„é¢†åŸŸã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§å›¾é©±åŠ¨çš„äº¤äº’é‡‡æ ·æ–¹æ³•ï¼Œé€šè¿‡åˆ©ç”¨ç°æœ‰çš„åŒäººè¿åŠ¨æ‰©æ•£æ¨¡å‹ä½œä¸ºè¿åŠ¨å…ˆéªŒï¼Œç”ŸæˆçœŸå®ä¸”å¤šæ ·çš„å¤šäººäººä½“äº¤äº’ã€‚æˆ‘ä»¬å°†å¤æ‚çš„å¤šäººäººä½“äº¤äº’åœ¨ç©ºé—´å’Œæ—¶é—´ä¸Šåˆ†ç¦»ä¸ºåŒäººäº¤äº’çš„å›¾ç»“æ„ï¼Œä»è€Œå°†ç”Ÿæˆä»»åŠ¡åˆ†è§£ä¸ºåŸºäºå½¼æ­¤åŠ¨ä½œçš„å•äººè¿åŠ¨ç”Ÿæˆã€‚åŒæ—¶ï¼Œä¸ºå‡å°‘ç”Ÿæˆå¤šäººäººä½“äº¤äº’æ—¶çš„ä¼ªå½±ï¼Œæˆ‘ä»¬åœ¨æ‰©æ•£é‡‡æ ·æ–¹æ¡ˆä¸­å¼•å…¥äº†ä¸¤ä¸ªå›¾ä¾èµ–çš„å¼•å¯¼é¡¹ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ç”Ÿæˆå¤šç§åŒäººå’Œå¤šäººäººä½“äº¤äº’æ—¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå‡å°‘ä¼ªå½±ï¼Œä¸”ä¸äº§ç”Ÿé‡å¤çš„ä¸ªä½“åŠ¨ä½œã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šäººäººä½“äº¤äº’ç”Ÿæˆä¸­çš„çœŸå®æ„Ÿå’Œå¤šæ ·æ€§ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ä¸“æ³¨äºå•ä¸€çš„åŒäººäº¤äº’ï¼Œéš¾ä»¥æœ‰æ•ˆæ‰©å±•åˆ°å¤šäººäººä½“äº¤äº’ï¼Œå¯¼è‡´ç”Ÿæˆç»“æœçš„è´¨é‡å’Œå¤šæ ·æ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†å¤æ‚çš„å¤šäººäººä½“äº¤äº’åˆ†è§£ä¸ºåŒäººäº¤äº’çš„å›¾ç»“æ„ï¼Œç§°ä¸ºæˆå¯¹äº¤äº’å›¾ï¼Œä»è€Œå®ç°åŸºäºå½¼æ­¤åŠ¨ä½œçš„å•äººè¿åŠ¨ç”Ÿæˆã€‚è¿™ç§è®¾è®¡ä½¿å¾—ç”Ÿæˆè¿‡ç¨‹æ›´ä¸ºçµæ´»ä¸”æ˜“äºæ§åˆ¶ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯æˆå¯¹äº¤äº’å›¾çš„æ„å»ºï¼Œå…¶æ¬¡æ˜¯åŸºäºå›¾ç»“æ„çš„æ‰©æ•£é‡‡æ ·è¿‡ç¨‹ã€‚é€šè¿‡å°†å¤šäººäººä½“äº¤äº’è½¬åŒ–ä¸ºåŒäººäº¤äº’çš„ç»„åˆï¼Œèƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨ç°æœ‰çš„åŒäººè¿åŠ¨æ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥äº†å›¾é©±åŠ¨çš„äº¤äº’é‡‡æ ·æ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨ä¸è®­ç»ƒæ–°æ¨¡å‹çš„æƒ…å†µä¸‹ï¼Œåˆ©ç”¨å·²æœ‰çš„åŒäººè¿åŠ¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆå¤šäººäººä½“äº¤äº’ã€‚è¿™ä¸€æ–¹æ³•æ˜¾è‘—æé«˜äº†ç”Ÿæˆçš„å¤šæ ·æ€§å’Œè´¨é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œè®ºæ–‡è®¾è®¡äº†ä¸¤ä¸ªå›¾ä¾èµ–çš„å¼•å¯¼é¡¹ï¼Œä»¥å‡å°‘ç”Ÿæˆè¿‡ç¨‹ä¸­å¯èƒ½å‡ºç°çš„èº«ä½“éƒ¨ä½äº¤å‰ç­‰ä¼ªå½±ã€‚æ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿè€ƒè™‘äº†ç”ŸæˆåŠ¨ä½œçš„è¿è´¯æ€§å’ŒçœŸå®æ„Ÿï¼Œç¡®ä¿ç”Ÿæˆç»“æœçš„è‡ªç„¶æµç•…ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„æ–¹æ³•åœ¨ç”Ÿæˆå¤šç§åŒäººå’Œå¤šäººäººä½“äº¤äº’æ—¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå‡å°‘èº«ä½“éƒ¨ä½äº¤å‰ç­‰ä¼ªå½±ï¼Œç›¸è¾ƒäºç°æœ‰æ–¹æ³•ï¼Œç”Ÿæˆè´¨é‡æå‡æ˜¾è‘—ï¼Œå…·ä½“æ€§èƒ½æ•°æ®æœªæä¾›ï¼Œä½†å®éªŒè¡¨æ˜ä¸€è‡´æ€§ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾äº¤æœºå™¨äººã€è™šæ‹Ÿç°å®ã€åŠ¨ç”»åˆ¶ä½œç­‰ã€‚é€šè¿‡ç”Ÿæˆé«˜è´¨é‡çš„å¤šäººäººä½“äº¤äº’ï¼Œèƒ½å¤Ÿæå‡äººæœºäº¤äº’çš„è‡ªç„¶æ€§å’ŒçœŸå®æ„Ÿï¼Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„å‘å±•ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯å¯èƒ½åœ¨æ¸¸æˆè®¾è®¡ã€å½±è§†åˆ¶ä½œç­‰æ–¹é¢å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Generating realistic human motion with high-level controls is a crucial task for social understanding, robotics, and animation. With high-quality MOCAP data becoming more available recently, a wide range of data-driven approaches have been presented. However, modelling multi-person interactions still remains a less explored area. In this paper, we present Graph-driven Interaction Sampling, a method that can generate realistic and diverse multi-person interactions by leveraging existing two-person motion diffusion models as motion priors. Instead of training a new model specific to multi-person interaction synthesis, our key insight is to spatially and temporally separate complex multi-person interactions into a graph structure of two-person interactions, which we name the Pairwise Interaction Graph. We thus decompose the generation task into simultaneous single-person motion generation conditioned on one other's motion. In addition, to reduce artifacts such as interpenetrations of body parts in generated multi-person interactions, we introduce two graph-dependent guidance terms into the diffusion sampling scheme. Unlike previous work, our method can produce various high-quality multi-person interactions without having repetitive individual motions. Extensive experiments demonstrate that our approach consistently outperforms existing methods in reducing artifacts when generating a wide range of two-person and multi-person interactions.

