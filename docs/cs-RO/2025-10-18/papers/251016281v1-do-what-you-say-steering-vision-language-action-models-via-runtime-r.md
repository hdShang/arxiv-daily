---
layout: default
title: "Do What You Say: Steering Vision-Language-Action Models via Runtime Reasoning-Action Alignment Verification"
---

# Do What You Say: Steering Vision-Language-Action Models via Runtime Reasoning-Action Alignment Verification

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.16281" class="toolbar-btn" target="_blank">üìÑ arXiv: 2510.16281v1</a>
  <a href="https://arxiv.org/pdf/2510.16281.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.16281v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.16281v1', 'Do What You Say: Steering Vision-Language-Action Models via Runtime Reasoning-Action Alignment Verification')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Yilin Wu, Anqi Li, Tucker Hermans, Fabio Ramos, Andrea Bajcsy, Claudia P'erez-D'Arpino

**ÂàÜÁ±ª**: cs.RO, cs.AI, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-18

**üîó ‰ª£Á†Å/È°πÁõÆ**: [PROJECT_PAGE](https://yilin-wu98.github.io/steering-reasoning-vla/)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éËøêË°åÊó∂Êé®ÁêÜ-Ë°åÂä®ÂØπÈΩêÈ™åËØÅÁöÑÁ≠ñÁï•ÂºïÂØºÊñπÊ≥ïÔºåÊèêÂçáVLAÊ®°ÂûãÂú®Êú∫Âô®‰∫∫‰ªªÂä°‰∏≠ÁöÑÊ≥õÂåñÊÄß„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâËØ≠Ë®ÄÂä®‰ΩúÊ®°Âûã` `Êú∫Âô®‰∫∫Êåá‰ª§Ë∑üÈöè` `Êé®ÁêÜË°åÂä®ÂØπÈΩê` `ËøêË°åÊó∂Á≠ñÁï•ÂºïÂØº` `ÂàÜÂ∏ÉÂ§ñÊ≥õÂåñ` `Ë°å‰∏∫ÁªÑÂêà` `‰ªøÁúüÁéØÂ¢É` `ËßÜËßâËØ≠Ë®ÄÊ®°Âûã`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâVLAÊ®°ÂûãÂú®ÂàÜÂ∏ÉÂ§ñÂú∫ÊôØ‰∏≠ÔºåÂç≥‰ΩøÊñáÊú¨ËÆ°ÂàíÊ≠£Á°ÆÔºåÊâßË°åÁöÑÂä®‰Ωú‰πüÂèØËÉΩÂÅèÁ¶ªËÆ°ÂàíÔºåÁº∫‰πèÂÖ∑Ë∫´CoTÁöÑÂø†ÂÆûÊÄß„ÄÇ
2. ÊèêÂá∫‰∏ÄÁßçËøêË°åÊó∂Á≠ñÁï•ÂºïÂØºÊñπÊ≥ïÔºåÈÄöËøáÈ™åËØÅÊé®ÁêÜ‰∏éË°åÂä®ÁöÑÂØπÈΩêÁ®ãÂ∫¶Ôºå‰ªéÂ§ö‰∏™ÂÄôÈÄâÂä®‰ΩúÂ∫èÂàó‰∏≠ÈÄâÊã©ÊúÄ‰Ω≥Â∫èÂàó„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåËØ•ÊñπÊ≥ïÊòæËëóÊèêÂçá‰∫ÜVLAÊ®°ÂûãÂú®OODÂú∫ÊôØ‰∏ãÁöÑÈ≤ÅÊ£íÊÄßÔºåÂπ∂Âú®Ë°å‰∏∫ÁªÑÂêà‰ªªÂä°‰∏äÂèñÂæó‰∫ÜÈ´òËææ15%ÁöÑÊÄßËÉΩÊèêÂçá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÈíàÂØπÊé®ÁêÜËßÜËßâ-ËØ≠Ë®Ä-Âä®‰Ωú(VLA)Ê®°ÂûãÂú®Êú∫Âô®‰∫∫Êåá‰ª§Ë∑üÈöè‰ªªÂä°‰∏≠ÔºåÂç≥‰ΩøÁîüÊàê‰∫ÜÊ≠£Á°ÆÁöÑÊñáÊú¨ËÆ°ÂàíÔºåÂÆûÈôÖÊâßË°åÁöÑÂä®‰Ωú‰πüÂèØËÉΩÊó†Ê≥ïËææÂà∞È¢ÑÊúüÁªìÊûúÁöÑÈóÆÈ¢òÔºåÊèêÂá∫‰∫Ü‰∏Ä‰∏™Êó†ÈúÄÈáçÊñ∞ËÆ≠ÁªÉÁöÑËøêË°åÊó∂Á≠ñÁï•ÂºïÂØºÊñπÊ≥ï„ÄÇËØ•ÊñπÊ≥ïÈÄöËøáÂØπVLAÊ®°ÂûãÁîüÊàêÁöÑÂ§ö‰∏™ÂÄôÈÄâÂä®‰ΩúÂ∫èÂàóËøõË°åÈááÊ†∑ÔºåÂà©Áî®‰ªøÁúüÈ¢ÑÊµãÂÖ∂ÁªìÊûúÔºåÂπ∂‰ΩøÁî®È¢ÑËÆ≠ÁªÉÁöÑËßÜËßâ-ËØ≠Ë®ÄÊ®°Âûã(VLM)ÈÄâÊã©‰∏éVLAËá™Ë∫´ÊñáÊú¨ËÆ°ÂàíÊúÄÂØπÈΩêÁöÑÂ∫èÂàó„ÄÇÈÄöËøá‰ªÖÊâßË°å‰∏éÊñáÊú¨Êé®ÁêÜÂØπÈΩêÁöÑÂä®‰ΩúÂ∫èÂàóÔºåÂ∞ÜVLAÊ®°ÂûãÂõ∫ÊúâÁöÑÂä®‰ΩúÂ§öÊ†∑ÊÄß‰ªéËØØÂ∑ÆÊù•Ê∫êËΩ¨Âåñ‰∏∫‰ºòÂäøÔºå‰ªéËÄåÊèêÈ´òÊ®°ÂûãÂØπËØ≠‰πâÂíåËßÜËßâÂàÜÂ∏ÉÂ§ñ(OOD)Êâ∞Âä®ÁöÑÈ≤ÅÊ£íÊÄßÔºåÂπ∂ÂÆûÁé∞Êñ∞ÁöÑË°å‰∏∫ÁªÑÂêà„ÄÇÊ≠§Â§ñÔºåÊú¨ÊñáËøòË¥°ÁåÆ‰∫Ü‰∏Ä‰∏™Êé®ÁêÜÊ†áÊ≥®ÁöÑLIBERO-100Êâ©Â±ïÔºå‰ª•Âèä‰∏∫OODËØÑ‰º∞ÂÆöÂà∂ÁöÑÁéØÂ¢ÉÂèò‰Ωì„ÄÇÂÆûÈ™åË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®Ë°å‰∏∫ÁªÑÂêà‰ªªÂä°‰∏äÊØîÁé∞ÊúâÊñπÊ≥ïÊèêÈ´ò‰∫ÜÈ´òËææ15%ÁöÑÊÄßËÉΩÔºåÂπ∂‰∏îÂèØ‰ª•ÈöèÁùÄËÆ°ÁÆóÂíåÊï∞ÊçÆÂ§öÊ†∑ÊÄßÁöÑÂ¢ûÂä†ËÄåÊâ©Â±ï„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Êé®ÁêÜËßÜËßâ-ËØ≠Ë®Ä-Âä®‰Ωú(VLA)Ê®°ÂûãÂú®Êú∫Âô®‰∫∫Êåá‰ª§Ë∑üÈöè‰ªªÂä°‰∏≠ÔºåÁîüÊàêÁöÑÂä®‰ΩúÂ∫èÂàó‰∏éÊ®°ÂûãËá™Ë∫´ÁöÑÊñáÊú¨Êé®ÁêÜËÆ°Âàí‰∏ç‰∏ÄËá¥ÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÔºåÂç≥‰ΩøÁîüÊàê‰∫ÜÊ≠£Á°ÆÁöÑÊñáÊú¨ËÆ°ÂàíÔºåÂÆûÈôÖÊâßË°åÁöÑÂä®‰Ωú‰πüÂèØËÉΩÊó†Ê≥ïËææÂà∞È¢ÑÊúüÁªìÊûúÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂàÜÂ∏ÉÂ§ñ(OOD)Âú∫ÊôØ‰∏≠ÔºåÂØºËá¥‰ªªÂä°Â§±Ë¥•„ÄÇËøôÁßç‰∏ç‰∏ÄËá¥ÊÄßÊ∫ê‰∫éÊ®°ÂûãÁº∫‰πè‚ÄúÂÖ∑Ë∫´CoTÂø†ÂÆûÊÄß‚Äù„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®VLAÊ®°ÂûãËá™Ë∫´ÁîüÊàêÁöÑÊñáÊú¨ËÆ°Âàí‰Ωú‰∏∫ÊåáÂØºÔºåÈÄöËøáÂØπÂ§ö‰∏™ÂÄôÈÄâÂä®‰ΩúÂ∫èÂàóËøõË°åËØÑ‰º∞ÔºåÈÄâÊã©‰∏éÊñáÊú¨ËÆ°ÂàíÊúÄÂØπÈΩêÁöÑÂä®‰ΩúÂ∫èÂàóÊâßË°å„ÄÇËøôÁßçÊñπÊ≥ïÂ∞ÜVLAÊ®°ÂûãÂõ∫ÊúâÁöÑÂä®‰ΩúÂ§öÊ†∑ÊÄß‰ªéËØØÂ∑ÆÊù•Ê∫êËΩ¨Âåñ‰∏∫‰ºòÂäøÔºåÊèêÂçá‰∫ÜÊ®°ÂûãÂØπOODÊâ∞Âä®ÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) **Âä®‰ΩúÂ∫èÂàóÈááÊ†∑**Ôºö‰ªéVLAÊ®°Âûã‰∏≠ÈááÊ†∑Â§ö‰∏™ÂÄôÈÄâÂä®‰ΩúÂ∫èÂàó„ÄÇ2) **ÁªìÊûúÈ¢ÑÊµã**ÔºöÂà©Áî®‰ªøÁúüÁéØÂ¢ÉÈ¢ÑÊµãÊØè‰∏™Âä®‰ΩúÂ∫èÂàóÊâßË°åÂêéÁöÑÁªìÊûú„ÄÇ3) **ÂØπÈΩêËØÑ‰º∞**Ôºö‰ΩøÁî®È¢ÑËÆ≠ÁªÉÁöÑËßÜËßâ-ËØ≠Ë®ÄÊ®°Âûã(VLM)ËØÑ‰º∞ÊØè‰∏™È¢ÑÊµãÁªìÊûú‰∏éVLAÊ®°ÂûãËá™Ë∫´ÊñáÊú¨ËÆ°ÂàíÁöÑÂØπÈΩêÁ®ãÂ∫¶„ÄÇ4) **Â∫èÂàóÈÄâÊã©**ÔºöÈÄâÊã©‰∏éÊñáÊú¨ËÆ°ÂàíÂØπÈΩêÁ®ãÂ∫¶ÊúÄÈ´òÁöÑÂä®‰ΩúÂ∫èÂàóÊâßË°å„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÊèêÂá∫‰∫Ü‰∏ÄÁßçÊó†ÈúÄÈáçÊñ∞ËÆ≠ÁªÉÁöÑËøêË°åÊó∂Á≠ñÁï•ÂºïÂØºÊñπÊ≥ïÔºåÈÄöËøáÊé®ÁêÜ-Ë°åÂä®ÂØπÈΩêÈ™åËØÅÊù•ÊèêÂçáVLAÊ®°ÂûãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ï‰∏çÈúÄË¶ÅÈ¢ùÂ§ñÁöÑËÆ≠ÁªÉÊï∞ÊçÆÊàñÊ®°ÂûãÂèÇÊï∞ÔºåÂèØ‰ª•Áõ¥Êé•Â∫îÁî®‰∫éÁé∞ÊúâÁöÑVLAÊ®°ÂûãÔºåÂπ∂‰∏îÂèØ‰ª•Âà©Áî®VLAÊ®°ÂûãËá™Ë∫´ÁöÑÂä®‰ΩúÂ§öÊ†∑ÊÄßÊù•ÊèêÂçáÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ‰ΩøÁî®È¢ÑËÆ≠ÁªÉÁöÑVLMËøõË°åÂØπÈΩêËØÑ‰º∞ÔºåÂà©Áî®VLMÂº∫Â§ßÁöÑËßÜËßâ-ËØ≠Ë®ÄÁêÜËß£ËÉΩÂäõ„ÄÇ2) ÈÄöËøá‰ªøÁúüÁéØÂ¢ÉËøõË°åÁªìÊûúÈ¢ÑÊµãÔºåÈÅøÂÖç‰∫ÜÂú®ÁúüÂÆûÁéØÂ¢É‰∏≠ËøõË°åÂ§öÊ¨°ÂÆûÈ™åÁöÑÊàêÊú¨„ÄÇ3) ÈááÁî®ÈááÊ†∑ÁöÑÊñπÂºèÁîüÊàêÂ§ö‰∏™ÂÄôÈÄâÂä®‰ΩúÂ∫èÂàóÔºåÂ¢ûÂä†‰∫ÜÈÄâÊã©ÊúÄ‰Ω≥Â∫èÂàóÁöÑÂèØËÉΩÊÄß„ÄÇÂÖ∑‰ΩìÁöÑÂèÇÊï∞ËÆæÁΩÆ„ÄÅÊçüÂ§±ÂáΩÊï∞ÂíåÁΩëÁªúÁªìÊûÑÂèñÂÜ≥‰∫éÊâÄ‰ΩøÁî®ÁöÑVLAÊ®°ÂûãÂíåVLM„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®Ë°å‰∏∫ÁªÑÂêà‰ªªÂä°‰∏äÊØîÁé∞ÊúâÊñπÊ≥ïÊèêÈ´ò‰∫ÜÈ´òËææ15%ÁöÑÊÄßËÉΩ„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïËøòÊòæËëóÊèêÂçá‰∫ÜVLAÊ®°ÂûãÂú®ËØ≠‰πâÂíåËßÜËßâOODÊâ∞Âä®‰∏ãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇÂÆûÈ™åËøòËØÅÊòéÔºåËØ•ÊñπÊ≥ïÁöÑÊÄßËÉΩÂèØ‰ª•ÈöèÁùÄËÆ°ÁÆóÂíåÊï∞ÊçÆÂ§öÊ†∑ÊÄßÁöÑÂ¢ûÂä†ËÄåÊâ©Â±ïÔºåÂÖ∑ÊúâËâØÂ•ΩÁöÑÂèØÊâ©Â±ïÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂπøÊ≥õÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫Êåá‰ª§Ë∑üÈöè„ÄÅËá™Âä®Âåñ‰ªªÂä°ÊâßË°åÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÊèêÈ´òÊú∫Âô®‰∫∫ÂØπÊåá‰ª§ÁöÑÁêÜËß£ÂíåÊâßË°åÁ≤æÂ∫¶ÔºåÂèØ‰ª•ÂÆûÁé∞Êõ¥Êô∫ËÉΩ„ÄÅÊõ¥ÂèØÈù†ÁöÑÊú∫Âô®‰∫∫ÊúçÂä°Ôºå‰æãÂ¶ÇÂÆ∂Â∫≠ÊúçÂä°Êú∫Âô®‰∫∫„ÄÅÂ∑•‰∏öËá™Âä®ÂåñÊú∫Âô®‰∫∫„ÄÅÂåªÁñóËæÖÂä©Êú∫Âô®‰∫∫Á≠â„ÄÇËØ•ÊñπÊ≥ïËøòÂèØÁî®‰∫éÊèêÂçáÊú∫Âô®‰∫∫Âú®Êú™Áü•ÁéØÂ¢É‰∏≠ÁöÑÈÄÇÂ∫îËÉΩÂäõÔºå‰ΩøÂÖ∂ËÉΩÂ§üÊõ¥Â•ΩÂú∞ÂÆåÊàêÂ§çÊùÇ‰ªªÂä°„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Reasoning Vision Language Action (VLA) models improve robotic instruction-following by generating step-by-step textual plans before low-level actions, an approach inspired by Chain-of-Thought (CoT) reasoning in language models. Yet even with a correct textual plan, the generated actions can still miss the intended outcomes in the plan, especially in out-of-distribution (OOD) scenarios. We formalize this phenomenon as a lack of embodied CoT faithfulness, and introduce a training-free, runtime policy steering method for reasoning-action alignment. Given a reasoning VLA's intermediate textual plan, our framework samples multiple candidate action sequences from the same model, predicts their outcomes via simulation, and uses a pre-trained Vision-Language Model (VLM) to select the sequence whose outcome best aligns with the VLA's own textual plan. Only executing action sequences that align with the textual reasoning turns our base VLA's natural action diversity from a source of error into a strength, boosting robustness to semantic and visual OOD perturbations and enabling novel behavior composition without costly re-training. We also contribute a reasoning-annotated extension of LIBERO-100, environment variations tailored for OOD evaluation, and demonstrate up to 15% performance gain over prior work on behavior composition tasks and scales with compute and data diversity. Project Website at: https://yilin-wu98.github.io/steering-reasoning-vla/

