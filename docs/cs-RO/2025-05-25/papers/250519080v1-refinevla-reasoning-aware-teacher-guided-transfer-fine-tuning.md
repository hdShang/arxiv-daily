---
layout: default
title: ReFineVLA: Reasoning-Aware Teacher-Guided Transfer Fine-Tuning
---

# ReFineVLA: Reasoning-Aware Teacher-Guided Transfer Fine-Tuning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.19080" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.19080v1</a>
  <a href="https://arxiv.org/pdf/2505.19080.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.19080v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.19080v1', 'ReFineVLA: Reasoning-Aware Teacher-Guided Transfer Fine-Tuning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Tuan Van Vo, Tan Quang Nguyen, Khang Minh Nguyen, Duy Ho Minh Nguyen, Minh Nhat Vu

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-05-25

**å¤‡æ³¨**: 10 pages

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºReFineVLAä»¥è§£å†³VLAæ¨¡å‹æ¨ç†ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€-åŠ¨ä½œ` `æ¨ç†èƒ½åŠ›` `æ•™å¸ˆå¼•å¯¼` `å¤šæ¨¡æ€å­¦ä¹ ` `æœºå™¨äººæ“ä½œ` `æ•°æ®å¢å¼º` `æ¨¡å‹å¾®è°ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰VLAæ¨¡å‹åœ¨å¤„ç†å¤æ‚é•¿æ—¶é—´æ“ä½œä»»åŠ¡æ—¶ï¼Œç¼ºä¹æ˜¾å¼æ¨ç†èƒ½åŠ›ï¼Œå¯¼è‡´å¯è§£é‡Šæ€§å’Œæ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºReFineVLAæ¡†æ¶ï¼Œé€šè¿‡æ•™å¸ˆå¼•å¯¼çš„æ¨ç†å¢å¼ºæ•°æ®é›†ï¼Œå¾®è°ƒVLAæ¨¡å‹ä»¥æå‡å…¶æ¨ç†èƒ½åŠ›ã€‚
3. åœ¨å¤šä¸ªæ“ä½œä»»åŠ¡ä¸­ï¼ŒReFineVLAæ¨¡å‹çš„è¡¨ç°ä¼˜äºç°æœ‰åŸºçº¿ï¼ŒæˆåŠŸç‡å¹³å‡æé«˜5.0%ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹å› å…¶å°†å¤šæ¨¡æ€è§‚å¯Ÿä¸è¯­è¨€æŒ‡ä»¤è½¬åŒ–ä¸ºæœºå™¨äººåŠ¨ä½œçš„èƒ½åŠ›è€Œå—åˆ°ç ”ç©¶ç•Œçš„å¹¿æ³›å…³æ³¨ã€‚ç„¶è€Œï¼Œç°æœ‰çš„VLAæ¨¡å‹å¾€å¾€å¿½è§†äº†æ˜¾å¼æ¨ç†ï¼Œä»…å­¦ä¹ åŠŸèƒ½æ€§è¾“å…¥-åŠ¨ä½œæ˜ å°„ï¼Œç¼ºä¹å¯¹å¤æ‚é•¿æ—¶é—´æ“ä½œä»»åŠ¡çš„å¯è§£é‡Šæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ReFineVLAï¼Œä¸€ä¸ªå¤šæ¨¡æ€æ¨ç†æ„ŸçŸ¥æ¡†æ¶ï¼Œé€šè¿‡æ•™å¸ˆå¼•å¯¼çš„æ¨ç†æ¥å¾®è°ƒVLAæ¨¡å‹ã€‚æˆ‘ä»¬é¦–å…ˆé€šè¿‡ä¸“å®¶æ•™å¸ˆæ¨¡å‹ç”Ÿæˆæ¨ç†ç†ç”±ï¼Œå¢å¼ºæœºå™¨äººæ•°æ®é›†ï¼ŒæŒ‡å¯¼VLAæ¨¡å‹å­¦ä¹ å…¶åŠ¨ä½œçš„æ¨ç†è¿‡ç¨‹ã€‚ç„¶åï¼Œåˆ©ç”¨ReFineVLAå¯¹é¢„è®­ç»ƒçš„VLAè¿›è¡Œå¾®è°ƒï¼Œä¿æŒå…¶å›ºæœ‰çš„æ³›åŒ–èƒ½åŠ›å¹¶æå‡æ¨ç†èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒReFineVLAåœ¨æ“ä½œä»»åŠ¡ä¸­è¶…è¶Šäº†æœ€å…ˆè¿›çš„åŸºçº¿ï¼ŒæˆåŠŸç‡å¹³å‡æé«˜5.0%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰VLAæ¨¡å‹åœ¨å¤æ‚é•¿æ—¶é—´æ“ä½œä»»åŠ¡ä¸­ç¼ºä¹æ˜¾å¼æ¨ç†èƒ½åŠ›çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä»…å…³æ³¨è¾“å…¥ä¸åŠ¨ä½œä¹‹é—´çš„åŠŸèƒ½æ€§æ˜ å°„ï¼Œå¿½è§†äº†æ¨ç†è¿‡ç¨‹çš„å¯è§£é‡Šæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šReFineVLAæ¡†æ¶é€šè¿‡æ•™å¸ˆå¼•å¯¼çš„æ¨ç†ç”Ÿæˆå¢å¼ºæ•°æ®é›†ï¼Œå¸®åŠ©VLAæ¨¡å‹å­¦ä¹ æ¨ç†è¿‡ç¨‹ï¼Œä»è€Œæå‡å…¶åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚è¯¥è®¾è®¡æ—¨åœ¨é€šè¿‡å¼•å…¥æ¨ç†æ­¥éª¤æ¥å¢å¼ºæ¨¡å‹çš„ç†è§£èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šReFineVLAçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®å¢å¼ºæ¨¡å—ã€æ•™å¸ˆæ¨¡å‹ç”Ÿæˆæ¨ç†ç†ç”±ã€VLAæ¨¡å‹å¾®è°ƒé˜¶æ®µä»¥åŠæ³¨æ„åŠ›å¯è§†åŒ–åˆ†æã€‚æ•°æ®å¢å¼ºæ¨¡å—è´Ÿè´£ç”Ÿæˆå¸¦æœ‰æ¨ç†ç†ç”±çš„æ•°æ®é›†ï¼Œå¾®è°ƒé˜¶æ®µåˆ™ä½¿ç”¨è¿™äº›æ•°æ®æ¥æå‡VLAæ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šReFineVLAçš„ä¸»è¦åˆ›æ–°åœ¨äºå¼•å…¥æ•™å¸ˆå¼•å¯¼çš„æ¨ç†è¿‡ç¨‹ï¼Œä½¿å¾—VLAæ¨¡å‹ä¸ä»…å­¦ä¹ è¾“å…¥ä¸åŠ¨ä½œçš„æ˜ å°„ï¼Œè¿˜èƒ½ç†è§£å…¶èƒŒåçš„æ¨ç†é€»è¾‘ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„VLAæ¨¡å‹åœ¨å­¦ä¹ æ–¹å¼ä¸Šæœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡æ¨ç†èƒ½åŠ›ä¸æ³›åŒ–èƒ½åŠ›ï¼ŒåŒæ—¶åœ¨æ³¨æ„åŠ›æœºåˆ¶ä¸­å¼•å…¥äº†å¯è§†åŒ–åˆ†æï¼Œä»¥ä¾¿æ›´å¥½åœ°ç†è§£æ¨¡å‹çš„å†³ç­–è¿‡ç¨‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å¤šä¸ªæ“ä½œä»»åŠ¡çš„è¯„ä¼°ä¸­ï¼ŒReFineVLAæ¨¡å‹è¡¨ç°ä¼˜å¼‚ï¼Œç‰¹åˆ«æ˜¯åœ¨SimplerEnv WidowX Robotä»»åŠ¡ä¸­æˆåŠŸç‡å¹³å‡æé«˜5.0%ï¼Œåœ¨å˜ä½“èšåˆè®¾ç½®ä¸­æé«˜8.6%ï¼Œåœ¨è§†è§‰åŒ¹é…è®¾ç½®ä¸­æé«˜1.7%ã€‚è¿™äº›ç»“æœè¡¨æ˜ReFineVLAåœ¨æå‡VLAæ¨¡å‹æ€§èƒ½æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ReFineVLAçš„ç ”ç©¶æˆæœåœ¨æœºå™¨äººæ“ä½œã€è‡ªåŠ¨åŒ–æ§åˆ¶å’Œäººæœºäº¤äº’ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æå‡VLAæ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿä½¿æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­æ›´æœ‰æ•ˆåœ°æ‰§è¡Œä»»åŠ¡ï¼Œå¢å¼ºå…¶è‡ªä¸»å†³ç­–èƒ½åŠ›ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ™ºèƒ½æœºå™¨äººæŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision-Language-Action (VLA) models have gained much attention from the research community thanks to their strength in translating multimodal observations with linguistic instructions into robotic actions. Despite their recent advancements, VLAs often overlook the explicit reasoning and only learn the functional input-action mappings, omitting these crucial logical steps for interpretability and generalization for complex, long-horizon manipulation tasks. In this work, we propose \textit{ReFineVLA}, a multimodal reasoning-aware framework that fine-tunes VLAs with teacher-guided reasons. We first augment robotic datasets with reasoning rationales generated by an expert teacher model, guiding VLA models to learn to reason about their actions. Then, we use \textit{ReFineVLA} to fine-tune pre-trained VLAs with the reasoning-enriched datasets, while maintaining their inherent generalization abilities and boosting reasoning capabilities. In addition, we conduct an attention map visualization to analyze the alignment among visual attention, linguistic prompts, and to-be-executed actions of \textit{ReFineVLA}, showcasing its ability to focus on relevant tasks and actions. Through the latter step, we explore that \textit{ReFineVLA}-trained models exhibit a meaningful attention shift towards relevant objects, highlighting the enhanced multimodal understanding and improved generalization.
>   Evaluated across manipulation tasks, \textit{ReFineVLA} outperforms the state-of-the-art baselines. Specifically, it achieves an average increase of $5.0\%$ success rate on SimplerEnv WidowX Robot tasks, improves by an average of $8.6\%$ in variant aggregation settings, and by $1.7\%$ in visual matching settings for SimplerEnv Google Robot tasks. The source code will be publicly available.

