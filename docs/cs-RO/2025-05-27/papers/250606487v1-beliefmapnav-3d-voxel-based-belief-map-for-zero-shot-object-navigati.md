---
layout: default
title: "BeliefMapNav: 3D Voxel-Based Belief Map for Zero-Shot Object Navigation"
---

# BeliefMapNav: 3D Voxel-Based Belief Map for Zero-Shot Object Navigation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.06487" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.06487v1</a>
  <a href="https://arxiv.org/pdf/2506.06487.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.06487v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.06487v1', 'BeliefMapNav: 3D Voxel-Based Belief Map for Zero-Shot Object Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zibo Zhou, Yue Hu, Lingkai Zhang, Zonglin Li, Siheng Chen

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºBeliefMapNavä»¥è§£å†³é›¶-shotç‰©ä½“å¯¼èˆªé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é›¶-shotå¯¼èˆª` `3Dä½“ç´ ` `ä¿¡å¿µå›¾` `è¯­ä¹‰æ¨ç†` `è·¯å¾„è§„åˆ’` `æœºå™¨äººå¯¼èˆª` `è§†è§‰-è¯­è¨€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„é›¶-shotç‰©ä½“å¯¼èˆªæ–¹æ³•åœ¨ç©ºé—´æ¨ç†å’Œå…¨å±€ç¯å¢ƒç†è§£æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´å¯¼èˆªæ•ˆç‡ä½ä¸‹ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº3Dä½“ç´ çš„ä¿¡å¿µå›¾ï¼Œé€šè¿‡æ•´åˆè¯­ä¹‰å…ˆéªŒå’Œå®æ—¶è§‚å¯Ÿï¼Œæ„å»ºç›®æ ‡ä½ç½®çš„å…¨å±€åéªŒä¿¡å¿µã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒBeliefMapNavåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œæ˜¾è‘—æå‡äº†å¯¼èˆªæˆåŠŸç‡å’Œæ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é›¶-shotç‰©ä½“å¯¼èˆªï¼ˆZSONï¼‰ä½¿æœºå™¨äººèƒ½å¤Ÿåœ¨ä¸ç†Ÿæ‚‰çš„ç¯å¢ƒä¸­æ ¹æ®è‡ªç„¶è¯­è¨€æŒ‡ä»¤æ‰¾åˆ°ç›®æ ‡ç‰©ä½“ï¼Œè€Œæ— éœ€ä¾èµ–é¢„æ„å»ºçš„åœ°å›¾æˆ–ç‰¹å®šä»»åŠ¡çš„è®­ç»ƒã€‚ç°æœ‰çš„é€šç”¨æ¨¡å‹ï¼Œå¦‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œè§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰ï¼Œè™½ç„¶èµ‹äºˆäº†ä»£ç†è¯­ä¹‰æ¨ç†èƒ½åŠ›ï¼Œä½†åœ¨ç¯å¢ƒçš„å…¨å±€ç†è§£å’Œç©ºé—´æ¨ç†æ–¹é¢å­˜åœ¨å±€é™ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŸºäº3Dä½“ç´ çš„ä¿¡å¿µå›¾ï¼Œèƒ½å¤Ÿåœ¨ä½“ç´ åŒ–çš„3Dç©ºé—´ä¸­ä¼°è®¡ç›®æ ‡çš„å…ˆéªŒå­˜åœ¨åˆ†å¸ƒã€‚åŸºäºè¿™ä¸€ä¿¡å¿µå›¾ï¼Œæˆ‘ä»¬å¼•å…¥äº†BeliefMapNavï¼Œä¸€ä¸ªé«˜æ•ˆçš„å¯¼èˆªç³»ç»Ÿï¼Œèƒ½å¤Ÿå®ç°ç²¾ç¡®çš„ç›®æ ‡ä½ç½®ä¼°è®¡å’Œé«˜æ•ˆçš„å…¨å±€å¯¼èˆªå†³ç­–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒBeliefMapNavåœ¨HM3Dã€MP3Då’ŒHSSDåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æˆåŠŸç‡ï¼ˆSRï¼‰å’Œè·¯å¾„é•¿åº¦åŠ æƒæˆåŠŸç‡ï¼ˆSPLï¼‰ï¼Œåœ¨SPLä¸Šæ¯”ä¹‹å‰çš„æœ€ä½³æ–¹æ³•æé«˜äº†46.4%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³é›¶-shotç‰©ä½“å¯¼èˆªä¸­çš„ç©ºé—´æ¨ç†ä¸è¶³å’Œå…¨å±€ç¯å¢ƒç†è§£ç¼ºå¤±çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸æ— æ³•æœ‰æ•ˆæ•´åˆè¯­ä¹‰ä¿¡æ¯ä¸ç¯å¢ƒä¿¡æ¯ï¼Œå¯¼è‡´å¯¼èˆªå†³ç­–ä¸å¤Ÿç²¾å‡†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºåŸºäº3Dä½“ç´ çš„ä¿¡å¿µå›¾ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹çš„è¯­ä¹‰æ¨ç†èƒ½åŠ›å’Œè§†è§‰åµŒå…¥ï¼Œç»“åˆåˆ†å±‚ç©ºé—´ç»“æ„å’Œå®æ—¶è§‚å¯Ÿï¼Œæ„å»ºç›®æ ‡ä½ç½®çš„å…¨å±€åéªŒä¿¡å¿µã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¿¡å¿µå›¾çš„æ„å»ºæ¨¡å—å’Œå¯¼èˆªå†³ç­–æ¨¡å—ã€‚ä¿¡å¿µå›¾æ¨¡å—è´Ÿè´£æ•´åˆè¯­ä¹‰ä¿¡æ¯å’Œç¯å¢ƒä¿¡æ¯ï¼Œè€Œå¯¼èˆªæ¨¡å—åˆ™åŸºäºä¿¡å¿µå›¾è¿›è¡Œè·¯å¾„è§„åˆ’å’Œç›®æ ‡å®šä½ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†LLMçš„è¯­ä¹‰æ¨ç†ä¸3Då±‚æ¬¡è¯­ä¹‰ä½“ç´ ç©ºé—´ç›¸ç»“åˆï¼Œä½¿å¾—ç›®æ ‡ä½ç½®ä¼°è®¡æ›´åŠ ç²¾å‡†ï¼ŒåŒæ—¶å¼•å…¥é¡ºåºè·¯å¾„è§„åˆ’ä»¥æå‡å…¨å±€å¯¼èˆªå†³ç­–çš„æ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ä½“ç´ åŒ–çš„3Dç©ºé—´è¡¨ç¤ºï¼Œç»“åˆäº†å¤šå±‚æ¬¡çš„è¯­ä¹‰ä¿¡æ¯ï¼Œå¹¶åœ¨æŸå¤±å‡½æ•°ä¸­è€ƒè™‘äº†è·¯å¾„é•¿åº¦å’ŒæˆåŠŸç‡çš„åŠ æƒï¼Œç¡®ä¿äº†æ¨¡å‹çš„é«˜æ•ˆæ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒBeliefMapNavåœ¨HM3Dã€MP3Då’ŒHSSDåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æˆåŠŸç‡ï¼ˆSRï¼‰å’ŒæˆåŠŸåŠ æƒè·¯å¾„é•¿åº¦ï¼ˆSPLï¼‰ï¼Œåœ¨SPLä¸Šæ¯”ä¹‹å‰çš„æœ€ä½³æ–¹æ³•æé«˜äº†46.4%ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œé«˜æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½æœºå™¨äººã€è‡ªåŠ¨é©¾é©¶ã€è™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®ç­‰ã€‚é€šè¿‡æå‡æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„å¯¼èˆªèƒ½åŠ›ï¼ŒBeliefMapNavæœ‰æœ›åœ¨å®é™…åº”ç”¨ä¸­å®ç°æ›´é«˜çš„è‡ªä¸»æ€§å’Œçµæ´»æ€§ï¼Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿçš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Zero-shot object navigation (ZSON) allows robots to find target objects in unfamiliar environments using natural language instructions, without relying on pre-built maps or task-specific training. Recent general-purpose models, such as large language models (LLMs) and vision-language models (VLMs), equip agents with semantic reasoning abilities to estimate target object locations in a zero-shot manner. However, these models often greedily select the next goal without maintaining a global understanding of the environment and are fundamentally limited in the spatial reasoning necessary for effective navigation. To overcome these limitations, we propose a novel 3D voxel-based belief map that estimates the target's prior presence distribution within a voxelized 3D space. This approach enables agents to integrate semantic priors from LLMs and visual embeddings with hierarchical spatial structure, alongside real-time observations, to build a comprehensive 3D global posterior belief of the target's location. Building on this 3D voxel map, we introduce BeliefMapNav, an efficient navigation system with two key advantages: i) grounding LLM semantic reasoning within the 3D hierarchical semantics voxel space for precise target position estimation, and ii) integrating sequential path planning to enable efficient global navigation decisions. Experiments on HM3D, MP3D, and HSSD benchmarks show that BeliefMapNav achieves state-of-the-art (SOTA) Success Rate (SR) and Success weighted by Path Length (SPL), with a notable 46.4% SPL improvement over the previous best SR method, validating its effectiveness and efficiency.

