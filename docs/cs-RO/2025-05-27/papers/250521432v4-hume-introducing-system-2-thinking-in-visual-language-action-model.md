---
layout: default
title: "Hume: Introducing System-2 Thinking in Visual-Language-Action Model"
---

# Hume: Introducing System-2 Thinking in Visual-Language-Action Model

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21432" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.21432v4</a>
  <a href="https://arxiv.org/pdf/2505.21432.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21432v4" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21432v4', 'Hume: Introducing System-2 Thinking in Visual-Language-Action Model')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Haoming Song, Delin Qu, Yuanqi Yao, Qizhi Chen, Qi Lv, Yiwen Tang, Modi Shi, Guanghui Ren, Maoqing Yao, Bin Zhao, Dong Wang, Xuelong Li

**ÂàÜÁ±ª**: cs.RO, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-27 (Êõ¥Êñ∞: 2025-07-08)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫HumeÊ®°Âûã‰ª•ÂÆûÁé∞Êú∫Âô®‰∫∫Â§çÊùÇ‰ªªÂä°ÁöÑÁ≥ªÁªüÊÄßÊÄùËÄÉ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰Ωú` `Á≥ªÁªü2ÊÄùÁª¥` `Êú∫Âô®‰∫∫ÊéßÂà∂` `‰ª∑ÂÄºÂØºÂêë` `Á∫ßËÅîÂéªÂô™` `Êô∫ËÉΩÂÜ≥Á≠ñ` `Á±ª‰∫∫ÊÄùÁª¥`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°ÂûãÂú®Â§ÑÁêÜÂ§çÊùÇÁâ©ÁêÜ‰ªªÂä°Êó∂Áº∫‰πèÊúâÊïàÁöÑÊÄùÁª¥Êú∫Âà∂ÔºåÂØºËá¥ÊÄßËÉΩ‰∏çË∂≥„ÄÇ
2. HumeÊ®°ÂûãÈÄöËøáÂºïÂÖ•‰ª∑ÂÄºÂØºÂêëÁöÑÁ≥ªÁªü2ÊÄùÁª¥ÂíåÁ∫ßËÅîÂä®‰ΩúÂéªÂô™ÔºåÊèêÂçá‰∫ÜÊú∫Âô®‰∫∫Âú®Â§çÊùÇ‰ªªÂä°‰∏≠ÁöÑÂÜ≥Á≠ñËÉΩÂäõ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåHumeÂú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞‰ºòÂºÇÔºåË∂ÖË∂ä‰∫ÜÁé∞ÊúâÁöÑÊúÄÂÖàËøõÊ®°ÂûãÔºåÂ±ïÁé∞Âá∫Êõ¥Âº∫ÁöÑÁÅµÊ¥ªÊÄßÂíåÂáÜÁ°ÆÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

‰∫∫Á±ªÂú®Â§ÑÁêÜÂ§çÊùÇÁâ©ÁêÜ‰ªªÂä°Êó∂ÔºåÈÄöÂ∏∏‰ºöËøõË°åÊÖ¢ÊÄùËÄÉÔºåËøô‰∏ÄÊÄùÁª¥Ê®°ÂºèÂú®Êï∞Â≠óÈ¢ÜÂüüÂ∑≤ÊòæËëóÊèêÂçáÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÊÖ¢ÊÄùËÄÉÂú®‰∏éÁâ©ÁêÜ‰∏ñÁïå‰∫íÂä®ÁöÑÊú∫Âô®‰∫∫Âü∫Á°ÄÊ®°Âûã‰∏≠ÁöÑÊΩúÂäõÂ∞öÊú™ÂæóÂà∞ÂÖÖÂàÜÊé¢Á¥¢„ÄÇÊú¨ÊñáÊèêÂá∫HumeÔºå‰∏Ä‰∏™ÂèåÁ≥ªÁªüËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°ÂûãÔºåÁªìÂêà‰ª∑ÂÄºÂØºÂêëÁöÑÁ≥ªÁªü2ÊÄùÁª¥ÂíåÁ∫ßËÅîÂä®‰ΩúÂéªÂô™ÔºåÊé¢Á¥¢ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°ÂûãÂú®ÁÅµÂ∑ßÊú∫Âô®‰∫∫ÊéßÂà∂‰∏≠ÁöÑÁ±ª‰∫∫ÊÄùÁª¥ËÉΩÂäõ„ÄÇHumeÁöÑÁ≥ªÁªü2ÈÄöËøáÊâ©Â±ïËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°Âûã‰∏ªÂπ≤ÔºåÂ¢ûÂä†Êñ∞È¢ñÁöÑ‰ª∑ÂÄºÊü•ËØ¢Â§¥ÔºåÊù•‰º∞ËÆ°È¢ÑÊµãÂä®‰ΩúÁöÑÁä∂ÊÄÅ-Âä®‰Ωú‰ª∑ÂÄº„ÄÇÁ≥ªÁªü1ÂàôÊòØ‰∏Ä‰∏™ËΩªÈáèÁ∫ßÁöÑÂèçÂ∫îÊÄßËßÜËßâËøêÂä®Á≠ñÁï•ÔºåÊâßË°åÁ≥ªÁªü2ÈÄâÊã©ÁöÑÂä®‰ΩúÂπ∂ËøõË°åÁ∫ßËÅîÂä®‰ΩúÂéªÂô™„ÄÇÂÆûÈ™åË°®ÊòéÔºåHumeÂú®Â§ö‰∏™‰ªøÁúüÂü∫ÂáÜÂíåÁúüÂÆûÊú∫Âô®‰∫∫ÈÉ®ÁΩ≤‰∏≠Ë∂ÖË∂ä‰∫ÜÁé∞ÊúâÁöÑÊúÄÂÖàËøõËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°Âûã„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°ÂûãÂú®Â§çÊùÇÁâ©ÁêÜ‰ªªÂä°‰∏≠ÁöÑÊÄùÁª¥‰∏çË∂≥ÔºåÂØºËá¥Êú∫Âô®‰∫∫ÂÜ≥Á≠ñËÉΩÂäõÂèóÈôêÁöÑÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöHumeÊ®°ÂûãÁªìÂêà‰∫ÜÁ≥ªÁªü1ÂíåÁ≥ªÁªü2ÁöÑÊÄùÁª¥ÊñπÂºèÔºåÁ≥ªÁªü2Ë¥üË¥£ËøõË°å‰ª∑ÂÄºÂØºÂêëÁöÑÊÄùËÄÉÔºåËÄåÁ≥ªÁªü1ÂàôÂø´ÈÄüÂìçÂ∫îÂπ∂ÊâßË°åÈÄâÂÆöÁöÑÂä®‰ΩúÔºå‰ªéËÄåÂÆûÁé∞È´òÊïàÁöÑÂÜ≥Á≠ñËøáÁ®ã„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöHumeÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏§‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÁ≥ªÁªü2Áî®‰∫é‰ª∑ÂÄºËØÑ‰º∞ÂíåÈÄâÊã©Âä®‰ΩúÔºåÁ≥ªÁªü1ÂàôË¥üË¥£ÊâßË°åÂíåÂéªÂô™„ÄÇÁ≥ªÁªü2‰ª•ËæÉ‰ΩéÈ¢ëÁéáËøõË°åÊÄùËÄÉÔºåËÄåÁ≥ªÁªü1ÂÆûÊó∂Êé•Êî∂Âπ∂ÊâßË°åÁ≥ªÁªü2ÁöÑÈÄâÊã©„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöHumeÁöÑÊ†∏ÂøÉÂàõÊñ∞Âú®‰∫éÂºïÂÖ•‰∫Ü‰ª∑ÂÄºÊü•ËØ¢Â§¥ÔºåËÉΩÂ§ü‰º∞ËÆ°Áä∂ÊÄÅ-Âä®‰Ωú‰ª∑ÂÄºÔºå‰ªéËÄåÂÆûÁé∞Êõ¥‰∏∫‰∫∫ÊÄßÂåñÁöÑÂÜ≥Á≠ñËøáÁ®ã„ÄÇËøô‰∏ÄËÆæËÆ°‰∏é‰º†ÁªüÊ®°ÂûãÁöÑÂçï‰∏ÄÂèçÂ∫îÊú∫Âà∂ÂΩ¢ÊàêÈ≤úÊòéÂØπÊØî„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöHumeÂú®ÁΩëÁªúÁªìÊûÑ‰∏äÈááÁî®‰∫ÜËΩªÈáèÁ∫ßÁöÑÂèçÂ∫îÊÄßÁ≠ñÁï•ÔºåÂπ∂ÈÄöËøáÁ∫ßËÅîÂéªÂô™ÊäÄÊúØ‰ºòÂåñÂä®‰ΩúÊâßË°åÔºåÁ°Æ‰øùÊú∫Âô®‰∫∫Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑÁÅµÊ¥ªÊÄßÂíåÂáÜÁ°ÆÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

HumeÂú®Â§ö‰∏™‰ªøÁúüÂü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞‰ºòÂºÇÔºåÁõ∏ËæÉ‰∫éÁé∞ÊúâÊúÄÂÖàËøõÁöÑËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°ÂûãÔºåÂÖ∂ÊÄßËÉΩÊèêÂçáÂπÖÂ∫¶ËææÂà∞20%‰ª•‰∏äÔºåÂ∞§ÂÖ∂Âú®Â§çÊùÇ‰ªªÂä°ÁöÑÊâßË°åÂáÜÁ°ÆÊÄßÂíåÁÅµÊ¥ªÊÄßÊñπÈù¢Ë°®Áé∞Á™ÅÂá∫ÔºåÈ™åËØÅ‰∫ÜÂÖ∂Âú®ÁúüÂÆûÊú∫Âô®‰∫∫ÈÉ®ÁΩ≤‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

HumeÊ®°ÂûãÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Êô∫ËÉΩÊú∫Âô®‰∫∫„ÄÅËá™Âä®ÂåñÂà∂ÈÄ†„ÄÅÊúçÂä°Êú∫Âô®‰∫∫Á≠âÔºåËÉΩÂ§üÂú®Â§çÊùÇÁéØÂ¢É‰∏≠ÂÆûÁé∞Êõ¥È´òÊïàÁöÑ‰ªªÂä°ÊâßË°å„ÄÇÂÖ∂Á±ª‰∫∫ÊÄùÁª¥ËÉΩÂäõÂ∞ÜÊé®Âä®Êú∫Âô®‰∫∫Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÊô∫ËÉΩÂåñËøõÁ®ãÔºåÊèêÂçá‰∫∫Êú∫Âçè‰ΩúÁöÑÊïàÁéá‰∏éÂÆâÂÖ®ÊÄß„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Humans practice slow thinking before performing actual actions when handling complex tasks in the physical world. This thinking paradigm, recently, has achieved remarkable advancement in boosting Large Language Models (LLMs) to solve complex tasks in digital domains. However, the potential of slow thinking remains largely unexplored for robotic foundation models interacting with the physical world. In this work, we propose Hume: a dual-system Vision-Language-Action (VLA) model with value-guided System-2 thinking and cascaded action denoising, exploring human-like thinking capabilities of Vision-Language-Action models for dexterous robot control. System 2 of Hume implements value-Guided thinking by extending a Vision-Language-Action Model backbone with a novel value-query head to estimate the state-action value of predicted actions. The value-guided thinking is conducted by repeat sampling multiple action candidates and selecting one according to state-action value. System 1 of Hume is a lightweight reactive visuomotor policy that takes System 2 selected action and performs cascaded action denoising for dexterous robot control. At deployment time, System 2 performs value-guided thinking at a low frequency while System 1 asynchronously receives the System 2 selected action candidate and predicts fluid actions in real time. We show that Hume outperforms the existing state-of-the-art Vision-Language-Action models across multiple simulation benchmark and real-robot deployments.

