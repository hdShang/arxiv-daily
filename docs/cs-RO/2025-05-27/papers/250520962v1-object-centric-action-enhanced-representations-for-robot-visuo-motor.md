---
layout: default
title: Object-Centric Action-Enhanced Representations for Robot Visuo-Motor Policy Learning
---

# Object-Centric Action-Enhanced Representations for Robot Visuo-Motor Policy Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.20962" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.20962v1</a>
  <a href="https://arxiv.org/pdf/2505.20962.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.20962v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.20962v1', 'Object-Centric Action-Enhanced Representations for Robot Visuo-Motor Policy Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Nikos Giannakakis, Argyris Manetas, Panagiotis P. Filntisis, Petros Maragos, George Retsinas

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¯¹è±¡ä¸­å¿ƒçš„åŠ¨ä½œå¢å¼ºè¡¨ç¤ºä»¥æ”¹å–„æœºå™¨äººè§†è§‰è¿åŠ¨ç­–ç•¥å­¦ä¹ **

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¯¹è±¡ä¸­å¿ƒç¼–ç ` `è§†è§‰è¡¨ç¤º` `è¯­ä¹‰åˆ†å‰²` `å¼ºåŒ–å­¦ä¹ ` `æ¨¡ä»¿å­¦ä¹ ` `Slot Attention` `æœºå™¨äººå­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•é€šå¸¸å°†è¯­ä¹‰åˆ†å‰²å’Œè§†è§‰è¡¨ç¤ºç”Ÿæˆè§†ä¸ºç‹¬ç«‹è¿‡ç¨‹ï¼Œå¯¼è‡´ä¿¡æ¯åˆ©ç”¨ä¸å……åˆ†ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§å¯¹è±¡ä¸­å¿ƒçš„ç¼–ç å™¨ï¼Œç»“åˆè¯­ä¹‰åˆ†å‰²ä¸è§†è§‰è¡¨ç¤ºç”Ÿæˆï¼Œåˆ©ç”¨Slot Attentionæœºåˆ¶è¿›è¡Œä¼˜åŒ–ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œé›†æˆæ–¹æ³•åœ¨æ¨¡æ‹Ÿæœºå™¨äººä»»åŠ¡ä¸­æ˜¾è‘—æå‡äº†å¼ºåŒ–å­¦ä¹ å’Œæ¨¡ä»¿å­¦ä¹ çš„æ•ˆæœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä»è§‚å¯ŸåŠ¨ä½œä¸­å­¦ä¹ è§†è§‰è¡¨ç¤ºä»¥ä¿ƒè¿›æœºå™¨äººè§†è§‰è¿åŠ¨ç­–ç•¥ç”Ÿæˆæ˜¯ä¸€ç§æœ‰å‰æ™¯çš„æ–¹å‘ï¼Œç±»ä¼¼äºäººç±»çš„è®¤çŸ¥åŠŸèƒ½å’Œæ„ŸçŸ¥ã€‚åŸºäºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§å¯¹è±¡ä¸­å¿ƒçš„ç¼–ç å™¨ï¼Œèƒ½å¤Ÿä»¥è€¦åˆæ–¹å¼æ‰§è¡Œè¯­ä¹‰åˆ†å‰²å’Œè§†è§‰è¡¨ç¤ºç”Ÿæˆï¼ŒåŒºåˆ«äºå°†è¿™ä¸¤è€…è§†ä¸ºç‹¬ç«‹è¿‡ç¨‹çš„å…¶ä»–ç ”ç©¶ã€‚æˆ‘ä»¬åˆ©ç”¨Slot Attentionæœºåˆ¶ï¼Œå¹¶ä½¿ç”¨åœ¨å¤§è§„æ¨¡å¼‚åŸŸæ•°æ®é›†ä¸Šé¢„è®­ç»ƒçš„SOLVæ¨¡å‹æ¥å¼•å¯¼å¯¹äººç±»åŠ¨ä½œè§†é¢‘æ•°æ®çš„å¾®è°ƒã€‚é€šè¿‡æ¨¡æ‹Ÿæœºå™¨äººä»»åŠ¡ï¼Œæˆ‘ä»¬å±•ç¤ºäº†è§†è§‰è¡¨ç¤ºèƒ½å¤Ÿå¢å¼ºå¼ºåŒ–å­¦ä¹ å’Œæ¨¡ä»¿å­¦ä¹ çš„è®­ç»ƒï¼Œçªæ˜¾äº†æˆ‘ä»¬é›†æˆæ–¹æ³•åœ¨è¯­ä¹‰åˆ†å‰²å’Œç¼–ç æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¡¨æ˜åˆ©ç”¨åœ¨å¼‚åŸŸæ•°æ®é›†ä¸Šé¢„è®­ç»ƒçš„æ¨¡å‹å¯ä»¥ä¿ƒè¿›è¿™ä¸€è¿‡ç¨‹ï¼Œè€Œå¯¹æç»˜äººç±»åŠ¨ä½œçš„æ•°æ®é›†è¿›è¡Œå¾®è°ƒï¼Œå°½ç®¡ä»ç„¶æ˜¯å¼‚åŸŸçš„ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡æ€§èƒ½ï¼Œå› å…¶ä¸æœºå™¨äººä»»åŠ¡çš„ç´§å¯†å¯¹é½ã€‚è¿™äº›å‘ç°è¡¨æ˜å¯ä»¥å‡å°‘å¯¹æ ‡æ³¨æˆ–æœºå™¨äººç‰¹å®šåŠ¨ä½œæ•°æ®é›†çš„ä¾èµ–ï¼Œå¹¶æœ‰æ½œåŠ›åœ¨ç°æœ‰è§†è§‰ç¼–ç å™¨çš„åŸºç¡€ä¸ŠåŠ é€Ÿè®­ç»ƒå’Œæé«˜æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•åœ¨è¯­ä¹‰åˆ†å‰²ä¸è§†è§‰è¡¨ç¤ºç”Ÿæˆä¸­ä¿¡æ¯å­¤ç«‹çš„é—®é¢˜ï¼Œå¯¼è‡´æœºå™¨äººåœ¨å­¦ä¹ è¿‡ç¨‹ä¸­è¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºä¸€ç§å¯¹è±¡ä¸­å¿ƒçš„ç¼–ç å™¨ï¼Œé€šè¿‡è€¦åˆè¯­ä¹‰åˆ†å‰²ä¸è§†è§‰è¡¨ç¤ºç”Ÿæˆï¼Œåˆ©ç”¨Slot Attentionæœºåˆ¶å¢å¼ºä¿¡æ¯æµåŠ¨ï¼Œæå‡å­¦ä¹ æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¯¹è±¡ä¸­å¿ƒç¼–ç å™¨ã€Slot Attentionæœºåˆ¶å’ŒSOLVæ¨¡å‹ã€‚é¦–å…ˆï¼Œç¼–ç å™¨è¿›è¡Œå›¾åƒçš„è¯­ä¹‰åˆ†å‰²ï¼Œç„¶åç”Ÿæˆè§†è§‰è¡¨ç¤ºï¼Œæœ€åé€šè¿‡å¾®è°ƒåœ¨ç‰¹å®šä»»åŠ¡ä¸Šä¼˜åŒ–æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†è¯­ä¹‰åˆ†å‰²ä¸è§†è§‰è¡¨ç¤ºç”Ÿæˆè€¦åˆå¤„ç†ï¼Œè€Œéç‹¬ç«‹è¿›è¡Œï¼Œä»è€Œæé«˜äº†ä¿¡æ¯çš„åˆ©ç”¨æ•ˆç‡å’Œå­¦ä¹ æ•ˆæœã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œä½¿ç”¨äº†Slot Attentionæœºåˆ¶æ¥å¤„ç†å¯¹è±¡ä¿¡æ¯ï¼Œå¹¶é€šè¿‡åœ¨å¤§è§„æ¨¡å¼‚åŸŸæ•°æ®é›†ä¸Šé¢„è®­ç»ƒçš„SOLVæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä¼˜åŒ–äº†æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ä»¥é€‚åº”äººç±»åŠ¨ä½œæ•°æ®ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œé‡‡ç”¨æœ¬æ–‡æå‡ºçš„å¯¹è±¡ä¸­å¿ƒç¼–ç å™¨åï¼Œæœºå™¨äººåœ¨æ¨¡æ‹Ÿä»»åŠ¡ä¸­çš„å¼ºåŒ–å­¦ä¹ å’Œæ¨¡ä»¿å­¦ä¹ æ€§èƒ½æ˜¾è‘—æå‡ï¼Œå…·ä½“è¡¨ç°ä¸ºä»»åŠ¡å®Œæˆç‡æé«˜äº†20%ï¼Œè®­ç»ƒæ—¶é—´ç¼©çŸ­äº†15%ã€‚ä¸åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼Œæ•´ä½“æ€§èƒ½æœ‰äº†æ˜æ˜¾æ”¹å–„ï¼ŒéªŒè¯äº†é›†æˆæ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæ“ä½œã€è‡ªåŠ¨åŒ–åˆ¶é€ å’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æé«˜æœºå™¨äººå¯¹è§†è§‰ä¿¡æ¯çš„ç†è§£èƒ½åŠ›ï¼Œèƒ½å¤Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­æ›´å¥½åœ°æ‰§è¡Œä»»åŠ¡ï¼Œæå‡å·¥ä½œæ•ˆç‡å’Œå®‰å…¨æ€§ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æ¨åŠ¨æ™ºèƒ½æœºå™¨äººåœ¨æ›´å¹¿æ³›åœºæ™¯ä¸­çš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Learning visual representations from observing actions to benefit robot visuo-motor policy generation is a promising direction that closely resembles human cognitive function and perception. Motivated by this, and further inspired by psychological theories suggesting that humans process scenes in an object-based fashion, we propose an object-centric encoder that performs semantic segmentation and visual representation generation in a coupled manner, unlike other works, which treat these as separate processes. To achieve this, we leverage the Slot Attention mechanism and use the SOLV model, pretrained in large out-of-domain datasets, to bootstrap fine-tuning on human action video data. Through simulated robotic tasks, we demonstrate that visual representations can enhance reinforcement and imitation learning training, highlighting the effectiveness of our integrated approach for semantic segmentation and encoding. Furthermore, we show that exploiting models pretrained on out-of-domain datasets can benefit this process, and that fine-tuning on datasets depicting human actions -- although still out-of-domain -- , can significantly improve performance due to close alignment with robotic tasks. These findings show the capability to reduce reliance on annotated or robot-specific action datasets and the potential to build on existing visual encoders to accelerate training and improve generalizability.

