---
layout: default
title: Fast and Cost-effective Speculative Edge-Cloud Decoding with Early Exits
---

# Fast and Cost-effective Speculative Edge-Cloud Decoding with Early Exits

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21594" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21594v1</a>
  <a href="https://arxiv.org/pdf/2505.21594.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21594v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21594v1', 'Fast and Cost-effective Speculative Edge-Cloud Decoding with Early Exits')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yeshwanth Venkatesha, Souvik Kundu, Priyadarshini Panda

**åˆ†ç±»**: cs.RO, cs.AI, cs.DC

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¿«é€Ÿä¸”ç»æµçš„è¾¹ç¼˜äº‘è§£ç æ¡†æ¶ä»¥é™ä½LLMéƒ¨ç½²æˆæœ¬**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¾¹ç¼˜è®¡ç®—` `äº‘è§£ç ` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ—©æœŸé€€å‡ºæœºåˆ¶` `èµ„æºä¼˜åŒ–` `å®æ—¶åº”ç”¨` `æœºå™¨äººæ§åˆ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„äº‘ç«¯APIä¾èµ–ä½¿å¾—å¤§å‹è¯­è¨€æ¨¡å‹çš„éƒ¨ç½²æˆæœ¬é«˜æ˜‚ï¼Œé™åˆ¶äº†å°å‹ç»„ç»‡çš„è®¿é—®å¹¶å¼•å‘å¯æŒç»­æ€§é—®é¢˜ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§è¾¹ç¼˜äº‘è§£ç æ¡†æ¶ï¼Œé€šè¿‡åœ¨ç›®æ ‡æ¨¡å‹ä¸­å¼•å…¥æ—©æœŸé€€å‡ºæœºåˆ¶ï¼Œæå‡äº†è¾¹ç¼˜è®¾å¤‡çš„è®¡ç®—æ•ˆç‡ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å»¶è¿Ÿä¸Šè¾ƒä¼ ç»Ÿäº‘ç«¯è‡ªå›å½’è§£ç å‡å°‘äº†35%ï¼Œåœ¨å››è¶³æœºå™¨äººä¸Šçš„åº”ç”¨å®ç°äº†21%çš„é€Ÿåº¦æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ™ºèƒ½æ‰‹æœºã€å¯ç©¿æˆ´è®¾å¤‡å’Œæœºå™¨äººç­‰è¾¹ç¼˜è®¾å¤‡ä¸Šçš„åº”ç”¨å—åˆ°äº‘ç«¯APIé«˜æ˜‚æˆæœ¬çš„é™åˆ¶ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§å¿«é€Ÿä¸”ç»æµçš„è¾¹ç¼˜äº‘è§£ç æ¡†æ¶ï¼Œç»“åˆäº†æœåŠ¡å™¨ä¸Šçš„å¤§å‹ç›®æ ‡æ¨¡å‹å’Œè®¾å¤‡ä¸Šçš„å°å‹è‰ç¨¿æ¨¡å‹ã€‚é€šè¿‡åœ¨ç›®æ ‡æ¨¡å‹ä¸­å¼•å…¥æ—©æœŸé€€å‡ºæœºåˆ¶ï¼Œå…è®¸åœ¨æœ€ç»ˆéªŒè¯å‰ç”Ÿæˆä»¤ç‰Œï¼Œä»è€Œæå‡è¾¹ç¼˜ä¸äº‘ä¹‹é—´çš„å¹¶è¡Œæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨NVIDIA Jetson Nanoå’ŒA100 GPUä¸Šå®ç°äº†é«˜è¾¾35%çš„å»¶è¿Ÿå‡å°‘ï¼Œå¹¶åœ¨Unitree Go2å››è¶³æœºå™¨äººä¸Šå®ç°äº†21%çš„é€Ÿåº¦æå‡ï¼Œå±•ç¤ºäº†å…¶åœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ä¸Šå®æ—¶åº”ç”¨çš„æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šéƒ¨ç½²æ—¶é¢ä¸´çš„é«˜æˆæœ¬å’Œå»¶è¿Ÿé—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äº‘ç«¯APIï¼Œå¯¼è‡´èµ„æºå—é™çš„è®¾å¤‡æ— æ³•æœ‰æ•ˆåˆ©ç”¨LLMã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºä¸€ç§è¾¹ç¼˜äº‘è§£ç æ¡†æ¶ï¼Œç»“åˆæœåŠ¡å™¨ä¸Šçš„å¤§å‹ç›®æ ‡æ¨¡å‹ä¸è®¾å¤‡ä¸Šçš„å°å‹è‰ç¨¿æ¨¡å‹ï¼Œé€šè¿‡æ—©æœŸé€€å‡ºæœºåˆ¶æå‡è®¡ç®—æ•ˆç‡ï¼Œå…è®¸åœ¨æœ€ç»ˆéªŒè¯å‰ç”Ÿæˆä»¤ç‰Œã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å®¢æˆ·ç«¯ï¼ˆNVIDIA Jetson Nanoï¼‰å’ŒæœåŠ¡å™¨ï¼ˆA100 GPUï¼‰ï¼Œå®¢æˆ·ç«¯ä½¿ç”¨è‰ç¨¿æ¨¡å‹ç”Ÿæˆåˆæ­¥ä»¤ç‰Œï¼ŒæœåŠ¡å™¨è¿›è¡Œæœ€ç»ˆéªŒè¯ï¼ŒäºŒè€…é€šè¿‡å¹¶è¡Œå¤„ç†æå‡æ•ˆç‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šå¼•å…¥æ—©æœŸé€€å‡ºæœºåˆ¶æ˜¯æœ¬æ–‡çš„æ ¸å¿ƒåˆ›æ–°ï¼Œä½¿å¾—åœ¨ç”Ÿæˆä»¤ç‰Œçš„è¿‡ç¨‹ä¸­èƒ½å¤Ÿåˆ©ç”¨ç©ºé—²æ—¶é—´ï¼Œæ˜¾è‘—æå‡äº†è¾¹ç¼˜ä¸äº‘ä¹‹é—´çš„å¹¶è¡Œæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸Šï¼Œè‰ç¨¿æ¨¡å‹ï¼ˆVicuna-68Mï¼‰å’Œç›®æ ‡æ¨¡å‹ï¼ˆLlama2-7Bï¼‰çš„é€‰æ‹©ç»è¿‡ä¼˜åŒ–ï¼Œä»¥ç¡®ä¿åœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­ä»èƒ½ä¿æŒè¾ƒé«˜çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨NVIDIA Jetson Nanoä¸Šå®ç°äº†é«˜è¾¾35%çš„å»¶è¿Ÿå‡å°‘ï¼Œç›¸è¾ƒäºä¼ ç»Ÿäº‘ç«¯è‡ªå›å½’è§£ç ï¼Œé¢„å…ˆè‰æ‹Ÿä»¤ç‰Œåˆæå‡äº†11%ã€‚åœ¨Unitree Go2å››è¶³æœºå™¨äººä¸Šåº”ç”¨æ—¶ï¼Œé€Ÿåº¦æå‡è¾¾21%ï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ¡†æ¶å¯å¹¿æ³›åº”ç”¨äºæ™ºèƒ½æ‰‹æœºã€å¯ç©¿æˆ´è®¾å¤‡å’Œæœºå™¨äººç­‰è¾¹ç¼˜è®¡ç®—åœºæ™¯ï¼Œå°¤å…¶é€‚åˆèµ„æºå—é™çš„ç¯å¢ƒã€‚é€šè¿‡é™ä½äº‘ç«¯ä¾èµ–ï¼Œæå‡äº†å®æ—¶åº”ç”¨çš„å¯è¡Œæ€§ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¯æŒç»­å‘å±•æ½œåŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) enable various applications on edge devices such as smartphones, wearables, and embodied robots. However, their deployment often depends on expensive cloud-based APIs, creating high operational costs, which limit access for smaller organizations and raise sustainability concerns. Certain LLMs can be deployed on-device, offering a cost-effective solution with reduced latency and improved privacy. Yet, limited computing resources constrain the size and accuracy of models that can be deployed, necessitating a collaborative design between edge and cloud. We propose a fast and cost-effective speculative edge-cloud decoding framework with a large target model on the server and a small draft model on the device. By introducing early exits in the target model, tokens are generated mid-verification, allowing the client to preemptively draft subsequent tokens before final verification, thus utilizing idle time and enhancing parallelism between edge and cloud. Using an NVIDIA Jetson Nano (client) and an A100 GPU (server) with Vicuna-68M (draft) and Llama2-7B (target) models, our method achieves up to a 35% reduction in latency compared to cloud-based autoregressive decoding, with an additional 11% improvement from preemptive drafting. To demonstrate real-world applicability, we deploy our method on the Unitree Go2 quadruped robot using Vision-Language Model (VLM) based control, achieving a 21% speedup over traditional cloud-based autoregressive decoding. These results demonstrate the potential of our framework for real-time LLM and VLM applications on resource-constrained edge devices.

