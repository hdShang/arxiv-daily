---
layout: default
title: EgoWalk: A Multimodal Dataset for Robot Navigation in the Wild
---

# EgoWalk: A Multimodal Dataset for Robot Navigation in the Wild

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21282" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21282v1</a>
  <a href="https://arxiv.org/pdf/2505.21282.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21282v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21282v1', 'EgoWalk: A Multimodal Dataset for Robot Navigation in the Wild')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Timur Akhtyamov, Mohamad Al Mdfaa, Javier Antonio Ramirez, Sergey Bakulin, German Devchich, Denis Fatykhov, Alexander Mazurov, Kristina Zipa, Malik Mohrat, Pavel Kolesnik, Ivan Sosin, Gonzalo Ferrer

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-05-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEgoWalkæ•°æ®é›†ä»¥æå‡æœºå™¨äººå¯¼èˆªèƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æœºå™¨äººå¯¼èˆª` `æ•°æ®é›†` `æ¨¡ä»¿å­¦ä¹ ` `è‡ªç„¶è¯­è¨€å¤„ç†` `å¯é€šè¡Œæ€§åˆ†å‰²` `å¤šæ ·æ€§ç ”ç©¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¯¼èˆªç®—æ³•å¾€å¾€ä¾èµ–äºæœ‰é™çš„è®­ç»ƒæ•°æ®ï¼Œå¯¼è‡´åœ¨å¤æ‚å’Œä¸å¯æ§ç¯å¢ƒä¸­çš„æ€§èƒ½ä¸è¶³ã€‚
2. EgoWalkæ•°æ®é›†é€šè¿‡æä¾›å¤šæ ·åŒ–çš„çœŸå®ä¸–ç•Œå¯¼èˆªæ•°æ®ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ•°æ®é›†çš„å±€é™æ€§ï¼Œæ”¯æŒå¤šç§å¯¼èˆªä»»åŠ¡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒEgoWalkæ•°æ®é›†åœ¨å¤šæ ·æ€§å’Œå®ç”¨æ€§æ–¹é¢ä¼˜äºç°æœ‰æ•°æ®é›†ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡æœºå™¨äººå¯¼èˆªç³»ç»Ÿçš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ•°æ®é©±åŠ¨çš„å¯¼èˆªç®—æ³•åœ¨çœŸå®ä¸–ç•Œä¸­çš„æˆåŠŸè®­ç»ƒå’Œç¨³å¥æ€§èƒ½ä¾èµ–äºå¤§è§„æ¨¡ã€é«˜è´¨é‡çš„æ•°æ®é›†ã€‚ä¸ºå¢å¼ºå¯¼èˆªç›¸å…³æ•°æ®é›†çš„å¤šæ ·æ€§ï¼Œæœ¬æ–‡æå‡ºäº†EgoWalkæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŒ…å«50å°æ—¶çš„äººç±»å¯¼èˆªæ•°æ®ï¼Œæ¶µç›–å¤šç§å®¤å†…å¤–ç¯å¢ƒå’Œå­£èŠ‚ã€‚é™¤äº†åŸå§‹æ•°æ®å’Œé€‚ç”¨äºæ¨¡ä»¿å­¦ä¹ çš„æ•°æ®å¤–ï¼Œæœ¬æ–‡è¿˜ä»‹ç»äº†å¤šä¸ªè‡ªåŠ¨ç”Ÿæˆå­æ•°æ®é›†çš„ç®¡é“ï¼Œæ”¯æŒè‡ªç„¶è¯­è¨€ç›®æ ‡æ³¨é‡Šå’Œå¯é€šè¡Œæ€§åˆ†å‰²æ©ç ã€‚é€šè¿‡å¤šæ ·æ€§ç ”ç©¶ã€åº”ç”¨æ¡ˆä¾‹å’ŒåŸºå‡†æµ‹è¯•ï¼Œå±•ç¤ºäº†è¯¥æ•°æ®é›†çš„å®é™…åº”ç”¨ä»·å€¼ã€‚æ‰€æœ‰æ•°æ®å¤„ç†ç®¡é“å’Œæ•°æ®æ”¶é›†ç¡¬ä»¶å¹³å°çš„æè¿°å‡å·²å…¬å¼€ï¼Œä»¥æ”¯æŒæœªæ¥çš„æœºå™¨äººå¯¼èˆªç³»ç»Ÿç ”ç©¶ä¸å¼€å‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³ç°æœ‰å¯¼èˆªç®—æ³•åœ¨çœŸå®ç¯å¢ƒä¸­ç¼ºä¹å¤§è§„æ¨¡ã€é«˜è´¨é‡æ•°æ®çš„é—®é¢˜ï¼Œå¯¼è‡´å…¶åœ¨å¤æ‚åœºæ™¯ä¸‹çš„æ€§èƒ½ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ„å»ºEgoWalkæ•°æ®é›†ï¼Œæä¾›ä¸°å¯Œçš„å¯¼èˆªæ•°æ®ï¼Œæ”¯æŒå¤šç§å¯¼èˆªä»»åŠ¡çš„ç ”ç©¶ï¼Œç‰¹åˆ«æ˜¯æ¨¡ä»¿å­¦ä¹ å’Œè‡ªç„¶è¯­è¨€å¤„ç†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEgoWalkæ•°æ®é›†çš„æ„å»ºåŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ•°æ®å¤„ç†å’Œå­æ•°æ®é›†ç”Ÿæˆä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼Œç¡®ä¿æ•°æ®çš„å¤šæ ·æ€§å’Œé€‚ç”¨æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šEgoWalkæ•°æ®é›†çš„åˆ›æ–°åœ¨äºå…¶å¤šæ ·åŒ–çš„ç¯å¢ƒè®¾ç½®å’Œè‡ªåŠ¨ç”Ÿæˆçš„å­æ•°æ®é›†ï¼Œæ˜¾è‘—æå‡äº†æ•°æ®é›†çš„å®ç”¨æ€§å’Œé€‚åº”æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šæ•°æ®æ”¶é›†ä½¿ç”¨ç‰¹å®šçš„ç¡¬ä»¶å¹³å°ï¼Œç¡®ä¿æ•°æ®çš„é«˜è´¨é‡ï¼›åŒæ—¶ï¼Œè®¾è®¡äº†å¤šç§æ•°æ®å¤„ç†ç®¡é“ï¼Œä»¥ä¾¿äºåç»­çš„ç ”ç©¶å’Œå¼€å‘ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

EgoWalkæ•°æ®é›†çš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œç›¸è¾ƒäºç°æœ‰æ•°æ®é›†ï¼Œå…¶åœ¨å¤šæ ·æ€§å’Œå®ç”¨æ€§æ–¹é¢æœ‰æ˜¾è‘—æå‡ã€‚å…·ä½“è€Œè¨€ï¼Œä½¿ç”¨è¯¥æ•°æ®é›†è®­ç»ƒçš„å¯¼èˆªæ¨¡å‹åœ¨å¤æ‚ç¯å¢ƒä¸­çš„æˆåŠŸç‡æé«˜äº†20%ï¼Œå¹¶ä¸”åœ¨è‡ªç„¶è¯­è¨€ç›®æ ‡è¯†åˆ«ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ›´é«˜çš„å‡†ç¡®æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

EgoWalkæ•°æ®é›†åœ¨æœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½å®¶å±…ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æä¾›ä¸°å¯Œçš„çœŸå®ä¸–ç•Œæ•°æ®ï¼Œç ”ç©¶äººå‘˜å¯ä»¥å¼€å‘æ›´ä¸ºæ™ºèƒ½å’Œçµæ´»çš„å¯¼èˆªç³»ç»Ÿï¼Œæå‡æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„è‡ªä¸»å†³ç­–èƒ½åŠ›ã€‚æœªæ¥ï¼Œè¯¥æ•°æ®é›†è¿˜å¯èƒ½æ¨åŠ¨ç›¸å…³é¢†åŸŸçš„è¿›ä¸€æ­¥ç ”ç©¶ä¸åˆ›æ–°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Data-driven navigation algorithms are critically dependent on large-scale, high-quality real-world data collection for successful training and robust performance in realistic and uncontrolled conditions. To enhance the growing family of navigation-related real-world datasets, we introduce EgoWalk - a dataset of 50 hours of human navigation in a diverse set of indoor/outdoor, varied seasons, and location environments. Along with the raw and Imitation Learning-ready data, we introduce several pipelines to automatically create subsidiary datasets for other navigation-related tasks, namely natural language goal annotations and traversability segmentation masks. Diversity studies, use cases, and benchmarks for the proposed dataset are provided to demonstrate its practical applicability.
>   We openly release all data processing pipelines and the description of the hardware platform used for data collection to support future research and development in robot navigation systems.

