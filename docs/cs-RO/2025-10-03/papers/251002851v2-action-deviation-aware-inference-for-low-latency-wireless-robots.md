---
layout: default
title: Action Deviation-Aware Inference for Low-Latency Wireless Robots
---

# Action Deviation-Aware Inference for Low-Latency Wireless Robots

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.02851" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.02851v2</a>
  <a href="https://arxiv.org/pdf/2510.02851.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.02851v2" onclick="toggleFavorite(this, '2510.02851v2', 'Action Deviation-Aware Inference for Low-Latency Wireless Robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jeyoung Park, Yeonsub Lim, Seungeun Oh, Jihong Park, Jinho Choi, Seong-Lyun Kim

**åˆ†ç±»**: cs.RO, cs.DC

**å‘å¸ƒæ—¥æœŸ**: 2025-10-03 (æ›´æ–°: 2025-11-06)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºADAHIï¼Œé€šè¿‡åŠ¨ä½œåå·®æ„ŸçŸ¥æ¨ç†é™ä½æ— çº¿æœºå™¨äººä½å»¶è¿Ÿéœ€æ±‚ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ— çº¿æœºå™¨äºº` `ä½å»¶è¿Ÿæ¨ç†` `æ¨æµ‹è§£ç ` `åŠ¨ä½œåå·®` `åˆ†å¸ƒå¼æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ¨¡ä»¿å­¦ä¹ ç­–ç•¥åœ¨æ— çº¿æœºå™¨äººååŒæ¨ç†ä¸­ï¼Œæ— æ³•æœ‰æ•ˆå¹¶è¡ŒéªŒè¯å’Œçº æ­£åŠ¨ä½œè‰æ¡ˆï¼Œå¯¼è‡´å»¶è¿Ÿè¾ƒé«˜ã€‚
2. ADAHIé€šè¿‡åŠ¨ä½œåå·®æ„ŸçŸ¥ï¼Œé€‰æ‹©æ€§ä¼ è¾“å’ŒéªŒè¯è‰æ¡ˆï¼Œé™ä½äº†ä¸å¿…è¦çš„é€šä¿¡å’Œè®¡ç®—å¼€é”€ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒADAHIæ˜¾è‘—é™ä½äº†ç«¯åˆ°ç«¯å»¶è¿Ÿï¼ŒåŒæ—¶ä¿æŒäº†è¾ƒé«˜çš„ä»»åŠ¡æˆåŠŸç‡ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸ºäº†æ”¯æŒä»è‡ªåŠ¨é©¾é©¶åˆ°å·¥ä¸šæœºå™¨äººæ“ä½œç­‰å¯¹å»¶è¿Ÿæ•æ„Ÿçš„AIåº”ç”¨ï¼Œ6Gè®¾æƒ³äº†åˆ†å¸ƒå¼æœºå™¨å­¦ä¹ ï¼Œå…¶ä¸­è®¡ç®—èµ„æºåˆ†å¸ƒåœ¨ç§»åŠ¨è®¾å¤‡ã€è¾¹ç¼˜å’Œäº‘ç«¯ï¼Œå¹¶é€šè¿‡è¶…å¯é ä½å»¶è¿Ÿé€šä¿¡ï¼ˆHRLLCï¼‰è¿æ¥ã€‚åœ¨è¿™ç§è®¾ç½®ä¸‹ï¼Œæ¨æµ‹è§£ç å¯ä»¥ä¿ƒè¿›åˆ†å¸ƒå¼éƒ¨ç½²æ¨¡å‹çš„ååŒæ¨ç†ï¼šè½»é‡çº§çš„è®¾å¤‡ç«¯æ¨¡å‹åœ¨æœ¬åœ°ç”Ÿæˆè‰æ¡ˆï¼Œè€ŒåŠŸèƒ½æ›´å¼ºå¤§çš„è¿œç¨‹æœåŠ¡å™¨ç«¯ç›®æ ‡æ¨¡å‹éªŒè¯å’Œçº æ­£è¿™äº›è‰æ¡ˆï¼Œä¸æ¨æµ‹é‡‡æ ·å¹¶è¡Œï¼Œä»è€Œåœ¨ä¸å½±å“å‡†ç¡®æ€§çš„å‰æä¸‹é™ä½å»¶è¿Ÿã€‚ç„¶è€Œï¼Œä¸è‡ªå›å½’æ–‡æœ¬ç”Ÿæˆä¸åŒï¼Œé€šå¸¸ç”¨äºå…·èº«AIåº”ç”¨çš„æ¨¡ä»¿å­¦ä¹ ç­–ç•¥æ— æ³•å¹¶è¡ŒéªŒè¯å’Œçº æ­£å¤šä¸ªè‰æ¡ˆï¼Œå› ä¸ºæ¯ä¸ªç”Ÿæˆçš„åŠ¨ä½œéƒ½ä¾èµ–äºå…ˆå‰åŠ¨ä½œæ›´æ–°çš„è§‚å¯Ÿã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†åŠ¨ä½œåå·®æ„ŸçŸ¥æ··åˆæ¨ç†ï¼ˆADAHIï¼‰ï¼Œå…¶ä¸­è‰æ¡ˆåŸºäºåŠ¨ä½œåå·®è¿›è¡Œé€‰æ‹©æ€§ä¼ è¾“å’ŒéªŒè¯ï¼ŒåŠ¨ä½œåå·®ä¸ç›®æ ‡æ¨¡å‹æ‹’ç»åŠ¨ä½œçš„æ¦‚ç‡å¯†åˆ‡ç›¸å…³ã€‚é€šè¿‡ä»…åœ¨å¿…è¦æ—¶è°ƒç”¨æœåŠ¡å™¨æ“ä½œï¼Œå¯ä»¥å‡å°‘é€šä¿¡å’Œè®¡ç®—å¼€é”€ï¼ŒåŒæ—¶ä¿ç•™æ¨æµ‹é‡‡æ ·å¸¦æ¥çš„å‡†ç¡®æ€§å¢ç›Šã€‚åœ¨æˆ‘ä»¬æµ‹è¯•å¹³å°ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒADAHIå‡å°‘äº†çº¦40%çš„ä¼ è¾“å’ŒæœåŠ¡å™¨æ“ä½œï¼Œé™ä½äº†39.2%çš„ç«¯åˆ°ç«¯å»¶è¿Ÿï¼Œå¹¶å®ç°äº†é«˜è¾¾97.2%çš„ä»»åŠ¡æˆåŠŸç‡ï¼Œè¯¥åŸºçº¿å¯¹æ¯ä¸ªè‰æ¡ˆåµŒå…¥å‘é‡è°ƒç”¨æ¨æµ‹é‡‡æ ·ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æ— çº¿æœºå™¨äººåº”ç”¨ä¸­ï¼Œç”±äºé€šä¿¡å»¶è¿Ÿå’Œè®¡ç®—èµ„æºé™åˆ¶ï¼Œéš¾ä»¥å®ç°ä½å»¶è¿Ÿã€é«˜ç²¾åº¦çš„è¡Œä¸ºå…‹éš†ç­–ç•¥æ¨ç†çš„é—®é¢˜ã€‚ä¼ ç»Ÿçš„æ¨æµ‹è§£ç æ–¹æ³•åœ¨å¤„ç†å…·èº«æ™ºèƒ½ä»»åŠ¡æ—¶ï¼Œç”±äºåŠ¨ä½œä¹‹é—´çš„ä¾èµ–æ€§ï¼Œæ— æ³•æœ‰æ•ˆå¹¶è¡ŒéªŒè¯å’Œçº æ­£å¤šä¸ªåŠ¨ä½œè‰æ¡ˆï¼Œå¯¼è‡´å»¶è¿Ÿå¢åŠ ã€‚ç°æœ‰æ–¹æ³•æ²¡æœ‰å……åˆ†åˆ©ç”¨åŠ¨ä½œä¹‹é—´çš„ç›¸å…³æ€§ï¼Œå¯¼è‡´ä¸å¿…è¦çš„é€šä¿¡å’Œè®¡ç®—å¼€é”€ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨åŠ¨ä½œåå·®ï¼ˆAction Deviationï¼‰ä½œä¸ºæŒ‡æ ‡ï¼Œæ¥åˆ¤æ–­è®¾å¤‡ç«¯ç”Ÿæˆçš„åŠ¨ä½œè‰æ¡ˆæ˜¯å¦éœ€è¦æœåŠ¡å™¨ç«¯çš„éªŒè¯å’Œçº æ­£ã€‚åŠ¨ä½œåå·®è¶Šå¤§ï¼Œè¯´æ˜è®¾å¤‡ç«¯ç”Ÿæˆçš„åŠ¨ä½œä¸ç›®æ ‡åŠ¨ä½œçš„å·®å¼‚è¶Šå¤§ï¼Œè¢«æœåŠ¡å™¨ç«¯æ‹’ç»çš„å¯èƒ½æ€§è¶Šé«˜ï¼Œå› æ­¤éœ€è¦è¿›è¡ŒéªŒè¯ã€‚é€šè¿‡è¿™ç§é€‰æ‹©æ€§çš„éªŒè¯æœºåˆ¶ï¼Œå¯ä»¥å‡å°‘ä¸å¿…è¦çš„é€šä¿¡å’Œè®¡ç®—å¼€é”€ï¼Œä»è€Œé™ä½æ•´ä½“å»¶è¿Ÿã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šADAHIåŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) è®¾å¤‡ç«¯è½»é‡çº§æ¨¡å‹ï¼šè´Ÿè´£ç”ŸæˆåŠ¨ä½œè‰æ¡ˆã€‚2) åŠ¨ä½œåå·®è®¡ç®—æ¨¡å—ï¼šè®¡ç®—è®¾å¤‡ç«¯ç”Ÿæˆçš„åŠ¨ä½œä¸å†å²åŠ¨ä½œä¹‹é—´çš„åå·®ã€‚3) ä¼ è¾“å†³ç­–æ¨¡å—ï¼šæ ¹æ®åŠ¨ä½œåå·®å†³å®šæ˜¯å¦å°†åŠ¨ä½œè‰æ¡ˆä¼ è¾“åˆ°æœåŠ¡å™¨ç«¯ã€‚4) æœåŠ¡å™¨ç«¯ç›®æ ‡æ¨¡å‹ï¼šè´Ÿè´£éªŒè¯å’Œçº æ­£è®¾å¤‡ç«¯ç”Ÿæˆçš„åŠ¨ä½œè‰æ¡ˆã€‚5) åŠ¨ä½œæ‰§è¡Œæ¨¡å—ï¼šæ‰§è¡Œæœ€ç»ˆçš„åŠ¨ä½œã€‚æ•´ä½“æµç¨‹æ˜¯ï¼šè®¾å¤‡ç«¯ç”ŸæˆåŠ¨ä½œè‰æ¡ˆ -> è®¡ç®—åŠ¨ä½œåå·® -> æ ¹æ®åå·®å†³å®šæ˜¯å¦ä¼ è¾“ -> æœåŠ¡å™¨ç«¯éªŒè¯å’Œçº æ­£ï¼ˆå¦‚æœä¼ è¾“ï¼‰ -> æ‰§è¡Œæœ€ç»ˆåŠ¨ä½œã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹æ˜¯æå‡ºäº†åŠ¨ä½œåå·®æ„ŸçŸ¥çš„æ¨ç†æœºåˆ¶ã€‚ä¸ä¼ ç»Ÿçš„æ¨æµ‹è§£ç æ–¹æ³•ä¸åŒï¼ŒADAHIä¸æ˜¯å¯¹æ‰€æœ‰åŠ¨ä½œè‰æ¡ˆéƒ½è¿›è¡ŒéªŒè¯ï¼Œè€Œæ˜¯æ ¹æ®åŠ¨ä½œåå·®è¿›è¡Œé€‰æ‹©æ€§éªŒè¯ã€‚è¿™ç§æ–¹æ³•å……åˆ†åˆ©ç”¨äº†åŠ¨ä½œä¹‹é—´çš„ç›¸å…³æ€§ï¼Œå‡å°‘äº†ä¸å¿…è¦çš„é€šä¿¡å’Œè®¡ç®—å¼€é”€ã€‚

**å…³é”®è®¾è®¡**ï¼šåŠ¨ä½œåå·®çš„è®¡ç®—æ–¹å¼æ˜¯å…³é”®è®¾è®¡ä¹‹ä¸€ã€‚è®ºæ–‡ä¸­å¯èƒ½é‡‡ç”¨äº†æŸç§è·ç¦»åº¦é‡æˆ–ç›¸ä¼¼åº¦è®¡ç®—æ–¹æ³•æ¥è¡¡é‡åŠ¨ä½œä¹‹é—´çš„åå·®ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç»†èŠ‚æœªçŸ¥ï¼Œä½†å¯ä»¥æ¨æµ‹è®¾å¤‡ç«¯æ¨¡å‹æ˜¯ä¸€ä¸ªè½»é‡çº§çš„ç¥ç»ç½‘ç»œï¼ŒæœåŠ¡å™¨ç«¯æ¨¡å‹æ˜¯ä¸€ä¸ªæ›´å¤æ‚çš„ç¥ç»ç½‘ç»œã€‚ä¼ è¾“å†³ç­–æ¨¡å—å¯èƒ½ä½¿ç”¨ä¸€ä¸ªé˜ˆå€¼æ¥åˆ¤æ–­åŠ¨ä½œåå·®æ˜¯å¦è¶³å¤Ÿå¤§ï¼Œéœ€è¦è¿›è¡ŒæœåŠ¡å™¨ç«¯éªŒè¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒADAHIç›¸æ¯”äºå¯¹æ¯ä¸ªè‰æ¡ˆåµŒå…¥å‘é‡éƒ½è¿›è¡Œæ¨æµ‹é‡‡æ ·çš„åŸºçº¿æ–¹æ³•ï¼Œå‡å°‘äº†çº¦40%çš„ä¼ è¾“å’ŒæœåŠ¡å™¨æ“ä½œï¼Œé™ä½äº†39.2%çš„ç«¯åˆ°ç«¯å»¶è¿Ÿï¼Œå¹¶å®ç°äº†é«˜è¾¾97.2%çš„ä»»åŠ¡æˆåŠŸç‡ã€‚è¿™äº›æ•°æ®è¡¨æ˜ï¼ŒADAHIåœ¨é™ä½å»¶è¿Ÿçš„åŒæ—¶ï¼Œèƒ½å¤Ÿä¿æŒè¾ƒé«˜çš„ä»»åŠ¡æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§å¯¹å»¶è¿Ÿæ•æ„Ÿçš„æ— çº¿æœºå™¨äººåº”ç”¨ï¼Œä¾‹å¦‚ï¼šè‡ªåŠ¨é©¾é©¶ã€å·¥ä¸šæœºå™¨äººæ“ä½œã€è¿œç¨‹åŒ»ç–—æ‰‹æœ¯ç­‰ã€‚é€šè¿‡é™ä½æ¨ç†å»¶è¿Ÿï¼Œå¯ä»¥æé«˜æœºå™¨äººçš„å“åº”é€Ÿåº¦å’Œæ“ä½œç²¾åº¦ï¼Œä»è€Œæå‡ç”¨æˆ·ä½“éªŒå’Œå·¥ä½œæ•ˆç‡ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›æ¨åŠ¨æ— çº¿æœºå™¨äººæŠ€æœ¯åœ¨æ›´å¤šé¢†åŸŸçš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> To support latency-sensitive AI applications ranging from autonomous driving to industrial robot manipulation, 6G envisions distributed ML with computational resources in mobile, edge, and cloud connected over hyper-reliable low-latency communication (HRLLC). In this setting, speculative decoding can facilitate collaborative inference of models distributively deployed: a lightweight on-device model locally generates drafts while a more capable remote target model on a server verifies and corrects them in parallel with speculative sampling, thus resulting in lower latency without compromising accuracy. However, unlike autoregressive text generation, behavior cloning policies, typically used for embodied AI applications, cannot parallelize verification and correction for multiple drafts as each generated action depends on observation updated by a previous action. To this end, we propose Action Deviation-Aware Hybrid Inference (ADAHI), wherein drafts are selectively transmitted and verified based on action deviation, which has a strong correlation with action's rejection probability by the target model. By invoking server operation only when necessary, communication and computational overhead can be reduced while accuracy gain from speculative sampling is preserved. Experiments on our testbed show that ADAHI reduces transmission and server operations by approximately 40%, lowers end-to-end latency by 39.2%, and attains up to 97.2% of the task-success rate of baseline that invokes speculative sampling for every draft embedding vector.

