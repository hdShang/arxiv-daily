---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-05-15
---

# cs.ROï¼ˆ2025-05-15ï¼‰

ğŸ“Š å…± **18** ç¯‡è®ºæ–‡
 | ğŸ”— **3** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (17 ğŸ”—3)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (17 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250510022v3-apex-action-priors-enable-efficient-exploration-for-robust-motion-tr.html">APEX: Action Priors Enable Efficient Exploration for Robust Motion Tracking on Legged Robots</a></td>
  <td>æå‡ºAPEXä»¥è§£å†³è…¿éƒ¨æœºå™¨äººè¿åŠ¨è·Ÿè¸ªä¸­çš„æ•°æ®ä¾èµ–é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">legged robot</span> <span class="paper-tag">locomotion</span> <span class="paper-tag">manipulation</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.10022v3" data-paper-url="./papers/250510022v3-apex-action-priors-enable-efficient-exploration-for-robust-motion-tr.html" onclick="toggleFavorite(this, '2505.10022v3', 'APEX: Action Priors Enable Efficient Exploration for Robust Motion Tracking on Legged Robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250510251v3-srt-h-a-hierarchical-framework-for-autonomous-surgery-via-language-c.html">SRT-H: A Hierarchical Framework for Autonomous Surgery via Language Conditioned Imitation Learning</a></td>
  <td>æå‡ºå±‚æ¬¡åŒ–æ¡†æ¶ä»¥è§£å†³è‡ªä¸»å¤–ç§‘æ‰‹æœ¯ä¸­çš„çµå·§æ“ä½œé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">dexterous manipulation</span> <span class="paper-tag">imitation learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.10251v3" data-paper-url="./papers/250510251v3-srt-h-a-hierarchical-framework-for-autonomous-surgery-via-language-c.html" onclick="toggleFavorite(this, '2505.10251v3', 'SRT-H: A Hierarchical Framework for Autonomous Surgery via Language Conditioned Imitation Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250510075v1-flowdreamer-a-rgb-d-world-model-with-flow-based-motion-representatio.html">FlowDreamer: A RGB-D World Model with Flow-based Motion Representations for Robot Manipulation</a></td>
  <td>æå‡ºFlowDreamerä»¥è§£å†³æœºå™¨äººæ“æ§ä¸­çš„è§†è§‰ä¸–ç•Œå»ºæ¨¡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">world model</span> <span class="paper-tag">dreamer</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.10075v1" data-paper-url="./papers/250510075v1-flowdreamer-a-rgb-d-world-model-with-flow-based-motion-representatio.html" onclick="toggleFavorite(this, '2505.10075v1', 'FlowDreamer: A RGB-D World Model with Flow-based Motion Representations for Robot Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250510359v1-nvspolicy-adaptive-novel-view-synthesis-for-generalizable-language-c.html">NVSPolicy: Adaptive Novel-View Synthesis for Generalizable Language-Conditioned Policy Learning</a></td>
  <td>æå‡ºNVSPolicyä»¥è§£å†³æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„æ”¿ç­–å­¦ä¹ é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">policy learning</span> <span class="paper-tag">language conditioned</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.10359v1" data-paper-url="./papers/250510359v1-nvspolicy-adaptive-novel-view-synthesis-for-generalizable-language-c.html" onclick="toggleFavorite(this, '2505.10359v1', 'NVSPolicy: Adaptive Novel-View Synthesis for Generalizable Language-Conditioned Policy Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250510105v1-embodiedmae-a-unified-3d-multi-modal-representation-for-robot-manipu.html">EmbodiedMAE: A Unified 3D Multi-Modal Representation for Robot Manipulation</a></td>
  <td>æå‡ºEmbodiedMAEä»¥è§£å†³æœºå™¨äººæ“ä½œä¸­çš„å¤šæ¨¡æ€è¡¨ç¤ºé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">policy learning</span> <span class="paper-tag">masked autoencoder</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.10105v1" data-paper-url="./papers/250510105v1-embodiedmae-a-unified-3d-multi-modal-representation-for-robot-manipu.html" onclick="toggleFavorite(this, '2505.10105v1', 'EmbodiedMAE: A Unified 3D Multi-Modal Representation for Robot Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250510033v2-evaluating-robustness-of-deep-reinforcement-learning-for-autonomous-.html">Evaluating Robustness of Deep Reinforcement Learning for Autonomous Surface Vehicle Control in Field Tests</a></td>
  <td>è¯„ä¼°æ·±åº¦å¼ºåŒ–å­¦ä¹ åœ¨è‡ªä¸»æ°´é¢è½¦è¾†æ§åˆ¶ä¸­çš„é²æ£’æ€§</td>
  <td class="tags-cell"><span class="paper-tag">domain randomization</span> <span class="paper-tag">MPC</span> <span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.10033v2" data-paper-url="./papers/250510033v2-evaluating-robustness-of-deep-reinforcement-learning-for-autonomous-.html" onclick="toggleFavorite(this, '2505.10033v2', 'Evaluating Robustness of Deep Reinforcement Learning for Autonomous Surface Vehicle Control in Field Tests')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250510219v1-towards-safe-robot-foundation-models-using-inductive-biases.html">Towards Safe Robot Foundation Models Using Inductive Biases</a></td>
  <td>æå‡ºATACOMä»¥è§£å†³æœºå™¨äººåŸºç¡€æ¨¡å‹çš„å®‰å…¨æ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">behavior cloning</span> <span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.10219v1" data-paper-url="./papers/250510219v1-towards-safe-robot-foundation-models-using-inductive-biases.html" onclick="toggleFavorite(this, '2505.10219v1', 'Towards Safe Robot Foundation Models Using Inductive Biases')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250510522v1-knowledge-capture-adaptation-and-composition-kcac-a-framework-for-cr.html">Knowledge capture, adaptation and composition (KCAC): A framework for cross-task curriculum learning in robotic manipulation</a></td>
  <td>æå‡ºKCACæ¡†æ¶ä»¥è§£å†³æœºå™¨äººæ“ä½œä¸­çš„çŸ¥è¯†è½¬ç§»é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">reinforcement learning</span> <span class="paper-tag">curriculum learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.10522v1" data-paper-url="./papers/250510522v1-knowledge-capture-adaptation-and-composition-kcac-a-framework-for-cr.html" onclick="toggleFavorite(this, '2505.10522v1', 'Knowledge capture, adaptation and composition (KCAC): A framework for cross-task curriculum learning in robotic manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250510442v1-in-ril-interleaved-reinforcement-and-imitation-learning-for-policy-f.html">IN-RIL: Interleaved Reinforcement and Imitation Learning for Policy Fine-Tuning</a></td>
  <td>æå‡ºIN-RILä»¥è§£å†³å¼ºåŒ–å­¦ä¹ å¾®è°ƒä¸­çš„ä¸ç¨³å®šæ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">locomotion</span> <span class="paper-tag">manipulation</span> <span class="paper-tag">reinforcement learning</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.10442v1" data-paper-url="./papers/250510442v1-in-ril-interleaved-reinforcement-and-imitation-learning-for-policy-f.html" onclick="toggleFavorite(this, '2505.10442v1', 'IN-RIL: Interleaved Reinforcement and Imitation Learning for Policy Fine-Tuning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250510355v1-pc-dbcbs-kinodynamic-motion-planning-of-physically-coupled-robot-tea.html">pc-dbCBS: Kinodynamic Motion Planning of Physically-Coupled Robot Teams</a></td>
  <td>æå‡ºpc-dbCBSä»¥è§£å†³ç‰©ç†è€¦åˆæœºå™¨äººå›¢é˜Ÿçš„è¿åŠ¨è§„åˆ’é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">trajectory optimization</span> <span class="paper-tag">motion planning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.10355v1" data-paper-url="./papers/250510355v1-pc-dbcbs-kinodynamic-motion-planning-of-physically-coupled-robot-tea.html" onclick="toggleFavorite(this, '2505.10355v1', 'pc-dbCBS: Kinodynamic Motion Planning of Physically-Coupled Robot Teams')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250509979v1-learning-diverse-natural-behaviors-for-enhancing-the-agility-of-quad.html">Learning Diverse Natural Behaviors for Enhancing the Agility of Quadrupedal Robots</a></td>
  <td>æå‡ºé›†æˆæ§åˆ¶å™¨ä»¥è§£å†³å››è¶³æœºå™¨äººçµæ´»æ€§ä¸è¶³é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">quadruped</span> <span class="paper-tag">imitation learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.09979v1" data-paper-url="./papers/250509979v1-learning-diverse-natural-behaviors-for-enhancing-the-agility-of-quad.html" onclick="toggleFavorite(this, '2505.09979v1', 'Learning Diverse Natural Behaviors for Enhancing the Agility of Quadrupedal Robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250510755v3-procedural-generation-of-articulated-simulation-ready-assets.html">Procedural Generation of Articulated Simulation-Ready Assets</a></td>
  <td>æå‡ºInfinigen-Articulatedå·¥å…·åŒ…ä»¥ç”Ÿæˆæœºå™¨äººä»¿çœŸæ‰€éœ€çš„å…³èŠ‚èµ„äº§</td>
  <td class="tags-cell"><span class="paper-tag">sim-to-real</span> <span class="paper-tag">reinforcement learning</span> <span class="paper-tag">imitation learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.10755v3" data-paper-url="./papers/250510755v3-procedural-generation-of-articulated-simulation-ready-assets.html" onclick="toggleFavorite(this, '2505.10755v3', 'Procedural Generation of Articulated Simulation-Ready Assets')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/250510547v2-real-time-out-of-distribution-failure-prevention-via-multi-modal-rea.html">Real-Time Out-of-Distribution Failure Prevention via Multi-Modal Reasoning</a></td>
  <td>æå‡ºFORTRESSæ¡†æ¶ä»¥è§£å†³æœºå™¨äººåœ¨OODåœºæ™¯ä¸­çš„å®‰å…¨é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">ANYmal</span> <span class="paper-tag">foundation model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.10547v2" data-paper-url="./papers/250510547v2-real-time-out-of-distribution-failure-prevention-via-multi-modal-rea.html" onclick="toggleFavorite(this, '2505.10547v2', 'Real-Time Out-of-Distribution Failure Prevention via Multi-Modal Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/250510696v2-tartanground-a-large-scale-dataset-for-ground-robot-perception-and-n.html">TartanGround: A Large-Scale Dataset for Ground Robot Perception and Navigation</a></td>
  <td>æå‡ºTartanGroundæ•°æ®é›†ä»¥æå‡åœ°é¢æœºå™¨äººæ„ŸçŸ¥ä¸å¯¼èˆªèƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">legged robot</span> <span class="paper-tag">optical flow</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.10696v2" data-paper-url="./papers/250510696v2-tartanground-a-large-scale-dataset-for-ground-robot-perception-and-n.html" onclick="toggleFavorite(this, '2505.10696v2', 'TartanGround: A Large-Scale Dataset for Ground Robot Perception and Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/250510552v2-loop-closure-grasping-topological-transformations-enable-strong-gent.html">Loop closure grasping: Topological transformations enable strong, gentle, and versatile grasps</a></td>
  <td>æå‡ºç¯é—­åˆæŠ“å–ä»¥è§£å†³å¼ºåº¦ã€æ¸©å’Œæ€§ä¸å¤šåŠŸèƒ½æ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.10552v2" data-paper-url="./papers/250510552v2-loop-closure-grasping-topological-transformations-enable-strong-gent.html" onclick="toggleFavorite(this, '2505.10552v2', 'Loop closure grasping: Topological transformations enable strong, gentle, and versatile grasps')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/250510542v4-aorrtc-almost-surely-asymptotically-optimal-planning-with-rrt-connec.html">AORRTC: Almost-Surely Asymptotically Optimal Planning with RRT-Connect</a></td>
  <td>æå‡ºAORRTCä»¥è§£å†³é«˜è‡ªç”±åº¦æœºå™¨äººè¿åŠ¨è§„åˆ’é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">motion planning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.10542v4" data-paper-url="./papers/250510542v4-aorrtc-almost-surely-asymptotically-optimal-planning-with-rrt-connec.html" onclick="toggleFavorite(this, '2505.10542v4', 'AORRTC: Almost-Surely Asymptotically Optimal Planning with RRT-Connect')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/250510239v1-context-aware-collaborative-pushing-of-heavy-objects-using-skeleton-.html">Context-aware collaborative pushing of heavy objects using skeleton-based intention prediction</a></td>
  <td>æå‡ºåŸºäºéª¨æ¶çš„æ„å›¾é¢„æµ‹æ–¹æ³•ä»¥è§£å†³é‡ç‰©åä½œæ¨æ‹‰é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.10239v1" data-paper-url="./papers/250510239v1-context-aware-collaborative-pushing-of-heavy-objects-using-skeleton-.html" onclick="toggleFavorite(this, '2505.10239v1', 'Context-aware collaborative pushing of heavy objects using skeleton-based intention prediction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>18</td>
  <td><a href="./papers/250513497v3-learning-hierarchical-domain-models-through-environment-grounded-int.html">Learning Hierarchical Domain Models Through Environment-Grounded Interaction</a></td>
  <td>æå‡ºLODGEæ¡†æ¶ä»¥è§£å†³å¼€æ”¾ä¸–ç•Œä»»åŠ¡å»ºæ¨¡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13497v3" data-paper-url="./papers/250513497v3-learning-hierarchical-domain-models-through-environment-grounded-int.html" onclick="toggleFavorite(this, '2505.13497v3', 'Learning Hierarchical Domain Models Through Environment-Grounded Interaction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)