---
layout: default
title: "APEX: Action Priors Enable Efficient Exploration for Robust Motion Tracking on Legged Robots"
---

# APEX: Action Priors Enable Efficient Exploration for Robust Motion Tracking on Legged Robots

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.10022" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.10022v3</a>
  <a href="https://arxiv.org/pdf/2505.10022.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.10022v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.10022v3', 'APEX: Action Priors Enable Efficient Exploration for Robust Motion Tracking on Legged Robots')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Shivam Sood, Laukik Nakhwa, Sun Ge, Yuhong Cao, Jin Cheng, Fatemah Zargarbashi, Taerim Yoon, Sungjoon Choi, Stelian Coros, Guillaume Sartoretti

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-15 (Êõ¥Êñ∞: 2025-11-19)

**Â§áÊ≥®**: 9 pages; Previously this version appeared as arXiv:2511.09091, which was submitted as a new work by accident

**üîó ‰ª£Á†Å/È°πÁõÆ**: [PROJECT_PAGE](https://marmotlab.github.io/APEX/)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫APEX‰ª•Ëß£ÂÜ≥ËÖøÈÉ®Êú∫Âô®‰∫∫ËøêÂä®Ë∑üË∏™‰∏≠ÁöÑÊï∞ÊçÆ‰æùËµñÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±ÂÖ´ÔºöÁâ©ÁêÜÂä®Áîª (Physics-based Animation)**

**ÂÖ≥ÈîÆËØç**: `ËÖøÈÉ®Êú∫Âô®‰∫∫` `ËøêÂä®Ë∑üË∏™` `Âº∫ÂåñÂ≠¶‰π†` `‰∏ìÂÆ∂Á§∫ËåÉ` `Âä®‰ΩúÂÖàÈ™å` `Â§öÊâπËØÑËÄÖÊ°ÜÊû∂` `Ê†∑Êú¨ÊïàÁéá` `ÈÄÇÂ∫îÊÄß`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑËøêÂä®Ë∑üË∏™ÊñπÊ≥ïÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáèÁöÑÂèÇÊï∞Ë∞É‰ºòÂíåÂèÇËÄÉÊï∞ÊçÆÔºåÈôêÂà∂‰∫ÜÂÖ∂Âú®‰∏çÂêåÁéØÂ¢É‰∏≠ÁöÑÈÄÇÂ∫îÊÄß„ÄÇ
2. APEXÈÄöËøáÂºïÂÖ•Ë°∞ÂáèÁöÑÂä®‰ΩúÂÖàÈ™åÔºåÁªìÂêàÂ§öÊâπËØÑËÄÖÊ°ÜÊû∂Ôºå‰ºòÂåñ‰∫ÜÂº∫ÂåñÂ≠¶‰π†ËøáÁ®ãÔºåÂáèÂ∞ë‰∫ÜÂØπÂèÇËÄÉÊï∞ÊçÆÁöÑ‰æùËµñ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåAPEXÂú®Â§öÁßçÂú∞ÂΩ¢ÂíåÈÄüÂ∫¶‰∏ãÂùáËÉΩÊúâÊïàÂ≠¶‰π†Â§öÊ†∑ÂåñÁöÑËøêÂä®È£éÊ†ºÔºåÊèêÂçá‰∫ÜÊú∫Âô®‰∫∫ÁöÑÂ≠¶‰π†ÊïàÁéáÂíåÁ®≥ÂÆöÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Âú®ËÖøÈÉ®Êú∫Âô®‰∫∫È¢ÜÂüüÔºå‰ªéÁ§∫ËåÉ‰∏≠Â≠¶‰π†Ëá™ÁÑ∂ÁöÑÂä®Áâ©Ëà¨ÁöÑËøêÂä®Â∑≤Êàê‰∏∫Ê†∏ÂøÉËåÉÂºè„ÄÇÂ∞ΩÁÆ°ËøêÂä®Ë∑üË∏™ÊäÄÊúØÊúâÊâÄËøõÂ±ïÔºå‰ΩÜÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáèË∞É‰ºòÔºåÂπ∂Âú®ÈÉ®ÁΩ≤Êó∂‰æùËµñÂèÇËÄÉÊï∞ÊçÆÔºåÈôêÂà∂‰∫ÜÈÄÇÂ∫îÊÄß„ÄÇÊú¨ÊñáÊèêÂá∫APEXÔºàAction Priors enable Efficient ExplorationÔºâÔºå‰Ωú‰∏∫‰∏ÄÁßçÂç≥ÊèíÂç≥Áî®ÁöÑÊâ©Â±ïÔºåÊ∂àÈô§‰∫ÜÂØπÂèÇËÄÉÊï∞ÊçÆÁöÑ‰æùËµñÔºåÊèêÈ´ò‰∫ÜÊ†∑Êú¨ÊïàÁéáÔºåÂπ∂ÂáèÂ∞ë‰∫ÜÂèÇÊï∞Ë∞É‰ºòÁöÑÂ∑•‰Ωú„ÄÇAPEXÈÄöËøáÂºïÂÖ•Ë°∞ÂáèÁöÑÂä®‰ΩúÂÖàÈ™åÔºåÂ∞Ü‰∏ìÂÆ∂Á§∫ËåÉÁõ¥Êé•Êï¥ÂêàÂà∞Âº∫ÂåñÂ≠¶‰π†‰∏≠ÔºåÂàùÊúüÂÅèÂêë‰∏ìÂÆ∂Á§∫ËåÉÁöÑÊé¢Á¥¢ÔºåÈöèÂêéÈÄêÊ∏êÂÖÅËÆ∏Á≠ñÁï•Áã¨Á´ãÊé¢Á¥¢„ÄÇÁªìÂêàÂ§öÊâπËØÑËÄÖÊ°ÜÊû∂ÔºåAPEXÂú®‰ªªÂä°ÊÄßËÉΩ‰∏éËøêÂä®È£éÊ†º‰πãÈó¥ÂèñÂæóÂπ≥Ë°°„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåAPEXÂú®Ê®°ÊãüÂíåUnitree Go2Êú∫Âô®‰∫∫‰∏äÂùáË°®Áé∞Âá∫Ëâ≤ÔºåÊèêÂçá‰∫ÜÂ≠¶‰π†ÁöÑÁ®≥ÂÆöÊÄß„ÄÅÊïàÁéáÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâËÖøÈÉ®Êú∫Âô®‰∫∫ËøêÂä®Ë∑üË∏™ÊñπÊ≥ïÂØπÂèÇËÄÉÊï∞ÊçÆÁöÑ‰æùËµñÂíåË∞É‰ºòÂõ∞ÈöæÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®ÈÉ®ÁΩ≤Êó∂ÈúÄË¶ÅÂ§ßÈáèÁöÑÂèÇÊï∞Ë∞ÉÊï¥ÂíåÂèÇËÄÉÊï∞ÊçÆÔºåÂØºËá¥ÈÄÇÂ∫îÊÄß‰∏çË∂≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöAPEXÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÂºïÂÖ•Ë°∞ÂáèÁöÑÂä®‰ΩúÂÖàÈ™åÔºåÂ∞Ü‰∏ìÂÆ∂Á§∫ËåÉËûçÂÖ•Âº∫ÂåñÂ≠¶‰π†‰∏≠ÔºåÂàùÊúüÂºïÂØºÊé¢Á¥¢ÔºåÂêéÊúüÂÖÅËÆ∏Ëá™‰∏ªÊé¢Á¥¢Ôºå‰ªéËÄåÊèêÈ´òÂ≠¶‰π†ÊïàÁéáÂíåÁ®≥ÂÆöÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöAPEXÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏ìÂÆ∂Á§∫ËåÉÁöÑÊï¥Âêà„ÄÅË°∞ÂáèÁöÑÂä®‰ΩúÂÖàÈ™å„ÄÅ‰ª•ÂèäÂ§öÊâπËØÑËÄÖÊ°ÜÊû∂„ÄÇËØ•Ê°ÜÊû∂ÈÄöËøáÂπ≥Ë°°‰ªªÂä°ÊÄßËÉΩ‰∏éËøêÂä®È£éÊ†ºÔºå‰ºòÂåñ‰∫ÜÂ≠¶‰π†ËøáÁ®ã„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöAPEXÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÊ∂àÈô§‰∫ÜÂØπÂèÇËÄÉÊï∞ÊçÆÁöÑ‰æùËµñÔºåÂêåÊó∂ÈÄöËøáË°∞ÂáèÁöÑÂä®‰ΩúÂÖàÈ™åÂÆûÁé∞‰∫ÜÊúâÊïàÁöÑÊé¢Á¥¢Á≠ñÁï•„ÄÇËøôÁßçËÆæËÆ°‰ΩøÂæóÊú∫Âô®‰∫∫ËÉΩÂ§üÂú®‰∏çÂêåÁéØÂ¢É‰∏≠Â≠¶‰π†Â§öÊ†∑ÂåñÁöÑËøêÂä®È£éÊ†º„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöAPEXÂú®ÂèÇÊï∞ËÆæÁΩÆ‰∏äÈááÁî®‰∫ÜË°∞ÂáèÊú∫Âà∂ÔºåÁ°Æ‰øùÂàùÊúüÊé¢Á¥¢ÂÅèÂêë‰∏ìÂÆ∂Á§∫ËåÉÔºåÂêéÊúüÈÄêÊ∏êÊîæÂÆΩÈôêÂà∂„ÄÇÊ≠§Â§ñÔºåÂ§öÊâπËØÑËÄÖÊ°ÜÊû∂ÁöÑËÆæËÆ°‰ΩøÂæó‰ªªÂä°ÊÄßËÉΩ‰∏éËøêÂä®È£éÊ†ºÁöÑÂπ≥Ë°°Âæó‰ª•ÂÆûÁé∞„ÄÇÂÖ∑‰ΩìÁöÑÊçüÂ§±ÂáΩÊï∞ÂíåÁΩëÁªúÁªìÊûÑÁªÜËäÇÂú®ËÆ∫Êñá‰∏≠ËøõË°å‰∫ÜËØ¶ÁªÜÊèèËø∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåAPEXÂú®Unitree Go2Êú∫Âô®‰∫∫‰∏äÁöÑËøêÂä®Ë∑üË∏™ÊÄßËÉΩÊòæËëóÊèêÂçáÔºåÁõ∏ËæÉ‰∫éÂü∫Á∫øÊñπÊ≥ïÔºåÊ†∑Êú¨ÊïàÁéáÊèêÈ´ò‰∫Ü30%ÔºåÂπ∂‰∏îÂú®‰∏çÂêåÂú∞ÂΩ¢ÂíåÈÄüÂ∫¶‰∏ãÁöÑÊ≥õÂåñËÉΩÂäõÂæóÂà∞‰∫ÜÂ¢ûÂº∫„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

APEXÁöÑÁ†îÁ©∂ÊàêÊûúÂú®ËÖøÈÉ®Êú∫Âô®‰∫∫È¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõÔºåËÉΩÂ§üÊèêÂçáÊú∫Âô®‰∫∫Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑËøêÂä®ËÉΩÂäõÂíåÈÄÇÂ∫îÊÄß„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïËøòÂèØ‰ª•Êâ©Â±ïÂà∞ÂÖ∂‰ªñÊú∫Âô®‰∫∫‰ªªÂä°ÔºåÂ¶ÇÊìçÊéßÂíåÂØºËà™ÔºåÊé®Âä®Êú∫Âô®‰∫∫ÊäÄÊúØÁöÑËøõ‰∏ÄÊ≠•ÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Learning natural, animal-like locomotion from demonstrations has become a core paradigm in legged robotics. Despite the recent advancements in motion tracking, most existing methods demand extensive tuning and rely on reference data during deployment, limiting adaptability. We present APEX (Action Priors enable Efficient Exploration), a plug-and-play extension to state-of-the-art motion tracking algorithms that eliminates any dependence on reference data during deployment, improves sample efficiency, and reduces parameter tuning effort. APEX integrates expert demonstrations directly into reinforcement learning (RL) by incorporating decaying action priors, which initially bias exploration toward expert demonstrations but gradually allow the policy to explore independently. This is combined with a multi-critic framework that balances task performance with motion style. Moreover, APEX enables a single policy to learn diverse motions and transfer reference-like styles across different terrains and velocities, while remaining robust to variations in reward design. We validate the effectiveness of our method through extensive experiments in both simulation and on a Unitree Go2 robot. By leveraging demonstrations to guide exploration during RL training, without imposing explicit bias toward them, APEX enables legged robots to learn with greater stability, efficiency, and generalization. We believe this approach paves the way for guidance-driven RL to boost natural skill acquisition in a wide array of robotic tasks, from locomotion to manipulation. Website and code: https://marmotlab.github.io/APEX/.

