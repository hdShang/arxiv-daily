---
layout: default
title: Towards Safe Robot Foundation Models Using Inductive Biases
---

# Towards Safe Robot Foundation Models Using Inductive Biases

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.10219" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.10219v1</a>
  <a href="https://arxiv.org/pdf/2505.10219.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.10219v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.10219v1', 'Towards Safe Robot Foundation Models Using Inductive Biases')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Maximilian TÃ¶lle, Theo Gruner, Daniel Palenicek, Tim Schneider, Jonas GÃ¼nster, Joe Watson, Davide Tateo, Puze Liu, Jan Peters

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-05-15

**å¤‡æ³¨**: 14 pages, 5 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºATACOMä»¥è§£å†³æœºå™¨äººåŸºç¡€æ¨¡å‹çš„å®‰å…¨æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æœºå™¨äººå®‰å…¨` `åŸºç¡€æ¨¡å‹` `å‡ ä½•å½’çº³åç½®` `å®‰å…¨å±‚` `åŠ¨æ€ä»»åŠ¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æœºå™¨äººåŸºç¡€æ¨¡å‹åœ¨å®‰å…¨æ€§æ–¹é¢å­˜åœ¨æ˜æ˜¾ä¸è¶³ï¼Œç¼ºä¹å½¢å¼åŒ–çš„å®‰å…¨ä¿è¯ã€‚
2. æœ¬æ–‡æå‡ºATACOMï¼Œé€šè¿‡ç»“åˆå‡ ä½•å½’çº³åç½®ï¼Œç¡®ä¿å®‰å…¨çŠ¶æ€è½¬ç§»å¹¶ç®€åŒ–å®‰å…¨è¡Œä¸ºçš„å­¦ä¹ è¿‡ç¨‹ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ç»å…¸æ“ä½œå’ŒåŠ¨æ€ä»»åŠ¡ä¸­å‡èƒ½æœ‰æ•ˆé¿å…ç¢°æ’ï¼Œå¹¶ç”Ÿæˆç¬¦åˆçº¦æŸçš„è½¨è¿¹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å®‰å…¨æ€§æ˜¯æœºå™¨äººç³»ç»Ÿåœ¨å®é™…éƒ¨ç½²ä¸­çš„å…³é”®è¦æ±‚ã€‚ç›®å‰çš„æœºå™¨äººåŸºç¡€æ¨¡å‹åœ¨å¤šç§ä»»åŠ¡ä¸­å±•ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œä½†æœªèƒ½æœ‰æ•ˆè§£å†³å®‰å…¨æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºä»å¤§é‡æ¼”ç¤ºä¸­å­¦ä¹ å®‰å…¨è¡Œä¸ºï¼Œç„¶è€Œç¼ºä¹å½¢å¼åŒ–çš„å®‰å…¨ä¿è¯ï¼Œå¹¶ä¸”åœ¨æ²¡æœ‰æ˜ç¡®å®‰å…¨çº¦æŸçš„æƒ…å†µä¸‹ï¼Œå¯èƒ½éœ€è¦å¤§é‡é¢å¤–æ¼”ç¤ºæ‰èƒ½æ¥è¿‘æœŸæœ›çš„å—é™è¡Œä¸ºã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ATACOMï¼Œä¸€ä¸ªå®‰å…¨å±‚ï¼Œç»“åˆå‡ ä½•å½’çº³åç½®ï¼Œç¡®ä¿å®‰å…¨çŠ¶æ€è½¬ç§»å¹¶å¼ºåˆ¶æ‰§è¡ŒåŠ¨ä½œçº¦æŸã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç»å…¸æ“ä½œä»»åŠ¡å’ŒåŠ¨æ€ä»»åŠ¡ä¸­å‡è¡¨ç°å‡ºè‰²ï¼Œèƒ½å¤Ÿé¿å…ä¸æ— å…³ç‰©ä½“çš„ç¢°æ’ï¼Œå¹¶ç”Ÿæˆç¬¦åˆå¤æ‚ä»»åŠ¡å’Œå…³èŠ‚ç©ºé—´çº¦æŸçš„å¿«é€Ÿè½¨è¿¹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰æœºå™¨äººåŸºç¡€æ¨¡å‹åœ¨å®‰å…¨æ€§æ–¹é¢çš„ä¸è¶³ï¼Œç‰¹åˆ«æ˜¯ç¼ºä¹å½¢å¼åŒ–å®‰å…¨ä¿è¯å’Œå¯¹å®‰å…¨çº¦æŸçš„æ˜ç¡®çŸ¥è¯†ï¼Œå¯¼è‡´éœ€è¦å¤§é‡é¢å¤–æ¼”ç¤ºä»¥å­¦ä¹ å®‰å…¨è¡Œä¸ºçš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºATACOMï¼Œä¸€ä¸ªå®‰å…¨å±‚ï¼Œé€šè¿‡å‡ ä½•å½’çº³åç½®ä¸åŸºç¡€æ”¿ç­–ç»“åˆï¼Œç¡®ä¿å®‰å…¨çŠ¶æ€è½¬ç§»ï¼Œé¿å…äº†å¯¹å¤§é‡å®‰å…¨è¡Œä¸ºæ¼”ç¤ºçš„ä¾èµ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬åŸºç¡€æ”¿ç­–æ¨¡å—å’ŒATACOMå®‰å…¨å±‚ï¼ŒåŸºç¡€æ”¿ç­–è´Ÿè´£ç”ŸæˆåŠ¨ä½œï¼ŒATACOMåˆ™åœ¨å…¶åç¡®ä¿çŠ¶æ€è½¬ç§»çš„å®‰å…¨æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šATACOMçš„è®¾è®¡ä½¿å¾—æœºå™¨äººèƒ½å¤Ÿåœ¨æ²¡æœ‰å¤§é‡å®‰å…¨æ¼”ç¤ºçš„æƒ…å†µä¸‹ï¼Œä¾ç„¶èƒ½å¤Ÿä¿è¯å®‰å…¨æ€§ï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•ä¾èµ–å¤§é‡æ•°æ®çš„æœ¬è´¨åŒºåˆ«æ˜¾è‘—ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ATACOMä¸­ï¼Œå…³é”®å‚æ•°åŒ…æ‹¬åŠ¨ä½œçº¦æŸçš„å®šä¹‰å’Œå‡ ä½•å½’çº³åç½®çš„å®ç°ï¼Œç¡®ä¿åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­éµå¾ªå®‰å…¨è§„åˆ™ï¼ŒåŒæ—¶ä¸éœ€è¦ç‰¹å®šçš„å®‰å…¨å¾®è°ƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒATACOMåœ¨ç»å…¸æ“ä½œä»»åŠ¡ä¸­æœ‰æ•ˆé¿å…äº†ä¸æ— å…³ç‰©ä½“çš„ç¢°æ’ï¼Œå¹¶åœ¨åŠ¨æ€ä»»åŠ¡ä¸­ç”Ÿæˆäº†ç¬¦åˆå¤æ‚çº¦æŸçš„å¿«é€Ÿè½¨è¿¹ã€‚ä¸åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼Œå®‰å…¨æ€§å’Œæ•ˆç‡å‡æœ‰æ˜¾è‘—æå‡ï¼Œå…·ä½“æ€§èƒ½æ•°æ®æœªæä¾›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å·¥ä¸šæœºå™¨äººã€æœåŠ¡æœºå™¨äººå’Œè‡ªä¸»ç§»åŠ¨ç³»ç»Ÿç­‰ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡è¿™äº›ç³»ç»Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­çš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚æœªæ¥ï¼ŒATACOMçš„è®¾è®¡ç†å¿µå¯èƒ½ä¼šè¢«å¹¿æ³›åº”ç”¨äºå…¶ä»–éœ€è¦å®‰å…¨ä¿éšœçš„æ™ºèƒ½ç³»ç»Ÿä¸­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Safety is a critical requirement for the real-world deployment of robotic systems. Unfortunately, while current robot foundation models show promising generalization capabilities across a wide variety of tasks, they fail to address safety, an important aspect for ensuring long-term operation. Current robot foundation models assume that safe behavior should emerge by learning from a sufficiently large dataset of demonstrations. However, this approach has two clear major drawbacks. Firstly, there are no formal safety guarantees for a behavior cloning policy trained using supervised learning. Secondly, without explicit knowledge of any safety constraints, the policy may require an unreasonable number of additional demonstrations to even approximate the desired constrained behavior. To solve these key issues, we show how we can instead combine robot foundation models with geometric inductive biases using ATACOM, a safety layer placed after the foundation policy that ensures safe state transitions by enforcing action constraints. With this approach, we can ensure formal safety guarantees for generalist policies without providing extensive demonstrations of safe behavior, and without requiring any specific fine-tuning for safety. Our experiments show that our approach can be beneficial both for classical manipulation tasks, where we avoid unwanted collisions with irrelevant objects, and for dynamic tasks, such as the robot air hockey environment, where we can generate fast trajectories respecting complex tasks and joint space constraints.

