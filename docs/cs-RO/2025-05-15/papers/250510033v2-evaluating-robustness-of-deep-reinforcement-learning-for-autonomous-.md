---
layout: default
title: Evaluating Robustness of Deep Reinforcement Learning for Autonomous Surface Vehicle Control in Field Tests
---

# Evaluating Robustness of Deep Reinforcement Learning for Autonomous Surface Vehicle Control in Field Tests

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.10033" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.10033v2</a>
  <a href="https://arxiv.org/pdf/2505.10033.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.10033v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.10033v2', 'Evaluating Robustness of Deep Reinforcement Learning for Autonomous Surface Vehicle Control in Field Tests')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Luis F. W. Batista, StÃ©phanie Aravecchia, Seth Hutchinson, CÃ©dric Pradalier

**åˆ†ç±»**: cs.RO, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-15 (æ›´æ–°: 2025-06-05)

**å¤‡æ³¨**: Presented at the 2025 IEEE ICRA Workshop on Field Robotics

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°æ·±åº¦å¼ºåŒ–å­¦ä¹ åœ¨è‡ªä¸»æ°´é¢è½¦è¾†æ§åˆ¶ä¸­çš„é²æ£’æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æ·±åº¦å¼ºåŒ–å­¦ä¹ ` `è‡ªä¸»æ°´é¢è½¦è¾†` `é²æ£’æ€§è¯„ä¼°` `é¢†åŸŸéšæœºåŒ–` `æ¨¡å‹é¢„æµ‹æ§åˆ¶` `ç¯å¢ƒç›‘æµ‹` `æµ·æ´‹æ¸…ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨çœŸå®ç¯å¢ƒä¸­çš„é²æ£’æ€§ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨é¢å¯¹å¤–éƒ¨å¹²æ‰°æ—¶è¡¨ç°ä¸ä½³ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡é¢†åŸŸéšæœºåŒ–è®­ç»ƒDRLä»£ç†ï¼Œä»¥å¢å¼ºå…¶åœ¨æ•æ‰æ¼‚æµ®åƒåœ¾æ—¶çš„é€‚åº”èƒ½åŠ›å’Œé²æ£’æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDRLä»£ç†åœ¨é¢å¯¹ä¸å¯¹ç§°é˜»åŠ›å’Œåå¿ƒè´Ÿè½½ç­‰å¹²æ‰°æ—¶ï¼Œè¡¨ç°å‡ºè‰¯å¥½çš„å¯é æ€§ï¼Œä¸”ä¼˜äºMPCåŸºçº¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDRLï¼‰åœ¨è‡ªä¸»æ°´é¢è½¦è¾†ï¼ˆASVï¼‰é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å…¶åœ¨çœŸå®ç¯å¢ƒä¸‹ï¼Œå°¤å…¶æ˜¯åœ¨å¤–éƒ¨å¹²æ‰°ä¸‹çš„é²æ£’æ€§ä»ç„¶ä¸è¶³ã€‚æœ¬æ–‡è¯„ä¼°äº†ä¸€ç§DRLä»£ç†åœ¨æ•æ‰æ¼‚æµ®åƒåœ¾æ—¶çš„éŸ§æ€§ï¼Œè®­ç»ƒè¿‡ç¨‹ä¸­é‡‡ç”¨é¢†åŸŸéšæœºåŒ–ï¼Œå¹¶åœ¨çœŸå®åœºæ™¯ä¸­è¿›è¡Œæ€§èƒ½è¯„ä¼°ï¼Œè€ƒå¯Ÿå…¶åº”å¯¹ä¸å¯¹ç§°é˜»åŠ›å’Œåå¿ƒè´Ÿè½½ç­‰æ„å¤–å¹²æ‰°çš„èƒ½åŠ›ã€‚é€šè¿‡æ¨¡æ‹Ÿå’Œå®é™…å®éªŒè¯„ä¼°ä»£ç†åœ¨è¿™äº›å¹²æ‰°ä¸‹çš„è¡¨ç°ï¼Œé‡åŒ–æ€§èƒ½ä¸‹é™ï¼Œå¹¶ä¸æ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼ˆMPCï¼‰åŸºçº¿è¿›è¡Œå¯¹æ¯”ã€‚ç»“æœè¡¨æ˜ï¼Œå°½ç®¡å­˜åœ¨æ˜¾è‘—å¹²æ‰°ï¼ŒDRLä»£ç†ä»è¡¨ç°å‡ºå¯é æ€§ã€‚æˆ‘ä»¬è¿˜å¼€æ”¾æºä»£ç ï¼Œæä¾›æœ‰æ•ˆè®­ç»ƒç­–ç•¥ã€ç°å®æŒ‘æˆ˜åŠDRL ASVæ§åˆ¶å™¨éƒ¨ç½²çš„å®é™…è€ƒè™‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ·±åº¦å¼ºåŒ–å­¦ä¹ åœ¨è‡ªä¸»æ°´é¢è½¦è¾†æ§åˆ¶ä¸­é¢å¯¹çœŸå®ç¯å¢ƒå¹²æ‰°æ—¶çš„é²æ£’æ€§ä¸è¶³é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨åº”å¯¹å¤–éƒ¨æ‰°åŠ¨æ—¶è¡¨ç°ä¸ç¨³å®šï¼Œé™åˆ¶äº†å…¶å®é™…åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡é¢†åŸŸéšæœºåŒ–æŠ€æœ¯è®­ç»ƒDRLä»£ç†ï¼Œä½¿å…¶åœ¨å¤šç§å¹²æ‰°æ¡ä»¶ä¸‹å…·å¤‡æ›´å¼ºçš„é€‚åº”èƒ½åŠ›ï¼Œä»è€Œæé«˜å…¶åœ¨çœŸå®ç¯å¢ƒä¸­çš„è¡¨ç°ã€‚è¯¥è®¾è®¡æ—¨åœ¨æ¨¡æ‹Ÿå¤šæ ·åŒ–çš„ç¯å¢ƒå˜åŒ–ï¼Œä»¥å¢å¼ºæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬è®­ç»ƒé˜¶æ®µå’Œè¯„ä¼°é˜¶æ®µã€‚åœ¨è®­ç»ƒé˜¶æ®µï¼Œé‡‡ç”¨é¢†åŸŸéšæœºåŒ–ç”Ÿæˆå¤šç§æ‰°åŠ¨åœºæ™¯ï¼›åœ¨è¯„ä¼°é˜¶æ®µï¼Œé€šè¿‡æ¨¡æ‹Ÿå’ŒçœŸå®ç¯å¢ƒæµ‹è¯•ä»£ç†çš„æ€§èƒ½ï¼Œæ¯”è¾ƒå…¶åœ¨ä¸åŒå¹²æ‰°ä¸‹çš„è¡¨ç°ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„ä¸»è¦åˆ›æ–°åœ¨äºç»“åˆé¢†åŸŸéšæœºåŒ–ä¸DRLï¼Œç³»ç»Ÿæ€§åœ°è¯„ä¼°äº†ä»£ç†åœ¨çœŸå®ç¯å¢ƒä¸­çš„é²æ£’æ€§ï¼Œå¡«è¡¥äº†ç°æœ‰ç ”ç©¶åœ¨è¿™ä¸€é¢†åŸŸçš„ç©ºç™½ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åº”å¯¹å¤æ‚çš„å¤–éƒ¨æ‰°åŠ¨ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œè®¾ç½®äº†å¤šç§æ‰°åŠ¨å‚æ•°ï¼Œå¦‚ä¸å¯¹ç§°é˜»åŠ›å’Œåå¿ƒè´Ÿè½½ï¼Œé‡‡ç”¨ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–ä»£ç†çš„æ§åˆ¶ç­–ç•¥ã€‚ç½‘ç»œç»“æ„æ–¹é¢ï¼Œä½¿ç”¨äº†æ·±åº¦ç¥ç»ç½‘ç»œæ¥å¤„ç†å¤æ‚çš„ç¯å¢ƒè¾“å…¥ï¼Œå¹¶é€šè¿‡å¼ºåŒ–å­¦ä¹ ç®—æ³•è¿›è¡Œè®­ç»ƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒDRLä»£ç†åœ¨é¢å¯¹ä¸å¯¹ç§°é˜»åŠ›å’Œåå¿ƒè´Ÿè½½ç­‰å¹²æ‰°æ—¶ï¼Œä»èƒ½ä¿æŒè¾ƒé«˜çš„æ€§èƒ½ï¼Œæ€§èƒ½ä¸‹é™å¹…åº¦å°äº20%ã€‚ä¸æ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼ˆMPCï¼‰åŸºçº¿ç›¸æ¯”ï¼ŒDRLä»£ç†åœ¨å¤„ç†å¤æ‚ç¯å¢ƒæ—¶è¡¨ç°å‡ºæ›´é«˜çš„å¯é æ€§å’Œé€‚åº”æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¯å¢ƒç›‘æµ‹ã€æµ·æ´‹æ¸…ç†å’Œè‡ªä¸»å¯¼èˆªç­‰ã€‚é€šè¿‡æé«˜è‡ªä¸»æ°´é¢è½¦è¾†åœ¨å¤æ‚ç¯å¢ƒä¸­çš„é²æ£’æ€§ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„è¡¨ç°ï¼Œæ¨åŠ¨æ™ºèƒ½æ°´é¢ä½œä¸šçš„å‘å±•ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯å¯èƒ½åœ¨æµ·æ´‹èµ„æºç®¡ç†å’Œç¯å¢ƒä¿æŠ¤ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Despite significant advancements in Deep Reinforcement Learning (DRL) for Autonomous Surface Vehicles (ASVs), their robustness in real-world conditions, particularly under external disturbances, remains insufficiently explored. In this paper, we evaluate the resilience of a DRL-based agent designed to capture floating waste under various perturbations. We train the agent using domain randomization and evaluate its performance in real-world field tests, assessing its ability to handle unexpected disturbances such as asymmetric drag and an off-center payload. We assess the agent's performance under these perturbations in both simulation and real-world experiments, quantifying performance degradation and benchmarking it against an MPC baseline. Results indicate that the DRL agent performs reliably despite significant disturbances. Along with the open-source release of our implementation, we provide insights into effective training strategies, real-world challenges, and practical considerations for deploying DRLbased ASV controllers.

