---
layout: default
title: TartanGround: A Large-Scale Dataset for Ground Robot Perception and Navigation
---

# TartanGround: A Large-Scale Dataset for Ground Robot Perception and Navigation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.10696" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.10696v2</a>
  <a href="https://arxiv.org/pdf/2505.10696.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.10696v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.10696v2', 'TartanGround: A Large-Scale Dataset for Ground Robot Perception and Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Manthan Patel, Fan Yang, Yuheng Qiu, Cesar Cadena, Sebastian Scherer, Marco Hutter, Wenshan Wang

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-15 (æ›´æ–°: 2025-07-30)

**å¤‡æ³¨**: Accepted for publication to IEEE/RSJ IROS 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTartanGroundæ•°æ®é›†ä»¥æå‡åœ°é¢æœºå™¨äººæ„ŸçŸ¥ä¸å¯¼èˆªèƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `åœ°é¢æœºå™¨äºº` `å¤šæ¨¡æ€æ•°æ®é›†` `æ„ŸçŸ¥ä¸å¯¼èˆª` `SLAM` `å ç”¨é¢„æµ‹` `ä»¿çœŸç¯å¢ƒ` `è‡ªåŠ¨åŒ–ç®¡é“`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤šæ ·åŒ–åœºæ™¯ä¸­çš„æ³›åŒ–èƒ½åŠ›ä¸è¶³ï¼Œé™åˆ¶äº†åœ°é¢æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„åº”ç”¨ã€‚
2. TartanGroundæ•°æ®é›†é€šè¿‡å¤šæ¨¡æ€æ•°æ®æ”¶é›†ï¼Œæä¾›ä¸°å¯Œçš„æ„ŸçŸ¥ä¿¡æ¯ï¼Œæ”¯æŒå¤šç§å­¦ä¹ ä»»åŠ¡çš„è®­ç»ƒä¸è¯„ä¼°ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTartanGroundæ˜¾è‘—æå‡äº†å ç”¨é¢„æµ‹å’ŒSLAMä»»åŠ¡çš„æ€§èƒ½ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤šæ ·åœºæ™¯ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬æå‡ºäº†TartanGroundï¼Œè¿™æ˜¯ä¸€ä¸ªå¤§è§„æ¨¡çš„å¤šæ¨¡æ€æ•°æ®é›†ï¼Œæ—¨åœ¨æ¨åŠ¨åœ°é¢æœºå™¨äººåœ¨å¤šæ ·ç¯å¢ƒä¸­çš„æ„ŸçŸ¥ä¸è‡ªä¸»èƒ½åŠ›ã€‚è¯¥æ•°æ®é›†åœ¨å¤šä¸ªé€¼çœŸçš„ä»¿çœŸç¯å¢ƒä¸­æ”¶é›†ï¼ŒåŒ…å«å¤šä¸ªRGBç«‹ä½“æ‘„åƒå¤´ä»¥å®ç°360åº¦è¦†ç›–ï¼ŒåŒæ—¶æä¾›æ·±åº¦ã€å…‰æµã€ç«‹ä½“è§†å·®ã€LiDARç‚¹äº‘ã€çœŸå®ä½å§¿ã€è¯­ä¹‰åˆ†å‰²å›¾åƒå’Œå¸¦è¯­ä¹‰æ ‡ç­¾çš„å ç”¨åœ°å›¾ã€‚æ•°æ®é€šè¿‡é›†æˆçš„è‡ªåŠ¨åŒ–ç®¡é“æ”¶é›†ï¼Œç”Ÿæˆæ¨¡æ‹Ÿå„ç§åœ°é¢æœºå™¨äººå¹³å°ï¼ˆåŒ…æ‹¬è½®å¼å’Œè…¿å¼æœºå™¨äººï¼‰è¿åŠ¨æ¨¡å¼çš„è½¨è¿¹ã€‚æˆ‘ä»¬åœ¨70ä¸ªç¯å¢ƒä¸­æ”¶é›†äº†910æ¡è½¨è¿¹ï¼Œç”Ÿæˆ150ä¸‡ä¸ªæ ·æœ¬ã€‚å¯¹å ç”¨é¢„æµ‹å’ŒSLAMä»»åŠ¡çš„è¯„ä¼°è¡¨æ˜ï¼Œç°æœ‰æ•°æ®é›†ä¸Šè®­ç»ƒçš„æœ€å…ˆè¿›æ–¹æ³•åœ¨å¤šæ ·åœºæ™¯ä¸­æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚TartanGroundå¯ä½œä¸ºè®­ç»ƒå’Œè¯„ä¼°å¤šç§åŸºäºå­¦ä¹ çš„ä»»åŠ¡çš„æµ‹è¯•å¹³å°ï¼Œæ¨åŠ¨æœºå™¨äººæ„ŸçŸ¥å’Œè‡ªä¸»èƒ½åŠ›çš„å‘å±•ï¼Œä»è€Œå®ç°æ›´å¼ºå¤§çš„æ¨¡å‹ï¼Œèƒ½å¤Ÿåœ¨æ›´å¹¿æ³›çš„åœºæ™¯ä¸­æ³›åŒ–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰åœ°é¢æœºå™¨äººåœ¨å¤šæ ·ç¯å¢ƒä¸­æ„ŸçŸ¥ä¸å¯¼èˆªèƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤æ‚åœºæ™¯ä¸­çš„æ³›åŒ–èƒ½åŠ›è¾ƒå·®ï¼Œé™åˆ¶äº†å…¶å®é™…åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„TartanGroundæ•°æ®é›†é€šè¿‡åœ¨å¤šç§ä»¿çœŸç¯å¢ƒä¸­æ”¶é›†å¤šæ¨¡æ€æ•°æ®ï¼Œæä¾›ä¸°å¯Œçš„æ„ŸçŸ¥ä¿¡æ¯ï¼Œæ—¨åœ¨æå‡æœºå™¨äººåœ¨ä¸åŒåœºæ™¯ä¸­çš„è‡ªä¸»å¯¼èˆªèƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•°æ®æ”¶é›†é‡‡ç”¨é›†æˆçš„è‡ªåŠ¨åŒ–ç®¡é“ï¼Œç”Ÿæˆæ¨¡æ‹Ÿä¸åŒåœ°é¢æœºå™¨äººè¿åŠ¨æ¨¡å¼çš„è½¨è¿¹ã€‚æ•°æ®é›†åŒ…å«RGBç«‹ä½“å›¾åƒã€æ·±åº¦å›¾ã€å…‰æµã€LiDARç‚¹äº‘ç­‰å¤šç§ä¿¡æ¯ï¼Œæ”¯æŒå¤šç§å­¦ä¹ ä»»åŠ¡çš„è®­ç»ƒä¸è¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šTartanGroundæ•°æ®é›†çš„æœ€å¤§åˆ›æ–°åœ¨äºå…¶å¤šæ¨¡æ€æ•°æ®çš„å…¨é¢æ€§å’Œä¸°å¯Œæ€§ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ”¯æŒå ç”¨é¢„æµ‹ã€SLAMç­‰ä»»åŠ¡çš„è®­ç»ƒï¼Œæ˜¾è‘—æå‡ç°æœ‰æ–¹æ³•åœ¨å¤šæ ·åœºæ™¯ä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šæ•°æ®é›†è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å¤šç§ä¼ æ„Ÿå™¨æ•°æ®çš„èåˆï¼ŒåŒ…æ‹¬RGBã€æ·±åº¦ã€å…‰æµç­‰ï¼ŒåŒæ—¶æä¾›çœŸå®ä½å§¿å’Œè¯­ä¹‰æ ‡ç­¾ï¼Œç¡®ä¿æ•°æ®çš„å‡†ç¡®æ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨TartanGroundæ•°æ®é›†è®­ç»ƒçš„æ¨¡å‹åœ¨å ç”¨é¢„æµ‹å’ŒSLAMä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œç›¸è¾ƒäºç°æœ‰æ•°æ®é›†ï¼Œæ³›åŒ–èƒ½åŠ›æå‡æ˜¾è‘—ï¼Œå…·ä½“æ€§èƒ½æ•°æ®å°šæœªæŠ«éœ²ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

TartanGroundæ•°æ®é›†çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªä¸»é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€ç¯å¢ƒæ„ŸçŸ¥ç­‰ã€‚é€šè¿‡æä¾›ä¸°å¯Œçš„å¤šæ¨¡æ€æ•°æ®ï¼Œè¯¥æ•°æ®é›†èƒ½å¤Ÿå¸®åŠ©ç ”ç©¶äººå‘˜å’Œå·¥ç¨‹å¸ˆå¼€å‘æ›´ä¸ºæ™ºèƒ½å’Œå¯é çš„æœºå™¨äººç³»ç»Ÿï¼Œæ¨åŠ¨æœºå™¨äººæŠ€æœ¯åœ¨å®é™…åº”ç”¨ä¸­çš„å‘å±•ä¸æ™®åŠã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present TartanGround, a large-scale, multi-modal dataset to advance the perception and autonomy of ground robots operating in diverse environments. This dataset, collected in various photorealistic simulation environments includes multiple RGB stereo cameras for 360-degree coverage, along with depth, optical flow, stereo disparity, LiDAR point clouds, ground truth poses, semantic segmented images, and occupancy maps with semantic labels. Data is collected using an integrated automatic pipeline, which generates trajectories mimicking the motion patterns of various ground robot platforms, including wheeled and legged robots. We collect 910 trajectories across 70 environments, resulting in 1.5 million samples. Evaluations on occupancy prediction and SLAM tasks reveal that state-of-the-art methods trained on existing datasets struggle to generalize across diverse scenes. TartanGround can serve as a testbed for training and evaluation of a broad range of learning-based tasks, including occupancy prediction, SLAM, neural scene representation, perception-based navigation, and more, enabling advancements in robotic perception and autonomy towards achieving robust models generalizable to more diverse scenarios. The dataset and codebase are available on the webpage: https://tartanair.org/tartanground

