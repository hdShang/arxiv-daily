---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-05-16
---

# cs.ROï¼ˆ2025-05-16ï¼‰

ğŸ“Š å…± **25** ç¯‡è®ºæ–‡
 | ğŸ”— **5** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (16 ğŸ”—4)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (4)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (2 ğŸ”—1)</a>
<a href="#æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation" class="interest-badge">æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (16 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250511164v1-parkour-in-the-wild-learning-a-general-and-extensible-agile-locomoti.html">Parkour in the Wild: Learning a General and Extensible Agile Locomotion Policy Using Multi-expert Distillation and RL Fine-tuning</a></td>
  <td>æå‡ºå¤šä¸“å®¶è’¸é¦ä¸å¼ºåŒ–å­¦ä¹ ç»“åˆçš„çµæ´»æ­¥æ€æ§åˆ¶æ¡†æ¶</td>
  <td class="tags-cell"><span class="paper-tag">legged robot</span> <span class="paper-tag">locomotion</span> <span class="paper-tag">locomotion policy</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.11164v1" data-paper-url="./papers/250511164v1-parkour-in-the-wild-learning-a-general-and-extensible-agile-locomoti.html" onclick="toggleFavorite(this, '2505.11164v1', 'Parkour in the Wild: Learning a General and Extensible Agile Locomotion Policy Using Multi-expert Distillation and RL Fine-tuning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250511495v1-bracing-for-impact-robust-humanoid-push-recovery-and-locomotion-with.html">Bracing for Impact: Robust Humanoid Push Recovery and Locomotion with Reduced Order Models</a></td>
  <td>æå‡ºç»Ÿä¸€æ¡†æ¶ä»¥å¢å¼ºç±»äººæœºå™¨äººåœ¨è¡Œèµ°ä¸­çš„æ¨åŠ›æ¢å¤èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid robot</span> <span class="paper-tag">locomotion</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.11495v1" data-paper-url="./papers/250511495v1-bracing-for-impact-robust-humanoid-push-recovery-and-locomotion-with.html" onclick="toggleFavorite(this, '2505.11495v1', 'Bracing for Impact: Robust Humanoid Push Recovery and Locomotion with Reduced Order Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250510973v3-groq-loco-generalist-and-robot-agnostic-quadruped-locomotion-control.html">GRoQ-LoCO: Generalist and Robot-agnostic Quadruped Locomotion Control using Offline Datasets</a></td>
  <td>æå‡ºGRoQ-LoCOä»¥è§£å†³å››è¶³æœºå™¨äººé€šç”¨è¿åŠ¨æ§åˆ¶é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">quadruped</span> <span class="paper-tag">legged locomotion</span> <span class="paper-tag">locomotion</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.10973v3" data-paper-url="./papers/250510973v3-groq-loco-generalist-and-robot-agnostic-quadruped-locomotion-control.html" onclick="toggleFavorite(this, '2505.10973v3', 'GRoQ-LoCO: Generalist and Robot-agnostic Quadruped Locomotion Control using Offline Datasets')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250511366v1-learning-multimodal-ai-algorithms-for-amplifying-limited-user-input-.html">Learning Multimodal AI Algorithms for Amplifying Limited User Input into High-dimensional Control Space</a></td>
  <td>æå‡ºå¤šæ¨¡æ€AIç®—æ³•ä»¥è§£å†³ä¸¥é‡ç˜«ç—ªæ‚£è€…çš„æ§åˆ¶ä¿¡å·é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">dexterous manipulation</span> <span class="paper-tag">sim-to-real</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.11366v1" data-paper-url="./papers/250511366v1-learning-multimodal-ai-algorithms-for-amplifying-limited-user-input-.html" onclick="toggleFavorite(this, '2505.11366v1', 'Learning Multimodal AI Algorithms for Amplifying Limited User Input into High-dimensional Control Space')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250511032v3-dexgarmentlab-dexterous-garment-manipulation-environment-with-genera.html">DexGarmentLab: Dexterous Garment Manipulation Environment with Generalizable Policy</a></td>
  <td>æå‡ºDexGarmentLabä»¥è§£å†³æœè£…çµå·§æ“ä½œçš„æŒ‘æˆ˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">bi-manual</span> <span class="paper-tag">sim-to-real</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.11032v3" data-paper-url="./papers/250511032v3-dexgarmentlab-dexterous-garment-manipulation-environment-with-genera.html" onclick="toggleFavorite(this, '2505.11032v3', 'DexGarmentLab: Dexterous Garment Manipulation Environment with Generalizable Policy')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250511719v1-zero-shot-visual-generalization-in-robot-manipulation.html">Zero-Shot Visual Generalization in Robot Manipulation</a></td>
  <td>æå‡ºè§£è€¦è¡¨ç¤ºå­¦ä¹ ä»¥è§£å†³æœºå™¨äººæ“ä½œä¸­çš„é›¶-shotè§†è§‰æ³›åŒ–é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">domain randomization</span> <span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.11719v1" data-paper-url="./papers/250511719v1-zero-shot-visual-generalization-in-robot-manipulation.html" onclick="toggleFavorite(this, '2505.11719v1', 'Zero-Shot Visual Generalization in Robot Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250511680v1-grounded-task-axes-zero-shot-semantic-skill-generalization-via-task-.html">Grounded Task Axes: Zero-Shot Semantic Skill Generalization via Task-Axis Controllers and Visual Foundation Models</a></td>
  <td>æå‡ºåŸºäºä»»åŠ¡è½´æ§åˆ¶å™¨çš„é›¶-shotæŠ€èƒ½è¿ç§»æ–¹æ³•ä»¥è§£å†³æœºå™¨äººæ“ä½œä¸­çš„æŠ€èƒ½è½¬ç§»é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">foundation model</span> <span class="paper-tag">zero-shot transfer</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.11680v1" data-paper-url="./papers/250511680v1-grounded-task-axes-zero-shot-semantic-skill-generalization-via-task-.html" onclick="toggleFavorite(this, '2505.11680v1', 'Grounded Task Axes: Zero-Shot Semantic Skill Generalization via Task-Axis Controllers and Visual Foundation Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250511494v2-shield-safety-on-humanoids-via-cbfs-in-expectation-on-learned-dynami.html">SHIELD: Safety on Humanoids via CBFs In Expectation on Learned Dynamics</a></td>
  <td>æå‡ºSHIELDæ¡†æ¶ä»¥è§£å†³äººå½¢æœºå™¨äººåŠ¨æ€å®‰å…¨é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">locomotion</span> <span class="paper-tag">Unitree</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.11494v2" data-paper-url="./papers/250511494v2-shield-safety-on-humanoids-via-cbfs-in-expectation-on-learned-dynami.html" onclick="toggleFavorite(this, '2505.11494v2', 'SHIELD: Safety on Humanoids via CBFs In Expectation on Learned Dynamics')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250510911v2-rewind-language-guided-rewards-teach-robot-policies-without-new-demo.html">ReWiND: Language-Guided Rewards Teach Robot Policies without New Demonstrations</a></td>
  <td>æå‡ºReWiNDæ¡†æ¶ä»¥è§£å†³æœºå™¨äººä»»åŠ¡å­¦ä¹ ä¸­çš„æ¼”ç¤ºä¾èµ–é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">bi-manual</span> <span class="paper-tag">reinforcement learning</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.10911v2" data-paper-url="./papers/250510911v2-rewind-language-guided-rewards-teach-robot-policies-without-new-demo.html" onclick="toggleFavorite(this, '2505.10911v2', 'ReWiND: Language-Guided Rewards Teach Robot Policies without New Demonstrations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250511146v2-x2c-a-dataset-featuring-nuanced-facial-expressions-for-realistic-hum.html">X2C: A Dataset Featuring Nuanced Facial Expressions for Realistic Humanoid Imitation</a></td>
  <td>æå‡ºX2Cæ•°æ®é›†ä»¥è§£å†³äººå½¢æœºå™¨äººé¢éƒ¨è¡¨æƒ…æ¨¡ä»¿é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid robot</span> <span class="paper-tag">human-to-humanoid</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.11146v2" data-paper-url="./papers/250511146v2-x2c-a-dataset-featuring-nuanced-facial-expressions-for-realistic-hum.html" onclick="toggleFavorite(this, '2505.11146v2', 'X2C: A Dataset Featuring Nuanced Facial Expressions for Realistic Humanoid Imitation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250510918v2-unleashing-humanoid-reaching-potential-via-real-world-ready-skill-sp.html">Unleashing Humanoid Reaching Potential via Real-world-Ready Skill Space</a></td>
  <td>æå‡ºR2S2ä»¥è§£å†³ç±»äººæœºå™¨äººå¤§ç©ºé—´è¾¾æˆæ§åˆ¶é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">whole-body control</span> <span class="paper-tag">sim2real</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.10918v2" data-paper-url="./papers/250510918v2-unleashing-humanoid-reaching-potential-via-real-world-ready-skill-sp.html" onclick="toggleFavorite(this, '2505.10918v2', 'Unleashing Humanoid Reaching Potential via Real-world-Ready Skill Space')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250511420v1-self-supervised-perception-for-tactile-skin-covered-dexterous-hands.html">Self-supervised perception for tactile skin covered dexterous hands</a></td>
  <td>æå‡ºSparsh-skinä»¥è§£å†³æœºå™¨äººæ‰‹éƒ¨è§¦è§‰æ„ŸçŸ¥é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">dexterous hand</span> <span class="paper-tag">policy learning</span> <span class="paper-tag">distillation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.11420v1" data-paper-url="./papers/250511420v1-self-supervised-perception-for-tactile-skin-covered-dexterous-hands.html" onclick="toggleFavorite(this, '2505.11420v1', 'Self-supervised perception for tactile skin covered dexterous hands')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/250511467v1-exploiting-radiance-fields-for-grasp-generation-on-novel-synthetic-v.html">Exploiting Radiance Fields for Grasp Generation on Novel Synthetic Views</a></td>
  <td>åˆ©ç”¨è¾å°„åœºç”Ÿæˆæ–°è§†è§’æŠ“å–æ–¹æ¡ˆ</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">gaussian splatting</span> <span class="paper-tag">splatting</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.11467v1" data-paper-url="./papers/250511467v1-exploiting-radiance-fields-for-grasp-generation-on-novel-synthetic-v.html" onclick="toggleFavorite(this, '2505.11467v1', 'Exploiting Radiance Fields for Grasp Generation on Novel Synthetic Views')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/250511563v1-object-centric-representations-improve-policy-generalization-in-robo.html">Object-Centric Representations Improve Policy Generalization in Robot Manipulation</a></td>
  <td>æå‡ºå¯¹è±¡ä¸­å¿ƒè¡¨ç¤ºä»¥æå‡æœºå™¨äººæ“ä½œç­–ç•¥çš„æ³›åŒ–èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.11563v1" data-paper-url="./papers/250511563v1-object-centric-representations-improve-policy-generalization-in-robo.html" onclick="toggleFavorite(this, '2505.11563v1', 'Object-Centric Representations Improve Policy Generalization in Robot Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/250510884v1-estimating-deformable-rigid-contact-interactions-for-a-deformable-to.html">Estimating Deformable-Rigid Contact Interactions for a Deformable Tool via Learning and Model-Based Optimization</a></td>
  <td>æå‡ºæ··åˆå­¦ä¹ ä¸æ¨¡å‹ä¼˜åŒ–æ–¹æ³•ä»¥è§£å†³å˜å½¢å·¥å…·çš„æ¥è§¦äº¤äº’é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">dexterous manipulation</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.10884v1" data-paper-url="./papers/250510884v1-estimating-deformable-rigid-contact-interactions-for-a-deformable-to.html" onclick="toggleFavorite(this, '2505.10884v1', 'Estimating Deformable-Rigid Contact Interactions for a Deformable Tool via Learning and Model-Based Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/250511376v1-decoupling-collision-avoidance-in-and-for-optimal-control-using-leas.html">Decoupling Collision Avoidance in and for Optimal Control using Least-Squares Support Vector Machines</a></td>
  <td>æå‡ºåŸºäºæœ€å°äºŒä¹˜æ”¯æŒå‘é‡æœºçš„ç¢°æ’é¿å…æ–¹æ³•ä»¥ä¼˜åŒ–æ§åˆ¶é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">motion planning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.11376v1" data-paper-url="./papers/250511376v1-decoupling-collision-avoidance-in-and-for-optimal-control-using-leas.html" onclick="toggleFavorite(this, '2505.11376v1', 'Decoupling Collision Avoidance in and for Optimal Control using Least-Squares Support Vector Machines')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (4 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>17</td>
  <td><a href="./papers/250511214v1-unveiling-the-potential-of-vision-language-action-models-with-open-e.html">Unveiling the Potential of Vision-Language-Action Models with Open-Ended Multimodal Instructions</a></td>
  <td>æå‡ºOE-VLAä»¥è§£å†³å¤šæ¨¡æ€æŒ‡ä»¤ä¸‹çš„æœºå™¨äººäº¤äº’é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">vision-language-action</span> <span class="paper-tag">VLA</span> <span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.11214v1" data-paper-url="./papers/250511214v1-unveiling-the-potential-of-vision-language-action-models-with-open-e.html" onclick="toggleFavorite(this, '2505.11214v1', 'Unveiling the Potential of Vision-Language-Action Models with Open-Ended Multimodal Instructions')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/250511350v5-search-tta-a-multimodal-test-time-adaptation-framework-for-visual-se.html">Search-TTA: A Multimodal Test-Time Adaptation Framework for Visual Search in the Wild</a></td>
  <td>æå‡ºSearch-TTAæ¡†æ¶ä»¥è§£å†³æˆ·å¤–è§†è§‰æœç´¢ä¸­çš„ä¿¡æ¯ä¸è¶³é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.11350v5" data-paper-url="./papers/250511350v5-search-tta-a-multimodal-test-time-adaptation-framework-for-visual-se.html" onclick="toggleFavorite(this, '2505.11350v5', 'Search-TTA: A Multimodal Test-Time Adaptation Framework for Visual Search in the Wild')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/250511175v2-real-time-verification-of-embodied-reasoning-for-generative-skill-ac.html">Real-Time Verification of Embodied Reasoning for Generative Skill Acquisition</a></td>
  <td>æå‡ºVERGSAæ¡†æ¶ä»¥è§£å†³å¤æ‚3Dç¯å¢ƒä¸­çš„æŠ€èƒ½å­¦ä¹ æ•ˆç‡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">generalist agent</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.11175v2" data-paper-url="./papers/250511175v2-real-time-verification-of-embodied-reasoning-for-generative-skill-ac.html" onclick="toggleFavorite(this, '2505.11175v2', 'Real-Time Verification of Embodied Reasoning for Generative Skill Acquisition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/250510872v2-rei-bench-can-embodied-agents-understand-vague-human-instructions-in.html">REI-Bench: Can Embodied Agents Understand Vague Human Instructions in Task Planning?</a></td>
  <td>æå‡ºREI-Benchä»¥è§£å†³æœºå™¨äººä»»åŠ¡è§„åˆ’ä¸­çš„æ¨¡ç³Šäººç±»æŒ‡ä»¤é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.10872v2" data-paper-url="./papers/250510872v2-rei-bench-can-embodied-agents-understand-vague-human-instructions-in.html" onclick="toggleFavorite(this, '2505.10872v2', 'REI-Bench: Can Embodied Agents Understand Vague Human Instructions in Task Planning?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>21</td>
  <td><a href="./papers/250511123v1-conditioning-matters-training-diffusion-policies-is-faster-than-you-.html">Conditioning Matters: Training Diffusion Policies is Faster Than You Think</a></td>
  <td>æå‡ºCocosä»¥è§£å†³æ¡ä»¶æ‰©æ•£ç­–ç•¥è®­ç»ƒæ•ˆç‡ä½ä¸‹é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">diffusion policy</span> <span class="paper-tag">flow matching</span> <span class="paper-tag">vision-language-action</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.11123v1" data-paper-url="./papers/250511123v1-conditioning-matters-training-diffusion-policies-is-faster-than-you-.html" onclick="toggleFavorite(this, '2505.11123v1', 'Conditioning Matters: Training Diffusion Policies is Faster Than You Think')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>22</td>
  <td><a href="./papers/250510760v1-counterfactual-behavior-cloning-offline-imitation-learning-from-impe.html">Counterfactual Behavior Cloning: Offline Imitation Learning from Imperfect Human Demonstrations</a></td>
  <td>æå‡ºCounter-BCä»¥è§£å†³äººç±»ç¤ºèŒƒä¸å®Œç¾é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">imitation learning</span> <span class="paper-tag">behavior cloning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.10760v1" data-paper-url="./papers/250510760v1-counterfactual-behavior-cloning-offline-imitation-learning-from-impe.html" onclick="toggleFavorite(this, '2505.10760v1', 'Counterfactual Behavior Cloning: Offline Imitation Learning from Imperfect Human Demonstrations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>23</td>
  <td><a href="./papers/250511116v1-planar-velocity-estimation-for-fast-moving-mobile-robots-using-event.html">Planar Velocity Estimation for Fast-Moving Mobile Robots Using Event-Based Optical Flow</a></td>
  <td>æå‡ºåŸºäºäº‹ä»¶ç›¸æœºçš„å¹³é¢é€Ÿåº¦ä¼°è®¡æ–¹æ³•ä»¥è§£å†³ç§»åŠ¨æœºå™¨äººé€Ÿåº¦ä¼°è®¡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">VIO</span> <span class="paper-tag">optical flow</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.11116v1" data-paper-url="./papers/250511116v1-planar-velocity-estimation-for-fast-moving-mobile-robots-using-event.html" onclick="toggleFavorite(this, '2505.11116v1', 'Planar Velocity Estimation for Fast-Moving Mobile Robots Using Event-Based Optical Flow')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>24</td>
  <td><a href="./papers/250510923v2-growsplat-constructing-temporal-digital-twins-of-plants-with-gaussia.html">GrowSplat: Constructing Temporal Digital Twins of Plants with Gaussian Splats</a></td>
  <td>æå‡ºGrowSplatæ¡†æ¶ä»¥æ„å»ºæ¤ç‰©çš„æ—¶é—´æ•°å­—åŒèƒèƒ</td>
  <td class="tags-cell"><span class="paper-tag">3D gaussian splatting</span> <span class="paper-tag">gaussian splatting</span> <span class="paper-tag">splatting</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.10923v2" data-paper-url="./papers/250510923v2-growsplat-constructing-temporal-digital-twins-of-plants-with-gaussia.html" onclick="toggleFavorite(this, '2505.10923v2', 'GrowSplat: Constructing Temporal Digital Twins of Plants with Gaussian Splats')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation">ğŸ”¬ æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>25</td>
  <td><a href="./papers/250511663v1-adaptive-ergodic-search-with-energy-aware-scheduling-for-persistent-.html">Adaptive Ergodic Search with Energy-Aware Scheduling for Persistent Multi-Robot Missions</a></td>
  <td>æå‡ºmEclaresæ¡†æ¶ä»¥è§£å†³å¤šæœºå™¨äººä»»åŠ¡ä¸­çš„ä¿¡æ¯æ”¶é›†ä¸èƒ½é‡è°ƒåº¦é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">spatiotemporal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.11663v1" data-paper-url="./papers/250511663v1-adaptive-ergodic-search-with-energy-aware-scheduling-for-persistent-.html" onclick="toggleFavorite(this, '2505.11663v1', 'Adaptive Ergodic Search with Energy-Aware Scheduling for Persistent Multi-Robot Missions')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)