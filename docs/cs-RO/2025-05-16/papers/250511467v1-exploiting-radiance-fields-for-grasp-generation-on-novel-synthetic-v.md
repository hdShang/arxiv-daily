---
layout: default
title: Exploiting Radiance Fields for Grasp Generation on Novel Synthetic Views
---

# Exploiting Radiance Fields for Grasp Generation on Novel Synthetic Views

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.11467" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.11467v1</a>
  <a href="https://arxiv.org/pdf/2505.11467.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.11467v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.11467v1', 'Exploiting Radiance Fields for Grasp Generation on Novel Synthetic Views')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Abhishek Kashyap, Henrik Andreasson, Todor Stoyanov

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-16

**å¤‡æ³¨**: 6 pages

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ©ç”¨è¾å°„åœºç”Ÿæˆæ–°è§†è§’æŠ“å–æ–¹æ¡ˆ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `æœºå™¨äººæŠ“å–` `è§†è§‰åˆæˆ` `åŠ›é—­åˆæŠ“å–` `è™šæ‹Ÿå›¾åƒ` `åœºæ™¯è¡¨ç¤º` `æ•°æ®é›†` `è‡ªåŠ¨åŒ–æŠ€æœ¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æŠ“å–å§¿æ€ç”Ÿæˆä¸­é¢ä¸´è§†è§’é™åˆ¶ï¼Œå¯¼è‡´ä¿¡æ¯ä¸è¶³ï¼Œå½±å“æŠ“å–æ•ˆæœã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡æ–°è§†è§’åˆæˆæŠ€æœ¯ï¼Œåˆ©ç”¨è™šæ‹Ÿå›¾åƒæä¾›é¢å¤–ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæ”¹å–„æŠ“å–å§¿æ€ç”Ÿæˆã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ–°è§†è§’åˆæˆä¸ä»…æé«˜äº†åŠ›é—­åˆæŠ“å–çš„æ•°é‡ï¼Œè¿˜æ”¹å–„äº†æŠ“å–è¦†ç›–ç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºäºè§†è§‰çš„æœºå™¨äººæ“ä½œä½¿ç”¨ç›¸æœºæ•æ‰åœºæ™¯ä¸­çš„å›¾åƒï¼Œä»¥ä¾¿è¿›è¡Œç‰©ä½“æ“æ§ã€‚è™½ç„¶å¤šè§†è§’å›¾åƒå¯ä»¥æä¾›æ›´å¤šä¿¡æ¯ï¼Œæ”¹å–„æŠ“å–å§¿æ€ï¼Œä½†ç›¸æœºç§»åŠ¨åˆ°å¤šä¸ªä½ç½®çš„è¿‡ç¨‹è€—æ—¶ä¸”å—é™äºå¯è¾¾æ€§ã€‚æœ¬æ–‡å±•ç¤ºäº†æ–°è§†è§’åˆæˆå¦‚ä½•ä¸ºæŠ“å–å§¿æ€ç”Ÿæˆæä¾›é¢å¤–ä¸Šä¸‹æ–‡ã€‚é€šè¿‡åœ¨Graspnet-1billionæ•°æ®é›†ä¸Šçš„å®éªŒï¼Œç»“æœè¡¨æ˜æ–°è§†è§’æœ‰åŠ©äºç”ŸæˆåŠ›é—­åˆæŠ“å–ï¼Œå¹¶æ”¹å–„æŠ“å–è¦†ç›–ç‡ã€‚æœªæ¥å¸Œæœ›å°†æ­¤å·¥ä½œæ‰©å±•åˆ°ä½¿ç”¨å•å¼ è¾“å…¥å›¾åƒæå–æŠ“å–å§¿æ€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨æœºå™¨äººæŠ“å–ä¸­ï¼Œç”±äºè§†è§’é™åˆ¶å¯¼è‡´çš„ä¿¡æ¯ä¸è¶³é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†é®æŒ¡ç‰©ä½“æ—¶ï¼Œä¾èµ–äºå¤šä¸ªè§†è§’å›¾åƒï¼Œä½†ç§»åŠ¨ç›¸æœºçš„è¿‡ç¨‹è€—æ—¶ä¸”å—é™äºå¯è¾¾æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ–°è§†è§’åˆæˆæŠ€æœ¯ï¼Œé€šè¿‡ç”Ÿæˆè™šæ‹Ÿå›¾åƒæ¥æä¾›é¢å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»è€Œæ”¹å–„æŠ“å–å§¿æ€çš„ç”Ÿæˆã€‚æ­¤æ–¹æ³•èƒ½å¤Ÿåœ¨ä¸å®é™…ç§»åŠ¨ç›¸æœºçš„æƒ…å†µä¸‹ï¼Œè·å¾—æ›´å¤šçš„åœºæ™¯ä¿¡æ¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é‡‡é›†ã€è§†è§’åˆæˆã€æŠ“å–å§¿æ€ç”Ÿæˆä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œä½¿ç”¨Gaussian Splattingç­‰æŠ€æœ¯ç”Ÿæˆè™šæ‹Ÿè§†è§’å›¾åƒï¼Œç„¶ååŸºäºè¿™äº›å›¾åƒç”ŸæˆæŠ“å–å§¿æ€ï¼Œæœ€åè¿›è¡Œè¯„ä¼°ä¸ä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºé€šè¿‡æ–°è§†è§’åˆæˆæä¾›é¢å¤–ä¿¡æ¯ï¼Œæ”¹å–„æŠ“å–å§¿æ€ç”Ÿæˆçš„å‡†ç¡®æ€§å’Œè¦†ç›–ç‡ã€‚è¿™ä¸ä¼ ç»Ÿæ–¹æ³•ä¾èµ–äºçœŸå®è§†è§’å›¾åƒçš„æ–¹å¼æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œä½¿ç”¨äº†Graspnet-1billionæ•°æ®é›†ï¼Œè®¾ç½®äº†é€‚å½“çš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–æŠ“å–å§¿æ€çš„ç”Ÿæˆï¼ŒåŒæ—¶é‡‡ç”¨äº†å¤šè§†è§’åˆæˆæŠ€æœ¯ä»¥æå‡æŠ“å–æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œåˆ©ç”¨æ–°è§†è§’åˆæˆæŠ€æœ¯ï¼Œç”Ÿæˆçš„æŠ“å–å§¿æ€æ•°é‡æ˜¾è‘—å¢åŠ ï¼ŒåŠ›é—­åˆæŠ“å–çš„æ•°é‡æå‡ï¼ŒåŒæ—¶æŠ“å–è¦†ç›–ç‡ä¹Ÿå¾—åˆ°äº†æ”¹å–„ã€‚å…·ä½“è€Œè¨€ï¼Œå®éªŒæ˜¾ç¤ºæ–°è§†è§’åˆæˆç›¸è¾ƒäºç¨€ç–çœŸå®è§†è§’å›¾åƒï¼Œèƒ½å¤Ÿæä¾›æ›´ä¸°å¯Œçš„æŠ“å–ä¿¡æ¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶åœ¨æœºå™¨äººæŠ“å–ã€è‡ªåŠ¨åŒ–ä»“å‚¨å’Œæ™ºèƒ½åˆ¶é€ ç­‰é¢†åŸŸã€‚é€šè¿‡æé«˜æŠ“å–å§¿æ€çš„å‡†ç¡®æ€§å’Œè¦†ç›–ç‡ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„æ“ä½œèƒ½åŠ›ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æœºå™¨äººæŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision based robot manipulation uses cameras to capture one or more images of a scene containing the objects to be manipulated. Taking multiple images can help if any object is occluded from one viewpoint but more visible from another viewpoint. However, the camera has to be moved to a sequence of suitable positions for capturing multiple images, which requires time and may not always be possible, due to reachability constraints. So while additional images can produce more accurate grasp poses due to the extra information available, the time-cost goes up with the number of additional views sampled. Scene representations like Gaussian Splatting are capable of rendering accurate photorealistic virtual images from user-specified novel viewpoints. In this work, we show initial results which indicate that novel view synthesis can provide additional context in generating grasp poses. Our experiments on the Graspnet-1billion dataset show that novel views contributed force-closure grasps in addition to the force-closure grasps obtained from sparsely sampled real views while also improving grasp coverage. In the future we hope this work can be extended to improve grasp extraction from radiance fields constructed with a single input image, using for example diffusion models or generalizable radiance fields.

