---
layout: default
title: Parkour in the Wild: Learning a General and Extensible Agile Locomotion Policy Using Multi-expert Distillation and RL Fine-tuning
---

# Parkour in the Wild: Learning a General and Extensible Agile Locomotion Policy Using Multi-expert Distillation and RL Fine-tuning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.11164" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.11164v1</a>
  <a href="https://arxiv.org/pdf/2505.11164.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.11164v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.11164v1', 'Parkour in the Wild: Learning a General and Extensible Agile Locomotion Policy Using Multi-expert Distillation and RL Fine-tuning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Nikita Rudin, Junzhe He, Joshua Aurand, Marco Hutter

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-05-16

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šä¸“å®¶è’¸é¦ä¸å¼ºåŒ–å­¦ä¹ ç»“åˆçš„çµæ´»æ­¥æ€æ§åˆ¶æ¡†æ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è…¿å¼æœºå™¨äºº` `å¤šä¸“å®¶è’¸é¦` `å¼ºåŒ–å­¦ä¹ ` `æ­¥æ€æ§åˆ¶` `ç¯å¢ƒé€‚åº”æ€§` `å¤æ‚åœ°å½¢` `æœºå™¨äººå¯¼èˆª`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è…¿å¼æœºå™¨äººæ§åˆ¶æ–¹æ³•åœ¨å¤šæ ·åŒ–å’Œéç»“æ„åŒ–ç¯å¢ƒä¸­çš„æ³›åŒ–èƒ½åŠ›ä¸è¶³ï¼Œé™åˆ¶äº†å…¶åº”ç”¨èŒƒå›´ã€‚
2. æœ¬æ–‡æå‡ºçš„æ¡†æ¶ç»“åˆäº†å¤šä¸“å®¶è’¸é¦ä¸å¼ºåŒ–å­¦ä¹ å¾®è°ƒï¼Œé€šè¿‡è®­ç»ƒç‰¹å®šåœ°å½¢çš„ä¸“å®¶ç­–ç•¥æ¥æå‡æ­¥æ€æŠ€èƒ½ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šåœ°å½¢æŠ€èƒ½åˆæˆæ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå±•ç¤ºäº†åœ¨å¤æ‚ç¯å¢ƒä¸­çš„ä¼˜è¶Šæ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è…¿å¼æœºå™¨äººåœ¨å¤æ‚åœ°å½¢ä¸­è¡¨ç°å‡ºè‰²ï¼Œé€‚ç”¨äºæœç´¢æ•‘æ´å’Œå¤ªç©ºæ¢ç´¢ç­‰åº”ç”¨ã€‚ç„¶è€Œï¼Œç°æœ‰æ§åˆ¶æ–¹æ³•åœ¨å¤šæ ·åŒ–å’Œéç»“æ„åŒ–ç¯å¢ƒä¸­çš„æ³›åŒ–èƒ½åŠ›è¾ƒå¼±ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„çµæ´»æ­¥æ€æ§åˆ¶æ¡†æ¶ï¼Œé€šè¿‡ç»“åˆå¤šä¸“å®¶è’¸é¦ä¸å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å¾®è°ƒï¼Œå®ç°äº†ç¨³å¥çš„æ³›åŒ–èƒ½åŠ›ã€‚é¦–å…ˆï¼Œé’ˆå¯¹ç‰¹å®šåœ°å½¢è®­ç»ƒä¸“å®¶ç­–ç•¥ä»¥å‘å±•ä¸“é—¨çš„æ­¥æ€æŠ€èƒ½ï¼Œç„¶åé€šè¿‡DAggerç®—æ³•å°†è¿™äº›ç­–ç•¥è’¸é¦ä¸ºç»Ÿä¸€çš„åŸºç¡€ç­–ç•¥ã€‚æ¥ç€ï¼Œåœ¨æ›´å¹¿æ³›çš„åœ°å½¢é›†ä¸Šå¯¹è’¸é¦ç­–ç•¥è¿›è¡ŒRLå¾®è°ƒï¼Œå…è®¸é€šè¿‡é‡å¤å¾®è°ƒè¿›ä¸€æ­¥é€‚åº”æ–°åœ°å½¢ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨åˆæˆå¤šåœ°å½¢æŠ€èƒ½æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶åœ¨ANYmal Dæœºå™¨äººä¸ŠéªŒè¯äº†å…¶åœ¨å¤æ‚ç¯å¢ƒä¸­çš„çµæ´»æ€§å’Œé²æ£’æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è…¿å¼æœºå™¨äººåœ¨å¤šæ ·åŒ–å’Œéç»“æ„åŒ–ç¯å¢ƒä¸­æ§åˆ¶ç­–ç•¥æ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•æœ‰æ•ˆåº”å¯¹ä¸åŒåœ°å½¢çš„æŒ‘æˆ˜ï¼Œé™åˆ¶äº†æœºå™¨äººçš„åº”ç”¨æ½œåŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„æ ¸å¿ƒæ€è·¯æ˜¯ç»“åˆå¤šä¸“å®¶è’¸é¦ä¸å¼ºåŒ–å­¦ä¹ å¾®è°ƒï¼Œé¦–å…ˆè®­ç»ƒé’ˆå¯¹ç‰¹å®šåœ°å½¢çš„ä¸“å®¶ç­–ç•¥ï¼Œç„¶åå°†å…¶è’¸é¦ä¸ºç»Ÿä¸€çš„åŸºç¡€ç­–ç•¥ï¼Œæœ€ååœ¨æ›´å¹¿æ³›çš„åœ°å½¢ä¸Šè¿›è¡Œå¾®è°ƒï¼Œä»¥å®ç°æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼šé¦–å…ˆï¼Œé’ˆå¯¹ä¸åŒåœ°å½¢è®­ç»ƒå¤šä¸ªä¸“å®¶ç­–ç•¥ï¼›å…¶æ¬¡ï¼Œé€šè¿‡DAggerç®—æ³•å°†è¿™äº›ä¸“å®¶ç­–ç•¥è’¸é¦ä¸ºä¸€ä¸ªåŸºç¡€ç­–ç•¥ï¼›æœ€åï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ å¯¹è’¸é¦åçš„ç­–ç•¥è¿›è¡Œå¾®è°ƒï¼Œä»¥é€‚åº”æ–°çš„åœ°å½¢ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†å¤šä¸“å®¶è’¸é¦ä¸å¼ºåŒ–å­¦ä¹ å¾®è°ƒç›¸ç»“åˆï¼Œå½¢æˆäº†ä¸€ç§æ–°çš„æ­¥æ€æ§åˆ¶ç­–ç•¥ã€‚è¿™ç§æ–¹æ³•ä¸ç°æœ‰çš„å•ä¸€ä¸“å®¶ç­–ç•¥æˆ–ç®€å•çš„å¾®è°ƒæ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°åº”å¯¹å¤æ‚ç¯å¢ƒã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œè®ºæ–‡é‡‡ç”¨äº†æ·±åº¦å›¾åƒä½œä¸ºå¤–éƒ¨è¾“å…¥ï¼Œè®¾è®¡äº†é€‚åº”æ€§å¼ºçš„æŸå¤±å‡½æ•°ï¼Œå¹¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†ä¼˜åŒ–ï¼Œä»¥ç¡®ä¿ç­–ç•¥åœ¨å¤šæ ·åŒ–åœ°å½¢ä¸Šçš„é²æ£’æ€§ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œæ¶æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æå‡ºçš„æ¡†æ¶åœ¨å¤šåœ°å½¢æŠ€èƒ½åˆæˆæ–¹é¢ç›¸æ¯”ç°æœ‰æ–¹æ³•æœ‰æ˜¾è‘—æå‡ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨å¤šç§å¤æ‚ç¯å¢ƒä¸­ï¼ŒANYmal Dæœºå™¨äººèƒ½å¤Ÿä»¥æ›´é«˜çš„çµæ´»æ€§å’Œé²æ£’æ€§å®Œæˆä»»åŠ¡ï¼Œæ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°XX%ï¼ˆå…·ä½“æ•°æ®éœ€æŸ¥é˜…åŸæ–‡ï¼‰ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœç´¢ä¸æ•‘æ´ã€ç¾åé‡å»ºã€ä»¥åŠå¤ªç©ºæ¢ç´¢ç­‰åœºæ™¯ã€‚é€šè¿‡æå‡è…¿å¼æœºå™¨äººåœ¨å¤æ‚å’Œå¤šå˜ç¯å¢ƒä¸­çš„å¯¼èˆªèƒ½åŠ›ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿä¸ºå®é™…ä»»åŠ¡æä¾›æ›´é«˜çš„çµæ´»æ€§å’Œé€‚åº”æ€§ï¼Œæ¨åŠ¨æœºå™¨äººæŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Legged robots are well-suited for navigating terrains inaccessible to wheeled robots, making them ideal for applications in search and rescue or space exploration. However, current control methods often struggle to generalize across diverse, unstructured environments. This paper introduces a novel framework for agile locomotion of legged robots by combining multi-expert distillation with reinforcement learning (RL) fine-tuning to achieve robust generalization. Initially, terrain-specific expert policies are trained to develop specialized locomotion skills. These policies are then distilled into a unified foundation policy via the DAgger algorithm. The distilled policy is subsequently fine-tuned using RL on a broader terrain set, including real-world 3D scans. The framework allows further adaptation to new terrains through repeated fine-tuning. The proposed policy leverages depth images as exteroceptive inputs, enabling robust navigation across diverse, unstructured terrains. Experimental results demonstrate significant performance improvements over existing methods in synthesizing multi-terrain skills into a single controller. Deployment on the ANYmal D robot validates the policy's ability to navigate complex environments with agility and robustness, setting a new benchmark for legged robot locomotion.

