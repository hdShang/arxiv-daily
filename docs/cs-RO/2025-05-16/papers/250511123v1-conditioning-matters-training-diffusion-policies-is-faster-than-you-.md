---
layout: default
title: Conditioning Matters: Training Diffusion Policies is Faster Than You Think
---

# Conditioning Matters: Training Diffusion Policies is Faster Than You Think

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.11123" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.11123v1</a>
  <a href="https://arxiv.org/pdf/2505.11123.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.11123v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.11123v1', 'Conditioning Matters: Training Diffusion Policies is Faster Than You Think')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zibin Dong, Yicheng Liu, Yinchuan Li, Hang Zhao, Jianye Hao

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-16

**å¤‡æ³¨**: arXiv admin note: substantial text overlap with arXiv:2505.10105

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCocosä»¥è§£å†³æ¡ä»¶æ‰©æ•£ç­–ç•¥è®­ç»ƒæ•ˆç‡ä½ä¸‹é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ‰©æ•£ç­–ç•¥` `æ¡ä»¶æµåŒ¹é…` `æœºå™¨äººæ§åˆ¶` `å¤šæ¨¡æ€å­¦ä¹ ` `è®­ç»ƒæ•ˆç‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ¡ä»¶æ‰©æ•£ç­–ç•¥è®­ç»ƒæ•ˆç‡ä½ä¸‹ï¼Œå°¤å…¶åœ¨ç”Ÿæˆæ¡ä»¶éš¾ä»¥åŒºåˆ†æ—¶ï¼Œè®­ç»ƒç›®æ ‡ä¼šé€€åŒ–ï¼Œå¯¼è‡´æŸå¤±å´©æºƒã€‚
2. æå‡ºCocosï¼Œé€šè¿‡ä½¿æ¡ä»¶æµåŒ¹é…ä¸­çš„æºåˆ†å¸ƒä¾èµ–äºæ¡ä»¶ï¼Œå¢å¼ºæ¡ä»¶æ•´åˆï¼Œé˜²æ­¢æŸå¤±å´©æºƒï¼Œä»è€Œæé«˜è®­ç»ƒæ•ˆç‡ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCocosåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æ›´å¿«çš„æ”¶æ•›å’Œæ›´é«˜çš„æˆåŠŸç‡ï¼Œæ˜¾è‘—å‡å°‘äº†æ¢¯åº¦æ­¥éª¤å’Œå‚æ•°éœ€æ±‚ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ‰©æ•£ç­–ç•¥å·²æˆä¸ºæ„å»ºè§†è§‰-è¯­è¨€-è¡ŒåŠ¨ï¼ˆVLAï¼‰æ¨¡å‹çš„ä¸»æµèŒƒå¼ï¼Œå°½ç®¡å…¶åœ¨æœºå™¨äººæ§åˆ¶æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†è®­ç»ƒæ•ˆç‡ä»ä¸ç†æƒ³ã€‚æœ¬æ–‡è¯†åˆ«å‡ºæ¡ä»¶æ‰©æ•£ç­–ç•¥è®­ç»ƒä¸­çš„ä¸€ä¸ªåŸºæœ¬æŒ‘æˆ˜ï¼šå½“ç”Ÿæˆæ¡ä»¶éš¾ä»¥åŒºåˆ†æ—¶ï¼Œè®­ç»ƒç›®æ ‡é€€åŒ–ä¸ºå»ºæ¨¡è¾¹é™…åŠ¨ä½œåˆ†å¸ƒï¼Œè¿™ä¸€ç°è±¡ç§°ä¸ºæŸå¤±å´©æºƒã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†Cocosï¼Œè¿™æ˜¯ä¸€ç§ç®€å•è€Œé€šç”¨çš„è§£å†³æ–¹æ¡ˆï¼Œé€šè¿‡ä½¿æ¡ä»¶æµåŒ¹é…ä¸­çš„æºåˆ†å¸ƒä¾èµ–äºæ¡ä»¶ï¼Œæ¥å¢å¼ºæ¡ä»¶æ•´åˆå¹¶é˜²æ­¢æŸå¤±å´©æºƒã€‚æˆ‘ä»¬æä¾›äº†ç†è®ºä¾æ®å’Œå¹¿æ³›çš„å®è¯ç»“æœï¼Œè¡¨æ˜è¯¥æ–¹æ³•åœ¨æ¨¡æ‹Ÿå’Œç°å®ä¸–ç•ŒåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æ›´å¿«çš„æ”¶æ•›å’Œæ›´é«˜çš„æˆåŠŸç‡ï¼Œä½¿ç”¨æ˜¾è‘—æ›´å°‘çš„æ¢¯åº¦æ­¥éª¤å’Œå‚æ•°ï¼ŒåŒ¹é…äº†å¤§è§„æ¨¡é¢„è®­ç»ƒVLAçš„æ€§èƒ½ã€‚Cocosè½»é‡ã€æ˜“äºå®ç°ï¼Œå¹¶å…¼å®¹å¤šç§ç­–ç•¥æ¶æ„ï¼Œä¸ºæ‰©æ•£ç­–ç•¥è®­ç»ƒæä¾›äº†é€šç”¨çš„æ”¹è¿›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ¡ä»¶æ‰©æ•£ç­–ç•¥è®­ç»ƒä¸­çš„æ•ˆç‡ä½ä¸‹é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨ç”Ÿæˆæ¡ä»¶éš¾ä»¥åŒºåˆ†æ—¶ï¼Œè®­ç»ƒç›®æ ‡ä¼šé€€åŒ–ä¸ºå»ºæ¨¡è¾¹é™…åŠ¨ä½œåˆ†å¸ƒï¼Œé€ æˆæŸå¤±å´©æºƒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šCocosçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ä¿®æ”¹æ¡ä»¶æµåŒ¹é…ä¸­çš„æºåˆ†å¸ƒï¼Œä½¿å…¶ä¾èµ–äºæ¡ä»¶è¾“å…¥æå–çš„è¯­ä¹‰ï¼Œä»è€Œå¢å¼ºæ¡ä»¶æ•´åˆï¼Œé˜²æ­¢æŸå¤±å´©æºƒã€‚è¿™æ ·çš„è®¾è®¡èƒ½å¤Ÿæœ‰æ•ˆæé«˜è®­ç»ƒçš„ç¨³å®šæ€§å’Œæ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCocosçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ¡ä»¶æµåŒ¹é…æ¨¡å—å’Œæºåˆ†å¸ƒè°ƒæ•´æ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡æ¡ä»¶è¾“å…¥æå–è¯­ä¹‰ä¿¡æ¯ï¼Œç„¶åæ ¹æ®è¿™äº›ä¿¡æ¯è°ƒæ•´æºåˆ†å¸ƒï¼Œä»¥å®ç°æ›´æœ‰æ•ˆçš„æ¡ä»¶æ•´åˆã€‚

**å…³é”®åˆ›æ–°**ï¼šCocosçš„ä¸»è¦åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§æ¡ä»¶ä¾èµ–çš„æºåˆ†å¸ƒè°ƒæ•´æ–¹æ³•ï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„è¾¹é™…åŠ¨ä½œåˆ†å¸ƒå»ºæ¨¡å½¢æˆäº†æœ¬è´¨åŒºåˆ«ï¼Œèƒ½å¤Ÿæœ‰æ•ˆé˜²æ­¢æŸå¤±å´©æºƒç°è±¡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼ŒCocosé‡‡ç”¨äº†è½»é‡çº§çš„ç½‘ç»œç»“æ„ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸Šå¼ºè°ƒæ¡ä»¶æ•´åˆçš„æœ‰æ•ˆæ€§ï¼Œç¡®ä¿åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­èƒ½å¤Ÿå¿«é€Ÿæ”¶æ•›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒCocosåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æ¯”ç°æœ‰æ–¹æ³•æ›´å¿«çš„æ”¶æ•›é€Ÿåº¦å’Œæ›´é«˜çš„æˆåŠŸç‡ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨ç›¸åŒä»»åŠ¡ä¸‹ï¼Œå‡å°‘äº†50%çš„æ¢¯åº¦æ­¥éª¤ï¼ŒåŒæ—¶ä¿æŒäº†ä¸å¤§è§„æ¨¡é¢„è®­ç»ƒVLAç›¸å½“çš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæ§åˆ¶ã€è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½å®¶å±…ç­‰å¤šæ¨¡æ€äº¤äº’åœºæ™¯ã€‚é€šè¿‡æé«˜æ‰©æ•£ç­–ç•¥çš„è®­ç»ƒæ•ˆç‡ï¼ŒCocosèƒ½å¤ŸåŠ é€Ÿç›¸å…³åº”ç”¨çš„å¼€å‘å’Œéƒ¨ç½²ï¼Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿçš„å®é™…åº”ç”¨å’Œæ™®åŠã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Diffusion policies have emerged as a mainstream paradigm for building vision-language-action (VLA) models. Although they demonstrate strong robot control capabilities, their training efficiency remains suboptimal. In this work, we identify a fundamental challenge in conditional diffusion policy training: when generative conditions are hard to distinguish, the training objective degenerates into modeling the marginal action distribution, a phenomenon we term loss collapse. To overcome this, we propose Cocos, a simple yet general solution that modifies the source distribution in the conditional flow matching to be condition-dependent. By anchoring the source distribution around semantics extracted from condition inputs, Cocos encourages stronger condition integration and prevents the loss collapse. We provide theoretical justification and extensive empirical results across simulation and real-world benchmarks. Our method achieves faster convergence and higher success rates than existing approaches, matching the performance of large-scale pre-trained VLAs using significantly fewer gradient steps and parameters. Cocos is lightweight, easy to implement, and compatible with diverse policy architectures, offering a general-purpose improvement to diffusion policy training.

