---
layout: default
title: Object-Centric Representations Improve Policy Generalization in Robot Manipulation
---

# Object-Centric Representations Improve Policy Generalization in Robot Manipulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.11563" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.11563v1</a>
  <a href="https://arxiv.org/pdf/2505.11563.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.11563v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.11563v1', 'Object-Centric Representations Improve Policy Generalization in Robot Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Alexandre Chapin, Bruno Machado, Emmanuel Dellandrea, Liming Chen

**åˆ†ç±»**: cs.RO, cs.AI, eess.IV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-16

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¯¹è±¡ä¸­å¿ƒè¡¨ç¤ºä»¥æå‡æœºå™¨äººæ“ä½œç­–ç•¥çš„æ³›åŒ–èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `å¯¹è±¡ä¸­å¿ƒè¡¨ç¤º` `æœºå™¨äººæ“ä½œ` `è§†è§‰è¡¨ç¤º` `ç­–ç•¥æ³›åŒ–` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å…¨å±€å’Œå¯†é›†ç‰¹å¾æ–¹æ³•åœ¨å¤„ç†ä»»åŠ¡ç›¸å…³å’Œæ— å…³ä¿¡æ¯æ—¶å­˜åœ¨æ··æ·†ï¼Œé™åˆ¶äº†ç­–ç•¥çš„é²æ£’æ€§ã€‚
2. æœ¬æ–‡æå‡ºå¯¹è±¡ä¸­å¿ƒè¡¨ç¤ºï¼ˆOCRï¼‰ï¼Œé€šè¿‡å°†è§†è§‰è¾“å…¥åˆ†å‰²ä¸ºç‹¬ç«‹å®ä½“ï¼Œå¢å¼ºäº†ä¸æ“ä½œä»»åŠ¡çš„åŒ¹é…æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒOCRç­–ç•¥åœ¨å¤šç§è§†è§‰æ¡ä»¶ä¸‹çš„æ³›åŒ–èƒ½åŠ›æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œä¸”æ— éœ€ä»»åŠ¡ç‰¹å®šçš„é¢„è®­ç»ƒã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰è¡¨ç¤ºåœ¨æœºå™¨äººæ“ä½œç­–ç•¥çš„å­¦ä¹ å’Œæ³›åŒ–èƒ½åŠ›ä¸­è‡³å…³é‡è¦ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºå…¨å±€æˆ–å¯†é›†ç‰¹å¾ï¼Œè¿™äº›è¡¨ç¤ºå¾€å¾€å°†ä»»åŠ¡ç›¸å…³å’Œæ— å…³çš„åœºæ™¯ä¿¡æ¯æ··åˆåœ¨ä¸€èµ·ï¼Œé™åˆ¶äº†åœ¨åˆ†å¸ƒå˜åŒ–ä¸‹çš„é²æ£’æ€§ã€‚æœ¬æ–‡æ¢è®¨äº†å¯¹è±¡ä¸­å¿ƒè¡¨ç¤ºï¼ˆOCRï¼‰ä½œä¸ºä¸€ç§ç»“æ„åŒ–æ›¿ä»£æ–¹æ¡ˆï¼Œå°†è§†è§‰è¾“å…¥åˆ†å‰²ä¸ºä¸€ç»„å®Œæˆçš„å®ä½“ï¼Œå¼•å…¥äº†ä¸æ“ä½œä»»åŠ¡æ›´è‡ªç„¶å¯¹é½çš„å½’çº³åç½®ã€‚æˆ‘ä»¬åœ¨ä¸€ç³»åˆ—æ¨¡æ‹Ÿå’Œç°å®ä¸–ç•Œçš„æ“ä½œä»»åŠ¡ä¸­å¯¹ä¸åŒçš„è§†è§‰ç¼–ç å™¨è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼Œè¯„ä¼°å…¶åœ¨å¤šç§è§†è§‰æ¡ä»¶ä¸‹çš„æ³›åŒ–èƒ½åŠ›ã€‚ç ”ç©¶å‘ç°ï¼ŒåŸºäºOCRçš„ç­–ç•¥åœ¨æ³›åŒ–è®¾ç½®ä¸­ä¼˜äºå¯†é›†å’Œå…¨å±€è¡¨ç¤ºï¼Œå³ä½¿æ²¡æœ‰ç‰¹å®šä»»åŠ¡çš„é¢„è®­ç»ƒã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼ŒOCRæ˜¯è®¾è®¡èƒ½å¤Ÿæœ‰æ•ˆæ³›åŒ–çš„åŠ¨æ€ç°å®æœºå™¨äººç¯å¢ƒè§†è§‰ç³»ç»Ÿçš„æœ‰å‰æ™¯æ–¹å‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰è§†è§‰è¡¨ç¤ºæ–¹æ³•åœ¨æœºå™¨äººæ“ä½œä¸­å¯¹ä»»åŠ¡ç›¸å…³å’Œæ— å…³ä¿¡æ¯çš„æ··æ·†é—®é¢˜ï¼Œå¯¼è‡´ç­–ç•¥åœ¨åˆ†å¸ƒå˜åŒ–ä¸‹çš„é²æ£’æ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºå¯¹è±¡ä¸­å¿ƒè¡¨ç¤ºï¼ˆOCRï¼‰ï¼Œå°†è§†è§‰è¾“å…¥åˆ†å‰²ä¸ºç‹¬ç«‹çš„å¯¹è±¡å®ä½“ï¼Œåˆ©ç”¨å½’çº³åç½®æ›´è‡ªç„¶åœ°é€‚åº”æ“ä½œä»»åŠ¡ï¼Œä»è€Œæå‡ç­–ç•¥çš„æ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬è§†è§‰è¾“å…¥çš„å¯¹è±¡åˆ†å‰²ã€ç‰¹å¾æå–å’Œç­–ç•¥å­¦ä¹ ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡OCRå¯¹è¾“å…¥å›¾åƒè¿›è¡Œå¤„ç†ï¼Œæå–å‡ºå„ä¸ªå¯¹è±¡çš„ç‰¹å¾ï¼Œç„¶åå°†è¿™äº›ç‰¹å¾è¾“å…¥åˆ°ç­–ç•¥ç½‘ç»œä¸­è¿›è¡Œè®­ç»ƒå’Œä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥å¯¹è±¡ä¸­å¿ƒè¡¨ç¤ºï¼Œæ˜¾è‘—æ”¹å–„äº†ç­–ç•¥åœ¨ä¸åŒè§†è§‰æ¡ä»¶ä¸‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œä¸ä¼ ç»Ÿçš„å…¨å±€å’Œå¯†é›†ç‰¹å¾æ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†æ›´æ¸…æ™°çš„ä»»åŠ¡ç›¸å…³ä¿¡æ¯ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼ŒOCRæ¨¡å—é‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–å¯¹è±¡åˆ†å‰²çš„å‡†ç¡®æ€§ï¼ŒåŒæ—¶ç½‘ç»œç»“æ„è®¾è®¡ä¸Šç»“åˆäº†å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å’Œæ³¨æ„åŠ›æœºåˆ¶ï¼Œä»¥å¢å¼ºç‰¹å¾æå–çš„æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŸºäºOCRçš„ç­–ç•¥åœ¨å¤šç§è§†è§‰æ¡ä»¶ä¸‹çš„æ³›åŒ–èƒ½åŠ›æ˜¾è‘—ä¼˜äºå¯†é›†å’Œå…¨å±€è¡¨ç¤ºï¼Œå°¤å…¶åœ¨å…‰ç…§ã€çº¹ç†å˜åŒ–å’Œå¹²æ‰°ç‰©å­˜åœ¨çš„æƒ…å†µä¸‹ï¼Œè¡¨ç°å‡ºæ›´é«˜çš„é²æ£’æ€§ï¼Œæå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæŠ“å–ã€è£…é…å’Œå…¶ä»–éœ€è¦è§†è§‰ç†è§£çš„æ“ä½œä»»åŠ¡ã€‚é€šè¿‡æå‡ç­–ç•¥çš„æ³›åŒ–èƒ½åŠ›ï¼ŒOCRå¯ä»¥åœ¨åŠ¨æ€å’Œå¤æ‚çš„ç°å®ç¯å¢ƒä¸­æ›´æœ‰æ•ˆåœ°æ‰§è¡Œä»»åŠ¡ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Visual representations are central to the learning and generalization capabilities of robotic manipulation policies. While existing methods rely on global or dense features, such representations often entangle task-relevant and irrelevant scene information, limiting robustness under distribution shifts. In this work, we investigate object-centric representations (OCR) as a structured alternative that segments visual input into a finished set of entities, introducing inductive biases that align more naturally with manipulation tasks. We benchmark a range of visual encoders-object-centric, global and dense methods-across a suite of simulated and real-world manipulation tasks ranging from simple to complex, and evaluate their generalization under diverse visual conditions including changes in lighting, texture, and the presence of distractors. Our findings reveal that OCR-based policies outperform dense and global representations in generalization settings, even without task-specific pretraining. These insights suggest that OCR is a promising direction for designing visual systems that generalize effectively in dynamic, real-world robotic environments.

