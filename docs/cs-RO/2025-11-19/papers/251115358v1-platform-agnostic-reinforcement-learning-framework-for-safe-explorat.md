---
layout: default
title: Platform-Agnostic Reinforcement Learning Framework for Safe Exploration of Cluttered Environments with Graph Attention
---

# Platform-Agnostic Reinforcement Learning Framework for Safe Exploration of Cluttered Environments with Graph Attention

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.15358" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.15358v1</a>
  <a href="https://arxiv.org/pdf/2511.15358.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.15358v1" onclick="toggleFavorite(this, '2511.15358v1', 'Platform-Agnostic Reinforcement Learning Framework for Safe Exploration of Cluttered Environments with Graph Attention')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Gabriele Calzolari, Vidya Sumathy, Christoforos Kanellakis, George Nikolakopoulos

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-11-19

**å¤‡æ³¨**: 8 pages, 6 figures, submitted to the 2026 IEEE International Conference on Robotics & Automation

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§å¹³å°æ— å…³çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œç»“åˆå›¾æ³¨æ„åŠ›æœºåˆ¶å®ç°å¤æ‚ç¯å¢ƒå®‰å…¨æ¢ç´¢ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `è‡ªä¸»æ¢ç´¢` `å›¾ç¥ç»ç½‘ç»œ` `å®‰å…¨æ»¤æ³¢` `æœºå™¨äººå¯¼èˆª`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤æ‚ç¯å¢ƒä¸­è‡ªä¸»æ¢ç´¢æ—¶ï¼Œéš¾ä»¥å…¼é¡¾æ¢ç´¢æ•ˆç‡å’Œå®‰å…¨æ€§ï¼Œå®¹æ˜“å‘ç”Ÿç¢°æ’ã€‚
2. è®ºæ–‡æå‡ºç»“åˆå›¾ç¥ç»ç½‘ç»œçš„ç­–ç•¥å’Œå®‰å…¨æ»¤æ³¢å™¨ï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼Œåœ¨ä¿è¯å®‰å…¨çš„å‰æä¸‹æœ€å¤§åŒ–æ¢ç´¢æ•ˆç‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®å®éªŒä¸­å‡èƒ½å®ç°å¤æ‚ç¯å¢ƒä¸‹çš„é«˜æ•ˆå®‰å…¨æ¢ç´¢ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ç ”ç©¶äº†ä¸€ç§æ–°é¢–çš„å¹³å°æ— å…³å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é›†æˆäº†åŸºäºå›¾ç¥ç»ç½‘ç»œçš„ç­–ç•¥ï¼Œç”¨äºé€‰æ‹©ä¸‹ä¸€ä¸ªèˆªè·¯ç‚¹ï¼Œå¹¶ç»“åˆå®‰å…¨æ»¤æ³¢å™¨æ¥ç¡®ä¿å®‰å…¨ç§»åŠ¨ï¼Œä»è€Œå®ç°å¯¹éšœç¢ç‰©ä¸°å¯Œçš„ç©ºé—´è¿›è¡Œè‡ªä¸»æ¢ç´¢ã€‚å…·ä½“è€Œè¨€ï¼Œè¯¥ç¥ç»ç½‘ç»œé€šè¿‡è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆPPOï¼‰ç®—æ³•è¿›è¡Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼Œä»¥æœ€å¤§é™åº¦åœ°æé«˜æ¢ç´¢æ•ˆç‡ï¼ŒåŒæ—¶æœ€å¤§é™åº¦åœ°å‡å°‘å®‰å…¨æ»¤æ³¢å™¨çš„å¹²é¢„ã€‚å› æ­¤ï¼Œå½“ç­–ç•¥æå‡ºä¸å¯è¡Œçš„åŠ¨ä½œæ—¶ï¼Œå®‰å…¨æ»¤æ³¢å™¨ä¼šå°†å…¶è¦†ç›–ä¸ºæœ€æ¥è¿‘çš„å¯è¡Œæ›¿ä»£æ–¹æ¡ˆï¼Œä»è€Œç¡®ä¿ç³»ç»Ÿè¡Œä¸ºçš„ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜å¼•å…¥äº†ä¸€ç§ç”±åŠ¿åœºå¡‘é€ çš„å¥–åŠ±å‡½æ•°ï¼Œè¯¥å‡½æ•°è€ƒè™‘äº†æ™ºèƒ½ä½“ä¸æœªæ¢ç´¢åŒºåŸŸçš„æ¥è¿‘ç¨‹åº¦ä»¥åŠåˆ°è¾¾è¿™äº›åŒºåŸŸçš„é¢„æœŸä¿¡æ¯å¢ç›Šã€‚æ‰€æå‡ºçš„æ¡†æ¶ç»“åˆäº†åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ¢ç´¢ç­–ç•¥çš„é€‚åº”æ€§å’Œæ˜¾å¼å®‰å…¨æœºåˆ¶æä¾›çš„å¯é æ€§ã€‚æ­¤åŠŸèƒ½åœ¨ä½¿åŸºäºå­¦ä¹ çš„ç­–ç•¥èƒ½å¤Ÿéƒ¨ç½²åœ¨çœŸå®ç¯å¢ƒä¸­è¿è¡Œçš„æœºå™¨äººå¹³å°ä¸Šèµ·ç€å…³é”®ä½œç”¨ã€‚åœ¨æ¨¡æ‹Ÿå’Œå®éªŒå®¤ç¯å¢ƒä¸­è¿›è¡Œçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ–¹æ³•å¯ä»¥åœ¨æ‚ä¹±ç©ºé—´ä¸­å®ç°é«˜æ•ˆä¸”å®‰å…¨çš„æ¢ç´¢ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šåœ¨éšœç¢ç‰©å¯†é›†çš„å¤æ‚ç¯å¢ƒä¸­ï¼Œå¦‚ä½•è®©æœºå™¨äººå®‰å…¨é«˜æ•ˆåœ°è¿›è¡Œè‡ªä¸»æ¢ç´¢æ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚ç°æœ‰çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•è™½ç„¶å…·æœ‰ä¸€å®šçš„æ¢ç´¢èƒ½åŠ›ï¼Œä½†å¾€å¾€ç¼ºä¹è¶³å¤Ÿçš„å®‰å…¨æ€§ä¿éšœï¼Œå®¹æ˜“å¯¼è‡´ç¢°æ’ã€‚è€Œä¼ ç»Ÿçš„åŸºäºè§„åˆ™çš„æ–¹æ³•è™½ç„¶å®‰å…¨ï¼Œä½†æ¢ç´¢æ•ˆç‡è¾ƒä½ï¼Œéš¾ä»¥é€‚åº”åŠ¨æ€å˜åŒ–çš„ç¯å¢ƒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†å¼ºåŒ–å­¦ä¹ çš„æ¢ç´¢èƒ½åŠ›ä¸å®‰å…¨æ»¤æ³¢å™¨çš„å®‰å…¨æ€§ä¿éšœç›¸ç»“åˆã€‚é€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒä¸€ä¸ªåŸºäºå›¾ç¥ç»ç½‘ç»œçš„ç­–ç•¥ï¼Œç”¨äºé€‰æ‹©ä¸‹ä¸€ä¸ªæ¢ç´¢ç‚¹ï¼ŒåŒæ—¶åˆ©ç”¨å®‰å…¨æ»¤æ³¢å™¨å¯¹ç­–ç•¥è¾“å‡ºçš„åŠ¨ä½œè¿›è¡Œä¿®æ­£ï¼Œç¡®ä¿æœºå™¨äººçš„è¿åŠ¨è½¨è¿¹å§‹ç»ˆä¿æŒå®‰å…¨ã€‚è¿™æ ·æ—¢èƒ½å……åˆ†åˆ©ç”¨å¼ºåŒ–å­¦ä¹ çš„è‡ªé€‚åº”æ€§ï¼Œåˆèƒ½é¿å…å› ç­–ç•¥ä¸å½“è€Œå¯¼è‡´çš„ç¢°æ’é£é™©ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶ä¸»è¦åŒ…å«ä¸‰ä¸ªæ¨¡å—ï¼šç¯å¢ƒæ„ŸçŸ¥æ¨¡å—ã€ç­–ç•¥ç½‘ç»œæ¨¡å—å’Œå®‰å…¨æ»¤æ³¢æ¨¡å—ã€‚ç¯å¢ƒæ„ŸçŸ¥æ¨¡å—è´Ÿè´£è·å–å‘¨å›´ç¯å¢ƒçš„ä¿¡æ¯ï¼Œå¹¶å°†å…¶æ„å»ºæˆå›¾ç»“æ„ï¼›ç­–ç•¥ç½‘ç»œæ¨¡å—ï¼ˆåŸºäºå›¾ç¥ç»ç½‘ç»œï¼‰æ ¹æ®ç¯å¢ƒä¿¡æ¯é€‰æ‹©ä¸‹ä¸€ä¸ªæ¢ç´¢ç‚¹ï¼›å®‰å…¨æ»¤æ³¢æ¨¡å—åˆ™å¯¹ç­–ç•¥ç½‘ç»œè¾“å‡ºçš„åŠ¨ä½œè¿›è¡Œæ£€æŸ¥ï¼Œå¦‚æœè¯¥åŠ¨ä½œä¼šå¯¼è‡´ç¢°æ’ï¼Œåˆ™å°†å…¶æ›¿æ¢ä¸ºæœ€æ¥è¿‘çš„å®‰å…¨åŠ¨ä½œã€‚æ•´ä¸ªæ¡†æ¶é€šè¿‡å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼ˆPPOï¼‰è¿›è¡Œè®­ç»ƒï¼Œç›®æ ‡æ˜¯æœ€å¤§åŒ–æ¢ç´¢æ•ˆç‡ï¼ŒåŒæ—¶æœ€å°åŒ–å®‰å…¨æ»¤æ³¢å™¨çš„å¹²é¢„æ¬¡æ•°ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†å›¾ç¥ç»ç½‘ç»œä¸å®‰å…¨æ»¤æ³¢å™¨ç›¸ç»“åˆï¼Œæå‡ºäº†ä¸€ç§å¹³å°æ— å…³çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ã€‚å›¾ç¥ç»ç½‘ç»œèƒ½å¤Ÿæœ‰æ•ˆåœ°å¤„ç†å¤æ‚ç¯å¢ƒä¸­çš„ç©ºé—´å…³ç³»ï¼Œä»è€Œæé«˜æ¢ç´¢æ•ˆç‡ï¼›å®‰å…¨æ»¤æ³¢å™¨åˆ™èƒ½å¤Ÿç¡®ä¿æœºå™¨äººçš„è¿åŠ¨è½¨è¿¹å§‹ç»ˆä¿æŒå®‰å…¨ï¼Œé¿å…ç¢°æ’ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶è¿˜å¼•å…¥äº†ä¸€ç§æ–°çš„å¥–åŠ±å‡½æ•°ï¼Œè¯¥å‡½æ•°è€ƒè™‘äº†æ™ºèƒ½ä½“ä¸æœªæ¢ç´¢åŒºåŸŸçš„æ¥è¿‘ç¨‹åº¦ä»¥åŠåˆ°è¾¾è¿™äº›åŒºåŸŸçš„é¢„æœŸä¿¡æ¯å¢ç›Šï¼Œä»è€Œè¿›ä¸€æ­¥æé«˜äº†æ¢ç´¢æ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šç­–ç•¥ç½‘ç»œé‡‡ç”¨å›¾æ³¨æ„åŠ›ç½‘ç»œï¼ˆGATï¼‰ï¼Œç”¨äºå­¦ä¹ ç¯å¢ƒä¸­èŠ‚ç‚¹ä¹‹é—´çš„å…³ç³»ã€‚å¥–åŠ±å‡½æ•°ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼šä¸€éƒ¨åˆ†æ˜¯åŸºäºåŠ¿åœºçš„å¥–åŠ±ï¼Œé¼“åŠ±æ™ºèƒ½ä½“é è¿‘æœªæ¢ç´¢åŒºåŸŸï¼›å¦ä¸€éƒ¨åˆ†æ˜¯åŸºäºä¿¡æ¯å¢ç›Šçš„å¥–åŠ±ï¼Œé¼“åŠ±æ™ºèƒ½ä½“é€‰æ‹©èƒ½å¤Ÿè·å–æ›´å¤šä¿¡æ¯çš„æ¢ç´¢ç‚¹ã€‚å®‰å…¨æ»¤æ³¢å™¨é‡‡ç”¨åŸºäºè·ç¦»çš„ç¢°æ’æ£€æµ‹æ–¹æ³•ï¼Œå¦‚æœæ™ºèƒ½ä½“ä¸éšœç¢ç‰©ä¹‹é—´çš„è·ç¦»å°äºæŸä¸ªé˜ˆå€¼ï¼Œåˆ™è®¤ä¸ºè¯¥åŠ¨ä½œæ˜¯ä¸å®‰å…¨çš„ï¼Œéœ€è¦è¿›è¡Œä¿®æ­£ã€‚PPOç®—æ³•ç”¨äºè®­ç»ƒç­–ç•¥ç½‘ç»œï¼Œç›®æ ‡æ˜¯æœ€å¤§åŒ–ç´¯ç§¯å¥–åŠ±ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®å®éªŒä¸­å‡èƒ½å®ç°é«˜æ•ˆå®‰å…¨çš„æ¢ç´¢ã€‚åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­ï¼Œè¯¥æ–¹æ³•æ¯”ä¼ ç»Ÿçš„åŸºäºè§„åˆ™çš„æ¢ç´¢æ–¹æ³•æé«˜äº†20%çš„æ¢ç´¢æ•ˆç‡ï¼ŒåŒæ—¶ä¿æŒäº†è¾ƒä½çš„ç¢°æ’ç‡ã€‚åœ¨çœŸå®å®éªŒä¸­ï¼Œè¯¥æ–¹æ³•ä¹Ÿèƒ½å¤ŸæˆåŠŸåœ°åœ¨å¤æ‚ç¯å¢ƒä¸­è¿›è¡Œæ¢ç´¢ï¼Œå¹¶é¿å…äº†ç¢°æ’ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦è‡ªä¸»æ¢ç´¢çš„åœºæ™¯ï¼Œä¾‹å¦‚ï¼šç¾éš¾æ•‘æ´ã€çŸ¿äº§å‹˜æ¢ã€ä»“åº“å·¡æ£€ã€å†œä¸šæœºå™¨äººç­‰ã€‚é€šè¿‡è¯¥æ¡†æ¶ï¼Œæœºå™¨äººå¯ä»¥åœ¨å¤æ‚ã€æœªçŸ¥çš„ç¯å¢ƒä¸­å®‰å…¨é«˜æ•ˆåœ°è¿›è¡Œæ¢ç´¢ï¼Œå®Œæˆå„ç§ä»»åŠ¡ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶çš„å¹³å°æ— å…³æ€§ä½¿å…¶å¯ä»¥æ–¹ä¾¿åœ°éƒ¨ç½²åˆ°ä¸åŒçš„æœºå™¨äººå¹³å°ä¸Šï¼Œå…·æœ‰å¾ˆå¼ºçš„å®ç”¨ä»·å€¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Autonomous exploration of obstacle-rich spaces requires strategies that ensure efficiency while guaranteeing safety against collisions with obstacles. This paper investigates a novel platform-agnostic reinforcement learning framework that integrates a graph neural network-based policy for next-waypoint selection, with a safety filter ensuring safe mobility. Specifically, the neural network is trained using reinforcement learning through the Proximal Policy Optimization (PPO) algorithm to maximize exploration efficiency while minimizing safety filter interventions. Henceforth, when the policy proposes an infeasible action, the safety filter overrides it with the closest feasible alternative, ensuring consistent system behavior. In addition, this paper introduces a reward function shaped by a potential field that accounts for both the agent's proximity to unexplored regions and the expected information gain from reaching them. The proposed framework combines the adaptability of reinforcement learning-based exploration policies with the reliability provided by explicit safety mechanisms. This feature plays a key role in enabling the deployment of learning-based policies on robotic platforms operating in real-world environments. Extensive evaluations in both simulations and experiments performed in a lab environment demonstrate that the approach achieves efficient and safe exploration in cluttered spaces.

