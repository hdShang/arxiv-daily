---
layout: default
title: "Symmetry-Breaking in Multi-Agent Navigation: Winding Number-Aware MPC with a Learned Topological Strategy"
---

# Symmetry-Breaking in Multi-Agent Navigation: Winding Number-Aware MPC with a Learned Topological Strategy

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.15239" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.15239v1</a>
  <a href="https://arxiv.org/pdf/2511.15239.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.15239v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.15239v1', 'Symmetry-Breaking in Multi-Agent Navigation: Winding Number-Aware MPC with a Learned Topological Strategy')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Tomoki Nakao, Kazumi Kasaura, Tadashi Kozuno

**åˆ†ç±»**: cs.RO, cs.MA

**å‘å¸ƒæ—¥æœŸ**: 2025-11-19

**å¤‡æ³¨**: 11 pages, 5 figures

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/omron-sinicx/WNumMPC)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºç»•æ•°æ„ŸçŸ¥çš„MPCæ–¹æ³•ï¼Œè§£å†³å¤šæ™ºèƒ½ä½“å¯¼èˆªä¸­çš„å¯¹ç§°æ€§ç ´ç¼ºé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `å¤šæ™ºèƒ½ä½“å¯¼èˆª` `å¯¹ç§°æ€§ç ´ç¼º` `ç»•æ•°` `å¼ºåŒ–å­¦ä¹ ` `æ¨¡å‹é¢„æµ‹æ§åˆ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤šæ™ºèƒ½ä½“å¯¼èˆªä¸­ï¼Œå¯¹ç§°æ€§å¯¼è‡´çš„æ­»é”é—®é¢˜æ˜¯æŒ‘æˆ˜ï¼Œæ™ºèƒ½ä½“éš¾ä»¥è‡ªä¸»å†³å®šé¿è®©æ–¹å¼ã€‚
2. åˆ©ç”¨ç»•æ•°è¿™ä¸€æ‹“æ‰‘ä¸å˜é‡é‡åŒ–åä½œç­–ç•¥ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ å­¦ä¹ å¯¹ç§°æ€§ç ´ç¼ºç­–ç•¥ã€‚
3. åˆ†å±‚ç­–ç•¥ç»“åˆå­¦ä¹ çš„å†³ç­–èƒ½åŠ›å’Œæ¨¡å‹çš„å¯é æ€§ï¼Œåœ¨å¯†é›†ç¯å¢ƒä¸­è¡¨ç°ä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„åˆ†å±‚å¯¼èˆªæ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³åˆ†å¸ƒå¼å¤šæ™ºèƒ½ä½“å¯¼èˆªä¸­ç”±å¯¹ç§°æ€§å¼•èµ·çš„æ­»é”è¿™ä¸€æ ¹æœ¬æŒ‘æˆ˜ã€‚å½“å¤šä¸ªæ™ºèƒ½ä½“äº¤äº’æ—¶ï¼Œè‡ªä¸»æ‰“ç ´ç›¸äº’é¿è®©æ–¹å¼çš„å¯¹ç§°æ€§éå¸¸å›°éš¾ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä½¿ç”¨ç§°ä¸ºç»•æ•°çš„æ‹“æ‰‘ä¸å˜é‡æ¥é‡åŒ–åä½œå¯¹ç§°æ€§ç ´ç¼ºç­–ç•¥ï¼Œå¹¶é€šè¿‡å¼ºåŒ–å­¦ä¹ æ¥å­¦ä¹ è¿™äº›ç­–ç•¥ã€‚æˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨åˆ†å±‚ç­–ç•¥ï¼ŒåŒ…æ‹¬ä¸€ä¸ªåŸºäºå­¦ä¹ çš„è§„åˆ’å™¨ï¼ˆPlannerï¼‰å’Œä¸€ä¸ªåŸºäºæ¨¡å‹çš„æ§åˆ¶å™¨ï¼ˆControllerï¼‰ã€‚é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼Œè§„åˆ’å™¨å­¦ä¹ ä¸ºæ§åˆ¶å™¨ç”Ÿæˆä¸¤ç§ç±»å‹çš„å‚æ•°ï¼šä¸€ç§æ˜¯ç”±ç»•æ•°è¡¨ç¤ºçš„æ‹“æ‰‘åä½œç­–ç•¥ï¼Œå¦ä¸€ç§æ˜¯åŠ¨æ€æƒé‡é›†ï¼Œç”¨äºç¡®å®šåœ¨å¤šä¸ªæ™ºèƒ½ä½“åŒæ—¶äº¤å‰çš„å¯†é›†åœºæ™¯ä¸­ä¼˜å…ˆè€ƒè™‘å“ªä¸ªæ™ºèƒ½ä½“äº¤äº’ã€‚ç„¶åï¼Œæ§åˆ¶å™¨æ ¹æ®è§„åˆ’å™¨æä¾›çš„ç­–ç•¥å’Œæƒé‡ç”Ÿæˆæ— ç¢°æ’ä¸”é«˜æ•ˆçš„è¿åŠ¨ã€‚è¿™ç§åˆ†å±‚ç»“æ„ç»“åˆäº†åŸºäºå­¦ä¹ çš„æ–¹æ³•çš„çµæ´»å†³ç­–èƒ½åŠ›å’ŒåŸºäºæ¨¡å‹çš„æ–¹æ³•çš„å¯é æ€§ã€‚ä»¿çœŸå’ŒçœŸå®æœºå™¨äººå®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºç°æœ‰çš„åŸºçº¿ï¼Œå°¤å…¶æ˜¯åœ¨å¯†é›†ç¯å¢ƒä¸­ï¼Œé€šè¿‡æœ‰æ•ˆåœ°é¿å…ç¢°æ’å’Œæ­»é”ï¼ŒåŒæ—¶å®ç°å“è¶Šçš„å¯¼èˆªæ€§èƒ½ã€‚å®éªŒä»£ç å·²åœ¨GitHubä¸Šå¼€æºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ™ºèƒ½ä½“å¯¼èˆªä¸­ï¼Œç”±äºå¯¹ç§°æ€§å¯¼è‡´çš„æ­»é”é—®é¢˜ã€‚å½“å¤šä¸ªæ™ºèƒ½ä½“éœ€è¦åœ¨åŒä¸€åŒºåŸŸå†…ç§»åŠ¨æ—¶ï¼Œå®ƒä»¬å¯èƒ½ä¼šé™·å…¥äº’ç›¸ç­‰å¾…çš„çŠ¶æ€ï¼Œæ— æ³•è‡ªä¸»å†³å®šå¦‚ä½•é¿è®©ï¼Œä»è€Œå¯¼è‡´å¯¼èˆªå¤±è´¥ã€‚ç°æœ‰çš„æ–¹æ³•é€šå¸¸éš¾ä»¥æœ‰æ•ˆåœ°æ‰“ç ´è¿™ç§å¯¹ç§°æ€§ï¼Œå°¤å…¶æ˜¯åœ¨æ™ºèƒ½ä½“å¯†åº¦è¾ƒé«˜çš„ç¯å¢ƒä¸­ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ‹“æ‰‘ä¸å˜é‡â€œç»•æ•°â€æ¥é‡åŒ–æ™ºèƒ½ä½“ä¹‹é—´çš„åä½œç­–ç•¥ï¼Œå¹¶é€šè¿‡å¼ºåŒ–å­¦ä¹ æ¥å­¦ä¹ è¿™äº›ç­–ç•¥ã€‚ç»•æ•°å¯ä»¥æè¿°æ™ºèƒ½ä½“å›´ç»•å½¼æ­¤è¿åŠ¨çš„åœˆæ•°ï¼Œä»è€Œåæ˜ äº†æ™ºèƒ½ä½“ä¹‹é—´çš„ç›¸å¯¹è¿åŠ¨å…³ç³»ã€‚é€šè¿‡å­¦ä¹ ä¸åŒçš„ç»•æ•°ç­–ç•¥ï¼Œæ™ºèƒ½ä½“å¯ä»¥æœ‰æ•ˆåœ°æ‰“ç ´å¯¹ç§°æ€§ï¼Œé¿å…æ­»é”ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•é‡‡ç”¨åˆ†å±‚ç­–ç•¥ï¼ŒåŒ…æ‹¬ä¸€ä¸ªåŸºäºå­¦ä¹ çš„è§„åˆ’å™¨ï¼ˆPlannerï¼‰å’Œä¸€ä¸ªåŸºäºæ¨¡å‹çš„æ§åˆ¶å™¨ï¼ˆControllerï¼‰ã€‚è§„åˆ’å™¨è´Ÿè´£ç”Ÿæˆæ‹“æ‰‘åä½œç­–ç•¥ï¼ˆç»•æ•°ï¼‰å’ŒåŠ¨æ€æƒé‡ï¼Œæ§åˆ¶å™¨åˆ™æ ¹æ®è¿™äº›ä¿¡æ¯ç”Ÿæˆæ— ç¢°æ’çš„è¿åŠ¨è½¨è¿¹ã€‚è§„åˆ’å™¨ä½¿ç”¨å¼ºåŒ–å­¦ä¹ è¿›è¡Œè®­ç»ƒï¼Œä»¥å­¦ä¹ æœ€ä¼˜çš„åä½œç­–ç•¥ã€‚æ§åˆ¶å™¨é‡‡ç”¨æ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼ˆMPCï¼‰æ–¹æ³•ï¼Œæ ¹æ®è§„åˆ’å™¨æä¾›çš„ç­–ç•¥å’Œæƒé‡ï¼Œç”Ÿæˆæ»¡è¶³çº¦æŸæ¡ä»¶çš„è¿åŠ¨è½¨è¿¹ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå°†æ‹“æ‰‘ä¸å˜é‡â€œç»•æ•°â€å¼•å…¥åˆ°å¤šæ™ºèƒ½ä½“å¯¼èˆªä¸­ï¼Œå¹¶å°†å…¶ä¸å¼ºåŒ–å­¦ä¹ ç›¸ç»“åˆï¼Œä»è€Œå®ç°äº†å¯¹åä½œç­–ç•¥çš„æœ‰æ•ˆå­¦ä¹ ã€‚ä¸ä¼ ç»Ÿçš„åŸºäºè§„åˆ™æˆ–ä¼˜åŒ–çš„æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”å¤æ‚çš„ç¯å¢ƒå’ŒåŠ¨æ€çš„æ™ºèƒ½ä½“äº¤äº’ã€‚

**å…³é”®è®¾è®¡**ï¼šè§„åˆ’å™¨ä½¿ç”¨æ·±åº¦ç¥ç»ç½‘ç»œä½œä¸ºç­–ç•¥ç½‘ç»œï¼Œè¾“å…¥æ˜¯æ™ºèƒ½ä½“çš„çŠ¶æ€ä¿¡æ¯ï¼Œè¾“å‡ºæ˜¯ç»•æ•°å’ŒåŠ¨æ€æƒé‡ã€‚å¼ºåŒ–å­¦ä¹ é‡‡ç”¨Actor-Criticç®—æ³•è¿›è¡Œè®­ç»ƒï¼Œå¥–åŠ±å‡½æ•°çš„è®¾è®¡æ—¨åœ¨é¼“åŠ±æ™ºèƒ½ä½“é¿å…ç¢°æ’ã€å°½å¿«åˆ°è¾¾ç›®æ ‡ç‚¹ï¼Œå¹¶ä¿æŒä¸€å®šçš„åä½œæ€§ã€‚æ§åˆ¶å™¨é‡‡ç”¨æ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼ˆMPCï¼‰æ–¹æ³•ï¼Œç›®æ ‡å‡½æ•°åŒ…æ‹¬åˆ°è¾¾ç›®æ ‡ç‚¹çš„æ—¶é—´ã€é¿å…ç¢°æ’çš„ä»£ä»·å’Œæ§åˆ¶è¾“å…¥çš„ä»£ä»·ã€‚åŠ¨æ€æƒé‡ç”¨äºè°ƒæ•´ä¸åŒæ™ºèƒ½ä½“ä¹‹é—´çš„ä¼˜å…ˆçº§ï¼Œä»è€Œåœ¨å¯†é›†ç¯å¢ƒä¸­æ›´å¥½åœ°é¿å…ç¢°æ’ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¯†é›†ç¯å¢ƒä¸­æ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿æ–¹æ³•ã€‚åœ¨ä»¿çœŸå’ŒçœŸå®æœºå™¨äººå®éªŒä¸­ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°é¿å…ç¢°æ’å’Œæ­»é”ï¼Œå¹¶å®ç°æ›´é«˜çš„å¯¼èˆªæˆåŠŸç‡å’Œæ›´çŸ­çš„å¯¼èˆªæ—¶é—´ã€‚å…·ä½“è€Œè¨€ï¼Œè¯¥æ–¹æ³•åœ¨æŸäº›åœºæ™¯ä¸‹å¯ä»¥å°†å¯¼èˆªæˆåŠŸç‡æé«˜10%-20%ï¼Œå¯¼èˆªæ—¶é—´ç¼©çŸ­5%-10%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºä»“å‚¨ç‰©æµã€è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººç¼–é˜Ÿç­‰é¢†åŸŸã€‚åœ¨è¿™äº›åœºæ™¯ä¸­ï¼Œå¤šä¸ªæ™ºèƒ½ä½“éœ€è¦åœ¨å¤æ‚çš„ç¯å¢ƒä¸­ååŒå®Œæˆä»»åŠ¡ï¼Œé¿å…ç¢°æ’å’Œæ­»é”è‡³å…³é‡è¦ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿæé«˜å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„æ•ˆç‡å’Œå®‰å…¨æ€§ï¼Œé™ä½äººå·¥å¹²é¢„çš„éœ€æ±‚ï¼Œå…·æœ‰é‡è¦çš„å®é™…åº”ç”¨ä»·å€¼å’Œå¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We address the fundamental challenge of resolving symmetry-induced deadlocks in distributed multi-agent navigation by proposing a new hierarchical navigation method. When multiple agents interact, it is inherently difficult for them to autonomously break the symmetry of deciding how to pass each other. To tackle this problem, we introduce an approach that quantifies cooperative symmetry-breaking strategies using a topological invariant called the winding number, and learns the strategies themselves through reinforcement learning. Our method features a hierarchical policy consisting of a learning-based Planner, which plans topological cooperative strategies, and a model-based Controller, which executes them. Through reinforcement learning, the Planner learns to produce two types of parameters for the Controller: one is the topological cooperative strategy represented by winding numbers, and the other is a set of dynamic weights that determine which agent interaction to prioritize in dense scenarios where multiple agents cross simultaneously. The Controller then generates collision-free and efficient motions based on the strategy and weights provided by the Planner. This hierarchical structure combines the flexible decision-making ability of learning-based methods with the reliability of model-based approaches. Simulation and real-world robot experiments demonstrate that our method outperforms existing baselines, particularly in dense environments, by efficiently avoiding collisions and deadlocks while achieving superior navigation performance. The code for the experiments is available at https://github.com/omron-sinicx/WNumMPC.

