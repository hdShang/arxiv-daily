---
layout: default
title: "RRT*former: Environment-Aware Sampling-Based Motion Planning using Transformer"
---

# RRT*former: Environment-Aware Sampling-Based Motion Planning using Transformer

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.15414" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.15414v1</a>
  <a href="https://arxiv.org/pdf/2511.15414.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.15414v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.15414v1', 'RRT*former: Environment-Aware Sampling-Based Motion Planning using Transformer')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mingyang Feng, Shaoyuan Li, Xiang Yin

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-19

**å¤‡æ³¨**: Accepted to IROS 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/fengmingyang666/RRTformer)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**RRT*formerï¼šåˆ©ç”¨Transformerè¿›è¡Œç¯å¢ƒæ„ŸçŸ¥é‡‡æ ·çš„æœºå™¨äººè¿åŠ¨è§„åˆ’**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `è¿åŠ¨è§„åˆ’` `RRT*` `Transformer` `ç¯å¢ƒæ„ŸçŸ¥` `é‡‡æ ·ç®—æ³•`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŸºäºé‡‡æ ·çš„è¿åŠ¨è§„åˆ’ç®—æ³•åœ¨å¤æ‚ç¯å¢ƒä¸­ç¼ºä¹å¯¹ç¯å¢ƒä¿¡æ¯å’Œå†å²æ ·æœ¬çš„æœ‰æ•ˆåˆ©ç”¨ï¼Œå¯¼è‡´é‡‡æ ·æ•ˆç‡ä½ä¸‹å’Œè·¯å¾„è´¨é‡ä¸é«˜ã€‚
2. RRT*formerç®—æ³•çš„æ ¸å¿ƒåœ¨äºåˆ©ç”¨Transformerç½‘ç»œæå–ç¯å¢ƒç‰¹å¾å’Œå†å²æ ·æœ¬ä¿¡æ¯ï¼Œä»è€ŒæŒ‡å¯¼é‡‡æ ·è¿‡ç¨‹ï¼Œæå‡é‡‡æ ·æ•ˆç‡å’Œè·¯å¾„è´¨é‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒRRT*formeråœ¨è·¯å¾„æœ€ä¼˜æ€§å’Œé‡‡æ ·æ•ˆç‡æ–¹é¢å‡ä¼˜äºRRT*ã€Neural RRT*ç­‰ç°æœ‰ç®—æ³•ï¼Œå…·æœ‰æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ç ”ç©¶äº†å¤æ‚åŠ¨æ€ç¯å¢ƒä¸­æœºå™¨äººæœ€ä¼˜è·¯å¾„è§„åˆ’é—®é¢˜ã€‚ç°æœ‰åŸºäºé‡‡æ ·çš„ç®—æ³•å¤§å¤šå¿½ç•¥ç¯å¢ƒä¿¡æ¯æˆ–å…ˆå‰æ ·æœ¬çš„ä¿¡æ¯ã€‚ç„¶è€Œï¼Œè¿™äº›ä¿¡æ¯éå¸¸æœ‰ç”¨ï¼Œå› ä¸ºåˆ©ç”¨å®ƒä»¬å¯ä»¥åœ¨é‡‡æ ·ä¸‹ä¸€ä¸ªçŠ¶æ€æ—¶æä¾›æ›´å¥½çš„å¯å‘ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºé‡‡æ ·çš„è§„åˆ’ç®—æ³•ï¼Œç§°ä¸ºRRT*formerï¼Œå®ƒä»¥æ–°é¢–çš„æ–¹å¼å°†æ ‡å‡†RRT*ç®—æ³•ä¸Transformerç½‘ç»œé›†æˆã€‚å…·ä½“æ¥è¯´ï¼ŒTransformerç”¨äºä»ç¯å¢ƒä¸­æå–ç‰¹å¾ï¼Œå¹¶åˆ©ç”¨å…ˆå‰æ ·æœ¬çš„ä¿¡æ¯æ¥æ›´å¥½åœ°æŒ‡å¯¼é‡‡æ ·è¿‡ç¨‹ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œä¸ç°æœ‰çš„åŸºäºé‡‡æ ·çš„æ–¹æ³•ï¼ˆå¦‚RRT*ã€Neural RRT*åŠå…¶å˜ä½“ï¼‰ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„ç®—æ³•åœ¨è·¯å¾„çš„æœ€ä¼˜æ€§å’Œé‡‡æ ·æ•ˆç‡æ–¹é¢éƒ½å–å¾—äº†æ˜¾è‘—çš„æ”¹è¿›ã€‚ä»£ç å·²åœ¨GitHubä¸Šå¼€æºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤æ‚åŠ¨æ€ç¯å¢ƒä¸­ï¼Œæœºå™¨äººåŸºäºé‡‡æ ·çš„æœ€ä¼˜è·¯å¾„è§„åˆ’é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚RRT*åŠå…¶å˜ä½“ï¼Œé€šå¸¸å¿½ç•¥äº†ç¯å¢ƒä¿¡æ¯å’Œå†å²é‡‡æ ·ä¿¡æ¯ï¼Œå¯¼è‡´é‡‡æ ·æ•ˆç‡ä½ä¸‹ï¼Œéš¾ä»¥å¿«é€Ÿæ‰¾åˆ°é«˜è´¨é‡çš„è·¯å¾„ã€‚è¿™äº›æ–¹æ³•åœ¨å¤æ‚ç¯å¢ƒä¸­è¡¨ç°ä¸ä½³ï¼Œéœ€è¦å¤§é‡çš„é‡‡æ ·æ‰èƒ½æ”¶æ•›åˆ°è¾ƒä¼˜è§£ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šRRT*formerçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨Transformerç½‘ç»œå­¦ä¹ ç¯å¢ƒå’Œå†å²é‡‡æ ·çš„ç‰¹å¾è¡¨ç¤ºï¼Œå¹¶å°†å…¶ä½œä¸ºå¯å‘ä¿¡æ¯æŒ‡å¯¼åç»­çš„é‡‡æ ·è¿‡ç¨‹ã€‚é€šè¿‡ç¯å¢ƒæ„ŸçŸ¥å’Œå†å²ä¿¡æ¯åˆ©ç”¨ï¼Œç®—æ³•èƒ½å¤Ÿæ›´æ™ºèƒ½åœ°é€‰æ‹©é‡‡æ ·ç‚¹ï¼Œä»è€Œæé«˜é‡‡æ ·æ•ˆç‡ï¼Œæ›´å¿«åœ°æ‰¾åˆ°æ›´ä¼˜çš„è·¯å¾„ã€‚Transformerçš„è‡ªæ³¨æ„åŠ›æœºåˆ¶èƒ½å¤Ÿæœ‰æ•ˆåœ°æ•æ‰ç¯å¢ƒå’Œé‡‡æ ·ç‚¹ä¹‹é—´çš„å…³ç³»ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRRT*formerç®—æ³•çš„æ•´ä½“æ¡†æ¶æ˜¯åœ¨æ ‡å‡†RRT*ç®—æ³•çš„åŸºç¡€ä¸Šï¼Œå¼•å…¥äº†ä¸€ä¸ªTransformerç½‘ç»œã€‚ä¸»è¦æµç¨‹å¦‚ä¸‹ï¼š1. åˆå§‹åŒ–RRT*æ ‘ï¼›2. ä½¿ç”¨Transformerç½‘ç»œï¼Œè¾“å…¥å½“å‰ç¯å¢ƒä¿¡æ¯å’Œå·²é‡‡æ ·çš„èŠ‚ç‚¹ä¿¡æ¯ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªé‡‡æ ·ç‚¹çš„æ¦‚ç‡åˆ†å¸ƒï¼›3. æ ¹æ®é¢„æµ‹çš„æ¦‚ç‡åˆ†å¸ƒè¿›è¡Œé‡‡æ ·ï¼›4. å°†æ–°çš„é‡‡æ ·ç‚¹åŠ å…¥RRT*æ ‘ï¼Œå¹¶è¿›è¡Œè¿æ¥å’Œé‡è¿æ¥æ“ä½œï¼Œæ›´æ–°è·¯å¾„ï¼›5. é‡å¤æ­¥éª¤2-4ï¼Œç›´åˆ°æ»¡è¶³åœæ­¢æ¡ä»¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šRRT*formerçš„å…³é”®åˆ›æ–°åœ¨äºå°†Transformerç½‘ç»œå¼•å…¥åˆ°é‡‡æ ·å¼è¿åŠ¨è§„åˆ’ä¸­ï¼Œå®ç°äº†ç¯å¢ƒæ„ŸçŸ¥å’Œå†å²ä¿¡æ¯åˆ©ç”¨çš„é‡‡æ ·ç­–ç•¥ã€‚ä¸ä¼ ç»Ÿçš„éšæœºé‡‡æ ·æˆ–åŸºäºç®€å•å¯å‘å¼çš„é‡‡æ ·æ–¹æ³•ç›¸æ¯”ï¼ŒRRT*formerèƒ½å¤Ÿæ›´æ™ºèƒ½åœ°é€‰æ‹©é‡‡æ ·ç‚¹ï¼Œä»è€Œæé«˜é‡‡æ ·æ•ˆç‡å’Œè·¯å¾„è´¨é‡ã€‚è¿™æ˜¯é¦–æ¬¡å°†TransformeræˆåŠŸåº”ç”¨äºRRT*ç®—æ³•ä¸­ã€‚

**å…³é”®è®¾è®¡**ï¼šTransformerç½‘ç»œçš„è¾“å…¥åŒ…æ‹¬ç¯å¢ƒçš„æ …æ ¼åœ°å›¾è¡¨ç¤ºå’Œå·²é‡‡æ ·èŠ‚ç‚¹çš„åæ ‡ä¿¡æ¯ã€‚Transformerçš„è¾“å‡ºæ˜¯ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒï¼Œè¡¨ç¤ºåœ¨ä¸åŒä½ç½®è¿›è¡Œé‡‡æ ·çš„æ¦‚ç‡ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡ç›®æ ‡æ˜¯ä½¿é‡‡æ ·ç‚¹æ›´å€¾å‘äºé è¿‘æœ€ä¼˜è·¯å¾„ï¼ŒåŒæ—¶é¿å…ç¢°æ’ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’Œå‚æ•°è®¾ç½®åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ï¼ŒåŒ…æ‹¬Transformerçš„å±‚æ•°ã€æ³¨æ„åŠ›å¤´çš„æ•°é‡ã€éšè—å±‚çš„å¤§å°ç­‰ã€‚æ­¤å¤–ï¼Œè¿˜è®¾è®¡äº†ä¸€äº›ç­–ç•¥æ¥å¹³è¡¡æ¢ç´¢å’Œåˆ©ç”¨ï¼Œä»¥é¿å…é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒRRT*formerç®—æ³•åœ¨è·¯å¾„æœ€ä¼˜æ€§å’Œé‡‡æ ·æ•ˆç‡æ–¹é¢å‡ä¼˜äºRRT*ã€Neural RRT*ç­‰ç°æœ‰ç®—æ³•ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨å¤šä¸ªæµ‹è¯•ç¯å¢ƒä¸­ï¼ŒRRT*formerèƒ½å¤Ÿä»¥æ›´å°‘çš„é‡‡æ ·æ¬¡æ•°æ‰¾åˆ°æ›´çŸ­çš„è·¯å¾„ã€‚ä¾‹å¦‚ï¼Œåœ¨ä¸€ä¸ªå¤æ‚ç¯å¢ƒä¸­ï¼ŒRRT*formerçš„è·¯å¾„é•¿åº¦æ¯”RRT*å‡å°‘äº†çº¦20%ï¼ŒåŒæ—¶é‡‡æ ·æ¬¡æ•°å‡å°‘äº†çº¦30%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒRRT*formerç®—æ³•å…·æœ‰æ˜¾è‘—çš„æ€§èƒ½ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

RRT*formerç®—æ³•å¯å¹¿æ³›åº”ç”¨äºæœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ã€æ¸¸æˆAIç­‰é¢†åŸŸã€‚åœ¨æœºå™¨äººå¯¼èˆªä¸­ï¼Œå¯ä»¥å¸®åŠ©æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­å¿«é€Ÿæ‰¾åˆ°æœ€ä¼˜è·¯å¾„ï¼Œæé«˜å¯¼èˆªæ•ˆç‡å’Œå®‰å…¨æ€§ã€‚åœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼Œå¯ä»¥ç”¨äºè½¦è¾†çš„è·¯å¾„è§„åˆ’ï¼Œæé«˜è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„å¯é æ€§ã€‚åœ¨æ¸¸æˆAIä¸­ï¼Œå¯ä»¥ç”¨äºè§’è‰²çš„è¿åŠ¨è§„åˆ’ï¼Œæé«˜æ¸¸æˆä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We investigate the sampling-based optimal path planning problem for robotics in complex and dynamic environments. Most existing sampling-based algorithms neglect environmental information or the information from previous samples. Yet, these pieces of information are highly informative, as leveraging them can provide better heuristics when sampling the next state. In this paper, we propose a novel sampling-based planning algorithm, called \emph{RRT*former}, which integrates the standard RRT* algorithm with a Transformer network in a novel way. Specifically, the Transformer is used to extract features from the environment and leverage information from previous samples to better guide the sampling process. Our extensive experiments demonstrate that, compared to existing sampling-based approaches such as RRT*, Neural RRT*, and their variants, our algorithm achieves considerable improvements in both the optimality of the path and sampling efficiency. The code for our implementation is available on https://github.com/fengmingyang666/RRTformer.

