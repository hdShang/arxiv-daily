---
layout: default
title: From Human Hands to Robot Arms: Manipulation Skills Transfer via Trajectory Alignment
---

# From Human Hands to Robot Arms: Manipulation Skills Transfer via Trajectory Alignment

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.00491" target="_blank" class="toolbar-btn">arXiv: 2510.00491v1</a>
    <a href="https://arxiv.org/pdf/2510.00491.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.00491v1" 
            onclick="toggleFavorite(this, '2510.00491v1', 'From Human Hands to Robot Arms: Manipulation Skills Transfer via Trajectory Alignment')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Han Zhou, Jinjin Cao, Liyuan Ma, Xueji Fang, Guo-jun Qi

**ÂàÜÁ±ª**: cs.RO, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-01

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**Traj2ActionÔºöÈÄöËøáËΩ®ËøπÂØπÈΩêÂÆûÁé∞‰∫∫ÊâãÊìç‰ΩúÊäÄËÉΩÂêëÊú∫Âô®‰∫∫ÊâãËáÇÁöÑËøÅÁßª**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰∏ÉÔºöÂä®‰ΩúÈáçÂÆöÂêë (Motion Retargeting)**

**ÂÖ≥ÈîÆËØç**: `Êú∫Âô®‰∫∫Êìç‰Ωú` `ÊäÄËÉΩËøÅÁßª` `ËΩ®ËøπÂØπÈΩê` `Ê®°‰ªøÂ≠¶‰π†` `‰∫∫Êú∫Âçè‰Ωú`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊú∫Âô®‰∫∫Êìç‰ΩúÊäÄËÉΩÂ≠¶‰π†‰∏•Èáç‰æùËµñÊòÇË¥µ‰∏îÈöæ‰ª•Êâ©Â±ïÁöÑÈÅ•Êìç‰ΩúÊºîÁ§∫ÔºåÈôêÂà∂‰∫ÜÊú∫Âô®‰∫∫Â≠¶‰π†Â§öÊ†∑ÂåñÊäÄËÉΩ„ÄÇ
2. Traj2ActionÈÄöËøáÂ∞Ü‰∫∫Á±ªÂíåÊú∫Âô®‰∫∫ÁöÑÊìç‰ΩúËΩ®ËøπÂØπÈΩêÂà∞Áªü‰∏ÄÁöÑ3DÁ©∫Èó¥ÔºåÂº•Âêà‰∫Ü‰∫∫Êú∫ÂΩ¢ÊÄÅÂ∑ÆÂºÇÔºåÂÆûÁé∞Áü•ËØÜËøÅÁßª„ÄÇ
3. Âú®ÁúüÂÆûFrankaÊú∫Âô®‰∫∫ÂÆûÈ™å‰∏≠ÔºåTraj2ActionÂú®Áü≠Á®ãÂíåÈïøÁ®ã‰ªªÂä°‰∏äÂàÜÂà´ÊèêÂçá‰∫Ü27%Âíå22.25%ÁöÑÊÄßËÉΩ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÁúüÂÆû‰∏ñÁïåÊú∫Âô®‰∫∫Â≠¶‰π†Â§öÊ†∑ÂåñÊìç‰ΩúÊäÄËÉΩ‰∏•ÈáçÂèóÈôê‰∫é‰æùËµñÊòÇË¥µ‰∏îÈöæ‰ª•Êâ©Â±ïÁöÑÈÅ•Êìç‰ΩúÊºîÁ§∫„ÄÇËôΩÁÑ∂‰∫∫Á±ªËßÜÈ¢ëÊèê‰æõ‰∫Ü‰∏ÄÁßçÂèØÊâ©Â±ïÁöÑÊõø‰ª£ÊñπÊ°àÔºå‰ΩÜ‰∫∫Á±ªÂíåÊú∫Âô®‰∫∫ÂΩ¢ÊÄÅ‰πãÈó¥ÁöÑÂ∑®Â§ßÂ∑ÆÂºÇ‰ªéÊ†πÊú¨‰∏äÈòªÁ¢ç‰∫ÜÊìç‰ΩúÁü•ËØÜÁöÑÊúâÊïàËΩ¨Áßª„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏ÄÊåëÊàòÂπ∂‰øÉËøõ‰ªé‰∫∫Á±ªÂà∞Êú∫Âô®‰∫∫ÁöÑÊäÄËÉΩËΩ¨ÁßªÔºåÊàë‰ª¨ÂºïÂÖ•‰∫ÜTraj2ActionÔºåËøôÊòØ‰∏Ä‰∏™Êñ∞È¢ñÁöÑÊ°ÜÊû∂ÔºåÂÆÉÈÄöËøá‰ΩøÁî®Êìç‰ΩúÁ´ØÁÇπÁöÑ3DËΩ®Ëøπ‰Ωú‰∏∫Áªü‰∏ÄÁöÑ‰∏≠Èó¥Ë°®Á§∫Êù•Âº•ÂêàËøôÁßçÂΩ¢ÊÄÅÂ∑ÆÂºÇÔºåÁÑ∂ÂêéÂ∞ÜÂµåÂÖ•Âú®ËØ•ËΩ®Ëøπ‰∏≠ÁöÑÊìç‰ΩúÁü•ËØÜËΩ¨ÁßªÂà∞Êú∫Âô®‰∫∫ÁöÑÂä®‰Ωú„ÄÇÊàë‰ª¨ÁöÑÁ≠ñÁï•È¶ñÂÖàÂ≠¶‰π†ÁîüÊàê‰∏Ä‰∏™Á≤óÁï•ÁöÑËΩ®ËøπÔºåÈÄöËøáÂà©Áî®‰∫∫Á±ªÂíåÊú∫Âô®‰∫∫ÁöÑÊï∞ÊçÆÊù•ÂΩ¢Êàê‰∏Ä‰∏™È´òÂ±ÇÊ¨°ÁöÑËøêÂä®ËÆ°Âàí„ÄÇÁÑ∂ÂêéÔºåËØ•ËÆ°ÂàíÂú®‰∏Ä‰∏™ÂçèÂêåÂéªÂô™Ê°ÜÊû∂ÂÜÖË∞ÉËäÇÁ≤æÁ°ÆÁöÑ„ÄÅÊú∫Âô®‰∫∫ÁâπÂÆöÁöÑÂä®‰ΩúÔºà‰æãÂ¶ÇÔºåÊñπÂêëÂíåÂ§πÊåÅÂô®Áä∂ÊÄÅÔºâÁöÑÂêàÊàê„ÄÇÂú®FrankaÊú∫Âô®‰∫∫‰∏äËøõË°åÁöÑÂ§ßÈáèÁúüÂÆû‰∏ñÁïåÂÆûÈ™åË°®ÊòéÔºåTraj2ActionÂú®Áü≠Á®ãÂíåÈïøÁ®ãÁúüÂÆû‰∏ñÁïå‰ªªÂä°‰∏äÁöÑÊÄßËÉΩÊØî$œÄ_0$Âü∫Á∫øÊèêÈ´ò‰∫ÜÈ´òËææ27%Âíå22.25%ÔºåÂπ∂‰∏îÈöèÁùÄ‰∫∫Á±ªÊï∞ÊçÆÂú®Êú∫Âô®‰∫∫Á≠ñÁï•Â≠¶‰π†‰∏≠ÁöÑÊâ©Â±ïÔºåÂÆûÁé∞‰∫ÜÊòæËëóÁöÑÊî∂Áõä„ÄÇÊàë‰ª¨ÁöÑÈ°πÁõÆÁΩëÁ´ôÔºåÂåÖÂê´‰ª£Á†ÅÂíåËßÜÈ¢ëÊºîÁ§∫ÔºåÂèØÂú®https://anonymous.4open.science/w/Traj2Action-4A45/‰∏äÊâæÂà∞„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Êú∫Âô®‰∫∫Êìç‰ΩúÊäÄËÉΩÂ≠¶‰π†‰∏≠Ôºå‰æùËµñÊòÇË¥µÈÅ•Êìç‰ΩúÊï∞ÊçÆÔºå‰ª•Âèä‰∫∫Á±ªËßÜÈ¢ëÊï∞ÊçÆÂõ†‰∫∫Êú∫ÂΩ¢ÊÄÅÂ∑ÆÂºÇÈöæ‰ª•Áõ¥Êé•ËøÅÁßªÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÈöæ‰ª•ÊúâÊïàÂà©Áî®‰∫∫Á±ªËßÜÈ¢ëÊï∞ÊçÆÔºåÈôêÂà∂‰∫ÜÊú∫Âô®‰∫∫ÊäÄËÉΩÂ≠¶‰π†ÁöÑÊïàÁéáÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞Ü‰∫∫Á±ªÊìç‰ΩúÊäÄËÉΩÁöÑ3DËΩ®Ëøπ‰Ωú‰∏∫‰∏≠Èó¥Ë°®Á§∫ÔºåÈÄöËøáËΩ®ËøπÂØπÈΩêÁöÑÊñπÂºèÔºåÂ∞Ü‰∫∫Á±ªÁöÑÊìç‰ΩúÁü•ËØÜËøÅÁßªÂà∞Êú∫Âô®‰∫∫„ÄÇËøôÁßçÊñπÊ≥ïËß£ËÄ¶‰∫Ü‰∫∫Êú∫ÂΩ¢ÊÄÅÂ∑ÆÂºÇÔºå‰ΩøÂæóÊú∫Âô®‰∫∫ÂèØ‰ª•Â≠¶‰π†‰∫∫Á±ªÁöÑÊìç‰ΩúÁ≠ñÁï•„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöTraj2ActionÊ°ÜÊû∂ÂåÖÂê´‰∏§‰∏™‰∏ªË¶ÅÈò∂ÊÆµÔºö1) ËΩ®ËøπÁîüÊàêÔºöÂà©Áî®‰∫∫Á±ªÂíåÊú∫Âô®‰∫∫Êï∞ÊçÆÂ≠¶‰π†ÁîüÊàêÁ≤óÁï•ÁöÑ3DËΩ®ËøπÔºå‰Ωú‰∏∫È´òÂ±ÇËøêÂä®ËßÑÂàí„ÄÇ2) Âä®‰ΩúÂêàÊàêÔºöÂü∫‰∫éÁîüÊàêÁöÑËΩ®ËøπÔºåÈÄöËøáÂçèÂêåÂéªÂô™Ê°ÜÊû∂ÔºåÂêàÊàêÁ≤æÁ°ÆÁöÑ„ÄÅÊú∫Âô®‰∫∫ÁâπÂÆöÁöÑÂä®‰ΩúÔºåÂåÖÊã¨ÊñπÂêëÂíåÂ§πÊåÅÂô®Áä∂ÊÄÅ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ÊñπÊ≥ïÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫é‰ΩøÁî®3DËΩ®Ëøπ‰Ωú‰∏∫‰∫∫Êú∫ÊäÄËÉΩËøÅÁßªÁöÑÊ°•Ê¢ÅÔºåÊúâÊïàËß£ÂÜ≥‰∫Ü‰∫∫Êú∫ÂΩ¢ÊÄÅÂ∑ÆÂºÇÂ∏¶Êù•ÁöÑÊåëÊàò„ÄÇÈÄöËøáËΩ®ËøπÂØπÈΩêÔºåÂèØ‰ª•Â∞Ü‰∫∫Á±ªÁöÑÊìç‰ΩúÁü•ËØÜËΩ¨Âåñ‰∏∫Êú∫Âô®‰∫∫ÂèØÊâßË°åÁöÑÂä®‰Ωú„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåTraj2ActionËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞Âà©Áî®‰∫∫Á±ªËßÜÈ¢ëÊï∞ÊçÆÔºåÊèêÂçáÊú∫Âô®‰∫∫ÊäÄËÉΩÂ≠¶‰π†ÁöÑÊïàÁéáÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËΩ®ËøπÁîüÊàêÈò∂ÊÆµÔºåËÆ∫ÊñáÂèØËÉΩ‰ΩøÁî®‰∫ÜÊ®°‰ªøÂ≠¶‰π†ÊàñÂº∫ÂåñÂ≠¶‰π†Á≠âÊñπÊ≥ïÔºåÂ≠¶‰π†‰ªé‰∫∫Á±ªÂíåÊú∫Âô®‰∫∫Êï∞ÊçÆ‰∏≠ÁîüÊàêËΩ®Ëøπ„ÄÇÂú®Âä®‰ΩúÂêàÊàêÈò∂ÊÆµÔºåÂçèÂêåÂéªÂô™Ê°ÜÊû∂ÂèØËÉΩÂåÖÂê´‰∏§‰∏™ÂéªÂô™ÁΩëÁªúÔºåÂàÜÂà´Ë¥üË¥£ÁîüÊàêÊú∫Âô®‰∫∫ÁöÑÊñπÂêëÂíåÂ§πÊåÅÂô®Áä∂ÊÄÅ„ÄÇÊçüÂ§±ÂáΩÊï∞ÂèØËÉΩÂåÖÂê´ËΩ®ËøπÁõ∏‰ººÊÄßÊçüÂ§±„ÄÅÂä®‰ΩúÂπ≥ÊªëÊÄßÊçüÂ§±Á≠âÔºå‰ª•‰øùËØÅÁîüÊàêÁöÑËΩ®ËøπÂíåÂä®‰ΩúÁöÑË¥®Èáè„ÄÇÂÖ∑‰ΩìÁöÑÁΩëÁªúÁªìÊûÑÂíåÂèÇÊï∞ËÆæÁΩÆÂú®ËÆ∫Êñá‰∏≠Â∫îËØ•ÊúâËØ¶ÁªÜÊèèËø∞ÔºàÊú™Áü•Ôºâ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Traj2ActionÂú®ÁúüÂÆûFrankaÊú∫Âô®‰∫∫ÂÆûÈ™å‰∏≠Ë°®Áé∞Âá∫Ëâ≤ÔºåÂú®Áü≠Á®ãÂíåÈïøÁ®ãÁúüÂÆû‰∏ñÁïå‰ªªÂä°‰∏äÁöÑÊÄßËÉΩÊØî$œÄ_0$Âü∫Á∫øÂàÜÂà´ÊèêÈ´ò‰∫ÜÈ´òËææ27%Âíå22.25%„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÊúâÊïàÂà©Áî®‰∫∫Á±ªËßÜÈ¢ëÊï∞ÊçÆÔºåÊòæËëóÊèêÂçáÊú∫Âô®‰∫∫Á≠ñÁï•Â≠¶‰π†ÁöÑÊÄßËÉΩÔºåÂ∞§ÂÖ∂ÊòØÂú®‰∫∫Á±ªÊï∞ÊçÆËßÑÊ®°ËæÉÂ§ßÊó∂ÔºåÊî∂ÁõäÊõ¥‰∏∫ÊòéÊòæ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂêÑÁßçÊú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°Ôºå‰æãÂ¶ÇÂ∑•‰∏öËá™Âä®Âåñ„ÄÅÂÆ∂Â∫≠ÊúçÂä°Êú∫Âô®‰∫∫„ÄÅÂåªÁñóÊú∫Âô®‰∫∫Á≠â„ÄÇÈÄöËøáÂà©Áî®‰∫∫Á±ªÁöÑÊìç‰ΩúÁªèÈ™åÔºåÂèØ‰ª•Âø´ÈÄüËÆ≠ÁªÉÊú∫Âô®‰∫∫ÂÆåÊàêÂ§çÊùÇÁöÑ‰ªªÂä°ÔºåÈôç‰ΩéÂºÄÂèëÊàêÊú¨ÔºåÊèêÈ´òÊú∫Âô®‰∫∫ÁöÑÊô∫ËÉΩÂåñÊ∞¥Âπ≥„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïÊúâÊúõÊé®ÂπøÂà∞Êõ¥Â§öÁ±ªÂûãÁöÑÊú∫Âô®‰∫∫ÂíåÊìç‰Ωú‰ªªÂä°‰∏≠„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Learning diverse manipulation skills for real-world robots is severely bottlenecked by the reliance on costly and hard-to-scale teleoperated demonstrations. While human videos offer a scalable alternative, effectively transferring manipulation knowledge is fundamentally hindered by the significant morphological gap between human and robotic embodiments. To address this challenge and facilitate skill transfer from human to robot, we introduce Traj2Action,a novel framework that bridges this embodiment gap by using the 3D trajectory of the operational endpoint as a unified intermediate representation, and then transfers the manipulation knowledge embedded in this trajectory to the robot's actions. Our policy first learns to generate a coarse trajectory, which forms an high-level motion plan by leveraging both human and robot data. This plan then conditions the synthesis of precise, robot-specific actions (e.g., orientation and gripper state) within a co-denoising framework. Extensive real-world experiments on a Franka robot demonstrate that Traj2Action boosts the performance by up to 27% and 22.25% over $œÄ_0$ baseline on short- and long-horizon real-world tasks, and achieves significant gains as human data scales in robot policy learning. Our project website, featuring code and video demonstrations, is available at https://anonymous.4open.science/w/Traj2Action-4A45/.

