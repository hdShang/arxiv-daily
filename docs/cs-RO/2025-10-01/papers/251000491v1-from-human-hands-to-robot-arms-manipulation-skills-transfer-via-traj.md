---
layout: default
title: From Human Hands to Robot Arms: Manipulation Skills Transfer via Trajectory Alignment
---

# From Human Hands to Robot Arms: Manipulation Skills Transfer via Trajectory Alignment

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.00491" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.00491v1</a>
  <a href="https://arxiv.org/pdf/2510.00491.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.00491v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.00491v1', 'From Human Hands to Robot Arms: Manipulation Skills Transfer via Trajectory Alignment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Han Zhou, Jinjin Cao, Liyuan Ma, Xueji Fang, Guo-jun Qi

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-10-01

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Traj2Actionï¼šé€šè¿‡è½¨è¿¹å¯¹é½å®ç°äººæ‰‹æ“ä½œæŠ€èƒ½å‘æœºå™¨äººæ‰‹è‡‚çš„è¿ç§»**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)**

**å…³é”®è¯**: `æœºå™¨äººæ“ä½œ` `æŠ€èƒ½è¿ç§»` `è½¨è¿¹å¯¹é½` `æ¨¡ä»¿å­¦ä¹ ` `äººæœºåä½œ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æœºå™¨äººæ“ä½œæŠ€èƒ½å­¦ä¹ ä¸¥é‡ä¾èµ–æ˜‚è´µä¸”éš¾ä»¥æ‰©å±•çš„é¥æ“ä½œæ¼”ç¤ºï¼Œé™åˆ¶äº†æœºå™¨äººå­¦ä¹ å¤šæ ·åŒ–æŠ€èƒ½ã€‚
2. Traj2Actioné€šè¿‡å°†äººç±»å’Œæœºå™¨äººçš„æ“ä½œè½¨è¿¹å¯¹é½åˆ°ç»Ÿä¸€çš„3Dç©ºé—´ï¼Œå¼¥åˆäº†äººæœºå½¢æ€å·®å¼‚ï¼Œå®ç°çŸ¥è¯†è¿ç§»ã€‚
3. åœ¨çœŸå®Frankaæœºå™¨äººå®éªŒä¸­ï¼ŒTraj2Actionåœ¨çŸ­ç¨‹å’Œé•¿ç¨‹ä»»åŠ¡ä¸Šåˆ†åˆ«æå‡äº†27%å’Œ22.25%çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

çœŸå®ä¸–ç•Œæœºå™¨äººå­¦ä¹ å¤šæ ·åŒ–æ“ä½œæŠ€èƒ½ä¸¥é‡å—é™äºä¾èµ–æ˜‚è´µä¸”éš¾ä»¥æ‰©å±•çš„é¥æ“ä½œæ¼”ç¤ºã€‚è™½ç„¶äººç±»è§†é¢‘æä¾›äº†ä¸€ç§å¯æ‰©å±•çš„æ›¿ä»£æ–¹æ¡ˆï¼Œä½†äººç±»å’Œæœºå™¨äººå½¢æ€ä¹‹é—´çš„å·¨å¤§å·®å¼‚ä»æ ¹æœ¬ä¸Šé˜»ç¢äº†æ“ä½œçŸ¥è¯†çš„æœ‰æ•ˆè½¬ç§»ã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜å¹¶ä¿ƒè¿›ä»äººç±»åˆ°æœºå™¨äººçš„æŠ€èƒ½è½¬ç§»ï¼Œæˆ‘ä»¬å¼•å…¥äº†Traj2Actionï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°é¢–çš„æ¡†æ¶ï¼Œå®ƒé€šè¿‡ä½¿ç”¨æ“ä½œç«¯ç‚¹çš„3Dè½¨è¿¹ä½œä¸ºç»Ÿä¸€çš„ä¸­é—´è¡¨ç¤ºæ¥å¼¥åˆè¿™ç§å½¢æ€å·®å¼‚ï¼Œç„¶åå°†åµŒå…¥åœ¨è¯¥è½¨è¿¹ä¸­çš„æ“ä½œçŸ¥è¯†è½¬ç§»åˆ°æœºå™¨äººçš„åŠ¨ä½œã€‚æˆ‘ä»¬çš„ç­–ç•¥é¦–å…ˆå­¦ä¹ ç”Ÿæˆä¸€ä¸ªç²—ç•¥çš„è½¨è¿¹ï¼Œé€šè¿‡åˆ©ç”¨äººç±»å’Œæœºå™¨äººçš„æ•°æ®æ¥å½¢æˆä¸€ä¸ªé«˜å±‚æ¬¡çš„è¿åŠ¨è®¡åˆ’ã€‚ç„¶åï¼Œè¯¥è®¡åˆ’åœ¨ä¸€ä¸ªååŒå»å™ªæ¡†æ¶å†…è°ƒèŠ‚ç²¾ç¡®çš„ã€æœºå™¨äººç‰¹å®šçš„åŠ¨ä½œï¼ˆä¾‹å¦‚ï¼Œæ–¹å‘å’Œå¤¹æŒå™¨çŠ¶æ€ï¼‰çš„åˆæˆã€‚åœ¨Frankaæœºå™¨äººä¸Šè¿›è¡Œçš„å¤§é‡çœŸå®ä¸–ç•Œå®éªŒè¡¨æ˜ï¼ŒTraj2Actionåœ¨çŸ­ç¨‹å’Œé•¿ç¨‹çœŸå®ä¸–ç•Œä»»åŠ¡ä¸Šçš„æ€§èƒ½æ¯”$Ï€_0$åŸºçº¿æé«˜äº†é«˜è¾¾27%å’Œ22.25%ï¼Œå¹¶ä¸”éšç€äººç±»æ•°æ®åœ¨æœºå™¨äººç­–ç•¥å­¦ä¹ ä¸­çš„æ‰©å±•ï¼Œå®ç°äº†æ˜¾è‘—çš„æ”¶ç›Šã€‚æˆ‘ä»¬çš„é¡¹ç›®ç½‘ç«™ï¼ŒåŒ…å«ä»£ç å’Œè§†é¢‘æ¼”ç¤ºï¼Œå¯åœ¨https://anonymous.4open.science/w/Traj2Action-4A45/ä¸Šæ‰¾åˆ°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æœºå™¨äººæ“ä½œæŠ€èƒ½å­¦ä¹ ä¸­ï¼Œä¾èµ–æ˜‚è´µé¥æ“ä½œæ•°æ®ï¼Œä»¥åŠäººç±»è§†é¢‘æ•°æ®å› äººæœºå½¢æ€å·®å¼‚éš¾ä»¥ç›´æ¥è¿ç§»çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆåˆ©ç”¨äººç±»è§†é¢‘æ•°æ®ï¼Œé™åˆ¶äº†æœºå™¨äººæŠ€èƒ½å­¦ä¹ çš„æ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†äººç±»æ“ä½œæŠ€èƒ½çš„3Dè½¨è¿¹ä½œä¸ºä¸­é—´è¡¨ç¤ºï¼Œé€šè¿‡è½¨è¿¹å¯¹é½çš„æ–¹å¼ï¼Œå°†äººç±»çš„æ“ä½œçŸ¥è¯†è¿ç§»åˆ°æœºå™¨äººã€‚è¿™ç§æ–¹æ³•è§£è€¦äº†äººæœºå½¢æ€å·®å¼‚ï¼Œä½¿å¾—æœºå™¨äººå¯ä»¥å­¦ä¹ äººç±»çš„æ“ä½œç­–ç•¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTraj2Actionæ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼š1) è½¨è¿¹ç”Ÿæˆï¼šåˆ©ç”¨äººç±»å’Œæœºå™¨äººæ•°æ®å­¦ä¹ ç”Ÿæˆç²—ç•¥çš„3Dè½¨è¿¹ï¼Œä½œä¸ºé«˜å±‚è¿åŠ¨è§„åˆ’ã€‚2) åŠ¨ä½œåˆæˆï¼šåŸºäºç”Ÿæˆçš„è½¨è¿¹ï¼Œé€šè¿‡ååŒå»å™ªæ¡†æ¶ï¼Œåˆæˆç²¾ç¡®çš„ã€æœºå™¨äººç‰¹å®šçš„åŠ¨ä½œï¼ŒåŒ…æ‹¬æ–¹å‘å’Œå¤¹æŒå™¨çŠ¶æ€ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºä½¿ç”¨3Dè½¨è¿¹ä½œä¸ºäººæœºæŠ€èƒ½è¿ç§»çš„æ¡¥æ¢ï¼Œæœ‰æ•ˆè§£å†³äº†äººæœºå½¢æ€å·®å¼‚å¸¦æ¥çš„æŒ‘æˆ˜ã€‚é€šè¿‡è½¨è¿¹å¯¹é½ï¼Œå¯ä»¥å°†äººç±»çš„æ“ä½œçŸ¥è¯†è½¬åŒ–ä¸ºæœºå™¨äººå¯æ‰§è¡Œçš„åŠ¨ä½œã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒTraj2Actionèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨äººç±»è§†é¢‘æ•°æ®ï¼Œæå‡æœºå™¨äººæŠ€èƒ½å­¦ä¹ çš„æ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è½¨è¿¹ç”Ÿæˆé˜¶æ®µï¼Œè®ºæ–‡å¯èƒ½ä½¿ç”¨äº†æ¨¡ä»¿å­¦ä¹ æˆ–å¼ºåŒ–å­¦ä¹ ç­‰æ–¹æ³•ï¼Œå­¦ä¹ ä»äººç±»å’Œæœºå™¨äººæ•°æ®ä¸­ç”Ÿæˆè½¨è¿¹ã€‚åœ¨åŠ¨ä½œåˆæˆé˜¶æ®µï¼ŒååŒå»å™ªæ¡†æ¶å¯èƒ½åŒ…å«ä¸¤ä¸ªå»å™ªç½‘ç»œï¼Œåˆ†åˆ«è´Ÿè´£ç”Ÿæˆæœºå™¨äººçš„æ–¹å‘å’Œå¤¹æŒå™¨çŠ¶æ€ã€‚æŸå¤±å‡½æ•°å¯èƒ½åŒ…å«è½¨è¿¹ç›¸ä¼¼æ€§æŸå¤±ã€åŠ¨ä½œå¹³æ»‘æ€§æŸå¤±ç­‰ï¼Œä»¥ä¿è¯ç”Ÿæˆçš„è½¨è¿¹å’ŒåŠ¨ä½œçš„è´¨é‡ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’Œå‚æ•°è®¾ç½®åœ¨è®ºæ–‡ä¸­åº”è¯¥æœ‰è¯¦ç»†æè¿°ï¼ˆæœªçŸ¥ï¼‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

Traj2Actionåœ¨çœŸå®Frankaæœºå™¨äººå®éªŒä¸­è¡¨ç°å‡ºè‰²ï¼Œåœ¨çŸ­ç¨‹å’Œé•¿ç¨‹çœŸå®ä¸–ç•Œä»»åŠ¡ä¸Šçš„æ€§èƒ½æ¯”$Ï€_0$åŸºçº¿åˆ†åˆ«æé«˜äº†é«˜è¾¾27%å’Œ22.25%ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨äººç±»è§†é¢‘æ•°æ®ï¼Œæ˜¾è‘—æå‡æœºå™¨äººç­–ç•¥å­¦ä¹ çš„æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨äººç±»æ•°æ®è§„æ¨¡è¾ƒå¤§æ—¶ï¼Œæ”¶ç›Šæ›´ä¸ºæ˜æ˜¾ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§æœºå™¨äººæ“ä½œä»»åŠ¡ï¼Œä¾‹å¦‚å·¥ä¸šè‡ªåŠ¨åŒ–ã€å®¶åº­æœåŠ¡æœºå™¨äººã€åŒ»ç–—æœºå™¨äººç­‰ã€‚é€šè¿‡åˆ©ç”¨äººç±»çš„æ“ä½œç»éªŒï¼Œå¯ä»¥å¿«é€Ÿè®­ç»ƒæœºå™¨äººå®Œæˆå¤æ‚çš„ä»»åŠ¡ï¼Œé™ä½å¼€å‘æˆæœ¬ï¼Œæé«˜æœºå™¨äººçš„æ™ºèƒ½åŒ–æ°´å¹³ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æ¨å¹¿åˆ°æ›´å¤šç±»å‹çš„æœºå™¨äººå’Œæ“ä½œä»»åŠ¡ä¸­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Learning diverse manipulation skills for real-world robots is severely bottlenecked by the reliance on costly and hard-to-scale teleoperated demonstrations. While human videos offer a scalable alternative, effectively transferring manipulation knowledge is fundamentally hindered by the significant morphological gap between human and robotic embodiments. To address this challenge and facilitate skill transfer from human to robot, we introduce Traj2Action,a novel framework that bridges this embodiment gap by using the 3D trajectory of the operational endpoint as a unified intermediate representation, and then transfers the manipulation knowledge embedded in this trajectory to the robot's actions. Our policy first learns to generate a coarse trajectory, which forms an high-level motion plan by leveraging both human and robot data. This plan then conditions the synthesis of precise, robot-specific actions (e.g., orientation and gripper state) within a co-denoising framework. Extensive real-world experiments on a Franka robot demonstrate that Traj2Action boosts the performance by up to 27% and 22.25% over $Ï€_0$ baseline on short- and long-horizon real-world tasks, and achieves significant gains as human data scales in robot policy learning. Our project website, featuring code and video demonstrations, is available at https://anonymous.4open.science/w/Traj2Action-4A45/.

