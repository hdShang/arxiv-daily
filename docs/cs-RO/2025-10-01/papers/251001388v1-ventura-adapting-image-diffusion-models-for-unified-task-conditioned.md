---
layout: default
title: VENTURA: Adapting Image Diffusion Models for Unified Task Conditioned Navigation
---

# VENTURA: Adapting Image Diffusion Models for Unified Task Conditioned Navigation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.01388" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.01388v1</a>
  <a href="https://arxiv.org/pdf/2510.01388.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.01388v1" onclick="toggleFavorite(this, '2510.01388v1', 'VENTURA: Adapting Image Diffusion Models for Unified Task Conditioned Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Arthur Zhang, Xiangyun Meng, Luca Calliari, Dong-Ki Kim, Shayegan Omidshafiei, Joydeep Biswas, Ali Agha, Amirreza Shaban

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-01

**å¤‡æ³¨**: 9 pages, 6 figures, 3 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVENTURAä»¥è§£å†³æœºå™¨äººå¯¼èˆªä»»åŠ¡ä¸­çš„é€‚åº”æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€æ¨¡å‹` `è·¯å¾„è§„åˆ’` `æœºå™¨äººå¯¼èˆª` `å›¾åƒæ‰©æ•£æ¨¡å‹` `è¡Œä¸ºå…‹éš†` `è‡ªç›‘ç£å­¦ä¹ ` `ä»»åŠ¡é€‚åº”æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨å¯¼èˆªä»»åŠ¡ä¸­éš¾ä»¥åº”ç”¨ï¼Œä¸»è¦ç”±äºè¡ŒåŠ¨ç©ºé—´å’Œé¢„è®­ç»ƒç›®æ ‡çš„å·®å¼‚ï¼Œå¯¼è‡´æ¨¡å‹çš„è¿ç§»èƒ½åŠ›ä¸è¶³ã€‚
2. VENTURAé€šè¿‡å¾®è°ƒå›¾åƒæ‰©æ•£æ¨¡å‹ç”Ÿæˆè·¯å¾„æ©ç ï¼Œç»“åˆè½»é‡çº§è¡Œä¸ºå…‹éš†ç­–ç•¥ï¼Œå°†è§†è§‰è®¡åˆ’è½¬åŒ–ä¸ºå¯æ‰§è¡Œè½¨è¿¹ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ‰§è¡Œè‡ªç„¶è¯­è¨€æŒ‡ä»¤ã€‚
3. åœ¨å®é™…è¯„ä¼°ä¸­ï¼ŒVENTURAåœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼ŒæˆåŠŸç‡æé«˜33%ï¼Œç¢°æ’ç‡é™ä½54%ï¼Œå¹¶å±•ç°å‡ºå¯¹æœªè§ä»»åŠ¡ç»„åˆçš„è‰¯å¥½æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœºå™¨äººå¿…é¡»é€‚åº”å¤šæ ·çš„äººç±»æŒ‡ä»¤ï¼Œå¹¶åœ¨éç»“æ„åŒ–çš„å¼€æ”¾ä¸–ç•Œç¯å¢ƒä¸­å®‰å…¨æ“ä½œã€‚è¿‘æœŸçš„è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰ä¸ºè¯­è¨€å’Œæ„ŸçŸ¥çš„ç»“åˆæä¾›äº†å¼ºæœ‰åŠ›çš„å…ˆéªŒçŸ¥è¯†ï¼Œä½†ç”±äºè¡ŒåŠ¨ç©ºé—´å’Œé¢„è®­ç»ƒç›®æ ‡çš„å·®å¼‚ï¼Œå¯¼è‡´å…¶åœ¨å¯¼èˆªä»»åŠ¡ä¸­çš„åº”ç”¨å—åˆ°é™åˆ¶ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†VENTURAï¼Œä¸€ä¸ªé€šè¿‡å¾®è°ƒäº’è”ç½‘é¢„è®­ç»ƒçš„å›¾åƒæ‰©æ•£æ¨¡å‹è¿›è¡Œè·¯å¾„è§„åˆ’çš„è§†è§‰-è¯­è¨€å¯¼èˆªç³»ç»Ÿã€‚VENTURAç”Ÿæˆè·¯å¾„æ©ç ï¼ˆå³è§†è§‰è®¡åˆ’ï¼‰ï¼Œå¹¶é€šè¿‡è½»é‡çº§çš„è¡Œä¸ºå…‹éš†ç­–ç•¥å°†è¿™äº›è§†è§‰è®¡åˆ’è½¬åŒ–ä¸ºå¯æ‰§è¡Œçš„è½¨è¿¹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒVENTURAåœ¨ç‰©ä½“åˆ°è¾¾ã€éšœç¢ç‰©è§„é¿å’Œåœ°å½¢åå¥½ä»»åŠ¡ä¸­è¶…è¶Šäº†ç°æœ‰çš„åŸºç¡€æ¨¡å‹åŸºçº¿ï¼ŒæˆåŠŸç‡æé«˜äº†33%ï¼Œç¢°æ’ç‡é™ä½äº†54%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­æ‰§è¡Œå¯¼èˆªä»»åŠ¡æ—¶çš„é€‚åº”æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨è¡ŒåŠ¨ç©ºé—´å’Œé¢„è®­ç»ƒç›®æ ‡ä¸Šå­˜åœ¨å·®å¼‚ï¼Œå¯¼è‡´éš¾ä»¥æœ‰æ•ˆè¿ç§»åˆ°æœºå™¨äººä»»åŠ¡ä¸­ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šVENTURAçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ç”Ÿæˆè·¯å¾„æ©ç æ¥æ•æ‰ç»†ç²’åº¦çš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥å¯¼èˆªè¡Œä¸ºï¼Œè€Œä¸æ˜¯ç›´æ¥é¢„æµ‹ä½çº§åŠ¨ä½œã€‚è¿™ç§æ–¹æ³•ä½¿å¾—æœºå™¨äººèƒ½å¤Ÿæ›´è‡ªç„¶åœ°éµå¾ªäººç±»æŒ‡ä»¤ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVENTURAçš„æ•´ä½“æ¶æ„åŒ…æ‹¬å›¾åƒæ‰©æ•£æ¨¡å‹çš„å¾®è°ƒã€è·¯å¾„æ©ç çš„ç”Ÿæˆå’Œè½»é‡çº§è¡Œä¸ºå…‹éš†ç­–ç•¥çš„åº”ç”¨ã€‚é¦–å…ˆï¼Œæ¨¡å‹ç”Ÿæˆè·¯å¾„æ©ç ï¼Œç„¶åé€šè¿‡è¡Œä¸ºå…‹éš†å°†å…¶è½¬åŒ–ä¸ºå¯æ‰§è¡Œçš„è½¨è¿¹ã€‚

**å…³é”®åˆ›æ–°**ï¼šVENTURAçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶è·¯å¾„æ©ç ç”Ÿæˆæœºåˆ¶ï¼Œè¿™ä¸ä¼ ç»Ÿçš„ç›´æ¥åŠ¨ä½œé¢„æµ‹æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œæ‰§è¡Œå¤æ‚çš„å¯¼èˆªä»»åŠ¡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒVENTURAä½¿ç”¨è‡ªç›‘ç£è·Ÿè¸ªæ¨¡å‹ç”Ÿæˆè·¯å¾„æ©ç ï¼Œå¹¶ç»“åˆVLMå¢å¼ºçš„æè¿°è¿›è¡Œç›‘ç£ï¼Œé¿å…äº†æ‰‹åŠ¨åƒç´ çº§æ ‡æ³¨çš„éœ€æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

VENTURAåœ¨å®é™…è¯„ä¼°ä¸­è¡¨ç°å‡ºè‰²ï¼ŒæˆåŠŸç‡æé«˜äº†33%ï¼Œç¢°æ’ç‡é™ä½äº†54%ã€‚ä¸ç°æœ‰åŸºç¡€æ¨¡å‹ç›¸æ¯”ï¼ŒVENTURAåœ¨ç‰©ä½“åˆ°è¾¾ã€éšœç¢ç‰©è§„é¿å’Œåœ°å½¢åå¥½ä»»åŠ¡ä¸Šå‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå±•ç°äº†è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

VENTURAçš„ç ”ç©¶æˆæœåœ¨æœºå™¨äººå¯¼èˆªã€æ™ºèƒ½å®¶å±…ã€æ— äººé©¾é©¶ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æé«˜æœºå™¨äººå¯¹äººç±»æŒ‡ä»¤çš„ç†è§£èƒ½åŠ›ï¼Œèƒ½å¤Ÿå®ç°æ›´æ™ºèƒ½çš„äº¤äº’å’Œè‡ªä¸»å†³ç­–ï¼Œæ¨åŠ¨æ™ºèƒ½æœºå™¨äººæŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Robots must adapt to diverse human instructions and operate safely in unstructured, open-world environments. Recent Vision-Language models (VLMs) offer strong priors for grounding language and perception, but remain difficult to steer for navigation due to differences in action spaces and pretraining objectives that hamper transferability to robotics tasks. Towards addressing this, we introduce VENTURA, a vision-language navigation system that finetunes internet-pretrained image diffusion models for path planning. Instead of directly predicting low-level actions, VENTURA generates a path mask (i.e. a visual plan) in image space that captures fine-grained, context-aware navigation behaviors. A lightweight behavior-cloning policy grounds these visual plans into executable trajectories, yielding an interface that follows natural language instructions to generate diverse robot behaviors. To scale training, we supervise on path masks derived from self-supervised tracking models paired with VLM-augmented captions, avoiding manual pixel-level annotation or highly engineered data collection setups. In extensive real-world evaluations, VENTURA outperforms state-of-the-art foundation model baselines on object reaching, obstacle avoidance, and terrain preference tasks, improving success rates by 33% and reducing collisions by 54% across both seen and unseen scenarios. Notably, we find that VENTURA generalizes to unseen combinations of distinct tasks, revealing emergent compositional capabilities. Videos, code, and additional materials: https://venturapath.github.io

