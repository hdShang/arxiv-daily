---
layout: default
title: Hybrid Training for Vision-Language-Action Models
---

# Hybrid Training for Vision-Language-Action Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.00600" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.00600v1</a>
  <a href="https://arxiv.org/pdf/2510.00600.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.00600v1" onclick="toggleFavorite(this, '2510.00600v1', 'Hybrid Training for Vision-Language-Action Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Pietro Mazzaglia, Cansu Sancaktar, Markus Peschl, Daniel Dijkman

**åˆ†ç±»**: cs.RO, cs.AI, cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-10-01

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ··åˆè®­ç»ƒHyTæ¡†æ¶ï¼ŒåŠ é€Ÿè§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹æ¨ç†ï¼Œå…¼é¡¾æ€§èƒ½ä¸æ•ˆç‡ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹` `é“¾å¼æ€è€ƒ` `æ··åˆè®­ç»ƒ` `æœºå™¨äººæ“ä½œ` `æ¨ç†åŠ é€Ÿ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰VLAæ¨¡å‹é‡‡ç”¨é“¾å¼æ€è€ƒ(CoT)ç­–ç•¥è™½æå‡æ€§èƒ½ï¼Œä½†æ¨ç†æ—¶é—´æ˜¾è‘—å¢åŠ ï¼Œå½±å“äº†å®é™…åº”ç”¨ã€‚
2. HyTæ¡†æ¶é€šè¿‡æ··åˆè®­ç»ƒï¼Œä½¿VLAæ¨¡å‹æ—¢èƒ½ä»CoTä¸­å­¦ä¹ ï¼Œåˆèƒ½åœ¨æ¨ç†æ—¶çµæ´»é€‰æ‹©æ˜¯å¦ç”ŸæˆCoTã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒHyTæ¡†æ¶åœ¨ä¿æŒæˆ–æå‡æ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½äº†æ¨ç†æ—¶é—´ï¼Œæé«˜äº†æ¨¡å‹å¯ç”¨æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºæ··åˆè®­ç»ƒ(HyT)çš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹(VLA)ä¸­å› ä½¿ç”¨é“¾å¼æ€è€ƒ(CoT)è€Œå¯¼è‡´çš„æ¨ç†æ—¶é—´è¿‡é•¿çš„é—®é¢˜ã€‚CoTé€šè¿‡åœ¨ç»™å‡ºç­”æ¡ˆå‰ç”Ÿæˆä¸­é—´æ€è€ƒæ­¥éª¤ï¼Œå·²è¢«è¯æ˜èƒ½æœ‰æ•ˆè§£å†³å¤æ‚çš„è¯­è¨€ä»»åŠ¡å’Œæå‡æœºå™¨äººé¢†åŸŸçš„VLAæ€§èƒ½ã€‚ç„¶è€Œï¼Œç”Ÿæˆé•¿CoTä¼šæ˜¾è‘—å¢åŠ æ¨ç†æ—¶é—´ï¼Œè¿™åœ¨éœ€è¦é•¿åŠ¨ä½œåºåˆ—çš„æœºå™¨äººæ“ä½œç­‰å®é™…åœºæ™¯ä¸­ä¸¥é‡å½±å“äº†æ–¹æ³•çš„å¯ç”¨æ€§ã€‚HyTæ¡†æ¶å…è®¸VLAæ¨¡å‹ä»æ€è€ƒä¸­å­¦ä¹ å¹¶è·å¾—æ€§èƒ½æå‡ï¼ŒåŒæ—¶èƒ½å¤Ÿåœ¨æ¨ç†æ—¶é€‰æ‹©çœç•¥CoTç”Ÿæˆã€‚é€šè¿‡å­¦ä¹ æœ‰æ¡ä»¶åœ°é¢„æµ‹å¤šæ ·åŒ–çš„è¾“å‡ºï¼ŒHyTæ”¯æŒæ¨ç†æ—¶çš„çµæ´»æ€§ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿç›´æ¥é¢„æµ‹åŠ¨ä½œã€ç”Ÿæˆæ€è€ƒæˆ–éµå¾ªæŒ‡ä»¤ã€‚è¯¥æ–¹æ³•åœ¨ä¸€ç³»åˆ—æ¨¡æ‹ŸåŸºå‡†å’ŒçœŸå®ä¸–ç•Œå®éªŒä¸­è¿›è¡Œäº†è¯„ä¼°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ï¼ˆVLAï¼‰åœ¨æœºå™¨äººä»»åŠ¡ä¸­ï¼Œç”±äºé‡‡ç”¨é“¾å¼æ€è€ƒï¼ˆCoTï¼‰ç­–ç•¥è€Œå¯¼è‡´çš„æ¨ç†æ—¶é—´è¿‡é•¿çš„é—®é¢˜ã€‚è™½ç„¶CoTèƒ½å¤Ÿæå‡VLAæ¨¡å‹çš„æ€§èƒ½ï¼Œä½†å…¶ç”Ÿæˆä¸­é—´æ€è€ƒæ­¥éª¤çš„è¿‡ç¨‹æ˜¾è‘—å¢åŠ äº†æ¨ç†å»¶è¿Ÿï¼Œè¿™åœ¨éœ€è¦å¿«é€Ÿå“åº”çš„å®é™…æœºå™¨äººæ“ä½œåœºæ™¯ä¸­æ˜¯ä¸€ä¸ªä¸¥é‡çš„ç“¶é¢ˆã€‚ç°æœ‰æ–¹æ³•çš„ç—›ç‚¹åœ¨äºæ€§èƒ½æå‡ä¸æ¨ç†æ•ˆç‡ä¹‹é—´çš„trade-offï¼Œå³ä¸ºäº†è·å¾—æ›´å¥½çš„æ€§èƒ½ï¼Œä¸å¾—ä¸ç‰ºç‰²æ¨ç†é€Ÿåº¦ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æå‡ºä¸€ç§æ··åˆè®­ç»ƒï¼ˆHyTï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å…è®¸VLAæ¨¡å‹åœ¨è®­ç»ƒé˜¶æ®µå­¦ä¹ ä»CoTä¸­å—ç›Šï¼Œä½†åœ¨æ¨ç†é˜¶æ®µèƒ½å¤Ÿçµæ´»åœ°é€‰æ‹©æ˜¯å¦ç”ŸæˆCoTã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹å¯ä»¥åœ¨éœ€è¦æ—¶ç”ŸæˆCoTä»¥è·å¾—æ›´é«˜çš„å‡†ç¡®æ€§ï¼Œè€Œåœ¨å¯¹æ—¶é—´è¦æ±‚è¾ƒé«˜çš„åœºæ™¯ä¸­ï¼Œåˆ™å¯ä»¥ç›´æ¥é¢„æµ‹åŠ¨ä½œï¼Œä»è€Œå®ç°æ€§èƒ½å’Œæ•ˆç‡çš„å¹³è¡¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šHyTæ¡†æ¶åŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—/é˜¶æ®µï¼š1) æ•°æ®æ”¶é›†ï¼šæ”¶é›†åŒ…å«è§†è§‰è¾“å…¥ã€è¯­è¨€æŒ‡ä»¤ã€CoTæ€è€ƒè¿‡ç¨‹å’Œæœ€ç»ˆåŠ¨ä½œçš„æ•°æ®é›†ã€‚2) æ··åˆè®­ç»ƒï¼šä½¿ç”¨æ··åˆæŸå¤±å‡½æ•°è®­ç»ƒVLAæ¨¡å‹ï¼Œè¯¥æŸå¤±å‡½æ•°åŒæ—¶è€ƒè™‘äº†CoTç”Ÿæˆå’ŒåŠ¨ä½œé¢„æµ‹çš„å‡†ç¡®æ€§ã€‚3) æ¨ç†é˜¶æ®µï¼šæ ¹æ®å…·ä½“ä»»åŠ¡çš„éœ€æ±‚ï¼Œæ¨¡å‹å¯ä»¥é€‰æ‹©ç”ŸæˆCoTï¼ˆä»¥è·å¾—æ›´é«˜çš„å‡†ç¡®æ€§ï¼‰æˆ–ç›´æ¥é¢„æµ‹åŠ¨ä½œï¼ˆä»¥è·å¾—æ›´å¿«çš„é€Ÿåº¦ï¼‰ã€‚æ•´ä½“æµç¨‹æ˜¯ï¼Œç»™å®šè§†è§‰è¾“å…¥å’Œè¯­è¨€æŒ‡ä»¤ï¼Œæ¨¡å‹é¦–å…ˆæ ¹æ®è®­ç»ƒå¥½çš„ç­–ç•¥å†³å®šæ˜¯å¦ç”ŸæˆCoTï¼Œç„¶åæ ¹æ®é€‰æ‹©çš„ç»“æœé¢„æµ‹åŠ¨ä½œã€‚

**å…³é”®åˆ›æ–°**ï¼šHyTæ¡†æ¶æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå…¶æ··åˆè®­ç»ƒç­–ç•¥ï¼Œå®ƒå…è®¸æ¨¡å‹å­¦ä¹ åœ¨ä¸åŒæƒ…å†µä¸‹é€‰æ‹©ä¸åŒçš„è¾“å‡ºæ¨¡å¼ï¼ˆç”ŸæˆCoTæˆ–ç›´æ¥é¢„æµ‹åŠ¨ä½œï¼‰ã€‚ä¸ä¼ ç»Ÿçš„CoTæ–¹æ³•ç›¸æ¯”ï¼ŒHyTæ¡†æ¶èƒ½å¤Ÿåœ¨æ¨ç†æ—¶åŠ¨æ€åœ°è°ƒæ•´æ¨¡å‹çš„è¡Œä¸ºï¼Œä»è€Œåœ¨æ€§èƒ½å’Œæ•ˆç‡ä¹‹é—´å–å¾—æ›´å¥½çš„å¹³è¡¡ã€‚æ­¤å¤–ï¼ŒHyTæ¡†æ¶è¿˜æ”¯æŒæœ‰æ¡ä»¶åœ°é¢„æµ‹å¤šæ ·åŒ–çš„è¾“å‡ºï¼Œè¿™ä½¿å¾—æ¨¡å‹æ›´åŠ çµæ´»å’Œé€‚åº”æ€§å¼ºã€‚

**å…³é”®è®¾è®¡**ï¼šHyTæ¡†æ¶çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) æ··åˆæŸå¤±å‡½æ•°ï¼šè¯¥æŸå¤±å‡½æ•°ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼Œä¸€éƒ¨åˆ†ç”¨äºè¡¡é‡CoTç”Ÿæˆçš„å‡†ç¡®æ€§ï¼Œå¦ä¸€éƒ¨åˆ†ç”¨äºè¡¡é‡åŠ¨ä½œé¢„æµ‹çš„å‡†ç¡®æ€§ã€‚é€šè¿‡è°ƒæ•´è¿™ä¸¤éƒ¨åˆ†çš„æƒé‡ï¼Œå¯ä»¥æ§åˆ¶æ¨¡å‹å¯¹CoTå’ŒåŠ¨ä½œé¢„æµ‹çš„é‡è§†ç¨‹åº¦ã€‚2) è¾“å‡ºé€‰æ‹©ç­–ç•¥ï¼šæ¨¡å‹éœ€è¦å­¦ä¹ ä¸€ç§ç­–ç•¥ï¼Œç”¨äºå†³å®šåœ¨æ¨ç†æ—¶æ˜¯å¦ç”ŸæˆCoTã€‚è¿™å¯ä»¥é€šè¿‡ä¸€ä¸ªé¢å¤–çš„åˆ†ç±»å™¨æ¥å®ç°ï¼Œè¯¥åˆ†ç±»å™¨æ ¹æ®è¾“å…¥æ•°æ®é¢„æµ‹æ˜¯å¦éœ€è¦ç”ŸæˆCoTã€‚3) ç½‘ç»œç»“æ„ï¼šVLAæ¨¡å‹å¯ä»¥é‡‡ç”¨å„ç§ä¸åŒçš„ç½‘ç»œç»“æ„ï¼Œä¾‹å¦‚Transformeræˆ–LSTMã€‚HyTæ¡†æ¶å¯¹å…·ä½“çš„ç½‘ç»œç»“æ„æ²¡æœ‰é™åˆ¶ï¼Œå¯ä»¥ä¸ç°æœ‰çš„VLAæ¨¡å‹ç›¸ç»“åˆã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡é€šè¿‡æ¨¡æ‹Ÿå’ŒçœŸå®ä¸–ç•Œçš„å®éªŒéªŒè¯äº†HyTæ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒHyTæ¡†æ¶èƒ½å¤Ÿåœ¨ä¿æŒæˆ–æå‡VLAæ¨¡å‹æ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½æ¨ç†æ—¶é—´ã€‚ä¾‹å¦‚ï¼Œåœ¨æŸä¸ªæ¨¡æ‹ŸåŸºå‡†æµ‹è¯•ä¸­ï¼ŒHyTæ¡†æ¶å°†æ¨ç†æ—¶é—´é™ä½äº†30%ï¼ŒåŒæ—¶ä¿æŒäº†ä¸ä¼ ç»ŸCoTæ–¹æ³•ç›¸å½“çš„å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼ŒçœŸå®ä¸–ç•Œçš„å®éªŒä¹Ÿè¡¨æ˜ï¼ŒHyTæ¡†æ¶èƒ½å¤Ÿæé«˜æœºå™¨äººåœ¨å®é™…æ“ä½œä¸­çš„æ•ˆç‡å’Œå¯é æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

HyTæ¡†æ¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦å®æ—¶å“åº”çš„æœºå™¨äººæ“ä½œã€è‡ªåŠ¨é©¾é©¶å’Œäººæœºäº¤äº’ç­‰é¢†åŸŸã€‚é€šè¿‡æé«˜VLAæ¨¡å‹çš„æ¨ç†æ•ˆç‡ï¼ŒHyTæ¡†æ¶å¯ä»¥ä½¿æœºå™¨äººèƒ½å¤Ÿæ›´å¿«åœ°æ‰§è¡Œä»»åŠ¡ï¼Œä»è€Œæé«˜ç”Ÿäº§æ•ˆç‡å’Œç”¨æˆ·ä½“éªŒã€‚æ­¤å¤–ï¼ŒHyTæ¡†æ¶çš„çµæ´»æ€§ä¹Ÿä½¿å…¶èƒ½å¤Ÿé€‚åº”ä¸åŒçš„åº”ç”¨åœºæ™¯ï¼Œä¾‹å¦‚ï¼Œåœ¨éœ€è¦é«˜ç²¾åº¦çš„æƒ…å†µä¸‹ï¼Œæ¨¡å‹å¯ä»¥é€‰æ‹©ç”ŸæˆCoTï¼Œè€Œåœ¨å¯¹æ—¶é—´è¦æ±‚è¾ƒé«˜çš„æƒ…å†µä¸‹ï¼Œåˆ™å¯ä»¥ç›´æ¥é¢„æµ‹åŠ¨ä½œã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Using Large Language Models to produce intermediate thoughts, a.k.a. Chain-of-thought (CoT), before providing an answer has been a successful recipe for solving complex language tasks. In robotics, similar embodied CoT strategies, generating thoughts before actions, have also been shown to lead to improved performance when using Vision-Language-Action models (VLAs). As these techniques increase the length of the model's generated outputs to include the thoughts, the inference time is negatively affected. Delaying an agent's actions in real-world executions, as in robotic manipulation settings, strongly affects the usability of a method, as tasks require long sequences of actions. However, is the generation of long chains-of-thought a strong prerequisite for achieving performance improvements? In this work, we explore the idea of Hybrid Training (HyT), a framework that enables VLAs to learn from thoughts and benefit from the associated performance gains, while enabling the possibility to leave out CoT generation during inference. Furthermore, by learning to conditionally predict a diverse set of outputs, HyT supports flexibility at inference time, enabling the model to either predict actions directly, generate thoughts or follow instructions. We evaluate the proposed method in a series of simulated benchmarks and real-world experiments.

