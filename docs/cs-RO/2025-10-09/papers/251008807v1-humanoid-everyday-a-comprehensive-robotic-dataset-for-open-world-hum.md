---
layout: default
title: Humanoid Everyday: A Comprehensive Robotic Dataset for Open-World Humanoid Manipulation
---

# Humanoid Everyday: A Comprehensive Robotic Dataset for Open-World Humanoid Manipulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.08807" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.08807v1</a>
  <a href="https://arxiv.org/pdf/2510.08807.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.08807v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.08807v1', 'Humanoid Everyday: A Comprehensive Robotic Dataset for Open-World Humanoid Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhenyu Zhao, Hongyi Jing, Xiawei Liu, Jiageng Mao, Abha Jha, Hanwen Yang, Rong Xue, Sergey Zakharor, Vitor Guizilini, Yue Wang

**åˆ†ç±»**: cs.RO, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-10-09

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Humanoid Everydayï¼šä¸€ä¸ªé¢å‘å¼€æ”¾ä¸–ç•Œäººå‹æœºå™¨äººæ“ä½œçš„ç»¼åˆæ•°æ®é›†**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `äººå½¢æœºå™¨äºº` `æ“ä½œæ•°æ®é›†` `äººæœºäº¤äº’` `å¼ºåŒ–å­¦ä¹ ` `å¤šæ¨¡æ€æ„ŸçŸ¥` `é¥æ“ä½œ` `äº‘å¹³å°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æœºå™¨äººå­¦ä¹ æ•°æ®é›†ä¸»è¦å…³æ³¨å›ºå®šæœºæ¢°è‡‚ï¼Œç¼ºä¹å¯¹å¤æ‚äººå‹æœºå™¨äººå…¨èº«æ“ä½œå’Œäººæœºäº¤äº’çš„æ”¯æŒã€‚
2. Humanoid Everydayæ•°æ®é›†é€šè¿‡äººå·¥ç›‘ç£é¥æ“ä½œï¼Œæ”¶é›†äº†åŒ…å«å¤šæ¨¡æ€æ•°æ®å’Œè‡ªç„¶è¯­è¨€æ ‡æ³¨çš„å¤§è§„æ¨¡äººå‹æœºå™¨äººæ“ä½œæ•°æ®ã€‚
3. è®ºæ–‡åˆ†æäº†ç°æœ‰ç­–ç•¥å­¦ä¹ æ–¹æ³•åœ¨æ•°æ®é›†ä¸Šçš„è¡¨ç°ï¼Œå¹¶æä¾›äº†ä¸€ä¸ªåŸºäºäº‘çš„è¯„ä¼°å¹³å°ï¼Œä»¥ä¿ƒè¿›æ ‡å‡†åŒ–è¯„ä¼°ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äººå½¢æœºå™¨äººåœ¨è¿åŠ¨å’Œçµå·§æ“ä½œæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œå½“å‰æœºå™¨äººå­¦ä¹ æ•°æ®é›†å’ŒåŸºå‡†æµ‹è¯•ä¸»è¦é›†ä¸­åœ¨å›ºå®šæœºå™¨äººæ‰‹è‡‚ä¸Šï¼Œè€Œç°æœ‰çš„äººå½¢æœºå™¨äººæ•°æ®é›†è¦ä¹ˆå±€é™äºå›ºå®šç¯å¢ƒï¼Œè¦ä¹ˆåœ¨ä»»åŠ¡å¤šæ ·æ€§æ–¹é¢å—åˆ°é™åˆ¶ï¼Œé€šå¸¸ç¼ºä¹äººæœºäº¤äº’å’Œä¸‹è‚¢è¿åŠ¨ã€‚æ­¤å¤–ï¼Œç¼ºä¹ç”¨äºè¯„ä¼°äººå½¢æœºå™¨äººæ•°æ®å­¦ä¹ ç­–ç•¥çš„æ ‡å‡†åŒ–è¯„ä¼°å¹³å°ã€‚æœ¬æ–‡æå‡ºäº†Humanoid Everydayï¼Œä¸€ä¸ªå¤§è§„æ¨¡ã€å¤šæ ·åŒ–çš„äººå½¢æœºå™¨äººæ“ä½œæ•°æ®é›†ï¼Œå…¶ç‰¹ç‚¹æ˜¯å¹¿æ³›çš„ä»»åŠ¡ç§ç±»ï¼ŒåŒ…æ‹¬çµå·§çš„ç‰©ä½“æ“ä½œã€äººæœºäº¤äº’ã€è¿åŠ¨é›†æˆåŠ¨ä½œç­‰ã€‚åˆ©ç”¨é«˜æ•ˆçš„äººå·¥ç›‘ç£é¥æ“ä½œæµç¨‹ï¼ŒHumanoid Everydayèšåˆäº†é«˜è´¨é‡çš„å¤šæ¨¡æ€æ„ŸçŸ¥æ•°æ®ï¼ŒåŒ…æ‹¬RGBã€æ·±åº¦ã€æ¿€å…‰é›·è¾¾å’Œè§¦è§‰è¾“å…¥ï¼Œä»¥åŠè‡ªç„¶è¯­è¨€æ³¨é‡Šï¼ŒåŒ…å«10.3kæ¡è½¨è¿¹å’Œè¶…è¿‡300ä¸‡å¸§çš„æ•°æ®ï¼Œæ¶µç›–7å¤§ç±»260ä¸ªä»»åŠ¡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¯¹æ•°æ®é›†ä¸Šå…·æœ‰ä»£è¡¨æ€§çš„ç­–ç•¥å­¦ä¹ æ–¹æ³•è¿›è¡Œäº†åˆ†æï¼Œæ·±å…¥äº†è§£äº†å®ƒä»¬åœ¨ä¸åŒä»»åŠ¡ç±»åˆ«ä¸­çš„ä¼˜åŠ¿å’Œå±€é™æ€§ã€‚ä¸ºäº†è¿›è¡Œæ ‡å‡†åŒ–è¯„ä¼°ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªåŸºäºäº‘çš„è¯„ä¼°å¹³å°ï¼Œå…è®¸ç ”ç©¶äººå‘˜åœ¨æˆ‘ä»¬çš„å—æ§ç¯å¢ƒä¸­æ— ç¼éƒ¨ç½²ä»–ä»¬çš„ç­–ç•¥å¹¶è·å¾—æ€§èƒ½åé¦ˆã€‚é€šè¿‡å‘å¸ƒHumanoid Everydayä»¥åŠæˆ‘ä»¬çš„ç­–ç•¥å­¦ä¹ åˆ†æå’Œä¸€ä¸ªæ ‡å‡†åŒ–çš„åŸºäºäº‘çš„è¯„ä¼°å¹³å°ï¼Œæˆ‘ä»¬æ—¨åœ¨æ¨è¿›é€šç”¨äººå½¢æœºå™¨äººæ“ä½œçš„ç ”ç©¶ï¼Œå¹¶ä¸ºç°å®åœºæ™¯ä¸­æ›´å¼ºå¤§å’Œå…·èº«åŒ–çš„æœºå™¨äººä»£ç†å¥ å®šåŸºç¡€ã€‚æˆ‘ä»¬çš„æ•°æ®é›†ã€æ•°æ®æ”¶é›†ä»£ç å’Œäº‘è¯„ä¼°ç½‘ç«™å·²åœ¨æˆ‘ä»¬çš„é¡¹ç›®ç½‘ç«™ä¸Šå…¬å¼€å‘å¸ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„äººå½¢æœºå™¨äººæ•°æ®é›†åœ¨ä»»åŠ¡å¤šæ ·æ€§ã€ç¯å¢ƒå¤æ‚æ€§ä»¥åŠäººæœºäº¤äº’æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥æ”¯æŒé€šç”¨äººå½¢æœºå™¨äººæ“ä½œçš„å­¦ä¹ å’Œè¯„ä¼°ã€‚æ­¤å¤–ï¼Œç¼ºä¹ç»Ÿä¸€çš„è¯„ä¼°å¹³å°æ¥æ¯”è¾ƒä¸åŒå­¦ä¹ ç­–ç•¥çš„æ€§èƒ½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡äººå·¥ç›‘ç£é¥æ“ä½œçš„æ–¹å¼ï¼Œæ”¶é›†å¤§è§„æ¨¡ã€å¤šæ ·åŒ–çš„çœŸå®ä¸–ç•Œäººå½¢æœºå™¨äººæ“ä½œæ•°æ®ï¼ŒåŒ…æ‹¬å¤šæ¨¡æ€ä¼ æ„Ÿå™¨ä¿¡æ¯å’Œè‡ªç„¶è¯­è¨€æè¿°ã€‚åŒæ—¶ï¼Œæ„å»ºä¸€ä¸ªåŸºäºäº‘çš„è¯„ä¼°å¹³å°ï¼Œä¸ºç ”ç©¶äººå‘˜æä¾›æ ‡å‡†åŒ–çš„ç­–ç•¥è¯„ä¼°ç¯å¢ƒã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šHumanoid Everydayæ•°æ®é›†çš„æ„å»ºæµç¨‹ä¸»è¦åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ•°æ®æ ‡æ³¨å’Œæ•°æ®ç®¡ç†ä¸‰ä¸ªé˜¶æ®µã€‚æ•°æ®æ”¶é›†é˜¶æ®µé‡‡ç”¨äººå·¥ç›‘ç£é¥æ“ä½œï¼Œç”±äººç±»æ“ä½œå‘˜æ§åˆ¶äººå½¢æœºå™¨äººå®Œæˆå„ç§ä»»åŠ¡ã€‚æ•°æ®æ ‡æ³¨é˜¶æ®µå¯¹æ”¶é›†åˆ°çš„æ•°æ®è¿›è¡Œå¤šæ¨¡æ€æ ‡æ³¨ï¼ŒåŒ…æ‹¬RGBå›¾åƒã€æ·±åº¦å›¾åƒã€æ¿€å…‰é›·è¾¾ç‚¹äº‘ã€è§¦è§‰ä¿¡æ¯ä»¥åŠè‡ªç„¶è¯­è¨€æè¿°ã€‚æ•°æ®ç®¡ç†é˜¶æ®µå¯¹æ•°æ®è¿›è¡Œæ¸…æ´—ã€æ•´ç†å’Œå­˜å‚¨ï¼Œå¹¶æä¾›APIæ–¹ä¾¿ç”¨æˆ·è®¿é—®ã€‚åŒæ—¶ï¼Œè®ºæ–‡è¿˜æ„å»ºäº†ä¸€ä¸ªåŸºäºäº‘çš„è¯„ä¼°å¹³å°ï¼Œç”¨æˆ·å¯ä»¥å°†è‡ªå·±çš„ç­–ç•¥éƒ¨ç½²åˆ°å¹³å°ä¸Šè¿›è¡Œè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ•°æ®é›†çš„å…³é”®åˆ›æ–°åœ¨äºå…¶è§„æ¨¡å’Œå¤šæ ·æ€§ï¼Œæ¶µç›–äº†260ä¸ªä»»åŠ¡ï¼Œæ¶‰åŠçµå·§æ“ä½œã€äººæœºäº¤äº’å’Œè¿åŠ¨é›†æˆç­‰å¤šä¸ªæ–¹é¢ã€‚æ­¤å¤–ï¼Œæ•°æ®é›†è¿˜æä¾›äº†å¤šæ¨¡æ€ä¼ æ„Ÿå™¨ä¿¡æ¯å’Œè‡ªç„¶è¯­è¨€æè¿°ï¼Œä¸ºç ”ç©¶äººå‘˜æä¾›äº†æ›´ä¸°å¯Œçš„ä¿¡æ¯ã€‚åŸºäºäº‘çš„è¯„ä¼°å¹³å°ä¹Ÿä¸ºç­–ç•¥è¯„ä¼°æä¾›äº†æ ‡å‡†åŒ–çš„ç¯å¢ƒã€‚

**å…³é”®è®¾è®¡**ï¼šæ•°æ®æ”¶é›†é‡‡ç”¨é«˜æ•ˆçš„äººå·¥ç›‘ç£é¥æ“ä½œæµç¨‹ï¼Œä¿è¯äº†æ•°æ®çš„è´¨é‡å’Œå¤šæ ·æ€§ã€‚æ•°æ®æ ‡æ³¨é‡‡ç”¨äº†å¤šæ¨¡æ€æ ‡æ³¨æ–¹æ¡ˆï¼Œä¸ºç ”ç©¶äººå‘˜æä¾›äº†æ›´ä¸°å¯Œçš„ä¿¡æ¯ã€‚åŸºäºäº‘çš„è¯„ä¼°å¹³å°é‡‡ç”¨äº†æ¨¡å—åŒ–è®¾è®¡ï¼Œæ–¹ä¾¿ç”¨æˆ·éƒ¨ç½²å’Œè¯„ä¼°è‡ªå·±çš„ç­–ç•¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡æ„å»ºäº†ä¸€ä¸ªåŒ…å«10.3kæ¡è½¨è¿¹å’Œè¶…è¿‡300ä¸‡å¸§çš„å¤§è§„æ¨¡äººå½¢æœºå™¨äººæ“ä½œæ•°æ®é›†ï¼Œæ¶µç›–260ä¸ªä»»åŠ¡ã€‚é€šè¿‡å¯¹ç°æœ‰ç­–ç•¥å­¦ä¹ æ–¹æ³•åœ¨æ•°æ®é›†ä¸Šçš„åˆ†æï¼Œæ­ç¤ºäº†å®ƒä»¬åœ¨ä¸åŒä»»åŠ¡ç±»åˆ«ä¸­çš„ä¼˜åŠ¿å’Œå±€é™æ€§ã€‚åŸºäºäº‘çš„è¯„ä¼°å¹³å°ä¸ºç­–ç•¥è¯„ä¼°æä¾›äº†æ ‡å‡†åŒ–çš„ç¯å¢ƒã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºäººå½¢æœºå™¨äººæ“ä½œã€äººæœºäº¤äº’ã€å¼ºåŒ–å­¦ä¹ ç­‰é¢†åŸŸã€‚Humanoid Everydayæ•°æ®é›†èƒ½å¤Ÿä¿ƒè¿›é€šç”¨äººå½¢æœºå™¨äººæ“ä½œç®—æ³•çš„å¼€å‘ï¼Œæé«˜æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„é€‚åº”æ€§å’Œè‡ªä¸»æ€§ã€‚åŸºäºäº‘çš„è¯„ä¼°å¹³å°èƒ½å¤Ÿä¸ºç ”ç©¶äººå‘˜æä¾›æ ‡å‡†åŒ–çš„è¯„ä¼°ç¯å¢ƒï¼ŒåŠ é€Ÿç›¸å…³ç ”ç©¶çš„è¿›å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> From loco-motion to dextrous manipulation, humanoid robots have made remarkable strides in demonstrating complex full-body capabilities. However, the majority of current robot learning datasets and benchmarks mainly focus on stationary robot arms, and the few existing humanoid datasets are either confined to fixed environments or limited in task diversity, often lacking human-humanoid interaction and lower-body locomotion. Moreover, there are a few standardized evaluation platforms for benchmarking learning-based policies on humanoid data. In this work, we present Humanoid Everyday, a large-scale and diverse humanoid manipulation dataset characterized by extensive task variety involving dextrous object manipulation, human-humanoid interaction, locomotion-integrated actions, and more. Leveraging a highly efficient human-supervised teleoperation pipeline, Humanoid Everyday aggregates high-quality multimodal sensory data, including RGB, depth, LiDAR, and tactile inputs, together with natural language annotations, comprising 10.3k trajectories and over 3 million frames of data across 260 tasks across 7 broad categories. In addition, we conduct an analysis of representative policy learning methods on our dataset, providing insights into their strengths and limitations across different task categories. For standardized evaluation, we introduce a cloud-based evaluation platform that allows researchers to seamlessly deploy their policies in our controlled setting and receive performance feedback. By releasing Humanoid Everyday along with our policy learning analysis and a standardized cloud-based evaluation platform, we intend to advance research in general-purpose humanoid manipulation and lay the groundwork for more capable and embodied robotic agents in real-world scenarios. Our dataset, data collection code, and cloud evaluation website are made publicly available on our project website.

