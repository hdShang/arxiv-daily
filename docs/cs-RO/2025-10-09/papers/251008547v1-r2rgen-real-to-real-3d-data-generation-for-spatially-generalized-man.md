---
layout: default
title: R2RGEN: Real-to-Real 3D Data Generation for Spatially Generalized Manipulation
---

# R2RGEN: Real-to-Real 3D Data Generation for Spatially Generalized Manipulation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.08547" target="_blank" class="toolbar-btn">arXiv: 2510.08547v1</a>
    <a href="https://arxiv.org/pdf/2510.08547.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.08547v1" 
            onclick="toggleFavorite(this, '2510.08547v1', 'R2RGEN: Real-to-Real 3D Data Generation for Spatially Generalized Manipulation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Xiuwei Xu, Angyuan Ma, Hankun Li, Bingyao Yu, Zheng Zhu, Jie Zhou, Jiwen Lu

**ÂàÜÁ±ª**: cs.RO, cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-09

**Â§áÊ≥®**: Project page: https://r2rgen.github.io/

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫R2RGenÔºåÁî®‰∫éÁîüÊàêÁúüÂÆû3DÊï∞ÊçÆÔºåÊèêÂçáÊú∫Âô®‰∫∫Á©∫Èó¥Ê≥õÂåñÊìç‰ΩúËÉΩÂäõ„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Êú∫Âô®‰∫∫Êìç‰Ωú` `Á©∫Èó¥Ê≥õÂåñ` `Êï∞ÊçÆÁîüÊàê` `ÁÇπ‰∫ëÂ§ÑÁêÜ` `Ê®°‰ªøÂ≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®Êú∫Âô®‰∫∫Êìç‰ΩúÁöÑÁ©∫Èó¥Ê≥õÂåñÊÄßÊñπÈù¢Â≠òÂú®‰∏çË∂≥Ôºå‰∏ªË¶ÅÊåëÊàòÂú®‰∫éÊ®°ÊãüÂà∞ÁúüÂÆûÁöÑÂ∑ÆË∑ù‰ª•ÂèäÂØπÂõ∫ÂÆöÂú∫ÊôØÂíåËßÜËßíÁöÑÈôêÂà∂„ÄÇ
2. R2RGenÈÄöËøáÁõ¥Êé•Â¢ûÂº∫ÁúüÂÆû‰∏ñÁïåÁöÑÁÇπ‰∫ëÊï∞ÊçÆÔºåÈÅøÂÖç‰∫ÜÊ®°ÊãüÂô®ÂíåÊ∏≤ÊüìÔºå‰ªéËÄåÈ´òÊïàÂú∞ÁîüÊàêÁ©∫Èó¥Â§öÊ†∑ÊÄßÁöÑËÆ≠ÁªÉÊï∞ÊçÆ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåR2RGenÊòæËëóÊèêÈ´ò‰∫ÜÊï∞ÊçÆÊïàÁéáÔºåÂπ∂ÂÖ∑Â§áÂú®ÁßªÂä®Êìç‰Ωú‰∏≠Êâ©Â±ïÂíåÂ∫îÁî®ÁöÑÊΩúÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

‰∏∫‰∫ÜÂÆûÁé∞Êú∫Âô®‰∫∫Êìç‰ΩúÁöÑÊ≥õÂåñÊÄßÔºåÁ©∫Èó¥Ê≥õÂåñÊòØÊúÄÂü∫Êú¨ÁöÑËÉΩÂäõÔºåÂÆÉË¶ÅÊ±ÇÁ≠ñÁï•Âú®‰∏çÂêåÁöÑÁâ©‰ΩìÁ©∫Èó¥ÂàÜÂ∏É„ÄÅÁéØÂ¢ÉÂíåÊú∫Âô®‰∫∫Ëá™Ë∫´‰∏ãÈÉΩËÉΩÁ®≥ÂÅ•Âú∞Â∑•‰Ωú„ÄÇ‰∏∫‰∫ÜÂÆûÁé∞Ëøô‰∏ÄÁÇπÔºåÈúÄË¶ÅÊî∂ÈõÜÂ§ßÈáèÁöÑ‰∫∫Â∑•ÊºîÁ§∫Ôºå‰ª•Ë¶ÜÁõñ‰∏çÂêåÁöÑÁ©∫Èó¥ÈÖçÁΩÆÔºå‰ªéËÄåÈÄöËøáÊ®°‰ªøÂ≠¶‰π†ËÆ≠ÁªÉ‰∏Ä‰∏™ÈÄöÁî®ÁöÑËßÜËßâËøêÂä®Á≠ñÁï•„ÄÇÂÖàÂâçÁöÑÂ∑•‰ΩúÊé¢Á¥¢‰∫Ü‰∏Ä‰∏™ÊúâÂ∏åÊúõÁöÑÊñπÂêëÔºåÂç≥Âà©Áî®Êï∞ÊçÆÁîüÊàê‰ªéÊúÄÂ∞ëÁöÑÊ∫êÊºîÁ§∫‰∏≠Ëé∑Âèñ‰∏∞ÂØåÁöÑÁ©∫Èó¥Â§öÊ†∑ÊÄßÊï∞ÊçÆ„ÄÇÁÑ∂ËÄåÔºåÂ§ßÂ§öÊï∞ÊñπÊ≥ïÈù¢‰∏¥ÁùÄÊòæËëóÁöÑÊ®°ÊãüÂà∞ÁúüÂÆûÂ∑ÆË∑ùÔºåÂπ∂‰∏îÈÄöÂ∏∏‰ªÖÈôê‰∫éÂèóÈôêÁöÑËÆæÁΩÆÔºå‰æãÂ¶ÇÂõ∫ÂÆöÂü∫Â∫ßÂú∫ÊôØÂíåÈ¢ÑÂÆö‰πâÁöÑÁõ∏Êú∫ËßÜËßí„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™ÁúüÂÆûÂà∞ÁúüÂÆûÁöÑ3DÊï∞ÊçÆÁîüÊàêÊ°ÜÊû∂ÔºàR2RGenÔºâÔºåÂÆÉÁõ¥Êé•Â¢ûÂº∫ÁÇπ‰∫ëËßÇÊµã-Âä®‰ΩúÂØπ‰ª•ÁîüÊàêÁúüÂÆû‰∏ñÁïåÊï∞ÊçÆ„ÄÇR2RGenÊó†ÈúÄÊ®°ÊãüÂô®ÂíåÊ∏≤ÊüìÔºåÂõ†Ê≠§È´òÊïà‰∏îÂç≥ÊèíÂç≥Áî®„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÁªôÂÆöÂçï‰∏™Ê∫êÊºîÁ§∫ÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏ÄÁßçÊ≥®ÈáäÊú∫Âà∂ÔºåÁî®‰∫éÁªÜÁ≤íÂ∫¶Âú∞Ëß£ÊûêÂú∫ÊôØÂíåËΩ®Ëøπ„ÄÇÊèêÂá∫‰∫Ü‰∏ÄÁßçÂàÜÁªÑÂ¢ûÂº∫Á≠ñÁï•Ôºå‰ª•Â§ÑÁêÜÂ§çÊùÇÁöÑÂ§öÂØπË±°ÁªÑÂêàÂíå‰∏çÂêåÁöÑ‰ªªÂä°Á∫¶Êùü„ÄÇÊàë‰ª¨Ëøõ‰∏ÄÊ≠•ÊèêÂá∫‰∫ÜÁõ∏Êú∫ÊÑüÁü•Â§ÑÁêÜÔºå‰ª•‰ΩøÁîüÊàêÊï∞ÊçÆÁöÑÂàÜÂ∏É‰∏éÁúüÂÆû‰∏ñÁïå3D‰º†ÊÑüÂô®ÂØπÈΩê„ÄÇÁªèÈ™åË°®ÊòéÔºåR2RGenÂú®ÂπøÊ≥õÁöÑÂÆûÈ™å‰∏≠ÊòæËëóÊèêÈ´ò‰∫ÜÊï∞ÊçÆÊïàÁéáÔºåÂπ∂Â±ïÁ§∫‰∫ÜÂú®ÁßªÂä®Êìç‰Ωú‰∏≠ËøõË°åÊâ©Â±ïÂíåÂ∫îÁî®ÁöÑÂº∫Â§ßÊΩúÂäõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Êú∫Âô®‰∫∫Êìç‰Ωú‰∏≠Á©∫Èó¥Ê≥õÂåñËÉΩÂäõ‰∏çË∂≥ÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ï‰æùËµñÂ§ßÈáè‰∫∫Â∑•Ê†áÊ≥®Êï∞ÊçÆÊàñÂ≠òÂú®Ê®°ÊãüÂà∞ÁúüÂÆûÁöÑÂ∑ÆË∑ùÔºåÈôêÂà∂‰∫ÜÁ≠ñÁï•Âú®ÁúüÂÆû‰∏ñÁïåÂ§çÊùÇÁéØÂ¢É‰∏≠ÁöÑÂ∫îÁî®„ÄÇËøô‰∫õÊñπÊ≥ïÈÄöÂ∏∏Âú®Âõ∫ÂÆöÂü∫Â∫ßÂíåÈ¢ÑÂÆö‰πâÁõ∏Êú∫ËßÜËßí‰∏ãËøõË°åÔºåÈöæ‰ª•Êé®ÂπøÂà∞Êõ¥ÂπøÊ≥õÁöÑÂú∫ÊôØ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöR2RGenÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÁõ¥Êé•Âú®ÁúüÂÆûÊï∞ÊçÆ‰∏äËøõË°åÂ¢ûÂº∫ÔºåÈÅøÂÖçÊ®°ÊãüÂô®Â∏¶Êù•ÁöÑÂÅèÂ∑Æ„ÄÇÈÄöËøáÂØπÁúüÂÆûÂú∫ÊôØÁöÑÁÇπ‰∫ëÊï∞ÊçÆËøõË°åÁªÜÁ≤íÂ∫¶ÁöÑËß£ÊûêÂíåÂàÜÁªÑÂ¢ûÂº∫ÔºåÁîüÊàêÂÖ∑ÊúâÁ©∫Èó¥Â§öÊ†∑ÊÄßÁöÑËÆ≠ÁªÉÊï∞ÊçÆÔºå‰ªéËÄåÊèêÈ´òÁ≠ñÁï•ÁöÑÁ©∫Èó¥Ê≥õÂåñËÉΩÂäõ„ÄÇËøôÁßçÊñπÊ≥ïÊó†ÈúÄÊ∏≤ÊüìÔºåÊïàÁéáÊõ¥È´òÔºåÊõ¥Êòì‰∫éÈÉ®ÁΩ≤„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöR2RGenÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Èò∂ÊÆµÔºö1) **Êï∞ÊçÆÈááÈõÜ**Ôºö‰ªéÁúüÂÆû‰∏ñÁïåËé∑ÂèñÂ∞ëÈáèÊ∫êÊºîÁ§∫Êï∞ÊçÆ„ÄÇ2) **Âú∫ÊôØÂíåËΩ®ËøπËß£Êûê**ÔºöÂØπÊ∫êÊºîÁ§∫Êï∞ÊçÆËøõË°åÁªÜÁ≤íÂ∫¶ÁöÑÂú∫ÊôØÂíåËΩ®ËøπËß£ÊûêÔºåÊ†áÊ≥®Áâ©‰ΩìÂíåÂä®‰Ωú„ÄÇ3) **ÂàÜÁªÑÂ¢ûÂº∫**ÔºöÈááÁî®ÂàÜÁªÑÂ¢ûÂº∫Á≠ñÁï•ÔºåÂ§ÑÁêÜÂ§çÊùÇÁöÑÂ§öÁâ©‰ΩìÁªÑÂêàÂíå‰ªªÂä°Á∫¶ÊùüÔºåÁîüÊàêÊñ∞ÁöÑÁÇπ‰∫ëÊï∞ÊçÆ„ÄÇ4) **Áõ∏Êú∫ÊÑüÁü•Â§ÑÁêÜ**ÔºöÂØπÁîüÊàêÁöÑÊï∞ÊçÆËøõË°åÁõ∏Êú∫ÊÑüÁü•Â§ÑÁêÜÔºå‰ΩøÂÖ∂ÂàÜÂ∏É‰∏éÁúüÂÆû‰∏ñÁïå3D‰º†ÊÑüÂô®ÂØπÈΩê„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöR2RGenÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂ÁúüÂÆûÂà∞ÁúüÂÆûÁöÑÊï∞ÊçÆÁîüÊàêÊñπÂºèÔºåÈÅøÂÖç‰∫ÜÊ®°ÊãüÂô®Â∏¶Êù•ÁöÑÂÅèÂ∑Æ„ÄÇÊ≠§Â§ñÔºåÁªÜÁ≤íÂ∫¶ÁöÑÂú∫ÊôØÂíåËΩ®ËøπËß£Êûê‰ª•ÂèäÂàÜÁªÑÂ¢ûÂº∫Á≠ñÁï•ÔºåËÉΩÂ§üÊúâÊïàÂú∞Â§ÑÁêÜÂ§çÊùÇÁöÑÂ§öÁâ©‰ΩìÂú∫ÊôØÂíå‰ªªÂä°Á∫¶Êùü„ÄÇÁõ∏Êú∫ÊÑüÁü•Â§ÑÁêÜËøõ‰∏ÄÊ≠•ÊèêÈ´ò‰∫ÜÁîüÊàêÊï∞ÊçÆÁöÑÁúüÂÆûÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöR2RGenÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) **ÁªÜÁ≤íÂ∫¶Ê†áÊ≥®Êú∫Âà∂**ÔºöÁî®‰∫éÁ≤æÁ°ÆËß£ÊûêÂú∫ÊôØÂíåËΩ®ËøπÔºå‰∏∫ÂêéÁª≠ÁöÑÂ¢ûÂº∫Êèê‰æõÂü∫Á°Ä„ÄÇ2) **ÂàÜÁªÑÂ¢ûÂº∫Á≠ñÁï•**ÔºöÊ†πÊçÆÁâ©‰Ωì‰πãÈó¥ÁöÑÂÖ≥Á≥ªÂíå‰ªªÂä°Á∫¶ÊùüÔºåÂØπÁâ©‰ΩìËøõË°åÂàÜÁªÑÔºåÂπ∂ÂàÜÂà´ËøõË°åÂ¢ûÂº∫Ôºå‰øùËØÅÁîüÊàêÊï∞ÊçÆÁöÑÂêàÁêÜÊÄß„ÄÇ3) **Áõ∏Êú∫ÊÑüÁü•Â§ÑÁêÜ**ÔºöÈÄöËøáË∞ÉÊï¥ÁÇπ‰∫ëÊï∞ÊçÆÁöÑËßÜËßíÂíåÂô™Â£∞Ôºå‰ΩøÂÖ∂ÂàÜÂ∏É‰∏éÁúüÂÆû‰∏ñÁïå3D‰º†ÊÑüÂô®ÈááÈõÜÁöÑÊï∞ÊçÆÊõ¥Âä†Êé•Ëøë„ÄÇÂÖ∑‰ΩìÁöÑÂèÇÊï∞ËÆæÁΩÆÂíåÁΩëÁªúÁªìÊûÑÁ≠âÁªÜËäÇÊú™Âú®ÊëòË¶Å‰∏≠ÊèêÂèäÔºåÂ±û‰∫éÊú™Áü•‰ø°ÊÅØ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

R2RGenÈÄöËøáÁúüÂÆûÂà∞ÁúüÂÆûÁöÑÊï∞ÊçÆÁîüÊàêÔºåÊòæËëóÊèêÈ´ò‰∫ÜÊú∫Âô®‰∫∫Êìç‰ΩúÁöÑÊï∞ÊçÆÊïàÁéá„ÄÇÊëòË¶Å‰∏≠ÊèêÂà∞ÔºåR2RGenÂú®ÂπøÊ≥õÁöÑÂÆûÈ™å‰∏≠Ë°®Áé∞Âá∫Âº∫Â§ßÁöÑÊΩúÂäõÔºå‰ΩÜÂÖ∑‰ΩìÁöÑÊÄßËÉΩÊï∞ÊçÆ„ÄÅÂØπÊØîÂü∫Á∫øÂíåÊèêÂçáÂπÖÂ∫¶Á≠âÁªÜËäÇÊú™Âú®ÊëòË¶Å‰∏≠ÁªôÂá∫ÔºåÂ±û‰∫éÊú™Áü•‰ø°ÊÅØ„ÄÇÂèØ‰ª•Êé®Êñ≠ÔºåR2RGenÂú®Êï∞ÊçÆÊïàÁéáÊñπÈù¢‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

R2RGenÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂèØÁî®‰∫éÊèêÂçáÂêÑÁßçÊú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°ÁöÑÁ©∫Èó¥Ê≥õÂåñËÉΩÂäõÔºå‰æãÂ¶ÇÁßªÂä®Êìç‰Ωú„ÄÅÊäìÂèñÊîæÁΩÆ„ÄÅË£ÖÈÖçÁ≠â„ÄÇËØ•ÊñπÊ≥ïÂèØ‰ª•Èôç‰ΩéÂØπÂ§ßÈáè‰∫∫Â∑•Ê†áÊ≥®Êï∞ÊçÆÁöÑ‰æùËµñÔºåÂä†ÈÄüÊú∫Âô®‰∫∫Á≠ñÁï•ÁöÑËÆ≠ÁªÉÂíåÈÉ®ÁΩ≤ÔºåÂ∞§ÂÖ∂ÈÄÇÁî®‰∫éÂ§çÊùÇ„ÄÅÂä®ÊÄÅÁöÑÁúüÂÆû‰∏ñÁïåÁéØÂ¢É„ÄÇÊú™Êù•ÔºåR2RGenÊúâÊúõÊé®Âä®Êú∫Âô®‰∫∫ÊäÄÊúØÂú®Â∑•‰∏öËá™Âä®Âåñ„ÄÅÂÆ∂Â∫≠ÊúçÂä°Á≠âÈ¢ÜÂüüÁöÑÂ∫îÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Towards the aim of generalized robotic manipulation, spatial generalization is the most fundamental capability that requires the policy to work robustly under different spatial distribution of objects, environment and agent itself. To achieve this, substantial human demonstrations need to be collected to cover different spatial configurations for training a generalized visuomotor policy via imitation learning. Prior works explore a promising direction that leverages data generation to acquire abundant spatially diverse data from minimal source demonstrations. However, most approaches face significant sim-to-real gap and are often limited to constrained settings, such as fixed-base scenarios and predefined camera viewpoints. In this paper, we propose a real-to-real 3D data generation framework (R2RGen) that directly augments the pointcloud observation-action pairs to generate real-world data. R2RGen is simulator- and rendering-free, thus being efficient and plug-and-play. Specifically, given a single source demonstration, we introduce an annotation mechanism for fine-grained parsing of scene and trajectory. A group-wise augmentation strategy is proposed to handle complex multi-object compositions and diverse task constraints. We further present camera-aware processing to align the distribution of generated data with real-world 3D sensor. Empirically, R2RGen substantially enhances data efficiency on extensive experiments and demonstrates strong potential for scaling and application on mobile manipulation.

