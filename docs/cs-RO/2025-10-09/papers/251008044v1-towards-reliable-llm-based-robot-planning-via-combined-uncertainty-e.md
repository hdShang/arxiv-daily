---
layout: default
title: Towards Reliable LLM-based Robot Planning via Combined Uncertainty Estimation
---

# Towards Reliable LLM-based Robot Planning via Combined Uncertainty Estimation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.08044" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.08044v1</a>
  <a href="https://arxiv.org/pdf/2510.08044.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.08044v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.08044v1', 'Towards Reliable LLM-based Robot Planning via Combined Uncertainty Estimation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shiyuan Yin, Chenjia Bai, Zihao Zhang, Junwei Jin, Xinxin Zhang, Chi Zhang, Xuelong Li

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-10-09

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCUREï¼Œç»“åˆä¸ç¡®å®šæ€§ä¼°è®¡ï¼Œæå‡LLMæœºå™¨äººè§„åˆ’çš„å¯é æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æœºå™¨äººè§„åˆ’` `ä¸ç¡®å®šæ€§ä¼°è®¡` `è®¤çŸ¥ä¸ç¡®å®šæ€§` `å†…åœ¨ä¸ç¡®å®šæ€§` `éšæœºç½‘ç»œè’¸é¦` `å¤šå±‚æ„ŸçŸ¥å™¨` `å…·èº«æ™ºèƒ½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŸºäºLLMçš„æœºå™¨äººè§„åˆ’æ–¹æ³•æ˜“å—LLMå¹»è§‰å½±å“ï¼Œäº§ç”Ÿä¸å®‰å…¨æˆ–é”™ä½çš„è®¡åˆ’ï¼Œä¸”ä¸ç¡®å®šæ€§ä¼°è®¡æ–¹æ³•æœªèƒ½å……åˆ†åŒºåˆ†è®¤çŸ¥å’Œå†…åœ¨ä¸ç¡®å®šæ€§ã€‚
2. CUREæ–¹æ³•å°†ä¸ç¡®å®šæ€§åˆ†è§£ä¸ºè®¤çŸ¥å’Œå†…åœ¨ä¸ç¡®å®šæ€§ï¼Œå¹¶è¿›ä¸€æ­¥å°†è®¤çŸ¥ä¸ç¡®å®šæ€§ç»†åˆ†ä¸ºä»»åŠ¡æ¸…æ™°åº¦å’Œä»»åŠ¡ç†Ÿæ‚‰åº¦ï¼Œä»è€Œå®ç°æ›´ç²¾ç¡®çš„ä¸ç¡®å®šæ€§è¯„ä¼°ã€‚
3. åœ¨å¨æˆ¿æ“ä½œå’Œæ¡Œé¢é‡æ’å®éªŒä¸­ï¼ŒCUREæ–¹æ³•ç”Ÿæˆçš„ä¸ç¡®å®šæ€§ä¼°è®¡ä¸å®é™…æ‰§è¡Œç»“æœçš„å¯¹é½ç¨‹åº¦ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹(LLM)å±•ç°äº†å…ˆè¿›çš„æ¨ç†èƒ½åŠ›ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿç†è§£è‡ªç„¶è¯­è¨€æŒ‡ä»¤å¹¶ç”Ÿæˆå…·æœ‰é€‚å½“åŸºç¡€çš„é«˜çº§è§„åˆ’ã€‚ç„¶è€Œï¼ŒLLMçš„å¹»è§‰æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ï¼Œå¸¸å¸¸å¯¼è‡´è¿‡åº¦è‡ªä¿¡ä½†å¯èƒ½é”™ä½æˆ–ä¸å®‰å…¨çš„è®¡åˆ’ã€‚è™½ç„¶ç ”ç©¶äººå‘˜å·²ç»æ¢ç´¢äº†ä¸ç¡®å®šæ€§ä¼°è®¡æ¥æé«˜åŸºäºLLMçš„è§„åˆ’çš„å¯é æ€§ï¼Œä½†ç°æœ‰ç ”ç©¶å°šæœªå……åˆ†åŒºåˆ†è®¤çŸ¥ä¸ç¡®å®šæ€§å’Œå†…åœ¨ä¸ç¡®å®šæ€§ï¼Œé™åˆ¶äº†ä¸ç¡®å®šæ€§ä¼°è®¡çš„æœ‰æ•ˆæ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ç”¨äºå¯é å…·èº«è§„åˆ’çš„ç»„åˆä¸ç¡®å®šæ€§ä¼°è®¡(CURE)ï¼Œå®ƒå°†ä¸ç¡®å®šæ€§åˆ†è§£ä¸ºè®¤çŸ¥ä¸ç¡®å®šæ€§å’Œå†…åœ¨ä¸ç¡®å®šæ€§ï¼Œåˆ†åˆ«è¿›è¡Œä¼°è®¡ã€‚æ­¤å¤–ï¼Œè®¤çŸ¥ä¸ç¡®å®šæ€§è¢«ç»†åˆ†ä¸ºä»»åŠ¡æ¸…æ™°åº¦å’Œä»»åŠ¡ç†Ÿæ‚‰åº¦ï¼Œä»¥è¿›è¡Œæ›´å‡†ç¡®çš„è¯„ä¼°ã€‚ä½¿ç”¨éšæœºç½‘ç»œè’¸é¦å’Œç”±LLMç‰¹å¾é©±åŠ¨çš„å¤šå±‚æ„ŸçŸ¥å™¨å›å½’å¤´è·å¾—æ€»ä½“ä¸ç¡®å®šæ€§è¯„ä¼°ã€‚æˆ‘ä»¬åœ¨ä¸¤ç§ä¸åŒçš„å®éªŒç¯å¢ƒä¸­éªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼šå¨æˆ¿æ“ä½œå’Œæ¡Œé¢é‡æ’å®éªŒã€‚ç»“æœè¡¨æ˜ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•äº§ç”Ÿçš„ä¸ç¡®å®šæ€§ä¼°è®¡ä¸å®é™…æ‰§è¡Œç»“æœæ›´åŠ ä¸€è‡´ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æœºå™¨äººè§„åˆ’ä¸­ï¼Œç”±äºLLMçš„â€œå¹»è§‰â€é—®é¢˜å¯¼è‡´è§„åˆ’ç»“æœä¸å¯é ï¼Œç”šè‡³å‡ºç°å®‰å…¨éšæ‚£çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨è¿›è¡Œä¸ç¡®å®šæ€§ä¼°è®¡æ—¶ï¼Œæœªèƒ½å……åˆ†åŒºåˆ†è®¤çŸ¥ä¸ç¡®å®šæ€§ï¼ˆepistemic uncertaintyï¼‰å’Œå†…åœ¨ä¸ç¡®å®šæ€§ï¼ˆintrinsic uncertaintyï¼‰ï¼Œå¯¼è‡´ä¸ç¡®å®šæ€§è¯„ä¼°ä¸å¤Ÿå‡†ç¡®ï¼Œæ— æ³•æœ‰æ•ˆæŒ‡å¯¼æœºå™¨äººè§„åˆ’ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†æ€»ä½“ä¸ç¡®å®šæ€§åˆ†è§£ä¸ºè®¤çŸ¥ä¸ç¡®å®šæ€§å’Œå†…åœ¨ä¸ç¡®å®šæ€§ï¼Œå¹¶åˆ†åˆ«è¿›è¡Œä¼°è®¡ã€‚è®¤çŸ¥ä¸ç¡®å®šæ€§åæ˜ äº†æ¨¡å‹å¯¹ä»»åŠ¡ç†è§£çš„ä¸è¶³ï¼Œè€Œå†…åœ¨ä¸ç¡®å®šæ€§åˆ™åæ˜ äº†ç¯å¢ƒæœ¬èº«çš„éšæœºæ€§ã€‚æ›´è¿›ä¸€æ­¥ï¼Œè®¤çŸ¥ä¸ç¡®å®šæ€§è¢«ç»†åˆ†ä¸ºä»»åŠ¡æ¸…æ™°åº¦å’Œä»»åŠ¡ç†Ÿæ‚‰åº¦ï¼Œä»¥ä¾¿æ›´ç²¾ç¡®åœ°è¯„ä¼°æ¨¡å‹å¯¹ä¸åŒä»»åŠ¡çš„ç†è§£ç¨‹åº¦ã€‚é€šè¿‡æ›´ç»†ç²’åº¦çš„ä¸ç¡®å®šæ€§ä¼°è®¡ï¼Œå¯ä»¥æ›´å‡†ç¡®åœ°è¯„ä¼°LLMè§„åˆ’çš„å¯é æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCUREæ–¹æ³•çš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) LLMç‰¹å¾æå–ï¼šåˆ©ç”¨LLMæå–ä»»åŠ¡ç›¸å…³çš„ç‰¹å¾è¡¨ç¤ºã€‚2) ä¸ç¡®å®šæ€§åˆ†è§£ï¼šå°†æ€»ä½“ä¸ç¡®å®šæ€§åˆ†è§£ä¸ºè®¤çŸ¥ä¸ç¡®å®šæ€§å’Œå†…åœ¨ä¸ç¡®å®šæ€§ã€‚3) è®¤çŸ¥ä¸ç¡®å®šæ€§è¯„ä¼°ï¼šè¿›ä¸€æ­¥å°†è®¤çŸ¥ä¸ç¡®å®šæ€§åˆ†è§£ä¸ºä»»åŠ¡æ¸…æ™°åº¦å’Œä»»åŠ¡ç†Ÿæ‚‰åº¦ï¼Œå¹¶åˆ†åˆ«è¿›è¡Œè¯„ä¼°ã€‚4) å†…åœ¨ä¸ç¡®å®šæ€§è¯„ä¼°ï¼šè¯„ä¼°ç¯å¢ƒçš„å†…åœ¨éšæœºæ€§ã€‚5) ä¸ç¡®å®šæ€§èåˆï¼šå°†å„ç§ä¸ç¡®å®šæ€§ä¼°è®¡ç»“æœèåˆï¼Œå¾—åˆ°æœ€ç»ˆçš„æ€»ä½“ä¸ç¡®å®šæ€§è¯„ä¼°ã€‚6) è§„åˆ’å¯é æ€§è¯„ä¼°ï¼šåˆ©ç”¨æ€»ä½“ä¸ç¡®å®šæ€§è¯„ä¼°ç»“æœï¼Œè¯„ä¼°LLMç”Ÿæˆçš„æœºå™¨äººè§„åˆ’çš„å¯é æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå¯¹ä¸ç¡®å®šæ€§çš„åˆ†è§£å’Œç»†åŒ–ã€‚ä¸ç°æœ‰æ–¹æ³•ç¬¼ç»Ÿåœ°ä¼°è®¡æ€»ä½“ä¸ç¡®å®šæ€§ä¸åŒï¼ŒCUREæ–¹æ³•å°†ä¸ç¡®å®šæ€§åˆ†è§£ä¸ºè®¤çŸ¥å’Œå†…åœ¨ä¸¤éƒ¨åˆ†ï¼Œå¹¶è¿›ä¸€æ­¥ç»†åŒ–è®¤çŸ¥ä¸ç¡®å®šæ€§ã€‚è¿™ç§ç»†ç²’åº¦çš„ä¸ç¡®å®šæ€§ä¼°è®¡èƒ½å¤Ÿæ›´å‡†ç¡®åœ°åæ˜ LLMè§„åˆ’çš„å¯é æ€§ï¼Œä»è€Œæé«˜æœºå™¨äººè§„åˆ’çš„å®‰å…¨æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å…·ä½“å®ç°ä¸Šï¼Œè®ºæ–‡é‡‡ç”¨äº†éšæœºç½‘ç»œè’¸é¦ï¼ˆrandom network distillationï¼‰æ¥ä¼°è®¡å†…åœ¨ä¸ç¡®å®šæ€§ã€‚å¯¹äºè®¤çŸ¥ä¸ç¡®å®šæ€§çš„è¯„ä¼°ï¼Œè®ºæ–‡ä½¿ç”¨äº†å¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰å›å½’å¤´ï¼Œå…¶è¾“å…¥ä¸ºLLMæå–çš„ç‰¹å¾ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡æ—¨åœ¨ä½¿MLPçš„è¾“å‡ºèƒ½å¤Ÿå‡†ç¡®åæ˜ ä»»åŠ¡çš„æ¸…æ™°åº¦å’Œç†Ÿæ‚‰åº¦ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒCUREæ–¹æ³•åœ¨å¨æˆ¿æ“ä½œå’Œæ¡Œé¢é‡æ’ä¸¤ä¸ªå®éªŒç¯å¢ƒä¸­ï¼Œèƒ½å¤Ÿæ›´å‡†ç¡®åœ°ä¼°è®¡LLMè§„åˆ’çš„ä¸ç¡®å®šæ€§ï¼Œä¸å®é™…æ‰§è¡Œç»“æœçš„å¯¹é½ç¨‹åº¦ä¼˜äºç°æœ‰æ–¹æ³•ã€‚è¿™æ„å‘³ç€CUREæ–¹æ³•èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°è¯†åˆ«æ½œåœ¨çš„é”™è¯¯æˆ–ä¸å®‰å…¨è§„åˆ’ï¼Œä»è€Œæé«˜æœºå™¨äººè§„åˆ’çš„å¯é æ€§ã€‚å…·ä½“çš„æ€§èƒ½æå‡æ•°æ®éœ€è¦åœ¨è®ºæ–‡ä¸­æŸ¥æ‰¾ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦æœºå™¨äººè¿›è¡Œè‡ªä¸»è§„åˆ’çš„åœºæ™¯ï¼Œä¾‹å¦‚æ™ºèƒ½å®¶å±…ã€å·¥ä¸šè‡ªåŠ¨åŒ–ã€åŒ»ç–—è¾…åŠ©ç­‰ã€‚é€šè¿‡æé«˜LLMæœºå™¨äººè§„åˆ’çš„å¯é æ€§ï¼Œå¯ä»¥å‡å°‘äººä¸ºå¹²é¢„ï¼Œæé«˜å·¥ä½œæ•ˆç‡ï¼Œå¹¶é™ä½å®‰å…¨é£é™©ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯ä»¥è¿›ä¸€æ­¥æ‰©å±•åˆ°æ›´å¤æ‚çš„ä»»åŠ¡å’Œç¯å¢ƒï¼Œå¹¶ä¸å…¶ä»–æœºå™¨äººæŠ€æœ¯ç›¸ç»“åˆï¼Œå®ç°æ›´æ™ºèƒ½ã€æ›´å®‰å…¨çš„æœºå™¨äººåº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) demonstrate advanced reasoning abilities, enabling robots to understand natural language instructions and generate high-level plans with appropriate grounding. However, LLM hallucinations present a significant challenge, often leading to overconfident yet potentially misaligned or unsafe plans. While researchers have explored uncertainty estimation to improve the reliability of LLM-based planning, existing studies have not sufficiently differentiated between epistemic and intrinsic uncertainty, limiting the effectiveness of uncertainty estimation. In this paper, we present Combined Uncertainty estimation for Reliable Embodied planning (CURE), which decomposes the uncertainty into epistemic and intrinsic uncertainty, each estimated separately. Furthermore, epistemic uncertainty is subdivided into task clarity and task familiarity for more accurate evaluation. The overall uncertainty assessments are obtained using random network distillation and multi-layer perceptron regression heads driven by LLM features. We validated our approach in two distinct experimental settings: kitchen manipulation and tabletop rearrangement experiments. The results show that, compared to existing methods, our approach yields uncertainty estimates that are more closely aligned with the actual execution outcomes.

