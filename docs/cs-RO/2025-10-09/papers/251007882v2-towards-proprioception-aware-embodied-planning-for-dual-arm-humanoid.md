---
layout: default
title: Towards Proprioception-Aware Embodied Planning for Dual-Arm Humanoid Robots
---

# Towards Proprioception-Aware Embodied Planning for Dual-Arm Humanoid Robots

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.07882" class="toolbar-btn" target="_blank">üìÑ arXiv: 2510.07882v2</a>
  <a href="https://arxiv.org/pdf/2510.07882.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.07882v2" onclick="toggleFavorite(this, '2510.07882v2', 'Towards Proprioception-Aware Embodied Planning for Dual-Arm Humanoid Robots')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Boyu Li, Siyuan He, Hang Xu, Haoqi Yuan, Xinrun Xu, Yu Zang, Liwei Hu, Junpeng Yue, Zhenxiong Jiang, Pengbo Hu, B√∂rje F. Karlsson, Yehui Tang, Zongqing Lu

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-09 (Êõ¥Êñ∞: 2025-10-15)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Proprio-MLLMÔºåÂ¢ûÂº∫ÂèåËáÇ‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ÂÖ∑Ë∫´ËßÑÂàíÁöÑÊú¨‰ΩìÊÑüÁü•ËÉΩÂäõ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÂÖ∑Ë∫´Êô∫ËÉΩ` `‰∫∫ÂΩ¢Êú∫Âô®‰∫∫` `Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã` `Êú¨‰ΩìÊÑüÂèó` `‰ªªÂä°ËßÑÂàí`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâMLLMÂú®ÂèåËáÇ‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ÈïøÊó∂Á®ã‰ªªÂä°‰∏≠Ë°®Áé∞ÂèóÈôêÔºåÁº∫‰πèÂêàÈÄÇÁöÑ‰ªøÁúüÂπ≥Âè∞ÂíåË∂≥Â§üÁöÑÂÖ∑Ë∫´ÊÑüÁü•ËÉΩÂäõÊòØ‰∏ªË¶ÅÁì∂È¢à„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫Proprio-MLLMÔºåÈÄöËøáËûçÂêàÊú¨‰ΩìÊÑüÂèó‰ø°ÊÅØÂíåËøêÂä®ÂµåÂÖ•ÔºåÂ¢ûÂº∫Ê®°ÂûãÂØπÊú∫Âô®‰∫∫Ëá™Ë∫´Áä∂ÊÄÅÂíåÁ©∫Èó¥ÂÖ≥Á≥ªÁöÑÁêÜËß£„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåProprio-MLLMÂú®DualTHORÊ®°ÊãüÂô®‰∏≠ÊòæËëóÊèêÂçá‰∫ÜËßÑÂàíÊÄßËÉΩÔºåÂπ≥ÂùáÊèêÂçáÂπÖÂ∫¶ËææÂà∞19.75%„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËøëÂπ¥Êù•ÔºåÂ§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMÔºâÂ∑≤Â±ïÁé∞Âá∫‰Ωú‰∏∫È´òÁ∫ßËßÑÂàíÂô®ÁöÑÊΩúÂäõÔºå‰ΩøÊú∫Âô®‰∫∫ËÉΩÂ§üÈÅµÂæ™Â§çÊùÇÁöÑ‰∫∫Á±ªÊåá‰ª§„ÄÇÁÑ∂ËÄåÔºåÂÆÉ‰ª¨Âú®Ê∂âÂèäÂèåËáÇ‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ÁöÑÈïøÊó∂Á®ã‰ªªÂä°‰∏≠ÁöÑÊúâÊïàÊÄß‰ªçÁÑ∂ÊúâÈôê„ÄÇËøô‰∏ªË¶ÅÊ∫ê‰∫é‰∏§‰∏™ÊåëÊàòÔºöÔºàiÔºâÁº∫‰πèÁ≥ªÁªüÊÄßÂú∞ÊîØÊåÅ‰∫∫ÂΩ¢Êú∫Âô®‰∫∫‰ªªÂä°ËØÑ‰º∞ÂíåÊï∞ÊçÆÊî∂ÈõÜÁöÑ‰ªøÁúüÂπ≥Âè∞Ôºå‰ª•ÂèäÔºàiiÔºâÂΩìÂâçMLLMÁöÑÂÖ∑Ë∫´ÊÑüÁü•‰∏çË∂≥ÔºåËøôÈòªÁ¢ç‰∫ÜËßÑÂàíËøáÁ®ã‰∏≠ÂØπÂèåËáÇÈÄâÊã©ÈÄªËæëÂíåË∫´‰Ωì‰ΩçÁΩÆÁöÑÊé®ÁêÜ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜDualTHORÔºå‰∏ÄÁßçÊñ∞ÁöÑÂèåËáÇ‰∫∫ÂΩ¢Êú∫Âô®‰∫∫Ê®°ÊãüÂô®ÔºåÂÖ∑ÊúâËøûÁª≠ËΩ¨Êç¢ÂíåÂ∫îÊÄ•Êú∫Âà∂„ÄÇÂú®Ê≠§Âπ≥Âè∞ÁöÑÂü∫Á°Ä‰∏äÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜProprio-MLLMÔºåËØ•Ê®°ÂûãÈÄöËøáÁªìÂêàÊú¨‰ΩìÊÑüÂèó‰ø°ÊÅØ„ÄÅÂü∫‰∫éËøêÂä®ÁöÑ‰ΩçÁΩÆÂµåÂÖ•ÂíåË∑®Á©∫Èó¥ÁºñÁ†ÅÂô®Êù•Â¢ûÂº∫ÂÖ∑Ë∫´ÊÑüÁü•ËÉΩÂäõ„ÄÇÂÆûÈ™åË°®ÊòéÔºåËôΩÁÑ∂Áé∞ÊúâÁöÑMLLMÂú®Ê≠§ÁéØÂ¢É‰∏≠Ë°®Áé∞‰∏ç‰Ω≥Ôºå‰ΩÜProprio-MLLMÂú®ËßÑÂàíÊÄßËÉΩÊñπÈù¢Âπ≥ÂùáÊèêÈ´ò‰∫Ü19.75%„ÄÇÊàë‰ª¨ÁöÑÂ∑•‰ΩúÊèê‰æõ‰∫Ü‰∏Ä‰∏™ÈáçË¶ÅÁöÑ‰ªøÁúüÂπ≥Âè∞Âíå‰∏Ä‰∏™ÊúâÊïàÁöÑÊ®°ÂûãÔºå‰ª•Êé®Ëøõ‰∫∫ÂΩ¢Êú∫Âô®‰∫∫‰∏≠ÁöÑÂÖ∑Ë∫´Êô∫ËÉΩ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâMLLMÂú®ÂèåËáÇ‰∫∫ÂΩ¢Êú∫Âô®‰∫∫‰ªªÂä°ËßÑÂàí‰∏≠Èù¢‰∏¥ÊåëÊàòÔºå‰∏ªË¶Å‰ΩìÁé∞Âú®‰∏§‰∏™ÊñπÈù¢Ôºö‰∏ÄÊòØÁº∫‰πè‰∏ìÈó®‰∏∫‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ËÆæËÆ°ÁöÑ‰ªøÁúüÁéØÂ¢ÉÔºåÈöæ‰ª•ËøõË°åÊúâÊïàÁöÑÊï∞ÊçÆÊî∂ÈõÜÂíåÊ®°ÂûãËØÑ‰º∞Ôºõ‰∫åÊòØMLLMÂØπÊú∫Âô®‰∫∫ÁöÑËá™Ë∫´Áä∂ÊÄÅÔºàÂ¶ÇÂÖ≥ËäÇËßíÂ∫¶„ÄÅË∫´‰ΩìÂßøÊÄÅÔºâÂíåÁ©∫Èó¥ÂÖ≥Á≥ªÊÑüÁü•‰∏çË∂≥ÔºåÂØºËá¥Èöæ‰ª•ËøõË°åÂêàÁêÜÁöÑÂä®‰ΩúËßÑÂàíÂíåÂèåËáÇÂçèÂêå„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÂºïÂÖ•Êú¨‰ΩìÊÑüÂèó‰ø°ÊÅØÊù•Â¢ûÂº∫MLLMÁöÑÂÖ∑Ë∫´ÊÑüÁü•ËÉΩÂäõ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÂ∞ÜÊú∫Âô®‰∫∫ÁöÑÂÖ≥ËäÇËßíÂ∫¶Á≠âÊú¨‰ΩìÊÑüÂèó‰ø°ÊÅØ‰∏éËßÜËßâ‰ø°ÊÅØÁõ∏ÁªìÂêàÔºå‰ΩøÊ®°ÂûãËÉΩÂ§üÊõ¥Â•ΩÂú∞ÁêÜËß£Êú∫Âô®‰∫∫ÁöÑËá™Ë∫´Áä∂ÊÄÅÂíåÂë®Âõ¥ÁéØÂ¢ÉÔºå‰ªéËÄåÂÅöÂá∫Êõ¥ÂêàÁêÜÁöÑËßÑÂàíÂÜ≥Á≠ñ„ÄÇÂêåÊó∂ÔºåËÆæËÆ°‰∫ÜÊñ∞ÁöÑ‰ªøÁúüÁéØÂ¢ÉDualTHORÔºå‰∏∫Ê®°ÂûãËÆ≠ÁªÉÂíåËØÑ‰º∞Êèê‰æõÊîØÊåÅ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöProprio-MLLMÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) ËßÜËßâÁºñÁ†ÅÂô®ÔºöÁî®‰∫éÊèêÂèñÂú∫ÊôØÁöÑËßÜËßâÁâπÂæÅÔºõ2) Êú¨‰ΩìÊÑüÂèóÁºñÁ†ÅÂô®ÔºöÁî®‰∫éÊèêÂèñÊú∫Âô®‰∫∫ÁöÑÂÖ≥ËäÇËßíÂ∫¶Á≠âÊú¨‰ΩìÊÑüÂèó‰ø°ÊÅØÔºõ3) ËøêÂä®ÂµåÂÖ•Ê®°ÂùóÔºöÂ∞ÜÊú∫Âô®‰∫∫ÁöÑËøêÂä®‰ø°ÊÅØÂµåÂÖ•Âà∞ÁâπÂæÅÁ©∫Èó¥‰∏≠Ôºõ4) Ë∑®Á©∫Èó¥ÁºñÁ†ÅÂô®ÔºöËûçÂêàËßÜËßâÁâπÂæÅ„ÄÅÊú¨‰ΩìÊÑüÂèó‰ø°ÊÅØÂíåËøêÂä®ÂµåÂÖ•ÔºåÂ¢ûÂº∫Ê®°ÂûãÂØπÊú∫Âô®‰∫∫Áä∂ÊÄÅÂíåÁéØÂ¢ÉÁöÑÁêÜËß£Ôºõ5) ËØ≠Ë®ÄÊ®°ÂûãÔºöÊ†πÊçÆËûçÂêàÂêéÁöÑÁâπÂæÅËøõË°å‰ªªÂä°ËßÑÂàí„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1) ÊèêÂá∫‰∫ÜProprio-MLLMÔºåÈÄöËøáËûçÂêàÊú¨‰ΩìÊÑüÂèó‰ø°ÊÅØÂíåËøêÂä®ÂµåÂÖ•ÔºåÊòæËëóÊèêÂçá‰∫ÜMLLMÂú®‰∫∫ÂΩ¢Êú∫Âô®‰∫∫‰ªªÂä°ËßÑÂàí‰∏≠ÁöÑÊÄßËÉΩÔºõ2) ËÆæËÆ°‰∫ÜDualTHOR‰ªøÁúüÁéØÂ¢ÉÔºå‰∏∫‰∫∫ÂΩ¢Êú∫Âô®‰∫∫‰ªªÂä°ËßÑÂàíÁöÑÁ†îÁ©∂Êèê‰æõ‰∫ÜÊñ∞ÁöÑÂπ≥Âè∞Ôºõ3) ÊèêÂá∫‰∫ÜË∑®Á©∫Èó¥ÁºñÁ†ÅÂô®ÔºåÊúâÊïàÂú∞ËûçÂêà‰∫ÜËßÜËßâÁâπÂæÅ„ÄÅÊú¨‰ΩìÊÑüÂèó‰ø°ÊÅØÂíåËøêÂä®ÂµåÂÖ•„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Êú¨‰ΩìÊÑüÂèóÁºñÁ†ÅÂô®‰∏≠Ôºå‰ΩøÁî®‰∫ÜÂ§öÂ±ÇÊÑüÁü•Êú∫ÔºàMLPÔºâÂ∞ÜÂÖ≥ËäÇËßíÂ∫¶Á≠âÊú¨‰ΩìÊÑüÂèó‰ø°ÊÅØÊò†Â∞ÑÂà∞ÁâπÂæÅÁ©∫Èó¥‰∏≠„ÄÇËøêÂä®ÂµåÂÖ•Ê®°Âùó‰ΩøÁî®TransformerÁΩëÁªúÂØπÊú∫Âô®‰∫∫ÁöÑËøêÂä®ËΩ®ËøπËøõË°åÁºñÁ†Å„ÄÇË∑®Á©∫Èó¥ÁºñÁ†ÅÂô®ÈááÁî®Ê≥®ÊÑèÂäõÊú∫Âà∂ÔºåËá™ÈÄÇÂ∫îÂú∞ËûçÂêàËßÜËßâÁâπÂæÅ„ÄÅÊú¨‰ΩìÊÑüÂèó‰ø°ÊÅØÂíåËøêÂä®ÂµåÂÖ•„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨‰ªªÂä°ÂÆåÊàêÊçüÂ§±ÂíåÂä®‰ΩúÂêàÁêÜÊÄßÊçüÂ§±ÔºåÁî®‰∫éÊåáÂØºÊ®°ÂûãÂ≠¶‰π†ÂêàÁêÜÁöÑËßÑÂàíÁ≠ñÁï•„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåProprio-MLLMÂú®DualTHOR‰ªøÁúüÁéØÂ¢É‰∏≠ÊòæËëóÊèêÂçá‰∫ÜËßÑÂàíÊÄßËÉΩÔºåÁõ∏ÊØî‰∫éÁé∞ÊúâÁöÑMLLMÔºåÂπ≥ÂùáÊèêÂçáÂπÖÂ∫¶ËææÂà∞19.75%„ÄÇËøôË°®ÊòéÈÄöËøáÂºïÂÖ•Êú¨‰ΩìÊÑüÂèó‰ø°ÊÅØÂíåËøêÂä®ÂµåÂÖ•ÔºåÂèØ‰ª•ÊúâÊïàÂ¢ûÂº∫MLLMÁöÑÂÖ∑Ë∫´ÊÑüÁü•ËÉΩÂäõÔºå‰ªéËÄåÊèêÈ´òÂÖ∂Âú®‰∫∫ÂΩ¢Êú∫Âô®‰∫∫‰ªªÂä°ËßÑÂàí‰∏≠ÁöÑÊÄßËÉΩ„ÄÇÊ≠§Â§ñÔºåDualTHOR‰ªøÁúüÁéØÂ¢ÉÁöÑÂèëÂ∏É‰πü‰∏∫ËØ•È¢ÜÂüüÁöÑÁ†îÁ©∂Êèê‰æõ‰∫ÜÊñ∞ÁöÑÂü∫ÂáÜÂπ≥Âè∞„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂêÑÁßçÈúÄË¶ÅÂèåËáÇ‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ËøõË°åÂ§çÊùÇÊìç‰ΩúÁöÑÂú∫ÊôØÔºå‰æãÂ¶ÇÊô∫ËÉΩÂà∂ÈÄ†„ÄÅÂÆ∂Â∫≠ÊúçÂä°„ÄÅÂåªÁñóËæÖÂä©Á≠â„ÄÇÈÄöËøáÂ¢ûÂº∫Êú∫Âô®‰∫∫ÁöÑÂÖ∑Ë∫´ÊÑüÁü•ËÉΩÂäõÔºåÂèØ‰ª•‰ΩøÂÖ∂Êõ¥Â•ΩÂú∞ÁêÜËß£‰∫∫Á±ªÊåá‰ª§ÔºåÂÆåÊàêÊõ¥Âä†Á≤æÁªÜÂíåÂ§çÊùÇÁöÑ‰ªªÂä°ÔºåÊèêÈ´òÂ∑•‰ΩúÊïàÁéáÂíåÊúçÂä°Ë¥®Èáè„ÄÇÊú™Êù•ÔºåËØ•ÊäÄÊúØÊúâÊúõÊé®Âä®‰∫∫ÂΩ¢Êú∫Âô®‰∫∫Âú®ÂÆûÈôÖÁîüÊ¥ª‰∏≠ÁöÑÂπøÊ≥õÂ∫îÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> In recent years, Multimodal Large Language Models (MLLMs) have demonstrated the ability to serve as high-level planners, enabling robots to follow complex human instructions. However, their effectiveness, especially in long-horizon tasks involving dual-arm humanoid robots, remains limited. This limitation arises from two main challenges: (i) the absence of simulation platforms that systematically support task evaluation and data collection for humanoid robots, and (ii) the insufficient embodiment awareness of current MLLMs, which hinders reasoning about dual-arm selection logic and body positions during planning. To address these issues, we present DualTHOR, a new dual-arm humanoid simulator, with continuous transition and a contingency mechanism. Building on this platform, we propose Proprio-MLLM, a model that enhances embodiment awareness by incorporating proprioceptive information with motion-based position embedding and a cross-spatial encoder. Experiments show that, while existing MLLMs struggle in this environment, Proprio-MLLM achieves an average improvement of 19.75% in planning performance. Our work provides both an essential simulation platform and an effective model to advance embodied intelligence in humanoid robotics. The code is available at https://anonymous.4open.science/r/DualTHOR-5F3B.

