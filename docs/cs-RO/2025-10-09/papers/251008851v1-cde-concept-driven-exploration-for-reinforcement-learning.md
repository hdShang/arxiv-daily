---
layout: default
title: CDE: Concept-Driven Exploration for Reinforcement Learning
---

# CDE: Concept-Driven Exploration for Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.08851" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.08851v1</a>
  <a href="https://arxiv.org/pdf/2510.08851.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.08851v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.08851v1', 'CDE: Concept-Driven Exploration for Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Le Mao, Andrew H. Liu, Renos Zabounidis, Zachary Kingston, Joseph Campbell

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-10-09

**å¤‡æ³¨**: Preprint

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ¦‚å¿µé©±åŠ¨æ¢ç´¢(CDE)æ–¹æ³•ï¼Œè§£å†³è§†è§‰å¼ºåŒ–å­¦ä¹ ä¸­é«˜æ•ˆæ¢ç´¢é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è§†è§‰å¼ºåŒ–å­¦ä¹ ` `æ¦‚å¿µé©±åŠ¨æ¢ç´¢` `è§†è§‰-è¯­è¨€æ¨¡å‹` `å†…åœ¨å¥–åŠ±` `æœºå™¨äººæ“ä½œ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. è§†è§‰å¼ºåŒ–å­¦ä¹ é¢ä¸´ä»åƒç´ ä¸­æå–ä»»åŠ¡ç›¸å…³ä¿¡æ¯çš„æŒ‘æˆ˜ï¼Œå¯¼è‡´æ¢ç´¢æ•ˆç‡ä½ä¸‹ã€‚
2. CDEåˆ©ç”¨é¢„è®­ç»ƒè§†è§‰-è¯­è¨€æ¨¡å‹ç”Ÿæˆæ¦‚å¿µï¼Œé€šè¿‡æ¦‚å¿µé‡å»ºä½œä¸ºå†…åœ¨å¥–åŠ±å¼•å¯¼æ¢ç´¢ã€‚
3. CDEåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­è¡¨ç°å‡ºé«˜æ•ˆæ¢ç´¢å’Œè‰¯å¥½çš„è¿ç§»èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ™ºèƒ½æ¢ç´¢æ˜¯å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä¸­çš„ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨è§†è§‰æ§åˆ¶ä»»åŠ¡ä¸­ã€‚ä¸ä½ç»´çŠ¶æ€RLä¸åŒï¼Œè§†è§‰RLå¿…é¡»ä»åŸå§‹åƒç´ ä¸­æå–ä»»åŠ¡ç›¸å…³çš„ç»“æ„ï¼Œè¿™ä½¿å¾—æ¢ç´¢æ•ˆç‡ä½ä¸‹ã€‚æˆ‘ä»¬æå‡ºäº†æ¦‚å¿µé©±åŠ¨æ¢ç´¢ï¼ˆCDEï¼‰ï¼Œå®ƒåˆ©ç”¨é¢„è®­ç»ƒçš„è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ä»æ–‡æœ¬ä»»åŠ¡æè¿°ä¸­ç”Ÿæˆä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„è§†è§‰æ¦‚å¿µï¼Œä½œä¸ºå¼±çš„ã€å¯èƒ½å­˜åœ¨å™ªå£°çš„ç›‘ç£ä¿¡å·ã€‚CDEä¸æ˜¯ç›´æ¥ä»¥è¿™äº›å™ªå£°ä¿¡å·ä¸ºæ¡ä»¶ï¼Œè€Œæ˜¯è®­ç»ƒç­–ç•¥é€šè¿‡è¾…åŠ©ç›®æ ‡é‡å»ºè¿™äº›æ¦‚å¿µï¼Œå¹¶ä½¿ç”¨é‡å»ºç²¾åº¦ä½œä¸ºå†…åœ¨å¥–åŠ±ï¼Œå¼•å¯¼æ¢ç´¢æœå‘ä»»åŠ¡ç›¸å…³çš„å¯¹è±¡ã€‚ç”±äºç­–ç•¥å†…åŒ–äº†è¿™äº›æ¦‚å¿µï¼Œå› æ­¤åªéœ€åœ¨è®­ç»ƒæœŸé—´è¿›è¡ŒVLMæŸ¥è¯¢ï¼Œä»è€Œå‡å°‘äº†éƒ¨ç½²æœŸé—´å¯¹å¤–éƒ¨æ¨¡å‹çš„ä¾èµ–ã€‚åœ¨äº”ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„æ¨¡æ‹Ÿè§†è§‰æ“ä½œä»»åŠ¡ä¸­ï¼ŒCDEå®ç°äº†é«˜æ•ˆã€æœ‰é’ˆå¯¹æ€§çš„æ¢ç´¢ï¼Œå¹¶ä¸”å¯¹å™ªå£°VLMé¢„æµ‹å…·æœ‰é²æ£’æ€§ã€‚æœ€åï¼Œæˆ‘ä»¬é€šè¿‡åœ¨Franka Research 3æœºæ¢°è‡‚ä¸Šéƒ¨ç½²CDEæ¥å±•ç¤ºçœŸå®ä¸–ç•Œçš„è¿ç§»èƒ½åŠ›ï¼Œåœ¨çœŸå®ä¸–ç•Œçš„æ“ä½œä»»åŠ¡ä¸­è¾¾åˆ°äº†80%çš„æˆåŠŸç‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè§†è§‰å¼ºåŒ–å­¦ä¹ ä¸­çš„æ¢ç´¢é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨æ“ä½œä»»åŠ¡ä¸­ï¼Œç”±äºçŠ¶æ€ç©ºé—´æ˜¯é«˜ç»´çš„åƒç´ ç©ºé—´ï¼Œæ™ºèƒ½ä½“éš¾ä»¥æœ‰æ•ˆåœ°å‘ç°ä¸ä»»åŠ¡ç›¸å…³çš„å¯¹è±¡å’Œäº¤äº’æ–¹å¼ã€‚ç°æœ‰çš„æ–¹æ³•è¦ä¹ˆä¾èµ–äºéšæœºæ¢ç´¢ï¼Œè¦ä¹ˆéœ€è¦å¤§é‡çš„ç¯å¢ƒäº¤äº’æ‰èƒ½å­¦ä¹ åˆ°æœ‰æ•ˆçš„ç­–ç•¥ï¼Œæ•ˆç‡è¾ƒä½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šåˆ©ç”¨é¢„è®­ç»ƒçš„è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰çš„å…ˆéªŒçŸ¥è¯†ï¼Œå°†æ–‡æœ¬ä»»åŠ¡æè¿°è½¬åŒ–ä¸ºå¯¹è±¡çº§åˆ«çš„è§†è§‰æ¦‚å¿µã€‚é€šè¿‡è®­ç»ƒæ™ºèƒ½ä½“å»é‡å»ºè¿™äº›æ¦‚å¿µï¼Œé¼“åŠ±æ™ºèƒ½ä½“å…³æ³¨ä»»åŠ¡ç›¸å…³çš„å¯¹è±¡ï¼Œå¹¶ä»¥æ­¤ä½œä¸ºå†…åœ¨å¥–åŠ±æ¥å¼•å¯¼æ¢ç´¢ã€‚æ ¸å¿ƒåœ¨äºå°†å¤–éƒ¨çŸ¥è¯†ï¼ˆVLMï¼‰èå…¥åˆ°æ™ºèƒ½ä½“çš„æ¢ç´¢è¿‡ç¨‹ä¸­ï¼ŒåŠ é€Ÿå­¦ä¹ ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCDEåŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) é¢„è®­ç»ƒçš„è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ï¼Œç”¨äºä»æ–‡æœ¬ä»»åŠ¡æè¿°ä¸­æå–è§†è§‰æ¦‚å¿µï¼›2) ç­–ç•¥ç½‘ç»œï¼Œç”¨äºç”ŸæˆåŠ¨ä½œï¼›3) æ¦‚å¿µé‡å»ºæ¨¡å—ï¼Œç”¨äºå°†å½“å‰çŠ¶æ€æ˜ å°„åˆ°è§†è§‰æ¦‚å¿µçš„è¡¨ç¤ºï¼Œå¹¶è®¡ç®—é‡å»ºè¯¯å·®ï¼›4) å¥–åŠ±å‡½æ•°ï¼Œç”±ç¯å¢ƒå¥–åŠ±å’Œæ¦‚å¿µé‡å»ºå¥–åŠ±ç»„æˆã€‚æ•´ä½“æµç¨‹æ˜¯ï¼šæ™ºèƒ½ä½“æ ¹æ®ç­–ç•¥ä¸ç¯å¢ƒäº¤äº’ï¼Œè·å¾—çŠ¶æ€å’Œç¯å¢ƒå¥–åŠ±ã€‚åŒæ—¶ï¼Œæ™ºèƒ½ä½“å°è¯•é‡å»ºä»å½“å‰çŠ¶æ€æå–çš„è§†è§‰æ¦‚å¿µï¼Œå¹¶æ ¹æ®é‡å»ºè¯¯å·®è·å¾—æ¦‚å¿µé‡å»ºå¥–åŠ±ã€‚æ€»å¥–åŠ±ç”¨äºæ›´æ–°ç­–ç•¥ç½‘ç»œã€‚

**å…³é”®åˆ›æ–°**ï¼šCDEçš„å…³é”®åˆ›æ–°åœ¨äºä½¿ç”¨æ¦‚å¿µé‡å»ºä½œä¸ºå†…åœ¨å¥–åŠ±æ¥å¼•å¯¼æ¢ç´¢ã€‚ä¸ç›´æ¥ä½¿ç”¨VLMçš„è¾“å‡ºä½œä¸ºç­–ç•¥çš„æ¡ä»¶ä¸åŒï¼ŒCDEé€šè¿‡è®­ç»ƒæ™ºèƒ½ä½“å»é‡å»ºæ¦‚å¿µï¼Œä½¿å¾—æ™ºèƒ½ä½“èƒ½å¤Ÿå†…åŒ–è¿™äº›æ¦‚å¿µï¼Œä»è€Œå‡å°‘äº†å¯¹VLMçš„ä¾èµ–ï¼Œå¹¶ä¸”æé«˜äº†å¯¹å™ªå£°VLMé¢„æµ‹çš„é²æ£’æ€§ã€‚æ­¤å¤–ï¼Œè¿™ç§æ–¹æ³•èƒ½å¤Ÿå°†å¤–éƒ¨çŸ¥è¯†æœ‰æ•ˆåœ°èå…¥åˆ°å¼ºåŒ–å­¦ä¹ çš„æ¢ç´¢è¿‡ç¨‹ä¸­ã€‚

**å…³é”®è®¾è®¡**ï¼šCDEçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨é¢„è®­ç»ƒçš„CLIPæ¨¡å‹ä½œä¸ºVLMï¼Œæå–è§†è§‰æ¦‚å¿µï¼›2) ä½¿ç”¨å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰ä½œä¸ºæ¦‚å¿µé‡å»ºçš„æŸå¤±å‡½æ•°ï¼›3) å°†æ¦‚å¿µé‡å»ºå¥–åŠ±ä¸ç¯å¢ƒå¥–åŠ±è¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œå¾—åˆ°æ€»å¥–åŠ±ï¼›4) ä½¿ç”¨Actor-Criticç®—æ³•è®­ç»ƒç­–ç•¥ç½‘ç»œã€‚å…·ä½“å‚æ•°è®¾ç½®éœ€è¦æ ¹æ®å…·ä½“ä»»åŠ¡è¿›è¡Œè°ƒæ•´ï¼Œä¾‹å¦‚æ¦‚å¿µé‡å»ºå¥–åŠ±çš„æƒé‡ï¼Œä»¥åŠActorå’ŒCriticç½‘ç»œçš„å­¦ä¹ ç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

CDEåœ¨äº”ä¸ªæ¨¡æ‹Ÿè§†è§‰æ“ä½œä»»åŠ¡ä¸­è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œå®ç°äº†é«˜æ•ˆã€æœ‰é’ˆå¯¹æ€§çš„æ¢ç´¢ï¼Œå¹¶ä¸”å¯¹å™ªå£°VLMé¢„æµ‹å…·æœ‰é²æ£’æ€§ã€‚åœ¨çœŸå®ä¸–ç•Œçš„æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­ï¼ŒCDEè¾¾åˆ°äº†80%çš„æˆåŠŸç‡ï¼Œè¯æ˜äº†å…¶åœ¨çœŸå®ç¯å¢ƒä¸­çš„å¯è¡Œæ€§å’Œæœ‰æ•ˆæ€§ã€‚ç›¸è¾ƒäºå…¶ä»–æ¢ç´¢æ–¹æ³•ï¼ŒCDEèƒ½å¤Ÿæ›´å¿«åœ°å­¦ä¹ åˆ°æœ‰æ•ˆçš„ç­–ç•¥ï¼Œå¹¶ä¸”å…·æœ‰æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

CDEæ–¹æ³•å¯åº”ç”¨äºå„ç§è§†è§‰æ§åˆ¶ä»»åŠ¡ï¼Œä¾‹å¦‚æœºå™¨äººæ“ä½œã€è‡ªåŠ¨é©¾é©¶å’Œæ¸¸æˆAIã€‚é€šè¿‡åˆ©ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹çš„å…ˆéªŒçŸ¥è¯†ï¼ŒCDEèƒ½å¤Ÿæé«˜æ™ºèƒ½ä½“åœ¨å¤æ‚ç¯å¢ƒä¸­çš„æ¢ç´¢æ•ˆç‡å’Œå­¦ä¹ èƒ½åŠ›ã€‚è¯¥æ–¹æ³•åœ¨å·¥ä¸šè‡ªåŠ¨åŒ–ã€æœåŠ¡æœºå™¨äººç­‰é¢†åŸŸå…·æœ‰æ½œåœ¨çš„åº”ç”¨ä»·å€¼ï¼Œèƒ½å¤Ÿå¸®åŠ©æœºå™¨äººæ›´å¥½åœ°ç†è§£å’Œå®Œæˆå„ç§ä»»åŠ¡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Intelligent exploration remains a critical challenge in reinforcement learning (RL), especially in visual control tasks. Unlike low-dimensional state-based RL, visual RL must extract task-relevant structure from raw pixels, making exploration inefficient. We propose Concept-Driven Exploration (CDE), which leverages a pre-trained vision-language model (VLM) to generate object-centric visual concepts from textual task descriptions as weak, potentially noisy supervisory signals. Rather than directly conditioning on these noisy signals, CDE trains a policy to reconstruct the concepts via an auxiliary objective, using reconstruction accuracy as an intrinsic reward to guide exploration toward task-relevant objects. Because the policy internalizes these concepts, VLM queries are only needed during training, reducing dependence on external models during deployment. Across five challenging simulated visual manipulation tasks, CDE achieves efficient, targeted exploration and remains robust to noisy VLM predictions. Finally, we demonstrate real-world transfer by deploying CDE on a Franka Research 3 arm, attaining an 80\% success rate in a real-world manipulation task.

