---
layout: default
title: CDE: Concept-Driven Exploration for Reinforcement Learning
---

# CDE: Concept-Driven Exploration for Reinforcement Learning

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.08851" target="_blank" class="toolbar-btn">arXiv: 2510.08851v1</a>
    <a href="https://arxiv.org/pdf/2510.08851.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.08851v1" 
            onclick="toggleFavorite(this, '2510.08851v1', 'CDE: Concept-Driven Exploration for Reinforcement Learning')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Le Mao, Andrew H. Liu, Renos Zabounidis, Zachary Kingston, Joseph Campbell

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-09

**Â§áÊ≥®**: Preprint

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Ê¶ÇÂøµÈ©±Âä®Êé¢Á¥¢(CDE)ÊñπÊ≥ïÔºåËß£ÂÜ≥ËßÜËßâÂº∫ÂåñÂ≠¶‰π†‰∏≠È´òÊïàÊé¢Á¥¢ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâÂº∫ÂåñÂ≠¶‰π†` `Ê¶ÇÂøµÈ©±Âä®Êé¢Á¥¢` `ËßÜËßâ-ËØ≠Ë®ÄÊ®°Âûã` `ÂÜÖÂú®Â•ñÂä±` `Êú∫Âô®‰∫∫Êìç‰Ωú`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ËßÜËßâÂº∫ÂåñÂ≠¶‰π†Èù¢‰∏¥‰ªéÂÉèÁ¥†‰∏≠ÊèêÂèñ‰ªªÂä°Áõ∏ÂÖ≥‰ø°ÊÅØÁöÑÊåëÊàòÔºåÂØºËá¥Êé¢Á¥¢ÊïàÁéá‰Ωé‰∏ã„ÄÇ
2. CDEÂà©Áî®È¢ÑËÆ≠ÁªÉËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÁîüÊàêÊ¶ÇÂøµÔºåÈÄöËøáÊ¶ÇÂøµÈáçÂª∫‰Ωú‰∏∫ÂÜÖÂú®Â•ñÂä±ÂºïÂØºÊé¢Á¥¢„ÄÇ
3. CDEÂú®Ê®°ÊãüÂíåÁúüÂÆûÊú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫È´òÊïàÊé¢Á¥¢ÂíåËâØÂ•ΩÁöÑËøÅÁßªËÉΩÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êô∫ËÉΩÊé¢Á¥¢ÊòØÂº∫ÂåñÂ≠¶‰π†ÔºàRLÔºâ‰∏≠ÁöÑ‰∏Ä‰∏™ÂÖ≥ÈîÆÊåëÊàòÔºåÂ∞§ÂÖ∂ÊòØÂú®ËßÜËßâÊéßÂà∂‰ªªÂä°‰∏≠„ÄÇ‰∏é‰ΩéÁª¥Áä∂ÊÄÅRL‰∏çÂêåÔºåËßÜËßâRLÂøÖÈ°ª‰ªéÂéüÂßãÂÉèÁ¥†‰∏≠ÊèêÂèñ‰ªªÂä°Áõ∏ÂÖ≥ÁöÑÁªìÊûÑÔºåËøô‰ΩøÂæóÊé¢Á¥¢ÊïàÁéá‰Ωé‰∏ã„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫ÜÊ¶ÇÂøµÈ©±Âä®Êé¢Á¥¢ÔºàCDEÔºâÔºåÂÆÉÂà©Áî®È¢ÑËÆ≠ÁªÉÁöÑËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÔºàVLMÔºâ‰ªéÊñáÊú¨‰ªªÂä°ÊèèËø∞‰∏≠ÁîüÊàê‰ª•ÂØπË±°‰∏∫‰∏≠ÂøÉÁöÑËßÜËßâÊ¶ÇÂøµÔºå‰Ωú‰∏∫Âº±ÁöÑ„ÄÅÂèØËÉΩÂ≠òÂú®Âô™Â£∞ÁöÑÁõëÁù£‰ø°Âè∑„ÄÇCDE‰∏çÊòØÁõ¥Êé•‰ª•Ëøô‰∫õÂô™Â£∞‰ø°Âè∑‰∏∫Êù°‰ª∂ÔºåËÄåÊòØËÆ≠ÁªÉÁ≠ñÁï•ÈÄöËøáËæÖÂä©ÁõÆÊ†áÈáçÂª∫Ëøô‰∫õÊ¶ÇÂøµÔºåÂπ∂‰ΩøÁî®ÈáçÂª∫Á≤æÂ∫¶‰Ωú‰∏∫ÂÜÖÂú®Â•ñÂä±ÔºåÂºïÂØºÊé¢Á¥¢ÊúùÂêë‰ªªÂä°Áõ∏ÂÖ≥ÁöÑÂØπË±°„ÄÇÁî±‰∫éÁ≠ñÁï•ÂÜÖÂåñ‰∫ÜËøô‰∫õÊ¶ÇÂøµÔºåÂõ†Ê≠§Âè™ÈúÄÂú®ËÆ≠ÁªÉÊúüÈó¥ËøõË°åVLMÊü•ËØ¢Ôºå‰ªéËÄåÂáèÂ∞ë‰∫ÜÈÉ®ÁΩ≤ÊúüÈó¥ÂØπÂ§ñÈÉ®Ê®°ÂûãÁöÑ‰æùËµñ„ÄÇÂú®‰∫î‰∏™ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÊ®°ÊãüËßÜËßâÊìç‰Ωú‰ªªÂä°‰∏≠ÔºåCDEÂÆûÁé∞‰∫ÜÈ´òÊïà„ÄÅÊúâÈíàÂØπÊÄßÁöÑÊé¢Á¥¢ÔºåÂπ∂‰∏îÂØπÂô™Â£∞VLMÈ¢ÑÊµãÂÖ∑ÊúâÈ≤ÅÊ£íÊÄß„ÄÇÊúÄÂêéÔºåÊàë‰ª¨ÈÄöËøáÂú®Franka Research 3Êú∫Ê¢∞ËáÇ‰∏äÈÉ®ÁΩ≤CDEÊù•Â±ïÁ§∫ÁúüÂÆû‰∏ñÁïåÁöÑËøÅÁßªËÉΩÂäõÔºåÂú®ÁúüÂÆû‰∏ñÁïåÁöÑÊìç‰Ωú‰ªªÂä°‰∏≠ËææÂà∞‰∫Ü80%ÁöÑÊàêÂäüÁéá„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËßÜËßâÂº∫ÂåñÂ≠¶‰π†‰∏≠ÁöÑÊé¢Á¥¢ÈóÆÈ¢òÔºåÂ∞§ÂÖ∂ÊòØÂú®Êìç‰Ωú‰ªªÂä°‰∏≠ÔºåÁî±‰∫éÁä∂ÊÄÅÁ©∫Èó¥ÊòØÈ´òÁª¥ÁöÑÂÉèÁ¥†Á©∫Èó¥ÔºåÊô∫ËÉΩ‰ΩìÈöæ‰ª•ÊúâÊïàÂú∞ÂèëÁé∞‰∏é‰ªªÂä°Áõ∏ÂÖ≥ÁöÑÂØπË±°Âíå‰∫§‰∫íÊñπÂºè„ÄÇÁé∞ÊúâÁöÑÊñπÊ≥ïË¶Å‰πà‰æùËµñ‰∫éÈöèÊú∫Êé¢Á¥¢ÔºåË¶Å‰πàÈúÄË¶ÅÂ§ßÈáèÁöÑÁéØÂ¢É‰∫§‰∫íÊâçËÉΩÂ≠¶‰π†Âà∞ÊúâÊïàÁöÑÁ≠ñÁï•ÔºåÊïàÁéáËæÉ‰Ωé„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÂà©Áî®È¢ÑËÆ≠ÁªÉÁöÑËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÔºàVLMÔºâÁöÑÂÖàÈ™åÁü•ËØÜÔºåÂ∞ÜÊñáÊú¨‰ªªÂä°ÊèèËø∞ËΩ¨Âåñ‰∏∫ÂØπË±°Á∫ßÂà´ÁöÑËßÜËßâÊ¶ÇÂøµ„ÄÇÈÄöËøáËÆ≠ÁªÉÊô∫ËÉΩ‰ΩìÂéªÈáçÂª∫Ëøô‰∫õÊ¶ÇÂøµÔºåÈºìÂä±Êô∫ËÉΩ‰ΩìÂÖ≥Ê≥®‰ªªÂä°Áõ∏ÂÖ≥ÁöÑÂØπË±°ÔºåÂπ∂‰ª•Ê≠§‰Ωú‰∏∫ÂÜÖÂú®Â•ñÂä±Êù•ÂºïÂØºÊé¢Á¥¢„ÄÇÊ†∏ÂøÉÂú®‰∫éÂ∞ÜÂ§ñÈÉ®Áü•ËØÜÔºàVLMÔºâËûçÂÖ•Âà∞Êô∫ËÉΩ‰ΩìÁöÑÊé¢Á¥¢ËøáÁ®ã‰∏≠ÔºåÂä†ÈÄüÂ≠¶‰π†„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöCDEÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) È¢ÑËÆ≠ÁªÉÁöÑËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÔºàVLMÔºâÔºåÁî®‰∫é‰ªéÊñáÊú¨‰ªªÂä°ÊèèËø∞‰∏≠ÊèêÂèñËßÜËßâÊ¶ÇÂøµÔºõ2) Á≠ñÁï•ÁΩëÁªúÔºåÁî®‰∫éÁîüÊàêÂä®‰ΩúÔºõ3) Ê¶ÇÂøµÈáçÂª∫Ê®°ÂùóÔºåÁî®‰∫éÂ∞ÜÂΩìÂâçÁä∂ÊÄÅÊò†Â∞ÑÂà∞ËßÜËßâÊ¶ÇÂøµÁöÑË°®Á§∫ÔºåÂπ∂ËÆ°ÁÆóÈáçÂª∫ËØØÂ∑ÆÔºõ4) Â•ñÂä±ÂáΩÊï∞ÔºåÁî±ÁéØÂ¢ÉÂ•ñÂä±ÂíåÊ¶ÇÂøµÈáçÂª∫Â•ñÂä±ÁªÑÊàê„ÄÇÊï¥‰ΩìÊµÅÁ®ãÊòØÔºöÊô∫ËÉΩ‰ΩìÊ†πÊçÆÁ≠ñÁï•‰∏éÁéØÂ¢É‰∫§‰∫íÔºåËé∑ÂæóÁä∂ÊÄÅÂíåÁéØÂ¢ÉÂ•ñÂä±„ÄÇÂêåÊó∂ÔºåÊô∫ËÉΩ‰ΩìÂ∞ùËØïÈáçÂª∫‰ªéÂΩìÂâçÁä∂ÊÄÅÊèêÂèñÁöÑËßÜËßâÊ¶ÇÂøµÔºåÂπ∂Ê†πÊçÆÈáçÂª∫ËØØÂ∑ÆËé∑ÂæóÊ¶ÇÂøµÈáçÂª∫Â•ñÂä±„ÄÇÊÄªÂ•ñÂä±Áî®‰∫éÊõ¥Êñ∞Á≠ñÁï•ÁΩëÁªú„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöCDEÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫é‰ΩøÁî®Ê¶ÇÂøµÈáçÂª∫‰Ωú‰∏∫ÂÜÖÂú®Â•ñÂä±Êù•ÂºïÂØºÊé¢Á¥¢„ÄÇ‰∏éÁõ¥Êé•‰ΩøÁî®VLMÁöÑËæìÂá∫‰Ωú‰∏∫Á≠ñÁï•ÁöÑÊù°‰ª∂‰∏çÂêåÔºåCDEÈÄöËøáËÆ≠ÁªÉÊô∫ËÉΩ‰ΩìÂéªÈáçÂª∫Ê¶ÇÂøµÔºå‰ΩøÂæóÊô∫ËÉΩ‰ΩìËÉΩÂ§üÂÜÖÂåñËøô‰∫õÊ¶ÇÂøµÔºå‰ªéËÄåÂáèÂ∞ë‰∫ÜÂØπVLMÁöÑ‰æùËµñÔºåÂπ∂‰∏îÊèêÈ´ò‰∫ÜÂØπÂô™Â£∞VLMÈ¢ÑÊµãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇÊ≠§Â§ñÔºåËøôÁßçÊñπÊ≥ïËÉΩÂ§üÂ∞ÜÂ§ñÈÉ®Áü•ËØÜÊúâÊïàÂú∞ËûçÂÖ•Âà∞Âº∫ÂåñÂ≠¶‰π†ÁöÑÊé¢Á¥¢ËøáÁ®ã‰∏≠„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöCDEÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ‰ΩøÁî®È¢ÑËÆ≠ÁªÉÁöÑCLIPÊ®°Âûã‰Ωú‰∏∫VLMÔºåÊèêÂèñËßÜËßâÊ¶ÇÂøµÔºõ2) ‰ΩøÁî®ÂùáÊñπËØØÂ∑ÆÔºàMSEÔºâ‰Ωú‰∏∫Ê¶ÇÂøµÈáçÂª∫ÁöÑÊçüÂ§±ÂáΩÊï∞Ôºõ3) Â∞ÜÊ¶ÇÂøµÈáçÂª∫Â•ñÂä±‰∏éÁéØÂ¢ÉÂ•ñÂä±ËøõË°åÂä†ÊùÉÊ±ÇÂíåÔºåÂæóÂà∞ÊÄªÂ•ñÂä±Ôºõ4) ‰ΩøÁî®Actor-CriticÁÆóÊ≥ïËÆ≠ÁªÉÁ≠ñÁï•ÁΩëÁªú„ÄÇÂÖ∑‰ΩìÂèÇÊï∞ËÆæÁΩÆÈúÄË¶ÅÊ†πÊçÆÂÖ∑‰Ωì‰ªªÂä°ËøõË°åË∞ÉÊï¥Ôºå‰æãÂ¶ÇÊ¶ÇÂøµÈáçÂª∫Â•ñÂä±ÁöÑÊùÉÈáçÔºå‰ª•ÂèäActorÂíåCriticÁΩëÁªúÁöÑÂ≠¶‰π†Áéá„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

CDEÂú®‰∫î‰∏™Ê®°ÊãüËßÜËßâÊìç‰Ωú‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫‰ºòÂºÇÁöÑÊÄßËÉΩÔºåÂÆûÁé∞‰∫ÜÈ´òÊïà„ÄÅÊúâÈíàÂØπÊÄßÁöÑÊé¢Á¥¢ÔºåÂπ∂‰∏îÂØπÂô™Â£∞VLMÈ¢ÑÊµãÂÖ∑ÊúâÈ≤ÅÊ£íÊÄß„ÄÇÂú®ÁúüÂÆû‰∏ñÁïåÁöÑÊú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰∏≠ÔºåCDEËææÂà∞‰∫Ü80%ÁöÑÊàêÂäüÁéáÔºåËØÅÊòé‰∫ÜÂÖ∂Âú®ÁúüÂÆûÁéØÂ¢É‰∏≠ÁöÑÂèØË°åÊÄßÂíåÊúâÊïàÊÄß„ÄÇÁõ∏ËæÉ‰∫éÂÖ∂‰ªñÊé¢Á¥¢ÊñπÊ≥ïÔºåCDEËÉΩÂ§üÊõ¥Âø´Âú∞Â≠¶‰π†Âà∞ÊúâÊïàÁöÑÁ≠ñÁï•ÔºåÂπ∂‰∏îÂÖ∑ÊúâÊõ¥Â•ΩÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

CDEÊñπÊ≥ïÂèØÂ∫îÁî®‰∫éÂêÑÁßçËßÜËßâÊéßÂà∂‰ªªÂä°Ôºå‰æãÂ¶ÇÊú∫Âô®‰∫∫Êìç‰Ωú„ÄÅËá™Âä®È©æÈ©∂ÂíåÊ∏∏ÊàèAI„ÄÇÈÄöËøáÂà©Áî®ËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÁöÑÂÖàÈ™åÁü•ËØÜÔºåCDEËÉΩÂ§üÊèêÈ´òÊô∫ËÉΩ‰ΩìÂú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑÊé¢Á¥¢ÊïàÁéáÂíåÂ≠¶‰π†ËÉΩÂäõ„ÄÇËØ•ÊñπÊ≥ïÂú®Â∑•‰∏öËá™Âä®Âåñ„ÄÅÊúçÂä°Êú∫Âô®‰∫∫Á≠âÈ¢ÜÂüüÂÖ∑ÊúâÊΩúÂú®ÁöÑÂ∫îÁî®‰ª∑ÂÄºÔºåËÉΩÂ§üÂ∏ÆÂä©Êú∫Âô®‰∫∫Êõ¥Â•ΩÂú∞ÁêÜËß£ÂíåÂÆåÊàêÂêÑÁßç‰ªªÂä°„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Intelligent exploration remains a critical challenge in reinforcement learning (RL), especially in visual control tasks. Unlike low-dimensional state-based RL, visual RL must extract task-relevant structure from raw pixels, making exploration inefficient. We propose Concept-Driven Exploration (CDE), which leverages a pre-trained vision-language model (VLM) to generate object-centric visual concepts from textual task descriptions as weak, potentially noisy supervisory signals. Rather than directly conditioning on these noisy signals, CDE trains a policy to reconstruct the concepts via an auxiliary objective, using reconstruction accuracy as an intrinsic reward to guide exploration toward task-relevant objects. Because the policy internalizes these concepts, VLM queries are only needed during training, reducing dependence on external models during deployment. Across five challenging simulated visual manipulation tasks, CDE achieves efficient, targeted exploration and remains robust to noisy VLM predictions. Finally, we demonstrate real-world transfer by deploying CDE on a Franka Research 3 arm, attaining an 80\% success rate in a real-world manipulation task.

