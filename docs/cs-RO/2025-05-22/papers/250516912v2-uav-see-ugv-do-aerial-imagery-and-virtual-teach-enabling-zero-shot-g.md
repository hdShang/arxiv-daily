---
layout: default
title: "UAV See, UGV Do: Aerial Imagery and Virtual Teach Enabling Zero-Shot Ground Vehicle Repeat"
---

# UAV See, UGV Do: Aerial Imagery and Virtual Teach Enabling Zero-Shot Ground Vehicle Repeat

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.16912" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.16912v2</a>
  <a href="https://arxiv.org/pdf/2505.16912.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.16912v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.16912v2', 'UAV See, UGV Do: Aerial Imagery and Virtual Teach Enabling Zero-Shot Ground Vehicle Repeat')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Desiree Fisker, Alexander Krawciw, Sven Lilge, Melissa Greeff, Timothy D. Barfoot

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-05-22 (æ›´æ–°: 2025-07-30)

**å¤‡æ³¨**: 8 pages, 8 figures, accepted to IROS 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVirT&Ræ¡†æ¶ä»¥è§£å†³GPSç¼ºå¤±ä¸‹çš„UGVè‡ªä¸»å¯¼èˆªé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `æ— äººé©¾é©¶` `è‡ªä¸»å¯¼èˆª` `ç¥ç»è¾å°„åœº` `ç¯å¢ƒæ¨¡æ‹Ÿ` `è·¯å¾„è·Ÿè¸ª` `è™šæ‹Ÿæ•™å­¦` `é›¶-shotå­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è‡ªä¸»å¯¼èˆªæ–¹æ³•åœ¨GPSç¼ºå¤±çš„ç¯å¢ƒä¸­è¡¨ç°ä¸ä½³ï¼Œé™åˆ¶äº†åœ°é¢è½¦è¾†çš„åº”ç”¨ã€‚
2. VirT&Ræ¡†æ¶é€šè¿‡èˆªæ‹å›¾åƒè®­ç»ƒNeRFæ¨¡å‹ï¼Œç”Ÿæˆé«˜ä¿çœŸç¯å¢ƒæ¨¡æ‹Ÿï¼Œå®ç°UGVçš„è™šæ‹Ÿè·¯å¾„å®šä¹‰ä¸æ‰§è¡Œã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒVirT&Råœ¨è·¯å¾„è·Ÿè¸ªç²¾åº¦ä¸Šä¸LT&Rç›¸å½“ï¼Œä¸”æ— éœ€äººå·¥æ•™å­¦ï¼Œæå‡äº†è‡ªä¸»æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†è™šæ‹Ÿæ•™å­¦ä¸é‡å¤ï¼ˆVirT&Rï¼‰æ¡†æ¶ï¼Œè¿™æ˜¯å¯¹ä¼ ç»Ÿæ•™å­¦ä¸é‡å¤ï¼ˆT&Rï¼‰æ¡†æ¶çš„æ‰©å±•ï¼Œæ—¨åœ¨å®ç°GPSç¼ºå¤±æƒ…å†µä¸‹çš„é›¶-shotè‡ªä¸»åœ°é¢è½¦è¾†å¯¼èˆªã€‚VirT&Råˆ©ç”¨ç›®æ ‡ç¯å¢ƒçš„èˆªæ‹å›¾åƒè®­ç»ƒç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æ¨¡å‹ï¼Œä»ä¸­æå–å¯†é›†ç‚¹äº‘å’Œç…§ç‰‡çº¹ç†ç½‘æ ¼ã€‚é€šè¿‡NeRFç”Ÿæˆçš„é«˜ä¿çœŸç¯å¢ƒæ¨¡æ‹Ÿï¼ŒUGVèƒ½å¤Ÿè™šæ‹Ÿå®šä¹‰æ‰€éœ€è·¯å¾„ï¼Œå¹¶åœ¨å®é™…ç¯å¢ƒä¸­æ‰§è¡Œä»»åŠ¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒVirT&Råœ¨è¶…è¿‡12å…¬é‡Œçš„è‡ªä¸»é©¾é©¶æ•°æ®ä¸­è¡¨ç°å‡ºè‰¯å¥½çš„é‡å¤æ€§ï¼ŒRMSEåˆ†åˆ«ä¸º19.5å˜ç±³å’Œ18.4å˜ç±³ï¼Œæ˜¾ç¤ºå‡ºä¸ä¼ ç»ŸLT&Ræ–¹æ³•ç›¸ä¼¼çš„è·¯å¾„è·Ÿè¸ªæ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨GPSç¼ºå¤±ç¯å¢ƒä¸­ï¼Œåœ°é¢è½¦è¾†ï¼ˆUGVï¼‰è‡ªä¸»å¯¼èˆªçš„æŒ‘æˆ˜ã€‚ç°æœ‰çš„æ•™å­¦ä¸é‡å¤ï¼ˆT&Rï¼‰æ–¹æ³•ä¾èµ–äºGPSå’Œäººå·¥è·¯å¾„æ•™å­¦ï¼Œé™åˆ¶äº†å…¶åœ¨æœªçŸ¥ç¯å¢ƒä¸­çš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šVirT&Ræ¡†æ¶çš„æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨èˆªæ‹å›¾åƒè®­ç»ƒç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æ¨¡å‹ï¼Œç”Ÿæˆç¯å¢ƒçš„é«˜ä¿çœŸæ¨¡æ‹Ÿï¼Œä»è€Œä½¿UGVèƒ½å¤Ÿåœ¨æœªæ¢ç´¢çš„ç¯å¢ƒä¸­è‡ªä¸»å¯¼èˆªï¼Œè€Œæ— éœ€äººå·¥å¹²é¢„ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVirT&Rçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œé€šè¿‡èˆªæ‹å›¾åƒè®­ç»ƒNeRFæ¨¡å‹ï¼Œæå–ç¯å¢ƒçš„ç‚¹äº‘å’Œçº¹ç†ï¼›å…¶æ¬¡ï¼Œåˆ©ç”¨ç”Ÿæˆçš„NeRFç½‘æ ¼åˆ›å»ºç¯å¢ƒçš„é«˜ä¿çœŸæ¨¡æ‹Ÿï¼›æœ€åï¼ŒUGVåœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­è™šæ‹Ÿå®šä¹‰è·¯å¾„ï¼Œå¹¶åœ¨å®é™…ç¯å¢ƒä¸­æ‰§è¡Œä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šVirT&Rçš„æœ€å¤§åˆ›æ–°åœ¨äºå…¶å®ç°äº†åœ¨GPSç¼ºå¤±æƒ…å†µä¸‹çš„é›¶-shotå¯¼èˆªèƒ½åŠ›ï¼Œä¸”æ— éœ€äººå·¥è·¯å¾„æ•™å­¦ï¼Œæ˜¾è‘—æé«˜äº†UGVçš„è‡ªä¸»æ€§å’Œçµæ´»æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼ŒVirT&Rä½¿ç”¨NeRFç”Ÿæˆçš„æ•™å¯¼åœ°å›¾è¿›è¡Œè·¯å¾„è§„åˆ’ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–ç‚¹äº‘çš„ç”Ÿæˆè´¨é‡ï¼Œå¹¶é€šè¿‡ç‰©ç†æ ‡è®°è¿›è¡Œè·¯å¾„è·Ÿè¸ªè¯¯å·®çš„è¯„ä¼°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒVirT&Råœ¨ä¸¤ç§ä¸åŒç¯å¢ƒä¸­å®ç°äº†19.5å˜ç±³å’Œ18.4å˜ç±³çš„å‡æ–¹æ ¹è¯¯å·®ï¼ˆRMSEï¼‰ï¼Œä¸LT&Ræ–¹æ³•ç›¸å½“ï¼Œä¸”æœ€å¤§è¯¯å·®åˆ†åˆ«ä¸º39.4å˜ç±³å’Œ47.6å˜ç±³ã€‚è¿™è¡¨æ˜VirT&Råœ¨è·¯å¾„è·Ÿè¸ªç²¾åº¦ä¸Šå…·æœ‰ç«äº‰åŠ›ï¼Œä¸”æ— éœ€äººå·¥å¹²é¢„ï¼Œæå‡äº†è‡ªä¸»æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ— äººé©¾é©¶æ±½è½¦ã€å†œä¸šæœºå™¨äººã€ç¾åæ•‘æ´ç­‰åœºæ™¯ï¼Œå°¤å…¶æ˜¯åœ¨GPSä¿¡å·å¼±æˆ–ç¼ºå¤±çš„ç¯å¢ƒä¸­ï¼ŒVirT&Ræ¡†æ¶èƒ½å¤Ÿæ˜¾è‘—æå‡åœ°é¢è½¦è¾†çš„è‡ªä¸»å¯¼èˆªèƒ½åŠ›ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper presents Virtual Teach and Repeat (VirT&R): an extension of the Teach and Repeat (T&R) framework that enables GPS-denied, zero-shot autonomous ground vehicle navigation in untraversed environments. VirT&R leverages aerial imagery captured for a target environment to train a Neural Radiance Field (NeRF) model so that dense point clouds and photo-textured meshes can be extracted. The NeRF mesh is used to create a high-fidelity simulation of the environment for piloting an unmanned ground vehicle (UGV) to virtually define a desired path. The mission can then be executed in the actual target environment by using NeRF-generated point cloud submaps associated along the path and an existing LiDAR Teach and Repeat (LT&R) framework. We benchmark the repeatability of VirT&R on over 12 km of autonomous driving data using physical markings that allow a sim-to-real lateral path-tracking error to be obtained and compared with LT&R. VirT&R achieved measured root mean squared errors (RMSE) of 19.5 cm and 18.4 cm in two different environments, which are slightly less than one tire width (24 cm) on the robot used for testing, and respective maximum errors were 39.4 cm and 47.6 cm. This was done using only the NeRF-derived teach map, demonstrating that VirT&R has similar closed-loop path-tracking performance to LT&R but does not require a human to manually teach the path to the UGV in the actual environment.

