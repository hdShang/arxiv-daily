---
layout: default
title: One-shot Humanoid Whole-body Motion Learning
---

# One-shot Humanoid Whole-body Motion Learning

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.25241" target="_blank" class="toolbar-btn">arXiv: 2510.25241v1</a>
    <a href="https://arxiv.org/pdf/2510.25241.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.25241v1" 
            onclick="toggleFavorite(this, '2510.25241v1', 'One-shot Humanoid Whole-body Motion Learning')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Hao Huang, Geeta Chandra Raju Bethala, Shuaihang Yuan, Congcong Wen, Anthony Tzes, Yi Fang

**ÂàÜÁ±ª**: cs.RO, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-29

**Â§áÊ≥®**: 10 pages, 3 figures, 5 tables

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éÂçïÊ†∑Êú¨Â≠¶‰π†ÁöÑ‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ÂÖ®Ë∫´ËøêÂä®Á≠ñÁï•ËÆ≠ÁªÉÊñπÊ≥ï**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `‰∫∫ÂΩ¢Êú∫Âô®‰∫∫` `ÂÖ®Ë∫´ËøêÂä®Â≠¶‰π†` `ÂçïÊ†∑Êú¨Â≠¶‰π†` `‰øùÂ∫èÊúÄ‰ºò‰º†Ëæì` `Âº∫ÂåñÂ≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂÖ®Ë∫´ËøêÂä®Â≠¶‰π†ÊñπÊ≥ï‰æùËµñÂ§ßÈáèËÆ≠ÁªÉÊ†∑Êú¨ÔºåÈ´òË¥®Èáè‰∫∫‰ΩìËøêÂä®Êï∞ÊçÆÊî∂ÈõÜÊàêÊú¨È´òÊòÇ„ÄÇ
2. Âà©Áî®‰øùÂ∫èÊúÄ‰ºò‰º†ËæìËÆ°ÁÆóË°åËµ∞‰∏éÈùûË°åËµ∞ËøêÂä®Ë∑ùÁ¶ªÔºåÊèíÂÄºÁîüÊàê‰∏≠Èó¥ÂßøÂäøÔºå‰ºòÂåñÂêéÁî®‰∫éÁ≠ñÁï•ËÆ≠ÁªÉ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®CMU MoCapÊï∞ÊçÆÈõÜ‰∏ä‰ºò‰∫éÁé∞ÊúâÂü∫Á∫øÊñπÊ≥ïÔºåÊÄßËÉΩÊòæËëóÊèêÂçá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ÂÖ®Ë∫´ËøêÂä®ÊòØÊú∫Âô®‰∫∫È¢ÜÂüüÁöÑÂÖ≥ÈîÆÊåëÊàòÔºåÂÆÉÊï¥Âêà‰∫ÜÂπ≥Ë°°„ÄÅÂçèË∞ÉÂíåÈÄÇÂ∫îÊÄßÔºå‰ª•ÂÆûÁé∞Á±ª‰∫∫Ë°å‰∏∫„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏ÈúÄË¶ÅÊØè‰∏™ËøêÂä®Á±ªÂà´Â§ö‰∏™ËÆ≠ÁªÉÊ†∑Êú¨ÔºåÂØºËá¥È´òË¥®Èáè‰∫∫‰ΩìËøêÂä®Êï∞ÊçÆÈõÜÁöÑÊî∂ÈõÜÊó¢Ë¥πÂäõÂèàÊòÇË¥µ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÊñπÊ≥ïÔºåËØ•ÊñπÊ≥ï‰ªÖ‰ΩøÁî®Âçï‰∏™ÈùûË°åËµ∞ÁõÆÊ†áËøêÂä®Ê†∑Êú¨‰ª•ÂèäÂÆπÊòìËé∑ÂæóÁöÑË°åËµ∞ËøêÂä®Êù•ËÆ≠ÁªÉÊúâÊïàÁöÑ‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ËøêÂä®Á≠ñÁï•„ÄÇÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÂà©Áî®‰øùÂ∫èÊúÄ‰ºò‰º†ËæìÊù•ËÆ°ÁÆóË°åËµ∞ÂíåÈùûË°åËµ∞Â∫èÂàó‰πãÈó¥ÁöÑË∑ùÁ¶ªÔºåÁÑ∂ÂêéÊ≤øÊµãÂú∞Á∫øËøõË°åÊèíÂÄº‰ª•ÁîüÊàêÊñ∞ÁöÑ‰∏≠Èó¥ÂßøÂäøÈ™®Êû∂ÔºåÊé•ÁùÄ‰ºòÂåñËøô‰∫õÈ™®Êû∂‰ª•Ëé∑ÂæóÊó†Á¢∞ÊíûÈÖçÁΩÆÔºåÂπ∂Â∞ÜÂÖ∂ÈáçÊñ∞ÂÆöÂêëÂà∞‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ÔºåÊúÄÂêéÈõÜÊàêÂà∞Ê®°ÊãüÁéØÂ¢É‰∏≠ÔºåÈÄöËøáÂº∫ÂåñÂ≠¶‰π†ËøõË°åÁ≠ñÁï•ËÆ≠ÁªÉ„ÄÇÂú®CMU MoCapÊï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åËØÑ‰º∞Ë°®ÊòéÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂßãÁªà‰ºò‰∫éÂü∫Á∫øÊñπÊ≥ïÔºåÂπ∂Âú®ÂêÑÈ°πÊåáÊ†á‰∏äÂèñÂæó‰∫ÜÂçìË∂äÁöÑÊÄßËÉΩ„ÄÇ‰ª£Á†ÅÂ∞ÜÂú®Êé•Êî∂ÂêéÂèëÂ∏É„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ÂÖ®Ë∫´ËøêÂä®Â≠¶‰π†‰∏≠ÔºåÂØπÊØè‰∏™ËøêÂä®Á±ªÂà´ÈúÄË¶ÅÂ§ßÈáèËÆ≠ÁªÉÊ†∑Êú¨ÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ï‰æùËµñ‰∫éÂ§ßÈáèÈ´òË¥®ÈáèÁöÑ‰∫∫‰ΩìËøêÂä®Êï∞ÊçÆÔºåËÄåËøô‰∫õÊï∞ÊçÆÁöÑËé∑ÂèñÊàêÊú¨È´òÊòÇ‰∏îË¥πÊó∂Ë¥πÂäõÔºåÈôêÂà∂‰∫ÜÂÖ®Ë∫´ËøêÂä®Â≠¶‰π†ÁöÑÊïàÁéáÂíåÂèØÊâ©Â±ïÊÄß„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®ÂçïÊ†∑Êú¨Â≠¶‰π†ÔºåÂç≥‰ªÖ‰ΩøÁî®‰∏Ä‰∏™ÁõÆÊ†áËøêÂä®Ê†∑Êú¨ÂíåÂ∑≤ÊúâÁöÑË°åËµ∞ËøêÂä®Êï∞ÊçÆÔºåÈÄöËøáÂ≠¶‰π†ÂÆÉ‰ª¨‰πãÈó¥ÁöÑÂÖ≥Á≥ªÔºåÁîüÊàêÊñ∞ÁöÑËøêÂä®Á≠ñÁï•„ÄÇÈÄöËøáËøôÁßçÊñπÂºèÔºåÂèØ‰ª•ÊòæËëóÂáèÂ∞ëÂØπÂ§ßÈáèËÆ≠ÁªÉÊï∞ÊçÆÁöÑ‰æùËµñÔºåÈôç‰ΩéÊï∞ÊçÆÊî∂ÈõÜÊàêÊú¨„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÈò∂ÊÆµÔºö1) **Ë∑ùÁ¶ªËÆ°ÁÆó**Ôºö‰ΩøÁî®‰øùÂ∫èÊúÄ‰ºò‰º†ËæìÔºàOrder-Preserving Optimal TransportÔºâËÆ°ÁÆóË°åËµ∞ËøêÂä®ÂíåÁõÆÊ†áÈùûË°åËµ∞ËøêÂä®Â∫èÂàó‰πãÈó¥ÁöÑË∑ùÁ¶ª„ÄÇ2) **ÂßøÂäøÊèíÂÄº**ÔºöÊ≤øÊµãÂú∞Á∫øÂú®Ë°åËµ∞ËøêÂä®ÂíåÁõÆÊ†áËøêÂä®‰πãÈó¥ËøõË°åÊèíÂÄºÔºåÁîüÊàê‰∏ÄÁ≥ªÂàó‰∏≠Èó¥ÂßøÂäøÈ™®Êû∂„ÄÇ3) **Á¢∞ÊíûÈÅøÂÖç‰∏éÈáçÂÆöÂêë**ÔºöÂØπÁîüÊàêÁöÑÂßøÂäøÈ™®Êû∂ËøõË°å‰ºòÂåñÔºåÁ°Æ‰øùÊó†Á¢∞ÊíûÔºåÂπ∂Â∞ÜËøêÂä®ÈáçÂÆöÂêëÂà∞‰∫∫ÂΩ¢Êú∫Âô®‰∫∫Ê®°Âûã„ÄÇ4) **Á≠ñÁï•ËÆ≠ÁªÉ**ÔºöÂ∞ÜÂ§ÑÁêÜÂêéÁöÑËøêÂä®Êï∞ÊçÆÈõÜÊàêÂà∞Ê®°ÊãüÁéØÂ¢É‰∏≠Ôºå‰ΩøÁî®Âº∫ÂåñÂ≠¶‰π†ËÆ≠ÁªÉ‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ÁöÑËøêÂä®Á≠ñÁï•„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ÊñπÊ≥ïÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éÂà©Áî®‰øùÂ∫èÊúÄ‰ºò‰º†ËæìÊù•Â∫¶Èáè‰∏çÂêåËøêÂä®Â∫èÂàó‰πãÈó¥ÁöÑË∑ùÁ¶ªÔºåÂπ∂Âú®Ê≠§Âü∫Á°Ä‰∏äËøõË°åÊèíÂÄºÔºå‰ªéËÄåÁîüÊàêÊñ∞ÁöÑËøêÂä®ÂßøÂäø„ÄÇËøôÁßçÊñπÊ≥ïËÉΩÂ§üÊúâÊïàÂú∞Âà©Áî®Â∞ëÈáèÊ†∑Êú¨Â≠¶‰π†Â§çÊùÇÁöÑÂÖ®Ë∫´ËøêÂä®ÔºåÈÅøÂÖç‰∫ÜÂØπÂ§ßÈáèÊï∞ÊçÆÁöÑ‰æùËµñ„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïÂú®Êï∞ÊçÆÊïàÁéáÊñπÈù¢ÂÖ∑ÊúâÊòæËëó‰ºòÂäø„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ‰ΩøÁî®‰øùÂ∫èÊúÄ‰ºò‰º†ËæìÊù•‰øùËØÅËøêÂä®Â∫èÂàóÁöÑÊó∂Èó¥È°∫Â∫è‰∏ÄËá¥ÊÄß„ÄÇ2) ÈÄöËøáÊµãÂú∞Á∫øÊèíÂÄºÁîüÊàêÂπ≥ÊªëÁöÑ‰∏≠Èó¥ÂßøÂäø„ÄÇ3) ‰ΩøÁî®Á¢∞ÊíûÈÅøÂÖçÁÆóÊ≥ïÁ°Æ‰øùÁîüÊàêÁöÑËøêÂä®ÂßøÂäøÂú®Áâ©ÁêÜ‰∏äÂèØË°å„ÄÇ4) ‰ΩøÁî®Âº∫ÂåñÂ≠¶‰π†ÁÆóÊ≥ïËÆ≠ÁªÉ‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ÁöÑËøêÂä®Á≠ñÁï•Ôºå‰ΩøÂÖ∂ËÉΩÂ§üÈÄÇÂ∫î‰∏çÂêåÁöÑÁéØÂ¢ÉÂíå‰ªªÂä°„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ËØ•ÊñπÊ≥ïÂú®CMU MoCapÊï∞ÊçÆÈõÜ‰∏äËøõË°å‰∫ÜÂÆûÈ™åÈ™åËØÅÔºåÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®ÂêÑÈ°πÊåáÊ†á‰∏äÂùá‰ºò‰∫éÂü∫Á∫øÊñπÊ≥ï„ÄÇÂÖ∑‰ΩìÊÄßËÉΩÊï∞ÊçÆÊú™Áü•Ôºå‰ΩÜÊëòË¶Å‰∏≠ÊòéÁ°ÆÊåáÂá∫ËØ•ÊñπÊ≥ï‚ÄúÂßãÁªà‰ºò‰∫éÂü∫Á∫øÊñπÊ≥ïÔºåÂπ∂Âú®ÂêÑÈ°πÊåáÊ†á‰∏äÂèñÂæó‰∫ÜÂçìË∂äÁöÑÊÄßËÉΩ‚ÄùÔºåË°®ÊòéËØ•ÊñπÊ≥ïÂÖ∑ÊúâÊòæËëóÁöÑ‰ºòÂäø„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫é‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ÁöÑËøêÂä®ÊéßÂà∂„ÄÅÂä®ÁîªÁîüÊàê„ÄÅÊ∏∏ÊàèÂºÄÂèëÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÂçïÊ†∑Êú¨Â≠¶‰π†ÔºåÂèØ‰ª•Âø´ÈÄüÁîüÊàêÂêÑÁßçÂ§çÊùÇÁöÑ‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ËøêÂä®ÔºåÈôç‰ΩéÂºÄÂèëÊàêÊú¨ÔºåÊèêÈ´òÂºÄÂèëÊïàÁéá„ÄÇÊú™Êù•ÔºåËØ•ÊäÄÊúØÊúâÊúõÂ∫îÁî®‰∫éÂ∫∑Â§çÊú∫Âô®‰∫∫„ÄÅÊúçÂä°Êú∫Âô®‰∫∫Á≠âÈ¢ÜÂüüÔºåÂÆûÁé∞Êõ¥Âä†Ëá™ÁÑ∂„ÄÅÊµÅÁïÖÁöÑ‰∫∫Êú∫‰∫§‰∫í„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Whole-body humanoid motion represents a cornerstone challenge in robotics, integrating balance, coordination, and adaptability to enable human-like behaviors. However, existing methods typically require multiple training samples per motion category, rendering the collection of high-quality human motion datasets both labor-intensive and costly. To address this, we propose a novel approach that trains effective humanoid motion policies using only a single non-walking target motion sample alongside readily available walking motions. The core idea lies in leveraging order-preserving optimal transport to compute distances between walking and non-walking sequences, followed by interpolation along geodesics to generate new intermediate pose skeletons, which are then optimized for collision-free configurations and retargeted to the humanoid before integration into a simulated environment for policy training via reinforcement learning. Experimental evaluations on the CMU MoCap dataset demonstrate that our method consistently outperforms baselines, achieving superior performance across metrics. Code will be released upon acceptance.

