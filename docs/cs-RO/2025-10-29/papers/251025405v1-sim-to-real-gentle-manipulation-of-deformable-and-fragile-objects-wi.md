---
layout: default
title: Sim-to-Real Gentle Manipulation of Deformable and Fragile Objects with Stress-Guided Reinforcement Learning
---

# Sim-to-Real Gentle Manipulation of Deformable and Fragile Objects with Stress-Guided Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.25405" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.25405v1</a>
  <a href="https://arxiv.org/pdf/2510.25405.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.25405v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.25405v1', 'Sim-to-Real Gentle Manipulation of Deformable and Fragile Objects with Stress-Guided Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kei Ikemura, Yifei Dong, David Blanco-Mulero, Alberta Longhini, Li Chen, Florian T. Pokorny

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-10-29

**å¤‡æ³¨**: Under review

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºåº”åŠ›å¼•å¯¼å¼ºåŒ–å­¦ä¹ çš„æŸ”æ€§ç‰©ä½“è½»æŸ”æ“ä½œæ–¹æ³•ï¼Œå®ç°Sim-to-Realè¿ç§»**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `æŸ”æ€§ç‰©ä½“æ“ä½œ` `Sim-to-Real` `åº”åŠ›å¼•å¯¼` `è¯¾ç¨‹å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æŸ”æ€§ç‰©ä½“æ“ä½œæ–¹æ³•ä¾èµ–ç²¾ç¡®æ¨¡å‹æˆ–ä¸“ç”¨ä¼ æ„Ÿå™¨ï¼Œæˆæœ¬é«˜ä¸”æ³›åŒ–æ€§ä¸è¶³ï¼Œéš¾ä»¥åº”å¯¹çœŸå®åœºæ™¯çš„å¤æ‚æ€§ã€‚
2. è®ºæ–‡æå‡ºä¸€ç§åŸºäºè§†è§‰çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡åº”åŠ›æƒ©ç½šå¥–åŠ±å¼•å¯¼æ™ºèƒ½ä½“å­¦ä¹ è½»æŸ”çš„æ“ä½œç­–ç•¥ï¼Œé¿å…ç‰©ä½“æŸä¼¤ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤ŸæˆåŠŸåœ°å°†ä»¿çœŸç­–ç•¥é›¶æ ·æœ¬è¿ç§»åˆ°çœŸå®ä¸–ç•Œï¼Œå¹¶åœ¨æ“ä½œæ˜“ç¢ç‰©ä½“æ—¶æ˜¾è‘—é™ä½åº”åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é’ˆå¯¹æŸ”æ€§å’Œæ˜“ç¢ç‰©ä½“çš„æœºå™¨äººæ“ä½œéš¾é¢˜ï¼Œç°æœ‰æ–¹æ³•ä¾èµ–ç²¾ç¡®æ¨¡å‹æˆ–ä¸“ç”¨ä¼ æ„Ÿå™¨ï¼Œå¤æ‚åº¦é«˜ä¸”æ³›åŒ–æ€§å·®ã€‚æœ¬æ–‡æå‡ºä¸€ç§åŸºäºè§†è§‰çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡åº”åŠ›æƒ©ç½šå¥–åŠ±æ˜¾å¼åœ°é¿å…ç‰©ä½“æŸä¼¤ã€‚ä¸ºåŠ é€Ÿå­¦ä¹ ï¼Œå¼•å…¥ç¦»çº¿æ¼”ç¤ºå’Œè¯¾ç¨‹å­¦ä¹ ï¼Œä»åˆšæ€§ä»£ç†é€æ­¥è¿‡æ¸¡åˆ°æŸ”æ€§ç‰©ä½“ã€‚åœ¨ä»¿çœŸå’ŒçœŸå®åœºæ™¯ä¸­éªŒè¯äº†è¯¥æ–¹æ³•ï¼Œè¯æ˜äº†ä»¿çœŸç­–ç•¥èƒ½å¤Ÿé›¶æ ·æœ¬è¿ç§»åˆ°çœŸå®ä¸–ç•Œï¼Œå®Œæˆè±†è…çš„æ‹¾å–å’Œæ¨åŠ¨ç­‰ä»»åŠ¡ã€‚ç»“æœè¡¨æ˜ï¼Œä¸æ™®é€šå¼ºåŒ–å­¦ä¹ ç­–ç•¥ç›¸æ¯”ï¼Œæ‰€å­¦ç­–ç•¥è¡¨ç°å‡ºæŸä¼¤æ„ŸçŸ¥çš„è½»æŸ”æ“ä½œè¡Œä¸ºï¼Œåœ¨å®Œæˆä»»åŠ¡ç›®æ ‡çš„åŒæ—¶ï¼Œæ–½åŠ åœ¨æ˜“ç¢ç‰©ä½“ä¸Šçš„åº”åŠ›é™ä½äº†36.5%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æŸ”æ€§å’Œæ˜“ç¢ç‰©ä½“ï¼ˆå¦‚è±†è…ï¼‰çš„æœºå™¨äººæ“ä½œé—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºç²¾ç¡®çš„ç‰©ä½“æ¨¡å‹ã€å¤æ‚çš„ä¼ æ„Ÿå™¨æˆ–å®šåˆ¶çš„å¤¹çˆªï¼Œè¿™äº›æ–¹æ³•æˆæœ¬é«˜æ˜‚ï¼Œä¸”éš¾ä»¥æ³›åŒ–åˆ°ä¸åŒçš„ç‰©ä½“å’Œç¯å¢ƒã€‚æ­¤å¤–ï¼Œç›´æ¥åœ¨çœŸå®ç¯å¢ƒä¸­è®­ç»ƒå¼ºåŒ–å­¦ä¹ ç­–ç•¥æˆæœ¬å¾ˆé«˜ï¼Œè€Œä»¿çœŸç¯å¢ƒä¸çœŸå®ç¯å¢ƒçš„å·®å¼‚ï¼ˆSim-to-Real gapï¼‰ä½¿å¾—ç­–ç•¥éš¾ä»¥ç›´æ¥è¿ç§»ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡åœ¨å¼ºåŒ–å­¦ä¹ çš„å¥–åŠ±å‡½æ•°ä¸­å¼•å…¥åº”åŠ›æƒ©ç½šé¡¹ï¼Œå¼•å¯¼æ™ºèƒ½ä½“å­¦ä¹ è½»æŸ”çš„æ“ä½œç­–ç•¥ï¼Œä»è€Œé¿å…å¯¹æŸ”æ€§ç‰©ä½“é€ æˆæŸä¼¤ã€‚åŒæ—¶ï¼Œåˆ©ç”¨ç¦»çº¿æ¼”ç¤ºå’Œè¯¾ç¨‹å­¦ä¹ æ¥åŠ é€Ÿå­¦ä¹ è¿‡ç¨‹ï¼Œå¹¶æé«˜ç­–ç•¥çš„æ³›åŒ–èƒ½åŠ›ã€‚é€šè¿‡ä»¿çœŸç¯å¢ƒè®­ç»ƒç­–ç•¥ï¼Œå¹¶å®ç°é›¶æ ·æœ¬è¿ç§»åˆ°çœŸå®ç¯å¢ƒã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦éƒ¨åˆ†ï¼š1) åŸºäºè§†è§‰çš„å¼ºåŒ–å­¦ä¹ ç¯å¢ƒï¼ŒåŒ…æ‹¬ä»¿çœŸç¯å¢ƒå’ŒçœŸå®ç¯å¢ƒï¼›2) å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œä½¿ç”¨SACï¼ˆSoft Actor-Criticï¼‰ç®—æ³•ï¼›3) åº”åŠ›ä¼°è®¡æ¨¡å—ï¼Œç”¨äºä¼°è®¡ç‰©ä½“å—åˆ°çš„åº”åŠ›ï¼›4) å¥–åŠ±å‡½æ•°è®¾è®¡ï¼ŒåŒ…å«ä»»åŠ¡å¥–åŠ±å’Œåº”åŠ›æƒ©ç½šï¼›5) ç¦»çº¿æ¼”ç¤ºæ•°æ®ï¼Œç”¨äºåˆå§‹åŒ–ç­–ç•¥ï¼›6) è¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼Œä»åˆšæ€§ä»£ç†é€æ­¥è¿‡æ¸¡åˆ°æŸ”æ€§ç‰©ä½“ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) å°†åº”åŠ›ä¿¡æ¯èå…¥å¼ºåŒ–å­¦ä¹ çš„å¥–åŠ±å‡½æ•°ä¸­ï¼Œä»è€Œå¼•å¯¼æ™ºèƒ½ä½“å­¦ä¹ è½»æŸ”çš„æ“ä½œç­–ç•¥ï¼›2) æå‡ºäº†ä¸€ç§è¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼Œä»åˆšæ€§ä»£ç†é€æ­¥è¿‡æ¸¡åˆ°æŸ”æ€§ç‰©ä½“ï¼ŒåŠ é€Ÿäº†å­¦ä¹ è¿‡ç¨‹ï¼›3) å®ç°äº†ä»¿çœŸç­–ç•¥åˆ°çœŸå®ç¯å¢ƒçš„é›¶æ ·æœ¬è¿ç§»ï¼Œé™ä½äº†è®­ç»ƒæˆæœ¬ã€‚

**å…³é”®è®¾è®¡**ï¼šåº”åŠ›ä¼°è®¡æ¨¡å—ä½¿ç”¨é¢„è®­ç»ƒçš„è§†è§‰æ¨¡å‹æ¥ä¼°è®¡ç‰©ä½“è¡¨é¢çš„åº”åŠ›åˆ†å¸ƒã€‚å¥–åŠ±å‡½æ•°è®¾è®¡ä¸ºä»»åŠ¡å¥–åŠ±å‡å»åº”åŠ›æƒ©ç½šé¡¹ï¼Œåº”åŠ›æƒ©ç½šé¡¹ä¸ä¼°è®¡çš„åº”åŠ›å¤§å°æˆæ­£æ¯”ã€‚è¯¾ç¨‹å­¦ä¹ ç­–ç•¥é€šè¿‡é€æ¸å‡å°åˆšæ€§ä»£ç†çš„åˆšåº¦ï¼Œä½¿å…¶é€æ¸æ¥è¿‘æŸ”æ€§ç‰©ä½“çš„ç‰¹æ€§ã€‚SACç®—æ³•ä½¿ç”¨ä¸¤ä¸ªQå‡½æ•°å’Œä¸€ä¸ªç­–ç•¥ç½‘ç»œï¼Œé€šè¿‡æœ€å¤§åŒ–ç†µæ¥æé«˜æ¢ç´¢èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä¸æ²¡æœ‰åº”åŠ›æƒ©ç½šçš„æ™®é€šå¼ºåŒ–å­¦ä¹ ç­–ç•¥ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ˜¾è‘—é™ä½æ–½åŠ åœ¨æ˜“ç¢ç‰©ä½“ä¸Šçš„åº”åŠ›ï¼Œé™ä½å¹…åº¦è¾¾åˆ°36.5%ï¼ŒåŒæ—¶ä¿æŒäº†è¾ƒé«˜çš„ä»»åŠ¡å®Œæˆç‡ã€‚æ­¤å¤–ï¼Œä»¿çœŸç­–ç•¥èƒ½å¤Ÿé›¶æ ·æœ¬è¿ç§»åˆ°çœŸå®ç¯å¢ƒï¼Œè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚åœ¨è±†è…çš„æ‹¾å–å’Œæ¨åŠ¨ä»»åŠ¡ä¸­ï¼Œæœºå™¨äººèƒ½å¤ŸæˆåŠŸåœ°å®Œæˆä»»åŠ¡ï¼Œå¹¶ä¸”é¿å…å¯¹è±†è…é€ æˆæ˜æ˜¾çš„æŸä¼¤ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºé£Ÿå“åŠ å·¥ã€åŒ»ç–—æ‰‹æœ¯ã€ç²¾å¯†ä»ªå™¨è£…é…ç­‰é¢†åŸŸï¼Œåœ¨è¿™äº›é¢†åŸŸä¸­ï¼Œå¯¹æŸ”æ€§å’Œæ˜“ç¢ç‰©ä½“çš„æ“ä½œè‡³å…³é‡è¦ã€‚é€šè¿‡å­¦ä¹ è½»æŸ”çš„æ“ä½œç­–ç•¥ï¼Œæœºå™¨äººå¯ä»¥æ›´å®‰å…¨ã€æ›´æœ‰æ•ˆåœ°å®Œæˆä»»åŠ¡ï¼Œå‡å°‘ç‰©ä½“æŸä¼¤ï¼Œæé«˜ç”Ÿäº§æ•ˆç‡ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æ‰©å±•åˆ°æ›´å¤æ‚çš„ç‰©ä½“å’Œç¯å¢ƒï¼Œå®ç°æ›´æ™ºèƒ½ã€æ›´çµæ´»çš„æœºå™¨äººæ“ä½œã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Robotic manipulation of deformable and fragile objects presents significant challenges, as excessive stress can lead to irreversible damage to the object. While existing solutions rely on accurate object models or specialized sensors and grippers, this adds complexity and often lacks generalization. To address this problem, we present a vision-based reinforcement learning approach that incorporates a stress-penalized reward to discourage damage to the object explicitly. In addition, to bootstrap learning, we incorporate offline demonstrations as well as a designed curriculum progressing from rigid proxies to deformables. We evaluate the proposed method in both simulated and real-world scenarios, showing that the policy learned in simulation can be transferred to the real world in a zero-shot manner, performing tasks such as picking up and pushing tofu. Our results show that the learned policies exhibit a damage-aware, gentle manipulation behavior, demonstrating their effectiveness by decreasing the stress applied to fragile objects by 36.5% while achieving the task goals, compared to vanilla RL policies.

