---
layout: default
title: Learning to Plan & Schedule with Reinforcement-Learned Bimanual Robot Skills
---

# Learning to Plan & Schedule with Reinforcement-Learned Bimanual Robot Skills

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.25634" target="_blank" class="toolbar-btn">arXiv: 2510.25634v1</a>
    <a href="https://arxiv.org/pdf/2510.25634.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.25634v1" 
            onclick="toggleFavorite(this, '2510.25634v1', 'Learning to Plan & Schedule with Reinforcement-Learned Bimanual Robot Skills')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Weikang Wan, Fabio Ramos, Xuning Yang, Caelan Garrett

**ÂàÜÁ±ª**: cs.RO, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-29

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éÂº∫ÂåñÂ≠¶‰π†ÂèåËáÇÊú∫Âô®‰∫∫ÊäÄËÉΩÂ∫ìÁöÑËßÑÂàí‰∏éË∞ÉÂ∫¶Ê°ÜÊû∂ÔºåËß£ÂÜ≥Â§çÊùÇÊìç‰Ωú‰ªªÂä°„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `ÂèåËáÇÊú∫Âô®‰∫∫` `Âº∫ÂåñÂ≠¶‰π†` `ÊäÄËÉΩËßÑÂàí` `‰ªªÂä°Ë∞ÉÂ∫¶` `Transformer` `Êú∫Âô®‰∫∫Êìç‰Ωú`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ÈïøÊó∂Á®ãÂèåËáÇÊìç‰Ωú‰ªªÂä°ÈúÄË¶ÅÂ§çÊùÇÁöÑÂçèË∞ÉÔºåÊ∂âÂèäÂπ∂Ë°åÊâßË°åÂíåÈ°∫Â∫èÂçè‰ΩúÔºåÁé∞ÊúâÊñπÊ≥ïÈöæ‰ª•ÊúâÊïàÂ§ÑÁêÜ„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫‰∏ÄÁßçÂàÜÂ±ÇÊ°ÜÊû∂ÔºåÂ∞Ü‰ªªÂä°ÂàÜËß£‰∏∫ÊäÄËÉΩËßÑÂàí‰∏éË∞ÉÂ∫¶ÈóÆÈ¢òÔºåÂà©Áî®ÊäÄËÉΩÂ∫ìÂíåTransformerËßÑÂàíÂô®ÂÆûÁé∞È´òÊïàÊìç‰Ωú„ÄÇ
3. ÂÆûÈ™åËØÅÊòéÔºåËØ•ÊñπÊ≥ïÂú®Â§çÊùÇ‰ªªÂä°‰∏≠‰ºò‰∫éÁ´ØÂà∞Á´ØÂº∫ÂåñÂ≠¶‰π†ÔºåÂπ∂ÁîüÊàêÊõ¥ÂçèË∞ÉÁöÑË°å‰∏∫ÔºåÊèêÂçá‰∫Ü‰ªªÂä°ÊàêÂäüÁéá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂàÜÂ±ÇÊ°ÜÊû∂ÔºåÁî®‰∫éËß£ÂÜ≥ÈïøÊó∂Á®ã„ÄÅÂØåÊé•Ëß¶ÁöÑÂèåËáÇÊìç‰Ωú‰ªªÂä°‰∏≠ÁöÑÊåëÊàò„ÄÇËØ•Ê°ÜÊû∂Â∞ÜÈóÆÈ¢òÂª∫Ê®°‰∏∫ÈõÜÊàêÁöÑÊäÄËÉΩËßÑÂàí‰∏éË∞ÉÂ∫¶ÈóÆÈ¢òÔºåË∂ÖË∂ä‰∫ÜÁ∫ØÁ≤πÁöÑÂ∫èÂàóÂÜ≥Á≠ñÔºåÊîØÊåÅÊäÄËÉΩÁöÑÂπ∂Ë°åË∞ÉÁî®„ÄÇËØ•ÊñπÊ≥ïÊûÑÂª∫‰∫éÂçïËáÇÂíåÂèåËáÇÊäÄËÉΩÂ∫ì‰πã‰∏äÔºåÊØè‰∏™ÊäÄËÉΩÈÉΩÈÄöËøáGPUÂä†ÈÄü‰ªøÁúü‰∏≠ÁöÑÂº∫ÂåñÂ≠¶‰π†ËøõË°åËÆ≠ÁªÉ„ÄÇÁÑ∂ÂêéÔºåÂú®ÊäÄËÉΩÁªÑÂêàÊï∞ÊçÆÈõÜ‰∏äËÆ≠ÁªÉ‰∏Ä‰∏™Âü∫‰∫éTransformerÁöÑËßÑÂàíÂô®Ôºå‰Ωú‰∏∫È´òÂ±ÇË∞ÉÂ∫¶Âô®ÔºåÂêåÊó∂È¢ÑÊµãÊäÄËÉΩÁöÑÁ¶ªÊï£Ë∞ÉÂ∫¶ÂèäÂÖ∂ËøûÁª≠ÂèÇÊï∞„ÄÇÂÆûÈ™åË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®Â§çÊùÇÁöÑ„ÄÅÂØåÊé•Ëß¶ÁöÑ‰ªªÂä°‰∏≠ÊØîÁ´ØÂà∞Á´ØÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÂÆûÁé∞‰∫ÜÊõ¥È´òÁöÑÊàêÂäüÁéáÔºåÂπ∂‰∏îÊØî‰º†ÁªüÁöÑ‰ªÖÂ∫èÂàóËßÑÂàíÂô®‰∫ßÁîü‰∫ÜÊõ¥ÊúâÊïà„ÄÅÊõ¥ÂçèË∞ÉÁöÑË°å‰∏∫„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥ÈïøÊó∂Á®ã„ÄÅÂØåÊé•Ëß¶ÁöÑÂèåËáÇÊìç‰Ωú‰ªªÂä°ÔºåËøôÁ±ª‰ªªÂä°ÈúÄË¶ÅÊú∫Âô®‰∫∫ËÉΩÂ§üËøõË°åÂ§çÊùÇÁöÑÂçèË∞ÉÔºåÂåÖÊã¨ÂèåËáÇÁöÑÂπ∂Ë°åÊâßË°åÂíåÈ°∫Â∫èÂçè‰Ωú„ÄÇÁé∞ÊúâÊñπÊ≥ïÔºåÂ¶ÇÁ´ØÂà∞Á´ØÂº∫ÂåñÂ≠¶‰π†ÔºåÈöæ‰ª•ÊúâÊïàÂ§ÑÁêÜËøôÁßçÂ§çÊùÇÊÄßÔºåËÄå‰º†ÁªüÁöÑÂ∫èÂàóËßÑÂàíÊñπÊ≥ïÊó†Ê≥ïÂÖÖÂàÜÂà©Áî®ÂèåËáÇÁöÑÂπ∂Ë°åËÉΩÂäõ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜÂ§çÊùÇÁöÑÂèåËáÇÊìç‰Ωú‰ªªÂä°ÂàÜËß£‰∏∫‰∏ÄÁ≥ªÂàóÈ¢ÑÂÖàËÆ≠ÁªÉÂ•ΩÁöÑÊäÄËÉΩÔºåÂπ∂ÈÄöËøá‰∏Ä‰∏™È´òÂ±ÇËßÑÂàíÂô®Êù•Ë∞ÉÂ∫¶Ëøô‰∫õÊäÄËÉΩÁöÑÊâßË°å„ÄÇËøôÁßçÂàÜÂ±ÇÊñπÊ≥ïÂÖÅËÆ∏Êú∫Âô®‰∫∫Âà©Áî®Â∑≤Áü•ÁöÑÊäÄËÉΩÊù•ÊûÑÂª∫Êõ¥Â§çÊùÇÁöÑË°å‰∏∫ÔºåÂêåÊó∂ËßÑÂàíÂô®ÂèØ‰ª•Â≠¶‰π†Â¶Ç‰ΩïÊúâÊïàÂú∞Âà©Áî®ÂèåËáÇÁöÑÂπ∂Ë°åËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´‰∏§‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) ÊäÄËÉΩÂ∫ìÔºöÂåÖÂê´ÂçïËáÇÂíåÂèåËáÇÁöÑÂéüÂßãÊäÄËÉΩÔºåËøô‰∫õÊäÄËÉΩÈÄöËøáÂº∫ÂåñÂ≠¶‰π†Âú®‰ªøÁúüÁéØÂ¢É‰∏≠ËÆ≠ÁªÉÂæóÂà∞„ÄÇ2) Âü∫‰∫éTransformerÁöÑËßÑÂàíÂô®ÔºöËØ•ËßÑÂàíÂô®Âú®È´òÂ±ÇËøõË°åÊäÄËÉΩË∞ÉÂ∫¶ÔºåÂêåÊó∂È¢ÑÊµãÊäÄËÉΩÁöÑÁ¶ªÊï£Ë∞ÉÂ∫¶ÂèäÂÖ∂ËøûÁª≠ÂèÇÊï∞„ÄÇËßÑÂàíÂô®Êé•Êî∂‰ªªÂä°ÁõÆÊ†áÂíåÂΩìÂâçÁä∂ÊÄÅ‰Ωú‰∏∫ËæìÂÖ•ÔºåËæìÂá∫‰∏Ä‰∏™ÊäÄËÉΩÂ∫èÂàóÂíåÁõ∏Â∫îÁöÑÂèÇÊï∞ÔºåÁÑ∂ÂêéÊú∫Âô®‰∫∫ÊåâÁÖßËøô‰∏™Â∫èÂàóÊâßË°åÊäÄËÉΩ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éÂ∞ÜÊäÄËÉΩËßÑÂàíÂíåË∞ÉÂ∫¶ÈóÆÈ¢òÈõÜÊàêÂà∞‰∏Ä‰∏™Ê°ÜÊû∂‰∏≠ÔºåÂπ∂Âà©Áî®TransformerÊ®°ÂûãÊù•Â≠¶‰π†ÊäÄËÉΩ‰πãÈó¥ÁöÑ‰æùËµñÂÖ≥Á≥ªÂíåÊúÄ‰ºòË∞ÉÂ∫¶Á≠ñÁï•„ÄÇ‰∏é‰º†ÁªüÁöÑÂ∫èÂàóËßÑÂàíÂô®Áõ∏ÊØîÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÊõ¥Â•ΩÂú∞Âà©Áî®ÂèåËáÇÁöÑÂπ∂Ë°åËÉΩÂäõÔºå‰ªéËÄåÂÆûÁé∞Êõ¥È´òÊïà„ÄÅÊõ¥ÂçèË∞ÉÁöÑÊìç‰Ωú„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÊäÄËÉΩÂ∫ì‰∏≠ÁöÑÊØè‰∏™ÊäÄËÉΩÈÉΩÈÄöËøáÂº∫ÂåñÂ≠¶‰π†ËøõË°åËÆ≠ÁªÉÔºå‰ΩøÁî®ÁöÑÂ•ñÂä±ÂáΩÊï∞Êó®Âú®ÈºìÂä±Êú∫Âô®‰∫∫ÂÆåÊàêÁâπÂÆöÁöÑÊìç‰ΩúÁõÆÊ†á„ÄÇTransformerËßÑÂàíÂô®ÁöÑËæìÂÖ•ÂåÖÊã¨‰ªªÂä°ÁõÆÊ†á„ÄÅÂΩìÂâçÁä∂ÊÄÅÂíåÊäÄËÉΩÂ∫ì‰∏≠ÁöÑÂèØÁî®ÊäÄËÉΩ„ÄÇËßÑÂàíÂô®ÁöÑËæìÂá∫ÂåÖÊã¨ÊäÄËÉΩÂ∫èÂàóÂíåÊØè‰∏™ÊäÄËÉΩÁöÑÂèÇÊï∞ÔºåËøô‰∫õÂèÇÊï∞ÂÜ≥ÂÆö‰∫ÜÊäÄËÉΩÁöÑÂÖ∑‰ΩìÊâßË°åÊñπÂºè„ÄÇÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°Êó®Âú®ÈºìÂä±ËßÑÂàíÂô®ÁîüÊàêÊúâÊïàÁöÑÊäÄËÉΩÂ∫èÂàóÔºåÂπ∂ÊúÄÂ§ßÂåñ‰ªªÂä°ÁöÑÊàêÂäüÁéá„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®Â§çÊùÇÁöÑ„ÄÅÂØåÊé•Ëß¶ÁöÑ‰ªªÂä°‰∏≠ÊØîÁ´ØÂà∞Á´ØÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÂÆûÁé∞‰∫ÜÊõ¥È´òÁöÑÊàêÂäüÁéá„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåÂú®‰∏Ä‰∫õË£ÖÈÖç‰ªªÂä°‰∏≠ÔºåËØ•ÊñπÊ≥ïÁöÑÊàêÂäüÁéáÊØîÁ´ØÂà∞Á´ØÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÊèêÈ´ò‰∫Ü15%-20%„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïÁîüÊàêÁöÑË°å‰∏∫‰πüÊõ¥Âä†È´òÊïàÂíåÂçèË∞ÉÔºåÂáèÂ∞ë‰∫Ü‰∏çÂøÖË¶ÅÁöÑÂä®‰ΩúÂíåÊó∂Èó¥Ê∂àËÄó„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éËá™Âä®ÂåñË£ÖÈÖç„ÄÅÂåªÁñóÊâãÊúØÊú∫Âô®‰∫∫„ÄÅÂÆ∂Â∫≠ÊúçÂä°Êú∫Âô®‰∫∫Á≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÈ¢ÑÂÖàËÆ≠ÁªÉÁöÑÊäÄËÉΩÂ∫ìÂíåÊô∫ËÉΩËßÑÂàíÂô®ÔºåÊú∫Âô®‰∫∫ËÉΩÂ§üÊõ¥ÁÅµÊ¥ª„ÄÅÈ´òÊïàÂú∞ÂÆåÊàêÂ§çÊùÇÁöÑÊìç‰Ωú‰ªªÂä°ÔºåÈôç‰Ωé‰∫∫Â∑•Âπ≤È¢ÑÁöÑÈúÄÊ±ÇÔºåÊèêÈ´òÁîü‰∫ßÊïàÁéáÂíåÊúçÂä°Ë¥®Èáè„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïÊúâÊúõÊâ©Â±ïÂà∞Êõ¥Â§öÁ±ªÂûãÁöÑÊú∫Âô®‰∫∫ÂíåÊõ¥Â§çÊùÇÁöÑ‰ªªÂä°Âú∫ÊôØ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Long-horizon contact-rich bimanual manipulation presents a significant challenge, requiring complex coordination involving a mixture of parallel execution and sequential collaboration between arms. In this paper, we introduce a hierarchical framework that frames this challenge as an integrated skill planning & scheduling problem, going beyond purely sequential decision-making to support simultaneous skill invocation. Our approach is built upon a library of single-arm and bimanual primitive skills, each trained using Reinforcement Learning (RL) in GPU-accelerated simulation. We then train a Transformer-based planner on a dataset of skill compositions to act as a high-level scheduler, simultaneously predicting the discrete schedule of skills as well as their continuous parameters. We demonstrate that our method achieves higher success rates on complex, contact-rich tasks than end-to-end RL approaches and produces more efficient, coordinated behaviors than traditional sequential-only planners.

