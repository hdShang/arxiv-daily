---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-05-12
---

# cs.ROï¼ˆ2025-05-12ï¼‰

ğŸ“Š å…± **19** ç¯‡è®ºæ–‡
 | ğŸ”— **2** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (13 ğŸ”—1)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (3)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (2 ğŸ”—1)</a>
<a href="#æ”¯æŸ±å…­è§†é¢‘æå–ä¸åŒ¹é…-video-extraction" class="interest-badge">æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (13 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250507395v1-reinbot-amplifying-robot-visual-language-manipulation-with-reinforce.html">ReinboT: Amplifying Robot Visual-Language Manipulation with Reinforcement Learning</a></td>
  <td>æå‡ºReinboTä»¥æå‡æœºå™¨äººè§†è§‰è¯­è¨€æ“ä½œçš„å†³ç­–èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">reinforcement learning</span> <span class="paper-tag">offline reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.07395v1" data-paper-url="./papers/250507395v1-reinbot-amplifying-robot-visual-language-manipulation-with-reinforce.html" onclick="toggleFavorite(this, '2505.07395v1', 'ReinboT: Amplifying Robot Visual-Language Manipulation with Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250507294v2-hub-learning-extreme-humanoid-balance.html">HuB: Learning Extreme Humanoid Balance</a></td>
  <td>æå‡ºHuBæ¡†æ¶ä»¥è§£å†³ç±»äººæœºå™¨äººå¹³è¡¡æ§åˆ¶é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid robot</span> <span class="paper-tag">humanoid control</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.07294v2" data-paper-url="./papers/250507294v2-hub-learning-extreme-humanoid-balance.html" onclick="toggleFavorite(this, '2505.07294v2', 'HuB: Learning Extreme Humanoid Balance')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250507668v1-intuitive-human-robot-interfaces-leveraging-on-autonomy-features-for.html">Intuitive Human-Robot Interfaces Leveraging on Autonomy Features for the Control of Highly-redundant Robots</a></td>
  <td>æå‡ºTelePhysicalOperationæ¥å£ä»¥è§£å†³è¿œç¨‹æ“æ§é«˜å†—ä½™æœºå™¨äººçš„é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">locomotion</span> <span class="paper-tag">manipulation</span> <span class="paper-tag">loco-manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.07668v1" data-paper-url="./papers/250507668v1-intuitive-human-robot-interfaces-leveraging-on-autonomy-features-for.html" onclick="toggleFavorite(this, '2505.07668v1', 'Intuitive Human-Robot Interfaces Leveraging on Autonomy Features for the Control of Highly-redundant Robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250507634v3-neural-brain-a-neuroscience-inspired-framework-for-embodied-agents.html">Neural Brain: A Neuroscience-inspired Framework for Embodied Agents</a></td>
  <td>æå‡ºç¥ç»å¤§è„‘æ¡†æ¶ä»¥è§£å†³å…·èº«æ™ºèƒ½ä»£ç†çš„åŠ¨æ€é€‚åº”æ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid robot</span> <span class="paper-tag">embodied AI</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.07634v3" data-paper-url="./papers/250507634v3-neural-brain-a-neuroscience-inspired-framework-for-embodied-agents.html" onclick="toggleFavorite(this, '2505.07634v3', 'Neural Brain: A Neuroscience-inspired Framework for Embodied Agents')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250507819v2-h3dp-triply-hierarchical-diffusion-policy-for-visuomotor-learning.html">H$^3$DP: Triply-Hierarchical Diffusion Policy for Visuomotor Learning</a></td>
  <td>æå‡ºH$^{	extbf{3}}$DPä»¥è§£å†³è§†è§‰æ„ŸçŸ¥ä¸åŠ¨ä½œé¢„æµ‹è€¦åˆé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">bi-manual</span> <span class="paper-tag">policy learning</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.07819v2" data-paper-url="./papers/250507819v2-h3dp-triply-hierarchical-diffusion-policy-for-visuomotor-learning.html" onclick="toggleFavorite(this, '2505.07819v2', 'H$^3$DP: Triply-Hierarchical Diffusion Policy for Visuomotor Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250507813v1-dexwild-dexterous-human-interactions-for-in-the-wild-robot-policies.html">DexWild: Dexterous Human Interactions for In-the-Wild Robot Policies</a></td>
  <td>æå‡ºDexWildä»¥è§£å†³æœºå™¨äººæ•°æ®æ”¶é›†çš„é«˜æˆæœ¬é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">dexterous manipulation</span> <span class="paper-tag">teleoperation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.07813v1" data-paper-url="./papers/250507813v1-dexwild-dexterous-human-interactions-for-in-the-wild-robot-policies.html" onclick="toggleFavorite(this, '2505.07813v1', 'DexWild: Dexterous Human Interactions for In-the-Wild Robot Policies')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250507455v1-gelfusion-enhancing-robotic-manipulation-under-visual-constraints-vi.html">GelFusion: Enhancing Robotic Manipulation under Visual Constraints via Visuotactile Fusion</a></td>
  <td>æå‡ºGelFusionä»¥è§£å†³è§†è§‰å—é™ä¸‹çš„æœºå™¨äººæ“ä½œé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">policy learning</span> <span class="paper-tag">imitation learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.07455v1" data-paper-url="./papers/250507455v1-gelfusion-enhancing-robotic-manipulation-under-visual-constraints-vi.html" onclick="toggleFavorite(this, '2505.07455v1', 'GelFusion: Enhancing Robotic Manipulation under Visual Constraints via Visuotactile Fusion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250507983v2-virtual-holonomic-constraints-in-motion-planning-revisiting-feasibil.html">Virtual Holonomic Constraints in Motion Planning: Revisiting Feasibility and Limitations</a></td>
  <td>é‡æ–°å®šä¹‰è™šæ‹Ÿå…¨å‘çº¦æŸä»¥è§£å†³è¿åŠ¨è§„åˆ’ä¸­çš„å¯è¡Œæ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">motion planning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.07983v2" data-paper-url="./papers/250507983v2-virtual-holonomic-constraints-in-motion-planning-revisiting-feasibil.html" onclick="toggleFavorite(this, '2505.07983v2', 'Virtual Holonomic Constraints in Motion Planning: Revisiting Feasibility and Limitations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250507259v1-a-framework-for-joint-grasp-and-motion-planning-in-confined-spaces.html">A Framework for Joint Grasp and Motion Planning in Confined Spaces</a></td>
  <td>æå‡ºè”åˆæŠ“å–ä¸è¿åŠ¨è§„åˆ’æ¡†æ¶ä»¥è§£å†³ç‹­å°ç©ºé—´ä¸­çš„æŠ“å–é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">motion planning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.07259v1" data-paper-url="./papers/250507259v1-a-framework-for-joint-grasp-and-motion-planning-in-confined-spaces.html" onclick="toggleFavorite(this, '2505.07259v1', 'A Framework for Joint Grasp and Motion Planning in Confined Spaces')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250507600v1-beyond-static-perception-integrating-temporal-context-into-vlms-for-.html">Beyond Static Perception: Integrating Temporal Context into VLMs for Cloth Folding</a></td>
  <td>æå‡ºBiFoldæ¨¡å‹ä»¥è§£å†³è¡£ç‰©æŠ˜å ä¸­çš„åŠ¨æ€æ„ŸçŸ¥é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">language conditioned</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.07600v1" data-paper-url="./papers/250507600v1-beyond-static-perception-integrating-temporal-context-into-vlms-for-.html" onclick="toggleFavorite(this, '2505.07600v1', 'Beyond Static Perception: Integrating Temporal Context into VLMs for Cloth Folding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250507728v1-guiding-data-collection-via-factored-scaling-curves.html">Guiding Data Collection via Factored Scaling Curves</a></td>
  <td>æå‡ºåŸºäºåˆ†è§£ç¼©æ”¾æ›²çº¿çš„æ•°æ®æ”¶é›†æŒ‡å¯¼æ–¹æ³•ä»¥æå‡æ¨¡ä»¿å­¦ä¹ æ•ˆæœ</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">imitation learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.07728v1" data-paper-url="./papers/250507728v1-guiding-data-collection-via-factored-scaling-curves.html" onclick="toggleFavorite(this, '2505.07728v1', 'Guiding Data Collection via Factored Scaling Curves')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250507802v2-improving-trajectory-stitching-with-flow-models.html">Improving Trajectory Stitching with Flow Models</a></td>
  <td>æå‡ºåŸºäºæµæ¨¡å‹çš„è½¨è¿¹æ‹¼æ¥æ–¹æ³•ä»¥è§£å†³æœºå™¨äººè·¯å¾„è§„åˆ’é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.07802v2" data-paper-url="./papers/250507802v2-improving-trajectory-stitching-with-flow-models.html" onclick="toggleFavorite(this, '2505.07802v2', 'Improving Trajectory Stitching with Flow Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/250507261v3-chd-coupled-hierarchical-diffusion-for-long-horizon-tasks.html">CHD: Coupled Hierarchical Diffusion for Long-Horizon Tasks</a></td>
  <td>æå‡ºè€¦åˆå±‚æ¬¡æ‰©æ•£æ¡†æ¶ä»¥è§£å†³é•¿æ—¶é—´ä»»åŠ¡è§„åˆ’é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.07261v3" data-paper-url="./papers/250507261v3-chd-coupled-hierarchical-diffusion-for-long-horizon-tasks.html" onclick="toggleFavorite(this, '2505.07261v3', 'CHD: Coupled Hierarchical Diffusion for Long-Horizon Tasks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (3 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>14</td>
  <td><a href="./papers/250508078v1-what-matters-for-batch-online-reinforcement-learning-in-robotics.html">What Matters for Batch Online Reinforcement Learning in Robotics?</a></td>
  <td>æå‡ºæœ‰æ•ˆçš„æ‰¹é‡åœ¨çº¿å¼ºåŒ–å­¦ä¹ æ–¹æ³•ä»¥è§£å†³æœºå™¨äººå­¦ä¹ ä¸­çš„æ•°æ®åˆ©ç”¨é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">offline RL</span> <span class="paper-tag">imitation learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.08078v1" data-paper-url="./papers/250508078v1-what-matters-for-batch-online-reinforcement-learning-in-robotics.html" onclick="toggleFavorite(this, '2505.08078v1', 'What Matters for Batch Online Reinforcement Learning in Robotics?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/250507516v1-average-reward-maximum-entropy-reinforcement-learning-for-global-pol.html">Average-Reward Maximum Entropy Reinforcement Learning for Global Policy in Double Pendulum Tasks</a></td>
  <td>æå‡ºåŸºäºå¹³å‡å¥–åŠ±æœ€å¤§ç†µå¼ºåŒ–å­¦ä¹ çš„æ–¹æ³•ä»¥è§£å†³åŒæ‘†ä»»åŠ¡</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.07516v1" data-paper-url="./papers/250507516v1-average-reward-maximum-entropy-reinforcement-learning-for-global-pol.html" onclick="toggleFavorite(this, '2505.07516v1', 'Average-Reward Maximum Entropy Reinforcement Learning for Global Policy in Double Pendulum Tasks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/250507321v1-drive-fast-learn-faster-on-board-rl-for-high-performance-autonomous-.html">Drive Fast, Learn Faster: On-Board RL for High Performance Autonomous Racing</a></td>
  <td>æå‡ºä¸€ç§åŸºäºå®æ—¶å¼ºåŒ–å­¦ä¹ çš„è‡ªä¸»èµ›è½¦æ¡†æ¶ä»¥è§£å†³é«˜æ€§èƒ½æŒ‘æˆ˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">SAC</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.07321v1" data-paper-url="./papers/250507321v1-drive-fast-learn-faster-on-board-rl-for-high-performance-autonomous-.html" onclick="toggleFavorite(this, '2505.07321v1', 'Drive Fast, Learn Faster: On-Board RL for High Performance Autonomous Racing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>17</td>
  <td><a href="./papers/250507808v1-acoustobots-a-swarm-of-robots-for-acoustophoretic-multimodal-interac.html">AcoustoBots: A swarm of robots for acoustophoretic multimodal interactions</a></td>
  <td>æå‡ºAcoustoBotsä»¥è§£å†³ä¼ ç»Ÿå£°å­¦æ“æ§çš„å±€é™æ€§</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.07808v1" data-paper-url="./papers/250507808v1-acoustobots-a-swarm-of-robots-for-acoustophoretic-multimodal-interac.html" onclick="toggleFavorite(this, '2505.07808v1', 'AcoustoBots: A swarm of robots for acoustophoretic multimodal interactions')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/250507817v2-pixel-motion-as-universal-representation-for-robot-control.html">Pixel Motion as Universal Representation for Robot Control</a></td>
  <td>æå‡ºLangToMoæ¡†æ¶ä»¥å®ç°æœºå™¨äººæ§åˆ¶çš„é€šç”¨è¡¨ç¤º</td>
  <td class="tags-cell"><span class="paper-tag">vision-language-action</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.07817v2" data-paper-url="./papers/250507817v2-pixel-motion-as-universal-representation-for-robot-control.html" onclick="toggleFavorite(this, '2505.07817v2', 'Pixel Motion as Universal Representation for Robot Control')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…­è§†é¢‘æå–ä¸åŒ¹é…-video-extraction">ğŸ”¬ æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>19</td>
  <td><a href="./papers/250507446v2-tpt-bench-a-large-scale-long-term-and-robot-egocentric-dataset-for-b.html">TPT-Bench: A Large-Scale, Long-Term and Robot-Egocentric Dataset for Benchmarking Target Person Tracking</a></td>
  <td>æå‡ºTPT-Benchæ•°æ®é›†ä»¥è§£å†³æœºå™¨äººè§†è§’ä¸‹ç›®æ ‡äººç‰©è·Ÿè¸ªé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">egocentric</span> <span class="paper-tag">embodied AI</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.07446v2" data-paper-url="./papers/250507446v2-tpt-bench-a-large-scale-long-term-and-robot-egocentric-dataset-for-b.html" onclick="toggleFavorite(this, '2505.07446v2', 'TPT-Bench: A Large-Scale, Long-Term and Robot-Egocentric Dataset for Benchmarking Target Person Tracking')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)