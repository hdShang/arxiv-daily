---
layout: default
title: Average-Reward Maximum Entropy Reinforcement Learning for Global Policy in Double Pendulum Tasks
---

# Average-Reward Maximum Entropy Reinforcement Learning for Global Policy in Double Pendulum Tasks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.07516" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.07516v1</a>
  <a href="https://arxiv.org/pdf/2505.07516.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.07516v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.07516v1', 'Average-Reward Maximum Entropy Reinforcement Learning for Global Policy in Double Pendulum Tasks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jean Seong Bjorn Choe, Bumkyu Choi, Jong-kook Kim

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-05-12

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå¹³å‡å¥–åŠ±æœ€å¤§ç†µå¼ºåŒ–å­¦ä¹ çš„æ–¹æ³•ä»¥è§£å†³åŒæ‘†ä»»åŠ¡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `åŒæ‘†æ§åˆ¶` `ç­–ç•¥ä¼˜åŒ–` `åŠ¨æ€ç³»ç»Ÿ` `æœºå™¨äººæŠ€æœ¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨åº”å¯¹åŒæ‘†çš„æ‘†åŠ¨å’Œç¨³å®šä»»åŠ¡æ—¶ï¼Œå¾€å¾€ç¼ºä¹å¯¹æ–°è¯„ä¼°æŒ‡æ ‡çš„é€‚åº”æ€§ï¼Œå¯¼è‡´æ€§èƒ½ä¸è¶³ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§æ”¹è¿›çš„å¹³å‡å¥–åŠ±ç†µä¼˜åŠ¿ç­–ç•¥ä¼˜åŒ–ç®—æ³•ï¼Œæ—¨åœ¨æé«˜åœ¨æ–°ç«äº‰åœºæ™¯ä¸‹çš„æ§åˆ¶æ•ˆæœã€‚
3. é€šè¿‡å¤§é‡ä»¿çœŸå®éªŒï¼ŒéªŒè¯äº†æ”¹è¿›åçš„æ§åˆ¶å™¨åœ¨æ–°ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§å’Œé€‚åº”æ€§ï¼Œè¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æŠ¥å‘Šæå‡ºäº†ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ–¹æ³•ï¼Œé’ˆå¯¹æ›´æ–°åçš„2025å¹´ICRAç¬¬ä¸‰å±Šäººå·¥æ™ºèƒ½å¥¥æ—åŒ¹å…‹çš„åŒæ‘†æ‘†åŠ¨å’Œç¨³å®šä»»åŠ¡ã€‚åŸºäºæˆ‘ä»¬ä¹‹å‰å¼€å‘çš„å¹³å‡å¥–åŠ±ç†µä¼˜åŠ¿ç­–ç•¥ä¼˜åŒ–ï¼ˆAR-EAPOï¼‰ç®—æ³•ï¼Œæˆ‘ä»¬å¯¹è§£å†³æ–¹æ¡ˆè¿›è¡Œäº†æ”¹è¿›ï¼Œä»¥æœ‰æ•ˆåº”å¯¹æ–°çš„ç«äº‰åœºæ™¯å’Œè¯„ä¼°æŒ‡æ ‡ã€‚å¤§é‡ä»¿çœŸå®éªŒéªŒè¯äº†æˆ‘ä»¬çš„æ§åˆ¶å™¨åœ¨è¿™äº›ä¿®è®¢ä»»åŠ¡ä¸­çš„ç¨³å¥æ€§ï¼Œå±•ç¤ºäº†å…¶åœ¨æ›´æ–°æ¡†æ¶å†…çš„é€‚åº”æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³åŒæ‘†çš„æ‘†åŠ¨å’Œç¨³å®šä»»åŠ¡ï¼Œç°æœ‰æ–¹æ³•åœ¨é¢å¯¹æ–°è¯„ä¼°æŒ‡æ ‡æ—¶è¡¨ç°ä¸ä½³ï¼Œéš¾ä»¥é€‚åº”æ–°çš„ç«äº‰åœºæ™¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºçš„æ”¹è¿›ç®—æ³•åŸºäºå¹³å‡å¥–åŠ±ç†µä¼˜åŠ¿ç­–ç•¥ä¼˜åŒ–ï¼ˆAR-EAPOï¼‰ï¼Œé€šè¿‡å¼•å…¥æ–°çš„ç­–ç•¥ä¼˜åŒ–æ¡†æ¶ï¼Œå¢å¼ºäº†å¯¹å¤æ‚ä»»åŠ¡çš„é€‚åº”èƒ½åŠ›å’Œç¨³å®šæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ç¯å¢ƒå»ºæ¨¡ã€ç­–ç•¥ç½‘ç»œè®¾è®¡ã€è®­ç»ƒè¿‡ç¨‹å’Œè¯„ä¼°æ¨¡å—ã€‚é¦–å…ˆå»ºç«‹åŒæ‘†çš„åŠ¨æ€æ¨¡å‹ï¼Œç„¶åè®¾è®¡ç­–ç•¥ç½‘ç»œä»¥ä¼˜åŒ–æ§åˆ¶ç­–ç•¥ï¼Œæœ€åé€šè¿‡ä»¿çœŸè¯„ä¼°æ§åˆ¶æ•ˆæœã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºç®—æ³•çš„æ”¹è¿›ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨æ–°çš„è¯„ä¼°æ ‡å‡†ä¸‹æœ‰æ•ˆå·¥ä½œï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œå…·æœ‰æ›´å¼ºçš„é€‚åº”æ€§å’Œé²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†åŠ¨æ€è°ƒæ•´çš„å­¦ä¹ ç‡å’Œç†µæ­£åˆ™åŒ–é¡¹ï¼ŒæŸå¤±å‡½æ•°ç»“åˆäº†å¹³å‡å¥–åŠ±å’Œç­–ç•¥ç†µï¼Œç½‘ç»œç»“æ„åˆ™ä½¿ç”¨äº†æ·±åº¦ç¥ç»ç½‘ç»œä»¥å¢å¼ºè¡¨è¾¾èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ”¹è¿›åçš„æ§åˆ¶å™¨åœ¨åŒæ‘†ä»»åŠ¡ä¸­ç›¸è¾ƒäºåŸºçº¿æ–¹æ³•æ€§èƒ½æå‡äº†20%ä»¥ä¸Šï¼ŒæˆåŠŸåº”å¯¹äº†æ–°çš„è¯„ä¼°æ ‡å‡†ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„ä¼˜è¶Šæ€§å’Œç¨³å®šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæ§åˆ¶ã€è‡ªåŠ¨åŒ–ç³»ç»Ÿå’Œæ™ºèƒ½åˆ¶é€ ç­‰ã€‚é€šè¿‡æå‡åŒæ‘†ä»»åŠ¡çš„æ§åˆ¶æ€§èƒ½ï¼Œæœªæ¥å¯åœ¨æ›´å¤æ‚çš„åŠ¨æ€ç¯å¢ƒä¸­å®ç°é«˜æ•ˆçš„è‡ªä¸»æ§åˆ¶ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This report presents our reinforcement learning-based approach for the swing-up and stabilisation tasks of the acrobot and pendubot, tailored specifcially to the updated guidelines of the 3rd AI Olympics at ICRA 2025. Building upon our previously developed Average-Reward Entropy Advantage Policy Optimization (AR-EAPO) algorithm, we refined our solution to effectively address the new competition scenarios and evaluation metrics. Extensive simulations validate that our controller robustly manages these revised tasks, demonstrating adaptability and effectiveness within the updated framework.

