---
layout: default
title: Guiding Data Collection via Factored Scaling Curves
---

# Guiding Data Collection via Factored Scaling Curves

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.07728" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.07728v1</a>
  <a href="https://arxiv.org/pdf/2505.07728.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.07728v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.07728v1', 'Guiding Data Collection via Factored Scaling Curves')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Lihan Zha, Apurva Badithela, Michael Zhang, Justin Lidard, Jeremy Bao, Emily Zhou, David Snyder, Allen Z. Ren, Dhruv Shah, Anirudha Majumdar

**åˆ†ç±»**: cs.RO, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-12

**å¤‡æ³¨**: Project website: https://factored-data-scaling.github.io

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºåˆ†è§£ç¼©æ”¾æ›²çº¿çš„æ•°æ®æ”¶é›†æŒ‡å¯¼æ–¹æ³•ä»¥æå‡æ¨¡ä»¿å­¦ä¹ æ•ˆæœ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æ¨¡ä»¿å­¦ä¹ ` `æ•°æ®æ”¶é›†` `åˆ†è§£ç¼©æ”¾æ›²çº¿` `ç¯å¢ƒé€‚åº”` `æœºå™¨äººæ“ä½œ` `æ™ºèƒ½åˆ¶é€ ` `æ€§èƒ½ä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ¨¡ä»¿å­¦ä¹ ç­–ç•¥åœ¨ä¸åŒç¯å¢ƒæ¡ä»¶ä¸‹çš„æ³›åŒ–èƒ½åŠ›ä¸è¶³ï¼Œå…¨é¢æ”¶é›†æ•°æ®çš„æˆæœ¬è¿‡é«˜ã€‚
2. æœ¬æ–‡æå‡ºé€šè¿‡åˆ†è§£ç¼©æ”¾æ›²çº¿ï¼ˆFSCï¼‰æ¥æŒ‡å¯¼æ•°æ®æ”¶é›†ï¼Œé‡åŒ–æ”¿ç­–æ€§èƒ½ä¸æ•°æ®è§„æ¨¡çš„å…³ç³»ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨æ–°ç¯å¢ƒä¸­çš„æˆåŠŸç‡æ¯”ä¼ ç»Ÿç­–ç•¥æé«˜äº†æœ€å¤š26%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é€šç”¨æ¨¡ä»¿å­¦ä¹ ç­–ç•¥åœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šè®­ç»ƒæ˜¾ç¤ºå‡ºè§£å†³å¤šæ ·åŒ–æ“ä½œä»»åŠ¡çš„è‰¯å¥½å‰æ™¯ã€‚ç„¶è€Œï¼Œä¸ºäº†ç¡®ä¿åœ¨ä¸åŒæ¡ä»¶ä¸‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œç­–ç•¥éœ€è¦åœ¨å¤§é‡ç¯å¢ƒå› ç´ å˜åŒ–ä¸‹æ”¶é›†æ•°æ®ï¼Œè¿™æ˜¯ä¸€é¡¹æˆæœ¬é«˜æ˜‚çš„ä»»åŠ¡ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸåˆ™æ€§çš„æ–¹æ³•ï¼Œé€šè¿‡æ„å»ºåˆ†è§£ç¼©æ”¾æ›²çº¿ï¼ˆFSCï¼‰ï¼Œé‡åŒ–æ”¿ç­–æ€§èƒ½å¦‚ä½•éšç€å•ä¸ªæˆ–æˆå¯¹å› ç´ çš„æ•°æ®è§„æ¨¡å˜åŒ–ã€‚è¿™äº›æ›²çº¿ä½¿å¾—åœ¨ç»™å®šé¢„ç®—å†…é’ˆå¯¹æœ€å…·å½±å“åŠ›çš„å› ç´ ç»„åˆè¿›è¡Œæœ‰é’ˆå¯¹æ€§çš„æ•°æ®è·å–æˆä¸ºå¯èƒ½ã€‚é€šè¿‡å¹¿æ³›çš„æ¨¡æ‹Ÿå’ŒçœŸå®ä¸–ç•Œå®éªŒè¯„ä¼°è¯¥æ–¹æ³•ï¼Œç»“æœè¡¨æ˜åœ¨æ–°ç¯å¢ƒä¸­çš„æˆåŠŸç‡æ¯”ç°æœ‰æ•°æ®æ”¶é›†ç­–ç•¥æé«˜äº†å¤šè¾¾26%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ¨¡ä»¿å­¦ä¹ ç­–ç•¥åœ¨ä¸åŒç¯å¢ƒæ¡ä»¶ä¸‹æ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€éœ€è¦å…¨é¢æ”¶é›†å¤§é‡æ•°æ®ï¼Œæˆæœ¬é«˜æ˜‚ä¸”æ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºåˆ†è§£ç¼©æ”¾æ›²çº¿ï¼ˆFSCï¼‰çš„æ–¹æ³•ï¼Œé€šè¿‡é‡åŒ–æ”¿ç­–æ€§èƒ½ä¸æ•°æ®è§„æ¨¡çš„å…³ç³»ï¼ŒæŒ‡å¯¼æ•°æ®æ”¶é›†çš„ä¼˜å…ˆçº§å’Œæ•°é‡ï¼Œä»¥ä¼˜åŒ–æ•°æ®è·å–è¿‡ç¨‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åŒ…æ‹¬æ•°æ®æ”¶é›†çš„åˆæ­¥åˆ†æã€æ„å»ºåˆ†è§£ç¼©æ”¾æ›²çº¿ã€ç¡®å®šä¼˜å…ˆçº§å› ç´ ç»„åˆä»¥åŠå®æ–½æ•°æ®æ”¶é›†ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ•°æ®åˆ†ææ¨¡å—ã€æ›²çº¿æ„å»ºæ¨¡å—å’Œæ•°æ®è·å–æ¨¡å—ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†åˆ†è§£ç¼©æ”¾æ›²çº¿è¿™ä¸€æ¦‚å¿µï¼Œä½¿å¾—åœ¨é¢„ç®—é™åˆ¶ä¸‹èƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«å’Œæ”¶é›†å¯¹æ”¿ç­–æ€§èƒ½å½±å“æœ€å¤§çš„å› ç´ ç»„åˆï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—æé«˜äº†æ•°æ®æ”¶é›†çš„æ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼ŒFSCçš„æ„å»ºä¾èµ–äºå¯¹ä¸åŒå› ç´ ç»„åˆçš„æ€§èƒ½è¯„ä¼°ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡è€ƒè™‘äº†å¤šå› ç´ å½±å“çš„ç»¼åˆæ€§ï¼Œç½‘ç»œç»“æ„åˆ™é‡‡ç”¨äº†é€‚åº”æ€§è°ƒæ•´çš„ç­–ç•¥ä»¥åº”å¯¹ä¸åŒç¯å¢ƒæ¡ä»¶çš„å˜åŒ–ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨åˆ†è§£ç¼©æ”¾æ›²çº¿æŒ‡å¯¼çš„æ•°æ®æ”¶é›†æ–¹æ³•åœ¨æ–°ç¯å¢ƒä¸­çš„æˆåŠŸç‡æ¯”ç°æœ‰ç­–ç•¥æé«˜äº†æœ€å¤š26%ã€‚è¿™ä¸€æ˜¾è‘—æå‡è¯æ˜äº†è¯¥æ–¹æ³•åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæ“ä½œã€è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½åˆ¶é€ ç­‰éœ€è¦åœ¨å¤šå˜ç¯å¢ƒä¸­è¿›è¡Œé«˜æ•ˆå†³ç­–çš„åœºæ™¯ã€‚é€šè¿‡ä¼˜åŒ–æ•°æ®æ”¶é›†ç­–ç•¥ï¼Œå¯ä»¥æ˜¾è‘—é™ä½è®­ç»ƒæˆæœ¬ï¼Œæé«˜æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„è¡¨ç°å’Œé€‚åº”èƒ½åŠ›ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Generalist imitation learning policies trained on large datasets show great promise for solving diverse manipulation tasks. However, to ensure generalization to different conditions, policies need to be trained with data collected across a large set of environmental factor variations (e.g., camera pose, table height, distractors) $-$ a prohibitively expensive undertaking, if done exhaustively. We introduce a principled method for deciding what data to collect and how much to collect for each factor by constructing factored scaling curves (FSC), which quantify how policy performance varies as data scales along individual or paired factors. These curves enable targeted data acquisition for the most influential factor combinations within a given budget. We evaluate the proposed method through extensive simulated and real-world experiments, across both training-from-scratch and fine-tuning settings, and show that it boosts success rates in real-world tasks in new environments by up to 26% over existing data-collection strategies. We further demonstrate how factored scaling curves can effectively guide data collection using an offline metric, without requiring real-world evaluation at scale.

