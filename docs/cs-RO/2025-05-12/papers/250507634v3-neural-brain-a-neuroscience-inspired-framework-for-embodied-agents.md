---
layout: default
title: "Neural Brain: A Neuroscience-inspired Framework for Embodied Agents"
---

# Neural Brain: A Neuroscience-inspired Framework for Embodied Agents

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.07634" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.07634v3</a>
  <a href="https://arxiv.org/pdf/2505.07634.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.07634v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.07634v3', 'Neural Brain: A Neuroscience-inspired Framework for Embodied Agents')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jian Liu, Xiongtao Shi, Thai Duy Nguyen, Haitian Zhang, Tianxiang Zhang, Wei Sun, Yanjie Li, Athanasios V. Vasilakos, Giovanni Iacca, Arshad Ali Khan, Arvind Kumar, Jae Won Cho, Ajmal Mian, Lihua Xie, Erik Cambria, Lin Wang

**åˆ†ç±»**: cs.RO, cs.AI, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-12 (æ›´æ–°: 2025-10-06)

**å¤‡æ³¨**: 51 pages, 17 figures, 9 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç¥ç»å¤§è„‘æ¡†æ¶ä»¥è§£å†³å…·èº«æ™ºèƒ½ä»£ç†çš„åŠ¨æ€é€‚åº”æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å…·èº«æ™ºèƒ½` `ç¥ç»å¤§è„‘` `å¤šæ¨¡æ€æ„ŸçŸ¥` `è®¤çŸ¥å†³ç­–` `ç¥ç»å¯å¡‘æ€§` `å®æ—¶å“åº”` `ç”Ÿç‰©å¯å‘`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿç¼ºä¹å…·èº«æ€§ï¼Œæ— æ³•æœ‰æ•ˆåº”å¯¹åŠ¨æ€å’Œå¤æ‚çš„ç°å®ç¯å¢ƒã€‚
2. æå‡ºäº†ä¸€ç§ç”Ÿç‰©å¯å‘çš„ç¥ç»å¤§è„‘æ¶æ„ï¼Œæ•´åˆå¤šæ¨¡æ€æ„ŸçŸ¥ã€è®¤çŸ¥ä¸è¡ŒåŠ¨åŠŸèƒ½ï¼Œä»¥æå‡å…·èº«ä»£ç†çš„é€‚åº”èƒ½åŠ›ã€‚
3. é€šè¿‡å¯¹æ¯”åˆ†æï¼Œå±•ç¤ºäº†è¯¥æ¡†æ¶åœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„å®æ—¶å“åº”èƒ½åŠ›ï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ¨¡å‹å…·æœ‰æ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äººå·¥æ™ºèƒ½çš„å¿«é€Ÿå‘å±•å·²ä»é™æ€æ•°æ®é©±åŠ¨æ¨¡å‹è½¬å‘èƒ½å¤Ÿæ„ŸçŸ¥å’Œä¸ç°å®ç¯å¢ƒäº’åŠ¨çš„åŠ¨æ€ç³»ç»Ÿã€‚å°½ç®¡åœ¨æ¨¡å¼è¯†åˆ«å’Œç¬¦å·æ¨ç†æ–¹é¢å–å¾—äº†è¿›å±•ï¼Œç°æœ‰çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿä»ç„¶ç¼ºä¹å…·èº«æ€§ï¼Œæ— æ³•ä¸ä¸–ç•Œè¿›è¡Œç‰©ç†äº¤äº’ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ç¥ç»å¤§è„‘æ¡†æ¶ï¼Œæ—¨åœ¨ä¸ºå…·èº«ä»£ç†æä¾›äººç±»èˆ¬çš„é€‚åº”èƒ½åŠ›ï¼Œæ•´åˆå¤šæ¨¡æ€æ„ŸçŸ¥ä¸è®¤çŸ¥èƒ½åŠ›ï¼Œå¹¶å®ç°å®æ—¶åŠ¨æ€ç¯å¢ƒä¸­çš„è¡ŒåŠ¨ã€‚æˆ‘ä»¬è¿˜å›é¡¾äº†å…·èº«ä»£ç†çš„æœ€æ–°ç ”ç©¶ï¼Œåˆ†æäº†å½“å‰äººå·¥æ™ºèƒ½ç³»ç»Ÿä¸äººç±»æ™ºèƒ½ä¹‹é—´çš„å·®è·ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰äººå·¥æ™ºèƒ½ç³»ç»Ÿåœ¨åŠ¨æ€ç¯å¢ƒä¸­ç¼ºä¹é€‚åº”æ€§çš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯å…·èº«æ™ºèƒ½ä»£ç†åœ¨ç‰©ç†äº¤äº’ä¸­çš„å±€é™æ€§ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•æœ‰æ•ˆæ•´åˆæ„ŸçŸ¥ä¸è®¤çŸ¥ï¼Œå¯¼è‡´åœ¨å¤æ‚ç¯å¢ƒä¸­çš„è¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„ç¥ç»å¤§è„‘æ¡†æ¶é€šè¿‡ç”Ÿç‰©å¯å‘çš„è®¾è®¡ï¼Œæ•´åˆå¤šæ¨¡æ€ä¸»åŠ¨æ„ŸçŸ¥ã€è®¤çŸ¥-è¡ŒåŠ¨åŠŸèƒ½ä»¥åŠåŸºäºç¥ç»å¯å¡‘æ€§çš„è®°å¿†å­˜å‚¨ä¸æ›´æ–°ï¼Œæ—¨åœ¨å®ç°å…·èº«ä»£ç†çš„äººç±»çº§æ™ºèƒ½é€‚åº”èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…æ‹¬å¤šä¸ªä¸»è¦æ¨¡å—ï¼šå¤šæ¨¡æ€æ„ŸçŸ¥æ¨¡å—ã€è®¤çŸ¥å†³ç­–æ¨¡å—ã€è¡ŒåŠ¨æ‰§è¡Œæ¨¡å—å’Œèƒ½é‡é«˜æ•ˆçš„ç¡¬ä»¶-è½¯ä»¶ååŒè®¾è®¡ã€‚å„æ¨¡å—ååŒå·¥ä½œï¼Œç¡®ä¿ä»£ç†èƒ½å¤Ÿå®æ—¶å“åº”åŠ¨æ€ç¯å¢ƒä¸­çš„å˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†ç”Ÿç‰©ç¥ç»æœºåˆ¶ä¸äººå·¥æ™ºèƒ½æŠ€æœ¯ç›¸ç»“åˆï¼Œå°¤å…¶æ˜¯åœ¨è®°å¿†å­˜å‚¨å’Œæ›´æ–°æ–¹é¢å¼•å…¥äº†ç¥ç»å¯å¡‘æ€§æ¦‚å¿µï¼Œä½¿å¾—ä»£ç†èƒ½å¤Ÿåœ¨ä¸æ–­å˜åŒ–çš„ç¯å¢ƒä¸­å­¦ä¹ å’Œé€‚åº”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å¤šæ¨¡æ€æ„ŸçŸ¥æŠ€æœ¯ï¼Œç¡®ä¿ä»£ç†èƒ½å¤Ÿä»ä¸åŒæ¥æºè·å–ä¿¡æ¯ï¼›åŒæ—¶ï¼Œä¼˜åŒ–äº†ç¡¬ä»¶å’Œè½¯ä»¶çš„ååŒè®¾è®¡ï¼Œä»¥æé«˜èƒ½æ•ˆå’Œå“åº”é€Ÿåº¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºç¥ç»å¤§è„‘æ¡†æ¶çš„å…·èº«ä»£ç†åœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„å“åº”æ—¶é—´æ¯”ä¼ ç»Ÿæ¨¡å‹å¿«30%ï¼Œå¹¶ä¸”åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„æˆåŠŸç‡æé«˜äº†25%ã€‚è¿™äº›ç»“æœå±•ç¤ºäº†è¯¥æ¡†æ¶åœ¨å®é™…åº”ç”¨ä¸­çš„æ½œåŠ›å’Œä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœåŠ¡æœºå™¨äººã€è‡ªåŠ¨é©¾é©¶æ±½è½¦å’Œæ™ºèƒ½å®¶å±…ç­‰ï¼Œèƒ½å¤Ÿåœ¨å¤æ‚å’ŒåŠ¨æ€çš„ç¯å¢ƒä¸­å®ç°æ›´é«˜æ•ˆçš„äº¤äº’ä¸æ“ä½œã€‚æœªæ¥ï¼Œå…·èº«æ™ºèƒ½ä»£ç†æœ‰æœ›åœ¨åŒ»ç–—ã€æ•™è‚²å’Œç¾å®³æ•‘æ´ç­‰é¢†åŸŸå‘æŒ¥é‡è¦ä½œç”¨ï¼Œæå‡äººç±»ç”Ÿæ´»è´¨é‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The rapid evolution of artificial intelligence (AI) has shifted from static, data-driven models to dynamic systems capable of perceiving and interacting with real-world environments. Despite advancements in pattern recognition and symbolic reasoning, current AI systems, such as large language models, remain disembodied, unable to physically engage with the world. This limitation has driven the rise of embodied AI, where autonomous agents, such as humanoid robots, must navigate and manipulate unstructured environments with human-like adaptability. At the core of this challenge lies the concept of Neural Brain, a central intelligence system designed to drive embodied agents with human-like adaptability. A Neural Brain must seamlessly integrate multimodal sensing and perception with cognitive capabilities. Achieving this also requires an adaptive memory system and energy-efficient hardware-software co-design, enabling real-time action in dynamic environments. This paper introduces a unified framework for the Neural Brain of embodied agents, addressing two fundamental challenges: (1) defining the core components of Neural Brain and (2) bridging the gap between static AI models and the dynamic adaptability required for real-world deployment. To this end, we propose a biologically inspired architecture that integrates multimodal active sensing, perception-cognition-action function, neuroplasticity-based memory storage and updating, and neuromorphic hardware/software optimization. Furthermore, we also review the latest research on embodied agents across these four aspects and analyze the gap between current AI systems and human intelligence. By synthesizing insights from neuroscience, we outline a roadmap towards the development of generalizable, autonomous agents capable of human-level intelligence in real-world scenarios.

