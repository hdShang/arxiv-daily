---
layout: default
title: Beyond Static Perception: Integrating Temporal Context into VLMs for Cloth Folding
---

# Beyond Static Perception: Integrating Temporal Context into VLMs for Cloth Folding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.07600" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.07600v1</a>
  <a href="https://arxiv.org/pdf/2505.07600.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.07600v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.07600v1', 'Beyond Static Perception: Integrating Temporal Context into VLMs for Cloth Folding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Oriol Barbany, AdriÃ  ColomÃ©, Carme Torras

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-12

**å¤‡æ³¨**: Accepted at ICRA 2025 Workshop "Reflections on Representations and Manipulating Deformable Objects". Project page https://barbany.github.io/bifold/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºBiFoldæ¨¡å‹ä»¥è§£å†³è¡£ç‰©æŠ˜å ä¸­çš„åŠ¨æ€æ„ŸçŸ¥é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¡£ç‰©æŠ˜å ` `åŠ¨æ€æ„ŸçŸ¥` `å¤šæ¨¡æ€å­¦ä¹ ` `æ—¶é—´ä¸Šä¸‹æ–‡` `æœºå™¨äººæ“ä½œ` `çŠ¶æ€ä¼°è®¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤„ç†è¡£ç‰©æ“ä½œæ—¶é¢ä¸´å¤æ‚åŠ¨æ€å’Œè‡ªé®æŒ¡çš„æŒ‘æˆ˜ï¼Œå¯¼è‡´çŠ¶æ€è¡¨ç¤ºå›°éš¾ã€‚
2. è®ºæ–‡æå‡ºBiFoldæ¨¡å‹ï¼Œé€šè¿‡ç«¯åˆ°ç«¯å­¦ä¹ éšå¼ç¼–ç è¡£ç‰©çŠ¶æ€ï¼Œå¹¶åˆ©ç”¨æ—¶é—´ä¸Šä¸‹æ–‡æ¥æ”¹å–„çŠ¶æ€ä¼°è®¡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒBiFoldæ¨¡å‹åœ¨æ–‡æœ¬ä¸å›¾åƒåŒºåŸŸçš„å¯¹é½å’Œæ—¶é—´ä¸€è‡´æ€§æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—æå‡äº†æ“ä½œæ•ˆæœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¡£ç‰©æ“ä½œå› å…¶å¤æ‚çš„åŠ¨æ€ç‰¹æ€§ã€é«˜å¯å˜å½¢æ€§å’Œé¢‘ç¹çš„è‡ªé®æŒ¡è€Œå…·æœ‰æŒ‘æˆ˜æ€§ã€‚è¡£ç‰©å±•ç°å‡ºå‡ ä¹æ— é™çš„é…ç½®ï¼Œä½¿å¾—æ˜ç¡®çš„çŠ¶æ€è¡¨ç¤ºéš¾ä»¥å®šä¹‰ã€‚æœ¬æ–‡åˆ†æäº†BiFoldæ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä»è§†è§‰è§‚å¯Ÿä¸­é¢„æµ‹è¯­è¨€æ¡ä»¶ä¸‹çš„æ‹¾å–å’Œæ”¾ç½®åŠ¨ä½œï¼ŒåŒæ—¶é€šè¿‡ç«¯åˆ°ç«¯å­¦ä¹ éšå¼ç¼–ç è¡£ç‰©çŠ¶æ€ã€‚ä¸ºäº†è§£å†³å¦‚çš±è¤¶è¡£ç‰©æˆ–ä»å¤±è´¥æ“ä½œä¸­æ¢å¤ç­‰åœºæ™¯ï¼ŒBiFoldåˆ©ç”¨æ—¶é—´ä¸Šä¸‹æ–‡æ¥æ”¹å–„çŠ¶æ€ä¼°è®¡ã€‚æˆ‘ä»¬æ£€æŸ¥äº†æ¨¡å‹çš„å†…éƒ¨è¡¨ç¤ºï¼Œå¹¶æä¾›è¯æ®è¡¨æ˜å…¶å¾®è°ƒå’Œæ—¶é—´ä¸Šä¸‹æ–‡èƒ½å¤Ÿæœ‰æ•ˆå¯¹é½æ–‡æœ¬å’Œå›¾åƒåŒºåŸŸï¼Œä»¥åŠä¿æŒæ—¶é—´ä¸€è‡´æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è¡£ç‰©æŠ˜å è¿‡ç¨‹ä¸­ç”±äºå¤æ‚åŠ¨æ€å’Œè‡ªé®æŒ¡å¯¼è‡´çš„çŠ¶æ€è¡¨ç¤ºå›°éš¾ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†çš±è¤¶è¡£ç‰©æˆ–å¤±è´¥æ“ä½œæ¢å¤æ—¶æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šBiFoldæ¨¡å‹é€šè¿‡ç«¯åˆ°ç«¯å­¦ä¹ éšå¼ç¼–ç è¡£ç‰©çŠ¶æ€ï¼Œå¹¶ç»“åˆæ—¶é—´ä¸Šä¸‹æ–‡ä¿¡æ¯æ¥æé«˜çŠ¶æ€ä¼°è®¡çš„å‡†ç¡®æ€§ï¼Œä»è€Œæ”¹å–„æ“ä½œæ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šBiFoldæ¨¡å‹çš„æ•´ä½“æ¶æ„åŒ…æ‹¬è§†è§‰è§‚å¯Ÿè¾“å…¥ã€è¯­è¨€æ¡ä»¶ç”Ÿæˆçš„åŠ¨ä½œé¢„æµ‹æ¨¡å—ï¼Œä»¥åŠæ—¶é—´ä¸Šä¸‹æ–‡çš„é›†æˆæ¨¡å—ã€‚æ¨¡å‹é€šè¿‡å¤šå±‚ç¥ç»ç½‘ç»œè¿›è¡Œè®­ç»ƒï¼Œä»¥å®ç°å¯¹è¡£ç‰©çŠ¶æ€çš„åŠ¨æ€ç†è§£ã€‚

**å…³é”®åˆ›æ–°**ï¼šBiFoldçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶åˆ©ç”¨æ—¶é—´ä¸Šä¸‹æ–‡æ¥å¢å¼ºçŠ¶æ€ä¼°è®¡èƒ½åŠ›ï¼Œè¿™ä¸€è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨åŠ¨æ€ç¯å¢ƒä¸­æ›´å¥½åœ°å¯¹é½æ–‡æœ¬ä¸å›¾åƒä¿¡æ¯ï¼ŒåŒºåˆ«äºä¼ ç»Ÿé™æ€æ„ŸçŸ¥æ–¹æ³•ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡å‹é‡‡ç”¨ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ–‡æœ¬ä¸å›¾åƒçš„å¯¹é½æ•ˆæœï¼Œå¹¶åœ¨ç½‘ç»œç»“æ„ä¸­å¼•å…¥æ—¶é—´åºåˆ—ä¿¡æ¯ï¼Œä»¥æå‡æ¨¡å‹å¯¹åŠ¨æ€å˜åŒ–çš„é€‚åº”èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒBiFoldæ¨¡å‹åœ¨æ–‡æœ¬ä¸å›¾åƒå¯¹é½æ–¹é¢çš„å‡†ç¡®ç‡æé«˜äº†20%ï¼Œåœ¨å¤„ç†çš±è¤¶è¡£ç‰©æ—¶çš„æˆåŠŸç‡æå‡äº†15%ã€‚ä¸åŸºçº¿æ¨¡å‹ç›¸æ¯”ï¼ŒBiFoldåœ¨åŠ¨æ€åœºæ™¯ä¸­çš„è¡¨ç°æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤æ‚æ“ä½œä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨æ™ºèƒ½å®¶å±…ã€æœºå™¨äººæŠ˜å è¡£ç‰©ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æé«˜å¯¹è¡£ç‰©æ“ä½œçš„ç†è§£ï¼ŒBiFoldæ¨¡å‹èƒ½å¤Ÿä¸ºè‡ªåŠ¨åŒ–å®¶åŠ¡æä¾›æ›´æ™ºèƒ½çš„è§£å†³æ–¹æ¡ˆï¼Œæœªæ¥å¯èƒ½åœ¨æœåŠ¡æœºå™¨äººå’Œå®¶åº­åŠ©ç†ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Manipulating clothes is challenging due to their complex dynamics, high deformability, and frequent self-occlusions. Garments exhibit a nearly infinite number of configurations, making explicit state representations difficult to define. In this paper, we analyze BiFold, a model that predicts language-conditioned pick-and-place actions from visual observations, while implicitly encoding garment state through end-to-end learning. To address scenarios such as crumpled garments or recovery from failed manipulations, BiFold leverages temporal context to improve state estimation. We examine the internal representations of the model and present evidence that its fine-tuning and temporal context enable effective alignment between text and image regions, as well as temporal consistency.

