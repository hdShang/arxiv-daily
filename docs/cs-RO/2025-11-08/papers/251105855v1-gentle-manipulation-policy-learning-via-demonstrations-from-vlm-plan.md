---
layout: default
title: Gentle Manipulation Policy Learning via Demonstrations from VLM Planned Atomic Skills
---

# Gentle Manipulation Policy Learning via Demonstrations from VLM Planned Atomic Skills

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.05855" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.05855v1</a>
  <a href="https://arxiv.org/pdf/2511.05855.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.05855v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.05855v1', 'Gentle Manipulation Policy Learning via Demonstrations from VLM Planned Atomic Skills')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiayu Zhou, Qiwei Wu, Jian Li, Zhe Chen, Xiaogang Xiong, Renjing Xu

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-11-08

**å¤‡æ³¨**: Accepted for the 40th Annual AAAI Conference on Artificial Intelligence (2026)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºVLMè§„åˆ’åŸå­æŠ€èƒ½çš„æŸ”æ€§æ“ä½œç­–ç•¥å­¦ä¹ æ¡†æ¶ï¼Œæ— éœ€äººå·¥æ¼”ç¤ºã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æ“ä½œç­–ç•¥å­¦ä¹ ` `è§†è§‰è¯­è¨€æ¨¡å‹` `å¼ºåŒ–å­¦ä¹ ` `çŸ¥è¯†è’¸é¦` `æœºå™¨äººæ“ä½œ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. é•¿æ—¶ç¨‹æ“ä½œä»»åŠ¡ä¾èµ–å¤§é‡çœŸå®æ•°æ®å’Œäººå·¥è®¾è®¡ï¼Œæˆæœ¬é«˜ä¸”éš¾ä»¥æ‰©å±•ã€‚
2. åˆ©ç”¨VLMè¿›è¡Œä»»åŠ¡åˆ†è§£å’ŒæŠ€èƒ½è§„åˆ’ï¼Œç”Ÿæˆä¸“å®¶æ¼”ç¤ºï¼Œå†é€šè¿‡çŸ¥è¯†è’¸é¦å­¦ä¹ ç»Ÿä¸€ç­–ç•¥ã€‚
3. é€šè¿‡æ¨¡æ‹Ÿå’Œç‰©ç†å®éªŒéªŒè¯ï¼Œè¯¥æ–¹æ³•æ— éœ€äººå·¥æ¼”ç¤ºå³å¯å­¦ä¹ é•¿æ—¶ç¨‹æ“ä½œç­–ç•¥ï¼Œå¹¶å…·å¤‡è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é›†æˆäº†åˆ†å±‚è¯­ä¹‰åˆ†è§£ã€å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ã€è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰å’ŒçŸ¥è¯†è’¸é¦ï¼Œä»¥å…‹æœé•¿æ—¶ç¨‹ã€æ¥è§¦ä¸°å¯Œçš„æ“ä½œä»»åŠ¡ä¸­æ•°æ®éœ€æ±‚å’Œå·¥ç¨‹æŒ‘æˆ˜ã€‚å¤æ‚ä»»åŠ¡è¢«åˆ†è§£ä¸ºåŸå­æŠ€èƒ½ï¼Œæ¯ä¸ªåŸè¯­çš„ç­–ç•¥ä»…åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­é€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼Œå¹¶æ˜¾å¼åœ°åŠ å…¥åŠ›çº¦æŸä»¥é˜²æ­¢ç‰©ä½“æŸåã€‚è§†è§‰è¯­è¨€æ¨¡å‹æ‰§è¡Œé«˜å±‚ä»»åŠ¡åˆ†è§£å’ŒæŠ€èƒ½è§„åˆ’ï¼Œç”Ÿæˆå¤šæ ·åŒ–çš„ä¸“å®¶æ¼”ç¤ºã€‚è¿™äº›æ¼”ç¤ºé€šè¿‡è§†è§‰-è§¦è§‰æ‰©æ•£ç­–ç•¥è¢«æç‚¼æˆç»Ÿä¸€çš„ç­–ç•¥ï¼Œç”¨äºç«¯åˆ°ç«¯æ‰§è¡Œã€‚é€šè¿‡æ¶ˆèå®éªŒæ¢ç´¢äº†ä¸åŒçš„åŸºäºVLMçš„ä»»åŠ¡è§„åˆ’å™¨ï¼Œä»¥ç¡®å®šæœ€ä½³çš„æ¼”ç¤ºç”Ÿæˆæµç¨‹ï¼Œå¹¶ç³»ç»Ÿåœ°æ¯”è¾ƒäº†ç”¨äºæŠ€èƒ½è’¸é¦çš„æ¨¡ä»¿å­¦ä¹ ç®—æ³•ã€‚å¤§é‡çš„æ¨¡æ‹Ÿå®éªŒå’Œç‰©ç†éƒ¨ç½²éªŒè¯äº†è¯¥æ–¹æ³•å¯ä»¥åœ¨æ²¡æœ‰æ˜‚è´µçš„äººå·¥æ¼”ç¤ºçš„æƒ…å†µä¸‹å®ç°é•¿æ—¶ç¨‹æ“ä½œçš„ç­–ç•¥å­¦ä¹ ï¼ŒåŒæ—¶VLMå¼•å¯¼çš„åŸå­æŠ€èƒ½æ¡†æ¶èƒ½å¤Ÿæ‰©å±•æ³›åŒ–åˆ°ä¸åŒçš„ä»»åŠ¡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰é•¿æ—¶ç¨‹ã€æ¥è§¦ä¸°å¯Œçš„æ“ä½œä»»åŠ¡ï¼Œéœ€è¦å¤§é‡çœŸå®ä¸–ç•Œæ•°æ®å’Œä¸“å®¶å·¥ç¨‹ï¼Œå¯¼è‡´æˆæœ¬é«˜æ˜‚ä¸”éš¾ä»¥æ‰©å±•ã€‚å°¤å…¶æ˜¯åœ¨æŸ”æ€§æ“ä½œä¸­ï¼Œéœ€è¦ç²¾ç¡®æ§åˆ¶åŠ›ä»¥é¿å…æŸåç‰©ä½“ï¼Œè¿™è¿›ä¸€æ­¥å¢åŠ äº†æ•°æ®æ”¶é›†çš„éš¾åº¦ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šå°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºä¸€ç³»åˆ—åŸå­æŠ€èƒ½ï¼Œæ¯ä¸ªæŠ€èƒ½é€šè¿‡å¼ºåŒ–å­¦ä¹ åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­è®­ç»ƒã€‚åˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰è¿›è¡Œé«˜å±‚ä»»åŠ¡åˆ†è§£å’ŒæŠ€èƒ½è§„åˆ’ï¼Œç”Ÿæˆå¤šæ ·åŒ–çš„ä¸“å®¶æ¼”ç¤ºã€‚ç„¶åï¼Œé€šè¿‡æ¨¡ä»¿å­¦ä¹ å°†è¿™äº›æ¼”ç¤ºæç‚¼æˆä¸€ä¸ªç»Ÿä¸€çš„ç­–ç•¥ï¼Œå®ç°ç«¯åˆ°ç«¯çš„ä»»åŠ¡æ‰§è¡Œã€‚æ ¸å¿ƒåœ¨äºåˆ©ç”¨VLMçš„å¼ºå¤§è¯­ä¹‰ç†è§£èƒ½åŠ›æ¥æŒ‡å¯¼æŠ€èƒ½è§„åˆ’ï¼Œä»è€Œé¿å…äº†å¯¹å¤§é‡äººå·¥æ¼”ç¤ºæ•°æ®çš„ä¾èµ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼š1) **åŸå­æŠ€èƒ½å­¦ä¹ **ï¼šä½¿ç”¨å¼ºåŒ–å­¦ä¹ åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­è®­ç»ƒæ¯ä¸ªåŸå­æŠ€èƒ½çš„ç­–ç•¥ï¼Œå¹¶åŠ å…¥åŠ›çº¦æŸã€‚2) **VLMä»»åŠ¡è§„åˆ’**ï¼šåˆ©ç”¨VLMè¿›è¡Œé«˜å±‚ä»»åŠ¡åˆ†è§£å’ŒæŠ€èƒ½è§„åˆ’ï¼Œç”Ÿæˆä¸€ç³»åˆ—åŸå­æŠ€èƒ½åºåˆ—ä½œä¸ºä¸“å®¶æ¼”ç¤ºã€‚3) **ç­–ç•¥è’¸é¦**ï¼šä½¿ç”¨æ¨¡ä»¿å­¦ä¹ å°†VLMç”Ÿæˆçš„ä¸“å®¶æ¼”ç¤ºæç‚¼æˆä¸€ä¸ªç»Ÿä¸€çš„ç­–ç•¥ï¼Œç”¨äºç«¯åˆ°ç«¯çš„ä»»åŠ¡æ‰§è¡Œã€‚è¯¥æ¡†æ¶é‡‡ç”¨åˆ†å±‚ç»“æ„ï¼Œå°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºæ˜“äºå­¦ä¹ å’Œæ³›åŒ–çš„åŸå­æŠ€èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•çš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå°†è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰å¼•å…¥åˆ°æ“ä½œç­–ç•¥å­¦ä¹ ä¸­ï¼Œåˆ©ç”¨VLMçš„è¯­ä¹‰ç†è§£å’Œè§„åˆ’èƒ½åŠ›æ¥ç”Ÿæˆä¸“å®¶æ¼”ç¤ºï¼Œä»è€Œé¿å…äº†å¯¹å¤§é‡äººå·¥æ¼”ç¤ºæ•°æ®çš„ä¾èµ–ã€‚ä¸ä¼ ç»Ÿçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å­¦ä¹ é•¿æ—¶ç¨‹ã€æ¥è§¦ä¸°å¯Œçš„æ“ä½œä»»åŠ¡ã€‚æ­¤å¤–ï¼Œæ˜¾å¼çš„åŠ›çº¦æŸå¼ºåŒ–å­¦ä¹ è®­ç»ƒä¹Ÿä¿è¯äº†æŸ”æ€§æ“ä½œçš„å®‰å…¨æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨åŸå­æŠ€èƒ½å­¦ä¹ é˜¶æ®µï¼Œä½¿ç”¨äº†å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼ˆå…·ä½“ç®—æ³•æœªçŸ¥ï¼‰å¹¶åŠ å…¥äº†åŠ›çº¦æŸï¼Œä»¥é˜²æ­¢ç‰©ä½“æŸåã€‚åœ¨VLMä»»åŠ¡è§„åˆ’é˜¶æ®µï¼Œæ¢ç´¢äº†ä¸åŒçš„VLMæ¨¡å‹å’Œæç¤ºå·¥ç¨‹æ–¹æ³•ï¼Œä»¥ç”Ÿæˆé«˜è´¨é‡çš„ä¸“å®¶æ¼”ç¤ºã€‚åœ¨ç­–ç•¥è’¸é¦é˜¶æ®µï¼Œä½¿ç”¨äº†è§†è§‰-è§¦è§‰æ‰©æ•£ç­–ç•¥ï¼ˆVisual-Tactile Diffusion Policyï¼‰ï¼Œå¹¶æ¯”è¾ƒäº†ä¸åŒçš„æ¨¡ä»¿å­¦ä¹ ç®—æ³•ï¼ˆå…·ä½“ç®—æ³•æœªçŸ¥ï¼‰ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡ç›®æ ‡æ˜¯æœ€å°åŒ–æ¨¡ä»¿å­¦ä¹ çš„è¯¯å·®ï¼Œå¹¶ä¿è¯ç­–ç•¥çš„å¹³æ»‘æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’Œå‚æ•°è®¾ç½®åœ¨è®ºæ–‡ä¸­å¯èƒ½æœ‰æ‰€æè¿°ï¼Œä½†æ­¤å¤„æœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­æˆåŠŸå­¦ä¹ é•¿æ—¶ç¨‹æ“ä½œç­–ç•¥ï¼Œå¹¶åœ¨ç‰©ç†æœºå™¨äººä¸Šå®ç°äº†æœ‰æ•ˆçš„éƒ¨ç½²ã€‚é€šè¿‡å¯¹æ¯”ä¸åŒçš„VLMä»»åŠ¡è§„åˆ’å™¨å’Œæ¨¡ä»¿å­¦ä¹ ç®—æ³•ï¼Œç¡®å®šäº†æœ€ä½³çš„æ¼”ç¤ºç”Ÿæˆå’Œç­–ç•¥è’¸é¦æµç¨‹ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦æœªçŸ¥ï¼Œä½†è®ºæ–‡å¼ºè°ƒäº†è¯¥æ–¹æ³•åœ¨æ— éœ€äººå·¥æ¼”ç¤ºçš„æƒ…å†µä¸‹ï¼Œå®ç°äº†å¯¹å¤æ‚æ“ä½œä»»åŠ¡çš„æœ‰æ•ˆå­¦ä¹ å’Œæ³›åŒ–ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè‡ªåŠ¨åŒ–è£…é…ã€ç²¾å¯†ä»ªå™¨æ“ä½œã€åŒ»ç–—æœºå™¨äººã€å®¶åº­æœåŠ¡æœºå™¨äººç­‰é¢†åŸŸã€‚é€šè¿‡VLMå¼•å¯¼çš„åŸå­æŠ€èƒ½å­¦ä¹ ï¼Œæœºå™¨äººèƒ½å¤Ÿæ›´çµæ´»ã€å®‰å…¨åœ°å®Œæˆå¤æ‚çš„æ“ä½œä»»åŠ¡ï¼Œé™ä½äº†å¯¹äººå·¥å¹²é¢„çš„ä¾èµ–ï¼Œæé«˜äº†ç”Ÿäº§æ•ˆç‡å’ŒæœåŠ¡è´¨é‡ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›æ¨åŠ¨æœºå™¨äººæ™ºèƒ½åŒ–æ°´å¹³çš„æå‡ï¼Œä½¿å…¶æ›´å¥½åœ°æœåŠ¡äºäººç±»ç¤¾ä¼šã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Autonomous execution of long-horizon, contact-rich manipulation tasks traditionally requires extensive real-world data and expert engineering, posing significant cost and scalability challenges. This paper proposes a novel framework integrating hierarchical semantic decomposition, reinforcement learning (RL), visual language models (VLMs), and knowledge distillation to overcome these limitations. Complex tasks are decomposed into atomic skills, with RL-trained policies for each primitive exclusively in simulation. Crucially, our RL formulation incorporates explicit force constraints to prevent object damage during delicate interactions. VLMs perform high-level task decomposition and skill planning, generating diverse expert demonstrations. These are distilled into a unified policy via Visual-Tactile Diffusion Policy for end-to-end execution. We conduct comprehensive ablation studies exploring different VLM-based task planners to identify optimal demonstration generation pipelines, and systematically compare imitation learning algorithms for skill distillation. Extensive simulation experiments and physical deployment validate that our approach achieves policy learning for long-horizon manipulation without costly human demonstrations, while the VLM-guided atomic skill framework enables scalable generalization to diverse tasks.

