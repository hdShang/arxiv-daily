---
layout: default
title: SpatialActor: Exploring Disentangled Spatial Representations for Robust Robotic Manipulation
---

# SpatialActor: Exploring Disentangled Spatial Representations for Robust Robotic Manipulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.09555" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.09555v1</a>
  <a href="https://arxiv.org/pdf/2511.09555.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.09555v1" onclick="toggleFavorite(this, '2511.09555v1', 'SpatialActor: Exploring Disentangled Spatial Representations for Robust Robotic Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hao Shi, Bin Xie, Yingfei Liu, Yang Yue, Tiancai Wang, Haoqiang Fan, Xiangyu Zhang, Gao Huang

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-12

**å¤‡æ³¨**: AAAI 2026 Oral \| Project Page: https://shihao1895.github.io/SpatialActor

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://shihao1895.github.io/SpatialActor)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**SpatialActorï¼šæ¢ç´¢è§£è€¦ç©ºé—´è¡¨å¾ï¼Œæå‡æœºå™¨äººæ“ä½œçš„é²æ£’æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `æœºå™¨äººæ“ä½œ` `ç©ºé—´è¡¨å¾` `è§£è€¦å­¦ä¹ ` `é²æ£’æ€§` `è¯­ä¹‰åˆ†å‰²` `å‡ ä½•ä¿¡æ¯` `ç©ºé—´å˜æ¢å™¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŸºäºç‚¹äº‘å’Œå›¾åƒçš„æ–¹æ³•åœ¨æœºå™¨äººæ“ä½œä¸­å­˜åœ¨ä¸è¶³ï¼Œå‰è€…é‡‡æ ·ç¨€ç–ï¼Œåè€…æ˜“å—æ·±åº¦å™ªå£°å¹²æ‰°ï¼Œå¿½ç•¥äº†ä½å±‚ç©ºé—´çº¿ç´¢ã€‚
2. SpatialActoré€šè¿‡è§£è€¦è¯­ä¹‰å’Œå‡ ä½•ä¿¡æ¯ï¼Œåˆ©ç”¨è¯­ä¹‰å¼•å¯¼çš„å‡ ä½•æ¨¡å—èåˆå™ªå£°æ·±åº¦å’Œä¸“å®¶å…ˆéªŒï¼Œå¹¶ä½¿ç”¨ç©ºé—´å˜æ¢å™¨æå–ä½å±‚ç©ºé—´çº¿ç´¢ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒSpatialActoråœ¨RLBenchä¸Šè¾¾åˆ°SOTAï¼Œå¹¶åœ¨å™ªå£°ç¯å¢ƒä¸‹æ˜¾è‘—æå‡æ€§èƒ½ï¼ŒåŒæ—¶å¢å¼ºäº†å°‘æ ·æœ¬æ³›åŒ–èƒ½åŠ›å’ŒæŠ—ç©ºé—´æ‰°åŠ¨èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœºå™¨äººæ“ä½œéœ€è¦ç²¾ç¡®çš„ç©ºé—´ç†è§£æ‰èƒ½ä¸ç°å®ä¸–ç•Œä¸­çš„ç‰©ä½“äº¤äº’ã€‚åŸºäºç‚¹çš„æ–¹æ³•å­˜åœ¨ç¨€ç–é‡‡æ ·é—®é¢˜ï¼Œå¯¼è‡´ç»†ç²’åº¦è¯­ä¹‰ä¿¡æ¯çš„ä¸¢å¤±ã€‚åŸºäºå›¾åƒçš„æ–¹æ³•é€šå¸¸å°†RGBå’Œæ·±åº¦ä¿¡æ¯è¾“å…¥åˆ°åœ¨3Dè¾…åŠ©ä»»åŠ¡ä¸Šé¢„è®­ç»ƒçš„2Déª¨å¹²ç½‘ç»œä¸­ï¼Œä½†å®ƒä»¬çº ç¼ çš„è¯­ä¹‰å’Œå‡ ä½•ä¿¡æ¯å¯¹ç°å®ä¸–ç•Œä¸­å›ºæœ‰çš„æ·±åº¦å™ªå£°éå¸¸æ•æ„Ÿï¼Œè¿™ä¼šæ‰°ä¹±è¯­ä¹‰ç†è§£ã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•ä¾§é‡äºé«˜å±‚å‡ ä½•ä¿¡æ¯ï¼Œè€Œå¿½ç•¥äº†å¯¹ç²¾ç¡®äº¤äº’è‡³å…³é‡è¦çš„ä½å±‚ç©ºé—´çº¿ç´¢ã€‚æˆ‘ä»¬æå‡ºäº†SpatialActorï¼Œä¸€ä¸ªç”¨äºé²æ£’æœºå™¨äººæ“ä½œçš„è§£è€¦æ¡†æ¶ï¼Œå®ƒæ˜¾å¼åœ°è§£è€¦äº†è¯­ä¹‰å’Œå‡ ä½•ä¿¡æ¯ã€‚è¯­ä¹‰å¼•å¯¼çš„å‡ ä½•æ¨¡å—è‡ªé€‚åº”åœ°èåˆäº†æ¥è‡ªå™ªå£°æ·±åº¦å’Œè¯­ä¹‰å¼•å¯¼çš„ä¸“å®¶å…ˆéªŒçš„ä¸¤ç§äº’è¡¥å‡ ä½•ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œç©ºé—´å˜æ¢å™¨åˆ©ç”¨ä½å±‚ç©ºé—´çº¿ç´¢è¿›è¡Œç²¾ç¡®çš„2D-3Dæ˜ å°„ï¼Œå¹¶å®ç°ç©ºé—´ç‰¹å¾ä¹‹é—´çš„äº¤äº’ã€‚æˆ‘ä»¬åœ¨50å¤šä¸ªä»»åŠ¡çš„å¤šä¸ªæ¨¡æ‹Ÿå’ŒçœŸå®ä¸–ç•Œåœºæ™¯ä¸­è¯„ä¼°äº†SpatialActorã€‚å®ƒåœ¨RLBenchä¸Šå®ç°äº†87.4%çš„æœ€å…ˆè¿›æ€§èƒ½ï¼Œå¹¶åœ¨ä¸åŒçš„å™ªå£°æ¡ä»¶ä¸‹æé«˜äº†13.9%åˆ°19.4%ï¼Œæ˜¾ç¤ºå‡ºå¼ºå¤§çš„é²æ£’æ€§ã€‚æ­¤å¤–ï¼Œå®ƒæ˜¾è‘—å¢å¼ºäº†å¯¹æ–°ä»»åŠ¡çš„å°‘æ ·æœ¬æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶åœ¨å„ç§ç©ºé—´æ‰°åŠ¨ä¸‹ä¿æŒäº†é²æ£’æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœºå™¨äººæ“ä½œä»»åŠ¡éœ€è¦ç²¾ç¡®çš„ç©ºé—´ç†è§£ï¼Œè€Œç°æœ‰çš„åŸºäºç‚¹äº‘çš„æ–¹æ³•ç”±äºç¨€ç–é‡‡æ ·ä¼šä¸¢å¤±ç»†ç²’åº¦è¯­ä¹‰ä¿¡æ¯ï¼ŒåŸºäºå›¾åƒçš„æ–¹æ³•åˆ™å®¹æ˜“å—åˆ°æ·±åº¦å™ªå£°çš„å½±å“ï¼Œå¹¶ä¸”å¿½ç•¥äº†ä½å±‚ç©ºé—´çº¿ç´¢ï¼Œå¯¼è‡´é²æ£’æ€§ä¸è¶³ã€‚å› æ­¤ï¼Œå¦‚ä½•ä»å™ªå£°æ•°æ®ä¸­æå–é²æ£’çš„ç©ºé—´ä¿¡æ¯ï¼Œå¹¶æœ‰æ•ˆåˆ©ç”¨ä½å±‚ç©ºé—´çº¿ç´¢ï¼Œæ˜¯æœ¬è®ºæ–‡è¦è§£å†³çš„å…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSpatialActorçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†è¯­ä¹‰ä¿¡æ¯å’Œå‡ ä½•ä¿¡æ¯è§£è€¦ï¼Œåˆ†åˆ«è¿›è¡Œå¤„ç†ï¼Œç„¶åé€šè¿‡è¯­ä¹‰å¼•å¯¼çš„å‡ ä½•æ¨¡å—å°†ä¸¤è€…èåˆã€‚åŒæ—¶ï¼Œåˆ©ç”¨ç©ºé—´å˜æ¢å™¨æå–å’Œåˆ©ç”¨ä½å±‚ç©ºé—´çº¿ç´¢ï¼Œä»è€Œæé«˜æœºå™¨äººæ“ä½œçš„é²æ£’æ€§å’Œç²¾åº¦ã€‚è¿™ç§è§£è€¦å’Œèåˆçš„è®¾è®¡èƒ½å¤Ÿæ›´å¥½åœ°åº”å¯¹çœŸå®ä¸–ç•Œä¸­çš„å™ªå£°å’Œä¸ç¡®å®šæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSpatialActorçš„æ•´ä½“æ¶æ„åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) å›¾åƒè¾“å…¥æ¨¡å—ï¼šæ¥æ”¶RGBå›¾åƒå’Œæ·±åº¦å›¾åƒä½œä¸ºè¾“å…¥ã€‚2) è¯­ä¹‰åˆ†å‰²æ¨¡å—ï¼šå¯¹RGBå›¾åƒè¿›è¡Œè¯­ä¹‰åˆ†å‰²ï¼Œæå–è¯­ä¹‰ä¿¡æ¯ã€‚3) è¯­ä¹‰å¼•å¯¼çš„å‡ ä½•æ¨¡å—ï¼šèåˆæ¥è‡ªå™ªå£°æ·±åº¦å›¾åƒå’Œè¯­ä¹‰å¼•å¯¼çš„ä¸“å®¶å…ˆéªŒçš„å‡ ä½•ä¿¡æ¯ã€‚4) ç©ºé—´å˜æ¢å™¨ï¼šåˆ©ç”¨ä½å±‚ç©ºé—´çº¿ç´¢è¿›è¡Œç²¾ç¡®çš„2D-3Dæ˜ å°„ï¼Œå¹¶å®ç°ç©ºé—´ç‰¹å¾ä¹‹é—´çš„äº¤äº’ã€‚5) åŠ¨ä½œé¢„æµ‹æ¨¡å—ï¼šåŸºäºèåˆåçš„ç©ºé—´ç‰¹å¾ï¼Œé¢„æµ‹æœºå™¨äººçš„åŠ¨ä½œã€‚

**å…³é”®åˆ›æ–°**ï¼šSpatialActorçš„å…³é”®åˆ›æ–°åœ¨äºä»¥ä¸‹å‡ ç‚¹ï¼š1) æ˜¾å¼åœ°è§£è€¦äº†è¯­ä¹‰ä¿¡æ¯å’Œå‡ ä½•ä¿¡æ¯ï¼Œé¿å…äº†ä¸¤è€…ä¹‹é—´çš„ç›¸äº’å¹²æ‰°ã€‚2) æå‡ºäº†è¯­ä¹‰å¼•å¯¼çš„å‡ ä½•æ¨¡å—ï¼Œèƒ½å¤Ÿè‡ªé€‚åº”åœ°èåˆæ¥è‡ªå™ªå£°æ·±åº¦å›¾åƒå’Œè¯­ä¹‰å¼•å¯¼çš„ä¸“å®¶å…ˆéªŒçš„å‡ ä½•ä¿¡æ¯ï¼Œæé«˜äº†å‡ ä½•ä¿¡æ¯çš„å‡†ç¡®æ€§ã€‚3) å¼•å…¥äº†ç©ºé—´å˜æ¢å™¨ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨ä½å±‚ç©ºé—´çº¿ç´¢ï¼Œæé«˜äº†æœºå™¨äººæ“ä½œçš„ç²¾åº¦ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒSpatialActoræ›´åŠ å…³æ³¨ä½å±‚ç©ºé—´ä¿¡æ¯çš„åˆ©ç”¨ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ›´å¥½åœ°åº”å¯¹çœŸå®ä¸–ç•Œä¸­çš„å™ªå£°å’Œä¸ç¡®å®šæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è¯­ä¹‰å¼•å¯¼çš„å‡ ä½•æ¨¡å—ä¸­ï¼Œä½¿ç”¨äº†æ³¨æ„åŠ›æœºåˆ¶æ¥èåˆæ¥è‡ªå™ªå£°æ·±åº¦å›¾åƒå’Œè¯­ä¹‰å¼•å¯¼çš„ä¸“å®¶å…ˆéªŒçš„å‡ ä½•ä¿¡æ¯ã€‚ç©ºé—´å˜æ¢å™¨ä½¿ç”¨äº†å¯å­¦ä¹ çš„å˜æ¢å‚æ•°ï¼Œèƒ½å¤Ÿè‡ªé€‚åº”åœ°è¿›è¡Œ2D-3Dæ˜ å°„ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬åŠ¨ä½œé¢„æµ‹æŸå¤±ã€è¯­ä¹‰åˆ†å‰²æŸå¤±å’Œå‡ ä½•é‡å»ºæŸå¤±ï¼Œç”¨äºè®­ç»ƒæ•´ä¸ªç½‘ç»œã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

SpatialActoråœ¨RLBenchä¸Šå–å¾—äº†87.4%çš„SOTAæ€§èƒ½ã€‚åœ¨ä¸åŒå™ªå£°æ¡ä»¶ä¸‹ï¼ŒSpatialActorçš„æ€§èƒ½æå‡äº†13.9%åˆ°19.4%ï¼Œå±•ç¤ºäº†å…¶å¼ºå¤§çš„é²æ£’æ€§ã€‚æ­¤å¤–ï¼ŒSpatialActorè¿˜æ˜¾è‘—å¢å¼ºäº†å¯¹æ–°ä»»åŠ¡çš„å°‘æ ·æœ¬æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶åœ¨å„ç§ç©ºé—´æ‰°åŠ¨ä¸‹ä¿æŒäº†é²æ£’æ€§ã€‚è¿™äº›å®éªŒç»“æœè¡¨æ˜ï¼ŒSpatialActoråœ¨æœºå™¨äººæ“ä½œé¢†åŸŸå…·æœ‰æ˜¾è‘—çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SpatialActoråœ¨æœºå™¨äººæ“ä½œé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚å·¥ä¸šè‡ªåŠ¨åŒ–ã€å®¶åº­æœåŠ¡æœºå™¨äººã€åŒ»ç–—æœºå™¨äººç­‰ã€‚å®ƒå¯ä»¥åº”ç”¨äºå„ç§éœ€è¦ç²¾ç¡®ç©ºé—´ç†è§£å’Œé²æ£’æ€§çš„ä»»åŠ¡ï¼Œä¾‹å¦‚ç‰©ä½“æŠ“å–ã€è£…é…ã€å¯¼èˆªç­‰ã€‚è¯¥ç ”ç©¶çš„æˆæœæœ‰åŠ©äºæé«˜æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„é€‚åº”æ€§å’Œå¯é æ€§ï¼Œæ¨åŠ¨æœºå™¨äººæŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Robotic manipulation requires precise spatial understanding to interact with objects in the real world. Point-based methods suffer from sparse sampling, leading to the loss of fine-grained semantics. Image-based methods typically feed RGB and depth into 2D backbones pre-trained on 3D auxiliary tasks, but their entangled semantics and geometry are sensitive to inherent depth noise in real-world that disrupts semantic understanding. Moreover, these methods focus on high-level geometry while overlooking low-level spatial cues essential for precise interaction. We propose SpatialActor, a disentangled framework for robust robotic manipulation that explicitly decouples semantics and geometry. The Semantic-guided Geometric Module adaptively fuses two complementary geometry from noisy depth and semantic-guided expert priors. Also, a Spatial Transformer leverages low-level spatial cues for accurate 2D-3D mapping and enables interaction among spatial features. We evaluate SpatialActor on multiple simulation and real-world scenarios across 50+ tasks. It achieves state-of-the-art performance with 87.4% on RLBench and improves by 13.9% to 19.4% under varying noisy conditions, showing strong robustness. Moreover, it significantly enhances few-shot generalization to new tasks and maintains robustness under various spatial perturbations. Project Page: https://shihao1895.github.io/SpatialActor

