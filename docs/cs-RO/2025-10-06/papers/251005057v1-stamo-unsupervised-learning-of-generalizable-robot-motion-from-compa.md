---
layout: default
title: StaMo: Unsupervised Learning of Generalizable Robot Motion from Compact State Representation
---

# StaMo: Unsupervised Learning of Generalizable Robot Motion from Compact State Representation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.05057" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.05057v1</a>
  <a href="https://arxiv.org/pdf/2510.05057.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.05057v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.05057v1', 'StaMo: Unsupervised Learning of Generalizable Robot Motion from Compact State Representation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mingyu Liu, Jiuhe Shu, Hui Chen, Zeju Li, Canyu Zhao, Jiange Yang, Shenyuan Gao, Hao Chen, Chunhua Shen

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-06

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**StaMoï¼šåŸºäºç´§å‡‘çŠ¶æ€è¡¨å¾æ— ç›‘ç£å­¦ä¹ é€šç”¨æœºå™¨äººè¿åŠ¨**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æœºå™¨äººè¿åŠ¨å­¦ä¹ ` `çŠ¶æ€è¡¨å¾` `æ— ç›‘ç£å­¦ä¹ ` `æ‰©æ•£Transformer` `æ½œåœ¨åŠ¨ä½œ` `å…·èº«æ™ºèƒ½` `ç­–ç•¥ååŒè®­ç»ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æœºå™¨äººå­¦ä¹ æ–¹æ³•éš¾ä»¥åœ¨çŠ¶æ€è¡¨å¾çš„è¡¨è¾¾æ€§å’Œç´§å‡‘æ€§ä¹‹é—´å–å¾—å¹³è¡¡ï¼Œé™åˆ¶äº†ä¸–ç•Œå»ºæ¨¡å’Œå†³ç­–æ•ˆç‡ã€‚
2. StaMoåˆ©ç”¨è½»é‡çº§ç¼–ç å™¨å’Œé¢„è®­ç»ƒçš„æ‰©æ•£Transformerï¼Œå­¦ä¹ é«˜åº¦å‹ç¼©çš„åŒtokençŠ¶æ€è¡¨å¾ï¼Œå¹¶ä»ä¸­æå–æ½œåœ¨åŠ¨ä½œã€‚
3. å®éªŒè¡¨æ˜ï¼ŒStaMoåœ¨LIBEROå’ŒçœŸå®ä¸–ç•Œä»»åŠ¡ä¸­æ˜¾è‘—æå‡æ€§èƒ½ï¼Œå¹¶èƒ½æœ‰æ•ˆæ‰©å±•åˆ°ä¸åŒæ•°æ®æºã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å…·èº«æ™ºèƒ½çš„ä¸€ä¸ªæ ¹æœ¬æŒ‘æˆ˜æ˜¯å¼€å‘å¯Œæœ‰è¡¨ç°åŠ›ä¸”ç´§å‡‘çš„çŠ¶æ€è¡¨å¾ï¼Œä»¥å®ç°é«˜æ•ˆçš„ä¸–ç•Œå»ºæ¨¡å’Œå†³ç­–ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•é€šå¸¸æ— æ³•å®ç°è¿™ç§å¹³è¡¡ï¼Œå¯¼è‡´è¡¨å¾è¦ä¹ˆè¿‡äºå†—ä½™ï¼Œè¦ä¹ˆç¼ºä¹ä»»åŠ¡å…³é”®ä¿¡æ¯ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ— ç›‘ç£æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä½¿ç”¨è½»é‡çº§ç¼–ç å™¨å’Œé¢„è®­ç»ƒçš„æ‰©æ•£Transformer (DiT) è§£ç å™¨å­¦ä¹ é«˜åº¦å‹ç¼©çš„åŒtokençŠ¶æ€è¡¨å¾ï¼Œåˆ©ç”¨å…¶å¼ºå¤§çš„ç”Ÿæˆå…ˆéªŒã€‚æˆ‘ä»¬çš„è¡¨å¾æ˜¯é«˜æ•ˆçš„ã€å¯è§£é‡Šçš„ï¼Œå¹¶ä¸”å¯ä»¥æ— ç¼é›†æˆåˆ°ç°æœ‰çš„åŸºäºVLAçš„æ¨¡å‹ä¸­ï¼Œåœ¨LIBEROä¸Šæé«˜äº†14.3%çš„æ€§èƒ½ï¼Œåœ¨çœŸå®ä¸–ç•Œä»»åŠ¡æˆåŠŸç‡ä¸Šæé«˜äº†30%ï¼Œä¸”æ¨ç†å¼€é”€æœ€å°ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬å‘ç°è¿™äº›tokenä¹‹é—´çš„å·®å¼‚ï¼Œé€šè¿‡æ½œåœ¨æ’å€¼è·å¾—ï¼Œè‡ªç„¶åœ°å……å½“äº†ä¸€ç§é«˜æ•ˆçš„æ½œåœ¨åŠ¨ä½œï¼Œå¯ä»¥è¿›ä¸€æ­¥è§£ç ä¸ºå¯æ‰§è¡Œçš„æœºå™¨äººåŠ¨ä½œã€‚è¿™ç§æ¶Œç°çš„èƒ½åŠ›è¡¨æ˜ï¼Œæˆ‘ä»¬çš„è¡¨å¾åœ¨æ²¡æœ‰æ˜¾å¼ç›‘ç£çš„æƒ…å†µä¸‹æ•è·äº†ç»“æ„åŒ–çš„åŠ¨åŠ›å­¦ã€‚æˆ‘ä»¬å°†æˆ‘ä»¬çš„æ–¹æ³•å‘½åä¸ºStaMoï¼Œå› ä¸ºå®ƒèƒ½å¤Ÿä»é™æ€å›¾åƒç¼–ç çš„ç´§å‡‘çŠ¶æ€è¡¨å¾ä¸­å­¦ä¹ é€šç”¨çš„æœºå™¨äººè¿åŠ¨ï¼ŒæŒ‘æˆ˜äº†å¯¹å¤æ‚æ¶æ„å’Œè§†é¢‘æ•°æ®å­¦ä¹ æ½œåœ¨åŠ¨ä½œçš„æ™®éä¾èµ–ã€‚ç”±æ­¤äº§ç”Ÿçš„æ½œåœ¨åŠ¨ä½œä¹Ÿå¢å¼ºäº†ç­–ç•¥ååŒè®­ç»ƒï¼Œä¼˜äºå…ˆå‰çš„æ–¹æ³•10.4%ï¼Œå¹¶æé«˜äº†å¯è§£é‡Šæ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°æ‰©å±•åˆ°ä¸åŒçš„æ•°æ®æºï¼ŒåŒ…æ‹¬çœŸå®ä¸–ç•Œçš„æœºå™¨äººæ•°æ®ã€æ¨¡æ‹Ÿå’Œäººç±»è‡ªæˆ‘ä¸­å¿ƒè§†é¢‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æœºå™¨äººå­¦ä¹ æ–¹æ³•åœ¨çŠ¶æ€è¡¨å¾æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œè¦ä¹ˆè¿‡äºå†—ä½™ï¼Œè¦ä¹ˆç¼ºä¹å…³é”®ä¿¡æ¯ï¼Œéš¾ä»¥å®ç°é«˜æ•ˆçš„ä¸–ç•Œå»ºæ¨¡å’Œå†³ç­–ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–å¤æ‚æ¶æ„å’Œè§†é¢‘æ•°æ®å­¦ä¹ æ½œåœ¨åŠ¨ä½œï¼Œè®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œæ³›åŒ–èƒ½åŠ›æœ‰é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šStaMoçš„æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£Transformer (DiT) çš„å¼ºå¤§ç”Ÿæˆå…ˆéªŒï¼Œå­¦ä¹ ä¸€ç§é«˜åº¦å‹ç¼©çš„åŒtokençŠ¶æ€è¡¨å¾ã€‚é€šè¿‡å¯¹è¿™ä¸¤ä¸ªtokenè¿›è¡Œæ½œåœ¨æ’å€¼ï¼Œæå–å‡ºæ½œåœ¨åŠ¨ä½œï¼Œä»è€Œåœ¨æ²¡æœ‰æ˜¾å¼ç›‘ç£çš„æƒ…å†µä¸‹æ•è·ç»“æ„åŒ–çš„åŠ¨åŠ›å­¦ã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨ä»é™æ€å›¾åƒä¸­å­¦ä¹ é€šç”¨çš„æœºå™¨äººè¿åŠ¨ï¼Œé™ä½å¯¹å¤æ‚æ¶æ„å’Œè§†é¢‘æ•°æ®çš„ä¾èµ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šStaMoåŒ…å«ä¸€ä¸ªè½»é‡çº§ç¼–ç å™¨å’Œä¸€ä¸ªé¢„è®­ç»ƒçš„æ‰©æ•£Transformer (DiT) è§£ç å™¨ã€‚ç¼–ç å™¨å°†é™æ€å›¾åƒç¼–ç ä¸ºä¸¤ä¸ªtokençš„çŠ¶æ€è¡¨å¾ã€‚ç„¶åï¼Œé€šè¿‡å¯¹è¿™ä¸¤ä¸ªtokenè¿›è¡Œæ½œåœ¨æ’å€¼ï¼Œå¾—åˆ°æ½œåœ¨åŠ¨ä½œã€‚æœ€åï¼Œè§£ç å™¨å°†æ½œåœ¨åŠ¨ä½œè§£ç ä¸ºå¯æ‰§è¡Œçš„æœºå™¨äººåŠ¨ä½œã€‚æ•´ä¸ªæ¡†æ¶æ˜¯æ— ç›‘ç£å­¦ä¹ çš„ï¼Œä¸éœ€è¦æ˜¾å¼çš„åŠ¨ä½œæ ‡ç­¾ã€‚

**å…³é”®åˆ›æ–°**ï¼šStaMoçš„å…³é”®åˆ›æ–°åœ¨äºå…¶åŒtokençŠ¶æ€è¡¨å¾å’Œæ½œåœ¨åŠ¨ä½œæå–æ–¹æ³•ã€‚é€šè¿‡å­¦ä¹ ä¸¤ä¸ªtokençš„å·®å¼‚ï¼ŒStaMoèƒ½å¤Ÿæ•è·çŠ¶æ€ä¹‹é—´çš„åŠ¨æ€å˜åŒ–ï¼Œä»è€Œæå–å‡ºæœ‰æ•ˆçš„æ½œåœ¨åŠ¨ä½œã€‚è¿™ç§æ–¹æ³•é¿å…äº†å¯¹å¤æ‚æ¶æ„å’Œè§†é¢‘æ•°æ®çš„ä¾èµ–ï¼Œé™ä½äº†è®¡ç®—æˆæœ¬ï¼Œæé«˜äº†æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£Transformer (DiT) çš„å¼ºå¤§ç”Ÿæˆå…ˆéªŒä¹Ÿæ˜¯ä¸€ä¸ªé‡è¦çš„åˆ›æ–°ç‚¹ã€‚

**å…³é”®è®¾è®¡**ï¼šStaMoçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) è½»é‡çº§ç¼–ç å™¨çš„é€‰æ‹©ï¼Œä»¥ä¿è¯è®¡ç®—æ•ˆç‡ï¼›2) é¢„è®­ç»ƒçš„æ‰©æ•£Transformer (DiT) çš„ä½¿ç”¨ï¼Œä»¥æä¾›å¼ºå¤§çš„ç”Ÿæˆå…ˆéªŒï¼›3) åŒtokençŠ¶æ€è¡¨å¾çš„è®¾è®¡ï¼Œä»¥ä¾¿æå–æ½œåœ¨åŠ¨ä½œï¼›4) æ½œåœ¨æ’å€¼æ–¹æ³•çš„é€‰æ‹©ï¼Œä»¥ä¿è¯æ½œåœ¨åŠ¨ä½œçš„æœ‰æ•ˆæ€§ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ï¼ˆæœªçŸ¥ï¼‰ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡ç›®æ ‡æ˜¯æœ€å°åŒ–é‡æ„è¯¯å·®ï¼Œå¹¶é¼“åŠ±å­¦ä¹ åˆ°çš„çŠ¶æ€è¡¨å¾å…·æœ‰è‰¯å¥½çš„å¯è§£é‡Šæ€§å’Œæ³›åŒ–èƒ½åŠ›ï¼ˆæœªçŸ¥ï¼‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

StaMoåœ¨LIBEROæ•°æ®é›†ä¸Šæ€§èƒ½æå‡14.3%ï¼Œåœ¨çœŸå®ä¸–ç•Œä»»åŠ¡æˆåŠŸç‡ä¸Šæå‡30%ï¼Œä¸”æ¨ç†å¼€é”€æå°ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒStaMoåœ¨ç­–ç•¥ååŒè®­ç»ƒä¸­æ€§èƒ½æå‡10.4%ï¼Œå¹¶æé«˜äº†å¯è§£é‡Šæ€§ã€‚æ­¤å¤–ï¼ŒStaMoèƒ½å¤Ÿæœ‰æ•ˆæ‰©å±•åˆ°ä¸åŒçš„æ•°æ®æºï¼ŒåŒ…æ‹¬çœŸå®ä¸–ç•Œçš„æœºå™¨äººæ•°æ®ã€æ¨¡æ‹Ÿå’Œäººç±»è‡ªæˆ‘ä¸­å¿ƒè§†é¢‘ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

StaMoå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯ç”¨äºæœºå™¨äººæ§åˆ¶ã€è‡ªåŠ¨é©¾é©¶ã€æ¸¸æˆAIç­‰é¢†åŸŸã€‚é€šè¿‡å­¦ä¹ é€šç”¨çš„æœºå™¨äººè¿åŠ¨ï¼ŒStaMoå¯ä»¥å¸®åŠ©æœºå™¨äººæ›´å¥½åœ°ç†è§£ç¯å¢ƒï¼Œåšå‡ºæ›´åˆç†çš„å†³ç­–ã€‚æ­¤å¤–ï¼ŒStaMoè¿˜å¯ä»¥ç”¨äºç”Ÿæˆé€¼çœŸçš„æœºå™¨äººåŠ¨ç”»ï¼Œæé«˜ç”¨æˆ·ä½“éªŒã€‚æœªæ¥ï¼ŒStaMoæœ‰æœ›æˆä¸ºå…·èº«æ™ºèƒ½é¢†åŸŸçš„é‡è¦æŠ€æœ¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> A fundamental challenge in embodied intelligence is developing expressive and compact state representations for efficient world modeling and decision making. However, existing methods often fail to achieve this balance, yielding representations that are either overly redundant or lacking in task-critical information. We propose an unsupervised approach that learns a highly compressed two-token state representation using a lightweight encoder and a pre-trained Diffusion Transformer (DiT) decoder, capitalizing on its strong generative prior. Our representation is efficient, interpretable, and integrates seamlessly into existing VLA-based models, improving performance by 14.3% on LIBERO and 30% in real-world task success with minimal inference overhead. More importantly, we find that the difference between these tokens, obtained via latent interpolation, naturally serves as a highly effective latent action, which can be further decoded into executable robot actions. This emergent capability reveals that our representation captures structured dynamics without explicit supervision. We name our method StaMo for its ability to learn generalizable robotic Motion from compact State representation, which is encoded from static images, challenging the prevalent dependence to learning latent action on complex architectures and video data. The resulting latent actions also enhance policy co-training, outperforming prior methods by 10.4% with improved interpretability. Moreover, our approach scales effectively across diverse data sources, including real-world robot data, simulation, and human egocentric video.

