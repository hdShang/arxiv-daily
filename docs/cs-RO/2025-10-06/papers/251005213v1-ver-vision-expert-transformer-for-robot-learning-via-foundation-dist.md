---
layout: default
title: VER: Vision Expert Transformer for Robot Learning via Foundation Distillation and Dynamic Routing
---

# VER: Vision Expert Transformer for Robot Learning via Foundation Distillation and Dynamic Routing

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.05213" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.05213v1</a>
  <a href="https://arxiv.org/pdf/2510.05213.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.05213v1" onclick="toggleFavorite(this, '2510.05213v1', 'VER: Vision Expert Transformer for Robot Learning via Foundation Distillation and Dynamic Routing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yixiao Wang, Mingxiao Huo, Zhixuan Liang, Yushi Du, Lingfeng Sun, Haotian Lin, Jinghuan Shang, Chensheng Peng, Mohit Bansal, Mingyu Ding, Masayoshi Tomizuka

**åˆ†ç±»**: cs.RO, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-10-06

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://yixiaowang7.github.io/ver_page/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVERï¼Œé€šè¿‡ä¸“å®¶è’¸é¦å’ŒåŠ¨æ€è·¯ç”±å®ç°æœºå™¨äººå­¦ä¹ çš„è§†è§‰çŸ¥è¯†è¿ç§»ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æœºå™¨äººå­¦ä¹ ` `è§†è§‰åŸºç¡€æ¨¡å‹` `çŸ¥è¯†è’¸é¦` `åŠ¨æ€è·¯ç”±` `Transformer` `ä¸“å®¶ç³»ç»Ÿ` `å‚æ•°é«˜æ•ˆå¾®è°ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰åŸºç¡€æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸè¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨è·¨ä»»åŠ¡æ³›åŒ–æ€§æ–¹é¢å­˜åœ¨å±€é™æ€§ï¼Œç›´æ¥è’¸é¦å¤šä¸ªVFMä¼šé€ æˆä»»åŠ¡ç‰¹å¾é€‰æ‹©ä¸çµæ´»ã€‚
2. VERé€šè¿‡é¢„è®­ç»ƒå°†å¤šä¸ªVFMè’¸é¦æˆä¸“å®¶åº“ï¼Œå¹¶ä½¿ç”¨è½»é‡çº§è·¯ç”±ç½‘ç»œåŠ¨æ€é€‰æ‹©ä»»åŠ¡ç›¸å…³çš„ä¸“å®¶ï¼Œé¿å…äº†å®Œå…¨é‡æ–°è®­ç»ƒçš„æˆæœ¬ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒVERåœ¨17ä¸ªæœºå™¨äººä»»åŠ¡ä¸Šå–å¾—äº†SOTAæ€§èƒ½ï¼Œå¹¶èƒ½æœ‰æ•ˆå‡å°‘ä»»åŠ¡æ— å…³åŒºåŸŸçš„å¹²æ‰°ï¼Œèšç„¦å…³é”®åŒºåŸŸã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äºæœºå™¨äººå­¦ä¹ çš„è§†è§‰ä¸“å®¶Transformerï¼ˆVERï¼‰ã€‚VERé€šè¿‡è’¸é¦å¤šä¸ªè§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆVFMsï¼‰åˆ°ä¸€ä¸ªè§†è§‰ä¸“å®¶åº“ä¸­ï¼Œä»è€Œåˆ©ç”¨ä¸°å¯Œçš„è§†è§‰è¡¨å¾æ¥æå‡æœºå™¨äººå­¦ä¹ ã€‚ä¸ºäº†é€‚åº”ä¸åŒçš„æœºå™¨äººä»»åŠ¡ï¼ŒVERä»…éœ€å¾®è°ƒä¸€ä¸ªè½»é‡çº§çš„è·¯ç”±ç½‘ç»œï¼ˆå‚æ•°é‡å°äº0.4%ï¼‰ï¼Œå³å¯ä»é¢„è®­ç»ƒçš„ä¸“å®¶åº“ä¸­åŠ¨æ€é€‰æ‹©ä»»åŠ¡ç›¸å…³çš„ä¸“å®¶ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜å¼•å…¥äº†å¸¦æœ‰è¯¾ç¨‹Top-Ké€€ç«çš„Patchwiseä¸“å®¶è·¯ç”±ï¼Œä»¥æé«˜åŠ¨æ€ä¸“å®¶é€‰æ‹©çš„çµæ´»æ€§å’Œç²¾ç¡®æ€§ã€‚VERè¿˜æ”¯æŒå‚æ•°é«˜æ•ˆçš„å¾®è°ƒï¼Œä»è€Œå®ç°ä¸“å®¶åˆ©ç”¨ç‡çš„å¯æ‰©å±•æ€§å’Œè‡ªé€‚åº”çš„æœºå™¨äººé¢†åŸŸçŸ¥è¯†é›†æˆã€‚åœ¨17ä¸ªä¸åŒçš„æœºå™¨äººä»»åŠ¡å’Œå¤šä¸ªç­–ç•¥å¤´ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒVERå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒVERå‡å°‘äº†ä»»åŠ¡æ— å…³åŒºåŸŸï¼ˆä¾‹å¦‚èƒŒæ™¯ï¼‰ä¸­çš„å¤§èŒƒæ•°å¼‚å¸¸å€¼ï¼Œå¹¶é›†ä¸­äºä»»åŠ¡å…³é”®åŒºåŸŸã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æ–¹æ³•åœ¨å°†å¤šä¸ªè§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆVFMsï¼‰åº”ç”¨äºæœºå™¨äººå­¦ä¹ æ—¶ï¼Œå­˜åœ¨ä¸¤ä¸ªä¸»è¦é—®é¢˜ã€‚ä¸€æ˜¯å•ä¸ªVFMé€šå¸¸åªæ“…é•¿ç‰¹å®šé¢†åŸŸï¼Œé™åˆ¶äº†å…¶åœ¨ä¸åŒä»»åŠ¡ä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚äºŒæ˜¯ç›´æ¥å°†å¤šä¸ªVFMè’¸é¦æˆç»Ÿä¸€çš„ç­–ç•¥è¡¨ç¤ºï¼Œä¼šå¯¼è‡´ä»»åŠ¡ç‰¹å®šçš„ç‰¹å¾é€‰æ‹©ä¸å¤Ÿçµæ´»ï¼Œå¹¶ä¸”éœ€è¦æ˜‚è´µçš„å®Œå…¨é‡æ–°è®­ç»ƒæ‰èƒ½æ•´åˆæœºå™¨äººé¢†åŸŸçš„çŸ¥è¯†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šVERçš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªè§†è§‰ä¸“å®¶åº“ï¼Œå…¶ä¸­æ¯ä¸ªä¸“å®¶éƒ½ä»ä¸åŒçš„VFMä¸­å­¦ä¹ åˆ°ç‰¹å®šçš„è§†è§‰çŸ¥è¯†ã€‚ç„¶åï¼Œé€šè¿‡ä¸€ä¸ªè½»é‡çº§çš„è·¯ç”±ç½‘ç»œï¼Œæ ¹æ®å½“å‰çš„ä»»åŠ¡åŠ¨æ€åœ°é€‰æ‹©åˆé€‚çš„ä¸“å®¶ç»„åˆã€‚è¿™ç§æ–¹æ³•æ—¢èƒ½åˆ©ç”¨å¤šä¸ªVFMçš„ä¼˜åŠ¿ï¼Œåˆèƒ½é¿å…å®Œå…¨é‡æ–°è®­ç»ƒçš„æˆæœ¬ï¼ŒåŒæ—¶è¿˜èƒ½å®ç°ä»»åŠ¡ç‰¹å®šçš„ç‰¹å¾é€‰æ‹©ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVERçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼š1) é¢„è®­ç»ƒé˜¶æ®µï¼šå°†å¤šä¸ªVFMè’¸é¦åˆ°ä¸€ä¸ªè§†è§‰ä¸“å®¶åº“ä¸­ã€‚æ¯ä¸ªä¸“å®¶éƒ½æ˜¯ä¸€ä¸ªTransformeræ¨¡å—ï¼Œè´Ÿè´£å¤„ç†å›¾åƒçš„ä¸åŒéƒ¨åˆ†æˆ–å­¦ä¹ ä¸åŒçš„è§†è§‰ç‰¹å¾ã€‚2) è·¯ç”±ç½‘ç»œè®­ç»ƒé˜¶æ®µï¼šè®­ç»ƒä¸€ä¸ªè½»é‡çº§çš„è·¯ç”±ç½‘ç»œï¼Œç”¨äºæ ¹æ®å½“å‰çš„ä»»åŠ¡åŠ¨æ€åœ°é€‰æ‹©åˆé€‚çš„ä¸“å®¶ç»„åˆã€‚è·¯ç”±ç½‘ç»œæ¥æ”¶å›¾åƒç‰¹å¾ä½œä¸ºè¾“å…¥ï¼Œè¾“å‡ºæ¯ä¸ªä¸“å®¶çš„æƒé‡ã€‚3) å¾®è°ƒé˜¶æ®µï¼šä½¿ç”¨æœºå™¨äººé¢†åŸŸçš„æ•°æ®å¯¹è·¯ç”±ç½‘ç»œè¿›è¡Œå¾®è°ƒï¼Œä»¥é€‚åº”ç‰¹å®šçš„æœºå™¨äººä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šVERçš„å…³é”®åˆ›æ–°åœ¨äºåŠ¨æ€ä¸“å®¶è·¯ç”±æœºåˆ¶å’ŒPatchwiseä¸“å®¶è·¯ç”±ä¸è¯¾ç¨‹Top-Ké€€ç«ç­–ç•¥ã€‚åŠ¨æ€ä¸“å®¶è·¯ç”±å…è®¸æ¨¡å‹æ ¹æ®ä»»åŠ¡éœ€æ±‚è‡ªé€‚åº”åœ°é€‰æ‹©åˆé€‚çš„ä¸“å®¶ï¼Œä»è€Œæé«˜äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚Patchwiseä¸“å®¶è·¯ç”±å…è®¸æ¨¡å‹åœ¨å›¾åƒçš„ä¸åŒåŒºåŸŸä½¿ç”¨ä¸åŒçš„ä¸“å®¶ï¼Œä»è€Œæé«˜äº†æ¨¡å‹çš„çµæ´»æ€§ã€‚è¯¾ç¨‹Top-Ké€€ç«ç­–ç•¥åˆ™åœ¨è®­ç»ƒåˆæœŸé¼“åŠ±æ¢ç´¢æ›´å¤šçš„ä¸“å®¶ç»„åˆï¼Œåœ¨è®­ç»ƒåæœŸåˆ™ä¸“æ³¨äºé€‰æ‹©æœ€ç›¸å…³çš„ä¸“å®¶ï¼Œä»è€Œæé«˜äº†æ¨¡å‹çš„è®­ç»ƒæ•ˆç‡å’Œæ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šVERä½¿ç”¨Transformerä½œä¸ºå…¶ä¸»è¦æ¶æ„ï¼Œå¹¶é‡‡ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°æ¥è®­ç»ƒè·¯ç”±ç½‘ç»œã€‚Patchwiseä¸“å®¶è·¯ç”±å°†å›¾åƒåˆ’åˆ†ä¸ºå¤šä¸ªpatchï¼Œå¹¶ä¸ºæ¯ä¸ªpatchåˆ†é…ä¸åŒçš„ä¸“å®¶ç»„åˆã€‚è¯¾ç¨‹Top-Ké€€ç«ç­–ç•¥é€šè¿‡é€æ¸å‡å°Top-Kçš„å€¼ï¼Œæ¥æ§åˆ¶ä¸“å®¶é€‰æ‹©çš„èŒƒå›´ã€‚è·¯ç”±ç½‘ç»œçš„å‚æ•°é‡è¢«æ§åˆ¶åœ¨æ€»å‚æ•°é‡çš„0.4%ä»¥ä¸‹ï¼Œä»¥ä¿è¯å…¶è½»é‡çº§å’Œé«˜æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

VERåœ¨17ä¸ªä¸åŒçš„æœºå™¨äººä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰çš„æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨æŸäº›ä»»åŠ¡ä¸Šï¼ŒVERçš„æ€§èƒ½æå‡è¶…è¿‡äº†10%ã€‚å®éªŒç»“æœè¿˜è¡¨æ˜ï¼ŒVERèƒ½å¤Ÿæœ‰æ•ˆåœ°å‡å°‘ä»»åŠ¡æ— å…³åŒºåŸŸçš„å¹²æ‰°ï¼Œå¹¶é›†ä¸­äºä»»åŠ¡å…³é”®åŒºåŸŸï¼Œä»è€Œæé«˜äº†æ¨¡å‹çš„é²æ£’æ€§å’Œå¯é æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

VERå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯åº”ç”¨äºå„ç§æœºå™¨äººå­¦ä¹ ä»»åŠ¡ï¼Œä¾‹å¦‚ç‰©ä½“æŠ“å–ã€å¯¼èˆªã€æ“ä½œç­‰ã€‚é€šè¿‡åˆ©ç”¨é¢„è®­ç»ƒçš„è§†è§‰çŸ¥è¯†ï¼ŒVERå¯ä»¥æ˜¾è‘—æé«˜æœºå™¨äººçš„å­¦ä¹ æ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒVERè¿˜å¯ä»¥åº”ç”¨äºå…¶ä»–éœ€è¦è§†è§‰çŸ¥è¯†è¿ç§»çš„é¢†åŸŸï¼Œä¾‹å¦‚è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½ç›‘æ§ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Pretrained vision foundation models (VFMs) advance robotic learning via rich visual representations, yet individual VFMs typically excel only in specific domains, limiting generality across tasks. Distilling multiple VFMs into a unified representation for policy can mitigate this limitation but often yields inflexible task-specific feature selection and requires costly full re-training to incorporate robot-domain knowledge. We propose VER, a Vision Expert transformer for Robot learning. During pretraining, VER distills multiple VFMs into a vision expert library. It then fine-tunes only a lightweight routing network (fewer than 0.4% of parameters) to dynamically select task-relevant experts from the pretrained library for downstream robot tasks. We further introduce Patchwise Expert Routing with Curriculum Top-K Annealing to improve both flexibility and precision of dynamic expert selection. Moreover, VER supports parameter-efficient finetuning for scalable expert utilization and adaptive robot-domain knowledge integration. Across 17 diverse robotic tasks and multiple policy heads, VER achieves state-of-the-art performance. We find that VER reduces large-norm outliers in task-irrelevant regions (e.g., background) and concentrates on task-critical regions. Visualizations and codes can be found in https://yixiaowang7.github.io/ver_page/.

