---
layout: default
title: VER: Vision Expert Transformer for Robot Learning via Foundation Distillation and Dynamic Routing
---

# VER: Vision Expert Transformer for Robot Learning via Foundation Distillation and Dynamic Routing

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.05213" target="_blank" class="toolbar-btn">arXiv: 2510.05213v1</a>
    <a href="https://arxiv.org/pdf/2510.05213.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.05213v1" 
            onclick="toggleFavorite(this, '2510.05213v1', 'VER: Vision Expert Transformer for Robot Learning via Foundation Distillation and Dynamic Routing')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yixiao Wang, Mingxiao Huo, Zhixuan Liang, Yushi Du, Lingfeng Sun, Haotian Lin, Jinghuan Shang, Chensheng Peng, Mohit Bansal, Mingyu Ding, Masayoshi Tomizuka

**ÂàÜÁ±ª**: cs.RO, cs.AI, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-06

**üîó ‰ª£Á†Å/È°πÁõÆ**: [PROJECT_PAGE](https://yixiaowang7.github.io/ver_page/)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫VERÔºåÈÄöËøá‰∏ìÂÆ∂Ëí∏È¶èÂíåÂä®ÊÄÅË∑ØÁî±ÂÆûÁé∞Êú∫Âô®‰∫∫Â≠¶‰π†ÁöÑËßÜËßâÁü•ËØÜËøÅÁßª„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Êú∫Âô®‰∫∫Â≠¶‰π†` `ËßÜËßâÂü∫Á°ÄÊ®°Âûã` `Áü•ËØÜËí∏È¶è` `Âä®ÊÄÅË∑ØÁî±` `Transformer` `‰∏ìÂÆ∂Á≥ªÁªü` `ÂèÇÊï∞È´òÊïàÂæÆË∞É`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËßÜËßâÂü∫Á°ÄÊ®°ÂûãÂú®ÁâπÂÆöÈ¢ÜÂüüË°®Áé∞Âá∫Ëâ≤Ôºå‰ΩÜÂú®Ë∑®‰ªªÂä°Ê≥õÂåñÊÄßÊñπÈù¢Â≠òÂú®Â±ÄÈôêÊÄßÔºåÁõ¥Êé•Ëí∏È¶èÂ§ö‰∏™VFM‰ºöÈÄ†Êàê‰ªªÂä°ÁâπÂæÅÈÄâÊã©‰∏çÁÅµÊ¥ª„ÄÇ
2. VERÈÄöËøáÈ¢ÑËÆ≠ÁªÉÂ∞ÜÂ§ö‰∏™VFMËí∏È¶èÊàê‰∏ìÂÆ∂Â∫ìÔºåÂπ∂‰ΩøÁî®ËΩªÈáèÁ∫ßË∑ØÁî±ÁΩëÁªúÂä®ÊÄÅÈÄâÊã©‰ªªÂä°Áõ∏ÂÖ≥ÁöÑ‰∏ìÂÆ∂ÔºåÈÅøÂÖç‰∫ÜÂÆåÂÖ®ÈáçÊñ∞ËÆ≠ÁªÉÁöÑÊàêÊú¨„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåVERÂú®17‰∏™Êú∫Âô®‰∫∫‰ªªÂä°‰∏äÂèñÂæó‰∫ÜSOTAÊÄßËÉΩÔºåÂπ∂ËÉΩÊúâÊïàÂáèÂ∞ë‰ªªÂä°Êó†ÂÖ≥Âå∫ÂüüÁöÑÂπ≤Êâ∞ÔºåËÅöÁÑ¶ÂÖ≥ÈîÆÂå∫Âüü„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÁî®‰∫éÊú∫Âô®‰∫∫Â≠¶‰π†ÁöÑËßÜËßâ‰∏ìÂÆ∂TransformerÔºàVERÔºâ„ÄÇVERÈÄöËøáËí∏È¶èÂ§ö‰∏™ËßÜËßâÂü∫Á°ÄÊ®°ÂûãÔºàVFMsÔºâÂà∞‰∏Ä‰∏™ËßÜËßâ‰∏ìÂÆ∂Â∫ì‰∏≠Ôºå‰ªéËÄåÂà©Áî®‰∏∞ÂØåÁöÑËßÜËßâË°®ÂæÅÊù•ÊèêÂçáÊú∫Âô®‰∫∫Â≠¶‰π†„ÄÇ‰∏∫‰∫ÜÈÄÇÂ∫î‰∏çÂêåÁöÑÊú∫Âô®‰∫∫‰ªªÂä°ÔºåVER‰ªÖÈúÄÂæÆË∞É‰∏Ä‰∏™ËΩªÈáèÁ∫ßÁöÑË∑ØÁî±ÁΩëÁªúÔºàÂèÇÊï∞ÈáèÂ∞è‰∫é0.4%ÔºâÔºåÂç≥ÂèØ‰ªéÈ¢ÑËÆ≠ÁªÉÁöÑ‰∏ìÂÆ∂Â∫ì‰∏≠Âä®ÊÄÅÈÄâÊã©‰ªªÂä°Áõ∏ÂÖ≥ÁöÑ‰∏ìÂÆ∂„ÄÇÊ≠§Â§ñÔºåÊú¨ÊñáËøòÂºïÂÖ•‰∫ÜÂ∏¶ÊúâËØæÁ®ãTop-KÈÄÄÁÅ´ÁöÑPatchwise‰∏ìÂÆ∂Ë∑ØÁî±Ôºå‰ª•ÊèêÈ´òÂä®ÊÄÅ‰∏ìÂÆ∂ÈÄâÊã©ÁöÑÁÅµÊ¥ªÊÄßÂíåÁ≤æÁ°ÆÊÄß„ÄÇVERËøòÊîØÊåÅÂèÇÊï∞È´òÊïàÁöÑÂæÆË∞ÉÔºå‰ªéËÄåÂÆûÁé∞‰∏ìÂÆ∂Âà©Áî®ÁéáÁöÑÂèØÊâ©Â±ïÊÄßÂíåËá™ÈÄÇÂ∫îÁöÑÊú∫Âô®‰∫∫È¢ÜÂüüÁü•ËØÜÈõÜÊàê„ÄÇÂú®17‰∏™‰∏çÂêåÁöÑÊú∫Âô®‰∫∫‰ªªÂä°ÂíåÂ§ö‰∏™Á≠ñÁï•Â§¥‰∏äÁöÑÂÆûÈ™åË°®ÊòéÔºåVERÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåVERÂáèÂ∞ë‰∫Ü‰ªªÂä°Êó†ÂÖ≥Âå∫ÂüüÔºà‰æãÂ¶ÇËÉåÊôØÔºâ‰∏≠ÁöÑÂ§ßËåÉÊï∞ÂºÇÂ∏∏ÂÄºÔºåÂπ∂ÈõÜ‰∏≠‰∫é‰ªªÂä°ÂÖ≥ÈîÆÂå∫Âüü„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÊñπÊ≥ïÂú®Â∞ÜÂ§ö‰∏™ËßÜËßâÂü∫Á°ÄÊ®°ÂûãÔºàVFMsÔºâÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫Â≠¶‰π†Êó∂ÔºåÂ≠òÂú®‰∏§‰∏™‰∏ªË¶ÅÈóÆÈ¢ò„ÄÇ‰∏ÄÊòØÂçï‰∏™VFMÈÄöÂ∏∏Âè™ÊìÖÈïøÁâπÂÆöÈ¢ÜÂüüÔºåÈôêÂà∂‰∫ÜÂÖ∂Âú®‰∏çÂêå‰ªªÂä°‰∏≠ÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ‰∫åÊòØÁõ¥Êé•Â∞ÜÂ§ö‰∏™VFMËí∏È¶èÊàêÁªü‰∏ÄÁöÑÁ≠ñÁï•Ë°®Á§∫Ôºå‰ºöÂØºËá¥‰ªªÂä°ÁâπÂÆöÁöÑÁâπÂæÅÈÄâÊã©‰∏çÂ§üÁÅµÊ¥ªÔºåÂπ∂‰∏îÈúÄË¶ÅÊòÇË¥µÁöÑÂÆåÂÖ®ÈáçÊñ∞ËÆ≠ÁªÉÊâçËÉΩÊï¥ÂêàÊú∫Âô®‰∫∫È¢ÜÂüüÁöÑÁü•ËØÜ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöVERÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÊûÑÂª∫‰∏Ä‰∏™ËßÜËßâ‰∏ìÂÆ∂Â∫ìÔºåÂÖ∂‰∏≠ÊØè‰∏™‰∏ìÂÆ∂ÈÉΩ‰ªé‰∏çÂêåÁöÑVFM‰∏≠Â≠¶‰π†Âà∞ÁâπÂÆöÁöÑËßÜËßâÁü•ËØÜ„ÄÇÁÑ∂ÂêéÔºåÈÄöËøá‰∏Ä‰∏™ËΩªÈáèÁ∫ßÁöÑË∑ØÁî±ÁΩëÁªúÔºåÊ†πÊçÆÂΩìÂâçÁöÑ‰ªªÂä°Âä®ÊÄÅÂú∞ÈÄâÊã©ÂêàÈÄÇÁöÑ‰∏ìÂÆ∂ÁªÑÂêà„ÄÇËøôÁßçÊñπÊ≥ïÊó¢ËÉΩÂà©Áî®Â§ö‰∏™VFMÁöÑ‰ºòÂäøÔºåÂèàËÉΩÈÅøÂÖçÂÆåÂÖ®ÈáçÊñ∞ËÆ≠ÁªÉÁöÑÊàêÊú¨ÔºåÂêåÊó∂ËøòËÉΩÂÆûÁé∞‰ªªÂä°ÁâπÂÆöÁöÑÁâπÂæÅÈÄâÊã©„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöVERÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰∏â‰∏™‰∏ªË¶ÅÈò∂ÊÆµÔºö1) È¢ÑËÆ≠ÁªÉÈò∂ÊÆµÔºöÂ∞ÜÂ§ö‰∏™VFMËí∏È¶èÂà∞‰∏Ä‰∏™ËßÜËßâ‰∏ìÂÆ∂Â∫ì‰∏≠„ÄÇÊØè‰∏™‰∏ìÂÆ∂ÈÉΩÊòØ‰∏Ä‰∏™TransformerÊ®°ÂùóÔºåË¥üË¥£Â§ÑÁêÜÂõæÂÉèÁöÑ‰∏çÂêåÈÉ®ÂàÜÊàñÂ≠¶‰π†‰∏çÂêåÁöÑËßÜËßâÁâπÂæÅ„ÄÇ2) Ë∑ØÁî±ÁΩëÁªúËÆ≠ÁªÉÈò∂ÊÆµÔºöËÆ≠ÁªÉ‰∏Ä‰∏™ËΩªÈáèÁ∫ßÁöÑË∑ØÁî±ÁΩëÁªúÔºåÁî®‰∫éÊ†πÊçÆÂΩìÂâçÁöÑ‰ªªÂä°Âä®ÊÄÅÂú∞ÈÄâÊã©ÂêàÈÄÇÁöÑ‰∏ìÂÆ∂ÁªÑÂêà„ÄÇË∑ØÁî±ÁΩëÁªúÊé•Êî∂ÂõæÂÉèÁâπÂæÅ‰Ωú‰∏∫ËæìÂÖ•ÔºåËæìÂá∫ÊØè‰∏™‰∏ìÂÆ∂ÁöÑÊùÉÈáç„ÄÇ3) ÂæÆË∞ÉÈò∂ÊÆµÔºö‰ΩøÁî®Êú∫Âô®‰∫∫È¢ÜÂüüÁöÑÊï∞ÊçÆÂØπË∑ØÁî±ÁΩëÁªúËøõË°åÂæÆË∞ÉÔºå‰ª•ÈÄÇÂ∫îÁâπÂÆöÁöÑÊú∫Âô®‰∫∫‰ªªÂä°„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöVERÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂä®ÊÄÅ‰∏ìÂÆ∂Ë∑ØÁî±Êú∫Âà∂ÂíåPatchwise‰∏ìÂÆ∂Ë∑ØÁî±‰∏éËØæÁ®ãTop-KÈÄÄÁÅ´Á≠ñÁï•„ÄÇÂä®ÊÄÅ‰∏ìÂÆ∂Ë∑ØÁî±ÂÖÅËÆ∏Ê®°ÂûãÊ†πÊçÆ‰ªªÂä°ÈúÄÊ±ÇËá™ÈÄÇÂ∫îÂú∞ÈÄâÊã©ÂêàÈÄÇÁöÑ‰∏ìÂÆ∂Ôºå‰ªéËÄåÊèêÈ´ò‰∫ÜÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇPatchwise‰∏ìÂÆ∂Ë∑ØÁî±ÂÖÅËÆ∏Ê®°ÂûãÂú®ÂõæÂÉèÁöÑ‰∏çÂêåÂå∫Âüü‰ΩøÁî®‰∏çÂêåÁöÑ‰∏ìÂÆ∂Ôºå‰ªéËÄåÊèêÈ´ò‰∫ÜÊ®°ÂûãÁöÑÁÅµÊ¥ªÊÄß„ÄÇËØæÁ®ãTop-KÈÄÄÁÅ´Á≠ñÁï•ÂàôÂú®ËÆ≠ÁªÉÂàùÊúüÈºìÂä±Êé¢Á¥¢Êõ¥Â§öÁöÑ‰∏ìÂÆ∂ÁªÑÂêàÔºåÂú®ËÆ≠ÁªÉÂêéÊúüÂàô‰∏ìÊ≥®‰∫éÈÄâÊã©ÊúÄÁõ∏ÂÖ≥ÁöÑ‰∏ìÂÆ∂Ôºå‰ªéËÄåÊèêÈ´ò‰∫ÜÊ®°ÂûãÁöÑËÆ≠ÁªÉÊïàÁéáÂíåÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöVER‰ΩøÁî®Transformer‰Ωú‰∏∫ÂÖ∂‰∏ªË¶ÅÊû∂ÊûÑÔºåÂπ∂ÈááÁî®‰∫§ÂèâÁÜµÊçüÂ§±ÂáΩÊï∞Êù•ËÆ≠ÁªÉË∑ØÁî±ÁΩëÁªú„ÄÇPatchwise‰∏ìÂÆ∂Ë∑ØÁî±Â∞ÜÂõæÂÉèÂàíÂàÜ‰∏∫Â§ö‰∏™patchÔºåÂπ∂‰∏∫ÊØè‰∏™patchÂàÜÈÖç‰∏çÂêåÁöÑ‰∏ìÂÆ∂ÁªÑÂêà„ÄÇËØæÁ®ãTop-KÈÄÄÁÅ´Á≠ñÁï•ÈÄöËøáÈÄêÊ∏êÂáèÂ∞èTop-KÁöÑÂÄºÔºåÊù•ÊéßÂà∂‰∏ìÂÆ∂ÈÄâÊã©ÁöÑËåÉÂõ¥„ÄÇË∑ØÁî±ÁΩëÁªúÁöÑÂèÇÊï∞ÈáèË¢´ÊéßÂà∂Âú®ÊÄªÂèÇÊï∞ÈáèÁöÑ0.4%‰ª•‰∏ãÔºå‰ª•‰øùËØÅÂÖ∂ËΩªÈáèÁ∫ßÂíåÈ´òÊïàÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

VERÂú®17‰∏™‰∏çÂêåÁöÑÊú∫Âô®‰∫∫‰ªªÂä°‰∏äÂèñÂæó‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÊòæËëó‰ºò‰∫éÁé∞ÊúâÁöÑÊñπÊ≥ï„ÄÇ‰æãÂ¶ÇÔºåÂú®Êüê‰∫õ‰ªªÂä°‰∏äÔºåVERÁöÑÊÄßËÉΩÊèêÂçáË∂ÖËøá‰∫Ü10%„ÄÇÂÆûÈ™åÁªìÊûúËøòË°®ÊòéÔºåVERËÉΩÂ§üÊúâÊïàÂú∞ÂáèÂ∞ë‰ªªÂä°Êó†ÂÖ≥Âå∫ÂüüÁöÑÂπ≤Êâ∞ÔºåÂπ∂ÈõÜ‰∏≠‰∫é‰ªªÂä°ÂÖ≥ÈîÆÂå∫ÂüüÔºå‰ªéËÄåÊèêÈ´ò‰∫ÜÊ®°ÂûãÁöÑÈ≤ÅÊ£íÊÄßÂíåÂèØÈù†ÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

VERÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂèØÂ∫îÁî®‰∫éÂêÑÁßçÊú∫Âô®‰∫∫Â≠¶‰π†‰ªªÂä°Ôºå‰æãÂ¶ÇÁâ©‰ΩìÊäìÂèñ„ÄÅÂØºËà™„ÄÅÊìç‰ΩúÁ≠â„ÄÇÈÄöËøáÂà©Áî®È¢ÑËÆ≠ÁªÉÁöÑËßÜËßâÁü•ËØÜÔºåVERÂèØ‰ª•ÊòæËëóÊèêÈ´òÊú∫Âô®‰∫∫ÁöÑÂ≠¶‰π†ÊïàÁéáÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåVERËøòÂèØ‰ª•Â∫îÁî®‰∫éÂÖ∂‰ªñÈúÄË¶ÅËßÜËßâÁü•ËØÜËøÅÁßªÁöÑÈ¢ÜÂüüÔºå‰æãÂ¶ÇËá™Âä®È©æÈ©∂„ÄÅÊô∫ËÉΩÁõëÊéßÁ≠â„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Pretrained vision foundation models (VFMs) advance robotic learning via rich visual representations, yet individual VFMs typically excel only in specific domains, limiting generality across tasks. Distilling multiple VFMs into a unified representation for policy can mitigate this limitation but often yields inflexible task-specific feature selection and requires costly full re-training to incorporate robot-domain knowledge. We propose VER, a Vision Expert transformer for Robot learning. During pretraining, VER distills multiple VFMs into a vision expert library. It then fine-tunes only a lightweight routing network (fewer than 0.4% of parameters) to dynamically select task-relevant experts from the pretrained library for downstream robot tasks. We further introduce Patchwise Expert Routing with Curriculum Top-K Annealing to improve both flexibility and precision of dynamic expert selection. Moreover, VER supports parameter-efficient finetuning for scalable expert utilization and adaptive robot-domain knowledge integration. Across 17 diverse robotic tasks and multiple policy heads, VER achieves state-of-the-art performance. We find that VER reduces large-norm outliers in task-irrelevant regions (e.g., background) and concentrates on task-critical regions. Visualizations and codes can be found in https://yixiaowang7.github.io/ver_page/.

