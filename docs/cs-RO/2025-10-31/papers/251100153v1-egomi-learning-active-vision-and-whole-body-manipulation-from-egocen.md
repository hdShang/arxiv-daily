---
layout: default
title: "EgoMI: Learning Active Vision and Whole-Body Manipulation from Egocentric Human Demonstrations"
---

# EgoMI: Learning Active Vision and Whole-Body Manipulation from Egocentric Human Demonstrations

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.00153" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.00153v1</a>
  <a href="https://arxiv.org/pdf/2511.00153.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.00153v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.00153v1', 'EgoMI: Learning Active Vision and Whole-Body Manipulation from Egocentric Human Demonstrations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Justin Yu, Yide Shentu, Di Wu, Pieter Abbeel, Ken Goldberg, Philipp Wu

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-10-31

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**EgoMIï¼šä»ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„äººç±»æ¼”ç¤ºä¸­å­¦ä¹ ä¸»åŠ¨è§†è§‰å’Œå…¨èº«æ“ä½œ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)**

**å…³é”®è¯**: `æ¨¡ä»¿å­¦ä¹ ` `æœºå™¨äººæ“ä½œ` `ä¸»åŠ¨è§†è§‰` `å…·èº«æ™ºèƒ½` `äººæœºäº¤äº’`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æœºå™¨äººæ¨¡ä»¿å­¦ä¹ æ–¹æ³•éš¾ä»¥å¤„ç†äººç±»æ¼”ç¤ºæ•°æ®ä¸­åŠ¨æ€çš„å¤´éƒ¨è¿åŠ¨ï¼Œå¯¼è‡´äººæœºå…·èº«å·®è·å’Œç­–ç•¥æ€§èƒ½ä¸‹é™ã€‚
2. EgoMIæ¡†æ¶é€šè¿‡æ•è·åŒæ­¥çš„æœ«ç«¯æ‰§è¡Œå™¨å’Œä¸»åŠ¨å¤´éƒ¨è½¨è¿¹ï¼Œå¹¶ç»“åˆè®°å¿†å¢å¼ºç­–ç•¥æ¥å¤„ç†å¿«é€Ÿå˜åŒ–çš„å¤´éƒ¨è§†ç‚¹ã€‚
3. å®éªŒè¡¨æ˜ï¼Œåœ¨åŒè‡‚æœºå™¨äººä¸Šï¼Œæ˜¾å¼å»ºæ¨¡å¤´éƒ¨è¿åŠ¨çš„ç­–ç•¥ä¼˜äºåŸºçº¿æ–¹æ³•ï¼Œæœ‰æ•ˆå¼¥åˆäº†äººæœºå…·èº«å·®è·ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºäººç±»æ¼”ç¤ºçš„æ¨¡ä»¿å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºæœºå™¨äººæŠ€èƒ½ä¹ å¾—ã€‚ç”±äºäººæœºä¹‹é—´çš„å…·èº«å·®è·ï¼Œä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„äººç±»æ•°æ®å¸¦æ¥äº†æ ¹æœ¬æ€§çš„æŒ‘æˆ˜ã€‚åœ¨æ“ä½œè¿‡ç¨‹ä¸­ï¼Œäººç±»ä¼šä¸»åŠ¨åè°ƒå¤´éƒ¨å’Œæ‰‹éƒ¨çš„è¿åŠ¨ï¼Œä¸æ–­è°ƒæ•´è§†è§’ï¼Œå¹¶ä½¿ç”¨é¢„å…ˆçš„è§†è§‰æ³¨è§†æœç´¢ç­–ç•¥æ¥å®šä½ç›¸å…³ç‰©ä½“ã€‚è¿™äº›è¡Œä¸ºäº§ç”Ÿäº†åŠ¨æ€çš„ã€ä»»åŠ¡é©±åŠ¨çš„å¤´éƒ¨è¿åŠ¨ï¼Œè€Œé™æ€çš„æœºå™¨äººä¼ æ„Ÿç³»ç»Ÿæ— æ³•å¤åˆ¶è¿™äº›è¿åŠ¨ï¼Œä»è€Œå¯¼è‡´æ˜¾è‘—çš„åˆ†å¸ƒåç§»ï¼Œé™ä½ç­–ç•¥æ€§èƒ½ã€‚æˆ‘ä»¬æå‡ºäº†EgoMIï¼ˆEgocentric Manipulation Interfaceï¼‰ï¼Œè¯¥æ¡†æ¶å¯ä»¥æ•è·æ“ä½œä»»åŠ¡æœŸé—´åŒæ­¥çš„æœ«ç«¯æ‰§è¡Œå™¨å’Œä¸»åŠ¨å¤´éƒ¨è½¨è¿¹ï¼Œä»è€Œç”Ÿæˆå¯ä»¥é‡æ–°å®šä½åˆ°å…¼å®¹çš„åŠäººå½¢æœºå™¨äººä¸Šçš„æ•°æ®ã€‚ä¸ºäº†å¤„ç†å¿«é€Ÿä¸”èŒƒå›´å¹¿æ³›çš„å¤´éƒ¨è§†ç‚¹å˜åŒ–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§è®°å¿†å¢å¼ºç­–ç•¥ï¼Œè¯¥ç­–ç•¥æœ‰é€‰æ‹©åœ°ç»“åˆäº†å†å²è§‚å¯Ÿã€‚æˆ‘ä»¬åœ¨é…å¤‡äº†ç”µåŠ¨ç›¸æœºå¤´çš„åŒè‡‚æœºå™¨äººä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œå‘ç°å…·æœ‰æ˜¾å¼å¤´éƒ¨è¿åŠ¨å»ºæ¨¡çš„ç­–ç•¥å§‹ç»ˆä¼˜äºåŸºçº¿æ–¹æ³•ã€‚ç»“æœè¡¨æ˜ï¼Œé€šè¿‡EgoMIè¿›è¡Œåè°ƒçš„æ‰‹çœ¼å­¦ä¹ æœ‰æ•ˆåœ°å¼¥åˆäº†äººæœºå…·èº«å·®è·ï¼Œä»è€Œåœ¨åŠäººå½¢æœºå™¨äººä¸Šå®ç°äº†é²æ£’çš„æ¨¡ä»¿å­¦ä¹ ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æœºå™¨äººæ¨¡ä»¿å­¦ä¹ æ–¹æ³•åœ¨å¤„ç†ä»¥äººä¸ºä¸­å¿ƒçš„æ•°æ®æ—¶ï¼Œé¢ä¸´ç€ä¸¥é‡çš„å…·èº«å·®è·é—®é¢˜ã€‚äººç±»åœ¨æ“ä½œç‰©ä½“æ—¶ï¼Œå¤´éƒ¨ä¼šè¿›è¡Œä¸»åŠ¨çš„ã€ä»»åŠ¡é©±åŠ¨çš„è¿åŠ¨ï¼Œä»¥ä¼˜åŒ–è§†è§’å’Œå®šä½ç›®æ ‡ã€‚ä¼ ç»Ÿçš„æœºå™¨äººé™æ€æ„ŸçŸ¥ç³»ç»Ÿæ— æ³•å¤åˆ¶è¿™ç§åŠ¨æ€çš„å¤´éƒ¨è¿åŠ¨ï¼Œå¯¼è‡´è®­ç»ƒæ•°æ®å’Œæœºå™¨äººå®é™…æ“ä½œç¯å¢ƒä¹‹é—´å­˜åœ¨æ˜¾è‘—çš„åˆ†å¸ƒå·®å¼‚ï¼Œä»è€Œé™ä½äº†æ¨¡ä»¿å­¦ä¹ ç­–ç•¥çš„æ€§èƒ½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šEgoMIçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ¨¡ä»¿äººç±»çš„ä¸»åŠ¨è§†è§‰è¡Œä¸ºæ¥å¼¥åˆäººæœºå…·èº«å·®è·ã€‚å…·ä½“æ¥è¯´ï¼ŒEgoMIæ¡†æ¶åŒæ—¶è®°å½•äººç±»æ“ä½œè¿‡ç¨‹ä¸­çš„æ‰‹éƒ¨è¿åŠ¨è½¨è¿¹å’Œå¤´éƒ¨è¿åŠ¨è½¨è¿¹ï¼Œå¹¶å°†è¿™äº›æ•°æ®ç”¨äºè®­ç»ƒæœºå™¨äººçš„æ§åˆ¶ç­–ç•¥ã€‚é€šè¿‡æ˜¾å¼åœ°å»ºæ¨¡å’Œæ§åˆ¶æœºå™¨äººçš„å¤´éƒ¨è¿åŠ¨ï¼ŒEgoMIä½¿å¾—æœºå™¨äººèƒ½å¤Ÿåƒäººç±»ä¸€æ ·ä¸»åŠ¨åœ°è°ƒæ•´è§†è§’ï¼Œä»è€Œæ›´å¥½åœ°æ„ŸçŸ¥å’Œæ“ä½œç‰©ä½“ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEgoMIæ¡†æ¶ä¸»è¦åŒ…å«ä¸¤ä¸ªéƒ¨åˆ†ï¼šæ•°æ®é‡‡é›†å’Œç­–ç•¥å­¦ä¹ ã€‚æ•°æ®é‡‡é›†éƒ¨åˆ†ä½¿ç”¨Egocentric Manipulation Interfaceæ¥è®°å½•äººç±»æ“ä½œè¿‡ç¨‹ä¸­çš„æ‰‹éƒ¨å’Œå¤´éƒ¨è¿åŠ¨è½¨è¿¹ã€‚ç­–ç•¥å­¦ä¹ éƒ¨åˆ†ä½¿ç”¨æ¨¡ä»¿å­¦ä¹ ç®—æ³•ï¼Œæ ¹æ®é‡‡é›†åˆ°çš„æ•°æ®è®­ç»ƒæœºå™¨äººçš„æ§åˆ¶ç­–ç•¥ã€‚ä¸ºäº†å¤„ç†å¿«é€Ÿå˜åŒ–çš„å¤´éƒ¨è§†ç‚¹ï¼ŒEgoMIå¼•å…¥äº†ä¸€ç§è®°å¿†å¢å¼ºç­–ç•¥ï¼Œè¯¥ç­–ç•¥å¯ä»¥æœ‰é€‰æ‹©åœ°ç»“åˆå†å²è§‚å¯Ÿï¼Œä»è€Œæé«˜ç­–ç•¥çš„é²æ£’æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šEgoMIæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå®ƒæ˜¾å¼åœ°å»ºæ¨¡å’Œæ§åˆ¶æœºå™¨äººçš„å¤´éƒ¨è¿åŠ¨ã€‚ä¸ä¼ ç»Ÿçš„æœºå™¨äººæ¨¡ä»¿å­¦ä¹ æ–¹æ³•ä¸åŒï¼ŒEgoMIä¸ä»…å­¦ä¹ æ‰‹éƒ¨è¿åŠ¨è½¨è¿¹ï¼Œè¿˜å­¦ä¹ å¤´éƒ¨è¿åŠ¨è½¨è¿¹ã€‚é€šè¿‡åŒæ—¶æ§åˆ¶æ‰‹éƒ¨å’Œå¤´éƒ¨è¿åŠ¨ï¼ŒEgoMIä½¿å¾—æœºå™¨äººèƒ½å¤Ÿåƒäººç±»ä¸€æ ·ä¸»åŠ¨åœ°è°ƒæ•´è§†è§’ï¼Œä»è€Œæ›´å¥½åœ°æ„ŸçŸ¥å’Œæ“ä½œç‰©ä½“ã€‚

**å…³é”®è®¾è®¡**ï¼šEgoMIçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨åŒæ­¥çš„æœ«ç«¯æ‰§è¡Œå™¨å’Œä¸»åŠ¨å¤´éƒ¨è½¨è¿¹æ•°æ®è¿›è¡Œè®­ç»ƒï¼›2) å¼•å…¥è®°å¿†å¢å¼ºç­–ç•¥æ¥å¤„ç†å¿«é€Ÿå˜åŒ–çš„å¤´éƒ¨è§†ç‚¹ï¼›3) ä½¿ç”¨æ¨¡ä»¿å­¦ä¹ ç®—æ³•æ¥è®­ç»ƒæœºå™¨äººçš„æ§åˆ¶ç­–ç•¥ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’ŒæŸå¤±å‡½æ•°ç­‰æŠ€æœ¯ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨é…å¤‡äº†ç”µåŠ¨ç›¸æœºå¤´çš„åŒè‡‚æœºå™¨äººä¸Šï¼Œä½¿ç”¨EgoMIè®­ç»ƒçš„ç­–ç•¥åœ¨æ“ä½œä»»åŠ¡ä¸­è¡¨ç°å‡ºæ˜¾è‘—çš„ä¼˜åŠ¿ã€‚ä¸æ²¡æœ‰æ˜¾å¼å»ºæ¨¡å¤´éƒ¨è¿åŠ¨çš„åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼ŒEgoMIèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å¼¥åˆäººæœºå…·èº«å·®è·ï¼Œæé«˜ç­–ç•¥çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚å…·ä½“æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†å±•ç¤ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

EgoMIæŠ€æœ¯å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚ï¼šè¿œç¨‹æ“ä½œã€è‡ªåŠ¨åŒ–è£…é…ã€åŒ»ç–—æœºå™¨äººã€å®¶åº­æœåŠ¡æœºå™¨äººç­‰ã€‚é€šè¿‡æ¨¡ä»¿äººç±»çš„æ“ä½œè¡Œä¸ºï¼ŒEgoMIå¯ä»¥ä½¿æœºå™¨äººæ›´åŠ æ™ºèƒ½ã€çµæ´»å’Œå®‰å…¨ã€‚æœªæ¥ï¼ŒEgoMIæœ‰æœ›æˆä¸ºæœºå™¨äººæŠ€æœ¯é¢†åŸŸçš„ä¸€é¡¹é‡è¦æŠ€æœ¯ï¼Œæ¨åŠ¨æœºå™¨äººæŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Imitation learning from human demonstrations offers a promising approach for robot skill acquisition, but egocentric human data introduces fundamental challenges due to the embodiment gap. During manipulation, humans actively coordinate head and hand movements, continuously reposition their viewpoint and use pre-action visual fixation search strategies to locate relevant objects. These behaviors create dynamic, task-driven head motions that static robot sensing systems cannot replicate, leading to a significant distribution shift that degrades policy performance. We present EgoMI (Egocentric Manipulation Interface), a framework that captures synchronized end-effector and active head trajectories during manipulation tasks, resulting in data that can be retargeted to compatible semi-humanoid robot embodiments. To handle rapid and wide-spanning head viewpoint changes, we introduce a memory-augmented policy that selectively incorporates historical observations. We evaluate our approach on a bimanual robot equipped with an actuated camera head and find that policies with explicit head-motion modeling consistently outperform baseline methods. Results suggest that coordinated hand-eye learning with EgoMI effectively bridges the human-robot embodiment gap for robust imitation learning on semi-humanoid embodiments. Project page: https://egocentric-manipulation-interface.github.io

