---
layout: default
title: End-to-End Dexterous Arm-Hand VLA Policies via Shared Autonomy: VR Teleoperation Augmented by Autonomous Hand VLA Policy for Efficient Data Collection
---

# End-to-End Dexterous Arm-Hand VLA Policies via Shared Autonomy: VR Teleoperation Augmented by Autonomous Hand VLA Policy for Efficient Data Collection

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.00139" target="_blank" class="toolbar-btn">arXiv: 2511.00139v2</a>
    <a href="https://arxiv.org/pdf/2511.00139.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.00139v2" 
            onclick="toggleFavorite(this, '2511.00139v2', 'End-to-End Dexterous Arm-Hand VLA Policies via Shared Autonomy: VR Teleoperation Augmented by Autonomous Hand VLA Policy for Efficient Data Collection')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yu Cui, Yujian Zhang, Lina Tao, Yang Li, Xinyu Yi, Zhibin Li

**ÂàÜÁ±ª**: cs.RO, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-31 (Êõ¥Êñ∞: 2025-12-13)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éÂÖ±‰∫´Ëá™‰∏ªÁöÑÁÅµÂ∑ßËáÇÊâãVLAÁ≠ñÁï•ÔºåÁî®‰∫éÈ´òÊïàÊï∞ÊçÆÊî∂ÈõÜ„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÁÅµÂ∑ßÊìç‰Ωú` `ÂÖ±‰∫´Ëá™‰∏ª` `VRÈÅ•Êìç‰Ωú` `ËßÜËßâËØ≠Ë®ÄÂä®‰ΩúÊ®°Âûã` `Êú∫Âô®‰∫∫Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁÅµÂ∑ßÊìç‰ΩúÊï∞ÊçÆÊî∂ÈõÜÊñπÊ≥ïÈù¢‰∏¥‰∫∫Â∑•ÈÅ•Êìç‰ΩúË¥üÊãÖÈáçÂíåËá™Âä®ËßÑÂàíÂä®‰Ωú‰∏çËá™ÁÑ∂Á≠âÊåëÊàò„ÄÇ
2. ÊèêÂá∫ÂÖ±‰∫´Ëá™‰∏ªÊ°ÜÊû∂ÔºåÁªìÂêàVRÈÅ•Êìç‰ΩúÁöÑÊâãËáÇÊéßÂà∂ÂíåËá™‰∏ªVLAÁ≠ñÁï•ÁöÑÊâãÈÉ®ÊéßÂà∂ÔºåÈôç‰ΩéËÆ§Áü•Ë¥üËç∑„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåËØ•Ê°ÜÊû∂ËÉΩÈ´òÊïàÁîüÊàêÈ´òË¥®ÈáèÊï∞ÊçÆÔºåËÆ≠ÁªÉÁöÑVLAÁ≠ñÁï•Âú®Â§öÁßçÁâ©‰Ωì‰∏äËææÂà∞90%ÁöÑÊàêÂäüÁéá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂÖ±‰∫´Ëá™‰∏ªÊ°ÜÊû∂ÔºåÊó®Âú®Ëß£ÂÜ≥ÈÄöÁî®Êú∫Âô®‰∫∫ÂÆûÁé∞Á±ª‰∫∫ÁÅµÂ∑ßÊìç‰ΩúÁöÑÊåëÊàò„ÄÇËØ•Ê°ÜÊû∂Âà©Áî®VRÈÅ•Êìç‰ΩúÂºïÂØºÊú∫Âô®‰∫∫ÊâãËáÇÁöÑÂÆèËßÇËøêÂä®ÔºåÂêåÊó∂ÈááÁî®Ëá™‰∏ªÁöÑDexGrasp-VLAÁ≠ñÁï•ÔºåÈÄöËøáÂÆûÊó∂Ëß¶ËßâÂíåËßÜËßâÂèçÈ¶àÂ§ÑÁêÜÁ≤æÁªÜÁöÑÊâãÈÉ®ÊéßÂà∂„ÄÇËøôÁßçÂàÜÂ∑•ÊòæËëóÈôç‰Ωé‰∫ÜÊìç‰ΩúÂëòÁöÑËÆ§Áü•Ë¥üËç∑ÔºåÂπ∂ËÉΩÂ§üÈ´òÊïàÊî∂ÈõÜÈ´òË¥®ÈáèÁöÑËáÇÊâãÂçèÂêåÊºîÁ§∫Êï∞ÊçÆ„ÄÇÂà©Áî®Ëøô‰∫õÊï∞ÊçÆÔºåËÆ≠ÁªÉ‰∫Ü‰∏Ä‰∏™Á´ØÂà∞Á´ØÁöÑVLAÁ≠ñÁï•ÔºåÂπ∂ÂºïÂÖ•‰∫ÜËáÇÊâãÁâπÂæÅÂ¢ûÂº∫Ê®°ÂùóÔºåËØ•Ê®°ÂùóÊçïËé∑ÂÆèËßÇÂíåÂæÆËßÇËøêÂä®ÁöÑÁã¨ÁâπÂíåÂÖ±‰∫´Ë°®Á§∫Ôºå‰ª•ÂÆûÁé∞Êõ¥Ëá™ÁÑ∂ÁöÑÂçèË∞É„ÄÇÊ≠§Â§ñÔºåËøòÊèêÂá∫‰∫ÜÁ∫†Ê≠£ÊÄßÈÅ•Êìç‰ΩúÁ≥ªÁªüÔºåÈÄöËøá‰∫∫Êú∫Âçè‰ΩúÁöÑÂ§±Ë¥•ÊÅ¢Â§çÂÆûÁé∞Á≠ñÁï•ÁöÑÊåÅÁª≠ÊîπËøõ„ÄÇÂÆûÈ™åË°®ÊòéÔºåËØ•Ê°ÜÊû∂ËÉΩÂ§ü‰ª•ÊúÄÂ∞ëÁöÑ‰∫∫ÂäõÁîüÊàêÈ´òË¥®ÈáèÁöÑÊï∞ÊçÆÔºåÂπ∂Âú®ÂêÑÁßçÁâ©‰ΩìÔºàÂåÖÊã¨Êú™ËßÅËøáÁöÑÂÆû‰æãÔºâ‰∏äÂÆûÁé∞‰∫Ü90%ÁöÑÊàêÂäüÁéá„ÄÇÁªºÂêàËØÑ‰º∞È™åËØÅ‰∫ÜËØ•Á≥ªÁªüÂú®ÂºÄÂèëÁÅµÂ∑ßÊìç‰ΩúËÉΩÂäõÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÊñπÊ≥ïÂú®Êî∂ÈõÜÈ´òË¥®ÈáèÁöÑÁÅµÂ∑ßÊìç‰ΩúÊï∞ÊçÆÊó∂Èù¢‰∏¥ÊåëÊàò„ÄÇ‰∫∫Â∑•ÈÅ•Êìç‰ΩúÈúÄË¶ÅÊìç‰ΩúÂëò‰ªòÂá∫Â§ßÈáèÁöÑËÆ§Áü•Âä™ÂäõÔºåÂÆπÊòìÁñ≤Âä≥Ôºå‰∏îÊïàÁéáËæÉ‰Ωé„ÄÇËÄåÂÆåÂÖ®Ëá™Âä®ÂåñÁöÑËßÑÂàíÊñπÊ≥ïÂæÄÂæÄÁîüÊàê‰∏çËá™ÁÑ∂ÁöÑËøêÂä®ÔºåÈöæ‰ª•Ê≥õÂåñÂà∞Â§çÊùÇÂú∫ÊôØ„ÄÇÂõ†Ê≠§ÔºåÂ¶Ç‰ΩïÈ´òÊïàÂú∞Êî∂ÈõÜÈ´òË¥®ÈáèÁöÑËáÇÊâãÂçèÂêåÊìç‰ΩúÊï∞ÊçÆÔºåÊòØÊú¨ÊñáË¶ÅËß£ÂÜ≥ÁöÑÊ†∏ÂøÉÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊú¨ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜÊéßÂà∂‰ªªÂä°ÂàÜËß£‰∏∫ÂÆèËßÇÂíåÂæÆËßÇ‰∏§‰∏™Â±ÇÈù¢ÔºåÂπ∂ÂàÜÂà´Áî±‰∫∫Á±ªÊìç‰ΩúÂëòÂíåËá™‰∏ªÁ≠ñÁï•Êù•ÊéßÂà∂„ÄÇ‰∫∫Á±ªÊìç‰ΩúÂëòÈÄöËøáVRÈÅ•Êìç‰ΩúË¥üË¥£ÂºïÂØºÊú∫Âô®‰∫∫ÁöÑÊâãËáÇÂßøÊÄÅÔºåËøõË°åÂÆèËßÇÁöÑËøêÂä®ËßÑÂàí„ÄÇËÄåËá™‰∏ªÁöÑDexGrasp-VLAÁ≠ñÁï•ÂàôË¥üË¥£Â§ÑÁêÜÁ≤æÁªÜÁöÑÊâãÈÉ®ÊéßÂà∂ÔºåÂà©Áî®ÂÆûÊó∂Ëß¶ËßâÂíåËßÜËßâÂèçÈ¶àËøõË°åÊäìÂèñÂíåÊìç‰Ωú„ÄÇËøôÁßçÂàÜÂ∑•Âçè‰ΩúÁöÑÊñπÂºèÂèØ‰ª•ÊúâÊïàÈôç‰ΩéÊìç‰ΩúÂëòÁöÑËÆ§Áü•Ë¥üËç∑ÔºåÂêåÊó∂‰øùËØÅÂä®‰ΩúÁöÑËá™ÁÑ∂ÊÄßÂíåÈ´òÊïàÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) **ÂÖ±‰∫´Ëá™‰∏ªÊéßÂà∂Ê®°Âùó**Ôºö‰∫∫Á±ªÊìç‰ΩúÂëòÈÄöËøáVRÁïåÈù¢ÊéßÂà∂Êú∫Ê¢∞ËáÇÁöÑÂÖ®Â±ÄÂßøÊÄÅÔºåËá™‰∏ªDexGrasp-VLAÁ≠ñÁï•ÊéßÂà∂Êú∫Ê¢∞ÊâãÁöÑÁ≤æÁªÜÂä®‰Ωú„ÄÇ2) **ËáÇÊâãÁâπÂæÅÂ¢ûÂº∫Ê®°Âùó**ÔºöËØ•Ê®°ÂùóÁî®‰∫éÂ¢ûÂº∫VLAÁ≠ñÁï•ÂØπËáÇÊâãÂçèÂêåÂä®‰ΩúÁöÑÁêÜËß£ÔºåÈÄöËøáÂ≠¶‰π†ËáÇÊâãÂä®‰ΩúÁöÑÂÖ±‰∫´ÂíåÁã¨Á´ãÁâπÂæÅÔºåÊèêÂçáÁ≠ñÁï•ÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ3) **Á∫†Ê≠£ÊÄßÈÅ•Êìç‰ΩúÁ≥ªÁªü**ÔºöÂÖÅËÆ∏‰∫∫Á±ªÊìç‰ΩúÂëòÂú®Ëá™‰∏ªÁ≠ñÁï•Â§±Ë¥•Êó∂‰ªãÂÖ•ÔºåÈÄöËøáÈÅ•Êìç‰ΩúËøõË°åÁ∫†Ê≠£ÔºåÂπ∂Â∞ÜÁ∫†Ê≠£Êï∞ÊçÆÁî®‰∫éÁ≠ñÁï•ÁöÑÊåÅÁª≠ÊîπËøõ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊú¨ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ±‰∫´Ëá™‰∏ªÊéßÂà∂Ê°ÜÊû∂ÂíåËáÇÊâãÁâπÂæÅÂ¢ûÂº∫Ê®°Âùó„ÄÇÂÖ±‰∫´Ëá™‰∏ªÊéßÂà∂Ê°ÜÊû∂ÈÄöËøá‰∫∫Êú∫Âçè‰ΩúÁöÑÊñπÂºèÔºåÂÆûÁé∞‰∫ÜÈ´òÊïàÁöÑÊï∞ÊçÆÊî∂ÈõÜ„ÄÇËáÇÊâãÁâπÂæÅÂ¢ûÂº∫Ê®°ÂùóÂàôÈÄöËøáÂ≠¶‰π†ËáÇÊâãÂä®‰ΩúÁöÑÂÖ±‰∫´ÂíåÁã¨Á´ãÁâπÂæÅÔºåÊèêÂçá‰∫ÜVLAÁ≠ñÁï•ÁöÑÊ≥õÂåñËÉΩÂäõÂíåÈ≤ÅÊ£íÊÄß„ÄÇÊ≠§Â§ñÔºåÁ∫†Ê≠£ÊÄßÈÅ•Êìç‰ΩúÁ≥ªÁªü‰πü‰∏∫Á≠ñÁï•ÁöÑÊåÅÁª≠ÊîπËøõÊèê‰æõ‰∫ÜÊúâÊïàÁöÑÊâãÊÆµ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöDexGrasp-VLAÁ≠ñÁï•‰ΩøÁî®TransformerÊû∂ÊûÑÔºåËæìÂÖ•ÂåÖÊã¨ËßÜËßâÂõæÂÉè„ÄÅËß¶Ëßâ‰º†ÊÑüÂô®Êï∞ÊçÆÂíåËØ≠Ë®ÄÊåá‰ª§„ÄÇËáÇÊâãÁâπÂæÅÂ¢ûÂº∫Ê®°ÂùóÈááÁî®ÂèåÂàÜÊîØÁΩëÁªúÁªìÊûÑÔºåÂàÜÂà´ÊèêÂèñÊâãËáÇÂíåÊâãÈÉ®ÁöÑÁâπÂæÅÔºåÂπ∂ÈÄöËøáÊ≥®ÊÑèÂäõÊú∫Âà∂ËøõË°åËûçÂêà„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨Ê®°‰ªøÂ≠¶‰π†ÊçüÂ§±ÂíåÂº∫ÂåñÂ≠¶‰π†ÊçüÂ§±ÔºåÁî®‰∫éËÆ≠ÁªÉVLAÁ≠ñÁï•„ÄÇÁ∫†Ê≠£ÊÄßÈÅ•Êìç‰ΩúÁ≥ªÁªü‰ΩøÁî®Êà∑ËÉΩÂ§üÈÄöËøáVRÁïåÈù¢ÂÆûÊó∂Ë∞ÉÊï¥Êú∫Âô®‰∫∫ÁöÑÂßøÊÄÅÂíåÊâãÈÉ®Âä®‰Ωú„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•Ê°ÜÊû∂ËÉΩÂ§ü‰ª•ÊúÄÂ∞ëÁöÑ‰∫∫ÂäõÁîüÊàêÈ´òË¥®ÈáèÁöÑÊï∞ÊçÆÔºåÂπ∂‰∏îËÆ≠ÁªÉÂæóÂà∞ÁöÑVLAÁ≠ñÁï•Âú®ÂêÑÁßçÁâ©‰ΩìÔºàÂåÖÊã¨Êú™ËßÅËøáÁöÑÂÆû‰æãÔºâ‰∏äÂÆûÁé∞‰∫Ü90%ÁöÑÊäìÂèñÊàêÂäüÁéá„ÄÇ‰∏é‰º†ÁªüÁöÑÈÅ•Êìç‰ΩúÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïÊòæËëóÈôç‰Ωé‰∫ÜÊìç‰ΩúÂëòÁöÑËÆ§Áü•Ë¥üËç∑ÔºåÂπ∂ÊèêÈ´ò‰∫ÜÊï∞ÊçÆÊî∂ÈõÜÁöÑÊïàÁéá„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂêÑÁßçÈúÄË¶ÅÁÅµÂ∑ßÊìç‰ΩúÁöÑÊú∫Âô®‰∫∫‰ªªÂä°‰∏≠Ôºå‰æãÂ¶ÇÔºöÂ∑•‰∏öËá™Âä®Âåñ‰∏≠ÁöÑÁ≤æÂØÜË£ÖÈÖç„ÄÅÂåªÁñóÊú∫Âô®‰∫∫‰∏≠ÁöÑÂæÆÂàõÊâãÊúØ„ÄÅÂÆ∂Â∫≠ÊúçÂä°Êú∫Âô®‰∫∫‰∏≠ÁöÑÁâ©ÂìÅÊï¥ÁêÜÁ≠â„ÄÇÈÄöËøáÈ´òÊïàÁöÑÊï∞ÊçÆÊî∂ÈõÜÂíåÁ≠ñÁï•Â≠¶‰π†ÔºåÂèØ‰ª•ÊòæËëóÈôç‰ΩéÊú∫Âô®‰∫∫ÈÉ®ÁΩ≤ÁöÑÊàêÊú¨ÂíåÈöæÂ∫¶ÔºåÂä†ÈÄüÊú∫Âô®‰∫∫Âú®ÂÆûÈôÖÂú∫ÊôØ‰∏≠ÁöÑÂ∫îÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Achieving human-like dexterous manipulation remains a major challenge for general-purpose robots. While Vision-Language-Action (VLA) models show potential in learning skills from demonstrations, their scalability is limited by scarce high-quality training data. Existing data collection methods face inherent constraints: manual teleoperation overloads human operators, while automated planning often produces unnatural motions. We propose a Shared Autonomy framework that divides control between macro and micro motions. A human operator guides the robot's arm pose through intuitive VR teleoperation, while an autonomous DexGrasp-VLA policy handles fine-grained hand control using real-time tactile and visual feedback. This division significantly reduces cognitive load and enables efficient collection of high-quality coordinated arm-hand demonstrations. Using this data, we train an end-to-end VLA policy enhanced with our novel Arm-Hand Feature Enhancement module, which captures both distinct and shared representations of macro and micro movements for more natural coordination. Our Corrective Teleoperation system enables continuous policy improvement through human-in-the-loop failure recovery. Experiments demonstrate that our framework generates high-quality data with minimal manpower and achieves a 90% success rate across diverse objects, including unseen instances. Comprehensive evaluations validate the system's effectiveness in developing dexterous manipulation capabilities.

