---
layout: default
title: Learning Generalizable Visuomotor Policy through Dynamics-Alignment
---

# Learning Generalizable Visuomotor Policy through Dynamics-Alignment

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.27114" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.27114v1</a>
  <a href="https://arxiv.org/pdf/2510.27114.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.27114v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.27114v1', 'Learning Generalizable Visuomotor Policy through Dynamics-Alignment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Dohyeok Lee, Jung Min Lee, Munkyung Kim, Seokhun Ju, Jin Woo Koo, Kyungjae Lee, Dohyeong Kim, TaeHyun Cho, Jungwoo Lee

**åˆ†ç±»**: cs.RO, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-10-31

**å¤‡æ³¨**: 9 pages, 6 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŠ¨åŠ›å­¦å¯¹é½çš„Flow Matchingç­–ç•¥ï¼Œæå‡æœºå™¨äººæ“ä½œç­–ç•¥çš„æ³›åŒ–æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `æœºå™¨äººå­¦ä¹ ` `è¡Œä¸ºå…‹éš†` `åŠ¨åŠ›å­¦é¢„æµ‹` `æ³›åŒ–èƒ½åŠ›` `Flow Matching` `ç­–ç•¥å­¦ä¹ ` `è§†è§‰æ“ä½œ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. è¡Œä¸ºå…‹éš†æ–¹æ³•ä¾èµ–ä¸“å®¶æ•°æ®ï¼Œæ³›åŒ–æ€§å—é™ï¼›è§†é¢‘é¢„æµ‹æ¨¡å‹è™½èƒ½å­¦ä¹ æ—¶ç©ºè¡¨å¾ï¼Œä½†åŠ¨ä½œæ— å…³çš„åŠ¨åŠ›å­¦é™åˆ¶äº†å…¶åœ¨ç²¾ç¡®æ“ä½œä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚
2. DAPé€šè¿‡ç­–ç•¥å’ŒåŠ¨åŠ›å­¦æ¨¡å‹çš„ç›¸äº’ä¿®æ­£åé¦ˆï¼Œå®ç°åŠ¨ä½œç”Ÿæˆè¿‡ç¨‹ä¸­çš„è‡ªæˆ‘æ ¡æ­£ï¼Œä»è€Œæå‡ç­–ç•¥çš„æ³›åŒ–èƒ½åŠ›ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒDAPåœ¨çœŸå®æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­ï¼Œå°¤å…¶æ˜¯åœ¨OODåœºæ™¯ä¸‹ï¼Œæ³›åŒ–æ€§èƒ½ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå±•ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é’ˆå¯¹æœºå™¨äººå­¦ä¹ ä¸­è¡Œä¸ºå…‹éš†æ–¹æ³•å› ä¸“å®¶æ¼”ç¤ºæ•°æ®æœ‰é™è€Œæ³›åŒ–æ€§å·®çš„é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŠ¨åŠ›å­¦å¯¹é½çš„Flow Matchingç­–ç•¥ï¼ˆDAPï¼‰ã€‚DAPå°†åŠ¨åŠ›å­¦é¢„æµ‹é›†æˆåˆ°ç­–ç•¥å­¦ä¹ ä¸­ï¼Œå¼•å…¥äº†ä¸€ç§æ–°é¢–çš„æ¶æ„ï¼Œå…¶ä¸­ç­–ç•¥æ¨¡å‹å’ŒåŠ¨åŠ›å­¦æ¨¡å‹åœ¨åŠ¨ä½œç”Ÿæˆè¿‡ç¨‹ä¸­æä¾›ç›¸äº’ä¿®æ­£çš„åé¦ˆï¼Œä»è€Œå®ç°è‡ªæˆ‘æ ¡æ­£å’Œæ”¹è¿›çš„æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒéªŒè¯è¡¨æ˜ï¼Œåœ¨çœŸå®æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­ï¼ŒDAPçš„æ³›åŒ–æ€§èƒ½ä¼˜äºåŸºçº¿æ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨åŒ…æ‹¬è§†è§‰å¹²æ‰°å’Œå…‰ç…§å˜åŒ–ç­‰è¶…å‡ºåˆ†å¸ƒï¼ˆOODï¼‰çš„åœºæ™¯ä¸­è¡¨ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰åŸºäºè¡Œä¸ºå…‹éš†çš„æœºå™¨äººå­¦ä¹ æ–¹æ³•ï¼Œç”±äºä¾èµ–æœ‰é™çš„ä¸“å®¶æ¼”ç¤ºæ•°æ®ï¼Œå¯¼è‡´ç­–ç•¥çš„æ³›åŒ–èƒ½åŠ›è¾ƒå·®ã€‚è™½ç„¶åˆ©ç”¨è§†é¢‘é¢„æµ‹æ¨¡å‹å¯ä»¥å­¦ä¹ ä¸°å¯Œçš„æ—¶ç©ºè¡¨å¾ï¼Œä½†è¿™äº›æ¨¡å‹å­¦ä¹ åˆ°çš„åŠ¨åŠ›å­¦æ˜¯åŠ¨ä½œæ— å…³çš„ï¼Œæ— æ³•åŒºåˆ†ä¸åŒçš„æ§åˆ¶è¾“å…¥ï¼Œé™åˆ¶äº†å…¶åœ¨ç²¾ç¡®æ“ä½œä»»åŠ¡ä¸­çš„åº”ç”¨ï¼Œå¹¶ä¸”éœ€è¦å¤§è§„æ¨¡çš„é¢„è®­ç»ƒæ•°æ®é›†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†åŠ¨åŠ›å­¦é¢„æµ‹é›†æˆåˆ°ç­–ç•¥å­¦ä¹ ä¸­ï¼Œé€šè¿‡ç­–ç•¥æ¨¡å‹å’ŒåŠ¨åŠ›å­¦æ¨¡å‹ä¹‹é—´çš„ç›¸äº’ä½œç”¨ï¼Œå®ç°åŠ¨ä½œç”Ÿæˆè¿‡ç¨‹ä¸­çš„è‡ªæˆ‘æ ¡æ­£ã€‚å…·ä½“æ¥è¯´ï¼Œç­–ç•¥æ¨¡å‹æ ¹æ®å½“å‰çŠ¶æ€ç”ŸæˆåŠ¨ä½œï¼ŒåŠ¨åŠ›å­¦æ¨¡å‹é¢„æµ‹è¯¥åŠ¨ä½œä½œç”¨åçš„çŠ¶æ€å˜åŒ–ï¼Œç„¶åç­–ç•¥æ¨¡å‹æ ¹æ®åŠ¨åŠ›å­¦æ¨¡å‹çš„é¢„æµ‹ç»“æœè°ƒæ•´åŠ¨ä½œï¼Œä»è€Œæé«˜åŠ¨ä½œçš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDAPåŒ…å«ç­–ç•¥æ¨¡å‹å’ŒåŠ¨åŠ›å­¦æ¨¡å‹ä¸¤ä¸ªä¸»è¦æ¨¡å—ã€‚ç­–ç•¥æ¨¡å‹è´Ÿè´£æ ¹æ®å½“å‰çŠ¶æ€ç”ŸæˆåŠ¨ä½œï¼ŒåŠ¨åŠ›å­¦æ¨¡å‹è´Ÿè´£é¢„æµ‹ç»™å®šçŠ¶æ€å’ŒåŠ¨ä½œåçš„çŠ¶æ€å˜åŒ–ã€‚è¿™ä¸¤ä¸ªæ¨¡å‹é€šè¿‡Flow Matchingæœºåˆ¶è¿›è¡Œè¿æ¥ï¼Œç­–ç•¥æ¨¡å‹ç”Ÿæˆçš„åŠ¨ä½œä½œä¸ºåŠ¨åŠ›å­¦æ¨¡å‹çš„è¾“å…¥ï¼ŒåŠ¨åŠ›å­¦æ¨¡å‹çš„é¢„æµ‹ç»“æœä½œä¸ºç­–ç•¥æ¨¡å‹çš„åé¦ˆï¼Œä»è€Œå®ç°ç›¸äº’ä¿®æ­£ã€‚æ•´ä¸ªæ¡†æ¶é‡‡ç”¨ç«¯åˆ°ç«¯çš„æ–¹å¼è¿›è¡Œè®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šDAPçš„å…³é”®åˆ›æ–°åœ¨äºå¼•å…¥äº†ç­–ç•¥æ¨¡å‹å’ŒåŠ¨åŠ›å­¦æ¨¡å‹ä¹‹é—´çš„ç›¸äº’åé¦ˆæœºåˆ¶ã€‚è¿™ç§æœºåˆ¶ä½¿å¾—ç­–ç•¥æ¨¡å‹èƒ½å¤Ÿåˆ©ç”¨åŠ¨åŠ›å­¦æ¨¡å‹çš„é¢„æµ‹ä¿¡æ¯æ¥è°ƒæ•´åŠ¨ä½œï¼Œä»è€Œæé«˜åŠ¨ä½œçš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚ä¸ä¼ ç»Ÿçš„è¡Œä¸ºå…‹éš†æ–¹æ³•ç›¸æ¯”ï¼ŒDAPä¸éœ€è¦å¤§é‡çš„ä¸“å®¶æ¼”ç¤ºæ•°æ®ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ›´å¥½åœ°æ³›åŒ–åˆ°æ–°çš„åœºæ™¯ä¸­ã€‚ä¸ç°æœ‰çš„è§†é¢‘é¢„æµ‹æ¨¡å‹ç›¸æ¯”ï¼ŒDAPèƒ½å¤Ÿå­¦ä¹ åˆ°åŠ¨ä½œç›¸å…³çš„åŠ¨åŠ›å­¦ï¼Œä»è€Œæ›´å¥½åœ°é€‚åº”ç²¾ç¡®æ“ä½œä»»åŠ¡ã€‚

**å…³é”®è®¾è®¡**ï¼šDAPé‡‡ç”¨Flow Matchingä½œä¸ºç­–ç•¥å’ŒåŠ¨åŠ›å­¦æ¨¡å‹ä¹‹é—´çš„è¿æ¥æœºåˆ¶ã€‚Flow Matchingçš„ç›®æ ‡æ˜¯å­¦ä¹ ä¸€ä¸ªå‘é‡åœºï¼Œä½¿å¾—ä»ä»»æ„çŠ¶æ€å‡ºå‘ï¼Œæ²¿ç€è¯¥å‘é‡åœºè¿åŠ¨ï¼Œæœ€ç»ˆèƒ½å¤Ÿåˆ°è¾¾ç›®æ ‡çŠ¶æ€ã€‚åœ¨DAPä¸­ï¼Œç­–ç•¥æ¨¡å‹ç”Ÿæˆçš„åŠ¨ä½œè¢«è§†ä¸ºå‘é‡åœºçš„ä¸€éƒ¨åˆ†ï¼ŒåŠ¨åŠ›å­¦æ¨¡å‹é¢„æµ‹çš„çŠ¶æ€å˜åŒ–è¢«è§†ä¸ºæ²¿ç€è¯¥å‘é‡åœºè¿åŠ¨çš„ç»“æœã€‚é€šè¿‡æœ€å°åŒ–ç­–ç•¥æ¨¡å‹ç”Ÿæˆçš„åŠ¨ä½œå’ŒåŠ¨åŠ›å­¦æ¨¡å‹é¢„æµ‹çš„çŠ¶æ€å˜åŒ–ä¹‹é—´çš„å·®å¼‚ï¼Œå¯ä»¥å®ç°ç­–ç•¥æ¨¡å‹å’ŒåŠ¨åŠ›å­¦æ¨¡å‹çš„å¯¹é½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒDAPåœ¨çœŸå®æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­ï¼Œæ³›åŒ–æ€§èƒ½ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚å°¤å…¶æ˜¯åœ¨è§†è§‰å¹²æ‰°å’Œå…‰ç…§å˜åŒ–ç­‰OODåœºæ™¯ä¸‹ï¼ŒDAPè¡¨ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§ï¼Œèƒ½å¤ŸæˆåŠŸå®Œæˆä»»åŠ¡ï¼Œè€ŒåŸºçº¿æ–¹æ³•åˆ™è¡¨ç°å‡ºæ˜æ˜¾çš„æ€§èƒ½ä¸‹é™ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†çš„å±•ç¤ºå’Œåˆ†æã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦é«˜ç²¾åº¦å’Œå¼ºæ³›åŒ–èƒ½åŠ›çš„æœºå™¨äººæ“ä½œä»»åŠ¡ï¼Œä¾‹å¦‚å·¥ä¸šè‡ªåŠ¨åŒ–ã€åŒ»ç–—æ‰‹æœ¯ã€å®¶åº­æœåŠ¡ç­‰ã€‚é€šè¿‡å­¦ä¹ åŠ¨åŠ›å­¦å¯¹é½çš„ç­–ç•¥ï¼Œæœºå™¨äººèƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”ä¸åŒçš„ç¯å¢ƒå’Œä»»åŠ¡ï¼Œæé«˜æ“ä½œçš„æ•ˆç‡å’Œå®‰å…¨æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–é¢†åŸŸï¼Œä¾‹å¦‚è‡ªåŠ¨é©¾é©¶ã€æ¸¸æˆAIç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Behavior cloning methods for robot learning suffer from poor generalization due to limited data support beyond expert demonstrations. Recent approaches leveraging video prediction models have shown promising results by learning rich spatiotemporal representations from large-scale datasets. However, these models learn action-agnostic dynamics that cannot distinguish between different control inputs, limiting their utility for precise manipulation tasks and requiring large pretraining datasets. We propose a Dynamics-Aligned Flow Matching Policy (DAP) that integrates dynamics prediction into policy learning. Our method introduces a novel architecture where policy and dynamics models provide mutual corrective feedback during action generation, enabling self-correction and improved generalization. Empirical validation demonstrates generalization performance superior to baseline methods on real-world robotic manipulation tasks, showing particular robustness in OOD scenarios including visual distractions and lighting variations.

