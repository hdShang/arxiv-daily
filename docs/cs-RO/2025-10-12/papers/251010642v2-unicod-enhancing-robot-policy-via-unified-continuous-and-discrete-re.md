---
layout: default
title: UniCoD: Enhancing Robot Policy via Unified Continuous and Discrete Representation Learning
---

# UniCoD: Enhancing Robot Policy via Unified Continuous and Discrete Representation Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.10642" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.10642v2</a>
  <a href="https://arxiv.org/pdf/2510.10642.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.10642v2" onclick="toggleFavorite(this, '2510.10642v2', 'UniCoD: Enhancing Robot Policy via Unified Continuous and Discrete Representation Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jianke Zhang, Yucheng Hu, Yanjiang Guo, Xiaoyu Chen, Yichen Liu, Wenna Chen, Chaochao Lu, Jianyu Chen

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-10-12 (æ›´æ–°: 2025-11-04)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**UniCoDï¼šé€šè¿‡ç»Ÿä¸€è¿ç»­å’Œç¦»æ•£è¡¨ç¤ºå­¦ä¹ å¢å¼ºæœºå™¨äººç­–ç•¥**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æœºå™¨äººç­–ç•¥å­¦ä¹ ` `è§†è§‰è¯­è¨€æ¨¡å‹` `è§†è§‰ç”Ÿæˆæ¨¡å‹` `ç»Ÿä¸€æ¨¡å‹` `é¢„è®­ç»ƒ` `è¿ç»­ç¦»æ•£è¡¨ç¤º` `å…·èº«æ™ºèƒ½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰é€šç”¨æœºå™¨äººç­–ç•¥ä¾èµ–è§†è§‰-è¯­è¨€æˆ–ç”Ÿæˆæ¨¡å‹ï¼Œç¼ºä¹åŒæ—¶ç†è§£è¯­ä¹‰å’Œå»ºæ¨¡è§†è§‰åŠ¨æ€çš„èƒ½åŠ›ã€‚
2. UniCoDé€šè¿‡å¤§è§„æ¨¡æ•™å­¦è§†é¢‘é¢„è®­ç»ƒï¼Œå­¦ä¹ åŠ¨æ€å»ºæ¨¡é«˜ç»´è§†è§‰ç‰¹å¾ï¼Œèåˆç†è§£ã€è§„åˆ’å’Œè¿ç»­è¡¨ç¤ºå­¦ä¹ ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒUniCoDåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ä¸–ç•Œä»»åŠ¡ä¸­ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ï¼Œåˆ†åˆ«æå‡9%å’Œ12%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ„å»ºèƒ½å¤Ÿå¤„ç†å¼€æ”¾ç¯å¢ƒä¸­å¤šæ ·åŒ–ä»»åŠ¡çš„é€šç”¨æœºå™¨äººç­–ç•¥æ˜¯æœºå™¨äººé¢†åŸŸçš„æ ¸å¿ƒæŒ‘æˆ˜ã€‚ä¸ºäº†åˆ©ç”¨å¤§è§„æ¨¡é¢„è®­ç»ƒçš„çŸ¥è¯†ï¼Œå…ˆå‰çš„å·¥ä½œé€šå¸¸åŸºäºè§†è§‰-è¯­è¨€ç†è§£æ¨¡å‹æˆ–ç”Ÿæˆæ¨¡å‹æ„å»ºé€šç”¨ç­–ç•¥ã€‚ç„¶è€Œï¼Œæ¥è‡ªè§†è§‰-è¯­è¨€é¢„è®­ç»ƒçš„è¯­ä¹‰ç†è§£å’Œæ¥è‡ªè§†è§‰ç”Ÿæˆé¢„è®­ç»ƒçš„è§†è§‰åŠ¨åŠ›å­¦å»ºæ¨¡å¯¹äºå…·èº«æœºå™¨äººè‡³å…³é‡è¦ã€‚æœ€è¿‘çš„ç”Ÿæˆå’Œç†è§£çš„ç»Ÿä¸€æ¨¡å‹å·²ç»è¯æ˜äº†é€šè¿‡å¤§è§„æ¨¡é¢„è®­ç»ƒåœ¨ç†è§£å’Œç”Ÿæˆæ–¹é¢çš„å¼ºå¤§èƒ½åŠ›ã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œæœºå™¨äººç­–ç•¥å­¦ä¹ åŒæ ·å¯ä»¥å—ç›Šäºç†è§£ã€è§„åˆ’å’Œè¿ç»­æœªæ¥è¡¨ç¤ºå­¦ä¹ çš„ç»“åˆä¼˜åŠ¿ã€‚åŸºäºè¿™ä¸€æ´å¯Ÿï¼Œæˆ‘ä»¬å¼•å…¥äº†UniCoDï¼Œå®ƒé€šè¿‡åœ¨è¶…è¿‡100ä¸‡ä¸ªäº’è”ç½‘è§„æ¨¡çš„æ•™å­¦æ“ä½œè§†é¢‘ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œè·å¾—äº†åŠ¨æ€å»ºæ¨¡é«˜ç»´è§†è§‰ç‰¹å¾çš„èƒ½åŠ›ã€‚éšåï¼ŒUniCoDåœ¨ä»æœºå™¨äººembodimentæ”¶é›†çš„æ•°æ®ä¸Šè¿›è¡Œå¾®è°ƒï¼Œä»è€Œèƒ½å¤Ÿå­¦ä¹ ä»é¢„æµ‹è¡¨ç¤ºåˆ°åŠ¨ä½œtokençš„æ˜ å°„ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æ¨¡æ‹Ÿç¯å¢ƒå’ŒçœŸå®ä¸–ç•Œåˆ†å¸ƒå¤–ä»»åŠ¡ä¸­å§‹ç»ˆä¼˜äºåŸºçº¿æ–¹æ³•ï¼Œåˆ†åˆ«æé«˜äº†9%å’Œ12%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æœºå™¨äººç­–ç•¥å­¦ä¹ æ–¹æ³•é€šå¸¸ä¾èµ–äºè§†è§‰-è¯­è¨€æ¨¡å‹æˆ–ç”Ÿæˆæ¨¡å‹ï¼Œä½†å‰è€…ç¼ºä¹å¯¹è§†è§‰åŠ¨æ€çš„å»ºæ¨¡èƒ½åŠ›ï¼Œåè€…åˆ™ç¼ºä¹å¯¹è¯­ä¹‰ä¿¡æ¯çš„ç†è§£ã€‚å› æ­¤ï¼Œå¦‚ä½•åŒæ—¶åˆ©ç”¨å¤§è§„æ¨¡é¢„è®­ç»ƒçš„è¯­ä¹‰ç†è§£å’Œè§†è§‰åŠ¨åŠ›å­¦å»ºæ¨¡èƒ½åŠ›ï¼Œæ„å»ºæ›´å¼ºå¤§çš„é€šç”¨æœºå™¨äººç­–ç•¥ï¼Œæ˜¯ä¸€ä¸ªäºŸå¾…è§£å†³çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šUniCoDçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨ç»Ÿä¸€çš„è¿ç»­å’Œç¦»æ•£è¡¨ç¤ºå­¦ä¹ æ¡†æ¶ï¼Œå°†è§†è§‰-è¯­è¨€ç†è§£å’Œè§†è§‰ç”Ÿæˆå»ºæ¨¡ç›¸ç»“åˆã€‚é€šè¿‡åœ¨å¤§è§„æ¨¡æ•™å­¦è§†é¢‘ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼ŒUniCoDèƒ½å¤Ÿå­¦ä¹ åˆ°åŠ¨æ€å»ºæ¨¡é«˜ç»´è§†è§‰ç‰¹å¾çš„èƒ½åŠ›ï¼Œä»è€Œæ›´å¥½åœ°ç†è§£ç¯å¢ƒå¹¶é¢„æµ‹æœªæ¥çŠ¶æ€ã€‚ç„¶åï¼Œé€šè¿‡åœ¨æœºå™¨äººæ•°æ®ä¸Šè¿›è¡Œå¾®è°ƒï¼ŒUniCoDå¯ä»¥å°†é¢„æµ‹çš„è§†è§‰è¡¨ç¤ºæ˜ å°„åˆ°å…·ä½“çš„åŠ¨ä½œtokenï¼Œä»è€Œå®ç°ç­–ç•¥å­¦ä¹ ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šUniCoDçš„æ•´ä½“æ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šé¢„è®­ç»ƒé˜¶æ®µå’Œå¾®è°ƒé˜¶æ®µã€‚åœ¨é¢„è®­ç»ƒé˜¶æ®µï¼ŒUniCoDä½¿ç”¨å¤§é‡çš„äº’è”ç½‘æ•™å­¦è§†é¢‘è¿›è¡Œè®­ç»ƒï¼Œå­¦ä¹ è§†è§‰ç‰¹å¾çš„åŠ¨æ€å»ºæ¨¡èƒ½åŠ›ã€‚åœ¨å¾®è°ƒé˜¶æ®µï¼ŒUniCoDä½¿ç”¨ä»æœºå™¨äººæ”¶é›†çš„æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œå­¦ä¹ ä»é¢„æµ‹çš„è§†è§‰è¡¨ç¤ºåˆ°åŠ¨ä½œtokençš„æ˜ å°„ã€‚è¯¥æ¡†æ¶åˆ©ç”¨Transformeræ¶æ„ä½œä¸ºæ ¸å¿ƒç»„ä»¶ï¼Œå¤„ç†è§†è§‰è¾“å…¥å¹¶ç”ŸæˆåŠ¨ä½œåºåˆ—ã€‚

**å…³é”®åˆ›æ–°**ï¼šUniCoDçš„å…³é”®åˆ›æ–°åœ¨äºå…¶ç»Ÿä¸€çš„è¿ç»­å’Œç¦»æ•£è¡¨ç¤ºå­¦ä¹ æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤ŸåŒæ—¶åˆ©ç”¨è§†è§‰-è¯­è¨€ç†è§£å’Œè§†è§‰ç”Ÿæˆå»ºæ¨¡çš„ä¼˜åŠ¿ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒUniCoDèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ç¯å¢ƒå¹¶é¢„æµ‹æœªæ¥çŠ¶æ€ï¼Œä»è€Œå®ç°æ›´å¼ºå¤§çš„é€šç”¨æœºå™¨äººç­–ç•¥ã€‚æ­¤å¤–ï¼ŒUniCoDé€šè¿‡åœ¨å¤§è§„æ¨¡æ•™å­¦è§†é¢‘ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨äº’è”ç½‘ä¸Šçš„æµ·é‡æ•°æ®ï¼Œä»è€Œæé«˜ç­–ç•¥å­¦ä¹ çš„æ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šUniCoDçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨Transformeræ¶æ„ä½œä¸ºæ ¸å¿ƒç»„ä»¶ï¼Œå¤„ç†è§†è§‰è¾“å…¥å¹¶ç”ŸæˆåŠ¨ä½œåºåˆ—ï¼›2) è®¾è®¡äº†ä¸€ç§æ–°çš„æŸå¤±å‡½æ•°ï¼Œç”¨äºåœ¨å¤§è§„æ¨¡æ•™å­¦è§†é¢‘ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œè¯¥æŸå¤±å‡½æ•°èƒ½å¤Ÿæœ‰æ•ˆåœ°å­¦ä¹ è§†è§‰ç‰¹å¾çš„åŠ¨æ€å»ºæ¨¡èƒ½åŠ›ï¼›3) ä½¿ç”¨äº†ä¸€ç§æ–°çš„å¾®è°ƒç­–ç•¥ï¼Œç”¨äºå°†é¢„æµ‹çš„è§†è§‰è¡¨ç¤ºæ˜ å°„åˆ°åŠ¨ä½œtokenï¼Œè¯¥ç­–ç•¥èƒ½å¤Ÿæœ‰æ•ˆåœ°æé«˜ç­–ç•¥å­¦ä¹ çš„æ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

UniCoDåœ¨æ¨¡æ‹Ÿç¯å¢ƒå’ŒçœŸå®ä¸–ç•Œåˆ†å¸ƒå¤–ä»»åŠ¡ä¸­å‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­ï¼ŒUniCoDçš„æ€§èƒ½æ¯”åŸºçº¿æ–¹æ³•æé«˜äº†9%ã€‚åœ¨çœŸå®ä¸–ç•Œåˆ†å¸ƒå¤–ä»»åŠ¡ä¸­ï¼ŒUniCoDçš„æ€§èƒ½æ¯”åŸºçº¿æ–¹æ³•æé«˜äº†12%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒUniCoDèƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨å¤§è§„æ¨¡é¢„è®­ç»ƒçš„çŸ¥è¯†ï¼Œå¹¶å°†å…¶è¿ç§»åˆ°æ–°çš„ä»»åŠ¡ä¸­ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

UniCoDå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯ç”¨äºå¼€å‘èƒ½å¤Ÿæ‰§è¡Œå„ç§ä»»åŠ¡çš„é€šç”¨æœºå™¨äººã€‚ä¾‹å¦‚ï¼Œå®ƒå¯ä»¥åº”ç”¨äºå®¶åº­æœåŠ¡æœºå™¨äººï¼Œä½¿å…¶èƒ½å¤Ÿç†è§£äººç±»æŒ‡ä»¤å¹¶æ‰§è¡Œå„ç§å®¶åŠ¡ä»»åŠ¡ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜å¯ä»¥åº”ç”¨äºå·¥ä¸šæœºå™¨äººï¼Œä½¿å…¶èƒ½å¤Ÿé€‚åº”ä¸åŒçš„ç”Ÿäº§ç¯å¢ƒå¹¶æ‰§è¡Œå¤æ‚çš„è£…é…ä»»åŠ¡ã€‚è¯¥ç ”ç©¶çš„çªç ´å°†åŠ é€Ÿæœºå™¨äººæ™ºèƒ½åŒ–è¿›ç¨‹ï¼Œæ¨åŠ¨æœºå™¨äººæŠ€æœ¯åœ¨å„è¡Œå„ä¸šçš„å¹¿æ³›åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Building generalist robot policies that can handle diverse tasks in open-ended environments is a central challenge in robotics. To leverage knowledge from large-scale pretraining, prior work (VLA) has typically built generalist policies either on top of vision-language understanding models (VLMs) or generative models. However, both semantic understanding from vision-language pretraining and visual dynamics modeling from visual-generation pretraining are crucial for embodied robots. Recent unified models of generation and understanding have demonstrated strong capabilities in both comprehension and generation through large-scale pretraining. We posit that robotic policy learning can likewise benefit from the combined strengths of understanding, planning, and continuous future representation learning. Building on this insight, we introduce UniCoD, which acquires the ability to dynamically model high-dimensional visual features through pretraining on over 1M internet-scale instructional manipulation videos. Subsequently, UniCoD is fine-tuned on data collected from the robot embodiment, enabling the learning of mappings from predictive representations to action tokens. Extensive experiments show our approach consistently outperforms baseline methods in terms of 9\% and 12\% across simulation environments and real-world out-of-distribution tasks.

