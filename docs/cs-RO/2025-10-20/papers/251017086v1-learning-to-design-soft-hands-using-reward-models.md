---
layout: default
title: Learning to Design Soft Hands using Reward Models
---

# Learning to Design Soft Hands using Reward Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.17086" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.17086v1</a>
  <a href="https://arxiv.org/pdf/2510.17086.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.17086v1" onclick="toggleFavorite(this, '2510.17086v1', 'Learning to Design Soft Hands using Reward Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xueqian Bai, Nicklas Hansen, Adabhav Singh, Michael T. Tolley, Yan Duan, Pieter Abbeel, Xiaolong Wang, Sha Yi

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-10-20

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå¥–åŠ±æ¨¡å‹çš„äº¤å‰ç†µæ–¹æ³•ï¼Œé«˜æ•ˆä¼˜åŒ–æŸ”æ€§æ‰‹çˆªè®¾è®¡ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `æŸ”æ€§æœºå™¨äºº` `æ‰‹çˆªè®¾è®¡` `å¥–åŠ±æ¨¡å‹` `äº¤å‰ç†µæ–¹æ³•` `ååŒè®¾è®¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æŸ”æ€§æ‰‹çˆªè®¾è®¡é¢ä¸´é«˜ç»´æœç´¢ç©ºé—´å’Œæ˜‚è´µè®¡ç®—è¯„ä¼°çš„æŒ‘æˆ˜ï¼Œéš¾ä»¥åœ¨å…¼å®¹æ€§å’ŒåŠŸèƒ½æ€§ä¹‹é—´å–å¾—å¹³è¡¡ã€‚
2. æå‡ºåŸºäºå¥–åŠ±æ¨¡å‹çš„äº¤å‰ç†µæ–¹æ³•ï¼ˆCEM-RMï¼‰ï¼Œåˆ©ç”¨é¥æ“ä½œæ•°æ®å­¦ä¹ ä¼˜åŒ–æ‰‹çˆªè®¾è®¡åˆ†å¸ƒï¼Œå‡å°‘è®¾è®¡è¯„ä¼°æ¬¡æ•°ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œä¼˜åŒ–åçš„æ‰‹çˆªåœ¨ä»¿çœŸå’ŒçœŸå®ç¯å¢ƒä¸­ï¼Œå¯¹å„ç§ç‰©ä½“çš„æŠ“å–æˆåŠŸç‡æ˜¾è‘—ä¼˜äºåŸºçº¿æ‰‹çˆªã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æŸ”æ€§æœºæ¢°æ‰‹æœ‰æœ›æä¾›ä¸ç‰©ä½“å’Œç¯å¢ƒçš„å…¼å®¹ä¸”å®‰å…¨çš„äº¤äº’ã€‚ç„¶è€Œï¼Œè®¾è®¡åœ¨å„ç§ç”¨ä¾‹ä¸­æ—¢å…¼å®¹åˆå®ç”¨çš„æŸ”æ€§æ‰‹çˆªä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ç¡¬ä»¶å’Œæ§åˆ¶çš„ååŒè®¾è®¡è™½ç„¶èƒ½æ›´å¥½åœ°å°†å½¢æ€ä¸è¡Œä¸ºç»“åˆèµ·æ¥ï¼Œä½†ç”±æ­¤äº§ç”Ÿçš„æœç´¢ç©ºé—´æ˜¯é«˜ç»´çš„ï¼Œå³ä½¿æ˜¯åŸºäºä»¿çœŸçš„è¯„ä¼°ä¹Ÿéœ€è¦å¤§é‡çš„è®¡ç®—ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¥–åŠ±æ¨¡å‹çš„äº¤å‰ç†µæ–¹æ³•ï¼ˆCEM-RMï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åŸºäºé¥æ“ä½œæ§åˆ¶ç­–ç•¥æœ‰æ•ˆåœ°ä¼˜åŒ–äº†è‚Œè…±é©±åŠ¨çš„æŸ”æ€§æœºæ¢°æ‰‹ï¼Œä¸çº¯ä¼˜åŒ–ç›¸æ¯”ï¼Œè®¾è®¡è¯„ä¼°å‡å°‘äº†ä¸€åŠä»¥ä¸Šï¼ŒåŒæ—¶ä»é¢„å…ˆæ”¶é›†çš„é¥æ“ä½œæ•°æ®ä¸­å­¦ä¹ ä¼˜åŒ–æ‰‹çˆªè®¾è®¡çš„åˆ†å¸ƒã€‚æˆ‘ä»¬æ¨å¯¼äº†ç”±å¼¯æ›²æŸ”æ€§æ‰‹æŒ‡ç»„æˆçš„æŸ”æ€§æœºæ¢°æ‰‹çš„è®¾è®¡ç©ºé—´ï¼Œå¹¶åœ¨ä»¿çœŸä¸­å®ç°äº†å¹¶è¡Œè®­ç»ƒã€‚ç„¶åï¼Œä½¿ç”¨é¥æ“ä½œæ•°æ®å’Œå®æ—¶é¥æ“ä½œï¼Œå°†ä¼˜åŒ–åçš„æ‰‹çˆªè¿›è¡Œ3Dæ‰“å°å¹¶åœ¨ç°å®ä¸–ç•Œä¸­éƒ¨ç½²ã€‚åœ¨ä»¿çœŸå’Œç¡¬ä»¶ä¸­çš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬ä¼˜åŒ–åçš„è®¾è®¡åœ¨å„ç§å…·æœ‰æŒ‘æˆ˜æ€§çš„ç‰©ä½“ä¸Šçš„æŠ“å–æˆåŠŸç‡æ˜æ˜¾ä¼˜äºåŸºçº¿æ‰‹çˆªã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æŸ”æ€§æ‰‹çˆªè®¾è®¡ä¸­ï¼Œå¦‚ä½•åœ¨ä¿è¯å…¼å®¹æ€§çš„å‰æä¸‹ï¼Œæå‡å…¶åœ¨å¤šæ ·åŒ–ä»»åŠ¡ä¸­çš„åŠŸèƒ½æ€§ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚çº¯ä¼˜åŒ–ç®—æ³•ï¼Œé¢ä¸´ç€é«˜ç»´è®¾è®¡ç©ºé—´å’Œæ˜‚è´µçš„ä»¿çœŸè¯„ä¼°æˆæœ¬ï¼Œéš¾ä»¥é«˜æ•ˆåœ°æœç´¢åˆ°æœ€ä¼˜è®¾è®¡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨é¢„å…ˆæ”¶é›†çš„é¥æ“ä½œæ•°æ®å­¦ä¹ ä¸€ä¸ªå¥–åŠ±æ¨¡å‹ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿé¢„æµ‹ä¸åŒæ‰‹çˆªè®¾è®¡çš„æ€§èƒ½ã€‚ç„¶åï¼Œä½¿ç”¨äº¤å‰ç†µæ–¹æ³•ï¼ˆCEMï¼‰ä¼˜åŒ–æ‰‹çˆªè®¾è®¡ï¼Œå…¶ä¸­å¥–åŠ±æ¨¡å‹ä½œä¸ºè¯„ä¼°å‡½æ•°ï¼Œä»è€Œå‡å°‘äº†å¯¹æ˜‚è´µä»¿çœŸè¯„ä¼°çš„ä¾èµ–ã€‚è¿™ç§æ–¹æ³•å°†æ•°æ®é©±åŠ¨çš„å­¦ä¹ ä¸ä¼˜åŒ–ç®—æ³•ç›¸ç»“åˆï¼Œæé«˜äº†è®¾è®¡æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCEM-RMæ¡†æ¶åŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) æ•°æ®æ”¶é›†ï¼šé€šè¿‡é¥æ“ä½œæ”¶é›†æ‰‹çˆªä¸å„ç§ç‰©ä½“çš„äº¤äº’æ•°æ®ã€‚2) å¥–åŠ±æ¨¡å‹è®­ç»ƒï¼šåˆ©ç”¨æ”¶é›†çš„æ•°æ®è®­ç»ƒä¸€ä¸ªå¥–åŠ±æ¨¡å‹ï¼Œè¯¥æ¨¡å‹é¢„æµ‹ç»™å®šæ‰‹çˆªè®¾è®¡å’Œæ§åˆ¶ç­–ç•¥ä¸‹çš„æŠ“å–æˆåŠŸç‡ã€‚3) äº¤å‰ç†µä¼˜åŒ–ï¼šä½¿ç”¨CEMç®—æ³•ä¼˜åŒ–æ‰‹çˆªè®¾è®¡ï¼Œå…¶ä¸­å¥–åŠ±æ¨¡å‹ä½œä¸ºè¯„ä¼°å‡½æ•°ã€‚CEMç®—æ³•è¿­ä»£åœ°æ›´æ–°æ‰‹çˆªè®¾è®¡åˆ†å¸ƒï¼Œä½¿å…¶å‘å¥–åŠ±æ›´é«˜çš„åŒºåŸŸç§»åŠ¨ã€‚4) ç¡¬ä»¶éƒ¨ç½²ï¼šå°†ä¼˜åŒ–åçš„æ‰‹çˆªè¿›è¡Œ3Dæ‰“å°ï¼Œå¹¶åœ¨çœŸå®ç¯å¢ƒä¸­è¿›è¡Œæµ‹è¯•ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†å¥–åŠ±æ¨¡å‹ä¸äº¤å‰ç†µæ–¹æ³•ç›¸ç»“åˆï¼Œç”¨äºæŸ”æ€§æ‰‹çˆªçš„ååŒè®¾è®¡ã€‚ä¸ä¼ ç»Ÿçš„ä¼˜åŒ–æ–¹æ³•ç›¸æ¯”ï¼ŒCEM-RMèƒ½å¤Ÿåˆ©ç”¨é¢„å…ˆæ”¶é›†çš„æ•°æ®ï¼Œå­¦ä¹ ä¸€ä¸ªä»£ç†æ¨¡å‹æ¥åŠ é€Ÿè®¾è®¡è¯„ä¼°ï¼Œä»è€Œæ˜¾è‘—å‡å°‘äº†è®¡ç®—æˆæœ¬ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿå­¦ä¹ æ‰‹çˆªè®¾è®¡çš„åˆ†å¸ƒï¼Œè€Œä¸ä»…ä»…æ˜¯å•ä¸ªæœ€ä¼˜è®¾è®¡ï¼Œä»è€Œæé«˜äº†è®¾è®¡çš„é²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­ï¼Œæ‰‹çˆªçš„è®¾è®¡ç©ºé—´åŒ…æ‹¬æ‰‹æŒ‡çš„å¼¯æ›²åº¦ã€è‚Œè…±çš„è¿æ¥ä½ç½®ç­‰å‚æ•°ã€‚å¥–åŠ±æ¨¡å‹é‡‡ç”¨ç¥ç»ç½‘ç»œç»“æ„ï¼Œè¾“å…¥ä¸ºæ‰‹çˆªè®¾è®¡å‚æ•°å’Œé¥æ“ä½œæ§åˆ¶ç­–ç•¥ï¼Œè¾“å‡ºä¸ºæŠ“å–æˆåŠŸç‡çš„é¢„æµ‹å€¼ã€‚CEMç®—æ³•ä½¿ç”¨é«˜æ–¯åˆ†å¸ƒæ¥è¡¨ç¤ºæ‰‹çˆªè®¾è®¡åˆ†å¸ƒï¼Œå¹¶è¿­ä»£åœ°æ›´æ–°é«˜æ–¯åˆ†å¸ƒçš„å‡å€¼å’Œæ–¹å·®ã€‚æŸå¤±å‡½æ•°é‡‡ç”¨å‡æ–¹è¯¯å·®æŸå¤±ï¼Œç”¨äºè®­ç»ƒå¥–åŠ±æ¨¡å‹ã€‚ä»¿çœŸç¯å¢ƒä½¿ç”¨MuJoCoç‰©ç†å¼•æ“ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒCEM-RMæ–¹æ³•èƒ½å¤Ÿæ˜¾è‘—æé«˜æŸ”æ€§æ‰‹çˆªçš„æŠ“å–æˆåŠŸç‡ã€‚åœ¨ä»¿çœŸç¯å¢ƒä¸­ï¼Œä¼˜åŒ–åçš„æ‰‹çˆªåœ¨æŠ“å–å„ç§å…·æœ‰æŒ‘æˆ˜æ€§çš„ç‰©ä½“æ—¶ï¼ŒæˆåŠŸç‡æ¯”åŸºçº¿æ‰‹çˆªæé«˜äº†çº¦20%ã€‚åœ¨çœŸå®ç¯å¢ƒä¸­ï¼Œä¼˜åŒ–åçš„æ‰‹çˆªä¹Ÿè¡¨ç°å‡ºæ›´é«˜çš„æŠ“å–æˆåŠŸç‡å’Œé²æ£’æ€§ã€‚æ­¤å¤–ï¼ŒCEM-RMæ–¹æ³•èƒ½å¤Ÿå°†è®¾è®¡è¯„ä¼°æ¬¡æ•°å‡å°‘ä¸€åŠä»¥ä¸Šï¼Œæ˜¾è‘—æé«˜äº†è®¾è®¡æ•ˆç‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæœºå™¨äººæŠ“å–ã€äººæœºäº¤äº’ã€åŒ»ç–—åº·å¤ç­‰é¢†åŸŸã€‚ä¼˜åŒ–åçš„æŸ”æ€§æ‰‹çˆªèƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”ä¸åŒå½¢çŠ¶å’Œæè´¨çš„ç‰©ä½“ï¼Œæé«˜æŠ“å–çš„æˆåŠŸç‡å’Œå®‰å…¨æ€§ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ‰©å±•åˆ°å…¶ä»–ç±»å‹çš„æŸ”æ€§æœºå™¨äººè®¾è®¡ï¼Œä¾‹å¦‚æŸ”æ€§è…¿éƒ¨æˆ–æŸ”æ€§èº¯å¹²ï¼Œä»è€Œå®ç°æ›´å¤æ‚å’Œçµæ´»çš„æœºå™¨äººè¡Œä¸ºã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Soft robotic hands promise to provide compliant and safe interaction with objects and environments. However, designing soft hands to be both compliant and functional across diverse use cases remains challenging. Although co-design of hardware and control better couples morphology to behavior, the resulting search space is high-dimensional, and even simulation-based evaluation is computationally expensive. In this paper, we propose a Cross-Entropy Method with Reward Model (CEM-RM) framework that efficiently optimizes tendon-driven soft robotic hands based on teleoperation control policy, reducing design evaluations by more than half compared to pure optimization while learning a distribution of optimized hand designs from pre-collected teleoperation data. We derive a design space for a soft robotic hand composed of flexural soft fingers and implement parallelized training in simulation. The optimized hands are then 3D-printed and deployed in the real world using both teleoperation data and real-time teleoperation. Experiments in both simulation and hardware demonstrate that our optimized design significantly outperforms baseline hands in grasping success rates across a diverse set of challenging objects.

