---
layout: default
title: Humanoid Goalkeeper: Learning from Position Conditioned Task-Motion Constraints
---

# Humanoid Goalkeeper: Learning from Position Conditioned Task-Motion Constraints

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.18002" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.18002v1</a>
  <a href="https://arxiv.org/pdf/2510.18002.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.18002v1" onclick="toggleFavorite(this, '2510.18002v1', 'Humanoid Goalkeeper: Learning from Position Conditioned Task-Motion Constraints')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Junli Ren, Junfeng Long, Tao Huang, Huayi Wang, Zirui Wang, Feiyu Jia, Wentao Zhang, Jingbo Wang, Ping Luo, Jiangmiao Pang

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-10-20

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºä½ç½®æ¡ä»¶ä»»åŠ¡-è¿åŠ¨çº¦æŸçš„äººå½¢æœºå™¨äººå®ˆé—¨å‘˜å¼ºåŒ–å­¦ä¹ æ¡†æ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `äººå½¢æœºå™¨äºº` `å¼ºåŒ–å­¦ä¹ ` `è¿åŠ¨æ§åˆ¶` `å¯¹æŠ—å­¦ä¹ ` `äººç±»è¿åŠ¨å…ˆéªŒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. äººå½¢æœºå™¨äººå®ˆé—¨é¢ä¸´ç”Ÿæˆè‡ªç„¶è¿åŠ¨å’Œè¦†ç›–æ›´å¤§èŒƒå›´çš„æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•ä¾èµ–é¥æ“ä½œæˆ–å›ºå®šè¿åŠ¨è·Ÿè¸ªã€‚
2. è¯¥æ–¹æ³•é€šè¿‡å¼ºåŒ–å­¦ä¹ å­¦ä¹ ç«¯åˆ°ç«¯ç­–ç•¥ï¼Œå¹¶åˆ©ç”¨å¯¹æŠ—å­¦ä¹ å°†äººç±»è¿åŠ¨å…ˆéªŒçŸ¥è¯†èå…¥è®­ç»ƒä¸­ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä½¿äººå½¢æœºå™¨äººèƒ½å¤Ÿæ•æ·ã€è‡ªä¸»ä¸”è‡ªç„¶åœ°æ‹¦æˆªå¿«é€Ÿç§»åŠ¨çš„çƒï¼Œå¹¶æ³›åŒ–åˆ°å…¶ä»–ä»»åŠ¡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äºçœŸå®åœºæ™¯ä¸­äººå½¢æœºå™¨äººè‡ªä¸»å®ˆé—¨å‘˜çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ã€‚ä¸å››è¶³æœºå™¨äººç›¸æ¯”ï¼Œäººå½¢æœºå™¨äººå®ˆé—¨é¢ä¸´ä¸¤å¤§æŒ‘æˆ˜ï¼šç”Ÿæˆè‡ªç„¶ã€ç±»äººçš„å…¨èº«è¿åŠ¨ï¼Œä»¥åŠåœ¨ç›¸åŒååº”æ—¶é—´å†…è¦†ç›–æ›´å¹¿çš„é˜²å®ˆèŒƒå›´ã€‚ä¸åŒäºä¾èµ–é¥æ“ä½œæˆ–å›ºå®šè¿åŠ¨è·Ÿè¸ªçš„ç°æœ‰æ–¹æ³•ï¼Œæœ¬æ–‡æ–¹æ³•å­¦ä¹ ä¸€ä¸ªç«¯åˆ°ç«¯çš„å¼ºåŒ–å­¦ä¹ ç­–ç•¥ï¼Œå®ç°å®Œå…¨è‡ªä¸»ã€é«˜åŠ¨æ€å’Œç±»äººçš„äººæœºäº¤äº’ã€‚é€šè¿‡å¯¹æŠ—å­¦ä¹ ï¼Œæˆ‘ä»¬å°†å¤šä¸ªåŸºäºæ„ŸçŸ¥è¾“å…¥çš„äººç±»è¿åŠ¨å…ˆéªŒçŸ¥è¯†èå…¥å¼ºåŒ–å­¦ä¹ è®­ç»ƒä¸­ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿä½¿äººå½¢æœºå™¨äººæˆåŠŸã€æ•æ·ã€è‡ªä¸»ä¸”è‡ªç„¶åœ°æ‹¦æˆªå¿«é€Ÿç§»åŠ¨çš„çƒã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯æ³›åŒ–åˆ°é€ƒé€¸å’ŒæŠ“å–ç­‰ä»»åŠ¡ã€‚æœ¬ç ”ç©¶ä¸ºå®ç°æœºå™¨äººä¸è¿åŠ¨ç‰©ä½“ä¹‹é—´çš„é«˜åŠ¨æ€äº¤äº’æä¾›äº†ä¸€ç§å®ç”¨ä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆï¼Œæ¨åŠ¨æœºå™¨äººé¢†åŸŸæœç€æ›´å…·é€‚åº”æ€§å’Œæ›´é€¼çœŸçš„è¡Œä¸ºå‘å±•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³äººå½¢æœºå™¨äººåœ¨çœŸå®åœºæ™¯ä¸­è‡ªä¸»å®ˆé—¨çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äºé¥æ“ä½œæˆ–é¢„å®šä¹‰çš„å›ºå®šè¿åŠ¨æ¨¡å¼ï¼Œæ— æ³•å®ç°å®Œå…¨è‡ªä¸»ã€é«˜åŠ¨æ€å’Œç±»äººçš„è¿åŠ¨æ§åˆ¶ï¼Œå¹¶ä¸”éš¾ä»¥åº”å¯¹å¿«é€Ÿå˜åŒ–çš„ç¯å¢ƒå’Œè¦†ç›–è¾ƒå¤§çš„é˜²å®ˆèŒƒå›´ã€‚è¿™äº›æ–¹æ³•åœ¨æ³›åŒ–æ€§å’Œé€‚åº”æ€§æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è®­ç»ƒä¸€ä¸ªç«¯åˆ°ç«¯çš„ç­–ç•¥ï¼Œç›´æ¥ä»æ„ŸçŸ¥è¾“å…¥æ˜ å°„åˆ°æœºå™¨äººåŠ¨ä½œã€‚ä¸ºäº†ç”Ÿæˆè‡ªç„¶ã€ç±»äººçš„è¿åŠ¨ï¼Œè®ºæ–‡å°†äººç±»è¿åŠ¨å…ˆéªŒçŸ¥è¯†èå…¥åˆ°RLè®­ç»ƒä¸­ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæœºå™¨äººå¯ä»¥å­¦ä¹ åˆ°æ›´ç¬¦åˆäººç±»ä¹ æƒ¯çš„è¿åŠ¨æ¨¡å¼ï¼Œä»è€Œæé«˜å®ˆé—¨æ•ˆç‡å’ŒåŠ¨ä½œçš„è‡ªç„¶æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) æ„ŸçŸ¥æ¨¡å—ï¼šç”¨äºè·å–ç¯å¢ƒä¿¡æ¯ï¼Œä¾‹å¦‚çƒçš„ä½ç½®å’Œé€Ÿåº¦ï¼›2) å¼ºåŒ–å­¦ä¹ æ¨¡å—ï¼šä½¿ç”¨RLç®—æ³•è®­ç»ƒä¸€ä¸ªç­–ç•¥ç½‘ç»œï¼Œè¯¥ç½‘ç»œæ ¹æ®æ„ŸçŸ¥è¾“å…¥è¾“å‡ºæœºå™¨äººçš„åŠ¨ä½œï¼›3) äººç±»è¿åŠ¨å…ˆéªŒæ¨¡å—ï¼šæä¾›äººç±»è¿åŠ¨æ•°æ®ï¼Œç”¨äºæŒ‡å¯¼RLè®­ç»ƒï¼Œç”Ÿæˆæ›´è‡ªç„¶çš„è¿åŠ¨ï¼›4) å¯¹æŠ—å­¦ä¹ æ¨¡å—ï¼šä½¿ç”¨å¯¹æŠ—å­¦ä¹ æ–¹æ³•ï¼Œå°†äººç±»è¿åŠ¨å…ˆéªŒçŸ¥è¯†èå…¥åˆ°RLè®­ç»ƒä¸­ï¼Œä½¿å¾—æœºå™¨äººç”Ÿæˆçš„è¿åŠ¨æ›´æ¥è¿‘äººç±»è¿åŠ¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†äººç±»è¿åŠ¨å…ˆéªŒçŸ¥è¯†é€šè¿‡å¯¹æŠ—å­¦ä¹ çš„æ–¹å¼èå…¥åˆ°å¼ºåŒ–å­¦ä¹ è®­ç»ƒä¸­ã€‚è¿™ç§æ–¹æ³•ä¸åŒäºä¼ ç»Ÿçš„åŸºäºè§„åˆ™æˆ–ä¼˜åŒ–çš„è¿åŠ¨æ§åˆ¶æ–¹æ³•ï¼Œä¹Ÿä¸åŒäºç®€å•çš„æ¨¡ä»¿å­¦ä¹ ã€‚é€šè¿‡å¯¹æŠ—å­¦ä¹ ï¼Œæœºå™¨äººå¯ä»¥å­¦ä¹ åˆ°äººç±»è¿åŠ¨çš„å†…åœ¨è§„å¾‹ï¼Œä»è€Œç”Ÿæˆæ›´è‡ªç„¶ã€æ›´æœ‰æ•ˆçš„è¿åŠ¨ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­ä½¿ç”¨äº†ä½ç½®æ¡ä»¶ä»»åŠ¡-è¿åŠ¨çº¦æŸï¼ˆPosition Conditioned Task-Motion Constraintsï¼‰ã€‚å…·ä½“æ¥è¯´ï¼Œè®ºæ–‡è®¾è®¡äº†ä¸€ä¸ªå¯¹æŠ—æŸå¤±å‡½æ•°ï¼Œç”¨äºè¡¡é‡æœºå™¨äººç”Ÿæˆçš„è¿åŠ¨ä¸äººç±»è¿åŠ¨ä¹‹é—´çš„å·®å¼‚ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜è®¾è®¡äº†ä¸€ä¸ªå¥–åŠ±å‡½æ•°ï¼Œç”¨äºé¼“åŠ±æœºå™¨äººå®Œæˆå®ˆé—¨ä»»åŠ¡ã€‚ç½‘ç»œç»“æ„æ–¹é¢ï¼Œè®ºæ–‡ä½¿ç”¨äº†æ·±åº¦ç¥ç»ç½‘ç»œä½œä¸ºç­–ç•¥ç½‘ç»œï¼Œè¾“å…¥æ˜¯æ„ŸçŸ¥ä¿¡æ¯ï¼Œè¾“å‡ºæ˜¯æœºå™¨äººçš„å…³èŠ‚è§’åº¦æˆ–åŠ›çŸ©ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥ç ”ç©¶é€šè¿‡çœŸå®ä¸–ç•Œå®éªŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œäººå½¢æœºå™¨äººèƒ½å¤ŸæˆåŠŸæ‹¦æˆªå¿«é€Ÿç§»åŠ¨çš„çƒï¼Œå¹¶ä¸”åŠ¨ä½œè‡ªç„¶æµç•…ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯æ³›åŒ–åˆ°é€ƒé€¸å’ŒæŠ“å–ç­‰ä»»åŠ¡ï¼Œå±•ç¤ºäº†å…¶è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚è™½ç„¶è®ºæ–‡ä¸­æ²¡æœ‰ç»™å‡ºå…·ä½“çš„æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿ï¼Œä½†å®éªŒç»“æœè¡¨æ˜è¯¥æ–¹æ³•åœ¨äººå½¢æœºå™¨äººè‡ªä¸»è¿åŠ¨æ§åˆ¶æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºäººå½¢æœºå™¨äººåœ¨ä½“è‚²ç«æŠ€ã€å®‰ä¿å·¡é€»ã€æœæ•‘ç­‰é¢†åŸŸçš„è‡ªä¸»è¿åŠ¨æ§åˆ¶ã€‚é€šè¿‡å­¦ä¹ äººç±»è¿åŠ¨å…ˆéªŒï¼Œæœºå™¨äººèƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”å¤æ‚ç¯å¢ƒï¼Œå®Œæˆå„ç§ä»»åŠ¡ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯æ¨å¹¿åˆ°å…¶ä»–ç±»å‹æœºå™¨äººçš„è¿åŠ¨æ§åˆ¶ï¼Œä¾‹å¦‚æœåŠ¡æœºå™¨äººã€å·¥ä¸šæœºå™¨äººç­‰ï¼Œæé«˜å…¶æ™ºèƒ½åŒ–æ°´å¹³å’Œäººæœºäº¤äº’èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present a reinforcement learning framework for autonomous goalkeeping with humanoid robots in real-world scenarios. While prior work has demonstrated similar capabilities on quadrupedal platforms, humanoid goalkeeping introduces two critical challenges: (1) generating natural, human-like whole-body motions, and (2) covering a wider guarding range with an equivalent response time. Unlike existing approaches that rely on separate teleoperation or fixed motion tracking for whole-body control, our method learns a single end-to-end RL policy, enabling fully autonomous, highly dynamic, and human-like robot-object interactions. To achieve this, we integrate multiple human motion priors conditioned on perceptual inputs into the RL training via an adversarial scheme. We demonstrate the effectiveness of our method through real-world experiments, where the humanoid robot successfully performs agile, autonomous, and naturalistic interceptions of fast-moving balls. In addition to goalkeeping, we demonstrate the generalization of our approach through tasks such as ball escaping and grabbing. Our work presents a practical and scalable solution for enabling highly dynamic interactions between robots and moving objects, advancing the field toward more adaptive and lifelike robotic behaviors.

