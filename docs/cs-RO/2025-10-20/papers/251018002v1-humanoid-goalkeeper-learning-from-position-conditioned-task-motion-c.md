---
layout: default
title: Humanoid Goalkeeper: Learning from Position Conditioned Task-Motion Constraints
---

# Humanoid Goalkeeper: Learning from Position Conditioned Task-Motion Constraints

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.18002" target="_blank" class="toolbar-btn">arXiv: 2510.18002v1</a>
    <a href="https://arxiv.org/pdf/2510.18002.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.18002v1" 
            onclick="toggleFavorite(this, '2510.18002v1', 'Humanoid Goalkeeper: Learning from Position Conditioned Task-Motion Constraints')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Junli Ren, Junfeng Long, Tao Huang, Huayi Wang, Zirui Wang, Feiyu Jia, Wentao Zhang, Jingbo Wang, Ping Luo, Jiangmiao Pang

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-20

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫é‰ΩçÁΩÆÊù°‰ª∂‰ªªÂä°-ËøêÂä®Á∫¶ÊùüÁöÑ‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ÂÆàÈó®ÂëòÂº∫ÂåñÂ≠¶‰π†Ê°ÜÊû∂**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±ÂÖ´ÔºöÁâ©ÁêÜÂä®Áîª (Physics-based Animation)**

**ÂÖ≥ÈîÆËØç**: `‰∫∫ÂΩ¢Êú∫Âô®‰∫∫` `Âº∫ÂåñÂ≠¶‰π†` `ËøêÂä®ÊéßÂà∂` `ÂØπÊäóÂ≠¶‰π†` `‰∫∫Á±ªËøêÂä®ÂÖàÈ™å`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ÂÆàÈó®Èù¢‰∏¥ÁîüÊàêËá™ÁÑ∂ËøêÂä®ÂíåË¶ÜÁõñÊõ¥Â§ßËåÉÂõ¥ÁöÑÊåëÊàòÔºåÁé∞ÊúâÊñπÊ≥ï‰æùËµñÈÅ•Êìç‰ΩúÊàñÂõ∫ÂÆöËøêÂä®Ë∑üË∏™„ÄÇ
2. ËØ•ÊñπÊ≥ïÈÄöËøáÂº∫ÂåñÂ≠¶‰π†Â≠¶‰π†Á´ØÂà∞Á´ØÁ≠ñÁï•ÔºåÂπ∂Âà©Áî®ÂØπÊäóÂ≠¶‰π†Â∞Ü‰∫∫Á±ªËøêÂä®ÂÖàÈ™åÁü•ËØÜËûçÂÖ•ËÆ≠ÁªÉ‰∏≠„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåËØ•ÊñπÊ≥ï‰Ωø‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ËÉΩÂ§üÊïèÊç∑„ÄÅËá™‰∏ª‰∏îËá™ÁÑ∂Âú∞Êã¶Êà™Âø´ÈÄüÁßªÂä®ÁöÑÁêÉÔºåÂπ∂Ê≥õÂåñÂà∞ÂÖ∂‰ªñ‰ªªÂä°„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÁî®‰∫éÁúüÂÆûÂú∫ÊôØ‰∏≠‰∫∫ÂΩ¢Êú∫Âô®‰∫∫Ëá™‰∏ªÂÆàÈó®ÂëòÁöÑÂº∫ÂåñÂ≠¶‰π†Ê°ÜÊû∂„ÄÇ‰∏éÂõõË∂≥Êú∫Âô®‰∫∫Áõ∏ÊØîÔºå‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ÂÆàÈó®Èù¢‰∏¥‰∏§Â§ßÊåëÊàòÔºöÁîüÊàêËá™ÁÑ∂„ÄÅÁ±ª‰∫∫ÁöÑÂÖ®Ë∫´ËøêÂä®Ôºå‰ª•ÂèäÂú®Áõ∏ÂêåÂèçÂ∫îÊó∂Èó¥ÂÜÖË¶ÜÁõñÊõ¥ÂπøÁöÑÈò≤ÂÆàËåÉÂõ¥„ÄÇ‰∏çÂêå‰∫é‰æùËµñÈÅ•Êìç‰ΩúÊàñÂõ∫ÂÆöËøêÂä®Ë∑üË∏™ÁöÑÁé∞ÊúâÊñπÊ≥ïÔºåÊú¨ÊñáÊñπÊ≥ïÂ≠¶‰π†‰∏Ä‰∏™Á´ØÂà∞Á´ØÁöÑÂº∫ÂåñÂ≠¶‰π†Á≠ñÁï•ÔºåÂÆûÁé∞ÂÆåÂÖ®Ëá™‰∏ª„ÄÅÈ´òÂä®ÊÄÅÂíåÁ±ª‰∫∫ÁöÑ‰∫∫Êú∫‰∫§‰∫í„ÄÇÈÄöËøáÂØπÊäóÂ≠¶‰π†ÔºåÊàë‰ª¨Â∞ÜÂ§ö‰∏™Âü∫‰∫éÊÑüÁü•ËæìÂÖ•ÁöÑ‰∫∫Á±ªËøêÂä®ÂÖàÈ™åÁü•ËØÜËûçÂÖ•Âº∫ÂåñÂ≠¶‰π†ËÆ≠ÁªÉ‰∏≠„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïËÉΩÂ§ü‰Ωø‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ÊàêÂäü„ÄÅÊïèÊç∑„ÄÅËá™‰∏ª‰∏îËá™ÁÑ∂Âú∞Êã¶Êà™Âø´ÈÄüÁßªÂä®ÁöÑÁêÉ„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïËøòÂèØÊ≥õÂåñÂà∞ÈÄÉÈÄ∏ÂíåÊäìÂèñÁ≠â‰ªªÂä°„ÄÇÊú¨Á†îÁ©∂‰∏∫ÂÆûÁé∞Êú∫Âô®‰∫∫‰∏éËøêÂä®Áâ©‰Ωì‰πãÈó¥ÁöÑÈ´òÂä®ÊÄÅ‰∫§‰∫íÊèê‰æõ‰∫Ü‰∏ÄÁßçÂÆûÁî®‰∏îÂèØÊâ©Â±ïÁöÑËß£ÂÜ≥ÊñπÊ°àÔºåÊé®Âä®Êú∫Âô®‰∫∫È¢ÜÂüüÊúùÁùÄÊõ¥ÂÖ∑ÈÄÇÂ∫îÊÄßÂíåÊõ¥ÈÄºÁúüÁöÑË°å‰∏∫ÂèëÂ±ï„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥‰∫∫ÂΩ¢Êú∫Âô®‰∫∫Âú®ÁúüÂÆûÂú∫ÊôØ‰∏≠Ëá™‰∏ªÂÆàÈó®ÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ï‰∏ªË¶Å‰æùËµñ‰∫éÈÅ•Êìç‰ΩúÊàñÈ¢ÑÂÆö‰πâÁöÑÂõ∫ÂÆöËøêÂä®Ê®°ÂºèÔºåÊó†Ê≥ïÂÆûÁé∞ÂÆåÂÖ®Ëá™‰∏ª„ÄÅÈ´òÂä®ÊÄÅÂíåÁ±ª‰∫∫ÁöÑËøêÂä®ÊéßÂà∂ÔºåÂπ∂‰∏îÈöæ‰ª•Â∫îÂØπÂø´ÈÄüÂèòÂåñÁöÑÁéØÂ¢ÉÂíåË¶ÜÁõñËæÉÂ§ßÁöÑÈò≤ÂÆàËåÉÂõ¥„ÄÇËøô‰∫õÊñπÊ≥ïÂú®Ê≥õÂåñÊÄßÂíåÈÄÇÂ∫îÊÄßÊñπÈù¢Â≠òÂú®Â±ÄÈôêÊÄß„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Âº∫ÂåñÂ≠¶‰π†ÔºàRLÔºâËÆ≠ÁªÉ‰∏Ä‰∏™Á´ØÂà∞Á´ØÁöÑÁ≠ñÁï•ÔºåÁõ¥Êé•‰ªéÊÑüÁü•ËæìÂÖ•Êò†Â∞ÑÂà∞Êú∫Âô®‰∫∫Âä®‰Ωú„ÄÇ‰∏∫‰∫ÜÁîüÊàêËá™ÁÑ∂„ÄÅÁ±ª‰∫∫ÁöÑËøêÂä®ÔºåËÆ∫ÊñáÂ∞Ü‰∫∫Á±ªËøêÂä®ÂÖàÈ™åÁü•ËØÜËûçÂÖ•Âà∞RLËÆ≠ÁªÉ‰∏≠„ÄÇÈÄöËøáËøôÁßçÊñπÂºèÔºåÊú∫Âô®‰∫∫ÂèØ‰ª•Â≠¶‰π†Âà∞Êõ¥Á¨¶Âêà‰∫∫Á±ª‰π†ÊÉØÁöÑËøêÂä®Ê®°ÂºèÔºå‰ªéËÄåÊèêÈ´òÂÆàÈó®ÊïàÁéáÂíåÂä®‰ΩúÁöÑËá™ÁÑ∂ÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) ÊÑüÁü•Ê®°ÂùóÔºöÁî®‰∫éËé∑ÂèñÁéØÂ¢É‰ø°ÊÅØÔºå‰æãÂ¶ÇÁêÉÁöÑ‰ΩçÁΩÆÂíåÈÄüÂ∫¶Ôºõ2) Âº∫ÂåñÂ≠¶‰π†Ê®°ÂùóÔºö‰ΩøÁî®RLÁÆóÊ≥ïËÆ≠ÁªÉ‰∏Ä‰∏™Á≠ñÁï•ÁΩëÁªúÔºåËØ•ÁΩëÁªúÊ†πÊçÆÊÑüÁü•ËæìÂÖ•ËæìÂá∫Êú∫Âô®‰∫∫ÁöÑÂä®‰ΩúÔºõ3) ‰∫∫Á±ªËøêÂä®ÂÖàÈ™åÊ®°ÂùóÔºöÊèê‰æõ‰∫∫Á±ªËøêÂä®Êï∞ÊçÆÔºåÁî®‰∫éÊåáÂØºRLËÆ≠ÁªÉÔºåÁîüÊàêÊõ¥Ëá™ÁÑ∂ÁöÑËøêÂä®Ôºõ4) ÂØπÊäóÂ≠¶‰π†Ê®°ÂùóÔºö‰ΩøÁî®ÂØπÊäóÂ≠¶‰π†ÊñπÊ≥ïÔºåÂ∞Ü‰∫∫Á±ªËøêÂä®ÂÖàÈ™åÁü•ËØÜËûçÂÖ•Âà∞RLËÆ≠ÁªÉ‰∏≠Ôºå‰ΩøÂæóÊú∫Âô®‰∫∫ÁîüÊàêÁöÑËøêÂä®Êõ¥Êé•Ëøë‰∫∫Á±ªËøêÂä®„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÂ∞Ü‰∫∫Á±ªËøêÂä®ÂÖàÈ™åÁü•ËØÜÈÄöËøáÂØπÊäóÂ≠¶‰π†ÁöÑÊñπÂºèËûçÂÖ•Âà∞Âº∫ÂåñÂ≠¶‰π†ËÆ≠ÁªÉ‰∏≠„ÄÇËøôÁßçÊñπÊ≥ï‰∏çÂêå‰∫é‰º†ÁªüÁöÑÂü∫‰∫éËßÑÂàôÊàñ‰ºòÂåñÁöÑËøêÂä®ÊéßÂà∂ÊñπÊ≥ïÔºå‰πü‰∏çÂêå‰∫éÁÆÄÂçïÁöÑÊ®°‰ªøÂ≠¶‰π†„ÄÇÈÄöËøáÂØπÊäóÂ≠¶‰π†ÔºåÊú∫Âô®‰∫∫ÂèØ‰ª•Â≠¶‰π†Âà∞‰∫∫Á±ªËøêÂä®ÁöÑÂÜÖÂú®ËßÑÂæãÔºå‰ªéËÄåÁîüÊàêÊõ¥Ëá™ÁÑ∂„ÄÅÊõ¥ÊúâÊïàÁöÑËøêÂä®„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËÆ∫Êñá‰∏≠‰ΩøÁî®‰∫Ü‰ΩçÁΩÆÊù°‰ª∂‰ªªÂä°-ËøêÂä®Á∫¶ÊùüÔºàPosition Conditioned Task-Motion ConstraintsÔºâ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåËÆ∫ÊñáËÆæËÆ°‰∫Ü‰∏Ä‰∏™ÂØπÊäóÊçüÂ§±ÂáΩÊï∞ÔºåÁî®‰∫éË°°ÈáèÊú∫Âô®‰∫∫ÁîüÊàêÁöÑËøêÂä®‰∏é‰∫∫Á±ªËøêÂä®‰πãÈó¥ÁöÑÂ∑ÆÂºÇ„ÄÇÊ≠§Â§ñÔºåËÆ∫ÊñáËøòËÆæËÆ°‰∫Ü‰∏Ä‰∏™Â•ñÂä±ÂáΩÊï∞ÔºåÁî®‰∫éÈºìÂä±Êú∫Âô®‰∫∫ÂÆåÊàêÂÆàÈó®‰ªªÂä°„ÄÇÁΩëÁªúÁªìÊûÑÊñπÈù¢ÔºåËÆ∫Êñá‰ΩøÁî®‰∫ÜÊ∑±Â∫¶Á•ûÁªèÁΩëÁªú‰Ωú‰∏∫Á≠ñÁï•ÁΩëÁªúÔºåËæìÂÖ•ÊòØÊÑüÁü•‰ø°ÊÅØÔºåËæìÂá∫ÊòØÊú∫Âô®‰∫∫ÁöÑÂÖ≥ËäÇËßíÂ∫¶ÊàñÂäõÁü©„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ËØ•Á†îÁ©∂ÈÄöËøáÁúüÂÆû‰∏ñÁïåÂÆûÈ™åÈ™åËØÅ‰∫ÜÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºå‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ËÉΩÂ§üÊàêÂäüÊã¶Êà™Âø´ÈÄüÁßªÂä®ÁöÑÁêÉÔºåÂπ∂‰∏îÂä®‰ΩúËá™ÁÑ∂ÊµÅÁïÖ„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïËøòÂèØÊ≥õÂåñÂà∞ÈÄÉÈÄ∏ÂíåÊäìÂèñÁ≠â‰ªªÂä°ÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂ËâØÂ•ΩÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇËôΩÁÑ∂ËÆ∫Êñá‰∏≠Ê≤°ÊúâÁªôÂá∫ÂÖ∑‰ΩìÁöÑÊÄßËÉΩÊï∞ÊçÆÂíåÂØπÊØîÂü∫Á∫øÔºå‰ΩÜÂÆûÈ™åÁªìÊûúË°®ÊòéËØ•ÊñπÊ≥ïÂú®‰∫∫ÂΩ¢Êú∫Âô®‰∫∫Ëá™‰∏ªËøêÂä®ÊéßÂà∂ÊñπÈù¢ÂÖ∑ÊúâÊòæËëó‰ºòÂäø„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫é‰∫∫ÂΩ¢Êú∫Âô®‰∫∫Âú®‰ΩìËÇ≤Á´ûÊäÄ„ÄÅÂÆâ‰øùÂ∑°ÈÄª„ÄÅÊêúÊïëÁ≠âÈ¢ÜÂüüÁöÑËá™‰∏ªËøêÂä®ÊéßÂà∂„ÄÇÈÄöËøáÂ≠¶‰π†‰∫∫Á±ªËøêÂä®ÂÖàÈ™åÔºåÊú∫Âô®‰∫∫ËÉΩÂ§üÊõ¥Â•ΩÂú∞ÈÄÇÂ∫îÂ§çÊùÇÁéØÂ¢ÉÔºåÂÆåÊàêÂêÑÁßç‰ªªÂä°„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïËøòÂèØÊé®ÂπøÂà∞ÂÖ∂‰ªñÁ±ªÂûãÊú∫Âô®‰∫∫ÁöÑËøêÂä®ÊéßÂà∂Ôºå‰æãÂ¶ÇÊúçÂä°Êú∫Âô®‰∫∫„ÄÅÂ∑•‰∏öÊú∫Âô®‰∫∫Á≠âÔºåÊèêÈ´òÂÖ∂Êô∫ËÉΩÂåñÊ∞¥Âπ≥Âíå‰∫∫Êú∫‰∫§‰∫íËÉΩÂäõ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> We present a reinforcement learning framework for autonomous goalkeeping with humanoid robots in real-world scenarios. While prior work has demonstrated similar capabilities on quadrupedal platforms, humanoid goalkeeping introduces two critical challenges: (1) generating natural, human-like whole-body motions, and (2) covering a wider guarding range with an equivalent response time. Unlike existing approaches that rely on separate teleoperation or fixed motion tracking for whole-body control, our method learns a single end-to-end RL policy, enabling fully autonomous, highly dynamic, and human-like robot-object interactions. To achieve this, we integrate multiple human motion priors conditioned on perceptual inputs into the RL training via an adversarial scheme. We demonstrate the effectiveness of our method through real-world experiments, where the humanoid robot successfully performs agile, autonomous, and naturalistic interceptions of fast-moving balls. In addition to goalkeeping, we demonstrate the generalization of our approach through tasks such as ball escaping and grabbing. Our work presents a practical and scalable solution for enabling highly dynamic interactions between robots and moving objects, advancing the field toward more adaptive and lifelike robotic behaviors.

