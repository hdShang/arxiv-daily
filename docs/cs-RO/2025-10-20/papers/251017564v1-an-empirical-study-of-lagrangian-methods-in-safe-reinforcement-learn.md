---
layout: default
title: An Empirical Study of Lagrangian Methods in Safe Reinforcement Learning
---

# An Empirical Study of Lagrangian Methods in Safe Reinforcement Learning

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.17564" target="_blank" class="toolbar-btn">arXiv: 2510.17564v1</a>
    <a href="https://arxiv.org/pdf/2510.17564.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.17564v1" 
            onclick="toggleFavorite(this, '2510.17564v1', 'An Empirical Study of Lagrangian Methods in Safe Reinforcement Learning')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Lindsay Spoor, √Ålvaro Serra-G√≥mez, Aske Plaat, Thomas Moerland

**ÂàÜÁ±ª**: cs.LG, cs.AI, cs.RO, eess.SY

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-20

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/lindsayspoor/Lagrangian_SafeRL)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**Á†îÁ©∂ÂÆâÂÖ®Âº∫ÂåñÂ≠¶‰π†‰∏≠ÊãâÊ†ºÊúóÊó•ÊñπÊ≥ïÁöÑŒªÊïèÊÑüÊÄß‰∏éËá™Âä®Êõ¥Êñ∞Á≠ñÁï•ÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `ÂÆâÂÖ®Âº∫ÂåñÂ≠¶‰π†` `ÊãâÊ†ºÊúóÊó•ÊñπÊ≥ï` `ÊãâÊ†ºÊúóÊó•‰πòÂ≠ê` `Á∫¶Êùü‰ºòÂåñ` `PIDÊéßÂà∂` `Œª-profiles` `Ëá™Âä®Êõ¥Êñ∞` `Á®≥ÂÆöÊÄßÂàÜÊûê`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ÂÆâÂÖ®Âº∫ÂåñÂ≠¶‰π†‰∏≠ÔºåÊãâÊ†ºÊúóÊó•ÊñπÊ≥ï‰æùËµñ‰∫éÊãâÊ†ºÊúóÊó•‰πòÂ≠êŒªÔºå‰ΩÜŒªÁöÑÊúÄ‰ºòÂÄºÈöæ‰ª•Á°ÆÂÆöÔºåÁº∫‰πèÈÄöÁî®ÈÄâÊã©Á≠ñÁï•„ÄÇ
2. ËÆ∫ÊñáÈÄöËøáŒª-profilesÂèØËßÜÂåñÂõûÊä•‰∏éÁ∫¶ÊùüÊàêÊú¨ÁöÑÊùÉË°°ÔºåÂàÜÊûê‰∫ÜËá™Âä®‰πòÂ≠êÊõ¥Êñ∞ÁöÑÊúÄ‰ºòÊÄßÂíåÁ®≥ÂÆöÊÄß„ÄÇ
3. ÂÆûÈ™åË°®ÊòéËá™Âä®‰πòÂ≠êÊõ¥Êñ∞ËÉΩÊÅ¢Â§çÁîöËá≥Ë∂ÖËøáŒª*ÁöÑÊúÄ‰ºòÊÄßËÉΩÔºå‰ΩÜÂ≠òÂú®ÊåØËç°Ë°å‰∏∫ÔºåPIDÊéßÂà∂ÂèØÁºìËß£‰ΩÜÈúÄÁ≤æÁªÜË∞ÉÂèÇ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Âú®Êú∫Âô®‰∫∫„ÄÅÂØºËà™ÂíåÁîµÂäõÁ≥ªÁªüÁ≠âÂÆâÂÖ®ÂÖ≥ÈîÆÈ¢ÜÂüüÔºåÁ∫¶Êùü‰ºòÂåñÈóÆÈ¢òÊôÆÈÅçÂ≠òÂú®ÔºåÈúÄË¶ÅÂú®ÊúÄÂ§ßÂåñÊÄßËÉΩÁöÑÂêåÊó∂‰ªîÁªÜÂπ≥Ë°°Áõ∏ÂÖ≥Á∫¶Êùü„ÄÇÂÆâÂÖ®Âº∫ÂåñÂ≠¶‰π†‰∏∫Ê≠§Êèê‰æõ‰∫Ü‰∏Ä‰∏™Ê°ÜÊû∂ÔºåËÄåÊãâÊ†ºÊúóÊó•ÊñπÊ≥ïÊòØÂ∏∏Áî®ÁöÑÈÄâÊã©„ÄÇÁÑ∂ËÄåÔºåÊãâÊ†ºÊúóÊó•ÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÂÖ≥ÈîÆÂèñÂÜ≥‰∫éÊãâÊ†ºÊúóÊó•‰πòÂ≠êŒªÁöÑÈÄâÊã©ÔºåÂÆÉÊéßÂà∂ÁùÄÂõûÊä•ÂíåÁ∫¶ÊùüÊàêÊú¨‰πãÈó¥ÁöÑÊùÉË°°„ÄÇ‰∏ÄÁßçÂ∏∏ËßÅÁöÑÊñπÊ≥ïÊòØÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠Ëá™Âä®Êõ¥Êñ∞‰πòÂ≠ê„ÄÇÂ∞ΩÁÆ°ËøôÂú®ÂÆûË∑µ‰∏≠ÂæàÂ∏∏ËßÅÔºå‰ΩÜÂÖ≥‰∫éËá™Âä®Êõ¥Êñ∞ÁöÑÈ≤ÅÊ£íÊÄßÂèäÂÖ∂ÂØπÊï¥‰ΩìÊÄßËÉΩÁöÑÂΩ±ÂìçÁöÑÁªèÈ™åËØÅÊçÆ‰ªçÁÑ∂ÊúâÈôê„ÄÇÂõ†Ê≠§ÔºåÊàë‰ª¨ÂàÜÊûê‰∫ÜÂÆâÂÖ®Âº∫ÂåñÂ≠¶‰π†‰∏≠ÊãâÊ†ºÊúóÊó•‰πòÂ≠êÁöÑ(i)ÊúÄ‰ºòÊÄßÂíå(ii)Á®≥ÂÆöÊÄßÔºåÊ∂µÁõñ‰∫Ü‰∏ÄÁ≥ªÂàó‰ªªÂä°„ÄÇÊàë‰ª¨Êèê‰æõ‰∫ÜŒª-profilesÔºåÂèØ‰ª•ÂÆåÊï¥Âú∞ÂèØËßÜÂåñ‰ºòÂåñÈóÆÈ¢ò‰∏≠ÂõûÊä•ÂíåÁ∫¶ÊùüÊàêÊú¨‰πãÈó¥ÁöÑÊùÉË°°„ÄÇËøô‰∫õprofilesÊòæÁ§∫‰∫ÜŒªÁöÑÈ´òÂ∫¶ÊïèÊÑüÊÄßÔºåÂπ∂‰∏îËØÅÂÆû‰∫ÜÈÄâÊã©ÊúÄ‰ºòÂÄºŒª*Áº∫‰πèÈÄöÁî®Áõ¥Ëßâ„ÄÇÊàë‰ª¨ÁöÑÁ†îÁ©∂ÁªìÊûúËøòË°®ÊòéÔºåÁî±‰∫éÂ≠¶‰π†ËΩ®ËøπÁöÑÂ∑®Â§ßÂ∑ÆÂºÇÔºåËá™Âä®‰πòÂ≠êÊõ¥Êñ∞ËÉΩÂ§üÊÅ¢Â§çÁîöËá≥Ë∂ÖËøáÂú®Œª*Â§ÑÊâæÂà∞ÁöÑÊúÄ‰ºòÊÄßËÉΩ„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨Ë°®ÊòéËá™Âä®‰πòÂ≠êÊõ¥Êñ∞Âú®ËÆ≠ÁªÉÊúüÈó¥Ë°®Áé∞Âá∫ÊåØËç°Ë°å‰∏∫ÔºåÂèØ‰ª•ÈÄöËøáPIDÊéßÂà∂ÁöÑÊõ¥Êñ∞Êù•ÁºìËß£„ÄÇÁÑ∂ËÄåÔºåËøôÁßçÊñπÊ≥ïÈúÄË¶Å‰ªîÁªÜË∞ÉÊï¥ÊâçËÉΩÂú®ÂêÑÈ°π‰ªªÂä°‰∏≠ÂÆûÁé∞ÂßãÁªàÂ¶Ç‰∏ÄÁöÑÊõ¥Â•ΩÊÄßËÉΩ„ÄÇËøôÁ™ÅÂá∫‰∫ÜËøõ‰∏ÄÊ≠•Á†îÁ©∂Á®≥ÂÆöÂÆâÂÖ®Âº∫ÂåñÂ≠¶‰π†‰∏≠ÊãâÊ†ºÊúóÊó•ÊñπÊ≥ïÁöÑÂøÖË¶ÅÊÄß„ÄÇÁî®‰∫éÈáçÁé∞Êàë‰ª¨ÁªìÊûúÁöÑ‰ª£Á†ÅÂèØ‰ª•Âú®https://github.com/lindsayspoor/Lagrangian_SafeRLÊâæÂà∞„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÂÆâÂÖ®Âº∫ÂåñÂ≠¶‰π†Êó®Âú®Ëß£ÂÜ≥Âú®Êª°Ë∂≥Á∫¶ÊùüÊù°‰ª∂ÁöÑÂâçÊèê‰∏ãÊúÄÂ§ßÂåñÂõûÊä•ÁöÑÈóÆÈ¢ò„ÄÇÊãâÊ†ºÊúóÊó•ÊñπÊ≥ïÊòØËß£ÂÜ≥Ê≠§Á±ªÈóÆÈ¢òÁöÑÂ∏∏Áî®ÊñπÊ≥ïÔºå‰ΩÜÂÖ∂ÊÄßËÉΩÈ´òÂ∫¶‰æùËµñ‰∫éÊãâÊ†ºÊúóÊó•‰πòÂ≠êŒªÁöÑÈÄâÊã©„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏ÈááÁî®Ëá™Âä®Êõ¥Êñ∞ŒªÁöÑÁ≠ñÁï•Ôºå‰ΩÜÁº∫‰πèÂØπËØ•Á≠ñÁï•È≤ÅÊ£íÊÄßÂíåÁ®≥ÂÆöÊÄßÁöÑÊ∑±ÂÖ•Á†îÁ©∂ÔºåÂØºËá¥Èöæ‰ª•ÈÄâÊã©ÂêàÈÄÇÁöÑŒªÂÄºÔºåÂΩ±ÂìçÊúÄÁªàÊÄßËÉΩ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÂÆûËØÅÁ†îÁ©∂ÔºåÊ∑±ÂÖ•ÂàÜÊûêÊãâÊ†ºÊúóÊó•‰πòÂ≠êŒªÂú®ÂÆâÂÖ®Âº∫ÂåñÂ≠¶‰π†‰∏≠ÁöÑË°å‰∏∫ÁâπÊÄß„ÄÇÈÄöËøáÊûÑÂª∫Œª-profilesÔºåÂèØËßÜÂåñÂõûÊä•ÂíåÁ∫¶ÊùüÊàêÊú¨‰πãÈó¥ÁöÑÊùÉË°°ÂÖ≥Á≥ªÔºåÊè≠Á§∫ŒªÁöÑÊïèÊÑüÊÄß„ÄÇÂêåÊó∂ÔºåÁ†îÁ©∂Ëá™Âä®Êõ¥Êñ∞ŒªÁ≠ñÁï•ÁöÑÁ®≥ÂÆöÊÄßÂíåÊúÄ‰ºòÊÄßÔºåÂπ∂Êé¢Á¥¢PIDÊéßÂà∂Á≠âÊñπÊ≥ïÊù•ÁºìËß£Êõ¥Êñ∞ËøáÁ®ã‰∏≠ÁöÑÊåØËç°Ë°å‰∏∫„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËÆ∫ÊñáÈááÁî®ÂÆûËØÅÁ†îÁ©∂ÁöÑÊñπÊ≥ïÔºåÂú®Â§ö‰∏™ÂÆâÂÖ®Âº∫ÂåñÂ≠¶‰π†‰ªªÂä°‰∏äËøõË°åÂÆûÈ™å„ÄÇÈ¶ñÂÖàÔºåÈÄöËøáÊâãÂä®Ë∞ÉÊï¥ŒªÂÄºÔºåÊûÑÂª∫Œª-profilesÔºåÂàÜÊûêŒªÂØπÂõûÊä•ÂíåÁ∫¶ÊùüÊàêÊú¨ÁöÑÂΩ±Âìç„ÄÇÁÑ∂ÂêéÔºåÁ†îÁ©∂Ëá™Âä®Êõ¥Êñ∞ŒªÁ≠ñÁï•ÁöÑÊÄßËÉΩÔºåÂåÖÊã¨ÂÖ∂ÊúÄ‰ºòÊÄßÂíåÁ®≥ÂÆöÊÄß„ÄÇÊúÄÂêéÔºåÂ∞ùËØï‰ΩøÁî®PIDÊéßÂà∂Êù•Âπ≥ÊªëŒªÁöÑÊõ¥Êñ∞ËøáÁ®ãÔºåÂπ∂ËØÑ‰º∞ÂÖ∂ÊïàÊûú„ÄÇÊï¥‰ΩìÊµÅÁ®ãÂåÖÊã¨ÁéØÂ¢ÉÊê≠Âª∫„ÄÅÁ≠ñÁï•ËÆ≠ÁªÉ„ÄÅÊÄßËÉΩËØÑ‰º∞ÂíåÁªìÊûúÂàÜÊûê„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂØπÂÆâÂÖ®Âº∫ÂåñÂ≠¶‰π†‰∏≠ÊãâÊ†ºÊúóÊó•ÊñπÊ≥ïÁöÑŒªÊïèÊÑüÊÄßÂíåËá™Âä®Êõ¥Êñ∞Á≠ñÁï•ÁöÑÈ≤ÅÊ£íÊÄßËøõË°å‰∫ÜÊ∑±ÂÖ•ÁöÑÂÆûËØÅÁ†îÁ©∂„ÄÇÈÄöËøáŒª-profilesÂèØËßÜÂåñ‰∫ÜŒªÂØπÊÄßËÉΩÁöÑÂΩ±ÂìçÔºåÊè≠Á§∫‰∫ÜŒªÈÄâÊã©ÁöÑÂõ∞ÈöæÊÄß„ÄÇÂêåÊó∂ÔºåÊåáÂá∫‰∫ÜËá™Âä®Êõ¥Êñ∞Á≠ñÁï•ÁöÑÊåØËç°Ë°å‰∏∫ÔºåÂπ∂Êé¢Á¥¢‰∫ÜPIDÊéßÂà∂Á≠âÊñπÊ≥ïÊù•ÁºìËß£ËØ•ÈóÆÈ¢ò„ÄÇËøô‰∫õÂèëÁé∞‰∏∫Êú™Êù•Á†îÁ©∂Á®≥ÂÆöÂíåÈ´òÊïàÁöÑÂÆâÂÖ®Âº∫ÂåñÂ≠¶‰π†ÁÆóÊ≥ïÊèê‰æõ‰∫ÜÈáçË¶ÅÁöÑÂèÇËÄÉ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) Œª-profilesÁöÑÊûÑÂª∫ÊñπÊ≥ïÔºåÈÄöËøáÂú®‰∏çÂêåŒªÂÄº‰∏ãËÆ≠ÁªÉÁ≠ñÁï•ÔºåËÆ∞ÂΩïÂõûÊä•ÂíåÁ∫¶ÊùüÊàêÊú¨Ôºå‰ªéËÄåÂèØËßÜÂåñŒªÁöÑÂΩ±Âìç„ÄÇ2) Ëá™Âä®Êõ¥Êñ∞ŒªÁ≠ñÁï•ÁöÑÂÖ∑‰ΩìÂÆûÁé∞ÔºåÂåÖÊã¨Êõ¥Êñ∞È¢ëÁéá„ÄÅÊõ¥Êñ∞Ê≠•ÈïøÁ≠âÂèÇÊï∞ÁöÑËÆæÁΩÆ„ÄÇ3) PIDÊéßÂà∂Âô®ÁöÑËÆæËÆ°ÔºåÂåÖÊã¨ÊØî‰æã„ÄÅÁßØÂàÜÂíåÂæÆÂàÜÁ≥ªÊï∞ÁöÑË∞ÉÊï¥Ôºå‰ª•ÂÆûÁé∞ÂØπŒªÊõ¥Êñ∞ËøáÁ®ãÁöÑÂπ≥Êªë„ÄÇ4) ÂÆûÈ™åÁéØÂ¢ÉÁöÑÈÄâÊã©ÔºåÊ∂µÁõñ‰∫Ü‰∏çÂêåÁ±ªÂûãÁöÑÂÆâÂÖ®Âº∫ÂåñÂ≠¶‰π†‰ªªÂä°Ôºå‰ª•ËØÑ‰º∞ÁÆóÊ≥ïÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËá™Âä®‰πòÂ≠êÊõ¥Êñ∞Á≠ñÁï•Âú®Êüê‰∫õÊÉÖÂÜµ‰∏ãËÉΩÂ§üÊÅ¢Â§çÁîöËá≥Ë∂ÖËøáÂú®ÊúÄ‰ºòŒªÂÄºŒª*Â§ÑËé∑ÂæóÁöÑÊÄßËÉΩ„ÄÇÁÑ∂ËÄåÔºåËá™Âä®Êõ¥Êñ∞ËøáÁ®ãË°®Áé∞Âá∫ÊåØËç°Ë°å‰∏∫ÔºåÈÄöËøáPIDÊéßÂà∂ÂèØ‰ª•ÁºìËß£Ôºå‰ΩÜÈúÄË¶Å‰ªîÁªÜË∞ÉÊï¥PIDÂèÇÊï∞„ÄÇŒª-profilesÊ∏ÖÊô∞Âú∞Â±ïÁ§∫‰∫ÜŒªÁöÑÊïèÊÑüÊÄßÔºåÂπ∂È™åËØÅ‰∫ÜÈÄâÊã©ÊúÄ‰ºòŒªÂÄºÁöÑÂõ∞ÈöæÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫„ÄÅËá™Âä®È©æÈ©∂„ÄÅÁîµÂäõÁ≥ªÁªüÁ≠âÂÆâÂÖ®ÂÖ≥ÈîÆÈ¢ÜÂüü„ÄÇÈÄöËøáÊõ¥Á®≥ÂÆöÂíåÈ´òÊïàÁöÑÊãâÊ†ºÊúóÊó•ÊñπÊ≥ïÔºåÂèØ‰ª•ÊèêÂçáËøô‰∫õÁ≥ªÁªüÂú®Êª°Ë∂≥ÂÆâÂÖ®Á∫¶ÊùüÁöÑÂâçÊèê‰∏ãÔºå‰ºòÂåñÊÄßËÉΩÁöÑËÉΩÂäõ„ÄÇ‰æãÂ¶ÇÔºåÂú®Ëá™Âä®È©æÈ©∂‰∏≠ÔºåÂèØ‰ª•Á°Æ‰øùËΩ¶ËæÜÂú®Ë°åÈ©∂ËøáÁ®ã‰∏≠ÈÅµÂÆà‰∫§ÈÄöËßÑÂàôÔºåÂêåÊó∂Â∞ΩÂèØËÉΩÂú∞ÊèêÈ´òË°åÈ©∂ÊïàÁéá„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> In safety-critical domains such as robotics, navigation and power systems, constrained optimization problems arise where maximizing performance must be carefully balanced with associated constraints. Safe reinforcement learning provides a framework to address these challenges, with Lagrangian methods being a popular choice. However, the effectiveness of Lagrangian methods crucially depends on the choice of the Lagrange multiplier $Œª$, which governs the trade-off between return and constraint cost. A common approach is to update the multiplier automatically during training. Although this is standard in practice, there remains limited empirical evidence on the robustness of an automated update and its influence on overall performance. Therefore, we analyze (i) optimality and (ii) stability of Lagrange multipliers in safe reinforcement learning across a range of tasks. We provide $Œª$-profiles that give a complete visualization of the trade-off between return and constraint cost of the optimization problem. These profiles show the highly sensitive nature of $Œª$ and moreover confirm the lack of general intuition for choosing the optimal value $Œª^*$. Our findings additionally show that automated multiplier updates are able to recover and sometimes even exceed the optimal performance found at $Œª^*$ due to the vast difference in their learning trajectories. Furthermore, we show that automated multiplier updates exhibit oscillatory behavior during training, which can be mitigated through PID-controlled updates. However, this method requires careful tuning to achieve consistently better performance across tasks. This highlights the need for further research on stabilizing Lagrangian methods in safe reinforcement learning. The code used to reproduce our results can be found at https://github.com/lindsayspoor/Lagrangian_SafeRL.

