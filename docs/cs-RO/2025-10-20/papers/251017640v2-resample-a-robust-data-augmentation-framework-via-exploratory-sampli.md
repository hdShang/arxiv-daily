---
layout: default
title: RESample: A Robust Data Augmentation Framework via Exploratory Sampling for Robotic Manipulation
---

# RESample: A Robust Data Augmentation Framework via Exploratory Sampling for Robotic Manipulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.17640" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.17640v2</a>
  <a href="https://arxiv.org/pdf/2510.17640.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.17640v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.17640v2', 'RESample: A Robust Data Augmentation Framework via Exploratory Sampling for Robotic Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuquan Xue, Guanxing Lu, Zhenyu Wu, Chuanrui Zhang, Bofang Jia, Zhengyi Gu, Yansong Tang, Ziwei Wang

**åˆ†ç±»**: cs.RO, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-10-20 (æ›´æ–°: 2025-10-24)

**å¤‡æ³¨**: 9 pages,7 figures, submitted to ICRA2026

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**RESampleï¼šæ¢ç´¢å¼é‡‡æ ·å¢å¼ºæœºå™¨äººæ“ä½œçš„é²æ£’æ•°æ®å¢å¼ºæ¡†æ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æœºå™¨äººæ“ä½œ` `æ¨¡ä»¿å­¦ä¹ ` `æ•°æ®å¢å¼º` `è¶…å‡ºåˆ†å¸ƒå­¦ä¹ ` `ç¦»çº¿å¼ºåŒ–å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ¨¡ä»¿å­¦ä¹ æ•°æ®é›†ç¼ºä¹å¤±è´¥å’Œæ¢å¤æ•°æ®ï¼Œå¯¼è‡´VLAæ¨¡å‹åœ¨å¤„ç†è¶…å‡ºåˆ†å¸ƒ(OOD)çŠ¶æ€æ—¶è¡¨ç°ä¸ä½³ã€‚
2. RESampleæ¡†æ¶é€šè¿‡ç¦»çº¿å¼ºåŒ–å­¦ä¹ å’Œæ¢ç´¢å¼é‡‡æ ·ï¼Œè‡ªåŠ¨ç”Ÿæˆå¹¶åˆ©ç”¨OODæ•°æ®æ¥å¢å¼ºæ¨¡å‹çš„é²æ£’æ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒRESampleèƒ½æ˜¾è‘—æå‡VLAæ¨¡å‹åœ¨LIBEROåŸºå‡†å’ŒçœŸå®æœºå™¨äººä»»åŠ¡ä¸­çš„ç¨³å®šæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹(VLA)åœ¨æ¨¡ä»¿å­¦ä¹ ä¸­å±•ç°äº†å“è¶Šçš„å¤æ‚æœºå™¨äººæ“ä½œèƒ½åŠ›ã€‚ç„¶è€Œï¼Œç°æœ‰çš„æ¨¡ä»¿å­¦ä¹ æ•°æ®é›†ä»…åŒ…å«æˆåŠŸçš„è½¨è¿¹ï¼Œç¼ºä¹å¤±è´¥æˆ–æ¢å¤æ•°æ®ï¼Œç‰¹åˆ«æ˜¯å¯¹äºè¶…å‡ºåˆ†å¸ƒ(OOD)çš„çŠ¶æ€ï¼Œå³æœºå™¨äººç”±äºå¾®å°æ‰°åŠ¨æˆ–é”™è¯¯è€Œåç¦»ä¸»è¦ç­–ç•¥çš„çŠ¶æ€ï¼Œè¿™å¯¼è‡´VLAæ¨¡å‹éš¾ä»¥å¤„ç†åç¦»è®­ç»ƒåˆ†å¸ƒçš„çŠ¶æ€ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é€šè¿‡æ¢ç´¢å¼é‡‡æ ·å®ç°çš„è‡ªåŠ¨åŒ–OODæ•°æ®å¢å¼ºæ¡†æ¶ï¼Œåä¸ºRESampleã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆåˆ©ç”¨ç¦»çº¿å¼ºåŒ–å­¦ä¹ è·å¾—ä¸€ä¸ªåŠ¨ä½œä»·å€¼ç½‘ç»œï¼Œè¯¥ç½‘ç»œèƒ½å¤Ÿå‡†ç¡®è¯†åˆ«å½“å‰æ“ä½œç­–ç•¥ä¸‹çš„æ¬¡ä¼˜åŠ¨ä½œã€‚æˆ‘ä»¬è¿›ä¸€æ­¥é€šè¿‡rolloutä»è½¨è¿¹ä¸­é‡‡æ ·æ½œåœ¨çš„OODçŠ¶æ€ï¼Œå¹¶è®¾è®¡äº†ä¸€ç§æ¢ç´¢å¼é‡‡æ ·æœºåˆ¶ï¼Œè‡ªé€‚åº”åœ°å°†è¿™äº›åŠ¨ä½œä»£ç†çº³å…¥è®­ç»ƒæ•°æ®é›†ï¼Œä»¥ç¡®ä¿æ•ˆç‡ã€‚éšåï¼Œæˆ‘ä»¬çš„æ¡†æ¶æ˜ç¡®åœ°é¼“åŠ±VLAä»OODçŠ¶æ€ä¸­æ¢å¤ï¼Œå¹¶å¢å¼ºå…¶å¯¹åˆ†å¸ƒåç§»çš„é²æ£’æ€§ã€‚æˆ‘ä»¬åœ¨LIBEROåŸºå‡†ä»¥åŠçœŸå®ä¸–ç•Œçš„æœºå™¨äººæ“ä½œä»»åŠ¡ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œè¡¨æ˜RESampleå§‹ç»ˆå¦‚ä¸€åœ°æé«˜äº†VLAæ¨¡å‹çš„ç¨³å®šæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹(VLA)åœ¨æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­ä¾èµ–æ¨¡ä»¿å­¦ä¹ ï¼Œä½†è®­ç»ƒæ•°æ®é€šå¸¸åªåŒ…å«æˆåŠŸçš„è½¨è¿¹ã€‚è¿™å¯¼è‡´æ¨¡å‹åœ¨é‡åˆ°åç¦»è®­ç»ƒåˆ†å¸ƒçš„OODçŠ¶æ€æ—¶ï¼Œç¼ºä¹æœ‰æ•ˆçš„æ¢å¤ç­–ç•¥ï¼Œé²æ£’æ€§è¾ƒå·®ã€‚å°¤å…¶æ˜¯åœ¨çœŸå®æœºå™¨äººæ“ä½œä¸­ï¼Œç”±äºå„ç§æ‰°åŠ¨ï¼ŒOODçŠ¶æ€éš¾ä»¥é¿å…ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šRESampleçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ¢ç´¢å¼é‡‡æ ·ï¼Œè‡ªåŠ¨ç”Ÿæˆå¹¶åˆ©ç”¨OODæ•°æ®æ¥å¢å¼ºVLAæ¨¡å‹çš„è®­ç»ƒã€‚å…·ä½“æ¥è¯´ï¼Œåˆ©ç”¨ç¦»çº¿å¼ºåŒ–å­¦ä¹ è®­ç»ƒä¸€ä¸ªåŠ¨ä½œä»·å€¼ç½‘ç»œï¼Œç”¨äºè¯„ä¼°å½“å‰ç­–ç•¥ä¸‹çš„åŠ¨ä½œä¼˜åŠ£ï¼Œå¹¶ä»¥æ­¤ä¸ºæŒ‡å¯¼ï¼Œåœ¨è½¨è¿¹ä¸­é‡‡æ ·å¯èƒ½å¯¼è‡´OODçŠ¶æ€çš„åŠ¨ä½œã€‚ç„¶åï¼Œå°†è¿™äº›OODçŠ¶æ€åŠ å…¥è®­ç»ƒé›†ï¼Œå¼•å¯¼æ¨¡å‹å­¦ä¹ ä»è¿™äº›çŠ¶æ€ä¸­æ¢å¤ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRESampleæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) ç¦»çº¿å¼ºåŒ–å­¦ä¹ ï¼šåˆ©ç”¨å·²æœ‰çš„æˆåŠŸè½¨è¿¹æ•°æ®ï¼Œè®­ç»ƒä¸€ä¸ªåŠ¨ä½œä»·å€¼ç½‘ç»œï¼Œç”¨äºè¯„ä¼°åŠ¨ä½œçš„ä¼˜åŠ£ã€‚2) æ¢ç´¢å¼é‡‡æ ·ï¼šé€šè¿‡rolloutç”Ÿæˆæ–°çš„è½¨è¿¹ï¼Œå¹¶åˆ©ç”¨åŠ¨ä½œä»·å€¼ç½‘ç»œè¯†åˆ«æ½œåœ¨çš„OODçŠ¶æ€ã€‚è®¾è®¡æ¢ç´¢å¼é‡‡æ ·æœºåˆ¶ï¼Œè‡ªé€‚åº”åœ°é€‰æ‹©æœ‰ä»·å€¼çš„OODçŠ¶æ€åŠ å…¥è®­ç»ƒé›†ã€‚3) æ¨¡å‹è®­ç»ƒï¼šä½¿ç”¨åŒ…å«åŸå§‹æ•°æ®å’ŒOODæ•°æ®çš„æ··åˆæ•°æ®é›†ï¼Œè®­ç»ƒVLAæ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šRESampleçš„å…³é”®åˆ›æ–°åœ¨äºå…¶è‡ªåŠ¨åŒ–çš„OODæ•°æ®ç”Ÿæˆå’Œé€‰æ‹©æœºåˆ¶ã€‚ä¸æ‰‹åŠ¨è®¾è®¡OODæ•°æ®æˆ–ç®€å•åœ°æ·»åŠ éšæœºå™ªå£°ç›¸æ¯”ï¼ŒRESampleèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å‘ç°å’Œåˆ©ç”¨å¯¹æ¨¡å‹é²æ£’æ€§æå‡æœ€æœ‰å¸®åŠ©çš„OODçŠ¶æ€ã€‚åŠ¨ä½œä»·å€¼ç½‘ç»œçš„å¼•å…¥ï¼Œä½¿å¾—é‡‡æ ·è¿‡ç¨‹æ›´åŠ æ™ºèƒ½å’Œé«˜æ•ˆã€‚

**å…³é”®è®¾è®¡**ï¼šRESampleçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) åŠ¨ä½œä»·å€¼ç½‘ç»œçš„è®­ç»ƒï¼šä½¿ç”¨ç¦»çº¿å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼ˆå¦‚Behavior Cloningæˆ–Q-learningï¼‰è®­ç»ƒåŠ¨ä½œä»·å€¼ç½‘ç»œï¼Œä½¿å…¶èƒ½å¤Ÿå‡†ç¡®è¯„ä¼°å½“å‰ç­–ç•¥ä¸‹çš„åŠ¨ä½œä¼˜åŠ£ã€‚2) æ¢ç´¢å¼é‡‡æ ·æœºåˆ¶ï¼šè®¾è®¡ä¸€ç§è‡ªé€‚åº”çš„é‡‡æ ·ç­–ç•¥ï¼Œæ ¹æ®åŠ¨ä½œä»·å€¼ç½‘ç»œçš„è¾“å‡ºï¼Œé€‰æ‹©é‚£äº›å¯èƒ½å¯¼è‡´OODçŠ¶æ€çš„åŠ¨ä½œã€‚3) æ··åˆæ•°æ®é›†çš„æ„å»ºï¼šåˆç†è®¾ç½®åŸå§‹æ•°æ®å’ŒOODæ•°æ®çš„æ¯”ä¾‹ï¼Œé¿å…OODæ•°æ®è¿‡å¤šå¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸‹é™ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒRESampleåœ¨LIBEROåŸºå‡†æµ‹è¯•ä»¥åŠçœŸå®æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­ï¼Œå‡èƒ½æ˜¾è‘—æå‡VLAæ¨¡å‹çš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨LIBEROçš„ç‰¹å®šä»»åŠ¡ä¸Šï¼ŒRESampleä½¿æ¨¡å‹çš„æˆåŠŸç‡æé«˜äº†10%-20%ã€‚ä¸ä¼ ç»Ÿçš„æ¨¡ä»¿å­¦ä¹ æ–¹æ³•ç›¸æ¯”ï¼ŒRESampleèƒ½å¤Ÿæ›´å¥½åœ°åº”å¯¹ç¯å¢ƒæ‰°åŠ¨å’ŒçŠ¶æ€åç§»ï¼Œè¡¨ç°å‡ºæ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

RESampleæ¡†æ¶å¯å¹¿æ³›åº”ç”¨äºå„ç§æœºå™¨äººæ“ä½œä»»åŠ¡ï¼Œä¾‹å¦‚ç‰©ä½“æŠ“å–ã€è£…é…ã€å¯¼èˆªç­‰ã€‚é€šè¿‡æå‡VLAæ¨¡å‹çš„é²æ£’æ€§ï¼Œå¯ä»¥æ˜¾è‘—æé«˜æœºå™¨äººåœ¨å¤æ‚å’Œä¸ç¡®å®šç¯å¢ƒä¸­çš„é€‚åº”èƒ½åŠ›ï¼Œé™ä½æ“ä½œå¤±è´¥çš„é£é™©ï¼Œä»è€Œåœ¨å·¥ä¸šè‡ªåŠ¨åŒ–ã€å®¶åº­æœåŠ¡ã€åŒ»ç–—è¾…åŠ©ç­‰é¢†åŸŸå‘æŒ¥é‡è¦ä½œç”¨ã€‚è¯¥æ–¹æ³•ä¹Ÿæœ‰æ½œåŠ›æ¨å¹¿åˆ°å…¶ä»–æ¨¡ä»¿å­¦ä¹ ä»»åŠ¡ä¸­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision-Language-Action models (VLAs) have demonstrated remarkable performance on complex robotic manipulation tasks through imitation learning. However, existing imitation learning datasets contain only successful trajectories and lack failure or recovery data, especially for out-of-distribution (OOD) states where the robot deviates from the main policy due to minor perturbations or errors, leading VLA models to struggle with states deviating from the training distribution. To this end, we propose an automated OOD data augmentation framework named RESample through exploratory sampling. Specifically, we first leverage offline reinforcement learning to obtain an action-value network that accurately identifies sub-optimal actions under the current manipulation policy. We further sample potential OOD states from trajectories via rollout, and design an exploratory sampling mechanism that adaptively incorporates these action proxies into the training dataset to ensure efficiency. Subsequently, our framework explicitly encourages the VLAs to recover from OOD states and enhances their robustness against distributional shifts. We conduct extensive experiments on the LIBERO benchmark as well as real-world robotic manipulation tasks, demonstrating that RESample consistently improves the stability and generalization ability of VLA models.

