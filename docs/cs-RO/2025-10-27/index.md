---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-10-27
---

# cs.ROï¼ˆ2025-10-27ï¼‰

ğŸ“Š å…± **23** ç¯‡è®ºæ–‡
 | ğŸ”— **1** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (12 ğŸ”—1)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (4)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (4)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (2)</a>
<a href="#æ”¯æŸ±å…­è§†é¢‘æå–ä¸åŒ¹é…-video-extraction" class="interest-badge">æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (12 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251023016v1-manidp-manipulability-aware-diffusion-policy-for-posture-dependent-b.html">ManiDP: Manipulability-Aware Diffusion Policy for Posture-Dependent Bimanual Manipulation</a></td>
  <td>ManiDPï¼šä¸€ç§å¯æ“ä½œæ€§æ„ŸçŸ¥çš„æ‰©æ•£ç­–ç•¥ï¼Œç”¨äºå§¿æ€ç›¸å…³çš„åŒè‡‚æ“ä½œ</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">bi-manual</span> <span class="paper-tag">dual-arm</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.23016v1" data-paper-url="./papers/251023016v1-manidp-manipulability-aware-diffusion-policy-for-posture-dependent-b.html" onclick="toggleFavorite(this, '2510.23016v1', 'ManiDP: Manipulability-Aware Diffusion Policy for Posture-Dependent Bimanual Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251023763v3-roboomni-proactive-robot-manipulation-in-omni-modal-context.html">RoboOmni: Proactive Robot Manipulation in Omni-modal Context</a></td>
  <td>RoboOmniï¼šæå‡ºä¸€ç§å…¨æ¨¡æ€ä¸Šä¸‹æ–‡ä¸­çš„ä¸»åŠ¨æœºå™¨äººæ“ä½œæ¡†æ¶ï¼Œè§£å†³æœºå™¨äººæ„å›¾ç†è§£é—®é¢˜ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">spatiotemporal</span> <span class="paper-tag">vision-language-action</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.23763v3" data-paper-url="./papers/251023763v3-roboomni-proactive-robot-manipulation-in-omni-modal-context.html" onclick="toggleFavorite(this, '2510.23763v3', 'RoboOmni: Proactive Robot Manipulation in Omni-modal Context')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251023902v1-stand-walk-navigate-recovery-aware-visual-navigation-on-a-low-cost-w.html">Stand, Walk, Navigate: Recovery-Aware Visual Navigation on a Low-Cost Wheeled Quadruped</a></td>
  <td>ä½æˆæœ¬è½®è…¿æœºå™¨äººä¸ŠåŸºäºè§†è§‰çš„ç¨³å¥å¯¼èˆªä¸è·Œå€’æ¢å¤</td>
  <td class="tags-cell"><span class="paper-tag">quadruped</span> <span class="paper-tag">legged robot</span> <span class="paper-tag">locomotion</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.23902v1" data-paper-url="./papers/251023902v1-stand-walk-navigate-recovery-aware-visual-navigation-on-a-low-cost-w.html" onclick="toggleFavorite(this, '2510.23902v1', 'Stand, Walk, Navigate: Recovery-Aware Visual Navigation on a Low-Cost Wheeled Quadruped')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251023119v1-omnidexgrasp-generalizable-dexterous-grasping-via-foundation-model-a.html">OmniDexGrasp: Generalizable Dexterous Grasping via Foundation Model and Force Feedback</a></td>
  <td>OmniDexGraspï¼šåŸºäºFoundation Modelå’ŒåŠ›åé¦ˆçš„é€šç”¨çµå·§æŠ“å–æ¡†æ¶</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">dexterous hand</span> <span class="paper-tag">dexterous manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.23119v1" data-paper-url="./papers/251023119v1-omnidexgrasp-generalizable-dexterous-grasping-via-foundation-model-a.html" onclick="toggleFavorite(this, '2510.23119v1', 'OmniDexGrasp: Generalizable Dexterous Grasping via Foundation Model and Force Feedback')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251023057v1-seq-deepipc-sequential-sensing-for-end-to-end-control-in-legged-robo.html">Seq-DeepIPC: Sequential Sensing for End-to-End Control in Legged Robot Navigation</a></td>
  <td>Seq-DeepIPCï¼šç”¨äºè…¿å¼æœºå™¨äººå¯¼èˆªçš„ç«¯åˆ°ç«¯æ—¶åºæ„ŸçŸ¥æ§åˆ¶æ¨¡å‹</td>
  <td class="tags-cell"><span class="paper-tag">legged robot</span> <span class="paper-tag">depth estimation</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.23057v1" data-paper-url="./papers/251023057v1-seq-deepipc-sequential-sensing-for-end-to-end-control-in-legged-robo.html" onclick="toggleFavorite(this, '2510.23057v1', 'Seq-DeepIPC: Sequential Sensing for End-to-End Control in Legged Robot Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251023386v1-full-dynamics-real-time-nonlinear-model-predictive-control-of-heavy-.html">Full-Dynamics Real-Time Nonlinear Model Predictive Control of Heavy-Duty Hydraulic Manipulator for Trajectory Tracking Tasks</a></td>
  <td>æå‡ºä¸€ç§é‡å‹æ¶²å‹æœºæ¢°è‡‚å…¨åŠ¨åŠ›å­¦å®æ—¶éçº¿æ€§æ¨¡å‹é¢„æµ‹æ§åˆ¶æ–¹æ³•ï¼Œç”¨äºè½¨è¿¹è·Ÿè¸ªä»»åŠ¡ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">model predictive control</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.23386v1" data-paper-url="./papers/251023386v1-full-dynamics-real-time-nonlinear-model-predictive-control-of-heavy-.html" onclick="toggleFavorite(this, '2510.23386v1', 'Full-Dynamics Real-Time Nonlinear Model Predictive Control of Heavy-Duty Hydraulic Manipulator for Trajectory Tracking Tasks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/251023176v1-tarc-time-adaptive-robotic-control.html">TARC: Time-Adaptive Robotic Control</a></td>
  <td>æå‡ºæ—¶é—´è‡ªé€‚åº”æœºå™¨äººæ§åˆ¶ï¼ˆTARCï¼‰ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ å®ç°æœºå™¨äººæ§åˆ¶é¢‘ç‡çš„è‡ªä¸»è°ƒèŠ‚ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">quadruped</span> <span class="paper-tag">sim-to-real</span> <span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.23176v1" data-paper-url="./papers/251023176v1-tarc-time-adaptive-robotic-control.html" onclick="toggleFavorite(this, '2510.23176v1', 'TARC: Time-Adaptive Robotic Control')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251023571v1-robotarena-infty-scalable-robot-benchmarking-via-real-to-sim-transla.html">RobotArena $\infty$: Scalable Robot Benchmarking via Real-to-Sim Translation</a></td>
  <td>RobotArena âˆï¼šé€šè¿‡çœŸå®åˆ°æ¨¡æ‹Ÿçš„è½¬æ¢å®ç°å¯æ‰©å±•çš„æœºå™¨äººåŸºå‡†æµ‹è¯•</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">VLA</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.23571v1" data-paper-url="./papers/251023571v1-robotarena-infty-scalable-robot-benchmarking-via-real-to-sim-transla.html" onclick="toggleFavorite(this, '2510.23571v1', 'RobotArena $\infty$: Scalable Robot Benchmarking via Real-to-Sim Translation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/251023129v2-combining-high-level-scheduling-and-low-level-control-to-manage-flee.html">Combining High Level Scheduling and Low Level Control to Manage Fleets of Mobile Robots</a></td>
  <td>æå‡ºé«˜å±‚è°ƒåº¦ä¸ä½å±‚æ§åˆ¶ç»“åˆæ¡†æ¶ï¼Œè§£å†³å·¥ä¸šç¯å¢ƒç§»åŠ¨æœºå™¨äººé›†ç¾¤çš„åŠ¨æ€åè°ƒé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">MPC</span> <span class="paper-tag">model predictive control</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.23129v2" data-paper-url="./papers/251023129v2-combining-high-level-scheduling-and-low-level-control-to-manage-flee.html" onclick="toggleFavorite(this, '2510.23129v2', 'Combining High Level Scheduling and Low Level Control to Manage Fleets of Mobile Robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/251023059v1-awakening-facial-emotional-expressions-in-human-robot.html">Awakening Facial Emotional Expressions in Human-Robot</a></td>
  <td>æå‡ºåŸºäºKANå’Œæ³¨æ„åŠ›æœºåˆ¶çš„ç«¯åˆ°ç«¯å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºäººå½¢æœºå™¨äººè‡ªä¸»ç”Ÿæˆé¢éƒ¨è¡¨æƒ…</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid robot</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.23059v1" data-paper-url="./papers/251023059v1-awakening-facial-emotional-expressions-in-human-robot.html" onclick="toggleFavorite(this, '2510.23059v1', 'Awakening Facial Emotional Expressions in Human-Robot')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/251023227v1-workspace-registration-and-collision-detection-for-industrial-roboti.html">Workspace Registration and Collision Detection for Industrial Robotics Applications</a></td>
  <td>é’ˆå¯¹å·¥ä¸šæœºå™¨äººåº”ç”¨ï¼Œæå‡ºå·¥ä½œç©ºé—´æ³¨å†Œä¸ç¢°æ’æ£€æµ‹æ–¹æ¡ˆ</td>
  <td class="tags-cell"><span class="paper-tag">motion planning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.23227v1" data-paper-url="./papers/251023227v1-workspace-registration-and-collision-detection-for-industrial-roboti.html" onclick="toggleFavorite(this, '2510.23227v1', 'Workspace Registration and Collision Detection for Industrial Robotics Applications')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/251023021v1-planning-oriented-integrated-sensing-and-communication.html">Planning Oriented Integrated Sensing and Communication</a></td>
  <td>æå‡ºé¢å‘è§„åˆ’çš„é›†æˆæ„ŸçŸ¥ä¸é€šä¿¡æ¡†æ¶ï¼Œæå‡è‡ªåŠ¨é©¾é©¶å®‰å…¨æ€§å’Œæ•ˆç‡</td>
  <td class="tags-cell"><span class="paper-tag">motion planning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.23021v1" data-paper-url="./papers/251023021v1-planning-oriented-integrated-sensing-and-communication.html" onclick="toggleFavorite(this, '2510.23021v1', 'Planning Oriented Integrated Sensing and Communication')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (4 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>13</td>
  <td><a href="./papers/251023509v1-deductive-chain-of-thought-augmented-socially-aware-robot-navigation.html">Deductive Chain-of-Thought Augmented Socially-aware Robot Navigation World Model</a></td>
  <td>æå‡ºNaviWMï¼Œç»“åˆä¸–ç•Œæ¨¡å‹ä¸é€»è¾‘æ¨ç†å¢å¼ºç¤¾äº¤æœºå™¨äººå¯¼èˆª</td>
  <td class="tags-cell"><span class="paper-tag">world model</span> <span class="paper-tag">large language model</span> <span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.23509v1" data-paper-url="./papers/251023509v1-deductive-chain-of-thought-augmented-socially-aware-robot-navigation.html" onclick="toggleFavorite(this, '2510.23509v1', 'Deductive Chain-of-Thought Augmented Socially-aware Robot Navigation World Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/251023329v1-transferable-deep-reinforcement-learning-for-cross-domain-navigation.html">Transferable Deep Reinforcement Learning for Cross-Domain Navigation: from Farmland to the Moon</a></td>
  <td>æå‡ºåŸºäºDRLçš„è·¨åŸŸè¿ç§»å¯¼èˆªæ–¹æ³•ï¼Œå®ç°ä»å†œç”°åˆ°æœˆçƒçš„é›¶æ ·æœ¬æ³›åŒ–</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">deep reinforcement learning</span> <span class="paper-tag">DRL</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.23329v1" data-paper-url="./papers/251023329v1-transferable-deep-reinforcement-learning-for-cross-domain-navigation.html" onclick="toggleFavorite(this, '2510.23329v1', 'Transferable Deep Reinforcement Learning for Cross-Domain Navigation: from Farmland to the Moon')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/251023258v1-deep-active-inference-with-diffusion-policy-and-multiple-timescale-w.html">Deep Active Inference with Diffusion Policy and Multiple Timescale World Model for Real-World Exploration and Navigation</a></td>
  <td>æå‡ºåŸºäºæ‰©æ•£ç­–ç•¥å’Œå¤šæ—¶é—´å°ºåº¦ä¸–ç•Œæ¨¡å‹çš„æ·±åº¦ä¸»åŠ¨æ¨ç†æ¡†æ¶ï¼Œç”¨äºçœŸå®ç¯å¢ƒæ¢ç´¢å’Œå¯¼èˆªã€‚</td>
  <td class="tags-cell"><span class="paper-tag">diffusion policy</span> <span class="paper-tag">world model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.23258v1" data-paper-url="./papers/251023258v1-deep-active-inference-with-diffusion-policy-and-multiple-timescale-w.html" onclick="toggleFavorite(this, '2510.23258v1', 'Deep Active Inference with Diffusion Policy and Multiple Timescale World Model for Real-World Exploration and Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/251022892v1-never-too-rigid-to-reach-adaptive-virtual-model-control-with-llm-and.html">Never Too Rigid to Reach: Adaptive Virtual Model Control with LLM- and Lyapunov-Based Reinforcement Learning</a></td>
  <td>æå‡ºåŸºäºLLMå’ŒLyapunovå¼ºåŒ–å­¦ä¹ çš„è‡ªé€‚åº”è™šæ‹Ÿæ¨¡å‹æ§åˆ¶ï¼Œæå‡æœºå™¨äººè‡‚åœ¨ä¸ç¡®å®šç¯å¢ƒä¸‹çš„é€‚åº”æ€§ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.22892v1" data-paper-url="./papers/251022892v1-never-too-rigid-to-reach-adaptive-virtual-model-control-with-llm-and.html" onclick="toggleFavorite(this, '2510.22892v1', 'Never Too Rigid to Reach: Adaptive Virtual Model Control with LLM- and Lyapunov-Based Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (4 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>17</td>
  <td><a href="./papers/251023511v1-dexbotic-open-source-vision-language-action-toolbox.html">Dexbotic: Open-Source Vision-Language-Action Toolbox</a></td>
  <td>Dexboticï¼šå¼€æºè§†è§‰-è¯­è¨€-åŠ¨ä½œå·¥å…·ç®±ï¼ŒåŠ©åŠ›å…·èº«æ™ºèƒ½ç ”ç©¶</td>
  <td class="tags-cell"><span class="paper-tag">vision-language-action</span> <span class="paper-tag">VLA</span> <span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.23511v1" data-paper-url="./papers/251023511v1-dexbotic-open-source-vision-language-action-toolbox.html" onclick="toggleFavorite(this, '2510.23511v1', 'Dexbotic: Open-Source Vision-Language-Action Toolbox')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/251023576v1-urbanvla-a-vision-language-action-model-for-urban-micromobility.html">UrbanVLA: A Vision-Language-Action Model for Urban Micromobility</a></td>
  <td>æå‡ºUrbanVLAï¼Œç”¨äºåŸå¸‚å¾®å‡ºè¡Œåœºæ™¯ä¸‹åŸºäºè§†è§‰-è¯­è¨€-åŠ¨ä½œçš„å¯¼èˆªã€‚</td>
  <td class="tags-cell"><span class="paper-tag">vision-language-action</span> <span class="paper-tag">VLA</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.23576v1" data-paper-url="./papers/251023576v1-urbanvla-a-vision-language-action-model-for-urban-micromobility.html" onclick="toggleFavorite(this, '2510.23576v1', 'UrbanVLA: A Vision-Language-Action Model for Urban Micromobility')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/251023357v1-large-language-model-based-task-planning-for-service-robots-a-review.html">Large language model-based task planning for service robots: A review</a></td>
  <td>ç»¼è¿°ï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æœåŠ¡æœºå™¨äººä»»åŠ¡è§„åˆ’ç ”ç©¶è¿›å±•</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.23357v1" data-paper-url="./papers/251023357v1-large-language-model-based-task-planning-for-service-robots-a-review.html" onclick="toggleFavorite(this, '2510.23357v1', 'Large language model-based task planning for service robots: A review')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/251100033v1-strider-navigation-via-instruction-aligned-structural-decision-space.html">STRIDER: Navigation via Instruction-Aligned Structural Decision Space Optimization</a></td>
  <td>STRIDERï¼šé€šè¿‡æŒ‡ä»¤å¯¹é½çš„ç»“æ„åŒ–å†³ç­–ç©ºé—´ä¼˜åŒ–å®ç°å¯¼èˆª</td>
  <td class="tags-cell"><span class="paper-tag">VLN</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.00033v1" data-paper-url="./papers/251100033v1-strider-navigation-via-instruction-aligned-structural-decision-space.html" onclick="toggleFavorite(this, '2511.00033v1', 'STRIDER: Navigation via Instruction-Aligned Structural Decision Space Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>21</td>
  <td><a href="./papers/251023521v1-explicit-memory-through-online-3d-gaussian-splatting-improves-class-.html">Explicit Memory through Online 3D Gaussian Splatting Improves Class-Agnostic Video Segmentation</a></td>
  <td>åˆ©ç”¨åœ¨çº¿3Dé«˜æ–¯æº…å°„æ˜¾å¼è®°å¿†æå‡ç±»åˆ«æ— å…³è§†é¢‘åˆ†å‰²</td>
  <td class="tags-cell"><span class="paper-tag">3D gaussian splatting</span> <span class="paper-tag">3DGS</span> <span class="paper-tag">gaussian splatting</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.23521v1" data-paper-url="./papers/251023521v1-explicit-memory-through-online-3d-gaussian-splatting-improves-class-.html" onclick="toggleFavorite(this, '2510.23521v1', 'Explicit Memory through Online 3D Gaussian Splatting Improves Class-Agnostic Video Segmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>22</td>
  <td><a href="./papers/251023928v2-adaptive-keyframe-selection-for-scalable-3d-scene-reconstruction-in-.html">Adaptive Keyframe Selection for Scalable 3D Scene Reconstruction in Dynamic Environments</a></td>
  <td>æå‡ºè‡ªé€‚åº”å…³é”®å¸§é€‰æ‹©æ–¹æ³•ï¼Œæå‡åŠ¨æ€ç¯å¢ƒä¸‹å¯æ‰©å±•3Dåœºæ™¯é‡å»ºæ•ˆæœã€‚</td>
  <td class="tags-cell"><span class="paper-tag">scene reconstruction</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.23928v2" data-paper-url="./papers/251023928v2-adaptive-keyframe-selection-for-scalable-3d-scene-reconstruction-in-.html" onclick="toggleFavorite(this, '2510.23928v2', 'Adaptive Keyframe Selection for Scalable 3D Scene Reconstruction in Dynamic Environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…­è§†é¢‘æå–ä¸åŒ¹é…-video-extraction">ğŸ”¬ æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>23</td>
  <td><a href="./papers/251022917v2-hypernav-hybrid-perception-for-object-oriented-navigation-in-unknown.html">HyPerNav: Hybrid Perception for Object-Oriented Navigation in Unknown Environment</a></td>
  <td>HyPerNavï¼šåˆ©ç”¨æ··åˆæ„ŸçŸ¥å®ç°æœªçŸ¥ç¯å¢ƒä¸­é¢å‘å¯¹è±¡çš„å¯¼èˆª</td>
  <td class="tags-cell"><span class="paper-tag">egocentric</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.22917v2" data-paper-url="./papers/251022917v2-hypernav-hybrid-perception-for-object-oriented-navigation-in-unknown.html" onclick="toggleFavorite(this, '2510.22917v2', 'HyPerNav: Hybrid Perception for Object-Oriented Navigation in Unknown Environment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)