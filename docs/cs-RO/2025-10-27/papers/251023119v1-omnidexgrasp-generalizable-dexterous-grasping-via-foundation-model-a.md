---
layout: default
title: OmniDexGrasp: Generalizable Dexterous Grasping via Foundation Model and Force Feedback
---

# OmniDexGrasp: Generalizable Dexterous Grasping via Foundation Model and Force Feedback

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.23119" target="_blank" class="toolbar-btn">arXiv: 2510.23119v1</a>
    <a href="https://arxiv.org/pdf/2510.23119.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.23119v1" 
            onclick="toggleFavorite(this, '2510.23119v1', 'OmniDexGrasp: Generalizable Dexterous Grasping via Foundation Model and Force Feedback')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yi-Lin Wei, Zhexi Luo, Yuhao Lin, Mu Lin, Zhizhao Liang, Shuoyu Chen, Wei-Shi Zheng

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-27

**Â§áÊ≥®**: Project page: https://isee-laboratory.github.io/OmniDexGrasp/

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**OmniDexGraspÔºöÂü∫‰∫éFoundation ModelÂíåÂäõÂèçÈ¶àÁöÑÈÄöÁî®ÁÅµÂ∑ßÊäìÂèñÊ°ÜÊû∂**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÁÅµÂ∑ßÊäìÂèñ` `Foundation Model` `ÂäõÂèçÈ¶à` `Êú∫Âô®‰∫∫Êìç‰Ωú` `ÈÄöÁî®ÊÄß` `ËøÅÁßªÂ≠¶‰π†` `Ëá™ÈÄÇÂ∫îÊéßÂà∂`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁÅµÂ∑ßÊäìÂèñÊñπÊ≥ïÂú®Èù¢ÂØπÂ§öÊ†∑ÂåñÁöÑÁâ©‰ΩìÊàñ‰ªªÂä°Êó∂ÔºåÁî±‰∫éËØ≠‰πâÁÅµÂ∑ßÊäìÂèñÊï∞ÊçÆÈõÜËßÑÊ®°ÊúâÈôêÔºåÊ≥õÂåñËÉΩÂäõ‰∏çË∂≥„ÄÇ
2. OmniDexGraspÊ°ÜÊû∂ÁªìÂêàFoundation Model„ÄÅ‰∫∫Á±ªÂä®‰ΩúËøÅÁßªÁ≠ñÁï•ÂíåÂäõÊÑüÁü•Ëá™ÈÄÇÂ∫îÊäìÂèñÔºåÊèêÂçá‰∫ÜÊú∫Âô®‰∫∫ÊäìÂèñÁöÑÊ≥õÂåñÊÄßÂíåÈ≤ÅÊ£íÊÄß„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåOmniDexGraspÂú®‰∏çÂêåÁî®Êà∑Êåá‰ª§„ÄÅÊäìÂèñ‰ªªÂä°ÂíåÁÅµÂ∑ßÊâã‰∏äÂùáË°®Áé∞Âá∫ËâØÂ•ΩÁöÑÊÄßËÉΩÔºåÂπ∂ÂÖ∑Â§áÊâ©Â±ïÂà∞ÁÅµÂ∑ßÊìç‰Ωú‰ªªÂä°ÁöÑÊΩúÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫OmniDexGraspÔºå‰∏Ä‰∏™ÈÄöÁî®ÁöÑÁÅµÂ∑ßÊäìÂèñÊ°ÜÊû∂ÔºåÊó®Âú®ÈÄöËøáÁªìÂêàFoundation Model‰∏éËøÅÁßªÂíåÊéßÂà∂Á≠ñÁï•ÔºåÂÆûÁé∞Áî®Êà∑ÊèêÁ§∫„ÄÅÁÅµÂ∑ßÊìç‰ΩúÂíåÊäìÂèñ‰ªªÂä°‰∏≠ÁöÑÂÖ®Êñπ‰ΩçËÉΩÂäõ„ÄÇOmniDexGraspÈõÜÊàê‰∫Ü‰∏â‰∏™ÂÖ≥ÈîÆÊ®°ÂùóÔºö(i) Âà©Áî®Foundation ModelÁîüÊàêÊîØÊåÅÁî®Êà∑ÊèêÁ§∫Âíå‰ªªÂä°ÂÖ®Êñπ‰ΩçËÉΩÂäõÁöÑ‰∫∫Á±ªÊäìÂèñÂõæÂÉèÔºå‰ªéËÄåÂ¢ûÂº∫Ê≥õÂåñÊÄßÔºõ(ii) ‰∏ÄÁßç‰∫∫Á±ªÂõæÂÉèÂà∞Êú∫Âô®‰∫∫Âä®‰ΩúÁöÑËøÅÁßªÁ≠ñÁï•ÔºåÂ∞Ü‰∫∫Á±ªÊºîÁ§∫ËΩ¨Âåñ‰∏∫ÂèØÊâßË°åÁöÑÊú∫Âô®‰∫∫Âä®‰ΩúÔºåÂÆûÁé∞ÂÖ®Êñπ‰ΩçÁöÑÁÅµÂ∑ßÊìç‰ΩúÔºõ(iii) ÂäõÊÑüÁü•ÁöÑËá™ÈÄÇÂ∫îÊäìÂèñÁ≠ñÁï•ÔºåÁ°Æ‰øùÈ≤ÅÊ£íÂíåÁ®≥ÂÆöÁöÑÊäìÂèñÊâßË°å„ÄÇÂú®Ê®°ÊãüÂíåÁúüÂÆûÊú∫Âô®‰∫∫‰∏äÁöÑÂÆûÈ™åÈ™åËØÅ‰∫ÜOmniDexGraspÂú®ÂêÑÁßçÁî®Êà∑ÊèêÁ§∫„ÄÅÊäìÂèñ‰ªªÂä°ÂíåÁÅµÂ∑ßÊâã‰∏äÁöÑÊúâÊïàÊÄßÔºåËøõ‰∏ÄÊ≠•ÁöÑÁªìÊûúË°®Êòé‰∫ÜÂÖ∂Âú®ÁÅµÂ∑ßÊìç‰Ωú‰ªªÂä°‰∏≠ÁöÑÂèØÊâ©Â±ïÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÁÅµÂ∑ßÊäìÂèñÊñπÊ≥ïÈöæ‰ª•Ê≥õÂåñÂà∞ÂêÑÁßçÁâ©‰ΩìÂíå‰ªªÂä°Ôºå‰∏ªË¶ÅÂéüÂõ†ÊòØÁº∫‰πèÂ§ßËßÑÊ®°ÁöÑËØ≠‰πâÁÅµÂ∑ßÊäìÂèñÊï∞ÊçÆÈõÜ„ÄÇÊ≠§Â§ñÔºåÁõ¥Êé•Âà©Áî®Foundation ModelÁîüÊàêÂèØË°åÁöÑÊú∫Âô®‰∫∫Âä®‰ΩúÂÖ∑ÊúâÊåëÊàòÊÄßÔºåÂõ†‰∏∫ÊäΩË±°ÁöÑÊ®°ÂûãÁü•ËØÜ‰∏éÁâ©ÁêÜÊú∫Âô®‰∫∫ÊâßË°å‰πãÈó¥Â≠òÂú®Â∑ÆË∑ù„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöOmniDexGraspÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Foundation ModelÁöÑÂº∫Â§ßÊ≥õÂåñËÉΩÂäõÔºåÁªìÂêà‰∫∫Á±ªÊºîÁ§∫Â≠¶‰π†ÂíåÂäõÂèçÈ¶àÊéßÂà∂ÔºåÂº•ÂêàÊäΩË±°Áü•ËØÜ‰∏éÁâ©ÁêÜÊâßË°å‰πãÈó¥ÁöÑÂ∑ÆË∑ù„ÄÇÈÄöËøáÂ∞Ü‰∫∫Á±ªÊäìÂèñÂõæÂÉèËΩ¨Âåñ‰∏∫Êú∫Âô®‰∫∫Âä®‰ΩúÔºåÂπ∂Âà©Áî®ÂäõÂèçÈ¶àËøõË°åËá™ÈÄÇÂ∫îË∞ÉÊï¥ÔºåÂÆûÁé∞Êõ¥È≤ÅÊ£íÂíåÈÄöÁî®ÁöÑÁÅµÂ∑ßÊäìÂèñ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöOmniDexGraspÊ°ÜÊû∂ÂåÖÂê´‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) **Foundation ModelÊ®°Âùó**ÔºöÂà©Áî®Foundation ModelÁîüÊàê‰∫∫Á±ªÊäìÂèñÂõæÂÉèÔºåÊîØÊåÅÂ§öÊ†∑ÂåñÁöÑÁî®Êà∑ÊèêÁ§∫Âíå‰ªªÂä°ÈúÄÊ±Ç„ÄÇ2) **‰∫∫Á±ªÂõæÂÉèÂà∞Êú∫Âô®‰∫∫Âä®‰ΩúËøÅÁßªÊ®°Âùó**ÔºöÂ∞Ü‰∫∫Á±ªÊºîÁ§∫ÂõæÂÉèËΩ¨Âåñ‰∏∫ÂèØÊâßË°åÁöÑÊú∫Âô®‰∫∫Âä®‰ΩúÔºåÂÆûÁé∞ÁÅµÂ∑ßÊìç‰ΩúÁöÑËøÅÁßª„ÄÇ3) **ÂäõÊÑüÁü•Ëá™ÈÄÇÂ∫îÊäìÂèñÊ®°Âùó**ÔºöÂà©Áî®Âäõ‰º†ÊÑüÂô®‰ø°ÊÅØÔºåÂØπÊäìÂèñÂä®‰ΩúËøõË°åËá™ÈÄÇÂ∫îË∞ÉÊï¥ÔºåÁ°Æ‰øùÊäìÂèñÁöÑÁ®≥ÂÆöÊÄßÂíåÈ≤ÅÊ£íÊÄß„ÄÇÊï¥‰ΩìÊµÅÁ®ãÊòØ‰ªéÁî®Êà∑Êåá‰ª§ÂºÄÂßãÔºåÈÄöËøáFoundation ModelÁîüÊàêÊäìÂèñÂõæÂÉèÔºåÁÑ∂ÂêéËøÅÁßªÂà∞Êú∫Âô®‰∫∫Âä®‰ΩúÔºåÊúÄÂêéÈÄöËøáÂäõÂèçÈ¶àËøõË°åË∞ÉÊï¥ÂíåÊâßË°å„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöOmniDexGraspÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜFoundation Model‰∏éÊú∫Âô®‰∫∫ÁÅµÂ∑ßÊäìÂèñÁõ∏ÁªìÂêàÔºåÂà©Áî®Foundation ModelÁöÑÊ≥õÂåñËÉΩÂäõÊù•Ëß£ÂÜ≥Êï∞ÊçÆÈõÜËßÑÊ®°ÊúâÈôêÁöÑÈóÆÈ¢ò„ÄÇÊ≠§Â§ñÔºåËØ•Ê°ÜÊû∂ËøòÂàõÊñ∞ÊÄßÂú∞ÊèêÂá∫‰∫Ü‰∫∫Á±ªÂõæÂÉèÂà∞Êú∫Âô®‰∫∫Âä®‰ΩúÁöÑËøÅÁßªÁ≠ñÁï•Ôºå‰ª•ÂèäÂäõÊÑüÁü•ÁöÑËá™ÈÄÇÂ∫îÊäìÂèñÊñπÊ≥ïÔºå‰ªéËÄåÊèêÈ´ò‰∫ÜÊäìÂèñÁöÑÈ≤ÅÊ£íÊÄßÂíåÈÄöÁî®ÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®‰∫∫Á±ªÂõæÂÉèÂà∞Êú∫Âô®‰∫∫Âä®‰ΩúËøÅÁßªÊ®°Âùó‰∏≠ÔºåÂèØËÉΩ‰ΩøÁî®‰∫ÜÂõæÂÉèÂåπÈÖç„ÄÅÂßøÊÄÅ‰º∞ËÆ°Á≠âÊäÄÊúØÔºåÂ∞Ü‰∫∫Á±ªÊâãÁöÑÂßøÊÄÅÊò†Â∞ÑÂà∞Êú∫Âô®‰∫∫Êâã‰∏ä„ÄÇÂäõÊÑüÁü•Ëá™ÈÄÇÂ∫îÊäìÂèñÊ®°ÂùóÂèØËÉΩ‰ΩøÁî®‰∫ÜPIDÊéßÂà∂ÊàñÂº∫ÂåñÂ≠¶‰π†Á≠âÊñπÊ≥ïÔºåÊ†πÊçÆÂäõ‰º†ÊÑüÂô®ÂèçÈ¶àË∞ÉÊï¥ÊäìÂèñÂäõÂ∫¶Âíå‰ΩçÁΩÆ„ÄÇÂÖ∑‰ΩìÁöÑÊçüÂ§±ÂáΩÊï∞ÂíåÁΩëÁªúÁªìÊûÑÁ≠âÁªÜËäÇÂú®ËÆ∫Êñá‰∏≠Â∫îËØ•ÊúâÊõ¥ËØ¶ÁªÜÁöÑÊèèËø∞ÔºàÊú™Áü•Ôºâ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåOmniDexGraspÂú®Ê®°ÊãüÂíåÁúüÂÆûÊú∫Âô®‰∫∫‰∏äÂùáË°®Áé∞Âá∫ËâØÂ•ΩÁöÑÊÄßËÉΩ„ÄÇËØ•Ê°ÜÊû∂ËÉΩÂ§üÊàêÂäüÂú∞Â§ÑÁêÜÂêÑÁßçÁî®Êà∑ÊèêÁ§∫„ÄÅÊäìÂèñ‰ªªÂä°ÂíåÁÅµÂ∑ßÊâãÔºåÂπ∂‰∏îËÉΩÂ§üÊâ©Â±ïÂà∞ÁÅµÂ∑ßÊìç‰Ωú‰ªªÂä°„ÄÇÂÖ∑‰ΩìÁöÑÊÄßËÉΩÊï∞ÊçÆÔºà‰æãÂ¶ÇÊàêÂäüÁéá„ÄÅÊäìÂèñÊó∂Èó¥Á≠âÔºâÂíåÂØπÊØîÂü∫Á∫øÔºà‰æãÂ¶Ç‰º†ÁªüÊäìÂèñÁÆóÊ≥ïÔºâÈúÄË¶ÅÂú®ËÆ∫Êñá‰∏≠Êü•ÊâæÔºàÊú™Áü•Ôºâ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

OmniDexGraspÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºå‰æãÂ¶ÇÂú®Êô∫ËÉΩÂà∂ÈÄ†‰∏≠ÔºåÊú∫Âô®‰∫∫ÂèØ‰ª•Ê†πÊçÆ‰∫∫Á±ªÊåá‰ª§ÁÅµÊ¥ªÂú∞ÊäìÂèñÂíåÊìç‰ΩúÂêÑÁßçÈõ∂‰ª∂„ÄÇÂú®ÂÆ∂Â∫≠ÊúçÂä°È¢ÜÂüüÔºåÊú∫Âô®‰∫∫ÂèØ‰ª•Â∏ÆÂä©‰∫∫‰ª¨ÂÆåÊàêÂêÑÁßçÂÆ∂Âä°ÔºåÂ¶ÇÊï¥ÁêÜÁâ©ÂìÅ„ÄÅÁÉπÈ•™Á≠â„ÄÇÊ≠§Â§ñÔºåËØ•ÊäÄÊúØËøòÂèØ‰ª•Â∫îÁî®‰∫éÂåªÁñóÂ∫∑Â§ç„ÄÅÁÅæÈöæÊïëÊè¥Á≠âÈ¢ÜÂüüÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÊú™Êù•ÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Enabling robots to dexterously grasp and manipulate objects based on human commands is a promising direction in robotics. However, existing approaches are challenging to generalize across diverse objects or tasks due to the limited scale of semantic dexterous grasp datasets. Foundation models offer a new way to enhance generalization, yet directly leveraging them to generate feasible robotic actions remains challenging due to the gap between abstract model knowledge and physical robot execution. To address these challenges, we propose OmniDexGrasp, a generalizable framework that achieves omni-capabilities in user prompting, dexterous embodiment, and grasping tasks by combining foundation models with the transfer and control strategies. OmniDexGrasp integrates three key modules: (i) foundation models are used to enhance generalization by generating human grasp images supporting omni-capability of user prompt and task; (ii) a human-image-to-robot-action transfer strategy converts human demonstrations into executable robot actions, enabling omni dexterous embodiment; (iii) force-aware adaptive grasp strategy ensures robust and stable grasp execution. Experiments in simulation and on real robots validate the effectiveness of OmniDexGrasp on diverse user prompts, grasp task and dexterous hands, and further results show its extensibility to dexterous manipulation tasks.

