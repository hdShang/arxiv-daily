---
layout: default
title: Driving Beyond Privilege: Distilling Dense-Reward Knowledge into Sparse-Reward Policies
---

# Driving Beyond Privilege: Distilling Dense-Reward Knowledge into Sparse-Reward Policies

**arXiv**: [2512.04279v1](https://arxiv.org/abs/2512.04279) | [PDF](https://arxiv.org/pdf/2512.04279.pdf)

**ä½œè€…**: Feeza Khan Khanzada, Jaerock Kwon

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-12-03

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¥–åŠ±ç‰¹æƒä¸–ç•Œæ¨¡åž‹è’¸é¦ï¼Œè§£å†³è‡ªåŠ¨é©¾é©¶ä¸­ç¨ å¯†å¥–åŠ±æ³›åŒ–æ€§å·®çš„é—®é¢˜**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `è‡ªåŠ¨é©¾é©¶` `å¼ºåŒ–å­¦ä¹ ` `çŸ¥è¯†è’¸é¦` `ä¸–ç•Œæ¨¡åž‹` `ç¨€ç–å¥–åŠ±`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•ä¾èµ–ç¨ å¯†å¥–åŠ±è®­ç»ƒè‡ªåŠ¨é©¾é©¶ç­–ç•¥ï¼Œä½†è¿™äº›ç­–ç•¥åœ¨éƒ¨ç½²æ—¶æ³›åŒ–æ€§å·®ï¼Œæ— æ³•å¾ˆå¥½åœ°é€‚åº”ç¨€ç–å¥–åŠ±åœºæ™¯ã€‚
2. æå‡ºå¥–åŠ±ç‰¹æƒä¸–ç•Œæ¨¡åž‹è’¸é¦ï¼Œåˆ©ç”¨ç¨ å¯†å¥–åŠ±è®­ç»ƒæ•™å¸ˆæ¨¡åž‹ï¼Œç„¶åŽå°†å­¦ä¹ åˆ°çš„æ½œåœ¨åŠ¨æ€çŸ¥è¯†è’¸é¦åˆ°ç¨€ç–å¥–åŠ±è®­ç»ƒçš„å­¦ç”Ÿæ¨¡åž‹ã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨CARLAæ¨¡æ‹Ÿå™¨ä¸­ï¼Œè½¦é“è·Ÿéšå’Œè¶…è½¦ä»»åŠ¡ä¸Šï¼Œæ˜¾è‘—ä¼˜äºŽç¨ å¯†å¥–åŠ±æ•™å¸ˆæ¨¡åž‹å’Œä»Žå¤´å¼€å§‹è®­ç»ƒçš„ç¨€ç–å¥–åŠ±æ¨¡åž‹ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ç ”ç©¶å¦‚ä½•åœ¨åŸºäºŽè§†è§‰çš„è‡ªåŠ¨é©¾é©¶ä¸­åˆ©ç”¨æ¨¡æ‹Ÿå™¨å®šä¹‰çš„ç¨ å¯†å¥–åŠ±ï¼ŒåŒæ—¶é¿å…å…¶ä¸Žéƒ¨ç½²æŒ‡æ ‡çš„ä¸å¯¹é½é—®é¢˜ã€‚åœ¨CARLAç­‰çœŸå®žæ¨¡æ‹Ÿå™¨ä¸­ï¼Œç‰¹æƒçŠ¶æ€ï¼ˆå¦‚è½¦é“å‡ ä½•ã€è¿è§„è¡Œä¸ºã€ç¢°æ’žæ—¶é—´ï¼‰å¯ä»¥è½¬åŒ–ä¸ºç¨ å¯†å¥–åŠ±ï¼Œä»Žè€Œç¨³å®šå’ŒåŠ é€ŸåŸºäºŽæ¨¡åž‹çš„å¼ºåŒ–å­¦ä¹ ã€‚ç„¶è€Œï¼Œç›´æŽ¥åŸºäºŽè¿™äº›ä¿¡å·è®­ç»ƒçš„ç­–ç•¥é€šå¸¸ä¼šè¿‡æ‹Ÿåˆï¼Œå¹¶ä¸”åœ¨è¯„ä¼°ç¨€ç–ç›®æ ‡ï¼ˆå¦‚è·¯çº¿å®Œæˆå’Œæ— ç¢°æ’žè¶…è½¦ï¼‰æ—¶æ³›åŒ–å¤±è´¥ã€‚æˆ‘ä»¬æå‡ºå¥–åŠ±ç‰¹æƒä¸–ç•Œæ¨¡åž‹è’¸é¦ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸¤é˜¶æ®µæ¡†æž¶ï¼Œå…¶ä¸­é¦–å…ˆä½¿ç”¨ç¨ å¯†ç‰¹æƒå¥–åŠ±è®­ç»ƒä¸€ä¸ªæ•™å¸ˆDreamerV3é£Žæ ¼çš„æ™ºèƒ½ä½“ï¼Œç„¶åŽä»…å°†å…¶æ½œåœ¨åŠ¨æ€è’¸é¦åˆ°ä»…ä½¿ç”¨ç¨€ç–ä»»åŠ¡å¥–åŠ±è®­ç»ƒçš„å­¦ç”Ÿæ™ºèƒ½ä½“ä¸­ã€‚æ•™å¸ˆå’Œå­¦ç”Ÿå…±äº«ç›¸åŒçš„è§‚å¯Ÿç©ºé—´ï¼ˆè¯­ä¹‰é¸Ÿçž°å›¾å›¾åƒï¼‰ï¼›ç‰¹æƒä¿¡æ¯ä»…é€šè¿‡æ•™å¸ˆçš„å¥–åŠ±è¿›å…¥ï¼Œå­¦ç”Ÿä¸æ¨¡ä»¿æ•™å¸ˆçš„åŠ¨ä½œæˆ–ä»·å€¼ä¼°è®¡ã€‚ç›¸åï¼Œå­¦ç”Ÿçš„World Modelè¢«æ­£åˆ™åŒ–ä»¥åŒ¹é…æ•™å¸ˆçš„æ½œåœ¨åŠ¨æ€ï¼Œè€Œå…¶ç­–ç•¥åˆ™å®Œå…¨ä»Žç¨€ç–çš„æˆåŠŸ/å¤±è´¥ä¿¡å·ä¸­å­¦ä¹ ã€‚åœ¨CARLAè½¦é“è·Ÿéšå’Œè¶…è½¦åŸºå‡†æµ‹è¯•ä¸­ï¼Œç¨€ç–å¥–åŠ±å­¦ç”Ÿä¼˜äºŽç¨ å¯†å¥–åŠ±æ•™å¸ˆå’Œä»Žå¤´å¼€å§‹çš„ç¨€ç–åŸºçº¿ã€‚åœ¨æœªè§è¿‡çš„è½¦é“è·Ÿéšè·¯çº¿ä¸Šï¼Œå¥–åŠ±ç‰¹æƒè’¸é¦ç›¸å¯¹äºŽç¨ å¯†æ•™å¸ˆæé«˜äº†çº¦23%çš„æˆåŠŸçŽ‡ï¼ŒåŒæ—¶ä¿æŒäº†ç›¸å½“æˆ–æ›´å¥½çš„å®‰å…¨æ€§ã€‚åœ¨è¶…è½¦æ–¹é¢ï¼Œå­¦ç”Ÿåœ¨è®­ç»ƒè·¯çº¿ä¸Šä¿æŒäº†è¿‘ä¹Žå®Œç¾Žçš„æ€§èƒ½ï¼Œå¹¶åœ¨æœªè§è¿‡çš„è·¯çº¿ä¸Šå®žçŽ°äº†é«˜è¾¾27å€çš„æˆåŠŸçŽ‡æå‡ï¼Œå¹¶æ”¹å–„äº†è½¦é“ä¿æŒã€‚è¿™äº›ç»“æžœè¡¨æ˜Žï¼Œå¯ä»¥åˆ©ç”¨ç¨ å¯†å¥–åŠ±æ¥å­¦ä¹ æ›´ä¸°å¯Œçš„åŠ¨æ€æ¨¡åž‹ï¼ŒåŒæ—¶ä¿æŒéƒ¨ç½²ç­–ç•¥ä¸¥æ ¼é’ˆå¯¹ç¨€ç–çš„ã€ä¸Žéƒ¨ç½²å¯¹é½çš„ç›®æ ‡è¿›è¡Œä¼˜åŒ–ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åœ¨è‡ªåŠ¨é©¾é©¶æ¨¡æ‹Ÿå™¨ä¸­ä½¿ç”¨ç¨ å¯†å¥–åŠ±è®­ç»ƒç­–ç•¥æ—¶ï¼Œç­–ç•¥éš¾ä»¥æ³›åŒ–åˆ°çœŸå®žä¸–ç•Œæˆ–ç¨€ç–å¥–åŠ±åœºæ™¯çš„é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•ç›´æŽ¥ä½¿ç”¨ç¨ å¯†å¥–åŠ±è®­ç»ƒç­–ç•¥ï¼Œå¯¼è‡´ç­–ç•¥è¿‡åº¦æ‹Ÿåˆæ¨¡æ‹Ÿå™¨çŽ¯å¢ƒï¼Œæ— æ³•å¾ˆå¥½åœ°é€‚åº”çœŸå®žä¸–ç•Œä¸­ç¨€ç–çš„å¥–åŠ±ä¿¡å·ï¼Œä¾‹å¦‚è·¯çº¿å®Œæˆæˆ–é¿å…ç¢°æ’žç­‰ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†çŸ¥è¯†ä»Žä¸€ä¸ªä½¿ç”¨ç¨ å¯†å¥–åŠ±è®­ç»ƒçš„æ•™å¸ˆæ¨¡åž‹è’¸é¦åˆ°ä¸€ä¸ªä»…ä½¿ç”¨ç¨€ç–å¥–åŠ±è®­ç»ƒçš„å­¦ç”Ÿæ¨¡åž‹ã€‚æ•™å¸ˆæ¨¡åž‹åˆ©ç”¨ç¨ å¯†å¥–åŠ±å­¦ä¹ çŽ¯å¢ƒçš„åŠ¨æ€ç‰¹æ€§ï¼Œç„¶åŽå°†è¿™äº›åŠ¨æ€ç‰¹æ€§ä¼ é€’ç»™å­¦ç”Ÿæ¨¡åž‹ï¼Œå­¦ç”Ÿæ¨¡åž‹åˆ™ä¸“æ³¨äºŽä¼˜åŒ–ç¨€ç–å¥–åŠ±ç›®æ ‡ã€‚è¿™æ ·ï¼Œå­¦ç”Ÿæ¨¡åž‹å¯ä»¥åˆ©ç”¨ç¨ å¯†å¥–åŠ±çš„ä¼˜åŠ¿ï¼ŒåŒæ—¶é¿å…è¿‡åº¦æ‹Ÿåˆç¨ å¯†å¥–åŠ±å¸¦æ¥çš„é—®é¢˜ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šè¯¥æ–¹æ³•é‡‡ç”¨ä¸¤é˜¶æ®µæ¡†æž¶ï¼š1) **æ•™å¸ˆæ¨¡åž‹è®­ç»ƒ**ï¼šä½¿ç”¨DreamerV3é£Žæ ¼çš„æ™ºèƒ½ä½“ï¼Œåˆ©ç”¨ç¨ å¯†ç‰¹æƒå¥–åŠ±åœ¨CARLAæ¨¡æ‹Ÿå™¨ä¸­è¿›è¡Œè®­ç»ƒã€‚æ•™å¸ˆæ¨¡åž‹å­¦ä¹ çŽ¯å¢ƒçš„æ½œåœ¨åŠ¨æ€æ¨¡åž‹ã€‚2) **å­¦ç”Ÿæ¨¡åž‹è®­ç»ƒ**ï¼šå­¦ç”Ÿæ¨¡åž‹ä¸Žæ•™å¸ˆæ¨¡åž‹å…±äº«ç›¸åŒçš„è§‚å¯Ÿç©ºé—´ï¼ˆè¯­ä¹‰é¸Ÿçž°å›¾å›¾åƒï¼‰ï¼Œä½†ä»…ä½¿ç”¨ç¨€ç–ä»»åŠ¡å¥–åŠ±è¿›è¡Œè®­ç»ƒã€‚å­¦ç”Ÿæ¨¡åž‹çš„World Modelè¢«æ­£åˆ™åŒ–ä»¥åŒ¹é…æ•™å¸ˆæ¨¡åž‹çš„æ½œåœ¨åŠ¨æ€ã€‚å­¦ç”Ÿæ¨¡åž‹ä¸æ¨¡ä»¿æ•™å¸ˆæ¨¡åž‹çš„åŠ¨ä½œæˆ–ä»·å€¼ä¼°è®¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºŽå°†ç¨ å¯†å¥–åŠ±å­¦ä¹ åˆ°çš„çŽ¯å¢ƒåŠ¨æ€çŸ¥è¯†è’¸é¦åˆ°ç¨€ç–å¥–åŠ±ç­–ç•¥ä¸­ï¼Œä»Žè€Œå®žçŽ°äº†åœ¨ç¨€ç–å¥–åŠ±åœºæ™¯ä¸‹çš„é«˜æ€§èƒ½ã€‚ä¸Žç›´æŽ¥ä½¿ç”¨ç¨ å¯†å¥–åŠ±è®­ç»ƒç­–ç•¥ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•é¿å…äº†ç­–ç•¥è¿‡åº¦æ‹Ÿåˆç¨ å¯†å¥–åŠ±çš„é—®é¢˜ã€‚ä¸Žä»Žå¤´å¼€å§‹è®­ç»ƒç¨€ç–å¥–åŠ±ç­–ç•¥ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨äº†ç¨ å¯†å¥–åŠ±æä¾›çš„ä¸°å¯Œä¿¡æ¯ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨DreamerV3ä½œä¸ºæ•™å¸ˆæ¨¡åž‹å’Œå­¦ç”Ÿæ¨¡åž‹çš„åŸºç¡€æž¶æž„ã€‚2) ä½¿ç”¨KLæ•£åº¦æ¥æ­£åˆ™åŒ–å­¦ç”Ÿæ¨¡åž‹çš„World Modelï¼Œä½¿å…¶åŒ¹é…æ•™å¸ˆæ¨¡åž‹çš„æ½œåœ¨åŠ¨æ€ã€‚3) å­¦ç”Ÿæ¨¡åž‹ä¸æ¨¡ä»¿æ•™å¸ˆæ¨¡åž‹çš„åŠ¨ä½œæˆ–ä»·å€¼ä¼°è®¡ï¼Œè€Œæ˜¯å®Œå…¨ä»Žç¨€ç–å¥–åŠ±ä¸­å­¦ä¹ ç­–ç•¥ã€‚4) æ•™å¸ˆæ¨¡åž‹ä½¿ç”¨ç‰¹æƒä¿¡æ¯ï¼ˆå¦‚è½¦é“å‡ ä½•ã€è¿è§„è¡Œä¸ºã€ç¢°æ’žæ—¶é—´ï¼‰æ¥ç”Ÿæˆç¨ å¯†å¥–åŠ±ï¼Œè€Œå­¦ç”Ÿæ¨¡åž‹ä»…ä½¿ç”¨è¯­ä¹‰é¸Ÿçž°å›¾å›¾åƒä½œä¸ºè¾“å…¥ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼Œåœ¨CARLAè½¦é“è·Ÿéšå’Œè¶…è½¦åŸºå‡†æµ‹è¯•ä¸­ï¼Œç¨€ç–å¥–åŠ±å­¦ç”Ÿæ¨¡åž‹ä¼˜äºŽç¨ å¯†å¥–åŠ±æ•™å¸ˆæ¨¡åž‹å’Œä»Žå¤´å¼€å§‹çš„ç¨€ç–åŸºçº¿ã€‚åœ¨æœªè§è¿‡çš„è½¦é“è·Ÿéšè·¯çº¿ä¸Šï¼Œå¥–åŠ±ç‰¹æƒè’¸é¦ç›¸å¯¹äºŽç¨ å¯†æ•™å¸ˆæé«˜äº†çº¦23%çš„æˆåŠŸçŽ‡ï¼ŒåŒæ—¶ä¿æŒäº†ç›¸å½“æˆ–æ›´å¥½çš„å®‰å…¨æ€§ã€‚åœ¨è¶…è½¦æ–¹é¢ï¼Œå­¦ç”Ÿåœ¨è®­ç»ƒè·¯çº¿ä¸Šä¿æŒäº†è¿‘ä¹Žå®Œç¾Žçš„æ€§èƒ½ï¼Œå¹¶åœ¨æœªè§è¿‡çš„è·¯çº¿ä¸Šå®žçŽ°äº†é«˜è¾¾27å€çš„æˆåŠŸçŽ‡æå‡ï¼Œå¹¶æ”¹å–„äº†è½¦é“ä¿æŒã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽè‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„å¼€å‘ï¼Œå°¤å…¶æ˜¯åœ¨å¥–åŠ±å‡½æ•°éš¾ä»¥è®¾è®¡æˆ–ä¸Žå®žé™…éƒ¨ç½²ç›®æ ‡ä¸å®Œå…¨ä¸€è‡´çš„æƒ…å†µä¸‹ã€‚é€šè¿‡åˆ©ç”¨æ¨¡æ‹Ÿå™¨ä¸­çš„ç¨ å¯†å¥–åŠ±è¿›è¡Œé¢„è®­ç»ƒï¼Œç„¶åŽå°†çŸ¥è¯†è¿ç§»åˆ°çœŸå®žä¸–ç•Œæˆ–ç¨€ç–å¥–åŠ±åœºæ™¯ï¼Œå¯ä»¥æé«˜è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚è¯¥æ–¹æ³•è¿˜å¯ä»¥åº”ç”¨äºŽå…¶ä»–æœºå™¨äººå­¦ä¹ ä»»åŠ¡ï¼Œä¾‹å¦‚å¯¼èˆªã€æ“ä½œç­‰ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We study how to exploit dense simulator-defined rewards in vision-based autonomous driving without inheriting their misalignment with deployment metrics. In realistic simulators such as CARLA, privileged state (e.g., lane geometry, infractions, time-to-collision) can be converted into dense rewards that stabilize and accelerate model-based reinforcement learning, but policies trained directly on these signals often overfit and fail to generalize when evaluated on sparse objectives such as route completion and collision-free overtaking. We propose reward-privileged world model distillation, a two-stage framework in which a teacher DreamerV3-style agent is first trained with a dense privileged reward, and only its latent dynamics are distilled into a student trained solely on sparse task rewards. Teacher and student share the same observation space (semantic bird's-eye-view images); privileged information enters only through the teacher's reward, and the student does not imitate the teacher's actions or value estimates. Instead, the student's world model is regularized to match the teacher's latent dynamics while its policy is learned from scratch on sparse success/failure signals. In CARLA lane-following and overtaking benchmarks, sparse-reward students outperform both dense-reward teachers and sparse-from-scratch baselines. On unseen lane-following routes, reward-privileged distillation improves success by about 23 percent relative to the dense teacher while maintaining comparable or better safety. On overtaking, students retain near-perfect performance on training routes and achieve up to a 27x improvement in success on unseen routes, with improved lane keeping. These results show that dense rewards can be leveraged to learn richer dynamics models while keeping the deployed policy optimized strictly for sparse, deployment-aligned objectives.

