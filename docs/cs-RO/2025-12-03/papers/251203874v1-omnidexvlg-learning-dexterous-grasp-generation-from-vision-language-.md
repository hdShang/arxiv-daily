---
layout: default
title: OmniDexVLG: Learning Dexterous Grasp Generation from Vision Language Model-Guided Grasp Semantics, Taxonomy and Functional Affordance
---

# OmniDexVLG: Learning Dexterous Grasp Generation from Vision Language Model-Guided Grasp Semantics, Taxonomy and Functional Affordance

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.03874" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.03874v1</a>
  <a href="https://arxiv.org/pdf/2512.03874.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.03874v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.03874v1', 'OmniDexVLG: Learning Dexterous Grasp Generation from Vision Language Model-Guided Grasp Semantics, Taxonomy and Functional Affordance')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Lei Zhang, Diwen Zheng, Kaixin Bai, Zhenshan Bing, Zoltan-Csaba Marton, Zhaopeng Chen, Alois Christian Knoll, Jianwei Zhang

**åˆ†ç±»**: cs.RO, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-12-03

**å¤‡æ³¨**: Project Website: https://sites.google.com/view/omnidexvlg, 16 pages

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**OmniDexVLGï¼šæå‡ºåŸºäºè§†è§‰è¯­è¨€æ¨¡å‹å¼•å¯¼çš„çµå·§æŠ“å–ç”Ÿæˆæ¡†æ¶ï¼Œå®ç°è¯­ä¹‰å¯æ§çš„æŠ“å–åˆæˆã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `çµå·§æŠ“å–` `è§†è§‰è¯­è¨€æ¨¡å‹` `å¤šæ¨¡æ€å­¦ä¹ ` `è¯­ä¹‰æ¨ç†` `æœºå™¨äººæ“ä½œ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çµå·§æŠ“å–ç”Ÿæˆæ–¹æ³•ç¼ºä¹å¯¹æŠ“å–åˆ†ç±»ã€æ¥è§¦è¯­ä¹‰å’ŒåŠŸèƒ½å¯ä¾›æ€§ç­‰å¤šç»´åº¦è¯­ä¹‰çš„ç»Ÿä¸€å»ºæ¨¡ï¼Œéš¾ä»¥å®ç°è¯­ä¹‰å¯æ§çš„æŠ“å–åˆæˆã€‚
2. OmniDexVLGé€šè¿‡æ„å»ºè¯­ä¹‰ä¸°å¯Œçš„æŠ“å–æ•°æ®é›†å’Œå¤šæ¨¡æ€è¯­ä¹‰æ¨ç†æ¨¡å—ï¼Œæ˜¾å¼åœ°ç»“åˆæŠ“å–åˆ†ç±»ã€æ¥è§¦ç»“æ„å’ŒåŠŸèƒ½å¯ä¾›æ€§è¯­ä¹‰ï¼Œå®ç°ç»†ç²’åº¦çš„æŠ“å–æ§åˆ¶ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒOmniDexVLGåœ¨æŠ“å–å¤šæ ·æ€§ã€æ¥è§¦è¯­ä¹‰å¤šæ ·æ€§ã€åŠŸèƒ½å¯ä¾›æ€§å¤šæ ·æ€§å’Œè¯­ä¹‰ä¸€è‡´æ€§æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºOmniDexVLGï¼Œä¸€ä¸ªå¤šæ¨¡æ€ã€è¯­ä¹‰æ„ŸçŸ¥çš„æŠ“å–ç”Ÿæˆæ¡†æ¶ï¼Œèƒ½å¤Ÿåœ¨è”åˆè¯­è¨€å’Œè§†è§‰å¼•å¯¼ä¸‹ï¼Œç”Ÿæˆç»“æ„å¤šæ ·ä¸”è¯­ä¹‰è¿è´¯çš„çµå·§æŠ“å–ã€‚è¯¥æ–¹æ³•é¦–å…ˆæ„å»ºäº†OmniDexDataGenï¼Œä¸€ä¸ªè¯­ä¹‰ä¸°å¯Œçš„çµå·§æŠ“å–æ•°æ®é›†ç”Ÿæˆæµç¨‹ï¼Œé›†æˆäº†æŠ“å–åˆ†ç±»å¼•å¯¼çš„é…ç½®é‡‡æ ·ã€åŠŸèƒ½å¯ä¾›æ€§æ¥è§¦ç‚¹é‡‡æ ·ã€åˆ†ç±»æ„ŸçŸ¥çš„å¾®åˆ†åŠ›é—­åˆæŠ“å–é‡‡æ ·ä»¥åŠåŸºäºç‰©ç†çš„ä¼˜åŒ–å’ŒéªŒè¯ï¼Œä»è€Œç³»ç»Ÿåœ°è¦†ç›–äº†å„ç§æŠ“å–ç±»å‹ã€‚è¿›ä¸€æ­¥å¼•å…¥OmniDexReasonerï¼Œä¸€ä¸ªå¤šæ¨¡æ€æŠ“å–ç±»å‹è¯­ä¹‰æ¨ç†æ¨¡å—ï¼Œåˆ©ç”¨å¤šæ™ºèƒ½ä½“åä½œã€æ£€ç´¢å¢å¼ºç”Ÿæˆå’Œæ€ç»´é“¾æ¨ç†æ¥æ¨æ–­æŠ“å–ç›¸å…³çš„è¯­ä¹‰ï¼Œå¹¶ç”Ÿæˆé«˜è´¨é‡çš„æ ‡æ³¨ï¼Œä½¿è¯­è¨€æŒ‡ä»¤ä¸ç‰¹å®šä»»åŠ¡çš„æŠ“å–æ„å›¾å¯¹é½ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œå¼€å‘äº†ä¸€ä¸ªç»Ÿä¸€çš„è§†è§‰è¯­è¨€æŠ“å–ç”Ÿæˆæ¨¡å‹ï¼Œæ˜¾å¼åœ°ç»“åˆäº†æŠ“å–åˆ†ç±»ã€æ¥è§¦ç»“æ„å’ŒåŠŸèƒ½å¯ä¾›æ€§è¯­ä¹‰ï¼Œä»è€Œèƒ½å¤Ÿé€šè¿‡è‡ªç„¶è¯­è¨€æŒ‡ä»¤å¯¹æŠ“å–åˆæˆè¿›è¡Œç»†ç²’åº¦çš„æ§åˆ¶ã€‚åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ç‰©ä½“æŠ“å–ä¸­çš„å¤§é‡å®éªŒä»¥åŠæ¶ˆèç ”ç©¶è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æŠ“å–å¤šæ ·æ€§ã€æ¥è§¦è¯­ä¹‰å¤šæ ·æ€§ã€åŠŸèƒ½å¯ä¾›æ€§å¤šæ ·æ€§å’Œè¯­ä¹‰ä¸€è‡´æ€§æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çµå·§æŠ“å–ç”Ÿæˆæ–¹æ³•éš¾ä»¥ç»Ÿä¸€å»ºæ¨¡æŠ“å–åˆ†ç±»ã€æ¥è§¦è¯­ä¹‰å’ŒåŠŸèƒ½å¯ä¾›æ€§ç­‰å¤šç»´åº¦è¯­ä¹‰ï¼Œå¯¼è‡´æ— æ³•æ ¹æ®ä»»åŠ¡éœ€æ±‚å’Œäººç±»å¯è§£é‡Šçš„æŠ“å–è¯­ä¹‰ç”ŸæˆæŠ“å–å§¿æ€ï¼Œç¼ºä¹è¯­ä¹‰å¯æ§æ€§ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥å°†è‡ªç„¶è¯­è¨€æŒ‡ä»¤ä¸ç‰¹å®šä»»åŠ¡çš„æŠ“å–æ„å›¾å¯¹é½ï¼Œé™åˆ¶äº†æŠ“å–çš„çµæ´»æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šOmniDexVLGçš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªå¤šæ¨¡æ€ã€è¯­ä¹‰æ„ŸçŸ¥çš„æŠ“å–ç”Ÿæˆæ¡†æ¶ï¼Œé€šè¿‡æ˜¾å¼åœ°ç»“åˆæŠ“å–åˆ†ç±»ã€æ¥è§¦ç»“æ„å’ŒåŠŸèƒ½å¯ä¾›æ€§è¯­ä¹‰ï¼Œå®ç°å¯¹æŠ“å–åˆæˆçš„ç»†ç²’åº¦æ§åˆ¶ã€‚è¯¥æ–¹æ³•åˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹å¼•å¯¼æŠ“å–è¯­ä¹‰çš„å­¦ä¹ ï¼Œä»è€Œèƒ½å¤Ÿæ ¹æ®è‡ªç„¶è¯­è¨€æŒ‡ä»¤ç”Ÿæˆç»“æ„å¤šæ ·ä¸”è¯­ä¹‰è¿è´¯çš„çµå·§æŠ“å–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šOmniDexVLGåŒ…å«ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šOmniDexDataGenã€OmniDexReasonerå’Œè§†è§‰è¯­è¨€æŠ“å–ç”Ÿæˆæ¨¡å‹ã€‚OmniDexDataGenè´Ÿè´£ç”Ÿæˆè¯­ä¹‰ä¸°å¯Œçš„çµå·§æŠ“å–æ•°æ®é›†ï¼Œæ¶µç›–å„ç§æŠ“å–ç±»å‹ã€‚OmniDexReasoneræ˜¯ä¸€ä¸ªå¤šæ¨¡æ€æŠ“å–ç±»å‹è¯­ä¹‰æ¨ç†æ¨¡å—ï¼Œç”¨äºæ¨æ–­æŠ“å–ç›¸å…³çš„è¯­ä¹‰ï¼Œå¹¶å°†è¯­è¨€æŒ‡ä»¤ä¸ç‰¹å®šä»»åŠ¡çš„æŠ“å–æ„å›¾å¯¹é½ã€‚è§†è§‰è¯­è¨€æŠ“å–ç”Ÿæˆæ¨¡å‹åˆ™åˆ©ç”¨è¿™ä¸¤ä¸ªæ¨¡å—çš„è¾“å‡ºï¼Œç”Ÿæˆæœ€ç»ˆçš„æŠ“å–å§¿æ€ã€‚

**å…³é”®åˆ›æ–°**ï¼šOmniDexVLGçš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†OmniDexDataGenï¼Œä¸€ä¸ªè¯­ä¹‰ä¸°å¯Œçš„çµå·§æŠ“å–æ•°æ®é›†ç”Ÿæˆæµç¨‹ï¼Œèƒ½å¤Ÿç³»ç»Ÿåœ°è¦†ç›–å„ç§æŠ“å–ç±»å‹ï¼›2) å¼•å…¥äº†OmniDexReasonerï¼Œä¸€ä¸ªå¤šæ¨¡æ€æŠ“å–ç±»å‹è¯­ä¹‰æ¨ç†æ¨¡å—ï¼Œèƒ½å¤Ÿåˆ©ç”¨å¤šæ™ºèƒ½ä½“åä½œã€æ£€ç´¢å¢å¼ºç”Ÿæˆå’Œæ€ç»´é“¾æ¨ç†æ¥æ¨æ–­æŠ“å–ç›¸å…³çš„è¯­ä¹‰ï¼›3) å¼€å‘äº†ä¸€ä¸ªç»Ÿä¸€çš„è§†è§‰è¯­è¨€æŠ“å–ç”Ÿæˆæ¨¡å‹ï¼Œæ˜¾å¼åœ°ç»“åˆäº†æŠ“å–åˆ†ç±»ã€æ¥è§¦ç»“æ„å’ŒåŠŸèƒ½å¯ä¾›æ€§è¯­ä¹‰ã€‚

**å…³é”®è®¾è®¡**ï¼šOmniDexDataGenä¸­ï¼Œé‡‡ç”¨äº†æŠ“å–åˆ†ç±»å¼•å¯¼çš„é…ç½®é‡‡æ ·ã€åŠŸèƒ½å¯ä¾›æ€§æ¥è§¦ç‚¹é‡‡æ ·ã€åˆ†ç±»æ„ŸçŸ¥çš„å¾®åˆ†åŠ›é—­åˆæŠ“å–é‡‡æ ·ä»¥åŠåŸºäºç‰©ç†çš„ä¼˜åŒ–å’ŒéªŒè¯ç­‰æŠ€æœ¯ï¼Œä»¥ç¡®ä¿æ•°æ®é›†çš„å¤šæ ·æ€§å’Œè´¨é‡ã€‚OmniDexReasonerä¸­ï¼Œåˆ©ç”¨äº†å¤šæ™ºèƒ½ä½“åä½œã€æ£€ç´¢å¢å¼ºç”Ÿæˆå’Œæ€ç»´é“¾æ¨ç†ç­‰æŠ€æœ¯ï¼Œä»¥æé«˜è¯­ä¹‰æ¨ç†çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚è§†è§‰è¯­è¨€æŠ“å–ç”Ÿæˆæ¨¡å‹ä¸­ï¼Œå…·ä½“ç½‘ç»œç»“æ„å’ŒæŸå¤±å‡½æ•°ç­‰ç»†èŠ‚æœªåœ¨æ‘˜è¦ä¸­æ˜ç¡®æåŠï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒOmniDexVLGåœ¨æŠ“å–å¤šæ ·æ€§ã€æ¥è§¦è¯­ä¹‰å¤šæ ·æ€§ã€åŠŸèƒ½å¯ä¾›æ€§å¤šæ ·æ€§å’Œè¯­ä¹‰ä¸€è‡´æ€§æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿æœªåœ¨æ‘˜è¦ä¸­æ˜ç¡®æåŠï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚ä½†æ‘˜è¦å¼ºè°ƒäº†è¯¥æ–¹æ³•åœ¨å¤šä¸ªå…³é”®æŒ‡æ ‡ä¸Šçš„ä¼˜è¶Šæ€§ï¼Œè¡¨æ˜å…¶å…·æœ‰æ˜¾è‘—çš„å®é™…æ•ˆæœã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

OmniDexVLGåœ¨æœºå™¨äººçµå·§æ“ä½œé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚è‡ªåŠ¨åŒ–è£…é…ã€åŒ»ç–—æ‰‹æœ¯ã€å®¶åº­æœåŠ¡ç­‰ã€‚è¯¥ç ”ç©¶èƒ½å¤Ÿæå‡æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸‹çš„æŠ“å–èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£äººç±»æŒ‡ä»¤ï¼Œå¹¶å®Œæˆå„ç§ç²¾ç»†æ“ä½œä»»åŠ¡ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºæ™ºèƒ½åˆ¶é€ ã€æ™ºèƒ½åŒ»ç–—å’Œæ™ºèƒ½å®¶å±…ç­‰é¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Dexterous grasp generation aims to produce grasp poses that align with task requirements and human interpretable grasp semantics. However, achieving semantically controllable dexterous grasp synthesis remains highly challenging due to the lack of unified modeling of multiple semantic dimensions, including grasp taxonomy, contact semantics, and functional affordance. To address these limitations, we present OmniDexVLG, a multimodal, semantics aware grasp generation framework capable of producing structurally diverse and semantically coherent dexterous grasps under joint language and visual guidance. Our approach begins with OmniDexDataGen, a semantic rich dexterous grasp dataset generation pipeline that integrates grasp taxonomy guided configuration sampling, functional affordance contact point sampling, taxonomy aware differential force closure grasp sampling, and physics based optimization and validation, enabling systematic coverage of diverse grasp types. We further introduce OmniDexReasoner, a multimodal grasp type semantic reasoning module that leverages multi agent collaboration, retrieval augmented generation, and chain of thought reasoning to infer grasp related semantics and generate high quality annotations that align language instructions with task specific grasp intent. Building upon these components, we develop a unified Vision Language Grasping generation model that explicitly incorporates grasp taxonomy, contact structure, and functional affordance semantics, enabling fine grained control over grasp synthesis from natural language instructions. Extensive experiments in simulation and real world object grasping and ablation studies demonstrate that our method substantially outperforms state of the art approaches in terms of grasp diversity, contact semantic diversity, functional affordance diversity, and semantic consistency.

