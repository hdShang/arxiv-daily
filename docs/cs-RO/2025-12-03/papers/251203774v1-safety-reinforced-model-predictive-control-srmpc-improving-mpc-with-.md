---
layout: default
title: Safety Reinforced Model Predictive Control (SRMPC): Improving MPC with Reinforcement Learning for Motion Planning in Autonomous Driving
---

# Safety Reinforced Model Predictive Control (SRMPC): Improving MPC with Reinforcement Learning for Motion Planning in Autonomous Driving

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.03774" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.03774v1</a>
  <a href="https://arxiv.org/pdf/2512.03774.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.03774v1" onclick="toggleFavorite(this, '2512.03774v1', 'Safety Reinforced Model Predictive Control (SRMPC): Improving MPC with Reinforcement Learning for Motion Planning in Autonomous Driving')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Johannes Fischer, Marlon Steiner, Ã–mer Sahin Tas, Christoph Stiller

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-12-03

**æœŸåˆŠ**: 2023 IEEE 26th International Conference on Intelligent Transportation Systems (ITSC), Bilbao, Spain, 2023, pp. 2811-2818

**DOI**: [10.1109/ITSC57777.2023.10422605](https://doi.org/10.1109/ITSC57777.2023.10422605)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå®‰å…¨å¼ºåŒ–å­¦ä¹ å¢å¼ºçš„æ¨¡å‹é¢„æµ‹æ§åˆ¶(SRMPC)ï¼Œæå‡è‡ªåŠ¨é©¾é©¶è¿åŠ¨è§„åˆ’çš„å®‰å…¨æ€§ä¸æ€§èƒ½ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æ¨¡å‹é¢„æµ‹æ§åˆ¶` `å¼ºåŒ–å­¦ä¹ ` `å®‰å…¨å¼ºåŒ–å­¦ä¹ ` `è‡ªåŠ¨é©¾é©¶` `è¿åŠ¨è§„åˆ’`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»ŸMPCä¸ºä¿è¯å®æ—¶æ€§é‡‡ç”¨å‡¸è¿‘ä¼¼ï¼Œé™åˆ¶äº†è§£ç©ºé—´ï¼Œå¯èƒ½é”™è¿‡å…¨å±€æœ€ä¼˜è§£ï¼Œå½±å“è‡ªåŠ¨é©¾é©¶æ€§èƒ½ã€‚
2. æå‡ºSRMPCï¼Œåˆ©ç”¨å®‰å…¨å¼ºåŒ–å­¦ä¹ åœ¨MPCæ¡†æ¶å†…ç”Ÿæˆå®‰å…¨å‚è€ƒè½¨è¿¹ï¼Œæ¢ç´¢æ›´å¹¿é˜”çš„è§£ç©ºé—´ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒSRMPCåœ¨é«˜é€Ÿå…¬è·¯åœºæ™¯ä¸­ï¼Œç›¸æ¯”MPCå’ŒSRLï¼Œåœ¨å®‰å…¨æ€§å’Œæ€§èƒ½ä¸Šå‡æœ‰æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§å®‰å…¨å¼ºåŒ–å­¦ä¹ å¢å¼ºçš„æ¨¡å‹é¢„æµ‹æ§åˆ¶(SRMPC)æ–¹æ³•ï¼Œç”¨äºæå‡è‡ªåŠ¨é©¾é©¶ä¸­çš„è¿åŠ¨è§„åˆ’æ€§èƒ½ã€‚ä¼ ç»Ÿçš„æ¨¡å‹é¢„æµ‹æ§åˆ¶(MPC)ä¸ºäº†ä¿è¯å®æ—¶æ€§ï¼Œé€šå¸¸é‡‡ç”¨å‡¸è¿‘ä¼¼æ¥ç®€åŒ–æœ€ä¼˜æ§åˆ¶é—®é¢˜(OCP)ï¼Œä½†è¿™ä¼šå°†è§£é™åˆ¶åœ¨å¯èƒ½ä¸åŒ…å«å…¨å±€æœ€ä¼˜è§£çš„å­ç©ºé—´ä¸­ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬åˆ©ç”¨å®‰å…¨å¼ºåŒ–å­¦ä¹ (SRL)åœ¨MPCæ¡†æ¶å†…ç”Ÿæˆæ–°çš„ã€å®‰å…¨çš„å‚è€ƒè½¨è¿¹ã€‚é€šè¿‡å­¦ä¹ çš„æ–¹å¼ï¼ŒMPCå¯ä»¥æ¢ç´¢å…ˆå‰è§£çš„é‚»åŸŸä¹‹å¤–çš„è§£ç©ºé—´ï¼Œä»è€Œæ‰¾åˆ°å…¨å±€æœ€ä¼˜è§£ã€‚æˆ‘ä»¬é‡‡ç”¨çº¦æŸå¼ºåŒ–å­¦ä¹ (CRL)æ¥ç¡®ä¿è‡ªåŠ¨é©¾é©¶çš„å®‰å…¨æ€§ï¼Œå¹¶ä½¿ç”¨åŸºäºæ‰‹å·¥è®¾è®¡çš„èƒ½é‡å‡½æ•°çš„å®‰å…¨æŒ‡æ ‡ä½œä¸ºçº¦æŸç›®æ ‡ï¼Œä»¥å»ºæ¨¡å®‰å…¨å’Œä¸å®‰å…¨åŒºåŸŸã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨ä¸€ä¸ªçŠ¶æ€ç›¸å…³çš„æ‹‰æ ¼æœ—æ—¥ä¹˜å­ï¼Œä¸å®‰å…¨ç­–ç•¥åŒæ—¶å­¦ä¹ ï¼Œä»¥è§£å†³CRLé—®é¢˜ã€‚åœ¨é«˜é€Ÿå…¬è·¯åœºæ™¯ä¸­çš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å®‰å…¨æ€§å’Œæ€§èƒ½æŒ‡æ ‡æ–¹é¢å‡ä¼˜äºMPCå’ŒSRLã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šä¼ ç»Ÿæ¨¡å‹é¢„æµ‹æ§åˆ¶(MPC)åœ¨è‡ªåŠ¨é©¾é©¶è¿åŠ¨è§„åˆ’ä¸­å¹¿æ³›åº”ç”¨ï¼Œä½†ä¸ºäº†æ»¡è¶³å®æ—¶æ€§è¦æ±‚ï¼Œé€šå¸¸éœ€è¦å¯¹æœ€ä¼˜æ§åˆ¶é—®é¢˜(OCP)è¿›è¡Œå‡¸è¿‘ä¼¼ã€‚è¿™ç§è¿‘ä¼¼ä¼šå°†è§£é™åˆ¶åœ¨ä¸€ä¸ªå­ç©ºé—´å†…ï¼Œå¯èƒ½æ— æ³•æ‰¾åˆ°å…¨å±€æœ€ä¼˜è§£ï¼Œä»è€Œå½±å“è§„åˆ’æ€§èƒ½ã€‚æ­¤å¤–ï¼Œå•çº¯ä¾èµ–MPCéš¾ä»¥åº”å¯¹å¤æ‚å’ŒåŠ¨æ€çš„äº¤é€šç¯å¢ƒï¼Œå®¹æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜æˆ–äº§ç”Ÿä¸å®‰å…¨çš„è¡Œä¸ºã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å®‰å…¨å¼ºåŒ–å­¦ä¹ (SRL)æ¥å¢å¼ºMPCçš„æ€§èƒ½ã€‚å…·ä½“æ¥è¯´ï¼ŒSRLè´Ÿè´£åœ¨MPCçš„æ¡†æ¶å†…ç”Ÿæˆæ–°çš„ã€å®‰å…¨çš„å‚è€ƒè½¨è¿¹ã€‚é€šè¿‡å­¦ä¹ ï¼ŒMPCå¯ä»¥æ¢ç´¢æ›´å¹¿é˜”çš„è§£ç©ºé—´ï¼Œæ‘†è„±å¯¹åˆå§‹è§£é‚»åŸŸçš„ä¾èµ–ï¼Œä»è€Œæ›´æœ‰å¯èƒ½æ‰¾åˆ°å…¨å±€æœ€ä¼˜è§£ã€‚åŒæ—¶ï¼Œé€šè¿‡çº¦æŸå¼ºåŒ–å­¦ä¹ (CRL)ä¿è¯ç”Ÿæˆè½¨è¿¹çš„å®‰å…¨æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSRMPCçš„æ•´ä½“æ¡†æ¶å¯ä»¥æ¦‚æ‹¬ä¸ºï¼šé¦–å…ˆï¼Œä½¿ç”¨ä¼ ç»Ÿçš„MPCç”Ÿæˆä¸€ä¸ªåˆå§‹è½¨è¿¹ï¼›ç„¶åï¼Œåˆ©ç”¨SRLå­¦ä¹ ä¸€ä¸ªç­–ç•¥ï¼Œè¯¥ç­–ç•¥èƒ½å¤Ÿç”Ÿæˆæ–°çš„å‚è€ƒè½¨è¿¹ï¼Œå¹¶å°†å…¶åé¦ˆç»™MPCï¼›MPCåŸºäºæ–°çš„å‚è€ƒè½¨è¿¹è¿›è¡Œä¼˜åŒ–ï¼Œå¾—åˆ°æœ€ç»ˆçš„æ§åˆ¶æŒ‡ä»¤ã€‚ä¸ºäº†ä¿è¯å®‰å…¨æ€§ï¼ŒSRLé‡‡ç”¨çº¦æŸå¼ºåŒ–å­¦ä¹ (CRL)ï¼Œå°†å®‰å…¨æ€§æŒ‡æ ‡ä½œä¸ºçº¦æŸæ¡ä»¶ã€‚CRLé—®é¢˜çš„æ±‚è§£é€šè¿‡å­¦ä¹ ä¸€ä¸ªçŠ¶æ€ç›¸å…³çš„æ‹‰æ ¼æœ—æ—¥ä¹˜å­æ¥å®ç°ï¼Œè¯¥ä¹˜å­ä¸å®‰å…¨ç­–ç•¥åŒæ—¶å­¦ä¹ ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå°†å®‰å…¨å¼ºåŒ–å­¦ä¹ ä¸æ¨¡å‹é¢„æµ‹æ§åˆ¶ç›¸ç»“åˆï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ æ¢ç´¢æ›´ä¼˜è§£ç©ºé—´çš„åŒæ—¶ï¼Œä¿è¯äº†è¿åŠ¨è§„åˆ’çš„å®‰å…¨æ€§ã€‚ä¸ä¼ ç»Ÿçš„MPCç›¸æ¯”ï¼ŒSRMPCèƒ½å¤Ÿè·³å‡ºå±€éƒ¨æœ€ä¼˜ï¼Œæ‰¾åˆ°å…¨å±€æ›´ä¼˜çš„è½¨è¿¹ã€‚ä¸å•çº¯çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ç›¸æ¯”ï¼ŒSRMPCåˆ©ç”¨MPCçš„é¢„æµ‹èƒ½åŠ›ï¼Œæé«˜äº†è§„åˆ’çš„ç¨³å®šæ€§å’Œå¯è§£é‡Šæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨CRLä¸­ï¼Œä½¿ç”¨åŸºäºæ‰‹å·¥è®¾è®¡çš„èƒ½é‡å‡½æ•°çš„å®‰å…¨æŒ‡æ ‡ä½œä¸ºçº¦æŸç›®æ ‡ï¼Œç”¨äºå»ºæ¨¡å®‰å…¨å’Œä¸å®‰å…¨åŒºåŸŸã€‚çŠ¶æ€ç›¸å…³çš„æ‹‰æ ¼æœ—æ—¥ä¹˜å­ç”¨äºå¹³è¡¡æ€§èƒ½å’Œå®‰å…¨çº¦æŸã€‚å…·ä½“æ¥è¯´ï¼ŒæŸå¤±å‡½æ•°åŒ…å«ä¸¤éƒ¨åˆ†ï¼šä¸€éƒ¨åˆ†æ˜¯å¼ºåŒ–å­¦ä¹ çš„å¥–åŠ±å‡½æ•°ï¼Œå¦ä¸€éƒ¨åˆ†æ˜¯å®‰å…¨çº¦æŸçš„æƒ©ç½šé¡¹ï¼Œæƒ©ç½šé¡¹çš„å¤§å°ç”±æ‹‰æ ¼æœ—æ—¥ä¹˜å­å†³å®šã€‚æ‹‰æ ¼æœ—æ—¥ä¹˜å­å’Œç­–ç•¥ç½‘ç»œåŒæ—¶è¿›è¡Œè®­ç»ƒï¼Œä»¥ä¿è¯åœ¨æ»¡è¶³å®‰å…¨çº¦æŸçš„å‰æä¸‹ï¼Œæœ€å¤§åŒ–å¥–åŠ±å‡½æ•°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨é«˜é€Ÿå…¬è·¯åœºæ™¯çš„å®éªŒä¸­ï¼ŒSRMPCåœ¨å®‰å…¨æ€§å’Œæ€§èƒ½æŒ‡æ ‡æ–¹é¢å‡ä¼˜äºä¼ ç»Ÿçš„MPCå’ŒSRLæ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼ŒSRMPCèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°é¿å…ç¢°æ’ï¼ŒåŒæ—¶ä¿æŒè¾ƒé«˜çš„è¡Œé©¶é€Ÿåº¦å’Œè¾ƒä½çš„æ²¹è€—ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSRMPCåœ¨ä¿è¯å®‰å…¨æ€§çš„å‰æä¸‹ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡è‡ªåŠ¨é©¾é©¶è½¦è¾†çš„æ•´ä½“æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SRMPCæ–¹æ³•å¯åº”ç”¨äºå„ç§è‡ªåŠ¨é©¾é©¶åœºæ™¯ï¼Œä¾‹å¦‚é«˜é€Ÿå…¬è·¯å·¡èˆªã€åŸå¸‚é“è·¯å¯¼èˆªã€è‡ªåŠ¨æ³Šè½¦ç­‰ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿæé«˜è‡ªåŠ¨é©¾é©¶è½¦è¾†åœ¨å¤æ‚äº¤é€šç¯å¢ƒä¸­çš„å®‰å…¨æ€§å’Œæ€§èƒ½ï¼Œå‡å°‘äººä¸ºå¹²é¢„ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–æœºå™¨äººè¿åŠ¨è§„åˆ’é¢†åŸŸï¼Œä¾‹å¦‚æ— äººæœºã€æ— äººèˆ¹ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Model predictive control (MPC) is widely used for motion planning, particularly in autonomous driving. Real-time capability of the planner requires utilizing convex approximation of optimal control problems (OCPs) for the planner. However, such approximations confine the solution to a subspace, which might not contain the global optimum. To address this, we propose using safe reinforcement learning (SRL) to obtain a new and safe reference trajectory within MPC. By employing a learning-based approach, the MPC can explore solutions beyond the close neighborhood of the previous one, potentially finding global optima. We incorporate constrained reinforcement learning (CRL) to ensure safety in automated driving, using a handcrafted energy function-based safety index as the constraint objective to model safe and unsafe regions. Our approach utilizes a state-dependent Lagrangian multiplier, learned concurrently with the safe policy, to solve the CRL problem. Through experimentation in a highway scenario, we demonstrate the superiority of our approach over both MPC and SRL in terms of safety and performance measures.

