---
layout: default
title: Learning to Act Through Contact: A Unified View of Multi-Task Robot Learning
---

# Learning to Act Through Contact: A Unified View of Multi-Task Robot Learning

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.03599" target="_blank" class="toolbar-btn">arXiv: 2510.03599v1</a>
    <a href="https://arxiv.org/pdf/2510.03599.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.03599v1" 
            onclick="toggleFavorite(this, '2510.03599v1', 'Learning to Act Through Contact: A Unified View of Multi-Task Robot Learning')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Shafeef Omar, Majid Khadiv

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-04

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éÊé•Ëß¶ÁöÑÁªü‰∏ÄÂ§ö‰ªªÂä°Êú∫Âô®‰∫∫Â≠¶‰π†Ê°ÜÊû∂ÔºåÂÆûÁé∞ÈÄöÁî®ËøêÂä®‰∏éÊìç‰ΩúÁ≠ñÁï•**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Êú∫Âô®‰∫∫Â≠¶‰π†` `Âº∫ÂåñÂ≠¶‰π†` `Â§ö‰ªªÂä°Â≠¶‰π†` `Êé•Ëß¶‰∫§‰∫í` `ËøêÂä®ËßÑÂàí`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊú∫Âô®‰∫∫Â≠¶‰π†ÊñπÊ≥ïÈÄöÂ∏∏‰∏∫ÊØè‰∏™‰ªªÂä°ËÆæËÆ°Áã¨Á´ãÁ≠ñÁï•ÔºåÁº∫‰πèÈÄöÁî®ÊÄßÔºåÈöæ‰ª•Â∫îÂØπÂ§çÊùÇ‰ªªÂä°„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫Âü∫‰∫éÊé•Ëß¶ÁõÆÊ†áÁöÑÁªü‰∏ÄÊ°ÜÊû∂ÔºåÈÄöËøáÊé•Ëß¶‰ΩçÁΩÆ„ÄÅÊó∂Èó¥ÂíåÊâßË°åÂô®Â∫èÂàóÂÆö‰πâ‰ªªÂä°ÔºåÂÆûÁé∞Ë∑®‰ªªÂä°Áü•ËØÜÂÖ±‰∫´„ÄÇ
3. ÂÆûÈ™åÈ™åËØÅ‰∫ÜËØ•Ê°ÜÊû∂Âú®Â§öÁßçÊú∫Âô®‰∫∫ÂΩ¢ÊÄÅÂíå‰ªªÂä°‰∏äÁöÑÊúâÊïàÊÄßÔºåÂ±ïÁ§∫‰∫ÜËâØÂ•ΩÁöÑÊ≥õÂåñËÉΩÂäõÂíåÈ≤ÅÊ£íÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÁªü‰∏ÄÁöÑÊ°ÜÊû∂ÔºåÁî®‰∫éÂ§ö‰ªªÂä°ËøêÂä®ÂíåÊìç‰ΩúÁ≠ñÁï•Â≠¶‰π†ÔºåËØ•Ê°ÜÊû∂Âü∫‰∫éÊòæÂºèÊé•Ëß¶Ë°®Á§∫„ÄÇ‰∏çÂêå‰∫é‰∏∫‰∏çÂêå‰ªªÂä°ËÆæËÆ°‰∏çÂêåÁöÑÁ≠ñÁï•ÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÈÄöËøá‰∏ÄÁ≥ªÂàóÊé•Ëß¶ÁõÆÊ†áÔºàÊúüÊúõÁöÑÊé•Ëß¶‰ΩçÁΩÆ„ÄÅÊó∂Èó¥Âíå‰∏ªÂä®Êú´Á´ØÊâßË°åÂô®ÔºâÁªü‰∏Ä‰∫Ü‰ªªÂä°ÁöÑÂÆö‰πâ„ÄÇËøô‰ΩøÂæóËÉΩÂ§üÂà©Áî®‰∏çÂêåÊé•Ëß¶‰∏∞ÂØåÁöÑ‰ªªÂä°‰πãÈó¥ÁöÑÂÖ±‰∫´ÁªìÊûÑÔºå‰ªéËÄå‰∫ßÁîü‰∏Ä‰∏™ËÉΩÂ§üÊâßË°åÂêÑÁßç‰ªªÂä°ÁöÑÂçï‰∏ÄÁ≠ñÁï•„ÄÇÁâπÂà´Âú∞ÔºåÊàë‰ª¨ËÆ≠ÁªÉ‰∫Ü‰∏Ä‰∏™ÁõÆÊ†áÊù°‰ª∂Âº∫ÂåñÂ≠¶‰π†ÔºàRLÔºâÁ≠ñÁï•Êù•ÂÆûÁé∞ÁªôÂÆöÁöÑÊé•Ëß¶ËÆ°Âàí„ÄÇÊàë‰ª¨Âú®Â§ö‰∏™Êú∫Âô®‰∫∫ÂΩ¢ÊÄÅÂíå‰ªªÂä°‰∏äÈ™åËØÅ‰∫ÜÊàë‰ª¨ÁöÑÊ°ÜÊû∂ÔºöÂõõË∂≥Êú∫Âô®‰∫∫ÊâßË°åÂ§ö‰∏™Ê≠•ÊÄÅÔºå‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ÊâßË°åÂ§ö‰∏™ÂèåË∂≥ÂíåÂõõË∂≥Ê≠•ÊÄÅÔºå‰ª•Âèä‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ÊâßË°å‰∏çÂêåÁöÑÂèåÊâãÁâ©‰ΩìÊìç‰Ωú‰ªªÂä°„ÄÇÊØè‰∏™Âú∫ÊôØÈÉΩÁî±‰∏Ä‰∏™Âçï‰∏ÄÁ≠ñÁï•ÊéßÂà∂ÔºåËØ•Á≠ñÁï•ÁªèËøáËÆ≠ÁªÉ‰ª•ÊâßË°åÂü∫‰∫éÊé•Ëß¶ÁöÑ‰∏çÂêå‰ªªÂä°ÔºåÂ±ïÁ§∫‰∫ÜË∑®ÂΩ¢ÊÄÅ‰∏çÂêåÁ≥ªÁªüÁöÑÈÄöÁî®ÂíåÈ≤ÅÊ£íË°å‰∏∫„ÄÇÊàë‰ª¨ÁöÑÁªìÊûúË°®ÊòéÔºåÊòæÂºèÊé•Ëß¶Êé®ÁêÜÊòæËëóÊèêÈ´ò‰∫ÜÂØπÊú™ËßÅÂú∫ÊôØÁöÑÊ≥õÂåñËÉΩÂäõÔºåÂ∞ÜÊòæÂºèÊé•Ëß¶Á≠ñÁï•Â≠¶‰π†ÂÆö‰Ωç‰∏∫ÂèØÊâ©Â±ïÁöÑËøêÂä®Êìç‰ΩúÁöÑÊúâÂ∏åÊúõÁöÑÂü∫Á°Ä„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÊú∫Âô®‰∫∫Â≠¶‰π†ÊñπÊ≥ïÈÄöÂ∏∏ÈíàÂØπÁâπÂÆö‰ªªÂä°ËÆæËÆ°Á≠ñÁï•ÔºåÈöæ‰ª•Ê≥õÂåñÂà∞Êñ∞ÁöÑ‰ªªÂä°ÊàñÁéØÂ¢É„ÄÇÂ∞§ÂÖ∂ÊòØÂú®ËøêÂä®ÂíåÊìç‰Ωú‰ªªÂä°‰∏≠ÔºåÈúÄË¶ÅÂ§ÑÁêÜÂ§çÊùÇÁöÑÊé•Ëß¶‰∫§‰∫íÔºåËÄåÁé∞ÊúâÊñπÊ≥ïÂæÄÂæÄÈöæ‰ª•ÊòæÂºèÂú∞Âª∫Ê®°Êé•Ëß¶‰ø°ÊÅØÔºåÂØºËá¥Á≠ñÁï•ÁöÑÈ≤ÅÊ£íÊÄßÂíåÊ≥õÂåñËÉΩÂäõ‰∏çË∂≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞Ü‰∏çÂêåÁöÑËøêÂä®ÂíåÊìç‰Ωú‰ªªÂä°Áªü‰∏ÄË°®Á§∫‰∏∫‰∏ÄÁ≥ªÂàóÊé•Ëß¶ÁõÆÊ†áÔºåÂåÖÊã¨ÊúüÊúõÁöÑÊé•Ëß¶‰ΩçÁΩÆ„ÄÅÊó∂Èó¥Âíå‰∏ªÂä®Êú´Á´ØÊâßË°åÂô®„ÄÇÈÄöËøáËøôÁßçÊñπÂºèÔºå‰∏çÂêåÁöÑ‰ªªÂä°ÂèØ‰ª•ÂÖ±‰∫´Â∫ïÂ±ÇÁöÑÊé•Ëß¶‰∫§‰∫íÊ®°ÂºèÔºå‰ªéËÄåÂÆûÁé∞Ë∑®‰ªªÂä°ÁöÑÁü•ËØÜËøÅÁßªÂíåÊ≥õÂåñ„ÄÇËÆ∫ÊñáËÆ≠ÁªÉ‰∏Ä‰∏™ÁõÆÊ†áÊù°‰ª∂Âº∫ÂåñÂ≠¶‰π†Á≠ñÁï•ÔºåÊ†πÊçÆÁªôÂÆöÁöÑÊé•Ëß¶ËÆ°ÂàíÁîüÊàêÁõ∏Â∫îÁöÑÂä®‰ΩúÂ∫èÂàó„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•Ê°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Ê®°ÂùóÔºö1ÔºâÊé•Ëß¶ËÆ°ÂàíÁîüÊàêÂô®ÔºöÊ†πÊçÆ‰ªªÂä°ÁõÆÊ†áÁîüÊàê‰∏ÄÁ≥ªÂàóÊé•Ëß¶ÁõÆÊ†áÔºõ2ÔºâÁõÆÊ†áÊù°‰ª∂Âº∫ÂåñÂ≠¶‰π†Á≠ñÁï•ÔºöÊ†πÊçÆÂΩìÂâçÁä∂ÊÄÅÂíåÊé•Ëß¶ÁõÆÊ†áÔºåÁîüÊàêÊú∫Âô®‰∫∫ÁöÑÂä®‰ΩúÔºõ3ÔºâÁéØÂ¢ÉÊ®°ÊãüÂô®ÔºöÁî®‰∫éËÆ≠ÁªÉÂíåËØÑ‰º∞Âº∫ÂåñÂ≠¶‰π†Á≠ñÁï•„ÄÇÊï¥‰ΩìÊµÅÁ®ãÊòØÔºåÈ¶ñÂÖàÁî±Êé•Ëß¶ËÆ°ÂàíÁîüÊàêÂô®ÁîüÊàêÊé•Ëß¶ÁõÆÊ†áÂ∫èÂàóÔºåÁÑ∂ÂêéÂ∞ÜÂΩìÂâçÁä∂ÊÄÅÂíåÊé•Ëß¶ÁõÆÊ†áËæìÂÖ•Âà∞ÁõÆÊ†áÊù°‰ª∂Âº∫ÂåñÂ≠¶‰π†Á≠ñÁï•‰∏≠ÔºåÁ≠ñÁï•ËæìÂá∫Êú∫Âô®‰∫∫ÁöÑÂä®‰ΩúÔºåÁéØÂ¢ÉÊ®°ÊãüÂô®Ê†πÊçÆÂä®‰ΩúÊõ¥Êñ∞Êú∫Âô®‰∫∫ÁöÑÁä∂ÊÄÅÔºåÂπ∂ËÆ°ÁÆóÂ•ñÂä±‰ø°Âè∑ÔºåÁî®‰∫éËÆ≠ÁªÉÂº∫ÂåñÂ≠¶‰π†Á≠ñÁï•„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÂ∞Ü‰∏çÂêåÁöÑËøêÂä®ÂíåÊìç‰Ωú‰ªªÂä°Áªü‰∏ÄË°®Á§∫‰∏∫‰∏ÄÁ≥ªÂàóÊé•Ëß¶ÁõÆÊ†á„ÄÇËøôÁßçË°®Á§∫ÊñπÂºèËÉΩÂ§üÊòæÂºèÂú∞Âª∫Ê®°Êé•Ëß¶‰ø°ÊÅØÔºåÂπ∂Âà©Áî®‰∏çÂêå‰ªªÂä°‰πãÈó¥ÁöÑÂÖ±‰∫´ÁªìÊûÑÔºå‰ªéËÄåÊèêÈ´òÁ≠ñÁï•ÁöÑÊ≥õÂåñËÉΩÂäõÂíåÈ≤ÅÊ£íÊÄß„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ï‰∏çÈúÄË¶Å‰∏∫ÊØè‰∏™‰ªªÂä°ÂçïÁã¨ËÆæËÆ°Á≠ñÁï•ÔºåËÄåÊòØÂèØ‰ª•ÈÄöËøá‰∏Ä‰∏™Áªü‰∏ÄÁöÑÁ≠ñÁï•Êù•ÂÆåÊàêÂ§ö‰∏™‰ªªÂä°„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËÆ∫Êñá‰ΩøÁî®ÁõÆÊ†áÊù°‰ª∂Âº∫ÂåñÂ≠¶‰π†ÁÆóÊ≥ïÊù•ËÆ≠ÁªÉÁ≠ñÁï•ÔºåÂ•ñÂä±ÂáΩÊï∞ÁöÑËÆæËÆ°Ëá≥ÂÖ≥ÈáçË¶ÅÔºåÈúÄË¶ÅËÄÉËôëÊé•Ëß¶ÁõÆÊ†áÁöÑÂÆûÁé∞Á®ãÂ∫¶„ÄÅÂä®‰ΩúÁöÑÂπ≥ÊªëÊÄß‰ª•ÂèäËÉΩÈáèÊ∂àËÄóÁ≠âÂõ†Á¥†„ÄÇÂÖ∑‰ΩìÁöÑÁΩëÁªúÁªìÊûÑÊú™Áü•Ôºå‰ΩÜÊé®Êµã‰ΩøÁî®‰∫ÜÂæ™ÁéØÁ•ûÁªèÁΩëÁªúÔºàRNNÔºâÊàñTransformerÁ≠âÁªìÊûÑÊù•Â§ÑÁêÜÊé•Ëß¶ÁõÆÊ†áÂ∫èÂàó„ÄÇËÆ∫Êñá‰∏≠Êé•Ëß¶ËÆ°ÂàíÁîüÊàêÂô®ÁöÑÂÖ∑‰ΩìÂÆûÁé∞ÊñπÂºèÊú™Áü•ÔºåÂèØËÉΩ‰ΩøÁî®‰∫Ü‰∫∫Â∑•ËÆæËÆ°ÊàñÂ≠¶‰π†ÁöÑÊñπÊ≥ï„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•Ê°ÜÊû∂Âú®Â§öÁßçÊú∫Âô®‰∫∫ÂΩ¢ÊÄÅÂíå‰ªªÂä°‰∏äÈÉΩÂèñÂæó‰∫ÜËâØÂ•ΩÁöÑÊïàÊûú„ÄÇ‰æãÂ¶ÇÔºåÂõõË∂≥Êú∫Âô®‰∫∫ÂèØ‰ª•ÊâßË°åÂ§öÁßçÊ≠•ÊÄÅÔºå‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ÂèØ‰ª•ÊâßË°åÂèåË∂≥ÂíåÂõõË∂≥Ê≠•ÊÄÅÔºåÂπ∂‰∏î‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ÂèØ‰ª•ÊâßË°å‰∏çÂêåÁöÑÂèåÊâãÁâ©‰ΩìÊìç‰Ωú‰ªªÂä°„ÄÇ‰∏é‰º†ÁªüÁöÑÂü∫‰∫é‰ªªÂä°ÁâπÂÆöÁ≠ñÁï•ÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïÂÖ∑ÊúâÊõ¥Â•ΩÁöÑÊ≥õÂåñËÉΩÂäõÂíåÈ≤ÅÊ£íÊÄßÔºåËÉΩÂ§üÊõ¥Â•ΩÂú∞ÈÄÇÂ∫îÊú™ËßÅËøáÁöÑÂú∫ÊôØ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂêÑÁßçÈúÄË¶ÅÂ§çÊùÇËøêÂä®ÂíåÊìç‰ΩúÁöÑÊú∫Âô®‰∫∫‰ªªÂä°Ôºå‰æãÂ¶ÇÔºöÂÆ∂Â∫≠ÊúçÂä°Êú∫Âô®‰∫∫„ÄÅÂ∑•‰∏öËá™Âä®ÂåñÊú∫Âô®‰∫∫„ÄÅÊêúÊïëÊú∫Âô®‰∫∫Á≠â„ÄÇÈÄöËøáÂ≠¶‰π†ÈÄöÁî®ÁöÑÊé•Ëß¶‰∫§‰∫íÁ≠ñÁï•ÔºåÊú∫Âô®‰∫∫ÂèØ‰ª•Êõ¥Â•ΩÂú∞ÈÄÇÂ∫î‰∏çÂêåÁöÑÁéØÂ¢ÉÂíå‰ªªÂä°ÔºåÊèêÈ´òÂ∑•‰ΩúÊïàÁéáÂíåÂÆâÂÖ®ÊÄß„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïÊúâÊúõÊé®Âä®Êú∫Âô®‰∫∫ÊäÄÊúØÂú®Êõ¥Â§öÈ¢ÜÂüüÁöÑÂ∫îÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> We present a unified framework for multi-task locomotion and manipulation policy learning grounded in a contact-explicit representation. Instead of designing different policies for different tasks, our approach unifies the definition of a task through a sequence of contact goals-desired contact positions, timings, and active end-effectors. This enables leveraging the shared structure across diverse contact-rich tasks, leading to a single policy that can perform a wide range of tasks. In particular, we train a goal-conditioned reinforcement learning (RL) policy to realise given contact plans. We validate our framework on multiple robotic embodiments and tasks: a quadruped performing multiple gaits, a humanoid performing multiple biped and quadrupedal gaits, and a humanoid executing different bimanual object manipulation tasks. Each of these scenarios is controlled by a single policy trained to execute different tasks grounded in contacts, demonstrating versatile and robust behaviours across morphologically distinct systems. Our results show that explicit contact reasoning significantly improves generalisation to unseen scenarios, positioning contact-explicit policy learning as a promising foundation for scalable loco-manipulation.

