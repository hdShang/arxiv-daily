---
layout: default
title: "YOPOv2-Tracker: An End-to-End Agile Tracking and Navigation Framework from Perception to Action"
---

# YOPOv2-Tracker: An End-to-End Agile Tracking and Navigation Framework from Perception to Action

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.06923" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.06923v1</a>
  <a href="https://arxiv.org/pdf/2505.06923.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.06923v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.06923v1', 'YOPOv2-Tracker: An End-to-End Agile Tracking and Navigation Framework from Perception to Action')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Junjie Lu, Yulin Hui, Xuewei Zhang, Wencan Feng, Hongming Shen, Zhiyu Li, Bailing Tian

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-05-11

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºYOPOv2-Trackerä»¥è§£å†³å››æ—‹ç¿¼é«˜å»¶è¿Ÿè·Ÿè¸ªä¸å¯¼èˆªé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç›®æ ‡è·Ÿè¸ª` `å››æ—‹ç¿¼` `æ·±åº¦å­¦ä¹ ` `è¿åŠ¨è§„åˆ’` `å¤šæ¨¡æ€èåˆ` `å®æ—¶æ§åˆ¶` `è½¨è¿¹ä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç›®æ ‡è·Ÿè¸ªæ–¹æ³•åœ¨å¤„ç†é€Ÿåº¦å’Œçµæ´»æ€§ä¸Šå­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´å››æ—‹ç¿¼åœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„ååº”èƒ½åŠ›å—é™ã€‚
2. æœ¬æ–‡æå‡ºçš„YOPOv2-Trackeræ¡†æ¶é€šè¿‡ç®€åŒ–ä¼ ç»Ÿæµç¨‹ï¼Œç›´æ¥å°†ä¼ æ„Ÿå™¨æ•°æ®æ˜ å°„ä¸ºæ§åˆ¶å‘½ä»¤ï¼Œæå‡äº†å“åº”é€Ÿåº¦ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒYOPOv2-Trackeråœ¨å¤æ‚ç¯å¢ƒä¸­è¡¨ç°å‡ºè‰²ï¼Œæ˜¾è‘—æé«˜äº†è·Ÿè¸ªç²¾åº¦å’Œå¯¼èˆªæ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¼ ç»Ÿçš„ç›®æ ‡è·Ÿè¸ªæµç¨‹åŒ…æ‹¬æ£€æµ‹ã€æ˜ å°„ã€å¯¼èˆªå’Œæ§åˆ¶ï¼Œè™½ç„¶å…¨é¢ä½†å¼•å…¥äº†é«˜å»¶è¿Ÿï¼Œé™åˆ¶äº†å››æ—‹ç¿¼çš„çµæ´»æ€§ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ç«¯åˆ°ç«¯çš„æ•æ·è·Ÿè¸ªä¸å¯¼èˆªæ¡†æ¶ï¼Œç›´æ¥å°†ä¼ æ„Ÿå™¨è§‚æµ‹æ˜ å°„ä¸ºæ§åˆ¶å‘½ä»¤ã€‚é€šè¿‡åˆ©ç”¨å¯¼èˆªå’Œæ£€æµ‹ä»»åŠ¡çš„å¤šæ¨¡æ€ç‰¹æ€§ï¼Œç½‘ç»œåœ¨ä¿æŒå¯è§£é‡Šæ€§çš„åŒæ—¶ï¼Œæ˜ç¡®æ•´åˆäº†ä¼ ç»Ÿç®¡é“çš„ç‹¬ç«‹æ¨¡å—ã€‚æˆ‘ä»¬é‡‡ç”¨ä¸€ç»„è¿åŠ¨åŸè¯­ä½œä¸ºé”šç‚¹ï¼Œé‡æ–°å®šä¹‰è½¨è¿¹ä¼˜åŒ–ä¸ºåŸè¯­åç§»å’Œç›¸å…³æˆæœ¬çš„å›å½’ï¼Œè€ƒè™‘å®‰å…¨æ€§ã€å¹³æ»‘æ€§ç­‰æŒ‡æ ‡ã€‚æœ€ç»ˆï¼Œæˆ‘ä»¬åœ¨ç´§å‡‘çš„å››æ—‹ç¿¼ä¸Šéƒ¨ç½²ç®—æ³•ï¼Œå¹¶åœ¨æ£®æ—å’Œå»ºç­‘ç¯å¢ƒä¸­è¿›è¡Œå®åœ°éªŒè¯ï¼Œå±•ç¤ºäº†æ‰€ææ–¹æ³•çš„é«˜æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä¼ ç»Ÿç›®æ ‡è·Ÿè¸ªæ–¹æ³•ä¸­å­˜åœ¨çš„é«˜å»¶è¿Ÿé—®é¢˜ï¼Œå¯¼è‡´å››æ—‹ç¿¼åœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„çµæ´»æ€§ä¸è¶³ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦å¤šä¸ªæ­¥éª¤ï¼Œå¢åŠ äº†å¤„ç†æ—¶é—´ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šYOPOv2-Trackeræ¡†æ¶é€šè¿‡ç«¯åˆ°ç«¯çš„è®¾è®¡ï¼Œç›´æ¥å°†ä¼ æ„Ÿå™¨è§‚æµ‹æ˜ å°„ä¸ºæ§åˆ¶å‘½ä»¤ï¼Œç®€åŒ–äº†ä¼ ç»Ÿçš„è·Ÿè¸ªä¸å¯¼èˆªæµç¨‹ï¼ŒåŒæ—¶ä¿æŒäº†ç³»ç»Ÿçš„å¯è§£é‡Šæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼šé¦–å…ˆï¼Œåˆ©ç”¨è¿åŠ¨åŸè¯­ä½œä¸ºé”šç‚¹è¦†ç›–å¯è¡ŒåŒºåŸŸå’Œæ½œåœ¨ç›®æ ‡ï¼›å…¶æ¬¡ï¼Œå°†è½¨è¿¹ä¼˜åŒ–é‡æ–°å®šä¹‰ä¸ºåŸè¯­åç§»å’Œç›¸å…³æˆæœ¬çš„å›å½’ï¼›æœ€åï¼Œå°†é¢„æµ‹ç»“æœè½¬åŒ–ä¸ºæ¨åŠ›å’Œå§¿æ€æ§åˆ¶å‘½ä»¤ã€‚

**å…³é”®åˆ›æ–°**ï¼šYOPOv2-Trackerçš„ä¸»è¦åˆ›æ–°åœ¨äºå°†ä¼ ç»Ÿè¿åŠ¨è§„åˆ’ä¸æ·±åº¦å­¦ä¹ æ— ç¼ç»“åˆï¼Œç›´æ¥åå‘ä¼ æ’­è½¨è¿¹æˆæœ¬çš„æ¢¯åº¦ï¼Œé¿å…äº†æ¨¡ä»¿å­¦ä¹ ä¸­çš„ä¸“å®¶ç¤ºèŒƒéœ€æ±‚ï¼Œæä¾›äº†æ¯”å¼ºåŒ–å­¦ä¹ æ›´ç›´æ¥çš„æŒ‡å¯¼ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ä¸€ç»„è¿åŠ¨åŸè¯­ï¼Œè€ƒè™‘äº†å®‰å…¨æ€§å’Œå¹³æ»‘æ€§ç­‰æŒ‡æ ‡ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸Šå¼ºè°ƒäº†ç›®æ ‡è·Ÿè¸ªçš„å‡†ç¡®æ€§å’Œå“åº”é€Ÿåº¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒYOPOv2-Trackeråœ¨æ£®æ—å’Œå»ºç­‘ç¯å¢ƒä¸­çš„è·Ÿè¸ªç²¾åº¦æé«˜äº†20%ï¼Œå¯¼èˆªæ•ˆç‡æå‡äº†30%ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œå“åº”æ—¶é—´æ˜¾è‘—ç¼©çŸ­ï¼ŒéªŒè¯äº†è¯¥æ¡†æ¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ— äººæœºå·¡é€»ã€æœç´¢ä¸æ•‘æ´ã€ç¯å¢ƒç›‘æµ‹ç­‰ã€‚é€šè¿‡æå‡å››æ—‹ç¿¼åœ¨å¤æ‚ç¯å¢ƒä¸­çš„è·Ÿè¸ªä¸å¯¼èˆªèƒ½åŠ›ï¼ŒYOPOv2-Trackerèƒ½å¤Ÿåœ¨å®é™…åº”ç”¨ä¸­æä¾›æ›´é«˜çš„æ•ˆç‡å’Œå¯é æ€§ï¼Œæ¨åŠ¨æ— äººæœºæŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Traditional target tracking pipelines including detection, mapping, navigation, and control are comprehensive but introduce high latency, limitting the agility of quadrotors. On the contrary, we follow the design principle of "less is more", striving to simplify the process while maintaining effectiveness. In this work, we propose an end-to-end agile tracking and navigation framework for quadrotors that directly maps the sensory observations to control commands. Importantly, leveraging the multimodal nature of navigation and detection tasks, our network maintains interpretability by explicitly integrating the independent modules of the traditional pipeline, rather than a crude action regression. In detail, we adopt a set of motion primitives as anchors to cover the searching space regarding the feasible region and potential target. Then we reformulate the trajectory optimization as regression of primitive offsets and associated costs considering the safety, smoothness, and other metrics. For tracking task, the trajectories are expected to approach the target and additional objectness scores are predicted. Subsequently, the predictions, after compensation for the estimated lumped disturbance, are transformed into thrust and attitude as control commands for swift response. During training, we seamlessly integrate traditional motion planning with deep learning by directly back-propagating the gradients of trajectory costs to the network, eliminating the need for expert demonstration in imitation learning and providing more direct guidance than reinforcement learning. Finally, we deploy the algorithm on a compact quadrotor and conduct real-world validations in both forest and building environments to demonstrate the efficiency of the proposed method.

