---
layout: default
title: X-Sim: Cross-Embodiment Learning via Real-to-Sim-to-Real
---

# X-Sim: Cross-Embodiment Learning via Real-to-Sim-to-Real

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.07096" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.07096v5</a>
  <a href="https://arxiv.org/pdf/2505.07096.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.07096v5" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.07096v5', 'X-Sim: Cross-Embodiment Learning via Real-to-Sim-to-Real')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Prithwish Dan, Kushal Kedia, Angela Chao, Edward Weiyi Duan, Maximus Adrian Pace, Wei-Chiu Ma, Sanjiban Choudhury

**åˆ†ç±»**: cs.RO, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-11 (æ›´æ–°: 2025-11-09)

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://portal-cornell.github.io/X-Sim/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºX-Simæ¡†æ¶ä»¥è§£å†³æœºå™¨äººæ¨¡ä»¿å­¦ä¹ ä¸­çš„åŠ¨ä½œæ ‡ç­¾ç¼ºå¤±é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)**

**å…³é”®è¯**: `æœºå™¨äººæ“ä½œ` `æ¨¡ä»¿å­¦ä¹ ` `è·¨ä½“ç°å­¦ä¹ ` `å¼ºåŒ–å­¦ä¹ ` `é¢†åŸŸé€‚åº”` `ç‰©ä½“è¿åŠ¨` `ç­–ç•¥è’¸é¦`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è·¨ä½“ç°æ–¹æ³•åœ¨å¤„ç†äººç±»ä¸æœºå™¨äººä¹‹é—´åŠ¨ä½œå·®å¼‚æ—¶æ•ˆæœä¸ä½³ï¼Œå¯¼è‡´æ¨¡ä»¿å­¦ä¹ çš„æ•ˆç‡ä½ä¸‹ã€‚
2. X-Simæ¡†æ¶é€šè¿‡é‡å»ºé€¼çœŸæ¨¡æ‹Ÿå’Œç‰©ä½“è¿åŠ¨è·Ÿè¸ªï¼Œåˆ©ç”¨ç‰©ä½“ä¸­å¿ƒå¥–åŠ±æ¥è®­ç»ƒæœºå™¨äººæ“ä½œç­–ç•¥ï¼Œå…‹æœäº†åŠ¨ä½œæ ‡ç­¾ç¼ºå¤±çš„é—®é¢˜ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒX-Simåœ¨ä»»åŠ¡è¿›å±•ä¸Šå¹³å‡æé«˜30%ï¼Œæ•°æ®æ”¶é›†æ—¶é—´å‡å°‘10å€ï¼Œå¹¶ä¸”å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äººç±»è§†é¢‘ä¸ºè®­ç»ƒæœºå™¨äººæ“ä½œç­–ç•¥æä¾›äº†ä¸€ç§å¯æ‰©å±•çš„æ–¹æ³•ï¼Œä½†ç¼ºä¹æ ‡å‡†æ¨¡ä»¿å­¦ä¹ ç®—æ³•æ‰€éœ€çš„åŠ¨ä½œæ ‡ç­¾ã€‚ç°æœ‰çš„è·¨ä½“ç°æ–¹æ³•è¯•å›¾å°†äººç±»åŠ¨ä½œæ˜ å°„åˆ°æœºå™¨äººåŠ¨ä½œï¼Œä½†åœ¨ä½“ç°å·®å¼‚æ˜¾è‘—æ—¶å¾€å¾€å¤±è´¥ã€‚æˆ‘ä»¬æå‡ºäº†X-Simï¼Œä¸€ä¸ªé€šè¿‡ç‰©ä½“è¿åŠ¨ä½œä¸ºå¯†é›†ä¸”å¯è½¬ç§»ä¿¡å·çš„çœŸå®-æ¨¡æ‹Ÿ-çœŸå®æ¡†æ¶ï¼Œç”¨äºå­¦ä¹ æœºå™¨äººç­–ç•¥ã€‚X-Simé¦–å…ˆä»RGBDäººç±»è§†é¢‘é‡å»ºå‡ºé€¼çœŸçš„æ¨¡æ‹Ÿï¼Œå¹¶è·Ÿè¸ªç‰©ä½“è½¨è¿¹ä»¥å®šä¹‰ä»¥ç‰©ä½“ä¸ºä¸­å¿ƒçš„å¥–åŠ±ã€‚è¿™äº›å¥–åŠ±ç”¨äºåœ¨æ¨¡æ‹Ÿä¸­è®­ç»ƒå¼ºåŒ–å­¦ä¹ ç­–ç•¥ã€‚å­¦ä¹ åˆ°çš„ç­–ç•¥éšåé€šè¿‡åˆæˆå›æ”¾è½¬åŒ–ä¸ºå›¾åƒæ¡ä»¶æ‰©æ•£ç­–ç•¥ã€‚ä¸ºäº†è½¬ç§»åˆ°ç°å®ä¸–ç•Œï¼ŒX-Simå¼•å…¥äº†ä¸€ç§åœ¨çº¿é¢†åŸŸé€‚åº”æŠ€æœ¯ï¼Œåœ¨éƒ¨ç½²æœŸé—´å¯¹é½çœŸå®å’Œæ¨¡æ‹Ÿè§‚å¯Ÿã€‚é‡è¦çš„æ˜¯ï¼ŒX-Simä¸éœ€è¦ä»»ä½•æœºå™¨äººé¥æ“ä½œæ•°æ®ã€‚æˆ‘ä»¬åœ¨ä¸¤ä¸ªç¯å¢ƒä¸­çš„äº”ä¸ªæ“ä½œä»»åŠ¡ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºï¼šåœ¨æ‰‹éƒ¨è·Ÿè¸ªå’Œæ¨¡æ‹Ÿåˆ°ç°å®çš„åŸºçº¿ä¹‹ä¸Šï¼Œä»»åŠ¡è¿›å±•å¹³å‡æé«˜äº†30%ï¼›ä¸è¡Œä¸ºå…‹éš†ç›¸æ¯”ï¼Œæ•°æ®æ”¶é›†æ—¶é—´å‡å°‘äº†10å€ï¼›å¹¶ä¸”èƒ½å¤Ÿæ¨å¹¿åˆ°æ–°çš„ç›¸æœºè§†è§’å’Œæµ‹è¯•æ—¶å˜åŒ–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³æœºå™¨äººæ¨¡ä»¿å­¦ä¹ ä¸­ç¼ºä¹åŠ¨ä½œæ ‡ç­¾çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†äººç±»ä¸æœºå™¨äººä¹‹é—´çš„åŠ¨ä½œå·®å¼‚æ—¶è¡¨ç°ä¸ä½³ï¼Œå¯¼è‡´å­¦ä¹ æ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šX-Simæ¡†æ¶é€šè¿‡å°†ç‰©ä½“è¿åŠ¨ä½œä¸ºå¯†é›†ä¸”å¯è½¬ç§»çš„ä¿¡å·ï¼Œé‡å»ºé€¼çœŸæ¨¡æ‹Ÿå¹¶å®šä¹‰ç‰©ä½“ä¸­å¿ƒå¥–åŠ±ï¼Œä»è€Œæœ‰æ•ˆè®­ç»ƒæœºå™¨äººæ“ä½œç­–ç•¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šX-Simçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼šé¦–å…ˆä»RGBDäººç±»è§†é¢‘é‡å»ºæ¨¡æ‹Ÿç¯å¢ƒï¼›å…¶æ¬¡è·Ÿè¸ªç‰©ä½“è½¨è¿¹å¹¶å®šä¹‰å¥–åŠ±ï¼›æœ€åé€šè¿‡åœ¨çº¿é¢†åŸŸé€‚åº”æŠ€æœ¯å°†å­¦ä¹ åˆ°çš„ç­–ç•¥è½¬ç§»åˆ°ç°å®ä¸–ç•Œã€‚

**å…³é”®åˆ›æ–°**ï¼šX-Simçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶çœŸå®-æ¨¡æ‹Ÿ-çœŸå®çš„å­¦ä¹ æ¡†æ¶ï¼Œç‰¹åˆ«æ˜¯é€šè¿‡ç‰©ä½“è¿åŠ¨ä½œä¸ºå¥–åŠ±ä¿¡å·çš„ä½¿ç”¨ï¼Œä½¿å¾—æœºå™¨äººèƒ½å¤Ÿåœ¨ä¸åŒä½“ç°é—´æœ‰æ•ˆè¿ç§»ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼ŒX-Simé‡‡ç”¨äº†å›¾åƒæ¡ä»¶çš„æ‰©æ•£ç­–ç•¥ï¼Œå¹¶é€šè¿‡åˆæˆå›æ”¾è¿›è¡Œç­–ç•¥è’¸é¦ï¼Œç¡®ä¿äº†åœ¨ä¸åŒè§†è§’å’Œå…‰ç…§æ¡ä»¶ä¸‹çš„é²æ£’æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒX-Simåœ¨äº”ä¸ªæ“ä½œä»»åŠ¡ä¸­å¹³å‡æé«˜äº†30%çš„ä»»åŠ¡è¿›å±•ï¼Œç›¸æ¯”äºæ‰‹éƒ¨è·Ÿè¸ªå’Œæ¨¡æ‹Ÿåˆ°ç°å®çš„åŸºçº¿è¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ã€‚æ­¤å¤–ï¼Œä¸è¡Œä¸ºå…‹éš†ç›¸æ¯”ï¼ŒX-Simåœ¨æ•°æ®æ”¶é›†æ—¶é—´ä¸Šå‡å°‘äº†10å€ï¼Œå±•ç¤ºäº†å…¶é«˜æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœåŠ¡æœºå™¨äººã€å·¥ä¸šè‡ªåŠ¨åŒ–å’Œäººæœºåä½œç­‰åœºæ™¯ã€‚é€šè¿‡æé«˜æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„æ“ä½œèƒ½åŠ›ï¼ŒX-Simèƒ½å¤Ÿæ˜¾è‘—æå‡æœºå™¨äººåœ¨å®é™…åº”ç”¨ä¸­çš„æ•ˆç‡å’Œçµæ´»æ€§ï¼Œæ¨åŠ¨æ™ºèƒ½æœºå™¨äººæŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Human videos offer a scalable way to train robot manipulation policies, but lack the action labels needed by standard imitation learning algorithms. Existing cross-embodiment approaches try to map human motion to robot actions, but often fail when the embodiments differ significantly. We propose X-Sim, a real-to-sim-to-real framework that uses object motion as a dense and transferable signal for learning robot policies. X-Sim starts by reconstructing a photorealistic simulation from an RGBD human video and tracking object trajectories to define object-centric rewards. These rewards are used to train a reinforcement learning (RL) policy in simulation. The learned policy is then distilled into an image-conditioned diffusion policy using synthetic rollouts rendered with varied viewpoints and lighting. To transfer to the real world, X-Sim introduces an online domain adaptation technique that aligns real and simulated observations during deployment. Importantly, X-Sim does not require any robot teleoperation data. We evaluate it across 5 manipulation tasks in 2 environments and show that it: (1) improves task progress by 30% on average over hand-tracking and sim-to-real baselines, (2) matches behavior cloning with 10x less data collection time, and (3) generalizes to new camera viewpoints and test-time changes. Code and videos are available at https://portal-cornell.github.io/X-Sim/.

