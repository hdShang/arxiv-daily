---
layout: default
title: From Generated Human Videos to Physically Plausible Robot Trajectories
---

# From Generated Human Videos to Physically Plausible Robot Trajectories

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.05094" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.05094v2</a>
  <a href="https://arxiv.org/pdf/2512.05094.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.05094v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.05094v2', 'From Generated Human Videos to Physically Plausible Robot Trajectories')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: James Ni, Zekai Wang, Wei Lin, Amir Bar, Yann LeCun, Trevor Darrell, Jitendra Malik, Roei Herzig

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-04 (æ›´æ–°: 2025-12-11)

**å¤‡æ³¨**: For project website, see https://genmimic.github.io

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**GenMimicï¼šåˆ©ç”¨ç”Ÿæˆè§†é¢‘å®ç°äººå½¢æœºå™¨äººé›¶æ ·æœ¬ç‰©ç†å¯è¡Œè½¨è¿¹æ§åˆ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æœºå™¨äººæ§åˆ¶` `äººå½¢æœºå™¨äºº` `è§†é¢‘ç”Ÿæˆ` `å¼ºåŒ–å­¦ä¹ ` `é›¶æ ·æœ¬å­¦ä¹ ` `è¿åŠ¨æ¨¡ä»¿` `ç‰©ç†ä»¿çœŸ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•éš¾ä»¥ç›´æ¥å°†ç”Ÿæˆçš„å«å™ªè§†é¢‘ç”¨äºæœºå™¨äººæ§åˆ¶ï¼Œå› ä¸ºç”Ÿæˆè§†é¢‘å­˜åœ¨å½¢æ€æ‰­æ›²å’Œå™ªå£°ï¼Œå¯¼è‡´ç›´æ¥æ¨¡ä»¿æ•ˆæœä¸ä½³ã€‚
2. è®ºæ–‡æå‡ºGenMimicï¼Œä¸€ä¸ªä¸¤é˜¶æ®µæ¡†æ¶ï¼šé¦–å…ˆå°†è§†é¢‘åƒç´ æå‡åˆ°4Däººä½“è¡¨ç¤ºå¹¶è¿›è¡Œå½¢æ€é‡å®šå‘ï¼Œç„¶åä½¿ç”¨åŸºäºç‰©ç†çš„å¼ºåŒ–å­¦ä¹ ç­–ç•¥è¿›è¡Œæ¨¡ä»¿ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒGenMimicåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®Unitree G1æœºå™¨äººä¸Šå‡è¡¨ç°å‡ºè‰¯å¥½çš„é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ï¼Œæ— éœ€å¾®è°ƒå³å¯å®ç°ç¨³å®šçš„è¿åŠ¨è·Ÿè¸ªã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†é¢‘ç”Ÿæˆæ¨¡å‹åœ¨åˆæˆæ–°åœºæ™¯ä¸‹çš„äººç±»è¡Œä¸ºæ–¹é¢èƒ½åŠ›è¿…é€Ÿæå‡ï¼Œæœ‰æ½œåŠ›ä½œä¸ºä¸Šä¸‹æ–‡æœºå™¨äººæ§åˆ¶çš„é«˜çº§è§„åˆ’å™¨ã€‚ä¸ºäº†å®ç°è¿™ä¸€æ½œåŠ›ï¼Œä¸€ä¸ªå…³é”®çš„ç ”ç©¶é—®é¢˜ä»ç„¶å­˜åœ¨ï¼šäººå½¢æœºå™¨äººå¦‚ä½•ä»¥é›¶æ ·æœ¬æ–¹å¼æ‰§è¡Œæ¥è‡ªç”Ÿæˆè§†é¢‘çš„äººç±»åŠ¨ä½œï¼Ÿç”±äºç”Ÿæˆè§†é¢‘é€šå¸¸åŒ…å«å™ªå£°å’Œå½¢æ€æ‰­æ›²ï¼Œä½¿å¾—ç›´æ¥æ¨¡ä»¿å˜å¾—å›°éš¾ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªä¸¤é˜¶æ®µæµç¨‹ã€‚é¦–å…ˆï¼Œå°†è§†é¢‘åƒç´ è½¬æ¢ä¸º4Däººä½“è¡¨ç¤ºï¼Œç„¶åé‡æ–°å®šä½åˆ°äººå½¢æœºå™¨äººçš„å½¢æ€ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬æå‡ºäº†GenMimicâ€”â€”ä¸€ç§åŸºäºç‰©ç†çš„å¼ºåŒ–å­¦ä¹ ç­–ç•¥ï¼Œä»¥3Då…³é”®ç‚¹ä¸ºæ¡ä»¶ï¼Œå¹¶é€šè¿‡å¯¹ç§°æ­£åˆ™åŒ–å’Œå…³é”®ç‚¹åŠ æƒè·Ÿè¸ªå¥–åŠ±è¿›è¡Œè®­ç»ƒã€‚å› æ­¤ï¼ŒGenMimicå¯ä»¥æ¨¡ä»¿æ¥è‡ªå˜ˆæ‚çš„ç”Ÿæˆè§†é¢‘çš„äººç±»åŠ¨ä½œã€‚æˆ‘ä»¬åˆ›å»ºäº†GenMimicBenchï¼Œè¿™æ˜¯ä¸€ä¸ªåˆæˆçš„äººä½“è¿åŠ¨æ•°æ®é›†ï¼Œä½¿ç”¨ä¸¤ä¸ªè§†é¢‘ç”Ÿæˆæ¨¡å‹è·¨è¶Šä¸€ç³»åˆ—åŠ¨ä½œå’Œä¸Šä¸‹æ–‡ç”Ÿæˆï¼Œä¸ºè¯„ä¼°é›¶æ ·æœ¬æ³›åŒ–å’Œç­–ç•¥é²æ£’æ€§å»ºç«‹äº†ä¸€ä¸ªåŸºå‡†ã€‚å¤§é‡çš„å®éªŒè¯æ˜äº†åœ¨æ¨¡æ‹Ÿä¸­ä¼˜äºå¼ºå¤§çš„åŸºçº¿ï¼Œå¹¶è¯å®äº†åœ¨Unitree G1äººå½¢æœºå™¨äººä¸Šæ— éœ€å¾®è°ƒå³å¯å®ç°è¿è´¯ã€ç‰©ç†ç¨³å®šçš„è¿åŠ¨è·Ÿè¸ªã€‚è¿™é¡¹å·¥ä½œä¸ºå®ç°è§†é¢‘ç”Ÿæˆæ¨¡å‹ä½œä¸ºæœºå™¨äººæ§åˆ¶é«˜çº§ç­–ç•¥çš„æ½œåŠ›æä¾›äº†ä¸€æ¡æœ‰å¸Œæœ›çš„é€”å¾„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¦‚ä½•åˆ©ç”¨å¿«é€Ÿå‘å±•çš„è§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼Œè®©äººå½¢æœºå™¨äººèƒ½å¤Ÿé›¶æ ·æœ¬æ¨¡ä»¿ç”Ÿæˆè§†é¢‘ä¸­çš„äººç±»åŠ¨ä½œã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥ç›´æ¥åº”ç”¨ï¼Œä¸»è¦ç—›ç‚¹åœ¨äºç”Ÿæˆè§†é¢‘é€šå¸¸åŒ…å«å™ªå£°ã€å½¢æ€å¤±çœŸï¼Œä½¿å¾—ç›´æ¥æ¨¡ä»¿å­¦ä¹ é¢ä¸´æŒ‘æˆ˜ï¼Œå¯¼è‡´æœºå™¨äººè¿åŠ¨ä¸ç¨³å®šç”šè‡³å¤±è´¥ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†é—®é¢˜åˆ†è§£ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šé¦–å…ˆï¼Œå°†å«å™ªçš„ç”Ÿæˆè§†é¢‘è½¬æ¢ä¸ºæ›´é²æ£’çš„ä¸­é—´è¡¨ç¤ºï¼ˆ4Däººä½“å§¿æ€ï¼‰ï¼Œä»¥æ¶ˆé™¤å™ªå£°å’Œå½¢æ€å·®å¼‚ï¼›ç„¶åï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒä¸€ä¸ªç­–ç•¥ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿæ ¹æ®è¯¥ä¸­é—´è¡¨ç¤ºè¿›è¡Œæ¨¡ä»¿ã€‚è¿™ç§è§£è€¦çš„è®¾è®¡ä½¿å¾—ç­–ç•¥å­¦ä¹ æ›´åŠ ç¨³å®šï¼Œå¹¶æé«˜äº†æ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šGenMimicåŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼š1) **è§†é¢‘åˆ°4Däººä½“è¡¨ç¤º**ï¼šä½¿ç”¨ç°æœ‰çš„å§¿æ€ä¼°è®¡æ¨¡å‹å°†è§†é¢‘å¸§è½¬æ¢ä¸º3Däººä½“å…³é”®ç‚¹ï¼Œå¹¶å°†å…¶æ‰©å±•åˆ°4Dç©ºé—´ä»¥åŒ…å«æ—¶é—´ä¿¡æ¯ã€‚ç„¶åï¼Œå°†äººä½“å…³é”®ç‚¹æ˜ å°„åˆ°äººå½¢æœºå™¨äººçš„éª¨éª¼ç»“æ„ã€‚2) **åŸºäºç‰©ç†çš„å¼ºåŒ–å­¦ä¹ **ï¼šè®¾è®¡ä¸€ä¸ªå¼ºåŒ–å­¦ä¹ ç¯å¢ƒï¼Œå…¶ä¸­æœºå™¨äººæ ¹æ®3Då…³é”®ç‚¹è¿›è¡Œè¿åŠ¨æ¨¡ä»¿ã€‚ä½¿ç”¨å¯¹ç§°æ­£åˆ™åŒ–å’Œå…³é”®ç‚¹åŠ æƒè·Ÿè¸ªå¥–åŠ±æ¥æé«˜ç­–ç•¥çš„é²æ£’æ€§å’Œç¨³å®šæ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ä¸ªä¸¤é˜¶æ®µçš„æ¡†æ¶ï¼Œå°†è§†é¢‘ç†è§£å’Œæœºå™¨äººæ§åˆ¶è§£è€¦ã€‚é€šè¿‡å¼•å…¥4Däººä½“è¡¨ç¤ºä½œä¸ºä¸­é—´å±‚ï¼Œæœ‰æ•ˆé™ä½äº†ç”Ÿæˆè§†é¢‘å™ªå£°å’Œå½¢æ€å·®å¼‚å¯¹æœºå™¨äººæ§åˆ¶çš„å½±å“ã€‚æ­¤å¤–ï¼ŒGenMimicBenchæ•°æ®é›†çš„æ„å»ºä¹Ÿä¸ºè¯¥é¢†åŸŸçš„ç ”ç©¶æä¾›äº†æ–°çš„åŸºå‡†ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å¼ºåŒ–å­¦ä¹ é˜¶æ®µï¼Œä½¿ç”¨äº†ä»¥ä¸‹å…³é”®è®¾è®¡ï¼š1) **å¯¹ç§°æ­£åˆ™åŒ–**ï¼šé€šè¿‡é¼“åŠ±æœºå™¨äººåœ¨å¯¹ç§°åŠ¨ä½œä¸­ä¿æŒå¹³è¡¡ï¼Œæé«˜ç­–ç•¥çš„ç¨³å®šæ€§ã€‚2) **å…³é”®ç‚¹åŠ æƒè·Ÿè¸ªå¥–åŠ±**ï¼šæ ¹æ®å…³é”®ç‚¹çš„é‡è¦æ€§åˆ†é…ä¸åŒçš„æƒé‡ï¼Œä½¿å¾—æœºå™¨äººæ›´åŠ å…³æ³¨é‡è¦çš„å…³èŠ‚è¿åŠ¨ã€‚3) **å¥–åŠ±å‡½æ•°è®¾è®¡**ï¼šå¥–åŠ±å‡½æ•°ç»¼åˆè€ƒè™‘äº†å…³é”®ç‚¹è·Ÿè¸ªè¯¯å·®ã€å¹³è¡¡æ€§å’Œèƒ½é‡æ¶ˆè€—ï¼Œä»¥å®ç°æ›´è‡ªç„¶å’Œé«˜æ•ˆçš„è¿åŠ¨ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒGenMimicåœ¨GenMimicBenchæ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ï¼Œåœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­å®ç°äº†æ›´é«˜çš„è¿åŠ¨æ¨¡ä»¿ç²¾åº¦å’Œç¨³å®šæ€§ã€‚æ›´é‡è¦çš„æ˜¯ï¼ŒGenMimicæˆåŠŸåœ°å°†è®­ç»ƒå¥½çš„ç­–ç•¥è¿ç§»åˆ°çœŸå®çš„Unitree G1äººå½¢æœºå™¨äººä¸Šï¼Œæ— éœ€è¿›è¡Œä»»ä½•å¾®è°ƒï¼Œå®ç°äº†è¿è´¯ä¸”ç‰©ç†ç¨³å®šçš„è¿åŠ¨è·Ÿè¸ªï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¤šç§åœºæ™¯ï¼Œä¾‹å¦‚ï¼š1) å®¶åº­æœåŠ¡æœºå™¨äººï¼šæ¨¡ä»¿äººç±»è¿›è¡Œå®¶åŠ¡æ“ä½œï¼›2) å·¥ä¸šæœºå™¨äººï¼šæ‰§è¡Œå¤æ‚çš„è£…é…ä»»åŠ¡ï¼›3) åº·å¤æœºå™¨äººï¼šè¾…åŠ©æ‚£è€…è¿›è¡Œè¿åŠ¨è®­ç»ƒã€‚é€šè¿‡åˆ©ç”¨è§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼Œå¯ä»¥è®©äººå½¢æœºå™¨äººå…·å¤‡æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›å’Œé€‚åº”æ€§ï¼Œä»è€Œæ›´å¥½åœ°æœåŠ¡äºäººç±»ç¤¾ä¼šã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Video generation models are rapidly improving in their ability to synthesize human actions in novel contexts, holding the potential to serve as high-level planners for contextual robot control. To realize this potential, a key research question remains open: how can a humanoid execute the human actions from generated videos in a zero-shot manner? This challenge arises because generated videos are often noisy and exhibit morphological distortions that make direct imitation difficult compared to real video. To address this, we introduce a two-stage pipeline. First, we lift video pixels into a 4D human representation and then retarget to the humanoid morphology. Second, we propose GenMimic-a physics-aware reinforcement learning policy conditioned on 3D keypoints, and trained with symmetry regularization and keypoint-weighted tracking rewards. As a result, GenMimic can mimic human actions from noisy, generated videos. We curate GenMimicBench, a synthetic human-motion dataset generated using two video generation models across a spectrum of actions and contexts, establishing a benchmark for assessing zero-shot generalization and policy robustness. Extensive experiments demonstrate improvements over strong baselines in simulation and confirm coherent, physically stable motion tracking on a Unitree G1 humanoid robot without fine-tuning. This work offers a promising path to realizing the potential of video generation models as high-level policies for robot control.

