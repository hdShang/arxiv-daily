---
layout: default
title: "GraspView: Active Perception Scoring and Best-View Optimization for Robotic Grasping in Cluttered Environments"
---

# GraspView: Active Perception Scoring and Best-View Optimization for Robotic Grasping in Cluttered Environments

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.04199" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.04199v1</a>
  <a href="https://arxiv.org/pdf/2511.04199.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.04199v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.04199v1', 'GraspView: Active Perception Scoring and Best-View Optimization for Robotic Grasping in Cluttered Environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shenglin Wang, Mingtong Dai, Jingxuan Su, Lingbo Liu, Chunjie Chen, Xinyu Wu, Liang Lin

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-11-06

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**GraspViewï¼šé¢å‘æ‚ä¹±ç¯å¢ƒçš„åŸºäºä¸»åŠ¨æ„ŸçŸ¥è¯„åˆ†å’Œæœ€ä½³è§†è§’ä¼˜åŒ–çš„æœºå™¨äººæŠ“å–**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `æœºå™¨äººæŠ“å–` `ä¸»åŠ¨æ„ŸçŸ¥` `å¤šè§†å›¾é‡å»º` `RGBå›¾åƒ` `æœ€ä½³è§†è§’é€‰æ‹©`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿæœºå™¨äººæŠ“å–ä¾èµ–RGB-Dç›¸æœºï¼Œä½†åœ¨é®æŒ¡ã€è¿‘è·ç¦»å’Œé€æ˜/åå…‰ç‰©ä½“ä¸Šè¡¨ç°ä¸ä½³ï¼Œå¯¼è‡´æŠ“å–å¤±è´¥ã€‚
2. GraspViewæå‡ºä¸€ç§ä»…ä½¿ç”¨RGBå›¾åƒçš„æŠ“å–æ–¹æ¡ˆï¼Œé€šè¿‡ä¸»åŠ¨è§†è§’é€‰æ‹©å’Œå¤šè§†å›¾èåˆé‡å»ºåœºæ™¯å‡ ä½•ä¿¡æ¯ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒGraspViewåœ¨å¤æ‚åœºæ™¯ä¸‹æ˜¾è‘—ä¼˜äºRGB-Då’Œå•è§†å›¾RGBæ–¹æ³•ï¼Œæå‡äº†æŠ“å–çš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºGraspViewï¼Œä¸€ä¸ªä»…ä½¿ç”¨RGBå›¾åƒçš„æœºå™¨äººæŠ“å–æµç¨‹ï¼Œæ—¨åœ¨æ— éœ€æ·±åº¦ä¼ æ„Ÿå™¨çš„æƒ…å†µä¸‹ï¼Œåœ¨æ‚ä¹±ç¯å¢ƒä¸­å®ç°ç²¾ç¡®æ“ä½œã€‚è¯¥æ¡†æ¶åŒ…å«ä¸‰ä¸ªå…³é”®ç»„ä»¶ï¼š(i) å…¨å±€æ„ŸçŸ¥åœºæ™¯é‡å»ºï¼Œä»å•ä¸ªRGBè§†å›¾æä¾›å±€éƒ¨ä¸€è‡´ã€æ¯”ä¾‹æ­£ç¡®çš„å‡ ä½•ä¿¡æ¯ï¼Œå¹¶å°†å¤šè§†å›¾æŠ•å½±èåˆåˆ°è¿è´¯çš„å…¨å±€3Dåœºæ™¯ä¸­ï¼›(ii) æ¸²æŸ“å’Œè¯„åˆ†çš„ä¸»åŠ¨æ„ŸçŸ¥ç­–ç•¥ï¼ŒåŠ¨æ€é€‰æ‹©æœ€ä½³è§†è§’ä»¥æ­ç¤ºè¢«é®æŒ¡åŒºåŸŸï¼›(iii) åœ¨çº¿åº¦é‡å¯¹é½æ¨¡å—ï¼Œæ ¡å‡†VGGTé¢„æµ‹ä¸æœºå™¨äººè¿åŠ¨å­¦ï¼Œä»¥ç¡®ä¿ç‰©ç†æ¯”ä¾‹ä¸€è‡´æ€§ã€‚GraspViewåŸºäºè¿™äº›å®šåˆ¶æ¨¡å—ï¼Œæ‰§è¡Œæœ€ä½³è§†è§’çš„å…¨å±€æŠ“å–ï¼Œèåˆå¤šè§†å›¾é‡å»ºå¹¶åˆ©ç”¨GraspNetå®ç°é²æ£’æ‰§è¡Œã€‚åœ¨å„ç§æ¡Œé¢ç‰©ä½“ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒGraspViewæ˜¾è‘—ä¼˜äºRGB-Då’Œå•è§†å›¾RGBåŸºçº¿ï¼Œå°¤å…¶æ˜¯åœ¨ä¸¥é‡é®æŒ¡ã€è¿‘åœºæ„ŸçŸ¥å’Œé€æ˜ç‰©ä½“çš„æƒ…å†µä¸‹ã€‚è¿™äº›ç»“æœè¡¨æ˜GraspViewæ˜¯RGB-Dæµç¨‹çš„ä¸€ç§å®ç”¨ä¸”é€šç”¨çš„æ›¿ä»£æ–¹æ¡ˆï¼Œèƒ½å¤Ÿåœ¨éç»“æ„åŒ–çš„çœŸå®ä¸–ç•Œç¯å¢ƒä¸­å®ç°å¯é çš„æŠ“å–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æœºå™¨äººæŠ“å–ç³»ç»Ÿä¾èµ–RGB-Dç›¸æœºè·å–åœºæ™¯æ·±åº¦ä¿¡æ¯ï¼Œä½†åœ¨æ‚ä¹±ç¯å¢ƒä¸­ï¼Œç”±äºé®æŒ¡ã€å…‰ç…§å˜åŒ–ã€é€æ˜æˆ–åå…‰ç‰©ä½“ç­‰å› ç´ çš„å½±å“ï¼Œæ·±åº¦ä¿¡æ¯çš„è´¨é‡ä¼šæ˜¾è‘—ä¸‹é™ï¼Œå¯¼è‡´æŠ“å–å¤±è´¥ç‡å‡é«˜ã€‚æ­¤å¤–ï¼Œè¿‘è·ç¦»æ„ŸçŸ¥æ—¶ï¼ŒRGB-Dç›¸æœºçš„ç²¾åº¦ä¹Ÿä¼šå—åˆ°é™åˆ¶ã€‚å› æ­¤ï¼Œå¦‚ä½•åœ¨ä»…ä½¿ç”¨RGBå›¾åƒçš„æƒ…å†µä¸‹ï¼Œå®ç°é²æ£’çš„æœºå™¨äººæŠ“å–æ˜¯ä¸€ä¸ªé‡è¦çš„æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šGraspViewçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤šè§†å›¾RGBå›¾åƒé‡å»ºåœºæ™¯çš„å‡ ä½•ä¿¡æ¯ï¼Œå¹¶é€šè¿‡ä¸»åŠ¨æ„ŸçŸ¥ç­–ç•¥é€‰æ‹©æœ€ä½³è§†è§’ï¼Œä»¥å‡å°‘é®æŒ¡å¹¶æé«˜é‡å»ºè´¨é‡ã€‚é€šè¿‡æ¸²æŸ“å’Œè¯„åˆ†çš„æ–¹å¼ï¼ŒåŠ¨æ€é€‰æ‹©ä¸‹ä¸€ä¸ªæœ€ä½³è§†è§’ï¼Œä»è€Œé€æ­¥å®Œå–„åœºæ™¯çš„3Dæ¨¡å‹ã€‚åŒæ—¶ï¼Œé‡‡ç”¨åœ¨çº¿åº¦é‡å¯¹é½æ¨¡å—ï¼Œæ ¡å‡†è§†è§‰é¢„æµ‹ä¸æœºå™¨äººè¿åŠ¨å­¦ï¼Œç¡®ä¿æŠ“å–çš„ç‰©ç†æ¯”ä¾‹ä¸€è‡´æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šGraspViewæ¡†æ¶åŒ…å«ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š(1) å…¨å±€æ„ŸçŸ¥åœºæ™¯é‡å»ºæ¨¡å—ï¼Œè´Ÿè´£ä»å•å¼ RGBå›¾åƒä¸­ä¼°è®¡å±€éƒ¨ä¸€è‡´ã€æ¯”ä¾‹æ­£ç¡®çš„å‡ ä½•ä¿¡æ¯ï¼Œå¹¶å°†å¤šè§†å›¾æŠ•å½±èåˆåˆ°å…¨å±€3Dåœºæ™¯ä¸­ã€‚(2) æ¸²æŸ“å’Œè¯„åˆ†çš„ä¸»åŠ¨æ„ŸçŸ¥ç­–ç•¥æ¨¡å—ï¼Œé€šè¿‡æ¸²æŸ“ä¸åŒè§†è§’çš„å›¾åƒå¹¶è¿›è¡Œè¯„åˆ†ï¼Œé€‰æ‹©ä¸‹ä¸€ä¸ªæœ€ä½³è§†è§’ï¼Œä»¥æ­ç¤ºè¢«é®æŒ¡çš„åŒºåŸŸã€‚(3) åœ¨çº¿åº¦é‡å¯¹é½æ¨¡å—ï¼Œç”¨äºæ ¡å‡†VGGTï¼ˆVision-Guided Grasping Transformerï¼‰çš„é¢„æµ‹ç»“æœä¸æœºå™¨äººè¿åŠ¨å­¦ï¼Œç¡®ä¿æŠ“å–çš„ç‰©ç†æ¯”ä¾‹ä¸€è‡´æ€§ã€‚æœ€ç»ˆï¼Œç³»ç»Ÿèåˆå¤šè§†å›¾é‡å»ºç»“æœï¼Œå¹¶åˆ©ç”¨GraspNetè¿›è¡ŒæŠ“å–ã€‚

**å…³é”®åˆ›æ–°**ï¼šGraspViewçš„å…³é”®åˆ›æ–°åœ¨äºå…¶ç»“åˆäº†ä¸»åŠ¨æ„ŸçŸ¥ç­–ç•¥å’Œå¤šè§†å›¾å‡ ä½•é‡å»ºï¼Œå®ç°äº†ä»…ä½¿ç”¨RGBå›¾åƒçš„é²æ£’æŠ“å–ã€‚ä¸ä¼ ç»Ÿçš„RGB-Dæ–¹æ³•ç›¸æ¯”ï¼ŒGraspViewä¸å—æ·±åº¦ä¼ æ„Ÿå™¨é™åˆ¶ï¼Œèƒ½å¤Ÿå¤„ç†é€æ˜å’Œåå…‰ç‰©ä½“ã€‚ä¸å•è§†å›¾RGBæ–¹æ³•ç›¸æ¯”ï¼ŒGraspViewé€šè¿‡ä¸»åŠ¨è§†è§’é€‰æ‹©å’Œå¤šè§†å›¾èåˆï¼Œæé«˜äº†åœºæ™¯é‡å»ºçš„å®Œæ•´æ€§å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šä¸»åŠ¨æ„ŸçŸ¥ç­–ç•¥é€šè¿‡æ¸²æŸ“ä¸åŒè§†è§’çš„å›¾åƒï¼Œå¹¶ä½¿ç”¨è¯„åˆ†å‡½æ•°è¯„ä¼°æ¯ä¸ªè§†è§’çš„è´¨é‡ã€‚è¯„åˆ†å‡½æ•°ç»¼åˆè€ƒè™‘äº†å¯è§åŒºåŸŸçš„å¤§å°ã€é®æŒ¡ç¨‹åº¦ç­‰å› ç´ ã€‚åœ¨çº¿åº¦é‡å¯¹é½æ¨¡å—ä½¿ç”¨å¡å°”æ›¼æ»¤æ³¢å™¨ä¼°è®¡è§†è§‰é¢„æµ‹çš„æ¯”ä¾‹å› å­ï¼Œå¹¶å°†å…¶ä¸æœºå™¨äººè¿åŠ¨å­¦ä¿¡æ¯èåˆï¼Œä»è€Œå®ç°ç²¾ç¡®çš„æŠ“å–æ§åˆ¶ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿè‡³å…³é‡è¦ï¼Œéœ€è¦å¹³è¡¡é‡å»ºç²¾åº¦å’ŒæŠ“å–æˆåŠŸç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒGraspViewåœ¨å„ç§æ¡Œé¢ç‰©ä½“ä¸Šçš„æŠ“å–æˆåŠŸç‡æ˜¾è‘—ä¼˜äºRGB-Då’Œå•è§†å›¾RGBåŸºçº¿ã€‚åœ¨ä¸¥é‡é®æŒ¡çš„æƒ…å†µä¸‹ï¼ŒGraspViewçš„æ€§èƒ½æå‡å°¤ä¸ºæ˜æ˜¾ã€‚æ­¤å¤–ï¼ŒGraspViewåœ¨å¤„ç†é€æ˜ç‰©ä½“å’Œè¿‘åœºæ„ŸçŸ¥æ—¶ä¹Ÿè¡¨ç°å‡ºä¼˜è¶Šçš„æ€§èƒ½ã€‚å…·ä½“æ•°æ®æœªçŸ¥ï¼Œä½†æ•´ä½“è¡¨ç°ä¼˜äºå¯¹æ¯”æ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

GraspViewåœ¨è‡ªåŠ¨åŒ–è£…é…ã€ç‰©æµåˆ†æ‹£ã€å®¶åº­æœåŠ¡æœºå™¨äººç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚è¯¥æŠ€æœ¯èƒ½å¤Ÿä½¿æœºå™¨äººåœ¨å¤æ‚ã€éç»“æ„åŒ–çš„ç¯å¢ƒä¸­è¿›è¡Œå¯é çš„æŠ“å–æ“ä½œï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦å¤„ç†é€æ˜æˆ–åå…‰ç‰©ä½“çš„åœºæ™¯ä¸­ã€‚æœªæ¥ï¼ŒGraspViewæœ‰æœ›è¿›ä¸€æ­¥æå‡æœºå™¨äººçš„è‡ªä¸»æ“ä½œèƒ½åŠ›ï¼Œé™ä½å¯¹ç¯å¢ƒçš„ä¾èµ–æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Robotic grasping is a fundamental capability for autonomous manipulation, yet remains highly challenging in cluttered environments where occlusion, poor perception quality, and inconsistent 3D reconstructions often lead to unstable or failed grasps. Conventional pipelines have widely relied on RGB-D cameras to provide geometric information, which fail on transparent or glossy objects and degrade at close range. We present GraspView, an RGB-only robotic grasping pipeline that achieves accurate manipulation in cluttered environments without depth sensors. Our framework integrates three key components: (i) global perception scene reconstruction, which provides locally consistent, up-to-scale geometry from a single RGB view and fuses multi-view projections into a coherent global 3D scene; (ii) a render-and-score active perception strategy, which dynamically selects next-best-views to reveal occluded regions; and (iii) an online metric alignment module that calibrates VGGT predictions against robot kinematics to ensure physical scale consistency. Building on these tailor-designed modules, GraspView performs best-view global grasping, fusing multi-view reconstructions and leveraging GraspNet for robust execution. Experiments on diverse tabletop objects demonstrate that GraspView significantly outperforms both RGB-D and single-view RGB baselines, especially under heavy occlusion, near-field sensing, and with transparent objects. These results highlight GraspView as a practical and versatile alternative to RGB-D pipelines, enabling reliable grasping in unstructured real-world environments.

