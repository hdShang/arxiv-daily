---
layout: default
title: Self-Supervised Multisensory Pretraining for Contact-Rich Robot Reinforcement Learning
---

# Self-Supervised Multisensory Pretraining for Contact-Rich Robot Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.14427" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.14427v1</a>
  <a href="https://arxiv.org/pdf/2511.14427.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.14427v1" onclick="toggleFavorite(this, '2511.14427v1', 'Self-Supervised Multisensory Pretraining for Contact-Rich Robot Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Rickmer Krohn, Vignesh Prasad, Gabriele Tiboni, Georgia Chalvatzaki

**åˆ†ç±»**: cs.RO, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-11-18

**å¤‡æ³¨**: 9 pages, 10 figures, preprint

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMSDPï¼Œç”¨äºæ¥è§¦å¼æœºå™¨äººå¼ºåŒ–å­¦ä¹ çš„å¤šæ¨¡æ€è‡ªç›‘ç£é¢„è®­ç»ƒã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `è‡ªç›‘ç£å­¦ä¹ ` `æœºå™¨äººå¼ºåŒ–å­¦ä¹ ` `æ¥è§¦å¼æ“ä½œ` `Transformer` `æ©ç è‡ªç¼–ç ` `ä¼ æ„Ÿå™¨èåˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨å¤šæ¨¡æ€æœºå™¨äººæ§åˆ¶ä¸­ï¼Œéš¾ä»¥åº”å¯¹ä¼ æ„Ÿå™¨å™ªå£°å’ŒåŠ¨æ€å˜åŒ–ï¼Œå¯¼è‡´å­¦ä¹ æ•ˆç‡ä½ä¸‹ã€‚
2. MSDPé€šè¿‡æ©ç è‡ªç¼–ç å™¨ï¼Œä»éƒ¨åˆ†ä¼ æ„Ÿå™¨æ•°æ®é‡å»ºå®Œæ•´çš„å¤šæ¨¡æ€è§‚æµ‹ï¼Œå®ç°è·¨æ¨¡æ€èåˆå’Œé²æ£’çš„ç‰¹å¾æå–ã€‚
3. MSDPåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®æœºå™¨äººä»»åŠ¡ä¸­è¡¨ç°å‡ºåŠ é€Ÿå­¦ä¹ å’Œå¯¹æ‰°åŠ¨çš„é²æ£’æ€§ï¼Œä»…éœ€å°‘é‡äº¤äº’å³å¯å®ç°é«˜æˆåŠŸç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ‰æ•ˆçš„æ¥è§¦å¼æ“ä½œéœ€è¦æœºå™¨äººååŒåˆ©ç”¨è§†è§‰ã€åŠ›è§‰å’Œæœ¬ä½“æ„Ÿè§‰ã€‚ç„¶è€Œï¼Œå¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“åœ¨è¿™ç§å¤šæ¨¡æ€ç¯å¢ƒä¸­éš¾ä»¥å­¦ä¹ ï¼Œå°¤å…¶æ˜¯åœ¨å­˜åœ¨ä¼ æ„Ÿå™¨å™ªå£°å’ŒåŠ¨æ€å˜åŒ–çš„æƒ…å†µä¸‹ã€‚æˆ‘ä»¬æå‡ºäº†å¤šæ¨¡æ€åŠ¨æ€é¢„è®­ç»ƒï¼ˆMSDPï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°é¢–çš„æ¡†æ¶ï¼Œç”¨äºå­¦ä¹ ä¸ºé¢å‘ä»»åŠ¡çš„ç­–ç•¥å­¦ä¹ é‡èº«å®šåˆ¶çš„è¡¨è¾¾æ€§å¤šæ¨¡æ€è¡¨ç¤ºã€‚MSDPåŸºäºæ©ç è‡ªç¼–ç ï¼Œå¹¶é€šè¿‡ä»…ä»ä¼ æ„Ÿå™¨åµŒå…¥çš„å­é›†ä¸­é‡å»ºå¤šæ¨¡æ€è§‚æµ‹æ¥è®­ç»ƒåŸºäºTransformerçš„ç¼–ç å™¨ï¼Œä»è€Œå®ç°è·¨æ¨¡æ€é¢„æµ‹å’Œä¼ æ„Ÿå™¨èåˆã€‚å¯¹äºä¸‹æ¸¸ç­–ç•¥å­¦ä¹ ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°é¢–çš„éå¯¹ç§°æ¶æ„ï¼Œå…¶ä¸­äº¤å‰æ³¨æ„åŠ›æœºåˆ¶å…è®¸è¯„è®ºå®¶ä»å†»ç»“çš„åµŒå…¥ä¸­æå–åŠ¨æ€çš„ã€ç‰¹å®šäºä»»åŠ¡çš„ç‰¹å¾ï¼Œè€Œæ¼”å‘˜æ¥æ”¶ç¨³å®šçš„æ± åŒ–è¡¨ç¤ºä»¥æŒ‡å¯¼å…¶åŠ¨ä½œã€‚æˆ‘ä»¬çš„æ–¹æ³•å±•ç¤ºäº†åœ¨å„ç§æ‰°åŠ¨ï¼ˆåŒ…æ‹¬ä¼ æ„Ÿå™¨å™ªå£°å’Œå¯¹è±¡åŠ¨æ€å˜åŒ–ï¼‰ä¸‹çš„åŠ é€Ÿå­¦ä¹ å’Œé²æ£’æ€§èƒ½ã€‚åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ä¸–ç•Œä¸­çš„å¤šä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ã€æ¥è§¦å¼æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­çš„è¯„ä¼°å±•ç¤ºäº†MSDPçš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¯¹æ‰°åŠ¨è¡¨ç°å‡ºå¾ˆå¼ºçš„é²æ£’æ€§ï¼Œå¹¶åœ¨çœŸå®æœºå™¨äººä¸Šä»…é€šè¿‡6,000æ¬¡åœ¨çº¿äº¤äº’å°±å®ç°äº†é«˜æˆåŠŸç‡ï¼Œä¸ºå¤æ‚çš„å¤šæ¨¡æ€æœºå™¨äººæ§åˆ¶æä¾›äº†ä¸€ä¸ªç®€å•è€Œå¼ºå¤§çš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æ¥è§¦å¼æœºå™¨äººå¼ºåŒ–å­¦ä¹ ä¸­ï¼Œç”±äºå¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®ï¼ˆè§†è§‰ã€åŠ›è§‰ã€æœ¬ä½“æ„Ÿè§‰ï¼‰çš„å™ªå£°å’ŒåŠ¨æ€å˜åŒ–ï¼Œå¯¼è‡´ä¼ ç»Ÿå¼ºåŒ–å­¦ä¹ ç®—æ³•éš¾ä»¥æœ‰æ•ˆå­¦ä¹ çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éš¾ä»¥å……åˆ†åˆ©ç”¨å¤šæ¨¡æ€ä¿¡æ¯ï¼Œå¹¶ä¸”å¯¹ç¯å¢ƒæ‰°åŠ¨çš„é²æ£’æ€§è¾ƒå·®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œé¢„è®­ç»ƒä¸€ä¸ªèƒ½å¤Ÿæœ‰æ•ˆèåˆå¤šæ¨¡æ€ä¼ æ„Ÿå™¨ä¿¡æ¯çš„ç¼–ç å™¨ã€‚é€šè¿‡æ©ç è‡ªç¼–ç çš„æ–¹å¼ï¼Œè¿«ä½¿æ¨¡å‹ä»éƒ¨åˆ†ä¼ æ„Ÿå™¨æ•°æ®ä¸­é‡å»ºå®Œæ•´çš„å¤šæ¨¡æ€è§‚æµ‹ï¼Œä»è€Œå­¦ä¹ åˆ°è·¨æ¨¡æ€çš„å…³è”æ€§å’Œé²æ£’çš„ç‰¹å¾è¡¨ç¤ºã€‚è¿™ç§é¢„è®­ç»ƒçš„è¡¨ç¤ºå¯ä»¥åŠ é€Ÿä¸‹æ¸¸å¼ºåŒ–å­¦ä¹ ä»»åŠ¡çš„å­¦ä¹ è¿‡ç¨‹ï¼Œå¹¶æé«˜ç­–ç•¥çš„é²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMSDPæ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šé¢„è®­ç»ƒé˜¶æ®µå’Œç­–ç•¥å­¦ä¹ é˜¶æ®µã€‚åœ¨é¢„è®­ç»ƒé˜¶æ®µï¼Œä½¿ç”¨ä¸€ä¸ªåŸºäºTransformerçš„ç¼–ç å™¨ï¼Œé€šè¿‡æ©ç è‡ªç¼–ç çš„æ–¹å¼å­¦ä¹ å¤šæ¨¡æ€è¡¨ç¤ºã€‚åœ¨ç­–ç•¥å­¦ä¹ é˜¶æ®µï¼Œé‡‡ç”¨ä¸€ç§éå¯¹ç§°çš„Actor-Criticæ¶æ„ã€‚Criticç½‘ç»œä½¿ç”¨äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œä»é¢„è®­ç»ƒçš„å†»ç»“åµŒå…¥ä¸­æå–åŠ¨æ€çš„ã€ç‰¹å®šäºä»»åŠ¡çš„ç‰¹å¾ã€‚Actorç½‘ç»œæ¥æ”¶ä¸€ä¸ªç¨³å®šçš„æ± åŒ–è¡¨ç¤ºï¼Œç”¨äºæŒ‡å¯¼åŠ¨ä½œçš„ç”Ÿæˆã€‚

**å…³é”®åˆ›æ–°**ï¼šMSDPçš„å…³é”®åˆ›æ–°åœ¨äºå…¶å¤šæ¨¡æ€åŠ¨æ€é¢„è®­ç»ƒæ–¹æ³•å’Œéå¯¹ç§°çš„Actor-Criticæ¶æ„ã€‚å¤šæ¨¡æ€åŠ¨æ€é¢„è®­ç»ƒé€šè¿‡æ©ç è‡ªç¼–ç çš„æ–¹å¼ï¼Œå®ç°äº†è·¨æ¨¡æ€çš„ä¼ æ„Ÿå™¨èåˆå’Œé²æ£’çš„ç‰¹å¾æå–ã€‚éå¯¹ç§°çš„Actor-Criticæ¶æ„å…è®¸Criticç½‘ç»œåˆ©ç”¨åŠ¨æ€çš„ã€ç‰¹å®šäºä»»åŠ¡çš„ç‰¹å¾ï¼Œè€ŒActorç½‘ç»œåˆ™ä¿æŒç¨³å®šï¼Œä»è€Œæé«˜äº†å­¦ä¹ æ•ˆç‡å’Œç­–ç•¥çš„é²æ£’æ€§ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒMSDPèƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨å¤šæ¨¡æ€ä¿¡æ¯ï¼Œå¹¶ä¸”å¯¹ç¯å¢ƒæ‰°åŠ¨å…·æœ‰æ›´å¼ºçš„é²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨é¢„è®­ç»ƒé˜¶æ®µï¼Œä½¿ç”¨Transformerç¼–ç å™¨ï¼Œè¾“å…¥ä¸ºæ©ç åçš„å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®åµŒå…¥ã€‚æŸå¤±å‡½æ•°ä¸ºé‡å»ºè¯¯å·®ï¼Œç›®æ ‡æ˜¯æœ€å°åŒ–é‡å»ºçš„å¤šæ¨¡æ€è§‚æµ‹ä¸åŸå§‹è§‚æµ‹ä¹‹é—´çš„å·®å¼‚ã€‚åœ¨ç­–ç•¥å­¦ä¹ é˜¶æ®µï¼ŒCriticç½‘ç»œä½¿ç”¨äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œå°†çŠ¶æ€è¡¨ç¤ºä¸é¢„è®­ç»ƒçš„åµŒå…¥è¿›è¡Œèåˆã€‚Actorç½‘ç»œä½¿ç”¨ä¸€ä¸ªç®€å•çš„å…¨è¿æ¥ç½‘ç»œï¼Œè¾“å…¥ä¸ºæ± åŒ–åçš„é¢„è®­ç»ƒåµŒå…¥ã€‚è®ºæ–‡ä¸­æ²¡æœ‰æ˜ç¡®ç»™å‡ºå…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚ï¼Œä½†å¼ºè°ƒäº†é¢„è®­ç»ƒåµŒå…¥çš„å†»ç»“ï¼Œä»¥ä¿è¯Actorç½‘ç»œçš„ç¨³å®šæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

MSDPåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®æœºå™¨äººä»»åŠ¡ä¸­éƒ½å–å¾—äº†æ˜¾è‘—çš„æˆæœã€‚åœ¨çœŸå®æœºå™¨äººå®éªŒä¸­ï¼Œä»…ä½¿ç”¨6000æ¬¡åœ¨çº¿äº¤äº’ï¼ŒMSDPå°±å®ç°äº†å¾ˆé«˜çš„æˆåŠŸç‡ï¼Œå¹¶ä¸”è¡¨ç°å‡ºå¯¹ä¼ æ„Ÿå™¨å™ªå£°å’Œå¯¹è±¡åŠ¨æ€å˜åŒ–çš„é²æ£’æ€§ã€‚ä¸æ²¡æœ‰é¢„è®­ç»ƒçš„åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼ŒMSDPæ˜¾è‘—æé«˜äº†å­¦ä¹ æ•ˆç‡å’Œç­–ç•¥æ€§èƒ½ï¼Œè¯æ˜äº†å…¶åœ¨æ¥è§¦å¼æœºå™¨äººå¼ºåŒ–å­¦ä¹ ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦æ¥è§¦å¼æ“ä½œçš„æœºå™¨äººä»»åŠ¡ï¼Œä¾‹å¦‚è£…é…ã€æŠ“å–ã€æ“ä½œå·¥å…·ç­‰ã€‚é€šè¿‡é¢„è®­ç»ƒçš„å¤šæ¨¡æ€è¡¨ç¤ºï¼Œæœºå™¨äººå¯ä»¥æ›´å¥½åœ°ç†è§£ç¯å¢ƒï¼Œå¹¶åšå‡ºæ›´ç²¾ç¡®å’Œé²æ£’çš„åŠ¨ä½œã€‚è¯¥æ–¹æ³•åœ¨å·¥ä¸šè‡ªåŠ¨åŒ–ã€åŒ»ç–—æœºå™¨äººã€å®¶åº­æœåŠ¡æœºå™¨äººç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œæœ‰åŠ©äºæå‡æœºå™¨äººçš„æ™ºèƒ½åŒ–æ°´å¹³å’Œé€‚åº”èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Effective contact-rich manipulation requires robots to synergistically leverage vision, force, and proprioception. However, Reinforcement Learning agents struggle to learn in such multisensory settings, especially amidst sensory noise and dynamic changes. We propose MultiSensory Dynamic Pretraining (MSDP), a novel framework for learning expressive multisensory representations tailored for task-oriented policy learning. MSDP is based on masked autoencoding and trains a transformer-based encoder by reconstructing multisensory observations from only a subset of sensor embeddings, leading to cross-modal prediction and sensor fusion. For downstream policy learning, we introduce a novel asymmetric architecture, where a cross-attention mechanism allows the critic to extract dynamic, task-specific features from the frozen embeddings, while the actor receives a stable pooled representation to guide its actions. Our method demonstrates accelerated learning and robust performance under diverse perturbations, including sensor noise, and changes in object dynamics. Evaluations in multiple challenging, contact-rich robot manipulation tasks in simulation and the real world showcase the effectiveness of MSDP. Our approach exhibits strong robustness to perturbations and achieves high success rates on the real robot with as few as 6,000 online interactions, offering a simple yet powerful solution for complex multisensory robotic control.

