---
layout: default
title: Entropy-Controlled Intrinsic Motivation Reinforcement Learning for Quadruped Robot Locomotion in Complex Terrains
---

# Entropy-Controlled Intrinsic Motivation Reinforcement Learning for Quadruped Robot Locomotion in Complex Terrains

**arXiv**: [2512.06486v2](https://arxiv.org/abs/2512.06486) | [PDF](https://arxiv.org/pdf/2512.06486.pdf)

**ä½œè€…**: Wanru Gong, Xinyi Zheng, Yuan Hui, Zhongjun Li, Weiqiang Wang, Xiaoqing Zhu

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-12-06 (æ›´æ–°: 2025-12-13)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽç†µæŽ§åˆ¶çš„å†…åœ¨åŠ¨æœºå¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œæå‡å››è¶³æœºå™¨äººå¤æ‚åœ°å½¢è¿åŠ¨èƒ½åŠ›ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `å››è¶³æœºå™¨äºº` `å¼ºåŒ–å­¦ä¹ ` `å†…åœ¨åŠ¨æœº` `ç†µæŽ§åˆ¶` `å¤æ‚åœ°å½¢` `è¿åŠ¨æŽ§åˆ¶` `æœºå™¨äºº locomotion`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿå¼ºåŒ–å­¦ä¹ ç®—æ³•åœ¨å››è¶³æœºå™¨äººè¿åŠ¨æŽ§åˆ¶ä¸­æ˜“é™·å…¥æ—©ç†Ÿæ”¶æ•›ï¼Œå¯¼è‡´æ¬¡ä¼˜è¿åŠ¨ç­–ç•¥å’Œä»»åŠ¡æ€§èƒ½ä¸‹é™ã€‚
2. è®ºæ–‡æå‡ºECIMç®—æ³•ï¼Œç»“åˆç†µæŽ§åˆ¶å’Œå†…åœ¨åŠ¨æœºï¼Œé¼“åŠ±æ™ºèƒ½ä½“æŽ¢ç´¢æœªçŸ¥çŠ¶æ€ï¼Œé¿å…è¿‡æ—©æ”¶æ•›åˆ°å±€éƒ¨æœ€ä¼˜è§£ã€‚
3. å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒECIMåœ¨å¤šç§å¤æ‚åœ°å½¢ä¸‹æ˜¾è‘—æå‡äº†å››è¶³æœºå™¨äººçš„è¿åŠ¨æ€§èƒ½ï¼Œé™ä½Žäº†èƒ½é‡æ¶ˆè€—å’Œå…³èŠ‚åŽ‹åŠ›ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºç†µæŽ§åˆ¶å†…åœ¨åŠ¨æœºï¼ˆECIMï¼‰çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œæ—¨åœ¨è§£å†³å››è¶³æœºå™¨äººè¿åŠ¨ç­–ç•¥è®­ç»ƒä¸­å¸¸è§çš„æ—©ç†Ÿæ”¶æ•›é—®é¢˜ã€‚ä¸Žè¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆPPOï¼‰ç³»åˆ—ç®—æ³•ä¸åŒï¼ŒECIMé€šè¿‡ç»“åˆå†…åœ¨åŠ¨æœºå’Œè‡ªé€‚åº”æŽ¢ç´¢æ¥å‡å°‘æ—©ç†Ÿæ”¶æ•›ã€‚å®žéªŒè¡¨æ˜Žï¼Œåœ¨Isaac Gymçš„å…­ç§åœ°å½¢ç±»åˆ«ï¼ˆå‘ä¸Šæ–œå¡ã€å‘ä¸‹æ–œå¡ã€ä¸å¹³å¦ç²—ç³™åœ°å½¢ã€ä¸Šå‡æ¥¼æ¢¯ã€ä¸‹é™æ¥¼æ¢¯å’Œå¹³å¦åœ°é¢ï¼‰ä¸­ï¼ŒECIMå§‹ç»ˆä¼˜äºŽå…¶ä»–åŸºçº¿æ–¹æ³•ã€‚å…·ä½“è€Œè¨€ï¼Œä»»åŠ¡å¥–åŠ±æé«˜äº†4-12%ï¼Œèº«ä½“ä¿¯ä»°æŒ¯è¡å³°å€¼é™ä½Žäº†23-29%ï¼Œå…³èŠ‚åŠ é€Ÿåº¦é™ä½Žäº†20-32%ï¼Œå…³èŠ‚æ‰­çŸ©æ¶ˆè€—é™ä½Žäº†11-20%ã€‚ECIMé€šè¿‡ç»“åˆç†µæŽ§åˆ¶å’Œå†…åœ¨åŠ¨æœºæŽ§åˆ¶ï¼Œåœ¨ä¸åŒåœ°å½¢ä¸­å®žçŽ°äº†æ›´å¥½çš„å››è¶³è¿åŠ¨ç¨³å®šæ€§ï¼ŒåŒæ—¶é™ä½Žäº†èƒ½é‡æ¶ˆè€—ï¼Œä½¿å…¶æˆä¸ºå¤æ‚æœºå™¨äººæŽ§åˆ¶ä»»åŠ¡çš„å®žç”¨é€‰æ‹©ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰çš„åŸºäºŽPPOçš„å¼ºåŒ–å­¦ä¹ ç®—æ³•åœ¨è®­ç»ƒå››è¶³æœºå™¨äººè¿åŠ¨ç­–ç•¥æ—¶ï¼Œå®¹æ˜“å‡ºçŽ°æ—©ç†Ÿæ”¶æ•›çš„é—®é¢˜ã€‚è¿™æ„å‘³ç€æ™ºèƒ½ä½“åœ¨æŽ¢ç´¢åˆ°å…¨å±€æœ€ä¼˜ç­–ç•¥ä¹‹å‰ï¼Œå°±é™·å…¥äº†å±€éƒ¨æœ€ä¼˜è§£ï¼Œå¯¼è‡´æœ€ç»ˆå­¦ä¹ åˆ°çš„è¿åŠ¨ç­–ç•¥å¹¶éžæœ€ä¼˜ï¼Œä»Žè€Œé™åˆ¶äº†æœºå™¨äººåœ¨å¤æ‚åœ°å½¢ä¸‹çš„è¿åŠ¨èƒ½åŠ›ã€‚çŽ°æœ‰æ–¹æ³•ç¼ºä¹æœ‰æ•ˆçš„æŽ¢ç´¢æœºåˆ¶ï¼Œéš¾ä»¥è·³å‡ºå±€éƒ¨æœ€ä¼˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å¼•å…¥ç†µæŽ§åˆ¶çš„å†…åœ¨åŠ¨æœºæœºåˆ¶ã€‚ç†µæŽ§åˆ¶ç”¨äºŽé¼“åŠ±æ™ºèƒ½ä½“æŽ¢ç´¢æœªçŸ¥çš„çŠ¶æ€ç©ºé—´ï¼Œé¿å…è¿‡æ—©æ”¶æ•›ã€‚å†…åœ¨åŠ¨æœºåˆ™ä¸ºæ™ºèƒ½ä½“æä¾›é¢å¤–çš„å¥–åŠ±ä¿¡å·ï¼Œä¿ƒä½¿å…¶ä¸»åŠ¨æŽ¢ç´¢çŽ¯å¢ƒï¼Œå­¦ä¹ æ›´é²æ£’çš„è¿åŠ¨ç­–ç•¥ã€‚é€šè¿‡å°†ä¸¤è€…ç»“åˆï¼ŒECIMç®—æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°å¹³è¡¡æŽ¢ç´¢å’Œåˆ©ç”¨ï¼Œä»Žè€Œé¿å…æ—©ç†Ÿæ”¶æ•›ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šECIMç®—æ³•çš„æ•´ä½“æ¡†æž¶ä»ç„¶åŸºäºŽActor-Criticæž¶æž„ï¼Œç±»ä¼¼äºŽPPOã€‚ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) Actorç½‘ç»œï¼Œç”¨äºŽç”ŸæˆåŠ¨ä½œç­–ç•¥ï¼›2) Criticç½‘ç»œï¼Œç”¨äºŽè¯„ä¼°çŠ¶æ€ä»·å€¼ï¼›3) ç†µå¥–åŠ±æ¨¡å—ï¼Œæ ¹æ®å½“å‰ç­–ç•¥çš„ç†µå€¼ï¼Œç»™äºˆæ™ºèƒ½ä½“é¢å¤–çš„å¥–åŠ±ï¼Œé¼“åŠ±æŽ¢ç´¢ï¼›4) å†…åœ¨åŠ¨æœºå¥–åŠ±æ¨¡å—ï¼Œæ ¹æ®æ™ºèƒ½ä½“å¯¹çŽ¯å¢ƒçš„é¢„æµ‹è¯¯å·®ï¼Œç»™äºˆæ™ºèƒ½ä½“é¢å¤–çš„å¥–åŠ±ï¼Œé¼“åŠ±æŽ¢ç´¢æœªçŸ¥çŠ¶æ€ã€‚è¿™äº›æ¨¡å—å…±åŒä½œç”¨ï¼ŒæŒ‡å¯¼æ™ºèƒ½ä½“å­¦ä¹ æœ€ä¼˜è¿åŠ¨ç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šECIMç®—æ³•çš„å…³é”®åˆ›æ–°åœ¨äºŽå°†ç†µæŽ§åˆ¶å’Œå†…åœ¨åŠ¨æœºç›¸ç»“åˆï¼Œå¹¶å°†å…¶åº”ç”¨äºŽå››è¶³æœºå™¨äººè¿åŠ¨æŽ§åˆ¶ã€‚ä¸Žä¼ ç»Ÿçš„PPOç®—æ³•ç›¸æ¯”ï¼ŒECIMç®—æ³•èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°é¿å…æ—©ç†Ÿæ”¶æ•›ï¼Œä»Žè€Œå­¦ä¹ åˆ°æ›´é²æ£’ã€æ›´é«˜æ•ˆçš„è¿åŠ¨ç­–ç•¥ã€‚æ­¤å¤–ï¼ŒECIMç®—æ³•è¿˜é‡‡ç”¨äº†è‡ªé€‚åº”çš„æŽ¢ç´¢ç­–ç•¥ï¼Œèƒ½å¤Ÿæ ¹æ®çŽ¯å¢ƒçš„å¤æ‚ç¨‹åº¦åŠ¨æ€è°ƒæ•´æŽ¢ç´¢åŠ›åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šECIMç®—æ³•çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ç†µå¥–åŠ±çš„è®¾è®¡ï¼Œé€šå¸¸ä½¿ç”¨ç­–ç•¥åˆ†å¸ƒçš„ç†µä½œä¸ºå¥–åŠ±ä¿¡å·ï¼Œä¾‹å¦‚ä½¿ç”¨é«˜æ–¯åˆ†å¸ƒçš„æ–¹å·®æˆ–softmaxè¾“å‡ºçš„ç†µï¼›2) å†…åœ¨åŠ¨æœºå¥–åŠ±çš„è®¾è®¡ï¼Œé€šå¸¸åŸºäºŽé¢„æµ‹è¯¯å·®ï¼Œä¾‹å¦‚ä½¿ç”¨å‰å‘æ¨¡åž‹çš„é¢„æµ‹è¯¯å·®æˆ–çŠ¶æ€è¡¨å¾çš„é‡æž„è¯¯å·®ï¼›3) Actorå’ŒCriticç½‘ç»œçš„ç»“æž„ï¼Œé€šå¸¸ä½¿ç”¨å¤šå±‚æ„ŸçŸ¥æœºæˆ–å¾ªçŽ¯ç¥žç»ç½‘ç»œï¼›4) æŸå¤±å‡½æ•°çš„è®¾è®¡ï¼ŒåŒ…æ‹¬ç­–ç•¥æ¢¯åº¦æŸå¤±ã€ä»·å€¼å‡½æ•°æŸå¤±ã€ç†µå¥–åŠ±æŸå¤±å’Œå†…åœ¨åŠ¨æœºå¥–åŠ±æŸå¤±ã€‚è¿™äº›è®¾è®¡å…±åŒå†³å®šäº†ECIMç®—æ³•çš„æ€§èƒ½ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒECIMç®—æ³•åœ¨å…­ç§å¤æ‚åœ°å½¢ä¸­å‡ä¼˜äºŽåŸºçº¿æ–¹æ³•ã€‚ä»»åŠ¡å¥–åŠ±å¹³å‡æé«˜äº†4-12%ï¼Œèº«ä½“ä¿¯ä»°æŒ¯è¡å³°å€¼é™ä½Žäº†23-29%ï¼Œå…³èŠ‚åŠ é€Ÿåº¦é™ä½Žäº†20-32%ï¼Œå…³èŠ‚æ‰­çŸ©æ¶ˆè€—é™ä½Žäº†11-20%ã€‚è¿™äº›æ•°æ®è¡¨æ˜Žï¼ŒECIMç®—æ³•ä¸ä»…æå‡äº†æœºå™¨äººçš„è¿åŠ¨æ€§èƒ½ï¼Œè¿˜é™ä½Žäº†èƒ½é‡æ¶ˆè€—å’Œå…³èŠ‚åŽ‹åŠ›ï¼Œä½¿å…¶æ›´å…·å®žç”¨ä»·å€¼ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯å¹¿æ³›åº”ç”¨äºŽå„ç§éœ€è¦å››è¶³æœºå™¨äººè¿›è¡Œå¤æ‚åœ°å½¢è¿åŠ¨çš„åœºæ™¯ï¼Œä¾‹å¦‚æœæ•‘ã€å‹˜æŽ¢ã€ç‰©æµå’Œå·¡æ£€ç­‰ã€‚é€šè¿‡æå‡æœºå™¨äººçš„è¿åŠ¨èƒ½åŠ›å’Œç¨³å®šæ€§ï¼Œå¯ä»¥ä½¿å…¶åœ¨æ¶åŠ£çŽ¯å¢ƒä¸‹æ‰§è¡Œä»»åŠ¡ï¼Œé™ä½Žäººå‘˜é£Žé™©ï¼Œæé«˜å·¥ä½œæ•ˆçŽ‡ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›è¿›ä¸€æ­¥æŽ¨å¹¿åˆ°å…¶ä»–ç±»åž‹çš„æœºå™¨äººï¼Œä¾‹å¦‚äººå½¢æœºå™¨äººå’Œè½®å¼æœºå™¨äººã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Learning is the basis of both biological and artificial systems when it comes to mimicking intelligent behaviors. From the classical PPO (Proximal Policy Optimization), there is a series of deep reinforcement learning algorithms which are widely used in training locomotion policies for quadrupedal robots because of their stability and sample efficiency. However, among all these variants, experiments and simulations often converge prematurely, leading to suboptimal locomotion and reduced task performance. Therefore, in this paper, we introduce Entropy-Controlled Intrinsic Motivation (ECIM), an entropy-based reinforcement learning algorithm in contrast with the PPO series, that can reduce premature convergence by combining intrinsic motivation with adaptive exploration.
>   For experiments, in order to parallel with other baselines, we chose to apply it in Isaac Gym across six terrain categories: upward slopes, downward slopes, uneven rough terrain, ascending stairs, descending stairs, and flat ground as widely used. For comparison, our experiments consistently achieve better performance: task rewards increase by 4--12%, peak body pitch oscillation is reduced by 23--29%, joint acceleration decreases by 20--32%, and joint torque consumption declines by 11--20%. Overall, our model ECIM, by combining entropy control and intrinsic motivation control, achieves better results in stability across different terrains for quadrupedal locomotion, and at the same time reduces energetic cost and makes it a practical choice for complex robotic control tasks.

