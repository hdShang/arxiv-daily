---
layout: default
title: "Demystifying Diffusion Policies: Action Memorization and Simple Lookup Table Alternatives"
---

# Demystifying Diffusion Policies: Action Memorization and Simple Lookup Table Alternatives

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.05787" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.05787v1</a>
  <a href="https://arxiv.org/pdf/2505.05787.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.05787v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.05787v1', 'Demystifying Diffusion Policies: Action Memorization and Simple Lookup Table Alternatives')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Chengyang He, Xu Liu, Gadiel Sznaier Camps, Guillaume Sartoretti, Mac Schwager

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-09

**üîó ‰ª£Á†Å/È°πÁõÆ**: [PROJECT_PAGE](https://stanfordmsl.github.io/alt/)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âä®‰ΩúÊü•ÊâæË°®ÊîøÁ≠ñ‰ª•Êõø‰ª£Êâ©Êï£ÊîøÁ≠ñËß£ÂÜ≥Êú∫Âô®‰∫∫Êìç‰ΩúÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Êâ©Êï£ÊîøÁ≠ñ` `Âä®‰ΩúÊü•ÊâæË°®` `Êú∫Âô®‰∫∫Êìç‰Ωú` `Á®ÄÁñèÊï∞ÊçÆ` `ÂØπÊØîÂ≠¶‰π†` `ËøêË°åÊó∂ÁõëÊéß` `È´òÊïàÊé®ÁêÜ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÊâ©Êï£ÊîøÁ≠ñÂú®È´òÁª¥Êú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰∏≠Ë°®Áé∞‰ºòÂºÇÔºå‰ΩÜÂÖ∂ÊÄßËÉΩÊú∫Âà∂Â∞ö‰∏çÊ∏ÖÊô∞ÔºåÂ∞§ÂÖ∂Âú®Á®ÄÁñèÊï∞ÊçÆÊÉÖÂÜµ‰∏ãÁöÑÊ≥õÂåñËÉΩÂäõ‰∏çË∂≥„ÄÇ
2. Êú¨ÊñáÊèêÂá∫ÁöÑÂä®‰ΩúÊü•ÊâæË°®ÔºàALTÔºâÊîøÁ≠ñÈÄöËøáÂØπÊØîÂõæÂÉèÁºñÁ†ÅÂô®‰Ωú‰∏∫ÂìàÂ∏åÂáΩÊï∞ÔºåÊòæÂºèÂú∞Á¥¢Âºï‰∏éËÆ≠ÁªÉÂä®‰ΩúÂ∫èÂàóÊúÄÊé•ËøëÁöÑÂõæÂÉèÔºåÊèê‰æõ‰∫Ü‰∏ÄÁßçËΩªÈáèÁ∫ßÁöÑÊõø‰ª£ÊñπÊ°à„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåALTÂú®Â∞èÂûãÊï∞ÊçÆÈõÜ‰∏ä‰∏éÊâ©Êï£Ê®°ÂûãÁöÑÊÄßËÉΩÁõ∏ÂΩìÔºåÂêåÊó∂Êé®ÁêÜÊó∂Èó¥‰ªÖ‰∏∫0.0034ÔºåÂÜÖÂ≠òÂç†Áî®‰∏∫0.0085ÔºåÊòæËëóÊèêÈ´ò‰∫ÜÈó≠ÁéØÊé®ÁêÜÁöÑÊïàÁéá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êâ©Êï£ÊîøÁ≠ñÂú®Â§çÊùÇÈ´òÁª¥Êú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫Ëâ≤ÔºåÂ∞§ÂÖ∂ÊòØÂú®Â∞ëÈáèÁ§∫‰æãËÆ≠ÁªÉÁöÑÊÉÖÂÜµ‰∏ã„ÄÇÁÑ∂ËÄåÔºåÂÖ∂ÊÄßËÉΩËÉåÂêéÁöÑÂéüÂõ†‰ªçÁÑ∂‰∏çÊòé„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏Ä‰∏™ÂÅáËÆæÔºöÊâ©Êï£ÊîøÁ≠ñÊú¨Ë¥®‰∏äÊòØËÆ∞ÂøÜ‰∏Ä‰∏™Âä®‰ΩúÊü•ÊâæË°®ÔºåËøôÂú®Á®ÄÁñèÊï∞ÊçÆÁéØÂ¢É‰∏≠ÊòØÊúâÁõäÁöÑ„ÄÇÊàë‰ª¨ÈÄöËøáÂÆûËØÅÁ†îÁ©∂ÊîØÊåÅËøô‰∏ÄËßÇÁÇπÔºåÂπ∂ÊèêÂá∫‰∫Ü‰∏ÄÁßçÁÆÄÂçïÁöÑÊõø‰ª£ÊñπÊ°à‚Äî‚ÄîÂä®‰ΩúÊü•ÊâæË°®ÔºàALTÔºâÔºåËØ•ÊñπÊ≥ïÂú®Â∞èÂûãÊï∞ÊçÆÈõÜ‰∏ä‰∏éÊâ©Êï£Ê®°ÂûãÁöÑÊÄßËÉΩÁõ∏ÂΩìÔºå‰ΩÜÊé®ÁêÜÊó∂Èó¥ÂíåÂÜÖÂ≠òÂç†Áî®ÊòæËëóÈôç‰ΩéÔºåÈÄÇÁî®‰∫éËµÑÊ∫êÂèóÈôêÁöÑÊú∫Âô®‰∫∫„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Êâ©Êï£ÊîøÁ≠ñÂú®È´òÁª¥Êú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰∏≠ÊÄßËÉΩÊú∫Âà∂‰∏çÊòéÁöÑÈóÆÈ¢òÔºåÂ∞§ÂÖ∂ÊòØÂú®Á®ÄÁñèÊï∞ÊçÆÁéØÂ¢É‰∏ãÁöÑÊ≥õÂåñËÉΩÂäõ‰∏çË∂≥„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®Â§ÑÁêÜÊú™Áü•ÂàÜÂ∏ÉÔºàOODÔºâÂõæÂÉèÊó∂Ë°®Áé∞‰∏ç‰Ω≥ÔºåÁº∫‰πèÊúâÊïàÁöÑËøêË°åÊó∂ÁõëÊéßÊú∫Âà∂„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÊèêÂá∫ÁöÑÂä®‰ΩúÊü•ÊâæË°®ÔºàALTÔºâÊîøÁ≠ñÈÄöËøáÂØπÊØîÂõæÂÉèÁºñÁ†ÅÂô®‰Ωú‰∏∫ÂìàÂ∏åÂáΩÊï∞ÔºåÊòæÂºèÂú∞Á¥¢Âºï‰∏éËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠ÊúÄÊé•ËøëÁöÑÂä®‰ΩúÂ∫èÂàóÔºå‰ªéËÄåÂÆûÁé∞È´òÊïàÁöÑÂä®‰ΩúÂõûÂøÜÔºåËÄåÊó†ÈúÄÂ§çÊùÇÁöÑÂä®‰ΩúÊ≥õÂåñ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöALTÊîøÁ≠ñÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨ÂõæÂÉèÁºñÁ†ÅÂô®„ÄÅÂä®‰ΩúÊü•ÊâæÊ®°ÂùóÂíåËøêË°åÊó∂ÁõëÊéßÊ®°Âùó„ÄÇÂõæÂÉèÁºñÁ†ÅÂô®Â∞ÜËæìÂÖ•ÂõæÂÉèÊò†Â∞ÑÂà∞ÊΩúÂú®Á©∫Èó¥ÔºåÊü•ÊâæÊ®°ÂùóÊ†πÊçÆÊΩúÂú®Á©∫Èó¥‰∏≠ÁöÑË∑ùÁ¶ªÊâæÂà∞ÊúÄÊé•ËøëÁöÑËÆ≠ÁªÉÂä®‰ΩúÂ∫èÂàóÔºåÁõëÊéßÊ®°ÂùóÂàôÂà§Êñ≠ËæìÂÖ•ÂõæÂÉèÊòØÂê¶Ë∂ÖÂá∫ËÆ≠ÁªÉÂàÜÂ∏É„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöALTÊîøÁ≠ñÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÂÖ∂ÊòæÂºèÁöÑÂä®‰ΩúÊü•ÊâæÊú∫Âà∂ÔºåÂå∫Âà´‰∫éÊâ©Êï£ÊîøÁ≠ñÁöÑÈöêÂºèÂ≠¶‰π†ÊñπÂºè„ÄÇÈÄöËøáËøôÁßçËÆæËÆ°ÔºåALTËÉΩÂ§üÂú®Á®ÄÁñèÊï∞ÊçÆÊÉÖÂÜµ‰∏ã‰ªçÁÑ∂‰øùÊåÅÈ´òÊïàÁöÑÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöALTÊîøÁ≠ñ‰ΩøÁî®ÂØπÊØîÊçüÂ§±ÂáΩÊï∞Êù•ËÆ≠ÁªÉÂõæÂÉèÁºñÁ†ÅÂô®ÔºåÁ°Æ‰øùÁõ∏‰ººÂõæÂÉèÂú®ÊΩúÂú®Á©∫Èó¥‰∏≠Ë∑ùÁ¶ªËæÉËøë„ÄÇÊ≠§Â§ñÔºåËÆæËÆ°‰∫Ü‰∏Ä‰∏™ÁÆÄÂçïÁöÑOODÊ†áÂøóÊú∫Âà∂ÔºåÂΩìËæìÂÖ•ÂõæÂÉè‰∏éËÆ≠ÁªÉÂõæÂÉèÁöÑË∑ùÁ¶ªË∂ÖËøáËÆæÂÆöÈòàÂÄºÊó∂ÔºåÁ≥ªÁªü‰ºöÂèëÂá∫Ë≠¶ÂëäÔºåÂ¢ûÂº∫‰∫ÜËøêË°åÊó∂ÁöÑÂÆâÂÖ®ÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåALTÊîøÁ≠ñÂú®Â∞èÂûãÊï∞ÊçÆÈõÜ‰∏äÁöÑÊÄßËÉΩ‰∏éÊâ©Êï£Ê®°ÂûãÁõ∏ÂΩìÔºåÊé®ÁêÜÊó∂Èó¥‰ªÖ‰∏∫0.0034ÔºåÂÜÖÂ≠òÂç†Áî®‰∏∫0.0085ÔºåÊòæËëóÊèêÈ´ò‰∫ÜÈó≠ÁéØÊé®ÁêÜÁöÑÊïàÁéá„ÄÇËøôË°®ÊòéALTÂú®ËµÑÊ∫êÂèóÈôêÁéØÂ¢É‰∏≠ÁöÑÂ∫îÁî®ÊΩúÂäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Â∑•‰∏öÊú∫Âô®‰∫∫„ÄÅÊúçÂä°Êú∫Âô®‰∫∫‰ª•Âèä‰ªª‰ΩïÈúÄË¶ÅÈ´òÊïàÂÜ≥Á≠ñÁöÑËá™Âä®ÂåñÁ≥ªÁªü„ÄÇALTÊîøÁ≠ñÁöÑÈ´òÊïàÊÄßÂíå‰ΩéËµÑÊ∫êÊ∂àËÄó‰ΩøÂÖ∂ÈÄÇÁî®‰∫éËµÑÊ∫êÂèóÈôêÁöÑÁéØÂ¢ÉÔºåÊú™Êù•ÂèØËÉΩÊé®Âä®Êõ¥Â§öÊô∫ËÉΩÊú∫Âô®‰∫∫Âú®Â§çÊùÇ‰ªªÂä°‰∏≠ÁöÑÂ∫îÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Diffusion policies have demonstrated remarkable dexterity and robustness in intricate, high-dimensional robot manipulation tasks, while training from a small number of demonstrations. However, the reason for this performance remains a mystery. In this paper, we offer a surprising hypothesis: diffusion policies essentially memorize an action lookup table -- and this is beneficial. We posit that, at runtime, diffusion policies find the closest training image to the test image in a latent space, and recall the associated training action sequence, offering reactivity without the need for action generalization. This is effective in the sparse data regime, where there is not enough data density for the model to learn action generalization. We support this claim with systematic empirical evidence. Even when conditioned on wildly out of distribution (OOD) images of cats and dogs, the Diffusion Policy still outputs an action sequence from the training data. With this insight, we propose a simple policy, the Action Lookup Table (ALT), as a lightweight alternative to the Diffusion Policy. Our ALT policy uses a contrastive image encoder as a hash function to index the closest corresponding training action sequence, explicitly performing the computation that the Diffusion Policy implicitly learns. We show empirically that for relatively small datasets, ALT matches the performance of a diffusion model, while requiring only 0.0034 of the inference time and 0.0085 of the memory footprint, allowing for much faster closed-loop inference with resource constrained robots. We also train our ALT policy to give an explicit OOD flag when the distance between the runtime image is too far in the latent space from the training images, giving a simple but effective runtime monitor. More information can be found at: https://stanfordmsl.github.io/alt/.

