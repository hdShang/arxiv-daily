---
layout: default
title: Multi-Agent Systems for Robotic Autonomy with LLMs
---

# Multi-Agent Systems for Robotic Autonomy with LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.05762" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.05762v1</a>
  <a href="https://arxiv.org/pdf/2505.05762.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.05762v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.05762v1', 'Multi-Agent Systems for Robotic Autonomy with LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Junhong Chen, Ziqi Yang, Haoyuan G Xu, Dandan Zhang, George Mylonas

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-09

**å¤‡æ³¨**: 11 pages, 2 figures, 5 tables, submitted for publication

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šæ™ºèƒ½ä½“æ¡†æ¶ä»¥æå‡æœºå™¨äººè‡ªä¸»æ€§ä¸ä»»åŠ¡åˆ†æèƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ` `æœºå™¨äººè‡ªä¸»æ€§` `ä»»åŠ¡åˆ†æ` `æœºæ¢°è®¾è®¡` `è·¯å¾„ç”Ÿæˆ` `å¼ºåŒ–å­¦ä¹ ` `å¤§å‹è¯­è¨€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æœºå™¨äººç³»ç»Ÿå¼€å‘æ–¹æ³•åœ¨ä»»åŠ¡åˆ†æå’Œè®¾è®¡æ•ˆç‡ä¸Šå­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥æ»¡è¶³å¤æ‚åº”ç”¨éœ€æ±‚ã€‚
2. æå‡ºçš„å¤šæ™ºèƒ½ä½“æ¡†æ¶é€šè¿‡é›†æˆä»»åŠ¡åˆ†æã€æœºæ¢°è®¾è®¡å’Œè·¯å¾„ç”Ÿæˆï¼Œæå‡æœºå™¨äººè‡ªä¸»æ€§å’Œè®¾è®¡æ•ˆç‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨é€‚å½“è¾“å…¥ä¸‹èƒ½å¤Ÿè®¾è®¡å‡ºæœ‰æ•ˆçš„æœºå™¨äººæ§åˆ¶ç­–ç•¥ï¼Œå±•ç¤ºå‡ºæ˜¾è‘—çš„åº”ç”¨æ½œåŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è‡ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é—®ä¸–ä»¥æ¥ï¼ŒåŸºäºæ­¤ç±»æ¨¡å‹çš„ç ”ç©¶åœ¨äººå·¥æ™ºèƒ½å’Œæœºå™¨äººé¢†åŸŸå¼•èµ·äº†å¹¿æ³›å…³æ³¨ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºLLMsçš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œç”¨äºæ„å»ºé›†æˆçš„æœºå™¨äººä»»åŠ¡åˆ†æã€æœºæ¢°è®¾è®¡å’Œè·¯å¾„ç”Ÿæˆç³»ç»Ÿã€‚è¯¥æ¡†æ¶åŒ…æ‹¬ä¸‰ä¸ªæ ¸å¿ƒæ™ºèƒ½ä½“ï¼šä»»åŠ¡åˆ†æå¸ˆã€æœºå™¨äººè®¾è®¡å¸ˆå’Œå¼ºåŒ–å­¦ä¹ è®¾è®¡å¸ˆã€‚è¾“å‡ºç»“æœä»¥å¤šæ¨¡æ€å½¢å¼å‘ˆç°ï¼Œå¦‚ä»£ç æ–‡ä»¶æˆ–æŠ€æœ¯æŠ¥å‘Šï¼Œä»¥å¢å¼ºå¯ç†è§£æ€§å’Œå¯ç”¨æ€§ã€‚é€šè¿‡å¯¹GPTå’ŒDeepSeekæ¨¡å‹çš„å®éªŒè¯„ä¼°ï¼Œç»“æœè¡¨æ˜è¯¥ç³»ç»Ÿèƒ½å¤Ÿåœ¨é€‚å½“çš„ä»»åŠ¡è¾“å…¥ä¸‹è®¾è®¡å‡ºå¯è¡Œçš„æœºå™¨äººåŠæ§åˆ¶ç­–ç•¥ï¼Œæ˜¾ç¤ºå‡ºåœ¨ç ”ç©¶å’Œå·¥ä¸šåº”ç”¨ä¸­æå‡æœºå™¨äººç³»ç»Ÿå¼€å‘æ•ˆç‡å’Œå¯åŠæ€§çš„æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰æœºå™¨äººç³»ç»Ÿå¼€å‘ä¸­ä»»åŠ¡åˆ†æå’Œè®¾è®¡æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•æœ‰æ•ˆæ•´åˆå¤šç§è®¾è®¡éœ€æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ„å»ºä¸€ä¸ªå¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ•´åˆä»»åŠ¡åˆ†æã€æœºæ¢°è®¾è®¡å’Œè·¯å¾„ç”Ÿæˆï¼Œåˆ©ç”¨LLMsçš„å¼ºå¤§èƒ½åŠ›æ¥æå‡æœºå™¨äººè®¾è®¡çš„æ™ºèƒ½åŒ–æ°´å¹³ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶ç”±ä¸‰ä¸ªæ ¸å¿ƒæ™ºèƒ½ä½“ç»„æˆï¼šä»»åŠ¡åˆ†æå¸ˆè´Ÿè´£è§£æä»»åŠ¡éœ€æ±‚ï¼Œæœºå™¨äººè®¾è®¡å¸ˆè¿›è¡Œæœºæ¢°è®¾è®¡ï¼Œå¼ºåŒ–å­¦ä¹ è®¾è®¡å¸ˆä¼˜åŒ–æ§åˆ¶ç­–ç•¥ã€‚æ•´ä½“æµç¨‹é€šè¿‡å¤šæ¨¡æ€è¾“å‡ºå¢å¼ºå¯ç†è§£æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†LLMsä¸å¤šæ™ºèƒ½ä½“ç³»ç»Ÿç»“åˆï¼Œå½¢æˆä¸€ä¸ªååŒå·¥ä½œçš„å¹³å°ï¼Œæ˜¾è‘—æå‡äº†æœºå™¨äººè®¾è®¡çš„çµæ´»æ€§å’Œæ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡è¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨ä»»åŠ¡åˆ†æå’Œè®¾è®¡ç”Ÿæˆä¸­çš„å‡†ç¡®æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨è¯¥æ¡†æ¶çš„æœºå™¨äººè®¾è®¡åœ¨ä»»åŠ¡è¾“å…¥é€‚å½“çš„æƒ…å†µä¸‹ï¼Œèƒ½å¤ŸæˆåŠŸç”Ÿæˆæœ‰æ•ˆçš„æ§åˆ¶ç­–ç•¥ï¼Œè¾ƒä¼ ç»Ÿæ–¹æ³•åœ¨è®¾è®¡æ•ˆç‡ä¸Šæå‡äº†æ˜¾è‘—çš„æ€§èƒ½ï¼Œå…·ä½“æå‡å¹…åº¦æœªçŸ¥ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å·¥ä¸šæœºå™¨äººè®¾è®¡ã€è‡ªåŠ¨åŒ–ç”Ÿäº§çº¿ã€æ™ºèƒ½å®¶å±…ç³»ç»Ÿç­‰ã€‚é€šè¿‡æå‡æœºå™¨äººç³»ç»Ÿçš„è‡ªä¸»æ€§å’Œè®¾è®¡æ•ˆç‡ï¼Œèƒ½å¤Ÿåœ¨å¤šä¸ªè¡Œä¸šä¸­å®ç°æ›´é«˜æ•ˆçš„èµ„æºé…ç½®å’Œä»»åŠ¡æ‰§è¡Œï¼Œæœªæ¥å¯èƒ½å¯¹æœºå™¨äººæŠ€æœ¯çš„æ™®åŠå’Œåº”ç”¨äº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Since the advent of Large Language Models (LLMs), various research based on such models have maintained significant academic attention and impact, especially in AI and robotics. In this paper, we propose a multi-agent framework with LLMs to construct an integrated system for robotic task analysis, mechanical design, and path generation. The framework includes three core agents: Task Analyst, Robot Designer, and Reinforcement Learning Designer. Outputs are formatted as multimodal results, such as code files or technical reports, for stronger understandability and usability. To evaluate generalizability comparatively, we conducted experiments with models from both GPT and DeepSeek. Results demonstrate that the proposed system can design feasible robots with control strategies when appropriate task inputs are provided, exhibiting substantial potential for enhancing the efficiency and accessibility of robotic system development in research and industrial applications.

