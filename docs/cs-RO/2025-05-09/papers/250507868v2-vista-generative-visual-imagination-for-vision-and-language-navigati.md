---
layout: default
title: VISTA: Generative Visual Imagination for Vision-and-Language Navigation
---

# VISTA: Generative Visual Imagination for Vision-and-Language Navigation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.07868" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.07868v2</a>
  <a href="https://arxiv.org/pdf/2505.07868.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.07868v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.07868v2', 'VISTA: Generative Visual Imagination for Vision-and-Language Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yanjia Huang, Mingyang Wu, Renjie Li, Zhengzhong Tu

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-05-09 (æ›´æ–°: 2025-05-17)

**å¤‡æ³¨**: 13 pages, 5 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVISTAä»¥è§£å†³è§†è§‰ä¸è¯­è¨€å¯¼èˆªä¸­çš„é•¿æ—¶é—´è§‚å¯Ÿé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰ä¸è¯­è¨€å¯¼èˆª` `ç”Ÿæˆæ¨¡å‹` `åŠ¨æ€è§†è§‰æƒ³è±¡` `æ„ŸçŸ¥å¯¹é½` `é•¿æ—¶é—´åœºæ™¯` `æ™ºèƒ½ä½“æ¨ç†` `æœºå™¨äººå¯¼èˆª`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†è§‰ä¸è¯­è¨€å¯¼èˆªæ–¹æ³•åœ¨é•¿æ—¶é—´åœºæ™¯ä¸­é¢ä¸´è§‚å¯Ÿé™åˆ¶å’Œè§†è§‰-è¯­è¨€æ¨¡æ€å·®è·ç­‰æŒ‘æˆ˜ï¼Œå¯¼è‡´å¯¼èˆªæ€§èƒ½ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºVISTAæ¡†æ¶ï¼Œé‡‡ç”¨'æƒ³è±¡ä¸å¯¹é½'ç­–ç•¥ï¼Œé€šè¿‡ç”Ÿæˆæ¨¡å‹è¿›è¡ŒåŠ¨æ€è§†è§‰æƒ³è±¡ï¼Œç»“åˆå±€éƒ¨è§‚å¯Ÿå’Œè¯­è¨€æŒ‡ä»¤ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒVISTAåœ¨R2Rå’ŒRoboTHORåŸºå‡†ä¸Šå–å¾—äº†æ˜¾è‘—æå‡ï¼ŒR2RæˆåŠŸç‡æé«˜3.6%ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰ä¸è¯­è¨€å¯¼èˆªï¼ˆVLNï¼‰ä»»åŠ¡è¦æ±‚æ™ºèƒ½ä½“åœ¨æœªè§ç¯å¢ƒä¸­æ ¹æ®è‡ªç„¶è¯­è¨€æŒ‡ä»¤å’Œè§†è§‰çº¿ç´¢å®šä½ç‰¹å®šç‰©ä½“ã€‚ç°æœ‰VLNæ–¹æ³•é€šå¸¸éµå¾ª'è§‚å¯Ÿä¸æ¨ç†'çš„æ¨¡å¼ï¼Œé¢ä¸´é•¿æ—¶é—´åœºæ™¯ä¸­çš„è§‚å¯Ÿé™åˆ¶å’Œè§†è§‰-è¯­è¨€æ¨¡æ€å·®è·ç­‰æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºVISTAï¼Œä¸€ä¸ªé‡‡ç”¨'æƒ³è±¡ä¸å¯¹é½'å¯¼èˆªç­–ç•¥çš„æ–°æ¡†æ¶ã€‚æˆ‘ä»¬åˆ©ç”¨é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆå…ˆéªŒï¼ŒåŸºäºå±€éƒ¨è§‚å¯Ÿå’Œé«˜å±‚è¯­è¨€æŒ‡ä»¤è¿›è¡ŒåŠ¨æ€è§†è§‰æƒ³è±¡ã€‚æ„ŸçŸ¥å¯¹é½è¿‡æ»¤å™¨æ¨¡å—å°†è¿™äº›ç›®æ ‡æƒ³è±¡ä¸å½“å‰è§‚å¯Ÿè¿›è¡Œå¯¹é½ï¼ŒæŒ‡å¯¼å¯è§£é‡Šå’Œç»“æ„åŒ–çš„æ¨ç†è¿‡ç¨‹ä»¥é€‰æ‹©è¡ŒåŠ¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒVISTAåœ¨Room-to-Roomï¼ˆR2Rï¼‰å’ŒRoboTHORåŸºå‡†ä¸Šè®¾å®šäº†æ–°çš„æœ€å…ˆè¿›ç»“æœï¼Œä¾‹å¦‚R2RæˆåŠŸç‡æé«˜3.6%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è§†è§‰ä¸è¯­è¨€å¯¼èˆªä»»åŠ¡ä¸­æ™ºèƒ½ä½“åœ¨é•¿æ—¶é—´åœºæ™¯ä¸‹çš„è§‚å¯Ÿé™åˆ¶å’Œè§†è§‰-è¯­è¨€æ¨¡æ€å·®è·é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–äºå³æ—¶è§‚å¯Ÿï¼Œéš¾ä»¥æœ‰æ•ˆåº”å¯¹å¤æ‚ç¯å¢ƒä¸­çš„å¯¼èˆªæŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šVISTAæ¡†æ¶é‡‡ç”¨'æƒ³è±¡ä¸å¯¹é½'çš„å¯¼èˆªç­–ç•¥ï¼Œé€šè¿‡ç”Ÿæˆæ¨¡å‹çš„èƒ½åŠ›è¿›è¡ŒåŠ¨æ€è§†è§‰æƒ³è±¡ï¼Œç»“åˆå±€éƒ¨è§‚å¯Ÿå’Œé«˜å±‚è¯­è¨€æŒ‡ä»¤ï¼Œä»è€Œå¢å¼ºæ™ºèƒ½ä½“çš„å¯¼èˆªèƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVISTAçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šç”Ÿæˆæ¨¡å‹ç”¨äºåŠ¨æ€è§†è§‰æƒ³è±¡ï¼Œæ„ŸçŸ¥å¯¹é½è¿‡æ»¤å™¨ç”¨äºå°†æƒ³è±¡ä¸å½“å‰è§‚å¯Ÿè¿›è¡Œå¯¹é½ã€‚è¿™ä¸€æµç¨‹ç¡®ä¿äº†æ™ºèƒ½ä½“åœ¨é€‰æ‹©è¡ŒåŠ¨æ—¶èƒ½å¤Ÿè¿›è¡Œå¯è§£é‡Šçš„æ¨ç†ã€‚

**å…³é”®åˆ›æ–°**ï¼šVISTAçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå¼•å…¥äº†åŸºäºç”Ÿæˆæ¨¡å‹çš„å‰ç»æ€§æƒ³è±¡èƒ½åŠ›ï¼Œæ˜¾è‘—åŒºåˆ«äºä¼ ç»Ÿçš„'è§‚å¯Ÿä¸æ¨ç†'æ–¹æ³•ï¼Œæå‡äº†åœ¨é•¿æ—¶é—´åœºæ™¯ä¸­çš„å¯¼èˆªè¡¨ç°ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼ŒVISTAä½¿ç”¨äº†é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ä½œä¸ºç”ŸæˆåŸºç¡€ï¼Œè®¾è®¡äº†æ„ŸçŸ¥å¯¹é½è¿‡æ»¤å™¨ä»¥å®ç°ç›®æ ‡æƒ³è±¡ä¸å½“å‰è§‚å¯Ÿçš„å¯¹é½ï¼Œç¡®ä¿äº†æ¨ç†è¿‡ç¨‹çš„ç»“æ„åŒ–å’Œå¯è§£é‡Šæ€§ã€‚å®éªŒä¸­è¿˜è¿›è¡Œäº†å¹¿æ³›çš„æ¶ˆèåˆ†æï¼Œä»¥éªŒè¯å„ä¸ªæ¨¡å—çš„è´¡çŒ®ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

VISTAåœ¨Room-to-Roomï¼ˆR2Rï¼‰å’ŒRoboTHORåŸºå‡†ä¸Šå–å¾—äº†æ–°çš„æœ€å…ˆè¿›ç»“æœï¼ŒR2RæˆåŠŸç‡æé«˜äº†3.6%ã€‚è¿™äº›å®éªŒç»“æœè¡¨æ˜ï¼ŒVISTAåœ¨é•¿æ—¶é—´å¯¼èˆªä»»åŠ¡ä¸­æ˜¾è‘—æå‡äº†æ™ºèƒ½ä½“çš„æ€§èƒ½ï¼ŒéªŒè¯äº†å…¶åˆ›æ–°æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

VISTAæ¡†æ¶åœ¨æ™ºèƒ½å¯¼èˆªã€æœºå™¨äººæ¢ç´¢å’Œäººæœºäº¤äº’ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æé«˜æ™ºèƒ½ä½“åœ¨å¤æ‚ç¯å¢ƒä¸­çš„å¯¼èˆªèƒ½åŠ›ï¼Œè¯¥ç ”ç©¶å¯ä»¥æ¨åŠ¨æ™ºèƒ½æœºå™¨äººåœ¨å®é™…åœºæ™¯ä¸­çš„åº”ç”¨ï¼Œå¦‚å®¶åº­æœåŠ¡ã€æ— äººé©¾é©¶å’Œè™šæ‹Ÿç°å®ç­‰ã€‚æœªæ¥ï¼ŒVISTAçš„æŠ€æœ¯ä¹Ÿå¯èƒ½è¢«æ‰©å±•åˆ°å…¶ä»–å¤šæ¨¡æ€ä»»åŠ¡ä¸­ï¼Œè¿›ä¸€æ­¥æå‡æ™ºèƒ½ä½“çš„ç†è§£å’Œäº¤äº’èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision-and-Language Navigation (VLN) tasks agents with locating specific objects in unseen environments using natural language instructions and visual cues. Many existing VLN approaches typically follow an 'observe-and-reason' schema, that is, agents observe the environment and decide on the next action to take based on the visual observations of their surroundings. They often face challenges in long-horizon scenarios due to limitations in immediate observation and vision-language modality gaps. To overcome this, we present VISTA, a novel framework that employs an 'imagine-and-align' navigation strategy. Specifically, we leverage the generative prior of pre-trained diffusion models for dynamic visual imagination conditioned on both local observations and high-level language instructions. A Perceptual Alignment Filter module then grounds these goal imaginations against current observations, guiding an interpretable and structured reasoning process for action selection. Experiments show that VISTA sets new state-of-the-art results on Room-to-Room (R2R) and RoboTHOR benchmarks, e.g.,+3.6% increase in Success Rate on R2R. Extensive ablation analysis underscores the value of integrating forward-looking imagination, perceptual alignment, and structured reasoning for robust navigation in long-horizon environments.

