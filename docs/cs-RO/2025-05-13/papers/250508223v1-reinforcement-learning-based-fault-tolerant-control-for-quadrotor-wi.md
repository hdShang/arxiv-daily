---
layout: default
title: Reinforcement Learning-based Fault-Tolerant Control for Quadrotor with Online Transformer Adaptation
---

# Reinforcement Learning-based Fault-Tolerant Control for Quadrotor with Online Transformer Adaptation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.08223" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.08223v1</a>
  <a href="https://arxiv.org/pdf/2505.08223.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.08223v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.08223v1', 'Reinforcement Learning-based Fault-Tolerant Control for Quadrotor with Online Transformer Adaptation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Dohyun Kim, Jayden Dongwoo Lee, Hyochoong Bang, Jungho Bae

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-13

**å¤‡æ³¨**: Accpted at the 2025 IEEE International Conference on Robotics & Automation (ICRA) Workshop: Robots in the Wild

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå¼ºåŒ–å­¦ä¹ çš„å®¹é”™æ§åˆ¶æ¡†æ¶ä»¥åº”å¯¹å››æ—‹ç¿¼æ•…éšœé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `å®¹é”™æ§åˆ¶` `å››æ—‹ç¿¼` `å˜æ¢å™¨` `åŠ¨æ€é€‚åº”` `æœºå™¨äººæŠ€æœ¯` `æ•…éšœç®¡ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å®¹é”™æ§åˆ¶æ–¹æ³•å¾€å¾€ä¾èµ–äºå¤šæ—‹ç¿¼çš„å…ˆéªŒæ¨¡å‹ï¼Œéš¾ä»¥é€‚åº”æ–°çš„é…ç½®ï¼Œé™åˆ¶äº†å…¶åº”ç”¨èŒƒå›´ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ··åˆå¼ºåŒ–å­¦ä¹ çš„å®¹é”™æ§åˆ¶æ¡†æ¶ï¼Œç»“åˆäº†å˜æ¢å™¨çš„åœ¨çº¿é€‚åº”èƒ½åŠ›ï¼Œèƒ½å¤Ÿå®æ—¶é€‚åº”æœªè§çš„ç³»ç»Ÿæ¨¡å‹ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨æ‰§è¡Œå™¨æ•…éšœæƒ…å†µä¸‹å–å¾—äº†95%çš„æˆåŠŸç‡ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤šæ—‹ç¿¼æ§åˆ¶ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ—‹ç¿¼åœ¨å„ç±»æœºå™¨äººåº”ç”¨ä¸­æ‰®æ¼”é‡è¦è§’è‰²ï¼Œä½†å¯¹æ‰§è¡Œå™¨æ•…éšœé«˜åº¦æ•æ„Ÿï¼Œå¯¼è‡´å¿«é€Ÿä¸ç¨³å®šå’Œä»»åŠ¡å¯é æ€§ä¸‹é™ã€‚å°½ç®¡å·²æœ‰å¤šç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„å®¹é”™æ§åˆ¶ç­–ç•¥è¢«å¹¿æ³›ç ”ç©¶ï¼Œä½†å¤§å¤šæ•°æ–¹æ³•éœ€è¦å…ˆéªŒçš„å¤šæ—‹ç¿¼æ¨¡å‹çŸ¥è¯†æˆ–éš¾ä»¥é€‚åº”æ–°é…ç½®ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ··åˆå¼ºåŒ–å­¦ä¹ å®¹é”™æ§åˆ¶æ¡†æ¶ï¼Œé›†æˆäº†åŸºäºå˜æ¢å™¨çš„åœ¨çº¿é€‚åº”æ¨¡å—ã€‚è¯¥æ¡†æ¶åˆ©ç”¨å˜æ¢å™¨æ¶æ„å®æ—¶æ¨æ–­æ½œåœ¨è¡¨ç¤ºï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨ä¸é‡æ–°è®­ç»ƒçš„æƒ…å†µä¸‹é€‚åº”ä»¥å‰æœªè§çš„ç³»ç»Ÿæ¨¡å‹ã€‚åœ¨PyBulletä»¿çœŸä¸­è¯„ä¼°è¯¥æ–¹æ³•ï¼Œåœ¨æ‰§è¡Œå™¨æ•…éšœä¸‹å®ç°äº†95%çš„æˆåŠŸç‡å’Œ0.129ç±³çš„ä½ç½®ä¿¡æ¯å‡æ–¹æ ¹è¯¯å·®ï¼ˆRMSEï¼‰ï¼Œä¼˜äºç°æœ‰é€‚åº”æ–¹æ³•çš„86%æˆåŠŸç‡å’Œ0.153ç±³çš„RMSEã€‚è¿™äº›ç»“æœå±•ç¤ºäº†è¯¥æ¡†æ¶åœ¨åŠ¨æ€å’Œä¸ç¡®å®šç¯å¢ƒä¸­å¢å¼ºå¤šæ—‹ç¿¼é€‚åº”æ€§å’Œå¯é æ€§çš„æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ—‹ç¿¼åœ¨æ‰§è¡Œå™¨æ•…éšœæƒ…å†µä¸‹çš„æ§åˆ¶é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦å…ˆéªŒæ¨¡å‹çŸ¥è¯†ï¼Œéš¾ä»¥é€‚åº”æ–°çš„åŠ¨æ€ç¯å¢ƒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºçš„æ¡†æ¶ç»“åˆäº†å¼ºåŒ–å­¦ä¹ ä¸å˜æ¢å™¨æ¶æ„ï¼Œèƒ½å¤Ÿå®æ—¶æ¨æ–­æ½œåœ¨çŠ¶æ€è¡¨ç¤ºï¼Œä»è€Œåœ¨ä¸é‡æ–°è®­ç»ƒçš„æƒ…å†µä¸‹é€‚åº”æ–°çš„ç³»ç»Ÿæ¨¡å‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¼ºåŒ–å­¦ä¹ æ¨¡å—å’Œå˜æ¢å™¨é€‚åº”æ¨¡å—ã€‚å¼ºåŒ–å­¦ä¹ æ¨¡å—è´Ÿè´£å­¦ä¹ æ§åˆ¶ç­–ç•¥ï¼Œè€Œå˜æ¢å™¨æ¨¡å—åˆ™å®æ—¶å¤„ç†è¾“å…¥æ•°æ®ï¼Œç”Ÿæˆé€‚åº”æ€§è¡¨ç¤ºã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†å˜æ¢å™¨ä¸å¼ºåŒ–å­¦ä¹ ç»“åˆï¼Œå…è®¸ç³»ç»Ÿåœ¨é¢å¯¹æœªè§çš„åŠ¨æ€æ—¶è¿›è¡Œå¿«é€Ÿé€‚åº”ï¼Œè¿™ä¸€è®¾è®¡æ˜¾è‘—æé«˜äº†å®¹é”™èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œç»“æ„ä¸Šï¼Œé‡‡ç”¨äº†å˜æ¢å™¨çš„è‡ªæ³¨æ„åŠ›æœºåˆ¶ä»¥æ•æ‰çŠ¶æ€ä¹‹é—´çš„å¤æ‚å…³ç³»ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸Šåˆ™è€ƒè™‘äº†æ§åˆ¶ç²¾åº¦ä¸é€‚åº”æ€§çš„å¹³è¡¡ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œè®­ç»ƒç»†èŠ‚åœ¨å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„æ–¹æ³•åœ¨æ‰§è¡Œå™¨æ•…éšœæƒ…å†µä¸‹å®ç°äº†95%çš„æˆåŠŸç‡ï¼Œä½ç½®ä¿¡æ¯å‡æ–¹æ ¹è¯¯å·®ä¸º0.129ç±³ï¼Œç›¸è¾ƒäºç°æœ‰æ–¹æ³•çš„86%æˆåŠŸç‡å’Œ0.153ç±³çš„RMSEï¼Œæå‡æ˜¾è‘—ï¼Œå±•ç¤ºäº†å…¶åœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„æœ‰æ•ˆæ€§å’Œé²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ— äººæœºå·¡æ£€ã€ç¾å®³æ•‘æ´å’Œç‰©æµè¿è¾“ç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿåœ¨æ‰§è¡Œå™¨æ•…éšœæ—¶ä¿æŒç¨³å®šæ€§å’Œä»»åŠ¡æ‰§è¡Œèƒ½åŠ›ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶æœ‰æœ›åœ¨æ›´å¹¿æ³›çš„åŠ¨æ€ç¯å¢ƒä¸­åº”ç”¨ï¼Œæå‡å¤šæ—‹ç¿¼çš„å¯é æ€§å’Œé€‚åº”æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multirotors play a significant role in diverse field robotics applications but remain highly susceptible to actuator failures, leading to rapid instability and compromised mission reliability. While various fault-tolerant control (FTC) strategies using reinforcement learning (RL) have been widely explored, most previous approaches require prior knowledge of the multirotor model or struggle to adapt to new configurations. To address these limitations, we propose a novel hybrid RL-based FTC framework integrated with a transformer-based online adaptation module. Our framework leverages a transformer architecture to infer latent representations in real time, enabling adaptation to previously unseen system models without retraining. We evaluate our method in a PyBullet simulation under loss-of-effectiveness actuator faults, achieving a 95% success rate and a positional root mean square error (RMSE) of 0.129 m, outperforming existing adaptation methods with 86% success and an RMSE of 0.153 m. Further evaluations on quadrotors with varying configurations confirm the robustness of our framework across untrained dynamics. These results demonstrate the potential of our framework to enhance the adaptability and reliability of multirotors, enabling efficient fault management in dynamic and uncertain environments. Website is available at http://00dhkim.me/paper/rl-ftc

