---
layout: default
title: "NavDP: Learning Sim-to-Real Navigation Diffusion Policy with Privileged Information Guidance"
---

# NavDP: Learning Sim-to-Real Navigation Diffusion Policy with Privileged Information Guidance

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.08712" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.08712v2</a>
  <a href="https://arxiv.org/pdf/2505.08712.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.08712v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.08712v2', 'NavDP: Learning Sim-to-Real Navigation Diffusion Policy with Privileged Information Guidance')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wenzhe Cai, Jiaqi Peng, Yuqiang Yang, Yujian Zhang, Meng Wei, Hanqing Wang, Yilun Chen, Tai Wang, Jiangmiao Pang

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-05-13 (æ›´æ–°: 2025-05-15)

**å¤‡æ³¨**: Project Page: https://wzcai99.github.io/navigation-diffusion-policy.github.io/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºNavDPä»¥è§£å†³åŠ¨æ€å¼€æ”¾ä¸–ç•Œå¯¼èˆªé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¯¼èˆªç­–ç•¥` `æ‰©æ•£æ¨¡å‹` `æœºå™¨äººå­¦ä¹ ` `æ¨¡æ‹Ÿåˆ°çœŸå®` `è½¨è¿¹ç”Ÿæˆ` `æ‰¹è¯„å­¦ä¹ ` `è‡ªä¸»å¯¼èˆª`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¯¼èˆªæ–¹æ³•ä¾èµ–äºç²¾ç¡®å®šä½å’Œæ˜‚è´µçš„çœŸå®ç¤ºä¾‹ï¼Œéš¾ä»¥é€‚åº”åŠ¨æ€å¼€æ”¾ä¸–ç•Œç¯å¢ƒã€‚
2. NavDPæ¡†æ¶é€šè¿‡æ‰©æ•£è½¨è¿¹ç”Ÿæˆå’Œæ‰¹è¯„å‡½æ•°é€‰æ‹©ï¼Œåˆ©ç”¨æ¨¡æ‹Ÿä¸­çš„å…¨å±€ä¿¡æ¯è¿›è¡Œè®­ç»ƒï¼Œå…·å¤‡é›¶-shotè¿ç§»èƒ½åŠ›ã€‚
3. NavDPåœ¨å¤šç§æœºå™¨äººå¹³å°ä¸Šè¡¨ç°å‡ºè‰²ï¼ŒæˆåŠŸç‡æé«˜30%ï¼Œå¹¶åœ¨ä¸åŒç¯å¢ƒä¸­å±•ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨åŠ¨æ€å¼€æ”¾ä¸–ç•Œç¯å¢ƒä¸­å­¦ä¹ å¯¼èˆªæ˜¯æœºå™¨äººé¢ä¸´çš„é‡è¦æŒ‘æˆ˜ã€‚å¤§å¤šæ•°ç°æœ‰æ–¹æ³•ä¾èµ–äºç²¾ç¡®çš„å®šä½å’Œæ˜ å°„ï¼Œæˆ–ä»æ˜‚è´µçš„çœŸå®ä¸–ç•Œç¤ºä¾‹ä¸­å­¦ä¹ ã€‚æœ¬æ–‡æå‡ºäº†å¯¼èˆªæ‰©æ•£ç­–ç•¥ï¼ˆNavDPï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªå®Œå…¨åœ¨æ¨¡æ‹Ÿä¸­è®­ç»ƒçš„ç«¯åˆ°ç«¯æ¡†æ¶ï¼Œèƒ½å¤Ÿé›¶-shotè¿ç§»åˆ°ä¸åŒçš„çœŸå®ç¯å¢ƒä¸­ã€‚NavDPçš„ç½‘ç»œæ ¸å¿ƒæ˜¯åŸºäºæ‰©æ•£çš„è½¨è¿¹ç”Ÿæˆä¸è½¨è¿¹é€‰æ‹©çš„æ‰¹è¯„å‡½æ•°çš„ç»“åˆï¼Œæ¡ä»¶ä»…åŸºäºä»å…±äº«ç­–ç•¥å˜æ¢å™¨ç¼–ç çš„å±€éƒ¨è§‚å¯Ÿä»¤ç‰Œã€‚é€šè¿‡åˆ©ç”¨æ¨¡æ‹Ÿä¸­çš„å…¨å±€ç¯å¢ƒç‰¹æƒä¿¡æ¯ï¼Œæˆ‘ä»¬ç”Ÿæˆé«˜è´¨é‡çš„æ¼”ç¤ºä»¥è®­ç»ƒæ‰©æ•£ç­–ç•¥ï¼Œå¹¶ä½¿ç”¨å¯¹æ¯”è´Ÿæ ·æœ¬æ¥åˆ¶å®šæ‰¹è¯„å€¼å‡½æ•°ç›®æ ‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒNavDPåœ¨å¤šç§å®¤å†…å¤–ç¯å¢ƒä¸­çš„å››è¶³ã€è½®å¼å’Œç±»äººæœºå™¨äººä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½å’Œå“è¶Šçš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æœºå™¨äººåœ¨åŠ¨æ€å¼€æ”¾ä¸–ç•Œä¸­å¯¼èˆªçš„æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–äºç²¾ç¡®çš„å®šä½å’Œæ˜‚è´µçš„çœŸå®ä¸–ç•Œç¤ºä¾‹ï¼Œé™åˆ¶äº†å…¶é€‚åº”æ€§å’Œæ•ˆç‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šNavDPé€šè¿‡åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­è®­ç»ƒï¼Œç»“åˆæ‰©æ•£è½¨è¿¹ç”Ÿæˆå’Œæ‰¹è¯„å‡½æ•°é€‰æ‹©ï¼Œåˆ©ç”¨å…¨å±€ç¯å¢ƒä¿¡æ¯ç”Ÿæˆé«˜è´¨é‡çš„æ¼”ç¤ºï¼Œä»è€Œå®ç°é›¶-shotè¿ç§»åˆ°çœŸå®ç¯å¢ƒã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šNavDPçš„æ•´ä½“æ¶æ„åŒ…æ‹¬è½¨è¿¹ç”Ÿæˆæ¨¡å—å’Œæ‰¹è¯„æ¨¡å—ï¼Œå‰è€…è´Ÿè´£ç”Ÿæˆå€™é€‰è½¨è¿¹ï¼Œåè€…åˆ™å¯¹è½¨è¿¹è¿›è¡Œè¯„ä¼°å’Œé€‰æ‹©ï¼Œæ•´ä¸ªè¿‡ç¨‹ä¾èµ–äºå…±äº«çš„ç­–ç•¥å˜æ¢å™¨å¯¹å±€éƒ¨è§‚å¯Ÿçš„ç¼–ç ã€‚

**å…³é”®åˆ›æ–°**ï¼šNavDPçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå°†æ‰©æ•£æ¨¡å‹ä¸æ‰¹è¯„å­¦ä¹ ç›¸ç»“åˆï¼Œåˆ©ç”¨æ¨¡æ‹Ÿä¸­çš„å…¨å±€ä¿¡æ¯ç”Ÿæˆå¤§é‡é«˜è´¨é‡è½¨è¿¹ï¼Œæ˜¾è‘—æé«˜äº†è®­ç»ƒæ•ˆç‡å’Œæ•ˆæœã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œä½¿ç”¨å¯¹æ¯”è´Ÿæ ·æœ¬æ¥åˆ¶å®šæ‰¹è¯„å€¼å‡½æ•°ç›®æ ‡ï¼Œç¡®ä¿ç”Ÿæˆçš„è½¨è¿¹å…·æœ‰è¾ƒé«˜çš„è´¨é‡ã€‚æ­¤å¤–ï¼Œæ¼”ç¤ºç”Ÿæˆæ•ˆç‡è¾¾åˆ°æ¯å¤©2500æ¡è½¨è¿¹/GPUï¼Œè¿œè¶…çœŸå®æ•°æ®æ”¶é›†çš„æ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒNavDPåœ¨å¤šç§æœºå™¨äººå¹³å°ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒæˆåŠŸç‡æé«˜äº†30%ã€‚åœ¨1244ä¸ªåœºæ™¯ä¸­ç”Ÿæˆäº†363.2å…¬é‡Œçš„è½¨è¿¹æ•°æ®ï¼Œå±•ç¤ºäº†å…¶å“è¶Šçš„æ³›åŒ–èƒ½åŠ›å’Œé«˜æ•ˆçš„æ•°æ®ç”Ÿæˆèƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªä¸»æœºå™¨äººå¯¼èˆªã€æ™ºèƒ½äº¤é€šç³»ç»Ÿå’Œæ— äººæœºé£è¡Œç­‰ã€‚é€šè¿‡åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­é«˜æ•ˆè®­ç»ƒï¼ŒNavDPèƒ½å¤Ÿå¿«é€Ÿé€‚åº”ä¸åŒçš„çœŸå®ç¯å¢ƒï¼Œé™ä½äº†æœºå™¨äººéƒ¨ç½²çš„æˆæœ¬å’Œæ—¶é—´ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Learning navigation in dynamic open-world environments is an important yet challenging skill for robots. Most previous methods rely on precise localization and mapping or learn from expensive real-world demonstrations. In this paper, we propose the Navigation Diffusion Policy (NavDP), an end-to-end framework trained solely in simulation and can zero-shot transfer to different embodiments in diverse real-world environments. The key ingredient of NavDP's network is the combination of diffusion-based trajectory generation and a critic function for trajectory selection, which are conditioned on only local observation tokens encoded from a shared policy transformer. Given the privileged information of the global environment in simulation, we scale up the demonstrations of good quality to train the diffusion policy and formulate the critic value function targets with contrastive negative samples. Our demonstration generation approach achieves about 2,500 trajectories/GPU per day, 20$\times$ more efficient than real-world data collection, and results in a large-scale navigation dataset with 363.2km trajectories across 1244 scenes. Trained with this simulation dataset, NavDP achieves state-of-the-art performance and consistently outstanding generalization capability on quadruped, wheeled, and humanoid robots in diverse indoor and outdoor environments. In addition, we present a preliminary attempt at using Gaussian Splatting to make in-domain real-to-sim fine-tuning to further bridge the sim-to-real gap. Experiments show that adding such real-to-sim data can improve the success rate by 30\% without hurting its generalization capability.

