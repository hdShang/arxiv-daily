---
layout: default
title: Scaling Multi Agent Reinforcement Learning for Underwater Acoustic Tracking via Autonomous Vehicles
---

# Scaling Multi Agent Reinforcement Learning for Underwater Acoustic Tracking via Autonomous Vehicles

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.08222" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.08222v2</a>
  <a href="https://arxiv.org/pdf/2505.08222.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.08222v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.08222v2', 'Scaling Multi Agent Reinforcement Learning for Underwater Acoustic Tracking via Autonomous Vehicles')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Matteo Gallici, Ivan Masmitja, Mario Mart√≠n

**ÂàÜÁ±ª**: cs.RO, cs.AI, cs.DC, cs.PF

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-13 (Êõ¥Êñ∞: 2025-10-17)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Ëø≠‰ª£Ëí∏È¶èÊñπÊ≥ï‰ª•Ëß£ÂÜ≥Ê∞¥‰∏ãÂ£∞Â≠¶Ë∑üË∏™‰∏≠ÁöÑÂ§öÊô∫ËÉΩ‰ΩìÂº∫ÂåñÂ≠¶‰π†ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊô∫ËÉΩ‰ΩìÂº∫ÂåñÂ≠¶‰π†` `Ê∞¥‰∏ãÂ£∞Â≠¶Ë∑üË∏™` `Ëá™‰∏ªËΩ¶ËæÜ` `Ëí∏È¶èËÆ≠ÁªÉ` `GPUÂä†ÈÄü` `TransformerÊû∂ÊûÑ` `Ê†∑Êú¨ÊïàÁéá` `Êµ∑Ê¥ã‰ªªÂä°`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÂ§öÊô∫ËÉΩ‰ΩìÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÂú®Â§ÑÁêÜÂø´ÈÄü„ÄÅ‰∏çÁ°ÆÂÆöËøêÂä®ÁöÑÂ§öÁõÆÊ†áË∑üË∏™Êó∂Èù¢‰∏¥ÊòæËëóÁöÑËÆ°ÁÆóÊåëÊàòÔºåÊ†∑Êú¨ÊïàÁéá‰Ωé‰∏ã„ÄÇ
2. Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçËø≠‰ª£Ëí∏È¶èÊñπÊ≥ïÔºåÂ∞ÜÈ´ò‰øùÁúüÊ®°ÊãüËΩ¨ÁßªÂà∞ÁÆÄÂåñÁöÑGPUÂä†ÈÄüÁéØÂ¢É‰∏≠ÔºåÊòæËëóÊèêÈ´òËÆ≠ÁªÉÈÄüÂ∫¶ÂíåÊïàÁéá„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊâÄÊèêÊñπÊ≥ïÂú®Gazebo‰∏≠ÂÆûÁé∞‰∫ÜÈ´òËææ30,000ÂÄçÁöÑÈÄüÂ∫¶ÊèêÂçáÔºåË∑üË∏™ËØØÂ∑Æ‰øùÊåÅÂú®5Á±≥‰ª•‰∏ãÔºåË°®Áé∞Âá∫Ëâ≤„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Ëá™‰∏ªËΩ¶ËæÜÔºàAVÔºâ‰∏∫Ê∞¥‰∏ãË∑üË∏™Á≠âÁßëÂ≠¶‰ªªÂä°Êèê‰æõ‰∫Ü‰∏ÄÁßçÁªèÊµéÊúâÊïàÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇËøëÂπ¥Êù•ÔºåÂº∫ÂåñÂ≠¶‰π†ÔºàRLÔºâÂ∑≤Êàê‰∏∫ÊéßÂà∂AVÂú®Â§çÊùÇÊµ∑Ê¥ãÁéØÂ¢É‰∏≠ÁöÑÂº∫Â§ßÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåÂ∞ÜËøô‰∫õÊäÄÊúØÊâ©Â±ïÂà∞Ëà∞Èòü‰ª•ÂÆûÁé∞Â§öÁõÆÊ†áË∑üË∏™ÊàñÂø´ÈÄü„ÄÅ‰∏çÁ°ÆÂÆöËøêÂä®ÁöÑÁõÆÊ†áÈù¢‰∏¥ÈáçÂ§ßËÆ°ÁÆóÊåëÊàò„ÄÇÂ§öÊô∫ËÉΩ‰ΩìÂº∫ÂåñÂ≠¶‰π†ÔºàMARLÔºâÈÄöÂ∏∏Ê†∑Êú¨ÊïàÁéá‰ΩéÔºåËÄåÈ´ò‰øùÁúüÊ®°ÊãüÂô®Â¶ÇGazeboÁöÑLRAUVÂú®ÂçïÊú∫Âô®‰∫∫Ê®°Êãü‰∏≠Êèê‰æõ100ÂÄçÁöÑÂÆûÊó∂ÈÄüÂ∫¶ÊèêÂçáÔºå‰ΩÜÂú®Â§öËΩ¶ËæÜÂú∫ÊôØ‰∏≠Âπ∂Êú™ÊòæËëóÂä†ÈÄüÔºåÂØºËá¥MARLËÆ≠ÁªÉ‰∏çÂàáÂÆûÈôÖ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈôêÂà∂ÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçËø≠‰ª£Ëí∏È¶èÊñπÊ≥ïÔºåÂ∞ÜÈ´ò‰øùÁúüÊ®°ÊãüËΩ¨ÁßªÂà∞ÁÆÄÂåñÁöÑGPUÂä†ÈÄüÁéØÂ¢É‰∏≠ÔºåÂêåÊó∂‰øùÊåÅÈ´òÂ±ÇÊ¨°Âä®ÊÄÅ„ÄÇËøôÁßçÊñπÊ≥ïÈÄöËøáÂπ∂Ë°åÂåñÂÆûÁé∞‰∫ÜÈ´òËææ30,000ÂÄçÁöÑÈÄüÂ∫¶ÊèêÂçáÔºå‰ΩøÂæóÈÄöËøáÁ´ØÂà∞Á´ØGPUÂä†ÈÄüËøõË°åÈ´òÊïàËÆ≠ÁªÉÊàê‰∏∫ÂèØËÉΩ„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÂü∫‰∫éTransformerÁöÑÊû∂ÊûÑÔºàTransfMAPPOÔºâÔºåËÉΩÂ§üÂ≠¶‰π†‰∏éÊô∫ËÉΩ‰ΩìÂíåÁõÆÊ†áÊï∞ÈáèÊó†ÂÖ≥ÁöÑÂ§öÊô∫ËÉΩ‰ΩìÁ≠ñÁï•ÔºåÊòæËëóÊèêÈ´òÊ†∑Êú¨ÊïàÁéá„ÄÇÁªèËøáÂú®GPU‰∏äËøõË°åÁöÑÂ§ßËßÑÊ®°ËØæÁ®ãÂ≠¶‰π†ÔºåÊàë‰ª¨Âú®Gazebo‰∏≠ËøõË°å‰∫ÜÂπøÊ≥õËØÑ‰º∞ÔºåËØÅÊòéËØ•ÊñπÊ≥ïÂú®Â§ö‰∏™Âø´ÈÄüÁßªÂä®ÁõÆÊ†áÁöÑÊÉÖÂÜµ‰∏ãÔºåË∑üË∏™ËØØÂ∑Æ‰øùÊåÅÂú®5Á±≥‰ª•‰∏ãÔºåÊåÅÁª≠Êó∂Èó¥ËæÉÈïø„ÄÇÊ≠§È°πÂ∑•‰ΩúÂº•Âêà‰∫ÜÂ§ßËßÑÊ®°MARLËÆ≠ÁªÉ‰∏éÈ´ò‰øùÁúüÈÉ®ÁΩ≤‰πãÈó¥ÁöÑÂ∑ÆË∑ùÔºå‰∏∫Áé∞ÂÆûÊµ∑Ê¥ã‰ªªÂä°‰∏≠ÁöÑËá™‰∏ªËà∞ÈòüÊéßÂà∂Êèê‰æõ‰∫ÜÂèØÊâ©Â±ïÊ°ÜÊû∂„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Â§öÊô∫ËÉΩ‰ΩìÂº∫ÂåñÂ≠¶‰π†Âú®Ê∞¥‰∏ãÂ£∞Â≠¶Ë∑üË∏™‰∏≠ÁöÑËÆ°ÁÆóÊïàÁéáÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®Â§öËΩ¶ËæÜÂú∫ÊôØ‰∏≠ËÆ≠ÁªÉÊïàÁéá‰ΩéÔºåÈöæ‰ª•Êª°Ë∂≥ÂÆûÈôÖÂ∫îÁî®ÈúÄÊ±Ç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊèêÂá∫‰∫Ü‰∏ÄÁßçËø≠‰ª£Ëí∏È¶èÊñπÊ≥ïÔºåÂ∞ÜÈ´ò‰øùÁúüÊ®°ÊãüËΩ¨Âåñ‰∏∫ÁÆÄÂåñÁöÑGPUÂä†ÈÄüÁéØÂ¢ÉÔºå‰ª•‰øùÊåÅÂä®ÊÄÅÁâπÊÄßÂπ∂ÊèêÈ´òËÆ≠ÁªÉÈÄüÂ∫¶„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨È´ò‰øùÁúüÊ®°ÊãüÂô®ÁöÑ‰ΩøÁî®„ÄÅËí∏È¶èËøáÁ®ãÁöÑËÆæËÆ°‰ª•ÂèäÂü∫‰∫éTransformerÁöÑÂ§öÊô∫ËÉΩ‰ΩìÁ≠ñÁï•Â≠¶‰π†Ê®°Âùó„ÄÇÈÄöËøáÂπ∂Ë°åÂåñÂ§ÑÁêÜÔºåÊòæËëóÊèêÂçáËÆ≠ÁªÉÊïàÁéá„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞Âú®‰∫éÊèêÂá∫ÁöÑTransfMAPPOÊû∂ÊûÑÔºåËÉΩÂ§üÂ≠¶‰π†‰∏éÊô∫ËÉΩ‰ΩìÊï∞ÈáèÊó†ÂÖ≥ÁöÑÁ≠ñÁï•ÔºåÊòæËëóÊèêÈ´òÊ†∑Êú¨ÊïàÁéáÔºåËß£ÂÜ≥‰∫Ü‰º†ÁªüMARLÊñπÊ≥ïÁöÑÊ†∑Êú¨ÊïàÁéá‰Ωé‰∏ãÈóÆÈ¢ò„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°‰∏≠ÔºåÈááÁî®‰∫ÜGPUÂä†ÈÄüÁöÑÁÆÄÂåñÁéØÂ¢ÉÔºåËÆæÁΩÆ‰∫ÜÈÄÇÂΩìÁöÑÊçüÂ§±ÂáΩÊï∞‰ª•‰ºòÂåñÁ≠ñÁï•Â≠¶‰π†ÔºåÂêåÊó∂Á°Æ‰øùÈ´òÂ±ÇÊ¨°Âä®ÊÄÅÁöÑ‰øùÁïô„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåÊâÄÊèêÊñπÊ≥ïÂú®Gazebo‰∏≠ÂÆûÁé∞‰∫ÜÈ´òËææ30,000ÂÄçÁöÑÈÄüÂ∫¶ÊèêÂçáÔºåÁõ∏ËæÉ‰∫é‰º†ÁªüÊñπÊ≥ïÔºåË∑üË∏™ËØØÂ∑Æ‰øùÊåÅÂú®5Á±≥‰ª•‰∏ãÔºåË°®Áé∞Âá∫Ëâ≤ÔºåÂ∞§ÂÖ∂Âú®Â§ö‰∏™Âø´ÈÄüÁßªÂä®ÁõÆÊ†áÁöÑÊÉÖÂÜµ‰∏ãÔºåÂ±ïÁé∞‰∫ÜËâØÂ•ΩÁöÑÁ®≥ÂÆöÊÄßÂíåÂáÜÁ°ÆÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Ê∞¥‰∏ãÊé¢Êµã„ÄÅÊµ∑Ê¥ãÁßëÂ≠¶Á†îÁ©∂ÂèäÁéØÂ¢ÉÁõëÊµãÁ≠â„ÄÇÈÄöËøáÊèêÈ´òÂ§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÁöÑËÆ≠ÁªÉÊïàÁéáÔºåËÉΩÂ§üÂú®Â§çÊùÇÁöÑÊµ∑Ê¥ãÁéØÂ¢É‰∏≠ÂÆûÁé∞Êõ¥È´òÊïàÁöÑËá™‰∏ªÊéßÂà∂ÔºåÊé®Âä®Áõ∏ÂÖ≥È¢ÜÂüüÁöÑÊäÄÊúØËøõÊ≠•ÂíåÂÆûÈôÖÂ∫îÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Autonomous vehicles (AV) offer a cost-effective solution for scientific missions such as underwater tracking. Recently, reinforcement learning (RL) has emerged as a powerful method for controlling AVs in complex marine environments. However, scaling these techniques to a fleet--essential for multi-target tracking or targets with rapid, unpredictable motion--presents significant computational challenges. Multi-Agent Reinforcement Learning (MARL) is notoriously sample-inefficient, and while high-fidelity simulators like Gazebo's LRAUV provide 100x faster-than-real-time single-robot simulations, they offer no significant speedup for multi-vehicle scenarios, making MARL training impractical. To address these limitations, we propose an iterative distillation method that transfers high-fidelity simulations into a simplified, GPU-accelerated environment while preserving high-level dynamics. This approach achieves up to a 30,000x speedup over Gazebo through parallelization, enabling efficient training via end-to-end GPU acceleration. Additionally, we introduce a novel Transformer-based architecture (TransfMAPPO) that learns multi-agent policies invariant to the number of agents and targets, significantly improving sample efficiency. Following large-scale curriculum learning conducted entirely on GPU, we perform extensive evaluations in Gazebo, demonstrating that our method maintains tracking errors below 5 meters over extended durations, even in the presence of multiple fast-moving targets. This work bridges the gap between large-scale MARL training and high-fidelity deployment, providing a scalable framework for autonomous fleet control in real-world sea missions.

