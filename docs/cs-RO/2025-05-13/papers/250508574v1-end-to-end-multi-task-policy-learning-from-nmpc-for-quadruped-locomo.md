---
layout: default
title: End-to-End Multi-Task Policy Learning from NMPC for Quadruped Locomotion
---

# End-to-End Multi-Task Policy Learning from NMPC for Quadruped Locomotion

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.08574" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.08574v1</a>
  <a href="https://arxiv.org/pdf/2505.08574.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.08574v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.08574v1', 'End-to-End Multi-Task Policy Learning from NMPC for Quadruped Locomotion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Anudeep Sajja, Shahram Khorshidi, Sebastian Houben, Maren Bennewitz

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-05-13

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šä»»åŠ¡å­¦ä¹ æ¡†æ¶ä»¥è§£å†³å››è¶³æœºå™¨äººè¿åŠ¨æ§åˆ¶é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å››è¶³æœºå™¨äºº` `å¤šä»»åŠ¡å­¦ä¹ ` `éçº¿æ€§æ¨¡å‹é¢„æµ‹æ§åˆ¶` `è¿åŠ¨æ§åˆ¶` `å®æ—¶éƒ¨ç½²` `ç¥ç»ç½‘ç»œ` `é€‚åº”æ€§è¿åŠ¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å››è¶³æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„è¿åŠ¨æ§åˆ¶é¢ä¸´éçº¿æ€§åŠ¨åŠ›å­¦å’Œé«˜è®¡ç®—éœ€æ±‚çš„æŒ‘æˆ˜ï¼Œç°æœ‰NMPCæ–¹æ³•éš¾ä»¥å®æ—¶åº”ç”¨ã€‚
2. æå‡ºçš„å¤šä»»åŠ¡å­¦ä¹ æ¡†æ¶é€šè¿‡ä¸“å®¶ç¤ºèŒƒè®­ç»ƒç¥ç»ç½‘ç»œï¼Œç›´æ¥ä»ä¼ æ„Ÿå™¨è¾“å…¥é¢„æµ‹å¤šç§æ­¥æ€çš„åŠ¨ä½œï¼Œç®€åŒ–æ§åˆ¶æµç¨‹ã€‚
3. åœ¨Go1æœºå™¨äººä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿå‡†ç¡®å†ç°ä¸“å®¶è¡Œä¸ºï¼Œå®ç°å¹³æ»‘æ­¥æ€åˆ‡æ¢ï¼Œå¹¶åœ¨å¤šä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å››è¶³æœºå™¨äººåœ¨å¤æ‚ã€ä¸è§„åˆ™ç¯å¢ƒä¸­çš„è¡¨ç°ä¼˜äºè½®å¼æœºå™¨äººï¼Œä½†ç”±äºå…¶éçº¿æ€§åŠ¨åŠ›å­¦å’Œé«˜è‡ªç”±åº¦ï¼Œé€‚åº”æ€§è¿åŠ¨æ§åˆ¶ä»ç„¶é¢ä¸´æŒ‘æˆ˜ã€‚åŸºäºä¼˜åŒ–çš„æ§åˆ¶å™¨å¦‚éçº¿æ€§æ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼ˆNMPCï¼‰è™½ç„¶è¡¨ç°å‡ºè‰²ï¼Œä½†å¯¹å‡†ç¡®çŠ¶æ€ä¼°è®¡å’Œé«˜è®¡ç®—å¼€é”€çš„ä¾èµ–ä½¿å…¶åœ¨å®é™…åº”ç”¨ä¸­å›°éš¾é‡é‡ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§å¤šä»»åŠ¡å­¦ä¹ ï¼ˆMTLï¼‰æ¡†æ¶ï¼Œåˆ©ç”¨ä¸“å®¶NMPCç¤ºèŒƒè®­ç»ƒå•ä¸€ç¥ç»ç½‘ç»œï¼Œç›´æ¥ä»åŸå§‹æœ¬ä½“ä¼ æ„Ÿå™¨è¾“å…¥ä¸­é¢„æµ‹å¤šç§è¿åŠ¨è¡Œä¸ºçš„åŠ¨ä½œã€‚é€šè¿‡åœ¨å››è¶³æœºå™¨äººGo1ä¸Šè¿›è¡Œå¹¿æ³›è¯„ä¼°ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•èƒ½å¤Ÿå‡†ç¡®å†ç°ä¸“å®¶è¡Œä¸ºï¼Œå®ç°å¹³æ»‘çš„æ­¥æ€åˆ‡æ¢ï¼Œå¹¶ç®€åŒ–å®æ—¶éƒ¨ç½²çš„æ§åˆ¶æµç¨‹ã€‚æˆ‘ä»¬çš„MTLæ¶æ„åœ¨ç»Ÿä¸€ç­–ç•¥ä¸­å­¦ä¹ å¤šæ ·åŒ–æ­¥æ€ï¼Œåœ¨æ‰€æœ‰ä»»åŠ¡ä¸­å®ç°äº†é«˜RÂ²åˆ†æ•°çš„å…³èŠ‚ç›®æ ‡é¢„æµ‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å››è¶³æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­è¿åŠ¨æ§åˆ¶çš„æŒ‘æˆ˜ï¼Œç°æœ‰çš„NMPCæ–¹æ³•ä¾èµ–äºå‡†ç¡®çš„çŠ¶æ€ä¼°è®¡å’Œé«˜è®¡ç®—å¼€é”€ï¼Œé™åˆ¶äº†å…¶å®æ—¶åº”ç”¨çš„å¯è¡Œæ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¤šä»»åŠ¡å­¦ä¹ æ¡†æ¶ï¼Œåˆ©ç”¨ä¸“å®¶NMPCç¤ºèŒƒæ¥è®­ç»ƒä¸€ä¸ªå•ä¸€çš„ç¥ç»ç½‘ç»œï¼Œä½¿å…¶èƒ½å¤Ÿä»åŸå§‹ä¼ æ„Ÿå™¨è¾“å…¥ä¸­ç›´æ¥é¢„æµ‹å¤šç§è¿åŠ¨è¡Œä¸ºçš„åŠ¨ä½œï¼Œä»è€Œç®€åŒ–æ§åˆ¶æµç¨‹å¹¶æé«˜é€‚åº”æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é‡‡é›†ã€ä¸“å®¶ç¤ºèŒƒã€ç¥ç»ç½‘ç»œè®­ç»ƒå’Œå®æ—¶æ§åˆ¶å››ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆæ”¶é›†å››è¶³æœºå™¨äººåœ¨ä¸åŒæ­¥æ€ä¸‹çš„ä¼ æ„Ÿå™¨æ•°æ®ï¼Œç„¶ååˆ©ç”¨è¿™äº›æ•°æ®è®­ç»ƒç¥ç»ç½‘ç»œï¼Œæœ€ååœ¨å®é™…æœºå™¨äººä¸Šè¿›è¡Œå®æ—¶æ§åˆ¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†å¤šä»»åŠ¡å­¦ä¹ ä¸NMPCç»“åˆï¼Œé€šè¿‡å•ä¸€ç¥ç»ç½‘ç»œå®ç°å¤šç§æ­¥æ€çš„å­¦ä¹ ä¸åˆ‡æ¢ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—å¤æ‚åº¦å’Œå®æ—¶æ§åˆ¶çš„éš¾åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œç»“æ„ä¸Šï¼Œé‡‡ç”¨äº†é€‚åº”æ€§æŸå¤±å‡½æ•°ä»¥å¹³è¡¡ä¸åŒä»»åŠ¡çš„å­¦ä¹ æ•ˆæœï¼Œå¹¶é€šè¿‡ä¼˜åŒ–è¶…å‚æ•°æ¥æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œç¡®ä¿åœ¨å¤šç§æ­¥æ€ä¸‹çš„é«˜æ•ˆè¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æå‡ºçš„å¤šä»»åŠ¡å­¦ä¹ æ¡†æ¶åœ¨Go1æœºå™¨äººä¸ŠæˆåŠŸå†ç°äº†ä¸“å®¶è¡Œä¸ºï¼Œæ­¥æ€åˆ‡æ¢å¹³æ»‘ï¼Œä¸”åœ¨æ‰€æœ‰ä»»åŠ¡ä¸­å®ç°äº†é«˜RÂ²åˆ†æ•°ï¼Œè¡¨æ˜æ¨¡å‹åœ¨å…³èŠ‚ç›®æ ‡é¢„æµ‹ä¸Šçš„å‡†ç¡®æ€§æ˜¾è‘—æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœåŠ¡æœºå™¨äººã€æ•‘æ´æœºå™¨äººä»¥åŠä»»ä½•éœ€è¦åœ¨å¤æ‚ç¯å¢ƒä¸­é«˜æ•ˆç§»åŠ¨çš„å››è¶³æœºå™¨äººã€‚é€šè¿‡ç®€åŒ–æ§åˆ¶æµç¨‹å’Œæé«˜é€‚åº”æ€§ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨å®é™…åº”ç”¨ä¸­æ˜¾è‘—æå‡å››è¶³æœºå™¨äººçš„æ€§èƒ½å’Œçµæ´»æ€§ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ›´å¤šè‡ªä¸»ç§»åŠ¨ç³»ç»Ÿçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Quadruped robots excel in traversing complex, unstructured environments where wheeled robots often fail. However, enabling efficient and adaptable locomotion remains challenging due to the quadrupeds' nonlinear dynamics, high degrees of freedom, and the computational demands of real-time control. Optimization-based controllers, such as Nonlinear Model Predictive Control (NMPC), have shown strong performance, but their reliance on accurate state estimation and high computational overhead makes deployment in real-world settings challenging. In this work, we present a Multi-Task Learning (MTL) framework in which expert NMPC demonstrations are used to train a single neural network to predict actions for multiple locomotion behaviors directly from raw proprioceptive sensor inputs. We evaluate our approach extensively on the quadruped robot Go1, both in simulation and on real hardware, demonstrating that it accurately reproduces expert behavior, allows smooth gait switching, and simplifies the control pipeline for real-time deployment. Our MTL architecture enables learning diverse gaits within a unified policy, achieving high $R^{2}$ scores for predicted joint targets across all tasks.

