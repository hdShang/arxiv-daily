---
layout: default
title: Learning Neural Observer-Predictor Models for Limb-level Sampling-based Locomotion Planning
---

# Learning Neural Observer-Predictor Models for Limb-level Sampling-based Locomotion Planning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.22789" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.22789v1</a>
  <a href="https://arxiv.org/pdf/2510.22789.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.22789v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.22789v1', 'Learning Neural Observer-Predictor Models for Limb-level Sampling-based Locomotion Planning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Abhijeet M. Kulkarni, Ioannis Poulakakis, Guoquan Huang

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-10-26

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå­¦ä¹ çš„ç¥ç»è§‚æµ‹å™¨-é¢„æµ‹å™¨æ¨¡å‹ï¼Œç”¨äºè…¿è¶³æœºå™¨äººåŸºäºé‡‡æ ·çš„è…¿éƒ¨çº§è¿åŠ¨è§„åˆ’ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `è…¿è¶³æœºå™¨äºº` `è¿åŠ¨è§„åˆ’` `ç¥ç»è§‚æµ‹å™¨` `é¢„æµ‹æ¨¡å‹` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è…¿è¶³æœºå™¨äººè¿åŠ¨è§„åˆ’æ–¹æ³•ä¾èµ–ç®€åŒ–æ¨¡å‹ï¼Œæ— æ³•å‡†ç¡®é¢„æµ‹å…¨èº«è¿åŠ¨ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚ç¯å¢ƒä¸­è¿›è¡Œè…¿éƒ¨çº§ç¢°æ’æ£€æµ‹æ—¶ã€‚
2. è®ºæ–‡æå‡ºä¸€ç§ç¥ç»è§‚æµ‹å™¨-é¢„æµ‹å™¨æ¡†æ¶ï¼Œåˆ©ç”¨ç¥ç»è§‚æµ‹å™¨æä¾›ç¨³å®šçš„çŠ¶æ€ä¼°è®¡ï¼Œå¹¶ä»¥æ­¤åˆå§‹åŒ–é«˜æ•ˆçš„é¢„æµ‹å™¨ã€‚
3. é€šè¿‡ç¡¬ä»¶å®éªŒï¼Œåœ¨Vision 60å››è¶³æœºå™¨äººä¸ŠéªŒè¯äº†è¯¥ç³»ç»Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­çš„è…¿éƒ¨æ„ŸçŸ¥è¿åŠ¨è§„åˆ’èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå­¦ä¹ çš„è§‚æµ‹å™¨-é¢„æµ‹å™¨æ¡†æ¶ï¼Œç”¨äºç²¾ç¡®é¢„æµ‹è…¿è¶³æœºå™¨äººçš„å…¨èº«è¿åŠ¨ï¼Œä»è€Œå®ç°å®‰å…¨è‡ªä¸»å¯¼èˆªï¼Œå¹¶æ”¯æŒåœ¨å¤æ‚ç¯å¢ƒä¸­è¿›è¡Œè…¿éƒ¨çº§åˆ«çš„ç¢°æ’æ£€æµ‹ã€‚ä¼ ç»Ÿçš„ç®€åŒ–è¿åŠ¨å­¦æ¨¡å‹éš¾ä»¥æ•æ‰æœºå™¨äººåŠå…¶åº•å±‚æ§åˆ¶å™¨çš„å¤æ‚é—­ç¯åŠ¨åŠ›å­¦ï¼Œé¢„æµ‹ç²¾åº¦å—é™ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæœ¬æ–‡è®¾è®¡äº†ä¸€ä¸ªç¥ç»è§‚æµ‹å™¨ï¼Œè¯¥è§‚æµ‹å™¨å…·æœ‰å¯è¯æ˜çš„ä¸€è‡´æœ€ç»ˆæœ‰ç•Œ(UUB)ä¿è¯ï¼Œèƒ½å¤Ÿä»å†å²æœ¬ä½“æ„Ÿå—æµ‹é‡ä¸­æä¾›å¯é çš„æ½œåœ¨çŠ¶æ€ä¼°è®¡ã€‚ç„¶åï¼Œåˆ©ç”¨è¿™ä¸ªç¨³å®šçš„ä¼°è®¡åˆå§‹åŒ–ä¸€ä¸ªè®¡ç®—é«˜æ•ˆçš„é¢„æµ‹å™¨ï¼Œè¯¥é¢„æµ‹å™¨ä¸“ä¸ºç°ä»£åŸºäºé‡‡æ ·çš„è§„åˆ’å™¨æ‰€éœ€çš„æ•°åƒæ¡æ½œåœ¨è½¨è¿¹çš„å¿«é€Ÿå¹¶è¡Œè¯„ä¼°è€Œè®¾è®¡ã€‚é€šè¿‡å°†ç¥ç»é¢„æµ‹å™¨é›†æˆåˆ°Vision 60å››è¶³æœºå™¨äººçš„MPPIè§„åˆ’å™¨ä¸­éªŒè¯äº†è¯¥ç³»ç»Ÿã€‚ç¡¬ä»¶å®éªŒæˆåŠŸå±•ç¤ºäº†åœ¨ç‹­çª„é€šé“å’Œå°å‹ç‰©ä½“ä¸Šçš„æœ‰æ•ˆã€è…¿éƒ¨æ„ŸçŸ¥è¿åŠ¨è§„åˆ’ï¼Œçªå‡ºäº†è¯¥ç³»ç»Ÿä¸ºåŠ¨æ€æœºå™¨äººå¹³å°ä¸Šçš„é«˜æ€§èƒ½ã€ç¢°æ’æ„ŸçŸ¥è§„åˆ’æä¾›å¼ºå¤§åŸºç¡€çš„èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„è…¿è¶³æœºå™¨äººè¿åŠ¨è§„åˆ’æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹å¤æ‚ç¯å¢ƒä¸‹çš„å…¨èº«è¿åŠ¨è§„åˆ’ï¼Œé¢ä¸´ç€ç²¾ç¡®é¢„æµ‹æœºå™¨äººè¿åŠ¨è½¨è¿¹çš„æŒ‘æˆ˜ã€‚ä¼ ç»Ÿçš„åŸºäºç®€åŒ–è¿åŠ¨å­¦æ¨¡å‹çš„æ–¹æ³•æ— æ³•å……åˆ†æ•æ‰æœºå™¨äººåŠå…¶åº•å±‚æ§åˆ¶å™¨çš„å¤æ‚é—­ç¯åŠ¨åŠ›å­¦ç‰¹æ€§ï¼Œå¯¼è‡´é¢„æµ‹ç²¾åº¦ä¸è¶³ï¼Œéš¾ä»¥æ”¯æŒè…¿éƒ¨çº§åˆ«çš„ç¢°æ’æ£€æµ‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å­¦ä¹ çš„æ–¹æ³•ï¼Œæ„å»ºä¸€ä¸ªç¥ç»è§‚æµ‹å™¨-é¢„æµ‹å™¨æ¡†æ¶ï¼Œä»è€Œæ›´å‡†ç¡®åœ°é¢„æµ‹æœºå™¨äººçš„è¿åŠ¨è½¨è¿¹ã€‚è¯¥æ¡†æ¶é¦–å…ˆä½¿ç”¨ç¥ç»è§‚æµ‹å™¨ä»å†å²æœ¬ä½“æ„Ÿå—æ•°æ®ä¸­ä¼°è®¡æœºå™¨äººçš„çŠ¶æ€ï¼Œç„¶ååˆ©ç”¨è¯¥çŠ¶æ€åˆå§‹åŒ–ä¸€ä¸ªé¢„æµ‹å™¨ï¼Œç”¨äºé¢„æµ‹æœªæ¥çš„è¿åŠ¨è½¨è¿¹ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨å…‹æœä¼ ç»Ÿæ–¹æ³•å¯¹ç®€åŒ–æ¨¡å‹çš„ä¾èµ–ï¼Œå¹¶å……åˆ†åˆ©ç”¨æ•°æ®é©±åŠ¨çš„ä¼˜åŠ¿ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šç¥ç»è§‚æµ‹å™¨å’Œé¢„æµ‹å™¨ã€‚ç¥ç»è§‚æµ‹å™¨è´Ÿè´£ä»å†å²æœ¬ä½“æ„Ÿå—æµ‹é‡æ•°æ®ä¸­ä¼°è®¡æœºå™¨äººçš„æ½œåœ¨çŠ¶æ€ï¼Œå¹¶æä¾›ä¸€è‡´æœ€ç»ˆæœ‰ç•Œ(UUB)ä¿è¯ï¼Œç¡®ä¿çŠ¶æ€ä¼°è®¡çš„ç¨³å®šæ€§ã€‚é¢„æµ‹å™¨åˆ™åˆ©ç”¨ç¥ç»è§‚æµ‹å™¨æä¾›çš„çŠ¶æ€ä¼°è®¡ä½œä¸ºåˆå§‹æ¡ä»¶ï¼Œé¢„æµ‹æœºå™¨äººçš„æœªæ¥è¿åŠ¨è½¨è¿¹ã€‚æ•´ä¸ªæ¡†æ¶æ—¨åœ¨å®ç°å¿«é€Ÿã€å¹¶è¡Œåœ°è¯„ä¼°å¤§é‡æ½œåœ¨è½¨è¿¹ï¼Œä»¥æ»¡è¶³åŸºäºé‡‡æ ·çš„è§„åˆ’å™¨çš„éœ€æ±‚ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†ç¥ç»è§‚æµ‹å™¨ä¸é¢„æµ‹å™¨ç›¸ç»“åˆï¼Œæ„å»ºäº†ä¸€ä¸ªå®Œæ•´çš„è¿åŠ¨é¢„æµ‹æ¡†æ¶ã€‚ç¥ç»è§‚æµ‹å™¨çš„UUBä¿è¯ç¡®ä¿äº†çŠ¶æ€ä¼°è®¡çš„å¯é æ€§ï¼Œè€Œé¢„æµ‹å™¨çš„è®¡ç®—æ•ˆç‡åˆ™ä½¿å…¶èƒ½å¤Ÿå¿«é€Ÿè¯„ä¼°å¤§é‡è½¨è¿¹ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿç›´æ¥ä»æœ¬ä½“æ„Ÿå—æ•°æ®ä¸­å­¦ä¹ æœºå™¨äººçš„åŠ¨åŠ›å­¦ç‰¹æ€§ï¼Œé¿å…äº†å¯¹ç®€åŒ–æ¨¡å‹çš„ä¾èµ–ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­ç¥ç»è§‚æµ‹å™¨çš„å…·ä½“ç½‘ç»œç»“æ„å’ŒæŸå¤±å‡½æ•°è®¾è®¡æœªçŸ¥ã€‚é¢„æµ‹å™¨çš„è®¾è®¡ç›®æ ‡æ˜¯è®¡ç®—æ•ˆç‡ï¼Œå¯èƒ½é‡‡ç”¨äº†è½»é‡çº§çš„ç½‘ç»œç»“æ„æˆ–ä¼˜åŒ–çš„è®¡ç®—æ–¹æ³•ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œè®­ç»ƒç»†èŠ‚æœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥ç ”ç©¶é€šè¿‡ç¡¬ä»¶å®éªŒéªŒè¯äº†æ‰€æå‡ºçš„ç¥ç»è§‚æµ‹å™¨-é¢„æµ‹å™¨æ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿèƒ½å¤ŸæˆåŠŸåœ°åœ¨Vision 60å››è¶³æœºå™¨äººä¸Šå®ç°è…¿éƒ¨æ„ŸçŸ¥çš„è¿åŠ¨è§„åˆ’ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨ç‹­çª„é€šé“å’Œå°å‹ç‰©ä½“ä¸Šå®‰å…¨é€šè¿‡ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦æœªçŸ¥ï¼Œä½†å®éªŒç»“æœè¡¨æ˜è¯¥ç³»ç»Ÿå…·æœ‰å¾ˆå¼ºçš„å®é™…åº”ç”¨æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè…¿è¶³æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„è‡ªä¸»å¯¼èˆªã€æœç´¢æ•‘æ´ã€ç‰©æµè¿è¾“ç­‰é¢†åŸŸã€‚é€šè¿‡ç²¾ç¡®çš„è¿åŠ¨é¢„æµ‹å’Œè…¿éƒ¨çº§ç¢°æ’æ£€æµ‹ï¼Œæœºå™¨äººèƒ½å¤Ÿåœ¨ç‹­çª„ç©ºé—´ã€å´å²–åœ°å½¢æˆ–å­˜åœ¨éšœç¢ç‰©çš„ç¯å¢ƒä¸­å®‰å…¨é«˜æ•ˆåœ°æ‰§è¡Œä»»åŠ¡ã€‚è¯¥æŠ€æœ¯è¿˜æœ‰æ½œåŠ›åº”ç”¨äºå…¶ä»–ç±»å‹çš„æœºå™¨äººï¼Œä¾‹å¦‚äººå½¢æœºå™¨äººå’Œå¤šè¶³æœºå™¨äººã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Accurate full-body motion prediction is essential for the safe, autonomous navigation of legged robots, enabling critical capabilities like limb-level collision checking in cluttered environments. Simplified kinematic models often fail to capture the complex, closed-loop dynamics of the robot and its low-level controller, limiting their predictions to simple planar motion. To address this, we present a learning-based observer-predictor framework that accurately predicts this motion. Our method features a neural observer with provable UUB guarantees that provides a reliable latent state estimate from a history of proprioceptive measurements. This stable estimate initializes a computationally efficient predictor, designed for the rapid, parallel evaluation of thousands of potential trajectories required by modern sampling-based planners. We validated the system by integrating our neural predictor into an MPPI-based planner on a Vision 60 quadruped. Hardware experiments successfully demonstrated effective, limb-aware motion planning in a challenging, narrow passage and over small objects, highlighting our system's ability to provide a robust foundation for high-performance, collision-aware planning on dynamic robotic platforms.

