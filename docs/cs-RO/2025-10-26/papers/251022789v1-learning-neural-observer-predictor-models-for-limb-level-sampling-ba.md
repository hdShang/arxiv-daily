---
layout: default
title: Learning Neural Observer-Predictor Models for Limb-level Sampling-based Locomotion Planning
---

# Learning Neural Observer-Predictor Models for Limb-level Sampling-based Locomotion Planning

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.22789" target="_blank" class="toolbar-btn">arXiv: 2510.22789v1</a>
    <a href="https://arxiv.org/pdf/2510.22789.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.22789v1" 
            onclick="toggleFavorite(this, '2510.22789v1', 'Learning Neural Observer-Predictor Models for Limb-level Sampling-based Locomotion Planning')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Abhijeet M. Kulkarni, Ioannis Poulakakis, Guoquan Huang

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-26

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éÂ≠¶‰π†ÁöÑÁ•ûÁªèËßÇÊµãÂô®-È¢ÑÊµãÂô®Ê®°ÂûãÔºåÁî®‰∫éËÖøË∂≥Êú∫Âô®‰∫∫Âü∫‰∫éÈááÊ†∑ÁöÑËÖøÈÉ®Á∫ßËøêÂä®ËßÑÂàí„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)**

**ÂÖ≥ÈîÆËØç**: `ËÖøË∂≥Êú∫Âô®‰∫∫` `ËøêÂä®ËßÑÂàí` `Á•ûÁªèËßÇÊµãÂô®` `È¢ÑÊµãÊ®°Âûã` `Êú∫Âô®Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËÖøË∂≥Êú∫Âô®‰∫∫ËøêÂä®ËßÑÂàíÊñπÊ≥ï‰æùËµñÁÆÄÂåñÊ®°ÂûãÔºåÊó†Ê≥ïÂáÜÁ°ÆÈ¢ÑÊµãÂÖ®Ë∫´ËøêÂä®ÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§çÊùÇÁéØÂ¢É‰∏≠ËøõË°åËÖøÈÉ®Á∫ßÁ¢∞ÊíûÊ£ÄÊµãÊó∂„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫‰∏ÄÁßçÁ•ûÁªèËßÇÊµãÂô®-È¢ÑÊµãÂô®Ê°ÜÊû∂ÔºåÂà©Áî®Á•ûÁªèËßÇÊµãÂô®Êèê‰æõÁ®≥ÂÆöÁöÑÁä∂ÊÄÅ‰º∞ËÆ°ÔºåÂπ∂‰ª•Ê≠§ÂàùÂßãÂåñÈ´òÊïàÁöÑÈ¢ÑÊµãÂô®„ÄÇ
3. ÈÄöËøáÁ°¨‰ª∂ÂÆûÈ™åÔºåÂú®Vision 60ÂõõË∂≥Êú∫Âô®‰∫∫‰∏äÈ™åËØÅ‰∫ÜËØ•Á≥ªÁªüÂú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑËÖøÈÉ®ÊÑüÁü•ËøêÂä®ËßÑÂàíËÉΩÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÂ≠¶‰π†ÁöÑËßÇÊµãÂô®-È¢ÑÊµãÂô®Ê°ÜÊû∂ÔºåÁî®‰∫éÁ≤æÁ°ÆÈ¢ÑÊµãËÖøË∂≥Êú∫Âô®‰∫∫ÁöÑÂÖ®Ë∫´ËøêÂä®Ôºå‰ªéËÄåÂÆûÁé∞ÂÆâÂÖ®Ëá™‰∏ªÂØºËà™ÔºåÂπ∂ÊîØÊåÅÂú®Â§çÊùÇÁéØÂ¢É‰∏≠ËøõË°åËÖøÈÉ®Á∫ßÂà´ÁöÑÁ¢∞ÊíûÊ£ÄÊµã„ÄÇ‰º†ÁªüÁöÑÁÆÄÂåñËøêÂä®Â≠¶Ê®°ÂûãÈöæ‰ª•ÊçïÊçâÊú∫Âô®‰∫∫ÂèäÂÖ∂Â∫ïÂ±ÇÊéßÂà∂Âô®ÁöÑÂ§çÊùÇÈó≠ÁéØÂä®ÂäõÂ≠¶ÔºåÈ¢ÑÊµãÁ≤æÂ∫¶ÂèóÈôê„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊú¨ÊñáËÆæËÆ°‰∫Ü‰∏Ä‰∏™Á•ûÁªèËßÇÊµãÂô®ÔºåËØ•ËßÇÊµãÂô®ÂÖ∑ÊúâÂèØËØÅÊòéÁöÑ‰∏ÄËá¥ÊúÄÁªàÊúâÁïå(UUB)‰øùËØÅÔºåËÉΩÂ§ü‰ªéÂéÜÂè≤Êú¨‰ΩìÊÑüÂèóÊµãÈáè‰∏≠Êèê‰æõÂèØÈù†ÁöÑÊΩúÂú®Áä∂ÊÄÅ‰º∞ËÆ°„ÄÇÁÑ∂ÂêéÔºåÂà©Áî®Ëøô‰∏™Á®≥ÂÆöÁöÑ‰º∞ËÆ°ÂàùÂßãÂåñ‰∏Ä‰∏™ËÆ°ÁÆóÈ´òÊïàÁöÑÈ¢ÑÊµãÂô®ÔºåËØ•È¢ÑÊµãÂô®‰∏ì‰∏∫Áé∞‰ª£Âü∫‰∫éÈááÊ†∑ÁöÑËßÑÂàíÂô®ÊâÄÈúÄÁöÑÊï∞ÂçÉÊù°ÊΩúÂú®ËΩ®ËøπÁöÑÂø´ÈÄüÂπ∂Ë°åËØÑ‰º∞ËÄåËÆæËÆ°„ÄÇÈÄöËøáÂ∞ÜÁ•ûÁªèÈ¢ÑÊµãÂô®ÈõÜÊàêÂà∞Vision 60ÂõõË∂≥Êú∫Âô®‰∫∫ÁöÑMPPIËßÑÂàíÂô®‰∏≠È™åËØÅ‰∫ÜËØ•Á≥ªÁªü„ÄÇÁ°¨‰ª∂ÂÆûÈ™åÊàêÂäüÂ±ïÁ§∫‰∫ÜÂú®Áã≠Á™ÑÈÄöÈÅìÂíåÂ∞èÂûãÁâ©‰Ωì‰∏äÁöÑÊúâÊïà„ÄÅËÖøÈÉ®ÊÑüÁü•ËøêÂä®ËßÑÂàíÔºåÁ™ÅÂá∫‰∫ÜËØ•Á≥ªÁªü‰∏∫Âä®ÊÄÅÊú∫Âô®‰∫∫Âπ≥Âè∞‰∏äÁöÑÈ´òÊÄßËÉΩ„ÄÅÁ¢∞ÊíûÊÑüÁü•ËßÑÂàíÊèê‰æõÂº∫Â§ßÂü∫Á°ÄÁöÑËÉΩÂäõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÁöÑËÖøË∂≥Êú∫Âô®‰∫∫ËøêÂä®ËßÑÂàíÊñπÊ≥ïÔºåÁâπÂà´ÊòØÈíàÂØπÂ§çÊùÇÁéØÂ¢É‰∏ãÁöÑÂÖ®Ë∫´ËøêÂä®ËßÑÂàíÔºåÈù¢‰∏¥ÁùÄÁ≤æÁ°ÆÈ¢ÑÊµãÊú∫Âô®‰∫∫ËøêÂä®ËΩ®ËøπÁöÑÊåëÊàò„ÄÇ‰º†ÁªüÁöÑÂü∫‰∫éÁÆÄÂåñËøêÂä®Â≠¶Ê®°ÂûãÁöÑÊñπÊ≥ïÊó†Ê≥ïÂÖÖÂàÜÊçïÊçâÊú∫Âô®‰∫∫ÂèäÂÖ∂Â∫ïÂ±ÇÊéßÂà∂Âô®ÁöÑÂ§çÊùÇÈó≠ÁéØÂä®ÂäõÂ≠¶ÁâπÊÄßÔºåÂØºËá¥È¢ÑÊµãÁ≤æÂ∫¶‰∏çË∂≥ÔºåÈöæ‰ª•ÊîØÊåÅËÖøÈÉ®Á∫ßÂà´ÁöÑÁ¢∞ÊíûÊ£ÄÊµã„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Â≠¶‰π†ÁöÑÊñπÊ≥ïÔºåÊûÑÂª∫‰∏Ä‰∏™Á•ûÁªèËßÇÊµãÂô®-È¢ÑÊµãÂô®Ê°ÜÊû∂Ôºå‰ªéËÄåÊõ¥ÂáÜÁ°ÆÂú∞È¢ÑÊµãÊú∫Âô®‰∫∫ÁöÑËøêÂä®ËΩ®Ëøπ„ÄÇËØ•Ê°ÜÊû∂È¶ñÂÖà‰ΩøÁî®Á•ûÁªèËßÇÊµãÂô®‰ªéÂéÜÂè≤Êú¨‰ΩìÊÑüÂèóÊï∞ÊçÆ‰∏≠‰º∞ËÆ°Êú∫Âô®‰∫∫ÁöÑÁä∂ÊÄÅÔºåÁÑ∂ÂêéÂà©Áî®ËØ•Áä∂ÊÄÅÂàùÂßãÂåñ‰∏Ä‰∏™È¢ÑÊµãÂô®ÔºåÁî®‰∫éÈ¢ÑÊµãÊú™Êù•ÁöÑËøêÂä®ËΩ®Ëøπ„ÄÇËøôÁßçËÆæËÆ°Êó®Âú®ÂÖãÊúç‰º†ÁªüÊñπÊ≥ïÂØπÁÆÄÂåñÊ®°ÂûãÁöÑ‰æùËµñÔºåÂπ∂ÂÖÖÂàÜÂà©Áî®Êï∞ÊçÆÈ©±Âä®ÁöÑ‰ºòÂäø„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•Ê°ÜÊû∂ÂåÖÂê´‰∏§‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÁ•ûÁªèËßÇÊµãÂô®ÂíåÈ¢ÑÊµãÂô®„ÄÇÁ•ûÁªèËßÇÊµãÂô®Ë¥üË¥£‰ªéÂéÜÂè≤Êú¨‰ΩìÊÑüÂèóÊµãÈáèÊï∞ÊçÆ‰∏≠‰º∞ËÆ°Êú∫Âô®‰∫∫ÁöÑÊΩúÂú®Áä∂ÊÄÅÔºåÂπ∂Êèê‰æõ‰∏ÄËá¥ÊúÄÁªàÊúâÁïå(UUB)‰øùËØÅÔºåÁ°Æ‰øùÁä∂ÊÄÅ‰º∞ËÆ°ÁöÑÁ®≥ÂÆöÊÄß„ÄÇÈ¢ÑÊµãÂô®ÂàôÂà©Áî®Á•ûÁªèËßÇÊµãÂô®Êèê‰æõÁöÑÁä∂ÊÄÅ‰º∞ËÆ°‰Ωú‰∏∫ÂàùÂßãÊù°‰ª∂ÔºåÈ¢ÑÊµãÊú∫Âô®‰∫∫ÁöÑÊú™Êù•ËøêÂä®ËΩ®Ëøπ„ÄÇÊï¥‰∏™Ê°ÜÊû∂Êó®Âú®ÂÆûÁé∞Âø´ÈÄü„ÄÅÂπ∂Ë°åÂú∞ËØÑ‰º∞Â§ßÈáèÊΩúÂú®ËΩ®ËøπÔºå‰ª•Êª°Ë∂≥Âü∫‰∫éÈááÊ†∑ÁöÑËßÑÂàíÂô®ÁöÑÈúÄÊ±Ç„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜÁ•ûÁªèËßÇÊµãÂô®‰∏éÈ¢ÑÊµãÂô®Áõ∏ÁªìÂêàÔºåÊûÑÂª∫‰∫Ü‰∏Ä‰∏™ÂÆåÊï¥ÁöÑËøêÂä®È¢ÑÊµãÊ°ÜÊû∂„ÄÇÁ•ûÁªèËßÇÊµãÂô®ÁöÑUUB‰øùËØÅÁ°Æ‰øù‰∫ÜÁä∂ÊÄÅ‰º∞ËÆ°ÁöÑÂèØÈù†ÊÄßÔºåËÄåÈ¢ÑÊµãÂô®ÁöÑËÆ°ÁÆóÊïàÁéáÂàô‰ΩøÂÖ∂ËÉΩÂ§üÂø´ÈÄüËØÑ‰º∞Â§ßÈáèËΩ®Ëøπ„ÄÇÊ≠§Â§ñÔºåËØ•Ê°ÜÊû∂ËÉΩÂ§üÁõ¥Êé•‰ªéÊú¨‰ΩìÊÑüÂèóÊï∞ÊçÆ‰∏≠Â≠¶‰π†Êú∫Âô®‰∫∫ÁöÑÂä®ÂäõÂ≠¶ÁâπÊÄßÔºåÈÅøÂÖç‰∫ÜÂØπÁÆÄÂåñÊ®°ÂûãÁöÑ‰æùËµñ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËÆ∫Êñá‰∏≠Á•ûÁªèËßÇÊµãÂô®ÁöÑÂÖ∑‰ΩìÁΩëÁªúÁªìÊûÑÂíåÊçüÂ§±ÂáΩÊï∞ËÆæËÆ°Êú™Áü•„ÄÇÈ¢ÑÊµãÂô®ÁöÑËÆæËÆ°ÁõÆÊ†áÊòØËÆ°ÁÆóÊïàÁéáÔºåÂèØËÉΩÈááÁî®‰∫ÜËΩªÈáèÁ∫ßÁöÑÁΩëÁªúÁªìÊûÑÊàñ‰ºòÂåñÁöÑËÆ°ÁÆóÊñπÊ≥ï„ÄÇÂÖ∑‰ΩìÁöÑÂèÇÊï∞ËÆæÁΩÆÂíåËÆ≠ÁªÉÁªÜËäÇÊú™Áü•„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ËØ•Á†îÁ©∂ÈÄöËøáÁ°¨‰ª∂ÂÆûÈ™åÈ™åËØÅ‰∫ÜÊâÄÊèêÂá∫ÁöÑÁ•ûÁªèËßÇÊµãÂô®-È¢ÑÊµãÂô®Ê°ÜÊû∂ÁöÑÊúâÊïàÊÄß„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•Á≥ªÁªüËÉΩÂ§üÊàêÂäüÂú∞Âú®Vision 60ÂõõË∂≥Êú∫Âô®‰∫∫‰∏äÂÆûÁé∞ËÖøÈÉ®ÊÑüÁü•ÁöÑËøêÂä®ËßÑÂàíÔºå‰ΩøÂÖ∂ËÉΩÂ§üÂú®Áã≠Á™ÑÈÄöÈÅìÂíåÂ∞èÂûãÁâ©‰Ωì‰∏äÂÆâÂÖ®ÈÄöËøá„ÄÇÂÖ∑‰ΩìÁöÑÊÄßËÉΩÊï∞ÊçÆÂíåÊèêÂçáÂπÖÂ∫¶Êú™Áü•Ôºå‰ΩÜÂÆûÈ™åÁªìÊûúË°®ÊòéËØ•Á≥ªÁªüÂÖ∑ÊúâÂæàÂº∫ÁöÑÂÆûÈôÖÂ∫îÁî®ÊΩúÂäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éËÖøË∂≥Êú∫Âô®‰∫∫Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑËá™‰∏ªÂØºËà™„ÄÅÊêúÁ¥¢ÊïëÊè¥„ÄÅÁâ©ÊµÅËøêËæìÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÁ≤æÁ°ÆÁöÑËøêÂä®È¢ÑÊµãÂíåËÖøÈÉ®Á∫ßÁ¢∞ÊíûÊ£ÄÊµãÔºåÊú∫Âô®‰∫∫ËÉΩÂ§üÂú®Áã≠Á™ÑÁ©∫Èó¥„ÄÅÂ¥éÂ≤ñÂú∞ÂΩ¢ÊàñÂ≠òÂú®ÈöúÁ¢çÁâ©ÁöÑÁéØÂ¢É‰∏≠ÂÆâÂÖ®È´òÊïàÂú∞ÊâßË°å‰ªªÂä°„ÄÇËØ•ÊäÄÊúØËøòÊúâÊΩúÂäõÂ∫îÁî®‰∫éÂÖ∂‰ªñÁ±ªÂûãÁöÑÊú∫Âô®‰∫∫Ôºå‰æãÂ¶Ç‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ÂíåÂ§öË∂≥Êú∫Âô®‰∫∫„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Accurate full-body motion prediction is essential for the safe, autonomous navigation of legged robots, enabling critical capabilities like limb-level collision checking in cluttered environments. Simplified kinematic models often fail to capture the complex, closed-loop dynamics of the robot and its low-level controller, limiting their predictions to simple planar motion. To address this, we present a learning-based observer-predictor framework that accurately predicts this motion. Our method features a neural observer with provable UUB guarantees that provides a reliable latent state estimate from a history of proprioceptive measurements. This stable estimate initializes a computationally efficient predictor, designed for the rapid, parallel evaluation of thousands of potential trajectories required by modern sampling-based planners. We validated the system by integrating our neural predictor into an MPPI-based planner on a Vision 60 quadruped. Hardware experiments successfully demonstrated effective, limb-aware motion planning in a challenging, narrow passage and over small objects, highlighting our system's ability to provide a robust foundation for high-performance, collision-aware planning on dynamic robotic platforms.

