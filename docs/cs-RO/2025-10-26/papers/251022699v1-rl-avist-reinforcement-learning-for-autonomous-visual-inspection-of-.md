---
layout: default
title: "RL-AVIST: Reinforcement Learning for Autonomous Visual Inspection of Space Targets"
---

# RL-AVIST: Reinforcement Learning for Autonomous Visual Inspection of Space Targets

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.22699" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.22699v1</a>
  <a href="https://arxiv.org/pdf/2510.22699.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.22699v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.22699v1', 'RL-AVIST: Reinforcement Learning for Autonomous Visual Inspection of Space Targets')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Matteo El-Hariry, Andrej Orsula, Matthieu Geist, Miguel Olivares-Mendez

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-10-26

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRL-AVISTæ¡†æ¶ï¼Œç”¨äºèˆªå¤©å™¨ç›®æ ‡è‡ªä¸»è§†è§‰æ£€æµ‹çš„å¼ºåŒ–å­¦ä¹ æ§åˆ¶ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `è‡ªä¸»è§†è§‰æ£€æµ‹` `èˆªå¤©å™¨æ§åˆ¶` `åœ¨è½¨æœåŠ¡` `DreamerV3`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿèˆªå¤©å™¨æ§åˆ¶ç³»ç»Ÿåœ¨æ¨¡å‹ä¸ç¡®å®šå’Œä»»åŠ¡åŠ¨æ€å˜åŒ–æ—¶é€‚åº”æ€§ä¸è¶³ï¼Œéš¾ä»¥æ»¡è¶³æ—¥ç›Šå¢é•¿çš„åœ¨è½¨æœåŠ¡éœ€æ±‚ã€‚
2. RL-AVISTæ¡†æ¶åˆ©ç”¨å¼ºåŒ–å­¦ä¹ ï¼Œé€šè¿‡å­¦ä¹ å¤æ‚æœºåŠ¨ç­–ç•¥ï¼Œå®ç°èˆªå¤©å™¨å¯¹ç©ºé—´ç›®æ ‡çš„è‡ªä¸»è§†è§‰æ£€æµ‹ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒåŸºäºæ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ åœ¨è½¨è¿¹ä¿çœŸåº¦å’Œæ ·æœ¬æ•ˆç‡æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä¸ºç©ºé—´ä»»åŠ¡æ§åˆ¶æä¾›äº†æ–°æ€è·¯ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äºèˆªå¤©å™¨ç›®æ ‡è‡ªä¸»è§†è§‰æ£€æµ‹çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶RL-AVISTã€‚é’ˆå¯¹æ—¥ç›Šå¢é•¿çš„åœ¨è½¨æœåŠ¡éœ€æ±‚ï¼Œå¦‚æ£€æµ‹ã€ç»´æŠ¤å’ŒçŠ¶æ€æ„ŸçŸ¥ï¼Œéœ€è¦æ™ºèƒ½èˆªå¤©å™¨èƒ½å¤Ÿå›´ç»•å¤§å‹è½¨é“ç›®æ ‡è¿›è¡Œå¤æ‚æœºåŠ¨ã€‚ä¼ ç»Ÿæ§åˆ¶ç³»ç»Ÿåœ¨é€‚åº”æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨æ¨¡å‹ä¸ç¡®å®šæ€§ã€å¤šèˆªå¤©å™¨é…ç½®æˆ–åŠ¨æ€æ¼”å˜çš„ à¤®à¤¿à¤¶à¤¨ ç¯å¢ƒä¸‹ã€‚è¯¥æ¡†æ¶åˆ©ç”¨Space Robotics Bench (SRB)æ¨¡æ‹Ÿé«˜ä¿çœŸ6è‡ªç”±åº¦èˆªå¤©å™¨åŠ¨åŠ›å­¦ï¼Œå¹¶ä½¿ç”¨DreamerV3ï¼ˆä¸€ç§å…ˆè¿›çš„åŸºäºæ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼‰ä»¥åŠPPOå’ŒTD3ï¼ˆä½œä¸ºæ— æ¨¡å‹åŸºçº¿ï¼‰è®­ç»ƒæ™ºèƒ½ä½“ã€‚ç ”ç©¶é‡ç‚¹æ˜¯å›´ç»•æœˆçƒé—¨æˆ·ç­‰ç›®æ ‡è¿›è¡Œ3Dè¿‘è·ç¦»æœºåŠ¨ä»»åŠ¡ã€‚è¯„ä¼°äº†ä¸¤ç§äº’è¡¥æ¨¡å¼ä¸‹çš„ä»»åŠ¡æ€§èƒ½ï¼šåœ¨éšæœºé€Ÿåº¦å‘é‡ä¸Šè®­ç»ƒçš„å¹¿ä¹‰æ™ºèƒ½ä½“ï¼Œä»¥åŠè®­ç»ƒç”¨äºéµå¾ªæ¨¡æ‹Ÿå·²çŸ¥æ£€æµ‹è½¨é“çš„å›ºå®šè½¨è¿¹çš„ä¸“ç”¨æ™ºèƒ½ä½“ã€‚æ­¤å¤–ï¼Œè¯„ä¼°äº†ç­–ç•¥åœ¨å¤šç§èˆªå¤©å™¨å½¢æ€å’Œä»»åŠ¡é¢†åŸŸä¸­çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚ç»“æœè¡¨æ˜ï¼ŒåŸºäºæ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ åœ¨è½¨è¿¹ä¿çœŸåº¦å’Œæ ·æœ¬æ•ˆç‡æ–¹é¢å…·æœ‰è‰¯å¥½çš„èƒ½åŠ›ï¼Œä¸ºæœªæ¥ç©ºé—´è¡ŒåŠ¨çš„å¯æ‰©å±•ã€å¯å†è®­ç»ƒçš„æ§åˆ¶è§£å†³æ–¹æ¡ˆé“ºå¹³äº†é“è·¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³èˆªå¤©å™¨åœ¨å¤æ‚ç©ºé—´ç¯å¢ƒä¸­ï¼Œå¦‚ä½•è‡ªä¸»åœ°è¿›è¡Œè§†è§‰æ£€æµ‹çš„é—®é¢˜ã€‚ç°æœ‰æ§åˆ¶æ–¹æ³•åœ¨é¢å¯¹æ¨¡å‹ä¸ç¡®å®šæ€§ã€å¤šèˆªå¤©å™¨ååŒä»¥åŠåŠ¨æ€å˜åŒ–çš„ä»»åŠ¡ç¯å¢ƒæ—¶ï¼Œé€‚åº”æ€§è¾ƒå·®ï¼Œéš¾ä»¥ä¿è¯æ£€æµ‹ä»»åŠ¡çš„ç²¾åº¦å’Œæ•ˆç‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¼ºåŒ–å­¦ä¹ ï¼Œç‰¹åˆ«æ˜¯åŸºäºæ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œè®©èˆªå¤©å™¨æ™ºèƒ½ä½“é€šè¿‡ä¸ç¯å¢ƒçš„äº¤äº’å­¦ä¹ æœ€ä¼˜çš„æ§åˆ¶ç­–ç•¥ã€‚é€šè¿‡å­¦ä¹ ï¼Œæ™ºèƒ½ä½“èƒ½å¤Ÿé€‚åº”ä¸åŒçš„èˆªå¤©å™¨å½¢æ€å’Œä»»åŠ¡ç¯å¢ƒï¼Œå®ç°è‡ªä¸»çš„è§†è§‰æ£€æµ‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRL-AVISTæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼š1) åŸºäºSpace Robotics Bench (SRB) çš„é«˜ä¿çœŸ6è‡ªç”±åº¦èˆªå¤©å™¨åŠ¨åŠ›å­¦ä»¿çœŸç¯å¢ƒï¼›2) åŸºäºDreamerV3çš„å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“ï¼Œä»¥åŠPPOå’ŒTD3ä½œä¸ºåŸºçº¿ç®—æ³•ï¼›3) å¥–åŠ±å‡½æ•°çš„è®¾è®¡ï¼Œç”¨äºå¼•å¯¼æ™ºèƒ½ä½“å­¦ä¹ æœŸæœ›çš„æ£€æµ‹è¡Œä¸ºï¼›4) ç­–ç•¥è¯„ä¼°å’Œæ³›åŒ–èƒ½åŠ›æµ‹è¯•ï¼ŒéªŒè¯æ™ºèƒ½ä½“åœ¨ä¸åŒç¯å¢ƒä¸‹çš„æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†åŸºäºæ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•DreamerV3åº”ç”¨äºèˆªå¤©å™¨è‡ªä¸»è§†è§‰æ£€æµ‹ä»»åŠ¡ã€‚ä¸ä¼ ç»Ÿçš„æ— æ¨¡å‹å¼ºåŒ–å­¦ä¹ ç®—æ³•ç›¸æ¯”ï¼ŒDreamerV3èƒ½å¤Ÿå­¦ä¹ ç¯å¢ƒçš„æ¨¡å‹ï¼Œä»è€Œæé«˜æ ·æœ¬æ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜ç ”ç©¶äº†ç­–ç•¥åœ¨ä¸åŒèˆªå¤©å™¨å½¢æ€å’Œä»»åŠ¡ç¯å¢ƒä¸‹çš„é²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä½¿ç”¨äº†DreamerV3ç®—æ³•ï¼Œè¿™æ˜¯ä¸€ç§åŸºäºéšå˜é‡æ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•ã€‚å¥–åŠ±å‡½æ•°çš„è®¾è®¡è‡³å…³é‡è¦ï¼Œéœ€è¦ç»¼åˆè€ƒè™‘èˆªå¤©å™¨çš„è½¨è¿¹ç²¾åº¦ã€ä¸ç›®æ ‡çš„è·ç¦»ã€ä»¥åŠèƒ½é‡æ¶ˆè€—ç­‰å› ç´ ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜å¯¹æ™ºèƒ½ä½“çš„ç½‘ç»œç»“æ„è¿›è¡Œäº†ä¼˜åŒ–ï¼Œä»¥æé«˜å­¦ä¹ æ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºæ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•DreamerV3åœ¨èˆªå¤©å™¨è‡ªä¸»è§†è§‰æ£€æµ‹ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œåœ¨è½¨è¿¹ä¿çœŸåº¦å’Œæ ·æœ¬æ•ˆç‡æ–¹é¢ä¼˜äºæ— æ¨¡å‹å¼ºåŒ–å­¦ä¹ ç®—æ³•PPOå’ŒTD3ã€‚é€šè¿‡åœ¨éšæœºé€Ÿåº¦å‘é‡å’Œå›ºå®šè½¨è¿¹ä¸Šè¿›è¡Œè®­ç»ƒï¼ŒéªŒè¯äº†æ™ºèƒ½ä½“åœ¨ä¸åŒä»»åŠ¡ç¯å¢ƒä¸‹çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¤šç§åœ¨è½¨æœåŠ¡ä»»åŠ¡ï¼Œå¦‚ç©ºé—´ç«™å’Œå«æ˜Ÿçš„è‡ªä¸»æ£€æµ‹ã€ç»´æŠ¤å’Œç»´ä¿®ï¼Œä»¥åŠç©ºé—´ç¢ç‰‡æ¸…é™¤ç­‰ã€‚é€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„æ™ºèƒ½ä½“èƒ½å¤Ÿè‡ªä¸»è§„åˆ’èˆªå¤©å™¨çš„è¿åŠ¨è½¨è¿¹ï¼Œæé«˜ä»»åŠ¡æ•ˆç‡å’Œå®‰å…¨æ€§ï¼Œé™ä½å¯¹åœ°é¢æ§åˆ¶çš„ä¾èµ–ï¼Œä¸ºæœªæ¥çš„æ·±ç©ºæ¢æµ‹å’Œç©ºé—´èµ„æºåˆ©ç”¨æä¾›æŠ€æœ¯æ”¯æŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The growing need for autonomous on-orbit services such as inspection, maintenance, and situational awareness calls for intelligent spacecraft capable of complex maneuvers around large orbital targets. Traditional control systems often fall short in adaptability, especially under model uncertainties, multi-spacecraft configurations, or dynamically evolving mission contexts. This paper introduces RL-AVIST, a Reinforcement Learning framework for Autonomous Visual Inspection of Space Targets. Leveraging the Space Robotics Bench (SRB), we simulate high-fidelity 6-DOF spacecraft dynamics and train agents using DreamerV3, a state-of-the-art model-based RL algorithm, with PPO and TD3 as model-free baselines. Our investigation focuses on 3D proximity maneuvering tasks around targets such as the Lunar Gateway and other space assets. We evaluate task performance under two complementary regimes: generalized agents trained on randomized velocity vectors, and specialized agents trained to follow fixed trajectories emulating known inspection orbits. Furthermore, we assess the robustness and generalization of policies across multiple spacecraft morphologies and mission domains. Results demonstrate that model-based RL offers promising capabilities in trajectory fidelity, and sample efficiency, paving the way for scalable, retrainable control solutions for future space operations

