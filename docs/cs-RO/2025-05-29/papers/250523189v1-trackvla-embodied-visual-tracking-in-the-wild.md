---
layout: default
title: TrackVLA: Embodied Visual Tracking in the Wild
---

# TrackVLA: Embodied Visual Tracking in the Wild

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.23189" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.23189v1</a>
  <a href="https://arxiv.org/pdf/2505.23189.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.23189v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.23189v1', 'TrackVLA: Embodied Visual Tracking in the Wild')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shaoan Wang, Jiazhao Zhang, Minghan Li, Jiahang Liu, Anqi Li, Kui Wu, Fangwei Zhong, Junzhi Yu, Zhizheng Zhang, He Wang

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-29

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://pku-epic.github.io/TrackVLA-web)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTrackVLAä»¥è§£å†³åŠ¨æ€ç¯å¢ƒä¸­çš„è§†è§‰è·Ÿè¸ªé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å…·èº«è§†è§‰è·Ÿè¸ª` `è§†è§‰-è¯­è¨€-åŠ¨ä½œ` `åŠ¨æ€ç¯å¢ƒ` `ç›®æ ‡è¯†åˆ«` `è½¨è¿¹è§„åˆ’` `æ·±åº¦å­¦ä¹ ` `æœºå™¨äººå¯¼èˆª`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•é€šå¸¸å°†ç›®æ ‡è¯†åˆ«ä¸è½¨è¿¹è§„åˆ’æ¨¡å—åŒ–ï¼Œå¯¼è‡´åœ¨åŠ¨æ€ç¯å¢ƒä¸­å¤„ç†å¤æ‚åœºæ™¯æ—¶çš„æ€§èƒ½ä¸è¶³ã€‚
2. TrackVLAé€šè¿‡å…±äº«çš„è¯­è¨€æ¨¡å‹éª¨å¹²ï¼Œç»“åˆè¯­è¨€å»ºæ¨¡å¤´è¿›è¡Œè¯†åˆ«å’ŒåŸºäºé”šç‚¹çš„æ‰©æ•£æ¨¡å‹è¿›è¡Œè½¨è¿¹è§„åˆ’ï¼Œæå‡äº†ä¸¤è€…çš„ååŒæ•ˆæœã€‚
3. åœ¨å¤šä¸ªå…¬å…±åŸºå‡†æµ‹è¯•ä¸­ï¼ŒTrackVLAä»¥é›¶æ ·æœ¬æ–¹å¼æ˜¾è‘—è¶…è¶Šç°æœ‰æ–¹æ³•ï¼Œä¸”åœ¨çœŸå®åœºæ™¯ä¸­ä»¥10 FPSçš„é€Ÿåº¦ä¿æŒé²æ£’æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å…·èº«è§†è§‰è·Ÿè¸ªæ˜¯å…·èº«äººå·¥æ™ºèƒ½ä¸­çš„ä¸€é¡¹åŸºç¡€æŠ€èƒ½ï¼Œä½¿å¾—æ™ºèƒ½ä½“èƒ½å¤Ÿåœ¨åŠ¨æ€ç¯å¢ƒä¸­ä»…ä¾é è‡ªæˆ‘ä¸­å¿ƒè§†è§‰è·Ÿéšç‰¹å®šç›®æ ‡ã€‚è¯¥ä»»åŠ¡å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºå®ƒéœ€è¦åœ¨ä¸¥é‡é®æŒ¡å’Œé«˜åœºæ™¯åŠ¨æ€æ¡ä»¶ä¸‹è¿›è¡Œå‡†ç¡®çš„ç›®æ ‡è¯†åˆ«å’Œæœ‰æ•ˆçš„è½¨è¿¹è§„åˆ’ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸é€šè¿‡å°†è¯†åˆ«ä¸è§„åˆ’æ¨¡å—åŒ–åˆ†å¼€æ¥è§£å†³è¿™ä¸€æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†TrackVLAï¼Œä¸€ä¸ªè§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹ï¼Œå­¦ä¹ ç‰©ä½“è¯†åˆ«ä¸è½¨è¿¹è§„åˆ’ä¹‹é—´çš„ååŒä½œç”¨ã€‚é€šè¿‡æ„å»ºå…·èº«è§†è§‰è·Ÿè¸ªåŸºå‡†ï¼ˆEVT-Benchï¼‰å¹¶æ”¶é›†å¤šæ ·åŒ–çš„è¯†åˆ«æ ·æœ¬ï¼ŒTrackVLAåœ¨åˆæˆå’ŒçœŸå®ç¯å¢ƒä¸­è¿›è¡Œäº†å¹¿æ³›å®éªŒï¼Œå±•ç¤ºäº†æœ€å…ˆè¿›çš„æ€§èƒ½å’Œå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å…·èº«è§†è§‰è·Ÿè¸ªä¸­çš„ç›®æ ‡è¯†åˆ«ä¸è½¨è¿¹è§„åˆ’çš„ååŒé—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨åŠ¨æ€ç¯å¢ƒä¸­é¢ä¸´ä¸¥é‡é®æŒ¡å’Œé«˜åœºæ™¯åŠ¨æ€æ—¶çš„æ€§èƒ½ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šTrackVLAé€šè¿‡æ•´åˆè§†è§‰ã€è¯­è¨€å’ŒåŠ¨ä½œçš„æ¨¡å‹ï¼Œåˆ©ç”¨å…±äº«çš„è¯­è¨€æ¨¡å‹éª¨å¹²ï¼Œå¢å¼ºç›®æ ‡è¯†åˆ«ä¸è½¨è¿¹è§„åˆ’çš„ååŒä½œç”¨ï¼Œä»è€Œæé«˜æ•´ä½“æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTrackVLAçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šä¸€ä¸ªç”¨äºç›®æ ‡è¯†åˆ«çš„è¯­è¨€å»ºæ¨¡å¤´å’Œä¸€ä¸ªç”¨äºè½¨è¿¹è§„åˆ’çš„åŸºäºé”šç‚¹çš„æ‰©æ•£æ¨¡å‹ã€‚è¿™ç§è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨å¤„ç†å¤æ‚åœºæ™¯æ—¶æ›´ä¸ºé«˜æ•ˆã€‚

**å…³é”®åˆ›æ–°**ï¼šTrackVLAçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå°†ç›®æ ‡è¯†åˆ«ä¸è½¨è¿¹è§„åˆ’çš„è¿‡ç¨‹è¿›è¡Œæ·±åº¦èåˆï¼Œè€Œä¸æ˜¯ç®€å•çš„æ¨¡å—åŒ–åˆ†å¼€ã€‚è¿™ç§æ–¹æ³•ä½¿å¾—æ¨¡å‹åœ¨åŠ¨æ€ç¯å¢ƒä¸­è¡¨ç°å‡ºæ›´å¼ºçš„é€‚åº”æ€§å’Œé²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒTrackVLAä½¿ç”¨äº†æ„å»ºçš„å…·èº«è§†è§‰è·Ÿè¸ªåŸºå‡†ï¼ˆEVT-Benchï¼‰ï¼ŒåŒ…å«170ä¸‡æ ·æœ¬ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨å¤šæ ·åŒ–åœºæ™¯ä¸­çš„æœ‰æ•ˆæ€§ã€‚é€šè¿‡è¿™äº›è®¾è®¡ï¼Œæ¨¡å‹åœ¨çœŸå®ä¸–ç•Œçš„åº”ç”¨ä¸­è¡¨ç°å‡ºè‰²ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

TrackVLAåœ¨å¤šä¸ªå…¬å…±åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œå°¤å…¶æ˜¯åœ¨é›¶æ ·æœ¬æ¡ä»¶ä¸‹ï¼Œå…¶æ€§èƒ½æ˜¾è‘—è¶…è¶Šç°æœ‰æ–¹æ³•ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTrackVLAåœ¨çœŸå®åœºæ™¯ä¸­ä»¥10 FPSçš„é€Ÿåº¦å¤„ç†é«˜åŠ¨æ€å’Œé®æŒ¡æƒ…å†µï¼Œå±•ç°å‡ºå¼ºå¤§çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

TrackVLAçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ï¼ŒåŒ…æ‹¬æœºå™¨äººå¯¼èˆªã€æ™ºèƒ½ç›‘æ§å’Œå¢å¼ºç°å®ç­‰ã€‚é€šè¿‡æé«˜åŠ¨æ€ç¯å¢ƒä¸­çš„ç›®æ ‡è·Ÿè¸ªèƒ½åŠ›ï¼Œèƒ½å¤Ÿä¸ºæ™ºèƒ½ä½“æä¾›æ›´ä¸ºç²¾å‡†çš„å†³ç­–æ”¯æŒï¼Œæ¨åŠ¨å…·èº«äººå·¥æ™ºèƒ½çš„å‘å±•ã€‚æœªæ¥ï¼ŒTrackVLAå¯èƒ½åœ¨è‡ªä¸»é©¾é©¶å’Œäººæœºäº¤äº’ç­‰é¢†åŸŸå‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Embodied visual tracking is a fundamental skill in Embodied AI, enabling an agent to follow a specific target in dynamic environments using only egocentric vision. This task is inherently challenging as it requires both accurate target recognition and effective trajectory planning under conditions of severe occlusion and high scene dynamics. Existing approaches typically address this challenge through a modular separation of recognition and planning. In this work, we propose TrackVLA, a Vision-Language-Action (VLA) model that learns the synergy between object recognition and trajectory planning. Leveraging a shared LLM backbone, we employ a language modeling head for recognition and an anchor-based diffusion model for trajectory planning. To train TrackVLA, we construct an Embodied Visual Tracking Benchmark (EVT-Bench) and collect diverse difficulty levels of recognition samples, resulting in a dataset of 1.7 million samples. Through extensive experiments in both synthetic and real-world environments, TrackVLA demonstrates SOTA performance and strong generalizability. It significantly outperforms existing methods on public benchmarks in a zero-shot manner while remaining robust to high dynamics and occlusion in real-world scenarios at 10 FPS inference speed. Our project page is: https://pku-epic.github.io/TrackVLA-web.

