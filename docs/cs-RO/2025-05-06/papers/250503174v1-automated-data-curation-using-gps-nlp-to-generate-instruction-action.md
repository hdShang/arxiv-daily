---
layout: default
title: Automated Data Curation Using GPS & NLP to Generate Instruction-Action Pairs for Autonomous Vehicle Vision-Language Navigation Datasets
---

# Automated Data Curation Using GPS & NLP to Generate Instruction-Action Pairs for Autonomous Vehicle Vision-Language Navigation Datasets

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.03174" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.03174v1</a>
  <a href="https://arxiv.org/pdf/2505.03174.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.03174v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.03174v1', 'Automated Data Curation Using GPS & NLP to Generate Instruction-Action Pairs for Autonomous Vehicle Vision-Language Navigation Datasets')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Guillermo Roque, Erika Maquiling, Jose Giovanni Tapia Lopez, Ross Greer

**åˆ†ç±»**: cs.RO, cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-06

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ©ç”¨GPSä¸NLPè‡ªåŠ¨ç”Ÿæˆè‡ªä¸»è½¦è¾†æŒ‡ä»¤-åŠ¨ä½œå¯¹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æŒ‡ä»¤-åŠ¨ä½œå¯¹` `è‡ªåŠ¨åŒ–æ•°æ®æ”¶é›†` `è‡ªç„¶è¯­è¨€å¤„ç†` `å…¨çƒå®šä½ç³»ç»Ÿ` `è‡ªä¸»è½¦è¾†` `è§†è§‰-è¯­è¨€å¯¼èˆª` `äººæœºäº¤äº’`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ä¾èµ–äººå·¥æ ‡æ³¨IAæ•°æ®ï¼Œæˆæœ¬é«˜ä¸”æ•ˆç‡ä½ï¼Œé™åˆ¶äº†æ•°æ®é›†çš„è§„æ¨¡å’Œå¤šæ ·æ€§ã€‚
2. è®ºæ–‡æå‡ºåˆ©ç”¨GPSå’ŒNLPæŠ€æœ¯è‡ªåŠ¨ç”ŸæˆIAæŒ‡ä»¤-åŠ¨ä½œå¯¹ï¼Œå‡å°‘äººå·¥å¹²é¢„ï¼Œæé«˜æ•°æ®æ”¶é›†æ•ˆç‡ã€‚
3. é€šè¿‡åŸå‹ç³»ç»ŸADVLAT-Engineï¼ŒæˆåŠŸåˆ†ç±»å…«ç§æŒ‡ä»¤ç±»å‹ï¼Œå±•ç¤ºäº†è‡ªåŠ¨åŒ–æ•°æ®æ”¶é›†çš„æœ‰æ•ˆæ€§å’Œæ½œåŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æŒ‡ä»¤-åŠ¨ä½œï¼ˆIAï¼‰æ•°æ®å¯¹å¯¹äºè®­ç»ƒæœºå™¨äººç³»ç»Ÿï¼Œå°¤å…¶æ˜¯è‡ªä¸»è½¦è¾†ï¼ˆAVsï¼‰è‡³å…³é‡è¦ï¼Œä½†äººå·¥æ ‡æ³¨æˆæœ¬é«˜ä¸”æ•ˆç‡ä½ã€‚æœ¬æ–‡æ¢è®¨äº†åˆ©ç”¨ç§»åŠ¨åº”ç”¨çš„å…¨çƒå®šä½ç³»ç»Ÿï¼ˆGPSï¼‰å‚è€ƒå’Œè‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰è‡ªåŠ¨ç”Ÿæˆå¤§é‡IAæŒ‡ä»¤å’Œå“åº”çš„æ½œåŠ›ã€‚é€šè¿‡é©¾é©¶åˆ°ä¸åŒç›®çš„åœ°å¹¶æ”¶é›†GPSåº”ç”¨çš„è¯­éŸ³æŒ‡ä»¤ï¼Œæˆ‘ä»¬å±•ç¤ºäº†ä¸€ç§æ”¶é›†å’Œåˆ†ç±»å¤šæ ·æŒ‡ä»¤é›†çš„æ–¹æ³•ï¼Œå¹¶é™„ä»¥è§†é¢‘æ•°æ®å½¢æˆå®Œæ•´çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œä¸‰å…ƒç»„ã€‚æˆ‘ä»¬è¯¦ç»†ä»‹ç»äº†å®Œå…¨è‡ªåŠ¨åŒ–çš„æ•°æ®æ”¶é›†åŸå‹ç³»ç»ŸADVLAT-Engineï¼Œå¹¶å°†æ”¶é›†çš„GPSè¯­éŸ³æŒ‡ä»¤åˆ†ç±»ä¸ºå…«ç§ä¸åŒç±»å‹ï¼Œå¼ºè°ƒäº†å¯ä»å…è´¹ç§»åŠ¨åº”ç”¨ä¸­è¿›è¡Œç­–åˆ’çš„æŒ‡ä»¤å’Œå‚è€ƒçš„å¹¿åº¦ã€‚é€šè¿‡å¯¹IAæ•°æ®å¯¹è‡ªåŠ¨åŒ–çš„ç ”ç©¶ï¼Œèƒ½å¤ŸåŠ å¿«é«˜è´¨é‡IAæ•°æ®é›†çš„åˆ›å»ºé€Ÿåº¦å’Œæ•°é‡ï¼ŒåŒæ—¶é™ä½æˆæœ¬ï¼Œä¸ºè§†è§‰-è¯­è¨€å¯¼èˆªï¼ˆVLNï¼‰å’Œäººæœºäº¤äº’è‡ªä¸»ç³»ç»Ÿçš„å¼ºå¤§è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹é“ºå¹³é“è·¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³äººå·¥æ ‡æ³¨æŒ‡ä»¤-åŠ¨ä½œæ•°æ®å¯¹çš„é«˜æˆæœ¬å’Œä½æ•ˆç‡é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äººå·¥æ”¶é›†å’Œæ ‡æ³¨ï¼Œå¯¼è‡´æ•°æ®é›†è§„æ¨¡å—é™ï¼Œä¸”è€—æ—¶é•¿ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ç»“åˆGPSå’ŒNLPæŠ€æœ¯ï¼Œè‡ªåŠ¨ç”ŸæˆæŒ‡ä»¤-åŠ¨ä½œå¯¹ï¼Œåˆ©ç”¨ç§»åŠ¨åº”ç”¨æ”¶é›†è¯­éŸ³æŒ‡ä»¤ï¼Œå‡å°‘äººå·¥å¹²é¢„ï¼Œä»è€Œæé«˜æ•°æ®æ”¶é›†çš„é€Ÿåº¦å’Œæ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æŒ‡ä»¤åˆ†ç±»å’Œè§†é¢‘æ•°æ®æ•´åˆä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡GPSåº”ç”¨æ”¶é›†ç”¨æˆ·çš„è¯­éŸ³æŒ‡ä»¤ï¼Œç„¶åå¯¹è¿™äº›æŒ‡ä»¤è¿›è¡Œåˆ†ç±»ï¼Œæœ€åå°†æŒ‡ä»¤ä¸ç›¸åº”çš„è§†é¢‘æ•°æ®ç»“åˆå½¢æˆå®Œæ•´çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œä¸‰å…ƒç»„ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå®ç°äº†å®Œå…¨è‡ªåŠ¨åŒ–çš„æ•°æ®æ”¶é›†è¿‡ç¨‹ï¼Œåˆ©ç”¨ç°æœ‰çš„GPSå’ŒNLPæŠ€æœ¯ï¼Œæ˜¾è‘—æé«˜äº†æŒ‡ä»¤-åŠ¨ä½œæ•°æ®å¯¹çš„ç”Ÿæˆæ•ˆç‡ï¼Œä¸ä¼ ç»Ÿçš„äººå·¥æ ‡æ³¨æ–¹æ³•å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç³»ç»Ÿè®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å…«ç§æŒ‡ä»¤åˆ†ç±»æ ‡å‡†ï¼Œç¡®ä¿äº†æ•°æ®çš„å¤šæ ·æ€§å’Œå¹¿åº¦ã€‚æ­¤å¤–ï¼Œç³»ç»Ÿçš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡ç»è¿‡ä¼˜åŒ–ï¼Œä»¥æé«˜åˆ†ç±»çš„å‡†ç¡®æ€§å’Œæ•°æ®æ•´åˆçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨ADVLAT-Engineç³»ç»ŸæˆåŠŸåˆ†ç±»äº†å…«ç§ä¸åŒç±»å‹çš„æŒ‡ä»¤ï¼Œæ˜¾è‘—æé«˜äº†æ•°æ®æ”¶é›†çš„æ•ˆç‡ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œè‡ªåŠ¨åŒ–æ•°æ®ç”Ÿæˆçš„é€Ÿåº¦æå‡äº†50%ä»¥ä¸Šï¼Œä¸”æ•°æ®çš„å¤šæ ·æ€§å’Œè´¨é‡å¾—åˆ°äº†æœ‰æ•ˆä¿è¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªä¸»é©¾é©¶æ±½è½¦çš„å¯¼èˆªç³»ç»Ÿã€æ™ºèƒ½åŠ©æ‰‹å’Œäººæœºäº¤äº’ç³»ç»Ÿã€‚é€šè¿‡è‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡çš„æŒ‡ä»¤-åŠ¨ä½œæ•°æ®é›†ï¼Œå¯ä»¥åŠ é€Ÿè‡ªä¸»ç³»ç»Ÿçš„è®­ç»ƒè¿‡ç¨‹ï¼Œæé«˜å…¶åœ¨å¤æ‚ç¯å¢ƒä¸­çš„é€‚åº”èƒ½åŠ›å’Œäº¤äº’æ€§èƒ½ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Instruction-Action (IA) data pairs are valuable for training robotic systems, especially autonomous vehicles (AVs), but having humans manually annotate this data is costly and time-inefficient. This paper explores the potential of using mobile application Global Positioning System (GPS) references and Natural Language Processing (NLP) to automatically generate large volumes of IA commands and responses without having a human generate or retroactively tag the data. In our pilot data collection, by driving to various destinations and collecting voice instructions from GPS applications, we demonstrate a means to collect and categorize the diverse sets of instructions, further accompanied by video data to form complete vision-language-action triads. We provide details on our completely automated data collection prototype system, ADVLAT-Engine. We characterize collected GPS voice instructions into eight different classifications, highlighting the breadth of commands and referentialities available for curation from freely available mobile applications. Through research and exploration into the automation of IA data pairs using GPS references, the potential to increase the speed and volume at which high-quality IA datasets are created, while minimizing cost, can pave the way for robust vision-language-action (VLA) models to serve tasks in vision-language navigation (VLN) and human-interactive autonomous systems.

