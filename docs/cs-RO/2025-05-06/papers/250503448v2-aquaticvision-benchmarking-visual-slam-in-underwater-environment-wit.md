---
layout: default
title: "AquaticVision: Benchmarking Visual SLAM in Underwater Environment with Events and Frames"
---

# AquaticVision: Benchmarking Visual SLAM in Underwater Environment with Events and Frames

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.03448" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.03448v2</a>
  <a href="https://arxiv.org/pdf/2505.03448.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.03448v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.03448v2', 'AquaticVision: Benchmarking Visual SLAM in Underwater Environment with Events and Frames')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yifan Peng, Yuze Hong, Ziyang Hong, Apple Pui-Yi Chui, Junfeng Wu

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-05-06 (æ›´æ–°: 2025-06-05)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAquaticVisionä»¥è§£å†³æ°´ä¸‹è§†è§‰SLAMåŸºå‡†é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `æ°´ä¸‹è§†è§‰SLAM` `äº‹ä»¶ç›¸æœº` `æ•°æ®é›†` `è¿åŠ¨æ•æ‰` `åŸºå‡†æµ‹è¯•` `æµ·æ´‹æœºå™¨äºº` `3Dé‡å»º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ°´ä¸‹è§†è§‰SLAMæ•°æ®é›†ç¼ºä¹çœŸå®è½¨è¿¹æ•°æ®ï¼Œå¯¼è‡´ç®—æ³•æ€§èƒ½æ¯”è¾ƒå›°éš¾ã€‚
2. æœ¬æ–‡æå‡ºçš„AquaticVisionæ•°æ®é›†åŒ…å«çœŸå®è½¨è¿¹æ•°æ®ï¼Œå¹¶é¦–æ¬¡å¼•å…¥äº‹ä»¶å’Œå¸§æ•°æ®è¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚
3. é€šè¿‡ä½¿ç”¨äº‹ä»¶ç›¸æœºï¼Œç ”ç©¶å±•ç¤ºäº†åœ¨ä½å…‰å’Œæµ‘æµŠæ¡ä»¶ä¸‹çš„SLAMæ€§èƒ½æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è®¸å¤šæ°´ä¸‹åº”ç”¨ï¼Œå¦‚æµ·ä¸Šèµ„äº§æ£€æŸ¥ï¼Œä¾èµ–äºè§†è§‰æ£€æŸ¥å’Œè¯¦ç»†çš„3Dé‡å»ºã€‚è¿‘å¹´æ¥ï¼Œæ°´ä¸‹è§†è§‰SLAMç³»ç»Ÿçš„è¿›å±•å¼•èµ·äº†æµ·æ´‹æœºå™¨äººç ”ç©¶çš„å¹¿æ³›å…³æ³¨ã€‚ç„¶è€Œï¼Œç°æœ‰çš„æ°´ä¸‹è§†è§‰SLAMæ•°æ®é›†å¾€å¾€ç¼ºä¹çœŸå®è½¨è¿¹æ•°æ®ï¼Œä½¿å¾—ä¸åŒSLAMç®—æ³•çš„æ€§èƒ½æ¯”è¾ƒå˜å¾—å›°éš¾ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ°´ä¸‹æ•°æ®é›†ï¼ŒåŒ…å«ä½¿ç”¨è¿åŠ¨æ•æ‰ç³»ç»Ÿè·å¾—çš„çœŸå®è½¨è¿¹æ•°æ®ã€‚æ­¤å¤–ï¼Œé¦–æ¬¡å‘å¸ƒäº†åŒ…æ‹¬äº‹ä»¶å’Œå¸§çš„è§†è§‰æ•°æ®ï¼Œä»¥ä¾¿å¯¹æ°´ä¸‹è§†è§‰å®šä½è¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚é€šè¿‡æä¾›äº‹ä»¶ç›¸æœºæ•°æ®ï¼Œæ—¨åœ¨ä¿ƒè¿›æ›´å¼ºå¤§å’Œå…ˆè¿›çš„æ°´ä¸‹è§†è§‰SLAMç®—æ³•çš„å‘å±•ï¼Œå¸®åŠ©ç¼“è§£æä½å…‰ç…§æˆ–æµ‘æµŠæ°´ä¸‹æ¡ä»¶å¸¦æ¥çš„æŒ‘æˆ˜ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰æ°´ä¸‹è§†è§‰SLAMæ•°æ®é›†ç¼ºä¹çœŸå®è½¨è¿¹æ•°æ®çš„é—®é¢˜ï¼Œå¯¼è‡´ä¸åŒç®—æ³•çš„æ€§èƒ½æ¯”è¾ƒå›°éš¾ã€‚ç°æœ‰æ–¹æ³•å¤šä¾èµ–äºå®šæ€§ç»“æœæˆ–COLMAPé‡å»ºï¼Œç¼ºä¹å®¢è§‚è¯„ä¼°æ ‡å‡†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„AquaticVisionæ•°æ®é›†é€šè¿‡ç»“åˆè¿åŠ¨æ•æ‰ç³»ç»Ÿè·å–çš„çœŸå®è½¨è¿¹æ•°æ®å’Œäº‹ä»¶ç›¸æœºæ•°æ®ï¼Œæä¾›äº†ä¸€ä¸ªå…¨é¢çš„åŸºå‡†æµ‹è¯•å¹³å°ï¼Œä»¥æ”¯æŒæ°´ä¸‹è§†è§‰SLAMç®—æ³•çš„å¼€å‘å’Œè¯„ä¼°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é‡‡é›†ã€æ•°æ®æ ‡æ³¨å’Œæ•°æ®å‘å¸ƒä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚æ•°æ®é‡‡é›†é˜¶æ®µåˆ©ç”¨è¿åŠ¨æ•æ‰ç³»ç»Ÿè·å–çœŸå®è½¨è¿¹ï¼Œæ•°æ®æ ‡æ³¨é˜¶æ®µæ•´åˆäº‹ä»¶å’Œå¸§æ•°æ®ï¼Œæœ€ååœ¨æ•°æ®å‘å¸ƒé˜¶æ®µæä¾›å…¬å¼€è®¿é—®ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºé¦–æ¬¡ç»“åˆäº‹ä»¶ç›¸æœºå’Œä¼ ç»Ÿå¸§æ•°æ®ï¼Œæä¾›äº†æ›´ä¸°å¯Œçš„è§†è§‰ä¿¡æ¯ï¼Œèƒ½å¤Ÿåœ¨ä½å…‰å’Œæµ‘æµŠç¯å¢ƒä¸­æå‡SLAMç®—æ³•çš„é²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®é‡‡é›†è¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨é«˜é¢‘ç‡çš„äº‹ä»¶ç›¸æœºæ•æ‰åŠ¨æ€åœºæ™¯ï¼ŒåŒæ—¶ç¡®ä¿è¿åŠ¨æ•æ‰ç³»ç»Ÿçš„å‡†ç¡®æ€§ï¼Œä»¥æä¾›é«˜è´¨é‡çš„çœŸå®è½¨è¿¹æ•°æ®ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨AquaticVisionæ•°æ®é›†çš„SLAMç®—æ³•åœ¨ä½å…‰å’Œæµ‘æµŠæ¡ä»¶ä¸‹çš„å®šä½ç²¾åº¦æ˜¾è‘—æé«˜ï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•ï¼Œæ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œå±•ç¤ºäº†äº‹ä»¶ç›¸æœºåœ¨æ°´ä¸‹ç¯å¢ƒä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ°´ä¸‹æœºå™¨äººã€æµ·æ´‹èµ„äº§æ£€æŸ¥ã€ç¯å¢ƒç›‘æµ‹ç­‰ã€‚é€šè¿‡æä¾›é«˜è´¨é‡çš„åŸºå‡†æ•°æ®é›†ï¼ŒAquaticVisionå°†æ¨åŠ¨æ°´ä¸‹è§†è§‰SLAMæŠ€æœ¯çš„å‘å±•ï¼Œæå‡ç›¸å…³é¢†åŸŸçš„è‡ªåŠ¨åŒ–å’Œæ™ºèƒ½åŒ–æ°´å¹³ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Many underwater applications, such as offshore asset inspections, rely on visual inspection and detailed 3D reconstruction. Recent advancements in underwater visual SLAM systems for aquatic environments have garnered significant attention in marine robotics research. However, existing underwater visual SLAM datasets often lack groundtruth trajectory data, making it difficult to objectively compare the performance of different SLAM algorithms based solely on qualitative results or COLMAP reconstruction. In this paper, we present a novel underwater dataset that includes ground truth trajectory data obtained using a motion capture system. Additionally, for the first time, we release visual data that includes both events and frames for benchmarking underwater visual positioning. By providing event camera data, we aim to facilitate the development of more robust and advanced underwater visual SLAM algorithms. The use of event cameras can help mitigate challenges posed by extremely low light or hazy underwater conditions. The webpage of our dataset is https://sites.google.com/view/aquaticvision-lias.

