---
layout: default
title: "RobotxR1: Enabling Embodied Robotic Intelligence on Large Language Models through Closed-Loop Reinforcement Learning"
---

# RobotxR1: Enabling Embodied Robotic Intelligence on Large Language Models through Closed-Loop Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.03238" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.03238v2</a>
  <a href="https://arxiv.org/pdf/2505.03238.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.03238v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.03238v2', 'RobotxR1: Enabling Embodied Robotic Intelligence on Large Language Models through Closed-Loop Reinforcement Learning')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Liam Boyle, Nicolas Baumann, Paviththiren Sivasothilingam, Michele Magno, Luca Benini

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-06 (Êõ¥Êñ∞: 2025-08-30)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éÈó≠ÁéØÂº∫ÂåñÂ≠¶‰π†ÁöÑR1-ZeroÊñπÊ≥ï‰ª•ÊèêÂçáÊú∫Âô®‰∫∫Êô∫ËÉΩ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Èó≠ÁéØÂº∫ÂåñÂ≠¶‰π†` `ÂµåÂÖ•ÂºèÊô∫ËÉΩ` `Â∞èÂûãËØ≠Ë®ÄÊ®°Âûã` `Ëá™‰∏ªÈ©æÈ©∂` `Êú∫Âô®‰∫∫Êé®ÁêÜ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®Êú∫Âô®‰∫∫Êô∫ËÉΩ‰∏≠‰æùËµñ‰∫éÂ§ßÂûãÊ®°ÂûãÔºåÂØºËá¥ËÆ°ÁÆóÂíåÂÜÖÂ≠òÈúÄÊ±ÇÈ´òÔºåÈôêÂà∂‰∫ÜÂÖ∂Âú®ÂµåÂÖ•ÂºèÁ≥ªÁªü‰∏≠ÁöÑÂ∫îÁî®„ÄÇ
2. Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÈó≠ÁéØÂº∫ÂåñÂ≠¶‰π†Ê°ÜÊû∂ÔºåÁªìÂêà‰ΩéÂèÇÊï∞ÈáèÁöÑLLMsÔºåÂ¢ûÂº∫‰∫ÜÊú∫Âô®‰∫∫Âú®Âä®ÊÄÅÁéØÂ¢É‰∏≠ÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåQwen2.5-1.5BÊ®°ÂûãÂú®Ëá™‰∏ªÈ©æÈ©∂‰ªªÂä°‰∏≠ÊØîÂü∫Á∫øÊèêÂçá20.2%ÔºåËÄåQwen2.5-3BÊ®°ÂûãÁöÑÊéßÂà∂ÈÄÇÂ∫îÊÄßÂæóÂàÜËææÂà∞63.3%ÔºåË∂ÖË∂ä‰∫ÜÊõ¥Â§ßÁöÑGPT-4o„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú™Êù•ÁöÑÊú∫Âô®‰∫∫Á≥ªÁªüÈúÄË¶ÅÂú®Ê≤°ÊúâÊåÅÁª≠‰∫ëËøûÊé•ÁöÑÊÉÖÂÜµ‰∏ãÂÖ∑Â§áÂµåÂÖ•ÂºèÊô∫ËÉΩÔºåÂêåÊó∂Âπ≥Ë°°ËÆ°ÁÆóËÉΩÂäõÂíåÂÜÖÂ≠òÁöÑÈôêÂà∂„ÄÇÊú¨ÊñáÊâ©Â±ï‰∫ÜR1-ZeroÊñπÊ≥ïÔºå‰Ωø‰ΩéÂèÇÊï∞ÈáèÁöÑÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâËÉΩÂ§üÂú®Êú∫Âô®‰∫∫È¢ÜÂüüÂ∫îÁî®„ÄÇÈÄöËøáÂ∞ÜÂÖ∂ÈõÜÊàêÂà∞Èó≠ÁéØÂº∫ÂåñÂ≠¶‰π†Ê°ÜÊû∂‰∏≠ÔºåÂ¢ûÂº∫‰∫ÜÂµåÂÖ•Âºè‰∫∫Â∑•Êô∫ËÉΩÁöÑÊé®ÁêÜËÉΩÂäõÔºåËÄå‰∏çÂÜçÂçïÁ∫Ø‰æùËµñ‰∫éÂ§ßÊ®°ÂûãÁöÑËí∏È¶èÂíåÁõëÁù£ÂæÆË∞É„ÄÇÂÆûÈ™åË°®ÊòéÔºåÂ∞èËßÑÊ®°LLMsÈÄöËøá‰∏éÁéØÂ¢ÉÁöÑÈó≠ÁéØ‰∫§‰∫íËÉΩÂ§üÂÆûÁé∞ÊúâÊïàÁöÑÊé®ÁêÜÊÄßËÉΩÔºåÁîöËá≥Âú®Ëá™‰∏ªÈ©æÈ©∂Âú∫ÊôØ‰∏≠Ë∂ÖË∂ä‰∫ÜÂü∫‰∫éÁõëÁù£ÂæÆË∞ÉÁöÑÂü∫Á∫øÔºåÂ±ïÁ§∫‰∫ÜÂ∞èÂûãLLMsÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÊΩúÂäõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâÊú∫Âô®‰∫∫Á≥ªÁªüÂú®ÂµåÂÖ•ÂºèÁéØÂ¢É‰∏≠ÂØπÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑ‰æùËµñÈóÆÈ¢òÔºåÁé∞ÊúâÊñπÊ≥ïÂú®ËÆ°ÁÆóÂíåÂÜÖÂ≠òÊñπÈù¢Â≠òÂú®ÊòæËëóÈôêÂà∂ÔºåÂΩ±Âìç‰∫ÜÊô∫ËÉΩÊé®ÁêÜËÉΩÂäõÁöÑÂèëÊå•„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÈÄöËøáÂ∞ÜR1-ZeroÊñπÊ≥ïÊâ©Â±ïÂà∞Èó≠ÁéØÂº∫ÂåñÂ≠¶‰π†Ê°ÜÊû∂ÔºåÂÖÅËÆ∏Â∞èËßÑÊ®°LLMsÈÄöËøá‰∏éÁéØÂ¢ÉÁöÑ‰∫§‰∫íËøõË°åÂ≠¶‰π†Ôºå‰ªéËÄåÊèêÂçáÊé®ÁêÜËÉΩÂäõÔºåËÄå‰∏ç‰æùËµñ‰∫é‰º†ÁªüÁöÑÁõëÁù£ÂæÆË∞É„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨ÁéØÂ¢É‰∫§‰∫íÊ®°Âùó„ÄÅÂèçÈ¶àÂ≠¶‰π†Ê®°ÂùóÂíåÊé®ÁêÜÊ®°Âùó„ÄÇÊú∫Âô®‰∫∫ÈÄöËøá‰∏éÁéØÂ¢ÉÁöÑÈó≠ÁéØ‰∫§‰∫íËé∑ÂèñÂèçÈ¶àÔºåËøõËÄåË∞ÉÊï¥ÂÖ∂Ë°å‰∏∫Á≠ñÁï•ÔºåÊèêÂçáÊô∫ËÉΩÂÜ≥Á≠ñËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞Âú®‰∫éÈÄöËøáÈó≠ÁéØÂº∫ÂåñÂ≠¶‰π†ÂÆûÁé∞Â∞èÂûãLLMsÁöÑÊúâÊïàÊé®ÁêÜÔºåÁ™ÅÁ†¥‰∫Ü‰º†Áªü‰æùËµñÂ§ßÂûãÊ®°ÂûãÁöÑÂ±ÄÈôêÔºåÂ±ïÁ§∫‰∫ÜÂ∞èÊ®°ÂûãÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÊΩúÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠ÔºåÈááÁî®‰∫ÜÁâπÂÆöÁöÑÊçüÂ§±ÂáΩÊï∞Êù•‰ºòÂåñÊ®°ÂûãÁöÑÂèçÈ¶àÂ≠¶‰π†ËÉΩÂäõÔºåÂπ∂ËÆæËÆ°‰∫ÜÈÄÇÂêàÂ∞èËßÑÊ®°Ê®°ÂûãÁöÑÁΩëÁªúÁªìÊûÑÔºå‰ª•Á°Æ‰øùÂú®ËµÑÊ∫êÂèóÈôêÁöÑÊÉÖÂÜµ‰∏ã‰ªçËÉΩÂÆûÁé∞È´òÊïàÁöÑÊé®ÁêÜ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåQwen2.5-1.5BÊ®°ÂûãÂú®Ëá™‰∏ªÈ©æÈ©∂‰ªªÂä°‰∏≠Áõ∏ÊØîÂü∫Á∫øÊèêÂçá‰∫Ü20.2‰∏™ÁôæÂàÜÁÇπÔºåËÄåQwen2.5-3BÊ®°ÂûãÁöÑÊéßÂà∂ÈÄÇÂ∫îÊÄßÂæóÂàÜ‰∏∫63.3%ÔºåË∂ÖË∂ä‰∫Ü‰∫ëÁ´ØÂ§ßÂûãÊ®°ÂûãGPT-4oÁöÑ58.5%„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéÂ∞èÂûãLLMsÂú®ÁéØÂ¢ÉÂèçÈ¶àÂ≠¶‰π†‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Ëá™‰∏ªÈ©æÈ©∂„ÄÅÊô∫ËÉΩÂÆ∂Â±ÖÊú∫Âô®‰∫∫ÂíåÊúçÂä°Êú∫Âô®‰∫∫Á≠â„ÄÇÈÄöËøáÂÆûÁé∞Â∞èÂûãLLMsÁöÑÂµåÂÖ•ÂºèÊô∫ËÉΩÔºåÊú∫Âô®‰∫∫ËÉΩÂ§üÂú®Â§çÊùÇÁöÑÁé∞ÂÆûÁéØÂ¢É‰∏≠Ëá™‰∏ªÂÜ≥Á≠ñÔºåÊèêÂçáÂÖ∂ÈÄÇÂ∫îÊÄßÂíåÂÆûÁî®ÊÄßÔºåÊú™Êù•ÂèØËÉΩÂú®ÂêÑÁ±ªÊú∫Âô®‰∫∫Â∫îÁî®‰∏≠ÂèëÊå•ÈáçË¶Å‰ΩúÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Future robotic systems operating in real-world environments will require on-board embodied intelligence without continuous cloud connection, balancing capabilities with constraints on computational power and memory. This work presents an extension of the R1-zero approach, which enables the usage of low parameter-count Large Language Models (LLMs) in the robotic domain. The R1-Zero approach was originally developed to enable mathematical reasoning in LLMs using static datasets. We extend it to the robotics domain through integration in a closed-loop Reinforcement Learning (RL) framework. This extension enhances reasoning in Embodied Artificial Intelligence (Embodied AI) settings without relying solely on distillation of large models through Supervised Fine-Tuning (SFT). We show that small-scale LLMs can achieve effective reasoning performance by learning through closed-loop interaction with their environment, which enables tasks that previously required significantly larger models. In an autonomous driving setting, a performance gain of 20.2%-points over the SFT-based baseline is observed with a Qwen2.5-1.5B model. Using the proposed training procedure, Qwen2.5-3B achieves a 63.3% control adaptability score, surpassing the 58.5% obtained by the much larger, cloud-bound GPT-4o. These results highlight that practical, on-board deployment of small LLMs is not only feasible but can outperform larger models if trained through environmental feedback, underscoring the importance of an interactive learning framework for robotic Embodied AI, one grounded in practical experience rather than static supervision.

