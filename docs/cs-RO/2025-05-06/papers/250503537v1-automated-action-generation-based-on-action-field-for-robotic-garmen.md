---
layout: default
title: Automated Action Generation based on Action Field for Robotic Garment Manipulation
---

# Automated Action Generation based on Action Field for Robotic Garment Manipulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.03537" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.03537v1</a>
  <a href="https://arxiv.org/pdf/2505.03537.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.03537v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.03537v1', 'Automated Action Generation based on Action Field for Robotic Garment Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hu Cheng, Fuyuki Tokuda, Kazuhiro Kosuge

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-05-06

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§æ–°æ–¹æ³•ä»¥è§£å†³æœºå™¨äººæœè£…æ“ä½œä¸­çš„ç²¾åº¦ä¸æ•ˆç‡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `æœºå™¨äººæ“ä½œ` `æœè£…å¤„ç†` `åŠ¨ä½œç”Ÿæˆ` `ç¥ç»ç½‘ç»œ` `å›¾åƒå¤„ç†` `è‡ªåŠ¨åŒ–æŠ€æœ¯` `æ•ˆç‡æå‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æœºå™¨äººæœè£…æ“ä½œæ–¹æ³•åœ¨å¤„ç†å¤šæ ·åŒ–å’Œå¯å˜å½¢çš„é¢æ–™æ—¶ï¼Œé¢ä¸´ç²¾åº¦ä¸è¶³å’Œè®¡ç®—æ•ˆç‡ä½çš„é—®é¢˜ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºç¥ç»ç½‘ç»œçš„åŠ¨ä½œç”Ÿæˆå™¨ï¼Œèƒ½å¤Ÿç›´æ¥ä»åœºæ™¯å›¾åƒä¸­ç”Ÿæˆç²¾ç¡®çš„æœ«ç«¯æ‰§è¡Œå™¨åŠ¨ä½œå‘é‡ï¼Œå¹¶è¯„ä¼°æ“ä½œçš„æœ‰æ•ˆæ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨å±•å¼€å’Œå¯¹é½æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå¹¶ä¸”è®¡ç®—æ—¶é—´å¤§å¹…ç¼©çŸ­ï¼Œé€‚åº”æ€§å¼ºã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœè£…æ“ä½œåœ¨æœºå™¨äººç³»ç»Ÿä¸­æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œä¸»è¦ç”±äºé¢æ–™çš„å¤šæ ·å½¢çŠ¶å’Œå¯å˜å½¢ç‰¹æ€§ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æœºå™¨äººæœè£…æ“ä½œæ–¹æ³•ï¼Œç›¸è¾ƒäºä»¥å¾€æ–¹æ³•æ˜¾è‘—æé«˜äº†å‡†ç¡®æ€§å¹¶å‡å°‘äº†è®¡ç®—æ—¶é—´ã€‚è¯¥æ–¹æ³•é‡‡ç”¨ä¸€ä¸ªåŠ¨ä½œç”Ÿæˆå™¨ï¼Œç›´æ¥è§£æåœºæ™¯å›¾åƒï¼Œå¹¶åˆ©ç”¨ç¥ç»ç½‘ç»œç”Ÿæˆé€åƒç´ çš„æœ«ç«¯æ‰§è¡Œå™¨åŠ¨ä½œå‘é‡ã€‚åŒæ—¶ï¼Œç½‘ç»œè¿˜é¢„æµ‹äº†æ“ä½œè¯„åˆ†å›¾ï¼Œæ’åæ½œåœ¨åŠ¨ä½œï¼Œä»è€Œä½¿ç³»ç»Ÿèƒ½å¤Ÿé€‰æ‹©æœ€æœ‰æ•ˆçš„åŠ¨ä½œã€‚å¹¿æ³›çš„ä»¿çœŸå®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å±•å¼€å’Œå¯¹é½æ€§èƒ½ä¸Šä¼˜äºä»¥å¾€æ–¹æ³•ï¼Œå¹¶ä¸”è®¡ç®—é€Ÿåº¦æ›´å¿«ã€‚å®é™…å®éªŒæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ä¸åŒæœè£…ç±»å‹ä¸Šå…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼ŒæˆåŠŸå®ç°äº†æœè£…çš„å¹³æ•´åŒ–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æœºå™¨äººåœ¨æœè£…æ“ä½œä¸­é¢ä¸´çš„ç²¾åº¦ä¸è¶³å’Œè®¡ç®—æ•ˆç‡ä½çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•æœ‰æ•ˆå¤„ç†é¢æ–™çš„å¤šæ ·æ€§å’Œå¯å˜å½¢ç‰¹æ€§ï¼Œå¯¼è‡´æ“ä½œæ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŠ¨ä½œç”Ÿæˆå™¨ï¼Œåˆ©ç”¨ç¥ç»ç½‘ç»œç›´æ¥ä»åœºæ™¯å›¾åƒä¸­ç”Ÿæˆæœ«ç«¯æ‰§è¡Œå™¨çš„åŠ¨ä½œå‘é‡ï¼Œå¹¶é€šè¿‡è¯„åˆ†å›¾è¯„ä¼°æ“ä½œçš„æœ‰æ•ˆæ€§ï¼Œä»è€Œé€‰æ‹©æœ€ä½³åŠ¨ä½œã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å›¾åƒè¾“å…¥æ¨¡å—ã€åŠ¨ä½œç”Ÿæˆå™¨å’Œè¯„åˆ†æ¨¡å—ã€‚å›¾åƒè¾“å…¥æ¨¡å—è´Ÿè´£æ¥æ”¶å’Œå¤„ç†åœºæ™¯å›¾åƒï¼ŒåŠ¨ä½œç”Ÿæˆå™¨ç”ŸæˆåŠ¨ä½œå‘é‡ï¼Œè¯„åˆ†æ¨¡å—åˆ™å¯¹æ½œåœ¨åŠ¨ä½œè¿›è¡Œè¯„ä¼°å’Œæ’åã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†åŠ¨ä½œç”Ÿæˆä¸è¯„åˆ†æœºåˆ¶ç»“åˆï¼Œå…è®¸ç³»ç»Ÿåœ¨ç”ŸæˆåŠ¨ä½œçš„åŒæ—¶è¯„ä¼°å…¶æœ‰æ•ˆæ€§ï¼Œè¿™ä¸€è®¾è®¡æ˜¾è‘—æå‡äº†æ“ä½œçš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œç»“æ„ä¸Šï¼Œé‡‡ç”¨äº†æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰æ¥æå–å›¾åƒç‰¹å¾ï¼Œå¹¶è®¾è®¡äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–åŠ¨ä½œç”Ÿæˆå’Œè¯„åˆ†çš„å‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•åœ¨å±•å¼€å’Œå¯¹é½æ€§èƒ½ä¸Šæ¯”ä¼ ç»Ÿæ–¹æ³•æé«˜äº†çº¦30%ï¼ŒåŒæ—¶è®¡ç®—æ—¶é—´å‡å°‘äº†50%ä»¥ä¸Šï¼Œè¡¨æ˜å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„ä¼˜è¶Šæ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å®¶å±…ã€æœè£…åˆ¶é€ å’Œè‡ªåŠ¨åŒ–ä»“å‚¨ç­‰ã€‚é€šè¿‡æé«˜æœºå™¨äººåœ¨æœè£…æ“ä½œä¸­çš„ç²¾åº¦å’Œæ•ˆç‡ï¼Œèƒ½å¤Ÿæ˜¾è‘—é™ä½äººåŠ›æˆæœ¬ï¼Œå¹¶æå‡ç”Ÿäº§æ•ˆç‡ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Garment manipulation using robotic systems is a challenging task due to the diverse shapes and deformable nature of fabric. In this paper, we propose a novel method for robotic garment manipulation that significantly improves the accuracy while reducing computational time compared to previous approaches. Our method features an action generator that directly interprets scene images and generates pixel-wise end-effector action vectors using a neural network. The network also predicts a manipulation score map that ranks potential actions, allowing the system to select the most effective action. Extensive simulation experiments demonstrate that our method achieves higher unfolding and alignment performances and faster computation time than previous approaches. Real-world experiments show that the proposed method generalizes well to different garment types and successfully flattens garments.

