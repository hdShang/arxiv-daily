---
layout: default
title: Towards Safe Maneuvering of Double-Ackermann-Steering Robots with a Soft Actor-Critic Framework
---

# Towards Safe Maneuvering of Double-Ackermann-Steering Robots with a Soft Actor-Critic Framework

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.10332" target="_blank" class="toolbar-btn">arXiv: 2510.10332v2</a>
    <a href="https://arxiv.org/pdf/2510.10332.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.10332v2" 
            onclick="toggleFavorite(this, '2510.10332v2', 'Towards Safe Maneuvering of Double-Ackermann-Steering Robots with a Soft Actor-Critic Framework')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Kohio Deflesselle, M√©lodie Daniel, Aly Magassouba, Miguel Aranda, Olivier Ly

**ÂàÜÁ±ª**: cs.RO, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-11 (Êõ¥Êñ∞: 2025-10-14)

**Â§áÊ≥®**: 4 pages, 3 figures, 2 tables, Accepted for Safety of Intelligent and Autonomous Vehicles: Formal Methods vs. Machine Learning approaches for reliable navigation (SIAV-FM2L) an IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2025) workshop

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éSACÁöÑÊ∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†Ê°ÜÊû∂ÔºåÁî®‰∫éÂèåÈòøÂÖãÊõºËΩ¨ÂêëÊú∫Âô®‰∫∫ÁöÑÂÆâÂÖ®ÊìçÊéß**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Ê∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†` `ËΩØÊºîÂëò-ËØÑËÆ∫ÂÆ∂ÁÆóÊ≥ï` `ÂèåÈòøÂÖãÊõºËΩ¨ÂêëÊú∫Âô®‰∫∫` `ÂÆâÂÖ®ÊìçÊéß` `ÂêéËßÅ‰πãÊòéÁªèÈ™åÂõûÊîæ` `Êú∫Âô®‰∫∫ÂØºËà™` `ËøêÂä®ËßÑÂàí` `ÂõõËΩÆËΩ¨Âêë`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ÂèåÈòøÂÖãÊõºËΩ¨ÂêëÊú∫Âô®‰∫∫ËøêÂä®Â≠¶Á∫¶ÊùüÂº∫Ôºå‰º†ÁªüËßÑÂàíÂô®Âú®Â§çÊùÇÁéØÂ¢ÉÂ§±ÊïàÔºåÈöæ‰ª•ÂÆâÂÖ®ÊìçÊéß„ÄÇ
2. Âà©Áî®SACÊ°ÜÊû∂ÔºåÁªìÂêàHERÂíåCrossQÔºåÈºìÂä±Êú∫Âô®‰∫∫È´òÊïàÊìçÊéßÂπ∂ÈÅøÂÖçÁ¢∞Êíû„ÄÇ
3. ‰ªøÁúüÁªìÊûúË°®ÊòéÔºåËØ•Á≠ñÁï•ËÉΩ‰ª•È´òÊàêÂäüÁéáÔºà97%ÔºâÂà∞ËææÁõÆÊ†áÁÇπÔºåÂêåÊó∂ÊúâÊïàÈÅøÈöú„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éËΩØÊºîÂëò-ËØÑËÆ∫ÂÆ∂(SAC)ÁöÑÊ∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†Ê°ÜÊû∂ÔºåÁî®‰∫éÂèåÈòøÂÖãÊõºËΩ¨ÂêëÁßªÂä®Êú∫Âô®‰∫∫(DASMRs)ÁöÑÂÆâÂÖ®ÂíåÁ≤æÁ°ÆÊìçÊéß„ÄÇ‰∏éÂÖ®ÂêëÊàñÊõ¥ÁÆÄÂçïÁöÑÈùûÂÖ®ÂêëÊú∫Âô®‰∫∫(Â¶ÇÂ∑ÆÈÄüÈ©±Âä®Êú∫Âô®‰∫∫)‰∏çÂêåÔºåDASMRsÈù¢‰∏¥ÁùÄÂæàÂº∫ÁöÑËøêÂä®Â≠¶Á∫¶ÊùüÔºåËøô‰ΩøÂæóÁªèÂÖ∏ËßÑÂàíÂô®Âú®ÊùÇ‰π±ÁéØÂ¢É‰∏≠ÂèòÂæóËÑÜÂº±„ÄÇÊàë‰ª¨ÁöÑÊ°ÜÊû∂Âà©Áî®ÂêéËßÅ‰πãÊòéÁªèÈ™åÂõûÊîæ(HER)ÂíåCrossQÂè†Âä†Êù•ÊèêÈ´òÊìçÊéßÊïàÁéáÔºåÂêåÊó∂ÈÅøÂºÄÈöúÁ¢çÁâ©„ÄÇÂØπÈáçÂûãÂõõËΩÆËΩ¨ÂêëÊº´Ê∏∏ËΩ¶ÁöÑ‰ªøÁúüÁªìÊûúË°®ÊòéÔºåÂ≠¶‰π†Âà∞ÁöÑÁ≠ñÁï•ÂèØ‰ª•Á®≥ÂÅ•Âú∞Âà∞ËææÈ´òËææ97%ÁöÑÁõÆÊ†á‰ΩçÁΩÆÔºåÂêåÊó∂ÈÅøÂºÄÈöúÁ¢çÁâ©„ÄÇÊàë‰ª¨ÁöÑÊ°ÜÊû∂‰∏ç‰æùËµñ‰∫éÊâãÂ∑•Âà∂‰ΩúÁöÑËΩ®ËøπÊàñ‰∏ìÂÆ∂ÊºîÁ§∫„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥ÂèåÈòøÂÖãÊõºËΩ¨ÂêëÁßªÂä®Êú∫Âô®‰∫∫Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÂÆâÂÖ®„ÄÅÁ≤æÁ°ÆÊìçÊéßÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÔºåÂ¶Ç‰º†ÁªüËßÑÂàíÂô®ÔºåÁî±‰∫éDASMRsÂº∫ÁÉàÁöÑËøêÂä®Â≠¶Á∫¶ÊùüÔºåÂú®ÊùÇ‰π±ÁéØÂ¢É‰∏≠Ë°®Áé∞ËÑÜÂº±ÔºåÈöæ‰ª•ÁîüÊàêÂèØË°åÁöÑËΩ®Ëøπ„ÄÇÊ≠§Â§ñÔºåÊâãÂ∑•ËÆæËÆ°ÁöÑËΩ®ËøπÊàñ‰∏ìÂÆ∂ÊºîÁ§∫ÊàêÊú¨È´òÊòÇ‰∏îÊ≥õÂåñËÉΩÂäõÊúâÈôê„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Ê∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†ÔºåÁâπÂà´ÊòØSoft Actor-Critic (SAC)ÁÆóÊ≥ïÔºåÂ≠¶‰π†‰∏Ä‰∏™ËÉΩÂ§üÁõ¥Êé•‰ªéÁéØÂ¢ÉÁä∂ÊÄÅÊò†Â∞ÑÂà∞ÊéßÂà∂Âä®‰ΩúÁöÑÁ≠ñÁï•„ÄÇÈÄöËøáÂ•ñÂä±ÂáΩÊï∞ÁöÑËÆæËÆ°ÔºåÈºìÂä±Êú∫Âô®‰∫∫Âà∞ËææÁõÆÊ†á‰ΩçÁΩÆÂπ∂ÈÅøÂÖçÁ¢∞ÊíûÔºå‰ªéËÄåÂÆûÁé∞ÂÆâÂÖ®È´òÊïàÁöÑÊìçÊéß„ÄÇÁªìÂêàHindsight Experience Replay (HER)ÂíåCrossQÔºåËøõ‰∏ÄÊ≠•ÊèêÂçáÂ≠¶‰π†ÊïàÁéáÂíåÂÆâÂÖ®ÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊ°ÜÊû∂Âü∫‰∫éSACÁÆóÊ≥ïÔºåÂåÖÊã¨ActorÁΩëÁªúÂíåCriticÁΩëÁªú„ÄÇActorÁΩëÁªúË¥üË¥£ÁîüÊàêÊéßÂà∂Âä®‰ΩúÔºåCriticÁΩëÁªúË¥üË¥£ËØÑ‰º∞ÂΩìÂâçÁä∂ÊÄÅ-Âä®‰ΩúÂØπÁöÑ‰ª∑ÂÄº„ÄÇHERÁî®‰∫é‰ªéÂ§±Ë¥•ÁöÑÁªèÈ™å‰∏≠Â≠¶‰π†ÔºåÊèêÈ´òÊ†∑Êú¨Âà©Áî®Áéá„ÄÇCrossQÂàôÈÄöËøáÂºïÂÖ•È¢ùÂ§ñÁöÑQÂáΩÊï∞ÔºåÁî®‰∫éËØÑ‰º∞Á≠ñÁï•ÁöÑÂÆâÂÖ®ÊÄßÔºåÈÅøÂÖçÊé¢Á¥¢ËøáÁ®ã‰∏≠Âá∫Áé∞Âç±Èô©Ë°å‰∏∫„ÄÇËÆ≠ÁªÉËøáÁ®ãÂú®‰ªøÁúüÁéØÂ¢É‰∏≠ËøõË°åÔºåÈÄöËøá‰∏çÊñ≠‰∏éÁéØÂ¢É‰∫§‰∫íÔºå‰ºòÂåñActorÂíåCriticÁΩëÁªú„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜSACÁÆóÊ≥ïÂ∫îÁî®‰∫éDASMRsÁöÑÊìçÊéßÈóÆÈ¢òÔºåÂπ∂ÁªìÂêàHERÂíåCrossQÊù•Ëß£ÂÜ≥Â≠¶‰π†ÊïàÁéáÂíåÂÆâÂÖ®ÊÄßÈóÆÈ¢ò„ÄÇ‰∏é‰º†ÁªüÁöÑÂü∫‰∫éËßÑÂàíÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÁõ¥Êé•Â≠¶‰π†ÊéßÂà∂Á≠ñÁï•ÔºåÊó†ÈúÄÊâãÂ∑•ËÆæËÆ°ËΩ®ËøπÊàñ‰∏ìÂÆ∂ÊºîÁ§∫„ÄÇCrossQÁöÑÂºïÂÖ•ÊòØ‰øùËØÅÂÆâÂÖ®ÊÄßÁöÑÈáçË¶ÅÊâãÊÆµÔºåËÉΩÂ§üÊúâÊïàÈÅøÂÖçÊé¢Á¥¢ËøáÁ®ã‰∏≠ÁöÑÁ¢∞Êíû„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂ•ñÂä±ÂáΩÊï∞ÁöÑËÆæËÆ°Ëá≥ÂÖ≥ÈáçË¶ÅÔºåÂåÖÊã¨Âà∞ËææÁõÆÊ†á‰ΩçÁΩÆÁöÑÂ•ñÂä±„ÄÅÁ¢∞ÊíûÊÉ©ÁΩö‰ª•ÂèäÊéßÂà∂Âä®‰ΩúÁöÑÊ≠£ÂàôÂåñÈ°π„ÄÇHERÈÄöËøáÂ∞ÜÂ§±Ë¥•ÁöÑÁªèÈ™åËΩ¨Âåñ‰∏∫ÊàêÂäüÁöÑÁªèÈ™åÔºåÊèêÈ´ò‰∫ÜÊ†∑Êú¨Âà©Áî®Áéá„ÄÇCrossQÈÄöËøáÂºïÂÖ•È¢ùÂ§ñÁöÑQÂáΩÊï∞ÔºåÁî®‰∫éËØÑ‰º∞Á≠ñÁï•ÁöÑÂÆâÂÖ®ÊÄßÔºåÈÅøÂÖçÊé¢Á¥¢ËøáÁ®ã‰∏≠Âá∫Áé∞Âç±Èô©Ë°å‰∏∫„ÄÇActorÂíåCriticÁΩëÁªúÈááÁî®Ê∑±Â∫¶Á•ûÁªèÁΩëÁªúÔºåÂÖ∑‰ΩìÁªìÊûÑÊú™Áü•„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïËÉΩÂ§ü‰ΩøÈáçÂûãÂõõËΩÆËΩ¨ÂêëÊº´Ê∏∏ËΩ¶Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÂÆâÂÖ®Âú∞Âà∞ËææÈ´òËææ97%ÁöÑÁõÆÊ†á‰ΩçÁΩÆÔºåÂêåÊó∂ÊúâÊïàÈÅøÂºÄÈöúÁ¢çÁâ©„ÄÇËØ•ÊñπÊ≥ïÊó†ÈúÄÊâãÂ∑•Âà∂‰ΩúËΩ®ËøπÊàñ‰∏ìÂÆ∂ÊºîÁ§∫ÔºåËÉΩÂ§üËá™‰∏ªÂ≠¶‰π†ÊéßÂà∂Á≠ñÁï•ÔºåÂÖ∑ÊúâËâØÂ•ΩÁöÑÊ≥õÂåñËÉΩÂäõÂíåÈ≤ÅÊ£íÊÄß„ÄÇ‰∏é‰º†ÁªüÁöÑÂü∫‰∫éËßÑÂàíÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÊõ¥Â•ΩÂú∞ÈÄÇÂ∫îÂ§çÊùÇÁéØÂ¢ÉÂíåÂä®ÊÄÅÂèòÂåñ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂêÑÁßçÈúÄË¶ÅÂèåÈòøÂÖãÊõºËΩ¨ÂêëÊú∫Âô®‰∫∫ÁöÑÂú∫ÊôØÔºå‰æãÂ¶ÇÔºöÂÜú‰∏öÊú∫Âô®‰∫∫„ÄÅÁüø‰∏öÊú∫Âô®‰∫∫„ÄÅÁâ©ÊµÅËøêËæìÊú∫Âô®‰∫∫Á≠â„ÄÇÂú®Ëøô‰∫õÂú∫ÊôØ‰∏≠ÔºåÊú∫Âô®‰∫∫ÈúÄË¶ÅÂú®Â§çÊùÇ„ÄÅÈùûÁªìÊûÑÂåñÁöÑÁéØÂ¢É‰∏≠Ëá™‰∏ªÂØºËà™ÂíåÊìçÊéßÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÊèêÈ´òÊú∫Âô®‰∫∫ÁöÑÂÆâÂÖ®ÊÄßÂíåÊïàÁéáÔºåÈôç‰Ωé‰∫∫Â∑•Âπ≤È¢ÑÁöÑÈúÄÊ±ÇÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖÂ∫îÁî®‰ª∑ÂÄº„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> We present a deep reinforcement learning framework based on Soft Actor-Critic (SAC) for safe and precise maneuvering of double-Ackermann-steering mobile robots (DASMRs). Unlike holonomic or simpler non-holonomic robots such as differential-drive robots, DASMRs face strong kinematic constraints that make classical planners brittle in cluttered environments. Our framework leverages the Hindsight Experience Replay (HER) and the CrossQ overlay to encourage maneuvering efficiency while avoiding obstacles. Simulation results with a heavy four-wheel-steering rover show that the learned policy can robustly reach up to 97% of target positions while avoiding obstacles. Our framework does not rely on handcrafted trajectories or expert demonstrations.

