---
layout: default
title: X-VLA: Soft-Prompted Transformer as Scalable Cross-Embodiment Vision-Language-Action Model
---

# X-VLA: Soft-Prompted Transformer as Scalable Cross-Embodiment Vision-Language-Action Model

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.10274" target="_blank" class="toolbar-btn">arXiv: 2510.10274v1</a>
    <a href="https://arxiv.org/pdf/2510.10274.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.10274v1" 
            onclick="toggleFavorite(this, '2510.10274v1', 'X-VLA: Soft-Prompted Transformer as Scalable Cross-Embodiment Vision-Language-Action Model')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Jinliang Zheng, Jianxiong Li, Zhihao Wang, Dongxiu Liu, Xirui Kang, Yuchun Feng, Yinan Zheng, Jiayin Zou, Yilun Chen, Jia Zeng, Ya-Qin Zhang, Jiangmiao Pang, Jingjing Liu, Tai Wang, Xianyuan Zhan

**ÂàÜÁ±ª**: cs.RO, cs.AI, cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-11

**Â§áÊ≥®**: preprint, technical report, 33 pages

**üîó ‰ª£Á†Å/È°πÁõÆ**: [PROJECT_PAGE](https://thu-air-dream.github.io/X-VLA/)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**X-VLAÔºöÂü∫‰∫éËΩØÊèêÁ§∫TransformerÁöÑÂèØÊâ©Â±ïË∑®ÂÖ∑Ë∫´ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°Âûã**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰∏ÉÔºöÂä®‰ΩúÈáçÂÆöÂêë (Motion Retargeting)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°Âûã` `Ë∑®ÂÖ∑Ë∫´Â≠¶‰π†` `ËΩØÊèêÁ§∫Â≠¶‰π†` `Transformer` `Êú∫Âô®‰∫∫Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâVLAÊ®°ÂûãÈöæ‰ª•ÊúâÊïàÂà©Áî®Ë∑®ÂÖ∑Ë∫´Êú∫Âô®‰∫∫Êï∞ÊçÆÁöÑÂºÇÊûÑÊÄßÔºåÈòªÁ¢ç‰∫ÜÈÄöÁî®Êú∫Âô®‰∫∫Â≠¶‰π†ÁöÑÂèëÂ±ï„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫ËΩØÊèêÁ§∫ÊñπÊ≥ïÔºå‰∏∫ÊØè‰∏™Êï∞ÊçÆÊ∫êÂºïÂÖ•ÂèØÂ≠¶‰π†ÂµåÂÖ•Ôºå‰Ωú‰∏∫ÂÖ∑Ë∫´ÁâπÂÆöÊèêÁ§∫ÔºåÊèêÂçáÊ®°ÂûãÂØπÂºÇÊûÑÊï∞ÊçÆÁöÑÂà©Áî®Áéá„ÄÇ
3. X-VLAÊ®°ÂûãÂú®Â§ö‰∏™Ê®°ÊãüÂíåÁúüÂÆûÊú∫Âô®‰∫∫‰ªªÂä°‰∏≠ÂèñÂæóSOTAÊÄßËÉΩÔºåÈ™åËØÅ‰∫ÜÂÖ∂Âú®Ë∑®ÂÖ∑Ë∫´ÈÄÇÂ∫îÊÄßÂíå‰ªªÂä°Ê≥õÂåñÊñπÈù¢ÁöÑ‰ºòÂäø„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÈÄöÁî®ÁöÑËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÔºàVLAÔºâÊ®°Âûã‰æùËµñ‰∫éË∑®Â§öÁßçÊú∫Âô®‰∫∫Âπ≥Âè∞„ÄÅÂ§ßËßÑÊ®°„ÄÅË∑®ÂÖ∑Ë∫´„ÄÅÂºÇÊûÑÊï∞ÊçÆÈõÜÁöÑÊúâÊïàËÆ≠ÁªÉ„ÄÇ‰∏∫‰∫Ü‰øÉËøõÂíåÂà©Áî®‰∏∞ÂØåÂ§öÊ†∑ÁöÑÊú∫Âô®‰∫∫Êï∞ÊçÆÊ∫ê‰∏≠ÁöÑÂºÇÊûÑÊÄßÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑËΩØÊèêÁ§∫ÊñπÊ≥ïÔºåÈÄöËøáÂ∞ÜÊèêÁ§∫Â≠¶‰π†Ê¶ÇÂøµÊ≥®ÂÖ•Ë∑®ÂÖ∑Ë∫´Êú∫Âô®‰∫∫Â≠¶‰π†ÔºåÂπ∂‰∏∫ÊØè‰∏™‰∏çÂêåÁöÑÊï∞ÊçÆÊ∫êÂºïÂÖ•ÂçïÁã¨ÁöÑÂèØÂ≠¶‰π†ÂµåÂÖ•ÈõÜÔºå‰ªéËÄå‰ª•ÊúÄÂ∞èÁöÑÂèÇÊï∞Ê∑ªÂä†ÂÆûÁé∞„ÄÇËøô‰∫õÂµåÂÖ•‰Ωú‰∏∫ÁâπÂÆö‰∫éÂÖ∑Ë∫´ÁöÑÊèêÁ§∫ÔºåÂÖ±ÂêåËµã‰∫àVLAÊ®°ÂûãÊúâÊïàÂà©Áî®‰∏çÂêåË∑®ÂÖ∑Ë∫´ÁâπÂæÅÁöÑËÉΩÂäõ„ÄÇÊàë‰ª¨Êñ∞ÁöÑX-VLAÔºå‰∏Ä‰∏™ÁÆÄÊ¥ÅÁöÑÂü∫‰∫éÊµÅÂåπÈÖçÁöÑVLAÊû∂ÊûÑÔºåÂÆåÂÖ®‰æùËµñ‰∫éËΩØÊèêÁ§∫ÁöÑÊ†áÂáÜTransformerÁºñÁ†ÅÂô®ÔºåÂÖºÂÖ∑ÂèØÊâ©Â±ïÊÄßÂíåÁÆÄÊ¥ÅÊÄß„ÄÇÂú®6‰∏™Ê®°ÊãüÁéØÂ¢ÉÂíå3‰∏™ÁúüÂÆû‰∏ñÁïåÊú∫Âô®‰∫∫‰∏äÁöÑËØÑ‰º∞Ë°®ÊòéÔºåÊàë‰ª¨ÁöÑ0.9BÂÆû‰æãÂåñ-X-VLA-0.9BÂêåÊó∂Âú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠ÂÆûÁé∞‰∫ÜSOTAÊÄßËÉΩÔºåÂú®ÁÅµÊ¥ªÁöÑÁÅµÂ∑ßÊÄßÂà∞Ë∑®ÂÖ∑Ë∫´„ÄÅÁéØÂ¢ÉÂíå‰ªªÂä°ÁöÑÂø´ÈÄüÈÄÇÂ∫îÁ≠âÂπøÊ≥õÁöÑËÉΩÂäõËΩ¥‰∏äÂ±ïÁ§∫‰∫ÜÂçìË∂äÁöÑÁªìÊûú„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÔºàVLAÔºâÊ®°ÂûãÂú®Â§ÑÁêÜÊù•Ëá™‰∏çÂêåÊú∫Âô®‰∫∫Âπ≥Âè∞ÂíåÁéØÂ¢ÉÁöÑÂºÇÊûÑÊï∞ÊçÆÊó∂Èù¢‰∏¥ÊåëÊàò„ÄÇ‰∏çÂêåÂÖ∑Ë∫´ÔºàembodimentÔºâÁöÑÊï∞ÊçÆÂÖ∑Êúâ‰∏çÂêåÁöÑÁâπÂæÅÂíåÂàÜÂ∏ÉÔºåÁõ¥Êé•Ê∑∑ÂêàËÆ≠ÁªÉ‰ºöÂØºËá¥Ê®°ÂûãÊÄßËÉΩ‰∏ãÈôçÔºåÈöæ‰ª•ÂÆûÁé∞ÊúâÊïàÁöÑË∑®ÂÖ∑Ë∫´Ê≥õÂåñ„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏ÈúÄË¶ÅÂ§çÊùÇÁöÑÈ¢ÜÂüüËá™ÈÄÇÂ∫îÊäÄÊúØÊàñÊï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºåÂ¢ûÂä†‰∫ÜËÆ≠ÁªÉÁöÑÂ§çÊùÇÊÄßÂíåÊàêÊú¨„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®ËΩØÊèêÁ§∫Ôºàsoft promptÔºâÂ≠¶‰π†Êù•Âå∫ÂàÜÂíåÂà©Áî®‰∏çÂêåÂÖ∑Ë∫´ÁöÑÊï∞ÊçÆÁâπÂæÅ„ÄÇÈÄöËøá‰∏∫ÊØè‰∏™ÂÖ∑Ë∫´ÂºïÂÖ•‰∏ÄÁªÑÂèØÂ≠¶‰π†ÁöÑÂµåÂÖ•ÂêëÈáè‰Ωú‰∏∫ÊèêÁ§∫ÔºåÊ®°ÂûãÂèØ‰ª•Ê†πÊçÆ‰∏çÂêåÁöÑÂÖ∑Ë∫´Ë∞ÉÊï¥ÂÖ∂Ë°å‰∏∫Ôºå‰ªéËÄåÊõ¥Â•ΩÂú∞ÈÄÇÂ∫îÂºÇÊûÑÊï∞ÊçÆ„ÄÇËøôÁßçÊñπÊ≥ïÂè™ÈúÄË¶ÅÂ∞ëÈáèÈ¢ùÂ§ñÁöÑÂèÇÊï∞ÔºåÂ∞±ÂèØ‰ª•ÊúâÊïàÂú∞ÊèêÈ´òÊ®°ÂûãÁöÑË∑®ÂÖ∑Ë∫´Ê≥õÂåñËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöX-VLAÊ®°ÂûãÂü∫‰∫éTransformerÊû∂ÊûÑÔºå‰∏ªË¶ÅÂåÖÂê´ËßÜËßâÁºñÁ†ÅÂô®„ÄÅËØ≠Ë®ÄÁºñÁ†ÅÂô®ÂíåÂä®‰ΩúËß£Á†ÅÂô®„ÄÇËßÜËßâÁºñÁ†ÅÂô®ÂíåËØ≠Ë®ÄÁºñÁ†ÅÂô®Â∞ÜËæìÂÖ•ÂõæÂÉèÂíåÊñáÊú¨Êåá‰ª§ËΩ¨Êç¢‰∏∫ÂµåÂÖ•ÂêëÈáèÔºåÁÑ∂ÂêéÈÄöËøá‰∫§ÂèâÊ≥®ÊÑèÂäõÊú∫Âà∂ËøõË°åËûçÂêà„ÄÇÂä®‰ΩúËß£Á†ÅÂô®Ê†πÊçÆËûçÂêàÂêéÁöÑÁâπÂæÅÁîüÊàêÊú∫Âô®‰∫∫Âä®‰Ωú„ÄÇÂÖ≥ÈîÆÂú®‰∫éÔºåÂú®ËßÜËßâÁºñÁ†ÅÂô®ÂíåËØ≠Ë®ÄÁºñÁ†ÅÂô®ÁöÑËæìÂÖ•Á´ØÔºå‰∏∫ÊØè‰∏™ÂÖ∑Ë∫´Ê∑ªÂä†‰∏Ä‰∏™ÂèØÂ≠¶‰π†ÁöÑËΩØÊèêÁ§∫ÂµåÂÖ•„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜËΩØÊèêÁ§∫Â≠¶‰π†Â∫îÁî®‰∫éË∑®ÂÖ∑Ë∫´Êú∫Âô®‰∫∫Â≠¶‰π†„ÄÇ‰∏é‰º†ÁªüÁöÑÁ°¨ÊèêÁ§∫Ôºàhard promptÔºâ‰∏çÂêåÔºåËΩØÊèêÁ§∫ÊòØÂèØÂ≠¶‰π†ÁöÑÔºåÂèØ‰ª•Ê†πÊçÆÊï∞ÊçÆËøõË°å‰ºòÂåñÔºå‰ªéËÄåÊõ¥Â•ΩÂú∞ÈÄÇÂ∫î‰∏çÂêåÂÖ∑Ë∫´ÁöÑÁâπÂæÅ„ÄÇÊ≠§Â§ñÔºåX-VLAÊ®°ÂûãÈááÁî®‰∫Ü‰∏ÄÁßçÁÆÄÊ¥ÅÁöÑÂü∫‰∫éÊµÅÂåπÈÖçÔºàflow-matchingÔºâÁöÑVLAÊû∂ÊûÑÔºåËøõ‰∏ÄÊ≠•ÊèêÈ´ò‰∫ÜÊ®°ÂûãÁöÑÊïàÁéáÂíåÂèØÊâ©Â±ïÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÊØè‰∏™ÂÖ∑Ë∫´ÁöÑËΩØÊèêÁ§∫ÂµåÂÖ•ÈÉΩÊòØ‰∏Ä‰∏™ÂèØÂ≠¶‰π†ÁöÑÂêëÈáèÔºåÂÖ∂Áª¥Â∫¶‰∏éTransformerÁºñÁ†ÅÂô®ÁöÑËæìÂÖ•Áª¥Â∫¶Áõ∏Âêå„ÄÇÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠ÔºåËΩØÊèêÁ§∫ÂµåÂÖ•‰∏éËæìÂÖ•ÂõæÂÉèÊàñÊñáÊú¨Êåá‰ª§ÁöÑÂµåÂÖ•ÂêëÈáèËøõË°åÊãºÊé•ÔºåÁÑ∂ÂêéËæìÂÖ•Âà∞TransformerÁºñÁ†ÅÂô®‰∏≠„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨Âä®‰ΩúÈ¢ÑÊµãÊçüÂ§±ÂíåÊµÅÂåπÈÖçÊçüÂ§±ÔºåÁî®‰∫é‰ºòÂåñÊ®°ÂûãÁöÑÂä®‰ΩúÁîüÊàêËÉΩÂäõÂíåË∑®ÂÖ∑Ë∫´Ê≥õÂåñËÉΩÂäõ„ÄÇÊ®°ÂûãÂèÇÊï∞Èáè‰∏∫0.9B„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

X-VLA-0.9BÊ®°ÂûãÂú®6‰∏™Ê®°ÊãüÁéØÂ¢ÉÂíå3‰∏™ÁúüÂÆû‰∏ñÁïåÊú∫Âô®‰∫∫‰∏äÁöÑÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÂÖ∂Âú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠ÂÆûÁé∞‰∫ÜSOTAÊÄßËÉΩ„ÄÇ‰æãÂ¶ÇÔºåÂú®Dexterity‰ªªÂä°‰∏≠ÔºåX-VLAÊ®°ÂûãÊØîÁé∞ÊúâÊúÄ‰Ω≥Ê®°ÂûãÊèêÈ´ò‰∫Ü10%‰ª•‰∏äÁöÑÊàêÂäüÁéá„ÄÇÊ≠§Â§ñÔºåX-VLAÊ®°ÂûãËøòÂ±ïÁ§∫‰∫ÜËâØÂ•ΩÁöÑË∑®ÂÖ∑Ë∫´ÈÄÇÂ∫îËÉΩÂäõÔºåËÉΩÂ§üÂú®Êñ∞ÁöÑÊú∫Âô®‰∫∫Âπ≥Âè∞‰∏äÂø´ÈÄüÂ≠¶‰π†ÂíåÊâßË°å‰ªªÂä°„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂêÑÁßçÊú∫Âô®‰∫∫Â∫îÁî®Âú∫ÊôØÔºå‰æãÂ¶ÇÂÆ∂Â∫≠ÊúçÂä°Êú∫Âô®‰∫∫„ÄÅÂ∑•‰∏öÊú∫Âô®‰∫∫ÂíåÂåªÁñóÊú∫Âô®‰∫∫„ÄÇÈÄöËøáÂà©Áî®Ë∑®ÂÖ∑Ë∫´Â≠¶‰π†ÔºåÊú∫Âô®‰∫∫ÂèØ‰ª•Âø´ÈÄüÈÄÇÂ∫îÊñ∞ÁöÑÁéØÂ¢ÉÂíå‰ªªÂä°ÔºåÊèêÈ´òÂÖ∂ÁÅµÊ¥ªÊÄßÂíåÈÄöÁî®ÊÄß„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïËøòÂèØ‰ª•Áî®‰∫éÊú∫Âô®‰∫∫Áæ§‰ΩìÁöÑÂçèÂêåÂ≠¶‰π†Ôºå‰ΩøÂ§ö‰∏™Êú∫Âô®‰∫∫ËÉΩÂ§üÂÖ±‰∫´Áü•ËØÜÂíåÁªèÈ™åÔºå‰ªéËÄåÊèêÈ´òÊï¥‰ΩìÊÄßËÉΩ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Successful generalist Vision-Language-Action (VLA) models rely on effective training across diverse robotic platforms with large-scale, cross-embodiment, heterogeneous datasets. To facilitate and leverage the heterogeneity in rich, diverse robotic data sources, we propose a novel Soft Prompt approach with minimally added parameters, by infusing prompt learning concepts into cross-embodiment robot learning and introducing separate sets of learnable embeddings for each distinct data source. These embeddings serve as embodiment-specific prompts, which in unity empower VLA models with effective exploitation of varying cross-embodiment features. Our new X-VLA, a neat flow-matching-based VLA architecture, relies exclusively on soft-prompted standard Transformer encoders, enjoying both scalability and simplicity. Evaluated across 6 simulations as well as 3 real-world robots, our 0.9B instantiation-X-VLA-0.9B simultaneously achieves SOTA performance over a sweep of benchmarks, demonstrating superior results on a wide axes of capabilities, from flexible dexterity to quick adaptation across embodiments, environments, and tasks. Website: https://thu-air-dream.github.io/X-VLA/

