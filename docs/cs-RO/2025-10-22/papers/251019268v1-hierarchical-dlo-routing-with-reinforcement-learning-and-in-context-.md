---
layout: default
title: Hierarchical DLO Routing with Reinforcement Learning and In-Context Vision-language Models
---

# Hierarchical DLO Routing with Reinforcement Learning and In-Context Vision-language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.19268" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.19268v1</a>
  <a href="https://arxiv.org/pdf/2510.19268.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.19268v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.19268v1', 'Hierarchical DLO Routing with Reinforcement Learning and In-Context Vision-language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mingen Li, Houjian Yu, Yixuan Huang, Youngjin Hong, Changhyun Choi

**åˆ†ç±»**: cs.RO, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-10-22

**å¤‡æ³¨**: 8 pages, 6 figures, 3 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå¼ºåŒ–å­¦ä¹ å’Œè§†è§‰è¯­è¨€æ¨¡å‹çš„å±‚çº§DLOè·¯å¾„è§„åˆ’æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¯å˜å½¢çº¿æ€§ç‰©ä½“` `è·¯å¾„è§„åˆ’` `è§†è§‰è¯­è¨€æ¨¡å‹` `å¼ºåŒ–å­¦ä¹ ` `å±‚çº§æ§åˆ¶` `æœºå™¨äººæ“ä½œ` `æ•…éšœæ¢å¤`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å·¥ä¸šè£…é…çº¿ä¸­DLOçš„é•¿æ—¶ç¨‹è·¯å¾„è§„åˆ’ä»»åŠ¡æå…·æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥é€‚åº”éçº¿æ€§åŠ¨åŠ›å­¦ï¼Œåˆ†è§£æŠ½è±¡ç›®æ ‡ï¼Œç”Ÿæˆå¤šæ­¥è®¡åˆ’ã€‚
2. è¯¥è®ºæ–‡æå‡ºä¸€ç§å±‚çº§æ¡†æ¶ï¼Œåˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹è¿›è¡Œé«˜å±‚æ¨ç†ï¼Œç”Ÿæˆå¯è¡Œæ–¹æ¡ˆï¼Œå†é€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„åº•å±‚æŠ€èƒ½æ‰§è¡Œã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å„ç§åœºæ™¯ä¸‹å‡è¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼ŒæˆåŠŸç‡æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œè¾¾åˆ°92.5%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§å…¨è‡ªåŠ¨çš„å±‚çº§æ¡†æ¶ï¼Œç”¨äºè§£å†³å…·æœ‰æŒ‘æˆ˜æ€§çš„å¯å˜å½¢çº¿æ€§ç‰©ä½“ï¼ˆDLOï¼‰è·¯å¾„è§„åˆ’ä»»åŠ¡ï¼Œä¾‹å¦‚ç”µç¼†å’Œç»³ç´¢çš„æ“çºµã€‚è¯¥æ¡†æ¶åˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰è¿›è¡Œä¸Šä¸‹æ–‡é«˜å±‚æ¨ç†ï¼Œæ ¹æ®è¯­è¨€è¡¨è¾¾çš„éšå¼æˆ–æ˜¾å¼è·¯å¾„è§„åˆ’ç›®æ ‡ï¼Œåˆæˆå¯è¡Œçš„æ–¹æ¡ˆã€‚ç„¶åï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„åº•å±‚æŠ€èƒ½æ¥æ‰§è¡Œè¿™äº›æ–¹æ¡ˆã€‚ä¸ºäº†æé«˜é•¿æ—¶ç¨‹ä»»åŠ¡çš„é²æ£’æ€§ï¼Œæœ¬æ–‡è¿˜å¼•å…¥äº†ä¸€ç§æ•…éšœæ¢å¤æœºåˆ¶ï¼Œå°†DLOé‡æ–°è°ƒæ•´åˆ°æ˜“äºæ’å…¥çš„çŠ¶æ€ã€‚è¯¥æ–¹æ³•å¯ä»¥æ¨å¹¿åˆ°æ¶‰åŠç‰©ä½“å±æ€§ã€ç©ºé—´æè¿°ä»¥åŠéšå¼è¯­è¨€å‘½ä»¤çš„å„ç§åœºæ™¯ï¼Œåœ¨é•¿æ—¶ç¨‹è·¯å¾„è§„åˆ’åœºæ™¯ä¸­ï¼Œå…¶æ€§èƒ½ä¼˜äºæ¬¡ä¼˜åŸºçº¿æ–¹æ³•è¿‘50%ï¼Œæ€»ä½“æˆåŠŸç‡è¾¾åˆ°92.5%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å·¥ä¸šè£…é…å’Œæ—¥å¸¸ç”Ÿæ´»ä¸­å¸¸è§çš„å¯å˜å½¢çº¿æ€§ç‰©ä½“ï¼ˆDLOï¼‰çš„é•¿æ—¶ç¨‹è·¯å¾„è§„åˆ’é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†æ­¤ç±»ä»»åŠ¡æ—¶ï¼Œé¢ä¸´ç€DLOéçº¿æ€§åŠ¨åŠ›å­¦ã€æŠ½è±¡ç›®æ ‡åˆ†è§£ä»¥åŠå¤šæ­¥è§„åˆ’ç”Ÿæˆç­‰æŒ‘æˆ˜ï¼Œå¯¼è‡´éš¾ä»¥å®ç°å¯é çš„æŠ€èƒ½æ‰§è¡Œå’Œé•¿æ—¶ç¨‹ä»»åŠ¡çš„æˆåŠŸå®Œæˆã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éš¾ä»¥æœ‰æ•ˆåœ°ç»“åˆè§†è§‰ä¿¡æ¯å’Œè¯­è¨€æŒ‡ä»¤ï¼Œè¿›è¡Œé«˜å±‚æ¬¡çš„æ¨ç†å’Œè§„åˆ’ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é‡‡ç”¨å±‚çº§æ§åˆ¶æ¡†æ¶ï¼Œå°†å¤æ‚çš„DLOè·¯å¾„è§„åˆ’ä»»åŠ¡åˆ†è§£ä¸ºé«˜å±‚è§„åˆ’å’Œåº•å±‚æŠ€èƒ½æ‰§è¡Œä¸¤ä¸ªå±‚æ¬¡ã€‚é«˜å±‚è§„åˆ’åˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰è¿›è¡Œä¸Šä¸‹æ–‡æ¨ç†ï¼Œå°†è¯­è¨€æŒ‡ä»¤è½¬åŒ–ä¸ºå¯è¡Œçš„è¡ŒåŠ¨åºåˆ—ã€‚åº•å±‚æŠ€èƒ½åˆ™é€šè¿‡å¼ºåŒ–å­¦ä¹ è¿›è¡Œè®­ç»ƒï¼Œè´Ÿè´£æ‰§è¡Œå…·ä½“çš„DLOæ“ä½œã€‚è¿™ç§åˆ†å±‚ç»“æ„ä½¿å¾—ç³»ç»Ÿèƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†ä»»åŠ¡çš„å¤æ‚æ€§ï¼Œæé«˜è§„åˆ’çš„æ•ˆç‡å’Œé²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶ä¸»è¦åŒ…å«ä¸‰ä¸ªæ¨¡å—ï¼š1) åŸºäºè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰çš„é«˜å±‚è§„åˆ’å™¨ï¼šæ¥æ”¶è§†è§‰è¾“å…¥å’Œè¯­è¨€æŒ‡ä»¤ï¼Œåˆ©ç”¨VLMè¿›è¡Œä¸Šä¸‹æ–‡æ¨ç†ï¼Œç”Ÿæˆä¸€ç³»åˆ—çš„ä¸­é—´ç›®æ ‡ç‚¹æˆ–æ“ä½œæ­¥éª¤ã€‚2) åŸºäºå¼ºåŒ–å­¦ä¹ çš„åº•å±‚æŠ€èƒ½æ‰§è¡Œå™¨ï¼šé€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒå¾—åˆ°ä¸€ç³»åˆ—çš„DLOæ“ä½œæŠ€èƒ½ï¼Œä¾‹å¦‚æŠ“å–ã€ç§»åŠ¨ã€æ’å…¥ç­‰ï¼Œç”¨äºæ‰§è¡Œé«˜å±‚è§„åˆ’å™¨ç”Ÿæˆçš„ä¸­é—´ç›®æ ‡ã€‚3) æ•…éšœæ¢å¤æœºåˆ¶ï¼šåœ¨ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹ä¸­ï¼Œå¦‚æœå‡ºç°é”™è¯¯æˆ–åå·®ï¼Œè¯¥æœºåˆ¶èƒ½å¤Ÿè¯†åˆ«å¹¶çº æ­£é”™è¯¯ï¼Œå°†DLOé‡æ–°è°ƒæ•´åˆ°æ˜“äºæ’å…¥çš„çŠ¶æ€ã€‚æ•´ä¸ªæµç¨‹æ˜¯ï¼šé¦–å…ˆï¼ŒVLMæ ¹æ®è§†è§‰è¾“å…¥å’Œè¯­è¨€æŒ‡ä»¤ç”Ÿæˆé«˜å±‚è§„åˆ’ï¼›ç„¶åï¼Œåº•å±‚æŠ€èƒ½æ‰§è¡Œå™¨æŒ‰ç…§è§„åˆ’é€æ­¥æ‰§è¡ŒDLOæ“ä½œï¼›æœ€åï¼Œæ•…éšœæ¢å¤æœºåˆ¶ç›‘æ§æ‰§è¡Œè¿‡ç¨‹ï¼Œå¹¶åœ¨å¿…è¦æ—¶è¿›è¡Œå¹²é¢„ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰å¼•å…¥åˆ°DLOè·¯å¾„è§„åˆ’ä»»åŠ¡ä¸­ï¼Œåˆ©ç”¨VLMçš„ä¸Šä¸‹æ–‡æ¨ç†èƒ½åŠ›ï¼Œå®ç°äº†åŸºäºè¯­è¨€æŒ‡ä»¤çš„é«˜å±‚è§„åˆ’ã€‚ä¸ä¼ ç»Ÿçš„åŸºäºè§„åˆ™æˆ–ä¼˜åŒ–çš„è§„åˆ’æ–¹æ³•ç›¸æ¯”ï¼ŒVLMèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ä»»åŠ¡çš„è¯­ä¹‰ä¿¡æ¯ï¼Œç”Ÿæˆæ›´åŠ çµæ´»å’Œé²æ£’çš„è§„åˆ’æ–¹æ¡ˆã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æå‡ºäº†ä¸€ç§æ•…éšœæ¢å¤æœºåˆ¶ï¼Œè¿›ä¸€æ­¥æé«˜äº†ç³»ç»Ÿçš„é²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨VLMçš„ä½¿ç”¨ä¸Šï¼Œè®ºæ–‡é‡‡ç”¨äº†in-context learningçš„æ–¹å¼ï¼Œå³é€šè¿‡å°‘é‡çš„ç¤ºä¾‹æ¥å¼•å¯¼VLMç”Ÿæˆåˆé€‚çš„è§„åˆ’æ–¹æ¡ˆã€‚åœ¨å¼ºåŒ–å­¦ä¹ æ–¹é¢ï¼Œè®ºæ–‡é‡‡ç”¨äº†å¸¸ç”¨çš„Actor-Criticç®—æ³•ï¼Œå¹¶è®¾è®¡äº†åˆé€‚çš„å¥–åŠ±å‡½æ•°ï¼Œä»¥é¼“åŠ±æ™ºèƒ½ä½“å­¦ä¹ åˆ°é«˜æ•ˆçš„DLOæ“ä½œæŠ€èƒ½ã€‚æ•…éšœæ¢å¤æœºåˆ¶çš„è®¾è®¡åˆ™ä¾èµ–äºå¯¹DLOçŠ¶æ€çš„å‡†ç¡®ä¼°è®¡ï¼Œä»¥åŠå¯¹å„ç§å¯èƒ½å‡ºç°çš„æ•…éšœæƒ…å†µçš„é¢„åˆ¤ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é•¿æ—¶ç¨‹DLOè·¯å¾„è§„åˆ’ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¸æ¬¡ä¼˜åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•çš„æˆåŠŸç‡æé«˜äº†è¿‘50%ï¼Œè¾¾åˆ°äº†92.5%ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜è¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œèƒ½å¤Ÿé€‚åº”å„ç§ä¸åŒçš„åœºæ™¯å’Œä»»åŠ¡è¦æ±‚ã€‚å®éªŒç»“æœéªŒè¯äº†è¯¥æ–¹æ³•åœ¨è§£å†³å¤æ‚DLOè·¯å¾„è§„åˆ’é—®é¢˜æ–¹é¢çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè‡ªåŠ¨åŒ–è£…é…çº¿ã€åŒ»ç–—æ‰‹æœ¯æœºå™¨äººã€å®¶åº­æœåŠ¡æœºå™¨äººç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨æ±½è½¦è£…é…çº¿ä¸Šï¼Œæœºå™¨äººå¯ä»¥æ ¹æ®å·¥ç¨‹å¸ˆçš„è¯­éŸ³æŒ‡ä»¤ï¼Œè‡ªåŠ¨å®Œæˆç”µç¼†çš„å¸ƒçº¿ä»»åŠ¡ã€‚åœ¨åŒ»ç–—æ‰‹æœ¯ä¸­ï¼ŒåŒ»ç”Ÿå¯ä»¥é€šè¿‡è¯­éŸ³æ§åˆ¶æœºå™¨äººè¿›è¡Œç²¾ç»†çš„ç¼åˆæ“ä½œã€‚åœ¨å®¶åº­ç¯å¢ƒä¸­ï¼Œæœºå™¨äººå¯ä»¥å¸®åŠ©äººä»¬æ•´ç†ç”µçº¿ã€ç»³ç´¢ç­‰ç‰©å“ï¼Œæé«˜ç”Ÿæ´»è´¨é‡ã€‚è¯¥ç ”ç©¶ä¸ºå®ç°æ›´åŠ æ™ºèƒ½ã€çµæ´»çš„æœºå™¨äººæ“ä½œæä¾›äº†æ–°çš„æ€è·¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Long-horizon routing tasks of deformable linear objects (DLOs), such as cables and ropes, are common in industrial assembly lines and everyday life. These tasks are particularly challenging because they require robots to manipulate DLO with long-horizon planning and reliable skill execution. Successfully completing such tasks demands adapting to their nonlinear dynamics, decomposing abstract routing goals, and generating multi-step plans composed of multiple skills, all of which require accurate high-level reasoning during execution. In this paper, we propose a fully autonomous hierarchical framework for solving challenging DLO routing tasks. Given an implicit or explicit routing goal expressed in language, our framework leverages vision-language models~(VLMs) for in-context high-level reasoning to synthesize feasible plans, which are then executed by low-level skills trained via reinforcement learning. To improve robustness in long horizons, we further introduce a failure recovery mechanism that reorients the DLO into insertion-feasible states. Our approach generalizes to diverse scenes involving object attributes, spatial descriptions, as well as implicit language commands. It outperforms the next best baseline method by nearly 50% and achieves an overall success rate of 92.5% across long-horizon routing scenarios.

