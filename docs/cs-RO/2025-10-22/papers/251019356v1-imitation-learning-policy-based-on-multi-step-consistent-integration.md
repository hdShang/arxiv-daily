---
layout: default
title: Imitation Learning Policy based on Multi-Step Consistent Integration Shortcut Model
---

# Imitation Learning Policy based on Multi-Step Consistent Integration Shortcut Model

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.19356" target="_blank" class="toolbar-btn">arXiv: 2510.19356v1</a>
    <a href="https://arxiv.org/pdf/2510.19356.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.19356v1" 
            onclick="toggleFavorite(this, '2510.19356v1', 'Imitation Learning Policy based on Multi-Step Consistent Integration Shortcut Model')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yu Fang, Xinyu Wang, Xuehe Zhang, Wanli Xue, Mingwei Zhang, Shengyong Chen, Jie Zhao

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-22

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éÂ§öÊ≠•‰∏ÄËá¥ÊÄßÁßØÂàÜÊç∑ÂæÑÊ®°ÂûãÁöÑÊ®°‰ªøÂ≠¶‰π†Á≠ñÁï•ÔºåÂä†ÈÄüÊú∫Âô®‰∫∫Á≠ñÁï•Êé®ÁêÜ„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Ê®°‰ªøÂ≠¶‰π†` `ÊµÅÈáèÂåπÈÖç` `Êú∫Âô®‰∫∫ÊéßÂà∂` `ÂçïÊ≠•Êé®ÁêÜ` `Â§öÊ≠•‰∏ÄËá¥ÊÄß` `Ëá™ÈÄÇÂ∫îÊ¢ØÂ∫¶` `Á≠ñÁï•Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂü∫‰∫éÊµÅÈáèÂåπÈÖçÁöÑÊ®°‰ªøÂ≠¶‰π†ÊñπÊ≥ïÊé®ÁêÜÈÄüÂ∫¶ÊÖ¢ÔºåËí∏È¶èÂíå‰∏ÄËá¥ÊÄßÊñπÊ≥ïÊÄßËÉΩ‰∏çË∂≥„ÄÇ
2. ÊèêÂá∫‰∏ÄÁßçÂçïÊ≠•Êç∑ÂæÑÊ®°ÂûãÔºåÁªìÂêàÂ§öÊ≠•‰∏ÄËá¥ÊÄßÊçüÂ§±Ôºå‰ª•Âπ≥Ë°°Êé®ÁêÜÈÄüÂ∫¶ÂíåÊÄßËÉΩ„ÄÇ
3. ÂºïÂÖ•Ëá™ÈÄÇÂ∫îÊ¢ØÂ∫¶ÂàÜÈÖçÊñπÊ≥ïÔºåËß£ÂÜ≥Â§öÊ≠•ÊçüÂ§±‰ºòÂåñ‰∏çÁ®≥ÂÆöÁöÑÈóÆÈ¢òÔºåÊèêÂçáÂ≠¶‰π†Á®≥ÂÆöÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÊµÅÈáèÂåπÈÖçÊñπÊ≥ïÂú®Êú∫Âô®‰∫∫Ê®°‰ªøÂ≠¶‰π†‰∏≠ÂæóÂà∞‰∫ÜÂπøÊ≥õÂ∫îÁî®Ôºå‰ΩÜÊôÆÈÅçÂ≠òÂú®Êé®ÁêÜÊó∂Èó¥ËøáÈïøÁöÑÈóÆÈ¢ò„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÁ†îÁ©∂‰∫∫ÂëòÊèêÂá∫‰∫ÜËí∏È¶èÊñπÊ≥ïÂíå‰∏ÄËá¥ÊÄßÊñπÊ≥ïÔºå‰ΩÜËøô‰∫õÊñπÊ≥ïÁöÑÊÄßËÉΩ‰ªçÁÑ∂Èöæ‰ª•‰∏éÂéüÂßãÁöÑÊâ©Êï£Ê®°ÂûãÂíåÊµÅÈáèÂåπÈÖçÊ®°ÂûãÁõ∏Â™≤Áæé„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÁî®‰∫éÊú∫Âô®‰∫∫Ê®°‰ªøÂ≠¶‰π†ÁöÑÂÖ∑ÊúâÂ§öÊ≠•ÁßØÂàÜÁöÑÂçïÊ≠•Êç∑ÂæÑÊñπÊ≥ï„ÄÇ‰∏∫‰∫ÜÂπ≥Ë°°Êé®ÁêÜÈÄüÂ∫¶ÂíåÊÄßËÉΩÔºåÊàë‰ª¨Âú®Êç∑ÂæÑÊ®°ÂûãÁöÑÂü∫Á°Ä‰∏äÊâ©Â±ï‰∫ÜÂ§öÊ≠•‰∏ÄËá¥ÊÄßÊçüÂ§±ÔºåÂ∞ÜÂçïÊ≠•ÊçüÂ§±ÂàÜËß£‰∏∫Â§öÊ≠•ÊçüÂ§±Ôºå‰ªéËÄåÊèêÈ´ò‰∫ÜÂçïÊ≠•Êé®ÁêÜÁöÑÊÄßËÉΩ„ÄÇÂÖ∂Ê¨°Ôºå‰∏∫‰∫ÜËß£ÂÜ≥Â§öÊ≠•ÊçüÂ§±ÂíåÂéüÂßãÊµÅÈáèÂåπÈÖçÊçüÂ§±‰ºòÂåñ‰∏çÁ®≥ÂÆöÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçËá™ÈÄÇÂ∫îÊ¢ØÂ∫¶ÂàÜÈÖçÊñπÊ≥ïÔºå‰ª•Â¢ûÂº∫Â≠¶‰π†ËøáÁ®ãÁöÑÁ®≥ÂÆöÊÄß„ÄÇÊúÄÂêéÔºåÊàë‰ª¨Âú®‰∏§‰∏™Ê®°ÊãüÂü∫ÂáÜÂíå‰∫î‰∏™ÁúüÂÆûÁéØÂ¢É‰ªªÂä°‰∏≠ËØÑ‰º∞‰∫ÜÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ï„ÄÇÂÆûÈ™åÁªìÊûúÈ™åËØÅ‰∫ÜËØ•ÁÆóÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÂü∫‰∫éÊµÅÈáèÂåπÈÖçÁöÑÊ®°‰ªøÂ≠¶‰π†ÊñπÊ≥ïÂú®Êú∫Âô®‰∫∫ÊéßÂà∂‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫Ëâ≤Ôºå‰ΩÜÂÖ∂Êé®ÁêÜËøáÁ®ãÈÄöÂ∏∏ÈúÄË¶ÅÂ§öÊ¨°Ëø≠‰ª£ÔºåÂØºËá¥Êé®ÁêÜÊó∂Èó¥ËøáÈïøÔºåÈöæ‰ª•Êª°Ë∂≥ÂÆûÊó∂ÊÄßË¶ÅÊ±Ç„ÄÇËí∏È¶èÂíå‰∏ÄËá¥ÊÄßÊñπÊ≥ïËôΩÁÑ∂ÂèØ‰ª•Âä†ÈÄüÊé®ÁêÜÔºå‰ΩÜÊÄßËÉΩÂæÄÂæÄ‰∏çÂ¶ÇÂéüÂßãÁöÑÊµÅÈáèÂåπÈÖçÊ®°Âûã„ÄÇÂõ†Ê≠§ÔºåÂ¶Ç‰ΩïÂú®‰øùËØÅÊÄßËÉΩÁöÑÂâçÊèê‰∏ãÔºåÊòæËëóÈôç‰ΩéÊé®ÁêÜÊó∂Èó¥ÔºåÊòØÊú¨ÊñáË¶ÅËß£ÂÜ≥ÁöÑÊ†∏ÂøÉÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊú¨ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÊûÑÂª∫‰∏Ä‰∏™ÂçïÊ≠•Êç∑ÂæÑÊ®°ÂûãÔºåÁõ¥Êé•È¢ÑÊµãÊúÄÁªàÁöÑÂä®‰ΩúÔºå‰ªéËÄåÈÅøÂÖçÂ§öÊ¨°Ëø≠‰ª£Êé®ÁêÜ„ÄÇ‰∏∫‰∫ÜÂº•Ë°•ÂçïÊ≠•Ê®°ÂûãÂèØËÉΩÂ∏¶Êù•ÁöÑÊÄßËÉΩÊçüÂ§±ÔºåÂºïÂÖ•Â§öÊ≠•‰∏ÄËá¥ÊÄßÊçüÂ§±ÔºåÂ∞ÜÂçïÊ≠•È¢ÑÊµãÂàÜËß£‰∏∫Â§ö‰∏™‰∏≠Èó¥Ê≠•È™§ÔºåÂπ∂Á∫¶ÊùüËøô‰∫õ‰∏≠Èó¥Ê≠•È™§ÁöÑ‰∏ÄËá¥ÊÄßÔºå‰ªéËÄåÊèêÈ´òÂçïÊ≠•Ê®°ÂûãÁöÑÈ¢ÑÊµãÁ≤æÂ∫¶„ÄÇÂêåÊó∂Ôºå‰∏∫‰∫ÜËß£ÂÜ≥Â§öÊ≠•ÊçüÂ§±Â∏¶Êù•ÁöÑ‰ºòÂåñ‰∏çÁ®≥ÂÆöÈóÆÈ¢òÔºåËÆæËÆ°Ëá™ÈÄÇÂ∫îÊ¢ØÂ∫¶ÂàÜÈÖçÊñπÊ≥ïÔºåÂä®ÊÄÅË∞ÉÊï¥‰∏çÂêåÊçüÂ§±È°πÁöÑÊùÉÈáçÔºå‰ª•‰øùËØÅÂ≠¶‰π†ËøáÁ®ãÁöÑÁ®≥ÂÆöÊÄßÂíåÊî∂ÊïõÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•ÊñπÊ≥ï‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Ê®°ÂùóÔºö1) Êç∑ÂæÑÊ®°ÂûãÔºöÁî®‰∫éÁõ¥Êé•È¢ÑÊµãÂä®‰ΩúÔºåÂÆûÁé∞ÂçïÊ≠•Êé®ÁêÜ„ÄÇ2) Â§öÊ≠•‰∏ÄËá¥ÊÄßÊçüÂ§±ÔºöÂ∞ÜÂçïÊ≠•È¢ÑÊµãÂàÜËß£‰∏∫Â§ö‰∏™‰∏≠Èó¥Ê≠•È™§ÔºåÂπ∂Á∫¶ÊùüËøô‰∫õ‰∏≠Èó¥Ê≠•È™§ÁöÑ‰∏ÄËá¥ÊÄß„ÄÇ3) Ëá™ÈÄÇÂ∫îÊ¢ØÂ∫¶ÂàÜÈÖçÔºöÂä®ÊÄÅË∞ÉÊï¥‰∏çÂêåÊçüÂ§±È°πÁöÑÊùÉÈáçÔºå‰øùËØÅÂ≠¶‰π†ËøáÁ®ãÁöÑÁ®≥ÂÆöÊÄßÂíåÊî∂ÊïõÊÄß„ÄÇÊï¥‰ΩìÊµÅÁ®ãÊòØÔºöÈ¶ñÂÖàÔºåÂà©Áî®ÊµÅÈáèÂåπÈÖçÊ®°ÂûãÁîüÊàêËÆ≠ÁªÉÊï∞ÊçÆÔºõÁÑ∂ÂêéÔºåËÆ≠ÁªÉÊç∑ÂæÑÊ®°ÂûãÔºåÂêåÊó∂‰ΩøÁî®Â§öÊ≠•‰∏ÄËá¥ÊÄßÊçüÂ§±ÂíåËá™ÈÄÇÂ∫îÊ¢ØÂ∫¶ÂàÜÈÖçÊñπÊ≥ïËøõË°å‰ºòÂåñÔºõÊúÄÂêéÔºåÂà©Áî®ËÆ≠ÁªÉÂ•ΩÁöÑÊç∑ÂæÑÊ®°ÂûãËøõË°åÂçïÊ≠•Êé®ÁêÜ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ÊñπÊ≥ïÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÂ∞ÜÂçïÊ≠•Êç∑ÂæÑÊ®°Âûã‰∏éÂ§öÊ≠•‰∏ÄËá¥ÊÄßÊçüÂ§±Áõ∏ÁªìÂêàÔºåÂπ∂Âú®‰ºòÂåñËøáÁ®ã‰∏≠ÂºïÂÖ•Ëá™ÈÄÇÂ∫îÊ¢ØÂ∫¶ÂàÜÈÖç„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÂú®‰øùËØÅÊÄßËÉΩÁöÑÂâçÊèê‰∏ãÔºåÊòæËëóÈôç‰ΩéÊé®ÁêÜÊó∂Èó¥„ÄÇÊ≠§Â§ñÔºåËá™ÈÄÇÂ∫îÊ¢ØÂ∫¶ÂàÜÈÖçÊñπÊ≥ïËÉΩÂ§üÊúâÊïàËß£ÂÜ≥Â§öÊ≠•ÊçüÂ§±Â∏¶Êù•ÁöÑ‰ºòÂåñ‰∏çÁ®≥ÂÆöÈóÆÈ¢òÔºåÊèêÈ´ò‰∫ÜÂ≠¶‰π†ËøáÁ®ãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂ§öÊ≠•‰∏ÄËá¥ÊÄßÊçüÂ§±ÁöÑÂÖ∑‰ΩìÂΩ¢Âºè‰∏∫ÔºöÂ∞ÜÂçïÊ≠•È¢ÑÊµãÂàÜËß£‰∏∫N‰∏™‰∏≠Èó¥Ê≠•È™§ÔºåÂπ∂ËÆ°ÁÆóÊØè‰∏™‰∏≠Èó¥Ê≠•È™§ÁöÑÈ¢ÑÊµãÁªìÊûú‰∏éÁúüÂÆûËΩ®Ëøπ‰πãÈó¥ÁöÑÂ∑ÆÂºÇÔºåÁÑ∂ÂêéÂ∞ÜËøô‰∫õÂ∑ÆÂºÇÂä†ÊùÉÊ±ÇÂíåÔºå‰Ωú‰∏∫Â§öÊ≠•‰∏ÄËá¥ÊÄßÊçüÂ§±„ÄÇËá™ÈÄÇÂ∫îÊ¢ØÂ∫¶ÂàÜÈÖçÁöÑÂÖ∑‰ΩìÊñπÊ≥ï‰∏∫ÔºöÊ†πÊçÆÊØè‰∏™ÊçüÂ§±È°πÁöÑÊ¢ØÂ∫¶Â§ßÂ∞èÔºåÂä®ÊÄÅË∞ÉÊï¥ÂÖ∂ÊùÉÈáçÔºå‰ΩøÂæóÊ¢ØÂ∫¶ËæÉÂ§ßÁöÑÊçüÂ§±È°πËé∑ÂæóÊõ¥Â§ßÁöÑÊùÉÈáçÔºå‰ªéËÄåÂä†ÈÄüÂÖ∂Êî∂Êïõ„ÄÇÂÖ∑‰ΩìÁöÑÁΩëÁªúÁªìÊûÑÂíåÂèÇÊï∞ËÆæÁΩÆÈúÄË¶ÅÊ†πÊçÆÂÖ∑‰ΩìÁöÑ‰ªªÂä°ËøõË°åË∞ÉÊï¥„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®‰∏§‰∏™Ê®°ÊãüÂü∫ÂáÜÂíå‰∫î‰∏™ÁúüÂÆûÁéØÂ¢É‰ªªÂä°‰∏äÁöÑÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÂú®‰øùËØÅÊÄßËÉΩÁöÑÂâçÊèê‰∏ãÔºåÊòæËëóÈôç‰ΩéÊé®ÁêÜÊó∂Èó¥„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºå‰∏éÂéüÂßãÁöÑÊµÅÈáèÂåπÈÖçÊ®°ÂûãÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïÁöÑÊé®ÁêÜÈÄüÂ∫¶ÊèêÈ´ò‰∫ÜÊï∞ÂÄçÔºåÂêåÊó∂ÊÄßËÉΩÊçüÂ§±ËæÉÂ∞è„ÄÇÊ≠§Â§ñÔºåËá™ÈÄÇÂ∫îÊ¢ØÂ∫¶ÂàÜÈÖçÊñπÊ≥ïËÉΩÂ§üÊúâÊïàÊèêÈ´òÂ≠¶‰π†ËøáÁ®ãÁöÑÁ®≥ÂÆöÊÄßÔºå‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üÊõ¥Âø´Âú∞Êî∂Êïõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂπøÊ≥õÂ∫îÁî®‰∫éÈúÄË¶ÅÂø´ÈÄüÂìçÂ∫îÁöÑÊú∫Âô®‰∫∫ÊéßÂà∂‰ªªÂä°‰∏≠Ôºå‰æãÂ¶ÇËá™Âä®È©æÈ©∂„ÄÅÊó†‰∫∫Êú∫ÊéßÂà∂„ÄÅÊú∫Âô®‰∫∫Êìç‰ΩúÁ≠â„ÄÇÈÄöËøáÈôç‰ΩéÊé®ÁêÜÊó∂Èó¥ÔºåÂèØ‰ª•ÊèêÈ´òÊú∫Âô®‰∫∫ÁöÑÂÆûÊó∂ÊÄßÂíåÂÆâÂÖ®ÊÄßÔºå‰ΩøÂÖ∂ËÉΩÂ§üÊõ¥Â•ΩÂú∞ÈÄÇÂ∫îÂ§çÊùÇÂ§öÂèòÁöÑÁéØÂ¢É„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïËøòÂèØ‰ª•Â∫îÁî®‰∫éÂÖ∂‰ªñÈúÄË¶ÅÂä†ÈÄüÊé®ÁêÜÁöÑÊú∫Âô®Â≠¶‰π†‰ªªÂä°‰∏≠Ôºå‰æãÂ¶ÇÂõæÂÉèËØÜÂà´„ÄÅËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÁ≠â„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> The wide application of flow-matching methods has greatly promoted the development of robot imitation learning. However, these methods all face the problem of high inference time. To address this issue, researchers have proposed distillation methods and consistency methods, but the performance of these methods still struggles to compete with that of the original diffusion models and flow-matching models. In this article, we propose a one-step shortcut method with multi-step integration for robot imitation learning. To balance the inference speed and performance, we extend the multi-step consistency loss on the basis of the shortcut model, split the one-step loss into multi-step losses, and improve the performance of one-step inference. Secondly, to solve the problem of unstable optimization of the multi-step loss and the original flow-matching loss, we propose an adaptive gradient allocation method to enhance the stability of the learning process. Finally, we evaluate the proposed method in two simulation benchmarks and five real-world environment tasks. The experimental results verify the effectiveness of the proposed algorithm.

