---
layout: default
title: Integrating Model-based Control and RL for Sim2Real Transfer of Tight Insertion Policies
---

# Integrating Model-based Control and RL for Sim2Real Transfer of Tight Insertion Policies

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.11858" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.11858v1</a>
  <a href="https://arxiv.org/pdf/2505.11858.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.11858v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.11858v1', 'Integrating Model-based Control and RL for Sim2Real Transfer of Tight Insertion Policies')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Isidoros Marougkas, Dhruv Metha Ramesh, Joe H. Doerr, Edgar Granados, Aravind Sivaramakrishnan, Abdeslam Boularias, Kostas E. Bekris

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-05-17

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé›†æˆæ¨¡å‹æ§åˆ¶ä¸å¼ºåŒ–å­¦ä¹ ä»¥è§£å†³ç´§å‡‘æ’å…¥é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `æ¨¡å‹æ§åˆ¶` `æœºå™¨äººæ’å…¥` `é›¶-shotè½¬ç§»` `æ½œåœ¨åœºæ§åˆ¶å™¨` `ç¨€ç–å¥–åŠ±` `å·¥ä¸šè‡ªåŠ¨åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨ç´§å‡‘æ’å…¥ä»»åŠ¡ä¸­ä¾èµ–äºå¤æ‚çš„å¥–åŠ±å‡½æ•°ï¼Œéš¾ä»¥å®ç°é«˜ç²¾åº¦çš„æ’å…¥ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæœ¬ç ”ç©¶æå‡ºå°†æ¨¡å‹æ§åˆ¶ä¸å¼ºåŒ–å­¦ä¹ ç›¸ç»“åˆï¼Œé€šè¿‡æ½œåœ¨åœºæ§åˆ¶å™¨å’Œæ®‹ä½™RLç­–ç•¥å®ç°é«˜æ•ˆçš„æ’å…¥æ§åˆ¶ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šå®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§å¯¹è±¡å’Œæ¡ä»¶ä¸‹çš„è¡¨ç°ä¼˜äºç°æœ‰çš„RLæ–¹æ³•ï¼Œä¸”æ— éœ€è¿›ä¸€æ­¥è®­ç»ƒæˆ–å¾®è°ƒã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨ç´§å‡‘æ’å…¥ä»»åŠ¡ä¸­ï¼Œç‰©ä½“æ’å…¥çš„ç²¾åº¦è¦æ±‚æé«˜ï¼ˆå°äº1mmï¼‰ï¼Œè¿™ä½¿å¾—å³ä½¿æ˜¯å¾®å°çš„è¯¯å·®ä¹Ÿä¼šå¯¼è‡´ä¸è‰¯æ¥è§¦ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æœ‰æ•ˆçš„ç­–ç•¥ï¼Œå°†ä¼ ç»Ÿçš„æ¨¡å‹æ§åˆ¶ä¸å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ç›¸ç»“åˆï¼Œä»¥æé«˜æ’å…¥ç²¾åº¦ã€‚è¯¥ç­–ç•¥åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­è¿›è¡Œè®­ç»ƒï¼Œå¹¶èƒ½å¤Ÿé›¶-shotè½¬ç§»åˆ°çœŸå®ç³»ç»Ÿä¸­ã€‚é€šè¿‡æ½œåœ¨åœºæ§åˆ¶å™¨è·å–æ¨¡å‹åŸºç¡€çš„æ’å…¥ç­–ç•¥ï¼Œå¹¶ä¸ä»…ä¾èµ–ç¨€ç–ç›®æ ‡å¥–åŠ±çš„æ®‹ä½™RLç›¸ç»“åˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§å¯¹è±¡å’Œæ¡ä»¶ä¸‹ä¼˜äºç°æœ‰çš„RLæ–¹æ³•å’Œæ··åˆç­–ç•¥ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨ç´§å‡‘æ’å…¥ä»»åŠ¡ä¸­ï¼Œç°æœ‰å¼ºåŒ–å­¦ä¹ æ–¹æ³•å› ä¾èµ–å¤æ‚å¥–åŠ±å‡½æ•°è€Œå¯¼è‡´çš„æ’å…¥ç²¾åº¦ä¸è¶³çš„é—®é¢˜ã€‚ä¼ ç»Ÿæ–¹æ³•åœ¨é¢å¯¹é«˜ç²¾åº¦è¦æ±‚æ—¶ï¼Œéš¾ä»¥æœ‰æ•ˆåº”å¯¹å°è¯¯å·®å¯¼è‡´çš„å¤±è´¥ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬ç ”ç©¶æå‡ºå°†æ¨¡å‹åŸºç¡€æ§åˆ¶ä¸å¼ºåŒ–å­¦ä¹ ç›¸ç»“åˆï¼Œåˆ©ç”¨æ½œåœ¨åœºæ§åˆ¶å™¨ç”Ÿæˆæ’å…¥ç­–ç•¥ï¼Œå¹¶é€šè¿‡æ®‹ä½™RLè¿›è¡Œä¼˜åŒ–ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨æé«˜æ’å…¥çš„å‡†ç¡®æ€§ï¼ŒåŒæ—¶å‡å°‘å¯¹å¤æ‚å¥–åŠ±å‡½æ•°çš„ä¾èµ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œåœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­ä½¿ç”¨æ½œåœ¨åœºæ§åˆ¶å™¨ç”Ÿæˆåˆå§‹æ’å…¥ç­–ç•¥ï¼›å…¶æ¬¡ï¼Œä½¿ç”¨æ®‹ä½™RLè¿›è¡Œè®­ç»ƒï¼Œä¼˜åŒ–è¯¥ç­–ç•¥ä»¥é€‚åº”ç¨€ç–çš„ç›®æ ‡å¥–åŠ±ã€‚æ•´ä¸ªè¿‡ç¨‹åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­å®Œæˆï¼Œæœ€ç»ˆå®ç°é›¶-shotè½¬ç§»åˆ°çœŸå®ç³»ç»Ÿã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶çš„ä¸»è¦åˆ›æ–°åœ¨äºå°†æ¨¡å‹æ§åˆ¶ä¸å¼ºåŒ–å­¦ä¹ æœ‰æ•ˆç»“åˆï¼Œå½¢æˆäº†ä¸€ç§æ–°çš„ç­–ç•¥ç”Ÿæˆä¸ä¼˜åŒ–æ¡†æ¶ã€‚è¿™ä¸€æ–¹æ³•åœ¨æ’å…¥ç²¾åº¦ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„RLæ–¹æ³•å’Œæ··åˆç­–ç•¥ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†è§‚å¯Ÿå™ªå£°å’ŒåŠ¨ä½œå¹…åº¦çš„è¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼Œä»¥æé«˜æ®‹ä½™RLçš„è®­ç»ƒæ•ˆæœã€‚è¾“å…¥ä¸ºæ’å¤´å’Œæ’åº§çš„SE(3)ä½å§¿ï¼Œè¾“å‡ºä¸ºæ’å¤´çš„SE(3)ä½å§¿å˜æ¢ï¼Œæœ€ç»ˆç”±æœºå™¨äººè‡‚æ‰§è¡Œã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨å¤šç§å¯¹è±¡å’Œæ¡ä»¶ä¸‹çš„æ’å…¥æˆåŠŸç‡æ˜¾è‘—é«˜äºç°æœ‰çš„RLæ–¹æ³•ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šã€‚æ­¤å¤–ï¼Œæ–¹æ³•æ— éœ€åœ¨çœŸå®ç¯å¢ƒä¸­è¿›è¡Œé¢å¤–è®­ç»ƒæˆ–å¾®è°ƒï¼Œå±•ç°å‡ºè‰¯å¥½çš„é›¶-shotè½¬ç§»èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å·¥ä¸šè‡ªåŠ¨åŒ–ã€æœºå™¨äººè£…é…å’Œæ™ºèƒ½åˆ¶é€ ç­‰ã€‚é€šè¿‡æé«˜æœºå™¨äººåœ¨å¤æ‚æ’å…¥ä»»åŠ¡ä¸­çš„ç²¾åº¦ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ˜¾è‘—æå‡ç”Ÿäº§æ•ˆç‡å’Œäº§å“è´¨é‡ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Object insertion under tight tolerances ($< \hspace{-.02in} 1mm$) is an important but challenging assembly task as even small errors can result in undesirable contacts. Recent efforts focused on Reinforcement Learning (RL), which often depends on careful definition of dense reward functions. This work proposes an effective strategy for such tasks that integrates traditional model-based control with RL to achieve improved insertion accuracy. The policy is trained exclusively in simulation and is zero-shot transferred to the real system. It employs a potential field-based controller to acquire a model-based policy for inserting a plug into a socket given full observability in simulation. This policy is then integrated with residual RL, which is trained in simulation given only a sparse, goal-reaching reward. A curriculum scheme over observation noise and action magnitude is used for training the residual RL policy. Both policy components use as input the SE(3) poses of both the plug and the socket and return the plug's SE(3) pose transform, which is executed by a robotic arm using a controller. The integrated policy is deployed on the real system without further training or fine-tuning, given a visual SE(3) object tracker. The proposed solution and alternatives are evaluated across a variety of objects and conditions in simulation and reality. The proposed approach outperforms recent RL-based methods in this domain and prior efforts with hybrid policies. Ablations highlight the impact of each component of the approach.

