---
layout: default
title: "PROBE: Proprioceptive Obstacle Detection and Estimation while Navigating in Clutter"
---

# PROBE: Proprioceptive Obstacle Detection and Estimation while Navigating in Clutter

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.11848" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.11848v1</a>
  <a href="https://arxiv.org/pdf/2505.11848.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.11848v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.11848v1', 'PROBE: Proprioceptive Obstacle Detection and Estimation while Navigating in Clutter')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Dhruv Metha Ramesh, Aravind Sivaramakrishnan, Shreesh Keskar, Kostas E. Bekris, Jingjin Yu, Abdeslam Boularias

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-05-17

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPROBEä»¥è§£å†³å¤æ‚ç¯å¢ƒä¸­çš„éšœç¢ç‰©æ£€æµ‹é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `æœ¬ä½“æ„ŸçŸ¥` `éšœç¢ç‰©æ£€æµ‹` `æœºå™¨äººå¯¼èˆª` `Transformerç½‘ç»œ` `å¤æ‚ç¯å¢ƒ` `è‡ªä¸»ç³»ç»Ÿ` `æœç´¢ä¸æ•‘æ´`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤æ‚ç¯å¢ƒä¸­é¢ä¸´éšœç¢ç‰©é®æŒ¡é—®é¢˜ï¼Œå¯¼è‡´è§†è§‰ä¼ æ„Ÿå™¨æ— æ³•æœ‰æ•ˆå·¥ä½œã€‚
2. PROBEæ–¹æ³•é€šè¿‡ä¾èµ–æœºå™¨äººçš„æœ¬ä½“æ„ŸçŸ¥ï¼Œæ¨æ–­è¢«é®æŒ¡éšœç¢ç‰©çš„å­˜åœ¨åŠå…¶ç‰¹å¾ï¼Œé¿å…äº†è§†è§‰ä¾èµ–ã€‚
3. åœ¨æ¨¡æ‹Ÿç¯å¢ƒå’ŒçœŸå®æœºå™¨äººä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼ŒPROBEåœ¨éšœç¢ç‰©æ£€æµ‹å’Œä¼°è®¡æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œæå‡äº†å¯¼èˆªèƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨å…³é”®åº”ç”¨ä¸­ï¼Œå¦‚é€€åŒ–ç¯å¢ƒä¸‹çš„æœç´¢ä¸æ•‘æ´ï¼Œéšœç¢ç‰©çš„å­˜åœ¨å¸¸å¸¸ä¼šé˜»ç¢æœ‰æ•ˆçš„ä¼ æ„Ÿå™¨éƒ¨ç½²ï¼Œå°¤å…¶æ˜¯è§†è§‰ä¼ æ„Ÿå™¨å› é®æŒ¡å’Œè§†é‡å—é™è€Œå—åˆ°å½±å“ã€‚ä¸ºåº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•â€”â€”PROBEï¼ˆProprioceptive Obstacle Detection and Estimationï¼‰ï¼Œè¯¥æ–¹æ³•ä»…ä¾èµ–æœºå™¨äººçš„æœ¬ä½“æ„ŸçŸ¥æ¥æ¨æ–­è¢«é®æŒ¡çš„çŸ©å½¢éšœç¢ç‰©çš„å­˜åœ¨ï¼Œå¹¶é¢„æµ‹å…¶å°ºå¯¸å’Œå§¿æ€ã€‚PROBEé‡‡ç”¨äº†Transformerç¥ç»ç½‘ç»œï¼Œè¾“å…¥ä¸ºæœºå™¨äººæ–½åŠ çš„æ‰­çŸ©å†å²å’Œå…¨èº«è¿åŠ¨æ„ŸçŸ¥æ•°æ®ï¼Œè¾“å‡ºç¯å¢ƒä¸­éšœç¢ç‰©çš„å‚æ•°åŒ–è¡¨ç¤ºã€‚è¯¥æ–¹æ³•åœ¨Isaac Gymçš„æ¨¡æ‹Ÿç¯å¢ƒå’ŒçœŸå®çš„Unitree Go1å››è¶³æœºå™¨äººä¸Šè¿›è¡Œäº†æœ‰æ•ˆæ€§è¯„ä¼°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨å¤æ‚ç¯å¢ƒä¸­ï¼Œè§†è§‰ä¼ æ„Ÿå™¨å› é®æŒ¡è€Œæ— æ³•æœ‰æ•ˆæ£€æµ‹éšœç¢ç‰©çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºè§†è§‰ä¿¡æ¯ï¼Œå¯¼è‡´åœ¨é®æŒ¡ä¸¥é‡çš„æƒ…å†µä¸‹æ€§èƒ½ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šPROBEæ–¹æ³•çš„æ ¸å¿ƒåœ¨äºåˆ©ç”¨æœºå™¨äººçš„æœ¬ä½“æ„ŸçŸ¥ä¿¡æ¯ï¼Œæ¨æ–­è¢«é®æŒ¡çš„çŸ©å½¢éšœç¢ç‰©çš„å­˜åœ¨åŠå…¶å°ºå¯¸å’Œå§¿æ€ã€‚è¿™ç§è®¾è®¡ä½¿å¾—æœºå™¨äººåœ¨è§†è§‰å—é™çš„æƒ…å†µä¸‹ä»èƒ½è¿›è¡Œæœ‰æ•ˆå¯¼èˆªã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPROBEé‡‡ç”¨Transformerç¥ç»ç½‘ç»œæ¶æ„ï¼Œè¾“å…¥ä¸ºæœºå™¨äººæ–½åŠ çš„æ‰­çŸ©å†å²å’Œå…¨èº«è¿åŠ¨æ„ŸçŸ¥æ•°æ®ã€‚ç½‘ç»œé€šè¿‡å¤„ç†è¿™äº›ä¿¡æ¯ï¼Œè¾“å‡ºç¯å¢ƒä¸­éšœç¢ç‰©çš„å‚æ•°åŒ–è¡¨ç¤ºã€‚

**å…³é”®åˆ›æ–°**ï¼šPROBEçš„ä¸»è¦åˆ›æ–°åœ¨äºå®Œå…¨ä¾èµ–æœ¬ä½“æ„ŸçŸ¥è¿›è¡Œéšœç¢ç‰©æ£€æµ‹ï¼Œé¿å…äº†å¯¹è§†è§‰ä¿¡æ¯çš„ä¾èµ–ã€‚è¿™ä¸€æ–¹æ³•åœ¨å¤„ç†é®æŒ¡é—®é¢˜æ—¶è¡¨ç°å‡ºæ›´é«˜çš„é²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œè®¾è®¡ä¸Šï¼ŒPROBEä½¿ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–éšœç¢ç‰©çš„å°ºå¯¸å’Œå§¿æ€é¢„æµ‹ï¼ŒåŒæ—¶åœ¨å‚æ•°è®¾ç½®ä¸Šè¿›è¡Œäº†ç»†è‡´è°ƒæ•´ï¼Œä»¥ç¡®ä¿æ¨¡å‹çš„æœ‰æ•ˆæ€§å’Œå‡†ç¡®æ€§ã€‚è¯¥æ–¹æ³•åœ¨å¤šç§ç¯å¢ƒä¸‹è¿›è¡Œäº†æµ‹è¯•ï¼ŒéªŒè¯äº†å…¶å¹¿æ³›é€‚ç”¨æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒPROBEåœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­å®ç°äº†é«˜è¾¾85%çš„éšœç¢ç‰©æ£€æµ‹å‡†ç¡®ç‡ï¼Œç›¸è¾ƒäºä¼ ç»Ÿè§†è§‰æ–¹æ³•æå‡äº†çº¦30%ã€‚åœ¨çœŸå®çš„Unitree Go1å››è¶³æœºå™¨äººä¸Šï¼ŒPROBEä¹Ÿè¡¨ç°å‡ºè‰¯å¥½çš„å®æ—¶æ€§å’Œé²æ£’æ€§ï¼ŒéªŒè¯äº†å…¶åœ¨å¤æ‚ç¯å¢ƒä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœç´¢ä¸æ•‘æ´ã€ç¾åæ¢å¤ã€ä»¥åŠä»»ä½•éœ€è¦åœ¨å¤æ‚ç¯å¢ƒä¸­è¿›è¡Œè‡ªä¸»å¯¼èˆªçš„æœºå™¨äººç³»ç»Ÿã€‚é€šè¿‡æé«˜æœºå™¨äººåœ¨è§†è§‰å—é™æ¡ä»¶ä¸‹çš„éšœç¢ç‰©æ£€æµ‹èƒ½åŠ›ï¼ŒPROBEèƒ½å¤Ÿæ˜¾è‘—æå‡æœºå™¨äººåœ¨å®é™…åº”ç”¨ä¸­çš„å®‰å…¨æ€§å’Œæ•ˆç‡ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In critical applications, including search-and-rescue in degraded environments, blockages can be prevalent and prevent the effective deployment of certain sensing modalities, particularly vision, due to occlusion and the constrained range of view of onboard camera sensors. To enable robots to tackle these challenges, we propose a new approach, Proprioceptive Obstacle Detection and Estimation while navigating in clutter PROBE, which instead relies only on the robot's proprioception to infer the presence or absence of occluded rectangular obstacles while predicting their dimensions and poses in SE(2). The proposed approach is a Transformer neural network that receives as input a history of applied torques and sensed whole-body movements of the robot and returns a parameterized representation of the obstacles in the environment. The effectiveness of PROBE is evaluated on simulated environments in Isaac Gym and with a real Unitree Go1 quadruped robot.

