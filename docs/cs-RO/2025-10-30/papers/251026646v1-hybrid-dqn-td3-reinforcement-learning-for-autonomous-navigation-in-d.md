---
layout: default
title: Hybrid DQN-TD3 Reinforcement Learning for Autonomous Navigation in Dynamic Environments
---

# Hybrid DQN-TD3 Reinforcement Learning for Autonomous Navigation in Dynamic Environments

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.26646" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.26646v1</a>
  <a href="https://arxiv.org/pdf/2510.26646.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.26646v1" onclick="toggleFavorite(this, '2510.26646v1', 'Hybrid DQN-TD3 Reinforcement Learning for Autonomous Navigation in Dynamic Environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xiaoyi He, Danggui Chen, Zhenshuo Zhang, Zimeng Bai

**åˆ†ç±»**: cs.RO, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-10-30

**å¤‡æ³¨**: 6 pages, 5 figures; ROS+Gazebo (TurtleBot3) implementation; evaluation with PathBench metrics; code (primary): https://github.com/MayaCHEN-github/HierarchicalRL-robot-navigation; mirror (for reproducibility): https://github.com/ShowyHe/DRL-robot-navigation

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ··åˆDQN-TD3å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºåŠ¨æ€ç¯å¢ƒä¸­è‡ªä¸»å¯¼èˆªã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `è‡ªä¸»å¯¼èˆª` `DQN` `TD3` `åˆ†å±‚æ§åˆ¶` `æœºå™¨äºº` `åŠ¨æ€ç¯å¢ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨åŠ¨æ€ç¯å¢ƒä¸­è‡ªä¸»å¯¼èˆªé¢ä¸´æŒ‘æˆ˜ï¼Œéš¾ä»¥å…¼é¡¾å…¨å±€è§„åˆ’å’Œå±€éƒ¨æ§åˆ¶ã€‚
2. é‡‡ç”¨åˆ†å±‚å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼ŒDQNè´Ÿè´£é«˜å±‚å†³ç­–ï¼ŒTD3è´Ÿè´£åº•å±‚æ§åˆ¶ï¼Œå®ç°å…¨å±€è§„åˆ’ä¸å±€éƒ¨æ§åˆ¶çš„ç»“åˆã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æˆåŠŸç‡å’Œæ ·æœ¬æ•ˆç‡æ–¹é¢ä¼˜äºå•ä¸€ç®—æ³•åŸºçº¿å’ŒåŸºäºè§„åˆ™çš„è§„åˆ’å™¨ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ†å±‚è·¯å¾„è§„åˆ’ä¸æ§åˆ¶æ¡†æ¶ï¼Œè¯¥æ¡†æ¶ç»“åˆäº†é«˜å±‚æ·±åº¦Qç½‘ç»œï¼ˆDQNï¼‰ç”¨äºç¦»æ•£å­ç›®æ ‡é€‰æ‹©ï¼Œä»¥åŠä½å±‚åŒå»¶è¿Ÿæ·±åº¦ç¡®å®šæ€§ç­–ç•¥æ¢¯åº¦ï¼ˆTD3ï¼‰æ§åˆ¶å™¨ç”¨äºè¿ç»­åŠ¨ä½œæ§åˆ¶ã€‚é«˜å±‚æ¨¡å—é€‰æ‹©è¡Œä¸ºå’Œå­ç›®æ ‡ï¼›ä½å±‚æ¨¡å—æ‰§è¡Œå¹³æ»‘çš„é€Ÿåº¦æŒ‡ä»¤ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ç§å®ç”¨çš„å¥–åŠ±å¡‘é€ æ–¹æ¡ˆï¼ˆæ–¹å‘ã€è·ç¦»ã€é¿éšœã€åŠ¨ä½œå¹³æ»‘æ€§ã€ç¢°æ’æƒ©ç½šã€æ—¶é—´æƒ©ç½šå’Œè¿›åº¦ï¼‰ï¼Œä»¥åŠä¸€ä¸ªåŸºäºæ¿€å…‰é›·è¾¾çš„å®‰å…¨é—¨ï¼Œä»¥é˜²æ­¢ä¸å®‰å…¨çš„è¿åŠ¨ã€‚è¯¥ç³»ç»Ÿåœ¨ROS + Gazeboï¼ˆTurtleBot3ï¼‰ä¸­å®ç°ï¼Œå¹¶ä½¿ç”¨PathBenchæŒ‡æ ‡ï¼ˆåŒ…æ‹¬æˆåŠŸç‡ã€ç¢°æ’ç‡ã€è·¯å¾„æ•ˆç‡å’Œé‡è§„åˆ’æ•ˆç‡ï¼‰åœ¨åŠ¨æ€å’Œéƒ¨åˆ†å¯è§‚å¯Ÿçš„ç¯å¢ƒä¸­è¿›è¡Œè¯„ä¼°ã€‚å®éªŒè¡¨æ˜ï¼Œä¸å•ä¸€ç®—æ³•åŸºçº¿ï¼ˆå•ç‹¬çš„DQNæˆ–TD3ï¼‰å’ŒåŸºäºè§„åˆ™çš„è§„åˆ’å™¨ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•æé«˜äº†æˆåŠŸç‡å’Œæ ·æœ¬æ•ˆç‡ï¼Œå¹¶ä¸”æ›´å¥½åœ°æ³›åŒ–åˆ°æœªè§è¿‡çš„éšœç¢ç‰©é…ç½®ï¼Œå¹¶å‡å°‘äº†çªå‘çš„æ§åˆ¶å˜åŒ–ã€‚ä»£ç å’Œè¯„ä¼°è„šæœ¬å¯åœ¨é¡¹ç›®å­˜å‚¨åº“ä¸­æ‰¾åˆ°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šåœ¨åŠ¨æ€å’Œéƒ¨åˆ†å¯è§‚æµ‹ç¯å¢ƒä¸­ï¼Œè‡ªä¸»å¯¼èˆªéœ€è¦åŒæ—¶è€ƒè™‘å…¨å±€è·¯å¾„è§„åˆ’å’Œå±€éƒ¨è¿åŠ¨æ§åˆ¶ã€‚ä¼ ç»Ÿæ–¹æ³•ï¼Œå¦‚å•ç‹¬ä½¿ç”¨DQNæˆ–TD3ï¼Œéš¾ä»¥åœ¨æ¢ç´¢æ•ˆç‡ã€æ³›åŒ–èƒ½åŠ›å’Œæ§åˆ¶å¹³æ»‘æ€§ä¹‹é—´å–å¾—å¹³è¡¡ã€‚åŸºäºè§„åˆ™çš„è§„åˆ’å™¨éš¾ä»¥é€‚åº”å¤æ‚å’ŒæœªçŸ¥çš„ç¯å¢ƒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé‡‡ç”¨åˆ†å±‚å¼ºåŒ–å­¦ä¹ æ¶æ„ï¼Œå°†å¯¼èˆªä»»åŠ¡åˆ†è§£ä¸ºé«˜å±‚ç¦»æ•£å†³ç­–å’Œä½å±‚è¿ç»­æ§åˆ¶ã€‚é«˜å±‚DQNè´Ÿè´£é€‰æ‹©å­ç›®æ ‡ï¼Œå¼•å¯¼å…¨å±€è·¯å¾„è§„åˆ’ï¼›ä½å±‚TD3è´Ÿè´£æ‰§è¡Œå¹³æ»‘çš„é€Ÿåº¦æŒ‡ä»¤ï¼Œå®ç°å±€éƒ¨è¿åŠ¨æ§åˆ¶ã€‚è¿™ç§åˆ†å±‚ç»“æ„èƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨DQNçš„ç¦»æ•£å†³ç­–èƒ½åŠ›å’ŒTD3çš„è¿ç»­æ§åˆ¶èƒ½åŠ›ï¼Œæé«˜å¯¼èˆªæ•ˆç‡å’Œé²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé«˜å±‚DQNå­ç›®æ ‡é€‰æ‹©å™¨å’Œä½å±‚TD3é€Ÿåº¦æ§åˆ¶å™¨ã€‚é¦–å…ˆï¼ŒDQNæ ¹æ®å½“å‰ç¯å¢ƒçŠ¶æ€é€‰æ‹©ä¸€ä¸ªå­ç›®æ ‡ã€‚ç„¶åï¼ŒTD3æ§åˆ¶å™¨æ¥æ”¶è¯¥å­ç›®æ ‡ï¼Œå¹¶ç”Ÿæˆç›¸åº”çš„é€Ÿåº¦æŒ‡ä»¤ï¼Œæ§åˆ¶æœºå™¨äººè¿åŠ¨ã€‚é€šè¿‡ROSå’ŒGazeboå¹³å°è¿›è¡Œä»¿çœŸå®éªŒã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•çš„æ ¸å¿ƒåˆ›æ–°åœ¨äºæ··åˆä½¿ç”¨DQNå’ŒTD3ï¼Œå½¢æˆä¸€ä¸ªäº’è¡¥çš„å¼ºåŒ–å­¦ä¹ ç³»ç»Ÿã€‚DQNæ“…é•¿ç¦»æ•£åŠ¨ä½œç©ºé—´çš„å†³ç­–ï¼ŒTD3æ“…é•¿è¿ç»­åŠ¨ä½œç©ºé—´çš„æ§åˆ¶ã€‚è¿™ç§æ··åˆæ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”åŠ¨æ€ç¯å¢ƒä¸­çš„è‡ªä¸»å¯¼èˆªä»»åŠ¡ï¼Œæé«˜å¯¼èˆªæ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šå¥–åŠ±å‡½æ•°çš„è®¾è®¡è‡³å…³é‡è¦ï¼ŒåŒ…æ‹¬æ–¹å‘å¥–åŠ±ã€è·ç¦»å¥–åŠ±ã€é¿éšœå¥–åŠ±ã€åŠ¨ä½œå¹³æ»‘æ€§å¥–åŠ±ã€ç¢°æ’æƒ©ç½šã€æ—¶é—´æƒ©ç½šå’Œè¿›åº¦å¥–åŠ±ã€‚åŸºäºæ¿€å…‰é›·è¾¾çš„å®‰å…¨é—¨ç”¨äºé˜²æ­¢ä¸å®‰å…¨çš„è¿åŠ¨ã€‚DQNä½¿ç”¨Îµ-greedyç­–ç•¥è¿›è¡Œæ¢ç´¢ï¼ŒTD3ä½¿ç”¨é«˜æ–¯å™ªå£°è¿›è¡Œæ¢ç´¢ã€‚ç½‘ç»œçš„å…·ä½“ç»“æ„ï¼ˆå±‚æ•°ã€ç¥ç»å…ƒæ•°é‡ç­‰ï¼‰æ ¹æ®å®éªŒç»“æœè¿›è¡Œè°ƒæ•´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ··åˆDQN-TD3æ–¹æ³•åœ¨æˆåŠŸç‡ã€ç¢°æ’ç‡ã€è·¯å¾„æ•ˆç‡å’Œé‡è§„åˆ’æ•ˆç‡ç­‰æ–¹é¢å‡ä¼˜äºå•ä¸€ç®—æ³•åŸºçº¿ï¼ˆDQNæˆ–TD3ï¼‰å’ŒåŸºäºè§„åˆ™çš„è§„åˆ’å™¨ã€‚å°¤å…¶æ˜¯åœ¨æœªè§è¿‡çš„éšœç¢ç‰©é…ç½®ä¸­ï¼Œè¯¥æ–¹æ³•è¡¨ç°å‡ºæ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶å‡å°‘äº†çªå‘çš„æ§åˆ¶å˜åŒ–ã€‚å…·ä½“æ€§èƒ½æ•°æ®å¯åœ¨é¡¹ç›®ä»“åº“ä¸­æ‰¾åˆ°ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦è‡ªä¸»å¯¼èˆªçš„æœºå™¨äººç³»ç»Ÿï¼Œä¾‹å¦‚æœåŠ¡æœºå™¨äººã€ç‰©æµæœºå™¨äººã€æ— äººé©¾é©¶è½¦è¾†ç­‰ã€‚é€šè¿‡æé«˜æœºå™¨äººåœ¨å¤æ‚åŠ¨æ€ç¯å¢ƒä¸­çš„å¯¼èˆªèƒ½åŠ›ï¼Œå¯ä»¥æå‡å·¥ä½œæ•ˆç‡ï¼Œé™ä½å®‰å…¨é£é™©ï¼Œå¹¶æ‰©å±•æœºå™¨äººçš„åº”ç”¨èŒƒå›´ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper presents a hierarchical path-planning and control framework that combines a high-level Deep Q-Network (DQN) for discrete sub-goal selection with a low-level Twin Delayed Deep Deterministic Policy Gradient (TD3) controller for continuous actuation. The high-level module selects behaviors and sub-goals; the low-level module executes smooth velocity commands. We design a practical reward shaping scheme (direction, distance, obstacle avoidance, action smoothness, collision penalty, time penalty, and progress), together with a LiDAR-based safety gate that prevents unsafe motions. The system is implemented in ROS + Gazebo (TurtleBot3) and evaluated with PathBench metrics, including success rate, collision rate, path efficiency, and re-planning efficiency, in dynamic and partially observable environments. Experiments show improved success rate and sample efficiency over single-algorithm baselines (DQN or TD3 alone) and rule-based planners, with better generalization to unseen obstacle configurations and reduced abrupt control changes. Code and evaluation scripts are available at the project repository.

