---
layout: default
title: Pelican-VL 1.0: A Foundation Brain Model for Embodied Intelligence
---

# Pelican-VL 1.0: A Foundation Brain Model for Embodied Intelligence

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.00108" target="_blank" class="toolbar-btn">arXiv: 2511.00108v2</a>
    <a href="https://arxiv.org/pdf/2511.00108.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.00108v2" 
            onclick="toggleFavorite(this, '2511.00108v2', 'Pelican-VL 1.0: A Foundation Brain Model for Embodied Intelligence')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yi Zhang, Che Liu, Xiancong Ren, Hanchu Ni, Shuai Zhang, Zeyuan Ding, Jiayu Hu, Hanzhe Shan, Zhenwei Niu, Zhaoyang Liu, Shuang Liu, Yue Zhao, Junbo Qi, Qinfan Zhang, Dengjie Li, Yidong Wang, Jiachen Luo, Yong Dai, Zenglin Xu, Bin Shen, Qifan Wang, Jian Tang, Xiaozhu Ju

**ÂàÜÁ±ª**: cs.LG, cs.AI, cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-30 (Êõ¥Êñ∞: 2025-11-14)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**Pelican-VL 1.0ÔºöÁî®‰∫éÂÖ∑Ë∫´Êô∫ËÉΩÁöÑÂºÄÊ∫êÂü∫Á°ÄÂ§ßËÑëÊ®°Âûã**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÂÖ∑Ë∫´Êô∫ËÉΩ` `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `Âº∫ÂåñÂ≠¶‰π†` `Êï∞ÊçÆÊèêÁÇº` `Â§ßËÑëÊ®°Âûã`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂÖ∑Ë∫´Êô∫ËÉΩÊ®°ÂûãÂú®Êï∞ÊçÆË¥®ÈáèÂíåËÆ≠ÁªÉÊïàÁéáÊñπÈù¢Â≠òÂú®Áì∂È¢àÔºåÈöæ‰ª•ÂÖÖÂàÜÂà©Áî®Â§ßËßÑÊ®°Êï∞ÊçÆ„ÄÇ
2. Pelican-VL 1.0 ÈÄöËøá metaloop ÊèêÁÇºÈ´òË¥®ÈáèÊï∞ÊçÆÈõÜÔºåÂπ∂ÈááÁî® DPPO Ê°ÜÊû∂ËøõË°åÂàªÊÑèÁªÉ‰π†ÔºåÊèêÂçáÊ®°ÂûãÊÄßËÉΩ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåPelican-VL 1.0 ÊÄßËÉΩ‰ºò‰∫éÂêåÁ≠âËßÑÊ®°ÁöÑÂºÄÊ∫êÊ®°ÂûãÔºåÂπ∂‰∏éÈ¢ÜÂÖàÁöÑ‰∏ìÊúâÁ≥ªÁªüÂú®ÂÖ∑Ë∫´Âü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞Áõ∏ÂΩì„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨Êä•Âëä‰ªãÁªç‰∫ÜPelican-VL 1.0ÔºåËøôÊòØ‰∏Ä‰∏™Êñ∞ÁöÑÂºÄÊ∫êÂÖ∑Ë∫´Â§ßËÑëÊ®°ÂûãÁ≥ªÂàóÔºåÂèÇÊï∞ËßÑÊ®°‰ªé70‰∫øÂà∞720‰∫ø‰∏çÁ≠â„ÄÇÊàë‰ª¨ÁöÑÊòéÁ°ÆÁõÆÊ†áÊòØÔºöÂ∞ÜÂº∫Â§ßÁöÑÊô∫ËÉΩÂµåÂÖ•Âà∞ÂêÑÁßçÂÖ∑Ë∫´ÁéØÂ¢É‰∏≠„ÄÇPelican-VL 1.0ÊòØÁõÆÂâçÊúÄÂ§ßËßÑÊ®°ÁöÑÂºÄÊ∫êÂÖ∑Ë∫´Â§öÊ®°ÊÄÅÂ§ßËÑëÊ®°Âûã„ÄÇÂÖ∂Ê†∏ÂøÉ‰ºòÂäøÂú®‰∫éÊï∞ÊçÆËÉΩÂäõÂíåÊô∫ËÉΩËá™ÈÄÇÂ∫îÂ≠¶‰π†Êú∫Âà∂ÁöÑÊ∑±Â∫¶Êï¥Âêà„ÄÇÂÖ∑‰ΩìÊù•ËØ¥Ôºåmetaloop‰ªéÂåÖÂê´40‰∫ø+ tokens ÁöÑÂéüÂßãÊï∞ÊçÆÈõÜ‰∏≠ÊèêÁÇºÂá∫‰∫ÜÈ´òË¥®ÈáèÁöÑÊï∞ÊçÆÈõÜ„ÄÇPelican-VL 1.0 Âú®‰∏Ä‰∏™ÂåÖÂê´ 1000+ A800 GPU ÁöÑÂ§ßÂûãÈõÜÁæ§‰∏äËøõË°åËÆ≠ÁªÉÔºåÊØè‰∏™ checkpoint Ê∂àËÄóË∂ÖËøá 50k+ A800 GPU-hours„ÄÇËøô‰ΩøÂæóÂÖ∂ÊÄßËÉΩÊØîÂü∫Á°ÄÊ®°ÂûãÊèêÂçá‰∫Ü 20.3%ÔºåÂπ∂‰∏îÊØî 100B Á∫ßÂà´ÁöÑÂºÄÊ∫êÊ®°ÂûãÈ´òÂá∫ 10.6%ÔºåÂú®ËëóÂêçÁöÑÂÖ∑Ë∫´Âü∫ÂáÜÊµãËØï‰∏≠‰∏éÈ¢ÜÂÖàÁöÑ‰∏ìÊúâÁ≥ªÁªüÁõ∏ÂΩì„ÄÇÊàë‰ª¨Âª∫Á´ã‰∫Ü‰∏Ä‰∏™Âèó‰∫∫Á±ªÂÖÉËÆ§Áü•ÂêØÂèëÁöÑÂÖ®Êñ∞Ê°ÜÊû∂ DPPO (Deliberate Practice Policy Optimization)ÔºåÁî®‰∫éËÆ≠ÁªÉ Pelican-VL 1.0„ÄÇÊàë‰ª¨Â∞ÜÂÖ∂Êìç‰ΩúÂåñ‰∏∫‰∏Ä‰∏™ metaloopÔºåÊïôÂØº AI ËøõË°åÂàªÊÑèÁªÉ‰π†ÔºåËøôÊòØ‰∏Ä‰∏™ RL-Refine-Diagnose-SFT Âæ™ÁéØ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÂÖ∑Ë∫´Êô∫ËÉΩÊ®°ÂûãÈù¢‰∏¥Êï∞ÊçÆË¥®Èáè‰∏çÈ´ò„ÄÅËÆ≠ÁªÉÊïàÁéá‰Ωé‰∏ãÁ≠âÈóÆÈ¢òÔºåÈôêÂà∂‰∫ÜÊ®°ÂûãÂú®Â§çÊùÇÂÖ∑Ë∫´‰ªªÂä°‰∏≠ÁöÑË°®Áé∞„ÄÇÁé∞ÊúâÊñπÊ≥ïÈöæ‰ª•ÊúâÊïàÂà©Áî®Â§ßËßÑÊ®°ÂéüÂßãÊï∞ÊçÆÔºåÂπ∂‰∏îÁº∫‰πèÊúâÊïàÁöÑËá™ÈÄÇÂ∫îÂ≠¶‰π†Êú∫Âà∂ÔºåÂØºËá¥Ê®°ÂûãÊ≥õÂåñËÉΩÂäõ‰∏çË∂≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöPelican-VL 1.0 ÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÊï∞ÊçÆÊèêÁÇºÂíåÂº∫ÂåñÂ≠¶‰π†‰ºòÂåñÁõ∏ÁªìÂêàÔºåÊèêÂçáÊ®°ÂûãÂú®ÂÖ∑Ë∫´ÁéØÂ¢É‰∏≠ÁöÑÊô∫ËÉΩÊ∞¥Âπ≥„ÄÇÈÄöËøá metaloop ÊèêÁÇºÈ´òË¥®ÈáèÊï∞ÊçÆÈõÜÔºåÂáèÂ∞ëÂô™Â£∞Êï∞ÊçÆÁöÑÂΩ±ÂìçÔºõÈÄöËøá DPPO Ê°ÜÊû∂Ê®°Êãü‰∫∫Á±ªÁöÑÂàªÊÑèÁªÉ‰π†ËøáÁ®ãÔºå‰ΩøÊ®°ÂûãËÉΩÂ§üËá™ÈÄÇÂ∫îÂú∞Â≠¶‰π†ÂíåÊîπËøõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöPelican-VL 1.0 ÁöÑËÆ≠ÁªÉÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Èò∂ÊÆµÔºö1) Êï∞ÊçÆÊî∂ÈõÜÔºöÊî∂ÈõÜÂåÖÂê´Â§ßÈáè tokens ÁöÑÂéüÂßãÊï∞ÊçÆÈõÜ„ÄÇ2) Êï∞ÊçÆÊèêÁÇºÔºö‰ΩøÁî® metaloop ‰ªéÂéüÂßãÊï∞ÊçÆÈõÜ‰∏≠ÊèêÁÇºÈ´òË¥®ÈáèÁöÑÊï∞ÊçÆÈõÜ„ÄÇ3) Ê®°ÂûãËÆ≠ÁªÉÔºö‰ΩøÁî®ÊèêÁÇºÂêéÁöÑÊï∞ÊçÆÈõÜËÆ≠ÁªÉÂü∫Á°ÄÊ®°Âûã„ÄÇ4) Á≠ñÁï•‰ºòÂåñÔºö‰ΩøÁî® DPPO Ê°ÜÊû∂ÂØπÊ®°ÂûãËøõË°åÂº∫ÂåñÂ≠¶‰π†‰ºòÂåñÔºå‰ΩøÂÖ∂ËÉΩÂ§üÊõ¥Â•ΩÂú∞ÈÄÇÂ∫îÂÖ∑Ë∫´ÁéØÂ¢É„ÄÇDPPO Ê°ÜÊû∂ÂåÖÂê´ RL (Reinforcement Learning)„ÄÅRefine„ÄÅDiagnose Âíå SFT (Supervised Fine-Tuning) Âõõ‰∏™Èò∂ÊÆµ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöPelican-VL 1.0 ÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫é DPPO Ê°ÜÊû∂Âíå metaloop Êï∞ÊçÆÊèêÁÇºÊñπÊ≥ï„ÄÇDPPO Ê°ÜÊû∂Ê®°Êãü‰∫∫Á±ªÁöÑÂàªÊÑèÁªÉ‰π†ËøáÁ®ãÔºå‰ΩøÊ®°ÂûãËÉΩÂ§üËá™ÈÄÇÂ∫îÂú∞Â≠¶‰π†ÂíåÊîπËøõ„ÄÇmetaloop Êï∞ÊçÆÊèêÁÇºÊñπÊ≥ïËÉΩÂ§ü‰ªéÂ§ßËßÑÊ®°ÂéüÂßãÊï∞ÊçÆÈõÜ‰∏≠ÊèêÂèñÈ´òË¥®ÈáèÁöÑÊï∞ÊçÆÔºåÂáèÂ∞ëÂô™Â£∞Êï∞ÊçÆÁöÑÂΩ±Âìç„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåDPPO Ê°ÜÊû∂Êõ¥Âä†Ê≥®ÈáçÊ®°ÂûãÁöÑËá™ÈÄÇÂ∫îÂ≠¶‰π†ËÉΩÂäõÔºåËÄå metaloop Êï∞ÊçÆÊèêÁÇºÊñπÊ≥ïËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞Âà©Áî®Â§ßËßÑÊ®°Êï∞ÊçÆ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöDPPO Ê°ÜÊû∂‰∏≠ÁöÑÂ•ñÂä±ÂáΩÊï∞ËÆæËÆ°ÊòØÂÖ≥ÈîÆ„ÄÇÂ•ñÂä±ÂáΩÊï∞ÈúÄË¶ÅËÉΩÂ§üÂáÜÁ°ÆÂú∞ÂèçÊò†Ê®°ÂûãÂú®ÂÖ∑Ë∫´ÁéØÂ¢É‰∏≠ÁöÑË°®Áé∞ÔºåÂπ∂‰∏îËÉΩÂ§üÂºïÂØºÊ®°ÂûãÊúùÁùÄÊ≠£Á°ÆÁöÑÊñπÂêëÂ≠¶‰π†„ÄÇmetaloop Êï∞ÊçÆÊèêÁÇºÊñπÊ≥ï‰∏≠ÁöÑÊèêÁÇºÁ≠ñÁï•‰πüÊòØÂÖ≥ÈîÆ„ÄÇÊèêÁÇºÁ≠ñÁï•ÈúÄË¶ÅËÉΩÂ§üÊúâÊïàÂú∞ËØÜÂà´ÂíåÊèêÂèñÈ´òË¥®ÈáèÁöÑÊï∞ÊçÆÔºåÂêåÊó∂ËøáÊª§ÊéâÂô™Â£∞Êï∞ÊçÆ„ÄÇÂÖ∑‰ΩìÁöÑÂèÇÊï∞ËÆæÁΩÆÂíåÁΩëÁªúÁªìÊûÑÁªÜËäÇÂú®ËÆ∫Êñá‰∏≠Êú™ËØ¶ÁªÜËØ¥ÊòéÔºåÂ±û‰∫éÊú™Áü•‰ø°ÊÅØ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Pelican-VL 1.0 Âú®ÂÖ∑Ë∫´Âü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞Âá∫Ëâ≤ÔºåÊØîÂü∫Á°ÄÊ®°ÂûãÊèêÂçá‰∫Ü 20.3%ÔºåÂπ∂‰∏îÊØî 100B Á∫ßÂà´ÁöÑÂºÄÊ∫êÊ®°ÂûãÈ´òÂá∫ 10.6%Ôºå‰∏éÈ¢ÜÂÖàÁöÑ‰∏ìÊúâÁ≥ªÁªüÁõ∏ÂΩì„ÄÇËøôË°®Êòé Pelican-VL 1.0 Âú®ÂÖ∑Ë∫´Êô∫ËÉΩÈ¢ÜÂüüÂÖ∑ÊúâÂæàÂº∫ÁöÑÁ´û‰∫âÂäõÔºåÂπ∂‰∏îÂÖ∑ÊúâÂæàÂ§ßÁöÑÂ∫îÁî®ÊΩúÂäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

Pelican-VL 1.0 ÂèØÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫ÊéßÂà∂„ÄÅËá™Âä®È©æÈ©∂„ÄÅËôöÊãüÁé∞ÂÆûÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÂ∞ÜÂº∫Â§ßÁöÑÊô∫ËÉΩÂµåÂÖ•Âà∞ÂêÑÁßçÂÖ∑Ë∫´ÁéØÂ¢É‰∏≠ÔºåÂèØ‰ª•ÂÆûÁé∞Êõ¥Êô∫ËÉΩ„ÄÅÊõ¥Ëá™‰∏ªÁöÑÊú∫Âô®‰∫∫Á≥ªÁªü„ÄÇ‰æãÂ¶ÇÔºåÂèØ‰ª•Áî®‰∫éÂºÄÂèëËÉΩÂ§üËá™‰∏ªÂÆåÊàêÂ§çÊùÇ‰ªªÂä°ÁöÑÊú∫Âô®‰∫∫Âä©ÊâãÔºåÊàñËÄÖÁî®‰∫éÂºÄÂèëÊõ¥ÂÆâÂÖ®„ÄÅÊõ¥ÂèØÈù†ÁöÑËá™Âä®È©æÈ©∂Á≥ªÁªü„ÄÇËØ•Á†îÁ©∂ÁöÑÊú™Êù•ÂΩ±ÂìçÂú®‰∫éÊé®Âä®ÂÖ∑Ë∫´Êô∫ËÉΩÊäÄÊúØÁöÑÂèëÂ±ïÔºåÂÆûÁé∞Êõ¥Êô∫ËÉΩ„ÄÅÊõ¥‰∫∫ÊÄßÂåñÁöÑÊú∫Âô®‰∫∫Á≥ªÁªü„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> This report presents Pelican-VL 1.0, a new family of open-source embodied brain models with parameter scales ranging from 7 billion to 72 billion. Our explicit mission is clearly stated as: To embed powerful intelligence into various embodiments. Pelican-VL 1.0 is currently the largest-scale open-source embodied multimodal brain model. Its core advantage lies in the in-depth integration of data power and intelligent adaptive learning mechanisms. Specifically, metaloop distilled a high-quality dataset from a raw dataset containing 4+ billion tokens. Pelican-VL 1.0 is trained on a large-scale cluster of 1000+ A800 GPUs, consuming over 50k+ A800 GPU-hours per checkpoint. This translates to a 20.3% performance uplift from its base model and outperforms 100B-level open-source counterparts by 10.6%, placing it on par with leading proprietary systems on well-known embodied benchmarks. We establish a novel framework, DPPO (Deliberate Practice Policy Optimization), inspired by human metacognition to train Pelican-VL 1.0. We operationalize this as a metaloop that teaches the AI to practice deliberately, which is a RL-Refine-Diagnose-SFT loop.

