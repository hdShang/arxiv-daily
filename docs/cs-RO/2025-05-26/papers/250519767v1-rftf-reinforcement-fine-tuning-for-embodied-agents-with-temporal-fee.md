---
layout: default
title: RFTF: Reinforcement Fine-tuning for Embodied Agents with Temporal Feedback
---

# RFTF: Reinforcement Fine-tuning for Embodied Agents with Temporal Feedback

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.19767" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.19767v1</a>
  <a href="https://arxiv.org/pdf/2505.19767.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.19767v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.19767v1', 'RFTF: Reinforcement Fine-tuning for Embodied Agents with Temporal Feedback')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Junyang Shu, Zhiwei Lin, Yongtao Wang

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-26

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫RFTF‰ª•Ëß£ÂÜ≥Áé∞ÊúâÂº∫ÂåñÂæÆË∞ÉÊñπÊ≥ïÁ®ÄÁñèÂ•ñÂä±ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Âº∫ÂåñÂ≠¶‰π†` `ÂÖ∑Ë∫´Êô∫ËÉΩ` `Â•ñÂä±Êú∫Âà∂` `‰ª∑ÂÄºÊ®°Âûã` `‰ªªÂä°ÊâßË°å` `ÈÄÇÂ∫îËÉΩÂäõ` `ÂæÆË∞ÉÊäÄÊúØ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÂº∫ÂåñÂæÆË∞ÉÊñπÊ≥ï‰æùËµñÁ®ÄÁñèÂ•ñÂä±ÔºåÈöæ‰ª•Êèê‰æõÁªÜÁ≤íÂ∫¶ÁöÑÂèçÈ¶àÔºåÈôêÂà∂‰∫ÜÊô∫ËÉΩ‰ΩìÁöÑÊìç‰ΩúËÉΩÂäõÂíåÊ≥õÂåñÊÄßËÉΩ„ÄÇ
2. RFTFÈÄöËøáÂºïÂÖ•‰ª∑ÂÄºÊ®°ÂûãÁîüÊàêÂØÜÈõÜÂ•ñÂä±ÔºåÂà©Áî®Êó∂Èó¥‰ø°ÊÅØËøõË°åËÆ≠ÁªÉÔºåÂáèÂ∞ëÂØπÊòÇË¥µÊ†áÁ≠æÁöÑ‰æùËµñ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåRFTFÊòæËëóÊèêÂçá‰∫ÜÂÖ∑Ë∫´Êô∫ËÉΩ‰ΩìÁöÑË°®Áé∞ÔºåÂú®CALVIN‰ªªÂä°‰∏äÂèñÂæó‰∫ÜÊñ∞ÁöÑÊàêÂäüÈïøÂ∫¶ËÆ∞ÂΩïÔºåÂπ∂ËÉΩÂø´ÈÄüÈÄÇÂ∫îÊñ∞ÁéØÂ¢É„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÔºàVLAÔºâÊ®°ÂûãÂú®ÂÖ∑Ë∫´Êô∫ËÉΩÈ¢ÜÂüüÂ±ïÁé∞Âá∫ÊòæËëóÊΩúÂäõÔºå‰ΩøÂæóÊô∫ËÉΩ‰ΩìËÉΩÂ§üÈÅµÂæ™‰∫∫Á±ªÊåá‰ª§Âú®Áâ©ÁêÜÁéØÂ¢É‰∏≠ÂÆåÊàêÂ§çÊùÇ‰ªªÂä°„ÄÇÁé∞ÊúâÁöÑÂÖ∑Ë∫´Êô∫ËÉΩ‰ΩìÈÄöÂ∏∏ÈÄöËøáË°å‰∏∫ÂÖãÈöÜËøõË°åËÆ≠ÁªÉÔºåËøôÈúÄË¶ÅÊòÇË¥µÁöÑÊï∞ÊçÆÂíåËÆ°ÁÆóËµÑÊ∫êÔºåÂπ∂ÂèóÂà∞‰∫∫Á±ªÁ§∫ËåÉÁöÑÈôêÂà∂„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏ÄÈóÆÈ¢òÔºåËÆ∏Â§öÁ†îÁ©∂ËÄÖÊé¢Á¥¢Â∞ÜÂº∫ÂåñÂæÆË∞ÉÂ∫îÁî®‰∫éÂÖ∑Ë∫´Êô∫ËÉΩ‰Ωì„ÄÇÁÑ∂ËÄåÔºåÂÖ∏ÂûãÁöÑÂº∫ÂåñÂæÆË∞ÉÊñπÊ≥ïÈÄöÂ∏∏‰æùËµñÁ®ÄÁñèÁöÑÂü∫‰∫éÁªìÊûúÁöÑÂ•ñÂä±ÔºåËøôÈôêÂà∂‰∫ÜÊ®°ÂûãÂú®ÁâπÂÆöÂä®‰Ωú‰∏äÁöÑÂèçÈ¶àËÉΩÂäõÔºå‰ªéËÄåÂΩ±ÂìçÂÖ∂Êìç‰ΩúËÉΩÂäõÂíåÊ≥õÂåñÊÄßËÉΩ„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÂº∫ÂåñÂæÆË∞ÉÊñπÊ≥ïRFTFÔºåÂà©Áî®‰ª∑ÂÄºÊ®°ÂûãÂú®ÂÖ∑Ë∫´Âú∫ÊôØ‰∏≠ÁîüÊàêÂØÜÈõÜÂ•ñÂä±ÔºåÊ∂àÈô§‰∫ÜÂØπÊòÇË¥µÊú∫Âô®‰∫∫Âä®‰ΩúÊ†áÁ≠æÁöÑÈúÄÊ±ÇÔºåÂπ∂ÈÄöËøáGAEÂíåÊ†∑Êú¨Âπ≥Ë°°Á≠âÊäÄÊúØÂ¢ûÂº∫ÂæÆË∞ÉÊïàÊûú„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºå‰ΩøÁî®RFTFÂæÆË∞ÉÁöÑÂÖ∑Ë∫´Êô∫ËÉΩ‰ΩìÂú®CALVIN ABC-D‰ªªÂä°‰∏äÂèñÂæó‰∫ÜÊñ∞ÁöÑÊúÄÂÖàËøõÊÄßËÉΩ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâÂº∫ÂåñÂæÆË∞ÉÊñπÊ≥ï‰∏≠Á®ÄÁñèÂ•ñÂä±ÁöÑÈóÆÈ¢òÔºåËøôÁßçÊñπÊ≥ïÈöæ‰ª•Êèê‰æõÈíàÂØπÁâπÂÆöÂä®‰ΩúÁöÑÁªÜÁ≤íÂ∫¶ÂèçÈ¶àÔºåÈôêÂà∂‰∫ÜÊô∫ËÉΩ‰ΩìÁöÑÊìç‰ΩúËÉΩÂäõÂíåÊ≥õÂåñÊÄßËÉΩ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöRFTFÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®‰ª∑ÂÄºÊ®°ÂûãÁîüÊàêÂØÜÈõÜÂ•ñÂä±ÔºåÈÄöËøáÊó∂Èó¥‰ø°ÊÅØÁöÑÂºïÂÖ•ÔºåÊ∂àÈô§ÂØπÊòÇË¥µÊú∫Âô®‰∫∫Âä®‰ΩúÊ†áÁ≠æÁöÑÈúÄÊ±ÇÔºå‰ªéËÄåÊèêÈ´òÂæÆË∞ÉÊïàÊûú„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöRFTFÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰ª∑ÂÄºÊ®°ÂûãÁöÑËÆ≠ÁªÉ„ÄÅÂ•ñÂä±ÁîüÊàêÂíåÂæÆË∞ÉËøáÁ®ã„ÄÇÈ¶ñÂÖàÔºå‰ª∑ÂÄºÊ®°ÂûãÂà©Áî®Êó∂Èó¥‰ø°ÊÅØËøõË°åËÆ≠ÁªÉÔºåÁÑ∂ÂêéÁîüÊàêÂØÜÈõÜÂ•ñÂä±ÔºåÊúÄÂêéÈÄöËøáÂº∫ÂåñÂ≠¶‰π†ÁÆóÊ≥ïËøõË°åÂæÆË∞É„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöRFTFÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÈÄöËøá‰ª∑ÂÄºÊ®°ÂûãÁîüÊàêÂØÜÈõÜÂ•ñÂä±ÔºåËß£ÂÜ≥‰∫Ü‰º†ÁªüÊñπÊ≥ï‰∏≠Á®ÄÁñèÂ•ñÂä±ÁöÑÂ±ÄÈôêÊÄß„ÄÇËøô‰∏ÄËÆæËÆ°‰ΩøÂæóÊô∫ËÉΩ‰ΩìËÉΩÂ§üËé∑ÂæóÊõ¥ÁªÜËá¥ÁöÑÂèçÈ¶àÔºå‰ªéËÄåÊèêÂçáÊìç‰ΩúËÉΩÂäõÂíåÊ≥õÂåñÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®RFTF‰∏≠ÔºåÈááÁî®‰∫ÜGAEÔºàÂπø‰πâ‰ºòÂäø‰º∞ËÆ°ÔºâÂíåÊ†∑Êú¨Âπ≥Ë°°Á≠âÊäÄÊúØÔºå‰ª•Â¢ûÂº∫ÂæÆË∞ÉËøáÁ®ãÁöÑÊúâÊïàÊÄß„ÄÇÊ≠§Â§ñÔºåÊ®°ÂûãÁöÑËÆ≠ÁªÉËøáÁ®ã‰∏≠‰∏çÂÜç‰æùËµñÊòÇË¥µÁöÑÂä®‰ΩúÊ†áÁ≠æÔºåÈôç‰Ωé‰∫ÜËÆ≠ÁªÉÊàêÊú¨„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫Ôºå‰ΩøÁî®RFTFÂæÆË∞ÉÁöÑÂÖ∑Ë∫´Êô∫ËÉΩ‰ΩìÂú®CALVIN ABC-D‰ªªÂä°‰∏äÂèñÂæó‰∫ÜÂπ≥ÂùáÊàêÂäüÈïøÂ∫¶4.296ÔºåË∂ÖË∂ä‰∫Ü‰ª•ÂæÄÁöÑÊúÄÂÖàËøõÊÄßËÉΩ„ÄÇÊ≠§Â§ñÔºåÂú®Êñ∞ÁéØÂ¢ÉD‰∏≠ÔºåÁªèËøáÂ∞ëÈáèÁöÑÂæÆË∞ÉÂêéÔºåÊàêÂäüÈïøÂ∫¶ËææÂà∞‰∫Ü4.301ÔºåÂ±ïÁé∞‰∫ÜÂø´ÈÄüÈÄÇÂ∫îËÉΩÂäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Êú∫Âô®‰∫∫ÂØºËà™„ÄÅËá™Âä®Âåñ‰ªªÂä°ÊâßË°åÂíå‰∫∫Êú∫‰∫§‰∫íÁ≠â„ÄÇÈÄöËøáÊèêÂçáÂÖ∑Ë∫´Êô∫ËÉΩ‰ΩìÁöÑÊìç‰ΩúËÉΩÂäõÂíåÈÄÇÂ∫îÊÄßÔºåRFTFÂèØ‰ª•Âú®Â§çÊùÇÁöÑÁâ©ÁêÜÁéØÂ¢É‰∏≠ÂÆûÁé∞Êõ¥È´òÊïàÁöÑ‰ªªÂä°ÊâßË°åÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇÊú™Êù•ÔºåRFTFÊúâÊúõÊé®Âä®Êô∫ËÉΩ‰ΩìÂú®Âä®ÊÄÅÁéØÂ¢É‰∏≠ÁöÑËá™‰∏ªÂ≠¶‰π†ÂíåÈÄÇÂ∫îËÉΩÂäõÁöÑËøõ‰∏ÄÊ≠•ÊèêÂçá„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Vision-Language-Action (VLA) models have demonstrated significant potential in the field of embodied intelligence, enabling agents to follow human instructions to complete complex tasks in physical environments. Existing embodied agents are often trained through behavior cloning, which requires expensive data and computational resources and is constrained by human demonstrations. To address this issue, many researchers explore the application of reinforcement fine-tuning to embodied agents. However, typical reinforcement fine-tuning methods for embodied agents usually rely on sparse, outcome-based rewards, which struggle to provide fine-grained feedback for specific actions within an episode, thus limiting the model's manipulation capabilities and generalization performance. In this paper, we propose RFTF, a novel reinforcement fine-tuning method that leverages a value model to generate dense rewards in embodied scenarios. Specifically, our value model is trained using temporal information, eliminating the need for costly robot action labels. In addition, RFTF incorporates a range of techniques, such as GAE and sample balance to enhance the effectiveness of the fine-tuning process. By addressing the sparse reward problem in reinforcement fine-tuning, our method significantly improves the performance of embodied agents, delivering superior generalization and adaptation capabilities across diverse embodied tasks. Experimental results show that embodied agents fine-tuned with RFTF achieve new state-of-the-art performance on the challenging CALVIN ABC-D with an average success length of 4.296. Moreover, RFTF enables rapid adaptation to new environments. After fine-tuning in the D environment of CALVIN for a few episodes, RFTF achieved an average success length of 4.301 in this new environment.

