---
layout: default
title: Intrinsic-Motivation Multi-Robot Social Formation Navigation with Coordinated Exploration
---

# Intrinsic-Motivation Multi-Robot Social Formation Navigation with Coordinated Exploration

**arXiv**: [2512.13293v2](https://arxiv.org/abs/2512.13293) | [PDF](https://arxiv.org/pdf/2512.13293.pdf)

**ä½œè€…**: Hao Fu, Wei Liu, Shuai Zhou

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-15 (æ›´æ–°: 2025-12-16)

**ðŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/czxhunzi/CEMRRL)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽå†…åœ¨åŠ¨æœºçš„å¤šæœºå™¨äººç¤¾ä¼šç¼–é˜Ÿå¯¼èˆªç®—æ³•ï¼Œå®žçŽ°ååŒæŽ¢ç´¢ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `å¤šæœºå™¨äººç³»ç»Ÿ` `å¼ºåŒ–å­¦ä¹ ` `ç¤¾ä¼šç¼–é˜Ÿå¯¼èˆª` `å†…åœ¨åŠ¨æœº` `ååŒæŽ¢ç´¢`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. è¡Œäººè¡Œä¸ºçš„ä¸å¯é¢„æµ‹æ€§å’Œä¸åˆä½œæ€§ç»™å¤šæœºå™¨äººç¤¾ä¼šç¼–é˜Ÿå¯¼èˆªå¸¦æ¥æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨ååŒæŽ¢ç´¢æ•ˆçŽ‡æ–¹é¢ã€‚
2. æå‡ºä¸€ç§åŸºäºŽå†…åœ¨åŠ¨æœºçš„ååŒæŽ¢ç´¢å¤šæœºå™¨äººå¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œé€šè¿‡è‡ªå­¦ä¹ å†…åœ¨å¥–åŠ±æœºåˆ¶ç¼“è§£ç­–ç•¥ä¿å®ˆæ€§ã€‚
3. é‡‡ç”¨åŒé‡é‡‡æ ·æ¨¡å¼å¢žå¼ºå¯¼èˆªç­–ç•¥å’Œå†…åœ¨å¥–åŠ±çš„è¡¨ç¤ºï¼Œå¹¶é€šè¿‡åŒæ—¶é—´å°ºåº¦æ›´æ–°è§„åˆ™è§£è€¦å‚æ•°æ›´æ–°ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ç ”ç©¶äº†å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åœ¨å¤šæœºå™¨äººç¤¾ä¼šç¼–é˜Ÿå¯¼èˆªä¸­çš„åº”ç”¨ï¼Œè¿™æ˜¯å®žçŽ°æ— ç¼äººæœºå…±å­˜çš„å…³é”®èƒ½åŠ›ã€‚è™½ç„¶RLæä¾›äº†ä¸€ä¸ªæœ‰å‰æ™¯çš„èŒƒä¾‹ï¼Œä½†è¡Œäººè¡Œä¸ºå›ºæœ‰çš„ä¸å¯é¢„æµ‹æ€§å’Œé€šå¸¸ä¸åˆä½œçš„åŠ¨æ€å¸¦æ¥äº†å·¨å¤§çš„æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨æœºå™¨äººä¹‹é—´åè°ƒæŽ¢ç´¢çš„æ•ˆçŽ‡æ–¹é¢ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„ååŒæŽ¢ç´¢å¤šæœºå™¨äººRLç®—æ³•ï¼Œå¼•å…¥äº†ä¸€ç§å†…åœ¨åŠ¨æœºæŽ¢ç´¢ã€‚å…¶æ ¸å¿ƒç»„æˆéƒ¨åˆ†æ˜¯ä¸€ç§è‡ªå­¦ä¹ å†…åœ¨å¥–åŠ±æœºåˆ¶ï¼Œæ—¨åœ¨å…±åŒç¼“è§£ç­–ç•¥ä¿å®ˆæ€§ã€‚æ­¤å¤–ï¼Œè¯¥ç®—æ³•åœ¨é›†ä¸­è®­ç»ƒå’Œåˆ†æ•£æ‰§è¡Œæ¡†æž¶å†…ç»“åˆäº†åŒé‡é‡‡æ ·æ¨¡å¼ï¼Œä»¥å¢žå¼ºå¯¼èˆªç­–ç•¥å’Œå†…åœ¨å¥–åŠ±çš„è¡¨ç¤ºï¼Œåˆ©ç”¨åŒæ—¶é—´å°ºåº¦æ›´æ–°è§„åˆ™æ¥è§£è€¦å‚æ•°æ›´æ–°ã€‚åœ¨ç¤¾ä¼šç¼–é˜Ÿå¯¼èˆªåŸºå‡†ä¸Šçš„ç»éªŒç»“æžœè¡¨æ˜Žï¼Œæ‰€æå‡ºçš„ç®—æ³•åœ¨å…³é”®æŒ‡æ ‡ä¸Šä¼˜äºŽçŽ°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šæœºå™¨äººç¤¾ä¼šç¼–é˜Ÿå¯¼èˆªä¸­ï¼Œç”±äºŽè¡Œäººè¡Œä¸ºçš„å¤æ‚æ€§å’Œä¸ç¡®å®šæ€§ï¼Œå¯¼è‡´æœºå™¨äººéš¾ä»¥é«˜æ•ˆååŒæŽ¢ç´¢çŽ¯å¢ƒï¼Œä»Žè€Œå½±å“å¯¼èˆªæ€§èƒ½çš„é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•å¾€å¾€å­˜åœ¨ç­–ç•¥ä¿å®ˆæ€§ï¼Œéš¾ä»¥å……åˆ†æŽ¢ç´¢å¤æ‚çŽ¯å¢ƒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å¼•å…¥å†…åœ¨åŠ¨æœºï¼Œé¼“åŠ±æœºå™¨äººä¸»åŠ¨æŽ¢ç´¢æœªçŸ¥åŒºåŸŸï¼Œä»Žè€Œæé«˜ååŒæŽ¢ç´¢çš„æ•ˆçŽ‡ã€‚é€šè¿‡è®¾è®¡ä¸€ç§è‡ªå­¦ä¹ çš„å†…åœ¨å¥–åŠ±æœºåˆ¶ï¼Œå¼•å¯¼æœºå™¨äººå­¦ä¹ æ›´æœ‰æ•ˆçš„å¯¼èˆªç­–ç•¥ï¼Œå¹¶ç¼“è§£ç­–ç•¥ä¿å®ˆæ€§ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šè¯¥ç®—æ³•é‡‡ç”¨é›†ä¸­è®­ç»ƒå’Œåˆ†æ•£æ‰§è¡Œï¼ˆCTDEï¼‰æ¡†æž¶ã€‚åœ¨é›†ä¸­è®­ç»ƒé˜¶æ®µï¼Œæ‰€æœ‰æœºå™¨äººçš„ä¿¡æ¯è¢«é›†ä¸­èµ·æ¥è¿›è¡Œç­–ç•¥å­¦ä¹ å’Œå†…åœ¨å¥–åŠ±å­¦ä¹ ã€‚åœ¨åˆ†æ•£æ‰§è¡Œé˜¶æ®µï¼Œæ¯ä¸ªæœºå™¨äººæ ¹æ®å­¦ä¹ åˆ°çš„ç­–ç•¥å’Œå†…åœ¨å¥–åŠ±ç‹¬ç«‹è¡ŒåŠ¨ã€‚ç®—æ³•åŒ…å«å¯¼èˆªç­–ç•¥å­¦ä¹ æ¨¡å—å’Œå†…åœ¨å¥–åŠ±å­¦ä¹ æ¨¡å—ï¼Œå¹¶é‡‡ç”¨åŒé‡é‡‡æ ·æ¨¡å¼æ¥å¢žå¼ºè¡¨ç¤ºèƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽæå‡ºäº†ä¸€ç§è‡ªå­¦ä¹ çš„å†…åœ¨å¥–åŠ±æœºåˆ¶ï¼Œè¯¥æœºåˆ¶èƒ½å¤Ÿæ ¹æ®çŽ¯å¢ƒçš„å¤æ‚æ€§å’Œæœºå™¨äººçš„æŽ¢ç´¢æƒ…å†µåŠ¨æ€è°ƒæ•´å¥–åŠ±ï¼Œä»Žè€Œæ›´æœ‰æ•ˆåœ°å¼•å¯¼æœºå™¨äººè¿›è¡ŒååŒæŽ¢ç´¢ã€‚æ­¤å¤–ï¼ŒåŒé‡é‡‡æ ·æ¨¡å¼å’ŒåŒæ—¶é—´å°ºåº¦æ›´æ–°è§„åˆ™ä¹Ÿæœ‰åŠ©äºŽæé«˜ç®—æ³•çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šå†…åœ¨å¥–åŠ±å‡½æ•°çš„è®¾è®¡æ˜¯å…³é”®ï¼Œå®ƒéœ€è¦èƒ½å¤Ÿåæ˜ çŽ¯å¢ƒçš„æœªçŸ¥æ€§å’Œæœºå™¨äººçš„æŽ¢ç´¢ç¨‹åº¦ã€‚è®ºæ–‡é‡‡ç”¨äº†ä¸€ç§åŸºäºŽé¢„æµ‹è¯¯å·®çš„å†…åœ¨å¥–åŠ±å‡½æ•°ï¼Œé¼“åŠ±æœºå™¨äººæŽ¢ç´¢é‚£äº›é¢„æµ‹è¯¯å·®è¾ƒå¤§çš„åŒºåŸŸã€‚åŒæ—¶é—´å°ºåº¦æ›´æ–°è§„åˆ™ç”¨äºŽè§£è€¦å¯¼èˆªç­–ç•¥å’Œå†…åœ¨å¥–åŠ±çš„å‚æ•°æ›´æ–°ï¼Œé¿å…ç›¸äº’å¹²æ‰°ã€‚å…·ä½“çš„ç½‘ç»œç»“æž„å’ŒæŸå¤±å‡½æ•°ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼Œæ‰€æå‡ºçš„ç®—æ³•åœ¨ç¤¾ä¼šç¼–é˜Ÿå¯¼èˆªåŸºå‡†ä¸Šä¼˜äºŽçŽ°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚å…·ä½“è€Œè¨€ï¼Œè¯¥ç®—æ³•åœ¨å¯¼èˆªæˆåŠŸçŽ‡ã€è·¯å¾„é•¿åº¦å’Œç¢°æ’žçŽ‡ç­‰å…³é”®æŒ‡æ ‡ä¸Šå‡å–å¾—äº†æ˜¾è‘—æå‡ã€‚å¼€æºä»£ç å’Œè§†é¢‘æ¼”ç¤ºå¯åœ¨GitHubä¸ŠèŽ·å–ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽå„ç§éœ€è¦äººæœºå…±å­˜å’ŒååŒå¯¼èˆªçš„åœºæ™¯ï¼Œä¾‹å¦‚ï¼šå•†åœºã€æœºåœºã€åšç‰©é¦†ç­‰å…¬å…±åœºæ‰€çš„å¯¼è§ˆæœºå™¨äººï¼ŒåŒ»é™¢ã€å…»è€é™¢ç­‰åœºæ‰€çš„è¾…åŠ©æœºå™¨äººï¼Œä»¥åŠæ™ºèƒ½ä»“å‚¨ã€æ™ºèƒ½å·¥åŽ‚ç­‰é¢†åŸŸçš„åä½œæœºå™¨äººã€‚é€šè¿‡æé«˜æœºå™¨äººçš„å¯¼èˆªæ•ˆçŽ‡å’Œå®‰å…¨æ€§ï¼Œå¯ä»¥æ”¹å–„ç”¨æˆ·ä½“éªŒï¼Œæé«˜å·¥ä½œæ•ˆçŽ‡ï¼Œå¹¶ä¿ƒè¿›äººæœºåä½œçš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> This paper investigates the application of reinforcement learning (RL) to multi-robot social formation navigation, a critical capability for enabling seamless human-robot coexistence. While RL offers a promising paradigm, the inherent unpredictability and often uncooperative dynamics of pedestrian behavior pose substantial challenges, particularly concerning the efficiency of coordinated exploration among robots. To address this, we propose a novel coordinated-exploration multi-robot RL algorithm introducing an intrinsic motivation exploration. Its core component is a self-learning intrinsic reward mechanism designed to collectively alleviate policy conservatism. Moreover, this algorithm incorporates a dual-sampling mode within the centralized training and decentralized execution framework to enhance the representation of both the navigation policy and the intrinsic reward, leveraging a two-time-scale update rule to decouple parameter updates. Empirical results on social formation navigation benchmarks demonstrate the proposed algorithm's superior performance over existing state-of-the-art methods across crucial metrics. Our code and video demos are available at: https://github.com/czxhunzi/CEMRRL.

