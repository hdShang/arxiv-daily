---
layout: default
title: "ImLPR: Image-based LiDAR Place Recognition using Vision Foundation Models"
---

# ImLPR: Image-based LiDAR Place Recognition using Vision Foundation Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.18364" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.18364v2</a>
  <a href="https://arxiv.org/pdf/2505.18364.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.18364v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.18364v2', 'ImLPR: Image-based LiDAR Place Recognition using Vision Foundation Models')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Minwoo Jung, Lanke Frank Tarimo Fu, Maurice Fallon, Ayoung Kim

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-23 (Êõ¥Êñ∞: 2025-08-08)

**Â§áÊ≥®**: CoRL2025 Accepted, 23 Pages, 15 Figures and 14 Tables

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/minwoo0611/ImLPR)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫ImLPR‰ª•Ëß£ÂÜ≥LiDARÂú∞ÁÇπËØÜÂà´‰∏≠ÁöÑÁü•ËØÜÂà©Áî®ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `LiDARÂú∞ÁÇπËØÜÂà´` `ËßÜËßâÂü∫Á°ÄÊ®°Âûã` `ÁâπÂæÅÊèêÂèñ` `Êú∫Âô®‰∫∫ÂÆö‰Ωç` `Ê∑±Â∫¶Â≠¶‰π†` `ÂºÄÊ∫êÈ°πÁõÆ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑLPRÊñπÊ≥ï‰∏ªË¶Å‰æùËµñ‰∫éÁâπÂÆö‰ªªÂä°Ê®°ÂûãÔºåÊú™ËÉΩÂÖÖÂàÜÂà©Áî®È¢ÑËÆ≠ÁªÉÁöÑÂü∫Á°ÄÁü•ËØÜÔºåÂØºËá¥È≤ÅÊ£íÊÄß‰∏çË∂≥„ÄÇ
2. ImLPRÈÄöËøáÂ∞ÜÂéüÂßãÁÇπ‰∫ëËΩ¨Êç¢‰∏∫‰∏âÈÄöÈÅìËåÉÂõ¥ÂõæÂÉèËßÜÂõæÔºåÂà©Áî®È¢ÑËÆ≠ÁªÉÁöÑDINOv2 VFMÁîüÊàê‰∏∞ÂØåÁöÑÊèèËø∞Á¨¶„ÄÇ
3. Âú®ÂÖ¨ÂÖ±Êï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåImLPRÂú®Â§ö‰∏™ËØÑ‰º∞ÊåáÊ†á‰∏äË∂ÖË∂ä‰∫ÜÁé∞ÊúâÁöÑÊúÄÂÖàËøõÊñπÊ≥ïÔºåË°®Áé∞Âá∫ÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

LiDARÂú∞ÁÇπËØÜÂà´ÔºàLPRÔºâÊòØÊú∫Âô®‰∫∫ÂÆö‰ΩçÁöÑÂÖ≥ÈîÆÁªÑÊàêÈÉ®ÂàÜÔºåËÉΩÂ§ü‰ΩøÊú∫Âô®‰∫∫Â∞ÜÂΩìÂâçÊâ´Êèè‰∏éÁéØÂ¢ÉÁöÑÂÖàÂâçÂú∞ÂõæÂØπÈΩê„ÄÇÂ∞ΩÁÆ°ËßÜËßâÂú∞ÁÇπËØÜÂà´ÔºàVPRÔºâÂ∑≤ÁªèÂà©Áî®ËßÜËßâÂü∫Á°ÄÊ®°ÂûãÔºàVFMÔºâÊù•Â¢ûÂº∫ÊèèËø∞Á¨¶ÁöÑÈ≤ÅÊ£íÊÄßÔºå‰ΩÜLPR‰ªç‰æùËµñ‰∫éÁâπÂÆö‰ªªÂä°ÁöÑÊ®°ÂûãÔºåÊú™ËÉΩÂÖÖÂàÜÂà©Áî®È¢ÑËÆ≠ÁªÉÁöÑÂü∫Á°ÄÁü•ËØÜ„ÄÇ‰∏∫Ê≠§ÔºåÊú¨ÊñáÊèêÂá∫‰∫ÜImLPRÔºå‰∏Ä‰∏™Êñ∞È¢ñÁöÑÁÆ°ÈÅìÔºåÂà©Áî®È¢ÑËÆ≠ÁªÉÁöÑDINOv2 VFMÁîüÊàê‰∏∞ÂØåÁöÑLPRÊèèËø∞Á¨¶„ÄÇImLPRÊòØÈ¶ñ‰∏™Âú®LPR‰∏≠‰ΩøÁî®VFMÂπ∂‰øùÁïôÂ§ßÈÉ®ÂàÜÈ¢ÑËÆ≠ÁªÉÁü•ËØÜÁöÑÊñπÊ≥ï„ÄÇËØ•ÊñπÊ≥ïÂ∞ÜÂéüÂßãÁÇπ‰∫ëËΩ¨Êç¢‰∏∫Êñ∞ÂûãÁöÑ‰∏âÈÄöÈÅìËåÉÂõ¥ÂõæÂÉèËßÜÂõæÔºàRIVÔºâÔºå‰ª•Âú®LiDARÈ¢ÜÂüü‰∏≠Âà©Áî®VFM„ÄÇÊàë‰ª¨Âú®ÂÖ¨ÂÖ±Êï∞ÊçÆÈõÜ‰∏äÈ™åËØÅ‰∫ÜImLPRÔºåÂπ∂Âú®Â§ö‰∏™ËØÑ‰º∞ÊåáÊ†á‰∏äË∂ÖË∂ä‰∫ÜÁé∞ÊúâÁöÑÊúÄÂÖàËøõÊñπÊ≥ï„ÄÇÊàë‰ª¨Â∞ÜImLPRÂºÄÊ∫êÔºå‰æõÊú∫Âô®‰∫∫Á§æÂå∫‰ΩøÁî®„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥LiDARÂú∞ÁÇπËØÜÂà´‰∏≠ÂØπÈ¢ÑËÆ≠ÁªÉÁü•ËØÜÂà©Áî®‰∏çË∂≥ÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂ§ö‰æùËµñ‰∫éÁâπÂÆö‰ªªÂä°Ê®°ÂûãÔºåÁº∫‰πèÂØπÂü∫Á°ÄÊ®°ÂûãÁöÑÊúâÊïàÂà©Áî®ÔºåÂØºËá¥ÊèèËø∞Á¨¶ÁöÑÈ≤ÅÊ£íÊÄßÂíåÂáÜÁ°ÆÊÄß‰∏çË∂≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöImLPRÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜÂéüÂßãLiDARÁÇπ‰∫ëËΩ¨Êç¢‰∏∫‰∏âÈÄöÈÅìËåÉÂõ¥ÂõæÂÉèËßÜÂõæÔºàRIVÔºâÔºåÂπ∂Âà©Áî®È¢ÑËÆ≠ÁªÉÁöÑDINOv2 VFMÁîüÊàê‰∏∞ÂØåÁöÑÁâπÂæÅÊèèËø∞Á¨¶„ÄÇËøôÁßçËÆæËÆ°‰ΩøÂæóLPRËÉΩÂ§üÂÄüÂä©ËßÜËßâÂü∫Á°ÄÊ®°ÂûãÁöÑÂº∫Â§ßËÉΩÂäõÔºåÊèêÂçáËØÜÂà´ÊÄßËÉΩ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöImLPRÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ„ÄÅRIVÁîüÊàê„ÄÅÁâπÂæÅÊèêÂèñÂíåÂåπÈÖçÈò∂ÊÆµ„ÄÇÈ¶ñÂÖàÔºåÂ∞ÜLiDARÁÇπ‰∫ëËΩ¨Êç¢‰∏∫RIVÔºåÁÑ∂ÂêéÈÄöËøáMultiConvÈÄÇÈÖçÂô®ÊèêÂèñÁâπÂæÅÔºåÊúÄÂêé‰ΩøÁî®Patch-InfoNCEÊçüÂ§±ËøõË°åÊúâÊïàÁöÑÁâπÂæÅÂ≠¶‰π†„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöImLPRÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÈ¶ñÊ¨°Â∞ÜVFMÂ∫îÁî®‰∫éLPR‰ªªÂä°ÔºåÂêåÊó∂‰øùÁïô‰∫ÜÂ§ßÈÉ®ÂàÜÈ¢ÑËÆ≠ÁªÉÁü•ËØÜ„ÄÇËøô‰∏ÄÊñπÊ≥ïÊòæËëóÊèêÂçá‰∫ÜLPRÁöÑÊÄßËÉΩÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§çÊùÇÁéØÂ¢É‰∏ãÁöÑËØÜÂà´ËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°‰∏≠ÔºåImLPRÈááÁî®‰∫ÜMultiConvÈÄÇÈÖçÂô®Êù•Â¢ûÂº∫ÁâπÂæÅÊèêÂèñËÉΩÂäõÔºåÂπ∂ÂºïÂÖ•‰∫ÜPatch-InfoNCEÊçüÂ§±‰ª•‰ºòÂåñÁâπÂæÅÂ≠¶‰π†ËøáÁ®ã„ÄÇRIVÁöÑ‰∏âÈÄöÈÅìËÆæËÆ°‰πü‰∏∫VFMÁöÑÊúâÊïàÂà©Áî®Êèê‰æõ‰∫ÜÂü∫Á°Ä„ÄÇÈÄöËøáÂØπÂÖ≥ÈîÆËÆæËÆ°ÈÄâÊã©ÁöÑÂÖ®Èù¢Ê∂àËûçÂÆûÈ™åÔºåÈáèÂåñ‰∫ÜÂêÑ‰∏™ÁªÑ‰ª∂ÁöÑÂΩ±Âìç„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®Â§ö‰∏™ÂÖ¨ÂÖ±Êï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåImLPRÂú®ÂÜÖÈÉ®ÂíåÂ§ñÈÉ®‰ºöËØùÁöÑLPR‰ªªÂä°‰∏≠ÂùáË∂ÖË∂ä‰∫ÜÁé∞ÊúâÁöÑÊúÄÂÖàËøõÊñπÊ≥ïÔºåÂÖ∑‰ΩìÊÄßËÉΩÊèêÂçáÂπÖÂ∫¶Âú®ÂêÑÈ°πËØÑ‰º∞ÊåáÊ†á‰∏äÂùáË°®Áé∞Âá∫ÊòæËëó‰ºòÂäøÔºåÈ™åËØÅ‰∫ÜÂÖ∂ÊúâÊïàÊÄßÂíå‰ºòË∂äÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ImLPRÁöÑÁ†îÁ©∂ÊàêÊûúÂú®Êú∫Âô®‰∫∫ÂÆö‰Ωç„ÄÅËá™Âä®È©æÈ©∂„ÄÅÊó†‰∫∫Êú∫ÂØºËà™Á≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõ„ÄÇÈÄöËøáÊèêÈ´òLiDARÂú∞ÁÇπËØÜÂà´ÁöÑÂáÜÁ°ÆÊÄßÂíåÈ≤ÅÊ£íÊÄßÔºåImLPRËÉΩÂ§üÊòæËëóÊèêÂçáÊú∫Âô®‰∫∫Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑËá™‰∏ªÂØºËà™ËÉΩÂäõÔºåÊé®Âä®Êô∫ËÉΩÊú∫Âô®‰∫∫ÊäÄÊúØÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> LiDAR Place Recognition (LPR) is a key component in robotic localization, enabling robots to align current scans with prior maps of their environment. While Visual Place Recognition (VPR) has embraced Vision Foundation Models (VFMs) to enhance descriptor robustness, LPR has relied on task-specific models with limited use of pre-trained foundation-level knowledge. This is due to the lack of 3D foundation models and the challenges of using VFM with LiDAR point clouds. To tackle this, we introduce ImLPR, a novel pipeline that employs a pre-trained DINOv2 VFM to generate rich descriptors for LPR. To the best of our knowledge, ImLPR is the first method to utilize a VFM for LPR while retaining the majority of pre-trained knowledge. ImLPR converts raw point clouds into novel three-channel Range Image Views (RIV) to leverage VFM in the LiDAR domain. It employs MultiConv adapters and Patch-InfoNCE loss for effective feature learning. We validate ImLPR on public datasets and outperform state-of-the-art (SOTA) methods across multiple evaluation metrics in both intra- and inter-session LPR. Comprehensive ablations on key design choices such as channel composition, RIV, adapters, and the patch-level loss quantify each component's impact. We release ImLPR as open source for the robotics community: https://github.com/minwoo0611/ImLPR.

