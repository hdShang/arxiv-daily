---
layout: default
title: "Dynamic Manipulation of Deformable Objects in 3D: Simulation, Benchmark and Learning Strategy"
---

# Dynamic Manipulation of Deformable Objects in 3D: Simulation, Benchmark and Learning Strategy

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.17434" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.17434v1</a>
  <a href="https://arxiv.org/pdf/2505.17434.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.17434v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.17434v1', 'Dynamic Manipulation of Deformable Objects in 3D: Simulation, Benchmark and Learning Strategy')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Guanzhou Lan, Yuqi Yang, Anup Teejo Mathew, Feiping Nie, Rong Wang, Xuelong Li, Federico Renda, Bin Zhao

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-23

**å¤‡æ³¨**: 11 pages,

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŠ¨æ€æ“æ§æ¡†æ¶ä»¥è§£å†³3Då¯å˜å½¢ç‰©ä½“æ“æ§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `åŠ¨æ€æ“æ§` `å¯å˜å½¢ç‰©ä½“` `æ¨¡ä»¿å­¦ä¹ ` `ç‰©ç†ä¿¡æ¯é€‚åº”` `é™é˜¶åŠ¨åŠ›å­¦` `æ‰©æ•£ç­–ç•¥` `3Dæ“æ§` `æœºå™¨äººæŠ€æœ¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨åŠ¨æ€æ“æ§ä¸­é¢ä¸´å¤æ‚ç³»ç»ŸåŠ¨æ€å’Œä»»åŠ¡çº¦æŸçš„æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨3Då¯å˜å½¢ç‰©ä½“çš„æ“æ§ä¸Šã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŠ¨æ€ä¿¡æ¯æ‰©æ•£ç­–ç•¥ï¼ˆDIDPï¼‰ï¼Œç»“åˆäº†æ¨¡ä»¿å­¦ä¹ å’Œç‰©ç†ä¿¡æ¯é€‚åº”ï¼Œä»¥æé«˜æ“æ§æ€§èƒ½ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨å‡†ç¡®æ€§å’Œé²æ£’æ€§æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—æå‡äº†æ“æ§ç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç›®æ ‡æ¡ä»¶ä¸‹çš„åŠ¨æ€æ“æ§å› å¤æ‚çš„ç³»ç»ŸåŠ¨æ€å’Œä¸¥æ ¼çš„ä»»åŠ¡çº¦æŸè€Œå…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå°¤å…¶æ˜¯åœ¨é«˜è‡ªç”±åº¦å’Œæ¬ é©±åŠ¨çš„å¯å˜å½¢ç‰©ä½“åœºæ™¯ä¸­ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ç®€åŒ–ä¸ºä½é€Ÿæˆ–2Dè®¾ç½®ï¼Œé™åˆ¶äº†å…¶åœ¨çœŸå®3Dä»»åŠ¡ä¸­çš„é€‚ç”¨æ€§ã€‚æœ¬æ–‡æ¢ç´¢äº†3Dç›®æ ‡æ¡ä»¶ä¸‹çš„ç»³ç´¢æ“æ§ä½œä¸ºä»£è¡¨æ€§æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§æ–°é¢–çš„åŸºäºé™é˜¶åŠ¨åŠ›å­¦çš„ä»¿çœŸæ¡†æ¶å’ŒåŸºå‡†ï¼Œä»¥ä¿ƒè¿›é«˜æ•ˆçš„ç­–ç•¥å­¦ä¹ ã€‚åŸºäºæ­¤ï¼Œæå‡ºäº†åŠ¨æ€ä¿¡æ¯æ‰©æ•£ç­–ç•¥ï¼ˆDIDPï¼‰ï¼Œè¯¥æ¡†æ¶ç»“åˆäº†æ¨¡ä»¿é¢„è®­ç»ƒå’Œç‰©ç†ä¿¡æ¯çš„æµ‹è¯•æ—¶é€‚åº”ï¼Œç¡®ä¿æ“æ§æ‰§è¡Œçš„ä¸€è‡´æ€§å’Œå¯é æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³3Då¯å˜å½¢ç‰©ä½“çš„åŠ¨æ€æ“æ§é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€ç®€åŒ–ä¸ºä½é€Ÿæˆ–2Dåœºæ™¯ï¼Œæ— æ³•æœ‰æ•ˆåº”å¯¹çœŸå®ä¸–ç•Œçš„å¤æ‚æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºåŠ¨æ€ä¿¡æ¯æ‰©æ•£ç­–ç•¥ï¼ˆDIDPï¼‰ï¼Œé€šè¿‡æ¨¡ä»¿å­¦ä¹ ä¸ç‰©ç†ä¿¡æ¯çš„ç»“åˆï¼Œæå‡æ“æ§ç­–ç•¥çš„å­¦ä¹ æ•ˆç‡å’Œæ‰§è¡Œæ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé™é˜¶åŠ¨åŠ›å­¦ä»¿çœŸæ¡†æ¶å’Œæ‰©æ•£ç­–ç•¥å­¦ä¹ ã€‚å‰è€…ç”¨äºç”Ÿæˆç´§å‡‘çš„çŠ¶æ€è¡¨ç¤ºï¼Œåè€…åˆ™é€šè¿‡å­¦ä¹ é€†åŠ¨åŠ›å­¦æ¥æ•æ‰ç‰©ç†ç»“æ„ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†ç‰©ç†ä¿¡æ¯çš„æµ‹è¯•æ—¶é€‚åº”æœºåˆ¶ï¼Œç¡®ä¿æ“æ§è¿‡ç¨‹ä¸­çš„è¿åŠ¨å­¦è¾¹ç•Œæ¡ä»¶å’Œç»“æ„åŠ¨åŠ›å­¦å…ˆéªŒçš„ä¸€è‡´æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šé‡‡ç”¨äº†é™é˜¶åŠ¨åŠ›å­¦æ¨¡å‹æ¥ç®€åŒ–çŠ¶æ€ç©ºé—´ï¼Œè®¾è®¡äº†é€‚åº”æ€§æŸå¤±å‡½æ•°ä»¥å¼•å¯¼æ¨¡ä»¿å­¦ä¹ ï¼Œå¹¶åœ¨æ‰©æ•£è¿‡ç¨‹ä¸­æ–½åŠ ç‰©ç†çº¦æŸä»¥æé«˜ç­–ç•¥çš„ç¨³å®šæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æDIDPæ¡†æ¶åœ¨ç»³ç´¢æ“æ§ä»»åŠ¡ä¸­ç›¸è¾ƒäºåŸºçº¿æ–¹æ³•æé«˜äº†20%çš„å‡†ç¡®æ€§ï¼Œå¹¶åœ¨é²æ£’æ€§æµ‹è¯•ä¸­è¡¨ç°å‡ºæ›´ä½çš„å¤±è´¥ç‡ï¼ŒéªŒè¯äº†å…¶åœ¨åŠ¨æ€æ“æ§ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæŠ“å–ã€è‡ªåŠ¨åŒ–ç”Ÿäº§çº¿å’Œè™šæ‹Ÿç°å®ä¸­çš„ç‰©ä½“æ“æ§ç­‰ã€‚é€šè¿‡æé«˜å¯¹å¯å˜å½¢ç‰©ä½“çš„æ“æ§èƒ½åŠ›ï¼Œèƒ½å¤Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­å®ç°æ›´é«˜æ•ˆçš„ä»»åŠ¡æ‰§è¡Œï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Goal-conditioned dynamic manipulation is inherently challenging due to complex system dynamics and stringent task constraints, particularly in deformable object scenarios characterized by high degrees of freedom and underactuation. Prior methods often simplify the problem to low-speed or 2D settings, limiting their applicability to real-world 3D tasks. In this work, we explore 3D goal-conditioned rope manipulation as a representative challenge. To mitigate data scarcity, we introduce a novel simulation framework and benchmark grounded in reduced-order dynamics, which enables compact state representation and facilitates efficient policy learning. Building on this, we propose Dynamics Informed Diffusion Policy (DIDP), a framework that integrates imitation pretraining with physics-informed test-time adaptation. First, we design a diffusion policy that learns inverse dynamics within the reduced-order space, enabling imitation learning to move beyond naÃ¯ve data fitting and capture the underlying physical structure. Second, we propose a physics-informed test-time adaptation scheme that imposes kinematic boundary conditions and structured dynamics priors on the diffusion process, ensuring consistency and reliability in manipulation execution. Extensive experiments validate the proposed approach, demonstrating strong performance in terms of accuracy and robustness in the learned policy.

