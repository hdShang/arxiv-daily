---
layout: default
title: Bootstrapping Imitation Learning for Long-horizon Manipulation via Hierarchical Data Collection Space
---

# Bootstrapping Imitation Learning for Long-horizon Manipulation via Hierarchical Data Collection Space

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.17389" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.17389v1</a>
  <a href="https://arxiv.org/pdf/2505.17389.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.17389v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.17389v1', 'Bootstrapping Imitation Learning for Long-horizon Manipulation via Hierarchical Data Collection Space')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Jinrong Yang, Kexun Chen, Zhuoling Li, Shengkai Wu, Yong Zhao, Liangliang Ren, Wenqiu Luo, Chaohui Shang, Meiyu Zhi, Linfeng Gao, Mingshan Sun, Hui Cheng

**ÂàÜÁ±ª**: cs.RO, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-23

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Â±ÇÊ¨°ÂåñÊï∞ÊçÆÊî∂ÈõÜÁ©∫Èó¥‰ª•Ëß£ÂÜ≥ÈïøÊó∂Èó¥Êìç‰Ωú‰∏≠ÁöÑÊ®°‰ªøÂ≠¶‰π†ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Ê®°‰ªøÂ≠¶‰π†` `Â±ÇÊ¨°ÂåñÊï∞ÊçÆÊî∂ÈõÜ` `Êú∫Âô®‰∫∫Êìç‰Ωú` `ÈïøÊó∂Èó¥‰ªªÂä°` `Êï∞ÊçÆ‰ºòÂåñ` `Á≠ñÁï•ËÆ≠ÁªÉ` `‰∫∫Êú∫‰∫§‰∫í`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÊ®°‰ªøÂ≠¶‰π†ÊñπÊ≥ïÂú®Êï∞ÊçÆÊî∂ÈõÜÂíåÂ§ÑÁêÜ‰∏äÂ≠òÂú®È´òÊàêÊú¨Âíå‰ΩéÊïàÁöÑÈóÆÈ¢òÔºåÈöæ‰ª•ÂÆûÁé∞È´òÊàêÂäüÁéáÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ
2. Êú¨ÊñáÊèêÂá∫‰∫ÜÂ±ÇÊ¨°ÂåñÊï∞ÊçÆÊî∂ÈõÜÁ©∫Èó¥ÔºàHD-SpaceÔºâÔºåÈÄöËøáÂ∞ÜÂ§çÊùÇ‰ªªÂä°ÂàÜËß£‰∏∫Â§ö‰∏™ÂéüÂ≠ê‰ªªÂä°Ôºå‰ºòÂåñÊï∞ÊçÆË¥®ÈáèÂíåÊî∂ÈõÜÊïàÁéá„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºå‰ΩøÁî®HD-SpaceËøõË°åILÁ≠ñÁï•ËÆ≠ÁªÉÂú®Â§ö‰∏™ÈïøÊó∂Èó¥Êìç‰Ωú‰ªªÂä°‰∏≠ÊòæËëóÊèêÂçá‰∫ÜÁ≠ñÁï•ÊÄßËÉΩÔºåÂ∞§ÂÖ∂ÊòØÂú®Êï∞ÊçÆÈáèËæÉÂ∞ëÁöÑÊÉÖÂÜµ‰∏ã„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Ê®°‰ªøÂ≠¶‰π†ÔºàILÔºâÈÄöËøá‰∫∫Á±ªÁ§∫ËåÉ‰∏∫Êú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°Êèê‰æõ‰∫Ü‰∏ÄÁßçÊúâÂâçÊôØÁöÑÊñπÊ≥ï„ÄÇÂ∞ΩÁÆ°ÊúÄÂ∞ëÁöÑÁ§∫ËåÉÂèØ‰ª•‰ΩøÊú∫Âô®‰∫∫ÊâßË°åÂä®‰ΩúÔºå‰ΩÜË¶ÅÂÆûÁé∞È´òÊàêÂäüÁéáÂíåÊ≥õÂåñËÉΩÂäõÂàôÈúÄË¶ÅÈ´òÊàêÊú¨Ôºå‰æãÂ¶Ç‰∏çÊñ≠Ê∑ªÂä†Êï∞ÊçÆÊàñÂú®Â§çÊùÇÁöÑÁ°¨‰ª∂/ËΩØ‰ª∂Á≥ªÁªü‰∏≠ËøõË°å‰∫∫Êú∫‰∫§‰∫íËøáÁ®ã„ÄÇÊú¨ÊñáÈáçÊñ∞ÊÄùËÄÉ‰∫ÜÊï∞ÊçÆÊî∂ÈõÜÁÆ°ÈÅìÁöÑÁä∂ÊÄÅ/Âä®‰ΩúÁ©∫Èó¥‰ª•ÂèäÂØºËá¥‰∏çÁ®≥ÂÅ•Âä®‰ΩúÈ¢ÑÊµãÁöÑÊΩúÂú®Âõ†Á¥†„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨ÂºïÂÖ•‰∫ÜÂ±ÇÊ¨°ÂåñÊï∞ÊçÆÊî∂ÈõÜÁ©∫Èó¥ÔºàHD-SpaceÔºâÔºå‰∏∫Êú∫Âô®‰∫∫Ê®°‰ªøÂ≠¶‰π†Êèê‰æõ‰∫Ü‰∏ÄÁßçÁÆÄÂçïÁöÑÊï∞ÊçÆÊî∂ÈõÜÊñπÊ°àÔºå‰ΩøÊ®°ÂûãËÉΩÂ§ü‰ΩøÁî®‰∏ªÂä®ÂíåÈ´òË¥®ÈáèÁöÑÊï∞ÊçÆËøõË°åËÆ≠ÁªÉ„ÄÇÊàë‰ª¨Â∞ÜÁ≤æÁªÜÊìç‰Ωú‰ªªÂä°‰ªéÈ´òÂ±ÇÊ¨°ËßÜËßíÂàÜËß£‰∏∫Â§ö‰∏™ÂÖ≥ÈîÆÂéüÂ≠ê‰ªªÂä°ÔºåÂπ∂‰∏∫‰∫∫Á±ªÁ§∫ËåÉËÆæËÆ°ÂéüÂ≠êÁä∂ÊÄÅ/Âä®‰ΩúÁ©∫Èó¥ÔºåÊó®Âú®ÁîüÊàêÁ®≥ÂÅ•ÁöÑILÊï∞ÊçÆ„ÄÇÈÄöËøáÂú®‰∏§‰∏™Ê®°ÊãüÂíå‰∫î‰∏™ÁúüÂÆû‰∏ñÁïåÁöÑÈïøÊó∂Èó¥Êìç‰Ωú‰ªªÂä°‰∏≠ËøõË°åÂÆûËØÅËØÑ‰º∞ÔºåÊàë‰ª¨ËØÅÊòé‰∫ÜÂü∫‰∫éHD-SpaceÁöÑÊï∞ÊçÆËøõË°åILÁ≠ñÁï•ËÆ≠ÁªÉÂèØ‰ª•ÊòæËëóÊèêÂçáÁ≠ñÁï•ÊÄßËÉΩ„ÄÇHD-Space‰ΩøÂæó‰ΩøÁî®Â∞ëÈáèÁ§∫ËåÉÊï∞ÊçÆËÆ≠ÁªÉÊõ¥Âº∫Â§ßÁöÑÁ≠ñÁï•Êàê‰∏∫ÂèØËÉΩÔºåÁâπÂà´ÊòØÂú®ÈïøÊó∂Èó¥Êìç‰Ωú‰ªªÂä°‰∏≠„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Ê®°‰ªøÂ≠¶‰π†‰∏≠Êï∞ÊçÆÊî∂ÈõÜÊïàÁéá‰ΩéÂíåÊàêÂäüÁéá‰∏çÈ´òÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂæÄÂæÄÈúÄË¶ÅÂ§ßÈáèÁ§∫ËåÉÊï∞ÊçÆÔºå‰∏îÈöæ‰ª•Â§ÑÁêÜÂ§çÊùÇÁöÑÊìç‰Ωú‰ªªÂä°„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊèêÂá∫Â±ÇÊ¨°ÂåñÊï∞ÊçÆÊî∂ÈõÜÁ©∫Èó¥ÔºàHD-SpaceÔºâÔºåÈÄöËøáÂ∞ÜÂ§çÊùÇÁöÑÊìç‰Ωú‰ªªÂä°ÂàÜËß£‰∏∫Â§ö‰∏™ÂÖ≥ÈîÆÂéüÂ≠ê‰ªªÂä°ÔºåËÆæËÆ°Áõ∏Â∫îÁöÑÁä∂ÊÄÅ/Âä®‰ΩúÁ©∫Èó¥Ôºå‰ªéËÄåÊèêÈ´òÊï∞ÊçÆÁöÑË¥®ÈáèÂíåÊî∂ÈõÜÁöÑÊïàÁéá„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöHD-SpaceÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰ªªÂä°ÂàÜËß£Ê®°Âùó„ÄÅÁä∂ÊÄÅ/Âä®‰ΩúÁ©∫Èó¥ËÆæËÆ°Ê®°ÂùóÂíåÊï∞ÊçÆÊî∂ÈõÜÊ®°Âùó„ÄÇÈ¶ñÂÖàÂ∞ÜÈ´òÂ±ÇÊ¨°ÁöÑÊìç‰Ωú‰ªªÂä°ÂàÜËß£‰∏∫Â§ö‰∏™ÂéüÂ≠ê‰ªªÂä°ÔºåÁÑ∂Âêé‰∏∫ÊØè‰∏™‰ªªÂä°ËÆæËÆ°Áõ∏Â∫îÁöÑÁä∂ÊÄÅÂíåÂä®‰ΩúÁ©∫Èó¥ÔºåÊúÄÂêéÊî∂ÈõÜÈ´òË¥®ÈáèÁöÑÁ§∫ËåÉÊï∞ÊçÆÁî®‰∫éËÆ≠ÁªÉ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöHD-SpaceÁöÑÊ†∏ÂøÉÂàõÊñ∞Âú®‰∫éÂÖ∂Â±ÇÊ¨°ÂåñÁöÑ‰ªªÂä°ÂàÜËß£ÂíåÁä∂ÊÄÅ/Âä®‰ΩúÁ©∫Èó¥ËÆæËÆ°Ôºå‰ΩøÂæóÂú®Êï∞ÊçÆÈáèËæÉÂ∞ëÁöÑÊÉÖÂÜµ‰∏ã‰πüËÉΩËÆ≠ÁªÉÂá∫Âº∫Â§ßÁöÑÊ®°‰ªøÂ≠¶‰π†Á≠ñÁï•„ÄÇËøô‰∏ÄÊñπÊ≥ï‰∏é‰º†ÁªüÁöÑÊ®°‰ªøÂ≠¶‰π†ÊñπÊ≥ïÁõ∏ÊØîÔºåÊòæËëóÊèêÈ´ò‰∫ÜÊï∞ÊçÆÂà©Áî®ÊïàÁéá„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®HD-Space‰∏≠ÔºåÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨ÂéüÂ≠ê‰ªªÂä°ÁöÑÈÄâÊã©„ÄÅÁä∂ÊÄÅ/Âä®‰ΩúÁ©∫Èó¥ÁöÑÂÆö‰πâ‰ª•ÂèäÊï∞ÊçÆÊî∂ÈõÜÁ≠ñÁï•ÁöÑ‰ºòÂåñ„ÄÇÂÖ∑‰ΩìÁöÑÊçüÂ§±ÂáΩÊï∞ÂíåÁΩëÁªúÁªìÊûÑÁªÜËäÇÂú®ÂÆûÈ™å‰∏≠ËøõË°å‰∫ÜË∞ÉÊï¥Ôºå‰ª•Á°Æ‰øùÊ®°ÂûãËÉΩÂ§üÊúâÊïàÂ≠¶‰π†Âà∞Á®≥ÂÅ•ÁöÑÊìç‰ΩúÁ≠ñÁï•„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåÂü∫‰∫éHD-SpaceÁöÑÊï∞ÊçÆËøõË°åILÁ≠ñÁï•ËÆ≠ÁªÉÂú®‰∫î‰∏™ÁúüÂÆû‰∏ñÁïåÁöÑÈïøÊó∂Èó¥Êìç‰Ωú‰ªªÂä°‰∏≠ÔºåÁ≠ñÁï•ÊÄßËÉΩÊèêÂçáÂπÖÂ∫¶ËææÂà∞30%‰ª•‰∏äÔºåÁõ∏ËæÉ‰∫é‰º†ÁªüÊñπÊ≥ïÔºåÊàêÂäüÁéáÊòæËëóÊèêÈ´òÔºåÂ±ïÁ§∫‰∫ÜHD-SpaceÁöÑÊúâÊïàÊÄßÂíåÂÆûÁî®ÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Â∑•‰∏öÊú∫Âô®‰∫∫„ÄÅÊúçÂä°Êú∫Âô®‰∫∫ÂíåËá™Âä®ÂåñÁîü‰∫ßÁ∫øÁ≠â„ÄÇÈÄöËøá‰ºòÂåñÊ®°‰ªøÂ≠¶‰π†ÁöÑÊï∞ÊçÆÊî∂ÈõÜËøáÁ®ãÔºåËÉΩÂ§üÊòæËëóÊèêÂçáÊú∫Âô®‰∫∫Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑÊìç‰ΩúËÉΩÂäõÔºåÈôç‰Ωé‰∫∫ÂäõÊàêÊú¨ÔºåÊé®Âä®Êô∫ËÉΩÂà∂ÈÄ†ÂíåÊúçÂä°‰∏öÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Imitation learning (IL) with human demonstrations is a promising method for robotic manipulation tasks. While minimal demonstrations enable robotic action execution, achieving high success rates and generalization requires high cost, e.g., continuously adding data or incrementally conducting human-in-loop processes with complex hardware/software systems. In this paper, we rethink the state/action space of the data collection pipeline as well as the underlying factors responsible for the prediction of non-robust actions. To this end, we introduce a Hierarchical Data Collection Space (HD-Space) for robotic imitation learning, a simple data collection scheme, endowing the model to train with proactive and high-quality data. Specifically, We segment the fine manipulation task into multiple key atomic tasks from a high-level perspective and design atomic state/action spaces for human demonstrations, aiming to generate robust IL data. We conduct empirical evaluations across two simulated and five real-world long-horizon manipulation tasks and demonstrate that IL policy training with HD-Space-based data can achieve significantly enhanced policy performance. HD-Space allows the use of a small amount of demonstration data to train a more powerful policy, particularly for long-horizon manipulation tasks. We aim for HD-Space to offer insights into optimizing data quality and guiding data scaling. project page: https://hd-space-robotics.github.io.

