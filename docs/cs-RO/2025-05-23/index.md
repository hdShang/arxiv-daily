---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-05-23
---

# cs.ROï¼ˆ2025-05-23ï¼‰

ğŸ“Š å…± **11** ç¯‡è®ºæ–‡
 | ğŸ”— **1** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (9)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1 ğŸ”—1)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (9 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250517627v1-h2-compact-human-humanoid-co-manipulation-via-adaptive-contact-traje.html">H2-COMPACT: Human-Humanoid Co-Manipulation via Adaptive Contact Trajectory Policies</a></td>
  <td>æå‡ºH2-COMPACTä»¥è§£å†³äººç±»ä¸ç±»äººæœºå™¨äººåä½œæ¬è¿é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">legged locomotion</span> <span class="paper-tag">humanoid</span> <span class="paper-tag">locomotion</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.17627v1" data-paper-url="./papers/250517627v1-h2-compact-human-humanoid-co-manipulation-via-adaptive-contact-traje.html" onclick="toggleFavorite(this, '2505.17627v1', 'H2-COMPACT: Human-Humanoid Co-Manipulation via Adaptive Contact Trajectory Policies')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250518418v1-mcarlmorphology-control-aware-reinforcement-learning-for-generalizab.html">McARL:Morphology-Control-Aware Reinforcement Learning for Generalizable Quadrupedal Locomotion</a></td>
  <td>æå‡ºMcARLä»¥è§£å†³å››è¶³æœºå™¨äººè¿åŠ¨çš„è¿ç§»å­¦ä¹ é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">quadruped</span> <span class="paper-tag">locomotion</span> <span class="paper-tag">Unitree</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.18418v1" data-paper-url="./papers/250518418v1-mcarlmorphology-control-aware-reinforcement-learning-for-generalizab.html" onclick="toggleFavorite(this, '2505.18418v1', 'McARL:Morphology-Control-Aware Reinforcement Learning for Generalizable Quadrupedal Locomotion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250518429v2-hacl-history-aware-curriculum-learning-for-fast-locomotion.html">HACL: History-Aware Curriculum Learning for Fast Locomotion</a></td>
  <td>æå‡ºå†å²æ„ŸçŸ¥è¯¾ç¨‹å­¦ä¹ ç®—æ³•ä»¥è§£å†³å¿«é€Ÿè¿åŠ¨é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">quadruped</span> <span class="paper-tag">bipedal</span> <span class="paper-tag">biped</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.18429v2" data-paper-url="./papers/250518429v2-hacl-history-aware-curriculum-learning-for-fast-locomotion.html" onclick="toggleFavorite(this, '2505.18429v2', 'HACL: History-Aware Curriculum Learning for Fast Locomotion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250518382v3-one-demo-is-all-it-takes-planning-domain-derivation-with-llms-from-a.html">One Demo Is All It Takes: Planning Domain Derivation with LLMs from A Single Demonstration</a></td>
  <td>æå‡ºPDDLLMæ¡†æ¶ä»¥è§£å†³é•¿æ—¶é—´è§„åˆ’çš„å¯é æ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">motion planning</span> <span class="paper-tag">large language model</span> <span class="paper-tag">task and motion planning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.18382v3" data-paper-url="./papers/250518382v3-one-demo-is-all-it-takes-planning-domain-derivation-with-llms-from-a.html" onclick="toggleFavorite(this, '2505.18382v3', 'One Demo Is All It Takes: Planning Domain Derivation with LLMs from A Single Demonstration')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250517434v1-dynamic-manipulation-of-deformable-objects-in-3d-simulation-benchmar.html">Dynamic Manipulation of Deformable Objects in 3D: Simulation, Benchmark and Learning Strategy</a></td>
  <td>æå‡ºåŠ¨æ€æ“æ§æ¡†æ¶ä»¥è§£å†³3Då¯å˜å½¢ç‰©ä½“æ“æ§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">policy learning</span> <span class="paper-tag">imitation learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.17434v1" data-paper-url="./papers/250517434v1-dynamic-manipulation-of-deformable-objects-in-3d-simulation-benchmar.html" onclick="toggleFavorite(this, '2505.17434v1', 'Dynamic Manipulation of Deformable Objects in 3D: Simulation, Benchmark and Learning Strategy')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250517389v1-bootstrapping-imitation-learning-for-long-horizon-manipulation-via-h.html">Bootstrapping Imitation Learning for Long-horizon Manipulation via Hierarchical Data Collection Space</a></td>
  <td>æå‡ºå±‚æ¬¡åŒ–æ•°æ®æ”¶é›†ç©ºé—´ä»¥è§£å†³é•¿æ—¶é—´æ“ä½œä¸­çš„æ¨¡ä»¿å­¦ä¹ é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">imitation learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.17389v1" data-paper-url="./papers/250517389v1-bootstrapping-imitation-learning-for-long-horizon-manipulation-via-h.html" onclick="toggleFavorite(this, '2505.17389v1', 'Bootstrapping Imitation Learning for Long-horizon Manipulation via Hierarchical Data Collection Space')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250517966v2-is-single-view-mesh-reconstruction-ready-for-robotics.html">Is Single-View Mesh Reconstruction Ready for Robotics?</a></td>
  <td>è¯„ä¼°å•è§†å›¾ç½‘æ ¼é‡å»ºåœ¨æœºå™¨äººé¢†åŸŸçš„åº”ç”¨æ½œåŠ›</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">physically plausible</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.17966v2" data-paper-url="./papers/250517966v2-is-single-view-mesh-reconstruction-ready-for-robotics.html" onclick="toggleFavorite(this, '2505.17966v2', 'Is Single-View Mesh Reconstruction Ready for Robotics?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250517738v1-object-classification-utilizing-neuromorphic-proprioceptive-signals-.html">Object Classification Utilizing Neuromorphic Proprioceptive Signals in Active Exploration: Validated on a Soft Anthropomorphic Hand</a></td>
  <td>æå‡ºç¥ç»å½¢æ€æœ¬ä½“æ„Ÿè§‰ä¿¡å·åˆ†ç±»æ–¹æ³•ä»¥æå‡è½¯æœºå™¨äººæ‰‹çš„ç‰©ä½“è¯†åˆ«èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">in-hand manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.17738v1" data-paper-url="./papers/250517738v1-object-classification-utilizing-neuromorphic-proprioceptive-signals-.html" onclick="toggleFavorite(this, '2505.17738v1', 'Object Classification Utilizing Neuromorphic Proprioceptive Signals in Active Exploration: Validated on a Soft Anthropomorphic Hand')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250518248v1-predictability-based-curiosity-guided-action-symbol-discovery.html">Predictability-Based Curiosity-Guided Action Symbol Discovery</a></td>
  <td>æå‡ºåŸºäºå¯é¢„æµ‹æ€§çš„å¥½å¥‡å¿ƒå¼•å¯¼çš„åŠ¨ä½œç¬¦å·å‘ç°æ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.18248v1" data-paper-url="./papers/250518248v1-predictability-based-curiosity-guided-action-symbol-discovery.html" onclick="toggleFavorite(this, '2505.18248v1', 'Predictability-Based Curiosity-Guided Action Symbol Discovery')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>10</td>
  <td><a href="./papers/250518364v2-imlpr-image-based-lidar-place-recognition-using-vision-foundation-mo.html">ImLPR: Image-based LiDAR Place Recognition using Vision Foundation Models</a></td>
  <td>æå‡ºImLPRä»¥è§£å†³LiDARåœ°ç‚¹è¯†åˆ«ä¸­çš„çŸ¥è¯†åˆ©ç”¨é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">foundation model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.18364v2" data-paper-url="./papers/250518364v2-imlpr-image-based-lidar-place-recognition-using-vision-foundation-mo.html" onclick="toggleFavorite(this, '2505.18364v2', 'ImLPR: Image-based LiDAR Place Recognition using Vision Foundation Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>11</td>
  <td><a href="./papers/250518417v1-reinforcement-learning-for-ballbot-navigation-in-uneven-terrain.html">Reinforcement Learning for Ballbot Navigation in Uneven Terrain</a></td>
  <td>æå‡ºåŸºäºå¼ºåŒ–å­¦ä¹ çš„Ballbotå¯¼èˆªæ–¹æ³•ä»¥è§£å†³ä¸å¹³å¦åœ°å½¢é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">reward shaping</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.18417v1" data-paper-url="./papers/250518417v1-reinforcement-learning-for-ballbot-navigation-in-uneven-terrain.html" onclick="toggleFavorite(this, '2505.18417v1', 'Reinforcement Learning for Ballbot Navigation in Uneven Terrain')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)