---
layout: default
title: Reliable and Scalable Robot Policy Evaluation with Imperfect Simulators
---

# Reliable and Scalable Robot Policy Evaluation with Imperfect Simulators

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.04354" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.04354v1</a>
  <a href="https://arxiv.org/pdf/2510.04354.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.04354v1" onclick="toggleFavorite(this, '2510.04354v1', 'Reliable and Scalable Robot Policy Evaluation with Imperfect Simulators')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Apurva Badithela, David Snyder, Lihan Zha, Joseph Mikhail, Matthew O'Kelly, Anushri Dixit, Anirudha Majumdar

**åˆ†ç±»**: cs.RO, cs.AI, eess.SY

**å‘å¸ƒæ—¥æœŸ**: 2025-10-05

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSureSimæ¡†æ¶ä»¥è§£å†³æœºå™¨äººç­–ç•¥è¯„ä¼°çš„å¯é æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æœºå™¨äººç­–ç•¥è¯„ä¼°` `æ¨¡ä»¿å­¦ä¹ ` `ä»¿çœŸä¸ç°å®ç»“åˆ` `éæ¸è¿‘å‡å€¼ä¼°è®¡` `è¯„ä¼°å¯é æ€§` `æ™ºèƒ½æœºå™¨äºº` `è‡ªåŠ¨åŒ–åˆ¶é€ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æœºå™¨äººç­–ç•¥è¯„ä¼°ä¸­ä¾èµ–å°‘é‡ç¡¬ä»¶è¯•éªŒï¼Œç¼ºä¹ç»Ÿè®¡ä¿éšœï¼Œå¯¼è‡´è¯„ä¼°ç»“æœä¸å¯é ã€‚
2. æœ¬æ–‡æå‡ºSureSimæ¡†æ¶ï¼Œé€šè¿‡ç»“åˆå¤§è§„æ¨¡ä»¿çœŸä¸å°è§„æ¨¡ç°å®æµ‹è¯•ï¼Œè§£å†³äº†è¯„ä¼°ä¸­çš„åå·®é—®é¢˜ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ç‰©ç†ä»¿çœŸä¸­èŠ‚çœäº†20-25%çš„ç¡¬ä»¶è¯„ä¼°å·¥ä½œé‡ï¼ŒåŒæ—¶ä¿æŒäº†ç­–ç•¥æ€§èƒ½çš„ç›¸ä¼¼ç•Œé™ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€æ¨¡ä»¿å­¦ä¹ ã€åŸºç¡€æ¨¡å‹å’Œå¤§è§„æ¨¡æ•°æ®é›†çš„å¿«é€Ÿå‘å±•ï¼Œæœºå™¨äººæ“ä½œç­–ç•¥åœ¨å¤šç§ä»»åŠ¡å’Œç¯å¢ƒä¸­è¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚ç„¶è€Œï¼Œè¿™äº›ç­–ç•¥çš„ä¸¥æ ¼è¯„ä¼°ä»ç„¶é¢ä¸´æŒ‘æˆ˜ã€‚é€šå¸¸ï¼Œæœºå™¨äººç­–ç•¥çš„è¯„ä¼°ä¾èµ–äºå°‘é‡çš„ç¡¬ä»¶è¯•éªŒï¼Œç¼ºä¹ç»Ÿè®¡ä¿éšœã€‚æœ¬æ–‡æå‡ºäº†SureSimæ¡†æ¶ï¼Œé€šè¿‡å°†å¤§è§„æ¨¡ä»¿çœŸä¸ç›¸å¯¹å°è§„æ¨¡çš„ç°å®æµ‹è¯•ç›¸ç»“åˆï¼Œæä¾›å¯¹ç­–ç•¥åœ¨ç°å®ä¸–ç•Œè¡¨ç°çš„å¯é æ¨æ–­ã€‚æ ¸å¿ƒæ€æƒ³æ˜¯å°†çœŸå®ä¸ä»¿çœŸè¯„ä¼°çš„ç»“åˆå½¢å¼åŒ–ä¸ºä¸€ä¸ªé¢„æµ‹é©±åŠ¨çš„æ¨æ–­é—®é¢˜ï¼Œåˆ©ç”¨å°‘é‡é…å¯¹çš„çœŸå®ä¸ä»¿çœŸè¯„ä¼°æ¥ä¿®æ­£å¤§è§„æ¨¡ä»¿çœŸä¸­çš„åå·®ã€‚æˆ‘ä»¬è¿˜åˆ©ç”¨éæ¸è¿‘å‡å€¼ä¼°è®¡ç®—æ³•æä¾›ç­–ç•¥æ€§èƒ½çš„ç½®ä¿¡åŒºé—´ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç‰©ç†ä»¿çœŸä¸­è¯„ä¼°æ‰©æ•£ç­–ç•¥å’Œå¤šä»»åŠ¡å¾®è°ƒçš„Ï€0ï¼ŒèŠ‚çœäº†20-25%çš„ç¡¬ä»¶è¯„ä¼°å·¥ä½œé‡ï¼ŒåŒæ—¶å®ç°äº†ç›¸ä¼¼çš„ç­–ç•¥æ€§èƒ½ç•Œé™ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æœºå™¨äººç­–ç•¥è¯„ä¼°ä¸­çš„å¯é æ€§é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºå°‘é‡çš„ç¡¬ä»¶è¯•éªŒï¼Œç¼ºä¹è¶³å¤Ÿçš„ç»Ÿè®¡ä¿éšœï¼Œå¯¼è‡´è¯„ä¼°ç»“æœçš„ä¸ç¡®å®šæ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†çœŸå®ä¸ä»¿çœŸè¯„ä¼°çš„ç»“åˆè§†ä¸ºä¸€ä¸ªé¢„æµ‹é©±åŠ¨çš„æ¨æ–­é—®é¢˜ï¼Œé€šè¿‡å°‘é‡çš„é…å¯¹è¯„ä¼°æ¥ä¿®æ­£ä»¿çœŸä¸­çš„åå·®ï¼Œä»è€Œæé«˜è¯„ä¼°çš„å¯é æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSureSimæ¡†æ¶çš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šä¸€æ˜¯å¤§è§„æ¨¡ä»¿çœŸè¯„ä¼°ï¼ŒäºŒæ˜¯å°è§„æ¨¡ç°å®æµ‹è¯•ã€‚é€šè¿‡è¿™ä¸¤ä¸ªæ¨¡å—çš„ç»“åˆï¼Œå½¢æˆä¸€ä¸ªé—­ç¯çš„è¯„ä¼°ç³»ç»Ÿã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†çœŸå®ä¸ä»¿çœŸè¯„ä¼°ç»“åˆçš„å½¢å¼åŒ–å¤„ç†ï¼Œåˆ©ç”¨éæ¸è¿‘å‡å€¼ä¼°è®¡ç®—æ³•æä¾›ç½®ä¿¡åŒºé—´ï¼Œä»è€Œå¢å¼ºè¯„ä¼°çš„ç»Ÿè®¡ä¿éšœã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒSureSimåœ¨è¯„ä¼°çš„å¯é æ€§å’Œæ•ˆç‡ä¸Šå…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œè®ºæ–‡é‡‡ç”¨äº†éæ¸è¿‘å‡å€¼ä¼°è®¡ç®—æ³•ï¼Œè®¾è®¡äº†é€‚åº”æ€§å‚æ•°è®¾ç½®ï¼Œä»¥ç¡®ä¿åœ¨ä¸åŒä»»åŠ¡å’Œç¯å¢ƒä¸‹çš„è¯„ä¼°å‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨SureSimæ¡†æ¶å¯ä»¥èŠ‚çœ20-25%çš„ç¡¬ä»¶è¯„ä¼°å·¥ä½œé‡ï¼ŒåŒæ—¶åœ¨ç‰©ç†ä»¿çœŸä¸­å¯¹æ‰©æ•£ç­–ç•¥å’Œå¤šä»»åŠ¡å¾®è°ƒçš„Ï€0å®ç°äº†ç›¸ä¼¼çš„ç­–ç•¥æ€§èƒ½ç•Œé™ï¼Œæ˜¾ç¤ºå‡ºè¯¥æ–¹æ³•åœ¨è¯„ä¼°æ•ˆç‡å’Œå¯é æ€§ä¸Šçš„æ˜¾è‘—æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæ“ä½œã€è‡ªåŠ¨åŒ–åˆ¶é€ å’Œæ™ºèƒ½å®¶å±…ç­‰ã€‚é€šè¿‡æé«˜æœºå™¨äººç­–ç•¥è¯„ä¼°çš„å¯é æ€§ï¼ŒSureSimæ¡†æ¶èƒ½å¤Ÿå¸®åŠ©å¼€å‘æ›´ä¸ºé«˜æ•ˆå’Œå®‰å…¨çš„æœºå™¨äººç³»ç»Ÿï¼Œæ¨åŠ¨æ™ºèƒ½æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„å¹¿æ³›åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Rapid progress in imitation learning, foundation models, and large-scale datasets has led to robot manipulation policies that generalize to a wide-range of tasks and environments. However, rigorous evaluation of these policies remains a challenge. Typically in practice, robot policies are often evaluated on a small number of hardware trials without any statistical assurances. We present SureSim, a framework to augment large-scale simulation with relatively small-scale real-world testing to provide reliable inferences on the real-world performance of a policy. Our key idea is to formalize the problem of combining real and simulation evaluations as a prediction-powered inference problem, in which a small number of paired real and simulation evaluations are used to rectify bias in large-scale simulation. We then leverage non-asymptotic mean estimation algorithms to provide confidence intervals on mean policy performance. Using physics-based simulation, we evaluate both diffusion policy and multi-task fine-tuned \(Ï€_0\) on a joint distribution of objects and initial conditions, and find that our approach saves over \(20-25\%\) of hardware evaluation effort to achieve similar bounds on policy performance.

