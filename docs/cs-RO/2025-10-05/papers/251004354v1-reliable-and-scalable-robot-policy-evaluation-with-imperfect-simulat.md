---
layout: default
title: Reliable and Scalable Robot Policy Evaluation with Imperfect Simulators
---

# Reliable and Scalable Robot Policy Evaluation with Imperfect Simulators

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.04354" target="_blank" class="toolbar-btn">arXiv: 2510.04354v1</a>
    <a href="https://arxiv.org/pdf/2510.04354.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.04354v1" 
            onclick="toggleFavorite(this, '2510.04354v1', 'Reliable and Scalable Robot Policy Evaluation with Imperfect Simulators')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Apurva Badithela, David Snyder, Lihan Zha, Joseph Mikhail, Matthew O'Kelly, Anushri Dixit, Anirudha Majumdar

**ÂàÜÁ±ª**: cs.RO, cs.AI, eess.SY

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-05

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫SureSimÊ°ÜÊû∂‰ª•Ëß£ÂÜ≥Êú∫Âô®‰∫∫Á≠ñÁï•ËØÑ‰º∞ÁöÑÂèØÈù†ÊÄßÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Êú∫Âô®‰∫∫Á≠ñÁï•ËØÑ‰º∞` `Ê®°‰ªøÂ≠¶‰π†` `‰ªøÁúü‰∏éÁé∞ÂÆûÁªìÂêà` `ÈùûÊ∏êËøëÂùáÂÄº‰º∞ËÆ°` `ËØÑ‰º∞ÂèØÈù†ÊÄß` `Êô∫ËÉΩÊú∫Âô®‰∫∫` `Ëá™Âä®ÂåñÂà∂ÈÄ†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®Êú∫Âô®‰∫∫Á≠ñÁï•ËØÑ‰º∞‰∏≠‰æùËµñÂ∞ëÈáèÁ°¨‰ª∂ËØïÈ™åÔºåÁº∫‰πèÁªüËÆ°‰øùÈöúÔºåÂØºËá¥ËØÑ‰º∞ÁªìÊûú‰∏çÂèØÈù†„ÄÇ
2. Êú¨ÊñáÊèêÂá∫SureSimÊ°ÜÊû∂ÔºåÈÄöËøáÁªìÂêàÂ§ßËßÑÊ®°‰ªøÁúü‰∏éÂ∞èËßÑÊ®°Áé∞ÂÆûÊµãËØïÔºåËß£ÂÜ≥‰∫ÜËØÑ‰º∞‰∏≠ÁöÑÂÅèÂ∑ÆÈóÆÈ¢ò„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåËØ•ÊñπÊ≥ïÂú®Áâ©ÁêÜ‰ªøÁúü‰∏≠ËäÇÁúÅ‰∫Ü20-25%ÁöÑÁ°¨‰ª∂ËØÑ‰º∞Â∑•‰ΩúÈáèÔºåÂêåÊó∂‰øùÊåÅ‰∫ÜÁ≠ñÁï•ÊÄßËÉΩÁöÑÁõ∏‰ººÁïåÈôê„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÈöèÁùÄÊ®°‰ªøÂ≠¶‰π†„ÄÅÂü∫Á°ÄÊ®°ÂûãÂíåÂ§ßËßÑÊ®°Êï∞ÊçÆÈõÜÁöÑÂø´ÈÄüÂèëÂ±ïÔºåÊú∫Âô®‰∫∫Êìç‰ΩúÁ≠ñÁï•Âú®Â§öÁßç‰ªªÂä°ÂíåÁéØÂ¢É‰∏≠Ë°®Áé∞Âá∫ËâØÂ•ΩÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåËøô‰∫õÁ≠ñÁï•ÁöÑ‰∏•Ê†ºËØÑ‰º∞‰ªçÁÑ∂Èù¢‰∏¥ÊåëÊàò„ÄÇÈÄöÂ∏∏ÔºåÊú∫Âô®‰∫∫Á≠ñÁï•ÁöÑËØÑ‰º∞‰æùËµñ‰∫éÂ∞ëÈáèÁöÑÁ°¨‰ª∂ËØïÈ™åÔºåÁº∫‰πèÁªüËÆ°‰øùÈöú„ÄÇÊú¨ÊñáÊèêÂá∫‰∫ÜSureSimÊ°ÜÊû∂ÔºåÈÄöËøáÂ∞ÜÂ§ßËßÑÊ®°‰ªøÁúü‰∏éÁõ∏ÂØπÂ∞èËßÑÊ®°ÁöÑÁé∞ÂÆûÊµãËØïÁõ∏ÁªìÂêàÔºåÊèê‰æõÂØπÁ≠ñÁï•Âú®Áé∞ÂÆû‰∏ñÁïåË°®Áé∞ÁöÑÂèØÈù†Êé®Êñ≠„ÄÇÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÂ∞ÜÁúüÂÆû‰∏é‰ªøÁúüËØÑ‰º∞ÁöÑÁªìÂêàÂΩ¢ÂºèÂåñ‰∏∫‰∏Ä‰∏™È¢ÑÊµãÈ©±Âä®ÁöÑÊé®Êñ≠ÈóÆÈ¢òÔºåÂà©Áî®Â∞ëÈáèÈÖçÂØπÁöÑÁúüÂÆû‰∏é‰ªøÁúüËØÑ‰º∞Êù•‰øÆÊ≠£Â§ßËßÑÊ®°‰ªøÁúü‰∏≠ÁöÑÂÅèÂ∑Æ„ÄÇÊàë‰ª¨ËøòÂà©Áî®ÈùûÊ∏êËøëÂùáÂÄº‰º∞ËÆ°ÁÆóÊ≥ïÊèê‰æõÁ≠ñÁï•ÊÄßËÉΩÁöÑÁΩÆ‰ø°Âå∫Èó¥„ÄÇÂÆûÈ™åË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®Áâ©ÁêÜ‰ªøÁúü‰∏≠ËØÑ‰º∞Êâ©Êï£Á≠ñÁï•ÂíåÂ§ö‰ªªÂä°ÂæÆË∞ÉÁöÑœÄ0ÔºåËäÇÁúÅ‰∫Ü20-25%ÁöÑÁ°¨‰ª∂ËØÑ‰º∞Â∑•‰ΩúÈáèÔºåÂêåÊó∂ÂÆûÁé∞‰∫ÜÁõ∏‰ººÁöÑÁ≠ñÁï•ÊÄßËÉΩÁïåÈôê„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Êú∫Âô®‰∫∫Á≠ñÁï•ËØÑ‰º∞‰∏≠ÁöÑÂèØÈù†ÊÄßÈóÆÈ¢òÔºåÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏‰æùËµñ‰∫éÂ∞ëÈáèÁöÑÁ°¨‰ª∂ËØïÈ™åÔºåÁº∫‰πèË∂≥Â§üÁöÑÁªüËÆ°‰øùÈöúÔºåÂØºËá¥ËØÑ‰º∞ÁªìÊûúÁöÑ‰∏çÁ°ÆÂÆöÊÄß„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜÁúüÂÆû‰∏é‰ªøÁúüËØÑ‰º∞ÁöÑÁªìÂêàËßÜ‰∏∫‰∏Ä‰∏™È¢ÑÊµãÈ©±Âä®ÁöÑÊé®Êñ≠ÈóÆÈ¢òÔºåÈÄöËøáÂ∞ëÈáèÁöÑÈÖçÂØπËØÑ‰º∞Êù•‰øÆÊ≠£‰ªøÁúü‰∏≠ÁöÑÂÅèÂ∑ÆÔºå‰ªéËÄåÊèêÈ´òËØÑ‰º∞ÁöÑÂèØÈù†ÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöSureSimÊ°ÜÊû∂ÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏§‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö‰∏ÄÊòØÂ§ßËßÑÊ®°‰ªøÁúüËØÑ‰º∞Ôºå‰∫åÊòØÂ∞èËßÑÊ®°Áé∞ÂÆûÊµãËØï„ÄÇÈÄöËøáËøô‰∏§‰∏™Ê®°ÂùóÁöÑÁªìÂêàÔºåÂΩ¢Êàê‰∏Ä‰∏™Èó≠ÁéØÁöÑËØÑ‰º∞Á≥ªÁªü„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÂ∞ÜÁúüÂÆû‰∏é‰ªøÁúüËØÑ‰º∞ÁªìÂêàÁöÑÂΩ¢ÂºèÂåñÂ§ÑÁêÜÔºåÂà©Áî®ÈùûÊ∏êËøëÂùáÂÄº‰º∞ËÆ°ÁÆóÊ≥ïÊèê‰æõÁΩÆ‰ø°Âå∫Èó¥Ôºå‰ªéËÄåÂ¢ûÂº∫ËØÑ‰º∞ÁöÑÁªüËÆ°‰øùÈöú„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåSureSimÂú®ËØÑ‰º∞ÁöÑÂèØÈù†ÊÄßÂíåÊïàÁéá‰∏äÂÖ∑ÊúâÊòæËëó‰ºòÂäø„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÊäÄÊúØÁªÜËäÇ‰∏äÔºåËÆ∫ÊñáÈááÁî®‰∫ÜÈùûÊ∏êËøëÂùáÂÄº‰º∞ËÆ°ÁÆóÊ≥ïÔºåËÆæËÆ°‰∫ÜÈÄÇÂ∫îÊÄßÂèÇÊï∞ËÆæÁΩÆÔºå‰ª•Á°Æ‰øùÂú®‰∏çÂêå‰ªªÂä°ÂíåÁéØÂ¢É‰∏ãÁöÑËØÑ‰º∞ÂáÜÁ°ÆÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºå‰ΩøÁî®SureSimÊ°ÜÊû∂ÂèØ‰ª•ËäÇÁúÅ20-25%ÁöÑÁ°¨‰ª∂ËØÑ‰º∞Â∑•‰ΩúÈáèÔºåÂêåÊó∂Âú®Áâ©ÁêÜ‰ªøÁúü‰∏≠ÂØπÊâ©Êï£Á≠ñÁï•ÂíåÂ§ö‰ªªÂä°ÂæÆË∞ÉÁöÑœÄ0ÂÆûÁé∞‰∫ÜÁõ∏‰ººÁöÑÁ≠ñÁï•ÊÄßËÉΩÁïåÈôêÔºåÊòæÁ§∫Âá∫ËØ•ÊñπÊ≥ïÂú®ËØÑ‰º∞ÊïàÁéáÂíåÂèØÈù†ÊÄß‰∏äÁöÑÊòæËëóÊèêÂçá„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Êú∫Âô®‰∫∫Êìç‰Ωú„ÄÅËá™Âä®ÂåñÂà∂ÈÄ†ÂíåÊô∫ËÉΩÂÆ∂Â±ÖÁ≠â„ÄÇÈÄöËøáÊèêÈ´òÊú∫Âô®‰∫∫Á≠ñÁï•ËØÑ‰º∞ÁöÑÂèØÈù†ÊÄßÔºåSureSimÊ°ÜÊû∂ËÉΩÂ§üÂ∏ÆÂä©ÂºÄÂèëÊõ¥‰∏∫È´òÊïàÂíåÂÆâÂÖ®ÁöÑÊú∫Âô®‰∫∫Á≥ªÁªüÔºåÊé®Âä®Êô∫ËÉΩÊú∫Âô®‰∫∫Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑÂπøÊ≥õÂ∫îÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Rapid progress in imitation learning, foundation models, and large-scale datasets has led to robot manipulation policies that generalize to a wide-range of tasks and environments. However, rigorous evaluation of these policies remains a challenge. Typically in practice, robot policies are often evaluated on a small number of hardware trials without any statistical assurances. We present SureSim, a framework to augment large-scale simulation with relatively small-scale real-world testing to provide reliable inferences on the real-world performance of a policy. Our key idea is to formalize the problem of combining real and simulation evaluations as a prediction-powered inference problem, in which a small number of paired real and simulation evaluations are used to rectify bias in large-scale simulation. We then leverage non-asymptotic mean estimation algorithms to provide confidence intervals on mean policy performance. Using physics-based simulation, we evaluate both diffusion policy and multi-task fine-tuned \(œÄ_0\) on a joint distribution of objects and initial conditions, and find that our approach saves over \(20-25\%\) of hardware evaluation effort to achieve similar bounds on policy performance.

