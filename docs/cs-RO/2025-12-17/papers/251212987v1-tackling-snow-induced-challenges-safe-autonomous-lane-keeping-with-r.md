---
layout: default
title: Tackling Snow-Induced Challenges: Safe Autonomous Lane-Keeping with Robust Reinforcement Learning
---

# Tackling Snow-Induced Challenges: Safe Autonomous Lane-Keeping with Robust Reinforcement Learning

**arXiv**: [2512.12987v1](https://arxiv.org/abs/2512.12987) | [PDF](https://arxiv.org/pdf/2512.12987.pdf)

**ä½œè€…**: Amin Jalal Aghdasian, Farzaneh Abdollahi, Ali Kamali Iglie

**åˆ†ç±»**: cs.RO, cs.AI, cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-12-15

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽé²æ£’å¼ºåŒ–å­¦ä¹ çš„è½¦é“ä¿æŒç³»ç»Ÿï¼Œè§£å†³é›ªåœ°è‡ªåŠ¨é©¾é©¶éš¾é¢˜**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `æ·±åº¦å¼ºåŒ–å­¦ä¹ ` `è‡ªåŠ¨é©¾é©¶` `è½¦é“ä¿æŒ` `é²æ£’æŽ§åˆ¶` `é›ªåœ°çŽ¯å¢ƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è½¦é“ä¿æŒç³»ç»Ÿåœ¨é›ªåœ°ç­‰å¤æ‚çŽ¯å¢ƒä¸‹ï¼Œæ˜“å—è·¯é¢æ»‘ç§»å’Œæ„ŸçŸ¥å™ªå£°å½±å“ï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚
2. è®ºæ–‡æå‡ºåŠ¨ä½œé²æ£’çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œå¢žå¼ºç­–ç•¥å¯¹çŽ¯å¢ƒä¸ç¡®å®šæ€§çš„é€‚åº”èƒ½åŠ›ï¼Œæé«˜ç³»ç»Ÿé²æ£’æ€§ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒAR-CADPGæ–¹æ³•åœ¨é›ªåœ°åœºæ™¯ä¸‹å…·æœ‰æ›´é«˜çš„è·¯å¾„è·Ÿè¸ªç²¾åº¦å’Œé²æ£’æ€§ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸¤ç§æ–°çš„ç®—æ³•ï¼Œç”¨äºŽåœ¨é›ªåœ°æ¡ä»¶ä¸‹è‡ªåŠ¨é©¾é©¶è½¦è¾†(AVs)çš„è½¦é“ä¿æŒç³»ç»Ÿ(LKS)ã€‚è¿™äº›ç®—æ³•åˆ©ç”¨æ·±åº¦å¼ºåŒ–å­¦ä¹ (DRL)æ¥å¤„ç†ä¸ç¡®å®šæ€§å’Œæ»‘ç§»ã€‚å®ƒä»¬åŒ…æ‹¬åŠ¨ä½œé²æ£’å¾ªçŽ¯æ·±åº¦ç¡®å®šæ€§ç­–ç•¥æ¢¯åº¦(AR-RDPG)å’Œç«¯åˆ°ç«¯åŠ¨ä½œé²æ£’å·ç§¯ç¥žç»ç½‘ç»œæ³¨æ„åŠ›ç¡®å®šæ€§ç­–ç•¥æ¢¯åº¦(AR-CADPG)ï¼Œè¿™ä¸¤ç§åŠ¨ä½œé²æ£’çš„å†³ç­–æ–¹æ³•ã€‚åœ¨AR-RDPGæ–¹æ³•ä¸­ï¼Œåœ¨æ„ŸçŸ¥å±‚å†…ï¼Œé¦–å…ˆä½¿ç”¨å¤šå°ºåº¦ç¥žç»ç½‘ç»œå¯¹ç›¸æœºå›¾åƒè¿›è¡ŒåŽ»å™ªã€‚ç„¶åŽï¼Œé€šè¿‡é¢„è®­ç»ƒçš„æ·±åº¦å·ç§¯ç¥žç»ç½‘ç»œ(DCNN)æå–ä¸­å¿ƒçº¿ç³»æ•°ã€‚è¿™äº›ç³»æ•°ä¸Žé©¾é©¶ç‰¹æ€§è¿žæŽ¥ï¼Œä½œä¸ºæŽ§åˆ¶å±‚çš„è¾“å…¥ã€‚AR-CADPGæ–¹æ³•æå‡ºäº†ä¸€ç§ç«¯åˆ°ç«¯çš„æ–¹æ³•ï¼Œå…¶ä¸­å·ç§¯ç¥žç»ç½‘ç»œ(CNN)å’Œæ³¨æ„åŠ›æœºåˆ¶è¢«é›†æˆåˆ°DRLæ¡†æž¶ä¸­ã€‚è¿™ä¸¤ç§æ–¹æ³•é¦–å…ˆåœ¨CARLAæ¨¡æ‹Ÿå™¨ä¸­è¿›è¡Œè®­ç»ƒï¼Œå¹¶åœ¨å„ç§é›ªåœ°åœºæ™¯ä¸‹è¿›è¡ŒéªŒè¯ã€‚åœ¨åŸºäºŽJetson Nanoçš„è‡ªåŠ¨é©¾é©¶è½¦è¾†ä¸Šçš„çœŸå®žå®žéªŒè¯å®žäº†å­¦ä¹ ç­–ç•¥çš„å¯è¡Œæ€§å’Œç¨³å®šæ€§ã€‚åœ¨ä¸¤ç§æ¨¡åž‹ä¸­ï¼ŒAR-CADPGæ–¹æ³•è¡¨çŽ°å‡ºå“è¶Šçš„è·¯å¾„è·Ÿè¸ªç²¾åº¦å’Œé²æ£’æ€§ï¼Œçªå‡ºäº†åœ¨AVsä¸­ç»“åˆæ—¶é—´è®°å¿†ã€å¯¹æŠ—å¼¹æ€§å’Œæ³¨æ„åŠ›æœºåˆ¶çš„æœ‰æ•ˆæ€§ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³é›ªåœ°çŽ¯å¢ƒä¸‹è‡ªåŠ¨é©¾é©¶è½¦è¾†è½¦é“ä¿æŒç³»ç»Ÿé¢ä¸´çš„æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬è·¯é¢æ»‘ç§»å¸¦æ¥çš„æŽ§åˆ¶ä¸ç¡®å®šæ€§ä»¥åŠæ„ŸçŸ¥ç³»ç»Ÿå—é™é›ªå½±å“äº§ç”Ÿçš„å™ªå£°ã€‚çŽ°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆåº”å¯¹è¿™äº›é—®é¢˜ï¼Œå¯¼è‡´è½¦é“ä¿æŒæ€§èƒ½ä¸‹é™ï¼Œç”šè‡³å‡ºçŽ°å®‰å…¨éšæ‚£ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ·±åº¦å¼ºåŒ–å­¦ä¹ (DRL)å­¦ä¹ åœ¨ä¸ç¡®å®šçŽ¯å¢ƒä¸‹çš„é²æ£’æŽ§åˆ¶ç­–ç•¥ã€‚é€šè¿‡å¼•å…¥åŠ¨ä½œé²æ£’æ€§ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿé€‚åº”çŽ¯å¢ƒå˜åŒ–å’Œæ„ŸçŸ¥å™ªå£°ï¼Œä»Žè€Œæé«˜è½¦é“ä¿æŒç³»ç»Ÿçš„ç¨³å®šæ€§å’Œå®‰å…¨æ€§ã€‚å…·ä½“è€Œè¨€ï¼Œé€šè¿‡åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¼•å…¥å¯¹æŠ—æ ·æœ¬ï¼Œä½¿ç­–ç•¥å¯¹åŠ¨ä½œæ‰°åŠ¨å…·æœ‰æ›´å¼ºçš„æŠµæŠ—èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šè®ºæ–‡æå‡ºäº†ä¸¤ç§ç®—æ³•ï¼šAR-RDPGå’ŒAR-CADPGã€‚AR-RDPGé¦–å…ˆä½¿ç”¨å¤šå°ºåº¦ç¥žç»ç½‘ç»œå¯¹å›¾åƒè¿›è¡ŒåŽ»å™ªï¼Œç„¶åŽåˆ©ç”¨é¢„è®­ç»ƒçš„DCNNæå–ä¸­å¿ƒçº¿ç³»æ•°ï¼Œå¹¶å°†å…¶ä¸Žé©¾é©¶ç‰¹å¾ç»“åˆä½œä¸ºRDPGæŽ§åˆ¶å™¨çš„è¾“å…¥ã€‚AR-CADPGåˆ™é‡‡ç”¨ç«¯åˆ°ç«¯çš„æ–¹å¼ï¼Œå°†CNNå’Œæ³¨æ„åŠ›æœºåˆ¶é›†æˆåˆ°DRLæ¡†æž¶ä¸­ï¼Œç›´æŽ¥ä»Žå›¾åƒè¾“å…¥å­¦ä¹ æŽ§åˆ¶ç­–ç•¥ã€‚ä¸¤ç§æ–¹æ³•éƒ½åœ¨CARLAæ¨¡æ‹Ÿå™¨ä¸­è¿›è¡Œè®­ç»ƒå’ŒéªŒè¯ï¼Œå¹¶åœ¨çœŸå®žè½¦è¾†ä¸Šè¿›è¡Œæµ‹è¯•ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽå¼•å…¥äº†åŠ¨ä½œé²æ£’æ€§åˆ°æ·±åº¦å¼ºåŒ–å­¦ä¹ æ¡†æž¶ä¸­ï¼Œå¹¶å°†å…¶åº”ç”¨äºŽé›ªåœ°çŽ¯å¢ƒä¸‹çš„è½¦é“ä¿æŒä»»åŠ¡ã€‚AR-CADPGçš„ç«¯åˆ°ç«¯ç»“æž„ä»¥åŠæ³¨æ„åŠ›æœºåˆ¶çš„å¼•å…¥ï¼Œä½¿å¾—æ¨¡åž‹èƒ½å¤Ÿæ›´å¥½åœ°å…³æ³¨å…³é”®ç‰¹å¾ï¼Œæé«˜è·¯å¾„è·Ÿè¸ªç²¾åº¦ã€‚æ­¤å¤–ï¼Œå¤šå°ºåº¦åŽ»å™ªç½‘ç»œçš„åº”ç”¨ä¹Ÿå¢žå¼ºäº†æ„ŸçŸ¥ç³»ç»Ÿçš„é²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šAR-RDPGä¸­ï¼Œå¤šå°ºåº¦åŽ»å™ªç½‘ç»œé‡‡ç”¨U-Netç»“æž„ï¼Œç”¨äºŽåŽ»é™¤å›¾åƒå™ªå£°ã€‚é¢„è®­ç»ƒçš„DCNNç”¨äºŽæå–è½¦é“ä¸­å¿ƒçº¿ç³»æ•°ã€‚AR-CADPGä¸­ï¼ŒCNNé‡‡ç”¨ResNetç»“æž„ï¼Œæ³¨æ„åŠ›æœºåˆ¶é‡‡ç”¨Transformerç»“æž„ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬æŽ§åˆ¶æŸå¤±å’ŒåŠ¨ä½œé²æ£’æ€§æŸå¤±ï¼Œå…¶ä¸­åŠ¨ä½œé²æ£’æ€§æŸå¤±é€šè¿‡å¯¹æŠ—è®­ç»ƒå®žçŽ°ï¼Œé¼“åŠ±ç­–ç•¥å¯¹åŠ¨ä½œæ‰°åŠ¨å…·æœ‰æŠµæŠ—èƒ½åŠ›ã€‚å…·ä½“å‚æ•°è®¾ç½®æœªçŸ¥ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒAR-CADPGæ–¹æ³•åœ¨é›ªåœ°åœºæ™¯ä¸‹å…·æœ‰æ›´é«˜çš„è·¯å¾„è·Ÿè¸ªç²¾åº¦å’Œé²æ£’æ€§ã€‚ä¸ŽAR-RDPGç›¸æ¯”ï¼ŒAR-CADPGèƒ½å¤Ÿæ›´å‡†ç¡®åœ°è·Ÿè¸ªè½¦é“ä¸­å¿ƒçº¿ï¼Œå¹¶å¯¹çŽ¯å¢ƒå˜åŒ–å…·æœ‰æ›´å¼ºçš„é€‚åº”èƒ½åŠ›ã€‚çœŸå®žè½¦è¾†å®žéªŒéªŒè¯äº†è¯¥æ–¹æ³•çš„å¯è¡Œæ€§å’Œç¨³å®šæ€§ã€‚å…·ä½“çš„æ€§èƒ½æå‡æ•°æ®æœªçŸ¥ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽå„ç§æ¶åŠ£å¤©æ°”æ¡ä»¶ä¸‹çš„è‡ªåŠ¨é©¾é©¶è½¦è¾†ï¼Œä¾‹å¦‚é›ªåœ°ã€é›¨å¤©ã€é›¾å¤©ç­‰ã€‚é€šè¿‡æé«˜è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿåœ¨å¤æ‚çŽ¯å¢ƒä¸‹çš„é²æ£’æ€§å’Œå®‰å…¨æ€§ï¼Œå¯ä»¥åŠ é€Ÿè‡ªåŠ¨é©¾é©¶æŠ€æœ¯çš„å•†ä¸šåŒ–è½åœ°ï¼Œå¹¶æå‡äº¤é€šè¿è¾“æ•ˆçŽ‡å’Œå®‰å…¨æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥æŽ¨å¹¿åˆ°å…¶ä»–æœºå™¨äººæŽ§åˆ¶ä»»åŠ¡ä¸­ï¼Œä¾‹å¦‚æ— äººæœºã€æ°´ä¸‹æœºå™¨äººç­‰ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> This paper proposes two new algorithms for the lane keeping system (LKS) in autonomous vehicles (AVs) operating under snowy road conditions. These algorithms use deep reinforcement learning (DRL) to handle uncertainties and slippage. They include Action-Robust Recurrent Deep Deterministic Policy Gradient (AR-RDPG) and end-to-end Action-Robust convolutional neural network Attention Deterministic Policy Gradient (AR-CADPG), two action-robust approaches for decision-making. In the AR-RDPG method, within the perception layer, camera images are first denoised using multi-scale neural networks. Then, the centerline coefficients are extracted by a pre-trained deep convolutional neural network (DCNN). These coefficients, concatenated with the driving characteristics, are used as input to the control layer. The AR-CADPG method presents an end-to-end approach in which a convolutional neural network (CNN) and an attention mechanism are integrated within a DRL framework. Both methods are first trained in the CARLA simulator and validated under various snowy scenarios. Real-world experiments on a Jetson Nano-based autonomous vehicle confirm the feasibility and stability of the learned policies. Among the two models, the AR-CADPG approach demonstrates superior path-tracking accuracy and robustness, highlighting the effectiveness of combining temporal memory, adversarial resilience, and attention mechanisms in AVs.

