---
layout: default
title: Digital Twin Supervised Reinforcement Learning Framework for Autonomous Underwater Navigation
---

# Digital Twin Supervised Reinforcement Learning Framework for Autonomous Underwater Navigation

**arXiv**: [2512.10925v1](https://arxiv.org/abs/2512.10925) | [PDF](https://arxiv.org/pdf/2512.10925.pdf)

**ä½œè€…**: Zamirddine Mari, Mohamad Motasem Nawaf, Pierre Drap

**åˆ†ç±»**: cs.LG, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-12-11

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽæ•°å­—å­ªç”Ÿç›‘ç£å¼ºåŒ–å­¦ä¹ çš„æ°´ä¸‹è‡ªä¸»å¯¼èˆªæ¡†æž¶ï¼Œæå‡å¤æ‚çŽ¯å¢ƒé€‚åº”æ€§ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `æ°´ä¸‹è‡ªä¸»å¯¼èˆª` `æ·±åº¦å¼ºåŒ–å­¦ä¹ ` `æ•°å­—å­ªç”Ÿ` `è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–` `æ°´ä¸‹æœºå™¨äºº`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ°´ä¸‹è‡ªä¸»å¯¼èˆªé¢ä¸´GPSç¼ºå¤±ã€ä½Žèƒ½è§åº¦ç­‰æŒ‘æˆ˜ï¼Œä¼ ç»Ÿæ–¹æ³•éš¾ä»¥æœ‰æ•ˆåº”å¯¹å¤æ‚çŽ¯å¢ƒã€‚
2. åˆ©ç”¨PPOç®—æ³•ï¼Œç»“åˆè™šæ‹ŸçŽ¯å¢ƒä¿¡æ¯å’Œå°„çº¿æŠ•å°„ï¼Œæž„å»ºå¼ºåŒ–å­¦ä¹ ç­–ç•¥ï¼Œæå‡å¯¼èˆªæ€§èƒ½ã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨ä»¿çœŸå’ŒçœŸå®žæ°´ä¸‹çŽ¯å¢ƒä¸­å‡ä¼˜äºŽDWAï¼Œå¹¶å…·å¤‡è‰¯å¥½çš„è¿ç§»èƒ½åŠ›ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡é’ˆå¯¹æ°´ä¸‹çŽ¯å¢ƒè‡ªä¸»å¯¼èˆªéš¾é¢˜ï¼Œå¦‚GPSç¼ºå¤±ã€ä½Žèƒ½è§åº¦å’Œæ°´ä¸‹éšœç¢ç‰©ï¼Œæå‡ºäº†ä¸€ç§åŸºäºŽè¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆPPOï¼‰ç®—æ³•çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ æ–¹æ³•ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ç›®æ ‡å¯¼å‘å¯¼èˆªä¿¡æ¯ã€è™šæ‹Ÿå æ®æ …æ ¼å’Œæ²¿æ“ä½œåŒºåŸŸè¾¹ç•Œçš„å°„çº¿æŠ•å°„æž„å»ºè§‚æµ‹ç©ºé—´ã€‚é€šè¿‡åœ¨é€¼çœŸçš„ä»¿çœŸçŽ¯å¢ƒä¸­è¯„ä¼°ï¼Œå¹¶å°†å­¦ä¹ åˆ°çš„ç­–ç•¥ä¸Žå¸¸ç”¨çš„åŠ¨æ€çª—å£æ³•ï¼ˆDWAï¼‰è¿›è¡Œæ¯”è¾ƒï¼Œç»“æžœè¡¨æ˜Žï¼ŒPPOç­–ç•¥åœ¨é«˜åº¦æ‚ä¹±çš„çŽ¯å¢ƒä¸­å§‹ç»ˆä¼˜äºŽDWAï¼Œè¿™ä¸»è¦å½’åŠŸäºŽå…¶æ›´å¥½çš„å±€éƒ¨é€‚åº”æ€§å’Œæ›´å°‘çš„ç¢°æ’žã€‚æ­¤å¤–ï¼Œé€šè¿‡æ•°å­—å­ªç”Ÿç›‘ç£ä¸‹çš„çœŸå®žBlueROV2å®žéªŒï¼ŒéªŒè¯äº†å­¦ä¹ åˆ°çš„è¡Œä¸ºä»Žä»¿çœŸåˆ°çŽ°å®žä¸–ç•Œçš„è¿ç§»èƒ½åŠ›ï¼Œè¯å®žäº†æ·±åº¦å¼ºåŒ–å­¦ä¹ åœ¨æ°´ä¸‹æœºå™¨äººè‡ªä¸»å¯¼èˆªä¸­çš„ç›¸å…³æ€§ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæ°´ä¸‹è‡ªä¸»å¯¼èˆªçš„ä¸»è¦é—®é¢˜åœ¨äºŽç¼ºä¹å¯é çš„å®šä½ä¿¡æ¯ï¼ˆGPSä¸å¯ç”¨ï¼‰ï¼Œæ°´ä¸‹çŽ¯å¢ƒçš„ä½Žèƒ½è§åº¦ï¼Œä»¥åŠå¤æ‚çŽ¯å¢ƒä¸­å­˜åœ¨çš„æ°´ä¸‹éšœç¢ç‰©ã€‚çŽ°æœ‰çš„æ–¹æ³•ï¼Œä¾‹å¦‚DWAï¼Œåœ¨é«˜åº¦åŠ¨æ€å’Œå¤æ‚çš„çŽ¯å¢ƒä¸­å®¹æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜ï¼Œå¯¼è‡´å¯¼èˆªæ•ˆçŽ‡é™ä½Žæˆ–ç¢°æ’žé£Žé™©å¢žåŠ ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDRLï¼‰æ¥å­¦ä¹ ä¸€ä¸ªèƒ½å¤Ÿé€‚åº”å¤æ‚æ°´ä¸‹çŽ¯å¢ƒçš„å¯¼èˆªç­–ç•¥ã€‚é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼Œæ™ºèƒ½ä½“å¯ä»¥ä»Žä¸ŽçŽ¯å¢ƒçš„äº¤äº’ä¸­å­¦ä¹ ï¼Œä»Žè€Œæ‰¾åˆ°æœ€ä¼˜çš„å¯¼èˆªè·¯å¾„ï¼Œé¿å…éšœç¢ç‰©ï¼Œå¹¶æœ€ç»ˆè¾¾åˆ°ç›®æ ‡ã€‚æ•°å­—å­ªç”Ÿçš„å¼•å…¥ï¼Œé™ä½Žäº†çœŸå®žçŽ¯å¢ƒå®žéªŒçš„é£Žé™©ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šè¯¥æ¡†æž¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) ä»¿çœŸçŽ¯å¢ƒï¼šç”¨äºŽè®­ç»ƒå¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“ï¼Œæä¾›é€¼çœŸçš„æ°´ä¸‹çŽ¯å¢ƒæ¨¡æ‹Ÿã€‚2) å¼ºåŒ–å­¦ä¹ æ¨¡å—ï¼šä½¿ç”¨PPOç®—æ³•è®­ç»ƒå¯¼èˆªç­–ç•¥ã€‚3) è§‚æµ‹ç©ºé—´æž„å»ºï¼šç»“åˆç›®æ ‡å¯¼å‘å¯¼èˆªä¿¡æ¯ã€è™šæ‹Ÿå æ®æ …æ ¼å’Œå°„çº¿æŠ•å°„ï¼Œä¸ºæ™ºèƒ½ä½“æä¾›ä¸°å¯Œçš„çŽ¯å¢ƒä¿¡æ¯ã€‚4) æ•°å­—å­ªç”Ÿç›‘ç£ï¼šåˆ©ç”¨æ•°å­—å­ªç”ŸæŠ€æœ¯ï¼Œåœ¨è™šæ‹ŸçŽ¯å¢ƒä¸­éªŒè¯å’Œä¼˜åŒ–ç­–ç•¥ï¼Œå‡å°‘çœŸå®žçŽ¯å¢ƒå®žéªŒçš„é£Žé™©ã€‚5) çœŸå®žæ°´ä¸‹æœºå™¨äººå®žéªŒï¼šå°†è®­ç»ƒå¥½çš„ç­–ç•¥éƒ¨ç½²åˆ°çœŸå®žçš„BlueROV2æ°´ä¸‹æœºå™¨äººä¸Šè¿›è¡ŒéªŒè¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽå°†æ·±åº¦å¼ºåŒ–å­¦ä¹ ä¸Žæ•°å­—å­ªç”ŸæŠ€æœ¯ç›¸ç»“åˆï¼Œç”¨äºŽè§£å†³æ°´ä¸‹è‡ªä¸»å¯¼èˆªé—®é¢˜ã€‚ä¼ ç»Ÿçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•é€šå¸¸éœ€è¦åœ¨çœŸå®žçŽ¯å¢ƒä¸­è¿›è¡Œå¤§é‡çš„å®žéªŒï¼Œè¿™å¯¹äºŽæ°´ä¸‹æœºå™¨äººæ¥è¯´æ˜¯å±é™©ä¸”æ˜‚è´µçš„ã€‚é€šè¿‡æ•°å­—å­ªç”ŸæŠ€æœ¯ï¼Œå¯ä»¥åœ¨è™šæ‹ŸçŽ¯å¢ƒä¸­è¿›è¡Œç­–ç•¥çš„è®­ç»ƒå’ŒéªŒè¯ï¼Œä»Žè€Œé™ä½Žäº†çœŸå®žçŽ¯å¢ƒå®žéªŒçš„é£Žé™©å’Œæˆæœ¬ã€‚æ­¤å¤–ï¼Œç»“åˆå¤šç§çŽ¯å¢ƒä¿¡æ¯æž„å»ºè§‚æµ‹ç©ºé—´ï¼Œæå‡äº†æ™ºèƒ½ä½“å¯¹çŽ¯å¢ƒçš„æ„ŸçŸ¥èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­ä½¿ç”¨äº†PPOç®—æ³•ä½œä¸ºå¼ºåŒ–å­¦ä¹ çš„æ ¸å¿ƒç®—æ³•ã€‚è§‚æµ‹ç©ºé—´ç”±ä¸‰éƒ¨åˆ†ç»„æˆï¼šç›®æ ‡å¯¼å‘å¯¼èˆªä¿¡æ¯ï¼ˆç›®æ ‡æ–¹å‘å’Œè·ç¦»ï¼‰ã€è™šæ‹Ÿå æ®æ …æ ¼ï¼ˆå‘¨å›´çŽ¯å¢ƒçš„å±€éƒ¨åœ°å›¾ï¼‰å’Œå°„çº¿æŠ•å°„ï¼ˆæ²¿æ“ä½œåŒºåŸŸè¾¹ç•Œçš„è·ç¦»ä¿¡æ¯ï¼‰ã€‚å¥–åŠ±å‡½æ•°çš„è®¾è®¡æ—¨åœ¨é¼“åŠ±æ™ºèƒ½ä½“æœç€ç›®æ ‡å‰è¿›ï¼ŒåŒæ—¶é¿å…ç¢°æ’žã€‚å…·ä½“çš„ç½‘ç»œç»“æž„å’Œå‚æ•°è®¾ç½®åœ¨è®ºæ–‡ä¸­æ²¡æœ‰è¯¦ç»†è¯´æ˜Žï¼Œå±žäºŽæœªçŸ¥ä¿¡æ¯ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒåŸºäºŽPPOçš„å¼ºåŒ–å­¦ä¹ ç­–ç•¥åœ¨é«˜åº¦æ‚ä¹±çš„æ°´ä¸‹çŽ¯å¢ƒä¸­ï¼Œå¯¼èˆªæ€§èƒ½æ˜Žæ˜¾ä¼˜äºŽä¼ ç»Ÿçš„DWAç®—æ³•ã€‚PPOç­–ç•¥èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”å±€éƒ¨çŽ¯å¢ƒå˜åŒ–ï¼Œå‡å°‘ç¢°æ’žæ¬¡æ•°ï¼Œå¹¶æˆåŠŸåœ°å°†å­¦ä¹ åˆ°çš„ç­–ç•¥ä»Žä»¿çœŸçŽ¯å¢ƒè¿ç§»åˆ°çœŸå®žçš„BlueROV2æ°´ä¸‹æœºå™¨äººä¸Šã€‚å…·ä½“æ€§èƒ½æ•°æ®æœªçŸ¥ï¼Œä½†æ•´ä½“è¡¨çŽ°ä¼˜äºŽDWAã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽæ°´ä¸‹çŽ¯å¢ƒç›‘æµ‹ã€æ°´ä¸‹èµ„æºå‹˜æŽ¢ã€æ°´ä¸‹åŸºç¡€è®¾æ–½ç»´æŠ¤ã€æ°´ä¸‹æœæ•‘ç­‰é¢†åŸŸã€‚é€šè¿‡è‡ªä¸»å¯¼èˆªï¼Œæ°´ä¸‹æœºå™¨äººå¯ä»¥æ›´é«˜æ•ˆã€æ›´å®‰å…¨åœ°å®Œæˆå„ç§æ°´ä¸‹ä»»åŠ¡ï¼Œé™ä½Žäººå·¥æ“ä½œçš„é£Žé™©å’Œæˆæœ¬ï¼Œæé«˜ä½œä¸šæ•ˆçŽ‡ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›è¿›ä¸€æ­¥æŽ¨å¹¿åˆ°å…¶ä»–ç±»åž‹çš„æœºå™¨äººå’Œå¤æ‚çŽ¯å¢ƒã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Autonomous navigation in underwater environments remains a major challenge due to the absence of GPS, degraded visibility, and the presence of submerged obstacles. This article investigates these issues through the case of the BlueROV2, an open platform widely used for scientific experimentation. We propose a deep reinforcement learning approach based on the Proximal Policy Optimization (PPO) algorithm, using an observation space that combines target-oriented navigation information, a virtual occupancy grid, and ray-casting along the boundaries of the operational area. The learned policy is compared against a reference deterministic kinematic planner, the Dynamic Window Approach (DWA), commonly employed as a robust baseline for obstacle avoidance. The evaluation is conducted in a realistic simulation environment and complemented by validation on a physical BlueROV2 supervised by a 3D digital twin of the test site, helping to reduce risks associated with real-world experimentation. The results show that the PPO policy consistently outperforms DWA in highly cluttered environments, notably thanks to better local adaptation and reduced collisions. Finally, the experiments demonstrate the transferability of the learned behavior from simulation to the real world, confirming the relevance of deep RL for autonomous navigation in underwater robotics.

