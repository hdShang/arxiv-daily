---
layout: default
title: Push Smarter, Not Harder: Hierarchical RL-Diffusion Policy for Efficient Nonprehensile Manipulation
---

# Push Smarter, Not Harder: Hierarchical RL-Diffusion Policy for Efficient Nonprehensile Manipulation

**arXiv**: [2512.10099v1](https://arxiv.org/abs/2512.10099) | [PDF](https://arxiv.org/pdf/2512.10099.pdf)

**ä½œè€…**: Steven Caro, Stephen L. Smith

**åˆ†ç±»**: cs.RO, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-12-10

**å¤‡æ³¨**: 8 pages, 8 figures

**ðŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/carosteven/HeRD)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHeRDï¼šä¸€ç§ç”¨äºŽé«˜æ•ˆéžæŠ“å–æ“ä½œçš„åˆ†å±‚RL-æ‰©æ•£ç­–ç•¥**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `éžæŠ“å–æ“ä½œ` `å¼ºåŒ–å­¦ä¹ ` `æ‰©æ•£æ¨¡åž‹` `åˆ†å±‚æŽ§åˆ¶` `æœºå™¨äººæ“ä½œ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. éžæŠ“å–æ“ä½œå› å…¶å¤æ‚çš„æŽ¥è§¦åŠ¨åŠ›å­¦å’Œé•¿ç¨‹è§„åˆ’éœ€æ±‚è€Œæžå…·æŒ‘æˆ˜æ€§ï¼ŒçŽ°æœ‰æ–¹æ³•éš¾ä»¥å…¼é¡¾æ•ˆçŽ‡ä¸Žæ³›åŒ–æ€§ã€‚
2. HeRDé‡‡ç”¨åˆ†å±‚å¼ºåŒ–å­¦ä¹ -æ‰©æ•£ç­–ç•¥ï¼Œåˆ©ç”¨é«˜å±‚RLé€‰æ‹©ä¸­é—´ç›®æ ‡ï¼Œä½Žå±‚æ‰©æ•£æ¨¡åž‹ç”Ÿæˆè½¨è¿¹ï¼Œå®žçŽ°é«˜æ•ˆæ“ä½œã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒHeRDåœ¨æˆåŠŸçŽ‡ã€è·¯å¾„æ•ˆçŽ‡å’Œæ³›åŒ–èƒ½åŠ›ä¸Šå‡ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œä¸ºéžæŠ“å–æ“ä½œæä¾›äº†ä¸€ç§æ–°æ€è·¯ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äºŽéžæŠ“å–æ“ä½œï¼ˆä¾‹å¦‚åœ¨æ‚ä¹±çŽ¯å¢ƒä¸­æŽ¨åŠ¨ç‰©ä½“ï¼‰çš„åˆ†å±‚å¼ºåŒ–å­¦ä¹ -æ‰©æ•£ç­–ç•¥ï¼Œç§°ä¸ºHeRDã€‚ç”±äºŽå¤æ‚çš„æŽ¥è§¦åŠ¨åŠ›å­¦å’Œé•¿ç¨‹è§„åˆ’éœ€æ±‚ï¼ŒéžæŠ“å–æ“ä½œæ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„æŽ§åˆ¶é—®é¢˜ã€‚HeRDå°†æŽ¨åŠ¨ä»»åŠ¡åˆ†è§£ä¸ºä¸¤ä¸ªå±‚æ¬¡ï¼šé«˜å±‚ç›®æ ‡é€‰æ‹©å’Œä½Žå±‚è½¨è¿¹ç”Ÿæˆã€‚æˆ‘ä»¬é‡‡ç”¨é«˜å±‚å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ™ºèƒ½ä½“æ¥é€‰æ‹©ä¸­é—´ç©ºé—´ç›®æ ‡ï¼Œå¹¶ä½¿ç”¨ä½Žå±‚ç›®æ ‡æ¡ä»¶æ‰©æ•£æ¨¡åž‹æ¥ç”Ÿæˆå¯è¡Œçš„ã€é«˜æ•ˆçš„è½¨è¿¹ä»¥è¾¾åˆ°è¿™äº›ç›®æ ‡ã€‚è¿™ç§æž¶æž„ç»“åˆäº†RLçš„é•¿æœŸå¥–åŠ±æœ€å¤§åŒ–è¡Œä¸ºå’Œæ‰©æ•£æ¨¡åž‹çš„ç”Ÿæˆèƒ½åŠ›ã€‚æˆ‘ä»¬åœ¨2Dä»¿çœŸçŽ¯å¢ƒä¸­è¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œç»“æžœè¡¨æ˜Žï¼Œåœ¨æˆåŠŸçŽ‡ã€è·¯å¾„æ•ˆçŽ‡å’Œè·¨å¤šç§çŽ¯å¢ƒé…ç½®çš„æ³›åŒ–æ–¹é¢ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºŽæœ€å…ˆè¿›çš„åŸºçº¿ã€‚æˆ‘ä»¬çš„ç»“æžœè¡¨æ˜Žï¼Œå…·æœ‰ç”Ÿæˆå¼ä½Žå±‚è§„åˆ’çš„åˆ†å±‚æŽ§åˆ¶æ˜¯å¯æ‰©å±•çš„ã€é¢å‘ç›®æ ‡çš„éžæŠ“å–æ“ä½œçš„ä¸€ä¸ªæœ‰å¸Œæœ›çš„æ–¹å‘ã€‚ä»£ç ã€æ–‡æ¡£å’Œè®­ç»ƒå¥½çš„æ¨¡åž‹å·²å¼€æºã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³éžæŠ“å–æ“ä½œä¸­ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚çŽ¯å¢ƒä¸­æŽ¨åŠ¨ç‰©ä½“æ—¶ï¼Œç”±äºŽæŽ¥è§¦åŠ¨åŠ›å­¦å¤æ‚å’Œéœ€è¦é•¿ç¨‹è§„åˆ’è€Œå¯¼è‡´çš„æŽ§åˆ¶éš¾é¢˜ã€‚çŽ°æœ‰æ–¹æ³•é€šå¸¸éš¾ä»¥åœ¨æˆåŠŸçŽ‡ã€è·¯å¾„æ•ˆçŽ‡å’Œæ³›åŒ–èƒ½åŠ›ä¹‹é—´å–å¾—å¹³è¡¡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†æŽ¨åŠ¨ä»»åŠ¡åˆ†è§£ä¸ºä¸¤ä¸ªå±‚æ¬¡ï¼šé«˜å±‚ç›®æ ‡é€‰æ‹©å’Œä½Žå±‚è½¨è¿¹ç”Ÿæˆã€‚é«˜å±‚ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æ¥é€‰æ‹©ä¸­é—´ç›®æ ‡ï¼Œä½Žå±‚ä½¿ç”¨æ‰©æ•£æ¨¡åž‹ç”Ÿæˆåˆ°è¾¾è¿™äº›ç›®æ ‡çš„è½¨è¿¹ã€‚è¿™ç§åˆ†å±‚ç»“æž„æ—¨åœ¨ç»“åˆå¼ºåŒ–å­¦ä¹ çš„é•¿æœŸè§„åˆ’èƒ½åŠ›å’Œæ‰©æ•£æ¨¡åž‹çš„ç”Ÿæˆèƒ½åŠ›ï¼Œä»Žè€Œå®žçŽ°æ›´é«˜æ•ˆå’Œé²æ£’çš„éžæŠ“å–æ“ä½œã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šHeRDæ¡†æž¶åŒ…å«ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé«˜å±‚RLæ™ºèƒ½ä½“å’Œä½Žå±‚ç›®æ ‡æ¡ä»¶æ‰©æ•£æ¨¡åž‹ã€‚é«˜å±‚RLæ™ºèƒ½ä½“è´Ÿè´£æ ¹æ®å½“å‰çŽ¯å¢ƒçŠ¶æ€é€‰æ‹©ä¸€ä¸ªä¸­é—´ç›®æ ‡ã€‚ä½Žå±‚æ‰©æ•£æ¨¡åž‹åˆ™æ ¹æ®é«˜å±‚é€‰æ‹©çš„ç›®æ ‡ï¼Œç”Ÿæˆä¸€æ¡ä»Žå½“å‰çŠ¶æ€åˆ°è¾¾è¯¥ç›®æ ‡çš„è½¨è¿¹ã€‚æ•´ä¸ªè¿‡ç¨‹é€šè¿‡å¼ºåŒ–å­¦ä¹ è¿›è¡Œè®­ç»ƒï¼Œä»¥æœ€å¤§åŒ–é•¿æœŸå¥–åŠ±ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°åœ¨äºŽå°†å¼ºåŒ–å­¦ä¹ å’Œæ‰©æ•£æ¨¡åž‹ç»“åˆèµ·æ¥ï¼Œå½¢æˆä¸€ä¸ªåˆ†å±‚æŽ§åˆ¶æ¡†æž¶ã€‚å¼ºåŒ–å­¦ä¹ è´Ÿè´£é«˜å±‚å†³ç­–ï¼Œæ‰©æ•£æ¨¡åž‹è´Ÿè´£ä½Žå±‚è½¨è¿¹ç”Ÿæˆã€‚è¿™ç§ç»“åˆæ—¢åˆ©ç”¨äº†å¼ºåŒ–å­¦ä¹ çš„é•¿æœŸè§„åˆ’èƒ½åŠ›ï¼Œåˆåˆ©ç”¨äº†æ‰©æ•£æ¨¡åž‹çš„ç”Ÿæˆèƒ½åŠ›ï¼Œä»Žè€Œå®žçŽ°äº†æ›´é«˜æ•ˆå’Œé²æ£’çš„éžæŠ“å–æ“ä½œã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒHeRDèƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†å¤æ‚çš„æŽ¥è§¦åŠ¨åŠ›å­¦å’Œé•¿ç¨‹è§„åˆ’éœ€æ±‚ã€‚

**å…³é”®è®¾è®¡**ï¼šé«˜å±‚RLæ™ºèƒ½ä½“ä½¿ç”¨æ ‡å‡†çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼ˆå…·ä½“ç®—æ³•æœªçŸ¥ï¼‰è¿›è¡Œè®­ç»ƒï¼Œå¥–åŠ±å‡½æ•°çš„è®¾è®¡æ—¨åœ¨é¼“åŠ±æ™ºèƒ½ä½“é€‰æ‹©èƒ½å¤Ÿæœ‰æ•ˆæŽ¨åŠ¨ç‰©ä½“åˆ°è¾¾æœ€ç»ˆç›®æ ‡çš„ä¸­é—´ç›®æ ‡ã€‚ä½Žå±‚æ‰©æ•£æ¨¡åž‹ä½¿ç”¨ç›®æ ‡æ¡ä»¶æ‰©æ•£æ¨¡åž‹ï¼Œè¯¥æ¨¡åž‹èƒ½å¤Ÿæ ¹æ®ç»™å®šçš„ç›®æ ‡ç”Ÿæˆç›¸åº”çš„è½¨è¿¹ã€‚æ‰©æ•£æ¨¡åž‹çš„å…·ä½“ç½‘ç»œç»“æž„å’Œè®­ç»ƒç»†èŠ‚æœªçŸ¥ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒHeRDåœ¨2Dä»¿çœŸçŽ¯å¢ƒä¸­ä¼˜äºŽæœ€å…ˆè¿›çš„åŸºçº¿æ–¹æ³•ã€‚å…·ä½“è€Œè¨€ï¼ŒHeRDåœ¨æˆåŠŸçŽ‡ã€è·¯å¾„æ•ˆçŽ‡å’Œè·¨å¤šç§çŽ¯å¢ƒé…ç½®çš„æ³›åŒ–èƒ½åŠ›æ–¹é¢å‡å–å¾—äº†æ˜¾è‘—æå‡ã€‚è¿™äº›ç»“æžœè¡¨æ˜Žï¼Œå…·æœ‰ç”Ÿæˆå¼ä½Žå±‚è§„åˆ’çš„åˆ†å±‚æŽ§åˆ¶æ˜¯å¯æ‰©å±•çš„ã€é¢å‘ç›®æ ‡çš„éžæŠ“å–æ“ä½œçš„ä¸€ä¸ªæœ‰å¸Œæœ›çš„æ–¹å‘ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽæœºå™¨äººæ“ä½œã€è‡ªåŠ¨åŒ–è£…é…ã€ç‰©æµåˆ†æ‹£ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨è‡ªåŠ¨åŒ–è£…é…ä¸­ï¼Œæœºå™¨äººå¯ä»¥åˆ©ç”¨è¯¥æ–¹æ³•åœ¨æ‹¥æŒ¤çš„çŽ¯å¢ƒä¸­æŽ¨åŠ¨é›¶ä»¶åˆ°æŒ‡å®šä½ç½®ã€‚åœ¨ç‰©æµåˆ†æ‹£ä¸­ï¼Œæœºå™¨äººå¯ä»¥åˆ©ç”¨è¯¥æ–¹æ³•é«˜æ•ˆåœ°å°†åŒ…è£¹æŽ¨é€åˆ°ä¸åŒçš„ä¼ é€å¸¦ä¸Šã€‚è¯¥ç ”ç©¶ä¸ºå®žçŽ°æ›´æ™ºèƒ½ã€æ›´çµæ´»çš„æœºå™¨äººæ“ä½œæä¾›äº†æ–°çš„æ€è·¯ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Nonprehensile manipulation, such as pushing objects across cluttered environments, presents a challenging control problem due to complex contact dynamics and long-horizon planning requirements. In this work, we propose HeRD, a hierarchical reinforcement learning-diffusion policy that decomposes pushing tasks into two levels: high-level goal selection and low-level trajectory generation. We employ a high-level reinforcement learning (RL) agent to select intermediate spatial goals, and a low-level goal-conditioned diffusion model to generate feasible, efficient trajectories to reach them.
>   This architecture combines the long-term reward maximizing behaviour of RL with the generative capabilities of diffusion models. We evaluate our method in a 2D simulation environment and show that it outperforms the state-of-the-art baseline in success rate, path efficiency, and generalization across multiple environment configurations. Our results suggest that hierarchical control with generative low-level planning is a promising direction for scalable, goal-directed nonprehensile manipulation. Code, documentation, and trained models are available: https://github.com/carosteven/HeRD.

