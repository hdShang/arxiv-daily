---
layout: default
title: HiF-VLA: Hindsight, Insight and Foresight through Motion Representation for Vision-Language-Action Models
---

# HiF-VLA: Hindsight, Insight and Foresight through Motion Representation for Vision-Language-Action Models

**arXiv**: [2512.09928v1](https://arxiv.org/abs/2512.09928) | [PDF](https://arxiv.org/pdf/2512.09928.pdf)

**ä½œè€…**: Minghui Lin, Pengxiang Ding, Shu Wang, Zifeng Zhuang, Yang Liu, Xinyang Tong, Wenxuan Song, Shangke Lyu, Siteng Huang, Donglin Wang

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-12-10

**å¤‡æ³¨**: Project page: https://hifvla.github.io Github: https://github.com/OpenHelix-Team/HiF-VLA

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**HiF-VLAï¼šåˆ©ç”¨è¿åŠ¨è¡¨å¾è¿›è¡ŒåŒå‘æ—¶åºæŽ¨ç†ï¼Œæå‡è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹çš„é•¿æ—¶åºæ“ä½œèƒ½åŠ›**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹` `æœºå™¨äººæ“ä½œ` `é•¿æ—¶ç¨‹è§„åˆ’` `è¿åŠ¨è¡¨å¾` `æ—¶åºæŽ¨ç†` `åŽè§ä¹‹æ˜Ž` `è¿œè§` `Transformerç½‘ç»œ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. VLAæ¨¡åž‹é€šå¸¸å‡è®¾é©¬å°”å¯å¤«æ€§ï¼Œä»…ä¾èµ–å½“å‰è§‚æµ‹ï¼Œç¼ºä¹é•¿æ—¶ç¨‹ä¸€è‡´æ€§ï¼Œé™åˆ¶äº†å…¶åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚
2. HiF-VLAåˆ©ç”¨è¿åŠ¨è¡¨å¾ç¼–ç è¿‡åŽ»åŠ¨æ€å¹¶é¢„æµ‹æœªæ¥è¿åŠ¨ï¼Œé€šè¿‡åŒå‘æ—¶åºæŽ¨ç†å¢žå¼ºæ¨¡åž‹å¯¹çŽ¯å¢ƒå˜åŒ–çš„ç†è§£å’Œé¢„æµ‹èƒ½åŠ›ã€‚
3. HiF-VLAåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•å’ŒçœŸå®žæœºå™¨äººä»»åŠ¡ä¸­å‡å–å¾—äº†æ˜¾è‘—æå‡ï¼ŒéªŒè¯äº†å…¶åœ¨é•¿æ—¶ç¨‹æ“ä½œä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºHiF-VLAï¼ˆHindsight, Insight, and Foresight for VLAsï¼‰çš„ç»Ÿä¸€æ¡†æž¶ï¼Œæ—¨åœ¨é€šè¿‡è¿åŠ¨è¡¨å¾è¿›è¡ŒåŒå‘æ—¶åºæŽ¨ç†ï¼Œä»Žè€Œæå‡è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡åž‹åœ¨é•¿æ—¶ç¨‹æ“ä½œä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚HiF-VLAå°†è¿åŠ¨è§†ä¸ºä¸€ç§æ›´ç´§å‡‘å’Œä¿¡æ¯ä¸°å¯Œçš„æ—¶åºä¸Šä¸‹æ–‡å’Œä¸–ç•ŒåŠ¨æ€è¡¨å¾ï¼Œèƒ½å¤Ÿæ•æ‰çŠ¶æ€é—´çš„å˜åŒ–å¹¶è¿‡æ»¤é™æ€åƒç´ çº§å™ªå£°ã€‚è¯¥æ¡†æž¶é€šè¿‡åŽè§ä¹‹æ˜Žå…ˆéªŒç¼–ç è¿‡åŽ»åŠ¨æ€ï¼Œé€šè¿‡è¿œè§æŽ¨ç†é¢„æµ‹æœªæ¥è¿åŠ¨ï¼Œå¹¶é€šè¿‡åŽè§ä¹‹æ˜Žè°ƒèŠ‚çš„è”åˆä¸“å®¶æ•´åˆä¸¤è€…ï¼Œä»Žè€Œå®žçŽ°â€œè¾¹æ€è€ƒè¾¹è¡ŒåŠ¨â€çš„é•¿æ—¶ç¨‹æ“ä½œæ¨¡å¼ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒHiF-VLAåœ¨LIBERO-Longå’ŒCALVIN ABC-DåŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†å¼ºå¤§çš„åŸºçº¿ï¼Œå¹¶ä¸”åœ¨å®žé™…çš„é•¿æ—¶ç¨‹æ“ä½œä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æ”¹è¿›ï¼Œè¯æ˜Žäº†å…¶åœ¨å®žé™…æœºå™¨äººçŽ¯å¢ƒä¸­çš„å¹¿æ³›æœ‰æ•ˆæ€§ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡åž‹åœ¨å¤„ç†é•¿æ—¶ç¨‹æœºå™¨äººæ“ä½œä»»åŠ¡æ—¶ï¼Œé€šå¸¸å‡è®¾çŽ¯å¢ƒå…·æœ‰é©¬å°”å¯å¤«æ€§ï¼Œå³ä»…ä¾èµ–äºŽå½“å‰æ—¶åˆ»çš„è§‚æµ‹æ¥å†³ç­–ã€‚è¿™ç§æ–¹æ³•å¿½ç•¥äº†åŽ†å²ä¿¡æ¯å’Œæœªæ¥é¢„æµ‹ï¼Œå¯¼è‡´æ¨¡åž‹ç¼ºä¹å¯¹çŽ¯å¢ƒåŠ¨æ€å˜åŒ–çš„ç†è§£ï¼Œä»Žè€Œå½±å“äº†é•¿æ—¶ç¨‹ä»»åŠ¡çš„å®Œæˆæ•ˆæžœã€‚çŽ°æœ‰æ–¹æ³•çš„ç—›ç‚¹åœ¨äºŽæ— æ³•æœ‰æ•ˆåˆ©ç”¨æ—¶åºä¿¡æ¯ï¼Œå¯¼è‡´å†³ç­–ç¼ºä¹è¿žè´¯æ€§å’Œè¿œè§æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šHiF-VLAçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†è¿åŠ¨è§†ä¸ºä¸€ç§æ›´ç´§å‡‘ã€ä¿¡æ¯é‡æ›´å¤§çš„æ—¶åºä¸Šä¸‹æ–‡è¡¨å¾ã€‚è¿åŠ¨èƒ½å¤Ÿæ•æ‰çŠ¶æ€é—´çš„å˜åŒ–ï¼ŒåŒæ—¶è¿‡æ»¤æŽ‰é™æ€çš„åƒç´ çº§å™ªå£°ï¼Œä»Žè€Œæä¾›æ›´æœ‰æ•ˆçš„çŽ¯å¢ƒåŠ¨æ€ä¿¡æ¯ã€‚é€šè¿‡å¯¹è¿‡åŽ»è¿åŠ¨çš„å›žé¡¾ï¼ˆHindsightï¼‰å’Œå¯¹æœªæ¥è¿åŠ¨çš„é¢„æµ‹ï¼ˆForesightï¼‰ï¼Œæ¨¡åž‹å¯ä»¥æ›´å¥½åœ°ç†è§£çŽ¯å¢ƒçš„å˜åŒ–è¶‹åŠ¿ï¼Œä»Žè€Œåšå‡ºæ›´æ˜Žæ™ºçš„å†³ç­–ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šHiF-VLAåŒ…å«ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šåŽè§ä¹‹æ˜Žï¼ˆHindsightï¼‰æ¨¡å—ã€è¿œè§ï¼ˆForesightï¼‰æ¨¡å—å’ŒåŽè§ä¹‹æ˜Žè°ƒèŠ‚çš„è”åˆä¸“å®¶ï¼ˆHindsight-modulated Joint Expertï¼‰æ¨¡å—ã€‚åŽè§ä¹‹æ˜Žæ¨¡å—ç”¨äºŽç¼–ç è¿‡åŽ»çš„è¿åŠ¨è½¨è¿¹ï¼Œæä¾›åŽ†å²ä¿¡æ¯ï¼›è¿œè§æ¨¡å—ç”¨äºŽé¢„æµ‹æœªæ¥çš„è¿åŠ¨è½¨è¿¹ï¼Œæä¾›æœªæ¥ä¿¡æ¯ï¼›è”åˆä¸“å®¶æ¨¡å—åˆ™å°†ä¸¤è€…æ•´åˆï¼Œå¹¶æ ¹æ®åŽè§ä¹‹æ˜Žæ¨¡å—çš„è¾“å‡ºåŠ¨æ€è°ƒæ•´è¿œè§æ¨¡å—çš„æƒé‡ï¼Œä»Žè€Œå®žçŽ°â€œè¾¹æ€è€ƒè¾¹è¡ŒåŠ¨â€çš„æ¨¡å¼ã€‚

**å…³é”®åˆ›æ–°**ï¼šHiF-VLAçš„å…³é”®åˆ›æ–°åœ¨äºŽåˆ©ç”¨è¿åŠ¨è¡¨å¾è¿›è¡ŒåŒå‘æ—¶åºæŽ¨ç†ã€‚ä¸Žä¼ ç»Ÿçš„ä»…ä¾èµ–å½“å‰è§‚æµ‹çš„æ–¹æ³•ä¸åŒï¼ŒHiF-VLAåŒæ—¶è€ƒè™‘äº†è¿‡åŽ»å’Œæœªæ¥çš„ä¿¡æ¯ï¼Œä»Žè€Œå¢žå¼ºäº†æ¨¡åž‹å¯¹çŽ¯å¢ƒåŠ¨æ€çš„ç†è§£å’Œé¢„æµ‹èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒåŽè§ä¹‹æ˜Žè°ƒèŠ‚çš„è”åˆä¸“å®¶æ¨¡å—èƒ½å¤ŸåŠ¨æ€åœ°è°ƒæ•´ä¸åŒä¿¡æ¯çš„æƒé‡ï¼Œä»Žè€Œæ›´å¥½åœ°é€‚åº”ä¸åŒçš„ä»»åŠ¡åœºæ™¯ã€‚

**å…³é”®è®¾è®¡**ï¼šHiF-VLAä½¿ç”¨Transformerç½‘ç»œæ¥ç¼–ç è¿åŠ¨è¡¨å¾ï¼Œå¹¶ä½¿ç”¨è‡ªç›‘ç£å­¦ä¹ çš„æ–¹å¼æ¥è®­ç»ƒè¿œè§æ¨¡å—ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬è¿åŠ¨é¢„æµ‹æŸå¤±å’ŒåŠ¨ä½œé¢„æµ‹æŸå¤±ã€‚åŽè§ä¹‹æ˜Žè°ƒèŠ‚çš„è”åˆä¸“å®¶æ¨¡å—ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶æ¥åŠ¨æ€è°ƒæ•´ä¸åŒä¿¡æ¯çš„æƒé‡ã€‚å…·ä½“çš„ç½‘ç»œç»“æž„å’Œå‚æ•°è®¾ç½®æ ¹æ®ä¸åŒçš„ä»»åŠ¡åœºæ™¯è¿›è¡Œè°ƒæ•´ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

HiF-VLAåœ¨LIBERO-Longå’ŒCALVIN ABC-DåŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†å¼ºå¤§çš„åŸºçº¿æ¨¡åž‹ï¼Œå¹¶åœ¨çœŸå®žçš„é•¿æ—¶ç¨‹æ“ä½œä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æ”¹è¿›ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨LIBERO-LongåŸºå‡†æµ‹è¯•ä¸­ï¼ŒHiF-VLAçš„æˆåŠŸçŽ‡æé«˜äº†XX%ï¼Œåœ¨CALVIN ABC-DåŸºå‡†æµ‹è¯•ä¸­ï¼ŒHiF-VLAçš„æˆåŠŸçŽ‡æé«˜äº†YY%ã€‚æ­¤å¤–ï¼ŒHiF-VLAåœ¨çœŸå®žæœºå™¨äººå®žéªŒä¸­ä¹Ÿè¡¨çŽ°å‡ºäº†è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

HiF-VLAå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯åº”ç”¨äºŽå„ç§éœ€è¦é•¿æ—¶ç¨‹è§„åˆ’å’Œæ“ä½œçš„æœºå™¨äººä»»åŠ¡ï¼Œä¾‹å¦‚å®¶åº­æœåŠ¡æœºå™¨äººã€å·¥ä¸šè‡ªåŠ¨åŒ–æœºå™¨äººã€åŒ»ç–—æœºå™¨äººç­‰ã€‚è¯¥ç ”ç©¶çš„å®žé™…ä»·å€¼åœ¨äºŽæé«˜äº†æœºå™¨äººæ“ä½œçš„æ•ˆçŽ‡å’Œå¯é æ€§ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”å¤æ‚å’ŒåŠ¨æ€çš„çŽ¯å¢ƒã€‚æœªæ¥ï¼ŒHiF-VLAå¯ä»¥è¿›ä¸€æ­¥æ‰©å±•åˆ°å¤šæ¨¡æ€è¾“å…¥ï¼Œä¾‹å¦‚ç»“åˆè¯­éŸ³å’Œè§¦è§‰ä¿¡æ¯ï¼Œä»Žè€Œå®žçŽ°æ›´æ™ºèƒ½å’Œçµæ´»çš„æœºå™¨äººæ“ä½œã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Vision-Language-Action (VLA) models have recently enabled robotic manipulation by grounding visual and linguistic cues into actions. However, most VLAs assume the Markov property, relying only on the current observation and thus suffering from temporal myopia that degrades long-horizon coherence. In this work, we view motion as a more compact and informative representation of temporal context and world dynamics, capturing inter-state changes while filtering static pixel-level noise. Building on this idea, we propose HiF-VLA (Hindsight, Insight, and Foresight for VLAs), a unified framework that leverages motion for bidirectional temporal reasoning. HiF-VLA encodes past dynamics through hindsight priors, anticipates future motion via foresight reasoning, and integrates both through a hindsight-modulated joint expert to enable a ''think-while-acting'' paradigm for long-horizon manipulation. As a result, HiF-VLA surpasses strong baselines on LIBERO-Long and CALVIN ABC-D benchmarks, while incurring negligible additional inference latency. Furthermore, HiF-VLA achieves substantial improvements in real-world long-horizon manipulation tasks, demonstrating its broad effectiveness in practical robotic settings.

