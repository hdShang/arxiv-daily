---
layout: default
title: AnchorDream: Repurposing Video Diffusion for Embodiment-Aware Robot Data Synthesis
---

# AnchorDream: Repurposing Video Diffusion for Embodiment-Aware Robot Data Synthesis

**arXiv**: [2512.11797v1](https://arxiv.org/abs/2512.11797) | [PDF](https://arxiv.org/pdf/2512.11797.pdf)

**ä½œè€…**: Junjie Ye, Rong Xue, Basile Van Hoorick, Pavel Tokmakov, Muhammad Zubair Irshad, Yue Wang, Vitor Guizilini

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-12

**å¤‡æ³¨**: Project page: https://jay-ye.github.io/AnchorDream/

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**AnchorDreamï¼šåˆ©ç”¨è§†é¢‘æ‰©æ•£æ¨¡åž‹è¿›è¡Œå…·èº«æ„ŸçŸ¥æœºå™¨äººæ•°æ®åˆæˆ**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `æœºå™¨äººæ•°æ®åˆæˆ` `è§†é¢‘æ‰©æ•£æ¨¡åž‹` `æ¨¡ä»¿å­¦ä¹ ` `å…·èº«æ„ŸçŸ¥` `è¿åŠ¨æ¸²æŸ“`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æœºå™¨äººæ¨¡ä»¿å­¦ä¹ æ–¹æ³•å—é™äºŽçœŸå®žæ•°æ®èŽ·å–æˆæœ¬é«˜æ˜‚å’Œä»¿çœŸçŽ¯å¢ƒçœŸå®žåº¦ä¸è¶³çš„é—®é¢˜ã€‚
2. AnchorDreamé€šè¿‡ä»¥æœºå™¨äººè¿åŠ¨æ¸²æŸ“ä¸ºæ¡ä»¶é©±åŠ¨è§†é¢‘æ‰©æ•£æ¨¡åž‹ï¼Œåˆæˆé«˜è´¨é‡ã€å¤šæ ·åŒ–çš„æœºå™¨äººæ•°æ®ã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œä½¿ç”¨AnchorDreamç”Ÿæˆçš„æ•°æ®èƒ½æ˜¾è‘—æå‡ä¸‹æ¸¸ç­–ç•¥å­¦ä¹ æ•ˆæžœï¼ŒçœŸå®žçŽ¯å¢ƒæ€§èƒ½æå‡è¿‘ä¸€å€ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§è§„æ¨¡å’Œå¤šæ ·åŒ–çš„æœºå™¨äººæ¼”ç¤ºæ•°æ®æ”¶é›†ä»ç„¶æ˜¯æ¨¡ä»¿å­¦ä¹ çš„ä¸»è¦ç“¶é¢ˆï¼Œå› ä¸ºçœŸå®žä¸–ç•Œçš„æ•°æ®èŽ·å–æˆæœ¬é«˜æ˜‚ï¼Œè€Œä»¿çœŸå™¨æä¾›çš„å¤šæ ·æ€§å’Œé€¼çœŸåº¦æœ‰é™ï¼Œå­˜åœ¨æ˜Žæ˜¾çš„æ¨¡æ‹Ÿåˆ°çœŸå®žä¸–ç•Œçš„å·®è·ã€‚è™½ç„¶ç”Ÿæˆæ¨¡åž‹æä¾›äº†ä¸€ä¸ªæœ‰å¸å¼•åŠ›çš„è§£å†³æ–¹æ¡ˆï¼Œä½†çŽ°æœ‰æ–¹æ³•é€šå¸¸åªæ”¹å˜è§†è§‰å¤–è§‚è€Œä¸åˆ›é€ æ–°çš„è¡Œä¸ºï¼Œæˆ–è€…é­å—å…·èº«ä¸ä¸€è‡´æ€§ï¼Œä»Žè€Œäº§ç”Ÿä¸åˆç†çš„è¿åŠ¨ã€‚ä¸ºäº†è§£å†³è¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†AnchorDreamï¼Œä¸€ç§å…·èº«æ„ŸçŸ¥çš„ä¸–ç•Œæ¨¡åž‹ï¼Œå®ƒå°†é¢„è®­ç»ƒçš„è§†é¢‘æ‰©æ•£æ¨¡åž‹é‡æ–°ç”¨äºŽæœºå™¨äººæ•°æ®åˆæˆã€‚AnchorDreamä»¥æœºå™¨äººè¿åŠ¨æ¸²æŸ“ä¸ºæ¡ä»¶æ¥é©±åŠ¨æ‰©æ•£è¿‡ç¨‹ï¼Œé”šå®šå…·èº«ä»¥é˜²æ­¢å¹»è§‰ï¼ŒåŒæ—¶åˆæˆä¸Žæœºå™¨äººè¿åŠ¨å­¦ä¸€è‡´çš„ç‰©ä½“å’ŒçŽ¯å¢ƒã€‚ä»Žå°‘é‡çš„è¿œç¨‹æ“ä½œæ¼”ç¤ºå¼€å§‹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å°†å…¶æ‰©å±•ä¸ºå¤§åž‹ã€å¤šæ ·åŒ–ã€é«˜è´¨é‡çš„æ•°æ®é›†ï¼Œè€Œæ— éœ€æ˜¾å¼çš„çŽ¯å¢ƒå»ºæ¨¡ã€‚å®žéªŒè¡¨æ˜Žï¼Œç”Ÿæˆçš„æ•°æ®èƒ½å¤ŸæŒç»­æ”¹è¿›ä¸‹æ¸¸ç­–ç•¥å­¦ä¹ ï¼Œåœ¨æ¨¡æ‹Ÿå™¨åŸºå‡†æµ‹è¯•ä¸­ç›¸å¯¹å¢žç›Šä¸º36.4%ï¼Œåœ¨çœŸå®žä¸–ç•Œç ”ç©¶ä¸­æ€§èƒ½å‡ ä¹Žç¿»å€ã€‚è¿™äº›ç»“æžœè¡¨æ˜Žï¼Œå°†ç”Ÿæˆä¸–ç•Œæ¨¡åž‹å»ºç«‹åœ¨æœºå™¨äººè¿åŠ¨çš„åŸºç¡€ä¸Šï¼Œä¸ºæ‰©å±•æ¨¡ä»¿å­¦ä¹ æä¾›äº†ä¸€æ¡åˆ‡å®žå¯è¡Œçš„é€”å¾„ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰æœºå™¨äººæ¨¡ä»¿å­¦ä¹ æ–¹æ³•é¢ä¸´æ•°æ®ç“¶é¢ˆï¼ŒçœŸå®žæ•°æ®é‡‡é›†æˆæœ¬é«˜ï¼Œä»¿çœŸæ•°æ®å­˜åœ¨â€œsim-to-realâ€å·®è·ã€‚ç”Ÿæˆæ¨¡åž‹è™½ç„¶æœ‰æ½œåŠ›ï¼Œä½†è¦ä¹ˆåªæ”¹å˜è§†è§‰æ•ˆæžœï¼Œè¦ä¹ˆäº§ç”Ÿä¸ç¬¦åˆæœºå™¨äººè¿åŠ¨å­¦è§„å¾‹çš„åŠ¨ä½œï¼Œç¼ºä¹å…·èº«æ„ŸçŸ¥èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šAnchorDreamçš„æ ¸å¿ƒåœ¨äºŽåˆ©ç”¨é¢„è®­ç»ƒçš„è§†é¢‘æ‰©æ•£æ¨¡åž‹ï¼Œå¹¶ä»¥æœºå™¨äººè¿åŠ¨æ¸²æŸ“ä½œä¸ºæ¡ä»¶ï¼ˆAnchorï¼‰æ¥å¼•å¯¼æ‰©æ•£è¿‡ç¨‹ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡åž‹å¯ä»¥ç”Ÿæˆä¸Žæœºå™¨äººè¿åŠ¨å­¦ä¸€è‡´çš„åœºæ™¯å’Œç‰©ä½“ï¼Œé¿å…å¹»è§‰ï¼Œä¿è¯åˆæˆæ•°æ®çš„åˆç†æ€§ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šAnchorDreamçš„æ•´ä½“æ¡†æž¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1) ä½¿ç”¨å°‘é‡äººå·¥é¥æ“ä½œæ•°æ®ä½œä¸ºç§å­ï¼›2) å°†æœºå™¨äººè¿åŠ¨ä¿¡æ¯æ¸²æŸ“æˆå›¾åƒåºåˆ—ï¼›3) å°†æ¸²æŸ“çš„å›¾åƒåºåˆ—ä½œä¸ºæ¡ä»¶è¾“å…¥åˆ°é¢„è®­ç»ƒçš„è§†é¢‘æ‰©æ•£æ¨¡åž‹ä¸­ï¼›4) è§†é¢‘æ‰©æ•£æ¨¡åž‹ç”Ÿæˆæ–°çš„è§†é¢‘åºåˆ—ï¼Œè¿™äº›åºåˆ—åŒ…å«ä¸Žæœºå™¨äººè¿åŠ¨ä¸€è‡´çš„åœºæ™¯å’Œç‰©ä½“ã€‚

**å…³é”®åˆ›æ–°**ï¼šAnchorDreamçš„å…³é”®åˆ›æ–°åœ¨äºŽå°†æœºå™¨äººè¿åŠ¨ä¿¡æ¯ä½œä¸ºâ€œé”šç‚¹â€èžå…¥åˆ°è§†é¢‘æ‰©æ•£æ¨¡åž‹ä¸­ï¼Œä»Žè€Œå®žçŽ°äº†å…·èº«æ„ŸçŸ¥çš„æœºå™¨äººæ•°æ®åˆæˆã€‚è¿™ä¸Žä»¥å¾€çš„ç”Ÿæˆæ¨¡åž‹åªå…³æ³¨è§†è§‰æ•ˆæžœæˆ–å¿½ç•¥æœºå™¨äººè¿åŠ¨å­¦çº¦æŸçš„æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šAnchorDreamçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨é¢„è®­ç»ƒçš„è§†é¢‘æ‰©æ•£æ¨¡åž‹ï¼Œé¿å…ä»Žå¤´è®­ç»ƒçš„æˆæœ¬ï¼›2) ç²¾å¿ƒè®¾è®¡çš„æœºå™¨äººè¿åŠ¨æ¸²æŸ“æ–¹å¼ï¼Œç¡®ä¿è¿åŠ¨ä¿¡æ¯èƒ½å¤Ÿæœ‰æ•ˆåœ°ä¼ é€’ç»™æ‰©æ•£æ¨¡åž‹ï¼›3) ä½¿ç”¨å¯¹æŠ—æ€§æŸå¤±å‡½æ•°æ¥æé«˜ç”Ÿæˆæ•°æ®çš„çœŸå®žæ„Ÿå’Œå¤šæ ·æ€§ï¼ˆå…·ä½“æŸå¤±å‡½æ•°ç»†èŠ‚è®ºæ–‡ä¸­å¯èƒ½åŒ…å«ï¼Œæ­¤å¤„æœªçŸ¥ï¼‰ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼Œä½¿ç”¨AnchorDreamç”Ÿæˆçš„æ•°æ®èƒ½å¤Ÿæ˜¾è‘—æå‡ä¸‹æ¸¸ç­–ç•¥å­¦ä¹ çš„æ€§èƒ½ã€‚åœ¨æ¨¡æ‹Ÿå™¨åŸºå‡†æµ‹è¯•ä¸­ï¼Œç›¸å¯¹å¢žç›Šè¾¾åˆ°36.4%ï¼Œè€Œåœ¨çœŸå®žä¸–ç•Œçš„ç ”ç©¶ä¸­ï¼Œæ€§èƒ½å‡ ä¹Žç¿»å€ã€‚è¿™äº›ç»“æžœéªŒè¯äº†AnchorDreamåœ¨æœºå™¨äººæ•°æ®åˆæˆæ–¹é¢çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

AnchorDreamåœ¨æœºå™¨äººæ¨¡ä»¿å­¦ä¹ é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯ä»¥ç”¨äºŽç”Ÿæˆå„ç§ä»»åŠ¡çš„è®­ç»ƒæ•°æ®ï¼Œä¾‹å¦‚ç‰©ä½“æŠ“å–ã€å¯¼èˆªã€è£…é…ç­‰ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿé™ä½Žæœºå™¨äººå­¦ä¹ çš„æˆæœ¬ï¼Œæé«˜å­¦ä¹ æ•ˆçŽ‡ï¼Œå¹¶æœ‰æœ›åŠ é€Ÿæœºå™¨äººæŠ€æœ¯åœ¨å·¥ä¸šã€åŒ»ç–—ã€æœåŠ¡ç­‰é¢†åŸŸçš„åº”ç”¨ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The collection of large-scale and diverse robot demonstrations remains a major bottleneck for imitation learning, as real-world data acquisition is costly and simulators offer limited diversity and fidelity with pronounced sim-to-real gaps. While generative models present an attractive solution, existing methods often alter only visual appearances without creating new behaviors, or suffer from embodiment inconsistencies that yield implausible motions. To address these limitations, we introduce AnchorDream, an embodiment-aware world model that repurposes pretrained video diffusion models for robot data synthesis. AnchorDream conditions the diffusion process on robot motion renderings, anchoring the embodiment to prevent hallucination while synthesizing objects and environments consistent with the robot's kinematics. Starting from only a handful of human teleoperation demonstrations, our method scales them into large, diverse, high-quality datasets without requiring explicit environment modeling. Experiments show that the generated data leads to consistent improvements in downstream policy learning, with relative gains of 36.4% in simulator benchmarks and nearly double performance in real-world studies. These results suggest that grounding generative world models in robot motion provides a practical path toward scaling imitation learning.

