---
layout: default
title: WholeBodyVLA: Towards Unified Latent VLA for Whole-Body Loco-Manipulation Control
---

# WholeBodyVLA: Towards Unified Latent VLA for Whole-Body Loco-Manipulation Control

**arXiv**: [2512.11047v2](https://arxiv.org/abs/2512.11047) | [PDF](https://arxiv.org/pdf/2512.11047.pdf)

**ä½œè€…**: Haoran Jiang, Jin Chen, Qingwen Bu, Li Chen, Modi Shi, Yanjie Zhang, Delong Li, Chuanzhe Suo, Chuang Wang, Zhihui Peng, Hongyang Li

**åˆ†ç±»**: cs.RO, cs.AI, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-11 (æ›´æ–°: 2025-12-15)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºWholeBodyVLAï¼Œå®žçŽ°åŸºäºŽç»Ÿä¸€éšç©ºé—´VLAçš„å¤§èŒƒå›´å…¨èº«Loco-ManipulationæŽ§åˆ¶**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `äººå½¢æœºå™¨äºº` `Loco-Manipulation` `è§†è§‰è¯­è¨€åŠ¨ä½œ` `å¼ºåŒ–å­¦ä¹ ` `éšç©ºé—´å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•åœ¨æ“ä½œæ„ŸçŸ¥çš„è¿åŠ¨æŽ§åˆ¶æ–¹é¢ä¸è¶³ï¼Œé™åˆ¶äº†äººå½¢æœºå™¨äººåœ¨å¤§èŒƒå›´åœºæ™¯ä¸‹çš„Loco-Manipulationèƒ½åŠ›ã€‚
2. æå‡ºWholeBodyVLAæ¡†æž¶ï¼Œåˆ©ç”¨ç»Ÿä¸€éšç©ºé—´å­¦ä¹ VLAç³»ç»Ÿï¼Œä»Žæ— åŠ¨ä½œè§†é¢‘ä¸­å­¦ä¹ ï¼Œå¹¶ç»“åˆLMO-RLç­–ç•¥æå‡è¿åŠ¨ç²¾åº¦ã€‚
3. åœ¨AgiBot X2ä¸Šå®žéªŒéªŒè¯ï¼ŒWholeBodyVLAæ€§èƒ½è¶…è¶ŠåŸºçº¿21.3%ï¼Œå±•çŽ°å‡ºè‰¯å¥½çš„æ³›åŒ–æ€§å’Œå¯æ‰©å±•æ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äººå½¢æœºå™¨äººéœ€è¦ç²¾ç¡®çš„è¿åŠ¨å’Œçµå·§çš„æ“ä½œæ¥æ‰§è¡Œå…·æœ‰æŒ‘æˆ˜æ€§çš„Loco-Manipulationä»»åŠ¡ã€‚ç„¶è€Œï¼ŒçŽ°æœ‰çš„æ¨¡å—åŒ–æˆ–ç«¯åˆ°ç«¯æ–¹æ³•åœ¨æ“ä½œæ„ŸçŸ¥çš„è¿åŠ¨æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œè¿™é™åˆ¶äº†æœºå™¨äººçš„å·¥ä½œç©ºé—´ï¼Œé˜»ç¢äº†å…¶æ‰§è¡Œå¤§èŒƒå›´çš„Loco-Manipulationä»»åŠ¡ã€‚æˆ‘ä»¬è®¤ä¸ºè¿™æ˜¯ç”±äºŽï¼š(1)ç¼ºä¹äººå½¢é¥æ“ä½œæ•°æ®å¯¼è‡´éš¾ä»¥èŽ·å–Loco-ManipulationçŸ¥è¯†ï¼›(2)çŽ°æœ‰RLæŽ§åˆ¶å™¨çš„ç²¾åº¦å’Œç¨³å®šæ€§æœ‰é™ï¼Œå¯¼è‡´éš¾ä»¥å¿ å®žå¯é åœ°æ‰§è¡Œè¿åŠ¨å‘½ä»¤ã€‚ä¸ºäº†èŽ·å–æ›´ä¸°å¯Œçš„Loco-ManipulationçŸ¥è¯†ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„éšç©ºé—´å­¦ä¹ æ¡†æž¶ï¼Œä½¿è§†è§‰-è¯­è¨€-åŠ¨ä½œ(VLA)ç³»ç»Ÿèƒ½å¤Ÿä»Žä½Žæˆæœ¬çš„æ— åŠ¨ä½œè‡ªæˆ‘ä¸­å¿ƒè§†é¢‘ä¸­å­¦ä¹ ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªé«˜æ•ˆçš„äººå·¥æ•°æ®æ”¶é›†æµç¨‹æ¥æ‰©å……æ•°æ®é›†å¹¶æ‰©å¤§æ”¶ç›Šã€‚ä¸ºäº†æ›´ç²¾ç¡®åœ°æ‰§è¡Œæ‰€éœ€çš„è¿åŠ¨å‘½ä»¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªä¸“é—¨ä¸ºç²¾ç¡®å’Œç¨³å®šçš„æ ¸å¿ƒLoco-Manipulationè¿åŠ¨ï¼ˆå¦‚å‰è¿›ã€è½¬å¼¯å’Œä¸‹è¹²ï¼‰é‡èº«å®šåˆ¶çš„é¢å‘Loco-Manipulation(LMO)çš„RLç­–ç•¥ã€‚åŸºäºŽè¿™äº›ç»„ä»¶ï¼Œæˆ‘ä»¬æŽ¨å‡ºäº†WholeBodyVLAï¼Œä¸€ä¸ªç”¨äºŽäººå½¢Loco-Manipulationçš„ç»Ÿä¸€æ¡†æž¶ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼ŒWholeBodyVLAæ˜¯åŒç±»äº§å“ä¸­é¦–ä¸ªå®žçŽ°å¤§èŒƒå›´äººå½¢Loco-Manipulationçš„æ¡†æž¶ã€‚é€šè¿‡åœ¨AgiBot X2äººå½¢æœºå™¨äººä¸Šçš„å…¨é¢å®žéªŒéªŒè¯ï¼Œå…¶æ€§èƒ½ä¼˜äºŽä¹‹å‰çš„åŸºçº¿21.3%ï¼Œå¹¶ä¸”åœ¨å¹¿æ³›çš„ä»»åŠ¡ä¸­è¡¨çŽ°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›å’Œé«˜åº¦çš„å¯æ‰©å±•æ€§ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰çš„äººå½¢æœºå™¨äººLoco-Manipulationæ–¹æ³•ï¼Œæ— è®ºæ˜¯æ¨¡å—åŒ–è¿˜æ˜¯ç«¯åˆ°ç«¯ï¼Œéƒ½ç¼ºä¹å¯¹æ“ä½œçš„æ„ŸçŸ¥ï¼Œå¯¼è‡´æœºå™¨äººéš¾ä»¥åœ¨è¾ƒå¤§çš„ç©ºé—´èŒƒå›´å†…å®Œæˆå¤æ‚çš„ä»»åŠ¡ã€‚ä¸»è¦ç—›ç‚¹åœ¨äºŽç¼ºä¹é«˜è´¨é‡çš„è®­ç»ƒæ•°æ®ï¼Œä»¥åŠçŽ°æœ‰å¼ºåŒ–å­¦ä¹ æŽ§åˆ¶å™¨åœ¨è¿åŠ¨æŽ§åˆ¶æ–¹é¢çš„ç²¾åº¦å’Œç¨³å®šæ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æž„å»ºä¸€ä¸ªç»Ÿä¸€çš„éšç©ºé—´å­¦ä¹ æ¡†æž¶ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿä»Žä½Žæˆæœ¬çš„ã€æ— åŠ¨ä½œçš„è‡ªæˆ‘ä¸­å¿ƒè§†é¢‘ä¸­å­¦ä¹ Loco-ManipulationçŸ¥è¯†ã€‚åŒæ—¶ï¼Œè®¾è®¡ä¸€ä¸ªé¢å‘Loco-Manipulationçš„å¼ºåŒ–å­¦ä¹ ç­–ç•¥ï¼Œä»¥æé«˜è¿åŠ¨æŽ§åˆ¶çš„ç²¾åº¦å’Œç¨³å®šæ€§ã€‚é€šè¿‡ç»“åˆè§†è§‰ã€è¯­è¨€å’ŒåŠ¨ä½œä¿¡æ¯ï¼Œå®žçŽ°æ›´æ™ºèƒ½ã€æ›´çµæ´»çš„å…¨èº«æŽ§åˆ¶ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šWholeBodyVLAæ¡†æž¶ä¸»è¦åŒ…å«ä¸¤ä¸ªæ ¸å¿ƒæ¨¡å—ï¼šä¸€æ˜¯åŸºäºŽè§†è§‰-è¯­è¨€-åŠ¨ä½œ(VLA)çš„éšç©ºé—´å­¦ä¹ æ¨¡å—ï¼Œç”¨äºŽä»Žæ— åŠ¨ä½œè§†é¢‘ä¸­å­¦ä¹ Loco-ManipulationçŸ¥è¯†ï¼›äºŒæ˜¯é¢å‘Loco-Manipulation(LMO)çš„å¼ºåŒ–å­¦ä¹ ç­–ç•¥ï¼Œç”¨äºŽç²¾ç¡®æŽ§åˆ¶æœºå™¨äººçš„è¿åŠ¨ã€‚æ•´ä¸ªæµç¨‹åŒ…æ‹¬æ•°æ®æ”¶é›†ã€éšç©ºé—´å­¦ä¹ ã€ç­–ç•¥è®­ç»ƒå’Œè¿åŠ¨æŽ§åˆ¶å››ä¸ªé˜¶æ®µã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽæå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„éšç©ºé—´å­¦ä¹ æ¡†æž¶ï¼Œèƒ½å¤Ÿä»Žä½Žæˆæœ¬çš„æ— åŠ¨ä½œè§†é¢‘ä¸­å­¦ä¹ Loco-ManipulationçŸ¥è¯†ï¼Œä»Žè€Œå…‹æœäº†æ•°æ®ç¨€ç¼ºçš„é—®é¢˜ã€‚æ­¤å¤–ï¼ŒLMO-RLç­–ç•¥çš„è®¾è®¡ä¹Ÿé’ˆå¯¹æ€§åœ°æé«˜äº†è¿åŠ¨æŽ§åˆ¶çš„ç²¾åº¦å’Œç¨³å®šæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šVLAæ¨¡å—ä½¿ç”¨è‡ªç¼–ç å™¨ç»“æž„å­¦ä¹ è§†è§‰å’Œè¯­è¨€ä¿¡æ¯çš„è”åˆéšç©ºé—´è¡¨ç¤ºã€‚LMO-RLç­–ç•¥é‡‡ç”¨Actor-Criticæž¶æž„ï¼Œå¥–åŠ±å‡½æ•°çš„è®¾è®¡ä¾§é‡äºŽè¿åŠ¨çš„ç²¾ç¡®æ€§å’Œç¨³å®šæ€§ï¼Œä¾‹å¦‚ï¼Œå¯¹å‰è¿›ã€è½¬å¼¯å’Œä¸‹è¹²ç­‰æ ¸å¿ƒåŠ¨ä½œè¿›è¡Œç²¾ç»†çš„å¥–åŠ±å¡‘é€ ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æž„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒWholeBodyVLAåœ¨AgiBot X2äººå½¢æœºå™¨äººä¸Šçš„æ€§èƒ½ä¼˜äºŽä¹‹å‰çš„åŸºçº¿21.3%ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æž¶åœ¨ä¸åŒçš„ä»»åŠ¡ä¸­è¡¨çŽ°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›å’Œé«˜åº¦çš„å¯æ‰©å±•æ€§ï¼Œè¯æ˜Žäº†å…¶åœ¨å®žé™…åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚è¿™äº›ç»“æžœéªŒè¯äº†æ‰€æå‡ºæ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽäººå½¢æœºå™¨äººåœ¨å¤æ‚çŽ¯å¢ƒä¸‹çš„è‡ªä¸»æ“ä½œï¼Œä¾‹å¦‚å®¶åº­æœåŠ¡ã€ç‰©æµé…é€ã€ç¾éš¾æ•‘æ´ç­‰ã€‚é€šè¿‡å­¦ä¹ äººç±»çš„åŠ¨ä½œå’Œè¡Œä¸ºæ¨¡å¼ï¼Œæœºå™¨äººèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£çŽ¯å¢ƒï¼Œæ‰§è¡Œå„ç§ä»»åŠ¡ï¼Œæé«˜å·¥ä½œæ•ˆçŽ‡å’Œå®‰å…¨æ€§ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›æŽ¨åŠ¨äººå½¢æœºå™¨äººåœ¨æ›´å¹¿æ³›é¢†åŸŸçš„åº”ç”¨ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Humanoid robots require precise locomotion and dexterous manipulation to perform challenging loco-manipulation tasks. Yet existing approaches, modular or end-to-end, are deficient in manipulation-aware locomotion. This confines the robot to a limited workspace, preventing it from performing large-space loco-manipulation. We attribute this to: (1) the challenge of acquiring loco-manipulation knowledge due to the scarcity of humanoid teleoperation data, and (2) the difficulty of faithfully and reliably executing locomotion commands, stemming from the limited precision and stability of existing RL controllers. To acquire richer loco-manipulation knowledge, we propose a unified latent learning framework that enables Vision-Language-Action (VLA) system to learn from low-cost action-free egocentric videos. Moreover, an efficient human data collection pipeline is devised to augment the dataset and scale the benefits. To execute the desired locomotion commands more precisely, we present a loco-manipulation-oriented (LMO) RL policy specifically tailored for accurate and stable core loco-manipulation movements, such as advancing, turning, and squatting. Building on these components, we introduce WholeBodyVLA, a unified framework for humanoid loco-manipulation. To the best of our knowledge, WholeBodyVLA is one of its kind enabling large-space humanoid loco-manipulation. It is verified via comprehensive experiments on the AgiBot X2 humanoid, outperforming prior baseline by 21.3%. It also demonstrates strong generalization and high extensibility across a broad range of tasks.

