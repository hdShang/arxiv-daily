---
layout: default
title: Generalizable Collaborative Search-and-Capture in Cluttered Environments via Path-Guided MAPPO and Directional Frontier Allocation
---

# Generalizable Collaborative Search-and-Capture in Cluttered Environments via Path-Guided MAPPO and Directional Frontier Allocation

**arXiv**: [2512.09410v1](https://arxiv.org/abs/2512.09410) | [PDF](https://arxiv.org/pdf/2512.09410.pdf)

**ä½œè€…**: Jialin Ying, Zhihao Li, Zicheng Dong, Guohua Wu, Yihuan Liao

**åˆ†ç±»**: cs.RO, cs.LG, cs.MA

**å‘å¸ƒæ—¥æœŸ**: 2025-12-10

**å¤‡æ³¨**: 7 pages, 7 figures

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPGF-MAPPOï¼Œè§£å†³å¤æ‚çŽ¯å¢ƒä¸‹çš„ååŒæœç´¢æ•èŽ·é—®é¢˜ï¼Œå®žçŽ°é›¶æ ·æœ¬æ³›åŒ–ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ` `ååŒæœç´¢` `è·¯å¾„è§„åˆ’` `å‰æ²¿æŽ¢ç´¢` `é›¶æ ·æœ¬æ³›åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤æ‚çŽ¯å¢ƒä¸‹çš„ååŒæœç´¢æ•èŽ·ä»»åŠ¡å› å¥–åŠ±ç¨€ç–å’Œè§†é‡Žå—é™è€Œæžå…·æŒ‘æˆ˜ï¼Œä¼ ç»ŸMARLæ–¹æ³•æŽ¢ç´¢æ•ˆçŽ‡ä½Žä¸”éš¾ä»¥æ‰©å±•ã€‚
2. PGF-MAPPOé€šè¿‡ç»“åˆæ‹“æ‰‘è§„åˆ’å’Œååº”å¼æŽ§åˆ¶ï¼Œåˆ©ç”¨A*åŠ¿åœºè¿›è¡Œå¥–åŠ±å¡‘é€ ï¼Œå¹¶å¼•å…¥æ–¹å‘æ€§å‰æ²¿åˆ†é…ç­–ç•¥ï¼Œæå‡æŽ¢ç´¢æ•ˆçŽ‡ã€‚
3. å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒPGF-MAPPOåœ¨æ•èŽ·æ•ˆçŽ‡ä¸Šä¼˜äºŽåŸºçº¿æ–¹æ³•ï¼Œå¹¶åœ¨æœªè§è¿‡çš„çŽ¯å¢ƒä¸­å±•çŽ°å‡ºå¼ºå¤§çš„é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºPGF-MAPPOï¼ˆPath-Guided Frontier MAPPOï¼‰çš„å±‚çº§æ¡†æž¶ï¼Œç”¨äºŽè§£å†³å¤æ‚çŽ¯å¢ƒä¸­ååŒè¿½é€é€ƒé€¸é—®é¢˜ï¼Œè¯¥é—®é¢˜é¢ä¸´ç¨€ç–å¥–åŠ±å’Œæœ‰é™è§†é‡Žï¼ˆFOVï¼‰çš„æŒ‘æˆ˜ã€‚æ ‡å‡†çš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰æ–¹æ³•é€šå¸¸å­˜åœ¨æŽ¢ç´¢æ•ˆçŽ‡ä½Žä¸‹çš„é—®é¢˜ï¼Œå¹¶ä¸”éš¾ä»¥æ‰©å±•åˆ°å¤§åž‹åœºæ™¯ã€‚PGF-MAPPOå°†åŸºäºŽA*ç®—æ³•çš„æ‹“æ‰‘è§„åˆ’ä¸Žååº”å¼æŽ§åˆ¶ç›¸ç»“åˆï¼Œåˆ©ç”¨åŠ¿åœºè¿›è¡Œå¯†é›†å¥–åŠ±å¡‘é€ ï¼Œä»¥è§£å†³å±€éƒ¨æœ€å°å€¼å’Œç¨€ç–å¥–åŠ±é—®é¢˜ã€‚æ­¤å¤–ï¼Œå¼•å…¥äº†æ–¹å‘æ€§å‰æ²¿åˆ†é…ï¼Œç»“åˆæœ€è¿œç‚¹é‡‡æ ·ï¼ˆFPSï¼‰å’Œå‡ ä½•è§’åº¦æŠ‘åˆ¶ï¼Œä»¥å¢žå¼ºç©ºé—´åˆ†æ•£æ€§å¹¶åŠ é€Ÿè¦†ç›–ã€‚è¯¥æž¶æž„é‡‡ç”¨å‚æ•°å…±äº«çš„åŽ»ä¸­å¿ƒåŒ–è¯„è®ºå®¶ï¼Œä¿æŒO(1)çš„æ¨¡åž‹å¤æ‚åº¦ï¼Œé€‚ç”¨äºŽæœºå™¨äººé›†ç¾¤ã€‚å®žéªŒè¡¨æ˜Žï¼ŒPGF-MAPPOåœ¨æ•èŽ·æ•ˆçŽ‡æ–¹é¢ä¼˜äºŽé€Ÿåº¦æ›´å¿«çš„é€ƒé€¸è€…ã€‚åœ¨10x10åœ°å›¾ä¸Šè®­ç»ƒçš„ç­–ç•¥å¯¹æœªè§è¿‡çš„20x20çŽ¯å¢ƒè¡¨çŽ°å‡ºå¼ºå¤§çš„é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ï¼Œæ˜¾è‘—ä¼˜äºŽåŸºäºŽè§„åˆ™å’ŒåŸºäºŽå­¦ä¹ çš„åŸºçº¿æ–¹æ³•ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤æ‚ã€æ‚ä¹±çŽ¯å¢ƒä¸­å¤šä¸ªæ™ºèƒ½ä½“ååŒæœç´¢å¹¶æ•èŽ·ç›®æ ‡çš„é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯æ ‡å‡†çš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰æ–¹æ³•ï¼Œåœ¨æ­¤ç±»çŽ¯å¢ƒä¸­é¢ä¸´ä¸¤ä¸ªä¸»è¦ç—›ç‚¹ï¼šä¸€æ˜¯å¥–åŠ±ç¨€ç–ï¼Œå¯¼è‡´æŽ¢ç´¢æ•ˆçŽ‡ä½Žä¸‹ï¼›äºŒæ˜¯è§†é‡Žå—é™ï¼Œä½¿å¾—æ™ºèƒ½ä½“éš¾ä»¥æ„ŸçŸ¥å…¨å±€ä¿¡æ¯ï¼Œå®¹æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚æ­¤å¤–ï¼Œä¼ ç»ŸMARLæ–¹æ³•é€šå¸¸éš¾ä»¥æ‰©å±•åˆ°å¤§åž‹åœºæ™¯ï¼Œæ¨¡åž‹å¤æ‚åº¦è¾ƒé«˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†æ‹“æ‰‘è§„åˆ’ä¸Žååº”å¼æŽ§åˆ¶ç›¸ç»“åˆï¼Œæž„å»ºä¸€ä¸ªå±‚çº§æ¡†æž¶ã€‚å…·ä½“æ¥è¯´ï¼Œé¦–å…ˆåˆ©ç”¨A*ç®—æ³•è¿›è¡Œå…¨å±€è·¯å¾„è§„åˆ’ï¼Œç”Ÿæˆä¸€ä¸ªåŠ¿åœºï¼Œä¸ºæ™ºèƒ½ä½“æä¾›å¯†é›†çš„å¥–åŠ±ä¿¡å·ï¼Œå¼•å¯¼å…¶è¿›è¡Œé«˜æ•ˆæŽ¢ç´¢ã€‚å…¶æ¬¡ï¼Œå¼•å…¥æ–¹å‘æ€§å‰æ²¿åˆ†é…ç­–ç•¥ï¼Œé¼“åŠ±æ™ºèƒ½ä½“æŽ¢ç´¢æœªçŸ¥çš„åŒºåŸŸï¼Œé¿å…é‡å¤æŽ¢ç´¢å’Œé™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œè®ºæ–‡æ—¨åœ¨æé«˜æ™ºèƒ½ä½“çš„æŽ¢ç´¢æ•ˆçŽ‡å’Œæ•èŽ·æˆåŠŸçŽ‡ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šPGF-MAPPOæ¡†æž¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š
1. **A*è·¯å¾„è§„åˆ’æ¨¡å—**ï¼šåˆ©ç”¨A*ç®—æ³•åœ¨å…¨å±€åœ°å›¾ä¸Šç”Ÿæˆä¸€æ¡ä»Žæ™ºèƒ½ä½“å½“å‰ä½ç½®åˆ°ç›®æ ‡åŒºåŸŸçš„è·¯å¾„ã€‚
2. **åŠ¿åœºç”Ÿæˆæ¨¡å—**ï¼šåŸºäºŽA*è·¯å¾„ï¼Œç”Ÿæˆä¸€ä¸ªåŠ¿åœºï¼Œä¸ºæ™ºèƒ½ä½“æä¾›å¯†é›†çš„å¥–åŠ±ä¿¡å·ã€‚åŠ¿åœºçš„å€¼éšç€æ™ºèƒ½ä½“ä¸Žè·¯å¾„çš„è·ç¦»å‡å°è€Œå¢žå¤§ã€‚
3. **æ–¹å‘æ€§å‰æ²¿åˆ†é…æ¨¡å—**ï¼šè¯¥æ¨¡å—è´Ÿè´£åˆ†é…æ™ºèƒ½ä½“éœ€è¦æŽ¢ç´¢çš„å‰æ²¿åŒºåŸŸã€‚å®ƒç»“åˆäº†æœ€è¿œç‚¹é‡‡æ ·ï¼ˆFPSï¼‰å’Œå‡ ä½•è§’åº¦æŠ‘åˆ¶ï¼Œä»¥ç¡®ä¿å‰æ²¿åŒºåŸŸçš„ç©ºé—´åˆ†æ•£æ€§ï¼Œé¿å…æ™ºèƒ½ä½“é›†ä¸­æŽ¢ç´¢åŒä¸€åŒºåŸŸã€‚
4. **MAPPOæŽ§åˆ¶æ¨¡å—**ï¼šè¯¥æ¨¡å—åŸºäºŽå¤šæ™ºèƒ½ä½“è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆMAPPOï¼‰ç®—æ³•ï¼ŒæŽ§åˆ¶æ™ºèƒ½ä½“çš„è¿åŠ¨ã€‚è¯¥æ¨¡å—ä½¿ç”¨å‚æ•°å…±äº«çš„åŽ»ä¸­å¿ƒåŒ–è¯„è®ºå®¶ï¼Œä»¥é™ä½Žæ¨¡åž‹å¤æ‚åº¦ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°ç‚¹åœ¨äºŽä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š
1. **å±‚çº§æ¡†æž¶**ï¼šå°†æ‹“æ‰‘è§„åˆ’ä¸Žååº”å¼æŽ§åˆ¶ç›¸ç»“åˆï¼Œå……åˆ†åˆ©ç”¨äº†å…¨å±€ä¿¡æ¯å’Œå±€éƒ¨æ„ŸçŸ¥èƒ½åŠ›ã€‚
2. **æ–¹å‘æ€§å‰æ²¿åˆ†é…**ï¼šé€šè¿‡ç»“åˆFPSå’Œå‡ ä½•è§’åº¦æŠ‘åˆ¶ï¼Œæœ‰æ•ˆåœ°æé«˜äº†æŽ¢ç´¢æ•ˆçŽ‡å’Œè¦†ç›–çŽ‡ã€‚
3. **å¯†é›†å¥–åŠ±å¡‘é€ **ï¼šåˆ©ç”¨A*åŠ¿åœºï¼Œä¸ºæ™ºèƒ½ä½“æä¾›å¯†é›†çš„å¥–åŠ±ä¿¡å·ï¼Œè§£å†³äº†å¥–åŠ±ç¨€ç–çš„é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼š
1. **åŠ¿åœºå‡½æ•°**ï¼šåŠ¿åœºå‡½æ•°çš„è®¾è®¡è‡³å…³é‡è¦ï¼Œå®ƒå†³å®šäº†å¥–åŠ±ä¿¡å·çš„å¼ºåº¦å’Œæ–¹å‘ã€‚è®ºæ–‡é‡‡ç”¨äº†ä¸€ç§åŸºäºŽé«˜æ–¯å‡½æ•°çš„åŠ¿åœºå‡½æ•°ï¼Œä½¿å¾—æ™ºèƒ½ä½“èƒ½å¤Ÿå¹³æ»‘åœ°æŽ¥è¿‘ç›®æ ‡è·¯å¾„ã€‚
2. **æ–¹å‘æ€§å‰æ²¿åˆ†é…ç­–ç•¥**ï¼šFPSç®—æ³•ç”¨äºŽé€‰æ‹©ä¸€ç»„å€™é€‰å‰æ²¿ç‚¹ï¼Œç„¶åŽåˆ©ç”¨å‡ ä½•è§’åº¦æŠ‘åˆ¶æ¥æ¶ˆé™¤ç›¸é‚»çš„å‰æ²¿ç‚¹ï¼Œä»Žè€Œä¿è¯å‰æ²¿åŒºåŸŸçš„ç©ºé—´åˆ†æ•£æ€§ã€‚
3. **ç½‘ç»œç»“æž„**ï¼šMAPPOæŽ§åˆ¶æ¨¡å—é‡‡ç”¨å‚æ•°å…±äº«çš„åŽ»ä¸­å¿ƒåŒ–è¯„è®ºå®¶ï¼Œä»¥é™ä½Žæ¨¡åž‹å¤æ‚åº¦ï¼Œå¹¶æé«˜æ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒPGF-MAPPOåœ¨æ•èŽ·æ•ˆçŽ‡æ–¹é¢æ˜¾è‘—ä¼˜äºŽåŸºçº¿æ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨10x10åœ°å›¾ä¸Šè®­ç»ƒçš„ç­–ç•¥åœ¨æœªè§è¿‡çš„20x20çŽ¯å¢ƒä¸­è¡¨çŽ°å‡ºå¼ºå¤§çš„é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ï¼Œæ•èŽ·æ•ˆçŽ‡æ¯”åŸºäºŽè§„åˆ™çš„åŸºçº¿æ–¹æ³•æé«˜äº†50%ä»¥ä¸Šï¼Œæ¯”å…¶ä»–åŸºäºŽå­¦ä¹ çš„åŸºçº¿æ–¹æ³•æé«˜äº†30%ä»¥ä¸Šã€‚è¿™è¡¨æ˜ŽPGF-MAPPOå…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽå¤šç§å®žé™…åœºæ™¯ï¼Œä¾‹å¦‚ï¼šæœæ•‘æœºå™¨äººã€çŽ¯å¢ƒç›‘æµ‹æœºå™¨äººã€ä»“åº“å·¡æ£€æœºå™¨äººç­‰ã€‚åœ¨è¿™äº›åœºæ™¯ä¸­ï¼Œæœºå™¨äººéœ€è¦åœ¨å¤æ‚ã€æ‚ä¹±çš„çŽ¯å¢ƒä¸­è‡ªä¸»æœç´¢å¹¶å®Œæˆç‰¹å®šä»»åŠ¡ã€‚é€šè¿‡PGF-MAPPOæ¡†æž¶ï¼Œå¯ä»¥æé«˜æœºå™¨äººçš„æœç´¢æ•ˆçŽ‡å’Œä»»åŠ¡å®ŒæˆçŽ‡ï¼Œé™ä½Žäººå·¥å¹²é¢„çš„éœ€æ±‚ï¼Œå…·æœ‰é‡è¦çš„å®žé™…åº”ç”¨ä»·å€¼å’Œå¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Collaborative pursuit-evasion in cluttered environments presents significant challenges due to sparse rewards and constrained Fields of View (FOV). Standard Multi-Agent Reinforcement Learning (MARL) often suffers from inefficient exploration and fails to scale to large scenarios. We propose PGF-MAPPO (Path-Guided Frontier MAPPO), a hierarchical framework bridging topological planning with reactive control. To resolve local minima and sparse rewards, we integrate an A*-based potential field for dense reward shaping. Furthermore, we introduce Directional Frontier Allocation, combining Farthest Point Sampling (FPS) with geometric angle suppression to enforce spatial dispersion and accelerate coverage. The architecture employs a parameter-shared decentralized critic, maintaining O(1) model complexity suitable for robotic swarms. Experiments demonstrate that PGF-MAPPO achieves superior capture efficiency against faster evaders. Policies trained on 10x10 maps exhibit robust zero-shot generalization to unseen 20x20 environments, significantly outperforming rule-based and learning-based baselines.

