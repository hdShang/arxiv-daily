---
layout: default
title: CRAFT-E: A Neuro-Symbolic Framework for Embodied Affordance Grounding
---

# CRAFT-E: A Neuro-Symbolic Framework for Embodied Affordance Grounding

**arXiv**: [2512.04231v1](https://arxiv.org/abs/2512.04231) | [PDF](https://arxiv.org/pdf/2512.04231.pdf)

**ä½œè€…**: Zhou Chen, Joe Lin, Carson Bulgin, Sathyanarayanan N. Aakur

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-03

**å¤‡æ³¨**: 20 pages. 3 figures, 4 tables. Under Review

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**CRAFT-Eï¼šç”¨äºŽå…·èº«å¯ä¾›æ€§æŽ¥åœ°çš„ç¥žç»ç¬¦å·æ¡†æž¶**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `å…·èº«æ™ºèƒ½` `å¯ä¾›æ€§` `ç¥žç»ç¬¦å·` `çŸ¥è¯†å›¾è°±` `æœºå™¨äºº` `è§†è§‰è¯­è¨€å¯¹é½` `æŠ“å–æŽ¨ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•ä¾èµ–é»‘ç›’æ¨¡åž‹æˆ–å›ºå®šæ ‡ç­¾ï¼Œç¼ºä¹é€æ˜Žæ€§å’Œå¯æŽ§æ€§ï¼Œéš¾ä»¥æ»¡è¶³äººæœºäº¤äº’åº”ç”¨çš„éœ€æ±‚ã€‚
2. CRAFT-Eç»“åˆçŸ¥è¯†å›¾è°±ã€è§†è§‰è¯­è¨€å¯¹é½å’Œèƒ½é‡æ¨¡åž‹ï¼Œç”Ÿæˆå¯è§£é‡Šçš„æŽ¨ç†è·¯å¾„ï¼Œå¹¶è€ƒè™‘æŠ“å–å¯è¡Œæ€§ã€‚
3. CRAFT-Eåœ¨é™æ€åœºæ™¯å’ŒçœŸå®žæœºå™¨äººå®žéªŒä¸­è¡¨çŽ°å‡ºè‰²ï¼Œä¸”åœ¨æ„ŸçŸ¥å™ªå£°ä¸‹ä¿æŒé²æ£’æ€§ï¼Œæä¾›ç»„ä»¶çº§è¯Šæ–­ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨éžç»“æž„åŒ–çŽ¯å¢ƒä¸­è¿è¡Œçš„è¾…åŠ©æœºå™¨äººä¸ä»…éœ€è¦ç†è§£ç‰©ä½“æ˜¯ä»€ä¹ˆï¼Œè¿˜éœ€è¦ç†è§£å®ƒä»¬å¯ä»¥ç”¨æ¥åšä»€ä¹ˆã€‚è¿™éœ€è¦å°†åŸºäºŽè¯­è¨€çš„åŠ¨ä½œæŸ¥è¯¢ä¸Žæ—¢èƒ½æä¾›æ‰€éœ€åŠŸèƒ½åˆèƒ½è¢«ç‰©ç†æ£€ç´¢çš„ç‰©ä½“è¿›è¡Œå…³è”ã€‚çŽ°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºŽé»‘ç›’æ¨¡åž‹æˆ–å›ºå®šçš„å¯ä¾›æ€§æ ‡ç­¾ï¼Œé™åˆ¶äº†é¢å‘äººç±»åº”ç”¨çš„é€æ˜Žæ€§ã€å¯æŽ§æ€§å’Œå¯é æ€§ã€‚æˆ‘ä»¬å¼•å…¥äº†CRAFT-Eï¼Œä¸€ä¸ªæ¨¡å—åŒ–çš„ç¥žç»ç¬¦å·æ¡†æž¶ï¼Œå®ƒå°†ç»“æž„åŒ–çš„åŠ¨è¯-å±žæ€§-å¯¹è±¡çŸ¥è¯†å›¾ä¸Žè§†è§‰-è¯­è¨€å¯¹é½å’ŒåŸºäºŽèƒ½é‡çš„æŠ“å–æŽ¨ç†ç›¸ç»“åˆã€‚è¯¥ç³»ç»Ÿç”Ÿæˆå¯è§£é‡Šçš„æŽ¥åœ°è·¯å¾„ï¼Œæ­ç¤ºå½±å“ç‰©ä½“é€‰æ‹©çš„å› ç´ ï¼Œå¹¶å°†æŠ“å–å¯è¡Œæ€§ä½œä¸ºå¯ä¾›æ€§æŽ¨ç†çš„ä¸€ä¸ªç»„æˆéƒ¨åˆ†ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥æž„å»ºäº†ä¸€ä¸ªåŸºå‡†æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«åŠ¨è¯-å¯¹è±¡å…¼å®¹æ€§ã€åˆ†å‰²å’ŒæŠ“å–å€™é€‰çš„ç»Ÿä¸€æ³¨é‡Šï¼Œå¹¶åœ¨ç‰©ç†æœºå™¨äººä¸Šéƒ¨ç½²äº†å®Œæ•´çš„pipelineã€‚CRAFT-Eåœ¨é™æ€åœºæ™¯ã€åŸºäºŽImageNetçš„åŠŸèƒ½æ£€ç´¢ä»¥åŠæ¶‰åŠ20ä¸ªåŠ¨è¯å’Œ39ä¸ªç‰©ä½“çš„çœŸå®žä¸–ç•Œè¯•éªŒä¸­å–å¾—äº†æœ‰ç«žäº‰åŠ›çš„æ€§èƒ½ã€‚è¯¥æ¡†æž¶åœ¨æ„ŸçŸ¥å™ªå£°ä¸‹ä¿æŒç¨³å¥ï¼Œå¹¶æä¾›é€æ˜Žçš„ç»„ä»¶çº§è¯Šæ–­ã€‚é€šè¿‡å°†ç¬¦å·æŽ¨ç†ä¸Žå…·èº«æ„ŸçŸ¥ç›¸ç»“åˆï¼ŒCRAFT-Eä¸ºå¯ä¾›æ€§æŽ¥åœ°çš„ç‰©ä½“é€‰æ‹©æä¾›äº†ä¸€ç§å¯è§£é‡Šå’Œå¯å®šåˆ¶çš„æ›¿ä»£æ–¹æ¡ˆï¼Œæ”¯æŒè¾…åŠ©æœºå™¨äººç³»ç»Ÿä¸­å€¼å¾—ä¿¡èµ–çš„å†³ç­–ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è¾…åŠ©æœºå™¨äººå¦‚ä½•åœ¨éžç»“æž„åŒ–çŽ¯å¢ƒä¸­ç†è§£ç‰©ä½“çš„åŠŸèƒ½ï¼ˆå¯ä¾›æ€§ï¼‰ï¼Œå¹¶æ ¹æ®è¯­è¨€æŒ‡ä»¤é€‰æ‹©åˆé€‚çš„ç‰©ä½“è¿›è¡Œæ“ä½œçš„é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•çš„ç—›ç‚¹åœ¨äºŽä¾èµ–é»‘ç›’æ¨¡åž‹æˆ–é¢„å®šä¹‰çš„å¯ä¾›æ€§æ ‡ç­¾ï¼Œç¼ºä¹é€æ˜Žæ€§å’Œå¯è§£é‡Šæ€§ï¼Œéš¾ä»¥è°ƒè¯•å’Œä¿¡ä»»ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†ç¥žç»æ–¹æ³•å’Œç¬¦å·æŽ¨ç†ç›¸ç»“åˆï¼Œæž„å»ºä¸€ä¸ªæ¨¡å—åŒ–çš„ç¥žç»ç¬¦å·æ¡†æž¶ã€‚é€šè¿‡çŸ¥è¯†å›¾è°±æ¥è¡¨ç¤ºç‰©ä½“ã€å±žæ€§å’ŒåŠ¨ä½œä¹‹é—´çš„å…³ç³»ï¼Œåˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡åž‹å°†è¯­è¨€æŒ‡ä»¤ä¸Žè§†è§‰ä¿¡æ¯å¯¹é½ï¼Œå¹¶ä½¿ç”¨èƒ½é‡æ¨¡åž‹æ¥è¯„ä¼°æŠ“å–çš„å¯è¡Œæ€§ã€‚è¿™æ ·å¯ä»¥ç”Ÿæˆå¯è§£é‡Šçš„æŽ¨ç†è·¯å¾„ï¼Œä»Žè€Œæé«˜ç³»ç»Ÿçš„é€æ˜Žæ€§å’Œå¯æŽ§æ€§ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šCRAFT-Eæ¡†æž¶åŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) çŸ¥è¯†å›¾è°±ï¼šå­˜å‚¨åŠ¨è¯ã€å±žæ€§å’Œå¯¹è±¡ä¹‹é—´çš„å…³ç³»ã€‚2) è§†è§‰è¯­è¨€å¯¹é½æ¨¡å—ï¼šå°†è¯­è¨€æŒ‡ä»¤ä¸­çš„åŠ¨è¯å’Œå¯¹è±¡ä¸Žå›¾åƒä¸­çš„è§†è§‰ä¿¡æ¯å¯¹é½ã€‚3) èƒ½é‡æ¨¡åž‹ï¼šè¯„ä¼°æŠ“å–å€™é€‰çš„è´¨é‡å’Œå¯è¡Œæ€§ã€‚4) æŽ¨ç†å¼•æ“Žï¼šæ ¹æ®çŸ¥è¯†å›¾è°±ã€è§†è§‰è¯­è¨€å¯¹é½ç»“æžœå’ŒæŠ“å–å¯è¡Œæ€§ï¼Œç”Ÿæˆå¯è§£é‡Šçš„æŽ¥åœ°è·¯å¾„ï¼Œé€‰æ‹©æœ€ä½³ç‰©ä½“ã€‚

**å…³é”®åˆ›æ–°**ï¼šCRAFT-Eçš„å…³é”®åˆ›æ–°åœ¨äºŽå°†ç¬¦å·æŽ¨ç†ä¸Žå…·èº«æ„ŸçŸ¥ç›¸ç»“åˆï¼Œæž„å»ºäº†ä¸€ä¸ªå¯è§£é‡Šçš„ç¥žç»ç¬¦å·æ¡†æž¶ã€‚ä¸Žç«¯åˆ°ç«¯æ¨¡åž‹ç›¸æ¯”ï¼ŒCRAFT-Eçš„æŽ¨ç†è¿‡ç¨‹æ›´åŠ é€æ˜Žï¼Œå¯ä»¥è¿›è¡Œç»„ä»¶çº§çš„è¯Šæ–­å’Œè°ƒè¯•ã€‚æ­¤å¤–ï¼ŒCRAFT-Eå°†æŠ“å–å¯è¡Œæ€§ä½œä¸ºå¯ä¾›æ€§æŽ¨ç†çš„ä¸€ä¸ªç»„æˆéƒ¨åˆ†ï¼Œæé«˜äº†ç‰©ä½“é€‰æ‹©çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šCRAFT-Eä½¿ç”¨é¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€æ¨¡åž‹ï¼ˆå¦‚CLIPï¼‰è¿›è¡Œè§†è§‰è¯­è¨€å¯¹é½ã€‚èƒ½é‡æ¨¡åž‹é‡‡ç”¨åŸºäºŽèƒ½é‡çš„æ¡†æž¶ï¼Œé€šè¿‡å­¦ä¹ èƒ½é‡å‡½æ•°æ¥è¯„ä¼°æŠ“å–å€™é€‰çš„è´¨é‡ã€‚çŸ¥è¯†å›¾è°±é‡‡ç”¨äººå·¥æž„å»ºçš„æ–¹å¼ï¼Œå¹¶æ ¹æ®å…·ä½“ä»»åŠ¡è¿›è¡Œæ‰©å±•ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬è§†è§‰è¯­è¨€å¯¹é½æŸå¤±å’ŒæŠ“å–èƒ½é‡æŸå¤±ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

CRAFT-Eåœ¨é™æ€åœºæ™¯ã€ImageNet-basedåŠŸèƒ½æ£€ç´¢å’ŒçœŸå®žä¸–ç•Œæœºå™¨äººå®žéªŒä¸­å–å¾—äº†æœ‰ç«žäº‰åŠ›çš„æ€§èƒ½ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒCRAFT-Eåœ¨æ„ŸçŸ¥å™ªå£°ä¸‹ä¿æŒé²æ£’æ€§ï¼Œå¹¶èƒ½å¤Ÿæä¾›é€æ˜Žçš„ç»„ä»¶çº§è¯Šæ–­ã€‚åœ¨çœŸå®žæœºå™¨äººå®žéªŒä¸­ï¼ŒCRAFT-EæˆåŠŸåœ°å®Œæˆäº†æ¶‰åŠ20ä¸ªåŠ¨è¯å’Œ39ä¸ªç‰©ä½“çš„ä»»åŠ¡ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

CRAFT-Eå¯åº”ç”¨äºŽè¾…åŠ©æœºå™¨äººã€æ™ºèƒ½å®¶å±…ã€å·¥ä¸šè‡ªåŠ¨åŒ–ç­‰é¢†åŸŸã€‚å®ƒå¯ä»¥å¸®åŠ©æœºå™¨äººç†è§£äººç±»çš„æŒ‡ä»¤ï¼Œé€‰æ‹©åˆé€‚çš„å·¥å…·å’Œç‰©ä½“è¿›è¡Œæ“ä½œï¼Œä»Žè€Œæé«˜æœºå™¨äººçš„è‡ªä¸»æ€§å’Œæ™ºèƒ½åŒ–æ°´å¹³ã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºŽæž„å»ºæ›´å€¼å¾—ä¿¡èµ–ã€æ›´æ˜“äºŽç†è§£å’ŒæŽ§åˆ¶çš„æœºå™¨äººç³»ç»Ÿï¼Œä¿ƒè¿›äººæœºåä½œã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Assistive robots operating in unstructured environments must understand not only what objects are, but what they can be used for. This requires grounding language-based action queries to objects that both afford the requested function and can be physically retrieved. Existing approaches often rely on black-box models or fixed affordance labels, limiting transparency, controllability, and reliability for human-facing applications. We introduce CRAFT-E, a modular neuro-symbolic framework that composes a structured verb-property-object knowledge graph with visual-language alignment and energy-based grasp reasoning. The system generates interpretable grounding paths that expose the factors influencing object selection and incorporates grasp feasibility as an integral part of affordance inference. We further construct a benchmark dataset with unified annotations for verb-object compatibility, segmentation, and grasp candidates, and deploy the full pipeline on a physical robot. CRAFT-E achieves competitive performance in static scenes, ImageNet-based functional retrieval, and real-world trials involving 20 verbs and 39 objects. The framework remains robust under perceptual noise and provides transparent, component-level diagnostics. By coupling symbolic reasoning with embodied perception, CRAFT-E offers an interpretable and customizable alternative to end-to-end models for affordance-grounded object selection, supporting trustworthy decision-making in assistive robotic systems.

