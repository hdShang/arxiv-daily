---
layout: default
title: Simultaneous Tactile-Visual Perception for Learning Multimodal Robot Manipulation
---

# Simultaneous Tactile-Visual Perception for Learning Multimodal Robot Manipulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.09851" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.09851v1</a>
  <a href="https://arxiv.org/pdf/2512.09851.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.09851v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.09851v1', 'Simultaneous Tactile-Visual Perception for Learning Multimodal Robot Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuyang Li, Yinghan Chen, Zihang Zhao, Puhao Li, Tengyu Liu, Siyuan Huang, Yixin Zhu

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-10

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTacThru-UMIï¼Œç»“åˆæ–°å‹è§¦è§‰è§†è§‰ä¼ æ„Ÿå™¨ä¸Transformeræ‰©æ•£ç­–ç•¥ï¼Œæå‡æœºå™¨äººæ“ä½œç²¾åº¦ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æœºå™¨äººæ“ä½œ` `è§¦è§‰æ„ŸçŸ¥` `è§†è§‰æ„ŸçŸ¥` `å¤šæ¨¡æ€èåˆ` `æ¨¡ä»¿å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰é€çš®è§†è§‰ä¼ æ„Ÿå™¨ç¼ºä¹åŒæ­¥å¤šæ¨¡æ€æ„ŸçŸ¥èƒ½åŠ›ï¼Œè§¦è§‰è·Ÿè¸ªçš„å¯é æ€§ä¸è¶³ï¼Œé™åˆ¶äº†æœºå™¨äººæ“ä½œçš„ç²¾åº¦ã€‚
2. TacThru-UMIç»“åˆæ–°å‹STSä¼ æ„Ÿå™¨TacThruå’ŒTransformeræ‰©æ•£ç­–ç•¥ï¼Œå®ç°åŒæ­¥è§¦è§‰è§†è§‰æ„ŸçŸ¥å’Œç²¾ç¡®æ“ä½œã€‚
3. å®éªŒè¡¨æ˜ï¼ŒTacThru-UMIåœ¨å¤šä¸ªçœŸå®æ“ä½œä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå¹³å‡æˆåŠŸç‡æå‡è‡³85.5%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœºå™¨äººæ“ä½œéœ€è¦ä¸°å¯Œçš„å¤šæ¨¡æ€æ„ŸçŸ¥å’Œæœ‰æ•ˆçš„å­¦ä¹ æ¡†æ¶æ¥å¤„ç†å¤æ‚çš„ç°å®ä¸–ç•Œä»»åŠ¡ã€‚é€çš®è§†è§‰ï¼ˆSTSï¼‰ä¼ æ„Ÿå™¨ç»“åˆäº†è§¦è§‰å’Œè§†è§‰æ„ŸçŸ¥ï¼Œæä¾›äº†æœ‰å‰æ™¯çš„ä¼ æ„Ÿèƒ½åŠ›ï¼Œè€Œç°ä»£æ¨¡ä»¿å­¦ä¹ ä¸ºç­–ç•¥è·å–æä¾›äº†å¼ºå¤§çš„å·¥å…·ã€‚ç„¶è€Œï¼Œç°æœ‰çš„STSè®¾è®¡ç¼ºä¹åŒæ­¥å¤šæ¨¡æ€æ„ŸçŸ¥ï¼Œå¹¶ä¸”å­˜åœ¨ä¸å¯é çš„è§¦è§‰è·Ÿè¸ªé—®é¢˜ã€‚æ­¤å¤–ï¼Œå°†è¿™äº›ä¸°å¯Œçš„å¤šæ¨¡æ€ä¿¡å·é›†æˆåˆ°åŸºäºå­¦ä¹ çš„æ“ä½œæµç¨‹ä¸­ä»ç„¶æ˜¯ä¸€ä¸ªå…¬å¼€çš„æŒ‘æˆ˜ã€‚æˆ‘ä»¬ä»‹ç»äº†TacThruï¼Œä¸€ç§èƒ½å¤Ÿå®ç°åŒæ­¥è§†è§‰æ„ŸçŸ¥å’Œé²æ£’è§¦è§‰ä¿¡å·æå–çš„STSä¼ æ„Ÿå™¨ï¼Œä»¥åŠTacThru-UMIï¼Œä¸€ç§åˆ©ç”¨è¿™äº›å¤šæ¨¡æ€ä¿¡å·è¿›è¡Œæ“ä½œçš„æ¨¡ä»¿å­¦ä¹ æ¡†æ¶ã€‚æˆ‘ä»¬çš„ä¼ æ„Ÿå™¨å…·æœ‰å®Œå…¨é€æ˜çš„å¼¹æ€§ä½“ã€æŒä¹…ç…§æ˜ã€æ–°å‹å…³é”®çº¿æ ‡è®°å’Œé«˜æ•ˆè·Ÿè¸ªï¼Œè€Œæˆ‘ä»¬çš„å­¦ä¹ ç³»ç»Ÿé€šè¿‡åŸºäºTransformerçš„æ‰©æ•£ç­–ç•¥é›†æˆè¿™äº›ä¿¡å·ã€‚åœ¨äº”ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ç°å®ä¸–ç•Œä»»åŠ¡ä¸­çš„å®éªŒè¡¨æ˜ï¼ŒTacThru-UMIå®ç°äº†å¹³å‡85.5%çš„æˆåŠŸç‡ï¼Œæ˜¾è‘—ä¼˜äºäº¤æ›¿è§¦è§‰è§†è§‰ï¼ˆ66.3%ï¼‰å’Œä»…è§†è§‰ï¼ˆ55.4%ï¼‰çš„åŸºçº¿ã€‚è¯¥ç³»ç»Ÿåœ¨å…³é”®åœºæ™¯ä¸­è¡¨ç°å‡ºè‰²ï¼ŒåŒ…æ‹¬è–„è€Œè½¯ç‰©ä½“çš„æ¥è§¦æ£€æµ‹ä»¥åŠéœ€è¦å¤šæ¨¡æ€åè°ƒçš„ç²¾ç¡®æ“ä½œã€‚è¿™é¡¹å·¥ä½œè¡¨æ˜ï¼Œå°†åŒæ­¥å¤šæ¨¡æ€æ„ŸçŸ¥ä¸ç°ä»£å­¦ä¹ æ¡†æ¶ç›¸ç»“åˆï¼Œå¯ä»¥å®ç°æ›´ç²¾ç¡®ã€æ›´å…·é€‚åº”æ€§çš„æœºå™¨äººæ“ä½œã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æœºå™¨äººæ“ä½œä¸­ï¼Œç”±äºä¼ æ„Ÿå™¨æ„ŸçŸ¥èƒ½åŠ›ä¸è¶³å’Œå­¦ä¹ æ¡†æ¶æ— æ³•æœ‰æ•ˆèåˆå¤šæ¨¡æ€ä¿¡æ¯ï¼Œå¯¼è‡´æ“ä½œç²¾åº¦å’Œé€‚åº”æ€§å—é™çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚äº¤æ›¿ä½¿ç”¨è§¦è§‰å’Œè§†è§‰ä¿¡æ¯ï¼Œæˆ–ä»…ä¾èµ–è§†è§‰ä¿¡æ¯ï¼Œæ— æ³•å……åˆ†åˆ©ç”¨è§¦è§‰æä¾›çš„æ¥è§¦ä¿¡æ¯ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†è–„ã€è½¯ç‰©ä½“æˆ–éœ€è¦ç²¾ç»†æ“ä½œçš„åœºæ™¯ä¸‹ï¼Œè¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯è®¾è®¡ä¸€ç§æ–°å‹çš„é€çš®è§†è§‰ï¼ˆSTSï¼‰ä¼ æ„Ÿå™¨TacThruï¼Œèƒ½å¤ŸåŒæ—¶æä¾›é«˜è´¨é‡çš„è§†è§‰å’Œè§¦è§‰ä¿¡æ¯ï¼Œå¹¶é€šè¿‡ä¸€ä¸ªåŸºäºTransformerçš„æ‰©æ•£ç­–ç•¥TacThru-UMIï¼Œå°†è¿™äº›å¤šæ¨¡æ€ä¿¡æ¯æœ‰æ•ˆåœ°èåˆåˆ°æœºå™¨äººæ“ä½œçš„å­¦ä¹ è¿‡ç¨‹ä¸­ã€‚é€šè¿‡åŒæ­¥æ„ŸçŸ¥å’Œå¤šæ¨¡æ€èåˆï¼Œæé«˜æœºå™¨äººå¯¹ç¯å¢ƒçš„ç†è§£å’Œæ“ä½œçš„ç²¾åº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTacThru-UMIçš„æ•´ä½“æ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦éƒ¨åˆ†ï¼šTacThruä¼ æ„Ÿå™¨å’ŒTransformeræ‰©æ•£ç­–ç•¥ã€‚TacThruä¼ æ„Ÿå™¨è´Ÿè´£é‡‡é›†åŒæ­¥çš„è§†è§‰å’Œè§¦è§‰ä¿¡æ¯ï¼ŒåŒ…æ‹¬é€šè¿‡é€æ˜å¼¹æ€§ä½“è·å–çš„è§†è§‰å›¾åƒå’Œé€šè¿‡å…³é”®çº¿æ ‡è®°è·Ÿè¸ªå¾—åˆ°çš„è§¦è§‰ä¿¡æ¯ã€‚è¿™äº›ä¿¡æ¯è¢«è¾“å…¥åˆ°Transformeræ‰©æ•£ç­–ç•¥ä¸­ï¼Œè¯¥ç­–ç•¥å­¦ä¹ ä»å¤šæ¨¡æ€æ•°æ®åˆ°æœºå™¨äººåŠ¨ä½œçš„æ˜ å°„ã€‚æ•´ä¸ªæµç¨‹åŒ…æ‹¬æ•°æ®é‡‡é›†ã€ä¼ æ„Ÿå™¨ä¿¡å·å¤„ç†ã€ç­–ç•¥å­¦ä¹ å’Œæœºå™¨äººæ§åˆ¶ç­‰é˜¶æ®µã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºTacThruä¼ æ„Ÿå™¨çš„è®¾è®¡å’ŒTacThru-UMIå­¦ä¹ æ¡†æ¶çš„æ„å»ºã€‚TacThruä¼ æ„Ÿå™¨é€šè¿‡å®Œå…¨é€æ˜çš„å¼¹æ€§ä½“ã€æŒä¹…ç…§æ˜å’Œæ–°å‹å…³é”®çº¿æ ‡è®°ï¼Œå®ç°äº†åŒæ­¥ã€é²æ£’çš„è§†è§‰å’Œè§¦è§‰æ„ŸçŸ¥ã€‚TacThru-UMIå­¦ä¹ æ¡†æ¶åˆ™åˆ©ç”¨Transformerçš„å¼ºå¤§å»ºæ¨¡èƒ½åŠ›ï¼Œæœ‰æ•ˆåœ°èåˆäº†è§†è§‰å’Œè§¦è§‰ä¿¡æ¯ï¼Œä»è€Œæé«˜äº†æœºå™¨äººæ“ä½œçš„ç²¾åº¦å’Œé€‚åº”æ€§ã€‚ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºï¼ŒTacThru-UMIèƒ½å¤ŸåŒæ—¶åˆ©ç”¨è§†è§‰å’Œè§¦è§‰ä¿¡æ¯è¿›è¡Œå†³ç­–ï¼Œè€Œä¸æ˜¯äº¤æ›¿ä½¿ç”¨æˆ–ä»…ä¾èµ–è§†è§‰ä¿¡æ¯ã€‚

**å…³é”®è®¾è®¡**ï¼šTacThruä¼ æ„Ÿå™¨é‡‡ç”¨å®Œå…¨é€æ˜çš„å¼¹æ€§ä½“ï¼Œä»¥å‡å°‘è§†è§‰é®æŒ¡ã€‚å…³é”®çº¿æ ‡è®°è¢«è®¾è®¡æˆæ˜“äºè·Ÿè¸ªå’ŒåŒºåˆ†çš„å½¢çŠ¶ï¼Œå¹¶ä½¿ç”¨é«˜æ•ˆçš„è·Ÿè¸ªç®—æ³•è¿›è¡Œå¤„ç†ã€‚Transformeræ‰©æ•£ç­–ç•¥ä½¿ç”¨Transformerç¼–ç å™¨æ¥æå–è§†è§‰å’Œè§¦è§‰ç‰¹å¾ï¼Œå¹¶ä½¿ç”¨æ‰©æ•£æ¨¡å‹æ¥ç”Ÿæˆæœºå™¨äººåŠ¨ä½œã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬æ¨¡ä»¿å­¦ä¹ æŸå¤±å’Œæ­£åˆ™åŒ–é¡¹ï¼Œä»¥æé«˜ç­–ç•¥çš„æ³›åŒ–èƒ½åŠ›ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’Œå‚æ•°è®¾ç½®åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒTacThru-UMIåœ¨äº”ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ç°å®ä¸–ç•Œä»»åŠ¡ä¸­ï¼Œå¹³å‡æˆåŠŸç‡è¾¾åˆ°85.5%ï¼Œæ˜¾è‘—ä¼˜äºäº¤æ›¿è§¦è§‰è§†è§‰ï¼ˆ66.3%ï¼‰å’Œä»…è§†è§‰ï¼ˆ55.4%ï¼‰çš„åŸºçº¿æ–¹æ³•ã€‚å°¤å…¶æ˜¯åœ¨å¤„ç†è–„è€Œè½¯çš„ç‰©ä½“ä»¥åŠéœ€è¦ç²¾ç¡®æ“ä½œçš„åœºæ™¯ä¸­ï¼ŒTacThru-UMIè¡¨ç°å‡ºæ˜æ˜¾çš„ä¼˜åŠ¿ï¼Œè¯æ˜äº†åŒæ­¥å¤šæ¨¡æ€æ„ŸçŸ¥å’Œå­¦ä¹ æ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦ç²¾ç»†æ“ä½œå’Œç¯å¢ƒæ„ŸçŸ¥çš„æœºå™¨äººä»»åŠ¡ä¸­ï¼Œä¾‹å¦‚åŒ»ç–—æ‰‹æœ¯æœºå™¨äººã€ç²¾å¯†è£…é…æœºå™¨äººã€ä»¥åŠåœ¨å¤æ‚ç¯å¢ƒä¸­è¿›è¡Œæ“ä½œçš„æœºå™¨äººã€‚é€šè¿‡æä¾›æ›´ç²¾ç¡®çš„æ„ŸçŸ¥å’Œæ›´æ™ºèƒ½çš„æ§åˆ¶ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›æé«˜æœºå™¨äººæ“ä½œçš„æ•ˆç‡å’Œå®‰å…¨æ€§ï¼Œå¹¶æ‰©å±•æœºå™¨äººçš„åº”ç”¨èŒƒå›´ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Robotic manipulation requires both rich multimodal perception and effective learning frameworks to handle complex real-world tasks. See-through-skin (STS) sensors, which combine tactile and visual perception, offer promising sensing capabilities, while modern imitation learning provides powerful tools for policy acquisition. However, existing STS designs lack simultaneous multimodal perception and suffer from unreliable tactile tracking. Furthermore, integrating these rich multimodal signals into learning-based manipulation pipelines remains an open challenge. We introduce TacThru, an STS sensor enabling simultaneous visual perception and robust tactile signal extraction, and TacThru-UMI, an imitation learning framework that leverages these multimodal signals for manipulation. Our sensor features a fully transparent elastomer, persistent illumination, novel keyline markers, and efficient tracking, while our learning system integrates these signals through a Transformer-based Diffusion Policy. Experiments on five challenging real-world tasks show that TacThru-UMI achieves an average success rate of 85.5%, significantly outperforming the baselines of alternating tactile-visual (66.3%) and vision-only (55.4%). The system excels in critical scenarios, including contact detection with thin and soft objects and precision manipulation requiring multimodal coordination. This work demonstrates that combining simultaneous multimodal perception with modern learning frameworks enables more precise, adaptable robotic manipulation.

