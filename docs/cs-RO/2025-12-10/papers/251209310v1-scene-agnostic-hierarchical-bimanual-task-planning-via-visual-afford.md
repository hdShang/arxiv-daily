---
layout: default
title: Scene-agnostic Hierarchical Bimanual Task Planning via Visual Affordance Reasoning
---

# Scene-agnostic Hierarchical Bimanual Task Planning via Visual Affordance Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.09310" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.09310v1</a>
  <a href="https://arxiv.org/pdf/2512.09310.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.09310v1" onclick="toggleFavorite(this, '2512.09310v1', 'Scene-agnostic Hierarchical Bimanual Task Planning via Visual Affordance Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kwang Bin Lee, Jiho Kang, Sung-Hee Lee

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-12-10

**å¤‡æ³¨**: 8 pages, 4 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºè§†è§‰å¯ä¾›æ€§çš„åœºæ™¯æ— å…³åˆ†å±‚åŒè‡‚ä»»åŠ¡è§„åˆ’æ¡†æ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `åŒè‡‚æœºå™¨äºº` `ä»»åŠ¡è§„åˆ’` `è§†è§‰å¯ä¾›æ€§` `åœºæ™¯æ— å…³` `æœºå™¨äººæ“ä½œ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æœºå™¨äººä»»åŠ¡è§„åˆ’ä¸»è¦é›†ä¸­äºå•è‡‚æ“ä½œï¼Œå¿½ç•¥äº†åŒè‡‚æ“ä½œä¸­å›ºæœ‰çš„ç©ºé—´ã€å‡ ä½•å’ŒååŒæŒ‘æˆ˜ï¼Œéš¾ä»¥åº”å¯¹å¤æ‚ç¯å¢ƒã€‚
2. è¯¥æ–¹æ³•é€šè¿‡è§†è§‰ç‚¹å®šä½ã€åŒè‡‚å­ç›®æ ‡è§„åˆ’å’Œäº¤äº’ç‚¹é©±åŠ¨çš„åŒè‡‚æç¤ºä¸‰ä¸ªæ¨¡å—ï¼Œå®ç°äº†é«˜å±‚æ¨ç†ä¸3Dåœºæ™¯ä¸­åŒè‡‚æ‰§è¡Œçš„æ¡¥æ¢ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆè¿è´¯ã€å¯è¡Œä¸”ç´§å‡‘çš„åŒè‡‚è§„åˆ’ï¼Œå¹¶å…·å¤‡è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œæ— éœ€é’ˆå¯¹æ–°åœºæ™¯è¿›è¡Œé‡æ–°è®­ç»ƒã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„åœºæ™¯æ— å…³åŒè‡‚ä»»åŠ¡è§„åˆ’æ¡†æ¶ï¼Œæ—¨åœ¨å°†é«˜å±‚æŒ‡ä»¤è½¬åŒ–ä¸ºå¯æ‰§è¡Œçš„è¡Œä¸ºï¼Œè§£å†³å¼€æ”¾ç¯å¢ƒä¸­åŒè‡‚ååŒæ“ä½œçš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸‰ä¸ªå…³é”®æ¨¡å—ï¼šè§†è§‰ç‚¹å®šä½ï¼ˆVPGï¼‰åˆ†æåœºæ™¯å›¾åƒä»¥æ£€æµ‹ç›¸å…³å¯¹è±¡å¹¶ç”Ÿæˆä¸–ç•Œåæ ‡å¯¹é½çš„äº¤äº’ç‚¹ï¼›åŒè‡‚å­ç›®æ ‡è§„åˆ’å™¨ï¼ˆBSPï¼‰æ¨ç†ç©ºé—´é‚»æ¥æ€§å’Œè·¨å¯¹è±¡å¯è¾¾æ€§ï¼Œç”Ÿæˆç´§å‡‘çš„ã€è¿åŠ¨ä¸­æ€§çš„å­ç›®æ ‡ï¼Œä»¥åˆ©ç”¨åŒè‡‚ååŒæ“ä½œçš„æœºä¼šï¼›äº¤äº’ç‚¹é©±åŠ¨çš„åŒè‡‚æç¤ºï¼ˆIPBPï¼‰å°†è¿™äº›å­ç›®æ ‡ç»‘å®šåˆ°ç»“æ„åŒ–çš„æŠ€èƒ½åº“ï¼Œå®ä¾‹åŒ–åŒæ­¥çš„å•è‡‚æˆ–åŒè‡‚åŠ¨ä½œåºåˆ—ï¼Œæ»¡è¶³æ‰‹éƒ¨çŠ¶æ€å’Œå¯ä¾›æ€§çº¦æŸã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆè¿è´¯ã€å¯è¡Œä¸”ç´§å‡‘çš„åŒè‡‚è§„åˆ’ï¼Œå¹¶æ¨å¹¿åˆ°æ‚ä¹±çš„åœºæ™¯ï¼Œæ— éœ€é‡æ–°è®­ç»ƒï¼Œå±•ç¤ºäº†é²æ£’çš„åœºæ™¯æ— å…³åŒè‡‚ä»»åŠ¡å¯ä¾›æ€§æ¨ç†èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æœºå™¨äººä»»åŠ¡è§„åˆ’å™¨ä¸»è¦å…³æ³¨å•è‡‚æ“ä½œï¼Œæ— æ³•æœ‰æ•ˆè§£å†³åŒè‡‚æ“ä½œä¸­å›ºæœ‰çš„ç©ºé—´å…³ç³»ã€å‡ ä½•çº¦æŸä»¥åŠååŒæ“ä½œçš„å¤æ‚æ€§ã€‚åœ¨å¼€æ”¾ä¸”æœªçŸ¥çš„ç¯å¢ƒä¸­ï¼Œå¦‚ä½•å°†é«˜å±‚æŒ‡ä»¤è½¬åŒ–ä¸ºå¯æ‰§è¡Œçš„åŒè‡‚åŠ¨ä½œåºåˆ—ï¼Œæ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥åœ¨æ‚ä¹±çš„åœºæ™¯ä¸­è¿›è¡Œæœ‰æ•ˆçš„åŒè‡‚ä»»åŠ¡è§„åˆ’ï¼Œç¼ºä¹åœºæ™¯æ³›åŒ–èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè¯¥è®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†é«˜å±‚ä»»åŠ¡åˆ†è§£ä¸ºä¸€ç³»åˆ—å¯æ‰§è¡Œçš„åŒè‡‚å­ç›®æ ‡ï¼Œå¹¶é€šè¿‡è§†è§‰å¯ä¾›æ€§æ¨ç†æ¥ç¡®å®šåˆé€‚çš„äº¤äº’ç‚¹å’ŒåŠ¨ä½œåºåˆ—ã€‚é€šè¿‡è§£è€¦ä»»åŠ¡è§„åˆ’å’Œå…·ä½“åŠ¨ä½œæ‰§è¡Œï¼Œå®ç°äº†æ›´çµæ´»å’Œå¯æ‰©å±•çš„åŒè‡‚ä»»åŠ¡è§„åˆ’æ¡†æ¶ã€‚åˆ©ç”¨è§†è§‰ä¿¡æ¯è¿›è¡Œç¯å¢ƒæ„ŸçŸ¥ï¼Œä»è€Œå®ç°åœºæ™¯æ— å…³æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…å«ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š1) **è§†è§‰ç‚¹å®šä½ (VPG)**ï¼šä»å•å¼ åœºæ™¯å›¾åƒä¸­æ£€æµ‹ç›¸å…³å¯¹è±¡ï¼Œå¹¶ç”Ÿæˆä¸ä¸–ç•Œåæ ‡ç³»å¯¹é½çš„äº¤äº’ç‚¹ã€‚2) **åŒè‡‚å­ç›®æ ‡è§„åˆ’å™¨ (BSP)**ï¼šåŸºäºç©ºé—´é‚»æ¥æ€§å’Œè·¨å¯¹è±¡å¯è¾¾æ€§è¿›è¡Œæ¨ç†ï¼Œç”Ÿæˆç´§å‡‘ä¸”è¿åŠ¨ä¸­æ€§çš„å­ç›®æ ‡ã€‚3) **äº¤äº’ç‚¹é©±åŠ¨çš„åŒè‡‚æç¤º (IPBP)**ï¼šå°†å­ç›®æ ‡ä¸ç»“æ„åŒ–çš„æŠ€èƒ½åº“ç»‘å®šï¼Œå®ä¾‹åŒ–åŒæ­¥çš„å•è‡‚æˆ–åŒè‡‚åŠ¨ä½œåºåˆ—ï¼Œå¹¶æ»¡è¶³æ‰‹éƒ¨çŠ¶æ€å’Œå¯ä¾›æ€§çº¦æŸã€‚æ•´ä½“æµç¨‹æ˜¯ä»é«˜å±‚æŒ‡ä»¤å¼€å§‹ï¼Œé€šè¿‡VPGè¿›è¡Œç¯å¢ƒæ„ŸçŸ¥ï¼ŒBSPç”Ÿæˆå­ç›®æ ‡ï¼Œæœ€åç”±IPBPç”Ÿæˆå…·ä½“çš„åŠ¨ä½œåºåˆ—ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•çš„ä¸»è¦åˆ›æ–°åœ¨äºå°†è§†è§‰å¯ä¾›æ€§æ¨ç†ä¸åŒè‡‚ä»»åŠ¡è§„åˆ’ç›¸ç»“åˆï¼Œå®ç°äº†åœºæ™¯æ— å…³çš„åŒè‡‚æ“ä½œã€‚é€šè¿‡åŒè‡‚å­ç›®æ ‡è§„åˆ’å™¨ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨åŒè‡‚ååŒæ“ä½œçš„ä¼˜åŠ¿ï¼Œç”Ÿæˆæ›´ç´§å‡‘å’Œé«˜æ•ˆçš„åŠ¨ä½œåºåˆ—ã€‚äº¤äº’ç‚¹é©±åŠ¨çš„åŒè‡‚æç¤ºæœºåˆ¶ï¼Œèƒ½å¤Ÿçµæ´»åœ°é€‰æ‹©åˆé€‚çš„åŠ¨ä½œæŠ€èƒ½ï¼Œå¹¶æ»¡è¶³æ‰‹éƒ¨çŠ¶æ€å’Œå¯ä¾›æ€§çº¦æŸã€‚

**å…³é”®è®¾è®¡**ï¼šVPGæ¨¡å—ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹è¿›è¡Œå¯¹è±¡æ£€æµ‹å’Œäº¤äº’ç‚¹é¢„æµ‹ã€‚BSPæ¨¡å—ä½¿ç”¨å›¾æœç´¢ç®—æ³•æ¥è§„åˆ’å­ç›®æ ‡åºåˆ—ï¼Œå¹¶è€ƒè™‘ç©ºé—´é‚»æ¥æ€§å’Œå¯è¾¾æ€§çº¦æŸã€‚IPBPæ¨¡å—ä½¿ç”¨æç¤ºå­¦ä¹ æ–¹æ³•ï¼Œå°†å­ç›®æ ‡ä¸æŠ€èƒ½åº“ä¸­çš„åŠ¨ä½œè¿›è¡ŒåŒ¹é…ï¼Œå¹¶ç”Ÿæˆå…·ä½“çš„åŠ¨ä½œå‚æ•°ã€‚æŠ€èƒ½åº“åŒ…å«é¢„å®šä¹‰çš„å•è‡‚å’ŒåŒè‡‚åŠ¨ä½œï¼Œä¾‹å¦‚æŠ“å–ã€æ”¾ç½®ã€ç§»åŠ¨ç­‰ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡æ—¨åœ¨ä¼˜åŒ–å­ç›®æ ‡åºåˆ—çš„ç´§å‡‘æ€§å’ŒåŠ¨ä½œåºåˆ—çš„å¯è¡Œæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆè¿è´¯ã€å¯è¡Œä¸”ç´§å‡‘çš„åŒè‡‚è§„åˆ’ï¼Œå¹¶ä¸”åœ¨æ‚ä¹±çš„åœºæ™¯ä¸­è¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œæ— éœ€é‡æ–°è®­ç»ƒã€‚ç›¸è¾ƒäºä¼ ç»Ÿçš„å•è‡‚è§„åˆ’æ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨åŒè‡‚ååŒæ“ä½œçš„ä¼˜åŠ¿ï¼Œç¼©çŸ­ä»»åŠ¡å®Œæˆæ—¶é—´ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®ï¼ˆä¾‹å¦‚ä»»åŠ¡æˆåŠŸç‡ã€è§„åˆ’æ—¶é—´ç­‰ï¼‰åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†çš„å±•ç¤ºå’Œå¯¹æ¯”ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦åŒè‡‚ååŒæ“ä½œçš„æœºå™¨äººåº”ç”¨åœºæ™¯ï¼Œä¾‹å¦‚ï¼šå®¶åº­æœåŠ¡æœºå™¨äººã€å·¥ä¸šè£…é…æœºå™¨äººã€åŒ»ç–—è¾…åŠ©æœºå™¨äººç­‰ã€‚é€šè¿‡è¯¥æ¡†æ¶ï¼Œæœºå™¨äººèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£äººç±»æŒ‡ä»¤ï¼Œå¹¶åœ¨å¤æ‚çš„ç¯å¢ƒä¸­æ‰§è¡Œå„ç§ä»»åŠ¡ï¼Œæé«˜å·¥ä½œæ•ˆç‡å’Œå®‰å…¨æ€§ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›è¿›ä¸€æ­¥æ‰©å±•åˆ°æ›´å¤æ‚çš„ä»»åŠ¡å’Œç¯å¢ƒï¼Œå®ç°æ›´æ™ºèƒ½åŒ–çš„æœºå™¨äººæ“ä½œã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Embodied agents operating in open environments must translate high-level instructions into grounded, executable behaviors, often requiring coordinated use of both hands. While recent foundation models offer strong semantic reasoning, existing robotic task planners remain predominantly unimanual and fail to address the spatial, geometric, and coordination challenges inherent to bimanual manipulation in scene-agnostic settings. We present a unified framework for scene-agnostic bimanual task planning that bridges high-level reasoning with 3D-grounded two-handed execution. Our approach integrates three key modules. Visual Point Grounding (VPG) analyzes a single scene image to detect relevant objects and generate world-aligned interaction points. Bimanual Subgoal Planner (BSP) reasons over spatial adjacency and cross-object accessibility to produce compact, motion-neutralized subgoals that exploit opportunities for coordinated two-handed actions. Interaction-Point-Driven Bimanual Prompting (IPBP) binds these subgoals to a structured skill library, instantiating synchronized unimanual or bimanual action sequences that satisfy hand-state and affordance constraints. Together, these modules enable agents to plan semantically meaningful, physically feasible, and parallelizable two-handed behaviors in cluttered, previously unseen scenes. Experiments show that it produces coherent, feasible, and compact two-handed plans, and generalizes to cluttered scenes without retraining, demonstrating robust scene-agnostic affordance reasoning for bimanual tasks.

