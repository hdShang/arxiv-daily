---
layout: default
title: GLaD: Geometric Latent Distillation for Vision-Language-Action Models
---

# GLaD: Geometric Latent Distillation for Vision-Language-Action Models

**arXiv**: [2512.09619v1](https://arxiv.org/abs/2512.09619) | [PDF](https://arxiv.org/pdf/2512.09619.pdf)

**ä½œè€…**: Minghao Guo, Meng Cao, Jiachen Tao, Rongtao Xu, Yan Yan, Xiaodan Liang, Ivan Laptev, Xiaojun Chang

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-12-10

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**GLaDï¼šå‡ ä½•æ½œåœ¨è’¸é¦å¢žå¼ºè§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹çš„ç©ºé—´æŽ¨ç†èƒ½åŠ›**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹` `å‡ ä½•æ„ŸçŸ¥` `çŸ¥è¯†è’¸é¦` `ç©ºé—´æŽ¨ç†` `æœºå™¨äººæ“ä½œ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰VLAæ¨¡åž‹å¿½ç•¥äº†å‡ ä½•ä¿¡æ¯ï¼Œé™åˆ¶äº†å…¶ç©ºé—´æŽ¨ç†å’Œæ“ä½œèƒ½åŠ›ã€‚
2. GLaDé€šè¿‡å‡ ä½•æ½œåœ¨è’¸é¦ï¼Œå°†3Då‡ ä½•å…ˆéªŒçŸ¥è¯†èžå…¥LLMçš„è§†è§‰tokenè¡¨ç¤ºä¸­ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒGLaDåœ¨LIBEROä»»åŠ¡ä¸­ä¼˜äºŽUniVLAï¼ŒéªŒè¯äº†å‡ ä½•æ„ŸçŸ¥é¢„è®­ç»ƒçš„æœ‰æ•ˆæ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

çŽ°æœ‰è§†è§‰-è¯­è¨€-åŠ¨ä½œ(VLA)æ¨¡åž‹ä¸»è¦ä¾èµ–RGBä¿¡æ¯ï¼Œå¿½ç•¥äº†å¯¹ç©ºé—´æŽ¨ç†å’Œæ“ä½œè‡³å…³é‡è¦çš„å‡ ä½•çº¿ç´¢ã€‚æœ¬æ–‡æå‡ºäº†GLaDï¼Œä¸€ä¸ªå‡ ä½•æ„ŸçŸ¥çš„VLAæ¡†æž¶ï¼Œé€šè¿‡çŸ¥è¯†è’¸é¦åœ¨é¢„è®­ç»ƒæœŸé—´èžå…¥3Då‡ ä½•å…ˆéªŒã€‚ä¸Žä»…å°†å‡ ä½•ç‰¹å¾è’¸é¦åˆ°è§†è§‰ç¼–ç å™¨ä¸åŒï¼ŒGLaDå°†LLMä¸­å¯¹åº”äºŽè§†è§‰tokençš„éšè—çŠ¶æ€ä¸Žå†»ç»“çš„å‡ ä½•æ„ŸçŸ¥è§†è§‰Transformer (VGGT)çš„ç‰¹å¾å¯¹é½ï¼Œç¡®ä¿å‡ ä½•ç†è§£è¢«æ·±åº¦é›†æˆåˆ°é©±åŠ¨åŠ¨ä½œé¢„æµ‹çš„å¤šæ¨¡æ€è¡¨ç¤ºä¸­ã€‚åœ¨Bridgeæ•°æ®é›†ä¸Šä½¿ç”¨è¿™ç§å‡ ä½•è’¸é¦æœºåˆ¶è¿›è¡Œé¢„è®­ç»ƒåŽï¼ŒGLaDåœ¨å››ä¸ªLIBEROä»»åŠ¡å¥—ä»¶ä¸­å®žçŽ°äº†94.1%çš„å¹³å‡æˆåŠŸçŽ‡ï¼Œä¼˜äºŽä½¿ç”¨ç›¸åŒé¢„è®­ç»ƒæ•°æ®çš„UniVLA (92.5%)ã€‚è¿™äº›ç»“æžœéªŒè¯äº†å‡ ä½•æ„ŸçŸ¥é¢„è®­ç»ƒå¢žå¼ºäº†ç©ºé—´æŽ¨ç†å’Œç­–ç•¥æ³›åŒ–èƒ½åŠ›ï¼Œè€Œæ— éœ€æ˜¾å¼æ·±åº¦ä¼ æ„Ÿå™¨æˆ–3Dæ ‡æ³¨ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡åž‹åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–äºŽRGBå›¾åƒä¿¡æ¯ï¼Œè€Œå¿½ç•¥äº†åœºæ™¯çš„å‡ ä½•ç»“æž„ä¿¡æ¯ã€‚è¿™ç§å¿½ç•¥å¯¼è‡´æ¨¡åž‹åœ¨éœ€è¦å¤æ‚ç©ºé—´æŽ¨ç†å’Œæ“ä½œçš„ä»»åŠ¡ä¸­è¡¨çŽ°ä¸ä½³ã€‚çŽ°æœ‰æ–¹æ³•ç¼ºä¹æœ‰æ•ˆåˆ©ç”¨å‡ ä½•ä¿¡æ¯çš„èƒ½åŠ›ï¼Œé™åˆ¶äº†æ¨¡åž‹çš„æ³›åŒ–æ€§å’Œé²æ£’æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šGLaDçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡çŸ¥è¯†è’¸é¦ï¼Œå°†å‡ ä½•ä¿¡æ¯ä»Žä¸€ä¸ªé¢„è®­ç»ƒçš„å‡ ä½•æ„ŸçŸ¥è§†è§‰Transformer (VGGT)ä¼ é€’åˆ°VLAæ¨¡åž‹ä¸­çš„è¯­è¨€æ¨¡åž‹ï¼ˆLLMï¼‰ã€‚å…·ä½“æ¥è¯´ï¼ŒGLaDä¸æ˜¯ç›´æŽ¥å°†å‡ ä½•ç‰¹å¾è’¸é¦åˆ°è§†è§‰ç¼–ç å™¨ï¼Œè€Œæ˜¯å°†LLMä¸­å¯¹åº”äºŽè§†è§‰tokençš„éšè—çŠ¶æ€ä¸ŽVGGTçš„ç‰¹å¾å¯¹é½ã€‚è¿™æ ·åšçš„ç›®çš„æ˜¯è®©LLMèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œåˆ©ç”¨åœºæ™¯çš„å‡ ä½•ä¿¡æ¯ï¼Œä»Žè€Œæé«˜æ¨¡åž‹çš„ç©ºé—´æŽ¨ç†å’Œæ“ä½œèƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šGLaDçš„æ•´ä½“æ¡†æž¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) ä¸€ä¸ªé¢„è®­ç»ƒçš„å‡ ä½•æ„ŸçŸ¥è§†è§‰Transformer (VGGT)ï¼Œç”¨äºŽæå–åœºæ™¯çš„å‡ ä½•ç‰¹å¾ï¼›2) ä¸€ä¸ªè§†è§‰ç¼–ç å™¨ï¼Œç”¨äºŽå°†RGBå›¾åƒç¼–ç æˆè§†è§‰ç‰¹å¾ï¼›3) ä¸€ä¸ªè¯­è¨€æ¨¡åž‹ï¼ˆLLMï¼‰ï¼Œç”¨äºŽå¤„ç†æ–‡æœ¬æŒ‡ä»¤å’Œèžåˆè§†è§‰ç‰¹å¾ï¼›4) ä¸€ä¸ªåŠ¨ä½œé¢„æµ‹æ¨¡å—ï¼Œç”¨äºŽæ ¹æ®èžåˆåŽçš„å¤šæ¨¡æ€è¡¨ç¤ºé¢„æµ‹åŠ¨ä½œã€‚GLaDçš„å…³é”®åœ¨äºŽå°†VGGTæå–çš„å‡ ä½•ç‰¹å¾é€šè¿‡çŸ¥è¯†è’¸é¦çš„æ–¹å¼èžå…¥åˆ°LLMä¸­ï¼Œä»Žè€Œå¢žå¼ºLLMå¯¹å‡ ä½•ä¿¡æ¯çš„ç†è§£ã€‚

**å…³é”®åˆ›æ–°**ï¼šGLaDæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽå…¶å‡ ä½•æ½œåœ¨è’¸é¦æœºåˆ¶ã€‚ä¸Žä¼ ç»Ÿçš„çŸ¥è¯†è’¸é¦æ–¹æ³•ä¸åŒï¼ŒGLaDä¸æ˜¯ç›´æŽ¥å°†å‡ ä½•ç‰¹å¾è’¸é¦åˆ°è§†è§‰ç¼–ç å™¨ï¼Œè€Œæ˜¯å°†LLMä¸­å¯¹åº”äºŽè§†è§‰tokençš„éšè—çŠ¶æ€ä¸ŽVGGTçš„ç‰¹å¾å¯¹é½ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å°†å‡ ä½•ä¿¡æ¯èžå…¥åˆ°å¤šæ¨¡æ€è¡¨ç¤ºä¸­ï¼Œä»Žè€Œæé«˜æ¨¡åž‹çš„ç©ºé—´æŽ¨ç†å’Œæ“ä½œèƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒGLaDæ— éœ€æ˜¾å¼çš„æ·±åº¦ä¼ æ„Ÿå™¨æˆ–3Dæ ‡æ³¨ï¼Œå³å¯å®žçŽ°å‡ ä½•æ„ŸçŸ¥çš„é¢„è®­ç»ƒã€‚

**å…³é”®è®¾è®¡**ï¼šGLaDçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨é¢„è®­ç»ƒçš„VGGTæå–å‡ ä½•ç‰¹å¾ï¼›2) ä½¿ç”¨Transformeræž¶æž„çš„LLMè¿›è¡Œå¤šæ¨¡æ€èžåˆï¼›3) è®¾è®¡åˆé€‚çš„æŸå¤±å‡½æ•°ï¼Œç”¨äºŽå°†LLMçš„éšè—çŠ¶æ€ä¸ŽVGGTçš„ç‰¹å¾å¯¹é½ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å¯èƒ½åŒ…æ‹¬KLæ•£åº¦æˆ–MSEæŸå¤±ç­‰ã€‚æ­¤å¤–ï¼ŒGLaDè¿˜å¯èƒ½é‡‡ç”¨ä¸€äº›æ•°æ®å¢žå¼ºæŠ€æœ¯ï¼Œä¾‹å¦‚éšæœºè£å‰ªã€æ—‹è½¬ç­‰ï¼Œä»¥æé«˜æ¨¡åž‹çš„é²æ£’æ€§ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æž„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­åº”è¯¥æœ‰æ›´è¯¦ç»†çš„æè¿°ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

GLaDåœ¨LIBEROä»»åŠ¡å¥—ä»¶ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚åœ¨å››ä¸ªLIBEROä»»åŠ¡å¥—ä»¶ä¸­ï¼ŒGLaDå®žçŽ°äº†94.1%çš„å¹³å‡æˆåŠŸçŽ‡ï¼Œä¼˜äºŽä½¿ç”¨ç›¸åŒé¢„è®­ç»ƒæ•°æ®çš„UniVLA (92.5%)ã€‚è¿™ä¸€ç»“æžœè¡¨æ˜Žï¼Œé€šè¿‡å‡ ä½•æ½œåœ¨è’¸é¦ï¼ŒGLaDèƒ½å¤Ÿæœ‰æ•ˆåœ°å¢žå¼ºæ¨¡åž‹çš„ç©ºé—´æŽ¨ç†å’Œç­–ç•¥æ³›åŒ–èƒ½åŠ›ã€‚è¯¥å®žéªŒç»“æžœéªŒè¯äº†å‡ ä½•æ„ŸçŸ¥é¢„è®­ç»ƒçš„æœ‰æ•ˆæ€§ï¼Œå¹¶ä¸ºVLAæ¨¡åž‹çš„ç ”ç©¶æä¾›äº†æ–°çš„æ€è·¯ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

GLaDçš„ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽæœºå™¨äººæ“ä½œã€è‡ªåŠ¨é©¾é©¶ã€å¢žå¼ºçŽ°å®žç­‰é¢†åŸŸã€‚é€šè¿‡å¢žå¼ºæ¨¡åž‹å¯¹ç©ºé—´å‡ ä½•ä¿¡æ¯çš„ç†è§£ï¼Œå¯ä»¥æé«˜æœºå™¨äººåœ¨å¤æ‚çŽ¯å¢ƒä¸­çš„æ“ä½œèƒ½åŠ›ï¼Œæå‡è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„çŽ¯å¢ƒæ„ŸçŸ¥èƒ½åŠ›ï¼Œå¹¶ä¸ºARåº”ç”¨æä¾›æ›´çœŸå®žçš„ç©ºé—´äº¤äº’ä½“éªŒã€‚è¯¥ç ”ç©¶çš„æœªæ¥å½±å“åœ¨äºŽæŽ¨åŠ¨VLAæ¨¡åž‹åœ¨å®žé™…åœºæ™¯ä¸­çš„åº”ç”¨ï¼Œå®žçŽ°æ›´æ™ºèƒ½ã€æ›´å¯é çš„äººæœºäº¤äº’ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Most existing Vision-Language-Action (VLA) models rely primarily on RGB information, while ignoring geometric cues crucial for spatial reasoning and manipulation. In this work, we introduce GLaD, a geometry-aware VLA framework that incorporates 3D geometric priors during pretraining through knowledge distillation. Rather than distilling geometric features solely into the vision encoder, we align the LLM's hidden states corresponding to visual tokens with features from a frozen geometry-aware vision transformer (VGGT), ensuring that geometric understanding is deeply integrated into the multimodal representations that drive action prediction. Pretrained on the Bridge dataset with this geometry distillation mechanism, GLaD achieves 94.1% average success rate across four LIBERO task suites, outperforming UniVLA (92.5%) which uses identical pretraining data. These results validate that geometry-aware pretraining enhances spatial reasoning and policy generalization without requiring explicit depth sensors or 3D annotations.

