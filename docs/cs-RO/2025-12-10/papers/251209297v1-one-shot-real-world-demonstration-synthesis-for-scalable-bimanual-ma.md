---
layout: default
title: One-Shot Real-World Demonstration Synthesis for Scalable Bimanual Manipulation
---

# One-Shot Real-World Demonstration Synthesis for Scalable Bimanual Manipulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.09297" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.09297v1</a>
  <a href="https://arxiv.org/pdf/2512.09297.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.09297v1" onclick="toggleFavorite(this, '2512.09297v1', 'One-Shot Real-World Demonstration Synthesis for Scalable Bimanual Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Huayi Zhou, Kui Jia

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-12-10

**å¤‡æ³¨**: under review

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**BiDemoSynï¼šåŸºäºå•æ ·æœ¬çœŸå®æ¼”ç¤ºåˆæˆå¯æ‰©å±•çš„åŒè‡‚æ“ä½œæ•°æ®**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `åŒè‡‚æ“ä½œ` `æ¨¡ä»¿å­¦ä¹ ` `æ•°æ®åˆæˆ` `å•æ ·æœ¬å­¦ä¹ ` `æœºå™¨äººå­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŒè‡‚æ“ä½œå­¦ä¹ æ–¹æ³•ä¾èµ–å¤§é‡äººå·¥é¥æ“ä½œæˆ–å—é™äºä»¿çœŸä¸ç°å®çš„å·®è·ï¼Œéš¾ä»¥å…¼é¡¾æ•°æ®è´¨é‡ä¸æ•ˆç‡ã€‚
2. BiDemoSynå°†ä»»åŠ¡åˆ†è§£ä¸ºä¸å˜åè°ƒå—å’Œå¯¹è±¡ä¾èµ–è°ƒæ•´ï¼Œé€šè¿‡è§†è§‰å¯¹é½å’Œè½¨è¿¹ä¼˜åŒ–ï¼Œä»å•æ ·æœ¬ç”Ÿæˆå¤§é‡å¯è¡Œæ¼”ç¤ºã€‚
3. å®éªŒè¡¨æ˜ï¼ŒåŸºäºBiDemoSynæ•°æ®è®­ç»ƒçš„ç­–ç•¥åœ¨ä¸åŒç‰©ä½“å§¿æ€å’Œå½¢çŠ¶ä¸‹è¡¨ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œè¶…è¶Šç°æœ‰åŸºçº¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å­¦ä¹ çµå·§çš„åŒè‡‚æ“ä½œç­–ç•¥ä¸¥é‡ä¾èµ–äºå¤§è§„æ¨¡ã€é«˜è´¨é‡çš„æ¼”ç¤ºæ•°æ®ï¼Œä½†ç°æœ‰æ–¹æ³•é¢ä¸´å›ºæœ‰çš„æƒè¡¡ï¼šé¥æ“ä½œæä¾›ç‰©ç†ä¸Šå¯é çš„æ•°æ®ï¼Œä½†åŠ³åŠ¨å¼ºåº¦è¿‡é«˜ï¼›åŸºäºä»¿çœŸçš„åˆæˆå¯ä»¥é«˜æ•ˆæ‰©å±•ï¼Œä½†å­˜åœ¨æ¨¡æ‹Ÿåˆ°çœŸå®çš„å·®è·ã€‚æˆ‘ä»¬æå‡ºäº†BiDemoSynï¼Œä¸€ä¸ªä»å•ä¸ªçœŸå®ä¸–ç•Œç¤ºä¾‹ä¸­åˆæˆæ¥è§¦ä¸°å¯Œã€ç‰©ç†ä¸Šå¯è¡Œçš„åŒè‡‚æ¼”ç¤ºçš„æ¡†æ¶ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†ä»»åŠ¡åˆ†è§£ä¸ºä¸å˜çš„åè°ƒå—å’Œå¯å˜çš„ã€ä¾èµ–äºå¯¹è±¡çš„è°ƒæ•´ï¼Œç„¶åé€šè¿‡è§†è§‰å¼•å¯¼çš„å¯¹é½å’Œè½»é‡çº§è½¨è¿¹ä¼˜åŒ–æ¥è°ƒæ•´å®ƒä»¬ã€‚è¿™ä½¿å¾—åœ¨å‡ ä¸ªå°æ—¶å†…ç”Ÿæˆæ•°åƒä¸ªä¸åŒçš„ã€å¯è¡Œçš„æ¼”ç¤ºæˆä¸ºå¯èƒ½ï¼Œè€Œæ— éœ€é‡å¤é¥æ“ä½œæˆ–ä¾èµ–ä¸å®Œå–„çš„ä»¿çœŸã€‚åœ¨å…­ä¸ªåŒè‡‚ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬è¡¨æ˜åœ¨BiDemoSynæ•°æ®ä¸Šè®­ç»ƒçš„ç­–ç•¥å¯ä»¥ç¨³å¥åœ°æ¨å¹¿åˆ°æ–°çš„å¯¹è±¡å§¿åŠ¿å’Œå½¢çŠ¶ï¼Œæ˜¾è‘—ä¼˜äºæœ€è¿‘çš„åŸºçº¿ã€‚é€šè¿‡å¼¥åˆæ•ˆç‡å’ŒçœŸå®ä¸–ç•Œä¿çœŸåº¦ä¹‹é—´çš„å·®è·ï¼ŒBiDemoSynä¸ºå¤æ‚çš„åŒè‡‚æ“ä½œçš„å®é™…æ¨¡ä»¿å­¦ä¹ æä¾›äº†ä¸€æ¡å¯æ‰©å±•çš„è·¯å¾„ï¼Œè€Œä¸ä¼šå½±å“ç‰©ç†åŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åŒè‡‚æ“ä½œæ¨¡ä»¿å­¦ä¹ ä¸­ï¼Œé«˜è´¨é‡æ¼”ç¤ºæ•°æ®è·å–å›°éš¾çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚é¥æ“ä½œï¼Œè™½ç„¶èƒ½æä¾›ç‰©ç†çœŸå®çš„äº¤äº’æ•°æ®ï¼Œä½†æˆæœ¬é«˜æ˜‚ï¼Œéš¾ä»¥æ‰©å±•ã€‚è€ŒåŸºäºä»¿çœŸçš„æ–¹æ³•è™½ç„¶é«˜æ•ˆï¼Œä½†ç”±äºæ¨¡æ‹Ÿç¯å¢ƒä¸çœŸå®ç¯å¢ƒçš„å·®å¼‚ï¼ˆsim-to-real gapï¼‰ï¼Œå¯¼è‡´è®­ç»ƒå‡ºçš„ç­–ç•¥åœ¨çœŸå®ä¸–ç•Œä¸­è¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ä»å•ä¸ªçœŸå®ä¸–ç•Œçš„æ¼”ç¤ºä¸­ï¼Œè‡ªåŠ¨ç”Ÿæˆå¤§é‡å¤šæ ·ä¸”ç‰©ç†å¯è¡Œçš„åŒè‡‚æ“ä½œæ¼”ç¤ºæ•°æ®ã€‚é€šè¿‡å°†ä»»åŠ¡åˆ†è§£ä¸ºä¸å¯¹è±¡æ— å…³çš„åè°ƒéƒ¨åˆ†å’Œä¸å¯¹è±¡ç›¸å…³çš„è°ƒæ•´éƒ¨åˆ†ï¼Œå¹¶åˆ©ç”¨è§†è§‰ä¿¡æ¯è¿›è¡Œå¯¹é½å’Œä¼˜åŒ–ï¼Œä»è€Œå®ç°ä»å•æ ·æœ¬åˆ°å¤šæ ·æœ¬çš„æ³›åŒ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šBiDemoSynæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) **ä»»åŠ¡åˆ†è§£**ï¼šå°†åŸå§‹æ¼”ç¤ºåˆ†è§£ä¸ºä¸å˜çš„åè°ƒå—ï¼ˆä¾‹å¦‚ï¼ŒæŠ“å–ã€æ”¾ç½®ï¼‰å’Œå¯å˜çš„ã€å¯¹è±¡ä¾èµ–çš„è°ƒæ•´ï¼ˆä¾‹å¦‚ï¼Œæ ¹æ®å¯¹è±¡å½¢çŠ¶è°ƒæ•´æŠ“å–ä½ç½®ï¼‰ã€‚2) **è§†è§‰å¼•å¯¼å¯¹é½**ï¼šåˆ©ç”¨è§†è§‰ä¿¡æ¯ï¼Œå°†åˆ†è§£åçš„åè°ƒå—å’Œè°ƒæ•´éƒ¨åˆ†ä¸æ–°çš„å¯¹è±¡å§¿æ€å’Œå½¢çŠ¶è¿›è¡Œå¯¹é½ã€‚3) **è½¨è¿¹ä¼˜åŒ–**ï¼šå¯¹å¯¹é½åçš„è½¨è¿¹è¿›è¡Œè½»é‡çº§çš„ä¼˜åŒ–ï¼Œä»¥ç¡®ä¿ç‰©ç†å¯è¡Œæ€§å’Œæ“ä½œçš„æµç•…æ€§ã€‚4) **æ•°æ®ç”Ÿæˆ**ï¼šé€šè¿‡æ”¹å˜å¯¹è±¡å§¿æ€å’Œå½¢çŠ¶ï¼Œé‡å¤ä¸Šè¿°è¿‡ç¨‹ï¼Œç”Ÿæˆå¤§é‡ä¸åŒçš„æ¼”ç¤ºæ•°æ®ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§ä»å•æ ·æœ¬çœŸå®æ¼”ç¤ºä¸­åˆæˆå¤§é‡å¤šæ ·ä¸”ç‰©ç†å¯è¡Œçš„åŒè‡‚æ“ä½œæ¼”ç¤ºæ•°æ®çš„æ–¹æ³•ã€‚ä¸ä¼ ç»Ÿçš„é¥æ“ä½œå’Œä»¿çœŸæ–¹æ³•ç›¸æ¯”ï¼ŒBiDemoSynèƒ½å¤Ÿåœ¨ä¿è¯æ•°æ®è´¨é‡çš„åŒæ—¶ï¼Œæ˜¾è‘—æé«˜æ•°æ®ç”Ÿæˆçš„æ•ˆç‡ã€‚æ­¤å¤–ï¼Œé€šè¿‡å°†ä»»åŠ¡åˆ†è§£ä¸ºä¸å˜éƒ¨åˆ†å’Œå¯å˜éƒ¨åˆ†ï¼Œå¹¶åˆ©ç”¨è§†è§‰ä¿¡æ¯è¿›è¡Œå¯¹é½ï¼ŒBiDemoSynèƒ½å¤Ÿæ›´å¥½åœ°æ³›åŒ–åˆ°æ–°çš„å¯¹è±¡å§¿æ€å’Œå½¢çŠ¶ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è§†è§‰å¼•å¯¼å¯¹é½é˜¶æ®µï¼Œè®ºæ–‡å¯èƒ½ä½¿ç”¨äº†åŸºäºè§†è§‰çš„ä½å§¿ä¼°è®¡æ–¹æ³•ï¼Œä¾‹å¦‚ä½¿ç”¨æ·±åº¦ç›¸æœºè·å–å¯¹è±¡çš„3Dæ¨¡å‹ï¼Œå¹¶ä½¿ç”¨ç‚¹äº‘é…å‡†ç®—æ³•å°†åŸå§‹æ¼”ç¤ºä¸­çš„å¯¹è±¡ä¸æ–°çš„å¯¹è±¡è¿›è¡Œå¯¹é½ã€‚åœ¨è½¨è¿¹ä¼˜åŒ–é˜¶æ®µï¼Œå¯èƒ½ä½¿ç”¨äº†åŸºäºä¼˜åŒ–çš„è¿åŠ¨è§„åˆ’æ–¹æ³•ï¼Œä¾‹å¦‚ä½¿ç”¨çº¦æŸä¼˜åŒ–å™¨æ¥ç¡®ä¿è½¨è¿¹çš„ç‰©ç†å¯è¡Œæ€§ï¼ˆä¾‹å¦‚ï¼Œé¿å…ç¢°æ’ã€æ»¡è¶³å…³èŠ‚åŠ›çŸ©é™åˆ¶ï¼‰ã€‚æŸå¤±å‡½æ•°å¯èƒ½åŒ…æ‹¬å¹³æ»‘æ€§æŸå¤±ã€æ¥è¿‘ç›®æ ‡æŸå¤±å’Œé¿å…ç¢°æ’æŸå¤±ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨å…­ä¸ªä¸åŒçš„åŒè‡‚æ“ä½œä»»åŠ¡ä¸­ï¼Œä½¿ç”¨BiDemoSynç”Ÿæˆçš„æ•°æ®è®­ç»ƒçš„ç­–ç•¥ï¼Œåœ¨é¢å¯¹æ–°çš„ç‰©ä½“å§¿æ€å’Œå½¢çŠ¶æ—¶ï¼Œè¡¨ç°å‡ºæ˜¾è‘—çš„æ³›åŒ–èƒ½åŠ›ï¼Œæ€§èƒ½æ˜æ˜¾ä¼˜äºç°æœ‰çš„åŸºçº¿æ–¹æ³•ã€‚å…·ä½“æå‡å¹…åº¦æœªçŸ¥ï¼Œä½†æ‘˜è¦ä¸­æ˜ç¡®æŒ‡å‡ºæ˜¯â€œsignificantly outperforming recent baselinesâ€ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

BiDemoSynä¸ºæœºå™¨äººåŒè‡‚æ“ä½œçš„æ¨¡ä»¿å­¦ä¹ æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å®ç”¨çš„æ•°æ®ç”Ÿæˆæ–¹æ³•ï¼Œå¯å¹¿æ³›åº”ç”¨äºå·¥ä¸šè‡ªåŠ¨åŒ–ã€å®¶åº­æœåŠ¡æœºå™¨äººç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œå¯ä»¥ç”¨äºè®­ç»ƒæœºå™¨äººå®Œæˆè£…é…ã€æŠ“å–ã€æ”¾ç½®ç­‰å¤æ‚ä»»åŠ¡ï¼Œæé«˜æœºå™¨äººçš„çµæ´»æ€§å’Œé€‚åº”æ€§ã€‚è¯¥æ–¹æ³•é™ä½äº†å¯¹å¤§é‡äººå·¥æ¼”ç¤ºçš„ä¾èµ–ï¼Œæœ‰æœ›åŠ é€Ÿæœºå™¨äººæŠ€æœ¯åœ¨å®é™…åœºæ™¯ä¸­çš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Learning dexterous bimanual manipulation policies critically depends on large-scale, high-quality demonstrations, yet current paradigms face inherent trade-offs: teleoperation provides physically grounded data but is prohibitively labor-intensive, while simulation-based synthesis scales efficiently but suffers from sim-to-real gaps. We present BiDemoSyn, a framework that synthesizes contact-rich, physically feasible bimanual demonstrations from a single real-world example. The key idea is to decompose tasks into invariant coordination blocks and variable, object-dependent adjustments, then adapt them through vision-guided alignment and lightweight trajectory optimization. This enables the generation of thousands of diverse and feasible demonstrations within several hour, without repeated teleoperation or reliance on imperfect simulation. Across six dual-arm tasks, we show that policies trained on BiDemoSyn data generalize robustly to novel object poses and shapes, significantly outperforming recent baselines. By bridging the gap between efficiency and real-world fidelity, BiDemoSyn provides a scalable path toward practical imitation learning for complex bimanual manipulation without compromising physical grounding.

