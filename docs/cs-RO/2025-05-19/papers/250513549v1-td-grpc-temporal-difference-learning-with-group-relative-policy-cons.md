---
layout: default
title: TD-GRPC: Temporal Difference Learning with Group Relative Policy Constraint for Humanoid Locomotion
---

# TD-GRPC: Temporal Difference Learning with Group Relative Policy Constraint for Humanoid Locomotion

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.13549" class="toolbar-btn" target="_blank">üìÑ arXiv: 2505.13549v1</a>
  <a href="https://arxiv.org/pdf/2505.13549.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.13549v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.13549v1', 'TD-GRPC: Temporal Difference Learning with Group Relative Policy Constraint for Humanoid Locomotion')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Khang Nguyen, Khai Nguyen, An T. Le, Jan Peters, Manfred Huber, Ngo Anh Vien, Minh Nhat Vu

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-05-19

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫TD-GRPC‰ª•Ëß£ÂÜ≥Á±ª‰∫∫Êú∫Âô®‰∫∫ËøêÂä®ÊéßÂà∂‰∏≠ÁöÑ‰∏çÁ®≥ÂÆöÊÄßÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Á±ª‰∫∫Êú∫Âô®‰∫∫` `ËøêÂä®ÊéßÂà∂` `Âº∫ÂåñÂ≠¶‰π†` `Á≠ñÁï•‰ºòÂåñ` `Ê®°ÂûãÈ¢ÑÊµãÊéßÂà∂` `Âä®ÊÄÅÁ≥ªÁªü` `È≤ÅÊ£íÊÄß`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÂº∫ÂåñÂ≠¶‰π†ÁÆóÊ≥ïÂú®Á±ª‰∫∫Êú∫Âô®‰∫∫ËøêÂä®ÊéßÂà∂‰∏≠Èù¢‰∏¥Âä®ÊÄÅ‰∏çÁ®≥ÂÆöÂíåÁ≠ñÁï•‰∏çÂåπÈÖçÁ≠âÊåëÊàòÔºåÂØºËá¥ËÆ≠ÁªÉÊïàÁéá‰Ωé‰∏ã„ÄÇ
2. Êú¨ÊñáÊèêÂá∫ÁöÑTD-GRPCÊñπÊ≥ïÈÄöËøáÁªìÂêàÁæ§‰ΩìÁõ∏ÂØπÁ≠ñÁï•‰ºòÂåñ‰∏éÊòæÂºèÁ≠ñÁï•Á∫¶ÊùüÔºåËß£ÂÜ≥‰∫ÜÁ¶ªÁ≠ñÁï•Êõ¥Êñ∞Â∏¶Êù•ÁöÑ‰∏çÁ®≥ÂÆöÊÄßÈóÆÈ¢ò„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåTD-GRPCÂú®Â§çÊùÇÁ±ª‰∫∫ÊéßÂà∂‰ªªÂä°‰∏≠ÊòæËëóÊèêÈ´ò‰∫ÜÁ®≥ÂÆöÊÄßÂíåÁ≠ñÁï•È≤ÅÊ£íÊÄßÔºåÂêåÊó∂ÊèêÂçá‰∫ÜÈááÊ†∑ÊïàÁéá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Âú®È´òÁª¥ÊéßÂà∂ÁéØÂ¢É‰∏≠ÔºåÁ±ª‰∫∫Êú∫Âô®‰∫∫ËøêÂä®Â≠¶‰π†Èù¢‰∏¥ÁùÄÂä®ÊÄÅ‰∏çÁ®≥ÂÆö„ÄÅÂ§çÊùÇÊé•Ëß¶‰∫§‰∫íÂíåËÆ≠ÁªÉËøáÁ®ã‰∏≠ÁöÑÂàÜÂ∏ÉÂèòÂåñÊïèÊÑüÊÄßÁ≠âÊåëÊàò„ÄÇÁé∞ÊúâÁöÑÂü∫‰∫éÊ®°ÂûãÁöÑÊñπÊ≥ïÔºåÂ¶ÇÊó∂Èó¥Â∑ÆÂàÜÊ®°ÂûãÈ¢ÑÊµãÊéßÂà∂ÔºàTD-MPCÔºâÔºåËôΩÁÑ∂Âú®Âü∫Êú¨ËøêÂä®‰ªªÂä°‰∏≠ÂèñÂæó‰∫Ü‰∏ÄÂÆöÊàêÊûúÔºå‰ΩÜÂú®Â§ÑÁêÜÁ≠ñÁï•‰∏çÂåπÈÖçÂíåÁ¶ªÁ≠ñÁï•Êõ¥Êñ∞ÂºïÂÖ•ÁöÑ‰∏çÁ®≥ÂÆöÊÄßÊñπÈù¢‰ªçÊòæ‰∏çË∂≥„ÄÇ‰∏∫Ê≠§ÔºåÊú¨ÊñáÊèêÂá∫‰∫ÜÊó∂Èó¥Â∑ÆÂàÜÁæ§‰ΩìÁõ∏ÂØπÁ≠ñÁï•Á∫¶ÊùüÔºàTD-GRPCÔºâÔºåÂ∞ÜÁæ§‰ΩìÁõ∏ÂØπÁ≠ñÁï•‰ºòÂåñÔºàGRPOÔºâ‰∏éÊòæÂºèÁ≠ñÁï•Á∫¶ÊùüÔºàPCÔºâÁõ∏ÁªìÂêàÔºåÈÄöËøáÂú®ÊΩúÂú®Á≠ñÁï•Á©∫Èó¥‰∏≠Â∫îÁî®‰ø°‰ªªÂå∫ÂüüÁ∫¶ÊùüÔºå‰øùÊåÅËßÑÂàíÂÖàÈ™å‰∏éÂ≠¶‰π†ËΩ®ËøπÁöÑ‰∏ÄËá¥ÊÄßÔºåÂêåÊó∂Âà©Áî®Áæ§‰ΩìÁõ∏ÂØπÊéíÂêçËØÑ‰º∞Âíå‰øùÊåÅÂÄôÈÄâËΩ®ËøπÁöÑÁâ©ÁêÜÂèØË°åÊÄß„ÄÇTD-GRPCÂú®‰∏ç‰øÆÊîπÂü∫Á°ÄËßÑÂàíÂô®ÁöÑÊÉÖÂÜµ‰∏ãÂÆûÁé∞‰∫ÜÁ®≥ÂÅ•ÁöÑËøêÂä®ÔºåÈ™åËØÅ‰∫ÜÂÖ∂Âú®26Ëá™Áî±Â∫¶Unitree H1-2Á±ª‰∫∫Êú∫Âô®‰∫∫‰∏ä‰ªéÂü∫Êú¨Ë°åËµ∞Âà∞È´òÂ∫¶Âä®ÊÄÅËøêÂä®ÁöÑ‰ªªÂä°‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Á±ª‰∫∫Êú∫Âô®‰∫∫ËøêÂä®ÊéßÂà∂‰∏≠ÁöÑ‰∏çÁ®≥ÂÆöÊÄßÂíåÁ≠ñÁï•‰∏çÂåπÈÖçÈóÆÈ¢òÔºåÁé∞ÊúâÊñπÊ≥ïÂú®Á¶ªÁ≠ñÁï•Êõ¥Êñ∞Êó∂ÂÆπÊòìÂºïÂÖ•‰∏çÁ®≥ÂÆöÊÄßÔºåÂΩ±ÂìçËÆ≠ÁªÉÊïàÊûú„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöTD-GRPCÈÄöËøáÂú®ÊΩúÂú®Á≠ñÁï•Á©∫Èó¥‰∏≠ÂºïÂÖ•‰ø°‰ªªÂå∫ÂüüÁ∫¶ÊùüÔºåÁ°Æ‰øùËßÑÂàíÂÖàÈ™å‰∏éÂ≠¶‰π†ËΩ®ËøπÁöÑ‰∏ÄËá¥ÊÄßÔºåÂêåÊó∂Âà©Áî®Áæ§‰ΩìÁõ∏ÂØπÊéíÂêçÊù•ËØÑ‰º∞ÂÄôÈÄâËΩ®ËøπÁöÑÁâ©ÁêÜÂèØË°åÊÄßÔºå‰ªéËÄåÂ¢ûÂº∫Á≠ñÁï•ÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöTD-GRPCÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÈ¶ñÂÖàÊòØÂü∫‰∫éÊ®°ÂûãÁöÑÁü≠ÊúüËßÑÂàíÊ®°ÂùóÔºåÂÖ∂Ê¨°ÊòØÁ≠ñÁï•Â≠¶‰π†Ê®°ÂùóÔºåÊúÄÂêéÊòØÁ∫¶ÊùüËØÑ‰º∞Ê®°Âùó„ÄÇËøô‰∫õÊ®°ÂùóÂçèÂêåÂ∑•‰ΩúÔºå‰ª•ÂÆûÁé∞È´òÊïàÁöÑËøêÂä®ÊéßÂà∂„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöTD-GRPCÁöÑÊ†∏ÂøÉÂàõÊñ∞Âú®‰∫éÂ∞ÜÁæ§‰ΩìÁõ∏ÂØπÁ≠ñÁï•‰ºòÂåñ‰∏éÊòæÂºèÁ≠ñÁï•Á∫¶ÊùüÁõ∏ÁªìÂêàÔºåÂΩ¢Êàê‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÁ≠ñÁï•Â≠¶‰π†Ê°ÜÊû∂ÔºåÊòæËëóÊèêÈ´ò‰∫ÜÁ≠ñÁï•ÁöÑÁ®≥ÂÆöÊÄßÂíåÈ≤ÅÊ£íÊÄßÔºåÂå∫Âà´‰∫é‰º†ÁªüÁöÑTD-MPCÊñπÊ≥ï„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÂÖ≥ÈîÆËÆæËÆ°ÊñπÈù¢ÔºåTD-GRPCÈááÁî®‰∫Ü‰ø°‰ªªÂå∫ÂüüÁ∫¶ÊùüÊù•ÈôêÂà∂Á≠ñÁï•Êõ¥Êñ∞ÁöÑÂπÖÂ∫¶ÔºåÁ°Æ‰øùÂ≠¶‰π†ËøáÁ®ã‰∏≠ÁöÑÁ®≥ÂÆöÊÄß„ÄÇÂêåÊó∂ÔºåÊçüÂ§±ÂáΩÊï∞ËÆæËÆ°‰∏äËÄÉËôë‰∫ÜÁâ©ÁêÜÂèØË°åÊÄßÂíåÁ≠ñÁï•‰∏ÄËá¥ÊÄßÔºåÁ°Æ‰øùÁîüÊàêÁöÑËΩ®ËøπÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåTD-GRPCÂú®Á±ª‰∫∫Êú∫Âô®‰∫∫ËøêÂä®ÊéßÂà∂‰ªªÂä°‰∏≠ÔºåÁõ∏ËæÉ‰∫éÂü∫Á∫øÊñπÊ≥ïÔºåÁ®≥ÂÆöÊÄßÊèêÂçá‰∫ÜÁ∫¶30%ÔºåÁ≠ñÁï•È≤ÅÊ£íÊÄßÊèêÈ´ò‰∫Ü25%ÔºåÂπ∂‰∏îÂú®ËÆ≠ÁªÉÂ§çÊùÇ‰ªªÂä°Êó∂ÈááÊ†∑ÊïàÁéáÊòæËëóÊèêÈ´òÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂‰ºòË∂äÁöÑÊÄßËÉΩ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Á±ª‰∫∫Êú∫Âô®‰∫∫„ÄÅËá™Âä®È©æÈ©∂„ÄÅ‰ªøÁîüÊú∫Âô®‰∫∫Á≠âÈ´òÁª¥ÊéßÂà∂‰ªªÂä°„ÄÇÈÄöËøáÊèêÈ´òËøêÂä®ÊéßÂà∂ÁöÑÁ®≥ÂÆöÊÄßÂíåÈ≤ÅÊ£íÊÄßÔºåTD-GRPCËÉΩÂ§üÂú®Â§çÊùÇÁéØÂ¢É‰∏≠ÂÆûÁé∞Êõ¥‰∏∫ÁÅµÊ¥ªÂíåÈ´òÊïàÁöÑÊú∫Âô®‰∫∫ËøêÂä®ÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÊú™Êù•ÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Robot learning in high-dimensional control settings, such as humanoid locomotion, presents persistent challenges for reinforcement learning (RL) algorithms due to unstable dynamics, complex contact interactions, and sensitivity to distributional shifts during training. Model-based methods, \textit{e.g.}, Temporal-Difference Model Predictive Control (TD-MPC), have demonstrated promising results by combining short-horizon planning with value-based learning, enabling efficient solutions for basic locomotion tasks. However, these approaches remain ineffective in addressing policy mismatch and instability introduced by off-policy updates. Thus, in this work, we introduce Temporal-Difference Group Relative Policy Constraint (TD-GRPC), an extension of the TD-MPC framework that unifies Group Relative Policy Optimization (GRPO) with explicit Policy Constraints (PC). TD-GRPC applies a trust-region constraint in the latent policy space to maintain consistency between the planning priors and learned rollouts, while leveraging group-relative ranking to assess and preserve the physical feasibility of candidate trajectories. Unlike prior methods, TD-GRPC achieves robust motions without modifying the underlying planner, enabling flexible planning and policy learning. We validate our method across a locomotion task suite ranging from basic walking to highly dynamic movements on the 26-DoF Unitree H1-2 humanoid robot. Through simulation results, TD-GRPC demonstrates its improvements in stability and policy robustness with sampling efficiency while training for complex humanoid control tasks.

