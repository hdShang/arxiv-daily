---
layout: default
title: GraspMolmo: Generalizable Task-Oriented Grasping via Large-Scale Synthetic Data Generation
---

# GraspMolmo: Generalizable Task-Oriented Grasping via Large-Scale Synthetic Data Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.13441" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.13441v3</a>
  <a href="https://arxiv.org/pdf/2505.13441.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.13441v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.13441v3', 'GraspMolmo: Generalizable Task-Oriented Grasping via Large-Scale Synthetic Data Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Abhay Deshpande, Yuquan Deng, Arijit Ray, Jordi Salvador, Winson Han, Jiafei Duan, Kuo-Hao Zeng, Yuke Zhu, Ranjay Krishna, Rose Hendrix

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-05-19 (æ›´æ–°: 2025-09-12)

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://abhaybd.github.io/GraspMolmo/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGraspMolmoä»¥è§£å†³ä»»åŠ¡å¯¼å‘æŠ“å–çš„æ³›åŒ–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `ä»»åŠ¡å¯¼å‘æŠ“å–` `è‡ªç„¶è¯­è¨€å¤„ç†` `åˆæˆæ•°æ®é›†` `è§†è§‰è¯­è¨€æ¨¡å‹` `æœºå™¨äººæ“ä½œ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ä»»åŠ¡å¯¼å‘æŠ“å–æ–¹æ³•å—é™äºå°å‹æ•°æ®é›†å’Œç®€å•çš„è¯­è¨€æè¿°ï¼Œå¯¼è‡´æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚
2. GraspMolmoé€šè¿‡å¤§è§„æ¨¡åˆæˆæ•°æ®é›†PRISMè¿›è¡Œè®­ç»ƒï¼Œèƒ½å¤Ÿæ ¹æ®è‡ªç„¶è¯­è¨€æŒ‡ä»¤ç”Ÿæˆç¨³å®šçš„æŠ“å–ç­–ç•¥ã€‚
3. åœ¨çœŸå®ä¸–ç•Œè¯„ä¼°ä¸­ï¼ŒGraspMolmoåœ¨å¤æ‚ä»»åŠ¡ä¸Šå®ç°äº†70%çš„æˆåŠŸç‡ï¼Œæ˜¾è‘—ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬æå‡ºäº†GraspMolmoï¼Œä¸€ä¸ªå¯æ³›åŒ–çš„å¼€æ”¾è¯æ±‡ä»»åŠ¡å¯¼å‘æŠ“å–æ¨¡å‹ã€‚GraspMolmoèƒ½å¤Ÿæ ¹æ®è‡ªç„¶è¯­è¨€æŒ‡ä»¤å’Œå•ä¸ªRGB-Då¸§é¢„æµ‹è¯­ä¹‰ä¸Šåˆé€‚ä¸”ç¨³å®šçš„æŠ“å–ã€‚ä¾‹å¦‚ï¼Œç»™å®šæŒ‡ä»¤â€œç»™æˆ‘å€’äº›èŒ¶â€ï¼ŒGraspMolmoä¼šé€‰æ‹©æŠ“å–èŒ¶å£¶çš„æŠŠæ‰‹è€Œéå£¶èº«ã€‚ä¸ä»¥å¾€å—é™äºå°å‹æ•°æ®é›†ã€ç®€å•è¯­è¨€å’Œæ•´æ´åœºæ™¯çš„TOGæ–¹æ³•ä¸åŒï¼ŒGraspMolmoä»PRISMè¿™ä¸€æ–°å‹å¤§è§„æ¨¡åˆæˆæ•°æ®é›†ä¸­å­¦ä¹ ï¼Œè¯¥æ•°æ®é›†åŒ…å«379kæ ·æœ¬ï¼Œæ¶µç›–äº†æ‚ä¹±ç¯å¢ƒå’Œå¤šæ ·åŒ–çš„ä»»åŠ¡æè¿°ã€‚æˆ‘ä»¬åœ¨æ­¤æ•°æ®é›†ä¸Šå¾®è°ƒäº†Molmoè§†è§‰è¯­è¨€æ¨¡å‹ï¼Œä½¿GraspMolmoèƒ½å¤Ÿæ³›åŒ–åˆ°æ–°çš„å¼€æ”¾è¯æ±‡æŒ‡ä»¤å’Œç‰©ä½“ã€‚åœ¨å¤æ‚ä»»åŠ¡çš„çœŸå®ä¸–ç•Œè¯„ä¼°ä¸­ï¼ŒGraspMolmoå®ç°äº†70%çš„é¢„æµ‹æˆåŠŸç‡ï¼Œè€Œæ¬¡ä¼˜æ–¹æ³•ä»…ä¸º35%ã€‚GraspMolmoè¿˜æˆåŠŸå±•ç¤ºäº†é›¶æ ·æœ¬é¢„æµ‹è¯­ä¹‰æ­£ç¡®çš„åŒæ‰‹æŠ“å–èƒ½åŠ›ã€‚æˆ‘ä»¬å‘å¸ƒäº†åˆæˆæ•°æ®é›†ã€ä»£ç ã€æ¨¡å‹å’ŒåŸºå‡†ï¼Œä»¥åŠ é€Ÿä»»åŠ¡è¯­ä¹‰æœºå™¨äººæ“ä½œçš„ç ”ç©¶ï¼Œç›¸å…³è§†é¢‘å¯åœ¨https://abhaybd.github.io/GraspMolmo/è·å–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ä»»åŠ¡å¯¼å‘æŠ“å–ï¼ˆTOGï¼‰æ¨¡å‹åœ¨å¤æ‚ç¯å¢ƒä¸­å¯¹è‡ªç„¶è¯­è¨€æŒ‡ä»¤çš„æ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºå°å‹æ•°æ®é›†ï¼Œå¯¼è‡´å…¶åœ¨å¤šæ ·åŒ–åœºæ™¯ä¸­çš„è¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šGraspMolmoçš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡å¤§è§„æ¨¡åˆæˆæ•°æ®é›†PRISMè¿›è¡Œè®­ç»ƒï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿç†è§£å¹¶æ‰§è¡Œå¼€æ”¾è¯æ±‡çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼Œä»è€Œæé«˜æŠ“å–çš„å‡†ç¡®æ€§å’Œç¨³å®šæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šGraspMolmoçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚é¦–å…ˆï¼Œåˆ©ç”¨PRISMæ•°æ®é›†è¿›è¡Œæ¨¡å‹çš„è®­ç»ƒï¼Œæ¥ç€é€šè¿‡å¾®è°ƒMolmoè§†è§‰è¯­è¨€æ¨¡å‹æ¥å¢å¼ºå…¶å¯¹æŒ‡ä»¤çš„ç†è§£èƒ½åŠ›ï¼Œæœ€ååœ¨çœŸå®åœºæ™¯ä¸­è¿›è¡Œè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šGraspMolmoçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶ä½¿ç”¨äº†å¤§è§„æ¨¡åˆæˆæ•°æ®é›†PRISMï¼ŒåŒ…å«379kæ ·æœ¬ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡æ¨¡å‹åœ¨å¤æ‚å’Œæ‚ä¹±ç¯å¢ƒä¸­çš„æŠ“å–èƒ½åŠ›ã€‚è¿™ä¸€æ–¹æ³•ä¸ä»¥å¾€ä¾èµ–å°å‹æ•°æ®é›†çš„TOGæ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸Šï¼ŒGraspMolmoé‡‡ç”¨äº†å…ˆè¿›çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œå¹¶é€šè¿‡ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æŠ“å–ç­–ç•¥çš„ç¨³å®šæ€§å’Œå‡†ç¡®æ€§ã€‚å…³é”®å‚æ•°è®¾ç½®ç»è¿‡å¤šæ¬¡å®éªŒè°ƒæ•´ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨å¤šæ ·åŒ–ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

GraspMolmoåœ¨å¤æ‚ä»»åŠ¡çš„çœŸå®ä¸–ç•Œè¯„ä¼°ä¸­å®ç°äº†70%çš„é¢„æµ‹æˆåŠŸç‡ï¼Œæ˜¾è‘—é«˜äºæ¬¡ä¼˜æ–¹æ³•çš„35%ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹è¿˜å±•ç¤ºäº†é›¶æ ·æœ¬é¢„æµ‹è¯­ä¹‰æ­£ç¡®çš„åŒæ‰‹æŠ“å–èƒ½åŠ›ï¼Œæ˜¾ç¤ºå‡ºå…¶å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

GraspMolmoçš„ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºæœåŠ¡æœºå™¨äººã€å®¶åº­è‡ªåŠ¨åŒ–ã€å·¥ä¸šæœºå™¨äººç­‰é¢†åŸŸï¼Œèƒ½å¤Ÿæå‡æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„æŠ“å–èƒ½åŠ›å’Œä»»åŠ¡æ‰§è¡Œæ•ˆç‡ã€‚æœªæ¥ï¼Œè¯¥æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å¯èƒ½æ¨åŠ¨æ›´å¤šæ™ºèƒ½æœºå™¨äººåœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­çš„åº”ç”¨ï¼Œå¢å¼ºäººæœºäº¤äº’çš„è‡ªç„¶æ€§å’Œæ™ºèƒ½æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present GrasMolmo, a generalizable open-vocabulary task-oriented grasping (TOG) model. GraspMolmo predicts semantically appropriate, stable grasps conditioned on a natural language instruction and a single RGB-D frame. For instance, given "pour me some tea", GraspMolmo selects a grasp on a teapot handle rather than its body. Unlike prior TOG methods, which are limited by small datasets, simplistic language, and uncluttered scenes, GraspMolmo learns from PRISM, a novel large-scale synthetic dataset of 379k samples featuring cluttered environments and diverse, realistic task descriptions. We fine-tune the Molmo visual-language model on this data, enabling GraspMolmo to generalize to novel open-vocabulary instructions and objects. In challenging real-world evaluations, GraspMolmo achieves state-of-the-art results, with a 70% prediction success on complex tasks, compared to the 35% achieved by the next best alternative. GraspMolmo also successfully demonstrates the ability to predict semantically correct bimanual grasps zero-shot. We release our synthetic dataset, code, model, and benchmarks to accelerate research in task-semantic robotic manipulation, which, along with videos, are available at https://abhaybd.github.io/GraspMolmo/.

