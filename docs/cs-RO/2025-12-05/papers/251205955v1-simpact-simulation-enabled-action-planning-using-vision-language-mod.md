---
layout: default
title: SIMPACT: Simulation-Enabled Action Planning using Vision-Language Models
---

# SIMPACT: Simulation-Enabled Action Planning using Vision-Language Models

**arXiv**: [2512.05955v1](https://arxiv.org/abs/2512.05955) | [PDF](https://arxiv.org/pdf/2512.05955.pdf)

**ä½œè€…**: Haowen Liu, Shaoxiong Yao, Haonan Chen, Jiawei Gao, Jiayuan Mao, Jia-Bin Huang, Yilun Du

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-05

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**SIMPACTï¼šåˆ©ç”¨è§†è§‰-è¯­è¨€æ¨¡åž‹å’Œä»¿çœŸè¿›è¡ŒåŠ¨ä½œè§„åˆ’ï¼Œè§£å†³æœºå™¨äººæ“ä½œä¸­ç‰©ç†ç†è§£ä¸è¶³çš„é—®é¢˜**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€æ¨¡åž‹` `æœºå™¨äººæ“ä½œ` `ç‰©ç†ä»¿çœŸ` `åŠ¨ä½œè§„åˆ’` `å…·èº«æ™ºèƒ½` `ç‰©ç†æŽ¨ç†` `ä»¿çœŸå¾ªçŽ¯` `RGB-Dæ„ŸçŸ¥`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è§†è§‰-è¯­è¨€æ¨¡åž‹ç¼ºä¹å¯¹ç‰©ç†åŠ¨æ€çš„å…·èº«ç†è§£ï¼Œéš¾ä»¥åº”ç”¨äºŽéœ€è¦ç‰©ç†æŽ¨ç†çš„æœºå™¨äººæ“ä½œä»»åŠ¡ã€‚
2. SIMPACTé€šè¿‡åœ¨æµ‹è¯•æ—¶æž„å»ºä»¿çœŸçŽ¯å¢ƒï¼Œè®©VLMåœ¨ä»¿çœŸä¸­è¿›è¡ŒåŠ¨ä½œè§„åˆ’å’ŒæŽ¨ç†ï¼Œä»Žè€Œèµ‹äºˆå…¶ç‰©ç†ç†è§£èƒ½åŠ›ã€‚
3. SIMPACTåœ¨çœŸå®žä¸–ç•Œçš„åˆšä½“å’Œå¯å˜å½¢ä½“æ“ä½œä»»åŠ¡ä¸Šå–å¾—äº†ä¼˜äºŽçŽ°æœ‰æ–¹æ³•çš„æ€§èƒ½ï¼Œè¯æ˜Žäº†å…¶æœ‰æ•ˆæ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€æ¨¡åž‹(VLMs)å±•çŽ°äº†å“è¶Šçš„å¸¸è¯†å’Œè¯­ä¹‰æŽ¨ç†èƒ½åŠ›ï¼Œä½†ç¼ºä¹å¯¹ç‰©ç†åŠ¨æ€çš„å…·èº«ç†è§£ã€‚è¿™æ˜¯å› ä¸ºVLMsåœ¨é™æ€çš„äº’è”ç½‘è§„æ¨¡è§†è§‰-è¯­è¨€æ•°æ®ä¸Šè®­ç»ƒï¼Œè¿™äº›æ•°æ®ä¸åŒ…å«å› æžœäº¤äº’æˆ–åŠ¨ä½œæ¡ä»¶ä¸‹çš„å˜åŒ–ã€‚å› æ­¤ï¼Œå°†VLMsç”¨äºŽéœ€è¦ç‰©ç†ç†è§£ã€æŽ¨ç†å’Œç›¸åº”åŠ¨ä½œè§„åˆ’çš„ç²¾ç»†æœºå™¨äººæ“ä½œä»»åŠ¡ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ä¸ºäº†å…‹æœè¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬æå‡ºäº†SIMPACTï¼Œè¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ—¶ã€åŸºäºŽä»¿çœŸçš„åŠ¨ä½œè§„åˆ’æ¡†æž¶ï¼Œé€šè¿‡ä»¿çœŸå¾ªçŽ¯ä¸–ç•Œå»ºæ¨¡èµ‹äºˆVLMsç‰©ç†æŽ¨ç†èƒ½åŠ›ï¼Œè€Œæ— éœ€ä»»ä½•é¢å¤–çš„è®­ç»ƒã€‚ä»Žå•ä¸ªRGB-Dè§‚æµ‹ä¸­ï¼ŒSIMPACTæœ‰æ•ˆåœ°æž„å»ºç‰©ç†ä»¿çœŸï¼Œä½¿VLMèƒ½å¤Ÿæå‡ºæ˜Žæ™ºçš„åŠ¨ä½œï¼Œè§‚å¯Ÿæ¨¡æ‹Ÿçš„rolloutï¼Œå¹¶è¿­ä»£åœ°æ”¹è¿›å…¶æŽ¨ç†ã€‚é€šè¿‡å°†è¯­è¨€æŽ¨ç†ä¸Žç‰©ç†é¢„æµ‹ç›¸ç»“åˆï¼Œæˆ‘ä»¬åŸºäºŽä»¿çœŸçš„VLMèƒ½å¤Ÿä»¥ç‰©ç†å…·èº«çš„æ–¹å¼ç†è§£æŽ¥è§¦åŠ¨åŠ›å­¦å’ŒåŠ¨ä½œç»“æžœã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨äº”ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„çœŸå®žåˆšä½“å’Œå¯å˜å½¢ä½“æ“ä½œä»»åŠ¡ä¸Šè¡¨çŽ°å‡ºæœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè¿™äº›ä»»åŠ¡éœ€è¦ç²¾ç»†çš„ç‰©ç†æŽ¨ç†ï¼Œä¼˜äºŽçŽ°æœ‰çš„é€šç”¨æœºå™¨äººæ“ä½œæ¨¡åž‹ã€‚æˆ‘ä»¬çš„ç»“æžœè¡¨æ˜Žï¼Œåœ¨æµ‹è¯•æ—¶é€šè¿‡é«˜æ•ˆä»¿çœŸå°†ç‰©ç†ç†è§£åµŒå…¥åˆ°VLMæŽ¨ç†ä¸­ï¼Œä¸ºå®žçŽ°é€šç”¨å…·èº«æ™ºèƒ½æä¾›äº†ä¸€æ¡æœ‰å¸Œæœ›çš„é€”å¾„ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è§†è§‰-è¯­è¨€æ¨¡åž‹ï¼ˆVLMsï¼‰åœ¨æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­ç”±äºŽç¼ºä¹ç‰©ç†ä¸–ç•Œç†è§£è€Œè¡¨çŽ°ä¸ä½³çš„é—®é¢˜ã€‚çŽ°æœ‰çš„VLMsä¸»è¦åœ¨é™æ€å›¾åƒå’Œæ–‡æœ¬æ•°æ®ä¸Šè®­ç»ƒï¼Œç¼ºä¹å¯¹åŠ¨ä½œä¸ŽçŽ¯å¢ƒäº¤äº’çš„å› æžœå…³ç³»å»ºæ¨¡èƒ½åŠ›ï¼Œå› æ­¤éš¾ä»¥è¿›è¡Œéœ€è¦ç²¾ç»†ç‰©ç†æŽ¨ç†çš„æœºå™¨äººæ“ä½œã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSIMPACTçš„æ ¸å¿ƒæ€è·¯æ˜¯åœ¨æµ‹è¯•æ—¶ï¼Œåˆ©ç”¨VLMè¿›è¡ŒåŠ¨ä½œè§„åˆ’çš„åŒæ—¶ï¼Œæž„å»ºä¸€ä¸ªä»¿çœŸçŽ¯å¢ƒï¼Œè®©VLMåœ¨ä»¿çœŸçŽ¯å¢ƒä¸­è¿›è¡Œrolloutï¼Œè§‚å¯ŸåŠ¨ä½œçš„ç‰©ç†æ•ˆæžœï¼Œå¹¶æ ¹æ®ä»¿çœŸç»“æžœè¿­ä»£ä¼˜åŒ–åŠ¨ä½œè§„åˆ’ã€‚é€šè¿‡è¿™ç§ä»¿çœŸå¾ªçŽ¯çš„æ–¹å¼ï¼Œèµ‹äºˆVLMç‰©ç†æŽ¨ç†èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£åŠ¨ä½œä¸ŽçŽ¯å¢ƒä¹‹é—´çš„äº¤äº’ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šSIMPACTçš„æ•´ä½“æ¡†æž¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) ä»ŽRGB-Då›¾åƒæž„å»ºç‰©ç†ä»¿çœŸçŽ¯å¢ƒï¼›2) VLMæ ¹æ®å½“å‰çŠ¶æ€æå‡ºå€™é€‰åŠ¨ä½œï¼›3) åœ¨ä»¿çœŸçŽ¯å¢ƒä¸­æ‰§è¡Œå€™é€‰åŠ¨ä½œï¼Œå¹¶è§‚å¯Ÿrolloutç»“æžœï¼›4) VLMæ ¹æ®rolloutç»“æžœè¯„ä¼°åŠ¨ä½œçš„ä¼˜åŠ£ï¼Œå¹¶è¿­ä»£ä¼˜åŒ–åŠ¨ä½œè§„åˆ’ã€‚è¿™ä¸ªè¿‡ç¨‹å¾ªçŽ¯è¿›è¡Œï¼Œç›´åˆ°æ‰¾åˆ°æœ€ä¼˜çš„åŠ¨ä½œåºåˆ—ã€‚

**å…³é”®åˆ›æ–°**ï¼šSIMPACTçš„å…³é”®åˆ›æ–°åœ¨äºŽå°†VLMçš„è¯­è¨€æŽ¨ç†èƒ½åŠ›ä¸Žç‰©ç†ä»¿çœŸç›¸ç»“åˆï¼Œåœ¨æµ‹è¯•æ—¶èµ‹äºˆVLMç‰©ç†ç†è§£èƒ½åŠ›ï¼Œè€Œæ— éœ€é¢å¤–çš„è®­ç»ƒã€‚è¿™ç§æ–¹æ³•å……åˆ†åˆ©ç”¨äº†VLMçš„è¯­ä¹‰æŽ¨ç†èƒ½åŠ›ï¼ŒåŒæ—¶å¼¥è¡¥äº†å…¶åœ¨ç‰©ç†ç†è§£æ–¹é¢çš„ä¸è¶³ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒSIMPACTä¸éœ€è¦é¢„å…ˆè®­ç»ƒä¸€ä¸ªå¤æ‚çš„ç‰©ç†æ¨¡åž‹ï¼Œè€Œæ˜¯é€šè¿‡åœ¨çº¿ä»¿çœŸæ¥å­¦ä¹ ç‰©ç†åŠ¨æ€ã€‚

**å…³é”®è®¾è®¡**ï¼šSIMPACTçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) å¦‚ä½•é«˜æ•ˆåœ°ä»ŽRGB-Då›¾åƒæž„å»ºç‰©ç†ä»¿çœŸçŽ¯å¢ƒï¼›2) å¦‚ä½•è®¾è®¡VLMçš„åŠ¨ä½œæè®®å’Œè¯„ä¼°æœºåˆ¶ï¼Œä½¿å…¶èƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨ä»¿çœŸç»“æžœè¿›è¡ŒåŠ¨ä½œè§„åˆ’ï¼›3) å¦‚ä½•å¹³è¡¡ä»¿çœŸç²¾åº¦å’Œè®¡ç®—æ•ˆçŽ‡ï¼Œä»¥ä¿è¯SIMPACTçš„å®žæ—¶æ€§ã€‚è®ºæ–‡ä¸­å¯èƒ½æ¶‰åŠä¸€äº›ç‰¹å®šçš„å‚æ•°è®¾ç½®ï¼Œä¾‹å¦‚ä»¿çœŸæ­¥é•¿ã€rollouté•¿åº¦ã€VLMçš„promptè®¾è®¡ç­‰ï¼Œä½†å…·ä½“ç»†èŠ‚éœ€è¦å‚è€ƒè®ºæ–‡åŽŸæ–‡ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

SIMPACTåœ¨äº”ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„çœŸå®žåˆšä½“å’Œå¯å˜å½¢ä½“æ“ä½œä»»åŠ¡ä¸Šå–å¾—äº†state-of-the-artçš„æ€§èƒ½ï¼Œè¶…è¶Šäº†çŽ°æœ‰çš„é€šç”¨æœºå™¨äººæ“ä½œæ¨¡åž‹ã€‚è¿™è¡¨æ˜Žé€šè¿‡åœ¨æµ‹è¯•æ—¶å°†ç‰©ç†ç†è§£åµŒå…¥åˆ°VLMæŽ¨ç†ä¸­ï¼Œå¯ä»¥æ˜¾è‘—æå‡æœºå™¨äººçš„æ“ä½œèƒ½åŠ›ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦éœ€è¦åœ¨è®ºæ–‡åŽŸæ–‡ä¸­æŸ¥æ‰¾ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

SIMPACTå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯åº”ç”¨äºŽå„ç§éœ€è¦ç²¾ç»†ç‰©ç†æŽ¨ç†çš„æœºå™¨äººæ“ä½œä»»åŠ¡ï¼Œä¾‹å¦‚ï¼šå®¶åº­æœåŠ¡æœºå™¨äººã€å·¥ä¸šè‡ªåŠ¨åŒ–ã€åŒ»ç–—æœºå™¨äººç­‰ã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºŽæå‡æœºå™¨äººåœ¨å¤æ‚çŽ¯å¢ƒä¸­çš„é€‚åº”æ€§å’Œæ“ä½œèƒ½åŠ›ï¼ŒæŽ¨åŠ¨æœºå™¨äººæŠ€æœ¯çš„æ™ºèƒ½åŒ–å‘å±•ï¼Œå¹¶æœ€ç»ˆå®žçŽ°é€šç”¨å…·èº«æ™ºèƒ½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Vision-Language Models (VLMs) exhibit remarkable common-sense and semantic reasoning capabilities. However, they lack a grounded understanding of physical dynamics. This limitation arises from training VLMs on static internet-scale visual-language data that contain no causal interactions or action-conditioned changes. Consequently, it remains challenging to leverage VLMs for fine-grained robotic manipulation tasks that require physical understanding, reasoning, and corresponding action planning. To overcome this, we present SIMPACT, a test-time, SIMulation-enabled ACTion Planning framework that equips VLMs with physical reasoning through simulation-in-the-loop world modeling, without requiring any additional training. From a single RGB-D observation, SIMPACT efficiently constructs physics simulations, enabling the VLM to propose informed actions, observe simulated rollouts, and iteratively refine its reasoning. By integrating language reasoning with physics prediction, our simulation-enabled VLM can understand contact dynamics and action outcomes in a physically grounded way. Our method demonstrates state-of-the-art performance on five challenging, real-world rigid-body and deformable manipulation tasks that require fine-grained physical reasoning, outperforming existing general-purpose robotic manipulation models. Our results demonstrate that embedding physics understanding via efficient simulation into VLM reasoning at test time offers a promising path towards generalizable embodied intelligence. Project webpage can be found at https://simpact-bot.github.io

