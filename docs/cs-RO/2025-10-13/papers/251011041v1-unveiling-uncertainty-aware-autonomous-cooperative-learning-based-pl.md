---
layout: default
title: Unveiling Uncertainty-Aware Autonomous Cooperative Learning Based Planning Strategy
---

# Unveiling Uncertainty-Aware Autonomous Cooperative Learning Based Planning Strategy

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.11041" target="_blank" class="toolbar-btn">arXiv: 2510.11041v1</a>
    <a href="https://arxiv.org/pdf/2510.11041.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.11041v1" 
            onclick="toggleFavorite(this, '2510.11041v1', 'Unveiling Uncertainty-Aware Autonomous Cooperative Learning Based Planning Strategy')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Shiyao Zhang, Liwei Deng, Shuyu Zhang, Weijie Yuan, Hong Zhang

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-13

**Â§áÊ≥®**: Accepted by IEEE RA-L

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫é‰∏çÁ°ÆÂÆöÊÄßÊÑüÁü•ÁöÑËá™‰∏ªÂçèÂêåÂ≠¶‰π†ËßÑÂàíÁ≠ñÁï•ÔºåÊèêÂçáÂ§öËΩ¶‰∫§‰∫íÁöÑÂÆâÂÖ®ÊÄßÂíåÊúâÊïàÊÄß„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Ëá™‰∏ªÂçèÂêåËßÑÂàí` `Ê∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†` `‰∏çÁ°ÆÂÆöÊÄßÊÑüÁü•` `ËΩØÊºîÂëò-ËØÑËÆ∫ÂÆ∂` `Èó®ÊéßÂæ™ÁéØÂçïÂÖÉ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËá™‰∏ªÂçèÂêåËßÑÂàíÊñπÊ≥ïÈöæ‰ª•ÂÖÖÂàÜËß£ÂÜ≥ÊÑüÁü•„ÄÅËßÑÂàíÂíåÈÄö‰ø°Á≠âÂ§öÁßç‰∏çÁ°ÆÂÆöÊÄßÂ∏¶Êù•ÁöÑÊåëÊàò„ÄÇ
2. ÊèêÂá∫‰∏ÄÁßçÂü∫‰∫éÊ∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†ÁöÑËá™‰∏ªÂçèÂêåËßÑÂàíÊ°ÜÊû∂ÔºåÂà©Áî®SACÁÆóÊ≥ïÂíåGRUÁΩëÁªúÂ≠¶‰π†‰∏çÁ°ÆÂÆöÁä∂ÊÄÅ‰∏ãÁöÑÊúÄ‰ºòÂä®‰Ωú„ÄÇ
3. Âú®CARLA‰ªøÁúüÂπ≥Âè∞‰∏äÈ™åËØÅ‰∫ÜËØ•ÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºåÁªìÊûúË°®ÊòéÂÖ∂ÊÄßËÉΩ‰ºò‰∫éÂÖ∂‰ªñÂü∫Á∫øÊñπÊ≥ï„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Âú®Êú™Êù•ÁöÑÊô∫ËÉΩ‰∫§ÈÄöÁ≥ªÁªü‰∏≠ÔºåËá™‰∏ªÂçèÂêåËßÑÂàí(ACP)ÊòØ‰∏ÄÁßçÂæàÊúâÂâçÊôØÁöÑÊäÄÊúØÔºåÂèØ‰ª•ÊèêÈ´òÂ§öËΩ¶ËæÜ‰∫§‰∫íÁöÑÊïàÁéáÂíåÂÆâÂÖ®ÊÄß„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÁöÑACPÁ≠ñÁï•Êó†Ê≥ïÂÆåÂÖ®Ëß£ÂÜ≥Â§öÁßç‰∏çÁ°ÆÂÆöÊÄßÔºå‰æãÂ¶ÇÊÑüÁü•„ÄÅËßÑÂàíÂíåÈÄö‰ø°ÁöÑ‰∏çÁ°ÆÂÆöÊÄß„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÊ∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†ÁöÑËá™‰∏ªÂçèÂêåËßÑÂàí(DRLACP)Ê°ÜÊû∂Ôºå‰ª•Â∫îÂØπÂçèÂêåËøêÂä®ËßÑÂàíÊñπÊ°à‰∏≠ÁöÑÂêÑÁßç‰∏çÁ°ÆÂÆöÊÄß„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåÈááÁî®Â∏¶ÊúâÈó®ÊéßÂæ™ÁéØÂçïÂÖÉ(GRU)ÁöÑËΩØÊºîÂëò-ËØÑËÆ∫ÂÆ∂(SAC)ÁÆóÊ≥ïÔºå‰ª•Â≠¶‰π†Áî±ËßÑÂàí„ÄÅÈÄö‰ø°ÂíåÊÑüÁü•‰∏çÁ°ÆÂÆöÊÄßÂºïËµ∑ÁöÑ‰∏çÂÆåÂñÑÁä∂ÊÄÅ‰ø°ÊÅØ‰∏ãÁöÑÁ°ÆÂÆöÊÄßÊúÄ‰ºòÊó∂ÂèòÂä®‰Ωú„ÄÇÊ≠§Â§ñÔºåËá™‰∏ªËΩ¶ËæÜ(AV)ÁöÑÂÆûÊó∂Âä®‰ΩúÈÄöËøáCar Learning to Act (CARLA)‰ªøÁúüÂπ≥Âè∞ËøõË°åÊºîÁ§∫„ÄÇËØÑ‰º∞ÁªìÊûúË°®ÊòéÔºåÊâÄÊèêÂá∫ÁöÑDRLACPËÉΩÂ§üÊúâÊïàÂú∞Â≠¶‰π†ÂíåÊâßË°åÂçèÂêåËßÑÂàíÔºåÂπ∂‰∏îÂú®ÂÖ∑Êúâ‰∏çÂÆåÂñÑAVÁä∂ÊÄÅ‰ø°ÊÅØÁöÑ‰∏çÂêåÂú∫ÊôØ‰∏ãÔºå‰ºò‰∫éÂÖ∂‰ªñÂü∫Á∫øÊñπÊ≥ï„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Â§öÊô∫ËÉΩ‰ΩìËá™‰∏ªÂçèÂêåËßÑÂàí‰∏≠ÔºåÁî±‰∫éÊÑüÁü•„ÄÅÈÄö‰ø°ÂíåËßÑÂàíÊú¨Ë∫´ÁöÑ‰∏çÁ°ÆÂÆöÊÄßÂØºËá¥ÁöÑËßÑÂàíÊÄßËÉΩ‰∏ãÈôçÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏ÂÅáËÆæÁéØÂ¢ÉÊòØÂÆåÂÖ®ÂèØËßÇÊµãÁöÑÔºåÊàñËÄÖÂøΩÁï•Ëøô‰∫õ‰∏çÁ°ÆÂÆöÊÄßÔºåÂØºËá¥Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÊïàÊûú‰∏ç‰Ω≥„ÄÇÂõ†Ê≠§ÔºåÂ¶Ç‰ΩïËÆæËÆ°‰∏ÄÁßçËÉΩÂ§üÊúâÊïàÂ§ÑÁêÜËøô‰∫õ‰∏çÁ°ÆÂÆöÊÄßÁöÑËá™‰∏ªÂçèÂêåËßÑÂàíÁ≠ñÁï•ÊòØÊú¨ÊñáË¶ÅËß£ÂÜ≥ÁöÑÂÖ≥ÈîÆÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Ê∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†(DRL)ÊñπÊ≥ïÔºåÈÄöËøáÂ≠¶‰π†ÁöÑÊñπÂºèÊù•ÈÄÇÂ∫îÂíåÂ§ÑÁêÜËøô‰∫õ‰∏çÁ°ÆÂÆöÊÄß„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÈááÁî®ËΩØÊºîÂëò-ËØÑËÆ∫ÂÆ∂(SAC)ÁÆóÊ≥ïÔºåËØ•ÁÆóÊ≥ïËÉΩÂ§üÂ≠¶‰π†ÈöèÊú∫Á≠ñÁï•Ôºå‰ªéËÄåÊõ¥Â•ΩÂú∞Êé¢Á¥¢ÁéØÂ¢ÉÂπ∂ÊâæÂà∞ÊúÄ‰ºòËß£„ÄÇÊ≠§Â§ñÔºåÂºïÂÖ•Èó®ÊéßÂæ™ÁéØÂçïÂÖÉ(GRU)Êù•Â§ÑÁêÜÊó∂Â∫è‰ø°ÊÅØÔºå‰ªéËÄåÊõ¥Â•ΩÂú∞Âª∫Ê®°ËΩ¶ËæÜ‰πãÈó¥ÁöÑ‰∫§‰∫íÂíåÁä∂ÊÄÅÂèòÂåñ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) ÁéØÂ¢ÉÂª∫Ê®°Ôºö‰ΩøÁî®CARLA‰ªøÁúüÂπ≥Âè∞Ê®°ÊãüÁúüÂÆû‰∫§ÈÄöÁéØÂ¢ÉÔºåÂåÖÊã¨ËΩ¶ËæÜÂä®ÂäõÂ≠¶„ÄÅ‰º†ÊÑüÂô®Âô™Â£∞ÂíåÈÄö‰ø°Âª∂ËøüÁ≠â„ÄÇ2) Áä∂ÊÄÅË°®Á§∫ÔºöÂ∞ÜËΩ¶ËæÜÁöÑÁä∂ÊÄÅ‰ø°ÊÅØÔºà‰ΩçÁΩÆ„ÄÅÈÄüÂ∫¶„ÄÅÂä†ÈÄüÂ∫¶Á≠âÔºâ‰ª•ÂèäÂÖ∂‰ªñËΩ¶ËæÜÁöÑ‰ø°ÊÅØ‰Ωú‰∏∫ËæìÂÖ•„ÄÇ3) Âä®‰ΩúÁ©∫Èó¥ÔºöÂÆö‰πâËΩ¶ËæÜÂèØ‰ª•ÊâßË°åÁöÑÂä®‰ΩúÔºå‰æãÂ¶ÇÂä†ÈÄü„ÄÅÂáèÈÄüÂíåËΩ¨Âêë„ÄÇ4) Â•ñÂä±ÂáΩÊï∞ÔºöËÆæËÆ°Â•ñÂä±ÂáΩÊï∞Êù•ÈºìÂä±ËΩ¶ËæÜÂÆâÂÖ®„ÄÅÈ´òÊïàÂú∞ÂÆåÊàêÂçèÂêåËßÑÂàí‰ªªÂä°„ÄÇ5) DRLÊô∫ËÉΩ‰ΩìÔºö‰ΩøÁî®SACÁÆóÊ≥ïÂíåGRUÁΩëÁªúÊù•Â≠¶‰π†ÊúÄ‰ºòÁ≠ñÁï•„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜSACÁÆóÊ≥ïÂíåGRUÁΩëÁªúÁªìÂêàËµ∑Êù•ÔºåÁî®‰∫éËß£ÂÜ≥Ëá™‰∏ªÂçèÂêåËßÑÂàí‰∏≠ÁöÑ‰∏çÁ°ÆÂÆöÊÄßÈóÆÈ¢ò„ÄÇSACÁÆóÊ≥ïËÉΩÂ§üÂ≠¶‰π†ÈöèÊú∫Á≠ñÁï•Ôºå‰ªéËÄåÊõ¥Â•ΩÂú∞Êé¢Á¥¢ÁéØÂ¢ÉÔºåËÄåGRUÁΩëÁªúËÉΩÂ§üÂ§ÑÁêÜÊó∂Â∫è‰ø°ÊÅØÔºå‰ªéËÄåÊõ¥Â•ΩÂú∞Âª∫Ê®°ËΩ¶ËæÜ‰πãÈó¥ÁöÑ‰∫§‰∫í„ÄÇËøôÁßçÁªìÂêà‰ΩøÂæóËØ•ÊñπÊ≥ïËÉΩÂ§üÊúâÊïàÂú∞Â§ÑÁêÜÊÑüÁü•„ÄÅÈÄö‰ø°ÂíåËßÑÂàí‰∏≠ÁöÑ‰∏çÁ°ÆÂÆöÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÁΩëÁªúÁªìÊûÑÊñπÈù¢ÔºåGRUÁΩëÁªúÁî®‰∫éÊèêÂèñÁä∂ÊÄÅ‰ø°ÊÅØÁöÑÊó∂Â∫èÁâπÂæÅÔºåÁÑ∂ÂêéÂ∞ÜËøô‰∫õÁâπÂæÅËæìÂÖ•Âà∞SACÁÆóÊ≥ïÁöÑÊºîÂëòÂíåËØÑËÆ∫ÂÆ∂ÁΩëÁªú‰∏≠„ÄÇÂ•ñÂä±ÂáΩÊï∞ÁöÑËÆæËÆ°ËÄÉËôë‰∫ÜÂ§ö‰∏™Âõ†Á¥†ÔºåÂåÖÊã¨ÂÆâÂÖ®ÊÄßÔºàÈÅøÂÖçÁ¢∞ÊíûÔºâ„ÄÅÊïàÁéáÔºàÂ∞ΩÂø´Âà∞ËææÁõÆÁöÑÂú∞ÔºâÂíåËàíÈÄÇÊÄßÔºàÈÅøÂÖçÊÄ•Âä†ÈÄüÂíåÊÄ•ÂáèÈÄüÔºâ„ÄÇÂÖ∑‰ΩìÁöÑÂèÇÊï∞ËÆæÁΩÆÈúÄË¶ÅÊ†πÊçÆÂÖ∑‰ΩìÁöÑ‰ªøÁúüÁéØÂ¢ÉËøõË°åË∞ÉÊï¥Ôºå‰æãÂ¶ÇÂ≠¶‰π†Áéá„ÄÅÊäòÊâ£Âõ†Â≠êÂíåÊé¢Á¥¢ÁéáÁ≠â„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊâÄÊèêÂá∫ÁöÑDRLACPÊñπÊ≥ïÂú®‰∏çÂêåÁöÑ‰ªøÁúüÂú∫ÊôØ‰∏ãÂùá‰ºò‰∫éÂÖ∂‰ªñÂü∫Á∫øÊñπÊ≥ï„ÄÇ‰æãÂ¶ÇÔºåÂú®È´òÈÄüÂÖ¨Ë∑ØÊ±áÂÖ•Âú∫ÊôØ‰∏≠ÔºåDRLACPÊñπÊ≥ïËÉΩÂ§üÊòæËëóÂáèÂ∞ëÁ¢∞ÊíûÊ¨°Êï∞ÔºåÂπ∂ÊèêÈ´òËΩ¶ËæÜÁöÑÂπ≥ÂùáÈÄüÂ∫¶„ÄÇ‰∏é‰º†ÁªüÁöÑÂü∫‰∫éËßÑÂàôÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåDRLACPÊñπÊ≥ïËÉΩÂ§üÊõ¥Â•ΩÂú∞ÈÄÇÂ∫î‰∏çÂêåÁöÑ‰∫§ÈÄöÁä∂ÂÜµÔºåÂπ∂ÂÅöÂá∫Êõ¥ÂêàÁêÜÁöÑÂÜ≥Á≠ñ„ÄÇÂÖ∑‰ΩìÊèêÂçáÂπÖÂ∫¶Êú™Áü•ÔºåÂéüÊñáÊú™ÁªôÂá∫ÂÖ∑‰ΩìÊï∞ÂÄº„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊú™Êù•ÁöÑÊô∫ËÉΩ‰∫§ÈÄöÁ≥ªÁªüÔºå‰æãÂ¶ÇËá™Âä®È©æÈ©∂Âá∫ÁßüËΩ¶„ÄÅËá™Âä®È©æÈ©∂Áâ©ÊµÅËΩ¶ÈòüÁ≠â„ÄÇÈÄöËøáÊèêÈ´òÂ§öËΩ¶ËæÜÂçèÂêåËßÑÂàíÁöÑÊïàÁéáÂíåÂÆâÂÖ®ÊÄßÔºåÂèØ‰ª•ÂáèÂ∞ë‰∫§ÈÄö‰∫ãÊïÖ„ÄÅÁºìËß£‰∫§ÈÄöÊã•Â†µÔºåÂπ∂ÊèêÈ´òËøêËæìÊïàÁéá„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïËøòÂèØ‰ª•Êâ©Â±ïÂà∞ÂÖ∂‰ªñÂ§öÊô∫ËÉΩ‰ΩìÂçèÂêå‰ªªÂä°‰∏≠Ôºå‰æãÂ¶ÇÊú∫Âô®‰∫∫ÁºñÈòü„ÄÅÊó†‰∫∫Êú∫ÂçèÂêåÁ≠â„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> In future intelligent transportation systems, autonomous cooperative planning (ACP), becomes a promising technique to increase the effectiveness and security of multi-vehicle interactions. However, multiple uncertainties cannot be fully addressed for existing ACP strategies, e.g. perception, planning, and communication uncertainties. To address these, a novel deep reinforcement learning-based autonomous cooperative planning (DRLACP) framework is proposed to tackle various uncertainties on cooperative motion planning schemes. Specifically, the soft actor-critic (SAC) with the implementation of gate recurrent units (GRUs) is adopted to learn the deterministic optimal time-varying actions with imperfect state information occurred by planning, communication, and perception uncertainties. In addition, the real-time actions of autonomous vehicles (AVs) are demonstrated via the Car Learning to Act (CARLA) simulation platform. Evaluation results show that the proposed DRLACP learns and performs cooperative planning effectively, which outperforms other baseline methods under different scenarios with imperfect AV state information.

