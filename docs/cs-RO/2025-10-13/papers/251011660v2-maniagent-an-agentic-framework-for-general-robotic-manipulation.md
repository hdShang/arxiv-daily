---
layout: default
title: ManiAgent: An Agentic Framework for General Robotic Manipulation
---

# ManiAgent: An Agentic Framework for General Robotic Manipulation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.11660" target="_blank" class="toolbar-btn">arXiv: 2510.11660v2</a>
    <a href="https://arxiv.org/pdf/2510.11660.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.11660v2" 
            onclick="toggleFavorite(this, '2510.11660v2', 'ManiAgent: An Agentic Framework for General Robotic Manipulation')" title="æ”¶è—">
      â˜† æ”¶è—
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="å¤åˆ¶é“¾æ¥">
      ğŸ”— åˆ†äº«
    </button>
  </div>
</div>


**ä½œè€…**: Yi Yang, Kefan Gu, Yuqing Wen, Hebei Li, Yucheng Zhao, Tiancai Wang, Xudong Liu

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-10-13 (æ›´æ–°: 2025-10-14)

**å¤‡æ³¨**: 8 pages, 6 figures, conference

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://yi-yang929.github.io/ManiAgent/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ManiAgentï¼šä¸€ç§ç”¨äºé€šç”¨æœºå™¨äººæ“ä½œçš„Agentæ¡†æ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æœºå™¨äººæ“ä½œ` `å¤šAgentç³»ç»Ÿ` `è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹` `ä»»åŠ¡åˆ†è§£` `å¼ºåŒ–å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹åœ¨å¤æ‚æ¨ç†å’Œé•¿æ—¶ç¨‹ä»»åŠ¡è§„åˆ’ä¸­å—åˆ°æ•°æ®ç¨€ç¼ºå’Œæ¨¡å‹å®¹é‡çš„é™åˆ¶ã€‚
2. ManiAgenté‡‡ç”¨å¤šAgentæ¶æ„ï¼Œé€šè¿‡Agenté—´çš„é€šä¿¡åä½œï¼Œå®ç°ç¯å¢ƒæ„ŸçŸ¥ã€ä»»åŠ¡åˆ†è§£å’ŒåŠ¨ä½œç”Ÿæˆï¼Œæå‡å¤æ‚æ“ä½œåœºæ™¯çš„å¤„ç†èƒ½åŠ›ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒManiAgentåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ä¸–ç•Œä»»åŠ¡ä¸­å‡å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸç‡ï¼Œå¹¶èƒ½é«˜æ•ˆæ”¶é›†æ•°æ®ï¼Œæå‡VLAæ¨¡å‹æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºManiAgentï¼Œä¸€ç§ç”¨äºé€šç”¨æ“ä½œä»»åŠ¡çš„Agentæ¶æ„ï¼Œèƒ½å¤Ÿå®ç°ä»ä»»åŠ¡æè¿°å’Œç¯å¢ƒè¾“å…¥åˆ°æœºå™¨äººæ“ä½œåŠ¨ä½œçš„ç«¯åˆ°ç«¯è¾“å‡ºã€‚è¯¥æ¡†æ¶ä¸­ï¼Œå¤šä¸ªAgenté€šè¿‡ç›¸äº’é€šä¿¡æ¥æ‰§è¡Œç¯å¢ƒæ„ŸçŸ¥ã€å­ä»»åŠ¡åˆ†è§£å’ŒåŠ¨ä½œç”Ÿæˆï¼Œä»è€Œèƒ½å¤Ÿé«˜æ•ˆåœ°å¤„ç†å¤æ‚çš„æ“ä½œåœºæ™¯ã€‚è¯„ä¼°ç»“æœè¡¨æ˜ï¼ŒManiAgentåœ¨SimplerEnvåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†86.8%çš„æˆåŠŸç‡ï¼Œåœ¨çœŸå®ä¸–ç•Œçš„æŠ“å–æ”¾ç½®ä»»åŠ¡ä¸­å–å¾—äº†95.8%çš„æˆåŠŸç‡ï¼Œä»è€Œèƒ½å¤Ÿé«˜æ•ˆåœ°æ”¶é›†æ•°æ®ï¼Œè¿›è€Œè®­ç»ƒå‡ºæ€§èƒ½ä¸åœ¨äººå·¥æ ‡æ³¨æ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹ç›¸å½“çš„VLAæ¨¡å‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹åœ¨æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­è¡¨ç°å‡ºæ½œåŠ›ï¼Œä½†é¢å¯¹éœ€è¦å¤æ‚æ¨ç†å’Œé•¿æ—¶ç¨‹è§„åˆ’çš„ä»»åŠ¡æ—¶ï¼Œç”±äºæ•°æ®é‡ä¸è¶³å’Œæ¨¡å‹å®¹é‡é™åˆ¶ï¼Œæ€§èƒ½å—åˆ°åˆ¶çº¦ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§èƒ½å¤Ÿæœ‰æ•ˆå¤„ç†å¤æ‚æ“ä½œåœºæ™¯ï¼Œå¹¶èƒ½é«˜æ•ˆåˆ©ç”¨æ•°æ®çš„æ¡†æ¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šManiAgentçš„æ ¸å¿ƒæ€è·¯æ˜¯å¼•å…¥å¤šAgentæ¶æ„ï¼Œå°†å¤æ‚çš„æœºå™¨äººæ“ä½œä»»åŠ¡åˆ†è§£ä¸ºå¤šä¸ªå­ä»»åŠ¡ï¼Œç”±ä¸åŒçš„Agentè´Ÿè´£ä¸åŒçš„å­ä»»åŠ¡ï¼Œå¹¶é€šè¿‡Agenté—´çš„é€šä¿¡åä½œï¼Œå…±åŒå®Œæˆæ•´ä¸ªä»»åŠ¡ã€‚è¿™ç§åˆ†è§£æ–¹å¼èƒ½å¤Ÿé™ä½å•ä¸ªAgentçš„å¤æ‚åº¦ï¼Œæé«˜æ•´ä½“çš„æ•ˆç‡å’Œé²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šManiAgentæ¡†æ¶åŒ…å«å¤šä¸ªAgentï¼Œä¾‹å¦‚æ„ŸçŸ¥Agentã€è§„åˆ’Agentå’Œæ‰§è¡ŒAgentã€‚æ„ŸçŸ¥Agentè´Ÿè´£ä»ç¯å¢ƒä¸­è·å–ä¿¡æ¯ï¼Œè§„åˆ’Agentè´Ÿè´£å°†ä»»åŠ¡åˆ†è§£ä¸ºå­ä»»åŠ¡å¹¶ç”Ÿæˆè¡ŒåŠ¨åºåˆ—ï¼Œæ‰§è¡ŒAgentè´Ÿè´£æ‰§è¡Œå…·ä½“çš„æœºå™¨äººåŠ¨ä½œã€‚Agentä¹‹é—´é€šè¿‡æ¶ˆæ¯ä¼ é€’è¿›è¡Œé€šä¿¡ï¼ŒååŒå®Œæˆä»»åŠ¡ã€‚æ•´ä¸ªæµç¨‹æ˜¯ä»ä»»åŠ¡æè¿°å’Œç¯å¢ƒè¾“å…¥å¼€å§‹ï¼Œç»è¿‡Agenté—´çš„ååŒå¤„ç†ï¼Œæœ€ç»ˆè¾“å‡ºæœºå™¨äººæ“ä½œåŠ¨ä½œã€‚

**å…³é”®åˆ›æ–°**ï¼šManiAgentçš„å…³é”®åˆ›æ–°åœ¨äºå…¶Agenticæ¶æ„ï¼Œé€šè¿‡å¤šAgentååŒå®Œæˆå¤æ‚æ“ä½œä»»åŠ¡ã€‚ä¸ä¼ ç»Ÿçš„å•ä½“VLAæ¨¡å‹ç›¸æ¯”ï¼ŒManiAgentèƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†å¤æ‚åœºæ™¯ï¼Œå¹¶ä¸”å…·æœ‰æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒManiAgentèƒ½å¤Ÿé«˜æ•ˆåœ°æ”¶é›†æ•°æ®ï¼Œç”¨äºè®­ç»ƒVLAæ¨¡å‹ï¼Œä»è€Œé™ä½äº†å¯¹äººå·¥æ ‡æ³¨æ•°æ®çš„ä¾èµ–ã€‚

**å…³é”®è®¾è®¡**ï¼šå…·ä½“çš„Agentè®¾è®¡å’Œé€šä¿¡æœºåˆ¶æ˜¯å…³é”®ã€‚ä¾‹å¦‚ï¼Œæ„ŸçŸ¥Agentå¯èƒ½é‡‡ç”¨è§†è§‰Transformeræ¥å¤„ç†å›¾åƒä¿¡æ¯ï¼Œè§„åˆ’Agentå¯èƒ½ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œä»»åŠ¡åˆ†è§£å’Œè¡ŒåŠ¨è§„åˆ’ã€‚Agenté—´çš„é€šä¿¡å¯èƒ½é‡‡ç”¨åŸºäºæ¶ˆæ¯é˜Ÿåˆ—çš„å¼‚æ­¥é€šä¿¡æ–¹å¼ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡éœ€è¦è€ƒè™‘ä»»åŠ¡çš„æˆåŠŸç‡å’ŒåŠ¨ä½œçš„æ•ˆç‡ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’Œå‚æ•°è®¾ç½®éœ€è¦æ ¹æ®å…·ä½“çš„ä»»åŠ¡è¿›è¡Œè°ƒæ•´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ManiAgentåœ¨SimplerEnvåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†86.8%çš„æˆåŠŸç‡ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚åœ¨çœŸå®ä¸–ç•Œçš„æŠ“å–æ”¾ç½®ä»»åŠ¡ä¸­ï¼ŒManiAgentå–å¾—äº†95.8%çš„æˆåŠŸç‡ï¼Œè¡¨æ˜å…¶å…·æœ‰å¾ˆå¼ºçš„å®é™…åº”ç”¨ä»·å€¼ã€‚æ­¤å¤–ï¼ŒManiAgentèƒ½å¤Ÿé«˜æ•ˆåœ°æ”¶é›†æ•°æ®ï¼Œä½¿å¾—è®­ç»ƒå‡ºçš„VLAæ¨¡å‹æ€§èƒ½ä¸åœ¨äººå·¥æ ‡æ³¨æ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹ç›¸å½“ï¼Œå¤§å¤§é™ä½äº†æ•°æ®æ ‡æ³¨æˆæœ¬ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ManiAgentå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚åœ¨æ™ºèƒ½åˆ¶é€ ã€ä»“å‚¨ç‰©æµã€å®¶åº­æœåŠ¡ç­‰é¢†åŸŸã€‚å®ƒå¯ä»¥ç”¨äºè‡ªåŠ¨åŒ–è£…é…ã€è´§ç‰©æ¬è¿ã€æ¸…æ´æ‰“æ‰«ç­‰ä»»åŠ¡ã€‚é€šè¿‡ä¸æ–­å­¦ä¹ å’Œä¼˜åŒ–ï¼ŒManiAgentæœ‰æœ›å®ç°æ›´é«˜çº§åˆ«çš„è‡ªä¸»æ€§å’Œæ™ºèƒ½åŒ–ï¼Œä»è€Œæé«˜ç”Ÿäº§æ•ˆç‡å’ŒæœåŠ¡è´¨é‡ï¼Œå¹¶é™ä½äººåŠ›æˆæœ¬ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While Vision-Language-Action (VLA) models have demonstrated impressive capabilities in robotic manipulation, their performance in complex reasoning and long-horizon task planning is limited by data scarcity and model capacity. To address this, we introduce ManiAgent, an agentic architecture for general manipulation tasks that achieves end-to-end output from task descriptions and environmental inputs to robotic manipulation actions. In this framework, multiple agents involve inter-agent communication to perform environmental perception, sub-task decomposition and action generation, enabling efficient handling of complex manipulation scenarios. Evaluations show ManiAgent achieves an 86.8% success rate on the SimplerEnv benchmark and 95.8% on real-world pick-and-place tasks, enabling efficient data collection that yields VLA models with performance comparable to those trained on human-annotated datasets. The project webpage is available at https://yi-yang929.github.io/ManiAgent/.

