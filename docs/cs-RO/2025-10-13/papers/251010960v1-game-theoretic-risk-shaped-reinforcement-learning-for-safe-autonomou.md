---
layout: default
title: Game-Theoretic Risk-Shaped Reinforcement Learning for Safe Autonomous Driving
---

# Game-Theoretic Risk-Shaped Reinforcement Learning for Safe Autonomous Driving

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.10960" target="_blank" class="toolbar-btn">arXiv: 2510.10960v1</a>
    <a href="https://arxiv.org/pdf/2510.10960.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.10960v1" 
            onclick="toggleFavorite(this, '2510.10960v1', 'Game-Theoretic Risk-Shaped Reinforcement Learning for Safe Autonomous Driving')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Dong Hu, Fenqing Hu, Lidong Yang, Chao Huang

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-13

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/DanielHu197/GTR2L)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Ê∏∏ÊàèÁêÜËÆ∫È£éÈô©Â°ëÂΩ¢Âº∫ÂåñÂ≠¶‰π†‰ª•Ëß£ÂÜ≥ÂÆâÂÖ®Ëá™Âä®È©æÈ©∂ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `ÂÆâÂÖ®Ëá™Âä®È©æÈ©∂` `Âº∫ÂåñÂ≠¶‰π†` `Ê∏∏ÊàèÁêÜËÆ∫` `È£éÈô©Âª∫Ê®°` `‰∏çÁ°ÆÂÆöÊÄßÂ§ÑÁêÜ` `‰∫§ÈÄöÂú∫ÊôØ` `ÂÜ≥Á≠ñ‰ºòÂåñ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÂú®ÂÆâÂÖ®ÊÄß„ÄÅÊïàÁéáÂíåÈÄÇÂ∫îÊÄß‰πãÈó¥Èöæ‰ª•ÂèñÂæóÂπ≥Ë°°ÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§çÊùÇÁöÑ‰∫§ÈÄöÁéØÂ¢É‰∏≠„ÄÇ
2. Êú¨Á†îÁ©∂ÊèêÂá∫ÁöÑGTR2LÊ°ÜÊû∂ÈÄöËøáÊ∏∏ÊàèÁêÜËÆ∫Ê®°ÂûãÈ¢ÑÊµãÂë®Âõ¥ËΩ¶ËæÜË°å‰∏∫ÂèäÈ£éÈô©ÔºåÂπ∂ÂºïÂÖ•‰∏çÁ°ÆÂÆöÊÄßÊÑüÁü•Êú∫Âà∂Êù•‰ºòÂåñÂÆâÂÖ®ÊÄß„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåGTR2LÂú®ÊàêÂäüÁéá„ÄÅÁ¢∞ÊíûÂáèÂ∞ëÂíåÈ©æÈ©∂ÊïàÁéáÊñπÈù¢ÊòæËëó‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®ÂÆâÂÖ®Ëá™Âä®È©æÈ©∂‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Á°Æ‰øùËá™Âä®È©æÈ©∂ÁöÑÂÆâÂÖ®ÊÄß‰ªçÁÑ∂ÊòØ‰∏Ä‰∏™ÈáçÂ§ßÊåëÊàòÔºåÂ∞§ÂÖ∂ÊòØÂú®È´òÂ∫¶Âä®ÊÄÅÂíåÂ§çÊùÇÁöÑ‰∫§ÈÄöÁéØÂ¢É‰∏≠ÔºåÂë®Âõ¥Â§öÁßç‰ª£ÁêÜÁöÑ‰∫íÂä®‰ª•ÂèäÊÑèÂ§ñÂç±Èô©ÁöÑÈ¢ëÁπÅÂá∫Áé∞‰ΩøÂæóËøô‰∏ÄÈóÆÈ¢òÊõ¥Âä†Â§çÊùÇ„ÄÇ‰º†ÁªüÁöÑÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÂæÄÂæÄÈöæ‰ª•Âπ≥Ë°°ÂÆâÂÖ®ÊÄß„ÄÅÊïàÁéáÂíåÈÄÇÂ∫îÊÄßÔºåÂõ†‰∏∫ÂÆÉ‰ª¨‰∏ªË¶ÅÂÖ≥Ê≥®Â•ñÂä±ÊúÄÂ§ßÂåñÔºåËÄåÊú™ÊòéÁ°ÆÂª∫Ê®°È£éÈô©ÊàñÂÆâÂÖ®Á∫¶Êùü„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÂ±ÄÈôêÊÄßÔºåÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÊ∏∏ÊàèÁêÜËÆ∫È£éÈô©Â°ëÂΩ¢Âº∫ÂåñÂ≠¶‰π†ÔºàGTR2LÔºâÊ°ÜÊû∂ÔºåGTR2LÁªìÂêà‰∫ÜÂ§öÂ±ÇÊ¨°ÁöÑÊ∏∏ÊàèÁêÜËÆ∫‰∏ñÁïåÊ®°ÂûãÔºåËÉΩÂ§üÂÖ±ÂêåÈ¢ÑÊµãÂë®Âõ¥ËΩ¶ËæÜÁöÑ‰∫íÂä®Ë°å‰∏∫ÂèäÂÖ∂Áõ∏ÂÖ≥È£éÈô©ÔºåÂπ∂‰∏îÂÖ∑ÊúâÂü∫‰∫éÈ¢ÑÊµã‰∏çÁ°ÆÂÆöÊÄßÂä®ÊÄÅË∞ÉÊï¥ÁöÑËá™ÈÄÇÂ∫îÂõûÊªöÊó∂Èó¥„ÄÇÊ≠§Â§ñÔºåËÆ∫ÊñáËøòÊèêÂá∫‰∫Ü‰∏ÄÁßç‰∏çÁ°ÆÂÆöÊÄßÊÑüÁü•ÁöÑÈöúÁ¢çÊú∫Âà∂Ôºå‰ª•ÁÅµÊ¥ªË∞ÉËäÇÂÆâÂÖ®ËæπÁïå„ÄÇÈÄöËøáÂú®Â§öÁßçÂÆâÂÖ®ÂÖ≥ÈîÆÁöÑ‰∫§ÈÄöÂú∫ÊôØ‰∏≠ËøõË°åÂπøÊ≥õËØÑ‰º∞ÔºåGTR2LÂú®ÊàêÂäüÁéá„ÄÅÁ¢∞ÊíûÂíåËøùËßÑÂáèÂ∞ë‰ª•ÂèäÈ©æÈ©∂ÊïàÁéáÁ≠âÊñπÈù¢ÊòæËëó‰ºò‰∫éÁé∞ÊúâÁöÑÊúÄÂÖàËøõÂü∫Á∫øÔºåÂåÖÊã¨‰∫∫Á±ªÈ©æÈ©∂Âëò„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Ëá™Âä®È©æÈ©∂‰∏≠ÁöÑÂÆâÂÖ®ÊÄßÈóÆÈ¢òÔºåÁé∞ÊúâÊñπÊ≥ïÂæÄÂæÄÂøΩËßÜÈ£éÈô©Âª∫Ê®°ÔºåÂØºËá¥Âú®Â§çÊùÇÁéØÂ¢É‰∏≠Ë°®Áé∞‰∏ç‰Ω≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöGTR2LÊ°ÜÊû∂ÈÄöËøáÂºïÂÖ•Ê∏∏ÊàèÁêÜËÆ∫ÂíåÈ£éÈô©Â°ëÂΩ¢Êú∫Âà∂ÔºåËÉΩÂ§üÊõ¥Â•ΩÂú∞È¢ÑÊµãÂë®Âõ¥ËΩ¶ËæÜÁöÑË°å‰∏∫ÂíåÈ£éÈô©Ôºå‰ªéËÄåÊèêÈ´òÂÜ≥Á≠ñÁöÑÂÆâÂÖ®ÊÄßÂíåÊïàÁéá„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•Ê°ÜÊû∂ÂåÖÊã¨Â§öÂ±ÇÊ¨°ÁöÑÊ∏∏ÊàèÁêÜËÆ∫‰∏ñÁïåÊ®°Âûã„ÄÅÂä®ÊÄÅË∞ÉÊï¥ÁöÑÂõûÊªöÊó∂Èó¥Âíå‰∏çÁ°ÆÂÆöÊÄßÊÑüÁü•ÁöÑÈöúÁ¢çÊú∫Âà∂ÔºåÊï¥‰ΩìÊµÅÁ®ãÂõ¥ÁªïÈ£éÈô©Âª∫Ê®°ÂíåÂÆâÂÖ®ËæπÁïåÁöÑÁÅµÊ¥ªË∞ÉËäÇÂ±ïÂºÄ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöGTR2LÁöÑÊ†∏ÂøÉÂàõÊñ∞Âú®‰∫éÂ∞ÜÈ£éÈô©Âª∫Ê®°‰∏éÂº∫ÂåñÂ≠¶‰π†Áõ∏ÁªìÂêàÔºåÊòéÁ°ÆÊçïÊçâËÆ§Áü•‰∏çÁ°ÆÂÆöÊÄßÂíåÈöèÊú∫‰∏çÁ°ÆÂÆöÊÄßÔºåÊòæËëóÊèêÂçá‰∫ÜÂÜ≥Á≠ñËøáÁ®ã‰∏≠ÁöÑÂÆâÂÖ®ÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËÆ∫Êñá‰∏≠ËÆæËÆ°‰∫ÜÈÄÇÂ∫îÊÄßÁöÑÂõûÊªöÊó∂Èó¥Âíå‰∏çÁ°ÆÂÆöÊÄßÊÑüÁü•ÁöÑÈöúÁ¢çÊú∫Âà∂ÔºåÁ°Æ‰øùÂú®Âä®ÊÄÅÁéØÂ¢É‰∏≠ËÉΩÂ§üÁÅµÊ¥ªË∞ÉÊï¥ÂÆâÂÖ®ËæπÁïåÔºåÂêåÊó∂ÈááÁî®‰∫Ü‰∏ìÈó®ÁöÑÈ£éÈô©Âª∫Ê®°ÊñπÊ≥ïÊù•‰ºòÂåñÁ≠ñÁï•„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåGTR2LÂú®Â§öÁßçÂÆâÂÖ®ÂÖ≥ÈîÆÁöÑ‰∫§ÈÄöÂú∫ÊôØ‰∏≠Ë°®Áé∞‰ºòÂºÇÔºåÊàêÂäüÁéáÊèêÈ´ò‰∫ÜXX%ÔºåÁ¢∞ÊíûÂíåËøùËßÑ‰∫ã‰ª∂ÂáèÂ∞ë‰∫ÜYY%ÔºåÂπ∂‰∏îÂú®È©æÈ©∂ÊïàÁéáÊñπÈù¢‰πüÊúâÊòæËëóÊèêÂçáÔºåË∂ÖË∂ä‰∫ÜÂåÖÊã¨‰∫∫Á±ªÈ©æÈ©∂ÂëòÂú®ÂÜÖÁöÑÂ§öÁßçÂü∫Á∫øÊñπÊ≥ï„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Ëá™Âä®È©æÈ©∂Ê±ΩËΩ¶„ÄÅÊô∫ËÉΩ‰∫§ÈÄöÁ≥ªÁªüÂíåÊú∫Âô®‰∫∫ÂØºËà™Á≠â„ÄÇÈÄöËøáÊèêÂçáËá™Âä®È©æÈ©∂ÁöÑÂÆâÂÖ®ÊÄßÂíåÊïàÁéáÔºåGTR2LÊ°ÜÊû∂ÊúâÊúõÂú®Êú™Êù•ÁöÑÊô∫ËÉΩ‰∫§ÈÄöÁéØÂ¢É‰∏≠ÂèëÊå•ÈáçË¶Å‰ΩúÁî®ÔºåÊé®Âä®Ëá™Âä®È©æÈ©∂ÊäÄÊúØÁöÑÂπøÊ≥õÂ∫îÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Ensuring safety in autonomous driving (AD) remains a significant challenge, especially in highly dynamic and complex traffic environments where diverse agents interact and unexpected hazards frequently emerge. Traditional reinforcement learning (RL) methods often struggle to balance safety, efficiency, and adaptability, as they primarily focus on reward maximization without explicitly modeling risk or safety constraints. To address these limitations, this study proposes a novel game-theoretic risk-shaped RL (GTR2L) framework for safe AD. GTR2L incorporates a multi-level game-theoretic world model that jointly predicts the interactive behaviors of surrounding vehicles and their associated risks, along with an adaptive rollout horizon that adjusts dynamically based on predictive uncertainty. Furthermore, an uncertainty-aware barrier mechanism enables flexible modulation of safety boundaries. A dedicated risk modeling approach is also proposed, explicitly capturing both epistemic and aleatoric uncertainty to guide constrained policy optimization and enhance decision-making in complex environments. Extensive evaluations across diverse and safety-critical traffic scenarios show that GTR2L significantly outperforms state-of-the-art baselines, including human drivers, in terms of success rate, collision and violation reduction, and driving efficiency. The code is available at https://github.com/DanielHu197/GTR2L.

