---
layout: default
title: SCOOP'D: Learning Mixed-Liquid-Solid Scooping via Sim2Real Generative Policy
---

# SCOOP'D: Learning Mixed-Liquid-Solid Scooping via Sim2Real Generative Policy

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.11566" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.11566v1</a>
  <a href="https://arxiv.org/pdf/2510.11566.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.11566v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.11566v1', 'SCOOP\'D: Learning Mixed-Liquid-Solid Scooping via Sim2Real Generative Policy')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kuanning Wang, Yongchong Gu, Yuqian Fu, Zeyu Shangguan, Sicheng He, Xiangyang Xue, Yanwei Fu, Daniel Seita

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-13

**å¤‡æ³¨**: Project page is at https://scoopdiff.github.io/

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://scoopdiff.github.io/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**SCOOP'Dï¼šé€šè¿‡Sim2Realç”Ÿæˆç­–ç•¥å­¦ä¹ æ··åˆæ¶²ä½“-å›ºä½“æŠ“å–**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `æœºå™¨äººæŠ“å–` `Sim2Real` `ç”Ÿæˆç­–ç•¥` `æ‰©æ•£æ¨¡å‹` `æ··åˆæ¶²ä½“-å›ºä½“` `æ¨¡ä»¿å­¦ä¹ ` `OmniGibson`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æœºå™¨äººæŠ“å–ç­–ç•¥éš¾ä»¥å¤„ç†å¤æ‚çš„å·¥å…·-ç‰©ä½“äº¤äº’ï¼Œå°¤å…¶æ˜¯åœ¨æ¶‰åŠé¢—ç²’ä»‹è´¨æˆ–æ¶²ä½“ç­‰å¯å˜å½¢ç‰©ä½“æ—¶ï¼Œé¢ä¸´æ— é™ç»´é…ç½®ç©ºé—´å’Œå¤æ‚åŠ¨åŠ›å­¦æŒ‘æˆ˜ã€‚
2. SCOOP'Dåˆ©ç”¨ä»¿çœŸç¯å¢ƒç”ŸæˆæŠ“å–æ¼”ç¤ºæ•°æ®ï¼Œå¹¶ä½¿ç”¨æ‰©æ•£æ¨¡å‹å­¦ä¹ ç”Ÿæˆç­–ç•¥ï¼Œä»è€Œæ¨¡ä»¿è¿™äº›æ¼”ç¤ºï¼Œå®ç°ä»ä»¿çœŸåˆ°çœŸå®çš„è¿ç§»ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒSCOOP'Dåœ¨å„ç§çœŸå®åœºæ™¯ä¸­è¡¨ç°å‡ºè‰¯å¥½çš„é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ï¼Œä¼˜äºå…¶ä»–åŸºçº¿æ–¹æ³•ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºSCOOP'Dçš„æ–¹æ³•ï¼Œç”¨äºå­¦ä¹ é€šç”¨çš„æœºå™¨äººæŠ“å–ç­–ç•¥ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹æ··åˆæ¶²ä½“-å›ºä½“çš„åœºæ™¯ã€‚è¯¥æ–¹æ³•åˆ©ç”¨OmniGibsonï¼ˆåŸºäºNVIDIA Omniverseæ„å»ºï¼‰è¿›è¡Œä»¿çœŸï¼Œé€šè¿‡ç®—æ³•ç¨‹åºæ”¶é›†æŠ“å–æ¼”ç¤ºæ•°æ®ï¼Œè¿™äº›ç®—æ³•ç¨‹åºä¾èµ–äºç‰¹æƒçŠ¶æ€ä¿¡æ¯ã€‚ç„¶åï¼Œä½¿ç”¨åŸºäºæ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆç­–ç•¥ï¼Œä»è§‚æµ‹è¾“å…¥ä¸­æ¨¡ä»¿è¿™äº›æ¼”ç¤ºã€‚è¯¥æ–¹æ³•ç›´æ¥å°†å­¦ä¹ åˆ°çš„ç­–ç•¥åº”ç”¨äºå„ç§çœŸå®åœºæ™¯ï¼Œæµ‹è¯•å…¶åœ¨ä¸åŒç‰©å“æ•°é‡ã€ç‰©å“ç‰¹æ€§å’Œå®¹å™¨ç±»å‹ä¸‹çš„æ€§èƒ½ã€‚åœ¨é›¶æ ·æœ¬éƒ¨ç½²ä¸­ï¼Œè¯¥æ–¹æ³•åœ¨465æ¬¡è¯•éªŒä¸­è¡¨ç°å‡ºè‰¯å¥½çš„æ•ˆæœï¼Œæ¶µç›–äº†ä¸åŒéš¾åº¦çš„ç‰©å“ï¼ˆåˆ†ä¸ºâ€œLevel 1â€å’Œâ€œLevel 2â€ï¼‰ã€‚SCOOP'Dä¼˜äºæ‰€æœ‰åŸºçº¿å’Œæ¶ˆèå®éªŒï¼Œè¡¨æ˜è¿™æ˜¯ä¸€ç§æœ‰å‰æ™¯çš„æœºå™¨äººæŠ“å–æŠ€èƒ½è·å–æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æœºå™¨äººè‡ªä¸»æŠ“å–æ··åˆæ¶²ä½“-å›ºä½“çš„é—®é¢˜ï¼Œä¾‹å¦‚ç”¨å‹ºå­æˆ–å‹ºå­ä»å®¹å™¨ä¸­èˆ€å–ç‰©ä½“ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥å¤„ç†æ­¤ç±»ä»»åŠ¡ï¼Œå› ä¸ºå®ƒä»¬éœ€è¦å¯¹å¤æ‚çš„å·¥å…·-ç‰©ä½“äº¤äº’è¿›è¡Œæ¨ç†ï¼Œå¹¶ä¸”éš¾ä»¥å¤„ç†å¯å˜å½¢ç‰©ä½“ï¼ˆå¦‚é¢—ç²’ä»‹è´¨æˆ–æ¶²ä½“ï¼‰çš„æ— é™ç»´é…ç½®ç©ºé—´å’Œå¤æ‚åŠ¨åŠ›å­¦ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨ä»¿çœŸç¯å¢ƒç”Ÿæˆé«˜è´¨é‡çš„æŠ“å–æ¼”ç¤ºæ•°æ®ï¼Œç„¶åä½¿ç”¨ç”Ÿæˆç­–ç•¥ï¼ˆå…·ä½“ä¸ºæ‰©æ•£æ¨¡å‹ï¼‰æ¥æ¨¡ä»¿è¿™äº›æ¼”ç¤ºï¼Œä»è€Œå­¦ä¹ åˆ°èƒ½å¤Ÿåœ¨çœŸå®ä¸–ç•Œä¸­æ³›åŒ–çš„æŠ“å–ç­–ç•¥ã€‚è¿™ç§Sim2Realçš„æ–¹æ³•å¯ä»¥é¿å…åœ¨çœŸå®ç¯å¢ƒä¸­æ”¶é›†å¤§é‡æ•°æ®çš„å›°éš¾ï¼Œå¹¶åˆ©ç”¨ä»¿çœŸç¯å¢ƒçš„ä¼˜åŠ¿æ¥æ¢ç´¢å„ç§æŠ“å–ç­–ç•¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSCOOP'Dçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦é˜¶æ®µï¼š1) åœ¨OmniGibsonä»¿çœŸç¯å¢ƒä¸­ï¼Œä½¿ç”¨ç®—æ³•ç¨‹åºç”ŸæˆæŠ“å–æ¼”ç¤ºæ•°æ®ã€‚è¿™äº›ç¨‹åºåˆ©ç”¨ç‰¹æƒçŠ¶æ€ä¿¡æ¯ï¼ˆä¾‹å¦‚ç‰©ä½“çš„ä½ç½®å’Œé€Ÿåº¦ï¼‰æ¥ç¡®ä¿ç”Ÿæˆé«˜è´¨é‡çš„æ¼”ç¤ºã€‚2) ä½¿ç”¨æ‰©æ•£æ¨¡å‹å­¦ä¹ ä¸€ä¸ªç”Ÿæˆç­–ç•¥ï¼Œè¯¥ç­–ç•¥èƒ½å¤Ÿä»è§‚æµ‹è¾“å…¥ï¼ˆä¾‹å¦‚å›¾åƒï¼‰ä¸­é¢„æµ‹æŠ“å–åŠ¨ä½œã€‚3) å°†å­¦ä¹ åˆ°çš„ç­–ç•¥ç›´æ¥éƒ¨ç½²åˆ°çœŸå®æœºå™¨äººä¸Šï¼Œè¿›è¡Œé›¶æ ·æœ¬æµ‹è¯•ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºä½¿ç”¨ç”Ÿæˆç­–ç•¥ï¼ˆæ‰©æ•£æ¨¡å‹ï¼‰æ¥å­¦ä¹ æŠ“å–ç­–ç•¥ï¼Œå¹¶å°†å…¶åº”ç”¨äºSim2Realåœºæ™¯ã€‚ä¸ä¼ ç»Ÿçš„æ¨¡ä»¿å­¦ä¹ æ–¹æ³•ç›¸æ¯”ï¼Œç”Ÿæˆç­–ç•¥èƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†è§‚æµ‹å™ªå£°å’ŒçŠ¶æ€ä¸ç¡®å®šæ€§ï¼Œä»è€Œæé«˜ç­–ç•¥çš„æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¯¥è®ºæ–‡è¿˜æå‡ºäº†ä¸€ç§åˆ©ç”¨ç‰¹æƒçŠ¶æ€ä¿¡æ¯ç”Ÿæˆé«˜è´¨é‡ä»¿çœŸæ¼”ç¤ºæ•°æ®çš„æ–¹æ³•ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ä»¿çœŸç¯å¢ƒä¸­ï¼Œè®ºæ–‡ä½¿ç”¨åŸºäºè§„åˆ™çš„ç®—æ³•æ¥ç”ŸæˆæŠ“å–æ¼”ç¤ºæ•°æ®ã€‚è¿™äº›ç®—æ³•è€ƒè™‘äº†ç‰©ä½“çš„ä½ç½®ã€å½¢çŠ¶å’Œæ•°é‡ç­‰å› ç´ ï¼Œå¹¶ç”Ÿæˆä¸€ç³»åˆ—æŠ“å–åŠ¨ä½œã€‚æ‰©æ•£æ¨¡å‹ä½¿ç”¨U-Netæ¶æ„ï¼Œå¹¶ç»è¿‡è®­ç»ƒä»¥ä»è§‚æµ‹è¾“å…¥ä¸­é¢„æµ‹æŠ“å–åŠ¨ä½œã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬åŠ¨ä½œé¢„æµ‹æŸå¤±å’ŒçŠ¶æ€é¢„æµ‹æŸå¤±ã€‚è®ºæ–‡è¿˜æ¢ç´¢äº†ä¸åŒçš„æ‰©æ•£æ¨¡å‹å‚æ•°è®¾ç½®ï¼Œä¾‹å¦‚æ‰©æ•£æ­¥æ•°å’Œå™ªå£°æ°´å¹³ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

SCOOP'Dåœ¨465æ¬¡çœŸå®ä¸–ç•Œè¯•éªŒä¸­è¡¨ç°å‡ºä¼˜å¼‚çš„é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ï¼ŒæˆåŠŸå¤„ç†äº†ä¸åŒéš¾åº¦çº§åˆ«ï¼ˆLevel 1å’ŒLevel 2ï¼‰çš„ç‰©ä½“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSCOOP'Dæ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿æ–¹æ³•å’Œæ¶ˆèå®éªŒï¼Œè¯æ˜äº†å…¶åœ¨æœºå™¨äººæŠ“å–ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚é¡¹ç›®ç½‘é¡µæä¾›äº†æ›´å¤šå®éªŒç»†èŠ‚å’Œè§†é¢‘ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼ŒåŒ…æ‹¬è¾…åŠ©å–‚é£Ÿã€ç¾éš¾ç°åœºç‰©å“æœå¯»ã€è‡ªåŠ¨åŒ–é¤é¥®æœåŠ¡ç­‰ã€‚é€šè¿‡å­¦ä¹ é€šç”¨çš„æŠ“å–ç­–ç•¥ï¼Œæœºå™¨äººå¯ä»¥æ›´å¥½åœ°é€‚åº”å„ç§å¤æ‚çš„ç¯å¢ƒå’Œä»»åŠ¡ï¼Œæé«˜å·¥ä½œæ•ˆç‡å’Œå®‰å…¨æ€§ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯å¯ä»¥è¿›ä¸€æ­¥æ‰©å±•åˆ°å…¶ä»–ç±»å‹çš„æ“ä½œä»»åŠ¡ï¼Œä¾‹å¦‚è£…é…ã€æ¸…æ´ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Scooping items with tools such as spoons and ladles is common in daily life, ranging from assistive feeding to retrieving items from environmental disaster sites. However, developing a general and autonomous robotic scooping policy is challenging since it requires reasoning about complex tool-object interactions. Furthermore, scooping often involves manipulating deformable objects, such as granular media or liquids, which is challenging due to their infinite-dimensional configuration spaces and complex dynamics. We propose a method, SCOOP'D, which uses simulation from OmniGibson (built on NVIDIA Omniverse) to collect scooping demonstrations using algorithmic procedures that rely on privileged state information. Then, we use generative policies via diffusion to imitate demonstrations from observational input. We directly apply the learned policy in diverse real-world scenarios, testing its performance on various item quantities, item characteristics, and container types. In zero-shot deployment, our method demonstrates promising results across 465 trials in diverse scenarios, including objects of different difficulty levels that we categorize as "Level 1" and "Level 2." SCOOP'D outperforms all baselines and ablations, suggesting that this is a promising approach to acquiring robotic scooping skills. Project page is at https://scoopdiff.github.io/.

