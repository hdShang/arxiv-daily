---
layout: default
title: XGrasp: Gripper-Aware Grasp Detection with Multi-Gripper Data Generation
---

# XGrasp: Gripper-Aware Grasp Detection with Multi-Gripper Data Generation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.11036" target="_blank" class="toolbar-btn">arXiv: 2510.11036v1</a>
    <a href="https://arxiv.org/pdf/2510.11036.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.11036v1" 
            onclick="toggleFavorite(this, '2510.11036v1', 'XGrasp: Gripper-Aware Grasp Detection with Multi-Gripper Data Generation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yeonseo Lee, Jungwook Mun, Hyosup Shin, Guebin Hwang, Junhee Nam, Taeyeop Lee, Sungho Jo

**ÂàÜÁ±ª**: cs.RO, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-13

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**XGraspÔºöÊèêÂá∫‰∏ÄÁßçÊîØÊåÅÂ§öÂ§πÁà™ÁöÑÂÆûÊó∂„ÄÅÂèØÊ≥õÂåñÊäìÂèñÊ£ÄÊµãÊ°ÜÊû∂„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Êú∫Âô®‰∫∫ÊäìÂèñ` `Â§πÁà™ÊÑüÁü•` `Â§öÂ§πÁà™` `Èõ∂Ê†∑Êú¨Â≠¶‰π†` `ÂØπÊØîÂ≠¶‰π†` `ÂÆûÊó∂ÊäìÂèñ` `ËßÜËßâÂü∫Á°ÄÊ®°Âûã`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊú∫Âô®‰∫∫ÊäìÂèñÊñπÊ≥ïÈÄöÂ∏∏ÈíàÂØπÂçï‰∏ÄÂ§πÁà™Á±ªÂûãËÆæËÆ°ÔºåÈôêÂà∂‰∫ÜÂÖ∂Âú®ÈúÄË¶ÅÂ§öÊ†∑ÂåñÊú´Á´ØÊâßË°åÂô®ÁöÑÂÆûÈôÖÂú∫ÊôØ‰∏≠ÁöÑÂ∫îÁî®„ÄÇ
2. XGraspÈÄöËøáÂàÜÂ±ÇÊû∂ÊûÑÂíåÂØπÊØîÂ≠¶‰π†ÔºåÂÆûÁé∞‰∫ÜÂØπÂ§öÁßçÂ§πÁà™ÁöÑÂÆûÊó∂ÊäìÂèñÊ£ÄÊµãÔºåÂπ∂ÂÖ∑Â§áÂØπÊú™ËßÅÂ§πÁà™ÁöÑÈõ∂Ê†∑Êú¨Ê≥õÂåñËÉΩÂäõ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåXGraspÂú®Â§öÁßçÂ§πÁà™‰∏äÂèñÂæó‰∫ÜÂÖ∑ÊúâÁ´û‰∫âÂäõÁöÑÊäìÂèñÊàêÂäüÁéáÔºåÂπ∂ÊòæËëóÊèêÂçá‰∫ÜÊé®ÁêÜÈÄüÂ∫¶„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫XGraspÁöÑÂÆûÊó∂„ÄÅgripper-awareÁöÑÊäìÂèñÊ£ÄÊµãÊ°ÜÊû∂ÔºåÊó®Âú®ÊúâÊïàÂ§ÑÁêÜÂ§öÁßçÂ§πÁà™ÈÖçÁΩÆ„ÄÇËØ•ÊñπÊ≥ïÈÄöËøáÁ≥ªÁªüÂú∞‰ΩøÁî®Â§öÂ§πÁà™Ê†áÊ≥®Â¢ûÂº∫Áé∞ÊúâÊï∞ÊçÆÈõÜÊù•Ëß£ÂÜ≥Êï∞ÊçÆÁ®ÄÁº∫ÈóÆÈ¢ò„ÄÇXGraspÈááÁî®ÂàÜÂ±Ç‰∏§Èò∂ÊÆµÊû∂ÊûÑ„ÄÇÁ¨¨‰∏ÄÈò∂ÊÆµÔºåÊäìÂèñÁÇπÈ¢ÑÊµãÂô®ÔºàGPPÔºâÂà©Áî®ÂÖ®Â±ÄÂú∫ÊôØ‰ø°ÊÅØÂíåÂ§πÁà™ËßÑÊ†ºËØÜÂà´ÊúÄ‰Ω≥‰ΩçÁΩÆ„ÄÇÁ¨¨‰∫åÈò∂ÊÆµÔºåËßíÂ∫¶-ÂÆΩÂ∫¶È¢ÑÊµãÂô®ÔºàAWPÔºâ‰ΩøÁî®Â±ÄÈÉ®ÁâπÂæÅÁªÜÂåñÊäìÂèñËßíÂ∫¶ÂíåÂÆΩÂ∫¶„ÄÇAWPÊ®°Âùó‰∏≠ÁöÑÂØπÊØîÂ≠¶‰π†ÈÄöËøáÂ≠¶‰π†Âü∫Êú¨ÁöÑÊäìÂèñÁâπÊÄßÔºåÂÆûÁé∞‰∫ÜÂØπÊú™ËßÅËøáÁöÑÂ§πÁà™ÁöÑÈõ∂Ê†∑Êú¨Ê≥õÂåñ„ÄÇËØ•Ê®°ÂùóÂåñÊ°ÜÊû∂‰∏éËßÜËßâÂü∫Á°ÄÊ®°ÂûãÊó†ÁºùÈõÜÊàêÔºå‰∏∫Êú™Êù•ÁöÑËßÜËßâ-ËØ≠Ë®ÄËÉΩÂäõÊèê‰æõ‰∫ÜÈÄîÂæÑ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®ÂêÑÁßçÂ§πÁà™Á±ªÂûã‰∏äÈÉΩÂÖ∑ÊúâÁ´û‰∫âÂäõÁöÑÊäìÂèñÊàêÂäüÁéáÔºåÂêåÊó∂‰∏éÁé∞ÊúâÁöÑgripper-awareÊñπÊ≥ïÁõ∏ÊØîÔºåÊé®ÁêÜÈÄüÂ∫¶Êúâ‰∫ÜÊòæËëóÊèêÈ´ò„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÁöÑÊú∫Âô®‰∫∫ÊäìÂèñÊñπÊ≥ïÂ§ßÂ§öÊòØ‰∏∫ÁâπÂÆöÁöÑÂ§πÁà™ËÆæËÆ°ÁöÑÔºåËøôÈôêÂà∂‰∫ÜÂÆÉ‰ª¨Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÁÅµÊ¥ªÊÄßÔºåÂõ†‰∏∫Áé∞ÂÆû‰∏ñÁïå‰∏≠ÈúÄË¶Å‰ΩøÁî®ÂêÑÁßç‰∏çÂêåÁöÑÂ§πÁà™Êù•Â§ÑÁêÜ‰∏çÂêåÁöÑÁâ©‰Ωì„ÄÇÂõ†Ê≠§ÔºåÂ¶Ç‰ΩïËÆæËÆ°‰∏Ä‰∏™ËÉΩÂ§üÈÄÇÂ∫îÂ§öÁßçÂ§πÁà™ÔºåÁîöËá≥ËÉΩÂ§üÊ≥õÂåñÂà∞Êú™ËßÅËøáÁöÑÂ§πÁà™ÁöÑÊäìÂèñÁ≥ªÁªüÔºåÊòØ‰∏Ä‰∏™ÈáçË¶ÅÁöÑÊåëÊàò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöXGraspÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®‰∏Ä‰∏™ÂàÜÂ±ÇÁöÑ‰∏§Èò∂ÊÆµÊû∂ÊûÑÔºåÁªìÂêàÂØπÊØîÂ≠¶‰π†ÔºåÊù•Â≠¶‰π†ÈÄöÁî®ÁöÑÊäìÂèñÁâπÂæÅÔºå‰ªéËÄåÂÆûÁé∞ÂØπÂ§öÁßçÂ§πÁà™ÁöÑÊäìÂèñÊ£ÄÊµã„ÄÇÁ¨¨‰∏ÄÈò∂ÊÆµÈ¢ÑÊµãÊäìÂèñÁÇπÔºåÁ¨¨‰∫åÈò∂ÊÆµÁªÜÂåñÊäìÂèñËßíÂ∫¶ÂíåÂÆΩÂ∫¶„ÄÇÂØπÊØîÂ≠¶‰π†ÂàôÁî®‰∫éÂ≠¶‰π†‰∏çÂêåÂ§πÁà™‰πãÈó¥ÁöÑÂÖ±ÊÄßÔºå‰ªéËÄåÂÆûÁé∞Èõ∂Ê†∑Êú¨Ê≥õÂåñ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöXGraspÁöÑÊï¥‰ΩìÊû∂ÊûÑÂàÜ‰∏∫‰∏§‰∏™Èò∂ÊÆµÔºöGrasp Point Predictor (GPP) Âíå Angle-Width Predictor (AWP)„ÄÇGPPÂà©Áî®ÂÖ®Â±ÄÂú∫ÊôØ‰ø°ÊÅØÂíåÂ§πÁà™ËßÑÊ†ºÔºåÈ¢ÑÊµãÊúÄ‰Ω≥ÁöÑÊäìÂèñ‰ΩçÁΩÆ„ÄÇAWPÂàôÂà©Áî®Â±ÄÈÉ®ÁâπÂæÅÔºåÁªÜÂåñÊäìÂèñËßíÂ∫¶ÂíåÂÆΩÂ∫¶„ÄÇAWPÊ®°Âùó‰∏≠‰ΩøÁî®‰∫ÜÂØπÊØîÂ≠¶‰π†Ôºå‰ª•ÊèêÈ´òÂØπÊú™ËßÅÂ§πÁà™ÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÊï¥‰∏™Ê°ÜÊû∂ÂèØ‰ª•‰∏éËßÜËßâÂü∫Á°ÄÊ®°ÂûãÈõÜÊàêÔºå‰∏∫Êú™Êù•ÁöÑËßÜËßâ-ËØ≠Ë®ÄËÉΩÂäõÊèê‰æõÊîØÊåÅ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöXGraspÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂gripper-awareÁöÑËÆæËÆ°ÂíåÂØπÊØîÂ≠¶‰π†ÁöÑÂ∫îÁî®„ÄÇÈÄöËøáÂ∞ÜÂ§πÁà™ÁöÑËßÑÊ†º‰ø°ÊÅØËûçÂÖ•Âà∞ÊäìÂèñÊ£ÄÊµãËøáÁ®ã‰∏≠ÔºåXGraspËÉΩÂ§üÊõ¥Â•ΩÂú∞ÈÄÇÂ∫î‰∏çÂêåÁöÑÂ§πÁà™„ÄÇÂØπÊØîÂ≠¶‰π†Âàô‰ΩøÂæóXGraspËÉΩÂ§üÂ≠¶‰π†Âà∞ÈÄöÁî®ÁöÑÊäìÂèñÁâπÂæÅÔºå‰ªéËÄåÂÆûÁé∞ÂØπÊú™ËßÅÂ§πÁà™ÁöÑÈõ∂Ê†∑Êú¨Ê≥õÂåñ„ÄÇËøô‰∏é‰º†ÁªüÁöÑÈíàÂØπÁâπÂÆöÂ§πÁà™ËÆæËÆ°ÁöÑÊäìÂèñÊñπÊ≥ïÊúâÊú¨Ë¥®ÁöÑÂå∫Âà´„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöGPPÊ®°Âùó‰ΩøÁî®ÂÖ®Â±ÄÂú∫ÊôØ‰ø°ÊÅØÂíåÂ§πÁà™ËßÑÊ†º‰Ωú‰∏∫ËæìÂÖ•ÔºåÈ¢ÑÊµãÊäìÂèñÁÇπ„ÄÇAWPÊ®°Âùó‰ΩøÁî®Â±ÄÈÉ®ÁâπÂæÅÔºåÂπ∂ÁªìÂêàÂØπÊØîÂ≠¶‰π†ÔºåÁªÜÂåñÊäìÂèñËßíÂ∫¶ÂíåÂÆΩÂ∫¶„ÄÇÂØπÊØîÂ≠¶‰π†ÁöÑÁõÆÊ†áÊòØÊãâËøëÁõ∏‰ººÂ§πÁà™ÁöÑÁâπÂæÅË°®Á§∫ÔºåÊé®Ëøú‰∏çÁõ∏‰ººÂ§πÁà™ÁöÑÁâπÂæÅË°®Á§∫„ÄÇÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°ÈúÄË¶Å‰ªîÁªÜËÄÉËôëÔºå‰ª•‰øùËØÅÂØπÊØîÂ≠¶‰π†ÁöÑÊúâÊïàÊÄß„ÄÇÂÖ∑‰ΩìÁöÑÁΩëÁªúÁªìÊûÑÂíåÂèÇÊï∞ËÆæÁΩÆÈúÄË¶ÅÊ†πÊçÆÂÆûÈôÖÊÉÖÂÜµËøõË°åË∞ÉÊï¥„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåXGraspÂú®Â§öÁßçÂ§πÁà™Á±ªÂûã‰∏äÈÉΩÂèñÂæó‰∫ÜÂÖ∑ÊúâÁ´û‰∫âÂäõÁöÑÊäìÂèñÊàêÂäüÁéá„ÄÇÊõ¥ÈáçË¶ÅÁöÑÊòØÔºåXGraspÂú®Êé®ÁêÜÈÄüÂ∫¶‰∏äÁõ∏ÊØîÁé∞ÊúâÁöÑgripper-awareÊñπÊ≥ïÊúâ‰∫ÜÊòæËëóÁöÑÊèêÂçá„ÄÇËøô‰ΩøÂæóXGraspËÉΩÂ§üÊª°Ë∂≥ÂÆûÊó∂ÊäìÂèñÁöÑÈúÄÊ±ÇÔºå‰ªéËÄåÂèØ‰ª•Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠‰ΩøÁî®„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

XGraspÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºå‰æãÂ¶ÇÂú®ÊüîÊÄßÂà∂ÈÄ†„ÄÅÁâ©ÊµÅÂàÜÊã£„ÄÅÂÆ∂Â∫≠ÊúçÂä°Êú∫Âô®‰∫∫Á≠âÈ¢ÜÂüü„ÄÇÂÆÉÂèØ‰ª•‰ΩøÊú∫Âô®‰∫∫ËÉΩÂ§ü‰ΩøÁî®‰∏çÂêåÁöÑÂ§πÁà™Êù•Â§ÑÁêÜÂêÑÁßçÂΩ¢Áä∂ÂíåÂ§ßÂ∞èÁöÑÁâ©‰ΩìÔºå‰ªéËÄåÊèêÈ´òÊú∫Âô®‰∫∫ÁöÑÁÅµÊ¥ªÊÄßÂíåÈÄÇÂ∫îÊÄß„ÄÇÊ≠§Â§ñÔºåXGraspÁöÑÈõ∂Ê†∑Êú¨Ê≥õÂåñËÉΩÂäõ‰ΩøÂæóÊú∫Âô®‰∫∫ËÉΩÂ§üÂ§ÑÁêÜÊú™Áü•ÁöÑÂ§πÁà™ÔºåËøõ‰∏ÄÊ≠•Êâ©Â±ï‰∫ÜÂÖ∂Â∫îÁî®ËåÉÂõ¥„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Most robotic grasping methods are typically designed for single gripper types, which limits their applicability in real-world scenarios requiring diverse end-effectors. We propose XGrasp, a real-time gripper-aware grasp detection framework that efficiently handles multiple gripper configurations. The proposed method addresses data scarcity by systematically augmenting existing datasets with multi-gripper annotations. XGrasp employs a hierarchical two-stage architecture. In the first stage, a Grasp Point Predictor (GPP) identifies optimal locations using global scene information and gripper specifications. In the second stage, an Angle-Width Predictor (AWP) refines the grasp angle and width using local features. Contrastive learning in the AWP module enables zero-shot generalization to unseen grippers by learning fundamental grasping characteristics. The modular framework integrates seamlessly with vision foundation models, providing pathways for future vision-language capabilities. The experimental results demonstrate competitive grasp success rates across various gripper types, while achieving substantial improvements in inference speed compared to existing gripper-aware methods. Project page: https://sites.google.com/view/xgrasp

