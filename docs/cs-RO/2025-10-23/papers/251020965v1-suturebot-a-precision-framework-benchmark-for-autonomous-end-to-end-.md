---
layout: default
title: SutureBot: A Precision Framework & Benchmark For Autonomous End-to-End Suturing
---

# SutureBot: A Precision Framework & Benchmark For Autonomous End-to-End Suturing

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.20965" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.20965v1</a>
  <a href="https://arxiv.org/pdf/2510.20965.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.20965v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.20965v1', 'SutureBot: A Precision Framework & Benchmark For Autonomous End-to-End Suturing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jesse Haworth, Juo-Tung Chen, Nigel Nelson, Ji Woong Kim, Masoud Moghani, Chelsea Finn, Axel Krieger

**åˆ†ç±»**: cs.RO, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-10-23

**å¤‡æ³¨**: 10 pages, 5 figures, 4 tables, NeurIPS 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [HUGGINGFACE](https://huggingface.co/datasets/jchen396)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**SutureBotï¼šç”¨äºè‡ªä¸»ç«¯åˆ°ç«¯ç¼åˆçš„ç²¾å‡†æ¡†æ¶ä¸åŸºå‡†æµ‹è¯•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æœºå™¨äººç¼åˆ` `è‡ªä¸»æ“ä½œ` `ç›®æ ‡æ¡ä»¶å­¦ä¹ ` `è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹` `è¾¾èŠ¬å¥‡ç ”ç©¶å¥—ä»¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æœºå™¨äººç¼åˆæ–¹æ³•åœ¨ç«¯åˆ°ç«¯è‡ªä¸»æ€§æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨ç‰©ç†ç¡¬ä»¶ä¸Šçš„å®Œå…¨è‡ªä¸»æµç¨‹ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§ä»¥ç›®æ ‡ä¸ºæ¡ä»¶çš„æ¡†æ¶ï¼Œæ˜¾å¼ä¼˜åŒ–æ’å…¥ç‚¹ç²¾åº¦ï¼Œä»¥æé«˜ç¼åˆçš„å‡†ç¡®æ€§ã€‚
3. é€šè¿‡åœ¨dVRKä¸Šæ„å»ºSutureBotåŸºå‡†ï¼Œå¹¶å‘å¸ƒåŒ…å«1890ä¸ªæ¼”ç¤ºçš„æ•°æ®é›†ï¼Œä¿ƒè¿›äº†å¯é‡å¤çš„è¯„ä¼°å’Œå¼€å‘ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœºå™¨äººç¼åˆæ˜¯ä¸€é¡¹å…¸å‹çš„é•¿æ—¶ç¨‹çµå·§æ“ä½œä»»åŠ¡ï¼Œéœ€è¦åè°ƒçš„æŒé’ˆã€ç²¾ç¡®çš„ç»„ç»‡ç©¿é€å’Œç‰¢å›ºçš„ç»“æ‰ã€‚å°½ç®¡åœ¨ç«¯åˆ°ç«¯è‡ªä¸»æ€§æ–¹é¢åšå‡ºäº†è¯¸å¤šåŠªåŠ›ï¼Œä½†å°šæœªåœ¨ç‰©ç†ç¡¬ä»¶ä¸Šæ¼”ç¤ºå®Œå…¨è‡ªä¸»çš„ç¼åˆæµç¨‹ã€‚æˆ‘ä»¬æ¨å‡ºäº†SutureBotï¼šä¸€ä¸ªåœ¨è¾¾èŠ¬å¥‡ç ”ç©¶å¥—ä»¶ï¼ˆdVRKï¼‰ä¸Šçš„è‡ªä¸»ç¼åˆåŸºå‡†ï¼Œæ¶µç›–äº†æŒé’ˆã€ç»„ç»‡æ’å…¥å’Œç»“æ‰ã€‚ä¸ºäº†ç¡®ä¿å¯é‡å¤æ€§ï¼Œæˆ‘ä»¬å‘å¸ƒäº†ä¸€ä¸ªåŒ…å«1890ä¸ªç¼åˆæ¼”ç¤ºçš„é«˜ä¿çœŸæ•°æ®é›†ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªä»¥ç›®æ ‡ä¸ºæ¡ä»¶çš„æ¡†æ¶ï¼Œè¯¥æ¡†æ¶æ˜¾å¼åœ°ä¼˜åŒ–äº†æ’å…¥ç‚¹ç²¾åº¦ï¼Œä¸ä»…ä»»åŠ¡åŸºçº¿ç›¸æ¯”ï¼Œç›®æ ‡ç²¾åº¦æé«˜äº†59%-74%ã€‚ä¸ºäº†å°†æ­¤ä»»åŠ¡ç¡®ç«‹ä¸ºçµå·§æ¨¡ä»¿å­¦ä¹ çš„åŸºå‡†ï¼Œæˆ‘ä»¬è¯„ä¼°äº†æœ€å…ˆè¿›çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹ï¼ŒåŒ…æ‹¬$Ï€_0$ã€GR00T N1ã€OpenVLA-OFTå’Œå¤šä»»åŠ¡ACTï¼Œæ¯ä¸ªæ¨¡å‹éƒ½é€šè¿‡é«˜çº§ä»»åŠ¡é¢„æµ‹ç­–ç•¥è¿›è¡Œäº†å¢å¼ºã€‚è‡ªä¸»ç¼åˆæ˜¯å®ç°æ‰‹æœ¯æœºå™¨äººè‡ªä¸»æ€§çš„ä¸€ä¸ªå…³é”®é‡Œç¨‹ç¢‘ã€‚è¿™äº›è´¡çŒ®æ”¯æŒå¯¹ç«¯åˆ°ç«¯ç¼åˆæ‰€éœ€çš„ã€ä»¥ç²¾åº¦ä¸ºä¸­å¿ƒçš„é•¿æ—¶ç¨‹çµå·§æ“ä½œç­–ç•¥è¿›è¡Œå¯é‡å¤çš„è¯„ä¼°å’Œå¼€å‘ã€‚æ•°æ®é›†å¯åœ¨ä»¥ä¸‹ç½‘å€è·å¾—ï¼šhttps://huggingface.co/datasets/jchen396/suturebot

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æœºå™¨äººè‡ªä¸»ç¼åˆä¸­ç²¾åº¦ä¸è¶³çš„é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨é•¿æ—¶ç¨‹æ“ä½œä¸­ï¼Œå¦‚ä½•å®ç°ç«¯åˆ°ç«¯çš„è‡ªä¸»ç¼åˆï¼ŒåŒ…æ‹¬æŒé’ˆã€ç»„ç»‡ç©¿é€å’Œç»“æ‰ç­‰æ­¥éª¤ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥åœ¨çœŸå®ç‰©ç†ç¯å¢ƒä¸­è¾¾åˆ°è¶³å¤Ÿçš„ç²¾åº¦å’Œé²æ£’æ€§ï¼Œé™åˆ¶äº†å…¶åœ¨å®é™…æ‰‹æœ¯ä¸­çš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ä»¥ç›®æ ‡ä¸ºæ¡ä»¶ï¼Œæ˜¾å¼åœ°ä¼˜åŒ–æ’å…¥ç‚¹ç²¾åº¦ã€‚é€šè¿‡é¢„æµ‹å’Œä¼˜åŒ–ç¼åˆé’ˆçš„æ’å…¥ä½ç½®ï¼Œæé«˜ç¼åˆçš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚è¿™ç§æ–¹æ³•å°†ç¼åˆä»»åŠ¡åˆ†è§£ä¸ºå¤šä¸ªå­ä»»åŠ¡ï¼Œå¹¶é’ˆå¯¹æ¯ä¸ªå­ä»»åŠ¡è¿›è¡Œä¼˜åŒ–ï¼Œä»è€Œå®ç°æ›´ç²¾ç¡®çš„æ§åˆ¶ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSutureBotæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) æ•°æ®é‡‡é›†æ¨¡å—ï¼Œç”¨äºæ”¶é›†dVRKä¸Šçš„ç¼åˆæ¼”ç¤ºæ•°æ®ï¼›2) ç›®æ ‡æ¡ä»¶ç­–ç•¥æ¨¡å—ï¼Œç”¨äºé¢„æµ‹å’Œä¼˜åŒ–æ’å…¥ç‚¹ï¼›3) è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹ï¼Œç”¨äºå­¦ä¹ ç¼åˆç­–ç•¥ï¼›4) ä»»åŠ¡é¢„æµ‹ç­–ç•¥æ¨¡å—ï¼Œç”¨äºå¢å¼ºVLAæ¨¡å‹ã€‚æ•´ä½“æµç¨‹æ˜¯ä»æ•°æ®é›†ä¸­å­¦ä¹ ç¼åˆç­–ç•¥ï¼Œç„¶åä½¿ç”¨ç›®æ ‡æ¡ä»¶ç­–ç•¥ä¼˜åŒ–æ’å…¥ç‚¹ï¼Œæœ€åé€šè¿‡VLAæ¨¡å‹æ‰§è¡Œç¼åˆæ“ä½œã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ç›®æ ‡æ¡ä»¶ç­–ç•¥ï¼Œæ˜¾å¼åœ°ä¼˜åŒ–æ’å…¥ç‚¹ç²¾åº¦ã€‚ä¸ä¼ ç»Ÿçš„ä»…ä»»åŠ¡å­¦ä¹ æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å­¦ä¹ ç¼åˆç­–ç•¥ï¼Œå¹¶æé«˜ç¼åˆçš„å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æ„å»ºäº†ä¸€ä¸ªé«˜ä¿çœŸæ•°æ®é›†ï¼Œä¸ºæœºå™¨äººç¼åˆçš„ç ”ç©¶æä¾›äº†é‡è¦çš„èµ„æºã€‚

**å…³é”®è®¾è®¡**ï¼šç›®æ ‡æ¡ä»¶ç­–ç•¥çš„å…³é”®è®¾è®¡åœ¨äºä½¿ç”¨ä¸€ä¸ªç¥ç»ç½‘ç»œæ¥é¢„æµ‹æ’å…¥ç‚¹ï¼Œå¹¶ä½¿ç”¨ä¸€ä¸ªæŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ’å…¥ç‚¹çš„ä½ç½®ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬ä¸€ä¸ªç›®æ ‡æŸå¤±å’Œä¸€ä¸ªæ­£åˆ™åŒ–æŸå¤±ï¼Œç›®æ ‡æŸå¤±ç”¨äºè¡¡é‡é¢„æµ‹çš„æ’å…¥ç‚¹ä¸ç›®æ ‡æ’å…¥ç‚¹ä¹‹é—´çš„è·ç¦»ï¼Œæ­£åˆ™åŒ–æŸå¤±ç”¨äºé˜²æ­¢æ’å…¥ç‚¹è¿‡äºåç¦»ã€‚VLAæ¨¡å‹ä½¿ç”¨äº†Transformeræ¶æ„ï¼Œå¹¶ç»“åˆäº†è§†è§‰ã€è¯­è¨€å’ŒåŠ¨ä½œä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè®ºæ–‡æå‡ºçš„ç›®æ ‡æ¡ä»¶æ¡†æ¶åœ¨æ’å…¥ç‚¹ç²¾åº¦æ–¹é¢æ¯”ä»…ä»»åŠ¡åŸºçº¿æé«˜äº†59%-74%ã€‚é€šè¿‡åœ¨SutureBotåŸºå‡†ä¸Šè¯„ä¼°å¤šç§VLAæ¨¡å‹ï¼ŒéªŒè¯äº†è¯¥æ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œå‘å¸ƒçš„é«˜ä¿çœŸæ•°æ®é›†ä¸ºæœºå™¨äººç¼åˆé¢†åŸŸçš„ç ”ç©¶æä¾›äº†é‡è¦çš„èµ„æºï¼Œä¿ƒè¿›äº†ç›¸å…³æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¾®åˆ›æ‰‹æœ¯ã€è¿œç¨‹æ‰‹æœ¯ç­‰é¢†åŸŸï¼Œæé«˜æ‰‹æœ¯çš„ç²¾åº¦å’Œæ•ˆç‡ï¼Œé™ä½æ‰‹æœ¯é£é™©ã€‚é€šè¿‡è‡ªä¸»ç¼åˆï¼Œå¯ä»¥å‡è½»åŒ»ç”Ÿçš„å·¥ä½œè´Ÿæ‹…ï¼Œå¹¶ä¸ºç¼ºä¹ä¸“ä¸šåŒ»ç”Ÿçš„åœ°åŒºæä¾›åŒ»ç–—æœåŠ¡ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºæ›´å¤æ‚çš„æ‰‹æœ¯æ“ä½œï¼Œå®ç°æ‰‹æœ¯æœºå™¨äººçš„å®Œå…¨è‡ªä¸»åŒ–ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Robotic suturing is a prototypical long-horizon dexterous manipulation task, requiring coordinated needle grasping, precise tissue penetration, and secure knot tying. Despite numerous efforts toward end-to-end autonomy, a fully autonomous suturing pipeline has yet to be demonstrated on physical hardware. We introduce SutureBot: an autonomous suturing benchmark on the da Vinci Research Kit (dVRK), spanning needle pickup, tissue insertion, and knot tying. To ensure repeatability, we release a high-fidelity dataset comprising 1,890 suturing demonstrations. Furthermore, we propose a goal-conditioned framework that explicitly optimizes insertion-point precision, improving targeting accuracy by 59\%-74\% over a task-only baseline. To establish this task as a benchmark for dexterous imitation learning, we evaluate state-of-the-art vision-language-action (VLA) models, including $Ï€_0$, GR00T N1, OpenVLA-OFT, and multitask ACT, each augmented with a high-level task-prediction policy. Autonomous suturing is a key milestone toward achieving robotic autonomy in surgery. These contributions support reproducible evaluation and development of precision-focused, long-horizon dexterous manipulation policies necessary for end-to-end suturing. Dataset is available at: https://huggingface.co/datasets/jchen396/suturebot

