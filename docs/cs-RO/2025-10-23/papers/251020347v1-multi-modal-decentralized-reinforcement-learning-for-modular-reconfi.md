---
layout: default
title: Multi-Modal Decentralized Reinforcement Learning for Modular Reconfigurable Lunar Robots
---

# Multi-Modal Decentralized Reinforcement Learning for Modular Reconfigurable Lunar Robots

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.20347" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.20347v1</a>
  <a href="https://arxiv.org/pdf/2510.20347.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.20347v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.20347v1', 'Multi-Modal Decentralized Reinforcement Learning for Modular Reconfigurable Lunar Robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ashutosh Mishra, Shreya Santra, Elian Neppel, Edoardo M. Rossi Lombardi, Shamistan Karimov, Kentaro Uno, Kazuya Yoshida

**åˆ†ç±»**: cs.RO, cs.MA

**å‘å¸ƒæ—¥æœŸ**: 2025-10-23

**å¤‡æ³¨**: Accepted in IEEE iSpaRo 2025. Awaiting Publication

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šæ¨¡æ€åˆ†æ•£å¼å¼ºåŒ–å­¦ä¹ ï¼Œç”¨äºæ¨¡å—åŒ–å¯é‡æ„æœˆçƒæœºå™¨äººã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æ¨¡å—åŒ–æœºå™¨äºº` `åˆ†æ•£å¼å¼ºåŒ–å­¦ä¹ ` `å¤šæ¨¡æ€å­¦ä¹ ` `é›¶æ ·æœ¬æ³›åŒ–` `æœˆçƒæ¢æµ‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ¨¡å—åŒ–æœºå™¨äººå½¢æ€ç»„åˆçˆ†ç‚¸ï¼Œéš¾ä»¥ç»Ÿä¸€æ§åˆ¶ï¼Œä¸ºç©ºé—´ä»»åŠ¡å¸¦æ¥æŒ‘æˆ˜ã€‚
2. é‡‡ç”¨åˆ†æ•£å¼å¼ºåŒ–å­¦ä¹ ï¼Œæ¯ä¸ªæ¨¡å—è‡ªä¸»å­¦ä¹ ç­–ç•¥ï¼Œå®ç°é›¶æ ·æœ¬æ³›åŒ–ã€‚
3. ä»¿çœŸå’Œæœˆçƒæ¨¡æ‹Ÿæµ‹è¯•éªŒè¯äº†è‡ªä¸»ç§»åŠ¨ã€è½¬å‘å’Œé‡æ„å¯¹é½çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ†æ•£å¼å¼ºåŒ–å­¦ä¹ (Dec-RL)æ–¹æ¡ˆï¼Œç”¨äºæ§åˆ¶æ¨¡å—åŒ–å¯é‡æ„æœºå™¨äººï¼Œä½¿å…¶é€‚åº”ç‰¹å®šä»»åŠ¡çš„ç©ºé—´æ“ä½œã€‚æ¯ä¸ªæ¨¡å—å­¦ä¹ è‡ªå·±çš„ç­–ç•¥ï¼šè½®å¼æ¨¡å—ä½¿ç”¨è½¯æ¼”å‘˜-è¯„è®ºå®¶(SAC)ç®—æ³•è¿›è¡Œç§»åŠ¨ï¼Œ7è‡ªç”±åº¦(DoF)æœºæ¢°è‡‚ä½¿ç”¨è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–(PPO)ç®—æ³•è¿›è¡Œè½¬å‘å’Œæ“ä½œï¼Œä»è€Œå®ç°å¯¹æœªè§é…ç½®çš„é›¶æ ·æœ¬æ³›åŒ–ã€‚åœ¨ä»¿çœŸä¸­ï¼Œè½¬å‘ç­–ç•¥åœ¨æœŸæœ›è§’åº¦å’Œå®é™…è§’åº¦ä¹‹é—´çš„å¹³å‡ç»å¯¹è¯¯å·®ä¸º3.63Â°ï¼›æ“ä½œç­–ç•¥åœ¨ç›®æ ‡åç§»æ ‡å‡†ä¸‹çš„æˆåŠŸç‡ç¨³å®šåœ¨84.6%ï¼›è½®å¼ç­–ç•¥åœ¨ä¿æŒ99.6%æˆåŠŸç‡çš„åŒæ—¶ï¼Œå°†å¹³å‡ç”µæœºæ‰­çŸ©ç›¸å¯¹äºåŸºçº¿é™ä½äº†95.4%ã€‚æœˆçƒæ¨¡æ‹Ÿåœºåœ°æµ‹è¯•éªŒè¯äº†è‡ªä¸»ç§»åŠ¨ã€è½¬å‘å’Œåˆæ­¥å¯¹é½ä»¥è¿›è¡Œé‡æ„çš„é›¶æ ·æœ¬é›†æˆã€‚è¯¥ç³»ç»Ÿåœ¨ç­–ç•¥æ‰§è¡Œçš„åŒæ­¥ã€å¹¶è¡Œå’Œé¡ºåºæ¨¡å¼ä¹‹é—´å¹³ç¨³è¿‡æ¸¡ï¼Œæ²¡æœ‰ç©ºé—²çŠ¶æ€æˆ–æ§åˆ¶å†²çªï¼Œè¡¨æ˜è¯¥æ–¹æ³•å¯¹äºæ¨¡å—åŒ–æœˆçƒæœºå™¨äººå…·æœ‰å¯æ‰©å±•æ€§ã€å¯é‡ç”¨æ€§å’Œé²æ£’æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæ¨¡å—åŒ–å¯é‡æ„æœºå™¨äººåœ¨ç©ºé—´ä»»åŠ¡ä¸­å…·æœ‰ä¼˜åŠ¿ï¼Œä½†å…¶å½¢æ€ç»„åˆå‘ˆæŒ‡æ•°å¢é•¿ï¼Œå¯¼è‡´éš¾ä»¥è®¾è®¡ä¸€ä¸ªé€šç”¨çš„æ§åˆ¶ç­–ç•¥ã€‚ç°æœ‰çš„é›†ä¸­å¼æ§åˆ¶æ–¹æ³•éš¾ä»¥é€‚åº”ä¸åŒæ„å‹çš„æœºå™¨äººï¼Œå¹¶ä¸”è®¡ç®—å¤æ‚åº¦é«˜ï¼Œéš¾ä»¥å®æ—¶æ§åˆ¶ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§èƒ½å¤Ÿé€‚åº”ä¸åŒæ„å‹ï¼Œå¹¶ä¸”å…·æœ‰è‰¯å¥½æ³›åŒ–èƒ½åŠ›çš„æ§åˆ¶æ–¹æ³•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†æ§åˆ¶é—®é¢˜åˆ†è§£ä¸ºå¤šä¸ªå­é—®é¢˜ï¼Œæ¯ä¸ªå­é—®é¢˜ç”±ä¸€ä¸ªç‹¬ç«‹çš„æ¨¡å—è´Ÿè´£ã€‚æ¯ä¸ªæ¨¡å—é€šè¿‡å¼ºåŒ–å­¦ä¹ å­¦ä¹ è‡ªå·±çš„æ§åˆ¶ç­–ç•¥ï¼Œä»è€Œå®ç°åˆ†æ•£å¼æ§åˆ¶ã€‚è¿™ç§æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°é™ä½æ§åˆ¶å¤æ‚åº¦ï¼Œå¹¶ä¸”å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œèƒ½å¤Ÿé€‚åº”ä¸åŒçš„æœºå™¨äººæ„å‹ã€‚æ­¤å¤–ï¼Œé€šè¿‡å¤šæ¨¡æ€å­¦ä¹ ï¼Œé’ˆå¯¹ä¸åŒç±»å‹çš„æ¨¡å—ï¼ˆè½®å¼å’Œæœºæ¢°è‡‚ï¼‰é‡‡ç”¨ä¸åŒçš„å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«å¤šä¸ªç‹¬ç«‹çš„æ¨¡å—ï¼Œæ¯ä¸ªæ¨¡å—é…å¤‡è‡ªå·±çš„ä¼ æ„Ÿå™¨å’Œè®¡ç®—å•å…ƒã€‚æ¯ä¸ªæ¨¡å—é€šè¿‡å¼ºåŒ–å­¦ä¹ å­¦ä¹ è‡ªå·±çš„æ§åˆ¶ç­–ç•¥ã€‚è½®å¼æ¨¡å—ä½¿ç”¨SACç®—æ³•è¿›è¡Œç§»åŠ¨æ§åˆ¶ï¼Œæœºæ¢°è‡‚æ¨¡å—ä½¿ç”¨PPOç®—æ³•è¿›è¡Œè½¬å‘å’Œæ“ä½œæ§åˆ¶ã€‚åœ¨ç­–ç•¥æ‰§è¡Œé˜¶æ®µï¼Œå„ä¸ªæ¨¡å—å¯ä»¥åŒæ­¥ã€å¹¶è¡Œæˆ–é¡ºåºæ‰§è¡ŒåŠ¨ä½œï¼Œä»¥å®Œæˆå¤æ‚çš„ä»»åŠ¡ã€‚ç³»ç»Ÿè®¾è®¡é¿å…äº†ç©ºé—²çŠ¶æ€å’Œæ§åˆ¶å†²çªï¼Œä¿è¯äº†ç³»ç»Ÿçš„é²æ£’æ€§å’Œå¯æ‰©å±•æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå°†åˆ†æ•£å¼å¼ºåŒ–å­¦ä¹ åº”ç”¨äºæ¨¡å—åŒ–å¯é‡æ„æœºå™¨äººçš„æ§åˆ¶ã€‚é€šè¿‡è®©æ¯ä¸ªæ¨¡å—è‡ªä¸»å­¦ä¹ ç­–ç•¥ï¼Œå®ç°äº†å¯¹ä¸åŒæ„å‹çš„é›¶æ ·æœ¬æ³›åŒ–ã€‚æ­¤å¤–ï¼Œé’ˆå¯¹ä¸åŒç±»å‹çš„æ¨¡å—é‡‡ç”¨ä¸åŒçš„å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œè¿›ä¸€æ­¥æé«˜äº†æ§åˆ¶æ€§èƒ½ã€‚è¿™ç§æ–¹æ³•æœ‰æ•ˆåœ°é™ä½äº†æ§åˆ¶å¤æ‚åº¦ï¼Œå¹¶ä¸”å…·æœ‰è‰¯å¥½çš„å¯æ‰©å±•æ€§å’Œé²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šè½®å¼æ¨¡å—ä½¿ç”¨SACç®—æ³•ï¼Œå¥–åŠ±å‡½æ•°è®¾è®¡é¼“åŠ±é«˜æ•ˆç§»åŠ¨å¹¶æƒ©ç½šè¿‡å¤§çš„ç”µæœºæ‰­çŸ©ã€‚æœºæ¢°è‡‚æ¨¡å—ä½¿ç”¨PPOç®—æ³•ï¼Œå¥–åŠ±å‡½æ•°è®¾è®¡é¼“åŠ±æœºæ¢°è‡‚åˆ°è¾¾ç›®æ ‡ä½ç½®å¹¶ä¿æŒç¨³å®šã€‚ç½‘ç»œç»“æ„æ–¹é¢ï¼ŒSACå’ŒPPOéƒ½é‡‡ç”¨äº†Actor-Criticç»“æ„ï¼Œå…·ä½“ç½‘ç»œå±‚æ•°å’Œç¥ç»å…ƒæ•°é‡æ ¹æ®å®é™…ä»»åŠ¡è¿›è¡Œè°ƒæ•´ã€‚å®éªŒä¸­ï¼Œå¯¹SACå’ŒPPOçš„è¶…å‚æ•°è¿›è¡Œäº†ç²¾ç»†è°ƒæ•´ï¼Œä¾‹å¦‚å­¦ä¹ ç‡ã€æŠ˜æ‰£å› å­ã€è£å‰ªèŒƒå›´ç­‰ï¼Œä»¥è·å¾—æœ€ä½³æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ä»¿çœŸç»“æœè¡¨æ˜ï¼Œè½¬å‘ç­–ç•¥çš„å¹³å‡ç»å¯¹è¯¯å·®ä¸º3.63Â°ï¼Œæ“ä½œç­–ç•¥çš„æˆåŠŸç‡è¾¾åˆ°84.6%ï¼Œè½®å¼ç­–ç•¥åœ¨ä¿æŒ99.6%æˆåŠŸç‡çš„åŒæ—¶ï¼Œå°†å¹³å‡ç”µæœºæ‰­çŸ©é™ä½äº†95.4%ã€‚æœˆçƒæ¨¡æ‹Ÿåœºåœ°æµ‹è¯•éªŒè¯äº†ç³»ç»Ÿåœ¨è‡ªä¸»ç§»åŠ¨ã€è½¬å‘å’Œé‡æ„å¯¹é½æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚ç³»ç»Ÿèƒ½å¤Ÿåœ¨åŒæ­¥ã€å¹¶è¡Œå’Œé¡ºåºæ¨¡å¼ä¹‹é—´å¹³ç¨³è¿‡æ¸¡ï¼Œæ²¡æœ‰ç©ºé—²çŠ¶æ€æˆ–æ§åˆ¶å†²çªã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæœˆçƒæ¢æµ‹ã€ç©ºé—´ç«™ç»´æŠ¤ã€ç¾åæ•‘æ´ç­‰é¢†åŸŸã€‚æ¨¡å—åŒ–æœºå™¨äººèƒ½å¤Ÿæ ¹æ®ä»»åŠ¡éœ€æ±‚è¿›è¡Œé‡æ„ï¼Œé€‚åº”å¤æ‚å¤šå˜çš„ç¯å¢ƒã€‚åˆ†æ•£å¼æ§åˆ¶æ–¹æ³•æé«˜äº†ç³»ç»Ÿçš„é²æ£’æ€§å’Œå¯æ‰©å±•æ€§ï¼Œä½¿å…¶èƒ½å¤Ÿåº”å¯¹çªå‘æƒ…å†µã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºæ›´å¹¿æ³›çš„æœºå™¨äººé¢†åŸŸï¼Œä¾‹å¦‚è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½åˆ¶é€ ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Modular reconfigurable robots suit task-specific space operations, but the combinatorial growth of morphologies hinders unified control. We propose a decentralized reinforcement learning (Dec-RL) scheme where each module learns its own policy: wheel modules use Soft Actor-Critic (SAC) for locomotion and 7-DoF limbs use Proximal Policy Optimization (PPO) for steering and manipulation, enabling zero-shot generalization to unseen configurations. In simulation, the steering policy achieved a mean absolute error of 3.63Â° between desired and induced angles; the manipulation policy plateaued at 84.6 % success on a target-offset criterion; and the wheel policy cut average motor torque by 95.4 % relative to baseline while maintaining 99.6 % success. Lunar-analogue field tests validated zero-shot integration for autonomous locomotion, steering, and preliminary alignment for reconfiguration. The system transitioned smoothly among synchronous, parallel, and sequential modes for Policy Execution, without idle states or control conflicts, indicating a scalable, reusable, and robust approach for modular lunar robots.

