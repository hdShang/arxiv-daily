---
layout: default
title: Robust Point Cloud Reinforcement Learning via PCA-Based Canonicalization
---

# Robust Point Cloud Reinforcement Learning via PCA-Based Canonicalization

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.20974" target="_blank" class="toolbar-btn">arXiv: 2510.20974v2</a>
    <a href="https://arxiv.org/pdf/2510.20974.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.20974v2" 
            onclick="toggleFavorite(this, '2510.20974v2', 'Robust Point Cloud Reinforcement Learning via PCA-Based Canonicalization')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Michael Bezick, Vittorio Giammarino, Ahmed H. Qureshi

**ÂàÜÁ±ª**: cs.RO, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-23 (Êõ¥Êñ∞: 2025-10-28)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éPCAÁöÑËßÑËåÉÂåñÊñπÊ≥ïPPCÔºåÊèêÂçáÁÇπ‰∫ëÂº∫ÂåñÂ≠¶‰π†Âú®Êú™Áü•ËßÜËßí‰∏ãÁöÑÈ≤ÅÊ£íÊÄß**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `ÁÇπ‰∫ëÂº∫ÂåñÂ≠¶‰π†` `PCA` `ËßÑËåÉÂåñ` `Êú∫Âô®‰∫∫ÊéßÂà∂` `ËßÜËßíÈ≤ÅÊ£íÊÄß`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂü∫‰∫éËßÜËßâÁöÑÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÂØπËßÜËßíÂèòÂåñÊïèÊÑüÔºåÂΩ±Âìç‰∫ÜÂú®ÁúüÂÆûÊú∫Âô®‰∫∫‰ªªÂä°‰∏≠ÁöÑÂèØÈù†ÊÄß„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫PCAÁÇπ‰∫ëÔºàPPCÔºâËßÑËåÉÂåñÊ°ÜÊû∂ÔºåÈÄöËøáÂ∞ÜÁÇπ‰∫ëÊò†Â∞ÑÂà∞Áªü‰∏ÄÁöÑËßÑËåÉÂßøÊÄÅÊù•ÂáèÂ∞ëËßÜËßíÂ∑ÆÂºÇ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåPPCËÉΩÊúâÊïàÊèêÂçáÂº∫ÂåñÂ≠¶‰π†ÁÆóÊ≥ïÂú®Êú™Áü•Áõ∏Êú∫ÂßøÊÄÅ‰∏ãÁöÑÈ≤ÅÊ£íÊÄßÔºå‰ºò‰∫éÈ¢ÜÂüüÈöèÊú∫ÂåñÊñπÊ≥ï„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËøëÂπ¥Êù•ÔºåÂü∫‰∫éÂéüÂßãËßÜËßâËæìÂÖ•ÁöÑÂº∫ÂåñÂ≠¶‰π†ÂèñÂæó‰∫ÜÊòæËëóËøõÂ±ïÔºå‰ΩÜÂÖ∂ÂØπÂÖâÁÖß„ÄÅÈ¢úËâ≤ÂíåËßÜËßíÁ≠âÂàÜÂ∏ÉÂ§ñÂèòÂåñÁöÑËÑÜÂº±ÊÄß‰ªçÁÑ∂Â≠òÂú®„ÄÇÁÇπ‰∫ëÂº∫ÂåñÂ≠¶‰π†ÔºàPC-RLÔºâÈÄöËøáÂáèËΩªÂü∫‰∫éÂ§ñËßÇÁöÑËÑÜÂº±ÊÄßÊèê‰æõ‰∫Ü‰∏ÄÁßçÊúâÂ∏åÊúõÁöÑÊõø‰ª£ÊñπÊ°àÔºå‰ΩÜÂÖ∂ÂØπÁõ∏Êú∫ÂßøÊÄÅ‰∏çÂåπÈÖçÁöÑÊïèÊÑüÊÄßÁªßÁª≠ÂâäÂº±‰∫ÜÂÖ∂Âú®ÂÆûÈôÖÁéØÂ¢É‰∏≠ÁöÑÂèØÈù†ÊÄß„ÄÇ‰∏∫‰∫ÜÂ∫îÂØπËøô‰∏ÄÊåëÊàòÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜPCAÁÇπ‰∫ëÔºàPPCÔºâÔºåËøôÊòØ‰∏ÄÁßç‰∏ìÈó®‰∏∫‰∏ãÊ∏∏Êú∫Âô®‰∫∫ÊéßÂà∂ÈáèË∫´ÂÆöÂà∂ÁöÑËßÑËåÉÂåñÊ°ÜÊû∂„ÄÇPPCÂ∞Ü‰ªªÊÑèÂàö‰ΩìÂèòÊç¢‰∏ãÁöÑÁÇπ‰∫ëÊò†Â∞ÑÂà∞ÂîØ‰∏ÄÁöÑËßÑËåÉÂßøÊÄÅÔºåÂ∞ÜËßÇÊµãÂØπÈΩêÂà∞‰∏ÄËá¥ÁöÑÂùêÊ†áÁ≥ªÔºå‰ªéËÄåÂ§ßÂ§ßÂáèÂ∞ë‰∫ÜËßÜËßíÂºïËµ∑ÁöÑ‰∏ç‰∏ÄËá¥ÊÄß„ÄÇÂú®Êàë‰ª¨ÁöÑÂÆûÈ™å‰∏≠ÔºåÊàë‰ª¨Ë°®ÊòéPPCÊèêÈ´ò‰∫ÜÂú®ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÊú∫Âô®‰∫∫‰ªªÂä°‰∏≠ÂØπÊú™ËßÅÁõ∏Êú∫ÂßøÊÄÅÁöÑÈ≤ÅÊ£íÊÄßÔºå‰∏∫È¢ÜÂüüÈöèÊú∫ÂåñÊèê‰æõ‰∫Ü‰∏ÄÁßçÂéüÂàôÊÄßÁöÑÊõø‰ª£ÊñπÊ°à„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÁöÑÁÇπ‰∫ëÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÂØπÁõ∏Êú∫ÂßøÊÄÅÁöÑÂèòÂåñÈùûÂ∏∏ÊïèÊÑü„ÄÇÂç≥‰ΩøÊòØËΩªÂæÆÁöÑËßÜËßíÂèòÂåñÔºå‰πü‰ºöÂØºËá¥Á≠ñÁï•ÊÄßËÉΩÊòæËëó‰∏ãÈôç„ÄÇËøôÁßçÊïèÊÑüÊÄßÈôêÂà∂‰∫ÜÁÇπ‰∫ëÂº∫ÂåñÂ≠¶‰π†Âú®ÂÆûÈôÖÊú∫Âô®‰∫∫Â∫îÁî®‰∏≠ÁöÑÈÉ®ÁΩ≤ÔºåÂõ†‰∏∫ÁúüÂÆûÁéØÂ¢É‰∏≠ÁöÑÁõ∏Êú∫ÂßøÊÄÅÂæÄÂæÄÈöæ‰ª•Á≤æÁ°ÆÊéßÂà∂„ÄÇÁé∞ÊúâÊñπÊ≥ïÔºåÂ¶ÇÈ¢ÜÂüüÈöèÊú∫ÂåñÔºåËôΩÁÑ∂ÂèØ‰ª•ÁºìËß£Ëøô‰∏™ÈóÆÈ¢òÔºå‰ΩÜÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáèÁöÑËÆ≠ÁªÉÊï∞ÊçÆÂíåÁ≤æÁªÜÁöÑÂèÇÊï∞Ë∞ÉÊï¥Ôºå‰∏îÊ≥õÂåñËÉΩÂäõÊúâÈôê„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜÁÇπ‰∫ëÊï∞ÊçÆËΩ¨Êç¢Âà∞‰∏Ä‰∏™ËßÑËåÉÁöÑÂùêÊ†áÁ≥ª‰∏≠Ôºå‰ªéËÄåÊ∂àÈô§Áî±‰∫éÁõ∏Êú∫ÂßøÊÄÅÂèòÂåñÂºïËµ∑ÁöÑËßÇÊµãÂ∑ÆÂºÇ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåËÆ∫ÊñáÂà©Áî®‰∏ªÊàêÂàÜÂàÜÊûêÔºàPCAÔºâÊù•Á°ÆÂÆöÁÇπ‰∫ëÁöÑ‰∏ªËΩ¥ÊñπÂêëÔºåÂπ∂Â∞ÜÁÇπ‰∫ëÊóãËΩ¨Âà∞‰∏éËøô‰∫õ‰∏ªËΩ¥ÂØπÈΩêÁöÑËßÑËåÉÂßøÊÄÅ„ÄÇËøôÊ†∑ÔºåÊó†ËÆ∫Áõ∏Êú∫ÂßøÊÄÅÂ¶Ç‰ΩïÂèòÂåñÔºåÁÇπ‰∫ëÊï∞ÊçÆÈÉΩ‰ºöË¢´Êò†Â∞ÑÂà∞Âêå‰∏Ä‰∏™ËßÑËåÉÂùêÊ†áÁ≥ª‰∏≠Ôºå‰ªéËÄåÂáèÂ∞ë‰∫ÜËßÜËßíÂèòÂåñÂØπÂº∫ÂåñÂ≠¶‰π†Á≠ñÁï•ÁöÑÂΩ±Âìç„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöPPCÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Ê≠•È™§Ôºö1) Ëé∑ÂèñÁÇπ‰∫ëÊï∞ÊçÆÔºõ2) ÂØπÁÇπ‰∫ëÊï∞ÊçÆËøõË°å‰∏≠ÂøÉÂåñÂ§ÑÁêÜÔºåÂç≥ÂáèÂéªÁÇπ‰∫ëÁöÑË¥®ÂøÉÔºõ3) ‰ΩøÁî®PCAËÆ°ÁÆóÁÇπ‰∫ëÁöÑ‰∏ªÊàêÂàÜÔºõ4) Ê†πÊçÆ‰∏ªÊàêÂàÜÊûÑÂª∫ÊóãËΩ¨Áü©ÈòµÔºåÂ∞ÜÁÇπ‰∫ëÊóãËΩ¨Âà∞ËßÑËåÉÂßøÊÄÅÔºõ5) Â∞ÜËßÑËåÉÂåñÂêéÁöÑÁÇπ‰∫ëÊï∞ÊçÆËæìÂÖ•Âà∞Âº∫ÂåñÂ≠¶‰π†ÁÆóÊ≥ï‰∏≠ËøõË°åËÆ≠ÁªÉ„ÄÇÊï¥‰∏™ÊµÅÁ®ãÂèØ‰ª•ÂµåÂÖ•Âà∞Áé∞ÊúâÁöÑÁÇπ‰∫ëÂº∫ÂåñÂ≠¶‰π†Ê°ÜÊû∂‰∏≠Ôºå‰Ωú‰∏∫‰∏Ä‰∏™È¢ÑÂ§ÑÁêÜÊ≠•È™§„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöPPCÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂà©Áî®PCAËøõË°åÁÇπ‰∫ëËßÑËåÉÂåñÔºå‰ªéËÄåÊúâÊïàÂú∞ÂáèÂ∞ë‰∫ÜËßÜËßíÂèòÂåñÂØπÂº∫ÂåñÂ≠¶‰π†Á≠ñÁï•ÁöÑÂΩ±Âìç„ÄÇ‰∏é‰º†ÁªüÁöÑÈ¢ÜÂüüÈöèÊú∫ÂåñÊñπÊ≥ïÁõ∏ÊØîÔºåPPC‰∏çÈúÄË¶ÅÂ§ßÈáèÁöÑËÆ≠ÁªÉÊï∞ÊçÆÂíåÁ≤æÁªÜÁöÑÂèÇÊï∞Ë∞ÉÊï¥Ôºå‰∏îÂÖ∑ÊúâÊõ¥Â•ΩÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåPPCÊòØ‰∏ÄÁßçÊï∞ÊçÆÈ©±Âä®ÁöÑÊñπÊ≥ïÔºåÂèØ‰ª•Ëá™Âä®ÈÄÇÂ∫î‰∏çÂêåÁöÑÁÇπ‰∫ëÂΩ¢Áä∂ÂíåÁªìÊûÑÔºåËÄå‰∏çÈúÄË¶Å‰∫∫Â∑•ËÆæËÆ°ÁâπÂæÅ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöPPCÁöÑÂÖ≥ÈîÆËÆæËÆ°Âú®‰∫éÂ¶Ç‰ΩïÈÄâÊã©ÂêàÈÄÇÁöÑ‰∏ªÊàêÂàÜÊù•ÊûÑÂª∫ÊóãËΩ¨Áü©Èòµ„ÄÇËÆ∫Êñá‰∏≠Ôºå‰ΩúËÄÖÈÄâÊã©Ââç‰∏â‰∏™‰∏ªÊàêÂàÜ‰Ωú‰∏∫ÊóãËΩ¨Áü©ÈòµÁöÑÂü∫ÂêëÈáèÔºåÂπ∂Ê†πÊçÆËøô‰∫õÂü∫ÂêëÈáèÁöÑÈ°∫Â∫èÂíåÊñπÂêëÊù•Á°ÆÂÆöÊóãËΩ¨Áü©ÈòµÁöÑÁ¨¶Âè∑„ÄÇÊ≠§Â§ñÔºå‰ΩúËÄÖËøòÂØπÁÇπ‰∫ëÊï∞ÊçÆËøõË°å‰∫Ü‰∏≠ÂøÉÂåñÂ§ÑÁêÜÔºå‰ª•Á°Æ‰øùPCAÁöÑËÆ°ÁÆóÁªìÊûú‰∏çÂèóÁÇπ‰∫ë‰ΩçÁΩÆÁöÑÂΩ±Âìç„ÄÇÂú®Âº∫ÂåñÂ≠¶‰π†ÁÆóÊ≥ïÁöÑÈÄâÊã©‰∏äÔºå‰ΩúËÄÖ‰ΩøÁî®‰∫ÜÂ∏∏ËßÅÁöÑDDPGÁÆóÊ≥ïÔºåÂπ∂ÂØπÂÖ∂ËøõË°å‰∫Ü‰∏Ä‰∫õÂæÆË∞ÉÔºå‰ª•ÈÄÇÂ∫îËßÑËåÉÂåñÂêéÁöÑÁÇπ‰∫ëÊï∞ÊçÆ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåPPCËÉΩÂ§üÊòæËëóÊèêÈ´òÂº∫ÂåñÂ≠¶‰π†ÁÆóÊ≥ïÂú®Êú™Áü•Áõ∏Êú∫ÂßøÊÄÅ‰∏ãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇÂú®Â§ö‰∏™ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÊú∫Âô®‰∫∫‰ªªÂä°‰∏≠ÔºåPPCÁöÑÊÄßËÉΩ‰ºò‰∫é‰º†ÁªüÁöÑÈ¢ÜÂüüÈöèÊú∫ÂåñÊñπÊ≥ï„ÄÇ‰æãÂ¶ÇÔºåÂú®ÊäìÂèñ‰ªªÂä°‰∏≠ÔºåPPCÂèØ‰ª•Â∞ÜÊäìÂèñÊàêÂäüÁéáÊèêÈ´ò10%‰ª•‰∏ä„ÄÇÊ≠§Â§ñÔºåÂÆûÈ™åËøòË°®ÊòéÔºåPPCÂÖ∑ÊúâËâØÂ•ΩÁöÑÊ≥õÂåñËÉΩÂäõÔºåÂèØ‰ª•Âú®‰∏çÂêåÁöÑÊú∫Âô®‰∫∫Âπ≥Âè∞Âíå‰∏çÂêåÁöÑ‰ªªÂä°‰∏≠ÂèñÂæóËâØÂ•ΩÁöÑÊïàÊûú„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂπøÊ≥õÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫Êìç‰Ωú„ÄÅËá™Âä®È©æÈ©∂„ÄÅ‰∏âÁª¥ÈáçÂª∫Á≠âÈ¢ÜÂüü„ÄÇ‰æãÂ¶ÇÔºåÂú®Êú∫Âô®‰∫∫Êìç‰Ωú‰∏≠ÔºåPPCÂèØ‰ª•Â∏ÆÂä©Êú∫Âô®‰∫∫Êõ¥Â•ΩÂú∞ÁêÜËß£ÂíåÂ§ÑÁêÜÊù•Ëá™‰∏çÂêåËßÜËßíÁöÑÁâ©‰ΩìÔºå‰ªéËÄåÊèêÈ´òÊìç‰ΩúÁöÑÈ≤ÅÊ£íÊÄßÂíåÁ≤æÂ∫¶„ÄÇÂú®Ëá™Âä®È©æÈ©∂‰∏≠ÔºåPPCÂèØ‰ª•Â∏ÆÂä©ËΩ¶ËæÜÊõ¥Â•ΩÂú∞ËØÜÂà´ÂíåË∑üË∏™Âë®Âõ¥ÁöÑËΩ¶ËæÜÂíåË°å‰∫∫Ôºå‰ªéËÄåÊèêÈ´òÈ©æÈ©∂ÁöÑÂÆâÂÖ®ÊÄß„ÄÇÊ≠§Â§ñÔºåPPCËøòÂèØ‰ª•Áî®‰∫é‰∏âÁª¥ÈáçÂª∫ÔºåÈÄöËøáÂ∞Ü‰∏çÂêåËßÜËßíÁöÑÁÇπ‰∫ëÊï∞ÊçÆÂØπÈΩêÂà∞Âêå‰∏Ä‰∏™ÂùêÊ†áÁ≥ª‰∏≠Ôºå‰ªéËÄåÊèêÈ´òÈáçÂª∫ÁöÑË¥®ÈáèÂíåÊïàÁéá„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Reinforcement Learning (RL) from raw visual input has achieved impressive successes in recent years, yet it remains fragile to out-of-distribution variations such as changes in lighting, color, and viewpoint. Point Cloud Reinforcement Learning (PC-RL) offers a promising alternative by mitigating appearance-based brittleness, but its sensitivity to camera pose mismatches continues to undermine reliability in realistic settings. To address this challenge, we propose PCA Point Cloud (PPC), a canonicalization framework specifically tailored for downstream robotic control. PPC maps point clouds under arbitrary rigid-body transformations to a unique canonical pose, aligning observations to a consistent frame, thereby substantially decreasing viewpoint-induced inconsistencies. In our experiments, we show that PPC improves robustness to unseen camera poses across challenging robotic tasks, providing a principled alternative to domain randomization.

