---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-05-14
---

# cs.ROï¼ˆ2025-05-14ï¼‰

ğŸ“Š å…± **5** ç¯‡è®ºæ–‡
 | ğŸ”— **1** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (3 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (3 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250509040v3-rt-cache-training-free-retrieval-for-real-time-manipulation.html">RT-Cache: Training-Free Retrieval for Real-Time Manipulation</a></td>
  <td>æå‡ºRT-Cacheä»¥è§£å†³å®æ—¶æ“ä½œä¸­çš„è®­ç»ƒéœ€æ±‚é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">multimodal</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.09040v3" data-paper-url="./papers/250509040v3-rt-cache-training-free-retrieval-for-real-time-manipulation.html" onclick="toggleFavorite(this, '2505.09040v3', 'RT-Cache: Training-Free Retrieval for Real-Time Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250509099v1-imitation-learning-for-adaptive-control-of-a-virtual-soft-exoglove.html">Imitation Learning for Adaptive Control of a Virtual Soft Exoglove</a></td>
  <td>æå‡ºåŸºäºæ¨¡ä»¿å­¦ä¹ çš„è™šæ‹Ÿè½¯å¤–éª¨éª¼è‡ªé€‚åº”æ§åˆ¶æ–¹æ¡ˆ</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">reinforcement learning</span> <span class="paper-tag">imitation learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.09099v1" data-paper-url="./papers/250509099v1-imitation-learning-for-adaptive-control-of-a-virtual-soft-exoglove.html" onclick="toggleFavorite(this, '2505.09099v1', 'Imitation Learning for Adaptive Control of a Virtual Soft Exoglove')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250509109v1-foldnet-learning-generalizable-closed-loop-policy-for-garment-foldin.html">FoldNet: Learning Generalizable Closed-Loop Policy for Garment Folding via Keypoint-Driven Asset and Demonstration Synthesis</a></td>
  <td>æå‡ºFoldNetä»¥è§£å†³æœè£…æŠ˜å ä»»åŠ¡ä¸­çš„æ•°æ®ç”ŸæˆæŒ‘æˆ˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">imitation learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.09109v1" data-paper-url="./papers/250509109v1-foldnet-learning-generalizable-closed-loop-policy-for-garment-foldin.html" onclick="toggleFavorite(this, '2505.09109v1', 'FoldNet: Learning Generalizable Closed-Loop Policy for Garment Folding via Keypoint-Driven Asset and Demonstration Synthesis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>4</td>
  <td><a href="./papers/250509108v1-air-ground-collaboration-for-language-specified-missions-in-unknown-.html">Air-Ground Collaboration for Language-Specified Missions in Unknown Environments</a></td>
  <td>æå‡ºä¸€ç§ç©ºåœ°åä½œç³»ç»Ÿä»¥è§£å†³è¯­è¨€æŒ‡å®šä»»åŠ¡çš„æŒ‘æˆ˜</td>
  <td class="tags-cell"><span class="paper-tag">semantic mapping</span> <span class="paper-tag">semantic map</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.09108v1" data-paper-url="./papers/250509108v1-air-ground-collaboration-for-language-specified-missions-in-unknown-.html" onclick="toggleFavorite(this, '2505.09108v1', 'Air-Ground Collaboration for Language-Specified Missions in Unknown Environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>5</td>
  <td><a href="./papers/250511535v1-bridging-human-oversight-and-black-box-driver-assistance-vision-lang.html">Bridging Human Oversight and Black-box Driver Assistance: Vision-Language Models for Predictive Alerting in Lane Keeping Assist Systems</a></td>
  <td>æå‡ºLKAlertä»¥è§£å†³LKAç³»ç»Ÿäººæœºåä½œä¸è¶³é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.11535v1" data-paper-url="./papers/250511535v1-bridging-human-oversight-and-black-box-driver-assistance-vision-lang.html" onclick="toggleFavorite(this, '2505.11535v1', 'Bridging Human Oversight and Black-box Driver Assistance: Vision-Language Models for Predictive Alerting in Lane Keeping Assist Systems')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)