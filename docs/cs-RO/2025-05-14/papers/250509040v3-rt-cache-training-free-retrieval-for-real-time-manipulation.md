---
layout: default
title: "RT-Cache: Training-Free Retrieval for Real-Time Manipulation"
---

# RT-Cache: Training-Free Retrieval for Real-Time Manipulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.09040" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.09040v3</a>
  <a href="https://arxiv.org/pdf/2505.09040.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.09040v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.09040v3', 'RT-Cache: Training-Free Retrieval for Real-Time Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Owen Kwon, Abraham George, Alison Bartsch, Amir Barati Farimani

**åˆ†ç±»**: cs.RO, cs.AI, cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-14 (æ›´æ–°: 2025-08-25)

**å¤‡æ³¨**: 8 pages, 6 figures. 2025 IEEE-RAS 24th International Conference on Humanoid Robots

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://rt-cache.github.io/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRT-Cacheä»¥è§£å†³å®æ—¶æ“ä½œä¸­çš„è®­ç»ƒéœ€æ±‚é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å®æ—¶æ§åˆ¶` `æ— è®­ç»ƒæ£€ç´¢` `æœºå™¨äººæ“ä½œ` `å‘é‡å†…å­˜` `åˆ†å±‚æœç´¢` `å¤šæ­¥åŠ¨ä½œé‡æ”¾` `æ™ºèƒ½åˆ¶é€ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æ–°ç¯å¢ƒä¸­é‡å¤è¡Œä¸ºæ—¶ï¼Œé€šå¸¸éœ€è¦å¤§é‡çš„æ¨ç†è®¡ç®—æˆ–å¾®è°ƒï¼Œå¯¼è‡´å®æ—¶æ§åˆ¶çš„æ•ˆç‡ä½ä¸‹ã€‚
2. RT-Cacheé€šè¿‡ç¼“å­˜å¤šæ ·çš„å›¾åƒåŠ¨ä½œè½¨è¿¹ï¼Œåˆ©ç”¨æ£€ç´¢æœºåˆ¶æ›¿ä»£æ¯æ­¥æ¨¡å‹è°ƒç”¨ï¼Œå®ç°æ— è®­ç»ƒçš„æ§åˆ¶ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒRT-Cacheåœ¨çœŸå®æœºå™¨äººä»»åŠ¡ä¸­æˆåŠŸç‡æé«˜çº¦2å€ï¼Œå®Œæˆæ—¶é—´å‡å°‘çº¦30%ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

çœŸå®æœºå™¨äººåœ¨æ–°ç¯å¢ƒä¸­é‡å¤ç›¸åŒè¡Œä¸ºæ—¶ï¼Œå¾€å¾€éœ€è¦æå°‘çš„æ–°æ•°æ®ã€‚ç„¶è€Œï¼Œç°ä»£æ§åˆ¶å™¨é€šå¸¸é¢ä¸´æ¯æ­¥æ¨ç†å¼€é”€å¤§æˆ–éœ€åœ¨éƒ¨ç½²æ—¶è¿›è¡Œå¾®è°ƒçš„é—®é¢˜ã€‚æœ¬æ–‡æå‡ºRT-Cacheï¼Œè¿™æ˜¯ä¸€ç§æ— è®­ç»ƒçš„æ£€ç´¢æ§åˆ¶ç®¡é“ï¼Œé€šè¿‡åœ¨ç»Ÿä¸€çš„å‘é‡å†…å­˜ä¸­ç¼“å­˜å¤šæ ·çš„å›¾åƒåŠ¨ä½œè½¨è¿¹ï¼Œåœ¨æµ‹è¯•æ—¶åµŒå…¥å½“å‰å¸§ä»¥æ£€ç´¢å’Œé‡æ”¾å¤šæ­¥ç‰‡æ®µï¼Œä»è€Œæ›¿ä»£æ¯æ­¥æ¨¡å‹è°ƒç”¨ã€‚åˆ†å±‚æœç´¢ä½¿å¾—åœ¨ç™¾ä¸‡è§„æ¨¡ä¸‹çš„æŸ¥æ‰¾ä¿æŒåœ¨äºšç§’çº§ï¼Œé™ä½äº†è®¡ç®—æˆæœ¬ï¼Œæ”¯æŒåœ¨ä¸­ç­‰æ€§èƒ½GPUä¸Šå®ç°å®æ—¶æ§åˆ¶ã€‚åœ¨çœŸå®æœºå™¨äººä»»åŠ¡å’Œå¤§å‹å¼€æ”¾æ—¥å¿—ä¸­ï¼ŒRT-Cacheçš„æˆåŠŸç‡æ¯”å¼ºåŸºçº¿é«˜å‡ºçº¦2å€ï¼Œå®Œæˆæ—¶é—´å¿«çº¦30%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è§£å†³çš„é—®é¢˜æ˜¯å¦‚ä½•åœ¨æ–°ç¯å¢ƒä¸­å®ç°çœŸå®æœºå™¨äººçš„é«˜æ•ˆé‡å¤è¡Œä¸ºï¼Œç°æœ‰æ–¹æ³•åœ¨æ­¤è¿‡ç¨‹ä¸­é¢ä¸´é«˜è®¡ç®—å¼€é”€å’Œå¾®è°ƒéœ€æ±‚çš„æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šRT-Cacheçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ç¼“å­˜å¤šæ ·çš„å›¾åƒåŠ¨ä½œè½¨è¿¹ï¼Œåˆ©ç”¨æ£€ç´¢æœºåˆ¶åœ¨æµ‹è¯•æ—¶å¿«é€Ÿé‡æ”¾å¤šæ­¥åŠ¨ä½œï¼Œé¿å…äº†æ¯æ­¥éƒ½è°ƒç”¨æ¨¡å‹çš„é«˜æˆæœ¬ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRT-Cacheçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ç»Ÿä¸€çš„å‘é‡å†…å­˜ç”¨äºå­˜å‚¨åŠ¨ä½œè½¨è¿¹ï¼Œåˆ†å±‚æœç´¢æœºåˆ¶ç”¨äºå¿«é€Ÿæ£€ç´¢ï¼Œä»¥åŠåµŒå…¥å½“å‰å¸§ä»¥è·å–ç›¸å…³åŠ¨ä½œç‰‡æ®µçš„æµç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šRT-Cacheçš„ä¸»è¦åˆ›æ–°åœ¨äºå°†ç»éªŒè½¬åŒ–ä¸ºä»…è¿½åŠ çš„å†…å­˜ç»“æ„ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—éœ€æ±‚ï¼ŒåŒæ—¶å®ç°äº†å®æ—¶æ§åˆ¶ï¼ŒåŒºåˆ«äºä¼ ç»Ÿéœ€è¦å¤§é‡æ¨ç†çš„æ§åˆ¶æ–¹æ³•ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬é«˜æ•ˆçš„å‘é‡å†…å­˜ç®¡ç†ã€åˆ†å±‚æœç´¢ç®—æ³•çš„å®ç°ï¼Œä»¥åŠåœ¨æ£€ç´¢è¿‡ç¨‹ä¸­å¯¹å½“å‰å¸§çš„åµŒå…¥æ–¹å¼ï¼Œè¿™äº›è®¾è®¡ç¡®ä¿äº†ç³»ç»Ÿåœ¨ç™¾ä¸‡è§„æ¨¡ä¸‹çš„å¿«é€Ÿå“åº”ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRT-Cacheåœ¨çœŸå®æœºå™¨äººä»»åŠ¡ä¸­æˆåŠŸç‡æé«˜çº¦2å€ï¼Œå®Œæˆæ—¶é—´å‡å°‘çº¦30%ã€‚ä¸å¼ºåŸºçº¿ç›¸æ¯”ï¼ŒRT-Cacheåœ¨æ€§èƒ½ä¸Šè¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ï¼Œè¯æ˜äº†å…¶åœ¨å®æ—¶æ§åˆ¶ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

RT-Cacheçš„ç ”ç©¶æˆæœåœ¨æœºå™¨äººæ“ä½œã€è‡ªåŠ¨åŒ–æ§åˆ¶å’Œæ™ºèƒ½åˆ¶é€ ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚å…¶æ— è®­ç»ƒçš„ç‰¹æ€§ä½¿å¾—æœºå™¨äººèƒ½å¤Ÿå¿«é€Ÿé€‚åº”æ–°ç¯å¢ƒï¼Œé™ä½äº†éƒ¨ç½²æˆæœ¬å’Œæ—¶é—´ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ›´å¤æ‚ä»»åŠ¡çš„å®æ—¶æ§åˆ¶èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Real robots are expected to repeat the same behavior in new environments with very little new data, yet modern controllers either incur heavy per-step inference or require deployment-time fine-tuning. We propose RT-Cache, a training-free retrieval-as-control pipeline that caches diverse image action trajectories in a unified vector memory and, at test time, embeds the current frame to retrieve and replay multi-step snippets, replacing per-step model calls. A hierarchical search keeps lookups sub-second at million scale, shifting cost from compute to storage and enabling real-time control on modest GPUs. Across real-robot tasks and large open logs, RT-Cache achieves higher success and lower completion time than strong retrieval baselines (approximately x2 higher success and ~30% faster in our settings), and a single-episode anchoring study shows immediate adaptation to a more complex, contact-rich task without fine-tuning. RT-Cache turns experience into an append-only memory, offering a simple, scalable path to few-shot deployment today and a foundation for multimodal keys and optional integration with high-level policies. Project page: https://rt-cache.github.io/.

