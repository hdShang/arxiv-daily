---
layout: default
title: One Policy but Many Worlds: A Scalable Unified Policy for Versatile Humanoid Locomotion
---

# One Policy but Many Worlds: A Scalable Unified Policy for Versatile Humanoid Locomotion

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.18780" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.18780v2</a>
  <a href="https://arxiv.org/pdf/2505.18780.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.18780v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.18780v2', 'One Policy but Many Worlds: A Scalable Unified Policy for Versatile Humanoid Locomotion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yahao Fan, Tianxiang Gui, Kaiyang Ji, Shutong Ding, Chixuan Zhang, Jiayuan Gu, Jingyi Yu, Jingya Wang, Ye Shi

**åˆ†ç±»**: cs.RO, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-24 (æ›´æ–°: 2025-06-03)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDreamPolicyä»¥è§£å†³äººå½¢æœºå™¨äººè¿åŠ¨çš„å¯æ‰©å±•æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)**

**å…³é”®è¯**: `äººå½¢æœºå™¨äºº` `å¼ºåŒ–å­¦ä¹ ` `è¿åŠ¨åˆæˆ` `æ•°æ®é©±åŠ¨` `å¯æ‰©å±•æ€§` `ç­–ç•¥ä¼˜åŒ–` `ç¦»çº¿å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨å¤„ç†å¤šæ ·åœ°å½¢æ—¶éœ€è¦ç‰¹å®šçš„å¥–åŠ±è®¾è®¡ï¼Œéš¾ä»¥åˆ©ç”¨æ‰©å±•çš„æ•°æ®é›†ï¼Œå¯¼è‡´å¯æ‰©å±•æ€§ä¸è¶³ã€‚
2. æˆ‘ä»¬æå‡ºçš„DreamPolicyæ¡†æ¶é€šè¿‡æ•´åˆç¦»çº¿æ•°æ®å’Œæ‰©æ•£é©±åŠ¨çš„è¿åŠ¨åˆæˆï¼Œå…è®¸å•ä¸€ç­–ç•¥åœ¨å¤šç§åœ°å½¢ä¸Šè¿›è¡Œå­¦ä¹ å’Œæ³›åŒ–ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDreamPolicyåœ¨è®­ç»ƒç¯å¢ƒä¸­çš„æˆåŠŸç‡è¾¾åˆ°90%ï¼Œå¹¶åœ¨æœªè§åœ°å½¢ä¸Šæ¯”ä¼ ç»Ÿæ–¹æ³•æé«˜äº†20%çš„æˆåŠŸç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äººå½¢æœºå™¨äººè¿åŠ¨é¢ä¸´å¯æ‰©å±•æ€§æŒ‘æˆ˜ï¼šä¼ ç»Ÿå¼ºåŒ–å­¦ä¹ æ–¹æ³•éœ€è¦ç‰¹å®šä»»åŠ¡çš„å¥–åŠ±ï¼Œä¸”éš¾ä»¥åˆ©ç”¨ä¸æ–­å¢é•¿çš„æ•°æ®é›†ã€‚æˆ‘ä»¬æå‡ºäº†DreamPolicyï¼Œä¸€ä¸ªç»Ÿä¸€æ¡†æ¶ï¼Œä½¿å•ä¸€ç­–ç•¥èƒ½å¤ŸæŒæ¡å¤šæ ·çš„åœ°å½¢ï¼Œå¹¶é€šè¿‡ç³»ç»Ÿæ•´åˆç¦»çº¿æ•°æ®å’Œæ‰©æ•£é©±åŠ¨çš„è¿åŠ¨åˆæˆï¼Œå®ç°å¯¹æœªè§åœºæ™¯çš„é›¶-shotæ³›åŒ–ã€‚DreamPolicyå¼•å…¥äº†äººå½¢è¿åŠ¨å›¾åƒï¼ˆHMIï¼‰ï¼Œé€šè¿‡è‡ªå›å½’çš„åœ°å½¢æ„ŸçŸ¥æ‰©æ•£è§„åˆ’å™¨åˆæˆæœªæ¥çŠ¶æ€é¢„æµ‹ï¼Œç›´æ¥æ•æ‰äººå½¢è¿åŠ¨å­¦ï¼Œé¿å…äº†ç¹ççš„é‡å®šå‘è¿‡ç¨‹ã€‚å®éªŒè¡¨æ˜ï¼ŒDreamPolicyåœ¨è®­ç»ƒç¯å¢ƒä¸­å¹³å‡æˆåŠŸç‡è¾¾åˆ°90%ï¼Œåœ¨æœªè§åœ°å½¢ä¸Šæ¯”ç°æœ‰æ–¹æ³•é«˜å‡º20%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³äººå½¢æœºå™¨äººè¿åŠ¨ä¸­çš„å¯æ‰©å±•æ€§é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨é¢å¯¹å¤šæ ·åŒ–åœ°å½¢æ—¶ï¼Œå¾€å¾€éœ€è¦ç‰¹å®šçš„ä»»åŠ¡å¥–åŠ±ï¼Œéš¾ä»¥æœ‰æ•ˆåˆ©ç”¨ä¸æ–­å¢é•¿çš„æ•°æ®é›†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDreamPolicyæ¡†æ¶çš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡æ•´åˆç¦»çº¿æ•°æ®å’Œæ‰©æ•£é©±åŠ¨çš„è¿åŠ¨åˆæˆï¼Œåˆ›å»ºä¸€ä¸ªç»Ÿä¸€çš„ç­–ç•¥ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨å¤šç§åœ°å½¢ä¸Šè¿›è¡Œå­¦ä¹ å’Œæ³›åŒ–ï¼Œé¿å…äº†ç¹ççš„æ‰‹åŠ¨å¥–åŠ±è®¾è®¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDreamPolicyçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šç¦»çº¿æ•°æ®æ•´åˆã€æ‰©æ•£é©±åŠ¨çš„è¿åŠ¨åˆæˆå’Œç­–ç•¥ä¼˜åŒ–ã€‚ç¦»çº¿æ•°æ®é€šè¿‡èšåˆä¸åŒåœ°å½¢çš„ç­–ç•¥å›æ”¾ï¼Œç”Ÿæˆæœªæ¥çŠ¶æ€é¢„æµ‹ï¼Œä¾›ç­–ç•¥å­¦ä¹ ä½¿ç”¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥äº†äººå½¢è¿åŠ¨å›¾åƒï¼ˆHMIï¼‰ï¼Œé€šè¿‡æ‰©æ•£è§„åˆ’å™¨åˆæˆçš„â€œæ¢¦å¢ƒâ€è½¨è¿¹ï¼Œç›´æ¥æ•æ‰äººå½¢è¿åŠ¨å­¦ï¼Œæ˜¾è‘—æé«˜äº†ç­–ç•¥çš„æ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸Šï¼ŒHMIçš„ç”Ÿæˆä¾èµ–äºè‡ªå›å½’çš„åœ°å½¢æ„ŸçŸ¥æ‰©æ•£è§„åˆ’å™¨ï¼Œé¿å…äº†ä¼ ç»Ÿæ–¹æ³•ä¸­çš„é‡å®šå‘éœ€æ±‚ï¼Œä¸”é€šè¿‡åŠ¨æ€ç›®æ ‡è®¾ç½®ï¼Œç®€åŒ–äº†å¥–åŠ±å·¥ç¨‹çš„å¤æ‚æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDreamPolicyåœ¨è®­ç»ƒç¯å¢ƒä¸­çš„å¹³å‡æˆåŠŸç‡è¾¾åˆ°90%ï¼Œåœ¨æœªè§åœ°å½¢ä¸Šæ¯”ç°æœ‰æ–¹æ³•æé«˜äº†20%çš„æˆåŠŸç‡ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨æ‰°åŠ¨å’Œå¤åˆåœºæ™¯ä¸­è¡¨ç°å‡ºè‰²ï¼Œå…‹æœäº†ä¼ ç»Ÿæ–¹æ³•çš„å±€é™æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬äººå½¢æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„è‡ªä¸»å¯¼èˆªã€æ•‘æ´ä»»åŠ¡å’Œäººæœºåä½œç­‰åœºæ™¯ã€‚é€šè¿‡å®ç°é«˜æ•ˆçš„è¿åŠ¨æ§åˆ¶ï¼ŒDreamPolicyèƒ½å¤Ÿæå‡æœºå™¨äººåœ¨å¤šæ ·åŒ–å’ŒæœªçŸ¥ç¯å¢ƒä¸­çš„é€‚åº”èƒ½åŠ›ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Humanoid locomotion faces a critical scalability challenge: traditional reinforcement learning (RL) methods require task-specific rewards and struggle to leverage growing datasets, even as more training terrains are introduced. We propose DreamPolicy, a unified framework that enables a single policy to master diverse terrains and generalize zero-shot to unseen scenarios by systematically integrating offline data and diffusion-driven motion synthesis. At its core, DreamPolicy introduces Humanoid Motion Imagery (HMI) - future state predictions synthesized through an autoregressive terrain-aware diffusion planner curated by aggregating rollouts from specialized policies across various distinct terrains. Unlike human motion datasets requiring laborious retargeting, our data directly captures humanoid kinematics, enabling the diffusion planner to synthesize "dreamed" trajectories that encode terrain-specific physical constraints. These trajectories act as dynamic objectives for our HMI-conditioned policy, bypassing manual reward engineering and enabling cross-terrain generalization. DreamPolicy addresses the scalability limitations of prior methods: while traditional RL fails to exploit growing datasets, our framework scales seamlessly with more offline data. As the dataset expands, the diffusion prior learns richer locomotion skills, which the policy leverages to master new terrains without retraining. Experiments demonstrate that DreamPolicy achieves average 90% success rates in training environments and an average of 20% higher success on unseen terrains than the prevalent method. It also generalizes to perturbed and composite scenarios where prior approaches collapse. By unifying offline data, diffusion-based trajectory synthesis, and policy optimization, DreamPolicy overcomes the "one task, one policy" bottleneck, establishing a paradigm for scalable, data-driven humanoid control.

