---
layout: default
title: "DiffusionRL: Efficient Training of Diffusion Policies for Robotic Grasping Using RL-Adapted Large-Scale Datasets"
---

# DiffusionRL: Efficient Training of Diffusion Policies for Robotic Grasping Using RL-Adapted Large-Scale Datasets

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.18876" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.18876v1</a>
  <a href="https://arxiv.org/pdf/2505.18876.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.18876v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.18876v1', 'DiffusionRL: Efficient Training of Diffusion Policies for Robotic Grasping Using RL-Adapted Large-Scale Datasets')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Maria Makarova, Qian Liu, Dzmitry Tsetserukou

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-05-24

**å¤‡æ³¨**: Submitted to CoRL 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDiffusionRLä»¥è§£å†³æœºå™¨äººæŠ“å–ä¸­çš„æ•°æ®é™åˆ¶é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æ‰©æ•£æ¨¡å‹` `å¼ºåŒ–å­¦ä¹ ` `æœºå™¨äººæŠ“å–` `æ•°æ®å¢å¼º` `çµå·§æ“ä½œ` `æ¨¡å‹æ³›åŒ–` `è‡ªåŠ¨åŒ–æŠ€æœ¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æœºå™¨äººæŠ“å–ä»»åŠ¡ä¸­é¢ä¸´æ•°æ®é™åˆ¶å’Œåœºæ™¯ç‰¹å®šé€‚åº”çš„æŒ‘æˆ˜ï¼Œå½±å“äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ‰©æ•£ç­–ç•¥è®­ç»ƒæ–¹æ³•ï¼Œåˆ©ç”¨å¤§å‹æ•°æ®é›†è¿›è¡Œä¼˜åŒ–ï¼Œæå‡äº†è®­ç»ƒæ•ˆç‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸‰ä¸ªDexGraspNetå¯¹è±¡ä¸Šå®ç°äº†80%çš„æˆåŠŸç‡ï¼Œæ˜¾è‘—æé«˜äº†æŠ“å–ä»»åŠ¡çš„è¡¨ç°ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ‰©æ•£æ¨¡å‹å·²æˆåŠŸåº”ç”¨äºå›¾åƒã€è§†é¢‘å’ŒéŸ³é¢‘ç”Ÿæˆç­‰é¢†åŸŸã€‚è¿‘æœŸç ”ç©¶è¡¨æ˜å…¶åœ¨åºåˆ—å†³ç­–å’Œçµå·§æ“ä½œä¸­çš„æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨å»ºæ¨¡å¤æ‚åŠ¨ä½œåˆ†å¸ƒæ–¹é¢ã€‚ç„¶è€Œï¼Œç”±äºæ•°æ®é™åˆ¶å’Œåœºæ™¯ç‰¹å®šé€‚åº”éœ€æ±‚ï¼Œä»é¢ä¸´æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ä¼˜åŒ–çš„æ‰©æ•£ç­–ç•¥è®­ç»ƒæ–¹æ³•ï¼Œåˆ©ç”¨å¤§å‹é¢„æ„å»ºæ•°æ®é›†ï¼Œå¹¶é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è¿›è¡Œå¢å¼ºã€‚æˆ‘ä»¬çš„ç«¯åˆ°ç«¯æµç¨‹ç»“åˆäº†åŸºäºRLçš„DexGraspNetæ•°æ®é›†å¢å¼ºã€è½»é‡çº§æ‰©æ•£ç­–ç•¥è®­ç»ƒä»¥åŠå§¿æ€é‡‡æ ·ç®—æ³•éªŒè¯ã€‚è¯¥æµç¨‹åœ¨ä¸‰ä¸ªDexGraspNetå¯¹è±¡ä¸Šå®ç°äº†80%çš„é«˜æˆåŠŸç‡ã€‚é€šè¿‡æ¶ˆé™¤æ‰‹åŠ¨æ•°æ®æ”¶é›†ï¼Œæˆ‘ä»¬çš„æ–¹æ³•é™ä½äº†æ‰©æ•£æ¨¡å‹åœ¨æœºå™¨äººé¢†åŸŸçš„åº”ç”¨é—¨æ§›ï¼Œå¢å¼ºäº†å®é™…åº”ç”¨çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æœºå™¨äººæŠ“å–ä»»åŠ¡ä¸­ç”±äºæ•°æ®é™åˆ¶å’Œåœºæ™¯ç‰¹å®šé€‚åº”éœ€æ±‚å¯¼è‡´çš„æ€§èƒ½ç“¶é¢ˆã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºæ‰‹åŠ¨æ•°æ®æ”¶é›†ï¼Œå¯¼è‡´è®­ç»ƒæ•ˆç‡ä½ä¸‹å’Œæ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºé€šè¿‡å¼ºåŒ–å­¦ä¹ å¢å¼ºå¤§å‹é¢„æ„å»ºæ•°æ®é›†ï¼Œç»“åˆè½»é‡çº§æ‰©æ•£ç­–ç•¥è®­ç»ƒï¼Œä»¥æé«˜æœºå™¨äººåœ¨çµå·§æ“ä½œä¸­çš„è¡¨ç°ã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨é™ä½æ•°æ®æ”¶é›†çš„å¤æ‚æ€§ï¼ŒåŒæ—¶æå‡æ¨¡å‹çš„é€‚åº”æ€§å’Œé²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯åŸºäºå¼ºåŒ–å­¦ä¹ çš„DexGraspNetæ•°æ®é›†å¢å¼ºï¼Œå…¶æ¬¡æ˜¯è½»é‡çº§çš„æ‰©æ•£ç­–ç•¥è®­ç»ƒï¼Œæœ€åæ˜¯ç”¨äºéªŒè¯çš„å§¿æ€é‡‡æ ·ç®—æ³•ã€‚è¿™ä¸€æµç¨‹ç¡®ä¿äº†ä»æ•°æ®å‡†å¤‡åˆ°æ¨¡å‹è®­ç»ƒçš„é«˜æ•ˆæ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†å¼ºåŒ–å­¦ä¹ ä¸æ‰©æ•£æ¨¡å‹ç»“åˆï¼Œåˆ©ç”¨å·²æœ‰æ•°æ®é›†è¿›è¡Œä¼˜åŒ–ï¼Œè€Œéä¾èµ–äºä¼ ç»Ÿçš„æ‰‹åŠ¨æ•°æ®æ”¶é›†ã€‚è¿™ä¸€æ–¹æ³•æ˜¾è‘—æé«˜äº†è®­ç»ƒæ•ˆç‡å’Œæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–æŠ“å–æˆåŠŸç‡ï¼Œå¹¶è®¾è®¡äº†é€‚åˆäº”æŒ‡æœºå™¨äººæ‰‹çš„è½»é‡çº§ç½‘ç»œç»“æ„ï¼Œä»¥ç¡®ä¿åœ¨çµå·§æ“ä½œä¸­çš„é«˜æ•ˆæ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæœ¬æ–‡æå‡ºçš„DiffusionRLæ–¹æ³•åœ¨ä¸‰ä¸ªDexGraspNetå¯¹è±¡ä¸Šå®ç°äº†80%çš„æˆåŠŸç‡ï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•æœ‰æ˜¾è‘—æå‡ã€‚è¿™ä¸€æˆæœè¡¨æ˜ï¼ŒåŸºäºå¼ºåŒ–å­¦ä¹ çš„æ‰©æ•£ç­–ç•¥è®­ç»ƒèƒ½å¤Ÿæœ‰æ•ˆæé«˜æœºå™¨äººæŠ“å–ä»»åŠ¡çš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½æœºå™¨äººã€è‡ªåŠ¨åŒ–ç”Ÿäº§çº¿å’Œäººæœºåä½œç­‰åœºæ™¯ã€‚é€šè¿‡æé«˜æœºå™¨äººæŠ“å–ä»»åŠ¡çš„æˆåŠŸç‡å’Œé€‚åº”æ€§ï¼Œè¯¥æ–¹æ³•æœ‰åŠ©äºæ¨åŠ¨æœºå™¨äººæŠ€æœ¯åœ¨å®é™…åº”ç”¨ä¸­çš„å¹¿æ³›é‡‡ç”¨ï¼Œæå‡ç”Ÿäº§æ•ˆç‡å’Œçµæ´»æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Diffusion models have been successfully applied in areas such as image, video, and audio generation. Recent works show their promise for sequential decision-making and dexterous manipulation, leveraging their ability to model complex action distributions. However, challenges persist due to the data limitations and scenario-specific adaptation needs. In this paper, we address these challenges by proposing an optimized approach to training diffusion policies using large, pre-built datasets that are enhanced using Reinforcement Learning (RL). Our end-to-end pipeline leverages RL-based enhancement of the DexGraspNet dataset, lightweight diffusion policy training on a dexterous manipulation task for a five-fingered robotic hand, and a pose sampling algorithm for validation. The pipeline achieved a high success rate of 80% for three DexGraspNet objects. By eliminating manual data collection, our approach lowers barriers to adopting diffusion models in robotics, enhancing generalization and robustness for real-world applications.

