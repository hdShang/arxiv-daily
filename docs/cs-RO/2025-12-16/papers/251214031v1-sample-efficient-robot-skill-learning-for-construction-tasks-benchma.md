---
layout: default
title: Sample-Efficient Robot Skill Learning for Construction Tasks: Benchmarking Hierarchical Reinforcement Learning and Vision-Language-Action VLA Model
---

# Sample-Efficient Robot Skill Learning for Construction Tasks: Benchmarking Hierarchical Reinforcement Learning and Vision-Language-Action VLA Model

**arXiv**: [2512.14031v1](https://arxiv.org/abs/2512.14031) | [PDF](https://arxiv.org/pdf/2512.14031.pdf)

**ä½œè€…**: Zhaofeng Hu, Hongrui Yu, Vaidhyanathan Chandramouli, Ci-Jyun Liang

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°åˆ†å±‚å¼ºåŒ–å­¦ä¹ ä¸Žè§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹åœ¨å»ºç­‘æœºå™¨äººæŠ€èƒ½å­¦ä¹ ä¸­çš„æ ·æœ¬æ•ˆçŽ‡ä¸Žå®žç”¨æ€§**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `æœºå™¨äººæŠ€èƒ½å­¦ä¹ ` `è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹` `å¼ºåŒ–å­¦ä¹ ` `æ ·æœ¬æ•ˆçŽ‡` `å»ºç­‘è‡ªåŠ¨åŒ–` `å¤šæ¨¡æ€å­¦ä¹ ` `é¥æ“ä½œæŽ¥å£` `æ³›åŒ–èƒ½åŠ›`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå»ºç­‘è‡ªåŠ¨åŒ–ä¸­æœºå™¨äººæŠ€èƒ½å­¦ä¹ é¢ä¸´æ ·æœ¬æ•ˆçŽ‡ä½Žã€æ³›åŒ–èƒ½åŠ›å·®å’Œå®žé™…éƒ¨ç½²å·¥ä½œé‡å¤§çš„æŒ‘æˆ˜ï¼ŒçŽ°æœ‰æ–¹æ³•å¦‚ä¼ ç»ŸRLéœ€è¦å¤§é‡æ•°æ®ä¸”è°ƒä¼˜å¤æ‚ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç³»ç»Ÿæ¯”è¾ƒVLAæ¨¡åž‹ä¸ŽRLæ–¹æ³•ï¼Œé€šè¿‡å¼€å‘é¥æ“ä½œæŽ¥å£æ”¶é›†æ¼”ç¤ºï¼Œå¹¶è¿›è¡Œä¸‰é˜¶æ®µè¯„ä¼°ä»¥é‡åŒ–æ€§èƒ½ã€æ³›åŒ–èƒ½åŠ›å’Œå®žé™…å·¥ä½œé‡ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šVLAåœ¨æ‹¾å–ä»»åŠ¡ä¸­è¾¾åˆ°60%å’Œ100%æˆåŠŸçŽ‡ï¼Œå±•çŽ°å¼ºæ³›åŒ–ï¼›DQNéœ€é¢å¤–è°ƒä¼˜å™ªå£°ï¼ŒVLAåœ¨æ ·æœ¬æ•ˆçŽ‡å’Œå®žç”¨æ€§ä¸Šæ›´å…·ä¼˜åŠ¿ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶è¯„ä¼°äº†ä¸¤ç§ç”¨äºŽæ•™æŽˆå»ºç­‘æœºå™¨äººæ–°æŠ€èƒ½çš„ä¸»æµæ–¹æ³•â€”â€”è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡åž‹å’Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ–¹æ³•ï¼Œä»¥ç†è§£å®ƒä»¬åœ¨å»ºç­‘è‡ªåŠ¨åŒ–ä¸­çš„é€‚ç”¨æ€§ã€‚ç›®æ ‡æ˜¯äº†è§£ä»»åŠ¡æ€§èƒ½ä»¥åŠåœ¨çœŸå®žå·¥ä½œä¸­éƒ¨ç½²æ¯ç§æ–¹æ³•æ‰€éœ€çš„å®žé™…å·¥ä½œé‡ã€‚ä½œè€…å¼€å‘äº†ä¸¤ç§é¥æ“ä½œæŽ¥å£æ¥æŽ§åˆ¶æœºå™¨äººå¹¶æ”¶é›†æ‰€éœ€çš„æ¼”ç¤ºï¼Œè¿™ä¸¤ç§æŽ¥å£å‡è¢«è¯æ˜Žå¯¹è®­ç»ƒæœºå™¨äººæ‰§è¡Œé•¿æœŸå’Œçµå·§ä»»åŠ¡æœ‰æ•ˆã€‚æ­¤å¤–ï¼Œä½œè€…è¿›è¡Œäº†ä¸‰é˜¶æ®µè¯„ä¼°ã€‚é¦–å…ˆï¼Œä½œè€…æ¯”è¾ƒäº†å¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰ç­–ç•¥å’Œæ·±åº¦Qç½‘ç»œï¼ˆDQNï¼‰æ¨¡ä»¿æ¨¡åž‹ï¼Œä»¥ç¡®å®šæ›´å¼ºçš„RLåŸºçº¿ï¼Œé‡ç‚¹å…³æ³¨æ¨¡åž‹æ€§èƒ½ã€æ³›åŒ–èƒ½åŠ›å’Œæ‹¾å–å®žéªŒã€‚å…¶æ¬¡ï¼Œåœ¨ä¸¤ç§ä¸åŒåœºæ™¯ä¸‹è®­ç»ƒäº†ä¸‰ç§ä¸åŒçš„VLAæ¨¡åž‹ï¼Œå¹¶è¿›è¡Œäº†ç›¸äº’æ¯”è¾ƒã€‚ç¬¬ä¸‰ï¼Œä½œè€…ä½¿ç”¨è®¡ç®—å’Œæ ·æœ¬æ•ˆçŽ‡æŒ‡æ ‡ï¼Œä»¥åŠåœ¨ä¸€ä¸ªåŒ…æ‹¬è¿è¾“å’Œå®‰è£…çš„å¤šé˜¶æ®µé¢æ¿å®‰è£…ä»»åŠ¡ä¸Šçš„æœºå™¨äººå®žéªŒï¼Œå¯¹é€‰å®šçš„RLåŸºçº¿ä¸ŽVLAæ¨¡åž‹è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ã€‚VLAæ¨¡åž‹è¡¨çŽ°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›å’Œå°‘æ ·æœ¬èƒ½åŠ›ï¼Œåœ¨æ‹¾å–é˜¶æ®µå®žçŽ°äº†60%å’Œ100%çš„æˆåŠŸçŽ‡ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒDQNè™½ç„¶å¯ä»¥å˜å¾—é²æ£’ï¼Œä½†éœ€è¦åœ¨è°ƒä¼˜è¿‡ç¨‹ä¸­æ·»åŠ é¢å¤–å™ªå£°ï¼Œè¿™å¢žåŠ äº†å·¥ä½œé‡ã€‚æ€»ä½“è€Œè¨€ï¼Œç ”ç©¶ç»“æžœè¡¨æ˜Žï¼ŒVLAé€šè¿‡å‡å°‘ç¼–ç¨‹å·¥ä½œé‡å¹¶ä»¥æœ€å°‘çš„æ•°æ®å®žçŽ°æœ‰ç”¨çš„æ€§èƒ½ï¼Œä¸ºä»»åŠ¡å˜æ›´æä¾›äº†å®žé™…ä¼˜åŠ¿ï¼Œè€ŒDQNåœ¨å¯æŽ¥å—è¶³å¤Ÿè°ƒä¼˜å·¥ä½œé‡çš„æƒ…å†µä¸‹æä¾›äº†ä¸€ä¸ªå¯è¡Œçš„åŸºçº¿ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å»ºç­‘æœºå™¨äººæŠ€èƒ½å­¦ä¹ ä¸­çš„æ ·æœ¬æ•ˆçŽ‡ä½Žã€æ³›åŒ–èƒ½åŠ›å·®å’Œå®žé™…éƒ¨ç½²å·¥ä½œé‡å¤§çš„é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•å¦‚ä¼ ç»Ÿå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰éœ€è¦å¤§é‡äº¤äº’æ•°æ®ï¼Œä¸”è°ƒä¼˜è¿‡ç¨‹å¤æ‚ï¼Œéš¾ä»¥é€‚åº”å¤šå˜ä»»åŠ¡ï¼›è€Œè§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡åž‹è™½å…·æ½œåŠ›ï¼Œä½†å…¶åœ¨å»ºç­‘åœºæ™¯ä¸­çš„é€‚ç”¨æ€§å’Œä¸ŽRLçš„å¯¹æ¯”å°šä¸æ˜Žç¡®ã€‚ç—›ç‚¹åœ¨äºŽç¼ºä¹ç³»ç»Ÿè¯„ä¼°ï¼Œä»¥æŒ‡å¯¼å®žé™…åº”ç”¨ä¸­é€‰æ‹©åˆé€‚æ–¹æ³•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼€å‘ä¸¤ç§é¥æ“ä½œæŽ¥å£æ”¶é›†æœºå™¨äººæ¼”ç¤ºæ•°æ®ï¼Œå¹¶è®¾è®¡ä¸‰é˜¶æ®µè¯„ä¼°æ¡†æž¶ï¼Œç³»ç»Ÿæ¯”è¾ƒVLAæ¨¡åž‹å’ŒRLæ–¹æ³•åœ¨æ€§èƒ½ã€æ³›åŒ–èƒ½åŠ›å’Œå®žé™…å·¥ä½œé‡æ–¹é¢çš„å·®å¼‚ã€‚è¿™æ ·è®¾è®¡æ—¨åœ¨æä¾›å®žè¯ä¾æ®ï¼Œå¸®åŠ©ç†è§£ä¸åŒæ–¹æ³•åœ¨å»ºç­‘è‡ªåŠ¨åŒ–ä¸­çš„ä¼˜ç¼ºç‚¹ï¼Œä»Žè€Œä¼˜åŒ–æŠ€èƒ½å­¦ä¹ ç­–ç•¥ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æž¶æž„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ¨¡åž‹è®­ç»ƒå’Œè¯„ä¼°ä¸‰éƒ¨åˆ†ã€‚é¦–å…ˆï¼Œä½¿ç”¨é¥æ“ä½œæŽ¥å£æŽ§åˆ¶æœºå™¨äººæ‰§è¡Œä»»åŠ¡å¹¶æ”¶é›†æ¼”ç¤ºæ•°æ®ã€‚å…¶æ¬¡ï¼Œè®­ç»ƒé˜¶æ®µï¼šå¯¹äºŽRLï¼Œæ¯”è¾ƒMLPç­–ç•¥å’ŒDQNæ¨¡ä»¿æ¨¡åž‹ï¼›å¯¹äºŽVLAï¼Œè®­ç»ƒä¸‰ç§ä¸åŒæ¨¡åž‹åœ¨ä¸¤ç§åœºæ™¯ä¸‹ã€‚æœ€åŽï¼Œè¯„ä¼°é˜¶æ®µåˆ†ä¸ºä¸‰æ­¥ï¼šæ¯”è¾ƒRLåŸºçº¿ä»¥ç¡®å®šæœ€ä¼˜æ¨¡åž‹ï¼›æ¯”è¾ƒVLAæ¨¡åž‹å†…éƒ¨æ€§èƒ½ï¼›åŸºå‡†æµ‹è¯•é€‰å®šçš„RLåŸºçº¿ä¸ŽVLAæ¨¡åž‹ï¼Œä½¿ç”¨è®¡ç®—æ•ˆçŽ‡ã€æ ·æœ¬æ•ˆçŽ‡å’Œæœºå™¨äººå®žéªŒï¼ˆå¦‚å¤šé˜¶æ®µé¢æ¿å®‰è£…ä»»åŠ¡ï¼‰ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºŽç³»ç»Ÿæ€§åœ°æ•´åˆé¥æ“ä½œæ•°æ®æ”¶é›†ä¸Žå¤šé˜¶æ®µè¯„ä¼°æ¡†æž¶ï¼Œé¦–æ¬¡åœ¨å»ºç­‘æœºå™¨äººé¢†åŸŸå¯¹VLAå’ŒRLè¿›è¡Œå¤´å¯¹å¤´æ¯”è¾ƒã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæœ¬è´¨åŒºåˆ«åœ¨äºŽå¼ºè°ƒå®žé™…éƒ¨ç½²å·¥ä½œé‡ï¼ˆå¦‚è°ƒä¼˜å¤æ‚åº¦ï¼‰çš„é‡åŒ–ï¼Œè€Œä¸ä»…ä»…æ˜¯ä»»åŠ¡æ€§èƒ½ï¼Œè¿™ä¸ºå®žé™…åº”ç”¨æä¾›äº†æ›´å…¨é¢çš„æŒ‡å¯¼ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼šé¥æ“ä½œæŽ¥å£è®¾è®¡ï¼Œç¡®ä¿æœ‰æ•ˆæ”¶é›†é•¿æœŸå’Œçµå·§ä»»åŠ¡çš„æ¼”ç¤ºï¼›åœ¨RLæ¯”è¾ƒä¸­ï¼Œä½¿ç”¨MLPå’ŒDQNä½œä¸ºåŸºçº¿ï¼Œé‡ç‚¹å…³æ³¨æ³›åŒ–èƒ½åŠ›å’Œæ‹¾å–å®žéªŒï¼›VLAæ¨¡åž‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨ä¸¤ç§ä¸åŒåœºæ™¯ä»¥æµ‹è¯•é€‚åº”æ€§ï¼›è¯„ä¼°æŒ‡æ ‡åŒ…æ‹¬æˆåŠŸçŽ‡ã€è®¡ç®—æ—¶é—´ã€æ ·æœ¬éœ€æ±‚ï¼Œä»¥åŠåœ¨å®žé™…æœºå™¨äººä»»åŠ¡ï¼ˆå¦‚é¢æ¿å®‰è£…ï¼‰ä¸­çš„è¡¨çŽ°ã€‚å…·ä½“å‚æ•°å’ŒæŸå¤±å‡½æ•°ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœªè¯¦ç»†è¯´æ˜Žï¼Œä½†å¼ºè°ƒDQNè°ƒä¼˜æ—¶éœ€æ·»åŠ å™ªå£°ä»¥æé«˜é²æ£’æ€§ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

æœ€é‡è¦çš„å®žéªŒç»“æžœåŒ…æ‹¬ï¼šVLAæ¨¡åž‹åœ¨æ‹¾å–é˜¶æ®µå®žçŽ°60%å’Œ100%æˆåŠŸçŽ‡ï¼Œå±•çŽ°å¼ºæ³›åŒ–å’Œå°‘æ ·æœ¬èƒ½åŠ›ï¼›DQNè™½å¯é²æ£’ï¼Œä½†éœ€é¢å¤–å™ªå£°è°ƒä¼˜ï¼Œå¢žåŠ å·¥ä½œé‡ã€‚åœ¨æ ·æœ¬æ•ˆçŽ‡æ¯”è¾ƒä¸­ï¼ŒVLAä»¥æ›´å°‘æ•°æ®è¾¾åˆ°æœ‰ç”¨æ€§èƒ½ï¼Œè€ŒDQNä½œä¸ºåŸºçº¿åœ¨å¯æŽ¥å—è°ƒä¼˜ä¸‹å¯è¡Œã€‚å¤šé˜¶æ®µé¢æ¿å®‰è£…ä»»åŠ¡ä¸­ï¼ŒVLAåœ¨è¿è¾“å’Œå®‰è£…çŽ¯èŠ‚è¡¨çŽ°ä¼˜å¼‚ï¼Œçªæ˜¾å…¶å®žé™…ä¼˜åŠ¿ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨å»ºç­‘è‡ªåŠ¨åŒ–é¢†åŸŸå…·æœ‰é‡è¦åº”ç”¨ä»·å€¼ï¼Œå¯ç”¨äºŽæœºå™¨äººæŠ€èƒ½å­¦ä¹ ï¼Œå¦‚é¢æ¿å®‰è£…ã€ææ–™è¿è¾“ç­‰å¤æ‚ä»»åŠ¡ã€‚æ½œåœ¨åº”ç”¨åŒ…æ‹¬æ™ºèƒ½æ–½å·¥ã€å·¥ä¸šæœºå™¨äººæ“ä½œå’Œå®¶åº­æœåŠ¡æœºå™¨äººï¼Œé€šè¿‡å‡å°‘ç¼–ç¨‹å·¥ä½œé‡å’Œæ•°æ®éœ€æ±‚ï¼Œæé«˜éƒ¨ç½²æ•ˆçŽ‡å’Œé€‚åº”æ€§ã€‚æœªæ¥å¯èƒ½æŽ¨åŠ¨å¤šæ¨¡æ€å­¦ä¹ åœ¨æœºå™¨äººé¢†åŸŸçš„æ™®åŠï¼Œä¿ƒè¿›å®žé™…åœºæ™¯ä¸­çš„å¿«é€ŸæŠ€èƒ½è¿ç§»ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> This study evaluates two leading approaches for teaching construction robots new skills to understand their applicability for construction automation: a Vision-Language-Action (VLA) model and Reinforcement Learning (RL) methods. The goal is to understand both task performance and the practical effort needed to deploy each approach on real jobs. The authors developed two teleoperation interfaces to control the robots and collect the demonstrations needed, both of which proved effective for training robots for long-horizon and dexterous tasks. In addition, the authors conduct a three-stage evaluation. First, the authors compare a Multi-Layer Perceptron (MLP) policy with a Deep Q-network (DQN) imitation model to identify the stronger RL baseline, focusing on model performance, generalization, and a pick-up experiment. Second, three different VLA models are trained in two different scenarios and compared with each other. Third, the authors benchmark the selected RL baseline against the VLA model using computational and sample-efficiency measures and then a robot experiment on a multi-stage panel installation task that includes transport and installation. The VLA model demonstrates strong generalization and few-shot capability, achieving 60% and 100% success in the pickup phase. In comparison, DQN can be made robust but needs additional noise during tuning, which increases the workload. Overall, the findings indicate that VLA offers practical advantages for changing tasks by reducing programming effort and enabling useful performance with minimal data, while DQN provides a viable baseline when sufficient tuning effort is acceptable.

