---
layout: default
title: Sample-Efficient Robot Skill Learning for Construction Tasks: Benchmarking Hierarchical Reinforcement Learning and Vision-Language-Action VLA Model
---

# Sample-Efficient Robot Skill Learning for Construction Tasks: Benchmarking Hierarchical Reinforcement Learning and Vision-Language-Action VLA Model

**arXiv**: [2512.14031v1](https://arxiv.org/abs/2512.14031) | [PDF](https://arxiv.org/pdf/2512.14031.pdf)

**ä½œè€…**: Zhaofeng Hu, Hongrui Yu, Vaidhyanathan Chandramouli, Ci-Jyun Liang

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**å¯¹æ¯”VLAæ¨¡åž‹ä¸Žå¼ºåŒ–å­¦ä¹ ï¼Œæå‡å»ºç­‘æœºå™¨äººæ“ä½œæŠ€èƒ½å¹¶å®žçŽ°é«˜æ•ˆæ ·æœ¬åˆ©ç”¨**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å…·èº«æ™ºèƒ½ (Embodied AI)**

**å…³é”®è¯**: `å»ºç­‘æœºå™¨äºº` `æŠ€èƒ½å­¦ä¹ ` `è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹` `å¼ºåŒ–å­¦ä¹ ` `æ ·æœ¬æ•ˆçŽ‡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰å»ºç­‘æœºå™¨äººæŠ€èƒ½å­¦ä¹ æ–¹æ³•åœ¨æ³›åŒ–æ€§å’Œæ ·æœ¬æ•ˆçŽ‡æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ï¼Œéš¾ä»¥é€‚åº”å¿«é€Ÿå˜åŒ–çš„æ–½å·¥ä»»åŠ¡ã€‚
2. è®ºæ–‡å¯¹æ¯”ç ”ç©¶VLAæ¨¡åž‹å’Œå¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œæ—¨åœ¨æ‰¾åˆ°ä¸€ç§æ›´é«˜æ•ˆã€æ³›åŒ–æ€§æ›´å¼ºçš„æœºå™¨äººæŠ€èƒ½å­¦ä¹ æ–¹æ¡ˆã€‚
3. å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒVLAæ¨¡åž‹åœ¨æ³›åŒ–æ€§å’Œå°‘æ ·æœ¬å­¦ä¹ æ–¹é¢è¡¨çŽ°å‡ºè‰²ï¼Œè€ŒDQNåœ¨ç»è¿‡å……åˆ†è°ƒæ•´åŽä¹Ÿèƒ½è¾¾åˆ°è¾ƒå¥½çš„æ•ˆæžœã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶è¯„ä¼°äº†ä¸¤ç§é¢†å…ˆçš„æ–¹æ³•ï¼Œå³è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡åž‹å’Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ–¹æ³•ï¼Œç”¨äºŽè®­ç»ƒå»ºç­‘æœºå™¨äººæŽŒæ¡æ–°æŠ€èƒ½ï¼Œæ—¨åœ¨äº†è§£å®ƒä»¬åœ¨å»ºç­‘è‡ªåŠ¨åŒ–ä¸­çš„é€‚ç”¨æ€§ã€‚ä½œè€…å¼€å‘äº†ä¸¤ç§é¥æ“ä½œç•Œé¢æ¥æŽ§åˆ¶æœºå™¨äººå¹¶æ”¶é›†æ‰€éœ€çš„æ¼”ç¤ºæ•°æ®ï¼Œè¿™ä¸¤ç§ç•Œé¢éƒ½è¢«è¯æ˜Žå¯¹è®­ç»ƒæœºå™¨äººæ‰§è¡Œé•¿æ—¶ç¨‹å’Œçµå·§ä»»åŠ¡æœ‰æ•ˆã€‚æ­¤å¤–ï¼Œä½œè€…è¿›è¡Œäº†ä¸‰ä¸ªé˜¶æ®µçš„è¯„ä¼°ã€‚é¦–å…ˆï¼Œå°†å¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰ç­–ç•¥ä¸Žæ·±åº¦Qç½‘ç»œï¼ˆDQNï¼‰æ¨¡ä»¿æ¨¡åž‹è¿›è¡Œæ¯”è¾ƒï¼Œä»¥ç¡®å®šæ›´å¼ºçš„RLåŸºçº¿ï¼Œé‡ç‚¹å…³æ³¨æ¨¡åž‹æ€§èƒ½ã€æ³›åŒ–èƒ½åŠ›å’Œæ‹¾å–å®žéªŒã€‚å…¶æ¬¡ï¼Œåœ¨ä¸¤ç§ä¸åŒçš„åœºæ™¯ä¸­è®­ç»ƒäº†ä¸‰ç§ä¸åŒçš„VLAæ¨¡åž‹ï¼Œå¹¶å°†å®ƒä»¬ç›¸äº’æ¯”è¾ƒã€‚ç¬¬ä¸‰ï¼Œä½œè€…ä½¿ç”¨è®¡ç®—å’Œæ ·æœ¬æ•ˆçŽ‡æŒ‡æ ‡ï¼Œä»¥åŠä¸€ä¸ªåŒ…å«è¿è¾“å’Œå®‰è£…çš„å¤šé˜¶æ®µé¢æ¿å®‰è£…æœºå™¨äººå®žéªŒï¼Œæ¥è¯„ä¼°é€‰å®šçš„RLåŸºçº¿ä¸ŽVLAæ¨¡åž‹ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å»ºç­‘æœºå™¨äººæŠ€èƒ½å­¦ä¹ ä¸­æ ·æœ¬æ•ˆçŽ‡ä½Žå’Œæ³›åŒ–èƒ½åŠ›å·®çš„é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•ï¼Œå¦‚ä¼ ç»Ÿçš„å¼ºåŒ–å­¦ä¹ ï¼Œé€šå¸¸éœ€è¦å¤§é‡çš„è®­ç»ƒæ•°æ®å’Œç²¾ç»†çš„è°ƒå‚æ‰èƒ½åœ¨å¤æ‚çŽ¯å¢ƒä¸­å–å¾—è‰¯å¥½çš„æ•ˆæžœï¼Œè¿™åœ¨å®žé™…çš„å»ºç­‘åœºæ™¯ä¸­æ˜¯éš¾ä»¥å®žçŽ°çš„ã€‚æ­¤å¤–ï¼Œä»»åŠ¡çš„å¿«é€Ÿå˜åŒ–ä¹Ÿå¯¹æœºå™¨äººçš„é€‚åº”æ€§æå‡ºäº†æ›´é«˜çš„è¦æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æŽ¢ç´¢åˆ©ç”¨è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡åž‹å’Œå¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œå¹¶å¯¹æ¯”åˆ†æžå®ƒä»¬åœ¨å»ºç­‘æœºå™¨äººæŠ€èƒ½å­¦ä¹ ä¸­çš„æ€§èƒ½ã€‚VLAæ¨¡åž‹é€šè¿‡ç»“åˆè§†è§‰ä¿¡æ¯å’Œè‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿç†è§£ä»»åŠ¡ç›®æ ‡å¹¶æ‰§è¡Œç›¸åº”çš„åŠ¨ä½œï¼Œä»Žè€Œæé«˜æ³›åŒ–èƒ½åŠ›å’Œå°‘æ ·æœ¬å­¦ä¹ èƒ½åŠ›ã€‚å¼ºåŒ–å­¦ä¹ åˆ™é€šè¿‡ä¸ŽçŽ¯å¢ƒçš„äº¤äº’å­¦ä¹ æœ€ä¼˜ç­–ç•¥ï¼Œä½†éœ€è¦æ›´å¤šçš„æ ·æœ¬å’Œè°ƒå‚ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šè®ºæ–‡çš„æ•´ä½“æ¡†æž¶åŒ…æ‹¬æ•°æ®é‡‡é›†ã€æ¨¡åž‹è®­ç»ƒå’Œå®žéªŒè¯„ä¼°ä¸‰ä¸ªé˜¶æ®µã€‚é¦–å…ˆï¼Œé€šè¿‡é¥æ“ä½œç•Œé¢æ”¶é›†æœºå™¨äººçš„æ¼”ç¤ºæ•°æ®ã€‚ç„¶åŽï¼Œåˆ†åˆ«è®­ç»ƒVLAæ¨¡åž‹å’Œå¼ºåŒ–å­¦ä¹ æ¨¡åž‹ã€‚æœ€åŽï¼Œé€šè¿‡ä¸€ç³»åˆ—çš„å®žéªŒï¼ŒåŒ…æ‹¬æ‹¾å–å®žéªŒå’Œå¤šé˜¶æ®µé¢æ¿å®‰è£…å®žéªŒï¼Œå¯¹ä¸¤ç§æ¨¡åž‹çš„æ€§èƒ½è¿›è¡Œè¯„ä¼°å’Œæ¯”è¾ƒã€‚VLAæ¨¡åž‹ä½¿ç”¨äº†ä¸åŒçš„æž¶æž„ï¼ŒåŒ…æ‹¬Transformerç­‰ï¼Œè€Œå¼ºåŒ–å­¦ä¹ åˆ™ä½¿ç”¨äº†DQNä½œä¸ºåŸºçº¿ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽå¯¹æ¯”ç ”ç©¶äº†VLAæ¨¡åž‹å’Œå¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨å»ºç­‘æœºå™¨äººæŠ€èƒ½å­¦ä¹ ä¸­çš„æ€§èƒ½ï¼Œå¹¶æ­ç¤ºäº†å®ƒä»¬å„è‡ªçš„ä¼˜ç¼ºç‚¹ã€‚VLAæ¨¡åž‹åœ¨æ³›åŒ–æ€§å’Œå°‘æ ·æœ¬å­¦ä¹ æ–¹é¢è¡¨çŽ°å‡ºè‰²ï¼Œè€Œå¼ºåŒ–å­¦ä¹ åœ¨ç»è¿‡å……åˆ†è°ƒæ•´åŽä¹Ÿèƒ½è¾¾åˆ°è¾ƒå¥½çš„æ•ˆæžœã€‚è¿™ä¸ºå»ºç­‘æœºå™¨äººæŠ€èƒ½å­¦ä¹ æä¾›äº†æ–°çš„æ€è·¯å’Œæ–¹æ³•ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨VLAæ¨¡åž‹ä¸­ï¼Œä½¿ç”¨äº†Transformeræž¶æž„æ¥å¤„ç†è§†è§‰ä¿¡æ¯å’Œè‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼Œå¹¶ç”Ÿæˆç›¸åº”çš„åŠ¨ä½œã€‚åœ¨å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œä½¿ç”¨äº†DQNä½œä¸ºåŸºçº¿ï¼Œå¹¶æŽ¢ç´¢äº†ä¸åŒçš„å™ªå£°æ·»åŠ æ–¹æ³•æ¥æé«˜æ¨¡åž‹çš„é²æ£’æ€§ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜è®¾è®¡äº†ä¸¤ç§é¥æ“ä½œç•Œé¢æ¥æ”¶é›†æœºå™¨äººçš„æ¼”ç¤ºæ•°æ®ï¼Œå¹¶è®¾è®¡äº†å¤šé˜¶æ®µé¢æ¿å®‰è£…å®žéªŒæ¥è¯„ä¼°æ¨¡åž‹çš„æ€§èƒ½ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

VLAæ¨¡åž‹åœ¨æ‹¾å–é˜¶æ®µè¡¨çŽ°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›å’Œå°‘æ ·æœ¬å­¦ä¹ èƒ½åŠ›ï¼ŒæˆåŠŸçŽ‡åˆ†åˆ«è¾¾åˆ°60%å’Œ100%ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒDQNéœ€è¦é¢å¤–çš„å™ªå£°è°ƒæ•´æ‰èƒ½å˜å¾—é²æ£’ï¼Œè¿™å¢žåŠ äº†å·¥ä½œé‡ã€‚åœ¨å¤šé˜¶æ®µé¢æ¿å®‰è£…ä»»åŠ¡ä¸­ï¼ŒVLAæ¨¡åž‹ä¹Ÿè¡¨çŽ°å‡ºè‰¯å¥½çš„æ€§èƒ½ï¼Œè¯æ˜Žäº†å…¶åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„æ½œåŠ›ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽå»ºç­‘è‡ªåŠ¨åŒ–é¢†åŸŸï¼Œä¾‹å¦‚å»ºç­‘æž„ä»¶çš„æ¬è¿ã€å®‰è£…å’Œè£…é…ç­‰ä»»åŠ¡ã€‚é€šè¿‡åˆ©ç”¨VLAæ¨¡åž‹æˆ–å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œå¯ä»¥æé«˜å»ºç­‘æœºå™¨äººçš„æ™ºèƒ½åŒ–æ°´å¹³å’Œå·¥ä½œæ•ˆçŽ‡ï¼Œé™ä½Žäººå·¥æˆæœ¬ï¼Œå¹¶æé«˜æ–½å·¥è´¨é‡å’Œå®‰å…¨æ€§ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å¯ä»¥æŽ¨å¹¿åˆ°å…¶ä»–éœ€è¦æœºå™¨äººæ‰§è¡Œå¤æ‚ä»»åŠ¡çš„é¢†åŸŸï¼Œå¦‚åˆ¶é€ ä¸šã€ç‰©æµç­‰ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> This study evaluates two leading approaches for teaching construction robots new skills to understand their applicability for construction automation: a Vision-Language-Action (VLA) model and Reinforcement Learning (RL) methods. The goal is to understand both task performance and the practical effort needed to deploy each approach on real jobs. The authors developed two teleoperation interfaces to control the robots and collect the demonstrations needed, both of which proved effective for training robots for long-horizon and dexterous tasks. In addition, the authors conduct a three-stage evaluation. First, the authors compare a Multi-Layer Perceptron (MLP) policy with a Deep Q-network (DQN) imitation model to identify the stronger RL baseline, focusing on model performance, generalization, and a pick-up experiment. Second, three different VLA models are trained in two different scenarios and compared with each other. Third, the authors benchmark the selected RL baseline against the VLA model using computational and sample-efficiency measures and then a robot experiment on a multi-stage panel installation task that includes transport and installation. The VLA model demonstrates strong generalization and few-shot capability, achieving 60% and 100% success in the pickup phase. In comparison, DQN can be made robust but needs additional noise during tuning, which increases the workload. Overall, the findings indicate that VLA offers practical advantages for changing tasks by reducing programming effort and enabling useful performance with minimal data, while DQN provides a viable baseline when sufficient tuning effort is acceptable.

