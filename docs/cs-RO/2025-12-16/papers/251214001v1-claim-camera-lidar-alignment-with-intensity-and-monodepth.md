---
layout: default
title: CLAIM: Camera-LiDAR Alignment with Intensity and Monodepth
---

# CLAIM: Camera-LiDAR Alignment with Intensity and Monodepth

**arXiv**: [2512.14001v1](https://arxiv.org/abs/2512.14001) | [PDF](https://arxiv.org/pdf/2512.14001.pdf)

**ä½œè€…**: Zhuo Zhang, Yonghui Liu, Meijie Zhang, Feiyang Tan, Yikang Ding

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: Accepted by IROS 2025

**ðŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Tompson11/claim)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCLAIMæ–¹æ³•ä»¥è§£å†³ç›¸æœºä¸ŽLiDARæ•°æ®å¯¹é½é—®é¢˜**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **è‡ªåŠ¨é©¾é©¶ (Autonomous Driving)**

**å…³é”®è¯**: `ç›¸æœºä¸ŽLiDARå¯¹é½` `å•ç›®æ·±åº¦æ¨¡åž‹` `æ•°æ®å¤„ç†ç®€åŒ–` `ç»“æž„æŸå¤±` `çº¹ç†æŸå¤±` `è‡ªåŠ¨é©¾é©¶` `æœºå™¨äººå¯¼èˆª`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰çš„ç›¸æœºä¸ŽLiDARå¯¹é½æ–¹æ³•é€šå¸¸ä¾èµ–å¤æ‚çš„æ•°æ®å¤„ç†å’Œç‰¹å¾åŒ¹é…ï¼Œå¯¼è‡´æ•ˆçŽ‡ä½Žä¸‹å’Œé€‚åº”æ€§å·®ã€‚
2. CLAIMæ–¹æ³•é€šè¿‡ç²—åˆ°ç»†çš„æœç´¢ç­–ç•¥ï¼Œç»“åˆç»“æž„æŸå¤±å’Œçº¹ç†æŸå¤±ï¼Œç®€åŒ–äº†ç›¸æœºä¸ŽLiDARçš„å¯¹é½è¿‡ç¨‹ã€‚
3. åœ¨KITTIã€Waymoå’ŒMIAS-LCECæ•°æ®é›†ä¸Šçš„å®žéªŒç»“æžœæ˜¾ç¤ºï¼ŒCLAIMåœ¨å¯¹é½ç²¾åº¦ä¸Šæ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡é‡Šæ”¾äº†å¼ºå¤§çš„å•ç›®æ·±åº¦æ¨¡åž‹åœ¨ç›¸æœºä¸ŽLiDARæ ¡å‡†ä¸­çš„æ½œåŠ›ï¼Œæå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•CLAIMï¼Œç”¨äºŽå¯¹é½ç›¸æœºå’ŒLiDARçš„æ•°æ®ã€‚CLAIMåˆ©ç”¨ç²—åˆ°ç»†çš„æœç´¢æ–¹æ³•ï¼ŒåŸºäºŽåˆå§‹çŒœæµ‹å’Œå›¾åƒä¸ŽLiDARç‚¹äº‘å¯¹ï¼Œå¯»æ‰¾æœ€ä¼˜å˜æ¢ï¼Œæœ€å°åŒ–åŸºäºŽåˆ†å—Pearsonç›¸å…³çš„ç»“æž„æŸå¤±å’ŒåŸºäºŽäº’ä¿¡æ¯çš„çº¹ç†æŸå¤±ã€‚è¿™ä¸¤ç§æŸå¤±å‡½æ•°ä½œä¸ºç›¸æœºä¸ŽLiDARå¯¹é½ç»“æžœçš„è‰¯å¥½åº¦é‡ï¼Œæ— éœ€å¤æ‚çš„æ•°æ®å¤„ç†ã€ç‰¹å¾æå–æˆ–ç‰¹å¾åŒ¹é…æ­¥éª¤ï¼Œä½¿å¾—è¯¥æ–¹æ³•ç®€å•ä¸”é€‚åº”å¤§å¤šæ•°åœºæ™¯ã€‚æˆ‘ä»¬åœ¨å…¬å…±çš„KITTIã€Waymoå’ŒMIAS-LCECæ•°æ®é›†ä¸ŠéªŒè¯äº†CLAIMï¼Œå®žéªŒç»“æžœè¡¨æ˜Žå…¶æ€§èƒ½ä¼˜äºŽçŽ°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚ä»£ç å¯åœ¨https://github.com/Tompson11/claimèŽ·å–ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç›¸æœºä¸ŽLiDARæ•°æ®å¯¹é½çš„æŒ‘æˆ˜ï¼ŒçŽ°æœ‰æ–¹æ³•å¾€å¾€éœ€è¦å¤æ‚çš„ç‰¹å¾æå–å’ŒåŒ¹é…æ­¥éª¤ï¼Œå¯¼è‡´æ•ˆçŽ‡ä½Žä¸‹å’Œé€‚åº”æ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šCLAIMæ–¹æ³•åˆ©ç”¨å•ç›®æ·±åº¦æ¨¡åž‹ï¼Œé€šè¿‡ç²—åˆ°ç»†çš„æœç´¢ç­–ç•¥ï¼Œç»“åˆç»“æž„æŸå¤±å’Œçº¹ç†æŸå¤±ï¼Œå¯»æ‰¾æœ€ä¼˜çš„ç›¸æœºä¸ŽLiDARå¯¹é½å˜æ¢ï¼Œç®€åŒ–äº†å¯¹é½è¿‡ç¨‹ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šCLAIMçš„æ•´ä½“æž¶æž„åŒ…æ‹¬åˆå§‹çŒœæµ‹çš„ç”Ÿæˆã€ç²—åˆ°ç»†çš„æœç´¢è¿‡ç¨‹ã€æŸå¤±å‡½æ•°çš„è®¡ç®—ä»¥åŠæœ€ç»ˆçš„å¯¹é½ç»“æžœè¾“å‡ºã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬å›¾åƒä¸Žç‚¹äº‘çš„é…å¯¹ã€æŸå¤±å‡½æ•°çš„ä¼˜åŒ–å’Œå˜æ¢å‚æ•°çš„æ›´æ–°ã€‚

**å…³é”®åˆ›æ–°**ï¼šCLAIMçš„ä¸»è¦åˆ›æ–°åœ¨äºŽå¼•å…¥äº†åŸºäºŽåˆ†å—Pearsonç›¸å…³çš„ç»“æž„æŸå¤±å’ŒåŸºäºŽäº’ä¿¡æ¯çš„çº¹ç†æŸå¤±ï¼Œè¿™äº›æŸå¤±å‡½æ•°æ— éœ€å¤æ‚çš„æ•°æ®å¤„ç†æ­¥éª¤ï¼Œæ˜¾è‘—æé«˜äº†å¯¹é½çš„æ•ˆçŽ‡å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šCLAIMåœ¨æŸå¤±å‡½æ•°è®¾è®¡ä¸Šé‡‡ç”¨äº†åˆ†å—Pearsonç›¸å…³æ€§å’Œäº’ä¿¡æ¯åº¦é‡ï¼Œç¡®ä¿äº†å¯¹é½ç»“æžœçš„é«˜è´¨é‡ã€‚æ­¤å¤–ï¼Œç²—åˆ°ç»†çš„æœç´¢ç­–ç•¥ä½¿å¾—ç®—æ³•åœ¨ä¸åŒåœºæ™¯ä¸‹éƒ½èƒ½å¿«é€Ÿæ”¶æ•›ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

CLAIMåœ¨KITTIã€Waymoå’ŒMIAS-LCECæ•°æ®é›†ä¸Šçš„å®žéªŒç»“æžœè¡¨æ˜Žï¼Œå…¶å¯¹é½ç²¾åº¦æ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æœ€å…ˆè¿›æ–¹æ³•ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°XX%ï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œé€‚ç”¨æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

CLAIMæ–¹æ³•åœ¨è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªå’Œå¢žå¼ºçŽ°å®žç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æé«˜ç›¸æœºä¸ŽLiDARæ•°æ®çš„å¯¹é½ç²¾åº¦ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡çŽ¯å¢ƒæ„ŸçŸ¥çš„å‡†ç¡®æ€§å’Œå¯é æ€§ï¼Œè¿›è€ŒæŽ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ä¸Žåº”ç”¨ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In this paper, we unleash the potential of the powerful monodepth model in camera-LiDAR calibration and propose CLAIM, a novel method of aligning data from the camera and LiDAR. Given the initial guess and pairs of images and LiDAR point clouds, CLAIM utilizes a coarse-to-fine searching method to find the optimal transformation minimizing a patched Pearson correlation-based structure loss and a mutual information-based texture loss. These two losses serve as good metrics for camera-LiDAR alignment results and require no complicated steps of data processing, feature extraction, or feature matching like most methods, rendering our method simple and adaptive to most scenes. We validate CLAIM on public KITTI, Waymo, and MIAS-LCEC datasets, and the experimental results demonstrate its superior performance compared with the state-of-the-art methods. The code is available at https://github.com/Tompson11/claim.

