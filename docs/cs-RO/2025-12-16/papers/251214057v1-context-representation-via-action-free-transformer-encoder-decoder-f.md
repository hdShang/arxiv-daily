---
layout: default
title: Context Representation via Action-Free Transformer encoder-decoder for Meta Reinforcement Learning
---

# Context Representation via Action-Free Transformer encoder-decoder for Meta Reinforcement Learning

**arXiv**: [2512.14057v1](https://arxiv.org/abs/2512.14057) | [PDF](https://arxiv.org/pdf/2512.14057.pdf)

**ä½œè€…**: Amir M. Soufi Enayati, Homayoun Honari, Homayoun Najjaran

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCRAFTæ¨¡åž‹ï¼Œé€šè¿‡æ— åŠ¨ä½œTransformerç¼–ç å™¨-è§£ç å™¨è¿›è¡Œä¸Šä¸‹æ–‡è¡¨ç¤ºï¼Œä»¥è§£å†³å…ƒå¼ºåŒ–å­¦ä¹ ä¸­ä»»åŠ¡æŽ¨æ–­ä¸Žç­–ç•¥ä¼˜åŒ–çš„è€¦åˆé—®é¢˜ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `å…ƒå¼ºåŒ–å­¦ä¹ ` `ä¸Šä¸‹æ–‡è¡¨ç¤º` `Transformerç¼–ç å™¨-è§£ç å™¨` `æ— åŠ¨ä½œæŽ¨æ–­` `ä»»åŠ¡æŽ¨æ–­è§£è€¦` `æ‘Šé”€å˜åˆ†æŽ¨æ–­` `æœºå™¨äººæ“ä½œ` `é•¿ç¨‹æ—¶é—´ä¾èµ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰ä¸Šä¸‹æ–‡è‡ªé€‚åº”å…ƒå¼ºåŒ–å­¦ä¹ æ–¹æ³•ä¾èµ–å®Œæ•´åŠ¨ä½œä¿¡æ¯ï¼Œå¯¼è‡´ä»»åŠ¡æŽ¨æ–­ä¸Žç‰¹å®šç­–ç•¥ç´§å¯†è€¦åˆï¼Œé™åˆ¶äº†æ³›åŒ–èƒ½åŠ›å’Œæ¨¡å—åŒ–è®­ç»ƒã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæå‡ºCRAFTæ¨¡åž‹ï¼Œä»…ä½¿ç”¨çŠ¶æ€å’Œå¥–åŠ±åºåˆ—è¿›è¡Œä»»åŠ¡æŽ¨æ–­ï¼Œé€šè¿‡Transformerç¼–ç å™¨-è§£ç å™¨æ•æ‰é•¿ç¨‹ä¾èµ–ï¼Œå®žçŽ°ä»»åŠ¡è¡¨ç¤ºä¸Žç­–ç•¥ä¼˜åŒ–çš„è§£è€¦ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨MetaWorld ML-10åŸºå‡†ä¸Šï¼ŒCRAFTç›¸æ¯”åŸºçº¿æ–¹æ³•ï¼Œå®žçŽ°äº†æ›´å¿«çš„é€‚åº”é€Ÿåº¦ã€æ›´å¥½çš„æ³›åŒ–æ€§èƒ½å’Œæ›´æœ‰æ•ˆçš„æŽ¢ç´¢ç­–ç•¥ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä½¿æœºå™¨äººèƒ½åœ¨ä¸ç¡®å®šçŽ¯å¢ƒä¸­æ“ä½œï¼Œä½†æ ‡å‡†æ–¹æ³•å¸¸éš¾ä»¥æ³›åŒ–åˆ°æœªè§ä»»åŠ¡ã€‚ä¸Šä¸‹æ–‡è‡ªé€‚åº”å…ƒå¼ºåŒ–å­¦ä¹ é€šè¿‡ä»»åŠ¡è¡¨ç¤ºæ¥åº”å¯¹è¿™äº›é™åˆ¶ï¼Œä½†å®ƒä»¬å¤§å¤šä¾èµ–ç»éªŒä¸­çš„å®Œæ•´åŠ¨ä½œä¿¡æ¯ï¼Œå¯¼è‡´ä»»åŠ¡æŽ¨æ–­ä¸Žç‰¹å®šç­–ç•¥ç´§å¯†è€¦åˆã€‚æœ¬æ–‡ä»‹ç»äº†Context Representation via Action Free Transformer encoder decoderï¼ˆCRAFTï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ä¿¡å¿µæ¨¡åž‹ï¼Œä»…ä»ŽçŠ¶æ€å’Œå¥–åŠ±åºåˆ—æŽ¨æ–­ä»»åŠ¡è¡¨ç¤ºã€‚é€šè¿‡æ¶ˆé™¤å¯¹åŠ¨ä½œçš„ä¾èµ–ï¼ŒCRAFTå°†ä»»åŠ¡æŽ¨æ–­ä¸Žç­–ç•¥ä¼˜åŒ–è§£è€¦ï¼Œæ”¯æŒæ¨¡å—åŒ–è®­ç»ƒï¼Œå¹¶åˆ©ç”¨æ‘Šé”€å˜åˆ†æŽ¨æ–­è¿›è¡Œå¯æ‰©å±•çš„ä¿¡å¿µæ›´æ–°ã€‚è¯¥æ¨¡åž‹åŸºäºŽå¸¦æœ‰æ—‹è½¬ä½ç½®åµŒå…¥çš„Transformerç¼–ç å™¨-è§£ç å™¨æž„å»ºï¼Œèƒ½æ•æ‰é•¿ç¨‹æ—¶é—´ä¾èµ–ï¼Œå¹¶ç¨³å¥ç¼–ç å‚æ•°åŒ–å’Œéžå‚æ•°åŒ–ä»»åŠ¡å˜åŒ–ã€‚åœ¨MetaWorld ML-10æœºå™¨äººæ“ä½œåŸºå‡†ä¸Šçš„å®žéªŒè¡¨æ˜Žï¼Œä¸Žä¸Šä¸‹æ–‡è‡ªé€‚åº”å…ƒRLåŸºçº¿ç›¸æ¯”ï¼ŒCRAFTå®žçŽ°äº†æ›´å¿«çš„é€‚åº”ã€æ›´å¥½çš„æ³›åŒ–å’Œæ›´æœ‰æ•ˆçš„æŽ¢ç´¢ã€‚è¿™äº›å‘çŽ°çªæ˜¾äº†æ— åŠ¨ä½œæŽ¨æ–­ä½œä¸ºæœºå™¨äººæŽ§åˆ¶ä¸­å¯æ‰©å±•RLåŸºç¡€çš„æ½œåŠ›ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å…ƒå¼ºåŒ–å­¦ä¹ ä¸­ä»»åŠ¡æŽ¨æ–­ä¸Žç­–ç•¥ä¼˜åŒ–ç´§å¯†è€¦åˆçš„é—®é¢˜ã€‚çŽ°æœ‰ä¸Šä¸‹æ–‡è‡ªé€‚åº”å…ƒRLæ–¹æ³•é€šå¸¸ä¾èµ–ç»éªŒä¸­çš„å®Œæ•´åŠ¨ä½œä¿¡æ¯ï¼Œè¿™å¯¼è‡´ä»»åŠ¡æŽ¨æ–­è¿‡ç¨‹å—é™äºŽç‰¹å®šç­–ç•¥ï¼Œé™åˆ¶äº†æ¨¡åž‹çš„æ³›åŒ–èƒ½åŠ›å’Œæ¨¡å—åŒ–è®­ç»ƒæ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨é¢å¯¹æœªè§ä»»åŠ¡æ—¶è¡¨çŽ°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯è®¾è®¡ä¸€ä¸ªæ— åŠ¨ä½œçš„ä¿¡å¿µæ¨¡åž‹CRAFTï¼Œä»…ä»ŽçŠ¶æ€å’Œå¥–åŠ±åºåˆ—æŽ¨æ–­ä»»åŠ¡è¡¨ç¤ºï¼Œä»Žè€Œå°†ä»»åŠ¡æŽ¨æ–­ä¸Žç­–ç•¥ä¼˜åŒ–è§£è€¦ã€‚è¿™æ ·è®¾è®¡æ˜¯ä¸ºäº†å‡å°‘å¯¹åŠ¨ä½œä¿¡æ¯çš„ä¾èµ–ï¼Œä½¿ä»»åŠ¡æŽ¨æ–­æ›´é€šç”¨ï¼Œæ”¯æŒç‹¬ç«‹äºŽç­–ç•¥çš„æ¨¡å—åŒ–è®­ç»ƒï¼Œå¹¶åˆ©ç”¨æ‘Šé”€å˜åˆ†æŽ¨æ–­å®žçŽ°é«˜æ•ˆä¿¡å¿µæ›´æ–°ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æž¶æž„åŸºäºŽTransformerç¼–ç å™¨-è§£ç å™¨ã€‚é¦–å…ˆï¼Œè¾“å…¥åºåˆ—åŒ…æ‹¬çŠ¶æ€å’Œå¥–åŠ±ï¼Œé€šè¿‡ç¼–ç å™¨æ•æ‰é•¿ç¨‹æ—¶é—´ä¾èµ–ï¼›ç„¶åŽï¼Œè§£ç å™¨ç”Ÿæˆä»»åŠ¡è¡¨ç¤ºï¼›æœ€åŽï¼Œåˆ©ç”¨å˜åˆ†æŽ¨æ–­è¿›è¡Œä¿¡å¿µæ›´æ–°ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€Transformerç¼–ç å™¨ã€è§£ç å™¨å’Œå˜åˆ†æŽ¨æ–­å±‚ï¼Œæµç¨‹æ¶‰åŠåºåˆ—ç¼–ç ã€ä»»åŠ¡æŽ¨æ–­å’Œä¿¡å¿µä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°æ˜¯å¼•å…¥æ— åŠ¨ä½œæŽ¨æ–­æœºåˆ¶ï¼Œä»…ä½¿ç”¨çŠ¶æ€å’Œå¥–åŠ±åºåˆ—è¿›è¡Œä»»åŠ¡è¡¨ç¤ºï¼Œè¿™æœ¬è´¨åŒºåˆ«äºŽçŽ°æœ‰æ–¹æ³•ä¾èµ–åŠ¨ä½œä¿¡æ¯çš„åšæ³•ã€‚è¿™å®žçŽ°äº†ä»»åŠ¡æŽ¨æ–­ä¸Žç­–ç•¥çš„å®Œå…¨è§£è€¦ï¼Œæå‡äº†æ¨¡åž‹çš„é€šç”¨æ€§å’Œå¯æ‰©å±•æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ä½¿ç”¨æ—‹è½¬ä½ç½®åµŒå…¥ï¼ˆRoPEï¼‰å¢žå¼ºä½ç½®ç¼–ç ï¼Œä»¥æ›´å¥½åœ°å¤„ç†åºåˆ—æ•°æ®ï¼›é‡‡ç”¨æ‘Šé”€å˜åˆ†æŽ¨æ–­è¿›è¡Œä¿¡å¿µæ›´æ–°ï¼Œæé«˜è®¡ç®—æ•ˆçŽ‡ï¼›ç½‘ç»œç»“æž„åŸºäºŽæ ‡å‡†Transformerï¼Œä½†é’ˆå¯¹çŠ¶æ€å’Œå¥–åŠ±è¾“å…¥è¿›è¡Œäº†ä¼˜åŒ–ï¼›æŸå¤±å‡½æ•°ç»“åˆé‡æž„æŸå¤±å’Œå˜åˆ†ä¸‹ç•Œï¼Œä»¥å¹³è¡¡è¡¨ç¤ºè´¨é‡å’ŒæŽ¨æ–­ç¨³å®šæ€§ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨MetaWorld ML-10æœºå™¨äººæ“ä½œåŸºå‡†å®žéªŒä¸­ï¼ŒCRAFTç›¸æ¯”ä¸Šä¸‹æ–‡è‡ªé€‚åº”å…ƒRLåŸºçº¿æ–¹æ³•ï¼Œå®žçŽ°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼šé€‚åº”é€Ÿåº¦æ›´å¿«ï¼Œæ³›åŒ–èƒ½åŠ›æ›´å¼ºï¼ŒæŽ¢ç´¢æ•ˆçŽ‡æ›´é«˜ã€‚å…·ä½“æ•°æ®æœªåœ¨æ‘˜è¦ä¸­æä¾›ï¼Œä½†å®žéªŒç»“æžœè¡¨æ˜ŽCRAFTåœ¨ä»»åŠ¡æŽ¨æ–­è§£è€¦æ–¹é¢ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œçªæ˜¾äº†æ— åŠ¨ä½œæŽ¨æ–­çš„æœ‰æ•ˆæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨æœºå™¨äººæŽ§åˆ¶é¢†åŸŸå…·æœ‰å¹¿æ³›æ½œåœ¨åº”ç”¨ï¼Œå¦‚å·¥ä¸šè‡ªåŠ¨åŒ–ã€æœåŠ¡æœºå™¨äººå’Œè‡ªä¸»å¯¼èˆªã€‚é€šè¿‡å®žçŽ°æ— åŠ¨ä½œçš„ä»»åŠ¡æŽ¨æ–­ï¼ŒCRAFTæ”¯æŒæ›´çµæ´»çš„æ¨¡å—åŒ–è®­ç»ƒï¼Œèƒ½å¿«é€Ÿé€‚åº”æ–°ä»»åŠ¡ï¼Œæå‡æœºå™¨äººåœ¨å¤æ‚çŽ¯å¢ƒä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚æœªæ¥å¯èƒ½æŽ¨åŠ¨å¯æ‰©å±•å¼ºåŒ–å­¦ä¹ æŠ€æœ¯çš„å‘å±•ï¼Œé™ä½Žå¯¹ä¸“å®¶ç­–ç•¥çš„ä¾èµ–ï¼Œä¿ƒè¿›æ™ºèƒ½ç³»ç»Ÿåœ¨çŽ°å®žä¸–ç•Œä¸­çš„éƒ¨ç½²ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Reinforcement learning (RL) enables robots to operate in uncertain environments, but standard approaches often struggle with poor generalization to unseen tasks. Context-adaptive meta reinforcement learning addresses these limitations by conditioning on the task representation, yet they mostly rely on complete action information in the experience making task inference tightly coupled to a specific policy. This paper introduces Context Representation via Action Free Transformer encoder decoder (CRAFT), a belief model that infers task representations solely from sequences of states and rewards. By removing the dependence on actions, CRAFT decouples task inference from policy optimization, supports modular training, and leverages amortized variational inference for scalable belief updates. Built on a transformer encoder decoder with rotary positional embeddings, the model captures long range temporal dependencies and robustly encodes both parametric and non-parametric task variations. Experiments on the MetaWorld ML-10 robotic manipulation benchmark show that CRAFT achieves faster adaptation, improved generalization, and more effective exploration compared to context adaptive meta--RL baselines. These findings highlight the potential of action-free inference as a foundation for scalable RL in robotic control.

