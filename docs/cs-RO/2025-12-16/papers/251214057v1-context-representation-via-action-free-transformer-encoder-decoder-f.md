---
layout: default
title: Context Representation via Action-Free Transformer encoder-decoder for Meta Reinforcement Learning
---

# Context Representation via Action-Free Transformer encoder-decoder for Meta Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.14057" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.14057v1</a>
  <a href="https://arxiv.org/pdf/2512.14057.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14057v1" onclick="toggleFavorite(this, '2512.14057v1', 'Context Representation via Action-Free Transformer encoder-decoder for Meta Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Amir M. Soufi Enayati, Homayoun Honari, Homayoun Najjaran

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCRAFTï¼šä¸€ç§åŸºäºæ— åŠ¨ä½œTransformerçš„å…ƒå¼ºåŒ–å­¦ä¹ ä¸Šä¸‹æ–‡è¡¨ç¤ºæ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å…ƒå¼ºåŒ–å­¦ä¹ ` `ä¸Šä¸‹æ–‡è¡¨ç¤º` `Transformer` `æ— åŠ¨ä½œå­¦ä¹ ` `æœºå™¨äººæ§åˆ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿå…ƒå¼ºåŒ–å­¦ä¹ æ–¹æ³•ä¾èµ–åŠ¨ä½œä¿¡æ¯è¿›è¡Œä»»åŠ¡æ¨æ–­ï¼Œå¯¼è‡´ä»»åŠ¡æ¨æ–­ä¸ç‰¹å®šç­–ç•¥ç»‘å®šï¼Œæ³›åŒ–èƒ½åŠ›å—é™ã€‚
2. CRAFTé€šè¿‡æ— åŠ¨ä½œTransformerç¼–ç å™¨-è§£ç å™¨ï¼Œä»…ä»çŠ¶æ€å’Œå¥–åŠ±åºåˆ—æ¨æ–­ä»»åŠ¡è¡¨ç¤ºï¼Œè§£è€¦ä»»åŠ¡æ¨æ–­ä¸ç­–ç•¥ä¼˜åŒ–ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒCRAFTåœ¨MetaWorld ML-10ä¸Šå®ç°äº†æ›´å¿«çš„é€‚åº”ã€æ›´å¥½çš„æ³›åŒ–å’Œæ›´æœ‰æ•ˆçš„æ¢ç´¢ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¼ºåŒ–å­¦ä¹ (RL)ä½¿æœºå™¨äººèƒ½å¤Ÿåœ¨ä¸ç¡®å®šç¯å¢ƒä¸­è¿è¡Œï¼Œä½†æ ‡å‡†æ–¹æ³•é€šå¸¸éš¾ä»¥æ³›åŒ–åˆ°æœªè§è¿‡çš„ä»»åŠ¡ã€‚ä¸Šä¸‹æ–‡è‡ªé€‚åº”å…ƒå¼ºåŒ–å­¦ä¹ é€šè¿‡è°ƒèŠ‚ä»»åŠ¡è¡¨ç¤ºæ¥è§£å†³è¿™äº›é™åˆ¶ï¼Œä½†å®ƒä»¬ä¸»è¦ä¾èµ–äºç»éªŒä¸­çš„å®Œæ•´åŠ¨ä½œä¿¡æ¯ï¼Œä½¿å¾—ä»»åŠ¡æ¨æ–­ä¸ç‰¹å®šç­–ç•¥ç´§å¯†è€¦åˆã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§é€šè¿‡æ— åŠ¨ä½œTransformerç¼–ç å™¨-è§£ç å™¨(CRAFT)è¿›è¡Œä¸Šä¸‹æ–‡è¡¨ç¤ºçš„æ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§ä»…ä»çŠ¶æ€å’Œå¥–åŠ±åºåˆ—æ¨æ–­ä»»åŠ¡è¡¨ç¤ºçš„ä¿¡å¿µæ¨¡å‹ã€‚é€šè¿‡æ¶ˆé™¤å¯¹åŠ¨ä½œçš„ä¾èµ–ï¼ŒCRAFTå°†ä»»åŠ¡æ¨æ–­ä¸ç­–ç•¥ä¼˜åŒ–è§£è€¦ï¼Œæ”¯æŒæ¨¡å—åŒ–è®­ç»ƒï¼Œå¹¶åˆ©ç”¨æ‘Šé”€å˜åˆ†æ¨æ–­è¿›è¡Œå¯æ‰©å±•çš„ä¿¡å¿µæ›´æ–°ã€‚è¯¥æ¨¡å‹å»ºç«‹åœ¨å…·æœ‰æ—‹è½¬ä½ç½®åµŒå…¥çš„Transformerç¼–ç å™¨-è§£ç å™¨ä¹‹ä¸Šï¼Œæ•è·é•¿ç¨‹æ—¶é—´ä¾èµ–æ€§ï¼Œå¹¶ç¨³å¥åœ°ç¼–ç å‚æ•°å’Œéå‚æ•°ä»»åŠ¡å˜åŒ–ã€‚åœ¨MetaWorld ML-10æœºå™¨äººæ“ä½œåŸºå‡†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œä¸ä¸Šä¸‹æ–‡è‡ªé€‚åº”å…ƒå¼ºåŒ–å­¦ä¹ åŸºçº¿ç›¸æ¯”ï¼ŒCRAFTå®ç°äº†æ›´å¿«çš„é€‚åº”ã€æ”¹è¿›çš„æ³›åŒ–å’Œæ›´æœ‰æ•ˆçš„æ¢ç´¢ã€‚è¿™äº›å‘ç°çªå‡ºäº†æ— åŠ¨ä½œæ¨æ–­ä½œä¸ºæœºå™¨äººæ§åˆ¶ä¸­å¯æ‰©å±•RLçš„åŸºç¡€çš„æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰å…ƒå¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨è¿›è¡Œä»»åŠ¡æ¨æ–­æ—¶ï¼Œé€šå¸¸éœ€è¦ä¾èµ–å®Œæ•´çš„åŠ¨ä½œä¿¡æ¯ï¼Œè¿™ä½¿å¾—ä»»åŠ¡æ¨æ–­è¿‡ç¨‹ä¸ç‰¹å®šçš„ç­–ç•¥ç´§å¯†è€¦åˆã€‚è¿™ç§è€¦åˆé™åˆ¶äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨é¢å¯¹æœªè§è¿‡çš„ä»»åŠ¡æ—¶ï¼Œæ¨¡å‹éš¾ä»¥å¿«é€Ÿé€‚åº”ã€‚æ­¤å¤–ï¼Œä¾èµ–åŠ¨ä½œä¿¡æ¯ä¹Ÿä½¿å¾—æ¨¡å‹éš¾ä»¥è¿›è¡Œæ¨¡å—åŒ–è®­ç»ƒï¼Œä¸åˆ©äºæ‰©å±•åˆ°æ›´å¤æ‚çš„ä»»åŠ¡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šCRAFTçš„æ ¸å¿ƒæ€è·¯æ˜¯è®¾è®¡ä¸€ä¸ªæ— åŠ¨ä½œçš„ä¿¡å¿µæ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä»…é€šè¿‡è§‚å¯ŸçŠ¶æ€å’Œå¥–åŠ±åºåˆ—æ¥æ¨æ–­ä»»åŠ¡è¡¨ç¤ºã€‚é€šè¿‡æ¶ˆé™¤å¯¹åŠ¨ä½œçš„ä¾èµ–ï¼ŒCRAFTå°†ä»»åŠ¡æ¨æ–­ä¸ç­–ç•¥ä¼˜åŒ–è§£è€¦ï¼Œä»è€Œæé«˜äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œå¯æ‰©å±•æ€§ã€‚è¿™ç§è§£è€¦ä¹Ÿä½¿å¾—æ¨¡å‹å¯ä»¥è¿›è¡Œæ¨¡å—åŒ–è®­ç»ƒï¼Œä¾‹å¦‚å¯ä»¥å…ˆè®­ç»ƒä»»åŠ¡æ¨æ–­æ¨¡å‹ï¼Œç„¶åå†è®­ç»ƒç­–ç•¥ä¼˜åŒ–æ¨¡å‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCRAFTçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä¸€ä¸ªTransformerç¼–ç å™¨-è§£ç å™¨ç»“æ„ã€‚ç¼–ç å™¨æ¥æ”¶çŠ¶æ€å’Œå¥–åŠ±åºåˆ—ä½œä¸ºè¾“å…¥ï¼Œå¹¶å°†å…¶ç¼–ç æˆä¸€ä¸ªä¸Šä¸‹æ–‡å‘é‡ï¼Œè¯¥å‘é‡ä»£è¡¨äº†å¯¹å½“å‰ä»»åŠ¡çš„ä¿¡å¿µã€‚è§£ç å™¨æ¥æ”¶è¯¥ä¸Šä¸‹æ–‡å‘é‡ï¼Œå¹¶è¾“å‡ºä¸€ä¸ªä»»åŠ¡è¡¨ç¤ºã€‚è¯¥ä»»åŠ¡è¡¨ç¤ºå¯ä»¥è¢«ç”¨äºæŒ‡å¯¼ç­–ç•¥ä¼˜åŒ–ã€‚CRAFTä½¿ç”¨æ‘Šé”€å˜åˆ†æ¨æ–­æ¥æ›´æ–°ä¿¡å¿µï¼Œä»è€Œå®ç°å¯æ‰©å±•çš„ä¿¡å¿µæ›´æ–°ã€‚

**å…³é”®åˆ›æ–°**ï¼šCRAFTæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå…¶æ— åŠ¨ä½œçš„ä»»åŠ¡æ¨æ–­æ–¹æ³•ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒCRAFTä¸éœ€è¦ä¾èµ–åŠ¨ä½œä¿¡æ¯ï¼Œä»è€Œå®ç°äº†ä»»åŠ¡æ¨æ–­ä¸ç­–ç•¥ä¼˜åŒ–çš„è§£è€¦ã€‚è¿™ç§è§£è€¦æé«˜äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œå¯æ‰©å±•æ€§ã€‚æ­¤å¤–ï¼ŒCRAFTè¿˜ä½¿ç”¨äº†Transformerç¼–ç å™¨-è§£ç å™¨ç»“æ„ï¼Œå¯ä»¥æœ‰æ•ˆåœ°æ•è·é•¿ç¨‹æ—¶é—´ä¾èµ–æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šCRAFTçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨æ—‹è½¬ä½ç½®åµŒå…¥çš„Transformerç¼–ç å™¨-è§£ç å™¨ï¼Œä»¥æ•è·é•¿ç¨‹æ—¶é—´ä¾èµ–æ€§ï¼›2) ä½¿ç”¨æ‘Šé”€å˜åˆ†æ¨æ–­è¿›è¡Œå¯æ‰©å±•çš„ä¿¡å¿µæ›´æ–°ï¼›3) è®¾è®¡æŸå¤±å‡½æ•°ï¼Œä»¥é¼“åŠ±æ¨¡å‹å­¦ä¹ åˆ°é²æ£’çš„ä»»åŠ¡è¡¨ç¤ºã€‚å…·ä½“æ¥è¯´ï¼ŒæŸå¤±å‡½æ•°åŒ…æ‹¬é‡æ„æŸå¤±å’ŒKLæ•£åº¦æŸå¤±ã€‚é‡æ„æŸå¤±ç”¨äºé¼“åŠ±æ¨¡å‹èƒ½å¤Ÿä»ä»»åŠ¡è¡¨ç¤ºä¸­é‡æ„å‡ºåŸå§‹çš„çŠ¶æ€å’Œå¥–åŠ±åºåˆ—ï¼ŒKLæ•£åº¦æŸå¤±ç”¨äºçº¦æŸä»»åŠ¡è¡¨ç¤ºçš„åˆ†å¸ƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

CRAFTåœ¨MetaWorld ML-10æœºå™¨äººæ“ä½œåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œä¸ä¸Šä¸‹æ–‡è‡ªé€‚åº”å…ƒå¼ºåŒ–å­¦ä¹ åŸºçº¿ç›¸æ¯”ï¼Œå®ç°äº†æ›´å¿«çš„é€‚åº”é€Ÿåº¦ã€æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›å’Œæ›´æœ‰æ•ˆçš„æ¢ç´¢ã€‚å…·ä½“æ€§èƒ½æ•°æ®æœªçŸ¥ï¼Œä½†è®ºæ–‡å¼ºè°ƒäº†CRAFTåœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šå‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

CRAFTçš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæ§åˆ¶ã€æ¸¸æˆAIå’Œè‡ªåŠ¨é©¾é©¶ç­‰ã€‚é€šè¿‡å­¦ä¹ ä»…åŸºäºçŠ¶æ€å’Œå¥–åŠ±çš„ä»»åŠ¡è¡¨ç¤ºï¼ŒCRAFTå¯ä»¥å¸®åŠ©æœºå™¨äººåœ¨æœªçŸ¥çš„ç¯å¢ƒä¸­å¿«é€Ÿé€‚åº”å’Œå­¦ä¹ æ–°çš„ä»»åŠ¡ã€‚è¿™å¯¹äºéœ€è¦åœ¨å¤æ‚å’ŒåŠ¨æ€ç¯å¢ƒä¸­è¿è¡Œçš„æœºå™¨äººæ¥è¯´å°¤å…¶é‡è¦ã€‚æ­¤å¤–ï¼ŒCRAFTçš„æ¨¡å—åŒ–è®¾è®¡ä¹Ÿä½¿å…¶æ˜“äºæ‰©å±•åˆ°æ›´å¤æ‚çš„ä»»åŠ¡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Reinforcement learning (RL) enables robots to operate in uncertain environments, but standard approaches often struggle with poor generalization to unseen tasks. Context-adaptive meta reinforcement learning addresses these limitations by conditioning on the task representation, yet they mostly rely on complete action information in the experience making task inference tightly coupled to a specific policy. This paper introduces Context Representation via Action Free Transformer encoder decoder (CRAFT), a belief model that infers task representations solely from sequences of states and rewards. By removing the dependence on actions, CRAFT decouples task inference from policy optimization, supports modular training, and leverages amortized variational inference for scalable belief updates. Built on a transformer encoder decoder with rotary positional embeddings, the model captures long range temporal dependencies and robustly encodes both parametric and non-parametric task variations. Experiments on the MetaWorld ML-10 robotic manipulation benchmark show that CRAFT achieves faster adaptation, improved generalization, and more effective exploration compared to context adaptive meta--RL baselines. These findings highlight the potential of action-free inference as a foundation for scalable RL in robotic control.

