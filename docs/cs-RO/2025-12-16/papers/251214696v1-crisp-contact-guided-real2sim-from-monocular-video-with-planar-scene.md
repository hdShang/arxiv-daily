---
layout: default
title: CRISP: Contact-Guided Real2Sim from Monocular Video with Planar Scene Primitives
---

# CRISP: Contact-Guided Real2Sim from Monocular Video with Planar Scene Primitives

**arXiv**: [2512.14696v1](https://arxiv.org/abs/2512.14696) | [PDF](https://arxiv.org/pdf/2512.14696.pdf)

**ä½œè€…**: Zihan Wang, Jiashun Wang, Jeff Tan, Yiwen Zhao, Jessica Hodgins, Shubham Tulsiani, Deva Ramanan

**åˆ†ç±»**: cs.CV, cs.GR, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: Project page: https://crisp-real2sim.github.io/CRISP-Real2Sim/

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCRISPæ–¹æ³•ï¼Œé€šè¿‡å¹³é¢åŸºå…ƒæ‹Ÿåˆå’ŒæŽ¥è§¦å¼•å¯¼ï¼Œä»Žå•ç›®è§†é¢‘é‡å»ºå¯æ¨¡æ‹Ÿçš„äººä½“è¿åŠ¨ä¸Žåœºæ™¯å‡ ä½•ï¼Œè§£å†³ç‰©ç†äº¤äº’å¤±è´¥é—®é¢˜ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **äººå½¢æœºå™¨äºº** **åŠ¨ä½œç”Ÿæˆ** **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `å•ç›®è§†é¢‘é‡å»º` `äººä½“-åœºæ™¯äº¤äº’` `å¹³é¢åŸºå…ƒæ‹Ÿåˆ` `æŽ¥è§¦å»ºæ¨¡` `å¼ºåŒ–å­¦ä¹ æ¨¡æ‹Ÿ` `çœŸå®žåˆ°æ¨¡æ‹Ÿ` `å‡ ä½•é‡å»º` `ç‰©ç†åˆç†æ€§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•ä¾èµ–æ•°æ®å…ˆéªŒæˆ–æ— ç‰©ç†ä¼˜åŒ–ï¼Œå¯¼è‡´å‡ ä½•å™ªå£°å’Œäº¤äº’å¤±è´¥ï¼Œéš¾ä»¥å®žçŽ°çœŸå®žåˆ°æ¨¡æ‹Ÿçš„è½¬æ¢ã€‚
2. CRISPé€šè¿‡å¹³é¢åŸºå…ƒæ‹Ÿåˆå’ŒæŽ¥è§¦å»ºæ¨¡ï¼Œæ¢å¤å¹²å‡€ã€å¯æ¨¡æ‹Ÿçš„å‡ ä½•ï¼Œå¹¶åˆ©ç”¨å¼ºåŒ–å­¦ä¹ ç¡®ä¿ç‰©ç†åˆç†æ€§ã€‚
3. åœ¨åŸºå‡†æµ‹è¯•ä¸­ï¼Œè¿åŠ¨è·Ÿè¸ªå¤±è´¥çŽ‡ä»Ž55.2%é™è‡³6.9%ï¼Œæ¨¡æ‹Ÿåžåé‡æå‡43%ï¼Œå¹¶åœ¨å¤šç§è§†é¢‘ä¸ŠéªŒè¯æœ‰æ•ˆæ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬ä»‹ç»äº†CRISPï¼Œä¸€ç§ä»Žå•ç›®è§†é¢‘ä¸­æ¢å¤å¯æ¨¡æ‹Ÿäººä½“è¿åŠ¨å’Œåœºæ™¯å‡ ä½•çš„æ–¹æ³•ã€‚å…ˆå‰å…³äºŽäººä½“-åœºæ™¯è”åˆé‡å»ºçš„å·¥ä½œä¾èµ–äºŽæ•°æ®é©±åŠ¨çš„å…ˆéªŒå’Œæ— ç‰©ç†çº¦æŸçš„è”åˆä¼˜åŒ–ï¼Œæˆ–è€…æ¢å¤å¸¦æœ‰å™ªå£°å’Œä¼ªå½±çš„å‡ ä½•ï¼Œå¯¼è‡´åœºæ™¯äº¤äº’çš„è¿åŠ¨è·Ÿè¸ªç­–ç•¥å¤±è´¥ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œæˆ‘ä»¬çš„å…³é”®è§è§£æ˜¯é€šè¿‡å¯¹åœºæ™¯ç‚¹äº‘é‡å»ºè¿›è¡Œå¹³é¢åŸºå…ƒæ‹Ÿåˆï¼Œåˆ©ç”¨æ·±åº¦ã€æ³•çº¿å’Œå…‰æµçš„ç®€å•èšç±»æµç¨‹ï¼Œæ¢å¤å‡¸é¢ã€å¹²å‡€ä¸”å¯æ¨¡æ‹Ÿçš„å‡ ä½•ã€‚ä¸ºäº†é‡å»ºåœ¨äº¤äº’è¿‡ç¨‹ä¸­å¯èƒ½è¢«é®æŒ¡çš„åœºæ™¯å‡ ä½•ï¼Œæˆ‘ä»¬åˆ©ç”¨äººä½“-åœºæ™¯æŽ¥è§¦å»ºæ¨¡ï¼ˆä¾‹å¦‚ï¼Œä½¿ç”¨äººä½“å§¿æ€é‡å»ºè¢«é®æŒ¡çš„æ¤…å­åº§ä½ï¼‰ã€‚æœ€åŽï¼Œæˆ‘ä»¬é€šè¿‡å¼ºåŒ–å­¦ä¹ é©±åŠ¨äººå½¢æŽ§åˆ¶å™¨ï¼Œç¡®ä¿äººä½“å’Œåœºæ™¯é‡å»ºå…·æœ‰ç‰©ç†åˆç†æ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨äººä½“ä¸­å¿ƒè§†é¢‘åŸºå‡†ï¼ˆEMDBã€PROXï¼‰ä¸Šå°†è¿åŠ¨è·Ÿè¸ªå¤±è´¥çŽ‡ä»Ž55.2%é™ä½Žåˆ°6.9%ï¼ŒåŒæ—¶æä¾›43%æ›´å¿«çš„RLæ¨¡æ‹Ÿåžåé‡ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥åœ¨é‡Žå¤–è§†é¢‘ä¸ŠéªŒè¯äº†è¯¥æ–¹æ³•ï¼ŒåŒ…æ‹¬éšæ„æ‹æ‘„çš„è§†é¢‘ã€äº’è”ç½‘è§†é¢‘ï¼Œç”šè‡³Soraç”Ÿæˆçš„è§†é¢‘ã€‚è¿™å±•ç¤ºäº†CRISPå¤§è§„æ¨¡ç”Ÿæˆç‰©ç†æœ‰æ•ˆäººä½“è¿åŠ¨å’Œäº¤äº’çŽ¯å¢ƒçš„èƒ½åŠ›ï¼Œæžå¤§åœ°æŽ¨è¿›äº†æœºå™¨äººå’ŒAR/VRçš„çœŸå®žåˆ°æ¨¡æ‹Ÿåº”ç”¨ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨ä»Žå•ç›®è§†é¢‘ä¸­è”åˆé‡å»ºå¯æ¨¡æ‹Ÿçš„äººä½“è¿åŠ¨å’Œåœºæ™¯å‡ ä½•ï¼Œä»¥æ”¯æŒç‰©ç†äº¤äº’åº”ç”¨ã€‚çŽ°æœ‰æ–¹æ³•çš„ç—›ç‚¹åŒ…æ‹¬ï¼šä¾èµ–æ•°æ®é©±åŠ¨å…ˆéªŒå¯¼è‡´æ³›åŒ–æ€§å·®ï¼›æ— ç‰©ç†çº¦æŸçš„ä¼˜åŒ–äº§ç”Ÿå™ªå£°å‡ ä½•å’Œä¼ªå½±ï¼›è¿™äº›ç¼ºé™·ä½¿å¾—åŸºäºŽåœºæ™¯äº¤äº’çš„è¿åŠ¨è·Ÿè¸ªç­–ç•¥ï¼ˆå¦‚å¼ºåŒ–å­¦ä¹ æŽ§åˆ¶å™¨ï¼‰å®¹æ˜“å¤±è´¥ï¼Œé™åˆ¶äº†çœŸå®žåˆ°æ¨¡æ‹Ÿï¼ˆreal-to-simï¼‰çš„å®žç”¨æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šCRISPçš„æ ¸å¿ƒæ€è·¯æ˜¯æ¢å¤å‡¸é¢ã€å¹²å‡€ä¸”å¯æ¨¡æ‹Ÿçš„åœºæ™¯å‡ ä½•ï¼Œé€šè¿‡æ‹Ÿåˆå¹³é¢åŸºå…ƒåˆ°ç‚¹äº‘é‡å»ºï¼Œå¹¶ç»“åˆäººä½“-åœºæ™¯æŽ¥è§¦å»ºæ¨¡æ¥è¡¥å…¨é®æŒ¡éƒ¨åˆ†ã€‚è®¾è®¡åŸºäºŽç‰©ç†åˆç†æ€§åŽŸåˆ™ï¼Œç¡®ä¿é‡å»ºç»“æžœå¯ç›´æŽ¥ç”¨äºŽæ¨¡æ‹ŸçŽ¯å¢ƒï¼Œä»Žè€Œæå‡è¿åŠ¨è·Ÿè¸ªçš„ç¨³å®šæ€§å’Œæ•ˆçŽ‡ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æµç¨‹åˆ†ä¸ºä¸‰ä¸ªé˜¶æ®µï¼šé¦–å…ˆï¼Œä»Žå•ç›®è§†é¢‘è¿›è¡Œåˆå§‹ç‚¹äº‘é‡å»ºï¼›å…¶æ¬¡ï¼Œé€šè¿‡èšç±»æµç¨‹ï¼ˆåŸºäºŽæ·±åº¦ã€æ³•çº¿å’Œå…‰æµï¼‰æ‹Ÿåˆå¹³é¢åŸºå…ƒï¼Œç”Ÿæˆå‡¸é¢å‡ ä½•ï¼›ç„¶åŽï¼Œåˆ©ç”¨äººä½“å§¿æ€å’ŒæŽ¥è§¦ä¿¡æ¯ï¼ˆå¦‚è„šéƒ¨æˆ–æ‰‹éƒ¨ä½ç½®ï¼‰é‡å»ºè¢«é®æŒ¡çš„åœºæ™¯éƒ¨åˆ†ï¼ˆå¦‚æ¤…å­åº§ä½ï¼‰ï¼›æœ€åŽï¼Œå°†é‡å»ºçš„äººä½“å’Œåœºæ™¯è¾“å…¥å¼ºåŒ–å­¦ä¹ äººå½¢æŽ§åˆ¶å™¨ï¼Œè¿›è¡Œç‰©ç†éªŒè¯å’Œä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°æ˜¯ç»“åˆå¹³é¢åŸºå…ƒæ‹Ÿåˆå’ŒæŽ¥è§¦å¼•å¯¼çš„å‡ ä½•é‡å»ºï¼Œä¸ŽçŽ°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºŽï¼šå¼ºè°ƒå‡ ä½•çš„å‡¸é¢å’Œå¯æ¨¡æ‹Ÿæ€§ï¼Œè€Œéžä»…è¿½æ±‚è§†è§‰ç²¾åº¦ï¼›å¼•å…¥ç‰©ç†çº¦æŸï¼ˆé€šè¿‡æŽ¥è§¦å»ºæ¨¡å’Œå¼ºåŒ–å­¦ä¹ ï¼‰ï¼Œç¡®ä¿é‡å»ºç»“æžœé€‚ç”¨äºŽäº¤äº’ä»»åŠ¡ï¼Œè€Œéžä»…ç”¨äºŽé™æ€é‡å»ºã€‚

**å…³é”®è®¾è®¡**ï¼šæŠ€æœ¯ç»†èŠ‚åŒ…æ‹¬ï¼šä½¿ç”¨ç®€å•èšç±»ç®—æ³•ï¼ˆå¦‚åŸºäºŽæ·±åº¦ã€æ³•å‘é‡å’Œå…‰æµçš„K-meansæˆ–åŒºåŸŸç”Ÿé•¿ï¼‰è¿›è¡Œå¹³é¢åˆ†å‰²ï¼›æŽ¥è§¦å»ºæ¨¡åŸºäºŽäººä½“å…³é”®ç‚¹ä¸Žåœºæ™¯çš„ä¼°è®¡æŽ¥è§¦åŒºåŸŸï¼Œç”¨äºŽæŽ¨æ–­é®æŒ¡å‡ ä½•ï¼›å¼ºåŒ–å­¦ä¹ æŽ§åˆ¶å™¨é‡‡ç”¨æ ‡å‡†äººå½¢æ¨¡æ‹ŸçŽ¯å¢ƒï¼ˆå¦‚Isaac Gymï¼‰ï¼ŒæŸå¤±å‡½æ•°ç»“åˆè¿åŠ¨è·Ÿè¸ªè¯¯å·®å’Œç‰©ç†çº¦æŸï¼ˆå¦‚æŽ¥è§¦åŠ›ï¼‰ï¼›å‚æ•°è®¾ç½®ä¸­ï¼Œå¹³é¢æ‹Ÿåˆçš„é˜ˆå€¼å’Œèšç±»æ•°é‡æ ¹æ®åœºæ™¯å¤æ‚åº¦è‡ªé€‚åº”è°ƒæ•´ï¼Œä»¥å¹³è¡¡ç²¾åº¦å’Œæ•ˆçŽ‡ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

æœ€é‡è¦çš„å®žéªŒç»“æžœåŒ…æ‹¬ï¼šåœ¨EMDBå’ŒPROXäººä½“ä¸­å¿ƒè§†é¢‘åŸºå‡†ä¸Šï¼Œè¿åŠ¨è·Ÿè¸ªå¤±è´¥çŽ‡ä»ŽåŸºçº¿æ–¹æ³•çš„55.2%æ˜¾è‘—é™ä½Žè‡³6.9%ï¼Œæå‡äº†48.3ä¸ªç™¾åˆ†ç‚¹ï¼›å¼ºåŒ–å­¦ä¹ æ¨¡æ‹Ÿåžåé‡æé«˜43%ï¼ŒåŠ é€Ÿäº†è®­ç»ƒè¿‡ç¨‹ã€‚æ–¹æ³•åœ¨å¤šç§è§†é¢‘ç±»åž‹ä¸ŠéªŒè¯æœ‰æ•ˆï¼ŒåŒ…æ‹¬éšæ„æ‹æ‘„è§†é¢‘ã€äº’è”ç½‘è§†é¢‘å’ŒAIç”Ÿæˆè§†é¢‘ï¼ˆå¦‚Soraï¼‰ï¼Œå±•ç¤ºäº†å…¶é²æ£’æ€§å’Œæ³›åŒ–æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

CRISPçš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººä»¿çœŸè®­ç»ƒã€å¢žå¼ºçŽ°å®ž/è™šæ‹ŸçŽ°å®žï¼ˆAR/VRï¼‰å†…å®¹ç”Ÿæˆå’Œäººä½“è¿åŠ¨åˆ†æžã€‚å®žé™…ä»·å€¼åœ¨äºŽèƒ½å¤Ÿä»ŽçœŸå®žä¸–ç•Œè§†é¢‘å¤§è§„æ¨¡ç”Ÿæˆç‰©ç†æœ‰æ•ˆçš„äº¤äº’çŽ¯å¢ƒï¼Œé™ä½Žä»¿çœŸæ•°æ®é‡‡é›†æˆæœ¬ï¼Œæå‡æ¨¡æ‹Ÿçš„çœŸå®žæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚æœªæ¥å½±å“å¯èƒ½æŽ¨åŠ¨çœŸå®žåˆ°æ¨¡æ‹ŸæŠ€æœ¯åœ¨è‡ªåŠ¨é©¾é©¶ã€æ¸¸æˆå¼€å‘å’Œæ™ºèƒ½ä½“è®­ç»ƒä¸­çš„å¹¿æ³›åº”ç”¨ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We introduce CRISP, a method that recovers simulatable human motion and scene geometry from monocular video. Prior work on joint human-scene reconstruction relies on data-driven priors and joint optimization with no physics in the loop, or recovers noisy geometry with artifacts that cause motion tracking policies with scene interactions to fail. In contrast, our key insight is to recover convex, clean, and simulation-ready geometry by fitting planar primitives to a point cloud reconstruction of the scene, via a simple clustering pipeline over depth, normals, and flow. To reconstruct scene geometry that might be occluded during interactions, we make use of human-scene contact modeling (e.g., we use human posture to reconstruct the occluded seat of a chair). Finally, we ensure that human and scene reconstructions are physically-plausible by using them to drive a humanoid controller via reinforcement learning. Our approach reduces motion tracking failure rates from 55.2\% to 6.9\% on human-centric video benchmarks (EMDB, PROX), while delivering a 43\% faster RL simulation throughput. We further validate it on in-the-wild videos including casually-captured videos, Internet videos, and even Sora-generated videos. This demonstrates CRISP's ability to generate physically-valid human motion and interaction environments at scale, greatly advancing real-to-sim applications for robotics and AR/VR.

