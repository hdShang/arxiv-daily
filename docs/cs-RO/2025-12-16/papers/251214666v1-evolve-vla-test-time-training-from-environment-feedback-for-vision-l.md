---
layout: default
title: EVOLVE-VLA: Test-Time Training from Environment Feedback for Vision-Language-Action Models
---

# EVOLVE-VLA: Test-Time Training from Environment Feedback for Vision-Language-Action Models

**arXiv**: [2512.14666v1](https://arxiv.org/abs/2512.14666) | [PDF](https://arxiv.org/pdf/2512.14666.pdf)

**ä½œè€…**: Zechen Bai, Chen Gao, Mike Zheng Shou

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: 15 pages

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEVOLVE-VLAæ¡†æž¶ï¼Œé€šè¿‡çŽ¯å¢ƒåé¦ˆå®žçŽ°è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹çš„æµ‹è¯•æ—¶è®­ç»ƒï¼Œè§£å†³æœºå™¨äººé€‚åº”æ€§é—®é¢˜ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **è§†è§‰é‡Œç¨‹è®¡** **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹` `æµ‹è¯•æ—¶è®­ç»ƒ` `çŽ¯å¢ƒåé¦ˆ` `æœºå™¨äººæ“ä½œ` `è‡ªé€‚åº”å­¦ä¹ ` `è¿›åº¦ä¼°è®¡` `å™ªå£°é©¯æœ` `è·¨ä»»åŠ¡æ³›åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰VLAæ¨¡åž‹ä¾èµ–ç›‘ç£å¾®è°ƒï¼Œéœ€è¦å¤§é‡æ¼”ç¤ºã€è®°å¿†è½¨è¿¹ï¼Œæ— æ³•é€‚åº”éƒ¨ç½²æ¡ä»¶å˜åŒ–ï¼Œé™åˆ¶äº†æœºå™¨äººè‡ªé€‚åº”èƒ½åŠ›ã€‚
2. æå‡ºEVOLVE-VLAæ¡†æž¶ï¼Œé€šè¿‡çŽ¯å¢ƒåé¦ˆå®žçŽ°æµ‹è¯•æ—¶è®­ç»ƒï¼Œåˆ©ç”¨å­¦ä¹ è¿›åº¦ä¼°è®¡å™¨å’Œå™ªå£°é©¯æœæœºåˆ¶ï¼Œä½¿æ¨¡åž‹æŒç»­è‡ªæˆ‘æ”¹è¿›ã€‚
3. å®žéªŒæ˜¾ç¤ºï¼ŒEVOLVE-VLAåœ¨é•¿è§†é‡Žä»»åŠ¡æå‡8.6%ï¼Œå•æ ·æœ¬å­¦ä¹ æå‡22.0%ï¼Œå¹¶åœ¨æœªè§ä»»åŠ¡ä¸Šå®žçŽ°20.8%æˆåŠŸçŽ‡ï¼Œæ˜¾è‘—ä¼˜äºŽçº¯SFTã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å®žçŽ°çœŸæ­£çš„è‡ªé€‚åº”å…·èº«æ™ºèƒ½éœ€è¦æ™ºèƒ½ä½“é€šè¿‡çŽ¯å¢ƒäº¤äº’æŒç»­å­¦ä¹ ï¼Œè€Œä¸ä»…ä»…æ˜¯æ¨¡ä»¿é™æ€æ¼”ç¤ºã€‚è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡åž‹é€šè¿‡åˆ©ç”¨å¤§è¯­è¨€æ¨¡åž‹æŽ¨åŠ¨äº†æœºå™¨äººæ“ä½œçš„å‘å±•ï¼Œä½†ä»å—é™äºŽç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ï¼šæ¯ä¸ªä»»åŠ¡éœ€è¦æ•°ç™¾ä¸ªæ¼”ç¤ºã€åƒµåŒ–åœ°è®°å¿†è½¨è¿¹ï¼Œä¸”åœ¨éƒ¨ç½²æ¡ä»¶åç¦»è®­ç»ƒæ—¶æ— æ³•é€‚åº”ã€‚æˆ‘ä»¬æå‡ºäº†EVOLVE-VLAï¼Œè¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ—¶è®­ç»ƒæ¡†æž¶ï¼Œä½¿VLAèƒ½å¤Ÿé€šè¿‡çŽ¯å¢ƒäº¤äº’ä»¥æœ€å°‘æˆ–é›¶ä»»åŠ¡ç‰¹å®šæ¼”ç¤ºæŒç»­é€‚åº”ã€‚å…³é”®æŠ€æœ¯æŒ‘æˆ˜æ˜¯ç”¨è‡ªä¸»åé¦ˆæ›¿ä»£æµ‹è¯•æ—¶ä¸å¯ç”¨çš„oracleå¥–åŠ±ä¿¡å·ã€‚æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªæä¾›å¯†é›†åé¦ˆçš„å­¦ä¹ è¿›åº¦ä¼°è®¡å™¨æ¥è§£å†³è¿™ä¸€é—®é¢˜ï¼Œå¹¶å…³é”®åœ°è®¾è®¡äº†ä¸¤ä¸ªæœºåˆ¶æ¥â€œé©¯æœâ€è¿™ç§å›ºæœ‰å™ªå£°ä¿¡å·ï¼šï¼ˆ1ï¼‰ç´¯ç§¯è¿›åº¦ä¼°è®¡æœºåˆ¶å¹³æ»‘å™ªå£°ç‚¹ä¼°è®¡ï¼›ï¼ˆ2ï¼‰æ¸è¿›è§†é‡Žæ‰©å±•ç­–ç•¥å®žçŽ°é€æ­¥ç­–ç•¥æ¼”åŒ–ã€‚EVOLVE-VLAå–å¾—äº†æ˜¾è‘—æå‡ï¼šé•¿è§†é‡Žä»»åŠ¡æå‡+8.6%ï¼Œå•æ ·æœ¬å­¦ä¹ æå‡+22.0%ï¼Œå¹¶å®žçŽ°è·¨ä»»åŠ¡æ³›åŒ–â€”â€”åœ¨æœªè§ä»»åŠ¡ä¸Šè¾¾åˆ°20.8%çš„æˆåŠŸçŽ‡ï¼Œæ— éœ€ä»»åŠ¡ç‰¹å®šæ¼”ç¤ºè®­ç»ƒï¼ˆçº¯SFTä¸º0%ï¼‰ã€‚å®šæ€§åˆ†æžæ­ç¤ºäº†æ¼”ç¤ºä¸­ä¸å­˜åœ¨çš„æ¶ŒçŽ°èƒ½åŠ›ï¼ŒåŒ…æ‹¬é”™è¯¯æ¢å¤å’Œæ–°ç­–ç•¥ã€‚è¿™é¡¹å·¥ä½œä»£è¡¨äº†VLAçœŸæ­£å­¦ä¹ å’Œé€‚åº”çš„å…³é”®ä¸€æ­¥ï¼Œä»Žé™æ€æ¨¡ä»¿è¿ˆå‘æŒç»­è‡ªæˆ‘æ”¹è¿›ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡åž‹åœ¨æœºå™¨äººæ“ä½œä¸­å› ä¾èµ–ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰è€Œå¯¼è‡´çš„é€‚åº”æ€§é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•çš„ç—›ç‚¹åŒ…æ‹¬ï¼šæ¯ä¸ªä»»åŠ¡éœ€è¦æ•°ç™¾ä¸ªæ¼”ç¤ºï¼Œå¯¼è‡´æ•°æ®æ•ˆçŽ‡ä½Žä¸‹ï¼›æ¨¡åž‹åƒµåŒ–åœ°è®°å¿†è½¨è¿¹ï¼Œç¼ºä¹çµæ´»æ€§ï¼›å½“éƒ¨ç½²çŽ¯å¢ƒä¸Žè®­ç»ƒæ¡ä»¶åå·®æ—¶ï¼Œæ¨¡åž‹æ— æ³•è‡ªé€‚åº”è°ƒæ•´ï¼Œé™åˆ¶äº†å®žé™…åº”ç”¨ä¸­çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒè§£å†³æ€è·¯æ˜¯å¼•å…¥æµ‹è¯•æ—¶è®­ç»ƒæ¡†æž¶ï¼Œä½¿VLAæ¨¡åž‹èƒ½å¤Ÿé€šè¿‡çŽ¯å¢ƒäº¤äº’æŒç»­å­¦ä¹ å’Œé€‚åº”ï¼Œè€Œæ— éœ€ä¾èµ–å¤§é‡ä»»åŠ¡ç‰¹å®šæ¼”ç¤ºã€‚è®¾è®¡çš„å…³é”®åœ¨äºŽç”¨è‡ªä¸»åé¦ˆæ›¿ä»£æµ‹è¯•æ—¶ä¸å¯ç”¨çš„oracleå¥–åŠ±ä¿¡å·ï¼Œé€šè¿‡ä¸€ä¸ªå­¦ä¹ è¿›åº¦ä¼°è®¡å™¨æä¾›å¯†é›†åé¦ˆï¼Œå¹¶é‡‡ç”¨æœºåˆ¶æ¥é©¯æœåé¦ˆä¸­çš„å™ªå£°ï¼Œä»Žè€Œå®žçŽ°ç¨³å®šå’Œæœ‰æ•ˆçš„ç­–ç•¥æ¼”åŒ–ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æž¶æž„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šç¦»çº¿é¢„è®­ç»ƒå’Œåœ¨çº¿æµ‹è¯•æ—¶è®­ç»ƒã€‚åœ¨ç¦»çº¿é˜¶æ®µï¼Œæ¨¡åž‹å¯èƒ½åŸºäºŽåŸºç¡€VLAæž¶æž„è¿›è¡Œåˆå§‹åŒ–ã€‚åœ¨çº¿é˜¶æ®µï¼Œæ¨¡åž‹ä¸ŽçŽ¯å¢ƒäº¤äº’ï¼Œæ”¶é›†çŠ¶æ€å’ŒåŠ¨ä½œæ•°æ®ï¼Œé€šè¿‡å­¦ä¹ è¿›åº¦ä¼°è®¡å™¨è®¡ç®—åé¦ˆä¿¡å·ï¼Œå¹¶åˆ©ç”¨ç´¯ç§¯è¿›åº¦ä¼°è®¡å’Œæ¸è¿›è§†é‡Žæ‰©å±•ç­–ç•¥æ¥æ›´æ–°ç­–ç•¥ã€‚æ¡†æž¶æµç¨‹ä¸ºï¼šäº¤äº’â†’åé¦ˆä¼°è®¡â†’å™ªå£°å¹³æ»‘â†’ç­–ç•¥æ›´æ–°â†’é‡å¤ï¼Œå½¢æˆä¸€ä¸ªé—­çŽ¯å­¦ä¹ å¾ªçŽ¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹æ˜¯æå‡ºäº†ä¸€ä¸ªå®Œå…¨è‡ªä¸»çš„æµ‹è¯•æ—¶è®­ç»ƒæ¡†æž¶ï¼Œæ— éœ€å¤–éƒ¨å¥–åŠ±ä¿¡å·ï¼Œé€šè¿‡çŽ¯å¢ƒåé¦ˆé©±åŠ¨æ¨¡åž‹é€‚åº”ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºŽï¼šEVOLVE-VLAæ‘†è„±äº†å¯¹é™æ€æ¼”ç¤ºçš„ä¾èµ–ï¼Œå®žçŽ°äº†ä»Žæ¨¡ä»¿å­¦ä¹ åˆ°äº¤äº’å­¦ä¹ çš„èŒƒå¼è½¬å˜ï¼›å®ƒé€šè¿‡å™ªå£°é©¯æœæœºåˆ¶å¤„ç†åé¦ˆçš„ä¸ç¡®å®šæ€§ï¼Œæé«˜äº†å­¦ä¹ ç¨³å®šæ€§å’Œæ•ˆçŽ‡ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼šå­¦ä¹ è¿›åº¦ä¼°è®¡å™¨ï¼Œå¯èƒ½åŸºäºŽç¥žç»ç½‘ç»œï¼Œè¾“å…¥çŠ¶æ€å’ŒåŠ¨ä½œåºåˆ—ï¼Œè¾“å‡ºå¯†é›†åé¦ˆå€¼ï¼›ç´¯ç§¯è¿›åº¦ä¼°è®¡æœºåˆ¶ï¼Œé€šè¿‡æ»‘åŠ¨å¹³å‡æˆ–ç§¯åˆ†æ–¹æ³•å¹³æ»‘ç‚¹ä¼°è®¡ï¼Œå‡å°‘å™ªå£°å½±å“ï¼›æ¸è¿›è§†é‡Žæ‰©å±•ç­–ç•¥ï¼Œé€æ­¥å¢žåŠ ç­–ç•¥æ›´æ–°çš„æ—¶é—´èŒƒå›´ï¼Œä»ŽçŸ­è§†é‡Žå¼€å§‹æ‰©å±•åˆ°é•¿è§†é‡Žï¼Œé¿å…è¿‡æ—©é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚æŸå¤±å‡½æ•°å¯èƒ½ç»“åˆåé¦ˆä¿¡å·å’Œç­–ç•¥æ¢¯åº¦æ–¹æ³•ï¼Œç½‘ç»œç»“æž„åŸºäºŽçŽ°æœ‰VLAæ¨¡åž‹ï¼ˆå¦‚Transformeræž¶æž„ï¼‰ï¼Œå‚æ•°è®¾ç½®æ¶‰åŠå­¦ä¹ çŽ‡ã€åé¦ˆæƒé‡å’Œè§†é‡Žæ‰©å±•é€ŸçŽ‡ç­‰è¶…å‚æ•°ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

EVOLVE-VLAåœ¨å®žéªŒä¸­å–å¾—æ˜¾è‘—æ€§èƒ½æå‡ï¼šé•¿è§†é‡Žä»»åŠ¡æˆåŠŸçŽ‡æé«˜8.6%ï¼Œå•æ ·æœ¬å­¦ä¹ æå‡22.0%ã€‚è·¨ä»»åŠ¡æ³›åŒ–æ–¹é¢ï¼Œåœ¨æœªè§ä»»åŠ¡ä¸Šè¾¾åˆ°20.8%æˆåŠŸçŽ‡ï¼Œè€Œçº¯ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰åŸºçº¿ä¸º0%ã€‚å®šæ€§åˆ†æžæ˜¾ç¤ºæ¨¡åž‹æ¶ŒçŽ°å‡ºé”™è¯¯æ¢å¤å’Œæ–°ç­–ç•¥ç­‰èƒ½åŠ›ï¼ŒéªŒè¯äº†æ¡†æž¶çš„æœ‰æ•ˆæ€§å’Œé€‚åº”æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨æœºå™¨äººæ“ä½œå’Œå…·èº«æ™ºèƒ½é¢†åŸŸå…·æœ‰å¹¿æ³›æ½œåœ¨åº”ç”¨ï¼Œå¦‚å®¶åº­æœåŠ¡æœºå™¨äººã€å·¥ä¸šè‡ªåŠ¨åŒ–ã€åŒ»ç–—è¾…åŠ©å’Œæ— äººé©¾é©¶ã€‚é€šè¿‡å®žçŽ°æµ‹è¯•æ—¶è‡ªé€‚åº”ï¼ŒEVOLVE-VLAèƒ½æå‡æœºå™¨äººåœ¨åŠ¨æ€çŽ¯å¢ƒä¸­çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ï¼Œå‡å°‘å¯¹å¤§é‡æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œé™ä½Žéƒ¨ç½²æˆæœ¬ã€‚æœªæ¥å¯èƒ½æŽ¨åŠ¨æ›´æ™ºèƒ½ã€æ›´çµæ´»çš„è‡ªä¸»ç³»ç»Ÿå‘å±•ï¼Œä¿ƒè¿›äººå·¥æ™ºèƒ½ä»Žé™æ€å­¦ä¹ å‘æŒç»­äº¤äº’å­¦ä¹ çš„æ¼”è¿›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Achieving truly adaptive embodied intelligence requires agents that learn not just by imitating static demonstrations, but by continuously improving through environmental interaction, which is akin to how humans master skills through practice. Vision-Language-Action (VLA) models have advanced robotic manipulation by leveraging large language models, yet remain fundamentally limited by Supervised Finetuning (SFT): requiring hundreds of demonstrations per task, rigidly memorizing trajectories, and failing to adapt when deployment conditions deviate from training. We introduce EVOLVE-VLA, a test-time training framework enabling VLAs to continuously adapt through environment interaction with minimal or zero task-specific demonstrations. The key technical challenge is replacing oracle reward signals (unavailable at test time) with autonomous feedback. We address this through a learned progress estimator providing dense feedback, and critically, we design our framework to ``tame'' this inherently noisy signal via two mechanisms: (1) an accumulative progress estimation mechanism smoothing noisy point-wise estimates, and (2) a progressive horizon extension strategy enabling gradual policy evolution. EVOLVE-VLA achieves substantial gains: +8.6\% on long-horizon tasks, +22.0\% in 1-shot learning, and enables cross-task generalization -- achieving 20.8\% success on unseen tasks without task-specific demonstrations training (vs. 0\% for pure SFT). Qualitative analysis reveals emergent capabilities absent in demonstrations, including error recovery and novel strategies. This work represents a critical step toward VLAs that truly learn and adapt, moving beyond static imitation toward continuous self-improvements.

