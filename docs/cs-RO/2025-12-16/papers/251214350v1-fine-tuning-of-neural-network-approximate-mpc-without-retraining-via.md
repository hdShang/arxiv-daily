---
layout: default
title: Fine-Tuning of Neural Network Approximate MPC without Retraining via Bayesian Optimization
---

# Fine-Tuning of Neural Network Approximate MPC without Retraining via Bayesian Optimization

**arXiv**: [2512.14350v1](https://arxiv.org/abs/2512.14350) | [PDF](https://arxiv.org/pdf/2512.14350.pdf)

**ä½œè€…**: Henrik Hose, Paul Brunzema, Alexander von Rohr, Alexander GrÃ¤fe, Angela P. Schoellig, Sebastian Trimpe

**åˆ†ç±»**: cs.RO, eess.SY

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽè´å¶æ–¯ä¼˜åŒ–çš„AMPCè°ƒå‚æ–¹æ³•ï¼Œæ— éœ€é‡è®­ç»ƒç¥žç»ç½‘ç»œ**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `è¿‘ä¼¼æ¨¡åž‹é¢„æµ‹æŽ§åˆ¶` `è´å¶æ–¯ä¼˜åŒ–` `ç¥žç»ç½‘ç»œ` `å‚æ•°è°ƒä¼˜` `æœºå™¨äººæŽ§åˆ¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»ŸAMPCåœ¨MPCå‚æ•°è°ƒæ•´åŽéœ€é‡æ–°è®­ç»ƒç¥žç»ç½‘ç»œï¼Œè€—æ—¶ä¸”ä½Žæ•ˆï¼Œé™åˆ¶äº†å…¶åœ¨å®žé™…éƒ¨ç½²ä¸­çš„åº”ç”¨ã€‚
2. åˆ©ç”¨è´å¶æ–¯ä¼˜åŒ–è‡ªåŠ¨è°ƒæ•´AMPCç­–ç•¥å‚æ•°ï¼Œç»“åˆæ¨¡åž‹æŽ§åˆ¶ä¸Žå±€éƒ¨å­¦ä¹ ï¼Œå®žçŽ°æ•°æ®é«˜æ•ˆçš„å‚æ•°ä¼˜åŒ–ã€‚
3. ç¡¬ä»¶å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨å€’ç«‹æ‘†å’Œå¹³è¡¡ç‹¬è½®è½¦æŽ§åˆ¶ä¸Šä¼˜äºŽä¼ ç»ŸAMPCï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘ä¼¼æ¨¡åž‹é¢„æµ‹æŽ§åˆ¶(AMPC)æ—¨åœ¨ç”¨ç¥žç»ç½‘ç»œæ¨¡ä»¿MPCçš„è¡Œä¸ºï¼Œä»Žè€Œé¿å…åœ¨è¿è¡Œæ—¶æ±‚è§£æ˜‚è´µçš„ä¼˜åŒ–é—®é¢˜ã€‚ç„¶è€Œï¼Œåœ¨éƒ¨ç½²æœŸé—´ï¼Œé€šå¸¸éœ€è¦å¯¹åº•å±‚MPCçš„å‚æ•°è¿›è¡Œå¾®è°ƒã€‚è¿™ä½¿å¾—AMPCåœ¨å®žè·µä¸­å˜å¾—ä¸åˆ‡å®žé™…ï¼Œå› ä¸ºå®ƒéœ€è¦é‡å¤ç”Ÿæˆæ–°çš„æ•°æ®é›†å¹¶é‡æ–°è®­ç»ƒç¥žç»ç½‘ç»œã€‚æœ€è¿‘çš„ç ”ç©¶é€šè¿‡ä½¿ç”¨MPCä¼˜åŒ–é—®é¢˜çš„è¿‘ä¼¼æ•æ„Ÿæ€§æ¥è°ƒæ•´AMPCï¼Œè€Œæ— éœ€é‡æ–°è®­ç»ƒã€‚ç›®å‰ï¼Œè¿™ç§è°ƒæ•´å¿…é¡»æ‰‹åŠ¨å®Œæˆï¼Œè¿™æ—¢è´¹åŠ›ï¼Œå¯¹äºŽé«˜ç»´ç³»ç»Ÿæ¥è¯´ä¹Ÿå¯èƒ½ä¸ç›´è§‚ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–æ¥æ ¹æ®å®žéªŒæ•°æ®è°ƒæ•´AMPCç­–ç•¥çš„å‚æ•°ã€‚é€šè¿‡å°†åŸºäºŽæ¨¡åž‹çš„æŽ§åˆ¶ä¸Žç›´æŽ¥å’Œå±€éƒ¨å­¦ä¹ ç›¸ç»“åˆï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ç¡¬ä»¶ä¸Šå®žçŽ°äº†ä¼˜äºŽæ ‡ç§°AMPCçš„æ€§èƒ½ï¼Œå¹¶ä¸”åªéœ€æœ€å°‘çš„å®žéªŒã€‚è¿™å…è®¸AMPCè‡ªåŠ¨ä¸”æ•°æ®é«˜æ•ˆåœ°é€‚åº”æ–°çš„ç³»ç»Ÿå®žä¾‹ï¼Œå¹¶å¾®è°ƒéš¾ä»¥ç›´æŽ¥åœ¨MPCä¸­å®žçŽ°çš„æˆæœ¬å‡½æ•°ã€‚æˆ‘ä»¬åœ¨å€’ç«‹æ‘†å°è½¦ä¸Šçš„æ‘†åŠ¨æ“ä½œå’Œæ¬ é©±åŠ¨å¹³è¡¡ç‹¬è½®è½¦æœºå™¨äººçš„åèˆªæŽ§åˆ¶ï¼ˆä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„æŽ§åˆ¶é—®é¢˜ï¼‰çš„ç¡¬ä»¶å®žéªŒä¸­å±•ç¤ºäº†æ‰€æå‡ºçš„æ–¹æ³•ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰çš„è¿‘ä¼¼æ¨¡åž‹é¢„æµ‹æŽ§åˆ¶(AMPC)æ–¹æ³•åœ¨å®žé™…éƒ¨ç½²ä¸­ï¼Œå½“åº•å±‚MPCçš„å‚æ•°éœ€è¦è°ƒæ•´æ—¶ï¼Œéœ€è¦é‡æ–°ç”Ÿæˆæ•°æ®é›†å¹¶é‡æ–°è®­ç»ƒç¥žç»ç½‘ç»œï¼Œè¿™ä½¿å¾—AMPCçš„éƒ¨ç½²å’Œç»´æŠ¤æˆæœ¬å¾ˆé«˜ï¼Œé™åˆ¶äº†å…¶åº”ç”¨èŒƒå›´ã€‚æ‰‹åŠ¨è°ƒæ•´AMPCç­–ç•¥å‚æ•°æ—¢è´¹æ—¶åˆå®¹æ˜“å‡ºé”™ï¼Œå°¤å…¶æ˜¯åœ¨é«˜ç»´ç³»ç»Ÿä¸­ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è´å¶æ–¯ä¼˜åŒ–(Bayesian Optimization)æ¥è‡ªåŠ¨è°ƒæ•´AMPCç­–ç•¥çš„å‚æ•°ï¼Œè€Œæ— éœ€é‡æ–°è®­ç»ƒç¥žç»ç½‘ç»œã€‚è´å¶æ–¯ä¼˜åŒ–æ˜¯ä¸€ç§é«˜æ•ˆçš„å…¨å±€ä¼˜åŒ–ç®—æ³•ï¼Œç‰¹åˆ«é€‚ç”¨äºŽç›®æ ‡å‡½æ•°è¯„ä¼°æˆæœ¬é«˜æ˜‚çš„æƒ…å†µã€‚é€šè¿‡å°†æ¨¡åž‹é¢„æµ‹æŽ§åˆ¶ä¸Žç›´æŽ¥å’Œå±€éƒ¨å­¦ä¹ ç›¸ç»“åˆï¼Œå¯ä»¥å®žçŽ°æ•°æ®é«˜æ•ˆçš„å‚æ•°è°ƒæ•´ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šè¯¥æ–¹æ³•çš„æŠ€æœ¯æ¡†æž¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1) åˆå§‹åŒ–AMPCç­–ç•¥ï¼›2) åœ¨å®žé™…ç³»ç»Ÿä¸­è¿è¡ŒAMPCç­–ç•¥å¹¶æ”¶é›†å®žéªŒæ•°æ®ï¼›3) ä½¿ç”¨å®žéªŒæ•°æ®æž„å»ºç›®æ ‡å‡½æ•°ï¼Œè¯¥ç›®æ ‡å‡½æ•°åæ˜ äº†AMPCç­–ç•¥çš„æ€§èƒ½ï¼›4) ä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–ç®—æ³•ä¼˜åŒ–AMPCç­–ç•¥çš„å‚æ•°ï¼Œä»¥æœ€å¤§åŒ–ç›®æ ‡å‡½æ•°ï¼›5) é‡å¤æ­¥éª¤2-4ï¼Œç›´åˆ°AMPCç­–ç•¥çš„æ€§èƒ½è¾¾åˆ°æœŸæœ›æ°´å¹³ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽå°†è´å¶æ–¯ä¼˜åŒ–åº”ç”¨äºŽAMPCç­–ç•¥çš„å‚æ•°è°ƒæ•´ï¼Œä»Žè€Œå®žçŽ°äº†è‡ªåŠ¨ã€æ•°æ®é«˜æ•ˆçš„å‚æ•°ä¼˜åŒ–ï¼Œé¿å…äº†é‡æ–°è®­ç»ƒç¥žç»ç½‘ç»œçš„éœ€è¦ã€‚ä¸Žæ‰‹åŠ¨è°ƒæ•´å‚æ•°ç›¸æ¯”ï¼Œè´å¶æ–¯ä¼˜åŒ–å¯ä»¥æ›´æœ‰æ•ˆåœ°æŽ¢ç´¢å‚æ•°ç©ºé—´ï¼Œæ‰¾åˆ°æ›´ä¼˜çš„å‚æ•°ç»„åˆã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•ç»“åˆäº†æ¨¡åž‹é¢„æµ‹æŽ§åˆ¶å’Œç›´æŽ¥å­¦ä¹ ï¼Œå¯ä»¥å……åˆ†åˆ©ç”¨å…ˆéªŒçŸ¥è¯†å’Œå®žéªŒæ•°æ®ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è´å¶æ–¯ä¼˜åŒ–ä¸­ï¼Œéœ€è¦é€‰æ‹©åˆé€‚çš„ä»£ç†æ¨¡åž‹(surrogate model)å’Œé‡‡é›†å‡½æ•°(acquisition function)ã€‚æœ¬æ–‡å¯èƒ½é‡‡ç”¨äº†é«˜æ–¯è¿‡ç¨‹(Gaussian Process)ä½œä¸ºä»£ç†æ¨¡åž‹ï¼Œå¹¶ä½¿ç”¨æœŸæœ›æå‡(Expected Improvement)æˆ–ç½®ä¿¡ä¸Šé™(Upper Confidence Bound)ä½œä¸ºé‡‡é›†å‡½æ•°ã€‚ç›®æ ‡å‡½æ•°çš„è®¾è®¡éœ€è¦æ ¹æ®å…·ä½“çš„æŽ§åˆ¶ä»»åŠ¡è¿›è¡Œè°ƒæ•´ï¼Œä¾‹å¦‚ï¼Œå¯ä»¥é‡‡ç”¨è·Ÿè¸ªè¯¯å·®ã€æŽ§åˆ¶è¾“å…¥èƒ½é‡ç­‰æŒ‡æ ‡ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

è¯¥è®ºæ–‡åœ¨å€’ç«‹æ‘†å°è½¦å’Œå¹³è¡¡ç‹¬è½®è½¦çš„ç¡¬ä»¶å®žéªŒä¸­éªŒè¯äº†æ‰€æå‡ºæ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨ç¡¬ä»¶ä¸Šå®žçŽ°äº†ä¼˜äºŽæ ‡ç§°AMPCçš„æ€§èƒ½ï¼Œå¹¶ä¸”åªéœ€æœ€å°‘çš„å®žéªŒã€‚å…·ä½“æ¥è¯´ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿè‡ªåŠ¨è°ƒæ•´AMPCç­–ç•¥çš„å‚æ•°ï¼Œä½¿å…¶é€‚åº”æ–°çš„ç³»ç»Ÿå®žä¾‹ï¼Œå¹¶å¾®è°ƒéš¾ä»¥ç›´æŽ¥åœ¨MPCä¸­å®žçŽ°çš„æˆæœ¬å‡½æ•°ã€‚è¿™äº›å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•å…·æœ‰å¾ˆå¼ºçš„å®žç”¨ä»·å€¼ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯å¹¿æ³›åº”ç”¨äºŽæœºå™¨äººæŽ§åˆ¶ã€è‡ªåŠ¨é©¾é©¶ã€è¿‡ç¨‹æŽ§åˆ¶ç­‰é¢†åŸŸã€‚é€šè¿‡è‡ªåŠ¨è°ƒæ•´AMPCç­–ç•¥å‚æ•°ï¼Œå¯ä»¥ä½¿ç³»ç»Ÿå¿«é€Ÿé€‚åº”æ–°çš„çŽ¯å¢ƒå’Œä»»åŠ¡ï¼Œæé«˜æŽ§åˆ¶æ€§èƒ½å’Œé²æ£’æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºŽå¾®è°ƒéš¾ä»¥ç›´æŽ¥åœ¨MPCä¸­å®žçŽ°çš„æˆæœ¬å‡½æ•°ï¼Œä¾‹å¦‚ï¼Œè€ƒè™‘èƒ½è€—ã€ç£¨æŸç­‰å› ç´ çš„æˆæœ¬å‡½æ•°ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›åº”ç”¨äºŽæ›´å¤æ‚çš„æŽ§åˆ¶ç³»ç»Ÿï¼Œä¾‹å¦‚ï¼Œå¤šæœºå™¨äººååŒæŽ§åˆ¶ã€æ™ºèƒ½äº¤é€šç³»ç»Ÿç­‰ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Approximate model-predictive control (AMPC) aims to imitate an MPC's behavior with a neural network, removing the need to solve an expensive optimization problem at runtime. However, during deployment, the parameters of the underlying MPC must usually be fine-tuned. This often renders AMPC impractical as it requires repeatedly generating a new dataset and retraining the neural network. Recent work addresses this problem by adapting AMPC without retraining using approximated sensitivities of the MPC's optimization problem. Currently, this adaption must be done by hand, which is labor-intensive and can be unintuitive for high-dimensional systems. To solve this issue, we propose using Bayesian optimization to tune the parameters of AMPC policies based on experimental data. By combining model-based control with direct and local learning, our approach achieves superior performance to nominal AMPC on hardware, with minimal experimentation. This allows automatic and data-efficient adaptation of AMPC to new system instances and fine-tuning to cost functions that are difficult to directly implement in MPC. We demonstrate the proposed method in hardware experiments for the swing-up maneuver on an inverted cartpole and yaw control of an under-actuated balancing unicycle robot, a challenging control problem.

