---
layout: default
title: Fine-Tuning of Neural Network Approximate MPC without Retraining via Bayesian Optimization
---

# Fine-Tuning of Neural Network Approximate MPC without Retraining via Bayesian Optimization

**arXiv**: [2512.14350v1](https://arxiv.org/abs/2512.14350) | [PDF](https://arxiv.org/pdf/2512.14350.pdf)

**ä½œè€…**: Henrik Hose, Paul Brunzema, Alexander von Rohr, Alexander GrÃ¤fe, Angela P. Schoellig, Sebastian Trimpe

**åˆ†ç±»**: cs.RO, eess.SY

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽè´å¶æ–¯ä¼˜åŒ–çš„ç¥žç»è¿‘ä¼¼MPCè°ƒå‚æ–¹æ³•ï¼Œæ— éœ€é‡è®­ç»ƒç½‘ç»œã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `è¿‘ä¼¼æ¨¡åž‹é¢„æµ‹æŽ§åˆ¶` `è´å¶æ–¯ä¼˜åŒ–` `ç¥žç»ç½‘ç»œ` `è‡ªé€‚åº”æŽ§åˆ¶` `æœºå™¨äººæŽ§åˆ¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»ŸAMPCåœ¨MPCå‚æ•°è°ƒæ•´åŽéœ€é‡æ–°è®­ç»ƒç½‘ç»œï¼Œæˆæœ¬é«˜æ˜‚ä¸”æ•ˆçŽ‡ä½Žä¸‹ï¼Œé™åˆ¶äº†å…¶åœ¨å®žé™…éƒ¨ç½²ä¸­çš„åº”ç”¨ã€‚
2. è¯¥è®ºæ–‡æå‡ºåˆ©ç”¨è´å¶æ–¯ä¼˜åŒ–è‡ªåŠ¨è°ƒæ•´AMPCç­–ç•¥å‚æ•°ï¼Œæ— éœ€é‡æ–°è®­ç»ƒç½‘ç»œï¼Œå®žçŽ°æ•°æ®é«˜æ•ˆçš„è‡ªé€‚åº”æŽ§åˆ¶ã€‚
3. å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨å€’ç«‹æ‘†å’Œå¹³è¡¡ç‹¬è½®è½¦ç­‰ç¡¬ä»¶å¹³å°ä¸Šï¼Œæ€§èƒ½ä¼˜äºŽä¼ ç»ŸAMPCï¼Œä¸”å®žéªŒæˆæœ¬æ›´ä½Žã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘ä¼¼æ¨¡åž‹é¢„æµ‹æŽ§åˆ¶ï¼ˆAMPCï¼‰æ—¨åœ¨ç”¨ç¥žç»ç½‘ç»œæ¨¡ä»¿MPCçš„è¡Œä¸ºï¼Œä»Žè€Œé¿å…åœ¨è¿è¡Œæ—¶æ±‚è§£æ˜‚è´µçš„ä¼˜åŒ–é—®é¢˜ã€‚ç„¶è€Œï¼Œåœ¨éƒ¨ç½²æœŸé—´ï¼Œé€šå¸¸éœ€è¦å¾®è°ƒåº•å±‚MPCçš„å‚æ•°ã€‚è¿™ä½¿å¾—AMPCä¸åˆ‡å®žé™…ï¼Œå› ä¸ºå®ƒéœ€è¦é‡å¤ç”Ÿæˆæ–°çš„æ•°æ®é›†å¹¶é‡æ–°è®­ç»ƒç¥žç»ç½‘ç»œã€‚æœ€è¿‘çš„ç ”ç©¶é€šè¿‡ä½¿ç”¨MPCä¼˜åŒ–é—®é¢˜çš„è¿‘ä¼¼æ•æ„Ÿæ€§æ¥è°ƒæ•´AMPCï¼Œè€Œæ— éœ€é‡æ–°è®­ç»ƒã€‚ç›®å‰ï¼Œè¿™ç§è°ƒæ•´å¿…é¡»æ‰‹åŠ¨å®Œæˆï¼Œè¿™æ—¢è´¹åŠ›åˆéš¾ä»¥ç†è§£é«˜ç»´ç³»ç»Ÿã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–æ¥æ ¹æ®å®žéªŒæ•°æ®è°ƒæ•´AMPCç­–ç•¥çš„å‚æ•°ã€‚é€šè¿‡å°†åŸºäºŽæ¨¡åž‹çš„æŽ§åˆ¶ä¸Žç›´æŽ¥å’Œå±€éƒ¨å­¦ä¹ ç›¸ç»“åˆï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ç¡¬ä»¶ä¸Šå®žçŽ°äº†ä¼˜äºŽæ ‡ç§°AMPCçš„æ€§èƒ½ï¼Œä¸”åªéœ€æœ€å°‘çš„å®žéªŒã€‚è¿™å…è®¸AMPCè‡ªåŠ¨ä¸”æ•°æ®é«˜æ•ˆåœ°é€‚åº”æ–°çš„ç³»ç»Ÿå®žä¾‹ï¼Œå¹¶å¾®è°ƒéš¾ä»¥åœ¨MPCä¸­ç›´æŽ¥å®žçŽ°çš„æˆæœ¬å‡½æ•°ã€‚æˆ‘ä»¬åœ¨å€’ç«‹æ‘†å°è½¦ä¸Šçš„æ‘†åŠ¨æ“ä½œå’Œæ¬ é©±åŠ¨å¹³è¡¡ç‹¬è½®è½¦æœºå™¨äººçš„åèˆªæŽ§åˆ¶ï¼ˆä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„æŽ§åˆ¶é—®é¢˜ï¼‰çš„ç¡¬ä»¶å®žéªŒä¸­å±•ç¤ºäº†æ‰€æå‡ºçš„æ–¹æ³•ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰çš„è¿‘ä¼¼æ¨¡åž‹é¢„æµ‹æŽ§åˆ¶ï¼ˆAMPCï¼‰æ–¹æ³•åœ¨åº•å±‚MPCå‚æ•°å‘ç”Ÿå˜åŒ–æ—¶ï¼Œéœ€è¦é‡æ–°æ”¶é›†æ•°æ®å¹¶è®­ç»ƒç¥žç»ç½‘ç»œï¼Œè¿™å¯¼è‡´éƒ¨ç½²å’Œç»´æŠ¤æˆæœ¬é«˜æ˜‚ï¼Œé™åˆ¶äº†AMPCçš„å®žé™…åº”ç”¨ã€‚æ‰‹åŠ¨è°ƒæ•´AMPCç­–ç•¥å‚æ•°æ—¢è´¹æ—¶åˆå®¹æ˜“å‡ºé”™ï¼Œå°¤å…¶æ˜¯åœ¨é«˜ç»´ç³»ç»Ÿä¸­ï¼Œéš¾ä»¥èŽ·å¾—ä»¤äººæ»¡æ„çš„æ€§èƒ½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè¯¥è®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è´å¶æ–¯ä¼˜åŒ–ï¼ˆBayesian Optimizationï¼‰ç®—æ³•ï¼Œæ ¹æ®å®žéªŒæ•°æ®è‡ªåŠ¨è°ƒæ•´AMPCç­–ç•¥çš„å‚æ•°ï¼Œè€Œæ— éœ€é‡æ–°è®­ç»ƒç¥žç»ç½‘ç»œã€‚è´å¶æ–¯ä¼˜åŒ–èƒ½å¤Ÿæœ‰æ•ˆåœ°æŽ¢ç´¢å‚æ•°ç©ºé—´ï¼Œæ‰¾åˆ°æœ€ä¼˜çš„å‚æ•°ç»„åˆï¼Œä»Žè€Œä½¿AMPCé€‚åº”æ–°çš„ç³»ç»Ÿå®žä¾‹å’Œæˆæœ¬å‡½æ•°ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šè¯¥æ–¹æ³•çš„æŠ€æœ¯æ¡†æž¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1. åˆå§‹åŒ–AMPCç­–ç•¥ï¼›2. åœ¨å®žé™…ç³»ç»Ÿä¸­è¿›è¡Œå°‘é‡å®žéªŒï¼Œæ”¶é›†æ•°æ®ï¼›3. ä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–ç®—æ³•ï¼Œæ ¹æ®å®žéªŒæ•°æ®è°ƒæ•´AMPCç­–ç•¥çš„å‚æ•°ï¼›4. è¯„ä¼°è°ƒæ•´åŽçš„AMPCç­–ç•¥çš„æ€§èƒ½ï¼›5. å¦‚æžœæ€§èƒ½æœªè¾¾åˆ°è¦æ±‚ï¼Œåˆ™é‡å¤æ­¥éª¤2-4ï¼Œç›´åˆ°æ‰¾åˆ°æœ€ä¼˜çš„å‚æ•°ç»„åˆã€‚è´å¶æ–¯ä¼˜åŒ–ç®—æ³•ä½¿ç”¨é«˜æ–¯è¿‡ç¨‹ä½œä¸ºä»£ç†æ¨¡åž‹ï¼Œç”¨äºŽä¼°è®¡ç›®æ ‡å‡½æ•°çš„åŽéªŒåˆ†å¸ƒï¼Œå¹¶ä½¿ç”¨é‡‡é›†å‡½æ•°ï¼ˆAcquisition Functionï¼‰æ¥é€‰æ‹©ä¸‹ä¸€ä¸ªè¦å®žéªŒçš„å‚æ•°ç»„åˆã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽå°†è´å¶æ–¯ä¼˜åŒ–åº”ç”¨äºŽAMPCç­–ç•¥çš„å‚æ•°è°ƒæ•´ï¼Œå®žçŽ°äº†è‡ªåŠ¨ã€æ•°æ®é«˜æ•ˆçš„è‡ªé€‚åº”æŽ§åˆ¶ã€‚ä¸Žä¼ ç»Ÿçš„AMPCæ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•æ— éœ€é‡æ–°è®­ç»ƒç¥žç»ç½‘ç»œï¼Œå¤§å¤§é™ä½Žäº†éƒ¨ç½²å’Œç»´æŠ¤æˆæœ¬ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºŽå¾®è°ƒéš¾ä»¥åœ¨MPCä¸­ç›´æŽ¥å®žçŽ°çš„æˆæœ¬å‡½æ•°ã€‚

**å…³é”®è®¾è®¡**ï¼šè´å¶æ–¯ä¼˜åŒ–ä¸­çš„é«˜æ–¯è¿‡ç¨‹æ ¸å‡½æ•°é€‰æ‹©ã€é‡‡é›†å‡½æ•°ç±»åž‹ã€å®žéªŒæ•°æ®çš„æ”¶é›†ç­–ç•¥ç­‰éƒ½ä¼šå½±å“æœ€ç»ˆçš„ä¼˜åŒ–æ•ˆæžœã€‚è®ºæ–‡ä¸­å¯èƒ½æ¶‰åŠäº†è¿™äº›å…³é”®å‚æ•°çš„è®¾è®¡ä¸Žé€‰æ‹©ï¼Œä½†å…·ä½“ç»†èŠ‚æœªçŸ¥ã€‚æ­¤å¤–ï¼ŒAMPCç­–ç•¥çš„å…·ä½“ç½‘ç»œç»“æž„ã€æŸå¤±å‡½æ•°ç­‰ä¹Ÿæ˜¯é‡è¦çš„è®¾è®¡å› ç´ ï¼Œä½†è®ºæ–‡æ‘˜è¦ä¸­æœªæåŠã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

è¯¥è®ºæ–‡åœ¨å€’ç«‹æ‘†å°è½¦å’Œå¹³è¡¡ç‹¬è½®è½¦ä¸¤ä¸ªç¡¬ä»¶å¹³å°ä¸Šè¿›è¡Œäº†å®žéªŒéªŒè¯ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒåŸºäºŽè´å¶æ–¯ä¼˜åŒ–çš„AMPCæ–¹æ³•åœ¨æ‘†åŠ¨æ“ä½œå’ŒåèˆªæŽ§åˆ¶ä»»åŠ¡ä¸­ï¼Œæ€§èƒ½ä¼˜äºŽä¼ ç»Ÿçš„AMPCæ–¹æ³•ã€‚å…·ä½“æ€§èƒ½æå‡æ•°æ®å’Œå¯¹æ¯”åŸºçº¿æœªçŸ¥ï¼Œä½†å¼ºè°ƒäº†è¯¥æ–¹æ³•åªéœ€æœ€å°‘çš„å®žéªŒå³å¯å®žçŽ°ä¼˜è¶Šçš„æ€§èƒ½ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯å¹¿æ³›åº”ç”¨äºŽæœºå™¨äººæŽ§åˆ¶ã€è‡ªåŠ¨åŒ–ç”Ÿäº§çº¿ã€æ™ºèƒ½äº¤é€šç³»ç»Ÿç­‰é¢†åŸŸã€‚é€šè¿‡è‡ªåŠ¨è°ƒæ•´æŽ§åˆ¶ç­–ç•¥å‚æ•°ï¼Œå¯ä»¥ä½¿ç³»ç»Ÿå¿«é€Ÿé€‚åº”æ–°çš„çŽ¯å¢ƒå’Œä»»åŠ¡ï¼Œæé«˜ç³»ç»Ÿçš„é²æ£’æ€§å’Œé€‚åº”æ€§ã€‚è¯¥æ–¹æ³•å°¤å…¶é€‚ç”¨äºŽéœ€è¦é¢‘ç¹è°ƒæ•´æŽ§åˆ¶å‚æ•°çš„å¤æ‚ç³»ç»Ÿï¼Œä¾‹å¦‚æ— äººé©¾é©¶è½¦è¾†ã€æŸ”æ€§åˆ¶é€ ç³»ç»Ÿç­‰ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›ä¸Žå¼ºåŒ–å­¦ä¹ ç­‰æŠ€æœ¯ç›¸ç»“åˆï¼Œå®žçŽ°æ›´é«˜çº§åˆ«çš„è‡ªä¸»æŽ§åˆ¶ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Approximate model-predictive control (AMPC) aims to imitate an MPC's behavior with a neural network, removing the need to solve an expensive optimization problem at runtime. However, during deployment, the parameters of the underlying MPC must usually be fine-tuned. This often renders AMPC impractical as it requires repeatedly generating a new dataset and retraining the neural network. Recent work addresses this problem by adapting AMPC without retraining using approximated sensitivities of the MPC's optimization problem. Currently, this adaption must be done by hand, which is labor-intensive and can be unintuitive for high-dimensional systems. To solve this issue, we propose using Bayesian optimization to tune the parameters of AMPC policies based on experimental data. By combining model-based control with direct and local learning, our approach achieves superior performance to nominal AMPC on hardware, with minimal experimentation. This allows automatic and data-efficient adaptation of AMPC to new system instances and fine-tuning to cost functions that are difficult to directly implement in MPC. We demonstrate the proposed method in hardware experiments for the swing-up maneuver on an inverted cartpole and yaw control of an under-actuated balancing unicycle robot, a challenging control problem.

