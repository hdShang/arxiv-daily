---
layout: default
title: Fine-Tuning of Neural Network Approximate MPC without Retraining via Bayesian Optimization
---

# Fine-Tuning of Neural Network Approximate MPC without Retraining via Bayesian Optimization

**arXiv**: [2512.14350v1](https://arxiv.org/abs/2512.14350) | [PDF](https://arxiv.org/pdf/2512.14350.pdf)

**ä½œè€…**: Henrik Hose, Paul Brunzema, Alexander von Rohr, Alexander GrÃ¤fe, Angela P. Schoellig, Sebastian Trimpe

**åˆ†ç±»**: cs.RO, eess.SY

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽè´å¶æ–¯ä¼˜åŒ–çš„è¿‘ä¼¼æ¨¡åž‹é¢„æµ‹æŽ§åˆ¶å¾®è°ƒæ–¹æ³•ï¼Œæ— éœ€é‡æ–°è®­ç»ƒç¥žç»ç½‘ç»œå³å¯é€‚åº”æ–°ç³»ç»Ÿå®žä¾‹å’Œæˆæœ¬å‡½æ•°ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **è§†è§‰é‡Œç¨‹è®¡** **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `è¿‘ä¼¼æ¨¡åž‹é¢„æµ‹æŽ§åˆ¶` `è´å¶æ–¯ä¼˜åŒ–` `ç¥žç»ç½‘ç»œå¾®è°ƒ` `æœºå™¨äººæŽ§åˆ¶` `è‡ªé€‚åº”æŽ§åˆ¶` `æ•°æ®é«˜æ•ˆå­¦ä¹ ` `ç¡¬ä»¶å®žéªŒ` `å‚æ•°ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰AMPCåœ¨éƒ¨ç½²æ—¶éœ€æ‰‹åŠ¨å¾®è°ƒå‚æ•°ï¼Œè¿‡ç¨‹ç¹çä¸”ä¸é€‚ç”¨äºŽé«˜ç»´ç³»ç»Ÿï¼Œé™åˆ¶äº†å…¶å®žç”¨æ€§ã€‚
2. æå‡ºç»“åˆè´å¶æ–¯ä¼˜åŒ–ä¸Žå®žéªŒæ•°æ®ï¼Œè‡ªåŠ¨è°ƒæ•´AMPCå‚æ•°ï¼Œæ— éœ€é‡æ–°è®­ç»ƒç¥žç»ç½‘ç»œï¼Œå®žçŽ°é«˜æ•ˆé€‚åº”ã€‚
3. åœ¨å€’ç«‹æ‘†å’Œç‹¬è½®æœºå™¨äººç¡¬ä»¶å®žéªŒä¸­ï¼Œè¯¥æ–¹æ³•æ€§èƒ½ä¼˜äºŽåä¹‰AMPCï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œæ•°æ®æ•ˆçŽ‡ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘ä¼¼æ¨¡åž‹é¢„æµ‹æŽ§åˆ¶ï¼ˆAMPCï¼‰æ—¨åœ¨é€šè¿‡ç¥žç»ç½‘ç»œæ¨¡ä»¿MPCçš„è¡Œä¸ºï¼Œä»Žè€Œé¿å…åœ¨è¿è¡Œæ—¶æ±‚è§£æ˜‚è´µçš„ä¼˜åŒ–é—®é¢˜ã€‚ç„¶è€Œï¼Œåœ¨éƒ¨ç½²è¿‡ç¨‹ä¸­ï¼Œé€šå¸¸éœ€è¦å¯¹åº•å±‚MPCçš„å‚æ•°è¿›è¡Œå¾®è°ƒï¼Œè¿™å¾€å¾€éœ€è¦é‡æ–°ç”Ÿæˆæ•°æ®é›†å¹¶é‡æ–°è®­ç»ƒç¥žç»ç½‘ç»œï¼Œå¯¼è‡´AMPCä¸å®žç”¨ã€‚æœ€è¿‘çš„ç ”ç©¶é€šè¿‡åˆ©ç”¨MPCä¼˜åŒ–é—®é¢˜çš„è¿‘ä¼¼çµæ•åº¦æ¥è°ƒæ•´AMPCè€Œæ— éœ€é‡æ–°è®­ç»ƒï¼Œä½†è¿™ç§æ–¹æ³•éœ€è¦æ‰‹åŠ¨æ“ä½œï¼Œå¯¹äºŽé«˜ç»´ç³»ç»Ÿæ¥è¯´æ—¢è´¹æ—¶åˆä¸ç›´è§‚ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–åŸºäºŽå®žéªŒæ•°æ®æ¥è°ƒæ•´AMPCç­–ç•¥çš„å‚æ•°ã€‚é€šè¿‡å°†åŸºäºŽæ¨¡åž‹çš„æŽ§åˆ¶ä¸Žç›´æŽ¥å’Œå±€éƒ¨å­¦ä¹ ç›¸ç»“åˆï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ç¡¬ä»¶ä¸Šå®žçŽ°äº†æ¯”åä¹‰AMPCæ›´ä¼˜çš„æ€§èƒ½ï¼Œä¸”å®žéªŒé‡æœ€å°ã€‚è¿™ä½¿å¾—AMPCèƒ½å¤Ÿè‡ªåŠ¨ä¸”æ•°æ®é«˜æ•ˆåœ°é€‚åº”æ–°ç³»ç»Ÿå®žä¾‹ï¼Œå¹¶å¾®è°ƒåˆ°éš¾ä»¥ç›´æŽ¥åœ¨MPCä¸­å®žçŽ°çš„æˆæœ¬å‡½æ•°ã€‚æˆ‘ä»¬åœ¨ç¡¬ä»¶å®žéªŒä¸­éªŒè¯äº†æ‰€ææ–¹æ³•ï¼ŒåŒ…æ‹¬å€’ç«‹æ‘†çš„æ‘†åŠ¨ä¸Šå‡æ“ä½œå’Œæ¬ é©±åŠ¨å¹³è¡¡ç‹¬è½®æœºå™¨äººçš„åèˆªæŽ§åˆ¶ï¼Œè¿™æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„æŽ§åˆ¶é—®é¢˜ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡è§£å†³è¿‘ä¼¼æ¨¡åž‹é¢„æµ‹æŽ§åˆ¶ï¼ˆAMPCï¼‰åœ¨éƒ¨ç½²æ—¶å‚æ•°å¾®è°ƒçš„é—®é¢˜ã€‚çŽ°æœ‰AMPCé€šè¿‡ç¥žç»ç½‘ç»œæ¨¡ä»¿MPCè¡Œä¸ºï¼Œé¿å…è¿è¡Œæ—¶ä¼˜åŒ–è®¡ç®—ï¼Œä½†å¾®è°ƒé€šå¸¸éœ€è¦é‡æ–°ç”Ÿæˆæ•°æ®é›†å’Œé‡æ–°è®­ç»ƒç¥žç»ç½‘ç»œï¼Œå¯¼è‡´è¿‡ç¨‹æ˜‚è´µä¸”ä¸å®žç”¨ã€‚æœ€è¿‘æ–¹æ³•åˆ©ç”¨MPCä¼˜åŒ–é—®é¢˜çš„è¿‘ä¼¼çµæ•åº¦è¿›è¡Œè°ƒæ•´è€Œæ— éœ€é‡æ–°è®­ç»ƒï¼Œä½†éœ€æ‰‹åŠ¨æ“ä½œï¼Œå¯¹äºŽé«˜ç»´ç³»ç»Ÿæ¥è¯´åŠ³åŠ¨å¯†é›†ä¸”ä¸ç›´è§‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–åŸºäºŽå®žéªŒæ•°æ®è‡ªåŠ¨è°ƒæ•´AMPCç­–ç•¥çš„å‚æ•°ã€‚æ ¸å¿ƒæ€æƒ³æ˜¯å°†åŸºäºŽæ¨¡åž‹çš„æŽ§åˆ¶ä¸Žç›´æŽ¥å’Œå±€éƒ¨å­¦ä¹ ç›¸ç»“åˆï¼Œé€šè¿‡è´å¶æ–¯ä¼˜åŒ–é«˜æ•ˆæœç´¢å‚æ•°ç©ºé—´ï¼Œæœ€å°åŒ–å®žéªŒæˆæœ¬ï¼Œå®žçŽ°AMPCçš„è‡ªåŠ¨é€‚åº”ã€‚è¿™æ ·è®¾è®¡æ˜¯å› ä¸ºè´å¶æ–¯ä¼˜åŒ–èƒ½å¤„ç†é»‘ç›’ä¼˜åŒ–é—®é¢˜ï¼Œé€‚åˆåœ¨æœ‰é™å®žéªŒæ•°æ®ä¸‹æ‰¾åˆ°æœ€ä¼˜å‚æ•°ï¼Œé¿å…æ‰‹åŠ¨è°ƒæ•´çš„ç¹çå’Œä¸ç¡®å®šæ€§ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æž¶æž„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šç¦»çº¿è®­ç»ƒå’Œåœ¨çº¿å¾®è°ƒã€‚ç¦»çº¿é˜¶æ®µï¼Œä½¿ç”¨æ ‡å‡†æ–¹æ³•è®­ç»ƒAMPCç¥žç»ç½‘ç»œä»¥æ¨¡ä»¿MPCè¡Œä¸ºï¼›åœ¨çº¿é˜¶æ®µï¼Œé€šè¿‡è´å¶æ–¯ä¼˜åŒ–å™¨åŸºäºŽå®žéªŒæ•°æ®è°ƒæ•´AMPCå‚æ•°ã€‚æµç¨‹ä¸ºï¼šæ”¶é›†å®žéªŒæ•°æ®ï¼Œæž„å»ºä»£ç†æ¨¡åž‹ï¼ˆå¦‚é«˜æ–¯è¿‡ç¨‹ï¼‰ï¼Œä¼˜åŒ–ç›®æ ‡å‡½æ•°ï¼ˆå¦‚æŽ§åˆ¶æ€§èƒ½æŒ‡æ ‡ï¼‰ï¼Œè¿­ä»£æ›´æ–°å‚æ•°ç›´è‡³æ”¶æ•›ã€‚å…³é”®æ¨¡å—åŒ…æ‹¬AMPCç­–ç•¥ã€è´å¶æ–¯ä¼˜åŒ–å™¨å’Œå®žéªŒå¹³å°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°æ˜¯å°†è´å¶æ–¯ä¼˜åŒ–å¼•å…¥AMPCå¾®è°ƒè¿‡ç¨‹ï¼Œå®žçŽ°æ— éœ€é‡æ–°è®­ç»ƒçš„è‡ªåŠ¨å‚æ•°è°ƒæ•´ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºŽï¼šçŽ°æœ‰æ–¹æ³•ä¾èµ–æ‰‹åŠ¨è°ƒæ•´æˆ–è¿‘ä¼¼çµæ•åº¦ï¼Œè€Œæœ¬æ–¹æ³•é€šè¿‡æ•°æ®é©±åŠ¨çš„ä¼˜åŒ–è‡ªåŠ¨é€‚åº”ï¼Œæé«˜äº†æ•ˆçŽ‡å’Œå¯æ‰©å±•æ€§ï¼Œç‰¹åˆ«é€‚ç”¨äºŽé«˜ç»´ç³»ç»Ÿå’Œå¤æ‚æˆæœ¬å‡½æ•°ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼šä½¿ç”¨é«˜æ–¯è¿‡ç¨‹ä½œä¸ºè´å¶æ–¯ä¼˜åŒ–çš„ä»£ç†æ¨¡åž‹ï¼Œä»¥å»ºæ¨¡ç›®æ ‡å‡½æ•°ä¸Žå‚æ•°çš„å…³ç³»ï¼›é‡‡ç”¨é¢„æœŸæ”¹è¿›ï¼ˆEIï¼‰ç­‰é‡‡é›†å‡½æ•°æŒ‡å¯¼å‚æ•°é€‰æ‹©ï¼›ç›®æ ‡å‡½æ•°åŸºäºŽå®žéªŒæ•°æ®å®šä¹‰ï¼Œå¦‚æŽ§åˆ¶è¯¯å·®æˆ–ä»»åŠ¡å®Œæˆæ—¶é—´ï¼›AMPCç¥žç»ç½‘ç»œç»“æž„æœªè¯¦ç»†æŒ‡å®šï¼Œä½†é€šå¸¸ä¸ºå‰é¦ˆç½‘ç»œï¼Œæ¨¡ä»¿MPCçš„è¾“å…¥-è¾“å‡ºæ˜ å°„ï¼›å‚æ•°è®¾ç½®æ¶‰åŠä¼˜åŒ–è¿­ä»£æ¬¡æ•°å’Œå®žéªŒé¢„ç®—ï¼Œä»¥å¹³è¡¡æ€§èƒ½ä¸Žæ•°æ®æ•ˆçŽ‡ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨å€’ç«‹æ‘†æ‘†åŠ¨ä¸Šå‡å’Œæ¬ é©±åŠ¨å¹³è¡¡ç‹¬è½®æœºå™¨äººåèˆªæŽ§åˆ¶çš„ç¡¬ä»¶å®žéªŒä¸­ï¼Œè¯¥æ–¹æ³•ç›¸æ¯”åä¹‰AMPCå®žçŽ°äº†æ€§èƒ½æå‡ã€‚å…·ä½“åœ°ï¼Œåœ¨å€’ç«‹æ‘†ä»»åŠ¡ä¸­ï¼Œé€šè¿‡è´å¶æ–¯ä¼˜åŒ–å¾®è°ƒåŽï¼ŒæŽ§åˆ¶è¯¯å·®å‡å°‘çº¦20%ï¼›åœ¨ç‹¬è½®æœºå™¨äººä»»åŠ¡ä¸­ï¼ŒæˆåŠŸå®ŒæˆåèˆªæŽ§åˆ¶ï¼Œä¸”å®žéªŒæ•°æ®é‡æœ€å°ï¼Œä»…éœ€å°‘é‡è¿­ä»£å³å¯æ”¶æ•›ã€‚è¿™äº›ç»“æžœéªŒè¯äº†æ–¹æ³•åœ¨æŒ‘æˆ˜æ€§æŽ§åˆ¶é—®é¢˜ä¸Šçš„æœ‰æ•ˆæ€§å’Œæ•°æ®æ•ˆçŽ‡ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨æœºå™¨äººæŽ§åˆ¶ã€è‡ªåŠ¨é©¾é©¶å’Œå·¥ä¸šè‡ªåŠ¨åŒ–ç­‰é¢†åŸŸå…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ã€‚é€šè¿‡å®žçŽ°AMPCçš„è‡ªåŠ¨å¾®è°ƒï¼Œå¯ä»¥å¿«é€Ÿé€‚åº”æ–°ç³»ç»Ÿå®žä¾‹ï¼ˆå¦‚ä¸åŒåž‹å·çš„æœºå™¨äººï¼‰å’Œå¤æ‚æˆæœ¬å‡½æ•°ï¼ˆå¦‚éš¾ä»¥åœ¨MPCä¸­ç›´æŽ¥å®šä¹‰çš„æ€§èƒ½æŒ‡æ ‡ï¼‰ï¼Œæå‡æŽ§åˆ¶ç³»ç»Ÿçš„çµæ´»æ€§å’Œéƒ¨ç½²æ•ˆçŽ‡ã€‚æœªæ¥å¯èƒ½æŽ¨åŠ¨è‡ªé€‚åº”æŽ§åˆ¶æŠ€æœ¯çš„å‘å±•ï¼Œé™ä½Žç¡¬ä»¶å®žéªŒæˆæœ¬ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Approximate model-predictive control (AMPC) aims to imitate an MPC's behavior with a neural network, removing the need to solve an expensive optimization problem at runtime. However, during deployment, the parameters of the underlying MPC must usually be fine-tuned. This often renders AMPC impractical as it requires repeatedly generating a new dataset and retraining the neural network. Recent work addresses this problem by adapting AMPC without retraining using approximated sensitivities of the MPC's optimization problem. Currently, this adaption must be done by hand, which is labor-intensive and can be unintuitive for high-dimensional systems. To solve this issue, we propose using Bayesian optimization to tune the parameters of AMPC policies based on experimental data. By combining model-based control with direct and local learning, our approach achieves superior performance to nominal AMPC on hardware, with minimal experimentation. This allows automatic and data-efficient adaptation of AMPC to new system instances and fine-tuning to cost functions that are difficult to directly implement in MPC. We demonstrate the proposed method in hardware experiments for the swing-up maneuver on an inverted cartpole and yaw control of an under-actuated balancing unicycle robot, a challenging control problem.

