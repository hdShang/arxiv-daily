---
layout: default
title: Fine-Tuning of Neural Network Approximate MPC without Retraining via Bayesian Optimization
---

# Fine-Tuning of Neural Network Approximate MPC without Retraining via Bayesian Optimization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.14350" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.14350v1</a>
  <a href="https://arxiv.org/pdf/2512.14350.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14350v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.14350v1', 'Fine-Tuning of Neural Network Approximate MPC without Retraining via Bayesian Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Henrik Hose, Paul Brunzema, Alexander von Rohr, Alexander GrÃ¤fe, Angela P. Schoellig, Sebastian Trimpe

**åˆ†ç±»**: cs.RO, eess.SY

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºè´å¶æ–¯ä¼˜åŒ–çš„ç¥ç»è¿‘ä¼¼MPCè°ƒå‚æ–¹æ³•ï¼Œæ— éœ€é‡è®­ç»ƒç½‘ç»œã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `è¿‘ä¼¼æ¨¡å‹é¢„æµ‹æ§åˆ¶` `ç¥ç»è¿‘ä¼¼MPC` `è´å¶æ–¯ä¼˜åŒ–` `å‚æ•°è°ƒä¼˜` `æœºå™¨äººæ§åˆ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»ŸAMPCåœ¨MPCå‚æ•°è°ƒæ•´åéœ€é‡æ–°è®­ç»ƒç½‘ç»œï¼Œæˆæœ¬é«˜æ˜‚ï¼Œé™åˆ¶äº†å…¶åº”ç”¨ã€‚
2. åˆ©ç”¨è´å¶æ–¯ä¼˜åŒ–è‡ªåŠ¨è°ƒæ•´AMPCç­–ç•¥å‚æ•°ï¼Œæ— éœ€é‡æ–°è®­ç»ƒï¼Œæå‡æ•°æ®æ•ˆç‡ã€‚
3. ç¡¬ä»¶å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºä¼ ç»ŸAMPCï¼Œå¹¶èƒ½é€‚åº”æ–°çš„ç³»ç»Ÿå®ä¾‹å’Œæˆæœ¬å‡½æ•°ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘ä¼¼æ¨¡å‹é¢„æµ‹æ§åˆ¶(AMPC)æ—¨åœ¨ç”¨ç¥ç»ç½‘ç»œæ¨¡ä»¿MPCçš„è¡Œä¸ºï¼Œä»è€Œé¿å…åœ¨è¿è¡Œæ—¶æ±‚è§£æ˜‚è´µçš„ä¼˜åŒ–é—®é¢˜ã€‚ç„¶è€Œï¼Œåœ¨éƒ¨ç½²æœŸé—´ï¼Œé€šå¸¸éœ€è¦å¾®è°ƒåº•å±‚MPCçš„å‚æ•°ã€‚è¿™ä½¿å¾—AMPCä¸åˆ‡å®é™…ï¼Œå› ä¸ºå®ƒéœ€è¦é‡å¤ç”Ÿæˆæ–°æ•°æ®é›†å¹¶é‡æ–°è®­ç»ƒç¥ç»ç½‘ç»œã€‚æœ€è¿‘çš„å·¥ä½œé€šè¿‡ä½¿ç”¨MPCä¼˜åŒ–é—®é¢˜çš„è¿‘ä¼¼æ•æ„Ÿæ€§æ¥è°ƒæ•´AMPCï¼Œè€Œæ— éœ€é‡æ–°è®­ç»ƒã€‚ç›®å‰ï¼Œè¿™ç§è°ƒæ•´å¿…é¡»æ‰‹åŠ¨å®Œæˆï¼Œè¿™æ—¢è´¹åŠ›åˆéš¾ä»¥ç†è§£é«˜ç»´ç³»ç»Ÿã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–æ¥æ ¹æ®å®éªŒæ•°æ®è°ƒæ•´AMPCç­–ç•¥çš„å‚æ•°ã€‚é€šè¿‡å°†åŸºäºæ¨¡å‹çš„æ§åˆ¶ä¸ç›´æ¥å’Œå±€éƒ¨å­¦ä¹ ç›¸ç»“åˆï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ç¡¬ä»¶ä¸Šå®ç°äº†ä¼˜äºæ ‡ç§°AMPCçš„æ€§èƒ½ï¼Œä¸”åªéœ€æœ€å°‘çš„å®éªŒã€‚è¿™å…è®¸AMPCè‡ªåŠ¨ä¸”æ•°æ®é«˜æ•ˆåœ°é€‚åº”æ–°çš„ç³»ç»Ÿå®ä¾‹ï¼Œå¹¶å¾®è°ƒéš¾ä»¥åœ¨MPCä¸­ç›´æ¥å®ç°çš„æˆæœ¬å‡½æ•°ã€‚æˆ‘ä»¬åœ¨å€’ç«‹æ‘†å°è½¦ä¸Šçš„æ‘†åŠ¨æ“ä½œå’Œæ¬ é©±åŠ¨å¹³è¡¡ç‹¬è½®è½¦æœºå™¨äººçš„åèˆªæ§åˆ¶ï¼ˆä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„æ§åˆ¶é—®é¢˜ï¼‰çš„ç¡¬ä»¶å®éªŒä¸­å±•ç¤ºäº†æ‰€æå‡ºçš„æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šAMPCæ—¨åœ¨é€šè¿‡ç¥ç»ç½‘ç»œè¿‘ä¼¼MPCï¼Œä»¥é™ä½åœ¨çº¿è®¡ç®—æˆæœ¬ã€‚ç„¶è€Œï¼Œå½“åº•å±‚MPCçš„å‚æ•°éœ€è¦è°ƒæ•´æ—¶ï¼ˆä¾‹å¦‚ï¼Œé€‚åº”æ–°çš„ç³»ç»Ÿæˆ–ä¼˜åŒ–ç›®æ ‡ï¼‰ï¼Œä¼ ç»Ÿçš„AMPCæ–¹æ³•éœ€è¦é‡æ–°ç”Ÿæˆè®­ç»ƒæ•°æ®å¹¶é‡æ–°è®­ç»ƒç¥ç»ç½‘ç»œï¼Œè¿™ä½¿å¾—AMPCçš„éƒ¨ç½²å’Œç»´æŠ¤æˆæœ¬å¾ˆé«˜ï¼Œå°¤å…¶æ˜¯åœ¨å®é™…åº”ç”¨ä¸­ï¼ŒMPCå‚æ•°çš„è°ƒæ•´æ˜¯ä¸å¯é¿å…çš„ã€‚ç°æœ‰æ–¹æ³•éœ€è¦æ‰‹åŠ¨è°ƒæ•´ï¼Œåœ¨é«˜ç»´ç³»ç»Ÿä¸­éš¾ä»¥æ“ä½œã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è´å¶æ–¯ä¼˜åŒ–(Bayesian Optimization, BO)æ¥è‡ªåŠ¨è°ƒæ•´AMPCç­–ç•¥çš„å‚æ•°ï¼Œè€Œæ— éœ€é‡æ–°è®­ç»ƒç¥ç»ç½‘ç»œã€‚BOæ˜¯ä¸€ç§é«˜æ•ˆçš„å…¨å±€ä¼˜åŒ–ç®—æ³•ï¼Œç‰¹åˆ«é€‚ç”¨äºç›®æ ‡å‡½æ•°è¯„ä¼°æˆæœ¬é«˜æ˜‚çš„æƒ…å†µã€‚é€šè¿‡å°†AMPCçš„å‚æ•°è°ƒæ•´è§†ä¸ºä¸€ä¸ªé»‘ç›’ä¼˜åŒ–é—®é¢˜ï¼ŒBOèƒ½å¤Ÿåˆ©ç”¨å®éªŒæ•°æ®æ¥å­¦ä¹ ç›®æ ‡å‡½æ•°çš„å…ˆéªŒçŸ¥è¯†ï¼Œå¹¶æŒ‡å¯¼åç»­çš„å‚æ•°æœç´¢ï¼Œä»è€Œåœ¨å°‘é‡å®éªŒä¸­æ‰¾åˆ°æœ€ä¼˜çš„å‚æ•°é…ç½®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1. åˆå§‹åŒ–ï¼šä½¿ç”¨åˆå§‹çš„AMPCç­–ç•¥å’ŒMPCå‚æ•°ã€‚2. å®éªŒï¼šåœ¨å®é™…ç³»ç»Ÿä¸­è¿è¡ŒAMPCç­–ç•¥ï¼Œå¹¶æ”¶é›†å®éªŒæ•°æ®ï¼ˆä¾‹å¦‚ï¼ŒçŠ¶æ€ã€æ§åˆ¶è¾“å…¥ã€æˆæœ¬ç­‰ï¼‰ã€‚3. è´å¶æ–¯ä¼˜åŒ–ï¼šä½¿ç”¨å®éªŒæ•°æ®æ¥æ„å»ºç›®æ ‡å‡½æ•°çš„ä»£ç†æ¨¡å‹ï¼ˆä¾‹å¦‚ï¼Œé«˜æ–¯è¿‡ç¨‹ï¼‰ï¼Œå¹¶åˆ©ç”¨é‡‡é›†å‡½æ•°ï¼ˆä¾‹å¦‚ï¼ŒæœŸæœ›æ”¹è¿›ï¼‰æ¥é€‰æ‹©ä¸‹ä¸€ä¸ªè¦è¯„ä¼°çš„å‚æ•°é…ç½®ã€‚4. å‚æ•°æ›´æ–°ï¼šä½¿ç”¨é€‰å®šçš„å‚æ•°é…ç½®æ¥æ›´æ–°AMPCç­–ç•¥çš„å‚æ•°ã€‚5. è¿­ä»£ï¼šé‡å¤æ­¥éª¤2-4ï¼Œç›´åˆ°è¾¾åˆ°é¢„å®šçš„è¿­ä»£æ¬¡æ•°æˆ–æ”¶æ•›æ¡ä»¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†è´å¶æ–¯ä¼˜åŒ–åº”ç”¨äºAMPCçš„å‚æ•°è°ƒæ•´ï¼Œä»è€Œå®ç°äº†è‡ªåŠ¨ã€æ•°æ®é«˜æ•ˆçš„AMPCé€‚åº”ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•æ— éœ€æ‰‹åŠ¨è°ƒæ•´å‚æ•°ï¼Œä¹Ÿæ— éœ€é‡æ–°è®­ç»ƒç¥ç»ç½‘ç»œï¼Œå¤§å¤§é™ä½äº†AMPCçš„éƒ¨ç½²å’Œç»´æŠ¤æˆæœ¬ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥é€‚åº”éš¾ä»¥åœ¨MPCä¸­ç›´æ¥å®ç°çš„æˆæœ¬å‡½æ•°ï¼Œä»è€Œæ‰©å±•äº†AMPCçš„åº”ç”¨èŒƒå›´ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1. ç›®æ ‡å‡½æ•°ï¼šç›®æ ‡å‡½æ•°å®šä¹‰äº†AMPCç­–ç•¥çš„æ€§èƒ½æŒ‡æ ‡ï¼Œä¾‹å¦‚ï¼Œè·Ÿè¸ªè¯¯å·®ã€æ§åˆ¶èƒ½é‡ç­‰ã€‚2. ä»£ç†æ¨¡å‹ï¼šä»£ç†æ¨¡å‹ç”¨äºè¿‘ä¼¼ç›®æ ‡å‡½æ•°ï¼Œä¾‹å¦‚ï¼Œé«˜æ–¯è¿‡ç¨‹ã€‚3. é‡‡é›†å‡½æ•°ï¼šé‡‡é›†å‡½æ•°ç”¨äºé€‰æ‹©ä¸‹ä¸€ä¸ªè¦è¯„ä¼°çš„å‚æ•°é…ç½®ï¼Œä¾‹å¦‚ï¼ŒæœŸæœ›æ”¹è¿›ã€‚4. å‚æ•°åŒ–æ–¹æ³•ï¼šå¦‚ä½•å°†MPCçš„å‚æ•°æ˜ å°„åˆ°AMPCç­–ç•¥çš„å‚æ•°ç©ºé—´ï¼Œä»¥ä¾¿è´å¶æ–¯ä¼˜åŒ–èƒ½å¤Ÿæœ‰æ•ˆåœ°æœç´¢æœ€ä¼˜å‚æ•°é…ç½®ã€‚è®ºæ–‡ä¸­ä½¿ç”¨äº†è¿‘ä¼¼æ•æ„Ÿåº¦æ–¹æ³•æ¥å»ºç«‹è¿™ç§æ˜ å°„å…³ç³»ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å€’ç«‹æ‘†å°è½¦å’Œæ¬ é©±åŠ¨å¹³è¡¡ç‹¬è½®è½¦çš„ç¡¬ä»¶å®éªŒä¸­ï¼Œè¯¥æ–¹æ³•å®ç°äº†ä¼˜äºæ ‡ç§°AMPCçš„æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°è°ƒæ•´AMPCç­–ç•¥çš„å‚æ•°ï¼Œä½¿å…¶é€‚åº”æ–°çš„ç³»ç»Ÿå®ä¾‹å’Œæˆæœ¬å‡½æ•°ã€‚é€šè¿‡æœ€å°‘çš„å®éªŒï¼Œè¯¥æ–¹æ³•å®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¯æ˜äº†å…¶æ•°æ®æ•ˆç‡å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºæœºå™¨äººæ§åˆ¶ã€è‡ªåŠ¨é©¾é©¶ã€è¿‡ç¨‹æ§åˆ¶ç­‰é¢†åŸŸã€‚é€šè¿‡è‡ªåŠ¨è°ƒæ•´AMPCç­–ç•¥å‚æ•°ï¼Œå¯ä»¥ä½¿ç³»ç»Ÿæ›´å¥½åœ°é€‚åº”ä¸åŒçš„ç¯å¢ƒå’Œä»»åŠ¡ï¼Œæé«˜æ§åˆ¶æ€§èƒ½å’Œé²æ£’æ€§ã€‚è¯¥æ–¹æ³•å°¤å…¶é€‚ç”¨äºéœ€è¦é¢‘ç¹è°ƒæ•´æ§åˆ¶å‚æ•°çš„å¤æ‚ç³»ç»Ÿï¼Œä¾‹å¦‚ï¼Œåœ¨åŠ¨æ€ç¯å¢ƒä¸­è¿è¡Œçš„æœºå™¨äººæˆ–éœ€è¦ä¼˜åŒ–èƒ½æºæ•ˆç‡çš„è¿‡ç¨‹æ§åˆ¶ç³»ç»Ÿã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›è¿›ä¸€æ­¥æ‰©å±•åˆ°å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå’Œåˆ†å¸ƒå¼æ§åˆ¶ç­‰é¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Approximate model-predictive control (AMPC) aims to imitate an MPC's behavior with a neural network, removing the need to solve an expensive optimization problem at runtime. However, during deployment, the parameters of the underlying MPC must usually be fine-tuned. This often renders AMPC impractical as it requires repeatedly generating a new dataset and retraining the neural network. Recent work addresses this problem by adapting AMPC without retraining using approximated sensitivities of the MPC's optimization problem. Currently, this adaption must be done by hand, which is labor-intensive and can be unintuitive for high-dimensional systems. To solve this issue, we propose using Bayesian optimization to tune the parameters of AMPC policies based on experimental data. By combining model-based control with direct and local learning, our approach achieves superior performance to nominal AMPC on hardware, with minimal experimentation. This allows automatic and data-efficient adaptation of AMPC to new system instances and fine-tuning to cost functions that are difficult to directly implement in MPC. We demonstrate the proposed method in hardware experiments for the swing-up maneuver on an inverted cartpole and yaw control of an under-actuated balancing unicycle robot, a challenging control problem.

