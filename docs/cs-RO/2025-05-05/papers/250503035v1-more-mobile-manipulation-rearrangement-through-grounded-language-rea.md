---
layout: default
title: "MORE: Mobile Manipulation Rearrangement Through Grounded Language Reasoning"
---

# MORE: Mobile Manipulation Rearrangement Through Grounded Language Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.03035" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.03035v1</a>
  <a href="https://arxiv.org/pdf/2505.03035.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.03035v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.03035v1', 'MORE: Mobile Manipulation Rearrangement Through Grounded Language Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mohammad Mohammadi, Daniel Honerkamp, Martin BÃ¼chner, Matteo Cassinelli, Tim Welschehold, Fabien Despinoy, Igor Gilitschenski, Abhinav Valada

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-05-05

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMOREä»¥è§£å†³é•¿è·ç¦»ç§»åŠ¨æ“æ§ä¸­çš„é‡æ’é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç§»åŠ¨æ“æ§` `é‡æ’ä»»åŠ¡` `åœºæ™¯å›¾` `å®ä¾‹åŒºåˆ†` `ä¸»åŠ¨è¿‡æ»¤` `æœºå™¨äººè§„åˆ’` `åŸºç¡€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤§é‡ç‰©ä½“å’Œå¤§è§„æ¨¡ç¯å¢ƒæ—¶æ€§èƒ½ä¸‹é™ï¼Œéš¾ä»¥åº”å¯¹å¤æ‚çš„ç§»åŠ¨æ“æ§ä»»åŠ¡ã€‚
2. MOREé€šè¿‡åœºæ™¯å›¾è¡¨ç¤ºç¯å¢ƒï¼Œç»“åˆå®ä¾‹åŒºåˆ†å’Œä¸»åŠ¨è¿‡æ»¤æœºåˆ¶ï¼Œæå‡äº†è¯­è¨€æ¨¡å‹åœ¨é‡æ’ä»»åŠ¡ä¸­çš„èƒ½åŠ›ã€‚
3. åœ¨81ä¸ªå¤šæ ·åŒ–çš„é‡æ’ä»»åŠ¡ä¸­ï¼ŒMOREé¦–æ¬¡æˆåŠŸè§£å†³äº†æ˜¾è‘—æ¯”ä¾‹çš„ä»»åŠ¡ï¼Œè¶…è¶Šäº†ç°æœ‰åŸºå‡†æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è‡ªä¸»é•¿è·ç¦»ç§»åŠ¨æ“æ§é¢ä¸´åœºæ™¯åŠ¨æ€ã€æœªæ¢ç´¢åŒºåŸŸå’Œé”™è¯¯æ¢å¤ç­‰å¤šé‡æŒ‘æˆ˜ã€‚å°½ç®¡è¿‘æœŸç ”ç©¶åˆ©ç”¨åŸºç¡€æ¨¡å‹è¿›è¡Œåœºæ™¯çº§æœºå™¨äººæ¨ç†ä¸è§„åˆ’ï¼Œä½†åœ¨å¤„ç†å¤§é‡ç‰©ä½“å’Œå¤§è§„æ¨¡ç¯å¢ƒæ—¶ï¼Œæ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºMOREï¼Œä¸€ç§å¢å¼ºè¯­è¨€æ¨¡å‹èƒ½åŠ›ä»¥è§£å†³é›¶æ ·æœ¬ç§»åŠ¨æ“æ§è§„åˆ’çš„é‡æ’ä»»åŠ¡çš„æ–°æ–¹æ³•ã€‚MOREåˆ©ç”¨åœºæ™¯å›¾è¡¨ç¤ºç¯å¢ƒï¼Œç»“åˆå®ä¾‹åŒºåˆ†ï¼Œå¹¶å¼•å…¥ä¸»åŠ¨è¿‡æ»¤æœºåˆ¶æå–ä»»åŠ¡ç›¸å…³çš„å­å›¾ï¼Œä»è€Œæœ‰æ•ˆå‡è½»å¹»è§‰ç°è±¡å¹¶æé«˜å¯é æ€§ã€‚æˆ‘ä»¬åœ¨BEHAVIOR-1KåŸºå‡†ä¸Šè¯„ä¼°MOREï¼Œé¦–æ¬¡æˆåŠŸè§£å†³äº†å¤§é‡é‡æ’ä»»åŠ¡ï¼Œè¶…è¶Šäº†è¿‘æœŸçš„åŸºç¡€æ¨¡å‹æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³é•¿è·ç¦»ç§»åŠ¨æ“æ§ä¸­çš„é‡æ’ä»»åŠ¡ï¼Œç°æœ‰æ–¹æ³•åœ¨é¢å¯¹å¤æ‚åœºæ™¯æ—¶å®¹æ˜“å‡ºç°æ€§èƒ½ä¸‹é™å’Œé”™è¯¯æ¢å¤å›°éš¾çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMOREé€šè¿‡å¼•å…¥åœºæ™¯å›¾ã€å®ä¾‹åŒºåˆ†å’Œä¸»åŠ¨è¿‡æ»¤æœºåˆ¶ï¼Œä¼˜åŒ–äº†ä»»åŠ¡ç›¸å…³ä¿¡æ¯çš„æå–ï¼Œè¿›è€Œæå‡äº†ç§»åŠ¨æ“æ§çš„è§„åˆ’èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMOREçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ç¯å¢ƒçš„åœºæ™¯å›¾è¡¨ç¤ºã€å®ä¾‹åŒºåˆ†æ¨¡å—å’Œä¸»åŠ¨è¿‡æ»¤æœºåˆ¶ï¼Œå½¢æˆä¸€ä¸ªæœ‰ç•Œçš„è§„åˆ’é—®é¢˜ï¼Œå‡å°‘äº†ä¸å¿…è¦çš„è®¡ç®—å’Œé”™è¯¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šMOREçš„ä¸»è¦åˆ›æ–°åœ¨äºé€šè¿‡åœºæ™¯å›¾å’Œä¸»åŠ¨è¿‡æ»¤æœºåˆ¶æœ‰æ•ˆå‡è½»äº†å¹»è§‰ç°è±¡ï¼Œæå‡äº†è§„åˆ’çš„å¯é æ€§ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”å…·æœ‰æ˜¾è‘—çš„æ€§èƒ½ä¼˜åŠ¿ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒMOREé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–å®ä¾‹åŒºåˆ†ï¼Œå¹¶é€šè¿‡å‚æ•°è°ƒèŠ‚å®ç°äº†å¯¹ä¸åŒç¯å¢ƒçš„é€‚åº”æ€§ï¼Œç¡®ä¿äº†åœ¨å®¤å†…å¤–ç¯å¢ƒä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨81ä¸ªé‡æ’ä»»åŠ¡çš„è¯„ä¼°ä¸­ï¼ŒMOREæˆåŠŸè§£å†³äº†æ˜¾è‘—æ¯”ä¾‹çš„ä»»åŠ¡ï¼Œè¶…è¶Šäº†æœ€æ–°çš„åŸºç¡€æ¨¡å‹æ–¹æ³•ï¼Œå±•ç¤ºäº†åœ¨å¤æ‚åœºæ™¯ä¸‹çš„ä¼˜è¶Šæ€§èƒ½ï¼Œæå‡å¹…åº¦æ˜æ˜¾ï¼Œæ ‡å¿—ç€ç§»åŠ¨æ“æ§é¢†åŸŸçš„é‡è¦è¿›å±•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MOREçš„ç ”ç©¶æˆæœåœ¨å®¶åº­æœåŠ¡æœºå™¨äººã€ä»“å‚¨è‡ªåŠ¨åŒ–å’Œæ™ºèƒ½äº¤é€šç³»ç»Ÿç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æå‡æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„è‡ªä¸»é‡æ’èƒ½åŠ›ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ»¡è¶³äººä»¬çš„æ—¥å¸¸éœ€æ±‚ï¼Œæå‡ç”Ÿæ´»è´¨é‡å’Œå·¥ä½œæ•ˆç‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Autonomous long-horizon mobile manipulation encompasses a multitude of challenges, including scene dynamics, unexplored areas, and error recovery. Recent works have leveraged foundation models for scene-level robotic reasoning and planning. However, the performance of these methods degrades when dealing with a large number of objects and large-scale environments. To address these limitations, we propose MORE, a novel approach for enhancing the capabilities of language models to solve zero-shot mobile manipulation planning for rearrangement tasks. MORE leverages scene graphs to represent environments, incorporates instance differentiation, and introduces an active filtering scheme that extracts task-relevant subgraphs of object and region instances. These steps yield a bounded planning problem, effectively mitigating hallucinations and improving reliability. Additionally, we introduce several enhancements that enable planning across both indoor and outdoor environments. We evaluate MORE on 81 diverse rearrangement tasks from the BEHAVIOR-1K benchmark, where it becomes the first approach to successfully solve a significant share of the benchmark, outperforming recent foundation model-based approaches. Furthermore, we demonstrate the capabilities of our approach in several complex real-world tasks, mimicking everyday activities. We make the code publicly available at https://more-model.cs.uni-freiburg.de.

