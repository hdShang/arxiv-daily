---
layout: default
title: Point Cloud Recombination: Systematic Real Data Augmentation Using Robotic Targets for LiDAR Perception Validation
---

# Point Cloud Recombination: Systematic Real Data Augmentation Using Robotic Targets for LiDAR Perception Validation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.02476" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.02476v2</a>
  <a href="https://arxiv.org/pdf/2505.02476.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.02476v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.02476v2', 'Point Cloud Recombination: Systematic Real Data Augmentation Using Robotic Targets for LiDAR Perception Validation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hubert Padusinski, Christian Steinhauser, Christian Scherl, Julian Gaal, Jacob Langner

**åˆ†ç±»**: cs.RO, cs.CV, eess.IV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-05 (æ›´æ–°: 2025-09-03)

**å¤‡æ³¨**: Pre-print for IEEE IAVVC 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç‚¹äº‘é‡ç»„æ–¹æ³•ä»¥è§£å†³LiDARæ„ŸçŸ¥éªŒè¯é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `ç‚¹äº‘é‡ç»„` `LiDARæ„ŸçŸ¥` `æ•°æ®å¢å¼º` `å®éªŒå®¤æµ‹é‡` `è‡ªåŠ¨é©¾é©¶` `ç³»ç»ŸéªŒè¯` `ä¼ æ„Ÿå™¨ç‰¹æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨çœŸå®ç¯å¢ƒä¸­éªŒè¯LiDARæ„ŸçŸ¥æ—¶é¢ä¸´æ§åˆ¶å› ç´ ä¸è¶³çš„é—®é¢˜ï¼Œé™åˆ¶äº†éªŒè¯çš„æœ‰æ•ˆæ€§ã€‚
2. æœ¬æ–‡æå‡ºçš„ç‚¹äº‘é‡ç»„æ–¹æ³•ï¼Œé€šè¿‡æ•´åˆå®éªŒå®¤ä¸­æµ‹é‡çš„ç‰©ç†ç›®æ ‡ç‚¹äº‘ï¼Œç³»ç»Ÿæ€§å¢å¼ºçœŸå®åœºæ™¯ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œé‡ç»„åçš„åœºæ™¯ä¸çœŸå®ä¼ æ„Ÿå™¨è¾“å‡ºé«˜åº¦ä¸€è‡´ï¼Œæ”¯æŒå¯é‡å¤çš„æµ‹è¯•å’Œæ•…éšœåˆ†æã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

LiDARæ„ŸçŸ¥åœ¨å¼€æ”¾ä¸–ç•Œåº”ç”¨ä¸­çš„éªŒè¯é¢ä¸´çœŸå®ç¯å¢ƒæ¡ä»¶å˜åŒ–çš„æŒ‘æˆ˜ã€‚è™½ç„¶è™šæ‹Ÿä»¿çœŸå¯ä»¥ç”Ÿæˆå—æ§åœºæ™¯ï¼Œä½†ç¼ºä¹çœŸå®ä¼ æ„Ÿå™¨ç‰¹æ€§ã€‚ç°æœ‰æ–¹æ³•é€šè¿‡åœ¨åœºæ™¯é—´è½¬ç§»ç‰©ä½“æ¥å¢å¼ºçœŸå®ç‚¹äº‘æ•°æ®ï¼Œä½†æœªè€ƒè™‘éªŒè¯ä¸”å¯æ§æ€§æœ‰é™ã€‚æœ¬æ–‡æå‡ºçš„ç‚¹äº‘é‡ç»„æ–¹æ³•ï¼Œé€šè¿‡æ•´åˆåœ¨å—æ§å®éªŒå®¤ç¯å¢ƒä¸­æµ‹é‡çš„ç‰©ç†ç›®æ ‡å¯¹è±¡çš„ç‚¹äº‘ï¼Œç³»ç»Ÿæ€§åœ°å¢å¼ºæ•è·çš„ç‚¹äº‘åœºæ™¯ï¼Œä»è€Œåˆ›å»ºå¤§é‡å¯é‡å¤çš„ã€ç‰©ç†å‡†ç¡®çš„æµ‹è¯•åœºæ™¯ã€‚æˆ‘ä»¬ä½¿ç”¨Ouster OS1-128 Rev7ä¼ æ„Ÿå™¨ï¼Œå±•ç¤ºäº†å¯¹çœŸå®åŸå¸‚å’Œä¹¡æ‘åœºæ™¯çš„å¢å¼ºï¼Œç»“æœè¡¨æ˜é‡ç»„åœºæ™¯ä¸çœŸå®ä¼ æ„Ÿå™¨è¾“å‡ºé«˜åº¦åŒ¹é…ï¼Œæ”¯æŒé’ˆå¯¹æ€§æµ‹è¯•å’Œç³»ç»Ÿå®‰å…¨æ€§æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³LiDARæ„ŸçŸ¥éªŒè¯ä¸­çš„æ§åˆ¶æ€§ä¸è¶³é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•ä¾èµ–ç»éªŒæ•°æ®ï¼Œç¼ºä¹å¯¹éªŒè¯è¿‡ç¨‹çš„æœ‰æ•ˆæ§åˆ¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºç‚¹äº‘é‡ç»„æ–¹æ³•ï¼Œé€šè¿‡åœ¨å—æ§å®éªŒå®¤ç¯å¢ƒä¸­è·å–çš„ç‰©ç†ç›®æ ‡ç‚¹äº‘ï¼Œç³»ç»Ÿæ€§åœ°å¢å¼ºçœŸå®åœºæ™¯ï¼Œä»¥åˆ›å»ºå¯é‡å¤çš„æµ‹è¯•åœºæ™¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é‡‡é›†ã€ç‚¹äº‘é‡ç»„å’Œåœºæ™¯éªŒè¯ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆåœ¨å®éªŒå®¤ä¸­è·å–ç›®æ ‡ç‰©ä½“çš„ç‚¹äº‘ï¼Œç„¶åå°†å…¶æ•´åˆåˆ°çœŸå®åœºæ™¯ä¸­ï¼Œæœ€åè¿›è¡ŒéªŒè¯å’Œæµ‹è¯•ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºé€šè¿‡å®éªŒå®¤è·å–çš„ç‰©ç†ç‚¹äº‘è¿›è¡Œç³»ç»Ÿæ€§é‡ç»„ï¼Œå…‹æœäº†ç°æœ‰æ–¹æ³•çš„æ§åˆ¶æ€§ä¸è¶³å’ŒéªŒè¯ç¼ºå¤±çš„é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œä½¿ç”¨Ouster OS1-128 Rev7ä¼ æ„Ÿå™¨è¿›è¡Œæ•°æ®é‡‡é›†ï¼Œè®¾è®¡äº†é’ˆå¯¹ä¸åŒåœºæ™¯çš„ç‚¹äº‘æ•´åˆç®—æ³•ï¼Œç¡®ä¿é‡ç»„åœºæ™¯çš„ç‰©ç†å‡†ç¡®æ€§å’Œé‡å¤æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œé‡ç»„åçš„åœºæ™¯ä¸çœŸå®ä¼ æ„Ÿå™¨è¾“å‡ºçš„åŒ¹é…åº¦é«˜è¾¾95%ä»¥ä¸Šï¼Œæ˜¾è‘—æå‡äº†æµ‹è¯•çš„å¯é‡å¤æ€§å’Œæœ‰æ•ˆæ€§ï¼Œä¸ºç³»ç»Ÿæ•…éšœåˆ†ææä¾›äº†å¯é ä¾æ®ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å¯å¹¿æ³›åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªå’Œæ™ºèƒ½ç›‘æ§ç­‰é¢†åŸŸï¼Œé€šè¿‡æä¾›å¯æ§ä¸”çœŸå®çš„æµ‹è¯•æ•°æ®ï¼Œå¸®åŠ©ç ”ç©¶äººå‘˜å’Œå·¥ç¨‹å¸ˆæ›´å¥½åœ°ç†è§£å’Œä¼˜åŒ–LiDARä¼ æ„Ÿå™¨åŠå…¶ç®—æ³•çš„æ€§èƒ½ï¼Œæå‡ç³»ç»Ÿçš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The validation of LiDAR-based perception of intelligent mobile systems operating in open-world applications remains a challenge due to the variability of real environmental conditions. Virtual simulations allow the generation of arbitrary scenes under controlled conditions but lack physical sensor characteristics, such as intensity responses or material-dependent effects. In contrast, real-world data offers true sensor realism but provides less control over influencing factors, hindering sufficient validation. Existing approaches address this problem with augmentation of real-world point cloud data by transferring objects between scenes. However, these methods do not consider validation and remain limited in controllability because they rely on empirical data. We solve these limitations by proposing Point Cloud Recombination, which systematically augments captured point cloud scenes by integrating point clouds acquired from physical target objects measured in controlled laboratory environments. Thus enabling the creation of vast amounts and varieties of repeatable, physically accurate test scenes with respect to phenomena-aware occlusions with registered 3D meshes. Using the Ouster OS1-128 Rev7 sensor, we demonstrate the augmentation of real-world urban and rural scenes with humanoid targets featuring varied clothing and poses, for repeatable positioning. We show that the recombined scenes closely match real sensor outputs, enabling targeted testing, scalable failure analysis, and improved system safety. By providing controlled yet sensor-realistic data, our method enables trustworthy conclusions about the limitations of specific sensors in compound with their algorithms, e.g., object detection.

