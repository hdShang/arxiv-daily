---
layout: default
title: DPL: Depth-only Perceptive Humanoid Locomotion via Realistic Depth Synthesis and Cross-Attention Terrain Reconstruction
---

# DPL: Depth-only Perceptive Humanoid Locomotion via Realistic Depth Synthesis and Cross-Attention Terrain Reconstruction

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.07152" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.07152v2</a>
  <a href="https://arxiv.org/pdf/2510.07152.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.07152v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.07152v2', 'DPL: Depth-only Perceptive Humanoid Locomotion via Realistic Depth Synthesis and Cross-Attention Terrain Reconstruction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jingkai Sun, Gang Han, Pihai Sun, Wen Zhao, Jiahang Cao, Jiaxu Wang, Yijie Guo, Qiang Zhang

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-10-08 (æ›´æ–°: 2025-10-10)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDPLæ¡†æ¶ï¼Œé€šè¿‡æ·±åº¦ä¿¡æ¯å®ç°ç±»äººæœºå™¨äººåœ¨å¤æ‚åœ°å½¢ä¸Šçš„ç¨³å¥è¿åŠ¨**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `ç±»äººæœºå™¨äºº` `åœ°å½¢æ„ŸçŸ¥` `æ·±åº¦å­¦ä¹ ` `å¼ºåŒ–å­¦ä¹ ` `æ·±åº¦å›¾åƒåˆæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŸºäºæ·±åº¦å›¾åƒçš„ç«¯åˆ°ç«¯å­¦ä¹ æ–¹æ³•ï¼Œè®­ç»ƒæ•ˆç‡ä½ï¼Œä¸”å­˜åœ¨è¾ƒå¤§çš„æ¨¡æ‹Ÿåˆ°çœŸå®ä¸–ç•Œçš„å·®è·ã€‚
2. è¯¥è®ºæ–‡æå‡ºä¸€ç§æ–°æ¡†æ¶ï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„é«˜ç¨‹å›¾æ„ŸçŸ¥å¼•å¯¼å¼ºåŒ–å­¦ä¹ ï¼Œå¹¶ç»“åˆäº¤å‰æ³¨æ„åŠ›Transformeré‡å»ºåœ°å½¢ã€‚
3. é€šè¿‡é€¼çœŸçš„æ·±åº¦å›¾åƒåˆæˆæ–¹æ³•ï¼Œæœ‰æ•ˆé™ä½äº†åœ°å½¢é‡å»ºè¯¯å·®ï¼Œå¹¶åœ¨å…¨å°ºå¯¸ç±»äººæœºå™¨äººä¸ŠéªŒè¯äº†å…¶æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶ï¼Œç”¨äºå®ç°ä»…ä¾èµ–æ·±åº¦ä¿¡æ¯çš„ç±»äººæœºå™¨äººæ„ŸçŸ¥è¿åŠ¨ã€‚è¯¥æ¡†æ¶ç´§å¯†ç»“åˆäº†ä¸‰ä¸ªå…³é”®ç»„ä»¶ï¼šï¼ˆ1ï¼‰å…·æœ‰ç›²éª¨å¹²çš„åœ°å½¢æ„ŸçŸ¥è¿åŠ¨ç­–ç•¥ï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„åŸºäºé«˜ç¨‹å›¾çš„æ„ŸçŸ¥æ¥æŒ‡å¯¼å¼ºåŒ–å­¦ä¹ ï¼ŒåŒæ—¶æœ€å¤§é™åº¦åœ°å‡å°‘è§†è§‰è¾“å…¥ï¼›ï¼ˆ2ï¼‰å¤šæ¨¡æ€äº¤å‰æ³¨æ„åŠ›Transformerï¼Œä»å˜ˆæ‚çš„æ·±åº¦å›¾åƒä¸­é‡å»ºç»“æ„åŒ–çš„åœ°å½¢è¡¨ç¤ºï¼›ï¼ˆ3ï¼‰é€¼çœŸçš„æ·±åº¦å›¾åƒåˆæˆæ–¹æ³•ï¼Œé‡‡ç”¨è‡ªé®æŒ¡æ„ŸçŸ¥å…‰çº¿æŠ•å°„å’Œå™ªå£°æ„ŸçŸ¥å»ºæ¨¡æ¥åˆæˆé€¼çœŸçš„æ·±åº¦è§‚æµ‹ï¼Œä»è€Œå°†åœ°å½¢é‡å»ºè¯¯å·®é™ä½30ï¼…ä»¥ä¸Šã€‚è¿™ç§ç»„åˆèƒ½å¤Ÿåœ¨æœ‰é™çš„æ•°æ®å’Œç¡¬ä»¶èµ„æºä¸‹å®ç°é«˜æ•ˆçš„ç­–ç•¥è®­ç»ƒï¼ŒåŒæ—¶ä¿ç•™æ³›åŒ–æ‰€éœ€çš„å…³é”®åœ°å½¢ç‰¹å¾ã€‚æˆ‘ä»¬åœ¨å…¨å°ºå¯¸ç±»äººæœºå™¨äººä¸ŠéªŒè¯äº†è¯¥æ¡†æ¶ï¼Œå±•ç¤ºäº†å…¶åœ¨å„ç§å…·æœ‰æŒ‘æˆ˜æ€§çš„åœ°å½¢ä¸Šçš„æ•æ·å’Œè‡ªé€‚åº”è¿åŠ¨èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰ç±»äººæœºå™¨äººåœ°å½¢æ„ŸçŸ¥è¿åŠ¨æ–¹æ³•ä¸»è¦ä¾èµ–äºæ·±åº¦å›¾åƒæˆ–é«˜ç¨‹å›¾ã€‚åŸºäºæ·±åº¦å›¾åƒçš„ç«¯åˆ°ç«¯å­¦ä¹ æ–¹æ³•è®­ç»ƒæ•ˆç‡ä½ï¼Œä¸”å­˜åœ¨æ¨¡æ‹Ÿåˆ°çœŸå®ä¸–ç•Œçš„å·®è·ã€‚åŸºäºé«˜ç¨‹å›¾çš„æ–¹æ³•ä¾èµ–äºå¤šä¸ªè§†è§‰ä¼ æ„Ÿå™¨å’Œå®šä½ç³»ç»Ÿï¼Œå¯¼è‡´å»¶è¿Ÿå’Œé²æ£’æ€§é™ä½ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§æ›´é«˜æ•ˆã€æ›´é²æ£’çš„ä»…ä¾èµ–æ·±åº¦ä¿¡æ¯çš„ç±»äººæœºå™¨äººè¿åŠ¨æ–¹æ³•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè¯¥è®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨é€¼çœŸçš„æ·±åº¦å›¾åƒåˆæˆæ–¹æ³•ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼Œå¹¶ç»“åˆé¢„è®­ç»ƒçš„é«˜ç¨‹å›¾æ„ŸçŸ¥å’Œäº¤å‰æ³¨æ„åŠ›Transformerï¼Œå®ç°ä»…ä¾èµ–æ·±åº¦ä¿¡æ¯çš„ç±»äººæœºå™¨äººåœ°å½¢æ„ŸçŸ¥è¿åŠ¨ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå¯ä»¥å‡å°‘å¯¹çœŸå®æ•°æ®çš„ä¾èµ–ï¼Œæé«˜è®­ç»ƒæ•ˆç‡å’Œé²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…å«ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šï¼ˆ1ï¼‰åœ°å½¢æ„ŸçŸ¥è¿åŠ¨ç­–ç•¥ï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„é«˜ç¨‹å›¾æ„ŸçŸ¥ä½œä¸ºå…ˆéªŒçŸ¥è¯†ï¼ŒæŒ‡å¯¼å¼ºåŒ–å­¦ä¹ ï¼›ï¼ˆ2ï¼‰å¤šæ¨¡æ€äº¤å‰æ³¨æ„åŠ›Transformerï¼Œç”¨äºä»æ·±åº¦å›¾åƒä¸­é‡å»ºç»“æ„åŒ–çš„åœ°å½¢è¡¨ç¤ºï¼›ï¼ˆ3ï¼‰é€¼çœŸçš„æ·±åº¦å›¾åƒåˆæˆæ–¹æ³•ï¼Œç”¨äºç”Ÿæˆè®­ç»ƒæ•°æ®ã€‚æ•´ä½“æµç¨‹æ˜¯ï¼šé¦–å…ˆä½¿ç”¨æ·±åº¦å›¾åƒåˆæˆæ–¹æ³•ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼Œç„¶åä½¿ç”¨è¿™äº›æ•°æ®è®­ç»ƒåœ°å½¢æ„ŸçŸ¥è¿åŠ¨ç­–ç•¥å’Œäº¤å‰æ³¨æ„åŠ›Transformerï¼Œæœ€åå°†è®­ç»ƒå¥½çš„ç­–ç•¥éƒ¨ç½²åˆ°çœŸå®çš„ç±»äººæœºå™¨äººä¸Šã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼šï¼ˆ1ï¼‰æå‡ºäº†ä¸€ç§é€¼çœŸçš„æ·±åº¦å›¾åƒåˆæˆæ–¹æ³•ï¼Œå¯ä»¥æœ‰æ•ˆå‡å°‘æ¨¡æ‹Ÿåˆ°çœŸå®ä¸–ç•Œçš„å·®è·ï¼›ï¼ˆ2ï¼‰æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€äº¤å‰æ³¨æ„åŠ›Transformerï¼Œå¯ä»¥ä»å˜ˆæ‚çš„æ·±åº¦å›¾åƒä¸­é‡å»ºç»“æ„åŒ–çš„åœ°å½¢è¡¨ç¤ºï¼›ï¼ˆ3ï¼‰å°†é¢„è®­ç»ƒçš„é«˜ç¨‹å›¾æ„ŸçŸ¥ä¸å¼ºåŒ–å­¦ä¹ ç›¸ç»“åˆï¼Œæé«˜äº†è®­ç»ƒæ•ˆç‡å’Œé²æ£’æ€§ã€‚ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºï¼Œè¯¥æ–¹æ³•ä»…ä¾èµ–æ·±åº¦ä¿¡æ¯ï¼Œå¹¶ä¸”èƒ½å¤Ÿæœ‰æ•ˆå‡å°‘æ¨¡æ‹Ÿåˆ°çœŸå®ä¸–ç•Œçš„å·®è·ã€‚

**å…³é”®è®¾è®¡**ï¼šæ·±åº¦å›¾åƒåˆæˆæ–¹æ³•é‡‡ç”¨è‡ªé®æŒ¡æ„ŸçŸ¥å…‰çº¿æŠ•å°„å’Œå™ªå£°æ„ŸçŸ¥å»ºæ¨¡ï¼Œä»¥ç”Ÿæˆé€¼çœŸçš„æ·±åº¦è§‚æµ‹ã€‚äº¤å‰æ³¨æ„åŠ›Transformerä½¿ç”¨æ·±åº¦å›¾åƒå’Œé¢„è®­ç»ƒçš„é«˜ç¨‹å›¾ç‰¹å¾ä½œä¸ºè¾“å…¥ï¼Œé€šè¿‡äº¤å‰æ³¨æ„åŠ›æœºåˆ¶èåˆä¸¤ç§æ¨¡æ€çš„ä¿¡æ¯ã€‚åœ°å½¢æ„ŸçŸ¥è¿åŠ¨ç­–ç•¥ä½¿ç”¨æ·±åº¦å›¾åƒé‡å»ºçš„åœ°å½¢è¡¨ç¤ºä½œä¸ºè¾“å…¥ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒå¾—åˆ°æœ€ä¼˜çš„è¿åŠ¨æ§åˆ¶ç­–ç•¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆé™ä½åœ°å½¢é‡å»ºè¯¯å·®ï¼Œé™ä½å¹…åº¦è¶…è¿‡30%ã€‚åœ¨å…¨å°ºå¯¸ç±»äººæœºå™¨äººä¸Šçš„å®éªŒéªŒè¯äº†è¯¥æ¡†æ¶åœ¨å„ç§å…·æœ‰æŒ‘æˆ˜æ€§çš„åœ°å½¢ä¸Šçš„æ•æ·å’Œè‡ªé€‚åº”è¿åŠ¨èƒ½åŠ›ã€‚ç›¸è¾ƒäºå…¶ä»–æ–¹æ³•ï¼Œè¯¥æ¡†æ¶åœ¨è®­ç»ƒæ•ˆç‡å’Œé²æ£’æ€§æ–¹é¢å‡æœ‰æ˜¾è‘—æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦ç±»äººæœºå™¨äººåœ¨å¤æ‚åœ°å½¢ä¸Šè¿›è¡Œè¿åŠ¨çš„åœºæ™¯ï¼Œä¾‹å¦‚æœæ•‘ã€å‹˜æ¢ã€ç‰©æµç­‰ã€‚é€šè¿‡ä»…ä¾èµ–æ·±åº¦ä¿¡æ¯ï¼Œå¯ä»¥é™ä½å¯¹ç¡¬ä»¶çš„è¦æ±‚ï¼Œæé«˜æœºå™¨äººçš„è‡ªä¸»æ€§å’Œé€‚åº”æ€§ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºæ›´å¹¿æ³›çš„æœºå™¨äººé¢†åŸŸï¼Œä¾‹å¦‚å®¶åº­æœåŠ¡æœºå™¨äººã€åŒ»ç–—æœºå™¨äººç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advancements in legged robot perceptive locomotion have shown promising progress. However, terrain-aware humanoid locomotion remains largely constrained to two paradigms: depth image-based end-to-end learning and elevation map-based methods. The former suffers from limited training efficiency and a significant sim-to-real gap in depth perception, while the latter depends heavily on multiple vision sensors and localization systems, resulting in latency and reduced robustness. To overcome these challenges, we propose a novel framework that tightly integrates three key components: (1) Terrain-Aware Locomotion Policy with a Blind Backbone, which leverages pre-trained elevation map-based perception to guide reinforcement learning with minimal visual input; (2) Multi-Modality Cross-Attention Transformer, which reconstructs structured terrain representations from noisy depth images; (3) Realistic Depth Images Synthetic Method, which employs self-occlusion-aware ray casting and noise-aware modeling to synthesize realistic depth observations, achieving over 30\% reduction in terrain reconstruction error. This combination enables efficient policy training with limited data and hardware resources, while preserving critical terrain features essential for generalization. We validate our framework on a full-sized humanoid robot, demonstrating agile and adaptive locomotion across diverse and challenging terrains.

