---
layout: default
title: UniFField: A Generalizable Unified Neural Feature Field for Visual, Semantic, and Spatial Uncertainties in Any Scene
---

# UniFField: A Generalizable Unified Neural Feature Field for Visual, Semantic, and Spatial Uncertainties in Any Scene

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.06754" target="_blank" class="toolbar-btn">arXiv: 2510.06754v1</a>
    <a href="https://arxiv.org/pdf/2510.06754.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.06754v1" 
            onclick="toggleFavorite(this, '2510.06754v1', 'UniFField: A Generalizable Unified Neural Feature Field for Visual, Semantic, and Spatial Uncertainties in Any Scene')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Christian Maurer, Snehal Jauhri, Sophie Lueth, Georgia Chalvatzaki

**ÂàÜÁ±ª**: cs.RO, cs.CV, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-08

**Â§áÊ≥®**: Project website: https://sites.google.com/view/uniffield

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**UniFFieldÔºöÈÄöÁî®„ÄÅÁªü‰∏Ä‰∏îËÉΩÊÑüÁü•‰∏çÁ°ÆÂÆöÊÄßÁöÑÁ•ûÁªèÁâπÂæÅÂú∫ÔºåÈÄÇÁî®‰∫é‰ªªÊÑèÂú∫ÊôØ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Á•ûÁªèÁâπÂæÅÂú∫` `‰∏çÁ°ÆÂÆöÊÄß‰º∞ËÆ°` `Êú∫Âô®‰∫∫Âú∫ÊôØÁêÜËß£` `ÈÄöÁî®Âú∫ÊôØË°®Á§∫` `‰∏ªÂä®ÂØπË±°ÊêúÁ¥¢`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞Êúâ3DÁ•ûÁªèÁâπÂæÅÂú∫ÊñπÊ≥ïÈÄöÂ∏∏ÊòØÂú∫ÊôØÁâπÂÆöÁöÑÔºåÊ≥õÂåñËÉΩÂäõÂº±ÔºåÈöæ‰ª•ÈÄÇÂ∫îÊñ∞ÁéØÂ¢É„ÄÇ
2. UniFFieldÈÄöËøáÁªü‰∏ÄÁöÑÁ•ûÁªèÁâπÂæÅÂú∫Ë°®Á§∫ÔºåÊï¥ÂêàËßÜËßâ„ÄÅËØ≠‰πâÂíåÂá†‰Ωï‰ø°ÊÅØÔºåÂπ∂È¢ÑÊµãÂêÑÊ®°ÊÄÅÁöÑ‰∏çÁ°ÆÂÆöÊÄßÔºåÊèêÂçá‰∫ÜÊ≥õÂåñÊÄß„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåUniFFieldËÉΩÂáÜÁ°Æ‰º∞ËÆ°Ê®°ÂûãÈ¢ÑÊµãËØØÂ∑ÆÔºåÂπ∂ÊàêÂäüÂ∫îÁî®‰∫éÁßªÂä®Êìç‰ΩúÊú∫Âô®‰∫∫ÁöÑ‰∏ªÂä®ÂØπË±°ÊêúÁ¥¢‰ªªÂä°„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫UniFFieldÔºå‰∏ÄÁßçÁªü‰∏ÄÁöÑ„ÄÅËÉΩÊÑüÁü•‰∏çÁ°ÆÂÆöÊÄßÁöÑÁ•ûÁªèÁâπÂæÅÂú∫ÔºåÂÆÉÂ∞ÜËßÜËßâ„ÄÅËØ≠‰πâÂíåÂá†‰ΩïÁâπÂæÅÊï¥ÂêàÂà∞‰∏Ä‰∏™ÈÄöÁî®ÁöÑË°®Á§∫‰∏≠ÔºåÂêåÊó∂È¢ÑÊµãÊØèÁßçÊ®°ÊÄÅÁöÑ‰∏çÁ°ÆÂÆöÊÄß„ÄÇËØ•ÊñπÊ≥ïËÉΩÂ§üÈõ∂Ê†∑Êú¨Â∫îÁî®‰∫é‰ªª‰ΩïÊñ∞ÁéØÂ¢ÉÔºåÂπ∂Âú®Êú∫Âô®‰∫∫Êé¢Á¥¢Âú∫ÊôØÊó∂ÔºåÈÄêÊ≠•Â∞ÜRGB-DÂõæÂÉèÈõÜÊàêÂà∞Âü∫‰∫é‰ΩìÁ¥†ÁöÑÁâπÂæÅË°®Á§∫‰∏≠ÔºåÂêåÊó∂Êõ¥Êñ∞‰∏çÁ°ÆÂÆöÊÄß‰º∞ËÆ°„ÄÇËÆ∫ÊñáËØÑ‰º∞‰∫Ü‰∏çÁ°ÆÂÆöÊÄß‰º∞ËÆ°Âú®Âú∫ÊôØÈáçÂª∫ÂíåËØ≠‰πâÁâπÂæÅÈ¢ÑÊµã‰∏≠ÂáÜÁ°ÆÊèèËø∞Ê®°ÂûãÈ¢ÑÊµãËØØÂ∑ÆÁöÑËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåÊàêÂäüÂú∞Âà©Áî®ÁâπÂæÅÈ¢ÑÊµãÂèäÂÖ∂ÂêÑËá™ÁöÑ‰∏çÁ°ÆÂÆöÊÄßÔºåÈÄöËøáÁßªÂä®Êìç‰ΩúÊú∫Âô®‰∫∫ÊâßË°å‰∏ªÂä®ÂØπË±°ÊêúÁ¥¢‰ªªÂä°ÔºåÂ±ïÁ§∫‰∫ÜÈ≤ÅÊ£íÂÜ≥Á≠ñÁöÑËÉΩÂäõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÂü∫‰∫éÁ•ûÁªèÁâπÂæÅÂú∫ÁöÑÊú∫Âô®‰∫∫Âú∫ÊôØÁêÜËß£ÊñπÊ≥ïÈÄöÂ∏∏ÊòØÂú∫ÊôØÁâπÂÆöÁöÑÔºåÂç≥ÈúÄË¶ÅÈíàÂØπÊØè‰∏™Âú∫ÊôØËøõË°åËÆ≠ÁªÉÔºåÊ≥õÂåñËÉΩÂäõÂ∑Æ„ÄÇÊ≠§Â§ñÔºåËøô‰∫õÊñπÊ≥ïÈÄöÂ∏∏ÂøΩÁï•‰∫ÜÈ¢ÑÊµãÁªìÊûúÁöÑ‰∏çÁ°ÆÂÆöÊÄßÔºåËøôÂú®Â§çÊùÇÂíåÈùûÁªìÊûÑÂåñÁéØÂ¢É‰∏≠‰ºöÂΩ±ÂìçÊú∫Âô®‰∫∫ÁöÑÂÜ≥Á≠ñÈ≤ÅÊ£íÊÄß„ÄÇÂõ†Ê≠§ÔºåÈúÄË¶Å‰∏ÄÁßçÈÄöÁî®ÁöÑ„ÄÅËÉΩÂ§üÊÑüÁü•‰∏çÁ°ÆÂÆöÊÄßÁöÑÂú∫ÊôØË°®Á§∫ÊñπÊ≥ïÔºå‰ª•ÊîØÊåÅÊú∫Âô®‰∫∫Âú®‰ªªÊÑèÁéØÂ¢É‰∏≠ÁöÑÈ≤ÅÊ£íÊìç‰Ωú„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöUniFFieldÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜËßÜËßâ„ÄÅËØ≠‰πâÂíåÂá†‰ΩïÁâπÂæÅËûçÂêàÂà∞‰∏Ä‰∏™Áªü‰∏ÄÁöÑÁ•ûÁªèÁâπÂæÅÂú∫‰∏≠ÔºåÂπ∂ÂêåÊó∂È¢ÑÊµãÊØè‰∏™Ê®°ÊÄÅÁöÑ‰∏çÁ°ÆÂÆöÊÄß„ÄÇÈÄöËøáËøôÁßçÊñπÂºèÔºåÊ®°Âûã‰∏ç‰ªÖÂèØ‰ª•È¢ÑÊµãÂú∫ÊôØÁöÑÂêÑÁßçÂ±ûÊÄßÔºåËøòÂèØ‰ª•ËØÑ‰º∞È¢ÑÊµãÁöÑÂèØÈù†ÊÄß„ÄÇËøôÁßçËÆæËÆ°‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üÊõ¥Â•ΩÂú∞Â§ÑÁêÜÂô™Â£∞Âíå‰∏çÁ°ÆÂÆöÊÄßÔºå‰ªéËÄåÊèêÈ´òÊú∫Âô®‰∫∫Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑÈ≤ÅÊ£íÊÄß„ÄÇÊ≠§Â§ñÔºåÈááÁî®‰ΩìÁ¥†ÂåñÁöÑÁâπÂæÅË°®Á§∫ÔºåÂèØ‰ª•Â¢ûÈáèÂºèÂú∞ËûçÂêàÊñ∞ÁöÑRGB-DÂõæÂÉè‰ø°ÊÅØÔºåÈÄÇÂ∫îÂä®ÊÄÅÂèòÂåñÁöÑÁéØÂ¢É„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöUniFFieldÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) ÁâπÂæÅÊèêÂèñÊ®°ÂùóÔºö‰ªéRGB-DÂõæÂÉè‰∏≠ÊèêÂèñËßÜËßâ„ÄÅËØ≠‰πâÂíåÂá†‰ΩïÁâπÂæÅ„ÄÇ2) ‰ΩìÁ¥†ÂåñÁâπÂæÅË°®Á§∫Ê®°ÂùóÔºöÂ∞ÜÊèêÂèñÁöÑÁâπÂæÅÂ≠òÂÇ®Âú®‰ΩìÁ¥†ÂåñÁöÑ‰∏âÁª¥Á©∫Èó¥‰∏≠ÔºåÂΩ¢ÊàêÁ•ûÁªèÁâπÂæÅÂú∫„ÄÇ3) ‰∏çÁ°ÆÂÆöÊÄß‰º∞ËÆ°Ê®°ÂùóÔºöÈ¢ÑÊµãÊØè‰∏™Ê®°ÊÄÅÁâπÂæÅÁöÑ‰∏çÁ°ÆÂÆöÊÄß„ÄÇ4) ËûçÂêàÊ®°ÂùóÔºöÂ∞Ü‰∏çÂêåÊ®°ÊÄÅÁöÑÁâπÂæÅÂíå‰∏çÁ°ÆÂÆöÊÄß‰ø°ÊÅØËøõË°åËûçÂêàÔºåÂæóÂà∞Áªü‰∏ÄÁöÑÂú∫ÊôØË°®Á§∫„ÄÇÊú∫Âô®‰∫∫ÈÄöËøá‰∏çÊñ≠Êé¢Á¥¢ÁéØÂ¢ÉÔºåËé∑ÂèñÊñ∞ÁöÑRGB-DÂõæÂÉèÔºåÂπ∂Â∞ÜÂÖ∂Â¢ûÈáèÂºèÂú∞ËûçÂêàÂà∞ÁâπÂæÅÂú∫‰∏≠ÔºåÂêåÊó∂Êõ¥Êñ∞‰∏çÁ°ÆÂÆöÊÄß‰º∞ËÆ°„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöUniFFieldÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1) ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Áªü‰∏ÄÁöÑÊ°ÜÊû∂ÔºåËÉΩÂ§üÂêåÊó∂Ë°®Á§∫ËßÜËßâ„ÄÅËØ≠‰πâÂíåÂá†‰ΩïÁâπÂæÅÔºåÂπ∂È¢ÑÊµãÂÆÉ‰ª¨ÁöÑ‰∏çÁ°ÆÂÆöÊÄß„ÄÇ2) ÂÆûÁé∞‰∫ÜÈõ∂Ê†∑Êú¨Ê≥õÂåñËÉΩÂäõÔºåÂç≥Ê®°ÂûãÂèØ‰ª•Áõ¥Êé•Â∫îÁî®‰∫éÊñ∞ÁöÑÁéØÂ¢ÉÔºåËÄåÊó†ÈúÄÈáçÊñ∞ËÆ≠ÁªÉ„ÄÇ3) ÈááÁî®‰∫ÜÂ¢ûÈáèÂºèÊõ¥Êñ∞Á≠ñÁï•ÔºåËÉΩÂ§üÈÄÇÂ∫îÂä®ÊÄÅÂèòÂåñÁöÑÁéØÂ¢É„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöUniFFieldÈááÁî®Âü∫‰∫é‰ΩìÁ¥†ÁöÑÁâπÂæÅË°®Á§∫ÔºåÊØè‰∏™‰ΩìÁ¥†Â≠òÂÇ®‰∫ÜËßÜËßâ„ÄÅËØ≠‰πâÂíåÂá†‰ΩïÁâπÂæÅ‰ª•ÂèäÂØπÂ∫îÁöÑ‰∏çÁ°ÆÂÆöÊÄß„ÄÇ‰∏çÁ°ÆÂÆöÊÄß‰º∞ËÆ°Ê®°ÂùóÂèØËÉΩÈááÁî®‰∫ÜÂèòÂàÜÊé®Êñ≠ÊàñDropoutÁ≠âÊäÄÊúØ„ÄÇÊçüÂ§±ÂáΩÊï∞ÂèØËÉΩÂåÖÊã¨ÈáçÂª∫ÊçüÂ§±„ÄÅËØ≠‰πâÂàÜÂâ≤ÊçüÂ§±Âíå‰∏çÁ°ÆÂÆöÊÄßÊçüÂ§±ÔºåÁî®‰∫é‰ºòÂåñÁâπÂæÅË°®Á§∫Âíå‰∏çÁ°ÆÂÆöÊÄß‰º∞ËÆ°ÁöÑÂáÜÁ°ÆÊÄß„ÄÇÂÖ∑‰ΩìÁöÑÁΩëÁªúÁªìÊûÑÂíåÂèÇÊï∞ËÆæÁΩÆÂú®ËÆ∫Êñá‰∏≠Â∫îËØ•ÊúâËØ¶ÁªÜÊèèËø∞ÔºàÊú™Áü•Ôºâ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ËÆ∫ÊñáÈÄöËøáÂÆûÈ™åÈ™åËØÅ‰∫ÜUniFFieldÂú®Âú∫ÊôØÈáçÂª∫ÂíåËØ≠‰πâÁâπÂæÅÈ¢ÑÊµãÊñπÈù¢ÁöÑÊÄßËÉΩÔºåÂπ∂ËØÑ‰º∞‰∫Ü‰∏çÁ°ÆÂÆöÊÄß‰º∞ËÆ°ÁöÑÂáÜÁ°ÆÊÄß„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåUniFFieldËÉΩÂ§üÊúâÊïàÂú∞ÊèèËø∞Ê®°ÂûãÈ¢ÑÊµãËØØÂ∑ÆÔºåÂπ∂ÊàêÂäüÂ∫îÁî®‰∫éÁßªÂä®Êìç‰ΩúÊú∫Âô®‰∫∫ÁöÑ‰∏ªÂä®ÂØπË±°ÊêúÁ¥¢‰ªªÂä°„ÄÇÂÖ∑‰ΩìÁöÑÊÄßËÉΩÊï∞ÊçÆÂíåÂØπÊØîÂü∫Á∫øÔºàÊú™Áü•ÔºâÔºå‰ΩÜÊï¥‰ΩìÁªìÊûúË°®ÊòéUniFFieldÂÖ∑ÊúâËâØÂ•ΩÁöÑÊ≥õÂåñËÉΩÂäõÂíåÈ≤ÅÊ£íÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

UniFFieldÂú®Êú∫Âô®‰∫∫ÂØºËà™„ÄÅÊìç‰ΩúÂíåÂú∫ÊôØÁêÜËß£Á≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇ‰æãÂ¶ÇÔºåÂèØ‰ª•Â∫îÁî®‰∫éÁßªÂä®Êú∫Âô®‰∫∫ÁöÑËá™‰∏ªÊé¢Á¥¢ÂíåÂª∫ÂõæÔºåÂ∏ÆÂä©Êú∫Âô®‰∫∫Âú®Êú™Áü•ÁéØÂ¢É‰∏≠ÂÆâÂÖ®ÊúâÊïàÂú∞ÂØºËà™„ÄÇÊ≠§Â§ñÔºåËøòÂèØ‰ª•Áî®‰∫éÊú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°Ôºå‰æãÂ¶ÇÁâ©‰ΩìÊäìÂèñÂíåÊîæÁΩÆÔºåÊèêÈ´òÊìç‰ΩúÁöÑÁ≤æÂ∫¶ÂíåÈ≤ÅÊ£íÊÄß„ÄÇËØ•Á†îÁ©∂ÂØπ‰∫éÊèêÂçáÊú∫Âô®‰∫∫Âú®Â§çÊùÇÂíåÈùûÁªìÊûÑÂåñÁéØÂ¢É‰∏≠ÁöÑËá™‰∏ªËÉΩÂäõÂÖ∑ÊúâÈáçË¶ÅÊÑè‰πâ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Comprehensive visual, geometric, and semantic understanding of a 3D scene is crucial for successful execution of robotic tasks, especially in unstructured and complex environments. Additionally, to make robust decisions, it is necessary for the robot to evaluate the reliability of perceived information. While recent advances in 3D neural feature fields have enabled robots to leverage features from pretrained foundation models for tasks such as language-guided manipulation and navigation, existing methods suffer from two critical limitations: (i) they are typically scene-specific, and (ii) they lack the ability to model uncertainty in their predictions. We present UniFField, a unified uncertainty-aware neural feature field that combines visual, semantic, and geometric features in a single generalizable representation while also predicting uncertainty in each modality. Our approach, which can be applied zero shot to any new environment, incrementally integrates RGB-D images into our voxel-based feature representation as the robot explores the scene, simultaneously updating uncertainty estimation. We evaluate our uncertainty estimations to accurately describe the model prediction errors in scene reconstruction and semantic feature prediction. Furthermore, we successfully leverage our feature predictions and their respective uncertainty for an active object search task using a mobile manipulator robot, demonstrating the capability for robust decision-making.

