---
layout: default
title: TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics
---

# TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.07181" target="_blank" class="toolbar-btn">arXiv: 2510.07181v2</a>
    <a href="https://arxiv.org/pdf/2510.07181.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.07181v2" 
            onclick="toggleFavorite(this, '2510.07181v2', 'TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yi Han, Cheng Chi, Enshen Zhou, Shanyu Rong, Jingkun An, Pengwei Wang, Zhongyuan Wang, Lu Sheng, Shanghang Zhang

**ÂàÜÁ±ª**: cs.RO, cs.AI, cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-08 (Êõ¥Êñ∞: 2025-10-09)

**Â§áÊ≥®**: 9 pages, 6 figures

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**TIGeRÔºöÈÄöËøáÂ∑•ÂÖ∑ÈõÜÊàêÂá†‰ΩïÊé®ÁêÜÔºåÊèêÂçáËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÂú®Êú∫Âô®‰∫∫È¢ÜÂüüÁöÑÁ≤æÂ∫¶**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâ-ËØ≠Ë®ÄÊ®°Âûã` `Êú∫Âô®‰∫∫Êìç‰Ωú` `Âá†‰ΩïÊé®ÁêÜ` `Â∑•ÂÖ∑ÈõÜÊàê` `Ê∑±Â∫¶Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÂú®Êú∫Âô®‰∫∫Âá†‰ΩïÊé®ÁêÜ‰∏≠Á≤æÂ∫¶‰∏çË∂≥ÔºåÊó†Ê≥ïÊª°Ë∂≥ÂéòÁ±≥Á∫ßÊìç‰ΩúÈúÄÊ±ÇÔºå‰∏ªË¶ÅÂéüÂõ†ÊòØÁº∫‰πèÂØπÊ∑±Â∫¶‰ø°ÊÅØÂíåÁõ∏Êú∫ÂèÇÊï∞ÁöÑÊúâÊïàÂà©Áî®„ÄÇ
2. TIGeRÁöÑÊ†∏ÂøÉÊÄùÊÉ≥ÊòØËÆ©Ê®°ÂûãÈÄöËøáË∞ÉÁî®Â§ñÈÉ®Â∑•ÂÖ∑ËøõË°åÁ≤æÁ°ÆÁöÑÂá†‰ΩïËÆ°ÁÆóÔºåËÄåÈùûÂ∞ÜÂ§çÊùÇËÆ°ÁÆóÂÜÖÁΩÆ‰∫éÁ•ûÁªèÁΩëÁªú‰∏≠Ôºå‰ªéËÄåÊèêÂçáÁ≤æÂ∫¶„ÄÇ
3. TIGeRÈÄöËøáÊûÑÂª∫TIGeR-300KÊï∞ÊçÆÈõÜÂíå‰∏§Èò∂ÊÆµËÆ≠ÁªÉÊµÅÁ®ãÔºåÂú®Âá†‰ΩïÊé®ÁêÜÂü∫ÂáÜÊµãËØïÂíåÁúüÂÆûÊú∫Âô®‰∫∫Êìç‰Ωú‰∏≠ÂùáÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËßÜËßâ-ËØ≠Ë®ÄÊ®°Âûã(VLMs)Âú®Á©∫Èó¥Êé®ÁêÜÊñπÈù¢Ë°®Áé∞Âá∫ÂçìË∂äÁöÑËÉΩÂäõÔºå‰ΩÜÊú¨Ë¥®‰∏ä‰ªçÂèóÈôê‰∫éÂÆöÊÄßÁ≤æÂ∫¶ÔºåÁº∫‰πèÁúüÂÆû‰∏ñÁïåÊú∫Âô®‰∫∫ÊâÄÈúÄÁöÑËÆ°ÁÆóÁ≤æÂ∫¶„ÄÇÁé∞ÊúâÊñπÊ≥ïÊú™ËÉΩÂà©Áî®Ê∑±Â∫¶‰º†ÊÑüÂô®ÂíåÁõ∏Êú∫Ê†°ÂáÜÊèê‰æõÁöÑÂ∫¶ÈáèÁ∫øÁ¥¢ÔºåËÄåÊòØÂ∞ÜÂá†‰ΩïÈóÆÈ¢òÁÆÄÂåñ‰∏∫Ê®°ÂºèËØÜÂà´‰ªªÂä°ÔºåÊó†Ê≥ïÊèê‰æõÊú∫Âô®‰∫∫Êìç‰ΩúÊâÄÈúÄÁöÑÂéòÁ±≥Á∫ßÁ≤æÂ∫¶„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫ÜTIGeRÔºàÂ∑•ÂÖ∑ÈõÜÊàêÂá†‰ΩïÊé®ÁêÜÔºâÔºåËøôÊòØ‰∏Ä‰∏™Êñ∞È¢ñÁöÑÊ°ÜÊû∂ÔºåÈÄöËøá‰ΩøVLMsËÉΩÂ§üÁîüÊàêÂíåÊâßË°åÁ≤æÁ°ÆÁöÑÂá†‰ΩïËÆ°ÁÆóÔºå‰ªéËÄåÂ∞ÜVLMs‰ªéÊÑüÁü•‰º∞ËÆ°Âô®ËΩ¨Âèò‰∏∫Âá†‰ΩïËÆ°ÁÆóÂô®„ÄÇTIGeR‰∏çÂ∞ùËØïÂ∞ÜÂ§çÊùÇÁöÑÂá†‰ΩïÊìç‰ΩúÂÜÖÁΩÆ‰∫éÁ•ûÁªèÁΩëÁªú‰∏≠ÔºåËÄåÊòØ‰ΩøÊ®°ÂûãËÉΩÂ§üËØÜÂà´Âá†‰ΩïÊé®ÁêÜÈúÄÊ±ÇÔºåÂêàÊàêÈÄÇÂΩìÁöÑËÆ°ÁÆó‰ª£Á†ÅÔºåÂπ∂Ë∞ÉÁî®‰∏ìÈó®ÁöÑÂ∫ìËøõË°åÁ≤æÁ°ÆËÆ°ÁÆó„ÄÇ‰∏∫‰∫ÜÊîØÊåÅËøôÁßçËåÉÂºèÔºåÊàë‰ª¨ÂºïÂÖ•‰∫ÜTIGeR-300KÔºåËøôÊòØ‰∏Ä‰∏™ÂÖ®Èù¢ÁöÑ„ÄÅÈù¢ÂêëÂ∑•ÂÖ∑Ë∞ÉÁî®ÁöÑÊï∞ÊçÆÈõÜÔºåÊ∂µÁõñÁÇπÂèòÊç¢„ÄÅÂßøÊÄÅ‰º∞ËÆ°ÂíåÁ©∫Èó¥ÂÖºÂÆπÊÄßÈ™åËØÅÔºåÂåÖÂê´Â∑•ÂÖ∑Ë∞ÉÁî®Â∫èÂàóÂíå‰∏≠Èó¥ËÆ°ÁÆó„ÄÇÈÄöËøáÁªìÂêàÁõëÁù£ÂæÆË∞É(SFT)ÂíåÂº∫ÂåñÂæÆË∞É(RFT)ÁöÑ‰∏§Èò∂ÊÆµËÆ≠ÁªÉÊµÅÁ®ãÔºå‰ª•ÂèäÊàë‰ª¨ÊèêÂá∫ÁöÑÂàÜÂ±ÇÂ•ñÂä±ËÆæËÆ°ÔºåTIGeRÂú®Âá†‰ΩïÊé®ÁêÜÂü∫ÂáÜÊµãËØï‰∏≠ÂÆûÁé∞‰∫ÜSOTAÊÄßËÉΩÔºåÂπ∂Âú®ÁúüÂÆû‰∏ñÁïåÁöÑÊú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰∏≠Â±ïÁ§∫‰∫ÜÂéòÁ±≥Á∫ßÁöÑÁ≤æÂ∫¶„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÂú®Êú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰∏≠ÔºåÂá†‰ΩïÊé®ÁêÜÁ≤æÂ∫¶‰∏çË∂≥ÔºåÊó†Ê≥ïÊª°Ë∂≥ÂÆûÈôÖÂ∫îÁî®ÈúÄÊ±Ç„ÄÇÂÆÉ‰ª¨ÈÄöÂ∏∏Â∞ÜÂá†‰ΩïÈóÆÈ¢òËßÜ‰∏∫Ê®°ÂºèËØÜÂà´ÔºåÂøΩÁï•‰∫ÜÊ∑±Â∫¶‰º†ÊÑüÂô®ÂíåÁõ∏Êú∫Ê†áÂÆöÁöÑÂ∫¶Èáè‰ø°ÊÅØÔºåÂØºËá¥Á≤æÂ∫¶ÂèóÈôê„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöTIGeRÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜËßÜËßâ-ËØ≠Ë®ÄÊ®°Âûã‰ªé‚ÄúÊÑüÁü•‰º∞ËÆ°Âô®‚ÄùËΩ¨Âèò‰∏∫‚ÄúÂá†‰ΩïËÆ°ÁÆóÂô®‚Äù„ÄÇÈÄöËøáËµã‰∫àÊ®°ÂûãË∞ÉÁî®Â§ñÈÉ®Â∑•ÂÖ∑ÁöÑËÉΩÂäõÔºå‰ΩøÂÖ∂ËÉΩÂ§üÁîüÊàêÂπ∂ÊâßË°åÁ≤æÁ°ÆÁöÑÂá†‰ΩïËÆ°ÁÆóÔºå‰ªéËÄåÁªïËøáÁ•ûÁªèÁΩëÁªúÂÜÖÈÉ®Â§çÊùÇÂá†‰ΩïËøêÁÆóÁöÑÈôêÂà∂ÔºåÊèêÈ´òÁ≤æÂ∫¶„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöTIGeRÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÁªÑÊàêÈÉ®ÂàÜÔºö1) Âá†‰ΩïÊé®ÁêÜÈúÄÊ±ÇËØÜÂà´Ê®°ÂùóÔºåÁî®‰∫éÂà§Êñ≠ÊòØÂê¶ÈúÄË¶ÅËøõË°åÂá†‰ΩïËÆ°ÁÆóÔºõ2) ‰ª£Á†ÅÁîüÊàêÊ®°ÂùóÔºåÊ†πÊçÆÈúÄÊ±ÇÁîüÊàêÁõ∏Â∫îÁöÑËÆ°ÁÆó‰ª£Á†ÅÔºõ3) Â∑•ÂÖ∑Ë∞ÉÁî®Ê®°ÂùóÔºåÊâßË°åÁîüÊàêÁöÑ‰ª£Á†ÅÔºåË∞ÉÁî®Â§ñÈÉ®Âá†‰ΩïËÆ°ÁÆóÂ∫ìÔºõ4) ÁªìÊûúÊï¥ÂêàÊ®°ÂùóÔºåÂ∞ÜËÆ°ÁÆóÁªìÊûúÊï¥ÂêàÂà∞ËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÁöÑËæìÂá∫‰∏≠„ÄÇËÆ≠ÁªÉËøáÁ®ãÈááÁî®‰∏§Èò∂ÊÆµÁ≠ñÁï•ÔºöÈ¶ñÂÖàÊòØÁõëÁù£ÂæÆË∞É(SFT)ÔºåÁÑ∂ÂêéÊòØÂº∫ÂåñÂæÆË∞É(RFT)„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöTIGeRÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫é‚ÄúÂ∑•ÂÖ∑ÈõÜÊàê‚ÄùÁöÑÊÄùÊÉ≥„ÄÇÂÆÉÊâìÁ†¥‰∫Ü‰º†ÁªüËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÂ∞ÜÊâÄÊúâÂäüËÉΩÈÉΩÂÜÖÁΩÆ‰∫éÁ•ûÁªèÁΩëÁªú‰∏≠ÁöÑÊ®°ÂºèÔºåËÄåÊòØÈÄöËøáË∞ÉÁî®Â§ñÈÉ®Â∑•ÂÖ∑Êù•ÂÆåÊàêÂ§çÊùÇÁöÑÂá†‰ΩïËÆ°ÁÆó„ÄÇËøôÁßçÊñπÊ≥ï‰∏ç‰ªÖÊèêÈ´ò‰∫ÜÁ≤æÂ∫¶ÔºåËøòÂ¢ûÂº∫‰∫ÜÊ®°ÂûãÁöÑÂèØËß£ÈáäÊÄßÂíåÂèØÊâ©Â±ïÊÄß„ÄÇÊ≠§Â§ñÔºåTIGeR-300KÊï∞ÊçÆÈõÜÁöÑÊûÑÂª∫‰πü‰∏∫ËØ•ÊñπÊ≥ïÊèê‰æõ‰∫ÜÊï∞ÊçÆÊîØÊíë„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöTIGeR-300KÊï∞ÊçÆÈõÜÂåÖÂê´ÁÇπÂèòÊç¢„ÄÅÂßøÊÄÅ‰º∞ËÆ°ÂíåÁ©∫Èó¥ÂÖºÂÆπÊÄßÈ™åËØÅÁ≠â‰ªªÂä°ÔºåÊØè‰∏™‰ªªÂä°ÈÉΩÂåÖÂê´Â∑•ÂÖ∑Ë∞ÉÁî®Â∫èÂàóÂíå‰∏≠Èó¥ËÆ°ÁÆóÁªìÊûú„ÄÇÂº∫ÂåñÂæÆË∞ÉÈò∂ÊÆµÈááÁî®‰∫ÜÂàÜÂ±ÇÂ•ñÂä±ËÆæËÆ°ÔºåÂØπÊ®°ÂûãÁöÑÊØè‰∏ÄÊ≠•Êìç‰ΩúÈÉΩËøõË°åËØÑ‰º∞ÂíåÂ•ñÂä±Ôºå‰ªéËÄåÂºïÂØºÊ®°ÂûãÂ≠¶‰π†Ê≠£Á°ÆÁöÑÂ∑•ÂÖ∑Ë∞ÉÁî®Á≠ñÁï•„ÄÇÂÖ∑‰ΩìÁöÑÂ•ñÂä±ÂáΩÊï∞ËÆæËÆ°ÁªÜËäÇÊú™Áü•„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

TIGeRÂú®Âá†‰ΩïÊé®ÁêÜÂü∫ÂáÜÊµãËØï‰∏≠ÂèñÂæó‰∫ÜSOTAÊÄßËÉΩÔºåÂπ∂Âú®ÁúüÂÆû‰∏ñÁïåÁöÑÊú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰∏≠Â±ïÁ§∫‰∫ÜÂéòÁ±≥Á∫ßÁöÑÁ≤æÂ∫¶„ÄÇÂÖ∑‰ΩìÊÄßËÉΩÊï∞ÊçÆÊú™Áü•Ôºå‰ΩÜËÆ∫ÊñáÂº∫Ë∞É‰∫ÜTIGeRÂú®Á≤æÂ∫¶ÊñπÈù¢ÁöÑÊòæËëóÊèêÂçáÔºåË°®ÊòéÂÖ∂Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÂÖ∑ÊúâÂæàÈ´òÁöÑ‰ª∑ÂÄº„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåTIGeRÈÄöËøáÂ∑•ÂÖ∑ÈõÜÊàêÁöÑÊñπÂºèÔºåÊòæËëóÊèêÈ´ò‰∫ÜÂá†‰ΩïÊé®ÁêÜÁöÑÁ≤æÂ∫¶ÂíåÂèØÈù†ÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

TIGeRÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂèØÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫Êìç‰Ωú„ÄÅËá™Âä®È©æÈ©∂„ÄÅÂ¢ûÂº∫Áé∞ÂÆûÁ≠âÈ¢ÜÂüü„ÄÇ‰æãÂ¶ÇÔºåÂú®Êú∫Âô®‰∫∫Êìç‰Ωú‰∏≠ÔºåTIGeRÂèØ‰ª•Â∏ÆÂä©Êú∫Âô®‰∫∫Êõ¥Á≤æÁ°ÆÂú∞ÊäìÂèñÁâ©‰Ωì„ÄÅËøõË°åË£ÖÈÖçÁ≠â‰ªªÂä°„ÄÇÂú®Ëá™Âä®È©æÈ©∂‰∏≠ÔºåTIGeRÂèØ‰ª•ÊèêÈ´òËΩ¶ËæÜÂØπÂë®Âõ¥ÁéØÂ¢ÉÁöÑÊÑüÁü•ÂíåÁêÜËß£ËÉΩÂäõÔºå‰ªéËÄåÊèêÈ´òÈ©æÈ©∂ÂÆâÂÖ®ÊÄß„ÄÇÂú®Â¢ûÂº∫Áé∞ÂÆû‰∏≠ÔºåTIGeRÂèØ‰ª•ÂÆûÁé∞Êõ¥ÈÄºÁúüÁöÑËôöÊãüÁâ©‰Ωì‰∏éÁé∞ÂÆû‰∏ñÁïåÁöÑ‰∫§‰∫í„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Vision-Language Models (VLMs) have shown remarkable capabilities in spatial reasoning, yet they remain fundamentally limited to qualitative precision and lack the computational precision required for real-world robotics. Current approaches fail to leverage metric cues from depth sensors and camera calibration, instead reducing geometric problems to pattern recognition tasks that cannot deliver the centimeter-level accuracy essential for robotic manipulation. We present TIGeR (Tool-Integrated Geometric Reasoning), a novel framework that transforms VLMs from perceptual estimators to geometric computers by enabling them to generate and execute precise geometric computations through external tools. Rather than attempting to internalize complex geometric operations within neural networks, TIGeR empowers models to recognize geometric reasoning requirements, synthesize appropriate computational code, and invoke specialized libraries for exact calculations. To support this paradigm, we introduce TIGeR-300K, a comprehensive tool-invocation-oriented dataset covering point transformations, pose estimation, and spatial compatibility verification, complete with tool invocation sequences and intermediate computations. Through a two-stage training pipeline combining supervised fine-tuning (SFT) and reinforcement fine-tuning (RFT) with our proposed hierarchical reward design, TIGeR achieves SOTA performance on geometric reasoning benchmarks while demonstrating centimeter-level precision in real-world robotic manipulation tasks.

