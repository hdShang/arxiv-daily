---
layout: default
title: TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics
---

# TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.07181" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.07181v2</a>
  <a href="https://arxiv.org/pdf/2510.07181.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.07181v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.07181v2', 'TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yi Han, Cheng Chi, Enshen Zhou, Shanyu Rong, Jingkun An, Pengwei Wang, Zhongyuan Wang, Lu Sheng, Shanghang Zhang

**åˆ†ç±»**: cs.RO, cs.AI, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-08 (æ›´æ–°: 2025-10-09)

**å¤‡æ³¨**: 9 pages, 6 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**TIGeRï¼šé€šè¿‡å·¥å…·é›†æˆå‡ ä½•æ¨ç†ï¼Œæå‡è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨æœºå™¨äººé¢†åŸŸçš„ç²¾åº¦**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€æ¨¡å‹` `æœºå™¨äººæ“ä½œ` `å‡ ä½•æ¨ç†` `å·¥å…·é›†æˆ` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨æœºå™¨äººå‡ ä½•æ¨ç†ä¸­ç²¾åº¦ä¸è¶³ï¼Œæ— æ³•æ»¡è¶³å˜ç±³çº§æ“ä½œéœ€æ±‚ï¼Œä¸»è¦åŸå› æ˜¯ç¼ºä¹å¯¹æ·±åº¦ä¿¡æ¯å’Œç›¸æœºå‚æ•°çš„æœ‰æ•ˆåˆ©ç”¨ã€‚
2. TIGeRçš„æ ¸å¿ƒæ€æƒ³æ˜¯è®©æ¨¡å‹é€šè¿‡è°ƒç”¨å¤–éƒ¨å·¥å…·è¿›è¡Œç²¾ç¡®çš„å‡ ä½•è®¡ç®—ï¼Œè€Œéå°†å¤æ‚è®¡ç®—å†…ç½®äºç¥ç»ç½‘ç»œä¸­ï¼Œä»è€Œæå‡ç²¾åº¦ã€‚
3. TIGeRé€šè¿‡æ„å»ºTIGeR-300Kæ•°æ®é›†å’Œä¸¤é˜¶æ®µè®­ç»ƒæµç¨‹ï¼Œåœ¨å‡ ä½•æ¨ç†åŸºå‡†æµ‹è¯•å’ŒçœŸå®æœºå™¨äººæ“ä½œä¸­å‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€æ¨¡å‹(VLMs)åœ¨ç©ºé—´æ¨ç†æ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„èƒ½åŠ›ï¼Œä½†æœ¬è´¨ä¸Šä»å—é™äºå®šæ€§ç²¾åº¦ï¼Œç¼ºä¹çœŸå®ä¸–ç•Œæœºå™¨äººæ‰€éœ€çš„è®¡ç®—ç²¾åº¦ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½åˆ©ç”¨æ·±åº¦ä¼ æ„Ÿå™¨å’Œç›¸æœºæ ¡å‡†æä¾›çš„åº¦é‡çº¿ç´¢ï¼Œè€Œæ˜¯å°†å‡ ä½•é—®é¢˜ç®€åŒ–ä¸ºæ¨¡å¼è¯†åˆ«ä»»åŠ¡ï¼Œæ— æ³•æä¾›æœºå™¨äººæ“ä½œæ‰€éœ€çš„å˜ç±³çº§ç²¾åº¦ã€‚æˆ‘ä»¬æå‡ºäº†TIGeRï¼ˆå·¥å…·é›†æˆå‡ ä½•æ¨ç†ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°é¢–çš„æ¡†æ¶ï¼Œé€šè¿‡ä½¿VLMsèƒ½å¤Ÿç”Ÿæˆå’Œæ‰§è¡Œç²¾ç¡®çš„å‡ ä½•è®¡ç®—ï¼Œä»è€Œå°†VLMsä»æ„ŸçŸ¥ä¼°è®¡å™¨è½¬å˜ä¸ºå‡ ä½•è®¡ç®—å™¨ã€‚TIGeRä¸å°è¯•å°†å¤æ‚çš„å‡ ä½•æ“ä½œå†…ç½®äºç¥ç»ç½‘ç»œä¸­ï¼Œè€Œæ˜¯ä½¿æ¨¡å‹èƒ½å¤Ÿè¯†åˆ«å‡ ä½•æ¨ç†éœ€æ±‚ï¼Œåˆæˆé€‚å½“çš„è®¡ç®—ä»£ç ï¼Œå¹¶è°ƒç”¨ä¸“é—¨çš„åº“è¿›è¡Œç²¾ç¡®è®¡ç®—ã€‚ä¸ºäº†æ”¯æŒè¿™ç§èŒƒå¼ï¼Œæˆ‘ä»¬å¼•å…¥äº†TIGeR-300Kï¼Œè¿™æ˜¯ä¸€ä¸ªå…¨é¢çš„ã€é¢å‘å·¥å…·è°ƒç”¨çš„æ•°æ®é›†ï¼Œæ¶µç›–ç‚¹å˜æ¢ã€å§¿æ€ä¼°è®¡å’Œç©ºé—´å…¼å®¹æ€§éªŒè¯ï¼ŒåŒ…å«å·¥å…·è°ƒç”¨åºåˆ—å’Œä¸­é—´è®¡ç®—ã€‚é€šè¿‡ç»“åˆç›‘ç£å¾®è°ƒ(SFT)å’Œå¼ºåŒ–å¾®è°ƒ(RFT)çš„ä¸¤é˜¶æ®µè®­ç»ƒæµç¨‹ï¼Œä»¥åŠæˆ‘ä»¬æå‡ºçš„åˆ†å±‚å¥–åŠ±è®¾è®¡ï¼ŒTIGeRåœ¨å‡ ä½•æ¨ç†åŸºå‡†æµ‹è¯•ä¸­å®ç°äº†SOTAæ€§èƒ½ï¼Œå¹¶åœ¨çœŸå®ä¸–ç•Œçš„æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­å±•ç¤ºäº†å˜ç±³çº§çš„ç²¾åº¦ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­ï¼Œå‡ ä½•æ¨ç†ç²¾åº¦ä¸è¶³ï¼Œæ— æ³•æ»¡è¶³å®é™…åº”ç”¨éœ€æ±‚ã€‚å®ƒä»¬é€šå¸¸å°†å‡ ä½•é—®é¢˜è§†ä¸ºæ¨¡å¼è¯†åˆ«ï¼Œå¿½ç•¥äº†æ·±åº¦ä¼ æ„Ÿå™¨å’Œç›¸æœºæ ‡å®šçš„åº¦é‡ä¿¡æ¯ï¼Œå¯¼è‡´ç²¾åº¦å—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šTIGeRçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†è§†è§‰-è¯­è¨€æ¨¡å‹ä»â€œæ„ŸçŸ¥ä¼°è®¡å™¨â€è½¬å˜ä¸ºâ€œå‡ ä½•è®¡ç®—å™¨â€ã€‚é€šè¿‡èµ‹äºˆæ¨¡å‹è°ƒç”¨å¤–éƒ¨å·¥å…·çš„èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿç”Ÿæˆå¹¶æ‰§è¡Œç²¾ç¡®çš„å‡ ä½•è®¡ç®—ï¼Œä»è€Œç»•è¿‡ç¥ç»ç½‘ç»œå†…éƒ¨å¤æ‚å‡ ä½•è¿ç®—çš„é™åˆ¶ï¼Œæé«˜ç²¾åº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTIGeRæ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦ç»„æˆéƒ¨åˆ†ï¼š1) å‡ ä½•æ¨ç†éœ€æ±‚è¯†åˆ«æ¨¡å—ï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦éœ€è¦è¿›è¡Œå‡ ä½•è®¡ç®—ï¼›2) ä»£ç ç”Ÿæˆæ¨¡å—ï¼Œæ ¹æ®éœ€æ±‚ç”Ÿæˆç›¸åº”çš„è®¡ç®—ä»£ç ï¼›3) å·¥å…·è°ƒç”¨æ¨¡å—ï¼Œæ‰§è¡Œç”Ÿæˆçš„ä»£ç ï¼Œè°ƒç”¨å¤–éƒ¨å‡ ä½•è®¡ç®—åº“ï¼›4) ç»“æœæ•´åˆæ¨¡å—ï¼Œå°†è®¡ç®—ç»“æœæ•´åˆåˆ°è§†è§‰-è¯­è¨€æ¨¡å‹çš„è¾“å‡ºä¸­ã€‚è®­ç»ƒè¿‡ç¨‹é‡‡ç”¨ä¸¤é˜¶æ®µç­–ç•¥ï¼šé¦–å…ˆæ˜¯ç›‘ç£å¾®è°ƒ(SFT)ï¼Œç„¶åæ˜¯å¼ºåŒ–å¾®è°ƒ(RFT)ã€‚

**å…³é”®åˆ›æ–°**ï¼šTIGeRçš„å…³é”®åˆ›æ–°åœ¨äºâ€œå·¥å…·é›†æˆâ€çš„æ€æƒ³ã€‚å®ƒæ‰“ç ´äº†ä¼ ç»Ÿè§†è§‰-è¯­è¨€æ¨¡å‹å°†æ‰€æœ‰åŠŸèƒ½éƒ½å†…ç½®äºç¥ç»ç½‘ç»œä¸­çš„æ¨¡å¼ï¼Œè€Œæ˜¯é€šè¿‡è°ƒç”¨å¤–éƒ¨å·¥å…·æ¥å®Œæˆå¤æ‚çš„å‡ ä½•è®¡ç®—ã€‚è¿™ç§æ–¹æ³•ä¸ä»…æé«˜äº†ç²¾åº¦ï¼Œè¿˜å¢å¼ºäº†æ¨¡å‹çš„å¯è§£é‡Šæ€§å’Œå¯æ‰©å±•æ€§ã€‚æ­¤å¤–ï¼ŒTIGeR-300Kæ•°æ®é›†çš„æ„å»ºä¹Ÿä¸ºè¯¥æ–¹æ³•æä¾›äº†æ•°æ®æ”¯æ’‘ã€‚

**å…³é”®è®¾è®¡**ï¼šTIGeR-300Kæ•°æ®é›†åŒ…å«ç‚¹å˜æ¢ã€å§¿æ€ä¼°è®¡å’Œç©ºé—´å…¼å®¹æ€§éªŒè¯ç­‰ä»»åŠ¡ï¼Œæ¯ä¸ªä»»åŠ¡éƒ½åŒ…å«å·¥å…·è°ƒç”¨åºåˆ—å’Œä¸­é—´è®¡ç®—ç»“æœã€‚å¼ºåŒ–å¾®è°ƒé˜¶æ®µé‡‡ç”¨äº†åˆ†å±‚å¥–åŠ±è®¾è®¡ï¼Œå¯¹æ¨¡å‹çš„æ¯ä¸€æ­¥æ“ä½œéƒ½è¿›è¡Œè¯„ä¼°å’Œå¥–åŠ±ï¼Œä»è€Œå¼•å¯¼æ¨¡å‹å­¦ä¹ æ­£ç¡®çš„å·¥å…·è°ƒç”¨ç­–ç•¥ã€‚å…·ä½“çš„å¥–åŠ±å‡½æ•°è®¾è®¡ç»†èŠ‚æœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

TIGeRåœ¨å‡ ä½•æ¨ç†åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†SOTAæ€§èƒ½ï¼Œå¹¶åœ¨çœŸå®ä¸–ç•Œçš„æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­å±•ç¤ºäº†å˜ç±³çº§çš„ç²¾åº¦ã€‚å…·ä½“æ€§èƒ½æ•°æ®æœªçŸ¥ï¼Œä½†è®ºæ–‡å¼ºè°ƒäº†TIGeRåœ¨ç²¾åº¦æ–¹é¢çš„æ˜¾è‘—æå‡ï¼Œè¡¨æ˜å…¶åœ¨å®é™…åº”ç”¨ä¸­å…·æœ‰å¾ˆé«˜çš„ä»·å€¼ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒTIGeRé€šè¿‡å·¥å…·é›†æˆçš„æ–¹å¼ï¼Œæ˜¾è‘—æé«˜äº†å‡ ä½•æ¨ç†çš„ç²¾åº¦å’Œå¯é æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

TIGeRå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯åº”ç”¨äºæœºå™¨äººæ“ä½œã€è‡ªåŠ¨é©¾é©¶ã€å¢å¼ºç°å®ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨æœºå™¨äººæ“ä½œä¸­ï¼ŒTIGeRå¯ä»¥å¸®åŠ©æœºå™¨äººæ›´ç²¾ç¡®åœ°æŠ“å–ç‰©ä½“ã€è¿›è¡Œè£…é…ç­‰ä»»åŠ¡ã€‚åœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼ŒTIGeRå¯ä»¥æé«˜è½¦è¾†å¯¹å‘¨å›´ç¯å¢ƒçš„æ„ŸçŸ¥å’Œç†è§£èƒ½åŠ›ï¼Œä»è€Œæé«˜é©¾é©¶å®‰å…¨æ€§ã€‚åœ¨å¢å¼ºç°å®ä¸­ï¼ŒTIGeRå¯ä»¥å®ç°æ›´é€¼çœŸçš„è™šæ‹Ÿç‰©ä½“ä¸ç°å®ä¸–ç•Œçš„äº¤äº’ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision-Language Models (VLMs) have shown remarkable capabilities in spatial reasoning, yet they remain fundamentally limited to qualitative precision and lack the computational precision required for real-world robotics. Current approaches fail to leverage metric cues from depth sensors and camera calibration, instead reducing geometric problems to pattern recognition tasks that cannot deliver the centimeter-level accuracy essential for robotic manipulation. We present TIGeR (Tool-Integrated Geometric Reasoning), a novel framework that transforms VLMs from perceptual estimators to geometric computers by enabling them to generate and execute precise geometric computations through external tools. Rather than attempting to internalize complex geometric operations within neural networks, TIGeR empowers models to recognize geometric reasoning requirements, synthesize appropriate computational code, and invoke specialized libraries for exact calculations. To support this paradigm, we introduce TIGeR-300K, a comprehensive tool-invocation-oriented dataset covering point transformations, pose estimation, and spatial compatibility verification, complete with tool invocation sequences and intermediate computations. Through a two-stage training pipeline combining supervised fine-tuning (SFT) and reinforcement fine-tuning (RFT) with our proposed hierarchical reward design, TIGeR achieves SOTA performance on geometric reasoning benchmarks while demonstrating centimeter-level precision in real-world robotic manipulation tasks.

