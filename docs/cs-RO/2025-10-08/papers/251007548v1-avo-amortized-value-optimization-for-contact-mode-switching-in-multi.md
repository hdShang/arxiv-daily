---
layout: default
title: AVO: Amortized Value Optimization for Contact Mode Switching in Multi-Finger Manipulation
---

# AVO: Amortized Value Optimization for Contact Mode Switching in Multi-Finger Manipulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.07548" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.07548v1</a>
  <a href="https://arxiv.org/pdf/2510.07548.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.07548v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.07548v1', 'AVO: Amortized Value Optimization for Contact Mode Switching in Multi-Finger Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Adam Hung, Fan Yang, Abhinav Kumar, Sergio Aguilera Marinovic, Soshi Iba, Rana Soltani Zarrin, Dmitry Berenson

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-10-08

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**AVOï¼šåŸºäºå€¼å‡½æ•°ä¼˜åŒ–çš„å¤šæŒ‡çµå·§æ“ä½œæ¥è§¦æ¨¡å¼åˆ‡æ¢æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `çµå·§æ“ä½œ` `è½¨è¿¹ä¼˜åŒ–` `å€¼å‡½æ•°å­¦ä¹ ` `æ¥è§¦æ¨¡å¼åˆ‡æ¢` `æœºå™¨äººæ§åˆ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çµå·§æ“ä½œä¸­æ¥è§¦æ¨¡å¼åˆ‡æ¢æ˜¯éš¾ç‚¹ï¼Œç°æœ‰æ–¹æ³•ç‹¬ç«‹ä¼˜åŒ–å„å­ä»»åŠ¡ï¼Œå¿½ç•¥äº†ä»»åŠ¡é—´çš„ä¾èµ–å…³ç³»ã€‚
2. AVOé€šè¿‡å­¦ä¹ å€¼å‡½æ•°é¢„æµ‹æœªæ¥ä»»åŠ¡æ€§èƒ½ï¼ŒæŒ‡å¯¼è½¨è¿¹ä¼˜åŒ–ï¼Œä»è€Œæ¡¥æ¥å­ä»»åŠ¡ï¼ŒåŠ é€Ÿä¼˜åŒ–è¿‡ç¨‹ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒAVOåœ¨èºä¸åˆ€æ“ä½œä»»åŠ¡ä¸­ï¼Œå³ä½¿è®¡ç®—èµ„æºå‡å°‘50%ï¼Œæ€§èƒ½ä»ä¼˜äºä¼ ç»Ÿè½¨è¿¹ä¼˜åŒ–ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

çµå·§æ“ä½œä»»åŠ¡é€šå¸¸éœ€è¦åœ¨ä¸åŒçš„æ¥è§¦æ¨¡å¼ä¹‹é—´åˆ‡æ¢ï¼Œä¾‹å¦‚æ»šåŠ¨ã€æ»‘åŠ¨ã€ç²˜æ»æˆ–éæ¥è§¦æ¨¡å¼ã€‚å°†çµå·§æ“ä½œä»»åŠ¡å»ºæ¨¡ä¸ºè½¨è¿¹ä¼˜åŒ–é—®é¢˜æ—¶ï¼Œå¸¸è§çš„æ–¹æ³•æ˜¯å°†è¿™äº›ä»»åŠ¡åˆ†è§£ä¸ºæ¯ä¸ªæ¥è§¦æ¨¡å¼çš„å­ä»»åŠ¡ï¼Œå¹¶ç‹¬ç«‹æ±‚è§£ã€‚ç‹¬ç«‹ä¼˜åŒ–æ¯ä¸ªå­ä»»åŠ¡ä¼šé™åˆ¶æ€§èƒ½ï¼Œå› ä¸ºåœ¨æ²¡æœ‰å…³äºæœªæ¥å­ä»»åŠ¡ä¿¡æ¯çš„æƒ…å†µä¸‹ä¼˜åŒ–æ¥è§¦ç‚¹ã€æ¥è§¦åŠ›æˆ–å…¶ä»–å˜é‡ï¼Œå¯èƒ½ä¼šä½¿ç³»ç»Ÿå¤„äºéš¾ä»¥åœ¨åç»­å­ä»»åŠ¡ä¸­å–å¾—è¿›å±•çš„çŠ¶æ€ã€‚æ­¤å¤–ï¼Œä¼˜åŒ–è¿™äº›å­ä»»åŠ¡çš„è®¡ç®—æˆæœ¬éå¸¸é«˜ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†æ‘Šé”€å€¼ä¼˜åŒ–ï¼ˆAVOï¼‰ï¼Œå®ƒå¼•å…¥äº†ä¸€ä¸ªå­¦ä¹ çš„å€¼å‡½æ•°ï¼Œç”¨äºé¢„æµ‹æœªæ¥çš„æ€»ä»»åŠ¡æ€§èƒ½ã€‚é€šè¿‡å°†æ­¤å€¼å‡½æ•°çº³å…¥æ¯ä¸ªè§„åˆ’æ­¥éª¤çš„è½¨è¿¹ä¼˜åŒ–æˆæœ¬ä¸­ï¼Œå€¼å‡½æ•°æ¢¯åº¦å¼•å¯¼ä¼˜åŒ–å™¨æœç€æœ€å°åŒ–æœªæ¥å­ä»»åŠ¡æˆæœ¬çš„çŠ¶æ€å‰è¿›ã€‚è¿™æœ‰æ•ˆåœ°æ¡¥æ¥äº†å•ç‹¬ä¼˜åŒ–çš„å­ä»»åŠ¡ï¼Œå¹¶é€šè¿‡å‡å°‘æ‰€éœ€çš„åœ¨çº¿è®¡ç®—é‡æ¥åŠ é€Ÿä¼˜åŒ–ã€‚æˆ‘ä»¬åœ¨ä»¿çœŸå’ŒçœŸå®ä¸–ç•Œçš„å®éªŒä¸­ï¼Œé€šè¿‡èºä¸åˆ€æŠ“å–å’Œè½¬åŠ¨ä»»åŠ¡éªŒè¯äº†AVOï¼Œç»“æœè¡¨æ˜ï¼Œå³ä½¿è®¡ç®—é¢„ç®—å‡å°‘50%ï¼Œä¸æ²¡æœ‰å€¼å‡½æ•°çš„è½¨è¿¹ä¼˜åŒ–ç›¸æ¯”ï¼Œæ€§èƒ½ä¹Ÿæœ‰æ‰€æé«˜ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„çµå·§æ“ä½œè½¨è¿¹ä¼˜åŒ–æ–¹æ³•é€šå¸¸å°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºå¤šä¸ªå­ä»»åŠ¡ï¼Œæ¯ä¸ªå­ä»»åŠ¡å¯¹åº”ä¸€ç§æ¥è§¦æ¨¡å¼ï¼ˆå¦‚æ»šåŠ¨ã€æ»‘åŠ¨ç­‰ï¼‰ã€‚è¿™äº›å­ä»»åŠ¡è¢«ç‹¬ç«‹ä¼˜åŒ–ï¼Œå¿½ç•¥äº†å­ä»»åŠ¡ä¹‹é—´çš„ä¾èµ–å…³ç³»ã€‚è¿™ç§ç‹¬ç«‹ä¼˜åŒ–å¯èƒ½å¯¼è‡´ç³»ç»Ÿåœ¨å½“å‰å­ä»»åŠ¡ä¸­é™·å…¥å±€éƒ¨æœ€ä¼˜ï¼Œä½¿å¾—åç»­å­ä»»åŠ¡éš¾ä»¥å®Œæˆï¼Œæœ€ç»ˆå½±å“æ•´ä½“ä»»åŠ¡çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œå¯¹æ¯ä¸ªå­ä»»åŠ¡è¿›è¡Œä¼˜åŒ–éƒ½éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºï¼Œé™åˆ¶äº†ç®—æ³•çš„å®æ—¶æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šAVOçš„æ ¸å¿ƒæ€æƒ³æ˜¯å¼•å…¥ä¸€ä¸ªå­¦ä¹ çš„å€¼å‡½æ•°ï¼Œè¯¥å‡½æ•°èƒ½å¤Ÿé¢„æµ‹ä»å½“å‰çŠ¶æ€å‡ºå‘ï¼Œå®Œæˆæ•´ä¸ªä»»åŠ¡çš„é¢„æœŸå›æŠ¥ã€‚é€šè¿‡å°†è¿™ä¸ªå€¼å‡½æ•°çº³å…¥è½¨è¿¹ä¼˜åŒ–çš„æˆæœ¬å‡½æ•°ä¸­ï¼Œä¼˜åŒ–å™¨ä¸ä»…è€ƒè™‘å½“å‰æ­¥éª¤çš„æˆæœ¬ï¼Œè¿˜ä¼šè€ƒè™‘æœªæ¥æ­¥éª¤çš„æ½œåœ¨å›æŠ¥ã€‚å€¼å‡½æ•°çš„æ¢¯åº¦å¯ä»¥å¼•å¯¼ä¼˜åŒ–å™¨æœç€æ›´æœ‰åˆ©äºæœªæ¥ä»»åŠ¡å®Œæˆçš„çŠ¶æ€å‰è¿›ï¼Œä»è€Œæœ‰æ•ˆåœ°æ¡¥æ¥äº†å„ä¸ªå­ä»»åŠ¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAVOçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) è½¨è¿¹ä¼˜åŒ–å™¨ï¼šç”¨äºç”Ÿæˆåˆå§‹çš„è½¨è¿¹æ–¹æ¡ˆã€‚2) å€¼å‡½æ•°ç½‘ç»œï¼šç”¨äºé¢„æµ‹ä»å½“å‰çŠ¶æ€å‡ºå‘çš„æœªæ¥ä»»åŠ¡å›æŠ¥ã€‚3) æˆæœ¬å‡½æ•°èåˆï¼šå°†å€¼å‡½æ•°çš„è¾“å‡ºä¸ä¼ ç»Ÿçš„è½¨è¿¹ä¼˜åŒ–æˆæœ¬å‡½æ•°ç›¸ç»“åˆã€‚4) ä¼˜åŒ–è¿­ä»£ï¼šé€šè¿‡è¿­ä»£ä¼˜åŒ–ï¼Œä¸æ–­è°ƒæ•´è½¨è¿¹ï¼Œä½¿å…¶æ—¢èƒ½é™ä½å½“å‰æ­¥éª¤çš„æˆæœ¬ï¼Œåˆèƒ½æé«˜æœªæ¥çš„ä»»åŠ¡å›æŠ¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šAVOæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†å­¦ä¹ çš„å€¼å‡½æ•°å¼•å…¥åˆ°è½¨è¿¹ä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œä»è€Œå®ç°äº†å¯¹æœªæ¥ä»»åŠ¡çš„é¢„æµ‹å’ŒæŒ‡å¯¼ã€‚ä¸ä¼ ç»Ÿçš„ç‹¬ç«‹å­ä»»åŠ¡ä¼˜åŒ–æ–¹æ³•ç›¸æ¯”ï¼ŒAVOèƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†å­ä»»åŠ¡ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼Œé¿å…é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚æ­¤å¤–ï¼Œé€šè¿‡å€¼å‡½æ•°çš„å¼•å¯¼ï¼Œä¼˜åŒ–å™¨å¯ä»¥æ›´å¿«åœ°æ”¶æ•›åˆ°æœ€ä¼˜è§£ï¼Œä»è€Œé™ä½äº†è®¡ç®—æˆæœ¬ã€‚

**å…³é”®è®¾è®¡**ï¼šå€¼å‡½æ•°ç½‘ç»œé€šå¸¸é‡‡ç”¨æ·±åº¦ç¥ç»ç½‘ç»œç»“æ„ï¼Œè¾“å…¥æ˜¯å½“å‰çš„çŠ¶æ€ï¼ˆåŒ…æ‹¬å…³èŠ‚è§’åº¦ã€æ¥è§¦åŠ›ç­‰ï¼‰ï¼Œè¾“å‡ºæ˜¯æœªæ¥ä»»åŠ¡çš„é¢„æœŸå›æŠ¥ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡è‡³å…³é‡è¦ï¼Œé€šå¸¸é‡‡ç”¨æ—¶åºå·®åˆ†å­¦ä¹ ï¼ˆTemporal Difference Learningï¼‰æˆ–è’™ç‰¹å¡æ´›æ–¹æ³•ï¼ˆMonte Carlo Methodï¼‰æ¥è®­ç»ƒå€¼å‡½æ•°ã€‚è½¨è¿¹ä¼˜åŒ–å™¨å¯ä»¥ä½¿ç”¨å„ç§ç°æœ‰çš„ä¼˜åŒ–ç®—æ³•ï¼Œå¦‚iLQRã€SQPç­‰ã€‚æˆæœ¬å‡½æ•°çš„èåˆæ–¹å¼ä¹Ÿéœ€è¦ä»”ç»†è®¾è®¡ï¼Œä»¥å¹³è¡¡å½“å‰æ­¥éª¤çš„æˆæœ¬å’Œæœªæ¥ä»»åŠ¡çš„å›æŠ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒAVOåœ¨èºä¸åˆ€æŠ“å–å’Œè½¬åŠ¨ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚åœ¨ä»¿çœŸå’ŒçœŸå®æœºå™¨äººå®éªŒä¸­ï¼Œä¸æ²¡æœ‰å€¼å‡½æ•°çš„è½¨è¿¹ä¼˜åŒ–æ–¹æ³•ç›¸æ¯”ï¼ŒAVOåœ¨è®¡ç®—é¢„ç®—å‡å°‘50%çš„æƒ…å†µä¸‹ï¼Œä»ç„¶èƒ½å¤Ÿå–å¾—æ›´å¥½çš„æ€§èƒ½ã€‚è¿™è¡¨æ˜AVOèƒ½å¤Ÿæœ‰æ•ˆåœ°åŠ é€Ÿä¼˜åŒ–è¿‡ç¨‹ï¼Œå¹¶æé«˜ä»»åŠ¡çš„å®Œæˆè´¨é‡ã€‚å…·ä½“è€Œè¨€ï¼ŒAVOèƒ½å¤Ÿæ›´ç¨³å®šåœ°å®Œæˆèºä¸åˆ€çš„æŠ“å–å’Œè½¬åŠ¨ï¼Œå‡å°‘äº†æ“ä½œå¤±è´¥çš„æ¦‚ç‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

AVOå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚åœ¨æœºå™¨äººçµå·§æ“ä½œã€è‡ªåŠ¨åŒ–è£…é…ã€åŒ»ç–—æ‰‹æœ¯æœºå™¨äººç­‰é¢†åŸŸã€‚å®ƒå¯ä»¥æé«˜æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸‹çš„æ“ä½œèƒ½åŠ›å’Œæ•ˆç‡ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°å®Œæˆå„ç§ç²¾ç»†æ“ä½œä»»åŠ¡ã€‚æ­¤å¤–ï¼ŒAVOè¿˜å¯ä»¥åº”ç”¨äºå…¶ä»–éœ€è¦è¿›è¡Œåºåˆ—å†³ç­–çš„é—®é¢˜ï¼Œä¾‹å¦‚è‡ªåŠ¨é©¾é©¶ã€æ¸¸æˆAIç­‰ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Dexterous manipulation tasks often require switching between different contact modes, such as rolling, sliding, sticking, or non-contact contact modes. When formulating dexterous manipulation tasks as a trajectory optimization problem, a common approach is to decompose these tasks into sub-tasks for each contact mode, which are each solved independently. Optimizing each sub-task independently can limit performance, as optimizing contact points, contact forces, or other variables without information about future sub-tasks can place the system in a state from which it is challenging to make progress on subsequent sub-tasks. Further, optimizing these sub-tasks is very computationally expensive. To address these challenges, we propose Amortized Value Optimization (AVO), which introduces a learned value function that predicts the total future task performance. By incorporating this value function into the cost of the trajectory optimization at each planning step, the value function gradients guide the optimizer toward states that minimize the cost in future sub-tasks. This effectively bridges separately optimized sub-tasks, and accelerates the optimization by reducing the amount of online computation needed. We validate AVO on a screwdriver grasping and turning task in both simulation and real world experiments, and show improved performance even with 50% less computational budget compared to trajectory optimization without the value function.

