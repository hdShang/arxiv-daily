---
layout: default
title: RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training
---

# RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.06710" class="toolbar-btn" target="_blank">üìÑ arXiv: 2510.06710v1</a>
  <a href="https://arxiv.org/pdf/2510.06710.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.06710v1" onclick="toggleFavorite(this, '2510.06710v1', 'RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Hongzhi Zang, Mingjie Wei, Si Xu, Yongji Wu, Zhen Guo, Yuanqing Wang, Hao Lin, Liangzhi Shi, Yuqing Xie, Zhexuan Xu, Zhihao Liu, Kang Chen, Wenhao Tang, Quanlu Zhang, Weinan Zhang, Chao Yu, Yu Wang

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-08

**Â§áÊ≥®**: This is the technical report of the RLinf Team, focusing on the algorithm side. For the system-level design, please refer to arXiv:2509.15965. The open-sourced code link: https://github.com/RLinf/RLinf

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**RLinf-VLAÔºöÁî®‰∫éVLA+RLËÆ≠ÁªÉÁöÑÁªü‰∏ÄÈ´òÊïàÊ°ÜÊû∂**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâËØ≠Ë®ÄÂä®‰ΩúÊ®°Âûã` `Âº∫ÂåñÂ≠¶‰π†` `ÂÖ∑Ë∫´Êô∫ËÉΩ` `Êú∫Âô®‰∫∫ÊéßÂà∂` `Áªü‰∏ÄÊ°ÜÊû∂` `È´òÊïàËÆ≠ÁªÉ` `ËµÑÊ∫êÂàÜÈÖç`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâVLAÊ®°Âûã‰∏ªË¶Å‰æùËµñÁõëÁù£ÂæÆË∞ÉÔºåÊ≥õÂåñËÉΩÂäõÂèóÈôêÔºåÂº∫ÂåñÂ≠¶‰π†ËôΩÊúâÊΩúÂäõÔºå‰ΩÜÁº∫‰πèÁªü‰∏ÄÁöÑËÆ≠ÁªÉÂπ≥Âè∞„ÄÇ
2. RLinf-VLAÊ°ÜÊû∂ÈÄöËøáÁÅµÊ¥ªÁöÑËµÑÊ∫êÂàÜÈÖçÂíåÊ∑∑ÂêàÊµÅÊ∞¥Á∫øÔºåÈ´òÊïàÈõÜÊàêÊ∏≤Êüì„ÄÅËÆ≠ÁªÉÂíåÊé®ÁêÜÔºåÂä†ÈÄüVLAÊ®°ÂûãÁöÑRLËÆ≠ÁªÉ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåRLinf-VLAÂú®Â§ö‰∏™Ê®°ÊãüÂô®Âíå‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫Ëâ≤ÔºåÂπ∂Âú®ÁúüÂÆûÊú∫Âô®‰∫∫‰∏äÂ±ïÁé∞Âá∫ÊØîSFTÊõ¥Âº∫ÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËßÜËßâËØ≠Ë®ÄÂü∫Á°ÄÊ®°ÂûãÔºàVLAÔºâÁöÑÊúÄÊñ∞ËøõÂ±ïÊòæËëóÊèêÂçá‰∫ÜÂ§öÊ®°ÊÄÅÁêÜËß£„ÄÅÊé®ÁêÜÂíåÁîüÊàêËÉΩÂäõÔºåÊøÄÂèë‰∫Ü‰∫∫‰ª¨ÂØπÈÄöËøáËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÔºàVLAÔºâÊ®°ÂûãÂ∞ÜËøô‰∫õËÉΩÂäõÊâ©Â±ïÂà∞ÂÖ∑Ë∫´ÁéØÂ¢ÉÁöÑÂÖ¥Ë∂£„ÄÇÁÑ∂ËÄåÔºåÂ§ßÂ§öÊï∞VLAÊ®°Âûã‰ªçÁÑ∂ÈááÁî®ÁõëÁù£ÂæÆË∞ÉÔºàSFTÔºâËøõË°åËÆ≠ÁªÉÔºåÁî±‰∫éËØØÂ∑ÆÁ¥ØÁßØÔºåSFTÂú®ÂàÜÂ∏ÉÂÅèÁßª‰∏ãÈöæ‰ª•Ê≥õÂåñ„ÄÇÂº∫ÂåñÂ≠¶‰π†ÔºàRLÔºâÈÄöËøáÁõ¥Êé•‰ºòÂåñ‰∫§‰∫í‰∏≠ÁöÑ‰ªªÂä°ÊÄßËÉΩÊèê‰æõ‰∫Ü‰∏ÄÁßçÊúâÂ∏åÊúõÁöÑÊõø‰ª£ÊñπÊ°àÔºå‰ΩÜÁé∞ÊúâÁöÑÂ∞ùËØï‰ªçÁÑ∂ÊòØÂàÜÊï£ÁöÑÔºåÂπ∂‰∏îÁº∫‰πè‰∏Ä‰∏™Áªü‰∏ÄÁöÑÂπ≥Âè∞Ôºå‰ª•‰æøÂú®Ê®°ÂûãÊû∂ÊûÑÂíåÁÆóÊ≥ïËÆæËÆ°‰πãÈó¥ËøõË°åÂÖ¨Âπ≥ÂíåÁ≥ªÁªüÁöÑÊØîËæÉ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏ÄÂ∑ÆË∑ùÔºåÊàë‰ª¨Êé®Âá∫‰∫ÜRLinf-VLAÔºåËøôÊòØ‰∏Ä‰∏™Áî®‰∫éVLAÊ®°ÂûãÂèØÊâ©Â±ïRLËÆ≠ÁªÉÁöÑÁªü‰∏ÄÈ´òÊïàÊ°ÜÊû∂„ÄÇËØ•Á≥ªÁªüÈááÁî®È´òÂ∫¶ÁÅµÊ¥ªÁöÑËµÑÊ∫êÂàÜÈÖçËÆæËÆ°ÔºåËß£ÂÜ≥‰∫ÜÂú®RL+VLAËÆ≠ÁªÉ‰∏≠ÈõÜÊàêÊ∏≤Êüì„ÄÅËÆ≠ÁªÉÂíåÊé®ÁêÜÁöÑÊåëÊàò„ÄÇÁâπÂà´ÊòØÔºåÂØπ‰∫éGPUÂπ∂Ë°åÊ®°ÊãüÂô®ÔºåRLinf-VLAÂÆûÁé∞‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÊ∑∑ÂêàÁªÜÁ≤íÂ∫¶ÊµÅÊ∞¥Á∫øÂàÜÈÖçÊ®°ÂºèÔºåÂÆûÁé∞‰∫Ü1.61x-1.88xÁöÑËÆ≠ÁªÉÂä†ÈÄü„ÄÇÈÄöËøáÁªü‰∏ÄÁöÑÊé•Âè£ÔºåRLinf-VLAÊó†ÁºùÊîØÊåÅÂêÑÁßçVLAÊû∂ÊûÑÔºà‰æãÂ¶ÇÔºåOpenVLA„ÄÅOpenVLA-OFTÔºâ„ÄÅÂ§öÁßçRLÁÆóÊ≥ïÔºà‰æãÂ¶ÇÔºåPPO„ÄÅGRPOÔºâÂíåÂêÑÁßçÊ®°ÊãüÂô®Ôºà‰æãÂ¶ÇÔºåManiSkill„ÄÅLIBEROÔºâ„ÄÇÂú®Ê®°Êãü‰∏≠ÔºåÁªü‰∏ÄÊ®°ÂûãÂú®130‰∏™LIBERO‰ªªÂä°‰∏≠ÂÆûÁé∞‰∫Ü98.11%ÁöÑÊàêÂäüÁéáÔºåÂú®25‰∏™ManiSkill‰ªªÂä°‰∏≠ÂÆûÁé∞‰∫Ü97.66%ÁöÑÊàêÂäüÁéá„ÄÇÈô§‰∫ÜÁªèÈ™åÊÄßËÉΩ‰πãÂ§ñÔºåÊàë‰ª¨ÁöÑÁ†îÁ©∂ËøòÊèêÁÇº‰∫Ü‰∏ÄÂ•óÂ∞ÜRLÂ∫îÁî®‰∫éVLAËÆ≠ÁªÉÁöÑÊúÄ‰Ω≥ÂÆûË∑µÔºåÂπ∂ÈòêÊòé‰∫ÜËøôÁßçÈõÜÊàê‰∏≠Âá∫Áé∞ÁöÑÊñ∞Ê®°Âºè„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ËøòÂú®ÁúüÂÆûÁöÑFrankaÊú∫Âô®‰∫∫‰∏äËøõË°å‰∫ÜÂàùÊ≠•ÈÉ®ÁΩ≤ÔºåÂÖ∂‰∏≠RLËÆ≠ÁªÉÁöÑÁ≠ñÁï•ÊØîSFTËÆ≠ÁªÉÁöÑÁ≠ñÁï•Ë°®Áé∞Âá∫Êõ¥Âº∫ÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÊàë‰ª¨ËÆæÊÉ≥RLinf-VLAÂ∞ÜÊàê‰∏∫Âä†ÈÄüÂíåÊ†áÂáÜÂåñÂÖ∑Ë∫´Êô∫ËÉΩÁ†îÁ©∂ÁöÑÂü∫Á°Ä„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÔºàVLAÔºâÊ®°Âûã‰∏ªË¶ÅÈÄöËøáÁõëÁù£ÂæÆË∞ÉÔºàSFTÔºâËÆ≠ÁªÉÔºåËøôÁßçÊñπÊ≥ïÂú®Èù¢ÂØπÁéØÂ¢ÉÂèòÂåñÊó∂Ê≥õÂåñËÉΩÂäõËæÉÂº±ÔºåÂÆπÊòìÂá∫Áé∞ËØØÂ∑ÆÁ¥ØÁßØ„ÄÇÂº∫ÂåñÂ≠¶‰π†ÔºàRLÔºâËôΩÁÑ∂ÂèØ‰ª•ÈÄöËøá‰∏éÁéØÂ¢É‰∫§‰∫íÁõ¥Êé•‰ºòÂåñ‰ªªÂä°ÊÄßËÉΩÔºå‰ΩÜÁº∫‰πè‰∏Ä‰∏™Áªü‰∏ÄÁöÑÂπ≥Âè∞Êù•ÊîØÊåÅ‰∏çÂêåVLAÊû∂ÊûÑÂíåRLÁÆóÊ≥ïÁöÑÂÖ¨Âπ≥ÊØîËæÉÂíåÁ≥ªÁªüÁ†îÁ©∂„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöRLinf-VLAÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÊûÑÂª∫‰∏Ä‰∏™Áªü‰∏Ä‰∏îÈ´òÊïàÁöÑÊ°ÜÊû∂ÔºåÁî®‰∫éVLAÊ®°ÂûãÁöÑÂº∫ÂåñÂ≠¶‰π†ËÆ≠ÁªÉ„ÄÇËØ•Ê°ÜÊû∂ÈÄöËøáÁÅµÊ¥ªÁöÑËµÑÊ∫êÂàÜÈÖçÂíå‰ºòÂåñÁöÑÊµÅÊ∞¥Á∫øËÆæËÆ°ÔºåËß£ÂÜ≥‰∫ÜÂú®RL+VLAËÆ≠ÁªÉ‰∏≠ÈõÜÊàêÊ∏≤Êüì„ÄÅËÆ≠ÁªÉÂíåÊé®ÁêÜÁöÑÊåëÊàòÔºå‰ªéËÄåÂä†ÈÄüËÆ≠ÁªÉËøáÁ®ãÂπ∂ÊîØÊåÅÂ§öÁßçVLAÊû∂ÊûÑÂíåRLÁÆóÊ≥ï„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöRLinf-VLAÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ã‰∏ªË¶ÅÊ®°ÂùóÔºö1) ËµÑÊ∫êÂàÜÈÖçÊ®°ÂùóÔºöË¥üË¥£Ê†πÊçÆ‰ªªÂä°ÈúÄÊ±ÇÂíåÁ°¨‰ª∂ËµÑÊ∫êÔºåÁÅµÊ¥ªÂú∞ÂàÜÈÖçËÆ°ÁÆóËµÑÊ∫êÁªôÊ∏≤Êüì„ÄÅËÆ≠ÁªÉÂíåÊé®ÁêÜÁ≠â‰∏çÂêåÈò∂ÊÆµ„ÄÇ2) Ê∑∑ÂêàÁªÜÁ≤íÂ∫¶ÊµÅÊ∞¥Á∫øÔºöÈíàÂØπGPUÂπ∂Ë°åÊ®°ÊãüÂô®ÔºåÂÆûÁé∞‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÊµÅÊ∞¥Á∫øÊ®°ÂºèÔºå‰ª•ÊèêÈ´òËÆ≠ÁªÉÊïàÁéá„ÄÇ3) Áªü‰∏ÄÊé•Âè£ÔºöÊèê‰æõÁªü‰∏ÄÁöÑÊé•Âè£ÔºåÊîØÊåÅÂêÑÁßçVLAÊû∂ÊûÑÔºàÂ¶ÇOpenVLA„ÄÅOpenVLA-OFTÔºâ„ÄÅRLÁÆóÊ≥ïÔºàÂ¶ÇPPO„ÄÅGRPOÔºâÂíåÊ®°ÊãüÂô®ÔºàÂ¶ÇManiSkill„ÄÅLIBEROÔºâ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöRLinf-VLAÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂Áªü‰∏ÄÁöÑÊ°ÜÊû∂ËÆæËÆ°ÂíåÈ´òÊïàÁöÑËµÑÊ∫êÂàÜÈÖçÁ≠ñÁï•„ÄÇÂÆÉÈÄöËøáÁªü‰∏ÄÁöÑÊé•Âè£ÊîØÊåÅÂ§öÁßçVLAÊû∂ÊûÑ„ÄÅRLÁÆóÊ≥ïÂíåÊ®°ÊãüÂô®ÔºåÈôç‰Ωé‰∫ÜÁ†îÁ©∂‰∫∫ÂëòÁöÑÂºÄÂèëÊàêÊú¨„ÄÇÊ≠§Â§ñÔºåÊ∑∑ÂêàÁªÜÁ≤íÂ∫¶ÊµÅÊ∞¥Á∫øËÉΩÂ§üÂÖÖÂàÜÂà©Áî®GPUËµÑÊ∫êÔºåÊòæËëóÂä†ÈÄüËÆ≠ÁªÉËøáÁ®ã„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöRLinf-VLAÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) Ê∑∑ÂêàÁªÜÁ≤íÂ∫¶ÊµÅÊ∞¥Á∫øÔºöÈíàÂØπGPUÂπ∂Ë°åÊ®°ÊãüÂô®ÔºåÂ∞ÜÊØè‰∏™GPUÁöÑ‰ªªÂä°Ëøõ‰∏ÄÊ≠•ÁªÜÂàÜÔºåÂÆûÁé∞Êõ¥È´òÊïàÁöÑËµÑÊ∫êÂà©Áî®„ÄÇ2) Áªü‰∏ÄÊé•Âè£ÔºöÈÄöËøáÁªü‰∏ÄÁöÑÊé•Âè£ÔºåÁÆÄÂåñ‰∫Ü‰∏çÂêåVLAÊû∂ÊûÑ„ÄÅRLÁÆóÊ≥ïÂíåÊ®°ÊãüÂô®ÁöÑÈõÜÊàêËøáÁ®ã„ÄÇ3) ÁÅµÊ¥ªÁöÑËµÑÊ∫êÂàÜÈÖçÁ≠ñÁï•ÔºöÊ†πÊçÆ‰ªªÂä°ÈúÄÊ±ÇÂíåÁ°¨‰ª∂ËµÑÊ∫êÔºåÂä®ÊÄÅË∞ÉÊï¥Ê∏≤Êüì„ÄÅËÆ≠ÁªÉÂíåÊé®ÁêÜÁ≠âÈò∂ÊÆµÁöÑËµÑÊ∫êÂàÜÈÖç„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

RLinf-VLAÊ°ÜÊû∂Âú®Ê®°ÊãüÁéØÂ¢É‰∏≠ÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇÂú®130‰∏™LIBERO‰ªªÂä°‰∏≠ÔºåÁªü‰∏ÄÊ®°ÂûãÂÆûÁé∞‰∫Ü98.11%ÁöÑÊàêÂäüÁéáÔºåÂú®25‰∏™ManiSkill‰ªªÂä°‰∏≠ÂÆûÁé∞‰∫Ü97.66%ÁöÑÊàêÂäüÁéá„ÄÇÊ≠§Â§ñÔºåÂú®ÁúüÂÆûFrankaÊú∫Âô®‰∫∫‰∏äÁöÑÂàùÊ≠•ÈÉ®ÁΩ≤Ë°®ÊòéÔºåRLËÆ≠ÁªÉÁöÑÁ≠ñÁï•ÊØîSFTËÆ≠ÁªÉÁöÑÁ≠ñÁï•Ë°®Áé∞Âá∫Êõ¥Âº∫ÁöÑÊ≥õÂåñËÉΩÂäõÔºåËÆ≠ÁªÉÈÄüÂ∫¶ÊèêÂçá1.61x-1.88x„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

RLinf-VLAÊ°ÜÊû∂ÂèØÂπøÊ≥õÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫ÊéßÂà∂„ÄÅËá™Âä®È©æÈ©∂„ÄÅÊ∏∏ÊàèAIÁ≠âÈ¢ÜÂüü„ÄÇÂÆÉËÉΩÂ§üÂ∏ÆÂä©Á†îÁ©∂‰∫∫ÂëòÊõ¥È´òÊïàÂú∞ËÆ≠ÁªÉÂÖ∑ÊúâÊõ¥Âº∫Ê≥õÂåñËÉΩÂäõÁöÑVLAÊ®°ÂûãÔºå‰ªéËÄåÂÆûÁé∞Êõ¥Êô∫ËÉΩ„ÄÅÊõ¥Ëá™‰∏ªÁöÑÊú∫Âô®‰∫∫ÂíåÊô∫ËÉΩ‰Ωì„ÄÇËØ•Ê°ÜÊû∂ÁöÑÁªü‰∏ÄÊÄßÂíåÈ´òÊïàÊÄßÂ∞ÜÂä†ÈÄüÂÖ∑Ë∫´Êô∫ËÉΩÈ¢ÜÂüüÁöÑÁ†îÁ©∂ËøõÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Recent progress in vision and language foundation models has significantly advanced multimodal understanding, reasoning, and generation, inspiring a surge of interest in extending such capabilities to embodied settings through vision-language-action (VLA) models. Yet, most VLA models are still trained with supervised fine-tuning (SFT), which struggles to generalize under distribution shifts due to error accumulation. Reinforcement learning (RL) offers a promising alternative by directly optimizing task performance through interaction, but existing attempts remain fragmented and lack a unified platform for fair and systematic comparison across model architectures and algorithmic designs. To address this gap, we introduce RLinf-VLA, a unified and efficient framework for scalable RL training of VLA models. The system adopts a highly flexible resource allocation design that addresses the challenge of integrating rendering, training, and inference in RL+VLA training. In particular, for GPU-parallelized simulators, RLinf-VLA implements a novel hybrid fine-grained pipeline allocation mode, achieving a 1.61x-1.88x speedup in training. Through a unified interface, RLinf-VLA seamlessly supports diverse VLA architectures (e.g., OpenVLA, OpenVLA-OFT), multiple RL algorithms (e.g., PPO, GRPO), and various simulators (e.g., ManiSkill, LIBERO). In simulation, a unified model achieves 98.11\% across 130 LIBERO tasks and 97.66\% across 25 ManiSkill tasks. Beyond empirical performance, our study distills a set of best practices for applying RL to VLA training and sheds light on emerging patterns in this integration. Furthermore, we present preliminary deployment on a real-world Franka robot, where RL-trained policies exhibit stronger generalization than those trained with SFT. We envision RLinf-VLA as a foundation to accelerate and standardize research on embodied intelligence.

