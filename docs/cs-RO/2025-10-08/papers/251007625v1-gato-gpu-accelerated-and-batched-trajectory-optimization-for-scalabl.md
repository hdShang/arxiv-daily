---
layout: default
title: GATO: GPU-Accelerated and Batched Trajectory Optimization for Scalable Edge Model Predictive Control
---

# GATO: GPU-Accelerated and Batched Trajectory Optimization for Scalable Edge Model Predictive Control

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.07625" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.07625v1</a>
  <a href="https://arxiv.org/pdf/2510.07625.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.07625v1" onclick="toggleFavorite(this, '2510.07625v1', 'GATO: GPU-Accelerated and Batched Trajectory Optimization for Scalable Edge Model Predictive Control')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Alexander Du, Emre Adabag, Gabriel Bravo, Brian Plancher

**åˆ†ç±»**: cs.RO, eess.SY

**å‘å¸ƒæ—¥æœŸ**: 2025-10-08

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**GATOï¼šç”¨äºå¯æ‰©å±•è¾¹ç¼˜æ¨¡å‹é¢„æµ‹æ§åˆ¶çš„GPUåŠ é€Ÿæ‰¹é‡è½¨è¿¹ä¼˜åŒ–**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `æ¨¡å‹é¢„æµ‹æ§åˆ¶` `è½¨è¿¹ä¼˜åŒ–` `GPUåŠ é€Ÿ` `æ‰¹é‡æ±‚è§£` `å®æ—¶æ§åˆ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰GPUåŠ é€Ÿçš„è½¨è¿¹ä¼˜åŒ–æ–¹æ³•åœ¨å®æ—¶æ€§å’Œæ¨¡å‹é€šç”¨æ€§ä¸Šå­˜åœ¨å±€é™ï¼Œæ— æ³•æ»¡è¶³ä¸­ç­‰æ‰¹é‡å¤§å°çš„MPCåº”ç”¨éœ€æ±‚ã€‚
2. GATOé€šè¿‡ç®—æ³•ã€è½¯ä»¶å’Œç¡¬ä»¶ååŒè®¾è®¡ï¼Œåˆ©ç”¨å—çº§ã€warpçº§å’Œçº¿ç¨‹çº§å¹¶è¡Œæ€§ï¼Œå®ç°äº†GPUåŠ é€Ÿçš„æ‰¹é‡è½¨è¿¹ä¼˜åŒ–ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒGATOç›¸æ¯”CPUåŸºçº¿åŠ é€Ÿ18-21å€ï¼Œç›¸æ¯”GPUåŸºçº¿åŠ é€Ÿ1.4-16å€ï¼Œå¹¶åœ¨å·¥ä¸šæœºæ¢°è‡‚ä¸ŠéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ¨¡å‹é¢„æµ‹æ§åˆ¶(MPC)åœ¨æœºå™¨äººåº”ç”¨ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨çº¿æ±‚è§£éçº¿æ€§è½¨è¿¹ä¼˜åŒ–(TO)é—®é¢˜ä»ç„¶è®¡ç®—å¯†é›†ã€‚ç°æœ‰çš„GPUåŠ é€Ÿæ–¹æ³•é€šå¸¸(i)å¹¶è¡ŒåŒ–å•ä¸ªæ±‚è§£ä»¥æ»¡è¶³å®æ—¶æ€§è¦æ±‚ï¼Œ(ii)ä»¥ä½äºå®æ—¶çš„é€Ÿç‡æ‰©å±•åˆ°éå¸¸å¤§çš„æ‰¹æ¬¡ï¼Œæˆ–(iii)é€šè¿‡é™åˆ¶æ¨¡å‹é€šç”¨æ€§(ä¾‹å¦‚ï¼Œè´¨ç‚¹åŠ¨åŠ›å­¦æˆ–å•ä¸ªçº¿æ€§åŒ–)æ¥æé«˜é€Ÿåº¦ã€‚è¿™ä½¿å¾—è®¸å¤šéœ€è¦å®æ—¶å¤„ç†æ•°ååˆ°æ•°ç™¾ä¸ªæ‰¹æ¬¡æ±‚è§£çš„å…ˆè¿›MPCåº”ç”¨åœ¨æ±‚è§£å™¨æ€§èƒ½æ–¹é¢å­˜åœ¨å·¨å¤§å·®è·ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†GATOï¼Œä¸€ä¸ªå¼€æºçš„ã€GPUåŠ é€Ÿçš„ã€æ‰¹é‡TOæ±‚è§£å™¨ï¼Œå®ƒåœ¨ç®—æ³•ã€è½¯ä»¶å’Œè®¡ç®—ç¡¬ä»¶ä¸ŠååŒè®¾è®¡ï¼Œä¸ºè¿™äº›ä¸­ç­‰æ‰¹é‡å¤§å°çš„åœºæ™¯æä¾›å®æ—¶ååé‡ã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨å—çº§ã€warpçº§å’Œçº¿ç¨‹çº§å¹¶è¡Œæ€§ï¼Œåœ¨æ±‚è§£å†…éƒ¨å’Œè·¨æ±‚è§£ä¹‹é—´å®ç°è¶…é«˜æ€§èƒ½ã€‚æˆ‘ä»¬é€šè¿‡ä»¥ä¸‹æ–¹å¼è¯æ˜äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼šæ¨¡æ‹ŸåŸºå‡†æµ‹è¯•æ˜¾ç¤ºï¼Œéšç€æ‰¹æ¬¡å¤§å°çš„å¢åŠ ï¼Œç›¸å¯¹äºCPUåŸºçº¿åŠ é€Ÿ18-21å€ï¼Œç›¸å¯¹äºGPUåŸºçº¿åŠ é€Ÿ1.4-16å€ï¼›æ¡ˆä¾‹ç ”ç©¶çªå‡ºäº†æ”¹è¿›çš„æŠ—æ‰°åŠ¨æ€§å’Œæ”¶æ•›è¡Œä¸ºï¼›æœ€åæ˜¯åœ¨ä½¿ç”¨å·¥ä¸šæœºæ¢°è‡‚çš„ç¡¬ä»¶ä¸Šè¿›è¡ŒéªŒè¯ã€‚æˆ‘ä»¬å¼€æºGATOä»¥æ”¯æŒå¯é‡å¤æ€§å’Œé‡‡ç”¨ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼ˆMPCï¼‰ä¸­ï¼Œåœ¨çº¿æ±‚è§£æ‰¹é‡éçº¿æ€§è½¨è¿¹ä¼˜åŒ–ï¼ˆTOï¼‰é—®é¢˜æ—¶ï¼Œç°æœ‰GPUåŠ é€Ÿæ–¹æ³•æ— æ³•å…¼é¡¾å®æ—¶æ€§ã€æ¨¡å‹é€šç”¨æ€§å’Œä¸­ç­‰æ‰¹é‡å¤§å°å¤„ç†èƒ½åŠ›çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•è¦ä¹ˆåªèƒ½å¹¶è¡ŒåŒ–å•ä¸ªæ±‚è§£ï¼Œè¦ä¹ˆåªèƒ½å¤„ç†éå¸¸å¤§çš„æ‰¹æ¬¡ä½†é€Ÿåº¦è¾ƒæ…¢ï¼Œè¦ä¹ˆé™åˆ¶æ¨¡å‹é€šç”¨æ€§ï¼Œæ— æ³•æ»¡è¶³å®é™…åº”ç”¨éœ€æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šGATOçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨GPUçš„å¹¶è¡Œè®¡ç®—èƒ½åŠ›ï¼Œé€šè¿‡ç®—æ³•ã€è½¯ä»¶å’Œç¡¬ä»¶çš„ååŒè®¾è®¡ï¼Œå®ç°å¯¹ä¸­ç­‰æ‰¹é‡å¤§å°çš„è½¨è¿¹ä¼˜åŒ–é—®é¢˜è¿›è¡Œå®æ—¶æ±‚è§£ã€‚å®ƒé€šè¿‡åœ¨æ±‚è§£å†…éƒ¨å’Œè·¨æ±‚è§£ä¹‹é—´åˆ©ç”¨å—çº§ã€warpçº§å’Œçº¿ç¨‹çº§å¹¶è¡Œæ€§ï¼Œæœ€å¤§åŒ–GPUçš„åˆ©ç”¨ç‡ï¼Œä»è€Œæé«˜è®¡ç®—æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šGATOçš„æ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªå…³é”®éƒ¨åˆ†ï¼šé¦–å…ˆï¼Œå®ƒé‡‡ç”¨äº†ä¸€ç§é€‚åˆGPUå¹¶è¡Œè®¡ç®—çš„è½¨è¿¹ä¼˜åŒ–ç®—æ³•ã€‚å…¶æ¬¡ï¼Œå®ƒåœ¨è½¯ä»¶å±‚é¢é’ˆå¯¹GPUæ¶æ„è¿›è¡Œäº†ä¼˜åŒ–ï¼ŒåŒ…æ‹¬å†…å­˜è®¿é—®æ¨¡å¼å’Œçº¿ç¨‹è°ƒåº¦ã€‚æœ€åï¼Œå®ƒåœ¨ç¡¬ä»¶å±‚é¢å……åˆ†åˆ©ç”¨GPUçš„è®¡ç®—èµ„æºï¼Œä¾‹å¦‚CUDAæ ¸å¿ƒå’Œå…±äº«å†…å­˜ã€‚æ•´ä¸ªæ¡†æ¶çš„ç›®æ ‡æ˜¯å®ç°é«˜æ€§èƒ½çš„æ‰¹é‡è½¨è¿¹ä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šGATOçš„å…³é”®åˆ›æ–°åœ¨äºå…¶å¤šå±‚æ¬¡çš„å¹¶è¡Œç­–ç•¥ï¼ŒåŒ…æ‹¬å—çº§ã€warpçº§å’Œçº¿ç¨‹çº§å¹¶è¡Œã€‚è¿™ç§ç­–ç•¥èƒ½å¤Ÿå……åˆ†åˆ©ç”¨GPUçš„è®¡ç®—èµ„æºï¼Œä»è€Œå®ç°æ›´é«˜çš„è®¡ç®—æ•ˆç‡ã€‚æ­¤å¤–ï¼ŒGATOçš„ç®—æ³•ã€è½¯ä»¶å’Œç¡¬ä»¶ååŒè®¾è®¡ä¹Ÿæ˜¯ä¸€ä¸ªé‡è¦çš„åˆ›æ–°ç‚¹ï¼Œå®ƒèƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”GPUçš„æ¶æ„ç‰¹ç‚¹ï¼Œä»è€Œæé«˜æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šGATOçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š(1) é’ˆå¯¹GPUæ¶æ„ä¼˜åŒ–çš„å†…å­˜è®¿é—®æ¨¡å¼ï¼Œå‡å°‘å†…å­˜è®¿é—®å»¶è¿Ÿï¼›(2) ç²¾ç»†çš„çº¿ç¨‹è°ƒåº¦ç­–ç•¥ï¼Œé¿å…çº¿ç¨‹ä¹‹é—´çš„å†²çªï¼›(3) ä¼˜åŒ–çš„è½¨è¿¹ä¼˜åŒ–ç®—æ³•ï¼Œå‡å°‘è®¡ç®—é‡ï¼›(4) å¯é…ç½®çš„å‚æ•°è®¾ç½®ï¼Œå…è®¸ç”¨æˆ·æ ¹æ®å…·ä½“åº”ç”¨åœºæ™¯è°ƒæ•´æ±‚è§£å™¨çš„æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

GATOåœ¨æ¨¡æ‹ŸåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œç›¸å¯¹äºCPUåŸºçº¿åŠ é€Ÿ18-21å€ï¼Œç›¸å¯¹äºGPUåŸºçº¿åŠ é€Ÿ1.4-16å€ï¼ŒåŠ é€Ÿæ•ˆæœéšç€æ‰¹æ¬¡å¤§å°çš„å¢åŠ è€Œæ›´åŠ æ˜æ˜¾ã€‚æ¡ˆä¾‹ç ”ç©¶è¡¨æ˜ï¼ŒGATOèƒ½å¤Ÿæé«˜æŠ—æ‰°åŠ¨æ€§å’Œæ”¶æ•›è¡Œä¸ºã€‚æ­¤å¤–ï¼ŒGATOè¿˜åœ¨å·¥ä¸šæœºæ¢°è‡‚ä¸Šè¿›è¡Œäº†ç¡¬ä»¶éªŒè¯ï¼Œè¯æ˜äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

GATOé€‚ç”¨äºéœ€è¦å®æ—¶æ¨¡å‹é¢„æµ‹æ§åˆ¶çš„æœºå™¨äººåº”ç”¨ï¼Œä¾‹å¦‚å·¥ä¸šæœºæ¢°è‡‚æ§åˆ¶ã€è‡ªåŠ¨é©¾é©¶ã€æ— äººæœºæ§åˆ¶ç­‰ã€‚é€šè¿‡æé«˜è½¨è¿¹ä¼˜åŒ–é€Ÿåº¦ï¼ŒGATOå¯ä»¥ä½¿è¿™äº›åº”ç”¨æ›´åŠ ç¨³å®šã€é«˜æ•ˆå’Œå¯é ã€‚æ­¤å¤–ï¼ŒGATOçš„å¼€æºç‰¹æ€§ä¹Ÿæœ‰åŠ©äºæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„ç ”ç©¶å’Œå‘å±•ï¼Œä¿ƒè¿›æ›´å¤šåˆ›æ–°åº”ç”¨çš„å‡ºç°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While Model Predictive Control (MPC) delivers strong performance across robotics applications, solving the underlying (batches of) nonlinear trajectory optimization (TO) problems online remains computationally demanding. Existing GPU-accelerated approaches typically (i) parallelize a single solve to meet real-time deadlines, (ii) scale to very large batches at slower-than-real-time rates, or (iii) achieve speed by restricting model generality (e.g., point-mass dynamics or a single linearization). This leaves a large gap in solver performance for many state-of-the-art MPC applications that require real-time batches of tens to low-hundreds of solves. As such, we present GATO, an open source, GPU-accelerated, batched TO solver co-designed across algorithm, software, and computational hardware to deliver real-time throughput for these moderate batch size regimes. Our approach leverages a combination of block-, warp-, and thread-level parallelism within and across solves for ultra-high performance. We demonstrate the effectiveness of our approach through a combination of: simulated benchmarks showing speedups of 18-21x over CPU baselines and 1.4-16x over GPU baselines as batch size increases; case studies highlighting improved disturbance rejection and convergence behavior; and finally a validation on hardware using an industrial manipulator. We open source GATO to support reproducibility and adoption.

