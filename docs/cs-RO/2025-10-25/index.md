---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-10-25
---

# cs.ROï¼ˆ2025-10-25ï¼‰

ğŸ“Š å…± **9** ç¯‡è®ºæ–‡
 | ğŸ”— **3** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (4 ğŸ”—2)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2)</a>
<a href="#æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation" class="interest-badge">æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (4 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251022201v1-acg-action-coherence-guidance-for-flow-based-vla-models.html">ACG: Action Coherence Guidance for Flow-based VLA models</a></td>
  <td>æå‡ºåŠ¨ä½œè¿è´¯æ€§å¼•å¯¼ï¼ˆACGï¼‰æ–¹æ³•ï¼Œæå‡åŸºäºæµçš„VLAæ¨¡å‹åœ¨æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­çš„æ€§èƒ½</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">imitation learning</span> <span class="paper-tag">flow matching</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.22201v1" onclick="toggleFavorite(this, '2510.22201v1', 'ACG: Action Coherence Guidance for Flow-based VLA models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251022126v1-easyuuv-an-llm-enhanced-universal-and-lightweight-sim-to-real-reinfo.html">EasyUUV: An LLM-Enhanced Universal and Lightweight Sim-to-Real Reinforcement Learning Framework for UUV Attitude Control</a></td>
  <td>EasyUUVï¼šåŸºäºLLMçš„é€šç”¨è½»é‡çº§UUVå§¿æ€æ§åˆ¶Sim-to-Realå¼ºåŒ–å­¦ä¹ æ¡†æ¶</td>
  <td class="tags-cell"><span class="paper-tag">sim-to-real</span> <span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.22126v1" onclick="toggleFavorite(this, '2510.22126v1', 'EasyUUV: An LLM-Enhanced Universal and Lightweight Sim-to-Real Reinforcement Learning Framework for UUV Attitude Control')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251022336v2-toward-humanoid-brain-body-co-design-joint-optimization-of-control-a.html">Toward Humanoid Brain-Body Co-design: Joint Optimization of Control and Morphology for Fall Recovery</a></td>
  <td>æå‡ºRoboCraftæ¡†æ¶ï¼Œè”åˆä¼˜åŒ–äººå½¢æœºå™¨äººæ§åˆ¶ä¸å½¢æ€ï¼Œæå‡è·Œå€’æ¢å¤èƒ½åŠ›ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid robot</span> <span class="paper-tag">locomotion</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.22336v2" onclick="toggleFavorite(this, '2510.22336v2', 'Toward Humanoid Brain-Body Co-design: Joint Optimization of Control and Morphology for Fall Recovery')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251022113v1-raycastgrasp-eye-gaze-interaction-with-wearable-devices-for-robotic-.html">RaycastGrasp: Eye-Gaze Interaction with Wearable Devices for Robotic Manipulation</a></td>
  <td>RaycastGraspï¼šåŸºäºçœ¼åŠ¨è¿½è¸ªä¸å¯ç©¿æˆ´è®¾å¤‡çš„æœºå™¨äººæ“ä½œäº¤äº’</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">egocentric</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.22113v1" onclick="toggleFavorite(this, '2510.22113v1', 'RaycastGrasp: Eye-Gaze Interaction with Wearable Devices for Robotic Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>5</td>
  <td><a href="./papers/251022370v1-blip-fuseppo-a-vision-language-deep-reinforcement-learning-framework.html">BLIP-FusePPO: A Vision-Language Deep Reinforcement Learning Framework for Lane Keeping in Autonomous Vehicles</a></td>
  <td>æå‡ºBLIP-FusePPOæ¡†æ¶ä»¥è§£å†³è‡ªåŠ¨é©¾é©¶è½¦è¾†çš„è½¦é“ä¿æŒé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">deep reinforcement learning</span> <span class="paper-tag">policy learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.22370v1" onclick="toggleFavorite(this, '2510.22370v1', 'BLIP-FusePPO: A Vision-Language Deep Reinforcement Learning Framework for Lane Keeping in Autonomous Vehicles')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251022420v1-a-novel-multi-timescale-stability-preserving-hierarchical-reinforcem.html">A Novel Multi-Timescale Stability-Preserving Hierarchical Reinforcement Learning Controller Framework for Adaptive Control in High-Dimensional Dynamical Systems</a></td>
  <td>æå‡ºå¤šæ—¶é—´å°ºåº¦ç¨³å®šæ€§ä¿æŒçš„å±‚æ¬¡å¼ºåŒ–å­¦ä¹ æ§åˆ¶æ¡†æ¶ä»¥è§£å†³é«˜ç»´åŠ¨æ€ç³»ç»Ÿæ§åˆ¶é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.22420v1" onclick="toggleFavorite(this, '2510.22420v1', 'A Novel Multi-Timescale Stability-Preserving Hierarchical Reinforcement Learning Controller Framework for Adaptive Control in High-Dimensional Dynamical Systems')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation">ğŸ”¬ æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>7</td>
  <td><a href="./papers/251022339v1-estimating-continuum-robot-shape-under-external-loading-using-spatio.html">Estimating Continuum Robot Shape under External Loading using Spatiotemporal Neural Networks</a></td>
  <td>æå‡ºæ—¶ç©ºç¥ç»ç½‘ç»œï¼Œèåˆå¤šæ¨¡æ€æ•°æ®ï¼Œç²¾ç¡®ä¼°è®¡å—è½½è¿ç»­ä½“æœºå™¨äººçš„å½¢çŠ¶</td>
  <td class="tags-cell"><span class="paper-tag">spatiotemporal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.22339v1" onclick="toggleFavorite(this, '2510.22339v1', 'Estimating Continuum Robot Shape under External Loading using Spatiotemporal Neural Networks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>8</td>
  <td><a href="./papers/251022313v1-breaking-the-static-assumption-a-dynamic-aware-lio-framework-via-spa.html">Breaking the Static Assumption: A Dynamic-Aware LIO Framework Via Spatio-Temporal Normal Analysis</a></td>
  <td>æå‡ºåŸºäºæ—¶ç©ºæ³•çº¿åˆ†æçš„åŠ¨æ€æ„ŸçŸ¥LIOæ¡†æ¶ï¼Œè§£å†³åŠ¨æ€ç¯å¢ƒä¸‹å®šä½éš¾é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">LIO</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.22313v1" onclick="toggleFavorite(this, '2510.22313v1', 'Breaking the Static Assumption: A Dynamic-Aware LIO Framework Via Spatio-Temporal Normal Analysis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>9</td>
  <td><a href="./papers/251022204v1-bridging-perception-and-reasoning-dual-pipeline-neuro-symbolic-landi.html">Bridging Perception and Reasoning: Dual-Pipeline Neuro-Symbolic Landing for UAVs in Cluttered Environments</a></td>
  <td>NeuroSymLandï¼šç»“åˆç¥ç»ç¬¦å·æ¨ç†ï¼Œæå‡æ— äººæœºåœ¨å¤æ‚ç¯å¢ƒä¸‹çš„è‡ªä¸»ç€é™†èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.22204v1" onclick="toggleFavorite(this, '2510.22204v1', 'Bridging Perception and Reasoning: Dual-Pipeline Neuro-Symbolic Landing for UAVs in Cluttered Environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)