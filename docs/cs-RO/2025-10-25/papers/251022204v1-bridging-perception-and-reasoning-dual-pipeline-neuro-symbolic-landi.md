---
layout: default
title: Bridging Perception and Reasoning: Dual-Pipeline Neuro-Symbolic Landing for UAVs in Cluttered Environments
---

# Bridging Perception and Reasoning: Dual-Pipeline Neuro-Symbolic Landing for UAVs in Cluttered Environments

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.22204" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.22204v1</a>
  <a href="https://arxiv.org/pdf/2510.22204.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.22204v1" onclick="toggleFavorite(this, '2510.22204v1', 'Bridging Perception and Reasoning: Dual-Pipeline Neuro-Symbolic Landing for UAVs in Cluttered Environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Weixian Qian, Sebastian Schroder, Yao Deng, Jiaohong Yao, Linfeng Liang, Xiao Cheng, Richard Han, Xi Zheng

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-10-25

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**NeuroSymLandï¼šç»“åˆç¥ç»ç¬¦å·æ¨ç†ï¼Œæå‡æ— äººæœºåœ¨å¤æ‚ç¯å¢ƒä¸‹çš„è‡ªä¸»ç€é™†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ— äººæœºè‡ªä¸»ç€é™†` `ç¥ç»ç¬¦å·æ¨ç†` `è¯­ä¹‰åˆ†å‰²` `å¤§å‹è¯­è¨€æ¨¡å‹` `çŸ¥è¯†è¡¨ç¤º` `æ¼”ç»æ¨ç†` `éç»“æ„åŒ–ç¯å¢ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ— äººæœºè‡ªä¸»ç€é™†æ–¹æ³•åœ¨å¤æ‚ç¯å¢ƒä¸‹è¡¨ç°ä¸ä½³ï¼Œçº¯è§†è§‰æˆ–æ·±åº¦å­¦ä¹ æ¨¡å‹æ³›åŒ–èƒ½åŠ›æœ‰é™ï¼Œç¼ºä¹å¯è§£é‡Šæ€§ã€‚
2. NeuroSymLandç»“åˆç¥ç»æ„ŸçŸ¥å’Œç¬¦å·æ¨ç†ï¼Œåˆ©ç”¨LLMç”Ÿæˆå¯éªŒè¯çš„Scallopä»£ç ï¼Œå¹¶ä½¿ç”¨è½»é‡çº§åŸºç¡€æ¨¡å‹è¿›è¡Œå®æ—¶æ¨ç†ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒNeuroSymLandåœ¨å‡†ç¡®ç‡ã€é²æ£’æ€§å’Œæ•ˆç‡æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæå‡äº†æ— äººæœºç€é™†çš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºNeuroSymLandï¼Œä¸€ç§ç¥ç»ç¬¦å·æ¡†æ¶ï¼Œç”¨äºæå‡æ— äººæœºåœ¨éç»“æ„åŒ–ç¯å¢ƒï¼ˆæ‚ä¹±ã€ä¸å¹³å¦ã€ç¼ºä¹åœ°å›¾ä¿¡æ¯ï¼‰ä¸‹çš„è‡ªä¸»ç€é™†èƒ½åŠ›ã€‚è¯¥æ¡†æ¶ç´§å¯†è€¦åˆä¸¤ä¸ªäº’è¡¥çš„æµç¨‹ï¼šï¼ˆ1ï¼‰ç¦»çº¿æµç¨‹ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œäººæœºåä½œï¼Œä»å„ç§ç€é™†åœºæ™¯ä¸­åˆæˆScallopä»£ç ï¼Œæç‚¼é€šç”¨ä¸”å¯éªŒè¯çš„ç¬¦å·çŸ¥è¯†ï¼›ï¼ˆ2ï¼‰åœ¨çº¿æµç¨‹ï¼Œåˆ©ç”¨è½»é‡çº§çš„åŸºç¡€æ¨¡å‹è¿›è¡Œè¯­ä¹‰åˆ†å‰²ï¼Œç”Ÿæˆæ¦‚ç‡æ€§çš„Scallopäº‹å®ï¼Œå¹¶å°†å…¶ç»„åˆæˆè¯­ä¹‰åœºæ™¯å›¾ï¼Œç”¨äºå®æ—¶æ¼”ç»æ¨ç†ã€‚è¿™ç§è®¾è®¡ç»“åˆäº†è½»é‡çº§åŸºç¡€æ¨¡å‹çš„æ„ŸçŸ¥èƒ½åŠ›ä¸ç¬¦å·æ¨ç†çš„å¯è§£é‡Šæ€§å’Œå¯éªŒè¯æ€§ã€‚èŠ‚ç‚¹å±æ€§ï¼ˆå¦‚å¹³å¦åº¦ã€é¢ç§¯ï¼‰å’Œè¾¹å…³ç³»ï¼ˆé‚»æ¥ã€åŒ…å«ã€é‚»è¿‘ï¼‰é€šè¿‡å‡ ä½•ä¾‹ç¨‹è®¡ç®—ï¼Œè€Œéå­¦ä¹ å¾—åˆ°ï¼Œé¿å…äº†è®­ç»ƒæ—¶å›¾æ„å»ºå™¨çš„æ•°æ®ä¾èµ–æ€§å’Œå»¶è¿Ÿã€‚ç”Ÿæˆçš„Scallopç¨‹åºç¼–ç äº†ç€é™†åŸåˆ™ï¼ˆé¿å¼€æ°´åŸŸå’Œéšœç¢ç‰©ï¼›åå¥½å¤§å‹ã€å¹³å¦ã€å¯è¾¾çš„åŒºåŸŸï¼‰ï¼Œå¹¶äº§ç”Ÿæ ¡å‡†åçš„å®‰å…¨è¯„åˆ†ï¼Œä»¥åŠæ’åºåçš„æ„Ÿå…´è¶£åŒºåŸŸï¼ˆROIsï¼‰å’Œäººç±»å¯è¯»çš„ç†ç”±ã€‚åœ¨æ•°æ®é›†ã€å¤šæ ·åŒ–çš„æ¨¡æ‹Ÿåœ°å›¾å’ŒçœŸå®æ— äººæœºç¡¬ä»¶ä¸Šçš„å¤§é‡è¯„ä¼°è¡¨æ˜ï¼ŒNeuroSymLandç›¸æ¯”æœ€å…ˆè¿›çš„åŸºçº¿æ–¹æ³•ï¼Œå®ç°äº†æ›´é«˜çš„å‡†ç¡®ç‡ã€æ›´å¼ºçš„åå˜é‡åç§»é²æ£’æ€§å’Œæ›´ä¼˜è¶Šçš„æ•ˆç‡ï¼ŒåŒæ—¶æé«˜äº†æ— äººæœºåœ¨åº”æ€¥å“åº”ã€ç›‘è§†å’Œäº¤ä»˜ä»»åŠ¡ä¸­çš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæ— äººæœºåœ¨éç»“æ„åŒ–ç¯å¢ƒä¸­è‡ªä¸»ç€é™†æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ã€‚ç°æœ‰çš„çº¯è§†è§‰æˆ–æ·±åº¦å­¦ä¹ æ–¹æ³•åœ¨é¢å¯¹ç¯å¢ƒå˜åŒ–æ—¶ï¼Œæ³›åŒ–èƒ½åŠ›è¾ƒå¼±ï¼Œå®¹æ˜“å‡ºç°é”™è¯¯ï¼Œå¹¶ä¸”ç¼ºä¹å¯è§£é‡Šæ€§ï¼Œéš¾ä»¥ä¿è¯å®‰å…¨æ€§ã€‚è¿™äº›æ–¹æ³•é€šå¸¸ä¾èµ–å¤§é‡æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œå¹¶ä¸”éš¾ä»¥å¤„ç†æœªçŸ¥çš„ç¯å¢ƒæ¡ä»¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šNeuroSymLandçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†ç¥ç»æ„ŸçŸ¥å’Œç¬¦å·æ¨ç†ç›¸ç»“åˆï¼Œåˆ©ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹è¿›è¡Œç¯å¢ƒæ„ŸçŸ¥ï¼Œæå–è¯­ä¹‰ä¿¡æ¯ï¼Œç„¶ååˆ©ç”¨ç¬¦å·æ¨ç†è¿›è¡Œå†³ç­–ï¼Œç”Ÿæˆå¯è§£é‡Šçš„ç€é™†æ–¹æ¡ˆã€‚è¿™ç§æ–¹æ³•ç»“åˆäº†æ·±åº¦å­¦ä¹ çš„æ„ŸçŸ¥èƒ½åŠ›å’Œç¬¦å·æ¨ç†çš„å¯è§£é‡Šæ€§å’Œå¯éªŒè¯æ€§ï¼Œä»è€Œæé«˜äº†æ— äººæœºåœ¨å¤æ‚ç¯å¢ƒä¸‹çš„è‡ªä¸»ç€é™†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šNeuroSymLandåŒ…å«ä¸¤ä¸ªä¸»è¦æµç¨‹ï¼šç¦»çº¿æµç¨‹å’Œåœ¨çº¿æµç¨‹ã€‚ç¦»çº¿æµç¨‹åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œäººæœºåä½œï¼Œä»å„ç§ç€é™†åœºæ™¯ä¸­åˆæˆScallopä»£ç ï¼Œæç‚¼é€šç”¨ä¸”å¯éªŒè¯çš„ç¬¦å·çŸ¥è¯†ã€‚åœ¨çº¿æµç¨‹åˆ©ç”¨è½»é‡çº§çš„åŸºç¡€æ¨¡å‹è¿›è¡Œè¯­ä¹‰åˆ†å‰²ï¼Œç”Ÿæˆæ¦‚ç‡æ€§çš„Scallopäº‹å®ï¼Œå¹¶å°†å…¶ç»„åˆæˆè¯­ä¹‰åœºæ™¯å›¾ï¼Œç”¨äºå®æ—¶æ¼”ç»æ¨ç†ã€‚ä¸¤ä¸ªæµç¨‹ç´§å¯†è€¦åˆï¼Œå…±åŒå®Œæˆæ— äººæœºçš„è‡ªä¸»ç€é™†ä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šNeuroSymLandçš„å…³é”®åˆ›æ–°åœ¨äºå°†ç¥ç»æ„ŸçŸ¥å’Œç¬¦å·æ¨ç†ç´§å¯†ç»“åˆï¼Œåˆ©ç”¨LLMç”Ÿæˆå¯éªŒè¯çš„Scallopä»£ç ï¼Œå¹¶ä½¿ç”¨è½»é‡çº§åŸºç¡€æ¨¡å‹è¿›è¡Œå®æ—¶æ¨ç†ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•ä½¿ç”¨å‡ ä½•ä¾‹ç¨‹è®¡ç®—èŠ‚ç‚¹å±æ€§å’Œè¾¹å…³ç³»ï¼Œé¿å…äº†è®­ç»ƒæ—¶å›¾æ„å»ºå™¨çš„æ•°æ®ä¾èµ–æ€§å’Œå»¶è¿Ÿã€‚è¿™ç§è®¾è®¡æé«˜äº†æ— äººæœºåœ¨å¤æ‚ç¯å¢ƒä¸‹çš„è‡ªä¸»ç€é™†èƒ½åŠ›ï¼Œå¹¶ä¿è¯äº†å®‰å…¨æ€§å’Œå¯é æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šNeuroSymLandçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š(1) ä½¿ç”¨LLMç”ŸæˆScallopä»£ç ï¼Œç¼–ç ç€é™†åŸåˆ™ï¼›(2) ä½¿ç”¨è½»é‡çº§åŸºç¡€æ¨¡å‹è¿›è¡Œè¯­ä¹‰åˆ†å‰²ï¼Œç”Ÿæˆæ¦‚ç‡æ€§çš„Scallopäº‹å®ï¼›(3) ä½¿ç”¨å‡ ä½•ä¾‹ç¨‹è®¡ç®—èŠ‚ç‚¹å±æ€§å’Œè¾¹å…³ç³»ï¼›(4) ä½¿ç”¨Scallopç¨‹åºè¿›è¡Œæ¼”ç»æ¨ç†ï¼Œç”Ÿæˆæ ¡å‡†åçš„å®‰å…¨è¯„åˆ†å’Œæ’åºåçš„æ„Ÿå…´è¶£åŒºåŸŸï¼ˆROIsï¼‰ã€‚è¿™äº›è®¾è®¡å…±åŒä¿è¯äº†NeuroSymLandçš„å‡†ç¡®æ€§ã€é²æ£’æ€§å’Œæ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒNeuroSymLandåœ¨æ•°æ®é›†ã€å¤šæ ·åŒ–çš„æ¨¡æ‹Ÿåœ°å›¾å’ŒçœŸå®æ— äººæœºç¡¬ä»¶ä¸Šçš„å¤§é‡è¯„ä¼°ä¸­ï¼Œç›¸æ¯”æœ€å…ˆè¿›çš„åŸºçº¿æ–¹æ³•ï¼Œå®ç°äº†æ›´é«˜çš„å‡†ç¡®ç‡ã€æ›´å¼ºçš„åå˜é‡åç§»é²æ£’æ€§å’Œæ›´ä¼˜è¶Šçš„æ•ˆç‡ã€‚å…·ä½“æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†å±•ç¤ºï¼Œè¯æ˜äº†NeuroSymLandçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

NeuroSymLandå¯åº”ç”¨äºåº”æ€¥å“åº”ã€ç›‘è§†å’Œäº¤ä»˜ç­‰é¢†åŸŸã€‚åœ¨åº”æ€¥å“åº”ä¸­ï¼Œæ— äººæœºå¯ä»¥è‡ªä¸»ç€é™†åœ¨å¤æ‚ç¯å¢ƒä¸­ï¼Œå¿«é€Ÿåˆ°è¾¾æ•‘æ´ç°åœºã€‚åœ¨ç›‘è§†ä»»åŠ¡ä¸­ï¼Œæ— äººæœºå¯ä»¥è‡ªä¸»é€‰æ‹©å®‰å…¨çš„ç€é™†ç‚¹ï¼Œè¿›è¡Œé•¿æ—¶é—´çš„ç›‘è§†ã€‚åœ¨äº¤ä»˜ä»»åŠ¡ä¸­ï¼Œæ— äººæœºå¯ä»¥è‡ªä¸»ç€é™†åœ¨ç”¨æˆ·æŒ‡å®šçš„åœ°ç‚¹ï¼Œå®ŒæˆåŒ…è£¹çš„äº¤ä»˜ã€‚è¯¥ç ”ç©¶æˆæœæœ‰åŠ©äºæé«˜æ— äººæœºåœ¨å„ç§å®é™…åº”ç”¨ä¸­çš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Autonomous landing in unstructured (cluttered, uneven, and map-poor) environments is a core requirement for Unmanned Aerial Vehicles (UAVs), yet purely vision-based or deep learning models often falter under covariate shift and provide limited interpretability. We propose NeuroSymLand, a neuro-symbolic framework that tightly couples two complementary pipelines: (i) an offline pipeline, where Large Language Models (LLMs) and human-in-the-loop refinement synthesize Scallop code from diverse landing scenarios, distilling generalizable and verifiable symbolic knowledge; and (ii) an online pipeline, where a compact foundation-based semantic segmentation model generates probabilistic Scallop facts that are composed into semantic scene graphs for real-time deductive reasoning. This design combines the perceptual strengths of lightweight foundation models with the interpretability and verifiability of symbolic reasoning. Node attributes (e.g., flatness, area) and edge relations (adjacency, containment, proximity) are computed with geometric routines rather than learned, avoiding the data dependence and latency of train-time graph builders. The resulting Scallop program encodes landing principles (avoid water and obstacles; prefer large, flat, accessible regions) and yields calibrated safety scores with ranked Regions of Interest (ROIs) and human-readable justifications. Extensive evaluations across datasets, diverse simulation maps, and real UAV hardware show that NeuroSymLand achieves higher accuracy, stronger robustness to covariate shift, and superior efficiency compared with state-of-the-art baselines, while advancing UAV safety and reliability in emergency response, surveillance, and delivery missions.

