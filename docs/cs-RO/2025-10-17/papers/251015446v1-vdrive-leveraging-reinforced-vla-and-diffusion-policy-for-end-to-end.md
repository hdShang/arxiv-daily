---
layout: default
title: VDRive: Leveraging Reinforced VLA and Diffusion Policy for End-to-end Autonomous Driving
---

# VDRive: Leveraging Reinforced VLA and Diffusion Policy for End-to-end Autonomous Driving

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.15446" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.15446v1</a>
  <a href="https://arxiv.org/pdf/2510.15446.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.15446v1" onclick="toggleFavorite(this, '2510.15446v1', 'VDRive: Leveraging Reinforced VLA and Diffusion Policy for End-to-end Autonomous Driving')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ziang Guo, Zufeng Zhang

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-10-17

**å¤‡æ³¨**: 1st version

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**VDRiveï¼šåˆ©ç”¨å¼ºåŒ–VLAå’Œæ‰©æ•£ç­–ç•¥å®ç°ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è‡ªåŠ¨é©¾é©¶` `ç«¯åˆ°ç«¯å­¦ä¹ ` `è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹` `æ‰©æ•£ç­–ç•¥` `å¼ºåŒ–å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è‡ªåŠ¨é©¾é©¶æ–¹æ³•åœ¨åŠ¨æ€ç¯å¢ƒå’Œæç«¯æƒ…å†µä¸‹ï¼Œè½¦è¾†çŠ¶æ€ç†è§£å’Œå†³ç­–çš„é²æ£’æ€§é¢ä¸´æŒ‘æˆ˜ã€‚
2. VDRiveé€šè¿‡å»ºæ¨¡çŠ¶æ€-åŠ¨ä½œæ˜ å°„ï¼Œç»“åˆè§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹å’Œæ‰©æ•£ç­–ç•¥ï¼Œå®ç°è¯­å¢ƒå’Œå‡ ä½•ä¸Šçš„é©¾é©¶å¼•å¯¼ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒVDRiveåœ¨Bench2Driveå’ŒnuScenesæ•°æ®é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶æµç¨‹VDRiveï¼Œå®ƒé€šè¿‡æ˜¾å¼åœ°å»ºæ¨¡çŠ¶æ€-åŠ¨ä½œæ˜ å°„æ¥è§£å†³åŠ¨æ€ç¯å¢ƒå’Œæç«¯æƒ…å†µå¯¹è‡ªåŠ¨é©¾é©¶é²æ£’æ€§çš„æŒ‘æˆ˜ï¼Œä»è€Œå®ç°å¯è§£é‡Šå’Œé²æ£’çš„å†³ç­–ã€‚VDRiveåˆ©ç”¨è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹(VLA)åœ¨çŠ¶æ€ç†è§£æ–¹é¢çš„ä¼˜åŠ¿ï¼Œå¹¶ç»“åˆåŸºäºç”Ÿæˆæ‰©æ•£ç­–ç•¥çš„åŠ¨ä½œå¤´ï¼Œä»è€Œåœ¨è¯­å¢ƒå’Œå‡ ä½•ä¸Šå¼•å¯¼é©¾é©¶ã€‚åœ¨è¯­å¢ƒä¸Šï¼ŒVLAé€šè¿‡tokenç”Ÿæˆé¢„è®­ç»ƒæ¥é¢„æµ‹æœªæ¥çš„è§‚æµ‹ï¼Œè¿™äº›è§‚æµ‹é€šè¿‡æ¡ä»¶å‘é‡é‡åŒ–å˜åˆ†è‡ªç¼–ç å™¨(CVQ-VAE)è¡¨ç¤ºä¸ºç¦»æ•£ä»£ç ã€‚åœ¨å‡ ä½•ä¸Šï¼Œæˆ‘ä»¬å¯¹VLAè¿›è¡Œå¼ºåŒ–å­¦ä¹ å¾®è°ƒï¼Œä»¥åŸºäºå½“å‰çš„é©¾é©¶æ¡ä»¶é¢„æµ‹æœªæ¥çš„è½¨è¿¹å’ŒåŠ¨ä½œã€‚VLAä¸ºåŠ¨ä½œç­–ç•¥å¤´æä¾›å½“å‰çŠ¶æ€tokenå’Œé¢„æµ‹çŠ¶æ€tokenï¼Œä»¥ç”Ÿæˆåˆ†å±‚åŠ¨ä½œå’Œè½¨è¿¹ã€‚åœ¨ç­–ç•¥è®­ç»ƒæœŸé—´ï¼Œä¸€ä¸ªå­¦ä¹ åˆ°çš„è¯„è®ºå®¶è¯„ä¼°ç­–ç•¥ç”Ÿæˆçš„åŠ¨ä½œï¼Œå¹¶æä¾›åŸºäºæ¢¯åº¦çš„åé¦ˆï¼Œå½¢æˆä¸€ä¸ªactor-criticæ¡†æ¶ï¼Œä»è€Œå®ç°åŸºäºå¼ºåŒ–çš„ç­–ç•¥å­¦ä¹ æµç¨‹ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„VDRiveåœ¨Bench2Driveé—­ç¯åŸºå‡†æµ‹è¯•å’ŒnuSceneså¼€ç¯è§„åˆ’ä¸­éƒ½å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè‡ªåŠ¨é©¾é©¶é¢ä¸´åŠ¨æ€ç¯å¢ƒå’Œæç«¯æƒ…å†µå¸¦æ¥çš„æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•åœ¨çŠ¶æ€ç†è§£å’Œå†³ç­–æ–¹é¢é²æ£’æ€§ä¸è¶³ï¼Œéš¾ä»¥åº”å¯¹å¤æ‚åœºæ™¯ã€‚è®ºæ–‡æ—¨åœ¨è§£å†³ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶ä¸­çŠ¶æ€ç†è§£å’Œå†³ç­–çš„é²æ£’æ€§é—®é¢˜ï¼Œæå‡è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ï¼ˆVLAï¼‰è¿›è¡ŒçŠ¶æ€ç†è§£ï¼Œå¹¶ç»“åˆç”Ÿæˆæ‰©æ•£ç­–ç•¥è¿›è¡ŒåŠ¨ä½œé¢„æµ‹ï¼Œä»è€Œå®ç°è¯­å¢ƒå’Œå‡ ä½•ä¸Šçš„é©¾é©¶å¼•å¯¼ã€‚é€šè¿‡æ˜¾å¼å»ºæ¨¡çŠ¶æ€-åŠ¨ä½œæ˜ å°„ï¼Œæé«˜å†³ç­–çš„å¯è§£é‡Šæ€§å’Œé²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVDRiveçš„æ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) åŸºäºæ¡ä»¶å‘é‡é‡åŒ–å˜åˆ†è‡ªç¼–ç å™¨(CVQ-VAE)çš„ç¦»æ•£çŠ¶æ€è¡¨ç¤ºï¼›2) åŸºäºè§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹(VLA)çš„çŠ¶æ€ç†è§£å’Œæœªæ¥è§‚æµ‹é¢„æµ‹ï¼›3) åŸºäºç”Ÿæˆæ‰©æ•£ç­–ç•¥çš„åŠ¨ä½œç­–ç•¥å¤´ï¼Œç”¨äºç”Ÿæˆåˆ†å±‚åŠ¨ä½œå’Œè½¨è¿¹ï¼›4) åŸºäºActor-Criticçš„å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ¡†æ¶ï¼Œç”¨äºä¼˜åŒ–åŠ¨ä½œç­–ç•¥ã€‚VLAæä¾›å½“å‰å’Œé¢„æµ‹çš„çŠ¶æ€tokenç»™åŠ¨ä½œç­–ç•¥å¤´ï¼ŒåŠ¨ä½œç­–ç•¥å¤´ç”ŸæˆåŠ¨ä½œï¼ŒCriticè¯„ä¼°åŠ¨ä½œå¹¶æä¾›åé¦ˆã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ä¸ç”Ÿæˆæ‰©æ•£ç­–ç•¥ç›¸ç»“åˆï¼Œç”¨äºç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶ã€‚VLAè´Ÿè´£çŠ¶æ€ç†è§£å’Œæœªæ¥é¢„æµ‹ï¼Œæ‰©æ•£ç­–ç•¥è´Ÿè´£åŠ¨ä½œç”Ÿæˆï¼ŒäºŒè€…ååŒå·¥ä½œï¼Œæé«˜äº†è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„é²æ£’æ€§å’Œå¯è§£é‡Šæ€§ã€‚æ­¤å¤–ï¼Œä½¿ç”¨å¼ºåŒ–å­¦ä¹ å¯¹VLAè¿›è¡Œå¾®è°ƒï¼Œè¿›ä¸€æ­¥æå‡äº†å…¶æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šCVQ-VAEç”¨äºå°†è¿ç»­çš„è§‚æµ‹æ•°æ®ç¼–ç ä¸ºç¦»æ•£çš„tokenè¡¨ç¤ºï¼Œä¾¿äºVLAè¿›è¡Œå¤„ç†ã€‚VLAé€šè¿‡tokenç”Ÿæˆé¢„è®­ç»ƒæ¥å­¦ä¹ é©¾é©¶åœºæ™¯çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚åŠ¨ä½œç­–ç•¥å¤´é‡‡ç”¨åˆ†å±‚ç»“æ„ï¼Œç”Ÿæˆç²—ç²’åº¦çš„è½¨è¿¹å’Œç»†ç²’åº¦çš„åŠ¨ä½œã€‚å¼ºåŒ–å­¦ä¹ è®­ç»ƒé‡‡ç”¨Actor-Criticæ¡†æ¶ï¼ŒCriticç½‘ç»œè¯„ä¼°åŠ¨ä½œçš„è´¨é‡ï¼Œå¹¶æä¾›æ¢¯åº¦åé¦ˆç»™Actorç½‘ç»œï¼Œä»è€Œä¼˜åŒ–åŠ¨ä½œç­–ç•¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

VDRiveåœ¨Bench2Driveé—­ç¯åŸºå‡†æµ‹è¯•å’ŒnuSceneså¼€ç¯è§„åˆ’ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚åœ¨Bench2Driveä¸Šï¼ŒVDRiveæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œè¯æ˜äº†å…¶åœ¨å¤æ‚é©¾é©¶åœºæ™¯ä¸­çš„é²æ£’æ€§ã€‚åœ¨nuScenesä¸Šï¼ŒVDRiveä¹Ÿå–å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„ç»“æœï¼ŒéªŒè¯äº†å…¶åœ¨çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„æœ‰æ•ˆæ€§ã€‚è¿™äº›å®éªŒç»“æœè¡¨æ˜ï¼ŒVDRiveæ˜¯ä¸€ç§æœ‰å‰æ™¯çš„ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶è§£å†³æ–¹æ¡ˆã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

VDRiveå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯åº”ç”¨äºå„ç§è‡ªåŠ¨é©¾é©¶åœºæ™¯ï¼ŒåŒ…æ‹¬åŸå¸‚é“è·¯ã€é«˜é€Ÿå…¬è·¯å’Œè¶Šé‡ç¯å¢ƒã€‚è¯¥ç ”ç©¶æˆæœæœ‰åŠ©äºæå‡è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„å®‰å…¨æ€§ã€å¯é æ€§å’Œæ™ºèƒ½åŒ–æ°´å¹³ï¼ŒåŠ é€Ÿè‡ªåŠ¨é©¾é©¶æŠ€æœ¯çš„å•†ä¸šåŒ–è½åœ°ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–æœºå™¨äººæ§åˆ¶é¢†åŸŸï¼Œä¾‹å¦‚æ— äººæœºå’Œç§»åŠ¨æœºå™¨äººã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In autonomous driving, dynamic environment and corner cases pose significant challenges to the robustness of ego vehicle's state understanding and decision making. We introduce VDRive, a novel pipeline for end-to-end autonomous driving that explicitly models state-action mapping to address these challenges, enabling interpretable and robust decision making. By leveraging the advancement of the state understanding of the Vision Language Action Model (VLA) with generative diffusion policy-based action head, our VDRive guides the driving contextually and geometrically. Contextually, VLA predicts future observations through token generation pre-training, where the observations are represented as discrete codes by a Conditional Vector Quantized Variational Autoencoder (CVQ-VAE). Geometrically, we perform reinforcement learning fine-tuning of the VLA to predict future trajectories and actions based on current driving conditions. VLA supplies the current state tokens and predicted state tokens for the action policy head to generate hierarchical actions and trajectories. During policy training, a learned critic evaluates the actions generated by the policy and provides gradient-based feedback, forming an actor-critic framework that enables a reinforcement-based policy learning pipeline. Experiments show that our VDRive achieves state-of-the-art performance in the Bench2Drive closed-loop benchmark and nuScenes open-loop planning.

