---
layout: default
title: VDRive: Leveraging Reinforced VLA and Diffusion Policy for End-to-end Autonomous Driving
---

# VDRive: Leveraging Reinforced VLA and Diffusion Policy for End-to-end Autonomous Driving

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.15446" target="_blank" class="toolbar-btn">arXiv: 2510.15446v1</a>
    <a href="https://arxiv.org/pdf/2510.15446.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.15446v1" 
            onclick="toggleFavorite(this, '2510.15446v1', 'VDRive: Leveraging Reinforced VLA and Diffusion Policy for End-to-end Autonomous Driving')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Ziang Guo, Zufeng Zhang

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-17

**Â§áÊ≥®**: 1st version

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**VDRiveÔºöÂà©Áî®Âº∫ÂåñVLAÂíåÊâ©Êï£Á≠ñÁï•ÂÆûÁé∞Á´ØÂà∞Á´ØËá™Âä®È©æÈ©∂**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±ÂõõÔºöÁîüÊàêÂºèÂä®‰Ωú (Generative Motion)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Ëá™Âä®È©æÈ©∂` `Á´ØÂà∞Á´ØÂ≠¶‰π†` `ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°Âûã` `Êâ©Êï£Á≠ñÁï•` `Âº∫ÂåñÂ≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËá™Âä®È©æÈ©∂ÊñπÊ≥ïÂú®Âä®ÊÄÅÁéØÂ¢ÉÂíåÊûÅÁ´ØÊÉÖÂÜµ‰∏ãÔºåËΩ¶ËæÜÁä∂ÊÄÅÁêÜËß£ÂíåÂÜ≥Á≠ñÁöÑÈ≤ÅÊ£íÊÄßÈù¢‰∏¥ÊåëÊàò„ÄÇ
2. VDRiveÈÄöËøáÂª∫Ê®°Áä∂ÊÄÅ-Âä®‰ΩúÊò†Â∞ÑÔºåÁªìÂêàËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°ÂûãÂíåÊâ©Êï£Á≠ñÁï•ÔºåÂÆûÁé∞ËØ≠Â¢ÉÂíåÂá†‰Ωï‰∏äÁöÑÈ©æÈ©∂ÂºïÂØº„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåVDRiveÂú®Bench2DriveÂíånuScenesÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÈ™åËØÅ‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÁ´ØÂà∞Á´ØËá™Âä®È©æÈ©∂ÊµÅÁ®ãVDRiveÔºåÂÆÉÈÄöËøáÊòæÂºèÂú∞Âª∫Ê®°Áä∂ÊÄÅ-Âä®‰ΩúÊò†Â∞ÑÊù•Ëß£ÂÜ≥Âä®ÊÄÅÁéØÂ¢ÉÂíåÊûÅÁ´ØÊÉÖÂÜµÂØπËá™Âä®È©æÈ©∂È≤ÅÊ£íÊÄßÁöÑÊåëÊàòÔºå‰ªéËÄåÂÆûÁé∞ÂèØËß£ÈáäÂíåÈ≤ÅÊ£íÁöÑÂÜ≥Á≠ñ„ÄÇVDRiveÂà©Áî®ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°Âûã(VLA)Âú®Áä∂ÊÄÅÁêÜËß£ÊñπÈù¢ÁöÑ‰ºòÂäøÔºåÂπ∂ÁªìÂêàÂü∫‰∫éÁîüÊàêÊâ©Êï£Á≠ñÁï•ÁöÑÂä®‰ΩúÂ§¥Ôºå‰ªéËÄåÂú®ËØ≠Â¢ÉÂíåÂá†‰Ωï‰∏äÂºïÂØºÈ©æÈ©∂„ÄÇÂú®ËØ≠Â¢É‰∏äÔºåVLAÈÄöËøátokenÁîüÊàêÈ¢ÑËÆ≠ÁªÉÊù•È¢ÑÊµãÊú™Êù•ÁöÑËßÇÊµãÔºåËøô‰∫õËßÇÊµãÈÄöËøáÊù°‰ª∂ÂêëÈáèÈáèÂåñÂèòÂàÜËá™ÁºñÁ†ÅÂô®(CVQ-VAE)Ë°®Á§∫‰∏∫Á¶ªÊï£‰ª£Á†Å„ÄÇÂú®Âá†‰Ωï‰∏äÔºåÊàë‰ª¨ÂØπVLAËøõË°åÂº∫ÂåñÂ≠¶‰π†ÂæÆË∞ÉÔºå‰ª•Âü∫‰∫éÂΩìÂâçÁöÑÈ©æÈ©∂Êù°‰ª∂È¢ÑÊµãÊú™Êù•ÁöÑËΩ®ËøπÂíåÂä®‰Ωú„ÄÇVLA‰∏∫Âä®‰ΩúÁ≠ñÁï•Â§¥Êèê‰æõÂΩìÂâçÁä∂ÊÄÅtokenÂíåÈ¢ÑÊµãÁä∂ÊÄÅtokenÔºå‰ª•ÁîüÊàêÂàÜÂ±ÇÂä®‰ΩúÂíåËΩ®Ëøπ„ÄÇÂú®Á≠ñÁï•ËÆ≠ÁªÉÊúüÈó¥Ôºå‰∏Ä‰∏™Â≠¶‰π†Âà∞ÁöÑËØÑËÆ∫ÂÆ∂ËØÑ‰º∞Á≠ñÁï•ÁîüÊàêÁöÑÂä®‰ΩúÔºåÂπ∂Êèê‰æõÂü∫‰∫éÊ¢ØÂ∫¶ÁöÑÂèçÈ¶àÔºåÂΩ¢Êàê‰∏Ä‰∏™actor-criticÊ°ÜÊû∂Ôºå‰ªéËÄåÂÆûÁé∞Âü∫‰∫éÂº∫ÂåñÁöÑÁ≠ñÁï•Â≠¶‰π†ÊµÅÁ®ã„ÄÇÂÆûÈ™åË°®ÊòéÔºåÊàë‰ª¨ÁöÑVDRiveÂú®Bench2DriveÈó≠ÁéØÂü∫ÂáÜÊµãËØïÂíånuScenesÂºÄÁéØËßÑÂàí‰∏≠ÈÉΩÂèñÂæó‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËá™Âä®È©æÈ©∂Èù¢‰∏¥Âä®ÊÄÅÁéØÂ¢ÉÂíåÊûÅÁ´ØÊÉÖÂÜµÂ∏¶Êù•ÁöÑÊåëÊàòÔºåÁé∞ÊúâÊñπÊ≥ïÂú®Áä∂ÊÄÅÁêÜËß£ÂíåÂÜ≥Á≠ñÊñπÈù¢È≤ÅÊ£íÊÄß‰∏çË∂≥ÔºåÈöæ‰ª•Â∫îÂØπÂ§çÊùÇÂú∫ÊôØ„ÄÇËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Á´ØÂà∞Á´ØËá™Âä®È©æÈ©∂‰∏≠Áä∂ÊÄÅÁêÜËß£ÂíåÂÜ≥Á≠ñÁöÑÈ≤ÅÊ£íÊÄßÈóÆÈ¢òÔºåÊèêÂçáËá™Âä®È©æÈ©∂Á≥ªÁªüÁöÑÂÆâÂÖ®ÊÄßÂíåÂèØÈù†ÊÄß„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°ÂûãÔºàVLAÔºâËøõË°åÁä∂ÊÄÅÁêÜËß£ÔºåÂπ∂ÁªìÂêàÁîüÊàêÊâ©Êï£Á≠ñÁï•ËøõË°åÂä®‰ΩúÈ¢ÑÊµãÔºå‰ªéËÄåÂÆûÁé∞ËØ≠Â¢ÉÂíåÂá†‰Ωï‰∏äÁöÑÈ©æÈ©∂ÂºïÂØº„ÄÇÈÄöËøáÊòæÂºèÂª∫Ê®°Áä∂ÊÄÅ-Âä®‰ΩúÊò†Â∞ÑÔºåÊèêÈ´òÂÜ≥Á≠ñÁöÑÂèØËß£ÈáäÊÄßÂíåÈ≤ÅÊ£íÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöVDRiveÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) Âü∫‰∫éÊù°‰ª∂ÂêëÈáèÈáèÂåñÂèòÂàÜËá™ÁºñÁ†ÅÂô®(CVQ-VAE)ÁöÑÁ¶ªÊï£Áä∂ÊÄÅË°®Á§∫Ôºõ2) Âü∫‰∫éËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°Âûã(VLA)ÁöÑÁä∂ÊÄÅÁêÜËß£ÂíåÊú™Êù•ËßÇÊµãÈ¢ÑÊµãÔºõ3) Âü∫‰∫éÁîüÊàêÊâ©Êï£Á≠ñÁï•ÁöÑÂä®‰ΩúÁ≠ñÁï•Â§¥ÔºåÁî®‰∫éÁîüÊàêÂàÜÂ±ÇÂä®‰ΩúÂíåËΩ®ËøπÔºõ4) Âü∫‰∫éActor-CriticÁöÑÂº∫ÂåñÂ≠¶‰π†ËÆ≠ÁªÉÊ°ÜÊû∂ÔºåÁî®‰∫é‰ºòÂåñÂä®‰ΩúÁ≠ñÁï•„ÄÇVLAÊèê‰æõÂΩìÂâçÂíåÈ¢ÑÊµãÁöÑÁä∂ÊÄÅtokenÁªôÂä®‰ΩúÁ≠ñÁï•Â§¥ÔºåÂä®‰ΩúÁ≠ñÁï•Â§¥ÁîüÊàêÂä®‰ΩúÔºåCriticËØÑ‰º∞Âä®‰ΩúÂπ∂Êèê‰æõÂèçÈ¶à„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°Âûã‰∏éÁîüÊàêÊâ©Êï£Á≠ñÁï•Áõ∏ÁªìÂêàÔºåÁî®‰∫éÁ´ØÂà∞Á´ØËá™Âä®È©æÈ©∂„ÄÇVLAË¥üË¥£Áä∂ÊÄÅÁêÜËß£ÂíåÊú™Êù•È¢ÑÊµãÔºåÊâ©Êï£Á≠ñÁï•Ë¥üË¥£Âä®‰ΩúÁîüÊàêÔºå‰∫åËÄÖÂçèÂêåÂ∑•‰ΩúÔºåÊèêÈ´ò‰∫ÜËá™Âä®È©æÈ©∂Á≥ªÁªüÁöÑÈ≤ÅÊ£íÊÄßÂíåÂèØËß£ÈáäÊÄß„ÄÇÊ≠§Â§ñÔºå‰ΩøÁî®Âº∫ÂåñÂ≠¶‰π†ÂØπVLAËøõË°åÂæÆË∞ÉÔºåËøõ‰∏ÄÊ≠•ÊèêÂçá‰∫ÜÂÖ∂ÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöCVQ-VAEÁî®‰∫éÂ∞ÜËøûÁª≠ÁöÑËßÇÊµãÊï∞ÊçÆÁºñÁ†Å‰∏∫Á¶ªÊï£ÁöÑtokenË°®Á§∫Ôºå‰æø‰∫éVLAËøõË°åÂ§ÑÁêÜ„ÄÇVLAÈÄöËøátokenÁîüÊàêÈ¢ÑËÆ≠ÁªÉÊù•Â≠¶‰π†È©æÈ©∂Âú∫ÊôØÁöÑ‰∏ä‰∏ãÊñá‰ø°ÊÅØ„ÄÇÂä®‰ΩúÁ≠ñÁï•Â§¥ÈááÁî®ÂàÜÂ±ÇÁªìÊûÑÔºåÁîüÊàêÁ≤óÁ≤íÂ∫¶ÁöÑËΩ®ËøπÂíåÁªÜÁ≤íÂ∫¶ÁöÑÂä®‰Ωú„ÄÇÂº∫ÂåñÂ≠¶‰π†ËÆ≠ÁªÉÈááÁî®Actor-CriticÊ°ÜÊû∂ÔºåCriticÁΩëÁªúËØÑ‰º∞Âä®‰ΩúÁöÑË¥®ÈáèÔºåÂπ∂Êèê‰æõÊ¢ØÂ∫¶ÂèçÈ¶àÁªôActorÁΩëÁªúÔºå‰ªéËÄå‰ºòÂåñÂä®‰ΩúÁ≠ñÁï•„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

VDRiveÂú®Bench2DriveÈó≠ÁéØÂü∫ÂáÜÊµãËØïÂíånuScenesÂºÄÁéØËßÑÂàí‰∏≠ÂèñÂæó‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩ„ÄÇÂú®Bench2Drive‰∏äÔºåVDRiveÊòæËëó‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåËØÅÊòé‰∫ÜÂÖ∂Âú®Â§çÊùÇÈ©æÈ©∂Âú∫ÊôØ‰∏≠ÁöÑÈ≤ÅÊ£íÊÄß„ÄÇÂú®nuScenes‰∏äÔºåVDRive‰πüÂèñÂæó‰∫ÜÂÖ∑ÊúâÁ´û‰∫âÂäõÁöÑÁªìÊûúÔºåÈ™åËØÅ‰∫ÜÂÖ∂Âú®ÁúüÂÆû‰∏ñÁïåÊï∞ÊçÆÈõÜ‰∏äÁöÑÊúâÊïàÊÄß„ÄÇËøô‰∫õÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåVDRiveÊòØ‰∏ÄÁßçÊúâÂâçÊôØÁöÑÁ´ØÂà∞Á´ØËá™Âä®È©æÈ©∂Ëß£ÂÜ≥ÊñπÊ°à„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

VDRiveÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂèØÂ∫îÁî®‰∫éÂêÑÁßçËá™Âä®È©æÈ©∂Âú∫ÊôØÔºåÂåÖÊã¨ÂüéÂ∏ÇÈÅìË∑Ø„ÄÅÈ´òÈÄüÂÖ¨Ë∑ØÂíåË∂äÈáéÁéØÂ¢É„ÄÇËØ•Á†îÁ©∂ÊàêÊûúÊúâÂä©‰∫éÊèêÂçáËá™Âä®È©æÈ©∂Á≥ªÁªüÁöÑÂÆâÂÖ®ÊÄß„ÄÅÂèØÈù†ÊÄßÂíåÊô∫ËÉΩÂåñÊ∞¥Âπ≥ÔºåÂä†ÈÄüËá™Âä®È©æÈ©∂ÊäÄÊúØÁöÑÂïÜ‰∏öÂåñËêΩÂú∞„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïËøòÂèØ‰ª•Êâ©Â±ïÂà∞ÂÖ∂‰ªñÊú∫Âô®‰∫∫ÊéßÂà∂È¢ÜÂüüÔºå‰æãÂ¶ÇÊó†‰∫∫Êú∫ÂíåÁßªÂä®Êú∫Âô®‰∫∫„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> In autonomous driving, dynamic environment and corner cases pose significant challenges to the robustness of ego vehicle's state understanding and decision making. We introduce VDRive, a novel pipeline for end-to-end autonomous driving that explicitly models state-action mapping to address these challenges, enabling interpretable and robust decision making. By leveraging the advancement of the state understanding of the Vision Language Action Model (VLA) with generative diffusion policy-based action head, our VDRive guides the driving contextually and geometrically. Contextually, VLA predicts future observations through token generation pre-training, where the observations are represented as discrete codes by a Conditional Vector Quantized Variational Autoencoder (CVQ-VAE). Geometrically, we perform reinforcement learning fine-tuning of the VLA to predict future trajectories and actions based on current driving conditions. VLA supplies the current state tokens and predicted state tokens for the action policy head to generate hierarchical actions and trajectories. During policy training, a learned critic evaluates the actions generated by the policy and provides gradient-based feedback, forming an actor-critic framework that enables a reinforcement-based policy learning pipeline. Experiments show that our VDRive achieves state-of-the-art performance in the Bench2Drive closed-loop benchmark and nuScenes open-loop planning.

