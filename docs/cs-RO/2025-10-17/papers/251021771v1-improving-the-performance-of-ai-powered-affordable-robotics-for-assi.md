---
layout: default
title: Improving the performance of AI-powered Affordable Robotics for Assistive Tasks
---

# Improving the performance of AI-powered Affordable Robotics for Assistive Tasks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.21771" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.21771v1</a>
  <a href="https://arxiv.org/pdf/2510.21771.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.21771v1" onclick="toggleFavorite(this, '2510.21771v1', 'Improving the performance of AI-powered Affordable Robotics for Assistive Tasks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Dharunish Yugeswardeenoo

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-10-17

**å¤‡æ³¨**: 6 pages, 5 figures. Accepted to Conference on Robot Learning (CoRL 2025), Seoul, Korea

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºæ¨¡ä»¿å­¦ä¹ çš„ä½æˆæœ¬æœºå™¨äººè‡‚ï¼Œç”¨äºè¾…åŠ©ä»»åŠ¡å¹¶æ˜¾è‘—æå‡æ€§èƒ½ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è¾…åŠ©æœºå™¨äºº` `æ¨¡ä»¿å­¦ä¹ ` `æœºå™¨äººè‡‚` `æ—¶é—´åºåˆ—å»ºæ¨¡` `Transformer` `åŠ¨ä½œåˆ†å‰²`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è¾…åŠ©æœºå™¨äººæˆæœ¬é«˜æ˜‚ä¸”éœ€è¦ä¸“ä¸šçŸ¥è¯†ï¼Œéš¾ä»¥æ»¡è¶³æ—¥ç›Šå¢é•¿çš„è¾…åŠ©æŠ¤ç†éœ€æ±‚ã€‚
2. æå‡ºPhased Action Chunking Transformer (PACT) å’Œæ—¶é—´é›†æˆ (TE) æ–¹æ³•ï¼Œé€šè¿‡æ¨¡ä»¿å­¦ä¹ æå‡æœºå™¨äººè‡‚çš„æ€§èƒ½ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨è¾…åŠ©ä»»åŠ¡ä¸­å®ç°äº†è¶…è¿‡90%çš„å‡†ç¡®ç‡ï¼Œæ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶é’ˆå¯¹è¾…åŠ©æŠ¤ç†é¢†åŸŸæ—¥ç›Šå¢é•¿çš„éœ€æ±‚å’Œç°æœ‰æœºå™¨äººè§£å†³æ–¹æ¡ˆçš„é«˜æˆæœ¬åŠæŠ€æœ¯é—¨æ§›é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ä½æˆæœ¬æœºå™¨äººè‡‚ï¼Œç”¨äºæ‰§è¡Œå–‚é£Ÿã€æ¸…ç†æº¢å‡ºå’Œå–è¯ç­‰è¾…åŠ©ä»»åŠ¡ã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨æ¨¡ä»¿å­¦ä¹ æ–¹æ³•ï¼Œä»æ¼”ç¤ºè§†é¢‘ä¸­å­¦ä¹ ï¼Œæ— éœ€ä»»åŠ¡ç‰¹å®šçš„ç¼–ç¨‹æˆ–æ‰‹åŠ¨æ ‡æ³¨ã€‚æœºå™¨äººç”±å…­ä¸ªèˆµæœºã€åŒæ‘„åƒå¤´å’Œ3Dæ‰“å°å¤¹çˆªç»„æˆã€‚é€šè¿‡é¥æ“ä½œæ”¶é›†äº†åŒ…å«50,000å¸§è§†é¢‘çš„æ•°æ®é›†ã€‚è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„Phased Action Chunking Transformer (PACT) æ¥æ•æ‰æ—¶é—´ä¾èµ–å…³ç³»å¹¶åˆ†å‰²è¿åŠ¨åŠ¨æ€ï¼Œä»¥åŠä¸€ç§æ—¶é—´é›†æˆ (TE) æ–¹æ³•æ¥ä¼˜åŒ–è½¨è¿¹ï¼Œæé«˜å‡†ç¡®æ€§å’Œå¹³æ»‘åº¦ã€‚åœ¨äº”ä¸ªæ¨¡å‹å°ºå¯¸å’Œå››ç§æ¶æ„ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»è¿‡åå°æ—¶çš„çœŸå®ä¸–ç•Œæµ‹è¯•ï¼Œè¯¥ç³»ç»Ÿå®ç°äº†è¶…è¿‡90%çš„ä»»åŠ¡å‡†ç¡®ç‡ï¼Œæ¯”åŸºçº¿æé«˜äº†é«˜è¾¾40%ã€‚PACTåœ¨ä¿æŒ75%å‡†ç¡®ç‡çš„åŒæ—¶ï¼Œå®ç°äº†5å€çš„æ¨¡å‹å°ºå¯¸ç¼©å‡ã€‚æ˜¾è‘—æ€§åˆ†æè¡¨æ˜ç³»ç»Ÿä¾èµ–äºå…³é”®è§†è§‰çº¿ç´¢ï¼Œå¹¶ä¸”ç›¸ä½tokenæ¢¯åº¦åœ¨å…³é”®è½¨è¿¹æ—¶åˆ»è¾¾åˆ°å³°å€¼ï¼Œè¡¨æ˜æœ‰æ•ˆçš„æ—¶é—´æ¨ç†ã€‚æœªæ¥çš„å·¥ä½œå°†æ¢ç´¢åŒè‡‚æ“ä½œå’Œç§»åŠ¨æ€§ï¼Œä»¥æ‰©å±•è¾…åŠ©èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è¾…åŠ©æœºå™¨äººæˆæœ¬é«˜ã€éƒ¨ç½²éš¾çš„é—®é¢˜ï¼Œä½¿å¾—æ›´å¤šäººèƒ½å¤Ÿè´Ÿæ‹…å¾—èµ·å¹¶ä½¿ç”¨æœºå™¨äººæ¥å®Œæˆè¾…åŠ©ä»»åŠ¡ï¼Œå¦‚å–‚é£Ÿã€æ¸…ç†å’Œå–è¯ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦å¤æ‚çš„ç¼–ç¨‹æˆ–æ‰‹åŠ¨æ ‡æ³¨ï¼Œé™åˆ¶äº†å…¶æ˜“ç”¨æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ¨¡ä»¿å­¦ä¹ ï¼Œè®©æœºå™¨äººé€šè¿‡è§‚çœ‹æ¼”ç¤ºè§†é¢‘æ¥å­¦ä¹ æ‰§è¡Œä»»åŠ¡ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œé¿å…äº†ç¹ççš„ç¼–ç¨‹å’Œæ ‡æ³¨è¿‡ç¨‹ï¼Œé™ä½äº†ä½¿ç”¨é—¨æ§›ã€‚åŒæ—¶ï¼Œé’ˆå¯¹æ¨¡ä»¿å­¦ä¹ ä¸­æ—¶é—´ä¾èµ–å…³ç³»å»ºæ¨¡çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†PACTå’ŒTEæ–¹æ³•æ¥æå‡æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ¨¡å‹è®­ç»ƒå’Œæœºå™¨äººæ§åˆ¶ä¸‰ä¸ªé˜¶æ®µã€‚é¦–å…ˆï¼Œé€šè¿‡é¥æ“ä½œæ”¶é›†æ¼”ç¤ºè§†é¢‘æ•°æ®ã€‚ç„¶åï¼Œä½¿ç”¨PACTæ¨¡å‹å­¦ä¹ åŠ¨ä½œåˆ†å‰²å’Œæ—¶é—´ä¾èµ–å…³ç³»ï¼Œå¹¶ä½¿ç”¨TEæ–¹æ³•ä¼˜åŒ–è½¨è¿¹ã€‚æœ€åï¼Œå°†å­¦ä¹ åˆ°çš„ç­–ç•¥éƒ¨ç½²åˆ°æœºå™¨äººè‡‚ä¸Šï¼Œæ§åˆ¶å…¶æ‰§è¡Œä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºPACTæ¨¡å‹ï¼Œå®ƒèƒ½å¤Ÿæœ‰æ•ˆåœ°æ•æ‰åŠ¨ä½œçš„æ—¶é—´åŠ¨æ€å’Œé˜¶æ®µæ€§ç‰¹å¾ã€‚PACTå°†åŠ¨ä½œåºåˆ—åˆ†è§£ä¸ºå¤šä¸ªé˜¶æ®µï¼ˆchunksï¼‰ï¼Œå¹¶ä½¿ç”¨Transformeræ¶æ„å­¦ä¹ è¿™äº›é˜¶æ®µä¹‹é—´çš„ä¾èµ–å…³ç³»ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£åŠ¨ä½œçš„æ„å›¾å’Œä¸Šä¸‹æ–‡ï¼Œä»è€Œæé«˜æ¨¡ä»¿å­¦ä¹ çš„å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šPACTæ¨¡å‹ä½¿ç”¨Transformerç¼–ç å™¨-è§£ç å™¨ç»“æ„ï¼Œå…¶ä¸­ç¼–ç å™¨ç”¨äºæå–è§†é¢‘å¸§çš„ç‰¹å¾ï¼Œè§£ç å™¨ç”¨äºé¢„æµ‹åŠ¨ä½œåºåˆ—ã€‚å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) Phased Action Chunkingï¼šå°†åŠ¨ä½œåºåˆ—åˆ†å‰²æˆå¤šä¸ªé˜¶æ®µï¼Œæ¯ä¸ªé˜¶æ®µåŒ…å«å¤šä¸ªè¿ç»­çš„å¸§ã€‚2) Phase Tokenï¼šä¸ºæ¯ä¸ªé˜¶æ®µå¼•å…¥ä¸€ä¸ªPhase Tokenï¼Œç”¨äºè¡¨ç¤ºè¯¥é˜¶æ®µçš„æ•´ä½“çŠ¶æ€ã€‚3) Temporal Ensembleï¼šä½¿ç”¨å¤šä¸ªPACTæ¨¡å‹è¿›è¡Œé›†æˆï¼Œé€šè¿‡å¹³å‡é¢„æµ‹ç»“æœæ¥æé«˜é²æ£’æ€§å’Œå‡†ç¡®æ€§ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬æ¨¡ä»¿å­¦ä¹ æŸå¤±å’Œæ—¶é—´ä¸€è‡´æ€§æŸå¤±ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨è¾…åŠ©ä»»åŠ¡ä¸­å®ç°äº†è¶…è¿‡90%çš„å‡†ç¡®ç‡ï¼Œç›¸æ¯”äºåŸºçº¿æ–¹æ³•æå‡äº†é«˜è¾¾40%ã€‚PACTæ¨¡å‹åœ¨ä¿æŒ75%å‡†ç¡®ç‡çš„åŒæ—¶ï¼Œå®ç°äº†5å€çš„æ¨¡å‹å°ºå¯¸ç¼©å‡ï¼Œè¡¨æ˜å…¶å…·æœ‰å¾ˆé«˜çš„æ•ˆç‡ã€‚æ˜¾è‘—æ€§åˆ†æè¡¨æ˜ï¼Œæ¨¡å‹èƒ½å¤Ÿå…³æ³¨å…³é”®çš„è§†è§‰çº¿ç´¢ï¼Œå¹¶ä¸”ç›¸ä½tokenæ¢¯åº¦åœ¨å…³é”®è½¨è¿¹æ—¶åˆ»è¾¾åˆ°å³°å€¼ï¼ŒéªŒè¯äº†æ¨¡å‹çš„æ—¶é—´æ¨ç†èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºåŒ»ç–—ã€å…»è€ç­‰é¢†åŸŸï¼Œå¸®åŠ©è€å¹´äººã€æ®‹ç–¾äººç­‰éœ€è¦è¾…åŠ©æŠ¤ç†çš„äººç¾¤ã€‚ä½æˆæœ¬çš„æœºå™¨äººè‡‚å¯ä»¥æ‰§è¡Œå–‚é£Ÿã€æ¸…ç†ã€å–è¯ç­‰æ—¥å¸¸ä»»åŠ¡ï¼Œå‡è½»æŠ¤ç†äººå‘˜çš„è´Ÿæ‹…ï¼Œæé«˜æ‚£è€…çš„ç”Ÿæ´»è´¨é‡ã€‚æœªæ¥ï¼Œç»“åˆåŒè‡‚æ“ä½œå’Œç§»åŠ¨æ€§ï¼Œå¯ä»¥æ‰©å±•åˆ°æ›´å¤æ‚çš„è¾…åŠ©ä»»åŠ¡ï¼Œå¦‚ç©¿è¡£ã€æ´—æ¼±ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> By 2050, the global demand for assistive care is expected to reach 3.5 billion people, far outpacing the availability of human caregivers. Existing robotic solutions remain expensive and require technical expertise, limiting accessibility. This work introduces a low-cost robotic arm for assistive tasks such as feeding, cleaning spills, and fetching medicine. The system uses imitation learning from demonstration videos, requiring no task-specific programming or manual labeling. The robot consists of six servo motors, dual cameras, and 3D-printed grippers. Data collection via teleoperation with a leader arm yielded 50,000 video frames across the three tasks. A novel Phased Action Chunking Transformer (PACT) captures temporal dependencies and segments motion dynamics, while a Temporal Ensemble (TE) method refines trajectories to improve accuracy and smoothness. Evaluated across five model sizes and four architectures, with ten hours of real-world testing, the system achieved over 90% task accuracy, up to 40% higher than baselines. PACT enabled a 5x model size reduction while maintaining 75% accuracy. Saliency analysis showed reliance on key visual cues, and phase token gradients peaked at critical trajectory moments, indicating effective temporal reasoning. Future work will explore bimanual manipulation and mobility for expanded assistive capabilities.

