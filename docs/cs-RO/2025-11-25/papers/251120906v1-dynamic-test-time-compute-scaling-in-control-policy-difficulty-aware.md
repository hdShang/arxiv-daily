---
layout: default
title: "Dynamic Test-Time Compute Scaling in Control Policy: Difficulty-Aware Stochastic Interpolant Policy"
---

# Dynamic Test-Time Compute Scaling in Control Policy: Difficulty-Aware Stochastic Interpolant Policy

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.20906" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.20906v1</a>
  <a href="https://arxiv.org/pdf/2511.20906.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.20906v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.20906v1', 'Dynamic Test-Time Compute Scaling in Control Policy: Difficulty-Aware Stochastic Interpolant Policy')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Inkook Chun, Seungjae Lee, Michael S. Albergo, Saining Xie, Eric Vanden-Eijnden

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-25

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDA-SIPï¼Œé€šè¿‡åŠ¨æ€è°ƒæ•´è®¡ç®—é‡ï¼Œæå‡æ‰©æ•£æ¨¡å‹å’Œæµæ¨¡å‹åœ¨æœºå™¨äººæ§åˆ¶ä¸­çš„æ•ˆç‡ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æœºå™¨äººæ§åˆ¶` `æ‰©æ•£æ¨¡å‹` `æµæ¨¡å‹` `è‡ªé€‚åº”è®¡ç®—` `éš¾åº¦æ„ŸçŸ¥` `éšæœºæ’å€¼` `é•¿æ—¶ç¨‹æ“ä½œ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æœºå™¨äººæ§åˆ¶å™¨åœ¨æ‰€æœ‰æ§åˆ¶æ­¥éª¤ä¸­ä½¿ç”¨å›ºå®šè®¡ç®—é‡ï¼Œå¿½ç•¥äº†ä»»åŠ¡éš¾åº¦å˜åŒ–ï¼Œå¯¼è‡´æ•ˆç‡ä½ä¸‹ã€‚
2. DA-SIPé€šè¿‡éš¾åº¦åˆ†ç±»å™¨åŠ¨æ€è°ƒæ•´è®¡ç®—é‡ï¼ŒåŒ…æ‹¬æ­¥æ•°é¢„ç®—ã€æ±‚è§£å™¨å’ŒODE/SDEç§¯åˆ†ï¼Œå®ç°è‡ªé€‚åº”æ§åˆ¶ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒDA-SIPåœ¨ä¿æŒä»»åŠ¡æˆåŠŸç‡çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—æ—¶é—´ï¼Œæå‡äº†æ§åˆ¶æ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ‰©æ•£æ¨¡å‹å’Œæµæ¨¡å‹åœ¨é•¿æ—¶ç¨‹æœºå™¨äººæ“ä½œå’Œæ¨¡ä»¿å­¦ä¹ ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚ç„¶è€Œï¼Œè¿™äº›æ§åˆ¶å™¨åœ¨æ¯ä¸ªæ§åˆ¶æ­¥éª¤éƒ½é‡‡ç”¨å›ºå®šçš„æ¨ç†é¢„ç®—ï¼Œå¿½ç•¥äº†ä»»åŠ¡çš„å¤æ‚æ€§ï¼Œå¯¼è‡´ç®€å•å­ä»»åŠ¡çš„è®¡ç®—æ•ˆç‡ä½ä¸‹ï¼Œè€Œå¤æ‚å­ä»»åŠ¡çš„æ€§èƒ½å¯èƒ½ä¸è¶³ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†éš¾åº¦æ„ŸçŸ¥éšæœºæ’å€¼ç­–ç•¥ï¼ˆDA-SIPï¼‰ï¼Œè¯¥æ¡†æ¶ä½¿æœºå™¨äººæ§åˆ¶å™¨èƒ½å¤Ÿæ ¹æ®ä»»åŠ¡éš¾åº¦å®æ—¶è°ƒæ•´å…¶ç§¯åˆ†èŒƒå›´ã€‚æˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨éš¾åº¦åˆ†ç±»å™¨æ¥åˆ†æè§‚æµ‹ï¼Œä»è€Œåœ¨æ¯ä¸ªæ§åˆ¶å‘¨æœŸåŠ¨æ€é€‰æ‹©æ­¥æ•°é¢„ç®—ã€æœ€ä½³æ±‚è§£å™¨å˜ä½“ä»¥åŠODE/SDEç§¯åˆ†ã€‚DA-SIPå»ºç«‹åœ¨éšæœºæ’å€¼å…¬å¼çš„åŸºç¡€ä¸Šï¼Œæä¾›äº†ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ï¼Œä¸ºæ‰©æ•£æ¨¡å‹å’Œæµæ¨¡å‹è§£é”äº†å¤šæ ·åŒ–çš„è®­ç»ƒå’Œæ¨ç†é…ç½®ã€‚é€šè¿‡å¯¹å„ç§æ“ä½œä»»åŠ¡çš„ç»¼åˆåŸºå‡†æµ‹è¯•ï¼ŒDA-SIPåœ¨ä¿æŒä¸å›ºå®šæœ€å¤§è®¡ç®—é‡åŸºçº¿ç›¸å½“çš„ä»»åŠ¡æˆåŠŸç‡çš„åŒæ—¶ï¼Œæ€»è®¡ç®—æ—¶é—´å‡å°‘äº†2.6-4.4å€ã€‚é€šè¿‡åœ¨è¯¥æ¡†æ¶å†…å®æ–½è‡ªé€‚åº”è®¡ç®—ï¼ŒDA-SIPå°†ç”Ÿæˆå¼æœºå™¨äººæ§åˆ¶å™¨è½¬å˜ä¸ºé«˜æ•ˆçš„ã€ä»»åŠ¡æ„ŸçŸ¥çš„ç³»ç»Ÿï¼Œä»è€Œæ™ºèƒ½åœ°åˆ†é…æ¨ç†èµ„æºï¼Œä½¿å…¶åœ¨æä¾›æœ€å¤§æ”¶ç›Šçš„åœ°æ–¹å‘æŒ¥ä½œç”¨ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰åŸºäºæ‰©æ•£æ¨¡å‹å’Œæµæ¨¡å‹çš„æœºå™¨äººæ§åˆ¶å™¨ï¼Œåœ¨æ‰§è¡Œé•¿æ—¶ç¨‹æ“ä½œä»»åŠ¡æ—¶ï¼Œé€šå¸¸é‡‡ç”¨å›ºå®šçš„è®¡ç®—é‡ï¼ˆä¾‹å¦‚å›ºå®šçš„ODE/SDEç§¯åˆ†æ­¥æ•°ï¼‰ã€‚è¿™ç§åšæ³•å¿½ç•¥äº†ä»»åŠ¡éš¾åº¦éšæ—¶é—´çš„å˜åŒ–ï¼Œå¯¼è‡´åœ¨ç®€å•ä»»åŠ¡ä¸Šæµªè´¹è®¡ç®—èµ„æºï¼Œè€Œåœ¨å¤æ‚ä»»åŠ¡ä¸Šè®¡ç®—èµ„æºä¸è¶³ï¼Œå½±å“æ€§èƒ½ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§èƒ½å¤Ÿæ ¹æ®ä»»åŠ¡éš¾åº¦åŠ¨æ€è°ƒæ•´è®¡ç®—é‡çš„æ§åˆ¶ç­–ç•¥ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDA-SIPçš„æ ¸å¿ƒæ€è·¯æ˜¯å¼•å…¥ä¸€ä¸ªéš¾åº¦åˆ†ç±»å™¨ï¼Œè¯¥åˆ†ç±»å™¨æ ¹æ®å½“å‰è§‚æµ‹ï¼ˆä¾‹å¦‚æœºå™¨äººçŠ¶æ€ã€ç¯å¢ƒä¿¡æ¯ï¼‰æ¥ä¼°è®¡ä»»åŠ¡çš„éš¾åº¦ã€‚åŸºäºä¼°è®¡çš„éš¾åº¦ï¼ŒDA-SIPåŠ¨æ€åœ°è°ƒæ•´æ§åˆ¶ç­–ç•¥çš„è®¡ç®—é‡ï¼ŒåŒ…æ‹¬ODE/SDEç§¯åˆ†çš„æ­¥æ•°ã€ä½¿ç”¨çš„æ±‚è§£å™¨ç±»å‹ï¼ˆä¾‹å¦‚Euler, RK45ï¼‰ä»¥åŠé€‰æ‹©ODEæˆ–SDEè¿›è¡Œç§¯åˆ†ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒDA-SIPèƒ½å¤Ÿè‡ªé€‚åº”åœ°åˆ†é…è®¡ç®—èµ„æºï¼Œä»è€Œæé«˜æ•´ä½“æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDA-SIPçš„æ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) è§‚æµ‹æ¨¡å—ï¼šæ¥æ”¶æ¥è‡ªæœºå™¨äººçš„çŠ¶æ€å’Œç¯å¢ƒä¿¡æ¯ä½œä¸ºè¾“å…¥ã€‚2) éš¾åº¦åˆ†ç±»å™¨ï¼šåŸºäºè§‚æµ‹ä¼°è®¡å½“å‰ä»»åŠ¡çš„éš¾åº¦ã€‚3) è®¡ç®—é‡è°ƒåº¦å™¨ï¼šæ ¹æ®éš¾åº¦åˆ†ç±»å™¨çš„è¾“å‡ºï¼ŒåŠ¨æ€é€‰æ‹©ODE/SDEç§¯åˆ†çš„æ­¥æ•°ã€æ±‚è§£å™¨ç±»å‹ä»¥åŠODE/SDEé€‰æ‹©ã€‚4) éšæœºæ’å€¼ç­–ç•¥ï¼šåŸºäºé€‰å®šçš„è®¡ç®—é‡é…ç½®ï¼Œæ‰§è¡Œæ§åˆ¶ç­–ç•¥ï¼Œç”Ÿæˆæ§åˆ¶æŒ‡ä»¤ã€‚5) æ‰§è¡Œå™¨ï¼šå°†æ§åˆ¶æŒ‡ä»¤å‘é€ç»™æœºå™¨äººæ‰§è¡Œã€‚

**å…³é”®åˆ›æ–°**ï¼šDA-SIPçš„å…³é”®åˆ›æ–°åœ¨äºå°†éš¾åº¦æ„ŸçŸ¥ä¸éšæœºæ’å€¼ç­–ç•¥ç›¸ç»“åˆï¼Œå®ç°äº†åŠ¨æ€è®¡ç®—é‡è°ƒæ•´ã€‚ä¸ä¼ ç»Ÿçš„å›ºå®šè®¡ç®—é‡æ–¹æ³•ç›¸æ¯”ï¼ŒDA-SIPèƒ½å¤Ÿæ ¹æ®ä»»åŠ¡éš¾åº¦è‡ªé€‚åº”åœ°åˆ†é…è®¡ç®—èµ„æºï¼Œä»è€Œåœ¨ä¿è¯æ€§èƒ½çš„åŒæ—¶æ˜¾è‘—æé«˜è®¡ç®—æ•ˆç‡ã€‚æ­¤å¤–ï¼ŒDA-SIPåŸºäºéšæœºæ’å€¼å…¬å¼ï¼Œæä¾›äº†ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ï¼Œå¯ä»¥çµæ´»åœ°é…ç½®è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ï¼Œæ”¯æŒä¸åŒçš„æ‰©æ•£æ¨¡å‹å’Œæµæ¨¡å‹ã€‚

**å…³é”®è®¾è®¡**ï¼šéš¾åº¦åˆ†ç±»å™¨å¯ä»¥ä½¿ç”¨å„ç§æœºå™¨å­¦ä¹ æ¨¡å‹å®ç°ï¼Œä¾‹å¦‚ç¥ç»ç½‘ç»œã€‚å…¶è®­ç»ƒæ•°æ®å¯ä»¥é€šè¿‡ä¸“å®¶ç­–ç•¥æˆ–ç¦»çº¿æ•°æ®ç”Ÿæˆã€‚è®¡ç®—é‡è°ƒåº¦å™¨å¯ä»¥é‡‡ç”¨ç®€å•çš„è§„åˆ™æˆ–æ›´å¤æ‚çš„ç­–ç•¥ï¼Œä¾‹å¦‚åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ–¹æ³•ã€‚éšæœºæ’å€¼ç­–ç•¥çš„å…·ä½“å®ç°å–å†³äºæ‰€ä½¿ç”¨çš„æ‰©æ•£æ¨¡å‹æˆ–æµæ¨¡å‹ã€‚è®ºæ–‡ä¸­å¯èƒ½ä½¿ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥è®­ç»ƒéš¾åº¦åˆ†ç±»å™¨å’Œæ§åˆ¶ç­–ç•¥ï¼Œä»¥ç¡®ä¿éš¾åº¦ä¼°è®¡çš„å‡†ç¡®æ€§å’Œæ§åˆ¶æ€§èƒ½çš„ä¼˜åŒ–ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒDA-SIPåœ¨å¤šç§æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­ï¼Œèƒ½å¤Ÿåœ¨ä¿æŒä¸å›ºå®šæœ€å¤§è®¡ç®—é‡åŸºçº¿ç›¸å½“çš„ä»»åŠ¡æˆåŠŸç‡çš„åŒæ—¶ï¼Œå°†æ€»è®¡ç®—æ—¶é—´å‡å°‘2.6-4.4å€ã€‚è¿™è¡¨æ˜DA-SIPèƒ½å¤Ÿæœ‰æ•ˆåœ°è‡ªé€‚åº”åˆ†é…è®¡ç®—èµ„æºï¼Œæ˜¾è‘—æé«˜æ§åˆ¶æ•ˆç‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

DA-SIPå¯åº”ç”¨äºå„ç§æœºå™¨äººæ“ä½œä»»åŠ¡ï¼Œå°¤å…¶æ˜¯åœ¨èµ„æºå—é™æˆ–ä»»åŠ¡éš¾åº¦åŠ¨æ€å˜åŒ–çš„ç¯å¢ƒä¸­ã€‚ä¾‹å¦‚ï¼Œåœ¨ç§»åŠ¨æœºå™¨äººå¯¼èˆªã€è‡ªä¸»è£…é…ã€åŒ»ç–—æœºå™¨äººæ‰‹æœ¯ç­‰é¢†åŸŸï¼ŒDA-SIPèƒ½å¤Ÿæ˜¾è‘—æé«˜æ§åˆ¶æ•ˆç‡ï¼Œé™ä½èƒ½è€—ï¼Œå¹¶æå‡ä»»åŠ¡æˆåŠŸç‡ã€‚è¯¥ç ”ç©¶ä¸ºå¼€å‘æ›´æ™ºèƒ½ã€æ›´é«˜æ•ˆçš„æœºå™¨äººæ§åˆ¶ç³»ç»Ÿæä¾›äº†æ–°çš„æ€è·¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Diffusion- and flow-based policies deliver state-of-the-art performance on long-horizon robotic manipulation and imitation learning tasks. However, these controllers employ a fixed inference budget at every control step, regardless of task complexity, leading to computational inefficiency for simple subtasks while potentially underperforming on challenging ones. To address these issues, we introduce Difficulty-Aware Stochastic Interpolant Policy (DA-SIP), a framework that enables robotic controllers to adaptively adjust their integration horizon in real time based on task difficulty. Our approach employs a difficulty classifier that analyzes observations to dynamically select the step budget, the optimal solver variant, and ODE/SDE integration at each control cycle. DA-SIP builds upon the stochastic interpolant formulation to provide a unified framework that unlocks diverse training and inference configurations for diffusion- and flow-based policies. Through comprehensive benchmarks across diverse manipulation tasks, DA-SIP achieves 2.6-4.4x reduction in total computation time while maintaining task success rates comparable to fixed maximum-computation baselines. By implementing adaptive computation within this framework, DA-SIP transforms generative robot controllers into efficient, task-aware systems that intelligently allocate inference resources where they provide the greatest benefit.

