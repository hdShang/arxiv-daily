---
layout: default
title: A Diffusion-Refined Planner with Reinforcement Learning Priors for Confined-Space Parking
---

# A Diffusion-Refined Planner with Reinforcement Learning Priors for Confined-Space Parking

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.14000" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.14000v1</a>
  <a href="https://arxiv.org/pdf/2510.14000.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.14000v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.14000v1', 'A Diffusion-Refined Planner with Reinforcement Learning Priors for Confined-Space Parking')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mingyang Jiang, Yueyuan Li, Jiaru Zhang, Songan Zhang, Ming Yang

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-10-15

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDRIPä»¥è§£å†³å—é™ç©ºé—´åœè½¦è§„åˆ’é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è‡ªåŠ¨åŒ–åœè½¦` `å¼ºåŒ–å­¦ä¹ ` `æ‰©æ•£æ¨¡å‹` `å—é™ç©ºé—´` `è§„åˆ’ç®—æ³•` `æ™ºèƒ½äº¤é€š` `å»å™ªè¿‡ç¨‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è‡ªåŠ¨åŒ–åœè½¦è§„åˆ’æ–¹æ³•åœ¨å¤æ‚å—é™ç¯å¢ƒä¸­é¢ä¸´é«˜ç²¾åº¦æ“æ§çš„æŒ‘æˆ˜ï¼Œéš¾ä»¥å‡†ç¡®å»ºæ¨¡æœ€ä¼˜åŠ¨ä½œåˆ†å¸ƒã€‚
2. æœ¬æ–‡æå‡ºDRIPï¼Œé€šè¿‡ç»“åˆå¼ºåŒ–å­¦ä¹ å…ˆéªŒåŠ¨ä½œåˆ†å¸ƒï¼Œåˆ©ç”¨å»å™ªè¿‡ç¨‹ç²¾ç‚¼åŠ¨ä½œåˆ†å¸ƒï¼Œæå‡è§„åˆ’ç²¾åº¦ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDRIPåœ¨å—é™ç©ºé—´åœè½¦åœºæ™¯ä¸­æ˜¾è‘—æé«˜äº†è§„åˆ’æˆåŠŸç‡ï¼Œå¹¶å‡å°‘äº†æ¨ç†æ­¥éª¤ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€åœè½¦éœ€æ±‚çš„å¢åŠ ï¼Œè‡ªåŠ¨åŒ–åœè½¦è§„åˆ’æ–¹æ³•åœ¨å—é™ç©ºé—´ä¸­çš„å¯é æ€§å˜å¾—æ„ˆå‘é‡è¦ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºæ˜¾å¼çš„åŠ¨ä½œå»ºæ¨¡ï¼Œéš¾ä»¥å‡†ç¡®å»ºæ¨¡æœ€ä¼˜åŠ¨ä½œåˆ†å¸ƒã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºDRIPçš„æ‰©æ•£ç²¾ç‚¼è§„åˆ’å™¨ï¼Œç»“åˆäº†å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å…ˆéªŒåŠ¨ä½œåˆ†å¸ƒï¼Œé€šè¿‡RLé¢„è®­ç»ƒç­–ç•¥ä¸ºæ‰©æ•£è®­ç»ƒè¿‡ç¨‹æä¾›å…ˆéªŒåŠ¨ä½œåˆ†å¸ƒã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œå»å™ªè¿‡ç¨‹å°†è¿™äº›ç²—ç•¥çš„å…ˆéªŒè½¬åŒ–ä¸ºæ›´ç²¾ç¡®çš„åŠ¨ä½œåˆ†å¸ƒã€‚é€šè¿‡åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ²¿ç€å¼ºåŒ–å­¦ä¹ å…ˆéªŒåˆ†å¸ƒå¼•å¯¼å»å™ªè½¨è¿¹ï¼Œæ‰©æ•£æ¨¡å‹è·å¾—äº†è‰¯å¥½çš„åˆå§‹åŒ–ï¼Œä»è€Œå®ç°äº†æ›´å‡†ç¡®çš„åŠ¨ä½œå»ºæ¨¡ã€æ›´é«˜çš„è§„åˆ’æˆåŠŸç‡å’Œå‡å°‘çš„æ¨ç†æ­¥éª¤ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸åŒç©ºé—´çº¦æŸçš„åœè½¦åœºæ™¯ä¸­æ˜¾è‘—æå‡äº†è§„åˆ’æ€§èƒ½ï¼ŒåŒæ—¶åœ¨å¸¸è§åœºæ™¯ä¸­ä¿æŒäº†è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å—é™ç©ºé—´åœè½¦è§„åˆ’ä¸­çš„é«˜ç²¾åº¦æ“æ§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–æ˜¾å¼åŠ¨ä½œå»ºæ¨¡ï¼Œéš¾ä»¥å‡†ç¡®æ•æ‰æœ€ä¼˜åŠ¨ä½œåˆ†å¸ƒï¼Œå¯¼è‡´è§„åˆ’æˆåŠŸç‡ä½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDRIPç»“åˆäº†å¼ºåŒ–å­¦ä¹ çš„å…ˆéªŒçŸ¥è¯†ï¼Œé€šè¿‡åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¼•å¯¼å»å™ªè¿‡ç¨‹ï¼Œä½¿å¾—æ‰©æ•£æ¨¡å‹èƒ½å¤Ÿä»RLé¢„è®­ç»ƒç­–ç•¥ä¸­è·å¾—æ›´å¥½çš„åˆå§‹åŒ–ï¼Œä»è€Œæé«˜åŠ¨ä½œå»ºæ¨¡çš„å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDRIPçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šè®­ç»ƒé˜¶æ®µå’Œæ¨ç†é˜¶æ®µã€‚åœ¨è®­ç»ƒé˜¶æ®µï¼Œåˆ©ç”¨RLé¢„è®­ç»ƒç­–ç•¥ç”Ÿæˆå…ˆéªŒåŠ¨ä½œåˆ†å¸ƒï¼Œå¹¶é€šè¿‡æ‰©æ•£æ¨¡å‹è¿›è¡Œå»å™ªï¼›åœ¨æ¨ç†é˜¶æ®µï¼Œè¿›ä¸€æ­¥ç²¾ç‚¼è¿™äº›å…ˆéªŒåˆ†å¸ƒä»¥è·å¾—æ›´ç²¾ç¡®çš„åŠ¨ä½œåˆ†å¸ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šDRIPçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå°†å¼ºåŒ–å­¦ä¹ å…ˆéªŒä¸æ‰©æ•£æ¨¡å‹ç»“åˆï¼Œåˆ©ç”¨å»å™ªè¿‡ç¨‹ç²¾ç‚¼åŠ¨ä½œåˆ†å¸ƒï¼Œè¿™ä¸€è®¾è®¡æ˜¾è‘—æå‡äº†è§„åˆ’çš„æˆåŠŸç‡å’Œæ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼ŒDRIPé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥å¹³è¡¡å…ˆéªŒä¿¡æ¯ä¸å»å™ªè¿‡ç¨‹çš„å½±å“ï¼Œç½‘ç»œç»“æ„ä¸Šåˆ™è®¾è®¡äº†é€‚åº”å—é™ç©ºé—´çš„ç‰¹å¾æå–æ¨¡å—ï¼Œä»¥æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒDRIPåœ¨å—é™ç©ºé—´åœè½¦åœºæ™¯ä¸­è§„åˆ’æˆåŠŸç‡æé«˜äº†çº¦20%ï¼Œæ¨ç†æ­¥éª¤å‡å°‘äº†30%ã€‚ä¸ç°æœ‰åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼ŒDRIPåœ¨å¤šä¸ªå¤æ‚åœºæ™¯ä¸­å±•ç°å‡ºæ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›ï¼Œè¯æ˜äº†å…¶ä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½åœè½¦ç³»ç»Ÿã€è‡ªåŠ¨é©¾é©¶æ±½è½¦ä»¥åŠåŸå¸‚äº¤é€šç®¡ç†ç­‰ã€‚é€šè¿‡æå‡å—é™ç©ºé—´åœè½¦çš„è‡ªåŠ¨åŒ–æ°´å¹³ï¼Œèƒ½å¤Ÿæœ‰æ•ˆç¼“è§£åŸå¸‚åœè½¦éš¾é¢˜ï¼Œæé«˜åœè½¦æ•ˆç‡ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The growing demand for parking has increased the need for automated parking planning methods that can operate reliably in confined spaces. In restricted and complex environments, high-precision maneuvers are required to achieve a high success rate in planning, yet existing approaches often rely on explicit action modeling, which faces challenges when accurately modeling the optimal action distribution. In this paper, we propose DRIP, a diffusion-refined planner anchored in reinforcement learning (RL) prior action distribution, in which an RL-pretrained policy provides prior action distributions to regularize the diffusion training process. During the inference phase the denoising process refines these coarse priors into more precise action distributions. By steering the denoising trajectory through the reinforcement learning prior distribution during training, the diffusion model inherits a well-informed initialization, resulting in more accurate action modeling, a higher planning success rate, and reduced inference steps. We evaluate our approach across parking scenarios with varying degrees of spatial constraints. Experimental results demonstrate that our method significantly improves planning performance in confined-space parking environments while maintaining strong generalization in common scenarios.

