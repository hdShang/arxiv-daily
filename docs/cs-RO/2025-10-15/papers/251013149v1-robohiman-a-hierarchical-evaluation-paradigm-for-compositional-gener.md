---
layout: default
title: "RoboHiMan: A Hierarchical Evaluation Paradigm for Compositional Generalization in Long-Horizon Manipulation"
---

# RoboHiMan: A Hierarchical Evaluation Paradigm for Compositional Generalization in Long-Horizon Manipulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.13149" class="toolbar-btn" target="_blank">üìÑ arXiv: 2510.13149v1</a>
  <a href="https://arxiv.org/pdf/2510.13149.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.13149v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.13149v1', 'RoboHiMan: A Hierarchical Evaluation Paradigm for Compositional Generalization in Long-Horizon Manipulation')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Yangtao Chen, Zixuan Chen, Nga Teng Chan, Junting Chen, Junhui Yin, Jieqi Shi, Yang Gao, Yong-Lu Li, Jing Huo

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-15

**Â§áÊ≥®**: Under review. These first two authors contributed equally to this work

**üîó ‰ª£Á†Å/È°πÁõÆ**: [PROJECT_PAGE](https://chenyt31.github.io/robo-himan.github.io/)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫RoboHiManÔºåÁî®‰∫éËØÑ‰º∞ÈïøÊó∂Á®ãÊìç‰Ωú‰∏≠ÁªÑÂêàÊ≥õÂåñÁöÑÂàÜÂ±ÇËØÑ‰º∞ËåÉÂºè„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÈïøÊó∂Á®ãÊìç‰Ωú` `ÁªÑÂêàÊ≥õÂåñ` `ÂàÜÂ±ÇËØÑ‰º∞` `Êú∫Âô®‰∫∫Êìç‰Ωú` `Âü∫ÂáÜÊµãËØï`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁ´ØÂà∞Á´ØÊ®°ÂûãÂú®ÈïøÊó∂Á®ãÊìç‰Ωú‰ªªÂä°‰∏≠Ê≥õÂåñËÉΩÂäõ‰∏çË∂≥ÔºåÂàÜÂ±ÇÊñπÊ≥ïÂú®Â§çÊùÇÊâ∞Âä®‰∏ãÊäÄËÉΩÁªÑÂêàËÉΩÂäõÊúâÈôê„ÄÇ
2. RoboHiManÈÄöËøáHiMan-BenchÂü∫ÂáÜÂíå‰∏âÁßçËØÑ‰º∞ËåÉÂºèÔºåÁ≥ªÁªüÊÄßÂú∞ËØÑ‰º∞ÁªÑÂêàÊ≥õÂåñ„ÄÅÈ≤ÅÊ£íÊÄß‰ª•ÂèäËßÑÂàí‰∏éÊâßË°åÁöÑÁõ∏‰∫í‰ΩúÁî®„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊè≠Á§∫‰∫ÜÁé∞ÊúâÊ®°ÂûãÂú®ÈïøÊó∂Á®ãÊìç‰Ωú‰ªªÂä°‰∏≠ÁöÑËÉΩÂäõÂ∑ÆË∑ùÔºå‰∏∫Êú™Êù•Ê®°ÂûãËÆæËÆ°Êèê‰æõ‰∫ÜÊñπÂêë„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫RoboHiManÔºå‰∏ÄÁßçÁî®‰∫éÈïøÊó∂Á®ãÊìç‰Ωú‰∏≠ÁªÑÂêàÊ≥õÂåñÁöÑÂàÜÂ±ÇËØÑ‰º∞ËåÉÂºè„ÄÇÁé∞ÊúâÁöÑÁ´ØÂà∞Á´ØËßÜËßâËØ≠Ë®ÄÂä®‰ΩúÊ®°ÂûãÊ≥õÂåñËÉΩÂäõÊúâÈôêÔºåÂàÜÂ±ÇÊñπÊ≥ïÂú®Â§çÊùÇÊâ∞Âä®‰∏ãË°®Áé∞‰∏ç‰Ω≥ÔºåË°®ÊòéÊäÄËÉΩÁªÑÂêàËÉΩÂäõ‰∏çË∂≥„ÄÇÁé∞ÊúâÂü∫ÂáÜÊµãËØï‰∏ªË¶ÅÂÖ≥Ê≥®ÈïøÊó∂Á®ã‰ªªÂä°ÂÆåÊàêÔºåÁº∫‰πèÂØπÁªÑÂêàÊ≥õÂåñ„ÄÅÈ≤ÅÊ£íÊÄß‰ª•ÂèäËßÑÂàí‰∏éÊâßË°å‰πãÈó¥Áõ∏‰∫í‰ΩúÁî®ÁöÑÊ∑±ÂÖ•Á†îÁ©∂„ÄÇRoboHiManÂºïÂÖ•HiMan-BenchÔºå‰∏Ä‰∏™ÂåÖÂê´ÂéüÂ≠êÂíåÁªÑÂêà‰ªªÂä°ÁöÑÂü∫ÂáÜÔºåÊîØÊåÅÂ§öÂ±ÇÊ¨°ËÆ≠ÁªÉÊï∞ÊçÆÈõÜ‰ª•ÂàÜÊûêÊ∏êËøõÂºèÊï∞ÊçÆÁº©Êîæ„ÄÇÂêåÊó∂ÔºåÊèêÂá∫‰∫Ü‰∏âÁßçËØÑ‰º∞ËåÉÂºèÔºàvanilla, decoupled, coupledÔºâÔºåÁî®‰∫éÊé¢Á©∂ÊäÄËÉΩÁªÑÂêàÁöÑÂøÖË¶ÅÊÄßÂπ∂Êè≠Á§∫ÂàÜÂ±ÇÊû∂ÊûÑ‰∏≠ÁöÑÁì∂È¢à„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºå‰ª£Ë°®ÊÄßÊ®°ÂûãÂíåÊû∂ÊûÑÂ≠òÂú®ÊòéÊòæÁöÑËÉΩÂäõÂ∑ÆË∑ùÔºå‰∏∫ÊîπËøõÊõ¥ÈÄÇÂêàÁé∞ÂÆû‰∏ñÁïåÈïøÊó∂Á®ãÊìç‰Ωú‰ªªÂä°ÁöÑÊ®°ÂûãÊåáÊòé‰∫ÜÊñπÂêë„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÈïøÊó∂Á®ãÊìç‰Ωú‰ªªÂä°ÁöÑËØÑ‰º∞Âü∫ÂáÜ‰∏ªË¶ÅÂÖ≥Ê≥®‰ªªÂä°ÂÆåÊàêÂ∫¶ÔºåÁº∫‰πèÂØπÁªÑÂêàÊ≥õÂåñËÉΩÂäõ„ÄÅÈ≤ÅÊ£íÊÄß‰ª•ÂèäËßÑÂàí‰∏éÊâßË°å‰πãÈó¥Áõ∏‰∫í‰ΩúÁî®ÁöÑÊ∑±ÂÖ•ËØÑ‰º∞„ÄÇÁé∞ÊúâÁöÑÁ´ØÂà∞Á´ØÊ®°ÂûãÂíåÂàÜÂ±ÇÊ®°ÂûãÂú®Â§çÊùÇÊâ∞Âä®‰∏ãË°®Áé∞‰∏ç‰Ω≥ÔºåÈöæ‰ª•ËÉú‰ªªÁúüÂÆû‰∏ñÁïåÁöÑÂ§çÊùÇÊìç‰Ωú‰ªªÂä°„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöRoboHiManÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÊèê‰æõ‰∏Ä‰∏™Á≥ªÁªüÊÄßÁöÑËØÑ‰º∞Ê°ÜÊû∂ÔºåÈÄöËøáÁ≤æÂøÉËÆæËÆ°ÁöÑÂü∫ÂáÜÊµãËØïÂíåËØÑ‰º∞ËåÉÂºèÔºåÊ∑±ÂÖ•ÂàÜÊûêÂàÜÂ±ÇÊ®°ÂûãÂú®ÈïøÊó∂Á®ãÊìç‰Ωú‰ªªÂä°‰∏≠ÁöÑÁªÑÂêàÊ≥õÂåñËÉΩÂäõ„ÄÇÈÄöËøáÊéßÂà∂‰ªªÂä°ÁöÑÂ§çÊùÇÂ∫¶ÂíåÂºïÂÖ•‰∏çÂêåÁöÑÊâ∞Âä®ÔºåÂèØ‰ª•Êõ¥Ê∏ÖÊô∞Âú∞Êè≠Á§∫Ê®°ÂûãÁöÑÁì∂È¢àÂíå‰∏çË∂≥„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöRoboHiManÂåÖÂê´‰∏§‰∏™‰∏ªË¶ÅÁªÑÊàêÈÉ®ÂàÜÔºöHiMan-BenchÂü∫ÂáÜÊµãËØïÂíå‰∏âÁßçËØÑ‰º∞ËåÉÂºè„ÄÇHiMan-BenchÂåÖÂê´ÂéüÂ≠ê‰ªªÂä°ÂíåÁªÑÂêà‰ªªÂä°ÔºåÊ∂µÁõñÂ§öÁßçÊâ∞Âä®Á±ªÂûã„ÄÇ‰∏âÁßçËØÑ‰º∞ËåÉÂºèÂàÜÂà´ÊòØÔºövanillaÔºàÁ´ØÂà∞Á´ØËØÑ‰º∞Ôºâ„ÄÅdecoupledÔºàÂàÜÂà´ËØÑ‰º∞ËßÑÂàíÂíåÊâßË°åÊ®°ÂùóÔºâ„ÄÅcoupledÔºàËÅîÂêàËØÑ‰º∞ËßÑÂàíÂíåÊâßË°åÊ®°ÂùóÔºâ„ÄÇÈÄöËøáËøô‰∏âÁßçËåÉÂºèÔºåÂèØ‰ª•ÂÖ®Èù¢ËØÑ‰º∞Ê®°ÂûãÁöÑÂêÑ‰∏™ÊñπÈù¢„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöRoboHiManÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂Á≥ªÁªüÊÄßÁöÑËØÑ‰º∞ÊñπÊ≥ïÔºåÂÆÉ‰∏ç‰ªÖÂÖ≥Ê≥®‰ªªÂä°ÁöÑÂÆåÊàêÂ∫¶ÔºåÊõ¥ÂÖ≥Ê≥®Ê®°ÂûãÁöÑÁªÑÂêàÊ≥õÂåñËÉΩÂäõÂíåÈ≤ÅÊ£íÊÄß„ÄÇHiMan-BenchÁöÑËÆæËÆ°ËÄÉËôë‰∫Ü‰ªªÂä°ÁöÑÂ§çÊùÇÂ∫¶ÂíåÊâ∞Âä®ÁöÑÂ§öÊ†∑ÊÄßÔºåËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞Êè≠Á§∫Ê®°ÂûãÁöÑÁì∂È¢à„ÄÇ‰∏âÁßçËØÑ‰º∞ËåÉÂºèËÉΩÂ§üÂàÜÂà´ËØÑ‰º∞ËßÑÂàíÂíåÊâßË°åÊ®°ÂùóÔºå‰ªéËÄåÊõ¥Ê∑±ÂÖ•Âú∞‰∫ÜËß£Ê®°ÂûãÁöÑË°å‰∏∫„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöHiMan-BenchÂü∫ÂáÜÊµãËØïÂåÖÂê´‰∏ÄÁ≥ªÂàóÂéüÂ≠ê‰ªªÂä°ÂíåÁªÑÂêà‰ªªÂä°ÔºåËøô‰∫õ‰ªªÂä°Ê∂µÁõñ‰∫Ü‰∏çÂêåÁöÑÊìç‰ΩúÁ±ªÂûãÂíåÂØπË±°„ÄÇÊâ∞Âä®Á±ªÂûãÂåÖÊã¨ËßÜËßâÊâ∞Âä®„ÄÅÁâ©ÁêÜÊâ∞Âä®ÂíåÊó∂Èó¥Êâ∞Âä®„ÄÇÂ§öÂ±ÇÊ¨°ËÆ≠ÁªÉÊï∞ÊçÆÈõÜÁî®‰∫éÂàÜÊûêÊ∏êËøõÂºèÊï∞ÊçÆÁº©ÊîæÂØπÊ®°ÂûãÊÄßËÉΩÁöÑÂΩ±Âìç„ÄÇ‰∏âÁßçËØÑ‰º∞ËåÉÂºèÈÄöËøá‰∏çÂêåÁöÑÊñπÂºèÁªÑÂêàËßÑÂàíÂíåÊâßË°åÊ®°ÂùóÔºå‰ªéËÄåËØÑ‰º∞Ê®°ÂûãÁöÑ‰∏çÂêåÊñπÈù¢„ÄÇÂÖ∑‰ΩìÁöÑÂèÇÊï∞ËÆæÁΩÆ„ÄÅÊçüÂ§±ÂáΩÊï∞ÂíåÁΩëÁªúÁªìÊûÑÂèñÂÜ≥‰∫éË¢´ËØÑ‰º∞ÁöÑÊ®°Âûã„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÁé∞ÊúâÁöÑ‰ª£Ë°®ÊÄßÊ®°ÂûãÂíåÊû∂ÊûÑÂú®RoboHiManÂü∫ÂáÜÊµãËØï‰∏≠Â≠òÂú®ÊòéÊòæÁöÑËÉΩÂäõÂ∑ÆË∑ùÔºåÂ∞§ÂÖ∂ÊòØÂú®ÁªÑÂêàÊ≥õÂåñÂíåÈ≤ÅÊ£íÊÄßÊñπÈù¢„ÄÇ‰æãÂ¶ÇÔºåÁ´ØÂà∞Á´ØÊ®°ÂûãÂú®Â§çÊùÇ‰ªªÂä°‰∏≠Ë°®Áé∞‰∏ç‰Ω≥ÔºåÂàÜÂ±ÇÊ®°ÂûãÂú®Èù¢ÂØπÊâ∞Âä®Êó∂ÂÆπÊòìÂ§±Êïà„ÄÇËøô‰∫õÁªìÊûú‰∏∫Êú™Êù•Ê®°ÂûãÁöÑËÆæËÆ°Êèê‰æõ‰∫ÜÈáçË¶ÅÁöÑÂèÇËÄÉ‰æùÊçÆ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

RoboHiManÁöÑÁ†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫Êìç‰Ωú„ÄÅËá™Âä®ÂåñÁîü‰∫ßÁ∫ø„ÄÅÊô∫ËÉΩÂÆ∂Â±ÖÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÊèêÂçáÊú∫Âô®‰∫∫ÁöÑÁªÑÂêàÊ≥õÂåñËÉΩÂäõÂíåÈ≤ÅÊ£íÊÄßÔºåÂèØ‰ª•‰ΩøÂÖ∂Êõ¥Â•ΩÂú∞ÈÄÇÂ∫îÂ§çÊùÇÂ§öÂèòÁöÑÁéØÂ¢ÉÔºåÂÆåÊàêÊõ¥Â§çÊùÇÁöÑ‰ªªÂä°„ÄÇËØ•Á†îÁ©∂ÊúâÂä©‰∫éÊé®Âä®Êú∫Âô®‰∫∫ÊäÄÊúØÂú®ÂÆûÈôÖÂú∫ÊôØ‰∏≠ÁöÑÂ∫îÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Enabling robots to flexibly schedule and compose learned skills for novel long-horizon manipulation under diverse perturbations remains a core challenge. Early explorations with end-to-end VLA models show limited success, as these models struggle to generalize beyond the training distribution. Hierarchical approaches, where high-level planners generate subgoals for low-level policies, bring certain improvements but still suffer under complex perturbations, revealing limited capability in skill composition. However, existing benchmarks primarily emphasize task completion in long-horizon settings, offering little insight into compositional generalization, robustness, and the interplay between planning and execution. To systematically investigate these gaps, we propose RoboHiMan, a hierarchical evaluation paradigm for compositional generalization in long-horizon manipulation. RoboHiMan introduces HiMan-Bench, a benchmark of atomic and compositional tasks under diverse perturbations, supported by a multi-level training dataset for analyzing progressive data scaling, and proposes three evaluation paradigms (vanilla, decoupled, coupled) that probe the necessity of skill composition and reveal bottlenecks in hierarchical architectures. Experiments highlight clear capability gaps across representative models and architectures, pointing to directions for advancing models better suited to real-world long-horizon manipulation tasks. Videos and open-source code can be found on our project website: https://chenyt31.github.io/robo-himan.github.io/.

