---
layout: default
title: ViTacGen: Robotic Pushing with Vision-to-Touch Generation
---

# ViTacGen: Robotic Pushing with Vision-to-Touch Generation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2510.14117" target="_blank" class="toolbar-btn">arXiv: 2510.14117v2</a>
    <a href="https://arxiv.org/pdf/2510.14117.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.14117v2" 
            onclick="toggleFavorite(this, '2510.14117v2', 'ViTacGen: Robotic Pushing with Vision-to-Touch Generation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Zhiyuan Wu, Yijiong Lin, Yongqiang Zhao, Xuyang Zhang, Zhuo Chen, Nathan Lepora, Shan Luo

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-15 (Êõ¥Êñ∞: 2025-10-23)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ViTacGenÔºöÂü∫‰∫éËßÜËßâÂà∞Ëß¶ËßâÁîüÊàêÁöÑÊú∫Âô®‰∫∫Êé®Áâ©Êìç‰ΩúÊ°ÜÊû∂**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Êú∫Âô®‰∫∫Êé®Áâ©` `ËßÜËßâËß¶ËßâËûçÂêà` `ËßÜËßâÂà∞Ëß¶ËßâÁîüÊàê` `Âº∫ÂåñÂ≠¶‰π†` `ÂØπÊØîÂ≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊú∫Âô®‰∫∫Êé®Áâ©Êìç‰Ωú‰æùËµñÊòÇË¥µÁöÑËß¶Ëßâ‰º†ÊÑüÂô®ÔºåÊàñÈù¢‰∏¥ËßÜËßâÁ≠ñÁï•ÊÄßËÉΩ‰∏çË∂≥ÁöÑÊåëÊàò„ÄÇ
2. ViTacGenÈÄöËøáËßÜËßâÂà∞Ëß¶ËßâÁîüÊàêÔºåÂ∞ÜËßÜËßâ‰ø°ÊÅØËΩ¨Âåñ‰∏∫Ëß¶ËßâË°®ÂæÅÔºåÁî®‰∫éÂº∫ÂåñÂ≠¶‰π†ÔºåÊó†ÈúÄÁúüÂÆûËß¶Ëßâ‰º†ÊÑüÂô®„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåViTacGenÂú®‰ªøÁúüÂíåÁúüÂÆûÁéØÂ¢É‰∏≠ÂùáË°®Áé∞Âá∫Ëâ≤ÔºåÊé®Áâ©ÊàêÂäüÁéáÈ´òËææ86%„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú∫Âô®‰∫∫Êé®Áâ©Êìç‰ΩúÊòØ‰∏ÄÈ°πÂü∫Á°ÄÊìç‰Ωú‰ªªÂä°ÔºåÈúÄË¶ÅËß¶ËßâÂèçÈ¶àÊù•ÊçïÊçâÊú´Á´ØÊâßË°åÂô®ÂíåÁâ©‰Ωì‰πãÈó¥ÁªÜÂæÆÁöÑÊé•Ëß¶ÂäõÂíåÂä®ÂäõÂ≠¶„ÄÇÁÑ∂ËÄåÔºåÁúüÂÆûÁöÑËß¶Ëßâ‰º†ÊÑüÂô®ÈÄöÂ∏∏Èù¢‰∏¥È´òÊàêÊú¨„ÄÅÊòìÊçüÂùèÁ≠âÁ°¨‰ª∂ÈôêÂà∂Ôºå‰ª•ÂèäÊ†°ÂáÜÂíå‰∏çÂêå‰º†ÊÑüÂô®‰πãÈó¥Â∑ÆÂºÇÁöÑÈÉ®ÁΩ≤ÊåëÊàòÔºåËÄå‰ªÖ‰ΩøÁî®ËßÜËßâÁöÑÁ≠ñÁï•Èöæ‰ª•Ëé∑Âæó‰ª§‰∫∫Êª°ÊÑèÁöÑÊÄßËÉΩ„ÄÇÂèóÂà∞‰∫∫Á±ª‰ªéËßÜËßâÊé®Êñ≠Ëß¶ËßâÁä∂ÊÄÅËÉΩÂäõÁöÑÂêØÂèëÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜViTacGenÔºå‰∏ÄÁßçÊñ∞È¢ñÁöÑÊú∫Âô®‰∫∫Êìç‰ΩúÊ°ÜÊû∂Ôºå‰∏ì‰∏∫ËßÜËßâÊú∫Âô®‰∫∫Êé®Áâ©ËÄåËÆæËÆ°ÔºåÈÄöËøáÂº∫ÂåñÂ≠¶‰π†‰∏≠ÁöÑËßÜËßâÂà∞Ëß¶ËßâÁîüÊàêÊù•Ê∂àÈô§ÂØπÈ´òÂàÜËæ®ÁéáÁúüÂÆûËß¶Ëßâ‰º†ÊÑüÂô®ÁöÑ‰æùËµñÔºå‰ªéËÄåÂú®‰ªÖËßÜËßâÊú∫Âô®‰∫∫Á≥ªÁªü‰∏äÂÆûÁé∞ÊúâÊïàÁöÑÈõ∂Ê†∑Êú¨ÈÉ®ÁΩ≤„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåViTacGenÂåÖÂê´‰∏Ä‰∏™ÁºñÁ†ÅÂô®-Ëß£Á†ÅÂô®ËßÜËßâÂà∞Ëß¶ËßâÁîüÊàêÁΩëÁªúÔºåËØ•ÁΩëÁªúÁõ¥Êé•‰ªéËßÜËßâÂõæÂÉèÂ∫èÂàóÁîüÊàêÊé•Ëß¶Ê∑±Â∫¶ÂõæÂÉèÔºà‰∏ÄÁßçÊ†áÂáÜÂåñÁöÑËß¶ËßâË°®Á§∫ÔºâÔºåÁÑ∂ÂêéÊòØ‰∏Ä‰∏™Âº∫ÂåñÂ≠¶‰π†Á≠ñÁï•ÔºåËØ•Á≠ñÁï•Âü∫‰∫éËßÜËßâÂíåÁîüÊàêÁöÑËß¶ËßâËßÇÊµãÔºåÈÄöËøáÂØπÊØîÂ≠¶‰π†ËûçÂêàËßÜËßâ-Ëß¶ËßâÊï∞ÊçÆ„ÄÇÊàë‰ª¨Âú®‰ªøÁúüÂíåÁúüÂÆû‰∏ñÁïåÂÆûÈ™å‰∏≠È™åËØÅ‰∫ÜÊàë‰ª¨ÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºåËØÅÊòé‰∫ÜÂÖ∂ÂçìË∂äÁöÑÊÄßËÉΩÔºåÂπ∂ÂÆûÁé∞‰∫ÜÈ´òËææ86%ÁöÑÊàêÂäüÁéá„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú∫Âô®‰∫∫Êé®Áâ©Êìç‰ΩúÈúÄË¶ÅÁ≤æÁ°ÆÁöÑËß¶ËßâÂèçÈ¶àÔºå‰ΩÜÁé∞ÊúâËß¶Ëßâ‰º†ÊÑüÂô®ÊàêÊú¨È´òÊòÇ„ÄÅÊòìÊçüÂùèÔºå‰∏îÈÉ®ÁΩ≤Ê†°ÂáÜÂõ∞Èöæ„ÄÇ‰ªÖ‰æùËµñËßÜËßâ‰ø°ÊÅØÁöÑÁ≠ñÁï•Èöæ‰ª•ÊçïÊçâÁâ©‰ΩìÈó¥ÁöÑÁªÜÂæÆÊé•Ëß¶ÔºåÂØºËá¥ÊÄßËÉΩ‰∏ç‰Ω≥„ÄÇÂõ†Ê≠§ÔºåÂ¶Ç‰ΩïÂú®Áº∫‰πèÂèØÈù†Ëß¶Ëßâ‰º†ÊÑüÂô®ÁöÑÊÉÖÂÜµ‰∏ãÔºåÂÆûÁé∞È´òÊÄßËÉΩÁöÑÊú∫Âô®‰∫∫Êé®Áâ©Êìç‰ΩúÊòØ‰∏Ä‰∏™ÂÖ≥ÈîÆÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöViTacGenÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÊ®°‰ªø‰∫∫Á±ª‰ªéËßÜËßâÊé®Êñ≠Ëß¶ËßâÁöÑËÉΩÂäõÔºåÈÄöËøáËßÜËßâ‰ø°ÊÅØÁîüÊàêËß¶ËßâË°®ÂæÅÔºå‰ªéËÄåÂú®Âº∫ÂåñÂ≠¶‰π†‰∏≠Âà©Áî®ËßÜËßâÂíåÁîüÊàêÁöÑËß¶Ëßâ‰ø°ÊÅØËøõË°åÁ≠ñÁï•Â≠¶‰π†„ÄÇËøôÁßçÊñπÊ≥ïÈÅøÂÖç‰∫ÜÂØπÁúüÂÆûËß¶Ëßâ‰º†ÊÑüÂô®ÁöÑ‰æùËµñÔºåÈôç‰Ωé‰∫ÜÊàêÊú¨ÂíåÈÉ®ÁΩ≤ÈöæÂ∫¶„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöViTacGenÊ°ÜÊû∂ÂåÖÂê´‰∏§‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöËßÜËßâÂà∞Ëß¶ËßâÁîüÊàêÁΩëÁªúÂíåÂº∫ÂåñÂ≠¶‰π†Á≠ñÁï•„ÄÇÈ¶ñÂÖàÔºåËßÜËßâÂà∞Ëß¶ËßâÁîüÊàêÁΩëÁªúÔºà‰∏Ä‰∏™ÁºñÁ†ÅÂô®-Ëß£Á†ÅÂô®ÁªìÊûÑÔºâ‰ªéËßÜËßâÂõæÂÉèÂ∫èÂàó‰∏≠ÁîüÊàêÊé•Ëß¶Ê∑±Â∫¶ÂõæÂÉèÔºå‰Ωú‰∏∫Ê†áÂáÜÂåñÁöÑËß¶ËßâË°®Á§∫„ÄÇÁÑ∂ÂêéÔºåÂº∫ÂåñÂ≠¶‰π†Á≠ñÁï•Â∞ÜËßÜËßâ‰ø°ÊÅØÂíåÁîüÊàêÁöÑËß¶Ëßâ‰ø°ÊÅØËûçÂêàÔºåÈÄöËøáÂØπÊØîÂ≠¶‰π†ÁöÑÊñπÂºèËøõË°åËÆ≠ÁªÉÔºåÊúÄÁªàÂ≠¶‰π†Âà∞ÊúâÊïàÁöÑÊé®Áâ©Á≠ñÁï•„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöViTacGenÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂà©Áî®ËßÜËßâ‰ø°ÊÅØÁîüÊàêËß¶ËßâË°®ÂæÅÔºåÂπ∂Â∞ÜÂÖ∂‰∏éËßÜËßâ‰ø°ÊÅØËûçÂêàÔºåÁî®‰∫éÂº∫ÂåñÂ≠¶‰π†„ÄÇËøôÁßçÊñπÊ≥ïÂ∞ÜËßÜËßâÂíåËß¶Ëßâ‰ø°ÊÅØÁªìÂêàËµ∑Êù•ÔºåÂÖãÊúç‰∫Ü‰ªÖ‰ΩøÁî®ËßÜËßâ‰ø°ÊÅØÁöÑÂ±ÄÈôêÊÄßÔºåÂêåÊó∂ÈÅøÂÖç‰∫ÜÂØπÁúüÂÆûËß¶Ëßâ‰º†ÊÑüÂô®ÁöÑ‰æùËµñ„ÄÇÈÄöËøáÂØπÊØîÂ≠¶‰π†ÔºåÊ®°ÂûãËÉΩÂ§üÊõ¥Â•ΩÂú∞ÁêÜËß£ËßÜËßâÂíåËß¶Ëßâ‰ø°ÊÅØ‰πãÈó¥ÁöÑÂÖ≥Á≥ªÔºå‰ªéËÄåÊèêÈ´òÁ≠ñÁï•ÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËßÜËßâÂà∞Ëß¶ËßâÁîüÊàêÁΩëÁªúÈááÁî®ÁºñÁ†ÅÂô®-Ëß£Á†ÅÂô®ÁªìÊûÑÔºåÁºñÁ†ÅÂô®ÊèêÂèñËßÜËßâÁâπÂæÅÔºåËß£Á†ÅÂô®ÁîüÊàêÊé•Ëß¶Ê∑±Â∫¶ÂõæÂÉè„ÄÇÂº∫ÂåñÂ≠¶‰π†Á≠ñÁï•‰ΩøÁî®ÂØπÊØîÂ≠¶‰π†ÊçüÂ§±ÔºåÈºìÂä±Ê®°ÂûãÂ≠¶‰π†ËßÜËßâÂíåÁîüÊàêÁöÑËß¶Ëßâ‰ø°ÊÅØ‰πãÈó¥ÁöÑÂÖ±ÂêåË°®Á§∫„ÄÇÂÖ∑‰ΩìÁöÑÁΩëÁªúÁªìÊûÑÂíåÂèÇÊï∞ËÆæÁΩÆÔºàÂ¶ÇÂç∑ÁßØÊ†∏Â§ßÂ∞è„ÄÅÂ±ÇÊï∞Á≠âÔºâ‰ª•ÂèäÂØπÊØîÂ≠¶‰π†ÁöÑÊ∏©Â∫¶ÂèÇÊï∞Á≠âÁªÜËäÇÔºåÈúÄË¶ÅÂú®ÂÆûÈ™å‰∏≠ËøõË°åË∞ÉÊï¥Âíå‰ºòÂåñ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ViTacGenÂú®‰ªøÁúüÂíåÁúüÂÆû‰∏ñÁïåÂÆûÈ™å‰∏≠ÂùáÂèñÂæó‰∫ÜÊòæËëóÊàêÊûú„ÄÇÂú®ÁúüÂÆûÊú∫Âô®‰∫∫Êé®Áâ©‰ªªÂä°‰∏≠ÔºåViTacGenÁöÑÊàêÂäüÁéáÈ´òËææ86%ÔºåÊòæËëó‰ºò‰∫é‰ªÖ‰ΩøÁî®ËßÜËßâ‰ø°ÊÅØÁöÑÂü∫Á∫øÊñπÊ≥ï„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÈÄöËøáËßÜËßâÂà∞Ëß¶ËßâÁîüÊàêÔºåViTacGenËÉΩÂ§üÊúâÊïàÂú∞ÊèêÂçáÊú∫Âô®‰∫∫Êé®Áâ©Êìç‰ΩúÁöÑÊÄßËÉΩÂíåÈ≤ÅÊ£íÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ViTacGenÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂèØÂ∫îÁî®‰∫éÂ∑•‰∏öËá™Âä®Âåñ„ÄÅÁâ©ÊµÅÂàÜÊã£„ÄÅÂÆ∂Â∫≠ÊúçÂä°Á≠âÈ¢ÜÂüü„ÄÇ‰æãÂ¶ÇÔºåÂú®Â§çÊùÇÁéØÂ¢É‰∏ãËøõË°åÁâ©‰ΩìÊìç‰ΩúÁöÑÊú∫Âô®‰∫∫ÔºåÂèØ‰ª•Âà©Áî®ViTacGenÂú®Áº∫‰πèËß¶Ëßâ‰º†ÊÑüÂô®ÁöÑÊÉÖÂÜµ‰∏ãÔºåÂÆûÁé∞Á≤æÁ°ÆÁöÑÁâ©‰ΩìÊäìÂèñÂíåÊîæÁΩÆ„ÄÇËØ•Á†îÁ©∂Èôç‰Ωé‰∫ÜÊú∫Âô®‰∫∫Êìç‰ΩúÂØπÁ°¨‰ª∂ÁöÑ‰æùËµñÔºå‰øÉËøõ‰∫Ü‰ΩéÊàêÊú¨„ÄÅÈ´òÈ≤ÅÊ£íÊÄßÊú∫Âô®‰∫∫Á≥ªÁªüÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Robotic pushing is a fundamental manipulation task that requires tactile feedback to capture subtle contact forces and dynamics between the end-effector and the object. However, real tactile sensors often face hardware limitations such as high costs and fragility, and deployment challenges involving calibration and variations between different sensors, while vision-only policies struggle with satisfactory performance. Inspired by humans' ability to infer tactile states from vision, we propose ViTacGen, a novel robot manipulation framework designed for visual robotic pushing with vision-to-touch generation in reinforcement learning to eliminate the reliance on high-resolution real tactile sensors, enabling effective zero-shot deployment on visual-only robotic systems. Specifically, ViTacGen consists of an encoder-decoder vision-to-touch generation network that generates contact depth images, a standardized tactile representation, directly from visual image sequence, followed by a reinforcement learning policy that fuses visual-tactile data with contrastive learning based on visual and generated tactile observations. We validate the effectiveness of our approach in both simulation and real world experiments, demonstrating its superior performance and achieving a success rate of up to 86\%.

