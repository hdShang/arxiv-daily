---
layout: default
title: LIBERO-Plus: In-depth Robustness Analysis of Vision-Language-Action Models
---

# LIBERO-Plus: In-depth Robustness Analysis of Vision-Language-Action Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.13626" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.13626v2</a>
  <a href="https://arxiv.org/pdf/2510.13626.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.13626v2" onclick="toggleFavorite(this, '2510.13626v2', 'LIBERO-Plus: In-depth Robustness Analysis of Vision-Language-Action Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Senyu Fei, Siyin Wang, Junhao Shi, Zihao Dai, Jikun Cai, Pengfang Qian, Li Ji, Xinzhe He, Shiduo Zhang, Zhaoye Fei, Jinlan Fu, Jingjing Gong, Xipeng Qiu

**åˆ†ç±»**: cs.RO, cs.CL, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-15 (æ›´æ–°: 2025-10-24)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**LIBERO-Plusï¼šå¯¹è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹è¿›è¡Œæ·±åº¦é²æ£’æ€§åˆ†æ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€åŠ¨ä½œæ¨¡å‹` `æœºå™¨äººæ“ä½œ` `é²æ£’æ€§åˆ†æ` `æ‰°åŠ¨æµ‹è¯•` `è„†å¼±æ€§è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰VLAæ¨¡å‹åœ¨ç†æƒ³ç¯å¢ƒä¸‹è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨çœŸå®åœºæ™¯ä¸­é²æ£’æ€§ä¸è¶³ï¼Œæ˜“å—å„ç§å› ç´ å¹²æ‰°ã€‚
2. é€šè¿‡å¼•å…¥ä¸ƒä¸ªç»´åº¦çš„å—æ§æ‰°åŠ¨ï¼Œç³»ç»Ÿæ€§åœ°è¯„ä¼°VLAæ¨¡å‹åœ¨ä¸åŒæ‰°åŠ¨ä¸‹çš„æ€§èƒ½è¡¨ç°ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒVLAæ¨¡å‹å¯¹ç›¸æœºè§†è§’å’Œæœºå™¨äººåˆå§‹çŠ¶æ€ç­‰æ‰°åŠ¨é«˜åº¦æ•æ„Ÿï¼Œä¸”å€¾å‘äºå¿½ç•¥è¯­è¨€æŒ‡ä»¤ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€-åŠ¨ä½œ(VLA)æ¨¡å‹åœ¨æœºå™¨äººæ“ä½œåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†ä»¤äººç©ç›®çš„æˆåŠŸç‡ï¼Œç„¶è€Œè¿™äº›ç»“æœå¯èƒ½æ©ç›–äº†é²æ£’æ€§æ–¹é¢çš„æ ¹æœ¬å¼±ç‚¹ã€‚æˆ‘ä»¬é€šè¿‡åœ¨ä¸ƒä¸ªç»´åº¦ä¸Šå¼•å…¥å—æ§æ‰°åŠ¨ï¼Œè¿›è¡Œç³»ç»Ÿçš„è„†å¼±æ€§åˆ†æï¼šç‰©ä½“å¸ƒå±€ã€ç›¸æœºè§†è§’ã€æœºå™¨äººåˆå§‹çŠ¶æ€ã€è¯­è¨€æŒ‡ä»¤ã€å…‰ç…§æ¡ä»¶ã€èƒŒæ™¯çº¹ç†å’Œä¼ æ„Ÿå™¨å™ªå£°ã€‚æˆ‘ä»¬å…¨é¢åˆ†æäº†å¤šä¸ªæœ€å…ˆè¿›çš„æ¨¡å‹ï¼Œæ­ç¤ºäº†è¡¨é¢èƒ½åŠ›ä¹‹ä¸‹çš„æŒç»­è„†å¼±æ€§ã€‚æˆ‘ä»¬çš„åˆ†ææ­ç¤ºäº†å…³é”®å¼±ç‚¹ï¼šæ¨¡å‹å¯¹æ‰°åŠ¨å› ç´ è¡¨ç°å‡ºæç«¯çš„æ•æ„Ÿæ€§ï¼ŒåŒ…æ‹¬ç›¸æœºè§†è§’å’Œæœºå™¨äººåˆå§‹çŠ¶æ€ï¼Œåœ¨é€‚åº¦æ‰°åŠ¨ä¸‹æ€§èƒ½ä»95%ä¸‹é™åˆ°30%ä»¥ä¸‹ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œæ¨¡å‹åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå¯¹è¯­è¨€å˜åŒ–ä¸æ•æ„Ÿï¼Œè¿›ä¸€æ­¥çš„å®éªŒè¡¨æ˜ï¼Œæ¨¡å‹å€¾å‘äºå®Œå…¨å¿½ç•¥è¯­è¨€æŒ‡ä»¤ã€‚æˆ‘ä»¬çš„å‘ç°æŒ‘æˆ˜äº†é«˜åŸºå‡†åˆ†æ•°ç­‰åŒäºçœŸæ­£èƒ½åŠ›çš„å‡è®¾ï¼Œå¹¶å¼ºè°ƒéœ€è¦è¯„ä¼°åœ¨çœŸå®å˜åŒ–ä¸‹å¯é æ€§çš„è¯„ä¼°å®è·µã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰è§†è§‰-è¯­è¨€-åŠ¨ä½œ(VLA)æ¨¡å‹åœ¨æ ‡å‡†æœºå™¨äººæ“ä½œåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†é«˜åˆ†ï¼Œä½†è¿™äº›åˆ†æ•°æ˜¯å¦çœŸå®åæ˜ äº†æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„èƒ½åŠ›ï¼Ÿç°æœ‰æ–¹æ³•ç¼ºä¹å¯¹æ¨¡å‹é²æ£’æ€§çš„æ·±å…¥åˆ†æï¼Œæ— æ³•æ­ç¤ºæ¨¡å‹åœ¨é¢å¯¹çœŸå®ä¸–ç•Œå¤æ‚ç¯å¢ƒæ—¶çš„è„†å¼±æ€§ã€‚å› æ­¤ï¼Œè¯¥è®ºæ–‡æ—¨åœ¨ç³»ç»Ÿæ€§åœ°è¯„ä¼°VLAæ¨¡å‹åœ¨å„ç§æ‰°åŠ¨ä¸‹çš„æ€§èƒ½è¡¨ç°ï¼Œä»è€Œå‘ç°æ¨¡å‹çš„æ½œåœ¨å¼±ç‚¹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè¯¥è®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼•å…¥å—æ§çš„æ‰°åŠ¨ï¼Œæ¨¡æ‹ŸçœŸå®ä¸–ç•Œä¸­å¯èƒ½å‡ºç°çš„å„ç§å˜åŒ–ï¼Œä»è€Œè¯„ä¼°VLAæ¨¡å‹åœ¨ä¸åŒæ‰°åŠ¨ä¸‹çš„é²æ£’æ€§ã€‚é€šè¿‡åˆ†ææ¨¡å‹åœ¨ä¸åŒæ‰°åŠ¨ä¸‹çš„æ€§èƒ½å˜åŒ–ï¼Œå¯ä»¥æ­ç¤ºæ¨¡å‹å¯¹å“ªäº›å› ç´ æ•æ„Ÿï¼Œä»¥åŠæ¨¡å‹åœ¨å“ªäº›æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥è®ºæ–‡æ„å»ºäº†ä¸€ä¸ªå…¨é¢çš„è¯„ä¼°æ¡†æ¶ï¼ŒåŒ…å«ä¸ƒä¸ªæ‰°åŠ¨ç»´åº¦ï¼šç‰©ä½“å¸ƒå±€ã€ç›¸æœºè§†è§’ã€æœºå™¨äººåˆå§‹çŠ¶æ€ã€è¯­è¨€æŒ‡ä»¤ã€å…‰ç…§æ¡ä»¶ã€èƒŒæ™¯çº¹ç†å’Œä¼ æ„Ÿå™¨å™ªå£°ã€‚é’ˆå¯¹æ¯ä¸ªç»´åº¦ï¼Œè®¾è®¡äº†ç›¸åº”çš„æ‰°åŠ¨ç­–ç•¥ï¼Œå¹¶ä½¿ç”¨è¿™äº›æ‰°åŠ¨ç­–ç•¥å¯¹VLAæ¨¡å‹è¿›è¡Œæµ‹è¯•ã€‚é€šè¿‡æ¯”è¾ƒæ¨¡å‹åœ¨åŸå§‹ç¯å¢ƒå’Œæ‰°åŠ¨ç¯å¢ƒä¸‹çš„æ€§èƒ½ï¼Œå¯ä»¥è¯„ä¼°æ¨¡å‹å¯¹è¯¥ç»´åº¦æ‰°åŠ¨çš„æ•æ„Ÿæ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå…¶ç³»ç»Ÿæ€§çš„æ‰°åŠ¨åˆ†ææ–¹æ³•ã€‚ä¸ä»¥å¾€çš„ç ”ç©¶ä¸åŒï¼Œè¯¥è®ºæ–‡ä¸ä»…è€ƒè™‘äº†å•ä¸€çš„æ‰°åŠ¨å› ç´ ï¼Œè€Œæ˜¯åŒæ—¶è€ƒè™‘äº†å¤šä¸ªæ‰°åŠ¨å› ç´ ï¼Œä»è€Œæ›´å…¨é¢åœ°è¯„ä¼°äº†VLAæ¨¡å‹çš„é²æ£’æ€§ã€‚æ­¤å¤–ï¼Œè¯¥è®ºæ–‡è¿˜å‘ç°äº†ä¸€äº›ä»¤äººæƒŠè®¶çš„ç°è±¡ï¼Œä¾‹å¦‚æ¨¡å‹å¯¹è¯­è¨€æŒ‡ä»¤çš„å¿½ç•¥ï¼Œè¿™ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†æ–°çš„æ–¹å‘ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ‰°åŠ¨ç­–ç•¥çš„è®¾è®¡ä¸Šï¼Œè®ºæ–‡é’ˆå¯¹æ¯ä¸ªç»´åº¦éƒ½è¿›è¡Œäº†ç²¾å¿ƒçš„è®¾è®¡ã€‚ä¾‹å¦‚ï¼Œåœ¨ç›¸æœºè§†è§’æ‰°åŠ¨æ–¹é¢ï¼Œè®ºæ–‡é€šè¿‡æ”¹å˜ç›¸æœºçš„ä¿¯ä»°è§’å’Œæ–¹ä½è§’æ¥æ¨¡æ‹Ÿä¸åŒçš„è§†è§’å˜åŒ–ã€‚åœ¨è¯­è¨€æŒ‡ä»¤æ‰°åŠ¨æ–¹é¢ï¼Œè®ºæ–‡é€šè¿‡æ”¹å˜æŒ‡ä»¤çš„æªè¾å’Œå¥å¼æ¥æ¨¡æ‹Ÿä¸åŒçš„è¯­è¨€è¡¨è¾¾æ–¹å¼ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜ä½¿ç”¨äº†å¤šç§è¯„ä»·æŒ‡æ ‡æ¥è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬æˆåŠŸç‡ã€å¹³å‡å®Œæˆæ—¶é—´å’Œè½¨è¿¹ç›¸ä¼¼åº¦ç­‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒVLAæ¨¡å‹å¯¹ç›¸æœºè§†è§’å’Œæœºå™¨äººåˆå§‹çŠ¶æ€ç­‰æ‰°åŠ¨é«˜åº¦æ•æ„Ÿï¼Œåœ¨é€‚åº¦æ‰°åŠ¨ä¸‹æ€§èƒ½ä»95%ä¸‹é™åˆ°30%ä»¥ä¸‹ã€‚æ­¤å¤–ï¼Œå®éªŒè¿˜å‘ç°æ¨¡å‹åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå¿½ç•¥è¯­è¨€æŒ‡ä»¤ï¼Œå³ä½¿æ”¹å˜æŒ‡ä»¤å†…å®¹ï¼Œæ¨¡å‹çš„è¡Œä¸ºä¹Ÿå‡ ä¹æ²¡æœ‰å˜åŒ–ã€‚è¿™äº›å‘ç°æŒ‘æˆ˜äº†ç°æœ‰VLAæ¨¡å‹çš„å¯é æ€§ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†é‡è¦çš„å¯ç¤ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæœºå™¨äººæ“ä½œç³»ç»Ÿçš„å¼€å‘ä¸è¯„ä¼°ï¼Œå¸®åŠ©å¼€å‘è€…è®¾è®¡æ›´é²æ£’ã€æ›´å¯é çš„VLAæ¨¡å‹ã€‚é€šè¿‡è¯†åˆ«æ¨¡å‹çš„å¼±ç‚¹ï¼Œå¯ä»¥é’ˆå¯¹æ€§åœ°æ”¹è¿›æ¨¡å‹çš„è®¾è®¡ï¼Œæé«˜æ¨¡å‹åœ¨çœŸå®ä¸–ç•Œç¯å¢ƒä¸­çš„é€‚åº”èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶ä¹Ÿä¸ºæœºå™¨äººæ“ä½œåŸºå‡†æµ‹è¯•çš„è®¾è®¡æä¾›äº†æ–°çš„æ€è·¯ï¼Œå¯ä»¥è®¾è®¡æ›´å…·æŒ‘æˆ˜æ€§çš„æµ‹è¯•åœºæ™¯ï¼Œä»è€Œæ›´å…¨é¢åœ°è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Visual-Language-Action (VLA) models report impressive success rates on robotic manipulation benchmarks, yet these results may mask fundamental weaknesses in robustness. We perform a systematic vulnerability analysis by introducing controlled perturbations across seven dimensions: objects layout, camera viewpoints, robot initial states, language instructions, light conditions, background textures and sensor noise. We comprehensively analyzed multiple state-of-the-art models and revealed consistent brittleness beneath apparent competence. Our analysis exposes critical weaknesses: models exhibit extreme sensitivity to perturbation factors, including camera viewpoints and robot initial states, with performance dropping from 95% to below 30% under modest perturbations. Surprisingly, models are largely insensitive to language variations, with further experiments revealing that models tend to ignore language instructions completely. Our findings challenge the assumption that high benchmark scores equate to true competency and highlight the need for evaluation practices that assess reliability under realistic variation.

