---
layout: default
title: Active Tactile Exploration for Rigid Body Pose and Shape Estimation
---

# Active Tactile Exploration for Rigid Body Pose and Shape Estimation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.13595" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.13595v1</a>
  <a href="https://arxiv.org/pdf/2510.13595.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.13595v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.13595v1', 'Active Tactile Exploration for Rigid Body Pose and Shape Estimation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ethan K. Gordon, Bruke Baraki, Hien Bui, Michael Posa

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-10-15

**å¤‡æ³¨**: 8 pages, 6 figures

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://dairlab.github.io/activetactile)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºä¸»åŠ¨è§¦è§‰æ¢ç´¢çš„åˆšä½“ä½å§¿ä¸å½¢çŠ¶ä¼°è®¡æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `ä¸»åŠ¨è§¦è§‰æ¢ç´¢` `åˆšä½“ä½å§¿ä¼°è®¡` `å½¢çŠ¶ä¼°è®¡` `æœºå™¨äººæ“ä½œ` `é¢„æœŸä¿¡æ¯å¢ç›Š`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. é€šç”¨æœºå™¨äººæ“ä½œéœ€è¦å¤„ç†å…ˆå‰æœªè§è¿‡çš„ç‰©ä½“ï¼Œæµ‹è¯•æ—¶å­¦ä¹ ç‰©ç†ç²¾ç¡®çš„æ¨¡å‹å¯ä»¥æ˜¾è‘—æé«˜æ•°æ®æ•ˆç‡ã€å¯é¢„æµ‹æ€§å’Œä»»åŠ¡é—´çš„é‡ç”¨æ€§ã€‚
2. è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºä¸»åŠ¨è§¦è§‰æ¢ç´¢çš„å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºåŒæ—¶ä¼°è®¡åˆšæ€§ç‰©ä½“çš„å½¢çŠ¶å’Œä½ç½®ï¼Œæ—¨åœ¨æœ€å°åŒ–æœºå™¨äººè¿åŠ¨å¹¶æé«˜æ•°æ®æ•ˆç‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®æœºå™¨äººç¯å¢ƒä¸­ï¼Œåˆ©ç”¨å°‘é‡è§¦è§‰æ•°æ®å¿«é€Ÿå­¦ä¹ ç‰©ä½“çš„å‡ ä½•å½¢çŠ¶ï¼Œå¹¶ä¼˜äºéšæœºæ¢ç´¢ç­–ç•¥ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§å­¦ä¹ ä¸æ¢ç´¢æ¡†æ¶ï¼Œä»…ä½¿ç”¨è§¦è§‰æ•°æ®æ¥åŒæ—¶ç¡®å®šåˆšæ€§ç‰©ä½“çš„å½¢çŠ¶å’Œä½ç½®ï¼Œå¹¶æœ€å¤§é™åº¦åœ°å‡å°‘æœºå™¨äººè¿åŠ¨ã€‚è¯¥æ–¹æ³•åŸºäºæ¥è§¦ä¸°å¯Œçš„ç³»ç»Ÿè¯†åˆ«çš„æœ€æ–°è¿›å±•ï¼Œæ„å»ºäº†ä¸€ä¸ªæŸå¤±å‡½æ•°ï¼Œè¯¥å‡½æ•°æƒ©ç½šç‰©ç†çº¦æŸè¿åï¼Œè€Œä¸ä¼šå¼•å…¥åˆšä½“æ¥è§¦ä¸­å›ºæœ‰çš„æ•°å€¼åˆšåº¦ã€‚é€šè¿‡ä¼˜åŒ–æ­¤æŸå¤±ï¼Œå¯ä»¥åœ¨é¦–æ¬¡æ¥è§¦åä½¿ç”¨å°‘äº10ç§’çš„éšæœºæ”¶é›†æ•°æ®æ¥å­¦ä¹ é•¿æ–¹ä½“å’Œå‡¸å¤šé¢ä½“å‡ ä½•å½¢çŠ¶ã€‚æ¢ç´¢æ–¹æ¡ˆæ—¨åœ¨æœ€å¤§åŒ–é¢„æœŸä¿¡æ¯å¢ç›Šï¼Œå¹¶åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®æœºå™¨äººå®éªŒä¸­å®ç°æ›´å¿«çš„å­¦ä¹ ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­ï¼Œå¤„ç†æœªçŸ¥çš„åˆšæ€§ç‰©ä½“æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚ä¼ ç»Ÿçš„è§†è§‰æ–¹æ³•å®¹æ˜“å—åˆ°é®æŒ¡çš„å½±å“ï¼Œè€Œè§¦è§‰æ„ŸçŸ¥è™½ç„¶å¯¹é®æŒ¡å…·æœ‰é²æ£’æ€§ï¼Œä½†å…¶æ—¶é—´ç¨€ç–æ€§ä½¿å¾—åœ¨çº¿æ¢ç´¢éœ€è¦è°¨æ…è®¾è®¡ä»¥ä¿è¯æ•°æ®æ•ˆç‡ã€‚æ­¤å¤–ï¼Œç›´æ¥æ¥è§¦å¯èƒ½å¯¼è‡´ç‰©ä½“ç§»åŠ¨ï¼Œå› æ­¤éœ€è¦åŒæ—¶ä¼°è®¡ç‰©ä½“çš„å½¢çŠ¶å’Œä½ç½®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè¯¥è®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨ä¸»åŠ¨è§¦è§‰æ¢ç´¢ï¼Œé€šè¿‡ä¼˜åŒ–é¢„æœŸä¿¡æ¯å¢ç›Šæ¥æŒ‡å¯¼æœºå™¨äººè¿›è¡Œè§¦è§‰é‡‡æ ·ï¼Œä»è€Œåœ¨å°½å¯èƒ½å°‘çš„è§¦è§‰äº¤äº’ä¸­ï¼ŒåŒæ—¶å­¦ä¹ ç‰©ä½“çš„å½¢çŠ¶å’Œä½å§¿ã€‚å…³é”®åœ¨äºè®¾è®¡ä¸€ä¸ªèƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨è§¦è§‰ä¿¡æ¯ï¼Œå¹¶èƒ½å¤„ç†åˆšä½“æ¥è§¦çº¦æŸçš„æŸå¤±å‡½æ•°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) è§¦è§‰æ•°æ®é‡‡é›†æ¨¡å—ï¼Œé€šè¿‡æœºå™¨äººä¸Šçš„è§¦è§‰ä¼ æ„Ÿå™¨è·å–ä¸ç‰©ä½“çš„æ¥è§¦ä¿¡æ¯ã€‚2) åŸºäºæ¥è§¦ä¸°å¯Œçš„ç³»ç»Ÿè¯†åˆ«çš„æŸå¤±å‡½æ•°æ„å»ºæ¨¡å—ï¼Œè¯¥æŸå¤±å‡½æ•°æƒ©ç½šç‰©ç†çº¦æŸè¿åã€‚3) ä¼˜åŒ–æ¨¡å—ï¼Œé€šè¿‡ä¼˜åŒ–æŸå¤±å‡½æ•°æ¥å­¦ä¹ ç‰©ä½“çš„å½¢çŠ¶å’Œä½å§¿ã€‚4) ä¸»åŠ¨æ¢ç´¢æ¨¡å—ï¼Œé€šè¿‡æœ€å¤§åŒ–é¢„æœŸä¿¡æ¯å¢ç›Šæ¥é€‰æ‹©ä¸‹ä¸€ä¸ªè§¦è§‰æ¢ç´¢åŠ¨ä½œã€‚æ•´ä½“æµç¨‹æ˜¯ï¼šæœºå™¨äººé¦–å…ˆè¿›è¡Œåˆå§‹è§¦è§‰æ¥è§¦ï¼Œç„¶åæ ¹æ®å½“å‰ä¼°è®¡çš„ç‰©ä½“å½¢çŠ¶å’Œä½å§¿ï¼Œåˆ©ç”¨ä¸»åŠ¨æ¢ç´¢ç­–ç•¥é€‰æ‹©ä¸‹ä¸€ä¸ªè§¦è§‰æ¢ç´¢åŠ¨ä½œï¼Œé‡‡é›†æ–°çš„è§¦è§‰æ•°æ®ï¼Œå¹¶æ›´æ–°ç‰©ä½“å½¢çŠ¶å’Œä½å§¿çš„ä¼°è®¡ï¼Œé‡å¤æ­¤è¿‡ç¨‹ç›´åˆ°æ»¡è¶³åœæ­¢æ¡ä»¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†ä¸€ç§åŸºäºé¢„æœŸä¿¡æ¯å¢ç›Šçš„ä¸»åŠ¨è§¦è§‰æ¢ç´¢ç­–ç•¥ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°æŒ‡å¯¼æœºå™¨äººè¿›è¡Œè§¦è§‰é‡‡æ ·ï¼Œä»è€Œæé«˜å­¦ä¹ æ•ˆç‡ã€‚2) æ„å»ºäº†ä¸€ä¸ªèƒ½å¤Ÿå¤„ç†åˆšä½“æ¥è§¦çº¦æŸçš„æŸå¤±å‡½æ•°ï¼Œè¯¥æŸå¤±å‡½æ•°é¿å…äº†ä¼ ç»Ÿåˆšä½“æ¥è§¦æ¨¡å‹ä¸­å›ºæœ‰çš„æ•°å€¼åˆšåº¦é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šæŸå¤±å‡½æ•°çš„è®¾è®¡æ˜¯å…³é”®ã€‚è¯¥æŸå¤±å‡½æ•°åŸºäºæ¥è§¦ä¸°å¯Œçš„ç³»ç»Ÿè¯†åˆ«ï¼Œæ—¨åœ¨æƒ©ç½šç‰©ç†çº¦æŸè¿åï¼ŒåŒæ—¶é¿å…å¼•å…¥æ•°å€¼åˆšåº¦ã€‚ä¸»åŠ¨æ¢ç´¢ç­–ç•¥é€šè¿‡æœ€å¤§åŒ–é¢„æœŸä¿¡æ¯å¢ç›Šæ¥é€‰æ‹©ä¸‹ä¸€ä¸ªè§¦è§‰æ¢ç´¢åŠ¨ä½œã€‚å…·ä½“è€Œè¨€ï¼Œé¢„æœŸä¿¡æ¯å¢ç›Šçš„è®¡ç®—æ¶‰åŠåˆ°å¯¹ç‰©ä½“å½¢çŠ¶å’Œä½å§¿çš„ä¸ç¡®å®šæ€§çš„ä¼°è®¡ï¼Œä»¥åŠå¯¹ä¸åŒè§¦è§‰æ¢ç´¢åŠ¨ä½œå¯èƒ½å¸¦æ¥çš„ä¿¡æ¯å¢ç›Šçš„é¢„æµ‹ã€‚è®ºæ–‡ä¸­ä½¿ç”¨äº†ç‰¹å®šçš„ä¼˜åŒ–ç®—æ³•æ¥æœ€å°åŒ–æŸå¤±å‡½æ•°ï¼Œå¹¶æœ€å¤§åŒ–é¢„æœŸä¿¡æ¯å¢ç›Šã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ï¼ˆå¦‚æœä½¿ç”¨ç¥ç»ç½‘ç»œï¼‰åœ¨è®ºæ–‡ä¸­åº”è¯¥æœ‰è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥è®ºæ–‡çš„å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„ä¸»åŠ¨è§¦è§‰æ¢ç´¢æ–¹æ³•èƒ½å¤Ÿæ˜¾è‘—æé«˜åˆšä½“ä½å§¿ä¸å½¢çŠ¶ä¼°è®¡çš„æ•ˆç‡ã€‚åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®æœºå™¨äººå®éªŒä¸­ï¼Œè¯¥æ–¹æ³•ä»…éœ€å°‘äº10ç§’çš„éšæœºæ•°æ®å³å¯å­¦ä¹ é•¿æ–¹ä½“å’Œå‡¸å¤šé¢ä½“å‡ ä½•å½¢çŠ¶ã€‚ä¸éšæœºæ¢ç´¢ç­–ç•¥ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´å¿«åœ°æ”¶æ•›åˆ°å‡†ç¡®çš„ç‰©ä½“å½¢çŠ¶å’Œä½å§¿ä¼°è®¡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæœºå™¨äººæ“ä½œã€è‡ªåŠ¨åŒ–è£…é…ã€ç‰©ä½“è¯†åˆ«ä¸å®šä½ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨æœªçŸ¥ç¯å¢ƒä¸‹ï¼Œæœºå™¨äººå¯ä»¥é€šè¿‡ä¸»åŠ¨è§¦è§‰æ¢ç´¢å¿«é€Ÿå­¦ä¹ ç‰©ä½“çš„å½¢çŠ¶å’Œä½å§¿ï¼Œä»è€Œå®ç°ç²¾ç¡®æŠ“å–å’Œæ“ä½œã€‚è¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºè´¨é‡æ£€æµ‹ï¼Œé€šè¿‡è§¦è§‰æ„ŸçŸ¥åˆ¤æ–­ç‰©ä½“çš„å½¢çŠ¶å’Œå°ºå¯¸æ˜¯å¦ç¬¦åˆè¦æ±‚ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºæ›´å¤æ‚çš„æœºå™¨äººä»»åŠ¡ï¼Œä¾‹å¦‚åœ¨æ‹¥æŒ¤ç¯å¢ƒä¸­è¿›è¡Œç‰©ä½“æ“ä½œã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> General robot manipulation requires the handling of previously unseen objects. Learning a physically accurate model at test time can provide significant benefits in data efficiency, predictability, and reuse between tasks. Tactile sensing can compliment vision with its robustness to occlusion, but its temporal sparsity necessitates careful online exploration to maintain data efficiency. Direct contact can also cause an unrestrained object to move, requiring both shape and location estimation. In this work, we propose a learning and exploration framework that uses only tactile data to simultaneously determine the shape and location of rigid objects with minimal robot motion. We build on recent advances in contact-rich system identification to formulate a loss function that penalizes physical constraint violation without introducing the numerical stiffness inherent in rigid-body contact. Optimizing this loss, we can learn cuboid and convex polyhedral geometries with less than 10s of randomly collected data after first contact. Our exploration scheme seeks to maximize Expected Information Gain and results in significantly faster learning in both simulated and real-robot experiments. More information can be found at https://dairlab.github.io/activetactile

