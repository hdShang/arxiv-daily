---
layout: default
title: Enhancing Tactile-based Reinforcement Learning for Robotic Control
---

# Enhancing Tactile-based Reinforcement Learning for Robotic Control

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.21609" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.21609v1</a>
  <a href="https://arxiv.org/pdf/2510.21609.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.21609v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.21609v1', 'Enhancing Tactile-based Reinforcement Learning for Robotic Control')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Elle Miller, Trevor McInroe, David Abel, Oisin Mac Aodha, Sethu Vijayakumar

**åˆ†ç±»**: cs.RO, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-10-24

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://elle-miller.github.io/tactile_rl)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè‡ªç›‘ç£å­¦ä¹ æ–¹æ³•ä»¥å¢å¼ºæœºå™¨äººè§¦è§‰å¼ºåŒ–å­¦ä¹ **

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è§¦è§‰æ„ŸçŸ¥` `è‡ªç›‘ç£å­¦ä¹ ` `å¼ºåŒ–å­¦ä¹ ` `æœºå™¨äººæ“ä½œ` `çµå·§æ€§` `ç¨€ç–ä¿¡å·` `æ¥è§¦ä»»åŠ¡` `æ€§èƒ½æå‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æœºå™¨äººæ“ä½œä¸­ä¸»è¦ä¾èµ–è§†è§‰ä¿¡æ¯ï¼Œå¿½è§†äº†è§¦è§‰æ„ŸçŸ¥çš„æ½œåŠ›ï¼Œå¯¼è‡´åœ¨å¤æ‚ç¯å¢ƒä¸­è¡¨ç°ä¸ä½³ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œæ—¨åœ¨æ›´æœ‰æ•ˆåœ°åˆ©ç”¨ç¨€ç–äºŒè¿›åˆ¶è§¦è§‰ä¿¡å·ï¼Œå¢å¼ºæœºå™¨äººåœ¨æ“ä½œä¸­çš„çµå·§æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œé‡‡ç”¨æ–°æ–¹æ³•çš„ä»£ç†åœ¨å¤æ‚æ¥è§¦ä»»åŠ¡ä¸­è¡¨ç°å‡ºè¶…äººç±»çš„çµå·§æ€§ï¼Œä¸”æ€§èƒ½æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å®ç°å®‰å…¨ã€å¯é çš„æœºå™¨äººæ“ä½œéœ€è¦è¶…è¶Šè§†è§‰ï¼Œç»“åˆè§¦è§‰æ„ŸçŸ¥ä»¥å…‹æœæ„ŸçŸ¥ç¼ºé™·å’Œå¯¹ç†æƒ³çŠ¶æ€ä¿¡æ¯çš„ä¾èµ–ã€‚å°½ç®¡è§¦è§‰æ„ŸçŸ¥å…·æœ‰æ½œåŠ›ï¼Œä½†åœ¨å¼ºåŒ–å­¦ä¹ ä¸­çš„æœ‰æ•ˆæ€§ä»ç„¶ä¸ä¸€è‡´ã€‚æœ¬æ–‡é€šè¿‡å¼€å‘è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œæ›´æœ‰æ•ˆåœ°åˆ©ç”¨è§¦è§‰è§‚å¯Ÿï¼Œé‡ç‚¹å…³æ³¨æœ¬ä½“æ„ŸçŸ¥å’Œç¨€ç–äºŒè¿›åˆ¶æ¥è§¦çš„å¯æ‰©å±•è®¾ç½®ã€‚å®éªŒè¯æ˜ï¼Œç¨€ç–çš„äºŒè¿›åˆ¶è§¦è§‰ä¿¡å·å¯¹çµå·§æ€§è‡³å…³é‡è¦ï¼Œå°¤å…¶æ˜¯åœ¨æœ¬ä½“æ„ŸçŸ¥æ§åˆ¶è¯¯å·®æ— æ³•æ³¨å†Œçš„äº¤äº’ä¸­ã€‚æˆ‘ä»¬çš„ä»£ç†åœ¨å¤æ‚æ¥è§¦ä»»åŠ¡ä¸­å®ç°äº†è¶…äººç±»çš„çµå·§æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘ç°å°†è‡ªç›‘ç£å­¦ä¹ è®°å¿†ä¸åœ¨çº¿ç­–ç•¥è®°å¿†è§£è€¦å¯ä»¥æé«˜æ€§èƒ½ã€‚æˆ‘ä»¬å‘å¸ƒäº†æœºå™¨äººè§¦è§‰å¥¥æ—åŒ¹å…‹ï¼ˆRoTOï¼‰åŸºå‡†ï¼Œä»¥æ ‡å‡†åŒ–å’Œä¿ƒè¿›æœªæ¥çš„è§¦è§‰æ“ä½œç ”ç©¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰æœºå™¨äººæ“ä½œæ–¹æ³•å¯¹è§†è§‰ä¿¡æ¯çš„è¿‡åº¦ä¾èµ–ï¼Œå¯¼è‡´åœ¨å¤æ‚ä»»åŠ¡ä¸­çµå·§æ€§ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†è§¦è§‰ä¿¡æ¯æ—¶æ•ˆæœä¸ä½³ï¼Œæ— æ³•å……åˆ†åˆ©ç”¨è§¦è§‰æ„ŸçŸ¥çš„ä¼˜åŠ¿ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºé€šè¿‡è‡ªç›‘ç£å­¦ä¹ ï¼ˆSSLï¼‰æ–¹æ³•æ¥æœ‰æ•ˆåˆ©ç”¨è§¦è§‰è§‚å¯Ÿï¼Œç‰¹åˆ«æ˜¯ç¨€ç–äºŒè¿›åˆ¶è§¦è§‰ä¿¡å·ï¼Œä»¥æé«˜æœºå™¨äººåœ¨å¤æ‚æ“ä½œä¸­çš„çµå·§æ€§ã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨å…‹æœä¼ ç»Ÿæ–¹æ³•åœ¨å¤„ç†è§¦è§‰ä¿¡æ¯æ—¶çš„å±€é™æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬è§¦è§‰ä¿¡å·çš„è·å–ã€å¤„ç†å’Œå­¦ä¹ ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚è§¦è§‰ä¿¡å·é€šè¿‡ä¼ æ„Ÿå™¨è·å–åï¼Œç»è¿‡è‡ªç›‘ç£å­¦ä¹ ç®—æ³•è¿›è¡Œå¤„ç†ï¼Œæœ€ç»ˆç”¨äºå¼ºåŒ–å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†è‡ªç›‘ç£å­¦ä¹ è®°å¿†ä¸åœ¨çº¿ç­–ç•¥è®°å¿†è§£è€¦ï¼Œè¿™ä¸€è®¾è®¡æ˜¾è‘—æé«˜äº†æ¨¡å‹çš„æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†å¤æ‚çš„æ¥è§¦ä»»åŠ¡æ—¶ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†ç¨€ç–äºŒè¿›åˆ¶è§¦è§‰ä¿¡å·ä½œä¸ºè¾“å…¥ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸ºé€‚åº”è§¦è§‰ä¿¡å·çš„ç‰¹æ€§ï¼Œç½‘ç»œç»“æ„åˆ™ç»“åˆäº†å·ç§¯ç¥ç»ç½‘ç»œå’Œå¼ºåŒ–å­¦ä¹ ç­–ç•¥ç½‘ç»œï¼Œä»¥å®ç°é«˜æ•ˆçš„å­¦ä¹ å’Œå†³ç­–ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨æ–°æ–¹æ³•çš„ä»£ç†åœ¨å¤æ‚æ¥è§¦ä»»åŠ¡ï¼ˆå¦‚çƒå¼¹è·³å’ŒæŠŠç©çƒæ—‹è½¬ï¼‰ä¸­å®ç°äº†è¶…äººç±»çš„çµå·§æ€§ï¼Œæ€§èƒ½æå‡å¹…åº¦æ˜¾è‘—ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†æœ¬ä½“æ„ŸçŸ¥æ§åˆ¶è¯¯å·®æ— æ³•æ³¨å†Œçš„äº¤äº’æ—¶ï¼Œè¡¨ç°å‡ºæ›´é«˜çš„çµæ´»æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæŠ“å–ã€ç‰©ä½“æ“æ§å’Œäººæœºäº¤äº’ç­‰åœºæ™¯ã€‚é€šè¿‡å¢å¼ºæœºå™¨äººå¯¹è§¦è§‰ä¿¡æ¯çš„å¤„ç†èƒ½åŠ›ï¼Œå¯ä»¥æé«˜å…¶åœ¨å¤æ‚ç¯å¢ƒä¸­çš„æ“ä½œçµæ´»æ€§å’Œå®‰å…¨æ€§ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Achieving safe, reliable real-world robotic manipulation requires agents to evolve beyond vision and incorporate tactile sensing to overcome sensory deficits and reliance on idealised state information. Despite its potential, the efficacy of tactile sensing in reinforcement learning (RL) remains inconsistent. We address this by developing self-supervised learning (SSL) methodologies to more effectively harness tactile observations, focusing on a scalable setup of proprioception and sparse binary contacts. We empirically demonstrate that sparse binary tactile signals are critical for dexterity, particularly for interactions that proprioceptive control errors do not register, such as decoupled robot-object motions. Our agents achieve superhuman dexterity in complex contact tasks (ball bouncing and Baoding ball rotation). Furthermore, we find that decoupling the SSL memory from the on-policy memory can improve performance. We release the Robot Tactile Olympiad (RoTO) benchmark to standardise and promote future research in tactile-based manipulation. Project page: https://elle-miller.github.io/tactile_rl

