---
layout: default
title: CLAM: Continuous Latent Action Models for Robot Learning from Unlabeled Demonstrations
---

# CLAM: Continuous Latent Action Models for Robot Learning from Unlabeled Demonstrations

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.04999" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.04999v1</a>
  <a href="https://arxiv.org/pdf/2505.04999.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.04999v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.04999v1', 'CLAM: Continuous Latent Action Models for Robot Learning from Unlabeled Demonstrations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Anthony Liang, Pavel Czempin, Matthew Hong, Yutai Zhou, Erdem Biyik, Stephen Tu

**åˆ†ç±»**: cs.RO, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-05-08

**å¤‡æ³¨**: Latent Action Models, Self-supervised Pretraining, Learning from Videos

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCLAMä»¥è§£å†³æœºå™¨äººæ— æ ‡ç­¾ç¤ºèŒƒå­¦ä¹ ä¸­çš„åŠ¨ä½œæ ‡æ³¨é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æ¨¡ä»¿å­¦ä¹ ` `æ— æ ‡ç­¾å­¦ä¹ ` `æœºå™¨äººæ§åˆ¶` `æ½œåœ¨åŠ¨ä½œæ¨¡å‹` `åŠ¨ä½œè§£ç å™¨` `å¤æ‚ä»»åŠ¡` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ¨¡ä»¿å­¦ä¹ æ–¹æ³•ä¾èµ–å¤§é‡å¸¦æ ‡ç­¾çš„ä¸“å®¶ç¤ºèŒƒï¼Œé™åˆ¶äº†æ•°æ®è§„æ¨¡å’Œå­¦ä¹ æ•ˆç‡ã€‚
2. CLAMæ¨¡å‹é‡‡ç”¨è¿ç»­æ½œåœ¨åŠ¨ä½œæ ‡ç­¾ï¼Œå¹¶é€šè¿‡è”åˆè®­ç»ƒåŠ¨ä½œè§£ç å™¨æ¥è§£å†³å¤æ‚æ§åˆ¶ä»»åŠ¡ã€‚
3. åœ¨DMControlå’ŒMetaWorldåŸºå‡†æµ‹è¯•ä¸­ï¼ŒCLAMçš„ä»»åŠ¡æˆåŠŸç‡è¾ƒæœ€ä½³åŸºçº¿æé«˜äº†2-3å€ï¼Œè¡¨ç°æ˜¾è‘—ä¼˜è¶Šã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨æ¨¡ä»¿å­¦ä¹ ä¸­ï¼Œå­¦ä¹ æœºå™¨äººç­–ç•¥é€šå¸¸éœ€è¦å¤§é‡æ˜‚è´µçš„å¸¦æ ‡ç­¾ä¸“å®¶ç¤ºèŒƒï¼Œè¿™é™åˆ¶äº†è®­ç»ƒæ•°æ®çš„è§„æ¨¡ã€‚ä¸ºäº†è§£å†³è¿™ä¸€ç“¶é¢ˆï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ©ç”¨æ— æ ‡ç­¾è§‚å¯Ÿï¼ˆå¦‚è§†é¢‘ç¤ºèŒƒï¼‰æ¥æ— ç›‘ç£å­¦ä¹ æ½œåœ¨åŠ¨ä½œæ ‡ç­¾çš„æ–¹æ³•ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚æœºå™¨äººä»»åŠ¡æ—¶è¡¨ç°ä¸ä½³ï¼Œå› æ­¤æˆ‘ä»¬è®¾è®¡äº†è¿ç»­æ½œåœ¨åŠ¨ä½œæ¨¡å‹ï¼ˆCLAMï¼‰ï¼Œè¯¥æ¨¡å‹é‡‡ç”¨è¿ç»­æ½œåœ¨åŠ¨ä½œæ ‡ç­¾å¹¶è”åˆè®­ç»ƒåŠ¨ä½œè§£ç å™¨ï¼Œä»¥ä¾¿åœ¨æ²¡æœ‰ä»»ä½•å¸¦æ ‡ç­¾ä¸“å®¶æ•°æ®çš„æƒ…å†µä¸‹ï¼Œä»éæœ€ä¼˜æ¸¸æˆæ•°æ®ä¸­å­¦ä¹ æœ‰æ•ˆç­–ç•¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCLAMåœ¨DMControlå’ŒMetaWorldçš„è¿ç»­æ§åˆ¶åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—è¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œä»»åŠ¡æˆåŠŸç‡æå‡äº†2-3å€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æœºå™¨äººå­¦ä¹ ä¸­å¯¹å¤§é‡å¸¦æ ‡ç­¾ç¤ºèŒƒçš„ä¾èµ–é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤æ‚ä»»åŠ¡ä¸­éš¾ä»¥æœ‰æ•ˆå¤„ç†ç»†ç²’åº¦åŠ¨ä½œï¼Œé™åˆ¶äº†å­¦ä¹ æ•ˆæœã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šCLAMæ¨¡å‹é€šè¿‡å¼•å…¥è¿ç»­æ½œåœ¨åŠ¨ä½œæ ‡ç­¾ï¼Œæ›¿ä»£ç¦»æ•£è¡¨ç¤ºï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰å¤æ‚åŠ¨ä½œçš„ç»†èŠ‚ã€‚åŒæ—¶ï¼Œè”åˆè®­ç»ƒçš„åŠ¨ä½œè§£ç å™¨ç¡®ä¿æ½œåœ¨åŠ¨ä½œç©ºé—´èƒ½å¤Ÿä¸çœŸå®åŠ¨ä½œæœ‰æ•ˆå¯¹æ¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCLAMçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šæ½œåœ¨åŠ¨ä½œæ ‡ç­¾ç”Ÿæˆæ¨¡å—å’ŒåŠ¨ä½œè§£ç å™¨ã€‚æ½œåœ¨åŠ¨ä½œæ ‡ç­¾é€šè¿‡æ— æ ‡ç­¾è§‚å¯Ÿæ•°æ®ç”Ÿæˆï¼Œè€ŒåŠ¨ä½œè§£ç å™¨åˆ™é€šè¿‡å°‘é‡å¸¦æ ‡ç­¾ç¤ºèŒƒè¿›è¡Œè®­ç»ƒï¼Œä»¥å®ç°æ½œåœ¨åŠ¨ä½œä¸å®é™…åŠ¨ä½œçš„æ˜ å°„ã€‚

**å…³é”®åˆ›æ–°**ï¼šCLAMçš„ä¸»è¦åˆ›æ–°åœ¨äºé‡‡ç”¨è¿ç»­æ½œåœ¨åŠ¨ä½œæ ‡ç­¾å’Œè”åˆè®­ç»ƒçš„è§£ç å™¨ï¼Œè¿™ä¸ä¼ ç»Ÿæ–¹æ³•çš„ç¦»æ•£æ ‡ç­¾è¡¨ç¤ºå½¢æˆé²œæ˜å¯¹æ¯”ï¼Œä½¿å¾—æ¨¡å‹åœ¨å¤æ‚æ§åˆ¶ä»»åŠ¡ä¸­è¡¨ç°æ›´ä½³ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œå…³é”®å‚æ•°åŒ…æ‹¬æ½œåœ¨åŠ¨ä½œç©ºé—´çš„ç»´åº¦å’Œè§£ç å™¨çš„ç½‘ç»œç»“æ„ï¼ŒæŸå¤±å‡½æ•°åˆ™ç»“åˆäº†é‡æ„æŸå¤±å’ŒåŠ¨ä½œé¢„æµ‹æŸå¤±ï¼Œä»¥ç¡®ä¿æ¨¡å‹çš„æœ‰æ•ˆæ€§å’Œç¨³å®šæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼ŒCLAMåœ¨DMControlå’ŒMetaWorldçš„è¿ç»­æ§åˆ¶ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä»»åŠ¡æˆåŠŸç‡ç›¸æ¯”æœ€ä½³åŸºçº¿æé«˜äº†2-3å€ï¼Œæ˜¾è‘—è¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤æ‚ä»»åŠ¡å­¦ä¹ ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæ“ä½œã€è‡ªåŠ¨åŒ–åˆ¶é€ å’Œäººæœºåä½œç­‰ã€‚é€šè¿‡å‡å°‘å¯¹å¸¦æ ‡ç­¾æ•°æ®çš„ä¾èµ–ï¼ŒCLAMèƒ½å¤Ÿåœ¨èµ„æºæœ‰é™çš„æƒ…å†µä¸‹ï¼Œæå‡æœºå™¨äººå­¦ä¹ çš„æ•ˆç‡å’Œçµæ´»æ€§ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Learning robot policies using imitation learning requires collecting large amounts of costly action-labeled expert demonstrations, which fundamentally limits the scale of training data. A promising approach to address this bottleneck is to harness the abundance of unlabeled observations-e.g., from video demonstrations-to learn latent action labels in an unsupervised way. However, we find that existing methods struggle when applied to complex robot tasks requiring fine-grained motions. We design continuous latent action models (CLAM) which incorporate two key ingredients we find necessary for learning to solve complex continuous control tasks from unlabeled observation data: (a) using continuous latent action labels instead of discrete representations, and (b) jointly training an action decoder to ensure that the latent action space can be easily grounded to real actions with relatively few labeled examples. Importantly, the labeled examples can be collected from non-optimal play data, enabling CLAM to learn performant policies without access to any action-labeled expert data. We demonstrate on continuous control benchmarks in DMControl (locomotion) and MetaWorld (manipulation), as well as on a real WidowX robot arm that CLAM significantly outperforms prior state-of-the-art methods, remarkably with a 2-3x improvement in task success rate compared to the best baseline. Videos and code can be found at clamrobot.github.io.

