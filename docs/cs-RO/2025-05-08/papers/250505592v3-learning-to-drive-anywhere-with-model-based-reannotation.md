---
layout: default
title: Learning to Drive Anywhere with Model-Based Reannotation
---

# Learning to Drive Anywhere with Model-Based Reannotation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.05592" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.05592v3</a>
  <a href="https://arxiv.org/pdf/2505.05592.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.05592v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.05592v3', 'Learning to Drive Anywhere with Model-Based Reannotation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Noriaki Hirose, Lydia Ignatova, Kyle Stachowicz, Catherine Glossop, Sergey Levine, Dhruv Shah

**åˆ†ç±»**: cs.RO, cs.CV, cs.LG, eess.SY

**å‘å¸ƒæ—¥æœŸ**: 2025-05-08 (æ›´æ–°: 2025-11-21)

**å¤‡æ³¨**: 9 pages, 8 figures, 6 tables

**æœŸåˆŠ**: IEEE Robotics and Automation Letters 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºæ¨¡å‹çš„é‡æ ‡æ³¨æ–¹æ³•ä»¥è§£å†³æœºå™¨äººå¯¼èˆªæ•°æ®ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `æœºå™¨äººå¯¼èˆª` `æ¨¡å‹é‡æ ‡æ³¨` `è§†è§‰ç›®æ ‡` `æ•°æ®è’¸é¦` `é•¿è§†é‡ç­–ç•¥` `å¤šæ ·åŒ–è®­ç»ƒæ•°æ®` `æ— äººé©¾é©¶` `å¤æ‚ç¯å¢ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æœºå™¨äººå¯¼èˆªç­–ç•¥å—é™äºé«˜è´¨é‡è®­ç»ƒæ•°æ®çš„ç¨€ç¼ºï¼Œå¯¼è‡´å…¶åœ¨å¤æ‚ç¯å¢ƒä¸­çš„æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºçš„MBRAæ¡†æ¶é€šè¿‡åˆ©ç”¨è¢«åŠ¨æ”¶é›†çš„æ•°æ®æºï¼Œç”Ÿæˆé«˜è´¨é‡çš„åŠ¨ä½œæ ‡ç­¾ï¼Œä»è€Œå¢å¼ºè®­ç»ƒæ•°æ®çš„å¤šæ ·æ€§å’Œè´¨é‡ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLogoNavåœ¨å¤šç§ç¯å¢ƒä¸­è¡¨ç°ä¼˜å¼‚ï¼Œèƒ½å¤Ÿåœ¨å¤æ‚åœºæ™¯ä¸­æœ‰æ•ˆå¯¼èˆªï¼ŒéªŒè¯äº†å…¶å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¼€å‘å¹¿æ³›å¯æ¨å¹¿çš„è§†è§‰å¯¼èˆªç­–ç•¥æ˜¯æœºå™¨äººé¢†åŸŸçš„ä¸€å¤§æŒ‘æˆ˜ï¼Œä¸»è¦å—é™äºå¤§è§„æ¨¡å¤šæ ·åŒ–è®­ç»ƒæ•°æ®çš„å¯ç”¨æ€§ã€‚è™½ç„¶ç ”ç©¶è€…æ”¶é›†çš„ç²¾å¿ƒç­–åˆ’çš„æ•°æ®é›†è´¨é‡é«˜ï¼Œä½†å…¶è§„æ¨¡æœ‰é™ï¼Œé™åˆ¶äº†ç­–ç•¥çš„æ³›åŒ–èƒ½åŠ›ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æ¢ç´¢åˆ©ç”¨ä¸°å¯Œçš„è¢«åŠ¨æ”¶é›†æ•°æ®æºï¼ŒåŒ…æ‹¬å¤§é‡ä¼—åŒ…çš„é¥æ§æ•°æ®å’Œæœªæ ‡è®°çš„YouTubeè§†é¢‘ï¼Œå°½ç®¡è¿™äº›æ•°æ®å¯èƒ½å­˜åœ¨è´¨é‡è¾ƒä½æˆ–ç¼ºå¤±åŠ¨ä½œæ ‡ç­¾çš„é—®é¢˜ã€‚æˆ‘ä»¬æå‡ºäº†åŸºäºæ¨¡å‹çš„é‡æ ‡æ³¨æ¡†æ¶ï¼ˆMBRAï¼‰ï¼Œåˆ©ç”¨å­¦ä¹ çš„çŸ­è§†é‡æ¨¡å‹ç”Ÿæˆé«˜è´¨é‡çš„åŠ¨ä½œæ ‡ç­¾ã€‚ç»è¿‡MBRAå¤„ç†çš„æ•°æ®è¢«è’¸é¦ä¸ºLogoNavï¼Œä¸€ä¸ªåŸºäºè§†è§‰ç›®æ ‡æˆ–GPSèˆªç‚¹çš„é•¿è§†é‡å¯¼èˆªç­–ç•¥ã€‚å®éªŒè¡¨æ˜ï¼Œä½¿ç”¨MBRAå¤„ç†æ•°æ®è®­ç»ƒçš„LogoNavåœ¨è¶…è¿‡300ç±³çš„è·ç¦»å†…ï¼Œåœ¨æœªè§è¿‡çš„å®¤å†…å’Œå®¤å¤–ç¯å¢ƒä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æœºå™¨äººå¯¼èˆªç­–ç•¥åœ¨å¤šæ ·åŒ–å’Œå¤§è§„æ¨¡è®­ç»ƒæ•°æ®ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºå°è§„æ¨¡çš„é«˜è´¨é‡æ•°æ®é›†ï¼Œé™åˆ¶äº†ç­–ç•¥çš„æ³›åŒ–èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„MBRAæ¡†æ¶é€šè¿‡åˆ©ç”¨è¢«åŠ¨æ”¶é›†çš„æ•°æ®æºï¼Œç”Ÿæˆé«˜è´¨é‡çš„åŠ¨ä½œæ ‡ç­¾ï¼Œè¿›è€Œå¢å¼ºè®­ç»ƒæ•°æ®çš„å¤šæ ·æ€§å’Œè´¨é‡ã€‚è¿™ç§æ–¹æ³•å…è®¸æœºå™¨äººåœ¨æœªè§è¿‡çš„ç¯å¢ƒä¸­è¿›è¡Œæœ‰æ•ˆå¯¼èˆªã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMBRAæ¡†æ¶åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ¨¡å‹è®­ç»ƒå’Œæ•°æ®é‡æ ‡æ³¨ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œæ”¶é›†å¤§é‡çš„ä¼—åŒ…é¥æ§æ•°æ®å’Œæœªæ ‡è®°è§†é¢‘ï¼›ç„¶åï¼Œè®­ç»ƒä¸€ä¸ªçŸ­è§†é‡çš„æ¨¡å‹ä»¥ç”ŸæˆåŠ¨ä½œæ ‡ç­¾ï¼›æœ€åï¼Œå°†è¿™äº›æ ‡ç­¾åº”ç”¨äºè®­ç»ƒLogoNavç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šMBRAçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºåˆ©ç”¨æ¨¡å‹ç”Ÿæˆé«˜è´¨é‡çš„åŠ¨ä½œæ ‡ç­¾ï¼Œå…‹æœäº†ä¼ ç»Ÿæ–¹æ³•å¯¹é«˜è´¨é‡æ ‡æ³¨æ•°æ®çš„ä¾èµ–ã€‚è¿™ç§æ–¹æ³•æ˜¾è‘—æé«˜äº†è®­ç»ƒæ•°æ®çš„æœ‰æ•ˆæ€§å’Œå¤šæ ·æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–åŠ¨ä½œç”Ÿæˆçš„å‡†ç¡®æ€§ï¼Œå¹¶è®¾è®¡äº†é€‚åº”æ€§å¼ºçš„ç½‘ç»œç»“æ„ï¼Œä»¥ä¾¿åœ¨ä¸åŒç¯å¢ƒä¸­è¿›è¡Œæœ‰æ•ˆçš„å¯¼èˆªã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œç»è¿‡MBRAå¤„ç†çš„æ•°æ®è®­ç»ƒçš„LogoNavåœ¨è¶…è¿‡300ç±³çš„å¯¼èˆªä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼ŒæˆåŠŸåœ¨å¤æ‚çš„å®¤å†…å¤–ç¯å¢ƒä¸­å¯¼èˆªï¼Œè¶…è¶Šäº†ç°æœ‰çš„åŸºçº¿æ–¹æ³•ï¼Œå±•ç¤ºäº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªåŠ¨é©¾é©¶ã€æœåŠ¡æœºå™¨äººå’Œæ— äººæœºç­‰ã€‚é€šè¿‡æé«˜æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„å¯¼èˆªèƒ½åŠ›ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡å…¶åœ¨å®é™…åœºæ™¯ä¸­çš„åº”ç”¨ä»·å€¼ï¼Œæ¨åŠ¨æ™ºèƒ½æœºå™¨äººæŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Developing broadly generalizable visual navigation policies for robots is a significant challenge, primarily constrained by the availability of large-scale, diverse training data. While curated datasets collected by researchers offer high quality, their limited size restricts policy generalization. To overcome this, we explore leveraging abundant, passively collected data sources, including large volumes of crowd-sourced teleoperation data and unlabeled YouTube videos, despite their potential for lower quality or missing action labels. We propose Model-Based ReAnnotation (MBRA), a framework that utilizes a learned short-horizon, model-based expert model to relabel or generate high-quality actions for these passive datasets. This relabeled data is then distilled into LogoNav, a long-horizon navigation policy conditioned on visual goals or GPS waypoints. We demonstrate that LogoNav, trained using MBRA-processed data, achieves state-of-the-art performance, enabling robust navigation over distances exceeding 300 meters in previously unseen indoor and outdoor environments. Our extensive real-world evaluations, conducted across a fleet of robots (including quadrupeds) in six cities on three continents, validate the policy's ability to generalize and navigate effectively even amidst pedestrians in crowded settings.

