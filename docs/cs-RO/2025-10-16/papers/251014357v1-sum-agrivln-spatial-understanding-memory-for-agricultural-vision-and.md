---
layout: default
title: "SUM-AgriVLN: Spatial Understanding Memory for Agricultural Vision-and-Language Navigation"
---

# SUM-AgriVLN: Spatial Understanding Memory for Agricultural Vision-and-Language Navigation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.14357" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.14357v1</a>
  <a href="https://arxiv.org/pdf/2510.14357.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.14357v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.14357v1', 'SUM-AgriVLN: Spatial Understanding Memory for Agricultural Vision-and-Language Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xiaobei Zhao, Xingqi Lyu, Xiang Li

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-10-16

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/AlexTraveling/SUM-AgriVLN)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSUM-AgriVLNï¼Œåˆ©ç”¨ç©ºé—´è®°å¿†æå‡å†œä¸šè§†è§‰è¯­è¨€å¯¼èˆªæ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å†œä¸šæœºå™¨äºº` `è§†è§‰è¯­è¨€å¯¼èˆª` `ç©ºé—´è®°å¿†` `3Dé‡å»º` `è‡ªä¸»å¯¼èˆª`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å†œä¸šVLNæ–¹æ³•å¿½ç•¥äº†å¯¼èˆªæŒ‡ä»¤çš„é‡å¤æ€§ï¼Œæœªèƒ½æœ‰æ•ˆåˆ©ç”¨å†å²ç»éªŒæä¾›çš„ç©ºé—´ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚
2. SUM-AgriVLNé€šè¿‡3Dé‡å»ºå’Œç©ºé—´è¡¨ç¤ºæ„å»ºç©ºé—´ç†è§£è®°å¿†ï¼Œä¸ºåç»­å¯¼èˆªæŒ‡ä»¤æä¾›ç©ºé—´ä¸Šä¸‹æ–‡ã€‚
3. åœ¨A2AåŸºå‡†æµ‹è¯•ä¸­ï¼ŒSUM-AgriVLNå°†æˆåŠŸç‡ä»0.47æå‡è‡³0.54ï¼Œè¯æ˜äº†å…¶åœ¨å†œä¸šé¢†åŸŸçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å†œä¸šæœºå™¨äººæ­£åœ¨æˆä¸ºå„ç§å†œä¸šä»»åŠ¡ä¸­çš„å¼ºå¤§åŠ©æ‰‹ï¼Œä½†ç›®å‰ä»ç„¶ä¸¥é‡ä¾èµ–äººå·¥æ“ä½œæˆ–å›ºå®šè½¨é“ç³»ç»Ÿè¿›è¡Œç§»åŠ¨ã€‚ AgriVLNæ–¹æ³•å’ŒA2AåŸºå‡†ç‡å…ˆå°†è§†è§‰è¯­è¨€å¯¼èˆªï¼ˆVLNï¼‰æ‰©å±•åˆ°å†œä¸šé¢†åŸŸï¼Œä½¿æœºå™¨äººèƒ½å¤ŸæŒ‰ç…§è‡ªç„¶è¯­è¨€æŒ‡ä»¤å¯¼èˆªåˆ°ç›®æ ‡ä½ç½®ã€‚åœ¨å®é™…å†œä¸šåœºæ™¯ä¸­ï¼Œå¯¼èˆªæŒ‡ä»¤ç»å¸¸é‡å¤å‡ºç°ï¼Œä½†AgriVLNå°†æ¯ä¸ªæŒ‡ä»¤è§†ä¸ºä¸€ä¸ªç‹¬ç«‹çš„episodeï¼Œå¿½ç•¥äº†è¿‡å»ç»éªŒä¸ºåç»­æŒ‡ä»¤æä¾›ç©ºé—´ä¸Šä¸‹æ–‡çš„æ½œåŠ›ã€‚ä¸ºäº†å¼¥åˆè¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”¨äºå†œä¸šè§†è§‰è¯­è¨€å¯¼èˆªçš„ç©ºé—´ç†è§£è®°å¿†æ–¹æ³•ï¼ˆSUM-AgriVLNï¼‰ï¼Œå…¶ä¸­SUMæ¨¡å—é‡‡ç”¨ç©ºé—´ç†è§£å¹¶é€šè¿‡3Dé‡å»ºå’Œè¡¨ç¤ºæ¥ä¿å­˜ç©ºé—´è®°å¿†ã€‚åœ¨A2AåŸºå‡†ä¸Šè¿›è¡Œè¯„ä¼°æ—¶ï¼Œæˆ‘ä»¬çš„SUM-AgriVLNæœ‰æ•ˆåœ°å°†æˆåŠŸç‡ä»0.47æé«˜åˆ°0.54ï¼Œå¯¼èˆªè¯¯å·®ç•¥æœ‰å¢åŠ ï¼Œä»2.91ç±³å¢åŠ åˆ°2.93ç±³ï¼Œå±•ç¤ºäº†åœ¨å†œä¸šé¢†åŸŸçš„æœ€å…ˆè¿›æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå†œä¸šè§†è§‰è¯­è¨€å¯¼èˆªï¼ˆAgriVLNï¼‰æ—¨åœ¨ä½¿æœºå™¨äººèƒ½å¤Ÿæ ¹æ®è‡ªç„¶è¯­è¨€æŒ‡ä»¤åœ¨å†œä¸šç¯å¢ƒä¸­å¯¼èˆªã€‚ç°æœ‰çš„AgriVLNæ–¹æ³•ï¼Œå¦‚A2Aï¼Œå°†æ¯ä¸ªå¯¼èˆªæŒ‡ä»¤è§†ä¸ºç‹¬ç«‹çš„episodeï¼Œå¿½ç•¥äº†å†œä¸šç¯å¢ƒä¸­æŒ‡ä»¤é‡å¤å‡ºç°çš„ç‰¹æ€§ã€‚è¿™ç§å¤„ç†æ–¹å¼æ— æ³•æœ‰æ•ˆåˆ©ç”¨å†å²å¯¼èˆªç»éªŒä¸­è•´å«çš„ç©ºé—´ä¿¡æ¯ï¼Œé™åˆ¶äº†å¯¼èˆªæ€§èƒ½çš„æå‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSUM-AgriVLNçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨ç©ºé—´ç†è§£è®°å¿†æ¨¡å—ï¼ˆSUMï¼‰æ¥å­˜å‚¨å’Œåˆ©ç”¨å†å²å¯¼èˆªç»éªŒä¸­çš„ç©ºé—´ä¿¡æ¯ã€‚é€šè¿‡3Dé‡å»ºå’Œç©ºé—´è¡¨ç¤ºï¼ŒSUMæ¨¡å—èƒ½å¤Ÿæ„å»ºå¯¹ç¯å¢ƒçš„ç©ºé—´ç†è§£ï¼Œå¹¶å°†å…¶å­˜å‚¨åœ¨ç©ºé—´è®°å¿†ä¸­ã€‚åœ¨åç»­å¯¼èˆªæŒ‡ä»¤åˆ°æ¥æ—¶ï¼ŒSUMæ¨¡å—å¯ä»¥æä¾›ç©ºé—´ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¸®åŠ©æœºå™¨äººæ›´å‡†ç¡®åœ°ç†è§£æŒ‡ä»¤å¹¶è§„åˆ’å¯¼èˆªè·¯å¾„ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSUM-AgriVLNçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) è§†è§‰è¾“å…¥æ¨¡å—ï¼šç”¨äºå¤„ç†æ¥è‡ªæœºå™¨äººçš„è§†è§‰è¾“å…¥ï¼Œä¾‹å¦‚æ‘„åƒå¤´å›¾åƒã€‚2) è¯­è¨€è¾“å…¥æ¨¡å—ï¼šç”¨äºå¤„ç†è‡ªç„¶è¯­è¨€å¯¼èˆªæŒ‡ä»¤ã€‚3) ç©ºé—´ç†è§£è®°å¿†æ¨¡å—ï¼ˆSUMï¼‰ï¼šè¿™æ˜¯è¯¥æ–¹æ³•çš„æ ¸å¿ƒæ¨¡å—ï¼Œè´Ÿè´£æ„å»ºå’Œç»´æŠ¤ç©ºé—´è®°å¿†ã€‚SUMæ¨¡å—é¦–å…ˆå¯¹ç¯å¢ƒè¿›è¡Œ3Dé‡å»ºï¼Œç„¶åå°†é‡å»ºç»“æœè¡¨ç¤ºä¸ºç©ºé—´è®°å¿†ã€‚4) å¯¼èˆªå†³ç­–æ¨¡å—ï¼šæ ¹æ®è§†è§‰è¾“å…¥ã€è¯­è¨€è¾“å…¥å’Œç©ºé—´è®°å¿†ï¼Œåšå‡ºå¯¼èˆªå†³ç­–ï¼Œæ§åˆ¶æœºå™¨äººçš„è¿åŠ¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šSUM-AgriVLNçš„å…³é”®åˆ›æ–°åœ¨äºå¼•å…¥äº†ç©ºé—´ç†è§£è®°å¿†æ¨¡å—ï¼ˆSUMï¼‰ï¼Œè¯¥æ¨¡å—èƒ½å¤Ÿé€šè¿‡3Dé‡å»ºå’Œç©ºé—´è¡¨ç¤ºæ¥æ„å»ºå¯¹ç¯å¢ƒçš„ç©ºé—´ç†è§£ï¼Œå¹¶å°†å…¶å­˜å‚¨åœ¨ç©ºé—´è®°å¿†ä¸­ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒSUM-AgriVLNèƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨å†å²å¯¼èˆªç»éªŒä¸­çš„ç©ºé—´ä¿¡æ¯ï¼Œä¸ºåç»­å¯¼èˆªæŒ‡ä»¤æä¾›ç©ºé—´ä¸Šä¸‹æ–‡ï¼Œä»è€Œæé«˜å¯¼èˆªæ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šSUMæ¨¡å—çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) 3Dé‡å»ºæ–¹æ³•ï¼šè®ºæ–‡å¯èƒ½é‡‡ç”¨äº†SLAMæˆ–SfMç­‰æ–¹æ³•è¿›è¡Œ3Dé‡å»ºã€‚2) ç©ºé—´è¡¨ç¤ºæ–¹æ³•ï¼šè®ºæ–‡å¯èƒ½é‡‡ç”¨äº†ç‚¹äº‘ã€ä½“ç´ æˆ–ç¥ç»éšå¼è¡¨ç¤ºç­‰æ–¹æ³•æ¥è¡¨ç¤ºç©ºé—´è®°å¿†ã€‚3) è®°å¿†æ›´æ–°æœºåˆ¶ï¼šè®ºæ–‡éœ€è¦è®¾è®¡ä¸€ç§æœºåˆ¶æ¥æ›´æ–°ç©ºé—´è®°å¿†ï¼Œä¾‹å¦‚ï¼Œå½“æœºå™¨äººé‡åˆ°æ–°çš„ç¯å¢ƒåŒºåŸŸæ—¶ï¼Œéœ€è¦å°†æ–°çš„ä¿¡æ¯æ·»åŠ åˆ°ç©ºé—´è®°å¿†ä¸­ã€‚4) è®°å¿†æ£€ç´¢æœºåˆ¶ï¼šè®ºæ–‡éœ€è¦è®¾è®¡ä¸€ç§æœºåˆ¶æ¥æ£€ç´¢ç©ºé—´è®°å¿†ï¼Œä¾‹å¦‚ï¼Œå½“æœºå™¨äººæ¥æ”¶åˆ°æ–°çš„å¯¼èˆªæŒ‡ä»¤æ—¶ï¼Œéœ€è¦ä»ç©ºé—´è®°å¿†ä¸­æ£€ç´¢ç›¸å…³çš„ç©ºé—´ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚å…·ä½“å‚æ•°è®¾ç½®ã€æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç­‰ç»†èŠ‚æœªçŸ¥ï¼Œéœ€è¦æŸ¥é˜…è®ºæ–‡åŸæ–‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

SUM-AgriVLNåœ¨A2AåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å…·ä½“è€Œè¨€ï¼ŒæˆåŠŸç‡ä»0.47æé«˜åˆ°0.54ï¼Œæå‡äº†çº¦15%ã€‚è™½ç„¶å¯¼èˆªè¯¯å·®ç•¥æœ‰å¢åŠ ï¼Œä»2.91ç±³å¢åŠ åˆ°2.93ç±³ï¼Œä½†æ•´ä½“æ€§èƒ½ä»ç„¶ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œè¯æ˜äº†SUM-AgriVLNåœ¨å†œä¸šè§†è§‰è¯­è¨€å¯¼èˆªé¢†åŸŸçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå†œä¸šæœºå™¨äººè‡ªä¸»å¯¼èˆªï¼Œä¾‹å¦‚ç”°é—´å·¡æ£€ã€ä½œç‰©æ”¶å‰²ã€ç²¾å‡†æ–½è‚¥ç­‰ä»»åŠ¡ã€‚é€šè¿‡æå‡å†œä¸šæœºå™¨äººçš„è‡ªä¸»å¯¼èˆªèƒ½åŠ›ï¼Œå¯ä»¥é™ä½äººå·¥æˆæœ¬ï¼Œæé«˜å†œä¸šç”Ÿäº§æ•ˆç‡ï¼Œå¹¶ä¿ƒè¿›å†œä¸šæ™ºèƒ½åŒ–å‘å±•ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–éœ€è¦é‡å¤å¯¼èˆªçš„åœºæ™¯ï¼Œä¾‹å¦‚ä»“åº“ç‰©æµã€å®¤å†…æœåŠ¡ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Agricultural robots are emerging as powerful assistants across a wide range of agricultural tasks, nevertheless, still heavily rely on manual operation or fixed rail systems for movement. The AgriVLN method and the A2A benchmark pioneeringly extend Vision-and-Language Navigation (VLN) to the agricultural domain, enabling robots to navigate to the target positions following the natural language instructions. In practical agricultural scenarios, navigation instructions often repeatedly occur, yet AgriVLN treat each instruction as an independent episode, overlooking the potential of past experiences to provide spatial context for subsequent ones. To bridge this gap, we propose the method of Spatial Understanding Memory for Agricultural Vision-and-Language Navigation (SUM-AgriVLN), in which the SUM module employs spatial understanding and save spatial memory through 3D reconstruction and representation. When evaluated on the A2A benchmark, our SUM-AgriVLN effectively improves Success Rate from 0.47 to 0.54 with slight sacrifice on Navigation Error from 2.91m to 2.93m, demonstrating the state-of-the-art performance in the agricultural domain. Code: https://github.com/AlexTraveling/SUM-AgriVLN.

