---
layout: default
title: Expertise need not monopolize: Action-Specialized Mixture of Experts for Vision-Language-Action Learning
---

# Expertise need not monopolize: Action-Specialized Mixture of Experts for Vision-Language-Action Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.14300" class="toolbar-btn" target="_blank">üìÑ arXiv: 2510.14300v1</a>
  <a href="https://arxiv.org/pdf/2510.14300.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.14300v1" onclick="toggleFavorite(this, '2510.14300v1', 'Expertise need not monopolize: Action-Specialized Mixture of Experts for Vision-Language-Action Learning')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Weijie Shen, Yitian Liu, Yuhao Wu, Zhixuan Liang, Sijia Gu, Dehui Wang, Tian Nian, Lei Xu, Yusen Qin, Jiangmiao Pang, Xinping Guan, Xiaokang Yang, Yao Mu

**ÂàÜÁ±ª**: cs.RO, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-16

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫AdaMoEÔºå‰∏ÄÁßçÂä®‰Ωú‰∏ìÁî®Ê∑∑Âêà‰∏ìÂÆ∂Ê®°ÂûãÔºåÊèêÂçáVLAÊ®°ÂûãÂú®Êú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰∏≠ÁöÑÊÄßËÉΩÂíåÊïàÁéá„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÂ≠¶‰π†` `Ê∑∑Âêà‰∏ìÂÆ∂Ê®°Âûã` `Êú∫Âô®‰∫∫Êìç‰Ωú` `Ê®°ÂûãÊâ©Â±ï` `È¢ÑËÆ≠ÁªÉÊ®°Âûã`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâVLAÊ®°ÂûãÊâ©Â±ïÈù¢‰∏¥ËÆ°ÁÆóËµÑÊ∫êÈúÄÊ±ÇÂ§ßÂíåÊú∫Âô®‰∫∫Êï∞ÊçÆÁ®ÄÁº∫ÁöÑÊåëÊàòÔºåÈöæ‰ª•ÂÖÖÂàÜÂà©Áî®È¢ÑËÆ≠ÁªÉÊùÉÈáç„ÄÇ
2. AdaMoEÈÄöËøáÁªßÊâøÈ¢ÑËÆ≠ÁªÉÊùÉÈáçÂπ∂ÂºïÂÖ•Á®ÄÁñèÊøÄÊ¥ªÁöÑMoEÂ±ÇÊâ©Â±ïÂä®‰Ωú‰∏ìÂÆ∂ÔºåÂÆûÁé∞È´òÊïàÁöÑÊ®°ÂûãÊâ©Â±ï„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåAdaMoEÂú®Â§ö‰∏™Âü∫ÂáÜÊµãËØïÂíåÁúüÂÆû‰∏ñÁïåÊú∫Âô®‰∫∫Êìç‰Ωú‰∏≠ÊòæËëó‰ºò‰∫éÂü∫Á∫øÊ®°ÂûãÔºåÈ™åËØÅ‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰Ωú(VLA)Ê®°ÂûãÊ≠£Âú®Âø´ÈÄüÂèëÂ±ïÔºåÂπ∂Âú®Êú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰∏≠Â±ïÁé∞Âá∫ËâØÂ•ΩÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÊâ©Â±ïVLAÊ®°ÂûãÈù¢‰∏¥Âá†‰∏™ÂÖ≥ÈîÆÊåëÊàòÔºö(1)‰ªéÂ§¥ÂºÄÂßãËÆ≠ÁªÉÊñ∞ÁöÑVLAÊ®°ÂûãÈúÄË¶ÅÂ§ßÈáèÁöÑËÆ°ÁÆóËµÑÊ∫êÂíåÂπøÊ≥õÁöÑÊï∞ÊçÆÈõÜ„ÄÇÈâ¥‰∫éÁõÆÂâçÊú∫Âô®‰∫∫Êï∞ÊçÆÁöÑÁ®ÄÁº∫ÊÄßÔºåÂú®Êâ©Â±ïËøáÁ®ã‰∏≠ÂÖÖÂàÜÂà©Áî®È¢ÑËÆ≠ÁªÉÁöÑVLAÊ®°ÂûãÊùÉÈáçÂèòÂæóÂ∞§‰∏∫ÈáçË¶Å„ÄÇ(2)ÂÆûÊó∂ÊéßÂà∂ÈúÄË¶Å‰ªîÁªÜÂπ≥Ë°°Ê®°ÂûãÂÆπÈáè‰∏éËÆ°ÁÆóÊïàÁéá„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÊåëÊàòÔºåÊàë‰ª¨ÊèêÂá∫AdaMoEÔºå‰∏ÄÁßçÊ∑∑Âêà‰∏ìÂÆ∂(MoE)Êû∂ÊûÑÔºåÂÆÉÁªßÊâø‰∫ÜÂØÜÈõÜVLAÊ®°ÂûãÁöÑÈ¢ÑËÆ≠ÁªÉÊùÉÈáçÔºåÂπ∂ÈÄöËøáÂ∞ÜÂâçÈ¶àÂ±ÇÊõøÊç¢‰∏∫Á®ÄÁñèÊøÄÊ¥ªÁöÑMoEÂ±ÇÊù•Êâ©Â±ïÂä®‰Ωú‰∏ìÂÆ∂„ÄÇAdaMoEÈááÁî®Ëß£ËÄ¶ÊäÄÊúØÔºåÈÄöËøá‰∏Ä‰∏™Áã¨Á´ã‰∫é‰º†ÁªüË∑ØÁî±Âô®ÁöÑÁº©ÊîæÈÄÇÈÖçÂô®ÔºåÂ∞Ü‰∏ìÂÆ∂ÈÄâÊã©‰∏é‰∏ìÂÆ∂ÊùÉÈáçËß£ËÄ¶„ÄÇËøô‰ΩøÂæó‰∏ìÂÆ∂ÂèØ‰ª•Âü∫‰∫é‰ªªÂä°Áõ∏ÂÖ≥ÊÄßËøõË°åÈÄâÊã©ÔºåÂπ∂‰ª•Áã¨Á´ãÊéßÂà∂ÁöÑÊùÉÈáçÂÅöÂá∫Ë¥°ÁåÆÔºå‰ªéËÄåÂÆûÁé∞Âçè‰Ωú‰∏ìÂÆ∂Âà©Áî®ÔºåËÄå‰∏çÊòØËµ¢ËÄÖÈÄöÂêÉÁöÑÊ®°Âºè„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïË°®ÊòéÔºå‰∏ì‰∏öÁü•ËØÜ‰∏çÂøÖÂûÑÊñ≠„ÄÇÁõ∏ÂèçÔºåÈÄöËøáÂçè‰Ωú‰∏ìÂÆ∂Âà©Áî®ÔºåÊàë‰ª¨ÂèØ‰ª•Âú®‰øùÊåÅËÆ°ÁÆóÊïàÁéáÁöÑÂêåÊó∂ÂÆûÁé∞ÂçìË∂äÁöÑÊÄßËÉΩ„ÄÇAdaMoEÂú®ÂÖ≥ÈîÆÂü∫ÂáÜÊµãËØï‰∏≠ÂßãÁªà‰ºò‰∫éÂü∫Á∫øÊ®°ÂûãÔºåÂú®LIBERO‰∏äÂÆûÁé∞‰∫Ü1.8%ÁöÑÊÄßËÉΩÊèêÂçáÔºåÂú®RoboTwin‰∏äÂÆûÁé∞‰∫Ü9.3%ÁöÑÊÄßËÉΩÊèêÂçá„ÄÇÊúÄÈáçË¶ÅÁöÑÊòØÔºåÂú®ÁúüÂÆû‰∏ñÁïåÂÆûÈ™å‰∏≠ÂÆûÁé∞‰∫Ü21.5%ÁöÑÊòæËëóÊîπËøõÔºåÈ™åËØÅ‰∫ÜÂÖ∂Âú®Êú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰∏≠ÁöÑÂÆûÈôÖÊúâÊïàÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâËßÜËßâ-ËØ≠Ë®Ä-Âä®‰Ωú(VLA)Ê®°ÂûãÂú®Êâ©Â±ïÊó∂Èù¢‰∏¥‰∏§‰∏™‰∏ªË¶ÅÈóÆÈ¢òÔºö‰∏ÄÊòØËÆ≠ÁªÉÊàêÊú¨È´òÊòÇÔºåÈúÄË¶ÅÂ§ßÈáèËÆ°ÁÆóËµÑÊ∫êÂíåÊï∞ÊçÆÔºõ‰∫åÊòØÂÆûÊó∂ÊéßÂà∂ÂØπËÆ°ÁÆóÊïàÁéáÊúâËæÉÈ´òË¶ÅÊ±ÇÔºåÈúÄË¶ÅÂπ≥Ë°°Ê®°ÂûãÂÆπÈáèÂíåÊïàÁéá„ÄÇÁé∞ÊúâÊñπÊ≥ïÈöæ‰ª•ÂÖÖÂàÜÂà©Áî®È¢ÑËÆ≠ÁªÉÊ®°ÂûãÊùÉÈáçÔºå‰∏îÈöæ‰ª•Âú®‰øùËØÅÊÄßËÉΩÁöÑÂêåÊó∂ÂÆûÁé∞È´òÊïàËÆ°ÁÆó„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöAdaMoEÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Ê∑∑Âêà‰∏ìÂÆ∂(MoE)Êû∂ÊûÑÔºåÂπ∂ÁªßÊâøÈ¢ÑËÆ≠ÁªÉÁöÑVLAÊ®°ÂûãÊùÉÈáç„ÄÇÈÄöËøáÂ∞ÜÂä®‰Ωú‰∏ìÂÆ∂‰∏≠ÁöÑÂâçÈ¶àÂ±ÇÊõøÊç¢‰∏∫Á®ÄÁñèÊøÄÊ¥ªÁöÑMoEÂ±ÇÔºåÂÆûÁé∞Ê®°ÂûãÂÆπÈáèÁöÑÊâ©Â±ïÔºåÂêåÊó∂‰øùÊåÅËÆ°ÁÆóÊïàÁéá„ÄÇÊ≠§Â§ñÔºåAdaMoEÂºïÂÖ•Ëß£ËÄ¶ÊäÄÊúØÔºåÂ∞Ü‰∏ìÂÆ∂ÈÄâÊã©Âíå‰∏ìÂÆ∂ÊùÉÈáçËß£ËÄ¶ÔºåÂÖÅËÆ∏‰∏ìÂÆ∂ÂçèÂêåÂ∑•‰ΩúÔºåËÄåÈùûËµ¢ËÄÖÈÄöÂêÉ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöAdaMoEÁöÑÊï¥‰ΩìÊû∂ÊûÑÂü∫‰∫éÁé∞ÊúâÁöÑVLAÊ®°ÂûãÔºå‰∏ªË¶ÅÊîπËøõÂú®‰∫éÂä®‰Ωú‰∏ìÂÆ∂ÈÉ®ÂàÜ„ÄÇÂÆÉÂåÖÂê´‰ª•‰∏ã‰∏ªË¶ÅÊ®°ÂùóÔºö1) È¢ÑËÆ≠ÁªÉVLAÊ®°ÂûãÔºö‰Ωú‰∏∫AdaMoEÁöÑÂàùÂßãÂåñÊùÉÈáçÔºõ2) MoEÂ±ÇÔºöÊõøÊç¢Âä®‰Ωú‰∏ìÂÆ∂‰∏≠ÁöÑÂâçÈ¶àÂ±ÇÔºåÂÆûÁé∞Ê®°ÂûãÂÆπÈáèÊâ©Â±ïÔºõ3) Ë∑ØÁî±Âô®(Router)ÔºöÊ†πÊçÆËæìÂÖ•ÈÄâÊã©ÊøÄÊ¥ªÁöÑ‰∏ìÂÆ∂Ôºõ4) Áº©ÊîæÈÄÇÈÖçÂô®(Scale Adapter)ÔºöÁã¨Á´ãÊéßÂà∂ÊØè‰∏™‰∏ìÂÆ∂ÁöÑÊùÉÈáçÔºåÂÆûÁé∞‰∏ìÂÆ∂Âçè‰Ωú„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöAdaMoEÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éËß£ËÄ¶‰∏ìÂÆ∂ÈÄâÊã©Âíå‰∏ìÂÆ∂ÊùÉÈáç„ÄÇ‰º†ÁªüÁöÑMoEÊ®°ÂûãÈÄöÂ∏∏ÈááÁî®Ëµ¢ËÄÖÈÄöÂêÉÁ≠ñÁï•ÔºåÂç≥Âè™ÊúâË¢´Ë∑ØÁî±Âô®ÈÄâ‰∏≠ÁöÑ‰∏ìÂÆ∂ÊâçËÉΩË¥°ÁåÆËæìÂá∫„ÄÇAdaMoEÈÄöËøáÂºïÂÖ•Áº©ÊîæÈÄÇÈÖçÂô®ÔºåÂÖÅËÆ∏ÊâÄÊúâ‰∏ìÂÆ∂ÈÉΩÂèÇ‰∏éËæìÂá∫Ôºå‰ΩÜÊØè‰∏™‰∏ìÂÆ∂ÁöÑË¥°ÁåÆÊùÉÈáçÁî±Áº©ÊîæÈÄÇÈÖçÂô®Áã¨Á´ãÊéßÂà∂„ÄÇËøôÁßçËß£ËÄ¶ËÆæËÆ°‰ΩøÂæó‰∏ìÂÆ∂ÂèØ‰ª•Âü∫‰∫é‰ªªÂä°Áõ∏ÂÖ≥ÊÄßËøõË°åÈÄâÊã©ÔºåÂπ∂‰ª•Áã¨Á´ãÊéßÂà∂ÁöÑÊùÉÈáçÂÅöÂá∫Ë¥°ÁåÆÔºå‰ªéËÄåÂÆûÁé∞Âçè‰Ωú‰∏ìÂÆ∂Âà©Áî®„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöAdaMoEÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) MoEÂ±ÇÁöÑÁ®ÄÁñèÊøÄÊ¥ªÂáΩÊï∞ÈÄâÊã©Ôºå‰ª•Âπ≥Ë°°ÊÄßËÉΩÂíåËÆ°ÁÆóÊïàÁéáÔºõ2) Áº©ÊîæÈÄÇÈÖçÂô®ÁöÑÁªìÊûÑËÆæËÆ°Ôºå‰æãÂ¶Ç‰ΩøÁî®Á∫øÊÄßÂ±ÇÊàñÈùûÁ∫øÊÄßÂ±ÇÔºõ3) Ë∑ØÁî±Âô®ÁöÑÈÄâÊã©Á≠ñÁï•Ôºå‰æãÂ¶Ç‰ΩøÁî®Top-KÈÄâÊã©ÊàñÊ¶ÇÁéáÈÄâÊã©Ôºõ4) ÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°Ôºå‰æãÂ¶ÇÂºïÂÖ•ËæÖÂä©ÊçüÂ§±‰ª•Âπ≥Ë°°‰∏ìÂÆ∂‰πãÈó¥ÁöÑË¥üËΩΩ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

AdaMoEÂú®LIBEROÂíåRoboTwinÂü∫ÂáÜÊµãËØï‰∏≠ÂàÜÂà´ÂèñÂæó‰∫Ü1.8%Âíå9.3%ÁöÑÊÄßËÉΩÊèêÂçá„ÄÇÊõ¥ÈáçË¶ÅÁöÑÊòØÔºåÂú®ÁúüÂÆû‰∏ñÁïåÊú∫Âô®‰∫∫Êìç‰ΩúÂÆûÈ™å‰∏≠ÔºåAdaMoEÂÆûÁé∞‰∫Ü21.5%ÁöÑÊòæËëóÊîπËøõÔºåÈ™åËØÅ‰∫ÜÂÖ∂Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéÔºåAdaMoEËÉΩÂ§üÊúâÊïàÊèêÂçáVLAÊ®°ÂûãÂú®Êú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰∏≠ÁöÑÊÄßËÉΩÂíåÊïàÁéá„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

AdaMoEÂèØÂ∫îÁî®‰∫éÂêÑÁßçÊú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°Ôºå‰æãÂ¶ÇÁâ©‰ΩìÊäìÂèñ„ÄÅË£ÖÈÖç„ÄÅÂØºËà™Á≠â„ÄÇËØ•Á†îÁ©∂ÊàêÊûúÊúâÂä©‰∫éÈôç‰ΩéVLAÊ®°ÂûãÁöÑËÆ≠ÁªÉÊàêÊú¨ÔºåÊèêÈ´òÊ®°ÂûãÂú®ËµÑÊ∫êÂèóÈôêÁéØÂ¢É‰∏≠ÁöÑÈÉ®ÁΩ≤ËÉΩÂäõÔºåÂπ∂‰øÉËøõÊú∫Âô®‰∫∫Êô∫ËÉΩÁöÑËøõ‰∏ÄÊ≠•ÂèëÂ±ï„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïÂèØ‰ª•Êâ©Â±ïÂà∞ÂÖ∂‰ªñÂ§öÊ®°ÊÄÅÂ≠¶‰π†‰ªªÂä°‰∏≠Ôºå‰æãÂ¶ÇËá™Âä®È©æÈ©∂„ÄÅÊô∫ËÉΩÂä©ÊâãÁ≠â„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Vision-Language-Action (VLA) models are experiencing rapid development and demonstrating promising capabilities in robotic manipulation tasks. However, scaling up VLA models presents several critical challenges: (1) Training new VLA models from scratch demands substantial computational resources and extensive datasets. Given the current scarcity of robot data, it becomes particularly valuable to fully leverage well-pretrained VLA model weights during the scaling process. (2) Real-time control requires carefully balancing model capacity with computational efficiency. To address these challenges, We propose AdaMoE, a Mixture-of-Experts (MoE) architecture that inherits pretrained weights from dense VLA models, and scales up the action expert by substituting the feedforward layers into sparsely activated MoE layers. AdaMoE employs a decoupling technique that decouples expert selection from expert weighting through an independent scale adapter working alongside the traditional router. This enables experts to be selected based on task relevance while contributing with independently controlled weights, allowing collaborative expert utilization rather than winner-takes-all dynamics. Our approach demonstrates that expertise need not monopolize. Instead, through collaborative expert utilization, we can achieve superior performance while maintaining computational efficiency. AdaMoE consistently outperforms the baseline model across key benchmarks, delivering performance gains of 1.8% on LIBERO and 9.3% on RoboTwin. Most importantly, a substantial 21.5% improvement in real-world experiments validates its practical effectiveness for robotic manipulation tasks.

