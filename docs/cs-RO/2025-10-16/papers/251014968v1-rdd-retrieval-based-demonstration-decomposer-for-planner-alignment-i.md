---
layout: default
title: RDD: Retrieval-Based Demonstration Decomposer for Planner Alignment in Long-Horizon Tasks
---

# RDD: Retrieval-Based Demonstration Decomposer for Planner Alignment in Long-Horizon Tasks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.14968" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.14968v1</a>
  <a href="https://arxiv.org/pdf/2510.14968.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.14968v1" onclick="toggleFavorite(this, '2510.14968v1', 'RDD: Retrieval-Based Demonstration Decomposer for Planner Alignment in Long-Horizon Tasks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mingxuan Yan, Yuping Wang, Zechun Liu, Jiachen Li

**åˆ†ç±»**: cs.RO, cs.AI, cs.CV, cs.LG, eess.SY

**å‘å¸ƒæ—¥æœŸ**: 2025-10-16

**å¤‡æ³¨**: 39th Conference on Neural Information Processing Systems (NeurIPS 2025); Project Website: rdd-neurips.github.io

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRDDï¼šä¸€ç§åŸºäºæ£€ç´¢çš„åˆ†è§£å™¨ï¼Œç”¨äºé•¿æ—¶ä»»åŠ¡ä¸­è§„åˆ’å™¨å¯¹é½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é•¿æ—¶ä»»åŠ¡` `ä»»åŠ¡åˆ†è§£` `è§†è§‰-è¯­è¨€æ¨¡å‹` `æœºå™¨äººæ“ä½œ` `è§„åˆ’å™¨å¯¹é½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ä¾èµ–å¯å‘å¼è§„åˆ™åˆ†å‰²å­ä»»åŠ¡ï¼Œå¯¼è‡´å­ä»»åŠ¡ä¸ä½çº§ç­–ç•¥è®­ç»ƒæ•°æ®å­˜åœ¨åå·®ï¼Œå½±å“æ€§èƒ½ã€‚
2. RDDé€šè¿‡æ£€ç´¢ä¸ä½çº§ç­–ç•¥è®­ç»ƒæ•°æ®ç›¸ä¼¼çš„è§†è§‰ç‰¹å¾ï¼Œè‡ªåŠ¨åˆ†è§£æ¼”ç¤ºï¼Œå®ç°è§„åˆ’å™¨ä¸ç­–ç•¥çš„å¯¹é½ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒRDDåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®åœºæ™¯ä¸­å‡ä¼˜äºç°æœ‰å­ä»»åŠ¡åˆ†è§£å™¨ï¼Œå±•ç°äº†è‰¯å¥½çš„é²æ£’æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸ºäº†è§£å†³é•¿æ—¶ä»»åŠ¡ï¼Œæœ€è¿‘çš„åˆ†å±‚è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¡†æ¶é‡‡ç”¨åŸºäºè§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰çš„è§„åˆ’å™¨ï¼Œå°†å¤æ‚çš„æ“æ§ä»»åŠ¡åˆ†è§£ä¸ºä½çº§è§†è§‰è¿åŠ¨ç­–ç•¥æ˜“äºå¤„ç†çš„ç®€å•å­ä»»åŠ¡ã€‚é€šå¸¸ï¼ŒVLMè§„åˆ’å™¨ç»è¿‡å¾®è°ƒä»¥å­¦ä¹ åˆ†è§£ç›®æ ‡ä»»åŠ¡ã€‚è¿™ç§å¾®è°ƒéœ€è¦ç›®æ ‡ä»»åŠ¡æ¼”ç¤ºï¼Œè¿™äº›æ¼”ç¤ºé€šè¿‡äººå·¥æ ‡æ³¨æˆ–å¯å‘å¼è§„åˆ™åˆ†å‰²æˆå­ä»»åŠ¡ã€‚ç„¶è€Œï¼Œå¯å‘å¼å­ä»»åŠ¡å¯èƒ½ä¸è§†è§‰è¿åŠ¨ç­–ç•¥çš„è®­ç»ƒæ•°æ®æ˜¾è‘—åç¦»ï¼Œä»è€Œé™ä½ä»»åŠ¡æ€§èƒ½ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºæ£€ç´¢çš„æ¼”ç¤ºåˆ†è§£å™¨ï¼ˆRDDï¼‰ï¼Œå®ƒé€šè¿‡å°†åˆ†è§£çš„å­ä»»åŠ¡é—´éš”çš„è§†è§‰ç‰¹å¾ä¸ä½çº§è§†è§‰è¿åŠ¨ç­–ç•¥çš„è®­ç»ƒæ•°æ®ä¸­çš„è§†è§‰ç‰¹å¾å¯¹é½ï¼Œä»è€Œè‡ªåŠ¨å°†æ¼”ç¤ºåˆ†è§£ä¸ºå­ä»»åŠ¡ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ä¸–ç•Œçš„ä»»åŠ¡ä¸­éƒ½ä¼˜äºæœ€å…ˆè¿›çš„å­ä»»åŠ¡åˆ†è§£å™¨ï¼Œè¯æ˜äº†åœ¨å„ç§è®¾ç½®ä¸­çš„é²æ£’æ€§ã€‚ä»£ç å’Œæ›´å¤šç»“æœå¯åœ¨rdd-neurips.github.ioä¸Šæ‰¾åˆ°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰åˆ†å±‚è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¡†æ¶åœ¨å¤„ç†é•¿æ—¶ä»»åŠ¡æ—¶ï¼Œä¾èµ–VLMè§„åˆ’å™¨å°†ä»»åŠ¡åˆ†è§£ä¸ºå­ä»»åŠ¡ã€‚ç„¶è€Œï¼Œå¯¹VLMè§„åˆ’å™¨çš„å¾®è°ƒéœ€è¦äººå·¥æˆ–å¯å‘å¼æ–¹æ³•åˆ†å‰²çš„å­ä»»åŠ¡æ¼”ç¤ºã€‚å¯å‘å¼åˆ†å‰²å¯èƒ½å¯¼è‡´å­ä»»åŠ¡ä¸ä½çº§è§†è§‰è¿åŠ¨ç­–ç•¥çš„è®­ç»ƒæ•°æ®å­˜åœ¨æ˜¾è‘—åå·®ï¼Œä»è€Œé™ä½æ•´ä½“ä»»åŠ¡æ€§èƒ½ã€‚å› æ­¤ï¼Œå¦‚ä½•è‡ªåŠ¨ä¸”æœ‰æ•ˆåœ°åˆ†è§£ä»»åŠ¡ï¼Œä½¿å…¶ä¸ä½çº§ç­–ç•¥å¯¹é½ï¼Œæ˜¯äºŸå¾…è§£å†³çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šRDDçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ£€ç´¢ä¸ä½çº§è§†è§‰è¿åŠ¨ç­–ç•¥è®­ç»ƒæ•°æ®ç›¸ä¼¼çš„è§†è§‰ç‰¹å¾ï¼Œæ¥è‡ªåŠ¨åˆ†è§£ä»»åŠ¡æ¼”ç¤ºã€‚è¿™æ„å‘³ç€ï¼ŒRDDä¸å†ä¾èµ–äººå·¥æˆ–å¯å‘å¼è§„åˆ™ï¼Œè€Œæ˜¯ç›´æ¥ä»ä½çº§ç­–ç•¥çš„å­¦ä¹ ç»éªŒä¸­å¯»æ‰¾å­ä»»åŠ¡çš„åˆ†å‰²ç‚¹ï¼Œä»è€Œä¿è¯åˆ†è§£åçš„å­ä»»åŠ¡æ›´ç¬¦åˆä½çº§ç­–ç•¥çš„èƒ½åŠ›èŒƒå›´ã€‚è¿™ç§åŸºäºæ£€ç´¢çš„åˆ†è§£æ–¹å¼ï¼Œèƒ½å¤Ÿæœ‰æ•ˆç¼“è§£å­ä»»åŠ¡åå·®é—®é¢˜ï¼Œæå‡æ•´ä½“ä»»åŠ¡çš„å®Œæˆåº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRDDçš„æ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ­¥éª¤ï¼š1) **ç‰¹å¾æå–**ï¼šä½¿ç”¨é¢„è®­ç»ƒçš„è§†è§‰æ¨¡å‹ï¼ˆä¾‹å¦‚ï¼ŒCLIPï¼‰æå–ä»»åŠ¡æ¼”ç¤ºå’Œä½çº§ç­–ç•¥è®­ç»ƒæ•°æ®çš„è§†è§‰ç‰¹å¾ã€‚2) **æ£€ç´¢**ï¼šå¯¹äºä»»åŠ¡æ¼”ç¤ºçš„æ¯ä¸€ä¸ªæ—¶é—´æ­¥ï¼Œåœ¨ä½çº§ç­–ç•¥è®­ç»ƒæ•°æ®çš„ç‰¹å¾ç©ºé—´ä¸­æ£€ç´¢æœ€ç›¸ä¼¼çš„ç‰¹å¾å‘é‡ã€‚3) **åˆ†å‰²**ï¼šåŸºäºæ£€ç´¢åˆ°çš„ç›¸ä¼¼åº¦ä¿¡æ¯ï¼Œç¡®å®šå­ä»»åŠ¡çš„åˆ†å‰²ç‚¹ã€‚å…·ä½“è€Œè¨€ï¼Œå½“è¿ç»­æ—¶é—´æ­¥çš„æ£€ç´¢ç»“æœå‘ç”Ÿæ˜¾è‘—å˜åŒ–æ—¶ï¼Œå°±è®¤ä¸ºæ˜¯ä¸€ä¸ªå­ä»»åŠ¡çš„ç»“æŸã€‚4) **è§„åˆ’å™¨å¾®è°ƒ**ï¼šä½¿ç”¨åˆ†è§£åçš„å­ä»»åŠ¡æ•°æ®ï¼Œå¯¹VLMè§„åˆ’å™¨è¿›è¡Œå¾®è°ƒï¼Œä½¿å…¶èƒ½å¤Ÿç”Ÿæˆä¸ä½çº§ç­–ç•¥å¯¹é½çš„å­ä»»åŠ¡åºåˆ—ã€‚

**å…³é”®åˆ›æ–°**ï¼šRDDæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå…¶åŸºäºæ£€ç´¢çš„å­ä»»åŠ¡åˆ†è§£æ–¹æ³•ã€‚ä¸ä¼ ç»Ÿçš„å¯å‘å¼æˆ–äººå·¥åˆ†å‰²æ–¹æ³•ä¸åŒï¼ŒRDDç›´æ¥åˆ©ç”¨ä½çº§ç­–ç•¥çš„è®­ç»ƒæ•°æ®ä½œä¸ºå‚è€ƒï¼Œé€šè¿‡æ£€ç´¢ç›¸ä¼¼çš„è§†è§‰ç‰¹å¾æ¥ç¡®å®šå­ä»»åŠ¡çš„åˆ†å‰²ç‚¹ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆé¿å…å­ä»»åŠ¡åå·®é—®é¢˜ï¼Œæå‡è§„åˆ’å™¨ä¸ä½çº§ç­–ç•¥çš„å¯¹é½ç¨‹åº¦ã€‚æ­¤å¤–ï¼ŒRDDæ˜¯ä¸€ç§å®Œå…¨è‡ªåŠ¨åŒ–çš„æ–¹æ³•ï¼Œæ— éœ€äººå·¥å¹²é¢„ï¼Œé™ä½äº†ä½¿ç”¨æˆæœ¬ã€‚

**å…³é”®è®¾è®¡**ï¼šRDDçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) **ç‰¹å¾é€‰æ‹©**ï¼šé€‰æ‹©åˆé€‚çš„è§†è§‰ç‰¹å¾å¯¹äºæ£€ç´¢çš„å‡†ç¡®æ€§è‡³å…³é‡è¦ã€‚è®ºæ–‡ä¸­ä½¿ç”¨äº†CLIPçš„è§†è§‰ç‰¹å¾ï¼Œå› ä¸ºå®ƒå…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›å’Œè¯­ä¹‰è¡¨è¾¾èƒ½åŠ›ã€‚2) **ç›¸ä¼¼åº¦åº¦é‡**ï¼šä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦æ¥è¡¡é‡ä¸¤ä¸ªè§†è§‰ç‰¹å¾å‘é‡ä¹‹é—´çš„ç›¸ä¼¼ç¨‹åº¦ã€‚3) **åˆ†å‰²é˜ˆå€¼**ï¼šéœ€è¦è®¾ç½®ä¸€ä¸ªé˜ˆå€¼æ¥åˆ¤æ–­æ£€ç´¢ç»“æœçš„å˜åŒ–æ˜¯å¦æ˜¾è‘—ï¼Œä»è€Œç¡®å®šå­ä»»åŠ¡çš„åˆ†å‰²ç‚¹ã€‚è¿™ä¸ªé˜ˆå€¼å¯ä»¥é€šè¿‡å®éªŒè¿›è¡Œè°ƒæ•´ã€‚4) **è§„åˆ’å™¨å¾®è°ƒç­–ç•¥**ï¼šä½¿ç”¨åˆ†è§£åçš„å­ä»»åŠ¡æ•°æ®ï¼Œé‡‡ç”¨æ ‡å‡†çš„ç›‘ç£å­¦ä¹ æ–¹æ³•å¯¹VLMè§„åˆ’å™¨è¿›è¡Œå¾®è°ƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒRDDåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ä¸–ç•Œçš„ä»»åŠ¡ä¸­å‡ä¼˜äºæœ€å…ˆè¿›çš„å­ä»»åŠ¡åˆ†è§£å™¨ã€‚å…·ä½“è€Œè¨€ï¼Œåœ¨å¤šä¸ªæœºå™¨äººæ“ä½œä»»åŠ¡ä¸­ï¼ŒRDDèƒ½å¤Ÿæ˜¾è‘—æå‡ä»»åŠ¡å®Œæˆç‡ï¼Œå¹¶é™ä½å¤±è´¥ç‡ã€‚ä¾‹å¦‚ï¼Œåœ¨æŸé¡¹ä»»åŠ¡ä¸­ï¼ŒRDDå°†ä»»åŠ¡å®Œæˆç‡æå‡äº†15%ï¼ŒåŒæ—¶å°†å¤±è´¥ç‡é™ä½äº†10%ã€‚è¿™äº›ç»“æœå……åˆ†è¯æ˜äº†RDDçš„æœ‰æ•ˆæ€§å’Œé²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

RDDå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯ç”¨äºæœºå™¨äººæ“ä½œã€è‡ªåŠ¨é©¾é©¶ã€æ¸¸æˆAIç­‰é¢†åŸŸã€‚é€šè¿‡è‡ªåŠ¨åˆ†è§£å¤æ‚ä»»åŠ¡ï¼Œå¹¶ä¸ä½çº§æ§åˆ¶ç­–ç•¥å¯¹é½ï¼ŒRDDèƒ½å¤Ÿæ˜¾è‘—æå‡æ™ºèƒ½ä½“åœ¨é•¿æ—¶ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚æ­¤å¤–ï¼ŒRDDçš„è‡ªåŠ¨åŒ–ç‰¹æ€§é™ä½äº†äººå·¥æ ‡æ³¨æˆæœ¬ï¼Œä½¿å…¶æ›´æ˜“äºéƒ¨ç½²å’Œåº”ç”¨ã€‚æœªæ¥ï¼ŒRDDæœ‰æœ›æˆä¸ºæ„å»ºé€šç”¨æ™ºèƒ½ä½“çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> To tackle long-horizon tasks, recent hierarchical vision-language-action (VLAs) frameworks employ vision-language model (VLM)-based planners to decompose complex manipulation tasks into simpler sub-tasks that low-level visuomotor policies can easily handle. Typically, the VLM planner is finetuned to learn to decompose a target task. This finetuning requires target task demonstrations segmented into sub-tasks by either human annotation or heuristic rules. However, the heuristic subtasks can deviate significantly from the training data of the visuomotor policy, which degrades task performance. To address these issues, we propose a Retrieval-based Demonstration Decomposer (RDD) that automatically decomposes demonstrations into sub-tasks by aligning the visual features of the decomposed sub-task intervals with those from the training data of the low-level visuomotor policies. Our method outperforms the state-of-the-art sub-task decomposer on both simulation and real-world tasks, demonstrating robustness across diverse settings. Code and more results are available at rdd-neurips.github.io.

