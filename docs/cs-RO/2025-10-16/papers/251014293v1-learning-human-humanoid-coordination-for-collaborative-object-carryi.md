---
layout: default
title: Learning Human-Humanoid Coordination for Collaborative Object Carrying
---

# Learning Human-Humanoid Coordination for Collaborative Object Carrying

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.14293" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.14293v1</a>
  <a href="https://arxiv.org/pdf/2510.14293.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.14293v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.14293v1', 'Learning Human-Humanoid Coordination for Collaborative Object Carrying')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yushi Du, Yixuan Li, Baoxiong Jia, Yutang Lin, Pei Zhou, Wei Liang, Yanchao Yang, Siyuan Huang

**åˆ†ç±»**: cs.RO, cs.AI, cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-10-16

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCOLAç®—æ³•ï¼Œå®ç°åŸºäºæœ¬ä½“æ„Ÿè§‰çš„äººå½¢æœºå™¨äººååŒæ¬è¿ï¼Œæå‡äººæœºåä½œæ•ˆç‡ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `äººæœºåä½œ` `äººå½¢æœºå™¨äºº` `å¼ºåŒ–å­¦ä¹ ` `ååŒæ¬è¿` `æœ¬ä½“æ„Ÿè§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. äººå½¢æœºå™¨äººå…¨èº«åŠ¨åŠ›å­¦å¤æ‚ï¼Œç°æœ‰æœºå™¨äººæ‰‹è‡‚çš„é¡ºåº”æ€§äººæœºåä½œæ–¹æ³•éš¾ä»¥ç›´æ¥åº”ç”¨äºäººå½¢æœºå™¨äººã€‚
2. æå‡ºCOLAç®—æ³•ï¼Œåœ¨å•ä¸€ç­–ç•¥ä¸­èåˆé¢†å¯¼è€…å’Œè·Ÿéšè€…è¡Œä¸ºï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ å®ç°äººæœºååŒæ¬è¿ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒCOLAç®—æ³•åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ç¯å¢ƒä¸­å‡èƒ½æœ‰æ•ˆé™ä½äººç±»ä½“åŠ›æ¶ˆè€—ï¼Œæå‡åä½œæ•ˆç‡å’Œé²æ£’æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§ä»…ä½¿ç”¨æœ¬ä½“æ„Ÿè§‰çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•COLAï¼Œç”¨äºå®ç°äººä¸äººå½¢æœºå™¨äººåœ¨ååŒæ¬è¿ä¸­çš„åä½œã€‚è¯¥æ–¹æ³•åœ¨é—­ç¯ç¯å¢ƒä¸­è®­ç»ƒï¼Œé€šè¿‡åŠ¨æ€ç‰©ä½“äº¤äº’éšå¼åœ°é¢„æµ‹ç‰©ä½“è¿åŠ¨æ¨¡å¼å’Œäººç±»æ„å›¾ï¼Œä»è€Œå®ç°ååŒè¿åŠ¨ï¼Œå¹¶é€šè¿‡åè°ƒçš„è½¨è¿¹è§„åˆ’æ¥ä¿æŒè´Ÿè½½å¹³è¡¡ã€‚é€šè¿‡æ¨¡æ‹Ÿå’ŒçœŸå®ä¸–ç•Œçš„å®éªŒï¼ŒéªŒè¯äº†è¯¥æ¨¡å‹åœ¨å„ç§åœ°å½¢å’Œç‰©ä½“ä¸Šçš„æœ‰æ•ˆæ€§ã€æ³›åŒ–æ€§å’Œé²æ£’æ€§ã€‚æ¨¡æ‹Ÿå®éªŒè¡¨æ˜ï¼Œä¸åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ¨¡å‹å¯å‡å°‘äººç±»24.7%çš„ä½“åŠ›æ¶ˆè€—ï¼ŒåŒæ—¶ä¿æŒç‰©ä½“ç¨³å®šæ€§ã€‚çœŸå®å®éªŒéªŒè¯äº†åœ¨ä¸åŒç‰©ä½“ç±»å‹ï¼ˆç®±å­ã€æ¡Œå­ã€æ‹…æ¶ç­‰ï¼‰å’Œè¿åŠ¨æ¨¡å¼ï¼ˆç›´çº¿ã€è½¬å¼¯ã€çˆ¬å¡ï¼‰ä¸‹çš„é²æ£’ååŒæ¬è¿ã€‚åŒ…å«23åå‚ä¸è€…çš„äººå·¥ç”¨æˆ·ç ”ç©¶è¯å®ï¼Œä¸åŸºçº¿æ¨¡å‹ç›¸æ¯”ï¼Œå¹³å‡æå‡äº†27.4%ã€‚è¯¥æ–¹æ³•æ— éœ€å¤–éƒ¨ä¼ æ„Ÿå™¨æˆ–å¤æ‚çš„äº¤äº’æ¨¡å‹ï¼Œå³å¯å®ç°ååŒæ¬è¿ï¼Œä¸ºå®é™…éƒ¨ç½²æä¾›äº†ä¸€ç§å¯è¡Œçš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³äººå½¢æœºå™¨äººä¸äººç±»ååŒæ¬è¿ç‰©ä½“æ—¶ï¼Œå¦‚ä½•å®ç°é«˜æ•ˆã€å®‰å…¨ã€è‡ªç„¶çš„åä½œé—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–å¤–éƒ¨ä¼ æ„Ÿå™¨ï¼ˆå¦‚è§†è§‰ï¼‰æˆ–å¤æ‚çš„äº¤äº’æ¨¡å‹ï¼Œæˆæœ¬é«˜æ˜‚ä¸”é²æ£’æ€§è¾ƒå·®ã€‚æ­¤å¤–ï¼Œå¦‚ä½•è®©äººå½¢æœºå™¨äººç†è§£äººç±»æ„å›¾å¹¶åšå‡ºç›¸åº”çš„åŠ¨ä½œï¼Œä¹Ÿæ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¼ºåŒ–å­¦ä¹ ï¼Œè®­ç»ƒä¸€ä¸ªä»…ä¾èµ–æœºå™¨äººæœ¬ä½“æ„Ÿè§‰çš„ç­–ç•¥ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿé€šè¿‡ä¸ç¯å¢ƒçš„äº¤äº’ï¼Œå­¦ä¹ åˆ°äººç±»çš„æ„å›¾å’Œç‰©ä½“çš„è¿åŠ¨æ¨¡å¼ï¼Œä»è€Œå®ç°ååŒæ¬è¿ã€‚é€šè¿‡å°†é¢†å¯¼è€…å’Œè·Ÿéšè€…è¡Œä¸ºèåˆåœ¨åŒä¸€ä¸ªç­–ç•¥ä¸­ï¼Œæœºå™¨äººå¯ä»¥æ ¹æ®å®é™…æƒ…å†µçµæ´»è°ƒæ•´è‡ªèº«è§’è‰²ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCOLAç®—æ³•çš„æ•´ä½“æ¡†æ¶æ˜¯ä¸€ä¸ªé—­ç¯å¼ºåŒ–å­¦ä¹ ç³»ç»Ÿã€‚æœºå™¨äººé€šè¿‡æœ¬ä½“æ„Ÿè§‰è·å–è‡ªèº«çŠ¶æ€ä¿¡æ¯ï¼Œå¹¶å°†å…¶è¾“å…¥åˆ°ç­–ç•¥ç½‘ç»œä¸­ã€‚ç­–ç•¥ç½‘ç»œè¾“å‡ºæœºå™¨äººçš„åŠ¨ä½œï¼Œä½œç”¨äºç¯å¢ƒï¼Œäº§ç”Ÿæ–°çš„çŠ¶æ€å’Œå¥–åŠ±ã€‚å¥–åŠ±å‡½æ•°çš„è®¾è®¡æ—¨åœ¨é¼“åŠ±æœºå™¨äººä¸äººç±»ååŒæ¬è¿ç‰©ä½“ï¼Œä¿æŒç‰©ä½“å¹³è¡¡ï¼Œå¹¶å‡å°‘äººç±»çš„ä½“åŠ›æ¶ˆè€—ã€‚é€šè¿‡ä¸æ–­åœ°ä¸ç¯å¢ƒäº¤äº’ï¼Œç­–ç•¥ç½‘ç»œé€æ¸å­¦ä¹ åˆ°æœ€ä¼˜ç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§ä»…ä¾èµ–æœ¬ä½“æ„Ÿè§‰çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œæ— éœ€å¤–éƒ¨ä¼ æ„Ÿå™¨å³å¯å®ç°äººæœºååŒæ¬è¿ã€‚æ­¤å¤–ï¼Œå°†é¢†å¯¼è€…å’Œè·Ÿéšè€…è¡Œä¸ºèåˆåœ¨åŒä¸€ä¸ªç­–ç•¥ä¸­ï¼Œä½¿å¾—æœºå™¨äººèƒ½å¤Ÿæ ¹æ®å®é™…æƒ…å†µçµæ´»è°ƒæ•´è‡ªèº«è§’è‰²ï¼Œæé«˜äº†åä½œçš„çµæ´»æ€§å’Œé²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šå¥–åŠ±å‡½æ•°çš„è®¾è®¡æ˜¯å…³é”®ã€‚å¥–åŠ±å‡½æ•°åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼šç‰©ä½“å¹³è¡¡å¥–åŠ±ï¼Œé¼“åŠ±æœºå™¨äººä¿æŒç‰©ä½“å¹³è¡¡ï¼›äººç±»ä½“åŠ›æ¶ˆè€—å¥–åŠ±ï¼Œé¼“åŠ±æœºå™¨äººå‡å°‘äººç±»çš„ä½“åŠ›æ¶ˆè€—ï¼›ååŒå¥–åŠ±ï¼Œé¼“åŠ±æœºå™¨äººä¸äººç±»ååŒæ¬è¿ç‰©ä½“ï¼›åŠ¨ä½œæƒ©ç½šï¼Œé˜²æ­¢æœºå™¨äººåšå‡ºä¸è‡ªç„¶çš„åŠ¨ä½œã€‚ç­–ç•¥ç½‘ç»œé‡‡ç”¨Actor-Criticç»“æ„ï¼ŒActorç½‘ç»œè¾“å‡ºæœºå™¨äººçš„åŠ¨ä½œï¼ŒCriticç½‘ç»œè¯„ä¼°å½“å‰çŠ¶æ€çš„ä»·å€¼ã€‚è®­ç»ƒç®—æ³•é‡‡ç”¨Trust Region Policy Optimization (TRPO)ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

æ¨¡æ‹Ÿå®éªŒè¡¨æ˜ï¼ŒCOLAç®—æ³•èƒ½å¤Ÿå‡å°‘äººç±»24.7%çš„ä½“åŠ›æ¶ˆè€—ï¼ŒåŒæ—¶ä¿æŒç‰©ä½“ç¨³å®šæ€§ã€‚çœŸå®ä¸–ç•Œå®éªŒéªŒè¯äº†COLAç®—æ³•åœ¨ä¸åŒç‰©ä½“ç±»å‹ï¼ˆç®±å­ã€æ¡Œå­ã€æ‹…æ¶ç­‰ï¼‰å’Œè¿åŠ¨æ¨¡å¼ï¼ˆç›´çº¿ã€è½¬å¼¯ã€çˆ¬å¡ï¼‰ä¸‹çš„é²æ£’æ€§ã€‚ç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼Œä¸åŸºçº¿æ¨¡å‹ç›¸æ¯”ï¼ŒCOLAç®—æ³•å¹³å‡æå‡äº†27.4%çš„ç”¨æˆ·ä½“éªŒã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºåŒ»ç–—ä¿å¥ã€å®¶åº­æœåŠ¡å’Œåˆ¶é€ ä¸šç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨åŒ»é™¢ä¸­ï¼Œäººå½¢æœºå™¨äººå¯ä»¥ä¸åŒ»æŠ¤äººå‘˜ååŒæ¬è¿ç—…äººæˆ–åŒ»ç–—è®¾å¤‡ï¼›åœ¨å®¶åº­ä¸­ï¼Œäººå½¢æœºå™¨äººå¯ä»¥å¸®åŠ©è€å¹´äººæˆ–æ®‹ç–¾äººæ¬è¿é‡ç‰©ï¼›åœ¨å·¥å‚ä¸­ï¼Œäººå½¢æœºå™¨äººå¯ä»¥ä¸å·¥äººååŒæ¬è¿é›¶éƒ¨ä»¶ã€‚è¯¥ç ”ç©¶æœ‰æœ›æé«˜äººæœºåä½œæ•ˆç‡ï¼Œé™ä½åŠ³åŠ¨å¼ºåº¦ï¼Œæ”¹å–„å·¥ä½œç¯å¢ƒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Human-humanoid collaboration shows significant promise for applications in healthcare, domestic assistance, and manufacturing. While compliant robot-human collaboration has been extensively developed for robotic arms, enabling compliant human-humanoid collaboration remains largely unexplored due to humanoids' complex whole-body dynamics. In this paper, we propose a proprioception-only reinforcement learning approach, COLA, that combines leader and follower behaviors within a single policy. The model is trained in a closed-loop environment with dynamic object interactions to predict object motion patterns and human intentions implicitly, enabling compliant collaboration to maintain load balance through coordinated trajectory planning. We evaluate our approach through comprehensive simulator and real-world experiments on collaborative carrying tasks, demonstrating the effectiveness, generalization, and robustness of our model across various terrains and objects. Simulation experiments demonstrate that our model reduces human effort by 24.7%. compared to baseline approaches while maintaining object stability. Real-world experiments validate robust collaborative carrying across different object types (boxes, desks, stretchers, etc.) and movement patterns (straight-line, turning, slope climbing). Human user studies with 23 participants confirm an average improvement of 27.4% compared to baseline models. Our method enables compliant human-humanoid collaborative carrying without requiring external sensors or complex interaction models, offering a practical solution for real-world deployment.

