---
layout: default
title: "AnyTask: an Automated Task and Data Generation Framework for Advancing Sim-to-Real Policy Learning"
---

# AnyTask: an Automated Task and Data Generation Framework for Advancing Sim-to-Real Policy Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.17853" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.17853v1</a>
  <a href="https://arxiv.org/pdf/2512.17853.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.17853v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.17853v1', 'AnyTask: an Automated Task and Data Generation Framework for Advancing Sim-to-Real Policy Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ran Gong, Xiaohan Zhang, Jinghuan Shang, Maria Vittoria Minniti, Jigarkumar Patel, Valerio Pepe, Riedana Yan, Ahmet Gundogdu, Ivan Kapelyukh, Ali Abbas, Xiaoqiang Yan, Harsh Patel, Laura Herlant, Karl Schmeckpeper

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-19

**å¤‡æ³¨**: 28 pages, 25 figures. The first four authors contributed equally

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**AnyTaskï¼šè‡ªåŠ¨åŒ–ä»»åŠ¡ä¸æ•°æ®ç”Ÿæˆæ¡†æ¶ï¼Œæ¨è¿›Sim-to-Realç­–ç•¥å­¦ä¹ **

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æœºå™¨äººå­¦ä¹ ` `Sim-to-Real` `è‡ªåŠ¨åŒ–ä»»åŠ¡ç”Ÿæˆ` `ä¸“å®¶æ¼”ç¤º` `è¡Œä¸ºå…‹éš†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çœŸå®ä¸–ç•Œæœºå™¨äººæ•°æ®æ”¶é›†æˆæœ¬é«˜æ˜‚ï¼Œä»¿çœŸæˆä¸ºé‡è¦æ›¿ä»£æ–¹æ¡ˆï¼Œä½†ä»»åŠ¡è®¾è®¡ã€åœºæ™¯ç”Ÿæˆå’Œè¿ç§»ä»éœ€å¤§é‡äººå·¥ã€‚
2. AnyTaskæ¡†æ¶ç»“åˆGPUå¹¶è¡Œä»¿çœŸä¸åŸºç¡€æ¨¡å‹ï¼Œè‡ªåŠ¨åŒ–è®¾è®¡å¤šæ ·æ“ä½œä»»åŠ¡å¹¶åˆæˆæœºå™¨äººæ•°æ®ï¼Œé™ä½äººå·¥æˆæœ¬ã€‚
3. é€šè¿‡ViPRç­‰Agentç”Ÿæˆä¸“å®¶æ¼”ç¤ºï¼Œè®­ç»ƒçš„è¡Œä¸ºå…‹éš†ç­–ç•¥åœ¨çœŸå®æœºå™¨äººä¸Šå®ç°äº†44%çš„å¹³å‡æˆåŠŸç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é€šç”¨æœºå™¨äººå­¦ä¹ å—åˆ°æ•°æ®é™åˆ¶ï¼šå¤§è§„æ¨¡ã€å¤šæ ·åŒ–å’Œé«˜è´¨é‡çš„äº¤äº’æ•°æ®åœ¨ç°å®ä¸–ç•Œä¸­æ”¶é›†æˆæœ¬é«˜æ˜‚ã€‚è™½ç„¶ä»¿çœŸå·²æˆä¸ºæ‰©å±•æ•°æ®æ”¶é›†çš„ä¸€ç§æœ‰å¸Œæœ›çš„æ–¹å¼ï¼Œä½†ç›¸å…³ä»»åŠ¡ï¼ŒåŒ…æ‹¬ä»¿çœŸä»»åŠ¡è®¾è®¡ã€ä»»åŠ¡æ„ŸçŸ¥åœºæ™¯ç”Ÿæˆã€ä¸“å®¶æ¼”ç¤ºåˆæˆå’ŒSim-to-Realè¿ç§»ï¼Œä»ç„¶éœ€è¦å¤§é‡çš„äººå·¥å¹²é¢„ã€‚æˆ‘ä»¬æå‡ºäº†AnyTaskï¼Œä¸€ä¸ªè‡ªåŠ¨åŒ–æ¡†æ¶ï¼Œå®ƒå°†å¤§è§„æ¨¡å¹¶è¡ŒGPUä»¿çœŸä¸åŸºç¡€æ¨¡å‹ç›¸ç»“åˆï¼Œä»¥è®¾è®¡å¤šæ ·åŒ–çš„æ“ä½œä»»åŠ¡å¹¶åˆæˆæœºå™¨äººæ•°æ®ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸‰ä¸ªAnyTask Agentï¼Œç”¨äºç”Ÿæˆæ—¨åœ¨è§£å†³å°½å¯èƒ½å¤šä»»åŠ¡çš„ä¸“å®¶æ¼”ç¤ºï¼š1) ViPRï¼Œä¸€ç§æ–°é¢–çš„ä»»åŠ¡å’Œè¿åŠ¨è§„åˆ’Agentï¼Œå…·æœ‰VLM-in-the-loopå¹¶è¡Œä¼˜åŒ–ï¼›2) ViPR-Eurekaï¼Œä¸€ç§å¼ºåŒ–å­¦ä¹ Agentï¼Œå…·æœ‰ç”Ÿæˆçš„å¯†é›†å¥–åŠ±å’ŒLLMå¼•å¯¼çš„æ¥è§¦é‡‡æ ·ï¼›3) ViPR-RLï¼Œä¸€ç§æ··åˆè§„åˆ’å’Œå­¦ä¹ æ–¹æ³•ï¼Œå®ƒä»…ä½¿ç”¨ç¨€ç–å¥–åŠ±å…±åŒäº§ç”Ÿé«˜è´¨é‡çš„æ¼”ç¤ºã€‚æˆ‘ä»¬åœ¨ç”Ÿæˆçš„æ•°æ®ä¸Šè®­ç»ƒè¡Œä¸ºå…‹éš†ç­–ç•¥ï¼Œåœ¨ä»¿çœŸä¸­éªŒè¯å®ƒä»¬ï¼Œå¹¶å°†å®ƒä»¬ç›´æ¥éƒ¨ç½²åœ¨çœŸå®æœºå™¨äººç¡¬ä»¶ä¸Šã€‚è¿™äº›ç­–ç•¥æ¨å¹¿åˆ°æ–°çš„ç‰©ä½“å§¿åŠ¿ï¼Œåœ¨çœŸå®ä¸–ç•Œçš„æŠ“å–æ”¾ç½®ã€æŠ½å±‰æ‰“å¼€ã€å¯Œæ¥è§¦æ¨å’Œé•¿æ—¶ç¨‹æ“ä½œä»»åŠ¡å¥—ä»¶ä¸­å®ç°äº†44%çš„å¹³å‡æˆåŠŸç‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æœºå™¨äººå­¦ä¹ æ–¹æ³•ä¾èµ–äºå¤§é‡çœŸå®ä¸–ç•Œæ•°æ®ï¼Œä½†æ•°æ®æ”¶é›†æˆæœ¬é«˜æ˜‚ä¸”è€—æ—¶ã€‚ä»¿çœŸç¯å¢ƒå¯ä»¥ç”Ÿæˆå¤§é‡æ•°æ®ï¼Œä½†ä»»åŠ¡è®¾è®¡ã€åœºæ™¯ç”Ÿæˆã€ä¸“å®¶æ¼”ç¤ºåˆæˆä»¥åŠä»ä»¿çœŸåˆ°çœŸå®çš„è¿ç§»ä»ç„¶éœ€è¦å¤§é‡çš„äººå·¥å¹²é¢„ã€‚è¿™é™åˆ¶äº†é€šç”¨æœºå™¨äººå­¦ä¹ çš„å‘å±•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šAnyTaskçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§è§„æ¨¡å¹¶è¡ŒGPUä»¿çœŸå’ŒåŸºç¡€æ¨¡å‹ï¼Œè‡ªåŠ¨åŒ–åœ°ç”Ÿæˆå¤šæ ·åŒ–çš„æ“ä½œä»»åŠ¡å’Œé«˜è´¨é‡çš„æœºå™¨äººæ•°æ®ã€‚é€šè¿‡è‡ªåŠ¨åŒ–ä»»åŠ¡è®¾è®¡å’Œæ•°æ®ç”Ÿæˆæµç¨‹ï¼Œé™ä½å¯¹äººå·¥å¹²é¢„çš„ä¾èµ–ï¼Œä»è€ŒåŠ é€ŸSim-to-Realç­–ç•¥å­¦ä¹ ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAnyTaskæ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) ä»»åŠ¡è®¾è®¡æ¨¡å—ï¼šåˆ©ç”¨åŸºç¡€æ¨¡å‹è‡ªåŠ¨ç”Ÿæˆå¤šæ ·åŒ–çš„æ“ä½œä»»åŠ¡ã€‚2) åœºæ™¯ç”Ÿæˆæ¨¡å—ï¼šæ ¹æ®ä»»åŠ¡éœ€æ±‚è‡ªåŠ¨ç”Ÿæˆä»»åŠ¡ç›¸å…³çš„åœºæ™¯ã€‚3) ä¸“å®¶æ¼”ç¤ºåˆæˆæ¨¡å—ï¼šä½¿ç”¨ViPRã€ViPR-Eurekaå’ŒViPR-RLç­‰Agentç”Ÿæˆé«˜è´¨é‡çš„ä¸“å®¶æ¼”ç¤ºæ•°æ®ã€‚4) ç­–ç•¥è®­ç»ƒæ¨¡å—ï¼šä½¿ç”¨ç”Ÿæˆçš„æ•°æ®è®­ç»ƒè¡Œä¸ºå…‹éš†ç­–ç•¥ã€‚5) Sim-to-Realè¿ç§»æ¨¡å—ï¼šå°†è®­ç»ƒå¥½çš„ç­–ç•¥éƒ¨ç½²åˆ°çœŸå®æœºå™¨äººä¸Šã€‚

**å…³é”®åˆ›æ–°**ï¼šAnyTaskçš„å…³é”®åˆ›æ–°åœ¨äºè‡ªåŠ¨åŒ–ä»»åŠ¡å’Œæ•°æ®ç”Ÿæˆæµç¨‹ï¼Œç‰¹åˆ«æ˜¯ViPR Agentçš„è®¾è®¡ã€‚ViPR Agenté‡‡ç”¨VLM-in-the-loopå¹¶è¡Œä¼˜åŒ–ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°ç”Ÿæˆé«˜è´¨é‡çš„ä¸“å®¶æ¼”ç¤ºæ•°æ®ã€‚æ­¤å¤–ï¼ŒViPR-Eureka Agentåˆ©ç”¨LLMå¼•å¯¼çš„æ¥è§¦é‡‡æ ·ï¼Œæé«˜äº†å¼ºåŒ–å­¦ä¹ çš„æ•ˆç‡ã€‚ViPR-RL Agentåˆ™ç»“åˆäº†è§„åˆ’å’Œå­¦ä¹ æ–¹æ³•ï¼Œåœ¨ç¨€ç–å¥–åŠ±ä¸‹ä¹Ÿèƒ½ç”Ÿæˆé«˜è´¨é‡çš„æ¼”ç¤ºã€‚

**å…³é”®è®¾è®¡**ï¼šViPR Agentçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) VLM-in-the-loopï¼šåˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰æ¥è¯„ä¼°ä»»åŠ¡å®Œæˆæƒ…å†µï¼Œå¹¶æŒ‡å¯¼ä»»åŠ¡è§„åˆ’ã€‚2) å¹¶è¡Œä¼˜åŒ–ï¼šåˆ©ç”¨GPUå¹¶è¡Œè®¡ç®—èƒ½åŠ›ï¼ŒåŒæ—¶ä¼˜åŒ–å¤šä¸ªä»»åŠ¡è§„åˆ’æ–¹æ¡ˆï¼Œæé«˜æ•ˆç‡ã€‚3) å¥–åŠ±å‡½æ•°è®¾è®¡ï¼šViPR-Eureka Agentè®¾è®¡äº†åŸºäºLLMçš„å¯†é›†å¥–åŠ±å‡½æ•°ï¼Œå¼•å¯¼Agentå­¦ä¹ ã€‚4) æ¥è§¦é‡‡æ ·ï¼šViPR-Eureka Agentåˆ©ç”¨LLMå¼•å¯¼çš„æ¥è§¦é‡‡æ ·ï¼Œæé«˜æ¢ç´¢æ•ˆç‡ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.17853v1/figures_and_tables/draft_main_figure.jpg" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.17853v1/figures_and_tables/vipr_improvement.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.17853v1/x1.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨AnyTaskæ¡†æ¶ç”Ÿæˆçš„æ•°æ®è®­ç»ƒçš„è¡Œä¸ºå…‹éš†ç­–ç•¥ï¼Œåœ¨çœŸå®ä¸–ç•Œçš„æŠ“å–æ”¾ç½®ã€æŠ½å±‰æ‰“å¼€ã€å¯Œæ¥è§¦æ¨å’Œé•¿æ—¶ç¨‹æ“ä½œä»»åŠ¡å¥—ä»¶ä¸­å®ç°äº†44%çš„å¹³å‡æˆåŠŸç‡ã€‚è¯¥ç­–ç•¥èƒ½å¤Ÿæ¨å¹¿åˆ°æ–°çš„ç‰©ä½“å§¿åŠ¿ï¼Œè¯æ˜äº†AnyTaskæ¡†æ¶çš„æœ‰æ•ˆæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚ç›¸è¾ƒäºå…¶ä»–æ–¹æ³•ï¼ŒAnyTaskæ˜¾è‘—é™ä½äº†äººå·¥å¹²é¢„çš„éœ€æ±‚ï¼Œæé«˜äº†æ•°æ®ç”Ÿæˆçš„æ•ˆç‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

AnyTaskæ¡†æ¶å¯åº”ç”¨äºå„ç§æœºå™¨äººæ“ä½œä»»åŠ¡ï¼Œä¾‹å¦‚å·¥ä¸šè‡ªåŠ¨åŒ–ã€å®¶åº­æœåŠ¡æœºå™¨äººã€åŒ»ç–—æœºå™¨äººç­‰ã€‚é€šè¿‡è‡ªåŠ¨åŒ–ä»»åŠ¡è®¾è®¡å’Œæ•°æ®ç”Ÿæˆï¼Œå¯ä»¥é™ä½æœºå™¨äººå­¦ä¹ çš„æˆæœ¬ï¼ŒåŠ é€Ÿæœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„éƒ¨ç½²ã€‚è¯¥æ¡†æ¶è¿˜æœ‰åŠ©äºæ¨åŠ¨é€šç”¨æœºå™¨äººå­¦ä¹ çš„å‘å±•ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿé€‚åº”å„ç§ä¸åŒçš„ä»»åŠ¡å’Œç¯å¢ƒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Generalist robot learning remains constrained by data: large-scale, diverse, and high-quality interaction data are expensive to collect in the real world. While simulation has become a promising way for scaling up data collection, the related tasks, including simulation task design, task-aware scene generation, expert demonstration synthesis, and sim-to-real transfer, still demand substantial human effort. We present AnyTask, an automated framework that pairs massively parallel GPU simulation with foundation models to design diverse manipulation tasks and synthesize robot data. We introduce three AnyTask agents for generating expert demonstrations aiming to solve as many tasks as possible: 1) ViPR, a novel task and motion planning agent with VLM-in-the-loop Parallel Refinement; 2) ViPR-Eureka, a reinforcement learning agent with generated dense rewards and LLM-guided contact sampling; 3) ViPR-RL, a hybrid planning and learning approach that jointly produces high-quality demonstrations with only sparse rewards. We train behavior cloning policies on generated data, validate them in simulation, and deploy them directly on real robot hardware. The policies generalize to novel object poses, achieving 44% average success across a suite of real-world pick-and-place, drawer opening, contact-rich pushing, and long-horizon manipulation tasks. Our project website is at https://anytask.rai-inst.com .

