---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-12-21
---

# cs.ROï¼ˆ2025-12-21ï¼‰

ğŸ“Š å…± **11** ç¯‡è®ºæ–‡


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (8)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (2)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (8 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251217853v1-anytask-an-automated-task-and-data-generation-framework-for-advancin.html">AnyTask: an Automated Task and Data Generation Framework for Advancing Sim-to-Real Policy Learning</a></td>
  <td>AnyTaskï¼šè‡ªåŠ¨åŒ–ä»»åŠ¡ä¸æ•°æ®ç”Ÿæˆæ¡†æ¶ï¼Œæ¨è¿›Sim-to-Realç­–ç•¥å­¦ä¹ </td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">sim-to-real</span> <span class="paper-tag">motion planning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.17853v1" data-paper-url="./papers/251217853v1-anytask-an-automated-task-and-data-generation-framework-for-advancin.html" onclick="toggleFavorite(this, '2512.17853v1', 'AnyTask: an Automated Task and Data Generation Framework for Advancing Sim-to-Real Policy Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251217183v1-semantic-co-speech-gesture-synthesis-and-real-time-control-for-human.html">Semantic Co-Speech Gesture Synthesis and Real-Time Control for Humanoid Robots</a></td>
  <td>æå‡ºä¸€ç§åŸºäºè¯­ä¹‰ç†è§£çš„å…±è¯­å§¿åŠ¿ç”Ÿæˆä¸äººå½¢æœºå™¨äººå®æ—¶æ§åˆ¶æ¡†æ¶</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid robot</span> <span class="paper-tag">Unitree</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.17183v1" data-paper-url="./papers/251217183v1-semantic-co-speech-gesture-synthesis-and-real-time-control-for-human.html" onclick="toggleFavorite(this, '2512.17183v1', 'Semantic Co-Speech Gesture Synthesis and Real-Time Control for Humanoid Robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251217568v1-kinematics-aware-diffusion-policy-with-consistent-3d-observation-and.html">Kinematics-Aware Diffusion Policy with Consistent 3D Observation and Action Space for Whole-Arm Robotic Manipulation</a></td>
  <td>æå‡ºåŸºäºè¿åŠ¨å­¦æ„ŸçŸ¥çš„æ‰©æ•£ç­–ç•¥ï¼Œè§£å†³æœºæ¢°è‡‚å…¨èº«æ“ä½œä¸­çš„ç©ºé—´æ³›åŒ–é—®é¢˜ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">whole-body control</span> <span class="paper-tag">manipulation</span> <span class="paper-tag">policy learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.17568v1" data-paper-url="./papers/251217568v1-kinematics-aware-diffusion-policy-with-consistent-3d-observation-and.html" onclick="toggleFavorite(this, '2512.17568v1', 'Kinematics-Aware Diffusion Policy with Consistent 3D Observation and Action Space for Whole-Arm Robotic Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251217321v1-neuro-symbolic-control-with-large-language-models-for-language-guide.html">Neuro-Symbolic Control with Large Language Models for Language-Guided Spatial Tasks</a></td>
  <td>æå‡ºç¥ç»ç¬¦å·æ§åˆ¶æ¡†æ¶ï¼Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹è§£å†³è¯­è¨€å¼•å¯¼çš„ç©ºé—´ä»»åŠ¡</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.17321v1" data-paper-url="./papers/251217321v1-neuro-symbolic-control-with-large-language-models-for-language-guide.html" onclick="toggleFavorite(this, '2512.17321v1', 'Neuro-Symbolic Control with Large Language Models for Language-Guided Spatial Tasks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251217349v1-flying-in-clutter-on-monocular-rgb-by-learning-in-3d-radiance-fields.html">Flying in Clutter on Monocular RGB by Learning in 3D Radiance Fields with Domain Adaptation</a></td>
  <td>æå‡ºåŸºäº3Dè¾å°„åœºå’Œå¯¹æŠ—åŸŸé€‚åº”çš„å•ç›®RGBå›¾åƒæ— äººæœºå¤æ‚ç¯å¢ƒå¯¼èˆªæ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">sim-to-real</span> <span class="paper-tag">3D gaussian splatting</span> <span class="paper-tag">3DGS</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.17349v1" data-paper-url="./papers/251217349v1-flying-in-clutter-on-monocular-rgb-by-learning-in-3d-radiance-fields.html" onclick="toggleFavorite(this, '2512.17349v1', 'Flying in Clutter on Monocular RGB by Learning in 3D Radiance Fields with Domain Adaptation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251217764v1-unistatedlo-unified-generative-state-estimation-and-tracking-of-defo.html">UniStateDLO: Unified Generative State Estimation and Tracking of Deformable Linear Objects Under Occlusion for Constrained Manipulation</a></td>
  <td>UniStateDLOï¼šæå‡ºç»Ÿä¸€çš„ç”Ÿæˆå¼æ¡†æ¶ï¼Œç”¨äºé®æŒ¡ä¸‹å¯å˜å½¢çº¿æ€§ç‰©ä½“çš„çŠ¶æ€ä¼°è®¡ä¸è·Ÿè¸ª</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">sim-to-real</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.17764v1" data-paper-url="./papers/251217764v1-unistatedlo-unified-generative-state-estimation-and-tracking-of-defo.html" onclick="toggleFavorite(this, '2512.17764v1', 'UniStateDLO: Unified Generative State Estimation and Tracking of Deformable Linear Objects Under Occlusion for Constrained Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/251217846v1-planning-as-descent-goal-conditioned-latent-trajectory-synthesis-in-.html">Planning as Descent: Goal-Conditioned Latent Trajectory Synthesis in Learned Energy Landscapes</a></td>
  <td>æå‡ºPlanning as Descent (PaD)ï¼Œé€šè¿‡å­¦ä¹ èƒ½é‡åœºè¿›è¡Œç¦»çº¿ç›®æ ‡æ¡ä»¶å¼ºåŒ–å­¦ä¹ ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">reinforcement learning</span> <span class="paper-tag">policy learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.17846v1" data-paper-url="./papers/251217846v1-planning-as-descent-goal-conditioned-latent-trajectory-synthesis-in-.html" onclick="toggleFavorite(this, '2512.17846v1', 'Planning as Descent: Goal-Conditioned Latent Trajectory Synthesis in Learned Energy Landscapes')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251217661v1-vidarc-embodied-video-diffusion-model-for-closed-loop-control.html">Vidarc: Embodied Video Diffusion Model for Closed-loop Control</a></td>
  <td>Vidarcï¼šç”¨äºé—­ç¯æ§åˆ¶çš„å…·èº«è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼Œæå‡æœºå™¨äººæ“ä½œæ€§èƒ½ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">cross-embodiment</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.17661v1" data-paper-url="./papers/251217661v1-vidarc-embodied-video-diffusion-model-for-closed-loop-control.html" onclick="toggleFavorite(this, '2512.17661v1', 'Vidarc: Embodied Video Diffusion Model for Closed-loop Control')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>9</td>
  <td><a href="./papers/251217309v1-recipemasterllm-revisiting-roboearth-in-the-era-of-large-language-mo.html">RecipeMasterLLM: Revisiting RoboEarth in the Era of Large Language Models</a></td>
  <td>RecipeMasterLLMï¼šåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹é‡å¡‘RoboEarthçŸ¥è¯†è·å–æµç¨‹</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.17309v1" data-paper-url="./papers/251217309v1-recipemasterllm-revisiting-roboearth-in-the-era-of-large-language-mo.html" onclick="toggleFavorite(this, '2512.17309v1', 'RecipeMasterLLM: Revisiting RoboEarth in the Era of Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/251217241v1-a-service-robots-guide-to-interacting-with-busy-customers.html">A Service Robot's Guide to Interacting with Busy Customers</a></td>
  <td>ç ”ç©¶æœåŠ¡æœºå™¨äººä¸å¿™ç¢Œé¡¾å®¢äº¤äº’ï¼Œä¼˜åŒ–æ²Ÿé€šæ–¹å¼ä»¥æå‡ç”¨æˆ·ä½“éªŒ</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.17241v1" data-paper-url="./papers/251217241v1-a-service-robots-guide-to-interacting-with-busy-customers.html" onclick="toggleFavorite(this, '2512.17241v1', 'A Service Robot&#39;s Guide to Interacting with Busy Customers')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>11</td>
  <td><a href="./papers/251217435v1-imaginenav-prompting-vision-language-models-as-embodied-navigator-th.html">ImagineNav++: Prompting Vision-Language Models as Embodied Navigator through Scene Imagination</a></td>
  <td>ImagineNav++ï¼šé€šè¿‡åœºæ™¯æƒ³è±¡æç¤ºè§†è§‰-è¯­è¨€æ¨¡å‹ï¼Œå®ç°å…·èº«å¯¼èˆª</td>
  <td class="tags-cell"><span class="paper-tag">open-vocabulary</span> <span class="paper-tag">open vocabulary</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.17435v1" data-paper-url="./papers/251217435v1-imaginenav-prompting-vision-language-models-as-embodied-navigator-th.html" onclick="toggleFavorite(this, '2512.17435v1', 'ImagineNav++: Prompting Vision-Language Models as Embodied Navigator through Scene Imagination')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)