---
layout: default
title: "DexUMI: Using Human Hand as the Universal Manipulation Interface for Dexterous Manipulation"
---

# DexUMI: Using Human Hand as the Universal Manipulation Interface for Dexterous Manipulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21864" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21864v3</a>
  <a href="https://arxiv.org/pdf/2505.21864.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21864v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21864v3', 'DexUMI: Using Human Hand as the Universal Manipulation Interface for Dexterous Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mengda Xu, Han Zhang, Yifan Hou, Zhenjia Xu, Linxi Fan, Manuela Veloso, Shuran Song

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-05-28 (æ›´æ–°: 2025-10-02)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDexUMIä»¥è§£å†³äººæœºäº¤äº’ä¸­çš„çµå·§æ“ä½œé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `çµå·§æ“ä½œ` `äººæœºäº¤äº’` `æœºå™¨äººæ‰‹` `æ•°æ®æ”¶é›†` `ç­–ç•¥å­¦ä¹ ` `å¯ç©¿æˆ´è®¾å¤‡` `å›¾åƒä¿®å¤`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å°†äººç±»çµå·§æ“ä½œæŠ€èƒ½è½¬ç§»åˆ°æœºå™¨äººæ‰‹æ—¶é¢ä¸´ä½“ç°å·®è·ï¼Œå¯¼è‡´æ“ä½œæ•ˆæœä¸ä½³ã€‚
2. DexUMIé€šè¿‡å¯ç©¿æˆ´æ‰‹éƒ¨å¤–éª¨éª¼å’Œé«˜ä¿çœŸæœºå™¨äººæ‰‹ä¿®å¤ï¼Œè§£å†³äº†äººæ‰‹ä¸æœºå™¨äººæ‰‹ä¹‹é—´çš„è¿åŠ¨å­¦å’Œè§†è§‰å·®è·ã€‚
3. åœ¨ä¸¤ç§ä¸åŒçš„çµå·§æœºå™¨äººæ‰‹å¹³å°ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼ŒDexUMIçš„å¹³å‡ä»»åŠ¡æˆåŠŸç‡è¾¾åˆ°äº†86%ï¼Œæ˜¾è‘—æå‡äº†æ“ä½œæˆåŠŸç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬æå‡ºäº†DexUMIâ€”â€”ä¸€ä¸ªæ•°æ®æ”¶é›†å’Œç­–ç•¥å­¦ä¹ æ¡†æ¶ï¼Œåˆ©ç”¨äººæ‰‹ä½œä¸ºè‡ªç„¶æ¥å£ï¼Œå°†çµå·§æ“ä½œæŠ€èƒ½è½¬ç§»åˆ°å„ç§æœºå™¨äººæ‰‹ä¸Šã€‚DexUMIé€šè¿‡ç¡¬ä»¶å’Œè½¯ä»¶é€‚é…ï¼Œæœ€å°åŒ–äººæ‰‹ä¸æœºå™¨äººæ‰‹ä¹‹é—´çš„ä½“ç°å·®è·ã€‚ç¡¬ä»¶é€‚é…é€šè¿‡å¯ç©¿æˆ´æ‰‹éƒ¨å¤–éª¨éª¼å¼¥è¡¥è¿åŠ¨å­¦å·®è·ï¼Œå…è®¸åœ¨æ•°æ®æ”¶é›†è¿‡ç¨‹ä¸­ç›´æ¥è¿›è¡Œè§¦è§‰åé¦ˆï¼Œå¹¶å°†äººç±»åŠ¨ä½œé€‚é…ä¸ºå¯è¡Œçš„æœºå™¨äººæ‰‹åŠ¨ä½œã€‚è½¯ä»¶é€‚é…åˆ™é€šè¿‡é«˜ä¿çœŸæœºå™¨äººæ‰‹çš„ä¿®å¤ï¼Œå¼¥è¡¥è§†è§‰å·®è·ã€‚æˆ‘ä»¬é€šè¿‡åœ¨ä¸¤ç§ä¸åŒçµå·§æœºå™¨äººæ‰‹ç¡¬ä»¶å¹³å°ä¸Šçš„å…¨é¢å®éªŒè¯æ˜äº†DexUMIçš„èƒ½åŠ›ï¼Œå¹³å‡ä»»åŠ¡æˆåŠŸç‡è¾¾åˆ°86%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³äººç±»çµå·§æ“ä½œæŠ€èƒ½å‘æœºå™¨äººæ‰‹è½¬ç§»è¿‡ç¨‹ä¸­çš„ä½“ç°å·®è·é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨è¿™ä¸€è¿‡ç¨‹ä¸­é¢ä¸´è¿åŠ¨å­¦å’Œè§†è§‰ä¸Šçš„éšœç¢ï¼Œå¯¼è‡´æ“ä½œæ•ˆæœä¸ç†æƒ³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDexUMIçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨äººæ‰‹ä½œä¸ºè‡ªç„¶æ¥å£ï¼Œé€šè¿‡ç¡¬ä»¶å’Œè½¯ä»¶çš„åŒé‡é€‚é…ï¼Œå‡å°‘äººæ‰‹ä¸æœºå™¨äººæ‰‹ä¹‹é—´çš„å·®è·ï¼Œä»è€Œå®ç°é«˜æ•ˆçš„æŠ€èƒ½è½¬ç§»ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDexUMIçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šç¡¬ä»¶é€‚é…æ¨¡å—å’Œè½¯ä»¶é€‚é…æ¨¡å—ã€‚ç¡¬ä»¶é€‚é…æ¨¡å—ä½¿ç”¨å¯ç©¿æˆ´æ‰‹éƒ¨å¤–éª¨éª¼æ¥æ•æ‰äººæ‰‹åŠ¨ä½œå¹¶æä¾›è§¦è§‰åé¦ˆï¼›è½¯ä»¶é€‚é…æ¨¡å—åˆ™é€šè¿‡é«˜ä¿çœŸæœºå™¨äººæ‰‹çš„ä¿®å¤æŠ€æœ¯ï¼Œå¤„ç†è§†é¢‘æ•°æ®ä¸­çš„äººæ‰‹å›¾åƒã€‚

**å…³é”®åˆ›æ–°**ï¼šDexUMIçš„å…³é”®åˆ›æ–°åœ¨äºå…¶ç¡¬ä»¶å’Œè½¯ä»¶çš„ç»“åˆä½¿ç”¨ï¼Œç‰¹åˆ«æ˜¯å¯ç©¿æˆ´å¤–éª¨éª¼çš„åº”ç”¨å’Œé«˜ä¿çœŸå›¾åƒä¿®å¤æŠ€æœ¯çš„ç»“åˆï¼Œä½¿å¾—äººæ‰‹ä¸æœºå™¨äººæ‰‹ä¹‹é—´çš„è¿åŠ¨å­¦å’Œè§†è§‰å·®è·å¾—ä»¥æœ‰æ•ˆå¼¥è¡¥ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç¡¬ä»¶è®¾è®¡ä¸­ï¼Œå¤–éª¨éª¼çš„çµæ´»æ€§å’Œèˆ’é€‚æ€§æ˜¯å…³é”®å‚æ•°ï¼›åœ¨è½¯ä»¶è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å…ˆè¿›çš„å›¾åƒä¿®å¤ç®—æ³•ï¼Œä»¥ç¡®ä¿æœºå™¨äººæ‰‹çš„é«˜ä¿çœŸåº¦å’Œè‡ªç„¶æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼ŒDexUMIåœ¨ä¸¤ç§ä¸åŒçš„çµå·§æœºå™¨äººæ‰‹å¹³å°ä¸Šå®ç°äº†å¹³å‡86%çš„ä»»åŠ¡æˆåŠŸç‡ï¼Œç›¸è¾ƒäºç°æœ‰æ–¹æ³•æœ‰æ˜¾è‘—æå‡ã€‚è¿™ä¸€ç»“æœè¡¨æ˜DexUMIåœ¨çµå·§æ“ä½œæŠ€èƒ½è½¬ç§»ä¸­çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

DexUMIçš„ç ”ç©¶æˆæœå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶åœ¨æœåŠ¡æœºå™¨äººã€åŒ»ç–—æœºå™¨äººå’Œäººæœºåä½œé¢†åŸŸã€‚é€šè¿‡å®ç°æ›´è‡ªç„¶çš„æ“ä½œæ¥å£ï¼ŒDexUMIå¯ä»¥æå‡æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„çµæ´»æ€§å’Œé€‚åº”æ€§ï¼Œæ¨åŠ¨æ™ºèƒ½æœºå™¨äººæŠ€æœ¯çš„è¿›æ­¥ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present DexUMI - a data collection and policy learning framework that uses the human hand as the natural interface to transfer dexterous manipulation skills to various robot hands. DexUMI includes hardware and software adaptations to minimize the embodiment gap between the human hand and various robot hands. The hardware adaptation bridges the kinematics gap using a wearable hand exoskeleton. It allows direct haptic feedback in manipulation data collection and adapts human motion to feasible robot hand motion. The software adaptation bridges the visual gap by replacing the human hand in video data with high-fidelity robot hand inpainting. We demonstrate DexUMI's capabilities through comprehensive real-world experiments on two different dexterous robot hand hardware platforms, achieving an average task success rate of 86%.

