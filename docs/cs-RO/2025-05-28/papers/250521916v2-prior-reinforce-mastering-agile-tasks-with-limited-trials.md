---
layout: default
title: "Prior Reinforce: Mastering Agile Tasks with Limited Trials"
---

# Prior Reinforce: Mastering Agile Tasks with Limited Trials

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.21916" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.21916v2</a>
  <a href="https://arxiv.org/pdf/2505.21916.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.21916v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.21916v2', 'Prior Reinforce: Mastering Agile Tasks with Limited Trials')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yihang Hu, Pingyue Sheng, Yuyang Liu, Shengjie Wang, Yang Gao

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-05-28 (æ›´æ–°: 2025-09-27)

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://adap-robotics.github.io/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPrior Reinforceä»¥è§£å†³åŠ¨æ€ä»»åŠ¡ä¸­çš„é«˜ç²¾åº¦é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å…·èº«æœºå™¨äºº` `åŠ¨æ€ä»»åŠ¡` `æ¨¡ä»¿å­¦ä¹ ` `åé¦ˆä¼˜åŒ–` `é«˜ç²¾åº¦æ“ä½œ` `è¿åŠ¨æ¨¡å¼å­¦ä¹ ` `äººç±»å­¦ä¹ å¯å‘`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤„ç†é«˜ç²¾åº¦åŠ¨æ€ä»»åŠ¡æ—¶ï¼Œå¾€å¾€éœ€è¦å¤§é‡çš„æ•°æ®å’Œå¤æ‚çš„è®¾è®¡ï¼Œå¯¼è‡´æ•ˆç‡ä½ä¸‹ã€‚
2. Prior Reinforceé€šè¿‡æ¨¡ä»¿å°‘é‡ç¤ºèŒƒå¹¶åŸºäºåé¦ˆè¿­ä»£ä¼˜åŒ–ï¼Œç®€åŒ–äº†åŠ¨æ€ä»»åŠ¡çš„å­¦ä¹ è¿‡ç¨‹ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPrior Reinforceèƒ½å¤Ÿåœ¨çœŸå®ç¯å¢ƒä¸­ä»¥äººç±»æ°´å¹³çš„ç²¾åº¦å®Œæˆå¤šç§ä»»åŠ¡ï¼Œæ˜¾è‘—å‡å°‘å°è¯•æ¬¡æ•°ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°ä»Šçš„å…·èº«æœºå™¨äººèƒ½å¤Ÿå¤„ç†è®¸å¤šç°å®ä¸–ç•Œçš„æ“ä½œä»»åŠ¡ï¼Œä½†åœ¨æ¶‰åŠåŠ¨æ€è¿‡ç¨‹çš„é«˜ç²¾åº¦ä»»åŠ¡ï¼ˆå¦‚æŠ•ç¯®ï¼‰æ—¶ï¼Œä»é¢ä¸´å·¨å¤§æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€éœ€è¦å¤§é‡çš„æ•°æ®æ”¶é›†å’Œå¤æ‚çš„å¥–åŠ±è®¾è®¡ã€‚å—äººç±»å­¦ä¹ è¿‡ç¨‹çš„å¯å‘ï¼Œæœ¬æ–‡æå‡ºäº†Prior Reinforceï¼ˆP.R.ï¼‰ï¼Œä¸€ç§ç®€å•ä¸”å¯æ‰©å±•çš„æ–¹æ³•ï¼Œèƒ½å¤Ÿä»å°‘é‡ç¤ºèŒƒä¸­å­¦ä¹ è¿åŠ¨æ¨¡å¼ï¼Œå¹¶é€šè¿‡å°‘é‡è¯•éªŒåé¦ˆè¿­ä»£ä¼˜åŒ–ï¼Œæœ€ç»ˆå®ç°ç‰¹å®šç›®æ ‡ã€‚å®éªŒè¡¨æ˜ï¼ŒPrior Reinforceèƒ½å¤Ÿåœ¨çœŸå®ç¯å¢ƒä¸­ä»¥äººç±»æ°´å¹³çš„ç²¾åº¦å’Œæ•ˆç‡å®Œæˆå¤šç§ç›®æ ‡å¯¼å‘çš„åŠ¨æ€ä»»åŠ¡ï¼Œå¦‚åœ¨å°‘äº10æ¬¡å°è¯•å†…æˆåŠŸæŠ•ç¯®ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å…·èº«æœºå™¨äººåœ¨é«˜ç²¾åº¦åŠ¨æ€ä»»åŠ¡ï¼ˆå¦‚æŠ•ç¯®ï¼‰ä¸­çš„å­¦ä¹ æ•ˆç‡ä½ä¸‹é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºå¤§é‡æ•°æ®å’Œå¤æ‚çš„å¥–åŠ±è®¾è®¡ï¼Œå¯¼è‡´åœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„åº”ç”¨å—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šPrior Reinforceçš„æ ¸å¿ƒæ€æƒ³æ˜¯æ¨¡ä»¿äººç±»å­¦ä¹ è¿‡ç¨‹ï¼Œé€šè¿‡å°‘é‡ç¤ºèŒƒå­¦ä¹ è¿åŠ¨æ¨¡å¼ï¼Œå¹¶åœ¨çœŸå®è¯•éªŒä¸­åŸºäºåé¦ˆè¿›è¡Œè¿­ä»£ä¼˜åŒ–ã€‚è¿™ç§æ–¹æ³•ä½¿å¾—æœºå™¨äººèƒ½å¤Ÿåœ¨è¾ƒå°‘çš„å°è¯•ä¸­è¾¾åˆ°é«˜ç²¾åº¦ç›®æ ‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPrior Reinforceçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µæ˜¯ä»å°‘é‡ç¤ºèŒƒä¸­å­¦ä¹ è¿åŠ¨æ¨¡å¼ï¼Œç¬¬äºŒé˜¶æ®µæ˜¯é€šè¿‡çœŸå®è¯•éªŒåé¦ˆè¿­ä»£ä¼˜åŒ–ç”Ÿæˆçš„è¿åŠ¨ã€‚æ¯ä¸ªé˜¶æ®µéƒ½å¼ºè°ƒäº†åé¦ˆçš„é‡è¦æ€§ï¼Œä»¥æé«˜å­¦ä¹ æ•ˆç‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šPrior Reinforceçš„åˆ›æ–°åœ¨äºç»“åˆäº†æ¨¡ä»¿å­¦ä¹ ä¸åé¦ˆä¼˜åŒ–çš„ç­–ç•¥ï¼Œä½¿å¾—æœºå™¨äººèƒ½å¤Ÿåœ¨åŠ¨æ€ä»»åŠ¡ä¸­å¿«é€Ÿé€‚åº”å¹¶è¾¾åˆ°ç›®æ ‡ã€‚è¿™ä¸ä¼ ç»Ÿæ–¹æ³•çš„ä¾èµ–å¤§é‡æ•°æ®å’Œå¤æ‚è®¾è®¡å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®ç°è¿‡ç¨‹ä¸­ï¼ŒPrior Reinforceé‡‡ç”¨äº†ç®€å•çš„è¿åŠ¨æ¨¡å¼å­¦ä¹ ç®—æ³•ï¼Œå¹¶è®¾è®¡äº†æœ‰æ•ˆçš„åé¦ˆæœºåˆ¶ï¼Œä»¥ç¡®ä¿æœºå™¨äººèƒ½å¤Ÿåœ¨æ¯æ¬¡è¯•éªŒä¸­ä¸æ–­è°ƒæ•´å’Œä¼˜åŒ–å…¶è¿åŠ¨ç­–ç•¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPrior Reinforceèƒ½å¤Ÿåœ¨å°‘äº10æ¬¡å°è¯•å†…æˆåŠŸå®ŒæˆæŠ•ç¯®ä»»åŠ¡ï¼Œè¾¾åˆ°äº†äººç±»æ°´å¹³çš„ç²¾åº¦ã€‚è¿™ä¸€æˆæœä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—å‡å°‘äº†è¯•éªŒæ¬¡æ•°ï¼Œæå‡äº†å­¦ä¹ æ•ˆç‡ï¼Œå±•ç¤ºäº†å…¶åœ¨åŠ¨æ€ä»»åŠ¡ä¸­çš„ä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ä½“è‚²è®­ç»ƒã€æœåŠ¡æœºå™¨äººã€æ•‘æ´ä»»åŠ¡ç­‰éœ€è¦é«˜ç²¾åº¦åŠ¨æ€æ“ä½œçš„åœºæ™¯ã€‚é€šè¿‡æé«˜æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„å­¦ä¹ æ•ˆç‡ï¼ŒPrior Reinforceæœ‰æœ›åœ¨å®é™…åº”ç”¨ä¸­æ˜¾è‘—æå‡æœºå™¨äººçš„æ“ä½œèƒ½åŠ›å’Œé€‚åº”æ€§ï¼Œæ¨åŠ¨æ™ºèƒ½æœºå™¨äººæŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Embodied robots nowadays can already handle many real-world manipulation tasks. However, certain other real-world tasks involving dynamic processes (e.g., shooting a basketball into a hoop) are highly agile and impose high precision requirements on the outcomes, presenting additional challenges for methods primarily designed for quasi-static manipulations. This leads to increased efforts in costly data collection, laborious reward design, or complex motion planning. Such tasks, however, are far less challenging for humans. Say a novice basketball player typically needs only about 10 attempts to make their first successful shot, by roughly imitating some motion priors and then iteratively adjusting their motion based on the past outcomes. Inspired by this human learning paradigm, we propose Prior Reinforce(P.R.), a simple and scalable approach which first learns a motion pattern from very few demonstrations, then iteratively refines its generated motions based on feedback of a few real-world trials, until reaching a specific goal. Experiments demonstrated that Prior Reinforce can learn and accomplish a wide range of goal-conditioned agile dynamic tasks with human-level precision and efficiency directly in real-world, such as throwing a basketball into the hoop in fewer than 10 trials. Project website:https://adap-robotics.github.io/.

