---
layout: default
title: RoboTAG: End-to-end Robot Configuration Estimation via Topological Alignment Graph
---

# RoboTAG: End-to-end Robot Configuration Estimation via Topological Alignment Graph

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.07717" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.07717v1</a>
  <a href="https://arxiv.org/pdf/2511.07717.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.07717v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.07717v1', 'RoboTAG: End-to-end Robot Configuration Estimation via Topological Alignment Graph')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yifan Liu, Fangneng Zhan, Wanhua Li, Haowen Sun, Katerina Fragkiadaki, Hanspeter Pfister

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-11

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**RoboTAGï¼šé€šè¿‡æ‹“æ‰‘å¯¹é½å›¾å®ç°ç«¯åˆ°ç«¯æœºå™¨äººé…ç½®ä¼°è®¡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `æœºå™¨äººä½å§¿ä¼°è®¡` `æ‹“æ‰‘å¯¹é½å›¾` `è‡ªç›‘ç£å­¦ä¹ ` `3Då…ˆéªŒ` `å•ç›®è§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æœºå™¨äººä½å§¿ä¼°è®¡æ–¹æ³•ä¾èµ–å¤§é‡æ ‡æ³¨æ•°æ®ï¼Œä¸”å°†3Dé—®é¢˜é™ç»´è‡³2Dï¼Œå¿½ç•¥äº†3Då…ˆéªŒä¿¡æ¯ï¼Œå¯¼è‡´æ³›åŒ–æ€§å·®ã€‚
2. RoboTAGé€šè¿‡å¼•å…¥3Dåˆ†æ”¯æ³¨å…¥3Då…ˆéªŒï¼Œå¹¶æ„å»º2Då’Œ3Dè¡¨ç¤ºçš„æ‹“æ‰‘å¯¹é½å›¾ï¼Œå®ç°è·¨åˆ†æ”¯ä¸€è‡´æ€§ç›‘ç£ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒRoboTAGåœ¨ä¸åŒæœºå™¨äººç±»å‹ä¸Šæœ‰æ•ˆï¼Œæ— éœ€æ ‡æ³¨å³å¯åˆ©ç”¨çœŸå®å›¾åƒè®­ç»ƒï¼Œç¼“è§£äº†æ•°æ®ç“¶é¢ˆã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä»å•ç›®RGBå›¾åƒä¼°è®¡æœºå™¨äººå§¿æ€æ˜¯æœºå™¨äººå’Œè®¡ç®—æœºè§†è§‰é¢†åŸŸçš„ä¸€é¡¹æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸åœ¨2Dè§†è§‰éª¨å¹²ç½‘ç»œä¹‹ä¸Šæ„å»ºç½‘ç»œï¼Œå¹¶ä¸”ä¸¥é‡ä¾èµ–äºå¸¦æ ‡ç­¾çš„æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œè€Œè¿™äº›æ•°æ®åœ¨å®é™…åœºæ™¯ä¸­é€šå¸¸å¾ˆç¨€ç¼ºï¼Œå¯¼è‡´äº†sim-to-realçš„å·®è·ã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•å°†åŸºäº3Dçš„é—®é¢˜ç®€åŒ–åˆ°2Dé¢†åŸŸï¼Œå¿½ç•¥äº†3Då…ˆéªŒçŸ¥è¯†ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†æœºå™¨äººæ‹“æ‰‘å¯¹é½å›¾ï¼ˆRoboTAGï¼‰ï¼Œå®ƒç»“åˆäº†ä¸€ä¸ª3Dåˆ†æ”¯æ¥æ³¨å…¥3Då…ˆéªŒï¼ŒåŒæ—¶å®ç°2Då’Œ3Dè¡¨ç¤ºçš„ååŒè¿›åŒ–ï¼Œä»è€Œå‡è½»äº†å¯¹æ ‡ç­¾çš„ä¾èµ–ã€‚å…·ä½“æ¥è¯´ï¼ŒRoboTAGç”±ä¸€ä¸ª3Dåˆ†æ”¯å’Œä¸€ä¸ª2Dåˆ†æ”¯ç»„æˆï¼Œå…¶ä¸­èŠ‚ç‚¹è¡¨ç¤ºç›¸æœºå’Œæœºå™¨äººç³»ç»Ÿçš„çŠ¶æ€ï¼Œè¾¹æ•è·è¿™äº›å˜é‡ä¹‹é—´çš„ä¾èµ–å…³ç³»æˆ–è¡¨ç¤ºå®ƒä»¬ä¹‹é—´çš„å¯¹é½å…³ç³»ã€‚ç„¶ååœ¨å›¾ä¸­å®šä¹‰é—­ç¯ï¼Œå¯ä»¥åœ¨åˆ†æ”¯ä¸Šåº”ç”¨ä¸€è‡´æ€§ç›‘ç£ã€‚è¿™ç§è®¾è®¡ä½¿æˆ‘ä»¬èƒ½å¤Ÿåˆ©ç”¨é‡å¤–å›¾åƒä½œä¸ºè®­ç»ƒæ•°æ®ï¼Œè€Œæ— éœ€æ³¨é‡Šã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å„ç§æœºå™¨äººç±»å‹ä¸­éƒ½æ˜¯æœ‰æ•ˆçš„ï¼Œçªå‡ºäº†å…¶å‡è½»æœºå™¨äººæ•°æ®ç“¶é¢ˆçš„æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ä»å•ç›®RGBå›¾åƒä¸­å‡†ç¡®ä¼°è®¡æœºå™¨äººä½å§¿çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äº2Dè§†è§‰ç‰¹å¾ï¼Œå¿½ç•¥äº†3Då‡ ä½•ä¿¡æ¯ï¼Œå¹¶ä¸”éœ€è¦å¤§é‡çš„æ ‡æ³¨æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œè¿™åœ¨å®é™…åº”ç”¨ä¸­éš¾ä»¥æ»¡è¶³ã€‚Sim-to-realçš„å·®è·ä¹Ÿæ˜¯ä¸€ä¸ªé‡è¦çš„æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ‹“æ‰‘å¯¹é½å›¾ï¼ˆTopological Alignment Graphï¼‰å°†2Dè§†è§‰ä¿¡æ¯å’Œ3Då‡ ä½•ä¿¡æ¯è¿›è¡Œèåˆï¼Œå¹¶åˆ©ç”¨è·¨åˆ†æ”¯çš„ä¸€è‡´æ€§çº¦æŸè¿›è¡Œè‡ªç›‘ç£å­¦ä¹ ã€‚é€šè¿‡å¼•å…¥3Dåˆ†æ”¯ï¼Œæ³¨å…¥3Då…ˆéªŒçŸ¥è¯†ï¼Œç¼“è§£å¯¹æ ‡æ³¨æ•°æ®çš„ä¾èµ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRoboTAGåŒ…å«ä¸€ä¸ª2Dåˆ†æ”¯å’Œä¸€ä¸ª3Dåˆ†æ”¯ã€‚2Dåˆ†æ”¯è´Ÿè´£æå–å›¾åƒçš„2Dç‰¹å¾ï¼Œ3Dåˆ†æ”¯è´Ÿè´£åˆ©ç”¨æœºå™¨äººæ¨¡å‹ç”Ÿæˆ3Dè¡¨ç¤ºã€‚æ‹“æ‰‘å¯¹é½å›¾å°†2Då’Œ3Dåˆ†æ”¯çš„ç‰¹å¾è¿›è¡Œå…³è”ï¼ŒèŠ‚ç‚¹è¡¨ç¤ºç›¸æœºå’Œæœºå™¨äººç³»ç»Ÿçš„çŠ¶æ€ï¼Œè¾¹è¡¨ç¤ºå˜é‡ä¹‹é—´çš„ä¾èµ–å…³ç³»æˆ–å¯¹é½å…³ç³»ã€‚é€šè¿‡åœ¨å›¾ä¸Šå®šä¹‰é—­ç¯ï¼Œå¯ä»¥æ–½åŠ è·¨åˆ†æ”¯çš„ä¸€è‡´æ€§ç›‘ç£ã€‚

**å…³é”®åˆ›æ–°**ï¼šRoboTAGçš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) å¼•å…¥3Dåˆ†æ”¯ï¼Œæ³¨å…¥3Då…ˆéªŒçŸ¥è¯†ï¼›2) æ„å»ºæ‹“æ‰‘å¯¹é½å›¾ï¼Œå®ç°2Då’Œ3Dç‰¹å¾çš„èåˆï¼›3) åˆ©ç”¨è·¨åˆ†æ”¯çš„ä¸€è‡´æ€§çº¦æŸè¿›è¡Œè‡ªç›‘ç£å­¦ä¹ ï¼Œå‡å°‘å¯¹æ ‡æ³¨æ•°æ®çš„ä¾èµ–ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒRoboTAGèƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨3Då‡ ä½•ä¿¡æ¯ï¼Œå¹¶ä¸”å…·æœ‰æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šæ‹“æ‰‘å¯¹é½å›¾çš„è®¾è®¡æ˜¯å…³é”®ã€‚èŠ‚ç‚¹è¡¨ç¤ºç›¸æœºå’Œæœºå™¨äººç³»ç»Ÿçš„çŠ¶æ€ï¼ˆä¾‹å¦‚ï¼Œå…³èŠ‚è§’åº¦ã€ç›¸æœºä½å§¿ï¼‰ï¼Œè¾¹è¡¨ç¤ºè¿™äº›çŠ¶æ€ä¹‹é—´çš„ä¾èµ–å…³ç³»æˆ–å¯¹é½å…³ç³»ã€‚é—­ç¯çš„è®¾è®¡å…è®¸åœ¨ä¸åŒåˆ†æ”¯ä¹‹é—´æ–½åŠ ä¸€è‡´æ€§çº¦æŸï¼Œä¾‹å¦‚ï¼Œ2Dåˆ†æ”¯é¢„æµ‹çš„æœºå™¨äººå…³èŠ‚è§’åº¦åº”è¯¥ä¸3Dåˆ†æ”¯é¢„æµ‹çš„å…³èŠ‚è§’åº¦ä¸€è‡´ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬2Dåˆ†æ”¯çš„é‡æ„æŸå¤±ã€3Dåˆ†æ”¯çš„é‡æ„æŸå¤±ä»¥åŠè·¨åˆ†æ”¯çš„ä¸€è‡´æ€§æŸå¤±ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡å®éªŒç»“æœè¡¨æ˜ï¼ŒRoboTAGåœ¨æœºå™¨äººä½å§¿ä¼°è®¡ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨æ— æ ‡æ³¨æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¹¶ä¸”åœ¨ä¸åŒæœºå™¨äººç±»å‹ä¸Šéƒ½è¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒRoboTAGèƒ½å¤Ÿæ›´å‡†ç¡®åœ°ä¼°è®¡æœºå™¨äººä½å§¿ï¼Œå¹¶ä¸”å¯¹å…‰ç…§ã€é®æŒ¡ç­‰å› ç´ å…·æœ‰æ›´å¼ºçš„é²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

RoboTAGå¯åº”ç”¨äºå„ç§æœºå™¨äººæ“ä½œä»»åŠ¡ï¼Œä¾‹å¦‚æœºå™¨äººæŠ“å–ã€è£…é…å’Œå¯¼èˆªã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿåˆ©ç”¨çœŸå®ä¸–ç•Œçš„æ— æ ‡æ³¨å›¾åƒè¿›è¡Œè®­ç»ƒï¼Œé™ä½äº†æ•°æ®é‡‡é›†å’Œæ ‡æ³¨çš„æˆæœ¬ï¼ŒåŠ é€Ÿäº†æœºå™¨äººæŠ€æœ¯çš„éƒ¨ç½²ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ‰©å±•åˆ°æ›´å¤æ‚çš„æœºå™¨äººç³»ç»Ÿå’Œç¯å¢ƒï¼Œå®ç°æ›´æ™ºèƒ½ã€æ›´è‡ªä¸»çš„æœºå™¨äººæ“ä½œã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Estimating robot pose from a monocular RGB image is a challenge in robotics and computer vision. Existing methods typically build networks on top of 2D visual backbones and depend heavily on labeled data for training, which is often scarce in real-world scenarios, causing a sim-to-real gap. Moreover, these approaches reduce the 3D-based problem to 2D domain, neglecting the 3D priors. To address these, we propose Robot Topological Alignment Graph (RoboTAG), which incorporates a 3D branch to inject 3D priors while enabling co-evolution of the 2D and 3D representations, alleviating the reliance on labels. Specifically, the RoboTAG consists of a 3D branch and a 2D branch, where nodes represent the states of the camera and robot system, and edges capture the dependencies between these variables or denote alignments between them. Closed loops are then defined in the graph, on which a consistency supervision across branches can be applied. This design allows us to utilize in-the-wild images as training data without annotations. Experimental results demonstrate that our method is effective across robot types, highlighting its potential to alleviate the data bottleneck in robotics.

