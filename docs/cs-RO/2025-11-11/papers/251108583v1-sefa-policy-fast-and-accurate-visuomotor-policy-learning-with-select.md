---
layout: default
title: SeFA-Policy: Fast and Accurate Visuomotor Policy Learning with Selective Flow Alignment
---

# SeFA-Policy: Fast and Accurate Visuomotor Policy Learning with Selective Flow Alignment

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.08583" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.08583v1</a>
  <a href="https://arxiv.org/pdf/2511.08583.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.08583v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.08583v1', 'SeFA-Policy: Fast and Accurate Visuomotor Policy Learning with Selective Flow Alignment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Rong Xue, Jiageng Mao, Mingtong Zhang, Yue Wang

**åˆ†ç±»**: cs.RO, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-11-11

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/RongXueZoe/SeFA)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSeFA-Policyï¼Œé€šè¿‡é€‰æ‹©æ€§æµå¯¹é½å®ç°å¿«é€Ÿå‡†ç¡®çš„è§†è§‰è¿åŠ¨ç­–ç•¥å­¦ä¹ **

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è§†è§‰è¿åŠ¨ç­–ç•¥å­¦ä¹ ` `æ¨¡ä»¿å­¦ä¹ ` `ä¿®æ­£æµ` `é€‰æ‹©æ€§æµå¯¹é½` `æœºå™¨äººæ“ä½œ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ä¿®æ­£æµæ–¹æ³•åœ¨è§†è§‰è¿åŠ¨ç­–ç•¥å­¦ä¹ ä¸­å­˜åœ¨åŠ¨ä½œæ¼‚ç§»é—®é¢˜ï¼Œå¯¼è‡´ç´¯ç§¯è¯¯å·®å’Œä»»åŠ¡æ‰§è¡Œä¸ç¨³å®šã€‚
2. SeFAé€šè¿‡é€‰æ‹©æ€§æµå¯¹é½ç­–ç•¥ï¼Œåˆ©ç”¨ä¸“å®¶æ¼”ç¤ºæ ¡æ­£ç”ŸæˆåŠ¨ä½œï¼Œæ¢å¤ä¸è§‚å¯Ÿçš„ä¸€è‡´æ€§ï¼ŒåŒæ—¶ä¿ç•™å¤šæ¨¡æ€ç‰¹æ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒSeFAåœ¨å‡†ç¡®æ€§ã€é²æ£’æ€§å’Œæ¨ç†é€Ÿåº¦æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæ¨ç†å»¶è¿Ÿé™ä½è¶…è¿‡98%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§é«˜æ•ˆä¸”å‡†ç¡®çš„è§†è§‰è¿åŠ¨ç­–ç•¥å­¦ä¹ æ¡†æ¶â€”â€”é€‰æ‹©æ€§æµå¯¹é½ï¼ˆSeFAï¼‰ã€‚é’ˆå¯¹ç°æœ‰ä¿®æ­£æµæ–¹æ³•åœ¨è§†è§‰è¿åŠ¨ç­–ç•¥å­¦ä¹ ä¸­ï¼Œå› è¿­ä»£è’¸é¦å¯¼è‡´ç”ŸæˆåŠ¨ä½œåç¦»çœŸå®åŠ¨ä½œï¼Œè¿›è€Œç´¯ç§¯è¯¯å·®å¹¶é€ æˆä»»åŠ¡æ‰§è¡Œä¸ç¨³å®šçš„é—®é¢˜ï¼ŒSeFAé‡‡ç”¨é€‰æ‹©æ€§æµå¯¹é½ç­–ç•¥ï¼Œåˆ©ç”¨ä¸“å®¶æ¼”ç¤ºæœ‰é€‰æ‹©åœ°æ ¡æ­£ç”ŸæˆåŠ¨ä½œï¼Œæ¢å¤ä¸è§‚å¯Ÿçš„ä¸€è‡´æ€§ï¼ŒåŒæ—¶ä¿ç•™å¤šæ¨¡æ€ç‰¹æ€§ã€‚è¿™ç§è®¾è®¡å¼•å…¥äº†ä¸€è‡´æ€§æ ¡æ­£æœºåˆ¶ï¼Œç¡®ä¿ç”ŸæˆåŠ¨ä½œä¸è§‚å¯Ÿå¯¹é½ï¼Œä¸”ä¸ç‰ºç‰²å•æ­¥æµæ¨ç†çš„æ•ˆç‡ã€‚åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ä¸–ç•Œçš„æ“ä½œä»»åŠ¡ä¸­è¿›è¡Œçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒSeFAç­–ç•¥è¶…è¶Šäº†æœ€å…ˆè¿›çš„åŸºäºæ‰©æ•£å’ŒåŸºäºæµçš„ç­–ç•¥ï¼Œå®ç°äº†å“è¶Šçš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ï¼ŒåŒæ—¶å°†æ¨ç†å»¶è¿Ÿé™ä½äº†98%ä»¥ä¸Šã€‚é€šè¿‡ç»Ÿä¸€ä¿®æ­£æµçš„æ•ˆç‡å’Œè§‚å¯Ÿä¸€è‡´çš„åŠ¨ä½œç”Ÿæˆï¼ŒSeFAä¸ºå®æ—¶è§†è§‰è¿åŠ¨ç­–ç•¥å­¦ä¹ æä¾›äº†ä¸€ä¸ªå¯æ‰©å±•ä¸”å¯é çš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰åŸºäºä¿®æ­£æµçš„è§†è§‰è¿åŠ¨ç­–ç•¥å­¦ä¹ æ–¹æ³•ï¼Œåœ¨ç»è¿‡å¤šæ¬¡è¿­ä»£è’¸é¦åï¼Œç”Ÿæˆçš„åŠ¨ä½œå¯èƒ½ä¼šåç¦»ä¸å½“å‰è§†è§‰è§‚å¯Ÿç›¸å¯¹åº”çš„çœŸå®åŠ¨ä½œï¼Œå¯¼è‡´ç´¯ç§¯è¯¯å·®ï¼Œæœ€ç»ˆå½±å“ä»»åŠ¡æ‰§è¡Œçš„ç¨³å®šæ€§ã€‚è¿™ç§åŠ¨ä½œæ¼‚ç§»é—®é¢˜æ˜¯ç°æœ‰æ–¹æ³•çš„ä¸»è¦ç—›ç‚¹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSeFAçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡é€‰æ‹©æ€§åœ°å¯¹é½ç”ŸæˆåŠ¨ä½œä¸ä¸“å®¶æ¼”ç¤ºï¼Œæ¥çº æ­£åŠ¨ä½œæ¼‚ç§»ï¼Œä¿æŒç”ŸæˆåŠ¨ä½œä¸è§†è§‰è§‚å¯Ÿä¹‹é—´çš„ä¸€è‡´æ€§ã€‚è¿™ç§é€‰æ‹©æ€§å¯¹é½ç­–ç•¥æ—¨åœ¨åˆ©ç”¨ä¸“å®¶çŸ¥è¯†æ¥æŒ‡å¯¼åŠ¨ä½œç”Ÿæˆï¼ŒåŒæ—¶é¿å…è¿‡åº¦çº¦æŸï¼Œä»è€Œä¿ç•™ç­–ç•¥çš„å¤šæ¨¡æ€ç‰¹æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSeFAæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼šé¦–å…ˆï¼Œåˆ©ç”¨ä¿®æ­£æµæ¨¡å‹ç”Ÿæˆåˆå§‹åŠ¨ä½œï¼›ç„¶åï¼Œé€šè¿‡é€‰æ‹©æ€§æµå¯¹é½æ¨¡å—ï¼Œæ ¹æ®ä¸“å®¶æ¼”ç¤ºå¯¹ç”Ÿæˆçš„åŠ¨ä½œè¿›è¡Œæ ¡æ­£ï¼Œä½¿å…¶ä¸å½“å‰è§†è§‰è§‚å¯Ÿæ›´åŠ ä¸€è‡´ï¼›æœ€åï¼Œå°†æ ¡æ­£åçš„åŠ¨ä½œä½œä¸ºç­–ç•¥çš„è¾“å‡ºã€‚æ•´ä¸ªæ¡†æ¶æ—¨åœ¨å®ç°é«˜æ•ˆä¸”å‡†ç¡®çš„è§†è§‰è¿åŠ¨ç­–ç•¥å­¦ä¹ ã€‚

**å…³é”®åˆ›æ–°**ï¼šSeFAçš„å…³é”®åˆ›æ–°åœ¨äºå…¶é€‰æ‹©æ€§æµå¯¹é½ç­–ç•¥ã€‚ä¸ä¼ ç»Ÿçš„ç›´æ¥æ¨¡ä»¿å­¦ä¹ æ–¹æ³•ä¸åŒï¼ŒSeFAä¸æ˜¯ç®€å•åœ°å¤åˆ¶ä¸“å®¶åŠ¨ä½œï¼Œè€Œæ˜¯æœ‰é€‰æ‹©åœ°åˆ©ç”¨ä¸“å®¶çŸ¥è¯†æ¥çº æ­£ç”ŸæˆåŠ¨ä½œï¼Œä»è€Œåœ¨ä¿æŒç­–ç•¥çµæ´»æ€§çš„åŒæ—¶ï¼Œç¡®ä¿åŠ¨ä½œä¸è§‚å¯Ÿçš„ä¸€è‡´æ€§ã€‚è¿™ç§é€‰æ‹©æ€§å¯¹é½ç­–ç•¥æ˜¯SeFAèƒ½å¤Ÿè¶…è¶Šç°æœ‰æ–¹æ³•çš„æ ¸å¿ƒåŸå› ã€‚

**å…³é”®è®¾è®¡**ï¼šSeFAçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1ï¼‰é€‰æ‹©æ€§æµå¯¹é½æ¨¡å—ï¼Œè¯¥æ¨¡å—æ ¹æ®ä¸€å®šçš„æ ‡å‡†ï¼ˆä¾‹å¦‚ï¼Œç”ŸæˆåŠ¨ä½œä¸ä¸“å®¶åŠ¨ä½œä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼‰æ¥å†³å®šæ˜¯å¦éœ€è¦å¯¹ç”ŸæˆåŠ¨ä½œè¿›è¡Œæ ¡æ­£ï¼›2ï¼‰æŸå¤±å‡½æ•°çš„è®¾è®¡ï¼ŒæŸå¤±å‡½æ•°æ—¨åœ¨å¹³è¡¡åŠ¨ä½œçš„å‡†ç¡®æ€§å’Œç­–ç•¥çš„å¤šæ¨¡æ€æ€§ï¼Œé¿å…è¿‡åº¦æ‹Ÿåˆä¸“å®¶æ•°æ®ï¼›3ï¼‰ç½‘ç»œç»“æ„çš„è®¾è®¡ï¼Œç½‘ç»œç»“æ„éœ€è¦èƒ½å¤Ÿæœ‰æ•ˆåœ°æå–è§†è§‰ç‰¹å¾ï¼Œå¹¶ç”Ÿæˆé«˜è´¨é‡çš„åŠ¨ä½œã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

SeFA-Policyåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ä¸–ç•Œçš„æ“ä½œä»»åŠ¡ä¸­å‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSeFAè¶…è¶Šäº†æœ€å…ˆè¿›çš„åŸºäºæ‰©æ•£å’ŒåŸºäºæµçš„ç­–ç•¥ï¼Œå®ç°äº†æ›´é«˜çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚æ›´é‡è¦çš„æ˜¯ï¼ŒSeFAå°†æ¨ç†å»¶è¿Ÿé™ä½äº†98%ä»¥ä¸Šï¼Œä½¿å…¶æ›´é€‚ç”¨äºå®æ—¶æ§åˆ¶åº”ç”¨ã€‚ä¾‹å¦‚ï¼Œåœ¨æŸé¡¹æŠ“å–ä»»åŠ¡ä¸­ï¼ŒSeFAçš„æˆåŠŸç‡æ¯”ç°æœ‰æœ€ä½³æ–¹æ³•æé«˜äº†15%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SeFA-Policyåœ¨æœºå™¨äººæ“ä½œé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚è‡ªåŠ¨åŒ–è£…é…ã€ç‰©ä½“æŠ“å–ã€å®¶åº­æœåŠ¡æœºå™¨äººç­‰ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿæ˜¾è‘—æé«˜æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„æ“ä½œèƒ½åŠ›å’Œé²æ£’æ€§ï¼Œé™ä½éƒ¨ç½²æˆæœ¬ï¼Œå¹¶åŠ é€Ÿæœºå™¨äººæŠ€æœ¯çš„æ™®åŠã€‚æœªæ¥ï¼ŒSeFAæœ‰æœ›åº”ç”¨äºæ›´å¤šéœ€è¦å®æ—¶è§†è§‰åé¦ˆçš„æ§åˆ¶ä»»åŠ¡ä¸­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Developing efficient and accurate visuomotor policies poses a central challenge in robotic imitation learning. While recent rectified flow approaches have advanced visuomotor policy learning, they suffer from a key limitation: After iterative distillation, generated actions may deviate from the ground-truth actions corresponding to the current visual observation, leading to accumulated error as the reflow process repeats and unstable task execution. We present Selective Flow Alignment (SeFA), an efficient and accurate visuomotor policy learning framework. SeFA resolves this challenge by a selective flow alignment strategy, which leverages expert demonstrations to selectively correct generated actions and restore consistency with observations, while preserving multimodality. This design introduces a consistency correction mechanism that ensures generated actions remain observation-aligned without sacrificing the efficiency of one-step flow inference. Extensive experiments across both simulated and real-world manipulation tasks show that SeFA Policy surpasses state-of-the-art diffusion-based and flow-based policies, achieving superior accuracy and robustness while reducing inference latency by over 98%. By unifying rectified flow efficiency with observation-consistent action generation, SeFA provides a scalable and dependable solution for real-time visuomotor policy learning. Code is available on https://github.com/RongXueZoe/SeFA.

