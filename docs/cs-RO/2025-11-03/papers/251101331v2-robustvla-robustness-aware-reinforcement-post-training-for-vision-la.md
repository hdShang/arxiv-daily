---
layout: default
title: "RobustVLA: Robustness-Aware Reinforcement Post-Training for Vision-Language-Action Models"
---

# RobustVLA: Robustness-Aware Reinforcement Post-Training for Vision-Language-Action Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.01331" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.01331v2</a>
  <a href="https://arxiv.org/pdf/2511.01331.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.01331v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.01331v2', 'RobustVLA: Robustness-Aware Reinforcement Post-Training for Vision-Language-Action Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hongyin Zhang, Shuo Zhang, Junxi Jin, Qixin Zeng, Runze Li, Donglin Wang

**åˆ†ç±»**: cs.RO, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-11-03 (æ›´æ–°: 2025-12-01)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**RobustVLAï¼šé¢å‘è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹çš„é²æ£’æ€§å¼ºåŒ–åè®­ç»ƒ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹` `å¼ºåŒ–å­¦ä¹ ` `é²æ£’æ€§` `åè®­ç»ƒ` `é›…å¯æ¯”æ­£åˆ™åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰VLAæ¨¡å‹åœ¨å®é™…æœºå™¨äººéƒ¨ç½²ä¸­ï¼Œé¢å¯¹è§‚æµ‹å™ªå£°å’ŒåŠ¨ä½œæ‰°åŠ¨ç­‰é—®é¢˜æ—¶ï¼Œæ³›åŒ–èƒ½åŠ›ä¸è¶³ï¼Œé²æ£’æ€§è¾ƒå·®ã€‚
2. RobustVLAé€šè¿‡åœ¨çº¿å¼ºåŒ–å­¦ä¹ åè®­ç»ƒï¼Œæ˜¾å¼åœ°æå‡VLAæ¨¡å‹å¯¹ç¯å¢ƒä¸ç¡®å®šæ€§çš„é²æ£’æ€§ï¼Œæ ¸å¿ƒåœ¨äºé›…å¯æ¯”æ­£åˆ™åŒ–å’Œå¹³æ»‘æ€§æ­£åˆ™åŒ–ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒRobustVLAåœ¨å¤šç§æœºå™¨äººç¯å¢ƒä¸­æ˜¾è‘—æå‡äº†VLAæ¨¡å‹çš„é²æ£’æ€§å’Œå¯é æ€§ï¼Œä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€-åŠ¨ä½œ(VLA)æ¨¡å‹å—ç›Šäºå¤§è§„æ¨¡å¤šæ¨¡æ€é¢„è®­ç»ƒï¼Œå·²æˆä¸ºæœºå™¨äººæ“ä½œé¢†åŸŸå¼ºå¤§çš„é€šç”¨ç­–ç•¥ã€‚ç„¶è€Œï¼Œåœ¨åˆ†å¸ƒå¤–çš„éƒ¨ç½²ä¸­ï¼Œç”±äºä¸å¯é¿å…çš„æ‰°åŠ¨ï¼ˆå¦‚è§‚æµ‹å™ªå£°ã€ä¼ æ„Ÿå™¨è¯¯å·®æˆ–æ‰§è¡Œæ‰°åŠ¨ï¼‰æ™®éå­˜åœ¨ï¼Œå®ƒä»¬é€šå¸¸æ— æ³•å¯é åœ°æ³›åŒ–ã€‚è™½ç„¶æœ€è¿‘åŸºäºå¼ºåŒ–å­¦ä¹ (RL)çš„åè®­ç»ƒä¸ºè°ƒæ•´é¢„è®­ç»ƒVLAæ¨¡å‹æä¾›äº†ä¸€ç§å®ç”¨é€”å¾„ï¼Œä½†ç°æœ‰æ–¹æ³•ä¸»è¦å¼ºè°ƒå¥–åŠ±æœ€å¤§åŒ–ï¼Œè€Œå¿½ç•¥äº†å¯¹ç¯å¢ƒä¸ç¡®å®šæ€§çš„é²æ£’æ€§ã€‚æœ¬æ–‡æå‡ºäº†RobustVLAï¼Œä¸€ç§è½»é‡çº§çš„åœ¨çº¿RLåè®­ç»ƒæ–¹æ³•ï¼Œæ—¨åœ¨æ˜¾å¼åœ°å¢å¼ºVLAæ¨¡å‹çš„é²æ£’æ€§ã€‚é€šè¿‡ç³»ç»Ÿçš„é²æ£’æ€§åˆ†æï¼Œæˆ‘ä»¬ç¡®å®šäº†ä¸¤ä¸ªå…³é”®çš„æ­£åˆ™åŒ–é¡¹ï¼šé›…å¯æ¯”æ­£åˆ™åŒ–ï¼Œç”¨äºå‡è½»å¯¹è§‚æµ‹å™ªå£°çš„æ•æ„Ÿæ€§ï¼›å¹³æ»‘æ€§æ­£åˆ™åŒ–ï¼Œç”¨äºç¨³å®šåŠ¨ä½œæ‰°åŠ¨ä¸‹çš„ç­–ç•¥ã€‚åœ¨å„ç§æœºå™¨äººç¯å¢ƒä¸­çš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒRobustVLAåœ¨é²æ£’æ€§å’Œå¯é æ€§æ–¹é¢æ˜¾è‘—ä¼˜äºå…ˆå‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚æˆ‘ä»¬çš„ç»“æœå¼ºè°ƒäº†ä»¥åŸåˆ™æ€§çš„é²æ£’æ€§ä¸ºå¯¼å‘çš„RLåè®­ç»ƒä½œä¸ºæé«˜VLAæ¨¡å‹å¯é æ€§å’Œé²æ£’æ€§çš„å…³é”®æ­¥éª¤çš„é‡è¦æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šVLAæ¨¡å‹åœ¨å®é™…æœºå™¨äººæ“ä½œä¸­ï¼Œå®¹æ˜“å—åˆ°è§‚æµ‹å™ªå£°ã€ä¼ æ„Ÿå™¨è¯¯å·®å’ŒåŠ¨ä½œæ‰°åŠ¨ç­‰å› ç´ çš„å½±å“ï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ç”šè‡³å¤±æ•ˆã€‚ç°æœ‰åŸºäºå¼ºåŒ–å­¦ä¹ çš„åè®­ç»ƒæ–¹æ³•ä¸»è¦å…³æ³¨å¥–åŠ±æœ€å¤§åŒ–ï¼Œå¿½ç•¥äº†å¯¹ç¯å¢ƒä¸ç¡®å®šæ€§çš„é²æ£’æ€§ï¼Œæ— æ³•æœ‰æ•ˆè§£å†³è¿™ä¸€é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šRobustVLAçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼ºåŒ–å­¦ä¹ åè®­ç»ƒï¼Œæ˜¾å¼åœ°æå‡VLAæ¨¡å‹å¯¹ç¯å¢ƒä¸ç¡®å®šæ€§çš„é²æ£’æ€§ã€‚å…·ä½“æ¥è¯´ï¼Œé€šè¿‡å¼•å…¥é›…å¯æ¯”æ­£åˆ™åŒ–å’Œå¹³æ»‘æ€§æ­£åˆ™åŒ–ï¼Œåˆ†åˆ«é™ä½æ¨¡å‹å¯¹è§‚æµ‹å™ªå£°çš„æ•æ„Ÿæ€§å’Œç¨³å®šåŠ¨ä½œæ‰°åŠ¨ä¸‹çš„ç­–ç•¥ã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨ä½¿æ¨¡å‹åœ¨é¢å¯¹å„ç§æ‰°åŠ¨æ—¶ï¼Œä»èƒ½ä¿æŒè¾ƒå¥½çš„æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRobustVLAé‡‡ç”¨åœ¨çº¿å¼ºåŒ–å­¦ä¹ æ¡†æ¶è¿›è¡Œåè®­ç»ƒã€‚è¯¥æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) VLAæ¨¡å‹ï¼šä½œä¸ºç­–ç•¥ç½‘ç»œï¼Œæ¥æ”¶è§†è§‰å’Œè¯­è¨€è¾“å…¥ï¼Œè¾“å‡ºåŠ¨ä½œæŒ‡ä»¤ã€‚2) å¼ºåŒ–å­¦ä¹ ç¯å¢ƒï¼šæ¨¡æ‹ŸçœŸå®çš„æœºå™¨äººæ“ä½œç¯å¢ƒï¼ŒåŒ…æ‹¬å„ç§æ‰°åŠ¨ã€‚3) å¥–åŠ±å‡½æ•°ï¼šç”¨äºè¯„ä¼°VLAæ¨¡å‹çš„æ€§èƒ½ã€‚4) é›…å¯æ¯”æ­£åˆ™åŒ–æ¨¡å—ï¼šè®¡ç®—ç­–ç•¥ç½‘ç»œè¾“å‡ºå¯¹è¾“å…¥çš„é›…å¯æ¯”çŸ©é˜µï¼Œå¹¶è¿›è¡Œæ­£åˆ™åŒ–ã€‚5) å¹³æ»‘æ€§æ­£åˆ™åŒ–æ¨¡å—ï¼šå¯¹è¿ç»­æ—¶åˆ»çš„åŠ¨ä½œè¾“å‡ºè¿›è¡Œå¹³æ»‘æ€§çº¦æŸã€‚

**å…³é”®åˆ›æ–°**ï¼šRobustVLAçš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸¤ç§æ–°çš„æ­£åˆ™åŒ–æ–¹æ³•ï¼šé›…å¯æ¯”æ­£åˆ™åŒ–å’Œå¹³æ»‘æ€§æ­£åˆ™åŒ–ã€‚é›…å¯æ¯”æ­£åˆ™åŒ–é€šè¿‡çº¦æŸç­–ç•¥ç½‘ç»œè¾“å‡ºå¯¹è¾“å…¥çš„æ•æ„Ÿæ€§ï¼Œé™ä½äº†æ¨¡å‹å¯¹è§‚æµ‹å™ªå£°çš„ä¾èµ–ã€‚å¹³æ»‘æ€§æ­£åˆ™åŒ–é€šè¿‡çº¦æŸè¿ç»­æ—¶åˆ»çš„åŠ¨ä½œè¾“å‡ºï¼Œç¨³å®šäº†åŠ¨ä½œæ‰°åŠ¨ä¸‹çš„ç­–ç•¥ã€‚è¿™ä¸¤ç§æ­£åˆ™åŒ–æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°æå‡VLAæ¨¡å‹çš„é²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šé›…å¯æ¯”æ­£åˆ™åŒ–æŸå¤±å‡½æ•°ä¸ºç­–ç•¥ç½‘ç»œè¾“å‡ºå¯¹è¾“å…¥çš„é›…å¯æ¯”çŸ©é˜µçš„FrobeniusèŒƒæ•°ã€‚å¹³æ»‘æ€§æ­£åˆ™åŒ–æŸå¤±å‡½æ•°ä¸ºè¿ç»­æ—¶åˆ»åŠ¨ä½œè¾“å‡ºçš„å·®çš„å¹³æ–¹ã€‚è¿™ä¸¤ä¸ªæŸå¤±å‡½æ•°ä¸å¥–åŠ±å‡½æ•°ç»“åˆï¼Œå…±åŒä¼˜åŒ–VLAæ¨¡å‹ã€‚å…·ä½“å‚æ•°è®¾ç½®ï¼ˆå¦‚æ­£åˆ™åŒ–ç³»æ•°ï¼‰éœ€è¦æ ¹æ®å…·ä½“ä»»åŠ¡è¿›è¡Œè°ƒæ•´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒRobustVLAåœ¨å¤šä¸ªæœºå™¨äººæ“ä½œç¯å¢ƒä¸­æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨å­˜åœ¨è§‚æµ‹å™ªå£°å’ŒåŠ¨ä½œæ‰°åŠ¨çš„ç¯å¢ƒä¸­ï¼ŒRobustVLAçš„æˆåŠŸç‡æ¯”åŸºçº¿æ–¹æ³•æé«˜äº†15%-20%ã€‚æ­¤å¤–ï¼ŒRobustVLAè¿˜è¡¨ç°å‡ºæ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œèƒ½å¤Ÿåœ¨æœªè§è¿‡çš„ç¯å¢ƒä¸­ä¿æŒè¾ƒé«˜çš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

RobustVLAå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯ç”¨äºæå‡å„ç§æœºå™¨äººæ“ä½œä»»åŠ¡çš„å¯é æ€§å’Œé²æ£’æ€§ï¼Œä¾‹å¦‚ï¼šå·¥ä¸šè‡ªåŠ¨åŒ–ã€å®¶åº­æœåŠ¡æœºå™¨äººã€åŒ»ç–—æœºå™¨äººç­‰ã€‚é€šè¿‡æé«˜VLAæ¨¡å‹åœ¨å¤æ‚ç¯å¢ƒä¸­çš„é€‚åº”èƒ½åŠ›ï¼Œå¯ä»¥é™ä½éƒ¨ç½²æˆæœ¬ï¼Œæé«˜å·¥ä½œæ•ˆç‡ï¼Œå¹¶æ‰©å±•æœºå™¨äººçš„åº”ç”¨èŒƒå›´ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½åˆ¶é€ ç­‰é¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision-Language-Action (VLA) models have recently emerged as powerful general-purpose policies for robotic manipulation, benefiting from large-scale multi-modal pre-training. However, they often fail to generalize reliably in out-of-distribution deployments, where unavoidable disturbances such as observation noise, sensor errors, or actuation perturbations become prevalent. While recent Reinforcement Learning (RL)-based post-training provides a practical means to adapt pre-trained VLA models, existing methods mainly emphasize reward maximization and overlook robustness to environmental uncertainty. In this work, we introduce RobustVLA, a lightweight online RL post-training method designed to explicitly enhance the resilience of VLA models. Through a systematic robustness analysis, we identify two key regularizations: Jacobian regularization, which mitigates sensitivity to observation noise, and smoothness regularization, which stabilizes policies under action perturbations. Extensive experiments across diverse robotic environments demonstrate that RobustVLA significantly outperforms prior state-of-the-art methods in robustness and reliability. Our results highlight the importance of principled robustness-aware RL post-training as a key step toward improving the reliability and robustness of VLA models.

