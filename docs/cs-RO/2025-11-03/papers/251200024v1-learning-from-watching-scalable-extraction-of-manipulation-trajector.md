---
layout: default
title: Learning from Watching: Scalable Extraction of Manipulation Trajectories from Human Videos
---

# Learning from Watching: Scalable Extraction of Manipulation Trajectories from Human Videos

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.00024" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.00024v1</a>
  <a href="https://arxiv.org/pdf/2512.00024.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.00024v1" onclick="toggleFavorite(this, '2512.00024v1', 'Learning from Watching: Scalable Extraction of Manipulation Trajectories from Human Videos')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: X. Hu, G. Ye

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-03

**å¤‡æ³¨**: Accepted to RSS 2025 Workshop

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§åŸºäºè§†é¢‘ç†è§£å’Œç‚¹è¿½è¸ªçš„æ“çºµè½¨è¿¹æå–æ–¹æ³•ï¼Œç”¨äºä»äººç±»è§†é¢‘ä¸­å­¦ä¹ **

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `æœºå™¨äººå­¦ä¹ ` `æ¨¡ä»¿å­¦ä¹ ` `è§†é¢‘ç†è§£` `ç‚¹è¿½è¸ª` `æ“çºµè½¨è¿¹æå–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æœºå™¨äººå­¦ä¹ æ–¹æ³•ä¾èµ–æ˜‚è´µçš„æœºå™¨äººå¹³å°å’Œäººå·¥æ ‡æ³¨ï¼Œé™åˆ¶äº†æ•°æ®è§„æ¨¡ã€‚
2. è¯¥æ–¹æ³•ç»“åˆè§†é¢‘ç†è§£æ¨¡å‹å’Œç‚¹è¿½è¸ªæŠ€æœ¯ï¼Œä»äººç±»æ“çºµè§†é¢‘ä¸­æå–å…³é”®ç‚¹è½¨è¿¹ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å‡†ç¡®è¿½è¸ªå…³é”®ç‚¹ï¼Œä¸ºæœºå™¨äººå­¦ä¹ æä¾›å¤§è§„æ¨¡æ•°æ®ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸ºäº†è®­ç»ƒå¤§è§„æ¨¡æœºå™¨äººæ¨¡å‹ï¼Œæ”¶é›†é«˜è´¨é‡æ•°æ®é€šå¸¸ä¾èµ–äºçœŸå®çš„æœºå™¨äººå¹³å°ï¼Œæ— è®ºæ˜¯é¥æ“ä½œè¿˜æ˜¯è„šæœ¬æ¼”ç¤ºï¼Œè¿™éƒ½éå¸¸è€—æ—¶ä¸”æˆæœ¬é«˜æ˜‚ã€‚ä¸ºäº†æ‰©å±•æ•°æ®æ”¶é›†ï¼Œè®¸å¤šç ”ç©¶äººå‘˜è½¬å‘åˆ©ç”¨åœ¨çº¿å¯è·å¾—çš„äººç±»æ“çºµè§†é¢‘ã€‚ç„¶è€Œï¼Œç›®å‰çš„æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨æ‰‹éƒ¨æ£€æµ‹æˆ–ç‰©ä½“å§¿æ€ä¼°è®¡ä¸Šï¼Œæœªèƒ½å……åˆ†åˆ©ç”¨è¿™äº›è§†é¢‘ä¸­è•´å«çš„ä¸°å¯Œäº¤äº’çº¿ç´¢ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ç»“åˆäº†ç”¨äºè§†é¢‘ç†è§£çš„å¤§å‹åŸºç¡€æ¨¡å‹å’Œç‚¹è¿½è¸ªæŠ€æœ¯ï¼Œä»¥æå–æ“çºµè¿‡ç¨‹ä¸­æ‰€æœ‰ä»»åŠ¡ç›¸å…³å…³é”®ç‚¹çš„å¯†é›†è½¨è¿¹ã€‚è¿™ä½¿å¾—èƒ½å¤Ÿæ›´å…¨é¢åœ°åˆ©ç”¨äº’è”ç½‘è§„æ¨¡çš„äººç±»æ¼”ç¤ºè§†é¢‘ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥å‡†ç¡®åœ°è·Ÿè¸ªæ•´ä¸ªæ“çºµè¿‡ç¨‹ä¸­çš„å…³é”®ç‚¹ï¼Œä¸ºæ›´å…·å¯æ‰©å±•æ€§å’Œæ•°æ®æ•ˆç‡çš„æœºå™¨äººå­¦ä¹ é“ºå¹³äº†é“è·¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æœºå™¨äººå­¦ä¹ çš„æ•°æ®æ”¶é›†æ–¹æ³•ï¼Œå¦‚é¥æ“ä½œå’Œè„šæœ¬æ¼”ç¤ºï¼Œæˆæœ¬é«˜æ˜‚ä¸”éš¾ä»¥æ‰©å±•ã€‚è™½ç„¶å¯ä»¥åˆ©ç”¨äº’è”ç½‘ä¸Šçš„äººç±»æ“çºµè§†é¢‘ï¼Œä½†ç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­äºæ‰‹éƒ¨æ£€æµ‹æˆ–ç‰©ä½“å§¿æ€ä¼°è®¡ï¼Œæ— æ³•å……åˆ†åˆ©ç”¨è§†é¢‘ä¸­è•´å«çš„ä¸°å¯Œäº¤äº’ä¿¡æ¯ï¼Œä¾‹å¦‚å…³é”®ç‚¹çš„è¿åŠ¨è½¨è¿¹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè¯¥è®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§å‹è§†é¢‘ç†è§£æ¨¡å‹æ¥è¯†åˆ«è§†é¢‘ä¸­çš„å…³é”®ç‚¹ï¼Œå¹¶ä½¿ç”¨ç‚¹è¿½è¸ªæŠ€æœ¯æ¥è·Ÿè¸ªè¿™äº›å…³é”®ç‚¹åœ¨æ•´ä¸ªæ“çºµè¿‡ç¨‹ä¸­çš„è¿åŠ¨è½¨è¿¹ã€‚é€šè¿‡æå–è¿™äº›å¯†é›†çš„å…³é”®ç‚¹è½¨è¿¹ï¼Œå¯ä»¥æ›´å…¨é¢åœ°ç†è§£äººç±»çš„æ“çºµè¡Œä¸ºï¼Œä»è€Œä¸ºæœºå™¨äººå­¦ä¹ æä¾›æ›´ä¸°å¯Œçš„æ•°æ®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…å«ä¸¤ä¸ªé˜¶æ®µï¼šé¦–å…ˆï¼Œä½¿ç”¨å¤§å‹è§†é¢‘ç†è§£æ¨¡å‹ï¼ˆå…·ä½“æ¨¡å‹æœªçŸ¥ï¼‰æ¥æ£€æµ‹å’Œè¯†åˆ«è§†é¢‘ä¸­çš„å…³é”®ç‚¹ã€‚è¿™äº›å…³é”®ç‚¹æ˜¯ä¸æ“çºµä»»åŠ¡ç›¸å…³çš„ï¼Œä¾‹å¦‚ç‰©ä½“ä¸Šçš„ç‰¹å®šä½ç½®æˆ–æ‰‹éƒ¨çš„å…³èŠ‚ã€‚å…¶æ¬¡ï¼Œä½¿ç”¨ç‚¹è¿½è¸ªæŠ€æœ¯æ¥è·Ÿè¸ªè¿™äº›å…³é”®ç‚¹åœ¨è§†é¢‘å¸§ä¹‹é—´çš„è¿åŠ¨è½¨è¿¹ã€‚é€šè¿‡è¿æ¥è¿™äº›è½¨è¿¹ï¼Œå¯ä»¥è·å¾—å…³é”®ç‚¹åœ¨æ•´ä¸ªæ“çºµè¿‡ç¨‹ä¸­çš„å¯†é›†è¿åŠ¨ä¿¡æ¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå°†å¤§å‹è§†é¢‘ç†è§£æ¨¡å‹ä¸ç‚¹è¿½è¸ªæŠ€æœ¯ç›¸ç»“åˆï¼Œä»è€Œèƒ½å¤Ÿä»äººç±»æ“çºµè§†é¢‘ä¸­æå–å‡ºå¯†é›†çš„å…³é”®ç‚¹è½¨è¿¹ã€‚è¿™ä¸ç°æœ‰æ–¹æ³•åªå…³æ³¨æ‰‹éƒ¨æ£€æµ‹æˆ–ç‰©ä½“å§¿æ€ä¼°è®¡å½¢æˆäº†é²œæ˜å¯¹æ¯”ï¼Œèƒ½å¤Ÿæ›´å…¨é¢åœ°åˆ©ç”¨è§†é¢‘ä¸­çš„ä¿¡æ¯ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­æ²¡æœ‰è¯¦ç»†è¯´æ˜å…³é”®å‚æ•°è®¾ç½®ã€æŸå¤±å‡½æ•°æˆ–ç½‘ç»œç»“æ„ç­‰æŠ€æœ¯ç»†èŠ‚ã€‚ä½†æ˜¯ï¼Œå¯ä»¥æ¨æµ‹ï¼Œè§†é¢‘ç†è§£æ¨¡å‹çš„é€‰æ‹©å’Œè®­ç»ƒï¼Œä»¥åŠç‚¹è¿½è¸ªç®—æ³•çš„é€‰æ‹©å’Œå‚æ•°è°ƒæ•´ï¼Œéƒ½ä¼šå¯¹æœ€ç»ˆçš„è½¨è¿¹æå–æ•ˆæœäº§ç”Ÿé‡è¦å½±å“ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„æœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿå‡†ç¡®åœ°è·Ÿè¸ªæ•´ä¸ªæ“çºµè¿‡ç¨‹ä¸­çš„å…³é”®ç‚¹ã€‚è™½ç„¶è®ºæ–‡ä¸­æ²¡æœ‰æä¾›å…·ä½“çš„æ€§èƒ½æ•°æ®æˆ–å¯¹æ¯”åŸºçº¿ï¼Œä½†å¼ºè°ƒäº†è¯¥æ–¹æ³•ä¸ºæ›´å…·å¯æ‰©å±•æ€§å’Œæ•°æ®æ•ˆç‡çš„æœºå™¨äººå­¦ä¹ é“ºå¹³äº†é“è·¯ã€‚å…·ä½“çš„æå‡å¹…åº¦æœªçŸ¥ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæœºå™¨äººæ¨¡ä»¿å­¦ä¹ ã€æœºå™¨äººæŠ€èƒ½å­¦ä¹ ã€äººæœºåä½œç­‰é¢†åŸŸã€‚é€šè¿‡ä»å¤§é‡äººç±»æ“çºµè§†é¢‘ä¸­å­¦ä¹ ï¼Œæœºå™¨äººå¯ä»¥æ›´é«˜æ•ˆåœ°æŒæ¡å„ç§æ“ä½œæŠ€èƒ½ï¼Œä»è€Œé™ä½æœºå™¨äººå¼€å‘çš„æˆæœ¬å’Œæ—¶é—´ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºåˆ†æäººç±»è¡Œä¸ºï¼Œä¾‹å¦‚è¿åŠ¨åˆ†æå’Œåº·å¤è®­ç»ƒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Collecting high-quality data for training large-scale robotic models typically relies on real robot platforms, which is labor-intensive and costly, whether via teleoperation or scripted demonstrations. To scale data collection, many researchers have turned to leveraging human manipulation videos available online. However, current methods predominantly focus on hand detection or object pose estimation, failing to fully exploit the rich interaction cues embedded in these videos. In this work, we propose a novel approach that combines large foundation models for video understanding with point tracking techniques to extract dense trajectories of all task-relevant keypoints during manipulation. This enables more comprehensive utilization of Internet-scale human demonstration videos. Experimental results demonstrate that our method can accurately track keypoints throughout the entire manipulation process, paving the way for more scalable and data-efficient robot learning.

