---
layout: default
title: "AERMANI-VLM: Structured Prompting and Reasoning for Aerial Manipulation with Vision Language Models"
---

# AERMANI-VLM: Structured Prompting and Reasoning for Aerial Manipulation with Vision Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.01472" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.01472v1</a>
  <a href="https://arxiv.org/pdf/2511.01472.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.01472v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.01472v1', 'AERMANI-VLM: Structured Prompting and Reasoning for Aerial Manipulation with Vision Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sarthak Mishra, Rishabh Dev Yadav, Avirup Das, Saksham Gupta, Wei Pan, Spandan Roy

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-11-03

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**AERMANI-VLMï¼šåŸºäºç»“æ„åŒ–æç¤ºå’Œæ¨ç†çš„è§†è§‰è¯­è¨€æ¨¡å‹åœ¨æ— äººæœºæ“ä½œä¸­çš„åº”ç”¨**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡å‹` `æ— äººæœºæ“ä½œ` `ç»“æ„åŒ–æç¤º` `æœºå™¨äººæ§åˆ¶` `é«˜çº§æ¨ç†` `ä½çº§æ§åˆ¶` `å®‰å…¨æŠ€èƒ½` `å¤šæ­¥éª¤ä»»åŠ¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰VLMç›´æ¥åº”ç”¨äºæ— äººæœºæ“ä½œæ—¶ï¼Œå­˜åœ¨åŠ¨ä½œä¸ä¸€è‡´ã€æ˜“äº§ç”Ÿå¹»è§‰ä»¥åŠåŠ¨æ€å¯è¡Œæ€§å·®ç­‰é—®é¢˜ï¼Œå¯¼è‡´ä¸å®‰å…¨å’Œä¸å¯é ã€‚
2. AERMANI-VLMé€šè¿‡ç»“æ„åŒ–æç¤ºå¼•å¯¼VLMç”Ÿæˆæ¨ç†è½¨è¿¹ï¼Œå¹¶ä»ä¸­é€‰æ‹©é¢„å®šä¹‰çš„é£è¡Œå®‰å…¨æŠ€èƒ½ï¼Œå®ç°é«˜çº§æ¨ç†ä¸ä½çº§æ§åˆ¶åˆ†ç¦»ã€‚
3. è¯¥æ¡†æ¶åœ¨æ¨¡æ‹Ÿå’Œç¡¬ä»¶å®éªŒä¸­ï¼Œå¯¹æœªè§è¿‡çš„å‘½ä»¤ã€å¯¹è±¡å’Œç¯å¢ƒè¡¨ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼ŒéªŒè¯äº†å…¶åœ¨å¤šæ­¥éª¤æ‹¾å–å’Œæ”¾ç½®ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰çš„å¿«é€Ÿå‘å±•æ¿€å‘äº†äººä»¬å¯¹æœºå™¨äººæ§åˆ¶çš„å…´è¶£ï¼Œå…¶ä¸­è‡ªç„¶è¯­è¨€å¯ä»¥è¡¨è¾¾æ“ä½œç›®æ ‡ï¼Œè€Œè§†è§‰åé¦ˆå°†æ„ŸçŸ¥ä¸åŠ¨ä½œè”ç³»èµ·æ¥ã€‚ç„¶è€Œï¼Œç›´æ¥åœ¨æ— äººæœºæ“ä½œå™¨ä¸Šéƒ¨ç½²VLMé©±åŠ¨çš„ç­–ç•¥ä»ç„¶ä¸å®‰å…¨ä¸”ä¸å¯é ï¼Œå› ä¸ºç”Ÿæˆçš„åŠ¨ä½œé€šå¸¸ä¸ä¸€è‡´ï¼Œå®¹æ˜“äº§ç”Ÿå¹»è§‰ï¼Œå¹¶ä¸”åœ¨åŠ¨æ€ä¸Šå¯¹äºé£è¡Œæ˜¯ä¸å¯è¡Œçš„ã€‚æœ¬æ–‡æå‡ºäº†AERMANI-VLMï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªé€šè¿‡å°†é«˜çº§æ¨ç†ä¸ä½çº§æ§åˆ¶åˆ†ç¦»æ¥è°ƒæ•´é¢„è®­ç»ƒVLMä»¥è¿›è¡Œæ— äººæœºæ“ä½œçš„æ¡†æ¶ï¼Œæ— éœ€ä»»ä½•ç‰¹å®šäºä»»åŠ¡çš„å¾®è°ƒã€‚æˆ‘ä»¬çš„æ¡†æ¶å°†è‡ªç„¶è¯­è¨€æŒ‡ä»¤ã€ä»»åŠ¡ä¸Šä¸‹æ–‡å’Œå®‰å…¨çº¦æŸç¼–ç ä¸ºç»“æ„åŒ–æç¤ºï¼Œå¼•å¯¼æ¨¡å‹ç”Ÿæˆè‡ªç„¶è¯­è¨€çš„é€æ­¥æ¨ç†è½¨è¿¹ã€‚æ­¤æ¨ç†è¾“å‡ºç”¨äºä»é¢„å®šä¹‰çš„ç¦»æ•£ã€é£è¡Œå®‰å…¨æŠ€èƒ½åº“ä¸­è¿›è¡Œé€‰æ‹©ï¼Œä»è€Œç¡®ä¿å¯è§£é‡Šä¸”æ—¶é—´ä¸Šä¸€è‡´çš„æ‰§è¡Œã€‚é€šè¿‡å°†ç¬¦å·æ¨ç†ä¸ç‰©ç†åŠ¨ä½œåˆ†ç¦»ï¼ŒAERMANI-VLMå‡è½»äº†å¹»è§‰å‘½ä»¤å¹¶é˜²æ­¢äº†ä¸å®‰å…¨è¡Œä¸ºï¼Œä»è€Œå®ç°äº†ç¨³å¥çš„ä»»åŠ¡å®Œæˆã€‚æˆ‘ä»¬åœ¨æ¨¡æ‹Ÿå’Œç¡¬ä»¶ä¸­éªŒè¯äº†è¯¥æ¡†æ¶åœ¨å„ç§å¤šæ­¥éª¤æ‹¾å–å’Œæ”¾ç½®ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ï¼Œå±•ç¤ºäº†å¯¹å…ˆå‰æœªè§è¿‡çš„å‘½ä»¤ã€å¯¹è±¡å’Œç¯å¢ƒçš„å¼ºå¤§æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å°†è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ç›´æ¥åº”ç”¨äºæ— äººæœºæ“ä½œæ—¶å­˜åœ¨çš„å®‰å…¨æ€§ä¸å¯é æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ç”Ÿæˆçš„åŠ¨ä½œå¸¸å¸¸ä¸ä¸€è‡´ï¼Œå®¹æ˜“äº§ç”Ÿå¹»è§‰ï¼Œå¹¶ä¸”åœ¨åŠ¨æ€ä¸Šå¯¹äºæ— äººæœºé£è¡Œæ˜¯ä¸å¯è¡Œçš„ï¼Œå¯¼è‡´ä»»åŠ¡æ‰§è¡Œå¤±è´¥ç”šè‡³å®‰å…¨äº‹æ•…ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†é«˜çº§æ¨ç†ä¸ä½çº§æ§åˆ¶è§£è€¦ã€‚é€šè¿‡ç»“æ„åŒ–çš„æç¤ºï¼ˆPromptingï¼‰å¼•å¯¼VLMè¿›è¡Œç¬¦å·æ¨ç†ï¼Œç”Ÿæˆå¯è§£é‡Šçš„æ­¥éª¤åºåˆ—ï¼Œç„¶åå°†è¿™äº›æ­¥éª¤æ˜ å°„åˆ°é¢„å®šä¹‰çš„ã€é£è¡Œå®‰å…¨çš„ç¦»æ•£æŠ€èƒ½åº“ä¸­çš„åŠ¨ä½œã€‚è¿™æ ·å¯ä»¥é¿å…VLMç›´æ¥ç”Ÿæˆä¸å¯é çš„æ§åˆ¶æŒ‡ä»¤ï¼Œä»è€Œæé«˜ç³»ç»Ÿçš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAERMANI-VLMæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) **ç»“æ„åŒ–æç¤ºæ¨¡å—**ï¼šå°†è‡ªç„¶è¯­è¨€æŒ‡ä»¤ã€ä»»åŠ¡ä¸Šä¸‹æ–‡å’Œå®‰å…¨çº¦æŸç¼–ç ä¸ºç»“æ„åŒ–æç¤ºã€‚2) **VLMæ¨ç†æ¨¡å—**ï¼šåˆ©ç”¨VLMå¯¹ç»“æ„åŒ–æç¤ºè¿›è¡Œæ¨ç†ï¼Œç”Ÿæˆè‡ªç„¶è¯­è¨€çš„æ­¥éª¤åºåˆ—ã€‚3) **æŠ€èƒ½é€‰æ‹©æ¨¡å—**ï¼šå°†æ¨ç†å‡ºçš„æ­¥éª¤åºåˆ—æ˜ å°„åˆ°é¢„å®šä¹‰çš„ç¦»æ•£æŠ€èƒ½åº“ä¸­çš„åŠ¨ä½œã€‚4) **ä½çº§æ§åˆ¶æ¨¡å—**ï¼šæ‰§è¡Œé€‰å®šçš„åŠ¨ä½œï¼Œå®Œæˆä»»åŠ¡ã€‚æ•´ä¸ªæµç¨‹å®ç°äº†ä»è‡ªç„¶è¯­è¨€æŒ‡ä»¤åˆ°å®‰å…¨å¯é çš„æ— äººæœºæ“ä½œçš„è½¬æ¢ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†å°†VLMåº”ç”¨äºæ— äººæœºæ“ä½œçš„ç»“æ„åŒ–æç¤ºæ–¹æ³•ï¼Œæœ‰æ•ˆå¼•å¯¼VLMè¿›è¡Œæ¨ç†ã€‚2) å°†é«˜çº§æ¨ç†ä¸ä½çº§æ§åˆ¶è§£è€¦ï¼Œé¿å…äº†VLMç›´æ¥ç”Ÿæˆä¸å¯é çš„æ§åˆ¶æŒ‡ä»¤ã€‚3) ä½¿ç”¨é¢„å®šä¹‰çš„é£è¡Œå®‰å…¨æŠ€èƒ½åº“ï¼Œä¿è¯äº†æ— äººæœºæ“ä½œçš„å®‰å…¨æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šç»“æ„åŒ–æç¤ºçš„è®¾è®¡æ˜¯å…³é”®ã€‚æç¤ºä¸­åŒ…å«äº†è‡ªç„¶è¯­è¨€æŒ‡ä»¤ã€ä»»åŠ¡ä¸Šä¸‹æ–‡ï¼ˆä¾‹å¦‚ï¼Œå½“å‰åœºæ™¯çš„è§†è§‰ä¿¡æ¯ï¼‰å’Œå®‰å…¨çº¦æŸï¼ˆä¾‹å¦‚ï¼Œé¿å…ç¢°æ’ï¼‰ã€‚VLMé‡‡ç”¨é¢„è®­ç»ƒçš„é€šç”¨VLMï¼Œæ— éœ€é’ˆå¯¹ç‰¹å®šä»»åŠ¡è¿›è¡Œå¾®è°ƒã€‚æŠ€èƒ½åº“ä¸­çš„æ¯ä¸ªæŠ€èƒ½éƒ½ç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œä»¥ç¡®ä¿é£è¡Œå®‰å…¨å’Œä»»åŠ¡çš„æœ‰æ•ˆæ‰§è¡Œã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥ç ”ç©¶åœ¨æ¨¡æ‹Ÿå’Œç¡¬ä»¶å®éªŒä¸­éªŒè¯äº†AERMANI-VLMçš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶èƒ½å¤ŸæˆåŠŸå®Œæˆå„ç§å¤šæ­¥éª¤æ‹¾å–å’Œæ”¾ç½®ä»»åŠ¡ï¼Œå¹¶ä¸”å¯¹å…ˆå‰æœªè§è¿‡çš„å‘½ä»¤ã€å¯¹è±¡å’Œç¯å¢ƒå…·æœ‰å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚ä¸ç›´æ¥ä½¿ç”¨VLMæ§åˆ¶æ— äººæœºçš„æ–¹æ³•ç›¸æ¯”ï¼ŒAERMANI-VLMæ˜¾è‘—æé«˜äº†ä»»åŠ¡å®Œæˆçš„æˆåŠŸç‡å’Œå®‰å…¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

AERMANI-VLMå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚åœ¨ç‰©æµé…é€ã€ç¾å®³æ•‘æ´ã€åŸºç¡€è®¾æ–½å·¡æ£€ç­‰é¢†åŸŸï¼Œå¯ä»¥é€šè¿‡è‡ªç„¶è¯­è¨€æŒ‡ä»¤æ§åˆ¶æ— äººæœºå®Œæˆå¤æ‚çš„ä»»åŠ¡ã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºæ¨åŠ¨æ— äººæœºæ™ºèƒ½åŒ–å‘å±•ï¼Œæé«˜æ— äººæœºæ“ä½œçš„æ•ˆç‡å’Œå®‰å…¨æ€§ï¼Œå¹¶é™ä½æ“ä½œéš¾åº¦ï¼Œä½¿å¾—éä¸“ä¸šäººå‘˜ä¹Ÿèƒ½è½»æ¾æ“æ§æ— äººæœºã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The rapid progress of vision--language models (VLMs) has sparked growing interest in robotic control, where natural language can express the operation goals while visual feedback links perception to action. However, directly deploying VLM-driven policies on aerial manipulators remains unsafe and unreliable since the generated actions are often inconsistent, hallucination-prone, and dynamically infeasible for flight. In this work, we present AERMANI-VLM, the first framework to adapt pretrained VLMs for aerial manipulation by separating high-level reasoning from low-level control, without any task-specific fine-tuning. Our framework encodes natural language instructions, task context, and safety constraints into a structured prompt that guides the model to generate a step-by-step reasoning trace in natural language. This reasoning output is used to select from a predefined library of discrete, flight-safe skills, ensuring interpretable and temporally consistent execution. By decoupling symbolic reasoning from physical action, AERMANI-VLM mitigates hallucinated commands and prevents unsafe behavior, enabling robust task completion. We validate the framework in both simulation and hardware on diverse multi-step pick-and-place tasks, demonstrating strong generalization to previously unseen commands, objects, and environments.

