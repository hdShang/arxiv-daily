---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-05-20
---

# cs.ROï¼ˆ2025-05-20ï¼‰

ğŸ“Š å…± **19** ç¯‡è®ºæ–‡
 | ğŸ”— **3** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (14 ğŸ”—2)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (2)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (2)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1 ğŸ”—1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (14 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250514819v1-dora-object-affordance-guided-reinforcement-learning-for-dexterous-r.html">DORA: Object Affordance-Guided Reinforcement Learning for Dexterous Robotic Manipulation</a></td>
  <td>æå‡ºåŸºäºç‰©ä½“å¯ä¾›æ€§æŒ‡å¯¼çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ä»¥è§£å†³çµå·§æœºå™¨äººæ“ä½œé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">reinforcement learning</span> <span class="paper-tag">affordance</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14819v1" data-paper-url="./papers/250514819v1-dora-object-affordance-guided-reinforcement-learning-for-dexterous-r.html" onclick="toggleFavorite(this, '2505.14819v1', 'DORA: Object Affordance-Guided Reinforcement Learning for Dexterous Robotic Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250514266v1-sampling-based-system-identification-with-active-exploration-for-leg.html">Sampling-Based System Identification with Active Exploration for Legged Robot Sim2Real Learning</a></td>
  <td>æå‡ºSPI-Activeä»¥è§£å†³è…¿éƒ¨æœºå™¨äººSim2Realå­¦ä¹ é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">legged robot</span> <span class="paper-tag">locomotion</span> <span class="paper-tag">sim-to-real</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14266v1" data-paper-url="./papers/250514266v1-sampling-based-system-identification-with-active-exploration-for-leg.html" onclick="toggleFavorite(this, '2505.14266v1', 'Sampling-Based System Identification with Active Exploration for Legged Robot Sim2Real Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250513925v2-time-reversal-symmetry-for-efficient-robotic-manipulations-in-deep-r.html">Time Reversal Symmetry for Efficient Robotic Manipulations in Deep Reinforcement Learning</a></td>
  <td>æå‡ºæ—¶é—´åè½¬å¯¹ç§°æ€§ä»¥æé«˜æ·±åº¦å¼ºåŒ–å­¦ä¹ ä¸­çš„æœºå™¨äººæ“ä½œæ•ˆç‡</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">reinforcement learning</span> <span class="paper-tag">deep reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13925v2" data-paper-url="./papers/250513925v2-time-reversal-symmetry-for-efficient-robotic-manipulations-in-deep-r.html" onclick="toggleFavorite(this, '2505.13925v2', 'Time Reversal Symmetry for Efficient Robotic Manipulations in Deep Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250513834v2-toward-real-world-cooperative-and-competitive-soccer-with-quadrupeda.html">Toward Real-World Cooperative and Competitive Soccer with Quadrupedal Robot Teams</a></td>
  <td>æå‡ºå±‚æ¬¡åŒ–å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ æ¡†æ¶ä»¥å®ç°å››è¶³æœºå™¨äººè¶³çƒæ¯”èµ›</td>
  <td class="tags-cell"><span class="paper-tag">quadruped</span> <span class="paper-tag">legged robot</span> <span class="paper-tag">legged locomotion</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13834v2" data-paper-url="./papers/250513834v2-toward-real-world-cooperative-and-competitive-soccer-with-quadrupeda.html" onclick="toggleFavorite(this, '2505.13834v2', 'Toward Real-World Cooperative and Competitive Soccer with Quadrupedal Robot Teams')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250514030v3-autobio-a-simulation-and-benchmark-for-robotic-automation-in-digital.html">AutoBio: A Simulation and Benchmark for Robotic Automation in Digital Biology Laboratory</a></td>
  <td>æå‡ºAutoBioä»¥è§£å†³ç”Ÿç‰©å®éªŒå®¤æœºå™¨äººè‡ªåŠ¨åŒ–è¯„ä¼°é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">vision-language-action</span> <span class="paper-tag">VLA</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14030v3" data-paper-url="./papers/250514030v3-autobio-a-simulation-and-benchmark-for-robotic-automation-in-digital.html" onclick="toggleFavorite(this, '2505.14030v3', 'AutoBio: A Simulation and Benchmark for Robotic Automation in Digital Biology Laboratory')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250514938v1-scan-materialize-simulate-a-generalizable-framework-for-physically-g.html">Scan, Materialize, Simulate: A Generalizable Framework for Physically Grounded Robot Planning</a></td>
  <td>æå‡ºSMSæ¡†æ¶ä»¥è§£å†³æœºå™¨äººè§„åˆ’ä¸­çš„ç‰©ç†æ¨ç†é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">3D gaussian splatting</span> <span class="paper-tag">gaussian splatting</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14938v1" data-paper-url="./papers/250514938v1-scan-materialize-simulate-a-generalizable-framework-for-physically-g.html" onclick="toggleFavorite(this, '2505.14938v1', 'Scan, Materialize, Simulate: A Generalizable Framework for Physically Grounded Robot Planning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250513982v2-adaptive-visuo-tactile-fusion-with-predictive-force-attention-for-de.html">Adaptive Visuo-Tactile Fusion with Predictive Force Attention for Dexterous Manipulation</a></td>
  <td>æå‡ºè‡ªé€‚åº”è§†è§‰-è§¦è§‰èåˆæ–¹æ³•ä»¥è§£å†³å¤šæ¨¡æ€æ•°æ®èåˆæŒ‘æˆ˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">dexterous manipulation</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13982v2" data-paper-url="./papers/250513982v2-adaptive-visuo-tactile-fusion-with-predictive-force-attention-for-de.html" onclick="toggleFavorite(this, '2505.13982v2', 'Adaptive Visuo-Tactile Fusion with Predictive Force Attention for Dexterous Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250514443v1-semantically-driven-deep-reinforcement-learning-for-inspection-path-.html">Semantically-driven Deep Reinforcement Learning for Inspection Path Planning</a></td>
  <td>æå‡ºè¯­ä¹‰é©±åŠ¨çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ ä»¥è§£å†³æ£€æµ‹è·¯å¾„è§„åˆ’é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">sim2real</span> <span class="paper-tag">reinforcement learning</span> <span class="paper-tag">deep reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14443v1" data-paper-url="./papers/250514443v1-semantically-driven-deep-reinforcement-learning-for-inspection-path-.html" onclick="toggleFavorite(this, '2505.14443v1', 'Semantically-driven Deep Reinforcement Learning for Inspection Path Planning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250513931v2-sketch-interface-for-teleoperation-of-mobile-manipulator-to-enable-i.html">Sketch Interface for Teleoperation of Mobile Manipulator to Enable Intuitive and Intended Operation: A Proof of Concept</a></td>
  <td>æå‡ºè‰å›¾æ¥å£ä»¥è§£å†³ç§»åŠ¨æ“æ§ä¸­çš„ç›´è§‚æ“ä½œé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">mobile manipulation</span> <span class="paper-tag">teleoperation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13931v2" data-paper-url="./papers/250513931v2-sketch-interface-for-teleoperation-of-mobile-manipulator-to-enable-i.html" onclick="toggleFavorite(this, '2505.13931v2', 'Sketch Interface for Teleoperation of Mobile Manipulator to Enable Intuitive and Intended Operation: A Proof of Concept')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250513889v1-certifiably-safe-manipulation-of-deformable-linear-objects-via-joint.html">Certifiably Safe Manipulation of Deformable Linear Objects via Joint Shape and Tension Prediction</a></td>
  <td>æå‡ºä¸€ç§è”åˆå½¢çŠ¶ä¸å¼ åŠ›é¢„æµ‹çš„å®‰å…¨æ“æ§æ¡†æ¶ä»¥è§£å†³å¯å˜å½¢çº¿æ€§ç‰©ä½“æ“æ§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">motion planning</span> <span class="paper-tag">predictive model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13889v1" data-paper-url="./papers/250513889v1-certifiably-safe-manipulation-of-deformable-linear-objects-via-joint.html" onclick="toggleFavorite(this, '2505.13889v1', 'Certifiably Safe Manipulation of Deformable Linear Objects via Joint Shape and Tension Prediction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250514486v2-robust-immersive-bilateral-teleoperation-of-beyond-human-scale-syste.html">Robust Immersive Bilateral Teleoperation of Beyond-Human-Scale Systems with Enhanced Transparency and Sense of Embodiment</a></td>
  <td>æå‡ºåŒå‘é¥æ“ä½œæ¡†æ¶ä»¥å¢å¼ºè¶…äººè§„æ¨¡ç³»ç»Ÿçš„é€æ˜åº¦ä¸èº«ä½“æ„ŸçŸ¥</td>
  <td class="tags-cell"><span class="paper-tag">teleoperation</span> <span class="paper-tag">motion tracking</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14486v2" data-paper-url="./papers/250514486v2-robust-immersive-bilateral-teleoperation-of-beyond-human-scale-syste.html" onclick="toggleFavorite(this, '2505.14486v2', 'Robust Immersive Bilateral Teleoperation of Beyond-Human-Scale Systems with Enhanced Transparency and Sense of Embodiment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250514526v2-roboran-a-unified-robotics-framework-for-reinforcement-learning-base.html">RoboRAN: A Unified Robotics Framework for Reinforcement Learning-Based Autonomous Navigation</a></td>
  <td>æå‡ºRoboRANæ¡†æ¶ä»¥è§£å†³å¤šé¢†åŸŸè‡ªä¸»å¯¼èˆªé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">sim-to-real</span> <span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14526v2" data-paper-url="./papers/250514526v2-roboran-a-unified-robotics-framework-for-reinforcement-learning-base.html" onclick="toggleFavorite(this, '2505.14526v2', 'RoboRAN: A Unified Robotics Framework for Reinforcement Learning-Based Autonomous Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/250513836v1-duawlfin-a-drone-with-unified-actuation-for-wheeled-locomotion-and-f.html">Duawlfin: A Drone with Unified Actuation for Wheeled Locomotion and Flight Operation</a></td>
  <td>æå‡ºDuawlfinä»¥å®ç°é«˜æ•ˆçš„åŒå‘åœ°é¢ç§»åŠ¨å’Œé£è¡Œæ“ä½œ</td>
  <td class="tags-cell"><span class="paper-tag">locomotion</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13836v1" data-paper-url="./papers/250513836v1-duawlfin-a-drone-with-unified-actuation-for-wheeled-locomotion-and-f.html" onclick="toggleFavorite(this, '2505.13836v1', 'Duawlfin: A Drone with Unified Actuation for Wheeled Locomotion and Flight Operation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/250513959v1-multidrive-a-co-simulation-framework-bridging-2d-and-3d-driving-simu.html">MultiDrive: A Co-Simulation Framework Bridging 2D and 3D Driving Simulation for AV Software Validation</a></td>
  <td>æå‡ºMultiDriveæ¡†æ¶ä»¥è§£å†³AVè½¯ä»¶éªŒè¯ä¸­çš„2Dä¸3Dæ¨¡æ‹Ÿé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">sim-to-real</span> <span class="paper-tag">motion planning</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13959v1" data-paper-url="./papers/250513959v1-multidrive-a-co-simulation-framework-bridging-2d-and-3d-driving-simu.html" onclick="toggleFavorite(this, '2505.13959v1', 'MultiDrive: A Co-Simulation Framework Bridging 2D and 3D Driving Simulation for AV Software Validation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>15</td>
  <td><a href="./papers/250513888v3-inspire-vision-language-action-models-with-intrinsic-spatial-reasoni.html">InSpire: Vision-Language-Action Models with Intrinsic Spatial Reasoning</a></td>
  <td>æå‡ºInSpireä»¥è§£å†³è§†è§‰è¯­è¨€è¡ŒåŠ¨æ¨¡å‹çš„ç©ºé—´æ¨ç†é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">vision-language-action</span> <span class="paper-tag">VLA</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13888v3" data-paper-url="./papers/250513888v3-inspire-vision-language-action-models-with-intrinsic-spatial-reasoni.html" onclick="toggleFavorite(this, '2505.13888v3', 'InSpire: Vision-Language-Action Models with Intrinsic Spatial Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/250514899v2-think-reflect-create-metacognitive-learning-for-zero-shot-robotic-pl.html">Think, Reflect, Create: Metacognitive Learning for Zero-Shot Robotic Planning with LLMs</a></td>
  <td>æå‡ºå…ƒè®¤çŸ¥å­¦ä¹ æ¡†æ¶ä»¥æå‡é›¶-shotæœºå™¨äººè§„åˆ’èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14899v2" data-paper-url="./papers/250514899v2-think-reflect-create-metacognitive-learning-for-zero-shot-robotic-pl.html" onclick="toggleFavorite(this, '2505.14899v2', 'Think, Reflect, Create: Metacognitive Learning for Zero-Shot Robotic Planning with LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>17</td>
  <td><a href="./papers/250514859v1-a-hierarchical-graph-based-terrain-aware-autonomous-navigation-appro.html">A Hierarchical Graph-Based Terrain-Aware Autonomous Navigation Approach for Complementary Multimodal Ground-Aerial Exploration</a></td>
  <td>æå‡ºå±‚æ¬¡å›¾å½¢åŸºç¡€çš„åœ°å½¢æ„ŸçŸ¥è‡ªä¸»å¯¼èˆªæ–¹æ³•ä»¥è§£å†³å¤šæ¨¡æ€æ¢ç´¢é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">traversability</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14859v1" data-paper-url="./papers/250514859v1-a-hierarchical-graph-based-terrain-aware-autonomous-navigation-appro.html" onclick="toggleFavorite(this, '2505.14859v1', 'A Hierarchical Graph-Based Terrain-Aware Autonomous Navigation Approach for Complementary Multimodal Ground-Aerial Exploration')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/250514580v2-traversability-aware-path-planning-in-dynamic-environments.html">Traversability-aware path planning in dynamic environments</a></td>
  <td>æå‡ºTraversability-aware FMMä»¥è§£å†³åŠ¨æ€ç¯å¢ƒä¸­çš„è·¯å¾„è§„åˆ’é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">traversability</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2505.14580v2" data-paper-url="./papers/250514580v2-traversability-aware-path-planning-in-dynamic-environments.html" onclick="toggleFavorite(this, '2505.14580v2', 'Traversability-aware path planning in dynamic environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>19</td>
  <td><a href="./papers/250513921v2-apex-empowering-llms-with-physics-based-task-planning-for-real-time-.html">APEX: Empowering LLMs with Physics-Based Task Planning for Real-time Insight</a></td>
  <td>æå‡ºAPEXæ¡†æ¶ä»¥è§£å†³LLMsåœ¨ç‰©ç†äº¤äº’å»ºæ¨¡ä¸­çš„å±€é™æ€§</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2505.13921v2" data-paper-url="./papers/250513921v2-apex-empowering-llms-with-physics-based-task-planning-for-real-time-.html" onclick="toggleFavorite(this, '2505.13921v2', 'APEX: Empowering LLMs with Physics-Based Task Planning for Real-time Insight')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)