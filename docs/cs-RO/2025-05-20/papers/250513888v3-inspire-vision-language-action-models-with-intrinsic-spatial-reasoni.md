---
layout: default
title: "InSpire: Vision-Language-Action Models with Intrinsic Spatial Reasoning"
---

# InSpire: Vision-Language-Action Models with Intrinsic Spatial Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.13888" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.13888v3</a>
  <a href="https://arxiv.org/pdf/2505.13888.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.13888v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.13888v3', 'InSpire: Vision-Language-Action Models with Intrinsic Spatial Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ji Zhang, Shihan Wu, Xu Luo, Hao Wu, Lianli Gao, Heng Tao Shen, Jingkuan Song

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-05-20 (æ›´æ–°: 2025-09-29)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºInSpireä»¥è§£å†³è§†è§‰è¯­è¨€è¡ŒåŠ¨æ¨¡å‹çš„ç©ºé—´æ¨ç†é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡å‹` `ç©ºé—´æ¨ç†` `æœºå™¨äººæŠ€æœ¯` `å¤šæ¨¡æ€å­¦ä¹ ` `è‡ªå›å½’æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†è§‰è¯­è¨€è¡ŒåŠ¨æ¨¡å‹ï¼ˆVLAsï¼‰å®¹æ˜“å°†ä¸ä»»åŠ¡æ— å…³çš„è§†è§‰ç‰¹å¾ä¸åŠ¨ä½œé”™è¯¯å…³è”ï¼Œé™åˆ¶äº†å…¶æ³›åŒ–èƒ½åŠ›ã€‚
2. æœ¬æ–‡æå‡ºçš„å†…åœ¨ç©ºé—´æ¨ç†ï¼ˆInSpireï¼‰æ–¹æ³•ï¼Œé€šè¿‡å¼•å¯¼æ¨¡å‹å…³æ³¨ä»»åŠ¡ç›¸å…³å› ç´ ï¼Œå¢å¼ºäº†ç©ºé—´æ¨ç†èƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒInSpireåœ¨æ¨¡æ‹Ÿå’Œç°å®ç¯å¢ƒä¸­å‡æ˜¾è‘—æé«˜äº†æ¨¡å‹çš„æ€§èƒ½ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œçµæ´»æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶åˆ©ç”¨é¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰å°†è¯­è¨€æŒ‡ä»¤å’Œè§†è§‰è§‚å¯Ÿæ˜ å°„åˆ°ä½çº§åŠ¨ä½œï¼Œæå‡ºäº†è§†è§‰è¯­è¨€è¡ŒåŠ¨æ¨¡å‹ï¼ˆVLAsï¼‰ã€‚å°½ç®¡å·²æœ‰è¿›å±•ï¼Œç°æœ‰VLAså¾€å¾€å°†ä¸ä»»åŠ¡æ— å…³çš„è§†è§‰ç‰¹å¾ä¸åŠ¨ä½œé”™è¯¯å…³è”ï¼Œé™åˆ¶äº†å…¶åœ¨è®­ç»ƒæ•°æ®ä¹‹å¤–çš„æ³›åŒ–èƒ½åŠ›ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†å†…åœ¨ç©ºé—´æ¨ç†ï¼ˆInSpireï¼‰ï¼Œé€šè¿‡å¢å¼ºVLAsçš„ç©ºé—´æ¨ç†èƒ½åŠ›ï¼Œæœ‰æ•ˆå‡è½»äº†è™šå‡å…³è”çš„è´Ÿé¢å½±å“ã€‚InSpireé€šè¿‡åœ¨è¯­è¨€æŒ‡ä»¤å‰æ·»åŠ é—®é¢˜â€œ[ç‰©ä½“]ç›¸å¯¹äºæœºå™¨äººåœ¨ä»€ä¹ˆæ–¹å‘ï¼Ÿâ€æ¥å¼•å¯¼VLAçš„æ³¨æ„åŠ›ï¼Œå¹¶å°†ç­”æ¡ˆä¸çœŸå®åŠ¨ä½œå¯¹é½ã€‚InSpireå¯ä½œä¸ºæ’ä»¶å¢å¼ºç°æœ‰çš„è‡ªå›å½’VLAï¼Œæ— éœ€é¢å¤–è®­ç»ƒæ•°æ®æˆ–ä¸å…¶ä»–å¤§å‹æ¨¡å‹äº¤äº’ã€‚å¤§é‡å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ¨¡æ‹Ÿå’Œç°å®ç¯å¢ƒä¸­å‡è¡¨ç°å‡ºæœ‰æ•ˆæ€§å’Œçµæ´»æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰è§†è§‰è¯­è¨€è¡ŒåŠ¨æ¨¡å‹ï¼ˆVLAsï¼‰åœ¨ä»»åŠ¡æ‰§è¡Œä¸­å› è™šå‡å…³è”è€Œå¯¼è‡´çš„æ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€å°†æ— å…³çš„è§†è§‰ç‰¹å¾ä¸åŠ¨ä½œé”™è¯¯å…³è”ï¼Œå½±å“äº†æ¨¡å‹çš„å®é™…åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šInSpireé€šè¿‡åœ¨è¯­è¨€æŒ‡ä»¤å‰æ·»åŠ é—®é¢˜â€œ[ç‰©ä½“]ç›¸å¯¹äºæœºå™¨äººåœ¨ä»€ä¹ˆæ–¹å‘ï¼Ÿâ€æ¥å¼•å¯¼æ¨¡å‹çš„æ³¨æ„åŠ›ï¼Œä»è€Œå¢å¼ºå…¶ç©ºé—´æ¨ç†èƒ½åŠ›ï¼Œå‡å°‘è™šå‡å…³è”çš„å½±å“ã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°å…³æ³¨ä¸ä»»åŠ¡ç›¸å…³çš„å› ç´ ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šè¯­è¨€æŒ‡ä»¤å¤„ç†æ¨¡å—ã€è§†è§‰ç‰¹å¾æå–æ¨¡å—å’ŒåŠ¨ä½œé¢„æµ‹æ¨¡å—ã€‚é¦–å…ˆï¼Œæ¨¡å‹æ¥æ”¶è¯­è¨€æŒ‡ä»¤å¹¶æ·»åŠ ç©ºé—´æ¨ç†é—®é¢˜ï¼›ç„¶åï¼Œæå–è§†è§‰ç‰¹å¾å¹¶ä¸è¯­è¨€ä¿¡æ¯ç»“åˆï¼›æœ€åï¼Œé¢„æµ‹ç›¸åº”çš„ä½çº§åŠ¨ä½œã€‚

**å…³é”®åˆ›æ–°**ï¼šInSpireçš„æœ€å¤§åˆ›æ–°åœ¨äºé€šè¿‡å¼•å¯¼é—®é¢˜çš„æ–¹å¼å¢å¼ºäº†æ¨¡å‹çš„ç©ºé—´æ¨ç†èƒ½åŠ›ï¼Œè¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„ç›´æ¥æ˜ å°„æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå‡è½»è™šå‡å…³è”çš„å½±å“ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼ŒInSpireæ— éœ€é¢å¤–çš„è®­ç»ƒæ•°æ®ï¼Œä¸”å¯ä»¥ä½œä¸ºæ’ä»¶ä¸ç°æœ‰è‡ªå›å½’VLAç»“åˆã€‚æŸå¤±å‡½æ•°è®¾è®¡ä¸Šï¼Œæ¨¡å‹çš„è¾“å‡ºåŠ¨ä½œä¸çœŸå®åŠ¨ä½œè¿›è¡Œå¯¹é½ï¼Œç¡®ä¿äº†è®­ç»ƒè¿‡ç¨‹çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨InSpireçš„æ¨¡å‹åœ¨å¤šä¸ªä»»åŠ¡ä¸Šç›¸è¾ƒäºåŸºçº¿æ¨¡å‹çš„æ€§èƒ½æå‡æ˜¾è‘—ï¼Œå°¤å…¶åœ¨ç©ºé—´æ¨ç†ç›¸å…³çš„ä»»åŠ¡ä¸­ï¼Œå‡†ç¡®ç‡æé«˜äº†15%ä»¥ä¸Šï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œçµæ´»æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªä¸»æœºå™¨äººã€æ™ºèƒ½å®¶å±…ç³»ç»Ÿä»¥åŠäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æå‡è§†è§‰è¯­è¨€è¡ŒåŠ¨æ¨¡å‹çš„ç©ºé—´æ¨ç†èƒ½åŠ›ï¼ŒInSpireèƒ½å¤Ÿä½¿æœºå™¨äººæ›´å‡†ç¡®åœ°ç†è§£å’Œæ‰§è¡Œå¤æ‚çš„ä»»åŠ¡ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Leveraging pretrained Vision-Language Models (VLMs) to map language instruction and visual observations to raw low-level actions, Vision-Language-Action models (VLAs) hold great promise for achieving general-purpose robotic systems. Despite their advancements, existing VLAs tend to spuriously correlate task-irrelevant visual features with actions, limiting their generalization capacity beyond the training data. To tackle this challenge, we propose Intrinsic Spatial Reasoning (InSpire), a simple yet effective approach that mitigates the adverse effects of spurious correlations by boosting the spatial reasoning ability of VLAs. Specifically, InSpire redirects the VLA's attention to task-relevant factors by prepending the question "In which direction is the [object] relative to the robot?" to the language instruction and aligning the answer "right/left/up/down/front/back/grasped" and predicted actions with ground-truth. Notably, InSpire can be used as a plugin to enhance existing autoregressive VLAs, requiring no extra training data or interaction with other large models. Extensive experimental results in both simulation and real-world environments demonstrate the effectiveness and flexibility of our approach.

