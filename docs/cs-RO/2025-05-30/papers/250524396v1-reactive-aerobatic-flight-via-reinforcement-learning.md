---
layout: default
title: Reactive Aerobatic Flight via Reinforcement Learning
---

# Reactive Aerobatic Flight via Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.24396" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.24396v1</a>
  <a href="https://arxiv.org/pdf/2505.24396.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.24396v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.24396v1', 'Reactive Aerobatic Flight via Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhichao Han, Xijie Huang, Zhuxiu Xu, Jiarui Zhang, Yuze Wu, Mingyang Wang, Tianyue Wu, Fei Gao

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-05-30

**å¤‡æ³¨**: This work has been submitted to RAL and is under review

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå¼ºåŒ–å­¦ä¹ çš„æ¡†æ¶ä»¥å®ç°å››æ—‹ç¿¼çš„ååº”å¼ç‰¹æŠ€é£è¡Œ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `å››æ—‹ç¿¼æ— äººæœº` `ç‰¹æŠ€é£è¡Œ` `è‡ªåŠ¨åŒ–è¯¾ç¨‹å­¦ä¹ ` `é¢†åŸŸéšæœºåŒ–` `è‡ªä¸»å¯¼èˆª` `æ§åˆ¶ç­–ç•¥`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å››æ—‹ç¿¼çš„ç‰¹æŠ€é£è¡Œæ—¶å­˜åœ¨è·Ÿè¸ªä¸å‡†ç¡®å’Œè®¡ç®—å»¶è¿Ÿç­‰é—®é¢˜ï¼Œé™åˆ¶äº†å…¶åœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„åº”ç”¨ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ¡†æ¶ï¼Œç›´æ¥å°†æ— äººæœºçŠ¶æ€ä¸ç‰¹æŠ€æ„å›¾æ˜ å°„ä¸ºæ§åˆ¶æŒ‡ä»¤ï¼Œå®ç°ç«¯åˆ°ç«¯çš„ç­–ç•¥ä¼˜åŒ–ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨çœŸå®ç¯å¢ƒä¸­æˆåŠŸå®ç°äº†æ— äººæœºçš„è¿ç»­å€’é£ï¼Œå¹¶èƒ½ååº”æ€§åœ°ç©¿è¶Šç§»åŠ¨éšœç¢ï¼Œå±•ç°å‡ºæ˜¾è‘—çš„çµæ´»æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å››æ—‹ç¿¼æ— äººæœºå±•ç°å‡ºå“è¶Šçš„å¤šåŠŸèƒ½æ€§ï¼Œä½†ç”±äºå›ºæœ‰çš„æ¬ é©±åŠ¨ç‰¹æ€§å’Œæ¿€çƒˆæœºåŠ¨çš„å¤æ‚æ€§ï¼Œå…¶ç‰¹æŠ€é£è¡Œæ½œåŠ›å°šæœªå¾—åˆ°å……åˆ†å‘æŒ¥ã€‚ä¼ ç»Ÿæ–¹æ³•å°†è½¨è¿¹ä¼˜åŒ–ä¸è·Ÿè¸ªæ§åˆ¶åˆ†å¼€ï¼Œå¯¼è‡´è·Ÿè¸ªä¸å‡†ç¡®ã€è®¡ç®—å»¶è¿ŸåŠå¯¹åˆå§‹æ¡ä»¶æ•æ„Ÿï¼Œé™åˆ¶äº†å…¶åœ¨åŠ¨æ€é«˜çµæ´»åœºæ™¯ä¸­çš„æœ‰æ•ˆæ€§ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ¡†æ¶ï¼Œç›´æ¥å°†æ— äººæœºçŠ¶æ€ä¸ç‰¹æŠ€æ„å›¾æ˜ å°„ä¸ºæ§åˆ¶æŒ‡ä»¤ï¼Œæ¶ˆé™¤äº†æ¨¡å—åŒ–åˆ†ç¦»ï¼Œå®ç°äº†æç«¯ç‰¹æŠ€æœºåŠ¨çš„ç«¯åˆ°ç«¯ç­–ç•¥ä¼˜åŒ–ã€‚ä¸ºç¡®ä¿é«˜æ•ˆç¨³å®šçš„è®­ç»ƒï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§è‡ªåŠ¨åŒ–è¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼ŒåŠ¨æ€è°ƒæ•´ç‰¹æŠ€ä»»åŠ¡çš„éš¾åº¦ã€‚é€šè¿‡é¢†åŸŸéšæœºåŒ–å®ç°ç¨³å¥çš„é›¶-shot æ¨¡æ‹Ÿåˆ°ç°å®è½¬ç§»ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨è¦æ±‚è‹›åˆ»çš„çœŸå®ä¸–ç•Œå®éªŒä¸­å¾—åˆ°äº†éªŒè¯ï¼ŒåŒ…æ‹¬é¦–æ¬¡å±•ç¤ºæ— äººæœºè‡ªä¸»æ‰§è¡Œè¿ç»­å€’é£å¹¶ååº”æ€§åœ°ç©¿è¶Šç§»åŠ¨é—¨ï¼Œå±•ç°å‡ºå‰æ‰€æœªæœ‰çš„çµæ´»æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å››æ—‹ç¿¼æ— äººæœºåœ¨ç‰¹æŠ€é£è¡Œä¸­çš„æ§åˆ¶é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å› æ¨¡å—åŒ–åˆ†ç¦»å¯¼è‡´è·Ÿè¸ªä¸å‡†ç¡®å’Œè®¡ç®—å»¶è¿Ÿï¼Œéš¾ä»¥åº”å¯¹åŠ¨æ€ç¯å¢ƒä¸­çš„é«˜æœºåŠ¨æ€§éœ€æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºçš„æ¡†æ¶é€šè¿‡å¼ºåŒ–å­¦ä¹ ç›´æ¥å°†æ— äººæœºçš„çŠ¶æ€ä¸ç‰¹æŠ€é£è¡Œæ„å›¾æ˜ å°„ä¸ºæ§åˆ¶æŒ‡ä»¤ï¼Œæ¶ˆé™¤äº†ä¼ ç»Ÿæ–¹æ³•ä¸­çš„æ¨¡å—åŒ–åˆ†ç¦»ï¼Œä»è€Œå®ç°äº†æ›´é«˜æ•ˆçš„ç«¯åˆ°ç«¯ç­–ç•¥ä¼˜åŒ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬çŠ¶æ€æ„ŸçŸ¥æ¨¡å—ã€æ„å›¾ç”Ÿæˆæ¨¡å—å’Œæ§åˆ¶æŒ‡ä»¤è¾“å‡ºæ¨¡å—ã€‚çŠ¶æ€æ„ŸçŸ¥æ¨¡å—è´Ÿè´£å®æ—¶è·å–æ— äººæœºçš„é£è¡ŒçŠ¶æ€ï¼Œæ„å›¾ç”Ÿæˆæ¨¡å—åŸºäºå¼ºåŒ–å­¦ä¹ ç®—æ³•ç”Ÿæˆç‰¹æŠ€é£è¡Œæ„å›¾ï¼Œæ§åˆ¶æŒ‡ä»¤è¾“å‡ºæ¨¡å—åˆ™å°†æ„å›¾è½¬æ¢ä¸ºå…·ä½“çš„æ§åˆ¶å‘½ä»¤ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„ä¸»è¦åˆ›æ–°åœ¨äºå¼•å…¥äº†è‡ªåŠ¨åŒ–è¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼ŒåŠ¨æ€è°ƒæ•´ç‰¹æŠ€ä»»åŠ¡çš„éš¾åº¦ï¼Œä»¥ç¡®ä¿è®­ç»ƒçš„é«˜æ•ˆæ€§å’Œç¨³å®šæ€§ã€‚æ­¤å¤–ï¼Œé¢†åŸŸéšæœºåŒ–æŠ€æœ¯çš„åº”ç”¨ä½¿å¾—æ¨¡å‹åœ¨çœŸå®ç¯å¢ƒä¸­çš„é›¶-shot è½¬ç§»èƒ½åŠ›æ˜¾è‘—å¢å¼ºã€‚

**å…³é”®è®¾è®¡**ï¼šæˆ‘ä»¬åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è®¾ç½®äº†å¤šç§éš¾åº¦ç­‰çº§çš„ç‰¹æŠ€ä»»åŠ¡ï¼Œå¹¶ä½¿ç”¨äº†é€‚åº”æ€§æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ§åˆ¶ç­–ç•¥ã€‚ç½‘ç»œç»“æ„é‡‡ç”¨æ·±åº¦å¼ºåŒ–å­¦ä¹ æ¨¡å‹ï¼Œç»“åˆå·ç§¯ç¥ç»ç½‘ç»œä»¥å¤„ç†å¤æ‚çš„çŠ¶æ€è¾“å…¥ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œæ¶æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æå‡ºçš„æ–¹æ³•æˆåŠŸå®ç°äº†æ— äººæœºçš„è¿ç»­å€’é£ï¼Œå¹¶èƒ½å¤Ÿåœ¨ç§»åŠ¨éšœç¢ç‰©ä¹‹é—´è¿›è¡Œååº”æ€§å¯¼èˆªã€‚è¿™ä¸€æˆæœåœ¨çœŸå®ç¯å¢ƒä¸­é¦–æ¬¡å±•ç¤ºï¼Œæ ‡å¿—ç€æ— äººæœºåœ¨ç‰¹æŠ€é£è¡Œé¢†åŸŸçš„æ˜¾è‘—è¿›æ­¥ï¼Œæå‡å¹…åº¦æ˜æ˜¾ï¼Œå…·æœ‰é‡è¦çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ— äººæœºè¡¨æ¼”ã€æœç´¢ä¸æ•‘æ´ã€ä»¥åŠå¤æ‚ç¯å¢ƒä¸­çš„è‡ªä¸»å¯¼èˆªç­‰ã€‚é€šè¿‡æå‡æ— äººæœºåœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„æœºåŠ¨èƒ½åŠ›ï¼Œæœªæ¥å¯åœ¨å¤šç§å®é™…åœºæ™¯ä¸­å®ç°æ›´é«˜æ•ˆçš„ä»»åŠ¡æ‰§è¡Œï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Quadrotors have demonstrated remarkable versatility, yet their full aerobatic potential remains largely untapped due to inherent underactuation and the complexity of aggressive maneuvers. Traditional approaches, separating trajectory optimization and tracking control, suffer from tracking inaccuracies, computational latency, and sensitivity to initial conditions, limiting their effectiveness in dynamic, high-agility scenarios. Inspired by recent breakthroughs in data-driven methods, we propose a reinforcement learning-based framework that directly maps drone states and aerobatic intentions to control commands, eliminating modular separation to enable quadrotors to perform end-to-end policy optimization for extreme aerobatic maneuvers. To ensure efficient and stable training, we introduce an automated curriculum learning strategy that dynamically adjusts aerobatic task difficulty. Enabled by domain randomization for robust zero-shot sim-to-real transfer, our approach is validated in demanding real-world experiments, including the first demonstration of a drone autonomously performing continuous inverted flight while reactively navigating a moving gate, showcasing unprecedented agility.

