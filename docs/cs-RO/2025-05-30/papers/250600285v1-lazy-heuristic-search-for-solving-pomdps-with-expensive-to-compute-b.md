---
layout: default
title: Lazy Heuristic Search for Solving POMDPs with Expensive-to-Compute Belief Transitions
---

# Lazy Heuristic Search for Solving POMDPs with Expensive-to-Compute Belief Transitions

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.00285" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.00285v1</a>
  <a href="https://arxiv.org/pdf/2506.00285.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.00285v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.00285v1', 'Lazy Heuristic Search for Solving POMDPs with Expensive-to-Compute Belief Transitions')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Muhammad Suhail Saleem, Rishi Veerapaneni, Maxim Likhachev

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-05-30

**å¤‡æ³¨**: Accepted for publication at The 18th International Symposium on Combinatorial Search (SOCS 2025)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ‡’æƒ°å¯å‘å¼æœç´¢ä»¥è§£å†³POMDPsä¸­çš„è®¡ç®—å¤æ‚æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `éƒ¨åˆ†å¯è§‚æµ‹é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹` `å¯å‘å¼æœç´¢` `ä¿¡å¿µçŠ¶æ€è½¬ç§»` `Qå€¼ä¼°è®¡` `æœºå™¨äººå¯¼èˆª` `è§„åˆ’ç®—æ³•` `è®¡ç®—æ•ˆç‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤„ç†POMDPsæ—¶ï¼Œè®¡ç®—ä¿¡å¿µçŠ¶æ€è½¬ç§»çš„ä»£ä»·è¿‡é«˜ï¼Œå¯¼è‡´è§„åˆ’æ•ˆç‡ä½ä¸‹ã€‚
2. æœ¬æ–‡æå‡ºæ‡’æƒ°RTDP-Belå’Œæ‡’æƒ°LAO*ï¼Œé€šè¿‡Qå€¼ä¼°è®¡æ¨è¿Ÿæ˜‚è´µçš„ä¿¡å¿µçŠ¶æ€è½¬ç§»è®¡ç®—ï¼Œé™ä½è§„åˆ’æ—¶é—´ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‡’æƒ°è§„åˆ’å™¨åœ¨å¤šä¸ªåº”ç”¨åœºæ™¯ä¸­æ˜¾è‘—æé«˜äº†è§„åˆ’é€Ÿåº¦ï¼ŒåŒæ—¶ä¿æŒäº†è§£çš„è´¨é‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¯å‘å¼æœç´¢æ±‚è§£å™¨å¦‚RTDP-Belå’ŒLAO*åœ¨è®¡ç®—éƒ¨åˆ†å¯è§‚æµ‹é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆPOMDPsï¼‰çš„æœ€ä¼˜å’Œæœ‰ç•Œæ¬¡ä¼˜è§£æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚ç„¶è€Œï¼Œåœ¨æŸäº›æœºå™¨äººé¢†åŸŸï¼Œè®¡ç®—ä¿¡å¿µçŠ¶æ€è½¬ç§»çš„ä»£ä»·å¯èƒ½éå¸¸é«˜ï¼Œå¯¼è‡´è§„åˆ’æ—¶é—´è¿‡é•¿ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†æ‡’æƒ°RTDP-Belå’Œæ‡’æƒ°LAO*ï¼Œé€šè¿‡åˆ©ç”¨Qå€¼ä¼°è®¡æ¥æ¨è¿Ÿè®¡ç®—æ˜‚è´µçš„ä¿¡å¿µçŠ¶æ€è½¬ç§»ï¼Œä»è€Œæ˜¾è‘—å‡å°‘è§„åˆ’æ—¶é—´ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ‡’æƒ°å¯å‘å¼æœç´¢æ–¹æ³•åœ¨æ¥è§¦ä¸°å¯Œçš„æ“ä½œã€ç²—ç³™åœ°å½¢çš„æˆ·å¤–å¯¼èˆªå’Œä½¿ç”¨1-D LiDARä¼ æ„Ÿå™¨çš„å®¤å†…å¯¼èˆªç­‰é¢†åŸŸè¡¨ç°ä¼˜è¶Šï¼ŒåŒæ—¶ä¿æŒäº†è§£çš„è´¨é‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è§£å†³çš„æ˜¯åœ¨éƒ¨åˆ†å¯è§‚æµ‹é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆPOMDPsï¼‰ä¸­ï¼Œä¿¡å¿µçŠ¶æ€è½¬ç§»è®¡ç®—ä»£ä»·é«˜æ˜‚çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¦‚RTDP-Belå’ŒLAO*åœ¨æŸäº›é¢†åŸŸï¼ˆå¦‚æœºå™¨äººï¼‰ä¸­ï¼Œå› ç‰©ç†ä»¿çœŸã€å…‰çº¿æŠ•å°„æˆ–ç¢°æ’æ£€æŸ¥ç­‰è®¡ç®—å¤æ‚æ€§ï¼Œå¯¼è‡´è§„åˆ’æ—¶é—´è¿‡é•¿ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼•å…¥æ‡’æƒ°çš„è®¡ç®—ç­–ç•¥ï¼Œæ¨è¿Ÿä¿¡å¿µçŠ¶æ€è½¬ç§»çš„è®¡ç®—ï¼Œåˆ©ç”¨Qå€¼ä¼°è®¡æ¥å‡å°‘è®¡ç®—è´Ÿæ‹…ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨åœ¨ä¿æŒè§£çš„è´¨é‡çš„åŒæ—¶ï¼Œæ˜¾è‘—æé«˜è§„åˆ’é€Ÿåº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ‡’æƒ°RTDP-Belå’Œæ‡’æƒ°LAO*ä¸¤ä¸ªæ¨¡å—ã€‚é¦–å…ˆï¼Œåˆ©ç”¨Qå€¼ä¼°è®¡æ¥é¢„æµ‹ä¿¡å¿µçŠ¶æ€è½¬ç§»çš„æ•ˆæœï¼Œè€Œä¸æ˜¯ç«‹å³è®¡ç®—ã€‚ç„¶åï¼Œåœ¨éœ€è¦æ—¶å†è¿›è¡Œç²¾ç¡®è®¡ç®—ï¼Œä»è€Œä¼˜åŒ–æ•´ä½“è§„åˆ’æµç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæ‡’æƒ°è®¡ç®—ç­–ç•¥çš„å¼•å…¥ï¼Œä½¿å¾—ä¿¡å¿µçŠ¶æ€è½¬ç§»çš„è®¡ç®—å¯ä»¥è¢«æ¨è¿Ÿï¼Œé¿å…äº†æ˜‚è´µçš„å®æ—¶è®¡ç®—ã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºï¼Œç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦å³æ—¶è®¡ç®—æ‰€æœ‰ä¿¡å¿µçŠ¶æ€è½¬ç§»ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒQå€¼ä¼°è®¡æŠ€æœ¯è¢«ç”¨ä½œä¸»è¦çš„è®¡ç®—æ‰‹æ®µï¼Œå…·ä½“çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡å°šæœªè¯¦ç»†è¯´æ˜ï¼Œä½†å…¶æ ¸å¿ƒåœ¨äºå¦‚ä½•æœ‰æ•ˆåœ°åˆ©ç”¨Qå€¼æ¥å‡å°‘ä¿¡å¿µçŠ¶æ€è½¬ç§»çš„è®¡ç®—éœ€æ±‚ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’Œå‚æ•°è®¾ç½®ä»éœ€è¿›ä¸€æ­¥ç ”ç©¶ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‡’æƒ°å¯å‘å¼æœç´¢æ–¹æ³•åœ¨å¤šä¸ªé¢†åŸŸä¸­æ˜¾è‘—æé«˜äº†è§„åˆ’é€Ÿåº¦ã€‚ä¾‹å¦‚ï¼Œåœ¨æ¥è§¦ä¸°å¯Œçš„æ“ä½œå’Œç²—ç³™åœ°å½¢çš„æˆ·å¤–å¯¼èˆªä¸­ï¼Œè§„åˆ’æ—¶é—´å‡å°‘äº†50%ä»¥ä¸Šï¼ŒåŒæ—¶ä¿æŒäº†è§£çš„è´¨é‡ã€‚è¿™ä¸€æˆæœå±•ç¤ºäº†æ‡’æƒ°è®¡ç®—ç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæ“ä½œã€è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½å¯¼èˆªç­‰ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦å®æ—¶å†³ç­–çš„å¤æ‚ç¯å¢ƒä¸­ã€‚é€šè¿‡æé«˜è§„åˆ’é€Ÿåº¦ï¼Œæ‡’æƒ°å¯å‘å¼æœç´¢æ–¹æ³•èƒ½å¤Ÿåœ¨å®é™…åº”ç”¨ä¸­å®ç°æ›´é«˜æ•ˆçš„å†³ç­–æ”¯æŒï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Heuristic search solvers like RTDP-Bel and LAO* have proven effective for computing optimal and bounded sub-optimal solutions for Partially Observable Markov Decision Processes (POMDPs), which are typically formulated as belief MDPs. A belief represents a probability distribution over possible system states. Given a parent belief and an action, computing belief state transitions involves Bayesian updates that combine the transition and observation models of the POMDP to determine successor beliefs and their transition probabilities. However, there is a class of problems, specifically in robotics, where computing these transitions can be prohibitively expensive due to costly physics simulations, raycasting, or expensive collision checks required by the underlying transition and observation models, leading to long planning times. To address this challenge, we propose Lazy RTDP-Bel and Lazy LAO*, which defer computing expensive belief state transitions by leveraging Q-value estimation, significantly reducing planning time. We demonstrate the superior performance of the proposed lazy planners in domains such as contact-rich manipulation for pose estimation, outdoor navigation in rough terrain, and indoor navigation with a 1-D LiDAR sensor. Additionally, we discuss practical Q-value estimation techniques for commonly encountered problem classes that our lazy planners can leverage. Our results show that lazy heuristic search methods dramatically improve planning speed by postponing expensive belief transition evaluations while maintaining solution quality.

