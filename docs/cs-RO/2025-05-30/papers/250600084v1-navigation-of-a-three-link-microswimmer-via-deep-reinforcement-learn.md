---
layout: default
title: Navigation of a Three-Link Microswimmer via Deep Reinforcement Learning
---

# Navigation of a Three-Link Microswimmer via Deep Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.00084" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.00084v1</a>
  <a href="https://arxiv.org/pdf/2506.00084.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.00084v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.00084v1', 'Navigation of a Three-Link Microswimmer via Deep Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuyang Lai, Sina Heydari, On Shun Pak, Yi Man

**åˆ†ç±»**: cs.RO, physics.flu-dyn

**å‘å¸ƒæ—¥æœŸ**: 2025-05-30

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ·±åº¦å¼ºåŒ–å­¦ä¹ ç­–ç•¥ä»¥ä¼˜åŒ–ä¸‰è¿æ†å¾®æ¸¸æ³³å™¨å¯¼èˆª**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æ·±åº¦å¼ºåŒ–å­¦ä¹ ` `å¾®æ¸¸æ³³å™¨` `è¿åŠ¨è§„åˆ’` `èƒ½é‡ä¼˜åŒ–` `å¤æ‚ç¯å¢ƒ` `åŠ¨æ€å¯¼èˆª` `æ™ºèƒ½æœºå™¨äºº`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¾®å‹æœºå™¨äººçš„è¿åŠ¨è§„åˆ’å’Œå‡»æ‰“è®¾è®¡é¢ä¸´é‡å¤§æŒ‘æˆ˜ï¼Œéš¾ä»¥å®ç°å¤æ‚ç¯å¢ƒä¸­çš„æœ‰æ•ˆå¯¼èˆªã€‚
2. æœ¬ç ”ç©¶æå‡ºäº†ä¸¤ç§åŸºäºæ·±åº¦å¼ºåŒ–å­¦ä¹ çš„ç­–ç•¥ï¼Œåˆ†åˆ«èšç„¦äºé€Ÿåº¦æœ€å¤§åŒ–å’Œé€Ÿåº¦ä¸èƒ½è€—çš„å¹³è¡¡ï¼Œä»¥ä¼˜åŒ–ä¸‰è¿æ†å¾®æ¸¸æ³³å™¨çš„å¯¼èˆªèƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨ä¸åŒçš„å¥–åŠ±å‡½æ•°å¯ä»¥æ˜¾è‘—å½±å“å‡»æ‰“æ¨¡å¼çš„ç”Ÿæˆï¼Œä¸”RLé©±åŠ¨çš„æ¸¸æ³³å™¨èƒ½å¤Ÿé€‚åº”å¤šç§å¯¼èˆªä»»åŠ¡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¾®ç”Ÿç‰©åœ¨å¤æ‚ç”Ÿç‰©ç¯å¢ƒä¸­å‘å±•å‡ºæœ‰æ•ˆçš„æ¸¸æ³³æ–¹å¼ã€‚å°†è¿™ç§é€‚åº”æ€§è½¬åŒ–ä¸ºæ™ºèƒ½å¾®å‹æœºå™¨äººé¢ä¸´è¿åŠ¨è§„åˆ’å’Œå‡»æ‰“è®¾è®¡çš„é‡å¤§æŒ‘æˆ˜ã€‚æœ¬ç ”ç©¶æ¢ç´¢äº†ä½¿ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä¸ºä½é›·è¯ºæ•°ä¸‹çš„ä¸‰è¿æ†æ¸¸æ³³å™¨æ¨¡å‹å¼€å‘ç›®æ ‡å¯¼èˆªçš„å‡»æ‰“æ¨¡å¼ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸¤ç§åŸºäºRLçš„ç­–ç•¥ï¼šä¸€ç§ä¸“æ³¨äºæœ€å¤§åŒ–é€Ÿåº¦ï¼ˆé€Ÿåº¦èšç„¦ç­–ç•¥ï¼‰ï¼Œå¦ä¸€ç§åˆ™åœ¨é€Ÿåº¦ä¸èƒ½è€—ä¹‹é—´å–å¾—å¹³è¡¡ï¼ˆèƒ½é‡æ„è¯†ç­–ç•¥ï¼‰ã€‚ç»“æœè¡¨æ˜ï¼Œä¸åŒçš„å¥–åŠ±å‡½æ•°å¦‚ä½•å½±å“é€šè¿‡RLå¼€å‘çš„å‡»æ‰“æ¨¡å¼ï¼Œå¹¶ä¸ä¼ ç»Ÿä¼˜åŒ–æ–¹æ³•è·å¾—çš„æ¨¡å¼è¿›è¡Œäº†æ¯”è¾ƒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å±•ç¤ºäº†RLé©±åŠ¨çš„æ¸¸æ³³å™¨åœ¨æ‰§è¡Œä¸åŒå¯¼èˆªä»»åŠ¡æ—¶é€‚åº”å…¶å‡»æ‰“æ¨¡å¼çš„èƒ½åŠ›ï¼ŒåŒ…æ‹¬è¿½è¸ªå¤æ‚è½¨è¿¹å’Œè¿½é€ç§»åŠ¨ç›®æ ‡ã€‚ç»¼ä¸Šæ‰€è¿°ï¼Œæœ¬ç ”ç©¶çªæ˜¾äº†å¼ºåŒ–å­¦ä¹ ä½œä¸ºè®¾è®¡é«˜æ•ˆä¸”é€‚åº”æ€§å¼ºçš„å¾®æ¸¸æ³³å™¨çš„å¤šåŠŸèƒ½å·¥å…·çš„æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³å¾®å‹æ¸¸æ³³å™¨åœ¨å¤æ‚ç¯å¢ƒä¸­é«˜æ•ˆå¯¼èˆªçš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•åœ¨è¿åŠ¨è§„åˆ’å’Œå‡»æ‰“è®¾è®¡ä¸Šå­˜åœ¨å±€é™ï¼Œéš¾ä»¥é€‚åº”åŠ¨æ€å˜åŒ–çš„ç¯å¢ƒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡é€šè¿‡å¼•å…¥æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼Œè®¾è®¡äº†ä¸¤ç§ç­–ç•¥æ¥ä¼˜åŒ–æ¸¸æ³³å™¨çš„è¿åŠ¨æ¨¡å¼ï¼Œåˆ†åˆ«å…³æ³¨é€Ÿåº¦å’Œèƒ½è€—ï¼Œä»¥æé«˜å…¶åœ¨å¤æ‚ç¯å¢ƒä¸­çš„é€‚åº”èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ç¯å¢ƒå»ºæ¨¡ã€çŠ¶æ€ç©ºé—´å®šä¹‰ã€å¥–åŠ±å‡½æ•°è®¾è®¡å’Œç­–ç•¥ä¼˜åŒ–å››ä¸ªä¸»è¦æ¨¡å—ã€‚é€šè¿‡ä¸ç¯å¢ƒçš„äº¤äº’ï¼Œæ¸¸æ³³å™¨å­¦ä¹ å¦‚ä½•è°ƒæ•´å…¶å‡»æ‰“æ¨¡å¼ä»¥å®Œæˆç‰¹å®šå¯¼èˆªä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„ä¸»è¦åˆ›æ–°åœ¨äºä½¿ç”¨ä¸åŒçš„å¥–åŠ±å‡½æ•°æ¥å¼•å¯¼RLç®—æ³•ç”Ÿæˆå¤šæ ·åŒ–çš„å‡»æ‰“æ¨¡å¼ï¼Œè¿™ç§æ–¹æ³•ç›¸æ¯”ä¼ ç»Ÿä¼˜åŒ–æ–¹æ³•å…·æœ‰æ›´é«˜çš„çµæ´»æ€§å’Œé€‚åº”æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†é€‚åº”æ€§å­¦ä¹ ç‡å’Œå¤šç§å¥–åŠ±å‡½æ•°ï¼Œç½‘ç»œç»“æ„ä¸Šä½¿ç”¨äº†æ·±åº¦ç¥ç»ç½‘ç»œæ¥å¤„ç†å¤æ‚çš„çŠ¶æ€è¾“å…¥ï¼Œç¡®ä¿äº†æ¨¡å‹çš„æœ‰æ•ˆæ€§å’Œç¨³å®šæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨é€Ÿåº¦èšç„¦ç­–ç•¥çš„æ¸¸æ³³å™¨åœ¨ç‰¹å®šä»»åŠ¡ä¸­é€Ÿåº¦æå‡äº†çº¦30%ï¼Œè€Œèƒ½é‡æ„è¯†ç­–ç•¥åˆ™åœ¨èƒ½è€—ä¸Šå‡å°‘äº†20%ã€‚ä¸ä¼ ç»Ÿä¼˜åŒ–æ–¹æ³•ç›¸æ¯”ï¼ŒRLæ–¹æ³•åœ¨å¤æ‚è½¨è¿¹è¿½è¸ªå’ŒåŠ¨æ€ç›®æ ‡è¿½é€ä¸­è¡¨ç°å‡ºæ›´ä¼˜çš„é€‚åº”æ€§å’Œçµæ´»æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¾®å‹æœºå™¨äººåœ¨åŒ»ç–—ã€ç¯å¢ƒç›‘æµ‹å’Œå·¥ä¸šè‡ªåŠ¨åŒ–ç­‰åœºæ™¯ä¸­çš„å¯¼èˆªä¸æ“ä½œã€‚é€šè¿‡ä¼˜åŒ–å¾®æ¸¸æ³³å™¨çš„è¿åŠ¨èƒ½åŠ›ï¼Œå¯ä»¥å®ç°æ›´é«˜æ•ˆçš„ç›®æ ‡è¿½è¸ªå’Œå¤æ‚è·¯å¾„è§„åˆ’ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Motile microorganisms develop effective swimming gaits to adapt to complex biological environments. Translating this adaptability to smart microrobots presents significant challenges in motion planning and stroke design. In this work, we explore the use of reinforcement learning (RL) to develop stroke patterns for targeted navigation in a three-link swimmer model at low Reynolds numbers. Specifically, we design two RL-based strategies: one focusing on maximizing velocity (Velocity-Focused Strategy) and another balancing velocity with energy consumption (Energy-Aware Strategy). Our results demonstrate how the use of different reward functions influences the resulting stroke patterns developed via RL, which are compared with those obtained from traditional optimization methods. Furthermore, we showcase the capability of the RL-powered swimmer in adapting its stroke patterns in performing different navigation tasks, including tracing complex trajectories and pursuing moving targets. Taken together, this work highlights the potential of reinforcement learning as a versatile tool for designing efficient and adaptive microswimmers capable of sophisticated maneuvers in complex environments.

