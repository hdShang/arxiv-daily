---
layout: default
title: Sim2Real Reinforcement Learning for Soccer skills
---

# Sim2Real Reinforcement Learning for Soccer skills

**arXiv**: [2512.12437v1](https://arxiv.org/abs/2512.12437) | [PDF](https://arxiv.org/pdf/2512.12437.pdf)

**ä½œè€…**: Jonathan Spraggett

**åˆ†ç±»**: cs.RO, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-12-13

**å¤‡æ³¨**: Undergrad Thesis

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽè¯¾ç¨‹å­¦ä¹ å’Œå¯¹æŠ—è¿åŠ¨å…ˆéªŒçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºŽè®­ç»ƒäººå½¢æœºå™¨äººè¶³çƒæŠ€èƒ½**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)** **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `äººå½¢æœºå™¨äºº` `è¯¾ç¨‹å­¦ä¹ ` `å¯¹æŠ—è¿åŠ¨å…ˆéªŒ` `è¿åŠ¨æŽ§åˆ¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿå¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨äººå½¢æœºå™¨äººæŽ§åˆ¶ä»»åŠ¡ä¸­ï¼Œéš¾ä»¥é€‚åº”çœŸå®žçŽ¯å¢ƒçš„å¤æ‚æ€§å’Œå®žçŽ°è‡ªç„¶è¿åŠ¨ã€‚
2. è®ºæ–‡æå‡ºç»“åˆè¯¾ç¨‹å­¦ä¹ å’Œå¯¹æŠ—è¿åŠ¨å…ˆéªŒï¼ˆAMPï¼‰çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œæå‡ç­–ç•¥çš„åŠ¨æ€æ€§å’Œé€‚åº”æ€§ã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨æ¨¡æ‹ŸçŽ¯å¢ƒä¸­è®­ç»ƒçš„è¸¢çƒã€è¡Œèµ°å’Œè·³è·ƒç­–ç•¥ä¼˜äºŽä»¥å¾€æ–¹æ³•ï¼Œä½†è¿ç§»åˆ°çœŸå®žçŽ¯å¢ƒå¤±è´¥ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§æ›´é«˜æ•ˆã€æ›´æœ‰æ•ˆçš„æ–¹æ³•ï¼Œç”¨äºŽè®­ç»ƒäººå½¢æœºå™¨äººçš„æŽ§åˆ¶ç›¸å…³ä»»åŠ¡ï¼Œè¯¥æ–¹æ³•åŸºäºŽå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ã€‚ä¼ ç»Ÿçš„RLæ–¹æ³•åœ¨é€‚åº”çœŸå®žçŽ¯å¢ƒã€å¤æ‚æ€§å’Œè‡ªç„¶è¿åŠ¨æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚æœ¬æ–‡æå‡ºçš„æ–¹æ³•é€šè¿‡ä½¿ç”¨è¯¾ç¨‹è®­ç»ƒå’Œå¯¹æŠ—è¿åŠ¨å…ˆéªŒï¼ˆAMPï¼‰æŠ€æœ¯å…‹æœäº†è¿™äº›é™åˆ¶ã€‚ç»“æžœè¡¨æ˜Žï¼Œæ‰€å¼€å‘çš„ç”¨äºŽè¸¢çƒã€è¡Œèµ°å’Œè·³è·ƒçš„RLç­–ç•¥æ›´å…·åŠ¨æ€æ€§å’Œé€‚åº”æ€§ï¼Œå¹¶ä¸”ä¼˜äºŽä»¥å¾€çš„æ–¹æ³•ã€‚ç„¶è€Œï¼Œå­¦ä¹ åˆ°çš„ç­–ç•¥ä»Žæ¨¡æ‹Ÿåˆ°çœŸå®žä¸–ç•Œçš„è¿ç§»å¹¶ä¸æˆåŠŸï¼Œçªå‡ºäº†å½“å‰RLæ–¹æ³•åœ¨å®Œå…¨é€‚åº”çœŸå®žåœºæ™¯æ–¹é¢çš„å±€é™æ€§ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³äººå½¢æœºå™¨äººæŽ§åˆ¶ä»»åŠ¡ä¸­ï¼Œå¼ºåŒ–å­¦ä¹ ç­–ç•¥éš¾ä»¥é€‚åº”çœŸå®žçŽ¯å¢ƒï¼ŒåŠ¨ä½œä¸å¤Ÿè‡ªç„¶æµç•…çš„é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•åœ¨å¤æ‚çŽ¯å¢ƒå’Œè‡ªç„¶è¿åŠ¨æ–¹é¢çš„æ³›åŒ–èƒ½åŠ›ä¸è¶³ï¼Œå¯¼è‡´æ¨¡æ‹ŸçŽ¯å¢ƒè®­ç»ƒçš„ç­–ç•¥éš¾ä»¥ç›´æŽ¥åº”ç”¨äºŽçœŸå®žæœºå™¨äººã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è¯¾ç¨‹å­¦ä¹ é€æ­¥å¢žåŠ è®­ç»ƒéš¾åº¦ï¼Œå¹¶å¼•å…¥å¯¹æŠ—è¿åŠ¨å…ˆéªŒï¼ˆAMPï¼‰æ¥å­¦ä¹ æ›´è‡ªç„¶çš„è¿åŠ¨æ¨¡å¼ã€‚é€šè¿‡è¯¾ç¨‹å­¦ä¹ ï¼Œæœºå™¨äººå¯ä»¥ä»Žç®€å•çš„ä»»åŠ¡å¼€å§‹ï¼Œé€æ­¥æŽŒæ¡æ›´å¤æ‚çš„æŠ€èƒ½ã€‚AMPåˆ™é€šè¿‡æ¨¡ä»¿çœŸå®žè¿åŠ¨æ•°æ®ï¼Œå¼•å¯¼æœºå™¨äººå­¦ä¹ æ›´é€¼çœŸçš„åŠ¨ä½œã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æ¡†æž¶åŒ…å«æ¨¡æ‹ŸçŽ¯å¢ƒã€å¼ºåŒ–å­¦ä¹ ç®—æ³•ã€è¯¾ç¨‹å­¦ä¹ æ¨¡å—å’Œå¯¹æŠ—è¿åŠ¨å…ˆéªŒæ¨¡å—ã€‚é¦–å…ˆï¼Œåœ¨æ¨¡æ‹ŸçŽ¯å¢ƒä¸­åˆ©ç”¨å¼ºåŒ–å­¦ä¹ ç®—æ³•è®­ç»ƒæœºå™¨äººã€‚ç„¶åŽï¼Œè¯¾ç¨‹å­¦ä¹ æ¨¡å—æ ¹æ®æœºå™¨äººçš„å­¦ä¹ è¿›åº¦ï¼Œé€æ­¥å¢žåŠ ä»»åŠ¡çš„éš¾åº¦ã€‚åŒæ—¶ï¼Œå¯¹æŠ—è¿åŠ¨å…ˆéªŒæ¨¡å—åˆ©ç”¨çœŸå®žè¿åŠ¨æ•°æ®ï¼Œè®­ç»ƒä¸€ä¸ªåˆ¤åˆ«å™¨æ¥åŒºåˆ†æœºå™¨äººç”Ÿæˆçš„è¿åŠ¨å’ŒçœŸå®žè¿åŠ¨ï¼Œå¹¶åˆ©ç”¨åˆ¤åˆ«å™¨çš„æ¢¯åº¦æ¥æŒ‡å¯¼æœºå™¨äººçš„ç­–ç•¥å­¦ä¹ ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽå°†è¯¾ç¨‹å­¦ä¹ å’Œå¯¹æŠ—è¿åŠ¨å…ˆéªŒç›¸ç»“åˆï¼Œç”¨äºŽäººå½¢æœºå™¨äººçš„å¼ºåŒ–å­¦ä¹ æŽ§åˆ¶ã€‚è¯¾ç¨‹å­¦ä¹ å¯ä»¥æœ‰æ•ˆåœ°å¼•å¯¼æœºå™¨äººå­¦ä¹ å¤æ‚çš„æŠ€èƒ½ï¼Œè€Œå¯¹æŠ—è¿åŠ¨å…ˆéªŒå¯ä»¥æé«˜æœºå™¨äººè¿åŠ¨çš„è‡ªç„¶æ€§å’ŒçœŸå®žæ„Ÿã€‚è¿™ç§ç»“åˆä½¿å¾—æœºå™¨äººèƒ½å¤Ÿå­¦ä¹ åˆ°æ›´é²æ£’ã€æ›´è‡ªç„¶çš„æŽ§åˆ¶ç­–ç•¥ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­ï¼Œè¯¾ç¨‹å­¦ä¹ çš„å…·ä½“å®žçŽ°æ–¹å¼æ˜¯é€æ­¥å¢žåŠ ä»»åŠ¡çš„éš¾åº¦ï¼Œä¾‹å¦‚ï¼Œä»Žç®€å•çš„ç«™ç«‹ä»»åŠ¡å¼€å§‹ï¼Œé€æ­¥è¿‡æ¸¡åˆ°è¡Œèµ°ã€è·‘æ­¥å’Œè·³è·ƒç­‰æ›´å¤æ‚çš„ä»»åŠ¡ã€‚å¯¹æŠ—è¿åŠ¨å…ˆéªŒæ¨¡å—ä½¿ç”¨ä¸€ä¸ªåˆ¤åˆ«å™¨ç½‘ç»œï¼Œè¯¥ç½‘ç»œè¾“å…¥æœºå™¨äººçš„è¿åŠ¨çŠ¶æ€ï¼Œå¹¶è¾“å‡ºä¸€ä¸ªæ¦‚çŽ‡å€¼ï¼Œè¡¨ç¤ºè¯¥è¿åŠ¨æ˜¯çœŸå®žçš„è¿˜æ˜¯ç”±æœºå™¨äººç”Ÿæˆçš„ã€‚åˆ¤åˆ«å™¨çš„æŸå¤±å‡½æ•°é‡‡ç”¨å¯¹æŠ—æŸå¤±ï¼Œé¼“åŠ±æœºå™¨äººç”Ÿæˆæ›´é€¼çœŸçš„è¿åŠ¨ã€‚å¼ºåŒ–å­¦ä¹ ç®—æ³•é‡‡ç”¨TRPOæˆ–PPOç­‰ç­–ç•¥æ¢¯åº¦ç®—æ³•ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

è®ºæ–‡åœ¨æ¨¡æ‹ŸçŽ¯å¢ƒä¸­éªŒè¯äº†æ‰€æå‡ºæ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œç»“æžœè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•è®­ç»ƒçš„è¸¢çƒã€è¡Œèµ°å’Œè·³è·ƒç­–ç•¥æ¯”ä»¥å¾€æ–¹æ³•æ›´å…·åŠ¨æ€æ€§å’Œé€‚åº”æ€§ã€‚å…·ä½“è€Œè¨€ï¼Œæœºå™¨äººèƒ½å¤Ÿå®Œæˆæ›´å¤æ‚çš„è¿åŠ¨ï¼Œå¹¶ä¸”å¯¹çŽ¯å¢ƒå˜åŒ–çš„é²æ£’æ€§æ›´é«˜ã€‚ç„¶è€Œï¼Œæ¨¡æ‹Ÿåˆ°çœŸå®žçš„è¿ç§»ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œè¡¨æ˜Žéœ€è¦è¿›ä¸€æ­¥ç ”ç©¶å¦‚ä½•ç¼©å°æ¨¡æ‹ŸçŽ¯å¢ƒå’ŒçœŸå®žçŽ¯å¢ƒä¹‹é—´çš„å·®è·ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽäººå½¢æœºå™¨äººçš„è¿åŠ¨æŽ§åˆ¶ã€ä½“è‚²ç«žæŠ€æœºå™¨äººã€ä»¥åŠå…¶ä»–éœ€è¦å¤æ‚è¿åŠ¨æŠ€èƒ½çš„æœºå™¨äººé¢†åŸŸã€‚é€šè¿‡æ¨¡æ‹ŸçŽ¯å¢ƒè®­ç»ƒï¼Œå¯ä»¥é™ä½ŽçœŸå®žæœºå™¨äººè®­ç»ƒçš„æˆæœ¬å’Œé£Žé™©ï¼ŒåŠ é€Ÿæœºå™¨äººåœ¨å¤æ‚çŽ¯å¢ƒä¸­çš„åº”ç”¨ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºŽç¾éš¾æ•‘æ´ã€åŒ»ç–—è¾…åŠ©ç­‰é¢†åŸŸã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> This thesis work presents a more efficient and effective approach to training control-related tasks for humanoid robots using Reinforcement Learning (RL). The traditional RL methods are limited in adapting to real-world environments, complexity, and natural motions, but the proposed approach overcomes these limitations by using curriculum training and Adversarial Motion Priors (AMP) technique. The results show that the developed RL policies for kicking, walking, and jumping are more dynamic, and adaptive, and outperformed previous methods. However, the transfer of the learned policy from simulation to the real world was unsuccessful, highlighting the limitations of current RL methods in fully adapting to real-world scenarios.

