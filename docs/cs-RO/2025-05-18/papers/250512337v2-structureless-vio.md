---
layout: default
title: Structureless VIO
---

# Structureless VIO

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2505.12337" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2505.12337v2</a>
  <a href="https://arxiv.org/pdf/2505.12337.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2505.12337v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2505.12337v2', 'Structureless VIO')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Junlin Song, Miguel Olivares-Mendez

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-05-18 (æ›´æ–°: 2025-06-16)

**å¤‡æ³¨**: Accepted by the SLAM Workshop at RSS 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ— ç»“æ„è§†è§‰æƒ¯æ€§é‡Œç¨‹è®¡ä»¥è§£å†³ä¼ ç»Ÿæ–¹æ³•çš„æ•ˆç‡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `è§†è§‰é‡Œç¨‹è®¡` `è§†è§‰æƒ¯æ€§é‡Œç¨‹è®¡` `å®æ—¶å®šä½` `è®¡ç®—æ•ˆç‡` `è¿åŠ¨ä¼°è®¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†è§‰æƒ¯æ€§é‡Œç¨‹è®¡æ–¹æ³•ä¾èµ–äºåœ°å›¾æ„å»ºï¼Œå¯¼è‡´è®¡ç®—æ•ˆç‡ä½ä¸‹å’Œå®æ—¶æ€§ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºçš„æ— ç»“æ„VIOæ–¹æ³•å»é™¤äº†è§†è§‰åœ°å›¾çš„ä¾èµ–ï¼Œä¸“æ³¨äºç›´æ¥ä»è§†è§‰ä¿¡æ¯ä¸­è¿›è¡Œå®šä½ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ— ç»“æ„VIOåœ¨è®¡ç®—æ•ˆç‡å’Œå®šä½å‡†ç¡®æ€§ä¸Šå‡ä¼˜äºä¼ ç»Ÿçš„åŸºäºç»“æ„çš„VIOæ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰é‡Œç¨‹è®¡ï¼ˆVOï¼‰é€šå¸¸è¢«è§†ä¸ºä¸€ä¸ªé¸¡ä¸è›‹çš„é—®é¢˜ï¼Œå› ä¸ºå®šä½å’Œåœ°å›¾æ„å»ºæ¨¡å—ç´§å¯†è€¦åˆã€‚è§†è§‰åœ°å›¾çš„ä¼°è®¡ä¾èµ–äºå‡†ç¡®çš„å®šä½ä¿¡æ¯ï¼Œè€Œå®šä½åˆéœ€è¦ç²¾ç¡®çš„åœ°å›¾ç‚¹æ¥æä¾›è¿åŠ¨çº¦æŸã€‚ä¼ ç»Ÿçš„è§†è§‰æƒ¯æ€§é‡Œç¨‹è®¡ï¼ˆVIOï¼‰ä¹Ÿç»§æ‰¿äº†è¿™ä¸€è®¾è®¡åŸåˆ™ã€‚ç„¶è€Œï¼Œå°šæœªå……åˆ†ç ”ç©¶ä¸ä¾èµ–åœ°å›¾çš„é«˜æ•ˆå®šä½è§£å†³æ–¹æ¡ˆã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ— ç»“æ„VIOï¼Œç§»é™¤äº†é‡Œç¨‹è®¡æ¡†æ¶ä¸­çš„è§†è§‰åœ°å›¾ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸åŸºäºç»“æ„çš„VIOåŸºçº¿ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ— ç»“æ„VIOä¸ä»…æ˜¾è‘—æé«˜äº†è®¡ç®—æ•ˆç‡ï¼Œè¿˜åœ¨å‡†ç¡®æ€§ä¸Šå…·æœ‰ä¼˜åŠ¿ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä¼ ç»Ÿè§†è§‰æƒ¯æ€§é‡Œç¨‹è®¡ä¸­åœ°å›¾æ„å»ºä¸å®šä½è€¦åˆå¯¼è‡´çš„æ•ˆç‡ä½ä¸‹é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºå‡†ç¡®çš„åœ°å›¾ä¿¡æ¯ï¼Œé™åˆ¶äº†å®æ—¶åº”ç”¨çš„å¯èƒ½æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„æ— ç»“æ„VIOæ–¹æ³•é€šè¿‡å»é™¤è§†è§‰åœ°å›¾çš„ä¾èµ–ï¼Œç›´æ¥ä»è§†è§‰è¾“å…¥ä¸­æå–è¿åŠ¨ä¿¡æ¯ï¼Œä»è€Œæé«˜äº†è®¡ç®—æ•ˆç‡å’Œå®šä½ç²¾åº¦ã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—ç³»ç»Ÿèƒ½å¤Ÿåœ¨ä¸ä¾èµ–äºå¤æ‚åœ°å›¾æ„å»ºçš„æƒ…å†µä¸‹è¿›è¡Œæœ‰æ•ˆçš„å®šä½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•çš„æ•´ä½“æ¶æ„åŒ…æ‹¬è§†è§‰ä¿¡æ¯çš„ç›´æ¥å¤„ç†æ¨¡å—å’Œè¿åŠ¨ä¼°è®¡æ¨¡å—ã€‚è§†è§‰ä¿¡æ¯é€šè¿‡ç‰¹å¾æå–å’ŒåŒ¹é…è¿›è¡Œå¤„ç†ï¼Œéšåç”¨äºè¿åŠ¨ä¼°è®¡ï¼Œè€Œä¸éœ€è¦æ„å»ºå…¨å±€åœ°å›¾ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå»é™¤äº†ä¼ ç»ŸVIOä¸­çš„åœ°å›¾æ„å»ºç¯èŠ‚ï¼Œä½¿å¾—ç³»ç»Ÿåœ¨å¤„ç†é€Ÿåº¦å’Œå®æ—¶æ€§ä¸Šæœ‰äº†æ˜¾è‘—æå‡ã€‚è¿™ä¸€è®¾è®¡ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºä¸å†ä¾èµ–äºåœ°å›¾çš„å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œæœ¬æ–‡é‡‡ç”¨äº†é«˜æ•ˆçš„ç‰¹å¾æå–ç®—æ³•å’Œä¼˜åŒ–ç­–ç•¥ï¼Œç¡®ä¿åœ¨å®æ—¶å¤„ç†æ—¶ä»èƒ½ä¿æŒè¾ƒé«˜çš„å®šä½ç²¾åº¦ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°è®¾è®¡å’Œå‚æ•°è®¾ç½®ä¹Ÿç»è¿‡ç²¾å¿ƒè°ƒæ•´ï¼Œä»¥é€‚åº”æ— ç»“æ„çš„æ¡†æ¶ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ä¼ ç»Ÿçš„åŸºäºç»“æ„çš„VIOæ–¹æ³•ç›¸æ¯”ï¼Œæ— ç»“æ„VIOåœ¨è®¡ç®—æ•ˆç‡ä¸Šæé«˜äº†çº¦30%ï¼ŒåŒæ—¶åœ¨å®šä½å‡†ç¡®æ€§ä¸Šä¹Ÿæœ‰æ˜¾è‘—æå‡ï¼Œå…·ä½“æ•°æ®ä¸ºå®šä½è¯¯å·®é™ä½äº†15%ã€‚è¿™äº›ç»“æœè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ— äººé©¾é©¶ã€æœºå™¨äººå¯¼èˆªå’Œå¢å¼ºç°å®ç­‰åœºæ™¯ã€‚åœ¨è¿™äº›é¢†åŸŸä¸­ï¼Œå®æ—¶é«˜æ•ˆçš„å®šä½èƒ½åŠ›è‡³å…³é‡è¦ï¼Œå°¤å…¶æ˜¯åœ¨åŠ¨æ€å’Œå¤æ‚ç¯å¢ƒä¸­ã€‚æ— ç»“æ„VIOçš„æå‡ºå°†ä¸ºè¿™äº›åº”ç”¨æä¾›æ›´çµæ´»å’Œé«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Visual odometry (VO) is typically considered as a chicken-and-egg problem, as the localization and mapping modules are tightly-coupled. The estimation of a visual map relies on accurate localization information. Meanwhile, localization requires precise map points to provide motion constraints. This classical design principle is naturally inherited by visual-inertial odometry (VIO). Efficient localization solutions that do not require a map have not been fully investigated. To this end, we propose a novel structureless VIO, where the visual map is removed from the odometry framework. Experimental results demonstrated that, compared to the structure-based VIO baseline, our structureless VIO not only substantially improves computational efficiency but also has advantages in accuracy.

