---
layout: default
title: ActiveUMI: Robotic Manipulation with Active Perception from Robot-Free Human Demonstrations
---

# ActiveUMI: Robotic Manipulation with Active Perception from Robot-Free Human Demonstrations

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.01607" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.01607v1</a>
  <a href="https://arxiv.org/pdf/2510.01607.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.01607v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.01607v1', 'ActiveUMI: Robotic Manipulation with Active Perception from Robot-Free Human Demonstrations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Qiyuan Zeng, Chengmeng Li, Jude St. John, Zhongyi Zhou, Junjie Wen, Guorui Feng, Yichen Zhu, Yi Xu

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-02

**å¤‡æ³¨**: technique report. The website is available at https://activeumi.github.io

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ActiveUMIï¼šé€šè¿‡æœºå™¨äººè‡ªç”±çš„äººç±»æ¼”ç¤ºè¿›è¡Œä¸»åŠ¨æ„ŸçŸ¥çš„æœºå™¨äººæ“ä½œ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)**

**å…³é”®è¯**: `æœºå™¨äººæ“ä½œ` `ä¸»åŠ¨æ„ŸçŸ¥` `VRé¥æ“ä½œ` `åŒæ‰‹åŠ¨æ“ä½œ` `æ•°æ®æ”¶é›†` `ç­–ç•¥å­¦ä¹ ` `æ³›åŒ–èƒ½åŠ›`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æœºå™¨äººæ“ä½œå­¦ä¹ æ–¹æ³•éš¾ä»¥æœ‰æ•ˆåˆ©ç”¨çœŸå®ä¸–ç•Œäººç±»æ¼”ç¤ºæ•°æ®ï¼Œé™åˆ¶äº†æœºå™¨äººæ³›åŒ–èƒ½åŠ›ã€‚
2. ActiveUMIé€šè¿‡ä¾¿æºå¼VRé¥æ“ä½œå¥—ä»¶å’Œä¼ æ„Ÿå™¨æ§åˆ¶å™¨ï¼Œç²¾ç¡®å¯¹é½äºº-æœºå™¨äººè¿åŠ¨å­¦ï¼Œæ•æ‰äººç±»æ“ä½œä¸­çš„ä¸»åŠ¨æ„ŸçŸ¥ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒåŸºäºActiveUMIæ•°æ®è®­ç»ƒçš„ç­–ç•¥åœ¨å¤æ‚åŒæ‰‹åŠ¨ä»»åŠ¡ä¸Šè¡¨ç°å‡ºä¼˜å¼‚çš„æˆåŠŸç‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ActiveUMIæ˜¯ä¸€ä¸ªæ•°æ®æ”¶é›†ç³»ç»Ÿæ¡†æ¶ï¼Œæ—¨åœ¨å°†çœŸå®åœºæ™¯ä¸‹çš„äººç±»æ¼”ç¤ºè¿ç§»åˆ°èƒ½å¤Ÿæ‰§è¡Œå¤æ‚åŒæ‰‹åŠ¨æ“ä½œçš„æœºå™¨äººä¸Šã€‚ActiveUMIå°†ä¾¿æºå¼VRé¥æ“ä½œå¥—ä»¶ä¸ä¼ æ„Ÿå™¨æ§åˆ¶å™¨ç›¸ç»“åˆï¼Œé€šè¿‡ç²¾ç¡®çš„å§¿æ€å¯¹é½è¿æ¥äºº-æœºå™¨äººè¿åŠ¨å­¦ã€‚ä¸ºäº†ç¡®ä¿ç§»åŠ¨æ€§å’Œæ•°æ®è´¨é‡ï¼Œå¼•å…¥äº†æ²‰æµ¸å¼3Dæ¨¡å‹æ¸²æŸ“ã€ç‹¬ç«‹çš„ç©¿æˆ´å¼è®¡ç®—æœºå’Œé«˜æ•ˆçš„æ ¡å‡†æ–¹æ³•ç­‰å…³é”®æŠ€æœ¯ã€‚ActiveUMIçš„æ ¸å¿ƒåœ¨äºæ•æ‰ä¸»åŠ¨çš„ã€ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„æ„ŸçŸ¥ã€‚é€šè¿‡è®°å½•æ“ä½œå‘˜é€šè¿‡å¤´æˆ´å¼æ˜¾ç¤ºå™¨è¿›è¡Œçš„å¤´éƒ¨è¿åŠ¨ï¼Œç³»ç»Ÿå­¦ä¹ è§†è§‰æ³¨æ„åŠ›å’Œæ“ä½œä¹‹é—´çš„å…³é”®è”ç³»ã€‚åœ¨å…­é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„åŒæ‰‹åŠ¨ä»»åŠ¡ä¸Šè¯„ä¼°äº†ActiveUMIã€‚ä»…ä½¿ç”¨ActiveUMIæ•°æ®è®­ç»ƒçš„ç­–ç•¥åœ¨åŒåˆ†å¸ƒä»»åŠ¡ä¸Šå¹³å‡æˆåŠŸç‡è¾¾åˆ°70%ï¼Œå¹¶è¡¨ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œåœ¨æ–°ç‰©ä½“å’Œæ–°ç¯å¢ƒä¸­æµ‹è¯•æ—¶ä»ä¿æŒ56%çš„æˆåŠŸç‡ã€‚ç»“æœè¡¨æ˜ï¼Œä¾¿æºå¼æ•°æ®æ”¶é›†ç³»ç»Ÿä¸å­¦ä¹ åˆ°çš„ä¸»åŠ¨æ„ŸçŸ¥ç›¸ç»“åˆï¼Œä¸ºåˆ›å»ºå¯æ³›åŒ–ä¸”é«˜æ€§èƒ½çš„çœŸå®ä¸–ç•Œæœºå™¨äººç­–ç•¥æä¾›äº†ä¸€æ¡æœ‰æ•ˆä¸”å¯æ‰©å±•çš„é€”å¾„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æœºå™¨äººæ“ä½œå­¦ä¹ æ–¹æ³•é€šå¸¸ä¾èµ–äºæ¨¡æ‹Ÿæ•°æ®æˆ–æ˜‚è´µçš„å®éªŒå®¤ç¯å¢ƒæ•°æ®ï¼Œéš¾ä»¥è·å–çœŸå®ä¸–ç•Œäººç±»æ“ä½œçš„ä¸°å¯Œä¿¡æ¯ã€‚æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€å¿½ç•¥äº†äººç±»æ“ä½œä¸­çš„ä¸»åŠ¨æ„ŸçŸ¥ï¼Œå³è§†è§‰æ³¨æ„åŠ›å’Œæ“ä½œä¹‹é—´çš„è”ç³»ï¼Œå¯¼è‡´æœºå™¨äººéš¾ä»¥æ³›åŒ–åˆ°æ–°ç¯å¢ƒå’Œæ–°ç‰©ä½“ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šActiveUMIçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ä¾¿æºå¼VRé¥æ“ä½œç³»ç»Ÿï¼Œè®©æ“ä½œå‘˜åœ¨è™šæ‹Ÿç¯å¢ƒä¸­è¿›è¡Œæ“ä½œï¼ŒåŒæ—¶è®°å½•æ“ä½œå‘˜çš„å¤´éƒ¨è¿åŠ¨å’Œæ§åˆ¶å™¨æ•°æ®ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œç³»ç»Ÿå¯ä»¥å­¦ä¹ åˆ°äººç±»æ“ä½œä¸­çš„ä¸»åŠ¨æ„ŸçŸ¥ï¼Œå¹¶å°†è¿™äº›çŸ¥è¯†è¿ç§»åˆ°æœºå™¨äººä¸Šã€‚è¿™æ ·è®¾è®¡çš„ç›®çš„æ˜¯ä¸ºäº†å…‹æœç°æœ‰æ–¹æ³•åœ¨æ•°æ®è·å–å’Œæ³›åŒ–èƒ½åŠ›æ–¹é¢çš„ä¸è¶³ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šActiveUMIç³»ç»Ÿä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) ä¾¿æºå¼VRé¥æ“ä½œå¥—ä»¶ï¼ŒåŒ…æ‹¬å¤´æˆ´å¼æ˜¾ç¤ºå™¨å’Œä¼ æ„Ÿå™¨æ§åˆ¶å™¨ï¼›2) æ²‰æµ¸å¼3Dæ¨¡å‹æ¸²æŸ“æ¨¡å—ï¼Œç”¨äºåˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼›3) æ•°æ®é‡‡é›†æ¨¡å—ï¼Œç”¨äºè®°å½•æ“ä½œå‘˜çš„å¤´éƒ¨è¿åŠ¨å’Œæ§åˆ¶å™¨æ•°æ®ï¼›4) ç­–ç•¥å­¦ä¹ æ¨¡å—ï¼Œç”¨äºè®­ç»ƒæœºå™¨äººæ“ä½œç­–ç•¥ã€‚æ•´ä¸ªæµç¨‹æ˜¯ï¼šæ“ä½œå‘˜ä½©æˆ´VRè®¾å¤‡åœ¨è™šæ‹Ÿç¯å¢ƒä¸­è¿›è¡Œæ“ä½œï¼Œç³»ç»Ÿè®°å½•æ•°æ®ï¼Œç„¶åä½¿ç”¨è¿™äº›æ•°æ®è®­ç»ƒæœºå™¨äººç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šActiveUMIæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæ•æ‰ä¸»åŠ¨æ„ŸçŸ¥ã€‚é€šè¿‡è®°å½•æ“ä½œå‘˜çš„å¤´éƒ¨è¿åŠ¨ï¼Œç³»ç»Ÿå¯ä»¥å­¦ä¹ åˆ°è§†è§‰æ³¨æ„åŠ›å’Œæ“ä½œä¹‹é—´çš„è”ç³»ã€‚è¿™ä¸ç°æœ‰æ–¹æ³•åªå…³æ³¨æ“ä½œè½¨è¿¹ä¸åŒï¼ŒActiveUMIèƒ½å¤Ÿè®©æœºå™¨äººåƒäººç±»ä¸€æ ·ï¼Œæ ¹æ®è§†è§‰ä¿¡æ¯è°ƒæ•´æ“ä½œç­–ç•¥ã€‚

**å…³é”®è®¾è®¡**ï¼šActiveUMIçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨ä¼ æ„Ÿå™¨æ§åˆ¶å™¨ç²¾ç¡®å¯¹é½äºº-æœºå™¨äººè¿åŠ¨å­¦ï¼›2) è®¾è®¡é«˜æ•ˆçš„æ ¡å‡†æ–¹æ³•ï¼Œç¡®ä¿æ•°æ®è´¨é‡ï¼›3) ä½¿ç”¨æ²‰æµ¸å¼3Dæ¨¡å‹æ¸²æŸ“ï¼Œæä¾›é€¼çœŸçš„è™šæ‹Ÿç¯å¢ƒï¼›4) ä½¿ç”¨ç‹¬ç«‹çš„ç©¿æˆ´å¼è®¡ç®—æœºï¼Œä¿è¯ç³»ç»Ÿçš„ç§»åŠ¨æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä»…ä½¿ç”¨ActiveUMIæ•°æ®è®­ç»ƒçš„ç­–ç•¥åœ¨åŒåˆ†å¸ƒä»»åŠ¡ä¸Šå¹³å‡æˆåŠŸç‡è¾¾åˆ°70%ï¼Œåœ¨æ–°ç‰©ä½“å’Œæ–°ç¯å¢ƒä¸­æµ‹è¯•æ—¶ä»ä¿æŒ56%çš„æˆåŠŸç‡ã€‚è¿™è¡¨æ˜ActiveUMIèƒ½å¤Ÿæœ‰æ•ˆåœ°æ•æ‰äººç±»æ“ä½œä¸­çš„ä¸»åŠ¨æ„ŸçŸ¥ï¼Œå¹¶å°†å…¶è¿ç§»åˆ°æœºå™¨äººä¸Šï¼Œä»è€Œæé«˜æœºå™¨äººçš„æ³›åŒ–èƒ½åŠ›ã€‚ç›¸æ¯”äºå…¶ä»–æ•°æ®æ”¶é›†æ–¹æ³•ï¼ŒActiveUMIå…·æœ‰æ›´é«˜çš„æ•ˆç‡å’Œæ›´ä½çš„æˆæœ¬ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ActiveUMIæŠ€æœ¯å¯åº”ç”¨äºå„ç§éœ€è¦å¤æ‚åŒæ‰‹åŠ¨æ“ä½œçš„æœºå™¨äººä»»åŠ¡ï¼Œä¾‹å¦‚ï¼šè¿œç¨‹åŒ»ç–—æ‰‹æœ¯ã€å±é™©ç¯å¢ƒä¸‹çš„ç‰©ä½“å¤„ç†ã€å®¶åº­æœåŠ¡æœºå™¨äººç­‰ã€‚è¯¥æŠ€æœ¯èƒ½å¤Ÿé™ä½æœºå™¨äººæ“ä½œå­¦ä¹ çš„æˆæœ¬ï¼Œæé«˜æœºå™¨äººçš„æ³›åŒ–èƒ½åŠ›ï¼ŒåŠ é€Ÿæœºå™¨äººåœ¨å®é™…åœºæ™¯ä¸­çš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present ActiveUMI, a framework for a data collection system that transfers in-the-wild human demonstrations to robots capable of complex bimanual manipulation. ActiveUMI couples a portable VR teleoperation kit with sensorized controllers that mirror the robot's end-effectors, bridging human-robot kinematics via precise pose alignment. To ensure mobility and data quality, we introduce several key techniques, including immersive 3D model rendering, a self-contained wearable computer, and efficient calibration methods. ActiveUMI's defining feature is its capture of active, egocentric perception. By recording an operator's deliberate head movements via a head-mounted display, our system learns the crucial link between visual attention and manipulation. We evaluate ActiveUMI on six challenging bimanual tasks. Policies trained exclusively on ActiveUMI data achieve an average success rate of 70\% on in-distribution tasks and demonstrate strong generalization, retaining a 56\% success rate when tested on novel objects and in new environments. Our results demonstrate that portable data collection systems, when coupled with learned active perception, provide an effective and scalable pathway toward creating generalizable and highly capable real-world robot policies.

