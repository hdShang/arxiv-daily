---
layout: default
title: "FailSafe: Reasoning and Recovery from Failures in Vision-Language-Action Models"
---

# FailSafe: Reasoning and Recovery from Failures in Vision-Language-Action Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.01642" class="toolbar-btn" target="_blank">üìÑ arXiv: 2510.01642v2</a>
  <a href="https://arxiv.org/pdf/2510.01642.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.01642v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.01642v2', 'FailSafe: Reasoning and Recovery from Failures in Vision-Language-Action Models')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Zijun Lin, Jiafei Duan, Haoquan Fang, Dieter Fox, Ranjay Krishna, Cheston Tan, Bihan Wen

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-10-02 (Êõ¥Êñ∞: 2025-10-27)

**Â§áÊ≥®**: Project Page: https://jimntu.github.io/FailSafe

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**FailSafeÔºö‰∏∫ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°ÂûãÊûÑÂª∫Â§±Ë¥•Êé®ÁêÜ‰∏éÊÅ¢Â§çÁ≥ªÁªü**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°Âûã` `Êú∫Âô®‰∫∫Êìç‰Ωú` `Â§±Ë¥•ÊÅ¢Â§ç` `Êï∞ÊçÆÂ¢ûÂº∫` `LLaVa` `Ê®°ÊãüÁéØÂ¢É` `È≤ÅÊ£íÊÄß` `Ëá™Âä®Âåñ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâVLAÊ®°ÂûãÂú®Êú∫Âô®‰∫∫Êìç‰Ωú‰∏≠ÊòìÂ§±Ë¥•ÔºåÁº∫‰πèÊúâÊïàÁöÑÂ§±Ë¥•ÊÅ¢Â§çÊú∫Âà∂ÔºåÈòªÁ¢ç‰∫ÜÂÖ∂Âú®ÂÆûÈôÖÂú∫ÊôØ‰∏≠ÁöÑÂ∫îÁî®„ÄÇ
2. FailSafeÁ≥ªÁªüËá™Âä®ÁîüÊàêÂ§öÊ†∑ÂåñÁöÑÂ§±Ë¥•Ê°à‰æãÂíåÂèØÊâßË°åÁöÑÊÅ¢Â§çÂä®‰ΩúÔºå‰∏∫VLAÊ®°ÂûãÊèê‰æõÂ§±Ë¥•Â≠¶‰π†Êï∞ÊçÆ„ÄÇ
3. FailSafe-VLMÊòæËëóÊèêÂçá‰∫ÜÁé∞ÊúâVLAÊ®°ÂûãÂú®Â§±Ë¥•Âú∫ÊôØ‰∏ãÁöÑÊÄßËÉΩÔºåÂπ∂Âú®‰∏çÂêåÈÖçÁΩÆ‰∏≠Ë°®Áé∞Âá∫ËâØÂ•ΩÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫FailSafeÔºå‰∏ÄÁßçÊñ∞È¢ñÁöÑÂ§±Ë¥•ÁîüÊàê‰∏éÊÅ¢Â§çÁ≥ªÁªüÔºåÊó®Âú®Ëß£ÂÜ≥ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰Ωú(VLA)Ê®°ÂûãÂú®Êú∫Âô®‰∫∫Êìç‰Ωú‰∏≠ÈÅáÂà∞ÁöÑÂ§±Ë¥•ÈóÆÈ¢ò„ÄÇFailSafeËÉΩÂ§üËá™Âä®ÁîüÊàêÂ§öÊ†∑ÂåñÁöÑÂ§±Ë¥•Ê°à‰æãÔºåÂπ∂Êèê‰æõÂèØÊâßË°åÁöÑÊÅ¢Â§çÂä®‰ΩúÔºåÂèØÊó†ÁºùÂ∫îÁî®‰∫é‰ªª‰ΩïÊ®°ÊãüÂô®‰∏≠ÁöÑÊìç‰Ωú‰ªªÂä°ÔºåÂÆûÁé∞Â§±Ë¥•Âä®‰ΩúÊï∞ÊçÆÁöÑÂèØÊâ©Â±ïÂàõÂª∫„ÄÇ‰∏∫È™åËØÅÂÖ∂ÊúâÊïàÊÄßÔºåËÆ∫ÊñáÂØπLLaVa-OneVision-7B (LLaVa-OV-7B)ËøõË°åÂæÆË∞ÉÔºåÊûÑÂª∫‰∫ÜFailSafe-VLM„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåFailSafe-VLMÊàêÂäüÂ∏ÆÂä©Êú∫Ê¢∞ËáÇÊ£ÄÊµãÂíåÊÅ¢Â§çÊΩúÂú®ÁöÑÂ§±Ë¥•ÔºåÂú®ManiskillÁöÑÂ§ö‰∏™‰ªªÂä°‰∏≠ÔºåÂ∞Ü‰∏âÁßçÊúÄÂÖàËøõÁöÑVLAÊ®°Âûã(pi0-FAST, OpenVLA, OpenVLA-OFT)ÁöÑÊÄßËÉΩÂπ≥ÂùáÊèêÈ´ò‰∫ÜÈ´òËææ22.6%„ÄÇÊ≠§Â§ñÔºåFailSafe-VLMÂèØ‰ª•Êé®ÂπøÂà∞‰∏çÂêåÁöÑÁ©∫Èó¥ÈÖçÁΩÆ„ÄÅÁõ∏Êú∫ËßÜËßí„ÄÅÁâ©‰ΩìÂíåÊú∫Âô®‰∫∫ÂΩ¢ÊÄÅ„ÄÇFailSafe‰ª£Á†ÅËÆ°ÂàíÂºÄÊ∫ê„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâËßÜËßâ-ËØ≠Ë®Ä-Âä®‰Ωú(VLA)Ê®°ÂûãÂú®Êú∫Âô®‰∫∫Êìç‰Ωú‰∏≠ÔºåÂ∞ΩÁÆ°ÈÄöËøáÂ§ßËßÑÊ®°Êï∞ÊçÆÈõÜËÆ≠ÁªÉÂèñÂæó‰∫ÜÊòæËëóËøõÂ±ïÔºå‰ΩÜ‰ªçÁÑ∂‰∏çÂèØÈÅøÂÖçÂú∞‰ºöÈÅáÂà∞Â§±Ë¥•„ÄÇÁé∞ÊúâÁöÑÊú∫Âô®‰∫∫Êìç‰ΩúÊï∞ÊçÆÈõÜ‰∏ªË¶ÅÊèê‰æõground-truthËΩ®ËøπÔºå‰∏ÄÊó¶ÂèëÁîüÂ§±Ë¥•ÔºåÊú∫Âô®‰∫∫Êó†Ê≥ïÊÅ¢Â§ç„ÄÇÂ∞ëÊï∞ÂÖ≥Ê≥®Â§±Ë¥•Ê£ÄÊµãÁöÑÊï∞ÊçÆÈõÜ‰ªÖÊèê‰æõÊñáÊú¨Ëß£ÈáäÔºåÈöæ‰ª•Áõ¥Êé•Áî®‰∫éVLAÊ®°Âûã„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöFailSafeÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØËá™Âä®ÁîüÊàêÂåÖÂê´Â§±Ë¥•Ê°à‰æãÂíåÂØπÂ∫îÊÅ¢Â§çÂä®‰ΩúÁöÑÊï∞ÊçÆÈõÜÔºå‰ªéËÄå‰ΩøVLAÊ®°ÂûãËÉΩÂ§üÂ≠¶‰π†ËØÜÂà´Â§±Ë¥•Âπ∂ÈááÂèñÈÄÇÂΩìÁöÑÊÅ¢Â§çÊé™ÊñΩ„ÄÇÈÄöËøáÂú®Ê®°ÊãüÁéØÂ¢É‰∏≠ÂºïÂÖ•Êâ∞Âä®ÊàñÈîôËØØÊìç‰ΩúÔºåÂπ∂ËÆæËÆ°Áõ∏Â∫îÁöÑÊÅ¢Â§çÁ≠ñÁï•ÔºåFailSafeËÉΩÂ§üÂàõÂª∫Â§öÊ†∑ÂåñÁöÑÂ§±Ë¥•Âú∫ÊôØ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöFailSafeÁ≥ªÁªüÂåÖÂê´‰ª•‰∏ã‰∏ªË¶ÅÊ®°ÂùóÔºö1) Â§±Ë¥•ÁîüÊàêÊ®°ÂùóÔºöÈÄöËøáÈöèÊú∫ÊàñÈ¢ÑÂÆö‰πâÁöÑÁ≠ñÁï•ÔºåÂú®Ê®°ÊãüÁéØÂ¢É‰∏≠ÂºïÂÖ•ÈîôËØØÊìç‰ΩúÔºåÂØºËá¥‰ªªÂä°Â§±Ë¥•„ÄÇ2) ÊÅ¢Â§çÂä®‰ΩúÁîüÊàêÊ®°ÂùóÔºöÈíàÂØπÊØèÁßçÂ§±Ë¥•ÊÉÖÂÜµÔºåËÆæËÆ°Âπ∂ÊâßË°åÁõ∏Â∫îÁöÑÊÅ¢Â§çÂä®‰ΩúÔºå‰ΩøÊú∫Âô®‰∫∫ËÉΩÂ§üÂõûÂà∞Ê≠£Â∏∏Áä∂ÊÄÅ„ÄÇ3) Êï∞ÊçÆËÆ∞ÂΩïÊ®°ÂùóÔºöËÆ∞ÂΩïÂ§±Ë¥•ÂèëÁîüÊó∂ÁöÑÁä∂ÊÄÅ„ÄÅÂ§±Ë¥•Á±ªÂûã‰ª•ÂèäÊÅ¢Â§çÂä®‰ΩúÂ∫èÂàóÔºåÂΩ¢ÊàêÂ§±Ë¥•ÊÅ¢Â§çÊï∞ÊçÆÈõÜ„ÄÇËØ•Êï∞ÊçÆÈõÜÁî®‰∫éËÆ≠ÁªÉVLAÊ®°Âûã„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöFailSafeÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂Ëá™Âä®ÂåñÁöÑÂ§±Ë¥•ÁîüÊàêÂíåÊÅ¢Â§çÂä®‰ΩúÁîüÊàêÊú∫Âà∂„ÄÇ‰∏éÊâãÂä®Ê†áÊ≥®Â§±Ë¥•Ê°à‰æãÂíåÊÅ¢Â§çÁ≠ñÁï•Áõ∏ÊØîÔºåFailSafeËÉΩÂ§üÈ´òÊïàÂú∞ÁîüÊàêÂ§ßËßÑÊ®°„ÄÅÂ§öÊ†∑ÂåñÁöÑÂ§±Ë¥•Êï∞ÊçÆÔºå‰ªéËÄåÊòæËëóÊèêÂçáVLAÊ®°ÂûãÁöÑÈ≤ÅÊ£íÊÄßÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåFailSafeÊèê‰æõÁöÑÊÅ¢Â§çÂä®‰ΩúÊòØÂèØÊâßË°åÁöÑÔºåÂèØ‰ª•Áõ¥Êé•Áî®‰∫éËÆ≠ÁªÉVLAÊ®°ÂûãÁöÑÂä®‰ΩúÁ≠ñÁï•„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöFailSafeÁöÑÂÖ∑‰ΩìÂÆûÁé∞‰æùËµñ‰∫éÊâÄ‰ΩøÁî®ÁöÑÊ®°ÊãüÂô®ÂíåÊú∫Âô®‰∫∫Âπ≥Âè∞„ÄÇÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) Â§±Ë¥•ÁîüÊàêÁ≠ñÁï•Ôºö‰æãÂ¶ÇÔºåÈöèÊú∫ÊñΩÂä†Â§ñÂäõ„ÄÅÈîôËØØÊäìÂèñ„ÄÅÁ¢∞ÊíûÁ≠â„ÄÇ2) ÊÅ¢Â§çÂä®‰ΩúËÆæËÆ°Ôºö‰æãÂ¶ÇÔºåÈáçÊñ∞ËßÑÂàíËΩ®Ëøπ„ÄÅË∞ÉÊï¥ÊäìÂèñÂßøÊÄÅ„ÄÅÈÅøÈöúÁ≠â„ÄÇ3) Êï∞ÊçÆÈõÜÊ†ºÂºèÔºöÂåÖÂê´Â§±Ë¥•ÂèëÁîüÊó∂ÁöÑÂõæÂÉè„ÄÅÊñáÊú¨ÊèèËø∞„ÄÅÊú∫Âô®‰∫∫Áä∂ÊÄÅ‰ª•ÂèäÊÅ¢Â§çÂä®‰ΩúÂ∫èÂàó„ÄÇËÆ∫Êñá‰ΩøÁî®LLaVa-OV-7B‰Ωú‰∏∫VLMÔºåÂπ∂‰ΩøÁî®ÁîüÊàêÁöÑFailSafeÊï∞ÊçÆÈõÜËøõË°åÂæÆË∞É„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåFailSafe-VLMÊòæËëóÊèêÂçá‰∫ÜÁé∞ÊúâVLAÊ®°ÂûãÂú®Â§±Ë¥•Âú∫ÊôØ‰∏ãÁöÑÊÄßËÉΩ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÂú®ManiskillÁöÑÂ§ö‰∏™‰ªªÂä°‰∏≠ÔºåFailSafe-VLMÂ∞Üpi0-FAST„ÄÅOpenVLAÂíåOpenVLA-OFT‰∏âÁßçÊúÄÂÖàËøõÁöÑVLAÊ®°ÂûãÁöÑÊÄßËÉΩÂπ≥ÂùáÊèêÈ´ò‰∫ÜÈ´òËææ22.6%„ÄÇÊ≠§Â§ñÔºåÂÆûÈ™åËøòËØÅÊòé‰∫ÜFailSafe-VLMÂú®‰∏çÂêåÁ©∫Èó¥ÈÖçÁΩÆ„ÄÅÁõ∏Êú∫ËßÜËßí„ÄÅÁâ©‰ΩìÂíåÊú∫Âô®‰∫∫ÂΩ¢ÊÄÅ‰∏ãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

FailSafeÊäÄÊúØÂèØÂπøÊ≥õÂ∫îÁî®‰∫éÂêÑÁßçÊú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°Ôºå‰æãÂ¶ÇÁâ©‰ΩìÊäìÂèñ„ÄÅË£ÖÈÖç„ÄÅÂØºËà™Á≠â„ÄÇÈÄöËøáÊèêÈ´òÊú∫Âô®‰∫∫Âú®Â§çÊùÇÂíå‰∏çÁ°ÆÂÆöÁéØÂ¢É‰∏≠ÁöÑÈ≤ÅÊ£íÊÄßÂíåÂèØÈù†ÊÄßÔºåFailSafeÊúâÂä©‰∫éÊé®Âä®Êú∫Âô®‰∫∫ÊäÄÊúØÂú®Â∑•‰∏öËá™Âä®Âåñ„ÄÅÂÆ∂Â∫≠ÊúçÂä°„ÄÅÂåªÁñó‰øùÂÅ•Á≠âÈ¢ÜÂüüÁöÑÂ∫îÁî®„ÄÇÊú™Êù•ÔºåFailSafeÂèØ‰ª•Êâ©Â±ïÂà∞Êõ¥Â§çÊùÇÁöÑ‰ªªÂä°ÂíåÁéØÂ¢ÉÔºåÂπ∂‰∏éÂÖ∂‰ªñÊú∫Âô®‰∫∫Â≠¶‰π†ÊäÄÊúØÁõ∏ÁªìÂêàÔºåÂÆûÁé∞Êõ¥Êô∫ËÉΩ„ÄÅÊõ¥Ëá™‰∏ªÁöÑÊú∫Âô®‰∫∫Á≥ªÁªü„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Recent advances in robotic manipulation have integrated low-level robotic control into Vision-Language Models (VLMs), extending them into Vision-Language-Action (VLA) models. Although state-of-the-art VLAs achieve strong performance in downstream robotic applications, supported by large-scale crowd-sourced robot training data, they still inevitably encounter failures during execution. Enabling robots to reason and recover from unpredictable and abrupt failures remains a critical challenge. Existing robotic manipulation datasets, collected in either simulation or the real world, primarily provide only ground-truth trajectories, leaving robots unable to recover once failures occur. Moreover, the few datasets that address failure detection typically offer only textual explanations, which are difficult to utilize directly in VLA models. To address this gap, we introduce FailSafe, a novel failure generation and recovery system that automatically produces diverse failure cases paired with executable recovery actions. FailSafe can be seamlessly applied to any manipulation task in any simulator, enabling scalable creation of failure action data. To demonstrate its effectiveness, we fine-tune LLaVa-OneVision-7B (LLaVa-OV-7B) to build FailSafe-VLM. Experimental results show that FailSafe-VLM successfully helps robotic arms detect and recover from potential failures, improving the performance of three state-of-the-art VLA models (pi0-FAST, OpenVLA, OpenVLA-OFT) by up to 22.6% on average across several tasks in Maniskill. Furthermore, FailSafe-VLM could generalize across different spatial configurations, camera viewpoints, object and robotic embodiments. We plan to release the FailSafe code to the community.

