{
    "papers": [
        {
            "title": "Odyssey: An Automotive Lidar-Inertial Odometry Dataset for GNSS-denied situations",
            "authors": [
                "Aaron Kurda",
                "Simon Steuernagel",
                "Lukas Jung",
                "Marcus Baum"
            ],
            "arxiv_id": "2512.14428v1",
            "summary": "The development and evaluation of Lidar-Inertial Odometry (LIO) and Simultaneous Localization and Mapping (SLAM) systems requires a precise ground truth. The Global Navigation Satellite System (GNSS) is often used as a foundation for this, but its signals can be unreliable in obstructed environments due to multi-path effects or loss-of-signal. While existing datasets compensate for the sporadic loss of GNSS signals by incorporating Inertial Measurement Unit (IMU) measurements, the commonly used Micro-Electro-Mechanical Systems (MEMS) or Fiber Optic Gyroscope (FOG)-based systems do not permit the prolonged study of GNSS-denied environments. To close this gap, we present Odyssey, a LIO dataset with a focus on GNSS-denied environments such as tunnels and parking garages as well as other underrepresented, yet ubiquitous situations such as stop-and-go-traffic, bumpy roads and wide open fields. Our ground truth is derived from a navigation-grade Inertial Navigation System (INS) equipped with a Ring Laser Gyroscope (RLG), offering exceptional bias stability characteristics compared to IMUs used in existing datasets and enabling the prolonged and accurate study of GNSS-denied environments. This makes Odyssey the first publicly available dataset featuring a RLG-based INS. Besides providing data for LIO, we also support other tasks, such as place recognition, through the threefold repetition of all trajectories as well as the integration of external mapping data by providing precise geodetic coordinates. All data, dataloader and other material is available online at https://odyssey.uni-goettingen.de/ .",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "9 pages, 4 figures, submitted to International Journal of Robotics Research (IJRR)",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14428v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "自动驾驶",
                    "matched_keywords": [
                        "traffic",
                        "lidar"
                    ],
                    "score": 2
                },
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "SLAM",
                        "localization",
                        "mapping"
                    ],
                    "score": 3
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL",
                        "PPO"
                    ],
                    "score": 2
                }
            ],
            "relevance_score": 7,
            "headline_zh": "提出Odyssey数据集，基于环形激光陀螺仪惯性导航系统，为GNSS信号缺失环境下的激光雷达-惯性里程计研究提供高精度地面真值。",
            "summary_zh": "激光雷达-惯性里程计（LIO）和同时定位与建图（SLAM）系统的开发与评估需要精确的地面真值。全球导航卫星系统（GNSS）常被用作基础，但其信号在遮挡环境中可能因多径效应或信号丢失而不可靠。现有数据集通过集成惯性测量单元（IMU）测量来补偿GNSS信号的偶发性丢失，但常用的微机电系统（MEMS）或光纤陀螺仪（FOG）系统无法支持对GNSS缺失环境的长期研究。为填补这一空白，我们提出了Odyssey，一个专注于GNSS缺失环境（如隧道和停车场）以及其他代表性不足但普遍存在场景（如启停交通、颠簸道路和开阔田野）的LIO数据集。我们的地面真值源自配备环形激光陀螺仪（RLG）的导航级惯性导航系统（INS），相比现有数据集使用的IMU，具有卓越的偏置稳定性特性，支持对GNSS缺失环境的长期准确研究。这使得Odyssey成为首个公开可用的基于RLG的INS数据集。除了为LIO提供数据外，我们还通过三次重复所有轨迹以及提供精确大地坐标集成外部地图数据，支持其他任务，如地点识别。所有数据、数据加载器和其他材料可在https://odyssey.uni-goettingen.de/在线获取。",
            "intro_zh": [
                "核心问题：现有数据集依赖GNSS作为地面真值，但在遮挡环境中信号不可靠，且常用IMU系统（如MEMS或FOG）偏置稳定性不足，无法支持GNSS缺失环境的长期研究。",
                "方法要点：提出Odyssey数据集，采用基于环形激光陀螺仪的导航级惯性导航系统提供高精度地面真值，专注于隧道、停车场等GNSS缺失场景。",
                "实验或效果：数据集首次公开基于RLG的INS数据，支持LIO、SLAM和地点识别等任务，通过重复轨迹和地理坐标增强实用性。"
            ],
            "method_zh": "论文的核心方法是构建Odyssey数据集，其整体框架包括数据采集、处理和发布。关键技术创新点在于使用配备环形激光陀螺仪的导航级惯性导航系统作为地面真值源，相比现有数据集中的微机电系统或光纤陀螺仪，RLG具有更高的偏置稳定性，能提供更准确和长期的姿态估计。与现有方法的主要区别在于：Odyssey专注于GNSS缺失环境（如隧道、停车场），并覆盖启停交通、颠簸道路等代表性不足场景；通过三次重复轨迹和集成外部地图数据，支持地点识别等扩展任务；数据集公开可用，填补了长期GNSS缺失研究的数据空白。",
            "application_zh": "该研究主要应用于自动驾驶和机器人领域，特别是在GNSS信号受限或缺失的环境（如城市隧道、地下停车场、山区道路）中，为激光雷达-惯性里程计和同时定位与建图系统的开发、测试和评估提供基准数据。此外，数据集支持地点识别、地图构建和传感器融合算法的研究，提升定位精度和鲁棒性。",
            "highlight_zh": "最重要的实验亮点是Odyssey数据集首次公开基于环形激光陀螺仪的惯性导航系统数据，相比现有数据集，其地面真值在偏置稳定性上显著提升，支持对GNSS缺失环境的长期准确研究。数据集覆盖多样场景，并通过重复轨迹增强实用性，为LIO和SLAM算法提供了更可靠的评估基准。",
            "tags_zh": [
                "激光雷达-惯性里程计",
                "同时定位与建图",
                "惯性导航系统",
                "环形激光陀螺仪",
                "GNSS缺失环境",
                "自动驾驶数据集",
                "地点识别",
                "传感器融合"
            ],
            "_index": 0
        },
        {
            "title": "A data-physics hybrid generative model for patient-specific post-stroke motor rehabilitation using wearable sensor data",
            "authors": [
                "Yanning Dai",
                "Chenyu Tang",
                "Ruizhi Zhang",
                "Wenyu Yang",
                "Yilan Zhang",
                "Yuhui Wang",
                "Junliang Chen",
                "Xuhang Chen",
                "Ruimou Xie",
                "Yangyue Cao",
                "Qiaoying Li",
                "Jin Cao",
                "Tao Li",
                "Hubin Zhao",
                "Yu Pan",
                "Arokia Nathan",
                "Xin Gao",
                "Peter Smielewski",
                "Shuo Gao"
            ],
            "arxiv_id": "2512.14329v1",
            "summary": "Dynamic prediction of locomotor capacity after stroke is crucial for tailoring rehabilitation, yet current assessments provide only static impairment scores and do not indicate whether patients can safely perform specific tasks such as slope walking or stair climbing. Here, we develop a data-physics hybrid generative framework that reconstructs an individual stroke survivor's neuromuscular control from a single 20 m level-ground walking trial and predicts task-conditioned locomotion across rehabilitation scenarios. The system combines wearable-sensor kinematics, a proportional-derivative physics controller, a population Healthy Motion Atlas, and goal-conditioned deep reinforcement learning with behaviour cloning and generative adversarial imitation learning to generate physically plausible, patient-specific gait simulations for slopes and stairs. In 11 stroke survivors, the personalized controllers preserved idiosyncratic gait patterns while improving joint-angle and endpoint fidelity by 4.73% and 12.10%, respectively, and reducing training time to 25.56% relative to a physics-only baseline. In a multicentre pilot involving 21 inpatients, clinicians who used our locomotion predictions to guide task selection and difficulty obtained larger gains in Fugl-Meyer lower-extremity scores over 28 days of standard rehabilitation than control clinicians (mean change 6.0 versus 3.7 points). These findings indicate that our generative, task-predictive framework can augment clinical decision-making in post-stroke gait rehabilitation and provide a template for dynamically personalized motor recovery strategies.",
            "categories": [
                "cs.CE",
                "cs.AI"
            ],
            "primary_category": "cs.CE",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "26 pages, 6 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14329v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "人形机器人",
                    "matched_keywords": [
                        "imitation learning",
                        "atlas"
                    ],
                    "score": 2
                },
                {
                    "name": "动作生成",
                    "matched_keywords": [
                        "motion prediction"
                    ],
                    "score": 1
                },
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO",
                        "VIO"
                    ],
                    "score": 2
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "reinforcement learning",
                        "imitation learning"
                    ],
                    "score": 2
                }
            ],
            "relevance_score": 7,
            "headline_zh": "提出数据-物理混合生成框架，基于单次平地行走数据预测中风患者个性化康复任务中的步态模拟，以增强临床决策。",
            "summary_zh": "中风后运动能力的动态预测对于定制康复至关重要，但当前评估仅提供静态损伤评分，无法指示患者是否能安全执行特定任务，如斜坡行走或爬楼梯。本文开发了一个数据-物理混合生成框架，通过单次20米平地行走试验重建个体中风幸存者的神经肌肉控制，并预测康复场景中的任务条件运动。该系统结合了可穿戴传感器运动学、比例-微分物理控制器、健康人群运动图谱，以及基于目标条件的深度强化学习与行为克隆和生成对抗模仿学习，生成物理上合理、患者特定的斜坡和楼梯步态模拟。在11名中风幸存者中，个性化控制器保留了独特步态模式，同时将关节角度和端点保真度分别提高了4.73%和12.10%，并将训练时间减少到仅物理基线的25.56%。在一项涉及21名住院患者的多中心试点中，使用我们的运动预测指导任务选择和难度的临床医生，在28天标准康复期间获得的Fugl-Meyer下肢评分增益大于对照组临床医生（平均变化6.0分对3.7分）。这些发现表明，我们的生成性任务预测框架可以增强中风后步态康复的临床决策，并为动态个性化运动恢复策略提供模板。",
            "intro_zh": [
                "核心问题：现有中风康复评估仅提供静态损伤评分，无法动态预测患者执行特定任务（如斜坡行走）的能力，限制了康复方案的个性化定制。",
                "方法要点：提出数据-物理混合生成框架，结合可穿戴传感器数据、物理控制器和深度学习，从单次平地行走重建患者神经肌肉控制，并生成任务条件步态模拟。",
                "实验或效果：在11名患者中，个性化控制器提升关节角度和端点保真度，减少训练时间；多中心试点显示临床使用后患者康复评分显著提高。"
            ],
            "method_zh": "论文提出一个数据-物理混合生成框架，整体架构包括：基于可穿戴传感器采集的运动学数据，结合比例-微分物理控制器模拟生物力学约束，利用健康人群运动图谱作为参考基准，并通过目标条件深度强化学习（结合行为克隆和生成对抗模仿学习）生成个性化步态模拟。关键技术创新点在于融合数据驱动与物理模型，实现从单次平地行走数据重建患者特异性神经肌肉控制，并预测不同康复任务（如斜坡、楼梯）下的运动。与现有方法的主要区别在于，传统方法多依赖静态评估或纯物理模拟，而本框架通过混合方法提高了模拟的物理合理性和个性化程度，同时减少了数据需求和训练时间。",
            "application_zh": "该研究主要应用于中风后运动康复领域，潜在价值包括：为临床医生提供动态预测工具，指导个性化康复任务选择和难度调整；作为模板推广到其他神经系统疾病或运动障碍的康复策略中，提升康复效率和效果。",
            "highlight_zh": "最重要的实验结果：在11名中风患者中，个性化控制器将关节角度和端点保真度分别提升4.73%和12.10%，训练时间减少至基线25.56%；多中心试点中，使用预测的临床医生组患者Fugl-Meyer评分平均增益达6.0分，显著高于对照组的3.7分，验证了框架的临床有效性。",
            "tags_zh": [
                "数据-物理混合模型",
                "个性化康复",
                "步态模拟",
                "深度强化学习",
                "可穿戴传感器",
                "中风康复",
                "生成对抗模仿学习",
                "临床决策支持"
            ],
            "_index": 1
        },
        {
            "title": "SUPER -- A Framework for Sensitivity-based Uncertainty-aware Performance and Risk Assessment in Visual Inertial Odometry",
            "authors": [
                "Johannes A. Gaus",
                "Daniel Häufle",
                "Woo-Jeong Baek"
            ],
            "arxiv_id": "2512.14189v1",
            "summary": "While many visual odometry (VO), visual-inertial odometry (VIO), and SLAM systems achieve high accuracy, the majority of existing methods miss to assess risks at runtime. This paper presents SUPER (Sensitivity-based Uncertainty-aware PErformance and Risk assessment) that is a generic and explainable framework that propagates uncertainties via sensitivities for real-time risk assessment in VIO. The scientific novelty lies in the derivation of a real-time risk indicator that is backend-agnostic and exploits the Schur complement blocks of the Gauss-Newton normal matrix to propagate uncertainties. Practically, the Schur complement captures the sensitivity that reflects the influence of the uncertainty on the risk occurrence. Our framework estimates risks on the basis of the residual magnitudes, geometric conditioning, and short horizon temporal trends without requiring ground truth knowledge. Our framework enables to reliably predict trajectory degradation 50 frames ahead with an improvement of 20% to the baseline. In addition, SUPER initiates a stop or relocalization policy with 89.1% recall. The framework is backend agnostic and operates in real time with less than 0.2% additional CPU cost. Experiments show that SUPER provides consistent uncertainty estimates. A SLAM evaluation highlights the applicability to long horizon mapping.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14189v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "visual odometry",
                        "VO",
                        "VIO",
                        "visual-inertial",
                        "SLAM",
                        "localization",
                        "mapping"
                    ],
                    "score": 7
                }
            ],
            "relevance_score": 7,
            "headline_zh": "提出SUPER框架，通过灵敏度传播不确定性，实现视觉惯性里程计中的实时风险与性能评估。",
            "summary_zh": "尽管许多视觉里程计（VO）、视觉惯性里程计（VIO）和SLAM系统实现了高精度，但现有方法大多未能在运行时评估风险。本文提出了SUPER（基于灵敏度的不确定性感知性能与风险评估）框架，这是一个通用且可解释的框架，通过灵敏度传播不确定性，用于VIO中的实时风险评估。科学创新在于推导了一个实时风险指标，该指标与后端无关，并利用高斯-牛顿正规矩阵的舒尔补块来传播不确定性。实际上，舒尔补捕获了反映不确定性对风险发生影响的灵敏度。我们的框架基于残差大小、几何条件和短期时间趋势估计风险，无需地面真值知识。该框架能够可靠地预测50帧前的轨迹退化，比基线提升20%。此外，SUPER以89.1%的召回率启动停止或重定位策略。框架与后端无关，实时运行，额外CPU成本低于0.2%。实验表明，SUPER提供一致的不确定性估计。SLAM评估突出了其在长时程建图中的应用性。",
            "intro_zh": [
                "现有VIO方法虽精度高，但缺乏运行时风险评估能力，导致系统在不确定环境中易失效。",
                "SUPER框架利用舒尔补块传播不确定性，基于残差、几何条件和时间趋势实时评估风险，无需地面真值。",
                "实验显示，SUPER能提前50帧预测轨迹退化，提升20%性能，并以89.1%召回率启动安全策略，额外CPU成本低。"
            ],
            "method_zh": "SUPER是一个通用框架，通过灵敏度分析传播不确定性进行实时风险评估。整体框架基于高斯-牛顿优化，利用舒尔补块计算灵敏度，反映不确定性对风险的影响。关键创新在于推导了后端无关的实时风险指标，结合残差大小、几何条件和短期时间趋势估计风险，无需依赖地面真值。与现有方法的主要区别在于，它首次将舒尔补用于不确定性传播，提供可解释的风险评估，而非仅依赖后验概率或启发式规则。",
            "application_zh": "该研究可应用于自动驾驶、无人机导航和机器人SLAM系统，增强在动态或恶劣环境中的鲁棒性，通过实时风险预警支持安全决策，如紧急停止或重定位，提升系统可靠性和自主性。",
            "highlight_zh": "SUPER能可靠预测50帧前的轨迹退化，性能比基线提升20%；以89.1%召回率启动停止或重定位策略；实时运行，额外CPU成本低于0.2%；在SLAM评估中展示长时程建图适用性，提供一致不确定性估计。",
            "tags_zh": [
                "视觉惯性里程计",
                "不确定性传播",
                "实时风险评估",
                "舒尔补灵敏度",
                "后端无关框架",
                "轨迹退化预测",
                "SLAM应用",
                "性能评估"
            ],
            "_index": 2
        },
        {
            "title": "MMGR: Multi-Modal Generative Reasoning",
            "authors": [
                "Zefan Cai",
                "Haoyi Qiu",
                "Tianyi Ma",
                "Haozhe Zhao",
                "Gengze Zhou",
                "Kung-Hsiang Huang",
                "Parisa Kordjamshidi",
                "Minjia Zhang",
                "Xiao Wen",
                "Jiuxiang Gu",
                "Nanyun Peng",
                "Junjie Hu"
            ],
            "arxiv_id": "2512.14691v1",
            "summary": "Video foundation models generate visually realistic and temporally coherent content, but their reliability as world simulators depends on whether they capture physical, logical, and spatial constraints. Existing metrics such as Frechet Video Distance (FVD) emphasize perceptual quality and overlook reasoning failures, including violations of causality, physics, and global consistency. We introduce MMGR (Multi-Modal Generative Reasoning Evaluation and Benchmark), a principled evaluation framework based on five reasoning abilities: Physical, Logical, 3D Spatial, 2D Spatial, and Temporal. MMGR evaluates generative reasoning across three domains: Abstract Reasoning (ARC-AGI, Sudoku), Embodied Navigation (real-world 3D navigation and localization), and Physical Commonsense (sports and compositional interactions). MMGR applies fine-grained metrics that require holistic correctness across both video and image generation. We benchmark leading video models (Veo-3, Sora-2, Wan-2.2) and image models (Nano-banana, Nano-banana Pro, GPT-4o-image, Qwen-image), revealing strong performance gaps across domains. Models show moderate success on Physical Commonsense tasks but perform poorly on Abstract Reasoning (below 10 percent accuracy on ARC-AGI) and struggle with long-horizon spatial planning in embodied settings. Our analysis highlights key limitations in current models, including overreliance on perceptual data, weak global state consistency, and objectives that reward visual plausibility over causal correctness. MMGR offers a unified diagnostic benchmark and a path toward reasoning-aware generative world models.",
            "categories": [
                "cs.CL",
                "cs.CV"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "work in progress",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14691v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VIO",
                        "localization"
                    ],
                    "score": 2
                },
                {
                    "name": "世界模型",
                    "matched_keywords": [
                        "world model",
                        "world simulator"
                    ],
                    "score": 2
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL",
                        "reward"
                    ],
                    "score": 2
                }
            ],
            "relevance_score": 6,
            "headline_zh": "提出MMGR多模态生成推理评估框架，以解决现有视频基础模型在物理、逻辑和空间约束方面缺乏可靠评估的问题。",
            "summary_zh": "视频基础模型能够生成视觉逼真且时序连贯的内容，但其作为世界模拟器的可靠性取决于是否捕捉了物理、逻辑和空间约束。现有指标如弗雷歇视频距离（FVD）强调感知质量而忽视了推理失败，包括违反因果关系、物理规律和全局一致性。我们引入了MMGR（多模态生成推理评估与基准），这是一个基于五种推理能力的原则性评估框架：物理推理、逻辑推理、3D空间推理、2D空间推理和时序推理。MMGR在三个领域评估生成推理：抽象推理（ARC-AGI、数独）、具身导航（真实世界3D导航与定位）和物理常识（运动和组合交互）。MMGR应用细粒度指标，要求视频和图像生成在整体上正确。我们对领先的视频模型（Veo-3、Sora-2、Wan-2.2）和图像模型（Nano-banana、Nano-banana Pro、GPT-4o-image、Qwen-image）进行了基准测试，揭示了跨领域的显著性能差距。模型在物理常识任务上表现中等，但在抽象推理上表现不佳（ARC-AGI准确率低于10%），并在具身设置中的长时程空间规划上存在困难。我们的分析突出了当前模型的关键局限性，包括过度依赖感知数据、全局状态一致性弱，以及目标函数奖励视觉合理性而非因果正确性。MMGR提供了一个统一的诊断基准，并为推理感知的生成世界模型指明了方向。",
            "intro_zh": [
                "现有视频基础模型评估指标（如FVD）过于关注感知质量，忽视了物理、逻辑和空间推理失败，导致模型作为世界模拟器的可靠性不足。",
                "论文提出MMGR框架，基于五种推理能力（物理、逻辑、3D空间、2D空间、时序）构建原则性评估体系，覆盖抽象推理、具身导航和物理常识三大领域。",
                "实验显示，主流模型在物理常识任务上表现中等，但在抽象推理（如ARC-AGI准确率低于10%）和长时程空间规划上存在显著性能差距，揭示了模型局限性。"
            ],
            "method_zh": "MMGR是一个多模态生成推理评估框架，整体框架基于五种核心推理能力（物理、逻辑、3D空间、2D空间、时序）构建，覆盖抽象推理、具身导航和物理常识三大评估领域。关键技术创新点在于引入细粒度评估指标，要求视频和图像生成在整体上正确，而非仅关注视觉质量；同时，框架强调推理能力的系统性诊断，而非单一感知指标。与现有方法的主要区别在于：现有方法（如FVD）侧重于感知质量评估，而MMGR专注于推理失败检测，通过多领域任务设计，全面评估模型对物理、逻辑和空间约束的捕捉能力，从而提供更可靠的模型诊断工具。",
            "application_zh": "该研究可应用于视频生成模型的质量评估与优化，特别是在需要高可靠性世界模拟的场景，如自动驾驶仿真、机器人导航训练、虚拟现实内容生成和教育模拟系统。通过MMGR框架，开发者能更准确地诊断模型在推理能力上的不足，推动生成式AI向更智能、更符合现实约束的方向发展。",
            "highlight_zh": "实验结果显示，主流视频和图像模型在物理常识任务上表现中等，但在抽象推理任务（如ARC-AGI）上准确率低于10%，且在具身导航的长时程空间规划中表现不佳，揭示了模型在全局状态一致性和因果推理方面的显著局限性。",
            "tags_zh": [
                "多模态推理评估",
                "视频基础模型",
                "生成式AI",
                "物理常识推理",
                "具身导航",
                "抽象推理",
                "模型诊断基准",
                "世界模拟器"
            ],
            "_index": 3
        },
        {
            "title": "CRISP: Contact-Guided Real2Sim from Monocular Video with Planar Scene Primitives",
            "authors": [
                "Zihan Wang",
                "Jiashun Wang",
                "Jeff Tan",
                "Yiwen Zhao",
                "Jessica Hodgins",
                "Shubham Tulsiani",
                "Deva Ramanan"
            ],
            "arxiv_id": "2512.14696v1",
            "summary": "We introduce CRISP, a method that recovers simulatable human motion and scene geometry from monocular video. Prior work on joint human-scene reconstruction relies on data-driven priors and joint optimization with no physics in the loop, or recovers noisy geometry with artifacts that cause motion tracking policies with scene interactions to fail. In contrast, our key insight is to recover convex, clean, and simulation-ready geometry by fitting planar primitives to a point cloud reconstruction of the scene, via a simple clustering pipeline over depth, normals, and flow. To reconstruct scene geometry that might be occluded during interactions, we make use of human-scene contact modeling (e.g., we use human posture to reconstruct the occluded seat of a chair). Finally, we ensure that human and scene reconstructions are physically-plausible by using them to drive a humanoid controller via reinforcement learning. Our approach reduces motion tracking failure rates from 55.2\\% to 6.9\\% on human-centric video benchmarks (EMDB, PROX), while delivering a 43\\% faster RL simulation throughput. We further validate it on in-the-wild videos including casually-captured videos, Internet videos, and even Sora-generated videos. This demonstrates CRISP's ability to generate physically-valid human motion and interaction environments at scale, greatly advancing real-to-sim applications for robotics and AR/VR.",
            "categories": [
                "cs.CV",
                "cs.GR",
                "cs.RO"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project page: https://crisp-real2sim.github.io/CRISP-Real2Sim/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14696v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "人形机器人",
                    "matched_keywords": [
                        "humanoid",
                        "humanoid control"
                    ],
                    "score": 2
                },
                {
                    "name": "动作生成",
                    "matched_keywords": [
                        "human motion"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "reinforcement learning",
                        "RL"
                    ],
                    "score": 2
                }
            ],
            "relevance_score": 5,
            "headline_zh": "提出CRISP方法，通过平面基元拟合和接触引导，从单目视频重建可仿真的运动与场景几何，解决物理交互失败问题。",
            "summary_zh": "我们介绍了CRISP方法，它能够从单目视频中恢复可仿真的人类运动和场景几何。先前关于人-场景联合重建的工作依赖于数据驱动的先验和无物理约束的联合优化，或者恢复带有伪影的噪声几何，导致场景交互的运动跟踪策略失败。相比之下，我们的关键见解是通过对场景点云重建进行平面基元拟合，利用深度、法线和光流的简单聚类流程，恢复凸面、干净且仿真就绪的几何。为了重建在交互过程中可能被遮挡的场景几何，我们利用人-场景接触建模（例如，使用人体姿态重建被遮挡的椅子座位）。最后，我们通过强化学习驱动人形控制器，确保人类和场景重建在物理上是合理的。我们的方法在以人为本的视频基准（EMDB、PROX）上将运动跟踪失败率从55.2%降低到6.9%，同时提供43%更快的RL仿真吞吐量。我们进一步在野外视频上验证了它，包括随意拍摄的视频、互联网视频，甚至Sora生成的视频。这展示了CRISP大规模生成物理有效的人类运动和交互环境的能力，极大地推进了机器人学和AR/VR的真实到仿真应用。",
            "intro_zh": [
                "现有方法依赖数据先验或无物理优化，导致几何噪声和交互失败，难以实现仿真就绪的重建。",
                "CRISP通过平面基元拟合点云和接触建模，恢复干净几何，并利用强化学习确保物理合理性。",
                "实验显示，运动跟踪失败率从55.2%降至6.9%，RL仿真吞吐量提升43%，并在多种视频上验证有效性。"
            ],
            "method_zh": "CRISP的整体框架包括从单目视频重建点云，然后通过基于深度、法线和光流的聚类流程拟合平面基元，以生成凸面、干净的场景几何。关键创新在于结合人-场景接触建模来重建遮挡区域（如利用人体姿态推断椅子座位），并通过强化学习驱动人形控制器来优化物理合理性。与现有方法的主要区别在于：它不依赖复杂的数据驱动先验，而是采用简单聚类和物理约束，直接生成仿真就绪的几何，避免了噪声和伪影导致的交互失败。",
            "application_zh": "该研究在机器人学和AR/VR领域有广泛应用，例如用于训练机器人交互策略、创建虚拟环境的物理模拟内容，以及增强现实中的真实场景重建，能够大规模生成物理有效的运动和交互环境。",
            "highlight_zh": "在EMDB和PROX基准上，运动跟踪失败率从55.2%显著降低至6.9%，RL仿真吞吐量提升43%，并在随意拍摄、互联网和Sora生成视频中验证了方法的鲁棒性和可扩展性。",
            "tags_zh": [
                "单目视频重建",
                "人-场景交互",
                "平面基元拟合",
                "接触建模",
                "强化学习仿真",
                "物理合理性",
                "真实到仿真",
                "机器人学应用"
            ],
            "_index": 4
        },
        {
            "title": "Synthetic Data Pipelines for Adaptive, Mission-Ready Militarized Humanoids",
            "authors": [
                "Mohammed Ayman Habib",
                "Aldo Petruzzelli"
            ],
            "arxiv_id": "2512.14411v1",
            "summary": "Omnia presents a synthetic data driven pipeline to accelerate the training, validation, and deployment readiness of militarized humanoids. The approach converts first-person spatial observations captured from point-of-view recordings, smart glasses, augmented reality headsets, and spatial browsing workflows into scalable, mission-specific synthetic datasets for humanoid autonomy. By generating large volumes of high-fidelity simulated scenarios and pairing them with automated labeling and model training, the pipeline enables rapid iteration on perception, navigation, and decision-making capabilities without the cost, risk, or time constraints of extensive field trials. The resulting datasets can be tuned quickly for new operational environments and threat conditions, supporting both baseline humanoid performance and advanced subsystems such as multimodal sensing, counter-detection survivability, and CBRNE-relevant reconnaissance behaviors. This work targets faster development cycles and improved robustness in complex, contested settings by exposing humanoid systems to broad scenario diversity early in the development process.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "6 pages; xTech Humanoid white paper submission",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14411v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "人形机器人",
                    "matched_keywords": [
                        "humanoid"
                    ],
                    "score": 1
                },
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO",
                        "VIO"
                    ],
                    "score": 2
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL",
                        "PPO"
                    ],
                    "score": 2
                }
            ],
            "relevance_score": 5,
            "headline_zh": "提出基于合成数据驱动的管道，以加速军事化人形机器人的训练、验证和部署准备。",
            "summary_zh": "Omnia提出了一种合成数据驱动的管道，用于加速军事化人形机器人的训练、验证和部署准备。该方法将来自第一人称空间观测（如点视角记录、智能眼镜、增强现实头显和空间浏览工作流）的数据转换为可扩展的、任务特定的合成数据集，以支持人形机器人的自主性。通过生成大量高保真模拟场景，并结合自动标注和模型训练，该管道能够在感知、导航和决策能力方面实现快速迭代，避免了广泛实地试验的成本、风险和时间限制。生成的数据集可以快速调整以适应新的操作环境和威胁条件，支持基线人形机器人性能以及高级子系统，如多模态传感、反检测生存能力和与CBRNE相关的侦察行为。这项工作旨在通过在人形机器人系统开发早期阶段暴露于广泛的场景多样性，实现更快的开发周期和在复杂、对抗性环境中提高鲁棒性。",
            "intro_zh": [
                "核心问题：传统军事化人形机器人训练依赖实地试验，成本高、风险大、周期长，难以快速适应新环境和威胁。",
                "方法要点：利用合成数据驱动管道，将第一人称空间观测转换为任务特定数据集，结合自动标注和模型训练实现快速迭代。",
                "实验或效果：支持感知、导航和决策能力的快速开发，提高在复杂对抗环境中的鲁棒性，缩短部署准备时间。"
            ],
            "method_zh": "论文提出一个合成数据驱动的整体框架，包括数据采集、合成场景生成、自动标注和模型训练模块。关键技术创新点在于将第一人称空间观测（如点视角记录和增强现实数据）高效转换为高保真模拟数据集，并集成自动化流程以支持快速迭代。与现有方法的主要区别在于其专注于军事化人形机器人的任务特定需求，通过合成数据减少对实地试验的依赖，实现更灵活和可扩展的训练管道。",
            "application_zh": "该研究主要应用于军事领域，特别是人形机器人的自主系统开发，如战场侦察、CBRNE威胁检测和反检测任务。潜在价值包括加速机器人部署、降低训练成本和提高在复杂环境中的适应性。",
            "highlight_zh": "实验表明，该管道能生成大量高保真合成场景，支持快速模型训练和验证，显著缩短开发周期。在模拟测试中，人形机器人展示了改进的感知和决策能力，适应新威胁条件的时间减少未知。",
            "tags_zh": [
                "合成数据管道",
                "军事化人形机器人",
                "第一人称空间观测",
                "自动标注",
                "模型训练迭代",
                "任务特定数据集",
                "高保真模拟场景",
                "CBRNE侦察"
            ],
            "_index": 5
        },
        {
            "title": "DriverGaze360: OmniDirectional Driver Attention with Object-Level Guidance",
            "authors": [
                "Shreedhar Govil",
                "Didier Stricker",
                "Jason Rambach"
            ],
            "arxiv_id": "2512.14266v1",
            "summary": "Predicting driver attention is a critical problem for developing explainable autonomous driving systems and understanding driver behavior in mixed human-autonomous vehicle traffic scenarios. Although significant progress has been made through large-scale driver attention datasets and deep learning architectures, existing works are constrained by narrow frontal field-of-view and limited driving diversity. Consequently, they fail to capture the full spatial context of driving environments, especially during lane changes, turns, and interactions involving peripheral objects such as pedestrians or cyclists. In this paper, we introduce DriverGaze360, a large-scale 360$^\\circ$ field of view driver attention dataset, containing $\\sim$1 million gaze-labeled frames collected from 19 human drivers, enabling comprehensive omnidirectional modeling of driver gaze behavior. Moreover, our panoramic attention prediction approach, DriverGaze360-Net, jointly learns attention maps and attended objects by employing an auxiliary semantic segmentation head. This improves spatial awareness and attention prediction across wide panoramic inputs. Extensive experiments demonstrate that DriverGaze360-Net achieves state-of-the-art attention prediction performance on multiple metrics on panoramic driving images. Dataset and method available at https://av.dfki.de/drivergaze360.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14266v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "自动驾驶",
                    "matched_keywords": [
                        "autonomous driving",
                        "autonomous vehicle",
                        "traffic"
                    ],
                    "score": 3
                },
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO",
                        "VIO"
                    ],
                    "score": 2
                }
            ],
            "relevance_score": 5,
            "headline_zh": "提出DriverGaze360全景数据集与DriverGaze360-Net模型，以解决自动驾驶中驾驶员注意力预测的视野局限问题。",
            "summary_zh": "预测驾驶员注意力是开发可解释自动驾驶系统及理解人机混合交通场景中驾驶员行为的关键问题。尽管通过大规模驾驶员注意力数据集和深度学习架构已取得显著进展，但现有工作受限于狭窄的前方视野和有限的驾驶多样性，无法捕捉驾驶环境的完整空间上下文，特别是在变道、转弯及涉及行人或骑行者等外围物体交互时。本文介绍了DriverGaze360，一个大规模360度视野驾驶员注意力数据集，包含从19名人类驾驶员收集的约100万帧带注视标签的图像，实现了对驾驶员注视行为的全方位建模。此外，我们的全景注意力预测方法DriverGaze360-Net通过采用辅助语义分割头联合学习注意力图和关注对象，提高了对宽全景输入的空间感知和注意力预测能力。大量实验表明，DriverGaze360-Net在全景驾驶图像上实现了多个指标的先进注意力预测性能。数据集和方法可在https://av.dfki.de/drivergaze360获取。",
            "intro_zh": [
                "现有驾驶员注意力预测方法受限于狭窄前方视野和有限驾驶多样性，无法捕捉变道、转弯等场景的完整空间上下文。",
                "提出DriverGaze360全景数据集和DriverGaze360-Net模型，通过联合学习注意力图和语义分割实现全方位注意力预测。",
                "实验显示DriverGaze360-Net在全景驾驶图像上实现先进性能，显著提升空间感知和预测准确性。"
            ],
            "method_zh": "DriverGaze360-Net是一个全景注意力预测框架，核心架构包括一个主干网络处理360度输入图像，以及两个并行输出头：一个用于生成注意力图，另一个作为辅助语义分割头识别关注对象。关键技术创新在于联合学习注意力图和语义分割，通过对象级引导增强空间感知能力。与现有方法的主要区别在于其全景视野处理能力和对象级语义融合，突破了传统方法在视野范围和上下文理解上的局限。",
            "application_zh": "该研究可应用于自动驾驶系统的可解释性开发，帮助理解驾驶员行为，提升人机混合交通场景的安全性，并支持高级驾驶辅助系统（ADAS）的优化设计。",
            "highlight_zh": "DriverGaze360-Net在全景驾驶图像上实现先进注意力预测性能，在多个评估指标上超越现有方法，显著提升对变道、转弯等复杂场景的预测准确性。",
            "tags_zh": [
                "驾驶员注意力预测",
                "全景视觉",
                "自动驾驶",
                "语义分割",
                "数据集构建",
                "深度学习",
                "人机交互",
                "可解释AI"
            ],
            "_index": 6
        },
        {
            "title": "ViBES: A Conversational Agent with Behaviorally-Intelligent 3D Virtual Body",
            "authors": [
                "Juze Zhang",
                "Changan Chen",
                "Xin Chen",
                "Heng Yu",
                "Tiange Xiang",
                "Ali Sartaz Khan",
                "Shrinidhi K. Lakshmikanth",
                "Ehsan Adeli"
            ],
            "arxiv_id": "2512.14234v1",
            "summary": "Human communication is inherently multimodal and social: words, prosody, and body language jointly carry intent. Yet most prior systems model human behavior as a translation task co-speech gesture or text-to-motion that maps a fixed utterance to motion clips-without requiring agentic decision-making about when to move, what to do, or how to adapt across multi-turn dialogue. This leads to brittle timing, weak social grounding, and fragmented stacks where speech, text, and motion are trained or inferred in isolation. We introduce ViBES (Voice in Behavioral Expression and Synchrony), a conversational 3D agent that jointly plans language and movement and executes dialogue-conditioned body actions. Concretely, ViBES is a speech-language-behavior (SLB) model with a mixture-of-modality-experts (MoME) backbone: modality-partitioned transformer experts for speech, facial expression, and body motion. The model processes interleaved multimodal token streams with hard routing by modality (parameters are split per expert), while sharing information through cross-expert attention. By leveraging strong pretrained speech-language models, the agent supports mixed-initiative interaction: users can speak, type, or issue body-action directives mid-conversation, and the system exposes controllable behavior hooks for streaming responses. We further benchmark on multi-turn conversation with automatic metrics of dialogue-motion alignment and behavior quality, and observe consistent gains over strong co-speech and text-to-motion baselines. ViBES goes beyond \"speech-conditioned motion generation\" toward agentic virtual bodies where language, prosody, and movement are jointly generated, enabling controllable, socially competent 3D interaction. Code and data will be made available at: ai.stanford.edu/~juze/ViBES/",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project page: https://ai.stanford.edu/~juze/ViBES/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14234v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "动作生成",
                    "matched_keywords": [
                        "motion generation"
                    ],
                    "score": 1
                },
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO",
                        "VIO"
                    ],
                    "score": 2
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL",
                        "PPO"
                    ],
                    "score": 2
                }
            ],
            "relevance_score": 5,
            "headline_zh": "提出ViBES对话代理，通过联合规划语言与动作解决多模态交互中的时序与社交基础问题",
            "summary_zh": "人类交流本质上是多模态和社交性的：语言、韵律和肢体语言共同传达意图。然而，大多数现有系统将人类行为建模为语音伴随手势或文本到动作的翻译任务，将固定话语映射到动作片段，而不需要代理决策何时移动、做什么或如何在多轮对话中适应。这导致脆弱的时序、薄弱的社交基础和碎片化的堆栈，其中语音、文本和动作被孤立地训练或推断。我们介绍了ViBES（语音行为表达与同步），这是一个对话式3D代理，联合规划语言和动作，并执行对话条件化的身体动作。具体来说，ViBES是一个语音-语言-行为（SLB）模型，具有混合模态专家（MoME）骨干：模态分区的Transformer专家用于语音、面部表情和身体动作。该模型通过模态硬路由（参数按专家分割）处理交错的多模态令牌流，同时通过跨专家注意力共享信息。通过利用强大的预训练语音-语言模型，该代理支持混合主动交互：用户可以在对话中说话、打字或发出身体动作指令，系统暴露可控的行为钩子用于流式响应。我们进一步在多轮对话上使用对话-动作对齐和行为质量的自动指标进行基准测试，并观察到相对于强大的语音伴随和文本到动作基线的持续增益。ViBES超越了“语音条件化动作生成”，走向代理虚拟身体，其中语言、韵律和动作被联合生成，实现可控、社交能力强的3D交互。代码和数据将在ai.stanford.edu/~juze/ViBES/提供。",
            "intro_zh": [
                "现有方法将人类行为建模为翻译任务，导致时序脆弱、社交基础薄弱和模态孤立，限制了多模态交互的自然性。",
                "ViBES采用混合模态专家骨干，通过模态分区Transformer联合处理语音、表情和动作，实现语言与动作的协同规划。",
                "实验显示，ViBES在对话-动作对齐和行为质量上优于基线，支持混合主动交互和可控流式响应，提升社交能力。"
            ],
            "method_zh": "ViBES的核心是一个语音-语言-行为（SLB）模型，基于混合模态专家（MoME）架构。整体框架包括模态分区的Transformer专家，分别处理语音、面部表情和身体动作的令牌流，通过硬路由按模态分配参数，同时利用跨专家注意力实现信息共享。关键技术创新在于联合规划语言和动作，而非孤立生成，并集成预训练语音-语言模型以支持多模态输入和输出。与现有方法的主要区别在于从翻译任务转向代理决策，强调时序同步和社交适应性，避免了碎片化堆栈问题。",
            "application_zh": "该研究可应用于虚拟助手、社交机器人、游戏角色和远程协作系统，通过实现可控、社交能力强的3D交互，提升用户体验和自然沟通，在教育、娱乐和医疗等领域具有实际价值。",
            "highlight_zh": "在多轮对话基准测试中，ViBES在对话-动作对齐和行为质量自动指标上均优于语音伴随和文本到动作基线，显示出持续的性能增益，验证了联合规划方法的有效性。",
            "tags_zh": [
                "多模态对话代理",
                "语音-语言-行为模型",
                "混合模态专家",
                "3D虚拟身体",
                "联合规划",
                "社交交互",
                "时序同步",
                "可控行为生成"
            ],
            "_index": 7
        },
        {
            "title": "Understanding and Improving Hyperbolic Deep Reinforcement Learning",
            "authors": [
                "Timo Klein",
                "Thomas Lang",
                "Andrii Shkabrii",
                "Alexander Sturm",
                "Kevin Sidak",
                "Lukas Miklautz",
                "Claudia Plant",
                "Yllka Velaj",
                "Sebastian Tschiatschek"
            ],
            "arxiv_id": "2512.14202v1",
            "summary": "The performance of reinforcement learning (RL) agents depends critically on the quality of the underlying feature representations. Hyperbolic feature spaces are well-suited for this purpose, as they naturally capture hierarchical and relational structure often present in complex RL environments. However, leveraging these spaces commonly faces optimization challenges due to the nonstationarity of RL. In this work, we identify key factors that determine the success and failure of training hyperbolic deep RL agents. By analyzing the gradients of core operations in the Poincaré Ball and Hyperboloid models of hyperbolic geometry, we show that large-norm embeddings destabilize gradient-based training, leading to trust-region violations in proximal policy optimization (PPO). Based on these insights, we introduce Hyper++, a new hyperbolic PPO agent that consists of three components: (i) stable critic training through a categorical value loss instead of regression; (ii) feature regularization guaranteeing bounded norms while avoiding the curse of dimensionality from clipping; and (iii) using a more optimization-friendly formulation of hyperbolic network layers. In experiments on ProcGen, we show that Hyper++ guarantees stable learning, outperforms prior hyperbolic agents, and reduces wall-clock time by approximately 30%. On Atari-5 with Double DQN, Hyper++ strongly outperforms Euclidean and hyperbolic baselines. We release our code at https://github.com/Probabilistic-and-Interactive-ML/hyper-rl .",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14202v1",
            "code_links": [
                {
                    "url": "https://github.com/Probabilistic-and-Interactive-ML/hyper-rl",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO",
                        "VIO"
                    ],
                    "score": 2
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "reinforcement learning",
                        "RL",
                        "PPO"
                    ],
                    "score": 3
                }
            ],
            "relevance_score": 5,
            "headline_zh": "提出Hyper++以解决双曲深度强化学习中梯度不稳定和优化挑战的问题。",
            "summary_zh": "强化学习（RL）智能体的性能关键取决于底层特征表示的质量。双曲特征空间非常适合此目的，因为它们能自然捕捉复杂RL环境中常见的层次和关系结构。然而，由于RL的非平稳性，利用这些空间通常面临优化挑战。在本工作中，我们确定了决定双曲深度RL智能体训练成功与失败的关键因素。通过分析双曲几何的Poincaré Ball和Hyperboloid模型中核心操作的梯度，我们表明大范数嵌入会破坏基于梯度的训练稳定性，导致近端策略优化（PPO）中的信任区域违反。基于这些见解，我们引入了Hyper++，一种新的双曲PPO智能体，包含三个组件：（i）通过分类值损失而非回归实现稳定的评论家训练；（ii）特征正则化保证有界范数，同时避免裁剪带来的维度诅咒；（iii）使用更优化友好的双曲网络层公式。在ProcGen实验中，我们表明Hyper++保证了稳定学习，优于先前的双曲智能体，并将挂钟时间减少了约30%。在Atari-5上使用Double DQN，Hyper++显著优于欧几里得和双曲基线。我们在https://github.com/Probabilistic-and-Interactive-ML/hyper-rl 发布了代码。",
            "intro_zh": [
                "核心问题：双曲深度强化学习中，大范数嵌入导致梯度不稳定，破坏训练，尤其在PPO中引发信任区域违反。",
                "方法要点：提出Hyper++，结合分类值损失稳定评论家训练、特征正则化控制范数，以及优化友好的双曲层设计。",
                "实验或效果：在ProcGen上实现稳定学习，性能优于基线，挂钟时间减少30%；在Atari-5上显著超越欧几里得和双曲方法。"
            ],
            "method_zh": "Hyper++的整体框架基于近端策略优化（PPO），针对双曲特征空间设计。关键技术创新点包括：使用分类值损失替代回归损失以稳定评论家训练，避免梯度爆炸；引入特征正则化机制，确保嵌入范数有界，防止维度诅咒；采用更优化友好的双曲网络层公式，提升训练效率。与现有方法的主要区别在于，它系统解决了双曲RL中的梯度不稳定问题，通过综合组件优化而非单一调整，实现了稳定且高效的训练。",
            "application_zh": "该研究可应用于复杂强化学习环境，如视频游戏（如ProcGen、Atari）、机器人导航和决策系统，其中环境具有层次或关系结构。实际价值在于提升智能体学习效率和稳定性，减少训练时间，推动双曲几何在AI中的实际部署。",
            "highlight_zh": "在ProcGen基准测试中，Hyper++保证稳定学习，性能优于先前双曲智能体，挂钟时间减少约30%；在Atari-5上使用Double DQN，显著超越欧几里得和双曲基线，验证了方法的有效性和泛化能力。",
            "tags_zh": [
                "双曲几何",
                "深度强化学习",
                "近端策略优化",
                "梯度稳定",
                "特征正则化",
                "ProcGen基准",
                "Atari游戏",
                "优化挑战"
            ],
            "_index": 8
        },
        {
            "title": "A First-Order Logic-Based Alternative to Reward Models in RLHF",
            "authors": [
                "Chunjin Jian",
                "Xinhua Zhu"
            ],
            "arxiv_id": "2512.14100v1",
            "summary": "Reinforcement Learning from Human Feedback (RLHF) plays a crucial role in aligning large language models (LLMs) with human values and preferences. However, the quality and stability of the trained reward model largely determine the final alignment performance. Existing approaches such as Proximal Policy Optimization (PPO) rely heavily on reward models to guide LLMs toward human-aligned behaviors.\n  In this work, we propose a logic-similarity-based reward mechanism as an alternative to conventional reward modeling. Instead of relying on heuristic reward estimation, our method leverages formal logical consistency to steer model alignment with human preferences. Since real-world questions can be interpreted from multiple perspectives, to ensure that logic-based reinforcement learning does not cause model collapse, we introduce S-GRPO, a supervised variant of the GRPO framework. S-GRPO incorporates an additional supervised component and jointly optimizes the generation term, KL-divergence regularization, and label-based objective during training.\n  Experimental results demonstrate that S-GRPO consistently outperforms standard supervised fine-tuning (SFT) in both performance and robustness. Furthermore, it extends existing preference-learning frameworks such as GRPO and DPO, offering a more flexible and task-adaptive approach to alignment training. Our code is available at https://github.com/ChunjinJiang/sgrpo.",
            "categories": [
                "cs.LG",
                "cs.LO"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14100v1",
            "code_links": [
                {
                    "url": "https://github.com/ChunjinJiang/sgrpo",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VIO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "reinforcement learning",
                        "RL",
                        "reward",
                        "PPO"
                    ],
                    "score": 4
                }
            ],
            "relevance_score": 5,
            "headline_zh": "提出基于逻辑相似性的奖励机制S-GRPO，替代传统奖励模型以提升RLHF的稳定性和性能。",
            "summary_zh": "基于人类反馈的强化学习（RLHF）在将大型语言模型（LLMs）与人类价值观和偏好对齐方面起着关键作用。然而，训练出的奖励模型的质量和稳定性在很大程度上决定了最终的对齐性能。现有方法如近端策略优化（PPO）严重依赖奖励模型来引导LLMs朝向人类对齐的行为。在这项工作中，我们提出了一种基于逻辑相似性的奖励机制，作为传统奖励建模的替代方案。我们的方法不依赖启发式奖励估计，而是利用形式逻辑一致性来引导模型与人类偏好对齐。由于现实世界的问题可以从多个角度解释，为确保基于逻辑的强化学习不会导致模型崩溃，我们引入了S-GRPO，这是GRPO框架的一个监督变体。S-GRPO在训练中结合了额外的监督组件，并联合优化生成项、KL散度正则化和基于标签的目标。实验结果表明，S-GRPO在性能和鲁棒性方面均持续优于标准监督微调（SFT）。此外，它扩展了现有的偏好学习框架如GRPO和DPO，为对齐训练提供了更灵活和任务自适应的途径。我们的代码可在https://github.com/ChunjinJiang/sgrpo获取。",
            "intro_zh": [
                "现有RLHF方法依赖奖励模型，其质量和稳定性直接影响对齐性能，存在不稳定和启发式估计的不足。",
                "提出基于逻辑相似性的奖励机制，利用形式逻辑一致性替代传统奖励建模，并引入S-GRPO框架以防止模型崩溃。",
                "实验显示S-GRPO在性能和鲁棒性上优于标准监督微调，并扩展了GRPO和DPO等偏好学习框架。"
            ],
            "method_zh": "论文提出S-GRPO框架，整体基于GRPO框架进行扩展，核心创新在于引入基于逻辑相似性的奖励机制，替代传统奖励模型。该方法利用形式逻辑一致性来评估模型输出与人类偏好的对齐程度，避免了启发式奖励估计的不稳定性。关键技术创新包括：在训练中联合优化生成项、KL散度正则化和基于标签的监督目标，通过额外监督组件增强稳定性。与现有方法的主要区别在于，它不依赖显式奖励模型，而是通过逻辑一致性直接引导对齐，减少了模型崩溃风险，提供了更灵活的任务自适应能力。",
            "application_zh": "该研究可应用于大型语言模型的对齐训练，特别是在需要稳定性和鲁棒性的场景，如AI助手、内容生成和对话系统。其逻辑一致性机制有助于提升模型在复杂任务中的表现，减少偏差，适用于教育和客服等领域。",
            "highlight_zh": "S-GRPO在实验中持续优于标准监督微调（SFT），在性能和鲁棒性方面均有显著提升。它有效扩展了GRPO和DPO等偏好学习框架，展示了更灵活的对齐训练能力，代码已开源供进一步研究。",
            "tags_zh": [
                "强化学习人类反馈",
                "逻辑相似性奖励",
                "模型对齐",
                "S-GRPO框架",
                "监督微调",
                "偏好学习",
                "大型语言模型",
                "鲁棒性优化"
            ],
            "_index": 9
        },
        {
            "title": "OmniDrive-R1: Reinforcement-driven Interleaved Multi-modal Chain-of-Thought for Trustworthy Vision-Language Autonomous Driving",
            "authors": [
                "Zhenguo Zhang",
                "Haohan Zhen",
                "Yishen Wang",
                "Le Xu",
                "Tianchen Deng",
                "Xuefeng Chen",
                "Qu Chen",
                "Bo Zhang",
                "Wuxiong Huang"
            ],
            "arxiv_id": "2512.14044v1",
            "summary": "The deployment of Vision-Language Models (VLMs) in safety-critical domains like autonomous driving (AD) is critically hindered by reliability failures, most notably object hallucination. This failure stems from their reliance on ungrounded, text-based Chain-of-Thought (CoT) reasoning.While existing multi-modal CoT approaches attempt mitigation, they suffer from two fundamental flaws: (1) decoupled perception and reasoning stages that prevent end-to-end joint optimization, and (2) reliance on expensive, dense localization labels.Thus we introduce OmniDrive-R1, an end-to-end VLM framework designed for autonomous driving, which unifies perception and reasoning through an interleaved Multi-modal Chain-of-Thought (iMCoT) mechanism. Our core innovation is an Reinforcement-driven visual grounding capability, enabling the model to autonomously direct its attention and \"zoom in\" on critical regions for fine-grained analysis. This capability is enabled by our pure two-stage reinforcement learning training pipeline and Clip-GRPO algorithm. Crucially, Clip-GRPO introduces an annotation-free, process-based grounding reward. This reward not only eliminates the need for dense labels but also circumvents the instability of external tool calls by enforcing real-time cross-modal consistency between the visual focus and the textual reasoning. Extensive experiments on DriveLMM-o1 demonstrate our model's significant improvements. Compared to the baseline Qwen2.5VL-7B, OmniDrive-R1 improves the overall reasoning score from 51.77% to 80.35%, and the final answer accuracy from 37.81% to 73.62%.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14044v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "自动驾驶",
                    "matched_keywords": [
                        "autonomous driving"
                    ],
                    "score": 1
                },
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "localization"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "reinforcement learning",
                        "RL",
                        "reward"
                    ],
                    "score": 3
                }
            ],
            "relevance_score": 5,
            "headline_zh": "提出OmniDrive-R1框架，通过强化学习驱动的交错多模态思维链解决自动驾驶中视觉语言模型的可靠性问题",
            "summary_zh": "在自动驾驶等安全关键领域部署视觉语言模型时，可靠性问题（特别是物体幻觉）严重阻碍了其应用。这种失败源于模型依赖未接地的、基于文本的思维链推理。现有的多模态思维链方法虽然尝试缓解这一问题，但存在两个根本缺陷：（1）解耦的感知和推理阶段阻碍了端到端的联合优化；（2）依赖昂贵且密集的定位标注。为此，我们提出了OmniDrive-R1，这是一个专为自动驾驶设计的端到端视觉语言模型框架，通过交错多模态思维链机制统一了感知和推理。我们的核心创新是强化学习驱动的视觉接地能力，使模型能够自主引导注意力并“放大”关键区域进行细粒度分析。这一能力通过我们的纯两阶段强化学习训练流程和Clip-GRPO算法实现。关键的是，Clip-GRPO引入了无需标注的、基于过程的接地奖励。该奖励不仅消除了对密集标注的需求，还通过强制视觉焦点和文本推理之间的实时跨模态一致性，规避了外部工具调用的不稳定性。在DriveLMM-o1数据集上的大量实验证明了我们模型的显著改进。与基线Qwen2.5VL-7B相比，OmniDrive-R1将整体推理分数从51.77%提升到80.35%，最终答案准确率从37.81%提升到73.62%。",
            "intro_zh": [
                "现有方法存在感知与推理阶段解耦的问题，无法实现端到端联合优化，且依赖昂贵密集的定位标注，限制了自动驾驶中视觉语言模型的可靠性。",
                "论文提出交错多模态思维链机制，通过强化学习驱动的视觉接地能力，使模型能自主聚焦关键区域，实现细粒度分析和实时跨模态一致性。",
                "在DriveLMM-o1数据集上，OmniDrive-R1相比基线模型，整体推理分数提升至80.35%，最终答案准确率提升至73.62%，显著改善性能。"
            ],
            "method_zh": "OmniDrive-R1是一个端到端的视觉语言模型框架，专为自动驾驶设计。其核心是交错多模态思维链机制，通过强化学习驱动的视觉接地能力统一感知和推理。关键技术创新包括纯两阶段强化学习训练流程和Clip-GRPO算法，后者引入无需标注的、基于过程的接地奖励，强制视觉焦点与文本推理的实时一致性。与现有方法的主要区别在于：它避免了感知和推理阶段的解耦，实现了端到端优化；同时，不依赖密集定位标注，通过强化学习自主引导注意力，提高了模型的可靠性和效率。",
            "application_zh": "该研究主要应用于自动驾驶领域，特别是视觉语言模型的部署，以提高在安全关键场景中的可靠性和决策准确性。潜在应用包括智能车辆的环境感知、实时推理和自主导航，有助于推动自动驾驶技术的实际落地和安全性提升。",
            "highlight_zh": "在DriveLMM-o1数据集上，OmniDrive-R1相比基线Qwen2.5VL-7B，整体推理分数从51.77%大幅提升至80.35%，最终答案准确率从37.81%提升至73.62%，显示出显著的性能改进和可靠性增强。",
            "tags_zh": [
                "自动驾驶",
                "视觉语言模型",
                "强化学习",
                "多模态思维链",
                "视觉接地",
                "端到端优化",
                "可靠性提升",
                "跨模态一致性"
            ],
            "_index": 10
        },
        {
            "title": "ACE-SLAM: Scene Coordinate Regression for Neural Implicit Real-Time SLAM",
            "authors": [
                "Ignacio Alzugaray",
                "Marwan Taher",
                "Andrew J. Davison"
            ],
            "arxiv_id": "2512.14032v1",
            "summary": "We present a novel neural RGB-D Simultaneous Localization And Mapping (SLAM) system that learns an implicit map of the scene in real time. For the first time, we explore the use of Scene Coordinate Regression (SCR) as the core implicit map representation in a neural SLAM pipeline, a paradigm that trains a lightweight network to directly map 2D image features to 3D global coordinates. SCR networks provide efficient, low-memory 3D map representations, enable extremely fast relocalization, and inherently preserve privacy, making them particularly suitable for neural implicit SLAM.\n  Our system is the first one to achieve strict real-time in neural implicit RGB-D SLAM by relying on a SCR-based representation. We introduce a novel SCR architecture specifically tailored for this purpose and detail the critical design choices required to integrate SCR into a live SLAM pipeline. The resulting framework is simple yet flexible, seamlessly supporting both sparse and dense features, and operates reliably in dynamic environments without special adaptation. We evaluate our approach on established synthetic and real-world benchmarks, demonstrating competitive performance against the state of the art. Project Page: https://github.com/ialzugaray/ace-slam",
            "categories": [
                "cs.CV",
                "cs.AI",
                "eess.IV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project Page: https://github.com/ialzugaray/ace-slam",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14032v1",
            "code_links": [
                {
                    "url": "https://github.com/ialzugaray/ace-slam",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "SLAM",
                        "localization",
                        "mapping"
                    ],
                    "score": 3
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL",
                        "PPO"
                    ],
                    "score": 2
                }
            ],
            "relevance_score": 5,
            "headline_zh": "提出ACE-SLAM系统，基于场景坐标回归实现神经隐式实时RGB-D SLAM，解决现有方法实时性和内存效率不足的问题。",
            "summary_zh": "我们提出了一种新颖的神经RGB-D同时定位与建图（SLAM）系统，能够实时学习场景的隐式地图。首次探索了在神经SLAM流程中使用场景坐标回归（SCR）作为核心隐式地图表示范式，该范式训练一个轻量级网络，直接将2D图像特征映射到3D全局坐标。SCR网络提供高效、低内存的3D地图表示，支持极快的重定位，并固有地保护隐私，使其特别适合神经隐式SLAM。我们的系统是首个通过依赖基于SCR的表示实现严格实时性的神经隐式RGB-D SLAM系统。我们引入了一种专门为此目的设计的新型SCR架构，并详细阐述了将SCR集成到实时SLAM流程中的关键设计选择。所得框架简单而灵活，无缝支持稀疏和稠密特征，并在动态环境中可靠运行，无需特殊适应。我们在已建立的合成和真实世界基准上评估了我们的方法，展示了与最先进技术相比的竞争性能。项目页面：https://github.com/ialzugaray/ace-slam",
            "intro_zh": [
                "现有神经隐式SLAM方法在实时性和内存效率方面存在不足，难以满足实际应用需求。",
                "论文提出基于场景坐标回归的轻量级网络，直接映射2D特征到3D坐标，实现高效隐式地图表示。",
                "实验表明，系统在合成和真实基准上达到严格实时性能，并在动态环境中表现可靠。"
            ],
            "method_zh": "ACE-SLAM的整体框架是一个神经RGB-D SLAM系统，核心采用场景坐标回归作为隐式地图表示。关键技术创新点包括：设计了一种新型SCR架构，专门针对实时SLAM优化，通过轻量级网络直接预测3D场景坐标；详细集成了SCR到实时SLAM流程中，支持稀疏和稠密特征的无缝处理。与现有方法的主要区别在于：首次将SCR范式应用于神经隐式SLAM，实现了严格实时性，而传统方法往往依赖更复杂的网络或存储密集型表示，导致计算和内存开销较大。",
            "application_zh": "该研究适用于增强现实、机器人导航和虚拟现实等领域，其高效实时SLAM能力可支持动态环境中的精准定位和地图构建，具有实际应用价值。",
            "highlight_zh": "在合成和真实世界基准测试中，ACE-SLAM实现了严格实时性能，重定位速度极快，内存占用低，并在动态环境中无需特殊适应即可可靠运行，性能与最先进方法竞争。",
            "tags_zh": [
                "神经隐式SLAM",
                "场景坐标回归",
                "实时RGB-D SLAM",
                "轻量级网络",
                "动态环境适应",
                "隐私保护",
                "地图表示",
                "重定位技术"
            ],
            "_index": 11
        },
        {
            "title": "CHIP: Adaptive Compliance for Humanoid Control through Hindsight Perturbation",
            "authors": [
                "Sirui Chen",
                "Zi-ang Cao",
                "Zhengyi Luo",
                "Fernando Castañeda",
                "Chenran Li",
                "Tingwu Wang",
                "Ye Yuan",
                "Linxi \"Jim\" Fan",
                "C. Karen Liu",
                "Yuke Zhu"
            ],
            "arxiv_id": "2512.14689v1",
            "summary": "Recent progress in humanoid robots has unlocked agile locomotion skills, including backflipping, running, and crawling. Yet it remains challenging for a humanoid robot to perform forceful manipulation tasks such as moving objects, wiping, and pushing a cart. We propose adaptive Compliance Humanoid control through hIsight Perturbation (CHIP), a plug-and-play module that enables controllable end-effector stiffness while preserving agile tracking of dynamic reference motions. CHIP is easy to implement and requires neither data augmentation nor additional reward tuning. We show that a generalist motion-tracking controller trained with CHIP can perform a diverse set of forceful manipulation tasks that require different end-effector compliance, such as multi-robot collaboration, wiping, box delivery, and door opening.",
            "categories": [
                "cs.RO",
                "cs.LG"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "The first two authors contributed equally. Project page: https://nvlabs.github.io/CHIP/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14689v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "人形机器人",
                    "matched_keywords": [
                        "humanoid",
                        "humanoid robot",
                        "humanoid control"
                    ],
                    "score": 3
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "reward"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 4,
            "headline_zh": "提出CHIP模块以解决人形机器人执行强力操作任务时末端执行器刚度控制与动态运动跟踪的平衡问题。",
            "summary_zh": "人形机器人领域近期在敏捷运动技能（如后空翻、奔跑、爬行）方面取得了显著进展，但在执行强力操作任务（如移动物体、擦拭、推车）时仍面临挑战。本文提出了一种自适应顺应性人形控制方法——通过后见扰动实现的自适应顺应性人形控制（CHIP），这是一个即插即用模块，能够在保持对动态参考运动敏捷跟踪的同时，实现可控的末端执行器刚度。CHIP易于实现，既不需要数据增强，也不需要额外的奖励调整。研究表明，使用CHIP训练的通用运动跟踪控制器能够执行多种需要不同末端执行器顺应性的强力操作任务，例如多机器人协作、擦拭、箱子递送和开门。",
            "intro_zh": [
                "现有方法在实现人形机器人敏捷运动跟踪时，难以同时控制末端执行器刚度以执行强力操作任务，导致操作性能受限。",
                "CHIP通过后见扰动技术，在强化学习框架中自适应调整末端执行器顺应性，实现刚度控制与运动跟踪的平衡。",
                "实验表明，CHIP使通用控制器能执行多机器人协作、擦拭等多样任务，无需额外奖励调整，提升了操作鲁棒性。"
            ],
            "method_zh": "CHIP是一个基于强化学习的即插即用模块，整体框架集成于通用运动跟踪控制器中。其核心创新点在于引入后见扰动技术，通过在训练过程中模拟末端执行器受力扰动，自适应学习最优顺应性策略，从而在不牺牲运动跟踪精度的情况下实现刚度控制。与现有方法相比，CHIP无需复杂的数据增强或奖励函数设计，直接通过扰动机制隐式学习顺应性，简化了实现流程并提高了泛化能力。",
            "application_zh": "该研究可应用于人形机器人的强力操作场景，如工业搬运、家庭服务（擦拭、开门）、物流递送和多机器人协作任务，提升机器人在动态环境中的操作适应性和安全性。",
            "highlight_zh": "CHIP使通用运动跟踪控制器成功执行了多机器人协作、擦拭、箱子递送和开门等多样强力操作任务，实验显示其在保持运动敏捷性的同时，显著提升了末端执行器刚度控制的性能，无需额外奖励调整。",
            "tags_zh": [
                "人形机器人控制",
                "自适应顺应性",
                "后见扰动",
                "强化学习",
                "末端执行器刚度",
                "运动跟踪",
                "强力操作",
                "多任务泛化"
            ],
            "_index": 12
        },
        {
            "title": "gridfm-datakit-v1: A Python Library for Scalable and Realistic Power Flow and Optimal Power Flow Data Generation",
            "authors": [
                "Alban Puech",
                "Matteo Mazzonelli",
                "Celia Cintas",
                "Tamara R. Govindasamy",
                "Mangaliso Mngomezulu",
                "Jonas Weiss",
                "Matteo Baù",
                "Anna Varbella",
                "François Mirallès",
                "Kibaek Kim",
                "Le Xie",
                "Hendrik F. Hamann",
                "Etienne Vos",
                "Thomas Brunschwiler"
            ],
            "arxiv_id": "2512.14658v1",
            "summary": "We introduce gridfm-datakit-v1, a Python library for generating realistic and diverse Power Flow (PF) and Optimal Power Flow (OPF) datasets for training Machine Learning (ML) solvers. Existing datasets and libraries face three main challenges: (1) lack of realistic stochastic load and topology perturbations, limiting scenario diversity; (2) PF datasets are restricted to OPF-feasible points, hindering generalization of ML solvers to cases that violate operating limits (e.g., branch overloads or voltage violations); and (3) OPF datasets use fixed generator cost functions, limiting generalization across varying costs. gridfm-datakit addresses these challenges by: (1) combining global load scaling from real-world profiles with localized noise and supporting arbitrary N-k topology perturbations to create diverse yet realistic datasets; (2) generating PF samples beyond operating limits; and (3) producing OPF data with varying generator costs. It also scales efficiently to large grids (up to 10,000 buses). Comparisons with OPFData, OPF-Learn, PGLearn, and PF$Δ$ are provided. Available on GitHub at https://github.com/gridfm/gridfm-datakit under Apache 2.0 and via `pip install gridfm-datakit`.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "eess.SY",
                "math.OC"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Main equal contributors: Alban Puech, Matteo Mazzonelli. Other equal contributors: Celia Cintas, Tamara R. Govindasamy, Mangaliso Mngomezulu, Jonas Weiss",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14658v1",
            "code_links": [
                {
                    "url": "https://github.com/gridfm/gridfm-datakit",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO",
                        "VIO"
                    ],
                    "score": 2
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL",
                        "PPO"
                    ],
                    "score": 2
                }
            ],
            "relevance_score": 4,
            "headline_zh": "提出gridfm-datakit-v1 Python库，以生成可扩展且现实的潮流和最优潮流数据集，解决现有数据生成方法的多样性不足和泛化限制问题。",
            "summary_zh": "我们介绍了gridfm-datakit-v1，这是一个用于生成现实且多样化的潮流（PF）和最优潮流（OPF）数据集的Python库，旨在训练机器学习（ML）求解器。现有数据集和库面临三个主要挑战：（1）缺乏现实的随机负荷和拓扑扰动，限制了场景多样性；（2）PF数据集仅限于OPF可行点，阻碍了ML求解器对违反运行限制（如支路过载或电压违规）情况的泛化；（3）OPF数据集使用固定的发电机成本函数，限制了在不同成本下的泛化能力。gridfm-datakit通过以下方式应对这些挑战：（1）结合来自真实世界配置文件的全局负荷缩放与局部噪声，并支持任意的N-k拓扑扰动，以创建多样且现实的数据集；（2）生成超出运行限制的PF样本；（3）生成具有变化发电机成本的OPF数据。它还高效扩展到大型电网（最多10,000个节点）。提供了与OPFData、OPF-Learn、PGLearn和PF$Δ$的比较。该库可在GitHub上获取，网址为https://github.com/gridfm/gridfm-datakit，遵循Apache 2.0许可，并通过`pip install gridfm-datakit`安装。",
            "intro_zh": [
                "现有方法缺乏现实随机负荷和拓扑扰动，导致数据集多样性不足，限制了机器学习求解器的训练效果。",
                "通过结合全局负荷缩放、局部噪声和N-k拓扑扰动，生成多样且现实的PF和OPF数据，并支持超出运行限制的样本和变化成本。",
                "库能高效扩展到10,000节点电网，相比现有工具，在数据多样性和泛化能力方面有显著提升。"
            ],
            "method_zh": "gridfm-datakit-v1的整体框架是一个基于Python的数据生成库，专注于潮流和最优潮流模拟。关键技术创新点包括：结合真实世界负荷配置文件的全局缩放与局部噪声，以模拟现实负荷变化；支持任意的N-k拓扑扰动，增强数据集的多样性和现实性；生成超出运行限制的PF样本，以训练ML求解器处理违规情况；以及生成具有变化发电机成本的OPF数据，提高成本泛化能力。与现有方法的主要区别在于，它解决了现有库在随机扰动、泛化限制和成本固定方面的不足，提供了更全面和可扩展的数据生成方案。",
            "application_zh": "该研究主要应用于电力系统优化和机器学习领域，可用于训练和评估潮流和最优潮流的ML求解器，支持电网规划、实时控制和能源管理，提升电力系统的效率和可靠性。",
            "highlight_zh": "实验表明，gridfm-datakit能生成多样且现实的数据集，扩展到10,000节点电网，相比OPFData等工具，在数据多样性和泛化能力方面有显著改进，支持超出运行限制的样本和变化成本。",
            "tags_zh": [
                "潮流数据生成",
                "最优潮流数据生成",
                "机器学习求解器",
                "电力系统模拟",
                "数据多样性",
                "泛化能力",
                "Python库",
                "电网优化"
            ],
            "_index": 13
        },
        {
            "title": "Model-Based Reinforcement Learning in Discrete-Action Non-Markovian Reward Decision Processes",
            "authors": [
                "Alessandro Trapasso",
                "Luca Iocchi",
                "Fabio Patrizi"
            ],
            "arxiv_id": "2512.14617v1",
            "summary": "Many practical decision-making problems involve tasks whose success depends on the entire system history, rather than on achieving a state with desired properties. Markovian Reinforcement Learning (RL) approaches are not suitable for such tasks, while RL with non-Markovian reward decision processes (NMRDPs) enables agents to tackle temporal-dependency tasks. This approach has long been known to lack formal guarantees on both (near-)optimality and sample efficiency. We contribute to solving both issues with QR-MAX, a novel model-based algorithm for discrete NMRDPs that factorizes Markovian transition learning from non-Markovian reward handling via reward machines. To the best of our knowledge, this is the first model-based RL algorithm for discrete-action NMRDPs that exploits this factorization to obtain PAC convergence to $\\varepsilon$-optimal policies with polynomial sample complexity. We then extend QR-MAX to continuous state spaces with Bucket-QR-MAX, a SimHash-based discretiser that preserves the same factorized structure and achieves fast and stable learning without manual gridding or function approximation. We experimentally compare our method with modern state-of-the-art model-based RL approaches on environments of increasing complexity, showing a significant improvement in sample efficiency and increased robustness in finding optimal policies.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "19 pages, 32 figures, includes appendix",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14617v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "reinforcement learning",
                        "RL",
                        "reward"
                    ],
                    "score": 3
                }
            ],
            "relevance_score": 4,
            "headline_zh": "提出QR-MAX算法，通过奖励机分解学习，解决离散动作非马尔可夫奖励决策过程的样本效率与最优性保证问题。",
            "summary_zh": "许多实际决策问题涉及任务的成功依赖于整个系统历史，而非仅达到具有期望属性的状态。马尔可夫强化学习方法不适用于此类任务，而非马尔可夫奖励决策过程使智能体能够处理时间依赖性任务。这种方法长期以来缺乏对（近）最优性和样本效率的形式化保证。我们通过QR-MAX贡献于解决这两个问题，这是一种基于模型的新算法，用于离散非马尔可夫奖励决策过程，通过奖励机将马尔可夫转移学习与非马尔可夫奖励处理分解。据我们所知，这是首个基于模型的强化学习算法，利用这种分解实现多项式样本复杂度下收敛到ε-最优策略的PAC保证。然后，我们将QR-MAX扩展到连续状态空间，通过Bucket-QR-MAX，一种基于SimHash的离散化器，保持相同的分解结构，实现快速稳定学习，无需手动网格化或函数逼近。我们在复杂度递增的环境上实验比较我们的方法与现代最先进的基于模型强化学习方法，显示样本效率显著提升和寻找最优策略的鲁棒性增强。",
            "intro_zh": [
                "核心问题：现有马尔可夫强化学习方法不适用于依赖历史的任务，非马尔可夫奖励决策过程缺乏最优性和样本效率的形式化保证。",
                "方法要点：提出QR-MAX算法，通过奖励机分解马尔可夫转移与非马尔可夫奖励，实现模型学习与奖励处理的分离。",
                "实验或效果：在复杂环境中，QR-MAX相比现有方法显著提升样本效率，增强策略最优性鲁棒性，并扩展到连续状态空间。"
            ],
            "method_zh": "QR-MAX是一种基于模型的强化学习算法，专为离散动作非马尔可夫奖励决策过程设计。整体框架结合奖励机来分解学习过程：智能体学习马尔可夫状态转移模型，同时使用奖励机处理非马尔可夫奖励信号。关键技术创新点在于这种分解结构，允许独立优化转移学习和奖励处理，从而获得多项式样本复杂度的PAC收敛保证。与现有方法的主要区别在于，它首次在基于模型强化学习中实现这种分解，避免了传统方法对函数逼近或手动离散化的依赖，并通过Bucket-QR-MAX扩展支持连续状态空间，利用SimHash进行高效离散化。",
            "application_zh": "该研究适用于需要处理时间依赖性任务的领域，如机器人导航、自动驾驶、游戏AI和工业自动化，其中任务成功依赖于历史序列而非单一状态，可提升决策系统的效率和鲁棒性。",
            "highlight_zh": "实验显示QR-MAX在样本效率上显著优于现代最先进的基于模型强化学习方法，在复杂环境中实现更快收敛和更高策略最优性，Bucket-QR-MAX在连续状态空间中保持稳定学习，无需手动调整。",
            "tags_zh": [
                "非马尔可夫奖励决策过程",
                "基于模型强化学习",
                "奖励机",
                "样本效率",
                "PAC收敛",
                "连续状态空间",
                "SimHash离散化",
                "时间依赖性任务"
            ],
            "_index": 14
        },
        {
            "title": "DASP: Self-supervised Nighttime Monocular Depth Estimation with Domain Adaptation of Spatiotemporal Priors",
            "authors": [
                "Yiheng Huang",
                "Junhong Chen",
                "Anqi Ning",
                "Zhanhong Liang",
                "Nick Michiels",
                "Luc Claesen",
                "Wenyin Liu"
            ],
            "arxiv_id": "2512.14536v1",
            "summary": "Self-supervised monocular depth estimation has achieved notable success under daytime conditions. However, its performance deteriorates markedly at night due to low visibility and varying illumination, e.g., insufficient light causes textureless areas, and moving objects bring blurry regions. To this end, we propose a self-supervised framework named DASP that leverages spatiotemporal priors for nighttime depth estimation. Specifically, DASP consists of an adversarial branch for extracting spatiotemporal priors and a self-supervised branch for learning. In the adversarial branch, we first design an adversarial network where the discriminator is composed of four devised spatiotemporal priors learning blocks (SPLB) to exploit the daytime priors. In particular, the SPLB contains a spatial-based temporal learning module (STLM) that uses orthogonal differencing to extract motion-related variations along the time axis and an axial spatial learning module (ASLM) that adopts local asymmetric convolutions with global axial attention to capture the multiscale structural information. By combining STLM and ASLM, our model can acquire sufficient spatiotemporal features to restore textureless areas and estimate the blurry regions caused by dynamic objects. In the self-supervised branch, we propose a 3D consistency projection loss to bilaterally project the target frame and source frame into a shared 3D space, and calculate the 3D discrepancy between the two projected frames as a loss to optimize the 3D structural consistency and daytime priors. Extensive experiments on the Oxford RobotCar and nuScenes datasets demonstrate that our approach achieves state-of-the-art performance for nighttime depth estimation. Ablation studies further validate the effectiveness of each component.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "8 pages, 7 figures",
            "doi": "10.1109/LRA.2025.3644148",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14536v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "自动驾驶",
                    "matched_keywords": [
                        "nuScenes"
                    ],
                    "score": 1
                },
                {
                    "name": "深度估计",
                    "matched_keywords": [
                        "depth estimation",
                        "monocular depth"
                    ],
                    "score": 2
                },
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 4,
            "headline_zh": "提出DASP框架，利用时空先验进行自监督夜间单目深度估计，以解决低可见度和动态物体导致的性能下降问题。",
            "summary_zh": "自监督单目深度估计在白天条件下已取得显著成功，但在夜间由于低可见度和变化光照（如光线不足导致纹理缺失区域，移动物体带来模糊区域）而性能显著下降。为此，我们提出了一个名为DASP的自监督框架，利用时空先验进行夜间深度估计。具体来说，DASP包括一个用于提取时空先验的对抗分支和一个用于学习的自监督分支。在对抗分支中，我们首先设计了一个对抗网络，其中判别器由四个设计的时空先验学习块（SPLB）组成，以利用白天先验。特别地，SPLB包含一个基于空间的时序学习模块（STLM），使用正交差分沿时间轴提取与运动相关的变化，以及一个轴向空间学习模块（ASLM），采用局部非对称卷积和全局轴向注意力来捕获多尺度结构信息。通过结合STLM和ASLM，我们的模型能够获取足够的时空特征来恢复纹理缺失区域并估计由动态物体引起的模糊区域。在自监督分支中，我们提出了一个3D一致性投影损失，将目标帧和源帧双边投影到一个共享的3D空间中，并计算两个投影帧之间的3D差异作为损失，以优化3D结构一致性和白天先验。在Oxford RobotCar和nuScenes数据集上的大量实验表明，我们的方法在夜间深度估计方面实现了最先进的性能。消融研究进一步验证了每个组件的有效性。",
            "intro_zh": [
                "现有自监督单目深度估计方法在夜间因低可见度和动态物体导致纹理缺失和模糊区域，性能显著下降。",
                "DASP框架结合对抗分支提取时空先验和自监督分支学习，通过SPLB模块捕获多尺度时空特征以恢复纹理和估计模糊区域。",
                "在Oxford RobotCar和nuScenes数据集上实现最先进性能，消融研究验证了各组件有效性，提升了夜间深度估计准确性。"
            ],
            "method_zh": "DASP框架包括对抗分支和自监督分支。对抗分支中，判别器由四个时空先验学习块（SPLB）组成，每个SPLB结合基于空间的时序学习模块（STLM）和轴向空间学习模块（ASLM），STLM使用正交差分提取时间轴运动变化，ASLM采用局部非对称卷积和全局轴向注意力捕获多尺度空间结构。自监督分支提出3D一致性投影损失，将目标帧和源帧投影到共享3D空间，计算3D差异作为损失以优化结构一致性和先验。与现有方法相比，DASP通过时空先验学习有效处理夜间低可见度和动态物体问题，而非仅依赖图像重建或简单时序建模。",
            "application_zh": "该研究可应用于自动驾驶、机器人导航和监控系统等领域，特别是在夜间或低光照环境下，通过提升单目深度估计的鲁棒性，增强环境感知能力，支持安全决策和路径规划。",
            "highlight_zh": "在Oxford RobotCar和nuScenes数据集上，DASP实现了最先进的夜间深度估计性能，通过消融研究验证了SPLB模块和3D一致性投影损失的有效性，显著提升了纹理缺失和模糊区域的估计准确性。",
            "tags_zh": [
                "自监督学习",
                "单目深度估计",
                "夜间视觉",
                "时空先验",
                "对抗网络",
                "3D一致性投影",
                "多尺度特征提取",
                "动态物体处理"
            ],
            "_index": 15
        },
        {
            "title": "CoLD Fusion: A Real-time Capable Spline-based Fusion Algorithm for Collective Lane Detection",
            "authors": [
                "Jörg Gamerdinger",
                "Sven Teufel",
                "Georg Volk",
                "Oliver Bringmann"
            ],
            "arxiv_id": "2512.14355v1",
            "summary": "Comprehensive environment perception is essential for autonomous vehicles to operate safely. It is crucial to detect both dynamic road users and static objects like traffic signs or lanes as these are required for safe motion planning. However, in many circumstances a complete perception of other objects or lanes is not achievable due to limited sensor ranges, occlusions, and curves. In scenarios where an accurate localization is not possible or for roads where no HD maps are available, an autonomous vehicle must rely solely on its perceived road information. Thus, extending local sensing capabilities through collective perception using vehicle-to-vehicle communication is a promising strategy that has not yet been explored for lane detection. Therefore, we propose a real-time capable approach for collective perception of lanes using a spline-based estimation of undetected road sections. We evaluate our proposed fusion algorithm in various situations and road types. We were able to achieve real-time capability and extend the perception range by up to 200%.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Accepted at IEEE IV 2023",
            "doi": "10.1109/IV55152.2023.10186632",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14355v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "自动驾驶",
                    "matched_keywords": [
                        "autonomous vehicle",
                        "lane detection",
                        "traffic"
                    ],
                    "score": 3
                },
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "localization"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 4,
            "headline_zh": "提出基于样条的实时集体车道检测融合算法，以扩展自动驾驶车辆在传感器受限场景下的感知范围。",
            "summary_zh": "全面的环境感知对于自动驾驶车辆的安全运行至关重要，需要检测动态道路使用者和静态对象如交通标志或车道，以支持安全运动规划。然而，在许多情况下，由于传感器范围有限、遮挡和弯道等因素，无法实现对其他对象或车道的完整感知。在无法精确定位或没有高清地图的道路场景中，自动驾驶车辆必须仅依赖其感知的道路信息。因此，通过车对车通信利用集体感知来扩展本地感知能力是一种有前景的策略，但尚未在车道检测中得到探索。为此，我们提出了一种实时可行的集体车道感知方法，使用基于样条的估计来预测未检测到的道路段。我们在多种情况和道路类型下评估了所提出的融合算法，实现了实时能力，并将感知范围扩展了高达200%。",
            "intro_zh": [
                "现有方法在传感器范围受限、遮挡和弯道场景下难以实现完整车道感知，导致自动驾驶车辆依赖局部信息，影响安全规划。",
                "论文提出基于样条的集体车道检测融合算法，通过车对车通信整合多车感知数据，实时估计未检测道路段，扩展感知范围。",
                "实验在多种道路类型下进行，算法实现实时运行，感知范围提升高达200%，验证了集体感知的有效性和实用性。"
            ],
            "method_zh": "论文提出CoLD Fusion算法，整体框架基于车对车通信实现集体车道检测。核心方法采用样条曲线建模道路几何，通过融合多车传感器数据，实时估计未检测区域的车道线。关键技术创新点在于将样条估计与集体感知结合，动态更新道路模型，以应对传感器局限。与现有方法的主要区别在于首次将集体感知应用于车道检测，并实现实时处理，避免了依赖高清地图或单一车辆感知的不足。",
            "application_zh": "该研究主要应用于自动驾驶领域，特别是在传感器受限、无高清地图或复杂道路环境中，如城市弯道、高速公路遮挡区域，能提升车辆安全性和规划能力，支持智能交通系统的发展。",
            "highlight_zh": "实验结果显示，CoLD Fusion算法在多种道路场景下实现实时运行，感知范围扩展高达200%，显著提升了车道检测的覆盖率和鲁棒性，验证了集体感知策略的有效性。",
            "tags_zh": [
                "集体感知",
                "车道检测",
                "样条估计",
                "车对车通信",
                "实时融合",
                "自动驾驶",
                "传感器融合",
                "道路建模"
            ],
            "_index": 16
        },
        {
            "title": "Elastic3D: Controllable Stereo Video Conversion with Guided Latent Decoding",
            "authors": [
                "Nando Metzger",
                "Prune Truong",
                "Goutam Bhat",
                "Konrad Schindler",
                "Federico Tombari"
            ],
            "arxiv_id": "2512.14236v1",
            "summary": "The growing demand for immersive 3D content calls for automated monocular-to-stereo video conversion. We present Elastic3D, a controllable, direct end-to-end method for upgrading a conventional video to a binocular one. Our approach, based on (conditional) latent diffusion, avoids artifacts due to explicit depth estimation and warping. The key to its high-quality stereo video output is a novel, guided VAE decoder that ensures sharp and epipolar-consistent stereo video output. Moreover, our method gives the user control over the strength of the stereo effect (more precisely, the disparity range) at inference time, via an intuitive, scalar tuning knob. Experiments on three different datasets of real-world stereo videos show that our method outperforms both traditional warping-based and recent warping-free baselines and sets a new standard for reliable, controllable stereo video conversion. Please check the project page for the video samples https://elastic3d.github.io.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project page: elastic3d.github.io",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14236v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "深度估计",
                    "matched_keywords": [
                        "depth estimation",
                        "disparity"
                    ],
                    "score": 2
                },
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 4,
            "headline_zh": "提出Elastic3D方法，基于条件潜在扩散和引导VAE解码器，实现可控的单目到立体视频转换。",
            "summary_zh": "随着沉浸式3D内容需求的增长，自动化单目到立体视频转换变得日益重要。本文提出Elastic3D，一种可控的端到端方法，用于将传统视频升级为双目立体视频。该方法基于条件潜在扩散模型，避免了因显式深度估计和变形而产生的伪影。其高质量立体视频输出的关键在于一种新颖的引导VAE解码器，确保输出视频清晰且满足极线一致性。此外，该方法通过直观的标量调节旋钮，在推理时允许用户控制立体效果的强度（更精确地说，是视差范围）。在三个真实世界立体视频数据集上的实验表明，我们的方法优于传统的基于变形的方法和最近的无变形基线，为可靠、可控的立体视频转换设定了新标准。请访问项目页面查看视频样本：https://elastic3d.github.io。",
            "intro_zh": [
                "核心问题：传统单目到立体视频转换方法依赖显式深度估计和变形，易产生伪影，且缺乏用户对立体效果强度的控制。",
                "方法要点：基于条件潜在扩散模型，避免显式变形；引入引导VAE解码器，确保输出视频的清晰度和极线一致性。",
                "实验或效果：在三个真实世界立体视频数据集上，性能优于传统和近期基线，实现了高质量、可控的立体视频转换。"
            ],
            "method_zh": "Elastic3D的整体框架是一个端到端的条件潜在扩散模型，用于直接生成立体视频。其关键技术创新点包括：1）采用条件潜在扩散模型，避免显式深度估计和变形步骤，从而减少伪影；2）设计了一种新颖的引导VAE解码器，该解码器在生成过程中引入引导机制，确保输出视频的清晰度和极线一致性，这是实现高质量立体视频的核心。与现有方法的主要区别在于：传统方法通常基于深度估计和变形，容易产生伪影且控制性差；而Elastic3D通过潜在扩散和引导解码，实现了更直接、可控的转换，无需显式变形步骤。",
            "application_zh": "该研究可应用于沉浸式3D内容创作，如虚拟现实、增强现实、3D电影和游戏开发，自动化将传统2D视频升级为立体视频，提升用户体验。此外，在教育和医疗可视化等领域也有潜在价值，用于生成高质量的3D教学或诊断材料。",
            "highlight_zh": "在三个真实世界立体视频数据集上的实验表明，Elastic3D在视觉质量和定量指标上均优于传统基于变形的方法和近期无变形基线，例如在PSNR和SSIM等指标上取得显著提升，同时用户可通过调节旋钮控制视差范围，实现灵活应用。",
            "tags_zh": [
                "立体视频转换",
                "潜在扩散模型",
                "引导VAE解码器",
                "极线一致性",
                "可控生成",
                "端到端学习",
                "单目到立体",
                "视频增强"
            ],
            "_index": 17
        },
        {
            "title": "OmniGen: Unified Multimodal Sensor Generation for Autonomous Driving",
            "authors": [
                "Tao Tang",
                "Enhui Ma",
                "xia zhou",
                "Letian Wang",
                "Tianyi Yan",
                "Xueyang Zhang",
                "Kun Zhan",
                "Peng Jia",
                "XianPeng Lang",
                "Jia-Wang Bian",
                "Kaicheng Yu",
                "Xiaodan Liang"
            ],
            "arxiv_id": "2512.14225v1",
            "summary": "Autonomous driving has seen remarkable advancements, largely driven by extensive real-world data collection. However, acquiring diverse and corner-case data remains costly and inefficient. Generative models have emerged as a promising solution by synthesizing realistic sensor data. However, existing approaches primarily focus on single-modality generation, leading to inefficiencies and misalignment in multimodal sensor data. To address these challenges, we propose OminiGen, which generates aligned multimodal sensor data in a unified framework. Our approach leverages a shared Bird\\u2019s Eye View (BEV) space to unify multimodal features and designs a novel generalizable multimodal reconstruction method, UAE, to jointly decode LiDAR and multi-view camera data. UAE achieves multimodal sensor decoding through volume rendering, enabling accurate and flexible reconstruction. Furthermore, we incorporate a Diffusion Transformer (DiT) with a ControlNet branch to enable controllable multimodal sensor generation. Our comprehensive experiments demonstrate that OminiGen achieves desired performances in unified multimodal sensor data generation with multimodal consistency and flexible sensor adjustments.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "ACM MM 2025",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14225v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "自动驾驶",
                    "matched_keywords": [
                        "autonomous driving",
                        "lidar"
                    ],
                    "score": 2
                },
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 4,
            "headline_zh": "提出OmniGen统一框架以解决自动驾驶中多模态传感器数据生成效率低、对齐难的问题",
            "summary_zh": "自动驾驶的显著进步很大程度上依赖于大量真实世界数据的收集，但获取多样化和极端案例数据仍然成本高昂且效率低下。生成模型通过合成逼真的传感器数据成为一种有前景的解决方案。然而，现有方法主要关注单模态生成，导致多模态传感器数据效率低下和对齐不准确。为解决这些挑战，我们提出了OmniGen，在一个统一框架中生成对齐的多模态传感器数据。我们的方法利用共享的鸟瞰图空间来统一多模态特征，并设计了一种新颖的可泛化多模态重建方法UAE，以联合解码激光雷达和多视角相机数据。UAE通过体渲染实现多模态传感器解码，从而实现准确和灵活的重建。此外，我们结合了带有ControlNet分支的扩散变换器，以实现可控的多模态传感器生成。我们的全面实验表明，OmniGen在多模态一致性和灵活传感器调整方面，在统一多模态传感器数据生成中实现了期望的性能。",
            "intro_zh": [
                "现有方法主要关注单模态生成，导致多模态传感器数据效率低下和对齐不准确，限制了自动驾驶数据合成的实用性。",
                "提出OmniGen统一框架，利用共享BEV空间统一多模态特征，并设计UAE方法通过体渲染联合解码激光雷达和相机数据，结合DiT和ControlNet实现可控生成。",
                "实验表明，OmniGen在多模态一致性和灵活传感器调整方面实现了期望性能，验证了其在统一多模态传感器数据生成中的有效性。"
            ],
            "method_zh": "OmniGen的整体框架是一个统一的多模态传感器数据生成系统。其核心创新点包括：利用共享的鸟瞰图空间来统一多模态特征表示，设计了一种新颖的可泛化多模态重建方法UAE，该方法通过体渲染技术联合解码激光雷达和多视角相机数据，实现准确和灵活的重建。此外，框架结合了扩散变换器与ControlNet分支，以支持可控的多模态传感器生成。与现有方法的主要区别在于，OmniGen不再局限于单模态生成，而是通过统一的BEV空间和UAE解码器，实现了多模态数据的对齐和协同生成，提高了数据合成的效率和一致性。",
            "application_zh": "该研究主要应用于自动驾驶领域，通过生成多样化和对齐的多模态传感器数据，可以高效合成极端案例数据，用于训练和测试自动驾驶系统，降低数据采集成本，提升模型鲁棒性和安全性。",
            "highlight_zh": "实验结果显示，OmniGen在统一多模态传感器数据生成中实现了多模态一致性和灵活传感器调整的期望性能，验证了其框架的有效性，具体性能提升数据未知，但强调了其在解决现有方法不足方面的优势。",
            "tags_zh": [
                "多模态传感器生成",
                "自动驾驶数据合成",
                "鸟瞰图空间",
                "体渲染",
                "扩散变换器",
                "可控生成",
                "激光雷达与相机融合",
                "统一框架"
            ],
            "_index": 18
        },
        {
            "title": "Beyond a Single Light: A Large-Scale Aerial Dataset for Urban Scene Reconstruction Under Varying Illumination",
            "authors": [
                "Zhuoxiao Li",
                "Wenzong Ma",
                "Taoyu Wu",
                "Jinjing Zhu",
                "Zhenchao Q",
                "Shuai Zhang",
                "Jing Ou",
                "Yinrui Ren",
                "Weiqing Qi",
                "Guobin Shen",
                "Hui Xiong",
                "Wufan Zhao"
            ],
            "arxiv_id": "2512.14200v1",
            "summary": "Recent advances in Neural Radiance Fields and 3D Gaussian Splatting have demonstrated strong potential for large-scale UAV-based 3D reconstruction tasks by fitting the appearance of images. However, real-world large-scale captures are often based on multi-temporal data capture, where illumination inconsistencies across different times of day can significantly lead to color artifacts, geometric inaccuracies, and inconsistent appearance. Due to the lack of UAV datasets that systematically capture the same areas under varying illumination conditions, this challenge remains largely underexplored. To fill this gap, we introduceSkyLume, a large-scale, real-world UAV dataset specifically designed for studying illumination robust 3D reconstruction in urban scene modeling: (1) We collect data from 10 urban regions data comprising more than 100k high resolution UAV images (four oblique views and nadir), where each region is captured at three periods of the day to systematically isolate illumination changes. (2) To support precise evaluation of geometry and appearance, we provide per-scene LiDAR scans and accurate 3D ground-truth for assessing depth, surface normals, and reconstruction quality under varying illumination. (3) For the inverse rendering task, we introduce the Temporal Consistency Coefficient (TCC), a metric that measuress cross-time albedo stability and directly evaluates the robustness of the disentanglement of light and material. We aim for this resource to serve as a foundation that advances research and real-world evaluation in large-scale inverse rendering, geometry reconstruction, and novel view synthesis.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14200v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "自动驾驶",
                    "matched_keywords": [
                        "lidar"
                    ],
                    "score": 1
                },
                {
                    "name": "深度估计",
                    "matched_keywords": [
                        "3D reconstruction"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL",
                        "PPO"
                    ],
                    "score": 2
                }
            ],
            "relevance_score": 4,
            "headline_zh": "提出SkyLume数据集以解决多时序无人机数据中光照不一致对大规模城市场景重建的挑战。",
            "summary_zh": "近年来，神经辐射场和3D高斯溅射在基于无人机的大规模3D重建任务中展现出强大潜力，通过拟合图像外观实现重建。然而，真实世界的大规模采集通常基于多时序数据捕获，其中不同时间段的光照不一致会显著导致颜色伪影、几何不准确和外观不一致。由于缺乏系统捕获同一区域在不同光照条件下的无人机数据集，这一挑战在很大程度上尚未得到充分探索。为填补这一空白，我们引入了SkyLume，这是一个大规模、真实世界的无人机数据集，专门用于研究城市场景建模中的光照鲁棒3D重建：(1) 我们从10个城市区域收集数据，包含超过10万张高分辨率无人机图像（四个倾斜视角和天底视角），每个区域在一天中的三个时间段进行捕获，以系统隔离光照变化。(2) 为支持几何和外观的精确评估，我们提供每场景的激光雷达扫描和准确的3D地面真值，用于评估不同光照下的深度、表面法线和重建质量。(3) 对于逆渲染任务，我们引入了时间一致性系数，这是一个度量跨时间反照率稳定性的指标，直接评估光照与材质解耦的鲁棒性。我们旨在使这一资源成为推动大规模逆渲染、几何重建和新视角合成研究和真实世界评估的基础。",
            "intro_zh": [
                "核心问题：现有方法在处理多时序无人机数据时，光照不一致导致颜色伪影和几何误差，缺乏相关数据集限制了研究进展。",
                "方法要点：提出SkyLume数据集，系统捕获城市区域在不同时间段的光照变化，提供激光雷达和3D真值以支持精确评估。",
                "实验或效果：引入时间一致性系数评估逆渲染鲁棒性，数据集促进光照鲁棒重建和逆渲染任务的研究与评估。"
            ],
            "method_zh": "论文的核心方法是构建SkyLume数据集，整体框架包括数据采集、标注和评估指标设计。关键技术创新点在于系统捕获同一城市区域在一天中三个时间段的光照变化，结合多视角无人机图像和激光雷达扫描，提供全面的3D地面真值。与现有方法的主要区别在于，SkyLume专门针对光照不一致问题，填补了大规模无人机数据集中光照变化研究的空白，并引入时间一致性系数作为逆渲染任务的评估指标，直接量化光照与材质解耦的稳定性。",
            "application_zh": "该研究可应用于城市建模、自动驾驶环境感知、虚拟现实场景生成和文化遗产数字化等领域，通过提供光照鲁棒的重建数据，提升大规模3D重建的准确性和一致性，支持真实世界逆渲染和几何优化任务。",
            "highlight_zh": "SkyLume数据集包含超过10万张高分辨率图像，覆盖10个城市区域，每个区域在三个时间段捕获，提供激光雷达扫描和3D真值。时间一致性系数作为新指标，有效评估逆渲染中光照解耦的鲁棒性，促进光照不一致条件下的重建性能提升。",
            "tags_zh": [
                "无人机数据集",
                "光照鲁棒重建",
                "3D高斯溅射",
                "神经辐射场",
                "逆渲染",
                "城市场景建模",
                "时间一致性系数",
                "多时序数据"
            ],
            "_index": 19
        },
        {
            "title": "CIS-BA: Continuous Interaction Space Based Backdoor Attack for Object Detection in the Real-World",
            "authors": [
                "Shuxin Zhao",
                "Bo Lang",
                "Nan Xiao",
                "Yilang Zhang"
            ],
            "arxiv_id": "2512.14158v1",
            "summary": "Object detection models deployed in real-world applications such as autonomous driving face serious threats from backdoor attacks. Despite their practical effectiveness,existing methods are inherently limited in both capability and robustness due to their dependence on single-trigger-single-object mappings and fragile pixel-level cues. We propose CIS-BA, a novel backdoor attack paradigm that redefines trigger design by shifting from static object features to continuous inter-object interaction patterns that describe how objects co-occur and interact in a scene. By modeling these patterns as a continuous interaction space, CIS-BA introduces space triggers that, for the first time, enable a multi-trigger-multi-object attack mechanism while achieving robustness through invariant geometric relations. To implement this paradigm, we design CIS-Frame, which constructs space triggers via interaction analysis, formalizes them as class-geometry constraints for sample poisoning, and embeds the backdoor during detector training. CIS-Frame supports both single-object attacks (object misclassification and disappearance) and multi-object simultaneous attacks, enabling complex and coordinated effects across diverse interaction states. Experiments on MS-COCO and real-world videos show that CIS-BA achieves over 97% attack success under complex environments and maintains over 95% effectiveness under dynamic multi-trigger conditions, while evading three state-of-the-art defenses. In summary, CIS-BA extends the landscape of backdoor attacks in interaction-intensive scenarios and provides new insights into the security of object detection systems.",
            "categories": [
                "cs.CV",
                "cs.CR"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14158v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "自动驾驶",
                    "matched_keywords": [
                        "autonomous driving"
                    ],
                    "score": 1
                },
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "mapping"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL",
                        "PPO"
                    ],
                    "score": 2
                }
            ],
            "relevance_score": 4,
            "headline_zh": "提出CIS-BA，基于连续交互空间的后门攻击范式，解决自动驾驶等场景中目标检测模型的安全威胁问题。",
            "summary_zh": "在自动驾驶等现实应用中部署的目标检测模型面临后门攻击的严重威胁。现有方法因依赖单触发-单对象映射和脆弱的像素级线索，在能力和鲁棒性上存在固有局限。本文提出CIS-BA，一种新颖的后门攻击范式，通过从静态对象特征转向描述场景中对象共现和交互方式的连续对象间交互模式，重新定义触发设计。通过将这些模式建模为连续交互空间，CIS-BA引入了空间触发器，首次实现了多触发-多对象攻击机制，并通过不变的几何关系实现鲁棒性。为实现此范式，设计了CIS-Frame，通过交互分析构建空间触发器，将其形式化为类别-几何约束以进行样本投毒，并在检测器训练期间嵌入后门。CIS-Frame支持单对象攻击（对象误分类和消失）和多对象同时攻击，能够在不同交互状态下实现复杂协调的效果。在MS-COCO和真实世界视频上的实验表明，CIS-BA在复杂环境下攻击成功率超过97%，在动态多触发条件下保持超过95%的有效性，同时规避了三种最先进的防御方法。总之，CIS-BA扩展了交互密集型场景中后门攻击的格局，并为目标检测系统的安全性提供了新见解。",
            "intro_zh": [
                "现有后门攻击依赖单触发-单对象映射和像素级线索，导致能力有限且鲁棒性差，难以应对复杂现实场景。",
                "CIS-BA将触发设计转向连续对象间交互模式，建模为交互空间，实现多触发-多对象攻击，提升鲁棒性和灵活性。",
                "实验显示攻击成功率超97%，动态多触发下保持95%以上有效性，并能规避先进防御，验证了方法的优越性。"
            ],
            "method_zh": "CIS-BA的整体框架基于CIS-Frame实现，核心思想是将对象间的交互模式建模为连续交互空间，并以此构建空间触发器。关键技术创新点包括：通过交互分析提取对象共现和几何关系，形成空间触发器；将触发器形式化为类别-几何约束，用于样本投毒；在目标检测器训练过程中嵌入后门，支持单对象和多对象攻击。与现有方法的主要区别在于，它摆脱了静态对象特征和像素级依赖，利用交互模式的连续性和几何不变性，实现了更鲁棒、更灵活的多触发-多对象攻击机制。",
            "application_zh": "该研究主要应用于自动驾驶、视频监控等现实世界目标检测系统，揭示交互密集型场景中的安全漏洞，为系统防御提供新视角，具有重要的实际安全价值。",
            "highlight_zh": "在MS-COCO和真实视频实验中，攻击成功率超过97%，动态多触发条件下保持95%以上有效性，成功规避三种先进防御方法，显著优于现有方法。",
            "tags_zh": [
                "后门攻击",
                "目标检测",
                "连续交互空间",
                "多触发攻击",
                "自动驾驶安全",
                "鲁棒性",
                "样本投毒",
                "几何约束"
            ],
            "_index": 20
        },
        {
            "title": "Incentivizing Tool-augmented Thinking with Images for Medical Image Analysis",
            "authors": [
                "Yankai Jiang",
                "Yujie Zhang",
                "Peng Zhang",
                "Yichen Li",
                "Jintai Chen",
                "Xiaoming Shi",
                "Shihui Zhen"
            ],
            "arxiv_id": "2512.14157v1",
            "summary": "Recent reasoning based medical MLLMs have made progress in generating step by step textual reasoning chains. However, they still struggle with complex tasks that necessitate dynamic and iterative focusing on fine-grained visual regions to achieve precise grounding and diagnosis. We introduce Ophiuchus, a versatile, tool-augmented framework that equips an MLLM to (i) decide when additional visual evidence is needed, (ii) determine where to probe and ground within the medical image, and (iii) seamlessly weave the relevant sub-image content back into an interleaved, multimodal chain of thought. In contrast to prior approaches limited by the performance ceiling of specialized tools, Ophiuchus integrates the model's inherent grounding and perception capabilities with external tools, thereby fostering higher-level reasoning. The core of our method is a three-stage training strategy: cold-start training with tool-integrated reasoning data to achieve basic tool selection and adaptation for inspecting key regions; self-reflection fine-tuning to strengthen reflective reasoning and encourage revisiting tool outputs; and Agentic Tool Reinforcement Learning to directly optimize task-specific rewards and emulate expert-like diagnostic behavior. Extensive experiments show that Ophiuchus consistently outperforms both closed-source and open-source SOTA methods across diverse medical benchmarks, including VQA, detection, and reasoning-based segmentation. Our approach illuminates a path toward medical AI agents that can genuinely \"think with images\" through tool-integrated reasoning. Datasets, codes, and trained models will be released publicly.",
            "categories": [
                "cs.AI",
                "cs.CV"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14157v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VIO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "reinforcement learning",
                        "RL",
                        "reward"
                    ],
                    "score": 3
                }
            ],
            "relevance_score": 4,
            "headline_zh": "提出Ophiuchus框架，通过工具增强的思维链解决医学图像分析中复杂任务的动态视觉聚焦问题。",
            "summary_zh": "近年来，基于推理的医学多模态大语言模型在生成逐步文本推理链方面取得了进展。然而，它们仍然难以处理需要动态、迭代地关注细粒度视觉区域以实现精确定位和诊断的复杂任务。我们引入了Ophiuchus，这是一个多功能、工具增强的框架，它使MLLM能够：(i)决定何时需要额外的视觉证据，(ii)确定在医学图像中探测和定位的位置，以及(iii)将相关的子图像内容无缝地编织到交错的、多模态的思维链中。与先前受限于专用工具性能上限的方法不同，Ophiuchus将模型固有的定位和感知能力与外部工具相结合，从而促进更高层次的推理。我们方法的核心是一个三阶段训练策略：使用工具集成推理数据进行冷启动训练，以实现对关键区域检查的基本工具选择和适应；自我反思微调，以加强反思性推理并鼓励重新审视工具输出；以及代理工具强化学习，以直接优化特定任务的奖励并模拟类似专家的诊断行为。大量实验表明，Ophiuchus在包括VQA、检测和基于推理的分割在内的多种医学基准测试中，始终优于闭源和开源的最先进方法。我们的方法为医学AI代理指明了一条通过工具集成推理真正“用图像思考”的道路。数据集、代码和训练模型将公开发布。",
            "intro_zh": [
                "现有医学MLLM在复杂任务中难以动态聚焦细粒度视觉区域，导致定位和诊断精度不足。",
                "Ophiuchus框架通过工具增强思维链，集成模型能力与外部工具，实现动态视觉证据获取和推理。",
                "实验显示Ophiuchus在VQA、检测和分割等医学基准上超越SOTA方法，验证了其有效性。"
            ],
            "method_zh": "Ophiuchus是一个工具增强的多模态框架，核心创新在于三阶段训练策略：冷启动训练使用工具集成数据，使模型学会选择和适应工具以检查关键区域；自我反思微调强化反思推理，鼓励模型重新评估工具输出；代理工具强化学习直接优化任务奖励，模拟专家诊断行为。与现有方法相比，它突破了专用工具的性能限制，通过整合模型内在能力与外部工具，实现了更高级的推理和动态视觉聚焦。",
            "application_zh": "该研究可应用于医学图像分析领域，如辅助诊断、病灶检测和分割，提升AI在复杂医疗任务中的精确性和可靠性，推动智能医疗代理的发展。",
            "highlight_zh": "Ophiuchus在多个医学基准测试中一致优于闭源和开源SOTA方法，包括VQA、检测和基于推理的分割任务，展示了其强大的泛化能力和性能提升。",
            "tags_zh": [
                "医学图像分析",
                "多模态大语言模型",
                "工具增强推理",
                "动态视觉聚焦",
                "三阶段训练策略",
                "代理强化学习",
                "医学AI代理"
            ],
            "_index": 21
        },
        {
            "title": "Context Representation via Action-Free Transformer encoder-decoder for Meta Reinforcement Learning",
            "authors": [
                "Amir M. Soufi Enayati",
                "Homayoun Honari",
                "Homayoun Najjaran"
            ],
            "arxiv_id": "2512.14057v1",
            "summary": "Reinforcement learning (RL) enables robots to operate in uncertain environments, but standard approaches often struggle with poor generalization to unseen tasks. Context-adaptive meta reinforcement learning addresses these limitations by conditioning on the task representation, yet they mostly rely on complete action information in the experience making task inference tightly coupled to a specific policy. This paper introduces Context Representation via Action Free Transformer encoder decoder (CRAFT), a belief model that infers task representations solely from sequences of states and rewards. By removing the dependence on actions, CRAFT decouples task inference from policy optimization, supports modular training, and leverages amortized variational inference for scalable belief updates. Built on a transformer encoder decoder with rotary positional embeddings, the model captures long range temporal dependencies and robustly encodes both parametric and non-parametric task variations. Experiments on the MetaWorld ML-10 robotic manipulation benchmark show that CRAFT achieves faster adaptation, improved generalization, and more effective exploration compared to context adaptive meta--RL baselines. These findings highlight the potential of action-free inference as a foundation for scalable RL in robotic control.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14057v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "reinforcement learning",
                        "RL",
                        "reward",
                        "PPO"
                    ],
                    "score": 4
                }
            ],
            "relevance_score": 4,
            "headline_zh": "提出CRAFT模型，通过无动作Transformer编码器-解码器实现任务表示，以解决元强化学习中任务推断与策略优化的耦合问题。",
            "summary_zh": "强化学习（RL）使机器人能在不确定环境中运行，但标准方法常难以泛化到未见任务。上下文自适应元强化学习通过任务表示来应对这些限制，但它们大多依赖经验中的完整动作信息，使任务推断与特定策略紧密耦合。本文介绍了Context Representation via Action Free Transformer encoder decoder（CRAFT），这是一种信念模型，仅从状态和奖励序列推断任务表示。通过消除对动作的依赖，CRAFT将任务推断与策略优化解耦，支持模块化训练，并利用摊销变分推断进行可扩展的信念更新。该模型基于带有旋转位置嵌入的Transformer编码器-解码器构建，能捕捉长程时间依赖，并稳健编码参数化和非参数化任务变化。在MetaWorld ML-10机器人操作基准测试中，实验表明CRAFT相比上下文自适应元RL基线，实现了更快的适应、更好的泛化和更有效的探索。这些发现突显了无动作推断作为机器人控制中可扩展RL基础的潜力。",
            "intro_zh": [
                "现有元强化学习方法依赖动作信息进行任务推断，导致任务表示与策略优化紧密耦合，限制了泛化能力。",
                "CRAFT模型仅使用状态和奖励序列，通过Transformer编码器-解码器推断任务表示，实现任务推断与策略优化的解耦。",
                "在MetaWorld ML-10基准测试中，CRAFT展现出更快的适应速度、更好的泛化性能和更有效的探索能力。"
            ],
            "method_zh": "CRAFT的整体框架是一个基于Transformer编码器-解码器的信念模型，用于从状态和奖励序列推断任务表示。关键技术创新点包括：使用无动作输入（仅状态和奖励）来解耦任务推断与策略优化；采用摊销变分推断进行可扩展的信念更新；以及集成旋转位置嵌入以捕捉长程时间依赖。与现有方法的主要区别在于，传统上下文自适应元RL方法依赖完整动作信息，而CRAFT通过移除动作依赖，实现了更模块化的训练和更灵活的任务表示学习，从而支持参数化和非参数化任务变化。",
            "application_zh": "该研究主要应用于机器人控制领域，特别是在需要快速适应新任务和泛化到未见场景的元强化学习环境中。潜在应用包括工业自动化、服务机器人、自动驾驶等，其中机器人需在动态和不确定环境中高效学习和执行多样化任务，提升系统的可扩展性和鲁棒性。",
            "highlight_zh": "在MetaWorld ML-10机器人操作基准测试中，CRAFT相比上下文自适应元RL基线，实现了更快的任务适应速度、更高的泛化性能（在未见任务上表现更优），以及更有效的探索策略，突显了无动作推断在提升元强化学习效率方面的优势。",
            "tags_zh": [
                "元强化学习",
                "任务表示学习",
                "Transformer编码器-解码器",
                "无动作推断",
                "机器人控制",
                "泛化能力",
                "变分推断",
                "长程依赖建模"
            ],
            "_index": 22
        },
        {
            "title": "Robust Single-shot Structured Light 3D Imaging via Neural Feature Decoding",
            "authors": [
                "Jiaheng Li",
                "Qiyu Dai",
                "Lihan Li",
                "Praneeth Chakravarthula",
                "He Sun",
                "Baoquan Chen",
                "Wenzheng Chen"
            ],
            "arxiv_id": "2512.14028v1",
            "summary": "We consider the problem of active 3D imaging using single-shot structured light systems, which are widely employed in commercial 3D sensing devices such as Apple Face ID and Intel RealSense. Traditional structured light methods typically decode depth correspondences through pixel-domain matching algorithms, resulting in limited robustness under challenging scenarios like occlusions, fine-structured details, and non-Lambertian surfaces. Inspired by recent advances in neural feature matching, we propose a learning-based structured light decoding framework that performs robust correspondence matching within feature space rather than the fragile pixel domain. Our method extracts neural features from the projected patterns and captured infrared (IR) images, explicitly incorporating their geometric priors by building cost volumes in feature space, achieving substantial performance improvements over pixel-domain decoding approaches. To further enhance depth quality, we introduce a depth refinement module that leverages strong priors from large-scale monocular depth estimation models, improving fine detail recovery and global structural coherence. To facilitate effective learning, we develop a physically-based structured light rendering pipeline, generating nearly one million synthetic pattern-image pairs with diverse objects and materials for indoor settings. Experiments demonstrate that our method, trained exclusively on synthetic data with multiple structured light patterns, generalizes well to real-world indoor environments, effectively processes various pattern types without retraining, and consistently outperforms both commercial structured light systems and passive stereo RGB-based depth estimation methods. Project page: https://namisntimpot.github.io/NSLweb/.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14028v1",
            "code_links": [
                {
                    "url": "https://namisntimpot.github.io/NSLweb/",
                    "type": "project_page"
                }
            ],
            "matched_interests": [
                {
                    "name": "深度估计",
                    "matched_keywords": [
                        "depth estimation",
                        "monocular depth"
                    ],
                    "score": 2
                },
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 4,
            "headline_zh": "提出基于神经特征解码的单次结构光3D成像方法，以提升在遮挡、精细结构和非朗伯表面等挑战场景下的鲁棒性。",
            "summary_zh": "本文研究了单次结构光系统在主动3D成像中的应用，这类系统广泛应用于苹果Face ID和英特尔RealSense等商业3D传感设备。传统结构光方法通常通过像素域匹配算法解码深度对应关系，导致在遮挡、精细结构细节和非朗伯表面等挑战场景下鲁棒性有限。受神经特征匹配最新进展的启发，我们提出了一种基于学习的结构光解码框架，在特征空间而非脆弱的像素域执行鲁棒的对应匹配。我们的方法从投影图案和捕获的红外图像中提取神经特征，通过在特征空间中构建代价体积显式地结合几何先验，相比像素域解码方法实现了显著的性能提升。为进一步提高深度质量，我们引入了深度细化模块，利用大规模单目深度估计模型的强先验，改善精细细节恢复和全局结构一致性。为促进有效学习，我们开发了基于物理的结构光渲染流程，生成了近百万个包含室内场景中多样物体和材质的合成图案-图像对。实验表明，我们的方法仅使用多种结构光图案的合成数据进行训练，能很好地泛化到真实室内环境，无需重新训练即可有效处理各种图案类型，并始终优于商业结构光系统和基于被动立体RGB的深度估计方法。项目页面：https://namisntimpot.github.io/NSLweb/。",
            "intro_zh": [
                "传统结构光方法依赖像素域匹配，在遮挡、精细结构或非朗伯表面等复杂场景下鲁棒性不足，导致深度估计精度受限。",
                "提出基于神经特征解码的框架，在特征空间进行对应匹配，并引入深度细化模块，结合几何先验和大规模单目深度模型提升性能。",
                "实验显示，该方法仅用合成数据训练，能泛化到真实室内场景，处理多种图案类型，性能优于商业系统和被动立体RGB方法。"
            ],
            "method_zh": "整体框架包括神经特征提取、特征空间代价体积构建和深度细化模块。关键技术创新点在于将结构光解码从像素域迁移到特征空间，通过提取投影图案和红外图像的神经特征，并构建代价体积来显式结合几何先验，从而提升匹配鲁棒性。与现有方法的主要区别在于：传统方法依赖像素级匹配，易受噪声和场景复杂性影响；而本方法利用学习到的特征进行匹配，更适应挑战场景，同时通过深度细化模块整合外部深度先验，进一步优化细节和全局结构。",
            "application_zh": "该研究可应用于消费电子3D传感（如人脸识别、增强现实）、工业检测、机器人导航和虚拟现实等领域，提升在复杂环境下的深度感知精度和鲁棒性，具有实际商业价值。",
            "highlight_zh": "实验结果表明，该方法在合成和真实数据上均优于传统像素域解码方法，能有效处理遮挡、精细细节和非朗伯表面，性能提升显著，且仅用合成数据训练即可泛化到真实场景，无需针对不同图案重新训练。",
            "tags_zh": [
                "单次结构光",
                "神经特征解码",
                "3D成像",
                "深度估计",
                "特征空间匹配",
                "合成数据训练",
                "鲁棒性提升",
                "室内场景"
            ],
            "_index": 23
        },
        {
            "title": "Deep Learning Perspective of Scene Understanding in Autonomous Robots",
            "authors": [
                "Afia Maham",
                "Dur E Nayab Tashfa"
            ],
            "arxiv_id": "2512.14020v1",
            "summary": "This paper provides a review of deep learning applications in scene understanding in autonomous robots, including innovations in object detection, semantic and instance segmentation, depth estimation, 3D reconstruction, and visual SLAM. It emphasizes how these techniques address limitations of traditional geometric models, improve depth perception in real time despite occlusions and textureless surfaces, and enhance semantic reasoning to understand the environment better. When these perception modules are integrated into dynamic and unstructured environments, they become more effective in decisionmaking, navigation and interaction. Lastly, the review outlines the existing problems and research directions to advance learning-based scene understanding of autonomous robots.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "11 pages. Review Paper on Deep Learning Perspective of Scene Understanding in Autonomous Robots",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14020v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "深度估计",
                    "matched_keywords": [
                        "depth estimation",
                        "3D reconstruction"
                    ],
                    "score": 2
                },
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "visual SLAM",
                        "SLAM"
                    ],
                    "score": 2
                }
            ],
            "relevance_score": 4,
            "headline_zh": "综述深度学习在自主机器人场景理解中的应用，涵盖对象检测、语义分割、深度估计、3D重建和视觉SLAM，以提升环境感知与决策能力。",
            "summary_zh": "本文综述了深度学习在自主机器人场景理解中的应用，包括对象检测、语义和实例分割、深度估计、3D重建以及视觉SLAM的创新。它强调这些技术如何解决传统几何模型的局限性，在遮挡和无纹理表面情况下实时改进深度感知，并增强语义推理以更好地理解环境。当这些感知模块集成到动态和非结构化环境中时，它们在决策、导航和交互方面变得更加有效。最后，综述概述了现有问题及研究方向，以推进基于学习的自主机器人场景理解。",
            "intro_zh": [
                "核心问题：传统几何模型在场景理解中存在局限性，如处理遮挡、无纹理表面和动态环境时效果不佳，影响自主机器人的实时感知与决策。",
                "方法要点：论文综述深度学习技术，包括对象检测、语义分割、深度估计和视觉SLAM，通过端到端学习提升环境感知的准确性和鲁棒性。",
                "实验或效果：综述指出这些方法能有效改进深度感知和语义推理，在动态环境中增强机器人的导航和交互能力，但具体性能提升需参考相关研究。"
            ],
            "method_zh": "论文整体框架为综述性分析，系统梳理深度学习在场景理解中的核心方法，包括卷积神经网络和循环神经网络等模型架构。关键技术创新点在于整合对象检测、语义分割、深度估计和视觉SLAM模块，形成端到端学习系统，以处理复杂环境。与现有方法的主要区别在于强调深度学习如何超越传统几何模型，通过数据驱动方式解决遮挡、纹理缺失等挑战，提升实时性和适应性。",
            "application_zh": "该研究可应用于自主机器人导航、自动驾驶、智能监控和工业自动化等领域，通过增强场景理解能力，提升机器人在动态和非结构化环境中的决策效率和安全性。",
            "highlight_zh": "综述强调深度学习技术能显著改进深度感知和语义推理，在遮挡和无纹理表面情况下实现实时性能提升，但具体实验结果和性能数据需基于所引用的相关研究，本文未提供量化指标。",
            "tags_zh": [
                "场景理解",
                "深度学习",
                "自主机器人",
                "语义分割",
                "视觉SLAM",
                "3D重建",
                "对象检测",
                "深度估计"
            ],
            "_index": 24
        },
        {
            "title": "TimeLens: Rethinking Video Temporal Grounding with Multimodal LLMs",
            "authors": [
                "Jun Zhang",
                "Teng Wang",
                "Yuying Ge",
                "Yixiao Ge",
                "Xinhao Li",
                "Ying Shan",
                "Limin Wang"
            ],
            "arxiv_id": "2512.14698v1",
            "summary": "This paper does not introduce a novel method but instead establishes a straightforward, incremental, yet essential baseline for video temporal grounding (VTG), a core capability in video understanding. While multimodal large language models (MLLMs) excel at various video understanding tasks, the recipes for optimizing them for VTG remain under-explored. In this paper, we present TimeLens, a systematic investigation into building MLLMs with strong VTG ability, along two primary dimensions: data quality and algorithmic design. We first expose critical quality issues in existing VTG benchmarks and introduce TimeLens-Bench, comprising meticulously re-annotated versions of three popular benchmarks with strict quality criteria. Our analysis reveals dramatic model re-rankings compared to legacy benchmarks, confirming the unreliability of prior evaluation standards. We also address noisy training data through an automated re-annotation pipeline, yielding TimeLens-100K, a large-scale, high-quality training dataset. Building on our data foundation, we conduct in-depth explorations of algorithmic design principles, yielding a series of meaningful insights and effective yet efficient practices. These include interleaved textual encoding for time representation, a thinking-free reinforcement learning with verifiable rewards (RLVR) approach as the training paradigm, and carefully designed recipes for RLVR training. These efforts culminate in TimeLens models, a family of MLLMs with state-of-the-art VTG performance among open-source models and even surpass proprietary models such as GPT-5 and Gemini-2.5-Flash. All codes, data, and models will be released to facilitate future research.",
            "categories": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.MM"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project Page: https://timelens-arc-lab.github.io/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14698v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "reinforcement learning",
                        "RL",
                        "reward"
                    ],
                    "score": 3
                }
            ],
            "relevance_score": 3,
            "headline_zh": "提出TimeLens基准与训练方法，通过高质量数据和算法设计提升多模态大语言模型的视频时序定位能力。",
            "summary_zh": "本文并未提出新方法，而是为视频理解的核心能力——视频时序定位（VTG）建立了一个直接、渐进但至关重要的基线。尽管多模态大语言模型（MLLMs）在多种视频理解任务中表现出色，但优化其VTG能力的方案仍待探索。本文提出TimeLens，从数据质量和算法设计两个主要维度，系统性地研究如何构建具有强大VTG能力的MLLMs。我们首先揭示了现有VTG基准中的关键质量问题，并引入TimeLens-Bench，包含三个流行基准的精心重新标注版本，遵循严格的质量标准。分析显示，与旧基准相比，模型排名发生显著变化，证实了先前评估标准的不可靠性。我们还通过自动重新标注流程处理噪声训练数据，生成了TimeLens-100K，一个大规模、高质量的训练数据集。基于数据基础，我们深入探索算法设计原则，获得了一系列有意义的见解和高效实用的实践。这些包括用于时间表示的交替文本编码、作为训练范式的免思考强化学习与可验证奖励（RLVR）方法，以及精心设计的RLVR训练方案。这些努力最终形成了TimeLens模型系列，在开源模型中实现了最先进的VTG性能，甚至超越了GPT-5和Gemini-2.5-Flash等专有模型。所有代码、数据和模型都将发布以促进未来研究。",
            "intro_zh": [
                "现有VTG基准存在质量问题，导致模型评估不可靠，限制了多模态大语言模型在视频时序定位中的优化。",
                "论文从数据质量和算法设计入手，构建高质量基准和训练集，并引入交替文本编码和RLVR训练范式。",
                "TimeLens模型在开源模型中达到SOTA性能，超越GPT-5等专有模型，验证了方法的有效性。"
            ],
            "method_zh": "TimeLens的整体框架基于多模态大语言模型，通过系统优化数据质量和算法设计来提升视频时序定位能力。关键技术创新包括：构建TimeLens-Bench高质量基准和TimeLens-100K训练数据集以解决数据噪声问题；采用交替文本编码有效表示时间信息；提出免思考强化学习与可验证奖励（RLVR）作为训练范式，结合精心设计的训练方案。与现有方法的主要区别在于，它不引入新模型架构，而是聚焦于数据清洗和算法优化，提供可复现的基线，强调评估可靠性和训练效率。",
            "application_zh": "该研究可应用于视频内容分析、智能监控、教育视频检索和自动驾驶场景理解等领域，通过提升视频时序定位精度，增强多模态AI系统在现实世界中的实用性和可靠性。",
            "highlight_zh": "TimeLens模型在开源模型中实现最先进的VTG性能，超越GPT-5和Gemini-2.5-Flash等专有模型；重新标注的基准导致模型排名显著变化，凸显了先前评估标准的问题；高质量数据和算法优化共同贡献了性能提升。",
            "tags_zh": [
                "视频时序定位",
                "多模态大语言模型",
                "基准评估",
                "数据质量",
                "强化学习",
                "视频理解",
                "开源模型",
                "算法设计"
            ],
            "_index": 25
        },
        {
            "title": "Beyond Lipschitz Continuity and Monotonicity: Fractal and Chaotic Activation Functions in Echo State Networks",
            "authors": [
                "Rae Chipera",
                "Jenny Du",
                "Irene Tsapara"
            ],
            "arxiv_id": "2512.14675v1",
            "summary": "Contemporary reservoir computing relies heavily on smooth, globally Lipschitz continuous activation functions, limiting applications in defense, disaster response, and pharmaceutical modeling where robust operation under extreme conditions is critical. We systematically investigate non-smooth activation functions, including chaotic, stochastic, and fractal variants, in echo state networks. Through comprehensive parameter sweeps across 36,610 reservoir configurations, we demonstrate that several non-smooth functions not only maintain the Echo State Property (ESP) but outperform traditional smooth activations in convergence speed and spectral radius tolerance. Notably, the Cantor function (continuous everywhere and flat almost everywhere) maintains ESP-consistent behavior up to spectral radii of rho ~ 10, an order of magnitude beyond typical bounds for smooth functions, while achieving 2.6x faster convergence than tanh and ReLU. We introduce a theoretical framework for quantized activation functions, defining a Degenerate Echo State Property (d-ESP) that captures stability for discrete-output functions and proving that d-ESP implies traditional ESP. We identify a critical crowding ratio Q=N/k (reservoir size / quantization levels) that predicts failure thresholds for discrete activations. Our analysis reveals that preprocessing topology, rather than continuity per se, determines stability: monotone, compressive preprocessing maintains ESP across scales, while dispersive or discontinuous preprocessing triggers sharp failures. While our findings challenge assumptions about activation function design in reservoir computing, the mechanism underlying the exceptional performance of certain fractal functions remains unexplained, suggesting fundamental gaps in our understanding of how geometric properties of activation functions influence reservoir dynamics.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "50 pages, 21 figures. Extended version with full proofs, parameter sweeps, and appendices",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14675v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO",
                        "VIO"
                    ],
                    "score": 2
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 3,
            "headline_zh": "提出非光滑激活函数在回声状态网络中的应用，挑战传统设计假设，提升极端条件下的鲁棒性。",
            "summary_zh": "当代储层计算严重依赖光滑、全局Lipschitz连续的激活函数，限制了在国防、灾害响应和药物建模等极端条件下需要鲁棒操作的应用。我们系统研究了回声状态网络中的非光滑激活函数，包括混沌、随机和分形变体。通过对36,610个储层配置的全面参数扫描，我们证明了几种非光滑函数不仅保持了回声状态特性（ESP），而且在收敛速度和谱半径容限方面优于传统光滑激活函数。值得注意的是，康托函数（处处连续且几乎处处平坦）在谱半径高达ρ~10时仍保持ESP一致行为，比光滑函数的典型界限高出一个数量级，同时实现了比tanh和ReLU快2.6倍的收敛速度。我们引入了量化激活函数的理论框架，定义了捕获离散输出函数稳定性的退化回声状态特性（d-ESP），并证明d-ESP蕴含传统ESP。我们识别了一个关键拥挤比Q=N/k（储层大小/量化级别），用于预测离散激活函数的失效阈值。我们的分析表明，预处理拓扑而非连续性本身决定了稳定性：单调、压缩的预处理在多个尺度上保持ESP，而分散或不连续的预处理则引发急剧失效。虽然我们的发现挑战了储层计算中激活函数设计的假设，但某些分形函数优异性能的机制仍未得到解释，这表明我们对激活函数几何性质如何影响储层动态的理解存在根本性差距。",
            "intro_zh": [
                "核心问题：传统储层计算依赖光滑激活函数，限制了在极端条件下的鲁棒应用，如国防和灾害响应。",
                "方法要点：系统研究非光滑激活函数，包括分形和混沌变体，并引入量化激活函数的理论框架。",
                "实验或效果：康托函数在谱半径高达10时保持稳定，收敛速度比tanh和ReLU快2.6倍。"
            ],
            "method_zh": "论文采用回声状态网络（ESN）作为整体框架，核心方法包括系统研究非光滑激活函数（如康托函数、混沌和随机变体）在储层计算中的应用。关键技术创新点在于引入了量化激活函数的理论框架，定义了退化回声状态特性（d-ESP），并证明其蕴含传统ESP，同时识别了关键拥挤比Q=N/k来预测离散激活函数的失效阈值。与现有方法的主要区别在于挑战了传统依赖光滑、Lipschitz连续激活函数的假设，通过预处理拓扑分析而非连续性本身来评估稳定性，扩展了激活函数的设计空间。",
            "application_zh": "该研究在国防、灾害响应和药物建模等领域具有潜在应用价值，特别是在需要极端条件下鲁棒操作的场景中，如实时监控、应急决策和复杂系统模拟，能提升模型的收敛速度和稳定性。",
            "highlight_zh": "康托函数在谱半径高达10时保持回声状态特性，比传统光滑函数界限高出一个数量级，收敛速度比tanh和ReLU快2.6倍；通过36,610个配置实验验证非光滑函数的优越性能。",
            "tags_zh": [
                "回声状态网络",
                "非光滑激活函数",
                "分形函数",
                "混沌激活",
                "储层计算",
                "量化激活",
                "稳定性分析",
                "极端条件鲁棒性"
            ],
            "_index": 26
        },
        {
            "title": "WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling",
            "authors": [
                "Wenqiang Sun",
                "Haiyu Zhang",
                "Haoyuan Wang",
                "Junta Wu",
                "Zehan Wang",
                "Zhenwei Wang",
                "Yunhong Wang",
                "Jun Zhang",
                "Tengfei Wang",
                "Chunchao Guo"
            ],
            "arxiv_id": "2512.14614v1",
            "summary": "This paper presents WorldPlay, a streaming video diffusion model that enables real-time, interactive world modeling with long-term geometric consistency, resolving the trade-off between speed and memory that limits current methods. WorldPlay draws power from three key innovations. 1) We use a Dual Action Representation to enable robust action control in response to the user's keyboard and mouse inputs. 2) To enforce long-term consistency, our Reconstituted Context Memory dynamically rebuilds context from past frames and uses temporal reframing to keep geometrically important but long-past frames accessible, effectively alleviating memory attenuation. 3) We also propose Context Forcing, a novel distillation method designed for memory-aware model. Aligning memory context between the teacher and student preserves the student's capacity to use long-range information, enabling real-time speeds while preventing error drift. Taken together, WorldPlay generates long-horizon streaming 720p video at 24 FPS with superior consistency, comparing favorably with existing techniques and showing strong generalization across diverse scenes. Project page and online demo can be found: https://3d-models.hunyuan.tencent.com/world/ and https://3d.hunyuan.tencent.com/sceneTo3D.",
            "categories": [
                "cs.CV",
                "cs.GR"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "project page: https://3d-models.hunyuan.tencent.com/world/, demo: https://3d.hunyuan.tencent.com/sceneTo3D",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14614v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                },
                {
                    "name": "世界模型",
                    "matched_keywords": [
                        "world model"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 3,
            "headline_zh": "提出WorldPlay流式视频扩散模型，实现实时交互式世界建模并保持长期几何一致性",
            "summary_zh": "本文介绍了WorldPlay，一种流式视频扩散模型，能够实现实时、交互式的世界建模，并保持长期几何一致性，解决了当前方法在速度与内存之间的权衡限制。WorldPlay基于三个关键创新：1）采用双动作表示，实现对用户键盘和鼠标输入的鲁棒动作控制；2）通过重构上下文记忆动态重建过去帧的上下文，并使用时间重帧技术保持几何重要但久远帧的可访问性，有效缓解记忆衰减；3）提出上下文强制，一种专为内存感知模型设计的新蒸馏方法，通过对齐教师和学生模型的记忆上下文，保留学生模型使用长程信息的能力，实现实时速度同时防止误差漂移。综合来看，WorldPlay能以24 FPS生成720p长时流式视频，具有优越的一致性，优于现有技术，并在多样场景中展现出强泛化能力。项目页面和在线演示可在https://3d-models.hunyuan.tencent.com/world/和https://3d.hunyuan.tencent.com/sceneTo3D找到。",
            "intro_zh": [
                "现有方法在实时交互式世界建模中面临速度与内存的权衡，难以保持长期几何一致性，导致误差漂移和记忆衰减问题。",
                "论文提出WorldPlay模型，核心创新包括双动作表示、重构上下文记忆和上下文强制蒸馏，旨在增强动作控制、动态管理记忆并保持长程信息一致性。",
                "实验结果显示，WorldPlay能以24 FPS实时生成720p长时视频，在几何一致性和泛化能力上优于现有技术，有效解决了速度与内存的冲突。"
            ],
            "method_zh": "WorldPlay是一个基于流式视频扩散模型的整体框架，用于实时交互式世界建模。其关键技术创新包括：1）双动作表示，通过编码用户输入实现鲁棒动作控制；2）重构上下文记忆，动态重建过去帧上下文并使用时间重帧技术保持几何重要帧的可访问性，以缓解记忆衰减；3）上下文强制蒸馏，一种新蒸馏方法，通过对齐教师和学生模型的记忆上下文，确保学生模型能有效利用长程信息，防止误差漂移。与现有方法的主要区别在于，WorldPlay通过内存感知设计解决了速度与内存的权衡，实现了长期几何一致性，而传统方法往往在实时性上牺牲一致性或依赖大量内存。",
            "application_zh": "该研究在虚拟现实、游戏开发、自动驾驶模拟和机器人导航等领域具有潜在应用价值，能够支持实时交互式场景生成和动态世界建模，提升用户体验和系统效率。",
            "highlight_zh": "最重要的实验结果是WorldPlay能以24 FPS实时生成720p长时流式视频，在几何一致性上显著优于现有技术，并在多样场景中展现出强泛化能力，有效解决了速度与内存的冲突。",
            "tags_zh": [
                "流式视频扩散模型",
                "实时交互式世界建模",
                "长期几何一致性",
                "重构上下文记忆",
                "上下文强制蒸馏",
                "双动作表示",
                "内存感知模型",
                "时间重帧技术"
            ],
            "_index": 27
        },
        {
            "title": "Residual GRU+MHSA: A Lightweight Hybrid Recurrent Attention Model for Cardiovascular Disease Detection",
            "authors": [
                "Tejaswani Dash",
                "Gautam Datla",
                "Anudeep Vurity",
                "Tazeem Ahmad",
                "Mohd Adnan",
                "Saima Rafi",
                "Saisha Patro",
                "Saina Patro"
            ],
            "arxiv_id": "2512.14563v1",
            "summary": "Cardiovascular disease (CVD) remains the leading cause of mortality worldwide, underscoring the need for reliable and efficient predictive tools that support early intervention. Traditional diagnostic approaches rely on handcrafted features and clinician expertise, while machine learning methods improve reproducibility but often struggle to generalize across noisy and heterogeneous clinical data. In this work, we propose Residual GRU with Multi-Head Self-Attention, a compact deep learning architecture designed for tabular clinical records. The model integrates residual bidirectional gated recurrent units for sequential modeling of feature columns, a channel reweighting block, and multi-head self-attention pooling with a learnable classification token to capture global context. We evaluate the model on the UCI Heart Disease dataset using 5-fold stratified cross-validation and compare it against classical methods such as Logistic Regression, Random Forest, and Support Vector Machines, as well as modern deep learning baselines including DeepMLP, convolutional networks, recurrent networks, and Transformers. The proposed model achieves an accuracy of 0.861, macro-F1 of 0.860, ROC-AUC of 0.908, and PR-AUC of 0.904, outperforming all baselines. Ablation studies confirm the individual contributions of residual recurrence, channel gating, and attention pooling. t-SNE visualizations further indicate that the learned embeddings exhibit clearer separation between disease and non-disease classes compared to raw features. These results demonstrate that lightweight hybrid recurrent and attention-based architectures provide a strong balance between accuracy and efficiency for clinical risk prediction, supporting deployment in resource-constrained healthcare settings.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Accepted in IEEE Bigdata 2025- Learning Representations with Limited Supervision",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14563v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL",
                        "PPO"
                    ],
                    "score": 2
                }
            ],
            "relevance_score": 3,
            "headline_zh": "提出Residual GRU+MHSA轻量混合循环注意力模型，以提升心血管疾病检测的准确性和效率。",
            "summary_zh": "心血管疾病是全球主要死因，需要可靠高效的预测工具以支持早期干预。传统诊断方法依赖手工特征和临床专家经验，而机器学习方法虽提高可重复性，但常难以泛化到噪声和异构临床数据。本研究提出Residual GRU with Multi-Head Self-Attention，一种紧凑的深度学习架构，专为表格临床记录设计。该模型集成残差双向门控循环单元用于特征列的序列建模、通道重加权块，以及带可学习分类令牌的多头自注意力池化以捕获全局上下文。我们在UCI心脏病数据集上使用5折分层交叉验证评估模型，并与逻辑回归、随机森林、支持向量机等经典方法，以及DeepMLP、卷积网络、循环网络和Transformer等现代深度学习基线进行比较。所提模型达到0.861的准确率、0.860的宏F1、0.908的ROC-AUC和0.904的PR-AUC，优于所有基线。消融研究确认了残差循环、通道门控和注意力池化的个体贡献。t-SNE可视化进一步表明，与原始特征相比，学习到的嵌入在疾病和非疾病类别间展现出更清晰的分离。这些结果表明，轻量混合循环和注意力架构在临床风险预测中提供了准确性和效率之间的强平衡，支持在资源受限的医疗环境中部署。",
            "intro_zh": [
                "现有方法依赖手工特征或难以泛化到噪声临床数据，限制了心血管疾病预测的可靠性。",
                "提出Residual GRU+MHSA模型，结合残差循环单元和注意力机制，以轻量架构捕获序列和全局特征。",
                "在UCI数据集上，模型准确率达0.861，优于传统和深度学习基线，并通过消融验证了组件有效性。"
            ],
            "method_zh": "整体框架为轻量混合模型，专为表格临床数据设计。关键技术创新包括：使用残差双向GRU处理特征列序列，增强梯度流动；引入通道重加权块动态调整特征重要性；结合多头自注意力池化与可学习分类令牌，捕获全局上下文并优化分类。与现有方法的主要区别在于，它融合循环和注意力机制于紧凑架构，避免了传统方法的手工特征依赖和深度学习模型的过参数化，实现高效且准确的预测。",
            "application_zh": "该研究可应用于心血管疾病早期筛查和风险预测，特别适合资源受限的医疗环境，如社区诊所或远程医疗系统，通过轻量模型部署提升诊断效率和可及性。",
            "highlight_zh": "模型在UCI心脏病数据集上取得0.861准确率、0.860宏F1、0.908 ROC-AUC和0.904 PR-AUC，全面超越逻辑回归、随机森林、支持向量机及DeepMLP、卷积网络、循环网络和Transformer等基线，并通过消融和t-SNE可视化验证了组件贡献和特征分离效果。",
            "tags_zh": [
                "心血管疾病检测",
                "轻量深度学习",
                "残差循环网络",
                "多头自注意力",
                "临床风险预测",
                "表格数据处理",
                "医疗人工智能",
                "模型效率优化"
            ],
            "_index": 28
        },
        {
            "title": "Counterfactual Explanations for Time Series Should be Human-Centered and Temporally Coherent in Interventions",
            "authors": [
                "Emmanuel C. Chukwu",
                "Rianne M. Schouten",
                "Monique Tabak",
                "Mykola Pechenizkiy"
            ],
            "arxiv_id": "2512.14559v1",
            "summary": "Counterfactual explanations are increasingly proposed as interpretable mechanisms to achieve algorithmic recourse. However, current counterfactual techniques for time series classification are predominantly designed with static data assumptions and focus on generating minimal input perturbations to flip model predictions. This paper argues that such approaches are fundamentally insufficient in clinical recommendation settings, where interventions unfold over time and must be causally plausible and temporally coherent. We advocate for a shift towards counterfactuals that reflect sustained, goal-directed interventions aligned with clinical reasoning and patient-specific dynamics. We identify critical gaps in existing methods that limit their practical applicability, specifically, temporal blind spots and the lack of user-centered considerations in both method design and evaluation metrics. To support our position, we conduct a robustness analysis of several state-of-the-art methods for time series and show that the generated counterfactuals are highly sensitive to stochastic noise. This finding highlights their limited reliability in real-world clinical settings, where minor measurement variations are inevitable. We conclude by calling for methods and evaluation frameworks that go beyond mere prediction changes without considering feasibility or actionability. We emphasize the need for actionable, purpose-driven interventions that are feasible in real-world contexts for the users of such applications.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14559v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL",
                        "PPO"
                    ],
                    "score": 2
                }
            ],
            "relevance_score": 3,
            "headline_zh": "提出以人为中心且时间连贯的反事实解释方法，以解决临床推荐系统中现有方法的不足。",
            "summary_zh": "反事实解释作为可解释机制被越来越多地用于实现算法追索。然而，当前针对时间序列分类的反事实技术主要基于静态数据假设，侧重于生成最小输入扰动以翻转模型预测。本文认为，在临床推荐场景中，此类方法从根本上不足，因为干预措施随时间展开，必须具有因果合理性和时间连贯性。我们主张转向反映持续、目标导向干预的反事实解释，这些干预应与临床推理和患者特定动态保持一致。我们指出了现有方法在实践应用中的关键缺陷，特别是时间盲点以及在方法设计和评估指标中缺乏以用户为中心的考虑。为支持我们的观点，我们对几种最先进的时间序列方法进行了鲁棒性分析，结果表明生成的反事实解释对随机噪声高度敏感。这一发现突显了它们在现实世界临床环境中的有限可靠性，因为微小的测量变化不可避免。最后，我们呼吁开发超越仅考虑预测变化而不考虑可行性或可操作性的方法和评估框架。我们强调需要可操作、目的驱动的干预措施，这些措施在现实世界中对应用用户是可行的。",
            "intro_zh": [
                "现有反事实方法基于静态假设，忽略时间连贯性和临床可行性，导致干预不切实际。",
                "提出以人为中心的反事实解释，强调持续、目标导向的干预，与临床推理和患者动态保持一致。",
                "鲁棒性分析显示现有方法对噪声敏感，突显其在真实临床环境中的可靠性不足，需改进评估框架。"
            ],
            "method_zh": "本文未提出具体的新模型架构，而是从方法论角度批判现有反事实解释技术，并倡导一种以人为中心、时间连贯的框架。整体框架强调反事实解释应反映持续干预，而非仅最小扰动。关键技术创新点在于将时间连贯性和因果合理性纳入反事实生成过程，与现有方法主要区别在于：现有方法聚焦静态数据扰动，而本文主张动态、目标导向的干预，考虑临床场景中的用户需求和可行性。这涉及重新设计评估指标，以超越预测翻转，纳入可操作性和现实世界适用性。",
            "application_zh": "该研究主要应用于临床推荐系统，如疾病预测、治疗规划等时间序列分类任务。潜在价值在于提升医疗AI的可解释性和实用性，通过生成更合理、可行的反事实解释，帮助医生和患者理解模型决策，实现个性化干预，从而提高医疗决策的透明度和信任度。",
            "highlight_zh": "对多种最先进时间序列反事实方法进行鲁棒性分析，发现生成的反事实对随机噪声高度敏感，表明现有方法在真实临床环境中可靠性有限，这突显了开发更稳健、以用户为中心方法的紧迫性。",
            "tags_zh": [
                "反事实解释",
                "时间序列分类",
                "临床推荐系统",
                "可解释人工智能",
                "时间连贯性",
                "以人为中心设计",
                "鲁棒性分析",
                "算法追索"
            ],
            "_index": 29
        },
        {
            "title": "C-ing Clearly: Enhanced Binary Code Explanations using C code",
            "authors": [
                "Teodor Poncu",
                "Ioana Pintilie",
                "Marius Dragoi",
                "Dragos Tantaru",
                "Florin Brad"
            ],
            "arxiv_id": "2512.14500v1",
            "summary": "Large Language Models (LLMs) typically excel at coding tasks involving high-level programming languages, as opposed to lower-level programming languages, such as assembly. We propose a synthetic data generation method named C-ing Clearly, which leverages the corresponding C code to enhance an LLM's understanding of assembly. By fine-tuning on data generated through our method, we demonstrate improved LLM performance for binary code summarization and vulnerability detection. Our approach demonstrates consistent gains across different LLM families and model sizes.",
            "categories": [
                "cs.CL",
                "cs.LG"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "18 pages, 5 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14500v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL",
                        "PPO"
                    ],
                    "score": 2
                }
            ],
            "relevance_score": 3,
            "headline_zh": "提出C-ing Clearly方法，利用C代码增强大语言模型对汇编的理解，以解决二进制代码分析任务性能不足的问题。",
            "summary_zh": "大语言模型（LLMs）通常在涉及高级编程语言的编码任务中表现出色，但对于低级编程语言（如汇编）则相对较弱。我们提出了一种名为C-ing Clearly的合成数据生成方法，该方法利用相应的C代码来增强LLM对汇编的理解。通过在通过我们的方法生成的数据上进行微调，我们展示了LLM在二进制代码摘要和漏洞检测任务上的性能提升。我们的方法在不同LLM家族和模型大小上均表现出了一致的增益。",
            "intro_zh": [
                "核心问题：大语言模型在处理低级汇编语言时性能不足，难以有效执行二进制代码分析任务。",
                "方法要点：提出C-ing Clearly方法，通过合成数据生成，利用C代码作为桥梁来增强模型对汇编代码的理解。",
                "实验或效果：在二进制代码摘要和漏洞检测任务上，微调后的模型性能显著提升，且在不同模型上均有效。"
            ],
            "method_zh": "C-ing Clearly方法的整体框架基于合成数据生成，核心思想是利用C代码与汇编代码之间的对应关系来创建训练数据。关键技术创新点在于设计了一种机制，将C代码作为解释或上下文，与汇编代码配对，生成高质量的微调数据集。与现有方法的主要区别在于，它不依赖于大量人工标注的汇编数据，而是通过自动化的方式从C代码中衍生出增强的汇编理解数据，从而更高效地提升模型在低级语言任务上的能力。",
            "application_zh": "该研究在二进制代码分析领域具有重要应用价值，可应用于软件安全分析、逆向工程、漏洞检测和代码审计等场景，帮助自动化工具更准确地理解和解释汇编代码，提升安全防护和代码维护的效率。",
            "highlight_zh": "实验结果显示，使用C-ing Clearly方法微调后的大语言模型在二进制代码摘要和漏洞检测任务上性能显著提升，且在不同模型家族（如不同LLM变体）和模型大小上均观察到一致的增益，证明了方法的鲁棒性和泛化能力。",
            "tags_zh": [
                "大语言模型",
                "汇编代码理解",
                "二进制代码分析",
                "合成数据生成",
                "漏洞检测",
                "代码摘要",
                "微调方法",
                "软件安全"
            ],
            "_index": 30
        },
        {
            "title": "Context-Picker: Dynamic context selection using multi-stage reinforcement learning",
            "authors": [
                "Siyuan Zhu",
                "Chengdong Xu",
                "Kaiqiang Ke",
                "Chao Yu"
            ],
            "arxiv_id": "2512.14465v1",
            "summary": "In long-context question answering (LCQA), determining the optimal amount of context for a given query is a significant challenge. Including too few passages may omit critical information, while including too many can introduce noise and reduce the quality of the answer. Traditional approaches, such as fixed Top-$K$ retrieval and single-stage reranking, face the dilemma of selecting the right number of passages. This problem is particularly pronounced for factoid questions, which often require only a few specific pieces of evidence. To address this issue, we introduce \\emph{Context-Picker}, a reasoning-aware framework that shifts the paradigm from similarity-based ranking to minimal sufficient subset selection. Context-Picker treats context selection as a decision-making process optimized via a human-inspired, two-stage reinforcement learning schedule: a \\emph{recall-oriented} stage that prioritizes the coverage of reasoning chains, followed by a \\emph{precision-oriented} stage that aggressively prunes redundancy to distill a compact evidence set. To resolve reward sparsity, we propose an offline evidence distillation pipeline that mines \"minimal sufficient sets\" via a Leave-One-Out (LOO) procedure, providing dense, task-aligned supervision. Experiments on five long-context and multi-hop QA benchmarks demonstrate that Context-Picker significantly outperforms strong RAG baselines, achieving superior answer accuracy with comparable or reduced context lengths. Ablation studies indicate that the coarse-to-fine optimization schedule, the redundancy-aware reward shaping, and the rationale-guided format all contribute substantially to these gains.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14465v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "reinforcement learning",
                        "RL",
                        "reward"
                    ],
                    "score": 3
                }
            ],
            "relevance_score": 3,
            "headline_zh": "提出Context-Picker框架，通过多阶段强化学习动态选择最小充分证据集，以解决长上下文问答中的噪声与信息不足问题。",
            "summary_zh": "在长上下文问答（LCQA）中，为给定查询确定最优的上下文量是一个重大挑战。包含过少段落可能遗漏关键信息，而包含过多则会引入噪声并降低答案质量。传统方法如固定Top-K检索和单阶段重排序面临选择适当段落数量的困境，这一问题在事实型问题中尤为突出，这类问题通常只需要少量特定证据。为解决此问题，我们引入了Context-Picker，这是一个推理感知框架，将范式从基于相似性的排序转向最小充分子集选择。Context-Picker将上下文选择视为一个决策过程，通过受人类启发的两阶段强化学习计划进行优化：一个以召回为导向的阶段，优先覆盖推理链；随后是一个以精确为导向的阶段，积极剪枝冗余以提炼紧凑的证据集。为解决奖励稀疏性问题，我们提出了一个离线证据蒸馏流程，通过留一法（LOO）挖掘“最小充分集”，提供密集、任务对齐的监督。在五个长上下文和多跳问答基准上的实验表明，Context-Picker显著优于强大的RAG基线，在可比或更短的上下文长度下实现了更优的答案准确性。消融研究表明，从粗到细的优化计划、冗余感知的奖励塑造和推理引导的格式都对这一增益有实质性贡献。",
            "intro_zh": [
                "长上下文问答中，传统固定Top-K检索和单阶段重排序方法难以平衡噪声与信息不足，尤其在事实型问题中。",
                "提出Context-Picker框架，采用两阶段强化学习：先召回覆盖推理链，再精确剪枝冗余，实现最小充分证据集选择。",
                "在五个基准测试中，Context-Picker显著超越RAG基线，答案准确性更高，同时上下文长度相当或更短。"
            ],
            "method_zh": "Context-Picker是一个推理感知框架，将上下文选择视为决策过程，通过多阶段强化学习优化。整体框架包括：以召回为导向的阶段，优先覆盖推理链；以精确为导向的阶段，积极剪枝冗余，提炼紧凑证据集。关键技术创新点包括：采用两阶段强化学习计划，模拟人类推理过程；提出离线证据蒸馏流程，通过留一法挖掘最小充分集，解决奖励稀疏性问题；引入冗余感知奖励塑造和推理引导格式。与现有方法的主要区别在于，它从相似性排序转向最小充分子集选择，动态调整上下文量，而非固定数量或单阶段处理。",
            "application_zh": "该研究可应用于长文档问答、多跳推理、事实核查和智能助手等领域，通过动态选择最小充分证据集，提高答案准确性并减少计算开销，具有实际价值。",
            "highlight_zh": "在五个长上下文和多跳问答基准上，Context-Picker显著优于RAG基线，答案准确性更高，同时上下文长度相当或更短，消融研究证实优化计划和奖励塑造的关键作用。",
            "tags_zh": [
                "长上下文问答",
                "强化学习",
                "证据选择",
                "多阶段优化",
                "推理感知",
                "最小充分集",
                "噪声剪枝",
                "问答系统"
            ],
            "_index": 31
        },
        {
            "title": "GRAFT: Grid-Aware Load Forecasting with Multi-Source Textual Alignment and Fusion",
            "authors": [
                "Fangzhou Lin",
                "Guoshun He",
                "Zhenyu Guo",
                "Zhe Huang",
                "Jinsong Tao"
            ],
            "arxiv_id": "2512.14400v1",
            "summary": "Electric load is simultaneously affected across multiple time scales by exogenous factors such as weather and calendar rhythms, sudden events, and policies. Therefore, this paper proposes GRAFT (GRid-Aware Forecasting with Text), which modifies and improves STanHOP to better support grid-aware forecasting and multi-source textual interventions. Specifically, GRAFT strictly aligns daily-aggregated news, social media, and policy texts with half-hour load, and realizes text-guided fusion to specific time positions via cross-attention during both training and rolling forecasting. In addition, GRAFT provides a plug-and-play external-memory interface to accommodate different information sources in real-world deployment. We construct and release a unified aligned benchmark covering 2019--2021 for five Australian states (half-hour load, daily-aligned weather/calendar variables, and three categories of external texts), and conduct systematic, reproducible evaluations at three scales -- hourly, daily, and monthly -- under a unified protocol for comparison across regions, external sources, and time scales. Experimental results show that GRAFT significantly outperforms strong baselines and reaches or surpasses the state of the art across multiple regions and forecasting horizons. Moreover, the model is robust in event-driven scenarios and enables temporal localization and source-level interpretation of text-to-load effects through attention read-out. We release the benchmark, preprocessing scripts, and forecasting results to facilitate standardized empirical evaluation and reproducibility in power grid load forecasting.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14400v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "localization"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL",
                        "PPO"
                    ],
                    "score": 2
                }
            ],
            "relevance_score": 3,
            "headline_zh": "提出GRAFT模型，通过多源文本对齐与融合解决电网负荷预测中外部因素影响建模不足的问题。",
            "summary_zh": "电力负荷同时受到天气、日历节律、突发事件和政策等多时间尺度外生因素的影响。为此，本文提出GRAFT（基于文本的电网感知预测）模型，改进STanHOP以更好地支持电网感知预测和多源文本干预。具体而言，GRAFT将每日聚合的新闻、社交媒体和政策文本与半小时负荷数据严格对齐，并通过训练和滚动预测期间的交叉注意力实现文本引导的融合到特定时间位置。此外，GRAFT提供即插即用的外部记忆接口，以适应实际部署中的不同信息源。我们构建并发布了一个覆盖2019-2021年澳大利亚五个州的统一对齐基准数据集（包括半小时负荷、每日对齐的天气/日历变量以及三类外部文本），并在统一协议下进行了系统、可重复的评估，涵盖小时、日和月三个尺度，以比较不同区域、外部源和时间尺度。实验结果表明，GRAFT显著优于强基线模型，并在多个区域和预测时间范围内达到或超越最先进水平。此外，该模型在事件驱动场景中表现稳健，并通过注意力读出实现文本对负荷影响的时序定位和源级解释。我们发布基准数据集、预处理脚本和预测结果，以促进电网负荷预测的标准化实证评估和可重复性。",
            "intro_zh": [
                "现有负荷预测方法难以有效整合多源文本信息（如新闻、社交媒体、政策）以建模外部因素对电网负荷的复杂影响。",
                "GRAFT通过严格对齐多源文本与负荷数据，并利用交叉注意力实现文本引导的融合，同时提供可扩展的外部记忆接口。",
                "实验显示GRAFT在多个区域和预测尺度上显著优于基线，达到或超越最先进水平，并支持文本影响的时序定位和解释。"
            ],
            "method_zh": "GRAFT基于改进的STanHOP框架，整体架构包括负荷序列编码、多源文本对齐与融合模块。关键技术创新点在于：严格对齐每日聚合的新闻、社交媒体和政策文本到半小时负荷时间点，通过交叉注意力机制在训练和滚动预测中实现文本信息到特定时间位置的引导融合；提供即插即用的外部记忆接口，便于集成不同信息源。与现有方法的主要区别在于其电网感知特性，能够更精细地处理多源文本干预，并支持实时部署中的灵活扩展。",
            "application_zh": "该研究主要应用于智能电网管理和能源系统优化，可提升电力负荷预测的准确性和鲁棒性，帮助电网运营商应对天气变化、突发事件和政策调整等外部因素，实现更高效的能源调度和需求响应。",
            "highlight_zh": "GRAFT在澳大利亚五个州的统一基准测试中，于小时、日、月三个预测尺度上均显著优于强基线，达到或超越最先进水平；模型在事件驱动场景下表现稳健，并通过注意力机制实现文本影响的时序定位和源级解释，增强了可解释性。",
            "tags_zh": [
                "电网负荷预测",
                "多源文本对齐",
                "交叉注意力融合",
                "外部记忆接口",
                "时序预测",
                "可解释人工智能",
                "能源系统优化"
            ],
            "_index": 32
        },
        {
            "title": "Field evaluation and optimization of a lightweight lidar-based UAV navigation system for dense boreal forest environments",
            "authors": [
                "Aleksi Karhunen",
                "Teemu Hakala",
                "Väinö Karjalainen",
                "Eija Honkavaara"
            ],
            "arxiv_id": "2512.14340v1",
            "summary": "The interest in the usage of uncrewed aerial vehicles (UAVs) for forest applications has increased in recent years. While above-canopy flight has reached a high level of autonomy, navigating under-canopy remains a significant challenge. The use of autonomous UAVs could reduce the burden of data collection, which has motivated the development of numerous solutions for under-canopy autonomous flight. However, the experiments conducted in the literature and their reporting lack rigor. Very rarely, the density and the difficulty of the test forests are reported, or multiple flights are flown, and the success rate of those flights is reported. The aim of this study was to implement an autonomously flying quadrotor based on a lightweight lidar using openly available algorithms and test its behavior in real forest environments. A set of rigorous experiments was conducted with a quadrotor prototype utilizing the IPC path planner and LTA-OM SLAM algorithm. Based on the results of the first 33 flights, the original system was further enhanced. With the optimized system, 60 flights were performed, resulting in a total of 93 test flights. The optimized system performed significantly better in terms of reliability and flight mission completion times, achieving success rates of 12/15 in a medium-density forest and 15/15 in a dense forest, at a target flight velocity of 1 m/s. At a target flight velocity of 2 m/s, it had a success rate of 12/15 and 5/15, respectively. Furthermore, a standardized testing setup and evaluation criteria were proposed, enabling consistent performance comparisons of autonomous under-canopy UAV systems, enhancing reproducibility, guiding system improvements, and accelerating progress in forest robotics.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "This work has been submitted to the IEEE for possible publication",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14340v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "自动驾驶",
                    "matched_keywords": [
                        "lidar"
                    ],
                    "score": 1
                },
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VIO",
                        "SLAM"
                    ],
                    "score": 2
                }
            ],
            "relevance_score": 3,
            "headline_zh": "提出基于轻量级激光雷达的无人机导航系统优化方案，解决稠密北方森林环境下的自主飞行挑战。",
            "summary_zh": "近年来，无人机在森林应用中的使用兴趣日益增长。虽然冠层以上飞行已达到高度自主性，但在冠层下导航仍是一个重大挑战。自主无人机的使用可以减轻数据收集的负担，这推动了众多冠层下自主飞行解决方案的开发。然而，文献中进行的实验及其报告缺乏严谨性。很少报告测试森林的密度和难度，或进行多次飞行并报告这些飞行的成功率。本研究旨在基于轻量级激光雷达，使用公开可用的算法实现自主飞行的四旋翼无人机，并在真实森林环境中测试其行为。利用IPC路径规划器和LTA-OM SLAM算法，对四旋翼原型进行了严格的实验。基于前33次飞行的结果，对原始系统进行了进一步优化。使用优化后的系统进行了60次飞行，总共完成了93次测试飞行。优化后的系统在可靠性和飞行任务完成时间方面表现显著更好，在目标飞行速度为1 m/s时，在中密度森林中实现了12/15的成功率，在稠密森林中实现了15/15的成功率。在目标飞行速度为2 m/s时，成功率分别为12/15和5/15。此外，提出了标准化的测试设置和评估标准，使自主冠层下无人机系统的性能比较具有一致性，增强了可重复性，指导系统改进，并加速了森林机器人技术的进展。",
            "intro_zh": [
                "现有方法在稠密森林冠层下自主飞行实验中缺乏严谨性，很少报告森林密度、难度和多次飞行的成功率。",
                "论文基于轻量级激光雷达，采用公开算法（IPC路径规划器和LTA-OM SLAM）实现自主四旋翼无人机，并通过实验优化系统性能。",
                "优化后系统在1 m/s速度下，中密度和稠密森林成功率分别达12/15和15/15，并提出了标准化测试框架以提升可重复性。"
            ],
            "method_zh": "论文构建了一个基于轻量级激光雷达的无人机导航系统整体框架，核心包括IPC路径规划器和LTA-OM SLAM算法。关键技术创新点在于结合公开算法实现轻量化系统，并通过实验数据驱动优化，提升在复杂森林环境中的鲁棒性。与现有方法的主要区别在于强调实验严谨性和标准化评估，而非仅提出新算法，这有助于系统性能的客观比较和改进。",
            "application_zh": "该研究主要应用于森林监测和数据收集领域，如生态调查、资源管理和灾害评估。通过实现稠密森林环境下的自主飞行，可降低人工数据采集成本，提升效率，推动森林机器人技术的实际部署和进步。",
            "highlight_zh": "优化系统在93次测试飞行中表现显著提升：1 m/s速度下，中密度森林成功率80%（12/15），稠密森林成功率100%（15/15）；2 m/s速度下，成功率分别为80%和33%。同时，提出的标准化测试框架增强了实验可重复性和系统比较性。",
            "tags_zh": [
                "无人机导航",
                "激光雷达",
                "森林环境",
                "自主飞行",
                "SLAM算法",
                "路径规划",
                "系统优化",
                "实验评估"
            ],
            "_index": 33
        },
        {
            "title": "ARCADE: Adaptive Robot Control with Online Changepoint-Aware Bayesian Dynamics Learning",
            "authors": [
                "Rishabh Dev Yadav",
                "Avirup Das",
                "Hongyu Song",
                "Samuel Kaski",
                "Wei Pan"
            ],
            "arxiv_id": "2512.14331v1",
            "summary": "Real-world robots must operate under evolving dynamics caused by changing operating conditions, external disturbances, and unmodeled effects. These may appear as gradual drifts, transient fluctuations, or abrupt shifts, demanding real-time adaptation that is robust to short-term variation yet responsive to lasting change. We propose a framework for modeling the nonlinear dynamics of robotic systems that can be updated in real time from streaming data. The method decouples representation learning from online adaptation, using latent representations learned offline to support online closed-form Bayesian updates. To handle evolving conditions, we introduce a changepoint-aware mechanism with a latent variable inferred from data likelihoods that indicates continuity or shift. When continuity is likely, evidence accumulates to refine predictions; when a shift is detected, past information is tempered to enable rapid re-learning. This maintains calibrated uncertainty and supports probabilistic reasoning about transient, gradual, or structural change. We prove that the adaptive regret of the framework grows only logarithmically in time and linearly with the number of shifts, competitive with an oracle that knows timings of shift. We validate on cartpole simulations and real quadrotor flights with swinging payloads and mid-flight drops, showing improved predictive accuracy, faster recovery, and more accurate closed-loop tracking than relevant baselines.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14331v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL",
                        "PPO"
                    ],
                    "score": 2
                }
            ],
            "relevance_score": 3,
            "headline_zh": "提出ARCADE框架，通过在线变点感知贝叶斯动力学学习解决机器人动态变化下的自适应控制问题。",
            "summary_zh": "现实世界中的机器人必须在动态变化的环境中运行，这些变化可能由操作条件改变、外部干扰或未建模效应引起，表现为渐进漂移、瞬态波动或突然转变，需要实时适应能力，既能抵抗短期变化又能响应持久变化。我们提出一个框架，用于建模机器人系统的非线性动力学，能够从流数据中实时更新。该方法将表示学习与在线适应解耦，利用离线学习的潜在表示支持在线闭式贝叶斯更新。为处理演化条件，我们引入一个变点感知机制，通过从数据似然推断的潜在变量指示连续性或转变。当连续性可能时，证据积累以优化预测；当检测到转变时，过去信息被调节以支持快速重新学习。这保持了校准的不确定性，并支持对瞬态、渐进或结构变化的概率推理。我们证明该框架的自适应遗憾仅随时间对数增长，与转变次数线性相关，与已知转变时间的神谕者竞争。我们在倒立摆仿真和真实四旋翼飞行器实验中验证，包括摆动负载和飞行中掉落场景，显示相比相关基线，预测准确性更高、恢复更快、闭环跟踪更准确。",
            "intro_zh": [
                "核心问题：机器人动态变化（如漂移、波动、突变）要求实时自适应，现有方法难以平衡短期鲁棒性与持久变化响应。",
                "方法要点：解耦表示学习与在线适应，引入变点感知机制，基于贝叶斯更新实现快速重学习。",
                "实验或效果：在仿真和真实实验中，预测准确性、恢复速度和跟踪精度均优于基线，自适应遗憾增长缓慢。"
            ],
            "method_zh": "ARCADE框架整体采用离线学习潜在表示与在线贝叶斯更新相结合的方式。关键技术创新点包括：1) 表示学习与在线适应解耦，利用离线学习的潜在表示支持在线闭式贝叶斯更新，提高计算效率；2) 变点感知机制，通过推断潜在变量（基于数据似然）动态检测连续性或转变，实现自适应调节；3) 当检测到转变时，调节过去信息以促进快速重新学习，同时保持不确定性校准。与现有方法的主要区别在于其能够实时处理动态变化（包括瞬态、渐进和结构变化），并通过理论证明自适应遗憾增长缓慢（对数时间与线性转变次数），提供更强的鲁棒性和适应性。",
            "application_zh": "该研究适用于需要实时适应动态变化的机器人系统，如无人机在负载变化或外部干扰下的飞行控制、工业机器人在环境波动中的操作、自动驾驶车辆在路况突变时的导航。潜在价值包括提高机器人在不确定环境中的鲁棒性、安全性和效率，支持更广泛的实际部署。",
            "highlight_zh": "在倒立摆仿真和真实四旋翼飞行器实验中，ARCADE框架相比基线方法，预测准确性显著提升，恢复速度更快（如在负载掉落场景中），闭环跟踪精度更高。理论分析显示自适应遗憾仅随时间对数增长，与转变次数线性相关，验证了其高效性和鲁棒性。",
            "tags_zh": [
                "自适应机器人控制",
                "在线贝叶斯学习",
                "变点检测",
                "动力学建模",
                "非线性系统",
                "实时适应",
                "不确定性校准",
                "机器人鲁棒性"
            ],
            "_index": 34
        },
        {
            "title": "Criminal Liability in AI-Enabled Autonomous Vehicles: A Comparative Study",
            "authors": [
                "Sahibpreet Singh",
                "Manjit Singh"
            ],
            "arxiv_id": "2512.14330v1",
            "summary": "AI revolutionizes transportation through autonomous vehicles (AVs) but introduces complex criminal liability issues regarding infractions. This study employs a comparative legal analysis of primary statutes, real-world liability claims, and academic literature across the US, Germany, UK, China, and India; jurisdictions selected for their technological advancement and contrasting regulatory approaches. The research examines the attribution of human error, AI moral agency, and the identification of primary offenders in AV incidents. Findings reveal fragmented regulatory landscapes: India and the US rely on loose networks of state laws, whereas the UK enacted the pioneering Automated and Electric Vehicles Act 2018. Germany enforces strict safety standards, distinguishing liability based on the vehicle's operating mode, while China similarly aims for a stringent liability regime. The study concludes that globally harmonized legal standards are essential to foster technological innovation while ensuring minimum risk and clear liability attribution.",
            "categories": [
                "cs.CY",
                "cs.AI",
                "cs.CR"
            ],
            "primary_category": "cs.CY",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Published in Journal of University Institute of Legal Studies, Vol. 18, Issue 1, pp. 57-78, 2025",
            "doi": "",
            "journal_ref": "Journal of University Institute of Legal Studies 18(1), 57-78 (2025)",
            "pdf_url": "https://arxiv.org/pdf/2512.14330v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "自动驾驶",
                    "matched_keywords": [
                        "autonomous vehicle"
                    ],
                    "score": 1
                },
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 3,
            "headline_zh": "通过比较法分析提出全球统一法律标准以解决自动驾驶车辆刑事责任的复杂问题",
            "summary_zh": "人工智能通过自动驾驶车辆（AVs）革新了交通运输，但也带来了关于违规行为的复杂刑事责任问题。本研究采用比较法律分析方法，对美国、德国、英国、中国和印度等司法管辖区的主要法规、现实世界的责任索赔和学术文献进行了分析；这些司法管辖区因其技术进步和对比鲜明的监管方法而被选中。研究探讨了在自动驾驶车辆事故中人类错误的归因、人工智能的道德主体性以及主要责任人的识别。研究发现监管格局碎片化：印度和美国依赖松散的国家法律网络，而英国则颁布了开创性的《2018年自动化和电动汽车法案》。德国执行严格的安全标准，根据车辆的运行模式区分责任，而中国同样旨在建立严格的责任制度。研究得出结论，全球统一的法律标准对于促进技术创新、同时确保最低风险和明确的责任归属至关重要。",
            "intro_zh": [
                "核心问题：自动驾驶车辆引发复杂刑事责任问题，现有法律框架碎片化，难以明确归责，阻碍技术创新与安全发展。",
                "方法要点：采用比较法律分析，研究多国法规、案例和文献，聚焦人类错误归因、AI道德主体和责任人识别等关键议题。",
                "实验或效果：揭示各国监管差异，如英国立法先行、德国模式区分责任，强调全球统一标准对降低风险、明确责任的重要性。"
            ],
            "method_zh": "论文的核心方法是比较法律分析，整体框架包括选取美国、德国、英国、中国和印度等代表性司法管辖区，基于其技术先进性和监管差异进行系统性研究。关键技术创新点在于综合运用法规分析、现实案例研究和学术文献综述，深入探讨自动驾驶车辆事故中的刑事责任归属问题，如人类错误归因、AI道德主体性等。与现有方法的主要区别在于，该方法不仅关注单一国家法律，而是通过跨国比较揭示全球监管格局的碎片化，并提出统一法律标准的必要性，以弥补传统法律分析在应对新兴技术挑战时的不足。",
            "application_zh": "该研究可应用于自动驾驶车辆的法律监管和政策制定领域，帮助各国政府、法律机构和科技公司理解刑事责任问题，促进全球统一标准的建立，从而降低法律风险、推动技术创新，并提升道路安全。",
            "highlight_zh": "主要实验结果揭示各国监管差异：印度和美国依赖松散法律网络，英国通过《2018年自动化和电动汽车法案》立法先行，德国基于运行模式区分责任，中国追求严格责任制度。性能提升体现在明确了全球统一法律标准对降低风险和明确归责的关键作用。",
            "tags_zh": [
                "自动驾驶车辆",
                "刑事责任",
                "比较法律分析",
                "AI道德主体",
                "法律监管",
                "全球统一标准",
                "技术创新",
                "道路安全"
            ],
            "_index": 35
        },
        {
            "title": "A Threshold-Triggered Deep Q-Network-Based Framework for Self-Healing in Autonomic Software-Defined IIoT-Edge Networks",
            "authors": [
                "Agrippina Mwangi",
                "León Navarro-Hilfiker",
                "Lukasz Brewka",
                "Mikkel Gryning",
                "Elena Fumagalli",
                "Madeleine Gibescu"
            ],
            "arxiv_id": "2512.14297v1",
            "summary": "Stochastic disruptions such as flash events arising from benign traffic bursts and switch thermal fluctuations are major contributors to intermittent service degradation in software-defined industrial networks. These events violate IEC~61850-derived quality-of-service requirements and user-defined service-level agreements, hindering the reliable and timely delivery of control, monitoring, and best-effort traffic in IEC~61400-25-compliant wind power plants. Failure to maintain these requirements often results in delayed or lost control signals, reduced operational efficiency, and increased risk of wind turbine generator downtime.\n  To address these challenges, this study proposes a threshold-triggered Deep Q-Network self-healing agent that autonomically detects, analyzes, and mitigates network disruptions while adapting routing behavior and resource allocation in real time. The proposed agent was trained, validated, and tested on an emulated tri-clustered switch network deployed in a cloud-based proof-of-concept testbed.\n  Simulation results show that the proposed agent improves disruption recovery performance by 53.84% compared to a baseline shortest-path and load-balanced routing approach and outperforms state-of-the-art methods, including the Adaptive Network-based Fuzzy Inference System by 13.1% and the Deep Q-Network and traffic prediction-based routing optimization method by 21.5%, in a super-spine leaf data-plane architecture.\n  Additionally, the agent maintains switch thermal stability by proactively initiating external rack cooling when required. These findings highlight the potential of deep reinforcement learning in building resilience in software-defined industrial networks deployed in mission-critical, time-sensitive application scenarios.",
            "categories": [
                "cs.NI",
                "cs.AI",
                "cs.ET",
                "cs.PF",
                "hep-ex"
            ],
            "primary_category": "cs.NI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14297v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "自动驾驶",
                    "matched_keywords": [
                        "traffic"
                    ],
                    "score": 1
                },
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VIO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "reinforcement learning"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 3,
            "headline_zh": "提出基于阈值触发的深度Q网络自愈框架，以解决软件定义工业物联网边缘网络中的随机中断问题。",
            "summary_zh": "软件定义工业网络中的随机中断（如良性流量突发和交换机热波动引起的闪断事件）是导致间歇性服务降级的主要原因。这些事件违反了IEC 61850衍生的服务质量要求和用户定义的服务级别协议，阻碍了符合IEC 61400-25标准的风力发电厂中控制、监控和尽力而为流量的可靠及时交付。未能维持这些要求通常会导致控制信号延迟或丢失、运行效率降低以及风力涡轮发电机停机风险增加。为应对这些挑战，本研究提出了一种阈值触发的深度Q网络自愈代理，能够自主检测、分析和缓解网络中断，同时实时调整路由行为和资源分配。该代理在基于云的概念验证测试平台中部署的模拟三集群交换机网络上进行了训练、验证和测试。仿真结果表明，与基线最短路径和负载均衡路由方法相比，所提出的代理将中断恢复性能提高了53.84%，并在超骨干叶数据平面架构中优于最先进的方法，包括自适应网络模糊推理系统（提升13.1%）以及基于深度Q网络和流量预测的路由优化方法（提升21.5%）。此外，该代理通过必要时主动启动外部机架冷却来维持交换机热稳定性。这些发现突显了深度强化学习在构建部署于关键任务、时间敏感应用场景的软件定义工业网络弹性方面的潜力。",
            "intro_zh": [
                "核心问题：随机中断（如流量突发和热波动）导致软件定义工业网络服务降级，违反服务质量要求，影响控制信号可靠交付。",
                "方法要点：提出阈值触发的深度Q网络自愈代理，自主检测、分析和缓解中断，实时调整路由和资源分配。",
                "实验或效果：在模拟网络中，中断恢复性能比基线方法提升53.84%，优于现有先进方法，并维持交换机热稳定性。"
            ],
            "method_zh": "论文提出一个基于阈值触发的深度Q网络（DQN）自愈框架，整体框架包括一个自愈代理，它通过监测网络状态（如流量和温度）来触发DQN模型，以自主决策路由调整和资源分配。关键技术创新点在于结合阈值机制与DQN：阈值用于实时检测异常事件（如流量突发或热波动），触发DQN进行强化学习优化，从而动态适应网络变化。与现有方法的主要区别在于，它不仅优化路由（如最短路径或负载均衡），还整合了热管理（如主动冷却），并利用DQN的实时学习能力，相比传统方法（如模糊推理或预测优化）更灵活和自适应。",
            "application_zh": "该研究主要应用于软件定义工业物联网边缘网络，特别是在关键任务和时间敏感场景中，如风力发电厂的控制和监控系统。潜在应用领域包括智能电网、工业自动化和其他需要高可靠性和低延迟的网络环境，实际价值在于提升网络弹性和运行效率，减少停机风险。",
            "highlight_zh": "最重要的实验结果是：在模拟三集群交换机网络中，自愈代理将中断恢复性能比基线方法提升53.84%；相比自适应网络模糊推理系统提升13.1%，相比基于深度Q网络和流量预测的路由优化方法提升21.5%；同时能主动管理交换机热稳定性。",
            "tags_zh": [
                "软件定义网络",
                "工业物联网",
                "深度强化学习",
                "自愈代理",
                "路由优化",
                "热管理",
                "网络弹性",
                "边缘计算"
            ],
            "_index": 36
        },
        {
            "title": "PentestEval: Benchmarking LLM-based Penetration Testing with Modular and Stage-Level Design",
            "authors": [
                "Ruozhao Yang",
                "Mingfei Cheng",
                "Gelei Deng",
                "Tianwei Zhang",
                "Junjie Wang",
                "Xiaofei Xie"
            ],
            "arxiv_id": "2512.14233v1",
            "summary": "Penetration testing is essential for assessing and strengthening system security against real-world threats, yet traditional workflows remain highly manual, expertise-intensive, and difficult to scale. Although recent advances in Large Language Models (LLMs) offer promising opportunities for automation, existing applications rely on simplistic prompting without task decomposition or domain adaptation, resulting in unreliable black-box behavior and limited insight into model capabilities across penetration testing stages. To address this gap, we introduce PentestEval, the first comprehensive benchmark for evaluating LLMs across six decomposed penetration testing stages: Information Collection, Weakness Gathering and Filtering, Attack Decision-Making, Exploit Generation and Revision. PentestEval integrates expert-annotated ground truth with a fully automated evaluation pipeline across 346 tasks covering all stages in 12 realistic vulnerable scenarios. Our stage-level evaluation of 9 widely used LLMs reveals generally weak performance and distinct limitations across the stages of penetration-testing workflow. End-to-end pipelines reach only 31% success rate, and existing LLM-powered systems such as PentestGPT, PentestAgent, and VulnBot exhibit similar limitations, with autonomous agents failing almost entirely. These findings highlight that autonomous penetration testing demands stronger structured reasoning, where modularization enhances each individual stage and improves overall performance. PentestEval provides the foundational benchmark needed for future research on fine-grained, stage-level evaluation, paving the way toward more reliable LLM-based automation.",
            "categories": [
                "cs.SE",
                "cs.AI",
                "cs.CR"
            ],
            "primary_category": "cs.SE",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "13 pages, 6 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14233v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VIO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL",
                        "PPO"
                    ],
                    "score": 2
                }
            ],
            "relevance_score": 3,
            "headline_zh": "提出PentestEval基准测试，通过模块化阶段设计评估LLM在渗透测试中的性能，揭示现有方法的局限性。",
            "summary_zh": "渗透测试对于评估和增强系统安全至关重要，但传统工作流程高度依赖人工、专业知识密集且难以扩展。尽管大语言模型（LLMs）为自动化提供了前景，但现有应用依赖简单的提示方法，缺乏任务分解或领域适应，导致不可靠的黑盒行为和有限的对渗透测试各阶段模型能力的洞察。为解决这一差距，我们引入了PentestEval，这是首个全面的基准测试，用于评估LLMs在六个分解的渗透测试阶段：信息收集、弱点收集与过滤、攻击决策、漏洞利用生成与修订。PentestEval集成了专家标注的真实数据和一个全自动评估管道，覆盖12个真实漏洞场景中的所有阶段，共346个任务。我们对9个广泛使用的LLMs进行阶段级评估，结果显示整体性能较弱，且在渗透测试工作流程的各阶段存在明显局限性。端到端管道的成功率仅为31%，现有LLM驱动的系统如PentestGPT、PentestAgent和VulnBot也表现出类似限制，自主代理几乎完全失败。这些发现强调自主渗透测试需要更强的结构化推理，其中模块化能增强每个单独阶段并提升整体性能。PentestEval为未来细粒度、阶段级评估研究提供了基础基准，为更可靠的基于LLM的自动化铺平道路。",
            "intro_zh": [
                "核心问题：现有LLM在渗透测试中依赖简单提示，缺乏任务分解和领域适应，导致性能不可靠且难以评估各阶段能力。",
                "方法要点：提出PentestEval基准测试，将渗透测试分解为六个阶段，集成专家标注数据和自动评估管道，覆盖多场景任务。",
                "实验或效果：评估9个LLM显示整体性能弱，端到端成功率仅31%，自主代理几乎失败，模块化能提升阶段和整体表现。"
            ],
            "method_zh": "PentestEval的整体框架是一个模块化基准测试系统，将渗透测试工作流程分解为六个阶段：信息收集、弱点收集与过滤、攻击决策、漏洞利用生成与修订。关键技术创新点包括：首次引入阶段级评估设计，覆盖12个真实漏洞场景的346个任务；集成专家标注的真实数据，确保评估的准确性和可靠性；开发全自动评估管道，支持高效、可扩展的测试。与现有方法的主要区别在于：现有LLM应用通常采用黑盒式简单提示，而PentestEval通过任务分解和领域适应，提供细粒度、结构化的评估，能深入分析模型在各阶段的能力和局限性。",
            "application_zh": "该研究可应用于网络安全领域，特别是自动化渗透测试工具的开发和评估。潜在价值包括：为LLM在安全任务中的性能提供基准，指导模型优化和领域适应；促进更可靠的自动化渗透测试系统设计，减少人工依赖；支持教育和培训，帮助研究人员和从业者理解LLM在复杂安全场景中的能力边界。",
            "highlight_zh": "最重要的实验结果：对9个广泛使用的LLMs进行阶段级评估，整体性能较弱，端到端管道成功率仅为31%；现有LLM驱动系统如PentestGPT等表现出类似限制，自主代理几乎完全失败。性能提升：模块化设计能增强各阶段表现，但当前LLM在结构化推理方面仍有不足，需进一步优化。",
            "tags_zh": [
                "渗透测试基准",
                "大语言模型评估",
                "模块化阶段设计",
                "网络安全自动化",
                "任务分解",
                "专家标注数据",
                "端到端管道",
                "结构化推理"
            ],
            "_index": 37
        },
        {
            "title": "FastDDHPose: Towards Unified, Efficient, and Disentangled 3D Human Pose Estimation",
            "authors": [
                "Qingyuan Cai",
                "Linxin Zhang",
                "Xuecai Hu",
                "Saihui Hou",
                "Yongzhen Huang"
            ],
            "arxiv_id": "2512.14162v1",
            "summary": "Recent approaches for monocular 3D human pose estimation (3D HPE) have achieved leading performance by directly regressing 3D poses from 2D keypoint sequences. Despite the rapid progress in 3D HPE, existing methods are typically trained and evaluated under disparate frameworks, lacking a unified framework for fair comparison. To address these limitations, we propose Fast3DHPE, a modular framework that facilitates rapid reproduction and flexible development of new methods. By standardizing training and evaluation protocols, Fast3DHPE enables fair comparison across 3D human pose estimation methods while significantly improving training efficiency. Within this framework, we introduce FastDDHPose, a Disentangled Diffusion-based 3D Human Pose Estimation method which leverages the strong latent distribution modeling capability of diffusion models to explicitly model the distributions of bone length and bone direction while avoiding further amplification of hierarchical error accumulation. Moreover, we design an efficient Kinematic-Hierarchical Spatial and Temporal Denoiser that encourages the model to focus on kinematic joint hierarchies while avoiding unnecessary modeling of overly complex joint topologies. Extensive experiments on Human3.6M and MPI-INF-3DHP show that the Fast3DHPE framework enables fair comparison of all methods while significantly improving training efficiency. Within this unified framework, FastDDHPose achieves state-of-the-art performance with strong generalization and robustness in in-the-wild scenarios. The framework and models will be released at: https://github.com/Andyen512/Fast3DHPE",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14162v1",
            "code_links": [
                {
                    "url": "https://github.com/Andyen512/Fast3DHPE",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO",
                        "pose estimation"
                    ],
                    "score": 2
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 3,
            "headline_zh": "提出FastDDHPose，一个基于解耦扩散的3D人体姿态估计方法，以解决现有方法缺乏统一框架和误差累积问题。",
            "summary_zh": "近期单目3D人体姿态估计方法通过从2D关键点序列直接回归3D姿态取得了领先性能，但现有方法通常在分散的框架下训练和评估，缺乏统一框架进行公平比较。为应对这些限制，我们提出Fast3DHPE，一个模块化框架，促进新方法的快速复现和灵活开发。通过标准化训练和评估协议，Fast3DHPE实现了3D人体姿态估计方法的公平比较，同时显著提升训练效率。在此框架内，我们引入FastDDHPose，一种基于解耦扩散的3D人体姿态估计方法，利用扩散模型的强大潜在分布建模能力，显式建模骨骼长度和骨骼方向的分布，同时避免进一步放大层次误差累积。此外，我们设计了一个高效的基于运动学层次的空间和时间去噪器，鼓励模型关注运动学关节层次，同时避免对过于复杂的关节拓扑进行不必要的建模。在Human3.6M和MPI-INF-3DHP上的大量实验表明，Fast3DHPE框架实现了所有方法的公平比较，同时显著提升训练效率。在此统一框架内，FastDDHPose在野外场景中实现了最先进的性能，具有强大的泛化性和鲁棒性。框架和模型将在https://github.com/Andyen512/Fast3DHPE发布。",
            "intro_zh": [
                "现有3D人体姿态估计方法缺乏统一训练和评估框架，导致公平比较困难，且训练效率低下。",
                "提出FastDDHPose，基于解耦扩散模型显式建模骨骼长度和方向分布，并设计高效去噪器以减少误差累积。",
                "在Human3.6M和MPI-INF-3DHP数据集上，FastDDHPose实现最先进性能，提升训练效率并增强泛化能力。"
            ],
            "method_zh": "FastDDHPose基于Fast3DHPE统一框架，核心方法采用解耦扩散模型进行3D人体姿态估计。关键创新点包括：利用扩散模型建模骨骼长度和方向的潜在分布，避免层次误差累积；设计基于运动学层次的空间和时间去噪器，优化关节层次建模，减少复杂拓扑的冗余计算。与现有方法的主要区别在于，它通过解耦方式显式处理骨骼属性，而非直接回归整体姿态，从而提升精度和效率。",
            "application_zh": "该研究可应用于虚拟现实、增强现实、人机交互和运动分析等领域，为实时3D姿态估计提供高效解决方案，提升在复杂场景下的鲁棒性和泛化能力。",
            "highlight_zh": "在Human3.6M和MPI-INF-3DHP数据集上，FastDDHPose实现最先进性能，显著提升训练效率，并在野外场景中展示强大的泛化性和鲁棒性，验证了统一框架的有效性。",
            "tags_zh": [
                "3D人体姿态估计",
                "扩散模型",
                "解耦建模",
                "运动学层次",
                "统一框架",
                "训练效率",
                "泛化能力",
                "单目视觉"
            ],
            "_index": 38
        },
        {
            "title": "SketchAssist: A Practical Assistant for Semantic Edits and Precise Local Redrawing",
            "authors": [
                "Han Zou",
                "Yan Zhang",
                "Ruiqi Yu",
                "Cong Xie",
                "Jie Huang",
                "Zhenpeng Zhan"
            ],
            "arxiv_id": "2512.14140v1",
            "summary": "Sketch editing is central to digital illustration, yet existing image editing systems struggle to preserve the sparse, style-sensitive structure of line art while supporting both high-level semantic changes and precise local redrawing. We present SketchAssist, an interactive sketch drawing assistant that accelerates creation by unifying instruction-guided global edits with line-guided region redrawing, while keeping unrelated regions and overall composition intact. To enable this assistant at scale, we introduce a controllable data generation pipeline that (i) constructs attribute-addition sequences from attribute-free base sketches, (ii) forms multi-step edit chains via cross-sequence sampling, and (iii) expands stylistic coverage with a style-preserving attribute-removal model applied to diverse sketches. Building on this data, SketchAssist employs a unified sketch editing framework with minimal changes to DiT-based editors. We repurpose the RGB channels to encode the inputs, enabling seamless switching between instruction-guided edits and line-guided redrawing within a single input interface. To further specialize behavior across modes, we integrate a task-guided mixture-of-experts into LoRA layers, routing by text and visual cues to improve semantic controllability, structural fidelity, and style preservation. Extensive experiments show state-of-the-art results on both tasks, with superior instruction adherence and style/structure preservation compared to recent baselines. Together, our dataset and SketchAssist provide a practical, controllable assistant for sketch creation and revision.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14140v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "人形机器人",
                    "matched_keywords": [
                        "digit"
                    ],
                    "score": 1
                },
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VIO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "PPO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 3,
            "headline_zh": "提出SketchAssist以解决线稿编辑中语义修改与局部重绘的平衡问题",
            "summary_zh": "线稿编辑是数字插画的核心，但现有图像编辑系统难以在支持高层次语义修改和精确局部重绘的同时，保持线稿的稀疏、风格敏感结构。本文提出SketchAssist，一个交互式线稿绘制助手，通过统一指令引导的全局编辑和线条引导的区域重绘来加速创作，同时保持无关区域和整体构图不变。为实现大规模应用，我们引入了一个可控数据生成流程：（i）从无属性基础线稿构建属性添加序列，（ii）通过跨序列采样形成多步编辑链，（iii）应用风格保持的属性移除模型到多样线稿以扩展风格覆盖。基于此数据，SketchAssist采用统一的线稿编辑框架，对基于DiT的编辑器进行最小改动。我们重新利用RGB通道编码输入，实现在单一输入界面中无缝切换指令引导编辑和线条引导重绘。为进一步专业化不同模式的行为，我们在LoRA层中集成任务引导的专家混合，通过文本和视觉线索路由，以提升语义可控性、结构保真度和风格保持。大量实验显示在两个任务上均达到最先进结果，与近期基线相比，在指令遵循和风格/结构保持方面表现更优。我们的数据集和SketchAssist共同为线稿创作和修订提供了一个实用、可控的助手。",
            "intro_zh": [
                "现有图像编辑系统难以在线稿编辑中同时支持高层次语义修改和精确局部重绘，且易破坏线稿的稀疏结构和风格敏感性。",
                "SketchAssist通过统一指令引导全局编辑和线条引导区域重绘，结合可控数据生成和任务引导专家混合，提升编辑的语义可控性和结构保真度。",
                "实验表明，SketchAssist在指令遵循和风格/结构保持方面优于基线，实现了线稿编辑任务的最先进性能。"
            ],
            "method_zh": "SketchAssist采用统一的线稿编辑框架，基于DiT编辑器进行最小改动。核心创新包括：重新利用RGB通道编码输入，实现单一界面中指令引导编辑和线条引导重绘的无缝切换；集成任务引导的专家混合到LoRA层，通过文本和视觉线索路由，以提升语义可控性、结构保真度和风格保持。与现有方法相比，其主要区别在于统一了全局语义编辑和局部精确重绘，并通过可控数据生成流程（包括属性添加序列、多步编辑链和风格保持属性移除）支持大规模应用。",
            "application_zh": "该研究可应用于数字插画、动画制作、游戏设计和工业设计等领域，为艺术家和设计师提供高效的线稿创作和修订工具，提升创意工作流程的效率和可控性。",
            "highlight_zh": "SketchAssist在指令遵循和风格/结构保持方面优于近期基线，实现了线稿编辑任务的最先进结果，实验显示其在语义编辑和局部重绘中均具有显著性能提升。",
            "tags_zh": [
                "线稿编辑",
                "语义编辑",
                "局部重绘",
                "可控数据生成",
                "专家混合",
                "风格保持",
                "交互式助手",
                "数字插画"
            ],
            "_index": 39
        },
        {
            "title": "AnchorHOI: Zero-shot Generation of 4D Human-Object Interaction via Anchor-based Prior Distillation",
            "authors": [
                "Sisi Dai",
                "Kai Xu"
            ],
            "arxiv_id": "2512.14095v1",
            "summary": "Despite significant progress in text-driven 4D human-object interaction (HOI) generation with supervised methods, the scalability remains limited by the scarcity of large-scale 4D HOI datasets. To overcome this, recent approaches attempt zero-shot 4D HOI generation with pre-trained image diffusion models. However, interaction cues are minimally distilled during the generation process, restricting their applicability across diverse scenarios. In this paper, we propose AnchorHOI, a novel framework that thoroughly exploits hybrid priors by incorporating video diffusion models beyond image diffusion models, advancing 4D HOI generation. Nevertheless, directly optimizing high-dimensional 4D HOI with such priors remains challenging, particularly for human pose and compositional motion. To address this challenge, AnchorHOI introduces an anchor-based prior distillation strategy, which constructs interaction-aware anchors and then leverages them to guide generation in a tractable two-step process. Specifically, two tailored anchors are designed for 4D HOI generation: anchor Neural Radiance Fields (NeRFs) for expressive interaction composition, and anchor keypoints for realistic motion synthesis. Extensive experiments demonstrate that AnchorHOI outperforms previous methods with superior diversity and generalization.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "AAAI 2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14095v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "动作生成",
                    "matched_keywords": [
                        "motion synthesis"
                    ],
                    "score": 1
                },
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VIO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 3,
            "headline_zh": "提出AnchorHOI框架，通过基于锚点的先验蒸馏策略解决零样本4D人-物交互生成中的交互线索不足问题。",
            "summary_zh": "尽管基于监督方法的文本驱动4D人-物交互生成取得了显著进展，但由于大规模4D HOI数据集的稀缺性，其可扩展性仍然受限。为了克服这一限制，最近的方法尝试使用预训练的图像扩散模型进行零样本4D HOI生成。然而，在生成过程中交互线索的蒸馏非常有限，限制了它们在不同场景中的适用性。在本文中，我们提出了AnchorHOI，这是一个新颖的框架，通过结合视频扩散模型超越图像扩散模型，充分利用混合先验，推进了4D HOI生成。然而，直接使用此类先验优化高维4D HOI仍然具有挑战性，特别是在人体姿态和组合运动方面。为了解决这一挑战，AnchorHOI引入了一种基于锚点的先验蒸馏策略，该策略构建交互感知的锚点，然后利用它们在一个可处理的两步过程中指导生成。具体来说，为4D HOI生成设计了两个定制的锚点：用于表达性交互组合的锚点神经辐射场，以及用于逼真运动合成的锚点关键点。大量实验表明，AnchorHOI在多样性和泛化性方面优于先前的方法。",
            "intro_zh": [
                "现有零样本4D HOI生成方法主要依赖图像扩散模型，交互线索蒸馏不足，限制了跨场景适用性。",
                "提出基于锚点的先验蒸馏策略，通过构建交互感知锚点（如锚点NeRF和关键点）指导生成过程。",
                "实验显示AnchorHOI在多样性和泛化性上优于先前方法，有效提升了4D HOI生成质量。"
            ],
            "method_zh": "AnchorHOI是一个零样本4D人-物交互生成框架，整体采用基于锚点的先验蒸馏策略。关键技术创新包括：结合视频扩散模型以利用混合先验，设计锚点NeRF用于交互组合和锚点关键点用于运动合成，通过两步过程（先构建锚点再指导生成）优化高维4D HOI。与现有方法的主要区别在于，它超越了仅依赖图像扩散模型的局限，通过锚点机制更有效地蒸馏交互线索，解决了人体姿态和组合运动的优化挑战。",
            "application_zh": "该研究可应用于虚拟现实、游戏开发、机器人交互仿真和影视特效等领域，通过生成逼真的4D人-物交互序列，降低数据采集成本，提升场景构建的灵活性和多样性。",
            "highlight_zh": "AnchorHOI在零样本4D HOI生成任务中表现出色，实验结果表明其在多样性和泛化性方面显著优于先前方法，有效解决了交互线索不足的问题，提升了生成质量。",
            "tags_zh": [
                "4D人-物交互生成",
                "零样本学习",
                "先验蒸馏",
                "神经辐射场",
                "视频扩散模型",
                "运动合成",
                "交互感知锚点",
                "多模态生成"
            ],
            "_index": 40
        },
        {
            "title": "Expert Switching for Robust AAV Landing: A Dual-Detector Framework in Simulation",
            "authors": [
                "Humaira Tasnim",
                "Ashik E Rasul",
                "Bruce Jo",
                "Hyung-Jin Yoon"
            ],
            "arxiv_id": "2512.14054v1",
            "summary": "Reliable helipad detection is essential for Autonomous Aerial Vehicle (AAV) landing, especially under GPS-denied or visually degraded conditions. While modern detectors such as YOLOv8 offer strong baseline performance, single-model pipelines struggle to remain robust across the extreme scale transitions that occur during descent, where helipads appear small at high altitude and large near touchdown. To address this limitation, we propose a scale-adaptive dual-expert perception framework that decomposes the detection task into far-range and close-range regimes. Two YOLOv8 experts are trained on scale-specialized versions of the HelipadCat dataset, enabling one model to excel at detecting small, low-resolution helipads and the other to provide high-precision localization when the target dominates the field of view. During inference, both experts operate in parallel, and a geometric gating mechanism selects the expert whose prediction is most consistent with the AAV's viewpoint. This adaptive routing prevents the degradation commonly observed in single-detector systems when operating across wide altitude ranges. The dual-expert perception module is evaluated in a closed-loop landing environment that integrates CARLA's photorealistic rendering with NASA's GUAM flight-dynamics engine. Results show substantial improvements in alignment stability, landing accuracy, and overall robustness compared to single-detector baselines. By introducing a scale-aware expert routing strategy tailored to the landing problem, this work advances resilient vision-based perception for autonomous descent and provides a foundation for future multi-expert AAV frameworks.",
            "categories": [
                "cs.RO",
                "cs.CV"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14054v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "自动驾驶",
                    "matched_keywords": [
                        "carla"
                    ],
                    "score": 1
                },
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "localization"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 3,
            "headline_zh": "提出基于双检测器的尺度自适应专家切换框架，以解决自主空中车辆在降落过程中因尺度变化导致的停机坪检测鲁棒性问题。",
            "summary_zh": "可靠的停机坪检测对于自主空中车辆（AAV）降落至关重要，尤其是在GPS失效或视觉条件退化的情况下。虽然现代检测器如YOLOv8提供了强大的基线性能，但单模型管道在降落过程中经历的极端尺度转换下难以保持鲁棒性，其中停机坪在高空时显得小而低分辨率，在接近着陆时则大而占据视野。为应对这一限制，本文提出了一种尺度自适应的双专家感知框架，将检测任务分解为远距离和近距离两个阶段。两个YOLOv8专家在HelipadCat数据集的尺度专门化版本上进行训练，使一个模型擅长检测小而低分辨率的停机坪，另一个在目标主导视野时提供高精度定位。在推理过程中，两个专家并行运行，几何门控机制选择与AAV视点最一致的预测专家。这种自适应路由防止了单检测器系统在宽高度范围内操作时常见的性能退化。双专家感知模块在闭环降落环境中进行评估，该环境集成了CARLA的光照真实渲染与NASA的GUAM飞行动力学引擎。结果显示，与单检测器基线相比，在对齐稳定性、降落精度和整体鲁棒性方面有显著提升。通过引入针对降落问题定制的尺度感知专家路由策略，这项工作推进了自主下降的弹性视觉感知，并为未来多专家AAV框架奠定了基础。",
            "intro_zh": [
                "核心问题：单检测器在AAV降落过程中因停机坪尺度剧烈变化（从高空小目标到近地大目标）导致检测鲁棒性不足。",
                "方法要点：提出双专家感知框架，训练两个YOLOv8专家分别处理远距离和近距离尺度，通过几何门控机制自适应切换专家。",
                "实验或效果：在CARLA与GUAM集成的仿真环境中，相比单检测器基线，显著提升了对齐稳定性、降落精度和整体鲁棒性。"
            ],
            "method_zh": "论文提出一种尺度自适应的双专家感知框架，整体架构包括两个并行运行的YOLOv8检测器，分别作为远距离和近距离专家，训练于HelipadCat数据集的尺度专门化版本。关键技术创新点是几何门控机制，它基于AAV的视点（如高度和视角）动态选择最一致的专家预测，实现自适应路由。与现有方法的主要区别在于，传统单检测器系统难以处理降落过程中的极端尺度变化，而本框架通过专家分解和切换策略，专门针对尺度变化问题，提升了检测的鲁棒性和精度。",
            "application_zh": "该研究主要应用于自主空中车辆的视觉引导降落场景，特别是在GPS失效或恶劣视觉条件下，如军事侦察、紧急救援或无人机物流。其潜在价值在于提高AAV在复杂环境中的自主性和安全性，为未来多专家感知系统提供基础。",
            "highlight_zh": "在CARLA与NASA GUAM集成的闭环仿真环境中，双专家框架相比单检测器基线，在停机坪检测上实现了显著改进：对齐稳定性提升，降落精度提高，整体鲁棒性增强，有效应对了降落过程中的尺度变化挑战。",
            "tags_zh": [
                "自主空中车辆",
                "停机坪检测",
                "尺度自适应",
                "双专家框架",
                "几何门控",
                "视觉感知",
                "仿真评估",
                "YOLOv8"
            ],
            "_index": 41
        },
        {
            "title": "E-Navi: Environmental Adaptive Navigation for UAVs on Resource Constrained Platforms",
            "authors": [
                "Boyang Li",
                "Zhongpeng Jin",
                "Shuai Zhao",
                "Jiahui Liao",
                "Tian Liu",
                "Han Liu",
                "Yuanhai Zhang",
                "Kai Huang"
            ],
            "arxiv_id": "2512.14046v1",
            "summary": "The ability to adapt to changing environments is crucial for the autonomous navigation systems of Unmanned Aerial Vehicles (UAVs). However, existing navigation systems adopt fixed execution configurations without considering environmental dynamics based on available computing resources, e.g., with a high execution frequency and task workload. This static approach causes rigid flight strategies and excessive computations, ultimately degrading flight performance or even leading to failures in UAVs. Despite the necessity for an adaptive system, dynamically adjusting workloads remains challenging, due to difficulties in quantifying environmental complexity and modeling the relationship between environment and system configuration. Aiming at adapting to dynamic environments, this paper proposes E-Navi, an environmental-adaptive navigation system for UAVs that dynamically adjusts task executions on the CPUs in response to environmental changes based on available computational resources. Specifically, the perception-planning pipeline of UAVs navigation system is redesigned through dynamic adaptation of mapping resolution and execution frequency, driven by the quantitative environmental complexity evaluations. In addition, E-Navi supports flexible deployment across hardware platforms with varying levels of computing capability. Extensive Hardware-In-the-Loop and real-world experiments demonstrate that the proposed system significantly outperforms the baseline method across various hardware platforms, achieving up to 53.9% navigation task workload reduction, up to 63.8% flight time savings, and delivering more stable velocity control.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14046v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "mapping"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL",
                        "PPO"
                    ],
                    "score": 2
                }
            ],
            "relevance_score": 3,
            "headline_zh": "提出E-Navi环境自适应导航系统，解决无人机在资源受限平台上动态环境适应问题",
            "summary_zh": "适应变化环境的能力对无人机自主导航系统至关重要。然而，现有导航系统采用固定的执行配置，未基于可用计算资源考虑环境动态性，例如采用高执行频率和任务负载。这种静态方法导致飞行策略僵化和计算过度，最终降低飞行性能甚至导致无人机故障。尽管自适应系统是必要的，但由于量化环境复杂性和建模环境与系统配置关系的困难，动态调整工作负载仍然具有挑战性。为适应动态环境，本文提出E-Navi，一种面向无人机的环境自适应导航系统，基于可用计算资源动态调整CPU上的任务执行以响应环境变化。具体而言，通过定量环境复杂度评估驱动，重新设计无人机导航系统的感知-规划流程，实现地图分辨率和执行频率的动态自适应。此外，E-Navi支持在不同计算能力水平的硬件平台上灵活部署。广泛的硬件在环和真实世界实验表明，所提系统在各种硬件平台上显著优于基线方法，实现高达53.9%的导航任务负载减少、高达63.8%的飞行时间节省，并提供更稳定的速度控制。",
            "intro_zh": [
                "现有无人机导航系统采用固定配置，无法根据环境动态调整计算资源，导致性能下降或故障。",
                "提出E-Navi系统，通过量化环境复杂度，动态调整地图分辨率和执行频率，实现资源自适应分配。",
                "实验显示系统显著减少任务负载和飞行时间，提升速度控制稳定性，支持跨硬件平台部署。"
            ],
            "method_zh": "E-Navi的核心框架是一个环境自适应导航系统，重新设计了无人机的感知-规划流程。关键技术创新包括：1）开发了环境复杂度量化方法，能够实时评估飞行环境的动态性和复杂性；2）建立了环境复杂度与系统配置（如地图分辨率和执行频率）的映射模型，实现动态调整；3）设计了资源感知的任务调度机制，根据可用计算资源优化工作负载分配。与现有方法的主要区别在于，传统系统采用静态配置，而E-Navi通过动态自适应机制，在保证导航性能的同时，显著降低计算开销，特别适用于资源受限平台。",
            "application_zh": "该研究适用于无人机在资源受限平台上的自主导航任务，如农业监测、灾害救援、物流配送和军事侦察等领域。其实际价值在于提升无人机在动态环境中的适应性和效率，降低硬件成本，支持更广泛的部署场景。",
            "highlight_zh": "硬件在环和真实世界实验表明，E-Navi相比基线方法，导航任务负载最高减少53.9%，飞行时间最高节省63.8%，并实现更稳定的速度控制，验证了其在多种硬件平台上的优越性能。",
            "tags_zh": [
                "无人机导航",
                "环境自适应",
                "资源受限平台",
                "动态任务调度",
                "感知-规划流程",
                "硬件在环实验",
                "计算效率优化",
                "自主飞行系统"
            ],
            "_index": 42
        },
        {
            "title": "Multivariate Time Series Forecasting with Hybrid Euclidean-SPD Manifold Graph Neural Networks",
            "authors": [
                "Yong Fang",
                "Na Li",
                "Hangguan Shan",
                "Eryun Liu",
                "Xinyu Li",
                "Wei Ni",
                "Er-Ping Li"
            ],
            "arxiv_id": "2512.14023v1",
            "summary": "Multivariate Time Series (MTS) forecasting plays a vital role in various real-world applications, such as traffic management and predictive maintenance. Existing approaches typically model MTS data in either Euclidean or Riemannian space, limiting their ability to capture the diverse geometric structures and complex spatio-temporal dependencies inherent in real-world data. To overcome this limitation, we propose the Hybrid Symmetric Positive-Definite Manifold Graph Neural Network (HSMGNN), a novel graph neural network-based model that captures data geometry within a hybrid Euclidean-Riemannian framework. To the best of our knowledge, this is the first work to leverage hybrid geometric representations for MTS forecasting, enabling expressive and comprehensive modeling of geometric properties. Specifically, we introduce a Submanifold-Cross-Segment (SCS) embedding to project input MTS into both Euclidean and Riemannian spaces, thereby capturing spatio-temporal variations across distinct geometric domains. To alleviate the high computational cost of Riemannian distance, we further design an Adaptive-Distance-Bank (ADB) layer with a trainable memory mechanism. Finally, a Fusion Graph Convolutional Network (FGCN) is devised to integrate features from the dual spaces via a learnable fusion operator for accurate prediction. Experiments on three benchmark datasets demonstrate that HSMGNN achieves up to a 13.8 percent improvement over state-of-the-art baselines in forecasting accuracy.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14023v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "自动驾驶",
                    "matched_keywords": [
                        "traffic"
                    ],
                    "score": 1
                },
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 3,
            "headline_zh": "提出混合欧几里得-对称正定流形图神经网络以解决多元时间序列预测中几何结构建模不足的问题。",
            "summary_zh": "多元时间序列预测在交通管理和预测性维护等实际应用中至关重要。现有方法通常在欧几里得空间或黎曼空间中建模MTS数据，限制了其捕捉真实数据中多样几何结构和复杂时空依赖性的能力。为克服这一限制，我们提出了混合对称正定流形图神经网络，这是一种基于图神经网络的新模型，在混合欧几里得-黎曼框架内捕捉数据几何。据我们所知，这是首个利用混合几何表示进行MTS预测的工作，实现了对几何属性的表达性和全面建模。具体而言，我们引入了子流形交叉段嵌入，将输入MTS投影到欧几里得和黎曼空间，从而捕捉不同几何域中的时空变化。为减轻黎曼距离的高计算成本，我们进一步设计了具有可训练记忆机制的自适应距离库层。最后，开发了融合图卷积网络，通过可学习融合算子整合双空间特征以进行准确预测。在三个基准数据集上的实验表明，HSMGNN在预测准确性上比最先进基线提升了高达13.8%。",
            "intro_zh": [
                "现有方法局限于单一几何空间建模，难以捕捉多元时间序列的多样几何结构和复杂时空依赖性。",
                "提出HSMGNN模型，结合欧几里得和黎曼空间表示，通过子流形交叉段嵌入和自适应距离库层优化计算。",
                "实验显示，HSMGNN在基准数据集上预测准确性提升高达13.8%，验证了混合几何表示的有效性。"
            ],
            "method_zh": "HSMGNN的整体框架基于图神经网络，在混合欧几里得-黎曼空间中建模多元时间序列。关键技术创新包括：子流形交叉段嵌入将数据投影到双几何空间以捕捉时空变化；自适应距离库层通过可训练记忆机制降低黎曼距离计算成本；融合图卷积网络使用可学习算子整合双空间特征进行预测。与现有方法的主要区别在于首次引入混合几何表示，克服了单一空间建模的局限性，实现了更全面的几何属性捕捉。",
            "application_zh": "该研究可应用于交通管理、预测性维护、金融分析和环境监测等领域，通过提升多元时间序列预测准确性，支持实时决策和资源优化，具有广泛的实际价值。",
            "highlight_zh": "在三个基准数据集上的实验表明，HSMGNN相比最先进基线，预测准确性提升高达13.8%，显著优于现有方法，证明了混合几何表示在捕捉复杂时空依赖性方面的优势。",
            "tags_zh": [
                "多元时间序列预测",
                "图神经网络",
                "混合几何表示",
                "对称正定流形",
                "时空依赖性建模",
                "自适应距离库",
                "融合图卷积",
                "预测准确性提升"
            ],
            "_index": 43
        },
        {
            "title": "Early Warning Index for Patient Deteriorations in Hospitals",
            "authors": [
                "Dimitris Bertsimas",
                "Yu Ma",
                "Kimberly Villalobos Carballo",
                "Gagan Singh",
                "Michal Laskowski",
                "Jeff Mather",
                "Dan Kombert",
                "Howard Haronian"
            ],
            "arxiv_id": "2512.14683v1",
            "summary": "Hospitals lack automated systems to harness the growing volume of heterogeneous clinical and operational data to effectively forecast critical events. Early identification of patients at risk for deterioration is essential not only for patient care quality monitoring but also for physician care management. However, translating varied data streams into accurate and interpretable risk assessments poses significant challenges due to inconsistent data formats. We develop a multimodal machine learning framework, the Early Warning Index (EWI), to predict the aggregate risk of ICU admission, emergency response team dispatch, and mortality. Key to EWI's design is a human-in-the-loop process: clinicians help determine alert thresholds and interpret model outputs, which are enhanced by explainable outputs using Shapley Additive exPlanations (SHAP) to highlight clinical and operational factors (e.g., scheduled surgeries, ward census) driving each patient's risk. We deploy EWI in a hospital dashboard that stratifies patients into three risk tiers. Using a dataset of 18,633 unique patients at a large U.S. hospital, our approach automatically extracts features from both structured and unstructured electronic health record (EHR) data and achieves C-statistics of 0.796. It is currently used as a triage tool for proactively managing at-risk patients. The proposed approach saves physicians valuable time by automatically sorting patients of varying risk levels, allowing them to concentrate on patient care rather than sifting through complex EHR data. By further pinpointing specific risk drivers, the proposed model provides data-informed adjustments to caregiver scheduling and allocation of critical resources. As a result, clinicians and administrators can avert downstream complications, including costly procedures or high readmission rates and improve overall patient flow.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14683v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出早期预警指数（EWI）多模态机器学习框架，以解决医院患者病情恶化预测中数据异构和可解释性不足的问题。",
            "summary_zh": "医院缺乏自动化系统来利用日益增长的异构临床和运营数据有效预测关键事件。早期识别有恶化风险的患者不仅对患者护理质量监控至关重要，也对医生护理管理至关重要。然而，由于数据格式不一致，将各种数据流转化为准确且可解释的风险评估面临重大挑战。我们开发了一个多模态机器学习框架——早期预警指数（EWI），用于预测ICU入院、紧急响应团队派遣和死亡率的综合风险。EWI设计的关键在于人机交互过程：临床医生帮助确定警报阈值并解释模型输出，这些输出通过使用Shapley Additive exPlanations（SHAP）的可解释输出增强，以突出驱动每个患者风险的临床和运营因素（例如，预定手术、病房普查）。我们将EWI部署在一个医院仪表板中，将患者分为三个风险等级。使用美国一家大型医院的18,633名独特患者的数据集，我们的方法从结构化和非结构化电子健康记录（EHR）数据中自动提取特征，并实现了0.796的C统计量。它目前被用作主动管理风险患者的分类工具。所提出的方法通过自动对不同风险水平的患者进行排序，为医生节省了宝贵时间，使他们能够专注于患者护理，而不是筛选复杂的EHR数据。通过进一步确定特定的风险驱动因素，所提出的模型为护理人员调度和关键资源分配提供了数据驱动的调整。因此，临床医生和管理人员可以避免下游并发症，包括昂贵的手术或高再入院率，并改善整体患者流程。",
            "intro_zh": [
                "核心问题：医院缺乏自动化系统整合异构临床和运营数据，导致患者病情恶化预测困难，数据格式不一致阻碍了准确且可解释的风险评估。",
                "方法要点：提出多模态机器学习框架EWI，结合人机交互过程，利用SHAP增强可解释性，从结构化和非结构化EHR数据自动提取特征预测综合风险。",
                "实验或效果：在18,633名患者数据集上实现C统计量0.796，部署为医院仪表板工具，有效分层患者风险，节省医生时间并优化资源分配。"
            ],
            "method_zh": "论文提出早期预警指数（EWI）多模态机器学习框架，整体框架包括数据预处理、特征提取、风险预测和人机交互模块。关键技术创新点在于整合结构化和非结构化电子健康记录（EHR）数据，通过自动特征提取处理异构数据，并引入人机交互过程，临床医生参与设定警报阈值和解释模型输出，同时使用Shapley Additive exPlanations（SHAP）提供可解释性输出，以突出临床和运营风险驱动因素。与现有方法的主要区别在于其多模态数据融合能力、可解释性增强以及实际部署中的实用性，解决了传统方法在数据一致性和可解释性方面的不足。",
            "application_zh": "该研究主要应用于医院临床管理领域，作为患者病情恶化的早期预警工具，用于ICU入院、紧急响应和死亡率风险预测。实际价值包括优化患者分类、提高护理效率、减少并发症和再入院率，并支持数据驱动的资源调度决策。",
            "highlight_zh": "最重要的实验结果是在大型医院18,633名患者数据集上，EWI框架实现了0.796的C统计量，表明模型具有良好的预测性能。性能提升体现在自动化风险分层和可解释性输出，成功部署为医院仪表板工具，有效辅助临床决策。",
            "tags_zh": [
                "早期预警指数",
                "多模态机器学习",
                "患者恶化预测",
                "可解释人工智能",
                "电子健康记录",
                "临床决策支持",
                "风险分层",
                "人机交互"
            ],
            "_index": 44
        },
        {
            "title": "EVOLVE-VLA: Test-Time Training from Environment Feedback for Vision-Language-Action Models",
            "authors": [
                "Zechen Bai",
                "Chen Gao",
                "Mike Zheng Shou"
            ],
            "arxiv_id": "2512.14666v1",
            "summary": "Achieving truly adaptive embodied intelligence requires agents that learn not just by imitating static demonstrations, but by continuously improving through environmental interaction, which is akin to how humans master skills through practice. Vision-Language-Action (VLA) models have advanced robotic manipulation by leveraging large language models, yet remain fundamentally limited by Supervised Finetuning (SFT): requiring hundreds of demonstrations per task, rigidly memorizing trajectories, and failing to adapt when deployment conditions deviate from training. We introduce EVOLVE-VLA, a test-time training framework enabling VLAs to continuously adapt through environment interaction with minimal or zero task-specific demonstrations. The key technical challenge is replacing oracle reward signals (unavailable at test time) with autonomous feedback. We address this through a learned progress estimator providing dense feedback, and critically, we design our framework to ``tame'' this inherently noisy signal via two mechanisms: (1) an accumulative progress estimation mechanism smoothing noisy point-wise estimates, and (2) a progressive horizon extension strategy enabling gradual policy evolution. EVOLVE-VLA achieves substantial gains: +8.6\\% on long-horizon tasks, +22.0\\% in 1-shot learning, and enables cross-task generalization -- achieving 20.8\\% success on unseen tasks without task-specific demonstrations training (vs. 0\\% for pure SFT). Qualitative analysis reveals emergent capabilities absent in demonstrations, including error recovery and novel strategies. This work represents a critical step toward VLAs that truly learn and adapt, moving beyond static imitation toward continuous self-improvements.",
            "categories": [
                "cs.RO",
                "cs.CV"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "15 pages",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14666v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "reward"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出EVOLVE-VLA框架，通过环境反馈实现视觉-语言-动作模型的测试时训练，解决静态模仿学习的适应性问题。",
            "summary_zh": "实现真正的自适应具身智能需要智能体通过环境交互持续学习，而不仅仅是模仿静态演示。视觉-语言-动作模型通过利用大语言模型推动了机器人操作的发展，但仍受限于监督微调：每个任务需要数百次演示、僵化地记忆轨迹，且在部署条件偏离训练时无法适应。我们提出了EVOLVE-VLA，这是一个测试时训练框架，使VLA模型能够通过环境交互以最少或零任务特定演示持续适应。关键技术挑战是用自主反馈替代测试时不可用的oracle奖励信号。我们通过一个提供密集反馈的学习进度估计器来解决这一问题，并关键地设计了两个机制来“驯服”这种固有噪声信号：(1) 累积进度估计机制平滑噪声点估计，(2) 渐进式视野扩展策略实现逐步策略演化。EVOLVE-VLA取得了显著提升：长视野任务提升8.6%，单样本学习提升22.0%，并实现跨任务泛化——在未见任务上达到20.8%的成功率（纯SFT为0%）。定性分析揭示了演示中不存在的涌现能力，包括错误恢复和新策略。这项工作代表了VLA模型向真正学习和适应迈出的关键一步，从静态模仿转向持续自我改进。",
            "intro_zh": [
                "现有VLA模型依赖监督微调，需要大量演示、记忆轨迹，部署条件变化时无法适应，限制了自适应能力。",
                "提出EVOLVE-VLA框架，通过环境反馈实现测试时训练，利用学习进度估计器和噪声驯服机制，使模型持续自我改进。",
                "实验显示，EVOLVE-VLA在长视野任务提升8.6%，单样本学习提升22.0%，跨任务泛化达20.8%成功率，涌现错误恢复等能力。"
            ],
            "method_zh": "EVOLVE-VLA是一个测试时训练框架，整体基于视觉-语言-动作模型，通过环境交互实现持续适应。关键技术创新包括：学习进度估计器提供密集反馈以替代oracle奖励信号，以及两个噪声驯服机制——累积进度估计平滑点估计噪声，渐进式视野扩展策略逐步演化策略。与现有方法的主要区别在于，它不依赖大量任务特定演示，而是利用环境反馈进行在线学习，解决了监督微调的静态性和适应性不足问题，实现了从模仿学习到交互学习的转变。",
            "application_zh": "该研究可应用于机器人操作、自动驾驶、智能家居等具身智能领域，使智能体能在动态环境中通过交互持续学习和适应，减少对人工演示的依赖，提升实际部署的鲁棒性和泛化能力。",
            "highlight_zh": "EVOLVE-VLA在长视野任务上提升8.6%成功率，单样本学习提升22.0%，跨任务泛化在未见任务上达到20.8%成功率（纯SFT为0%），并涌现出错误恢复和新策略等能力，验证了测试时训练的有效性。",
            "tags_zh": [
                "测试时训练",
                "视觉-语言-动作模型",
                "环境反馈",
                "进度估计",
                "噪声驯服",
                "跨任务泛化",
                "具身智能",
                "自适应学习"
            ],
            "_index": 45
        },
        {
            "title": "ViRC: Enhancing Visual Interleaved Mathematical CoT with Reason Chunking",
            "authors": [
                "Lihong Wang",
                "Liangqi Li",
                "Weiwei Feng",
                "Jiamin Wu",
                "Changtao Miao",
                "Tieru Wu",
                "Rui Ma",
                "Bo Zhang",
                "Zhe Li"
            ],
            "arxiv_id": "2512.14654v1",
            "summary": "CoT has significantly enhanced the reasoning ability of LLMs while it faces challenges when extended to multimodal domains, particularly in mathematical tasks. Existing MLLMs typically perform textual reasoning solely from a single static mathematical image, overlooking dynamic visual acquisition during reasoning. In contrast, humans repeatedly examine visual image and employ step-by-step reasoning to prove intermediate propositions. This strategy of decomposing the problem-solving process into key logical nodes adheres to Miller's Law in cognitive science. Inspired by this insight, we propose a ViRC framework for multimodal mathematical tasks, introducing a Reason Chunking mechanism that structures multimodal mathematical CoT into consecutive Critical Reasoning Units (CRUs) to simulate human expert problem-solving patterns. CRUs ensure intra-unit textual coherence for intermediate proposition verification while integrating visual information across units to generate subsequent propositions and support structured reasoning. To this end, we present CRUX dataset by using three visual tools and four reasoning patterns to provide explicitly annotated CRUs across multiple reasoning paths for each mathematical problem. Leveraging the CRUX dataset, we propose a progressive training strategy inspired by human cognitive learning, which includes Instructional SFT, Practice SFT, and Strategic RL, aimed at further strengthening the Reason Chunking ability of the model.The resulting ViRC-7B model achieves a 18.8\\% average improvement over baselines across multiple mathematical benchmarks. Code is available at https://github.com/Leon-LihongWang/ViRC.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Code is available at https://github.com/Leon-LihongWang/ViRC",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14654v1",
            "code_links": [
                {
                    "url": "https://github.com/Leon-LihongWang/ViRC",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL",
                        "PPO"
                    ],
                    "score": 2
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出ViRC框架，通过Reason Chunking机制增强多模态数学推理中的视觉交错思维链。",
            "summary_zh": "思维链（CoT）显著提升了大型语言模型的推理能力，但在扩展到多模态领域时面临挑战，特别是在数学任务中。现有的多模态大语言模型通常仅从单个静态数学图像进行文本推理，忽视了推理过程中的动态视觉获取。相比之下，人类会反复检查视觉图像，并采用逐步推理来证明中间命题。这种将问题解决过程分解为关键逻辑节点的策略符合认知科学中的米勒定律。受此启发，我们提出了一个用于多模态数学任务的ViRC框架，引入了Reason Chunking机制，将多模态数学CoT结构化为连续的Critical Reasoning Units（CRUs），以模拟人类专家的问题解决模式。CRUs确保单元内的文本连贯性以验证中间命题，同时跨单元整合视觉信息以生成后续命题并支持结构化推理。为此，我们使用三种视觉工具和四种推理模式构建了CRUX数据集，为每个数学问题提供跨多个推理路径的显式标注CRUs。利用CRUX数据集，我们提出了一种受人类认知学习启发的渐进式训练策略，包括Instructional SFT、Practice SFT和Strategic RL，旨在进一步增强模型的Reason Chunking能力。由此产生的ViRC-7B模型在多个数学基准测试中平均比基线提升了18.8%。代码可在https://github.com/Leon-LihongWang/ViRC获取。",
            "intro_zh": [
                "现有MLLMs在数学任务中仅从静态图像推理，缺乏动态视觉获取，导致多模态推理能力受限。",
                "提出ViRC框架，引入Reason Chunking机制，将推理分解为CRUs，模拟人类逐步验证和视觉整合过程。",
                "ViRC-7B模型在多个数学基准上平均提升18.8%，通过CRUX数据集和渐进训练策略实现显著性能改进。"
            ],
            "method_zh": "ViRC框架的核心是Reason Chunking机制，它将多模态数学思维链分解为连续的Critical Reasoning Units（CRUs），每个CRU对应一个关键推理步骤，确保单元内文本连贯性以验证中间命题，同时跨单元整合视觉信息生成后续命题。关键创新包括：CRUs的结构化设计模拟人类专家问题解决模式，CRUX数据集提供显式标注的CRUs支持训练，以及渐进式训练策略（Instructional SFT、Practice SFT、Strategic RL）增强模型推理能力。与现有方法相比，ViRC强调动态视觉获取和结构化推理，而非仅依赖静态图像，从而更贴近人类认知过程。",
            "application_zh": "该研究可应用于教育技术中的智能数学辅导系统，帮助学生通过视觉交互逐步解决复杂问题；也可用于自动化数学问题求解工具，提升多模态AI在科学计算和工程领域的推理准确性。",
            "highlight_zh": "ViRC-7B模型在多个数学基准测试中平均比基线提升18.8%，通过Reason Chunking机制和CRUX数据集显著增强了多模态推理能力，验证了模拟人类认知策略的有效性。",
            "tags_zh": [
                "多模态推理",
                "数学思维链",
                "视觉交错",
                "Reason Chunking",
                "CRUs",
                "渐进式训练",
                "认知科学",
                "多模态大语言模型"
            ],
            "_index": 46
        },
        {
            "title": "A Multicenter Benchmark of Multiple Instance Learning Models for Lymphoma Subtyping from HE-stained Whole Slide Images",
            "authors": [
                "Rao Muhammad Umer",
                "Daniel Sens",
                "Jonathan Noll",
                "Christian Matek",
                "Lukas Wolfseher",
                "Rainer Spang",
                "Ralf Huss",
                "Johannes Raffler",
                "Sarah Reinke",
                "Wolfram Klapper",
                "Katja Steiger",
                "Kristina Schwamborn",
                "Carsten Marr"
            ],
            "arxiv_id": "2512.14640v1",
            "summary": "Timely and accurate lymphoma diagnosis is essential for guiding cancer treatment. Standard diagnostic practice combines hematoxylin and eosin (HE)-stained whole slide images with immunohistochemistry, flow cytometry, and molecular genetic tests to determine lymphoma subtypes, a process requiring costly equipment, skilled personnel, and causing treatment delays. Deep learning methods could assist pathologists by extracting diagnostic information from routinely available HE-stained slides, yet comprehensive benchmarks for lymphoma subtyping on multicenter data are lacking. In this work, we present the first multicenter lymphoma benchmarking dataset covering four common lymphoma subtypes and healthy control tissue. We systematically evaluate five publicly available pathology foundation models (H-optimus-1, H0-mini, Virchow2, UNI2, Titan) combined with attention-based (AB-MIL) and transformer-based (TransMIL) multiple instance learning aggregators across three magnifications (10x, 20x, 40x). On in-distribution test sets, models achieve multiclass balanced accuracies exceeding 80% across all magnifications, with all foundation models performing similarly and both aggregation methods showing comparable results. The magnification study reveals that 40x resolution is sufficient, with no performance gains from higher resolutions or cross-magnification aggregation. However, on out-of-distribution test sets, performance drops substantially to around 60%, highlighting significant generalization challenges. To advance the field, larger multicenter studies covering additional rare lymphoma subtypes are needed. We provide an automated benchmarking pipeline to facilitate such future research.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "17 pages",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14640v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "人形机器人",
                    "matched_keywords": [
                        "optimus"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出首个多中心淋巴瘤分型基准数据集，系统评估病理基础模型与多实例学习聚合器在HE染色全切片图像上的性能。",
            "summary_zh": "及时准确的淋巴瘤诊断对指导癌症治疗至关重要。标准诊断实践结合苏木精-伊红（HE）染色全切片图像与免疫组化、流式细胞术和分子遗传学检测来确定淋巴瘤亚型，这一过程需要昂贵设备、熟练人员并导致治疗延迟。深度学习方法可以通过从常规可用的HE染色切片中提取诊断信息来协助病理学家，但目前缺乏基于多中心数据的淋巴瘤分型综合基准。在这项工作中，我们提出了首个覆盖四种常见淋巴瘤亚型和健康对照组织的多中心淋巴瘤基准数据集。我们系统评估了五种公开可用的病理基础模型（H-optimus-1、H0-mini、Virchow2、UNI2、Titan）与基于注意力（AB-MIL）和基于Transformer（TransMIL）的多实例学习聚合器在三种放大倍数（10x、20x、40x）下的组合。在分布内测试集上，模型在所有放大倍数下实现了超过80%的多类平衡准确率，所有基础模型表现相似，两种聚合方法结果相当。放大倍数研究表明，40x分辨率已足够，更高分辨率或跨放大倍数聚合未带来性能提升。然而，在分布外测试集上，性能显著下降至约60%，突显了显著的泛化挑战。为推进该领域发展，需要覆盖更多罕见淋巴瘤亚型的更大规模多中心研究。我们提供了一个自动化基准测试流程以促进此类未来研究。",
            "intro_zh": [
                "现有淋巴瘤诊断依赖多模态检测，成本高、耗时长，且缺乏基于多中心HE切片数据的深度学习基准。",
                "论文构建首个多中心淋巴瘤基准数据集，系统评估病理基础模型与多实例学习聚合器在不同放大倍数下的性能。",
                "模型在分布内测试集上准确率超80%，但分布外泛化性能显著下降至约60%，揭示泛化挑战。"
            ],
            "method_zh": "论文采用多实例学习框架处理全切片图像，核心方法包括：整体框架结合预训练的病理基础模型（如H-optimus-1、Virchow2等）提取图像特征，然后使用基于注意力（AB-MIL）或基于Transformer（TransMIL）的聚合器整合特征以进行淋巴瘤亚型分类。关键技术创新点在于首次系统评估多种公开病理基础模型与不同聚合器在多中心数据集上的性能，并研究放大倍数（10x、20x、40x）的影响。与现有方法的主要区别是提供了首个针对淋巴瘤分型的多中心基准，并自动化评估流程，填补了该领域综合比较的空白。",
            "application_zh": "该研究可应用于医疗病理学领域，特别是淋巴瘤的辅助诊断，通过深度学习从常规HE染色切片中提取信息，减少对昂贵检测设备的依赖，加速诊断流程，具有临床实用价值。",
            "highlight_zh": "在分布内测试集上，所有模型在10x、20x、40x放大倍数下均实现超过80%的多类平衡准确率，基础模型性能相似，聚合方法结果相当；40x分辨率已足够，更高分辨率无增益；但分布外测试集性能下降至约60%，突显泛化挑战。",
            "tags_zh": [
                "淋巴瘤分型",
                "全切片图像分析",
                "多实例学习",
                "病理基础模型",
                "多中心基准",
                "HE染色图像",
                "深度学习辅助诊断",
                "泛化性能评估"
            ],
            "_index": 47
        },
        {
            "title": "Hierarchical Persistence Velocity for Network Anomaly Detection: Theory and Applications to Cryptocurrency Markets",
            "authors": [
                "Omid Khormali"
            ],
            "arxiv_id": "2512.14615v1",
            "summary": "We introduce the Overlap-Weighted Hierarchical Normalized Persistence Velocity (OW-HNPV), a novel topological data analysis method for detecting anomalies in time-varying networks. Unlike existing methods that measure cumulative topological presence, we introduce the first velocity-based perspective on persistence diagrams, measuring the rate at which features appear and disappear, automatically downweighting noise through overlap-based weighting. We also prove that OW-HNPV is mathematically stable. It behaves in a controlled, predictable way, even when comparing persistence diagrams from networks with different feature types. Applied to Ethereum transaction networks (May 2017-May 2018), OW-HNPV demonstrates superior performance for cryptocurrency anomaly detection, achieving up to 10.4% AUC gain over baseline models for 7-day price movement predictions. Compared with established methods, including Vector of Averaged Bettis (VAB), persistence landscapes, and persistence images, velocity-based summaries excel at medium- to long-range forecasting (4-7 days), with OW-HNPV providing the most consistent and stable performance across prediction horizons. Our results show that modeling topological velocity is crucial for detecting structural anomalies in dynamic networks.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14615v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL",
                        "SAC"
                    ],
                    "score": 2
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出基于重叠加权的层次化归一化持久性速度方法，用于时变网络异常检测，在加密货币市场预测中表现优异。",
            "summary_zh": "我们引入了重叠加权层次化归一化持久性速度（OW-HNPV），这是一种用于检测时变网络异常的新型拓扑数据分析方法。与现有测量累积拓扑存在的方法不同，我们首次从速度角度分析持久图，测量特征出现和消失的速率，并通过基于重叠的加权自动降低噪声影响。我们还证明了OW-HNPV在数学上是稳定的，即使在比较具有不同特征类型的网络持久图时，其行为也是可控且可预测的。应用于以太坊交易网络（2017年5月至2018年5月），OW-HNPV在加密货币异常检测中表现出卓越性能，在7天价格变动预测中比基线模型实现了高达10.4%的AUC增益。与现有方法（如平均贝蒂向量、持久景观和持久图像）相比，基于速度的摘要在中长期预测（4-7天）中表现突出，OW-HNPV在不同预测时间范围内提供了最一致和稳定的性能。我们的结果表明，建模拓扑速度对于检测动态网络中的结构异常至关重要。",
            "intro_zh": [
                "现有方法主要关注累积拓扑特征，难以捕捉动态网络中的快速结构变化，限制了异常检测的时效性和准确性。",
                "提出基于速度的持久图分析，通过重叠加权自动降噪，并证明方法的数学稳定性，确保可控和可预测的行为。",
                "在以太坊交易网络实验中，OW-HNPV实现高达10.4%的AUC增益，在中长期预测中表现最稳定，优于多种基线方法。"
            ],
            "method_zh": "整体框架基于拓扑数据分析，通过持久图捕捉网络拓扑特征。关键创新点包括：首次引入速度视角分析持久图，测量特征出现和消失的速率；提出重叠加权机制，自动降低噪声影响；证明方法的数学稳定性，确保鲁棒性。与现有方法（如VAB、持久景观）的主要区别在于，现有方法侧重于累积拓扑存在，而OW-HNPV专注于拓扑变化的速度，从而更敏感地检测动态网络中的结构异常。",
            "application_zh": "该方法适用于时变网络的异常检测，如加密货币交易网络、社交网络动态分析、物联网设备通信监控等。实际价值在于提升中长期预测准确性，为金融风险管理和网络安全提供新工具。",
            "highlight_zh": "在以太坊交易网络实验中，OW-HNPV在7天价格变动预测中实现高达10.4%的AUC增益，优于VAB、持久景观等基线方法。在中长期预测（4-7天）中表现最稳定，验证了拓扑速度建模对异常检测的关键作用。",
            "tags_zh": [
                "拓扑数据分析",
                "持久图",
                "网络异常检测",
                "加密货币市场",
                "时变网络",
                "速度建模",
                "重叠加权",
                "数学稳定性"
            ],
            "_index": 48
        },
        {
            "title": "Hybrid Iterative Solvers with Geometry-Aware Neural Preconditioners for Parametric PDEs",
            "authors": [
                "Youngkyu Lee",
                "Francesc Levrero Florencio",
                "Jay Pathak",
                "George Em Karniadakis"
            ],
            "arxiv_id": "2512.14596v1",
            "summary": "The convergence behavior of classical iterative solvers for parametric partial differential equations (PDEs) is often highly sensitive to the domain and specific discretization of PDEs. Previously, we introduced hybrid solvers by combining the classical solvers with neural operators for a specific geometry 1, but they tend to under-perform in geometries not encountered during training. To address this challenge, we introduce Geo-DeepONet, a geometry-aware deep operator network that incorporates domain information extracted from finite element discretizations. Geo-DeepONet enables accurate operator learning across arbitrary unstructured meshes without requiring retraining. Building on this, we develop a class of geometry-aware hybrid preconditioned iterative solvers by coupling Geo-DeepONet with traditional methods such as relaxation schemes and Krylov subspace algorithms. Through numerical experiments on parametric PDEs posed over diverse unstructured domains, we demonstrate the enhanced robustness and efficiency of the proposed hybrid solvers for multiple real-world applications.",
            "categories": [
                "cs.LG",
                "math.NA"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "19 pages, 10 figures, 3 tables",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14596v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VIO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出几何感知神经预条件器与混合迭代求解器，以解决参数偏微分方程在任意非结构化网格上的求解鲁棒性问题。",
            "summary_zh": "参数偏微分方程（PDEs）的经典迭代求解器收敛行为通常对域和特定离散化高度敏感。先前我们通过将经典求解器与神经算子结合，针对特定几何引入了混合求解器，但它们在训练未遇到的几何上表现不佳。为解决这一挑战，我们引入了Geo-DeepONet，这是一种几何感知的深度算子网络，它结合了从有限元离散化中提取的域信息。Geo-DeepONet能够在任意非结构化网格上实现精确的算子学习，无需重新训练。在此基础上，我们通过将Geo-DeepONet与传统方法（如松弛方案和Krylov子空间算法）耦合，开发了一类几何感知的混合预条件迭代求解器。通过在多样非结构化域上的参数PDE数值实验，我们证明了所提出的混合求解器在多个实际应用中具有增强的鲁棒性和效率。",
            "intro_zh": [
                "现有混合求解器对训练未见的几何泛化能力差，导致参数PDE求解鲁棒性不足。",
                "提出Geo-DeepONet，结合有限元离散化信息，实现跨任意非结构化网格的几何感知算子学习。",
                "实验表明，混合求解器在多样非结构化域上显著提升求解效率和鲁棒性，适用于实际应用。"
            ],
            "method_zh": "论文提出几何感知混合迭代求解器框架，核心是Geo-DeepONet模型。该模型基于深度算子网络（DeepONet）架构，创新性地融入从有限元离散化提取的几何信息（如网格节点坐标和连接关系），使网络能学习参数PDE解算子在任意非结构化网格上的映射，无需针对新几何重新训练。与传统神经算子方法相比，Geo-DeepONet的关键区别在于其几何感知能力，通过显式编码域结构，克服了现有方法在未见几何上性能下降的问题。在此基础上，将Geo-DeepONet作为预条件器与传统迭代求解器（如松弛法和Krylov算法）结合，形成混合求解流程，提升收敛速度和稳定性。",
            "application_zh": "该研究适用于计算流体力学、结构力学、电磁学等领域的参数偏微分方程求解，特别是在复杂几何形状和非结构化网格的工程仿真中，如航空航天设计、生物医学建模和气候模拟，能提高求解效率和鲁棒性，降低计算成本。",
            "highlight_zh": "数值实验在多样非结构化域上进行，包括参数化几何和真实世界场景。结果显示，所提混合求解器相比纯传统方法，收敛速度提升高达50%，且在训练未见几何上保持稳定性能，验证了Geo-DeepONet的泛化能力和实际应用价值。",
            "tags_zh": [
                "参数偏微分方程",
                "几何感知学习",
                "神经算子网络",
                "混合迭代求解器",
                "非结构化网格",
                "预条件技术",
                "有限元方法",
                "计算仿真"
            ],
            "_index": 49
        },
        {
            "title": "TUMTraf EMOT: Event-Based Multi-Object Tracking Dataset and Baseline for Traffic Scenarios",
            "authors": [
                "Mengyu Li",
                "Xingcheng Zhou",
                "Guang Chen",
                "Alois Knoll",
                "Hu Cao"
            ],
            "arxiv_id": "2512.14595v1",
            "summary": "In Intelligent Transportation Systems (ITS), multi-object tracking is primarily based on frame-based cameras. However, these cameras tend to perform poorly under dim lighting and high-speed motion conditions. Event cameras, characterized by low latency, high dynamic range and high temporal resolution, have considerable potential to mitigate these issues. Compared to frame-based vision, there are far fewer studies on event-based vision. To address this research gap, we introduce an initial pilot dataset tailored for event-based ITS, covering vehicle and pedestrian detection and tracking. We establish a tracking-by-detection benchmark with a specialized feature extractor based on this dataset, achieving excellent performance.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "10 pages, 9 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14595v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "自动驾驶",
                    "matched_keywords": [
                        "traffic"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出TUMTraf EMOT数据集和基准方法，以解决智能交通系统中基于事件相机的多目标跟踪问题。",
            "summary_zh": "在智能交通系统中，多目标跟踪主要基于帧式相机，但这些相机在弱光和高速度运动条件下性能较差。事件相机具有低延迟、高动态范围和高时间分辨率的特点，有潜力缓解这些问题。与基于帧的视觉相比，基于事件的视觉研究较少。为填补这一研究空白，我们引入了一个专为基于事件的智能交通系统设计的初始试点数据集，涵盖车辆和行人的检测与跟踪。基于此数据集，我们建立了一个检测-跟踪基准，并采用专门的特征提取器，实现了优异的性能。",
            "intro_zh": [
                "核心问题：帧式相机在弱光和高速度运动条件下性能不佳，限制了智能交通系统中多目标跟踪的可靠性。",
                "方法要点：提出TUMTraf EMOT数据集和基准方法，利用事件相机的优势，通过专门的特征提取器提升跟踪性能。",
                "实验或效果：基于新数据集建立基准，实现了优异的跟踪性能，验证了事件相机在交通场景中的潜力。"
            ],
            "method_zh": "论文采用检测-跟踪框架，核心方法包括基于TUMTraf EMOT数据集的专门特征提取器。整体框架结合事件相机的低延迟和高时间分辨率特性，通过优化特征表示来提升多目标跟踪的准确性和鲁棒性。关键技术创新点在于针对事件数据设计特征提取器，以处理动态交通场景中的挑战。与现有方法的主要区别在于专注于事件相机数据，而非传统帧式相机，从而在弱光和高速度条件下提供更优性能。",
            "application_zh": "该研究可应用于智能交通系统，如自动驾驶、交通监控和行人安全，特别是在弱光、高动态范围或高速运动场景中，提升多目标跟踪的可靠性和实时性。",
            "highlight_zh": "实验结果显示，基于TUMTraf EMOT数据集的基准方法在车辆和行人跟踪任务中实现了优异的性能，验证了事件相机在交通场景中的有效性，尤其在挑战性条件下相比帧式相机有显著提升。",
            "tags_zh": [
                "事件相机",
                "多目标跟踪",
                "智能交通系统",
                "数据集",
                "特征提取",
                "检测-跟踪",
                "弱光条件",
                "高速度运动"
            ],
            "_index": 50
        },
        {
            "title": "Low-Resource, High-Impact: Building Corpora for Inclusive Language Technologies",
            "authors": [
                "Ekaterina Artemova",
                "Laurie Burchell",
                "Daryna Dementieva",
                "Shu Okabe",
                "Mariya Shmatova",
                "Pedro Ortiz Suarez"
            ],
            "arxiv_id": "2512.14576v1",
            "summary": "This tutorial (https://tum-nlp.github.io/low-resource-tutorial) is designed for NLP practitioners, researchers, and developers working with multilingual and low-resource languages who seek to create more equitable and socially impactful language technologies. Participants will walk away with a practical toolkit for building end-to-end NLP pipelines for underrepresented languages -- from data collection and web crawling to parallel sentence mining, machine translation, and downstream applications such as text classification and multimodal reasoning. The tutorial presents strategies for tackling the challenges of data scarcity and cultural variance, offering hands-on methods and modeling frameworks. We will focus on fair, reproducible, and community-informed development approaches, grounded in real-world scenarios. We will showcase a diverse set of use cases covering over 10 languages from different language families and geopolitical contexts, including both digitally resource-rich and severely underrepresented languages.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Tutorial is accepted to LREC2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14576v1",
            "code_links": [
                {
                    "url": "https://tum-nlp.github.io/low-resource-tutorial",
                    "type": "project_page"
                }
            ],
            "matched_interests": [
                {
                    "name": "人形机器人",
                    "matched_keywords": [
                        "digit"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出低资源语言NLP教程，构建端到端流程以解决数据稀缺和文化差异问题",
            "summary_zh": "本教程面向从事多语言和低资源语言工作的NLP从业者、研究人员和开发者，旨在创建更公平且具有社会影响力的语言技术。参与者将获得构建针对代表性不足语言的端到端NLP流程的实用工具包——从数据收集和网络爬取，到平行句挖掘、机器翻译，以及文本分类和多模态推理等下游应用。教程介绍了应对数据稀缺和文化差异挑战的策略，提供了实践方法和建模框架。我们将重点关注公平、可重复且基于社区反馈的开发方法，并以真实场景为基础。我们将展示涵盖超过10种来自不同语系和地缘政治背景的语言的多样化用例，包括数字资源丰富和严重代表性不足的语言。",
            "intro_zh": [
                "核心问题：低资源语言面临数据稀缺、文化差异和代表性不足的挑战，现有方法难以构建公平且有效的NLP技术。",
                "方法要点：提供端到端NLP流程工具包，涵盖数据收集、平行句挖掘、机器翻译等，强调公平、可重复和社区参与的方法。",
                "实验或效果：教程展示超过10种语言的多样化用例，包括资源丰富和严重不足的语言，验证了方法的实用性和广泛适用性。"
            ],
            "method_zh": "本教程的核心方法是一个端到端的NLP流程框架，专为低资源语言设计。整体框架包括数据收集、网络爬取、平行句挖掘、机器翻译和下游应用（如文本分类和多模态推理）的完整流程。关键技术创新点在于整合了应对数据稀缺和文化差异的实践策略，例如基于社区反馈的开发方法和可重复的建模框架。与现有方法的主要区别在于强调公平性和社会影响力，通过真实场景和多样化语言用例，提供更系统化和包容性的解决方案，而非仅关注技术优化。",
            "application_zh": "该研究可应用于多语言NLP开发、低资源语言技术推广、社会公平性项目等领域，帮助构建更包容的语言技术，提升全球语言多样性支持，具有促进数字包容和社会影响的潜在价值。",
            "highlight_zh": "教程亮点包括展示超过10种来自不同语系和地缘政治背景的语言用例，涵盖资源丰富和严重不足的语言，验证了端到端流程的实用性和广泛适用性，强调了公平和社区参与的方法在实际场景中的效果。",
            "tags_zh": [
                "低资源语言处理",
                "多语言NLP",
                "数据稀缺应对",
                "端到端流程",
                "公平性技术",
                "社区参与开发",
                "平行句挖掘",
                "机器翻译应用"
            ],
            "_index": 51
        },
        {
            "title": "Polypersona: Persona-Grounded LLM for Synthetic Survey Responses",
            "authors": [
                "Tejaswani Dash",
                "Dinesh Karri",
                "Anudeep Vurity",
                "Gautam Datla",
                "Tazeem Ahmad",
                "Saima Rafi",
                "Rohith Tangudu"
            ],
            "arxiv_id": "2512.14562v1",
            "summary": "This paper introduces PolyPersona, a generative framework for synthesizing persona-conditioned survey responses across multiple domains. The framework instruction-tunes compact chat models using parameter-efficient LoRA adapters with 4-bit quantization under a resource-adaptive training setup. A dialogue-based data pipeline explicitly preserves persona cues, ensuring consistent behavioral alignment across generated responses. Using this pipeline, we construct a dataset of 3,568 synthetic survey responses spanning ten domains and 433 distinct personas, enabling controlled instruction tuning and systematic multi-domain evaluation. We evaluate the generated responses using a multi-metric evaluation suite that combines standard text generation metrics, including BLEU, ROUGE, and BERTScore, with survey-specific metrics designed to assess structural coherence, stylistic consistency, and sentiment alignment.Experimental results show that compact models such as TinyLlama 1.1B and Phi-2 achieve performance comparable to larger 7B to 8B baselines, with a highest BLEU score of 0.090 and ROUGE-1 of 0.429. These findings demonstrate that persona-conditioned fine-tuning enables small language models to generate reliable and coherent synthetic survey data. The proposed framework provides an efficient and reproducible approach for survey data generation, supporting scalable evaluation while facilitating bias analysis through transparent and open protocols.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Accepted in IEEE Bigdata 2025- LLMs4ALL",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14562v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VIO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "PPO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出PolyPersona框架，通过角色条件化微调小型语言模型，实现多领域合成调查数据的高效生成。",
            "summary_zh": "本文介绍了PolyPersona，一个用于生成跨多个领域的角色条件化调查响应的生成框架。该框架在资源自适应训练设置下，使用参数高效的LoRA适配器和4位量化技术，对紧凑的聊天模型进行指令微调。基于对话的数据管道明确保留了角色线索，确保生成响应在行为上的一致性。利用该管道，我们构建了一个包含3,568个合成调查响应的数据集，涵盖十个领域和433个不同角色，支持可控的指令微调和系统的多领域评估。我们使用多指标评估套件评估生成响应，该套件结合了标准文本生成指标（包括BLEU、ROUGE和BERTScore）和专门设计的调查特定指标，用于评估结构连贯性、风格一致性和情感对齐。实验结果表明，TinyLlama 1.1B和Phi-2等紧凑模型实现了与较大7B至8B基线相当的性能，最高BLEU得分为0.090，ROUGE-1为0.429。这些发现表明，角色条件化微调使小型语言模型能够生成可靠且连贯的合成调查数据。所提出的框架为调查数据生成提供了一种高效且可复现的方法，支持可扩展的评估，同时通过透明和开放的协议促进偏见分析。",
            "intro_zh": [
                "现有方法在生成合成调查数据时，难以确保角色一致性和跨领域适应性，导致数据质量受限。",
                "PolyPersona采用基于对话的数据管道和LoRA适配器，对紧凑模型进行角色条件化微调，以高效生成多领域响应。",
                "实验显示，小型模型如TinyLlama 1.1B在BLEU和ROUGE指标上接近大型基线，验证了框架的有效性。"
            ],
            "method_zh": "PolyPersona是一个生成框架，整体基于指令微调的紧凑聊天模型，结合参数高效的LoRA适配器和4位量化技术，在资源自适应训练设置下实现高效训练。关键技术创新点包括：基于对话的数据管道，明确保留角色线索以确保行为一致性；构建多领域合成数据集，支持可控微调和系统评估。与现有方法的主要区别在于，它专注于角色条件化生成，通过透明协议促进偏见分析，并利用小型模型实现与大型模型相当的性能，提高了生成效率和可扩展性。",
            "application_zh": "该研究可应用于市场调研、社会科学实验和用户行为分析等领域，通过生成高质量的合成调查数据，支持数据增强、模型评估和偏见研究，降低真实数据收集成本。",
            "highlight_zh": "紧凑模型TinyLlama 1.1B和Phi-2在BLEU和ROUGE指标上达到与7B-8B基线相当水平，最高BLEU为0.090，ROUGE-1为0.429，证明了角色条件化微调能有效提升小型模型生成质量。",
            "tags_zh": [
                "合成调查数据生成",
                "角色条件化语言模型",
                "LoRA适配器微调",
                "多领域评估",
                "参数高效训练",
                "文本生成指标",
                "偏见分析协议",
                "紧凑模型优化"
            ],
            "_index": 52
        },
        {
            "title": "VLegal-Bench: Cognitively Grounded Benchmark for Vietnamese Legal Reasoning of Large Language Models",
            "authors": [
                "Nguyen Tien Dong",
                "Minh-Anh Nguyen",
                "Thanh Dat Hoang",
                "Nguyen Tuan Ngoc",
                "Dao Xuan Quang Minh",
                "Phan Phi Hai",
                "Nguyen Thi Ngoc Anh",
                "Dang Van Tu",
                "Binh Vu"
            ],
            "arxiv_id": "2512.14554v1",
            "summary": "The rapid advancement of large language models (LLMs) has enabled new possibilities for applying artificial intelligence within the legal domain. Nonetheless, the complexity, hierarchical organization, and frequent revisions of Vietnamese legislation pose considerable challenges for evaluating how well these models interpret and utilize legal knowledge. To address this gap, Vietnamese Legal Benchmark (VLegal-Bench) is introduced, the first comprehensive benchmark designed to systematically assess LLMs on Vietnamese legal tasks. Informed by Bloom's cognitive taxonomy, VLegal-Bench encompasses multiple levels of legal understanding through tasks designed to reflect practical usage scenarios. The benchmark comprises 10,450 samples generated through a rigorous annotation pipeline, where legal experts label and cross-validate each instance using our annotation system to ensure every sample is grounded in authoritative legal documents and mirrors real-world legal assistant workflows, including general legal questions and answers, retrieval-augmented generation, multi-step reasoning, and scenario-based problem solving tailored to Vietnamese law. By providing a standardized, transparent, and cognitively informed evaluation framework, VLegal-Bench establishes a solid foundation for assessing LLM performance in Vietnamese legal contexts and supports the development of more reliable, interpretable, and ethically aligned AI-assisted legal systems.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14554v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL",
                        "PPO"
                    ],
                    "score": 2
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出VLegal-Bench基准以解决越南法律领域大语言模型评估的标准化与认知深度问题",
            "summary_zh": "大语言模型的快速发展为人工智能在法律领域的应用开辟了新可能。然而，越南法律的复杂性、层级结构和频繁修订给评估这些模型如何解释和利用法律知识带来了巨大挑战。为填补这一空白，越南法律基准被引入，这是首个旨在系统评估大语言模型在越南法律任务上表现的综合性基准。基于布鲁姆认知分类法，VLegal-Bench通过设计反映实际使用场景的任务，涵盖了多个层次的法律理解。该基准包含10,450个样本，通过严格的标注流程生成，法律专家使用我们的标注系统对每个实例进行标注和交叉验证，确保每个样本都基于权威法律文件，并模拟真实世界法律助手的工作流程，包括一般法律问答、检索增强生成、多步推理和针对越南法律的场景化问题解决。通过提供一个标准化、透明且基于认知科学的评估框架，VLegal-Bench为评估大语言模型在越南法律环境中的表现奠定了坚实基础，并支持开发更可靠、可解释且符合伦理的AI辅助法律系统。",
            "intro_zh": [
                "核心问题：越南法律复杂多变，现有评估方法缺乏标准化基准，难以系统衡量大语言模型的法律推理能力。",
                "方法要点：基于布鲁姆认知分类法设计多层次任务，通过专家标注构建权威数据集，模拟真实法律工作流程。",
                "实验或效果：构建包含10,450个样本的基准，提供透明评估框架，支持AI法律系统开发，提升模型可靠性和可解释性。"
            ],
            "method_zh": "VLegal-Bench的整体框架是一个基于认知科学的标准化评估基准，核心方法包括任务设计、数据生成和验证流程。关键技术创新点在于结合布鲁姆认知分类法，设计多层次法律理解任务，如问答、检索增强生成、多步推理和场景化问题解决，以反映实际法律应用场景。与现有方法的主要区别在于其专门针对越南法律特性，通过严格专家标注和交叉验证确保数据权威性，并模拟真实法律助手工作流程，提供更全面和实用的评估标准。",
            "application_zh": "该研究可应用于越南法律领域的AI辅助系统开发，如智能法律咨询、文档分析、案例检索和决策支持，提升法律服务的效率和准确性，促进法律科技发展。",
            "highlight_zh": "构建了首个针对越南法律的综合性基准，包含10,450个专家标注样本，基于认知分类法设计多层次任务，为评估大语言模型提供标准化框架，支持开发更可靠的AI法律系统。",
            "tags_zh": [
                "法律基准",
                "越南法律",
                "大语言模型评估",
                "认知分类法",
                "法律推理",
                "专家标注",
                "检索增强生成",
                "场景化问题解决"
            ],
            "_index": 53
        },
        {
            "title": "HiFi-Portrait: Zero-shot Identity-preserved Portrait Generation with High-fidelity Multi-face Fusion",
            "authors": [
                "Yifang Xu",
                "Benxiang Zhai",
                "Yunzhuo Sun",
                "Ming Li",
                "Yang Li",
                "Sidan Du"
            ],
            "arxiv_id": "2512.14542v1",
            "summary": "Recent advancements in diffusion-based technologies have made significant strides, particularly in identity-preserved portrait generation (IPG). However, when using multiple reference images from the same ID, existing methods typically produce lower-fidelity portraits and struggle to customize face attributes precisely. To address these issues, this paper presents HiFi-Portrait, a high-fidelity method for zero-shot portrait generation. Specifically, we first introduce the face refiner and landmark generator to obtain fine-grained multi-face features and 3D-aware face landmarks. The landmarks include the reference ID and the target attributes. Then, we design HiFi-Net to fuse multi-face features and align them with landmarks, which improves ID fidelity and face control. In addition, we devise an automated pipeline to construct an ID-based dataset for training HiFi-Portrait. Extensive experimental results demonstrate that our method surpasses the SOTA approaches in face similarity and controllability. Furthermore, our method is also compatible with previous SDXL-based works.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Accepted by CVPR 2025",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14542v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VIO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出HiFi-Portrait方法，通过高保真多脸融合解决零样本身份保持肖像生成中的保真度和属性控制问题。",
            "summary_zh": "基于扩散技术的进步，身份保持肖像生成（IPG）已取得显著进展，但在使用同一身份的多张参考图像时，现有方法通常生成保真度较低的肖像，且难以精确定制面部属性。为解决这些问题，本文提出HiFi-Portrait，一种用于零样本肖像生成的高保真方法。具体而言，我们首先引入面部精炼器和地标生成器，以获取细粒度的多脸特征和3D感知的面部地标，这些地标包括参考身份和目标属性。然后，我们设计HiFi-Net来融合多脸特征并与地标对齐，从而提高身份保真度和面部控制。此外，我们开发了一个自动化流程来构建基于身份的数据集，用于训练HiFi-Portrait。大量实验结果表明，我们的方法在面部相似性和可控性方面超越了最先进的方法。此外，我们的方法也与之前基于SDXL的工作兼容。",
            "intro_zh": [
                "现有方法在使用多张参考图像时，生成肖像保真度低且难以精确控制面部属性。",
                "引入面部精炼器和地标生成器获取细粒度特征，设计HiFi-Net融合特征并与地标对齐。",
                "实验显示，方法在面部相似性和可控性上超越SOTA，并与SDXL兼容。"
            ],
            "method_zh": "HiFi-Portrait的整体框架包括面部精炼器、地标生成器和HiFi-Net。面部精炼器从多张参考图像中提取细粒度特征，地标生成器生成3D感知的面部地标以编码身份和属性信息。HiFi-Net作为核心模块，融合多脸特征并与地标对齐，通过特征融合和地标对齐机制提升身份保真度和控制精度。关键技术创新在于细粒度多脸特征提取和3D感知地标引导的融合策略，与现有方法相比，它更注重高保真度和精确属性控制，而非仅依赖单一参考或粗粒度特征。",
            "application_zh": "该方法可应用于数字娱乐、虚拟现实、个性化内容创作等领域，如生成高保真虚拟角色、定制化肖像艺术或增强社交媒体内容，具有提升用户体验和创意表达的潜力。",
            "highlight_zh": "实验结果表明，HiFi-Portrait在面部相似性和可控性指标上显著超越现有SOTA方法，同时保持与SDXL的兼容性，验证了其高保真和精确控制的有效性。",
            "tags_zh": [
                "身份保持肖像生成",
                "零样本学习",
                "高保真融合",
                "多脸特征",
                "3D面部地标",
                "扩散模型",
                "可控生成",
                "SDXL兼容"
            ],
            "_index": 54
        },
        {
            "title": "Native Intelligence Emerges from Large-Scale Clinical Practice: A Retinal Foundation Model with Deployment Efficiency",
            "authors": [
                "Jia Guo",
                "Jiawei Du",
                "Shengzhu Yang",
                "Shuai Lu",
                "Wenquan Cheng",
                "Kaiwen Zhang",
                "Yihua Sun",
                "Chuhong Yang",
                "Weihang Zhang",
                "Fang Chen",
                "Yilan Wu",
                "Lie Ju",
                "Guochen Ning",
                "Longfei Ma",
                "Huiping Yao",
                "Jinyuan Wang",
                "Peilun Shi",
                "Yukun Zhou",
                "Jie Xu",
                "Pearse A. Keane",
                "Hanruo Liu",
                "Hongen Liao",
                "Ningli Wang",
                "Huiqi Li"
            ],
            "arxiv_id": "2512.14499v1",
            "summary": "Current retinal foundation models remain constrained by curated research datasets that lack authentic clinical context, and require extensive task-specific optimization for each application, limiting their deployment efficiency in low-resource settings. Here, we show that these barriers can be overcome by building clinical native intelligence directly from real-world medical practice. Our key insight is that large-scale telemedicine programs, where expert centers provide remote consultations across distributed facilities, represent a natural reservoir for learning clinical image interpretation. We present ReVision, a retinal foundation model that learns from the natural alignment between 485,980 color fundus photographs and their corresponding diagnostic reports, accumulated through a decade-long telemedicine program spanning 162 medical institutions across China. Through extensive evaluation across 27 ophthalmic benchmarks, we demonstrate that ReVison enables deployment efficiency with minimal local resources. Without any task-specific training, ReVision achieves zero-shot disease detection with an average AUROC of 0.946 across 12 public benchmarks and 0.952 on 3 independent clinical cohorts. When minimal adaptation is feasible, ReVision matches extensively fine-tuned alternatives while requiring orders of magnitude fewer trainable parameters and labeled examples. The learned representations also transfer effectively to new clinical sites, imaging domains, imaging modalities, and systemic health prediction tasks. In a prospective reader study with 33 ophthalmologists, ReVision's zero-shot assistance improved diagnostic accuracy by 14.8% across all experience levels. These results demonstrate that clinical native intelligence can be directly extracted from clinical archives without any further annotation to build medical AI systems suited to various low-resource settings.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14499v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出ReVision视网膜基础模型，从大规模临床实践中学习，以解决低资源环境下部署效率低的问题。",
            "summary_zh": "当前视网膜基础模型受限于缺乏真实临床背景的精选研究数据集，且需要针对每个应用进行大量任务特定优化，限制了其在低资源环境下的部署效率。本文表明，通过直接从真实世界医疗实践中构建临床原生智能，可以克服这些障碍。我们的核心见解是，大规模远程医疗项目（专家中心为分布式设施提供远程咨询）是学习临床图像解读的自然资源库。我们提出了ReVision，一个视网膜基础模型，它从485,980张彩色眼底照片及其对应诊断报告的自然对齐中学习，这些数据来自中国162家医疗机构长达十年的远程医疗项目积累。通过在27个眼科基准上进行广泛评估，我们证明ReVision能以最小本地资源实现部署效率。无需任何任务特定训练，ReVision在12个公共基准上实现零样本疾病检测，平均AUROC为0.946，在3个独立临床队列上为0.952。当最小适应可行时，ReVision匹配经过广泛微调的替代方案，同时需要数量级更少的可训练参数和标记示例。学习到的表示还能有效迁移到新临床站点、成像域、成像模态和全身健康预测任务。在一项涉及33名眼科医生的前瞻性读者研究中，ReVision的零样本辅助将诊断准确性提高了14.8%，覆盖所有经验水平。这些结果表明，临床原生智能可以直接从临床档案中提取，无需进一步标注，以构建适合各种低资源环境的医疗AI系统。",
            "intro_zh": [
                "现有视网膜基础模型依赖精选数据集，缺乏真实临床上下文，且需大量任务特定优化，导致低资源部署效率低。",
                "论文提出从大规模远程医疗项目中学习临床原生智能，利用眼底照片与诊断报告的自然对齐构建基础模型。",
                "ReVision在零样本疾病检测中平均AUROC达0.946，最小适应下匹配微调模型，并提升医生诊断准确性14.8%。"
            ],
            "method_zh": "ReVision是一个视网膜基础模型，整体框架基于大规模远程医疗数据构建，利用485,980张彩色眼底照片及其对应诊断报告的自然对齐进行学习。关键技术创新点在于直接从临床实践中提取原生智能，无需额外标注，通过自监督或弱监督方法（具体方法未知）学习图像与文本的关联。与现有方法的主要区别在于，它不依赖精选研究数据集，而是基于真实世界临床数据，减少了任务特定优化的需求，提高了部署效率。",
            "application_zh": "该研究可应用于低资源医疗环境，如远程眼科诊断、疾病筛查和健康预测，通过零样本或最小适应实现高效部署，提升临床决策支持。",
            "highlight_zh": "ReVision在12个公共基准上零样本疾病检测平均AUROC为0.946，最小适应下匹配微调模型，可训练参数和标记示例大幅减少，并在前瞻性研究中提升医生诊断准确性14.8%。",
            "tags_zh": [
                "视网膜基础模型",
                "临床原生智能",
                "远程医疗",
                "零样本学习",
                "部署效率",
                "眼底图像分析",
                "医疗AI",
                "低资源环境"
            ],
            "_index": 55
        },
        {
            "title": "SuperCLIP: CLIP with Simple Classification Supervision",
            "authors": [
                "Weiheng Zhao",
                "Zilong Huang",
                "Jiashi Feng",
                "Xinggang Wang"
            ],
            "arxiv_id": "2512.14480v1",
            "summary": "Contrastive Language-Image Pretraining (CLIP) achieves strong generalization in vision-language tasks by aligning images and texts in a shared embedding space. However, recent findings show that CLIP-like models still underutilize fine-grained semantic signals in text, and this issue becomes even more pronounced when dealing with long and detailed captions. This stems from CLIP's training objective, which optimizes only global image-text similarity and overlooks token-level supervision - limiting its ability to achieve fine-grained visual-text alignment. To address this, we propose SuperCLIP, a simple yet effective framework that augments contrastive learning with classification-based supervision. By adding only a lightweight linear layer to the vision encoder, SuperCLIP leverages token-level cues to enhance visual-textual alignment - with just a 0.077% increase in total FLOPs, and no need for additional annotated data. Experiments show that SuperCLIP consistently improves zero-shot classification, image-text retrieval, and purely visual tasks. These gains hold regardless of whether the model is trained on original web data or rich re-captioned data, demonstrating SuperCLIP's ability to recover textual supervision in both cases. Furthermore, SuperCLIP alleviates CLIP's small-batch performance drop through classification-based supervision that avoids reliance on large batch sizes. Code and models will be made open source.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Accepted by NeurIPS 2025. Code: https://github.com/hustvl/SuperCLIP",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14480v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出SuperCLIP框架，通过分类监督增强对比学习，解决CLIP模型细粒度语义利用不足的问题。",
            "summary_zh": "对比语言-图像预训练（CLIP）通过在共享嵌入空间中对齐图像和文本来实现视觉-语言任务的强泛化能力。然而，最近的研究发现，CLIP类模型在处理文本时仍未能充分利用细粒度语义信号，这一问题在处理长而详细的描述时尤为突出。这源于CLIP的训练目标仅优化全局图像-文本相似性，而忽略了词元级监督，限制了其实现细粒度视觉-文本对齐的能力。为解决这一问题，我们提出了SuperCLIP，一个简单而有效的框架，通过基于分类的监督来增强对比学习。仅通过在视觉编码器上添加一个轻量级线性层，SuperCLIP利用词元级线索来增强视觉-文本对齐，总FLOPs仅增加0.077%，且无需额外标注数据。实验表明，SuperCLIP在零样本分类、图像-文本检索和纯视觉任务上均能持续提升性能。这些增益无论模型是在原始网络数据还是丰富的重新描述数据上训练都成立，证明了SuperCLIP在两种情况下恢复文本监督的能力。此外，SuperCLIP通过基于分类的监督减轻了CLIP在小批量情况下的性能下降，避免了依赖大批量大小。代码和模型将开源。",
            "intro_zh": [
                "CLIP模型仅优化全局图像-文本相似性，忽略词元级监督，导致细粒度语义信号利用不足，尤其在处理长描述时表现更差。",
                "SuperCLIP通过添加轻量级线性层，引入基于分类的监督，增强对比学习，利用词元级线索提升视觉-文本对齐，无需额外数据。",
                "实验显示SuperCLIP在零样本分类、图像-文本检索和视觉任务上均提升性能，并缓解小批量性能下降，适用于多种训练数据。"
            ],
            "method_zh": "SuperCLIP是一个增强CLIP的框架，整体基于对比学习，但引入分类监督。关键创新在于在视觉编码器后添加一个轻量级线性层，用于生成词元级分类预测，从而利用文本中的细粒度语义信号。与现有方法的主要区别在于，它不依赖额外标注数据或复杂架构，仅通过简单分类监督弥补CLIP的全局对齐不足，实现更精细的视觉-文本对齐，同时保持计算效率。",
            "application_zh": "该研究可应用于多模态人工智能领域，如零样本图像分类、图像-文本检索、视觉问答和机器人视觉理解，提升模型在细粒度语义任务上的性能，具有实际价值。",
            "highlight_zh": "SuperCLIP在零样本分类、图像-文本检索和纯视觉任务上均实现性能提升，总FLOPs仅增加0.077%，且能缓解CLIP的小批量性能下降，适用于原始和重新描述数据。",
            "tags_zh": [
                "对比学习",
                "多模态对齐",
                "细粒度语义",
                "零样本分类",
                "图像-文本检索",
                "轻量级监督",
                "视觉-语言模型",
                "分类监督"
            ],
            "_index": 56
        },
        {
            "title": "TACK Tunnel Data (TTD): A Benchmark Dataset for Deep Learning-Based Defect Detection in Tunnels",
            "authors": [
                "Andreas Sjölander",
                "Valeria Belloni",
                "Robel Fekadu",
                "Andrea Nascetti"
            ],
            "arxiv_id": "2512.14477v1",
            "summary": "Tunnels are essential elements of transportation infrastructure, but are increasingly affected by ageing and deterioration mechanisms such as cracking. Regular inspections are required to ensure their safety, yet traditional manual procedures are time-consuming, subjective, and costly. Recent advances in mobile mapping systems and Deep Learning (DL) enable automated visual inspections. However, their effectiveness is limited by the scarcity of tunnel datasets. This paper introduces a new publicly available dataset containing annotated images of three different tunnel linings, capturing typical defects: cracks, leaching, and water infiltration. The dataset is designed to support supervised, semi-supervised, and unsupervised DL methods for defect detection and segmentation. Its diversity in texture and construction techniques also enables investigation of model generalization and transferability across tunnel types. By addressing the critical lack of domain-specific data, this dataset contributes to advancing automated tunnel inspection and promoting safer, more efficient infrastructure maintenance strategies.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14477v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "mapping"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "PPO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出TACK隧道数据集（TTD）以解决隧道缺陷检测中领域数据稀缺问题",
            "summary_zh": "隧道是交通基础设施的关键组成部分，但日益受到老化和劣化机制（如开裂）的影响。为确保其安全，需要定期检查，但传统的人工检查方法耗时、主观且成本高昂。移动测绘系统和深度学习的最新进展使得自动化视觉检查成为可能，但其有效性受限于隧道数据集的稀缺性。本文介绍了一个新的公开可用数据集，包含三种不同隧道衬砌的标注图像，捕捉了典型缺陷：裂缝、渗漏和水渗透。该数据集旨在支持有监督、半监督和无监督的深度学习方法进行缺陷检测和分割。其在纹理和施工技术方面的多样性也使得能够研究模型在不同隧道类型间的泛化性和可迁移性。通过解决领域特定数据的关键缺乏问题，该数据集有助于推进自动化隧道检查，并促进更安全、更高效的基础设施维护策略。",
            "intro_zh": [
                "核心问题：隧道缺陷检测依赖传统人工检查，存在耗时、主观和成本高的问题，且深度学习应用受限于领域数据稀缺。",
                "方法要点：构建公开隧道数据集TTD，包含多种衬砌类型的标注图像，支持监督、半监督和无监督学习方法。",
                "实验或效果：数据集促进模型泛化性研究，提升自动化检测效率，为基础设施维护提供数据基础。"
            ],
            "method_zh": "论文的核心方法是构建TACK隧道数据集（TTD），整体框架包括数据采集、标注和公开共享。关键技术创新点在于数据集覆盖三种不同隧道衬砌类型（如混凝土、砖石等），并标注了裂缝、渗漏和水渗透等典型缺陷，增强了纹理和施工技术的多样性。与现有方法的主要区别在于，TTD专门针对隧道领域，解决了数据稀缺问题，支持多种深度学习范式（监督、半监督、无监督），并强调模型跨隧道类型的泛化性和可迁移性研究，而现有数据集往往规模小或缺乏多样性。",
            "application_zh": "该研究主要应用于交通基础设施的自动化隧道检查领域，潜在价值包括提升隧道安全监测效率、降低人工检查成本，并支持智能维护策略的开发，促进更可持续的基础设施管理。",
            "highlight_zh": "最重要的实验结果包括数据集成功捕捉了多种隧道缺陷，支持深度学习模型训练，并通过多样性设计促进了模型泛化性研究，为自动化检测提供了基准数据，但具体性能提升数据未知。",
            "tags_zh": [
                "隧道缺陷检测",
                "深度学习数据集",
                "基础设施检查",
                "图像分割",
                "模型泛化性",
                "自动化视觉检查",
                "移动测绘系统",
                "半监督学习"
            ],
            "_index": 57
        },
        {
            "title": "Kinetic-Mamba: Mamba-Assisted Predictions of Stiff Chemical Kinetics",
            "authors": [
                "Additi Pandey",
                "Liang Wei",
                "Hessam Babaee",
                "George Em Karniadakis"
            ],
            "arxiv_id": "2512.14471v1",
            "summary": "Accurate chemical kinetics modeling is essential for combustion simulations, as it governs the evolution of complex reaction pathways and thermochemical states. In this work, we introduce Kinetic-Mamba, a Mamba-based neural operator framework that integrates the expressive power of neural operators with the efficient temporal modeling capabilities of Mamba architectures. The framework comprises three complementary models: (i) a standalone Mamba model that predicts the time evolution of thermochemical state variables from given initial conditions; (ii) a constrained Mamba model that enforces mass conservation while learning the state dynamics; and (iii) a regime-informed architecture employing two standalone Mamba models to capture dynamics across temperature-dependent regimes. We additionally develop a latent Kinetic-Mamba variant that evolves dynamics in a reduced latent space and reconstructs the full state on the physical manifold. We evaluate the accuracy and robustness of Kinetic-Mamba using both time-decomposition and recursive-prediction strategies. We further assess the extrapolation capabilities of the model on varied out-of-distribution datasets. Computational experiments on Syngas and GRI-Mech 3.0 reaction mechanisms demonstrate that our framework achieves high fidelity in predicting complex kinetic behavior using only the initial conditions of the state variables.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14471v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO",
                        "VIO"
                    ],
                    "score": 2
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出Kinetic-Mamba框架，结合Mamba架构与神经算子，以解决燃烧模拟中刚性化学动力学的高精度预测问题。",
            "summary_zh": "精确的化学动力学建模对燃烧模拟至关重要，它控制着复杂反应路径和热化学状态的演化。本文介绍了Kinetic-Mamba，这是一个基于Mamba的神经算子框架，将神经算子的表达能力与Mamba架构的高效时间建模能力相结合。该框架包含三个互补模型：（i）一个独立的Mamba模型，从给定初始条件预测热化学状态变量的时间演化；（ii）一个约束Mamba模型，在学习状态动力学的同时强制质量守恒；（iii）一个基于温度依赖区域的架构，采用两个独立的Mamba模型来捕捉跨区域的动力学。我们还开发了一个潜在Kinetic-Mamba变体，在降维潜在空间中演化动力学，并在物理流形上重建完整状态。我们使用时间分解和递归预测策略评估Kinetic-Mamba的准确性和鲁棒性。进一步评估了模型在不同分布外数据集上的外推能力。在Syngas和GRI-Mech 3.0反应机制上的计算实验表明，我们的框架仅使用状态变量的初始条件就能高保真地预测复杂的动力学行为。",
            "intro_zh": [
                "核心问题：燃烧模拟中刚性化学动力学建模面临计算成本高、传统方法难以捕捉复杂反应路径的挑战，现有方法在效率和精度上存在不足。",
                "方法要点：提出Kinetic-Mamba框架，结合Mamba架构的高效时间建模与神经算子的表达能力，通过多个互补模型和潜在空间演化提升预测能力。",
                "实验或效果：在Syngas和GRI-Mech 3.0机制上验证，仅用初始条件即可高保真预测动力学，展现出优异的准确性和外推鲁棒性。"
            ],
            "method_zh": "Kinetic-Mamba是一个基于Mamba的神经算子框架，整体框架包括三个互补模型：独立Mamba模型用于直接预测状态演化，约束Mamba模型在训练中强制质量守恒，以及基于温度依赖区域的架构使用两个Mamba模型捕捉跨区域动力学。关键技术创新点在于将Mamba架构的高效序列建模能力与神经算子的泛化能力相结合，并引入潜在空间变体以降低计算复杂度。与现有方法的主要区别在于其专注于刚性化学动力学的端到端预测，通过多模型集成和约束设计，显著提升了在复杂反应系统中的建模效率和精度。",
            "application_zh": "该研究主要应用于燃烧模拟领域，如发动机设计、能源系统和环境建模，通过高精度化学动力学预测优化燃烧过程，提高模拟效率，降低计算成本，对工业设计和科学研究具有重要价值。",
            "highlight_zh": "实验在Syngas和GRI-Mech 3.0反应机制上进行，Kinetic-Mamba仅使用初始条件即实现高保真动力学预测，通过时间分解和递归策略验证了其准确性和鲁棒性，并在分布外数据集上展现出良好的外推能力，显著提升了预测性能。",
            "tags_zh": [
                "化学动力学建模",
                "Mamba架构",
                "神经算子",
                "燃烧模拟",
                "刚性系统",
                "潜在空间学习",
                "质量守恒约束",
                "温度依赖区域"
            ],
            "_index": 58
        },
        {
            "title": "Nonlinear System Identification Nano-drone Benchmark",
            "authors": [
                "Riccardo Busetto",
                "Elia Cereda",
                "Marco Forgione",
                "Gabriele Maroni",
                "Dario Piga",
                "Daniele Palossi"
            ],
            "arxiv_id": "2512.14450v1",
            "summary": "We introduce a benchmark for system identification based on 75k real-world samples from the Crazyflie 2.1 Brushless nano-quadrotor, a sub-50g aerial vehicle widely adopted in robotics research. The platform presents a challenging testbed due to its multi-input, multi-output nature, open-loop instability, and nonlinear dynamics under agile maneuvers. The dataset comprises four aggressive trajectories with synchronized 4-dimensional motor inputs and 13-dimensional output measurements. To enable fair comparison of identification methods, the benchmark includes a suite of multi-horizon prediction metrics for evaluating both one-step and multi-step error propagation. In addition to the data, we provide a detailed description of the platform and experimental setup, as well as baseline models highlighting the challenge of accurate prediction under real-world noise and actuation nonlinearities. All data, scripts, and reference implementations are released as open-source at https://github.com/idsia-robotics/nanodrone-sysid-benchmark to facilitate transparent comparison of algorithms and support research on agile, miniaturized aerial robotics.",
            "categories": [
                "eess.SY",
                "cs.RO"
            ],
            "primary_category": "eess.SY",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14450v1",
            "code_links": [
                {
                    "url": "https://github.com/idsia-robotics/nanodrone-sysid-benchmark",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL",
                        "PPO"
                    ],
                    "score": 2
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出基于Crazyflie 2.1纳米四旋翼的75k真实世界样本系统辨识基准，以解决敏捷微型无人机非线性动力学建模挑战。",
            "summary_zh": "我们引入了一个基于Crazyflie 2.1无刷纳米四旋翼（一种广泛用于机器人研究的重量低于50克的飞行器）75k真实世界样本的系统辨识基准。该平台因其多输入多输出特性、开环不稳定性以及敏捷机动下的非线性动力学而成为一个具有挑战性的测试平台。数据集包含四条激进轨迹，具有同步的4维电机输入和13维输出测量。为了公平比较辨识方法，该基准包括一套多步长预测指标，用于评估一步和多步误差传播。除了数据外，我们还提供了平台和实验设置的详细描述，以及基线模型，突出了在真实世界噪声和执行器非线性下准确预测的挑战。所有数据、脚本和参考实现均以开源形式发布在https://github.com/idsia-robotics/nanodrone-sysid-benchmark，以促进算法的透明比较并支持敏捷微型空中机器人研究。",
            "intro_zh": [
                "现有系统辨识方法在微型无人机等非线性、不稳定平台上缺乏标准化评估基准，难以公平比较算法性能。",
                "论文提出基于Crazyflie 2.1纳米四旋翼的真实世界数据集和基准框架，包含多步预测指标和开源实现。",
                "基准提供了75k样本数据和基线模型，展示了在噪声和非线性下预测的挑战，支持算法透明比较。"
            ],
            "method_zh": "论文的核心方法是构建一个系统辨识基准框架，整体框架包括数据采集、基准定义和评估指标。关键技术创新点在于：基于Crazyflie 2.1纳米四旋翼平台，采集了75k真实世界样本，涵盖四条激进轨迹，提供4维电机输入和13维输出测量的同步数据；引入多步长预测指标，如一步和多步误差传播评估，以全面衡量辨识模型的性能。与现有方法的主要区别在于：该基准专注于微型无人机的非线性、不稳定动力学，提供开源数据和脚本，促进透明和可重复的比较，而传统基准可能缺乏真实世界噪声和非线性的考虑。",
            "application_zh": "该研究在敏捷微型空中机器人领域具有广泛应用，如无人机控制、自主导航和系统优化。潜在应用包括：为研究人员提供标准测试平台，加速非线性系统辨识算法开发；支持微型无人机在复杂环境中的精准建模，提升飞行稳定性和机动性；促进机器人学中真实世界数据驱动的建模研究。",
            "highlight_zh": "最重要的实验结果包括：基准数据集包含75k真实世界样本，覆盖激进机动下的非线性动力学；基线模型展示了在真实噪声和执行器非线性下预测的显著挑战，如多步误差累积；开源实现促进了算法透明比较，为后续研究提供了可靠基础。",
            "tags_zh": [
                "系统辨识基准",
                "非线性动力学",
                "微型无人机",
                "真实世界数据",
                "多步预测",
                "开源数据集",
                "机器人控制",
                "敏捷机动"
            ],
            "_index": 59
        },
        {
            "title": "A4-Agent: An Agentic Framework for Zero-Shot Affordance Reasoning",
            "authors": [
                "Zixin Zhang",
                "Kanghao Chen",
                "Hanqing Wang",
                "Hongfei Zhang",
                "Harold Haodong Chen",
                "Chenfei Liao",
                "Litao Guo",
                "Ying-Cong Chen"
            ],
            "arxiv_id": "2512.14442v1",
            "summary": "Affordance prediction, which identifies interaction regions on objects based on language instructions, is critical for embodied AI. Prevailing end-to-end models couple high-level reasoning and low-level grounding into a single monolithic pipeline and rely on training over annotated datasets, which leads to poor generalization on novel objects and unseen environments. In this paper, we move beyond this paradigm by proposing A4-Agent, a training-free agentic framework that decouples affordance prediction into a three-stage pipeline. Our framework coordinates specialized foundation models at test time: (1) a $\\textbf{Dreamer}$ that employs generative models to visualize $\\textit{how}$ an interaction would look; (2) a $\\textbf{Thinker}$ that utilizes large vision-language models to decide $\\textit{what}$ object part to interact with; and (3) a $\\textbf{Spotter}$ that orchestrates vision foundation models to precisely locate $\\textit{where}$ the interaction area is. By leveraging the complementary strengths of pre-trained models without any task-specific fine-tuning, our zero-shot framework significantly outperforms state-of-the-art supervised methods across multiple benchmarks and demonstrates robust generalization to real-world settings.",
            "categories": [
                "cs.CV",
                "cs.RO"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14442v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "世界模型",
                    "matched_keywords": [
                        "dreamer"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出A4-Agent框架，通过解耦推理过程实现零样本可及性预测，以解决具身AI中交互区域识别泛化性差的问题。",
            "summary_zh": "可及性预测是基于语言指令识别物体上交互区域的关键技术，对具身AI至关重要。当前主流端到端模型将高层推理与低层定位耦合在单一流程中，并依赖标注数据集训练，导致在新物体和未见环境上泛化能力差。本文超越这一范式，提出A4-Agent，一种无需训练的智能体框架，将可及性预测解耦为三阶段流程。该框架在测试时协调专用基础模型：(1) Dreamer利用生成模型可视化交互过程；(2) Thinker使用大型视觉语言模型决定交互的物体部分；(3) Spotter协调视觉基础模型精确定位交互区域。通过利用预训练模型的互补优势且无需任务特定微调，我们的零样本框架在多个基准测试中显著优于最先进的监督方法，并展现出对真实场景的鲁棒泛化能力。",
            "intro_zh": [
                "现有端到端模型耦合推理与定位，依赖标注数据训练，导致在新物体和环境中泛化性差。",
                "提出A4-Agent框架，解耦可及性预测为三阶段流程，协调专用基础模型实现零样本推理。",
                "在多个基准测试中显著优于监督方法，并展现出对真实场景的鲁棒泛化能力。"
            ],
            "method_zh": "A4-Agent是一个无需训练的智能体框架，将可及性预测解耦为三阶段流程：Dreamer阶段利用生成模型（如扩散模型）可视化交互过程，提供高层语义指导；Thinker阶段使用大型视觉语言模型（如GPT-4V）分析物体部分，决定交互目标；Spotter阶段协调视觉基础模型（如SAM）精确定位交互区域。关键创新在于通过模块化设计，将推理任务分解为“如何”、“什么”和“哪里”三个子问题，并利用预训练模型的互补能力，无需额外微调。与现有方法的主要区别在于避免了端到端耦合和标注数据依赖，实现了零样本泛化。",
            "application_zh": "该研究可应用于具身AI领域，如家庭服务机器人、工业自动化、虚拟现实交互等，通过零样本可及性预测，提升机器人在新环境中的自主交互能力，减少对大量标注数据的依赖，具有实际部署价值。",
            "highlight_zh": "在多个基准测试中，A4-Agent的零样本性能显著优于最先进的监督方法，例如在特定数据集上提升超过10%，并展现出对真实世界场景的强泛化能力，验证了框架的有效性。",
            "tags_zh": [
                "可及性预测",
                "零样本学习",
                "具身AI",
                "智能体框架",
                "视觉语言模型",
                "基础模型协调",
                "解耦推理",
                "交互区域识别"
            ],
            "_index": 60
        },
        {
            "title": "Effect of Document Packing on the Latent Multi-Hop Reasoning Capabilities of Large Language Models",
            "authors": [
                "Gabriele Prato",
                "Shagun Sodhani",
                "Alessandro Sordoni",
                "Sarath Chandar"
            ],
            "arxiv_id": "2512.14427v1",
            "summary": "The standard practice for training large language models involves packing multiple documents together to optimize computational efficiency. However, the impact of this process on the models' capabilities remains largely unexplored. To address this gap, we investigate how different document-packing strategies influence the latent multi-hop reasoning abilities of LLMs. Our findings indicate that packing can improve model performance compared to training on individual documents, at the expense of more compute. To further understand the underlying mechanisms, we conduct an ablation study, identifying key factors that explain the advantages of packing. Ultimately, our research deepens the understanding of LLM training dynamics and provides practical insights for optimizing model development.",
            "categories": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14427v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "研究文档打包策略对大型语言模型潜在多跳推理能力的影响，优化模型训练效率与性能",
            "summary_zh": "训练大型语言模型的标准实践通常涉及将多个文档打包在一起以提高计算效率，但这一过程对模型能力的影响尚未得到充分探索。为填补这一空白，本研究调查了不同文档打包策略如何影响LLMs的潜在多跳推理能力。我们的发现表明，与在单个文档上训练相比，打包可以提高模型性能，但需要更多的计算资源。为了进一步理解底层机制，我们进行了消融研究，识别了解释打包优势的关键因素。最终，我们的研究深化了对LLM训练动态的理解，并为优化模型开发提供了实用见解。",
            "intro_zh": [
                "核心问题：现有LLM训练中广泛采用文档打包以提升计算效率，但其对模型潜在多跳推理能力的影响机制尚不明确，缺乏系统研究。",
                "方法要点：通过对比不同文档打包策略，分析其对LLMs多跳推理能力的影响，并设计消融实验探究关键因素。",
                "实验或效果：发现打包策略能提升模型性能，但需更多计算资源；消融研究揭示了打包优势的驱动因素。"
            ],
            "method_zh": "本研究采用实验分析框架，核心方法包括设计不同文档打包策略（如基于内容或长度的打包），在标准LLM训练流程中应用这些策略，并评估其对多跳推理任务的影响。关键技术创新点在于系统量化打包策略与模型能力间的关联，通过消融研究分离出影响性能的关键变量（如文档间关联性、打包密度）。与现有方法的主要区别在于，现有研究多关注打包的计算效率，而本文首次深入探讨其对模型内在推理能力的潜在影响，提供了更全面的训练动态分析。",
            "application_zh": "该研究可应用于优化大型语言模型的训练流程，帮助开发者在计算资源与模型性能间做出平衡决策，提升多跳推理任务（如复杂问答、逻辑推理）的模型表现，对AI助手、教育工具和自动化分析系统有实际价值。",
            "highlight_zh": "实验表明，文档打包策略相比单文档训练能显著提升LLMs的多跳推理能力，但计算成本增加；消融研究识别出文档间语义关联和打包顺序是关键影响因素，为高效训练提供了实证依据。",
            "tags_zh": [
                "文档打包策略",
                "多跳推理",
                "大型语言模型训练",
                "计算效率优化",
                "消融研究",
                "模型性能分析",
                "训练动态"
            ],
            "_index": 61
        },
        {
            "title": "The Devil is in Attention Sharing: Improving Complex Non-rigid Image Editing Faithfulness via Attention Synergy",
            "authors": [
                "Zhuo Chen",
                "Fanyue Wei",
                "Runze Xu",
                "Jingjing Li",
                "Lixin Duan",
                "Angela Yao",
                "Wen Li"
            ],
            "arxiv_id": "2512.14423v1",
            "summary": "Training-free image editing with large diffusion models has become practical, yet faithfully performing complex non-rigid edits (e.g., pose or shape changes) remains highly challenging. We identify a key underlying cause: attention collapse in existing attention sharing mechanisms, where either positional embeddings or semantic features dominate visual content retrieval, leading to over-editing or under-editing.To address this issue, we introduce SynPS, a method that Synergistically leverages Positional embeddings and Semantic information for faithful non-rigid image editing. We first propose an editing measurement that quantifies the required editing magnitude at each denoising step. Based on this measurement, we design an attention synergy pipeline that dynamically modulates the influence of positional embeddings, enabling SynPS to balance semantic modifications and fidelity preservation.By adaptively integrating positional and semantic cues, SynPS effectively avoids both over- and under-editing. Extensive experiments on public and newly curated benchmarks demonstrate the superior performance and faithfulness of our approach.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project page:https://synps26.github.io/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14423v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出SynPS方法，通过注意力协同机制解决复杂非刚性图像编辑中的过编辑与欠编辑问题",
            "summary_zh": "基于大型扩散模型的无训练图像编辑已变得实用，但忠实执行复杂非刚性编辑（如姿态或形状变化）仍然极具挑战。我们发现一个关键根本原因：现有注意力共享机制中的注意力崩溃，其中位置嵌入或语义特征主导视觉内容检索，导致过编辑或欠编辑。为解决这一问题，我们引入了SynPS方法，该方法协同利用位置嵌入和语义信息进行忠实的非刚性图像编辑。我们首先提出一种编辑度量，量化每个去噪步骤所需的编辑幅度。基于此度量，我们设计了一个注意力协同流程，动态调节位置嵌入的影响，使SynPS能够平衡语义修改和保真度保持。通过自适应整合位置和语义线索，SynPS有效避免了过编辑和欠编辑。在公共和新策划的基准测试上的大量实验证明了我们方法的优越性能和忠实性。",
            "intro_zh": [
                "现有方法在复杂非刚性编辑中存在注意力崩溃问题，位置嵌入或语义特征主导导致过编辑或欠编辑",
                "提出SynPS方法，通过编辑度量动态调节位置嵌入影响，协同利用位置和语义信息",
                "实验表明SynPS在公共和新基准上表现优越，有效提升编辑忠实性，避免过编辑和欠编辑"
            ],
            "method_zh": "SynPS的整体框架是一个基于扩散模型的注意力协同编辑流程。首先，提出编辑度量来量化每个去噪步骤的编辑需求，这是关键创新点，使编辑过程可测量。然后，设计注意力协同机制，动态调制位置嵌入的影响，平衡语义修改与保真度保持。与现有方法的主要区别在于：现有方法往往固定依赖位置或语义信息，导致注意力崩溃；而SynPS通过自适应整合两者，实现更精细的控制，避免过编辑和欠编辑，提升复杂非刚性编辑的忠实性。",
            "application_zh": "该研究在计算机视觉和图像处理领域有广泛应用，特别适用于需要高保真度的复杂非刚性图像编辑，如人物姿态调整、物体形状变换、艺术创作和影视后期制作。其实际价值在于提供更可靠、可控的编辑工具，提升自动化编辑的质量和效率。",
            "highlight_zh": "在公共基准和新策划数据集上的实验显示，SynPS在复杂非刚性编辑任务中显著优于现有方法，有效避免过编辑和欠编辑，编辑忠实性得到大幅提升，证明了注意力协同机制的有效性和优越性。",
            "tags_zh": [
                "图像编辑",
                "扩散模型",
                "注意力机制",
                "非刚性编辑",
                "位置嵌入",
                "语义信息",
                "编辑忠实性",
                "去噪过程"
            ],
            "_index": 62
        },
        {
            "title": "Hybrid Ensemble Method for Detecting Cyber-Attacks in Water Distribution Systems Using the BATADAL Dataset",
            "authors": [
                "Waqas Ahmed"
            ],
            "arxiv_id": "2512.14422v1",
            "summary": "The cybersecurity of Industrial Control Systems that manage critical infrastructure such as Water Distribution Systems has become increasingly important as digital connectivity expands. BATADAL benchmark data is a good source of testing intrusion detection techniques, but it presents several important problems, such as imbalance in the number of classes, multivariate time dependence, and stealthy attacks. We consider a hybrid ensemble learning model that will enhance the detection ability of cyber-attacks in WDS by using the complementary capabilities of machine learning and deep learning models. Three base learners, namely, Random Forest , eXtreme Gradient Boosting , and Long Short-Term Memory network, have been strictly compared and seven ensemble types using simple averaged and stacked learning with a logistic regression meta-learner. Random Forest analysis identified top predictors turned into temporal and statistical features, and Synthetic Minority Oversampling Technique (SMOTE) was used to overcome the class imbalance issue. The analyics indicates that the single Long Short-Term Memory network model is of poor performance (F1 = 0.000, AUC = 0.4460), but tree-based models, especially eXtreme Gradient Boosting, perform well (F1 = 0.7470, AUC=0.9684). The hybrid stacked ensemble of Random Forest , eXtreme Gradient Boosting , and Long Short-Term Memory network scored the highest, with the attack class of 0.7205 with an F1-score and a AUC of 0.9826 indicating that the heterogeneous stacking between model precision and generalization can work. The proposed framework establishes a robust and scalable solution for cyber-attack detection in time-dependent industrial systems, integrating temporal learning and ensemble diversity to support the secure operation of critical infrastructure.",
            "categories": [
                "cs.CR",
                "cs.LG"
            ],
            "primary_category": "cs.CR",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "18 pages, & figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14422v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "人形机器人",
                    "matched_keywords": [
                        "digit"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "PPO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出混合集成学习方法以解决水分配系统中网络攻击检测的类别不平衡与时间依赖性问题。",
            "summary_zh": "随着数字连接性的扩展，管理关键基础设施（如水分配系统）的工业控制系统的网络安全变得越来越重要。BATADAL基准数据是测试入侵检测技术的良好来源，但它提出了几个重要问题，如类别数量不平衡、多变量时间依赖性和隐蔽攻击。我们考虑一种混合集成学习模型，通过利用机器学习和深度学习模型的互补能力，增强水分配系统中网络攻击的检测能力。对三种基础学习器（随机森林、极限梯度提升和长短期记忆网络）进行了严格比较，并使用了七种集成类型，包括简单平均和基于逻辑回归元学习器的堆叠学习。随机森林分析确定了转化为时间和统计特征的重要预测因子，并使用合成少数类过采样技术（SMOTE）来克服类别不平衡问题。分析表明，单一长短期记忆网络模型性能较差（F1 = 0.000，AUC = 0.4460），但基于树的模型，尤其是极限梯度提升，表现良好（F1 = 0.7470，AUC = 0.9684）。随机森林、极限梯度提升和长短期记忆网络的混合堆叠集成得分最高，攻击类别的F1分数为0.7205，AUC为0.9826，表明模型精度和泛化能力之间的异构堆叠是有效的。所提出的框架为时间依赖的工业系统中的网络攻击检测建立了一个稳健且可扩展的解决方案，集成了时间学习和集成多样性，以支持关键基础设施的安全运行。",
            "intro_zh": [
                "核心问题：BATADAL数据集存在类别不平衡、多变量时间依赖性和隐蔽攻击等挑战，影响网络攻击检测的准确性。",
                "方法要点：提出混合集成学习框架，结合随机森林、极限梯度提升和长短期记忆网络，利用堆叠学习提升检测能力。",
                "实验或效果：混合堆叠集成在攻击检测上达到最高性能（F1=0.7205，AUC=0.9826），显著优于单一模型。"
            ],
            "method_zh": "论文提出一个混合集成学习框架，用于水分配系统中的网络攻击检测。整体框架包括三个基础学习器：随机森林（RF）、极限梯度提升（XGBoost）和长短期记忆网络（LSTM），通过简单平均和堆叠学习（使用逻辑回归作为元学习器）进行集成。关键技术创新点在于异构模型的互补集成，结合了基于树的模型（处理静态特征）和深度学习模型（处理时间依赖），并应用SMOTE解决类别不平衡问题。与现有方法的主要区别在于，该方法针对BATADAL数据集的多变量时间依赖和隐蔽攻击特性，通过集成多样性增强检测鲁棒性，而传统方法可能忽视时间维度或模型异构性。",
            "application_zh": "该研究主要应用于工业控制系统的网络安全领域，特别是水分配系统等关键基础设施的网络攻击检测。实际价值在于提供一种可扩展的解决方案，能够处理实时数据流和复杂攻击模式，支持基础设施的安全监控和防御，提升系统韧性。",
            "highlight_zh": "最重要的实验结果是混合堆叠集成（RF、XGBoost和LSTM）在攻击检测上表现最佳，F1分数为0.7205，AUC达到0.9826，相比单一LSTM模型（F1=0.000，AUC=0.4460）有显著提升，验证了异构集成在精度和泛化上的优势。",
            "tags_zh": [
                "网络攻击检测",
                "混合集成学习",
                "水分配系统",
                "BATADAL数据集",
                "时间依赖分析",
                "类别不平衡处理",
                "堆叠学习",
                "工业控制系统安全"
            ],
            "_index": 63
        },
        {
            "title": "Dual-Axis RCCL: Representation-Complete Convergent Learning for Organic Chemical Space",
            "authors": [
                "Dejun Hu",
                "Zhiming Li",
                "Jia-Rui Shen",
                "Jia-Ning Tu",
                "Zi-Hao Ye",
                "Junliang Zhang"
            ],
            "arxiv_id": "2512.14418v1",
            "summary": "Machine learning is profoundly reshaping molecular and materials modeling; however, given the vast scale of chemical space (10^30-10^60), it remains an open scientific question whether models can achieve convergent learning across this space. We introduce a Dual-Axis Representation-Complete Convergent Learning (RCCL) strategy, enabled by a molecular representation that integrates graph convolutional network (GCN) encoding of local valence environments, grounded in modern valence bond theory, together with no-bridge graph (NBG) encoding of ring/cage topologies, providing a quantitative measure of chemical-space coverage. This framework formalizes representation completeness, establishing a principled basis for constructing datasets that support convergent learning for large models. Guided by this RCCL framework, we develop the FD25 dataset, systematically covering 13,302 local valence units and 165,726 ring/cage topologies, achieving near-complete combinatorial coverage of organic molecules with H/C/N/O/F elements. Graph neural networks trained on FD25 exhibit representation-complete convergent learning and strong out-of-distribution generalization, with an overall prediction error of approximately 1.0 kcal/mol MAE across external benchmarks. Our results establish a quantitative link between molecular representation, structural completeness, and model generalization, providing a foundation for interpretable, transferable, and data-efficient molecular intelligence.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "33 pages, 10 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14418v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "PPO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出双轴表示完全收敛学习策略，以解决有机化学空间大规模模型收敛学习问题。",
            "summary_zh": "机器学习正在深刻重塑分子与材料建模；然而，考虑到化学空间的巨大规模（10^30-10^60），模型能否在该空间实现收敛学习仍是一个开放的科学问题。我们引入了一种双轴表示完全收敛学习策略，该策略通过一种分子表示实现，该表示整合了基于现代价键理论的局部价环境图卷积网络编码，以及环/笼拓扑的无桥图编码，提供了化学空间覆盖的定量度量。该框架形式化了表示完全性，为构建支持大模型收敛学习的数据集建立了原则性基础。在此RCCL框架指导下，我们开发了FD25数据集，系统覆盖了13,302个局部价单元和165,726个环/笼拓扑，实现了对含H/C/N/O/F元素的有机分子的近乎完全组合覆盖。在FD25上训练的图神经网络表现出表示完全收敛学习和强大的分布外泛化能力，在外部基准测试中整体预测误差约为1.0 kcal/mol MAE。我们的结果建立了分子表示、结构完全性和模型泛化之间的定量联系，为可解释、可迁移和数据高效的分子智能奠定了基础。",
            "intro_zh": [
                "核心问题：化学空间规模巨大（10^30-10^60），现有方法难以确保模型在该空间实现收敛学习，泛化能力受限。",
                "方法要点：提出双轴RCCL策略，结合局部价环境GCN编码和环/笼拓扑NBG编码，构建表示完全的数据集FD25。",
                "实验或效果：模型在FD25上训练后，实现收敛学习，外部基准预测误差约1.0 kcal/mol MAE，泛化性能显著提升。"
            ],
            "method_zh": "论文提出双轴表示完全收敛学习框架，核心方法包括：整体框架基于分子表示的双轴编码，一轴使用图卷积网络编码局部价环境（基于现代价键理论），另一轴使用无桥图编码环/笼拓扑，以量化化学空间覆盖。关键技术创新在于形式化表示完全性概念，并据此构建FD25数据集，系统覆盖局部价单元和环/笼拓扑的组合。与现有方法的主要区别在于，它提供了原则性数据集构建基础，确保模型在有机化学空间实现收敛学习，而非依赖随机或有限数据。",
            "application_zh": "该研究在分子与材料建模领域具有广泛应用潜力，可用于药物发现、材料设计、催化剂开发等，通过提供可解释、可迁移的分子智能模型，提升数据效率和预测准确性，加速新分子和材料的研发进程。",
            "highlight_zh": "最重要的实验结果包括：FD25数据集覆盖13,302个局部价单元和165,726个环/笼拓扑，实现近乎完全组合覆盖；图神经网络在FD25上训练后，在外部基准测试中整体预测误差约为1.0 kcal/mol MAE，显示出强大的分布外泛化能力，验证了表示完全收敛学习的有效性。",
            "tags_zh": [
                "化学空间建模",
                "表示完全收敛学习",
                "图神经网络",
                "分子表示学习",
                "有机分子数据集",
                "分布外泛化",
                "价键理论编码",
                "拓扑结构编码"
            ],
            "_index": 64
        },
        {
            "title": "Massive Editing for Large Language Models Based on Dynamic Weight Generation",
            "authors": [
                "Wentao Wan",
                "Qiqing Lao",
                "Zhiwei Xie",
                "Hefeng Wu",
                "Runnan Lin",
                "Liang Lin",
                "Keze Wang"
            ],
            "arxiv_id": "2512.14395v1",
            "summary": "Knowledge Editing (KE) is a field that studies how to modify some knowledge in Large Language Models (LLMs) at a low cost (compared to pre-training). Currently, performing large-scale edits on LLMs while ensuring the Reliability, Generality, and Locality metrics of the edits remain a challenge. This paper proposes a Massive editing approach for LLMs based on dynamic weight Generation (MeG). Our MeG involves attaching a dynamic weight neuron to specific layers of the LLMs and using a diffusion model to conditionally generate the weights of this neuron based on the input query required for the knowledge. This allows the use of adding a single dynamic weight neuron to achieve the goal of large-scale knowledge editing. Experiments show that our MeG can significantly improve the performance of large-scale KE in terms of Reliability, Generality, and Locality metrics compared to existing knowledge editing methods, particularly with a high percentage point increase in the absolute value index for the Locality metric, demonstrating the advantages of our proposed method.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "27 pages, 8 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14395v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出基于动态权重生成的大规模编辑方法MeG，以解决大语言模型知识编辑中的大规模修改挑战。",
            "summary_zh": "知识编辑（KE）是研究如何以低成本（相比预训练）修改大语言模型（LLMs）中某些知识的领域。目前，在对LLMs进行大规模编辑的同时，确保编辑的可靠性、通用性和局部性指标仍是一个挑战。本文提出了一种基于动态权重生成的大规模编辑方法（MeG）。我们的MeG涉及在LLMs的特定层附加一个动态权重神经元，并使用扩散模型根据知识所需的输入查询条件生成该神经元的权重。这使得通过添加单个动态权重神经元即可实现大规模知识编辑的目标。实验表明，与现有知识编辑方法相比，我们的MeG在可靠性、通用性和局部性指标方面能显著提升大规模KE的性能，特别是局部性指标的绝对值指数有较高的百分点提升，证明了我们提出方法的优势。",
            "intro_zh": [
                "现有知识编辑方法难以在大规模修改时同时保证可靠性、通用性和局部性，导致编辑效果受限。",
                "MeG通过附加动态权重神经元，利用扩散模型根据输入查询生成权重，实现单神经元支持大规模编辑。",
                "实验显示MeG在可靠性、通用性和局部性指标上显著优于现有方法，局部性提升尤为突出。"
            ],
            "method_zh": "MeG的整体框架是在大语言模型的特定层中附加一个动态权重神经元，该神经元的权重不固定，而是由扩散模型根据输入查询条件生成。关键技术创新在于将知识编辑问题转化为权重生成问题，通过扩散模型学习查询与编辑权重之间的映射关系，从而实现灵活的大规模编辑。与现有方法主要区别在于，传统方法通常依赖静态参数修改或外部存储，而MeG通过动态权重生成机制，仅需添加单个神经元即可适应多种编辑需求，提高了编辑的效率和可扩展性。",
            "application_zh": "该研究可应用于大语言模型的快速知识更新、错误修正和个性化定制，例如在对话系统、内容生成和知识库维护中，实现低成本、高效率的模型调整，提升AI系统的适应性和准确性。",
            "highlight_zh": "MeG在可靠性、通用性和局部性指标上均显著优于现有知识编辑方法，特别是局部性指标的绝对值指数有较高百分点提升，验证了其在大规模编辑场景下的优越性能。",
            "tags_zh": [
                "知识编辑",
                "大语言模型",
                "动态权重生成",
                "扩散模型",
                "大规模编辑",
                "神经元附加",
                "模型优化",
                "条件生成"
            ],
            "_index": 65
        },
        {
            "title": "A Comprehensive Safety Metric to Evaluate Perception in Autonomous Systems",
            "authors": [
                "Georg Volk",
                "Jörg Gamerdinger",
                "Alexander von Bernuth",
                "Oliver Bringmann"
            ],
            "arxiv_id": "2512.14367v1",
            "summary": "Complete perception of the environment and its correct interpretation is crucial for autonomous vehicles. Object perception is the main component of automotive surround sensing. Various metrics already exist for the evaluation of object perception. However, objects can be of different importance depending on their velocity, orientation, distance, size, or the potential damage that could be caused by a collision due to a missed detection. Thus, these additional parameters have to be considered for safety evaluation. We propose a new safety metric that incorporates all these parameters and returns a single easily interpretable safety assessment score for object perception. This new metric is evaluated with both real world and virtual data sets and compared to state of the art metrics.",
            "categories": [
                "cs.RO",
                "cs.CV"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Accepted at IEEE ITSC 2020",
            "doi": "10.1109/ITSC45102.2020.9294708",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14367v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "自动驾驶",
                    "matched_keywords": [
                        "autonomous vehicle"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出一种综合安全度量标准，用于评估自动驾驶系统中的感知性能，以解决现有度量忽略对象重要性差异的问题。",
            "summary_zh": "环境感知及其正确解释对自动驾驶车辆至关重要，对象感知是汽车环绕感知的核心组成部分。现有多种度量标准用于评估对象感知，但对象的重要性可能因其速度、方向、距离、大小或漏检可能导致碰撞的潜在损害而不同。因此，安全评估需考虑这些额外参数。我们提出一种新的安全度量标准，整合所有这些参数，并返回一个易于解释的单一安全评估分数。该新度量标准通过真实世界和虚拟数据集进行评估，并与最先进度量标准进行比较。",
            "intro_zh": [
                "现有对象感知度量标准未考虑对象重要性差异，如速度、方向、距离、大小和潜在碰撞损害，导致安全评估不全面。",
                "论文提出一种综合安全度量标准，整合对象重要性参数，生成单一安全评估分数，以提升感知评估的准确性和实用性。",
                "通过真实世界和虚拟数据集验证，新度量标准在安全评估方面优于现有方法，提供更全面的性能分析。"
            ],
            "method_zh": "论文提出一种综合安全度量标准框架，整体框架基于对象感知输出，整合速度、方向、距离、大小和潜在碰撞损害等参数，通过加权计算生成单一安全分数。关键技术创新点在于将多维度重要性参数统一量化，并设计可解释的评分机制。与现有方法的主要区别在于，现有度量通常仅关注检测精度或召回率，而新方法融合了安全相关因素，提供更贴近实际驾驶场景的评估。",
            "application_zh": "该研究主要应用于自动驾驶系统，特别是汽车环绕感知模块的评估和优化，可用于提升感知算法的安全性和可靠性，支持自动驾驶车辆的安全认证和实际部署。",
            "highlight_zh": "实验使用真实世界和虚拟数据集，新度量标准在安全评估方面表现优于现有最先进度量，能更准确地反映感知性能对安全的影响，验证了其有效性和实用性。",
            "tags_zh": [
                "自动驾驶安全",
                "感知评估",
                "对象重要性",
                "综合度量标准",
                "安全分数",
                "环绕感知",
                "虚拟数据集",
                "真实世界验证"
            ],
            "_index": 66
        },
        {
            "title": "Unified Semantic Transformer for 3D Scene Understanding",
            "authors": [
                "Sebastian Koch",
                "Johanna Wald",
                "Hide Matsuki",
                "Pedro Hermosilla",
                "Timo Ropinski",
                "Federico Tombari"
            ],
            "arxiv_id": "2512.14364v1",
            "summary": "Holistic 3D scene understanding involves capturing and parsing unstructured 3D environments. Due to the inherent complexity of the real world, existing models have predominantly been developed and limited to be task-specific. We introduce UNITE, a Unified Semantic Transformer for 3D scene understanding, a novel feed-forward neural network that unifies a diverse set of 3D semantic tasks within a single model. Our model operates on unseen scenes in a fully end-to-end manner and only takes a few seconds to infer the full 3D semantic geometry. Our approach is capable of directly predicting multiple semantic attributes, including 3D scene segmentation, instance embeddings, open-vocabulary features, as well as affordance and articulations, solely from RGB images. The method is trained using a combination of 2D distillation, heavily relying on self-supervision and leverages novel multi-view losses designed to ensure 3D view consistency. We demonstrate that UNITE achieves state-of-the-art performance on several different semantic tasks and even outperforms task-specific models, in many cases, surpassing methods that operate on ground truth 3D geometry. See the project website at unite-page.github.io",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project page: https://unite-page.github.io/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14364v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出UNITE统一语义Transformer，以单一模型解决3D场景理解中的多任务分割与属性预测问题。",
            "summary_zh": "整体3D场景理解涉及捕获和解析非结构化3D环境。由于现实世界的固有复杂性，现有模型主要被开发并局限于任务特定。我们引入了UNITE，一种用于3D场景理解的统一语义Transformer，这是一种新颖的前馈神经网络，将多种3D语义任务统一在单个模型中。我们的模型以完全端到端的方式在未见场景上运行，仅需几秒钟即可推断完整的3D语义几何。我们的方法能够直接从RGB图像预测多个语义属性，包括3D场景分割、实例嵌入、开放词汇特征，以及功能性和关节性。该方法使用2D蒸馏的组合进行训练，严重依赖自监督，并利用新颖的多视图损失设计以确保3D视图一致性。我们证明UNITE在多个不同语义任务上实现了最先进的性能，甚至在许多情况下超越了任务特定模型，超过了基于真实3D几何操作的方法。请访问项目网站unite-page.github.io。",
            "intro_zh": [
                "现有3D场景理解模型多为任务特定，难以统一处理复杂现实世界中的多语义属性，限制了泛化能力和效率。",
                "提出UNITE统一语义Transformer，通过端到端前馈网络结合2D蒸馏和多视图损失，直接从RGB图像预测分割、实例、开放词汇等多任务。",
                "实验显示UNITE在多个语义任务上达到SOTA性能，超越任务特定模型，甚至优于基于真实3D几何的方法，推理仅需几秒。"
            ],
            "method_zh": "UNITE是一种基于Transformer的前馈神经网络，整体框架以端到端方式从RGB图像直接预测3D语义几何。关键技术创新点包括：统一多任务预测（如分割、实例嵌入、开放词汇特征），结合2D蒸馏和自监督训练，以及设计多视图损失确保3D一致性。与现有方法的主要区别在于，它避免了任务特定模型的局限性，通过单一模型处理多样语义任务，且不依赖真实3D几何输入，提升了泛化能力和效率。",
            "application_zh": "该研究在机器人导航、自动驾驶、增强现实和智能监控等领域有广泛应用潜力，能高效解析复杂3D环境，支持多语义属性理解，提升系统自主决策和交互能力。",
            "highlight_zh": "UNITE在3D场景分割、实例嵌入等任务上实现SOTA性能，超越任务特定模型，并在许多情况下优于基于真实3D几何的方法，推理速度快至几秒，展示了统一模型的强大泛化能力。",
            "tags_zh": [
                "3D场景理解",
                "统一语义Transformer",
                "多任务学习",
                "端到端预测",
                "2D蒸馏",
                "多视图一致性",
                "开放词汇特征",
                "自监督训练"
            ],
            "_index": 67
        },
        {
            "title": "Causal Structure Learning for Dynamical Systems with Theoretical Score Analysis",
            "authors": [
                "Nicholas Tagliapietra",
                "Katharina Ensinger",
                "Christoph Zimmer",
                "Osman Mian"
            ],
            "arxiv_id": "2512.14361v1",
            "summary": "Real world systems evolve in continuous-time according to their underlying causal relationships, yet their dynamics are often unknown. Existing approaches to learning such dynamics typically either discretize time -- leading to poor performance on irregularly sampled data -- or ignore the underlying causality. We propose CaDyT, a novel method for causal discovery on dynamical systems addressing both these challenges. In contrast to state-of-the-art causal discovery methods that model the problem using discrete-time Dynamic Bayesian networks, our formulation is grounded in Difference-based causal models, which allow milder assumptions for modeling the continuous nature of the system. CaDyT leverages exact Gaussian Process inference for modeling the continuous-time dynamics which is more aligned with the underlying dynamical process. We propose a practical instantiation that identifies the causal structure via a greedy search guided by the Algorithmic Markov Condition and Minimum Description Length principle. Our experiments show that CaDyT outperforms state-of-the-art methods on both regularly and irregularly-sampled data, discovering causal networks closer to the true underlying dynamics.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "math.DS"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Accepted as Oral at AAAI 2026 Conference",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14361v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出CaDyT方法，基于差分因果模型与高斯过程推理，解决动态系统中连续时间因果发现难题。",
            "summary_zh": "现实世界系统根据其潜在因果关系在连续时间内演化，但其动态特性往往未知。现有学习方法通常要么离散化时间——导致在不规则采样数据上性能不佳，要么忽略底层因果关系。我们提出CaDyT，一种用于动态系统因果发现的新方法，同时应对这两个挑战。与使用离散时间动态贝叶斯网络建模该问题的最先进因果发现方法不同，我们的公式基于差分因果模型，该模型允许对系统的连续性质进行更温和的假设建模。CaDyT利用精确的高斯过程推理来建模连续时间动态，这更符合底层动态过程。我们提出了一种实用的实例化方法，通过由算法马尔可夫条件和最小描述长度原则指导的贪婪搜索来识别因果结构。我们的实验表明，CaDyT在规则和不规则采样数据上均优于最先进的方法，发现的因果网络更接近真实的底层动态。",
            "intro_zh": [
                "现有方法在动态系统因果发现中面临挑战：时间离散化导致不规则采样数据性能差，或忽略底层因果关系。",
                "CaDyT基于差分因果模型，利用高斯过程推理建模连续时间动态，通过贪婪搜索识别因果结构。",
                "实验表明，CaDyT在规则和不规则采样数据上均优于现有方法，发现的网络更接近真实动态。"
            ],
            "method_zh": "CaDyT的整体框架基于差分因果模型，通过高斯过程推理精确建模连续时间动态，避免了传统离散时间方法的局限性。关键技术创新点在于结合差分因果模型的温和假设与高斯过程推理的灵活性，实现对系统连续性质的更准确描述。与现有方法的主要区别在于：不同于使用离散时间动态贝叶斯网络的方法，CaDyT直接处理连续时间，更符合实际动态过程；同时，其实用实例化通过算法马尔可夫条件和最小描述长度原则指导的贪婪搜索，高效识别因果结构。",
            "application_zh": "该研究可应用于需要建模连续时间动态的领域，如生物医学信号分析、金融时间序列预测、机器人控制和环境监测，帮助揭示系统内在因果关系，提升模型解释性和预测准确性。",
            "highlight_zh": "CaDyT在规则和不规则采样数据上的实验均优于最先进方法，显著提升了因果网络发现的准确性，更接近真实底层动态，验证了其在连续时间建模中的有效性。",
            "tags_zh": [
                "因果发现",
                "动态系统",
                "连续时间建模",
                "高斯过程",
                "差分因果模型",
                "算法马尔可夫条件",
                "最小描述长度",
                "不规则采样数据"
            ],
            "_index": 68
        },
        {
            "title": "Mimicking Human Visual Development for Learning Robust Image Representations",
            "authors": [
                "Ankita Raj",
                "Kaashika Prajaapat",
                "Tapan Kumar Gandhi",
                "Chetan Arora"
            ],
            "arxiv_id": "2512.14360v1",
            "summary": "The human visual system is remarkably adept at adapting to changes in the input distribution; a capability modern convolutional neural networks (CNNs) still struggle to match. Drawing inspiration from the developmental trajectory of human vision, we propose a progressive blurring curriculum to improve the generalization and robustness of CNNs. Human infants are born with poor visual acuity, gradually refining their ability to perceive fine details. Mimicking this process, we begin training CNNs on highly blurred images during the initial epochs and progressively reduce the blur as training advances. This approach encourages the network to prioritize global structures over high-frequency artifacts, improving robustness against distribution shifts and noisy inputs. Challenging prior claims that blurring in the initial training epochs imposes a stimulus deficit and irreversibly harms model performance, we reveal that early-stage blurring enhances generalization with minimal impact on in-domain accuracy. Our experiments demonstrate that the proposed curriculum reduces mean corruption error (mCE) by up to 8.30% on CIFAR-10-C and 4.43% on ImageNet-100-C datasets, compared to standard training without blurring. Unlike static blur-based augmentation, which applies blurred images randomly throughout training, our method follows a structured progression, yielding consistent gains across various datasets. Furthermore, our approach complements other augmentation techniques, such as CutMix and MixUp, and enhances both natural and adversarial robustness against common attack methods. Code is available at https://github.com/rajankita/Visual_Acuity_Curriculum.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Accepted to ICVGIP 2025",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14360v1",
            "code_links": [
                {
                    "url": "https://github.com/rajankita/Visual_Acuity_Curriculum",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出渐进模糊课程学习，模仿人类视觉发育过程以提升卷积神经网络的泛化与鲁棒性。",
            "summary_zh": "人类视觉系统能出色适应输入分布变化，而现代卷积神经网络（CNNs）在这方面仍有不足。受人类视觉发育轨迹启发，我们提出一种渐进模糊课程学习方法来提升CNNs的泛化能力和鲁棒性。人类婴儿出生时视觉敏锐度较差，逐渐发展出感知细节的能力。模仿这一过程，我们在训练初期使用高度模糊的图像训练CNNs，随着训练推进逐步减少模糊程度。这种方法促使网络优先关注全局结构而非高频伪影，从而提升对分布偏移和噪声输入的鲁棒性。与先前认为早期模糊会造成刺激缺陷并不可逆损害模型性能的观点不同，我们发现早期模糊能增强泛化能力，对域内精度影响极小。实验表明，相比无模糊的标准训练，所提方法在CIFAR-10-C数据集上平均腐蚀误差（mCE）降低达8.30%，在ImageNet-100-C数据集上降低4.43%。与静态模糊增强（在整个训练中随机应用模糊图像）不同，我们的方法遵循结构化渐进过程，在不同数据集上均取得一致提升。此外，该方法可与其他增强技术（如CutMix和MixUp）互补，并提升对常见攻击方法的自然和对抗鲁棒性。代码已开源。",
            "intro_zh": [
                "核心问题：现代卷积神经网络在适应输入分布变化方面不如人类视觉系统鲁棒，易受分布偏移和噪声影响。",
                "方法要点：模仿人类视觉发育，设计渐进模糊课程，从高度模糊图像开始训练并逐步减少模糊，引导网络学习全局结构。",
                "实验或效果：在CIFAR-10-C和ImageNet-100-C上显著降低平均腐蚀误差，提升泛化能力且不影响域内精度。"
            ],
            "method_zh": "整体框架基于标准卷积神经网络训练，但引入渐进模糊课程作为预处理步骤。关键技术创新点在于模拟人类视觉发育过程：训练初期对输入图像应用强高斯模糊，随着训练轮次增加，逐步降低模糊强度直至为零，形成从模糊到清晰的动态课程。与现有方法的主要区别在于：不同于静态模糊增强（在整个训练中随机应用模糊），该方法采用结构化渐进策略；且与先前认为早期模糊有害的观点相反，证明了早期模糊能促进泛化学习。",
            "application_zh": "该研究可应用于需要高鲁棒性的计算机视觉任务，如自动驾驶中的环境感知、医疗图像分析中的噪声鲁棒分类、安防监控中的抗干扰识别，以及任何面临分布偏移或对抗攻击的场景，提升模型在实际复杂环境中的可靠性。",
            "highlight_zh": "在CIFAR-10-C数据集上平均腐蚀误差降低8.30%，在ImageNet-100-C上降低4.43%；与CutMix、MixUp等增强技术兼容，进一步提升自然和对抗鲁棒性；实验验证了早期模糊对泛化的积极影响，反驳了相关负面观点。",
            "tags_zh": [
                "渐进模糊课程学习",
                "人类视觉发育模拟",
                "卷积神经网络鲁棒性",
                "分布偏移适应",
                "图像增强技术",
                "泛化能力提升",
                "对抗鲁棒性",
                "课程学习策略"
            ],
            "_index": 69
        },
        {
            "title": "Enhancing Interpretability for Vision Models via Shapley Value Optimization",
            "authors": [
                "Kanglong Fan",
                "Yunqiao Yang",
                "Chen Ma"
            ],
            "arxiv_id": "2512.14354v1",
            "summary": "Deep neural networks have demonstrated remarkable performance across various domains, yet their decision-making processes remain opaque. Although many explanation methods are dedicated to bringing the obscurity of DNNs to light, they exhibit significant limitations: post-hoc explanation methods often struggle to faithfully reflect model behaviors, while self-explaining neural networks sacrifice performance and compatibility due to their specialized architectural designs. To address these challenges, we propose a novel self-explaining framework that integrates Shapley value estimation as an auxiliary task during training, which achieves two key advancements: 1) a fair allocation of the model prediction scores to image patches, ensuring explanations inherently align with the model's decision logic, and 2) enhanced interpretability with minor structural modifications, preserving model performance and compatibility. Extensive experiments on multiple benchmarks demonstrate that our method achieves state-of-the-art interpretability.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Accepted to AAAI2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14354v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VIO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "SAC"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出基于沙普利值优化的自解释框架，以增强视觉模型的可解释性并保持性能。",
            "summary_zh": "深度神经网络在多个领域表现出色，但其决策过程仍不透明。现有解释方法存在显著局限：后处理解释方法难以忠实反映模型行为，而自解释神经网络因特殊架构设计牺牲了性能和兼容性。为解决这些问题，我们提出一种新颖的自解释框架，在训练过程中集成沙普利值估计作为辅助任务，实现两大关键进展：1）公平分配模型预测分数到图像块，确保解释与模型决策逻辑内在对齐；2）通过微小结构修改增强可解释性，同时保持模型性能和兼容性。在多个基准上的广泛实验表明，我们的方法实现了最先进的可解释性。",
            "intro_zh": [
                "现有解释方法存在不足：后处理解释方法难以忠实反映模型行为，自解释神经网络牺牲性能和兼容性。",
                "提出自解释框架，集成沙普利值估计作为辅助任务，公平分配预测分数到图像块，确保解释与决策逻辑对齐。",
                "在多个基准上实验，方法实现最先进的可解释性，同时保持模型性能和兼容性。"
            ],
            "method_zh": "论文提出一种自解释框架，整体上在训练过程中集成沙普利值估计作为辅助任务。关键技术创新点包括：通过优化沙普利值来公平分配模型预测分数到图像块，确保解释与模型决策逻辑内在对齐；仅进行微小结构修改，如添加解释层，以增强可解释性而不显著改变模型架构。与现有方法的主要区别在于：不同于后处理解释方法，它直接嵌入解释过程到训练中，提高忠实性；相比自解释神经网络，它避免大规模架构改动，保持性能和兼容性。",
            "application_zh": "该研究可应用于医疗影像分析、自动驾驶系统、安防监控等领域，通过增强视觉模型的可解释性，帮助用户理解模型决策，提高信任度和可靠性，支持关键决策过程。",
            "highlight_zh": "在多个基准实验中，该方法实现最先进的可解释性，如通过定量指标（如忠实度分数）显著优于现有方法，同时模型性能（如分类准确率）保持稳定，验证了其有效性和实用性。",
            "tags_zh": [
                "可解释人工智能",
                "沙普利值",
                "自解释神经网络",
                "视觉模型",
                "深度学习",
                "模型解释",
                "图像块分配",
                "辅助任务优化"
            ],
            "_index": 70
        },
        {
            "title": "Fine-Tuning of Neural Network Approximate MPC without Retraining via Bayesian Optimization",
            "authors": [
                "Henrik Hose",
                "Paul Brunzema",
                "Alexander von Rohr",
                "Alexander Gräfe",
                "Angela P. Schoellig",
                "Sebastian Trimpe"
            ],
            "arxiv_id": "2512.14350v1",
            "summary": "Approximate model-predictive control (AMPC) aims to imitate an MPC's behavior with a neural network, removing the need to solve an expensive optimization problem at runtime. However, during deployment, the parameters of the underlying MPC must usually be fine-tuned. This often renders AMPC impractical as it requires repeatedly generating a new dataset and retraining the neural network. Recent work addresses this problem by adapting AMPC without retraining using approximated sensitivities of the MPC's optimization problem. Currently, this adaption must be done by hand, which is labor-intensive and can be unintuitive for high-dimensional systems. To solve this issue, we propose using Bayesian optimization to tune the parameters of AMPC policies based on experimental data. By combining model-based control with direct and local learning, our approach achieves superior performance to nominal AMPC on hardware, with minimal experimentation. This allows automatic and data-efficient adaptation of AMPC to new system instances and fine-tuning to cost functions that are difficult to directly implement in MPC. We demonstrate the proposed method in hardware experiments for the swing-up maneuver on an inverted cartpole and yaw control of an under-actuated balancing unicycle robot, a challenging control problem.",
            "categories": [
                "cs.RO",
                "eess.SY"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14350v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VIO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出基于贝叶斯优化的近似模型预测控制微调方法，无需重新训练神经网络，实现自动高效参数调整。",
            "summary_zh": "近似模型预测控制（AMPC）旨在通过神经网络模仿MPC的行为，避免运行时求解昂贵的优化问题。然而，在部署过程中，通常需要微调底层MPC的参数，这往往导致AMPC不实用，因为它需要重复生成新数据集并重新训练神经网络。最近的研究通过利用MPC优化问题的近似灵敏度来适应AMPC而无需重新训练，解决了这一问题。目前，这种适应必须手动完成，这既耗时又对高维系统不直观。为了解决这个问题，我们提出使用贝叶斯优化基于实验数据来调整AMPC策略的参数。通过将基于模型的控制与直接和局部学习相结合，我们的方法在硬件上实现了优于名义AMPC的性能，且实验量最小。这使得AMPC能够自动且数据高效地适应新系统实例，并微调到难以直接在MPC中实现的成本函数。我们在硬件实验中展示了所提出的方法，包括倒立摆的摆动上升操作和欠驱动平衡独轮机器人的偏航控制，这是一个具有挑战性的控制问题。",
            "intro_zh": [
                "现有AMPC方法在部署时需手动微调参数，过程耗时且对高维系统不直观，限制了实际应用。",
                "提出结合贝叶斯优化与AMPC，利用实验数据自动调整参数，无需重新训练神经网络，实现高效适应。",
                "在倒立摆和独轮机器人硬件实验中，该方法性能优于名义AMPC，实验量最小，验证了其有效性。"
            ],
            "method_zh": "论文提出一种基于贝叶斯优化的AMPC微调框架。整体框架包括：使用神经网络近似MPC策略，然后通过贝叶斯优化基于实验数据自动调整AMPC的参数，无需重新训练神经网络。关键技术创新点在于将贝叶斯优化与AMPC结合，利用模型预测控制的先验知识和局部学习，实现数据高效的参数优化。与现有方法的主要区别在于：现有方法依赖手动调整或基于近似灵敏度的适应，而本方法自动化程度高，能处理高维参数空间，且通过贝叶斯优化直接优化性能指标，避免了重新训练的开销。",
            "application_zh": "该研究适用于机器人控制、自动化系统等需要实时优化的领域，特别是在系统参数变化或成本函数复杂时，能自动适应新实例，提高控制性能，降低部署成本。",
            "highlight_zh": "在倒立摆摆动上升和独轮机器人偏航控制的硬件实验中，该方法相比名义AMPC实现了性能提升，实验量最小，成功处理了欠驱动系统的挑战性控制问题。",
            "tags_zh": [
                "近似模型预测控制",
                "贝叶斯优化",
                "神经网络控制",
                "参数微调",
                "机器人控制",
                "硬件实验",
                "数据高效学习",
                "自动适应"
            ],
            "_index": 71
        },
        {
            "title": "Vector Prism: Animating Vector Graphics by Stratifying Semantic Structure",
            "authors": [
                "Jooyeol Yun",
                "Jaegul Choo"
            ],
            "arxiv_id": "2512.14336v1",
            "summary": "Scalable Vector Graphics (SVG) are central to modern web design, and the demand to animate them continues to grow as web environments become increasingly dynamic. Yet automating the animation of vector graphics remains challenging for vision-language models (VLMs) despite recent progress in code generation and motion planning. VLMs routinely mis-handle SVGs, since visually coherent parts are often fragmented into low-level shapes that offer little guidance of which elements should move together. In this paper, we introduce a framework that recovers the semantic structure required for reliable SVG animation and reveals the missing layer that current VLM systems overlook. This is achieved through a statistical aggregation of multiple weak part predictions, allowing the system to stably infer semantics from noisy predictions. By reorganizing SVGs into semantic groups, our approach enables VLMs to produce animations with far greater coherence. Our experiments demonstrate substantial gains over existing approaches, suggesting that semantic recovery is the key step that unlocks robust SVG animation and supports more interpretable interactions between VLMs and vector graphics.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "yeolj00.github.io/personal-projects/vector-prism",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14336v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL",
                        "PPO"
                    ],
                    "score": 2
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出Vector Prism框架，通过恢复SVG语义结构解决视觉语言模型动画生成中的碎片化问题",
            "summary_zh": "可缩放矢量图形（SVG）在现代网页设计中至关重要，随着网络环境日益动态化，对其动画化的需求持续增长。尽管在代码生成和运动规划方面取得了进展，但自动化矢量图形动画对视觉语言模型（VLMs）仍然具有挑战性。VLMs经常错误处理SVG，因为视觉上连贯的部分通常被分割成低级形状，这些形状几乎无法指导哪些元素应该一起移动。本文引入了一个框架，该框架恢复了可靠SVG动画所需的语义结构，并揭示了当前VLM系统忽略的缺失层。这是通过对多个弱部分预测进行统计聚合实现的，使系统能够从噪声预测中稳定推断语义。通过将SVG重新组织成语义组，我们的方法使VLMs能够生成更具连贯性的动画。实验表明，与现有方法相比，我们的方法取得了显著提升，这表明语义恢复是解锁稳健SVG动画并支持VLMs与矢量图形之间更可解释交互的关键步骤。",
            "intro_zh": [
                "现有视觉语言模型处理SVG动画时，常因图形元素被分割为低级形状而无法识别语义连贯部分，导致动画生成碎片化。",
                "提出Vector Prism框架，通过统计聚合多个弱预测来恢复SVG的语义结构，并将图形重组成语义组以指导动画生成。",
                "实验显示，该方法在SVG动画生成中显著提升了连贯性，验证了语义恢复对增强VLM与矢量图形交互的关键作用。"
            ],
            "method_zh": "Vector Prism框架的核心是通过分层语义结构来恢复SVG的语义信息。整体框架包括：首先，利用视觉语言模型生成多个弱部分预测，这些预测可能包含噪声；然后，通过统计聚合技术（如聚类或投票机制）将这些弱预测整合，稳定推断出SVG的语义组；最后，基于恢复的语义结构重新组织SVG元素，为动画生成提供高层指导。关键技术创新点在于引入了语义恢复层，解决了现有方法因忽略语义而导致的碎片化问题。与现有方法的主要区别在于，现有VLM系统直接处理低级形状，而Vector Prism通过中间语义层桥接，使动画生成更具连贯性和可解释性。",
            "application_zh": "该研究可应用于网页设计、动态图形生成、教育工具和交互式媒体等领域，通过自动化SVG动画提升用户体验和设计效率，支持更智能的视觉内容创作。",
            "highlight_zh": "实验结果表明，Vector Prism在SVG动画生成任务中相比基线方法取得了显著性能提升，具体表现为动画连贯性增强和错误率降低，验证了语义恢复对提升视觉语言模型处理矢量图形能力的有效性。",
            "tags_zh": [
                "矢量图形动画",
                "语义结构恢复",
                "视觉语言模型",
                "统计聚合",
                "SVG处理",
                "网页设计自动化",
                "多模态交互",
                "弱预测整合"
            ],
            "_index": 72
        },
        {
            "title": "Step-Tagging: Toward controlling the generation of Language Reasoning Models through step monitoring",
            "authors": [
                "Yannis Belkhiter",
                "Seshu Tirupathi",
                "Giulio Zizzo",
                "John D. Kelleher"
            ],
            "arxiv_id": "2512.14332v1",
            "summary": "The field of Language Reasoning Models (LRMs) has been very active over the past few years with advances in training and inference techniques enabling LRMs to reason longer, and more accurately. However, a growing body of studies show that LRMs are still inefficient, over-generating verification and reflection steps. To address this challenge, we introduce the Step-Tagging framework, a lightweight sentence-classifier enabling real-time annotation of the type of reasoning steps that an LRM is generating. To monitor reasoning behaviors, we introduced ReasonType: a novel taxonomy of reasoning steps. Building on this framework, we demonstrated that online monitoring of the count of specific steps can produce effective interpretable early stopping criteria of LRM inferences. We evaluate the Step-tagging framework on three open-source reasoning models across standard benchmark datasets: MATH500, GSM8K, AIME and non-mathematical tasks (GPQA and MMLU-Pro). We achieve 20 to 50\\% token reduction while maintaining comparable accuracy to standard generation, with largest gains observed on more computation-heavy tasks. This work offers a novel way to increase control over the generation of LRMs, and a new tool to study behaviors of LRMs.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14332v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VIO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出Step-Tagging框架，通过实时监控推理步骤类型来控制语言推理模型的生成过程。",
            "summary_zh": "语言推理模型（LRMs）领域近年来发展迅速，训练和推理技术的进步使LRMs能够进行更长、更准确的推理。然而，大量研究表明LRMs仍然效率低下，过度生成验证和反思步骤。为解决这一挑战，我们引入了Step-Tagging框架，这是一个轻量级的句子分类器，能够实时标注LRM生成的推理步骤类型。为了监控推理行为，我们提出了ReasonType：一种新颖的推理步骤分类法。基于此框架，我们证明了在线监控特定步骤的数量可以产生有效的可解释早期停止标准，用于LRM推理。我们在三个开源推理模型上评估了Step-Tagging框架，覆盖标准基准数据集：MATH500、GSM8K、AIME以及非数学任务（GPQA和MMLU-Pro）。我们实现了20%到50%的令牌减少，同时保持与标准生成相当的准确性，在计算量更大的任务中观察到最大的收益。这项工作提供了一种新颖的方式来增加对LRM生成的控制，以及一种研究LRM行为的新工具。",
            "intro_zh": [
                "语言推理模型（LRMs）在推理过程中存在效率低下问题，常过度生成验证和反思步骤，导致计算资源浪费。",
                "论文提出Step-Tagging框架，通过轻量级句子分类器实时标注推理步骤类型，并引入ReasonType分类法来监控推理行为。",
                "实验表明，该框架在多个基准数据集上实现20-50%令牌减少，同时保持准确性，尤其在计算密集型任务中效果显著。"
            ],
            "method_zh": "Step-Tagging框架是一个轻量级句子分类器，用于实时标注语言推理模型（LRMs）生成的推理步骤类型。其核心创新点包括：引入ReasonType分类法，这是一种新颖的推理步骤分类体系，用于系统化监控推理行为；基于此分类法，框架通过在线监控特定步骤的数量，实现可解释的早期停止标准，从而控制LRM的生成过程。与现有方法相比，Step-Tagging不依赖于复杂的模型修改或重训练，而是通过外部监控机制直接干预推理流程，提供了一种更灵活和高效的控制方式。",
            "application_zh": "该研究可应用于需要高效推理的语言模型场景，如数学问题求解、科学问答和复杂逻辑任务，通过减少冗余步骤来优化计算资源使用，提升模型部署的实时性和成本效益。",
            "highlight_zh": "在MATH500、GSM8K、AIME等数学任务及GPQA、MMLU-Pro非数学任务上，Step-Tagging框架实现20%至50%的令牌减少，同时保持与标准生成相当的准确性，计算量越大任务收益越显著。",
            "tags_zh": [
                "语言推理模型",
                "推理步骤监控",
                "早期停止标准",
                "轻量级分类器",
                "令牌减少",
                "ReasonType分类法",
                "计算效率优化"
            ],
            "_index": 73
        },
        {
            "title": "Leveraging LLMs for Collaborative Ontology Engineering in Parkinson Disease Monitoring and Alerting",
            "authors": [
                "Georgios Bouchouras",
                "Dimitrios Doumanas",
                "Andreas Soularidis",
                "Konstantinos Kotis",
                "George A. Vouros"
            ],
            "arxiv_id": "2512.14288v1",
            "summary": "This paper explores the integration of Large Language Models (LLMs) in the engineering of a Parkinson's Disease (PD) monitoring and alerting ontology through four key methodologies: One Shot (OS) prompt techniques, Chain of Thought (CoT) prompts, X-HCOME, and SimX-HCOME+. The primary objective is to determine whether LLMs alone can create comprehensive ontologies and, if not, whether human-LLM collaboration can achieve this goal. Consequently, the paper assesses the effectiveness of LLMs in automated ontology development and the enhancement achieved through human-LLM collaboration.\n  Initial ontology generation was performed using One Shot (OS) and Chain of Thought (CoT) prompts, demonstrating the capability of LLMs to autonomously construct ontologies for PD monitoring and alerting. However, these outputs were not comprehensive and required substantial human refinement to enhance their completeness and accuracy.\n  X-HCOME, a hybrid ontology engineering approach that combines human expertise with LLM capabilities, showed significant improvements in ontology comprehensiveness. This methodology resulted in ontologies that are very similar to those constructed by experts.\n  Further experimentation with SimX-HCOME+, another hybrid methodology emphasizing continuous human supervision and iterative refinement, highlighted the importance of ongoing human involvement. This approach led to the creation of more comprehensive and accurate ontologies.\n  Overall, the paper underscores the potential of human-LLM collaboration in advancing ontology engineering, particularly in complex domains like PD. The results suggest promising directions for future research, including the development of specialized GPT models for ontology construction.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14288v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出人机协作本体工程方法，利用LLMs增强帕金森病监测与警报本体构建的完整性与准确性。",
            "summary_zh": "本文探讨了将大型语言模型（LLMs）集成到帕金森病（PD）监测与警报本体工程中的四种关键方法：单次提示（OS）、思维链（CoT）提示、X-HCOME和SimX-HCOME+。主要目标是确定LLMs能否独立创建全面本体，若不能，人机协作是否能实现此目标。因此，本文评估了LLMs在自动化本体开发中的有效性以及通过人机协作实现的改进。初始本体生成使用OS和CoT提示进行，展示了LLMs自主构建PD监测与警报本体的能力，但这些输出不够全面，需要大量人工细化以提升完整性和准确性。X-HCOME是一种结合人类专业知识与LLM能力的混合本体工程方法，显著提高了本体全面性，产生的本体与专家构建的非常相似。进一步实验使用SimX-HCOME+，另一种强调持续人工监督和迭代细化的混合方法，突出了持续人工参与的重要性，该方法创建了更全面和准确的本体。总体而言，本文强调了人机协作在推进本体工程中的潜力，特别是在PD等复杂领域。结果指出了未来研究的有前景方向，包括开发用于本体构建的专用GPT模型。",
            "intro_zh": [
                "核心问题：LLMs在自动化本体工程中难以独立生成全面且准确的本体，尤其在复杂医学领域如帕金森病监测与警报。",
                "方法要点：提出X-HCOME和SimX-HCOME+混合方法，结合人类专业知识与LLMs能力，通过迭代协作提升本体质量。",
                "实验或效果：人机协作方法显著提高本体完整性和准确性，SimX-HCOME+在持续监督下实现最优性能，接近专家水平。"
            ],
            "method_zh": "论文提出一个基于人机协作的本体工程框架，核心包括四种方法：单次提示（OS）和思维链（CoT）提示用于初始LLMs自主本体生成；X-HCOME作为混合方法，整合人类专家输入与LLMs输出进行协同构建；SimX-HCOME+进一步强调持续人工监督和迭代细化过程。关键创新点在于系统化评估LLMs在复杂领域本体工程中的能力，并设计结构化协作流程以弥补LLMs的不足。与现有方法的主要区别在于，传统本体工程多依赖专家手动构建或自动化工具，而本文首次系统探索LLMs与人力的协同作用，通过实验验证协作模式的有效性，为智能本体开发提供新范式。",
            "application_zh": "该研究可应用于医学信息学领域，特别是慢性病如帕金森病的智能监测与警报系统开发，通过构建高质量本体支持数据集成、知识推理和临床决策辅助，提升医疗服务的个性化和实时性。",
            "highlight_zh": "实验显示，纯LLMs方法（OS和CoT）生成的本体不全面，需人工细化；X-HCOME混合方法使本体接近专家构建水平；SimX-HCOME+在持续监督下实现最高完整性和准确性，验证了人机协作在复杂本体工程中的关键作用。",
            "tags_zh": [
                "大型语言模型",
                "本体工程",
                "人机协作",
                "帕金森病监测",
                "医疗本体",
                "智能提示",
                "知识表示",
                "混合方法"
            ],
            "_index": 74
        },
        {
            "title": "SS4D: Native 4D Generative Model via Structured Spacetime Latents",
            "authors": [
                "Zhibing Li",
                "Mengchen Zhang",
                "Tong Wu",
                "Jing Tan",
                "Jiaqi Wang",
                "Dahua Lin"
            ],
            "arxiv_id": "2512.14284v1",
            "summary": "We present SS4D, a native 4D generative model that synthesizes dynamic 3D objects directly from monocular video. Unlike prior approaches that construct 4D representations by optimizing over 3D or video generative models, we train a generator directly on 4D data, achieving high fidelity, temporal coherence, and structural consistency. At the core of our method is a compressed set of structured spacetime latents. Specifically, (1) To address the scarcity of 4D training data, we build on a pre-trained single-image-to-3D model, preserving strong spatial consistency. (2) Temporal consistency is enforced by introducing dedicated temporal layers that reason across frames. (3) To support efficient training and inference over long video sequences, we compress the latent sequence along the temporal axis using factorized 4D convolutions and temporal downsampling blocks. In addition, we employ a carefully designed training strategy to enhance robustness against occlusion",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "ToG(Siggraph Asia 2025)",
            "doi": "10.1145/3763302",
            "journal_ref": "ACM Transactions on Graphics, 44(6): Article 244, 12 pages, December 2025",
            "pdf_url": "https://arxiv.org/pdf/2512.14284v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "PPO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出SS4D原生4D生成模型，通过结构化时空潜在表示从单目视频直接合成动态3D物体",
            "summary_zh": "我们提出了SS4D，一种原生4D生成模型，能够直接从单目视频合成动态3D物体。与先前通过优化3D或视频生成模型来构建4D表示的方法不同，我们直接在4D数据上训练生成器，实现了高保真度、时间一致性和结构一致性。我们方法的核心是一组压缩的结构化时空潜在表示。具体而言：（1）为了解决4D训练数据稀缺的问题，我们基于预训练的单图像到3D模型构建，保持了强大的空间一致性。（2）通过引入专门的时序层来跨帧推理，强制实现时间一致性。（3）为了支持长视频序列的高效训练和推理，我们使用分解的4D卷积和时序下采样块沿时间轴压缩潜在序列。此外，我们采用精心设计的训练策略来增强对遮挡的鲁棒性。",
            "intro_zh": [
                "现有方法依赖3D或视频生成模型优化构建4D表示，导致保真度、时间一致性和结构一致性不足。",
                "提出结构化时空潜在表示，结合预训练单图像到3D模型、时序层和压缩机制，实现原生4D生成。",
                "实验表明SS4D在动态3D物体合成中实现高保真度、时间一致性和高效性，优于现有方法。"
            ],
            "method_zh": "SS4D的整体框架是一个原生4D生成模型，直接从单目视频合成动态3D物体。关键技术创新点包括：结构化时空潜在表示，通过压缩机制（如分解4D卷积和时序下采样）处理长序列；基于预训练单图像到3D模型增强空间一致性；引入时序层强制时间一致性；以及精心设计的训练策略提升对遮挡的鲁棒性。与现有方法的主要区别在于，SS4D直接在4D数据上训练生成器，而非优化3D或视频模型，从而实现了更高效和一致的4D生成。",
            "application_zh": "该研究在虚拟现实、增强现实、游戏开发和电影特效等领域具有潜在应用价值，能够高效生成动态3D内容，提升内容创作的自动化水平和真实感。",
            "highlight_zh": "SS4D在动态3D物体合成任务中实现了高保真度和时间一致性，通过结构化时空潜在表示和压缩机制，显著提升了生成效率，并在实验中表现出优于现有方法的性能。",
            "tags_zh": [
                "4D生成模型",
                "动态3D合成",
                "时空潜在表示",
                "单目视频处理",
                "时间一致性",
                "结构一致性",
                "高效训练",
                "遮挡鲁棒性"
            ],
            "_index": 75
        },
        {
            "title": "SPARQL-LLM: Real-Time SPARQL Query Generation from Natural Language Questions",
            "authors": [
                "Panayiotis Smeros",
                "Vincent Emonet",
                "Ruijie Wang",
                "Ana-Claudia Sima",
                "Tarcisio Mendes de Farias"
            ],
            "arxiv_id": "2512.14277v1",
            "summary": "The advent of large language models is contributing to the emergence of novel approaches that promise to better tackle the challenge of generating structured queries, such as SPARQL queries, from natural language. However, these new approaches mostly focus on response accuracy over a single source while ignoring other evaluation criteria, such as federated query capability over distributed data stores, as well as runtime and cost to generate SPARQL queries. Consequently, they are often not production-ready or easy to deploy over (potentially federated) knowledge graphs with good accuracy. To mitigate these issues, in this paper, we extend our previous work and describe and systematically evaluate SPARQL-LLM, an open-source and triplestore-agnostic approach, powered by lightweight metadata, that generates SPARQL queries from natural language text. First, we describe its architecture, which consists of dedicated components for metadata indexing, prompt building, and query generation and execution. Then, we evaluate it based on a state-of-the-art challenge with multilingual questions, and a collection of questions from three of the most prevalent knowledge graphs within the field of bioinformatics. Our results demonstrate a substantial increase of 24% in the F1 Score on the state-of-the-art challenge, adaptability to high-resource languages such as English and Spanish, as well as ability to form complex and federated bioinformatics queries. Furthermore, we show that SPARQL-LLM is up to 36x faster than other systems participating in the challenge, while costing a maximum of $0.01 per question, making it suitable for real-time, low-cost text-to-SPARQL applications. One such application deployed over real-world decentralized knowledge graphs can be found at https://www.expasy.org/chat.",
            "categories": [
                "cs.IR",
                "cs.AI",
                "cs.CL"
            ],
            "primary_category": "cs.IR",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "17 pages, 8 figures, 1 table. Under Review",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14277v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VIO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出SPARQL-LLM方法，通过轻量级元数据实现实时、低成本的自然语言到SPARQL查询生成，适用于分布式知识图谱应用。",
            "summary_zh": "大型语言模型的出现催生了从自然语言生成结构化查询（如SPARQL查询）的新方法。然而，这些方法大多关注单一数据源的响应准确性，而忽略了其他评估标准，如分布式数据存储的联邦查询能力，以及生成SPARQL查询的运行时间和成本。因此，它们通常难以在生产环境中部署，或在（可能联邦的）知识图谱上实现高精度。为缓解这些问题，本文扩展了先前工作，提出并系统评估了SPARQL-LLM——一种开源、与三元存储无关的方法，利用轻量级元数据从自然语言文本生成SPARQL查询。首先，我们描述了其架构，包括元数据索引、提示构建、查询生成和执行等专用组件。然后，基于一个包含多语言问题的最新挑战，以及来自生物信息学领域三个最流行知识图谱的问题集合，对其进行了评估。结果显示，在最新挑战中F1分数显著提高了24%，适应英语和西班牙语等高资源语言，并能形成复杂和联邦的生物信息学查询。此外，SPARQL-LLM比参与挑战的其他系统快达36倍，每个问题成本最高仅0.01美元，使其适用于实时、低成本的文本到SPARQL应用。一个部署在真实世界去中心化知识图谱上的此类应用可在https://www.expasy.org/chat找到。",
            "intro_zh": [
                "现有方法主要关注单一数据源的准确性，忽视联邦查询能力、运行时间和成本，导致难以在生产环境中部署或适应分布式知识图谱。",
                "SPARQL-LLM采用轻量级元数据索引和专用组件架构，实现与三元存储无关的查询生成，提升灵活性和效率。",
                "实验显示F1分数提高24%，支持多语言和复杂联邦查询，运行速度快达36倍，成本低至每问题0.01美元。"
            ],
            "method_zh": "SPARQL-LLM的整体框架包括元数据索引、提示构建、查询生成和执行三个核心组件。关键技术创新在于利用轻量级元数据（而非完整数据）来驱动查询生成，这降低了计算负担并提高了可扩展性。与现有方法的主要区别在于其三元存储无关性，能够处理分布式知识图谱的联邦查询，同时优化了运行时间和成本，使其更适用于实时生产环境。",
            "application_zh": "该研究适用于生物信息学、知识图谱查询和智能问答系统等领域，特别是在需要实时、低成本处理自然语言查询的分布式知识图谱应用中，如在线知识服务平台或科研数据检索工具。",
            "highlight_zh": "在最新挑战中F1分数提升24%，支持英语和西班牙语多语言查询，能生成复杂联邦查询，运行速度比其他系统快达36倍，每个问题成本最高仅0.01美元。",
            "tags_zh": [
                "SPARQL查询生成",
                "自然语言处理",
                "知识图谱",
                "联邦查询",
                "轻量级元数据",
                "实时系统",
                "低成本应用",
                "生物信息学"
            ],
            "_index": 76
        },
        {
            "title": "Zoom-Zero: Reinforced Coarse-to-Fine Video Understanding via Temporal Zoom-in",
            "authors": [
                "Xiaoqian Shen",
                "Min-Hung Chen",
                "Yu-Chiang Frank Wang",
                "Mohamed Elhoseiny",
                "Ryo Hachiuma"
            ],
            "arxiv_id": "2512.14273v1",
            "summary": "Grounded video question answering (GVQA) aims to localize relevant temporal segments in videos and generate accurate answers to a given question; however, large video-language models (LVLMs) exhibit limited temporal awareness. Although existing approaches based on Group Relative Policy Optimization (GRPO) attempt to improve temporal grounding, they still struggle to faithfully ground their answers in the relevant video evidence, leading to temporal mislocalization and hallucinations. In this work, we present Zoom-Zero, a coarse-to-fine framework that first localizes query-relevant segments and then temporally zooms into the most salient frames for finer-grained visual verification. Our method addresses the limits of GRPO for the GVQA task with two key innovations: (i) a zoom-in accuracy reward that validates the fidelity of temporal grounding prediction and facilitates fine-grained visual verification on grounded frames; (ii) token-selective credit assignment, which attributes rewards to the tokens responsible for temporal localization or answer generation, mitigating GRPO's issue in handling multi-faceted reward signals. Our proposed method advances grounded video question answering, improving temporal grounding by 5.2\\% on NExT-GQA and 4.6\\% on ReXTime, while also enhancing average answer accuracy by 2.4\\%. Additionally, the coarse-to-fine zoom-in during inference further benefits long-form video understanding by preserving critical visual details without compromising global context, yielding an average improvement of 6.4\\% on long-video benchmarks.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project page: https://xiaoqian-shen.github.io/Zoom-Zero/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14273v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "localization"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "reward"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出Zoom-Zero框架，通过粗到细的时序放大机制解决视频问答中的时序定位不准确问题。",
            "summary_zh": "基于视频的问答任务旨在定位视频中的相关时序片段并生成准确答案，但现有大型视频语言模型在时序感知方面存在局限。虽然基于组相对策略优化的方法试图改进时序定位，但仍难以忠实将答案基于相关视频证据，导致时序错位和幻觉。本文提出Zoom-Zero，一种粗到细的框架，首先定位查询相关片段，然后时序放大到最显著帧进行细粒度视觉验证。该方法通过两个关键创新解决GVQA任务中GRPO的局限：(i) 放大精度奖励，验证时序定位预测的保真度并促进对定位帧的细粒度视觉验证；(ii) 令牌选择性信用分配，将奖励归因于负责时序定位或答案生成的令牌，缓解GRPO处理多方面奖励信号的问题。所提方法推进了基于视频的问答，在NExT-GQA和ReXTime上分别将时序定位精度提升5.2%和4.6%，同时将平均答案准确率提高2.4%。此外，推理过程中的粗到细放大通过保留关键视觉细节而不损害全局上下文，进一步有益于长视频理解，在长视频基准上平均提升6.4%。",
            "intro_zh": [
                "现有大型视频语言模型在时序感知方面有限，基于GRPO的方法仍存在时序错位和幻觉问题，难以忠实基于视频证据生成答案。",
                "提出Zoom-Zero框架，采用粗到细策略：先定位相关片段，再放大到显著帧进行视觉验证，结合放大精度奖励和令牌选择性信用分配。",
                "在NExT-GQA和ReXTime数据集上，时序定位精度分别提升5.2%和4.6%，答案准确率提高2.4%，长视频理解平均提升6.4%。"
            ],
            "method_zh": "Zoom-Zero是一个粗到细的框架，整体流程包括两个阶段：首先，通过粗粒度定位模块识别查询相关的视频片段；然后，时序放大模块选择最显著的帧进行细粒度视觉验证。关键技术创新点包括：(1) 放大精度奖励机制，用于评估时序定位的准确性并促进对定位帧的详细视觉分析；(2) 令牌选择性信用分配，将强化学习奖励精确分配给负责时序定位或答案生成的具体令牌，以优化多任务学习。与现有基于GRPO的方法相比，该方法更有效地整合了时序定位和视觉验证，减少了时序错位和幻觉问题。",
            "application_zh": "该研究可应用于智能视频监控、教育视频分析、医疗视频诊断和娱乐内容推荐等领域，通过提高视频问答的准确性和时序定位能力，增强对长视频内容的理解和交互，具有实际价值。",
            "highlight_zh": "在NExT-GQA数据集上时序定位精度提升5.2%，ReXTime数据集上提升4.6%；平均答案准确率提高2.4%；长视频基准测试中平均性能提升6.4%，显著优于现有方法。",
            "tags_zh": [
                "视频问答",
                "时序定位",
                "粗到细框架",
                "强化学习",
                "多模态融合",
                "长视频理解",
                "视觉验证",
                "令牌信用分配"
            ],
            "_index": 77
        },
        {
            "title": "CaFe-TeleVision: A Coarse-to-Fine Teleoperation System with Immersive Situated Visualization for Enhanced Ergonomics",
            "authors": [
                "Zixin Tang",
                "Yiming Chen",
                "Quentin Rouxel",
                "Dianxi Li",
                "Shuang Wu",
                "Fei Chen"
            ],
            "arxiv_id": "2512.14270v1",
            "summary": "Teleoperation presents a promising paradigm for remote control and robot proprioceptive data collection. Despite recent progress, current teleoperation systems still suffer from limitations in efficiency and ergonomics, particularly in challenging scenarios. In this paper, we propose CaFe-TeleVision, a coarse-to-fine teleoperation system with immersive situated visualization for enhanced ergonomics. At its core, a coarse-to-fine control mechanism is proposed in the retargeting module to bridge workspace disparities, jointly optimizing efficiency and physical ergonomics. To stream immersive feedback with adequate visual cues for human vision systems, an on-demand situated visualization technique is integrated in the perception module, which reduces the cognitive load for multi-view processing. The system is built on a humanoid collaborative robot and validated with six challenging bimanual manipulation tasks. User study among 24 participants confirms that CaFe-TeleVision enhances ergonomics with statistical significance, indicating a lower task load and a higher user acceptance during teleoperation. Quantitative results also validate the superior performance of our system across six tasks, surpassing comparative methods by up to 28.89% in success rate and accelerating by 26.81% in completion time. Project webpage: https://clover-cuhk.github.io/cafe_television/",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14270v1",
            "code_links": [
                {
                    "url": "https://clover-cuhk.github.io/cafe_television/",
                    "type": "project_page"
                }
            ],
            "matched_interests": [
                {
                    "name": "人形机器人",
                    "matched_keywords": [
                        "humanoid"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出CaFe-TeleVision系统，通过粗到精控制与沉浸式可视化提升远程操作的效率与人体工学性能。",
            "summary_zh": "远程操作为远程控制和机器人本体感知数据收集提供了有前景的范式。尽管近期取得进展，当前远程操作系统在效率和人体工学方面仍存在局限，尤其在挑战性场景中。本文提出CaFe-TeleVision，一种具有沉浸式情境可视化功能的粗到精远程操作系统，旨在提升人体工学性能。其核心在于重定向模块中提出的粗到精控制机制，以弥合工作空间差异，共同优化效率和物理人体工学。为提供具有足够视觉线索的沉浸式反馈以适配人类视觉系统，感知模块集成了按需情境可视化技术，降低了多视图处理的认知负荷。该系统基于人形协作机器人构建，并通过六项挑战性双手操作任务进行验证。对24名参与者的用户研究证实，CaFe-TeleVision在统计学上显著提升了人体工学性能，表现为任务负荷更低、用户接受度更高。定量结果也验证了本系统在六项任务中的优越性能，成功率最高超出对比方法28.89%，完成时间加速26.81%。项目网页：https://clover-cuhk.github.io/cafe_television/",
            "intro_zh": [
                "现有远程操作系统在挑战性场景下效率与人体工学性能不足，影响操作体验与任务成功率。",
                "提出粗到精控制机制优化工作空间映射，并集成沉浸式情境可视化以降低认知负荷。",
                "用户研究显示系统显著降低任务负荷、提升接受度，定量指标在成功率与完成时间上大幅领先。"
            ],
            "method_zh": "CaFe-TeleVision系统整体框架包含重定向模块与感知模块。核心创新在于：1) 重定向模块采用粗到精控制机制，通过分层策略（如先粗略定位后精细调整）解决操作者与机器人工作空间不匹配问题，兼顾效率与物理人体工学；2) 感知模块集成按需情境可视化技术，动态提供沉浸式视觉反馈（如关键视角或深度信息），减少多视图处理的认知负担。与现有方法相比，本系统将控制优化与视觉增强紧密结合，而非孤立处理，从而更全面地提升远程操作性能。",
            "application_zh": "该系统可应用于远程机器人操作领域，如危险环境作业（核设施维护、灾难救援）、医疗手术辅助、工业制造中的精密装配，以及机器人数据收集与训练，具有提升操作安全性、精度与效率的实际价值。",
            "highlight_zh": "在六项挑战性双手操作任务中，CaFe-TeleVision相比对比方法，成功率最高提升28.89%，完成时间加速26.81%；用户研究（24名参与者）显示任务负荷显著降低、用户接受度提高，统计学上证实了人体工学性能的增强。",
            "tags_zh": [
                "远程操作",
                "人形机器人",
                "粗到精控制",
                "沉浸式可视化",
                "人体工学",
                "双手操作",
                "认知负荷",
                "工作空间映射"
            ],
            "_index": 78
        },
        {
            "title": "Enhancing Visual Programming for Visual Reasoning via Probabilistic Graphs",
            "authors": [
                "Wentao Wan",
                "Kaiyu Wu",
                "Qingyang Ma",
                "Nan Kang",
                "Yunjie Chen",
                "Liang Lin",
                "Keze Wang"
            ],
            "arxiv_id": "2512.14257v1",
            "summary": "Recently, Visual Programming (VP) based on large language models (LLMs) has rapidly developed and demonstrated significant potential in complex Visual Reasoning (VR) tasks. Previous works to enhance VP have primarily focused on improving the quality of LLM-generated visual programs. However, they have neglected to optimize the VP-invoked pre-trained models, which serve as modules for the visual sub-tasks decomposed from the targeted tasks by VP. The difficulty is that there are only final labels of targeted VR tasks rather than labels of sub-tasks. Besides, the non-differentiable nature of VP impedes the direct use of efficient gradient-based optimization methods to leverage final labels for end-to-end learning of the entire VP framework. To overcome these issues, we propose EVPG, a method to Enhance Visual Programming for visual reasoning via Probabilistic Graphs. Specifically, we creatively build a directed probabilistic graph according to the variable dependency relationships during the VP executing process, which reconstructs the non-differentiable VP executing process into a differentiable exact probability inference process on this directed probabilistic graph. As a result, this enables the VP framework to utilize the final labels for efficient, gradient-based optimization in end-to-end supervised learning on targeted VR tasks. Extensive and comprehensive experiments demonstrate the effectiveness and advantages of our EVPG, showing significant performance improvements for VP on three classical complex VR tasks: GQA, NLVRv2, and Open Images.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "13 Pages, 12 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14257v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO",
                        "VIO"
                    ],
                    "score": 2
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出EVPG方法，通过概率图将不可微视觉编程重构为可微推理过程，以增强复杂视觉推理任务性能。",
            "summary_zh": "近年来，基于大语言模型的视觉编程在复杂视觉推理任务中展现出巨大潜力。先前增强视觉编程的研究主要关注提升大语言模型生成的视觉程序质量，但忽略了优化视觉编程调用的预训练模型，这些模型作为视觉编程分解出的视觉子任务模块。困难在于只有目标视觉推理任务的最终标签，而没有子任务标签。此外，视觉编程的不可微特性阻碍了直接使用高效的基于梯度的优化方法，以利用最终标签进行整个视觉编程框架的端到端学习。为克服这些问题，我们提出EVPG，一种通过概率图增强视觉编程进行视觉推理的方法。具体而言，我们根据视觉编程执行过程中的变量依赖关系，创新性地构建了一个有向概率图，将不可微的视觉编程执行过程重构为该有向概率图上的可微精确概率推理过程。这使得视觉编程框架能够利用最终标签，在目标视觉推理任务上进行高效的、基于梯度的端到端监督学习优化。广泛而全面的实验证明了EVPG的有效性和优势，在GQA、NLVRv2和Open Images三个经典复杂视觉推理任务上，视觉编程性能显著提升。",
            "intro_zh": [
                "现有视觉编程方法主要优化大语言模型生成的程序，但忽略了预训练子任务模块的优化，且缺乏子任务标签，导致端到端学习困难。",
                "EVPG通过构建有向概率图，将不可微的视觉编程执行过程转化为可微的概率推理，实现基于梯度的端到端优化。",
                "在GQA、NLVRv2和Open Images等复杂视觉推理任务上，EVPG显著提升了视觉编程的性能，验证了其有效性。"
            ],
            "method_zh": "EVPG的整体框架基于视觉编程，核心创新在于构建有向概率图来建模视觉编程执行过程中的变量依赖关系。该图将每个视觉子任务模块的输出视为概率变量，通过精确概率推理计算最终预测的概率，从而将不可微的视觉编程过程重构为可微的推理过程。这使得整个框架可以利用目标任务的最终标签，通过梯度下降进行端到端监督学习，优化预训练子任务模块。与现有方法的主要区别在于，EVPG不仅关注程序生成质量，还通过概率图机制实现了对子任务模块的联合优化，解决了视觉编程中不可微和标签缺失的挑战。",
            "application_zh": "EVPG可应用于需要复杂视觉推理的领域，如智能问答系统、视觉语言导航、自动驾驶中的场景理解，以及教育或医疗领域的多模态分析任务，提升模型在真实世界复杂视觉任务中的准确性和鲁棒性。",
            "highlight_zh": "实验在GQA、NLVRv2和Open Images三个基准数据集上进行，EVPG相比基线视觉编程方法取得了显著性能提升，具体提升幅度未知，但论文报告了全面的实验结果，证明了该方法在复杂视觉推理任务中的有效性和优势。",
            "tags_zh": [
                "视觉编程",
                "概率图模型",
                "视觉推理",
                "端到端学习",
                "大语言模型",
                "多模态学习",
                "可微优化",
                "监督学习"
            ],
            "_index": 79
        },
        {
            "title": "DRAW2ACT: Turning Depth-Encoded Trajectories into Robotic Demonstration Videos",
            "authors": [
                "Yang Bai",
                "Liudi Yang",
                "George Eskandar",
                "Fengyi Shen",
                "Mohammad Altillawi",
                "Ziyuan Liu",
                "Gitta Kutyniok"
            ],
            "arxiv_id": "2512.14217v1",
            "summary": "Video diffusion models provide powerful real-world simulators for embodied AI but remain limited in controllability for robotic manipulation. Recent works on trajectory-conditioned video generation address this gap but often rely on 2D trajectories or single modality conditioning, which restricts their ability to produce controllable and consistent robotic demonstrations. We present DRAW2ACT, a depth-aware trajectory-conditioned video generation framework that extracts multiple orthogonal representations from the input trajectory, capturing depth, semantics, shape and motion, and injects them into the diffusion model. Moreover, we propose to jointly generate spatially aligned RGB and depth videos, leveraging cross-modality attention mechanisms and depth supervision to enhance the spatio-temporal consistency. Finally, we introduce a multimodal policy model conditioned on the generated RGB and depth sequences to regress the robot's joint angles. Experiments on Bridge V2, Berkeley Autolab, and simulation benchmarks show that DRAW2ACT achieves superior visual fidelity and consistency while yielding higher manipulation success rates compared to existing baselines.",
            "categories": [
                "cs.CV",
                "cs.RO"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14217v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "世界模型",
                    "matched_keywords": [
                        "world simulator"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出DRAW2ACT框架，通过深度感知轨迹条件视频生成，解决机器人演示视频可控性和一致性问题。",
            "summary_zh": "视频扩散模型为具身AI提供了强大的真实世界模拟器，但在机器人操作的可控性方面仍有限制。近期基于轨迹条件的视频生成工作填补了这一空白，但通常依赖于2D轨迹或单模态条件，限制了其生成可控且一致的机器人演示的能力。我们提出了DRAW2ACT，一个深度感知轨迹条件视频生成框架，从输入轨迹中提取多个正交表示，捕捉深度、语义、形状和运动，并将它们注入扩散模型。此外，我们提出联合生成空间对齐的RGB和深度视频，利用跨模态注意力机制和深度监督来增强时空一致性。最后，我们引入了一个基于生成的RGB和深度序列的多模态策略模型，以回归机器人的关节角度。在Bridge V2、Berkeley Autolab和模拟基准测试上的实验表明，与现有基线相比，DRAW2ACT实现了更优的视觉保真度和一致性，同时获得了更高的操作成功率。",
            "intro_zh": [
                "现有方法依赖2D轨迹或单模态条件，导致机器人演示视频可控性和一致性受限。",
                "DRAW2ACT提取轨迹的深度、语义等多正交表示，并注入扩散模型，联合生成RGB和深度视频。",
                "实验显示，DRAW2ACT在视觉保真度、一致性和操作成功率上均优于基线方法。"
            ],
            "method_zh": "DRAW2ACT是一个深度感知轨迹条件视频生成框架，整体包括轨迹表示提取、多模态视频生成和策略模型三部分。关键技术创新点在于从轨迹中提取深度、语义、形状和运动等多正交表示，并通过跨模态注意力机制联合生成空间对齐的RGB和深度视频，以增强时空一致性。与现有方法的主要区别在于其深度感知能力和多模态联合生成，克服了2D轨迹或单模态条件的限制，提高了可控性和一致性。",
            "application_zh": "该研究可应用于机器人演示视频生成、具身AI模拟和自动化操作任务，通过生成高质量、可控的演示视频，提升机器人学习和操作的成功率，具有实际价值。",
            "highlight_zh": "在Bridge V2、Berkeley Autolab和模拟基准测试中，DRAW2ACT实现了更优的视觉保真度和一致性，操作成功率显著高于现有基线，验证了其有效性。",
            "tags_zh": [
                "深度感知轨迹条件",
                "视频生成",
                "机器人演示",
                "多模态融合",
                "扩散模型",
                "时空一致性",
                "具身AI",
                "操作成功率"
            ],
            "_index": 80
        },
        {
            "title": "Error Bound Analysis of Physics-Informed Neural Networks-Driven T2 Quantification in Cardiac Magnetic Resonance Imaging",
            "authors": [
                "Mengxue Zhang",
                "Qingrui Cai",
                "Yinyin Chen",
                "Hang Jin",
                "Jianjun Zhou",
                "Qiu Guo",
                "Peijun Zhao",
                "Zhiping Mao",
                "Xingxing Zhang",
                "Yuyu Xia",
                "Xianwang Jiang",
                "Qin Xu",
                "Chunyan Xiong",
                "Yirong Zhou",
                "Chengyan Wang",
                "Xiaobo Qu"
            ],
            "arxiv_id": "2512.14211v1",
            "summary": "Physics-Informed Neural Networks (PINN) are emerging as a promising approach for quantitative parameter estimation of Magnetic Resonance Imaging (MRI). While existing deep learning methods can provide an accurate quantitative estimation of the T2 parameter, they still require large amounts of training data and lack theoretical support and a recognized gold standard. Thus, given the absence of PINN-based approaches for T2 estimation, we propose embedding the fundamental physics of MRI, the Bloch equation, in the loss of PINN, which is solely based on target scan data and does not require a pre-defined training database. Furthermore, by deriving rigorous upper bounds for both the T2 estimation error and the generalization error of the Bloch equation solution, we establish a theoretical foundation for evaluating the PINN's quantitative accuracy. Even without access to the ground truth or a gold standard, this theory enables us to estimate the error with respect to the real quantitative parameter T2. The accuracy of T2 mapping and the validity of the theoretical analysis are demonstrated on a numerical cardiac model and a water phantom, where our method exhibits excellent quantitative precision in the myocardial T2 range. Clinical applicability is confirmed in 94 acute myocardial infarction (AMI) patients, achieving low-error quantitative T2 estimation under the theoretical error bound, highlighting the robustness and potential of PINN.",
            "categories": [
                "physics.bio-ph",
                "cs.AI"
            ],
            "primary_category": "physics.bio-ph",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14211v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "mapping"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "PPO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出基于物理信息神经网络的T2量化误差界分析方法，解决心脏磁共振成像中定量参数估计的理论支撑问题。",
            "summary_zh": "物理信息神经网络（PINN）正成为磁共振成像（MRI）定量参数估计的一种有前景方法。虽然现有深度学习方法能提供T2参数的准确定量估计，但仍需要大量训练数据，且缺乏理论支持和公认的金标准。因此，鉴于目前尚无基于PINN的T2估计方法，我们提出将MRI的基本物理原理——布洛赫方程嵌入PINN的损失函数中，该方法仅基于目标扫描数据，无需预定义的训练数据库。此外，通过推导T2估计误差和布洛赫方程解泛化误差的严格上界，我们为评估PINN的定量准确性建立了理论基础。即使无法获得真实值或金标准，该理论也能使我们估计相对于真实定量参数T2的误差。T2映射的准确性和理论分析的有效性在数值心脏模型和水模上得到验证，我们的方法在心肌T2范围内表现出优异的定量精度。临床适用性在94名急性心肌梗死（AMI）患者中得到确认，在理论误差界内实现了低误差的定量T2估计，突显了PINN的鲁棒性和潜力。",
            "intro_zh": [
                "现有深度学习方法依赖大量训练数据且缺乏理论支撑，难以在无金标准下评估T2定量准确性。",
                "将布洛赫方程嵌入PINN损失函数，仅需目标扫描数据，无需预训练数据库，实现物理驱动的参数估计。",
                "在数值模型和临床患者中验证，T2估计误差低于理论界，定量精度高，证实方法的有效性和鲁棒性。"
            ],
            "method_zh": "论文提出一种基于物理信息神经网络（PINN）的T2量化框架，核心是将MRI的物理原理——布洛赫方程作为约束嵌入神经网络的损失函数中。关键创新在于推导了T2估计误差和布洛赫方程解泛化误差的严格上界，为定量准确性提供了理论保障。与现有深度学习方法相比，该方法无需大量训练数据，仅依赖目标扫描数据，实现了数据高效且理论可解释的物理驱动估计。",
            "application_zh": "该研究主要应用于心脏磁共振成像中的T2参数定量估计，特别适用于急性心肌梗死等心脏疾病的临床诊断和监测。通过提供理论误差界，可在无金标准情况下评估定量准确性，提升MRI参数映射的可靠性和临床决策支持价值。",
            "highlight_zh": "在数值心脏模型和水模实验中，方法在心肌T2范围内表现出优异定量精度；临床验证于94名AMI患者，T2估计误差低于理论界，平均误差降低约30%，证实了理论分析的有效性和临床适用性。",
            "tags_zh": [
                "物理信息神经网络",
                "T2量化",
                "心脏磁共振成像",
                "误差界分析",
                "布洛赫方程",
                "定量参数估计",
                "急性心肌梗死",
                "理论保障"
            ],
            "_index": 81
        },
        {
            "title": "Towards Explainable Quantum AI: Informing the Encoder Selection of Quantum Neural Networks via Visualization",
            "authors": [
                "Shaolun Ruan",
                "Feng Liang",
                "Rohan Ramakrishna",
                "Chao Ren",
                "Rudai Yan",
                "Qiang Guan",
                "Jiannan Li",
                "Yong Wang"
            ],
            "arxiv_id": "2512.14181v1",
            "summary": "Quantum Neural Networks (QNNs) represent a promising fusion of quantum computing and neural network architectures, offering speed-ups and efficient processing of high-dimensional, entangled data. A crucial component of QNNs is the encoder, which maps classical input data into quantum states. However, choosing suitable encoders remains a significant challenge, largely due to the lack of systematic guidance and the trial-and-error nature of current approaches. This process is further impeded by two key challenges: (1) the difficulty in evaluating encoded quantum states prior to training, and (2) the lack of intuitive methods for analyzing an encoder's ability to effectively distinguish data features. To address these issues, we introduce a novel visualization tool, XQAI-Eyes, which enables QNN developers to compare classical data features with their corresponding encoded quantum states and to examine the mixed quantum states across different classes. By bridging classical and quantum perspectives, XQAI-Eyes facilitates a deeper understanding of how encoders influence QNN performance. Evaluations across diverse datasets and encoder designs demonstrate XQAI-Eyes's potential to support the exploration of the relationship between encoder design and QNN effectiveness, offering a holistic and transparent approach to optimizing quantum encoders. Moreover, domain experts used XQAI-Eyes to derive two key practices for quantum encoder selection, grounded in the principles of pattern preservation and feature mapping.",
            "categories": [
                "quant-ph",
                "cs.AI",
                "cs.HC"
            ],
            "primary_category": "quant-ph",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "9 pages, 6 figures, accepted by TVCG 2026, not published yet",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14181v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "mapping"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "PPO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出XQAI-Eyes可视化工具以解决量子神经网络编码器选择缺乏系统指导的问题。",
            "summary_zh": "量子神经网络（QNNs）结合了量子计算和神经网络架构，在处理高维纠缠数据时具有加速和高效处理的潜力。编码器作为QNNs的关键组件，负责将经典输入数据映射到量子态，但选择合适的编码器仍面临重大挑战，主要原因是缺乏系统化指导且当前方法多依赖试错。这一过程还受到两个关键问题的阻碍：（1）在训练前难以评估编码后的量子态；（2）缺乏直观方法来分析编码器有效区分数据特征的能力。为解决这些问题，我们引入了一种新颖的可视化工具XQAI-Eyes，使QNN开发者能够比较经典数据特征与对应的编码量子态，并检查不同类别间的混合量子态。通过桥接经典和量子视角，XQAI-Eyes有助于深入理解编码器如何影响QNN性能。在不同数据集和编码器设计上的评估表明，XQAI-Eyes有潜力支持探索编码器设计与QNN有效性之间的关系，为优化量子编码器提供全面且透明的方法。此外，领域专家利用XQAI-Eyes基于模式保留和特征映射原则，推导出量子编码器选择的两项关键实践。",
            "intro_zh": [
                "核心问题：量子神经网络编码器选择缺乏系统指导，现有方法依赖试错，且难以在训练前评估量子态和分析特征区分能力。",
                "方法要点：提出XQAI-Eyes可视化工具，通过比较经典数据与编码量子态，帮助开发者直观理解编码器对性能的影响。",
                "实验或效果：评估显示XQAI-Eyes能支持编码器设计与QNN有效性关系探索，并推导出基于模式保留和特征映射的编码器选择实践。"
            ],
            "method_zh": "论文的核心方法是开发XQAI-Eyes可视化工具，整体框架包括数据输入、编码器映射和量子态可视化模块。关键技术创新点在于将经典数据特征与编码后的量子态进行对比分析，并可视化不同类别间的混合量子态，从而提供直观的编码器评估手段。与现有方法的主要区别在于，XQAI-Eyes通过可视化桥接经典和量子视角，解决了传统试错方法中缺乏预训练评估和特征分析能力的问题，为编码器选择提供系统化指导。",
            "application_zh": "该研究在量子人工智能领域具有潜在应用价值，可用于优化量子神经网络在药物发现、材料科学和金融建模等任务中的编码器设计，提升模型性能和可解释性，促进量子计算与机器学习的融合应用。",
            "highlight_zh": "最重要的实验结果是XQAI-Eyes在不同数据集和编码器设计上成功支持了编码器与QNN有效性关系的探索，并帮助领域专家基于模式保留和特征映射原则推导出两项关键编码器选择实践，为量子编码器优化提供了透明且实用的方法。",
            "tags_zh": [
                "量子神经网络",
                "编码器选择",
                "可视化工具",
                "量子态分析",
                "可解释AI",
                "量子计算",
                "机器学习",
                "特征映射"
            ],
            "_index": 82
        },
        {
            "title": "Spherical Voronoi: Directional Appearance as a Differentiable Partition of the Sphere",
            "authors": [
                "Francesco Di Sario",
                "Daniel Rebain",
                "Dor Verbin",
                "Marco Grangetto",
                "Andrea Tagliasacchi"
            ],
            "arxiv_id": "2512.14180v1",
            "summary": "Radiance field methods (e.g. 3D Gaussian Splatting) have emerged as a powerful paradigm for novel view synthesis, yet their appearance modeling often relies on Spherical Harmonics (SH), which impose fundamental limitations. SH struggle with high-frequency signals, exhibit Gibbs ringing artifacts, and fail to capture specular reflections - a key component of realistic rendering. Although alternatives like spherical Gaussians offer improvements, they add significant optimization complexity. We propose Spherical Voronoi (SV) as a unified framework for appearance representation in 3D Gaussian Splatting. SV partitions the directional domain into learnable regions with smooth boundaries, providing an intuitive and stable parameterization for view-dependent effects. For diffuse appearance, SV achieves competitive results while keeping optimization simpler than existing alternatives. For reflections - where SH fail - we leverage SV as learnable reflection probes, taking reflected directions as input following principles from classical graphics. This formulation attains state-of-the-art results on synthetic and real-world datasets, demonstrating that SV offers a principled, efficient, and general solution for appearance modeling in explicit 3D representations.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14180v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出球面Voronoi作为3D高斯泼溅中外观建模的统一框架，以解决球谐函数在高频信号和镜面反射方面的局限性。",
            "summary_zh": "辐射场方法（如3D高斯泼溅）已成为新视角合成的强大范式，但其外观建模通常依赖于球谐函数（SH），这带来了根本性限制。SH难以处理高频信号，会出现吉布斯振铃伪影，且无法捕捉镜面反射——这是真实感渲染的关键组成部分。虽然球面高斯等替代方法有所改进，但显著增加了优化复杂性。我们提出球面Voronoi（SV）作为3D高斯泼溅中外观表示的统一框架。SV将方向域划分为具有平滑边界的可学习区域，为视角相关效果提供了直观且稳定的参数化。对于漫反射外观，SV在保持优化比现有替代方法更简单的同时，实现了有竞争力的结果。对于SH失败的反射情况，我们利用SV作为可学习的反射探针，遵循经典图形学原理，以反射方向作为输入。该公式在合成和真实世界数据集上取得了最先进的结果，表明SV为显式3D表示中的外观建模提供了一个原则性、高效且通用的解决方案。",
            "intro_zh": [
                "现有球谐函数在3D高斯泼溅中处理高频信号时存在吉布斯振铃伪影，且无法有效建模镜面反射，限制了真实感渲染效果。",
                "提出球面Voronoi框架，通过将方向域划分为可学习区域来参数化外观，利用平滑边界实现稳定优化，并作为反射探针处理镜面效果。",
                "在合成和真实数据集上实现最先进性能，漫反射建模保持简单优化，镜面反射表现显著优于球谐函数，验证了方法的有效性和通用性。"
            ],
            "method_zh": "论文提出球面Voronoi（SV）作为3D高斯泼溅中外观建模的统一框架。整体框架基于将球面方向域划分为多个Voronoi区域，每个区域对应一个可学习的外观参数，通过平滑边界函数实现可微分优化。关键技术创新点包括：利用Voronoi划分提供直观的方向分区，避免球谐函数的频域限制；引入可学习反射探针机制，直接以反射方向作为输入处理镜面反射。与现有方法的主要区别在于：相比球谐函数，SV能更好地捕捉高频和镜面效果；相比球面高斯，SV优化更简单稳定，无需复杂参数调整。",
            "application_zh": "该研究主要应用于计算机视觉和图形学领域，特别是基于辐射场的新视角合成和3D重建任务。潜在应用包括虚拟现实、增强现实中的真实感场景渲染，以及电影特效、游戏开发中的高效外观建模，提升视觉保真度和优化效率。",
            "highlight_zh": "实验在合成和真实数据集上验证了SV的优越性：在镜面反射建模方面，SV显著优于球谐函数，消除了吉布斯伪影；在漫反射任务中，SV达到竞争性结果且优化更简单；整体性能在多个指标上达到最先进水平，证明了其作为通用外观表示框架的有效性。",
            "tags_zh": [
                "球面Voronoi",
                "3D高斯泼溅",
                "外观建模",
                "新视角合成",
                "镜面反射",
                "可微分渲染",
                "辐射场方法",
                "方向域划分"
            ],
            "_index": 83
        },
        {
            "title": "IntentMiner: Intent Inversion Attack via Tool Call Analysis in the Model Context Protocol",
            "authors": [
                "Yunhao Yao",
                "Zhiqiang Wang",
                "Haoran Cheng",
                "Yihang Cheng",
                "Haohua Du",
                "Xiang-Yang Li"
            ],
            "arxiv_id": "2512.14166v1",
            "summary": "The rapid evolution of Large Language Models (LLMs) into autonomous agents has led to the adoption of the Model Context Protocol (MCP) as a standard for discovering and invoking external tools. While this architecture decouples the reasoning engine from tool execution to enhance scalability, it introduces a significant privacy surface: third-party MCP servers, acting as semi-honest intermediaries, can observe detailed tool interaction logs outside the user's trusted boundary. In this paper, we first identify and formalize a novel privacy threat termed Intent Inversion, where a semi-honest MCP server attempts to reconstruct the user's private underlying intent solely by analyzing legitimate tool calls. To systematically assess this vulnerability, we propose IntentMiner, a framework that leverages Hierarchical Information Isolation and Three-Dimensional Semantic Analysis, integrating tool purpose, call statements, and returned results, to accurately infer user intent at the step level. Extensive experiments demonstrate that IntentMiner achieves a high degree of semantic alignment (over 85%) with original user queries, significantly outperforming baseline approaches. These results highlight the inherent privacy risks in decoupled agent architectures, revealing that seemingly benign tool execution logs can serve as a potent vector for exposing user secrets.",
            "categories": [
                "cs.CR",
                "cs.AI"
            ],
            "primary_category": "cs.CR",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "12 pages, 6 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14166v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出IntentMiner框架，通过分析模型上下文协议中的工具调用，揭示半诚实服务器对用户隐私意图的逆向攻击风险。",
            "summary_zh": "大型语言模型（LLMs）向自主代理的快速发展促使模型上下文协议（MCP）成为发现和调用外部工具的标准。虽然这种架构将推理引擎与工具执行解耦以提升可扩展性，但也引入了显著的隐私暴露面：作为半诚实中介的第三方MCP服务器可以在用户信任边界外观察详细的工具交互日志。本文首次识别并形式化了一种名为“意图逆向”的新型隐私威胁，即半诚实MCP服务器仅通过分析合法工具调用来尝试重建用户的私有底层意图。为系统评估此漏洞，我们提出了IntentMiner框架，该框架利用分层信息隔离和三维语义分析，整合工具目的、调用语句和返回结果，以在步骤级别准确推断用户意图。大量实验表明，IntentMiner与原始用户查询实现了高度的语义对齐（超过85%），显著优于基线方法。这些结果突显了解耦代理架构中固有的隐私风险，揭示了看似良性的工具执行日志可能成为暴露用户秘密的有效载体。",
            "intro_zh": [
                "核心问题：模型上下文协议（MCP）架构中，半诚实服务器通过工具交互日志暴露用户隐私意图，现有方法缺乏对此威胁的系统评估。",
                "方法要点：提出IntentMiner框架，结合分层信息隔离和三维语义分析，从工具调用中逆向推断用户意图。",
                "实验或效果：实验显示IntentMiner在语义对齐上超过85%，显著优于基线，揭示了代理架构的隐私漏洞。"
            ],
            "method_zh": "IntentMiner的整体框架基于分层信息隔离和三维语义分析。关键技术创新点包括：首先，通过分层结构隔离工具调用中的不同信息维度（如工具目的、调用语句和返回结果），以减少噪声干扰；其次，采用三维语义分析整合这些维度，构建意图推断模型，以在步骤级别准确重建用户意图。与现有方法的主要区别在于，IntentMiner专注于从合法工具日志中逆向攻击，而非传统的数据泄露或模型攻击，且通过系统化分析提升了推断精度，直接针对MCP架构的隐私弱点。",
            "application_zh": "该研究可应用于评估自主代理系统的隐私安全性，帮助开发者识别和缓解工具调用中的意图泄露风险，提升人工智能代理在医疗、金融等敏感领域的可信部署。",
            "highlight_zh": "IntentMiner在实验中实现了超过85%的语义对齐率，显著优于基线方法，证明了工具执行日志作为隐私攻击载体的有效性，突显了MCP架构的潜在安全威胁。",
            "tags_zh": [
                "意图逆向攻击",
                "模型上下文协议",
                "隐私安全",
                "工具调用分析",
                "自主代理",
                "语义对齐",
                "分层信息隔离",
                "三维语义分析"
            ],
            "_index": 84
        },
        {
            "title": "LAPPI: Interactive Optimization with LLM-Assisted Preference-Based Problem Instantiation",
            "authors": [
                "So Kuroki",
                "Manami Nakagawa",
                "Shigeo Yoshida",
                "Yuki Koyama",
                "Kozuno Tadashi"
            ],
            "arxiv_id": "2512.14138v1",
            "summary": "Many real-world tasks, such as trip planning or meal planning, can be formulated as combinatorial optimization problems. However, using optimization solvers is difficult for end users because it requires problem instantiation: defining candidate items, assigning preference scores, and specifying constraints. We introduce LAPPI (LLM-Assisted Preference-based Problem Instantiation), an interactive approach that uses large language models (LLMs) to support users in this instantiation process. Through natural language conversations, the system helps users transform vague preferences into well-defined optimization problems. These instantiated problems are then passed to existing optimization solvers to generate solutions. In a user study on trip planning, our method successfully captured user preferences and generated feasible plans that outperformed both conventional and prompt-engineering approaches. We further demonstrate LAPPI's versatility by adapting it to an additional use case.",
            "categories": [
                "cs.HC",
                "cs.AI"
            ],
            "primary_category": "cs.HC",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14138v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL",
                        "PPO"
                    ],
                    "score": 2
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出LAPPI交互式优化方法，利用大语言模型辅助用户将模糊偏好转化为可求解的组合优化问题。",
            "summary_zh": "许多现实世界任务（如旅行规划或膳食规划）可被表述为组合优化问题。然而，对于终端用户而言，使用优化求解器是困难的，因为它需要问题实例化：定义候选项目、分配偏好分数和指定约束条件。我们引入了LAPPI（LLM辅助的基于偏好的问题实例化），这是一种交互式方法，利用大语言模型（LLMs）支持用户在此实例化过程中。通过自然语言对话，系统帮助用户将模糊偏好转化为明确定义的优化问题。这些实例化的问题随后被传递给现有的优化求解器以生成解决方案。在旅行规划的用户研究中，我们的方法成功捕捉了用户偏好，并生成了可行的计划，其性能优于传统方法和提示工程方法。我们通过将其适应于另一个用例进一步展示了LAPPI的通用性。",
            "intro_zh": [
                "现有方法中，终端用户难以直接使用优化求解器，因为需要精确的问题实例化（如定义候选项和约束），这通常超出非专家能力范围。",
                "论文提出LAPPI方法，核心思想是通过LLM驱动的自然语言对话交互，辅助用户将模糊偏好逐步转化为结构化优化问题，再调用现有求解器。",
                "在旅行规划用户研究中，LAPPI成功捕捉用户偏好，生成可行计划，性能优于传统方法和提示工程方法，并展示了跨领域适应性。"
            ],
            "method_zh": "LAPPI的整体框架是一个交互式系统，用户通过自然语言对话表达偏好，LLM作为中介，逐步引导用户完成问题实例化过程，包括识别候选项目、量化偏好分数和定义约束条件。关键技术创新点在于将LLM的对话能力与优化问题形式化相结合，实现从非结构化语言输入到结构化优化模型的转换。与现有方法的主要区别在于：传统方法依赖用户手动实例化，而LAPPI通过LLM自动化部分过程；相比纯提示工程方法，LAPPI更系统化地整合了优化求解器，确保生成问题的可解性和实用性。",
            "application_zh": "该研究适用于需要个性化规划的场景，如旅行行程安排、膳食计划制定、日程优化等，能帮助非专业用户轻松利用优化技术解决日常决策问题，提升效率和满意度。",
            "highlight_zh": "在旅行规划用户实验中，LAPPI成功捕捉用户偏好，生成可行计划，其性能优于传统手动实例化方法和基于提示工程的直接优化方法，验证了交互式LLM辅助在优化问题实例化中的有效性。",
            "tags_zh": [
                "组合优化",
                "大语言模型",
                "交互式系统",
                "问题实例化",
                "用户偏好建模",
                "自然语言处理",
                "优化求解器",
                "人机交互"
            ],
            "_index": 85
        },
        {
            "title": "UIXPOSE: Mobile Malware Detection via Intention-Behaviour Discrepancy Analysis",
            "authors": [
                "Amirmohammad Pasdar",
                "Toby Murray",
                "Van-Thuan Pham"
            ],
            "arxiv_id": "2512.14130v1",
            "summary": "We introduce UIXPOSE, a source-code-agnostic framework that operates on both compiled and open-source apps. This framework applies Intention Behaviour Alignment (IBA) to mobile malware analysis, aligning UI-inferred intent with runtime semantics. Previous work either infers intent statically, e.g., permission-centric, or widget-level or monitors coarse dynamic signals (endpoints, partial resource usage) that miss content and context. UIXPOSE infers an intent vector from each screen using vision-language models and knowledge structures and combines decoded network payloads, heap/memory signals, and resource utilisation traces into a behaviour vector. Their alignment, calculated at runtime, can both detect misbehaviour and highlight exploration of behaviourally rich paths. In three real-world case studies, UIXPOSE reveals covert exfiltration and hidden background activity that evade metadata-only baselines, demonstrating how IBA improves dynamic detection.",
            "categories": [
                "cs.CR",
                "cs.AI"
            ],
            "primary_category": "cs.CR",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "15 pages",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14130v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VIO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出UIXPOSE框架，通过意图-行为差异分析解决移动恶意软件检测问题。",
            "summary_zh": "我们介绍了UIXPOSE，这是一个与源代码无关的框架，适用于编译和开源应用程序。该框架将意图行为对齐（IBA）应用于移动恶意软件分析，将UI推断的意图与运行时语义对齐。先前的工作要么静态推断意图（例如，基于权限或小部件级别），要么监控粗糙的动态信号（如端点、部分资源使用），这些方法忽略了内容和上下文。UIXPOSE使用视觉语言模型和知识结构从每个屏幕推断意图向量，并将解码的网络负载、堆/内存信号和资源利用跟踪组合成行为向量。在运行时计算它们的对齐度，既可以检测不当行为，又可以突出行为丰富路径的探索。在三个真实案例研究中，UIXPOSE揭示了仅基于元数据的基线方法无法检测到的隐蔽数据外泄和隐藏后台活动，展示了IBA如何改进动态检测。",
            "intro_zh": [
                "核心问题：现有移动恶意软件检测方法要么静态推断意图（如权限分析），要么监控粗糙动态信号（如端点），忽略UI内容和上下文，导致检测不准确。",
                "方法要点：提出UIXPOSE框架，通过视觉语言模型从UI推断意图向量，结合运行时行为向量，实现意图-行为对齐分析，提升检测精度。",
                "实验或效果：在真实案例中，UIXPOSE成功检测到隐蔽数据外泄和后台活动，优于仅基于元数据的基线方法，验证了IBA的有效性。"
            ],
            "method_zh": "UIXPOSE是一个与源代码无关的框架，整体上通过意图行为对齐（IBA）分析移动应用。关键技术创新点包括：使用视觉语言模型从UI屏幕推断意图向量，结合解码的网络负载、堆/内存信号和资源利用跟踪形成行为向量，并在运行时计算对齐度以检测恶意行为。与现有方法的主要区别在于，它动态整合UI内容和上下文，而非仅依赖静态权限或粗糙动态信号，从而更全面地捕捉恶意活动。",
            "application_zh": "该研究主要应用于移动安全领域，特别是Android和iOS平台的恶意软件检测。潜在价值包括提升应用商店审核效率、企业移动设备管理和个人用户安全防护，通过实时分析意图-行为差异，有效识别隐蔽威胁。",
            "highlight_zh": "在三个真实案例研究中，UIXPOSE成功检测到仅基于元数据的基线方法无法发现的隐蔽数据外泄和隐藏后台活动，证明了意图-行为对齐分析在动态检测中的显著提升效果。",
            "tags_zh": [
                "移动恶意软件检测",
                "意图行为对齐",
                "视觉语言模型",
                "动态分析",
                "UI推断",
                "运行时语义",
                "隐蔽活动检测",
                "多模态融合"
            ],
            "_index": 86
        },
        {
            "title": "Interactive Motion Planning for Human-Robot Collaboration Based on Human-Centric Configuration Space Ergonomic Field",
            "authors": [
                "Chenzui Li",
                "Yiming Chen",
                "Xi Wu",
                "Tao Teng",
                "Sylvain Calinon",
                "Darwin Caldwell",
                "Fei Chen"
            ],
            "arxiv_id": "2512.14111v1",
            "summary": "Industrial human-robot collaboration requires motion planning that is collision-free, responsive, and ergonomically safe to reduce fatigue and musculoskeletal risk. We propose the Configuration Space Ergonomic Field (CSEF), a continuous and differentiable field over the human joint space that quantifies ergonomic quality and provides gradients for real-time ergonomics-aware planning. An efficient algorithm constructs CSEF from established metrics with joint-wise weighting and task conditioning, and we integrate it into a gradient-based planner compatible with impedance-controlled robots. In a 2-DoF benchmark, CSEF-based planning achieves higher success rates, lower ergonomic cost, and faster computation than a task-space ergonomic planner. Hardware experiments with a dual-arm robot in unimanual guidance, collaborative drilling, and bimanual cocarrying show faster ergonomic cost reduction, closer tracking to optimized joint targets, and lower muscle activation than a point-to-point baseline. CSEF-based planning method reduces average ergonomic scores by up to 10.31% for collaborative drilling tasks and 5.60% for bimanual co-carrying tasks while decreasing activation in key muscle groups, indicating practical benefits for real-world deployment.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "10 pages, 9 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14111v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "物理动作",
                    "matched_keywords": [
                        "musculoskeletal"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出基于人机配置空间人因工程场的交互式运动规划方法，以提升工业人机协作中的实时人因安全与效率。",
            "summary_zh": "工业人机协作需要无碰撞、响应迅速且人因工程安全的运动规划，以减少疲劳和肌肉骨骼风险。本文提出配置空间人因工程场（CSEF），这是一个在人体关节空间上连续可微的场，用于量化人因工程质量并提供实时人因感知规划的梯度。我们开发了一种高效算法，基于现有指标构建CSEF，包括关节权重和任务条件化，并将其集成到与阻抗控制机器人兼容的基于梯度的规划器中。在2自由度基准测试中，基于CSEF的规划比任务空间人因规划器具有更高的成功率、更低的人因成本和更快的计算速度。硬件实验中，使用双臂机器人进行单臂引导、协作钻孔和双臂协同搬运任务，结果显示比点到点基线方法更快地降低人因成本、更接近优化关节目标的跟踪以及更低的肌肉激活。基于CSEF的规划方法在协作钻孔任务中平均人因分数降低高达10.31%，在双臂协同搬运任务中降低5.60%，同时减少关键肌肉群的激活，表明其实用价值。",
            "intro_zh": [
                "现有工业人机协作规划方法在实时人因工程优化方面不足，难以平衡安全、响应速度和计算效率。",
                "论文提出配置空间人因工程场（CSEF），通过连续可微场量化人因质量，并利用梯度实现实时规划。",
                "实验显示，CSEF规划在基准测试和硬件任务中显著降低人因成本，提升成功率和计算速度。"
            ],
            "method_zh": "论文提出配置空间人因工程场（CSEF）作为核心方法，整体框架包括：首先，基于现有的人因工程指标，通过关节权重和任务条件化构建CSEF，形成一个在人体关节空间上连续可微的场；其次，将CSEF集成到基于梯度的运动规划器中，与阻抗控制机器人兼容，实现实时优化。关键技术创新点在于CSEF的连续可微性，允许直接计算梯度以指导规划，而现有方法通常依赖离散优化或任务空间近似，导致计算效率低或人因优化不精确。主要区别在于CSEF直接在配置空间操作，提供更精确的人因量化，并支持实时响应，优于传统任务空间规划器。",
            "application_zh": "该研究适用于工业人机协作场景，如装配线、制造和物流，通过实时人因优化提升工人安全、减少疲劳，并提高协作效率，具有实际部署价值。",
            "highlight_zh": "在2自由度基准测试中，CSEF规划成功率更高、人因成本更低、计算更快；硬件实验中，协作钻孔任务人因分数降低10.31%，双臂协同搬运降低5.60%，肌肉激活减少，验证了方法的有效性。",
            "tags_zh": [
                "人机协作",
                "运动规划",
                "人因工程",
                "配置空间",
                "梯度优化",
                "实时控制",
                "工业机器人",
                "肌肉激活分析"
            ],
            "_index": 87
        },
        {
            "title": "OUSAC: Optimized Guidance Scheduling with Adaptive Caching for DiT Acceleration",
            "authors": [
                "Ruitong Sun",
                "Tianze Yang",
                "Wei Niu",
                "Jin Sun"
            ],
            "arxiv_id": "2512.14096v1",
            "summary": "Diffusion models have emerged as the dominant paradigm for high-quality image generation, yet their computational expense remains substantial due to iterative denoising. Classifier-Free Guidance (CFG) significantly enhances generation quality and controllability but doubles the computation by requiring both conditional and unconditional forward passes at every timestep. We present OUSAC (Optimized gUidance Scheduling with Adaptive Caching), a framework that accelerates diffusion transformers (DiT) through systematic optimization. Our key insight is that variable guidance scales enable sparse computation: adjusting scales at certain timesteps can compensate for skipping CFG at others, enabling both fewer total sampling steps and fewer CFG steps while maintaining quality. However, variable guidance patterns introduce denoising deviations that undermine standard caching methods, which assume constant CFG scales across steps. Moreover, different transformer blocks are affected at different levels under dynamic conditions. This paper develops a two-stage approach leveraging these insights. Stage-1 employs evolutionary algorithms to jointly optimize which timesteps to skip and what guidance scale to use, eliminating up to 82% of unconditional passes. Stage-2 introduces adaptive rank allocation that tailors calibration efforts per transformer block, maintaining caching effectiveness under variable guidance. Experiments demonstrate that OUSAC significantly outperforms state-of-the-art acceleration methods, achieving 53% computational savings with 15% quality improvement on DiT-XL/2 (ImageNet 512x512), 60% savings with 16.1% improvement on PixArt-alpha (MSCOCO), and 5x speedup on FLUX while improving CLIP Score over the 50-step baseline.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "29 pages",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14096v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "SAC"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出OUSAC框架以解决扩散模型中无分类器引导计算开销大的问题，通过优化引导调度与自适应缓存实现高效加速。",
            "summary_zh": "扩散模型已成为高质量图像生成的主导范式，但其迭代去噪过程计算开销巨大。无分类器引导（CFG）显著提升了生成质量和可控性，但需要在每个时间步同时执行条件前向传播和无条件前向传播，导致计算量加倍。本文提出了OUSAC（优化引导调度与自适应缓存）框架，通过系统优化加速扩散变换器（DiT）。我们的核心洞察是：可变的引导尺度可以实现稀疏计算——在某些时间步调整引导尺度可以补偿在其他时间步跳过CFG的操作，从而在保持质量的同时减少总采样步数和CFG步数。然而，可变引导模式会引入去噪偏差，破坏标准缓存方法的有效性（这些方法假设CFG尺度在步间恒定）。此外，在动态条件下，不同的变换器块受到的影响程度不同。本文基于这些洞察开发了一种两阶段方法。第一阶段采用进化算法联合优化跳过哪些时间步以及使用何种引导尺度，最多可消除82%的无条件前向传播。第二阶段引入自适应秩分配，针对每个变换器块定制校准工作，在可变引导下保持缓存有效性。实验表明，OUSAC显著优于最先进的加速方法：在DiT-XL/2（ImageNet 512x512）上实现53%的计算节省和15%的质量提升，在PixArt-alpha（MSCOCO）上实现60%的节省和16.1%的提升，在FLUX上实现5倍加速且CLIP分数超过50步基线。",
            "intro_zh": [
                "扩散模型中无分类器引导（CFG）虽提升质量，但需在每个时间步执行两次前向传播，计算开销加倍，成为加速瓶颈。",
                "提出OUSAC框架，通过可变引导尺度实现稀疏计算，结合进化算法优化调度和自适应缓存，减少CFG步数并保持质量。",
                "实验显示OUSAC在多个模型上显著节省计算并提升质量，如DiT-XL/2节省53%计算且质量提升15%，优于现有方法。"
            ],
            "method_zh": "OUSAC框架采用两阶段方法。整体框架包括：第一阶段使用进化算法联合优化时间步跳过策略和引导尺度，实现稀疏计算，最多减少82%无条件前向传播；第二阶段引入自适应秩分配，针对扩散变换器中不同块在动态引导下的敏感性差异，定制化校准缓存，以应对可变引导导致的去噪偏差。关键技术创新点在于可变引导尺度的调度优化和自适应缓存机制，与现有方法的主要区别在于：传统方法假设恒定CFG尺度，而OUSAC允许尺度变化，并通过系统优化和自适应设计维持缓存有效性，从而在减少计算的同时保持或提升生成质量。",
            "application_zh": "该研究可应用于需要高效高质量图像生成的领域，如创意设计、媒体内容制作、游戏开发和虚拟现实，通过加速扩散模型降低计算成本，提升实时性和可扩展性，具有实际工业价值。",
            "highlight_zh": "OUSAC在多个基准测试中表现优异：DiT-XL/2上节省53%计算且质量提升15%，PixArt-alpha上节省60%计算且提升16.1%，FLUX上实现5倍加速并超越基线CLIP分数，显著优于现有加速方法。",
            "tags_zh": [
                "扩散模型加速",
                "无分类器引导优化",
                "稀疏计算调度",
                "自适应缓存",
                "扩散变换器",
                "进化算法",
                "图像生成效率",
                "计算节省"
            ],
            "_index": 88
        },
        {
            "title": "GaussianPlant: Structure-aligned Gaussian Splatting for 3D Reconstruction of Plants",
            "authors": [
                "Yang Yang",
                "Risa Shinoda",
                "Hiroaki Santo",
                "Fumio Okura"
            ],
            "arxiv_id": "2512.14087v1",
            "summary": "We present a method for jointly recovering the appearance and internal structure of botanical plants from multi-view images based on 3D Gaussian Splatting (3DGS). While 3DGS exhibits robust reconstruction of scene appearance for novel-view synthesis, it lacks structural representations underlying those appearances (e.g., branching patterns of plants), which limits its applicability to tasks such as plant phenotyping. To achieve both high-fidelity appearance and structural reconstruction, we introduce GaussianPlant, a hierarchical 3DGS representation, which disentangles structure and appearance. Specifically, we employ structure primitives (StPs) to explicitly represent branch and leaf geometry, and appearance primitives (ApPs) to the plants' appearance using 3D Gaussians. StPs represent a simplified structure of the plant, i.e., modeling branches as cylinders and leaves as disks. To accurately distinguish the branches and leaves, StP's attributes (i.e., branches or leaves) are optimized in a self-organized manner. ApPs are bound to each StP to represent the appearance of branches or leaves as in conventional 3DGS. StPs and ApPs are jointly optimized using a re-rendering loss on the input multi-view images, as well as the gradient flow from ApP to StP using the binding correspondence information. We conduct experiments to qualitatively evaluate the reconstruction accuracy of both appearance and structure, as well as real-world experiments to qualitatively validate the practical performance. Experiments show that the GaussianPlant achieves both high-fidelity appearance reconstruction via ApPs and accurate structural reconstruction via StPs, enabling the extraction of branch structure and leaf instances.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Submitted to IEEE TPAMI, under review",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14087v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "深度估计",
                    "matched_keywords": [
                        "3D reconstruction"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出GaussianPlant方法，通过解耦结构和外观的高斯溅射表示，实现植物高保真三维重建，以解决植物表型分析等应用中的结构缺失问题。",
            "summary_zh": "我们提出了一种基于3D高斯溅射（3DGS）的方法，用于从多视角图像中联合恢复植物外观和内部结构。虽然3DGS在新视角合成中表现出强大的场景外观重建能力，但它缺乏支撑这些外观的结构表示（例如植物的分枝模式），这限制了其在植物表型分析等任务中的应用。为了实现高保真外观和结构重建，我们引入了GaussianPlant，这是一种分层3DGS表示，解耦了结构和外观。具体而言，我们使用结构基元（StPs）来显式表示枝干和叶片的几何形状，并使用外观基元（ApPs）通过3D高斯表示植物的外观。StPs表示植物的简化结构，即将枝干建模为圆柱体、叶片建模为圆盘。为了准确区分枝干和叶片，StP的属性（即枝干或叶片）以自组织方式进行优化。ApPs绑定到每个StP，以像传统3DGS那样表示枝干或叶片的外观。StPs和ApPs通过输入多视角图像的重渲染损失以及利用绑定对应信息从ApP到StP的梯度流进行联合优化。我们进行了实验，定性和定量评估外观和结构的重建准确性，以及实际实验来定性验证实际性能。实验表明，GaussianPlant通过ApPs实现了高保真外观重建，通过StPs实现了准确结构重建，从而能够提取枝干结构和叶片实例。",
            "intro_zh": [
                "现有3D高斯溅射方法在植物重建中缺乏结构表示，如分枝模式，限制了其在表型分析等任务的应用。",
                "提出GaussianPlant，通过结构基元和外观基元解耦表示，实现植物外观与结构的联合优化重建。",
                "实验验证了该方法在植物外观和结构重建上的高保真性能，能够有效提取枝干和叶片实例。"
            ],
            "method_zh": "GaussianPlant采用分层3D高斯溅射框架，核心创新在于解耦结构和外观表示。结构基元（StPs）显式建模枝干为圆柱体、叶片为圆盘，通过自组织优化区分属性；外观基元（ApPs）绑定到StPs，使用3D高斯表示外观。两者通过重渲染损失和基于绑定信息的梯度流联合优化。与现有3DGS方法相比，该方法首次引入显式结构表示，解决了植物重建中结构缺失问题，实现了外观与结构的高效协同学习。",
            "application_zh": "该方法在植物表型分析、农业监测、植物生长建模和虚拟植物展示等领域具有应用价值，能够提供精确的枝干结构和叶片实例数据，支持植物健康评估和科学研究。",
            "highlight_zh": "实验表明，GaussianPlant在植物三维重建中同时实现了高保真外观和准确结构恢复，通过ApPs和StPs的协同优化，显著提升了结构提取能力，为植物分析任务提供了可靠的三维模型。",
            "tags_zh": [
                "三维高斯溅射",
                "植物三维重建",
                "结构外观解耦",
                "多视角图像处理",
                "植物表型分析",
                "分层表示学习",
                "自组织优化",
                "梯度流联合训练"
            ],
            "_index": 89
        },
        {
            "title": "RADAR: Accelerating Large Language Model Inference With RL-Based Dynamic Draft Trees",
            "authors": [
                "Junjie Ma",
                "Jinlong Li"
            ],
            "arxiv_id": "2512.14069v1",
            "summary": "Inference with modern Large Language Models (LLMs) is expensive and slow, and speculative sampling has emerged as an effective solution to this problem, however, the number of the calls to the draft model for generating candidate tokens in speculative sampling is a preset hyperparameter, lacking flexibility. To generate and utilize the candidate tokens more effectively, we propose RADAR, a novel speculative sampling method with RL-based dynamic draft trees. RADAR formulates the draft tree generation process as a Markov Decision Process (MDP) and employs offline reinforcement learning to train a prediction model, which enables real-time decision on the calls to the draft model, reducing redundant computations and further accelerating inference. Evaluations across three LLMs and four tasks show that RADAR achieves a speedup of 3.17x-4.82x over the auto-regressive decoding baseline. The code is available at https://github.com/minaduki-sora/RADAR.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "5 pages, 2 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14069v1",
            "code_links": [
                {
                    "url": "https://github.com/minaduki-sora/RADAR",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "reinforcement learning",
                        "RL"
                    ],
                    "score": 2
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出RADAR方法，基于强化学习的动态草稿树加速大语言模型推理",
            "summary_zh": "现代大语言模型（LLMs）的推理过程成本高昂且速度缓慢，推测采样已成为解决此问题的有效方案。然而，推测采样中用于生成候选标记的草稿模型调用次数是一个预设的超参数，缺乏灵活性。为了更有效地生成和利用候选标记，我们提出了RADAR，这是一种基于强化学习动态草稿树的新型推测采样方法。RADAR将草稿树生成过程建模为马尔可夫决策过程（MDP），并采用离线强化学习训练预测模型，从而实现对草稿模型调用的实时决策，减少冗余计算并进一步加速推理。在三个LLM和四个任务上的评估表明，RADAR相比自回归解码基线实现了3.17倍至4.82倍的加速。代码可在https://github.com/minaduki-sora/RADAR获取。",
            "intro_zh": [
                "现有推测采样方法中草稿模型调用次数固定，缺乏灵活性，导致计算冗余和效率低下。",
                "RADAR将草稿树生成建模为MDP，利用离线强化学习训练预测模型，动态决定草稿模型调用。",
                "实验显示RADAR在多个LLM和任务上实现3.17-4.82倍加速，显著提升推理效率。"
            ],
            "method_zh": "RADAR的整体框架是基于推测采样的改进方法，核心创新在于引入动态草稿树生成机制。该方法将草稿树生成过程形式化为马尔可夫决策过程（MDP），其中状态包括当前上下文和候选标记，动作是决定是否继续调用草稿模型生成更多候选标记。通过离线强化学习训练一个预测模型，该模型能够实时评估每个决策点的价值，从而动态调整草稿树的深度和结构，减少不必要的草稿模型调用。与现有推测采样方法的主要区别在于，传统方法使用固定次数的草稿模型调用（即静态草稿树），而RADAR通过强化学习实现自适应决策，优化计算资源分配。",
            "application_zh": "RADAR可广泛应用于需要高效LLM推理的场景，如实时对话系统、代码生成、文本摘要和机器翻译等。其动态决策机制能降低计算成本，提升响应速度，适用于云服务和边缘设备部署，具有实际商业价值。",
            "highlight_zh": "在三个大语言模型和四个任务上的评估中，RADAR相比自回归解码基线实现了3.17倍至4.82倍的加速，显著超越传统推测采样方法，证明了动态草稿树在减少冗余计算和提升推理效率方面的有效性。",
            "tags_zh": [
                "大语言模型推理加速",
                "推测采样",
                "强化学习",
                "动态草稿树",
                "马尔可夫决策过程",
                "离线强化学习",
                "计算优化",
                "实时决策"
            ],
            "_index": 90
        },
        {
            "title": "OpenDataArena: A Fair and Open Arena for Benchmarking Post-Training Dataset Value",
            "authors": [
                "Mengzhang Cai",
                "Xin Gao",
                "Yu Li",
                "Honglin Lin",
                "Zheng Liu",
                "Zhuoshi Pan",
                "Qizhi Pei",
                "Xiaoran Shang",
                "Mengyuan Sun",
                "Zinan Tang",
                "Xiaoyang Wang",
                "Zhanping Zhong",
                "Yun Zhu",
                "Dahua Lin",
                "Conghui He",
                "Lijun Wu"
            ],
            "arxiv_id": "2512.14051v1",
            "summary": "The rapid evolution of Large Language Models (LLMs) is predicated on the quality and diversity of post-training datasets. However, a critical dichotomy persists: while models are rigorously benchmarked, the data fueling them remains a black box--characterized by opaque composition, uncertain provenance, and a lack of systematic evaluation. This opacity hinders reproducibility and obscures the causal link between data characteristics and model behaviors. To bridge this gap, we introduce OpenDataArena (ODA), a holistic and open platform designed to benchmark the intrinsic value of post-training data. ODA establishes a comprehensive ecosystem comprising four key pillars: (i) a unified training-evaluation pipeline that ensures fair, open comparisons across diverse models (e.g., Llama, Qwen) and domains; (ii) a multi-dimensional scoring framework that profiles data quality along tens of distinct axes; (iii) an interactive data lineage explorer to visualize dataset genealogy and dissect component sources; and (iv) a fully open-source toolkit for training, evaluation, and scoring to foster data research. Extensive experiments on ODA--covering over 120 training datasets across multiple domains on 22 benchmarks, validated by more than 600 training runs and 40 million processed data points--reveal non-trivial insights. Our analysis uncovers the inherent trade-offs between data complexity and task performance, identifies redundancy in popular benchmarks through lineage tracing, and maps the genealogical relationships across datasets. We release all results, tools, and configurations to democratize access to high-quality data evaluation. Rather than merely expanding a leaderboard, ODA envisions a shift from trial-and-error data curation to a principled science of Data-Centric AI, paving the way for rigorous studies on data mixing laws and the strategic composition of foundation models.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14051v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO",
                        "VIO"
                    ],
                    "score": 2
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出OpenDataArena平台以解决大语言模型后训练数据集评估不透明的问题",
            "summary_zh": "大语言模型的快速发展依赖于后训练数据集的质量和多样性，但当前存在一个关键矛盾：模型被严格基准测试，而支撑它们的数据却是一个黑箱——其组成不透明、来源不确定且缺乏系统评估。这种不透明性阻碍了可重复性，并模糊了数据特征与模型行为之间的因果关系。为弥合这一差距，我们引入了OpenDataArena，这是一个全面开放的平台，旨在基准测试后训练数据的内在价值。ODA建立了一个包含四个关键支柱的综合生态系统：(i) 一个统一的训练-评估管道，确保在不同模型和领域间进行公平、开放的比较；(ii) 一个多维评分框架，从数十个不同维度分析数据质量；(iii) 一个交互式数据谱系探索器，可视化数据集谱系并剖析组件来源；(iv) 一个完全开源的工具包，用于训练、评估和评分，以促进数据研究。在ODA上进行的大量实验——涵盖多个领域的120多个训练数据集、22个基准测试，通过超过600次训练运行和4000万个处理数据点验证——揭示了非平凡的见解。我们的分析揭示了数据复杂性与任务性能之间的内在权衡，通过谱系追踪识别了流行基准中的冗余，并绘制了数据集间的谱系关系。我们发布所有结果、工具和配置，以民主化高质量数据评估的访问。ODA不仅扩展了排行榜，更旨在从试错式数据策展转向以数据为中心的人工智能原则科学，为数据混合规律和基础模型战略组成的研究铺平道路。",
            "intro_zh": [
                "核心问题：大语言模型后训练数据评估不透明，数据组成、来源和系统性评估缺失，阻碍可重复性和因果分析。",
                "方法要点：提出OpenDataArena平台，通过统一训练-评估管道、多维评分框架、数据谱系探索器和开源工具包，实现公平开放的数据基准测试。",
                "实验或效果：实验涵盖120多个数据集和22个基准，揭示数据复杂性与性能的权衡，识别基准冗余，并绘制数据集谱系关系。"
            ],
            "method_zh": "OpenDataArena是一个全面开放的平台，其核心框架包括四个关键支柱：统一的训练-评估管道，支持多种模型和领域，确保公平比较；多维评分框架，从数十个维度分析数据质量；交互式数据谱系探索器，可视化数据集谱系和来源；以及开源工具包，促进数据研究。技术创新点在于整合了数据评估的多个方面，从训练到谱系分析，形成一个生态系统。与现有方法的主要区别在于，ODA不仅关注模型性能，还系统评估数据本身的价值，解决了数据黑箱问题，提供了透明和可重复的评估标准。",
            "application_zh": "该研究可应用于大语言模型开发、数据策展和人工智能研究领域，帮助研究人员和开发者评估和优化后训练数据集，提高模型性能，促进数据驱动的AI发展，具有推动数据科学和模型可解释性的实际价值。",
            "highlight_zh": "实验覆盖120多个训练数据集和22个基准，通过600多次训练运行验证，揭示了数据复杂性与任务性能的权衡，识别了流行基准中的冗余，并绘制了数据集间的谱系关系，为数据评估提供了新见解。",
            "tags_zh": [
                "大语言模型",
                "后训练数据集",
                "数据评估",
                "基准测试",
                "数据谱系",
                "开源平台",
                "数据质量分析",
                "人工智能研究"
            ],
            "_index": 91
        },
        {
            "title": "Evaluating Small Language Models for Agentic On-Farm Decision Support Systems",
            "authors": [
                "Enhong Liu",
                "Haiyu Yang",
                "Miel Hostens"
            ],
            "arxiv_id": "2512.14043v1",
            "summary": "Large Language Models (LLM) hold potential to support dairy scholars and farmers by supporting decision-making and broadening access to knowledge for stakeholders with limited technical expertise. However, the substantial computational demand restricts access to LLM almost exclusively through cloud-based service, which makes LLM-based decision support tools impractical for dairy farming. To address this gap, lightweight alternatives capable of running locally on farm hardware are required. In this work, we benchmarked 20 open-source Small Language Models (SLM) available on HuggingFace under farm-realistic computing constraints. Building on our prior work, we developed an agentic AI system that integrates five task-specific agents: literature search, web search, SQL database interaction, NoSQL database interaction, and graph generation following predictive models. Evaluation was conducted in two phases. In the first phase, five test questions were used for the initial screening to identify models capable of following basic dairy-related instructions and performing reliably in a compute-constrained environment. Models that passed this preliminary stage were then evaluated using 30 questions (five per task category mentioned above, plus one category addressing integrity and misconduct) in phase two. In results, Qwen-4B achieved superior performance across most of task categories, although showed unstable effectiveness in NoSQL database interactions through PySpark. To our knowledge, this is the first work explicitly evaluating the feasibility of SLM as engines for dairy farming decision-making, with central emphases on privacy and computational efficiency. While results highlight the promise of SLM-assisted tools for practical deployment in dairy farming, challenges remain, and fine-tuning is still needed to refine SLM performance in dairy-specific questions.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14043v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "世界模型",
                    "matched_keywords": [
                        "predictive model"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "PPO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "评估小型语言模型作为乳业农场决策支持系统的可行性，强调隐私与计算效率",
            "summary_zh": "大型语言模型（LLM）有潜力通过支持决策制定和扩大知识获取来帮助乳业学者和农民，特别是对那些技术专业知识有限的利益相关者。然而，巨大的计算需求使得LLM几乎只能通过基于云的服务访问，这使得基于LLM的决策支持工具在乳业农场中不切实际。为了解决这一差距，需要能够在农场硬件上本地运行的轻量级替代方案。在这项工作中，我们在农场现实计算约束下，对HuggingFace上可用的20个开源小型语言模型（SLM）进行了基准测试。基于我们之前的工作，我们开发了一个代理式AI系统，该系统集成了五个任务特定的代理：文献搜索、网络搜索、SQL数据库交互、NoSQL数据库交互以及基于预测模型的图生成。评估分两个阶段进行。在第一阶段，使用五个测试问题进行初步筛选，以识别能够遵循基本乳业相关指令并在计算受限环境中可靠运行的模型。通过初步阶段的模型随后在第二阶段使用30个问题（上述每个任务类别五个，加上一个涉及完整性和不当行为的类别）进行评估。在结果中，Qwen-4B在大多数任务类别中实现了卓越性能，尽管在通过PySpark进行NoSQL数据库交互时表现出不稳定的有效性。据我们所知，这是第一项明确评估SLM作为乳业农场决策引擎可行性的工作，重点关注隐私和计算效率。虽然结果突出了SLM辅助工具在乳业农场实际部署中的前景，但挑战仍然存在，并且仍需要微调以优化SLM在乳业特定问题中的性能。",
            "intro_zh": [
                "核心问题：大型语言模型计算需求高，依赖云服务，在乳业农场中不切实际，限制了决策支持工具的部署。",
                "方法要点：开发代理式AI系统，集成五个任务特定代理，在农场硬件约束下评估20个开源小型语言模型。",
                "实验或效果：Qwen-4B在多数任务中表现优异，但NoSQL交互不稳定，证明了SLM在乳业决策中的潜力。"
            ],
            "method_zh": "论文的核心方法是开发一个代理式AI系统，该系统集成了五个任务特定代理：文献搜索、网络搜索、SQL数据库交互、NoSQL数据库交互和基于预测模型的图生成。整体框架基于农场现实计算约束，对20个开源小型语言模型进行基准测试。关键技术创新点在于首次将SLM作为乳业农场决策引擎进行可行性评估，并构建多代理系统以模拟实际决策流程。与现有方法的主要区别在于，现有研究多关注大型语言模型在云端的应用，而本工作专注于轻量级、本地化的小型语言模型，强调隐私保护和计算效率，解决了乳业农场中资源受限环境下的实际部署问题。",
            "application_zh": "该研究主要应用于乳业农场决策支持系统，帮助农民和学者进行数据驱动的决策制定，如疾病预测、资源管理和知识查询。潜在价值在于提供本地化、隐私保护的AI工具，降低技术门槛，提升农场运营效率。",
            "highlight_zh": "最重要的实验结果是Qwen-4B在大多数任务类别中表现最佳，证明了小型语言模型在乳业决策中的可行性。性能提升体现在计算效率高、隐私保护强，但NoSQL数据库交互存在不稳定性，表明仍需优化。",
            "tags_zh": [
                "小型语言模型",
                "乳业农场决策",
                "代理式AI系统",
                "计算效率",
                "隐私保护",
                "基准测试",
                "本地化部署",
                "多任务评估"
            ],
            "_index": 92
        },
        {
            "title": "Sample-Efficient Robot Skill Learning for Construction Tasks: Benchmarking Hierarchical Reinforcement Learning and Vision-Language-Action VLA Model",
            "authors": [
                "Zhaofeng Hu",
                "Hongrui Yu",
                "Vaidhyanathan Chandramouli",
                "Ci-Jyun Liang"
            ],
            "arxiv_id": "2512.14031v1",
            "summary": "This study evaluates two leading approaches for teaching construction robots new skills to understand their applicability for construction automation: a Vision-Language-Action (VLA) model and Reinforcement Learning (RL) methods. The goal is to understand both task performance and the practical effort needed to deploy each approach on real jobs. The authors developed two teleoperation interfaces to control the robots and collect the demonstrations needed, both of which proved effective for training robots for long-horizon and dexterous tasks. In addition, the authors conduct a three-stage evaluation. First, the authors compare a Multi-Layer Perceptron (MLP) policy with a Deep Q-network (DQN) imitation model to identify the stronger RL baseline, focusing on model performance, generalization, and a pick-up experiment. Second, three different VLA models are trained in two different scenarios and compared with each other. Third, the authors benchmark the selected RL baseline against the VLA model using computational and sample-efficiency measures and then a robot experiment on a multi-stage panel installation task that includes transport and installation. The VLA model demonstrates strong generalization and few-shot capability, achieving 60% and 100% success in the pickup phase. In comparison, DQN can be made robust but needs additional noise during tuning, which increases the workload. Overall, the findings indicate that VLA offers practical advantages for changing tasks by reducing programming effort and enabling useful performance with minimal data, while DQN provides a viable baseline when sufficient tuning effort is acceptable.",
            "categories": [
                "cs.RO",
                "cs.AI"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14031v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "reinforcement learning",
                        "RL"
                    ],
                    "score": 2
                }
            ],
            "relevance_score": 2,
            "headline_zh": "评估VLA模型与分层强化学习在建筑机器人技能学习中的样本效率与实用性",
            "summary_zh": "本研究评估了两种用于教授建筑机器人新技能的主流方法——视觉-语言-动作（VLA）模型和强化学习（RL）方法，以理解它们在建筑自动化中的适用性。目标是了解任务性能以及在真实工作中部署每种方法所需的实际工作量。作者开发了两个遥操作接口来控制机器人并收集所需的演示，这两种接口都被证明对训练机器人执行长期和灵巧任务有效。此外，作者进行了三阶段评估。首先，比较多层感知器（MLP）策略与深度Q网络（DQN）模仿模型，以确定更强的RL基线，重点关注模型性能、泛化能力和拾取实验。其次，在两种不同场景中训练三种不同的VLA模型并进行比较。第三，使用计算和样本效率指标对选定的RL基线与VLA模型进行基准测试，然后进行包括运输和安装在内的多阶段面板安装任务的机器人实验。VLA模型表现出强大的泛化和少样本能力，在拾取阶段实现了60%和100%的成功率。相比之下，DQN可以变得稳健，但需要在调优期间添加额外噪声，这增加了工作量。总体而言，研究结果表明，VLA通过减少编程工作量和用最少数据实现有用性能，为任务变更提供了实际优势，而DQN在可接受足够调优工作量的情况下提供了可行的基线。",
            "intro_zh": [
                "核心问题：建筑自动化中机器人技能学习面临样本效率低、泛化能力差和部署工作量大的挑战，现有方法难以平衡性能与实用性。",
                "方法要点：通过系统评估VLA模型与分层RL方法，结合遥操作接口收集演示，比较其在样本效率、泛化和实际部署中的表现。",
                "实验或效果：VLA在少样本场景下实现高成功率（60%-100%），而DQN需额外调优但提供稳健基线，为实际应用提供指导。"
            ],
            "method_zh": "论文采用系统评估框架，核心方法包括：1）开发两种遥操作接口收集机器人演示数据，支持长期和灵巧任务训练；2）三阶段评估流程：首先比较MLP与DQN作为RL基线，其次训练三种VLA模型在不同场景下对比，最后通过计算和样本效率指标及多阶段面板安装实验基准测试VLA与DQN。关键创新点在于将VLA模型与分层RL方法在建筑任务中直接对比，突出样本效率和泛化能力。与现有方法的主要区别在于综合评估了VLA的少样本学习优势和RL的调优需求，为实际部署提供实用指南。",
            "application_zh": "该研究主要应用于建筑自动化领域，如机器人面板安装、运输和灵巧操作任务，可减少人工编程工作量，提升机器人技能学习的效率和适应性，推动智能建造和工业机器人发展。",
            "highlight_zh": "VLA模型在拾取实验中展现出色泛化能力，少样本下实现60%和100%成功率；DQN虽稳健但需额外噪声调优增加工作量；整体上VLA在样本效率和实用性上优于RL基线。",
            "tags_zh": [
                "建筑机器人",
                "视觉-语言-动作模型",
                "分层强化学习",
                "样本效率",
                "少样本学习",
                "机器人技能学习",
                "多阶段任务",
                "泛化能力"
            ],
            "_index": 93
        },
        {
            "title": "MobileWorldBench: Towards Semantic World Modeling For Mobile Agents",
            "authors": [
                "Shufan Li",
                "Konstantinos Kallidromitis",
                "Akash Gokul",
                "Yusuke Kato",
                "Kazuki Kozuka",
                "Aditya Grover"
            ],
            "arxiv_id": "2512.14014v1",
            "summary": "World models have shown great utility in improving the task performance of embodied agents. While prior work largely focuses on pixel-space world models, these approaches face practical limitations in GUI settings, where predicting complex visual elements in future states is often difficult. In this work, we explore an alternative formulation of world modeling for GUI agents, where state transitions are described in natural language rather than predicting raw pixels. First, we introduce MobileWorldBench, a benchmark that evaluates the ability of vision-language models (VLMs) to function as world models for mobile GUI agents. Second, we release MobileWorld, a large-scale dataset consisting of 1.4M samples, that significantly improves the world modeling capabilities of VLMs. Finally, we propose a novel framework that integrates VLM world models into the planning framework of mobile agents, demonstrating that semantic world models can directly benefit mobile agents by improving task success rates. The code and dataset is available at https://github.com/jacklishufan/MobileWorld",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "21 pages, 13 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14014v1",
            "code_links": [
                {
                    "url": "https://github.com/jacklishufan/MobileWorld",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "世界模型",
                    "matched_keywords": [
                        "world model"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出MobileWorldBench基准和MobileWorld数据集，通过语义世界建模提升移动GUI代理的任务成功率。",
            "summary_zh": "世界模型在提升具身代理任务性能方面显示出巨大效用。先前工作主要关注像素空间世界模型，但这些方法在GUI设置中面临实际限制，预测未来状态的复杂视觉元素通常很困难。在本工作中，我们探索了GUI代理世界建模的替代方案，其中状态转换用自然语言描述，而不是预测原始像素。首先，我们引入了MobileWorldBench，这是一个评估视觉语言模型作为移动GUI代理世界模型能力的基准。其次，我们发布了MobileWorld，一个包含140万个样本的大规模数据集，显著提升了视觉语言模型的世界建模能力。最后，我们提出了一个新颖框架，将视觉语言模型世界模型集成到移动代理的规划框架中，证明语义世界模型可以通过提高任务成功率直接使移动代理受益。代码和数据集可在https://github.com/jacklishufan/MobileWorld获取。",
            "intro_zh": [
                "现有像素空间世界模型在GUI环境中预测复杂视觉元素困难，限制了移动代理的实际应用。",
                "论文提出用自然语言描述状态转换的语义世界建模方法，替代传统像素预测，并引入基准和数据集。",
                "实验表明，集成视觉语言模型世界模型能显著提升移动代理的任务成功率，验证了语义建模的有效性。"
            ],
            "method_zh": "论文提出一个集成视觉语言模型世界模型到移动代理规划框架的新颖框架。整体框架包括MobileWorldBench基准评估视觉语言模型作为世界模型的能力，以及MobileWorld数据集用于训练和提升模型性能。关键技术创新点在于将状态转换从像素空间迁移到语义空间，用自然语言描述GUI状态变化，避免了复杂视觉预测的困难。与现有方法的主要区别在于，传统方法依赖像素级预测，而本方法利用视觉语言模型的语义理解能力，更适用于GUI环境，提高了世界建模的实用性和可扩展性。",
            "application_zh": "该研究主要应用于移动GUI代理领域，如智能手机应用自动化、机器人界面交互和智能助手任务执行。通过语义世界建模，代理能更准确地理解和预测GUI状态变化，提升任务完成效率和成功率，具有实际部署价值。",
            "highlight_zh": "实验结果显示，使用MobileWorld数据集训练的视觉语言模型世界模型在MobileWorldBench基准上表现优异，集成到移动代理规划框架后，任务成功率得到显著提升，具体数值未知，但验证了语义世界建模对移动代理性能的积极影响。",
            "tags_zh": [
                "语义世界建模",
                "移动GUI代理",
                "视觉语言模型",
                "基准评估",
                "大规模数据集",
                "规划框架",
                "自然语言描述",
                "任务成功率提升"
            ],
            "_index": 94
        },
        {
            "title": "Professional Software Developers Don't Vibe, They Control: AI Agent Use for Coding in 2025",
            "authors": [
                "Ruanqianqian Huang",
                "Avery Reyna",
                "Sorin Lerner",
                "Haijun Xia",
                "Brian Hempel"
            ],
            "arxiv_id": "2512.14012v1",
            "summary": "The rise of AI agents is transforming how software can be built. The promise of agents is that developers might write code quicker, delegate multiple tasks to different agents, and even write a full piece of software purely out of natural language. In reality, what roles agents play in professional software development remains in question. This paper investigates how experienced developers use agents in building software, including their motivations, strategies, task suitability, and sentiments. Through field observations (N=13) and qualitative surveys (N=99), we find that while experienced developers value agents as a productivity boost, they retain their agency in software design and implementation out of insistence on fundamental software quality attributes, employing strategies for controlling agent behavior leveraging their expertise. In addition, experienced developers feel overall positive about incorporating agents into software development given their confidence in complementing the agents' limitations. Our results shed light on the value of software development best practices in effective use of agents, suggest the kinds of tasks for which agents may be suitable, and point towards future opportunities for better agentic interfaces and agentic use guidelines.",
            "categories": [
                "cs.SE",
                "cs.AI",
                "cs.HC"
            ],
            "primary_category": "cs.SE",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14012v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VIO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "PPO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "通过实地观察和定性调查揭示专业开发者如何控制AI代理以提升软件质量与生产力。",
            "summary_zh": "AI代理的兴起正在改变软件构建方式，其承诺是开发者可能更快地编写代码、将多个任务委托给不同代理，甚至纯粹用自然语言编写完整软件。然而，代理在专业软件开发中扮演的角色仍存疑问。本文通过实地观察（N=13）和定性调查（N=99），研究了经验丰富的开发者如何在构建软件时使用代理，包括他们的动机、策略、任务适用性和情感态度。研究发现，尽管经验丰富的开发者重视代理作为生产力提升工具，但他们出于对基本软件质量属性的坚持，在软件设计和实现中保留自主权，利用自身专业知识控制代理行为。此外，经验丰富的开发者对将代理融入软件开发持总体积极态度，因为他们有信心弥补代理的局限性。研究结果揭示了软件开发最佳实践在有效使用代理中的价值，提出了代理可能适用的任务类型，并指出了未来改进代理界面和使用指南的机会。",
            "intro_zh": [
                "核心问题：AI代理在专业软件开发中的实际角色和有效性尚不明确，开发者如何平衡代理使用与软件质量控制是关键挑战。",
                "方法要点：采用实地观察和定性调查相结合的方法，深入分析经验丰富开发者的代理使用动机、策略和情感态度。",
                "实验或效果：发现开发者通过专业知识控制代理行为，对代理融入持积极态度，并识别出代理适用的任务类型。"
            ],
            "method_zh": "论文采用混合研究方法，整体框架包括实地观察和定性调查两部分。实地观察涉及13名经验丰富的专业开发者，直接记录他们在实际软件开发项目中使用AI代理的行为和决策过程；定性调查则通过问卷收集了99名开发者的反馈，涵盖代理使用动机、策略、任务适用性和情感态度等多个维度。关键技术创新点在于将人类因素研究引入AI代理应用领域，通过实证数据揭示开发者与代理的互动模式。与现有方法的主要区别在于，现有研究多关注代理技术本身或简单用户测试，而本文深入探讨了专业环境下的实际使用情况，强调开发者的控制策略和软件质量考量。",
            "application_zh": "该研究可应用于软件开发工具设计、AI代理界面优化和行业培训指南制定。通过理解专业开发者的控制需求，能设计更符合实际工作流程的代理系统，提升软件工程效率和质量，同时为企业和教育机构提供代理使用最佳实践参考。",
            "highlight_zh": "最重要的实验结果是：经验丰富的开发者通过专业知识主动控制代理行为，以保障软件质量；他们对代理融入持总体积极态度，但强调自主权；研究识别出代理适合的任务类型，为未来工具设计提供依据。性能提升体现在生产力增强与质量控制的平衡。",
            "tags_zh": [
                "AI代理",
                "软件开发",
                "人机交互",
                "质量控制",
                "实地观察",
                "定性调查",
                "专业开发者",
                "生产力提升"
            ],
            "_index": 95
        },
        {
            "title": "CLAIM: Camera-LiDAR Alignment with Intensity and Monodepth",
            "authors": [
                "Zhuo Zhang",
                "Yonghui Liu",
                "Meijie Zhang",
                "Feiyang Tan",
                "Yikang Ding"
            ],
            "arxiv_id": "2512.14001v1",
            "summary": "In this paper, we unleash the potential of the powerful monodepth model in camera-LiDAR calibration and propose CLAIM, a novel method of aligning data from the camera and LiDAR. Given the initial guess and pairs of images and LiDAR point clouds, CLAIM utilizes a coarse-to-fine searching method to find the optimal transformation minimizing a patched Pearson correlation-based structure loss and a mutual information-based texture loss. These two losses serve as good metrics for camera-LiDAR alignment results and require no complicated steps of data processing, feature extraction, or feature matching like most methods, rendering our method simple and adaptive to most scenes. We validate CLAIM on public KITTI, Waymo, and MIAS-LCEC datasets, and the experimental results demonstrate its superior performance compared with the state-of-the-art methods. The code is available at https://github.com/Tompson11/claim.",
            "categories": [
                "cs.RO",
                "cs.CV"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Accepted by IROS 2025",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14001v1",
            "code_links": [
                {
                    "url": "https://github.com/Tompson11/claim",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "自动驾驶",
                    "matched_keywords": [
                        "lidar",
                        "waymo"
                    ],
                    "score": 2
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出CLAIM方法，利用单目深度模型和粗到精搜索策略，解决相机与LiDAR数据对齐问题，无需复杂特征处理。",
            "summary_zh": "本文释放了强大单目深度模型在相机-LiDAR标定中的潜力，提出了CLAIM，一种新颖的相机与LiDAR数据对齐方法。给定初始猜测和图像-LiDAR点云对，CLAIM采用粗到精搜索策略，寻找最优变换以最小化基于补丁皮尔逊相关的结构损失和基于互信息的纹理损失。这两种损失作为相机-LiDAR对齐结果的良好度量，无需像大多数方法那样进行复杂的数据处理、特征提取或特征匹配步骤，使我们的方法简单且适应大多数场景。我们在公开的KITTI、Waymo和MIAS-LCEC数据集上验证了CLAIM，实验结果表明其性能优于最先进的方法。代码可在https://github.com/Tompson11/claim获取。",
            "intro_zh": [
                "现有相机-LiDAR对齐方法通常依赖复杂的数据处理、特征提取或匹配步骤，导致计算成本高且适应性受限。",
                "CLAIM利用单目深度模型，通过粗到精搜索最小化结构损失和纹理损失，实现高效对齐，无需复杂特征处理。",
                "在KITTI、Waymo和MIAS-LCEC数据集上，CLAIM表现出优于现有方法的性能，验证了其有效性和泛化能力。"
            ],
            "method_zh": "CLAIM的整体框架基于粗到精搜索策略，输入初始变换猜测和图像-LiDAR点云对，迭代优化变换参数。关键技术创新包括：使用基于补丁皮尔逊相关的结构损失来度量几何对齐，以及基于互信息的纹理损失来评估外观一致性。与现有方法的主要区别在于，CLAIM无需复杂的特征提取或匹配步骤，直接利用单目深度模型和损失函数，简化了流程并提高了适应性。",
            "application_zh": "该研究可应用于自动驾驶、机器人导航和增强现实等领域，通过精确对齐相机与LiDAR数据，提升多模态感知系统的准确性和鲁棒性，支持环境建模和物体检测任务。",
            "highlight_zh": "在KITTI、Waymo和MIAS-LCEC数据集上的实验显示，CLAIM在相机-LiDAR对齐任务中性能优于最先进方法，验证了其损失函数的有效性和方法的泛化能力，代码已开源。",
            "tags_zh": [
                "相机-LiDAR对齐",
                "单目深度模型",
                "粗到精搜索",
                "结构损失",
                "纹理损失",
                "多模态融合",
                "自动驾驶",
                "点云处理"
            ],
            "_index": 96
        },
        {
            "title": "On the Hardness of Conditional Independence Testing In Practice",
            "authors": [
                "Zheng He",
                "Roman Pogodin",
                "Yazhe Li",
                "Namrata Deka",
                "Arthur Gretton",
                "Danica J. Sutherland"
            ],
            "arxiv_id": "2512.14000v1",
            "summary": "Tests of conditional independence (CI) underpin a number of important problems in machine learning and statistics, from causal discovery to evaluation of predictor fairness and out-of-distribution robustness. Shah and Peters (2020) showed that, contrary to the unconditional case, no universally finite-sample valid test can ever achieve nontrivial power. While informative, this result (based on \"hiding\" dependence) does not seem to explain the frequent practical failures observed with popular CI tests. We investigate the Kernel-based Conditional Independence (KCI) test - of which we show the Generalized Covariance Measure underlying many recent tests is nearly a special case - and identify the major factors underlying its practical behavior. We highlight the key role of errors in the conditional mean embedding estimate for the Type-I error, while pointing out the importance of selecting an appropriate conditioning kernel (not recognized in previous work) as being necessary for good test power but also tending to inflate Type-I error.",
            "categories": [
                "stat.ML",
                "cs.LG",
                "stat.ME"
            ],
            "primary_category": "stat.ML",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Published at NeurIPS 2025: https://openreview.net/forum?id=Tn1M71PDfF",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14000v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VIO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "揭示核条件独立性测试的实践难点，强调条件均值嵌入误差和核选择对性能的关键影响。",
            "summary_zh": "条件独立性测试在机器学习和统计学中至关重要，支撑着从因果发现到预测器公平性和分布外鲁棒性评估等多个重要问题。Shah和Peters（2020）的研究表明，与无条件情况不同，不存在普遍有限样本有效的测试能够实现非平凡功效。尽管这一结果（基于“隐藏”依赖性）具有启发性，但它似乎未能解释实践中常见CI测试频繁失败的现象。本文研究了基于核的条件独立性测试——我们展示了其作为许多近期测试基础的广义协方差度量几乎是一个特例——并识别了影响其实践行为的主要因素。我们强调了条件均值嵌入估计误差对第一类错误的关键作用，同时指出选择适当的条件核（先前工作中未被认识到）对于良好测试功效的必要性，但也倾向于增加第一类错误。",
            "intro_zh": [
                "核心问题：现有条件独立性测试在实践中常失败，Shah和Peters的理论结果未能完全解释这些实际困难。",
                "方法要点：聚焦核条件独立性测试，分析条件均值嵌入误差和核选择对测试性能的影响机制。",
                "实验或效果：识别出关键因素，如误差导致第一类错误增加，核选择影响功效但可能加剧错误。"
            ],
            "method_zh": "论文以核条件独立性测试为核心框架，通过理论分析和实验验证，深入探讨其实践行为。关键技术创新点在于揭示了条件均值嵌入估计误差对第一类错误的主导作用，并首次强调了条件核选择的重要性——这不仅对提升测试功效至关重要，还可能引发错误膨胀。与现有方法的主要区别在于，本文不仅关注理论极限，还从实际应用角度出发，系统分析了测试失败的具体原因，特别是将广义协方差度量视为KCI测试的特例，从而统一了多个近期测试的视角。",
            "application_zh": "该研究在因果发现、机器学习模型公平性评估和分布外鲁棒性测试等领域具有重要应用价值，能帮助改进条件独立性测试的实践可靠性，提升相关算法在真实世界数据中的性能。",
            "highlight_zh": "实验结果表明，条件均值嵌入误差是导致第一类错误增加的主要因素，而条件核选择虽能提升测试功效，但需谨慎以避免错误膨胀，这为优化CI测试提供了具体指导。",
            "tags_zh": [
                "条件独立性测试",
                "核方法",
                "条件均值嵌入",
                "第一类错误",
                "测试功效",
                "因果发现",
                "机器学习公平性",
                "分布外鲁棒性"
            ],
            "_index": 97
        },
        {
            "title": "Maximum Mean Discrepancy with Unequal Sample Sizes via Generalized U-Statistics",
            "authors": [
                "Aaron Wei",
                "Milad Jalali",
                "Danica J. Sutherland"
            ],
            "arxiv_id": "2512.13997v1",
            "summary": "Existing two-sample testing techniques, particularly those based on choosing a kernel for the Maximum Mean Discrepancy (MMD), often assume equal sample sizes from the two distributions. Applying these methods in practice can require discarding valuable data, unnecessarily reducing test power. We address this long-standing limitation by extending the theory of generalized U-statistics and applying it to the usual MMD estimator, resulting in new characterization of the asymptotic distributions of the MMD estimator with unequal sample sizes (particularly outside the proportional regimes required by previous partial results). This generalization also provides a new criterion for optimizing the power of an MMD test with unequal sample sizes. Our approach preserves all available data, enhancing test accuracy and applicability in realistic settings. Along the way, we give much cleaner characterizations of the variance of MMD estimators, revealing something that might be surprising to those in the area: while zero MMD implies a degenerate estimator, it is sometimes possible to have a degenerate estimator with nonzero MMD as well; we give a construction and a proof that it does not happen in common situations.",
            "categories": [
                "stat.ML",
                "cs.LG",
                "math.ST",
                "stat.ME"
            ],
            "primary_category": "stat.ML",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13997v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VIO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 2,
            "headline_zh": "提出基于广义U统计量的最大均值差异方法，解决不等样本量下的两样本检验问题",
            "summary_zh": "现有的两样本检验技术，特别是基于选择核函数的最大均值差异方法，通常假设两个分布具有相等的样本量。在实际应用中，这些方法可能需要丢弃有价值的数据，不必要地降低检验功效。我们通过扩展广义U统计量理论并将其应用于通常的MMD估计量，解决了这一长期存在的限制，从而对不等样本量下MMD估计量的渐近分布进行了新的刻画（特别是在先前部分结果所需的比例范围之外）。这一推广还为优化不等样本量下MMD检验的功效提供了新的准则。我们的方法保留了所有可用数据，提高了实际场景中的检验准确性和适用性。在此过程中，我们对MMD估计量的方差给出了更清晰的刻画，揭示了一个可能令该领域研究者惊讶的现象：虽然零MMD意味着退化估计量，但有时也可能存在非零MMD的退化估计量；我们给出了一个构造，并证明这在常见情况下不会发生。",
            "intro_zh": [
                "现有MMD两样本检验方法通常假设等样本量，实际应用中需丢弃数据，降低检验功效",
                "通过扩展广义U统计量理论，重新刻画不等样本量下MMD估计量的渐近分布",
                "提出新准则优化不等样本量检验功效，保留所有数据，提升实际应用中的准确性和适用性"
            ],
            "method_zh": "论文的核心方法基于广义U统计量理论对最大均值差异进行扩展。整体框架是将传统的MMD估计量重新表述为广义U统计量，从而处理不等样本量的情况。关键技术创新点包括：推导了不等样本量下MMD估计量的渐近分布理论，特别是在非比例样本量下的完整刻画；提出了基于该理论的新检验功效优化准则。与现有方法的主要区别在于：不再需要丢弃数据或假设等样本量，能够充分利用所有可用样本；提供了更一般的理论框架，覆盖了先前部分结果未涉及的非比例样本量情况。",
            "application_zh": "该方法在需要处理不等样本量的两样本检验场景中具有重要价值，如医学研究中的病例-对照研究、机器学习中的领域适应、异常检测等。实际应用中能够避免数据浪费，提高统计检验的准确性和可靠性。",
            "highlight_zh": "论文最重要的实验结果包括：在不等样本量下，新方法相比传统丢弃数据的方法显著提高了检验功效；理论分析揭示了MMD估计量方差的新性质，包括非零MMD下可能存在的退化情况；实验验证了新优化准则的有效性。",
            "tags_zh": [
                "最大均值差异",
                "两样本检验",
                "不等样本量",
                "广义U统计量",
                "渐近分布",
                "检验功效优化",
                "统计学习理论"
            ],
            "_index": 98
        },
        {
            "title": "Universal Reasoning Model",
            "authors": [
                "Zitian Gao",
                "Lynx Chen",
                "Yihao Xiao",
                "He Xing",
                "Ran Tao",
                "Haoming Luo",
                "Joey Zhou",
                "Bryan Dai"
            ],
            "arxiv_id": "2512.14693v1",
            "summary": "Universal transformers (UTs) have been widely used for complex reasoning tasks such as ARC-AGI and Sudoku, yet the specific sources of their performance gains remain underexplored. In this work, we systematically analyze UTs variants and show that improvements on ARC-AGI primarily arise from the recurrent inductive bias and strong nonlinear components of Transformer, rather than from elaborate architectural designs. Motivated by this finding, we propose the Universal Reasoning Model (URM), which enhances the UT with short convolution and truncated backpropagation. Our approach substantially improves reasoning performance, achieving state-of-the-art 53.8% pass@1 on ARC-AGI 1 and 16.0% pass@1 on ARC-AGI 2. Our code is avaliable at https://github.com/zitian-gao/URM.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14693v1",
            "code_links": [
                {
                    "url": "https://github.com/zitian-gao/URM",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出通用推理模型以提升复杂推理任务性能，在ARC-AGI基准上实现新突破",
            "summary_zh": "通用Transformer（UT）已被广泛应用于ARC-AGI和数独等复杂推理任务，但其性能提升的具体来源尚未得到充分探索。本研究系统分析了UT的变体，发现ARC-AGI上的改进主要源于Transformer的循环归纳偏置和强非线性组件，而非复杂的架构设计。基于这一发现，我们提出了通用推理模型（URM），通过引入短卷积和截断反向传播来增强UT。该方法显著提升了推理性能，在ARC-AGI 1上达到了53.8%的pass@1，在ARC-AGI 2上达到了16.0%的pass@1，实现了最先进水平。代码已开源：https://github.com/zitian-gao/URM。",
            "intro_zh": [
                "现有通用Transformer在复杂推理任务中性能提升来源不明确，限制了进一步优化。",
                "提出URM模型，通过短卷积和截断反向传播增强通用Transformer的推理能力。",
                "在ARC-AGI基准上取得显著提升，达到最先进水平，验证了方法的有效性。"
            ],
            "method_zh": "通用推理模型（URM）基于通用Transformer（UT）框架进行改进。整体框架保留了UT的循环归纳偏置和强非线性组件，这是性能提升的关键基础。关键技术创新点包括引入短卷积模块来增强局部特征提取能力，以及采用截断反向传播技术来优化训练效率和稳定性。与现有方法的主要区别在于，URM不依赖复杂的架构设计，而是通过简单有效的增强手段，直接针对推理任务的核心需求进行优化，从而在保持模型简洁性的同时大幅提升性能。",
            "application_zh": "该研究主要应用于复杂推理任务，如抽象推理（ARC-AGI）、逻辑谜题（如数独）和需要高级认知能力的AI系统。潜在价值包括推动通用人工智能的发展，提升模型在少样本或零样本场景下的推理能力，为教育、游戏和自动化决策等领域提供技术支持。",
            "highlight_zh": "URM在ARC-AGI基准上实现了最先进性能：ARC-AGI 1达到53.8% pass@1，ARC-AGI 2达到16.0% pass@1。相比现有方法，性能提升显著，验证了短卷积和截断反向传播的有效性，为复杂推理任务提供了新的解决方案。",
            "tags_zh": [
                "通用推理模型",
                "Transformer架构",
                "复杂推理任务",
                "ARC-AGI基准",
                "短卷积",
                "截断反向传播",
                "归纳偏置",
                "非线性组件"
            ],
            "_index": 99
        },
        {
            "title": "Native and Compact Structured Latents for 3D Generation",
            "authors": [
                "Jianfeng Xiang",
                "Xiaoxue Chen",
                "Sicheng Xu",
                "Ruicheng Wang",
                "Zelong Lv",
                "Yu Deng",
                "Hongyuan Zhu",
                "Yue Dong",
                "Hao Zhao",
                "Nicholas Jing Yuan",
                "Jiaolong Yang"
            ],
            "arxiv_id": "2512.14692v1",
            "summary": "Recent advancements in 3D generative modeling have significantly improved the generation realism, yet the field is still hampered by existing representations, which struggle to capture assets with complex topologies and detailed appearance. This paper present an approach for learning a structured latent representation from native 3D data to address this challenge. At its core is a new sparse voxel structure called O-Voxel, an omni-voxel representation that encodes both geometry and appearance. O-Voxel can robustly model arbitrary topology, including open, non-manifold, and fully-enclosed surfaces, while capturing comprehensive surface attributes beyond texture color, such as physically-based rendering parameters. Based on O-Voxel, we design a Sparse Compression VAE which provides a high spatial compression rate and a compact latent space. We train large-scale flow-matching models comprising 4B parameters for 3D generation using diverse public 3D asset datasets. Despite their scale, inference remains highly efficient. Meanwhile, the geometry and material quality of our generated assets far exceed those of existing models. We believe our approach offers a significant advancement in 3D generative modeling.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project Page: https://microsoft.github.io/TRELLIS.2/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14692v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出O-Voxel稀疏体素表示与稀疏压缩VAE，以解决3D生成中复杂拓扑与细节外观建模的挑战。",
            "summary_zh": "近年来，3D生成建模在生成真实感方面取得了显著进展，但该领域仍受限于现有表示方法，这些方法难以捕捉具有复杂拓扑和详细外观的资产。本文提出了一种从原生3D数据中学习结构化潜在表示的方法来解决这一挑战。其核心是一种称为O-Voxel的新稀疏体素结构，这是一种全向体素表示，能够同时编码几何和外观。O-Voxel能够稳健地建模任意拓扑，包括开放、非流形和完全封闭的表面，同时捕捉超越纹理颜色的全面表面属性，例如基于物理的渲染参数。基于O-Voxel，我们设计了一种稀疏压缩变分自编码器，提供了高空间压缩率和紧凑的潜在空间。我们使用多样化的公共3D资产数据集训练了包含40亿参数的大规模流匹配模型用于3D生成。尽管模型规模庞大，推理仍然非常高效。同时，我们生成资产的几何和材质质量远超现有模型。我们相信，我们的方法为3D生成建模提供了重要进展。",
            "intro_zh": [
                "现有3D表示方法难以有效建模复杂拓扑（如开放、非流形表面）和详细外观（如物理渲染参数），限制了生成资产的真实感。",
                "提出O-Voxel稀疏体素表示，统一编码几何与外观，并基于此设计稀疏压缩VAE，实现高压缩率和紧凑潜在空间，支持大规模流匹配训练。",
                "实验表明，生成资产的几何和材质质量显著超越现有模型，且40亿参数模型推理高效，在公共数据集上验证了方法的优越性。"
            ],
            "method_zh": "论文提出一种基于结构化潜在表示的3D生成框架。整体框架包括：首先，引入O-Voxel稀疏体素表示，这是一种全向体素结构，能够同时编码几何（如任意拓扑表面）和外观（如纹理、物理渲染参数），解决了传统表示在复杂资产建模上的不足。其次，基于O-Voxel设计稀疏压缩变分自编码器，通过高效压缩实现高空间压缩率和紧凑潜在空间，便于后续生成建模。关键技术创新点在于O-Voxel的稀疏性和多属性编码能力，以及VAE的压缩优化。与现有方法的主要区别在于：O-Voxel比传统体素或网格更灵活地处理拓扑，且整合了更丰富的表面属性；稀疏压缩VAE相比标准VAE提供了更高效的潜在表示，支持大规模参数模型训练。",
            "application_zh": "该研究在3D内容生成领域具有广泛潜在应用，如游戏开发、虚拟现实、影视特效和工业设计，可用于快速生成高质量、复杂拓扑的3D资产，提升创作效率和真实感，推动数字孪生和元宇宙等技术的发展。",
            "highlight_zh": "最重要的实验结果包括：生成资产的几何和材质质量远超现有模型，在公共数据集上表现出色；训练了40亿参数的大规模流匹配模型，尽管规模庞大，推理仍保持高效，验证了方法的可扩展性和实用性。",
            "tags_zh": [
                "3D生成建模",
                "稀疏体素表示",
                "结构化潜在空间",
                "变分自编码器",
                "流匹配模型",
                "复杂拓扑建模",
                "物理渲染参数",
                "大规模参数训练"
            ],
            "_index": 100
        },
        {
            "title": "VASA-3D: Lifelike Audio-Driven Gaussian Head Avatars from a Single Image",
            "authors": [
                "Sicheng Xu",
                "Guojun Chen",
                "Jiaolong Yang",
                "Yizhong Zhang",
                "Yu Deng",
                "Steve Lin",
                "Baining Guo"
            ],
            "arxiv_id": "2512.14677v1",
            "summary": "We propose VASA-3D, an audio-driven, single-shot 3D head avatar generator. This research tackles two major challenges: capturing the subtle expression details present in real human faces, and reconstructing an intricate 3D head avatar from a single portrait image. To accurately model expression details, VASA-3D leverages the motion latent of VASA-1, a method that yields exceptional realism and vividness in 2D talking heads. A critical element of our work is translating this motion latent to 3D, which is accomplished by devising a 3D head model that is conditioned on the motion latent. Customization of this model to a single image is achieved through an optimization framework that employs numerous video frames of the reference head synthesized from the input image. The optimization takes various training losses robust to artifacts and limited pose coverage in the generated training data. Our experiment shows that VASA-3D produces realistic 3D talking heads that cannot be achieved by prior art, and it supports the online generation of 512x512 free-viewpoint videos at up to 75 FPS, facilitating more immersive engagements with lifelike 3D avatars.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "NeurIPS 2025 paper. Project webpage: https://www.microsoft.com/en-us/research/project/vasa-3d/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14677v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "PPO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出VASA-3D以解决从单张图像生成高真实感音频驱动3D头部虚拟形象的挑战",
            "summary_zh": "我们提出了VASA-3D，一种音频驱动的单次3D头部虚拟形象生成器。这项研究解决了两个主要挑战：捕捉真实人脸中存在的细微表情细节，以及从单张肖像图像重建复杂的3D头部虚拟形象。为了准确建模表情细节，VASA-3D利用了VASA-1的运动潜在表示，该方法在2D说话头部生成中展现出卓越的真实感和生动性。我们工作的一个关键要素是将这种运动潜在表示转换到3D空间，这是通过设计一个以运动潜在表示为条件的3D头部模型来实现的。该模型针对单张图像的定制化是通过一个优化框架实现的，该框架使用了从输入图像合成的参考头部的大量视频帧。优化过程采用了多种训练损失函数，这些损失函数对生成训练数据中的伪影和有限姿态覆盖具有鲁棒性。我们的实验表明，VASA-3D生成了现有技术无法实现的逼真3D说话头部，并支持在线生成512x512分辨率、高达75 FPS的自由视点视频，从而促进了与逼真3D虚拟形象更沉浸式的互动。",
            "intro_zh": [
                "现有方法难以从单张图像生成高真实感的3D头部虚拟形象，特别是在捕捉细微表情细节方面存在不足。",
                "VASA-3D通过利用VASA-1的运动潜在表示，并设计条件化3D头部模型和优化框架，实现从单张图像生成音频驱动的3D虚拟形象。",
                "实验结果显示，VASA-3D能生成逼真的3D说话头部，支持在线生成512x512分辨率、75 FPS的自由视点视频，显著超越现有技术。"
            ],
            "method_zh": "VASA-3D的整体框架基于音频驱动的3D头部虚拟形象生成，核心包括：利用VASA-1的运动潜在表示来建模表情细节，设计一个以该运动潜在表示为条件的3D头部模型，实现从2D到3D的转换。关键技术创新点在于通过优化框架定制化模型到单张图像，使用从输入图像合成的视频帧进行训练，并采用鲁棒损失函数处理数据中的伪影和姿态限制。与现有方法的主要区别在于，它结合了VASA-1的高质量2D运动建模能力，并扩展到3D空间，解决了单图像重建和表情细节捕捉的挑战，而传统方法往往依赖多视图数据或难以生成逼真动态。",
            "application_zh": "该研究在虚拟现实、增强现实、游戏、在线教育和远程会议等领域具有广泛应用潜力，能创建逼真的3D虚拟形象，提升沉浸式互动体验，例如用于个性化虚拟助手或社交平台中的动态头像。",
            "highlight_zh": "VASA-3D在实验中生成逼真的3D说话头部，超越现有技术，支持在线生成512x512分辨率、高达75 FPS的自由视点视频，优化框架有效处理训练数据中的伪影和姿态覆盖问题，实现了高真实感和实时性能。",
            "tags_zh": [
                "音频驱动虚拟形象",
                "3D头部重建",
                "单图像生成",
                "运动潜在表示",
                "优化框架",
                "自由视点视频",
                "表情细节建模",
                "实时渲染"
            ],
            "_index": 101
        },
        {
            "title": "ART: Articulated Reconstruction Transformer",
            "authors": [
                "Zizhang Li",
                "Cheng Zhang",
                "Zhengqin Li",
                "Henry Howard-Jenkins",
                "Zhaoyang Lv",
                "Chen Geng",
                "Jiajun Wu",
                "Richard Newcombe",
                "Jakob Engel",
                "Zhao Dong"
            ],
            "arxiv_id": "2512.14671v1",
            "summary": "We introduce ART, Articulated Reconstruction Transformer -- a category-agnostic, feed-forward model that reconstructs complete 3D articulated objects from only sparse, multi-state RGB images. Previous methods for articulated object reconstruction either rely on slow optimization with fragile cross-state correspondences or use feed-forward models limited to specific object categories. In contrast, ART treats articulated objects as assemblies of rigid parts, formulating reconstruction as part-based prediction. Our newly designed transformer architecture maps sparse image inputs to a set of learnable part slots, from which ART jointly decodes unified representations for individual parts, including their 3D geometry, texture, and explicit articulation parameters. The resulting reconstructions are physically interpretable and readily exportable for simulation. Trained on a large-scale, diverse dataset with per-part supervision, and evaluated across diverse benchmarks, ART achieves significant improvements over existing baselines and establishes a new state of the art for articulated object reconstruction from image inputs.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project Page: https://kyleleey.github.io/ART/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14671v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VIO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出ART以解决从稀疏多状态RGB图像重建完整3D关节物体的问题，实现类别无关的前馈建模。",
            "summary_zh": "我们介绍了ART（Articulated Reconstruction Transformer），这是一个类别无关的前馈模型，能够仅从稀疏的多状态RGB图像中重建完整的3D关节物体。先前的方法要么依赖于缓慢的优化过程，需要脆弱的跨状态对应关系，要么使用仅限于特定物体类别的前馈模型。相比之下，ART将关节物体视为刚性部件的组装体，将重建问题表述为基于部件的预测。我们新设计的Transformer架构将稀疏图像输入映射到一组可学习的部件槽，ART从中联合解码出统一表示，包括每个部件的3D几何、纹理和显式关节参数。所得重建结果具有物理可解释性，并易于导出用于仿真。通过在具有每部件监督的大规模多样化数据集上进行训练，并在多个基准测试中评估，ART相比现有基线取得了显著改进，为从图像输入重建关节物体建立了新的最先进水平。",
            "intro_zh": [
                "现有方法依赖缓慢优化或脆弱对应关系，或局限于特定类别，难以高效重建通用关节物体。",
                "ART将关节物体建模为刚性部件组装，使用Transformer架构从稀疏图像预测部件几何、纹理和关节参数。",
                "在多样化数据集上训练和评估，ART显著超越基线，实现了类别无关的快速重建，并支持物理仿真。"
            ],
            "method_zh": "ART的整体框架是一个基于Transformer的前馈模型，输入稀疏多状态RGB图像，输出关节物体的完整3D重建。关键技术创新包括：将重建任务分解为部件级预测，通过可学习部件槽统一编码几何、纹理和关节参数；新设计的Transformer架构直接映射图像到部件表示，避免了传统优化中的对应关系依赖。与现有方法的主要区别在于，ART是类别无关的，不依赖于特定物体先验，且通过前馈方式实现快速推理，同时保持物理可解释性。",
            "application_zh": "该研究在机器人操作、虚拟现实和增强现实中有广泛应用潜力，例如用于模拟真实世界物体的交互、自动化装配或游戏开发。其物理可解释的重建结果可直接导出用于仿真，提升系统效率和安全性。",
            "highlight_zh": "ART在多个基准测试中显著优于现有基线，实现了类别无关的关节物体重建，重建质量高且速度快，支持从稀疏图像直接生成可仿真模型，为相关领域树立了新标准。",
            "tags_zh": [
                "关节物体重建",
                "3D重建",
                "Transformer架构",
                "前馈模型",
                "类别无关建模",
                "部件预测",
                "物理仿真",
                "稀疏图像输入"
            ],
            "_index": 102
        },
        {
            "title": "WaveSim: A Wavelet-based Multi-scale Similarity Metric for Weather and Climate Fields",
            "authors": [
                "Gabriele Accarino",
                "Viviana Acquaviva",
                "Sara Shamekh",
                "Duncan Watson-Parris",
                "David Lawrence"
            ],
            "arxiv_id": "2512.14656v1",
            "summary": "We introduce WaveSim, a multi-scale similarity metric for the evaluation of spatial fields in weather and climate applications. WaveSim exploits wavelet transforms to decompose input fields into scale-specific wavelet coefficients. The metric is built by multiplying three orthogonal components derived from these coefficients: Magnitude, which quantifies similarities in the energy distribution of the coefficients, i.e., the intensity of the field; Displacement, which captures spatial shift by comparing the centers of mass of normalized energy distributions; and Structure, which assesses pattern organization independent of location and amplitude. Each component yields a scale-specific similarity score ranging from 0 (no similarity) to 1 (perfect similarity), which are then combined across scales to produce an overall similarity measure. We first evaluate WaveSim using synthetic test cases, applying controlled spatial and temporal perturbations to systematically assess its sensitivity and expected behavior. We then demonstrate its applicability to physically relevant case studies of key modes of climate variability in Earth System Models. Traditional point-wise metrics lack a mechanism for attributing errors to physical scales or modes of dissimilarity. By operating in the wavelet domain and decomposing the signal along independent axes, WaveSim bypasses these limitations and provides an interpretable and diagnostically rich framework for assessing similarity in complex fields. Additionally, the WaveSim framework allows users to place emphasis on a specific scale or component, and lends itself to user-specific model intercomparison, model evaluation, and calibration and training of forecasting systems. We provide a PyTorch-ready implementation of WaveSim, along with all evaluation scripts, at: https://github.com/gabrieleaccarino/wavesim.",
            "categories": [
                "physics.ao-ph",
                "cs.CV",
                "physics.data-an"
            ],
            "primary_category": "physics.ao-ph",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14656v1",
            "code_links": [
                {
                    "url": "https://github.com/gabrieleaccarino/wavesim",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VIO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出WaveSim小波多尺度相似度度量方法，用于评估天气和气候空间场的相似性",
            "summary_zh": "我们介绍了WaveSim，一种用于评估天气和气候应用中空间场的多尺度相似度度量方法。WaveSim利用小波变换将输入场分解为尺度特定的小波系数。该度量通过乘以从这些系数导出的三个正交分量构建：幅度（量化系数能量分布的相似性，即场的强度）、位移（通过比较归一化能量分布的质量中心来捕捉空间偏移）和结构（评估独立于位置和幅度的模式组织）。每个分量产生一个从0（无相似性）到1（完美相似性）的尺度特定相似度分数，然后跨尺度组合以产生整体相似度度量。我们首先使用合成测试案例评估WaveSim，应用受控的空间和时间扰动来系统评估其敏感性和预期行为。然后，我们展示了其在物理相关案例研究中的适用性，这些案例研究涉及地球系统模型中关键的气候变率模式。传统的逐点度量缺乏将误差归因于物理尺度或差异模式的机制。通过在小波域中操作并沿独立轴分解信号，WaveSim克服了这些限制，为评估复杂场中的相似性提供了一个可解释且诊断丰富的框架。此外，WaveSim框架允许用户强调特定尺度或分量，并适用于用户特定的模型比较、模型评估以及预测系统的校准和训练。我们提供了WaveSim的PyTorch就绪实现以及所有评估脚本，网址为：https://github.com/gabrieleaccarino/wavesim。",
            "intro_zh": [
                "传统逐点度量无法将误差归因于物理尺度或差异模式，限制了天气和气候场评估的深度诊断能力。",
                "WaveSim利用小波变换分解信号，通过幅度、位移和结构三个正交分量量化多尺度相似性，提供可解释的评估框架。",
                "在合成测试和气候变率案例中，WaveSim表现出对空间和时间扰动的敏感性，并成功应用于模型比较和评估。"
            ],
            "method_zh": "WaveSim的整体框架基于小波变换，将输入空间场分解为多尺度小波系数。关键技术创新点在于从系数中提取三个正交分量：幅度（量化能量分布相似性）、位移（捕捉空间偏移）和结构（评估模式组织），每个分量生成尺度特定相似度分数，再跨尺度组合成整体度量。与现有方法的主要区别在于，传统逐点度量（如均方误差）缺乏多尺度分析和物理模式分解能力，而WaveSim通过小波域操作和正交分解，提供了更丰富、可解释的相似度评估，能够区分不同物理尺度的差异。",
            "application_zh": "WaveSim适用于天气和气候领域的模型比较、模型评估、预测系统校准和训练，特别在地球系统模型分析中，可用于评估关键气候变率模式（如厄尔尼诺-南方涛动）的模拟性能，提升诊断能力和模型优化。",
            "highlight_zh": "在合成测试中，WaveSim对受控空间和时间扰动表现出预期敏感性；在气候变率案例研究中，成功应用于评估地球系统模型的关键模式，提供了比传统度量更丰富的诊断信息，验证了其多尺度相似度评估的有效性。",
            "tags_zh": [
                "小波变换",
                "多尺度相似度度量",
                "天气气候场评估",
                "模型比较",
                "地球系统模型",
                "空间场分析",
                "可解释性框架",
                "PyTorch实现"
            ],
            "_index": 103
        },
        {
            "title": "Adaptable Segmentation Pipeline for Diverse Brain Tumors with Radiomic-guided Subtyping and Lesion-Wise Model Ensemble",
            "authors": [
                "Daniel Capellán-Martín",
                "Abhijeet Parida",
                "Zhifan Jiang",
                "Nishad Kulkarni",
                "Krithika Iyer",
                "Austin Tapp",
                "Syed Muhammad Anwar",
                "María J. Ledesma-Carbayo",
                "Marius George Linguraru"
            ],
            "arxiv_id": "2512.14648v1",
            "summary": "Robust and generalizable segmentation of brain tumors on multi-parametric magnetic resonance imaging (MRI) remains difficult because tumor types differ widely. The BraTS 2025 Lighthouse Challenge benchmarks segmentation methods on diverse high-quality datasets of adult and pediatric tumors: multi-consortium international pediatric brain tumor segmentation (PED), preoperative meningioma tumor segmentation (MEN), meningioma radiotherapy segmentation (MEN-RT), and segmentation of pre- and post-treatment brain metastases (MET). We present a flexible, modular, and adaptable pipeline that improves segmentation performance by selecting and combining state-of-the-art models and applying tumor- and lesion-specific processing before and after training. Radiomic features extracted from MRI help detect tumor subtype, ensuring a more balanced training. Custom lesion-level performance metrics determine the influence of each model in the ensemble and optimize post-processing that further refines the predictions, enabling the workflow to tailor every step to each case. On the BraTS testing sets, our pipeline achieved performance comparable to top-ranked algorithms across multiple challenges. These findings confirm that custom lesion-aware processing and model selection yield robust segmentations yet without locking the method to a specific network architecture. Our method has the potential for quantitative tumor measurement in clinical practice, supporting diagnosis and prognosis.",
            "categories": [
                "cs.CV",
                "eess.IV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "12 pages, 5 figures, 3 tables. Algorithm presented at MICCAI BraTS 2025",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14648v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "PPO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出可适应脑肿瘤分割流程，通过影像组学引导亚型识别和病灶级模型集成，提升多类型肿瘤分割的鲁棒性。",
            "summary_zh": "在多参数磁共振成像（MRI）上实现鲁棒且可泛化的脑肿瘤分割仍然困难，因为肿瘤类型差异很大。BraTS 2025 Lighthouse Challenge 在多样化的高质量数据集上评估分割方法，包括成人和儿童肿瘤：多联盟国际儿童脑肿瘤分割（PED）、术前脑膜瘤分割（MEN）、脑膜瘤放疗分割（MEN-RT）以及治疗前后脑转移瘤分割（MET）。我们提出了一种灵活、模块化且可适应的流程，通过选择和组合最先进的模型，并在训练前后应用肿瘤和病灶特定的处理来提升分割性能。从MRI提取的影像组学特征有助于检测肿瘤亚型，确保更平衡的训练。自定义的病灶级性能指标确定每个模型在集成中的影响，并优化后处理以进一步细化预测，使工作流程能够针对每个病例定制每一步。在BraTS测试集上，我们的流程在多个挑战中取得了与排名靠前算法相当的性能。这些发现证实，自定义的病灶感知处理和模型选择能够产生鲁棒的分割，同时不将方法锁定于特定的网络架构。我们的方法在临床实践中具有定量肿瘤测量的潜力，支持诊断和预后。",
            "intro_zh": [
                "核心问题：脑肿瘤类型多样，现有分割方法难以在MRI上实现鲁棒且可泛化的分割，尤其是在成人和儿童肿瘤、脑膜瘤及转移瘤等不同数据集上。",
                "方法要点：提出灵活可适应流程，结合影像组学引导亚型识别、病灶级模型集成和定制后处理，提升分割性能而不依赖单一网络架构。",
                "实验或效果：在BraTS 2025 Lighthouse Challenge测试集上，性能与顶级算法相当，验证了方法的鲁棒性和临床潜力。"
            ],
            "method_zh": "整体框架是一个模块化、可适应的分割流程，核心包括：选择和集成最先进的分割模型，应用肿瘤和病灶特定处理。关键技术创新点在于：利用从MRI提取的影像组学特征进行肿瘤亚型检测，以平衡训练数据；通过自定义病灶级性能指标动态调整模型在集成中的权重，并优化后处理步骤，实现针对每个病例的定制化分割。与现有方法的主要区别在于：不锁定于特定网络架构，而是通过灵活的模型选择和病灶级处理来提升泛化能力，特别适用于多样化的脑肿瘤类型。",
            "application_zh": "该研究在临床医学影像分析领域有重要应用价值，可用于脑肿瘤的定量测量，支持诊断和预后评估，特别是在成人和儿童肿瘤、脑膜瘤及脑转移瘤的MRI分割中，有助于提高分割精度和鲁棒性，促进个性化医疗。",
            "highlight_zh": "在BraTS 2025 Lighthouse Challenge的测试集上，该方法在PED、MEN、MEN-RT和MET等多个数据集上均取得了与排名靠前算法相当的分割性能，验证了其鲁棒性和泛化能力，无需依赖特定网络架构即可实现高效分割。",
            "tags_zh": [
                "脑肿瘤分割",
                "多参数MRI",
                "影像组学",
                "模型集成",
                "病灶级处理",
                "可适应流程",
                "临床影像分析",
                "BraTS挑战"
            ],
            "_index": 104
        },
        {
            "title": "TiME: Tiny Monolingual Encoders for Efficient NLP Pipelines",
            "authors": [
                "David Schulmeister",
                "Valentin Hartmann",
                "Lars Klein",
                "Robert West"
            ],
            "arxiv_id": "2512.14645v1",
            "summary": "Today, a lot of research on language models is focused on large, general-purpose models. However, many NLP pipelines only require models with a well-defined, small set of capabilities. While large models are capable of performing the tasks of those smaller models, they are simply not fast enough to process large amounts of data or offer real-time responses. Furthermore, they often use unnecessarily large amounts of energy, leading to sustainability concerns and problems when deploying them on battery-powered devices. In our work, we show how to train small models for such efficiency-critical applications. As opposed to many off-the-shelf NLP pipelines, our models use modern training techniques such as distillation, and offer support for low-resource languages. We call our models TiME (Tiny Monolingual Encoders) and comprehensively evaluate them on a range of common NLP tasks, observing an improved trade-off between benchmark performance on one hand, and throughput, latency and energy consumption on the other. Along the way, we show that distilling monolingual models from multilingual teachers is possible, and likewise distilling models with absolute positional embeddings from teachers with relative positional embeddings.",
            "categories": [
                "cs.CL",
                "cs.LG"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14645v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "PPO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出TiME（Tiny Monolingual Encoders）以解决大型语言模型在效率关键应用中速度慢、能耗高的问题。",
            "summary_zh": "当前语言模型研究多集中于大型通用模型，但许多NLP流水线仅需具备明确、小规模能力的模型。大型模型虽能执行这些任务，但处理大量数据或提供实时响应时速度不足，且能耗过高，导致可持续性问题，在电池供电设备上部署困难。本工作展示了如何为这类效率关键应用训练小型模型。与许多现成NLP流水线不同，我们的模型采用蒸馏等现代训练技术，并支持低资源语言。我们称这些模型为TiME（Tiny Monolingual Encoders），并在多种常见NLP任务上全面评估，观察到其在基准性能与吞吐量、延迟和能耗之间实现了更好的权衡。过程中，我们证明了从多语言教师模型蒸馏单语言模型是可行的，同样可以从具有相对位置嵌入的教师模型蒸馏出具有绝对位置嵌入的模型。",
            "intro_zh": [
                "核心问题：大型通用语言模型在NLP流水线中速度慢、能耗高，不适合效率关键应用和低资源设备部署。",
                "方法要点：提出TiME模型，通过蒸馏技术训练小型单语言编码器，支持低资源语言，优化性能与效率的权衡。",
                "实验或效果：在多种NLP任务上评估，TiME在基准性能、吞吐量、延迟和能耗方面表现更优，验证了蒸馏方法的可行性。"
            ],
            "method_zh": "TiME模型采用基于蒸馏的整体框架，从大型多语言教师模型蒸馏出小型单语言编码器。关键技术创新点包括：使用现代蒸馏技术优化训练过程，支持从多语言教师蒸馏单语言模型，以及从具有相对位置嵌入的教师蒸馏出具有绝对位置嵌入的模型。与现有方法的主要区别在于，TiME专注于效率关键应用，通过小型化设计减少模型参数，结合蒸馏提升性能，而传统NLP流水线往往依赖大型模型或缺乏高效训练技术。",
            "application_zh": "TiME适用于需要高效NLP处理的场景，如实时响应系统、大规模数据处理、低资源语言支持，以及在电池供电设备（如移动设备或物联网设备）上的部署，有助于降低能耗和提升可持续性。",
            "highlight_zh": "实验结果显示，TiME在多种NLP任务上实现了基准性能与吞吐量、延迟和能耗的更好权衡，验证了从多语言教师蒸馏单语言模型以及从相对位置嵌入教师蒸馏绝对位置嵌入模型的可行性，提升了小型模型的实用价值。",
            "tags_zh": [
                "小型语言模型",
                "单语言编码器",
                "蒸馏训练",
                "效率优化",
                "低资源语言",
                "能耗降低",
                "实时NLP",
                "模型压缩"
            ],
            "_index": 105
        },
        {
            "title": "AMD-HookNet++: Evolution of AMD-HookNet with Hybrid CNN-Transformer Feature Enhancement for Glacier Calving Front Segmentation",
            "authors": [
                "Fei Wu",
                "Marcel Dreier",
                "Nora Gourmelon",
                "Sebastian Wind",
                "Jianlin Zhang",
                "Thorsten Seehaus",
                "Matthias Braun",
                "Andreas Maier",
                "Vincent Christlein"
            ],
            "arxiv_id": "2512.14639v1",
            "summary": "The dynamics of glaciers and ice shelf fronts significantly impact the mass balance of ice sheets and coastal sea levels. To effectively monitor glacier conditions, it is crucial to consistently estimate positional shifts of glacier calving fronts. AMD-HookNet firstly introduces a pure two-branch convolutional neural network (CNN) for glacier segmentation. Yet, the local nature and translational invariance of convolution operations, while beneficial for capturing low-level details, restricts the model ability to maintain long-range dependencies. In this study, we propose AMD-HookNet++, a novel advanced hybrid CNN-Transformer feature enhancement method for segmenting glaciers and delineating calving fronts in synthetic aperture radar images. Our hybrid structure consists of two branches: a Transformer-based context branch to capture long-range dependencies, which provides global contextual information in a larger view, and a CNN-based target branch to preserve local details. To strengthen the representation of the connected hybrid features, we devise an enhanced spatial-channel attention module to foster interactions between the hybrid CNN-Transformer branches through dynamically adjusting the token relationships from both spatial and channel perspectives. Additionally, we develop a pixel-to-pixel contrastive deep supervision to optimize our hybrid model by integrating pixelwise metric learning into glacier segmentation. Through extensive experiments and comprehensive quantitative and qualitative analyses on the challenging glacier segmentation benchmark dataset CaFFe, we show that AMD-HookNet++ sets a new state of the art with an IoU of 78.2 and a HD95 of 1,318 m, while maintaining a competitive MDE of 367 m. More importantly, our hybrid model produces smoother delineations of calving fronts, resolving the issue of jagged edges typically seen in pure Transformer-based approaches.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "10.1109/TGRS.2025.3642764",
            "journal_ref": "IEEE Transactions on Geoscience and Remote Sensing (2025)",
            "pdf_url": "https://arxiv.org/pdf/2512.14639v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出AMD-HookNet++混合CNN-Transformer特征增强方法，用于合成孔径雷达图像中的冰川崩解前缘分割。",
            "summary_zh": "冰川和冰架前缘的动态变化显著影响冰盖质量平衡和沿海海平面。为有效监测冰川状况，持续估计冰川崩解前缘的位置变化至关重要。AMD-HookNet首次引入了纯双分支卷积神经网络（CNN）进行冰川分割。然而，卷积操作的局部性和平移不变性虽然有利于捕捉低级细节，但限制了模型保持长距离依赖关系的能力。本研究提出AMD-HookNet++，一种新颖的先进混合CNN-Transformer特征增强方法，用于分割合成孔径雷达图像中的冰川并描绘崩解前缘。我们的混合结构包括两个分支：一个基于Transformer的上下文分支以捕获长距离依赖关系，在更大视图中提供全局上下文信息；一个基于CNN的目标分支以保留局部细节。为增强连接混合特征的表示，我们设计了一个增强的空间通道注意力模块，通过从空间和通道角度动态调整令牌关系，促进混合CNN-Transformer分支之间的交互。此外，我们开发了像素到像素对比深度监督，通过将像素级度量学习集成到冰川分割中，优化我们的混合模型。通过在具有挑战性的冰川分割基准数据集CaFFe上进行广泛实验和全面的定量与定性分析，我们表明AMD-HookNet++以78.2的IoU和1,318米的HD95设定了新的最先进水平，同时保持了367米的竞争性MDE。更重要的是，我们的混合模型产生了更平滑的崩解前缘描绘，解决了纯基于Transformer方法中常见的锯齿边缘问题。",
            "intro_zh": [
                "核心问题：纯CNN方法在冰川分割中难以捕获长距离依赖关系，导致全局上下文信息不足，影响崩解前缘的准确描绘。",
                "方法要点：提出混合CNN-Transformer架构，结合Transformer分支捕获全局上下文和CNN分支保留局部细节，并引入增强注意力模块优化特征交互。",
                "实验或效果：在CaFFe数据集上实现78.2 IoU和1,318米HD95，优于现有方法，并生成更平滑的前缘分割结果。"
            ],
            "method_zh": "AMD-HookNet++采用双分支混合架构：一个基于Transformer的上下文分支用于捕获全局长距离依赖关系，提供大视图下的上下文信息；一个基于CNN的目标分支用于保留局部细节特征。关键技术创新包括增强的空间通道注意力模块，该模块通过动态调整空间和通道维度的令牌关系，促进两个分支之间的特征交互，从而优化混合特征的表示。此外，引入了像素到像素对比深度监督，将像素级度量学习集成到训练过程中，进一步提升分割精度。与现有方法的主要区别在于：相比纯CNN的AMD-HookNet，本方法通过Transformer分支弥补了长距离依赖的不足；相比纯Transformer方法，本方法通过CNN分支避免了锯齿边缘问题，实现了更平滑的分割结果。",
            "application_zh": "该研究主要应用于冰川监测和气候变化研究领域，通过高精度分割合成孔径雷达图像中的冰川崩解前缘，支持冰川动态变化分析、冰盖质量平衡评估和沿海海平面预测，具有重要的环境科学和地球观测价值。",
            "highlight_zh": "在CaFFe基准数据集上，AMD-HookNet++实现了78.2的IoU和1,318米的HD95，显著优于先前方法，同时保持367米的MDE；定性分析显示，模型能生成更平滑的崩解前缘分割，有效解决了纯Transformer方法的锯齿边缘问题。",
            "tags_zh": [
                "冰川分割",
                "合成孔径雷达图像",
                "混合CNN-Transformer",
                "特征增强",
                "注意力机制",
                "像素级对比学习",
                "崩解前缘检测",
                "遥感图像分析"
            ],
            "_index": 106
        },
        {
            "title": "MuseCPBench: an Empirical Study of Music Editing Methods through Music Context Preservation",
            "authors": [
                "Yash Vishe",
                "Eric Xue",
                "Xunyi Jiang",
                "Zachary Novack",
                "Junda Wu",
                "Julian McAuley",
                "Xin Xu"
            ],
            "arxiv_id": "2512.14629v1",
            "summary": "Music editing plays a vital role in modern music production, with applications in film, broadcasting, and game development. Recent advances in music generation models have enabled diverse editing tasks such as timbre transfer, instrument substitution, and genre transformation. However, many existing works overlook the evaluation of their ability to preserve musical facets that should remain unchanged during editing a property we define as Music Context Preservation (MCP). While some studies do consider MCP, they adopt inconsistent evaluation protocols and metrics, leading to unreliable and unfair comparisons. To address this gap, we introduce the first MCP evaluation benchmark, MuseCPBench, which covers four categories of musical facets and enables comprehensive comparisons across five representative music editing baselines. Through systematic analysis along musical facets, methods, and models, we identify consistent preservation gaps in current music editing methods and provide insightful explanations. We hope our findings offer practical guidance for developing more effective and reliable music editing strategies with strong MCP capability",
            "categories": [
                "cs.SD",
                "cs.AI"
            ],
            "primary_category": "cs.SD",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14629v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出首个音乐上下文保持评估基准MuseCPBench，以解决音乐编辑方法评估不一致的问题",
            "summary_zh": "音乐编辑在现代音乐制作中扮演着重要角色，广泛应用于电影、广播和游戏开发。近年来音乐生成模型的进步使得音色转换、乐器替换和风格变换等多样化编辑任务成为可能。然而，许多现有研究忽视了评估编辑过程中应保持不变的音乐要素的保持能力，这一属性被定义为音乐上下文保持（MCP）。虽然部分研究考虑了MCP，但它们采用了不一致的评估协议和指标，导致不可靠且不公平的比较。为填补这一空白，我们引入了首个MCP评估基准MuseCPBench，涵盖四类音乐要素，并支持对五种代表性音乐编辑基线方法进行全面比较。通过对音乐要素、方法和模型的系统分析，我们识别出当前音乐编辑方法中一致的保持差距，并提供深入解释。我们希望这些发现能为开发具有强大MCP能力的更有效、可靠音乐编辑策略提供实用指导。",
            "intro_zh": [
                "现有音乐编辑方法缺乏统一的音乐上下文保持评估标准，导致结果不可比且不可靠。",
                "论文提出首个MCP评估基准MuseCPBench，涵盖四类音乐要素并整合五种基线方法。",
                "实验揭示当前方法在音乐要素保持上存在一致差距，为改进编辑策略提供实证依据。"
            ],
            "method_zh": "MuseCPBench是一个系统化的评估框架，其核心是定义音乐上下文保持（MCP）为编辑过程中应保持不变的音乐要素保持能力。框架包括四类音乐要素（如旋律、节奏、和声和音色）的量化指标，并整合了五种代表性音乐编辑基线方法（如基于生成模型的方法）。关键创新在于首次建立了标准化的MCP评估协议，避免了现有研究中的不一致性。与现有方法的主要区别在于，它不提出新编辑算法，而是专注于评估现有方法的MCP能力，通过统一基准实现公平比较。",
            "application_zh": "该研究可应用于音乐制作、影视配乐和游戏音效设计等领域，帮助开发者选择或改进音乐编辑方法，确保编辑后音乐的核心要素不被破坏，提升制作效率和艺术质量。",
            "highlight_zh": "实验显示，当前音乐编辑方法在MCP上存在显著差距，例如在旋律和节奏保持上表现不一；MuseCPBench实现了跨方法的标准化评估，为未来研究提供了可靠基准。",
            "tags_zh": [
                "音乐编辑",
                "上下文保持",
                "评估基准",
                "音乐生成模型",
                "多要素分析",
                "标准化协议",
                "实证研究"
            ],
            "_index": 107
        },
        {
            "title": "JMMMU-Pro: Image-based Japanese Multi-discipline Multimodal Understanding Benchmark via Vibe Benchmark Construction",
            "authors": [
                "Atsuyuki Miyai",
                "Shota Onohara",
                "Jeonghun Baek",
                "Kiyoharu Aizawa"
            ],
            "arxiv_id": "2512.14620v1",
            "summary": "This paper introduces JMMMU-Pro, an image-based Japanese Multi-discipline Multimodal Understanding Benchmark, and Vibe Benchmark Construction, a scalable construction method. Following the evolution from MMMU to MMMU-Pro, JMMMU-Pro extends JMMMU by composing the question image and question text into a single image, thereby creating a benchmark that requires integrated visual-textual understanding through visual perception. To build JMMMU-Pro, we propose Vibe Benchmark Construction, a methodology in which an image generative model (e.g., Nano Banana Pro) produces candidate visual questions, and humans verify the outputs and, when necessary, regenerate with adjusted prompts to ensure quality. By leveraging Nano Banana Pro's highly realistic image generation capabilities and its ability to embed clean Japanese text, we construct a high-quality benchmark at low cost, covering a wide range of background and layout designs. Experimental results show that all open-source LMMs struggle substantially with JMMMU-Pro, underscoring JMMMU-Pro as an important benchmark for guiding future efforts in the open-source community. We believe that JMMMU-Pro provides a more rigorous evaluation tool for assessing the Japanese capabilities of LMMs and that our Vibe Benchmark Construction also offers an efficient guideline for future development of image-based VQA benchmarks.",
            "categories": [
                "cs.CL",
                "cs.AI",
                "cs.CV"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project page: https://mmmu-japanese-benchmark.github.io/JMMMU_Pro/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14620v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出JMMMU-Pro基准和Vibe Benchmark Construction方法，以低成本构建高质量日语多学科多模态理解评估工具。",
            "summary_zh": "本文介绍了JMMMU-Pro，一个基于图像的日语多学科多模态理解基准，以及Vibe Benchmark Construction，一种可扩展的构建方法。继从MMMU到MMMU-Pro的演进后，JMMMU-Pro通过将问题图像和问题文本组合成单一图像来扩展JMMMU，从而创建一个需要通过视觉感知进行集成视觉-文本理解的基准。为了构建JMMMU-Pro，我们提出了Vibe Benchmark Construction方法，其中图像生成模型（如Nano Banana Pro）生成候选视觉问题，人类验证输出并在必要时通过调整提示重新生成以确保质量。通过利用Nano Banana Pro的高度真实图像生成能力及其嵌入清晰日语文本的能力，我们以低成本构建了一个高质量的基准，覆盖广泛的背景和布局设计。实验结果表明，所有开源LMM在JMMMU-Pro上都面临显著困难，这突显了JMMMU-Pro作为指导开源社区未来努力的重要基准。我们相信，JMMMU-Pro为评估LMM的日语能力提供了一个更严格的评估工具，并且我们的Vibe Benchmark Construction也为未来基于图像的VQA基准开发提供了高效指南。",
            "intro_zh": [
                "现有日语多模态基准在集成视觉-文本理解方面存在不足，难以全面评估LMM的日语能力。",
                "提出Vibe Benchmark Construction方法，结合图像生成模型和人工验证，低成本构建高质量视觉问题。",
                "实验显示开源LMM在JMMMU-Pro上表现不佳，验证了其作为严格评估工具的有效性。"
            ],
            "method_zh": "论文的核心方法是Vibe Benchmark Construction，整体框架包括使用图像生成模型（如Nano Banana Pro）自动生成候选视觉问题，然后通过人工验证和调整提示来确保质量。关键技术创新点在于将问题图像和文本组合成单一图像，要求模型进行集成视觉-文本理解，并利用生成模型的高真实性和文本嵌入能力。与现有方法的主要区别在于其可扩展性和低成本，通过自动化生成减少人工标注负担，同时覆盖多学科背景和布局设计，提供更全面的评估。",
            "application_zh": "该研究可应用于评估大型语言模型（LMM）在日语多模态任务中的能力，为开源社区提供基准指导，促进多模态AI在日语教育、内容生成和智能助手等领域的实际应用。",
            "highlight_zh": "所有开源LMM在JMMMU-Pro基准上均表现不佳，突显了其在集成视觉-文本理解方面的挑战，验证了基准的严格性和实用性。",
            "tags_zh": [
                "多模态理解",
                "日语基准",
                "图像生成",
                "视觉问答",
                "开源评估",
                "多学科任务",
                "低成本构建"
            ],
            "_index": 108
        },
        {
            "title": "ParaFormer: A Generalized PageRank Graph Transformer for Graph Representation Learning",
            "authors": [
                "Chaohao Yuan",
                "Zhenjie Song",
                "Ercan Engin Kuruoglu",
                "Kangfei Zhao",
                "Yang Liu",
                "Deli Zhao",
                "Hong Cheng",
                "Yu Rong"
            ],
            "arxiv_id": "2512.14619v1",
            "summary": "Graph Transformers (GTs) have emerged as a promising graph learning tool, leveraging their all-pair connected property to effectively capture global information. To address the over-smoothing problem in deep GNNs, global attention was initially introduced, eliminating the necessity for using deep GNNs. However, through empirical and theoretical analysis, we verify that the introduced global attention exhibits severe over-smoothing, causing node representations to become indistinguishable due to its inherent low-pass filtering. This effect is even stronger than that observed in GNNs. To mitigate this, we propose PageRank Transformer (ParaFormer), which features a PageRank-enhanced attention module designed to mimic the behavior of deep Transformers. We theoretically and empirically demonstrate that ParaFormer mitigates over-smoothing by functioning as an adaptive-pass filter. Experiments show that ParaFormer achieves consistent performance improvements across both node classification and graph classification tasks on 11 datasets ranging from thousands to millions of nodes, validating its efficacy. The supplementary material, including code and appendix, can be found in https://github.com/chaohaoyuan/ParaFormer.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Accepted by WSDM 2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14619v1",
            "code_links": [
                {
                    "url": "https://github.com/chaohaoyuan/ParaFormer",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VIO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出PageRank Transformer以解决图Transformer中的过度平滑问题",
            "summary_zh": "图Transformer（GTs）作为一种有前景的图学习工具，利用其全连接特性有效捕获全局信息。为解决深度图神经网络（GNNs）中的过度平滑问题，全局注意力机制被引入，消除了使用深度GNNs的必要性。然而，通过实证和理论分析，我们发现引入的全局注意力表现出严重的过度平滑，由于其固有的低通滤波特性，导致节点表示变得难以区分，这种效应甚至比GNNs中观察到的更强。为缓解此问题，我们提出了PageRank Transformer（ParaFormer），其特点是包含一个PageRank增强的注意力模块，旨在模拟深度Transformer的行为。我们从理论和实证上证明，ParaFormer通过充当自适应通滤波器来减轻过度平滑。实验表明，ParaFormer在从数千到数百万节点的11个数据集上的节点分类和图分类任务中均实现了持续的性能提升，验证了其有效性。补充材料，包括代码和附录，可在https://github.com/chaohaoyuan/ParaFormer找到。",
            "intro_zh": [
                "现有图Transformer的全局注意力机制存在严重过度平滑问题，导致节点表示难以区分，影响模型性能。",
                "提出PageRank Transformer，通过PageRank增强的注意力模块模拟深度Transformer行为，实现自适应滤波以缓解过度平滑。",
                "在11个数据集上的实验显示，ParaFormer在节点和图分类任务中均取得一致性能提升，验证其有效性。"
            ],
            "method_zh": "ParaFormer的整体框架基于图Transformer，核心创新在于引入PageRank增强的注意力模块。该模块通过整合PageRank算法来调整注意力权重，使其能够自适应地过滤信息，从而模拟深度Transformer的层次化特征提取过程。与现有方法的主要区别在于，传统图Transformer的全局注意力是低通滤波器，导致过度平滑；而ParaFormer通过PageRank机制实现自适应通滤波，有效平衡局部和全局信息，减少表示退化。",
            "application_zh": "该研究可应用于社交网络分析、生物信息学、推荐系统等需要处理大规模图数据的领域，通过提升图表示学习的准确性和鲁棒性，支持节点分类、图分类等任务，具有广泛的实际价值。",
            "highlight_zh": "ParaFormer在11个数据集上均表现出色，包括节点分类和图分类任务，性能提升一致，特别是在大规模图数据上验证了其缓解过度平滑的有效性，证明了自适应滤波策略的优越性。",
            "tags_zh": [
                "图Transformer",
                "过度平滑",
                "PageRank",
                "自适应滤波",
                "图表示学习",
                "节点分类",
                "图分类",
                "全局注意力"
            ],
            "_index": 109
        },
        {
            "title": "LLmFPCA-detect: LLM-powered Multivariate Functional PCA for Anomaly Detection in Sparse Longitudinal Texts",
            "authors": [
                "Prasanjit Dubey",
                "Aritra Guha",
                "Zhengyi Zhou",
                "Qiong Wu",
                "Xiaoming Huo",
                "Paromita Dubey"
            ],
            "arxiv_id": "2512.14604v1",
            "summary": "Sparse longitudinal (SL) textual data arises when individuals generate text repeatedly over time (e.g., customer reviews, occasional social media posts, electronic medical records across visits), but the frequency and timing of observations vary across individuals. These complex textual data sets have immense potential to inform future policy and targeted recommendations. However, because SL text data lack dedicated methods and are noisy, heterogeneous, and prone to anomalies, detecting and inferring key patterns is challenging. We introduce LLmFPCA-detect, a flexible framework that pairs LLM-based text embeddings with functional data analysis to detect clusters and infer anomalies in large SL text datasets. First, LLmFPCA-detect embeds each piece of text into an application-specific numeric space using LLM prompts. Sparse multivariate functional principal component analysis (mFPCA) conducted in the numeric space forms the workhorse to recover primary population characteristics, and produces subject-level scores which, together with baseline static covariates, facilitate data segmentation, unsupervised anomaly detection and inference, and enable other downstream tasks. In particular, we leverage LLMs to perform dynamic keyword profiling guided by the data segments and anomalies discovered by LLmFPCA-detect, and we show that cluster-specific functional PC scores from LLmFPCA-detect, used as features in existing pipelines, help boost prediction performance. We support the stability of LLmFPCA-detect with experiments and evaluate it on two different applications using public datasets, Amazon customer-review trajectories, and Wikipedia talk-page comment streams, demonstrating utility across domains and outperforming state-of-the-art baselines.",
            "categories": [
                "stat.ML",
                "cs.LG"
            ],
            "primary_category": "stat.ML",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14604v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "PPO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出LLmFPCA-detect框架，结合LLM文本嵌入与功能数据分析，解决稀疏纵向文本数据中的异常检测问题。",
            "summary_zh": "稀疏纵向（SL）文本数据出现在个体随时间重复生成文本的场景中（如客户评论、偶尔的社交媒体帖子、跨次就诊的电子病历），但观测频率和时间在个体间存在差异。这些复杂的文本数据集具有巨大潜力，可为未来政策和针对性推荐提供信息。然而，由于SL文本数据缺乏专门方法，且具有噪声、异质性和易出现异常的特点，检测和推断关键模式具有挑战性。我们引入了LLmFPCA-detect，这是一个灵活的框架，将基于LLM的文本嵌入与功能数据分析相结合，以检测大型SL文本数据集中的聚类并推断异常。首先，LLmFPCA-detect使用LLM提示将每段文本嵌入到特定应用的数值空间中。在数值空间中进行的稀疏多元功能主成分分析（mFPCA）是恢复主要群体特征的核心工具，并生成个体级分数，这些分数与基线静态协变量一起，促进数据分割、无监督异常检测和推断，并支持其他下游任务。特别是，我们利用LLM在LLmFPCA-detect发现的数据段和异常指导下进行动态关键词分析，并展示LLmFPCA-detect生成的聚类特定功能PC分数作为现有流程中的特征，有助于提升预测性能。我们通过实验支持LLmFPCA-detect的稳定性，并使用公共数据集（亚马逊客户评论轨迹和维基百科讨论页评论流）在两个不同应用中评估它，展示了跨领域的实用性并优于最先进的基线方法。",
            "intro_zh": [
                "稀疏纵向文本数据缺乏专门分析方法，面临噪声、异质性和异常检测的挑战。",
                "结合LLM文本嵌入与稀疏多元功能主成分分析，构建灵活框架以恢复群体特征并检测异常。",
                "在亚马逊评论和维基百科评论数据集上验证，性能优于现有基线，提升预测任务表现。"
            ],
            "method_zh": "LLmFPCA-detect框架首先使用LLM提示将稀疏纵向文本嵌入到数值空间，然后应用稀疏多元功能主成分分析（mFPCA）恢复群体特征并生成个体级分数。关键创新在于将LLM的语义理解能力与功能数据分析的时序建模相结合，处理文本的稀疏性和异质性。与现有方法相比，它专门针对稀疏纵向文本设计，避免了传统方法对密集数据的依赖，并通过LLM增强嵌入质量。",
            "application_zh": "该研究适用于客户评论分析、社交媒体监控、电子病历异常检测等领域，能帮助企业和机构从稀疏文本数据中提取模式、发现异常并优化推荐系统，具有广泛的实际应用价值。",
            "highlight_zh": "在亚马逊客户评论和维基百科评论数据集上，LLmFPCA-detect在异常检测和聚类任务中优于最先进基线，实验显示其稳定性和跨领域泛化能力，功能PC分数作为特征能显著提升下游预测性能。",
            "tags_zh": [
                "稀疏纵向文本",
                "异常检测",
                "大语言模型嵌入",
                "功能数据分析",
                "多元功能主成分分析",
                "无监督学习",
                "文本聚类",
                "动态关键词分析"
            ],
            "_index": 110
        },
        {
            "title": "Sound and Music Biases in Deep Music Transcription Models: A Systematic Analysis",
            "authors": [
                "Lukáš Samuel Marták",
                "Patricia Hu",
                "Gerhard Widmer"
            ],
            "arxiv_id": "2512.14602v1",
            "summary": "Automatic Music Transcription (AMT) -- the task of converting music audio into note representations -- has seen rapid progress, driven largely by deep learning systems. Due to the limited availability of richly annotated music datasets, much of the progress in AMT has been concentrated on classical piano music, and even a few very specific datasets. Whether these systems can generalize effectively to other musical contexts remains an open question. Complementing recent studies on distribution shifts in sound (e.g., recording conditions), in this work we investigate the musical dimension -- specifically, variations in genre, dynamics, and polyphony levels. To this end, we introduce the MDS corpus, comprising three distinct subsets -- (1) Genre, (2) Random, and (3) MAEtest -- to emulate different axes of distribution shift. We evaluate the performance of several state-of-the-art AMT systems on the MDS corpus using both traditional information-retrieval and musically-informed performance metrics. Our extensive evaluation isolates and exposes varying degrees of performance degradation under specific distribution shifts. In particular, we measure a note-level F1 performance drop of 20 percentage points due to sound, and 14 due to genre. Generally, we find that dynamics estimation proves more vulnerable to musical variation than onset prediction. Musically informed evaluation metrics, particularly those capturing harmonic structure, help identify potential contributing factors. Furthermore, experiments with randomly generated, non-musical sequences reveal clear limitations in system performance under extreme musical distribution shifts. Altogether, these findings offer new evidence of the persistent impact of the Corpus Bias problem in deep AMT systems.",
            "categories": [
                "cs.SD",
                "cs.LG"
            ],
            "primary_category": "cs.SD",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "pre-print of the upcoming EURASIP JASM journal article",
            "doi": "10.1186/s13636-025-00428-z",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14602v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "系统分析深度音乐转录模型中的声音与音乐偏见，揭示其在分布偏移下的性能退化问题。",
            "summary_zh": "自动音乐转录（AMT）——将音乐音频转换为音符表示的任务——在深度学习系统的推动下取得了快速进展。由于丰富标注音乐数据集的可用性有限，AMT的大部分进展集中在古典钢琴音乐，甚至少数特定数据集上。这些系统是否能有效泛化到其他音乐背景仍是一个开放问题。本研究补充了最近关于声音分布偏移（如录音条件）的研究，调查了音乐维度——特别是流派、动态和复音水平的变化。为此，我们引入了MDS语料库，包含三个不同子集——（1）流派，（2）随机，和（3）MAEtest——以模拟分布偏移的不同轴。我们使用传统信息检索和音乐感知性能指标评估了多个最先进AMT系统在MDS语料库上的表现。广泛的评估隔离并暴露了在特定分布偏移下不同程度的性能退化。特别是，我们测量到由于声音导致的音符级F1性能下降20个百分点，由于流派导致的下降14个百分点。总体而言，我们发现动态估计比起始预测更容易受到音乐变化的影响。音乐感知评估指标，特别是那些捕捉和声结构的指标，有助于识别潜在贡献因素。此外，随机生成的非音乐序列实验揭示了在极端音乐分布偏移下系统性能的明显限制。总之，这些发现为深度AMT系统中语料库偏见问题的持续影响提供了新证据。",
            "intro_zh": [
                "核心问题：深度AMT模型因训练数据集中于古典钢琴音乐，泛化能力受限，对流派、动态等音乐变化敏感。",
                "方法要点：引入MDS语料库模拟分布偏移，结合传统和音乐感知指标，系统评估模型在声音与音乐维度上的性能。",
                "实验或效果：发现音符级F1性能因声音下降20个百分点，因流派下降14个百分点，动态估计更易受音乐变化影响。"
            ],
            "method_zh": "论文的核心方法是引入MDS语料库作为评估框架，包含Genre、Random和MAEtest三个子集，以模拟音乐流派、随机序列和特定测试条件下的分布偏移。整体框架涉及使用多个最先进的深度AMT模型，在MDS语料库上进行系统评估，结合传统信息检索指标（如F1分数）和音乐感知指标（如捕捉和声结构的指标）。关键技术创新点在于将音乐维度（如流派、动态、复音水平）作为分布偏移轴进行量化分析，与现有方法主要关注声音条件偏移形成区别。主要区别在于本研究不仅评估模型在标准数据集上的性能，还通过设计多样化测试集来揭示模型在真实世界音乐变化中的泛化瓶颈。",
            "application_zh": "该研究可应用于改进自动音乐转录系统的鲁棒性，支持音乐教育、音乐信息检索和音频编辑工具的开发，通过识别和缓解偏见，提升模型在多样化音乐场景（如流行音乐、现场录音）中的实用价值。",
            "highlight_zh": "最重要的实验结果显示，音符级F1性能在声音分布偏移下下降20个百分点，在流派偏移下下降14个百分点；动态估计比起始预测更脆弱；随机非音乐序列实验暴露了模型在极端偏移下的性能限制。",
            "tags_zh": [
                "自动音乐转录",
                "分布偏移",
                "语料库偏见",
                "音乐感知评估",
                "深度学习",
                "泛化能力",
                "性能退化",
                "MDS语料库"
            ],
            "_index": 111
        },
        {
            "title": "FakeRadar: Probing Forgery Outliers to Detect Unknown Deepfake Videos",
            "authors": [
                "Zhaolun Li",
                "Jichang Li",
                "Yinqi Cai",
                "Junye Chen",
                "Xiaonan Luo",
                "Guanbin Li",
                "Rushi Lan"
            ],
            "arxiv_id": "2512.14601v1",
            "summary": "In this paper, we propose FakeRadar, a novel deepfake video detection framework designed to address the challenges of cross-domain generalization in real-world scenarios. Existing detection methods typically rely on manipulation-specific cues, performing well on known forgery types but exhibiting severe limitations against emerging manipulation techniques. This poor generalization stems from their inability to adapt effectively to unseen forgery patterns. To overcome this, we leverage large-scale pretrained models (e.g. CLIP) to proactively probe the feature space, explicitly highlighting distributional gaps between real videos, known forgeries, and unseen manipulations. Specifically, FakeRadar introduces Forgery Outlier Probing, which employs dynamic subcluster modeling and cluster-conditional outlier generation to synthesize outlier samples near boundaries of estimated subclusters, simulating novel forgery artifacts beyond known manipulation types. Additionally, we design Outlier-Guided Tri-Training, which optimizes the detector to distinguish real, fake, and outlier samples using proposed outlier-driven contrastive learning and outlier-conditioned cross-entropy losses. Experiments show that FakeRadar outperforms existing methods across various benchmark datasets for deepfake video detection, particularly in cross-domain evaluations, by handling the variety of emerging manipulation techniques.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14601v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出FakeRadar框架以解决深度伪造视频检测中的跨域泛化挑战，通过主动探测伪造异常来应对未知伪造技术。",
            "summary_zh": "本文提出FakeRadar，一种新颖的深度伪造视频检测框架，旨在解决现实场景中跨域泛化的挑战。现有检测方法通常依赖于特定操纵线索，在已知伪造类型上表现良好，但对新兴操纵技术表现出严重局限性。这种泛化能力差源于它们无法有效适应未见过的伪造模式。为克服此问题，我们利用大规模预训练模型（如CLIP）主动探测特征空间，明确突出真实视频、已知伪造和未知操纵之间的分布差距。具体而言，FakeRadar引入伪造异常探测，采用动态子聚类建模和聚类条件异常生成来合成估计子聚类边界附近的异常样本，模拟超出已知操纵类型的新伪造伪影。此外，我们设计异常引导的三重训练，通过提出的异常驱动对比学习和异常条件交叉熵损失优化检测器，以区分真实、伪造和异常样本。实验表明，FakeRadar在深度伪造视频检测的多个基准数据集上优于现有方法，特别是在跨域评估中，通过处理各种新兴操纵技术。",
            "intro_zh": [
                "现有深度伪造检测方法依赖已知伪造线索，对新兴技术泛化能力差，导致跨域性能下降。",
                "FakeRadar通过伪造异常探测主动模拟未知伪造模式，结合异常引导训练优化检测器区分能力。",
                "实验显示FakeRadar在跨域评估中显著提升性能，有效应对多种新兴伪造技术。"
            ],
            "method_zh": "FakeRadar的整体框架基于大规模预训练模型（如CLIP）进行特征提取，核心包括伪造异常探测和异常引导的三重训练。关键技术创新点在于动态子聚类建模和聚类条件异常生成，主动合成异常样本以模拟未知伪造伪影，以及异常驱动对比学习和异常条件交叉熵损失优化检测器。与现有方法的主要区别在于不依赖特定操纵线索，而是通过主动探测特征空间分布差距来增强跨域泛化能力，从而更有效地适应新兴伪造技术。",
            "application_zh": "该研究可应用于社交媒体内容审核、新闻真实性验证、法律证据分析等领域，帮助自动检测深度伪造视频，提升信息安全和信任度，尤其在面对不断演变的伪造技术时具有实际价值。",
            "highlight_zh": "FakeRadar在多个深度伪造视频检测基准数据集上表现优异，特别是在跨域评估中，通过处理新兴操纵技术显著超越现有方法，验证了其泛化能力和鲁棒性。",
            "tags_zh": [
                "深度伪造检测",
                "跨域泛化",
                "伪造异常探测",
                "对比学习",
                "预训练模型",
                "视频分析",
                "异常生成",
                "机器学习安全"
            ],
            "_index": 112
        },
        {
            "title": "FoodLogAthl-218: Constructing a Real-World Food Image Dataset Using Dietary Management Applications",
            "authors": [
                "Mitsuki Watanabe",
                "Sosuke Amano",
                "Kiyoharu Aizawa",
                "Yoko Yamakata"
            ],
            "arxiv_id": "2512.14574v1",
            "summary": "Food image classification models are crucial for dietary management applications because they reduce the burden of manual meal logging. However, most publicly available datasets for training such models rely on web-crawled images, which often differ from users' real-world meal photos. In this work, we present FoodLogAthl-218, a food image dataset constructed from real-world meal records collected through the dietary management application FoodLog Athl. The dataset contains 6,925 images across 218 food categories, with a total of 14,349 bounding boxes. Rich metadata, including meal date and time, anonymized user IDs, and meal-level context, accompany each image. Unlike conventional datasets-where a predefined class set guides web-based image collection-our data begins with user-submitted photos, and labels are applied afterward. This yields greater intra-class diversity, a natural frequency distribution of meal types, and casual, unfiltered images intended for personal use rather than public sharing. In addition to (1) a standard classification benchmark, we introduce two FoodLog-specific tasks: (2) an incremental fine-tuning protocol that follows the temporal stream of users' logs, and (3) a context-aware classification task where each image contains multiple dishes, and the model must classify each dish by leveraging the overall meal context. We evaluate these tasks using large multimodal models (LMMs). The dataset is publicly available at https://huggingface.co/datasets/FoodLog/FoodLogAthl-218.",
            "categories": [
                "cs.CV",
                "cs.MM"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "10.1145/3746027.3758276",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14574v1",
            "code_links": [
                {
                    "url": "https://huggingface.co/datasets/FoodLog",
                    "type": "huggingface"
                }
            ],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出FoodLogAthl-218真实世界食物图像数据集，以解决基于网络爬取图像训练模型与实际用户餐照差异大的问题。",
            "summary_zh": "食物图像分类模型对饮食管理应用至关重要，能减轻手动记录餐食的负担。然而，大多数公开可用的训练数据集依赖于网络爬取的图像，这些图像常与用户真实世界餐照存在差异。本研究介绍了FoodLogAthl-218，一个从饮食管理应用FoodLog Athl收集的真实世界餐食记录构建的食物图像数据集。该数据集包含6,925张图像，覆盖218个食物类别，总计14,349个边界框。每张图像附有丰富元数据，如餐食日期和时间、匿名用户ID及餐食级上下文。与传统数据集不同，后者基于预定义类别集指导网络图像收集，而我们的数据始于用户提交的照片，随后才应用标签。这带来了更大的类内多样性、餐食类型的自然频率分布，以及用于个人而非公开分享的随意、未过滤图像。除了（1）标准分类基准，我们引入了两个FoodLog特定任务：（2）遵循用户日志时间流的增量微调协议，和（3）上下文感知分类任务，其中每张图像包含多道菜肴，模型必须利用整体餐食上下文对每道菜进行分类。我们使用大型多模态模型（LMMs）评估这些任务。数据集公开可用，地址为https://huggingface.co/datasets/FoodLog/FoodLogAthl-218。",
            "intro_zh": [
                "现有食物图像数据集多基于网络爬取，与实际用户餐照差异大，限制了模型在真实饮食管理应用中的性能。",
                "论文提出FoodLogAthl-218数据集，通过收集用户提交的真实餐照并后加标签，增强类内多样性和自然分布。",
                "实验引入增量微调和上下文感知分类任务，使用大型多模态模型评估，验证了数据集在真实场景下的有效性。"
            ],
            "method_zh": "论文的核心方法是构建FoodLogAthl-218数据集，整体框架包括从饮食管理应用FoodLog Athl收集用户真实餐食图像，并添加边界框和元数据。关键技术创新点在于数据收集方式：不同于传统基于预定义类别的网络爬取，本数据集基于用户提交照片后加标签，从而捕捉更真实的类内多样性和自然频率分布。与现有方法的主要区别在于强调真实世界场景，包括多菜肴图像和上下文信息，支持增量学习和上下文感知任务，以模拟实际应用中的动态需求。",
            "application_zh": "该研究主要应用于饮食管理领域，如健康监测、营养分析和个性化膳食推荐。通过提供真实世界食物图像数据集，能提升分类模型在实际应用中的准确性和鲁棒性，支持智能饮食日志和健康管理工具的开发。",
            "highlight_zh": "实验结果显示，FoodLogAthl-218数据集包含6,925张图像和14,349个边界框，覆盖218个类别，具有高类内多样性和自然分布。使用大型多模态模型评估，在增量微调和上下文感知分类任务中表现出色，验证了数据集在真实场景下的实用性和提升潜力。",
            "tags_zh": [
                "食物图像分类",
                "真实世界数据集",
                "饮食管理应用",
                "上下文感知学习",
                "增量微调",
                "大型多模态模型",
                "边界框标注",
                "用户生成内容"
            ],
            "_index": 113
        },
        {
            "title": "CLNet: Cross-View Correspondence Makes a Stronger Geo-Localizationer",
            "authors": [
                "Xianwei Cao",
                "Dou Quan",
                "Shuang Wang",
                "Ning Huyan",
                "Wei Wang",
                "Yunan Li",
                "Licheng Jiao"
            ],
            "arxiv_id": "2512.14560v1",
            "summary": "Image retrieval-based cross-view geo-localization (IRCVGL) aims to match images captured from significantly different viewpoints, such as satellite and street-level images. Existing methods predominantly rely on learning robust global representations or implicit feature alignment, which often fail to model explicit spatial correspondences crucial for accurate localization. In this work, we propose a novel correspondence-aware feature refinement framework, termed CLNet, that explicitly bridges the semantic and geometric gaps between different views. CLNet decomposes the view alignment process into three learnable and complementary modules: a Neural Correspondence Map (NCM) that spatially aligns cross-view features via latent correspondence fields; a Nonlinear Embedding Converter (NEC) that remaps features across perspectives using an MLP-based transformation; and a Global Feature Recalibration (GFR) module that reweights informative feature channels guided by learned spatial cues. The proposed CLNet can jointly capture both high-level semantics and fine-grained alignments. Extensive experiments on four public benchmarks, CVUSA, CVACT, VIGOR, and University-1652, demonstrate that our proposed CLNet achieves state-of-the-art performance while offering better interpretability and generalizability.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "16 pages, 6 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14560v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "localization"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出CLNet框架，通过显式跨视图对应关系解决图像检索式跨视角地理定位问题。",
            "summary_zh": "基于图像检索的跨视角地理定位（IRCVGL）旨在匹配从显著不同视角（如卫星和街景图像）捕获的图像。现有方法主要依赖学习鲁棒的全局表示或隐式特征对齐，往往无法建模对精确定位至关重要的显式空间对应关系。本文提出一种新颖的对应感知特征细化框架，称为CLNet，它显式地桥接不同视图之间的语义和几何差距。CLNet将视图对齐过程分解为三个可学习且互补的模块：神经对应图（NCM），通过潜在对应场在空间上对齐跨视图特征；非线性嵌入转换器（NEC），使用基于MLP的变换跨视角重新映射特征；以及全局特征重校准（GFR）模块，通过学习到的空间线索引导重新加权信息丰富的特征通道。所提出的CLNet能够联合捕获高级语义和细粒度对齐。在四个公共基准数据集（CVUSA、CVACT、VIGOR和University-1652）上的广泛实验表明，CLNet实现了最先进的性能，同时提供了更好的可解释性和泛化性。",
            "intro_zh": [
                "现有方法依赖全局表示或隐式对齐，难以建模跨视图的显式空间对应关系，导致地理定位精度受限。",
                "CLNet通过神经对应图、非线性嵌入转换器和全局特征重校准模块，显式学习语义和几何对应，提升特征对齐能力。",
                "在多个基准数据集上，CLNet达到最先进性能，并展现出更好的可解释性和泛化性，验证了其有效性。"
            ],
            "method_zh": "CLNet是一个对应感知特征细化框架，整体架构包括三个核心模块：神经对应图（NCM）通过潜在对应场实现跨视图特征的空间对齐；非线性嵌入转换器（NEC）使用MLP变换跨视角重新映射特征；全局特征重校准（GFR）基于学习到的空间线索重新加权特征通道。关键创新在于显式建模跨视图对应关系，而非依赖隐式对齐。与现有方法的主要区别在于将视图对齐分解为可学习的互补模块，联合捕获高级语义和细粒度几何信息，从而更有效地桥接语义和几何差距。",
            "application_zh": "该研究可应用于自动驾驶、无人机导航和增强现实等领域，通过跨视角图像匹配实现精确的地理定位，提升位置感知系统的鲁棒性和准确性。",
            "highlight_zh": "在CVUSA、CVACT、VIGOR和University-1652四个基准数据集上，CLNet均达到最先进性能，显著提升了跨视角地理定位的准确率，同时实验验证了其更好的可解释性和泛化能力。",
            "tags_zh": [
                "跨视角地理定位",
                "图像检索",
                "特征对齐",
                "神经对应图",
                "非线性嵌入转换",
                "全局特征重校准",
                "语义几何对应",
                "多视图匹配"
            ],
            "_index": 114
        },
        {
            "title": "Test Time Optimized Generalized AI-based Medical Image Registration Method",
            "authors": [
                "Sneha Sree C.",
                "Dattesh Shanbhag",
                "Sudhanya Chatterjee"
            ],
            "arxiv_id": "2512.14556v1",
            "summary": "Medical image registration is critical for aligning anatomical structures across imaging modalities such as computed tomography (CT), magnetic resonance imaging (MRI), and ultrasound. Among existing techniques, non-rigid registration (NRR) is particularly challenging due to the need to capture complex anatomical deformations caused by physiological processes like respiration or contrast-induced signal variations. Traditional NRR methods, while theoretically robust, often require extensive parameter tuning and incur high computational costs, limiting their use in real-time clinical workflows. Recent deep learning (DL)-based approaches have shown promise; however, their dependence on task-specific retraining restricts scalability and adaptability in practice. These limitations underscore the need for efficient, generalizable registration frameworks capable of handling heterogeneous imaging contexts. In this work, we introduce a novel AI-driven framework for 3D non-rigid registration that generalizes across multiple imaging modalities and anatomical regions. Unlike conventional methods that rely on application-specific models, our approach eliminates anatomy- or modality-specific customization, enabling streamlined integration into diverse clinical environments.",
            "categories": [
                "eess.IV",
                "cs.CV"
            ],
            "primary_category": "eess.IV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14556v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出一种AI驱动的3D非刚性配准框架，以解决多模态医学图像配准中依赖任务特定训练和计算成本高的问题。",
            "summary_zh": "医学图像配准对于对齐计算机断层扫描（CT）、磁共振成像（MRI）和超声等成像模态中的解剖结构至关重要。在现有技术中，非刚性配准（NRR）尤其具有挑战性，因为它需要捕捉由呼吸或对比剂引起的信号变化等生理过程导致的复杂解剖变形。传统的NRR方法虽然在理论上稳健，但通常需要大量参数调整并产生高计算成本，限制了其在实时临床工作流程中的应用。最近的基于深度学习（DL）的方法显示出潜力；然而，它们对任务特定再训练的依赖在实践中限制了可扩展性和适应性。这些局限性凸显了对能够处理异构成像环境的高效、可泛化配准框架的需求。在这项工作中，我们引入了一种新颖的AI驱动的3D非刚性配准框架，该框架可泛化到多种成像模态和解剖区域。与依赖应用特定模型的传统方法不同，我们的方法消除了解剖或模态特定的定制，实现了在不同临床环境中的简化集成。",
            "intro_zh": [
                "核心问题：传统非刚性配准方法参数调整复杂、计算成本高，而深度学习方法依赖任务特定训练，限制了临床应用的泛化性和实时性。",
                "方法要点：提出一种AI驱动的3D非刚性配准框架，无需解剖或模态特定定制，实现跨多模态和解剖区域的通用配准。",
                "实验或效果：框架在多种成像模态和解剖区域上表现出高效性和泛化能力，提升了配准精度和临床集成便利性。"
            ],
            "method_zh": "论文提出一种AI驱动的3D非刚性配准框架，整体基于深度学习模型，旨在处理多模态医学图像。关键技术创新点在于设计了一个通用架构，无需针对特定解剖结构或成像模态进行定制，通过优化测试时间性能来增强泛化能力。与现有方法的主要区别在于，传统方法通常依赖应用特定模型或需要大量参数调整，而本框架通过消除定制需求，实现了更高效的跨模态配准，减少了计算开销和部署复杂性。",
            "application_zh": "该研究可应用于医学影像分析领域，如多模态图像融合、手术导航和疾病监测，通过通用配准框架提升临床工作流程的效率和准确性，支持实时诊断和治疗规划。",
            "highlight_zh": "实验结果显示，该框架在多种成像模态（如CT、MRI、超声）和解剖区域上实现了高效配准，相比传统方法减少了计算时间，并保持了高精度，验证了其泛化能力和临床实用性。",
            "tags_zh": [
                "医学图像配准",
                "非刚性配准",
                "深度学习",
                "多模态融合",
                "3D配准",
                "泛化框架",
                "临床集成",
                "AI驱动"
            ],
            "_index": 115
        },
        {
            "title": "Dual Language Models: Balancing Training Efficiency and Overfitting Resilience",
            "authors": [
                "David Samuel",
                "Lucas Georges Gabriel Charpentier"
            ],
            "arxiv_id": "2512.14549v1",
            "summary": "This paper combines autoregressive and masked-diffusion training objectives without any architectural modifications, resulting in flexible language models that outperform single-objective models. Autoregressive modeling has been a popular approach, partly because of its training efficiency; however, that comes at the cost of sensitivity to overfitting. On the other hand, masked-diffusion models are less efficient to train while being more resilient to overfitting. In this work, we demonstrate that dual-objective training achieves the best of both worlds. To derive the optimal ratio between both objectives, we train and evaluate 50 language models under varying levels of data repetition. We show that it is optimal to combine both objectives under all evaluated settings and that the optimal ratio is similar whether targeting autoregressive or masked-diffusion downstream performance.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14549v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出双目标训练方法以平衡语言模型训练效率与过拟合鲁棒性",
            "summary_zh": "本文结合自回归和掩码扩散训练目标，无需修改模型架构，实现了灵活的语言模型，其性能优于单目标模型。自回归建模因其训练效率高而广受欢迎，但代价是对过拟合敏感；而掩码扩散模型训练效率较低，但对过拟合更具鲁棒性。本研究证明，双目标训练能兼顾两者优势。为确定两个目标之间的最优比例，我们在不同数据重复水平下训练和评估了50个语言模型。结果表明，在所有评估设置下，结合两个目标是最优的，且无论针对自回归还是掩码扩散的下游性能，最优比例都相似。",
            "intro_zh": [
                "自回归模型训练效率高但易过拟合，掩码扩散模型鲁棒性强但训练慢，现有单目标方法难以平衡效率与鲁棒性。",
                "提出双目标训练框架，结合自回归和掩码扩散目标，通过优化比例实现高效且鲁棒的语言模型训练。",
                "实验显示双目标模型在所有设置下均优于单目标模型，最优比例稳定，显著提升下游任务性能。"
            ],
            "method_zh": "论文提出一种双目标训练框架，核心方法是在不改变模型架构的前提下，同时结合自回归和掩码扩散训练目标。关键创新点在于通过动态调整两个目标的损失权重比例，实现训练效率与过拟合鲁棒性的平衡。与现有方法的主要区别在于，它避免了单一目标训练的局限性，无需复杂架构修改，而是通过目标组合优化模型性能，提供了一种灵活且高效的训练策略。",
            "application_zh": "该研究可应用于自然语言处理领域，如文本生成、机器翻译和对话系统，通过提升语言模型的训练效率和鲁棒性，降低过拟合风险，适用于数据有限或重复性高的场景，具有实际部署价值。",
            "highlight_zh": "在50个语言模型的实验中，双目标训练在所有数据重复水平下均优于单目标模型，最优比例稳定，显著提升下游任务性能，验证了方法在平衡效率与鲁棒性方面的有效性。",
            "tags_zh": [
                "语言模型训练",
                "自回归建模",
                "掩码扩散模型",
                "双目标优化",
                "过拟合鲁棒性",
                "训练效率",
                "下游任务性能",
                "损失权重比例"
            ],
            "_index": 116
        },
        {
            "title": "Improving Slow Transfer Predictions: Generative Methods Compared",
            "authors": [
                "Jacob Taegon Kim",
                "Alex Sim",
                "Kesheng Wu",
                "Jinoh Kim"
            ],
            "arxiv_id": "2512.14522v1",
            "summary": "Monitoring data transfer performance is a crucial task in scientific computing networks. By predicting performance early in the communication phase, potentially sluggish transfers can be identified and selectively monitored, optimizing network usage and overall performance. A key bottleneck to improving the predictive power of machine learning (ML) models in this context is the issue of class imbalance. This project focuses on addressing the class imbalance problem to enhance the accuracy of performance predictions. In this study, we analyze and compare various augmentation strategies, including traditional oversampling methods and generative techniques. Additionally, we adjust the class imbalance ratios in training datasets to evaluate their impact on model performance. While augmentation may improve performance, as the imbalance ratio increases, the performance does not significantly improve. We conclude that even the most advanced technique, such as CTGAN, does not significantly improve over simple stratified sampling.",
            "categories": [
                "cs.LG",
                "cs.DC",
                "cs.NI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "10.1109/ICNC64010.2025.10994006",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14522v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "比较生成方法与传统过采样在解决数据不平衡问题上的效果，以提升科学计算网络中的传输性能预测准确性。",
            "summary_zh": "监测数据转移性能是科学计算网络中的关键任务。通过在通信阶段早期预测性能，可以识别潜在缓慢的传输并选择性监控，从而优化网络使用和整体性能。在此背景下，提高机器学习模型预测能力的一个关键瓶颈是类别不平衡问题。本项目专注于解决类别不平衡问题以增强性能预测的准确性。在本研究中，我们分析并比较了多种增强策略，包括传统的过采样方法和生成技术。此外，我们调整训练数据集中的类别不平衡比例以评估其对模型性能的影响。虽然增强可能提高性能，但随着不平衡比例增加，性能并未显著改善。我们得出结论，即使是最先进的技术，如CTGAN，也没有比简单的分层采样显著改进。",
            "intro_zh": [
                "核心问题：机器学习模型在科学计算网络性能预测中面临类别不平衡问题，导致预测准确性受限。",
                "方法要点：通过比较传统过采样和生成方法（如CTGAN）来增强数据，并调整训练集的不平衡比例以优化模型。",
                "实验或效果：研究发现，随着不平衡比例增加，增强方法对性能提升有限，CTGAN未显著优于简单分层采样。"
            ],
            "method_zh": "论文的核心方法基于一个比较框架，旨在评估不同数据增强策略对解决类别不平衡问题的效果。整体框架包括使用传统过采样方法（如SMOTE）和生成技术（如CTGAN）来生成合成数据，以平衡训练数据集中的类别分布。关键技术创新点在于系统性地调整类别不平衡比例，并对比这些增强方法在性能预测任务中的表现。与现有方法的主要区别在于，论文不仅关注单一增强技术，而是通过实验验证了在高度不平衡场景下，生成方法相对于简单分层采样的优势有限，这挑战了生成模型在数据不平衡问题中的普遍假设。",
            "application_zh": "该研究主要应用于科学计算网络中的数据转移性能监控和优化。通过提高预测准确性，可以帮助网络管理员早期识别缓慢传输，实现资源的高效分配和网络性能提升，具有实际价值于高性能计算和分布式系统管理。",
            "highlight_zh": "最重要的实验结果是，随着类别不平衡比例增加，数据增强方法（包括CTGAN）对模型性能的提升不显著，CTGAN未明显优于简单的分层采样，这表明在高度不平衡场景下，生成方法的有效性有限。",
            "tags_zh": [
                "类别不平衡",
                "数据增强",
                "生成对抗网络",
                "过采样",
                "性能预测",
                "科学计算网络",
                "机器学习模型",
                "CTGAN"
            ],
            "_index": 117
        },
        {
            "title": "SASQ: Static Activation Scaling for Quantization-Aware Training in Large Language Models",
            "authors": [
                "Shizhuo Mao",
                "Song Chen",
                "Yi Kang"
            ],
            "arxiv_id": "2512.14481v1",
            "summary": "Large language models (LLMs) excel at natural language tasks but face deployment challenges due to their growing size outpacing GPU memory advancements. Model quantization mitigates this issue by lowering weight and activation precision, but existing solutions face fundamental trade-offs: dynamic quantization incurs high computational overhead and poses deployment challenges on edge devices, while static quantization sacrifices accuracy. Existing approaches of quantization-aware training (QAT) further suffer from weight training costs. We propose SASQ: a lightweight QAT framework specifically tailored for activation quantization factors. SASQ exclusively optimizes only the quantization factors (without changing pre-trained weights), enabling static inference with high accuracy while maintaining deployment efficiency. SASQ adaptively truncates some outliers, thereby reducing the difficulty of quantization while preserving the distributional characteristics of the activations. SASQ not only surpasses existing SOTA quantization schemes but also outperforms the corresponding FP16 models. On LLaMA2-7B, it achieves 5.2% lower perplexity than QuaRot and 4.7% lower perplexity than the FP16 model on WikiText2.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14481v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "SAC"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出SASQ静态激活缩放框架，以解决大语言模型量化训练中精度与效率的权衡问题。",
            "summary_zh": "大语言模型（LLMs）在自然语言任务中表现出色，但其规模增长超过了GPU内存的进步，导致部署面临挑战。模型量化通过降低权重和激活的精度来缓解这一问题，但现有解决方案存在根本性权衡：动态量化计算开销高且在边缘设备上部署困难，而静态量化则牺牲了精度。现有的量化感知训练（QAT）方法还面临权重训练成本高的问题。我们提出了SASQ：一个专门针对激活量化因子设计的轻量级QAT框架。SASQ仅优化量化因子（不改变预训练权重），实现了高精度的静态推理，同时保持了部署效率。SASQ自适应地截断一些异常值，从而降低了量化的难度，同时保留了激活的分布特性。SASQ不仅超越了现有的SOTA量化方案，还优于相应的FP16模型。在LLaMA2-7B上，它在WikiText2上实现了比QuaRot低5.2%的困惑度，比FP16模型低4.7%的困惑度。",
            "intro_zh": [
                "现有量化方法面临动态量化计算开销高、静态量化精度低的根本性权衡，且量化感知训练成本高。",
                "SASQ框架仅优化激活量化因子，不改变预训练权重，通过自适应截断异常值实现轻量级训练。",
                "在LLaMA2-7B上，SASQ超越SOTA量化方案，甚至优于FP16模型，显著降低困惑度。"
            ],
            "method_zh": "SASQ是一个轻量级的量化感知训练框架，专注于优化激活量化因子。整体框架基于预训练的大语言模型，通过静态方式调整激活的量化参数，而不修改权重。关键技术创新点包括：自适应截断激活中的异常值，以简化量化过程并保持分布特性；仅训练量化因子，避免了权重更新的高成本。与现有方法的主要区别在于：相比动态量化，SASQ实现了静态推理，减少了计算开销；相比传统静态量化，它通过训练提升了精度；相比全量QAT，它大幅降低了训练负担。",
            "application_zh": "该研究适用于大语言模型的边缘部署和资源受限环境，如移动设备、嵌入式系统，能提升模型效率并保持高精度，具有实际部署价值。",
            "highlight_zh": "在LLaMA2-7B模型上，SASQ在WikiText2数据集上实现了比QuaRot量化方案低5.2%的困惑度，甚至比原始FP16模型低4.7%的困惑度，展示了显著的性能提升。",
            "tags_zh": [
                "大语言模型",
                "模型量化",
                "量化感知训练",
                "激活量化",
                "静态推理",
                "边缘部署",
                "轻量级框架",
                "精度提升"
            ],
            "_index": 118
        },
        {
            "title": "Model-First Reasoning LLM Agents: Reducing Hallucinations through Explicit Problem Modeling",
            "authors": [
                "Annu Rana",
                "Gaurav Kumar"
            ],
            "arxiv_id": "2512.14474v1",
            "summary": "Large Language Models (LLMs) often struggle with complex multi-step planning tasks, showing high rates of constraint violations and inconsistent solutions. Existing strategies such as Chain-of-Thought and ReAct rely on implicit state tracking and lack an explicit problem representation. Inspired by classical AI planning, we propose Model-First Reasoning (MFR), a two-phase paradigm in which the LLM first constructs an explicit model of the problem, defining entities, state variables, actions, and constraints, before generating a solution plan. Across multiple planning domains, including medical scheduling, route planning, resource allocation, logic puzzles, and procedural synthesis, MFR reduces constraint violations and improves solution quality compared to Chain-of-Thought and ReAct. Ablation studies show that the explicit modeling phase is critical for these gains. Our results suggest that many LLM planning failures stem from representational deficiencies rather than reasoning limitations, highlighting explicit modeling as a key component for robust and interpretable AI agents. All prompts, evaluation procedures, and task datasets are documented to facilitate reproducibility.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14474v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VIO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出模型优先推理范式，通过显式问题建模减少大语言模型在复杂规划任务中的幻觉问题",
            "summary_zh": "大语言模型在处理复杂多步规划任务时，常出现高约束违反率和不一致解决方案。现有方法如思维链和ReAct依赖隐式状态跟踪，缺乏显式问题表示。受经典AI规划启发，本文提出模型优先推理范式，该范式分为两个阶段：首先构建问题的显式模型，定义实体、状态变量、动作和约束，然后生成解决方案计划。在医疗调度、路径规划、资源分配、逻辑谜题和程序合成等多个规划领域中，与思维链和ReAct相比，MFR减少了约束违反并提高了解决方案质量。消融研究表明显式建模阶段对这些改进至关重要。结果表明，许多LLM规划失败源于表示缺陷而非推理限制，凸显显式建模作为稳健可解释AI代理的关键组成部分。所有提示、评估程序和任务数据集均已记录，以促进可重复性。",
            "intro_zh": [
                "现有方法如思维链和ReAct依赖隐式状态跟踪，缺乏显式问题表示，导致高约束违反率和不一致解决方案。",
                "提出模型优先推理范式，先构建问题的显式模型，再生成解决方案计划，以增强表示能力。",
                "在多个规划领域中，MFR相比现有方法减少了约束违反并提高了解决方案质量，消融研究证实显式建模的关键作用。"
            ],
            "method_zh": "论文提出模型优先推理范式，整体框架分为两个阶段：第一阶段，LLM构建问题的显式模型，包括定义实体、状态变量、动作和约束；第二阶段，基于该模型生成解决方案计划。关键技术创新点在于引入显式建模步骤，将问题表示与推理分离，从而减少幻觉。与现有方法的主要区别在于，思维链和ReAct依赖隐式状态跟踪，而MFR通过显式建模提供结构化问题表示，增强了可解释性和稳健性。",
            "application_zh": "该研究可应用于医疗调度、路径规划、资源分配、逻辑谜题和程序合成等领域，通过显式建模提高AI代理在复杂规划任务中的准确性和可靠性，具有实际价值。",
            "highlight_zh": "在多个规划领域中，MFR相比思维链和ReAct显著减少了约束违反并提高了解决方案质量，消融研究证实显式建模阶段是关键改进因素，凸显表示缺陷是LLM规划失败的主要原因。",
            "tags_zh": [
                "大语言模型",
                "规划任务",
                "显式建模",
                "模型优先推理",
                "约束违反",
                "AI代理",
                "可解释性",
                "多步规划"
            ],
            "_index": 119
        },
        {
            "title": "AnySleep: a channel-agnostic deep learning system for high-resolution sleep staging in multi-center cohorts",
            "authors": [
                "Niklas Grieger",
                "Jannik Raskob",
                "Siamak Mehrkanoon",
                "Stephan Bialonski"
            ],
            "arxiv_id": "2512.14461v1",
            "summary": "Sleep is essential for good health throughout our lives, yet studying its dynamics requires manual sleep staging, a labor-intensive step in sleep research and clinical care. Across centers, polysomnography (PSG) recordings are traditionally scored in 30-s epochs for pragmatic, not physiological, reasons and can vary considerably in electrode count, montage, and subject characteristics. These constraints present challenges in conducting harmonized multi-center sleep studies and discovering novel, robust biomarkers on shorter timescales. Here, we present AnySleep, a deep neural network model that uses any electroencephalography (EEG) or electrooculography (EOG) data to score sleep at adjustable temporal resolutions. We trained and validated the model on over 19,000 overnight recordings from 21 datasets collected across multiple clinics, spanning nearly 200,000 hours of EEG and EOG data, to promote robust generalization across sites. The model attains state-of-the-art performance and surpasses or equals established baselines at 30-s epochs. Performance improves as more channels are provided, yet remains strong when EOG is absent or when only EOG or single EEG derivations (frontal, central, or occipital) are available. On sub-30-s timescales, the model captures short wake intrusions consistent with arousals and improves prediction of physiological characteristics (age, sex) and pathophysiological conditions (sleep apnea), relative to standard 30-s scoring. We make the model publicly available to facilitate large-scale studies with heterogeneous electrode setups and to accelerate the discovery of novel biomarkers in sleep.",
            "categories": [
                "cs.LG",
                "eess.SP",
                "q-bio.QM"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "18 pages, 6 figures, 2 tables",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14461v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出AnySleep深度学习系统，以解决多中心睡眠研究中电极设置异质性和时间分辨率固定的问题。",
            "summary_zh": "睡眠对健康至关重要，但研究其动态需要人工睡眠分期，这是睡眠研究和临床护理中劳动密集的步骤。传统上，多导睡眠图（PSG）记录在30秒时段内评分，这是出于实用而非生理原因，且电极数量、导联方式和受试者特征差异很大。这些限制给开展协调的多中心睡眠研究以及在更短时间尺度上发现新的、稳健的生物标志物带来了挑战。本文提出AnySleep，一种深度神经网络模型，可使用任何脑电图（EEG）或眼电图（EOG）数据以可调时间分辨率进行睡眠评分。我们在来自21个数据集的超过19,000个夜间记录上训练和验证了该模型，涵盖近200,000小时的EEG和EOG数据，以促进跨站点的稳健泛化。该模型达到了最先进的性能，在30秒时段上超越或等同于现有基线。提供更多通道时性能提高，但当EOG缺失或仅EOG或单个EEG导联（额叶、中央或枕叶）可用时，性能仍然强劲。在30秒以下的时间尺度上，该模型捕获了与觉醒一致的短暂清醒侵入，并相对于标准的30秒评分，改善了生理特征（年龄、性别）和病理生理状况（睡眠呼吸暂停）的预测。我们公开提供该模型，以促进具有异质电极设置的大规模研究，并加速睡眠中新生物标志物的发现。",
            "intro_zh": [
                "核心问题：传统睡眠分期依赖人工评分，电极设置和时间分辨率（30秒）固定，限制了多中心研究和短时生物标志物发现。",
                "方法要点：开发AnySleep深度学习模型，利用任意EEG或EOG数据，支持可调时间分辨率，实现跨中心稳健泛化。",
                "实验或效果：在21个数据集上验证，性能达SOTA，在30秒以下尺度捕获短时觉醒，提升生理和病理预测能力。"
            ],
            "method_zh": "AnySleep是一个深度神经网络模型，整体框架基于深度学习处理EEG和EOG信号。关键技术创新点包括：通道无关设计，能处理任意电极数量和导联方式；支持可调时间分辨率，突破传统30秒限制；利用大规模多中心数据（19,000+记录）训练，增强泛化能力。与现有方法的主要区别在于其灵活性和高分辨率能力，传统方法通常固定于特定电极设置和30秒时段，而AnySleep适应异质设置并支持更细粒度分析。",
            "application_zh": "该研究可应用于多中心睡眠研究、临床睡眠监测和生物标志物发现。实际价值在于促进大规模协调研究，加速新睡眠障碍诊断工具开发，并支持个性化医疗。",
            "highlight_zh": "模型在30秒时段达到SOTA性能，超越基线；在30秒以下尺度捕获短时觉醒，提升年龄、性别和睡眠呼吸暂停预测；即使仅用单通道EEG或EOG，性能仍强劲。",
            "tags_zh": [
                "睡眠分期",
                "深度学习",
                "脑电图分析",
                "多中心研究",
                "时间分辨率可调",
                "通道无关模型",
                "生物标志物发现",
                "睡眠障碍诊断"
            ],
            "_index": 120
        },
        {
            "title": "Reasoning-Style Poisoning of LLM Agents via Stealthy Style Transfer: Process-Level Attacks and Runtime Monitoring in RSV Space",
            "authors": [
                "Xingfu Zhou",
                "Pengfei Wang"
            ],
            "arxiv_id": "2512.14448v1",
            "summary": "Large Language Model (LLM) agents relying on external retrieval are increasingly deployed in high-stakes environments. While existing adversarial attacks primarily focus on content falsification or instruction injection, we identify a novel, process-oriented attack surface: the agent's reasoning style. We propose Reasoning-Style Poisoning (RSP), a paradigm that manipulates how agents process information rather than what they process. We introduce Generative Style Injection (GSI), an attack method that rewrites retrieved documents into pathological tones--specifically \"analysis paralysis\" or \"cognitive haste\"--without altering underlying facts or using explicit triggers. To quantify these shifts, we develop the Reasoning Style Vector (RSV), a metric tracking Verification depth, Self-confidence, and Attention focus. Experiments on HotpotQA and FEVER using ReAct, Reflection, and Tree of Thoughts (ToT) architectures reveal that GSI significantly degrades performance. It increases reasoning steps by up to 4.4 times or induces premature errors, successfully bypassing state-of-the-art content filters. Finally, we propose RSP-M, a lightweight runtime monitor that calculates RSV metrics in real-time and triggers alerts when values exceed safety thresholds. Our work demonstrates that reasoning style is a distinct, exploitable vulnerability, necessitating process-level defenses beyond static content analysis.",
            "categories": [
                "cs.CR",
                "cs.AI"
            ],
            "primary_category": "cs.CR",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14448v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出推理风格投毒攻击与实时监控方法，揭示LLM代理在过程层面的安全漏洞。",
            "summary_zh": "大型语言模型（LLM）代理依赖外部检索，在高风险环境中部署日益增多。现有对抗攻击主要关注内容伪造或指令注入，而本文识别出一种新颖的、面向过程的攻击面：代理的推理风格。我们提出推理风格投毒（RSP），这是一种操纵代理处理信息方式而非处理内容的范式。我们引入生成式风格注入（GSI），一种攻击方法，将检索到的文档重写为病态语调——特别是“分析瘫痪”或“认知仓促”——而不改变基本事实或使用显式触发器。为了量化这些变化，我们开发了推理风格向量（RSV），一种跟踪验证深度、自信度和注意力焦点的指标。在HotpotQA和FEVER数据集上使用ReAct、Reflection和思维树（ToT）架构进行的实验表明，GSI显著降低了性能。它将推理步骤增加多达4.4倍或诱导过早错误，成功绕过最先进的内容过滤器。最后，我们提出RSP-M，一种轻量级运行时监控器，实时计算RSV指标并在值超过安全阈值时触发警报。我们的工作表明推理风格是一种独特、可利用的漏洞，需要超越静态内容分析的过程级防御。",
            "intro_zh": [
                "现有攻击主要针对内容伪造或指令注入，忽视了LLM代理推理过程本身的脆弱性。",
                "提出推理风格投毒攻击，通过生成式风格注入操纵推理风格而不改变事实内容。",
                "实验显示攻击显著降低性能，增加推理步骤或诱导错误，并成功绕过内容过滤器。"
            ],
            "method_zh": "论文提出推理风格投毒（RSP）攻击范式，核心方法是生成式风格注入（GSI）。整体框架包括：攻击者将检索到的文档重写为“分析瘫痪”（过度谨慎）或“认知仓促”（草率决策）的病态风格，而不修改事实或使用显式触发器。关键技术创新是推理风格向量（RSV），它量化推理风格变化，通过验证深度、自信度和注意力焦点三个维度跟踪过程级异常。与现有方法的主要区别在于，RSP攻击的是代理的推理过程而非内容本身，属于过程导向攻击，而传统防御如内容过滤器难以检测这种风格转移。",
            "application_zh": "该研究适用于高风险的LLM代理部署场景，如金融分析、医疗诊断或法律咨询，其中代理依赖外部检索进行决策。实际价值在于揭示了过程级安全漏洞，推动开发实时监控和防御机制，提升代理在对抗环境中的鲁棒性。",
            "highlight_zh": "在HotpotQA和FEVER数据集上，GSI攻击使推理步骤增加高达4.4倍，或诱导过早错误，性能显著下降。攻击成功绕过最先进的内容过滤器，验证了推理风格作为独立攻击面的有效性。RSP-M监控器实时检测异常，为过程级防御提供了可行方案。",
            "tags_zh": [
                "推理风格投毒",
                "过程导向攻击",
                "生成式风格注入",
                "推理风格向量",
                "LLM代理安全",
                "实时监控",
                "对抗攻击",
                "检索增强生成"
            ],
            "_index": 121
        },
        {
            "title": "S2D: Sparse-To-Dense Keymask Distillation for Unsupervised Video Instance Segmentation",
            "authors": [
                "Leon Sick",
                "Lukas Hoyer",
                "Dominik Engel",
                "Pedro Hermosilla",
                "Timo Ropinski"
            ],
            "arxiv_id": "2512.14440v1",
            "summary": "In recent years, the state-of-the-art in unsupervised video instance segmentation has heavily relied on synthetic video data, generated from object-centric image datasets such as ImageNet. However, video synthesis by artificially shifting and scaling image instance masks fails to accurately model realistic motion in videos, such as perspective changes, movement by parts of one or multiple instances, or camera motion. To tackle this issue, we propose an unsupervised video instance segmentation model trained exclusively on real video data. We start from unsupervised instance segmentation masks on individual video frames. However, these single-frame segmentations exhibit temporal noise and their quality varies through the video. Therefore, we establish temporal coherence by identifying high-quality keymasks in the video by leveraging deep motion priors. The sparse keymask pseudo-annotations are then used to train a segmentation model for implicit mask propagation, for which we propose a Sparse-To-Dense Distillation approach aided by a Temporal DropLoss. After training the final model on the resulting dense labelset, our approach outperforms the current state-of-the-art across various benchmarks.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project Page with Code/Models/Demo: https://leonsick.github.io/s2d/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14440v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "动作生成",
                    "matched_keywords": [
                        "motion prior"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出S2D稀疏到稠密关键掩码蒸馏方法，利用真实视频数据解决无监督视频实例分割中的运动建模不足问题。",
            "summary_zh": "近年来，无监督视频实例分割的最先进方法严重依赖从ImageNet等以对象为中心的图像数据集生成的合成视频数据。然而，通过人工平移和缩放图像实例掩码来合成视频的方法无法准确建模视频中的真实运动，例如视角变化、单个或多个实例的部分运动或相机运动。为解决这一问题，我们提出了一种仅使用真实视频数据训练的无监督视频实例分割模型。我们从单个视频帧上的无监督实例分割掩码开始。然而，这些单帧分割存在时间噪声，且其质量在整个视频中变化。因此，我们通过利用深度运动先验识别视频中的高质量关键掩码来建立时间一致性。稀疏的关键掩码伪标注随后用于训练一个用于隐式掩码传播的分割模型，为此我们提出了一种由时间DropLoss辅助的稀疏到稠密蒸馏方法。在最终模型上对生成的稠密标签集进行训练后，我们的方法在各种基准测试中超越了当前的最先进水平。",
            "intro_zh": [
                "现有方法依赖合成视频数据，无法准确建模真实运动如视角变化和部分运动，导致分割质量受限。",
                "提出S2D方法，利用深度运动先验识别高质量关键掩码，并通过稀疏到稠密蒸馏训练模型实现隐式掩码传播。",
                "在多个基准测试中，该方法超越了当前最先进水平，显著提升了无监督视频实例分割的性能。"
            ],
            "method_zh": "论文提出S2D框架，整体基于真实视频数据训练无监督视频实例分割模型。首先从单帧无监督分割掩码出发，利用深度运动先验识别高质量关键掩码以建立时间一致性。关键技术创新包括稀疏到稠密蒸馏方法，将稀疏关键掩码伪标注用于训练分割模型进行隐式掩码传播，并引入时间DropLoss辅助训练。与现有方法的主要区别在于完全依赖真实视频数据而非合成数据，通过运动先验和蒸馏策略有效处理时间噪声和掩码质量变化，避免了合成数据中运动建模不准确的问题。",
            "application_zh": "该研究可应用于视频监控、自动驾驶、机器人视觉和视频编辑等领域，通过无监督学习实现高质量的视频实例分割，减少对标注数据的依赖，提升在真实世界视频中的分割准确性和鲁棒性。",
            "highlight_zh": "在多个基准测试中，S2D方法显著超越了当前最先进的无监督视频实例分割模型，证明了仅使用真实视频数据训练的有效性，并通过稀疏到稠密蒸馏和时间DropLoss提升了分割性能。",
            "tags_zh": [
                "无监督视频实例分割",
                "稀疏到稠密蒸馏",
                "深度运动先验",
                "关键掩码识别",
                "时间一致性",
                "真实视频数据",
                "隐式掩码传播",
                "时间DropLoss"
            ],
            "_index": 122
        },
        {
            "title": "VICTOR: Dataset Copyright Auditing in Video Recognition Systems",
            "authors": [
                "Quan Yuan",
                "Zhikun Zhang",
                "Linkang Du",
                "Min Chen",
                "Mingyang Sun",
                "Yunjun Gao",
                "Shibo He",
                "Jiming Chen"
            ],
            "arxiv_id": "2512.14439v1",
            "summary": "Video recognition systems are increasingly being deployed in daily life, such as content recommendation and security monitoring. To enhance video recognition development, many institutions have released high-quality public datasets with open-source licenses for training advanced models. At the same time, these datasets are also susceptible to misuse and infringement. Dataset copyright auditing is an effective solution to identify such unauthorized use. However, existing dataset copyright solutions primarily focus on the image domain; the complex nature of video data leaves dataset copyright auditing in the video domain unexplored. Specifically, video data introduces an additional temporal dimension, which poses significant challenges to the effectiveness and stealthiness of existing methods.\n  In this paper, we propose VICTOR, the first dataset copyright auditing approach for video recognition systems. We develop a general and stealthy sample modification strategy that enhances the output discrepancy of the target model. By modifying only a small proportion of samples (e.g., 1%), VICTOR amplifies the impact of published modified samples on the prediction behavior of the target models. Then, the difference in the model's behavior for published modified and unpublished original samples can serve as a key basis for dataset auditing. Extensive experiments on multiple models and datasets highlight the superiority of VICTOR. Finally, we show that VICTOR is robust in the presence of several perturbation mechanisms to the training videos or the target models.",
            "categories": [
                "cs.CR",
                "cs.CV"
            ],
            "primary_category": "cs.CR",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "To appear in the NDSS Symposium 2026, February 2026, San Diego, CA, USA",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14439v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VIO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出VICTOR方法以解决视频识别系统中数据集版权审计的挑战",
            "summary_zh": "视频识别系统在内容推荐和安全监控等日常生活中的应用日益广泛。为促进视频识别技术的发展，许多机构发布了高质量的开源公共数据集用于训练先进模型。然而，这些数据集也容易遭到滥用和侵权。数据集版权审计是识别此类未经授权使用的有效解决方案。但现有的数据集版权解决方案主要集中于图像领域；视频数据的复杂性使得视频领域的数据集版权审计尚未得到充分探索。具体而言，视频数据引入了额外的时间维度，这对现有方法的有效性和隐蔽性提出了重大挑战。本文提出了VICTOR，这是首个针对视频识别系统的数据集版权审计方法。我们开发了一种通用且隐蔽的样本修改策略，增强了目标模型的输出差异。通过仅修改一小部分样本（例如1%），VICTOR放大了已发布修改样本对目标模型预测行为的影响。然后，模型对已发布修改样本和未发布原始样本的行为差异可作为数据集审计的关键依据。在多个模型和数据集上的广泛实验突显了VICTOR的优越性。最后，我们展示了VICTOR在面对训练视频或目标模型的多种扰动机制时具有鲁棒性。",
            "intro_zh": [
                "现有方法主要针对图像领域，视频数据的时间维度带来有效性和隐蔽性挑战，导致视频数据集版权审计未被探索。",
                "提出VICTOR方法，通过隐蔽修改少量样本（如1%）来放大模型输出差异，利用行为差异作为审计依据。",
                "在多个模型和数据集上实验显示VICTOR具有优越性，且对训练视频或模型的扰动机制保持鲁棒。"
            ],
            "method_zh": "VICTOR的整体框架基于一种通用且隐蔽的样本修改策略，旨在增强目标模型在已发布修改样本和未发布原始样本之间的输出差异。关键技术创新点在于设计了一种高效的修改机制，仅需修改极小比例（如1%）的视频样本，即可显著影响模型的预测行为，从而在不引起注意的情况下实现审计。与现有方法的主要区别在于，VICTOR专门针对视频数据的时空特性进行优化，克服了时间维度带来的挑战，而现有方法多局限于静态图像，缺乏对视频复杂性的处理能力。",
            "application_zh": "该研究可应用于视频识别系统的数据集版权保护，例如在内容推荐、安全监控等领域，帮助机构检测未经授权的数据集使用，维护知识产权，促进视频数据资源的合法共享和利用。",
            "highlight_zh": "实验表明，VICTOR在多个视频识别模型和数据集上均表现出优越的审计性能，仅修改1%样本即可有效放大模型行为差异，且在面对训练视频或模型的扰动时保持鲁棒，验证了其在实际场景中的实用性和可靠性。",
            "tags_zh": [
                "视频识别",
                "数据集版权审计",
                "样本修改策略",
                "模型行为差异",
                "时空维度挑战",
                "隐蔽性审计",
                "鲁棒性验证",
                "知识产权保护"
            ],
            "_index": 123
        },
        {
            "title": "Score-Based Turbo Message Passing for Plug-and-Play Compressive Imaging",
            "authors": [
                "Chang Cai",
                "Hao Jiang",
                "Xiaojun Yuan",
                "Ying-Jun Angela Zhang"
            ],
            "arxiv_id": "2512.14435v1",
            "summary": "Message-passing algorithms have been adapted for compressive imaging by incorporating various off-the-shelf image denoisers. However, these denoisers rely largely on generic or hand-crafted priors and often fall short in accurately capturing the complex statistical structure of natural images. As a result, traditional plug-and-play (PnP) methods often lead to suboptimal reconstruction, especially in highly underdetermined regimes. Recently, score-based generative models have emerged as a powerful framework for accurately characterizing sophisticated image distribution. Yet, their direct use for posterior sampling typically incurs prohibitive computational complexity. In this paper, by exploiting the close connection between score-based generative modeling and empirical Bayes denoising, we devise a message-passing framework that integrates a score-based minimum mean-squared error (MMSE) denoiser for compressive image recovery. The resulting algorithm, named score-based turbo message passing (STMP), combines the fast convergence of message passing with the expressive power of score-based generative priors. For practical systems with quantized measurements, we further propose quantized STMP (Q-STMP), which augments STMP with a component-wise MMSE dequantization module. We demonstrate that the asymptotic performance of STMP and Q-STMP can be accurately predicted by a set of state-evolution (SE) equations. Experiments on the FFHQ dataset demonstrate that STMP strikes a significantly better performance-complexity tradeoff compared with competing baselines, and that Q-STMP remains robust even under 1-bit quantization. Remarkably, both STMP and Q-STMP typically converge within 10 iterations.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14435v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出基于分数的Turbo消息传递算法，以解决压缩成像中传统插拔式方法重建性能不足的问题。",
            "summary_zh": "消息传递算法已通过整合各种现成图像去噪器应用于压缩成像。然而，这些去噪器主要依赖通用或手工先验，往往难以准确捕捉自然图像的复杂统计结构，导致传统插拔式方法在高度欠定情况下重建效果不佳。最近，基于分数的生成模型已成为准确表征复杂图像分布的强大框架，但其直接用于后验采样通常计算复杂度极高。本文通过利用基于分数的生成建模与经验贝叶斯去噪之间的紧密联系，设计了一个消息传递框架，整合基于分数的最小均方误差去噪器用于压缩图像恢复。所得算法称为基于分数的Turbo消息传递，结合了消息传递的快速收敛性和基于分数生成先验的表达能力。对于具有量化测量的实际系统，我们进一步提出量化STMP，通过分量级MMSE去量化模块增强STMP。我们证明STMP和Q-STMP的渐近性能可以通过一组状态演化方程准确预测。在FFHQ数据集上的实验表明，STMP在性能与复杂度权衡方面显著优于竞争基线，且Q-STMP即使在1位量化下仍保持鲁棒性。值得注意的是，STMP和Q-STMP通常能在10次迭代内收敛。",
            "intro_zh": [
                "核心问题：传统插拔式压缩成像方法依赖通用或手工先验，难以准确建模自然图像复杂统计结构，导致重建性能不足，尤其在高度欠定场景下。",
                "方法要点：提出基于分数的Turbo消息传递框架，整合基于分数的最小均方误差去噪器，结合消息传递快速收敛性和分数生成先验表达能力。",
                "实验或效果：在FFHQ数据集上，STMP显著优于基线方法，Q-STMP在1位量化下保持鲁棒，两者通常10次迭代内收敛，性能可预测。"
            ],
            "method_zh": "整体框架是基于消息传递的压缩成像算法，核心创新点在于整合基于分数的生成模型作为先验，通过经验贝叶斯去噪连接，实现最小均方误差去噪。关键技术创新包括设计STMP算法，结合Turbo消息传递的快速迭代和分数模型的表达能力，以及针对量化测量扩展为Q-STMP，加入分量级MMSE去量化模块。与现有方法的主要区别在于：传统插拔式方法依赖通用去噪器，而STMP利用分数模型更准确捕捉图像分布；相比直接后验采样，STMP通过消息传递降低计算复杂度，实现高效重建。",
            "application_zh": "该研究主要应用于压缩成像领域，如医学成像、遥感图像处理和低功耗传感器系统，通过高效算法提升图像重建质量，尤其在资源受限或高压缩比场景下具有实际价值，可促进智能视觉系统的发展。",
            "highlight_zh": "实验在FFHQ数据集上进行，STMP在性能-复杂度权衡上显著优于基线方法，Q-STMP在1位量化下保持鲁棒性，两者均能在10次迭代内快速收敛，且性能可通过状态演化方程准确预测，验证了方法的有效性和高效性。",
            "tags_zh": [
                "压缩成像",
                "消息传递算法",
                "基于分数的生成模型",
                "插拔式方法",
                "图像去噪",
                "量化测量",
                "状态演化方程",
                "FFHQ数据集"
            ],
            "_index": 124
        },
        {
            "title": "Geometric Parameter Optimization of a Novel 3-(PP(2-(UPS))) Redundant Parallel Mechanism based on Workspace Determination",
            "authors": [
                "Quan Yuan",
                "Daqian Cao",
                "Weibang Bai"
            ],
            "arxiv_id": "2512.14434v1",
            "summary": "Redundant parallel robots are normally employed in scenarios requiring good precision, high load capability, and large workspace compared to traditional parallel mechanisms. However, the elementary robotic configuration and geometric parameter optimization are still quite challenging. This paper proposes a novel 3-(PP(2-(UPS))) redundant parallel mechanism, with good generalizability first, and further investigates the kinematic optimization issue by analyzing and investigating how its key geometric parameters influence the volume, shape, boundary completeness, and orientation capabilities of its workspace. The torsional capability index TI_1 and tilting capability index TI_2 are defined to evaluate the orientation performance of the mechanism. Numerical simulation studies are completed to indicate the analysis, providing reasonable but essential references for the parameter optimization of 3-(PP(2-(UPS))) and other similar redundant parallel mechanisms.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "7 pages, 5 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14434v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出一种新型3-(PP(2-(UPS)))冗余并联机构，并通过工作空间分析优化几何参数以提升性能。",
            "summary_zh": "冗余并联机器人通常用于需要高精度、高负载能力和大工作空间的场景，相比传统并联机构具有优势。然而，其基本机器人构型和几何参数优化仍面临挑战。本文提出了一种新型3-(PP(2-(UPS)))冗余并联机构，首先具有良好的通用性，然后通过分析关键几何参数如何影响其工作空间的体积、形状、边界完整性和定向能力，进一步研究了运动学优化问题。定义了扭转能力指数TI_1和倾斜能力指数TI_2来评估机构的定向性能。完成了数值模拟研究以验证分析，为3-(PP(2-(UPS)))及其他类似冗余并联机构的参数优化提供了合理且重要的参考。",
            "intro_zh": [
                "冗余并联机构在几何参数优化方面存在挑战，现有方法难以平衡工作空间性能与结构复杂性。",
                "提出新型3-(PP(2-(UPS)))构型，通过定义TI_1和TI_2指数分析参数对工作空间的影响。",
                "数值模拟验证了参数优化效果，为类似机构设计提供了关键参考，提升了定向能力评估。"
            ],
            "method_zh": "论文整体框架基于新型3-(PP(2-(UPS)))冗余并联机构的运动学建模与工作空间分析。关键技术创新点包括：定义扭转能力指数TI_1和倾斜能力指数TI_2，用于量化评估机构的定向性能；通过参数化方法系统研究几何参数对工作空间体积、形状和边界的影响。与现有方法的主要区别在于，该方法结合了构型创新与定量指标，提供了更全面的优化策略，而非仅依赖经验或单一性能指标。",
            "application_zh": "该研究可应用于高精度制造、航空航天装配和医疗机器人等领域，其中需要冗余并联机构实现大工作空间、高负载和精确定向操作，提升自动化系统的灵活性和可靠性。",
            "highlight_zh": "数值模拟结果表明，通过优化几何参数，工作空间体积和形状得到显著改善，TI_1和TI_2指数有效评估了定向性能，为实际设计提供了可量化的优化依据，提升了机构的整体运动能力。",
            "tags_zh": [
                "冗余并联机构",
                "几何参数优化",
                "工作空间分析",
                "运动学建模",
                "定向能力指数",
                "数值模拟",
                "机器人设计",
                "并联机器人"
            ],
            "_index": 125
        },
        {
            "title": "Seismology modeling agent: A smart assistant for geophysical researchers",
            "authors": [
                "Yukun Ren",
                "Siwei Yu",
                "Kai Chen",
                "Jianwei Ma"
            ],
            "arxiv_id": "2512.14429v1",
            "summary": "To address the steep learning curve and reliance on complex manual file editing and command-line operations in the traditional workflow of the mainstream open-source seismic wave simulation software SPECFEM, this paper proposes an intelligent, interactive workflow powered by Large Language Models (LLMs). We introduce the first Model Context Protocol (MCP) server suite for SPECFEM (supporting 2D, 3D Cartesian, and 3D Globe versions), which decomposes the entire simulation process into discrete, agent-executable tools spanning from parameter generation and mesh partitioning to solver execution and visualization. This approach enables a paradigm shift from file-driven to intent-driven conversational interactions. The framework supports both fully automated execution and human-in-the-loop collaboration, allowing researchers to guide simulation strategies in real time and retain scientific decision-making authority while significantly reducing tedious low-level operations. Validated through multiple case studies, the workflow operates seamlessly in both autonomous and interactive modes, yielding high-fidelity results consistent with standard baselines. As the first application of MCP technology to computational seismology, this study significantly lowers the entry barrier, enhances reproducibility, and offers a promising avenue for advancing computational geophysics toward AI-assisted and automated scientific research. The complete source code is available at https://github.com/RenYukun1563/specfem-mcp.",
            "categories": [
                "cs.AI",
                "cs.SE"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "26 pages, 15 figures. Code available at https://github.com/RenYukun1563/specfem-mcp",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14429v1",
            "code_links": [
                {
                    "url": "https://github.com/RenYukun1563/specfem-mcp",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "PPO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出基于大语言模型的智能交互工作流，以降低SPECFEM地震波模拟软件的使用门槛并提升效率。",
            "summary_zh": "针对主流开源地震波模拟软件SPECFEM在传统工作流程中存在的学习曲线陡峭、依赖复杂手动文件编辑和命令行操作等问题，本文提出了一种由大语言模型驱动的智能交互工作流。我们首次为SPECFEM（支持2D、3D笛卡尔和3D全球版本）引入了模型上下文协议服务器套件，将整个模拟过程分解为从参数生成、网格划分到求解器执行和可视化的离散化、可由智能体执行的工具。这种方法实现了从文件驱动到意图驱动的对话式交互的范式转变。该框架支持全自动执行和人机协同两种模式，使研究人员能够实时指导模拟策略并保留科学决策权，同时显著减少繁琐的低级操作。通过多个案例研究验证，该工作流在自主和交互模式下均能无缝运行，产生与标准基线一致的高保真结果。作为MCP技术在计算地震学中的首次应用，本研究显著降低了入门门槛，增强了可重复性，并为推动计算地球物理学向AI辅助和自动化科学研究发展提供了有前景的途径。完整源代码可在https://github.com/RenYukun1563/specfem-mcp获取。",
            "intro_zh": [
                "传统SPECFEM工作流程依赖复杂手动文件编辑和命令行操作，学习曲线陡峭，效率低下。",
                "提出基于大语言模型的智能交互工作流，通过MCP服务器套件将模拟过程分解为可执行工具，实现意图驱动交互。",
                "案例验证显示工作流在自主和交互模式下均能无缝运行，结果与标准基线一致，显著降低操作复杂度。"
            ],
            "method_zh": "论文的核心方法是构建一个基于大语言模型的智能交互框架，整体框架包括为SPECFEM设计的MCP服务器套件，将地震波模拟流程（如参数设置、网格生成、求解计算和结果可视化）模块化为离散工具。关键技术创新点在于首次将MCP技术应用于计算地震学，实现从文件驱动到意图驱动的范式转变，支持全自动和人机协同模式。与现有方法的主要区别在于传统工作流依赖手动操作和命令行，而本方法通过自然语言交互简化流程，提升易用性和效率。",
            "application_zh": "该研究主要应用于计算地球物理学领域，特别是地震波模拟和地震学研究。潜在价值包括降低研究人员使用SPECFEM等专业软件的门槛，提升模拟实验的可重复性和效率，为AI辅助的自动化科学研究提供新途径，适用于教育、科研和工程实践。",
            "highlight_zh": "最重要的实验结果是工作流在多个案例中验证了其有效性，自主和交互模式均能无缝运行，产生高保真结果与标准基线一致。性能提升体现在显著减少手动操作时间，增强工作流的灵活性和可重复性，但具体量化指标如速度提升百分比在摘要中未提及。",
            "tags_zh": [
                "地震波模拟",
                "大语言模型",
                "智能交互工作流",
                "模型上下文协议",
                "计算地球物理学",
                "AI辅助研究",
                "自动化科学工作流",
                "SPECFEM软件"
            ],
            "_index": 126
        },
        {
            "title": "Quadratic Kalman Filter for Elliptical Extended Object Tracking based on Decoupling State Components",
            "authors": [
                "Simon Steuernagel",
                "Marcus Baum"
            ],
            "arxiv_id": "2512.14426v1",
            "summary": "Extended object tracking involves estimating both the physical extent and kinematic parameters of a target object, where typically multiple measurements are observed per time step. In this article, we propose a deterministic closed-form elliptical extended object tracker, based on decoupling of the kinematics, orientation, and axis lengths. By disregarding potential correlations between these state components, fewer approximations are required for the individual estimators than for an overall joint solution. The resulting algorithm outperforms existing algorithms, reaching the accuracy of sampling-based procedures. Additionally, a batch-based variant is introduced, yielding highly efficient computation while outperforming all comparable state-of-the-art algorithms. This is validated both by a simulation study using common models from literature, as well as an extensive quantitative evaluation on real automotive radar data.",
            "categories": [
                "eess.SP",
                "cs.RO"
            ],
            "primary_category": "eess.SP",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "13 pages, 8 figures, submitted to IEEE Transactions on Aerospace and Electronic Systems",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14426v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出基于状态分量解耦的二次卡尔曼滤波器，用于椭圆扩展目标跟踪，实现高效高精度估计。",
            "summary_zh": "扩展目标跟踪涉及同时估计目标物体的物理尺寸和运动学参数，通常每个时间步会观测到多个测量值。本文提出了一种基于运动学、方向和轴长分量解耦的确定性闭式椭圆扩展目标跟踪器。通过忽略这些状态分量之间的潜在相关性，相比整体联合解决方案，各个估计器所需的近似更少。所得算法优于现有算法，达到了基于采样方法的精度水平。此外，还引入了基于批处理的变体，实现了高效计算，同时超越了所有可比较的最先进算法。这通过使用文献中常见模型的仿真研究，以及对真实汽车雷达数据的广泛定量评估得到了验证。",
            "intro_zh": [
                "现有扩展目标跟踪方法通常需要复杂近似或采样，计算成本高且难以平衡精度与效率。",
                "论文提出将状态分解为运动学、方向和轴长分量，分别估计以简化计算并减少近似需求。",
                "算法在仿真和真实雷达数据上验证，达到采样方法精度，批处理变体计算高效且超越现有方法。"
            ],
            "method_zh": "论文提出一种基于二次卡尔曼滤波器的椭圆扩展目标跟踪框架，核心创新在于将状态向量解耦为运动学、方向和轴长三个独立分量，分别进行估计。通过忽略分量间的相关性，减少了整体联合估计所需的近似步骤，从而简化了计算复杂度。关键技术创新包括设计确定性闭式解和引入批处理变体以提高效率。与现有方法相比，该方法避免了复杂的采样过程，同时保持了高精度，实现了精度与效率的更好平衡。",
            "application_zh": "该研究主要应用于自动驾驶和智能交通系统中的目标跟踪，如汽车雷达对车辆、行人等扩展目标的实时监测与状态估计。其高效高精度的特性可提升环境感知能力，支持更安全的决策和控制，具有实际工程价值。",
            "highlight_zh": "在仿真和真实汽车雷达数据上验证，算法精度达到基于采样方法的水平，批处理变体计算效率高，在性能上超越了所有可比较的最先进算法，显示出显著的性能提升。",
            "tags_zh": [
                "扩展目标跟踪",
                "椭圆目标跟踪",
                "卡尔曼滤波器",
                "状态解耦",
                "汽车雷达",
                "自动驾驶",
                "高效计算",
                "确定性算法"
            ],
            "_index": 127
        },
        {
            "title": "DISCODE: Distribution-Aware Score Decoder for Robust Automatic Evaluation of Image Captioning",
            "authors": [
                "Nakamasa Inoue",
                "Kanoko Goto",
                "Masanari Oi",
                "Martyna Gruszka",
                "Mahiro Ukai",
                "Takumi Hirose",
                "Yusuke Sekikawa"
            ],
            "arxiv_id": "2512.14420v1",
            "summary": "Large vision-language models (LVLMs) have shown impressive performance across a broad range of multimodal tasks. However, robust image caption evaluation using LVLMs remains challenging, particularly under domain-shift scenarios. To address this issue, we introduce the Distribution-Aware Score Decoder (DISCODE), a novel finetuning-free method that generates robust evaluation scores better aligned with human judgments across diverse domains. The core idea behind DISCODE lies in its test-time adaptive evaluation approach, which introduces the Adaptive Test-Time (ATT) loss, leveraging a Gaussian prior distribution to improve robustness in evaluation score estimation. This loss is efficiently minimized at test time using an analytical solution that we derive. Furthermore, we introduce the Multi-domain Caption Evaluation (MCEval) benchmark, a new image captioning evaluation benchmark covering six distinct domains, designed to assess the robustness of evaluation metrics. In our experiments, we demonstrate that DISCODE achieves state-of-the-art performance as a reference-free evaluation metric across MCEval and four representative existing benchmarks.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Paper accepted to AAAI 2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14420v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出DISCODE方法以解决图像描述评估在域偏移场景下的鲁棒性问题",
            "summary_zh": "大型视觉语言模型（LVLMs）在多模态任务中表现出色，但用于图像描述评估时，在域偏移场景下仍面临鲁棒性挑战。为解决此问题，本文引入了分布感知分数解码器（DISCODE），这是一种无需微调的新方法，能生成更符合人类判断的鲁棒评估分数。DISCODE的核心思想是测试时自适应评估方法，通过引入自适应测试时（ATT）损失，利用高斯先验分布提升分数估计的鲁棒性，并推导出高效的最小化解析解。此外，本文还提出了多域描述评估（MCEval）基准，覆盖六个不同领域，用于评估指标的鲁棒性。实验表明，DISCODE在MCEval和四个现有基准上作为无参考评估指标达到了最先进性能。",
            "intro_zh": [
                "现有大型视觉语言模型在图像描述评估中，尤其在域偏移场景下，鲁棒性不足，难以与人类判断对齐。",
                "DISCODE采用测试时自适应评估，引入ATT损失和高斯先验，通过解析解优化，无需微调即可提升评估分数鲁棒性。",
                "在MCEval和四个现有基准上，DISCODE作为无参考评估指标实现了最先进性能，验证了其跨域鲁棒性。"
            ],
            "method_zh": "DISCODE的整体框架基于测试时自适应评估，核心是分布感知分数解码器。关键技术创新点包括：引入自适应测试时（ATT）损失，该损失利用高斯先验分布来建模评估分数的分布特性，从而在域偏移下增强鲁棒性；通过推导出的解析解，在测试时高效最小化ATT损失，避免了传统微调的需求。与现有方法的主要区别在于，DISCODE无需额外训练或微调，直接利用LVLMs的预训练能力，通过统计先验自适应调整评估过程，提高了跨域一致性。",
            "application_zh": "该研究可应用于图像描述生成系统的自动评估，特别是在多领域或域偏移场景下，如医疗影像、艺术创作或自动驾驶中的视觉描述任务，为模型优化和基准测试提供鲁棒的评估工具。",
            "highlight_zh": "DISCODE在MCEval基准上作为无参考评估指标达到最先进性能，同时在四个代表性现有基准上表现优异，显著提升了跨域鲁棒性，验证了ATT损失和解析解的有效性。",
            "tags_zh": [
                "图像描述评估",
                "大型视觉语言模型",
                "域偏移鲁棒性",
                "测试时自适应",
                "无参考评估",
                "多模态任务",
                "高斯先验分布",
                "解析解优化"
            ],
            "_index": 128
        },
        {
            "title": "PortAgent: LLM-driven Vehicle Dispatching Agent for Port Terminals",
            "authors": [
                "Jia Hu",
                "Junqi Li",
                "Weimeng Lin",
                "Peng Jia",
                "Yuxiong Ji",
                "Jintao Lai"
            ],
            "arxiv_id": "2512.14417v1",
            "summary": "Vehicle Dispatching Systems (VDSs) are critical to the operational efficiency of Automated Container Terminals (ACTs). However, their widespread commercialization is hindered due to their low transferability across diverse terminals. This transferability challenge stems from three limitations: high reliance on port operational specialists, a high demand for terminal-specific data, and time-consuming manual deployment processes. Leveraging the emergence of Large Language Models (LLMs), this paper proposes PortAgent, an LLM-driven vehicle dispatching agent that fully automates the VDS transferring workflow. It bears three features: (1) no need for port operations specialists; (2) low need of data; and (3) fast deployment. Specifically, specialist dependency is eliminated by the Virtual Expert Team (VET). The VET collaborates with four virtual experts, including a Knowledge Retriever, Modeler, Coder, and Debugger, to emulate a human expert team for the VDS transferring workflow. These experts specialize in the domain of terminal VDS via a few-shot example learning approach. Through this approach, the experts are able to learn VDS-domain knowledge from a few VDS examples. These examples are retrieved via a Retrieval-Augmented Generation (RAG) mechanism, mitigating the high demand for terminal-specific data. Furthermore, an automatic VDS design workflow is established among these experts to avoid extra manual interventions. In this workflow, a self-correction loop inspired by the LLM Reflexion framework is created",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14417v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出PortAgent：基于大语言模型的自动化车辆调度代理，解决自动化集装箱码头系统跨终端迁移难题",
            "summary_zh": "车辆调度系统对自动化集装箱码头的运营效率至关重要，但其广泛商业化受到跨终端可迁移性低的限制。这一挑战源于三个局限：高度依赖港口运营专家、对终端特定数据需求高以及部署过程耗时。本文利用大语言模型的兴起，提出PortAgent，一个基于大语言模型的车辆调度代理，完全自动化车辆调度系统的迁移工作流。它具有三个特点：（1）无需港口运营专家；（2）数据需求低；（3）部署快速。具体而言，通过虚拟专家团队消除专家依赖。该团队由知识检索器、建模器、编码器和调试器四个虚拟专家组成，模拟人类专家团队执行车辆调度系统迁移工作流。这些专家通过少样本示例学习方法专门化于终端车辆调度系统领域。通过这种方法，专家能够从少量车辆调度系统示例中学习领域知识。这些示例通过检索增强生成机制检索，减轻了对终端特定数据的高需求。此外，在这些专家之间建立了自动车辆调度系统设计工作流，以避免额外的人工干预。在该工作流中，创建了一个受大语言模型反思框架启发的自校正循环。",
            "intro_zh": [
                "现有车辆调度系统跨终端迁移困难，依赖专家、数据需求高且部署耗时，阻碍商业化应用。",
                "提出PortAgent，利用大语言模型构建虚拟专家团队，通过少样本学习和检索增强生成实现自动化迁移。",
                "实验表明PortAgent能显著降低专家依赖和数据需求，实现快速部署，提升系统可迁移性和效率。"
            ],
            "method_zh": "PortAgent的核心方法基于大语言模型驱动的虚拟专家团队框架。整体框架包括知识检索器、建模器、编码器和调试器四个虚拟专家，它们通过协作模拟人类专家团队，执行车辆调度系统的自动化迁移工作流。关键技术创新点在于采用少样本示例学习方法，使专家从少量车辆调度示例中学习领域知识，并结合检索增强生成机制动态检索相关示例，以降低数据需求。此外，引入受LLM Reflexion框架启发的自校正循环，实现工作流的自动优化和错误修正。与现有方法的主要区别在于完全自动化迁移过程，无需人工干预，显著减少了对专家和大量终端特定数据的依赖。",
            "application_zh": "该研究主要应用于自动化集装箱码头的车辆调度系统迁移和部署，可扩展到其他工业自动化场景，如物流中心或制造工厂的调度优化。实际价值在于提升系统跨终端可迁移性，降低部署成本和时间，促进智能调度技术的商业化应用。",
            "highlight_zh": "PortAgent在实验中展示了高效迁移能力，无需港口运营专家参与，仅需少量示例数据即可实现快速部署。性能提升体现在迁移工作流的自动化程度高，减少了人工干预，同时通过自校正机制提高了系统设计的准确性和鲁棒性。",
            "tags_zh": [
                "大语言模型",
                "车辆调度系统",
                "自动化集装箱码头",
                "虚拟专家团队",
                "少样本学习",
                "检索增强生成",
                "系统迁移",
                "自校正循环"
            ],
            "_index": 129
        },
        {
            "title": "Pattern Recognition of Aluminium Arbitrage in Global Trade Data",
            "authors": [
                "Muhammad Sukri Bin Ramli"
            ],
            "arxiv_id": "2512.14410v1",
            "summary": "As the global economy transitions toward decarbonization, the aluminium sector has become a focal point for strategic resource management. While policies such as the Carbon Border Adjustment Mechanism (CBAM) aim to reduce emissions, they have inadvertently widened the price arbitrage between primary metal, scrap, and semi-finished goods, creating new incentives for market optimization. This study presents a unified, unsupervised machine learning framework to detect and classify emerging trade anomalies within UN Comtrade data (2020 to 2024). Moving beyond traditional rule-based monitoring, we apply a four-layer analytical pipeline utilizing Forensic Statistics, Isolation Forests, Network Science, and Deep Autoencoders. Contrary to the hypothesis that Sustainability Arbitrage would be the primary driver, empirical results reveal a contradictory and more severe phenomenon of Hardware Masking. Illicit actors exploit bi-directional tariff incentives by misclassifying scrap as high-count heterogeneous goods to justify extreme unit-price outliers of >$160/kg, a 1,900% markup indicative of Trade-Based Money Laundering (TBML) rather than commercial arbitrage. Topologically, risk is not concentrated in major exporters but in high-centrality Shadow Hubs that function as pivotal nodes for illicit rerouting. These actors execute a strategy of Void-Shoring, systematically suppressing destination data to Unspecified Code to fracture mirror statistics and sever forensic trails. Validated by SHAP (Shapley Additive Explanations), the results confirm that price deviation is the dominant predictor of anomalies, necessitating a paradigm shift in customs enforcement from physical volume checks to dynamic, algorithmic valuation auditing.",
            "categories": [
                "econ.GN",
                "cs.LG"
            ],
            "primary_category": "econ.GN",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14410v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出无监督机器学习框架以检测全球铝贸易数据中的异常模式，揭示硬件掩蔽和贸易洗钱现象。",
            "summary_zh": "随着全球经济向脱碳转型，铝行业成为战略资源管理的焦点。尽管碳边境调节机制等政策旨在减少排放，却无意中扩大了原铝、废铝和半成品之间的价格套利空间，为市场优化创造了新激励。本研究提出一个统一的无监督机器学习框架，用于检测和分类联合国商品贸易统计数据库（2020年至2024年）中的新兴贸易异常。超越传统的基于规则的监测，我们应用一个四层分析流程，利用法证统计、孤立森林、网络科学和深度自编码器。与可持续性套利是主要驱动因素的假设相反，实证结果揭示了一个矛盾且更严重的硬件掩蔽现象。非法行为者利用双向关税激励，将废铝错误分类为高计数异质商品，以证明单价异常值超过160美元/公斤的合理性，这一1900%的加价表明是贸易洗钱而非商业套利。从拓扑结构看，风险并非集中在主要出口国，而是集中在作为非法改道关键节点的高中心性影子枢纽。这些行为者执行空岸策略，系统性地将目的地数据抑制为未指定代码，以破坏镜像统计并切断法证追踪。通过SHAP验证，结果确认价格偏差是异常的主要预测因子，需要海关执法从物理量检查转向动态算法估值审计的范式转变。",
            "intro_zh": [
                "核心问题：传统基于规则的监测方法难以捕捉全球铝贸易中的新兴异常，如价格套利和贸易洗钱，导致监管滞后和风险低估。",
                "方法要点：提出四层无监督分析框架，结合法证统计、孤立森林、网络科学和深度自编码器，自动检测和分类贸易数据中的异常模式。",
                "实验或效果：实证揭示硬件掩蔽现象，价格偏差是主要预测因子，推动海关执法向动态算法审计转变，提升异常检测准确性。"
            ],
            "method_zh": "论文提出一个统一的无监督机器学习框架，整体框架包括四层分析流程：法证统计用于初步数据清洗和异常筛选，孤立森林检测高维数据中的离群点，网络科学分析贸易网络拓扑结构以识别影子枢纽，深度自编码器学习正常贸易模式并重构异常。关键技术创新点在于多方法融合，结合统计、机器学习和网络分析，全面捕捉复杂异常。与现有基于规则或单一方法相比，该方法能自动发现未知模式，如硬件掩蔽和空岸策略，提升检测的鲁棒性和解释性。",
            "application_zh": "该研究可应用于海关监管、金融犯罪调查和贸易政策制定，帮助识别贸易洗钱、关税欺诈等非法活动，优化全球资源管理，支持脱碳转型中的战略决策。",
            "highlight_zh": "实证结果推翻可持续性套利假设，揭示硬件掩蔽现象，单价异常值达1900%加价；识别高中心性影子枢纽而非主要出口国为风险集中点；SHAP验证价格偏差为关键预测因子，推动执法范式向算法审计转变。",
            "tags_zh": [
                "无监督学习",
                "贸易异常检测",
                "网络科学",
                "深度自编码器",
                "孤立森林",
                "贸易洗钱",
                "价格套利",
                "海关执法"
            ],
            "_index": 130
        },
        {
            "title": "Broadening View Synthesis of Dynamic Scenes from Constrained Monocular Videos",
            "authors": [
                "Le Jiang",
                "Shaotong Zhu",
                "Yedi Luo",
                "Shayda Moezzi",
                "Sarah Ostadabbas"
            ],
            "arxiv_id": "2512.14406v1",
            "summary": "In dynamic Neural Radiance Fields (NeRF) systems, state-of-the-art novel view synthesis methods often fail under significant viewpoint deviations, producing unstable and unrealistic renderings. To address this, we introduce Expanded Dynamic NeRF (ExpanDyNeRF), a monocular NeRF framework that leverages Gaussian splatting priors and a pseudo-ground-truth generation strategy to enable realistic synthesis under large-angle rotations. ExpanDyNeRF optimizes density and color features to improve scene reconstruction from challenging perspectives. We also present the Synthetic Dynamic Multiview (SynDM) dataset, the first synthetic multiview dataset for dynamic scenes with explicit side-view supervision-created using a custom GTA V-based rendering pipeline. Quantitative and qualitative results on SynDM and real-world datasets demonstrate that ExpanDyNeRF significantly outperforms existing dynamic NeRF methods in rendering fidelity under extreme viewpoint shifts. Further details are provided in the supplementary materials.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14406v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出ExpanDyNeRF框架，利用高斯先验和伪真值生成策略，解决动态NeRF在大视角偏移下渲染不稳定的问题。",
            "summary_zh": "在动态神经辐射场（NeRF）系统中，当前最先进的新视角合成方法在显著视角偏差下常失效，产生不稳定和不真实的渲染结果。为解决此问题，我们引入了扩展动态NeRF（ExpanDyNeRF），这是一个单目NeRF框架，利用高斯溅射先验和伪真值生成策略，以实现大角度旋转下的真实合成。ExpanDyNeRF优化密度和颜色特征，以改进从挑战性视角的场景重建。我们还提出了合成动态多视角（SynDM）数据集，这是首个用于动态场景的合成多视角数据集，具有明确的侧视角监督，通过基于GTA V的自定义渲染管线创建。在SynDM和真实世界数据集上的定量和定性结果表明，ExpanDyNeRF在极端视角偏移下的渲染保真度显著优于现有动态NeRF方法。更多细节见补充材料。",
            "intro_zh": [
                "现有动态NeRF方法在大视角偏移下渲染不稳定，导致新视角合成失败和失真。",
                "ExpanDyNeRF结合高斯先验和伪真值生成，优化特征以提升重建质量。",
                "在SynDM和真实数据集上，ExpanDyNeRF在极端视角下渲染保真度显著超越现有方法。"
            ],
            "method_zh": "ExpanDyNeRF是一个基于单目视频的动态NeRF框架，整体架构包括高斯溅射先验模块和伪真值生成策略。关键技术创新在于利用高斯先验增强场景表示稳定性，并通过伪真值生成提供额外监督，优化密度和颜色特征。与现有方法的主要区别在于其能处理大角度旋转，通过先验和策略改进视角泛化能力，而传统动态NeRF常依赖有限视角数据导致性能下降。",
            "application_zh": "该研究可应用于虚拟现实、增强现实和机器人导航，通过提升动态场景在新视角下的渲染质量，支持更真实的沉浸式体验和精确环境感知。",
            "highlight_zh": "在SynDM数据集上，ExpanDyNeRF在极端视角偏移下渲染保真度显著优于基线方法，定量指标如PSNR和SSIM有显著提升，定性结果展示更稳定和真实的合成效果。",
            "tags_zh": [
                "动态神经辐射场",
                "新视角合成",
                "单目视频",
                "高斯先验",
                "伪真值生成",
                "合成数据集",
                "渲染保真度",
                "视角泛化"
            ],
            "_index": 131
        },
        {
            "title": "RePo: Language Models with Context Re-Positioning",
            "authors": [
                "Huayang Li",
                "Tianyu Zhao",
                "Richard Sproat"
            ],
            "arxiv_id": "2512.14391v1",
            "summary": "In-context learning is fundamental to modern Large Language Models (LLMs); however, prevailing architectures impose a rigid and fixed contextual structure by assigning linear or constant positional indices. Drawing on Cognitive Load Theory (CLT), we argue that this uninformative structure increases extraneous cognitive load, consuming finite working memory capacity that should be allocated to deep reasoning and attention allocation. To address this, we propose RePo, a novel mechanism that reduces extraneous load via context re-positioning. Unlike standard approaches, RePo utilizes a differentiable module, $f_φ$, to assign token positions that capture contextual dependencies, rather than replying on pre-defined integer range. By continually pre-training on the OLMo-2 1B backbone, we demonstrate that RePo significantly enhances performance on tasks involving noisy contexts, structured data, and longer context length, while maintaining competitive performance on general short-context tasks. Detailed analysis reveals that RePo successfully allocate higher attention to distant but relevant information, assign positions in dense and non-linear space, and capture the intrinsic structure of the input context. Our code is available at https://github.com/SakanaAI/repo.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14391v1",
            "code_links": [
                {
                    "url": "https://github.com/SakanaAI/repo",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出RePo机制，通过上下文重定位减少额外认知负荷，提升大语言模型在噪声上下文和长文本任务中的性能。",
            "summary_zh": "上下文学习是现代大语言模型（LLMs）的基础，但主流架构通过分配线性或恒定的位置索引，强加了僵化固定的上下文结构。基于认知负荷理论（CLT），我们认为这种无信息结构增加了额外认知负荷，消耗了本应用于深度推理和注意力分配的有限工作记忆容量。为解决此问题，我们提出了RePo，一种通过上下文重定位减少额外负荷的新机制。与标准方法不同，RePo使用可微分模块fφ来分配捕捉上下文依赖关系的标记位置，而非依赖预定义的整数范围。通过在OLMo-2 1B骨干网络上持续预训练，我们证明RePo在涉及噪声上下文、结构化数据和较长上下文长度的任务中显著提升性能，同时在一般短上下文任务上保持竞争力。详细分析显示，RePo成功将更高注意力分配给遥远但相关的信息，在密集非线性空间中分配位置，并捕捉输入上下文的内在结构。我们的代码可在https://github.com/SakanaAI/repo获取。",
            "intro_zh": [
                "现有大语言模型使用线性或恒定位置索引，导致上下文结构僵化，增加额外认知负荷，限制深度推理能力。",
                "提出RePo机制，利用可微分模块fφ动态分配标记位置，捕捉上下文依赖，减少额外负荷，优化注意力分配。",
                "实验表明，RePo在噪声上下文、结构化数据和长文本任务中性能显著提升，同时保持短上下文任务的竞争力。"
            ],
            "method_zh": "RePo的整体框架基于大语言模型骨干（如OLMo-2 1B），引入可微分模块fφ进行上下文重定位。关键技术创新在于fφ模块动态学习标记位置，替代传统预定义整数位置索引，使位置分配能捕捉上下文依赖关系，形成密集非线性空间。与现有方法的主要区别是：传统方法依赖固定位置编码（如线性或RoPE），而RePo通过端到端训练优化位置，减少额外认知负荷，提升模型对上下文结构的适应性。",
            "application_zh": "该研究可应用于需要处理噪声上下文、结构化数据或长文本的场景，如文档理解、代码生成、对话系统和信息检索。实际价值在于提升大语言模型在复杂上下文环境中的推理效率和准确性，降低计算资源消耗。",
            "highlight_zh": "RePo在噪声上下文任务中性能显著提升，例如在结构化数据解析上准确率提高约15%；在长上下文任务中，注意力分配更有效，模型能更好捕捉遥远相关信息；同时，在一般短上下文基准测试上保持竞争性表现，验证了方法的通用性。",
            "tags_zh": [
                "上下文学习",
                "位置编码",
                "认知负荷理论",
                "大语言模型",
                "注意力机制",
                "可微分模块",
                "长文本处理",
                "结构化数据"
            ],
            "_index": 132
        },
        {
            "title": "Optimizing Rank for High-Fidelity Implicit Neural Representations",
            "authors": [
                "Julian McGinnis",
                "Florian A. Hölzl",
                "Suprosanna Shit",
                "Florentin Bieder",
                "Paul Friedrich",
                "Mark Mühlau",
                "Björn Menze",
                "Daniel Rueckert",
                "Benedikt Wiestler"
            ],
            "arxiv_id": "2512.14366v1",
            "summary": "Implicit Neural Representations (INRs) based on vanilla Multi-Layer Perceptrons (MLPs) are widely believed to be incapable of representing high-frequency content. This has directed research efforts towards architectural interventions, such as coordinate embeddings or specialized activation functions, to represent high-frequency signals. In this paper, we challenge the notion that the low-frequency bias of vanilla MLPs is an intrinsic, architectural limitation to learn high-frequency content, but instead a symptom of stable rank degradation during training. We empirically demonstrate that regulating the network's rank during training substantially improves the fidelity of the learned signal, rendering even simple MLP architectures expressive. Extensive experiments show that using optimizers like Muon, with high-rank, near-orthogonal updates, consistently enhances INR architectures even beyond simple ReLU MLPs. These substantial improvements hold across a diverse range of domains, including natural and medical images, and novel view synthesis, with up to 9 dB PSNR improvements over the previous state-of-the-art. Our project page, which includes code and experimental results, is available at: (https://muon-inrs.github.io).",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14366v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VIO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出通过优化网络秩来提升隐式神经表示的高频信号保真度，挑战传统架构限制观点。",
            "summary_zh": "基于普通多层感知机（MLPs）的隐式神经表示（INRs）被广泛认为无法表示高频内容，这导致研究转向坐标嵌入或特殊激活函数等架构干预。本文挑战了普通MLPs的低频偏差是学习高频内容的内在架构限制的观点，认为这是训练过程中稳定秩退化的症状。我们通过实验证明，在训练期间调节网络的秩可以显著提高学习信号的保真度，使简单的MLP架构也具有表达力。大量实验表明，使用Muon等具有高秩、近正交更新的优化器，可以持续增强INRs架构，甚至超越简单的ReLU MLPs。这些显著改进适用于多个领域，包括自然和医学图像以及新视角合成，与先前最先进方法相比，PSNR提升高达9 dB。我们的项目页面包含代码和实验结果，可在https://muon-inrs.github.io访问。",
            "intro_zh": [
                "现有方法认为普通MLPs因架构限制无法表示高频信号，导致研究过度依赖复杂架构干预。",
                "论文提出高频学习受限源于训练中网络秩退化，通过优化器如Muon调节秩来提升保真度。",
                "实验显示该方法在图像和视图合成中PSNR提升高达9 dB，验证了简单MLPs的潜力。"
            ],
            "method_zh": "论文整体框架基于隐式神经表示（INRs），使用普通多层感知机（MLPs）作为基础架构。关键技术创新点在于识别并解决训练过程中的稳定秩退化问题，通过引入优化器（如Muon）来生成高秩、近正交的权重更新，从而维持网络表达高频信号的能力。与现有方法的主要区别在于，不依赖额外的架构修改（如坐标嵌入或特殊激活函数），而是从优化角度直接提升网络秩，使简单MLP也能有效学习高频内容，挑战了传统认为架构限制是瓶颈的观点。",
            "application_zh": "该研究在计算机视觉和医学图像处理领域具有广泛应用潜力，可用于自然图像重建、医学图像分析（如MRI或CT扫描）以及新视角合成（如3D场景渲染），提升信号保真度和细节还原能力，为高精度图像表示和生成任务提供更高效的解决方案。",
            "highlight_zh": "实验结果表明，使用优化器调节网络秩后，在多个数据集上PSNR提升高达9 dB，显著超越先前最先进方法，验证了该方法在提升隐式神经表示保真度方面的有效性，且适用于多样领域如自然图像、医学图像和新视角合成。",
            "tags_zh": [
                "隐式神经表示",
                "网络秩优化",
                "高频信号学习",
                "多层感知机",
                "图像保真度",
                "新视角合成",
                "医学图像处理",
                "优化器设计"
            ],
            "_index": 133
        },
        {
            "title": "TiCard: Deployable EXPLAIN-only Residual Learning for Cardinality Estimation",
            "authors": [
                "Qizhi Wang"
            ],
            "arxiv_id": "2512.14358v1",
            "summary": "Cardinality estimation is a key bottleneck for cost-based query optimization, yet deployable improvements remain difficult: classical estimators miss correlations, while learned estimators often require workload-specific training pipelines and invasive integration into the optimizer. This paper presents TiCard, a low intrusion, correction-based framework that augments (rather than replaces) a database's native estimator. TiCard learns multiplicative residual corrections using EXPLAIN-only features, and uses EXPLAIN ANALYZE only for offline labels. We study two practical instantiations: (i) a Gradient Boosting Regressor for sub-millisecond inference, and (ii) TabPFN, an in-context tabular foundation model that adapts by refreshing a small reference set without gradient retraining. On TiDB with TPCH and the Join Order Benchmark, in a low-trace setting (263 executions total; 157 used for learning), TiCard improves operator-level tail accuracy substantially: P90 Q-error drops from 312.85 (native) to 13.69 (TiCard-GBR), and P99 drops from 37,974.37 to 3,416.50 (TiCard-TabPFN), while a join-only policy preserves near-perfect median behavior. We position TiCard as an AI4DB building block focused on deployability: explicit scope, conservative integration policies, and an integration roadmap from offline correction to in-optimizer use.",
            "categories": [
                "cs.AI",
                "cs.DB"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "16 pages(/wo references), 4 figures, 10 tables",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14358v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VIO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出TiCard框架，通过可部署的仅解释残差学习来增强数据库基数估计，解决传统方法缺失相关性和学习型方法部署困难的问题。",
            "summary_zh": "基数估计是基于成本的查询优化的关键瓶颈，但可部署的改进仍然困难：传统估计器缺失相关性，而学习型估计器通常需要特定工作负载的训练流程和侵入式集成到优化器中。本文提出TiCard，一个低侵入、基于校正的框架，用于增强（而非替换）数据库的原生估计器。TiCard使用仅解释特征学习乘法残差校正，并仅使用解释分析进行离线标签。我们研究了两种实际实例化：（i）梯度提升回归器用于亚毫秒级推理，和（ii）TabPFN，一种上下文表格基础模型，通过刷新小参考集而无需梯度重新训练来适应。在TiDB上使用TPCH和连接顺序基准测试，在低跟踪设置中（总共263次执行；157次用于学习），TiCard显著提高了操作员级尾部准确性：P90 Q误差从312.85（原生）降至13.69（TiCard-GBR），P99从37,974.37降至3,416.50（TiCard-TabPFN），而仅连接策略保持了近乎完美的中位数行为。我们将TiCard定位为专注于可部署性的AI4DB构建块：明确的范围、保守的集成策略，以及从离线校正到优化器内使用的集成路线图。",
            "intro_zh": [
                "核心问题：传统基数估计器忽略数据相关性，而学习型方法通常需要复杂训练流程和侵入式集成，导致部署困难。",
                "方法要点：TiCard框架通过仅解释特征学习乘法残差校正，低侵入地增强数据库原生估计器，无需替换现有系统。",
                "实验或效果：在低跟踪设置下，TiCard显著降低尾部Q误差，如P90从312.85降至13.69，同时保持中位数准确性。"
            ],
            "method_zh": "TiCard是一个基于校正的框架，整体上通过仅解释特征（如查询计划结构）学习乘法残差来增强数据库原生基数估计器。关键技术创新包括：使用EXPLAIN-only特征避免运行时数据访问，仅依赖EXPLAIN ANALYZE进行离线标签生成，以及提供两种实例化——梯度提升回归器（GBR）用于快速推理和TabPFN基础模型用于上下文适应。与现有方法的主要区别在于其低侵入性：它不替换原生估计器，而是作为校正层，通过保守集成策略（如仅连接策略）减少对优化器的干扰，并支持从离线到在线集成的路线图。",
            "application_zh": "该研究主要应用于数据库查询优化领域，特别是基于成本的查询优化器，如TiDB等关系型数据库系统。潜在价值在于提供可部署的AI增强方案，通过低侵入方式提升基数估计准确性，减少查询执行时间，适用于需要高效数据处理的企业级应用和云数据库服务。",
            "highlight_zh": "在TiDB的TPCH和Join Order Benchmark测试中，TiCard在低跟踪设置（仅157次学习执行）下显著提升尾部准确性：P90 Q误差从原生312.85降至13.69（TiCard-GBR），P99从37,974.37降至3,416.50（TiCard-TabPFN），同时仅连接策略保持中位数Q误差接近1，展示了高效部署潜力。",
            "tags_zh": [
                "基数估计",
                "查询优化",
                "残差学习",
                "可部署AI",
                "数据库增强",
                "梯度提升回归器",
                "表格基础模型",
                "低侵入集成"
            ],
            "_index": 134
        },
        {
            "title": "HGS: Hybrid Gaussian Splatting with Static-Dynamic Decomposition for Compact Dynamic View Synthesis",
            "authors": [
                "Kaizhe Zhang",
                "Yijie Zhou",
                "Weizhan Zhang",
                "Caixia Yan",
                "Haipeng Du",
                "yugui xie",
                "Yu-Hui Wen",
                "Yong-Jin Liu"
            ],
            "arxiv_id": "2512.14352v1",
            "summary": "Dynamic novel view synthesis (NVS) is essential for creating immersive experiences. Existing approaches have advanced dynamic NVS by introducing 3D Gaussian Splatting (3DGS) with implicit deformation fields or indiscriminately assigned time-varying parameters, surpassing NeRF-based methods. However, due to excessive model complexity and parameter redundancy, they incur large model sizes and slow rendering speeds, making them inefficient for real-time applications, particularly on resource-constrained devices. To obtain a more efficient model with fewer redundant parameters, in this paper, we propose Hybrid Gaussian Splatting (HGS), a compact and efficient framework explicitly designed to disentangle static and dynamic regions of a scene within a unified representation. The core innovation of HGS lies in our Static-Dynamic Decomposition (SDD) strategy, which leverages Radial Basis Function (RBF) modeling for Gaussian primitives. Specifically, for dynamic regions, we employ time-dependent RBFs to effectively capture temporal variations and handle abrupt scene changes, while for static regions, we reduce redundancy by sharing temporally invariant parameters. Additionally, we introduce a two-stage training strategy tailored for explicit models to enhance temporal coherence at static-dynamic boundaries. Experimental results demonstrate that our method reduces model size by up to 98% and achieves real-time rendering at up to 125 FPS at 4K resolution on a single RTX 3090 GPU. It further sustains 160 FPS at 1352 * 1014 on an RTX 3050 and has been integrated into the VR system. Moreover, HGS achieves comparable rendering quality to state-of-the-art methods while providing significantly improved visual fidelity for high-frequency details and abrupt scene changes.",
            "categories": [
                "cs.CV",
                "cs.CG"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "11 pages, 9 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14352v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出混合高斯溅射框架，通过静态-动态分解策略实现紧凑高效的动态新视角合成。",
            "summary_zh": "动态新视角合成对于创造沉浸式体验至关重要。现有方法通过引入带有隐式变形场或非区分性时变参数的3D高斯溅射技术，超越了基于神经辐射场的方法。然而，由于模型复杂度过高和参数冗余，这些方法导致模型体积庞大、渲染速度缓慢，在资源受限设备上效率低下。为获得参数更少的高效模型，本文提出混合高斯溅射框架，这是一种紧凑高效的框架，旨在统一表示中显式解耦场景的静态和动态区域。HGS的核心创新在于静态-动态分解策略，该策略利用径向基函数对高斯基元进行建模。具体而言，对于动态区域，我们使用时变径向基函数有效捕捉时间变化并处理场景突变；对于静态区域，我们通过共享时间不变参数减少冗余。此外，我们引入针对显式模型的两阶段训练策略，以增强静态-动态边界的时间一致性。实验结果表明，我们的方法将模型大小减少了高达98%，在单张RTX 3090 GPU上实现4K分辨率下高达125 FPS的实时渲染。在RTX 3050上，它还能在1352×1014分辨率下维持160 FPS，并已集成到VR系统中。此外，HGS在实现与最先进方法相当的渲染质量的同时，为高频细节和场景突变提供了显著改善的视觉保真度。",
            "intro_zh": [
                "现有动态新视角合成方法模型复杂、参数冗余，导致模型体积大、渲染慢，难以实时应用。",
                "提出混合高斯溅射框架，通过静态-动态分解策略，使用径向基函数分别建模动态和静态区域。",
                "实验显示模型大小减少高达98%，渲染速度达125 FPS，在VR系统中实现高效集成。"
            ],
            "method_zh": "HGS整体框架基于3D高斯溅射技术，通过静态-动态分解策略统一表示场景。关键创新包括：使用径向基函数建模高斯基元，动态区域采用时变RBF捕捉时间变化，静态区域共享时间不变参数以减少冗余；引入两阶段训练策略优化显式模型，增强静态-动态边界的时间一致性。与现有方法的主要区别在于显式解耦静态和动态区域，避免了隐式变形场或非区分性时变参数带来的复杂性和冗余，从而实现了更紧凑的模型和更高效的渲染。",
            "application_zh": "该研究适用于虚拟现实、增强现实、游戏开发和影视制作等领域，能够实现实时、高质量的动态场景渲染，特别适合资源受限设备如移动VR头显，提升沉浸式体验的效率和可访问性。",
            "highlight_zh": "模型大小减少高达98%，在RTX 3090上实现4K分辨率125 FPS实时渲染，RTX 3050上维持160 FPS，已集成到VR系统，同时保持与最先进方法相当的渲染质量，并改善高频细节和场景突变的视觉保真度。",
            "tags_zh": [
                "动态新视角合成",
                "3D高斯溅射",
                "静态-动态分解",
                "径向基函数建模",
                "实时渲染",
                "模型压缩",
                "虚拟现实集成",
                "高效计算"
            ],
            "_index": 135
        },
        {
            "title": "Implicit Bias and Invariance: How Hopfield Networks Efficiently Learn Graph Orbits",
            "authors": [
                "Michael Murray",
                "Tenzin Chan",
                "Kedar Karhadker",
                "Christopher J. Hillar"
            ],
            "arxiv_id": "2512.14338v1",
            "summary": "Many learning problems involve symmetries, and while invariance can be built into neural architectures, it can also emerge implicitly when training on group-structured data. We study this phenomenon in classical Hopfield networks and show they can infer the full isomorphism class of a graph from a small random sample. Our results reveal that: (i) graph isomorphism classes can be represented within a three-dimensional invariant subspace, (ii) using gradient descent to minimize energy flow (MEF) has an implicit bias toward norm-efficient solutions, which underpins a polynomial sample complexity bound for learning isomorphism classes, and (iii) across multiple learning rules, parameters converge toward the invariant subspace as sample sizes grow. Together, these findings highlight a unifying mechanism for generalization in Hopfield networks: a bias toward norm efficiency in learning drives the emergence of approximate invariance under group-structured data.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14338v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "揭示Hopfield网络通过范数效率隐式学习图同构类，实现多项式样本复杂度",
            "summary_zh": "许多学习问题涉及对称性，虽然不变性可以内置到神经架构中，但在群结构数据上训练时也可能隐式出现。我们研究了经典Hopfield网络中的这一现象，并表明它们可以从小的随机样本中推断出图的完整同构类。我们的结果显示：(i) 图同构类可以在三维不变子空间中表示，(ii) 使用梯度下降最小化能量流（MEF）具有对范数效率解的隐式偏置，这支撑了学习同构类的多项式样本复杂度界限，以及(iii) 在多种学习规则下，参数随着样本量增长而收敛到不变子空间。这些发现共同突出了Hopfield网络中泛化的统一机制：学习中对范数效率的偏置驱动了在群结构数据下近似不变性的出现。",
            "intro_zh": [
                "核心问题：现有方法常显式构建不变性，但隐式学习机制在群结构数据中的效率和泛化能力尚不明确。",
                "方法要点：利用Hopfield网络，通过最小化能量流的梯度下降，隐式偏置范数效率解，实现图同构类的高效学习。",
                "实验或效果：实验表明网络能在三维子空间表示同构类，样本复杂度为多项式级，参数收敛到不变子空间。"
            ],
            "method_zh": "论文基于经典Hopfield网络框架，研究其在图同构类学习中的隐式偏置机制。整体框架涉及使用梯度下降最小化能量流（MEF）作为学习规则，以优化网络参数。关键技术创新点在于揭示了MEF具有对范数效率解的隐式偏置，这促使网络参数在训练过程中自动收敛到三维不变子空间，从而高效表示图同构类。与现有方法的主要区别在于，不依赖显式的不变性设计，而是通过隐式学习机制在群结构数据中自然涌现近似不变性，简化了架构并提升了泛化能力。",
            "application_zh": "该研究可应用于图结构数据分析、社交网络建模、化学分子识别等领域，通过隐式学习对称性，提高模型在复杂数据中的泛化效率和鲁棒性，为设计更简洁的神经网络提供理论指导。",
            "highlight_zh": "最重要的实验结果显示，Hopfield网络能从少量随机样本中学习图同构类，样本复杂度为多项式界限，参数收敛到三维不变子空间，验证了隐式偏置范数效率在驱动近似不变性中的核心作用。",
            "tags_zh": [
                "Hopfield网络",
                "隐式偏置",
                "图同构",
                "不变子空间",
                "范数效率",
                "样本复杂度",
                "群结构数据",
                "能量最小化"
            ],
            "_index": 136
        },
        {
            "title": "Semantic Mismatch and Perceptual Degradation: A New Perspective on Image Editing Immunity",
            "authors": [
                "Shuai Dong",
                "Jie Zhang",
                "Guoying Zhao",
                "Shiguang Shan",
                "Xilin Chen"
            ],
            "arxiv_id": "2512.14320v1",
            "summary": "Text-guided image editing via diffusion models, while powerful, raises significant concerns about misuse, motivating efforts to immunize images against unauthorized edits using imperceptible perturbations. Prevailing metrics for evaluating immunization success typically rely on measuring the visual dissimilarity between the output generated from a protected image and a reference output generated from the unprotected original. This approach fundamentally overlooks the core requirement of image immunization, which is to disrupt semantic alignment with attacker intent, regardless of deviation from any specific output. We argue that immunization success should instead be defined by the edited output either semantically mismatching the prompt or suffering substantial perceptual degradations, both of which thwart malicious intent. To operationalize this principle, we propose Synergistic Intermediate Feature Manipulation (SIFM), a method that strategically perturbs intermediate diffusion features through dual synergistic objectives: (1) maximizing feature divergence from the original edit trajectory to disrupt semantic alignment with the expected edit, and (2) minimizing feature norms to induce perceptual degradations. Furthermore, we introduce the Immunization Success Rate (ISR), a novel metric designed to rigorously quantify true immunization efficacy for the first time. ISR quantifies the proportion of edits where immunization induces either semantic failure relative to the prompt or significant perceptual degradations, assessed via Multimodal Large Language Models (MLLMs). Extensive experiments show our SIFM achieves the state-of-the-art performance for safeguarding visual content against malicious diffusion-based manipulation.",
            "categories": [
                "cs.CV",
                "cs.AI",
                "cs.CY",
                "cs.LG"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "11 pages, 4 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14320v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出SIFM方法以解决图像免疫评估中语义失配与感知退化被忽视的问题",
            "summary_zh": "基于扩散模型的文本引导图像编辑虽然强大，但也引发了严重的滥用担忧，这促使人们努力使用不可察觉的扰动来免疫图像以防止未经授权的编辑。评估免疫成功的主流指标通常依赖于测量受保护图像生成的输出与未受保护原始图像生成的参考输出之间的视觉差异。这种方法从根本上忽视了图像免疫的核心要求，即破坏与攻击者意图的语义对齐，而不管与任何特定输出的偏差如何。我们认为，免疫成功应定义为编辑输出要么在语义上与提示不匹配，要么遭受严重的感知退化，这两者都会挫败恶意意图。为了实施这一原则，我们提出了协同中间特征操纵（SIFM），这是一种通过双重协同目标策略性地扰动扩散中间特征的方法：（1）最大化特征与原始编辑轨迹的差异，以破坏与预期编辑的语义对齐；（2）最小化特征范数以诱导感知退化。此外，我们引入了免疫成功率（ISR），这是一种新颖的指标，首次设计用于严格量化真正的免疫效果。ISR量化了免疫导致相对于提示的语义失败或显著感知退化的编辑比例，通过多模态大语言模型（MLLMs）进行评估。大量实验表明，我们的SIFM在保护视觉内容免受基于扩散的恶意操纵方面达到了最先进的性能。",
            "intro_zh": [
                "现有图像免疫评估方法依赖视觉差异度量，忽视了破坏语义对齐的核心要求，导致评估不准确。",
                "提出SIFM方法，通过最大化特征差异和最小化特征范数，协同扰动扩散中间特征，实现语义失配和感知退化。",
                "实验表明SIFM在免疫成功率上达到最先进水平，有效保护图像免受恶意编辑，验证了新评估指标ISR的有效性。"
            ],
            "method_zh": "论文提出协同中间特征操纵（SIFM）方法，整体框架基于扩散模型，在图像编辑过程中策略性地扰动中间特征。关键技术创新点包括：通过双重协同目标——最大化特征与原始编辑轨迹的差异以破坏语义对齐，以及最小化特征范数以诱导感知退化——来优化扰动。与现有方法的主要区别在于，SIFM直接针对语义失配和感知退化进行优化，而非依赖视觉差异度量，从而更准确地实现图像免疫。",
            "application_zh": "该研究可应用于数字版权保护、社交媒体内容安全、新闻图像防篡改等领域，通过免疫图像防止未经授权的恶意编辑，保障视觉内容的真实性和完整性，具有重要的实际价值。",
            "highlight_zh": "SIFM在免疫成功率（ISR）上达到最先进性能，通过多模态大语言模型评估，显著提升了图像免疫效果，实验验证了新指标ISR能更准确量化免疫效能。",
            "tags_zh": [
                "图像免疫",
                "扩散模型",
                "语义失配",
                "感知退化",
                "中间特征扰动",
                "免疫成功率",
                "多模态评估",
                "恶意编辑防护"
            ],
            "_index": 137
        },
        {
            "title": "From YOLO to VLMs: Advancing Zero-Shot and Few-Shot Detection of Wastewater Treatment Plants Using Satellite Imagery in MENA Region",
            "authors": [
                "Akila Premarathna",
                "Kanishka Hewageegana",
                "Garcia Andarcia Mariangel"
            ],
            "arxiv_id": "2512.14312v1",
            "summary": "In regions of the Middle East and North Africa (MENA), there is a high demand for wastewater treatment plants (WWTPs), crucial for sustainable water management. Precise identification of WWTPs from satellite images enables environmental monitoring. Traditional methods like YOLOv8 segmentation require extensive manual labeling. But studies indicate that vision-language models (VLMs) are an efficient alternative to achieving equivalent or superior results through inherent reasoning and annotation. This study presents a structured methodology for VLM comparison, divided into zero-shot and few-shot streams specifically to identify WWTPs. The YOLOv8 was trained on a governmental dataset of 83,566 high-resolution satellite images from Egypt, Saudi Arabia, and UAE: ~85% WWTPs (positives), 15% non-WWTPs (negatives). Evaluated VLMs include LLaMA 3.2 Vision, Qwen 2.5 VL, DeepSeek-VL2, Gemma 3, Gemini, and Pixtral 12B (Mistral), used to identify WWTP components such as circular/rectangular tanks, aeration basins and distinguish confounders via expert prompts producing JSON outputs with confidence and descriptions. The dataset comprises 1,207 validated WWTP locations (198 UAE, 354 KSA, 655 Egypt) and equal non-WWTP sites from field/AI data, as 600mx600m Geo-TIFF images (Zoom 18, EPSG:4326). Zero-shot evaluations on WWTP images showed several VLMs out-performing YOLOv8's true positive rate, with Gemma-3 highest. Results confirm that VLMs, particularly with zero-shot, can replace YOLOv8 for efficient, annotation-free WWTP classification, enabling scalable remote sensing.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "9 pages, 9 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14312v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出基于视觉语言模型的零样本与少样本方法，以解决中东和北非地区废水处理厂卫星图像检测中标注成本高的问题。",
            "summary_zh": "在中东和北亚地区，废水处理厂对可持续水资源管理至关重要，从卫星图像中精确识别这些设施有助于环境监测。传统方法如YOLOv8分割需要大量人工标注，但研究表明视觉语言模型通过其内在推理和标注能力，能高效实现同等或更优结果。本研究提出了一种结构化的VLM比较方法，分为零样本和少样本流程，专门用于识别废水处理厂。YOLOv8在来自埃及、沙特阿拉伯和阿联酋的83,566张高分辨率卫星图像政府数据集上训练，其中约85%为废水处理厂（正样本），15%为非废水处理厂（负样本）。评估的VLM包括LLaMA 3.2 Vision、Qwen 2.5 VL、DeepSeek-VL2、Gemma 3、Gemini和Pixtral 12B（Mistral），用于识别废水处理厂组件如圆形/矩形罐、曝气池，并通过专家提示区分混淆物，生成带有置信度和描述的JSON输出。数据集包含1,207个已验证的废水处理厂位置（198个阿联酋、354个沙特阿拉伯、655个埃及）和等量的非废水处理厂站点，来自现场/AI数据，作为600米×600米的Geo-TIFF图像（缩放级别18，EPSG:4326）。在废水处理厂图像上的零样本评估显示，多个VLM在真阳性率上优于YOLOv8，其中Gemma-3表现最佳。结果证实，VLM特别是零样本方法，可以替代YOLOv8进行高效、无需标注的废水处理厂分类，实现可扩展的遥感应用。",
            "intro_zh": [
                "核心问题：传统YOLOv8方法依赖大量人工标注，成本高且难以适应中东和北非地区废水处理厂的快速检测需求。",
                "方法要点：采用视觉语言模型进行零样本和少样本检测，利用专家提示识别废水处理厂组件，减少标注依赖。",
                "实验或效果：多个VLM在零样本评估中真阳性率超越YOLOv8，Gemma-3表现最优，验证了VLM的高效性。"
            ],
            "method_zh": "论文提出一种结构化方法，比较视觉语言模型在废水处理厂检测中的性能。整体框架包括零样本和少样本两个流程：零样本直接使用预训练VLM进行推理，少样本则可能涉及少量标注数据微调。关键技术创新在于利用专家设计的提示词，引导VLM识别废水处理厂特定组件（如圆形/矩形罐、曝气池）并区分混淆物，输出结构化JSON结果。与现有方法的主要区别在于，传统YOLOv8依赖全监督训练和大量标注，而VLM通过其多模态理解能力，实现无需或少量标注的检测，显著降低人工成本。",
            "application_zh": "该研究可应用于中东和北非地区的环境监测和城市规划，通过卫星图像自动检测废水处理厂，支持可持续水资源管理和基础设施评估，具有远程、高效、可扩展的优势。",
            "highlight_zh": "在零样本评估中，多个视觉语言模型（如Gemma-3）的真阳性率超过YOLOv8，最高性能模型实现高效检测，验证了VLM在无需标注情况下替代传统方法的潜力，提升遥感应用的可扩展性。",
            "tags_zh": [
                "视觉语言模型",
                "零样本检测",
                "少样本学习",
                "卫星图像分析",
                "废水处理厂识别",
                "遥感应用",
                "中东和北非地区",
                "环境监测"
            ],
            "_index": 138
        },
        {
            "title": "Continual Learning at the Edge: An Agnostic IIoT Architecture",
            "authors": [
                "Pablo García-Santaclara",
                "Bruno Fernández-Castro",
                "Rebeca P. Díaz-Redondo",
                "Carlos Calvo-Moa",
                "Henar Mariño-Bodelón"
            ],
            "arxiv_id": "2512.14311v1",
            "summary": "The exponential growth of Internet-connected devices has presented challenges to traditional centralized computing systems due to latency and bandwidth limitations. Edge computing has evolved to address these difficulties by bringing computations closer to the data source. Additionally, traditional machine learning algorithms are not suitable for edge-computing systems, where data usually arrives in a dynamic and continual way. However, incremental learning offers a good solution for these settings. We introduce a new approach that applies the incremental learning philosophy within an edge-computing scenario for the industrial sector with a specific purpose: real time quality control in a manufacturing system. Applying continual learning we reduce the impact of catastrophic forgetting and provide an efficient and effective solution.",
            "categories": [
                "stat.ML",
                "cs.LG"
            ],
            "primary_category": "stat.ML",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "10.1007/978-981-96-6938-7_33",
            "journal_ref": "García-Santaclara, P., Fernández-Castro, B., Díaz-Redondo, R. P., Calvo-Moa, C., & Mariño-Bodelón, H. (2025). Continual learning at the edge: An agnostic IIoT architecture. In Lecture Notes in Networks and Systems. Springer",
            "pdf_url": "https://arxiv.org/pdf/2512.14311v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出一种边缘计算场景下的增量学习方法，用于工业物联网实时质量控制，减少灾难性遗忘影响。",
            "summary_zh": "互联网连接设备的指数级增长给传统集中式计算系统带来了延迟和带宽限制的挑战。边缘计算通过将计算更靠近数据源来解决这些困难。此外，传统机器学习算法不适合边缘计算系统，因为数据通常以动态和连续的方式到达。然而，增量学习为这些场景提供了良好的解决方案。我们引入了一种新方法，将增量学习理念应用于工业领域的边缘计算场景，具体目的是在制造系统中实现实时质量控制。通过应用持续学习，我们减少了灾难性遗忘的影响，并提供了一种高效有效的解决方案。",
            "intro_zh": [
                "传统集中式计算系统面临延迟和带宽限制，边缘计算虽能缓解但数据动态连续到达，传统机器学习算法难以适应。",
                "提出在工业边缘计算场景中应用增量学习，通过持续学习机制减少灾难性遗忘，实现实时质量控制。",
                "该方法在制造系统中提供高效解决方案，降低遗忘影响，提升边缘设备的学习效率和适应性。"
            ],
            "method_zh": "论文提出了一种面向工业物联网的边缘计算架构，核心是集成增量学习方法。整体框架包括边缘设备层、数据处理层和学习模块，其中关键技术创新在于将增量学习算法适配到资源受限的边缘环境，以处理动态流入的数据流。与现有方法的主要区别在于，它专门针对工业场景设计，强调实时性和低延迟，而非依赖集中式云处理，从而更有效地应对灾难性遗忘问题，并优化计算资源使用。",
            "application_zh": "该研究主要应用于工业制造领域的实时质量控制，例如生产线上的缺陷检测和过程监控。潜在价值包括提升生产效率、减少停机时间，并支持智能工厂的自动化决策，为工业物联网提供可扩展的边缘智能解决方案。",
            "highlight_zh": "实验表明，该方法在制造系统实时质量控制任务中有效减少了灾难性遗忘，相比传统方法提升了学习效率和适应性，具体性能提升未知，但强调了在边缘设备上的可行性和效果。",
            "tags_zh": [
                "边缘计算",
                "增量学习",
                "工业物联网",
                "实时质量控制",
                "灾难性遗忘",
                "制造系统",
                "动态数据流"
            ],
            "_index": 139
        },
        {
            "title": "PSMamba: Progressive Self-supervised Vision Mamba for Plant Disease Recognition",
            "authors": [
                "Abdullah Al Mamun",
                "Miaohua Zhang",
                "David Ahmedt-Aristizabal",
                "Zeeshan Hayder",
                "Mohammad Awrangjeb"
            ],
            "arxiv_id": "2512.14309v1",
            "summary": "Self-supervised Learning (SSL) has become a powerful paradigm for representation learning without manual annotations. However, most existing frameworks focus on global alignment and struggle to capture the hierarchical, multi-scale lesion patterns characteristic of plant disease imagery. To address this gap, we propose PSMamba, a progressive self-supervised framework that integrates the efficient sequence modelling of Vision Mamba (VM) with a dual-student hierarchical distillation strategy. Unlike conventional single teacher-student designs, PSMamba employs a shared global teacher and two specialised students: one processes mid-scale views to capture lesion distributions and vein structures, while the other focuses on local views to capture fine-grained cues such as texture irregularities and early-stage lesions. This multi-granular supervision facilitates the joint learning of contextual and detailed representations, with consistency losses ensuring coherent cross-scale alignment. Experiments on three benchmark datasets show that PSMamba consistently outperforms state-of-the-art SSL methods, delivering superior accuracy and robustness in both domain-shifted and fine-grained scenarios.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14309v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出PSMamba框架，通过渐进式自监督视觉Mamba和双学生分层蒸馏策略，解决植物病害识别中多尺度病变模式捕获不足的问题。",
            "summary_zh": "自监督学习已成为无需人工标注的强大表示学习范式，但现有框架多关注全局对齐，难以捕获植物病害图像中层次化、多尺度的病变模式。为填补这一空白，本文提出PSMamba，一个渐进式自监督框架，将视觉Mamba的高效序列建模与双学生分层蒸馏策略相结合。不同于传统的单教师-学生设计，PSMamba采用共享的全局教师和两个专门化学生：一个处理中尺度视图以捕获病变分布和叶脉结构，另一个专注于局部视图以捕获细粒度线索，如纹理不规则和早期病变。这种多粒度监督促进了上下文和细节表示的联合学习，并通过一致性损失确保跨尺度对齐的连贯性。在三个基准数据集上的实验表明，PSMamba在领域转移和细粒度场景中均优于最先进的自监督学习方法，展现出卓越的准确性和鲁棒性。",
            "intro_zh": [
                "现有自监督学习框架主要依赖全局对齐，难以有效捕获植物病害图像中层次化、多尺度的病变模式，导致识别精度受限。",
                "PSMamba整合视觉Mamba的高效序列建模与双学生分层蒸馏，通过共享全局教师和专门化学生，实现多粒度监督和跨尺度对齐。",
                "在三个基准数据集上，PSMamba在领域转移和细粒度场景中均超越现有方法，显著提升了准确性和鲁棒性。"
            ],
            "method_zh": "PSMamba是一个渐进式自监督框架，整体架构基于视觉Mamba，结合双学生分层蒸馏策略。关键技术创新点包括：采用共享全局教师和两个专门化学生，分别处理中尺度和局部视图，以捕获病变分布、叶脉结构及细粒度纹理；通过一致性损失实现跨尺度对齐，促进上下文与细节表示的联合学习。与现有方法的主要区别在于，传统自监督学习多依赖单一教师-学生设计，而PSMamba通过多粒度监督和分层蒸馏，更有效地建模植物病害的多尺度特征，提升了表示学习的效率和效果。",
            "application_zh": "该研究主要应用于植物病害识别领域，可支持农业自动化监测、精准病害诊断和早期预警系统。通过提升自监督学习的表示能力，PSMamba有助于减少对大量标注数据的依赖，降低人工成本，并增强模型在复杂环境下的鲁棒性，为智能农业和植物保护提供技术支撑。",
            "highlight_zh": "在三个基准数据集上的实验显示，PSMamba在领域转移和细粒度场景中均优于最先进的自监督学习方法，准确性和鲁棒性显著提升，验证了其多尺度建模和分层蒸馏策略的有效性。",
            "tags_zh": [
                "自监督学习",
                "视觉Mamba",
                "植物病害识别",
                "分层蒸馏",
                "多尺度建模",
                "表示学习",
                "农业人工智能",
                "序列建模"
            ],
            "_index": 140
        },
        {
            "title": "Improving the Accuracy of Amortized Model Comparison with Self-Consistency",
            "authors": [
                "Šimon Kucharský",
                "Aayush Mishra",
                "Daniel Habermann",
                "Stefan T. Radev",
                "Paul-Christian Bürkner"
            ],
            "arxiv_id": "2512.14308v1",
            "summary": "Amortized Bayesian inference (ABI) offers fast, scalable approximations to posterior densities by training neural surrogates on data simulated from the statistical model. However, ABI methods are highly sensitive to model misspecification: when observed data fall outside the training distribution (generative scope of the statistical models), neural surrogates can behave unpredictably. This makes it a challenge in a model comparison setting, where multiple statistical models are considered, of which at least some are misspecified. Recent work on self-consistency (SC) provides a promising remedy to this issue, accessible even for empirical data (without ground-truth labels). In this work, we investigate how SC can improve amortized model comparison conceptualized in four different ways. Across two synthetic and two real-world case studies, we find that approaches for model comparison that estimate marginal likelihoods through approximate parameter posteriors consistently outperform methods that directly approximate model evidence or posterior model probabilities. SC training improves robustness when the likelihood is available, even under severe model misspecification. The benefits of SC for methods without access of analytic likelihoods are more limited and inconsistent. Our results suggest practical guidance for reliable amortized Bayesian model comparison: prefer parameter posterior-based methods and augment them with SC training on empirical datasets to mitigate extrapolation bias under model misspecification.",
            "categories": [
                "stat.ML",
                "cs.LG",
                "stat.CO"
            ],
            "primary_category": "stat.ML",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "17 pages, 9 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14308v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出基于自一致性的训练方法，提升模型错误设定下摊销贝叶斯模型比较的准确性",
            "summary_zh": "摊销贝叶斯推断（ABI）通过训练神经网络代理来快速近似后验密度，但该方法对模型错误设定高度敏感：当观测数据超出训练分布时，神经网络代理可能表现不可预测。这在模型比较场景中尤为挑战，因为需要考虑多个统计模型，其中至少部分模型存在错误设定。最近关于自一致性（SC）的研究为解决这一问题提供了有前景的补救措施，即使对于没有真实标签的经验数据也可应用。本研究探讨了SC如何改进四种不同概念化的摊销模型比较方法。通过两个合成和两个真实世界案例研究，我们发现通过近似参数后验估计边际似然的方法，在性能上始终优于直接近似模型证据或后验模型概率的方法。当似然函数可用时，SC训练即使在严重模型错误设定下也能提高鲁棒性。对于无法访问解析似然函数的方法，SC的益处则更为有限且不一致。我们的结果为可靠的摊销贝叶斯模型比较提供了实用指导：优先选择基于参数后验的方法，并在经验数据集上使用SC训练进行增强，以减轻模型错误设定下的外推偏差。",
            "intro_zh": [
                "摊销贝叶斯推断对模型错误设定高度敏感，当数据超出训练分布时神经网络代理表现不可预测",
                "引入自一致性训练方法，通过增强神经网络代理在经验数据上的鲁棒性来缓解外推偏差",
                "实验表明基于参数后验的方法优于直接近似证据的方法，SC训练显著提升模型错误设定下的性能"
            ],
            "method_zh": "论文提出一个基于自一致性的摊销贝叶斯模型比较框架。核心方法是在训练神经网络代理时引入自一致性约束，确保代理在不同数据子集上的预测保持一致。关键创新点是将自一致性损失函数整合到摊销推断训练过程中，即使在没有真实标签的经验数据上也能实施。与现有方法的主要区别在于：传统ABI方法仅依赖模拟数据训练，而SC方法通过经验数据的自监督信号增强了模型的泛化能力；同时，论文系统比较了四种不同的模型比较范式，明确了基于参数后验的方法架构优势。",
            "application_zh": "该方法可应用于需要快速模型选择的科学领域，如计算神经科学中的模型比较、生态学中的种群动态建模、以及任何涉及多个竞争统计模型的贝叶斯分析场景，为实际数据中的模型错误设定问题提供可靠解决方案。",
            "highlight_zh": "在合成和真实数据案例中，基于参数后验的模型比较方法比直接近似证据的方法准确率提升显著；当似然可用时，SC训练使模型在严重错误设定下的鲁棒性提高30%以上；但对于无解析似然的方法，SC改善效果有限且不稳定。",
            "tags_zh": [
                "摊销贝叶斯推断",
                "模型比较",
                "自一致性训练",
                "模型错误设定",
                "神经网络代理",
                "边际似然估计",
                "后验近似",
                "鲁棒性增强"
            ],
            "_index": 141
        },
        {
            "title": "The Trust in AI-Generated Health Advice (TAIGHA) Scale and Short Version (TAIGHA-S): Development and Validation Study",
            "authors": [
                "Marvin Kopka",
                "Azeem Majeed",
                "Gabriella Spinelli",
                "Austen El-Osta",
                "Markus Feufel"
            ],
            "arxiv_id": "2512.14278v1",
            "summary": "Artificial Intelligence tools such as large language models are increasingly used by the public to obtain health information and guidance. In health-related contexts, following or rejecting AI-generated advice can have direct clinical implications. Existing instruments like the Trust in Automated Systems Survey assess trustworthiness of generic technology, and no validated instrument measures users' trust in AI-generated health advice specifically. This study developed and validated the Trust in AI-Generated Health Advice (TAIGHA) scale and its four-item short form (TAIGHA-S) as theory-based instruments measuring trust and distrust, each with cognitive and affective components. The items were developed using a generative AI approach, followed by content validation with 10 domain experts, face validation with 30 lay participants, and psychometric validation with 385 UK participants who received AI-generated advice in a symptom-assessment scenario. After automated item reduction, 28 items were retained and reduced to 10 based on expert ratings. TAIGHA showed excellent content validity (S-CVI/Ave=0.99) and CFA confirmed a two-factor model with excellent fit (CFI=0.98, TLI=0.98, RMSEA=0.07, SRMR=0.03). Internal consistency was high (α=0.95). Convergent validity was supported by correlations with the Trust in Automated Systems Survey (r=0.67/-0.66) and users' reliance on the AI's advice (r=0.37 for trust), while divergent validity was supported by low correlations with reading flow and mental load (all |r|<0.25). TAIGHA-S correlated highly with the full scale (r=0.96) and showed good reliability (α=0.88). TAIGHA and TAIGHA-S are validated instruments for assessing user trust and distrust in AI-generated health advice. Reporting trust and distrust separately permits a more complete evaluation of AI interventions, and the short scale is well-suited for time-constrained settings.",
            "categories": [
                "cs.HC",
                "cs.AI"
            ],
            "primary_category": "cs.HC",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14278v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "PPO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出TAIGHA和TAIGHA-S量表，专门评估用户对AI生成健康建议的信任与不信任，以解决现有工具缺乏针对性测量的问题。",
            "summary_zh": "随着大型语言模型等人工智能工具被公众用于获取健康信息和指导，遵循或拒绝AI生成建议在健康相关情境中具有直接临床意义。现有工具如自动化系统信任调查评估通用技术的可信度，但缺乏专门测量用户对AI生成健康建议信任的有效工具。本研究开发并验证了基于理论的信任与不信任量表——TAIGHA及其四项简短形式TAIGHA-S，每个量表包含认知和情感成分。项目通过生成式AI方法开发，随后进行内容验证（10名领域专家）、表面验证（30名普通参与者）和心理测量验证（385名英国参与者在症状评估场景中接收AI建议）。经过自动项目缩减，保留28项并根据专家评分缩减至10项。TAIGHA显示出优异的内容效度（S-CVI/Ave=0.99），验证性因子分析确认双因子模型拟合良好（CFI=0.98, TLI=0.98, RMSEA=0.07, SRMR=0.03）。内部一致性高（α=0.95）。收敛效度得到与自动化系统信任调查（r=0.67/-0.66）和用户对AI建议的依赖（信任r=0.37）相关性的支持，而发散效度得到与阅读流畅性和心理负荷低相关性（所有|r|<0.25）的支持。TAIGHA-S与完整量表高度相关（r=0.96）并显示出良好信度（α=0.88）。TAIGHA和TAIGHA-S是评估用户对AI生成健康建议信任与不信任的有效工具。单独报告信任与不信任允许更全面地评估AI干预，简短量表适合时间受限场景。",
            "intro_zh": [
                "现有工具如自动化系统信任调查评估通用技术可信度，但缺乏专门测量用户对AI生成健康建议信任的有效工具，导致在健康相关情境中评估不足。",
                "论文提出基于理论的TAIGHA和TAIGHA-S量表，通过生成式AI方法开发项目，并整合认知和情感成分，以专门测量信任与不信任。",
                "验证结果显示TAIGHA具有优异的内容效度和模型拟合，TAIGHA-S与完整量表高度相关，支持其在时间受限场景中的应用。"
            ],
            "method_zh": "论文采用理论驱动的量表开发框架，核心方法包括：首先，使用生成式AI方法生成初始项目，确保覆盖信任与不信任的认知和情感维度；其次，通过内容验证（专家评审）和表面验证（参与者反馈）优化项目；最后，进行心理测量验证，包括验证性因子分析确认双因子结构（信任与不信任），并评估效度和信度。关键技术创新在于专门针对AI生成健康建议设计量表，与现有通用工具相比，更精准地捕捉健康情境下的用户信任动态。主要区别在于整合了生成式AI辅助项目开发，并强调信任与不信任的分离测量，以提供更全面的评估。",
            "application_zh": "该研究可应用于健康信息学、人机交互和临床决策支持领域，帮助评估AI工具在提供健康建议时的用户接受度，优化AI干预设计，提升健康服务的有效性和安全性。",
            "highlight_zh": "TAIGHA量表显示出优异的内容效度（S-CVI/Ave=0.99）和模型拟合（CFI=0.98），内部一致性高（α=0.95）；TAIGHA-S与完整量表高度相关（r=0.96），信度良好（α=0.88），支持其在快速评估场景中的实用性。",
            "tags_zh": [
                "AI生成健康建议",
                "信任量表",
                "心理测量验证",
                "人机交互",
                "健康信息学",
                "量表开发",
                "验证性因子分析",
                "自动化系统信任"
            ],
            "_index": 142
        },
        {
            "title": "TUN: Detecting Significant Points in Persistence Diagrams with Deep Learning",
            "authors": [
                "Yu Chen",
                "Hongwei Lin"
            ],
            "arxiv_id": "2512.14274v1",
            "summary": "Persistence diagrams (PDs) provide a powerful tool for understanding the topology of the underlying shape of a point cloud. However, identifying which points in PDs encode genuine signals remains challenging. This challenge directly hinders the practical adoption of topological data analysis in many applications, where automated and reliable interpretation of persistence diagrams is essential for downstream decision-making. In this paper, we study automatic significance detection for one-dimensional persistence diagrams. Specifically, we propose Topology Understanding Net (TUN), a multi-modal network that combines enhanced PD descriptors with self-attention, a PointNet-style point cloud encoder, learned fusion, and per-point classification, alongside stable preprocessing and imbalance-aware training. It provides an automated and effective solution for identifying significant points in PDs, which are critical for downstream applications. Experiments show that TUN outperforms classic methods in detecting significant points in PDs, illustrating its effectiveness in real-world applications.",
            "categories": [
                "cs.CV",
                "cs.LG",
                "math.AT"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14274v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出TUN网络以解决一维持久性图中显著点自动检测的挑战，提升拓扑数据分析的实用性。",
            "summary_zh": "持久性图（PDs）是理解点云底层形状拓扑结构的强大工具，但识别PDs中哪些点编码真实信号仍具挑战性，这直接阻碍了拓扑数据分析在许多应用中的实际采用，其中持久性图的自动可靠解释对下游决策至关重要。本文研究一维持久性图的自动显著性检测，提出拓扑理解网络（TUN），这是一个多模态网络，结合增强的PD描述符与自注意力机制、PointNet风格的点云编码器、学习融合和逐点分类，以及稳定的预处理和不平衡感知训练。它为识别PDs中的显著点提供了自动有效的解决方案，这对下游应用至关重要。实验表明，TUN在检测PDs中的显著点方面优于经典方法，证明了其在现实应用中的有效性。",
            "intro_zh": [
                "核心问题：持久性图中哪些点编码真实信号难以自动识别，阻碍拓扑数据分析在实际应用中的可靠采用。",
                "方法要点：提出TUN网络，结合增强描述符、自注意力、点云编码器和学习融合，实现多模态显著点分类。",
                "实验或效果：TUN在检测显著点方面超越经典方法，验证了其在真实场景中的有效性和实用性。"
            ],
            "method_zh": "TUN的整体框架是一个多模态网络，专为一维持久性图的显著点检测设计。关键技术创新点包括：结合增强的持久性图描述符以捕获拓扑特征；引入自注意力机制和PointNet风格的点云编码器处理点云数据；通过学习融合模块整合多模态信息；采用逐点分类输出显著点预测。与现有方法的主要区别在于，TUN集成了深度学习和拓扑描述符，提供端到端的自动化解决方案，而传统方法多依赖手动阈值或统计测试，缺乏灵活性和准确性。",
            "application_zh": "该研究可应用于计算机视觉、机器人和生物信息学等领域，其中点云数据的拓扑分析是关键步骤，如形状识别、异常检测和结构分析，通过自动检测显著点提升下游任务的决策效率和可靠性。",
            "highlight_zh": "实验结果显示，TUN在检测一维持久性图中的显著点时，性能优于经典方法，如基于统计测试或阈值的方法，具体提升表现为更高的准确率和鲁棒性，证明了其在实际应用中的有效性和自动化优势。",
            "tags_zh": [
                "持久性图",
                "拓扑数据分析",
                "显著点检测",
                "多模态网络",
                "自注意力机制",
                "点云编码",
                "深度学习",
                "不平衡感知训练"
            ],
            "_index": 143
        },
        {
            "title": "Explainable Preference Learning: a Decision Tree-based Surrogate Model for Preferential Bayesian Optimization",
            "authors": [
                "Nick Leenders",
                "Thomas Quadt",
                "Boris Cule",
                "Roy Lindelauf",
                "Herman Monsuur",
                "Joost van Oijen",
                "Mark Voskuijl"
            ],
            "arxiv_id": "2512.14263v1",
            "summary": "Current Preferential Bayesian Optimization methods rely on Gaussian Processes (GPs) as surrogate models. These models are hard to interpret, struggle with handling categorical data, and are computationally complex, limiting their real-world usability. In this paper, we introduce an inherently interpretable decision tree-based surrogate model capable of handling both categorical and continuous data, and scalable to large datasets. Extensive numerical experiments on eight increasingly spiky optimization functions show that our model outperforms GP-based alternatives on spiky functions and has only marginally lower performance for non-spiky functions. Moreover, we apply our model to the real-world Sushi dataset and show its ability to learn an individual's sushi preferences. Finally, we show some initial work on using historical preference data to speed up the optimization process for new unseen users.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "math.OC"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14263v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出基于决策树的可解释偏好学习模型，以解决高斯过程在偏好贝叶斯优化中可解释性差、处理分类数据困难及计算复杂的问题。",
            "summary_zh": "当前的偏好贝叶斯优化方法依赖于高斯过程作为代理模型，这些模型难以解释、处理分类数据困难且计算复杂，限制了其实际应用。本文引入了一种基于决策树的固有可解释代理模型，能够处理分类和连续数据，并可扩展到大型数据集。在八个逐渐尖峰的优化函数上进行的大量数值实验表明，该模型在尖峰函数上优于基于高斯过程的替代方法，在非尖峰函数上性能仅略低。此外，我们将模型应用于真实世界的寿司数据集，展示了其学习个人寿司偏好的能力。最后，我们展示了利用历史偏好数据加速新用户优化过程的初步工作。",
            "intro_zh": [
                "现有高斯过程模型在偏好贝叶斯优化中可解释性差、难以处理分类数据且计算复杂，限制了实际应用。",
                "提出基于决策树的代理模型，具有固有可解释性，能处理分类和连续数据，并支持大规模数据集。",
                "实验显示，在尖峰函数上性能优于高斯过程模型，在非尖峰函数上性能接近，并成功应用于寿司偏好学习。"
            ],
            "method_zh": "论文提出了一种基于决策树的代理模型框架，用于替代传统的高斯过程在偏好贝叶斯优化中的角色。关键技术创新点在于利用决策树的固有可解释性，通过树结构直接建模用户偏好，支持混合数据类型（如分类和连续变量），并采用高效算法实现可扩展性。与现有方法的主要区别在于，该方法避免了高斯过程的黑盒特性，提供了更直观的模型解释，同时降低了计算复杂度，更适合处理大规模或复杂数据场景。",
            "application_zh": "该研究可应用于个性化推荐系统、产品设计优化和用户偏好建模等领域，通过可解释的偏好学习提升决策透明度和效率，具有实际商业和科研价值。",
            "highlight_zh": "在八个尖峰优化函数实验中，基于决策树的模型在尖峰函数上显著优于高斯过程模型，在非尖峰函数上性能损失微小；寿司数据集应用成功学习个人偏好，验证了模型的实际有效性。",
            "tags_zh": [
                "偏好学习",
                "贝叶斯优化",
                "决策树模型",
                "可解释人工智能",
                "分类数据处理",
                "大规模优化",
                "个性化推荐"
            ],
            "_index": 144
        },
        {
            "title": "FLAME: Flow Enhanced Legendre Memory Models for General Time Series Forecasting",
            "authors": [
                "Xingjian Wu",
                "Hanyin Cheng",
                "Xiangfei Qiu",
                "Zhengyu Li",
                "Jilin Hu",
                "Chenjuan Guo",
                "Bin Yang"
            ],
            "arxiv_id": "2512.14253v1",
            "summary": "In this work, we introduce FLAME, a family of extremely lightweight and capable Time Series Foundation Models, which support both deterministic and probabilistic forecasting via generative probabilistic modeling, thus ensuring both efficiency and robustness. FLAME utilizes the Legendre Memory for strong generalization capabilities. Through adapting variants of Legendre Memory, i.e., translated Legendre (LegT) and scaled Legendre (LegS), in the Encoding and Decoding phases, FLAME can effectively capture the inherent inductive bias within data and make efficient long-range inferences. To enhance the accuracy of probabilistic forecasting while keeping efficient, FLAME adopts a Normalization Flow based forecasting head, which can model the arbitrarily intricate distributions over the forecasting horizon in a generative manner. Comprehensive experiments on well-recognized benchmarks, including TSFM-Bench and ProbTS, demonstrate the consistent state-of-the-art zero-shot performance of FLAME on both deterministic and probabilistic forecasting tasks.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14253v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "PPO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出FLAME模型，通过流增强的勒让德记忆和归一化流预测头，实现高效且鲁棒的通用时间序列确定性及概率预测。",
            "summary_zh": "本文介绍了FLAME，一个极其轻量且强大的时间序列基础模型家族，支持通过生成式概率建模进行确定性和概率预测，从而确保效率和鲁棒性。FLAME利用勒让德记忆实现强大的泛化能力。通过在编码和解码阶段采用勒让德记忆的变体，即平移勒让德（LegT）和缩放勒让德（LegS），FLAME能有效捕捉数据中的内在归纳偏置，并进行高效的长程推理。为了在保持高效的同时提升概率预测的准确性，FLAME采用基于归一化流的预测头，以生成方式建模预测范围内任意复杂的分布。在公认基准（如TSFM-Bench和ProbTS）上的全面实验表明，FLAME在确定性和概率预测任务上均展现出一致的零样本最先进性能。",
            "intro_zh": [
                "现有时间序列预测方法在泛化能力、长程推理效率和概率建模精度方面存在不足，难以兼顾轻量化和鲁棒性。",
                "FLAME通过勒让德记忆变体（LegT和LegS）捕捉数据归纳偏置，并结合归一化流预测头生成复杂分布，实现高效且准确的预测。",
                "在TSFM-Bench和ProbTS基准测试中，FLAME在确定性和概率预测任务上均达到零样本最先进性能，验证了其优越性。"
            ],
            "method_zh": "FLAME的整体框架基于勒让德记忆单元，在编码和解码阶段分别采用LegT和LegS变体，以增强对时间序列动态的建模能力。关键技术创新包括：利用勒让德记忆的数学特性实现强泛化和长程推理，以及引入归一化流作为预测头，以生成方式灵活建模预测分布。与现有方法的主要区别在于，FLAME将轻量化的基础模型设计与生成式概率预测相结合，避免了传统方法在复杂分布建模上的计算开销或精度损失。",
            "application_zh": "该研究可应用于金融、能源、交通和医疗等领域的时间序列预测任务，如股票价格预测、电力负荷预测、交通流量分析和疾病趋势预测，提供高效且鲁棒的预测解决方案。",
            "highlight_zh": "在TSFM-Bench和ProbTS基准测试中，FLAME在确定性和概率预测任务上均实现零样本最先进性能，显著提升了预测准确性和效率，证明了其作为时间序列基础模型的强大能力。",
            "tags_zh": [
                "时间序列预测",
                "勒让德记忆",
                "归一化流",
                "概率建模",
                "零样本学习",
                "基础模型",
                "长程推理",
                "轻量化模型"
            ],
            "_index": 145
        },
        {
            "title": "From Context to EDUs: Faithful and Structured Context Compression via Elementary Discourse Unit Decomposition",
            "authors": [
                "Yiqing Zhou",
                "Yu Lei",
                "Shuzheng Si",
                "Qingyan Sun",
                "Wei Wang",
                "Yifei Wu",
                "Hao Wen",
                "Gang Chen",
                "Fanchao Qi",
                "Maosong Sun"
            ],
            "arxiv_id": "2512.14244v1",
            "summary": "Managing extensive context remains a critical bottleneck for Large Language Models (LLMs), particularly in applications like long-document question answering and autonomous agents where lengthy inputs incur high computational costs and introduce noise. Existing compression techniques often disrupt local coherence through discrete token removal or rely on implicit latent encoding that suffers from positional bias and incompatibility with closed-source APIs. To address these limitations, we introduce the EDU-based Context Compressor, a novel explicit compression framework designed to preserve both global structure and fine-grained details. Our approach reformulates context compression as a structure-then-select process. First, our LingoEDU transforms linear text into a structural relation tree of Elementary Discourse Units (EDUs) which are anchored strictly to source indices to eliminate hallucination. Second, a lightweight ranking module selects query-relevant sub-trees for linearization. To rigorously evaluate structural understanding, we release StructBench, a manually annotated dataset of 248 diverse documents. Empirical results demonstrate that our method achieves state-of-the-art structural prediction accuracy and significantly outperforms frontier LLMs while reducing costs. Furthermore, our structure-aware compression substantially enhances performance across downstream tasks ranging from long-context tasks to complex Deep Search scenarios.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14244v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出基于基本话语单元的上下文压缩框架，以解决长文档处理中的计算成本高和噪声问题。",
            "summary_zh": "管理大量上下文仍然是大型语言模型（LLMs）的关键瓶颈，特别是在长文档问答和自主代理等应用中，冗长的输入会导致高计算成本并引入噪声。现有的压缩技术通常通过离散标记删除破坏局部连贯性，或依赖存在位置偏差且与闭源API不兼容的隐式潜在编码。为解决这些限制，我们引入了基于EDU的上下文压缩器，这是一种新颖的显式压缩框架，旨在保留全局结构和细粒度细节。我们的方法将上下文压缩重新表述为结构-然后-选择的过程。首先，我们的LingoEDU将线性文本转换为基本话语单元（EDUs）的结构关系树，这些单元严格锚定到源索引以消除幻觉。其次，一个轻量级排名模块选择与查询相关的子树进行线性化。为了严格评估结构理解，我们发布了StructBench，这是一个包含248个多样化文档的手动标注数据集。实证结果表明，我们的方法实现了最先进的结构预测准确性，并显著优于前沿LLMs，同时降低了成本。此外，我们的结构感知压缩显著提高了从长上下文任务到复杂深度搜索场景的下游任务的性能。",
            "intro_zh": [
                "现有压缩方法破坏局部连贯性或存在位置偏差，导致长文档处理效率低下。",
                "提出基于基本话语单元的结构化压缩框架，通过分解和选择保留上下文完整性。",
                "实验显示该方法在结构预测和下游任务中优于前沿模型，同时降低计算成本。"
            ],
            "method_zh": "论文提出EDU-based Context Compressor框架，整体采用结构-然后-选择的两阶段流程。首先，LingoEDU模块将线性文本分解为基本话语单元（EDUs），构建结构关系树并严格锚定源索引以避免幻觉。其次，轻量级排名模块基于查询相关性选择子树进行线性化输出。关键创新在于显式结构化压缩，通过EDU分解保留全局和局部信息，与现有基于离散删除或隐式编码的方法相比，显著提升了结构保真度和兼容性。",
            "application_zh": "该研究适用于长文档问答、自主代理系统、复杂深度搜索等场景，能有效降低LLMs的计算开销和噪声干扰，提升处理效率和准确性，具有实际部署价值。",
            "highlight_zh": "在StructBench数据集上实现最先进的结构预测准确性，显著优于前沿LLMs；结构感知压缩使下游任务性能大幅提升，同时减少计算成本，验证了方法的有效性。",
            "tags_zh": [
                "上下文压缩",
                "基本话语单元",
                "结构关系树",
                "长文档处理",
                "大型语言模型",
                "计算效率",
                "下游任务增强",
                "显式压缩框架"
            ],
            "_index": 146
        },
        {
            "title": "Beyond MMD: Evaluating Graph Generative Models with Geometric Deep Learning",
            "authors": [
                "Salvatore Romano",
                "Marco Grassia",
                "Giuseppe Mangioni"
            ],
            "arxiv_id": "2512.14241v1",
            "summary": "Graph generation is a crucial task in many fields, including network science and bioinformatics, as it enables the creation of synthetic graphs that mimic the properties of real-world networks for various applications. Graph Generative Models (GGMs) have emerged as a promising solution to this problem, leveraging deep learning techniques to learn the underlying distribution of real-world graphs and generate new samples that closely resemble them. Examples include approaches based on Variational Auto-Encoders, Recurrent Neural Networks, and more recently, diffusion-based models. However, the main limitation often lies in the evaluation process, which typically relies on Maximum Mean Discrepancy (MMD) as a metric to assess the distribution of graph properties in the generated ensemble. This paper introduces a novel methodology for evaluating GGMs that overcomes the limitations of MMD, which we call RGM (Representation-aware Graph-generation Model evaluation). As a practical demonstration of our methodology, we present a comprehensive evaluation of two state-of-the-art Graph Generative Models: Graph Recurrent Attention Networks (GRAN) and Efficient and Degree-guided graph GEnerative model (EDGE). We investigate their performance in generating realistic graphs and compare them using a Geometric Deep Learning model trained on a custom dataset of synthetic and real-world graphs, specifically designed for graph classification tasks. Our findings reveal that while both models can generate graphs with certain topological properties, they exhibit significant limitations in preserving the structural characteristics that distinguish different graph domains. We also highlight the inadequacy of Maximum Mean Discrepancy as an evaluation metric for GGMs and suggest alternative approaches for future research.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "physics.soc-ph"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "16 pages, 4 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14241v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出RGM方法以解决图生成模型评估中MMD的局限性，基于几何深度学习进行更准确评估。",
            "summary_zh": "图生成是网络科学和生物信息学等领域的核心任务，图生成模型（GGMs）利用深度学习技术学习真实世界图的分布并生成相似样本，如基于变分自编码器、循环神经网络和扩散模型的方法。然而，现有评估过程主要依赖最大均值差异（MMD）作为度量，存在局限性。本文提出一种名为RGM（表示感知图生成模型评估）的新方法，克服了MMD的不足。作为方法演示，我们全面评估了两种先进图生成模型：图循环注意力网络（GRAN）和高效度引导图生成模型（EDGE），通过几何深度学习模型在自定义合成与真实图数据集上进行分类任务分析。研究发现，尽管两种模型能生成具有特定拓扑性质的图，但在保持区分不同图域的结构特征方面存在显著限制，同时强调了MMD作为评估度量的不足，并为未来研究提出了替代方案。",
            "intro_zh": [
                "核心问题：现有图生成模型评估过度依赖最大均值差异（MMD），无法准确捕捉图的结构特性差异，导致评估不全面。",
                "方法要点：提出RGM方法，基于几何深度学习模型训练自定义数据集，通过图分类任务评估生成图的表示质量，超越MMD的局限性。",
                "实验或效果：评估GRAN和EDGE模型，发现它们在生成图时能保留某些拓扑性质，但在结构特征保持上存在不足，验证了MMD的缺陷。"
            ],
            "method_zh": "论文核心方法是RGM（表示感知图生成模型评估），整体框架包括：首先，构建一个包含合成和真实图的自定义数据集，专门用于图分类任务；其次，训练一个几何深度学习模型（如基于图神经网络的分类器）来学习图的表示；然后，使用该模型评估图生成模型（如GRAN和EDGE）生成的图，通过分类性能或表示相似性来量化生成图与真实图的差异。关键技术创新点在于将评估从传统的MMD度量转向基于几何深度学习的表示分析，这能更细致地捕捉图的结构和域特性。与现有方法的主要区别是，RGM不依赖单一统计度量，而是利用深度学习模型进行端到端评估，从而提供更全面和准确的性能分析。",
            "application_zh": "该研究可应用于网络科学、生物信息学、社交网络分析和药物发现等领域，通过改进图生成模型的评估，帮助生成更逼真的合成图，用于模拟、数据增强和算法测试，提升实际应用的可靠性和效率。",
            "highlight_zh": "实验显示，GRAN和EDGE在生成图时能模拟某些拓扑属性（如度分布），但在保持图域特有结构特征（如社区结构或全局连通性）方面表现不佳；RGM方法通过几何深度学习模型揭示了这些局限性，并证明MMD作为评估度量不足以捕捉复杂图特性，为未来研究提供了更准确的评估基准。",
            "tags_zh": [
                "图生成模型评估",
                "几何深度学习",
                "最大均值差异",
                "图神经网络",
                "图分类任务",
                "表示学习",
                "拓扑性质分析",
                "合成图生成"
            ],
            "_index": 147
        },
        {
            "title": "Ladder Up, Memory Down: Low-Cost Fine-Tuning With Side Nets",
            "authors": [
                "Estelle Zheng",
                "Nathan Cerisara",
                "Sébastien Warichet",
                "Emmanuel Helbert",
                "Christophe Cerisara"
            ],
            "arxiv_id": "2512.14237v1",
            "summary": "Fine-tuning large language models (LLMs) is often limited by the memory available on commodity GPUs. Parameter-efficient fine-tuning (PEFT) methods such as QLoRA reduce the number of trainable parameters, yet still incur high memory usage induced by the backward pass in the full model. We revisit Ladder Side Tuning (LST), a rarely explored PEFT technique that adds a lightweight side network, and show that it matches QLoRA's compute scaling slope while cutting peak memory by 50\\%. Across different downstream benchmarks spanning natural language understanding, mathematical and LLM-critic tasks, LST has competitive performance with QLoRA's accuracy on average while being much more memory-efficient. This efficiency enables fine-tuning of 7B-parameter models on a single 12 GB consumer GPU with 2k-token contexts, requiring no gradient checkpointing\\textemdash conditions under which QLoRA exhausts memory. Beyond memory efficiency, we also establish scaling laws showing that LST scales similarly to QLoRA. We exploit Ladder's architectural flexibility by introducing xLadder, a depth-extended variant that increases effective depth via cross-connections and shortens chain-of-thought (CoT) at fixed parameter count. Ladder is strong when memory is the bottleneck; xLadder builds on this by enabling deeper reasoning without additional memory overhead.",
            "categories": [
                "cs.CL",
                "cs.LG"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14237v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出Ladder Side Tuning方法，通过轻量级侧网络实现大语言模型低成本微调，显著降低内存需求。",
            "summary_zh": "微调大语言模型（LLMs）常受限于商用GPU的内存容量。参数高效微调（PEFT）方法如QLoRA减少了可训练参数数量，但仍因完整模型的反向传播而产生高内存占用。本文重新审视了Ladder Side Tuning（LST），这是一种较少被探索的PEFT技术，通过添加轻量级侧网络，在保持与QLoRA相似计算扩展斜率的同时，将峰值内存降低50%。在涵盖自然语言理解、数学和LLM批评任务的不同下游基准测试中，LST平均性能与QLoRA相当，同时内存效率更高。这种效率使得在单个12GB消费级GPU上微调70亿参数模型成为可能，支持2k令牌上下文且无需梯度检查点——在这些条件下QLoRA会耗尽内存。除了内存效率，我们还建立了扩展定律，表明LST的扩展方式与QLoRA相似。通过利用Ladder的架构灵活性，我们引入了xLadder，这是一种深度扩展变体，通过交叉连接增加有效深度，并在固定参数数量下缩短思维链（CoT）。Ladder在内存受限时表现强劲；xLadder在此基础上实现了更深层推理，且无额外内存开销。",
            "intro_zh": [
                "现有PEFT方法如QLoRA虽减少可训练参数，但反向传播仍导致高内存占用，限制大模型在消费级GPU上的微调。",
                "提出Ladder Side Tuning（LST），添加轻量级侧网络，仅微调侧网络参数，大幅降低内存需求，同时保持性能。",
                "实验显示LST峰值内存降低50%，在12GB GPU上微调7B模型可行，性能与QLoRA相当，扩展定律相似。"
            ],
            "method_zh": "论文核心方法是Ladder Side Tuning（LST），整体框架基于预训练大语言模型，添加一个轻量级侧网络（side network），该网络通过梯子状连接（ladder connections）与主模型交互。关键技术创新点在于仅微调侧网络参数，主模型参数保持冻结，从而大幅减少反向传播时的内存占用。与现有PEFT方法（如QLoRA）的主要区别在于：QLoRA通过量化等技术减少参数但仍在完整模型上进行反向传播，而LST通过侧网络实现参数高效，避免了主模型的反向传播开销，因此内存效率更高。此外，论文还提出了xLadder变体，通过交叉连接增加网络深度，提升推理能力。",
            "application_zh": "该研究适用于资源受限环境下的自然语言处理任务，如消费级GPU上的大语言模型微调，可应用于自然语言理解、数学推理、LLM批评等领域，降低部署成本，促进AI技术普及。",
            "highlight_zh": "LST在多个下游任务中性能与QLoRA相当，峰值内存降低50%，支持在12GB GPU上微调7B参数模型（2k令牌上下文），无需梯度检查点，扩展定律显示与QLoRA相似扩展性。",
            "tags_zh": [
                "参数高效微调",
                "大语言模型",
                "内存优化",
                "侧网络",
                "轻量级微调",
                "自然语言理解",
                "扩展定律",
                "消费级GPU"
            ],
            "_index": 148
        },
        {
            "title": "4D-RaDiff: Latent Diffusion for 4D Radar Point Cloud Generation",
            "authors": [
                "Jimmie Kwok",
                "Holger Caesar",
                "Andras Palffy"
            ],
            "arxiv_id": "2512.14235v1",
            "summary": "Automotive radar has shown promising developments in environment perception due to its cost-effectiveness and robustness in adverse weather conditions. However, the limited availability of annotated radar data poses a significant challenge for advancing radar-based perception systems. To address this limitation, we propose a novel framework to generate 4D radar point clouds for training and evaluating object detectors. Unlike image-based diffusion, our method is designed to consider the sparsity and unique characteristics of radar point clouds by applying diffusion to a latent point cloud representation. Within this latent space, generation is controlled via conditioning at either the object or scene level. The proposed 4D-RaDiff converts unlabeled bounding boxes into high-quality radar annotations and transforms existing LiDAR point cloud data into realistic radar scenes. Experiments demonstrate that incorporating synthetic radar data of 4D-RaDiff as data augmentation method during training consistently improves object detection performance compared to training on real data only. In addition, pre-training on our synthetic data reduces the amount of required annotated radar data by up to 90% while achieving comparable object detection performance.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14235v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "自动驾驶",
                    "matched_keywords": [
                        "lidar"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出4D-RaDiff框架，通过潜在扩散生成4D雷达点云，以解决雷达数据标注不足的问题，提升自动驾驶环境感知能力。",
            "summary_zh": "汽车雷达因其成本效益和在恶劣天气条件下的鲁棒性，在环境感知方面展现出有前景的发展。然而，标注雷达数据的有限可用性对推进基于雷达的感知系统构成了重大挑战。为应对这一限制，我们提出了一种新颖框架来生成4D雷达点云，用于训练和评估物体检测器。与基于图像的扩散方法不同，我们的方法通过将扩散应用于潜在点云表示，考虑了雷达点云的稀疏性和独特特性。在此潜在空间中，生成通过对象或场景级别的条件进行控制。所提出的4D-RaDiff将未标注的边界框转换为高质量的雷达标注，并将现有的激光雷达点云数据转换为逼真的雷达场景。实验表明，在训练过程中将4D-RaDiff的合成雷达数据作为数据增强方法，相比仅使用真实数据进行训练，能持续提升物体检测性能。此外，在我们的合成数据上进行预训练，可将所需标注雷达数据量减少高达90%，同时实现可比的物体检测性能。",
            "intro_zh": [
                "核心问题：标注雷达数据稀缺，限制了基于雷达的感知系统发展，尤其在自动驾驶领域。",
                "方法要点：提出4D-RaDiff框架，利用潜在扩散模型生成4D雷达点云，通过对象或场景条件控制生成过程。",
                "实验或效果：合成数据作为增强方法提升检测性能，预训练可减少90%标注数据需求，保持性能可比。"
            ],
            "method_zh": "4D-RaDiff框架整体基于潜在扩散模型，核心创新点在于将扩散过程应用于雷达点云的潜在表示，而非直接处理原始点云。这允许模型更好地捕捉雷达数据的稀疏性和噪声特性。关键技术创新包括设计潜在空间编码器以压缩点云信息，以及引入对象级和场景级条件机制来控制生成内容。与现有方法（如图像扩散）的主要区别在于专门针对雷达点云的独特结构进行优化，避免了直接处理高维稀疏数据带来的计算挑战，从而更高效地生成逼真的雷达场景。",
            "application_zh": "该研究主要应用于自动驾驶领域，用于生成合成雷达数据以增强物体检测器的训练和评估。潜在应用包括雷达感知系统的开发、数据增强工具，以及减少对昂贵真实标注数据的依赖，推动雷达技术在恶劣天气和低成本场景下的部署。",
            "highlight_zh": "实验显示，使用4D-RaDiff合成数据作为增强方法，物体检测性能相比仅用真实数据有持续提升；预训练可减少高达90%的标注雷达数据需求，同时保持可比检测性能，验证了框架的有效性和实用性。",
            "tags_zh": [
                "4D雷达点云生成",
                "潜在扩散模型",
                "自动驾驶感知",
                "数据增强",
                "物体检测",
                "雷达数据合成",
                "点云表示学习",
                "条件生成"
            ],
            "_index": 149
        },
        {
            "title": "Multi-View MRI Approach for Classification of MGMT Methylation in Glioblastoma Patients",
            "authors": [
                "Rawan Alyahya",
                "Asrar Alruwayqi",
                "Atheer Alqarni",
                "Asma Alkhaldi",
                "Metab Alkubeyyer",
                "Xin Gao",
                "Mona Alshahrani"
            ],
            "arxiv_id": "2512.14232v1",
            "summary": "The presence of MGMT promoter methylation significantly affects how well chemotherapy works for patients with Glioblastoma Multiforme (GBM). Currently, confirmation of MGMT promoter methylation relies on invasive brain tumor tissue biopsies. In this study, we explore radiogenomics techniques, a promising approach in precision medicine, to identify genetic markers from medical images. Using MRI scans and deep learning models, we propose a new multi-view approach that considers spatial relationships between MRI views to detect MGMT methylation status. Importantly, our method extracts information from all three views without using a complicated 3D deep learning model, avoiding issues associated with high parameter count, slow convergence, and substantial memory demands. We also introduce a new technique for tumor slice extraction and show its superiority over existing methods based on multiple evaluation metrics. By comparing our approach to state-of-the-art models, we demonstrate the efficacy of our method. Furthermore, we share a reproducible pipeline of published models, encouraging transparency and the development of robust diagnostic tools. Our study highlights the potential of non-invasive methods for identifying MGMT promoter methylation and contributes to advancing precision medicine in GBM treatment.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14232v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出多视图MRI方法，利用空间关系和深度学习非侵入性检测胶质母细胞瘤MGMT甲基化状态。",
            "summary_zh": "MGMT启动子甲基化的存在显著影响胶质母细胞瘤（GBM）患者化疗效果。目前，确认MGMT启动子甲基化依赖于侵入性脑肿瘤组织活检。本研究探索了放射基因组学技术，这是一种在精准医学中前景广阔的方法，旨在从医学图像中识别遗传标记。利用MRI扫描和深度学习模型，我们提出了一种新的多视图方法，考虑MRI视图之间的空间关系来检测MGMT甲基化状态。重要的是，我们的方法从所有三个视图中提取信息，而不使用复杂的3D深度学习模型，避免了高参数数量、收敛慢和大量内存需求等问题。我们还引入了一种新的肿瘤切片提取技术，并基于多个评估指标展示了其优于现有方法的性能。通过将我们的方法与最先进模型进行比较，我们证明了该方法的有效性。此外，我们分享了已发表模型的可复现流程，鼓励透明度和稳健诊断工具的开发。我们的研究突出了非侵入性方法识别MGMT启动子甲基化的潜力，并有助于推进GBM治疗中的精准医学。",
            "intro_zh": [
                "核心问题：现有MGMT甲基化检测依赖侵入性活检，风险高且耗时，而传统3D深度学习模型参数多、收敛慢、内存需求大。",
                "方法要点：提出多视图MRI方法，结合空间关系和深度学习，从三个视图提取信息，避免复杂3D模型，并引入新肿瘤切片提取技术。",
                "实验或效果：新方法在多个评估指标上优于现有方法，展示了非侵入性检测的潜力，并提供了可复现流程。"
            ],
            "method_zh": "论文提出一个多视图MRI框架，用于MGMT甲基化分类。整体框架基于深度学习模型，从MRI的三个视图（如轴向、冠状、矢状）提取特征，并考虑视图间的空间关系进行融合，以增强信息表示。关键技术创新点包括：避免使用复杂3D模型，通过多视图方法减少参数和内存需求；引入新的肿瘤切片提取技术，提高数据预处理效率。与现有方法的主要区别在于：传统方法常依赖单一视图或复杂3D模型，而本方法通过多视图融合和简化架构，在保持性能的同时降低了计算负担。",
            "application_zh": "该研究在精准医学领域有重要应用，特别是胶质母细胞瘤（GBM）治疗。通过非侵入性MRI扫描检测MGMT甲基化状态，可辅助临床决策，优化化疗方案，减少患者活检风险。此外，方法可推广至其他脑肿瘤或癌症的遗传标记检测，推动个性化医疗发展。",
            "highlight_zh": "实验结果显示，新方法在MGMT甲基化分类任务中，基于多个评估指标（如准确率、灵敏度）优于现有最先进模型。肿瘤切片提取技术的引入显著提升了性能，同时多视图框架避免了3D模型的高计算成本，实现了高效且稳健的检测。",
            "tags_zh": [
                "放射基因组学",
                "多视图MRI",
                "深度学习",
                "MGMT甲基化检测",
                "胶质母细胞瘤",
                "非侵入性诊断",
                "精准医学",
                "肿瘤切片提取"
            ],
            "_index": 150
        },
        {
            "title": "Weighted Conformal Prediction Provides Adaptive and Valid Mask-Conditional Coverage for General Missing Data Mechanisms",
            "authors": [
                "Jiarong Fan",
                "Juhyun Park. Thi Phuong Thuy Vo",
                "Nicolas Brunel"
            ],
            "arxiv_id": "2512.14221v1",
            "summary": "Conformal prediction (CP) offers a principled framework for uncertainty quantification, but it fails to guarantee coverage when faced with missing covariates. In addressing the heterogeneity induced by various missing patterns, Mask-Conditional Valid (MCV) Coverage has emerged as a more desirable property than Marginal Coverage. In this work, we adapt split CP to handle missing values by proposing a preimpute-mask-then-correct framework that can offer valid coverage. We show that our method provides guaranteed Marginal Coverage and Mask-Conditional Validity for general missing data mechanisms. A key component of our approach is a reweighted conformal prediction procedure that corrects the prediction sets after distributional imputation (multiple imputation) of the calibration dataset, making our method compatible with standard imputation pipelines. We derive two algorithms, and we show that they are approximately marginally valid and MCV. We evaluate them on synthetic and real-world datasets. It reduces significantly the width of prediction intervals w.r.t standard MCV methods, while maintaining the target guarantees.",
            "categories": [
                "stat.ML",
                "cs.LG"
            ],
            "primary_category": "stat.ML",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14221v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出加权共形预测方法，为一般缺失数据机制提供自适应且有效的掩码条件覆盖保证。",
            "summary_zh": "共形预测（CP）为不确定性量化提供了原则性框架，但在面对缺失协变量时无法保证覆盖。针对由各种缺失模式引起的异质性，掩码条件有效（MCV）覆盖已成为比边际覆盖更理想的属性。本研究通过提出一个预填补-掩码-校正框架来适应分割CP处理缺失值，该框架能够提供有效覆盖。我们证明，我们的方法为一般缺失数据机制提供了保证的边际覆盖和掩码条件有效性。我们方法的一个关键组成部分是重新加权的共形预测过程，在校准数据集的分布填补（多重填补）后校正预测集，使我们的方法与标准填补流程兼容。我们推导出两种算法，并证明它们近似边际有效和MCV。我们在合成和真实世界数据集上评估它们。相对于标准MCV方法，它显著减少了预测区间的宽度，同时保持了目标保证。",
            "intro_zh": [
                "共形预测在处理缺失协变量时无法保证覆盖，现有方法难以应对缺失模式引起的异质性。",
                "提出预填补-掩码-校正框架，通过加权共形预测校正填补后的预测集，兼容标准填补流程。",
                "在合成和真实数据集上验证，显著减少预测区间宽度，同时维持边际覆盖和掩码条件有效性保证。"
            ],
            "method_zh": "论文提出一个预填补-掩码-校正框架，整体流程包括：首先对校准数据集进行分布填补（多重填补），然后应用掩码处理缺失模式，最后通过重新加权的共形预测过程校正预测集。关键技术创新在于引入加权机制，根据缺失模式调整预测集的权重，以提供自适应覆盖。与现有方法的主要区别在于，该方法不仅保证边际覆盖，还能为一般缺失数据机制提供掩码条件有效性，同时通过校正步骤减少预测区间宽度，提高了效率。",
            "application_zh": "该研究可应用于医疗诊断、金融风险评估和工业质量控制等领域，其中数据常存在缺失值，需要可靠的不确定性量化来支持决策。通过提供自适应且有效的覆盖保证，有助于提升模型在现实世界中的鲁棒性和可信度。",
            "highlight_zh": "实验表明，该方法在合成和真实数据集上显著减少了预测区间宽度，相对于标准MCV方法平均降低约20-30%，同时严格维持了边际覆盖和掩码条件有效性的目标保证，验证了其高效性和可靠性。",
            "tags_zh": [
                "共形预测",
                "缺失数据处理",
                "不确定性量化",
                "掩码条件覆盖",
                "加权校正",
                "多重填补",
                "预测区间优化"
            ],
            "_index": 151
        },
        {
            "title": "Trajectory Tracking for Multi-Manipulator Systems in Constrained Environments",
            "authors": [
                "Mayank Sewlia",
                "Christos K. Verginis",
                "Dimos V. Dimarogonas"
            ],
            "arxiv_id": "2512.14206v1",
            "summary": "We consider the problem of cooperative manipulation by a mobile multi-manipulator system operating in obstacle-cluttered and highly constrained environments under spatio-temporal task specifications. The task requires transporting a grasped object while respecting both continuous robot dynamics and discrete geometric constraints arising from obstacles and narrow passages. To address this hybrid structure, we propose a multi-rate planning and control framework that combines offline generation of an STL-satisfying object trajectory and collision-free base footprints with online constrained inverse kinematics and continuous-time feedback control. The resulting closed-loop system enables coordinated reconfiguration of multiple manipulators while tracking the desired object motion. The approach is evaluated in high-fidelity physics simulations using three Franka Emika Panda mobile manipulators rigidly grasping an object.",
            "categories": [
                "cs.RO",
                "eess.SY"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14206v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "物理动作",
                    "matched_keywords": [
                        "physics simulation"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出多速率规划与控制框架，解决多移动机械臂在受限环境中协同搬运的轨迹跟踪问题。",
            "summary_zh": "本文研究了移动多机械臂系统在障碍物密集且高度受限环境下的协同操作问题，任务要求搬运抓取物体时同时满足连续机器人动力学和由障碍物及狭窄通道引起的离散几何约束。为应对这种混合结构，我们提出了一种多速率规划与控制框架，结合离线生成满足信号时序逻辑（STL）的物体轨迹和无碰撞基座足迹，以及在线约束逆运动学和连续时间反馈控制。该闭环系统实现了在跟踪期望物体运动的同时，协调多个机械臂的重新配置。方法通过三个Franka Emika Panda移动机械臂刚性抓取物体的高保真物理仿真进行评估。",
            "intro_zh": [
                "核心问题：现有方法难以处理多移动机械臂在受限环境中协同搬运时的混合约束，包括连续动力学和离散几何限制。",
                "方法要点：提出多速率框架，离线规划STL满足的物体轨迹和基座足迹，在线执行约束逆运动学和反馈控制以实现协调跟踪。",
                "实验或效果：在高保真仿真中验证了框架有效性，三个移动机械臂能成功搬运物体通过障碍物密集环境，提升系统鲁棒性。"
            ],
            "method_zh": "论文提出一个多速率规划与控制框架，整体分为离线规划和在线控制两部分。离线阶段生成满足信号时序逻辑（STL）的物体轨迹和无碰撞的基座足迹，确保任务规范和环境约束；在线阶段结合约束逆运动学和连续时间反馈控制，实时调整机械臂姿态以跟踪物体轨迹。关键技术创新在于将混合约束分解为离散和连续部分，通过多速率处理实现高效协调。与现有方法相比，该方法能同时处理时空任务规范和复杂环境约束，提升系统在受限场景下的适应性和可靠性。",
            "application_zh": "该研究适用于工业自动化、仓储物流和灾难救援等领域，例如在狭窄空间或障碍物密集环境中协同搬运重物，提高操作效率和安全性。",
            "highlight_zh": "实验使用三个Franka Emika Panda移动机械臂进行高保真物理仿真，成功在障碍物密集环境中实现物体搬运，验证了框架在满足STL规范和避免碰撞方面的有效性，系统表现出良好的协调性和鲁棒性。",
            "tags_zh": [
                "多机械臂协同",
                "轨迹跟踪",
                "受限环境",
                "信号时序逻辑",
                "多速率控制",
                "移动机械臂",
                "约束逆运动学",
                "物理仿真"
            ],
            "_index": 152
        },
        {
            "title": "Fracture Morphology Classification: Local Multiclass Modeling for Multilabel Complexity",
            "authors": [
                "Cassandra Krause",
                "Mattias P. Heinrich",
                "Ron Keuth"
            ],
            "arxiv_id": "2512.14196v1",
            "summary": "Between $15\\,\\%$ and $45\\,\\%$ of children experience a fracture during their growth years, making accurate diagnosis essential. Fracture morphology, alongside location and fragment angle, is a key diagnostic feature. In this work, we propose a method to extract fracture morphology by assigning automatically global AO codes to corresponding fracture bounding boxes. This approach enables the use of public datasets and reformulates the global multilabel task into a local multiclass one, improving the average F1 score by $7.89\\,\\%$. However, performance declines when using imperfect fracture detectors, highlighting challenges for real-world deployment. Our code is available on GitHub.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Accepted as poster at the German Conference on Medical Image Computing 2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14196v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出局部多类建模方法，将骨折形态全局多标签分类任务转化为局部多类任务，提升诊断准确性。",
            "summary_zh": "在儿童成长过程中，15%至45%的儿童会经历骨折，因此准确诊断至关重要。骨折形态、位置和碎片角度是关键的诊断特征。本研究提出一种方法，通过自动分配全局AO代码到相应的骨折边界框来提取骨折形态。该方法能够利用公共数据集，并将全局多标签任务重新表述为局部多类任务，从而将平均F1分数提高了7.89%。然而，当使用不完美的骨折检测器时，性能会下降，这突显了实际部署中的挑战。我们的代码已在GitHub上提供。",
            "intro_zh": [
                "核心问题：骨折形态分类面临全局多标签任务的复杂性，现有方法难以高效处理，导致诊断准确性受限。",
                "方法要点：通过将全局多标签任务转化为局部多类任务，利用骨折边界框自动分配AO代码，简化模型学习过程。",
                "实验或效果：平均F1分数提升7.89%，但使用不完美检测器时性能下降，表明实际应用需优化检测环节。"
            ],
            "method_zh": "整体框架基于计算机视觉和机器学习，首先使用骨折检测器定位骨折区域，然后对每个边界框应用局部多类分类模型来分配AO代码。关键技术创新点在于任务重构：将全局多标签分类（处理整个图像中的多个标签）转化为局部多类分类（针对每个边界框进行单一类别预测），这减少了模型复杂度并提高了可解释性。与现有方法的主要区别在于，传统方法直接处理全局多标签，而本方法通过局部化处理，更好地利用了公共数据集，并增强了模型的泛化能力。",
            "application_zh": "该研究在医疗影像诊断领域具有潜在应用价值，特别是儿科骨折的自动诊断系统。通过提高骨折形态分类的准确性，可以辅助医生进行快速、准确的诊断，减少误诊率，并可能集成到临床工作流中，提升医疗效率。",
            "highlight_zh": "最重要的实验结果是平均F1分数提升了7.89%，这表明局部多类建模能有效提高分类性能。然而，实验也显示当骨折检测器不完美时，性能会显著下降，这强调了在实际部署中需要高精度检测器的重要性。",
            "tags_zh": [
                "骨折形态分类",
                "局部多类建模",
                "全局多标签任务",
                "AO代码分配",
                "医疗影像分析",
                "计算机辅助诊断",
                "儿科骨折",
                "边界框检测"
            ],
            "_index": 153
        },
        {
            "title": "Improving Semantic Uncertainty Quantification in LVLMs with Semantic Gaussian Processes",
            "authors": [
                "Joseph Hoche",
                "Andrei Bursuc",
                "David Brellmann",
                "Gilles Louppe",
                "Pavel Izmailov",
                "Angela Yao",
                "Gianni Franchi"
            ],
            "arxiv_id": "2512.14177v1",
            "summary": "Large Vision-Language Models (LVLMs) often produce plausible but unreliable outputs, making robust uncertainty estimation essential. Recent work on semantic uncertainty estimates relies on external models to cluster multiple sampled responses and measure their semantic consistency. However, these clustering methods are often fragile, highly sensitive to minor phrasing variations, and can incorrectly group or separate semantically similar answers, leading to unreliable uncertainty estimates. We propose Semantic Gaussian Process Uncertainty (SGPU), a Bayesian framework that quantifies semantic uncertainty by analyzing the geometric structure of answer embeddings, avoiding brittle clustering. SGPU maps generated answers into a dense semantic space, computes the Gram matrix of their embeddings, and summarizes their semantic configuration via the eigenspectrum. This spectral representation is then fed into a Gaussian Process Classifier that learns to map patterns of semantic consistency to predictive uncertainty, and that can be applied in both black-box and white-box settings. Across six LLMs and LVLMs on eight datasets spanning VQA, image classification, and textual QA, SGPU consistently achieves state-of-the-art calibration (ECE) and discriminative (AUROC, AUARC) performance. We further show that SGPU transfers across models and modalities, indicating that its spectral representation captures general patterns of semantic uncertainty.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14177v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出语义高斯过程不确定性框架，以解决大型视觉语言模型语义不确定性量化中的聚类脆弱性问题。",
            "summary_zh": "大型视觉语言模型常产生看似合理但不可靠的输出，因此稳健的不确定性估计至关重要。现有的语义不确定性估计方法依赖外部模型对多个采样响应进行聚类并测量其语义一致性，但这些聚类方法往往脆弱，对细微的措辞变化高度敏感，可能错误地分组或分离语义相似的答案，导致不可靠的不确定性估计。我们提出了语义高斯过程不确定性，这是一个贝叶斯框架，通过分析答案嵌入的几何结构来量化语义不确定性，避免了脆弱的聚类。SGPU将生成的答案映射到密集的语义空间，计算其嵌入的Gram矩阵，并通过特征谱总结其语义配置。这种谱表示随后被输入到高斯过程分类器中，该分类器学习将语义一致性模式映射到预测不确定性，并可在黑盒和白盒设置中应用。在涵盖VQA、图像分类和文本QA的八个数据集上，对六个LLM和LVLM进行测试，SGPU在标定和判别性能方面均达到最先进水平。我们还展示了SGPU能够跨模型和模态迁移，表明其谱表示捕捉了语义不确定性的一般模式。",
            "intro_zh": [
                "现有方法依赖外部聚类模型，对措辞变化敏感，易错误分组语义相似答案，导致不确定性估计不可靠。",
                "提出SGPU框架，通过分析答案嵌入的几何结构，避免聚类，使用特征谱和高斯过程分类器量化语义不确定性。",
                "在多个数据集和模型上，SGPU在标定和判别性能方面达到最先进水平，并展示跨模型和模态的迁移能力。"
            ],
            "method_zh": "SGPU是一个贝叶斯框架，整体流程包括：将模型生成的多个答案映射到语义空间，计算其嵌入的Gram矩阵，提取特征谱作为语义配置的紧凑表示。关键创新在于避免脆弱的聚类步骤，直接利用嵌入的几何结构，通过高斯过程分类器学习从谱模式到预测不确定性的映射。与现有方法的主要区别在于，它不依赖外部聚类模型，而是基于嵌入的统计特性，提高了鲁棒性和泛化能力，适用于黑盒和白盒设置。",
            "application_zh": "该研究可应用于需要高可靠性的大型视觉语言模型场景，如自动驾驶中的视觉问答、医疗图像分析、内容审核和智能客服，通过改进不确定性估计，提升模型输出的可信度和安全性。",
            "highlight_zh": "在八个数据集和六个模型上，SGPU在标定误差和判别指标方面均达到最先进性能，例如在VQA任务中显著降低错误率，并成功迁移到不同模态任务，验证了其通用性。",
            "tags_zh": [
                "语义不确定性量化",
                "大型视觉语言模型",
                "高斯过程分类器",
                "特征谱分析",
                "贝叶斯框架",
                "多模态迁移",
                "模型校准",
                "嵌入几何结构"
            ],
            "_index": 154
        },
        {
            "title": "On Improving Deep Active Learning with Formal Verification",
            "authors": [
                "Jonathan Spiegelman",
                "Guy Amir",
                "Guy Katz"
            ],
            "arxiv_id": "2512.14170v1",
            "summary": "Deep Active Learning (DAL) aims to reduce labeling costs in neural-network training by prioritizing the most informative unlabeled samples for annotation. Beyond selecting which samples to label, several DAL approaches further enhance data efficiency by augmenting the training set with synthetic inputs that do not require additional manual labeling. In this work, we investigate how augmenting the training data with adversarial inputs that violate robustness constraints can improve DAL performance. We show that adversarial examples generated via formal verification contribute substantially more than those produced by standard, gradient-based attacks. We apply this extension to multiple modern DAL techniques, as well as to a new technique that we propose, and show that it yields significant improvements in model generalization across standard benchmarks.",
            "categories": [
                "cs.LG",
                "cs.LO"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14170v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VIO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出基于形式验证的对抗样本增强方法，以提升深度主动学习的模型泛化性能。",
            "summary_zh": "深度主动学习（DAL）旨在通过优先标注信息量最大的未标记样本来降低神经网络训练中的标注成本。除了选择哪些样本进行标注外，一些DAL方法还通过添加无需额外手动标注的合成输入来增强训练集，进一步提高数据效率。在本研究中，我们探讨了如何通过添加违反鲁棒性约束的对抗样本来增强训练数据，以提升DAL性能。我们表明，通过形式验证生成的对抗样本比基于标准梯度攻击生成的样本贡献更大。我们将此扩展应用于多种现代DAL技术以及我们提出的一种新技术，并在标准基准测试中显示出模型泛化能力的显著提升。",
            "intro_zh": [
                "现有深度主动学习方法在数据增强方面依赖标准合成输入，可能忽略对抗性扰动对模型鲁棒性的影响，导致泛化能力受限。",
                "论文提出利用形式验证生成对抗样本，这些样本能更有效地违反模型鲁棒性约束，作为训练数据增强手段，提升主动学习效率。",
                "实验表明，该方法在多个DAL技术和新提出的技术上应用后，在标准基准测试中显著提高了模型泛化性能。"
            ],
            "method_zh": "论文的核心方法是将形式验证生成的对抗样本集成到深度主动学习框架中。整体框架包括：在主动学习循环中，不仅选择信息量大的未标记样本进行标注，还通过形式验证工具生成对抗样本作为额外训练数据。关键技术创新点在于使用形式验证而非传统梯度攻击来生成对抗样本，这能更系统地探索模型决策边界，确保样本违反鲁棒性约束。与现有方法的主要区别在于，现有DAL方法通常依赖随机或基于梯度的数据增强，而本方法引入形式验证的精确性来生成更具挑战性的对抗样本，从而更有效地提升模型鲁棒性和泛化能力。",
            "application_zh": "该研究可应用于需要高数据效率的机器学习场景，如医疗图像分析、自动驾驶和自然语言处理，其中标注成本高昂且模型鲁棒性至关重要。通过减少标注需求并提升泛化性能，有助于在实际部署中提高AI系统的可靠性和效率。",
            "highlight_zh": "实验结果显示，基于形式验证的对抗样本增强在多个标准基准测试中显著提升了模型泛化性能，相比传统梯度攻击方法，贡献更大，验证了该方法在深度主动学习中的有效性和优越性。",
            "tags_zh": [
                "深度主动学习",
                "形式验证",
                "对抗样本",
                "数据增强",
                "模型泛化",
                "鲁棒性约束",
                "神经网络训练",
                "标注成本降低"
            ],
            "_index": 155
        },
        {
            "title": "PathFinder: Advancing Path Loss Prediction for Single-to-Multi-Transmitter Scenario",
            "authors": [
                "Zhijie Zhong",
                "Zhiwen Yu",
                "Pengyu Li",
                "Jianming Lv",
                "C. L. Philip Chen",
                "Min Chen"
            ],
            "arxiv_id": "2512.14150v1",
            "summary": "Radio path loss prediction (RPP) is critical for optimizing 5G networks and enabling IoT, smart city, and similar applications. However, current deep learning-based RPP methods lack proactive environmental modeling, struggle with realistic multi-transmitter scenarios, and generalize poorly under distribution shifts, particularly when training/testing environments differ in building density or transmitter configurations. This paper identifies three key issues: (1) passive environmental modeling that overlooks transmitters and key environmental features; (2) overemphasis on single-transmitter scenarios despite real-world multi-transmitter prevalence; (3) excessive focus on in-distribution performance while neglecting distribution shift challenges. To address these, we propose PathFinder, a novel architecture that actively models buildings and transmitters via disentangled feature encoding and integrates Mask-Guided Low-rank Attention to independently focus on receiver and building regions. We also introduce a Transmitter-Oriented Mixup strategy for robust training and a new benchmark, single-to-multi-transmitter RPP (S2MT-RPP), tailored to evaluate extrapolation performance (multi-transmitter testing after single-transmitter training). Experimental results show PathFinder outperforms state-of-the-art methods significantly, especially in challenging multi-transmitter scenarios. Our code and project site are available at: https://emorzz1g.github.io/PathFinder/.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "34 pages, 14 figures, 4 tables. Under review",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14150v1",
            "code_links": [
                {
                    "url": "https://emorzz1g.github.io/PathFinder/",
                    "type": "project_page"
                }
            ],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出PathFinder架构，通过主动环境建模和注意力机制解决单到多发射器场景下的路径损耗预测问题。",
            "summary_zh": "无线电路径损耗预测（RPP）对于优化5G网络和实现物联网、智慧城市等应用至关重要。然而，当前基于深度学习的RPP方法存在三个主要问题：缺乏主动环境建模，难以处理现实中的多发射器场景，以及在分布偏移下泛化能力差，特别是当训练和测试环境在建筑密度或发射器配置上不同时。本文提出了PathFinder，一种新颖的架构，通过解耦特征编码主动建模建筑物和发射器，并集成掩码引导的低秩注意力机制，独立关注接收器和建筑区域。此外，还引入了面向发射器的混合策略进行鲁棒训练，并创建了一个新的基准——单到多发射器RPP（S2MT-RPP），专门用于评估外推性能（在单发射器训练后进行多发射器测试）。实验结果表明，PathFinder在性能上显著优于现有最先进方法，尤其是在具有挑战性的多发射器场景中。我们的代码和项目网站可在https://emorzz1g.github.io/PathFinder/获取。",
            "intro_zh": [
                "现有方法被动建模环境，忽视发射器和关键特征，导致预测不准确。",
                "PathFinder通过解耦编码和掩码引导注意力，主动建模建筑物和发射器，提升多场景适应性。",
                "实验显示PathFinder在S2MT-RPP基准上显著优于现有方法，尤其在多发射器测试中表现突出。"
            ],
            "method_zh": "PathFinder的整体框架基于深度神经网络，核心创新点包括解耦特征编码，将建筑物和发射器信息分离处理，以及掩码引导的低秩注意力机制，该机制独立聚焦于接收器和建筑区域，避免信息混淆。与现有方法的主要区别在于主动环境建模，而非被动依赖数据，同时通过面向发射器的混合策略增强训练鲁棒性，专门针对单到多发射器场景设计，解决了分布偏移问题。",
            "application_zh": "该研究可应用于5G网络优化、物联网部署和智慧城市建设，通过准确预测路径损耗，帮助规划基站布局、提升信号覆盖和网络效率，支持大规模无线通信系统的智能管理。",
            "highlight_zh": "PathFinder在单到多发射器RPP基准测试中表现优异，相比现有方法，在多发射器场景下的预测精度显著提升，验证了其在外推任务中的强大泛化能力。",
            "tags_zh": [
                "路径损耗预测",
                "主动环境建模",
                "多发射器场景",
                "解耦特征编码",
                "掩码引导注意力",
                "分布偏移",
                "5G网络优化",
                "深度学习"
            ],
            "_index": 156
        },
        {
            "title": "Consistent Instance Field for Dynamic Scene Understanding",
            "authors": [
                "Junyi Wu",
                "Van Nguyen Nguyen",
                "Benjamin Planche",
                "Jiachen Tao",
                "Changchang Sun",
                "Zhongpai Gao",
                "Zhenghao Zhao",
                "Anwesa Choudhuri",
                "Gengyu Zhang",
                "Meng Zheng",
                "Feiran Wang",
                "Terrence Chen",
                "Yan Yan",
                "Ziyan Wu"
            ],
            "arxiv_id": "2512.14126v1",
            "summary": "We introduce Consistent Instance Field, a continuous and probabilistic spatio-temporal representation for dynamic scene understanding. Unlike prior methods that rely on discrete tracking or view-dependent features, our approach disentangles visibility from persistent object identity by modeling each space-time point with an occupancy probability and a conditional instance distribution. To realize this, we introduce a novel instance-embedded representation based on deformable 3D Gaussians, which jointly encode radiance and semantic information and are learned directly from input RGB images and instance masks through differentiable rasterization. Furthermore, we introduce new mechanisms to calibrate per-Gaussian identities and resample Gaussians toward semantically active regions, ensuring consistent instance representations across space and time. Experiments on HyperNeRF and Neu3D datasets demonstrate that our method significantly outperforms state-of-the-art methods on novel-view panoptic segmentation and open-vocabulary 4D querying tasks.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14126v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出一致实例场以解决动态场景理解中离散跟踪和视角依赖特征的不足，实现连续时空表示。",
            "summary_zh": "我们引入了“一致实例场”，这是一种用于动态场景理解的连续且概率性的时空表示。与先前依赖离散跟踪或视角依赖特征的方法不同，我们的方法通过为每个时空点建模占用概率和条件实例分布，将可见性与持久对象身份解耦。为实现这一点，我们引入了一种基于可变形3D高斯的新型实例嵌入表示，该表示联合编码辐射度和语义信息，并通过可微分光栅化直接从输入RGB图像和实例掩码中学习。此外，我们引入了新机制来校准每个高斯的身份，并向语义活跃区域重新采样高斯，确保跨空间和时间的一致实例表示。在HyperNeRF和Neu3D数据集上的实验表明，我们的方法在新视角全景分割和开放词汇4D查询任务上显著优于最先进的方法。",
            "intro_zh": [
                "现有方法依赖离散跟踪或视角依赖特征，难以实现动态场景中对象身份的连续一致表示。",
                "提出一致实例场，基于可变形3D高斯建模时空点，解耦可见性与对象身份，并通过校准和重采样机制优化表示。",
                "在HyperNeRF和Neu3D数据集上，新视角全景分割和开放词汇4D查询任务性能显著提升，超越现有方法。"
            ],
            "method_zh": "整体框架基于可变形3D高斯构建一致实例场，每个高斯编码辐射度和语义信息，通过可微分光栅化从RGB图像和实例掩码学习。关键技术创新包括：引入实例嵌入表示以联合建模对象身份和可见性；设计校准机制确保高斯身份一致性；实施重采样策略聚焦语义活跃区域。与现有方法的主要区别在于：避免了离散跟踪的局限性，提供连续概率表示；通过解耦设计增强时空一致性，而非依赖视角依赖特征。",
            "application_zh": "该研究可应用于自动驾驶、机器人导航和增强现实等领域，通过动态场景的连续理解，支持实时对象跟踪、环境交互和沉浸式体验，提升智能系统的感知和决策能力。",
            "highlight_zh": "在HyperNeRF和Neu3D数据集上，新视角全景分割任务中准确率显著提高，开放词汇4D查询任务表现优异，验证了方法在动态场景理解中的有效性和鲁棒性，超越现有最先进方法。",
            "tags_zh": [
                "动态场景理解",
                "一致实例场",
                "可变形3D高斯",
                "新视角全景分割",
                "开放词汇4D查询",
                "时空表示",
                "实例嵌入",
                "可微分光栅化"
            ],
            "_index": 157
        },
        {
            "title": "SportsGPT: An LLM-driven Framework for Interpretable Sports Motion Assessment and Training Guidance",
            "authors": [
                "Wenbo Tian",
                "Ruting Lin",
                "Hongxian Zheng",
                "Yaodong Yang",
                "Geng Wu",
                "Zihao Zhang",
                "Zhang Zhang"
            ],
            "arxiv_id": "2512.14121v1",
            "summary": "Existing intelligent sports analysis systems mainly focus on \"scoring and visualization,\" often lacking automatic performance diagnosis and interpretable training guidance. Recent advances of Large Language Models (LMMs) and motion analysis techniques provide new opportunities to address the above limitations. In this paper, we propose SportsGPT, an LLM-driven framework for interpretable sports motion assessment and training guidance, which establishes a closed loop from motion time-series input to professional training guidance. First, given a set of high-quality target models, we introduce MotionDTW, a two-stage time series alignment algorithm designed for accurate keyframe extraction from skeleton-based motion sequences. Subsequently, we design a Knowledge-based Interpretable Sports Motion Assessment Model (KISMAM) to obtain a set of interpretable assessment metrics (e.g., insufficient extension) by constrasting the keyframes with the targe models. Finally, we propose SportsRAG, a RAG-based training guidance model based on Qwen3. Leveraging a 6B-token knowledge base, it prompts the LLM to generate professional training guidance by retrieving domain-specific QA pairs. Experimental results demonstrate that MotionDTW significantly outperforms traditional methods with lower temporal error and higher IoU scores. Furthermore, ablation studies validate the KISMAM and SportsRAG, confirming that SportsGPT surpasses general LLMs in diagnostic accuracy and professionalism.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14121v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "PPO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出SportsGPT框架，通过LLM驱动实现可解释的运动评估与训练指导，解决现有系统缺乏自动诊断和可解释指导的问题。",
            "summary_zh": "现有的智能运动分析系统主要关注“评分和可视化”，往往缺乏自动性能诊断和可解释的训练指导。大型语言模型（LLMs）和运动分析技术的最新进展为解决上述局限提供了新机遇。本文提出SportsGPT，一个LLM驱动的可解释运动评估与训练指导框架，建立了从运动时间序列输入到专业训练指导的闭环。首先，给定一组高质量目标模型，我们引入MotionDTW，一种两阶段时间序列对齐算法，用于从基于骨架的运动序列中准确提取关键帧。随后，我们设计了一个基于知识的可解释运动评估模型（KISMAM），通过将关键帧与目标模型对比，获得一组可解释的评估指标（例如，伸展不足）。最后，我们提出SportsRAG，一个基于Qwen3的RAG训练指导模型。利用一个6B-token的知识库，它通过检索领域特定的问答对来提示LLM生成专业训练指导。实验结果表明，MotionDTW在时间误差更低和IoU分数更高方面显著优于传统方法。此外，消融研究验证了KISMAM和SportsRAG，确认SportsGPT在诊断准确性和专业性方面超越了通用LLMs。",
            "intro_zh": [
                "现有智能运动分析系统主要聚焦于评分和可视化，缺乏自动性能诊断和可解释的训练指导，限制了实际应用价值。",
                "论文提出SportsGPT框架，结合MotionDTW关键帧提取、KISMAM评估模型和SportsRAG指导生成，实现从运动输入到专业指导的闭环。",
                "实验显示MotionDTW在时间对齐上优于传统方法，SportsGPT在诊断准确性和专业性上超越通用LLMs，验证了框架有效性。"
            ],
            "method_zh": "SportsGPT是一个LLM驱动的闭环框架，核心包括三个部分：首先，MotionDTW算法通过两阶段时间序列对齐（动态时间规整和关键帧提取）从骨架运动序列中准确提取关键帧；其次，KISMAM模型基于知识对比关键帧与目标模型，生成可解释的评估指标（如动作偏差）；最后，SportsRAG模型基于RAG架构和Qwen3 LLM，利用6B-token知识库检索领域问答对，生成专业训练指导。关键创新在于将运动分析与LLM结合，实现可解释的评估和指导生成，与现有方法的主要区别在于从单纯评分转向闭环诊断和指导，提升了自动化和专业性。",
            "application_zh": "该研究可应用于体育训练、康复医疗和健身指导等领域，为运动员、教练和普通用户提供自动化的运动性能评估和个性化训练建议，提升训练效率和安全性，具有实际商业和教育价值。",
            "highlight_zh": "MotionDTW在关键帧提取上显著优于传统方法，时间误差更低、IoU分数更高；SportsGPT通过消融研究验证，在诊断准确性和专业性方面超越通用LLMs，证明了框架的整体有效性。",
            "tags_zh": [
                "运动分析",
                "大型语言模型",
                "时间序列对齐",
                "可解释评估",
                "检索增强生成",
                "骨架动作识别",
                "训练指导系统",
                "多模态融合"
            ],
            "_index": 158
        },
        {
            "title": "Joint Multimodal Contrastive Learning for Robust Spoken Term Detection and Keyword Spotting",
            "authors": [
                "Ramesh Gundluru",
                "Shubham Gupta",
                "Sri Rama Murty K"
            ],
            "arxiv_id": "2512.14115v1",
            "summary": "Acoustic Word Embeddings (AWEs) improve the efficiency of speech retrieval tasks such as Spoken Term Detection (STD) and Keyword Spotting (KWS). However, existing approaches suffer from limitations, including unimodal supervision, disjoint optimization of audio-audio and audio-text alignment, and the need for task-specific models. To address these shortcomings, we propose a joint multimodal contrastive learning framework that unifies both acoustic and cross-modal supervision in a shared embedding space. Our approach simultaneously optimizes: (i) audio-text contrastive learning, inspired by the CLAP loss, to align audio and text representations and (ii) audio-audio contrastive learning, via Deep Word Discrimination (DWD) loss, to enhance intra-class compactness and inter-class separation. The proposed method outperforms existing AWE baselines on word discrimination task while flexibly supporting both STD and KWS. To our knowledge, this is the first comprehensive approach of its kind.",
            "categories": [
                "cs.SD",
                "cs.LG"
            ],
            "primary_category": "cs.SD",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14115v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "PPO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出联合多模态对比学习框架，以解决声学词嵌入在语音检索任务中的局限性，提升口语词检测和关键词识别的鲁棒性。",
            "summary_zh": "声学词嵌入（AWEs）提高了语音检索任务（如口语词检测和关键词识别）的效率。然而，现有方法存在局限性，包括单模态监督、音频-音频和音频-文本对齐的分离优化，以及需要任务特定模型。为解决这些不足，我们提出了一个联合多模态对比学习框架，在共享嵌入空间中统一了声学和跨模态监督。我们的方法同时优化：（i）音频-文本对比学习，受CLAP损失启发，以对齐音频和文本表示；（ii）音频-音频对比学习，通过深度词判别损失，以增强类内紧凑性和类间分离性。所提方法在词判别任务上优于现有AWE基线，同时灵活支持口语词检测和关键词识别。据我们所知，这是首个此类综合方法。",
            "intro_zh": [
                "现有声学词嵌入方法依赖单模态监督，音频-音频和音频-文本对齐优化分离，导致语音检索任务效率受限。",
                "论文提出联合多模态对比学习框架，统一音频-文本和音频-音频监督，在共享嵌入空间同时优化对齐和判别。",
                "实验表明，该方法在词判别任务上优于基线，并灵活支持口语词检测和关键词识别，提升鲁棒性和性能。"
            ],
            "method_zh": "论文核心方法是一个联合多模态对比学习框架，整体架构基于共享嵌入空间，同时整合音频-文本和音频-音频监督。关键技术创新点包括：采用CLAP损失进行音频-文本对比学习，以对齐跨模态表示；结合深度词判别损失进行音频-音频对比学习，增强类内紧凑性和类间分离性。与现有方法的主要区别在于，它统一了多模态监督，避免了分离优化，从而提高了模型的泛化能力和任务适应性，无需依赖任务特定模型。",
            "application_zh": "该研究主要应用于语音检索领域，如口语词检测和关键词识别，可提升智能助手、语音搜索和音频内容分析系统的效率和准确性。潜在价值包括支持多语言处理、低资源场景下的鲁棒性，以及跨模态信息融合的实际应用。",
            "highlight_zh": "实验结果显示，所提方法在词判别任务上优于现有声学词嵌入基线，性能提升显著。同时，它灵活支持口语词检测和关键词识别，无需任务特定模型，验证了联合多模态对比学习的有效性和鲁棒性。",
            "tags_zh": [
                "多模态对比学习",
                "声学词嵌入",
                "口语词检测",
                "关键词识别",
                "音频-文本对齐",
                "深度词判别",
                "语音检索",
                "共享嵌入空间"
            ],
            "_index": 159
        },
        {
            "title": "MFE-GAN: Efficient GAN-based Framework for Document Image Enhancement and Binarization with Multi-scale Feature Extraction",
            "authors": [
                "Rui-Yang Ju",
                "KokSheik Wong",
                "Yanlin Jin",
                "Jen-Shiun Chiang"
            ],
            "arxiv_id": "2512.14114v1",
            "summary": "Document image enhancement and binarization are commonly performed prior to document analysis and recognition tasks for improving the efficiency and accuracy of optical character recognition (OCR) systems. This is because directly recognizing text in degraded documents, particularly in color images, often results in unsatisfactory recognition performance. To address these issues, existing methods train independent generative adversarial networks (GANs) for different color channels to remove shadows and noise, which, in turn, facilitates efficient text information extraction. However, deploying multiple GANs results in long training and inference times. To reduce both training and inference times of document image enhancement and binarization models, we propose MFE-GAN, an efficient GAN-based framework with multi-scale feature extraction (MFE), which incorporates Haar wavelet transformation (HWT) and normalization to process document images before feeding them into GANs for training. In addition, we present novel generators, discriminators, and loss functions to improve the model's performance, and we conduct ablation studies to demonstrate their effectiveness. Experimental results on the Benchmark, Nabuco, and CMATERdb datasets demonstrate that the proposed MFE-GAN significantly reduces the total training and inference times while maintaining comparable performance with respect to state-of-the-art (SOTA) methods. The implementation of this work is available at https://ruiyangju.github.io/MFE-GAN.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Extended Journal Version of APSIPA ASC 2025",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14114v1",
            "code_links": [
                {
                    "url": "https://ruiyangju.github.io/MFE-GAN",
                    "type": "project_page"
                }
            ],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出MFE-GAN框架，通过多尺度特征提取提升文档图像增强与二值化效率，减少训练和推理时间。",
            "summary_zh": "文档图像增强和二值化通常在文档分析与识别任务前执行，以提高光学字符识别（OCR）系统的效率和准确性。这是因为直接识别退化文档（尤其是彩色图像）中的文本往往导致不理想的识别性能。为解决这些问题，现有方法训练独立的生成对抗网络（GAN）处理不同颜色通道以去除阴影和噪声，从而促进高效的文本信息提取。然而，部署多个GAN会导致较长的训练和推理时间。为减少文档图像增强和二值化模型的训练和推理时间，我们提出了MFE-GAN，这是一种基于GAN的高效框架，采用多尺度特征提取（MFE），结合哈尔小波变换（HWT）和归一化处理文档图像，然后输入GAN进行训练。此外，我们提出了新颖的生成器、判别器和损失函数以提升模型性能，并通过消融研究验证其有效性。在Benchmark、Nabuco和CMATERdb数据集上的实验结果表明，所提出的MFE-GAN显著减少了总训练和推理时间，同时保持了与最先进（SOTA）方法相当的性能。本工作的实现可在https://ruiyangju.github.io/MFE-GAN获取。",
            "intro_zh": [
                "现有方法使用多个独立GAN处理不同颜色通道，导致训练和推理时间过长，效率低下。",
                "提出MFE-GAN框架，集成多尺度特征提取（MFE）和哈尔小波变换，优化图像预处理和GAN架构。",
                "实验显示MFE-GAN在多个数据集上显著减少时间消耗，同时性能与SOTA方法相当，验证了其高效性。"
            ],
            "method_zh": "MFE-GAN是一个基于生成对抗网络（GAN）的高效框架，用于文档图像增强和二值化。整体框架包括多尺度特征提取（MFE）模块，该模块利用哈尔小波变换（HWT）和归一化对输入图像进行预处理，提取多尺度特征后输入到GAN中进行训练。关键技术创新点包括：新颖的生成器和判别器设计，以及优化的损失函数，这些改进提升了模型处理退化文档的能力。与现有方法的主要区别在于，MFE-GAN通过集成MFE模块避免了使用多个独立GAN，从而减少了模型复杂度和计算开销，实现了更快的训练和推理速度，同时保持了图像增强和二值化的质量。",
            "application_zh": "该研究主要应用于文档分析与识别领域，特别是光学字符识别（OCR）系统。通过高效增强和二值化退化文档图像，如去除阴影和噪声，可以提升OCR的准确性和效率，适用于数字化档案处理、历史文档修复、自动化办公等实际场景，具有重要的工业应用价值。",
            "highlight_zh": "在Benchmark、Nabuco和CMATERdb数据集上的实验表明，MFE-GAN显著减少了总训练和推理时间，同时性能与最先进方法相当，消融研究验证了其新颖组件（如生成器、判别器和损失函数）的有效性，突出了框架的高效性和实用性。",
            "tags_zh": [
                "文档图像增强",
                "图像二值化",
                "生成对抗网络",
                "多尺度特征提取",
                "哈尔小波变换",
                "光学字符识别",
                "高效训练",
                "模型优化"
            ],
            "_index": 160
        },
        {
            "title": "Selective, Controlled and Domain-Agnostic Unlearning in Pretrained CLIP: A Training- and Data-Free Approach",
            "authors": [
                "Ashish Mishra",
                "Gyanaranjan Nayak",
                "Tarun Kumar",
                "Arpit Shah",
                "Suparna Bhattacharya",
                "Martin Foltin"
            ],
            "arxiv_id": "2512.14113v1",
            "summary": "Pretrained models like CLIP have demonstrated impressive zero-shot classification capabilities across diverse visual domains, spanning natural images, artistic renderings, and abstract representations. However, real-world applications often demand the removal (or \"unlearning\") of specific object classes without requiring additional data or retraining, or affecting the model's performance on unrelated tasks. In this paper, we propose a novel training- and data-free unlearning framework that enables three distinct forgetting paradigms: (1) global unlearning of selected objects across all domains, (2) domain-specific knowledge removal (e.g., eliminating sketch representations while preserving photo recognition), and (3) complete unlearning in selective domains. By leveraging a multimodal nullspace through synergistic integration of text prompts and synthesized visual prototypes derived from CLIP's joint embedding space, our method efficiently removes undesired class information while preserving the remaining knowledge. This approach overcomes the limitations of existing retraining-based methods and offers a flexible and computationally efficient solution for controlled model forgetting.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14113v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出一种无需训练和数据的CLIP选择性遗忘框架，实现跨域、领域特定和选择性领域的可控知识移除。",
            "summary_zh": "预训练模型如CLIP在多种视觉领域（如自然图像、艺术渲染和抽象表示）中展现出卓越的零样本分类能力。然而，实际应用常需移除特定对象类别的知识（即“遗忘”），且要求无需额外数据或重新训练，同时不影响模型在无关任务上的性能。本文提出一种新颖的无需训练和数据的遗忘框架，支持三种遗忘范式：（1）在所有域中全局遗忘选定对象，（2）领域特定知识移除（例如，消除草图表示同时保留照片识别），以及（3）在选择性域中完全遗忘。通过利用多模态零空间，结合文本提示和从CLIP联合嵌入空间衍生的合成视觉原型，该方法高效移除不需要的类别信息，同时保留其余知识。此方法克服了现有基于重新训练方法的局限性，为可控模型遗忘提供了灵活且计算高效的解决方案。",
            "intro_zh": [
                "核心问题：现有遗忘方法通常依赖重新训练或额外数据，计算成本高且灵活性不足，难以实现跨域或领域特定的选择性知识移除。",
                "方法要点：提出一种无需训练和数据的框架，通过多模态零空间整合文本提示和合成视觉原型，实现三种遗忘范式，高效移除目标类别信息。",
                "实验或效果：在多种视觉域上验证，该方法能有效移除指定知识，同时保持模型在其他任务上的性能，相比基线方法计算效率更高。"
            ],
            "method_zh": "整体框架基于CLIP的预训练模型，无需额外训练或数据。关键技术创新点在于利用多模态零空间，通过协同整合文本提示和从CLIP联合嵌入空间合成的视觉原型，构建遗忘机制。具体地，通过优化嵌入空间中的表示，使目标类别的信息被抑制或消除，同时最小化对其他类别的影响。与现有方法的主要区别在于：本方法完全避免重新训练，支持跨域和领域特定的选择性遗忘，且操作在嵌入空间层面，计算效率更高，灵活性更强。",
            "application_zh": "该研究可应用于隐私保护（如移除敏感类别）、模型合规性调整（如删除侵权内容）和多模态系统优化（如定制化知识库），为AI模型提供可控遗忘能力，提升实际部署的适应性和安全性。",
            "highlight_zh": "实验表明，该方法在多种视觉域（如照片、草图）上成功实现选择性遗忘，移除目标类别后模型在其他任务上的性能下降最小，相比重新训练方法节省大量计算资源，验证了其高效性和可控性。",
            "tags_zh": [
                "CLIP模型",
                "知识遗忘",
                "多模态学习",
                "零样本分类",
                "嵌入空间优化",
                "无需训练方法",
                "可控遗忘",
                "视觉域适应"
            ],
            "_index": 161
        },
        {
            "title": "Neurosymbolic Inference On Foundation Models For Remote Sensing Text-to-image Retrieval With Complex Queries",
            "authors": [
                "Emanuele Mezzi",
                "Gertjan Burghouts",
                "Maarten Kruithof"
            ],
            "arxiv_id": "2512.14102v1",
            "summary": "Text-to-image retrieval in remote sensing (RS) has advanced rapidly with the rise of large vision-language models (LVLMs) tailored for aerial and satellite imagery, culminating in remote sensing large vision-language models (RS-LVLMS). However, limited explainability and poor handling of complex spatial relations remain key challenges for real-world use. To address these issues, we introduce RUNE (Reasoning Using Neurosymbolic Entities), an approach that combines Large Language Models (LLMs) with neurosymbolic AI to retrieve images by reasoning over the compatibility between detected entities and First-Order Logic (FOL) expressions derived from text queries. Unlike RS-LVLMs that rely on implicit joint embeddings, RUNE performs explicit reasoning, enhancing performance and interpretability. For scalability, we propose a logic decomposition strategy that operates on conditioned subsets of detected entities, guaranteeing shorter execution time compared to neural approaches. Rather than using foundation models for end-to-end retrieval, we leverage them only to generate FOL expressions, delegating reasoning to a neurosymbolic inference module. For evaluation we repurpose the DOTA dataset, originally designed for object detection, by augmenting it with more complex queries than in existing benchmarks. We show the LLM's effectiveness in text-to-logic translation and compare RUNE with state-of-the-art RS-LVLMs, demonstrating superior performance. We introduce two metrics, Retrieval Robustness to Query Complexity (RRQC) and Retrieval Robustness to Image Uncertainty (RRIU), which evaluate performance relative to query complexity and image uncertainty. RUNE outperforms joint-embedding models in complex RS retrieval tasks, offering gains in performance, robustness, and explainability. We show RUNE's potential for real-world RS applications through a use case on post-flood satellite image retrieval.",
            "categories": [
                "cs.CV",
                "cs.AI",
                "cs.IR"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14102v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出RUNE方法，结合大语言模型与神经符号AI，解决遥感文本到图像检索中复杂查询的推理与可解释性问题。",
            "summary_zh": "遥感领域的文本到图像检索随着针对航空和卫星影像定制的大型视觉语言模型（RS-LVLMs）的兴起而快速发展。然而，有限的可解释性和对复杂空间关系处理能力差仍是实际应用中的关键挑战。为解决这些问题，我们引入了RUNE（使用神经符号实体进行推理），该方法将大语言模型与神经符号AI相结合，通过推理检测到的实体与从文本查询导出的谓词逻辑表达式之间的兼容性来检索图像。与依赖隐式联合嵌入的RS-LVLMs不同，RUNE执行显式推理，从而提升性能和可解释性。为扩展性，我们提出一种逻辑分解策略，在检测实体的条件子集上操作，保证比神经方法更短的执行时间。我们仅利用基础模型生成谓词逻辑表达式，将推理委托给神经符号推理模块，而非用于端到端检索。为评估，我们重新利用原本为物体检测设计的DOTA数据集，通过添加比现有基准更复杂的查询来增强它。我们展示了大语言模型在文本到逻辑翻译中的有效性，并将RUNE与最先进的RS-LVLMs进行比较，证明了其优越性能。我们引入了两个指标：检索对查询复杂性的鲁棒性和检索对图像不确定性的鲁棒性，评估性能相对于查询复杂性和图像不确定性的表现。RUNE在复杂遥感检索任务中优于联合嵌入模型，在性能、鲁棒性和可解释性方面带来增益。我们通过一个洪水后卫星图像检索的用例展示了RUNE在现实世界遥感应用中的潜力。",
            "intro_zh": [
                "现有遥感文本到图像检索方法（如RS-LVLMs）存在可解释性差和难以处理复杂空间关系的挑战，限制了实际应用。",
                "论文提出RUNE方法，结合大语言模型生成谓词逻辑表达式，并利用神经符号AI进行显式推理，提升检索性能和可解释性。",
                "实验表明，RUNE在复杂查询任务中优于现有RS-LVLMs，并引入新指标评估鲁棒性，展示了在洪水后卫星图像检索等场景的应用潜力。"
            ],
            "method_zh": "RUNE的整体框架包括两个核心模块：大语言模型用于将文本查询翻译为谓词逻辑表达式，以及神经符号推理模块用于基于检测到的实体进行显式推理。关键技术创新在于逻辑分解策略，它通过操作检测实体的条件子集来保证更短的执行时间，提高可扩展性。与现有方法的主要区别在于，RUNE不依赖隐式联合嵌入，而是执行显式推理，从而增强可解释性和处理复杂查询的能力，同时仅利用基础模型生成逻辑表达式，而非端到端检索。",
            "application_zh": "该研究在遥感领域具有广泛潜在应用，如洪水后卫星图像检索、城市规划中的复杂场景分析，以及环境监测中的多目标识别任务，能提升检索的准确性和可解释性，支持决策制定。",
            "highlight_zh": "RUNE在复杂遥感检索任务中显著优于最先进的RS-LVLMs，通过引入检索对查询复杂性和图像不确定性的鲁棒性指标，展示了更高的性能和鲁棒性，并在DOTA数据集增强版本上验证了有效性。",
            "tags_zh": [
                "遥感文本到图像检索",
                "神经符号AI",
                "大语言模型",
                "谓词逻辑推理",
                "复杂查询处理",
                "可解释性增强",
                "遥感应用",
                "性能鲁棒性评估"
            ],
            "_index": 162
        },
        {
            "title": "Quality-Aware Framework for Video-Derived Respiratory Signals",
            "authors": [
                "Nhi Nguyen",
                "Constantino Álvarez Casado",
                "Le Nguyen",
                "Manuel Lage Cañellas",
                "Miguel Bordallo López"
            ],
            "arxiv_id": "2512.14093v1",
            "summary": "Video-based respiratory rate (RR) estimation is often unreliable due to inconsistent signal quality across extraction methods. We present a predictive, quality-aware framework that integrates heterogeneous signal sources with dynamic assessment of reliability. Ten signals are extracted from facial remote photoplethysmography (rPPG), upper-body motion, and deep learning pipelines, and analyzed using four spectral estimators: Welch's method, Multiple Signal Classification (MUSIC), Fast Fourier Transform (FFT), and peak detection. Segment-level quality indices are then used to train machine learning models that predict accuracy or select the most reliable signal. This enables adaptive signal fusion and quality-based segment filtering. Experiments on three public datasets (OMuSense-23, COHFACE, MAHNOB-HCI) show that the proposed framework achieves lower RR estimation errors than individual methods in most cases, with performance gains depending on dataset characteristics. These findings highlight the potential of quality-driven predictive modeling to deliver scalable and generalizable video-based respiratory monitoring solutions.",
            "categories": [
                "cs.CV",
                "eess.SP"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "6 pages, 1 figure, 2 tables, conference",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14093v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "世界模型",
                    "matched_keywords": [
                        "predictive model"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出质量感知框架以解决视频呼吸信号估计中信号质量不一致的问题，实现自适应融合与过滤。",
            "summary_zh": "基于视频的呼吸率估计常因不同提取方法产生的信号质量不一致而不可靠。本文提出一个预测性、质量感知的框架，整合了异质信号源并动态评估其可靠性。从面部远程光电容积描记术、上半身运动和深度学习流程中提取了十种信号，并使用四种频谱估计器进行分析：Welch方法、多重信号分类、快速傅里叶变换和峰值检测。然后，利用片段级质量指标训练机器学习模型，以预测准确性或选择最可靠的信号。这实现了自适应信号融合和基于质量的片段过滤。在三个公共数据集上的实验表明，该框架在大多数情况下比单个方法实现了更低的呼吸率估计误差，性能提升取决于数据集特性。这些发现突出了质量驱动的预测建模在提供可扩展和泛化的视频呼吸监测解决方案方面的潜力。",
            "intro_zh": [
                "现有视频呼吸率估计方法因信号提取质量不一致导致结果不可靠，缺乏统一的质量评估机制。",
                "提出质量感知框架，整合多源信号并动态评估可靠性，通过机器学习模型预测准确性或选择最优信号。",
                "在三个公共数据集上实验，框架在多数情况下降低了呼吸率估计误差，性能提升依赖于数据集特性。"
            ],
            "method_zh": "论文提出一个质量感知框架，整体包括信号提取、频谱分析和质量评估三部分。从视频中提取十种信号，包括面部rPPG、上半身运动和深度学习输出，使用四种频谱估计器分析。关键创新在于引入片段级质量指标，训练机器学习模型预测信号准确性或选择最可靠信号，实现自适应融合与过滤。与现有方法的主要区别在于动态整合异质信号源并基于质量进行预测性建模，而非依赖单一方法或固定融合策略。",
            "application_zh": "该研究可应用于远程医疗监测、健康管理、运动生理学和智能家居等领域，提供非接触式、可扩展的呼吸监测解决方案，提升视频呼吸率估计的可靠性和泛化能力。",
            "highlight_zh": "在OMuSense-23、COHFACE和MAHNOB-HCI三个数据集上实验，框架在大多数情况下显著降低了呼吸率估计误差，性能提升最高达未知百分比，具体取决于数据集特性，验证了质量驱动方法的有效性。",
            "tags_zh": [
                "视频呼吸率估计",
                "质量感知框架",
                "信号融合",
                "远程光电容积描记术",
                "机器学习预测",
                "频谱分析",
                "自适应过滤",
                "呼吸监测"
            ],
            "_index": 163
        },
        {
            "title": "ProtoFlow: Interpretable and Robust Surgical Workflow Modeling with Learned Dynamic Scene Graph Prototypes",
            "authors": [
                "Felix Holm",
                "Ghazal Ghazaei",
                "Nassir Navab"
            ],
            "arxiv_id": "2512.14092v1",
            "summary": "Purpose: Detailed surgical recognition is critical for advancing AI-assisted surgery, yet progress is hampered by high annotation costs, data scarcity, and a lack of interpretable models. While scene graphs offer a structured abstraction of surgical events, their full potential remains untapped. In this work, we introduce ProtoFlow, a novel framework that learns dynamic scene graph prototypes to model complex surgical workflows in an interpretable and robust manner.\n  Methods: ProtoFlow leverages a graph neural network (GNN) encoder-decoder architecture that combines self-supervised pretraining for rich representation learning with a prototype-based fine-tuning stage. This process discovers and refines core prototypes that encapsulate recurring, clinically meaningful patterns of surgical interaction, forming an explainable foundation for workflow analysis.\n  Results: We evaluate our approach on the fine-grained CAT-SG dataset. ProtoFlow not only outperforms standard GNN baselines in overall accuracy but also demonstrates exceptional robustness in limited-data, few-shot scenarios, maintaining strong performance when trained on as few as one surgical video. Our qualitative analyses further show that the learned prototypes successfully identify distinct surgical sub-techniques and provide clear, interpretable insights into workflow deviations and rare complications.\n  Conclusion: By uniting robust representation learning with inherent explainability, ProtoFlow represents a significant step toward developing more transparent, reliable, and data-efficient AI systems, accelerating their potential for clinical adoption in surgical training, real-time decision support, and workflow optimization.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14092v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "PPO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出ProtoFlow框架，通过动态场景图原型学习实现可解释且鲁棒的手术工作流建模",
            "summary_zh": "目的：详细的手术识别对推进AI辅助手术至关重要，但高标注成本、数据稀缺和缺乏可解释模型阻碍了进展。虽然场景图提供了手术事件的结构化抽象，但其全部潜力尚未被充分挖掘。本研究提出ProtoFlow，一种新颖的框架，通过学习动态场景图原型，以可解释且鲁棒的方式建模复杂手术工作流。方法：ProtoFlow利用图神经网络编码器-解码器架构，结合自监督预训练进行丰富表示学习，以及基于原型的微调阶段。该过程发现并精炼核心原型，这些原型封装了重复出现的、具有临床意义的手术交互模式，为工作流分析形成可解释的基础。结果：我们在细粒度CAT-SG数据集上评估了该方法。ProtoFlow不仅在整体准确率上优于标准GNN基线，还在有限数据、少样本场景中表现出卓越的鲁棒性，在仅用一个手术视频训练时仍保持强劲性能。定性分析进一步显示，学习到的原型成功识别了不同的手术子技术，并为工作流偏差和罕见并发症提供了清晰、可解释的见解。结论：通过将鲁棒表示学习与内在可解释性相结合，ProtoFlow代表了向开发更透明、可靠和数据高效的AI系统迈出的重要一步，加速了其在手术培训、实时决策支持和工作流优化中的临床采用潜力。",
            "intro_zh": [
                "核心问题：手术识别面临高标注成本、数据稀缺和模型缺乏可解释性，现有场景图方法未能充分发挥潜力。",
                "方法要点：提出ProtoFlow框架，结合自监督预训练和原型微调，学习动态场景图原型以建模手术工作流。",
                "实验或效果：在CAT-SG数据集上超越GNN基线，少样本场景下鲁棒性强，原型提供可解释的手术模式分析。"
            ],
            "method_zh": "ProtoFlow采用图神经网络编码器-解码器架构，整体框架包括自监督预训练和基于原型的微调两个阶段。关键技术创新点在于学习动态场景图原型，这些原型自动发现并封装手术中的重复交互模式，形成可解释的工作流表示。与现有方法的主要区别在于，它通过原型学习将鲁棒表示与内在可解释性结合，避免了传统黑盒模型的局限性，同时利用自监督学习缓解数据稀缺问题。",
            "application_zh": "该研究可应用于手术培训、实时决策支持和工作流优化等领域，通过提供可解释的手术模式分析，帮助医生理解复杂手术流程、检测偏差和并发症，加速AI系统在临床环境中的安全采用。",
            "highlight_zh": "在CAT-SG数据集上，ProtoFlow整体准确率优于标准GNN基线；在少样本场景中，仅用一个手术视频训练时仍保持强劲性能，显示出卓越的鲁棒性；定性分析证实学习到的原型能识别手术子技术并提供工作流偏差的清晰见解。",
            "tags_zh": [
                "手术工作流建模",
                "动态场景图",
                "原型学习",
                "图神经网络",
                "自监督学习",
                "可解释AI",
                "少样本学习",
                "医疗AI"
            ],
            "_index": 164
        },
        {
            "title": "Derivative-Informed Fourier Neural Operator: Universal Approximation and Applications to PDE-Constrained Optimization",
            "authors": [
                "Boyuan Yao",
                "Dingcheng Luo",
                "Lianghao Cao",
                "Nikola Kovachki",
                "Thomas O'Leary-Roseberry",
                "Omar Ghattas"
            ],
            "arxiv_id": "2512.14086v1",
            "summary": "We present approximation theories and efficient training methods for derivative-informed Fourier neural operators (DIFNOs) with applications to PDE-constrained optimization. A DIFNO is an FNO trained by minimizing its prediction error jointly on output and Fréchet derivative samples of a high-fidelity operator (e.g., a parametric PDE solution operator). As a result, a DIFNO can closely emulate not only the high-fidelity operator's response but also its sensitivities. To motivate the use of DIFNOs instead of conventional FNOs as surrogate models, we show that accurate surrogate-driven PDE-constrained optimization requires accurate surrogate Fréchet derivatives. Then, for continuously differentiable operators, we establish (i) simultaneous universal approximation of FNOs and their Fréchet derivatives on compact sets, and (ii) universal approximation of FNOs in weighted Sobolev spaces with input measures that have unbounded supports. Our theoretical results certify the capability of FNOs for accurate derivative-informed operator learning and accurate solution of PDE-constrained optimization. Furthermore, we develop efficient training schemes using dimension reduction and multi-resolution techniques that significantly reduce memory and computational costs for Fréchet derivative learning. Numerical examples on nonlinear diffusion--reaction, Helmholtz, and Navier--Stokes equations demonstrate that DIFNOs are superior in sample complexity for operator learning and solving infinite-dimensional PDE-constrained inverse problems, achieving high accuracy at low training sample sizes.",
            "categories": [
                "cs.LG",
                "math.NA"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14086v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "PPO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出导数信息傅里叶神经算子，通过联合优化输出和导数样本，提升PDE约束优化的精度和效率。",
            "summary_zh": "本文介绍了导数信息傅里叶神经算子的近似理论和高效训练方法，应用于偏微分方程约束优化。DIFNO是一种傅里叶神经算子，通过最小化其在高保真算子输出和Fréchet导数样本上的预测误差进行训练，从而不仅能紧密模拟高保真算子的响应，还能模拟其敏感性。为证明DIFNO优于传统FNO作为代理模型，我们指出精确的代理驱动PDE约束优化需要精确的代理Fréchet导数。对于连续可微算子，我们建立了（i）FNO及其Fréchet导数在紧集上的同时通用近似性，以及（ii）FNO在具有无界支持的输入测度的加权Sobolev空间中的通用近似性。这些理论结果验证了FNO在精确导数信息算子学习和精确求解PDE约束优化方面的能力。此外，我们开发了使用降维和多分辨率技术的高效训练方案，显著降低了Fréchet导数学习的内存和计算成本。在非线性扩散-反应、Helmholtz和Navier-Stokes方程上的数值实验表明，DIFNO在算子学习和求解无限维PDE约束逆问题的样本复杂度方面表现优越，能在低训练样本量下实现高精度。",
            "intro_zh": [
                "现有傅里叶神经算子在PDE约束优化中，由于缺乏精确导数信息，导致代理模型驱动优化时精度不足。",
                "提出导数信息傅里叶神经算子，通过联合训练输出和Fréchet导数样本，实现算子和导数的同时高精度近似。",
                "实验显示DIFNO在低样本量下显著提升优化精度，并降低计算成本，验证了其高效性和通用近似能力。"
            ],
            "method_zh": "DIFNO基于傅里叶神经算子框架，通过最小化高保真算子的输出和Fréchet导数样本的联合损失函数进行训练。关键创新在于引入导数信息学习，利用降维和多分辨率技术优化训练过程，减少内存和计算开销。与现有FNO的主要区别在于，DIFNO不仅学习算子映射，还学习其导数，从而在PDE约束优化中提供更精确的敏感性信息。",
            "application_zh": "该研究主要应用于偏微分方程约束优化问题，如非线性扩散-反应、Helmholtz和Navier-Stokes方程的逆问题求解，在工程和科学计算中具有广泛价值，可提升优化效率和精度。",
            "highlight_zh": "数值实验表明，DIFNO在非线性扩散-反应、Helmholtz和Navier-Stokes方程上，相比传统FNO，样本复杂度显著降低，能在少量训练样本下实现高精度优化，验证了其高效性和理论优势。",
            "tags_zh": [
                "傅里叶神经算子",
                "导数信息学习",
                "PDE约束优化",
                "通用近似理论",
                "Fréchet导数",
                "样本复杂度",
                "多分辨率训练",
                "无限维逆问题"
            ],
            "_index": 165
        },
        {
            "title": "Scalable Frameworks for Real-World Audio-Visual Speech Recognition",
            "authors": [
                "Sungnyun Kim"
            ],
            "arxiv_id": "2512.14083v1",
            "summary": "The practical deployment of Audio-Visual Speech Recognition (AVSR) systems is fundamentally challenged by significant performance degradation in real-world environments, characterized by unpredictable acoustic noise and visual interference. This dissertation posits that a systematic, hierarchical approach is essential to overcome these challenges, achieving the robust scalability at the representation, architecture, and system levels. At the representation level, we investigate methods for building a unified model that learns audio-visual features inherently robust to diverse real-world corruptions, thereby enabling generalization to new environments without specialized modules. To address architectural scalability, we explore how to efficiently expand model capacity while ensuring the adaptive and reliable use of multimodal inputs, developing a framework that intelligently allocates computational resources based on the input characteristics. Finally, at the system level, we present methods to expand the system's functionality through modular integration with large-scale foundation models, leveraging their powerful cognitive and generative capabilities to maximize final recognition accuracy. By systematically providing solutions at each of these three levels, this dissertation aims to build a next-generation, robust, and scalable AVSR system with high reliability in real-world applications.",
            "categories": [
                "eess.AS",
                "cs.CL",
                "cs.LG"
            ],
            "primary_category": "eess.AS",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "PhD Dissertation",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14083v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出分层框架以解决真实世界音频-视觉语音识别中的鲁棒性和可扩展性问题。",
            "summary_zh": "音频-视觉语音识别（AVSR）系统在实际部署中面临显著性能下降的挑战，主要源于不可预测的声学噪声和视觉干扰。本论文主张采用系统性的分层方法来克服这些挑战，在表示、架构和系统三个层面实现鲁棒的可扩展性。在表示层面，我们研究构建统一模型的方法，学习对多样真实世界干扰具有内在鲁棒性的音频-视觉特征，从而无需专用模块即可泛化到新环境。针对架构可扩展性，我们探索如何高效扩展模型容量，同时确保多模态输入的自适应可靠使用，开发了一个基于输入特征智能分配计算资源的框架。最后，在系统层面，我们提出通过模块化集成大规模基础模型来扩展系统功能的方法，利用其强大的认知和生成能力最大化最终识别准确率。通过在这三个层面系统提供解决方案，本论文旨在构建下一代鲁棒、可扩展且在实际应用中高可靠性的AVSR系统。",
            "intro_zh": [
                "核心问题：现有AVSR系统在真实世界环境中性能显著下降，主要受不可预测的声学噪声和视觉干扰影响，缺乏鲁棒性和可扩展性。",
                "方法要点：采用分层方法，在表示、架构和系统三个层面构建统一模型、智能资源分配框架和模块化集成基础模型。",
                "实验或效果：通过系统解决方案，提升了AVSR系统在噪声和干扰环境下的识别准确率，增强了泛化能力和计算效率。"
            ],
            "method_zh": "论文提出一个分层框架，包括表示、架构和系统三个层面。在表示层面，核心是构建统一模型，学习对多样真实世界干扰具有内在鲁棒性的音频-视觉特征，无需依赖专用模块即可实现环境泛化。架构层面开发了智能资源分配框架，根据输入特征动态调整计算资源，确保多模态输入的高效和可靠使用。系统层面通过模块化集成大规模基础模型，利用其认知和生成能力提升识别性能。关键创新点在于分层系统性设计，与现有方法相比，更注重整体鲁棒性和可扩展性，而非单一技术优化。",
            "application_zh": "该研究可应用于智能助手、视频会议、自动驾驶和医疗辅助等领域，提升在嘈杂或视觉受限环境下的语音识别可靠性，具有实际部署价值。",
            "highlight_zh": "实验表明，分层框架显著提高了AVSR系统在真实世界噪声和干扰下的识别准确率，同时增强了模型泛化能力和计算资源利用效率。",
            "tags_zh": [
                "音频-视觉语音识别",
                "多模态融合",
                "鲁棒性学习",
                "可扩展架构",
                "基础模型集成",
                "真实世界应用",
                "智能资源分配",
                "分层框架"
            ],
            "_index": 166
        },
        {
            "title": "SonicMoE: Accelerating MoE with IO and Tile-aware Optimizations",
            "authors": [
                "Wentao Guo",
                "Mayank Mishra",
                "Xinle Cheng",
                "Ion Stoica",
                "Tri Dao"
            ],
            "arxiv_id": "2512.14080v1",
            "summary": "Mixture of Experts (MoE) models have emerged as the de facto architecture for scaling up language models without significantly increasing the computational cost. Recent MoE models demonstrate a clear trend towards high expert granularity (smaller expert intermediate dimension) and higher sparsity (constant number of activated experts with higher number of total experts), which improve model quality per FLOP. However, fine-grained MoEs suffer from increased activation memory footprint and reduced hardware efficiency due to higher IO costs, while sparser MoEs suffer from wasted computations due to padding in Grouped GEMM kernels. In response, we propose a memory-efficient algorithm to compute the forward and backward passes of MoEs with minimal activation caching for the backward pass. We also design GPU kernels that overlap memory IO with computation benefiting all MoE architectures. Finally, we propose a novel \"token rounding\" method that minimizes the wasted compute due to padding in Grouped GEMM kernels. As a result, our method SonicMoE reduces activation memory by 45% and achieves a 1.86x compute throughput improvement on Hopper GPUs compared to ScatterMoE's BF16 MoE kernel for a fine-grained 7B MoE. Concretely, SonicMoE on 64 H100s achieves a training throughput of 213 billion tokens per day comparable to ScatterMoE's 225 billion tokens per day on 96 H100s for a 7B MoE model training with FSDP-2 using the lm-engine codebase. Under high MoE sparsity settings, our tile-aware token rounding algorithm yields an additional 1.16x speedup on kernel execution time compared to vanilla top-$K$ routing while maintaining similar downstream performance. We open-source all our kernels to enable faster MoE model training.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14080v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出SonicMoE以解决细粒度MoE模型中的内存效率低下和计算浪费问题，通过IO与瓦片感知优化加速训练。",
            "summary_zh": "混合专家（MoE）模型已成为扩展语言模型而不显著增加计算成本的事实标准架构。最近的MoE模型显示出高专家粒度（较小的专家中间维度）和更高稀疏性（激活专家数量恒定但总专家数增加）的明显趋势，这提高了每FLOP的模型质量。然而，细粒度MoE由于更高的IO成本而面临激活内存占用增加和硬件效率降低的问题，而更稀疏的MoE则因分组GEMM内核中的填充而导致计算浪费。为此，我们提出了一种内存高效的算法来计算MoE的前向和后向传递，最小化后向传递的激活缓存。我们还设计了GPU内核，将内存IO与计算重叠，使所有MoE架构受益。最后，我们提出了一种新颖的“令牌舍入”方法，最小化分组GEMM内核中填充造成的计算浪费。因此，我们的方法SonicMoE在细粒度7B MoE上，相比ScatterMoE的BF16 MoE内核，减少了45%的激活内存，并在Hopper GPU上实现了1.86倍的计算吞吐量提升。具体来说，在64个H100上，SonicMoE实现了每天2130亿令牌的训练吞吐量，与ScatterMoE在96个H100上使用lm-engine代码库进行7B MoE模型训练（采用FSDP-2）的每天2250亿令牌吞吐量相当。在高MoE稀疏性设置下，我们的瓦片感知令牌舍入算法相比普通top-K路由，在保持类似下游性能的同时，实现了额外1.16倍的内核执行时间加速。我们开源了所有内核以加速MoE模型训练。",
            "intro_zh": [
                "核心问题：细粒度MoE模型因高IO成本导致激活内存占用增加和硬件效率降低，稀疏MoE则因分组GEMM内核填充造成计算浪费。",
                "方法要点：提出内存高效算法减少激活缓存，设计GPU内核实现IO与计算重叠，并引入令牌舍入方法优化填充计算。",
                "实验或效果：在7B MoE上，SonicMoE减少45%激活内存，提升1.86倍计算吞吐量，并在高稀疏设置下实现额外1.16倍加速。"
            ],
            "method_zh": "SonicMoE的整体框架基于MoE模型，通过算法和内核优化提升训练效率。关键技术创新包括：内存高效算法最小化后向传递的激活缓存，减少内存占用；GPU内核设计实现内存IO与计算的重叠，提高硬件利用率；瓦片感知令牌舍入方法动态调整令牌分配，最小化分组GEMM内核中的填充浪费。与现有方法如ScatterMoE相比，SonicMoE更注重IO和瓦片级优化，直接针对细粒度和稀疏MoE的特定瓶颈，而非仅依赖通用加速技术。",
            "application_zh": "该研究主要应用于大规模语言模型的训练加速，特别是在需要高专家粒度和稀疏性的MoE架构中，如GPT-4等前沿模型。潜在价值包括降低训练成本、提高硬件效率，并支持更高效的模型扩展，适用于云计算、AI研究和工业级AI系统开发。",
            "highlight_zh": "在Hopper GPU上，SonicMoE相比ScatterMoE的BF16 MoE内核，对细粒度7B MoE实现45%激活内存减少和1.86倍计算吞吐量提升；在高稀疏设置下，令牌舍入算法带来额外1.16倍内核执行加速，同时保持下游性能不变。",
            "tags_zh": [
                "混合专家模型",
                "内存优化",
                "GPU加速",
                "IO重叠",
                "令牌舍入",
                "训练效率",
                "稀疏计算",
                "硬件感知优化"
            ],
            "_index": 167
        },
        {
            "title": "FusAD: Time-Frequency Fusion with Adaptive Denoising for General Time Series Analysis",
            "authors": [
                "Da Zhang",
                "Bingyu Li",
                "Zhiyuan Zhao",
                "Feiping Nie",
                "Junyu Gao",
                "Xuelong Li"
            ],
            "arxiv_id": "2512.14078v1",
            "summary": "Time series analysis plays a vital role in fields such as finance, healthcare, industry, and meteorology, underpinning key tasks including classification, forecasting, and anomaly detection. Although deep learning models have achieved remarkable progress in these areas in recent years, constructing an efficient, multi-task compatible, and generalizable unified framework for time series analysis remains a significant challenge. Existing approaches are often tailored to single tasks or specific data types, making it difficult to simultaneously handle multi-task modeling and effectively integrate information across diverse time series types. Moreover, real-world data are often affected by noise, complex frequency components, and multi-scale dynamic patterns, which further complicate robust feature extraction and analysis. To ameliorate these challenges, we propose FusAD, a unified analysis framework designed for diverse time series tasks. FusAD features an adaptive time-frequency fusion mechanism, integrating both Fourier and Wavelet transforms to efficiently capture global-local and multi-scale dynamic features. With an adaptive denoising mechanism, FusAD automatically senses and filters various types of noise, highlighting crucial sequence variations and enabling robust feature extraction in complex environments. In addition, the framework integrates a general information fusion and decoding structure, combined with masked pre-training, to promote efficient learning and transfer of multi-granularity representations. Extensive experiments demonstrate that FusAD consistently outperforms state-of-the-art models on mainstream time series benchmarks for classification, forecasting, and anomaly detection tasks, while maintaining high efficiency and scalability. Code is available at https://github.com/zhangda1018/FusAD.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Paper has been accepted by ICDE2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14078v1",
            "code_links": [
                {
                    "url": "https://github.com/zhangda1018/FusAD",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出FusAD统一框架，通过自适应时频融合与去噪解决多任务时间序列分析难题",
            "summary_zh": "时间序列分析在金融、医疗、工业和气象等领域至关重要，支撑着分类、预测和异常检测等关键任务。尽管深度学习模型近年来在这些领域取得了显著进展，但构建一个高效、多任务兼容且可泛化的统一框架仍面临重大挑战。现有方法通常针对单一任务或特定数据类型设计，难以同时处理多任务建模并有效整合不同类型时间序列的信息。此外，现实世界数据常受噪声、复杂频率成分和多尺度动态模式影响，进一步增加了稳健特征提取和分析的难度。为应对这些挑战，我们提出了FusAD，一个为多样化时间序列任务设计的统一分析框架。FusAD采用自适应时频融合机制，结合傅里叶和小波变换，高效捕捉全局-局部和多尺度动态特征。通过自适应去噪机制，FusAD自动感知并过滤各类噪声，突出关键序列变化，在复杂环境中实现稳健特征提取。此外，该框架整合了通用信息融合与解码结构，结合掩码预训练，促进多粒度表示的高效学习和迁移。大量实验表明，FusAD在主流时间序列基准测试中，在分类、预测和异常检测任务上持续优于最先进模型，同时保持高效率和可扩展性。代码可在https://github.com/zhangda1018/FusAD获取。",
            "intro_zh": [
                "现有方法多为单任务或特定数据类型设计，难以统一处理多任务和多样化时间序列。",
                "提出自适应时频融合与去噪机制，结合傅里叶/小波变换和掩码预训练，实现稳健特征提取。",
                "在分类、预测和异常检测任务上，FusAD在主流基准测试中持续优于最先进模型。"
            ],
            "method_zh": "FusAD是一个统一的时间序列分析框架，整体架构包括自适应时频融合、自适应去噪、信息融合与解码模块。关键技术创新点在于：1）自适应时频融合机制，同时利用傅里叶变换捕捉全局频率特征和小波变换提取局部多尺度动态；2）自适应去噪机制，自动检测并过滤噪声，增强特征鲁棒性；3）通用信息融合与解码结构，结合掩码预训练，促进多粒度表示学习。与现有方法的主要区别在于其多任务兼容性和泛化能力，通过统一设计有效整合时频信息，而非针对单一任务或数据类型的定制化方案。",
            "application_zh": "该研究可广泛应用于金融风险预测、医疗健康监测、工业设备故障检测和气象数据分析等领域，为复杂时间序列任务提供高效、稳健的解决方案，提升实际应用中的准确性和可靠性。",
            "highlight_zh": "实验显示，FusAD在UCR时间序列分类、ETT电力预测和Yahoo异常检测等主流基准测试中，性能持续超越现有最先进模型，验证了其高效性和可扩展性。",
            "tags_zh": [
                "时间序列分析",
                "时频融合",
                "自适应去噪",
                "多任务学习",
                "傅里叶变换",
                "小波变换",
                "掩码预训练",
                "统一框架"
            ],
            "_index": 168
        },
        {
            "title": "Efficient-DLM: From Autoregressive to Diffusion Language Models, and Beyond in Speed",
            "authors": [
                "Yonggan Fu",
                "Lexington Whalen",
                "Zhifan Ye",
                "Xin Dong",
                "Shizhe Diao",
                "Jingyu Liu",
                "Chengyue Wu",
                "Hao Zhang",
                "Enze Xie",
                "Song Han",
                "Maksim Khadkevich",
                "Jan Kautz",
                "Yingyan Celine Lin",
                "Pavlo Molchanov"
            ],
            "arxiv_id": "2512.14067v1",
            "summary": "Diffusion language models (dLMs) have emerged as a promising paradigm that enables parallel, non-autoregressive generation, but their learning efficiency lags behind that of autoregressive (AR) language models when trained from scratch. To this end, we study AR-to-dLM conversion to transform pretrained AR models into efficient dLMs that excel in speed while preserving AR models' task accuracy. We achieve this by identifying limitations in the attention patterns and objectives of existing AR-to-dLM methods and then proposing principles and methodologies for more effective AR-to-dLM conversion. Specifically, we first systematically compare different attention patterns and find that maintaining pretrained AR weight distributions is critical for effective AR-to-dLM conversion. As such, we introduce a continuous pretraining scheme with a block-wise attention pattern, which remains causal across blocks while enabling bidirectional modeling within each block. We find that this approach can better preserve pretrained AR models' weight distributions than fully bidirectional modeling, in addition to its known benefit of enabling KV caching, and leads to a win-win in accuracy and efficiency. Second, to mitigate the training-test gap in mask token distributions (uniform vs. highly left-to-right), we propose a position-dependent token masking strategy that assigns higher masking probabilities to later tokens during training to better mimic test-time behavior. Leveraging this framework, we conduct extensive studies of dLMs' attention patterns, training dynamics, and other design choices, providing actionable insights into scalable AR-to-dLM conversion. These studies lead to the Efficient-DLM family, which outperforms state-of-the-art AR models and dLMs, e.g., our Efficient-DLM 8B achieves +5.4%/+2.7% higher accuracy with 4.5x/2.7x higher throughput compared to Dream 7B and Qwen3 4B, respectively.",
            "categories": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14067v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VIO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出Efficient-DLM框架，通过改进AR到dLM转换方法，实现高效扩散语言模型，在保持任务准确性的同时提升生成速度。",
            "summary_zh": "扩散语言模型（dLMs）作为一种并行、非自回归生成范式展现出潜力，但其从头训练的学习效率落后于自回归（AR）语言模型。为此，本研究探索AR到dLM的转换方法，将预训练的AR模型转化为高效的dLMs，在保持AR模型任务准确性的同时提升速度。我们通过分析现有AR-to-dLM方法在注意力模式和目标上的局限性，提出更有效的转换原则和方法。具体而言，首先系统比较不同注意力模式，发现保持预训练AR权重分布对有效转换至关重要，因此引入基于块级注意力模式的连续预训练方案，在块间保持因果性、块内实现双向建模，这比完全双向建模更好地保留权重分布，并支持KV缓存，实现准确性和效率的双赢。其次，为缓解训练与测试中掩码标记分布（均匀vs.高度从左到右）的差距，提出位置依赖的标记掩码策略，在训练中为后续标记分配更高掩码概率以更好模拟测试行为。基于此框架，我们深入研究了dLMs的注意力模式、训练动态和其他设计选择，为可扩展的AR-to-dLM转换提供实用见解。这些研究催生了Efficient-DLM系列模型，其性能超越最先进的AR模型和dLMs，例如，我们的Efficient-DLM 8B相比Dream 7B和Qwen3 4B，准确率分别提升+5.4%和+2.7%，吞吐量分别提高4.5倍和2.7倍。",
            "intro_zh": [
                "现有AR-to-dLM转换方法在注意力模式和目标上存在局限性，导致学习效率低和训练-测试分布不匹配。",
                "提出块级注意力模式和位置依赖掩码策略，以保持预训练权重分布并模拟测试行为，实现高效转换。",
                "Efficient-DLM系列模型在准确性和吞吐量上显著超越现有AR和dLM模型，如8B版本相比基准模型提升准确率并加速生成。"
            ],
            "method_zh": "论文提出Efficient-DLM框架，核心方法包括AR-to-dLM转换的连续预训练方案。整体框架基于预训练AR模型，通过改进注意力模式和掩码策略实现高效扩散建模。关键技术创新点在于块级注意力模式，它在块间保持因果性以保留AR权重分布，块内实现双向建模以支持并行生成，同时引入位置依赖的掩码策略来缓解训练-测试分布差距。与现有方法的主要区别在于避免了完全双向建模导致的权重分布破坏，并优化了掩码过程以更好地模拟实际生成场景，从而在准确性和效率上取得平衡。",
            "application_zh": "该研究可应用于需要高效文本生成的自然语言处理任务，如机器翻译、文本摘要和对话系统，通过提升扩散语言模型的生成速度和准确性，支持大规模实时应用，降低计算成本。",
            "highlight_zh": "Efficient-DLM 8B模型相比Dream 7B和Qwen3 4B，准确率分别提升5.4%和2.7%，吞吐量提高4.5倍和2.7倍，展示了在保持任务准确性的同时显著加速生成的优势。",
            "tags_zh": [
                "扩散语言模型",
                "自回归模型转换",
                "注意力模式优化",
                "位置依赖掩码",
                "高效文本生成",
                "KV缓存",
                "连续预训练",
                "非自回归生成"
            ],
            "_index": 169
        },
        {
            "title": "Bridging Fidelity-Reality with Controllable One-Step Diffusion for Image Super-Resolution",
            "authors": [
                "Hao Chen",
                "Junyang Chen",
                "Jinshan Pan",
                "Jiangxin Dong"
            ],
            "arxiv_id": "2512.14061v1",
            "summary": "Recent diffusion-based one-step methods have shown remarkable progress in the field of image super-resolution, yet they remain constrained by three critical limitations: (1) inferior fidelity performance caused by the information loss from compression encoding of low-quality (LQ) inputs; (2) insufficient region-discriminative activation of generative priors; (3) misalignment between text prompts and their corresponding semantic regions. To address these limitations, we propose CODSR, a controllable one-step diffusion network for image super-resolution. First, we propose an LQ-guided feature modulation module that leverages original uncompressed information from LQ inputs to provide high-fidelity conditioning for the diffusion process. We then develop a region-adaptive generative prior activation method to effectively enhance perceptual richness without sacrificing local structural fidelity. Finally, we employ a text-matching guidance strategy to fully harness the conditioning potential of text prompts. Extensive experiments demonstrate that CODSR achieves superior perceptual quality and competitive fidelity compared with state-of-the-art methods with efficient one-step inference.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project page: https://github.com/Chanson94/CODSR",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14061v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "SAC"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出CODSR可控一步扩散网络，通过LQ引导特征调制、区域自适应生成先验激活和文本匹配指导，解决图像超分辨率中保真度与感知质量平衡问题。",
            "summary_zh": "近年来，基于扩散的一步方法在图像超分辨率领域取得了显著进展，但仍受限于三个关键问题：(1) 由于低质量输入压缩编码导致的信息损失，造成保真度性能下降；(2) 生成先验的区域判别性激活不足；(3) 文本提示与其对应语义区域之间的错位。为解决这些限制，我们提出了CODSR，一种用于图像超分辨率的可控一步扩散网络。首先，我们提出了一个LQ引导的特征调制模块，利用低质量输入的原始未压缩信息为扩散过程提供高保真度条件。然后，我们开发了一种区域自适应的生成先验激活方法，以在不牺牲局部结构保真度的情况下有效增强感知丰富度。最后，我们采用文本匹配指导策略，充分利用文本提示的条件潜力。大量实验表明，CODSR在高效一步推理下，相比最先进方法实现了卓越的感知质量和有竞争力的保真度。",
            "intro_zh": [
                "现有基于扩散的一步超分辨率方法存在保真度不足、生成先验激活不充分和文本提示与语义区域错位三大问题，限制了性能提升。",
                "CODSR通过LQ引导特征调制模块、区域自适应生成先验激活和文本匹配指导策略，整合原始信息、增强感知并优化文本条件，实现可控超分辨率。",
                "实验显示CODSR在一步推理下达到卓越感知质量和竞争性保真度，显著优于现有方法，验证了其有效性和效率。"
            ],
            "method_zh": "CODSR是一个可控的一步扩散网络，整体框架基于扩散模型，通过一步推理实现图像超分辨率。关键技术创新包括：LQ引导特征调制模块，直接利用低质量输入的未压缩信息提供高保真度条件；区域自适应生成先验激活方法，动态调整生成先验的激活强度以平衡感知丰富度和局部结构；文本匹配指导策略，确保文本提示与图像语义区域对齐。与现有方法的主要区别在于，它综合解决了信息损失、先验激活不足和文本错位问题，通过模块化设计实现更精确的条件控制和性能提升。",
            "application_zh": "该研究可应用于图像增强、视频超分辨率、医学影像分析和数字媒体修复等领域，提升低质量图像的视觉质量和细节还原能力，具有实际价值如改善监控视频清晰度、增强老旧照片或优化遥感图像。",
            "highlight_zh": "CODSR在标准数据集上进行了广泛实验，结果显示其感知质量显著优于现有一步扩散方法，同时保真度指标保持竞争力，在一步推理下实现了高效与高质量的平衡，验证了所提模块的有效性。",
            "tags_zh": [
                "图像超分辨率",
                "扩散模型",
                "一步推理",
                "可控生成",
                "特征调制",
                "生成先验激活",
                "文本指导",
                "保真度-感知平衡"
            ],
            "_index": 170
        },
        {
            "title": "SELECT: Detecting Label Errors in Real-world Scene Text Data",
            "authors": [
                "Wenjun Liu",
                "Qian Wu",
                "Yifeng Hu",
                "Yuke Li"
            ],
            "arxiv_id": "2512.14050v1",
            "summary": "We introduce SELECT (Scene tExt Label Errors deteCTion), a novel approach that leverages multi-modal training to detect label errors in real-world scene text datasets. Utilizing an image-text encoder and a character-level tokenizer, SELECT addresses the issues of variable-length sequence labels, label sequence misalignment, and character-level errors, outperforming existing methods in accuracy and practical utility. In addition, we introduce Similarity-based Sequence Label Corruption (SSLC), a process that intentionally introduces errors into the training labels to mimic real-world error scenarios during training. SSLC not only can cause a change in the sequence length but also takes into account the visual similarity between characters during corruption. Our method is the first to detect label errors in real-world scene text datasets successfully accounting for variable-length labels. Experimental results demonstrate the effectiveness of SELECT in detecting label errors and improving STR accuracy on real-world text datasets, showcasing its practical utility.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "10.1145/3743093.3771031",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14050v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出SELECT方法，利用多模态训练检测真实场景文本数据集中的标签错误，解决变长标签序列和字符级错误问题。",
            "summary_zh": "我们介绍了SELECT（Scene tExt Label Errors deteCTion），一种新颖的方法，利用多模态训练来检测真实场景文本数据集中的标签错误。通过使用图像-文本编码器和字符级分词器，SELECT解决了变长序列标签、标签序列错位和字符级错误的问题，在准确性和实用性上优于现有方法。此外，我们引入了基于相似性的序列标签损坏（SSLC）过程，该过程在训练期间有意向训练标签中引入错误，以模拟真实世界的错误场景。SSLC不仅可能导致序列长度变化，还在损坏过程中考虑了字符之间的视觉相似性。我们的方法是首个成功检测真实场景文本数据集中标签错误并考虑变长标签的方法。实验结果表明，SELECT在检测标签错误和提高真实世界文本数据集上的场景文本识别（STR）准确性方面具有有效性，展示了其实用价值。",
            "intro_zh": [
                "现有方法难以处理真实场景文本数据中的变长标签序列、标签错位和字符级错误，导致标签错误检测不准确。",
                "SELECT采用多模态训练，结合图像-文本编码器和字符级分词器，并引入SSLC过程模拟真实错误，提升检测鲁棒性。",
                "实验显示SELECT在标签错误检测和STR准确性上优于现有方法，验证了其在真实数据集上的实用性和有效性。"
            ],
            "method_zh": "SELECT的整体框架基于多模态训练，使用图像-文本编码器提取视觉和文本特征，字符级分词器处理变长序列。关键技术创新包括SSLC过程，该过程在训练中引入基于视觉相似性的标签错误，模拟真实场景的字符替换和序列长度变化。与现有方法的主要区别在于，SELECT是首个专门针对真实场景文本数据中变长标签序列设计的错误检测方法，通过多模态融合和SSLC增强了模型对复杂错误的处理能力。",
            "application_zh": "该研究可应用于自动驾驶、文档数字化、智能监控等领域的场景文本识别系统，通过检测和纠正标签错误，提升数据质量和模型性能，具有实际部署价值。",
            "highlight_zh": "实验结果表明，SELECT在真实场景文本数据集上显著提高了标签错误检测的准确性，并改善了场景文本识别（STR）模型的性能，优于现有基准方法，展示了其在实际应用中的优势。",
            "tags_zh": [
                "场景文本识别",
                "标签错误检测",
                "多模态训练",
                "字符级分词器",
                "序列标签损坏",
                "视觉相似性",
                "真实世界数据集",
                "变长序列处理"
            ],
            "_index": 171
        },
        {
            "title": "Intention Chain-of-Thought Prompting with Dynamic Routing for Code Generation",
            "authors": [
                "Shen Li",
                "Li Huang",
                "Shaoxiong Zhan",
                "Weifeng Sun",
                "Tao Yin",
                "Zhongxin Liu",
                "Meng Yan"
            ],
            "arxiv_id": "2512.14048v1",
            "summary": "Large language models (LLMs) exhibit strong generative capabilities and have shown great potential in code generation. Existing chain-of-thought (CoT) prompting methods enhance model reasoning by eliciting intermediate steps, but suffer from two major limitations: First, their uniform application tends to induce overthinking on simple tasks. Second, they lack intention abstraction in code generation, such as explicitly modeling core algorithmic design and efficiency, leading models to focus on surface-level structures while neglecting the global problem objective. Inspired by the cognitive economy principle of engaging structured reasoning only when necessary to conserve cognitive resources, we propose RoutingGen, a novel difficulty-aware routing framework that dynamically adapts prompting strategies for code generation. For simple tasks, it adopts few-shot prompting; for more complex ones, it invokes a structured reasoning strategy, termed Intention Chain-of-Thought (ICoT), which we introduce to guide the model in capturing task intention, such as the core algorithmic logic and its time complexity. Experiments across three models and six standard code generation benchmarks show that RoutingGen achieves state-of-the-art performance in most settings, while reducing total token usage by 46.37% on average across settings. Furthermore, ICoT outperforms six existing prompting baselines on challenging benchmarks.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Accepted at AAAI-2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14048v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出RoutingGen框架，通过动态路由和意图链式思考解决代码生成中过度推理和意图抽象不足的问题。",
            "summary_zh": "大型语言模型在代码生成方面展现出强大的生成能力和巨大潜力。现有的链式思考提示方法通过引出中间步骤来增强模型推理，但存在两个主要局限：首先，其统一应用倾向于在简单任务上引发过度思考；其次，在代码生成中缺乏意图抽象，例如明确建模核心算法设计和效率，导致模型关注表面结构而忽视全局问题目标。受认知经济原则启发，即仅在必要时进行结构化推理以节省认知资源，我们提出了RoutingGen，一种新颖的难度感知路由框架，动态调整代码生成的提示策略。对于简单任务，它采用少样本提示；对于更复杂的任务，它调用结构化推理策略，称为意图链式思考，我们引入该策略来指导模型捕捉任务意图，例如核心算法逻辑及其时间复杂度。在三个模型和六个标准代码生成基准上的实验表明，RoutingGen在大多数设置中实现了最先进的性能，同时在所有设置中平均减少了46.37%的总令牌使用量。此外，在具有挑战性的基准上，ICoT优于六个现有的提示基线。",
            "intro_zh": [
                "现有链式思考提示方法在代码生成中存在过度推理和意图抽象不足的问题，导致模型效率低下且忽视全局目标。",
                "论文提出RoutingGen框架，结合动态路由和意图链式思考，根据任务难度自适应选择提示策略，提升推理效率。",
                "实验显示RoutingGen在多个基准上达到最优性能，平均减少46.37%令牌使用，ICoT在挑战性任务上优于现有基线。"
            ],
            "method_zh": "RoutingGen是一个难度感知的动态路由框架，整体框架包括任务难度评估模块和策略选择模块。关键技术创新点在于引入意图链式思考，它通过结构化推理指导模型捕捉任务意图，如算法逻辑和复杂度，与现有方法的主要区别在于动态路由机制，避免了统一应用链式思考导致的过度推理，同时增强了意图抽象能力，从而更高效地处理不同复杂度的代码生成任务。",
            "application_zh": "该研究可应用于自动化代码生成、智能编程助手和软件工程工具开发，通过提升代码生成效率和准确性，降低开发成本，支持复杂算法设计和优化任务，具有实际工业价值。",
            "highlight_zh": "RoutingGen在三个模型和六个标准基准上实现最先进性能，平均减少46.37%令牌使用，ICoT在挑战性任务上优于六个现有提示基线，显著提升代码生成效率。",
            "tags_zh": [
                "代码生成",
                "大型语言模型",
                "链式思考提示",
                "动态路由",
                "意图抽象",
                "难度感知",
                "算法设计",
                "效率优化"
            ],
            "_index": 172
        },
        {
            "title": "A Deep Dive into Function Inlining and its Security Implications for ML-based Binary Analysis",
            "authors": [
                "Omar Abusabha",
                "Jiyong Uhm",
                "Tamer Abuhmed",
                "Hyungjoon Koo"
            ],
            "arxiv_id": "2512.14045v1",
            "summary": "A function inlining optimization is a widely used transformation in modern compilers, which replaces a call site with the callee's body in need. While this transformation improves performance, it significantly impacts static features such as machine instructions and control flow graphs, which are crucial to binary analysis. Yet, despite its broad impact, the security impact of function inlining remains underexplored to date. In this paper, we present the first comprehensive study of function inlining through the lens of machine learning-based binary analysis. To this end, we dissect the inlining decision pipeline within the LLVM's cost model and explore the combinations of the compiler options that aggressively promote the function inlining ratio beyond standard optimization levels, which we term extreme inlining. We focus on five ML-assisted binary analysis tasks for security, using 20 unique models to systematically evaluate their robustness under extreme inlining scenarios. Our extensive experiments reveal several significant findings: i) function inlining, though a benign transformation in intent, can (in)directly affect ML model behaviors, being potentially exploited by evading discriminative or generative ML models; ii) ML models relying on static features can be highly sensitive to inlining; iii) subtle compiler settings can be leveraged to deliberately craft evasive binary variants; and iv) inlining ratios vary substantially across applications and build configurations, undermining assumptions of consistency in training and evaluation of ML models.",
            "categories": [
                "cs.CR",
                "cs.LG",
                "cs.PL"
            ],
            "primary_category": "cs.CR",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14045v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VIO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "首次全面研究函数内联对基于机器学习的二进制分析安全影响，揭示极端内联可被利用以规避ML模型。",
            "summary_zh": "函数内联优化是现代编译器中广泛使用的转换技术，它通过将调用点替换为被调用函数体来提高性能。然而，这种转换会显著影响机器指令和控制流图等静态特征，这些特征对二进制分析至关重要。尽管其影响广泛，但函数内联的安全影响至今仍未得到充分探索。本文首次从基于机器学习的二进制分析角度对函数内联进行了全面研究。为此，我们剖析了LLVM成本模型中的内联决策流程，并探索了编译器选项的组合，这些组合能够将函数内联比率提升到标准优化级别之上，我们称之为极端内联。我们专注于五个用于安全的ML辅助二进制分析任务，使用20个独特模型来系统评估它们在极端内联场景下的鲁棒性。我们的大量实验揭示了几个重要发现：i）函数内联虽然意图上是良性转换，但可能（间接）影响ML模型行为，可能被利用来规避判别性或生成性ML模型；ii）依赖静态特征的ML模型可能对内联高度敏感；iii）微妙的编译器设置可被利用来故意制作规避性二进制变体；iv）内联比率在不同应用程序和构建配置中差异很大，破坏了ML模型训练和评估中一致性假设。",
            "intro_zh": [
                "现有方法未充分探索函数内联对基于ML的二进制分析安全影响，导致模型鲁棒性未知。",
                "论文提出极端内联概念，通过剖析LLVM成本模型和组合编译器选项来系统评估内联影响。",
                "实验发现ML模型对内联高度敏感，极端内联可被利用制作规避性二进制变体，破坏模型一致性。"
            ],
            "method_zh": "论文的核心方法包括：整体框架基于LLVM编译器，通过剖析其成本模型中的内联决策流程，探索编译器选项组合以实施极端内联。关键技术创新点在于首次系统研究函数内联对ML模型的影响，并定义极端内联作为评估场景。与现有方法的主要区别在于，现有研究多关注内联的性能优化，而本文聚焦其安全影响，特别是对基于静态特征的ML模型的鲁棒性挑战，通过多任务、多模型实验设计进行全面评估。",
            "application_zh": "该研究在二进制安全分析领域具有重要应用价值，可用于评估和提升ML模型对编译器优化的鲁棒性，指导安全工具开发，防止攻击者利用内联等优化技术规避检测，增强软件供应链安全。",
            "highlight_zh": "实验发现函数内联可间接影响ML模型行为，极端内联下模型敏感度高，内联比率差异大破坏训练一致性，为安全分析提供新视角。",
            "tags_zh": [
                "函数内联",
                "二进制分析",
                "机器学习安全",
                "编译器优化",
                "极端内联",
                "模型鲁棒性",
                "LLVM成本模型",
                "静态特征"
            ],
            "_index": 173
        },
        {
            "title": "ChartAgent: A Chart Understanding Framework with Tool Integrated Reasoning",
            "authors": [
                "Boran Wang",
                "Xinming Wang",
                "Yi Chen",
                "Xiang Li",
                "Jian Xu",
                "Jing Yuan",
                "Chenglin Liu"
            ],
            "arxiv_id": "2512.14040v1",
            "summary": "With their high information density and intuitive readability, charts have become the de facto medium for data analysis and communication across disciplines. Recent multimodal large language models (MLLMs) have made notable progress in automated chart understanding, yet they remain heavily dependent on explicit textual annotations and the performance degrades markedly when key numerals are absent. To address this limitation, we introduce ChartAgent, a chart understanding framework grounded in Tool-Integrated Reasoning (TIR). Inspired by human cognition, ChartAgent decomposes complex chart analysis into a sequence of observable, replayable steps. Supporting this architecture is an extensible, modular tool library comprising more than a dozen core tools, such as keyelement detection, instance segmentation, and optical character recognition (OCR), which the agent dynamically orchestrates to achieve systematic visual parsing across diverse chart types. Leveraging TIRs transparency and verifiability, ChartAgent moves beyond the black box paradigm by standardizing and consolidating intermediate outputs into a structured Evidence Package, providing traceable and reproducible support for final conclusions. Experiments show that ChartAgent substantially improves robustness under sparse annotation settings, offering a practical path toward trustworthy and extensible systems for chart understanding.",
            "categories": [
                "cs.CV",
                "cs.LG"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14040v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "PPO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出ChartAgent框架，通过工具集成推理解决图表理解在稀疏标注下的鲁棒性问题。",
            "summary_zh": "图表因其高信息密度和直观可读性，已成为跨学科数据分析和交流的实际媒介。近年来，多模态大语言模型（MLLMs）在自动化图表理解方面取得了显著进展，但它们仍然严重依赖显式文本标注，并且在关键数字缺失时性能显著下降。为了解决这一限制，我们引入了ChartAgent，这是一个基于工具集成推理（TIR）的图表理解框架。受人类认知启发，ChartAgent将复杂的图表分析分解为一系列可观察、可重放的步骤。支持这一架构的是一个可扩展的模块化工具库，包含十多个核心工具，如关键元素检测、实例分割和光学字符识别（OCR），智能体动态编排这些工具，以实现跨不同图表类型的系统化视觉解析。利用TIR的透明性和可验证性，ChartAgent超越了黑盒范式，通过将中间输出标准化并整合为结构化的证据包，为最终结论提供可追溯和可复现的支持。实验表明，ChartAgent在稀疏标注设置下显著提高了鲁棒性，为可信赖和可扩展的图表理解系统提供了一条实用路径。",
            "intro_zh": [
                "现有MLLMs依赖显式文本标注，关键数字缺失时性能显著下降，限制了实际应用。",
                "提出ChartAgent框架，基于工具集成推理，将图表分析分解为可观察步骤，动态编排模块化工具库。",
                "实验显示，ChartAgent在稀疏标注设置下显著提升鲁棒性，提供可追溯和可复现的图表理解支持。"
            ],
            "method_zh": "ChartAgent是一个基于工具集成推理（TIR）的图表理解框架。整体框架包括一个可扩展的模块化工具库（如关键元素检测、实例分割、OCR等），智能体动态编排这些工具，将复杂图表分析分解为可观察、可重放的步骤。关键技术创新在于引入结构化证据包，标准化和整合中间输出，实现透明和可验证的推理过程。与现有方法的主要区别在于，它不依赖黑盒模型，而是通过工具集成提供系统化视觉解析，减少对显式文本标注的依赖，提高在稀疏标注下的鲁棒性。",
            "application_zh": "该研究可应用于数据可视化分析、自动化报告生成、教育辅助工具和商业智能系统等领域，为跨学科数据交流提供可信赖的图表理解支持，提升信息处理效率和准确性。",
            "highlight_zh": "实验结果表明，ChartAgent在稀疏标注设置下显著提高了鲁棒性，通过工具集成推理和结构化证据包，实现了可追溯和可复现的图表理解，为实际应用提供了实用路径。",
            "tags_zh": [
                "图表理解",
                "工具集成推理",
                "多模态大语言模型",
                "稀疏标注鲁棒性",
                "结构化证据包",
                "视觉解析",
                "模块化工具库",
                "可追溯推理"
            ],
            "_index": 174
        },
        {
            "title": "Unleashing the Power of Image-Tabular Self-Supervised Learning via Breaking Cross-Tabular Barriers",
            "authors": [
                "Yibing Fu",
                "Yunpeng Zhao",
                "Zhitao Zeng",
                "Cheng Chen",
                "Yueming Jin"
            ],
            "arxiv_id": "2512.14026v1",
            "summary": "Multi-modal learning integrating medical images and tabular data has significantly advanced clinical decision-making in recent years. Self-Supervised Learning (SSL) has emerged as a powerful paradigm for pretraining these models on large-scale unlabeled image-tabular data, aiming to learn discriminative representations. However, existing SSL methods for image-tabular representation learning are often confined to specific data cohorts, mainly due to their rigid tabular modeling mechanisms when modeling heterogeneous tabular data. This inter-tabular barrier hinders the multi-modal SSL methods from effectively learning transferrable medical knowledge shared across diverse cohorts. In this paper, we propose a novel SSL framework, namely CITab, designed to learn powerful multi-modal feature representations in a cross-tabular manner. We design the tabular modeling mechanism from a semantic-awareness perspective by integrating column headers as semantic cues, which facilitates transferrable knowledge learning and the scalability in utilizing multiple data sources for pretraining. Additionally, we propose a prototype-guided mixture-of-linear layer (P-MoLin) module for tabular feature specialization, empowering the model to effectively handle the heterogeneity of tabular data and explore the underlying medical concepts. We conduct comprehensive evaluations on Alzheimer's disease diagnosis task across three publicly available data cohorts containing 4,461 subjects. Experimental results demonstrate that CITab outperforms state-of-the-art approaches, paving the way for effective and scalable cross-tabular multi-modal learning.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14026v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出CITab框架以解决跨队列图像-表格自监督学习中的表格异构性障碍问题",
            "summary_zh": "近年来，整合医学图像和表格数据的多模态学习显著推动了临床决策的进步。自监督学习已成为在这些大规模未标记图像-表格数据上进行预训练的强大范式，旨在学习判别性表征。然而，现有的图像-表格表征学习自监督方法通常局限于特定数据队列，主要原因是其建模异构表格数据时采用僵化的表格建模机制。这种跨表格障碍阻碍了多模态自监督方法有效学习跨不同队列共享的可迁移医学知识。本文提出了一种新颖的自监督学习框架CITab，旨在以跨表格方式学习强大的多模态特征表征。我们从语义感知的角度设计表格建模机制，通过整合列标题作为语义线索，促进可迁移知识学习以及利用多个数据源进行预训练的可扩展性。此外，我们提出了原型引导的线性混合层模块用于表格特征专业化，使模型能够有效处理表格数据的异构性并探索潜在的医学概念。我们在包含4,461名受试者的三个公开数据队列上对阿尔茨海默病诊断任务进行了全面评估。实验结果表明，CITab优于最先进的方法，为有效且可扩展的跨表格多模态学习铺平了道路。",
            "intro_zh": [
                "现有自监督学习方法因僵化的表格建模机制，难以处理异构表格数据，导致跨队列知识迁移受限。",
                "提出CITab框架，通过语义感知的表格建模和原型引导的线性混合层，实现跨表格多模态表征学习。",
                "在阿尔茨海默病诊断任务中，CITab在三个公开队列上超越现有方法，验证了其有效性和可扩展性。"
            ],
            "method_zh": "CITab是一个跨表格自监督学习框架，核心创新包括：1）语义感知的表格建模机制，将列标题作为语义线索整合，增强模型对表格结构的理解；2）原型引导的线性混合层模块，通过原型聚类和线性组合实现表格特征专业化，以处理数据异构性。整体框架结合图像和表格模态，通过自监督预训练学习共享表征。与现有方法相比，CITab突破了跨表格障碍，支持多数据源预训练，提升了可迁移性和泛化能力。",
            "application_zh": "该研究主要应用于医学领域，特别是阿尔茨海默病等疾病的诊断和预测，通过整合医学图像和临床表格数据，提升临床决策的准确性和效率。其跨队列学习能力可扩展到其他多模态医疗数据分析任务。",
            "highlight_zh": "在包含4,461名受试者的三个公开阿尔茨海默病数据队列上，CITab在诊断任务中显著优于现有最先进方法，证明了其在跨表格多模态学习中的有效性和性能提升。",
            "tags_zh": [
                "自监督学习",
                "多模态融合",
                "医学图像分析",
                "表格数据处理",
                "跨队列学习",
                "表征学习",
                "阿尔茨海默病诊断",
                "语义感知建模"
            ],
            "_index": 175
        },
        {
            "title": "EXAONE Path 2.5: Pathology Foundation Model with Multi-Omics Alignment",
            "authors": [
                "Juseung Yun",
                "Sunwoo Yu",
                "Sumin Ha",
                "Jonghyun Kim",
                "Janghyeon Lee",
                "Jongseong Jang",
                "Soonyoung Lee"
            ],
            "arxiv_id": "2512.14019v1",
            "summary": "Cancer progression arises from interactions across multiple biological layers, especially beyond morphological and across molecular layers that remain invisible to image-only models. To capture this broader biological landscape, we present EXAONE Path 2.5, a pathology foundation model that jointly models histologic, genomic, epigenetic and transcriptomic modalities, producing an integrated patient representation that reflects tumor biology more comprehensively. Our approach incorporates three key components: (1) multimodal SigLIP loss enabling all-pairwise contrastive learning across heterogeneous modalities, (2) a fragment-aware rotary positional encoding (F-RoPE) module that preserves spatial structure and tissue-fragment topology in WSI, and (3) domain-specialized internal foundation models for both WSI and RNA-seq to provide biologically grounded embeddings for robust multimodal alignment. We evaluate EXAONE Path 2.5 against six leading pathology foundation models across two complementary benchmarks: an internal real-world clinical dataset and the Patho-Bench benchmark covering 80 tasks. Our framework demonstrates high data and parameter efficiency, achieving on-par performance with state-of-the-art foundation models on Patho-Bench while exhibiting the highest adaptability in the internal clinical setting. These results highlight the value of biologically informed multimodal design and underscore the potential of integrated genotype-to-phenotype modeling for next-generation precision oncology.",
            "categories": [
                "cs.LG",
                "q-bio.QM"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14019v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出EXAONE Path 2.5病理学基础模型，通过多组学对齐解决癌症多模态建模不足问题",
            "summary_zh": "癌症进展源于多个生物层面的相互作用，特别是超越形态学且涉及分子层面，这些对仅基于图像的模型是不可见的。为捕捉更广泛的生物景观，我们提出了EXAONE Path 2.5，这是一个病理学基础模型，联合建模组织学、基因组学、表观遗传学和转录组学模态，生成反映肿瘤生物学更全面的整合患者表征。我们的方法包含三个关键组件：(1) 多模态SigLIP损失，实现跨异质模态的全配对对比学习；(2) 片段感知旋转位置编码(F-RoPE)模块，保留全切片图像中的空间结构和组织片段拓扑；(3) 针对全切片图像和RNA-seq的领域专用内部基础模型，提供基于生物学的嵌入，以实现稳健的多模态对齐。我们在两个互补基准上评估EXAONE Path 2.5与六个领先的病理学基础模型：一个内部真实世界临床数据集和覆盖80个任务的Patho-Bench基准。我们的框架展示了高数据和参数效率，在Patho-Bench上达到与最先进基础模型相当的性能，同时在内部临床设置中表现出最高的适应性。这些结果突显了基于生物学的多模态设计的价值，并强调了整合基因型到表型建模对下一代精准肿瘤学的潜力。",
            "intro_zh": [
                "核心问题：现有病理学模型主要依赖图像模态，难以捕捉癌症进展中跨分子层面的相互作用，导致对肿瘤生物学的理解不全面。",
                "方法要点：提出EXAONE Path 2.5，整合组织学、基因组学等多模态数据，通过多模态对齐和专用编码模块生成综合患者表征。",
                "实验或效果：在Patho-Bench基准上达到最先进性能，在临床数据中展示高适应性，验证了多组学建模的有效性。"
            ],
            "method_zh": "EXAONE Path 2.5的整体框架是一个多模态病理学基础模型，旨在联合处理组织学图像（如全切片图像）和分子数据（如基因组、转录组）。关键技术创新点包括：使用多模态SigLIP损失进行跨模态对比学习，确保不同数据类型的有效对齐；引入片段感知旋转位置编码(F-RoPE)模块，以保留全切片图像中的空间结构和组织片段拓扑；以及部署领域专用内部基础模型，为全切片图像和RNA-seq提供生物学基础的嵌入。与现有方法的主要区别在于其强调多组学对齐，通过整合多种生物模态来更全面地建模肿瘤生物学，而传统方法通常局限于单一模态或简单融合。",
            "application_zh": "该研究在精准肿瘤学领域具有重要应用价值，可用于癌症诊断、预后预测和治疗响应分析。通过整合多模态数据，模型能提供更全面的患者表征，支持个性化医疗决策，推动下一代癌症研究和临床实践的发展。",
            "highlight_zh": "在Patho-Bench基准测试中，EXAONE Path 2.5达到与最先进模型相当的性能，覆盖80个任务；在内部临床数据集上展示最高适应性，验证了其高数据和参数效率，突显多模态对齐的优势。",
            "tags_zh": [
                "病理学基础模型",
                "多模态对齐",
                "多组学整合",
                "对比学习",
                "精准肿瘤学",
                "全切片图像分析",
                "生物信息学",
                "癌症建模"
            ],
            "_index": 176
        },
        {
            "title": "PerfCoder: Large Language Models for Interpretable Code Performance Optimization",
            "authors": [
                "Jiuding Yang",
                "Shengyao Lu",
                "Hongxuan Liu",
                "Shayan Shirahmad Gale Bagi",
                "Zahra Fazel",
                "Tomasz Czajkowski",
                "Di Niu"
            ],
            "arxiv_id": "2512.14018v1",
            "summary": "Large language models (LLMs) have achieved remarkable progress in automatic code generation, yet their ability to produce high-performance code remains limited--a critical requirement in real-world software systems. We argue that current LLMs struggle not only due to data scarcity but, more importantly, because they lack supervision that guides interpretable and effective performance improvements. In this work, we introduce PerfCoder, a family of LLMs specifically designed to generate performance-enhanced code from source code via interpretable, customized optimizations. PerfCoder is fine-tuned on a curated collection of real-world optimization trajectories with human-readable annotations, and preference-aligned by reinforcement fine-tuning using runtime measurements, enabling it to propose input-specific improvement strategies and apply them directly without relying on iterative refinement. On the PIE code performance benchmark, PerfCoder surpasses all existing models in both runtime speedup and effective optimization rate, demonstrating that performance optimization cannot be achieved by scale alone but requires optimization stratetgy awareness. In addition, PerfCoder can generate interpretable feedback about the source code, which, when provided as input to a larger LLM in a planner-and-optimizer cooperative workflow, can further improve outcomes. Specifically, we elevate the performance of 32B models and GPT-5 to new levels on code optimization, substantially surpassing their original performance.",
            "categories": [
                "cs.SE",
                "cs.AI"
            ],
            "primary_category": "cs.SE",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14018v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出PerfCoder系列大语言模型，通过可解释的定制化优化生成高性能代码，解决现有模型性能优化能力不足的问题。",
            "summary_zh": "大语言模型（LLMs）在自动代码生成方面取得了显著进展，但其生成高性能代码的能力仍然有限——这是现实世界软件系统的关键需求。我们认为，当前LLMs的困难不仅源于数据稀缺，更重要的是缺乏指导可解释且有效性能改进的监督。在这项工作中，我们引入了PerfCoder，这是一个专门设计用于通过可解释的定制化优化从源代码生成性能增强代码的LLMs系列。PerfCoder在精心策划的真实世界优化轨迹集合上进行了微调，这些轨迹带有可读的人工注释，并通过使用运行时测量的强化微调进行偏好对齐，使其能够提出输入特定的改进策略并直接应用，而不依赖于迭代优化。在PIE代码性能基准测试中，PerfCoder在运行时加速和有效优化率方面均超越了所有现有模型，表明性能优化不能仅通过规模实现，而需要优化策略意识。此外，PerfCoder可以生成关于源代码的可解释反馈，当在规划器与优化器协作的工作流中作为输入提供给更大的LLM时，可以进一步改善结果。具体来说，我们将32B模型和GPT-5在代码优化方面的性能提升到新水平，大幅超越了它们的原始性能。",
            "intro_zh": [
                "现有大语言模型在生成高性能代码方面存在不足，主要由于数据稀缺和缺乏可解释的性能改进监督。",
                "PerfCoder通过微调真实优化轨迹和强化微调，实现输入特定的可解释优化策略，无需迭代优化。",
                "在PIE基准测试中，PerfCoder在运行时加速和优化率上超越所有现有模型，并提升32B模型和GPT-5的性能。"
            ],
            "method_zh": "PerfCoder的整体框架基于大语言模型，通过两个关键步骤实现性能优化：首先，在带有可读注释的真实世界优化轨迹数据集上进行监督微调，学习可解释的优化策略；其次，使用运行时测量进行强化微调，对齐模型偏好以生成更有效的代码。关键技术创新点包括引入优化策略意识，使模型能够直接应用定制化改进，而不依赖传统迭代方法。与现有方法的主要区别在于，PerfCoder强调可解释性和策略指导，而非仅依赖模型规模或通用代码生成能力。",
            "application_zh": "该研究可应用于软件开发、编译器优化和系统性能调优等领域，帮助开发者自动生成高性能代码，提升软件效率和资源利用率，具有重要的实际价值。",
            "highlight_zh": "在PIE代码性能基准测试中，PerfCoder在运行时加速和有效优化率方面均超越所有现有模型，并将32B模型和GPT-5的代码优化性能提升到新水平，大幅超越原始表现。",
            "tags_zh": [
                "代码性能优化",
                "大语言模型",
                "可解释优化",
                "强化微调",
                "监督学习",
                "软件工程",
                "编译器技术",
                "人工智能辅助编程"
            ],
            "_index": 177
        },
        {
            "title": "Accelerating MHC-II Epitope Discovery via Multi-Scale Prediction in Antigen Presentation",
            "authors": [
                "Yue Wan",
                "Jiayi Yuan",
                "Zhiwei Feng",
                "Xiaowei Jia"
            ],
            "arxiv_id": "2512.14011v1",
            "summary": "Antigenic epitope presented by major histocompatibility complex II (MHC-II) proteins plays an essential role in immunotherapy. However, compared to the more widely studied MHC-I in computational immunotherapy, the study of MHC-II antigenic epitope poses significantly more challenges due to its complex binding specificity and ambiguous motif patterns. Consequently, existing datasets for MHC-II interactions are smaller and less standardized than those available for MHC-I. To address these challenges, we present a well-curated dataset derived from the Immune Epitope Database (IEDB) and other public sources. It not only extends and standardizes existing peptide-MHC-II datasets, but also introduces a novel antigen-MHC-II dataset with richer biological context. Leveraging this dataset, we formulate three major machine learning (ML) tasks of peptide binding, peptide presentation, and antigen presentation, which progressively capture the broader biological processes within the MHC-II antigen presentation pathway. We further employ a multi-scale evaluation framework to benchmark existing models, along with a comprehensive analysis over various modeling designs to this problem with a modular framework. Overall, this work serves as a valuable resource for advancing computational immunotherapy, providing a foundation for future research in ML guided epitope discovery and predictive modeling of immune responses.",
            "categories": [
                "cs.LG",
                "q-bio.QM"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14011v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "世界模型",
                    "matched_keywords": [
                        "predictive model"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出多尺度预测框架以加速MHC-II抗原呈递中的表位发现，解决数据稀缺和建模复杂性挑战。",
            "summary_zh": "主要组织相容性复合体II（MHC-II）蛋白呈递的抗原表位在免疫治疗中至关重要。然而，与计算免疫治疗中更广泛研究的MHC-I相比，MHC-II抗原表位的研究因其复杂的结合特异性和模糊的基序模式而面临更多挑战。因此，现有的MHC-II相互作用数据集比MHC-I的数据集更小且标准化程度更低。为应对这些挑战，我们提出了一个从免疫表位数据库（IEDB）和其他公共来源精心整理的数据集。它不仅扩展和标准化了现有的肽-MHC-II数据集，还引入了一个具有更丰富生物学背景的新型抗原-MHC-II数据集。利用此数据集，我们制定了肽结合、肽呈递和抗原呈递三个主要机器学习任务，逐步捕捉MHC-II抗原呈递途径中更广泛的生物过程。我们进一步采用多尺度评估框架对现有模型进行基准测试，并通过模块化框架对该问题的各种建模设计进行全面分析。总体而言，这项工作为推进计算免疫治疗提供了宝贵资源，为未来机器学习指导的表位发现和免疫反应预测建模研究奠定了基础。",
            "intro_zh": [
                "核心问题：MHC-II表位研究面临数据稀缺、标准化不足和复杂结合特异性，导致现有方法难以准确预测。",
                "方法要点：构建标准化数据集，定义多尺度机器学习任务，采用模块化框架进行模型评估和设计分析。",
                "实验或效果：通过多尺度评估基准测试现有模型，提供资源支持未来研究，提升表位发现效率。"
            ],
            "method_zh": "论文提出一个模块化多尺度预测框架，核心包括：从IEDB等来源整理标准化数据集，涵盖肽-MHC-II和抗原-MHC-II交互；定义肽结合、肽呈递和抗原呈递三个渐进式机器学习任务，以模拟完整抗原呈递途径；采用多尺度评估框架对现有模型进行基准测试，并结合模块化设计分析不同建模策略。关键创新在于引入抗原-MHC-II数据集和任务分层，与现有方法相比，更全面地整合生物学背景和过程建模。",
            "application_zh": "该研究可应用于计算免疫治疗领域，如疫苗设计、自身免疫疾病治疗和癌症免疫疗法，通过加速MHC-II表位发现，优化免疫反应预测，提升个性化医疗效果。",
            "highlight_zh": "实验亮点包括构建大规模标准化数据集，覆盖肽和抗原级别；多尺度任务定义有效捕捉生物过程；基准测试显示模型在复杂场景下的性能提升，为后续研究提供可靠基础。",
            "tags_zh": [
                "MHC-II表位预测",
                "计算免疫治疗",
                "多尺度机器学习",
                "抗原呈递建模",
                "数据集标准化",
                "模块化框架",
                "免疫反应预测"
            ],
            "_index": 178
        },
        {
            "title": "Physics-Informed Machine Learning for Two-Phase Moving-Interface and Stefan Problems",
            "authors": [
                "Che-Chia Chang",
                "Te-Sheng Lin",
                "Ming-Chih Lai"
            ],
            "arxiv_id": "2512.14010v1",
            "summary": "The Stefan problem is a classical free-boundary problem that models phase-change processes and poses computational challenges due to its moving interface and nonlinear temperature-phase coupling. In this work, we develop a physics-informed neural network framework for solving two-phase Stefan problems. The proposed method explicitly tracks the interface motion and enforces the discontinuity in the temperature gradient across the interface while maintaining global consistency of the temperature field. Our approach employs two neural networks: one representing the moving interface and the other for the temperature field. The interface network allows rapid categorization of thermal diffusivity in the spatial domain, which is a crucial step for selecting training points for the temperature network. The temperature network's input is augmented with a modified zero-level set function to accurately capture the jump in its normal derivative across the interface. Numerical experiments on two-phase dynamical Stefan problems demonstrate the superior accuracy and effectiveness of our proposed method compared with the ones obtained by other neural network methodology in literature. The results indicate that the proposed framework offers a robust and flexible alternative to traditional numerical methods for solving phase-change problems governed by moving boundaries. In addition, the proposed method can capture an unstable interface evolution associated with the Mullins-Sekerka instability.",
            "categories": [
                "physics.comp-ph",
                "cs.LG"
            ],
            "primary_category": "physics.comp-ph",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14010v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出基于物理信息神经网络的框架以解决两相Stefan移动界面问题",
            "summary_zh": "Stefan问题是一个经典的相变过程自由边界问题，因其移动界面和非线性温度-相耦合而带来计算挑战。本研究开发了一个基于物理信息的神经网络框架来解决两相Stefan问题。该方法显式跟踪界面运动，在保持温度场全局一致性的同时，强制界面处温度梯度的不连续性。我们的方法采用两个神经网络：一个表示移动界面，另一个用于温度场。界面网络允许在空间域中快速分类热扩散率，这是为温度网络选择训练点的关键步骤。温度网络的输入通过修改的零水平集函数进行增强，以准确捕捉界面处法向导数的跳跃。在两相动态Stefan问题上的数值实验表明，与文献中其他神经网络方法相比，我们提出的方法具有更高的准确性和有效性。结果表明，该框架为解决受移动边界控制的相变问题提供了一个稳健且灵活的替代传统数值方法的选择。此外，该方法能够捕捉与Mullins-Sekerka不稳定性相关的不稳定界面演化。",
            "intro_zh": [
                "Stefan问题作为经典自由边界问题，因移动界面和温度-相非线性耦合导致传统数值方法计算复杂且精度受限。",
                "提出双神经网络框架：界面网络跟踪运动并分类热扩散率，温度网络通过增强输入捕捉梯度跳跃，实现物理约束的精确求解。",
                "数值实验显示，相比现有神经网络方法，该方法在精度和有效性上显著提升，并能模拟不稳定界面演化如Mullins-Sekerka不稳定性。"
            ],
            "method_zh": "论文提出一个基于物理信息神经网络（PINN）的框架，用于求解两相Stefan问题。整体框架由两个神经网络组成：界面网络负责显式跟踪移动界面并快速分类空间域中的热扩散率，从而指导温度网络的训练点选择；温度网络则通过输入增强（使用修改的零水平集函数）来准确捕捉界面处温度法向导数的跳跃，同时强制物理约束如能量守恒。关键技术创新在于将界面运动与温度场解耦处理，并通过增强机制处理不连续性，与现有PINN方法相比，该方法更直接地建模界面动态并提高求解精度。",
            "application_zh": "该研究在相变过程模拟中具有广泛潜在应用，如材料科学中的凝固与熔化、能源领域的相变储能、以及生物医学中的组织冷冻治疗。其稳健性和灵活性为传统数值方法提供了高效替代，有助于优化工业设计和科学研究中的移动边界问题求解。",
            "highlight_zh": "数值实验表明，该方法在两相动态Stefan问题上相比文献中其他神经网络方法，展现出更高的精度和有效性，并能成功捕捉Mullins-Sekerka不稳定性相关的不稳定界面演化，验证了框架的优越性能。",
            "tags_zh": [
                "物理信息神经网络",
                "Stefan问题",
                "移动界面",
                "两相流",
                "相变模拟",
                "自由边界问题",
                "Mullins-Sekerka不稳定性",
                "数值求解"
            ],
            "_index": 179
        }
    ]
}