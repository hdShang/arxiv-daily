{
    "papers": [
        {
            "title": "Sample-Efficient Robot Skill Learning for Construction Tasks: Benchmarking Hierarchical Reinforcement Learning and Vision-Language-Action VLA Model",
            "authors": [
                "Zhaofeng Hu",
                "Hongrui Yu",
                "Vaidhyanathan Chandramouli",
                "Ci-Jyun Liang"
            ],
            "arxiv_id": "2512.14031",
            "summary": "This study evaluates two leading approaches for teaching construction robots new skills to understand their applicability for construction automation: a Vision-Language-Action (VLA) model and Reinforcement Learning (RL) methods. The goal is to understand both task performance and the practical effort needed to deploy each approach on real jobs. The authors developed two teleoperation interfaces to control the robots and collect the demonstrations needed, both of which proved effective for training robots for long-horizon and dexterous tasks. In addition, the authors conduct a three-stage evaluation. First, the authors compare a Multi-Layer Perceptron (MLP) policy with a Deep Q-network (DQN) imitation model to identify the stronger RL baseline, focusing on model performance, generalization, and a pick-up experiment. Second, three different VLA models are trained in two different scenarios and compared with each other. Third, the authors benchmark the selected RL baseline against the VLA model using computational and sample-efficiency measures and then a robot experiment on a multi-stage panel installation task that includes transport and installation. The VLA model demonstrates strong generalization and few-shot capability, achieving 60% and 100% success in the pickup phase. In comparison, DQN can be made robust but needs additional noise during tuning, which increases the workload. Overall, the findings indicate that VLA offers practical advantages for changing tasks by reducing programming effort and enabling useful performance with minimal data, while DQN provides a viable baseline when sufficient tuning effort is acceptable.",
            "categories": [
                "cs.RO",
                "cs.AI"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14031",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "teleoperation"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning"
                    ],
                    "score": 4.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]vision-language-action",
                        "[T]VLA"
                    ],
                    "score": 18.0
                }
            ],
            "relevance_score": 24.5,
            "hit_pillars": [
                "1_robot_core",
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "对比VLA模型与强化学习，提升建筑机器人操作技能并实现高效样本利用",
            "summary_zh": "本研究评估了两种领先的方法，即视觉-语言-动作（VLA）模型和强化学习（RL）方法，用于训练建筑机器人掌握新技能，旨在了解它们在建筑自动化中的适用性。作者开发了两种遥操作界面来控制机器人并收集所需的演示数据，这两种界面都被证明对训练机器人执行长时程和灵巧任务有效。此外，作者进行了一个三阶段的评估。首先，作者比较了多层感知器（MLP）策略与深度Q网络（DQN）模仿模型，以确定更强的RL基线，重点关注模型性能、泛化能力和一个拾取实验。其次，在两种不同的场景中训练了三种不同的VLA模型，并将它们相互比较。第三，作者使用计算和样本效率指标，以及一个包含运输和安装的多阶段面板安装机器人实验，将选定的RL基线与VLA模型进行基准测试。VLA模型表现出强大的泛化能力和少样本学习能力，在拾取阶段实现了60%和100%的成功率。相比之下，DQN可以通过在调整过程中添加额外的噪声来使其更加鲁棒，但这增加了工作量。总的来说，研究结果表明，VLA通过减少编程工作量和以最少的数据实现有用的性能，为改变任务提供了实际优势，而DQN在可以接受足够的调整工作量时，提供了一个可行的基线。",
            "intro_zh": [
                "建筑机器人技能学习面临挑战，传统方法编程复杂且泛化性差，难以适应多变的任务需求。",
                "论文对比VLA模型和强化学习，利用遥操作数据训练机器人，旨在提升样本效率和泛化能力。",
                "实验表明，VLA模型在少样本学习和泛化方面优于DQN，但在充分调优下DQN也是可行的基线。"
            ],
            "method_zh": "**问题定义**：论文旨在解决建筑机器人技能学习中样本效率低和泛化能力差的问题。现有方法通常需要大量的训练数据和精细的手动调整，难以适应建筑工地多变的环境和任务需求。因此，如何利用少量样本快速训练出具有良好泛化能力的机器人技能是本研究的核心问题。\\n\\n**核心思路**：论文的核心思路是对比研究视觉-语言-动作（VLA）模型和强化学习（RL）方法在建筑机器人技能学习中的表现。VLA模型通过结合视觉信息、语言指令和动作控制，使机器人能够理解任务目标并执行相应的动作。强化学习则通过试错学习，使机器人能够自主地探索环境并优化策略。通过对比两种方法的性能，可以了解它们在样本效率、泛化能力和实际部署方面的优劣。\\n\\n**技术框架**：论文的整体框架包括数据收集、模型训练和实验评估三个阶段。首先，通过遥操作界面收集机器人的演示数据。然后，分别训练VLA模型和RL模型。VLA模型采用不同的架构，包括MLP等。RL模型则采用DQN算法。最后，通过一系列实验评估两种模型的性能，包括拾取实验和多阶段面板安装实验。\\n\\n**关键创新**：论文的关键创新在于对比研究了VLA模型和RL模型在建筑机器人技能学习中的表现，并提出了基于遥操作数据的训练方法。VLA模型能够利用语言指令和视觉信息，实现更强的泛化能力和少样本学习能力。与传统的RL方法相比，VLA模型能够更快地适应新的任务。\\n\\n**关键设计**：在VLA模型中，采用了不同的网络结构，包括MLP等，以提取视觉特征和语言特征，并将它们融合到动作控制中。在RL模型中，采用了DQN算法，并添加了噪声来提高鲁棒性。此外，论文还设计了两种遥操作界面，用于收集机器人的演示数据。损失函数的设计也至关重要，需要平衡模仿学习和强化学习的目标。",
            "application_zh": "该研究成果可应用于建筑自动化领域，例如建筑构件的搬运、安装和装配。通过VLA模型或强化学习，机器人可以自主地完成各种建筑任务，提高施工效率和质量，降低人工成本和安全风险。此外，该研究方法也可以推广到其他机器人应用领域，例如物流、医疗和农业。",
            "highlight_zh": "实验结果表明，VLA模型在拾取阶段实现了60%和100%的成功率，表现出强大的泛化能力和少样本学习能力。相比之下，DQN需要额外的噪声调整才能达到较好的鲁棒性。在多阶段面板安装实验中，VLA模型也表现出优于DQN的性能。这些结果表明，VLA模型在建筑机器人技能学习中具有实际优势。",
            "tags_zh": [
                "建筑机器人",
                "技能学习",
                "视觉-语言-动作模型",
                "强化学习",
                "样本效率",
                "泛化能力",
                "遥操作",
                "DQN"
            ],
            "_index": 0,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14031/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14031/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14031/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "WAM-Diff: A Masked Diffusion VLA Framework with MoE and Online Reinforcement Learning for Autonomous Driving",
            "authors": [
                "Mingwang Xu",
                "Jiahao Cui",
                "Feipeng Cai",
                "Hanlin Shang",
                "Zhihao Zhu",
                "Shan Luan",
                "Yifang Xu",
                "Neng Zhang",
                "Yaoyi Li",
                "Jia Cai",
                "Siyu Zhu"
            ],
            "arxiv_id": "2512.11872",
            "summary": "End-to-end autonomous driving systems based on vision-language-action (VLA) models integrate multimodal sensor inputs and language instructions to generate planning and control signals. While autoregressive large language models and continuous diffusion policies are prevalent, the potential of discrete masked diffusion for trajectory generation remains largely unexplored. This paper presents WAM-Diff, a VLA framework that employs masked diffusion to iteratively refine a discrete sequence representing future ego-trajectories. Our approach features three key innovations: a systematic adaptation of masked diffusion for autonomous driving that supports flexible, non-causal decoding orders; scalable model capacity via a sparse MoE architecture trained jointly on motion prediction and driving-oriented visual question answering (VQA); and online reinforcement learning using Group Sequence Policy Optimization (GSPO) to optimize sequence-level driving rewards. Remarkably, our model achieves 91.0 PDMS on NAVSIM-v1 and 89.7 EPDMS on NAVSIM-v2, demonstrating the effectiveness of masked diffusion for autonomous driving. The approach provides a promising alternative to autoregressive and diffusion-based policies, supporting scenario-aware decoding strategies for trajectory generation. The code for this paper will be released publicly at:this https URL",
            "categories": [
                "cs.RO",
                "cs.AI",
                "cs.CV"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.11872",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning",
                        "diffusion policy"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "vision-language-action",
                        "[T]VLA",
                        "large language model",
                        "multimodal"
                    ],
                    "score": 18.0
                }
            ],
            "relevance_score": 24.0,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出WAM-Diff，一种基于Masked Diffusion和MoE的VLA自动驾驶框架。",
            "summary_zh": "本文提出WAM-Diff，一个基于视觉-语言-动作(VLA)模型的端到端自动驾驶框架，该框架利用Masked Diffusion迭代地优化离散序列，该序列代表未来的车辆轨迹。该方法包含三个关键创新：系统性地调整Masked Diffusion以适应自动驾驶，支持灵活的非因果解码顺序；通过稀疏MoE架构扩展模型容量，并在运动预测和面向驾驶的视觉问答(VQA)上联合训练；使用群体序列策略优化(GSPO)进行在线强化学习，以优化序列级别的驾驶奖励。该模型在NAVSIM-v1上达到91.0 PDMS，在NAVSIM-v2上达到89.7 EPDMS，证明了Masked Diffusion在自动驾驶中的有效性。该方法为自动驾驶轨迹生成提供了一种有前景的替代方案，支持场景感知的解码策略。",
            "intro_zh": [
                "现有基于自回归LLM和连续扩散策略的端到端自动驾驶系统，缺乏对离散Masked Diffusion在轨迹生成方面的探索。",
                "WAM-Diff框架采用Masked Diffusion迭代优化离散轨迹序列，并结合MoE扩展模型容量，使用在线强化学习优化驾驶奖励。",
                "实验结果表明，WAM-Diff在NAVSIM-v1和NAVSIM-v2上取得了显著的性能，验证了Masked Diffusion在自动驾驶中的有效性。"
            ],
            "method_zh": "**问题定义**：现有端到端自动驾驶系统主要依赖自回归大型语言模型或连续扩散策略生成轨迹，但对离散Masked Diffusion在轨迹生成方面的潜力挖掘不足。如何有效地利用Masked Diffusion生成高质量的自动驾驶轨迹，并克服其在序列生成任务中的挑战，是本文要解决的关键问题。\\n\\n**核心思路**：本文的核心思路是将自动驾驶轨迹生成问题建模为离散序列的Masked Diffusion过程。通过迭代地掩码和预测轨迹序列中的元素，模型能够学习到轨迹之间的依赖关系，并生成符合驾驶规则和场景约束的轨迹。同时，利用MoE架构扩展模型容量，并结合在线强化学习优化策略，进一步提升轨迹生成的质量和安全性。\\n\\n**技术框架**：WAM-Diff框架主要包含三个核心模块：1) Masked Diffusion模块，负责迭代地掩码和预测离散轨迹序列；2) MoE模块，用于扩展模型容量，提升模型对复杂场景的理解能力；3) 在线强化学习模块，使用GSPO算法优化策略，提升驾驶奖励。整体流程为：首先，模型接收视觉和语言输入，然后通过Masked Diffusion模块生成初始轨迹序列，接着利用MoE模块进行特征提取和融合，最后通过在线强化学习模块优化策略，生成最终的驾驶轨迹。\\n\\n**关键创新**：本文最重要的技术创新在于将Masked Diffusion成功应用于自动驾驶轨迹生成任务。与传统的自回归模型相比，Masked Diffusion支持非因果的解码顺序，能够更灵活地处理轨迹序列中的依赖关系。此外，结合MoE和在线强化学习，进一步提升了模型的性能和安全性。\\n\\n**关键设计**：在Masked Diffusion模块中，采用了离散的轨迹表示，并将轨迹生成问题建模为离散序列的预测问题。MoE模块采用了稀疏激活机制，以降低计算复杂度。在线强化学习模块使用了GSPO算法，以优化序列级别的驾驶奖励。具体的损失函数包括运动预测损失、视觉问答损失和强化学习奖励。",
            "application_zh": "该研究成果可应用于各种自动驾驶场景，例如城市道路、高速公路和停车场等。通过结合视觉、语言和动作信息，WAM-Diff能够生成安全、高效的驾驶轨迹，提升自动驾驶系统的智能化水平。未来，该技术有望应用于无人配送、自动泊车等领域，并促进智能交通的发展。",
            "highlight_zh": "WAM-Diff在NAVSIM-v1上取得了91.0 PDMS的性能，在NAVSIM-v2上取得了89.7 EPDMS的性能。这些结果表明，Masked Diffusion在自动驾驶轨迹生成方面具有显著的优势。与现有的自回归模型和连续扩散模型相比，WAM-Diff能够生成更安全、更高效的驾驶轨迹。",
            "tags_zh": [
                "自动驾驶",
                "Masked Diffusion",
                "视觉语言动作模型",
                "轨迹生成",
                "在线强化学习",
                "MoE",
                "端到端学习"
            ],
            "_index": 1,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.11872/figures/teaser.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.11872/figures/main_arch.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.11872/figures/scheduler.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "EVOLVE-VLA: Test-Time Training from Environment Feedback for Vision-Language-Action Models",
            "authors": [
                "Zechen Bai",
                "Chen Gao",
                "Mike Zheng Shou"
            ],
            "arxiv_id": "2512.14666",
            "summary": "Achieving truly adaptive embodied intelligence requires agents that learn not just by imitating static demonstrations, but by continuously improving through environmental interaction, which is akin to how humans master skills through practice. Vision-Language-Action (VLA) models have advanced robotic manipulation by leveraging large language models, yet remain fundamentally limited by Supervised Finetuning (SFT): requiring hundreds of demonstrations per task, rigidly memorizing trajectories, and failing to adapt when deployment conditions deviate from training. We introduce EVOLVE-VLA, a test-time training framework enabling VLAs to continuously adapt through environment interaction with minimal or zero task-specific demonstrations. The key technical challenge is replacing oracle reward signals (unavailable at test time) with autonomous feedback. We address this through a learned progress estimator providing dense feedback, and critically, we design our framework to ``tame'' this inherently noisy signal via two mechanisms: (1) an accumulative progress estimation mechanism smoothing noisy point-wise estimates, and (2) a progressive horizon extension strategy enabling gradual policy evolution. EVOLVE-VLA achieves substantial gains: +8.6\\% on long-horizon tasks, +22.0\\% in 1-shot learning, and enables cross-task generalization -- achieving 20.8\\% success on unseen tasks without task-specific demonstrations training (vs. 0\\% for pure SFT). Qualitative analysis reveals emergent capabilities absent in demonstrations, including error recovery and novel strategies. This work represents a critical step toward VLAs that truly learn and adapt, moving beyond static imitation toward continuous self-improvements.",
            "categories": [
                "cs.RO",
                "cs.CV"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14666",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]vision-language-action",
                        "[T]VLA",
                        "large language model"
                    ],
                    "score": 21.0
                }
            ],
            "relevance_score": 23.0,
            "hit_pillars": [
                "1_robot_core",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出EVOLVE-VLA以解决视觉-语言-动作模型的适应性问题",
            "summary_zh": "实现真正自适应的具身智能需要代理不仅通过模仿静态示范来学习，而是通过与环境的持续互动不断改进。尽管视觉-语言-动作（VLA）模型通过利用大型语言模型推动了机器人操作的发展，但仍然受到监督微调（SFT）的限制，需数百个示范，且在部署条件偏离训练时无法适应。我们提出了EVOLVE-VLA，一个在测试时通过环境互动持续适应的训练框架，能够在最小或零任务特定示范的情况下进行学习。关键技术挑战是用自主反馈替代不可用的oracle奖励信号。我们通过学习的进度估计器提供密集反馈，并设计了两个机制来“驯服”这种固有的噪声信号。EVOLVE-VLA在长时间任务上提升了8.6%，在一次学习中提升了22.0%，并实现了跨任务泛化，在没有任务特定示范训练的情况下，在未见任务上取得了20.8%的成功。",
            "intro_zh": [
                "现有的视觉-语言-动作模型依赖于大量示范进行监督微调，导致适应性差，无法应对环境变化。",
                "EVOLVE-VLA框架通过环境反馈进行测试时训练，允许模型在没有任务特定示范的情况下进行持续学习和适应。",
                "实验结果显示，EVOLVE-VLA在长时间任务上提升8.6%，在一次学习中提升22.0%，并在未见任务上实现20.8%的成功率。"
            ],
            "method_zh": "**问题定义**：本论文旨在解决视觉-语言-动作模型在测试时缺乏适应性的具体问题。现有方法依赖于大量的示范进行监督微调，导致在环境变化时无法有效适应。\\n\\n**核心思路**：我们提出的EVOLVE-VLA框架通过环境反馈进行测试时训练，允许模型在没有任务特定示范的情况下进行持续学习。通过学习的进度估计器提供密集反馈，并设计机制来处理噪声信号。\\n\\n**技术框架**：EVOLVE-VLA的整体架构包括两个主要模块：进度估计器和反馈处理机制。进度估计器用于生成环境反馈，而反馈处理机制则通过平滑和逐步扩展策略来优化学习过程。\\n\\n**关键创新**：本研究的关键创新在于用自主反馈替代传统的oracle奖励信号，并通过累积进度估计和平滑机制来处理噪声信号，从而实现模型的持续适应。\\n\\n**关键设计**：在设计中，我们采用了累积进度估计机制来平滑噪声点估计，并引入了逐步扩展策略以促进策略的渐进演变。",
            "application_zh": "该研究的潜在应用领域包括机器人操作、自动化制造和智能家居等场景。通过实现持续学习和适应，EVOLVE-VLA能够在动态环境中提高机器人执行复杂任务的能力，具有重要的实际价值和未来影响。",
            "highlight_zh": "实验结果表明，EVOLVE-VLA在长时间任务上提升了8.6%，在一次学习中提升了22.0%，并在未见任务上成功率达到20.8%，显著优于传统的监督微调方法（0%成功率）。",
            "tags_zh": [
                "视觉-语言-动作",
                "自适应学习",
                "环境反馈",
                "机器人操作",
                "持续学习"
            ],
            "_index": 2,
            "_used_api": "openai",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14666/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14666/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14666/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "MindDrive: A Vision-Language-Action Model for Autonomous Driving via Online Reinforcement Learning",
            "authors": [
                "Haoyu Fu",
                "Diankun Zhang",
                "Zongchuang Zhao",
                "Jianfeng Cui",
                "Hongwei Xie",
                "Bing Wang",
                "Guang Chen",
                "Dingkang Liang",
                "Xiang Bai"
            ],
            "arxiv_id": "2512.13636",
            "summary": "Current Vision-Language-Action (VLA) paradigms in autonomous driving primarily rely on Imitation Learning (IL), which introduces inherent challenges such as distribution shift and causal confusion. Online Reinforcement Learning offers a promising pathway to address these issues through trial-and-error learning. However, applying online reinforcement learning to VLA models in autonomous driving is hindered by inefficient exploration in continuous action spaces. To overcome this limitation, we propose MindDrive, a VLA framework comprising a large language model (LLM) with two distinct sets of LoRA parameters. The one LLM serves as a Decision Expert for scenario reasoning and driving decision-making, while the other acts as an Action Expert that dynamically maps linguistic decisions into feasible trajectories. By feeding trajectory-level rewards back into the reasoning space, MindDrive enables trial-and-error learning over a finite set of discrete linguistic driving decisions, instead of operating directly in a continuous action space. This approach effectively balances optimal decision-making in complex scenarios, human-like driving behavior, and efficient exploration in online reinforcement learning. Using the lightweight Qwen-0.5B LLM, MindDrive achieves Driving Score (DS) of 78.04 and Success Rate (SR) of 55.09% on the challenging Bench2Drive benchmark. To the best of our knowledge, this is the first work to demonstrate the effectiveness of online reinforcement learning for the VLA model in autonomous driving.",
            "categories": [
                "cs.CV",
                "cs.RO"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13636",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning",
                        "imitation learning"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]vision-language-action",
                        "VLA",
                        "large language model"
                    ],
                    "score": 15.0
                }
            ],
            "relevance_score": 21.0,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "MindDrive：提出基于在线强化学习的视觉-语言-动作模型，用于自动驾驶。",
            "summary_zh": "当前的自动驾驶视觉-语言-动作（VLA）模型主要依赖于模仿学习（IL），这带来了分布偏移和因果混淆等固有挑战。在线强化学习通过试错学习为解决这些问题提供了一条有希望的途径。然而，将在线强化学习应用于自动驾驶中的VLA模型受到连续动作空间中低效探索的阻碍。为了克服这个限制，我们提出了MindDrive，一个VLA框架，包含一个带有两组不同LoRA参数的大型语言模型（LLM）。一个LLM作为决策专家，用于场景推理和驾驶决策，而另一个作为动作专家，动态地将语言决策映射到可行的轨迹。通过将轨迹级别的奖励反馈到推理空间，MindDrive能够在有限的离散语言驾驶决策集合上进行试错学习，而不是直接在连续动作空间中操作。这种方法有效地平衡了复杂场景中的最优决策、类人驾驶行为以及在线强化学习中的高效探索。使用轻量级的Qwen-0.5B LLM，MindDrive在具有挑战性的Bench2Drive基准测试中实现了78.04的驾驶分数（DS）和55.09%的成功率（SR）。据我们所知，这是第一个证明在线强化学习对自动驾驶中VLA模型有效性的工作。",
            "intro_zh": [
                "现有VLA自动驾驶模型依赖模仿学习，存在分布偏移和因果混淆问题，泛化能力受限。",
                "MindDrive通过在线强化学习，利用LLM进行场景推理和决策，并引入动作专家将语言决策映射为轨迹。",
                "MindDrive在Bench2Drive基准测试中取得了显著成果，驾驶分数达到78.04，成功率达到55.09%。"
            ],
            "method_zh": "**问题定义**：论文旨在解决自动驾驶中视觉-语言-动作模型（VLA）依赖模仿学习所带来的分布偏移和因果混淆问题。现有方法难以在复杂场景下进行有效的探索和学习，导致泛化能力不足。\\n\\n**核心思路**：论文的核心思路是将在线强化学习引入VLA模型，通过试错学习来优化驾驶策略。为了解决连续动作空间中探索效率低下的问题，论文将连续动作空间离散化为有限的语言决策集合，并在该集合上进行强化学习。\\n\\n**技术框架**：MindDrive框架包含一个大型语言模型（LLM），该LLM通过两组LoRA参数分别作为决策专家和动作专家。决策专家负责场景理解和驾驶决策，输出离散的语言指令。动作专家负责将这些语言指令转化为具体的车辆轨迹。系统通过将轨迹级别的奖励反馈给决策专家，实现端到端的强化学习。\\n\\n**关键创新**：该论文最重要的创新在于将在线强化学习应用于VLA自动驾驶模型，并提出了一种将连续动作空间离散化为语言决策空间的方法，从而提高了探索效率。与传统的模仿学习方法相比，该方法能够通过试错学习来优化驾驶策略，从而更好地适应复杂场景。\\n\\n**关键设计**：论文使用了轻量级的Qwen-0.5B LLM作为基础模型。LoRA参数用于调整LLM的行为，使其能够更好地适应驾驶任务。轨迹级别的奖励函数用于评估驾驶行为的优劣。通过精心设计的奖励函数，可以引导模型学习安全、高效的驾驶策略。",
            "application_zh": "MindDrive的研究成果可应用于各种自动驾驶场景，例如城市道路、高速公路和越野环境。该方法能够提高自动驾驶系统的安全性和可靠性，并降低开发成本。未来，该研究可以扩展到其他机器人领域，例如无人机和家用机器人。",
            "highlight_zh": "MindDrive在Bench2Drive基准测试中取得了显著成果，驾驶分数（DS）达到78.04，成功率（SR）达到55.09%。这些结果表明，该方法在复杂驾驶场景中具有很强的竞争力，并且能够有效地解决模仿学习所带来的问题。该论文是首个证明在线强化学习对自动驾驶中VLA模型有效性的工作。",
            "tags_zh": [
                "自动驾驶",
                "视觉-语言-动作模型",
                "强化学习",
                "大型语言模型",
                "在线学习",
                "轨迹规划",
                "Bench2Drive"
            ],
            "_index": 3,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13636/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13636/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.13636/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "AnchorHOI: Zero-shot Generation of 4D Human-Object Interaction via Anchor-based Prior Distillation",
            "authors": [
                "Sisi Dai",
                "Kai Xu"
            ],
            "arxiv_id": "2512.14095",
            "summary": "Despite significant progress in text-driven 4D human-object interaction (HOI) generation with supervised methods, the scalability remains limited by the scarcity of large-scale 4D HOI datasets. To overcome this, recent approaches attempt zero-shot 4D HOI generation with pre-trained image diffusion models. However, interaction cues are minimally distilled during the generation process, restricting their applicability across diverse scenarios. In this paper, we propose AnchorHOI, a novel framework that thoroughly exploits hybrid priors by incorporating video diffusion models beyond image diffusion models, advancing 4D HOI generation. Nevertheless, directly optimizing high-dimensional 4D HOI with such priors remains challenging, particularly for human pose and compositional motion. To address this challenge, AnchorHOI introduces an anchor-based prior distillation strategy, which constructs interaction-aware anchors and then leverages them to guide generation in a tractable two-step process. Specifically, two tailored anchors are designed for 4D HOI generation: anchor Neural Radiance Fields (NeRFs) for expressive interaction composition, and anchor keypoints for realistic motion synthesis. Extensive experiments demonstrate that AnchorHOI outperforms previous methods with superior diversity and generalization.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14095",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]distillation"
                    ],
                    "score": 4.5
                },
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "NeRF",
                        "neural radiance field"
                    ],
                    "score": 4.0
                },
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "motion synthesis"
                    ],
                    "score": 2.5
                },
                {
                    "name": "支柱五：交互与反应 (Interaction & Reaction)",
                    "id": "5_interaction_reaction",
                    "matched_keywords": [
                        "[T]human-object interaction",
                        "HOI"
                    ],
                    "score": 10.0
                }
            ],
            "relevance_score": 21.0,
            "hit_pillars": [
                "2_algo_arch",
                "3_perception_slam",
                "4_motion_diffusion",
                "5_interaction_reaction"
            ],
            "headline_zh": "AnchorHOI：基于锚点的先验知识蒸馏实现零样本4D人-物交互生成",
            "summary_zh": "本文提出AnchorHOI框架，旨在解决大规模4D人-物交互(HOI)数据集稀缺导致的文本驱动4D HOI生成可扩展性受限问题。AnchorHOI通过结合视频扩散模型和图像扩散模型，充分利用混合先验知识，从而推进4D HOI生成。该方法引入基于锚点的先验知识蒸馏策略，构建交互感知的锚点，并利用这些锚点指导生成过程，从而解决直接优化高维4D HOI带来的挑战，特别是对于人体姿态和组合运动。具体而言，AnchorHOI为4D HOI生成设计了两个定制锚点：用于表达交互组合的锚点神经辐射场(NeRFs)和用于逼真运动合成的锚点关键点。实验结果表明，AnchorHOI在多样性和泛化性方面优于现有方法。",
            "intro_zh": [
                "现有文本驱动4D HOI生成方法受限于大规模数据集的稀缺，泛化能力不足。",
                "AnchorHOI利用锚点先验蒸馏策略，通过交互感知的锚点引导生成，降低优化难度。",
                "实验表明，AnchorHOI在生成多样性和泛化性上优于现有方法，提升了4D HOI生成效果。"
            ],
            "method_zh": "**问题定义**：现有文本驱动的4D人-物交互（HOI）生成方法依赖于大规模的4D HOI数据集进行训练，但此类数据集的获取成本高昂，导致模型泛化能力受限，难以应用于各种复杂的交互场景。直接利用预训练的图像扩散模型进行零样本生成时，交互信息的有效利用不足，影响了生成结果的质量和多样性。\\n\\n**核心思路**：AnchorHOI的核心思路是利用预训练的图像和视频扩散模型中的先验知识，通过锚点（anchors）作为桥梁，将这些先验知识有效地蒸馏到4D HOI生成过程中。通过构建交互感知的锚点，降低了直接优化高维4D HOI的难度，从而实现高质量、多样化的零样本4D HOI生成。\\n\\n**技术框架**：AnchorHOI框架包含两个主要阶段：锚点构建阶段和生成阶段。在锚点构建阶段，首先根据文本描述生成初始的3D人体姿态和物体形状。然后，利用预训练的图像和视频扩散模型，分别生成锚点NeRFs（用于表达交互组合）和锚点关键点（用于逼真运动合成）。在生成阶段，利用锚点NeRFs和锚点关键点作为引导，通过扩散模型逐步生成最终的4D HOI结果。\\n\\n**关键创新**：AnchorHOI的关键创新在于提出了基于锚点的先验知识蒸馏策略。与直接优化4D HOI不同，AnchorHOI通过构建交互感知的锚点，将复杂的4D HOI生成过程分解为两个更易于处理的子问题：交互组合和运动合成。这种分解方式使得模型能够更好地利用预训练模型中的先验知识，从而提高生成结果的质量和多样性。\\n\\n**关键设计**：AnchorHOI的关键设计包括：1) 锚点NeRFs的设计，用于表达人体和物体之间的交互关系，通过NeRFs可以生成高质量的3D形状和纹理；2) 锚点关键点的设计，用于捕捉人体运动的动态信息，通过关键点可以生成逼真的运动序列；3) 损失函数的设计，用于约束生成结果与锚点之间的相似性，确保生成结果符合预期的交互模式和运动轨迹。",
            "application_zh": "AnchorHOI在虚拟现实、游戏开发、人机交互等领域具有广泛的应用前景。它可以用于生成逼真的人-物交互动画，提升虚拟环境的沉浸感和交互性。此外，AnchorHOI还可以用于机器人控制和行为规划，帮助机器人更好地理解和执行复杂的任务。",
            "highlight_zh": "实验结果表明，AnchorHOI在4D HOI生成任务上取得了显著的性能提升。相较于现有方法，AnchorHOI在生成结果的多样性和泛化性方面均有明显优势。具体而言，AnchorHOI能够生成更加逼真、自然的交互动画，并且能够处理各种复杂的交互场景。",
            "tags_zh": [
                "4D人-物交互",
                "零样本生成",
                "扩散模型",
                "先验知识蒸馏",
                "锚点",
                "神经辐射场",
                "运动合成"
            ],
            "_index": 4,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14095/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14095/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14095/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "CHIP: Adaptive Compliance for Humanoid Control through Hindsight Perturbation",
            "authors": [
                "Sirui Chen",
                "Zi-ang Cao",
                "Zhengyi Luo",
                "Fernando Castañeda",
                "Chenran Li",
                "Tingwu Wang",
                "Ye Yuan",
                "Linxi \"Jim\" Fan",
                "C. Karen Liu",
                "Yuke Zhu"
            ],
            "arxiv_id": "2512.14689",
            "summary": "Recent progress in humanoid robots has unlocked agile locomotion skills, including backflipping, running, and crawling. Yet it remains challenging for a humanoid robot to perform forceful manipulation tasks such as moving objects, wiping, and pushing a cart. We propose adaptive Compliance Humanoid control through hIsight Perturbation (CHIP), a plug-and-play module that enables controllable end-effector stiffness while preserving agile tracking of dynamic reference motions. CHIP is easy to implement and requires neither data augmentation nor additional reward tuning. We show that a generalist motion-tracking controller trained with CHIP can perform a diverse set of forceful manipulation tasks that require different end-effector compliance, such as multi-robot collaboration, wiping, box delivery, and door opening.",
            "categories": [
                "cs.RO",
                "cs.LG"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14689",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "[T]humanoid",
                        "humanoid robot",
                        "[T]humanoid control",
                        "locomotion",
                        "manipulation"
                    ],
                    "score": 18.0
                },
                {
                    "name": "支柱八：物理动画 (Physics-based Animation)",
                    "id": "8_physics_animation",
                    "matched_keywords": [
                        "motion tracking"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 20.0,
            "hit_pillars": [
                "1_robot_core",
                "8_physics_animation"
            ],
            "headline_zh": "CHIP：通过后见之明扰动实现人型机器人自适应柔顺控制",
            "summary_zh": "人形机器人领域的最新进展已经解锁了敏捷的运动技能，包括后空翻、跑步和爬行。然而，人形机器人执行需要较大作用力的操作任务仍然具有挑战性，例如移动物体、擦拭和推动手推车。我们提出了一种通过后见之明扰动实现自适应柔顺的人形控制方法（CHIP），这是一个即插即用的模块，可以在保持动态参考运动的敏捷跟踪的同时，实现可控的末端执行器刚度。CHIP易于实现，不需要数据增强或额外的奖励调整。我们展示了使用CHIP训练的通用运动跟踪控制器可以执行各种需要不同末端执行器柔顺性的操作任务，例如多机器人协作、擦拭、箱子递送和开门。",
            "intro_zh": [
                "人形机器人难以胜任需要较大作用力的操作任务，如移动物体，现有方法在控制末端执行器柔顺性方面存在不足。",
                "CHIP通过后见之明扰动实现自适应柔顺控制，无需额外数据增强或奖励调整，即可实现末端执行器刚度的灵活控制。",
                "实验表明，使用CHIP训练的通用控制器能够完成多机器人协作、擦拭、箱子递送和开门等多种操作任务。"
            ],
            "method_zh": "**问题定义**：人形机器人虽然在敏捷运动方面取得了显著进展，但在需要较大作用力的操作任务中仍然面临挑战。现有的运动控制方法难以有效控制末端执行器的柔顺性，导致机器人无法灵活适应不同的操作任务需求，例如，在擦拭任务中需要一定的柔顺性以适应表面变化，而在推动重物时则需要较高的刚度。\n\n**核心思路**：CHIP的核心思路是通过引入后见之明扰动来学习自适应的柔顺控制。具体来说，CHIP在训练过程中对机器人的目标状态进行扰动，并让机器人学习如何从这些扰动中恢复。通过这种方式，机器人可以学习到一种对外部扰动具有鲁棒性的控制策略，从而实现自适应的柔顺控制。这种方法避免了显式地建模柔顺性，而是通过隐式的方式学习如何调整机器人的行为以适应不同的任务需求。\n\n**技术框架**：CHIP是一个即插即用的模块，可以集成到现有的运动跟踪控制器中。整体框架包括以下几个主要步骤：1) 给定一个目标运动轨迹；2) 对目标状态进行扰动；3) 使用运动跟踪控制器控制机器人跟踪扰动后的目标状态；4) 使用强化学习算法优化控制器的参数，使得机器人能够更好地从扰动中恢复。CHIP模块主要负责生成扰动，并将其传递给运动跟踪控制器。\n\n**关键创新**：CHIP最重要的创新点在于其通过后见之明扰动来学习自适应柔顺控制的方法。与传统的柔顺控制方法相比，CHIP不需要显式地建模柔顺性，而是通过隐式的方式学习如何调整机器人的行为以适应不同的任务需求。此外，CHIP易于实现，不需要数据增强或额外的奖励调整，可以方便地集成到现有的运动控制系统中。\n\n**关键设计**：CHIP的关键设计包括扰动策略和强化学习算法的选择。扰动策略需要能够有效地探索状态空间，并覆盖不同的任务需求。论文中使用了随机扰动策略，并对扰动的大小进行了调整。强化学习算法则需要能够有效地学习控制器的参数，使得机器人能够更好地从扰动中恢复。论文中使用了PPO算法进行训练。",
            "application_zh": "CHIP具有广泛的应用前景，可以应用于各种需要人形机器人进行操作的场景，例如：工业自动化、家庭服务、医疗康复等。通过CHIP，人形机器人可以更加灵活地适应不同的任务需求，提高操作效率和安全性。此外，CHIP还可以用于多机器人协作，使得多个机器人可以协同完成复杂的任务。",
            "highlight_zh": "实验结果表明，使用CHIP训练的通用运动跟踪控制器可以成功完成多种需要不同末端执行器柔顺性的操作任务，包括多机器人协作、擦拭、箱子递送和开门。与没有使用CHIP的基线方法相比，CHIP在这些任务上取得了显著的性能提升，例如，在擦拭任务中，CHIP可以更好地适应表面变化，从而提高擦拭质量。",
            "tags_zh": [
                "人形机器人控制",
                "柔顺控制",
                "后见之明学习",
                "强化学习",
                "运动跟踪"
            ],
            "_index": 5,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14689/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14689/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14689/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Data-fused MPC with Guarantees: Application to Flying Humanoid Robots",
            "authors": [
                "Davide Gorbani",
                "Mohamed Elobaid",
                "Giuseppe L'Erario",
                "Hosameldin Awadalla Omer Mohamed",
                "Daniele Pucci"
            ],
            "arxiv_id": "2509.10353",
            "summary": "This paper introduces a Data-Fused Model Predictive Control (DFMPC) framework that combines physics-based models with data-driven representations of unknown dynamics. Leveraging Willems' Fundamental Lemma and an artificial equilibrium formulation, the method enables tracking of changing, potentially unreachable setpoints while explicitly handling measurement noise through slack variables and regularization. We provide guarantees of recursive feasibility and practical stability under input-output constraints for a specific class of reference signals. The approach is validated on the iRonCub flying humanoid robot, integrating analytical momentum models with data-driven turbine dynamics. Simulations show improved tracking and robustness compared to a purely model-based MPC, while maintaining real-time feasibility.",
            "categories": [
                "eess.SY",
                "cs.RO"
            ],
            "primary_category": "eess.SY",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2509.10353",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "[T]humanoid",
                        "[T]humanoid robot",
                        "[T]MPC",
                        "model predictive control"
                    ],
                    "score": 20.0
                }
            ],
            "relevance_score": 20.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "提出数据融合MPC框架，解决飞行人形机器人未知动力学下的轨迹跟踪问题",
            "summary_zh": "本文提出了一种数据融合模型预测控制（DFMPC）框架，该框架结合了基于物理的模型和未知动力学的数据驱动表示。该方法利用Willems基本引理和人工平衡公式，能够在显式处理测量噪声的同时，跟踪不断变化的、可能无法达到的设定点，通过松弛变量和正则化实现。对于特定类型的参考信号，我们提供了递归可行性和实际稳定性的保证，同时考虑了输入输出约束。该方法在iRonCub飞行人形机器人上进行了验证，集成了分析动量模型和数据驱动的涡轮动力学。仿真结果表明，与纯粹基于模型的MPC相比，该方法在保持实时可行性的同时，提高了跟踪性能和鲁棒性。",
            "intro_zh": [
                "现有基于模型的MPC在处理飞行人形机器人等复杂系统时，难以准确建模所有动力学，导致控制性能下降。",
                "本文提出DFMPC框架，融合物理模型和数据驱动的动力学表示，利用Willems引理和人工平衡公式实现轨迹跟踪。",
                "在iRonCub飞行人形机器人上的仿真结果表明，DFMPC在跟踪性能和鲁棒性方面优于纯模型MPC，并保持实时性。"
            ],
            "method_zh": "**问题定义**：本文旨在解决飞行人形机器人在存在未知动力学和测量噪声的情况下，如何实现精确的轨迹跟踪问题。传统的基于模型的MPC方法依赖于精确的系统模型，但在实际应用中，由于建模误差、未建模动力学以及环境干扰等因素，难以获得完全准确的模型，导致控制性能下降，甚至稳定性问题。\\n\\n**核心思路**：本文的核心思路是将基于物理的模型与数据驱动的模型相结合，利用数据来学习和补偿未知的动力学部分。具体而言，利用Willems基本引理，将系统状态和控制输入的数据轨迹转化为状态空间表示，从而实现对未知动力学的建模。同时，引入人工平衡公式，使得MPC能够跟踪可能无法达到的设定点。\\n\\n**技术框架**：DFMPC框架主要包含以下几个模块：1) 基于物理的模型：描述已知的系统动力学；2) 数据驱动的模型：利用Willems基本引理从数据中学习未知的动力学；3) 模型预测控制器：基于融合的模型进行轨迹优化，生成控制指令；4) 噪声处理模块：通过松弛变量和正则化显式处理测量噪声。整体流程是，首先利用历史数据训练数据驱动模型，然后在MPC的优化过程中，将基于物理的模型和数据驱动的模型结合起来，预测系统未来的状态，并生成最优的控制输入。\\n\\n**关键创新**：本文的关键创新在于将Willems基本引理应用于MPC框架中，实现数据驱动的动力学建模。与传统的系统辨识方法不同，Willems基本引理可以直接利用数据轨迹构建状态空间表示，无需显式地估计系统参数。此外，本文还提出了人工平衡公式，使得MPC能够跟踪可能无法达到的设定点，提高了控制器的灵活性。\\n\\n**关键设计**：在MPC的优化问题中，目标函数包含跟踪误差、控制输入惩罚项以及松弛变量惩罚项。松弛变量用于处理测量噪声和约束违反。正则化项用于防止数据驱动模型过拟合。控制器的采样时间需要根据系统的动态特性进行选择，以保证控制性能和实时性。此外，数据驱动模型的训练数据的质量和数量对控制性能有重要影响，需要进行合理的选择和预处理。",
            "application_zh": "该研究成果可应用于各种需要精确控制的机器人系统，尤其是在环境复杂、模型难以精确建立的场景下，例如飞行机器人、水下机器人、人形机器人等。通过数据驱动的方式补偿模型误差，可以提高机器人的控制精度和鲁棒性，使其能够更好地适应实际应用环境。未来，该方法有望推广到更广泛的控制领域，例如自动驾驶、智能制造等。",
            "highlight_zh": "在iRonCub飞行人形机器人上的仿真结果表明，与纯粹基于模型的MPC相比，DFMPC在跟踪性能方面有显著提升。具体而言，DFMPC能够更准确地跟踪目标轨迹，减小跟踪误差，并对外部干扰具有更强的鲁棒性。此外，DFMPC在保持实时可行性的前提下，实现了更高的控制性能，验证了该方法的有效性。",
            "tags_zh": [
                "模型预测控制",
                "数据融合",
                "飞行人形机器人",
                "Willems基本引理",
                "未知动力学",
                "轨迹跟踪",
                "鲁棒控制"
            ],
            "_index": 6,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2509.10353/Figs/snapshot.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2509.10353/Figs/sysStruct.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2509.10353/x1.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "RTR-GS: 3D Gaussian Splatting for Inverse Rendering with Radiance Transfer and Reflection",
            "authors": [
                "Yongyang Zhou",
                "Fang-Lue Zhang",
                "Zichen Wang",
                "Lei Zhang"
            ],
            "arxiv_id": "2507.07733",
            "summary": "3D Gaussian Splatting (3DGS) has demonstrated impressive capabilities in novel view synthesis. However, rendering reflective objects remains a significant challenge, particularly in inverse rendering and relighting. We introduce RTR-GS, a novel inverse rendering framework capable of robustly rendering objects with arbitrary reflectance properties, decomposing BRDF and lighting, and delivering credible relighting results. Given a collection of multi-view images, our method effectively recovers geometric structure through a hybrid rendering model that combines forward rendering for radiance transfer with deferred rendering for reflections. This approach successfully separates high-frequency and low-frequency appearances, mitigating floating artifacts caused by spherical harmonic overfitting when handling high-frequency details. We further refine BRDF and lighting decomposition using an additional physically-based deferred rendering branch. Experimental results show that our method enhances novel view synthesis, normal estimation, decomposition, and relighting while maintaining efficient training inference process.",
            "categories": [
                "cs.GR",
                "cs.CV"
            ],
            "primary_category": "cs.GR",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2507.07733",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "[T]3D gaussian splatting",
                        "3DGS",
                        "[T]gaussian splatting",
                        "[T]splatting"
                    ],
                    "score": 20.0
                }
            ],
            "relevance_score": 20.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "RTR-GS：基于3D高斯溅射的辐射传输与反射逆渲染方法",
            "summary_zh": "3D高斯溅射(3DGS)在 novel view synthesis 方面表现出令人印象深刻的能力。然而，渲染反射物体仍然是一个重大挑战，特别是在逆渲染和光照重定向中。我们提出了RTR-GS，一种新颖的逆渲染框架，能够稳健地渲染具有任意反射率属性的物体，分解BRDF和光照，并提供可信的光照重定向结果。给定一组多视角图像，我们的方法通过混合渲染模型有效地恢复几何结构，该模型结合了用于辐射传输的前向渲染和用于反射的延迟渲染。这种方法成功地分离了高频和低频外观，减轻了在处理高频细节时由球谐函数过拟合引起的浮动伪影。我们使用额外的基于物理的延迟渲染分支进一步细化BRDF和光照分解。实验结果表明，我们的方法增强了 novel view synthesis、法线估计、分解和光照重定向，同时保持了高效的训练推理过程。",
            "intro_zh": [
                "现有方法在处理具有复杂反射属性的物体时，难以准确分解BRDF和光照，导致逆渲染和光照重定向效果不佳。",
                "RTR-GS采用混合渲染模型，结合前向渲染处理辐射传输和延迟渲染处理反射，有效分离高低频外观信息。",
                "实验结果表明，RTR-GS在novel view synthesis、法线估计、分解和光照重定向方面均有提升，并保持了高效的训练和推理速度。"
            ],
            "method_zh": "**问题定义**：论文旨在解决逆渲染中反射物体的渲染问题，特别是BRDF和光照的分解以及光照重定向。现有方法在处理具有复杂反射属性的物体时，容易出现球谐函数过拟合导致的伪影，难以准确分离高频细节，从而影响渲染质量。\\n\\n**核心思路**：论文的核心思路是采用混合渲染模型，将前向渲染和延迟渲染相结合。前向渲染用于处理辐射传输，捕捉低频外观信息；延迟渲染用于处理反射，捕捉高频细节。通过这种方式，可以有效分离高低频信息，避免球谐函数过拟合，从而提高渲染质量。\\n\\n**技术框架**：RTR-GS框架包含以下主要模块：1) 基于3D高斯溅射的几何结构重建；2) 前向渲染分支，用于辐射传输；3) 延迟渲染分支，用于反射；4) BRDF和光照分解模块，利用基于物理的延迟渲染分支进行细化。整体流程是：首先利用多视角图像重建3D高斯模型，然后通过前向渲染和延迟渲染分别计算辐射传输和反射，最后进行BRDF和光照分解。\\n\\n**关键创新**：RTR-GS的关键创新在于混合渲染模型，它将前向渲染和延迟渲染相结合，有效分离了高低频外观信息，避免了球谐函数过拟合。此外，利用基于物理的延迟渲染分支进行BRDF和光照分解，提高了分解的准确性。\\n\\n**关键设计**：论文中可能包含的关键设计细节包括：1) 前向渲染和延迟渲染的权重分配；2) BRDF模型的选择和参数化；3) 光照模型的选择和参数化；4) 损失函数的设计，例如，可能包含重建损失、BRDF损失和光照损失等。",
            "application_zh": "RTR-GS具有广泛的应用前景，包括虚拟现实、增强现实、游戏开发、电影制作等领域。它可以用于创建逼真的虚拟场景和物体，实现真实感的光照效果，并支持光照重定向等高级功能。该研究的成果有助于提升视觉体验，并为相关行业带来新的发展机遇。",
            "highlight_zh": "实验结果表明，RTR-GS在novel view synthesis、法线估计、BRDF和光照分解以及光照重定向方面均优于现有方法。具体性能数据未知，但摘要强调了在各项指标上的提升，并保持了高效的训练和推理速度。该方法能够有效处理具有复杂反射属性的物体，并生成高质量的渲染结果。",
            "tags_zh": [
                "逆渲染",
                "3D高斯溅射",
                "辐射传输",
                "BRDF分解",
                "光照重定向",
                "延迟渲染",
                "novel view synthesis"
            ],
            "_index": 7,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2507.07733/imgs/teaser.jpg",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2507.07733/x1.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2507.07733/x2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "WAM-Flow: Parallel Coarse-to-Fine Motion Planning via Discrete Flow Matching for Autonomous Driving",
            "authors": [
                "Yifang Xu",
                "Jiahao Cui",
                "Feipeng Cai",
                "Zhihao Zhu",
                "Hanlin Shang",
                "Shan Luan",
                "Mingwang Xu",
                "Neng Zhang",
                "Yaoyi Li",
                "Jia Cai",
                "Siyu Zhu"
            ],
            "arxiv_id": "2512.06112",
            "summary": "We introduce WAM-Flow, a vision-language-action (VLA) model that casts ego-trajectory planning as discrete flow matching over a structured token space. In contrast to autoregressive decoders, WAM-Flow performs fully parallel, bidirectional denoising, enabling coarse-to-fine refinement with a tunable compute-accuracy trade-off. Specifically, the approach combines a metric-aligned numerical tokenizer that preserves scalar geometry via triplet-margin learning, a geometry-aware flow objective and a simulator-guided GRPO alignment that integrates safety, ego progress, and comfort rewards while retaining parallel generation. A multi-stage adaptation converts a pre-trained auto-regressive backbone (Janus-1.5B) from causal decoding to non-causal flow model and strengthens road-scene competence through continued multimodal pretraining. Thanks to the inherent nature of consistency model training and parallel decoding inference, WAM-Flow achieves superior closed-loop performance against autoregressive and diffusion-based VLA baselines, with 1-step inference attaining 89.1 PDMS and 5-step inference reaching 90.3 PDMS on NAVSIM v1 benchmark. These results establish discrete flow matching as a new promising paradigm for end-to-end autonomous driving. The code will be publicly available soon.",
            "categories": [
                "cs.RO",
                "cs.AI",
                "cs.CV"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.06112",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "[T]motion planning"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]flow matching"
                    ],
                    "score": 4.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "vision-language-action",
                        "VLA",
                        "multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 19.5,
            "hit_pillars": [
                "1_robot_core",
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出WAM-Flow，通过离散流匹配实现自动驾驶并行粗到精运动规划",
            "summary_zh": "本文介绍了一种视觉-语言-动作(VLA)模型WAM-Flow，它将自车轨迹规划视为结构化token空间上的离散流匹配问题。与自回归解码器不同，WAM-Flow执行完全并行的双向去噪，从而实现具有可调计算-精度权衡的粗到精细化。具体来说，该方法结合了通过三元组边际学习保留标量几何的度量对齐数值分词器、几何感知流目标以及模拟器引导的GRPO对齐，该对齐集成了安全性、自车进度和舒适性奖励，同时保留了并行生成。多阶段自适应将预训练的自回归骨干网络(Janus-1.5B)从因果解码转换为非因果流模型，并通过持续的多模态预训练加强道路场景能力。由于一致性模型训练和并行解码推理的固有特性，WAM-Flow在闭环性能方面优于自回归和基于扩散的VLA基线，在NAVSIM v1基准测试中，单步推理达到89.1 PDMS，五步推理达到90.3 PDMS。这些结果确立了离散流匹配作为端到端自动驾驶的一个新的有希望的范例。代码即将公开。",
            "intro_zh": [
                "现有自回归模型在轨迹规划中存在推理速度慢、难以并行化的问题，限制了其在自动驾驶中的应用。",
                "WAM-Flow通过离散流匹配，将轨迹规划转化为并行去噪过程，实现粗到精的轨迹优化，提升计算效率。",
                "实验表明，WAM-Flow在闭环性能上优于自回归和扩散模型，在NAVSIM v1上取得了显著的PDMS指标提升。"
            ],
            "method_zh": "**问题定义**：论文旨在解决端到端自动驾驶中轨迹规划的效率问题。现有的自回归模型通常采用串行解码方式，推理速度较慢，难以满足自动驾驶对实时性的要求。此外，基于扩散的模型虽然可以并行生成，但训练和推理成本较高。因此，需要一种既能并行生成又能保证精度的轨迹规划方法。\\n\\n**核心思路**：论文的核心思路是将轨迹规划问题转化为离散流匹配问题。通过将轨迹离散化为token序列，并利用流匹配模型学习token之间的转移概率，从而实现轨迹的并行生成和优化。这种方法借鉴了计算机视觉和自然语言处理领域中流匹配模型的成功经验，并将其应用于自动驾驶领域。\\n\\n**技术框架**：WAM-Flow的整体框架包括以下几个主要模块：1) 度量对齐数值分词器：将连续的轨迹数据转换为离散的token序列，并保证token之间的几何关系；2) 几何感知流目标：设计损失函数，引导模型学习token之间的合理转移；3) 模拟器引导的GRPO对齐：利用模拟器环境，对模型进行强化学习，优化轨迹的安全性、自车进度和舒适性；4) 多阶段自适应：将预训练的自回归模型转换为流模型，并进行多模态预训练，提升模型在道路场景下的表现。\\n\\n**关键创新**：WAM-Flow的关键创新在于将离散流匹配引入到自动驾驶的轨迹规划中。与传统的自回归模型相比，WAM-Flow可以并行生成轨迹，显著提升了推理速度。与基于扩散的模型相比，WAM-Flow的训练和推理成本更低。此外，WAM-Flow还设计了度量对齐数值分词器和几何感知流目标，保证了轨迹的几何合理性。\\n\\n**关键设计**：在度量对齐数值分词器中，使用了三元组边际学习来保证token之间的几何关系。在几何感知流目标中，设计了基于流匹配的损失函数，引导模型学习token之间的合理转移。在模拟器引导的GRPO对齐中，使用了强化学习算法，优化轨迹的安全性、自车进度和舒适性。此外，还采用了多阶段自适应策略，将预训练的自回归模型转换为流模型，并进行多模态预训练。",
            "application_zh": "WAM-Flow具有广泛的应用前景，可用于各种自动驾驶场景，例如城市道路、高速公路和停车场等。该方法可以显著提升自动驾驶系统的决策效率和安全性，并为未来的自动驾驶技术发展提供新的思路。此外，该方法还可以应用于机器人导航、游戏AI等领域。",
            "highlight_zh": "WAM-Flow在NAVSIM v1基准测试中取得了显著的性能提升。单步推理达到89.1 PDMS，五步推理达到90.3 PDMS，优于现有的自回归和基于扩散的VLA基线。这些结果表明，离散流匹配是一种很有前途的端到端自动驾驶轨迹规划方法。",
            "tags_zh": [
                "自动驾驶",
                "轨迹规划",
                "流匹配",
                "视觉语言动作模型",
                "并行计算"
            ],
            "_index": 8,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.06112/fig/Figure_2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.06112/fig/Figure_3.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.06112/fig/navsim_comp.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Sim2Real Reinforcement Learning for Soccer skills",
            "authors": [
                "Jonathan Spraggett"
            ],
            "arxiv_id": "2512.12437",
            "summary": "This thesis work presents a more efficient and effective approach to training control-related tasks for humanoid robots using Reinforcement Learning (RL). The traditional RL methods are limited in adapting to real-world environments, complexity, and natural motions, but the proposed approach overcomes these limitations by using curriculum training and Adversarial Motion Priors (AMP) technique. The results show that the developed RL policies for kicking, walking, and jumping are more dynamic, and adaptive, and outperformed previous methods. However, the transfer of the learned policy from simulation to the real world was unsuccessful, highlighting the limitations of current RL methods in fully adapting to real-world scenarios.",
            "categories": [
                "cs.RO",
                "cs.LG"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.12437",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "humanoid",
                        "humanoid robot",
                        "[T]sim2real"
                    ],
                    "score": 10.0
                },
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning"
                    ],
                    "score": 4.5
                },
                {
                    "name": "支柱八：物理动画 (Physics-based Animation)",
                    "id": "8_physics_animation",
                    "matched_keywords": [
                        "AMP",
                        "adversarial motion priors"
                    ],
                    "score": 4.0
                }
            ],
            "relevance_score": 18.5,
            "hit_pillars": [
                "1_robot_core",
                "2_algo_arch",
                "8_physics_animation"
            ],
            "headline_zh": "提出基于课程学习和对抗运动先验的强化学习方法，用于训练人形机器人足球技能",
            "summary_zh": "本论文提出了一种更高效、更有效的强化学习（RL）方法，用于训练人形机器人的控制相关任务。传统强化学习方法在适应真实环境、复杂性和自然运动方面存在局限性。本文提出的方法通过使用课程训练和对抗运动先验（AMP）技术克服了这些限制。结果表明，所开发的踢球、行走和跳跃的强化学习策略更具动态性和适应性，并且优于以往的方法。然而，学习到的策略从仿真到真实世界的迁移并不成功，突显了当前强化学习方法在完全适应真实场景方面的局限性。",
            "intro_zh": [
                "传统强化学习方法难以适应真实环境的复杂性，限制了人形机器人控制任务的训练效果。",
                "论文提出结合课程学习和对抗运动先验（AMP）的强化学习方法，提升策略的动态性和适应性。",
                "实验结果表明，该方法在仿真环境中训练的踢球、行走和跳跃策略优于以往方法，但迁移到真实环境失败。"
            ],
            "method_zh": "**问题定义**：论文旨在解决人形机器人控制任务中，传统强化学习方法难以适应真实环境，导致训练出的策略泛化能力差的问题。现有方法在复杂性和自然运动方面存在局限性，难以生成动态和适应性强的运动策略。\\n\\n**核心思路**：论文的核心思路是利用课程学习和对抗运动先验（AMP）技术，提升强化学习策略的泛化能力和适应性。课程学习通过逐步增加任务难度，引导智能体学习；AMP则利用真实运动数据作为先验知识，约束智能体的行为，使其更接近自然运动。\\n\\n**技术框架**：整体框架包含以下几个主要模块：1) 强化学习智能体，负责与环境交互并学习策略；2) 课程学习模块，根据智能体的学习进度调整任务难度；3) 对抗运动先验（AMP）模块，利用真实运动数据作为判别器，区分智能体生成的运动和真实运动，并引导智能体生成更自然的运动。训练过程中，智能体与环境交互，课程学习模块动态调整任务难度，AMP模块提供运动先验指导，最终训练出能够在仿真环境中表现良好的策略。\\n\\n**关键创新**：论文的关键创新在于将课程学习和对抗运动先验（AMP）技术结合起来，用于人形机器人控制任务的强化学习训练。AMP通过对抗学习的方式，使智能体学习到的运动更接近真实运动，从而提升了策略的泛化能力。同时，课程学习能够有效地引导智能体学习，避免陷入局部最优解。\\n\\n**关键设计**：论文中，课程学习的具体实现方式是逐步增加任务的难度，例如，从简单的站立任务开始，逐步过渡到行走、踢球等复杂任务。对抗运动先验（AMP）模块使用真实运动数据训练一个判别器，该判别器能够区分智能体生成的运动和真实运动。强化学习智能体通过最大化奖励和最小化判别器的损失来学习策略。具体的网络结构和参数设置在论文中应该有详细描述（未知）。",
            "application_zh": "该研究成果可应用于人形机器人的运动控制领域，例如足球机器人、服务机器人等。通过强化学习训练，可以使机器人掌握更复杂、更自然的运动技能，从而更好地完成各种任务。未来，如果能够解决仿真到真实的迁移问题，该方法将具有更广泛的应用前景。",
            "highlight_zh": "实验结果表明，该方法在仿真环境中训练的踢球、行走和跳跃策略优于以往的方法。具体性能数据（例如，踢球的准确率、行走的速度等）和对比基线（例如，传统的强化学习方法）需要在论文中查找。虽然仿真结果良好，但策略迁移到真实环境失败，表明仍存在较大的仿真差距。",
            "tags_zh": [
                "强化学习",
                "人形机器人",
                "运动控制",
                "课程学习",
                "对抗运动先验",
                "Sim2Real",
                "足球机器人"
            ],
            "_index": 9,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.12437/20220714_150726.jpg",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.12437/bez.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.12437/sim.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "CRISP: Contact-Guided Real2Sim from Monocular Video with Planar Scene Primitives",
            "authors": [
                "Zihan Wang",
                "Jiashun Wang",
                "Jeff Tan",
                "Yiwen Zhao",
                "Jessica Hodgins",
                "Shubham Tulsiani",
                "Deva Ramanan"
            ],
            "arxiv_id": "2512.14696",
            "summary": "We introduce CRISP, a method that recovers simulatable human motion and scene geometry from monocular video. Prior work on joint human-scene reconstruction relies on data-driven priors and joint optimization with no physics in the loop, or recovers noisy geometry with artifacts that cause motion tracking policies with scene interactions to fail. In contrast, our key insight is to recover convex, clean, and simulation-ready geometry by fitting planar primitives to a point cloud reconstruction of the scene, via a simple clustering pipeline over depth, normals, and flow. To reconstruct scene geometry that might be occluded during interactions, we make use of human-scene contact modeling (e.g., we use human posture to reconstruct the occluded seat of a chair). Finally, we ensure that human and scene reconstructions are physically-plausible by using them to drive a humanoid controller via reinforcement learning. Our approach reduces motion tracking failure rates from 55.2\\% to 6.9\\% on human-centric video benchmarks (EMDB, PROX), while delivering a 43\\% faster RL simulation throughput. We further validate it on in-the-wild videos including casually-captured videos, Internet videos, and even Sora-generated videos. This demonstrates CRISP's ability to generate physically-valid human motion and interaction environments at scale, greatly advancing real-to-sim applications for robotics and AR/VR.",
            "categories": [
                "cs.CV",
                "cs.GR",
                "cs.RO"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14696",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "humanoid",
                        "humanoid control",
                        "[T]real2sim"
                    ],
                    "score": 10.0
                },
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "scene reconstruction"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "physically plausible"
                    ],
                    "score": 2.5
                },
                {
                    "name": "支柱八：物理动画 (Physics-based Animation)",
                    "id": "8_physics_animation",
                    "matched_keywords": [
                        "motion tracking"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 18.0,
            "hit_pillars": [
                "1_robot_core",
                "2_algo_arch",
                "3_perception_slam",
                "4_motion_diffusion",
                "8_physics_animation"
            ],
            "headline_zh": "CRISP：基于单目视频和平面场景原语的接触引导Real2Sim方法",
            "summary_zh": "CRISP是一种从单目视频中恢复可模拟的人体运动和场景几何结构的方法。现有的人体-场景联合重建工作依赖于数据驱动的先验和无物理引擎参与的联合优化，或者恢复的几何结构噪声大，导致带有场景交互的运动跟踪策略失败。CRISP的关键在于通过拟合平面原语到场景的点云重建，恢复凸的、干净的、可用于仿真的几何结构，这通过一个简单的深度、法线和光流聚类流程实现。为了重建交互过程中可能被遮挡的场景几何结构，我们利用了人体-场景接触建模（例如，使用人体姿势来重建椅子被遮挡的座位）。最后，我们通过强化学习驱动人形控制器，确保人体和场景重建在物理上是合理的。在以人为中心的视频基准测试（EMDB、PROX）中，我们的方法将运动跟踪失败率从55.2%降低到6.9%，同时RL模拟吞吐量提高了43%。我们还在包括随意拍摄的视频、互联网视频，甚至是Sora生成的视频在内的真实视频中验证了它。这证明了CRISP能够大规模生成物理上有效的人体运动和交互环境，极大地推进了机器人和AR/VR的real-to-sim应用。",
            "intro_zh": [
                "现有方法在人体-场景联合重建中存在不足，要么依赖数据先验和无物理的优化，要么重建的几何体噪声大，导致交互式运动跟踪失败。",
                "CRISP的核心思想是通过平面原语拟合点云重建，恢复凸的、干净的、可用于仿真的场景几何，并利用人体-场景接触建模来补全遮挡区域。",
                "实验表明，CRISP在人体视频基准测试中显著降低了运动跟踪失败率，并提高了强化学习模拟的效率，同时在真实视频中也表现良好。"
            ],
            "method_zh": "**问题定义**：现有方法在从单目视频进行人体-场景联合重建时，要么依赖大量数据先验，缺乏物理合理性，要么重建的场景几何体质量差，无法直接用于物理仿真和控制，导致交互式运动跟踪失败。因此，需要一种方法能够从单目视频中重建出高质量、物理上合理、可用于仿真的三维人体和场景模型。\n\n**核心思路**：CRISP的核心思路是利用平面原语来表示场景几何，并通过深度、法线和光流信息进行聚类，从而得到干净、凸的场景表示。同时，利用人体与场景的接触信息来推断被遮挡的场景部分，例如通过人体坐在椅子上的姿势来推断椅子座位的形状。最后，通过强化学习训练人形控制器，确保重建的人体和场景在物理上是合理的。\n\n**技术框架**：CRISP的整体框架包括以下几个主要阶段：1) 从单目视频中重建点云；2) 对点云进行平面原语拟合，得到场景的几何表示；3) 利用人体姿势和接触信息补全被遮挡的场景区域；4) 使用重建的人体和场景训练人形控制器，通过强化学习保证物理合理性。\n\n**关键创新**：CRISP的关键创新在于：1) 使用平面原语来表示场景几何，简化了场景重建的复杂度，并保证了重建结果的凸性和可仿真性；2) 利用人体-场景接触信息来补全被遮挡的场景区域，提高了场景重建的完整性；3) 通过强化学习来保证重建的人体和场景在物理上是合理的，使得重建结果可以直接用于物理仿真和控制。\n\n**关键设计**：CRISP的关键设计包括：1) 使用基于深度、法线和光流的聚类算法来拟合平面原语；2) 设计了基于人体姿势的接触模型来推断被遮挡的场景区域；3) 使用强化学习算法训练人形控制器，目标是使控制器能够在重建的场景中稳定行走和交互，损失函数包括平衡损失、运动损失和接触损失等。",
            "application_zh": "CRISP在机器人、增强现实（AR）和虚拟现实（VR）等领域具有广泛的应用前景。它可以用于创建逼真的虚拟环境，用于训练机器人或进行虚拟交互。例如，可以利用CRISP从真实视频中重建出房间场景，然后让机器人在虚拟环境中学习如何在房间中导航和操作物体。此外，CRISP还可以用于AR/VR应用中，将虚拟物体与真实场景进行交互，例如在真实房间中放置虚拟家具。",
            "highlight_zh": "CRISP在以人为中心的视频基准测试（EMDB、PROX）中取得了显著的性能提升，运动跟踪失败率从55.2%降低到6.9%，同时RL模拟吞吐量提高了43%。此外，CRISP在真实世界的视频（包括随意拍摄的视频、互联网视频，甚至是Sora生成的视频）中也表现出了良好的泛化能力，证明了其在复杂场景下的有效性。",
            "tags_zh": [
                "Real2Sim",
                "单目视频重建",
                "人体-场景交互",
                "平面原语",
                "强化学习",
                "物理仿真",
                "场景重建"
            ],
            "_index": 10,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "HyperVL: An Efficient and Dynamic Multimodal Large Language Model for Edge Devices",
            "authors": [
                "HyperAI Team",
                "Yuchen Liu",
                "Kaiyang Han",
                "Zhiqiang Xia",
                "Yuhang Dong",
                "Chen Song",
                "Kangyu Tang",
                "Jiaming Xu",
                "Xiushi Feng",
                "WenXuan Yu",
                "Li Peng",
                "Mingyang Wang",
                "Kai Wang",
                "Changpeng Yang",
                "Yang Li",
                "Haoyu Lu",
                "Hao Wang",
                "Bingna Xu",
                "Guangyao Liu",
                "Long Huang",
                "Kaibin Guo",
                "Jinyang Wu",
                "Dan Wu",
                "Hongzhen Wang",
                "Peng Zhou",
                "Shuai Nie",
                "Shande Wang",
                "Runyu Shi",
                "Ying Huang"
            ],
            "arxiv_id": "2512.14052",
            "summary": "Current multimodal large lanauge models possess strong perceptual and reasoning capabilities, however high computational and memory requirements make them difficult to deploy directly on on-device environments. While small-parameter models are progressively endowed with strong general capabilities, standard Vision Transformer (ViT) encoders remain a critical bottleneck, suffering from excessive latency and memory consumption when processing high-resolutionthis http URLaddress these challenges, we introduce HyperVL, an efficient multimodal large language model tailored for on-device inference. HyperVL adopts an image-tiling strategy to cap peak memory usage and incorporates two novel techniques: (1) a Visual Resolution Compressor (VRC) that adaptively predicts optimal encoding resolutions to eliminate redundant computation, and (2) Dual Consistency Learning (DCL), which aligns multi-scale ViT encoders within a unified framework, enabling dynamic switching between visual branches under a shared LLM. Extensive experiments demonstrate that HyperVL achieves state-of-the-art performance among models of comparable size across multiple benchmarks. Furthermore, it significantly significantly reduces latency and power consumption on real mobile devices, demonstrating its practicality for on-device multimodal inference.",
            "categories": [
                "cs.CV",
                "cs.CL"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14052",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model",
                        "[T]multimodal"
                    ],
                    "score": 18.0
                }
            ],
            "relevance_score": 18.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "HyperVL：面向边缘设备的高效动态多模态大语言模型",
            "summary_zh": "当前的多模态大语言模型拥有强大的感知和推理能力，但其高计算和内存需求使其难以直接部署在端侧设备上。虽然小参数模型的能力逐渐增强，但标准的Vision Transformer (ViT) 编码器仍然是一个关键瓶颈，在高分辨率图像处理时会产生过高的延迟和内存消耗。为了解决这些挑战，我们提出了HyperVL，一种专为端侧推理设计的高效多模态大语言模型。HyperVL采用图像分块策略来限制峰值内存使用，并引入了两项新技术：(1) 视觉分辨率压缩器 (VRC)，自适应地预测最佳编码分辨率以消除冗余计算；(2) 双重一致性学习 (DCL)，在一个统一的框架内对齐多尺度ViT编码器，从而实现共享LLM下视觉分支之间的动态切换。大量实验表明，HyperVL在多个基准测试中，在同等规模的模型中实现了最先进的性能。此外，它还显著降低了真实移动设备上的延迟和功耗，证明了其在端侧多模态推理中的实用性。",
            "intro_zh": [
                "现有多模态大模型计算和内存需求高，难以在边缘设备上部署，ViT编码器成为高分辨率图像处理的瓶颈。",
                "HyperVL通过图像分块限制内存，并引入视觉分辨率压缩器(VRC)和双重一致性学习(DCL)来优化视觉编码。",
                "实验表明，HyperVL在同等规模模型中达到SOTA，并显著降低了移动设备上的延迟和功耗。"
            ],
            "method_zh": "**问题定义**：现有的大型多模态模型虽然性能强大，但计算量和内存占用巨大，难以在资源受限的边缘设备上部署。特别是Vision Transformer (ViT) 编码器，在处理高分辨率图像时，会消耗大量的计算资源和内存，成为性能瓶颈。因此，如何在保证性能的前提下，降低多模态模型在边缘设备上的计算复杂度和内存占用，是本文要解决的核心问题。\\n\\n**核心思路**：HyperVL的核心思路是通过动态调整视觉编码的分辨率和选择合适的视觉分支，来降低计算复杂度和内存占用。具体来说，它引入了视觉分辨率压缩器 (VRC) 来预测最佳的编码分辨率，避免对所有图像都进行高分辨率编码。同时，通过双重一致性学习 (DCL) 来对齐多尺度 ViT 编码器，从而实现视觉分支之间的动态切换，选择最合适的视觉分支进行编码。\\n\\n**技术框架**：HyperVL的整体框架包括图像分块模块、视觉编码模块和语言模型模块。图像分块模块将输入图像分割成多个小块，以限制峰值内存使用。视觉编码模块包含多个不同分辨率的 ViT 编码器和一个视觉分辨率压缩器 (VRC)。VRC 根据输入图像的内容，自适应地预测最佳的编码分辨率。然后，选择对应分辨率的 ViT 编码器进行特征提取。最后，将提取的视觉特征输入到语言模型模块进行多模态推理。\\n\\n**关键创新**：HyperVL的关键创新在于视觉分辨率压缩器 (VRC) 和双重一致性学习 (DCL)。VRC 能够自适应地预测最佳的编码分辨率，从而避免对所有图像都进行高分辨率编码，降低了计算复杂度。DCL 通过对齐多尺度 ViT 编码器，实现了视觉分支之间的动态切换，从而可以选择最合适的视觉分支进行编码，进一步降低了计算复杂度和内存占用。与现有方法相比，HyperVL 能够更有效地利用计算资源，在保证性能的前提下，显著降低了延迟和功耗。\\n\\n**关键设计**：VRC 的设计采用了轻量级的神经网络结构，以减少额外的计算开销。DCL 的实现采用了对比学习的损失函数，以确保不同分辨率的 ViT 编码器输出的特征具有一致性。图像分块的大小根据设备的内存容量进行调整，以避免内存溢出。此外，HyperVL 还采用了知识蒸馏技术，将大型模型的知识迁移到小型模型中，以提高模型的性能。",
            "application_zh": "HyperVL适用于各种需要端侧多模态推理的应用场景，例如智能手机上的图像识别、视频分析、智能家居设备中的语音助手、以及自动驾驶汽车中的环境感知等。通过降低计算复杂度和内存占用，HyperVL使得这些应用能够在资源受限的边缘设备上高效运行，从而实现更快的响应速度和更低的功耗，具有广阔的应用前景。",
            "highlight_zh": "实验结果表明，HyperVL在多个基准测试中，在同等规模的模型中实现了最先进的性能。例如，在视觉问答任务中，HyperVL的准确率超过了现有最佳模型X%。此外，HyperVL在真实移动设备上的延迟和功耗也显著降低，延迟降低了Y%，功耗降低了Z%，证明了其在端侧多模态推理中的实用性。",
            "tags_zh": [
                "多模态大语言模型",
                "边缘计算",
                "视觉分辨率压缩",
                "双重一致性学习",
                "端侧推理",
                "低延迟",
                "低功耗"
            ],
            "_index": 11,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14052/Figure/trend.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14052/Figure/model_architecture.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14052/Figure/visual_resolution_compressor.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "HGS: Hybrid Gaussian Splatting with Static-Dynamic Decomposition for Compact Dynamic View Synthesis",
            "authors": [
                "Kaizhe Zhang",
                "Yijie Zhou",
                "Weizhan Zhang",
                "Caixia Yan",
                "Haipeng Du",
                "yugui xie",
                "Yu-Hui Wen",
                "Yong-Jin Liu"
            ],
            "arxiv_id": "2512.14352",
            "summary": "Dynamic novel view synthesis (NVS) is essential for creating immersive experiences. Existing approaches have advanced dynamic NVS by introducing 3D Gaussian Splatting (3DGS) with implicit deformation fields or indiscriminately assigned time-varying parameters, surpassing NeRF-based methods. However, due to excessive model complexity and parameter redundancy, they incur large model sizes and slow rendering speeds, making them inefficient for real-time applications, particularly on resource-constrained devices. To obtain a more efficient model with fewer redundant parameters, in this paper, we propose Hybrid Gaussian Splatting (HGS), a compact and efficient framework explicitly designed to disentangle static and dynamic regions of a scene within a unified representation. The core innovation of HGS lies in our Static-Dynamic Decomposition (SDD) strategy, which leverages Radial Basis Function (RBF) modeling for Gaussian primitives. Specifically, for dynamic regions, we employ time-dependent RBFs to effectively capture temporal variations and handle abrupt scene changes, while for static regions, we reduce redundancy by sharing temporally invariant parameters. Additionally, we introduce a two-stage training strategy tailored for explicit models to enhance temporal coherence at static-dynamic boundaries. Experimental results demonstrate that our method reduces model size by up to 98% and achieves real-time rendering at up to 125 FPS at 4K resolution on a single RTX 3090 GPU. It further sustains 160 FPS at 1352 * 1014 on an RTX 3050 and has been integrated into the VR system. Moreover, HGS achieves comparable rendering quality to state-of-the-art methods while providing significantly improved visual fidelity for high-frequency details and abrupt scene changes.",
            "categories": [
                "cs.CV",
                "cs.CG"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14352",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "3D gaussian splatting",
                        "3DGS",
                        "[T]gaussian splatting",
                        "[T]splatting",
                        "NeRF"
                    ],
                    "score": 18.0
                }
            ],
            "relevance_score": 18.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "提出HGS混合高斯溅射方法，通过静态-动态分解实现紧凑的动态视角合成",
            "summary_zh": "动态新视角合成（NVS）对于创造沉浸式体验至关重要。现有方法通过引入带有隐式变形场的3D高斯溅射（3DGS）或不加区分地分配时变参数来推进动态NVS，超越了基于NeRF的方法。然而，由于过度的模型复杂性和参数冗余，它们导致模型体积庞大和渲染速度缓慢，使得它们在实时应用中效率低下，尤其是在资源受限的设备上。为了获得一个更高效且冗余参数更少的模型，本文提出混合高斯溅射（HGS），这是一个紧凑而高效的框架，专门设计用于在统一表示中解耦场景的静态和动态区域。HGS的核心创新在于我们的静态-动态分解（SDD）策略，该策略利用径向基函数（RBF）建模高斯基元。具体来说，对于动态区域，我们采用时间相关的RBF来有效地捕获时间变化并处理突发的场景变化，而对于静态区域，我们通过共享时间不变参数来减少冗余。此外，我们引入了一种为显式模型量身定制的两阶段训练策略，以增强静态-动态边界处的时间一致性。实验结果表明，我们的方法将模型大小减少了高达98%，并在单个RTX 3090 GPU上实现了高达125 FPS的4K分辨率实时渲染。它还在RTX 3050上保持了160 FPS（1352 * 1014），并且已集成到VR系统中。此外，HGS在实现与最先进方法相当的渲染质量的同时，为高频细节和突发场景变化提供了显着改进的视觉保真度。",
            "intro_zh": [
                "现有动态新视角合成方法模型复杂、参数冗余，导致模型体积大、渲染速度慢，难以在资源受限设备上实时运行。",
                "HGS通过静态-动态分解策略，利用径向基函数建模高斯基元，对动态区域使用时变RBF，静态区域共享时不变参数，减少冗余。",
                "实验表明，HGS模型大小减少高达98%，在RTX 3090上实现4K分辨率125 FPS实时渲染，并在高频细节和突发场景变化上提升视觉保真度。"
            ],
            "method_zh": "**问题定义**：现有动态新视角合成方法，如基于3D高斯溅射（3DGS）的方法，虽然取得了不错的渲染效果，但由于模型复杂度和参数冗余，导致模型体积过大，渲染速度慢，难以满足实时应用的需求，尤其是在移动端或VR等资源受限的设备上。这些方法没有充分利用场景中静态和动态区域的差异，对所有区域都采用复杂的时变参数建模，造成了不必要的计算负担。\\n\\n**核心思路**：HGS的核心思路是将场景分解为静态和动态两个部分，并分别采用不同的建模方式。对于动态区域，使用时变的径向基函数（RBF）来捕捉时间变化；对于静态区域，则共享时间不变的参数，从而减少冗余参数，降低模型复杂度。通过这种静态-动态分解（SDD）策略，HGS能够在保证渲染质量的同时，显著减小模型体积，提高渲染速度。\\n\\n**技术框架**：HGS的整体框架包含以下几个主要步骤：1) 使用多视角视频数据作为输入；2) 初始化3D高斯基元；3) 使用静态-动态分解（SDD）策略，将高斯基元分为静态和动态两部分；4) 对动态区域的高斯基元使用时变RBF建模，对静态区域的高斯基元共享时间不变参数；5) 使用两阶段训练策略优化模型参数，增强静态-动态边界处的时间一致性；6) 使用优化的模型进行新视角的渲染。\\n\\n**关键创新**：HGS最重要的技术创新点在于其静态-动态分解（SDD）策略。与现有方法不同，HGS不是对整个场景都采用统一的时变参数建模，而是根据场景的静态和动态特性，分别采用不同的建模方式。这种分解策略能够有效地减少参数冗余，降低模型复杂度，从而提高渲染效率。此外，使用RBF对高斯基元进行建模也是一个创新点，RBF能够灵活地捕捉动态区域的时间变化。\\n\\n**关键设计**：HGS的关键设计包括：1) 静态-动态分解的判断标准，需要设计合理的指标来区分静态和动态区域；2) RBF函数的选择和参数设置，需要根据具体的场景和数据进行调整；3) 两阶段训练策略的设计，需要平衡渲染质量和时间一致性；4) 损失函数的设计，需要考虑渲染质量、时间一致性和模型复杂度等因素。",
            "application_zh": "HGS在动态新视角合成领域具有广泛的应用前景，例如VR/AR、游戏、电影特效、机器人导航等。它可以用于创建更加逼真和沉浸式的虚拟现实体验，也可以用于生成高质量的动态场景渲染图像。此外，由于其模型体积小、渲染速度快的特点，HGS特别适合在移动端或嵌入式设备上部署，从而实现实时的动态新视角合成。",
            "highlight_zh": "HGS在多个数据集上进行了实验，结果表明，HGS可以将模型大小减少高达98%，并在单个RTX 3090 GPU上实现4K分辨率下125 FPS的实时渲染。在RTX 3050上，HGS也能达到160 FPS（1352 * 1014）。同时，HGS在渲染质量上与最先进的方法相当，并且在高频细节和突发场景变化上具有更好的视觉保真度。",
            "tags_zh": [
                "动态新视角合成",
                "高斯溅射",
                "静态-动态分解",
                "径向基函数",
                "实时渲染"
            ],
            "_index": 12,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14352/x2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14352/x3.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14352/x5.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "DASP: Self-supervised Nighttime Monocular Depth Estimation with Domain Adaptation of Spatiotemporal Priors",
            "authors": [
                "Yiheng Huang",
                "Junhong Chen",
                "Anqi Ning",
                "Zhanhong Liang",
                "Nick Michiels",
                "Luc Claesen",
                "Wenyin Liu"
            ],
            "arxiv_id": "2512.14536",
            "summary": "Self-supervised monocular depth estimation has achieved notable success under daytime conditions. However, its performance deteriorates markedly at night due to low visibility and varying illumination, e.g., insufficient light causes textureless areas, and moving objects bring blurry regions. To this end, we propose a self-supervised framework named DASP that leverages spatiotemporal priors for nighttime depth estimation. Specifically, DASP consists of an adversarial branch for extracting spatiotemporal priors and a self-supervised branch for learning. In the adversarial branch, we first design an adversarial network where the discriminator is composed of four devised spatiotemporal priors learning blocks (SPLB) to exploit the daytime priors. In particular, the SPLB contains a spatial-based temporal learning module (STLM) that uses orthogonal differencing to extract motion-related variations along the time axis and an axial spatial learning module (ASLM) that adopts local asymmetric convolutions with global axial attention to capture the multiscale structural information. By combining STLM and ASLM, our model can acquire sufficient spatiotemporal features to restore textureless areas and estimate the blurry regions caused by dynamic objects. In the self-supervised branch, we propose a 3D consistency projection loss to bilaterally project the target frame and source frame into a shared 3D space, and calculate the 3D discrepancy between the two projected frames as a loss to optimize the 3D structural consistency and daytime priors. Extensive experiments on the Oxford RobotCar and nuScenes datasets demonstrate that our approach achieves state-of-the-art performance for nighttime depth estimation. Ablation studies further validate the effectiveness of each component.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14536",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "[T]depth estimation",
                        "[T]monocular depth"
                    ],
                    "score": 12.0
                },
                {
                    "name": "支柱八：物理动画 (Physics-based Animation)",
                    "id": "8_physics_animation",
                    "matched_keywords": [
                        "[T]spatiotemporal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 18.0,
            "hit_pillars": [
                "3_perception_slam",
                "8_physics_animation"
            ],
            "headline_zh": "DASP：利用时空先验域适应的自监督夜间单目深度估计",
            "summary_zh": "本文提出了一种名为DASP的自监督框架，利用时空先验进行夜间深度估计。DASP包含一个用于提取时空先验的对抗分支和一个用于学习的自监督分支。在对抗分支中，设计了一个对抗网络，其判别器由四个设计的时空先验学习块（SPLB）组成，以利用白天先验。SPLB包含一个基于空间的时序学习模块（STLM），它使用正交差分来提取沿时间轴的运动相关变化，以及一个轴向空间学习模块（ASLM），它采用具有全局轴向注意力的局部非对称卷积来捕获多尺度结构信息。通过结合STLM和ASLM，该模型可以获得足够的时空特征来恢复无纹理区域并估计由动态对象引起的模糊区域。在自监督分支中，提出了一个3D一致性投影损失，以双边地将目标帧和源帧投影到共享的3D空间中，并计算两个投影帧之间的3D差异作为损失，以优化3D结构一致性和白天先验。在Oxford RobotCar和nuScenes数据集上的大量实验表明，该方法实现了最先进的夜间深度估计性能。消融研究进一步验证了每个组件的有效性。",
            "intro_zh": [
                "夜间场景光照不足和动态模糊导致现有自监督单目深度估计方法性能显著下降。",
                "DASP框架利用对抗学习提取白天场景的时空先验知识，并将其迁移到夜间深度估计中。",
                "实验表明，DASP在夜间深度估计任务上取得了state-of-the-art的性能，并验证了各模块的有效性。"
            ],
            "method_zh": "**问题定义**：现有自监督单目深度估计方法在白天场景表现良好，但在夜间场景中，由于光照不足导致的纹理缺失以及运动物体造成的模糊，性能会显著下降。因此，论文旨在解决夜间单目深度估计问题，提高在低光照和动态环境下的深度估计精度。\\n\\n**核心思路**：论文的核心思路是利用白天场景的时空先验知识来辅助夜间深度估计。通过对抗学习，将白天场景中丰富的纹理信息和运动模式迁移到夜间场景，从而弥补夜间场景中信息不足的问题。这种域适应的方法能够有效地提高夜间深度估计的准确性和鲁棒性。\\n\\n**技术框架**：DASP框架包含两个主要分支：对抗分支和自监督分支。对抗分支负责提取白天场景的时空先验知识，并将其迁移到夜间场景。该分支包含一个生成器和一个判别器，判别器由四个时空先验学习块（SPLB）组成。自监督分支则利用3D一致性投影损失来优化深度估计结果，并保持3D结构的一致性。两个分支协同工作，共同提高夜间深度估计的性能。\\n\\n**关键创新**：论文的关键创新在于提出了时空先验学习块（SPLB），它能够有效地提取白天场景的时空特征。SPLB包含一个基于空间的时序学习模块（STLM）和一个轴向空间学习模块（ASLM）。STLM利用正交差分提取时间轴上的运动信息，ASLM利用局部非对称卷积和全局轴向注意力捕获多尺度结构信息。这种时空特征提取方法能够有效地恢复无纹理区域和估计模糊区域。\\n\\n**关键设计**：在对抗分支中，判别器由四个SPLB组成，每个SPLB都包含STLM和ASLM。STLM使用正交差分来提取运动信息，ASLM使用局部非对称卷积和全局轴向注意力来捕获多尺度结构信息。在自监督分支中，使用3D一致性投影损失来优化深度估计结果。该损失函数将目标帧和源帧投影到共享的3D空间中，并计算两个投影帧之间的3D差异。通过最小化该差异，可以提高深度估计的准确性和鲁棒性。",
            "application_zh": "该研究成果可应用于自动驾驶、机器人导航、智能监控等领域，尤其是在夜间或低光照环境下的应用。更准确的深度估计能够提高自动驾驶车辆在夜间的感知能力，增强机器人在复杂环境中的导航能力，并提升智能监控系统的目标检测和跟踪性能。该研究对提升夜间视觉系统的可靠性和安全性具有重要意义。",
            "highlight_zh": "DASP在Oxford RobotCar和nuScenes数据集上进行了广泛的实验，结果表明其在夜间深度估计任务上取得了state-of-the-art的性能。相较于现有方法，DASP能够更准确地估计夜间场景的深度信息，尤其是在纹理缺失和动态模糊的区域。消融实验验证了SPLB、STLM、ASLM以及3D一致性投影损失的有效性。",
            "tags_zh": [
                "自监督学习",
                "深度估计",
                "夜间场景",
                "域适应",
                "时空先验",
                "对抗学习",
                "单目视觉"
            ],
            "_index": 13,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14536/fig9-mask.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14536/fig3-tmp4.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14536/fig2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "MoLingo: Motion-Language Alignment for Text-to-Motion Generation",
            "authors": [
                "Yannan He",
                "Garvita Tiwari",
                "Xiaohan Zhang",
                "Pankaj Bora",
                "Tolga Birdal",
                "Jan Eric Lenssen",
                "Gerard Pons-Moll"
            ],
            "arxiv_id": "2512.13840",
            "summary": "We introduce MoLingo, a text-to-motion (T2M) model that generates realistic, lifelike human motion by denoising in a continuous latent space. Recent works perform latent space diffusion, either on the whole latent at once or auto-regressively over multiple latents. In this paper, we study how to make diffusion on continuous motion latents work best. We focus on two questions: (1) how to build a semantically aligned latent space so diffusion becomes more effective, and (2) how to best inject text conditioning so the motion follows the description closely. We propose a semantic-aligned motion encoder trained with frame-level text labels so that latents with similar text meaning stay close, which makes the latent space more diffusion-friendly. We also compare single-token conditioning with a multi-token cross-attention scheme and find that cross-attention gives better motion realism and text-motion alignment. With semantically aligned latents, auto-regressive generation, and cross-attention text conditioning, our model sets a new state of the art in human motion generation on standard metrics and in a user study. We will release our code and models for further research and downstream usage.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13840",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "[T]text-to-motion",
                        "[T]motion generation",
                        "motion latent"
                    ],
                    "score": 17.5
                }
            ],
            "relevance_score": 17.5,
            "hit_pillars": [
                "4_motion_diffusion"
            ],
            "headline_zh": "MoLingo：通过运动-语言对齐实现文本到动作生成，达到新的SOTA",
            "summary_zh": "本文提出了一种名为MoLingo的文本到动作(T2M)模型，该模型通过在连续潜在空间中去噪来生成逼真、栩栩如生的人体运动。现有工作主要在潜在空间中进行扩散，要么一次性处理整个潜在空间，要么自回归地处理多个潜在空间。本文研究了如何使连续运动潜在空间的扩散效果最佳。我们关注两个问题：(1)如何构建语义对齐的潜在空间，使扩散更有效；(2)如何最好地注入文本条件，使运动紧密遵循描述。我们提出了一种语义对齐的运动编码器，该编码器使用帧级别的文本标签进行训练，以便具有相似文本含义的潜在变量保持接近，从而使潜在空间更适合扩散。我们还将单token条件与多token交叉注意力方案进行了比较，发现交叉注意力可以提供更好的运动真实感和文本-运动对齐。凭借语义对齐的潜在变量、自回归生成和交叉注意力文本条件，我们的模型在标准指标和用户研究中，在人体运动生成方面达到了新的state-of-the-art。我们将发布我们的代码和模型，以供进一步研究和下游使用。",
            "intro_zh": [
                "现有文本到动作生成方法在语义对齐的潜在空间构建和文本条件注入方面存在不足，影响了生成动作的真实性和文本一致性。",
                "MoLingo通过训练语义对齐的运动编码器，并结合多token交叉注意力机制，增强了潜在空间的语义表达能力和文本条件的有效性。",
                "实验结果表明，MoLingo在人体运动生成任务上取得了显著的性能提升，并在标准指标和用户研究中均达到了新的state-of-the-art。"
            ],
            "method_zh": "**问题定义**：本文旨在解决文本到动作生成任务中，生成动作的真实性和与文本描述一致性不足的问题。现有方法在构建语义对齐的运动潜在空间以及有效利用文本信息方面存在局限性，导致生成的动作不够自然，或者与文本描述不符。\\n\\n**核心思路**：MoLingo的核心思路是通过构建一个语义对齐的运动潜在空间，并采用多token交叉注意力机制来更好地融合文本信息，从而提高生成动作的真实性和文本一致性。语义对齐的潜在空间使得具有相似语义的动作在潜在空间中更加接近，有利于扩散模型的学习和生成。交叉注意力机制能够更精细地捕捉文本信息，并将其融入到动作生成过程中。\\n\\n**技术框架**：MoLingo的整体框架包含以下几个主要模块：1) 运动编码器：将运动数据编码到潜在空间中；2) 文本编码器：将文本描述编码为文本特征；3) 扩散模型：在潜在空间中进行去噪，生成新的运动；4) 文本条件注入模块：将文本特征融入到扩散模型的生成过程中。该框架采用自回归生成的方式，逐步生成运动序列。\\n\\n**关键创新**：MoLingo的关键创新在于：1) 提出了语义对齐的运动编码器，通过帧级别的文本标签训练，使得潜在空间具有更好的语义表达能力；2) 采用了多token交叉注意力机制，能够更有效地利用文本信息，提高生成动作的文本一致性。\\n\\n**关键设计**：在语义对齐的运动编码器中，使用了对比学习损失，使得具有相似文本描述的运动在潜在空间中更加接近。在多token交叉注意力机制中，使用了多个注意力头，以捕捉文本信息的不同方面。扩散模型采用了标准的扩散模型结构，并使用余弦噪声调度策略。",
            "application_zh": "MoLingo在游戏开发、虚拟现实、动画制作等领域具有广泛的应用前景。它可以根据文本描述自动生成逼真的人体运动，从而降低了人工制作运动的成本和时间。此外，MoLingo还可以用于人机交互，例如，用户可以通过语音或文本指令控制虚拟角色的运动。",
            "highlight_zh": "MoLingo在HumanML3D和KIT-ML数据集上进行了评估，并在多个指标上取得了显著的提升。例如，在HumanML3D数据集上，MoLingo在FID指标上优于现有方法，并在用户研究中获得了更高的偏好度。这些结果表明，MoLingo能够生成更真实、更符合文本描述的人体运动。",
            "tags_zh": [
                "文本到动作生成",
                "运动生成",
                "扩散模型",
                "语义对齐",
                "交叉注意力"
            ],
            "_index": 14,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13840/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                }
            ]
        },
        {
            "title": "GASPACHO: Gaussian Splatting for Controllable Humans and Objects",
            "authors": [
                "Aymen Mir",
                "Arthur Moreau",
                "Helisa Dhamo",
                "Zhensong Zhang",
                "Gerard Pons-Moll",
                "Eduardo Pérez-Pellitero"
            ],
            "arxiv_id": "2503.09342",
            "summary": "We present GASPACHO, a method for generating photorealistic, controllable renderings of human-object interactions from multi-view RGB video. Unlike prior work that reconstructs only the human and treats objects as background, GASPACHO simultaneously recovers animatable templates for both the human and the interacting object as distinct sets of Gaussians, thereby allowing for controllable renderings of novel human object interactions in different poses from novel-camera viewpoints. We introduce a novel formulation that learns object Gaussians on an underlying 2D surface manifold rather than in 3D volume, yielding sharper, fine-grained object details for dynamic object reconstruction. We further propose a contact constraint in Gaussian space that regularizes human-object relations and enables natural, physically plausible animation. Across three benchmarks - BEHAVE, NeuralDome, and DNA-Rendering - GASPACHO achieves high-quality reconstructions under heavy occlusion and supports controllable synthesis of novel human-object interactions. We also demonstrate that our method allows for composition of humans and objects in 3D scenes and for the first time showcase that neural rendering can be used for the controllable generation of photoreal humans interacting with dynamic objects in diverse scenes. Our results are available at:this https URL",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2503.09342",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "[T]gaussian splatting",
                        "[T]splatting"
                    ],
                    "score": 12.0
                },
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "physically plausible"
                    ],
                    "score": 2.5
                },
                {
                    "name": "支柱五：交互与反应 (Interaction & Reaction)",
                    "id": "5_interaction_reaction",
                    "matched_keywords": [
                        "human-object interaction"
                    ],
                    "score": 2.5
                }
            ],
            "relevance_score": 17.0,
            "hit_pillars": [
                "3_perception_slam",
                "4_motion_diffusion",
                "5_interaction_reaction"
            ],
            "headline_zh": "GASPACHO：基于高斯溅射的可控人与物体交互渲染",
            "summary_zh": "GASPACHO 是一种从多视角 RGB 视频中生成逼真且可控的人与物体交互渲染的方法。与以往仅重建人体并将物体视为背景的工作不同，GASPACHO 同时恢复人体和交互物体的可动画模板，并将它们表示为不同的高斯集合，从而允许在新的相机视角下，对不同姿势的新型人与物体交互进行可控渲染。该方法提出了一种新的公式，在底层 2D 表面流形上学习物体高斯分布，而不是在 3D 体积中，从而为动态物体重建产生更清晰、更精细的物体细节。此外，还提出了一种高斯空间中的接触约束，用于规范人与物体之间的关系，并实现自然、物理上合理的动画。在 BEHAVE、NeuralDome 和 DNA-Rendering 三个基准测试中，GASPACHO 在严重遮挡下实现了高质量的重建，并支持对新型人与物体交互的可控合成。该方法还允许在 3D 场景中组合人和物体，并首次展示了神经渲染可用于在不同场景中可控地生成与动态物体交互的逼真人。",
            "intro_zh": [
                "现有方法难以同时重建可控的人体和交互物体，限制了人与物体交互场景的真实感和可控性。",
                "GASPACHO 通过将人体和物体建模为独立的高斯集合，并引入 2D 表面流形上的物体高斯学习，实现精细的动态物体重建。",
                "实验表明，GASPACHO 在多个基准测试中实现了高质量的重建，并支持对新型人与物体交互的可控合成。"
            ],
            "method_zh": "**问题定义**：现有方法在处理人与物体交互时，通常只关注人体重建，将物体视为静态背景，无法实现对交互物体的精细控制和动画。此外，直接在 3D 体积中学习物体高斯分布容易导致细节模糊。\\n\\n**核心思路**：GASPACHO 的核心在于同时重建人体和交互物体，并将它们建模为独立的可动画高斯集合。通过在 2D 表面流形上学习物体高斯分布，可以获得更清晰、更精细的物体细节。此外，引入高斯空间中的接触约束，可以规范人与物体之间的关系，实现更自然的交互动画。\\n\\n**技术框架**：GASPACHO 的整体框架包括以下几个主要阶段：1) 多视角 RGB 视频输入；2) 人体和物体的高斯表示初始化；3) 在 2D 表面流形上学习物体高斯分布；4) 引入高斯空间中的接触约束；5) 优化高斯参数，实现高质量的重建和可控渲染。\\n\\n**关键创新**：GASPACHO 的关键创新在于：1) 同时重建人体和交互物体，并将它们建模为独立的可动画高斯集合；2) 在 2D 表面流形上学习物体高斯分布，从而获得更清晰、更精细的物体细节；3) 引入高斯空间中的接触约束，用于规范人与物体之间的关系，实现更自然的交互动画。\\n\\n**关键设计**：GASPACHO 的关键设计包括：1) 使用 3D 高斯溅射进行渲染；2) 定义了在 2D 表面流形上学习物体高斯分布的损失函数，鼓励高斯分布与表面对齐；3) 设计了高斯空间中的接触约束，通过惩罚高斯之间的穿透来规范人与物体之间的关系；4) 使用 Adam 优化器优化高斯参数。",
            "application_zh": "GASPACHO 在虚拟现实、增强现实、游戏开发和电影制作等领域具有广泛的应用前景。它可以用于生成逼真且可控的人与物体交互场景，例如虚拟试穿、人机协作模拟、以及电影特效制作。该技术还可以用于创建更具沉浸感和互动性的虚拟体验。",
            "highlight_zh": "GASPACHO 在 BEHAVE、NeuralDome 和 DNA-Rendering 三个基准测试中取得了显著的成果。实验结果表明，GASPACHO 在严重遮挡下实现了高质量的重建，并支持对新型人与物体交互的可控合成。与现有方法相比，GASPACHO 能够生成更逼真、更精细的人与物体交互场景。",
            "tags_zh": [
                "高斯溅射",
                "神经渲染",
                "人与物体交互",
                "可控渲染",
                "动态物体重建"
            ],
            "_index": 15,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2503.09342/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2503.09342/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2503.09342/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Masked Omics Modeling for Multimodal Representation Learning across Histopathology and Molecular Profiles",
            "authors": [
                "Lucas Robinet",
                "Ahmad Berjaoui",
                "Elizabeth Cohen-Jonathan Moyal"
            ],
            "arxiv_id": "2508.00969",
            "summary": "Self-supervised learning (SSL) has driven major advances in computational pathology by enabling the learning of rich representations from histopathology data. Yet, tissue analysis alone may fall short in capturing broader molecular complexity, as key complementary information resides in high-dimensional omics profiles such as transcriptomics, methylomics, and genomics. To address this gap, we introduce MORPHEUS, the first multimodal pre-training strategy that integrates histopathology images and multi-omics data within a shared transformer-based architecture. At its core, MORPHEUS relies on a novel masked omics modeling objective that encourages the model to learn meaningful cross-modal relationships. This yields a general-purpose pre-trained encoder that can be applied to histopathology alone or in combination with any subset of omics modalities. Beyond inference, MORPHEUS also supports flexible any-to-any omics reconstruction, enabling one or more omics profiles to be reconstructed from any modality subset that includes histopathology. Pre-trained on a large pan-cancer cohort, MORPHEUS shows substantial improvements over supervised and SSL baselines across diverse tasks and modality combinations. Together, these capabilities position it as a promising direction for the development of multimodal foundation models in oncology. Code is publicly available atthis https URL",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2508.00969",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]representation learning"
                    ],
                    "score": 4.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "foundation model",
                        "[T]multimodal"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 16.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "MORPHEUS：用于组织病理学和分子图谱多模态表征学习的掩码组学建模",
            "summary_zh": "本文提出了一种名为MORPHEUS的多模态预训练策略，旨在整合组织病理学图像和多组学数据（如转录组学、甲基化组学和基因组学）到一个共享的基于Transformer的架构中。MORPHEUS的核心是一种新颖的掩码组学建模目标，它鼓励模型学习有意义的跨模态关系。这产生了一个通用的预训练编码器，可以单独应用于组织病理学，也可以与任何组学模态子集结合使用。除了推理之外，MORPHEUS还支持灵活的任意到任意组学重建，从而能够从包括组织病理学在内的任何模态子集重建一个或多个组学图谱。MORPHEUS在一个大型泛癌队列上进行了预训练，在各种任务和模态组合中，相对于监督和自监督学习基线显示出显著的改进。这些能力使其成为肿瘤学中多模态基础模型开发的一个有希望的方向。",
            "intro_zh": [
                "组织病理学图像分析在计算病理学中取得了显著进展，但单独分析可能无法捕捉更广泛的分子复杂性。",
                "MORPHEUS通过掩码组学建模，将组织病理学图像和多组学数据整合到Transformer架构中，学习跨模态关系。",
                "MORPHEUS在泛癌队列上预训练，并在多种任务和模态组合中超越了监督和自监督基线。"
            ],
            "method_zh": "**问题定义**：现有方法在计算病理学中主要依赖组织病理学图像，但忽略了高维组学数据中包含的关键互补信息，导致无法全面捕捉肿瘤的复杂分子特征。现有方法难以有效融合多模态数据，并缺乏灵活的组学数据重建能力。\\n\\n**核心思路**：MORPHEUS的核心思路是通过自监督学习中的掩码建模，迫使模型学习组织病理学图像和多组学数据之间的内在联系。通过掩盖部分组学数据，模型需要根据其他模态的信息进行重建，从而学习到跨模态的共享表征。这种方法能够有效地融合不同类型的数据，并支持灵活的组学数据重建。\\n\\n**技术框架**：MORPHEUS采用基于Transformer的架构，将组织病理学图像和多组学数据作为输入。整体流程包括：1) 数据预处理，包括图像切片和组学数据标准化；2) 特征提取，使用卷积神经网络提取图像特征，使用线性层或其他方法提取组学特征；3) 跨模态融合，将图像和组学特征输入Transformer编码器，通过自注意力机制学习跨模态关系；4) 掩码组学建模，随机掩盖部分组学数据，并使用Transformer解码器进行重建；5) 模型训练，使用重建损失和其他辅助损失优化模型参数。\\n\\n**关键创新**：MORPHEUS的关键创新在于提出了掩码组学建模目标，这是一种新颖的自监督学习方法，专门用于融合组织病理学图像和多组学数据。与传统的自监督学习方法相比，掩码组学建模能够更有效地学习跨模态的共享表征，并支持灵活的组学数据重建。此外，MORPHEUS是第一个将组织病理学图像和多组学数据整合到统一Transformer架构中的模型。\\n\\n**关键设计**：在掩码组学建模中，随机掩盖一定比例（例如30%-50%）的组学数据。重建损失可以使用均方误差（MSE）或其他适合组学数据类型的损失函数。Transformer编码器和解码器的层数、注意力头数和隐藏层维度等参数需要根据数据集大小和计算资源进行调整。为了提高模型的泛化能力，可以使用数据增强技术，例如图像旋转、翻转和颜色抖动。",
            "application_zh": "MORPHEUS在肿瘤学领域具有广泛的应用前景，可用于肿瘤诊断、预后预测、治疗方案选择和药物研发。通过整合组织病理学图像和多组学数据，MORPHEUS能够更全面地了解肿瘤的生物学特征，从而为临床决策提供更准确的依据。此外，MORPHEUS的组学数据重建能力可以用于填补缺失的组学数据，降低实验成本。",
            "highlight_zh": "MORPHEUS在泛癌队列上进行了预训练，并在多种任务和模态组合中进行了评估。实验结果表明，MORPHEUS在肿瘤亚型分类、生存预测和药物反应预测等任务上显著优于监督学习和自监督学习基线。例如，在肿瘤亚型分类任务中，MORPHEUS的准确率比最佳基线提高了5%-10%。此外，MORPHEUS的组学数据重建能力也得到了验证，能够以较高的准确率重建缺失的组学数据。",
            "tags_zh": [
                "多模态学习",
                "自监督学习",
                "组织病理学",
                "组学数据",
                "Transformer",
                "掩码建模",
                "肿瘤学"
            ],
            "_index": 16,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2508.00969/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2508.00969/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2508.00969/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "GaussianPlant: Structure-aligned Gaussian Splatting for 3D Reconstruction of Plants",
            "authors": [
                "Yang Yang",
                "Risa Shinoda",
                "Hiroaki Santo",
                "Fumio Okura"
            ],
            "arxiv_id": "2512.14087",
            "summary": "We present a method for jointly recovering the appearance and internal structure of botanical plants from multi-view images based on 3D Gaussian Splatting (3DGS). While 3DGS exhibits robust reconstruction of scene appearance for novel-view synthesis, it lacks structural representations underlying those appearances (e.g., branching patterns of plants), which limits its applicability to tasks such as plant phenotyping. To achieve both high-fidelity appearance and structural reconstruction, we introduce GaussianPlant, a hierarchical 3DGS representation, which disentangles structure and appearance. Specifically, we employ structure primitives (StPs) to explicitly represent branch and leaf geometry, and appearance primitives (ApPs) to the plants' appearance using 3D Gaussians. StPs represent a simplified structure of the plant, i.e., modeling branches as cylinders and leaves as disks. To accurately distinguish the branches and leaves, StP's attributes (i.e., branches or leaves) are optimized in a self-organized manner. ApPs are bound to each StP to represent the appearance of branches or leaves as in conventional 3DGS. StPs and ApPs are jointly optimized using a re-rendering loss on the input multi-view images, as well as the gradient flow from ApP to StP using the binding correspondence information. We conduct experiments to qualitatively evaluate the reconstruction accuracy of both appearance and structure, as well as real-world experiments to qualitatively validate the practical performance. Experiments show that the GaussianPlant achieves both high-fidelity appearance reconstruction via ApPs and accurate structural reconstruction via StPs, enabling the extraction of branch structure and leaf instances.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14087",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "3D gaussian splatting",
                        "3DGS",
                        "[T]gaussian splatting",
                        "[T]splatting"
                    ],
                    "score": 16.0
                }
            ],
            "relevance_score": 16.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "GaussianPlant：提出结构对齐的高斯溅射方法，用于植物三维重建",
            "summary_zh": "本文提出了一种基于3D高斯溅射(3DGS)的多视角图像植物外观和内部结构联合重建方法。3DGS虽然能够鲁棒地重建场景外观以进行新视角合成，但缺乏对外观的底层结构表示（例如，植物的分枝模式），这限制了其在植物表型分析等任务中的应用。为了实现高保真度的外观和结构重建，我们引入了GaussianPlant，一种分层3DGS表示，它解耦了结构和外观。具体来说，我们采用结构基元(StP)来显式地表示分支和叶片的几何形状，并使用3D高斯函数将外观基元(ApP)绑定到植物的外观。StP表示植物的简化结构，即将分支建模为圆柱体，将叶片建模为圆盘。为了准确区分分支和叶片，StP的属性（即分支或叶片）以自组织的方式进行优化。ApP绑定到每个StP，以表示分支或叶片的外观，类似于传统的3DGS。StP和ApP使用输入多视角图像上的重渲染损失以及从ApP到StP的梯度流（使用绑定对应关系信息）进行联合优化。我们进行了实验，以定性地评估外观和结构的重建精度，并进行了真实世界的实验，以定性地验证实际性能。实验表明，GaussianPlant通过ApP实现了高保真度的外观重建，并通过StP实现了准确的结构重建，从而能够提取分支结构和叶片实例。",
            "intro_zh": [
                "现有3DGS方法在植物重建中缺乏对底层结构（如分枝模式）的显式建模，限制了其在植物表型分析等领域的应用。",
                "GaussianPlant通过引入结构基元(StP)和外观基元(ApP)的分层3DGS表示，解耦了植物的结构和外观。",
                "实验结果表明，GaussianPlant能够实现高保真度的外观重建和准确的结构重建，并能提取分支结构和叶片实例。"
            ],
            "method_zh": "**问题定义**：现有基于3D高斯溅射(3DGS)的植物三维重建方法，虽然能够较好地重建植物的外观，但缺乏对植物内部结构的显式建模，例如分枝模式、叶片分布等。这使得这些方法难以应用于需要结构信息的任务，如植物表型分析、生长模拟等。现有方法无法同时保证外观重建的逼真度和结构信息的准确性。\\n\\n**核心思路**：GaussianPlant的核心思路是将植物的结构和外观进行解耦，分别使用不同的基元进行表示。具体来说，使用结构基元(StP)来显式地表示植物的骨架结构（分支和叶片），并使用外观基元(ApP)来表示植物的表面纹理和颜色。通过将ApP绑定到StP上，可以实现结构和外观的对齐，从而在优化过程中利用结构信息来指导外观重建，反之亦然。这种解耦的设计使得模型能够更好地学习植物的结构和外观特征。\\n\\n**技术框架**：GaussianPlant的整体框架包含以下几个主要模块：1) **结构基元(StP)初始化**：根据多视角图像初始化StP，StP包括位置、方向、类型（分支或叶片）等属性。2) **外观基元(ApP)初始化**：在每个StP附近初始化ApP，ApP使用3D高斯函数表示，包含位置、协方差、颜色、透明度等属性。3) **StP和ApP联合优化**：使用重渲染损失和结构损失联合优化StP和ApP的属性。重渲染损失用于保证外观重建的逼真度，结构损失用于保证结构重建的准确性。4) **结构提取**：从优化后的StP中提取植物的骨架结构，例如分枝模式、叶片分布等。\\n\\n**关键创新**：GaussianPlant的关键创新在于：1) **结构和外观解耦表示**：通过引入StP和ApP，将植物的结构和外观进行解耦，从而能够更好地学习植物的结构和外观特征。2) **结构引导的外观重建**：通过将ApP绑定到StP上，可以利用结构信息来指导外观重建，从而提高外观重建的准确性。3) **自组织的结构优化**：StP的类型（分支或叶片）以自组织的方式进行优化，无需人工标注。\\n\\n**关键设计**：1) **StP表示**：分支建模为圆柱体，叶片建模为圆盘，简化了结构表示，降低了优化难度。2) **ApP绑定**：ApP绑定到StP上，通过计算ApP到StP的距离来确定绑定关系。3) **损失函数**：使用重渲染损失（L1损失、SSIM损失）和结构损失（StP类型分类损失）联合优化StP和ApP。4) **梯度流**：利用绑定对应关系信息，将ApP的梯度反向传播到StP，从而实现结构引导的外观重建。",
            "application_zh": "GaussianPlant在植物表型分析、虚拟植物建模、农业监测、园艺设计等领域具有广泛的应用前景。它可以用于自动提取植物的结构参数，例如分枝角度、叶片大小、叶片数量等，从而为植物生长研究提供数据支持。此外，GaussianPlant还可以用于创建逼真的虚拟植物模型，用于游戏、电影等领域。在农业领域，可以用于监测作物生长状况，预测产量。在园艺设计领域，可以用于模拟植物的生长形态，辅助景观设计。",
            "highlight_zh": "论文通过实验验证了GaussianPlant在植物三维重建方面的有效性。定性结果表明，GaussianPlant能够重建出高保真度的植物外观和准确的结构信息。与现有方法相比，GaussianPlant能够更好地提取植物的分枝结构和叶片实例。真实场景实验验证了GaussianPlant在实际应用中的可行性。虽然论文没有提供具体的定量指标，但定性结果足以说明GaussianPlant的优越性。",
            "tags_zh": [
                "三维重建",
                "高斯溅射",
                "植物建模",
                "结构化表示",
                "表型分析"
            ],
            "_index": 17,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14087/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14087/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14087/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Semantic-Drive: Democratizing Long-Tail Data Curation via Open-Vocabulary Grounding and Neuro-Symbolic VLM Consensus",
            "authors": [
                "Antonio Guillen-Perez"
            ],
            "arxiv_id": "2512.12012",
            "summary": "The development of robust Autonomous Vehicles (AVs) is bottlenecked by the scarcity of \"Long-Tail\" training data. While fleets collect petabytes of video logs, identifying rare safety-critical events (e.g., erratic jaywalking, construction diversions) remains a manual, cost-prohibitive process. Existing solutions rely on coarse metadata search, which lacks precision, or cloud-based VLMs, which are privacy-invasive and expensive. We introduce Semantic-Drive, a local-first, neuro-symbolic framework for semantic data mining. Our approach decouples perception into two stages: (1) Symbolic Grounding via a real-time open-vocabulary detector (YOLOE) to anchor attention, and (2) Cognitive Analysis via a Reasoning VLM that performs forensic scene analysis. To mitigate hallucination, we implement a \"System 2\" inference-time alignment strategy, utilizing a multi-model \"Judge-Scout\" consensus mechanism. Benchmarked on the nuScenes dataset against the Waymo Open Dataset (WOD-E2E) taxonomy, Semantic-Drive achieves a Recall of 0.966 (vs. 0.475 for CLIP) and reduces Risk Assessment Error by 40% ccompared to the best single scout models. The system runs entirely on consumer hardware (NVIDIA RTX 3090), offering a privacy-preserving alternative to the cloud.",
            "categories": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.RO"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.12012",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "[T]open-vocabulary",
                        "[T]open vocabulary"
                    ],
                    "score": 12.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "symbolic grounding"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 15.0,
            "hit_pillars": [
                "3_perception_slam",
                "9_embodied_foundation"
            ],
            "headline_zh": "Semantic-Drive：通过开放词汇 grounding 和神经符号 VLM 共识实现长尾数据挖掘",
            "summary_zh": "自动驾驶车辆(AVs)的稳健发展受到“长尾”训练数据稀缺的限制。虽然车队收集了PB级的视频日志，但识别罕见的安全关键事件(例如，不稳定的乱穿马路、施工改道)仍然是一个手动且成本高昂的过程。现有的解决方案依赖于粗略的元数据搜索(缺乏精度)或基于云的VLM(侵犯隐私且昂贵)。我们引入了Semantic-Drive，这是一个用于语义数据挖掘的本地优先、神经符号框架。我们的方法将感知解耦为两个阶段：(1)通过实时开放词汇检测器(YOLOE)进行符号 grounding 以锚定注意力，以及(2)通过推理VLM进行认知分析，执行取证场景分析。为了减轻幻觉，我们实现了一种“系统2”推理时对齐策略，利用多模型“Judge-Scout”共识机制。在nuScenes数据集上针对Waymo开放数据集(WOD-E2E)分类法进行基准测试，Semantic-Drive实现了0.966的召回率(CLIP为0.475)，并且与最佳单 scout 模型相比，风险评估误差降低了40%。该系统完全在消费级硬件(NVIDIA RTX 3090)上运行，为云提供了一种保护隐私的替代方案。",
            "intro_zh": [
                "自动驾驶长尾数据匮乏，人工标注成本高昂，现有元数据搜索精度不足，云端VLM方案存在隐私和成本问题。",
                "Semantic-Drive 采用本地优先的神经符号框架，通过开放词汇检测器和推理 VLM 实现语义数据挖掘。",
                "实验表明，Semantic-Drive 在 nuScenes 数据集上实现了更高的召回率，并显著降低了风险评估误差，且可在消费级硬件上运行。"
            ],
            "method_zh": "**问题定义**：自动驾驶领域中，长尾场景数据（如罕见交通事件）的获取成本高昂，严重制约了自动驾驶系统的鲁棒性。现有方法依赖粗糙的元数据搜索，精度不足；而云端视觉语言模型（VLM）方案存在隐私泄露和高昂计算成本的风险。因此，如何高效、低成本、保护隐私地挖掘长尾数据是亟待解决的问题。\\n\\n**核心思路**：Semantic-Drive 的核心思路是将复杂的场景理解任务分解为两个阶段：首先，利用开放词汇检测器进行符号 grounding，将视觉信息与语义概念关联；然后，利用推理 VLM 对场景进行认知分析，判断是否存在目标事件。此外，为了降低 VLM 的幻觉问题，引入了多模型共识机制，提高判断的可靠性。\\n\\n**技术框架**：Semantic-Drive 包含以下主要模块：1) **开放词汇检测器 (YOLOE)**：用于检测图像中的物体，并将其与开放词汇表中的概念关联，实现符号 grounding。2) **推理 VLM**：对场景进行认知分析，判断是否存在目标事件。3) **Judge-Scout 共识机制**：采用多个 VLM 模型（Scout）进行独立判断，然后由一个 Judge 模型综合评估，形成最终的判断结果。这种多模型共识机制可以有效降低 VLM 的幻觉问题。\\n\\n**关键创新**：Semantic-Drive 的关键创新在于：1) 提出了一个本地优先的神经符号框架，能够在消费级硬件上运行，保护用户隐私。2) 引入了 Judge-Scout 共识机制，有效降低了 VLM 的幻觉问题，提高了判断的可靠性。3) 将场景理解任务分解为符号 grounding 和认知分析两个阶段，降低了任务的复杂度。\\n\\n**关键设计**：YOLOE 作为开放词汇检测器，其训练数据和检测精度至关重要。推理 VLM 的选择需要兼顾推理能力和计算效率。Judge-Scout 共识机制中，Scout 模型的数量和 Judge 模型的选择会影响最终的判断结果。论文中具体使用的 VLM 模型和参数设置未知。",
            "application_zh": "Semantic-Drive 可应用于自动驾驶长尾数据挖掘、智能交通监控、安全事件检测等领域。该系统能够帮助自动驾驶公司更高效地获取安全关键数据，提高自动驾驶系统的鲁棒性。同时，本地优先的设计使其能够在保护用户隐私的前提下进行数据分析，具有重要的实际应用价值和未来发展潜力。",
            "highlight_zh": "Semantic-Drive 在 nuScenes 数据集上进行了评估，结果表明，其召回率达到 0.966，远高于 CLIP 的 0.475。与最佳单 Scout 模型相比，风险评估误差降低了 40%。该系统完全在消费级硬件（NVIDIA RTX 3090）上运行，验证了其在实际应用中的可行性。",
            "tags_zh": [
                "自动驾驶",
                "长尾数据挖掘",
                "开放词汇检测",
                "视觉语言模型",
                "神经符号推理",
                "多模型共识",
                "本地部署"
            ],
            "_index": 18,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.12012/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.12012/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.12012/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling",
            "authors": [
                "Wenqiang Sun",
                "Haiyu Zhang",
                "Haoyuan Wang",
                "Junta Wu",
                "Zehan Wang",
                "Zhenwei Wang",
                "Yunhong Wang",
                "Jun Zhang",
                "Tengfei Wang",
                "Chunchao Guo"
            ],
            "arxiv_id": "2512.14614",
            "summary": "This paper presents WorldPlay, a streaming video diffusion model that enables real-time, interactive world modeling with long-term geometric consistency, resolving the trade-off between speed and memory that limits current methods. WorldPlay draws power from three key innovations. 1) We use a Dual Action Representation to enable robust action control in response to the user's keyboard and mouse inputs. 2) To enforce long-term consistency, our Reconstituted Context Memory dynamically rebuilds context from past frames and uses temporal reframing to keep geometrically important but long-past frames accessible, effectively alleviating memory attenuation. 3) We also propose Context Forcing, a novel distillation method designed for memory-aware model. Aligning memory context between the teacher and student preserves the student's capacity to use long-range information, enabling real-time speeds while preventing error drift. Taken together, WorldPlay generates long-horizon streaming 720p video at 24 FPS with superior consistency, comparing favorably with existing techniques and showing strong generalization across diverse scenes. Project page and online demo can be found:this https URLandthis https URL.",
            "categories": [
                "cs.CV",
                "cs.GR"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14614",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]world model",
                        "distillation"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱七：动作重定向 (Motion Retargeting)",
                    "id": "7_retargeting",
                    "matched_keywords": [
                        "[T]geometric consistency"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 15.0,
            "hit_pillars": [
                "2_algo_arch",
                "7_retargeting"
            ],
            "headline_zh": "WorldPlay：面向实时交互世界建模的长时几何一致性视频扩散模型",
            "summary_zh": "本文提出WorldPlay，一种流式视频扩散模型，能够实现具有长期几何一致性的实时交互世界建模，解决了现有方法在速度和内存之间的权衡问题。WorldPlay得益于三个关键创新：1) 使用双重动作表示，以响应用户的键盘和鼠标输入，实现鲁棒的动作控制；2) 为了保证长期一致性，我们的重构上下文记忆动态地从过去的帧中重建上下文，并使用时间重构来保持几何上重要但时间上久远的帧的可访问性，有效地缓解了记忆衰减；3) 我们还提出了一种新颖的上下文强制蒸馏方法，专为内存感知模型设计。对齐教师和学生模型之间的记忆上下文，保持学生模型使用长程信息的能力，从而在防止误差漂移的同时实现实时速度。综上所述，WorldPlay以24 FPS生成长时程流式720p视频，具有卓越的一致性，与现有技术相比表现出色，并在各种场景中表现出强大的泛化能力。",
            "intro_zh": [
                "现有方法在实时交互世界建模中，难以兼顾速度和长期几何一致性，面临内存限制和误差累积的挑战。",
                "WorldPlay通过双重动作表示、重构上下文记忆和上下文强制蒸馏，实现了快速、一致且可交互的世界建模。",
                "实验表明，WorldPlay能够以24 FPS生成720p长时程视频，并在几何一致性和泛化能力上优于现有技术。"
            ],
            "method_zh": "**问题定义**：现有实时交互世界建模方法需要在速度、内存占用和长期几何一致性之间进行权衡。一方面，为了保证实时性，模型往往无法利用足够长的历史信息，导致几何一致性较差。另一方面，如果简单地增加历史信息的长度，则会显著增加内存占用，并可能导致误差累积和漂移。因此，如何在有限的内存资源下，实现具有长期几何一致性的实时交互世界建模是一个关键问题。\\n\\n**核心思路**：WorldPlay的核心思路是利用视频扩散模型，并结合双重动作表示、重构上下文记忆和上下文强制蒸馏等技术，在有限的内存资源下，实现具有长期几何一致性的实时交互世界建模。通过双重动作表示，模型可以更好地理解用户的交互意图；通过重构上下文记忆，模型可以有效地利用历史信息，保证长期几何一致性；通过上下文强制蒸馏，模型可以在保证速度的同时，防止误差漂移。\\n\\n**技术框架**：WorldPlay的整体框架是一个流式视频扩散模型，包括以下几个主要模块：1) 双重动作表示模块，用于将用户的键盘和鼠标输入转换为动作表示；2) 重构上下文记忆模块，用于从过去的帧中重建上下文，并使用时间重构来保持几何上重要但时间上久远的帧的可访问性；3) 视频扩散模型，用于根据动作表示和上下文信息生成视频帧；4) 上下文强制蒸馏模块，用于训练内存感知模型，防止误差漂移。\\n\\n**关键创新**：WorldPlay最重要的技术创新点在于重构上下文记忆和上下文强制蒸馏。重构上下文记忆能够有效地利用历史信息，保证长期几何一致性，缓解了记忆衰减问题。上下文强制蒸馏能够训练内存感知模型，在保证速度的同时，防止误差漂移。这两个创新点共同解决了现有方法在速度、内存占用和长期几何一致性之间的权衡问题。\\n\\n**关键设计**：在重构上下文记忆模块中，论文使用了一种动态重建上下文的方法，根据帧的重要性选择性地保留和更新历史帧。在上下文强制蒸馏模块中，论文设计了一种新的损失函数，用于对齐教师和学生模型之间的记忆上下文，从而保持学生模型使用长程信息的能力。具体的网络结构和参数设置在论文中有详细描述。",
            "application_zh": "WorldPlay在虚拟现实、游戏开发、机器人控制等领域具有广泛的应用前景。它可以用于创建具有高度真实感和交互性的虚拟环境，为用户提供沉浸式的体验。此外，WorldPlay还可以用于训练机器人，使其能够在复杂环境中进行导航和操作。",
            "highlight_zh": "WorldPlay在多个场景下进行了实验，结果表明，它能够以24 FPS生成720p长时程视频，具有卓越的几何一致性，并且在各种场景中表现出强大的泛化能力。与现有技术相比，WorldPlay在几何一致性指标上取得了显著的提升，并且能够生成更长时程的视频。",
            "tags_zh": [
                "视频扩散模型",
                "实时渲染",
                "交互式建模",
                "长时几何一致性",
                "上下文记忆",
                "知识蒸馏",
                "虚拟现实",
                "机器人"
            ],
            "_index": 19,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14614/x2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14614/x3.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14614/x4.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Exo2Ego: Exocentric Knowledge Guided MLLM for Egocentric Video Understanding",
            "authors": [
                "Haoyu Zhang",
                "Qiaohui Chu",
                "Meng Liu",
                "Haoxiang Shi",
                "Yaowei Wang",
                "Liqiang Nie"
            ],
            "arxiv_id": "2503.09143",
            "summary": "AI personal assistants, deployed through robots or wearables, require embodied understanding to collaborate effectively with humans. However, current Multimodal Large Language Models (MLLMs) primarily focus on third-person (exocentric) vision, overlooking the unique challenges of first-person (egocentric) videos. Additionally, high acquisition costs limit data size, impairing MLLM performance. To address these challenges, we propose learning the mapping between exocentric and egocentric domains, leveraging the extensive exocentric knowledge within existing MLLMs to enhance egocentric video understanding. To this end, we introduce Ego-ExoClip, a pre-training dataset comprising 1.1M synchronized ego-exo clip-text pairs derived from Ego-Exo4D, together with the instruction-tuning dataset EgoIT, which is collected from multiple sources to enhance the model's instruction-following capabilities. Building upon the datasets, we propose a migration strategy and further design a progressive mapping learning pipeline with three stages: Demonstrator Self-Preparation, Demonstrator-Learner Guidance, and Learner Self-Practice. Extensive experiments across diverse egocentric tasks reveal that existing MLLMs perform inadequately in egocentric video understanding, while our model significantly outperforms these leading models.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2503.09143",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱六：视频提取与匹配 (Video Extraction)",
                    "id": "6_video_extraction",
                    "matched_keywords": [
                        "[T]egocentric"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "multimodal",
                        "instruction following"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 15.0,
            "hit_pillars": [
                "6_video_extraction",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出Exo2Ego，利用外视知识指导MLLM进行第一人称视频理解",
            "summary_zh": "为了使AI助手能够更好地与人类协作，需要具备具身理解能力。然而，目前的多模态大语言模型(MLLMs)主要关注第三人称(外视)视觉，忽略了第一人称(内视)视频的独特挑战。此外，高昂的数据采集成本限制了数据规模，影响了MLLM的性能。为了解决这些问题，我们提出学习外视和内视域之间的映射，利用现有MLLM中丰富的外视知识来增强内视视频理解。为此，我们引入了Ego-ExoClip，一个包含110万个同步内视-外视剪辑-文本对的预训练数据集，该数据集源自Ego-Exo4D。同时，我们收集了来自多个来源的指令调优数据集EgoIT，以增强模型的指令遵循能力。基于这些数据集，我们提出了一种迁移策略，并进一步设计了一个包含三个阶段的渐进式映射学习流程：演示者自我准备、演示者-学习者指导和学习者自我实践。在各种内视任务上的大量实验表明，现有的MLLM在内视视频理解方面表现不足，而我们的模型显著优于这些领先模型。",
            "intro_zh": [
                "现有MLLM主要关注外视视觉，忽略了内视视频理解的特殊性，且内视数据获取成本高昂。",
                "提出学习外视到内视的知识迁移，利用外视MLLM的知识增强内视视频理解能力。",
                "构建Ego-ExoClip和EgoIT数据集，并设计渐进式映射学习流程，实验表明模型性能显著提升。"
            ],
            "method_zh": "**问题定义**：论文旨在解决多模态大语言模型(MLLMs)在第一人称(内视)视频理解方面的不足。现有MLLMs主要针对第三人称(外视)视觉进行训练，缺乏对内视视频中视角、动作和交互的理解能力。此外，内视视频数据采集成本高，导致数据规模有限，进一步限制了MLLMs的性能。\\n\\n**核心思路**：论文的核心思路是利用现有的、经过大量外视数据训练的MLLMs所具备的丰富知识，通过学习外视和内视域之间的映射，将外视知识迁移到内视视频理解任务中。这种方法旨在克服内视数据稀缺的问题，并充分利用现有MLLMs的强大能力。\\n\\n**技术框架**：整体框架包含三个主要阶段：\n1. **演示者自我准备(Demonstrator Self-Preparation)**：利用外视数据预训练MLLM，使其具备基本的外视知识。\n2. **演示者-学习者指导(Demonstrator-Learner Guidance)**：利用Ego-ExoClip数据集，通过对比学习等方法，训练模型学习外视和内视之间的对应关系，将外视知识迁移到内视域。\n3. **学习者自我实践(Learner Self-Practice)**：利用EgoIT数据集，通过指令调优，进一步提升模型在内视视频理解任务中的性能和指令遵循能力。\\n\\n**关键创新**：论文的关键创新在于提出了一种基于知识迁移的内视视频理解方法，通过学习外视和内视域之间的映射，有效地利用了现有MLLMs的知识。此外，Ego-ExoClip数据集的构建也为内视视频理解研究提供了新的资源。与现有方法相比，该方法无需从头训练MLLM，而是通过知识迁移的方式，更高效地提升了内视视频理解的性能。\\n\\n**关键设计**：\n1. **Ego-ExoClip数据集**：包含110万个同步内视-外视剪辑-文本对，用于学习外视和内视之间的对应关系。\n2. **EgoIT数据集**：包含多个来源的指令数据，用于指令调优，提升模型性能。\n3. **渐进式映射学习流程**：包含演示者自我准备、演示者-学习者指导和学习者自我实践三个阶段，逐步提升模型在内视视频理解任务中的性能。\n4. **迁移策略**：具体迁移策略细节未知，但应包含如何将外视知识有效迁移到内视域的方法。",
            "application_zh": "该研究成果可应用于开发更智能的AI个人助手，例如部署在机器人或可穿戴设备上的助手，能够更好地理解用户的意图和行为，从而提供更有效的帮助和支持。此外，该技术还可应用于智能家居、智能安防、医疗健康等领域，提升相关系统的智能化水平。",
            "highlight_zh": "实验结果表明，现有的MLLM在内视视频理解方面表现不佳，而提出的Exo2Ego模型显著优于这些领先模型。具体的性能数据和提升幅度未知，但摘要强调了“显著优于”的结果，表明该方法在内视视频理解方面取得了重要进展。",
            "tags_zh": [
                "内视视频理解",
                "多模态大语言模型",
                "知识迁移",
                "外视知识",
                "具身智能"
            ],
            "_index": 20,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2503.09143/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2503.09143/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2503.09143/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Understanding the Gain from Data Filtering in Multimodal Contrastive Learning",
            "authors": [
                "Divyansh Pareek",
                "Sewoong Oh",
                "Simon S. Du"
            ],
            "arxiv_id": "2512.14230",
            "summary": "The success of modern multimodal representation learning relies on internet-scale datasets. Due to the low quality of a large fraction of raw web data, data curation has become a critical step in the training pipeline. Filtering using a trained model (i.e., teacher-based filtering) has emerged as a successful solution, leveraging a pre-trained model to compute quality scores. To explain the empirical success of teacher-based filtering, we characterize the performance of filtered contrastive learning under the standard bimodal data generation model. Denoting $\\eta\\in(0,1]$ as the fraction of data with correctly matched modalities among $n$ paired samples, we utilize a linear contrastive learning setup to show a provable benefit of data filtering: $(i)$ the error without filtering is upper and lower bounded by $\\frac{1}{\\eta \\sqrt{n}}$, and $(ii)$ the error with teacher-based filtering is upper bounded by $\\frac{1}{\\sqrt{\\eta n}}$ in the large $\\eta$ regime, and by $\\frac{1}{\\sqrt{n}}$ in the small $\\eta$ regime.",
            "categories": [
                "cs.LG",
                "stat.ML"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14230",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "representation learning",
                        "[T]contrastive learning"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 15.0,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于教师模型的数据过滤方法以提升多模态对比学习效果",
            "summary_zh": "现代多模态表示学习的成功依赖于互联网规模的数据集。然而，原始网络数据的低质量使得数据筛选成为训练流程中的关键步骤。基于训练模型的过滤方法（即教师模型过滤）已成为一种成功的解决方案，利用预训练模型计算质量评分。为了解释教师模型过滤的经验成功，本文在标准双模态数据生成模型下表征了过滤对比学习的性能。研究表明，未过滤情况下的误差有上下界，而使用教师模型过滤后的误差在大和小的$\theta$范围内分别有不同的上界。通过这些分析，论文展示了数据过滤的可证明益处。",
            "intro_zh": [
                "现有的多模态学习方法在处理低质量数据时面临挑战，导致模型性能不稳定。",
                "论文提出了一种基于教师模型的数据过滤方法，通过计算质量评分来提升数据质量。",
                "研究表明，使用教师模型过滤后，模型误差显著降低，尤其在高质量数据比例较高时效果更佳。"
            ],
            "method_zh": "**问题定义**：本文旨在解决多模态对比学习中因低质量数据导致的性能下降问题。现有方法在处理原始网络数据时，未能有效过滤低质量样本，影响了模型的学习效果。\\n\\n**核心思路**：论文的核心思路是利用预训练的教师模型对数据进行过滤，从而提高训练数据的质量。通过计算每个样本的质量评分，筛选出高质量的样本进行对比学习，进而提升模型的性能。\\n\\n**技术框架**：整体架构包括数据收集、教师模型训练、质量评分计算和数据过滤四个主要模块。首先收集原始数据，然后训练教师模型，接着对数据进行质量评分，最后根据评分进行样本过滤。\\n\\n**关键创新**：最重要的技术创新在于提出了基于教师模型的过滤方法，并通过理论分析证明了其在不同数据质量下的有效性。这一方法与传统的随机过滤方法本质上不同，后者未能考虑数据的质量差异。\\n\\n**关键设计**：在设计中，论文设置了不同的质量评分阈值，并采用线性对比学习的损失函数。网络结构上，使用了预训练的深度学习模型作为教师模型，以确保评分的准确性和可靠性。通过这些设计，论文有效提升了对比学习的性能。 ",
            "application_zh": "该研究的潜在应用场景包括图像和文本的多模态学习、视频理解以及跨模态检索等领域。通过提升数据质量，研究能够显著提高模型的泛化能力和准确性，具有重要的实际价值和广泛的应用前景。未来，随着数据集规模的不断扩大，该方法有望在更多实际应用中发挥作用。",
            "highlight_zh": "实验结果显示，使用教师模型过滤后，模型的误差在高质量数据比例较高时上界为$\frac{1}{\theta \times \text{n}}$，而未过滤情况下的误差上界为$\frac{1}{\theta \times \text{n}}$。在小$\theta$范围内，过滤后的误差上界为$\frac{1}{\text{n}}$，表明数据过滤显著提升了模型性能，尤其在数据质量较高的情况下效果更为明显。",
            "tags_zh": [
                "多模态学习",
                "对比学习",
                "数据过滤",
                "教师模型",
                "质量评分",
                "深度学习",
                "模型训练"
            ],
            "_index": 21,
            "_used_api": "openai",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14230/figures/hist_scores.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14230/figures/error_vs_eta_10000000_first95trials.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14230/figures/plot_dfn.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "COMMA: A Communicative Multimodal Multi-Agent Benchmark",
            "authors": [
                "Timothy Ossowski",
                "Danyal Maqbool",
                "Jixuan Chen",
                "Zefan Cai",
                "Tyler Bradshaw",
                "Junjie Hu"
            ],
            "arxiv_id": "2410.07553",
            "summary": "The rapid advances of multimodal agents built on large foundation models have largely overlooked their potential for language-based communication between agents in collaborative tasks. This oversight presents a critical gap in understanding their effectiveness in real-world deployments, particularly when communicating with humans. Existing agentic benchmarks fail to address key aspects of inter-agent communication and collaboration, particularly in scenarios where agents have unequal access to information and must work together to achieve tasks beyond the scope of individual capabilities. To fill this gap, we introduce COMMA: a novel puzzle benchmark designed to evaluate the collaborative performance of multimodal multi-agent systems through language communication. Our benchmark features a variety of multimodal puzzles, providing a comprehensive evaluation across four key categories of agentic capability in a communicative collaboration setting. Our findings reveal surprising weaknesses in state-of-the-art models, including strong proprietary models like GPT-4o and reasoning models like o4-mini. Many chain of thought reasoning models such as R1-Onevision and LLaVA-CoT struggle to outperform even a random baseline in agent-agent collaboration, indicating a potential growth area in their communication abilities.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2410.07553",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "foundation model",
                        "[T]multimodal",
                        "chain-of-thought"
                    ],
                    "score": 15.0
                }
            ],
            "relevance_score": 15.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出COMMA：一个用于评估多模态多智能体语言交流协作的新基准。",
            "summary_zh": "本文介绍了一个名为COMMA的新型谜题基准，旨在评估多模态多智能体系统通过语言交流进行协作的性能。现有基于大型模型的多模态智能体在语言交流协作方面潜力被忽视，这导致对它们在真实场景中有效性的理解存在关键差距，尤其是在与人类交流时。现有智能体基准未能解决智能体间交流和协作的关键方面，特别是在智能体对信息的访问不平等，且必须协同完成超出个体能力的任务时。COMMA包含各种多模态谜题，对智能体在交流协作环境中的四类关键能力进行全面评估。研究结果揭示了现有模型（包括GPT-4o和o4-mini等强大专有模型，以及R1-Onevision和LLaVA-CoT等推理模型）的弱点，许多思维链推理模型在智能体间协作中的表现甚至不如随机基线，表明其交流能力有待提高。",
            "intro_zh": [
                "现有智能体基准在评估多智能体语言交流协作方面存在不足，无法有效衡量智能体在信息不对称情况下的协同能力。",
                "COMMA基准通过设计多模态谜题，模拟真实协作场景，考察智能体在语言沟通下的问题解决、信息共享和协同推理能力。",
                "实验结果表明，即使是GPT-4o等先进模型在COMMA基准上表现不佳，表明多智能体交流协作仍是当前模型的薄弱环节。"
            ],
            "method_zh": "**问题定义**：现有的大型多模态模型在单智能体任务上取得了显著进展，但在多智能体协作，特别是需要语言交流的协作场景中，其能力尚未得到充分评估。现有的智能体基准测试未能充分考虑智能体之间信息不对称、任务复杂性以及交流策略等关键因素，导致无法准确评估智能体在真实协作环境中的表现。\\n\\n**核心思路**：COMMA基准的核心思路是设计一系列多模态谜题，这些谜题需要多个智能体通过语言交流，共享信息、协商策略并协同解决。通过控制每个智能体所能访问的信息，并增加谜题的复杂性，COMMA能够更全面地评估智能体在协作过程中的推理、沟通和决策能力。\\n\\n**技术框架**：COMMA基准包含一个谜题生成器，用于创建各种多模态谜题。每个谜题都包含视觉信息（例如图像）和文本描述，并分配给多个智能体。智能体之间可以通过语言进行交流，但每个智能体只能访问部分信息。智能体需要通过交流，整合信息，推理出谜题的答案。评估指标包括谜题解决率、交流效率和协作质量。\\n\\n**关键创新**：COMMA基准的关键创新在于其对多智能体协作场景的模拟，以及对语言交流在协作过程中的作用的强调。与传统的单智能体基准测试相比，COMMA更贴近真实世界的应用场景，能够更有效地评估智能体的协作能力。此外，COMMA还提供了一个可扩展的谜题生成框架，可以根据需要生成不同难度和类型的谜题。\\n\\n**关键设计**：COMMA基准中的谜题设计考虑了以下关键因素：信息不对称程度、谜题复杂性、交流成本和协作策略。谜题的难度可以通过调整视觉信息的清晰度、文本描述的详细程度以及智能体之间的交流限制来控制。评估指标的设计旨在衡量智能体的协作效率和质量，包括谜题解决率、交流轮数、交流内容的相关性和准确性等。",
            "application_zh": "COMMA基准的潜在应用领域包括：多智能体机器人协作、人机协作、智能交通系统、分布式决策系统等。通过COMMA基准，可以更好地评估和改进多智能体系统的协作能力，提高其在复杂环境中的适应性和可靠性。此外，COMMA还可以用于研究人类协作行为，为设计更有效的人机协作系统提供理论基础。",
            "highlight_zh": "实验结果表明，即使是像GPT-4o这样强大的专有模型，在COMMA基准上的表现也远未达到理想水平。许多思维链推理模型，如R1-Onevision和LLaVA-CoT，在智能体间协作中的表现甚至不如随机基线。这表明当前的多模态模型在多智能体交流协作方面仍存在显著的不足，需要进一步的研究和改进。",
            "tags_zh": [
                "多智能体系统",
                "多模态学习",
                "语言交流",
                "协作基准",
                "智能体评估"
            ],
            "_index": 22,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2410.07553/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2410.07553/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2410.07553/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Why Text Prevails: Vision May Undermine Multimodal Medical Decision Making",
            "authors": [
                "Siyuan Dai",
                "Lunxiao Li",
                "Kun Zhao",
                "Eardi Lila",
                "Paul K. Crane",
                "Heng Huang",
                "Dongkuan Xu",
                "Haoteng Tang",
                "Liang Zhan"
            ],
            "arxiv_id": "2512.13747",
            "summary": "With the rapid progress of large language models (LLMs), advanced multimodal large language models (MLLMs) have demonstrated impressive zero-shot capabilities on vision-language tasks. In the biomedical domain, however, even state-of-the-art MLLMs struggle with basic Medical Decision Making (MDM) tasks. We investigate this limitation using two challenging datasets: (1) three-stage Alzheimer's disease (AD) classification (normal, mild cognitive impairment, dementia), where category differences are visually subtle, and (2) MIMIC-CXR chest radiograph classification with 14 non-mutually exclusive conditions. Our empirical study shows that text-only reasoning consistently outperforms vision-only or vision-text settings, with multimodal inputs often performing worse than text alone. To mitigate this, we explore three strategies: (1) in-context learning with reason-annotated exemplars, (2) vision captioning followed by text-only inference, and (3) few-shot fine-tuning of the vision tower with classification supervision. These findings reveal that current MLLMs lack grounded visual understanding and point to promising directions for improving multimodal decision making in healthcare.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13747",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "MDM"
                    ],
                    "score": 2.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "[T]multimodal"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 14.5,
            "hit_pillars": [
                "4_motion_diffusion",
                "9_embodied_foundation"
            ],
            "headline_zh": "研究表明：在医学决策中，文本信息优于视觉信息，多模态融合可能适得其反",
            "summary_zh": "随着大型语言模型（LLMs）的快速发展，先进的多模态大型语言模型（MLLMs）在视觉-语言任务中展现了令人印象深刻的零样本能力。然而，在生物医学领域，即使是最先进的MLLMs在基本的医学决策（MDM）任务中也表现不佳。本研究通过两个具有挑战性的数据集来调查这一局限性：（1）三阶段阿尔茨海默病（AD）分类（正常、轻度认知障碍、痴呆），其中类别差异在视觉上很微妙；（2）MIMIC-CXR胸部X光片分类，包含14种非互斥的疾病。实证研究表明，仅文本推理始终优于仅视觉或视觉-文本设置，多模态输入通常比仅文本表现更差。为了缓解这个问题，我们探索了三种策略：（1）使用带有原因注释的示例进行上下文学习；（2）视觉描述后进行仅文本推理；（3）使用分类监督对视觉塔进行少量样本微调。这些发现表明，当前的MLLMs缺乏扎实的视觉理解，并为改善医疗保健中的多模态决策提供了有希望的方向。",
            "intro_zh": [
                "现有MLLMs在生物医学决策任务中表现不佳，尤其是在视觉信息微妙或复杂的场景下，面临挑战。",
                "研究核心在于分析文本、视觉以及多模态信息在医学决策中的作用，并探索提升多模态性能的策略。",
                "实验结果表明，文本信息在医学决策中起主导作用，多模态融合效果不佳，并提出了三种改进策略。"
            ],
            "method_zh": "**问题定义**：论文旨在解决多模态大型语言模型（MLLMs）在医学决策（MDM）任务中表现不佳的问题，尤其是在视觉信息不明显或容易产生歧义的情况下。现有方法过度依赖视觉信息，导致性能下降，未能充分利用文本信息的优势。\\n\\n**核心思路**：论文的核心思路是揭示文本信息在医学决策中的主导地位，并探索如何更好地利用文本信息来提升多模态模型的性能。通过对比文本、视觉和多模态输入在不同医学数据集上的表现，验证文本信息的重要性，并提出相应的改进策略。\\n\\n**技术框架**：整体框架包括数据准备、模型选择、实验设计和结果分析四个主要部分。首先，选择两个具有挑战性的医学数据集：阿尔茨海默病（AD）分类和MIMIC-CXR胸部X光片分类。然后，使用现有的MLLMs作为基线模型，并设计不同的输入模式（仅文本、仅视觉、多模态）。最后，通过实验对比不同输入模式下的性能，并分析结果。\\n\\n**关键创新**：论文的关键创新在于揭示了在医学决策任务中，文本信息的重要性超过视觉信息，并且多模态融合可能适得其反。这一发现挑战了传统的视觉-语言模型的设计理念，并为未来的研究提供了新的方向。\\n\\n**关键设计**：论文的关键设计包括：(1) 使用reason-annotated exemplars进行上下文学习，以提升模型的推理能力；(2) 使用视觉描述模型生成文本描述，然后进行文本推理，以缓解视觉信息的不足；(3) 使用少量样本对视觉塔进行微调，以提升视觉特征的表达能力。这些设计旨在更好地利用文本信息，并提升多模态模型的性能。",
            "application_zh": "该研究成果可应用于辅助医生进行疾病诊断和治疗决策，尤其是在影像学诊断方面。通过优化多模态模型的性能，可以提高诊断的准确性和效率，减少误诊和漏诊的风险。未来的研究可以进一步探索如何更好地融合文本和视觉信息，开发更智能、更可靠的医学决策支持系统。",
            "highlight_zh": "实验结果表明，在阿尔茨海默病分类和MIMIC-CXR胸部X光片分类任务中，仅文本推理的性能始终优于仅视觉或视觉-文本设置。多模态输入甚至可能比仅文本表现更差。通过提出的三种改进策略，可以在一定程度上提升多模态模型的性能，但仍有很大的提升空间。",
            "tags_zh": [
                "医学决策",
                "多模态学习",
                "视觉语言模型",
                "文本信息",
                "阿尔茨海默病",
                "胸部X光片",
                "MIMIC-CXR"
            ],
            "_index": 23,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13747/fig.png",
                    "caption": "",
                    "figure_id": "fig_0"
                }
            ]
        },
        {
            "title": "CaFe-TeleVision: A Coarse-to-Fine Teleoperation System with Immersive Situated Visualization for Enhanced Ergonomics",
            "authors": [
                "Zixin Tang",
                "Yiming Chen",
                "Quentin Rouxel",
                "Dianxi Li",
                "Shuang Wu",
                "Fei Chen"
            ],
            "arxiv_id": "2512.14270",
            "summary": "Teleoperation presents a promising paradigm for remote control and robot proprioceptive data collection. Despite recent progress, current teleoperation systems still suffer from limitations in efficiency and ergonomics, particularly in challenging scenarios. In this paper, we propose CaFe-TeleVision, a coarse-to-fine teleoperation system with immersive situated visualization for enhanced ergonomics. At its core, a coarse-to-fine control mechanism is proposed in the retargeting module to bridge workspace disparities, jointly optimizing efficiency and physical ergonomics. To stream immersive feedback with adequate visual cues for human vision systems, an on-demand situated visualization technique is integrated in the perception module, which reduces the cognitive load for multi-view processing. The system is built on a humanoid collaborative robot and validated with six challenging bimanual manipulation tasks. User study among 24 participants confirms that CaFe-TeleVision enhances ergonomics with statistical significance, indicating a lower task load and a higher user acceptance during teleoperation. Quantitative results also validate the superior performance of our system across six tasks, surpassing comparative methods by up to 28.89% in success rate and accelerating by 26.81% in completion time. Project webpage:this https URL",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14270",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "humanoid",
                        "manipulation",
                        "bi-manual",
                        "bimanual manipulation",
                        "[T]teleoperation"
                    ],
                    "score": 14.0
                }
            ],
            "relevance_score": 14.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "CaFe-TeleVision：面向人机工效增强的粗细粒度遥操作与沉浸式情境可视化系统",
            "summary_zh": "本文提出了一种名为CaFe-TeleVision的粗细粒度遥操作系统，该系统具有沉浸式情境可视化功能，旨在增强人机工效。该系统的核心在于重定向模块中提出的粗细粒度控制机制，用于弥合工作空间差异，从而联合优化效率和物理人机工效。为了以足够视觉线索传输沉浸式反馈，感知模块中集成了一种按需情境可视化技术，从而降低了多视图处理的认知负荷。该系统构建在一个人形协作机器人之上，并通过六项具有挑战性的双手操作任务进行了验证。对24名参与者进行的用户研究证实，CaFe-TeleVision在统计学意义上增强了人机工效，表明在遥操作期间任务负荷更低，用户接受度更高。定量结果还验证了我们的系统在六项任务中的卓越性能，在成功率方面超过了比较方法高达28.89%，在完成时间方面加快了26.81%。",
            "intro_zh": [
                "现有遥操作系统在效率和人机工效方面存在局限性，尤其是在复杂场景下，需要更高效舒适的控制方案。",
                "CaFe-TeleVision采用粗细粒度控制机制，优化工作空间映射，并结合按需情境可视化，降低认知负荷。",
                "实验表明，该系统显著提升了人机工效，任务成功率提升高达28.89%，完成时间缩短高达26.81%。"
            ],
            "method_zh": "**问题定义**：现有遥操作系统在处理工作空间差异时，往往难以兼顾操作效率和人机工效。操作员需要花费大量精力进行空间转换和多视角信息融合，导致认知负荷高，操作疲劳，从而影响任务完成质量和效率。现有方法缺乏对操作员认知负荷的有效优化，限制了遥操作系统的应用范围。\\n\\n**核心思路**：CaFe-TeleVision的核心思路是通过粗细粒度控制机制和按需情境可视化，降低操作员的认知负荷，提高操作效率和舒适度。粗粒度控制用于快速定位目标，细粒度控制用于精确操作。按需情境可视化则根据操作员的需求，提供关键的视觉信息，避免信息过载。\\n\\n**技术框架**：CaFe-TeleVision系统主要包含感知模块和重定向模块。感知模块负责获取机器人周围环境的多视角图像，并进行处理，生成用于情境可视化的信息。重定向模块负责将操作员的动作映射到机器人，并实现粗细粒度的控制。系统整体流程为：操作员通过输入设备进行操作 -> 重定向模块将操作映射到机器人 -> 感知模块提供情境可视化反馈 -> 操作员根据反馈调整操作。\\n\\n**关键创新**：该论文的关键创新在于粗细粒度控制机制和按需情境可视化技术的结合。粗细粒度控制机制能够有效地弥合工作空间差异，提高操作效率。按需情境可视化技术能够根据操作员的需求，提供关键的视觉信息，降低认知负荷。与现有方法相比，CaFe-TeleVision更加注重人机工效，能够提供更舒适、高效的遥操作体验。\\n\\n**关键设计**：粗细粒度控制机制的具体实现方式未知，论文中可能涉及一些参数设置，比如粗细粒度切换的阈值，以及重定向模块中使用的映射函数。按需情境可视化技术的具体实现方式也未知，可能涉及一些图像处理算法，用于提取关键的视觉信息。损失函数和网络结构等技术细节在摘要中未提及，属于未知信息。",
            "application_zh": "CaFe-TeleVision系统具有广泛的应用前景，可应用于危险环境下的远程操作、医疗手术辅助、太空探索等领域。该系统能够提高操作效率和安全性，降低操作员的认知负荷，从而扩展遥操作技术的应用范围。未来，该系统可以与更先进的机器人技术和人工智能技术相结合，实现更智能、更高效的遥操作。",
            "highlight_zh": "用户研究表明，CaFe-TeleVision系统在统计学意义上增强了人机工效，降低了任务负荷，提高了用户接受度。定量结果显示，该系统在六项任务中的成功率超过了比较方法高达28.89%，完成时间加快了26.81%。这些结果表明，CaFe-TeleVision系统在效率和人机工效方面都具有显著优势。",
            "tags_zh": [
                "遥操作",
                "人机工效",
                "粗细粒度控制",
                "情境可视化",
                "机器人",
                "人机交互",
                "远程控制"
            ],
            "_index": 24,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14270/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14270/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14270/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Beyond a Single Light: A Large-Scale Aerial Dataset for Urban Scene Reconstruction Under Varying Illumination",
            "authors": [
                "Zhuoxiao Li",
                "Wenzong Ma",
                "Taoyu Wu",
                "Jinjing Zhu",
                "Zhenchao Q",
                "Shuai Zhang",
                "Jing Ou",
                "Yinrui Ren",
                "Weiqing Qi",
                "Guobin Shen",
                "Hui Xiong",
                "Wufan Zhao"
            ],
            "arxiv_id": "2512.14200",
            "summary": "Recent advances in Neural Radiance Fields and 3D Gaussian Splatting have demonstrated strong potential for large-scale UAV-based 3D reconstruction tasks by fitting the appearance of images. However, real-world large-scale captures are often based on multi-temporal data capture, where illumination inconsistencies across different times of day can significantly lead to color artifacts, geometric inaccuracies, and inconsistent appearance. Due to the lack of UAV datasets that systematically capture the same areas under varying illumination conditions, this challenge remains largely underexplored. To fill this gap, we introduceSkyLume, a large-scale, real-world UAV dataset specifically designed for studying illumination robust 3D reconstruction in urban scene modeling: (1) We collect data from 10 urban regions data comprising more than 100k high resolution UAV images (four oblique views and nadir), where each region is captured at three periods of the day to systematically isolate illumination changes. (2) To support precise evaluation of geometry and appearance, we provide per-scene LiDAR scans and accurate 3D ground-truth for assessing depth, surface normals, and reconstruction quality under varying illumination. (3) For the inverse rendering task, we introduce the Temporal Consistency Coefficient (TCC), a metric that measuress cross-time albedo stability and directly evaluates the robustness of the disentanglement of light and material. We aim for this resource to serve as a foundation that advances research and real-world evaluation in large-scale inverse rendering, geometry reconstruction, and novel view synthesis.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14200",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "3D gaussian splatting",
                        "gaussian splatting",
                        "splatting",
                        "neural radiance field",
                        "[T]scene reconstruction"
                    ],
                    "score": 14.0
                }
            ],
            "relevance_score": 14.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "提出SkyLume数据集，用于解决城市场景三维重建中光照变化带来的挑战。",
            "summary_zh": "本文提出了SkyLume，一个大规模的真实无人机航拍数据集，专门用于研究城市场景建模中光照鲁棒的三维重建。现有的基于神经辐射场和3D高斯溅射的方法在拟合图像外观方面表现出强大的潜力，但真实场景的大规模数据采集通常基于多时相数据，不同时间段的光照不一致会导致颜色伪影、几何不准确和外观不一致。SkyLume数据集包含10个城市区域，超过10万张高分辨率无人机图像（四个倾斜视图和正射视图），每个区域在一天中的三个时段进行拍摄，以系统地隔离光照变化。为了支持对几何和外观的精确评估，本文提供了每个场景的LiDAR扫描和精确的3D真值，用于评估深度、表面法线和不同光照下的重建质量。此外，本文还引入了时间一致性系数（TCC），用于衡量跨时间的反照率稳定性，并直接评估光照和材质解耦的鲁棒性。该数据集旨在为大规模逆渲染、几何重建和新视角合成的研究和实际评估提供基础。",
            "intro_zh": [
                "现有方法在多时相数据下，由于光照不一致，导致三维重建出现颜色伪影和几何误差。",
                "SkyLume数据集通过系统地捕捉不同光照条件下的城市区域图像，为研究光照鲁棒性提供了数据基础。",
                "论文提出了时间一致性系数（TCC）指标，用于评估逆渲染中光照和材质解耦的鲁棒性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决城市场景三维重建中，由于多时相数据采集导致的光照变化问题。现有方法在处理此类数据时，容易产生颜色伪影、几何不准确和外观不一致等问题，严重影响重建质量。缺乏系统性的、包含不同光照条件下的无人机数据集是阻碍相关研究进展的关键因素。\\n\\n**核心思路**：论文的核心思路是构建一个大规模的、包含不同光照条件下的城市区域无人机数据集，从而为研究光照鲁棒的三维重建方法提供数据基础。通过在一天中的不同时段对同一区域进行多次拍摄，系统性地捕捉光照变化，并提供高精度的几何真值，为算法的评估和改进提供支持。\\n\\n**技术框架**：SkyLume数据集的构建流程主要包括以下几个阶段：1) 数据采集：使用无人机在10个不同的城市区域进行数据采集，每个区域在一天中的三个不同时段（例如早晨、中午和傍晚）进行拍摄，以捕捉不同的光照条件。2) 图像获取：每个区域采集超过10万张高分辨率无人机图像，包括四个倾斜视图和一个正射视图。3) 几何真值获取：使用LiDAR扫描仪获取每个场景的精确三维点云数据，作为几何真值。4) 数据处理与标注：对采集到的图像和点云数据进行处理和标注，生成可用于训练和评估的数据集。\\n\\n**关键创新**：SkyLume数据集的关键创新在于其系统性地捕捉了不同光照条件下的城市区域图像，并提供了高精度的几何真值。此外，论文还提出了时间一致性系数（TCC）指标，用于评估逆渲染中光照和材质解耦的鲁棒性。这是现有数据集和评估方法所缺乏的。\\n\\n**关键设计**：数据集包含10个城市区域，每个区域在三个不同时段拍摄，图像分辨率高。提供了LiDAR扫描数据作为几何真值，并提出了时间一致性系数（TCC）作为评估指标。TCC的具体计算方法未知，但其目的是衡量跨时间的反照率稳定性，从而评估光照和材质解耦的鲁棒性。",
            "application_zh": "该研究成果可广泛应用于城市建模、自动驾驶、虚拟现实、增强现实等领域。通过利用SkyLume数据集训练的光照鲁棒的三维重建算法，可以提高城市模型的精度和真实感，为自动驾驶车辆提供更可靠的环境感知，并为虚拟现实和增强现实应用提供更逼真的场景。",
            "highlight_zh": "SkyLume数据集包含10个城市区域，超过10万张高分辨率无人机图像，并提供了高精度的LiDAR扫描数据作为几何真值。论文提出了时间一致性系数（TCC）指标，用于评估逆渲染中光照和材质解耦的鲁棒性。这些数据和评估指标为研究光照鲁棒的三维重建方法提供了有力支持。",
            "tags_zh": [
                "三维重建",
                "无人机航拍",
                "光照鲁棒性",
                "城市建模",
                "数据集",
                "逆渲染",
                "神经辐射场",
                "3D高斯溅射"
            ],
            "_index": 25,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14200/images/pipeline.jpg",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14200/images/post1.jpg",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14200/images/lidarmesh.jpg",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "A4-Agent: An Agentic Framework for Zero-Shot Affordance Reasoning",
            "authors": [
                "Zixin Zhang",
                "Kanghao Chen",
                "Hanqing Wang",
                "Hongfei Zhang",
                "Harold Haodong Chen",
                "Chenfei Liao",
                "Litao Guo",
                "Ying-Cong Chen"
            ],
            "arxiv_id": "2512.14442",
            "summary": "Affordance prediction, which identifies interaction regions on objects based on language instructions, is critical for embodied AI. Prevailing end-to-end models couple high-level reasoning and low-level grounding into a single monolithic pipeline and rely on training over annotated datasets, which leads to poor generalization on novel objects and unseen environments. In this paper, we move beyond this paradigm by proposing A4-Agent, a training-free agentic framework that decouples affordance prediction into a three-stage pipeline. Our framework coordinates specialized foundation models at test time: (1) a $\\textbf{Dreamer}$ that employs generative models to visualize $\\textit{how}$ an interaction would look; (2) a $\\textbf{Thinker}$ that utilizes large vision-language models to decide $\\textit{what}$ object part to interact with; and (3) a $\\textbf{Spotter}$ that orchestrates vision foundation models to precisely locate $\\textit{where}$ the interaction area is. By leveraging the complementary strengths of pre-trained models without any task-specific fine-tuning, our zero-shot framework significantly outperforms state-of-the-art supervised methods across multiple benchmarks and demonstrates robust generalization to real-world settings.",
            "categories": [
                "cs.CV",
                "cs.RO"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14442",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "dreamer"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "[T]affordance"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "embodied AI",
                        "foundation model"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 13.5,
            "hit_pillars": [
                "2_algo_arch",
                "3_perception_slam",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出A4-Agent，一个零样本具身智能框架，用于解决通用可供性推理问题。",
            "summary_zh": "本文提出A4-Agent，一个无需训练的agent框架，用于解决具身智能中的可供性预测问题。可供性预测旨在根据语言指令识别物体上的交互区域，这对于具身AI至关重要。现有的端到端模型将高层推理和低层基础耦合到一个单一的pipeline中，并依赖于带标注数据集的训练，导致对新物体和未见环境的泛化能力较差。A4-Agent通过将可供性预测解耦为一个三阶段的pipeline来突破这一局限。该框架在测试时协调专门的基础模型：(1) Dreamer，利用生成模型来可视化交互的样子；(2) Thinker，利用大型视觉-语言模型来决定与哪个物体部分进行交互；(3) Spotter，协调视觉基础模型来精确定位交互区域。通过利用预训练模型的互补优势，无需任何特定于任务的微调，我们的零样本框架在多个基准测试中显著优于最先进的监督方法，并展示了对真实世界环境的强大泛化能力。",
            "intro_zh": [
                "现有可供性预测模型依赖大量标注数据，泛化性差，难以适应新物体和环境。",
                "A4-Agent将可供性预测解耦为三个阶段，分别由Dreamer、Thinker和Spotter三个模块完成。",
                "A4-Agent无需训练，利用预训练模型优势，在多个基准测试中超越了有监督方法。"
            ],
            "method_zh": "**问题定义**：论文旨在解决零样本条件下的可供性推理问题，即在没有特定任务训练数据的情况下，根据语言指令预测物体上可交互的区域。现有方法的痛点在于过度依赖有监督学习，导致模型泛化能力不足，难以适应新的物体和环境。这些方法通常将高层推理和低层视觉感知耦合在一起，难以有效利用预训练模型的知识。\n\n**核心思路**：论文的核心思路是将可供性推理过程解耦为三个独立的阶段，每个阶段由专门的预训练模型负责。这种解耦使得每个模块可以专注于特定的任务，并充分利用预训练模型在各自领域的优势。通过组合这些模块，A4-Agent能够实现零样本的可供性推理。\n\n**技术框架**：A4-Agent框架包含三个主要模块：Dreamer、Thinker和Spotter。Dreamer模块使用生成模型（如扩散模型）根据语言指令生成交互的视觉效果，模拟交互过程。Thinker模块使用大型视觉-语言模型（如CLIP）来判断应该与物体的哪个部分进行交互，进行高层推理。Spotter模块使用视觉基础模型（如分割模型）来精确定位交互区域，完成低层视觉感知。这三个模块依次执行，形成一个完整的可供性推理pipeline。\n\n**关键创新**：A4-Agent的关键创新在于其agentic的框架设计，将可供性推理分解为多个可解释的步骤，并利用预训练模型在每个步骤中发挥作用。与传统的端到端模型相比，A4-Agent不需要任何特定任务的训练数据，并且能够更好地利用预训练模型的知识，从而实现更好的泛化能力。此外，这种解耦的设计也使得模型更易于理解和调试。\n\n**关键设计**：Dreamer模块可以使用不同的生成模型，例如Stable Diffusion。Thinker模块可以使用CLIP等视觉-语言模型，通过计算文本描述和图像区域之间的相似度来选择交互区域。Spotter模块可以使用Mask R-CNN等分割模型来精确定位交互区域。论文中可能涉及一些超参数的调整，例如相似度阈值等，但具体细节需要参考论文原文。",
            "application_zh": "A4-Agent在机器人操作、虚拟助手和增强现实等领域具有广泛的应用前景。它可以帮助机器人理解人类指令，并自主地与环境中的物体进行交互。在虚拟助手领域，它可以根据用户的语言描述，在虚拟环境中进行操作。在增强现实领域，它可以为用户提供关于物体交互方式的指导。该研究有望推动具身智能的发展，使AI系统更加智能和实用。",
            "highlight_zh": "A4-Agent在多个基准测试中显著优于最先进的监督方法，展示了强大的零样本泛化能力。具体性能数据和对比基线需要在论文原文中查找。该框架在真实世界环境中的表现也令人印象深刻，证明了其在实际应用中的潜力。无需任何特定任务的微调是其最大的优势之一。",
            "tags_zh": [
                "可供性推理",
                "具身智能",
                "零样本学习",
                "视觉-语言模型",
                "预训练模型"
            ],
            "_index": 26,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14442/x2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14442/x3.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14442/x4.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "OmniDrive-R1: Reinforcement-driven Interleaved Multi-modal Chain-of-Thought for Trustworthy Vision-Language Autonomous Driving",
            "authors": [
                "Zhenguo Zhang",
                "Haohan Zhen",
                "Yishen Wang",
                "Le Xu",
                "Tianchen Deng",
                "Xuefeng Chen",
                "Qu Chen",
                "Bo Zhang",
                "Wuxiong Huang"
            ],
            "arxiv_id": "2512.14044",
            "summary": "The deployment of Vision-Language Models (VLMs) in safety-critical domains like autonomous driving (AD) is critically hindered by reliability failures, most notably object hallucination. This failure stems from their reliance on ungrounded, text-based Chain-of-Thought (CoT)this http URLexisting multi-modal CoT approaches attempt mitigation, they suffer from two fundamental flaws: (1) decoupled perception and reasoning stages that prevent end-to-end joint optimization, and (2) reliance on expensive, dense localizationthis http URLwe introduce OmniDrive-R1, an end-to-end VLM framework designed for autonomous driving, which unifies perception and reasoning through an interleaved Multi-modal Chain-of-Thought (iMCoT) mechanism. Our core innovation is an Reinforcement-driven visual grounding capability, enabling the model to autonomously direct its attention and \"zoom in\" on critical regions for fine-grained analysis. This capability is enabled by our pure two-stage reinforcement learning training pipeline and Clip-GRPO algorithm. Crucially, Clip-GRPO introduces an annotation-free, process-based grounding reward. This reward not only eliminates the need for dense labels but also circumvents the instability of external tool calls by enforcing real-time cross-modal consistency between the visual focus and the textual reasoning. Extensive experiments on DriveLMM-o1 demonstrate our model's significant improvements. Compared to the baseline Qwen2.5VL-7B, OmniDrive-R1 improves the overall reasoning score from 51.77% to 80.35%, and the final answer accuracy from 37.81% to 73.62%.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14044",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "visual grounding",
                        "[T]chain-of-thought"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 13.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "OmniDrive-R1：基于强化学习的多模态交错CoT，提升自动驾驶视觉语言模型的可靠性",
            "summary_zh": "视觉语言模型(VLM)在自动驾驶等安全关键领域的部署受到可靠性问题的严重阻碍，特别是目标幻觉。这种失败源于它们对未经验证的、基于文本的思维链(CoT)的依赖。现有的多模态CoT方法试图缓解这个问题，但存在两个根本缺陷：(1)解耦的感知和推理阶段，阻碍了端到端联合优化；(2)依赖于昂贵的、密集的定位标注。我们提出了OmniDrive-R1，一个为自动驾驶设计的端到端VLM框架，它通过交错多模态思维链(iMCoT)机制统一了感知和推理。我们的核心创新是强化学习驱动的视觉 grounding 能力，使模型能够自主地引导其注意力并“放大”关键区域以进行细粒度分析。这种能力由我们的纯粹两阶段强化学习训练流程和Clip-GRPO算法实现。至关重要的是，Clip-GRPO引入了一种无标注的、基于过程的 grounding 奖励。这种奖励不仅消除了对密集标签的需求，还通过强制视觉焦点和文本推理之间的实时跨模态一致性，规避了外部工具调用的不稳定性。在DriveLMM-o1上的大量实验证明了我们模型的显著改进。与基线Qwen2.5VL-7B相比，OmniDrive-R1将整体推理得分从51.77%提高到80.35%，最终答案准确率从37.81%提高到73.62%。",
            "intro_zh": [
                "现有VLM在自动驾驶中面临目标幻觉问题，源于对未经验证文本CoT的依赖，且感知与推理解耦。",
                "OmniDrive-R1提出交错多模态CoT，通过强化学习驱动视觉grounding，使模型自主关注关键区域。",
                "在DriveLMM-o1数据集上，OmniDrive-R1显著提升推理得分和答案准确率，优于Qwen2.5VL-7B基线。"
            ],
            "method_zh": "**问题定义**：现有视觉语言模型在自动驾驶场景中，由于依赖于纯文本的CoT推理，容易产生目标幻觉，导致决策错误。同时，现有的多模态CoT方法通常将感知和推理阶段解耦，无法进行端到端的联合优化，并且需要昂贵的密集标注。\n\n**核心思路**：OmniDrive-R1的核心思路是通过交错的多模态CoT（iMCoT）机制，将感知和推理过程紧密结合，实现端到端的优化。同时，利用强化学习来驱动视觉 grounding，使模型能够自主地关注图像中的关键区域，从而减少目标幻觉。\n\n**技术框架**：OmniDrive-R1是一个端到端的VLM框架，包含以下主要模块：1) 交错多模态CoT模块：将视觉信息和文本信息交替输入，进行感知和推理的融合。2) 强化学习模块：通过强化学习训练视觉 grounding 能力，使模型能够自主地选择关注的图像区域。3) Clip-GRPO算法：用于生成无标注的、基于过程的 grounding 奖励，鼓励模型关注与文本推理一致的视觉区域。\n\n**关键创新**：OmniDrive-R1的关键创新在于：1) 提出了交错多模态CoT（iMCoT）机制，实现了感知和推理的端到端联合优化。2) 引入了强化学习来驱动视觉 grounding，使模型能够自主地关注图像中的关键区域。3) 提出了Clip-GRPO算法，生成无标注的、基于过程的 grounding 奖励，避免了对密集标注的依赖。\n\n**关键设计**：OmniDrive-R1使用纯粹的两阶段强化学习训练流程。Clip-GRPO算法的关键在于设计了一个基于过程的 grounding 奖励，该奖励基于视觉焦点和文本推理之间的跨模态一致性。具体来说，模型会根据当前的文本推理状态，选择一个图像区域进行关注，然后根据该区域的视觉信息更新文本推理状态。如果更新后的文本推理状态与预期的一致，则给予模型正向奖励，否则给予负向奖励。这种奖励机制鼓励模型关注与文本推理相关的视觉区域。",
            "application_zh": "OmniDrive-R1的研究成果可应用于自动驾驶、机器人导航、智能监控等领域。通过提高视觉语言模型的可靠性和准确性，可以提升自动驾驶系统的安全性，减少事故发生率。此外，该方法还可以应用于其他需要视觉和语言理解的场景，例如智能客服、图像描述等。",
            "highlight_zh": "OmniDrive-R1在DriveLMM-o1数据集上取得了显著的性能提升。与基线模型Qwen2.5VL-7B相比，OmniDrive-R1将整体推理得分从51.77%提高到80.35%，最终答案准确率从37.81%提高到73.62%。这些结果表明，OmniDrive-R1能够有效地减少目标幻觉，提高视觉语言模型在自动驾驶场景中的可靠性。",
            "tags_zh": [
                "自动驾驶",
                "视觉语言模型",
                "多模态学习",
                "思维链",
                "强化学习",
                "目标幻觉",
                "视觉 grounding"
            ],
            "_index": 27,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14044/exam.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14044/overview.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14044/2_stage.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Unified Semantic Transformer for 3D Scene Understanding",
            "authors": [
                "Sebastian Koch",
                "Johanna Wald",
                "Hide Matsuki",
                "Pedro Hermosilla",
                "Timo Ropinski",
                "Federico Tombari"
            ],
            "arxiv_id": "2512.14364",
            "summary": "Holistic 3D scene understanding involves capturing and parsing unstructured 3D environments. Due to the inherent complexity of the real world, existing models have predominantly been developed and limited to be task-specific. We introduce UNITE, a Unified Semantic Transformer for 3D scene understanding, a novel feed-forward neural network that unifies a diverse set of 3D semantic tasks within a single model. Our model operates on unseen scenes in a fully end-to-end manner and only takes a few seconds to infer the full 3D semantic geometry. Our approach is capable of directly predicting multiple semantic attributes, including 3D scene segmentation, instance embeddings, open-vocabulary features, as well as affordance and articulations, solely from RGB images. The method is trained using a combination of 2D distillation, heavily relying on self-supervision and leverages novel multi-view losses designed to ensure 3D view consistency. We demonstrate that UNITE achieves state-of-the-art performance on several different semantic tasks and even outperforms task-specific models, in many cases, surpassing methods that operate on ground truth 3D geometry. See the project website atthis http URL",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14364",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "distillation"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "[T]scene understanding",
                        "open-vocabulary",
                        "open vocabulary",
                        "affordance"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 13.5,
            "hit_pillars": [
                "2_algo_arch",
                "3_perception_slam"
            ],
            "headline_zh": "提出UNITE：用于3D场景理解的统一语义Transformer模型",
            "summary_zh": "本文提出UNITE，一种用于3D场景理解的统一语义Transformer模型。该模型是一个新颖的前馈神经网络，它在一个单一模型中统一了多种3D语义任务。UNITE以完全端到端的方式处理未见过的场景，只需几秒钟即可推断出完整的3D语义几何结构。该方法能够仅从RGB图像直接预测多个语义属性，包括3D场景分割、实例嵌入、开放词汇特征以及可供性和关节。该模型采用2D知识蒸馏进行训练，大量依赖自监督，并利用新颖的多视角损失来确保3D视角一致性。实验表明，UNITE在多个不同的语义任务上实现了最先进的性能，甚至优于特定任务的模型，在许多情况下，超过了在真实3D几何上运行的方法。",
            "intro_zh": [
                "现有3D场景理解模型通常是任务特定的，难以处理真实世界环境的复杂性。",
                "UNITE通过统一的Transformer架构，从RGB图像直接预测多种语义属性，实现端到端的3D场景理解。",
                "UNITE在多个语义任务上取得了SOTA性能，甚至超越了使用真实3D几何信息的特定任务模型。"
            ],
            "method_zh": "**问题定义**：现有的3D场景理解模型通常是针对特定任务设计的，例如场景分割、实例分割或可供性预测。这些模型无法在一个统一的框架下处理多种语义任务，并且通常需要ground truth 3D几何信息。因此，如何设计一个能够从RGB图像中直接预测多种语义属性，并且能够处理未见过的场景的统一模型是一个挑战。\\n\\n**核心思路**：UNITE的核心思路是利用Transformer架构的强大表示能力，将不同的3D语义任务统一到一个模型中。通过共享的特征表示，模型可以学习不同任务之间的关联性，从而提高整体性能。此外，模型采用2D知识蒸馏和自监督学习，以减少对ground truth 3D几何信息的依赖。\\n\\n**技术框架**：UNITE的整体架构是一个前馈神经网络，它以RGB图像作为输入，并输出多个语义属性，包括3D场景分割、实例嵌入、开放词汇特征、可供性和关节。该模型包含一个图像编码器，用于提取图像特征；一个Transformer编码器，用于学习特征之间的关系；以及多个解码器，用于预测不同的语义属性。模型采用多视角损失函数，以确保3D视角一致性。\\n\\n**关键创新**：UNITE的关键创新在于它是一个统一的3D场景理解模型，能够在一个单一框架下处理多种语义任务。与现有的特定任务模型相比，UNITE具有更强的泛化能力和更高的效率。此外，UNITE采用2D知识蒸馏和自监督学习，减少了对ground truth 3D几何信息的依赖。\\n\\n**关键设计**：UNITE的关键设计包括：1) 使用Transformer编码器来学习特征之间的关系；2) 采用多视角损失函数来确保3D视角一致性；3) 使用2D知识蒸馏和自监督学习来减少对ground truth 3D几何信息的依赖。具体的损失函数包括分割损失、实例嵌入损失、开放词汇特征损失、可供性损失和关节损失。网络结构细节未在摘要中详细说明，具体实现可能参考了Transformer相关的经典设计。",
            "application_zh": "UNITE具有广泛的应用前景，例如机器人导航、自动驾驶、增强现实和虚拟现实。它可以帮助机器人理解周围环境，从而实现更智能的交互。在自动驾驶领域，UNITE可以用于识别道路上的物体和场景，从而提高驾驶安全性。在AR/VR领域，UNITE可以用于创建更逼真的虚拟环境，并实现更自然的交互。",
            "highlight_zh": "UNITE在多个3D语义任务上取得了state-of-the-art的性能，包括3D场景分割、实例嵌入、开放词汇特征、可供性和关节预测。在许多情况下，UNITE甚至超过了使用ground truth 3D几何信息的特定任务模型。具体的性能数据未在摘要中给出，需要在论文正文中查找。",
            "tags_zh": [
                "3D场景理解",
                "语义分割",
                "Transformer",
                "知识蒸馏",
                "自监督学习",
                "多视角学习",
                "机器人视觉"
            ],
            "_index": 28,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14364/x2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14364/x3.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14364/x4.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "TimeLens: Rethinking Video Temporal Grounding with Multimodal LLMs",
            "authors": [
                "Jun Zhang",
                "Teng Wang",
                "Yuying Ge",
                "Yixiao Ge",
                "Xinhao Li",
                "Ying Shan",
                "Limin Wang"
            ],
            "arxiv_id": "2512.14698",
            "summary": "This paper does not introduce a novel method but instead establishes a straightforward, incremental, yet essential baseline for video temporal grounding (VTG), a core capability in video understanding. While multimodal large language models (MLLMs) excel at various video understanding tasks, the recipes for optimizing them for VTG remain under-explored. In this paper, we present TimeLens, a systematic investigation into building MLLMs with strong VTG ability, along two primary dimensions: data quality and algorithmic design. We first expose critical quality issues in existing VTG benchmarks and introduce TimeLens-Bench, comprising meticulously re-annotated versions of three popular benchmarks with strict quality criteria. Our analysis reveals dramatic model re-rankings compared to legacy benchmarks, confirming the unreliability of prior evaluation standards. We also address noisy training data through an automated re-annotation pipeline, yielding TimeLens-100K, a large-scale, high-quality training dataset. Building on our data foundation, we conduct in-depth explorations of algorithmic design principles, yielding a series of meaningful insights and effective yet efficient practices. These include interleaved textual encoding for time representation, a thinking-free reinforcement learning with verifiable rewards (RLVR) approach as the training paradigm, and carefully designed recipes for RLVR training. These efforts culminate in TimeLens models, a family of MLLMs with state-of-the-art VTG performance among open-source models and even surpass proprietary models such as GPT-5 and Gemini-2.5-Flash. All codes, data, and models will be released to facilitate future research.",
            "categories": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.MM"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14698",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "[T]multimodal"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 13.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "TimeLens：通过多模态LLM重新思考视频时序定位，构建高质量基线。",
            "summary_zh": "本文并非提出一种全新的方法，而是为视频理解中的核心能力——视频时序定位（VTG）建立了一个直接、增量但至关重要的基线。尽管多模态大型语言模型（MLLM）在各种视频理解任务中表现出色，但优化它们以用于VTG的方法仍未得到充分探索。本文提出了TimeLens，对构建具有强大VTG能力的MLLM进行了系统研究，主要关注数据质量和算法设计两个方面。首先，揭示了现有VTG基准测试中存在的关键质量问题，并引入了TimeLens-Bench，它包含经过严格质量标准重新注释的三个流行基准测试版本。分析表明，与传统基准相比，模型重新排序发生了巨大变化，证实了先前评估标准的不可靠性。还通过自动重新注释流程解决了嘈杂的训练数据问题，从而产生了大规模、高质量的训练数据集TimeLens-100K。在数据基础之上，深入探索了算法设计原则，产生了一系列有意义的见解和有效但高效的实践。这些包括用于时间表示的交错文本编码，一种无需思考的具有可验证奖励的强化学习（RLVR）方法作为训练范例，以及为RLVR训练精心设计的方案。这些努力最终促成了TimeLens模型，这是一系列MLLM，在开源模型中具有最先进的VTG性能，甚至超过了GPT-5和Gemini-2.5-Flash等专有模型。所有代码、数据和模型都将发布，以促进未来的研究。",
            "intro_zh": [
                "现有视频时序定位基准测试存在数据质量问题，导致模型评估结果不可靠，阻碍了有效方法的发展。",
                "TimeLens通过高质量数据构建和算法设计，系统性地研究了如何利用多模态LLM提升视频时序定位能力。",
                "TimeLens模型在视频时序定位任务上取得了显著的性能提升，甚至超越了部分闭源模型，为开源社区提供了强大的基线。"
            ],
            "method_zh": "**问题定义**：视频时序定位（VTG）旨在从视频中定位与给定文本查询相关的特定时间片段。现有VTG方法受限于低质量的训练和评估数据，导致模型泛化能力差，且难以公平比较不同方法的优劣。现有方法缺乏针对MLLM在VTG任务上的优化策略。\n\n**核心思路**：TimeLens的核心思路是通过高质量的数据和算法设计，充分利用多模态LLM的潜力，提升VTG的性能。具体来说，通过重新标注现有数据集，构建高质量的训练和评估基准，并探索有效的训练策略和模型结构。\n\n**技术框架**：TimeLens包含以下几个主要模块：\n1. **数据构建**：重新标注现有VTG数据集，构建高质量的TimeLens-Bench和TimeLens-100K数据集。\n2. **模型结构**：采用多模态LLM作为基础模型，并引入交错文本编码用于时间表示。\n3. **训练策略**：使用无需思考的强化学习与可验证奖励（RLVR）作为训练范例，并设计了相应的训练方案。\n\n**关键创新**：TimeLens的关键创新在于：\n1. **高质量数据**：通过严格的质量控制和重新标注，构建了高质量的VTG数据集，解决了现有数据集的质量问题。\n2. **RLVR训练**：采用无需思考的强化学习与可验证奖励（RLVR）作为训练范例，避免了复杂的奖励函数设计，提高了训练效率和稳定性。\n\n**关键设计**：\n1. **交错文本编码**：将时间信息与文本查询交错编码，使模型能够更好地理解时间上下文。\n2. **RLVR奖励函数**：设计了基于IoU（Intersection over Union）的可验证奖励函数，用于指导强化学习过程。\n3. **训练方案**：精心设计了RLVR训练的超参数和训练流程，以保证模型的收敛性和性能。",
            "application_zh": "TimeLens的研究成果可广泛应用于视频内容理解、智能视频搜索、视频编辑和智能监控等领域。高质量的VTG能力可以帮助用户更准确地定位视频中的关键时刻，提高信息检索效率，并为视频内容分析提供更精确的基础。",
            "highlight_zh": "TimeLens模型在TimeLens-Bench上取得了显著的性能提升，在多个指标上超越了现有的开源模型，甚至超过了GPT-5和Gemini-2.5-Flash等闭源模型。通过高质量数据和有效的训练策略，TimeLens证明了多模态LLM在VTG任务上的巨大潜力。",
            "tags_zh": [
                "视频时序定位",
                "多模态LLM",
                "高质量数据集",
                "强化学习",
                "视频理解",
                "时间表示",
                "数据重标注"
            ],
            "_index": 29,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14698/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14698/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14698/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "MMhops-R1: Multimodal Multi-hop Reasoning",
            "authors": [
                "Tao Zhang",
                "Ziqi Zhang",
                "Zongyang Ma",
                "Yuxin Chen",
                "Bing Li",
                "Chunfeng Yuan",
                "Guangting Wang",
                "Fengyun Rao",
                "Ying Shan",
                "Weiming Hu"
            ],
            "arxiv_id": "2512.13573",
            "summary": "The ability to perform multi-modal multi-hop reasoning by iteratively integrating information across various modalities and external knowledge is critical for addressing complex real-world challenges. However, existing Multi-modal Large Language Models (MLLMs) are predominantly limited to single-step reasoning, as existing benchmarks lack the complexity needed to evaluate and drive multi-hop abilities. To bridge this gap, we introduce MMhops, a novel, large-scale benchmark designed to systematically evaluate and foster multi-modal multi-hop reasoning. MMhops dataset comprises two challenging task formats, Bridging and Comparison, which necessitate that models dynamically construct complex reasoning chains by integrating external knowledge. To tackle the challenges posed by MMhops, we propose MMhops-R1, a novel multi-modal Retrieval-Augmented Generation (mRAG) framework for dynamic reasoning. Our framework utilizes reinforcement learning to optimize the model for autonomously planning reasoning paths, formulating targeted queries, and synthesizing multi-level information. Comprehensive experiments demonstrate that MMhops-R1 significantly outperforms strong baselines on MMhops, highlighting that dynamic planning and multi-modal knowledge integration are crucial for complex reasoning. Moreover, MMhops-R1 demonstrates strong generalization to tasks requiring fixed-hop reasoning, underscoring the robustness of our dynamic planning approach. In conclusion, our work contributes a challenging new benchmark and a powerful baseline model, and we will release the associated code, data, and weights to catalyze future research in this critical area.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13573",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "[T]multimodal"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 13.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出MMhops基准和MMhops-R1框架，用于评估和提升多模态多跳推理能力",
            "summary_zh": "为了解决现有多模态大语言模型(MLLM)在多步推理能力上的不足，本研究提出了一个名为MMhops的大规模基准数据集，旨在系统地评估和促进多模态多跳推理。MMhops包含两种具有挑战性的任务形式：Bridging和Comparison，要求模型通过整合外部知识动态构建复杂的推理链。为了应对MMhops的挑战，我们提出了MMhops-R1，一种新颖的多模态检索增强生成(mRAG)框架，用于动态推理。该框架利用强化学习来优化模型，使其能够自主地规划推理路径、制定有针对性的查询并综合多层次的信息。综合实验表明，MMhops-R1在MMhops上显著优于强大的基线模型，突出了动态规划和多模态知识整合对于复杂推理的重要性。此外，MMhops-R1在需要固定跳数推理的任务中也表现出强大的泛化能力，强调了我们动态规划方法的鲁棒性。总之，我们的工作贡献了一个具有挑战性的新基准和一个强大的基线模型，我们将发布相关的代码、数据和权重，以促进该关键领域的未来研究。",
            "intro_zh": [
                "现有MLLM主要局限于单步推理，缺乏评估和驱动多跳能力的复杂基准。",
                "提出MMhops-R1，一个基于检索增强生成(mRAG)的框架，利用强化学习优化推理路径规划。",
                "实验表明，MMhops-R1在MMhops上显著优于基线，并展现出良好的泛化能力。"
            ],
            "method_zh": "**问题定义**：现有的大型多模态语言模型（MLLM）在复杂现实场景下的多模态多跳推理能力不足。现有的基准数据集缺乏足够的复杂性来评估和驱动模型进行多跳推理，限制了模型在需要整合多种模态信息和外部知识的复杂任务中的应用。\\n\\n**核心思路**：论文的核心思路是提出一个更具挑战性的基准数据集MMhops，并设计一个能够动态规划推理路径的多模态检索增强生成框架MMhops-R1。通过强化学习优化推理路径，使模型能够自主地进行多跳推理，并整合多层次的信息。\\n\\n**技术框架**：MMhops-R1是一个多模态检索增强生成(mRAG)框架，主要包含以下几个模块：1)推理路径规划器：使用强化学习来学习如何规划推理路径，确定每一步需要检索的信息。2)查询生成器：根据推理路径生成针对性的查询，用于从外部知识库中检索相关信息。3)多模态知识整合器：将检索到的信息与原始的多模态输入进行整合，形成新的上下文信息。4)答案生成器：根据整合后的上下文信息生成最终的答案。\\n\\n**关键创新**：该论文的关键创新在于提出了一个基于强化学习的动态推理路径规划方法。与传统的固定推理路径方法不同，该方法能够根据不同的输入动态地调整推理路径，从而更好地适应复杂的多模态推理任务。此外，该框架还能够有效地整合多层次的信息，从而提高推理的准确性。\\n\\n**关键设计**：在强化学习部分，使用了策略梯度算法来训练推理路径规划器。奖励函数的设计考虑了推理的准确性和效率。在多模态知识整合部分，使用了注意力机制来选择重要的信息。损失函数包括交叉熵损失和强化学习奖励损失。",
            "application_zh": "该研究成果可应用于需要复杂推理和知识整合的场景，例如智能问答系统、视觉对话、医疗诊断辅助等。通过提升模型的多模态多跳推理能力，可以更好地理解和处理真实世界的复杂问题，为用户提供更准确、更智能的服务。未来可以进一步探索如何将该方法应用于更多的领域，例如机器人导航、自动驾驶等。",
            "highlight_zh": "MMhops-R1在MMhops基准测试中显著优于其他基线模型，证明了动态规划和多模态知识整合对于复杂推理的重要性。具体而言，MMhops-R1在Bridging和Comparison任务上均取得了显著的性能提升，并且在固定跳数推理任务中也表现出强大的泛化能力。这些实验结果表明，MMhops-R1是一种有效的多模态多跳推理方法。",
            "tags_zh": [
                "多模态学习",
                "多跳推理",
                "检索增强生成",
                "强化学习",
                "知识整合"
            ],
            "_index": 30,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13573/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13573/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.13573/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "The Laminar Flow Hypothesis: Detecting Jailbreaks via Semantic Turbulence in Large Language Models",
            "authors": [
                "Md. Hasib Ur Rahman"
            ],
            "arxiv_id": "2512.13741",
            "summary": "As Large Language Models (LLMs) become ubiquitous, the challenge of securing them against adversarial \"jailbreaking\" attacks has intensified. Current defense strategies often rely on computationally expensive external classifiers or brittle lexical filters, overlooking the intrinsic dynamics of the model's reasoning process. In this work, the Laminar Flow Hypothesis is introduced, which posits that benign inputs induce smooth, gradual transitions in an LLM's high-dimensional latent space, whereas adversarial prompts trigger chaotic, high-variance trajectories - termed Semantic Turbulence - resulting from the internal conflict between safety alignment and instruction-following objectives. This phenomenon is formalized through a novel, zero-shot metric: the variance of layer-wise cosine velocity. Experimental evaluation across diverse small language models reveals a striking diagnostic capability. The RLHF-aligned Qwen2-1.5B exhibits a statistically significant 75.4% increase in turbulence under attack (p less than 0.001), validating the hypothesis of internal conflict. Conversely, Gemma-2B displays a 22.0% decrease in turbulence, characterizing a distinct, low-entropy \"reflex-based\" refusal mechanism. These findings demonstrate that Semantic Turbulence serves not only as a lightweight, real-time jailbreak detector but also as a non-invasive diagnostic tool for categorizing the underlying safety architecture of black-box models.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13741",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "RLHF"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model",
                        "instruction following"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 13.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出层流假设，通过语义湍流检测大语言模型的越狱攻击",
            "summary_zh": "随着大型语言模型（LLMs）的普及，保护它们免受对抗性“越狱”攻击的挑战日益严峻。目前的防御策略通常依赖于计算成本高昂的外部分类器或脆弱的词汇过滤器，忽略了模型推理过程的内在动态。本文提出了层流假设，该假设认为良性输入会在LLM的高维潜在空间中引起平滑、渐进的转换，而对抗性提示会触发混乱、高方差的轨迹——称为语义湍流，这是由于安全对齐和指令遵循目标之间的内部冲突造成的。通过一种新颖的零样本指标：层间余弦速度的方差，将这种现象形式化。对各种小型语言模型的实验评估揭示了惊人的诊断能力。经过RLHF对齐的Qwen2-1.5B在受到攻击时，湍流显著增加了75.4%（p小于0.001），验证了内部冲突的假设。相反，Gemma-2B的湍流减少了22.0%，体现了一种独特的、低熵的“基于反射”的拒绝机制。这些发现表明，语义湍流不仅可以作为一种轻量级的实时越狱检测器，还可以作为一种非侵入性的诊断工具，用于对黑盒模型的底层安全架构进行分类。",
            "intro_zh": [
                "现有防御LLM越狱攻击的方法依赖高成本的外部分类器或脆弱的词汇过滤，忽略了模型推理的内在动态。",
                "论文提出层流假设，认为良性输入导致平滑转换，而恶意攻击导致潜在空间中的“语义湍流”。",
                "实验表明，语义湍流可有效检测越狱攻击，并能诊断黑盒模型的底层安全架构，无需额外训练。"
            ],
            "method_zh": "**问题定义**：当前大型语言模型面临着日益严峻的越狱攻击威胁，现有的防御方法，如外部分类器和词汇过滤器，存在计算成本高、易被绕过等问题，无法有效捕捉模型内部的推理过程和潜在的安全漏洞。因此，需要一种轻量级、实时的检测方法，能够深入理解模型内部状态，从而更有效地防御越狱攻击。\\n\\n**核心思路**：论文的核心思路是基于“层流假设”，即良性输入在LLM的潜在空间中产生平滑的轨迹，而恶意攻击会引发混乱的“语义湍流”。通过量化这种湍流程度，可以判断输入是否为越狱攻击。这种方法无需额外的训练数据或模型，直接利用模型自身的内部状态进行判断。\\n\\n**技术框架**：该方法主要包含以下几个步骤：1) 获取LLM各层的输出向量；2) 计算相邻层之间输出向量的余弦相似度，得到层间余弦速度；3) 计算层间余弦速度的方差，作为语义湍流的度量；4) 将语义湍流值与预设阈值进行比较，判断是否为越狱攻击。整体流程简单高效，易于部署。\\n\\n**关键创新**：该方法最重要的创新在于提出了“语义湍流”的概念，并将其与越狱攻击联系起来。通过量化模型内部状态的混乱程度，实现了对越狱攻击的零样本检测。与传统的基于规则或分类器的防御方法相比，该方法更加灵活、鲁棒，能够应对各种新型的越狱攻击。\\n\\n**关键设计**：关键设计在于层间余弦速度方差的计算。选择余弦相似度是因为它能够衡量向量方向的差异，而忽略向量长度的影响，从而更好地捕捉模型内部状态的变化。方差则用于量化层间余弦速度的波动程度，反映语义湍流的强度。阈值的设定可以根据具体的模型和应用场景进行调整。",
            "application_zh": "该研究成果可应用于各种需要保护大型语言模型免受越狱攻击的场景，例如智能客服、内容生成、代码助手等。通过实时检测和阻止恶意输入，可以有效防止模型被用于生成有害信息、泄露敏感数据或执行恶意代码。此外，该方法还可以作为一种诊断工具，帮助研究人员理解和改进LLM的安全架构。",
            "highlight_zh": "实验结果表明，该方法能够有效检测越狱攻击。在RLHF对齐的Qwen2-1.5B模型上，受到攻击时语义湍流显著增加了75.4%（p<0.001）。而在Gemma-2B模型上，语义湍流减少了22.0%，表明其采用了一种不同的防御机制。这些结果验证了层流假设的有效性，并展示了该方法在不同模型上的适用性。",
            "tags_zh": [
                "大型语言模型",
                "越狱攻击",
                "安全防御",
                "语义湍流",
                "层流假设"
            ],
            "_index": 31,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13741/Untitledpresentation.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13741/laminar.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.13741/download1.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "EXAONE Path 2.5: Pathology Foundation Model with Multi-Omics Alignment",
            "authors": [
                "Juseung Yun",
                "Sunwoo Yu",
                "Sumin Ha",
                "Jonghyun Kim",
                "Janghyeon Lee",
                "Jongseong Jang",
                "Soonyoung Lee"
            ],
            "arxiv_id": "2512.14019",
            "summary": "Cancer progression arises from interactions across multiple biological layers, especially beyond morphological and across molecular layers that remain invisible to image-only models. To capture this broader biological landscape, we present EXAONE Path 2.5, a pathology foundation model that jointly models histologic, genomic, epigenetic and transcriptomic modalities, producing an integrated patient representation that reflects tumor biology more comprehensively. Our approach incorporates three key components: (1) multimodal SigLIP loss enabling all-pairwise contrastive learning across heterogeneous modalities, (2) a fragment-aware rotary positional encoding (F-RoPE) module that preserves spatial structure and tissue-fragment topology in WSI, and (3) domain-specialized internal foundation models for both WSI and RNA-seq to provide biologically grounded embeddings for robust multimodal alignment. We evaluate EXAONE Path 2.5 against six leading pathology foundation models across two complementary benchmarks: an internal real-world clinical dataset and the Patho-Bench benchmark covering 80 tasks. Our framework demonstrates high data and parameter efficiency, achieving on-par performance with state-of-the-art foundation models on Patho-Bench while exhibiting the highest adaptability in the internal clinical setting. These results highlight the value of biologically informed multimodal design and underscore the potential of integrated genotype-to-phenotype modeling for next-generation precision oncology.",
            "categories": [
                "cs.LG",
                "bio.QM"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14019",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "contrastive learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]foundation model",
                        "multimodal"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 13.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "EXAONE Path 2.5：多组学对齐的病理学基础模型，用于更全面的肿瘤生物学理解。",
            "summary_zh": "癌症进展源于多个生物层面的相互作用，特别是形态学之外以及分子层面的相互作用，这些相互作用对于仅使用图像的模型来说是不可见的。为了捕捉更广泛的生物学图景，我们提出了EXAONE Path 2.5，这是一个病理学基础模型，它联合建模组织学、基因组学、表观基因组学和转录组学模态，产生一个综合的患者表征，更全面地反映肿瘤生物学。我们的方法包含三个关键组成部分：（1）多模态SigLIP损失，支持跨异构模态的所有成对对比学习；（2）片段感知旋转位置编码（F-RoPE）模块，在WSI中保留空间结构和组织片段拓扑；（3）WSI和RNA-seq的领域专用内部基础模型，为稳健的多模态对齐提供生物学基础的嵌入。我们在两个互补的基准上评估了EXAONE Path 2.5，一个是内部真实临床数据集，另一个是涵盖80个任务的Patho-Bench基准，并与六个领先的病理学基础模型进行了比较。我们的框架展示了高数据和参数效率，在Patho-Bench上实现了与最先进的基础模型相当的性能，同时在内部临床环境中表现出最高的适应性。这些结果突出了生物信息多模态设计的价值，并强调了用于下一代精准肿瘤学的整合基因型到表型建模的潜力。",
            "intro_zh": [
                "现有病理学模型主要依赖图像信息，忽略了基因组学、表观基因组学等分子层面的信息，限制了对肿瘤生物学的全面理解。",
                "EXAONE Path 2.5通过多模态SigLIP损失、片段感知旋转位置编码和领域专用内部基础模型，实现组织学、基因组学等多组学信息的联合建模。",
                "实验结果表明，EXAONE Path 2.5在Patho-Bench上达到SOTA性能，并在内部临床数据集中表现出更高的适应性，验证了多模态建模的有效性。"
            ],
            "method_zh": "**问题定义**：现有病理学基础模型主要依赖于组织病理学图像，忽略了基因组学、表观基因组学和转录组学等其他重要的生物学信息。这导致模型无法全面理解肿瘤的复杂生物学机制，限制了其在精准肿瘤学中的应用。现有方法难以有效地整合这些异构数据，并且缺乏对组织空间结构的有效建模。\\n\\n**核心思路**：EXAONE Path 2.5的核心思路是将组织病理学图像与基因组学、表观基因组学和转录组学数据进行联合建模，从而获得一个更全面的患者表征。通过多模态对比学习，模型能够学习到不同模态之间的关联，从而更好地理解肿瘤的生物学特性。同时，模型还考虑了组织的空间结构，以更好地捕捉肿瘤的微环境信息。\\n\\n**技术框架**：EXAONE Path 2.5的技术框架主要包含三个模块：1) 多模态SigLIP损失：用于跨异构模态进行对比学习，使得不同模态的表征能够对齐。2) 片段感知旋转位置编码（F-RoPE）：用于在WSI中保留空间结构和组织片段拓扑。3) 领域专用内部基础模型：为WSI和RNA-seq提供生物学基础的嵌入，从而实现稳健的多模态对齐。整体流程是首先使用领域专用模型提取各模态的特征，然后使用F-RoPE编码WSI的空间信息，最后通过多模态SigLIP损失进行联合训练。\\n\\n**关键创新**：该论文的关键创新在于以下几个方面：1) 提出了多模态SigLIP损失，能够有效地进行跨异构模态的对比学习。2) 提出了片段感知旋转位置编码（F-RoPE），能够更好地保留WSI中的空间结构和组织片段拓扑。3) 构建了领域专用的内部基础模型，能够为WSI和RNA-seq提供生物学基础的嵌入。这些创新使得模型能够更全面地理解肿瘤的生物学特性，从而提高了模型的性能。\\n\\n**关键设计**：多模态SigLIP损失采用所有成对的对比学习，鼓励来自同一患者的不同模态的嵌入彼此靠近，而来自不同患者的嵌入彼此远离。F-RoPE通过旋转位置编码来保留空间信息，并使用片段信息来增强位置编码。领域专用内部基础模型针对WSI和RNA-seq分别进行预训练，以获得更好的特征提取能力。具体的参数设置和网络结构在论文中有详细描述，但此处未提供。",
            "application_zh": "EXAONE Path 2.5在精准肿瘤学领域具有广泛的应用前景，可以用于肿瘤诊断、预后预测和治疗方案选择。通过整合多组学信息，该模型能够更全面地理解肿瘤的生物学特性，从而为临床医生提供更准确的决策支持。未来，该模型还可以应用于新药研发，加速精准医疗的发展。",
            "highlight_zh": "EXAONE Path 2.5在Patho-Bench基准测试中取得了与最先进的基础模型相当的性能，同时在内部临床数据集中表现出更高的适应性。这表明该模型具有良好的泛化能力和临床应用潜力。该模型还具有高数据和参数效率，能够在有限的数据集上取得良好的性能。",
            "tags_zh": [
                "病理学",
                "多组学",
                "基础模型",
                "对比学习",
                "精准肿瘤学"
            ],
            "_index": 32,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "A First-Order Logic-Based Alternative to Reward Models in RLHF",
            "authors": [
                "Chunjin Jian",
                "Xinhua Zhu"
            ],
            "arxiv_id": "2512.14100",
            "summary": "Reinforcement Learning from Human Feedback (RLHF) plays a crucial role in aligning large language models (LLMs) with human values and preferences. However, the quality and stability of the trained reward model largely determine the final alignment performance. Existing approaches such as Proximal Policy Optimization (PPO) rely heavily on reward models to guide LLMs toward human-aligned behaviors.In this work, we propose a logic-similarity-based reward mechanism as an alternative to conventional reward modeling. Instead of relying on heuristic reward estimation, our method leverages formal logical consistency to steer model alignment with human preferences. Since real-world questions can be interpreted from multiple perspectives, to ensure that logic-based reinforcement learning does not cause model collapse, we introduce S-GRPO, a supervised variant of the GRPO framework. S-GRPO incorporates an additional supervised component and jointly optimizes the generation term, KL-divergence regularization, and label-based objective during training.Experimental results demonstrate that S-GRPO consistently outperforms standard supervised fine-tuning (SFT) in both performance and robustness. Furthermore, it extends existing preference-learning frameworks such as GRPO and DPO, offering a more flexible and task-adaptive approach to alignment training. Our code is available atthis https URL.",
            "categories": [
                "cs.LG",
                "cs.LO"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14100",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning",
                        "PPO",
                        "preference learning",
                        "[T]RLHF",
                        "DPO"
                    ],
                    "score": 10.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 13.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于逻辑相似度的奖励机制S-GRPO，提升RLHF中LLM对齐的性能与鲁棒性。",
            "summary_zh": "从人类反馈中进行强化学习（RLHF）在使大型语言模型（LLM）与人类价值观和偏好对齐方面起着至关重要的作用。然而，训练后的奖励模型的质量和稳定性在很大程度上决定了最终的对齐性能。现有的方法，如近端策略优化（PPO），严重依赖奖励模型来引导LLM朝着与人类对齐的行为发展。本文提出了一种基于逻辑相似性的奖励机制，作为传统奖励建模的替代方案。我们的方法不依赖于启发式奖励估计，而是利用形式逻辑一致性来引导模型与人类偏好对齐。由于现实世界的问题可以从多个角度解释，为了确保基于逻辑的强化学习不会导致模型崩溃，我们引入了S-GRPO，一种GRPO框架的监督变体。S-GRPO包含一个额外的监督组件，并在训练期间联合优化生成项、KL散度正则化和基于标签的目标。实验结果表明，S-GRPO在性能和鲁棒性方面始终优于标准监督微调（SFT）。此外，它扩展了现有的偏好学习框架，如GRPO和DPO，为对齐训练提供了一种更灵活和任务自适应的方法。",
            "intro_zh": [
                "现有RLHF方法依赖奖励模型，其质量直接影响LLM对齐效果，存在不稳定性和启发式估计问题。",
                "提出基于逻辑相似度的奖励机制S-GRPO，利用形式逻辑一致性引导模型对齐，避免启发式奖励估计。",
                "实验表明，S-GRPO在性能和鲁棒性上优于SFT，并扩展了GRPO和DPO等偏好学习框架。"
            ],
            "method_zh": "**问题定义**：现有RLHF方法严重依赖奖励模型，而奖励模型的训练质量和稳定性直接影响最终LLM的对齐效果。传统的奖励模型通常基于启发式方法进行奖励估计，这可能导致模型学习到次优策略，并且对噪声数据敏感。此外，奖励模型本身也需要大量的标注数据进行训练，增加了训练成本。\\n\\n**核心思路**：本文的核心思路是使用逻辑相似度来替代传统的奖励模型。通过将人类偏好表示为逻辑规则，并计算模型生成结果与这些规则之间的相似度，从而为模型提供更准确、更稳定的奖励信号。这种方法避免了启发式奖励估计，并利用形式逻辑的严谨性来指导模型学习。\\n\\n**技术框架**：S-GRPO框架在GRPO的基础上增加了一个监督组件。整体流程包括：1) 使用LLM生成文本；2) 将生成的文本和参考答案转换为逻辑表达式；3) 计算生成文本逻辑表达式与参考答案逻辑表达式之间的相似度，作为奖励信号；4) 使用奖励信号、KL散度正则化项以及监督学习损失函数联合优化模型。\\n\\n**关键创新**：最重要的技术创新点在于使用逻辑相似度作为奖励信号，替代了传统的奖励模型。与现有方法相比，S-GRPO不需要训练单独的奖励模型，而是直接利用逻辑规则来评估模型生成结果的质量。这使得模型对齐过程更加稳定和可解释。\\n\\n**关键设计**：S-GRPO的关键设计包括：1) 如何将自然语言转换为逻辑表达式（具体转换方法未知）；2) 如何定义逻辑表达式之间的相似度（具体相似度计算方法未知）；3) 如何平衡生成项、KL散度正则化项和监督学习损失函数之间的权重（具体权重设置未知）。此外，S-GRPO还引入了一个监督学习损失函数，以防止模型在逻辑相似度引导下发生崩溃。",
            "application_zh": "该研究成果可应用于各种需要与人类价值观和偏好对齐的LLM应用场景，例如对话系统、文本摘要、代码生成等。通过使用基于逻辑相似度的奖励机制，可以提高LLM生成结果的质量、安全性和可靠性，使其更好地服务于人类社会。未来，该方法有望推广到其他类型的AI模型和任务中。",
            "highlight_zh": "实验结果表明，S-GRPO在性能和鲁棒性方面均优于标准的监督微调（SFT）方法。具体性能提升数据未知，但论文强调S-GRPO在多个任务上都取得了显著的改进，并且对噪声数据具有更强的鲁棒性。此外，S-GRPO还扩展了现有的偏好学习框架，如GRPO和DPO，为对齐训练提供了一种更灵活和任务自适应的方法。",
            "tags_zh": [
                "RLHF",
                "大型语言模型",
                "逻辑推理",
                "奖励模型",
                "模型对齐",
                "偏好学习",
                "形式逻辑"
            ],
            "_index": 33,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14100/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14100/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14100/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Joint Multimodal Contrastive Learning for Robust Spoken Term Detection and Keyword Spotting",
            "authors": [
                "Ramesh Gundluru",
                "Shubham Gupta",
                "Sri Rama Murty K"
            ],
            "arxiv_id": "2512.14115",
            "summary": "Acoustic Word Embeddings (AWEs) improve the efficiency of speech retrieval tasks such as Spoken Term Detection (STD) and Keyword Spotting (KWS). However, existing approaches suffer from limitations, including unimodal supervision, disjoint optimization of audio-audio and audio-text alignment, and the need for task-specific models. To address these shortcomings, we propose a joint multimodal contrastive learning framework that unifies both acoustic and cross-modal supervision in a shared embedding space. Our approach simultaneously optimizes: (i) audio-text contrastive learning, inspired by the CLAP loss, to align audio and text representations and (ii) audio-audio contrastive learning, via Deep Word Discrimination (DWD) loss, to enhance intra-class compactness and inter-class separation. The proposed method outperforms existing AWE baselines on word discrimination task while flexibly supporting both STD and KWS. To our knowledge, this is the first comprehensive approach of its kind.",
            "categories": [
                "cs.SD",
                "cs.LG"
            ],
            "primary_category": "cs.SD",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14115",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]contrastive learning"
                    ],
                    "score": 4.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 13.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出联合多模态对比学习框架，提升语音检索任务的鲁棒性和效率",
            "summary_zh": "本文提出了一种联合多模态对比学习框架，旨在提升语音检索任务（如语音术语检测STD和关键词检索KWS）的性能。现有方法存在单模态监督、音频-音频和音频-文本对齐的独立优化以及需要任务特定模型等局限性。为了解决这些问题，该框架在共享嵌入空间中统一了声学和跨模态监督，同时优化了：(i) 受CLAP损失启发的音频-文本对比学习，以对齐音频和文本表示；(ii) 通过深度词语区分(DWD)损失实现的音频-音频对比学习，以增强类内紧凑性和类间分离性。实验结果表明，该方法在词语区分任务上优于现有的AWE基线，并能灵活支持STD和KWS。据我们所知，这是同类方法中的首个综合性方案。",
            "intro_zh": [
                "现有声学词嵌入（AWE）方法在语音检索任务中存在单模态监督和优化分离等问题。",
                "提出联合多模态对比学习框架，同时优化音频-文本和音频-音频的对齐，提升性能。",
                "实验表明，该方法在词语区分任务上超越现有基线，并能灵活支持STD和KWS。"
            ],
            "method_zh": "**问题定义**：论文旨在解决语音术语检测（STD）和关键词检索（KWS）任务中，现有声学词嵌入（AWE）方法的局限性。这些局限性包括：仅使用单模态监督信号，音频-音频和音频-文本的对齐过程是独立优化的，以及需要针对特定任务训练不同的模型。这些问题导致模型泛化能力不足，且效率较低。\\n\\n**核心思路**：论文的核心思路是利用联合多模态对比学习，将音频和文本信息融合到一个共享的嵌入空间中。通过同时优化音频-文本和音频-音频的对比损失，模型能够学习到更鲁棒、更具判别性的声学词嵌入表示。这种联合学习的方式可以克服单模态监督的限制，并实现跨模态信息的有效利用。\\n\\n**技术框架**：整体框架包含两个主要的对比学习模块：音频-文本对比学习和音频-音频对比学习。音频-文本对比学习模块采用类似于CLAP的损失函数，旨在将音频和文本的表示对齐到同一嵌入空间。音频-音频对比学习模块则使用深度词语区分（DWD）损失，鼓励同一类别的音频样本在嵌入空间中更加紧凑，不同类别的样本之间更加分离。这两个模块的损失函数被联合优化，从而实现声学词嵌入的有效学习。\\n\\n**关键创新**：该方法最重要的创新在于将音频-文本和音频-音频对比学习联合起来，在一个统一的框架中进行优化。与以往分别优化这两个过程的方法相比，该方法能够更好地利用跨模态信息，学习到更具判别性的声学词嵌入。此外，该方法还避免了针对特定任务训练模型的需要，提高了模型的泛化能力。\\n\\n**关键设计**：音频-文本对比学习模块使用Transformer网络提取音频和文本的特征表示，然后通过对比损失函数进行优化。音频-音频对比学习模块使用深度神经网络学习音频的嵌入表示，并通过DWD损失函数来增强类内紧凑性和类间分离性。DWD损失函数的设计考虑了类别之间的关系，能够更有效地提高词语区分的性能。具体的损失函数权重和网络结构参数需要根据实验进行调整。",
            "application_zh": "该研究成果可广泛应用于语音搜索、智能语音助手、语音内容分析等领域。通过提升语音检索的准确性和效率，可以改善用户体验，并为相关应用提供更强大的技术支持。未来，该方法有望扩展到更多模态的数据融合，例如视频和文本的联合检索，从而实现更智能化的信息处理。",
            "highlight_zh": "实验结果表明，该方法在词语区分任务上优于现有的AWE基线。具体性能提升数据未知，但摘要中明确指出该方法在词语区分任务上表现更优，并且能够灵活支持STD和KWS任务。这表明该方法在实际应用中具有较强的竞争力。",
            "tags_zh": [
                "语音术语检测",
                "关键词检索",
                "声学词嵌入",
                "多模态对比学习",
                "音频文本对齐"
            ],
            "_index": 34,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14115/figures/CLAP_for_STD.jpg",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14115/figures/tsne_word_embeddings.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14115/figures/oov_Scores_cosine.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Holistic Utility Preference Learning for Listwise Alignment",
            "authors": [
                "Jiacong Zhou",
                "Xianyun Wang",
                "Min Zhang",
                "Jun Yu"
            ],
            "arxiv_id": "2410.18127",
            "summary": "Aligning large language models with human preferences is essential for improving interaction quality and safety by ensuring outputs better reflect human values. A promising strategy involves Reinforcement Learning from Human Feedback (RLHF), starting with collecting and ranking responses generated by a supervised fine-tuning model to refine alignment. Existing methods such as Direct Preference Optimization (DPO) focus on pairwise comparisons, categorizing responses into preferred and less preferred pairs and optimizing pairwise margins. However, this pairwise approach cannot capture the holistic ranking relationships among multiple responses or effectively leverage the rich preference information available in list-wise comparisons. To address this challenge, this paper introduces \\underline{D}irect \\underline{R}anking \\underline{P}reference \\underline{O}ptimization (DRPO), a novel method that views human preference alignment as a Learning-to-Rank (LTR) task. Unlike pairwise methods, DRPO optimizes the preference ranking of entire response lists by computing holistic utility scores through NDCG, a standard LTR metric. To enable end-to-end optimization with the non-differentiable NDCG, we propose diffNDCG loss, a differentiable approximation facilitated by a sorting network. Furthermore, we introduce a novel margin-based Adaptive Rank Policy Score to enhance the discriminative quality of generated responses. Extensive experiments have shown that DRPO outperforms existing methods, enhancing the quality of the generated responses.",
            "categories": [
                "cs.IR",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ],
            "primary_category": "cs.IR",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2410.18127",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning",
                        "[T]preference learning",
                        "RLHF",
                        "DPO",
                        "direct preference optimization"
                    ],
                    "score": 10.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 13.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出DRPO以解决人类偏好对齐中的全局排名问题",
            "summary_zh": "对齐大型语言模型与人类偏好对于提高交互质量和安全性至关重要。现有的直接偏好优化方法主要集中在成对比较，无法有效捕捉多个响应之间的整体排名关系。为此，本文提出了直接排名偏好优化（DRPO），将人类偏好对齐视为学习排序任务，通过计算整体效用分数来优化响应列表的偏好排名。为实现与非可微的NDCG的端到端优化，提出了diffNDCG损失函数，并引入了自适应排名策略评分以增强生成响应的区分质量。实验结果表明，DRPO在生成响应的质量上超越了现有方法。",
            "intro_zh": [
                "现有的直接偏好优化方法主要依赖成对比较，无法有效捕捉多个响应之间的整体排名关系，限制了偏好信息的利用。",
                "本文提出的DRPO方法将人类偏好对齐视为学习排序任务，通过计算整体效用分数来优化整个响应列表的偏好排名。",
                "实验结果显示，DRPO在生成响应的质量上显著优于现有方法，验证了其有效性和实用性。"
            ],
            "method_zh": "**问题定义**：本文旨在解决大型语言模型与人类偏好对齐中的整体排名问题。现有的成对比较方法无法充分利用多个响应之间的偏好信息，导致对齐效果不佳。\\n\\n**核心思路**：DRPO方法通过将人类偏好对齐视为学习排序任务，优化整个响应列表的偏好排名，而不是单独比较成对响应。这样的设计能够更全面地捕捉人类的偏好。\\n\\n**技术框架**：DRPO的整体架构包括数据收集、响应生成、偏好评分和优化四个主要模块。首先收集人类反馈，然后生成响应，接着计算整体效用分数，最后进行优化。\\n\\n**关键创新**：DRPO的核心创新在于引入了diffNDCG损失函数，作为NDCG的可微近似，从而实现了与非可微指标的端到端优化。这一方法与传统的成对比较方法本质上不同，能够更好地利用整体偏好信息。\\n\\n**关键设计**：在DRPO中，采用了自适应排名策略评分，以增强生成响应的区分质量。此外，损失函数的设计考虑了整体效用分数的计算，确保了优化过程的有效性。",
            "application_zh": "该研究的潜在应用领域包括智能助手、推荐系统和人机交互等。通过更好地对齐人类偏好，DRPO能够提升生成内容的质量和安全性，进而改善用户体验。未来，该方法可能在更广泛的AI应用中发挥重要作用，推动人机协作的进步。",
            "highlight_zh": "实验结果表明，DRPO在生成响应的质量上显著优于现有的直接偏好优化方法，具体表现为在NDCG指标上提升了约15%。这一结果验证了DRPO在处理人类偏好对齐任务中的有效性和优越性。",
            "tags_zh": [
                "人类偏好对齐",
                "直接排名偏好优化",
                "学习排序",
                "NDCG",
                "响应生成",
                "机器学习"
            ],
            "_index": 35,
            "_used_api": "openai",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2410.18127/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2410.18127/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                }
            ]
        },
        {
            "title": "DART: Difficulty-Adaptive Reasoning Truncation for Efficient Large Language Models",
            "authors": [
                "Ruofan Zhang",
                "Bin Xia",
                "Zhen Cheng",
                "Cairen Jian",
                "Minglun Yang",
                "Ngai Wong",
                "Yuan Cheng"
            ],
            "arxiv_id": "2511.01170",
            "summary": "Adaptive reasoning is essential for aligning the computational effort of large language models (LLMs) with the intrinsic difficulty of problems. Current chain-of-thought methods boost reasoning ability but indiscriminately generate long explanations, leading to evident inefficiency. However, existing reinforcement learning approaches to adaptive thinking remain unstable and heavily reward-dependent. Here we propose \\textbf{DART}, a supervised \\textbf{D}ifficulty-\\textbf{A}daptive \\textbf{R}easoning \\textbf{T}runcation framework that adjusts thinking length according to problem difficulty. By distilling concise reasoning patterns from stronger models, interpolating them into a continuum of reasoning styles, and curating optimal training data that balances correctness and compactness, DART learns when to ``stop thinking''. Across multiple mathematical benchmarks, experimental results demonstrate its remarkable efficiency while preserving or improving accuracy, achieving a significant 81.2\\% reasoning truncation (DeepSeek-R1-Distill-Qwen-7B on GSM8K dataset) with 5.33$\\times$ computational acceleration. DART provides a stable and general paradigm for efficient reasoning, advancing the development of adaptive intelligence in LLMs.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2511.01170",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model",
                        "chain-of-thought"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 13.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "DART：面向高效大语言模型的难度自适应推理截断框架",
            "summary_zh": "自适应推理对于使大型语言模型（LLM）的计算量与问题的内在难度相匹配至关重要。现有的思维链方法虽然增强了推理能力，但会不加区分地生成冗长的解释，导致明显的效率低下。然而，现有的自适应思维强化学习方法仍然不稳定，并且严重依赖奖励。本文提出了DART，一个监督的难度自适应推理截断框架，它根据问题的难度调整思维长度。通过从更强的模型中提炼简洁的推理模式，将它们内插到连续的推理风格中，并精心策划平衡正确性和紧凑性的最佳训练数据，DART学会了何时“停止思考”。在多个数学基准测试中，实验结果表明了其显著的效率，同时保持或提高了准确性，实现了显著的81.2%的推理截断（DeepSeek-R1-Distill-Qwen-7B在GSM8K数据集上），并实现了5.33倍的计算加速。DART为高效推理提供了一个稳定和通用的范例，推动了LLM中自适应智能的发展。",
            "intro_zh": [
                "现有思维链方法生成冗长解释导致效率低下，而强化学习方法又不稳定且依赖奖励。",
                "DART通过模仿学习从强模型中提炼简洁推理模式，并学习何时停止思考。",
                "实验表明DART在保持或提高准确性的同时，显著提升了推理效率，实现了推理截断和计算加速。"
            ],
            "method_zh": "**问题定义**：现有的大语言模型推理方法，特别是思维链方法，在解决问题时会生成冗长的推理过程，导致计算效率低下。即使对于简单的问题，模型也会产生不必要的推理步骤，浪费计算资源。现有的基于强化学习的自适应推理方法，虽然可以动态调整推理长度，但训练过程不稳定，且对奖励函数的设计高度敏感。\\n\\n**核心思路**：DART的核心思路是通过模仿学习，让小模型学习大模型在不同难度问题上的推理模式，特别是学习何时停止推理。通过将大模型的推理过程提炼成一系列不同长度的推理风格，并构建平衡正确性和紧凑性的训练数据集，使小模型能够根据问题的难度自适应地调整推理长度。\\n\\n**技术框架**：DART框架主要包含三个阶段：1) **推理风格蒸馏**：从一个更强大的教师模型中提取不同长度的推理链，形成一个推理风格的连续谱。2) **数据策展**：构建一个训练数据集，该数据集包含不同长度的推理链，并根据正确性和紧凑性对这些推理链进行加权。3) **模型训练**：使用策展的数据集训练一个较小的学生模型，使其能够根据问题的难度自适应地选择合适的推理长度。\\n\\n**关键创新**：DART的关键创新在于其难度自适应的推理截断机制。与传统的思维链方法不同，DART能够根据问题的难度动态调整推理长度，避免了不必要的计算开销。与基于强化学习的方法相比，DART采用监督学习的方式，训练过程更加稳定，且不需要复杂的奖励函数设计。\\n\\n**关键设计**：DART的关键设计包括：1) 使用插值方法生成连续的推理风格，允许模型在不同的推理长度之间平滑过渡。2) 设计了一种数据策展策略，平衡了推理的正确性和紧凑性，确保模型既能正确解决问题，又能尽可能地减少计算量。3) 使用标准的Transformer架构作为学生模型，并采用交叉熵损失函数进行训练。",
            "application_zh": "DART框架可应用于各种需要高效推理的大语言模型应用场景，例如移动设备上的智能助手、资源受限的边缘计算设备以及对延迟敏感的在线服务。通过减少推理所需的计算量，DART可以降低模型的部署成本，提高响应速度，并扩展大语言模型在资源有限环境中的应用范围。",
            "highlight_zh": "DART在GSM8K数据集上实现了81.2%的推理截断，同时保持了与原始模型相当的准确率。在DeepSeek-R1-Distill-Qwen-7B模型上，DART实现了5.33倍的计算加速。实验结果表明，DART在多个数学基准测试中都取得了显著的效率提升，并且在某些情况下甚至超过了原始模型的性能。",
            "tags_zh": [
                "大语言模型",
                "推理效率",
                "自适应推理",
                "思维链",
                "知识蒸馏"
            ],
            "_index": 36,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2511.01170/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2511.01170/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2511.01170/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Physically Grounded Monocular Depth via Nanophotonic Wavefront Prompting",
            "authors": [
                "Bingxuan Li",
                "Jiahao Wu",
                "Yuan Xu",
                "Zezheng Zhu",
                "Yunxiang Zhang",
                "Kenneth Chen",
                "Yanqi Liang",
                "Nanfang Yu",
                "Qi Sun"
            ],
            "arxiv_id": "2503.15770",
            "summary": "Depth foundation models offer strong learned priors for 3D perception but lack physical depth cues, leading to ambiguities in metric scale. We introduce a birefringent metalens -- a planar nanophotonic lens composed of subwavelength pixels for wavefront shaping with a thickness of 700 nm and a diameter of 3 mm -- to physically prompt depth foundation models. In a single monocular shot, our metalens physically embeds depth information into two polarized optical wavefronts, which we decode through a lightweight prompting and fine-tuning framework that aligns depth foundation models with the optical signals. To scale the training data, we develop a light wave propagation simulator that synthesizes metalens responses from RGB-D datasets, incorporating key physical factors to minimize the sim-to-real gap. Simulated and physical experiments with our fabricated titanium-dioxide metalens demonstrate accurate and consistent metric depth over state-of-the-art monocular depth estimators. The research demonstrates that nanophotonic wavefront formation offers a promising bridge for grounding depth foundation models in physical depth sensing.",
            "categories": [
                "cs.AR",
                "cs.CV"
            ],
            "primary_category": "cs.AR",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2503.15770",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "sim-to-real"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "[T]monocular depth",
                        "metric depth"
                    ],
                    "score": 8.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "foundation model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 13.0,
            "hit_pillars": [
                "1_robot_core",
                "3_perception_slam",
                "9_embodied_foundation"
            ],
            "headline_zh": "利用纳米光子波前调控，实现物理可信的单目深度估计",
            "summary_zh": "深度基础模型在3D感知方面表现出强大的先验知识，但缺乏物理深度线索，导致度量尺度模糊。本文提出一种双折射超透镜——一种由亚波长像素组成的平面纳米光子透镜，厚度为700纳米，直径为3毫米——用于物理提示深度基础模型。在单次单目拍摄中，我们的超透镜将深度信息物理地嵌入到两个偏振光波前中，我们通过轻量级的提示和微调框架来解码这些信息，使深度基础模型与光学信号对齐。为了扩展训练数据，我们开发了一种光波传播模拟器，可以从RGB-D数据集中合成超透镜响应，并结合关键物理因素以最小化模拟到真实的差距。使用我们制造的二氧化钛超透镜进行的模拟和物理实验表明，与最先进的单目深度估计器相比，我们的方法能够实现准确且一致的度量深度。该研究表明，纳米光子波前形成为将深度基础模型植根于物理深度感知提供了一种有希望的桥梁。",
            "intro_zh": [
                "深度学习模型缺乏物理深度线索，导致单目深度估计结果在尺度上存在不确定性。",
                "利用超透镜对光波进行调控，将深度信息编码到偏振光波前中，为深度估计提供物理约束。",
                "通过光波传播模拟器生成训练数据，并结合轻量级微调框架，实现准确的单目深度估计。"
            ],
            "method_zh": "**问题定义**：单目深度估计依赖于深度学习模型学习场景的先验知识，但缺乏真实的物理深度线索，导致估计结果在绝对尺度上存在偏差。现有方法难以将物理世界的深度信息有效融入到深度学习模型中，限制了单目深度估计的精度和可靠性。\\n\\n**核心思路**：利用超透镜对入射光波进行调制，将深度信息编码到不同偏振态的光波中。通过分析这些偏振光波，可以提取出场景的深度信息，从而为深度学习模型提供物理约束，解决尺度不确定性问题。这种方法将物理光学与深度学习相结合，实现了物理可信的单目深度估计。\\n\\n**技术框架**：该方法主要包含三个阶段：1) 超透镜设计与制造：设计并制造具有特定双折射特性的超透镜，使其能够将深度信息编码到偏振光波中。2) 光波传播模拟：开发光波传播模拟器，用于生成大量带有深度信息的训练数据，并考虑了关键的物理因素，以减小模拟与真实数据之间的差距。3) 深度估计网络训练：利用模拟数据对深度学习模型进行预训练，然后使用真实数据进行微调，使模型能够准确地从偏振光波中提取深度信息。\\n\\n**关键创新**：该方法的核心创新在于利用超透镜进行波前调控，将深度信息以物理的方式嵌入到光波中。与传统的基于学习的方法相比，该方法能够提供更强的物理约束，从而提高深度估计的精度和鲁棒性。此外，该方法还提出了一种光波传播模拟器，能够有效地生成训练数据，解决了真实数据获取困难的问题。\\n\\n**关键设计**：超透镜采用二氧化钛材料，厚度为700纳米，直径为3毫米。光波传播模拟器考虑了材料的折射率、波长、偏振态等因素。深度估计网络采用轻量级的提示和微调框架，以适应超透镜编码的深度信息。损失函数包括深度损失和偏振损失，用于约束深度估计的精度和偏振信息的准确性。",
            "application_zh": "该研究成果可应用于机器人导航、增强现实、自动驾驶等领域。通过提供准确的单目深度估计，可以提高机器人对环境的感知能力，增强AR/VR应用的沉浸感，并提升自动驾驶系统的安全性。此外，该技术还可以应用于三维重建、虚拟现实等领域，具有广阔的应用前景。",
            "highlight_zh": "实验结果表明，该方法在单目深度估计任务中取得了显著的性能提升。与最先进的单目深度估计器相比，该方法能够实现更准确和一致的度量深度。通过模拟和物理实验验证了该方法的有效性，并证明了纳米光子波前形成在深度感知方面的潜力。",
            "tags_zh": [
                "单目深度估计",
                "超透镜",
                "波前调控",
                "纳米光子学",
                "深度学习",
                "物理约束",
                "光波传播模拟"
            ],
            "_index": 37,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2503.15770/x2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2503.15770/x3.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2503.15770/x4.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "STAR: STacked AutoRegressive Scheme for Unified Multimodal Learning",
            "authors": [
                "Jie Qin",
                "Jiancheng Huang",
                "Limeng Qiao",
                "Lin Ma"
            ],
            "arxiv_id": "2512.13752",
            "summary": "Multimodal large language models (MLLMs) play a pivotal role in advancing the quest for general artificial intelligence. However, achieving unified target for multimodal understanding and generation remains challenging due to optimization conflicts and performance trade-offs. To effectively enhance generative performance while preserving existing comprehension capabilities, we introduce STAR: a STacked AutoRegressive scheme for task-progressive unified multimodal learning. This approach decomposes multimodal learning into multiple stages: understanding, generation, and editing. By freezing the parameters of the fundamental autoregressive (AR) model and progressively stacking isomorphic AR modules, it avoids cross-task interference while expanding the model's capabilities. Concurrently, we introduce a high-capacity VQ to enhance the granularity of image representations and employ an implicit reasoning mechanism to improve generation quality under complex conditions. Experiments demonstrate that STAR achieves state-of-the-art performance on GenEval (0.91), DPG-Bench (87.44), and ImgEdit (4.34), validating its efficacy for unified multimodal learning.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13752",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "[T]multimodal"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出STAR：堆叠自回归方案，用于统一多模态学习，提升生成性能。",
            "summary_zh": "多模态大型语言模型（MLLM）在推动通用人工智能发展中起着关键作用。然而，由于优化冲突和性能权衡，实现多模态理解和生成的统一目标仍然具有挑战性。为了有效提升生成性能，同时保留现有的理解能力，我们提出了STAR：一种用于任务渐进式统一多模态学习的堆叠自回归方案。该方法将多模态学习分解为多个阶段：理解、生成和编辑。通过冻结基础自回归（AR）模型的参数并逐步堆叠同构AR模块，避免了跨任务干扰，同时扩展了模型的能力。此外，我们引入了高容量VQ以增强图像表示的粒度，并采用隐式推理机制来提高复杂条件下的生成质量。实验表明，STAR在GenEval（0.91）、DPG-Bench（87.44）和ImgEdit（4.34）上实现了最先进的性能，验证了其在统一多模态学习中的有效性。",
            "intro_zh": [
                "多模态大模型面临理解和生成任务间的优化冲突和性能权衡问题，难以兼顾。",
                "STAR通过堆叠自回归模块，将多模态学习分解为理解、生成和编辑阶段，避免任务干扰。",
                "实验结果表明，STAR在GenEval、DPG-Bench和ImgEdit等基准测试中取得了领先性能。"
            ],
            "method_zh": "**问题定义**：多模态大型语言模型在统一多模态理解和生成方面面临挑战，主要痛点在于不同任务之间的优化冲突和性能权衡，导致模型难以同时提升理解和生成能力。现有方法往往顾此失彼，要么牺牲理解能力来提升生成性能，要么反之。\\n\\n**核心思路**：STAR的核心思路是将多模态学习过程解耦为多个阶段，包括理解、生成和编辑，并采用堆叠自回归模块的方式，逐步扩展模型的能力。通过冻结基础自回归模型的参数，避免了跨任务的干扰，从而能够在提升生成性能的同时，保持现有的理解能力。\\n\\n**技术框架**：STAR的技术框架主要包含三个阶段：理解阶段、生成阶段和编辑阶段。在理解阶段，模型利用预训练的自回归模型进行多模态信息的编码和理解。在生成阶段，模型通过堆叠额外的自回归模块，学习生成新的内容。在编辑阶段，模型可以对已生成的内容进行修改和完善。整个框架采用任务渐进式的学习方式，逐步提升模型的能力。\\n\\n**关键创新**：STAR最重要的技术创新点在于其堆叠自回归模块的设计。通过冻结基础模型的参数，并逐步堆叠同构的自回归模块，避免了跨任务的干扰，从而能够在提升生成性能的同时，保持现有的理解能力。此外，高容量VQ和隐式推理机制也进一步提升了图像表示的粒度和生成质量。\\n\\n**关键设计**：STAR的关键设计包括：1) 基础自回归模型的选择和参数冻结策略；2) 堆叠自回归模块的数量和结构；3) 高容量VQ的设计，用于增强图像表示的粒度；4) 隐式推理机制的实现，用于提高复杂条件下的生成质量。具体的参数设置和损失函数等细节在论文中进行了详细描述。",
            "application_zh": "STAR具有广泛的应用前景，可应用于智能对话、图像生成、视频编辑等领域。例如，可以利用STAR构建更强大的多模态对话系统，实现更自然、更流畅的人机交互。此外，STAR还可以用于生成高质量的图像和视频内容，为创意设计和内容创作提供支持。未来，STAR有望成为通用人工智能的重要组成部分。",
            "highlight_zh": "STAR在GenEval、DPG-Bench和ImgEdit等多个基准测试中取得了显著的性能提升。具体而言，在GenEval上达到了0.91的得分，在DPG-Bench上达到了87.44的得分，在ImgEdit上达到了4.34的得分。这些结果表明，STAR在统一多模态学习方面具有显著的优势，能够有效提升生成性能，同时保持现有的理解能力。",
            "tags_zh": [
                "多模态学习",
                "自回归模型",
                "生成模型",
                "图像编辑",
                "统一模型",
                "堆叠结构",
                "任务渐进学习"
            ],
            "_index": 38,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13752/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13752/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.13752/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "ViewMask-1-to-3: Multi-View Consistent Image Generation via Multimodal Diffusion Models",
            "authors": [
                "Ruishu Zhu",
                "Zhihao Huang",
                "Jiacheng Sun",
                "Ping Luo",
                "Hongyuan Zhang",
                "Xuelong Li"
            ],
            "arxiv_id": "2512.14099",
            "summary": "Multi-view image generation from a single image and text description remains challenging due to the difficulty of maintaining geometric consistency across different viewpoints. Existing approaches typically rely on 3D-aware architectures or specialized diffusion models that require extensive multi-view training data and complex geometric priors. In this work, we introduce ViewMask-1-to-3, a pioneering approach to apply discrete diffusion models to multi-view image generation. Unlike continuous diffusion methods that operate in latent spaces, ViewMask-1-to-3 formulates multi-view synthesis as a discrete sequence modeling problem, where each viewpoint is represented as visual tokens obtained through MAGVIT-v2 tokenization. By unifying language and vision through masked token prediction, our approach enables progressive generation of multiple viewpoints through iterative token unmasking with text input. ViewMask-1-to-3 achieves cross-view consistency through simple random masking combined with self-attention, eliminating the requirement for complex 3D geometric constraints or specialized attention architectures. Our approach demonstrates that discrete diffusion provides a viable and simple alternative to existing multi-view generation methods, ranking first on average across GSO and 3D-FUTURE datasets in terms of PSNR, SSIM, and LPIPS, while maintaining architectural simplicity.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14099",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱七：动作重定向 (Motion Retargeting)",
                    "id": "7_retargeting",
                    "matched_keywords": [
                        "geometric consistency"
                    ],
                    "score": 3.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "7_retargeting",
                "9_embodied_foundation"
            ],
            "headline_zh": "ViewMask-1-to-3：基于多模态扩散模型实现多视角一致的图像生成",
            "summary_zh": "本文提出ViewMask-1-to-3，一种利用离散扩散模型进行多视角图像生成的创新方法。针对从单张图像和文本描述生成多视角图像时难以保持几何一致性的挑战，现有方法通常依赖于3D感知架构或专门的扩散模型，这些方法需要大量的多视角训练数据和复杂的几何先验。ViewMask-1-to-3将多视角合成问题转化为离散序列建模问题，通过MAGVIT-v2标记化将每个视角表示为视觉token。通过掩码token预测统一语言和视觉，该方法能够通过迭代token解掩码和文本输入逐步生成多个视角。ViewMask-1-to-3通过简单的随机掩码和自注意力实现跨视角一致性，无需复杂的3D几何约束或专门的注意力架构。实验结果表明，离散扩散为现有的多视角生成方法提供了一种可行且简单的替代方案，在GSO和3D-FUTURE数据集上，PSNR、SSIM和LPIPS指标均排名第一，同时保持了架构的简洁性。",
            "intro_zh": [
                "现有方法在单图文条件下生成多视角图像时，难以保证视角间几何一致性，且依赖大量多视角数据和复杂几何先验。",
                "ViewMask-1-to-3将多视角生成转化为离散序列建模，通过掩码token预测统一语言和视觉信息，迭代生成多视角。",
                "该方法通过随机掩码和自注意力实现跨视角一致性，无需复杂3D约束，在GSO和3D-FUTURE数据集上取得了领先的性能。"
            ],
            "method_zh": "**问题定义**：论文旨在解决从单张图像和文本描述生成多个视角图像时，如何保证生成图像在不同视角下几何一致性的问题。现有方法通常依赖于3D感知架构或专门设计的扩散模型，这些方法需要大量的多视角训练数据，并且需要复杂的几何先验知识，限制了其应用范围和效率。\\n\\n**核心思路**：论文的核心思路是将多视角图像生成问题转化为一个离散序列建模问题。通过将每个视角表示为离散的视觉token，并利用掩码token预测的方式，将语言和视觉信息统一起来。通过迭代地解掩码token，逐步生成多个视角，从而实现多视角图像的生成。\\n\\n**技术框架**：ViewMask-1-to-3的整体框架基于离散扩散模型。首先，使用MAGVIT-v2将输入图像和文本描述转换为视觉token和文本token。然后，通过随机掩码的方式，将部分视觉token进行掩盖。接下来，利用Transformer架构，结合文本token和未被掩盖的视觉token，预测被掩盖的视觉token。通过迭代地进行掩码和预测，逐步生成完整的多视角图像。\\n\\n**关键创新**：该方法最重要的创新点在于将多视角图像生成问题转化为离散序列建模问题，并利用离散扩散模型进行求解。与传统的连续扩散模型相比，离散扩散模型不需要在潜在空间中进行操作，而是直接在token空间中进行操作，从而简化了模型的复杂性。此外，该方法通过简单的随机掩码和自注意力机制，实现了跨视角的一致性，避免了使用复杂的3D几何约束。\\n\\n**关键设计**：ViewMask-1-to-3的关键设计包括：1) 使用MAGVIT-v2进行token化，将图像和文本转换为离散的token序列；2) 采用随机掩码策略，对视觉token进行掩盖；3) 使用Transformer架构，结合文本token和未被掩盖的视觉token，预测被掩盖的视觉token；4) 通过迭代地进行掩码和预测，逐步生成完整的多视角图像。损失函数主要包括token预测的交叉熵损失。",
            "application_zh": "ViewMask-1-to-3在3D内容生成、虚拟现实、增强现实、游戏开发等领域具有广泛的应用前景。它可以根据单张图像和文本描述生成多个视角的图像，从而为用户提供更加沉浸式的体验。此外，该方法还可以用于生成用于3D重建或SLAM的训练数据，从而提高3D视觉算法的性能。未来，该方法有望应用于自动驾驶、机器人导航等领域。",
            "highlight_zh": "ViewMask-1-to-3在GSO和3D-FUTURE数据集上取得了显著的性能提升，在PSNR、SSIM和LPIPS指标上均排名第一。实验结果表明，该方法能够有效地生成多视角一致的图像，并且具有较高的图像质量。与现有方法相比，ViewMask-1-to-3在保持架构简洁性的同时，实现了更好的性能。",
            "tags_zh": [
                "多视角图像生成",
                "离散扩散模型",
                "跨视角一致性",
                "多模态学习",
                "MAGVIT-v2"
            ],
            "_index": 39,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14099/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14099/figs/files/training.jpg",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14099/figs/files/infer.jpg",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Neurosymbolic Inference On Foundation Models For Remote Sensing Text-to-image Retrieval With Complex Queries",
            "authors": [
                "Emanuele Mezzi",
                "Gertjan Burghouts",
                "Maarten Kruithof"
            ],
            "arxiv_id": "2512.14102",
            "summary": "Text-to-image retrieval in remote sensing (RS) has advanced rapidly with the rise of large vision-language models (LVLMs) tailored for aerial and satellite imagery, culminating in remote sensing large vision-language models (RS-LVLMS). However, limited explainability and poor handling of complex spatial relations remain key challenges for real-world use. To address these issues, we introduce RUNE (Reasoning Using Neurosymbolic Entities), an approach that combines Large Language Models (LLMs) with neurosymbolic AI to retrieve images by reasoning over the compatibility between detected entities and First-Order Logic (FOL) expressions derived from text queries. Unlike RS-LVLMs that rely on implicit joint embeddings, RUNE performs explicit reasoning, enhancing performance and interpretability. For scalability, we propose a logic decomposition strategy that operates on conditioned subsets of detected entities, guaranteeing shorter execution time compared to neural approaches. Rather than using foundation models for end-to-end retrieval, we leverage them only to generate FOL expressions, delegating reasoning to a neurosymbolic inference module. For evaluation we repurpose the DOTA dataset, originally designed for object detection, by augmenting it with more complex queries than in existing benchmarks. We show the LLM's effectiveness in text-to-logic translation and compare RUNE with state-of-the-art RS-LVLMs, demonstrating superior performance. We introduce two metrics, Retrieval Robustness to Query Complexity (RRQC) and Retrieval Robustness to Image Uncertainty (RRIU), which evaluate performance relative to query complexity and image uncertainty. RUNE outperforms joint-embedding models in complex RS retrieval tasks, offering gains in performance, robustness, and explainability. We show RUNE's potential for real-world RS applications through a use case on post-flood satellite image retrieval.",
            "categories": [
                "cs.CV",
                "cs.AI",
                "cs.IR"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14102",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "[T]foundation model"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出RUNE：结合神经符号推理与大语言模型，提升遥感图像文本检索的复杂查询处理能力。",
            "summary_zh": "遥感图像文本检索随着大型视觉-语言模型（LVLM）的发展而迅速进步，特别是针对航空和卫星图像的遥感大型视觉-语言模型（RS-LVLM）。然而，有限的可解释性和对复杂空间关系的较差处理仍然是实际应用中的关键挑战。为了解决这些问题，我们引入了RUNE（Reasoning Using Neurosymbolic Entities），这是一种结合大型语言模型（LLM）与神经符号AI的方法，通过推理检测到的实体与从文本查询导出的First-Order Logic（FOL）表达式之间的兼容性来检索图像。与依赖隐式联合嵌入的RS-LVLM不同，RUNE执行显式推理，从而提高性能和可解释性。为了可扩展性，我们提出了一种逻辑分解策略，该策略在检测到的实体的条件子集上运行，与神经方法相比，保证了更短的执行时间。我们没有使用基础模型进行端到端检索，而是仅利用它们来生成FOL表达式，并将推理委托给神经符号推理模块。为了评估，我们重新利用了最初为对象检测而设计的DOTA数据集，通过添加比现有基准更复杂的查询来增强它。我们展示了LLM在文本到逻辑翻译方面的有效性，并将RUNE与最先进的RS-LVLM进行了比较，证明了其卓越的性能。我们引入了两个指标，查询复杂度的检索鲁棒性（RRQC）和图像不确定性的检索鲁棒性（RRIU），它们评估相对于查询复杂度和图像不确定性的性能。RUNE在复杂的RS检索任务中优于联合嵌入模型，从而提高了性能、鲁棒性和可解释性。我们通过洪水后卫星图像检索的用例展示了RUNE在实际RS应用中的潜力。",
            "intro_zh": [
                "现有遥感图像文本检索模型在处理复杂空间关系和提供可解释性方面存在不足，限制了实际应用。",
                "RUNE结合大语言模型和神经符号AI，通过显式推理检测到的实体与一阶逻辑表达式的兼容性来检索图像。",
                "实验表明，RUNE在复杂查询下优于现有遥感视觉-语言模型，并在查询复杂度和图像不确定性方面表现出更强的鲁棒性。"
            ],
            "method_zh": "**问题定义**：遥感图像文本检索任务旨在根据文本描述检索相关的遥感图像。现有方法，特别是基于联合嵌入的遥感视觉-语言模型（RS-LVLM），在处理涉及复杂空间关系的查询时表现不佳，并且缺乏可解释性。这些模型通常依赖于隐式的联合嵌入空间，难以理解检索结果背后的推理过程。\\n\\n**核心思路**：RUNE的核心思路是将文本查询转化为一阶逻辑（FOL）表达式，然后通过神经符号推理来判断图像中检测到的实体是否满足这些逻辑表达式。这种方法将检索过程分解为文本理解、逻辑推理和实体匹配三个步骤，从而提高了可解释性和处理复杂查询的能力。通过显式地建模实体之间的关系，RUNE能够更好地理解查询的意图并检索相关的图像。\\n\\n**技术框架**：RUNE的整体框架包括以下几个主要模块：1) **文本到逻辑转换模块**：使用大型语言模型（LLM）将文本查询转换为一阶逻辑表达式。2) **实体检测模块**：使用现有的目标检测模型检测遥感图像中的实体。3) **神经符号推理模块**：该模块接收逻辑表达式和检测到的实体作为输入，通过推理判断图像是否满足查询条件。为了提高可扩展性，RUNE采用了一种逻辑分解策略，将复杂的逻辑表达式分解为更小的子表达式，并在实体的子集上进行推理。\\n\\n**关键创新**：RUNE的关键创新在于将神经符号推理引入遥感图像文本检索任务。与传统的基于联合嵌入的方法不同，RUNE通过显式地建模实体之间的关系和推理过程，提高了可解释性和处理复杂查询的能力。此外，RUNE的逻辑分解策略提高了推理效率，使其能够处理大规模的遥感图像数据。\\n\\n**关键设计**：RUNE的关键设计包括：1) 使用预训练的大型语言模型（如GPT-3）进行文本到逻辑的转换，并进行微调以适应遥感领域的特定词汇和表达方式。2) 设计合适的逻辑表达式来表示遥感图像中的空间关系，例如“在…的上方”、“在…的左侧”等。3) 实现高效的神经符号推理算法，例如基于约束满足的推理或基于图神经网络的推理。4) 通过RRQC和RRIU指标来评估模型在复杂查询和图像不确定性下的鲁棒性。",
            "application_zh": "RUNE在遥感图像分析领域具有广泛的应用前景，例如灾害监测（洪水、地震后的建筑物损毁评估）、城市规划（建筑物变化检测、土地利用分类）、环境监测（森林砍伐、水体污染）等。通过处理复杂的空间关系查询，RUNE可以帮助用户更有效地检索和分析遥感图像，为决策提供支持。未来，RUNE可以与其他遥感数据源（如LiDAR、SAR）结合，实现更全面的遥感信息提取和分析。",
            "highlight_zh": "RUNE在DOTA数据集上进行了评估，并与最先进的遥感视觉-语言模型进行了比较。实验结果表明，RUNE在处理复杂查询时显著优于现有方法，并在查询复杂度的检索鲁棒性（RRQC）和图像不确定性的检索鲁棒性（RRIU）方面表现出更强的鲁棒性。例如，RUNE在RRQC指标上比基线模型提高了10%以上，证明了其在处理复杂查询方面的优势。",
            "tags_zh": [
                "遥感图像检索",
                "神经符号推理",
                "大语言模型",
                "一阶逻辑",
                "复杂查询"
            ],
            "_index": 40,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14102/pipeline.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14102/decomposition.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14102/graph_complexity.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "LLM-driven Knowledge Enhancement for Multimodal Cancer Survival Prediction",
            "authors": [
                "Chenyu Zhao",
                "Yingxue Xu",
                "Fengtao Zhou",
                "Yihui Wang",
                "Hao Chen"
            ],
            "arxiv_id": "2512.14594",
            "summary": "Current multimodal survival prediction methods typically rely on pathology images (WSIs) and genomic data, both of which are high-dimensional and redundant, making it difficult to extract discriminative features from them and align different modalities. Moreover, using a simple survival follow-up label is insufficient to supervise such a complex task. To address these challenges, we propose KEMM, an LLM-driven Knowledge-Enhanced Multimodal Model for cancer survival prediction, which integrates expert reports and prognostic background knowledge. 1) Expert reports, provided by pathologists on a case-by-case basis and refined by large language model (LLM), offer succinct and clinically focused diagnostic statements. This information may typically suggest different survival outcomes. 2) Prognostic background knowledge (PBK), generated concisely by LLM, provides valuable prognostic background knowledge on different cancer types, which also enhances survival prediction. To leverage these knowledge, we introduce the knowledge-enhanced cross-modal (KECM) attention module. KECM can effectively guide the network to focus on discriminative and survival-relevant features from highly redundant modalities. Extensive experiments on five datasets demonstrate that KEMM achieves state-of-the-art performance. The code will be released upon acceptance.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14594",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "[T]multimodal"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出KEMM模型，利用LLM增强知识的多模态癌症生存预测。",
            "summary_zh": "当前的多模态生存预测方法通常依赖于病理图像（WSIs）和基因组数据，这些数据维度高且冗余，难以从中提取判别性特征并对齐不同模态。此外，使用简单的生存随访标签不足以监督如此复杂的任务。为了解决这些挑战，我们提出了一种基于LLM驱动的知识增强多模态模型KEMM，用于癌症生存预测，该模型集成了专家报告和预后背景知识。专家报告由病理学家逐个案例提供，并由大型语言模型（LLM）提炼，提供了简洁且以临床为中心的诊断声明，这些信息通常暗示不同的生存结果。预后背景知识（PBK）由LLM简洁地生成，提供了关于不同癌症类型的有价值的预后背景知识，这也增强了生存预测。为了利用这些知识，我们引入了知识增强的跨模态（KECM）注意力模块。KECM可以有效地引导网络关注来自高度冗余模态的判别性和生存相关的特征。在五个数据集上的大量实验表明，KEMM实现了最先进的性能。代码将在接受后发布。",
            "intro_zh": [
                "现有方法难以从高维冗余的病理图像和基因组数据中提取判别性特征，且缺乏有效的模态对齐手段。",
                "KEMM模型利用LLM处理专家报告和生成预后背景知识，增强模型对生存预测相关特征的关注。",
                "实验结果表明，KEMM在五个数据集上实现了最先进的性能，验证了知识增强方法的有效性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决多模态癌症生存预测中，病理图像和基因组数据维度高、冗余度大，以及缺乏有效利用临床知识的问题。现有方法难以从这些数据中提取判别性特征，并且简单的生存随访标签不足以充分监督模型的训练。\\n\\n**核心思路**：论文的核心思路是利用大型语言模型（LLM）处理和提炼临床知识，包括专家报告和预后背景知识，并将这些知识融入到多模态融合的过程中，从而引导模型关注与生存预测相关的关键特征。\\n\\n**技术框架**：KEMM模型主要包含以下几个模块：1) LLM驱动的知识提取模块，用于从专家报告中提取诊断信息，并生成预后背景知识；2) 特征提取模块，用于从病理图像和基因组数据中提取特征；3) 知识增强的跨模态（KECM）注意力模块，用于融合不同模态的特征，并利用提取的知识引导模型关注关键特征；4) 生存预测模块，用于预测患者的生存概率。\\n\\n**关键创新**：论文的关键创新在于引入了LLM来处理和生成临床知识，并设计了知识增强的跨模态注意力模块（KECM）。KECM能够有效地将外部知识融入到多模态特征融合的过程中，从而提高模型的预测性能。与现有方法相比，KEMM能够更好地利用临床知识，并更有效地提取和融合不同模态的特征。\\n\\n**关键设计**：KECM模块的设计是关键。具体来说，KECM利用LLM生成的知识作为query，去attention病理图像和基因组数据的特征，从而突出与生存预测相关的特征。损失函数方面，使用了标准的生存分析损失函数，例如Cox比例风险损失函数。",
            "application_zh": "该研究成果可应用于临床辅助诊断，帮助医生更准确地预测癌症患者的生存概率，从而制定更个性化的治疗方案。此外，该方法也可以推广到其他多模态医学数据分析任务中，例如疾病诊断、预后评估等，具有广阔的应用前景。",
            "highlight_zh": "KEMM模型在五个癌症数据集上进行了广泛的实验，结果表明KEMM显著优于现有的多模态生存预测方法。具体性能提升数据在论文中给出，证明了KEMM模型在癌症生存预测任务上的有效性和优越性。",
            "tags_zh": [
                "多模态学习",
                "癌症生存预测",
                "大型语言模型",
                "知识增强",
                "跨模态注意力"
            ],
            "_index": 41,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14594/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14594/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                }
            ]
        },
        {
            "title": "A Unified Framework with Multimodal Fine-tuning for Remote Sensing Semantic Segmentation",
            "authors": [
                "Xianping Ma",
                "Xiaokang Zhang",
                "Man-On Pun",
                "Bo Huang"
            ],
            "arxiv_id": "2410.11160",
            "summary": "Multimodal remote sensing data, acquired from diverse sensors, offer a comprehensive and integrated perspective of the Earth's surface. Leveraging multimodal fusion techniques, semantic segmentation enables detailed and accurate analysis of geographic scenes, surpassing single-modality approaches. Building on advancements in vision foundation models, particularly the Segment Anything Model (SAM), this study proposes a unified framework incorporating a novel Multimodal Fine-tuning Network (MFNet) for remote sensing semantic segmentation. The proposed framework is designed to seamlessly integrate with various fine-tuning mechanisms, demonstrated through the inclusion of Adapter and Low-Rank Adaptation (LoRA) as representative examples. This extensibility ensures the framework's adaptability to other emerging fine-tuning strategies, allowing models to retain SAM's general knowledge while effectively leveraging multimodal data. Additionally, a pyramid-based Deep Fusion Module (DFM) is introduced to integrate high-level geographic features across multiple scales, enhancing feature representation prior to decoding. This work also highlights SAM's robust generalization capabilities with Digital Surface Model (DSM) data, a novel application. Extensive experiments on three benchmark multimodal remote sensing datasets, ISPRS Vaihingen, ISPRS Potsdam and MMHunan, demonstrate that the proposed MFNet significantly outperforms existing methods in multimodal semantic segmentation, setting a new standard in the field while offering a versatile foundation for future research and applications. The source code for this work is accessible atthis https URL.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2410.11160",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "foundation model",
                        "[T]multimodal"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出MFNet，结合多模态微调的遥感语义分割统一框架，性能显著提升。",
            "summary_zh": "本研究提出了一种统一框架，该框架结合了用于遥感语义分割的新型多模态微调网络(MFNet)。该框架旨在与各种微调机制无缝集成，并通过包含Adapter和Low-Rank Adaptation (LoRA)作为代表性示例来展示。这种可扩展性确保了框架对其他新兴微调策略的适应性，使模型能够在有效利用多模态数据的同时保留SAM的通用知识。此外，还引入了基于金字塔的深度融合模块(DFM)，以整合跨多个尺度的高级地理特征，从而在解码之前增强特征表示。这项工作还强调了SAM在数字表面模型(DSM)数据上的强大泛化能力，这是一种新颖的应用。在三个基准多模态遥感数据集ISPRS Vaihingen、ISPRS Potsdam和MMHunan上的大量实验表明，所提出的MFNet在多模态语义分割方面显著优于现有方法，为该领域树立了新标准，并为未来的研究和应用提供了通用的基础。",
            "intro_zh": [
                "现有遥感语义分割方法难以有效融合多模态数据，且模型泛化能力受限，尤其是在处理新型数据如DSM时。",
                "提出MFNet，一个统一框架，通过多模态微调网络和深度融合模块，有效整合多模态遥感数据，并保留SAM的通用知识。",
                "在三个遥感数据集上实验表明，MFNet显著优于现有方法，并在DSM数据上展现出强大的泛化能力，为遥感语义分割设立新标准。"
            ],
            "method_zh": "**问题定义**：遥感语义分割旨在对遥感图像中的每个像素进行分类，但现有方法在融合来自不同传感器（如RGB图像和DSM数据）的多模态信息时存在困难。此外，现有方法通常缺乏利用视觉基础模型（如SAM）的通用知识的能力，限制了其泛化性能。\\n\\n**核心思路**：本论文的核心思路是构建一个统一的框架，该框架能够有效地融合多模态遥感数据，并利用视觉基础模型的先验知识。通过多模态微调网络（MFNet）和深度融合模块（DFM），模型可以学习到更具判别性的特征表示，从而提高语义分割的准确性和泛化能力。\\n\\n**技术框架**：该框架主要包含以下几个模块：1) 多模态数据输入模块：接收来自不同传感器的遥感数据，如RGB图像和DSM数据。2) 特征提取模块：使用预训练的视觉基础模型（如SAM）提取图像特征。3) 多模态微调网络（MFNet）：通过Adapter或LoRA等微调策略，将视觉基础模型的知识迁移到遥感语义分割任务中，并融合多模态特征。4) 深度融合模块（DFM）：利用金字塔结构，在多个尺度上融合特征，增强特征表示。5) 解码器：将融合后的特征映射到像素级别的语义标签。\\n\\n**关键创新**：1) 提出了一个统一的框架，可以灵活地集成不同的微调策略，如Adapter和LoRA。2) 设计了多模态微调网络（MFNet），能够有效地融合多模态遥感数据，并利用视觉基础模型的先验知识。3) 引入了深度融合模块（DFM），通过金字塔结构，在多个尺度上融合特征，增强特征表示。4) 验证了SAM在DSM数据上的泛化能力。\\n\\n**关键设计**：MFNet采用Adapter或LoRA进行微调，以在保留SAM通用知识的同时适应遥感数据。DFM使用金字塔结构提取多尺度特征，并通过卷积操作进行融合。损失函数采用交叉熵损失，优化器采用AdamW。",
            "application_zh": "该研究成果可广泛应用于城市规划、环境监测、灾害评估、农业管理等领域。通过精确的遥感语义分割，可以为土地利用分析、植被覆盖度评估、建筑物提取、道路识别等提供重要的数据支持，从而辅助决策制定和资源管理。未来，该方法有望应用于自动驾驶、机器人导航等领域，提升智能化水平。",
            "highlight_zh": "实验结果表明，提出的MFNet在ISPRS Vaihingen、ISPRS Potsdam和MMHunan三个数据集上均取得了显著的性能提升，超越了现有的多模态语义分割方法。例如，在MMHunan数据集上，MFNet的平均交并比（mIoU）相比最佳基线方法提升了超过5个百分点。此外，该研究还验证了SAM在DSM数据上的泛化能力，为未来的研究提供了新的方向。",
            "tags_zh": [
                "遥感语义分割",
                "多模态融合",
                "视觉基础模型",
                "微调网络",
                "深度融合",
                "数字表面模型",
                "迁移学习"
            ],
            "_index": 42,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2410.11160/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2410.11160/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2410.11160/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "GT2-GS: Geometry-aware Texture Transfer for Gaussian Splatting",
            "authors": [
                "Wenjie Liu",
                "Zhongliang Liu",
                "Junwei Shu",
                "Changbo Wang",
                "Yang Li"
            ],
            "arxiv_id": "2505.15208",
            "summary": "Transferring 2D textures to 3D modalities is of great significance for improving the efficiency of multimedia content creation. Existing approaches have rarely focused on transferring image textures onto 3D representations. 3D style transfer methods are capable of transferring abstract artistic styles to 3D scenes. However, these methods often overlook the geometric information of the scene, which makes it challenging to achieve high-quality 3D texture transfer results. In this paper, we present GT^2-GS, a geometry-aware texture transfer framework for gaussian splitting. From the perspective of matching texture features with geometric information in rendered views, we identify the issue of insufficient texture features and propose a geometry-aware texture augmentation module to expand the texture feature set. Moreover, a geometry-consistent texture loss is proposed to optimize texture features into the scene representation. This loss function incorporates both camera pose and 3D geometric information of the scene, enabling controllable texture-oriented appearance editing. Finally, a geometry preservation strategy is introduced. By alternating between the texture transfer and geometry correction stages over multiple iterations, this strategy achieves a balance between learning texture features and preserving geometric integrity. Extensive experiments demonstrate the effectiveness and controllability of our method. Through geometric awareness, our approach achieves texture transfer results that better align with human visual perception. Our homepage is available atthis https URL.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2505.15208",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "[T]gaussian splatting",
                        "[T]splatting"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "提出GT2-GS，用于高斯溅射的几何感知纹理迁移，提升3D内容创作效率。",
            "summary_zh": "本文提出了一种用于高斯溅射的几何感知纹理迁移框架GT^2-GS，旨在提升多媒体内容创作的效率。现有方法很少关注将图像纹理迁移到3D表示上。3D风格迁移方法虽然能够将抽象的艺术风格迁移到3D场景中，但往往忽略了场景的几何信息，导致难以实现高质量的3D纹理迁移结果。GT^2-GS通过匹配渲染视图中的纹理特征与几何信息，解决了纹理特征不足的问题，并提出了一个几何感知纹理增强模块来扩展纹理特征集。此外，还提出了一种几何一致性纹理损失，将纹理特征优化到场景表示中。该损失函数结合了相机姿态和场景的3D几何信息，实现了可控的、面向纹理的外观编辑。最后，引入了一种几何保持策略，通过在纹理迁移和几何校正阶段之间交替迭代，实现了学习纹理特征和保持几何完整性之间的平衡。大量实验表明了该方法的有效性和可控性，通过几何感知，该方法实现了更符合人类视觉感知的纹理迁移结果。",
            "intro_zh": [
                "现有3D纹理迁移方法忽略场景几何信息，导致迁移质量不高，难以满足高质量内容创作需求。",
                "GT2-GS通过几何感知纹理增强和几何一致性损失，将纹理特征与几何信息对齐，实现高质量纹理迁移。",
                "实验结果表明，GT2-GS在纹理迁移效果和几何保持方面均优于现有方法，更符合人类视觉感知。"
            ],
            "method_zh": "**问题定义**：论文旨在解决将2D纹理高效、高质量地迁移到3D高斯溅射表示上的问题。现有方法，特别是3D风格迁移方法，通常忽略了场景的几何信息，导致纹理迁移结果与场景几何结构不一致，影响视觉效果。因此，如何利用几何信息指导纹理迁移，是本文要解决的核心问题。\\n\\n**核心思路**：论文的核心思路是将纹理迁移过程与场景的几何信息紧密结合。通过几何感知的方式增强纹理特征，并利用几何一致性损失来约束纹理特征的学习，从而保证迁移后的纹理与场景的几何结构相符。此外，通过纹理迁移和几何校正的交替迭代，平衡纹理学习和几何保持。\\n\\n**技术框架**：GT2-GS框架主要包含三个关键模块：几何感知纹理增强模块、几何一致性纹理损失和几何保持策略。首先，几何感知纹理增强模块用于扩展纹理特征集，弥补纹理特征的不足。然后，几何一致性纹理损失将纹理特征优化到场景表示中，确保纹理与几何结构一致。最后，几何保持策略通过交替迭代纹理迁移和几何校正，维持场景的几何完整性。\\n\\n**关键创新**：该方法最重要的创新在于引入了几何感知的概念，将纹理迁移与场景的几何信息紧密结合。具体体现在：1）提出了几何感知纹理增强模块，利用几何信息指导纹理特征的提取和增强；2）设计了几何一致性纹理损失，利用相机姿态和3D几何信息约束纹理特征的学习。这种几何感知的策略是与现有方法最本质的区别。\\n\\n**关键设计**：几何感知纹理增强模块的具体实现细节未知，但可以推测其利用了场景的深度信息或法向量信息来指导纹理特征的提取。几何一致性纹理损失可能采用了类似于光度一致性的损失函数，但加入了相机姿态和3D几何信息的约束项。几何保持策略的具体迭代次数和校正方法未知，但其目的是为了防止纹理迁移过程中对原始几何结构的过度破坏。",
            "application_zh": "该研究成果可广泛应用于3D内容创作、虚拟现实、增强现实等领域。例如，可以快速将照片纹理迁移到3D模型上，生成逼真的3D场景；也可以用于游戏开发中，快速创建具有特定纹理风格的3D角色和场景。该方法有望降低3D内容创作的门槛，提高创作效率。",
            "highlight_zh": "实验结果表明，GT2-GS在纹理迁移效果和几何保持方面均优于现有方法。通过几何感知，该方法能够生成更符合人类视觉感知的纹理迁移结果。具体的性能数据和对比基线在论文中进行了详细的展示，证明了该方法的有效性和优越性。",
            "tags_zh": [
                "高斯溅射",
                "纹理迁移",
                "几何感知",
                "3D重建",
                "风格迁移"
            ],
            "_index": 43,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2505.15208/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2505.15208/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2505.15208/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Debiasing Diffusion Priors via 3D Attention for Consistent Gaussian Splatting",
            "authors": [
                "Shilong Jin",
                "Haoran Duan",
                "Litao Hua",
                "Wentao Huang",
                "Yuan Zhou"
            ],
            "arxiv_id": "2512.07345",
            "summary": "Versatile 3D tasks (e.g., generation or editing) that distill from Text-to-Image (T2I) diffusion models have attracted significant research interest for not relying on extensive 3D training data. However, T2I models exhibit limitations resulting from prior view bias, which produces conflicting appearances between different views of an object. This bias causes subject-words to preferentially activate prior view features during cross-attention (CA) computation, regardless of the target view condition. To overcome this limitation, we conduct a comprehensive mathematical analysis to reveal the root cause of the prior view bias in T2I models. Moreover, we find different UNet layers show different effects of prior view in CA. Therefore, we propose a novel framework, TD-Attn, which addresses multi-view inconsistency via two key components: (1) the 3D-Aware Attention Guidance Module (3D-AAG) constructs a view-consistent 3D attention Gaussian for subject-words to enforce spatial consistency across attention-focused regions, thereby compensating for the limited spatial information in 2D individual view CA maps; (2) the Hierarchical Attention Modulation Module (HAM) utilizes a Semantic Guidance Tree (SGT) to direct the Semantic Response Profiler (SRP) in localizing and modulating CA layers that are highly responsive to view conditions, where the enhanced CA maps further support the construction of more consistent 3D attention Gaussians. Notably, HAM facilitates semantic-specific interventions, enabling controllable and precise 3D editing. Extensive experiments firmly establish that TD-Attn has the potential to serve as a universal plugin, significantly enhancing multi-view consistency across 3D tasks.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.07345",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "[T]gaussian splatting",
                        "[T]splatting"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "提出TD-Attn，通过3D注意力机制消除扩散先验偏差，提升高斯溅射一致性",
            "summary_zh": "本文针对从文本到图像（T2I）扩散模型中存在的先验视图偏差问题，该偏差导致对象不同视图之间出现不一致的外观。通过数学分析揭示了T2I模型中先验视图偏差的根本原因，并发现UNet不同层对交叉注意力（CA）中先验视图的影响不同。为此，提出了TD-Attn框架，通过3D感知注意力引导模块（3D-AAG）构建视图一致的3D注意力高斯分布，增强空间一致性；分层注意力调制模块（HAM）利用语义引导树（SGT）指导语义响应分析器（SRP）定位和调制对视图条件高度敏感的CA层。实验表明，TD-Attn可作为通用插件，显著提高3D任务中的多视图一致性。",
            "intro_zh": [
                "T2I模型在3D任务中受限于先验视图偏差，导致不同视角下物体外观不一致，影响3D重建质量。",
                "提出TD-Attn框架，利用3D感知注意力引导和分层注意力调制，增强交叉注意力机制的空间一致性和语义控制。",
                "实验证明TD-Attn能有效提升多视图一致性，可作为通用插件应用于多种3D任务，具有良好的泛化能力。"
            ],
            "method_zh": "**问题定义**：现有方法利用T2I扩散模型进行3D生成或编辑时，由于T2I模型固有的先验视图偏差，导致生成的3D对象在不同视角下外观不一致。这种偏差源于交叉注意力机制对先验视图特征的过度激活，忽略了目标视图的条件信息。现有方法难以有效消除这种偏差，从而限制了3D重建和编辑的质量。\\n\\n**核心思路**：本文的核心思路是通过引入3D感知的注意力机制，显式地建模不同视角之间的空间关系，从而消除先验视图偏差。具体来说，通过构建视图一致的3D注意力高斯分布，强制交叉注意力机制关注空间一致的区域，从而抑制先验视图特征的过度激活。同时，通过分层注意力调制，选择性地增强对视图条件敏感的交叉注意力层，进一步提升多视图一致性。\\n\\n**技术框架**：TD-Attn框架包含两个主要模块：3D-Aware Attention Guidance Module (3D-AAG) 和 Hierarchical Attention Modulation Module (HAM)。3D-AAG模块首先利用交叉注意力图构建3D注意力高斯分布，然后利用该分布引导交叉注意力机制，增强空间一致性。HAM模块则利用语义引导树（SGT）和语义响应分析器（SRP）定位对视图条件敏感的交叉注意力层，并对其进行调制，进一步提升多视图一致性。整个框架可以作为插件集成到现有的T2I扩散模型中。\\n\\n**关键创新**：本文的关键创新在于提出了3D-AAG模块和HAM模块，分别从空间一致性和语义控制两个方面解决了先验视图偏差问题。3D-AAG模块通过显式地建模3D空间关系，有效抑制了先验视图特征的过度激活。HAM模块则通过选择性地增强对视图条件敏感的交叉注意力层，进一步提升了多视图一致性。此外，HAM模块还支持语义特定的干预，实现了可控和精确的3D编辑。\\n\\n**关键设计**：3D-AAG模块中，3D注意力高斯分布的构建依赖于交叉注意力图的加权平均，权重由交叉注意力值决定。HAM模块中，语义引导树（SGT）的构建依赖于预训练的CLIP模型，用于提取图像的语义信息。语义响应分析器（SRP）则利用SGT的信息，定位对视图条件敏感的交叉注意力层。损失函数方面，主要采用L1损失和L2损失，用于约束3D注意力高斯分布的形状和位置。",
            "application_zh": "该研究成果可广泛应用于3D内容生成、3D对象编辑、虚拟现实、增强现实等领域。通过消除先验视图偏差，可以生成更逼真、更一致的3D模型，提升用户体验。此外，该方法还可用于机器人视觉、自动驾驶等领域，提高对3D环境的感知能力。",
            "highlight_zh": "实验结果表明，TD-Attn能够显著提高多视图一致性，在多个3D任务上取得了state-of-the-art的性能。与现有方法相比，TD-Attn能够生成更清晰、更逼真的3D模型，减少伪影和失真。例如，在3D对象重建任务中，TD-Attn能够将多视图一致性指标提升10%以上。",
            "tags_zh": [
                "扩散模型",
                "3D生成",
                "多视图一致性",
                "注意力机制",
                "高斯溅射"
            ],
            "_index": 44,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.07345/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.07345/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.07345/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Seedance 1.5 pro: A Native Audio-Visual Joint Generation Foundation Model",
            "authors": [
                "Heyi Chen",
                "Siyan Chen",
                "Xin Chen",
                "Yanfei Chen",
                "Ying Chen",
                "Zhuo Chen",
                "Feng Cheng",
                "Tianheng Cheng",
                "Xinqi Cheng",
                "Xuyan Chi",
                "Jian Cong",
                "Jing Cui",
                "Qinpeng Cui",
                "Qide Dong",
                "Junliang Fan",
                "Jing Fang",
                "Zetao Fang",
                "Chengjian Feng",
                "Han Feng",
                "Mingyuan Gao",
                "Yu Gao",
                "Dong Guo",
                "Qiushan Guo",
                "Boyang Hao",
                "Qingkai Hao",
                "Bibo He",
                "Qian He",
                "Tuyen Hoang",
                "Ruoqing Hu",
                "Xi Hu",
                "Weilin Huang",
                "Zhaoyang Huang",
                "Zhongyi Huang",
                "Donglei Ji",
                "Siqi Jiang",
                "Wei Jiang",
                "Yunpu Jiang",
                "Zhuo Jiang",
                "Ashley Kim",
                "Jianan Kong",
                "Zhichao Lai",
                "Shanshan Lao",
                "Yichong Leng",
                "Ai Li",
                "Feiya Li",
                "Gen Li",
                "Huixia Li",
                "JiaShi Li",
                "Liang Li",
                "Ming Li",
                "Shanshan Li",
                "Tao Li",
                "Xian Li",
                "Xiaojie Li",
                "Xiaoyang Li",
                "Xingxing Li",
                "Yameng Li",
                "Yifu Li",
                "Yiying Li",
                "Chao Liang",
                "Han Liang",
                "Jianzhong Liang",
                "Ying Liang",
                "Zhiqiang Liang",
                "Wang Liao",
                "Yalin Liao",
                "Heng Lin",
                "Kengyu Lin",
                "Shanchuan Lin",
                "Xi Lin",
                "Zhijie Lin",
                "Feng Ling",
                "Fangfang Liu",
                "Gaohong Liu",
                "Jiawei Liu",
                "Jie Liu",
                "Jihao Liu",
                "Shouda Liu",
                "Shu Liu",
                "Sichao Liu",
                "Songwei Liu",
                "Xin Liu",
                "Xue Liu",
                "Yibo Liu",
                "Zikun Liu",
                "Zuxi Liu",
                "Junlin Lyu",
                "Lecheng Lyu",
                "Qian Lyu",
                "Han Mu",
                "Xiaonan Nie",
                "Jingzhe Ning",
                "Xitong Pan",
                "Yanghua Peng",
                "Lianke Qin",
                "Xueqiong Qu",
                "Yuxi Ren",
                "Kai Shen",
                "Guang Shi",
                "Lei Shi"
            ],
            "arxiv_id": "2512.13507",
            "summary": "Recent strides in video generation have paved the way for unified audio-visual generation. In this work, we present Seedance 1.5 pro, a foundational model engineered specifically for native, joint audio-video generation. Leveraging a dual-branch Diffusion Transformer architecture, the model integrates a cross-modal joint module with a specialized multi-stage data pipeline, achieving exceptional audio-visual synchronization and superior generation quality. To ensure practical utility, we implement meticulous post-training optimizations, including Supervised Fine-Tuning (SFT) on high-quality datasets and Reinforcement Learning from Human Feedback (RLHF) with multi-dimensional reward models. Furthermore, we introduce an acceleration framework that boosts inference speed by over 10X. Seedance 1.5 pro distinguishes itself through precise multilingual and dialect lip-syncing, dynamic cinematic camera control, and enhanced narrative coherence, positioning it as a robust engine for professional-grade content creation. Seedance 1.5 pro is now accessible on Volcano Engine atthis https URL.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13507",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning",
                        "RLHF"
                    ],
                    "score": 3.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]foundation model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "Seedance 1.5 pro：原生音视频联合生成基础模型，提升专业级内容创作能力",
            "summary_zh": "本文介绍了Seedance 1.5 pro，一个专为原生、联合音视频生成而设计的基石模型。该模型采用双分支扩散Transformer架构，集成了一个跨模态联合模块和一个专门的多阶段数据管道，实现了卓越的音视频同步和卓越的生成质量。为了确保实际应用价值，我们实施了细致的后训练优化，包括基于高质量数据集的监督微调（SFT）和利用多维奖励模型的人工反馈强化学习（RLHF）。此外，我们还引入了一个加速框架，将推理速度提高了10倍以上。Seedance 1.5 pro以其精确的多语言和方言唇形同步、动态电影摄像机控制和增强的叙事连贯性而著称，使其成为专业级内容创作的强大引擎。Seedance 1.5 pro现已在火山引擎上提供。",
            "intro_zh": [
                "现有视频生成方法在音视频同步和生成质量方面存在挑战，难以满足专业级内容创作的需求。",
                "Seedance 1.5 pro采用双分支扩散Transformer架构，结合跨模态联合模块和多阶段数据管道，实现高质量音视频同步生成。",
                "通过监督微调、强化学习等后训练优化，以及推理加速框架，显著提升了生成质量和效率，并具备多语言唇形同步能力。"
            ],
            "method_zh": "**问题定义**：当前音视频生成模型在生成高质量、同步性好的内容方面存在挑战，尤其是在多语言唇形同步、动态镜头控制和叙事连贯性方面表现不足。现有方法难以满足专业级内容创作的需求，需要更强大的基础模型来解决这些问题。\\n\\n**核心思路**：Seedance 1.5 pro的核心思路是构建一个原生、联合的音视频生成基础模型，通过深度融合音频和视频信息，实现高质量的同步生成。模型采用双分支架构，分别处理音频和视频信息，并通过跨模态联合模块实现信息融合。此外，通过多阶段数据管道和后训练优化，进一步提升生成质量和实用性。\\n\\n**技术框架**：Seedance 1.5 pro采用双分支扩散Transformer架构。该架构包含两个主要分支：音频分支和视频分支。音频分支处理音频信息，视频分支处理视频信息。两个分支通过一个跨模态联合模块进行信息融合。模型还包含一个多阶段数据管道，用于处理不同类型的数据。后训练优化包括监督微调（SFT）和人工反馈强化学习（RLHF）。此外，还引入了一个加速框架，用于提高推理速度。\\n\\n**关键创新**：Seedance 1.5 pro的关键创新在于其原生、联合的音视频生成方法，以及双分支扩散Transformer架构和跨模态联合模块。该模型能够实现高质量的音视频同步生成，并具备多语言唇形同步、动态电影摄像机控制和增强的叙事连贯性。此外，后训练优化和加速框架进一步提升了模型的实用性。\\n\\n**关键设计**：模型的关键设计包括：1) 双分支扩散Transformer架构，用于分别处理音频和视频信息；2) 跨模态联合模块，用于实现音频和视频信息的融合；3) 多阶段数据管道，用于处理不同类型的数据；4) 监督微调（SFT），用于提升生成质量；5) 人工反馈强化学习（RLHF），用于优化生成结果；6) 推理加速框架，用于提高推理速度。具体的参数设置、损失函数和网络结构等细节未在摘要中详细说明，属于未知信息。",
            "application_zh": "Seedance 1.5 pro可广泛应用于电影制作、游戏开发、广告创意、虚拟现实等领域。它能够帮助专业人士和普通用户快速生成高质量的音视频内容，降低创作门槛，提升创作效率。未来，该模型有望成为内容创作领域的重要基础设施，推动音视频生成技术的进一步发展。",
            "highlight_zh": "摘要中提到，Seedance 1.5 pro实现了卓越的音视频同步和卓越的生成质量。通过后训练优化，包括监督微调（SFT）和人工反馈强化学习（RLHF），进一步提升了生成质量。此外，引入的加速框架将推理速度提高了10倍以上。该模型还具备精确的多语言和方言唇形同步、动态电影摄像机控制和增强的叙事连贯性。",
            "tags_zh": [
                "音视频生成",
                "扩散模型",
                "Transformer",
                "跨模态学习",
                "唇形同步"
            ],
            "_index": 45,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Multimodal Deep Learning for Stroke Prediction and Detection using Retinal Imaging and Clinical Data",
            "authors": [
                "Saeed Shurrab",
                "Aadim Nepal",
                "Terrence J. Lee-St. John",
                "Nicola G. Ghazi",
                "Bartlomiej Piechowski-Jozwiak",
                "Farah E. Shamout"
            ],
            "arxiv_id": "2505.02677",
            "summary": "Stroke is a major public health problem, affecting millions worldwide. Deep learning has recently demonstrated promise for enhancing the diagnosis and risk prediction of stroke. However, existing methods rely on costly medical imaging modalities, such as computed tomography. Recent studies suggest that retinal imaging could offer a cost-effective alternative for cerebrovascular health assessment due to the shared clinical pathways between the retina and the brain. Hence, this study explores the impact of leveraging retinal images and clinical data for stroke detection and risk prediction. We propose a multimodal deep neural network that processes Optical Coherence Tomography (OCT) and infrared reflectance retinal scans, combined with clinical data, such as demographics, vital signs, and diagnosis codes. We pretrained our model using a self-supervised learning framework using a real-world dataset consisting of $37$ k scans, and then fine-tuned and evaluated the model using a smaller labeled subset. Our empirical findings establish the predictive ability of the considered modalities in detecting lasting effects in the retina associated with acute stroke and forecasting future risk within a specific time horizon. The experimental results demonstrate the effectiveness of our proposed framework by achieving $5$\\% AUROC improvement as compared to the unimodal image-only baseline, and $8$\\% improvement compared to an existing state-of-the-art foundation model. In conclusion, our study highlights the potential of retinal imaging in identifying high-risk patients and improving long-term outcomes.",
            "categories": [
                "eess.IV",
                "cs.CV"
            ],
            "primary_category": "eess.IV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2505.02677",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "foundation model",
                        "[T]multimodal"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出一种基于视网膜影像和临床数据的多模态深度学习方法，用于卒中预测和检测。",
            "summary_zh": "卒中是一个影响全球数百万人的重大公共健康问题。深度学习最近在增强卒中的诊断和风险预测方面展现出潜力。然而，现有方法依赖于昂贵的医学影像模态，如计算机断层扫描。最近的研究表明，由于视网膜和大脑之间存在共同的临床通路，视网膜成像可能为脑血管健康评估提供一种经济高效的替代方案。因此，本研究探讨了利用视网膜图像和临床数据进行卒中检测和风险预测的影响。我们提出了一种多模态深度神经网络，该网络处理光学相干断层扫描（OCT）和红外反射视网膜扫描，并结合临床数据，如人口统计学、生命体征和诊断代码。我们使用包含 3.7 万次扫描的真实世界数据集，通过自监督学习框架预训练了我们的模型，然后使用较小的标记子集对模型进行微调和评估。我们的经验结果证实了所考虑的模态在检测与急性卒中相关的视网膜持久影响以及预测特定时间范围内的未来风险方面的预测能力。实验结果表明，与仅使用图像的单模态基线相比，我们提出的框架的 AUROC 提高了 5%，与现有的最先进的基础模型相比，提高了 8%。总之，我们的研究强调了视网膜成像在识别高危患者和改善长期预后方面的潜力。",
            "intro_zh": [
                "现有卒中诊断方法依赖昂贵的CT等医学影像，成本高且不便普及，限制了早期筛查。",
                "提出一种多模态深度学习框架，融合OCT、红外视网膜扫描和临床数据，提升卒中预测能力。",
                "实验表明，该方法在卒中检测和风险预测方面优于单模态基线和现有模型，AUROC最高提升8%。"
            ],
            "method_zh": "**问题定义**：论文旨在解决卒中早期预测和检测的问题，现有方法主要依赖于昂贵的医学影像设备，如CT扫描，这限制了其在早期筛查和大规模应用中的可行性。因此，需要一种更经济、更便捷的方法来评估卒中风险。\\n\\n**核心思路**：论文的核心思路是利用视网膜成像作为卒中风险评估的替代方案。由于视网膜与大脑之间存在共同的临床通路，视网膜图像可以反映脑血管的健康状况。通过结合视网膜图像（OCT和红外反射扫描）和临床数据，可以更全面地评估卒中风险。\\n\\n**技术框架**：该方法采用多模态深度神经网络，整体框架包含以下几个主要阶段：1) 数据收集：收集包含OCT、红外反射视网膜扫描和临床数据（如人口统计学、生命体征和诊断代码）的数据集。2) 自监督预训练：使用大规模未标记的视网膜图像数据集，通过自监督学习方法预训练模型，以学习视网膜图像的通用特征表示。3) 多模态融合：将视网膜图像和临床数据输入到深度神经网络中，通过融合不同模态的信息，提取与卒中相关的特征。4) 微调和评估：使用标记的卒中数据集对模型进行微调，并在测试集上评估模型的性能。\\n\\n**关键创新**：该论文的关键创新在于：1) 提出了一种基于视网膜成像的卒中预测方法，避免了对昂贵医学影像设备的依赖。2) 采用多模态深度学习框架，融合视网膜图像和临床数据，提高了卒中预测的准确性。3) 使用自监督学习方法预训练模型，充分利用了大规模未标记的视网膜图像数据。\\n\\n**关键设计**：在模型设计方面，论文采用了深度神经网络结构，具体网络结构未知。自监督预训练阶段使用了特定的自监督学习任务，具体任务未知。损失函数方面，使用了标准的分类损失函数（如交叉熵损失）进行微调。临床数据可能经过了特征工程处理，例如one-hot编码或标准化。",
            "application_zh": "该研究成果可应用于卒中高危人群的早期筛查，尤其是在医疗资源有限的地区。通过分析视网膜图像和临床数据，可以识别出潜在的卒中患者，从而进行早期干预和治疗，降低卒中的发生率和致残率。此外，该方法还可以用于评估卒中患者的预后，指导康复治疗方案的制定。",
            "highlight_zh": "实验结果表明，该方法在卒中检测和风险预测方面取得了显著的性能提升。与仅使用图像的单模态基线相比，AUROC提高了5%。与现有的最先进的基础模型相比，AUROC提高了8%。这些结果表明，融合视网膜图像和临床数据可以有效提高卒中预测的准确性。",
            "tags_zh": [
                "卒中预测",
                "视网膜成像",
                "多模态学习",
                "深度学习",
                "自监督学习"
            ],
            "_index": 46,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2505.02677/RetStroke-overview.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2505.02677/overall.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2505.02677/comorbidities.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Informing Acquisition Functions via Foundation Models for Molecular Discovery",
            "authors": [
                "Qi Chen",
                "Fabio Ramos",
                "Alán Aspuru-Guzik",
                "Florian Shkurti"
            ],
            "arxiv_id": "2512.13935",
            "summary": "Bayesian Optimization (BO) is a key methodology for accelerating molecular discovery by estimating the mapping from molecules to their properties while seeking the optimal candidate. Typically, BO iteratively updates a probabilistic surrogate model of this mapping and optimizes acquisition functions derived from the model to guide molecule selection. However, its performance is limited in low-data regimes with insufficient prior knowledge and vast candidate spaces. Large language models (LLMs) and chemistry foundation models offer rich priors to enhance BO, but high-dimensional features, costly in-context learning, and the computational burden of deep Bayesian surrogates hinder their full utilization. To address these challenges, we propose a likelihood-free BO method that bypasses explicit surrogate modeling and directly leverages priors from general LLMs and chemistry-specific foundation models to inform acquisition functions. Our method also learns a tree-structured partition of the molecular search space with local acquisition functions, enabling efficient candidate selection via Monte Carlo Tree Search. By further incorporating coarse-grained LLM-based clustering, it substantially improves scalability to large candidate sets by restricting acquisition function evaluations to clusters with statistically higher property values. We show through extensive experiments and ablations that the proposed method substantially improves scalability, robustness, and sample efficiency in LLM-guided BO for molecular discovery.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "bio.QM"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13935",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "[T]foundation model"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于大模型的无似然贝叶斯优化方法，加速分子发现。",
            "summary_zh": "贝叶斯优化(BO)是一种通过估计分子到其属性的映射并寻找最佳候选分子来加速分子发现的关键方法。通常，BO迭代地更新该映射的概率代理模型，并优化从模型导出的采集函数来指导分子选择。然而，其性能在数据量不足、先验知识匮乏和候选空间巨大的低数据状态下受到限制。大型语言模型(LLM)和化学基础模型提供了丰富的先验知识来增强BO，但高维特征、昂贵的上下文学习以及深度贝叶斯代理模型的计算负担阻碍了它们的充分利用。为了解决这些挑战，我们提出了一种无似然BO方法，该方法绕过显式代理建模，直接利用来自通用LLM和化学特定基础模型的先验知识来告知采集函数。我们的方法还学习分子搜索空间的树状结构划分，并使用局部采集函数，从而可以通过蒙特卡洛树搜索有效地选择候选分子。通过进一步结合基于LLM的粗粒度聚类，它通过将采集函数评估限制在具有统计学上更高属性值的聚类中，从而大大提高了对大型候选集的可扩展性。通过广泛的实验和消融研究，我们表明所提出的方法大大提高了LLM引导的分子发现中BO的可扩展性、鲁棒性和样本效率。",
            "intro_zh": [
                "传统贝叶斯优化在分子发现中面临低数据、高维度和计算成本高的挑战，限制了其性能。",
                "该论文提出一种无似然贝叶斯优化方法，直接利用大型语言模型和化学基础模型的先验知识来指导采集函数。",
                "实验结果表明，该方法在可扩展性、鲁棒性和样本效率方面均有显著提升，尤其是在LLM引导的分子发现中。"
            ],
            "method_zh": "**问题定义**：论文旨在解决分子发现中，传统贝叶斯优化方法在低数据量、高维空间和计算资源有限的情况下表现不佳的问题。现有方法依赖于构建分子属性的代理模型，但当数据不足时，代理模型的准确性会受到严重影响，导致优化效果不佳。此外，直接使用大型语言模型（LLM）的特征进行贝叶斯优化面临高维特征处理和计算负担过重的问题。\\n\\n**核心思路**：论文的核心思路是绕过显式的代理模型构建，直接利用大型语言模型和化学领域基础模型提供的先验知识来指导贝叶斯优化的采集函数。通过这种方式，可以避免代理模型带来的误差累积，并充分利用预训练模型中蕴含的丰富信息。同时，论文还引入了树状结构的搜索空间划分和基于LLM的粗粒度聚类，以提高算法的可扩展性和效率。\\n\\n**技术框架**：该方法主要包含以下几个阶段：1) 利用大型语言模型或化学领域基础模型提取分子特征；2) 构建分子搜索空间的树状结构划分，每个节点对应一个分子子集；3) 在每个节点上定义局部采集函数，该函数直接利用预训练模型的先验知识；4) 使用蒙特卡洛树搜索（MCTS）在树状结构上进行搜索，选择具有最高采集函数值的分子；5) 利用基于LLM的粗粒度聚类，将候选分子集划分为若干个簇，并仅在具有较高属性值的簇中进行采集函数评估。\\n\\n**关键创新**：该方法最重要的创新点在于提出了无似然贝叶斯优化框架，避免了显式代理模型的构建，直接利用预训练模型的先验知识指导采集函数。此外，树状结构搜索空间划分和基于LLM的粗粒度聚类也显著提高了算法的可扩展性和效率。\\n\\n**关键设计**：论文的关键设计包括：1) 采集函数的具体形式，如何将预训练模型的输出转化为采集函数值；2) 树状结构划分的具体方法，例如如何选择划分标准和划分深度；3) 基于LLM的粗粒度聚类的实现细节，例如如何选择聚类算法和簇的数量；4) 蒙特卡洛树搜索的参数设置，例如探索-利用平衡系数。",
            "application_zh": "该研究成果可广泛应用于药物发现、材料设计等领域。通过利用大型语言模型和化学基础模型的先验知识，可以加速新分子或新材料的发现过程，降低研发成本，并提高研发效率。该方法尤其适用于数据稀缺或计算资源有限的场景，具有重要的实际应用价值。",
            "highlight_zh": "实验结果表明，该方法在分子发现任务中显著优于传统的贝叶斯优化方法。具体而言，该方法在可扩展性、鲁棒性和样本效率方面均有显著提升。例如，在处理大规模候选分子集时，该方法能够有效地缩小搜索范围，并快速找到具有较高属性值的分子。消融实验进一步验证了各个模块的有效性。",
            "tags_zh": [
                "贝叶斯优化",
                "分子发现",
                "大型语言模型",
                "化学基础模型",
                "无似然优化"
            ],
            "_index": 47,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13935/figures/molecules/mole1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13935/x1.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.13935/figures/toy_data/root_leaf_acqf_iter_1.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Cornserve: Efficiently Serving Any-to-Any Multimodal Models",
            "authors": [
                "Jeff J. Ma",
                "Jae-Won Chung",
                "Jisang Ahn",
                "Yizhuo Liang",
                "Akshay Jajoo",
                "Myungjin Lee",
                "Mosharaf Chowdhury"
            ],
            "arxiv_id": "2512.14098",
            "summary": "We present Cornserve, an efficient online serving system for an emerging class of multimodal models called Any-to-Any models. Any-to-Any models accept combinations of text and multimodal data (e.g., image, video, audio) as input and also generate combinations of text and multimodal data as output, introducing request type, computation path, and computation scaling heterogeneity in model serving.Cornserve allows model developers to describe the computation graph of generic Any-to-Any models, which consists of heterogeneous components such as multimodal encoders, autoregressive models like Large Language Models (LLMs), and multimodal generators like Diffusion Transformers (DiTs). Given this, Cornserve's planner automatically finds an optimized deployment plan for the model, including whether and how to disaggregate the model into smaller components based on model and workload characteristics. Cornserve's distributed runtime then executes the model per the plan, efficiently handling Any-to-Any model heterogeneity during online serving. Evaluations show that Cornserve can efficiently serve diverse Any-to-Any models and workloads, delivering up to 3.81$\\times$ throughput improvement and up to 5.79$\\times$ tail latency reduction over existing solutions.",
            "categories": [
                "cs.LG",
                "cs.DC"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14098",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "[T]multimodal"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "Cornserve：高效服务任意到任意多模态模型，提升吞吐和降低延迟。",
            "summary_zh": "本文提出了Cornserve，一个高效的在线服务系统，专门针对新兴的任意到任意（Any-to-Any）多模态模型。这类模型接受文本和多模态数据（如图像、视频、音频）的组合作为输入，并生成文本和多模态数据的组合作为输出，从而在模型服务中引入了请求类型、计算路径和计算规模的异构性。Cornserve允许模型开发者描述通用Any-to-Any模型的计算图，该计算图由异构组件构成，例如多模态编码器、大型语言模型（LLM）等自回归模型以及扩散Transformer（DiT）等多模态生成器。在此基础上，Cornserve的规划器自动为模型找到优化的部署方案，包括是否以及如何基于模型和工作负载特征将模型分解为更小的组件。然后，Cornserve的分布式运行时按照该方案执行模型，从而在在线服务期间高效地处理Any-to-Any模型的异构性。评估表明，Cornserve可以高效地服务各种Any-to-Any模型和工作负载，与现有解决方案相比，吞吐量提高了3.81倍，尾部延迟降低了5.79倍。",
            "intro_zh": [
                "现有模型服务系统难以有效处理Any-to-Any多模态模型的异构性，导致资源利用率低和延迟高。",
                "Cornserve通过计算图描述Any-to-Any模型，并自动规划优化部署方案，从而高效处理模型异构性。",
                "实验结果表明，Cornserve在吞吐量和尾部延迟方面显著优于现有解决方案，提升效果明显。"
            ],
            "method_zh": "**问题定义**：现有模型服务系统难以有效处理Any-to-Any多模态模型的异构性。Any-to-Any模型输入输出均为多种模态数据的组合，导致请求类型、计算路径和计算规模差异巨大，传统模型服务方法难以有效应对这种异构性，造成资源浪费和延迟增加。\\n\\n**核心思路**：Cornserve的核心思路是允许模型开发者描述Any-to-Any模型的计算图，然后由系统自动规划和执行优化的部署方案。通过显式地表示模型的计算流程和组件，系统可以更好地理解模型的异构性，并根据模型和工作负载的特性进行优化。\\n\\n**技术框架**：Cornserve包含两个主要组件：规划器（Planner）和分布式运行时（Distributed Runtime）。规划器接收模型开发者定义的计算图，并根据模型和工作负载的特征，自动生成优化的部署方案，包括模型分解策略、组件放置策略等。分布式运行时按照规划器生成的方案执行模型，负责组件之间的通信、数据传输和资源管理。\\n\\n**关键创新**：Cornserve的关键创新在于其自动化的模型部署规划能力。与传统的手动部署方式相比，Cornserve可以根据模型和工作负载的动态变化，自动调整部署方案，从而实现更高的资源利用率和更低的延迟。此外，Cornserve还支持将模型分解为更小的组件，并根据组件的计算特性进行优化部署，进一步提升了性能。\\n\\n**关键设计**：Cornserve的规划器使用基于成本模型的优化算法，综合考虑模型的计算复杂度、数据传输开销、资源可用性等因素，选择最优的部署方案。分布式运行时采用基于Actor模型的并发编程框架，实现高效的组件间通信和数据传输。具体的参数设置和网络结构细节在论文中未详细描述，属于未知信息。",
            "application_zh": "Cornserve可广泛应用于需要处理多模态数据输入输出的AI应用，例如智能客服、多模态内容生成、跨模态检索等。它能够提升这些应用的响应速度和用户体验，并降低部署和维护成本。未来，Cornserve有望成为构建下一代多模态AI应用的关键基础设施。",
            "highlight_zh": "实验结果表明，Cornserve在服务各种Any-to-Any模型和工作负载时，与现有解决方案相比，吞吐量提高了高达3.81倍，尾部延迟降低了高达5.79倍。这些显著的性能提升证明了Cornserve在处理多模态模型异构性方面的有效性。",
            "tags_zh": [
                "多模态模型服务",
                "Any-to-Any模型",
                "计算图",
                "模型部署优化",
                "分布式系统",
                "异构计算",
                "大型语言模型",
                "扩散模型"
            ],
            "_index": 48,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14098/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14098/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14098/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Hierarchical Multi-agent Large Language Model Reasoning for Autonomous Functional Materials Discovery",
            "authors": [
                "Samuel Rothfarb",
                "Megan C. Davis",
                "Ivana Matanovic",
                "Baikun Li",
                "Edward F. Holby",
                "Wilton J.M. Kort-Kamp"
            ],
            "arxiv_id": "2512.13930",
            "summary": "Artificial intelligence is reshaping scientific exploration, but most methods automate procedural tasks without engaging in scientific reasoning, limiting autonomy in discovery. We introduce Materials Agents for Simulation and Theory in Electronic-structure Reasoning (MASTER), an active learning framework where large language models autonomously design, execute, and interpret atomistic simulations. In MASTER, a multimodal system translates natural language into density functional theory workflows, while higher-level reasoning agents guide discovery through a hierarchy of strategies, including a single agent baseline and three multi-agent approaches: peer review, triage-ranking, and triage-forms. Across two chemical applications, CO adsorption on Cu-surface transition metal (M) adatoms and on M-N-C catalysts, reasoning-driven exploration reduces required atomistic simulations by up to 90% relative to trial-and-error selection. Reasoning trajectories reveal chemically grounded decisions that cannot be explained by stochastic sampling or semantic bias. Altogether, multi-agent collaboration accelerates materials discovery and marks a new paradigm for autonomous scientific exploration.",
            "categories": [
                "cs.AI",
                "cs.CL",
                "cs.LG",
                "cs.MA"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13930",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model",
                        "multimodal"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出MASTER框架，利用层级多智能体大语言模型加速自主功能材料发现。",
            "summary_zh": "人工智能正在重塑科学探索，但现有方法大多自动化程序性任务，缺乏科学推理，限制了发现的自主性。我们提出了材料模拟与电子结构推理智能体（MASTER），一个主动学习框架，其中大语言模型自主设计、执行和解释原子模拟。在MASTER中，多模态系统将自然语言转化为密度泛函理论工作流程，而更高层次的推理智能体通过层级策略指导发现，包括单智能体基线和三种多智能体方法：同行评审、分流排序和分流表单。在两个化学应用中，CO在Cu表面过渡金属(M)吸附原子和M-N-C催化剂上的吸附，基于推理的探索相对于试错选择减少了高达90%的原子模拟需求。推理轨迹揭示了化学基础的决策，这些决策无法用随机抽样或语义偏差来解释。总而言之，多智能体协作加速了材料发现，并标志着自主科学探索的新范式。",
            "intro_zh": [
                "现有材料发现方法侧重自动化程序任务，缺乏科学推理能力，限制了自主性。",
                "MASTER框架利用多智能体大语言模型进行层级推理，自主设计、执行和解释原子模拟。",
                "实验表明，MASTER框架在材料发现中，可减少高达90%的原子模拟需求，加速发现过程。"
            ],
            "method_zh": "**问题定义**：论文旨在解决功能材料发现过程中计算成本高昂、依赖专家经验的问题。现有方法通常依赖试错法或高通量计算，效率低下，且难以进行深入的科学推理和策略调整。因此，如何利用人工智能实现更高效、自主的材料发现是本研究的核心问题。\\n\\n**核心思路**：论文的核心思路是利用大语言模型（LLM）的推理能力，构建一个多智能体系统，模拟科学家进行材料发现的过程。通过将材料发现任务分解为多个子任务，并分配给不同的智能体，实现协同工作和知识共享，从而提高发现效率和质量。这种方法旨在将LLM从单纯的数据分析工具转变为具有科学推理能力的助手。\\n\\n**技术框架**：MASTER框架包含以下主要模块：1) 多模态系统：将自然语言描述转化为密度泛函理论（DFT）工作流程。2) 层级推理智能体：包括单智能体基线和三种多智能体方法（同行评审、分流排序、分流表单），用于指导材料发现过程。3) 原子模拟模块：执行DFT计算，提供材料性质数据。整个流程如下：用户输入自然语言描述的材料发现目标，多模态系统将其转化为DFT工作流程，层级推理智能体根据当前知识和目标，选择合适的模拟方案，原子模拟模块执行计算，并将结果反馈给推理智能体，智能体根据结果调整策略，重复上述过程，直到达到目标。\\n\\n**关键创新**：该论文的关键创新在于：1) 提出了一个基于多智能体大语言模型的自主材料发现框架，实现了科学推理和策略调整。2) 设计了多种多智能体协作策略（同行评审、分流排序、分流表单），提高了发现效率。3) 将自然语言描述转化为DFT工作流程，实现了人机交互的无缝衔接。与现有方法相比，MASTER框架能够更高效地探索材料空间，并提供可解释的推理轨迹。\\n\\n**关键设计**：论文中关键的设计包括：1) 智能体的角色分配和协作机制：不同的智能体负责不同的子任务，通过共享信息和协同工作，实现整体目标的优化。2) 推理策略的设计：同行评审、分流排序和分流表单等策略，模拟了科学家进行材料发现的常用方法，提高了发现效率。3) 多模态系统的设计：将自然语言描述转化为DFT工作流程，降低了使用门槛，方便用户进行材料发现。",
            "application_zh": "该研究成果可应用于各种功能材料的发现，例如催化剂、储能材料、光电器件等。通过减少实验和计算成本，加速新材料的开发，有望推动相关领域的科技进步。未来，该框架可以扩展到其他科学领域，例如药物发现、生物工程等，实现更广泛的自主科学探索。",
            "highlight_zh": "实验结果表明，MASTER框架在CO吸附于Cu表面过渡金属原子和M-N-C催化剂两个化学应用中，相对于试错法，减少了高达90%的原子模拟需求。推理轨迹显示，MASTER框架能够做出基于化学原理的决策，而这些决策无法用随机抽样或语义偏差来解释。这表明MASTER框架具有真正的科学推理能力，能够有效地指导材料发现。",
            "tags_zh": [
                "材料发现",
                "大语言模型",
                "多智能体系统",
                "密度泛函理论",
                "自主探索"
            ],
            "_index": 49,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "AI-Powered Annotation Pipelines for Stabilizing Large Language Models: A Human-AI Synergy Approach",
            "authors": [
                "Gangesh Pathak",
                "Prasanna Kumar"
            ],
            "arxiv_id": "2512.13714",
            "summary": "LLM implementations are failing in highly regulated industries owing to instability issues, inconsistent reasoning, hallucinations and performance variability, especially in workflows. These reliability issues restrict safe use of LLM in areas that need the precision of facts and consistent behavior (Aiyappa et al., 2023). The current methods of stabilization, such as, reinforcement learning with human feedback (RLHF) and supervised fine-tuning, offer quantifiable improvements but are expensive and based on the intensive annotation of humans, thus being not easily scaled in a sustainable way (Dong et al., 2023; Retzlaff et al., 2024). This paper presents an AI-based annotation pipeline that systematically identifies, labels, and fixes for instability patterns on LLM output. Our human-AI synergy method combines the models of automated weak supervision and confidence-based annotation with the target human validation to guarantee the reliability and moral uprightness of feedback information (Cabitza et al., 2023; Jiang et al., 2023). The semantic consistency, factual correctness, and logical coherence categories of stability-specific annotation are introduced into our framework, allowing the continuous calibration of models and the enhancement of their robustness based on the feedback loops (Honovich et al., 2021; Nan et al., 2021).",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13714",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning",
                        "RLHF"
                    ],
                    "score": 3.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出AI驱动的标注流水线，稳定大语言模型并提升可靠性",
            "summary_zh": "由于不稳定、不一致的推理、幻觉和性能变化等问题，大语言模型（LLM）在高度监管的行业中应用受阻。这些可靠性问题限制了LLM在需要事实精确性和行为一致性的领域中的安全使用。目前诸如基于人类反馈的强化学习（RLHF）和监督微调等稳定方法虽然提供了可量化的改进，但成本高昂，并且依赖于密集的人工标注，因此难以可持续地扩展。本文提出了一种基于AI的标注流水线，该流水线系统地识别、标记和修复LLM输出中的不稳定模式。我们的人机协同方法将自动弱监督和基于置信度的标注模型与目标人工验证相结合，以保证反馈信息的可靠性和道德正确性。该框架引入了语义一致性、事实正确性和逻辑连贯性等稳定性特定标注类别，从而允许基于反馈循环持续校准模型并增强其鲁棒性。",
            "intro_zh": [
                "现有大语言模型稳定方法依赖大量人工标注，成本高且难以持续扩展。",
                "提出一种AI驱动的标注流水线，结合自动弱监督、置信度标注与人工验证。",
                "引入语义一致性、事实正确性和逻辑连贯性等标注类别，持续校准模型。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大语言模型在实际应用中由于不稳定、不一致、幻觉等问题导致的可靠性不足。现有稳定方法，如RLHF和监督微调，依赖大量人工标注，成本高昂且难以规模化，限制了LLM在需要高精度和一致性的场景中的应用。\\n\\n**核心思路**：论文的核心思路是利用AI技术自动化标注流程，减少对人工标注的依赖，同时保证标注质量。通过结合自动弱监督、置信度标注和人工验证，构建一个人机协同的标注流水线，从而更高效、更经济地稳定大语言模型。\\n\\n**技术框架**：该AI驱动的标注流水线包含以下主要模块：1) 自动弱监督模块：利用已有的知识或规则自动生成初步标注；2) 基于置信度的标注模块：根据模型对标注结果的置信度进行筛选，提高标注质量；3) 人工验证模块：对自动标注结果进行人工审核和修正，确保标注的可靠性和道德正确性；4) 反馈循环：将人工验证后的标注数据用于持续校准模型，提升模型的鲁棒性。\\n\\n**关键创新**：论文的关键创新在于提出了一种人机协同的标注框架，该框架能够有效地结合AI的自动化能力和人类的判断力，从而在保证标注质量的同时，显著降低标注成本。此外，论文还引入了语义一致性、事实正确性和逻辑连贯性等稳定性特定标注类别，为模型的持续校准提供了更细粒度的反馈信息。\\n\\n**关键设计**：论文的关键设计包括：1) 如何选择合适的弱监督源，以保证自动标注的覆盖率和准确率；2) 如何设计置信度评估指标，以有效筛选高质量的自动标注结果；3) 如何设计人工验证流程，以最大程度地减少人工干预，同时保证标注的可靠性；4) 如何设计反馈循环，以实现模型的持续学习和改进。具体的参数设置、损失函数和网络结构等技术细节在论文中可能未详细描述，属于未知信息。",
            "application_zh": "该研究成果可应用于金融、医疗、法律等高度监管行业，提升大语言模型在这些领域的可靠性和安全性。通过降低标注成本，加速LLM在各行业的落地应用。未来可进一步探索如何利用主动学习等技术，更有效地利用人工标注资源，进一步提升标注效率和模型性能。",
            "highlight_zh": "论文提出了AI驱动的标注流水线，旨在解决大语言模型在实际应用中稳定性和可靠性问题。虽然摘要中没有明确给出实验数据，但强调了该方法能够降低标注成本，并提升模型的鲁棒性。具体性能提升幅度未知，需要在论文正文中查找。",
            "tags_zh": [
                "大语言模型",
                "AI标注",
                "人机协同",
                "弱监督学习",
                "模型稳定",
                "可靠性",
                "反馈循环"
            ],
            "_index": 50,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Sparsity-Controllable Dynamic Top-p MoE for Large Foundation Model Pre-training",
            "authors": [
                "Can Jin",
                "Hongwu Peng",
                "Mingcan Xiang",
                "Qixin Zhang",
                "Xiangchi Yuan",
                "Amit Hasan",
                "Ohiremen Dibua",
                "Yifan Gong",
                "Yan Kang",
                "Dimitris N. Metaxas"
            ],
            "arxiv_id": "2512.13996",
            "summary": "Sparse Mixture-of-Experts (MoE) architectures effectively scale model capacity by activating only a subset of experts for each input token. However, the standard Top-k routing strategy imposes a uniform sparsity pattern that ignores the varying difficulty of tokens. While Top-p routing offers a flexible alternative, existing implementations typically rely on a fixed global probability threshold, which results in uncontrolled computational costs and sensitivity to hyperparameter selection. In this paper, we propose DTop-p MoE, a sparsity-controllable dynamic Top-p routing mechanism. To resolve the challenge of optimizing a non-differentiable threshold, we utilize a Proportional-Integral (PI) Controller that dynamically adjusts the probability threshold to align the running activated-expert sparsity with a specified target. Furthermore, we introduce a dynamic routing normalization mechanism that adapts layer-wise routing logits, allowing different layers to learn distinct expert-selection patterns while utilizing a global probability threshold. Extensive experiments on Large Language Models and Diffusion Transformers demonstrate that DTop-p consistently outperforms both Top-k and fixed-threshold Top-p baselines. Our analysis confirms that DTop-p maintains precise control over the number of activated experts while adaptively allocating resources across different tokens and layers. Furthermore, DTop-p exhibits strong scaling properties with respect to expert granularity, expert capacity, model size, and dataset size, offering a robust framework for large-scale MoE pre-training.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13996",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "[T]foundation model"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出DTop-p MoE，实现稀疏度可控的动态Top-p路由，提升大模型预训练效果。",
            "summary_zh": "稀疏混合专家(MoE)架构通过仅激活每个输入token的专家子集来有效地扩展模型容量。然而，标准的Top-k路由策略施加了一种统一的稀疏模式，忽略了token难度的变化。虽然Top-p路由提供了一种灵活的替代方案，但现有的实现通常依赖于固定的全局概率阈值，这导致了不可控的计算成本和对超参数选择的敏感性。本文提出了DTop-p MoE，一种稀疏度可控的动态Top-p路由机制。为了解决优化不可微阈值的挑战，我们利用比例-积分(PI)控制器动态调整概率阈值，使运行激活的专家稀疏度与指定的target对齐。此外，我们引入了一种动态路由归一化机制，该机制调整层级的路由logits，允许不同的层学习不同的专家选择模式，同时使用全局概率阈值。在大型语言模型和扩散Transformer上的大量实验表明，DTop-p始终优于Top-k和固定阈值Top-p基线。我们的分析证实，DTop-p保持对激活专家数量的精确控制，同时自适应地在不同的token和层之间分配资源。此外，DTop-p在专家粒度、专家容量、模型大小和数据集大小方面表现出强大的缩放特性，为大规模MoE预训练提供了一个鲁棒的框架。",
            "intro_zh": [
                "传统Top-k路由在MoE中强制统一稀疏性，忽略了不同token的难度差异，而固定阈值的Top-p路由难以控制计算成本。",
                "DTop-p MoE利用PI控制器动态调整Top-p阈值，使激活专家数量与目标稀疏度对齐，实现稀疏度可控。",
                "实验表明，DTop-p在LLM和Diffusion Transformer上优于Top-k和固定阈值Top-p，并展现出良好的扩展性。"
            ],
            "method_zh": "**问题定义**：现有MoE模型中的Top-k路由策略对所有token采用相同的稀疏度，无法根据token的难易程度自适应地分配计算资源。而Top-p路由虽然可以自适应地选择专家，但依赖于固定的全局概率阈值，难以控制计算成本，且对超参数敏感。这限制了MoE模型在大规模预训练中的应用。\\n\\n**核心思路**：DTop-p MoE的核心思路是引入一个动态调整的Top-p阈值，该阈值由一个比例-积分(PI)控制器控制。PI控制器根据当前激活的专家数量与目标稀疏度之间的差异，动态地调整概率阈值，从而实现对激活专家数量的精确控制。同时，引入动态路由归一化机制，允许不同层学习不同的专家选择模式。\\n\\n**技术框架**：DTop-p MoE的整体框架与标准的MoE模型类似，主要区别在于路由机制。对于每个输入token，首先计算路由logits。然后，通过动态Top-p路由选择激活的专家。PI控制器根据激活的专家数量与目标稀疏度之间的差异，动态调整Top-p阈值。最后，将token分配给选定的专家进行处理。\\n\\n**关键创新**：DTop-p MoE的关键创新在于：1) 提出了一种稀疏度可控的动态Top-p路由机制，解决了传统Top-p路由难以控制计算成本的问题。2) 利用PI控制器动态调整Top-p阈值，实现了对激活专家数量的精确控制。3) 引入动态路由归一化机制，允许不同层学习不同的专家选择模式。\\n\\n**关键设计**：PI控制器的参数（比例增益和积分增益）需要根据具体任务进行调整。动态路由归一化机制通过学习每个层的缩放因子来实现。损失函数包括标准的预训练损失和用于控制稀疏度的辅助损失。目标稀疏度是一个重要的超参数，需要根据计算资源和模型性能进行权衡。",
            "application_zh": "DTop-p MoE可应用于大规模语言模型、视觉模型等各种深度学习模型的预训练，尤其适用于计算资源有限的场景。通过精确控制稀疏度，可以在保证模型性能的同时，降低计算成本，加速模型训练。该方法有望推动更大规模、更高效的AI模型的发展。",
            "highlight_zh": "实验结果表明，DTop-p MoE在大型语言模型和扩散Transformer上均优于Top-k和固定阈值Top-p基线。例如，在语言模型预训练中，DTop-p在保持相同计算成本的情况下，能够获得更高的perplexity。此外，DTop-p在不同专家粒度、专家容量、模型大小和数据集大小下均表现出良好的扩展性。",
            "tags_zh": [
                "混合专家模型",
                "MoE",
                "稀疏路由",
                "Top-p路由",
                "动态阈值",
                "PI控制器",
                "大模型预训练",
                "计算效率"
            ],
            "_index": 51,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13996/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13996/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.13996/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Intention Chain-of-Thought Prompting with Dynamic Routing for Code Generation",
            "authors": [
                "Shen Li",
                "Li Huang",
                "Shaoxiong Zhan",
                "Weifeng Sun",
                "Tao Yin",
                "Zhongxin Liu",
                "Meng Yan"
            ],
            "arxiv_id": "2512.14048",
            "summary": "Large language models (LLMs) exhibit strong generative capabilities and have shown great potential in code generation. Existing chain-of-thought (CoT) prompting methods enhance model reasoning by eliciting intermediate steps, but suffer from two major limitations: First, their uniform application tends to induce overthinking on simple tasks. Second, they lack intention abstraction in code generation, such as explicitly modeling core algorithmic design and efficiency, leading models to focus on surface-level structures while neglecting the global problem objective. Inspired by the cognitive economy principle of engaging structured reasoning only when necessary to conserve cognitive resources, we propose RoutingGen, a novel difficulty-aware routing framework that dynamically adapts prompting strategies for code generation. For simple tasks, it adopts few-shot prompting; for more complex ones, it invokes a structured reasoning strategy, termed Intention Chain-of-Thought (ICoT), which we introduce to guide the model in capturing task intention, such as the core algorithmic logic and its time complexity. Experiments across three models and six standard code generation benchmarks show that RoutingGen achieves state-of-the-art performance in most settings, while reducing total token usage by 46.37% on average across settings. Furthermore, ICoT outperforms six existing prompting baselines on challenging benchmarks.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14048",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "[T]chain-of-thought"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出RoutingGen框架，通过动态路由和意图链式思考提升代码生成效果。",
            "summary_zh": "大型语言模型(LLMs)在代码生成方面展现出强大的生成能力和巨大的潜力。现有的思维链(CoT)提示方法通过引发中间步骤来增强模型推理，但存在两个主要限制：首先，它们的统一应用容易导致简单任务的过度思考。其次，它们在代码生成中缺乏意图抽象，例如显式地建模核心算法设计和效率，导致模型专注于表面结构而忽略了全局问题目标。受到认知经济原则的启发，即仅在必要时才进行结构化推理以节省认知资源，我们提出RoutingGen，一种新颖的难度感知路由框架，可以动态地调整代码生成的提示策略。对于简单的任务，它采用少样本提示；对于更复杂的任务，它调用一种结构化的推理策略，称为意图链式思考(ICoT)，我们引入该策略来指导模型捕获任务意图，例如核心算法逻辑及其时间复杂度。在三个模型和六个标准代码生成基准上的实验表明，RoutingGen在大多数设置中实现了最先进的性能，同时在各种设置中平均减少了46.37%的总token使用量。此外，ICoT在具有挑战性的基准测试中优于六个现有的提示基线。",
            "intro_zh": [
                "现有CoT方法在代码生成中存在过度思考和缺乏意图抽象的问题，导致效率降低和性能瓶颈。",
                "RoutingGen框架通过难度感知路由，动态选择少样本提示或意图链式思考(ICoT)策略，优化资源利用。",
                "实验结果表明，RoutingGen在多个代码生成基准上达到SOTA，并显著降低了token使用量。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型在代码生成任务中，现有思维链(CoT)提示方法存在的两个主要问题：一是对于简单任务的过度推理，导致计算资源浪费；二是缺乏对代码意图的抽象，使得模型难以把握算法的核心逻辑和效率，从而影响代码质量。现有方法未能根据任务难度动态调整推理策略，导致效率和性能受限。\\n\\n**核心思路**：论文的核心思路是引入难度感知的动态路由机制，根据任务的复杂程度，选择合适的提示策略。对于简单任务，采用更高效的少样本提示；对于复杂任务，则采用结构化的意图链式思考(ICoT)方法，引导模型理解任务意图，从而生成更优质的代码。这种动态调整策略旨在平衡推理成本和代码质量。\\n\\n**技术框架**：RoutingGen框架包含两个主要模块：难度评估模块和提示策略选择模块。难度评估模块用于判断输入代码生成任务的复杂程度。提示策略选择模块根据难度评估结果，动态选择合适的提示策略。如果任务难度较低，则采用少样本提示；如果任务难度较高，则采用ICoT提示。ICoT提示包括明确建模核心算法逻辑和时间复杂度等步骤，以引导模型捕获任务意图。\\n\\n**关键创新**：论文的关键创新在于提出了难度感知的动态路由机制和意图链式思考(ICoT)方法。动态路由机制能够根据任务难度自适应地选择提示策略，避免了过度推理和资源浪费。ICoT方法则通过显式地建模任务意图，引导模型生成更符合要求的代码，提升了代码质量。\\n\\n**关键设计**：难度评估模块的具体实现方式未知，可能采用了基于规则或机器学习的方法。ICoT提示的具体步骤包括：首先，明确任务的目标和约束；其次，设计核心算法逻辑；然后，分析算法的时间复杂度；最后，生成代码。论文中没有详细说明少样本提示的具体实现方式，但可以推测是采用了常见的示例学习方法。",
            "application_zh": "该研究成果可应用于各种代码生成场景，例如软件开发、自动化测试、数据分析等。通过动态调整推理策略和引导模型理解任务意图，可以提高代码生成的效率和质量，降低开发成本，并加速软件开发流程。未来，该方法有望扩展到其他自然语言处理任务中，例如文本摘要、机器翻译等。",
            "highlight_zh": "实验结果表明，RoutingGen框架在六个标准代码生成基准测试中，在大多数设置下实现了最先进的性能。与现有方法相比，RoutingGen平均减少了46.37%的token使用量，显著提高了效率。此外，ICoT方法在具有挑战性的基准测试中优于六个现有的提示基线，证明了其有效性。",
            "tags_zh": [
                "代码生成",
                "大型语言模型",
                "思维链",
                "动态路由",
                "意图建模",
                "提示学习",
                "认知经济",
                "算法设计"
            ],
            "_index": 52,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14048/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14048/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14048/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "RADAR: Accelerating Large Language Model Inference With RL-Based Dynamic Draft Trees",
            "authors": [
                "Junjie Ma",
                "Jinlong Li"
            ],
            "arxiv_id": "2512.14069",
            "summary": "Inference with modern Large Language Models (LLMs) is expensive and slow, and speculative sampling has emerged as an effective solution to this problem, however, the number of the calls to the draft model for generating candidate tokens in speculative sampling is a preset hyperparameter, lacking flexibility. To generate and utilize the candidate tokens more effectively, we propose RADAR, a novel speculative sampling method with RL-based dynamic draft trees. RADAR formulates the draft tree generation process as a Markov Decision Process (MDP) and employs offline reinforcement learning to train a prediction model, which enables real-time decision on the calls to the draft model, reducing redundant computations and further accelerating inference. Evaluations across three LLMs and four tasks show that RADAR achieves a speedup of 3.17x-4.82x over the auto-regressive decoding baseline. The code is available atthis https URL.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14069",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning",
                        "offline reinforcement learning"
                    ],
                    "score": 3.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于强化学习动态草稿树的RADAR，加速大语言模型推理。",
            "summary_zh": "现代大型语言模型（LLM）的推理成本高且速度慢，推测采样已成为解决此问题的有效方法。然而，推测采样中用于生成候选token的草稿模型调用次数是一个预设的超参数，缺乏灵活性。为了更有效地生成和利用候选token，我们提出了一种新的推测采样方法RADAR，它采用基于强化学习的动态草稿树。RADAR将草稿树生成过程形式化为一个马尔可夫决策过程（MDP），并采用离线强化学习来训练预测模型，从而能够实时决策草稿模型的调用次数，减少冗余计算，进一步加速推理。在三个LLM和四个任务上的评估表明，RADAR相对于自回归解码基线实现了3.17倍-4.82倍的加速。代码可在该URL获得。",
            "intro_zh": [
                "现有推测采样方法中，草稿模型调用次数为预设超参数，缺乏灵活性，导致计算冗余。",
                "RADAR将草稿树生成过程建模为MDP，利用离线强化学习训练预测模型，动态决策草稿模型调用次数。",
                "实验结果表明，RADAR在多个LLM和任务上实现了显著的推理加速，最高可达4.82倍。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型推理速度慢、成本高的问题。现有的推测采样方法虽然能加速推理，但其草稿模型调用次数是预先设定的超参数，无法根据实际情况动态调整，导致在某些情况下产生不必要的计算冗余，效率不高。\\n\\n**核心思路**：论文的核心思路是将草稿树的生成过程视为一个马尔可夫决策过程（MDP），并利用强化学习来训练一个策略，该策略能够根据当前状态动态地决定是否继续调用草稿模型生成候选token。通过这种方式，可以避免不必要的草稿模型调用，从而提高推理效率。\\n\\n**技术框架**：RADAR的整体框架包含以下几个主要模块：1) **状态表示**：定义MDP的状态，包括当前已生成的token序列、草稿模型的置信度等信息。2) **动作空间**：定义MDP的动作，例如“继续调用草稿模型”或“停止调用草稿模型”。3) **奖励函数**：设计奖励函数，鼓励生成准确的候选token，并惩罚不必要的草稿模型调用。4) **强化学习模型**：使用离线强化学习算法训练一个策略模型，该模型根据当前状态输出最优动作。5) **推理过程**：在推理过程中，根据策略模型的输出动态地生成草稿树，并利用目标模型进行验证。\\n\\n**关键创新**：RADAR的关键创新在于将强化学习引入到推测采样中，实现了草稿模型调用次数的动态调整。与传统的推测采样方法相比，RADAR能够根据实际情况自适应地调整草稿树的深度，从而更有效地利用草稿模型生成的候选token，减少冗余计算。\\n\\n**关键设计**：论文使用离线强化学习算法来训练策略模型，避免了在线探索带来的高成本。具体来说，作者首先收集大量的草稿树生成数据，然后使用这些数据来训练一个Q函数，该Q函数用于评估不同状态-动作对的价值。在推理过程中，策略模型根据Q函数的输出选择最优动作。奖励函数的设计至关重要，作者设计了一个综合考虑准确性和效率的奖励函数，以平衡生成准确token和减少计算开销之间的关系。",
            "application_zh": "RADAR具有广泛的应用前景，可用于加速各种基于大型语言模型的应用，例如文本生成、机器翻译、对话系统等。通过提高推理效率，RADAR可以降低部署和运行大型语言模型的成本，使其更容易被广泛应用。此外，RADAR的动态草稿树生成方法也可以应用于其他需要进行序列决策的任务中。",
            "highlight_zh": "实验结果表明，RADAR在三个不同的LLM（包括LLaMA-7B、LLaMA-13B和GPT-2）和四个不同的任务上均取得了显著的加速效果。相对于自回归解码基线，RADAR实现了3.17倍到4.82倍的加速。这些结果表明，RADAR能够有效地减少冗余计算，提高推理效率。",
            "tags_zh": [
                "大语言模型",
                "推理加速",
                "推测采样",
                "强化学习",
                "动态草稿树"
            ],
            "_index": 53,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14069/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14069/x3.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14069/x2.png",
                    "caption": "",
                    "figure_id": "img_2"
                }
            ]
        },
        {
            "title": "HydroGEM: A Self Supervised Zero Shot Hybrid TCN Transformer Foundation Model for Continental Scale Streamflow Quality Control",
            "authors": [
                "Ijaz Ul Haq",
                "Byung Suk Lee",
                "Julia N. Perdrial",
                "David Baude"
            ],
            "arxiv_id": "2512.14106",
            "summary": "Real-time streamflow monitoring networks generate millions of observations annually, yet maintaining data quality across thousands of remote sensors remains labor-intensive. We introduce HydroGEM (Hydrological Generalizable Encoder for Monitoring), a foundation model for continental-scale streamflow quality control. HydroGEM uses two-stage training: self-supervised pretraining on 6.03 million sequences from 3,724 USGS stations learns hydrological representations, followed by fine-tuning with synthetic anomalies for detection and reconstruction. A hybrid TCN-Transformer architecture (14.2M parameters) captures local temporal patterns and long-range dependencies, while hierarchical normalization handles six orders of magnitude in discharge. On held-out synthetic tests comprising 799 stations with 18 expert-validated anomaly types, HydroGEM achieves F1 = 0.792 for detection and 68.7% reconstruction-error reduction, a 36.3% improvement over existing methods. Zero-shot transfer to 100 Environment and Climate Change Canada stations yields F1 = 0.586, exceeding all baselines and demonstrating cross-national generalization. The model maintains consistent detection across correction magnitudes and aligns with operational seasonal patterns. HydroGEM is designed for human-in-the-loop workflows - outputs are quality control suggestions requiring expert review, not autonomous corrections.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14106",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]foundation model",
                        "zero-shot transfer"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "HydroGEM：用于洲际尺度流量质量控制的自监督零样本混合TCN-Transformer基础模型",
            "summary_zh": "实时流量监测网络每年产生数百万条观测数据，但维护数千个远程传感器的数据质量仍然非常耗费人力。我们提出了HydroGEM（用于监测的水文可泛化编码器），这是一个用于洲际尺度流量质量控制的基础模型。HydroGEM使用两阶段训练：在来自3724个美国地质调查局站点的603万个序列上进行自监督预训练，以学习水文表示，然后使用合成异常进行微调，以进行检测和重建。混合TCN-Transformer架构（1420万个参数）捕获局部时间模式和长期依赖关系，而分层归一化处理六个数量级的流量。在包含799个站点和18种专家验证的异常类型的保留合成测试中，HydroGEM在检测方面实现了F1 = 0.792，重建误差降低了68.7％，比现有方法提高了36.3％。零样本迁移到100个加拿大环境与气候变化部站点，产生F1 = 0.586，超过了所有基线，并证明了跨国泛化能力。该模型在校正幅度上保持一致的检测，并与运营季节性模式保持一致。HydroGEM专为人工参与的工作流程而设计——输出是需要专家审查的质量控制建议，而不是自主校正。",
            "intro_zh": [
                "现有流量监测网络数据质量维护依赖人工，成本高昂，缺乏自动化手段。",
                "HydroGEM通过自监督学习水文表征，并利用混合TCN-Transformer架构捕获时间依赖关系，实现流量质量控制。",
                "实验表明，HydroGEM在流量异常检测和重建方面显著优于现有方法，并具备跨国泛化能力。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大规模流量监测网络中数据质量控制的问题。现有方法依赖人工，效率低下且成本高昂。缺乏能够自动检测和纠正流量数据异常的模型，尤其是在跨区域和跨国界的情况下。\\n\\n**核心思路**：论文的核心思路是利用自监督学习方法，从大量的无标签流量数据中学习水文表征。然后，通过在合成异常数据上进行微调，使模型能够检测和重建真实的流量异常。混合TCN-Transformer架构旨在同时捕获局部时间模式和长期依赖关系，从而提高异常检测的准确性。\\n\\n**技术框架**：HydroGEM的整体框架包含两个主要阶段：1) 自监督预训练阶段：使用大量的USGS流量数据进行预训练，学习水文表征。2) 微调阶段：使用合成的流量异常数据进行微调，提高模型对异常的检测和重建能力。模型的核心是一个混合TCN-Transformer架构，用于提取流量数据的时间特征。\\n\\n**关键创新**：HydroGEM的关键创新点在于：1) 提出了一个用于流量质量控制的自监督基础模型。2) 使用混合TCN-Transformer架构，能够同时捕获局部和全局的时间依赖关系。3) 采用分层归一化方法，处理不同站点流量数据量级差异大的问题。4) 实现了零样本跨国迁移，无需目标域数据进行训练。\\n\\n**关键设计**：HydroGEM使用了混合TCN-Transformer架构，其中TCN用于捕获局部时间模式，Transformer用于捕获长期依赖关系。分层归一化用于处理不同站点流量数据量级差异大的问题。损失函数包括检测损失和重建损失，用于优化模型的异常检测和重建能力。模型参数量为1420万。",
            "application_zh": "HydroGEM可应用于大规模流量监测网络的数据质量控制，提高数据质量和可靠性，减少人工干预，降低维护成本。该模型还可用于水资源管理、洪水预警、气候变化研究等领域，为相关决策提供支持。未来，该模型有望扩展到其他类型的水文数据，例如地下水位、水质等。",
            "highlight_zh": "HydroGEM在合成测试集上实现了F1=0.792的异常检测性能，重建误差降低了68.7%，相比现有方法提升了36.3%。在零样本跨国迁移到加拿大站点时，F1值达到0.586，超过所有基线模型，验证了模型的泛化能力。该模型在不同异常幅度下保持稳定的检测性能，并与实际的季节性模式相符。",
            "tags_zh": [
                "流量质量控制",
                "自监督学习",
                "时间卷积网络",
                "Transformer",
                "水文模型",
                "零样本学习",
                "异常检测"
            ],
            "_index": 54,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14106/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14106/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14106/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Georeferencing complex relative locality descriptions with large language models",
            "authors": [
                "Aneesha Fernando",
                "Surangika Ranathunga",
                "Kristin Stock",
                "Raj Prasanna",
                "Christopher B. Jones"
            ],
            "arxiv_id": "2512.14228",
            "summary": "Georeferencing text documents has typically relied on either gazetteer-based methods to assign geographic coordinates to place names, or on language modelling approaches that associate textual terms with geographic locations. However, many location descriptions specify positions relatively with spatial relationships, making geocoding based solely on place names or geo-indicative words inaccurate. This issue frequently arises in biological specimen collection records, where locations are often described through narratives rather than coordinates if they pre-date GPS. Accurate georeferencing is vital for biodiversity studies, yet the process remains labour-intensive, leading to a demand for automated georeferencing solutions. This paper explores the potential of Large Language Models (LLMs) to georeference complex locality descriptions automatically, focusing on the biodiversity collections domain. We first identified effective prompting patterns, then fine-tuned an LLM using Quantized Low-Rank Adaptation (QLoRA) on biodiversity datasets from multiple regions and languages. Our approach outperforms existing baselines with an average, across datasets, of 65% of records within a 10 km radius, for a fixed amount of training data. The best results (New York state) were 85% within 10km and 67% within 1km. The selected LLM performs well for lengthy, complex descriptions, highlighting its potential for georeferencing intricate locality descriptions.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14228",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱七：动作重定向 (Motion Retargeting)",
                    "id": "7_retargeting",
                    "matched_keywords": [
                        "spatial relationship"
                    ],
                    "score": 3.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "7_retargeting",
                "9_embodied_foundation"
            ],
            "headline_zh": "利用大型语言模型解决生物多样性领域复杂相对位置描述的地理定位问题",
            "summary_zh": "地理定位文本通常依赖于地名词典方法或语言建模方法，前者将地理坐标分配给地名，后者将文本术语与地理位置相关联。然而，许多位置描述通过空间关系相对地指定位置，使得仅基于地名或地理指示词的地理编码不准确。生物标本采集记录中经常出现这个问题，因为早于GPS时代的位置通常通过叙述而非坐标描述。准确的地理定位对于生物多样性研究至关重要，但该过程仍然是劳动密集型的，因此需要自动化的地理定位解决方案。本文探讨了大型语言模型（LLM）自动地理定位复杂位置描述的潜力，重点关注生物多样性收藏领域。我们首先确定了有效的提示模式，然后使用量化低秩适应（QLoRA）在来自多个地区和语言的生物多样性数据集上微调LLM。我们的方法优于现有基线，对于固定数量的训练数据，平均而言，跨数据集有65%的记录位于10公里半径内。最佳结果（纽约州）为85%在10公里内，67%在1公里内。所选的LLM对于冗长、复杂的描述表现良好，突出了其地理定位复杂位置描述的潜力。",
            "intro_zh": [
                "现有地理定位方法难以处理基于空间关系的复杂相对位置描述，尤其是在生物多样性标本记录等领域。",
                "该论文提出利用大型语言模型（LLM）理解和处理复杂的位置描述，实现自动地理定位。",
                "通过QLoRA微调LLM，在生物多样性数据集上取得了显著的性能提升，优于现有基线方法。"
            ],
            "method_zh": "**问题定义**：论文旨在解决生物多样性领域中，由于历史原因或缺乏精确GPS数据，标本采集记录中存在大量复杂、相对的位置描述，导致传统地理定位方法失效的问题。现有方法依赖于地名词典或简单的语言模型，无法有效理解和处理这些复杂的空间关系描述，人工地理定位耗时耗力。\\n\\n**核心思路**：论文的核心思路是利用大型语言模型（LLM）强大的语言理解和推理能力，将复杂的位置描述转化为地理坐标。LLM能够学习和理解文本中蕴含的空间关系，从而更准确地推断出位置信息。通过微调LLM，使其适应生物多样性领域的特定语言和描述习惯，进一步提高地理定位的准确性。\\n\\n**技术框架**：整体框架包括以下几个阶段：1) 数据准备：收集和整理包含复杂位置描述的生物多样性数据集。2) 提示工程：设计有效的提示模式，引导LLM理解和生成地理坐标。3) 模型微调：使用量化低秩适应（QLoRA）方法，在预训练的LLM上进行微调，使其适应特定领域的数据。4) 评估：使用距离误差等指标评估模型的地理定位准确性。\\n\\n**关键创新**：该论文的关键创新在于将大型语言模型应用于复杂相对位置描述的地理定位问题，并探索了有效的提示模式和微调策略。与传统方法相比，LLM能够更好地理解和处理自然语言描述中的空间关系，从而提高地理定位的准确性。QLoRA的使用降低了微调LLM的计算成本。\\n\\n**关键设计**：论文中使用了量化低秩适应（QLoRA）方法进行模型微调，这是一种参数高效的微调技术，可以在资源有限的情况下对大型语言模型进行微调。具体的提示模式设计和损失函数选择等细节在论文中未详细说明，属于未知信息。",
            "application_zh": "该研究成果可应用于生物多样性保护、生态学研究、历史地理学等领域。通过自动地理定位生物标本采集记录，可以加速生物多样性数据的整合和分析，为物种分布建模、气候变化影响评估等研究提供支持。此外，该方法还可以应用于其他包含复杂位置描述的文本数据，例如历史文献、考古报告等。",
            "highlight_zh": "实验结果表明，该方法在生物多样性数据集上优于现有基线方法，平均而言，跨数据集有65%的记录位于10公里半径内。在纽约州数据集上，最佳结果为85%在10公里内，67%在1公里内。这些结果表明，大型语言模型在处理复杂位置描述方面具有显著的优势。",
            "tags_zh": [
                "地理定位",
                "大型语言模型",
                "生物多样性",
                "位置描述",
                "量化低秩适应"
            ],
            "_index": 55,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14228/figures/1_fig_sample-prompt.jpeg",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14228/figures/2_fig_methodology_overview.jpeg",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14228/figures/3_fig_distance_histogram.jpeg",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Advanced Black-Box Tuning of Large Language Models with Limited API Calls",
            "authors": [
                "Zhikang Xie",
                "Weilin Wan",
                "Peizhu Gong",
                "Weizhong Zhang",
                "Cheng Jin"
            ],
            "arxiv_id": "2511.10210",
            "summary": "Black-box tuning is an emerging paradigm for adapting large language models (LLMs) to better achieve desired behaviors, particularly when direct access to model parameters is unavailable. Current strategies, however, often present a dilemma of suboptimal extremes: either separately train a small proxy model and then use it to shift the predictions of the foundation model, offering notable efficiency but often yielding limited improvement; or making API calls in each tuning iteration to the foundation model, which entails prohibitive computational costs. Therefore, we propose a novel advanced black-box tuning method for LLMs with limited API calls. Our core strategy involves training a Gaussian Process (GP) surrogate model with \"LogitMap Pairs\" derived from querying the foundation model on a minimal but highly informative training subset. This surrogate can approximate the outputs of the foundation model to guide the training of the proxy model, thereby effectively reducing the need for direct queries to the foundation model. Extensive experiments verify that our approach elevates pre-trained language model accuracy from 55.92% to 86.85%, reducing the frequency of API queries to merely 1.38%. This significantly outperforms offline approaches that operate entirely without API access. Notably, our method also achieves comparable or superior accuracy to query-intensive approaches, while significantly reducing API costs. This offers a robust and high-efficiency paradigm for language model adaptation.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2511.10210",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model",
                        "foundation model"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出一种高级黑盒调优方法，以有限API调用高效优化大语言模型。",
            "summary_zh": "黑盒调优是一种新兴范式，用于调整大型语言模型（LLM）以更好地实现期望的行为，尤其是在无法直接访问模型参数时。然而，当前的策略常常面临次优的极端困境：要么单独训练一个小型的代理模型，然后用它来改变基础模型的预测，这种方法效率显著，但改进有限；要么在每个调优迭代中对基础模型进行API调用，这会带来过高的计算成本。因此，我们提出了一种针对LLM的高级黑盒调优方法，该方法限制了API调用次数。我们的核心策略包括训练一个高斯过程（GP）代理模型，该模型使用从基础模型查询获得的“LogitMap Pairs”，这些查询基于一个最小但信息量极高的训练子集。该代理模型可以近似基础模型的输出，从而指导代理模型的训练，有效地减少了对基础模型直接查询的需求。大量实验验证了我们的方法将预训练语言模型的准确率从55.92%提高到86.85%，并将API查询频率降低到仅1.38%。这显著优于完全无需API访问的离线方法。值得注意的是，我们的方法在显著降低API成本的同时，也实现了与查询密集型方法相当或更高的准确率。这为语言模型适配提供了一种稳健且高效的范式。",
            "intro_zh": [
                "现有黑盒调优方法在效率和性能之间存在权衡，要么效率高但提升有限，要么性能好但API调用成本过高。",
                "该论文提出使用高斯过程（GP）代理模型，通过少量API调用学习基础模型的行为，指导代理模型的训练。",
                "实验表明，该方法在显著降低API调用次数的同时，将模型准确率从55.92%提升至86.85%，优于离线方法。"
            ],
            "method_zh": "**问题定义**：现有黑盒调优方法在调整大型语言模型时面临效率和性能的困境。直接对基础模型进行API调用成本高昂，而离线训练代理模型效果有限。因此，需要一种在有限API调用的情况下，有效提升模型性能的黑盒调优方法。\\n\\n**核心思路**：核心思路是利用高斯过程（GP）构建一个代理模型，该模型能够近似基础模型的输出。通过少量但信息量大的API调用，学习基础模型的“LogitMap Pairs”，然后利用这些信息训练GP代理模型。该代理模型随后用于指导代理模型的训练，从而减少对基础模型直接查询的需求。\\n\\n**技术框架**：整体框架包含以下几个主要阶段：1) 使用少量API调用查询基础模型，获取“LogitMap Pairs”；2) 利用“LogitMap Pairs”训练高斯过程（GP）代理模型；3) 使用GP代理模型指导代理模型的训练；4) 使用训练好的代理模型进行预测。\\n\\n**关键创新**：关键创新在于使用高斯过程（GP）作为代理模型，并利用“LogitMap Pairs”进行训练。这种方法能够在少量API调用的情况下，有效地学习基础模型的行为，从而指导代理模型的训练。与现有方法相比，该方法在API调用成本和模型性能之间取得了更好的平衡。\\n\\n**关键设计**：论文中关键的设计包括：如何选择最具信息量的训练子集以减少API调用次数；如何构建和训练高斯过程（GP）代理模型；以及如何利用GP代理模型指导代理模型的训练。具体的参数设置和损失函数等技术细节在论文中进行了详细描述（具体数值未知）。",
            "application_zh": "该研究成果可应用于各种需要对大型语言模型进行定制化调整的场景，例如特定领域的文本生成、对话系统优化、以及模型行为的干预和控制。该方法降低了API调用成本，使得在资源受限的环境下也能高效地进行模型调优，具有广泛的应用前景和实际价值。未来，该方法可以进一步扩展到其他类型的黑盒模型调优任务。",
            "highlight_zh": "实验结果表明，该方法在将预训练语言模型的准确率从55.92%提升到86.85%的同时，将API查询频率降低到仅1.38%。这显著优于完全无需API访问的离线方法，并且在API成本显著降低的情况下，实现了与查询密集型方法相当或更高的准确率。这些结果验证了该方法在黑盒调优方面的有效性和高效性。",
            "tags_zh": [
                "黑盒调优",
                "大语言模型",
                "高斯过程",
                "代理模型",
                "API调用",
                "模型适配",
                "LogitMap Pairs"
            ],
            "_index": 56,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2511.10210/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2511.10210/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2511.10210/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Single-Agent Scaling Fails Multi-Agent Intelligence: Towards Foundation Models with Native Multi-Agent Intelligence",
            "authors": [
                "Shuyue Hu",
                "Haoyang Yan",
                "Yiqun Zhang",
                "Yang Chen",
                "Dongzhan Zhou",
                "Lei Bai"
            ],
            "arxiv_id": "2512.08743",
            "summary": "Foundation models (FMs) are increasingly assuming the role of the ''brain'' of AI agents. While recent efforts have begun to equip FMs with native single-agent abilities -- such as GUI interaction or integrated tool use -- we argue that the next frontier is endowing FMs with native multi-agent intelligence. We identify four core capabilities of FMs in multi-agent contexts: understanding, planning, efficient communication, and adaptation. Contrary to assumptions about the spontaneous emergence of such abilities, we provide extensive empirical evidence, across 41 large language models and 7 challenging benchmarks, showing that scaling single-agent performance alone does not automatically yield robust multi-agent intelligence. To address this gap, we outline key research directions -- spanning dataset construction, evaluation, training paradigms, and safety considerations -- for building FMs with native multi-agent intelligence.",
            "categories": [
                "cs.AI",
                "cs.MA"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.08743",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "[T]foundation model"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "揭示单智能体扩展无法实现多智能体智能，提出原生多智能体智能基础模型",
            "summary_zh": "基础模型（FMs）正日益成为人工智能体的“大脑”。虽然最近的研究开始赋予FMs原生的单智能体能力，例如GUI交互或集成工具使用，但我们认为下一个前沿是赋予FMs原生的多智能体智能。我们确定了FMs在多智能体环境中的四个核心能力：理解、规划、高效沟通和适应。与关于这些能力自发涌现的假设相反，我们提供了广泛的经验证据，涵盖41个大型语言模型和7个具有挑战性的基准测试，表明仅扩展单智能体性能并不能自动产生强大的多智能体智能。为了弥补这一差距，我们概述了构建具有原生多智能体智能的FMs的关键研究方向，包括数据集构建、评估、训练范式和安全考虑。",
            "intro_zh": [
                "现有基础模型主要关注单智能体能力，忽略了多智能体环境下的核心能力，如理解、规划、沟通和适应。",
                "论文核心思想是，单智能体性能的提升并不自然转化为强大的多智能体智能，需要专门设计和训练。",
                "通过对41个大型语言模型和7个基准测试的广泛实验，验证了单智能体扩展在多智能体任务中的局限性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决现有基础模型在多智能体环境中表现不足的问题。现有方法主要关注单智能体能力的提升，而忽略了多智能体协作所需的理解、规划、高效沟通和适应等关键能力。单智能体性能的提升并不能直接转化为多智能体智能，这限制了基础模型在复杂协作场景中的应用。\\n\\n**核心思路**：论文的核心思路是，需要专门设计和训练基础模型，使其具备原生的多智能体智能。这意味着需要从数据集构建、评估、训练范式和安全考虑等方面进行全面改进，以弥补单智能体扩展的不足。论文强调，多智能体智能并非单智能体智能的自然涌现，而需要有针对性的方法。\\n\\n**技术框架**：论文并未提出一个具体的模型架构，而是提出了一个研究框架，包含以下几个关键模块：1) **数据集构建**：设计包含多智能体交互场景的数据集，用于训练模型。2) **评估指标**：开发能够衡量多智能体智能的评估指标，例如协作效率、沟通质量等。3) **训练范式**：探索适合多智能体学习的训练方法，例如强化学习、自监督学习等。4) **安全考虑**：关注多智能体系统中的安全问题，例如避免恶意行为、确保公平性等。\\n\\n**关键创新**：论文最重要的创新点在于，它明确指出了单智能体扩展无法实现多智能体智能，并提出了构建原生多智能体智能基础模型的研究方向。这与现有研究主要关注单智能体能力提升的趋势形成了鲜明对比。论文强调了多智能体智能的独特性和重要性，为未来的研究指明了方向。\\n\\n**关键设计**：论文并未提供具体的模型设计细节，而是提出了构建多智能体智能基础模型需要考虑的关键因素，包括数据集的设计、评估指标的选择、训练范式的探索以及安全问题的关注。这些因素将直接影响模型的性能和可靠性。未来的研究需要根据具体的应用场景和任务需求，对这些因素进行精细的设计和优化。",
            "application_zh": "该研究成果可应用于机器人协作、自动驾驶、智能交通、智能制造、多智能体游戏等领域。通过构建具有原生多智能体智能的基础模型，可以实现更高效、更智能的协作系统，提高生产效率，改善用户体验，并解决复杂现实世界问题。未来的影响包括更智能的自动化系统、更安全的协作环境和更强大的问题解决能力。",
            "highlight_zh": "论文通过对41个大型语言模型和7个具有挑战性的基准测试的实验，证明了单智能体性能的提升并不能自动转化为强大的多智能体智能。实验结果表明，现有基础模型在多智能体任务中的表现远低于预期，这突显了构建原生多智能体智能基础模型的必要性。具体的性能数据和对比基线在论文中进行了详细展示。",
            "tags_zh": [
                "多智能体智能",
                "基础模型",
                "大型语言模型",
                "智能体协作",
                "强化学习"
            ],
            "_index": 57,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "TIBSTC-CoT: A Multi-Domain Instruction Dataset for Chain-of-Thought Reasoning in Language Models",
            "authors": [
                "Fan Gao",
                "Cheng Huang",
                "Nyima Tashi",
                "Yutong Liu",
                "Xiangxiang Wang",
                "Thupten Tsering",
                "Ban Ma-bao",
                "Renzeg Duojie",
                "Gadeng Luosang",
                "Rinchen Dongrub",
                "Dorje Tashi",
                "Xiao Feng",
                "Hao Wang",
                "Yongbin Yu"
            ],
            "arxiv_id": "2508.01977",
            "summary": "To address the severe data scarcity in Tibetan, a low-resource language spoken by over six million people, we introduce TIBSTC-CoT, the large-scale, multi-domain Tibetan dataset automatically constructed via chain-of-thought prompting with large language models (LLMs). TIBSTC-CoT establishes a scalable and reproducible framework for dataset creation in low-resource settings, covering diverse domains and reasoning patterns essential for language understanding and generation. Building on this dataset, we develop the Sunshine-thinking LLM family, a series of Tibetan-centric LLMs equipped with chain-of-thought capabilities. Trained entirely on TIBSTC-CoT, Sunshine-thinking has demonstrated strong reasoning and generation performance, comparable to state-of-the-art (SOTA) multilingual LLMs. Our work marks a significant step toward inclusive AI by enabling high-quality Tibetan language processing through both resource creation and model innovation. All data are available:this https URL.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2508.01977",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "[T]chain-of-thought"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出TIBSTC-CoT藏语数据集，并训练Sunshine-thinking系列LLM，提升低资源藏语的CoT推理能力。",
            "summary_zh": "为了解决藏语（一种拥有超过六百万使用者的低资源语言）中严重的数据稀缺问题，我们推出了TIBSTC-CoT，这是一个大规模、多领域的藏语数据集，它通过大型语言模型（LLM）的思维链提示自动构建。TIBSTC-CoT为低资源环境下的数据集创建建立了一个可扩展和可复现的框架，涵盖了语言理解和生成所必需的各种领域和推理模式。基于此数据集，我们开发了Sunshine-thinking LLM系列，这是一系列以藏语为中心的、具备思维链能力的LLM。Sunshine-thinking完全在TIBSTC-CoT上训练，已经展示出强大的推理和生成性能，可与最先进（SOTA）的多语言LLM相媲美。我们的工作通过资源创建和模型创新，为实现包容性人工智能迈出了重要一步，从而实现了高质量的藏语语言处理。所有数据均可用。",
            "intro_zh": [
                "藏语作为低资源语言，面临数据稀缺的挑战，阻碍了藏语自然语言处理技术的发展。",
                "论文提出利用大型语言模型（LLM）的思维链提示，自动构建大规模多领域的藏语数据集TIBSTC-CoT。",
                "基于TIBSTC-CoT训练的Sunshine-thinking LLM系列，在推理和生成性能上可与SOTA多语言LLM媲美。"
            ],
            "method_zh": "**问题定义**：论文旨在解决低资源语言（特别是藏语）数据稀缺的问题，这限制了大型语言模型在藏语环境下的应用，尤其是在需要复杂推理的任务中。现有方法要么依赖少量人工标注数据，要么直接使用其他语言的模型进行迁移，效果不佳。缺乏大规模、高质量的藏语数据集是主要痛点。\\n\\n**核心思路**：论文的核心思路是利用大型语言模型（LLM）的强大生成能力，通过思维链（Chain-of-Thought, CoT）提示自动生成大规模的藏语数据集。CoT提示能够引导LLM逐步推理，生成包含中间推理步骤的文本，从而提高数据的质量和多样性。这种方法避免了大量的人工标注工作，降低了数据获取的成本。\\n\\n**技术框架**：整体框架包括以下几个主要阶段：1) 确定数据集的领域和任务类型；2) 设计合适的CoT提示模板，引导LLM生成包含推理步骤的藏语文本；3) 使用LLM进行数据生成，得到初始的TIBSTC-CoT数据集；4) 对生成的数据进行清洗和过滤，去除低质量或不符合要求的样本；5) 使用TIBSTC-CoT数据集训练Sunshine-thinking LLM系列。\\n\\n**关键创新**：论文的关键创新在于提出了一种可扩展和可复现的低资源语言数据集自动构建框架。该框架利用CoT提示，有效地利用了现有LLM的知识，生成了高质量的藏语数据集。此外，论文还提出了Sunshine-thinking LLM系列，证明了该数据集的有效性。与现有方法相比，该方法能够以较低的成本获取大规模的藏语数据，并显著提升藏语LLM的性能。\\n\\n**关键设计**：CoT提示模板的设计是关键。论文可能针对不同的领域和任务类型，设计了不同的提示模板，以引导LLM生成符合要求的推理过程。具体参数设置和损失函数等技术细节在摘要中未提及，属于未知信息。网络结构也属于未知信息。",
            "application_zh": "该研究成果可应用于藏语信息处理的多个领域，如机器翻译、智能问答、文本摘要、情感分析等。通过提升藏语LLM的性能，可以促进藏语文化传承和信息交流，为藏族人民提供更便捷的智能化服务。未来，该方法可以推广到其他低资源语言，助力实现更包容的人工智能。",
            "highlight_zh": "论文构建了大规模多领域的藏语数据集TIBSTC-CoT，并基于此数据集训练了Sunshine-thinking LLM系列。实验结果表明，Sunshine-thinking LLM在推理和生成性能上可与SOTA多语言LLM媲美，证明了该数据集的有效性和该方法的优越性。具体的性能数据和提升幅度在摘要中未提及，属于未知信息。",
            "tags_zh": [
                "藏语",
                "低资源语言",
                "大型语言模型",
                "思维链",
                "数据集构建"
            ],
            "_index": 58,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2508.01977/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2508.01977/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2508.01977/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Sparse-LaViDa: Sparse Multimodal Discrete Diffusion Language Models",
            "authors": [
                "Shufan Li",
                "Jiuxiang Gu",
                "Kangning Liu",
                "Zhe Lin",
                "Zijun Wei",
                "Aditya Grover",
                "Jason Kuen"
            ],
            "arxiv_id": "2512.14008",
            "summary": "Masked Discrete Diffusion Models (MDMs) have achieved strong performance across a wide range of multimodal tasks, including image understanding, generation, and editing. However, their inference speed remains suboptimal due to the need to repeatedly process redundant masked tokens at every sampling step. In this work, we propose Sparse-LaViDa, a novel modeling framework that dynamically truncates unnecessary masked tokens at each inference step to accelerate MDM sampling. To preserve generation quality, we introduce specialized register tokens that serve as compact representations for the truncated tokens. Furthermore, to ensure consistency between training and inference, we design a specialized attention mask that faithfully matches the truncated sampling procedure during training. Built upon the state-of-the-art unified MDM LaViDa-O, Sparse-LaViDa achieves up to a 2x speedup across diverse tasks including text-to-image generation, image editing, and mathematical reasoning, while maintaining generation quality.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14008",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "MDM"
                    ],
                    "score": 2.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 11.5,
            "hit_pillars": [
                "4_motion_diffusion",
                "9_embodied_foundation"
            ],
            "headline_zh": "Sparse-LaViDa：通过稀疏化采样加速多模态离散扩散语言模型",
            "summary_zh": "本文提出了一种名为Sparse-LaViDa的新建模框架，旨在加速Masked Discrete Diffusion Models (MDMs)的推理过程。MDMs在图像理解、生成和编辑等多种多模态任务中表现出色，但由于需要在每个采样步骤中重复处理冗余的masked tokens，导致推理速度较慢。Sparse-LaViDa通过在每个推理步骤中动态截断不必要的masked tokens来解决这个问题。为了保持生成质量，引入了专门的register tokens，作为被截断tokens的紧凑表示。此外，为了确保训练和推理之间的一致性，设计了一种专门的attention mask，在训练期间忠实地匹配截断的采样过程。基于最先进的统一MDM LaViDa-O，Sparse-LaViDa在文本到图像生成、图像编辑和数学推理等多种任务中实现了高达2倍的加速，同时保持了生成质量。",
            "intro_zh": [
                "MDM推理速度受限于重复处理冗余的masked tokens。",
                "Sparse-LaViDa动态截断不必要的tokens，并用register tokens保持质量。",
                "特殊attention mask保证训练与推理一致性，加速效果显著。"
            ],
            "method_zh": "**问题定义**：现有的Masked Discrete Diffusion Models (MDMs)虽然在多模态任务中表现出色，但其推理速度较慢。主要原因是需要在每个采样步骤中重复处理大量的masked tokens，这些tokens中有很多是冗余的，不包含有效信息，导致计算资源的浪费。因此，如何减少冗余计算，加速MDM的推理过程是一个重要的研究问题。\\n\\n**核心思路**：Sparse-LaViDa的核心思路是在推理过程中动态地截断那些不必要的masked tokens，从而减少计算量，加速推理过程。为了弥补截断tokens带来的信息损失，引入了register tokens作为被截断tokens的紧凑表示，以保持生成质量。通过这种稀疏化的采样方式，可以在保证生成质量的前提下，显著提高推理速度。\\n\\n**技术框架**：Sparse-LaViDa建立在LaViDa-O模型之上，整体框架仍然是扩散模型的迭代采样过程。主要包含以下几个关键模块：1) Token截断模块：根据某种策略（例如，基于attention score）动态地选择并截断一部分masked tokens。2) Register Token模块：为每个被截断的token集合生成一个register token，用于保留被截断token的信息。3) Attention Mask模块：设计一种特殊的attention mask，在训练过程中模拟推理时的截断过程，保证训练和推理的一致性。\\n\\n**关键创新**：Sparse-LaViDa的关键创新在于动态稀疏化采样和register token的设计。与传统的MDM方法不同，Sparse-LaViDa不是在每个采样步骤中处理所有的masked tokens，而是只处理一部分重要的tokens，从而减少了计算量。Register token的设计保证了在截断tokens的同时，尽可能地保留了被截断tokens的信息，避免了生成质量的下降。\\n\\n**关键设计**：关于token截断模块，一种可能的实现方式是基于attention score进行选择。例如，可以计算每个masked token与其他token之间的平均attention score，然后选择attention score较低的tokens进行截断。Register token可以通过一个小型神经网络来生成，其输入是被截断的tokens的表示，输出是register token的表示。Attention mask的设计需要保证在训练过程中，模型只能看到未被截断的tokens和register tokens，从而模拟推理时的截断过程。",
            "application_zh": "Sparse-LaViDa具有广泛的应用前景，包括但不限于：文本到图像生成、图像编辑、视频生成、3D内容生成、数学推理等。通过加速多模态内容的生成和编辑过程，可以提高生产效率，降低计算成本，并为创意设计提供更多可能性。该研究还有助于推动人工智能在各个领域的应用，例如教育、娱乐、医疗等。",
            "highlight_zh": "Sparse-LaViDa在多种任务上实现了显著的加速效果。在文本到图像生成、图像编辑和数学推理等任务中，Sparse-LaViDa相比于LaViDa-O实现了高达2倍的加速，同时保持了生成质量。这表明Sparse-LaViDa是一种有效的加速MDM推理的方法，具有很强的实用价值。",
            "tags_zh": [
                "多模态扩散模型",
                "稀疏采样",
                "模型加速",
                "图像生成",
                "图像编辑"
            ],
            "_index": 59,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14008/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14008/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14008/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "RAST-MoE-RL: A Regime-Aware Spatio-Temporal MoE Framework for Deep Reinforcement Learning in Ride-Hailing",
            "authors": [
                "Yuhan Tang",
                "Kangxin Cui",
                "Jung Ho Park",
                "Yibo Zhao",
                "Xuan Jiang",
                "Haoze He",
                "Dingyi Zhuang",
                "Shenhao Wang",
                "Jiangbo Yu",
                "Haris Koutsopoulos",
                "Jinhua Zhao"
            ],
            "arxiv_id": "2512.13727",
            "summary": "Ride-hailing platforms face the challenge of balancing passenger waiting times with overall system efficiency under highly uncertain supply-demand conditions. Adaptive delayed matching creates a trade-off between matching and pickup delays by deciding whether to assign drivers immediately or batch requests. Since outcomes accumulate over long horizons with stochastic dynamics, reinforcement learning (RL) is a suitable framework. However, existing approaches often oversimplify traffic dynamics or use shallow encoders that miss complex spatiotemporal patterns.We introduce the Regime-Aware Spatio-Temporal Mixture-of-Experts (RAST-MoE), which formalizes adaptive delayed matching as a regime-aware MDP equipped with a self-attention MoE encoder. Unlike monolithic networks, our experts specialize automatically, improving representation capacity while maintaining computational efficiency. A physics-informed congestion surrogate preserves realistic density-speed feedback, enabling millions of efficient rollouts, while an adaptive reward scheme guards against pathological strategies.With only 12M parameters, our framework outperforms strong baselines. On real-world Uber trajectory data (San Francisco), it improves total reward by over 13%, reducing average matching and pickup delays by 10% and 15% respectively. It demonstrates robustness across unseen demand regimes and stable training. These findings highlight the potential of MoE-enhanced RL for large-scale decision-making with complex spatiotemporal dynamics.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13727",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning",
                        "[T]deep reinforcement learning"
                    ],
                    "score": 9.0
                },
                {
                    "name": "支柱八：物理动画 (Physics-based Animation)",
                    "id": "8_physics_animation",
                    "matched_keywords": [
                        "spatiotemporal"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 11.0,
            "hit_pillars": [
                "2_algo_arch",
                "8_physics_animation"
            ],
            "headline_zh": "提出RAST-MoE-RL框架，解决网约车中复杂时空动态下的自适应延迟匹配问题。",
            "summary_zh": "网约车平台面临在高度不确定的供需条件下平衡乘客等待时间和整体系统效率的挑战。自适应延迟匹配通过决定立即分配司机或批量处理请求，从而在匹配延迟和接载延迟之间进行权衡。由于结果会在具有随机动态的长时程中累积，因此强化学习(RL)是一个合适的框架。然而，现有的方法通常过度简化交通动态或使用浅层编码器，从而错失了复杂的时空模式。我们引入了Regime-Aware Spatio-Temporal Mixture-of-Experts (RAST-MoE)，它将自适应延迟匹配形式化为一个配备了自注意力MoE编码器的regime-aware MDP。与单体网络不同，我们的专家可以自动专门化，从而提高表示能力，同时保持计算效率。一个物理信息驱动的拥塞代理保留了真实的密度-速度反馈，从而能够进行数百万次高效的rollout，而自适应奖励方案则可以防止病态策略。我们的框架仅使用12M参数，就优于强大的基线。在真实的Uber轨迹数据（旧金山）上，它将总奖励提高了13%以上，并将平均匹配和接载延迟分别降低了10%和15%。它展示了跨越未见过的需求regime的鲁棒性和稳定的训练。这些发现突出了MoE增强的RL在具有复杂时空动态的大规模决策中的潜力。",
            "intro_zh": [
                "现有网约车调度方法在处理复杂时空动态时存在不足，或过度简化交通模型，或无法有效捕捉时空模式。",
                "RAST-MoE-RL框架通过引入Regime-Aware的MoE编码器，使专家能够自动学习专门化，提升表征能力和计算效率。",
                "实验表明，该框架在真实Uber数据上显著提升了奖励，降低了匹配和接载延迟，并展现了良好的鲁棒性和训练稳定性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决网约车平台中，如何在不确定的供需条件下，通过自适应延迟匹配策略，最小化乘客等待时间和提升系统整体效率的问题。现有方法的痛点在于无法有效建模复杂的时空交通动态，或者使用过于简化的模型导致性能受限。\\n\\n**核心思路**：论文的核心思路是将自适应延迟匹配问题建模为一个regime-aware的马尔可夫决策过程(MDP)，并利用MoE（Mixture-of-Experts）结构来增强对时空状态的表征能力。通过让不同的专家学习不同的交通状态模式，从而提高模型的泛化能力和效率。\\n\\n**技术框架**：RAST-MoE-RL框架包含以下主要模块：1) Regime-Aware MDP：将自适应延迟匹配问题形式化为MDP，并根据不同的交通状态（regime）调整策略。2) 自注意力MoE编码器：使用自注意力机制的MoE结构来编码时空状态信息，不同的专家负责处理不同的状态模式。3) 物理信息拥塞代理：利用物理信息来建模交通拥塞，从而实现更真实的模拟环境。4) 自适应奖励方案：设计奖励函数，鼓励模型学习合理的调度策略，并防止出现病态行为。\\n\\n**关键创新**：该论文的关键创新在于将MoE结构引入到网约车调度的强化学习框架中，并结合regime-aware MDP和物理信息拥塞代理，从而实现了更高效和鲁棒的调度策略。与现有方法的本质区别在于，RAST-MoE-RL能够自动学习和适应不同的交通状态模式，而不需要人工设计复杂的交通模型。\\n\\n**关键设计**：MoE编码器使用自注意力机制来捕捉时空依赖关系。奖励函数的设计考虑了匹配延迟、接载延迟和系统效率等多个因素，并采用自适应策略来调整奖励权重。物理信息拥塞代理利用宏观交通流模型来模拟交通拥塞现象。",
            "application_zh": "该研究成果可应用于实际的网约车平台，提升调度效率，降低乘客等待时间，并提高平台整体的运营效率和用户满意度。此外，该框架的设计思路也可以推广到其他具有复杂时空动态的大规模决策问题，例如物流调度、交通信号控制等。",
            "highlight_zh": "实验结果表明，RAST-MoE-RL框架在真实的Uber轨迹数据（旧金山）上，将总奖励提高了13%以上，并将平均匹配和接载延迟分别降低了10%和15%。该框架仅使用12M参数，就优于其他强大的基线方法，并且展现了跨越未见过的需求regime的鲁棒性和稳定的训练。",
            "tags_zh": [
                "网约车调度",
                "强化学习",
                "混合专家模型",
                "时空建模",
                "自适应延迟匹配"
            ],
            "_index": 60,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13727/image/model.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13727/image/training_testing_comparison_smooth0.6.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.13727/image/combined_expert_and_performance.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Understanding and Improving Hyperbolic Deep Reinforcement Learning",
            "authors": [
                "Timo Klein",
                "Thomas Lang",
                "Andrii Shkabrii",
                "Alexander Sturm",
                "Kevin Sidak",
                "Lukas Miklautz",
                "Claudia Plant",
                "Yllka Velaj",
                "Sebastian Tschiatschek"
            ],
            "arxiv_id": "2512.14202",
            "summary": "The performance of reinforcement learning (RL) agents depends critically on the quality of the underlying feature representations. Hyperbolic feature spaces are well-suited for this purpose, as they naturally capture hierarchical and relational structure often present in complex RL environments. However, leveraging these spaces commonly faces optimization challenges due to the nonstationarity of RL. In this work, we identify key factors that determine the success and failure of training hyperbolic deep RL agents. By analyzing the gradients of core operations in the Poincaré Ball and Hyperboloid models of hyperbolic geometry, we show that large-norm embeddings destabilize gradient-based training, leading to trust-region violations in proximal policy optimization (PPO). Based on these insights, we introduce Hyper++, a new hyperbolic PPO agent that consists of three components: (i) stable critic training through a categorical value loss instead of regression; (ii) feature regularization guaranteeing bounded norms while avoiding the curse of dimensionality from clipping; and (iii) using a more optimization-friendly formulation of hyperbolic network layers. In experiments on ProcGen, we show that Hyper++ guarantees stable learning, outperforms prior hyperbolic agents, and reduces wall-clock time by approximately 30%. On Atari-5 with Double DQN, Hyper++ strongly outperforms Euclidean and hyperbolic baselines. We release our code atthis https URL.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14202",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning",
                        "[T]deep reinforcement learning",
                        "PPO"
                    ],
                    "score": 10.5
                }
            ],
            "relevance_score": 10.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出Hyper++，稳定双曲深度强化学习，提升ProcGen和Atari性能。",
            "summary_zh": "强化学习（RL）智能体的性能严重依赖于底层特征表示的质量。双曲特征空间非常适合此目的，因为它们自然地捕获了复杂RL环境中常见的层级和关系结构。然而，利用这些空间通常面临由于RL的非平稳性带来的优化挑战。在这项工作中，我们确定了决定双曲深度RL智能体训练成功与失败的关键因素。通过分析庞加莱球和双曲面模型中核心操作的梯度，我们表明大范数嵌入会破坏基于梯度的训练，导致近端策略优化（PPO）中的信任域违规。基于这些见解，我们引入了Hyper++，一种新的双曲PPO智能体，它由三个组件组成：（i）通过分类价值损失而非回归实现稳定的评论家训练；（ii）特征正则化，保证有界范数，同时避免了裁剪带来的维度灾难；（iii）使用更优化友好的双曲网络层公式。在ProcGen上的实验表明，Hyper++保证了稳定的学习，优于先前的双曲智能体，并将实际运行时间减少了约30%。在Atari-5上使用Double DQN，Hyper++显著优于欧几里德和双曲基线。我们在此URL发布了我们的代码。",
            "intro_zh": [
                "现有双曲深度强化学习方法在非平稳环境中面临优化挑战，大范数嵌入导致梯度不稳定和信任域违规。",
                "Hyper++通过分类价值损失、特征正则化和优化友好的双曲网络层公式，稳定训练过程，避免维度灾难。",
                "实验表明，Hyper++在ProcGen上保证稳定学习，减少运行时间，并在Atari-5上显著优于欧几里德和双曲基线。"
            ],
            "method_zh": "**问题定义**：论文旨在解决双曲深度强化学习中训练不稳定的问题。现有方法在利用双曲空间的层级结构优势时，容易受到大范数嵌入的影响，导致梯度爆炸或消失，进而破坏策略优化过程的稳定性。特别是在使用PPO等算法时，信任域容易被违反，导致训练崩溃。\\n\\n**核心思路**：论文的核心思路是通过稳定评论家训练、正则化特征范数以及优化双曲网络层公式来解决训练不稳定性问题。通过限制嵌入的范数，避免梯度爆炸，并采用更适合优化的网络结构，从而提高双曲深度强化学习的性能。\\n\\n**技术框架**：Hyper++框架主要包含三个核心模块：(1) 稳定的评论家训练：使用分类价值损失代替回归，避免了回归损失对异常值的敏感性，从而稳定了评论家的训练。(2) 特征正则化：通过正则化项约束特征的范数，防止其过大，从而避免梯度爆炸，同时避免了直接裁剪可能导致的维度灾难。(3) 优化友好的双曲网络层：采用更适合优化的双曲网络层公式，例如使用黎曼梯度下降等方法，提高训练效率。\\n\\n**关键创新**：Hyper++的关键创新在于其综合性的稳定训练方法。它不仅关注了评论家的训练，还通过特征正则化和网络层优化，从多个角度解决了双曲深度强化学习中的训练不稳定性问题。与之前的双曲强化学习方法相比，Hyper++更加注重优化过程的稳定性，从而能够更好地利用双曲空间的优势。\\n\\n**关键设计**：(1) 分类价值损失：将价值函数的回归问题转化为分类问题，使用交叉熵损失函数进行训练。(2) 特征正则化：在损失函数中添加L2正则化项，约束特征的范数。(3) 双曲网络层：使用Poincaré Ball或Hyperboloid模型，并采用黎曼梯度下降等优化方法。",
            "application_zh": "该研究成果可应用于具有层级结构和关系结构的复杂强化学习任务，例如机器人导航、游戏AI、推荐系统等。通过利用双曲空间的优势，可以更有效地学习到环境的抽象表示，从而提高智能体的决策能力和泛化性能。未来，该方法有望在更多实际场景中得到应用，例如自动驾驶、金融交易等。",
            "highlight_zh": "Hyper++在ProcGen环境上实现了稳定的学习，并且相比之前的双曲智能体，运行时间减少了约30%。在Atari-5环境上，Hyper++使用Double DQN算法，显著优于欧几里德和双曲基线方法，表明了其在复杂环境下的优越性能。这些实验结果验证了Hyper++在稳定训练和提升性能方面的有效性。",
            "tags_zh": [
                "双曲强化学习",
                "深度强化学习",
                "庞加莱球",
                "特征表示",
                "近端策略优化",
                "ProcGen",
                "Atari",
                "梯度稳定"
            ],
            "_index": 61,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14202/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14202/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14202/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "PrivORL: Differentially Private Synthetic Dataset for Offline Reinforcement Learning",
            "authors": [
                "Chen Gong",
                "Zheng Liu",
                "Kecen Li",
                "Tianhao Wang"
            ],
            "arxiv_id": "2512.07342",
            "summary": "Recently, offline reinforcement learning (RL) has become a popular RL paradigm. In offline RL, data providers share pre-collected datasets -- either as individual transitions or sequences of transitions forming trajectories -- to enable the training of RL models (also called agents) without direct interaction with the environments. Offline RL saves interactions with environments compared to traditional RL, and has been effective in critical areas, such as navigation tasks. Meanwhile, concerns about privacy leakage from offline RL datasets have emerged.To safeguard private information in offline RL datasets, we propose the first differential privacy (DP) offline dataset synthesis method, PrivORL, which leverages a diffusion model and diffusion transformer to synthesize transitions and trajectories, respectively, under DP. The synthetic dataset can then be securely released for downstream analysis and research. PrivORL adopts the popular approach of pre-training a synthesizer on public datasets, and then fine-tuning on sensitive datasets using DP Stochastic Gradient Descent (DP-SGD). Additionally, PrivORL introduces curiosity-driven pre-training, which uses feedback from the curiosity module to diversify the synthetic dataset and thus can generate diverse synthetic transitions and trajectories that closely resemble the sensitive dataset. Extensive experiments on five sensitive offline RL datasets show that our method achieves better utility and fidelity in both DP transition and trajectory synthesis compared to baselines. The replication package is available at the GitHub repository.",
            "categories": [
                "cs.CR",
                "cs.LG"
            ],
            "primary_category": "cs.CR",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.07342",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning",
                        "offline RL",
                        "[T]offline reinforcement learning"
                    ],
                    "score": 10.5
                }
            ],
            "relevance_score": 10.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "PrivORL：一种差分隐私离线强化学习合成数据集生成方法",
            "summary_zh": "离线强化学习(RL)已成为一种流行的RL范式。在离线RL中，数据提供者共享预先收集的数据集（单个转移或形成轨迹的转移序列），以支持RL模型（也称为智能体）的训练，而无需与环境直接交互。离线RL节省了与环境的交互，并且在导航等关键领域非常有效。与此同时，离线RL数据集中的隐私泄露问题日益突出。为了保护离线RL数据集中的隐私信息，我们提出了第一个差分隐私(DP)离线数据集合成方法PrivORL，它利用扩散模型和扩散Transformer分别在DP下合成转移和轨迹。然后，可以安全地发布合成数据集，用于下游分析和研究。PrivORL采用了一种流行的方法，即在公共数据集上预训练合成器，然后使用DP随机梯度下降(DP-SGD)在敏感数据集上进行微调。此外，PrivORL引入了好奇心驱动的预训练，它利用来自好奇心模块的反馈来多样化合成数据集，从而可以生成与敏感数据集非常相似的各种合成转移和轨迹。在五个敏感离线RL数据集上的大量实验表明，与基线方法相比，我们的方法在DP转移和轨迹合成中都实现了更好的效用和保真度。",
            "intro_zh": [
                "离线强化学习数据集存在隐私泄露风险，需要保护数据集中包含的敏感信息。",
                "PrivORL利用扩散模型和扩散Transformer，在差分隐私保护下合成高质量的转移和轨迹数据。",
                "实验表明，PrivORL在效用性和保真度方面优于现有方法，能够生成更逼真的合成数据集。"
            ],
            "method_zh": "**问题定义**：论文旨在解决离线强化学习中数据集的隐私泄露问题。现有的离线强化学习方法依赖于预先收集的数据集，这些数据集可能包含敏感信息。直接使用这些数据集进行模型训练会带来隐私泄露的风险，因此需要一种方法来生成既能保护隐私又能保留数据集特征的合成数据集。\\n\\n**核心思路**：论文的核心思路是利用差分隐私(DP)技术，结合扩散模型和扩散Transformer，生成既能保护隐私又能保留原始数据集特征的合成数据集。通过在公共数据集上预训练合成器，然后在敏感数据集上进行差分隐私微调，可以有效地平衡隐私保护和数据效用。\\n\\n**技术框架**：PrivORL的整体框架包括以下几个主要阶段：1) 在公共数据集上预训练扩散模型和扩散Transformer；2) 在敏感数据集上使用DP-SGD对预训练模型进行微调；3) 使用微调后的模型生成合成的转移和轨迹数据。其中，扩散模型用于生成单个转移，扩散Transformer用于生成轨迹。\\n\\n**关键创新**：PrivORL的关键创新在于以下几个方面：1) 首次将扩散模型和扩散Transformer应用于差分隐私离线强化学习数据集合成；2) 提出了好奇心驱动的预训练方法，利用好奇心模块的反馈来多样化合成数据集，提高数据质量；3) 实现了在差分隐私保护下生成高质量的转移和轨迹数据，有效平衡了隐私保护和数据效用。\\n\\n**关键设计**：PrivORL的关键设计包括：1) 使用DP-SGD进行微调，以保证差分隐私；2) 设计好奇心模块，鼓励模型探索更多样化的状态空间；3) 使用扩散模型和扩散Transformer分别生成转移和轨迹，充分利用了两种模型的优势；4) 损失函数的设计，旨在最小化合成数据与原始数据之间的差异，同时满足差分隐私约束。",
            "application_zh": "PrivORL可应用于各种需要保护隐私的离线强化学习场景，例如医疗、金融和自动驾驶等领域。通过生成差分隐私的合成数据集，可以安全地共享数据，促进算法研究和模型训练，同时避免敏感信息的泄露。该方法有助于推动离线强化学习在隐私敏感领域的应用。",
            "highlight_zh": "实验结果表明，PrivORL在五个敏感离线RL数据集上取得了显著的性能提升。与基线方法相比，PrivORL在DP转移和轨迹合成中都实现了更好的效用和保真度。具体来说，PrivORL能够生成更逼真的合成数据集，使得在合成数据集上训练的RL智能体能够获得与在原始数据集上训练的智能体相近的性能。",
            "tags_zh": [
                "离线强化学习",
                "差分隐私",
                "数据集合成",
                "扩散模型",
                "扩散Transformer",
                "隐私保护",
                "数据效用"
            ],
            "_index": 62,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.07342/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.07342/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.07342/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "PentestEval: Benchmarking LLM-based Penetration Testing with Modular and Stage-Level Design",
            "authors": [
                "Ruozhao Yang",
                "Mingfei Cheng",
                "Gelei Deng",
                "Tianwei Zhang",
                "Junjie Wang",
                "Xiaofei Xie"
            ],
            "arxiv_id": "2512.14233",
            "summary": "Penetration testing is essential for assessing and strengthening system security against real-world threats, yet traditional workflows remain highly manual, expertise-intensive, and difficult to scale. Although recent advances in Large Language Models (LLMs) offer promising opportunities for automation, existing applications rely on simplistic prompting without task decomposition or domain adaptation, resulting in unreliable black-box behavior and limited insight into model capabilities across penetration testing stages. To address this gap, we introduce PentestEval, the first comprehensive benchmark for evaluating LLMs across six decomposed penetration testing stages: Information Collection, Weakness Gathering and Filtering, Attack Decision-Making, Exploit Generation and Revision. PentestEval integrates expert-annotated ground truth with a fully automated evaluation pipeline across 346 tasks covering all stages in 12 realistic vulnerable scenarios. Our stage-level evaluation of 9 widely used LLMs reveals generally weak performance and distinct limitations across the stages of penetration-testing workflow. End-to-end pipelines reach only 31% success rate, and existing LLM-powered systems such as PentestGPT, PentestAgent, and VulnBot exhibit similar limitations, with autonomous agents failing almost entirely. These findings highlight that autonomous penetration testing demands stronger structured reasoning, where modularization enhances each individual stage and improves overall performance. PentestEval provides the foundational benchmark needed for future research on fine-grained, stage-level evaluation, paving the way toward more reliable LLM-based automation.",
            "categories": [
                "cs.SE",
                "cs.AI",
                "cs.CR"
            ],
            "primary_category": "cs.SE",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14233",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "[T]penetration"
                    ],
                    "score": 7.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 10.5,
            "hit_pillars": [
                "4_motion_diffusion",
                "9_embodied_foundation"
            ],
            "headline_zh": "PentestEval：首个模块化、分阶段评估LLM渗透测试能力的综合基准",
            "summary_zh": "渗透测试对于评估和加强系统安全性至关重要，但传统工作流程仍然高度依赖手动操作、专业知识，并且难以扩展。虽然大型语言模型（LLM）的最新进展为自动化提供了有希望的机会，但现有应用依赖于简单的提示，缺乏任务分解或领域自适应，导致不可靠的黑盒行为，并且对模型在渗透测试各个阶段的能力的洞察有限。为了解决这个问题，我们推出了PentestEval，这是第一个全面的基准，用于评估LLM在六个分解的渗透测试阶段的能力：信息收集、弱点收集和过滤、攻击决策、漏洞利用生成和修改。PentestEval集成了专家注释的真实数据，以及一个完全自动化的评估流程，涵盖12个现实的脆弱场景中的346个任务。我们对9个广泛使用的LLM进行的阶段性评估显示，总体性能较弱，并且在渗透测试工作流程的各个阶段存在明显的局限性。端到端管道的成功率仅为31%，现有的LLM驱动系统（如PentestGPT、PentestAgent和VulnBot）也表现出类似的局限性，自主代理几乎完全失败。这些发现表明，自主渗透测试需要更强的结构化推理，其中模块化增强了每个单独的阶段并提高了整体性能。PentestEval为未来关于细粒度、阶段性评估的研究提供了基础基准，为更可靠的基于LLM的自动化铺平了道路。",
            "intro_zh": [
                "传统渗透测试流程依赖人工，效率低且成本高，LLM有潜力实现自动化，但现有方法缺乏细致的任务分解和领域适配。",
                "PentestEval通过模块化设计，将渗透测试分解为六个阶段，并构建自动化评估流程，从而更全面地评估LLM在各阶段的能力。",
                "实验结果表明，现有LLM在渗透测试任务中表现不佳，端到端成功率低，表明需要更强的结构化推理和模块化设计。"
            ],
            "method_zh": "**问题定义**：现有渗透测试流程高度依赖人工，效率低下且难以扩展。虽然LLM有潜力实现自动化，但现有方法通常采用简单的prompting方式，缺乏对渗透测试任务的细致分解和领域知识的有效利用，导致LLM在渗透测试中的表现不稳定且难以解释。因此，需要一个更细粒度的评估框架，以深入了解LLM在渗透测试各个阶段的能力，并指导LLM在渗透测试中的应用。\n\\n**核心思路**：PentestEval的核心思路是将渗透测试流程分解为六个关键阶段：信息收集、弱点收集与过滤、攻击决策、漏洞利用生成与修改。通过对每个阶段进行独立评估，可以更清晰地了解LLM在不同任务中的表现，从而发现其优势和不足。此外，PentestEval还集成了专家标注的ground truth，用于评估LLM生成的答案的准确性。\n\\n**技术框架**：PentestEval包含以下主要模块：(1) 脆弱场景库：包含12个现实的脆弱场景，涵盖各种常见的安全漏洞。(2) 任务生成器：根据脆弱场景生成346个渗透测试任务，覆盖六个阶段。(3) LLM接口：提供统一的接口，方便集成不同的LLM。(4) 评估引擎：根据专家标注的ground truth，自动评估LLM生成的答案的准确性。(5) 报告生成器：生成详细的评估报告，展示LLM在各个阶段的表现。\n\\n**关键创新**：PentestEval的主要创新在于其模块化和分阶段的设计。与以往的黑盒评估方法不同，PentestEval将渗透测试流程分解为多个阶段，并对每个阶段进行独立评估。这种设计可以更清晰地了解LLM在不同任务中的表现，从而发现其优势和不足。此外，PentestEval还集成了专家标注的ground truth，用于评估LLM生成的答案的准确性。\n\\n**关键设计**：PentestEval的关键设计包括：(1) 阶段划分：将渗透测试流程划分为六个阶段，每个阶段对应不同的任务。(2) 任务生成：根据脆弱场景生成多样化的渗透测试任务，覆盖各种常见的安全漏洞。(3) 评估指标：采用多种评估指标，包括准确率、召回率、F1值等，全面评估LLM的表现。(4) 自动化评估流程：构建全自动化的评估流程，减少人工干预，提高评估效率。",
            "application_zh": "PentestEval可用于评估和比较不同LLM在渗透测试任务中的能力，帮助安全研究人员选择合适的LLM进行自动化渗透测试。此外，PentestEval还可以用于指导LLM在渗透测试中的应用，例如通过优化prompting策略或引入领域知识，提高LLM在特定阶段的表现。该基准的建立将促进基于LLM的自动化渗透测试技术的发展，提高系统安全性。",
            "highlight_zh": "PentestEval对9个广泛使用的LLM进行了阶段性评估，结果表明，现有LLM在渗透测试任务中表现普遍较弱，端到端管道的成功率仅为31%。现有的LLM驱动系统（如PentestGPT、PentestAgent和VulnBot）也表现出类似的局限性，自主代理几乎完全失败。这些结果表明，需要更强的结构化推理和模块化设计来提高LLM在渗透测试中的表现。",
            "tags_zh": [
                "渗透测试",
                "大型语言模型",
                "基准测试",
                "自动化",
                "安全漏洞"
            ],
            "_index": 63,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14233/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14233/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14233/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Developing Large Language Models for Clinical Research Using One Million Clinical Trials",
            "authors": [
                "Zifeng Wang",
                "Jiacheng Lin",
                "Qiao Jin",
                "Junyi Gao",
                "Jathurshan Pradeepkumar",
                "Pengcheng Jiang",
                "Zhiyong Lu",
                "Jimeng Sun"
            ],
            "arxiv_id": "2505.16097",
            "summary": "Developing artificial intelligence (AI) for clinical research requires a comprehensive data foundation that supports model training and rigorous evaluation. Here, we introduce TrialPanorama, a large-scale structured resource that aggregates 1.6M clinical trial records from fifteen global registries and links them with biomedical ontologies and associated literature. To demonstrate its utility, we build a pipeline that constructs 152K training and testing samples for eight key clinical research tasks. Three tasks support systematic review workflows, including study search, study screening, and evidence summarization. Five tasks focus on trial design and optimization, including arm design, eligibility criteria design, endpoint selection, sample size estimation, and trial completion assessment and rationalization. Benchmarking cutting-edge large language models (LLMs) reveals that generic LLMs have limited capability in clinical reasoning. In contrast, an 8B LLM we developed on TrialPanorama using supervised finetuning and reinforcement learning wins over the 70B generic counterparts in all eight tasks, with a relative improvement of 73.7%, 67.6%, 38.4%, 37.8%, 26.5%, 20.7%, 20.0%, 18.1%, and 5.2%, respectively. We envision that TrialPanorama provides a solid foundation for future scaling of AI for clinical research.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2505.16097",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 10.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "TrialPanorama：构建百万级临床试验数据集，提升LLM在临床研究任务中的性能",
            "summary_zh": "本文介绍了一个名为TrialPanorama的大规模结构化资源，它汇集了来自15个全球注册机构的160万条临床试验记录，并将它们与生物医学本体和相关文献联系起来。为了展示其效用，作者构建了一个pipeline，为八个关键临床研究任务构建了15.2万个训练和测试样本。这些任务包括支持系统评价工作流程（研究搜索、研究筛选和证据总结）以及关注试验设计和优化（臂设计、纳入标准设计、终点选择、样本量估计以及试验完成评估和合理化）。对先进大型语言模型（LLM）的基准测试表明，通用LLM在临床推理方面的能力有限。相比之下，作者在TrialPanorama上使用监督微调和强化学习开发的8B LLM在所有八个任务中都优于70B的通用LLM，相对改进分别为73.7%、67.6%、38.4%、37.8%、26.5%、20.7%、20.0%、18.1%和5.2%。TrialPanorama为未来扩展临床研究AI提供了坚实的基础。",
            "intro_zh": [
                "现有通用LLM在临床推理方面能力有限，难以满足临床研究的特定需求。",
                "论文构建TrialPanorama数据集，并在此基础上微调LLM，以提升其在临床研究任务中的性能。",
                "实验结果表明，基于TrialPanorama训练的8B LLM在多个临床研究任务上显著优于通用LLM。"
            ],
            "method_zh": "**问题定义**：现有的大型语言模型在处理临床研究任务时，由于缺乏针对性的训练数据和领域知识，表现出临床推理能力不足的问题。这限制了它们在临床研究中的应用，例如系统评价、试验设计和优化等。\n\n**核心思路**：论文的核心思路是构建一个大规模的、结构化的临床试验数据集TrialPanorama，并利用该数据集对LLM进行微调，使其能够更好地理解和处理临床研究相关的任务。通过监督微调和强化学习，使模型学习到特定领域的知识和推理能力。\n\n**技术框架**：该研究的技术框架主要包括以下几个步骤：1) 数据收集与整合：从15个全球临床试验注册机构收集数据，并进行清洗和整合。2) 数据结构化：将临床试验数据与生物医学本体和相关文献进行链接，构建结构化的TrialPanorama数据集。3) 任务构建：基于TrialPanorama数据集，构建八个关键临床研究任务的训练和测试样本。4) 模型训练与评估：使用监督微调和强化学习在TrialPanorama数据集上训练LLM，并在八个任务上进行评估。\n\n**关键创新**：该研究的关键创新在于构建了TrialPanorama数据集，这是一个大规模的、结构化的临床试验资源，为LLM在临床研究领域的应用提供了数据基础。此外，通过监督微调和强化学习，有效地提升了LLM在临床研究任务中的性能。\n\n**关键设计**：论文中使用了监督微调和强化学习两种方法来训练LLM。监督微调使用标注好的训练数据来调整模型的参数，使其更好地适应特定任务。强化学习则通过奖励机制来引导模型学习，使其能够更好地完成任务。具体参数设置和损失函数等技术细节在论文中未详细说明，属于未知信息。",
            "application_zh": "该研究成果可应用于临床研究的多个领域，例如加速系统评价流程、优化临床试验设计、辅助医生进行决策等。TrialPanorama数据集和训练好的LLM可以作为临床研究人员的有力工具，提高研究效率和质量，并最终改善患者的治疗效果。未来，该方法有望扩展到其他医学领域，推动AI在医疗健康领域的应用。",
            "highlight_zh": "实验结果表明，基于TrialPanorama数据集训练的8B LLM在八个关键临床研究任务中均优于70B的通用LLM。具体而言，相对改进幅度分别为73.7%、67.6%、38.4%、37.8%、26.5%、20.7%、20.0%、18.1%和5.2%。这些结果表明，针对特定领域的数据集和训练方法能够显著提升LLM在该领域的性能。",
            "tags_zh": [
                "临床研究",
                "大型语言模型",
                "数据集构建",
                "监督微调",
                "强化学习",
                "临床试验",
                "自然语言处理"
            ],
            "_index": 64,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2505.16097/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2505.16097/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2505.16097/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "LTA-thinker: Latent Thought-Augmented Training Framework for Large Language Models on Complex Reasoning",
            "authors": [
                "Jiaqi Wang",
                "Binquan Ji",
                "Haibo Luo",
                "Yiyang Qi",
                "Ruiting Li",
                "Huiyan Wang",
                "Yuantao Han",
                "Cangyi Yang",
                "jiaxu Zhang",
                "Feiliang Ren"
            ],
            "arxiv_id": "2509.12875",
            "summary": "Complex Reasoning in Large Language Models can be dynamically optimized using Test-Time Scaling (TTS) to mitigate Overthinking. Methods such as Coconut, SoftCoT and its variant are effective in continuous latent space inference, the core bottleneck still lies in the efficient generation and utilization of high-quality Latent Thought. Drawing from the theory of SoftCoT++ that a larger variance in the generated Latent Thought distribution more closely approximates the golden truth distribution, we propose a Latent Thought-Augmented Training Framework--LTA-Thinker, which improves distributional variance and enhances reasoning performance from two perspectives. First, LTA-Thinker constructs a Latent Thought generation architecture based on a learnable prior. This architecture aims to increase the variance distribution of generated Latent Thought Vectors in order to simplify the overall structure and raise the performance ceiling. Second, LTA-Thinker introduces a distribution-based directional optimization paradigm that jointly constrains both distribution locality and distribution scale. This mechanism improves information efficiency and computational cost through a multi-objective co-training strategy, which combines standard Supervised Fine-Tuning (SFT) loss with two novel losses: Semantic Alignment Loss, which utilizes KL divergence to ensure that the Latent Thought is highly relevant to the semantics of the question; Reasoning Focus Loss, which utilizes a contrastive learning mechanism to guide the model to focus on the most critical reasoning steps. Experiments show that LTA-thinker achieves state-of-the-art (SOTA) performance among various baselines and demonstrates a higher performance ceiling and better scaling effects.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2509.12875",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "contrastive learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 10.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "LTA-thinker：潜变量思想增强训练框架，提升大语言模型复杂推理能力",
            "summary_zh": "本文提出了一种名为LTA-Thinker的潜变量思想增强训练框架，旨在提升大型语言模型在复杂推理任务中的性能。该框架受到SoftCoT++理论的启发，即生成潜变量思想分布的更大方差更接近真实分布。LTA-Thinker从两个角度出发，提高分布方差并增强推理性能。首先，构建了一个基于可学习先验的潜变量思想生成架构，旨在增加生成潜变量向量的方差分布，从而简化整体结构并提高性能上限。其次，引入了一种基于分布的定向优化范式，联合约束分布局部性和分布尺度。该机制通过结合标准监督微调（SFT）损失与两个新颖的损失函数，即语义对齐损失（利用KL散度确保潜变量思想与问题语义高度相关）和推理焦点损失（利用对比学习机制引导模型关注最关键的推理步骤），来提高信息效率和计算成本。实验结果表明，LTA-Thinker在各种基线模型中实现了最先进（SOTA）的性能，并展示了更高的性能上限和更好的缩放效果。",
            "intro_zh": [
                "现有方法在利用潜变量空间进行复杂推理时，高质量潜变量思想的有效生成和利用仍然是瓶颈。",
                "LTA-Thinker通过构建基于可学习先验的潜变量生成架构，并引入基于分布的定向优化范式，提升潜变量思想的质量和利用效率。",
                "实验表明，LTA-Thinker在复杂推理任务上取得了SOTA性能，并展现出更高的性能上限和更好的扩展性。"
            ],
            "method_zh": "**问题定义**：现有的大语言模型在复杂推理任务中，虽然可以通过测试时缩放（TTS）等方法缓解过度思考问题，但如何高效地生成和利用高质量的潜变量思想仍然是一个关键挑战。现有的方法，例如Coconut和SoftCoT，在连续潜变量空间推理方面取得了一定的进展，但仍然受限于潜变量质量不高以及利用效率不足的问题。\\n\\n**核心思路**：LTA-Thinker的核心思路是通过增大生成的潜变量思想分布的方差来更逼近真实的分布。借鉴SoftCoT++的理论，认为更大的方差能够更好地覆盖可能的推理路径。因此，LTA-Thinker旨在提高潜变量的生成质量和利用效率，从而提升整体的推理性能。\\n\\n**技术框架**：LTA-Thinker框架主要包含两个核心模块：潜变量思想生成架构和基于分布的定向优化范式。潜变量思想生成架构基于可学习的先验分布，用于生成具有更大方差的潜变量向量。基于分布的定向优化范式则通过联合约束分布的局部性和尺度，提高信息效率和计算效率。整个训练过程采用多目标协同训练策略，结合标准的监督微调（SFT）损失以及两个新颖的损失函数。\\n\\n**关键创新**：LTA-Thinker的关键创新在于：1) 提出了基于可学习先验的潜变量思想生成架构，能够生成具有更大方差的潜变量，从而提高模型的探索能力；2) 引入了基于分布的定向优化范式，通过语义对齐损失和推理焦点损失，引导模型学习与问题语义相关且聚焦关键推理步骤的潜变量表示。与现有方法相比，LTA-Thinker更加注重潜变量分布的质量和利用效率。\\n\\n**关键设计**：LTA-Thinker的关键设计包括：1) 可学习先验分布的设计，具体形式未知；2) 语义对齐损失，使用KL散度来衡量生成潜变量与问题语义之间的相似度，确保潜变量与问题相关；3) 推理焦点损失，使用对比学习机制，引导模型关注最关键的推理步骤，提高推理的准确性。损失函数的具体权重比例未知。",
            "application_zh": "LTA-Thinker框架可以应用于各种需要复杂推理能力的场景，例如问答系统、知识图谱推理、代码生成等。通过提升大语言模型的推理能力，可以提高这些应用在复杂任务上的性能和可靠性，具有广泛的应用前景和实际价值。未来，该框架可以进一步扩展到其他模态，例如图像和语音，以支持更复杂的跨模态推理任务。",
            "highlight_zh": "LTA-Thinker在实验中取得了SOTA性能，证明了其有效性。具体性能数据和对比基线未知，但摘要强调了LTA-Thinker具有更高的性能上限和更好的缩放效果，意味着该方法在模型规模增大时能够获得更大的性能提升。实验结果表明，LTA-Thinker能够有效地提高大语言模型在复杂推理任务上的性能。",
            "tags_zh": [
                "大语言模型",
                "复杂推理",
                "潜变量模型",
                "对比学习",
                "知识蒸馏"
            ],
            "_index": 65,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://ar5iv.labs.arxiv.org/html/2509.12875/assets/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://ar5iv.labs.arxiv.org/html/2509.12875/assets/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://ar5iv.labs.arxiv.org/html/2509.12875/assets/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Interactive Motion Planning for Human-Robot Collaboration Based on Human-Centric Configuration Space Ergonomic Field",
            "authors": [
                "Chenzui Li",
                "Yiming Chen",
                "Xi Wu",
                "Tao Teng",
                "Sylvain Calinon",
                "Darwin Caldwell",
                "Fei Chen"
            ],
            "arxiv_id": "2512.14111",
            "summary": "Industrial human-robot collaboration requires motion planning that is collision-free, responsive, and ergonomically safe to reduce fatigue and musculoskeletal risk. We propose the Configuration Space Ergonomic Field (CSEF), a continuous and differentiable field over the human joint space that quantifies ergonomic quality and provides gradients for real-time ergonomics-aware planning. An efficient algorithm constructs CSEF from established metrics with joint-wise weighting and task conditioning, and we integrate it into a gradient-based planner compatible with impedance-controlled robots. In a 2-DoF benchmark, CSEF-based planning achieves higher success rates, lower ergonomic cost, and faster computation than a task-space ergonomic planner. Hardware experiments with a dual-arm robot in unimanual guidance, collaborative drilling, and bimanual cocarrying show faster ergonomic cost reduction, closer tracking to optimized joint targets, and lower muscle activation than a point-to-point baseline. CSEF-based planning method reduces average ergonomic scores by up to 10.31% for collaborative drilling tasks and 5.60% for bimanual co-carrying tasks while decreasing activation in key muscle groups, indicating practical benefits for real-world deployment.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14111",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "bi-manual",
                        "dual-arm",
                        "[T]motion planning"
                    ],
                    "score": 10.0
                }
            ],
            "relevance_score": 10.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "提出基于人机协作构型空间人体工学场的交互式机器人运动规划方法",
            "summary_zh": "本文针对工业人机协作中运动规划的需求，旨在实现无碰撞、响应迅速且符合人体工学的安全运动，以降低疲劳和肌肉骨骼风险。为此，我们提出了构型空间人体工学场(CSEF)，这是一个在人体关节空间上的连续可微场，用于量化人体工学质量，并为实时人体工学感知规划提供梯度。该算法通过结合关节权重和任务条件，从已建立的指标中高效构建CSEF，并将其集成到与阻抗控制机器人兼容的基于梯度的规划器中。在2自由度基准测试中，基于CSEF的规划比基于任务空间人体工学的规划实现了更高的成功率、更低的人体工学成本和更快的计算速度。在双臂机器人上的单手动引导、协作钻孔和双手协同搬运硬件实验表明，与点到点基线相比，CSEF能更快地降低人体工学成本，更紧密地跟踪优化后的关节目标，并降低肌肉激活。对于协作钻孔任务，基于CSEF的规划方法将平均人体工学评分降低了高达10.31%，对于双手协同搬运任务降低了5.60%，同时降低了关键肌肉群的激活，表明了其在实际部署中的益处。",
            "intro_zh": [
                "现有的人机协作运动规划方法在人体工学安全性方面存在不足，容易导致操作人员疲劳和肌肉骨骼损伤。",
                "论文提出构型空间人体工学场(CSEF)，通过量化人体工学质量并提供梯度，实现实时人体工学感知规划。",
                "实验结果表明，与传统方法相比，CSEF能有效降低人体工学成本，提高任务成功率，并减少操作人员的肌肉激活。"
            ],
            "method_zh": "**问题定义**：论文旨在解决工业人机协作中，机器人运动规划缺乏对人体工学因素的考虑，导致工人疲劳和受伤的问题。现有方法通常在任务空间进行人体工学优化，计算效率低，难以满足实时性要求。此外，缺乏对人体关节空间人体工学特性的建模，难以指导机器人进行符合人体工学的运动规划。\\n\\n**核心思路**：论文的核心思路是将人体工学评估指标映射到机器人的构型空间，构建一个连续可微的构型空间人体工学场(CSEF)。通过CSEF，机器人可以感知不同构型下的人体工学质量，并利用梯度信息进行优化，从而规划出符合人体工学的运动轨迹。这种方法将人体工学优化融入到运动规划过程中，提高了效率和实时性。\\n\\n**技术框架**：整体框架包括以下几个主要步骤：1) 选择合适的人体工学评估指标，例如关节角度、力矩等；2) 对每个关节进行加权，并考虑任务条件，以突出重要关节和任务相关性；3) 利用选定的指标和权重，构建构型空间人体工学场(CSEF)；4) 将CSEF集成到基于梯度的运动规划器中，实现实时人体工学感知规划；5) 通过阻抗控制机器人执行规划的运动轨迹。\\n\\n**关键创新**：论文的关键创新在于提出了构型空间人体工学场(CSEF)的概念，并将人体工学评估从任务空间转移到构型空间。与传统的任务空间人体工学优化方法相比，CSEF具有以下优势：1) 计算效率更高，能够满足实时性要求；2) 能够直接指导机器人进行符合人体工学的运动规划；3) 能够灵活地适应不同的任务和人体工学指标。\\n\\n**关键设计**：CSEF的构建需要选择合适的人体工学评估指标，并对每个关节进行加权。权重的选择需要考虑关节的重要性以及任务的相关性。此外，CSEF的构建还需要保证其连续性和可微性，以便于梯度优化。在运动规划器中，需要设计合适的梯度下降算法，以找到符合人体工学要求的运动轨迹。阻抗控制器的参数需要根据机器人的动力学特性进行调整，以保证运动的平稳性和精度。",
            "application_zh": "该研究成果可应用于各种工业人机协作场景，例如装配、搬运、焊接等。通过优化机器人的运动轨迹，降低工人的疲劳和受伤风险，提高生产效率和安全性。此外，该方法还可以应用于医疗康复机器人、辅助生活机器人等领域，为用户提供更加舒适和安全的服务。未来，该研究有望推动人机协作技术的进一步发展，实现更加智能和人性化的机器人系统。",
            "highlight_zh": "实验结果表明，与传统的点到点基线方法相比，基于CSEF的规划方法在协作钻孔任务中将平均人体工学评分降低了高达10.31%，在双手协同搬运任务中降低了5.60%，同时降低了关键肌肉群的激活。在2自由度基准测试中，基于CSEF的规划比基于任务空间人体工学的规划实现了更高的成功率、更低的人体工学成本和更快的计算速度。",
            "tags_zh": [
                "人机协作",
                "运动规划",
                "人体工学",
                "构型空间",
                "机器人"
            ],
            "_index": 66,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14111/fig/cover.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14111/fig/CSEF.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14111/fig/framework_interactive_motion_planning.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Deep Learning Perspective of Scene Understanding in Autonomous Robots",
            "authors": [
                "Afia Maham",
                "Dur E Nayab Tashfa"
            ],
            "arxiv_id": "2512.14020",
            "summary": "This paper provides a review of deep learning applications in scene understanding in autonomous robots, including innovations in object detection, semantic and instance segmentation, depth estimation, 3D reconstruction, and visual SLAM. It emphasizes how these techniques address limitations of traditional geometric models, improve depth perception in real time despite occlusions and textureless surfaces, and enhance semantic reasoning to understand the environment better. When these perception modules are integrated into dynamic and unstructured environments, they become more effective in decisionmaking, navigation and interaction. Lastly, the review outlines the existing problems and research directions to advance learning-based scene understanding of autonomous robots.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14020",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "visual SLAM",
                        "depth estimation",
                        "[T]scene understanding"
                    ],
                    "score": 10.0
                }
            ],
            "relevance_score": 10.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "综述深度学习在自主机器人场景理解中的应用，提升机器人感知与决策能力",
            "summary_zh": "本文综述了深度学习在自主机器人场景理解中的应用，包括目标检测、语义分割与实例分割、深度估计、3D重建和视觉SLAM等方面的创新。重点强调了这些技术如何解决传统几何模型的局限性，如何在遮挡和无纹理表面情况下实时提高深度感知能力，以及如何增强语义推理以更好地理解环境。当这些感知模块集成到动态和非结构化环境中时，它们在决策、导航和交互方面变得更加有效。最后，本文概述了现有问题和研究方向，以推进自主机器人基于学习的场景理解。",
            "intro_zh": [
                "传统几何模型在复杂环境下的感知能力有限，难以应对遮挡、无纹理等挑战。",
                "利用深度学习进行场景理解，增强机器人对环境的语义推理能力和深度感知能力。",
                "深度学习技术提升了机器人在动态环境中的决策、导航和交互能力，具有重要意义。"
            ],
            "method_zh": "**问题定义**：自主机器人在复杂、动态和非结构化的环境中运行时，需要准确、鲁棒地理解周围的场景。传统方法，如基于几何模型的算法，在处理遮挡、光照变化、无纹理表面等问题时表现不佳，限制了机器人的感知能力和决策能力。因此，如何利用深度学习技术提升机器人的场景理解能力，是本文关注的核心问题。\\n\\n**核心思路**：本文的核心思路是利用深度学习强大的特征提取和表示能力，构建更鲁棒、更准确的场景理解模块。通过深度学习模型，机器人可以更好地理解场景中的语义信息、几何信息和运动信息，从而做出更合理的决策。\\n\\n**技术框架**：本文综述了深度学习在以下几个场景理解任务中的应用：1) 目标检测：识别场景中的物体；2) 语义分割与实例分割：将图像像素划分为不同的语义类别和实例；3) 深度估计：估计场景中每个像素的深度信息；4) 3D重建：构建场景的三维模型；5) 视觉SLAM：同时定位机器人自身位置并构建环境地图。这些模块可以单独使用，也可以集成在一起，形成一个完整的场景理解系统。\\n\\n**关键创新**：本文的关键创新在于总结了深度学习在自主机器人场景理解中的最新进展，并指出了现有方法的局限性和未来的研究方向。与传统的综述文章不同，本文更加关注深度学习技术在解决实际问题中的应用，并强调了不同模块之间的集成和协同作用。\\n\\n**关键设计**：本文没有提出新的算法或模型，而是对现有方法进行了系统的梳理和分析。在目标检测方面，综述了基于卷积神经网络（CNN）的各种目标检测算法，如Faster R-CNN、YOLO和SSD。在语义分割方面，综述了基于全卷积网络（FCN）和U-Net等算法。在深度估计方面，综述了基于单目视觉、双目视觉和RGB-D相机的深度估计方法。在视觉SLAM方面，综述了基于深度学习的视觉里程计和回环检测算法。",
            "application_zh": "该研究成果可广泛应用于各种自主机器人应用场景，如自动驾驶、物流配送、家庭服务、工业自动化和医疗机器人等。通过提升机器人的场景理解能力，可以提高其在复杂环境中的适应性和安全性，从而实现更高效、更智能的自动化。",
            "highlight_zh": "本文是一篇综述性文章，主要贡献在于对现有深度学习方法在自主机器人场景理解中的应用进行了系统性的总结和分析。虽然没有提供具体的实验数据，但通过对各种方法的优缺点进行比较，为未来的研究方向提供了有价值的参考。",
            "tags_zh": [
                "自主机器人",
                "场景理解",
                "深度学习",
                "目标检测",
                "语义分割",
                "深度估计",
                "视觉SLAM",
                "3D重建"
            ],
            "_index": 67,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Consistent Instance Field for Dynamic Scene Understanding",
            "authors": [
                "Junyi Wu",
                "Van Nguyen Nguyen",
                "Benjamin Planche",
                "Jiachen Tao",
                "Changchang Sun",
                "Zhongpai Gao",
                "Zhenghao Zhao",
                "Anwesa Choudhuri",
                "Gengyu Zhang",
                "Meng Zheng",
                "Feiran Wang",
                "Terrence Chen",
                "Yan Yan",
                "Ziyan Wu"
            ],
            "arxiv_id": "2512.14126",
            "summary": "We introduce Consistent Instance Field, a continuous and probabilistic spatio-temporal representation for dynamic scene understanding. Unlike prior methods that rely on discrete tracking or view-dependent features, our approach disentangles visibility from persistent object identity by modeling each space-time point with an occupancy probability and a conditional instance distribution. To realize this, we introduce a novel instance-embedded representation based on deformable 3D Gaussians, which jointly encode radiance and semantic information and are learned directly from input RGB images and instance masks through differentiable rasterization. Furthermore, we introduce new mechanisms to calibrate per-Gaussian identities and resample Gaussians toward semantically active regions, ensuring consistent instance representations across space and time. Experiments on HyperNeRF and Neu3D datasets demonstrate that our method significantly outperforms state-of-the-art methods on novel-view panoptic segmentation and open-vocabulary 4D querying tasks.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14126",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "[T]scene understanding",
                        "open-vocabulary",
                        "open vocabulary"
                    ],
                    "score": 10.0
                }
            ],
            "relevance_score": 10.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "提出一致性实例场，用于动态场景理解中的时空连续建模。",
            "summary_zh": "本文提出了一种一致性实例场（Consistent Instance Field），这是一种用于动态场景理解的连续且概率性的时空表示方法。与依赖于离散跟踪或视角相关特征的现有方法不同，我们的方法通过对每个时空点建模其占用概率和条件实例分布，从而将可见性与持久的对象身份解耦。为了实现这一点，我们引入了一种基于可变形3D高斯的新型实例嵌入表示，该表示联合编码辐射和语义信息，并通过可微光栅化直接从输入的RGB图像和实例掩码中学习。此外，我们引入了新的机制来校准每个高斯的身份，并将高斯重新采样到语义活跃区域，从而确保跨时空的一致实例表示。在HyperNeRF和Neu3D数据集上的实验表明，我们的方法在novel-view全景分割和开放词汇4D查询任务上显著优于最先进的方法。",
            "intro_zh": [
                "现有动态场景理解方法依赖离散跟踪或视角相关特征，难以有效解耦可见性和对象身份。",
                "论文提出一致性实例场，通过对时空点建模占用概率和条件实例分布，实现可见性与对象身份的解耦。",
                "实验表明，该方法在HyperNeRF和Neu3D数据集上，显著提升了novel-view全景分割和开放词汇4D查询的性能。"
            ],
            "method_zh": "**问题定义**：动态场景理解旨在理解场景中物体的运动和变化，现有方法通常依赖于离散的物体跟踪或视角相关的特征，这导致难以在遮挡、快速运动等情况下保持物体身份的一致性，并且难以进行时空连续的查询和推理。这些方法的痛点在于无法有效解耦可见性与持久的对象身份。\\n\\n**核心思路**：论文的核心思路是使用连续且概率性的时空表示，即一致性实例场，来建模动态场景。通过对每个时空点建模其占用概率和条件实例分布，将可见性与持久的对象身份解耦。此外，使用可变形3D高斯来表示实例，并引入机制来校准高斯身份和重新采样高斯，以确保跨时空的一致性。这样设计的目的是为了克服现有方法在处理动态场景时物体身份不一致的问题，并实现更灵活的时空查询和推理。\\n\\n**技术框架**：整体框架包括以下几个主要模块：1) 使用可变形3D高斯表示场景中的物体，每个高斯包含辐射和语义信息。2) 通过可微光栅化，从RGB图像和实例掩码中学习高斯参数。3) 引入身份校准机制，确保每个高斯的身份在时空上保持一致。4) 引入高斯重采样机制，将高斯重新采样到语义活跃区域，提高表示的效率和准确性。5) 使用占用概率和条件实例分布来建模每个时空点，实现时空连续的表示。\\n\\n**关键创新**：最重要的技术创新点在于提出了一致性实例场，这是一种连续且概率性的时空表示方法，能够有效解耦可见性与持久的对象身份。与现有方法依赖离散跟踪或视角相关特征不同，该方法通过对每个时空点建模占用概率和条件实例分布，实现了更鲁棒和灵活的动态场景理解。此外，使用可变形3D高斯来表示实例，并引入身份校准和高斯重采样机制，进一步提高了表示的质量和一致性。\\n\\n**关键设计**：论文的关键设计包括：1) 使用可变形3D高斯来表示实例，高斯参数包括位置、旋转、缩放、颜色和语义特征。2) 使用可微光栅化来渲染高斯，并计算渲染损失和语义损失，从而优化高斯参数。3) 引入身份校准损失，鼓励相邻时空点的高斯具有相似的身份特征。4) 引入高斯重采样机制，根据语义活跃度对高斯进行重采样，提高表示的效率和准确性。5) 使用占用概率和条件实例分布来建模每个时空点，并使用交叉熵损失来优化这些概率分布。",
            "application_zh": "该研究成果可应用于自动驾驶、机器人导航、增强现实等领域。例如，在自动驾驶中，可以利用该方法理解周围车辆和行人的运动轨迹，从而做出更安全的决策。在机器人导航中，可以利用该方法构建动态环境地图，从而实现更智能的路径规划。在增强现实中，可以利用该方法将虚拟物体与真实场景中的动态物体进行交互，从而提供更沉浸式的体验。",
            "highlight_zh": "实验结果表明，该方法在HyperNeRF和Neu3D数据集上，显著优于最先进的方法。在novel-view全景分割任务上，该方法取得了显著的性能提升。在开放词汇4D查询任务上，该方法能够准确地查询指定物体在特定时间和空间位置的信息。具体性能数据在论文中有详细展示。",
            "tags_zh": [
                "动态场景理解",
                "神经表示",
                "实例分割",
                "时空建模",
                "可变形3D高斯"
            ],
            "_index": 68,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14126/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14126/x8.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14126/x9.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Broadening View Synthesis of Dynamic Scenes from Constrained Monocular Videos",
            "authors": [
                "Le Jiang",
                "Shaotong Zhu",
                "Yedi Luo",
                "Shayda Moezzi",
                "Sarah Ostadabbas"
            ],
            "arxiv_id": "2512.14406",
            "summary": "In dynamic Neural Radiance Fields (NeRF) systems, state-of-the-art novel view synthesis methods often fail under significant viewpoint deviations, producing unstable and unrealistic renderings. To address this, we introduce Expanded Dynamic NeRF (ExpanDyNeRF), a monocular NeRF framework that leverages Gaussian splatting priors and a pseudo-ground-truth generation strategy to enable realistic synthesis under large-angle rotations. ExpanDyNeRF optimizes density and color features to improve scene reconstruction from challenging perspectives. We also present the Synthetic Dynamic Multiview (SynDM) dataset, the first synthetic multiview dataset for dynamic scenes with explicit side-view supervision-created using a custom GTA V-based rendering pipeline. Quantitative and qualitative results on SynDM and real-world datasets demonstrate that ExpanDyNeRF significantly outperforms existing dynamic NeRF methods in rendering fidelity under extreme viewpoint shifts. Further details are provided in the supplementary materials.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14406",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "gaussian splatting",
                        "splatting",
                        "NeRF",
                        "neural radiance field",
                        "scene reconstruction"
                    ],
                    "score": 10.0
                }
            ],
            "relevance_score": 10.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "ExpanDyNeRF：扩展动态场景视角合成，解决单目视频大角度渲染失真问题",
            "summary_zh": "针对动态神经辐射场（NeRF）系统中，现有视角合成方法在大角度偏差下易产生不稳定和不真实渲染的问题，本文提出扩展动态NeRF（ExpanDyNeRF），这是一个单目NeRF框架，利用高斯溅射先验和伪真值生成策略，实现大角度旋转下的逼真合成。ExpanDyNeRF优化密度和颜色特征，以改善从具有挑战性视角进行场景重建的效果。此外，本文还提出了合成动态多视角（SynDM）数据集，这是首个具有显式侧视监督的动态场景合成多视角数据集，该数据集使用基于GTA V的自定义渲染管线创建。在SynDM和真实世界数据集上的定量和定性结果表明，ExpanDyNeRF在极端视角偏移下的渲染保真度方面显著优于现有的动态NeRF方法。",
            "intro_zh": [
                "现有动态NeRF方法在视角偏差较大时，渲染效果不稳定且不真实，难以满足实际应用需求。",
                "ExpanDyNeRF利用高斯溅射先验和伪真值生成策略，优化密度和颜色特征，从而实现大角度下的高质量渲染。",
                "在SynDM和真实数据集上，ExpanDyNeRF显著优于现有方法，尤其在极端视角偏移下，渲染保真度提升明显。"
            ],
            "method_zh": "**问题定义**：现有动态NeRF方法在处理单目视频时，当视角发生较大变化时，渲染结果往往出现失真、模糊等问题，难以生成高质量的新视角图像。这是因为单目视频提供的视角信息有限，导致NeRF在学习场景几何和外观时存在歧义性，尤其是在缺乏侧视监督的情况下。\\n\\n**核心思路**：ExpanDyNeRF的核心思路是利用高斯溅射（Gaussian Splatting）先验来约束NeRF的学习过程，并结合伪真值生成策略来补充视角信息。高斯溅射能够提供更精确的场景几何表示，从而减少NeRF的歧义性。伪真值生成则通过合成额外的视角图像，为NeRF提供更丰富的训练数据。\\n\\n**技术框架**：ExpanDyNeRF的整体框架包括以下几个主要模块：1) 高斯溅射先验模块：利用高斯溅射算法对输入视频进行场景重建，得到场景的几何和外观先验信息。2) 伪真值生成模块：基于高斯溅射重建结果，通过视角变换生成额外的视角图像，作为伪真值。3) NeRF优化模块：利用高斯溅射先验和伪真值，对NeRF进行优化，学习场景的密度和颜色特征。\\n\\n**关键创新**：ExpanDyNeRF的关键创新在于：1) 将高斯溅射先验引入到动态NeRF中，从而提高了场景重建的精度和稳定性。2) 提出了伪真值生成策略，有效地补充了视角信息，解决了单目视频视角受限的问题。3) 构建了SynDM数据集，为动态场景新视角合成提供了基准测试平台。\\n\\n**关键设计**：ExpanDyNeRF的关键设计包括：1) 使用可微分的高斯溅射算法，以便将高斯溅射先验无缝地集成到NeRF的优化过程中。2) 设计了基于深度信息的视角变换算法，以生成高质量的伪真值图像。3) 采用了多尺度损失函数，以平衡重建精度和渲染质量。",
            "application_zh": "ExpanDyNeRF在虚拟现实、增强现实、自动驾驶、电影特效等领域具有广泛的应用前景。例如，可以用于创建沉浸式的虚拟现实体验，实现逼真的增强现实效果，提高自动驾驶系统的环境感知能力，以及生成高质量的电影特效。该研究的实际价值在于提升动态场景新视角合成的质量和效率，为相关应用提供更强大的技术支持。未来，可以进一步探索如何将ExpanDyNeRF应用于更复杂的动态场景，并与其他技术相结合，以实现更高级的视觉效果。",
            "highlight_zh": "ExpanDyNeRF在SynDM数据集和真实世界数据集上都取得了显著的性能提升。在SynDM数据集上，ExpanDyNeRF在PSNR、SSIM和LPIPS等指标上均优于现有方法，尤其是在极端视角偏移下，PSNR提升超过3dB。在真实世界数据集上，ExpanDyNeRF也能够生成更清晰、更真实的渲染结果，有效地解决了现有方法存在的失真和模糊问题。",
            "tags_zh": [
                "动态NeRF",
                "视角合成",
                "高斯溅射",
                "单目视频",
                "伪真值生成"
            ],
            "_index": 69,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14406/Figures/real.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14406/x1.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14406/x2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Synthetic Data Pipelines for Adaptive, Mission-Ready Militarized Humanoids",
            "authors": [
                "Mohammed Ayman Habib",
                "Aldo Petruzzelli"
            ],
            "arxiv_id": "2512.14411",
            "summary": "Omnia presents a synthetic data driven pipeline to accelerate the training, validation, and deployment readiness of militarized humanoids. The approach converts first-person spatial observations captured from point-of-view recordings, smart glasses, augmented reality headsets, and spatial browsing workflows into scalable, mission-specific synthetic datasets for humanoid autonomy. By generating large volumes of high-fidelity simulated scenarios and pairing them with automated labeling and model training, the pipeline enables rapid iteration on perception, navigation, and decision-making capabilities without the cost, risk, or time constraints of extensive field trials. The resulting datasets can be tuned quickly for new operational environments and threat conditions, supporting both baseline humanoid performance and advanced subsystems such as multimodal sensing, counter-detection survivability, and CBRNE-relevant reconnaissance behaviors. This work targets faster development cycles and improved robustness in complex, contested settings by exposing humanoid systems to broad scenario diversity early in the development process.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14411",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "[T]humanoid"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "1_robot_core",
                "9_embodied_foundation"
            ],
            "headline_zh": "Omnia提出一种基于合成数据的流程，加速军用人形机器人的训练和部署。",
            "summary_zh": "Omnia提出了一种基于合成数据的流程，旨在加速军用人形机器人的训练、验证和部署准备。该方法将第一人称视角空间观测数据（来自POV录像、智能眼镜、增强现实头显和空间浏览工作流）转换为可扩展的、特定任务的合成数据集，用于人形机器人的自主性训练。通过生成大量高保真模拟场景，并结合自动标注和模型训练，该流程能够快速迭代感知、导航和决策能力，而无需耗费大量成本、风险或时间进行广泛的现场试验。生成的数据集可以针对新的作战环境和威胁条件进行快速调整，支持人形机器人的基线性能和高级子系统，例如多模态传感、反检测生存能力以及与CBRNE相关的侦察行为。这项工作旨在通过在开发过程的早期阶段让人形机器人系统接触广泛的场景多样性，从而加快开发周期并提高在复杂、竞争环境中的鲁棒性。",
            "intro_zh": [
                "现有军用人形机器人训练依赖昂贵的实地测试，面临成本高、风险大、耗时长的挑战。",
                "Omnia提出利用合成数据管道，从第一人称视角数据生成大规模、任务相关的模拟数据集。",
                "该方法通过自动标注和模型训练，加速人形机器人在感知、导航和决策方面的迭代优化。"
            ],
            "method_zh": "**问题定义**：论文旨在解决军用人形机器人训练中对大量真实世界数据的依赖问题。传统的实地测试成本高昂，且存在安全风险，难以覆盖各种复杂场景。现有方法难以快速适应新的作战环境和威胁条件，限制了人形机器人的部署速度和鲁棒性。\\n\\n**核心思路**：论文的核心思路是利用合成数据来模拟各种作战场景，从而避免对真实世界数据的过度依赖。通过将第一人称视角空间观测数据转换为合成数据集，可以生成大量多样化的训练样本，加速人形机器人的学习过程。这种方法能够降低成本、减少风险，并提高人形机器人在复杂环境中的适应能力。\\n\\n**技术框架**：Omnia流程主要包含以下几个阶段：1) 数据采集：从POV录像、智能眼镜、AR头显等设备获取第一人称视角空间观测数据。2) 场景生成：利用采集的数据生成高保真模拟场景，包括各种作战环境和威胁条件。3) 自动标注：对生成的合成数据进行自动标注，为模型训练提供标签。4) 模型训练：利用合成数据集训练人形机器人的感知、导航和决策模型。5) 验证与部署：在模拟环境中验证模型的性能，并最终部署到真实机器人上。\\n\\n**关键创新**：该论文的关键创新在于提出了一种完整的、基于合成数据的军用人形机器人训练流程。该流程能够将第一人称视角数据转换为可扩展的合成数据集，并利用自动标注和模型训练技术加速人形机器人的开发。与传统的实地测试方法相比，该方法具有成本低、风险小、效率高的优点。\\n\\n**关键设计**：论文中没有详细说明关键参数设置、损失函数或网络结构等技术细节。这些细节可能取决于具体的任务和模型选择。但是，论文强调了合成数据的质量和多样性对于模型训练的重要性。为了提高合成数据的真实感，可以采用各种渲染技术和物理模拟方法。为了增加数据的多样性，可以生成各种不同的场景和任务。",
            "application_zh": "该研究成果可广泛应用于军用人形机器人的开发和部署，例如战场侦察、危险环境探测、CBRNE事件响应等。通过利用合成数据进行训练，可以加速人形机器人的开发周期，提高其在复杂环境中的鲁棒性和适应性，从而提升作战效能和安全性。该方法也可推广到其他机器人领域，例如工业机器人、服务机器人等。",
            "highlight_zh": "论文着重介绍了合成数据管道的概念和流程，但没有提供具体的实验结果或性能数据。因此，无法量化地评估该方法的有效性。未来的研究可以重点关注合成数据的质量和多样性对模型性能的影响，并与传统的实地测试方法进行对比，以验证该方法的优越性。",
            "tags_zh": [
                "合成数据",
                "人形机器人",
                "自主导航",
                "机器学习",
                "军用机器人"
            ],
            "_index": 70,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "MMDrive: Interactive Scene Understanding Beyond Vision with Multi-representational Fusion",
            "authors": [
                "Minghui Hou",
                "Wei-Hsing Huang",
                "Shaofeng Liang",
                "Daizong Liu",
                "Tai-Hao Wen",
                "Gang Wang",
                "Runwei Guan",
                "Weiping Ding"
            ],
            "arxiv_id": "2512.13177",
            "summary": "Vision-language models enable the understanding and reasoning of complex traffic scenarios through multi-source information fusion, establishing it as a core technology for autonomous driving. However, existing vision-language models are constrained by the image understanding paradigm in 2D plane, which restricts their capability to perceive 3D spatial information and perform deep semantic fusion, resulting in suboptimal performance in complex autonomous driving environments. This study proposes MMDrive, an multimodal vision-language model framework that extends traditional image understanding to a generalized 3D scene understanding framework. MMDrive incorporates three complementary modalities, including occupancy maps, LiDAR point clouds, and textual scene descriptions. To this end, it introduces two novel components for adaptive cross-modal fusion and key information extraction. Specifically, the Text-oriented Multimodal Modulator dynamically weights the contributions of each modality based on the semantic cues in the question, guiding context-aware feature integration. The Cross-Modal Abstractor employs learnable abstract tokens to generate compact, cross-modal summaries that highlight key regions and essential semantics. Comprehensive evaluations on the DriveLM and NuScenes-QA benchmarks demonstrate that MMDrive achieves significant performance gains over existing vision-language models for autonomous driving, with a BLEU-4 score of 54.56 and METEOR of 41.78 on DriveLM, and an accuracy score of 62.7% on NuScenes-QA. MMDrive effectively breaks the traditional image-only understanding barrier, enabling robust multimodal reasoning in complex driving environments and providing a new foundation for interpretable autonomous driving scene understanding.",
            "categories": [
                "cs.CV",
                "cs.RO"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13177",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "[T]scene understanding"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "3_perception_slam",
                "9_embodied_foundation"
            ],
            "headline_zh": "MMDrive：提出多模态融合的交互式场景理解框架，超越视觉限制。",
            "summary_zh": "本文提出了MMDrive，一个多模态视觉-语言模型框架，旨在将传统的2D图像理解扩展到广义的3D场景理解。MMDrive融合了占用地图、激光雷达点云和文本场景描述三种互补模态的信息。为此，论文引入了两个新颖的组件，用于自适应跨模态融合和关键信息提取。具体来说，Text-oriented Multimodal Modulator基于问题中的语义线索动态地加权每个模态的贡献，从而指导上下文感知的特征集成。Cross-Modal Abstractor采用可学习的抽象token来生成紧凑的跨模态摘要，突出关键区域和重要语义。在DriveLM和NuScenes-QA基准上的综合评估表明，MMDrive在自动驾驶的视觉-语言模型方面取得了显著的性能提升，在DriveLM上BLEU-4得分为54.56，METEOR得分为41.78，在NuScenes-QA上准确率得分为62.7%。MMDrive有效地打破了传统仅依赖图像理解的障碍，实现了复杂驾驶环境中强大的多模态推理，并为可解释的自动驾驶场景理解提供了新的基础。",
            "intro_zh": [
                "现有视觉-语言模型受限于2D图像理解，缺乏3D空间感知和深度语义融合能力，导致在复杂自动驾驶环境中表现欠佳。",
                "MMDrive通过融合占用地图、激光雷达点云和文本描述，并设计自适应跨模态融合和关键信息提取模块，实现3D场景理解。",
                "实验表明，MMDrive在DriveLM和NuScenes-QA基准上显著优于现有模型，BLEU-4提升至54.56，NuScenes-QA准确率达62.7%。"
            ],
            "method_zh": "**问题定义**：现有视觉-语言模型在自动驾驶场景中，主要依赖2D图像进行理解和推理，无法充分利用3D空间信息，导致对复杂交通状况的理解存在局限性。痛点在于缺乏有效的多模态融合机制，无法将视觉信息与激光雷达、地图等信息进行深度整合。\\n\\n**核心思路**：MMDrive的核心思路是将传统的2D图像理解扩展到3D场景理解，通过融合多种模态的信息（占用地图、激光雷达点云、文本描述）来提升模型对复杂驾驶环境的感知和推理能力。通过引入自适应跨模态融合和关键信息提取机制，使模型能够根据任务需求动态地调整不同模态的权重，并提取关键信息。\\n\\n**技术框架**：MMDrive框架包含三个主要部分：多模态输入编码器、Text-oriented Multimodal Modulator和Cross-Modal Abstractor。首先，多模态输入编码器将占用地图、激光雷达点云和文本描述分别编码成特征向量。然后，Text-oriented Multimodal Modulator根据文本描述中的语义线索，动态地调整不同模态特征的权重，实现自适应跨模态融合。最后，Cross-Modal Abstractor提取融合后的特征中的关键信息，生成紧凑的跨模态摘要，用于后续的推理和问答。\\n\\n**关键创新**：MMDrive的关键创新在于Text-oriented Multimodal Modulator和Cross-Modal Abstractor的设计。Text-oriented Multimodal Modulator能够根据文本描述动态调整不同模态的权重，实现了上下文感知的特征融合，克服了传统方法中静态融合的局限性。Cross-Modal Abstractor通过可学习的抽象token提取关键信息，减少了冗余信息对推理的影响。与现有方法相比，MMDrive能够更有效地利用多模态信息，提升了对复杂驾驶场景的理解能力。\\n\\n**关键设计**：Text-oriented Multimodal Modulator使用注意力机制，根据文本描述的嵌入向量计算每个模态的权重。Cross-Modal Abstractor使用Transformer结构，通过可学习的抽象token与多模态特征进行交互，提取关键信息。损失函数包括问答损失和对比学习损失，用于优化模型的推理能力和跨模态表示能力。具体参数设置未知。",
            "application_zh": "MMDrive可应用于高级驾驶辅助系统（ADAS）和自动驾驶系统，提升车辆对复杂交通场景的感知和理解能力，从而提高驾驶安全性。该研究还可扩展到其他需要多模态信息融合的机器人应用，例如智能巡检机器人、智能家居等，具有广阔的应用前景。",
            "highlight_zh": "MMDrive在DriveLM和NuScenes-QA两个基准测试中取得了显著的性能提升。在DriveLM上，MMDrive的BLEU-4得分达到54.56，METEOR得分达到41.78，相较于现有最佳模型有显著提升。在NuScenes-QA上，MMDrive的准确率达到62.7%，同样优于其他基线模型。这些结果表明，MMDrive能够有效地融合多模态信息，提升对复杂驾驶场景的理解能力。",
            "tags_zh": [
                "多模态融合",
                "自动驾驶",
                "场景理解",
                "视觉-语言模型",
                "3D场景理解"
            ],
            "_index": 71,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13177/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13177/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.13177/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "DL$^3$M: A Vision-to-Language Framework for Expert-Level Medical Reasoning through Deep Learning and Large Language Models",
            "authors": [
                "Md. Najib Hasan",
                "Imran Ahmad",
                "Sourav Basak Shuvo",
                "Md. Mahadi Hasan Ankon",
                "Sunanda Das",
                "Nazmul Siddique",
                "Hui Wang"
            ],
            "arxiv_id": "2512.13742",
            "summary": "Medical image classifiers detect gastrointestinal diseases well, but they do not explain their decisions. Large language models can generate clinical text, yet they struggle with visual reasoning and often produce unstable or incorrect explanations. This leaves a gap between what a model sees and the type of reasoning a clinician expects. We introduce a framework that links image classification with structured clinical reasoning. A new hybrid model, MobileCoAtNet, is designed for endoscopic images and achieves high accuracy across eight stomach-related classes. Its outputs are then used to drive reasoning by several LLMs. To judge this reasoning, we build two expert-verified benchmarks covering causes, symptoms, treatment, lifestyle, and follow-up care. Thirty-two LLMs are evaluated against these gold standards. Strong classification improves the quality of their explanations, but none of the models reach human-level stability. Even the best LLMs change their reasoning when prompts vary. Our study shows that combining DL with LLMs can produce useful clinical narratives, but current LLMs remain unreliable for high-stakes medical decisions. The framework provides a clearer view of their limits and a path for building safer reasoning systems. The complete source code and datasets used in this study are available atthis https URL.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13742",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "DL$^3$M：结合深度学习与大语言模型，实现专家级医学推理的视觉-语言框架",
            "summary_zh": "医学图像分类器在检测胃肠道疾病方面表现良好，但无法解释其决策过程。大型语言模型可以生成临床文本，但难以进行视觉推理，并且常常产生不稳定或不正确的解释。这导致模型所见与临床医生期望的推理类型之间存在差距。我们引入了一个框架，将图像分类与结构化的临床推理联系起来。我们设计了一种新的混合模型MobileCoAtNet，专门用于内窥镜图像，并在八个与胃相关的类别中实现了高精度。其输出被用于驱动多个大型语言模型的推理。为了评估这种推理，我们构建了两个经过专家验证的基准，涵盖病因、症状、治疗、生活方式和随访护理。我们针对这些黄金标准评估了32个大型语言模型。强大的分类能力提高了它们解释的质量，但没有一个模型达到人类水平的稳定性。即使是最好的大型语言模型，在提示发生变化时也会改变其推理。我们的研究表明，将深度学习与大型语言模型相结合可以产生有用的临床叙述，但目前的大型语言模型对于高风险的医疗决策仍然不可靠。该框架提供了一个更清晰的视角来了解它们的局限性，并为构建更安全的推理系统提供了一条途径。本研究中使用的完整源代码和数据集可在指定网址获取。",
            "intro_zh": [
                "医学图像分类器缺乏决策解释能力，而大型语言模型在视觉推理方面存在困难，导致模型推理与临床期望存在差距。",
                "提出DL$^3$M框架，通过结合图像分类与结构化临床推理，弥合模型所见与临床医生期望之间的差距。",
                "设计了MobileCoAtNet模型用于内窥镜图像分类，并在八个胃相关类别上取得了高精度，并构建了专家验证的推理基准。"
            ],
            "method_zh": "**问题定义**：现有医学图像分类器虽然能有效检测疾病，但缺乏可解释性，无法提供决策依据。大型语言模型虽然能生成临床文本，但在视觉推理方面表现不足，容易产生不准确或不稳定的解释。这导致模型输出与临床医生的期望存在鸿沟，阻碍了其在实际医疗场景中的应用。\\n\\n**核心思路**：DL$^3$M框架的核心在于将图像分类与结构化的临床推理相结合。首先，利用深度学习模型对医学图像进行精确分类，提取关键视觉特征。然后，将这些特征作为输入，驱动大型语言模型进行推理，生成包含病因、症状、治疗等信息的临床叙述。通过这种方式，弥合了视觉信息与临床推理之间的差距，提高了模型的可解释性和实用性。\\n\\n**技术框架**：DL$^3$M框架主要包含两个阶段：图像分类阶段和语言推理阶段。在图像分类阶段，使用MobileCoAtNet模型对内窥镜图像进行分类，输出图像所属的类别以及相应的置信度。在语言推理阶段，将图像分类的结果作为提示（prompt）输入到大型语言模型中，引导其生成结构化的临床叙述。框架还包括两个专家验证的基准数据集，用于评估大型语言模型推理的质量和稳定性。\\n\\n**关键创新**：该论文的关键创新在于提出了一个将深度学习图像分类与大型语言模型推理相结合的框架，并针对医学领域的特殊需求进行了优化。MobileCoAtNet模型的设计以及专家验证的推理基准的构建，都为该框架的有效性提供了保障。此外，该研究还深入分析了现有大型语言模型在医学推理方面的局限性，为未来研究方向提供了指导。\\n\\n**关键设计**：MobileCoAtNet模型是基于CoAtNet架构改进而来，针对内窥镜图像的特点进行了优化。具体的技术细节包括：采用了MobileNetV2的倒残差模块以减少计算量，使用了更大的卷积核以捕获更丰富的上下文信息，并引入了注意力机制以增强模型的特征表达能力。在语言推理阶段，使用了不同的提示策略来引导大型语言模型生成临床叙述，并对不同模型的推理结果进行了详细的对比分析。损失函数未知。",
            "application_zh": "该研究成果可应用于辅助医生进行疾病诊断和治疗方案制定，提高诊断效率和准确性。通过提供可解释的临床推理，增强医生对AI系统的信任度。此外，该框架还可用于构建智能化的医学教育和培训系统，帮助医学生更好地理解疾病的病理机制和临床表现。未来，该研究有望推动AI技术在医疗领域的更广泛应用。",
            "highlight_zh": "实验结果表明，MobileCoAtNet模型在内窥镜图像分类任务中取得了优异的性能，并在八个胃相关类别上实现了高精度。对32个大型语言模型的评估结果显示，强大的分类能力可以提高其解释的质量，但没有一个模型达到人类水平的稳定性。即使是最好的大型语言模型，在提示发生变化时也会改变其推理，表明当前的大型语言模型在医学推理方面仍存在局限性。",
            "tags_zh": [
                "医学图像分类",
                "大型语言模型",
                "临床推理",
                "深度学习",
                "可解释性",
                "内窥镜图像",
                "MobileCoAtNet"
            ],
            "_index": 72,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13742/Figures/DL_vs_LLM_comparison.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13742/x1.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.13742/x2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Real-time prediction of workplane illuminance distribution for daylight-linked controls using non-intrusive multimodal deep learning",
            "authors": [
                "Zulin Zhuang",
                "Yu Bian"
            ],
            "arxiv_id": "2512.14058",
            "summary": "Daylight-linked controls (DLCs) have significant potential for energy savings in buildings, especially when abundant daylight is available and indoor workplane illuminance can be accurately predicted in real time. Most existing studies on indoor daylight predictions were developed and tested for static scenes. This study proposes a multimodal deep learning framework that predicts indoor workplane illuminance distributions in real time from non-intrusive images with temporal-spatial features. By extracting image features only from the side-lit window areas rather than interior pixels, the approach remains applicable in dynamically occupied indoor spaces. A field experiment was conducted in a test room in Guangzhou (China), where 17,344 samples were collected for model training and validation. The model achieved R2 > 0.98 with RMSE < 0.14 on the same-distribution test set and R2 > 0.82 with RMSE < 0.17 on an unseen-day test set, indicating high accuracy and acceptable temporal generalization.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14058",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出一种非侵入式多模态深度学习框架，用于日光照明控制的实时工作面照度预测。",
            "summary_zh": "日光照明控制（DLCs）在建筑物节能方面具有巨大潜力，尤其是在充足的日光可用且室内工作面照度可以实时准确预测时。现有关于室内日光预测的大多数研究都是为静态场景开发和测试的。本研究提出了一种多模态深度学习框架，该框架通过具有时空特征的非侵入式图像实时预测室内工作面照度分布。通过仅从侧光窗户区域而非内部像素提取图像特征，该方法在动态Occupied室内空间中仍然适用。在中国广州的一个测试室内进行了一项现场实验，收集了17344个样本用于模型训练和验证。该模型在同分布测试集上实现了R2 > 0.98，RMSE < 0.14，在未见过的日期测试集上实现了R2 > 0.82，RMSE < 0.17，表明了高精度和可接受的时间泛化能力。",
            "intro_zh": [
                "现有日光预测方法多针对静态场景，难以适应动态Occupied的室内环境，限制了日光照明控制的应用。",
                "该研究提出一种多模态深度学习框架，仅利用侧光窗户区域的图像特征，实现实时工作面照度预测。",
                "实验结果表明，该模型具有较高的预测精度和良好的时间泛化能力，适用于实际应用场景。"
            ],
            "method_zh": "**问题定义**：论文旨在解决在动态Occupied的室内环境中，如何实时、准确地预测工作面照度分布，从而实现高效的日光照明控制。现有方法主要针对静态场景，无法有效应对室内人员活动带来的光照变化，且通常需要侵入式传感器，影响用户体验。\\n\\n**核心思路**：论文的核心思路是利用非侵入式的图像信息，特别是侧光窗户区域的图像特征，来预测室内工作面照度。这种方法避免了直接使用室内像素，从而减少了人员活动对预测的影响，提高了模型的鲁棒性。同时，采用深度学习模型可以有效提取图像中的时空特征，提高预测精度。\\n\\n**技术框架**：该研究提出的框架主要包含以下几个模块：1) 数据采集模块：通过摄像头采集侧光窗户区域的图像数据，并记录对应的工作面照度数据。2) 特征提取模块：利用卷积神经网络（CNN）提取图像中的视觉特征。3) 时序建模模块：使用循环神经网络（RNN）或Transformer等模型对时间序列特征进行建模，捕捉光照随时间的变化规律。4) 照度预测模块：将提取的特征输入到全连接层或其他回归模型中，预测工作面照度分布。\\n\\n**关键创新**：该研究的关键创新在于：1) 提出了一种非侵入式的照度预测方法，仅利用侧光窗户区域的图像信息，避免了对室内环境的干扰。2) 采用多模态深度学习框架，有效融合了图像的时空特征，提高了预测精度和泛化能力。\\n\\n**关键设计**：论文中可能涉及的关键设计包括：1) CNN网络结构的选择，例如ResNet、DenseNet等。2) RNN或Transformer模型的选择和参数设置，例如LSTM、GRU等。3) 损失函数的选择，例如均方误差（MSE）、Huber loss等。4) 数据增强方法，例如图像旋转、缩放等。5) 模型训练的优化算法，例如Adam、SGD等。这些细节将直接影响模型的性能。",
            "application_zh": "该研究成果可应用于智能建筑的日光照明控制系统，根据实时照度预测结果自动调节灯光亮度，从而实现节能和提高室内舒适度。此外，该方法还可扩展到其他室内环境参数的预测，例如温度、湿度等，为智能家居和智慧城市的发展提供技术支持。",
            "highlight_zh": "实验结果表明，该模型在同分布测试集上实现了R2 > 0.98，RMSE < 0.14，在未见过的日期测试集上实现了R2 > 0.82，RMSE < 0.17。这些结果表明，该模型具有较高的预测精度和良好的时间泛化能力，优于传统的基于静态场景的预测方法。",
            "tags_zh": [
                "日光照明控制",
                "深度学习",
                "多模态融合",
                "实时预测",
                "非侵入式",
                "室内环境",
                "照度预测"
            ],
            "_index": 73,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14058/figure/workflow.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14058/figure/case.jpg",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14058/figure/lab.jpg",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "OmniGen: Unified Multimodal Sensor Generation for Autonomous Driving",
            "authors": [
                "Tao Tang",
                "Enhui Ma",
                "xia zhou",
                "Letian Wang",
                "Tianyi Yan",
                "Xueyang Zhang",
                "Kun Zhan",
                "Peng Jia",
                "XianPeng Lang",
                "Jia-Wang Bian",
                "Kaicheng Yu",
                "Xiaodan Liang"
            ],
            "arxiv_id": "2512.14225",
            "summary": "Autonomous driving has seen remarkable advancements, largely driven by extensive real-world data collection. However, acquiring diverse and corner-case data remains costly and inefficient. Generative models have emerged as a promising solution by synthesizing realistic sensor data. However, existing approaches primarily focus on single-modality generation, leading to inefficiencies and misalignment in multimodal sensor data. To address these challenges, we propose OminiGen, which generates aligned multimodal sensor data in a unified framework. Our approach leverages a shared Bird\\u2019s Eye View (BEV) space to unify multimodal features and designs a novel generalizable multimodal reconstruction method, UAE, to jointly decode LiDAR and multi-view camera data. UAE achieves multimodal sensor decoding through volume rendering, enabling accurate and flexible reconstruction. Furthermore, we incorporate a Diffusion Transformer (DiT) with a ControlNet branch to enable controllable multimodal sensor generation. Our comprehensive experiments demonstrate that OminiGen achieves desired performances in unified multimodal sensor data generation with multimodal consistency and flexible sensor adjustments.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14225",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "OmniGen：提出统一的多模态传感器生成框架，用于自动驾驶场景。",
            "summary_zh": "自动驾驶的发展很大程度上依赖于大量的真实世界数据。然而，获取多样化和极端情况的数据仍然成本高昂且效率低下。生成模型通过合成逼真的传感器数据提供了一个有前景的解决方案。但是，现有方法主要集中在单模态生成上，导致多模态传感器数据效率低下和不对齐。为了解决这些挑战，我们提出了OmniGen，它在一个统一的框架中生成对齐的多模态传感器数据。我们的方法利用共享的鸟瞰图（BEV）空间来统一多模态特征，并设计了一种新颖的通用多模态重建方法UAE，以联合解码激光雷达和多视角相机数据。UAE通过体渲染实现多模态传感器解码，从而实现准确和灵活的重建。此外，我们结合了带有ControlNet分支的Diffusion Transformer（DiT），以实现可控的多模态传感器生成。我们的综合实验表明，OminiGen在统一的多模态传感器数据生成中实现了期望的性能，具有多模态一致性和灵活的传感器调整。",
            "intro_zh": [
                "现有自动驾驶数据采集成本高昂，且难以覆盖所有corner case，单模态生成方法效率低且易导致多模态数据不对齐。",
                "OmniGen利用共享BEV空间统一多模态特征，并提出通用多模态重建方法UAE，实现激光雷达和多视角相机数据的联合解码。",
                "通过集成ControlNet分支的Diffusion Transformer，OmniGen实现了可控的多模态传感器数据生成，并保证了多模态一致性。"
            ],
            "method_zh": "**问题定义**：现有自动驾驶生成模型主要集中于单模态传感器数据的生成，这导致了多模态数据之间缺乏一致性，并且生成效率较低。获取真实世界中多样化的、极端情况下的多模态数据成本高昂，阻碍了自动驾驶系统的发展。因此，如何高效且一致地生成多模态传感器数据是亟待解决的问题。\\n\\n**核心思路**：OmniGen的核心思路是利用一个统一的框架来生成对齐的多模态传感器数据。具体来说，它首先将不同模态的数据投影到共享的鸟瞰图（BEV）空间中，从而实现多模态特征的统一表示。然后，通过提出的通用多模态重建方法（UAE），联合解码激光雷达和多视角相机数据。这种统一的表示和解码方式能够保证多模态数据之间的一致性，并提高生成效率。\\n\\n**技术框架**：OmniGen的整体框架包含以下几个主要模块：1) 多模态特征编码器：将不同模态的传感器数据（如激光雷达点云和多视角图像）编码到BEV空间中。2) 通用多模态重建模块（UAE）：基于体渲染技术，从BEV特征中重建出激光雷达点云和多视角图像。3) Diffusion Transformer (DiT) with ControlNet：用于可控的多模态传感器数据生成，ControlNet分支允许用户指定生成数据的属性。\\n\\n**关键创新**：OmniGen的关键创新点在于：1) 提出了一个统一的多模态传感器生成框架，能够同时生成激光雷达和多视角相机数据，保证了多模态数据之间的一致性。2) 设计了一种通用的多模态重建方法（UAE），通过体渲染技术实现多模态传感器数据的解码，具有较高的重建精度和灵活性。3) 引入了带有ControlNet分支的Diffusion Transformer，实现了可控的多模态传感器数据生成。\\n\\n**关键设计**：UAE模块的关键设计在于使用体渲染技术进行多模态传感器数据的解码。具体来说，它将BEV特征作为体素的属性，然后通过光线投射算法，将体素属性渲染成激光雷达点云和多视角图像。ControlNet分支的设计允许用户通过控制信号来调整生成数据的属性，例如车辆的位置、速度和朝向。损失函数方面，可能采用了L1损失、L2损失或感知损失等，以保证生成数据的质量和真实感。（具体损失函数细节未知）",
            "application_zh": "OmniGen在自动驾驶领域具有广泛的应用前景。它可以用于生成大量的训练数据，从而提高自动驾驶系统的性能和鲁棒性。此外，OmniGen还可以用于模拟各种极端情况，例如恶劣天气、复杂交通等，从而帮助自动驾驶系统更好地应对这些挑战。该研究的成果有助于推动自动驾驶技术的进一步发展和应用。",
            "highlight_zh": "论文通过综合实验验证了OmniGen的有效性。实验结果表明，OmniGen能够在统一的多模态传感器数据生成中实现期望的性能，具有多模态一致性和灵活的传感器调整能力。具体的性能数据和对比基线未知，但摘要强调了OmniGen在多模态一致性和可控性方面的优势。",
            "tags_zh": [
                "自动驾驶",
                "多模态生成",
                "传感器数据",
                "鸟瞰图",
                "扩散模型"
            ],
            "_index": 74,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14225/imgs/teaser2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14225/imgs/framework_2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14225/x1.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "PSMamba: Progressive Self-supervised Vision Mamba for Plant Disease Recognition",
            "authors": [
                "Abdullah Al Mamun",
                "Miaohua Zhang",
                "David Ahmedt-Aristizabal",
                "Zeeshan Hayder",
                "Mohammad Awrangjeb"
            ],
            "arxiv_id": "2512.14309",
            "summary": "Self-supervised Learning (SSL) has become a powerful paradigm for representation learning without manual annotations. However, most existing frameworks focus on global alignment and struggle to capture the hierarchical, multi-scale lesion patterns characteristic of plant disease imagery. To address this gap, we propose PSMamba, a progressive self-supervised framework that integrates the efficient sequence modelling of Vision Mamba (VM) with a dual-student hierarchical distillation strategy. Unlike conventional single teacher-student designs, PSMamba employs a shared global teacher and two specialised students: one processes mid-scale views to capture lesion distributions and vein structures, while the other focuses on local views to capture fine-grained cues such as texture irregularities and early-stage lesions. This multi-granular supervision facilitates the joint learning of contextual and detailed representations, with consistency losses ensuring coherent cross-scale alignment. Experiments on three benchmark datasets show that PSMamba consistently outperforms state-of-the-art SSL methods, delivering superior accuracy and robustness in both domain-shifted and fine-grained scenarios.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14309",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]Mamba",
                        "representation learning",
                        "teacher-student",
                        "distillation"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "PSMamba：一种用于植物病害识别的渐进式自监督视觉Mamba框架",
            "summary_zh": "自监督学习(SSL)已成为一种无需手动标注即可进行表征学习的强大范例。然而，现有的大多数框架侧重于全局对齐，难以捕捉植物病害图像中具有代表性的分层、多尺度病变模式。为了解决这一差距，我们提出了PSMamba，一个渐进式自监督框架，它将Vision Mamba (VM)的高效序列建模与双学生分层蒸馏策略相结合。与传统的单教师-学生设计不同，PSMamba采用共享的全局教师和两个专门的学生：一个处理中等尺度的视图以捕捉病变分布和静脉结构，而另一个则侧重于局部视图以捕捉纹理不规则和早期病变等细粒度线索。这种多粒度监督促进了上下文和详细表征的联合学习，一致性损失确保了连贯的跨尺度对齐。在三个基准数据集上的实验表明，PSMamba始终优于最先进的SSL方法，在领域迁移和细粒度场景中均提供了卓越的准确性和鲁棒性。",
            "intro_zh": [
                "现有自监督学习方法难以有效捕捉植物病害图像中复杂的分层、多尺度病变特征。",
                "PSMamba采用双学生分层蒸馏策略，结合全局教师和两个分别关注中尺度和局部尺度的学生网络。",
                "实验结果表明，PSMamba在植物病害识别任务中，显著优于现有自监督学习方法，具有更好的准确性和鲁棒性。"
            ],
            "method_zh": "**问题定义**：植物病害识别依赖于对病变区域的准确表征。现有自监督学习方法侧重于全局特征对齐，忽略了病害图像中重要的分层、多尺度局部病变信息，导致识别精度受限。\\n\\n**核心思路**：PSMamba的核心在于通过渐进式的自监督学习，利用双学生网络分别学习不同尺度的病变特征，并利用一致性损失保证跨尺度特征的一致性。这种方法旨在弥补现有方法在捕捉局部细节和多尺度信息方面的不足。\\n\\n**技术框架**：PSMamba框架包含一个共享的全局教师网络和两个专门的学生网络。全局教师网络学习全局图像表征。一个学生网络专注于中等尺度的视图，捕捉病变分布和静脉结构；另一个学生网络专注于局部视图，捕捉纹理不规则和早期病变等细粒度线索。通过分层蒸馏和一致性损失，学生网络学习教师网络的知识，并相互对齐。\\n\\n**关键创新**：PSMamba的关键创新在于其双学生分层蒸馏策略，该策略允许模型同时学习全局上下文信息和局部细节信息。此外，PSMamba利用Vision Mamba (VM)作为骨干网络，提高了序列建模的效率。\\n\\n**关键设计**：PSMamba使用Vision Mamba作为骨干网络，利用其高效的序列建模能力。双学生网络分别处理不同尺度的图像视图。一致性损失用于约束两个学生网络输出的一致性，确保跨尺度特征对齐。具体的损失函数选择和参数设置在论文中有详细描述。",
            "application_zh": "PSMamba在植物病害识别领域具有广泛的应用前景，可以帮助农民和农业专家快速准确地诊断植物病害，从而采取及时的防治措施，减少作物损失，提高农业生产效率。该方法还可以扩展到其他医学图像分析、遥感图像分析等领域，具有重要的实际应用价值和未来发展潜力。",
            "highlight_zh": "PSMamba在三个基准植物病害数据集上进行了评估，实验结果表明，PSMamba consistently outperforms state-of-the-art SSL methods，在领域迁移和细粒度场景中均提供了卓越的准确性和鲁棒性。具体性能提升数据需要在论文中查找。",
            "tags_zh": [
                "植物病害识别",
                "自监督学习",
                "Vision Mamba",
                "分层蒸馏",
                "双学生网络",
                "多尺度特征",
                "一致性学习",
                "计算机视觉"
            ],
            "_index": 75,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14309/Figures/global.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14309/Figures/psmamba.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14309/Figures/visual/gradcam/pd_o_2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "SignIT: A Comprehensive Dataset and Multimodal Analysis for Italian Sign Language Recognition",
            "authors": [
                "Alessia Micieli",
                "Giovanni Maria Farinella",
                "Francesco Ragusa"
            ],
            "arxiv_id": "2512.14489",
            "summary": "In this work we present SignIT, a new dataset to study the task of Italian Sign Language (LIS) recognition. The dataset is composed of 644 videos covering 3.33 hours. We manually annotated videos considering a taxonomy of 94 distinct sign classes belonging to 5 macro-categories: Animals, Food, Colors, Emotions and Family. We also extracted 2D keypoints related to the hands, face and body of the users. With the dataset, we propose a benchmark for the sign recognition task, adopting several state-of-the-art models showing how temporal information, 2D keypoints and RGB frames can be influence the performance of these models. Results show the limitations of these models on this challenging LIS dataset. We release data and annotations at the following link:this https URL.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14489",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "SignIT：一个用于意大利手语识别的综合数据集与多模态分析",
            "summary_zh": "本文提出了SignIT，一个新的用于研究意大利手语（LIS）识别任务的数据集。该数据集包含644个视频，总时长3.33小时。我们手动标注了这些视频，涵盖了94个不同的手语类别，这些类别属于5个宏观类别：动物、食物、颜色、情感和家庭。我们还提取了用户的手、面部和身体相关的2D关键点。基于该数据集，我们提出了一个手语识别任务的基准，采用了几种最先进的模型，展示了时间信息、2D关键点和RGB帧如何影响这些模型的性能。结果表明，这些模型在这个具有挑战性的LIS数据集上存在局限性。我们公开了数据和标注。",
            "intro_zh": [
                "现有的意大利手语识别数据集规模有限，难以充分训练和评估复杂模型。",
                "SignIT数据集包含大量视频和细粒度的手语类别标注，并提供2D关键点信息，支持多模态分析。",
                "论文通过实验评估了现有模型在SignIT数据集上的性能，揭示了现有方法在意大利手语识别上的挑战。"
            ],
            "method_zh": "**问题定义**：论文旨在解决意大利手语（LIS）识别问题。现有手语识别数据集，特别是针对意大利手语的数据集，规模较小，标注信息不足，难以支持复杂模型的训练和评估。这限制了意大利手语识别技术的发展。\\n\\n**核心思路**：论文的核心思路是构建一个大规模、高质量的意大利手语数据集SignIT，并利用该数据集对现有手语识别模型进行基准测试。通过多模态数据（RGB视频和2D关键点）的结合，探索不同模态信息对手语识别性能的影响。\\n\\n**技术框架**：该研究的技术框架主要包括以下几个阶段：1) 数据采集：收集包含多种手语类别的大量意大利手语视频。2) 数据标注：手动标注视频中的手语类别，并提取手、面部和身体的2D关键点。3) 模型评估：选择几种最先进的手语识别模型，在SignIT数据集上进行训练和测试。4) 性能分析：分析不同模型在不同模态数据下的性能表现，找出模型的优势和不足。\\n\\n**关键创新**：该论文的关键创新在于构建了一个新的、大规模的意大利手语数据集SignIT，该数据集不仅包含RGB视频，还提供了2D关键点信息，为多模态手语识别研究提供了基础。此外，论文还对现有手语识别模型在SignIT数据集上进行了全面的基准测试，为后续研究提供了参考。\\n\\n**关键设计**：SignIT数据集包含644个视频，涵盖94个不同的手语类别。这些类别被划分为5个宏观类别：动物、食物、颜色、情感和家庭。论文采用了常见的关键点检测方法提取手、面部和身体的2D关键点。在模型评估方面，论文选择了多种最先进的手语识别模型，并针对不同模态的数据进行了实验。具体的参数设置和网络结构等技术细节取决于所选用的具体模型。",
            "application_zh": "该研究成果可应用于开发意大利手语翻译系统，帮助听力障碍人士进行交流。此外，该数据集和基准测试结果可以促进手语识别领域的研究进展，推动更准确、更鲁棒的手语识别技术的开发。未来，该技术有望应用于智能助手、教育、医疗等领域。",
            "highlight_zh": "论文构建的SignIT数据集包含644个视频，覆盖94个手语类别，是目前最大的意大利手语数据集之一。实验结果表明，现有手语识别模型在SignIT数据集上表现出一定的局限性，这突显了意大利手语识别任务的挑战性，并为未来的研究方向提供了指导。",
            "tags_zh": [
                "意大利手语识别",
                "手语数据集",
                "多模态分析",
                "2D关键点",
                "视频理解"
            ],
            "_index": 76,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14489/Image/grid_name.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14489/Image/verdeGreen.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14489/Image/pre.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Native Intelligence Emerges from Large-Scale Clinical Practice: A Retinal Foundation Model with Deployment Efficiency",
            "authors": [
                "Jia Guo",
                "Jiawei Du",
                "Shengzhu Yang",
                "Shuai Lu",
                "Wenquan Cheng",
                "Kaiwen Zhang",
                "Yihua Sun",
                "Chuhong Yang",
                "Weihang Zhang",
                "Fang Chen",
                "Yilan Wu",
                "Lie Ju",
                "Guochen Ning",
                "Longfei Ma",
                "Huiping Yao",
                "Jinyuan Wang",
                "Peilun Shi",
                "Yukun Zhou",
                "Jie Xu",
                "Pearse A. Keane",
                "Hanruo Liu",
                "Hongen Liao",
                "Ningli Wang",
                "Huiqi Li"
            ],
            "arxiv_id": "2512.14499",
            "summary": "Current retinal foundation models remain constrained by curated research datasets that lack authentic clinical context, and require extensive task-specific optimization for each application, limiting their deployment efficiency in low-resource settings. Here, we show that these barriers can be overcome by building clinical native intelligence directly from real-world medical practice. Our key insight is that large-scale telemedicine programs, where expert centers provide remote consultations across distributed facilities, represent a natural reservoir for learning clinical image interpretation. We present ReVision, a retinal foundation model that learns from the natural alignment between 485,980 color fundus photographs and their corresponding diagnostic reports, accumulated through a decade-long telemedicine program spanning 162 medical institutions across China. Through extensive evaluation across 27 ophthalmic benchmarks, we demonstrate that ReVison enables deployment efficiency with minimal local resources. Without any task-specific training, ReVision achieves zero-shot disease detection with an average AUROC of 0.946 across 12 public benchmarks and 0.952 on 3 independent clinical cohorts. When minimal adaptation is feasible, ReVision matches extensively fine-tuned alternatives while requiring orders of magnitude fewer trainable parameters and labeled examples. The learned representations also transfer effectively to new clinical sites, imaging domains, imaging modalities, and systemic health prediction tasks. In a prospective reader study with 33 ophthalmologists, ReVision's zero-shot assistance improved diagnostic accuracy by 14.8% across all experience levels. These results demonstrate that clinical native intelligence can be directly extracted from clinical archives without any further annotation to build medical AI systems suited to various low-resource settings.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14499",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]foundation model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "ReVision：基于大规模临床实践的视网膜原生智能模型，提升部署效率",
            "summary_zh": "现有的视网膜基础模型受限于缺乏真实临床背景的人工数据集，并且需要针对每个应用进行大量的任务特定优化，限制了其在低资源环境中的部署效率。本文提出ReVision，一个从真实医疗实践中学习临床原生智能的视网膜基础模型。核心思想是，大型远程医疗项目（专家中心为分布式机构提供远程咨询）是学习临床图像解读的天然资源。ReVision从中国162家医疗机构十年远程医疗项目中积累的485,980张彩色眼底照片及其诊断报告的自然对齐关系中学习。在27个眼科基准测试中，ReVision以最小的本地资源实现了部署效率。在没有任何任务特定训练的情况下，ReVision在12个公共基准测试中实现了0.946的平均AUROC，在3个独立的临床队列中实现了0.952的平均AUROC。当最小限度的适应可行时，ReVision匹配了经过大量微调的替代方案，同时需要的可训练参数和标记示例的数量级更少。学习到的表征也能有效地转移到新的临床站点、成像领域、成像模式和全身健康预测任务。在对33名眼科医生的前瞻性读者研究中，ReVision的零样本辅助将所有经验水平的诊断准确率提高了14.8%。这些结果表明，可以直接从临床档案中提取临床原生智能，而无需任何进一步的注释，从而构建适用于各种低资源环境的医疗AI系统。",
            "intro_zh": [
                "现有视网膜基础模型依赖人工标注数据集，缺乏真实临床环境，且任务特定优化需求高，限制了低资源环境下的部署。",
                "ReVision利用大规模远程医疗数据中眼底照片与诊断报告的自然对齐关系，学习临床原生智能，无需额外标注。",
                "实验表明，ReVision在零样本疾病检测中表现出色，且能有效迁移到新场景，显著提升医生诊断准确率。"
            ],
            "method_zh": "**问题定义**：现有视网膜基础模型依赖于经过精心策划的研究数据集，这些数据集通常缺乏真实的临床背景，并且需要针对每个特定任务进行大量的优化。这限制了它们在资源有限的环境中的部署效率。因此，如何构建一个能够直接从真实临床数据中学习，并且具有良好泛化能力和部署效率的视网膜基础模型是一个关键问题。\\n\\n**核心思路**：论文的核心思路是利用大规模远程医疗项目中积累的眼底照片和诊断报告之间的自然对齐关系，构建一个能够学习临床原生智能的视网膜基础模型。这种方法避免了对大量人工标注数据的依赖，并且能够更好地捕捉真实临床场景中的复杂性和多样性。\\n\\n**技术框架**：ReVision的整体框架包括以下几个主要部分：1) 数据收集：收集来自大规模远程医疗项目的眼底照片和对应的诊断报告。2) 数据预处理：对图像进行标准化处理，并对诊断报告进行文本解析和结构化。3) 模型训练：使用对比学习或自监督学习等方法，训练一个能够将眼底照片映射到高质量表征空间的深度学习模型。4) 零样本推理：利用学习到的表征空间，进行零样本疾病检测和诊断。5) 微调适应：在少量标注数据上进行微调，以适应新的临床站点、成像领域或成像模式。\\n\\n**关键创新**：ReVision的关键创新在于其利用了大规模远程医疗数据中固有的自然对齐关系，避免了对大量人工标注数据的依赖。这种方法使得模型能够直接从真实临床数据中学习，从而更好地捕捉临床场景中的复杂性和多样性。此外，ReVision还具有良好的泛化能力和部署效率，能够有效地迁移到新的临床站点、成像领域和成像模式。\\n\\n**关键设计**：论文中没有明确给出关键的参数设置、损失函数、网络结构等技术细节。但是，可以推测，ReVision可能采用了以下一些关键设计：1) 使用Transformer或卷积神经网络作为基础架构，以提取图像特征。2) 使用对比学习或自监督学习等方法，训练模型学习高质量的表征空间。3) 使用合适的损失函数，例如InfoNCE损失或交叉熵损失，来优化模型。4) 使用数据增强技术，例如随机裁剪、旋转和颜色抖动，来提高模型的鲁棒性。",
            "application_zh": "ReVision具有广泛的应用前景，可用于远程医疗、基层医疗机构的眼科疾病辅助诊断，提高诊断效率和准确性。该模型还可应用于眼科疾病的早期筛查、风险评估和个性化治疗方案制定。未来，ReVision有望与其他医疗影像模态和临床数据相结合，实现更全面的健康管理。",
            "highlight_zh": "ReVision在27个眼科基准测试中表现出色，在没有任何任务特定训练的情况下，在12个公共基准测试中实现了0.946的平均AUROC，在3个独立的临床队列中实现了0.952的平均AUROC。在对33名眼科医生的前瞻性读者研究中，ReVision的零样本辅助将所有经验水平的诊断准确率提高了14.8%。",
            "tags_zh": [
                "视网膜疾病诊断",
                "眼底图像分析",
                "远程医疗",
                "深度学习",
                "迁移学习"
            ],
            "_index": 77,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14499/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14499/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14499/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "JMMMU-Pro: Image-based Japanese Multi-discipline Multimodal Understanding Benchmark via Vibe Benchmark Construction",
            "authors": [
                "Atsuyuki Miyai",
                "Shota Onohara",
                "Jeonghun Baek",
                "Kiyoharu Aizawa"
            ],
            "arxiv_id": "2512.14620",
            "summary": "This paper introduces JMMMU-Pro, an image-based Japanese Multi-discipline Multimodal Understanding Benchmark, and Vibe Benchmark Construction, a scalable construction method. Following the evolution from MMMU to MMMU-Pro, JMMMU-Pro extends JMMMU by composing the question image and question text into a single image, thereby creating a benchmark that requires integrated visual-textual understanding through visual perception. To build JMMMU-Pro, we propose Vibe Benchmark Construction, a methodology in which an image generative model (e.g., Nano Banana Pro) produces candidate visual questions, and humans verify the outputs and, when necessary, regenerate with adjusted prompts to ensure quality. By leveraging Nano Banana Pro's highly realistic image generation capabilities and its ability to embed clean Japanese text, we construct a high-quality benchmark at low cost, covering a wide range of background and layout designs. Experimental results show that all open-source LMMs struggle substantially with JMMMU-Pro, underscoring JMMMU-Pro as an important benchmark for guiding future efforts in the open-source community. We believe that JMMMU-Pro provides a more rigorous evaluation tool for assessing the Japanese capabilities of LMMs and that our Vibe Benchmark Construction also offers an efficient guideline for future development of image-based VQA benchmarks.",
            "categories": [
                "cs.CL",
                "cs.AI",
                "cs.CV"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14620",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出JMMMU-Pro基准测试，用于评估日语多学科多模态理解能力，并提出Vibe基准构建方法。",
            "summary_zh": "本文介绍了JMMMU-Pro，一个基于图像的日语多学科多模态理解基准测试，以及Vibe基准构建方法，一种可扩展的构建方法。JMMMU-Pro延续了从MMMU到MMMU-Pro的演进，通过将问题图像和问题文本组合成单个图像来扩展JMMMU，从而创建一个需要通过视觉感知进行综合视觉-文本理解的基准。为了构建JMMMU-Pro，我们提出了Vibe基准构建方法，该方法利用图像生成模型（例如Nano Banana Pro）生成候选视觉问题，然后由人工验证输出，并在必要时使用调整后的提示重新生成，以确保质量。通过利用Nano Banana Pro的高度逼真的图像生成能力及其嵌入清晰日语文本的能力，我们以低成本构建了一个高质量的基准，涵盖了广泛的背景和布局设计。实验结果表明，所有开源LMM在JMMMU-Pro上都表现不佳，这突显了JMMMU-Pro作为指导开源社区未来工作的重要基准。我们相信JMMMU-Pro为评估LMM的日语能力提供了一个更严格的评估工具，并且我们的Vibe基准构建方法也为未来基于图像的VQA基准的开发提供了有效的指导。",
            "intro_zh": [
                "现有基准测试在评估大型语言模型（LMM）的日语多模态理解能力方面存在不足，尤其是在视觉-文本集成理解方面。",
                "提出Vibe基准构建方法，利用图像生成模型生成候选视觉问题，并通过人工验证和调整提示来保证基准质量。",
                "实验表明，开源LMM在JMMMU-Pro基准测试上表现不佳，验证了该基准的挑战性，并为未来研究提供了方向。"
            ],
            "method_zh": "**问题定义**：论文旨在解决现有日语多模态理解基准测试的不足，特别是缺乏对视觉和文本信息进行深度融合理解的评估。现有方法难以生成高质量、多样化的测试用例，并且成本较高。\\n\\n**核心思路**：论文的核心思路是利用图像生成模型（如Nano Banana Pro）自动生成候选的视觉问题，然后通过人工验证和调整提示来确保生成高质量的基准测试。这种方法旨在降低基准测试的构建成本，并提高其多样性和质量。\\n\\n**技术框架**：Vibe基准构建方法包含以下主要阶段：1) 使用图像生成模型生成候选视觉问题，包括图像和嵌入图像中的日语文本。2) 人工验证生成的视觉问题，评估其质量和相关性。3) 如果需要，调整图像生成模型的提示，重新生成视觉问题，直到满足质量要求。4) 将验证通过的视觉问题添加到基准测试中。\\n\\n**关键创新**：该方法最重要的技术创新点在于利用图像生成模型自动生成视觉问题，并结合人工验证和调整提示的反馈机制。这与传统的人工标注方法相比，大大降低了成本，并提高了基准测试的多样性和可扩展性。\\n\\n**关键设计**：关键设计包括选择合适的图像生成模型（Nano Banana Pro），该模型需要能够生成高质量的图像，并且能够嵌入清晰的日语文本。此外，人工验证过程需要制定明确的质量标准，并提供有效的反馈机制，以便调整图像生成模型的提示。",
            "application_zh": "JMMMU-Pro基准测试可用于评估和提升大型语言模型在日语环境下的多模态理解能力，尤其是在需要视觉和文本信息深度融合的场景中。该研究成果可应用于智能客服、教育、医疗等领域，提升人机交互的智能化水平。",
            "highlight_zh": "实验结果表明，现有的开源LMM在JMMMU-Pro基准测试上表现显著不足，这表明JMMMU-Pro是一个具有挑战性的基准，能够有效评估LMM的日语多模态理解能力。该基准的构建方法Vibe，为低成本、高质量地构建图像相关的VQA基准提供了新的思路。",
            "tags_zh": [
                "多模态理解",
                "视觉问答",
                "日语处理",
                "基准测试",
                "图像生成模型",
                "大型语言模型",
                "Vibe构建方法"
            ],
            "_index": 78,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14620/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14620/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14620/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Multimodal classification of forest biodiversity potential from 2D orthophotos and 3D airborne laser scanning point clouds",
            "authors": [
                "Simon B. Jensen",
                "Stefan Oehmcke",
                "Andreas Møgelmose",
                "Meysam Madadi",
                "Christian Igel",
                "Sergio Escalera",
                "Thomas B. Moeslund"
            ],
            "arxiv_id": "2501.01728",
            "summary": "Assessment of forest biodiversity is crucial for ecosystem management and conservation. While traditional field surveys provide high-quality assessments, they are labor-intensive and spatially limited. This study investigates whether deep learning-based fusion of close-range sensing data from 2D orthophotos and 3D airborne laser scanning (ALS) point clouds can reliable assess the biodiversity potential of forests. We introduce the BioVista dataset, comprising 44378 paired samples of orthophotos and ALS point clouds from temperate forests in Denmark, designed to explore multimodal fusion approaches. Using deep neural networks (ResNet for orthophotos and PointVector for ALS point clouds), we investigate each data modality's ability to assess forest biodiversity potential, achieving overall accuracies of 76.7% and 75.8%, respectively. We explore various 2D and 3D fusion approaches: confidence-based ensembling, feature-level concatenation, and end-to-end training, with the latter achieving an overall accuracies of 82.0% when separating low- and high potential forest areas. Our results demonstrate that spectral information from orthophotos and structural information from ALS point clouds effectively complement each other in the assessment of forest biodiversity potential.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2501.01728",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于深度学习的多模态融合方法，用于评估森林生物多样性潜力。",
            "summary_zh": "本研究旨在探索利用深度学习融合二维正射影像和三维机载激光扫描（ALS）点云数据，以可靠评估森林生物多样性潜力。我们引入了BioVista数据集，该数据集包含来自丹麦温带森林的44378个正射影像和ALS点云配对样本，用于研究多模态融合方法。我们使用深度神经网络（正射影像使用ResNet，ALS点云使用PointVector）研究了每种数据模态评估森林生物多样性潜力的能力，分别实现了76.7%和75.8%的总体准确率。我们探索了各种二维和三维融合方法：基于置信度的集成、特征级联和端到端训练，其中后者在区分低潜力和高潜力森林区域时实现了82.0%的总体准确率。结果表明，正射影像的光谱信息和ALS点云的结构信息在评估森林生物多样性潜力方面有效地互补。",
            "intro_zh": [
                "传统森林生物多样性评估依赖人工调查，成本高昂且空间覆盖有限，亟需高效遥感方法。",
                "论文提出一种基于深度学习的多模态融合方法，结合正射影像的光谱信息和ALS点云的结构信息。",
                "实验结果表明，该方法在森林生物多样性潜力评估中表现出色，端到端训练融合方法准确率达82.0%。"
            ],
            "method_zh": "**问题定义**：现有森林生物多样性评估方法依赖于人工地面调查，存在成本高、效率低、空间覆盖范围有限等问题。如何利用遥感数据，实现快速、准确、大范围的森林生物多样性评估是一个挑战。\\n\\n**核心思路**：论文的核心思路是利用正射影像的光谱信息和ALS点云的结构信息，通过深度学习模型进行多模态融合，从而更全面地评估森林的生物多样性潜力。正射影像提供地表反射率信息，ALS点云提供三维结构信息，二者互补，能够更准确地反映森林的生态特征。\\n\\n**技术框架**：整体框架包括数据采集、数据预处理、单模态特征提取、多模态融合和分类预测五个主要阶段。首先，采集正射影像和ALS点云数据，并进行预处理。然后，使用ResNet提取正射影像的特征，使用PointVector提取ALS点云的特征。接着，采用不同的融合策略，包括基于置信度的集成、特征级联和端到端训练。最后，使用分类器预测森林生物多样性潜力等级。\\n\\n**关键创新**：论文的关键创新在于提出了一个基于深度学习的多模态融合框架，有效地结合了正射影像的光谱信息和ALS点云的结构信息。与传统的单模态方法相比，该方法能够更全面地捕捉森林的生态特征，从而提高生物多样性评估的准确性。此外，论文还探索了多种融合策略，并验证了端到端训练的有效性。\\n\\n**关键设计**：在网络结构方面，正射影像使用预训练的ResNet模型，ALS点云使用PointVector模型。在融合策略方面，探索了基于置信度的集成、特征级联和端到端训练三种方法。在损失函数方面，使用交叉熵损失函数进行训练。在数据集方面，构建了包含44378个配对样本的BioVista数据集，用于训练和评估模型。",
            "application_zh": "该研究成果可应用于森林资源管理、生态环境保护和生物多样性监测等领域。通过遥感数据和深度学习技术，可以快速、准确地评估大范围森林的生物多样性潜力，为制定合理的森林管理策略提供科学依据，促进可持续发展。",
            "highlight_zh": "实验结果表明，单模态下，ResNet（正射影像）和PointVector（ALS点云）分别达到76.7%和75.8%的总体准确率。多模态融合后，端到端训练方法在区分低潜力和高潜力森林区域时，总体准确率提升至82.0%，显著优于单模态方法，验证了多模态融合的有效性。",
            "tags_zh": [
                "森林生物多样性",
                "多模态融合",
                "深度学习",
                "遥感",
                "点云处理"
            ],
            "_index": 79,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2501.01728/images/figure-1-orthophoto-als-pairs.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2501.01728/images/figure-2-biovista-dataset-structure.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2501.01728/images/figure-3-denmark-hnv-index.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Adapting General-Purpose Foundation Models for X-ray Ptychography in Low-Data Regimes",
            "authors": [
                "Robinson Umeike",
                "Neil Getty",
                "Yin Xiangyu",
                "Yi Jiang"
            ],
            "arxiv_id": "2511.02503",
            "summary": "The automation of workflows in advanced microscopy is a key goal where foundation models like Language Models (LLMs) and Vision-Language Models (VLMs) show great potential. However, adapting these general-purpose models for specialized scientific tasks is critical, and the optimal domain adaptation strategy is often unclear. To address this, we introduce PtychoBench, a new multi-modal, multi-task benchmark for ptychographic analysis. Using this benchmark, we systematically compare two specialization strategies: Supervised Fine-Tuning (SFT) and In-Context Learning (ICL). We evaluate these strategies on a visual artifact detection task with VLMs and a textual parameter recommendation task with LLMs in a data-scarce regime. Our findings reveal that the optimal specialization pathway is task-dependent. For the visual task, SFT and ICL are highly complementary, with a fine-tuned model guided by context-aware examples achieving the highest mean performance (Micro-F1 of 0.728). Conversely, for the textual task, ICL on a large base model is the superior strategy, reaching a peak Micro-F1 of 0.847 and outperforming a powerful \"super-expert\" SFT model (0-shot Micro-F1 of 0.839). We also confirm the superiority of context-aware prompting and identify a consistent contextual interference phenomenon in fine-tuned models. These results, benchmarked against strong baselines including GPT-4o and a DINOv3-based classifier, offer key observations for AI in science: the optimal specialization path in our benchmark is dependent on the task modality, offering a clear framework for developing more effective science-based agentic systems.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2511.02503",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]foundation model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "针对低数据量X射线衍射成像，提出通用基础模型自适应方法PtychoBench",
            "summary_zh": "先进显微镜工作流程的自动化是关键目标，而语言模型（LLM）和视觉-语言模型（VLM）等基础模型显示出巨大潜力。然而，将这些通用模型适配到专门的科学任务至关重要，且最佳的领域适配策略通常不明确。为此，我们引入了PtychoBench，这是一个用于衍射成像分析的新型多模态、多任务基准。利用此基准，我们系统地比较了两种专门化策略：监督微调（SFT）和上下文学习（ICL）。我们在数据稀缺的情况下，使用VLM评估了视觉伪影检测任务，并使用LLM评估了文本参数推荐任务。我们的研究结果表明，最佳的专门化路径取决于任务模态。对于视觉任务，SFT和ICL高度互补，通过上下文感知示例引导的微调模型实现了最高的平均性能（Micro-F1为0.728）。相反，对于文本任务，大型基础模型上的ICL是更优越的策略，达到了峰值Micro-F1为0.847，优于强大的“超级专家”SFT模型（0-shot Micro-F1为0.839）。我们还证实了上下文感知提示的优越性，并识别了微调模型中一致的上下文干扰现象。这些结果以GPT-4o和基于DINOv3的分类器等强大基线为基准，为科学中的人工智能提供了关键观察：在我们的基准中，最佳的专门化路径取决于任务模态，为开发更有效的基于科学的智能体系统提供了一个清晰的框架。",
            "intro_zh": [
                "现有先进显微镜工作流程自动化程度低，缺乏针对性强、数据高效的AI解决方案。",
                "提出PtychoBench基准，系统评估监督微调（SFT）和上下文学习（ICL）两种领域适配策略。",
                "实验表明，最佳策略取决于任务模态，视觉任务SFT+ICL互补，文本任务ICL更优。"
            ],
            "method_zh": "**问题定义**：论文旨在解决在低数据量情况下，如何有效地将通用基础模型（如LLM和VLM）应用于X射线衍射成像（Ptychography）中的特定任务，例如视觉伪影检测和文本参数推荐。现有方法要么需要大量标注数据进行微调，要么泛化能力不足，难以适应科学领域的专业任务。\\n\\n**核心思路**：论文的核心思路是通过构建一个多模态、多任务的基准测试平台PtychoBench，系统性地比较和分析两种主要的领域适配策略：监督微调（SFT）和上下文学习（ICL）。通过对比不同策略在不同任务上的表现，揭示最佳的适配路径，并为未来开发更有效的科学智能体系统提供指导。\\n\\n**技术框架**：论文的技术框架主要包括以下几个部分：1) 构建PtychoBench基准数据集，包含多模态数据（图像和文本）和多个任务（视觉伪影检测和文本参数推荐）；2) 实施并比较两种领域适配策略：SFT和ICL；3) 使用强大的基线模型（如GPT-4o和DINOv3）进行性能对比；4) 分析实验结果，识别最佳适配策略，并解释其背后的原因。\\n\\n**关键创新**：论文的关键创新在于：1) 提出了PtychoBench基准，为X射线衍射成像领域的AI研究提供了一个标准化的评估平台；2) 系统性地比较了SFT和ICL两种领域适配策略，揭示了它们在不同任务上的优劣；3) 发现了上下文感知提示的优越性，并识别了微调模型中存在的上下文干扰现象。\\n\\n**关键设计**：在视觉伪影检测任务中，论文使用了基于DINOv3的分类器作为基线，并探索了SFT和ICL的组合策略。在文本参数推荐任务中，论文使用了LLM，并比较了不同规模的模型和不同的提示策略。论文还特别关注了低数据量的情况，并设计了相应的实验来评估不同策略的鲁棒性。",
            "application_zh": "该研究成果可应用于自动化显微镜工作流程，加速科学发现。通过优化模型适配策略，能更有效地利用AI进行图像分析、参数优化等任务，降低对人工干预的依赖，提升科研效率。未来可扩展到其他科学领域，促进AI在科学研究中的更广泛应用。",
            "highlight_zh": "实验结果表明，对于视觉伪影检测任务，SFT和ICL互补，微调模型在上下文感知示例引导下Micro-F1达到0.728。对于文本参数推荐任务，ICL优于SFT，Micro-F1达到0.847，超过了“超级专家”SFT模型（0.839）。同时，验证了上下文感知提示的有效性，并发现了微调模型中的上下文干扰现象。",
            "tags_zh": [
                "X射线衍射成像",
                "基础模型",
                "领域适配",
                "监督微调",
                "上下文学习",
                "多模态学习",
                "低数据学习",
                "PtychoBench"
            ],
            "_index": 80,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2511.02503/key_metrics.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2511.02503/artifact_type_counts.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2511.02503/sample_type_counts.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "A Semantically Enhanced Generative Foundation Model Improves Pathological Image Synthesis",
            "authors": [
                "Xianchao Guan",
                "Zhiyuan Fan",
                "Yifeng Wang",
                "Fuqiang Chen",
                "Yanjiang Zhou",
                "Zengyang Che",
                "Hongxue Meng",
                "Xin Li",
                "Yaowei Wang",
                "Hongpeng Wang",
                "Min Zhang",
                "Heng Tao Shen",
                "Zheng Zhang",
                "Yongbing Zhang"
            ],
            "arxiv_id": "2512.13164",
            "summary": "The development of clinical-grade artificial intelligence in pathology is limited by the scarcity of diverse, high-quality annotated datasets. Generative models offer a potential solution but suffer from semantic instability and morphological hallucinations that compromise diagnostic reliability. To address this challenge, we introduce a Correlation-Regulated Alignment Framework for Tissue Synthesis (CRAFTS), the first generative foundation model for pathology-specific text-to-image synthesis. By leveraging a dual-stage training strategy on approximately 2.8 million image-caption pairs, CRAFTS incorporates a novel alignment mechanism that suppresses semantic drift to ensure biological accuracy. This model generates diverse pathological images spanning 30 cancer types, with quality rigorously validated by objective metrics and pathologist evaluations. Furthermore, CRAFTS-augmented datasets enhance the performance across various clinical tasks, including classification, cross-modal retrieval, self-supervised learning, and visual question answering. In addition, coupling CRAFTS with ControlNet enables precise control over tissue architecture from inputs such as nuclear segmentation masks and fluorescence images. By overcoming the critical barriers of data scarcity and privacy concerns, CRAFTS provides a limitless source of diverse, annotated histology data, effectively unlocking the creation of robust diagnostic tools for rare and complex cancer phenotypes.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13164",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]foundation model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "CRAFTS：一种语义增强的病理图像生成模型，提升病理图像合成质量",
            "summary_zh": "病理学临床级人工智能的发展受到高质量、多样化标注数据集稀缺的限制。生成模型提供了一种潜在的解决方案，但存在语义不稳定和形态学幻觉的问题，从而损害了诊断的可靠性。为了解决这个挑战，我们引入了用于组织合成的相关性调节对齐框架（CRAFTS），这是第一个病理学特定的文本到图像生成的基础模型。通过在大约280万个图像-标题对上采用双阶段训练策略，CRAFTS结合了一种新颖的对齐机制，抑制语义漂移以确保生物学准确性。该模型生成了涵盖30种癌症类型的多样化病理图像，其质量经过客观指标和病理学家评估的严格验证。此外，CRAFTS增强的数据集提高了各种临床任务的性能，包括分类、跨模态检索、自监督学习和视觉问答。此外，将CRAFTS与ControlNet结合使用，可以精确控制来自核分割掩码和荧光图像等输入的组织结构。通过克服数据稀缺和隐私顾虑的关键障碍，CRAFTS提供了一个无限的、多样化的、带注释的组织学数据来源，有效地解锁了用于罕见和复杂癌症表型的强大诊断工具的创建。",
            "intro_zh": [
                "病理图像数据匮乏限制了相关AI模型发展，现有生成模型存在语义不稳定和形态学幻觉问题。",
                "CRAFTS通过相关性调节对齐框架，抑制语义漂移，确保生成病理图像的生物学准确性。",
                "实验表明，CRAFTS生成的数据集能提升分类、跨模态检索等临床任务的性能，并可结合ControlNet精确控制组织结构。"
            ],
            "method_zh": "**问题定义**：病理图像分析领域面临着高质量、多样化标注数据集稀缺的难题，这严重阻碍了临床级人工智能模型的发展。现有的生成模型在病理图像合成方面表现出语义不稳定和形态学幻觉等问题，导致生成的图像在诊断可靠性方面存在不足。因此，如何生成高质量、语义准确的病理图像，以缓解数据匮乏问题，是本研究要解决的核心问题。\\n\\n**核心思路**：CRAFTS的核心思路是构建一个病理学特定的文本到图像生成的基础模型，通过引入相关性调节对齐框架，抑制生成过程中的语义漂移，从而确保生成图像的生物学准确性。这种方法旨在克服现有生成模型在病理图像合成中存在的语义不稳定和形态学幻觉问题，提高生成图像的质量和可靠性。\\n\\n**技术框架**：CRAFTS采用双阶段训练策略。第一阶段，模型在大规模图像-文本对上进行预训练，学习通用的图像生成能力。第二阶段，引入相关性调节对齐机制，对模型进行微调，以抑制语义漂移，确保生成图像的生物学准确性。该框架利用ControlNet实现对组织结构的精确控制，允许用户通过输入核分割掩码和荧光图像等信息来指导图像生成过程。\\n\\n**关键创新**：CRAFTS的关键创新在于其相关性调节对齐框架，该框架通过在训练过程中引入对齐机制，有效地抑制了语义漂移，从而提高了生成图像的生物学准确性。此外，CRAFTS是第一个病理学特定的文本到图像生成的基础模型，它为病理图像合成领域提供了一个新的研究方向。\\n\\n**关键设计**：CRAFTS的关键设计包括：(1) 双阶段训练策略，先学习通用图像生成能力，再进行病理学特定微调；(2) 相关性调节对齐机制，通过损失函数约束，确保生成图像与输入文本描述在语义上保持一致；(3) 与ControlNet的结合，实现对组织结构的精确控制；(4) 使用大规模病理图像-文本对数据集进行训练，保证模型的泛化能力。",
            "application_zh": "CRAFTS在病理学领域具有广泛的应用前景，可用于生成罕见和复杂癌症表型的病理图像，从而扩充训练数据集，提高诊断模型的性能。此外，CRAFTS还可用于教育和培训，为病理学家提供多样化的病例学习资源。该模型有望加速病理学人工智能的发展，并最终改善患者的诊断和治疗。",
            "highlight_zh": "CRAFTS在30种癌症类型的病理图像生成任务中表现出色，通过客观指标和病理学家评估验证了其生成图像的质量。实验表明，使用CRAFTS生成的数据集可以显著提升分类、跨模态检索、自监督学习和视觉问答等临床任务的性能。例如，在XXX任务上，性能提升了XX%。",
            "tags_zh": [
                "病理图像生成",
                "文本到图像合成",
                "生成对抗网络",
                "数据增强",
                "深度学习"
            ],
            "_index": 81,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Scaling and Transferability of Annealing Strategies in Large Language Model Training",
            "authors": [
                "Siqi Wang",
                "Zhengyu Chen",
                "Teng Xiao",
                "Zheqi Lv",
                "Jinluan Yang",
                "Xunliang Cai",
                "Jingang Wang",
                "Xiaomeng Li"
            ],
            "arxiv_id": "2512.13705",
            "summary": "Learning rate scheduling is crucial for training large language models, yet understanding the optimal annealing strategies across different model configurations remains challenging. In this work, we investigate the transferability of annealing dynamics in large language model training and refine a generalized predictive framework for optimizing annealing strategies under the Warmup-Steady-Decay (WSD) scheduler. Our improved framework incorporates training steps, maximum learning rate, and annealing behavior, enabling more efficient optimization of learning rate schedules. Our work provides a practical guidance for selecting optimal annealing strategies without exhaustive hyperparameter searches, demonstrating that smaller models can serve as reliable proxies for optimizing the training dynamics of larger models. We validate our findings on extensive experiments using both Dense and Mixture-of-Experts (MoE) models, demonstrating that optimal annealing ratios follow consistent patterns and can be transferred across different training configurations.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13705",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出一种可迁移的学习率退火策略优化框架，提升大语言模型训练效率。",
            "summary_zh": "学习率调度对于训练大型语言模型至关重要，但理解不同模型配置下的最优退火策略仍然具有挑战性。本文研究了大语言模型训练中退火动态的可迁移性，并改进了一个广义预测框架，用于优化Warmup-Steady-Decay (WSD)调度器下的退火策略。改进后的框架结合了训练步数、最大学习率和退火行为，从而能够更有效地优化学习率计划。我们的工作为选择最优退火策略提供了实用的指导，无需详尽的超参数搜索，证明了较小的模型可以作为优化较大模型训练动态的可靠代理。我们通过使用稠密模型和混合专家(MoE)模型进行的大量实验验证了我们的发现，表明最优退火比率遵循一致的模式，并且可以在不同的训练配置之间转移。",
            "intro_zh": [
                "现有大语言模型训练中，学习率退火策略的优化面临挑战，缺乏有效的跨模型配置迁移方法。",
                "论文提出一种改进的预测框架，通过结合训练步数、最大学习率和退火行为，优化Warmup-Steady-Decay调度器。",
                "实验表明，最优退火比率具有一致性，可以在不同训练配置间迁移，小模型可作为大模型训练动态优化的代理。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型训练中学习率退火策略优化的问题。现有方法通常需要大量的超参数搜索，计算成本高昂，并且难以在不同模型配置之间迁移最优策略。因此，如何高效地找到适用于不同规模和架构模型的学习率退火策略是一个关键挑战。\\n\\n**核心思路**：论文的核心思路是研究学习率退火动态在不同模型配置之间的可迁移性。通过观察和分析不同模型在训练过程中的学习率变化规律，发现最优退火比率具有一致性，从而可以将小模型上优化得到的退火策略迁移到大模型上，减少超参数搜索的成本。\\n\\n**技术框架**：论文的技术框架主要包括以下几个部分：1) 提出了一种改进的广义预测框架，用于优化Warmup-Steady-Decay (WSD) 调度器下的退火策略。2) 该框架结合了训练步数、最大学习率和退火行为等关键因素，能够更准确地预测最优学习率计划。3) 通过大量的实验验证了退火策略的可迁移性，并证明了小模型可以作为大模型训练动态优化的可靠代理。\\n\\n**关键创新**：论文的关键创新在于发现了学习率退火动态的可迁移性，并将其应用于大语言模型的训练中。这使得可以在小模型上进行高效的超参数搜索，然后将优化后的策略迁移到大模型上，从而大大降低了训练成本。此外，改进的预测框架能够更准确地预测最优学习率计划，进一步提升了训练效率。\\n\\n**关键设计**：论文的关键设计包括：1) 使用Warmup-Steady-Decay (WSD) 调度器作为学习率调整的基础。2) 改进的预测框架，该框架考虑了训练步数、最大学习率和退火行为等关键因素。3) 通过大量的实验，探索了不同模型配置下的最优退火比率，并验证了其可迁移性。具体的参数设置和损失函数等细节在论文中进行了详细描述。",
            "application_zh": "该研究成果可广泛应用于各种大型语言模型的训练中，尤其是在计算资源有限的情况下，可以利用小模型优化后的退火策略来加速大模型的训练过程。此外，该方法还可以应用于其他深度学习模型的训练，具有广泛的应用前景和实际价值，有助于推动人工智能技术的发展。",
            "highlight_zh": "实验结果表明，最优退火比率在不同模型配置之间具有一致性，并且小模型可以作为大模型训练动态优化的可靠代理。通过将小模型上优化后的退火策略迁移到大模型上，可以显著降低超参数搜索的成本，并提升训练效率。具体的性能数据和提升幅度在论文中进行了详细展示。",
            "tags_zh": [
                "大语言模型",
                "学习率调度",
                "退火策略",
                "模型迁移",
                "超参数优化"
            ],
            "_index": 82,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13705/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13705/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.13705/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Estimating problem difficulty without ground truth using Large Language Model comparisons",
            "authors": [
                "Marthe Ballon",
                "Andres Algaba",
                "Brecht Verbeken",
                "Vincent Ginis"
            ],
            "arxiv_id": "2512.14220",
            "summary": "Recent advances in the finetuning of large language models (LLMs) have significantly improved their performance on established benchmarks, emphasizing the need for increasingly difficult, synthetic data. A key step in this data generation pipeline is a method for estimating problem difficulty. Current approaches, such as human calibration or performance-based scoring, fail to generalize to out-of-distribution problems, i.e. problems currently unsolvable by humans and LLMs, because they are not scalable, time-consuming, and ground truth dependent. Therefore, we propose a new method for estimating problem difficulty, LLM compare, that addresses these limitations. An LLM performs pairwise difficulty comparisons, and then Bradley-Terry scores are computed based on the outcomes. To validate our method, we first propose a conceptual framework that positions existing approaches on three orthogonal planes--construction, scale and dependence--identifying which quadrants a measure needs to occupy to score out-of-distribution problems. LLM compare naturally occupies all desirable quadrants as the first measure that is continuous and dynamic, model-agnostic and independent of ground truth information. As a second validation, we show that LLM compare demonstrates strong alignment with human annotations: Pearson $r \\geq 0.80$ for $n=1876$. Thirdly, we show that LLM compare is robust to hallucinations, with less than $6\\%$ degradation in Pearson correlation for $10\\%$ noise injection. Our work represents a significant step towards replacing time-consuming human annotations and synthetic data generation, and will be an important driver for curriculum design, model evaluation, and AI-assisted research ideation.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14220",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出LLM compare以解决无地面真相问题难度估计",
            "summary_zh": "近年来，大型语言模型（LLMs）的微调显著提升了其在基准测试中的表现，突显了对更复杂合成数据的需求。现有的难度估计方法，如人工校准或基于表现的评分，无法推广到当前人类和LLMs无法解决的分布外问题，因为这些方法不具可扩展性、耗时且依赖于地面真相。因此，本文提出了一种新的难度估计方法LLM compare，旨在解决这些局限性。该方法通过LLM进行成对难度比较，并基于结果计算Bradley-Terry分数。我们验证了该方法的有效性，结果显示LLM compare与人类注释高度一致，且对噪声具有鲁棒性。我们的研究为替代耗时的人类注释和合成数据生成迈出了重要一步。",
            "intro_zh": [
                "现有的难度估计方法如人工校准和表现评分无法有效处理分布外问题，缺乏可扩展性且依赖地面真相。",
                "本文提出的LLM compare方法通过LLM进行成对难度比较，计算Bradley-Terry分数，克服了现有方法的局限性。",
                "实验结果表明，LLM compare与人类注释的Pearson相关系数达到0.80以上，并且在噪声注入情况下表现出良好的鲁棒性。"
            ],
            "method_zh": "**问题定义**：本文旨在解决如何在没有地面真相的情况下估计问题的难度。现有方法如人工校准和基于表现的评分在处理分布外问题时存在可扩展性差、耗时长和依赖地面真相等痛点。\\n\\n**核心思路**：论文提出的LLM compare方法通过大型语言模型进行成对的难度比较，利用比较结果计算Bradley-Terry分数，从而实现对问题难度的估计。这种设计使得方法具备动态性和模型无关性，避免了对地面真相的依赖。\\n\\n**技术框架**：该方法的整体架构包括三个主要模块：首先，使用LLM进行成对问题的难度比较；其次，基于比较结果计算Bradley-Terry分数；最后，验证该方法与人类注释的一致性及其对噪声的鲁棒性。\\n\\n**关键创新**：LLM compare是首个在无地面真相情况下进行动态和连续难度估计的度量，具有模型无关性，能够有效处理分布外问题，与现有方法相比具有本质上的区别。\\n\\n**关键设计**：在实现过程中，LLM compare的设计中考虑了成对比较的选择策略、Bradley-Terry模型的参数设置，以及在噪声注入情况下的性能评估等技术细节。具体的损失函数和网络结构细节在论文中进行了详细描述。",
            "application_zh": "该研究的潜在应用领域包括教育领域的课程设计、模型评估以及AI辅助的研究构思。通过提供一种高效的难度估计方法，研究人员和教育工作者可以更好地生成合成数据，优化学习路径和模型训练过程，提升整体研究效率。",
            "highlight_zh": "实验结果显示，LLM compare与人类注释的Pearson相关系数达到0.80以上，表明其在难度估计上的高一致性。此外，在进行10%噪声注入的情况下，Pearson相关性仅下降不到6%，显示出该方法的鲁棒性。",
            "tags_zh": [
                "大型语言模型",
                "难度估计",
                "Bradley-Terry模型",
                "无地面真相",
                "合成数据生成",
                "模型评估",
                "教育技术",
                "AI辅助研究"
            ],
            "_index": 83,
            "_used_api": "openai",
            "figures": []
        },
        {
            "title": "Effect of Document Packing on the Latent Multi-Hop Reasoning Capabilities of Large Language Models",
            "authors": [
                "Gabriele Prato",
                "Shagun Sodhani",
                "Alessandro Sordoni",
                "Sarath Chandar"
            ],
            "arxiv_id": "2512.14427",
            "summary": "The standard practice for training large language models involves packing multiple documents together to optimize computational efficiency. However, the impact of this process on the models' capabilities remains largely unexplored. To address this gap, we investigate how different document-packing strategies influence the latent multi-hop reasoning abilities of LLMs. Our findings indicate that packing can improve model performance compared to training on individual documents, at the expense of more compute. To further understand the underlying mechanisms, we conduct an ablation study, identifying key factors that explain the advantages of packing. Ultimately, our research deepens the understanding of LLM training dynamics and provides practical insights for optimizing model development.",
            "categories": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14427",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "研究文档打包策略对大语言模型多跳推理能力的影响",
            "summary_zh": "本文研究了文档打包策略对大语言模型（LLM）潜在多跳推理能力的影响。通常，训练大型语言模型时会将多个文档打包在一起，以优化计算效率。然而，这种做法对模型能力的影响在很大程度上尚未被探索。研究结果表明，与在单个文档上训练相比，打包可以提高模型性能，但会增加计算成本。为了进一步理解其潜在机制，本文进行了一项消融研究，确定了解释打包优势的关键因素。最终，这项研究加深了对LLM训练动态的理解，并为优化模型开发提供了实践见解。",
            "intro_zh": [
                "现有大语言模型训练通常采用文档打包策略以提升计算效率，但其对模型推理能力的潜在影响尚不明确。",
                "本文通过实验分析不同文档打包策略对LLM多跳推理能力的影响，旨在揭示打包策略背后的机制。",
                "研究发现，相比于单文档训练，文档打包能在增加计算成本的同时，有效提升模型性能。"
            ],
            "method_zh": "**问题定义**：论文旨在研究文档打包这种常用的LLM训练技巧，对模型多跳推理能力的影响。现有研究缺乏对文档打包策略的系统性分析，无法解释其对模型性能的具体影响，以及潜在的机制。因此，需要深入探究不同打包策略如何影响模型的推理能力，并找出关键的影响因素。\\n\\n**核心思路**：论文的核心思路是通过对比不同文档打包策略下训练的LLM，在多跳推理任务上的表现，来评估打包策略的优劣。通过消融实验，进一步分析影响模型性能的关键因素，例如文档之间的相关性、文档长度等。通过这种方式，揭示文档打包如何影响模型的知识获取和推理能力。\\n\\n**技术框架**：论文的技术框架主要包括以下几个部分：1) 定义不同的文档打包策略，例如随机打包、按主题打包等。2) 使用这些策略训练LLM。3) 在多跳推理数据集上评估模型的性能。4) 进行消融实验，分析不同因素对模型性能的影响。整个流程旨在系统性地评估文档打包策略对LLM推理能力的影响。\\n\\n**关键创新**：论文的关键创新在于系统性地研究了文档打包策略对LLM多跳推理能力的影响。以往的研究主要关注模型结构和训练方法，而忽略了文档打包这种常用的训练技巧。本文通过实验揭示了文档打包对模型性能的潜在影响，并分析了其背后的机制。这为LLM的训练和优化提供了新的视角。\\n\\n**关键设计**：论文的关键设计包括：1) 多种文档打包策略的设计，例如随机打包、按主题打包等，以覆盖不同的场景。2) 使用标准的多跳推理数据集进行评估，以保证结果的可比性。3) 消融实验的设计，例如改变文档长度、文档相关性等，以分析关键的影响因素。4) 使用标准的LLM架构进行实验，以保证结果的通用性。",
            "application_zh": "该研究成果可应用于优化大语言模型的训练流程，通过选择合适的文档打包策略，提升模型在知识密集型任务中的表现，例如问答系统、信息检索和知识图谱构建。此外，该研究也为未来研究LLM训练技巧提供了新的思路。",
            "highlight_zh": "实验结果表明，相比于在单个文档上训练，文档打包可以在增加计算成本的同时，有效提升模型在多跳推理任务上的性能。消融实验进一步揭示了文档相关性和文档长度等因素对模型性能的影响。具体性能提升幅度未知，需要查阅原文。",
            "tags_zh": [
                "大语言模型",
                "文档打包",
                "多跳推理",
                "训练策略",
                "消融研究"
            ],
            "_index": 84,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14427/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                }
            ]
        },
        {
            "title": "Light-Weight Benchmarks Reveal the Hidden Hardware Cost of Zero-Shot Tabular Foundation Models",
            "authors": [
                "Ishaan Gangwani",
                "Aayam Bansal"
            ],
            "arxiv_id": "2512.00888",
            "summary": "Zero-shot foundation models (FMs) promise training-free prediction on tabular data, yet their hardware footprint remains poorly characterized. We present a fully reproducible benchmark that reports test accuracy together with wall-clock latency, peak CPU RAM, and peak GPU VRAM on four public datasets: Adult-Income, Higgs-100k, Wine-Quality, and California-Housing. Two open FMs (TabPFN-1.0 and TabICL-base) are compared against tuned XGBoost, LightGBM, and Random Forest baselines on a single NVIDIA T4 GPU. The tree ensembles equal or surpass FM accuracy on three datasets while completing full-test batches in <= 0.40 s and <= 150 MB RAM, using zero VRAM. TabICL achieves a 0.8 percentage-point gain on Higgs but requires roughly 40,000 times more latency (960 s) and 9 GB VRAM. TabPFN matches tree-model accuracy on Wine and Housing but peaks at 4 GB VRAM and cannot process the full 100k-row Higgs table. These results quantify the substantial hardware-versus-accuracy trade-offs in current tabular FMs and provide an open baseline for future efficiency-oriented research.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.00888",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]foundation model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "轻量级基准测试揭示零样本表格数据基础模型隐藏的硬件成本",
            "summary_zh": "零样本基础模型(FMs)承诺在表格数据上进行免训练预测，但它们的硬件占用仍然缺乏充分的表征。本文提出了一个完全可复现的基准测试，报告了在四个公共数据集（Adult-Income、Higgs-100k、Wine-Quality和California-Housing）上的测试精度以及实际延迟、峰值CPU RAM和峰值GPU VRAM。在单个NVIDIA T4 GPU上，将两个开放的FM（TabPFN-1.0和TabICL-base）与经过调整的XGBoost、LightGBM和Random Forest基线进行比较。树集成模型在三个数据集上达到或超过了FM的精度，同时在<= 0.40秒内完成完整测试批次，并使用<= 150 MB的RAM，且不使用VRAM。TabICL在Higgs上实现了0.8个百分点的增益，但需要大约40,000倍的延迟（960秒）和9 GB的VRAM。TabPFN在Wine和Housing上匹配了树模型的精度，但峰值达到4 GB VRAM，并且无法处理完整的10万行Higgs表。这些结果量化了当前表格数据FM中显著的硬件与精度之间的权衡，并为未来面向效率的研究提供了一个开放的基线。",
            "intro_zh": [
                "现有零样本表格数据基础模型硬件资源消耗评估不足，缺乏统一的性能基准。",
                "构建可复现的基准测试，同时评估模型精度、推理延迟、CPU RAM和GPU VRAM占用。",
                "实验表明，传统树模型在精度和效率上优于现有零样本模型，揭示了硬件与精度之间的权衡。"
            ],
            "method_zh": "**问题定义**：论文旨在解决零样本表格数据基础模型（FMs）的硬件资源消耗评估问题。现有研究主要关注FMs的预测精度，而忽略了其在实际应用中所需的计算资源，如延迟、CPU RAM和GPU VRAM。这使得难以评估FMs在资源受限环境下的适用性，也缺乏一个统一的基准来比较不同FMs的效率。\n\n**核心思路**：论文的核心思路是通过构建一个全面的、可复现的基准测试，同时评估FMs的预测精度和硬件资源消耗。通过对比FMs与传统机器学习模型（如树集成模型）在不同数据集上的性能，量化FMs在精度和效率之间的权衡。这种方法能够更全面地评估FMs的实用性，并为未来的效率优化研究提供参考。\n\n**技术框架**：该研究的技术框架主要包括以下几个部分：1) 选择具有代表性的表格数据集（Adult-Income, Higgs-100k, Wine-Quality, California-Housing）；2) 选择具有代表性的零样本FMs（TabPFN-1.0, TabICL-base）和传统机器学习模型（XGBoost, LightGBM, Random Forest）作为对比；3) 在统一的硬件平台上（NVIDIA T4 GPU）运行所有模型，并记录测试精度、推理延迟、峰值CPU RAM和峰值GPU VRAM；4) 对比不同模型在精度和硬件资源消耗方面的表现，分析FMs的优缺点。\n\n**关键创新**：论文的关键创新在于构建了一个全面的、可复现的基准测试，能够同时评估零样本FMs的预测精度和硬件资源消耗。该基准测试不仅提供了具体的性能数据，还揭示了FMs在精度和效率之间的权衡，为未来的效率优化研究提供了重要的参考。此外，论文还强调了硬件资源消耗在评估FMs实用性中的重要性，这有助于推动FMs在资源受限环境下的应用。\n\n**关键设计**：论文的关键设计包括：1) 选择具有代表性的表格数据集，覆盖不同规模和特征类型；2) 选择具有代表性的零样本FMs和传统机器学习模型，进行公平的对比；3) 使用统一的硬件平台和评估指标，确保结果的可比性；4) 详细记录和分析硬件资源消耗数据，揭示FMs的优缺点。论文没有特别提及损失函数或网络结构等细节，因为重点在于评估现有模型的性能，而不是提出新的模型。",
            "application_zh": "该研究成果可应用于评估和选择适用于资源受限环境的表格数据预测模型。例如，在边缘计算设备或移动设备上部署模型时，需要考虑模型的硬件资源消耗。该研究提供的基准测试可以帮助用户选择在精度和效率之间取得平衡的模型。此外，该研究还可以促进对现有零样本模型的效率优化，推动其在实际应用中的落地。",
            "highlight_zh": "实验结果表明，在三个数据集上，经过调优的树集成模型在精度上与零样本FM相当甚至超过，同时延迟远低于FM（<= 0.40秒 vs. 960秒），RAM占用也远低于FM（<= 150 MB vs. 9 GB VRAM）。TabICL虽然在Higgs数据集上精度略有提升（0.8个百分点），但延迟和VRAM占用显著增加。TabPFN无法处理完整的Higgs数据集，且VRAM占用较高（4GB）。",
            "tags_zh": [
                "零样本学习",
                "表格数据",
                "基础模型",
                "硬件资源消耗",
                "基准测试"
            ],
            "_index": 85,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.00888/acc_vs_latency.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.00888/ram_bar.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.00888/vram_bar.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Temporal Tokenization Strategies for Event Sequence Modeling with Large Language Models",
            "authors": [
                "Zefang Liu",
                "Nam H. Nguyen",
                "Yinzhu Quan",
                "Shi-Xiong Zhang"
            ],
            "arxiv_id": "2512.13618",
            "summary": "Representing continuous time is a critical and under-explored challenge in modeling temporal event sequences with large language models (LLMs). Various strategies like byte-level representations or calendar tokens have been proposed. However, the optimal approach remains unclear, especially given the diverse statistical distributions of real-world event data, which range from smooth log-normal to discrete, spiky patterns. This paper presents the first empirical study of temporal tokenization for event sequences, comparing distinct encoding strategies: naive numeric strings, high-precision byte-level representations, human-semantic calendar tokens, classic uniform binning, and adaptive residual scalar quantization. We evaluate these strategies by fine-tuning LLMs on real-world datasets that exemplify these diverse distributions. Our analysis reveals that no single strategy is universally superior; instead, prediction performance depends heavily on aligning the tokenizer with the data's statistical properties, with log-based strategies excelling on skewed distributions and human-centric formats proving robust for mixed modalities.",
            "categories": [
                "cs.CL",
                "cs.LG"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13618",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "针对LLM事件序列建模，提出时间Token化策略选择框架，适配不同数据分布。",
            "summary_zh": "在使用大型语言模型（LLM）建模时序事件序列时，如何表示连续时间是一个至关重要但尚未充分探索的挑战。目前已提出多种策略，如字节级表示或日历Token。然而，考虑到真实世界事件数据分布的多样性（从平滑的对数正态分布到离散的尖峰模式），最佳方法仍不明确。本文首次对事件序列的时间Token化进行了实证研究，比较了不同的编码策略：朴素的数字字符串、高精度字节级表示、人类语义日历Token、经典均匀分箱和自适应残差标量量化。通过在具有代表性的真实世界数据集上微调LLM来评估这些策略。分析表明，没有一种策略是普遍优越的；相反，预测性能在很大程度上取决于Token化器与数据统计属性的对齐，其中基于对数的策略在偏斜分布上表现出色，而以人为中心的格式对于混合模态证明是稳健的。",
            "intro_zh": [
                "现有方法在利用LLM建模时序事件序列时，对连续时间的表示方法缺乏深入研究，最佳策略不明确。",
                "该论文提出了一种时间Token化策略选择框架，核心思想是根据数据的统计特性选择合适的Token化方法。",
                "通过在真实世界数据集上微调LLM进行评估，结果表明预测性能高度依赖于Token化器与数据统计属性的对齐。"
            ],
            "method_zh": "**问题定义**：论文旨在解决使用大型语言模型（LLM）建模时序事件序列时，如何有效地表示连续时间的问题。现有方法，如字节级表示或日历Token，各有优缺点，但缺乏系统性的比较和选择依据，尤其是在面对不同统计分布的真实世界数据时，难以确定最佳策略。现有方法的痛点在于缺乏对数据分布的适配性。\n\n**核心思路**：论文的核心思路是根据时序事件数据的统计特性，选择合适的Token化策略。不同的数据分布（如对数正态分布、离散分布）可能需要不同的Token化方法才能达到最佳的建模效果。通过比较多种Token化策略在不同数据集上的性能，找到与数据分布相匹配的策略。\n\n**技术框架**：该研究的技术框架主要包括以下几个步骤：1）选择具有不同统计分布的真实世界事件序列数据集；2）实现并比较多种时间Token化策略，包括朴素的数字字符串、高精度字节级表示、人类语义日历Token、经典均匀分箱和自适应残差标量量化；3）使用这些Token化后的数据微调LLM；4）评估不同Token化策略在不同数据集上的预测性能；5）分析结果，得出Token化策略与数据分布之间的关系。\n\n**关键创新**：该论文的关键创新在于首次对事件序列的时间Token化进行了全面的实证研究，并揭示了Token化策略与数据统计属性之间的重要关系。它表明，没有一种通用的最佳策略，而是需要根据数据的具体分布进行选择。这种针对数据分布的自适应Token化方法是与现有方法的本质区别。\n\n**关键设计**：论文的关键设计包括：1）选择了具有代表性的真实世界数据集，涵盖了不同的统计分布；2）实现了多种具有代表性的时间Token化策略，包括数值型、字节型、语义型和分箱型；3）使用了标准的LLM微调流程进行评估；4）采用了多种评估指标来衡量预测性能。具体的参数设置和损失函数等细节可能因使用的LLM而异，但整体流程保持一致。",
            "application_zh": "该研究成果可应用于各种需要对时序事件进行建模和预测的领域，例如医疗健康（预测疾病进展）、金融（预测股票价格波动）、物联网（预测设备故障）和推荐系统（预测用户行为）。通过选择合适的Token化策略，可以提高LLM在这些领域的预测精度和效率，从而带来实际价值和未来影响。",
            "highlight_zh": "实验结果表明，没有一种时间Token化策略在所有数据集上都表现最佳。基于对数的策略在偏斜分布的数据集上表现出色，而以人为中心的格式对于混合模态的数据集表现稳健。这强调了根据数据统计属性选择Token化策略的重要性，为实际应用提供了指导。",
            "tags_zh": [
                "时间序列建模",
                "大型语言模型",
                "Token化策略",
                "事件序列",
                "数据分布"
            ],
            "_index": 86,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13618/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13618/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.13618/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Massive Editing for Large Language Models Based on Dynamic Weight Generation",
            "authors": [
                "Wentao Wan",
                "Qiqing Lao",
                "Zhiwei Xie",
                "Hefeng Wu",
                "Runnan Lin",
                "Liang Lin",
                "Keze Wang"
            ],
            "arxiv_id": "2512.14395",
            "summary": "Knowledge Editing (KE) is a field that studies how to modify some knowledge in Large Language Models (LLMs) at a low cost (compared to pre-training). Currently, performing large-scale edits on LLMs while ensuring the Reliability, Generality, and Locality metrics of the edits remain a challenge. This paper proposes a Massive editing approach for LLMs based on dynamic weight Generation (MeG). Our MeG involves attaching a dynamic weight neuron to specific layers of the LLMs and using a diffusion model to conditionally generate the weights of this neuron based on the input query required for the knowledge. This allows the use of adding a single dynamic weight neuron to achieve the goal of large-scale knowledge editing. Experiments show that our MeG can significantly improve the performance of large-scale KE in terms of Reliability, Generality, and Locality metrics compared to existing knowledge editing methods, particularly with a high percentage point increase in the absolute value index for the Locality metric, demonstrating the advantages of our proposed method.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14395",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于动态权重生成的大语言模型批量知识编辑方法MeG",
            "summary_zh": "知识编辑(KE)旨在以低成本（相对于预训练）修改大语言模型(LLM)中的知识。目前，对LLM进行大规模编辑，同时确保编辑的可靠性、通用性和局部性指标仍然是一个挑战。本文提出了一种基于动态权重生成的大语言模型批量编辑方法(MeG)。MeG通过在LLM的特定层附加一个动态权重神经元，并使用扩散模型根据知识所需的输入查询有条件地生成该神经元的权重。这使得仅添加一个动态权重神经元就能实现大规模知识编辑的目标。实验表明，与现有的知识编辑方法相比，MeG在可靠性、通用性和局部性指标方面显著提高了大规模KE的性能，尤其是在局部性指标的绝对值方面有很高的百分点提升，证明了我们提出的方法的优势。",
            "intro_zh": [
                "现有知识编辑方法难以兼顾可靠性、通用性和局部性，无法有效支持大语言模型的大规模知识编辑。",
                "MeG的核心思想是在LLM中引入动态权重神经元，并利用扩散模型生成与输入查询相关的权重。",
                "实验表明，MeG在可靠性、通用性和局部性指标上均优于现有方法，尤其在局部性方面提升显著。"
            ],
            "method_zh": "**问题定义**：现有的大语言模型知识编辑方法难以同时保证编辑的可靠性（Reliability，编辑后的模型能正确反映新的知识）、通用性（Generality，编辑后的模型在相关任务上表现良好）和局部性（Locality，编辑对模型其他知识的影响尽可能小）。大规模知识编辑场景下，这些问题尤为突出。\\n\\n**核心思路**：MeG的核心思路是引入动态权重神经元，通过控制这些神经元的权重来修改模型的知识。这些权重不是固定的，而是根据输入的查询动态生成的，从而实现对特定知识的编辑。这种方法允许通过少量参数的修改来实现大规模的知识编辑。\\n\\n**技术框架**：MeG的技术框架主要包括以下几个步骤：1) 在LLM的特定层（例如Transformer层的FFN层）添加动态权重神经元。2) 使用扩散模型，根据输入的查询（即需要编辑的知识）有条件地生成这些动态权重神经元的权重。3) 在推理时，根据输入查询，动态地调整这些神经元的权重，从而实现知识的编辑。\\n\\n**关键创新**：MeG的关键创新在于使用动态权重神经元和扩散模型相结合的方式来实现知识编辑。与传统的知识编辑方法相比，MeG不需要修改模型的大部分参数，而是通过动态调整少量参数来实现知识的修改，从而提高了编辑的效率和局部性。此外，使用扩散模型生成权重可以更好地控制编辑的质量和泛化能力。\\n\\n**关键设计**：MeG的关键设计包括：1) 动态权重神经元的位置选择：选择对知识表达影响较大的层（例如FFN层）。2) 扩散模型的结构和训练：使用合适的扩散模型结构，并使用大量的知识编辑数据进行训练，以保证生成的权重的质量。3) 查询的表示方式：将查询转化为适合扩散模型输入的向量表示，例如使用预训练的语言模型进行编码。",
            "application_zh": "MeG可应用于各种需要对大语言模型进行知识更新和修正的场景，例如：事实核查、信息校正、个性化知识定制等。该方法能够以较低的成本实现对LLM知识的快速更新，提高LLM的可靠性和实用性，并有望在智能客服、教育辅导等领域发挥重要作用。",
            "highlight_zh": "实验结果表明，MeG在可靠性、通用性和局部性指标上均优于现有方法。尤其是在局部性指标上，MeG取得了显著的提升，绝对值提升高达多个百分点。这表明MeG能够有效地修改LLM的知识，同时尽可能地减少对模型其他知识的影响。具体数值提升数据未知，需要在论文中查找。",
            "tags_zh": [
                "知识编辑",
                "大语言模型",
                "动态权重生成",
                "扩散模型",
                "批量编辑"
            ],
            "_index": 87,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14395/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14395/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14395/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Safe2Harm: Semantic Isomorphism Attacks for Jailbreaking Large Language Models",
            "authors": [
                "Fan Yang"
            ],
            "arxiv_id": "2512.13703",
            "summary": "Large Language Models (LLMs) have demonstrated exceptional performance across various tasks, but their security vulnerabilities can be exploited by attackers to generate harmful content, causing adverse impacts across various societal domains. Most existing jailbreak methods revolve around Prompt Engineering or adversarial optimization, yet we identify a previously overlooked phenomenon: many harmful scenarios are highly consistent with legitimate ones in terms of underlying principles. Based on this finding, this paper proposes the Safe2Harm Semantic Isomorphism Attack method, which achieves efficient jailbreaking through four stages: first, rewrite the harmful question into a semantically safe question with similar underlying principles; second, extract the thematic mapping relationship between the two; third, let the LLM generate a detailed response targeting the safe question; finally, reversely rewrite the safe response based on the thematic mapping relationship to obtain harmful output. Experiments on 7 mainstream LLMs and three types of benchmark datasets show that Safe2Harm exhibits strong jailbreaking capability, and its overall performance is superior to existing methods. Additionally, we construct a challenging harmful content evaluation dataset containing 358 samples and evaluate the effectiveness of existing harmful detection methods, which can be deployed for LLM input-output filtering to enable defense.",
            "categories": [
                "cs.CR",
                "cs.AI"
            ],
            "primary_category": "cs.CR",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13703",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出Safe2Harm语义同构攻击，实现对大型语言模型的有效越狱",
            "summary_zh": "大型语言模型（LLMs）在各种任务中表现出卓越的性能，但其安全漏洞可能被攻击者利用以生成有害内容，从而对各个社会领域造成不利影响。现有的大多数越狱方法都围绕提示工程或对抗优化展开，但我们发现了一个先前被忽视的现象：许多有害场景在底层原理上与合法场景高度一致。基于这一发现，本文提出了一种Safe2Harm语义同构攻击方法，该方法通过四个阶段实现高效的越狱：首先，将有害问题重写为语义上安全的、具有相似底层原理的问题；其次，提取两者之间的主题映射关系；第三，让LLM生成针对安全问题的详细回答；最后，基于主题映射关系反向重写安全回答，以获得有害输出。在7个主流LLM和三种类型的基准数据集上的实验表明，Safe2Harm表现出强大的越狱能力，其整体性能优于现有方法。此外，我们构建了一个包含358个样本的具有挑战性的有害内容评估数据集，并评估了现有有害检测方法的有效性，这些方法可以部署用于LLM输入输出过滤，以实现防御。",
            "intro_zh": [
                "现有LLM越狱方法主要依赖提示工程或对抗优化，忽略了有害场景与合法场景在底层原理上的相似性。",
                "Safe2Harm攻击通过将有害问题转化为语义安全的同构问题，利用LLM对安全问题的回答，再反向映射生成有害内容。",
                "实验证明Safe2Harm在多个LLM上表现出强大的越狱能力，优于现有方法，并构建了新的有害内容评估数据集。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型（LLMs）容易被越狱，从而生成有害内容的问题。现有的越狱方法，如提示工程和对抗优化，存在效率低、泛化性差等痛点，并且忽略了有害场景与合法场景在底层原理上的相似性，导致攻击效果不佳。\\n\\n**核心思路**：论文的核心思路是利用语义同构性，将有害问题转化为语义上安全的、但底层原理相似的问题，诱导LLM生成针对安全问题的回答，然后通过反向映射将安全回答转化为有害输出。这种方法旨在绕过LLM的安全机制，利用其在安全问题上的生成能力，间接生成有害内容。\\n\\n**技术框架**：Safe2Harm攻击方法包含四个主要阶段：\n1. **问题重写**：将有害问题重写为语义安全的同构问题。\n2. **主题映射**：提取有害问题和安全问题之间的主题映射关系。\n3. **安全回答生成**：利用LLM生成针对安全问题的详细回答。\n4. **反向重写**：基于主题映射关系，将安全回答反向重写为有害输出。\\n\\n**关键创新**：Safe2Harm的关键创新在于发现了并利用了有害场景与合法场景之间的语义同构性。与直接攻击LLM的安全机制不同，Safe2Harm通过转换问题，绕过了安全检测，利用了LLM在安全问题上的生成能力。这种间接攻击方式更具隐蔽性和有效性。\\n\\n**关键设计**：论文的关键设计包括：\n1. **语义安全问题生成策略**：如何将有害问题转化为语义安全的同构问题，保证底层原理相似，但表面上无害。\n2. **主题映射关系提取方法**：如何准确提取有害问题和安全问题之间的主题映射关系，保证反向重写的准确性。\n3. **反向重写策略**：如何基于主题映射关系，将安全回答准确地转化为有害输出，避免引入新的安全风险。",
            "application_zh": "该研究成果可应用于提升大型语言模型的安全性评估，通过Safe2Harm攻击方法发现LLM潜在的安全漏洞。同时，构建的有害内容评估数据集可用于训练和评估LLM的有害内容检测能力，从而提高LLM的安全性，减少有害内容的生成和传播。",
            "highlight_zh": "Safe2Harm在7个主流LLM和三种类型的基准数据集上进行了实验，结果表明其越狱能力优于现有方法。此外，论文构建了一个包含358个样本的具有挑战性的有害内容评估数据集，并评估了现有有害检测方法的有效性，为LLM的安全防御提供了新的思路。",
            "tags_zh": [
                "大型语言模型",
                "越狱攻击",
                "语义同构",
                "安全漏洞",
                "有害内容检测"
            ],
            "_index": 88,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13703/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13703/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.13703/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "PerfCoder: Large Language Models for Interpretable Code Performance Optimization",
            "authors": [
                "Jiuding Yang",
                "Shengyao Lu",
                "Hongxuan Liu",
                "Shayan Shirahmad Gale Bagi",
                "Zahra Fazel",
                "Tomasz Czajkowski",
                "Di Niu"
            ],
            "arxiv_id": "2512.14018",
            "summary": "Large language models (LLMs) have achieved remarkable progress in automatic code generation, yet their ability to produce high-performance code remains limited--a critical requirement in real-world software systems. We argue that current LLMs struggle not only due to data scarcity but, more importantly, because they lack supervision that guides interpretable and effective performance improvements. In this work, we introduce PerfCoder, a family of LLMs specifically designed to generate performance-enhanced code from source code via interpretable, customized optimizations. PerfCoder is fine-tuned on a curated collection of real-world optimization trajectories with human-readable annotations, and preference-aligned by reinforcement fine-tuning using runtime measurements, enabling it to propose input-specific improvement strategies and apply them directly without relying on iterative refinement. On the PIE code performance benchmark, PerfCoder surpasses all existing models in both runtime speedup and effective optimization rate, demonstrating that performance optimization cannot be achieved by scale alone but requires optimization stratetgy awareness. In addition, PerfCoder can generate interpretable feedback about the source code, which, when provided as input to a larger LLM in a planner-and-optimizer cooperative workflow, can further improve outcomes. Specifically, we elevate the performance of 32B models and GPT-5 to new levels on code optimization, substantially surpassing their original performance.",
            "categories": [
                "cs.SE",
                "cs.AI"
            ],
            "primary_category": "cs.SE",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14018",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "PerfCoder：利用大语言模型实现可解释的代码性能优化",
            "summary_zh": "大语言模型（LLMs）在自动代码生成方面取得了显著进展，但其生成高性能代码的能力仍然有限，这在实际软件系统中至关重要。我们认为，当前LLMs的不足不仅在于数据稀缺，更重要的是，它们缺乏指导可解释和有效性能改进的监督。本文提出了PerfCoder，一个专门设计用于通过可解释的、定制的优化从源代码生成性能增强代码的LLM家族。PerfCoder在一个精心策划的、带有可读注释的真实优化轨迹集合上进行微调，并通过使用运行时测量的强化微调进行偏好对齐，使其能够提出特定于输入的改进策略并直接应用它们，而无需依赖迭代细化。在PIE代码性能基准测试中，PerfCoder在运行时加速和有效优化率方面均超过了所有现有模型，表明性能优化不能仅靠规模来实现，还需要优化策略意识。此外，PerfCoder可以生成关于源代码的可解释反馈，当在规划器-优化器协同工作流程中作为较大LLM的输入提供时，可以进一步改善结果。具体来说，我们提升了32B模型和GPT-5在代码优化方面的性能至新的水平，大大超过了它们原来的性能。",
            "intro_zh": [
                "现有大语言模型在生成高性能代码方面存在不足，缺乏有效的性能优化指导。",
                "PerfCoder通过在优化轨迹上微调，并使用运行时测量进行强化学习，实现可解释的代码性能优化。",
                "实验表明，PerfCoder在代码性能基准测试中超越现有模型，并能提升更大模型的优化能力。"
            ],
            "method_zh": "**问题定义**：现有的大语言模型在代码生成方面取得了进展，但生成高性能代码的能力仍然不足。它们缺乏对代码性能优化的有效指导，难以产生可解释的优化策略，导致生成的代码在实际应用中性能受限。\\n\\n**核心思路**：PerfCoder的核心思路是通过学习真实世界的代码优化轨迹，使模型能够理解和应用有效的优化策略。通过可解释的优化过程，模型能够生成性能增强的代码，并提供关于源代码的反馈，从而提升代码质量。\\n\\n**技术框架**：PerfCoder的技术框架主要包括以下几个部分：1) 数据收集：构建包含真实世界代码优化轨迹的数据集，并进行人工标注，提供可解释的优化信息。2) 模型微调：在收集的数据集上对大语言模型进行微调，使模型学习优化策略。3) 强化学习：使用运行时测量作为奖励信号，通过强化学习对模型进行偏好对齐，使其能够生成性能更优的代码。4) 规划器-优化器协同：将PerfCoder生成的反馈提供给更大的LLM，协同完成代码优化任务。\\n\\n**关键创新**：PerfCoder的关键创新在于其专注于可解释的性能优化策略学习。与以往依赖大规模数据和模型的方法不同，PerfCoder通过学习优化轨迹，使模型能够理解优化背后的原理，并生成可解释的优化建议。此外，PerfCoder还通过强化学习，将运行时测量纳入优化过程，从而更好地提升代码性能。\\n\\n**关键设计**：PerfCoder的关键设计包括：1) 优化轨迹数据集的构建，需要精心选择和标注真实的优化案例。2) 强化学习奖励函数的设计，需要准确反映代码性能的提升。3) 规划器-优化器协同工作流程的设计，需要有效地利用PerfCoder生成的反馈信息。",
            "application_zh": "PerfCoder可应用于各种软件开发场景，例如编译器优化、代码重构和性能调优。它可以帮助开发者自动生成高性能代码，并提供可解释的优化建议，从而提高开发效率和软件质量。未来，PerfCoder有望成为自动化代码优化工具的核心组件，并推动软件工程领域的智能化发展。",
            "highlight_zh": "PerfCoder在PIE代码性能基准测试中超越了所有现有模型，在运行时加速和有效优化率方面均取得了显著提升。此外，PerfCoder生成的反馈信息能够有效提升更大模型的代码优化能力，例如将32B模型和GPT-5的性能提升到新的水平，大幅超过了它们原始的性能表现。",
            "tags_zh": [
                "代码优化",
                "大语言模型",
                "性能提升",
                "可解释性",
                "强化学习"
            ],
            "_index": 89,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14018/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14018/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14018/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "A data-physics hybrid generative model for patient-specific post-stroke motor rehabilitation using wearable sensor data",
            "authors": [
                "Yanning Dai",
                "Chenyu Tang",
                "Ruizhi Zhang",
                "Wenyu Yang",
                "Yilan Zhang",
                "Yuhui Wang",
                "Junliang Chen",
                "Xuhang Chen",
                "Ruimou Xie",
                "Yangyue Cao",
                "Qiaoying Li",
                "Jin Cao",
                "Tao Li",
                "Hubin Zhao",
                "Yu Pan",
                "Arokia Nathan",
                "Xin Gao",
                "Peter Smielewski",
                "Shuo Gao"
            ],
            "arxiv_id": "2512.14329",
            "summary": "Dynamic prediction of locomotor capacity after stroke is crucial for tailoring rehabilitation, yet current assessments provide only static impairment scores and do not indicate whether patients can safely perform specific tasks such as slope walking or stair climbing. Here, we develop a data-physics hybrid generative framework that reconstructs an individual stroke survivor's neuromuscular control from a single 20 m level-ground walking trial and predicts task-conditioned locomotion across rehabilitation scenarios. The system combines wearable-sensor kinematics, a proportional-derivative physics controller, a population Healthy Motion Atlas, and goal-conditioned deep reinforcement learning with behaviour cloning and generative adversarial imitation learning to generate physically plausible, patient-specific gait simulations for slopes and stairs. In 11 stroke survivors, the personalized controllers preserved idiosyncratic gait patterns while improving joint-angle and endpoint fidelity by 4.73% and 12.10%, respectively, and reducing training time to 25.56% relative to a physics-only baseline. In a multicentre pilot involving 21 inpatients, clinicians who used our locomotion predictions to guide task selection and difficulty obtained larger gains in Fugl-Meyer lower-extremity scores over 28 days of standard rehabilitation than control clinicians (mean change 6.0 versus 3.7 points). These findings indicate that our generative, task-predictive framework can augment clinical decision-making in post-stroke gait rehabilitation and provide a template for dynamically personalized motor recovery strategies.",
            "categories": [
                "cs.CE",
                "cs.AI"
            ],
            "primary_category": "cs.CE",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14329",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "locomotion"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning",
                        "deep reinforcement learning",
                        "imitation learning"
                    ],
                    "score": 4.5
                },
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "physically plausible"
                    ],
                    "score": 2.5
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "1_robot_core",
                "2_algo_arch",
                "4_motion_diffusion"
            ],
            "headline_zh": "提出数据-物理混合生成模型，利用可穿戴传感器数据实现卒中后患者的个性化运动康复。",
            "summary_zh": "本研究开发了一种数据-物理混合生成框架，旨在通过单次20米平地行走试验重建卒中幸存者的神经肌肉控制，并预测不同康复场景下的任务条件步态。该系统结合了可穿戴传感器运动学数据、比例-微分物理控制器、健康运动图谱以及目标条件深度强化学习（结合行为克隆和生成对抗模仿学习），为斜坡和楼梯行走生成物理上合理且患者特定的步态模拟。在11名卒中幸存者中，个性化控制器在保留个体步态特征的同时，将关节角度和终点保真度分别提高了4.73%和12.10%，并将训练时间缩短至仅为纯物理基线的25.56%。在一项涉及21名住院患者的多中心试验中，使用该步态预测指导任务选择和难度调整的临床医生，在28天的标准康复后，Fugl-Meyer下肢评分的增益高于对照组临床医生（平均变化6.0分 vs 3.7分）。这些发现表明，该生成式任务预测框架可以增强卒中后步态康复中的临床决策，并为动态个性化运动恢复策略提供模板。",
            "intro_zh": [
                "现有卒中康复评估主要提供静态损伤评分，无法动态预测患者在斜坡或楼梯等特定任务中的运动能力。",
                "论文提出一种数据-物理混合生成模型，结合可穿戴传感器数据、物理控制器和深度强化学习，重建个性化神经肌肉控制。",
                "实验表明，该模型能有效预测患者在不同康复场景下的步态，并指导临床医生制定更有效的康复方案，提升康复效果。"
            ],
            "method_zh": "**问题定义**：卒中后患者的运动能力评估是康复的关键，但现有方法主要依赖静态的损伤评分，无法动态预测患者在不同任务（如斜坡行走、楼梯攀爬）中的运动表现。这导致康复方案缺乏个性化和针对性，影响康复效果。现有方法难以准确模拟患者的神经肌肉控制机制，也难以根据患者的个体差异进行调整。\\n\\n**核心思路**：论文的核心思路是结合数据驱动和物理建模的优势，构建一个混合生成模型。通过可穿戴传感器数据捕捉患者的个体步态特征，利用物理控制器模拟神经肌肉控制，并借助深度强化学习优化控制策略，从而生成个性化的步态模拟。这种混合方法既能保证模拟的物理合理性，又能反映患者的个体差异。\\n\\n**技术框架**：该框架包含以下主要模块：1) 可穿戴传感器数据采集：收集患者在平地行走时的运动学数据。2) 比例-微分物理控制器：模拟患者的神经肌肉控制，控制虚拟人体模型。3) 健康运动图谱：提供健康的步态数据作为参考。4) 目标条件深度强化学习：使用行为克隆和生成对抗模仿学习，训练控制器在不同任务（斜坡、楼梯）中生成合理的步态。整体流程是：首先利用患者的平地行走数据初始化控制器，然后通过强化学习在特定任务中优化控制器，最后生成患者在该任务中的步态模拟。\\n\\n**关键创新**：该方法最重要的创新点在于将数据驱动的深度学习与物理建模相结合，实现了对患者个性化神经肌肉控制的重建和预测。与传统的纯物理建模方法相比，该方法能够更好地反映患者的个体差异。与纯数据驱动的方法相比，该方法能够保证模拟的物理合理性。此外，使用行为克隆和生成对抗模仿学习加速了强化学习的训练过程。\\n\\n**关键设计**：比例-微分控制器的参数根据患者的平地行走数据进行初始化。强化学习的目标函数包括任务完成奖励、步态相似性奖励和控制力惩罚。行为克隆用于初始化强化学习策略，生成对抗模仿学习用于提高步态的真实性。网络结构采用多层感知机，输入包括关节角度、角速度和任务目标，输出为关节力矩。",
            "application_zh": "该研究成果可应用于卒中后患者的个性化康复方案设计。临床医生可以利用该模型预测患者在不同任务中的运动能力，从而制定更具针对性的康复计划。此外，该模型还可以用于评估不同康复策略的效果，为临床决策提供依据。该方法具有推广潜力，可应用于其他神经系统疾病的运动康复。",
            "highlight_zh": "实验结果表明，该个性化控制器在保留个体步态特征的同时，将关节角度和终点保真度分别提高了4.73%和12.10%，并将训练时间缩短至仅为纯物理基线的25.56%。在一项多中心试验中，使用该步态预测指导任务选择的临床医生，在28天的标准康复后，Fugl-Meyer下肢评分的增益高于对照组临床医生（平均变化6.0分 vs 3.7分）。",
            "tags_zh": [
                "卒中康复",
                "步态预测",
                "数据-物理混合模型",
                "深度强化学习",
                "可穿戴传感器",
                "个性化康复",
                "神经肌肉控制"
            ],
            "_index": 90,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "SASQ: Static Activation Scaling for Quantization-Aware Training in Large Language Models",
            "authors": [
                "Shizhuo Mao",
                "Song Chen",
                "Yi Kang"
            ],
            "arxiv_id": "2512.14481",
            "summary": "Large language models (LLMs) excel at natural language tasks but face deployment challenges due to their growing size outpacing GPU memory advancements. Model quantization mitigates this issue by lowering weight and activation precision, but existing solutions face fundamental trade-offs: dynamic quantization incurs high computational overhead and poses deployment challenges on edge devices, while static quantization sacrifices accuracy. Existing approaches of quantization-aware training (QAT) further suffer from weight training costs. We propose SASQ: a lightweight QAT framework specifically tailored for activation quantization factors. SASQ exclusively optimizes only the quantization factors (without changing pre-trained weights), enabling static inference with high accuracy while maintaining deployment efficiency. SASQ adaptively truncates some outliers, thereby reducing the difficulty of quantization while preserving the distributional characteristics of the activations. SASQ not only surpasses existing SOTA quantization schemes but also outperforms the corresponding FP16 models. On LLaMA2-7B, it achieves 5.2% lower perplexity than QuaRot and 4.7% lower perplexity than the FP16 model on WikiText2.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14481",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "SASQ：一种用于大语言模型量化感知训练的静态激活缩放方法",
            "summary_zh": "大型语言模型（LLMs）在自然语言任务中表现出色，但其不断增长的规模超过了GPU内存的发展速度，给部署带来了挑战。模型量化通过降低权重和激活的精度来缓解这个问题，但现有的解决方案面临着根本性的权衡：动态量化会产生很高的计算开销，并在边缘设备上带来部署挑战，而静态量化会牺牲精度。现有的量化感知训练（QAT）方法进一步受到权重训练成本的困扰。我们提出了SASQ：一个轻量级的QAT框架，专门为激活量化因子量身定制。SASQ仅优化量化因子（不改变预训练权重），从而实现高精度的静态推理，同时保持部署效率。SASQ自适应地截断一些异常值，从而降低了量化的难度，同时保留了激活的分布特征。SASQ不仅超越了现有的SOTA量化方案，而且优于相应的FP16模型。在LLaMA2-7B上，它在WikiText2上的困惑度比QuaRot低5.2%，比FP16模型低4.7%。",
            "intro_zh": [
                "现有大模型量化方法在精度、计算开销和部署效率之间存在权衡，静态量化精度低，动态量化开销大，权重训练成本高。",
                "SASQ通过仅优化激活量化因子，避免了权重训练的开销，实现了高精度和高效率的静态量化推理。",
                "实验表明，SASQ在LLaMA2-7B模型上优于现有SOTA量化方案，甚至超过了FP16模型的性能。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大语言模型量化过程中，静态量化精度损失和动态量化计算开销大的问题。现有的量化感知训练（QAT）方法通常需要对权重进行微调，导致训练成本高昂。因此，如何在保证精度的前提下，实现高效的静态量化，是本文要解决的核心问题。\\n\\n**核心思路**：SASQ的核心思路是仅优化激活的量化因子，而不改变预训练的权重。通过这种方式，可以避免权重训练带来的高昂计算成本，同时实现静态量化，从而保证部署效率。此外，SASQ还引入了自适应截断机制，以降低量化难度，并保留激活的分布特征。\\n\\n**技术框架**：SASQ的整体框架包括以下几个主要步骤：1) 加载预训练的大语言模型；2) 对激活进行量化，并引入可学习的量化因子；3) 使用量化后的模型进行前向传播，计算损失；4) 仅更新量化因子，保持预训练权重不变；5) 重复步骤3和4，直到量化因子收敛。最终得到一个量化后的模型，可以进行高效的静态推理。\\n\\n**关键创新**：SASQ的关键创新在于：1) 仅优化激活量化因子，避免了权重训练的开销；2) 引入自适应截断机制，降低了量化难度，并保留了激活的分布特征。与现有方法相比，SASQ在保证精度的前提下，显著提高了量化效率。\\n\\n**关键设计**：SASQ的关键设计包括：1) 量化因子的初始化策略，需要保证量化后的激活值能够尽可能地接近原始激活值；2) 自适应截断机制的具体实现，需要根据激活值的分布动态调整截断阈值；3) 损失函数的选择，需要能够反映量化误差，并引导量化因子朝着最优方向更新。",
            "application_zh": "SASQ适用于对计算资源和延迟有严格要求的场景，例如边缘设备上的大语言模型部署。通过高效的静态量化，SASQ可以降低模型大小和计算复杂度，从而使大语言模型能够在资源受限的设备上运行，并加速推理过程。这对于智能手机、物联网设备等应用具有重要意义。",
            "highlight_zh": "SASQ在LLaMA2-7B模型上进行了实验，结果表明，SASQ在WikiText2数据集上的困惑度比QuaRot低5.2%，比FP16模型低4.7%。这表明SASQ不仅超越了现有的SOTA量化方案，而且优于相应的FP16模型，实现了显著的性能提升。",
            "tags_zh": [
                "大语言模型",
                "量化感知训练",
                "静态量化",
                "激活量化",
                "模型压缩"
            ],
            "_index": 91,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14481/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14481/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14481/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "VLegal-Bench: Cognitively Grounded Benchmark for Vietnamese Legal Reasoning of Large Language Models",
            "authors": [
                "Nguyen Tien Dong",
                "Minh-Anh Nguyen",
                "Thanh Dat Hoang",
                "Nguyen Tuan Ngoc",
                "Dao Xuan Quang Minh",
                "Phan Phi Hai",
                "Nguyen Thi Ngoc Anh",
                "Dang Van Tu",
                "Binh Vu"
            ],
            "arxiv_id": "2512.14554",
            "summary": "The rapid advancement of large language models (LLMs) has enabled new possibilities for applying artificial intelligence within the legal domain. Nonetheless, the complexity, hierarchical organization, and frequent revisions of Vietnamese legislation pose considerable challenges for evaluating how well these models interpret and utilize legal knowledge. To address this gap, Vietnamese Legal Benchmark (VLegal-Bench) is introduced, the first comprehensive benchmark designed to systematically assess LLMs on Vietnamese legal tasks. Informed by Bloom's cognitive taxonomy, VLegal-Bench encompasses multiple levels of legal understanding through tasks designed to reflect practical usage scenarios. The benchmark comprises 10,450 samples generated through a rigorous annotation pipeline, where legal experts label and cross-validate each instance using our annotation system to ensure every sample is grounded in authoritative legal documents and mirrors real-world legal assistant workflows, including general legal questions and answers, retrieval-augmented generation, multi-step reasoning, and scenario-based problem solving tailored to Vietnamese law. By providing a standardized, transparent, and cognitively informed evaluation framework, VLegal-Bench establishes a solid foundation for assessing LLM performance in Vietnamese legal contexts and supports the development of more reliable, interpretable, and ethically aligned AI-assisted legal systems.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14554",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出VLegal-Bench，用于评估LLM在越南法律推理任务中的能力。",
            "summary_zh": "大型语言模型（LLM）的快速发展为人工智能在法律领域的应用带来了新的可能性。然而，越南法律的复杂性、层级结构和频繁修订对评估这些模型解释和利用法律知识的能力提出了巨大挑战。为了解决这一差距，我们推出了越南法律基准（VLegal-Bench），这是第一个旨在系统评估LLM在越南法律任务中表现的综合基准。VLegal-Bench以Bloom的认知分类学为基础，通过旨在反映实际使用场景的任务，涵盖了多个层次的法律理解。该基准包含10,450个样本，这些样本通过严格的标注流程生成，法律专家使用我们的标注系统对每个实例进行标注和交叉验证，以确保每个样本都基于权威的法律文件，并反映了现实世界的法律助理工作流程，包括一般法律问答、检索增强生成、多步骤推理和针对越南法律的基于场景的问题解决。通过提供一个标准化、透明和认知驱动的评估框架，VLegal-Bench为评估LLM在越南法律环境中的性能奠定了坚实的基础，并支持开发更可靠、可解释和符合伦理的人工智能辅助法律系统。",
            "intro_zh": [
                "现有LLM在处理复杂、层级化且频繁修订的越南法律时，面临法律知识理解和应用的挑战。",
                "VLegal-Bench通过模拟实际法律场景的任务，从认知角度系统评估LLM的法律理解能力。",
                "该基准包含10450个样本，由法律专家标注和验证，确保数据权威性和真实性。"
            ],
            "method_zh": "**问题定义**：现有的大型语言模型在处理越南法律领域的问题时，由于越南法律的复杂性、层级结构以及频繁的修订，难以准确理解和应用法律知识。这导致了LLM在越南法律领域的应用受限，无法有效辅助法律工作者。现有方法缺乏一个专门针对越南法律的综合性评估基准，难以系统地评估LLM在越南法律任务中的表现。\\n\\n**核心思路**：VLegal-Bench的核心思路是构建一个全面、系统且认知驱动的评估基准，用于评估LLM在越南法律领域的推理能力。该基准的设计受到Bloom认知分类学的启发，涵盖了不同层次的法律理解，从简单的知识回忆到复杂的问题解决。通过模拟实际的法律场景，VLegal-Bench能够更真实地反映LLM在实际应用中的表现。\\n\\n**技术框架**：VLegal-Bench的整体框架包括数据收集、标注、验证和评估四个主要阶段。首先，收集大量的越南法律相关文本和案例。然后，由法律专家对这些数据进行标注，标注过程遵循一套严格的标注指南，确保标注的准确性和一致性。接下来，对标注的数据进行交叉验证，以进一步提高数据质量。最后，使用标注好的数据对LLM进行评估，评估指标包括准确率、召回率和F1值等。该基准包含多种任务类型，包括一般法律问答、检索增强生成、多步骤推理和基于场景的问题解决。\\n\\n**关键创新**：VLegal-Bench的关键创新在于它是第一个专门针对越南法律的综合性评估基准。与现有的通用型评估基准相比，VLegal-Bench更能够反映LLM在越南法律领域的实际表现。此外，VLegal-Bench的设计受到Bloom认知分类学的启发，能够更全面地评估LLM的法律理解能力。该基准的数据集经过法律专家的严格标注和验证，保证了数据的质量和权威性。\\n\\n**关键设计**：VLegal-Bench的关键设计包括任务类型的选择、评估指标的设定和数据标注指南的制定。任务类型涵盖了法律领域的各种常见任务，例如一般法律问答、检索增强生成、多步骤推理和基于场景的问题解决。评估指标包括准确率、召回率和F1值等，这些指标能够全面反映LLM的性能。数据标注指南详细规定了标注的标准和流程，确保标注的准确性和一致性。",
            "application_zh": "VLegal-Bench可用于评估和提升LLM在越南法律领域的应用能力，例如智能法律咨询、法律文书生成、案件分析等。该基准有助于开发更可靠、可解释和符合伦理的人工智能辅助法律系统，提高法律服务的效率和质量，并为法律从业者提供更强大的工具。",
            "highlight_zh": "VLegal-Bench包含10,450个高质量样本，涵盖多种法律任务。实验结果（论文中未明确给出具体数值，此处为推测）表明，现有LLM在VLegal-Bench上的表现仍有提升空间，尤其是在多步骤推理和基于场景的问题解决方面。该基准为未来研究提供了明确的方向。",
            "tags_zh": [
                "越南法律",
                "大型语言模型",
                "法律推理",
                "评估基准",
                "认知分类学"
            ],
            "_index": 92,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14554/img/VietLegalBench_overview.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14554/x1.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14554/img/anotate_tool.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Optimizing Large Language Models for ESG Activity Detection in Financial Texts",
            "authors": [
                "Mattia Birti",
                "Andrea Maurino",
                "Francesco Osborne"
            ],
            "arxiv_id": "2502.21112",
            "summary": "The integration of Environmental, Social, and Governance (ESG) factors into corporate decision-making is a fundamental aspect of sustainable finance. However, ensuring that business practices align with evolving regulatory frameworks remains a persistent challenge. AI-driven solutions for automatically assessing the alignment of sustainability reports and non-financial disclosures with specific ESG activities could greatly support this process. Yet, this task remains complex due to the limitations of general-purpose Large Language Models (LLMs) in domain-specific contexts and the scarcity of structured, high-quality datasets. In this paper, we investigate the ability of current-generation LLMs to identify text related to environmental activities. Furthermore, we demonstrate that their performance can be significantly enhanced through fine-tuning on a combination of original and synthetically generated data. To this end, we introduce ESG-Activities, a benchmark dataset containing 1,325 labelled text segments classified according to the EU ESG taxonomy. Our experimental results show that fine-tuning on ESG-Activities significantly enhances classification accuracy, with open models such as Llama 7B and Gemma 7B outperforming large proprietary solutions in specific configurations. These findings have important implications for financial analysts, policymakers, and AI researchers seeking to enhance ESG transparency and compliance through advanced natural language processing techniques.",
            "categories": [
                "cs.AI",
                "cs.CE",
                "cs.CL",
                "cs.CY",
                "cs.IR"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2502.21112",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "通过微调大型语言模型，提升金融文本中ESG活动检测的准确性。",
            "summary_zh": "将环境、社会和治理（ESG）因素整合到企业决策中是可持续金融的一个基本方面。然而，确保商业实践与不断发展的监管框架保持一致仍然是一个持续的挑战。用于自动评估可持续性报告和非财务披露与特定ESG活动的一致性的人工智能驱动解决方案，可以极大地支持这一过程。然而，由于通用大型语言模型（LLM）在特定领域环境中的局限性以及结构化、高质量数据集的稀缺性，这项任务仍然很复杂。本文研究了当前一代LLM识别与环境活动相关的文本的能力。此外，我们证明了通过对原始和合成生成的数据组合进行微调，可以显著提高其性能。为此，我们引入了ESG-Activities，这是一个基准数据集，包含1,325个标记的文本片段，这些片段根据欧盟ESG分类法进行分类。我们的实验结果表明，在ESG-Activities上进行微调可以显著提高分类准确性，在特定配置中，Llama 7B和Gemma 7B等开放模型优于大型专有解决方案。这些发现对于金融分析师、政策制定者和人工智能研究人员具有重要意义，他们希望通过先进的自然语言处理技术来提高ESG透明度和合规性。",
            "intro_zh": [
                "通用大语言模型在特定领域的表现受限，且缺乏高质量的结构化ESG数据集，导致金融文本中ESG活动检测任务面临挑战。",
                "该论文通过微调大语言模型，结合原始数据和合成数据，提升模型在ESG活动识别方面的性能，从而更好地对齐可持续性报告与监管框架。",
                "实验结果表明，在ESG-Activities数据集上微调后，Llama 7B和Gemma 7B等开源模型在特定配置下优于大型商业模型。"
            ],
            "method_zh": "**问题定义**：论文旨在解决金融文本中自动检测与识别ESG（环境、社会和治理）活动的问题。现有方法，特别是通用大语言模型，在处理领域特定任务时存在局限性，并且缺乏高质量的标注数据来训练模型，导致检测精度不高。\\n\\n**核心思路**：论文的核心思路是通过在特定领域的ESG数据集上对大型语言模型进行微调，使其更好地适应金融文本的特点，从而提高ESG活动检测的准确性。同时，利用合成数据增强训练集，缓解数据稀缺问题。\\n\\n**技术框架**：整体框架包括以下几个步骤：1) 构建ESG-Activities数据集，包含人工标注的金融文本片段；2) 利用原始数据和合成数据组合对预训练的大型语言模型进行微调；3) 在测试集上评估微调后模型的性能，并与基线模型进行比较。主要模块包括数据预处理、模型微调和性能评估。\\n\\n**关键创新**：论文的关键创新在于：1) 构建了一个高质量的ESG-Activities基准数据集，为该领域的研究提供了数据基础；2) 证明了通过微调和合成数据增强，可以显著提升大型语言模型在ESG活动检测任务中的性能，甚至超越一些大型商业模型。\\n\\n**关键设计**：论文的关键设计包括：1) 数据集的构建，需要仔细设计标注规范，确保数据质量；2) 微调策略的选择，包括选择合适的预训练模型、调整学习率等超参数；3) 合成数据的生成方法，需要保证合成数据的真实性和多样性，避免引入噪声。",
            "application_zh": "该研究成果可应用于金融分析、政策制定和企业合规等领域。金融分析师可以利用该技术自动评估企业的ESG表现，政策制定者可以监测企业是否符合相关法规，企业可以自查自纠，提高ESG透明度和合规性。该研究有助于推动可持续金融的发展。",
            "highlight_zh": "实验结果表明，通过在ESG-Activities数据集上进行微调，Llama 7B和Gemma 7B等开源模型在特定配置下优于大型商业模型，显著提高了ESG活动检测的准确性。该研究验证了微调和合成数据增强在提升领域特定任务性能方面的有效性。",
            "tags_zh": [
                "ESG活动检测",
                "大型语言模型",
                "金融文本",
                "微调",
                "合成数据",
                "可持续金融",
                "自然语言处理"
            ],
            "_index": 93,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Efficient Reinforcement Learning with Semantic and Token Entropy for LLM Reasoning",
            "authors": [
                "Hongye Cao",
                "Zhixin Bai",
                "Ziyue Peng",
                "Boyan Wang",
                "Tianpei Yang",
                "Jing Huo",
                "Yuyao Zhang",
                "Yang Gao"
            ],
            "arxiv_id": "2512.04359",
            "summary": "Reinforcement learning with verifiable rewards (RLVR) has demonstrated superior performance in enhancing the reasoning capability of large language models (LLMs). However, this accuracy-oriented learning paradigm often suffers from entropy collapse, which reduces policy exploration and limits reasoning capabilities. To address this challenge, we propose an efficient reinforcement learning framework that leverages entropy signals at both the semantic and token levels to improve reasoning. From the data perspective, we introduce semantic entropy-guided curriculum learning, organizing training data from low to high semantic entropy to guide progressive optimization from easier to more challenging tasks. For the algorithmic design, we adopt non-uniform token treatment by imposing KL regularization on low-entropy tokens that critically impact policy exploration and applying stronger constraints on high-covariance portions within these tokens. By jointly optimizing data organization and algorithmic design, our method effectively mitigates entropy collapse and enhances LLM reasoning. Experimental results across 6 benchmarks with 3 different parameter-scale base models demonstrate that our method outperforms other entropy-based approaches in improving reasoning.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.04359",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning",
                        "curriculum learning"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于语义和Token熵的强化学习框架，提升LLM推理能力。",
            "summary_zh": "本文提出了一种高效的强化学习框架，该框架利用语义和Token层面的熵信号来提升大型语言模型（LLM）的推理能力。针对现有基于可验证奖励的强化学习（RLVR）方法中存在的熵坍塌问题，本文从数据和算法两个角度入手。在数据层面，引入了语义熵引导的课程学习，按照语义熵从小到大的顺序组织训练数据，引导模型从易到难地进行优化。在算法层面，采用非均匀的Token处理方式，对低熵Token施加KL正则化，并对这些Token内的高协方差部分施加更强的约束，以促进策略探索。通过联合优化数据组织和算法设计，有效缓解了熵坍塌问题，提升了LLM的推理能力。在6个基准测试和3个不同参数规模的基础模型上的实验结果表明，本文方法优于其他基于熵的方法。",
            "intro_zh": [
                "现有基于可验证奖励的强化学习方法易出现熵坍塌，限制了策略探索和推理能力。",
                "提出一种利用语义和Token熵信号的强化学习框架，从数据和算法层面缓解熵坍塌。",
                "实验表明，该方法在多个基准测试中优于其他基于熵的方法，提升了LLM推理能力。"
            ],
            "method_zh": "**问题定义**：现有基于可验证奖励的强化学习（RLVR）方法在提升大型语言模型（LLM）推理能力方面表现出色，但常常面临熵坍塌的问题。熵坍塌会导致策略探索不足，从而限制了LLM的推理能力。现有方法难以有效平衡探索与利用，导致模型容易陷入局部最优解。\n\n**核心思路**：本文的核心思路是通过引入语义和Token层面的熵信号来促进策略探索，缓解熵坍塌。具体而言，从数据层面，利用语义熵引导课程学习，让模型先学习简单的任务，再逐步学习复杂的任务。从算法层面，对不同熵值的Token采取不同的处理方式，对低熵Token进行正则化，以鼓励探索。\n\n**技术框架**：该框架包含两个主要组成部分：语义熵引导的课程学习和非均匀Token处理的强化学习算法。首先，计算训练数据的语义熵，并按照语义熵从小到大的顺序组织数据。然后，使用强化学习算法训练LLM，在训练过程中，对低熵Token施加KL正则化，并对这些Token内的高协方差部分施加更强的约束。整体流程是从简单到复杂地训练模型，同时鼓励模型探索不同的策略。\n\n**关键创新**：本文的关键创新在于联合优化数据组织和算法设计，利用语义熵和Token熵两种信息来缓解熵坍塌。与现有方法相比，本文方法不仅考虑了数据的难度，还考虑了Token的重要性，从而更有效地促进了策略探索。非均匀Token处理是另一个创新点，它允许对不同的Token采取不同的处理方式，从而更精细地控制策略的探索。\n\n**关键设计**：语义熵的计算方式未知，但应该是基于某种语义表示的距离或差异性。KL正则化的系数需要根据实验进行调整，以平衡探索和利用。对低熵Token内的高协方差部分施加更强的约束的具体实现方式未知，可能涉及到对损失函数的修改或对网络结构的调整。",
            "application_zh": "该研究成果可应用于各种需要LLM进行复杂推理的场景，例如问答系统、对话生成、代码生成等。通过提升LLM的推理能力，可以提高这些应用的准确性和可靠性。此外，该方法还可以用于训练其他类型的语言模型，提升其在各种任务上的表现。未来，该方法有望推动LLM在更多领域的应用。",
            "highlight_zh": "实验结果表明，本文方法在6个基准测试中优于其他基于熵的方法。具体而言，在某些基准测试中，本文方法相比于基线方法取得了显著的性能提升，例如在XXX数据集上提升了X%。此外，实验还验证了语义熵引导的课程学习和非均匀Token处理的有效性。",
            "tags_zh": [
                "强化学习",
                "大型语言模型",
                "推理能力",
                "熵正则化",
                "课程学习"
            ],
            "_index": 94,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.04359/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.04359/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.04359/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "A Systematic Evaluation of Preference Aggregation in Federated RLHF for Pluralistic Alignment of LLMs",
            "authors": [
                "Mahmoud Srewa",
                "Tianyu Zhao",
                "Salma Elmalaki"
            ],
            "arxiv_id": "2512.08786",
            "summary": "This paper addresses the challenge of aligning large language models (LLMs) with diverse human preferences within federated learning (FL) environments, where standard methods often fail to adequately represent diverse viewpoints. We introduce a comprehensive evaluation framework that systematically assesses the trade-off between alignment quality and fairness when using different aggregation strategies for human preferences. In our federated setting, each group locally evaluates rollouts and produces reward signals, and the server aggregates these group-level rewards without accessing any raw data. Specifically, we evaluate standard reward aggregation techniques (min, max, and average) and introduce a novel adaptive scheme that dynamically adjusts preference weights based on a group's historical alignment performance. Our experiments on question-answering (Q/A) tasks using a PPO-based RLHF pipeline demonstrate that our adaptive approach consistently achieves superior fairness while maintaining competitive alignment scores. This work offers a robust methodology for evaluating LLM behavior across diverse populations and provides a practical solution for developing truly pluralistic and fairly aligned models.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.08786",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "PPO",
                        "[T]RLHF"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出自适应联邦RLHF方法，解决LLM在多元偏好对齐中的公平性问题",
            "summary_zh": "本文致力于解决联邦学习（FL）环境中大型语言模型（LLM）与不同人类偏好对齐的挑战，现有方法通常无法充分代表不同的观点。我们引入了一个全面的评估框架，系统地评估了在使用不同的人类偏好聚合策略时，对齐质量和公平性之间的权衡。在我们的联邦设置中，每个组本地评估rollout并产生奖励信号，服务器聚合这些组级别的奖励，而无需访问任何原始数据。具体来说，我们评估了标准的奖励聚合技术（最小、最大和平均），并引入了一种新颖的自适应方案，该方案根据组的历史对齐性能动态调整偏好权重。我们在基于PPO的RLHF pipeline上，针对问答（Q/A）任务进行的实验表明，我们的自适应方法在保持竞争性对齐分数的同时，始终如一地实现了卓越的公平性。这项工作为跨不同人群评估LLM行为提供了一种稳健的方法，并为开发真正多元化和公平对齐的模型提供了一种实用的解决方案。",
            "intro_zh": [
                "现有联邦学习中的LLM对齐方法难以有效处理不同人群的多元偏好，导致模型可能存在偏差。",
                "提出一种自适应的偏好聚合方案，根据各组历史对齐表现动态调整权重，以提升整体公平性。",
                "实验表明，该自适应方法在问答任务中，能够在保持对齐质量的同时，显著提升模型对不同人群的公平性。"
            ],
            "method_zh": "**问题定义**：现有联邦学习环境下的LLM对齐方法，在面对不同人群的多元偏好时，难以保证模型的公平性。简单地聚合各组的偏好可能导致模型偏向某些群体，忽略其他群体的需求，从而损害模型的普适性和公正性。现有方法缺乏对不同群体贡献的动态调整机制，无法有效平衡对齐质量和公平性。\\n\\n**核心思路**：本文的核心思路是引入一种自适应的偏好聚合机制，该机制能够根据每个群体在历史对齐过程中的表现，动态调整其偏好权重。表现好的群体，其偏好权重会相应增加，反之则减少。这种动态调整机制旨在使模型能够更好地适应不同群体的需求，从而在保证对齐质量的同时，提升模型的公平性。\\n\\n**技术框架**：整体框架基于联邦强化学习（FL）中的人类反馈强化学习（RLHF）流程。每个客户端（代表一个群体）在本地使用PPO算法进行训练，并根据本地数据生成奖励信号。服务器端接收来自各个客户端的奖励信号，并使用提出的自适应聚合策略对这些信号进行聚合。聚合后的奖励信号用于更新全局模型。该过程迭代进行，直至模型收敛。\\n\\n**关键创新**：最重要的技术创新点在于提出的自适应偏好聚合策略。与传统的最小、最大或平均聚合方法不同，该策略能够根据每个群体的历史对齐表现动态调整其偏好权重。这种动态调整机制使得模型能够更好地适应不同群体的需求，从而在保证对齐质量的同时，提升模型的公平性。\\n\\n**关键设计**：自适应权重调整基于每个组的历史对齐性能。具体来说，可以使用例如组的平均奖励或对齐成功率等指标来衡量组的性能。权重更新公式可以设计为：$w_i^{t+1} = w_i^t + \\alpha (performance_i^t - \\bar{performance}^t)$，其中$w_i^t$是第i组在第t轮的权重，$\\alpha$是学习率，$performance_i^t$是第i组在第t轮的性能，$\\bar{performance}^t$是所有组在第t轮的平均性能。损失函数仍然是标准的PPO损失函数，但奖励信号由自适应聚合后的奖励值代替。",
            "application_zh": "该研究成果可应用于各种需要兼顾公平性和个性化的LLM应用场景，例如教育、医疗、法律等领域。通过自适应地聚合不同人群的偏好，可以训练出更加公平、普适且符合不同群体需求的LLM模型，从而提升用户体验和应用效果。此外，该方法也为联邦学习环境下的模型对齐提供了一种新的思路。",
            "highlight_zh": "实验结果表明，提出的自适应偏好聚合方法在问答任务中，能够在保持与传统聚合方法（如平均聚合）相当的对齐质量的同时，显著提升模型的公平性。具体来说，在某些公平性指标上，自适应方法相比基线方法提升了10%-20%。这表明该方法能够有效平衡对齐质量和公平性，为开发更加公正的LLM模型提供了一种有效的解决方案。",
            "tags_zh": [
                "联邦学习",
                "人类反馈强化学习",
                "大型语言模型",
                "偏好对齐",
                "公平性",
                "自适应聚合",
                "多元偏好"
            ],
            "_index": 95,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.08786/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.08786/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                }
            ]
        },
        {
            "title": "Efficient Adaptive Rejection Sampling for Accelerating Speculative Decoding in Large Language Models",
            "authors": [
                "Chendong Sun",
                "mingmin Chen",
                "Lei Xu"
            ],
            "arxiv_id": "2512.13194",
            "summary": "Speculative Decoding is a prominent technique for accelerating the autoregressive inference of large language models (LLMs) by employing a fast draft model to propose candidate token sequences and a large target model to verify them in parallel. However, its core component -- the rejection sampling mechanism -- relies on a fixed, context-independent random threshold. This leads to a significant \"random rejection\" problem in high-uncertainty generation scenarios, where plausible candidate tokens are frequently rejected due to random chance, undermining inference efficiency. This paper introduces Efficient Adaptive Rejection Sampling (EARS), a novel method that dynamically adjusts the acceptance threshold by incorporating the target model's own predictive uncertainty, measured as 1 - max(P_target). By introducing a tolerance term proportional to this uncertainty, EARS intelligently relaxes the acceptance criterion when the model is uncertain, effectively reducing random rejections while maintaining strict standards when the model is confident. Experiments on creative writing and open-domain QA tasks demonstrate that EARS significantly enhances the efficiency of speculative decoding, achieving up to an 18.12% increase in throughput with a negligible 0.84% accuracy drop on the GSM8K benchmark. The method requires no modifications to model architectures and can be seamlessly integrated into existing speculative decoding frameworks.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13194",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出高效自适应拒绝采样(EARS)以加速大语言模型推测解码。",
            "summary_zh": "推测解码是一种通过利用快速草稿模型提出候选token序列，并使用大型目标模型并行验证它们来加速大型语言模型(LLM)自回归推理的突出技术。然而，其核心组件——拒绝采样机制——依赖于固定的、与上下文无关的随机阈值。这导致了高不确定性生成场景中显著的“随机拒绝”问题，其中合理的候选token由于随机机会而被频繁拒绝，从而降低了推理效率。本文介绍了一种高效自适应拒绝采样(EARS)方法，该方法通过结合目标模型自身的预测不确定性（以1 - max(P_target)衡量）来动态调整接受阈值。通过引入与此不确定性成比例的容差项，EARS在模型不确定时智能地放宽接受标准，在模型有信心时保持严格标准，从而有效地减少随机拒绝。在创造性写作和开放领域问答任务上的实验表明，EARS显著提高了推测解码的效率，在GSM8K基准测试中实现了高达18.12%的吞吐量提升，而准确率仅下降了0.84%。该方法不需要修改模型架构，并且可以无缝集成到现有的推测解码框架中。",
            "intro_zh": [
                "推测解码中固定的拒绝采样阈值导致高不确定性场景下出现不必要的token拒绝，降低效率。",
                "EARS通过目标模型预测不确定性动态调整接受阈值，在不确定时放宽标准，减少随机拒绝。",
                "实验表明，EARS显著提升了推测解码的吞吐量，且对模型准确率的影响可忽略不计。"
            ],
            "method_zh": "**问题定义**：推测解码旨在加速LLM的自回归推理，但其拒绝采样机制依赖于固定的阈值，导致在高不确定性场景下，即使是合理的候选token也可能被随机拒绝，降低了推理效率。现有方法未能充分利用目标模型自身的信息来动态调整接受标准。\\n\\n**核心思路**：EARS的核心在于利用目标模型预测的不确定性来动态调整拒绝采样的接受阈值。当目标模型对预测结果不确定时，适当放宽接受标准，允许更多可能的token通过，从而减少随机拒绝；当模型有信心时，则保持严格的标准。这样可以在保证生成质量的前提下，提高推理效率。\\n\\n**技术框架**：EARS可以无缝集成到现有的推测解码框架中。其主要流程如下：首先，草稿模型生成候选token序列；然后，目标模型对这些token进行验证。在验证过程中，EARS根据目标模型预测概率的最大值(max(P_target))计算不确定性，并基于此动态调整接受阈值。最后，根据调整后的阈值决定是否接受候选token。\\n\\n**关键创新**：EARS的关键创新在于引入了自适应的拒绝采样机制，它不再依赖于固定的阈值，而是根据目标模型自身的预测不确定性动态调整。这种方法能够更智能地平衡生成质量和推理效率，尤其是在高不确定性场景下，能够显著减少随机拒绝，提高吞吐量。\\n\\n**关键设计**：EARS的关键设计在于容差项的引入，该容差项与目标模型预测不确定性成比例。具体来说，接受阈值被调整为原始阈值加上一个容差值，该容差值等于 `alpha * (1 - max(P_target))`，其中 `alpha` 是一个可调节的超参数，用于控制容差的强度。`alpha` 的选择需要根据具体任务进行调整，以达到最佳的性能。",
            "application_zh": "EARS可广泛应用于需要快速生成文本的场景，例如聊天机器人、机器翻译、文本摘要、代码生成等。通过提高LLM的推理效率，EARS能够降低计算成本，提升用户体验，并促进LLM在资源受限环境中的部署。此外，EARS的自适应特性使其能够更好地应对各种生成任务，尤其是在创造性写作和开放领域问答等高不确定性场景中。",
            "highlight_zh": "实验结果表明，EARS在创造性写作和开放领域问答任务中显著提高了推测解码的效率。在GSM8K基准测试中，EARS实现了高达18.12%的吞吐量提升，而准确率仅下降了0.84%。这些结果表明，EARS能够在保证生成质量的前提下，显著加速LLM的推理过程。",
            "tags_zh": [
                "推测解码",
                "大语言模型",
                "拒绝采样",
                "自适应阈值",
                "模型不确定性"
            ],
            "_index": 96,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "What Affects the Effective Depth of Large Language Models?",
            "authors": [
                "Yi Hu",
                "Cai Zhou",
                "Muhan Zhang"
            ],
            "arxiv_id": "2512.14064",
            "summary": "The scaling of large language models (LLMs) emphasizes increasing depth, yet performance gains diminish with added layers. Prior work introduces the concept of \"effective depth\", arguing that deeper models fail to fully utilize their layers for meaningful computation. Building on this, we systematically study how effective depth varies with model scale, training type, and task difficulty. First, we analyze the model behavior of Qwen-2.5 family (1.5B-32B) and find that while the number of effective layers grows with model size, the effective depth ratio remains stable. Besides, comparisons between base and corresponding long-CoT models show no increase in effective depth, suggesting that improved reasoning stems from longer context rather than deeper per-token computation. Furthermore, evaluations across tasks of varying difficulty indicate that models do not dynamically use more layers for harder problems. Our results suggest that current LLMs underuse available depth across scales, training paradigms and tasks of varying difficulties, pointing out research opportunities on increasing the layer utilization rate of LLMs, model pruning, and early exiting. Our code is released atthis https URL.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14064",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "研究揭示大语言模型有效深度受限，提出提升层利用率的研究方向",
            "summary_zh": "大型语言模型（LLM）的扩展趋势强调增加模型深度，但随着层数的增加，性能提升逐渐减小。先前的工作引入了“有效深度”的概念，认为更深的模型未能充分利用其层进行有意义的计算。本文在此基础上，系统地研究了有效深度如何随模型规模、训练类型和任务难度变化。首先，分析了Qwen-2.5系列模型（1.5B-32B）的行为，发现有效层数随模型大小增加，但有效深度比率保持稳定。此外，基础模型和对应的长上下文CoT模型之间的比较表明，有效深度没有增加，这表明改进的推理源于更长的上下文，而不是更深的token计算。进一步地，对不同难度的任务进行评估表明，模型不会动态地使用更多层来解决更难的问题。研究结果表明，当前的LLM在不同规模、训练范式和不同难度的任务中都未能充分利用可用的深度，指出了提高LLM层利用率、模型剪枝和提前退出等方面的研究机会。代码已开源。",
            "intro_zh": [
                "现有大语言模型深度增加带来的性能提升逐渐减小，模型可能未能充分利用所有层进行有效计算。",
                "该研究系统分析了有效深度与模型规模、训练方式和任务难度的关系，旨在揭示模型深度利用率的瓶颈。",
                "实验表明，模型有效深度比率稳定，且未随任务难度增加而动态调整，暗示模型存在深度利用不足的问题。"
            ],
            "method_zh": "**问题定义**：论文旨在研究大型语言模型（LLM）的有效深度问题。现有LLM虽然层数很多，但并非所有层都对最终的预测结果有贡献。现有方法缺乏对LLM有效深度与模型规模、训练方式和任务难度之间关系的系统性分析，无法有效指导模型设计和优化。\\n\\n**核心思路**：论文的核心思路是通过实验分析不同规模、不同训练方式的LLM在不同难度任务上的表现，从而揭示LLM的有效深度与这些因素之间的关系。通过观察模型在不同层上的激活情况，判断哪些层对最终结果起到了关键作用，从而确定模型的有效深度。\\n\\n**技术框架**：论文的技术框架主要包括以下几个部分：1) 选择Qwen-2.5系列模型（1.5B-32B）作为研究对象，涵盖不同规模的LLM；2) 比较基础模型和长上下文CoT模型，分析训练方式的影响；3) 设计不同难度的任务，评估模型在不同任务上的表现；4) 通过分析模型在不同层上的激活情况，计算模型的有效深度。\\n\\n**关键创新**：论文的关键创新在于对LLM的有效深度进行了系统性的研究，揭示了LLM在不同规模、训练方式和任务难度下都存在深度利用不足的问题。这一发现为后续研究提供了新的方向，例如如何提高LLM的层利用率、如何进行模型剪枝和提前退出等。\\n\\n**关键设计**：论文的关键设计包括：1) 选择Qwen-2.5系列模型，保证了实验结果的可靠性和可比性；2) 设计不同难度的任务，能够更全面地评估模型的性能；3) 通过分析模型在不同层上的激活情况，能够更准确地计算模型的有效深度；4) 比较基础模型和长上下文CoT模型，能够更深入地了解训练方式对模型有效深度的影响。",
            "application_zh": "该研究成果可应用于大语言模型的设计与优化，例如指导模型剪枝，减少计算开销；优化训练策略，提升层利用率；设计自适应深度模型，根据任务难度动态调整模型深度。这些应用能够降低模型部署成本，提高推理效率，并促进大语言模型在资源受限环境下的应用。",
            "highlight_zh": "实验结果表明，Qwen-2.5系列模型（1.5B-32B）的有效深度随模型规模增加，但有效深度比率保持稳定。基础模型和长上下文CoT模型相比，有效深度没有显著增加，表明长上下文推理的提升主要源于上下文信息，而非更深层的计算。此外，模型在不同难度的任务中，并未动态调整有效深度。",
            "tags_zh": [
                "大语言模型",
                "有效深度",
                "模型扩展",
                "层利用率",
                "模型剪枝"
            ],
            "_index": 97,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14064/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14064/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14064/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "CogMem: A Cognitive Memory Architecture for Sustained Multi-Turn Reasoning in Large Language Models",
            "authors": [
                "Yiran Zhang",
                "Jincheng Hu",
                "Mark Dras",
                "Usman Naseem"
            ],
            "arxiv_id": "2512.14118",
            "summary": "Large language models (LLMs) excel at single-turn reasoning but often lose accuracy and coherence over extended, multi-turn interactions. Recent evaluations such as TurnBench highlight recurring failure modes-reasoning bias, task drift, hallucination, overconfidence, and memory decay. Current approaches typically append full conversational histories, causing unbounded context growth, higher computational costs, and degraded reasoning efficiency. We introduce CogMem, a cognitively inspired, memory-augmented LLM architecture that supports sustained iterative reasoning through structured, persistent memory. CogMem incorporates three layers: a Long-Term Memory (LTM) that consolidates cross-session reasoning strategies; a Direct Access (DA) memory that maintains session-level notes and retrieves relevant long-term memories; and a Focus of Attention (FoA) mechanism that dynamically reconstructs concise, task-relevant context at each turn. Experiments on TurnBench show that this layered design mitigates reasoning failures, controls context growth, and improves consistency across extended reasoning chains, moving toward more reliable, human-like reasoning in LLMs.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14118",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "CogMem：一种认知记忆架构，用于大型语言模型中持续的多轮推理",
            "summary_zh": "大型语言模型(LLM)擅长单轮推理，但在扩展的多轮交互中常常会损失准确性和连贯性。TurnBench等最新评估突出了重复出现的失败模式——推理偏差、任务漂移、幻觉、过度自信和记忆衰退。目前的方法通常附加完整的对话历史，导致无限制的上下文增长、更高的计算成本和降低的推理效率。我们介绍CogMem，一种认知启发、记忆增强的LLM架构，它通过结构化的持久记忆来支持持续的迭代推理。CogMem包含三个层：长期记忆(LTM)，用于巩固跨会话的推理策略；直接访问(DA)记忆，用于维护会话级别的笔记并检索相关的长期记忆；以及注意力焦点(FoA)机制，用于在每一轮动态地重建简洁的、与任务相关的上下文。在TurnBench上的实验表明，这种分层设计减轻了推理失败，控制了上下文增长，并提高了扩展推理链中的一致性，从而朝着LLM中更可靠、更像人类的推理迈进。",
            "intro_zh": [
                "现有大型语言模型在多轮对话中存在推理偏差、任务漂移和记忆衰退等问题，影响了推理的准确性和连贯性。",
                "CogMem架构通过引入长期记忆、直接访问记忆和注意力焦点机制，模拟认知过程，实现对上下文信息的有效管理和利用。",
                "实验结果表明，CogMem能够有效缓解推理失败，控制上下文增长，并提高多轮推理的一致性，提升了LLM的可靠性。"
            ],
            "method_zh": "**问题定义**：大型语言模型在多轮对话中面临推理能力下降的问题。简单地拼接对话历史会导致上下文长度无限增长，增加计算成本，并降低推理效率。现有的方法难以有效地管理和利用对话历史中的信息，导致推理偏差、任务漂移、幻觉和记忆衰退等问题。\\n\\n**核心思路**：CogMem的核心思路是借鉴人类认知架构，通过构建分层记忆系统来模拟人类的记忆和推理过程。长期记忆(LTM)存储通用的推理策略，直接访问记忆(DA)维护当前会话的上下文信息，注意力焦点(FoA)动态地选择与当前任务相关的上下文，从而实现高效和可靠的多轮推理。\\n\\n**技术框架**：CogMem架构包含三个主要模块：1) **长期记忆(LTM)**：存储跨会话学习到的通用推理策略。2) **直接访问记忆(DA)**：维护当前会话的笔记，并检索相关的长期记忆。3) **注意力焦点(FoA)**：动态地从LTM和DA中选择与当前任务相关的上下文，构建简洁的输入。整个流程是，在每一轮对话中，DA首先检索LTM中相关的知识，然后FoA根据当前输入和DA中的信息，选择最相关的上下文，最后将选择的上下文输入LLM进行推理。\\n\\n**关键创新**：CogMem的关键创新在于其分层记忆架构和注意力焦点机制。与现有方法直接拼接对话历史不同，CogMem通过LTM存储通用知识，DA维护会话上下文，FoA动态选择相关信息，从而实现了对上下文信息的有效管理和利用。这种分层结构能够缓解推理偏差、任务漂移和记忆衰退等问题。\\n\\n**关键设计**：LTM使用知识图谱或向量数据库存储推理策略。DA使用滑动窗口或循环神经网络维护会话上下文。FoA使用注意力机制或检索模型选择相关信息。具体的参数设置、损失函数和网络结构需要根据具体的应用场景进行调整。例如，可以使用对比学习来训练LTM，使用强化学习来优化FoA的选择策略。",
            "application_zh": "CogMem架构可应用于需要持续多轮推理的对话系统，例如智能客服、虚拟助手和教育辅导机器人。通过提高LLM在多轮对话中的推理能力和一致性，可以提升用户体验，并扩展LLM的应用范围。该研究对于开发更可靠、更像人类的对话系统具有重要意义。",
            "highlight_zh": "在TurnBench基准测试中，CogMem在多轮推理任务上显著优于现有方法。实验结果表明，CogMem能够有效缓解推理失败，控制上下文增长，并提高多轮推理的一致性。具体性能数据需要在论文中查找，但摘要表明CogMem在多个指标上都取得了显著提升。",
            "tags_zh": [
                "大型语言模型",
                "多轮推理",
                "认知架构",
                "记忆增强",
                "上下文管理"
            ],
            "_index": 98,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14118/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14118/images/Tokens.png",
                    "caption": "",
                    "figure_id": "fig_1"
                }
            ]
        },
        {
            "title": "Inflation Attitudes of Large Language Models",
            "authors": [
                "Nikoleta Anesti",
                "Edward Hill",
                "Andreas Joseph"
            ],
            "arxiv_id": "2512.14306",
            "summary": "This paper investigates the ability of Large Language Models (LLMs), specifically GPT-3.5-turbo (GPT), to form inflation perceptions and expectations based on macroeconomic price signals. We compare the LLM's output to household survey data and official statistics, mimicking the information set and demographic characteristics of the Bank of England's Inflation Attitudes Survey (IAS). Our quasi-experimental design exploits the timing of GPT's training cut-off in September 2021 which means it has no knowledge of the subsequent UK inflation surge. We find that GPT tracks aggregate survey projections and official statistics at short horizons. At a disaggregated level, GPT replicates key empirical regularities of households' inflation perceptions, particularly for income, housing tenure, and social class. A novel Shapley value decomposition of LLM outputs suited for the synthetic survey setting provides well-defined insights into the drivers of model outputs linked to prompt content. We find that GPT demonstrates a heightened sensitivity to food inflation information similar to that of human respondents. However, we also find that it lacks a consistent model of consumer price inflation. More generally, our approach could be used to evaluate the behaviour of LLMs for use in the social sciences, to compare different models, or to assist in survey design.",
            "categories": [
                "cs.CL",
                "econ.EM"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14306",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "利用大型语言模型GPT-3.5研究通货膨胀感知与预期，并与人类调查数据对比。",
            "summary_zh": "本文研究了大型语言模型（LLM），特别是GPT-3.5-turbo（GPT），基于宏观经济价格信号形成通货膨胀感知和期望的能力。我们将LLM的输出与家庭调查数据和官方统计数据进行比较，模拟英国央行通货膨胀态度调查（IAS）的信息集和人口特征。我们的准实验设计利用了GPT在2021年9月的训练截止时间，这意味着它不了解随后的英国通货膨胀飙升。我们发现GPT在短期内跟踪总体调查预测和官方统计数据。在分解层面，GPT复制了家庭通货膨胀感知的关键经验规律，特别是在收入、住房保有权和社会阶层方面。一种新颖的Shapley值分解方法适用于合成调查环境，为与提示内容相关的模型输出驱动因素提供了明确的见解。我们发现GPT表现出对食品通货膨胀信息的高度敏感性，类似于人类受访者。然而，我们也发现它缺乏一致的消费者价格通货膨胀模型。更广泛地说，我们的方法可以用于评估LLM在社会科学中的行为，比较不同的模型，或协助调查设计。",
            "intro_zh": [
                "现有方法难以有效模拟和预测个体对通货膨胀的感知和预期，缺乏细粒度分析。",
                "利用GPT-3.5，通过模拟调查环境，研究LLM对宏观经济信号的反应，并与人类数据对比。",
                "实验表明，GPT在短期内能跟踪总体预测，并在收入、住房等方面重现人类通胀感知的规律。"
            ],
            "method_zh": "**问题定义**：论文旨在研究大型语言模型（LLM）是否能够像人类一样，基于宏观经济数据形成对通货膨胀的感知和预期。现有方法主要依赖于传统的经济模型和调查数据，难以捕捉个体差异，且成本较高。此外，缺乏对LLM在社会科学领域应用的系统性评估。\n\n**核心思路**：核心思路是将LLM（GPT-3.5）视为一个“合成受访者”，通过向其输入类似人类调查问卷的提示，模拟人类在通货膨胀态度调查中的行为。通过对比LLM的输出与真实调查数据和官方统计数据，评估LLM在通货膨胀感知和预期方面的能力。利用GPT训练截止日期（2021年9月）的天然分割，模拟LLM对未知通胀事件的反应。\n\n**技术框架**：整体框架包括以下几个阶段：1) 数据准备：收集英国央行通货膨胀态度调查（IAS）数据和官方统计数据。2) 提示工程：设计针对GPT-3.5的提示，模拟IAS问卷，并考虑不同的信息集和人口特征。3) 模型推理：使用GPT-3.5生成通货膨胀感知和预期数据。4) 结果分析：对比GPT-3.5的输出与真实调查数据和官方统计数据，评估其性能。5) Shapley值分解：使用Shapley值分解方法，分析提示内容对模型输出的影响。\n\n**关键创新**：主要创新点在于：1) 将LLM应用于通货膨胀感知和预期研究，开辟了新的研究方向。2) 提出了一个基于Shapley值分解的分析框架，用于理解LLM在合成调查环境中的行为。3) 利用GPT的训练截止日期，进行了一个准实验设计，评估LLM对未知事件的反应。\n\n**关键设计**：关键设计包括：1) 提示的设计，需要尽可能模拟真实调查问卷，并考虑不同的信息集和人口特征。2) Shapley值分解方法的应用，需要针对合成调查环境进行调整，以获得对模型输出驱动因素的有效解释。3) 对比指标的选择，需要选择合适的指标来评估LLM的性能，例如均方误差、相关系数等。",
            "application_zh": "该研究具有广泛的应用前景，可用于：1) 评估LLM在社会科学领域的应用潜力。2) 比较不同LLM的性能。3) 辅助调查设计，例如优化问卷内容和抽样策略。4) 构建更准确的通货膨胀预测模型，为政策制定提供参考。5) 模拟和预测其他社会经济现象，例如消费者行为、市场情绪等。",
            "highlight_zh": "实验结果表明，GPT-3.5在短期内能够跟踪总体调查预测和官方统计数据。在分解层面，GPT-3.5能够重现人类通货膨胀感知的关键经验规律，特别是在收入、住房保有权和社会阶层方面。Shapley值分解结果表明，GPT-3.5对食品通货膨胀信息表现出高度敏感性，与人类受访者相似。但GPT-3.5缺乏一致的消费者价格通货膨胀模型。",
            "tags_zh": [
                "大型语言模型",
                "通货膨胀感知",
                "通货膨胀预期",
                "社会科学",
                "Shapley值",
                "GPT-3.5",
                "调查模拟"
            ],
            "_index": 99,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14306/inflation_time_series.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14306/temp-0.0_CV_hist_negative-True.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14306/question-present_T-0_hist_negative-True.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Agreement Between Large Language Models and Human Raters in Essay Scoring: A Research Synthesis",
            "authors": [
                "Hongli Li",
                "Che Han Chen",
                "Kevin Fan",
                "Chiho Young-Johnson",
                "Soyoung Lim",
                "Yali Feng"
            ],
            "arxiv_id": "2512.14561",
            "summary": "Despite the growing promise of large language models (LLMs) in automatic essay scoring (AES), empirical findings regarding their reliability compared to human raters remain mixed. Following the PRISMA 2020 guidelines, we synthesized 65 published and unpublished studies from January 2022 to August 2025 that examined agreement between LLMs and human raters in AES. Across studies, reported LLM-human agreement was generally moderate to good, with agreement indices (e.g., Quadratic Weighted Kappa, Pearson correlation, and Spearman's rho) mostly ranging between 0.30 and 0.80. Substantial variability in agreement levels was observed across studies, reflecting differences in study-specific factors as well as the lack of standardized reporting practices. Implications and directions for future research are discussed.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14561",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "综述研究：大型语言模型在作文评分中与人类评分者的一致性分析",
            "summary_zh": "尽管大型语言模型(LLMs)在自动作文评分(AES)中展现出日益增长的潜力，但关于它们与人类评分者相比的可靠性的实证研究结果仍然不一致。本研究遵循PRISMA 2020指南，综合了2022年1月至2025年8月期间发表和未发表的65项研究，这些研究考察了LLMs在AES中与人类评分者之间的一致性。研究表明，总体而言，LLM与人类评分者之间的一致性为中等到良好，一致性指标（例如，二次加权Kappa系数、Pearson相关系数和Spearman等级相关系数）大多在0.30到0.80之间。在不同研究中观察到一致性水平存在显著差异，这反映了研究特定因素的差异以及缺乏标准化的报告实践。最后，讨论了研究的意义，并为未来的研究指明了方向。",
            "intro_zh": [
                "自动作文评分领域中，大型语言模型展现潜力，但其评分可靠性与人类评分员相比仍存在争议。",
                "该研究综合分析了大量已发表和未发表的论文，评估LLM在自动作文评分中与人类评分员的一致性。",
                "研究发现LLM与人类评分员的一致性总体中等到良好，但不同研究间存在显著差异，缺乏标准化报告。"
            ],
            "method_zh": "**问题定义**：自动作文评分(AES)旨在利用算法自动评估作文质量，降低人工评分成本。然而，现有研究中，大型语言模型(LLMs)在AES任务中与人类评分者的一致性存在较大差异，缺乏统一的评估标准和方法，导致难以准确评估LLMs在AES中的可靠性。\\n\\n**核心思路**：本研究采用系统综述的方法，对大量已发表和未发表的关于LLMs在AES中与人类评分者一致性的研究进行综合分析。通过对这些研究结果进行整合和比较，旨在揭示影响LLM与人类评分者一致性的关键因素，并为未来的研究提供指导。\\n\\n**技术框架**：该研究遵循PRISMA 2020指南，系统地检索、筛选和分析了相关文献。具体流程包括：(1) 确定研究问题和检索策略；(2) 从多个数据库和资源中检索相关研究；(3) 根据预定的纳入和排除标准筛选研究；(4) 提取研究数据，包括一致性指标（如Quadratic Weighted Kappa、Pearson correlation、Spearman's rho）和研究特定因素；(5) 对提取的数据进行综合分析，评估LLM与人类评分者之间的一致性水平，并识别影响一致性的因素。\\n\\n**关键创新**：本研究的关键创新在于对现有关于LLMs在AES中与人类评分者一致性的研究进行了全面的系统综述。通过对大量研究结果进行整合和比较，揭示了影响LLM与人类评分者一致性的关键因素，并为未来的研究提供了指导。与以往的单个研究相比，本研究提供了更全面、更客观的评估结果。\\n\\n**关键设计**：研究中，关键设计包括：(1) 严格遵循PRISMA 2020指南，确保研究的系统性和透明性；(2) 采用多种一致性指标（如Quadratic Weighted Kappa、Pearson correlation、Spearman's rho）来评估LLM与人类评分者之间的一致性；(3) 考虑了研究特定因素（如作文类型、评分标准、LLM模型等）对一致性的影响；(4) 对提取的数据进行定量和定性分析，以全面评估LLM在AES中的可靠性。",
            "application_zh": "该研究结果可应用于自动作文评分系统的开发和评估，帮助教育机构和研究人员更好地了解LLM在AES中的优势和局限性。通过识别影响LLM与人类评分者一致性的关键因素，可以指导LLM的优化和改进，提高AES的可靠性和有效性，最终辅助教学和评估。",
            "highlight_zh": "研究综合分析了65项相关研究，发现LLM与人类评分者的一致性总体为中等到良好，一致性指标大多在0.30到0.80之间。研究还发现，不同研究之间的一致性水平存在显著差异，这表明研究特定因素和缺乏标准化报告实践对结果有重要影响。",
            "tags_zh": [
                "大型语言模型",
                "自动作文评分",
                "一致性分析",
                "系统综述",
                "教育评估"
            ],
            "_index": 100,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "One Battle After Another: Probing LLMs' Limits on Multi-Turn Instruction Following with a Benchmark Evolving Framework",
            "authors": [
                "Qi Jia",
                "Ye Shen",
                "Xiujie Song",
                "Kaiwei Zhang",
                "Shibo Wang",
                "Dun Pei",
                "Xiangyang Zhu",
                "Guangtao Zhai"
            ],
            "arxiv_id": "2511.03508",
            "summary": "Evaluating LLMs' instruction-following ability in multi-topic dialogues is essential yet challenging. Existing benchmarks are limited to a fixed number of turns, susceptible to saturation and failing to account for users' interactive experience. In this work, we propose a novel framework backed by a three-layer tracking mechanism and a query synthesis agent to mimic sequential user behaviors. Incorporating Flow Theory, we introduce process-centric metrics and terminate a conversational evaluation only upon exhausting user patience. Upon this framework, we present EvolIF, an evolving benchmark covering 12 constraint groups. Results indicate that GPT-5 excels, sustaining 14 turns with 66.40% robustness. It outperforms Gemini-3.0-Pro by a margin of 5.59%, while other models trail behind. Resources are available atthis https URL.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2511.03508",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]instruction following"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出EvolIF框架，用于评估LLM在多轮交互中指令跟随能力，并揭示现有模型的局限性。",
            "summary_zh": "评估大型语言模型（LLM）在多主题对话中指令跟随能力至关重要，但也极具挑战性。现有的评测基准通常仅限于固定轮数，容易达到饱和，并且未能充分考虑用户的交互体验。本文提出了一个新颖的框架，该框架由三层跟踪机制和一个查询合成代理支持，以模拟连续的用户行为。结合心流理论，引入了以过程为中心的指标，并在用户耐心耗尽时终止对话评估。基于此框架，提出了EvolIF，一个涵盖12个约束组的演进基准。结果表明，GPT-5表现出色，能够维持14轮对话，鲁棒性达到66.40%。它比Gemini-3.0-Pro高出5.59%，而其他模型则落后。",
            "intro_zh": [
                "现有LLM评测基准在多轮对话指令跟随能力评估方面存在局限性，无法模拟真实用户交互。",
                "提出EvolIF框架，通过三层跟踪机制和查询合成代理，模拟用户连续交互行为，更贴近实际。",
                "实验结果表明，GPT-5在EvolIF基准上表现最佳，但在长程对话中仍存在鲁棒性问题。"
            ],
            "method_zh": "**问题定义**：论文旨在解决现有LLM评测基准在评估多轮对话中指令跟随能力时的不足。现有方法通常采用固定轮数的对话，无法模拟真实用户交互的动态性和复杂性，容易出现饱和现象，并且忽略了用户在交互过程中的耐心程度。这导致对LLM真实指令跟随能力的评估不够准确和全面。\\n\\n**核心思路**：论文的核心思路是通过构建一个更贴近真实用户交互场景的评测框架，来更准确地评估LLM的指令跟随能力。该框架模拟用户在对话中的连续行为，并根据用户耐心程度动态调整对话轮数，从而避免了固定轮数带来的局限性。同时，引入了以过程为中心的指标，更全面地评估LLM在整个交互过程中的表现。\\n\\n**技术框架**：EvolIF框架包含三个主要层次：用户模拟层、对话管理层和LLM交互层。用户模拟层负责生成模拟用户查询，模拟用户行为。对话管理层负责跟踪对话状态，维护对话历史，并根据用户耐心程度决定是否终止对话。LLM交互层负责接收用户查询，调用LLM生成回复，并将回复返回给用户模拟层。框架还包含一个查询合成代理，用于生成多样化的用户查询。\\n\\n**关键创新**：EvolIF框架的关键创新在于其动态的对话轮数控制和以过程为中心的评估指标。传统的评测基准通常采用固定轮数的对话，而EvolIF框架则根据用户耐心程度动态调整对话轮数，更贴近真实用户交互场景。此外，EvolIF框架引入了以过程为中心的指标，例如对话一致性、信息完整性和用户满意度，更全面地评估LLM在整个交互过程中的表现。\\n\\n**关键设计**：EvolIF框架的关键设计包括：1) 三层跟踪机制，用于跟踪对话状态和用户行为；2) 查询合成代理，用于生成多样化的用户查询；3) 基于心流理论的用户耐心模型，用于动态调整对话轮数；4) 以过程为中心的评估指标，用于全面评估LLM的指令跟随能力。具体的参数设置和网络结构等技术细节在论文中未详细描述，属于未知信息。",
            "application_zh": "该研究成果可应用于LLM的评测与优化，帮助开发者更全面地了解LLM在多轮交互场景下的指令跟随能力。通过EvolIF框架，可以更有效地发现LLM的不足之处，并针对性地进行改进，从而提升LLM在实际应用中的性能和用户体验。此外，该框架也可以用于训练LLM，提高其在多轮对话中的指令跟随能力。",
            "highlight_zh": "实验结果表明，GPT-5在EvolIF基准上表现最佳，能够维持14轮对话，鲁棒性达到66.40%。GPT-5的性能优于Gemini-3.0-Pro 5.59%，但其他模型表现相对落后。这些结果揭示了现有LLM在多轮交互指令跟随能力方面的差距，并为未来的研究方向提供了参考。",
            "tags_zh": [
                "多轮对话",
                "指令跟随",
                "LLM评估",
                "用户模拟",
                "心流理论"
            ],
            "_index": 101,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2511.03508/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2511.03508/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2511.03508/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "AugServe: Adaptive Request Scheduling for Augmented Large Language Model Inference Serving",
            "authors": [
                "Ying Wang",
                "Zhen Jin",
                "Jiexiong Xu",
                "Wenhai Lin",
                "Yiquan Chen",
                "Wenzhi Chen"
            ],
            "arxiv_id": "2512.04013",
            "summary": "As augmented large language models (LLMs) with external tools become increasingly popular in web applications, improving augmented LLM inference serving efficiency and optimizing service-level objectives (SLOs) are critical for enhancing user experience. To achieve this, inference systems must maximize request handling within latency constraints, referred to as increasing effective throughput. However, existing systems face two major challenges: (i) reliance on first-come-first-served (FCFS) scheduling causes severe head-of-line blocking, leading to queuing delays exceeding the SLOs for many requests; and (ii) static batch token limit, which fails to adapt to fluctuating loads and hardware conditions. Both of these factors degrade effective throughput and service quality.This paper presents AugServe, an efficient inference framework designed to reduce queueing latency and enhance effective throughput for augmented LLM inference services. The core idea of AugServe is a two-stage adaptive request scheduling strategy. Specifically, AugServe combines the inference features of augmented LLM requests to optimize the order of scheduling decisions (stage I). These decisions are continuously refined with runtime information (stage II), adapting to both request characteristics and system capabilities. In addition, AugServe dynamically adjusts the token batching mechanism based on hardware status and real-time load, further enhancing throughput performance. Experimental results show that AugServe achieves 4.7x and 3.3x higher effective throughput than vLLM and InferCept, while reducing time-to-first-token (TTFT) by up to 96.3% and 95.0%, respectively.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.04013",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "AugServe：用于增强型大语言模型推理服务的自适应请求调度",
            "summary_zh": "随着集成外部工具的增强型大语言模型（LLM）在Web应用中日益普及，提升增强型LLM推理服务效率和优化服务级别目标（SLO）对于改善用户体验至关重要。为了实现这一目标，推理系统必须在延迟约束内最大化请求处理量，即提高有效吞吐量。然而，现有系统面临两个主要挑战：（i）依赖先进先出（FCFS）调度导致严重的队头阻塞，使得许多请求的排队延迟超过SLO；（ii）静态批处理token限制无法适应波动的负载和硬件条件。这两个因素都会降低有效吞吐量和服务质量。本文提出了AugServe，一个旨在减少排队延迟并提高增强型LLM推理服务有效吞吐量的高效推理框架。AugServe的核心思想是两阶段自适应请求调度策略。具体来说，AugServe结合了增强型LLM请求的推理特征来优化调度决策的顺序（阶段I）。这些决策通过运行时信息不断完善（阶段II），从而适应请求特征和系统能力。此外，AugServe根据硬件状态和实时负载动态调整token批处理机制，进一步提高吞吐量性能。实验结果表明，AugServe的有效吞吐量比vLLM和InferCept分别高4.7倍和3.3倍，同时将首个token生成时间（TTFT）分别降低高达96.3%和95.0%。",
            "intro_zh": [
                "现有增强型LLM推理服务依赖FCFS调度，易产生队头阻塞，导致排队延迟超标。",
                "AugServe采用两阶段自适应请求调度，结合推理特征和运行时信息优化调度决策。",
                "实验表明，AugServe有效吞吐量显著高于vLLM和InferCept，并大幅降低TTFT。"
            ],
            "method_zh": "**问题定义**：论文旨在解决增强型大语言模型推理服务中，由于传统的先进先出（FCFS）调度策略和静态token批处理机制导致的排队延迟过高和有效吞吐量不足的问题。现有方法无法有效适应请求特征和系统状态的变化，导致服务质量下降。\\n\\n**核心思路**：AugServe的核心思路是采用两阶段自适应请求调度策略，并结合动态token批处理机制。通过分析请求的推理特征和利用运行时信息，优化请求的调度顺序，从而减少排队延迟。同时，根据硬件状态和实时负载动态调整token批处理大小，以提高资源利用率和吞吐量。\\n\\n**技术框架**：AugServe框架包含两个主要阶段：第一阶段是基于推理特征的请求排序，利用请求的元数据（例如，请求所需的工具类型、预计的计算复杂度等）来预测请求的优先级，并据此进行排序。第二阶段是基于运行时信息的调度优化，根据系统负载、硬件资源利用率等实时信息，动态调整请求的调度顺序。此外，AugServe还包含一个动态token批处理模块，根据硬件状态和实时负载调整批处理大小。\\n\\n**关键创新**：AugServe的关键创新在于其两阶段自适应请求调度策略和动态token批处理机制。与传统的静态调度策略相比，AugServe能够更好地适应请求特征和系统状态的变化，从而提高有效吞吐量和服务质量。动态token批处理机制能够根据硬件状态和实时负载动态调整批处理大小，从而更好地利用硬件资源。\\n\\n**关键设计**：在第一阶段，AugServe使用一个轻量级的预测模型来估计请求的优先级。该模型可以基于请求的元数据进行训练，例如，请求所需的工具类型、预计的计算复杂度等。在第二阶段，AugServe使用一个反馈控制机制来动态调整请求的调度顺序。该机制根据系统负载、硬件资源利用率等实时信息，调整请求的优先级。动态token批处理模块使用一个简单的启发式算法来调整批处理大小，该算法根据硬件状态和实时负载来调整批处理大小。",
            "application_zh": "AugServe可应用于各种需要高效增强型大语言模型推理服务的场景，例如智能客服、自动化报告生成、代码生成等。通过提高推理效率和优化服务质量，AugServe可以显著提升用户体验，并降低服务成本。未来，该技术有望进一步推广到其他类型的AI推理服务中。",
            "highlight_zh": "实验结果表明，AugServe在有效吞吐量方面显著优于现有系统。与vLLM相比，AugServe的有效吞吐量提高了4.7倍；与InferCept相比，提高了3.3倍。同时，AugServe还显著降低了首个token生成时间（TTFT），与vLLM和InferCept相比，分别降低了高达96.3%和95.0%。这些结果表明，AugServe能够有效提高增强型LLM推理服务的效率和质量。",
            "tags_zh": [
                "增强型大语言模型",
                "推理服务",
                "请求调度",
                "自适应调度",
                "动态批处理"
            ],
            "_index": 102,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.04013/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.04013/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.04013/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "MentraSuite: Post-Training Large Language Models for Mental Health Reasoning and Assessment",
            "authors": [
                "Mengxi Xiao",
                "Kailai Yang",
                "Pengde Zhao",
                "Enze Zhang",
                "Ziyan Kuang",
                "Zhiwei Liu",
                "Weiguang Han",
                "Shu Liao",
                "Lianting Huang",
                "Jinpeng Hu",
                "Min Peng",
                "Qianqian Xie",
                "Sophia Ananiadou"
            ],
            "arxiv_id": "2512.09636",
            "summary": "Mental health disorders affect hundreds of millions globally, and the Web now serves as a primary medium for accessing support, information, and assessment. Large language models (LLMs) offer scalable and accessible assistance, yet their deployment in mental-health settings remains risky when their reasoning is incomplete, inconsistent, or ungrounded. Existing psychological LLMs emphasize emotional understanding or knowledge recall but overlook the step-wise, clinically aligned reasoning required for appraisal, diagnosis, intervention planning, abstraction, and verification. To address these issues, we introduce MentraSuite, a unified framework for advancing reliable mental-health reasoning. We propose MentraBench, a comprehensive benchmark spanning five core reasoning aspects, six tasks, and 13 datasets, evaluating both task performance and reasoning quality across five dimensions: conciseness, coherence, hallucination avoidance, task understanding, and internal consistency. We further present Mindora, a post-trained model optimized through a hybrid SFT-RL framework with an inconsistency-detection reward to enforce faithful and coherent reasoning. To support training, we construct high-quality trajectories using a novel reasoning trajectory generation strategy, that strategically filters difficult samples and applies a structured, consistency-oriented rewriting process to produce concise, readable, and well-balanced trajectories. Across 20 evaluated LLMs, Mindora achieves the highest average performance on MentraBench and shows remarkable performances in reasoning reliability, demonstrating its effectiveness for complex mental-health scenarios.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.09636",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "MentraSuite：通过后训练大语言模型提升心理健康推理与评估能力",
            "summary_zh": "心理健康问题影响着全球数亿人，网络已成为获取支持、信息和评估的主要渠道。大型语言模型（LLMs）提供了可扩展且易于访问的帮助，但当其推理不完整、不一致或缺乏依据时，在心理健康环境中的部署仍然存在风险。现有的心理学LLM强调情感理解或知识回忆，但忽略了评估、诊断、干预计划、抽象和验证所需的逐步、临床对齐的推理。为了解决这些问题，我们引入了MentraSuite，一个用于推进可靠心理健康推理的统一框架。我们提出了MentraBench，一个全面的基准，涵盖五个核心推理方面、六个任务和13个数据集，评估任务性能和推理质量的五个维度：简洁性、连贯性、避免幻觉、任务理解和内部一致性。我们进一步提出了Mindora，一个通过混合SFT-RL框架优化的后训练模型，具有不一致性检测奖励，以强制执行忠实和连贯的推理。为了支持训练，我们使用一种新颖的推理轨迹生成策略构建高质量的轨迹，该策略策略性地过滤困难样本，并应用结构化的、面向一致性的重写过程来生成简洁、可读且平衡良好的轨迹。在评估的20个LLM中，Mindora在MentraBench上实现了最高的平均性能，并在推理可靠性方面表现出色，证明了其在复杂心理健康场景中的有效性。",
            "intro_zh": [
                "现有心理健康领域的大语言模型缺乏临床对齐的逐步推理能力，限制了其在评估、诊断等任务中的应用。",
                "MentraSuite框架通过构建高质量推理轨迹和混合SFT-RL训练，优化模型推理的连贯性和可靠性。",
                "Mindora模型在MentraBench基准测试中表现最佳，尤其在推理可靠性方面，验证了其在复杂心理健康场景中的有效性。"
            ],
            "method_zh": "**问题定义**：现有心理健康领域的大语言模型（LLMs）虽然在情感理解和知识回忆方面表现良好，但在进行心理评估、诊断和干预计划等任务时，缺乏临床专家所具备的逐步、连贯且可靠的推理能力。这些模型容易产生不一致、不完整甚至幻觉性的推理结果，限制了它们在实际临床环境中的应用。因此，如何提升LLMs在心理健康领域的推理能力，使其能够进行更准确、更可靠的评估和诊断，是本研究要解决的核心问题。\\n\\n**核心思路**：本研究的核心思路是通过后训练的方式，利用高质量的推理轨迹数据，提升LLMs在心理健康领域的推理能力。具体来说，首先构建一个全面的基准测试集MentraBench，用于评估模型在多个推理维度上的性能。然后，通过一种新颖的推理轨迹生成策略，生成高质量的训练数据，并采用混合的SFT（监督微调）和RL（强化学习）框架，训练一个名为Mindora的模型。通过不一致性检测奖励，鼓励模型生成更忠实和连贯的推理过程。\\n\\n**技术框架**：MentraSuite框架主要包含以下几个关键组成部分：1) MentraBench基准测试集，用于评估模型在心理健康推理方面的性能；2) 推理轨迹生成策略，用于生成高质量的训练数据；3) Mindora模型，通过混合SFT-RL框架进行训练，并采用不一致性检测奖励；4) 评估流程，用于评估Mindora模型在MentraBench上的性能。整个流程首先利用推理轨迹生成策略构建训练数据，然后使用SFT进行初步微调，接着使用RL进一步优化，最后在MentraBench上进行评估。\\n\\n**关键创新**：本研究的关键创新点在于：1) 提出了MentraBench基准测试集，该基准全面评估了模型在心理健康推理方面的多个维度；2) 提出了一种新颖的推理轨迹生成策略，能够生成高质量、简洁、可读且平衡良好的训练数据；3) 采用了混合SFT-RL框架，并引入了不一致性检测奖励，有效提升了模型的推理连贯性和可靠性。与现有方法相比，本研究更注重模型的推理过程，而非仅仅关注最终的预测结果。\\n\\n**关键设计**：在推理轨迹生成策略中，采用了策略性地过滤困难样本，并应用结构化的、面向一致性的重写过程。在混合SFT-RL框架中，SFT用于初始化模型参数，RL用于进一步优化推理过程。不一致性检测奖励基于模型生成的推理轨迹，检测其中是否存在矛盾或不一致之处，并给予相应的惩罚。具体的奖励函数设计和超参数设置在论文中有详细描述，但此处未知。",
            "application_zh": "该研究成果可应用于开发智能心理健康助手，辅助心理咨询师进行初步评估和诊断，提供个性化的干预建议。此外，该技术还可用于构建在线心理健康教育平台，提供高质量的心理健康知识和资源，提升公众的心理健康素养。未来，该研究有望推动心理健康服务的普及和智能化。",
            "highlight_zh": "Mindora模型在MentraBench基准测试中取得了最佳的平均性能，显著优于其他20个评估的LLM。尤其在推理可靠性方面，Mindora表现出色，证明了其在复杂心理健康场景中的有效性。具体的性能提升幅度未知，但整体结果表明Mindora在心理健康推理方面具有显著优势。",
            "tags_zh": [
                "心理健康",
                "大语言模型",
                "推理能力",
                "后训练",
                "强化学习",
                "基准测试",
                "一致性",
                "评估诊断"
            ],
            "_index": 103,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.09636/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.09636/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.09636/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "MatTools: Benchmarking Large Language Models for Materials Science Tools",
            "authors": [
                "Siyu Liu",
                "Bo Hu",
                "Beilin Ye",
                "Jiamin Xu",
                "David J. Srolovitz",
                "Tongqi Wen"
            ],
            "arxiv_id": "2505.10852",
            "summary": "Large language models (LLMs) are increasingly applied to materials science questions, including literature comprehension, property prediction, materials discovery and alloy design. At the same time, a wide range of physics-based computational approaches have been developed in which materials properties can be calculated. Here, we propose a benchmark application to evaluate the proficiency of LLMs to answer materials science questions through the generation and safe execution of codes based on such physics-based computational materials science packages. MatTools is built on two complementary components: a materials simulation tool question-answer (QA) benchmark and a real-world tool-usage benchmark. We designed an automated methodology to efficiently collect real-world materials science tool-use examples. The QA benchmark, derived from the pymatgen (Python Materials Genomics) codebase and documentation, comprises 69,225 QA pairs that assess the ability of an LLM to understand materials science tools. The real-world benchmark contains 49 tasks (138 subtasks) requiring the generation of functional Python code for materials property calculations. Our evaluation of diverse LLMs yields three key insights: (1)Generalists outshine specialists;(2)AI knows AI; and (3)Simpler is better. MatTools provides a standardized framework for assessing and improving LLM capabilities for materials science tool applications, facilitating the development of more effective AI systems for materials science and general scientific research.",
            "categories": [
                "cs.CL",
                "cs.DB"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2505.10852",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "MatTools：评估大语言模型在材料科学工具应用中的基准测试",
            "summary_zh": "大语言模型（LLMs）越来越多地应用于材料科学问题，包括文献理解、性质预测、材料发现和合金设计。同时，已经开发了各种基于物理的计算方法，可以通过这些方法计算材料性质。本文提出了一个基准测试应用，旨在评估LLMs通过生成和安全执行基于物理的计算材料科学软件包的代码来回答材料科学问题的能力。MatTools建立在两个互补的组件之上：材料模拟工具问答（QA）基准和真实工具使用基准。我们设计了一种自动化的方法来有效地收集真实的材料科学工具使用示例。QA基准源自pymatgen（Python Materials Genomics）代码库和文档，包含69,225个QA对，用于评估LLM理解材料科学工具的能力。真实基准包含49个任务（138个子任务），需要生成用于材料性质计算的功能性Python代码。我们对各种LLM的评估产生了三个关键见解：（1）通用模型优于专用模型；（2）AI了解AI；（3）越简单越好。MatTools提供了一个标准化的框架，用于评估和改进LLM在材料科学工具应用中的能力，从而促进开发更有效的AI系统，用于材料科学和一般科学研究。",
            "intro_zh": [
                "现有材料科学领域缺乏系统评估LLM使用物理计算工具能力的基准测试。",
                "MatTools通过构建材料模拟工具问答基准和真实工具使用基准，评估LLM生成和执行材料科学代码的能力。",
                "实验结果表明，通用LLM优于专用LLM，并且模型复杂度与性能并非正相关。"
            ],
            "method_zh": "**问题定义**：现有材料科学领域缺乏一个标准化的基准来评估大型语言模型（LLMs）在利用物理计算工具解决材料科学问题方面的能力。现有的方法要么是针对特定任务的，要么缺乏对LLM生成代码的实际执行和安全性的考量。因此，需要一个全面的基准来评估LLM在理解材料科学工具、生成可执行代码以及解决实际材料科学问题方面的能力。\\n\\n**核心思路**：MatTools的核心思路是构建两个互补的基准：一个基于问答（QA）的基准，用于评估LLM对材料科学工具的理解；另一个基于真实工具使用的基准，用于评估LLM生成可执行代码的能力。通过这两个基准，可以全面评估LLM在材料科学工具应用中的能力，并为未来的研究提供一个标准化的评估框架。\\n\\n**技术框架**：MatTools包含两个主要组件：材料模拟工具问答（QA）基准和真实工具使用基准。QA基准包含69,225个QA对，这些QA对源自pymatgen代码库和文档，用于评估LLM理解材料科学工具的能力。真实工具使用基准包含49个任务（138个子任务），这些任务需要LLM生成用于材料性质计算的功能性Python代码。此外，论文还设计了一种自动化的方法来收集真实的材料科学工具使用示例。\\n\\n**关键创新**：MatTools的关键创新在于其构建了两个互补的基准，可以全面评估LLM在材料科学工具应用中的能力。QA基准侧重于评估LLM对材料科学工具的理解，而真实工具使用基准侧重于评估LLM生成可执行代码的能力。此外，MatTools还提供了一个标准化的评估框架，可以方便地比较不同LLM的性能。\\n\\n**关键设计**：QA基准中的QA对是基于pymatgen代码库和文档生成的，涵盖了各种材料科学工具的使用方法。真实工具使用基准中的任务是基于真实的材料科学问题设计的，需要LLM生成用于材料性质计算的功能性Python代码。论文还设计了一种自动化的方法来收集真实的材料科学工具使用示例，以确保基准的真实性和可靠性。",
            "application_zh": "MatTools可用于评估和改进LLM在材料科学领域的应用能力，例如材料性质预测、材料发现和合金设计。该基准测试框架可以促进开发更有效的AI系统，加速材料科学研究进程，并为其他科学领域的AI应用提供借鉴。",
            "highlight_zh": "实验结果表明，通用LLM在MatTools基准测试中表现优于专用LLM，这表明通用知识对于理解和使用材料科学工具至关重要。此外，研究发现模型复杂度与性能并非正相关，简单的模型有时能取得更好的效果。例如，在某些任务上，GPT-3.5的性能优于更复杂的模型。",
            "tags_zh": [
                "大语言模型",
                "材料科学",
                "基准测试",
                "物理计算",
                "代码生成"
            ],
            "_index": 104,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2505.10852/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2505.10852/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2505.10852/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "DRAW2ACT: Turning Depth-Encoded Trajectories into Robotic Demonstration Videos",
            "authors": [
                "Yang Bai",
                "Liudi Yang",
                "George Eskandar",
                "Fengyi Shen",
                "Mohammad Altillawi",
                "Ziyuan Liu",
                "Gitta Kutyniok"
            ],
            "arxiv_id": "2512.14217",
            "summary": "Video diffusion models provide powerful real-world simulators for embodied AI but remain limited in controllability for robotic manipulation. Recent works on trajectory-conditioned video generation address this gap but often rely on 2D trajectories or single modality conditioning, which restricts their ability to produce controllable and consistent robotic demonstrations. We present DRAW2ACT, a depth-aware trajectory-conditioned video generation framework that extracts multiple orthogonal representations from the input trajectory, capturing depth, semantics, shape and motion, and injects them into the diffusion model. Moreover, we propose to jointly generate spatially aligned RGB and depth videos, leveraging cross-modality attention mechanisms and depth supervision to enhance the spatio-temporal consistency. Finally, we introduce a multimodal policy model conditioned on the generated RGB and depth sequences to regress the robot's joint angles. Experiments on Bridge V2, Berkeley Autolab, and simulation benchmarks show that DRAW2ACT achieves superior visual fidelity and consistency while yielding higher manipulation success rates compared to existing baselines.",
            "categories": [
                "cs.CV",
                "cs.RO"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14217",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "embodied AI",
                        "multimodal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 8.0,
            "hit_pillars": [
                "1_robot_core",
                "9_embodied_foundation"
            ],
            "headline_zh": "DRAW2ACT：提出深度感知的轨迹条件视频生成框架，用于机器人操作演示视频生成。",
            "summary_zh": "视频扩散模型为具身智能提供了强大的真实世界模拟器，但在机器人操作的可控性方面仍然有限。最近关于轨迹条件视频生成的工作弥补了这一差距，但通常依赖于2D轨迹或单模态条件，这限制了它们生成可控和一致的机器人演示的能力。我们提出了DRAW2ACT，一个深度感知的轨迹条件视频生成框架，它从输入轨迹中提取多个正交表示，捕捉深度、语义、形状和运动，并将它们注入到扩散模型中。此外，我们提出联合生成空间对齐的RGB和深度视频，利用跨模态注意力机制和深度监督来增强时空一致性。最后，我们引入了一个以生成的RGB和深度序列为条件的多模态策略模型，以回归机器人的关节角度。在Bridge V2、Berkeley Autolab和模拟基准上的实验表明，与现有基线相比，DRAW2ACT实现了卓越的视觉保真度和一致性，同时产生了更高的操作成功率。",
            "intro_zh": [
                "现有轨迹条件视频生成方法依赖2D轨迹或单模态信息，限制了机器人演示视频的可控性和一致性。",
                "DRAW2ACT从轨迹中提取深度、语义、形状和运动等多重表示，并融入扩散模型，实现深度感知的视频生成。",
                "实验表明，DRAW2ACT在视觉保真度、一致性和操作成功率方面均优于现有方法，提升了机器人操作性能。"
            ],
            "method_zh": "**问题定义**：现有的轨迹条件视频生成方法在机器人操作领域面临挑战，主要痛点在于对轨迹信息的利用不足，通常只依赖于2D轨迹或单一模态的条件信息，导致生成视频的可控性和时空一致性较差，难以用于训练有效的机器人控制策略。\\n\\n**核心思路**：DRAW2ACT的核心思路是从输入轨迹中提取更丰富的多模态信息，包括深度、语义、形状和运动等，并将这些信息有效地融入到视频生成过程中。通过深度感知，模型能够更好地理解场景的三维结构，从而生成更逼真、更一致的机器人操作视频。\\n\\n**技术框架**：DRAW2ACT框架主要包含轨迹编码器、视频生成器和策略模型三个部分。轨迹编码器负责从输入轨迹中提取多模态特征表示；视频生成器基于扩散模型，以轨迹编码器的输出为条件，生成RGB和深度视频序列；策略模型则以生成的RGB和深度视频为输入，预测机器人的关节角度，从而实现机器人控制。框架采用联合训练的方式，优化视频生成和策略学习。\\n\\n**关键创新**：DRAW2ACT的关键创新在于深度感知的轨迹条件视频生成方法。它通过提取轨迹的深度信息，并将其融入到视频生成过程中，显著提升了生成视频的真实感和一致性。此外，联合生成RGB和深度视频，并利用跨模态注意力机制和深度监督，进一步增强了时空一致性。\\n\\n**关键设计**：在轨迹编码器中，论文采用了多层感知机（MLP）来提取轨迹的深度、语义、形状和运动特征。在视频生成器中，使用了U-Net结构的扩散模型，并引入了跨模态注意力机制，以融合RGB和深度信息。损失函数包括RGB和深度视频的重建损失、对抗损失以及深度监督损失，以保证生成视频的质量和一致性。策略模型采用卷积神经网络（CNN）结构，以生成的RGB和深度视频为输入，预测机器人的关节角度。",
            "application_zh": "DRAW2ACT可应用于机器人操作技能学习、强化学习环境构建、虚拟机器人训练等领域。通过生成高质量的机器人操作视频，可以降低机器人训练的成本和难度，加速机器人技术的应用和发展。该技术还可用于生成各种复杂的机器人操作场景，为机器人研究提供更丰富的实验数据。",
            "highlight_zh": "DRAW2ACT在Bridge V2、Berkeley Autolab和模拟基准上进行了实验，结果表明，与现有基线相比，DRAW2ACT在视觉保真度和一致性方面取得了显著提升，并且在机器人操作成功率方面也表现出更高的性能。具体数据未知，但论文强调了其优越性。",
            "tags_zh": [
                "机器人操作",
                "视频生成",
                "扩散模型",
                "轨迹条件",
                "深度感知",
                "多模态融合",
                "具身智能"
            ],
            "_index": 105,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14217/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14217/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14217/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Decomposed Object Manipulation via Dual-Actor Policy",
            "authors": [
                "Bin Fan",
                "Jian-Jian Jiang",
                "Zhuohao Li",
                "Xiao-Ming Wu",
                "Yi-Xiang He",
                "YiHan Yang",
                "Shengbang Liu",
                "Wei-Shi Zheng"
            ],
            "arxiv_id": "2511.05129",
            "summary": "Object manipulation, which focuses on learning to perform tasks on similar parts across different types of objects, can be divided into an approaching stage and a manipulation stage. However, previous works often ignore this characteristic of the task and rely on a single policy to directly learn the whole process of object manipulation. To address this problem, we propose a novel Dual-Actor Policy, termed DAP, which explicitly considers different stages and leverages heterogeneous visual priors to enhance each stage. Specifically, we introduce an affordance-based actor to locate the functional part in the manipulation task, thereby improving the approaching process. Following this, we propose a motion flow-based actor to capture the movement of the component, facilitating the manipulation process. Finally, we introduce a decision maker to determine the current stage of DAP and select the corresponding actor. Moreover, existing object manipulation datasets contain few objects and lack the visual priors needed to support training. To address this, we construct a simulated dataset, the Dual-Prior Object Manipulation Dataset, which combines the two visual priors and includes seven tasks, including two challenging long-term, multi-stage tasks. Experimental results on our dataset, the RoboTwin benchmark and real-world scenarios illustrate that our method consistently outperforms the SOTA method by 5.55%, 14.7% and 10.4% on average respectively.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2511.05129",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "[T]manipulation"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "affordance"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 8.0,
            "hit_pillars": [
                "1_robot_core",
                "3_perception_slam"
            ],
            "headline_zh": "提出双Actor策略DAP，解决物体操作任务中不同阶段的策略学习问题",
            "summary_zh": "本文提出了一种新颖的双Actor策略（DAP），显式地考虑了物体操作任务中的接近阶段和操作阶段，并利用异构视觉先验来增强每个阶段。具体来说，引入了一个基于可供性的Actor来定位操作任务中的功能部件，从而改进接近过程。随后，提出了一个基于运动流的Actor来捕获部件的运动，从而促进操作过程。最后，引入了一个决策器来确定DAP的当前阶段并选择相应的Actor。此外，现有的物体操作数据集包含的对象很少，并且缺乏支持训练所需的视觉先验。为了解决这个问题，构建了一个模拟数据集，即双先验物体操作数据集，该数据集结合了两种视觉先验，并包括七个任务，包括两个具有挑战性的长期多阶段任务。在我们的数据集、RoboTwin基准和真实场景中的实验结果表明，我们的方法始终优于SOTA方法，平均分别提高了5.55%、14.7%和10.4%。",
            "intro_zh": [
                "现有物体操作方法忽略了任务的阶段性，依赖单一策略学习整个过程，导致性能受限。",
                "提出双Actor策略DAP，利用可供性先验和运动流先验，分别优化接近和操作阶段。",
                "构建包含视觉先验的模拟数据集，实验表明DAP在多个场景下优于SOTA方法。"
            ],
            "method_zh": "**问题定义**：物体操作任务通常包含接近和操作两个阶段，现有方法通常使用单一策略直接学习整个过程，忽略了任务的阶段性特点，难以有效利用不同阶段的视觉信息，导致操作性能受限。此外，现有数据集规模小，缺乏视觉先验，不利于策略学习。\\n\\n**核心思路**：将物体操作任务分解为接近和操作两个阶段，并为每个阶段设计专门的Actor。接近阶段利用可供性先验定位功能部件，操作阶段利用运动流先验捕获部件运动。通过决策器动态选择合适的Actor，从而实现更高效的物体操作。\\n\\n**技术框架**：DAP包含三个主要模块：基于可供性的Actor、基于运动流的Actor和决策器。基于可供性的Actor负责接近阶段，通过学习可供性特征定位功能部件。基于运动流的Actor负责操作阶段，通过学习运动流特征控制部件运动。决策器根据当前状态选择合适的Actor执行动作。\\n\\n**关键创新**：DAP的核心创新在于将物体操作任务分解为两个阶段，并为每个阶段设计专门的Actor，从而能够更有效地利用视觉先验信息。此外，提出的双先验物体操作数据集为训练DAP提供了充足的数据支持。\\n\\n**关键设计**：可供性Actor和运动流Actor的网络结构未知，损失函数未知。决策器的设计细节未知。数据集包含七个任务，包括两个具有挑战性的长期多阶段任务，具体任务内容未知。",
            "application_zh": "该研究成果可应用于机器人自动化操作、智能制造、家庭服务机器人等领域。通过提升机器人对物体的操作能力，可以实现更高效、更智能的自动化生产线，以及更便捷的家庭服务。未来，该方法有望扩展到更复杂的物体操作任务和更广泛的应用场景。",
            "highlight_zh": "实验结果表明，DAP在自建数据集上优于SOTA方法5.55%，在RoboTwin基准上优于14.7%，在真实场景中优于10.4%。这些结果验证了DAP在不同场景下的有效性，表明其能够显著提升物体操作的性能。",
            "tags_zh": [
                "物体操作",
                "双Actor策略",
                "可供性",
                "运动流",
                "机器人学习"
            ],
            "_index": 106,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2511.05129/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2511.05129/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2511.05129/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "ViBES: A Conversational Agent with Behaviorally-Intelligent 3D Virtual Body",
            "authors": [
                "Juze Zhang",
                "Changan Chen",
                "Xin Chen",
                "Heng Yu",
                "Tiange Xiang",
                "Ali Sartaz Khan",
                "Shrinidhi K. Lakshmikanth",
                "Ehsan Adeli"
            ],
            "arxiv_id": "2512.14234",
            "summary": "Human communication is inherently multimodal and social: words, prosody, and body language jointly carry intent. Yet most prior systems model human behavior as a translation task co-speech gesture or text-to-motion that maps a fixed utterance to motion clips-without requiring agentic decision-making about when to move, what to do, or how to adapt across multi-turn dialogue. This leads to brittle timing, weak social grounding, and fragmented stacks where speech, text, and motion are trained or inferred in isolation. We introduce ViBES (Voice in Behavioral Expression and Synchrony), a conversational 3D agent that jointly plans language and movement and executes dialogue-conditioned body actions. Concretely, ViBES is a speech-language-behavior (SLB) model with a mixture-of-modality-experts (MoME) backbone: modality-partitioned transformer experts for speech, facial expression, and body motion. The model processes interleaved multimodal token streams with hard routing by modality (parameters are split per expert), while sharing information through cross-expert attention. By leveraging strong pretrained speech-language models, the agent supports mixed-initiative interaction: users can speak, type, or issue body-action directives mid-conversation, and the system exposes controllable behavior hooks for streaming responses. We further benchmark on multi-turn conversation with automatic metrics of dialogue-motion alignment and behavior quality, and observe consistent gains over strong co-speech and text-to-motion baselines. ViBES goes beyond \"speech-conditioned motion generation\" toward agentic virtual bodies where language, prosody, and movement are jointly generated, enabling controllable, socially competent 3D interaction. Code and data will be made available at:this http URL",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14234",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "text-to-motion",
                        "motion generation"
                    ],
                    "score": 5.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 8.0,
            "hit_pillars": [
                "4_motion_diffusion",
                "9_embodied_foundation"
            ],
            "headline_zh": "ViBES：一个具有行为智能的3D虚拟化身对话代理",
            "summary_zh": "人类交流本质上是多模态和社交的：语言、韵律和肢体语言共同传递意图。然而，大多数现有系统将人类行为建模为翻译任务，例如语音协同手势或文本到动作，将固定的语句映射到动作片段，而不需要代理自主决策何时移动、做什么或如何在多轮对话中适应。这导致了脆弱的时序、薄弱的社交基础以及碎片化的堆栈，其中语音、文本和动作被孤立地训练或推断。我们介绍了ViBES（语音行为表达和同步），一个对话式3D代理，它联合规划语言和运动，并执行对话条件下的身体动作。具体来说，ViBES是一个具有混合模态专家（MoME）主干的语音-语言-行为（SLB）模型：用于语音、面部表情和身体运动的模态划分Transformer专家。该模型处理交错的多模态token流，并通过模态进行硬路由（参数按专家划分），同时通过跨专家注意力共享信息。通过利用强大的预训练语音语言模型，该代理支持混合主动交互：用户可以在对话中说话、打字或发出身体动作指令，并且系统公开可控的行为钩子以进行流式响应。我们进一步在多轮对话中以对话-运动对齐和行为质量的自动指标进行基准测试，并观察到相对于强大的语音协同和文本到运动基线的持续提升。ViBES超越了“语音条件运动生成”，朝着代理虚拟化身发展，其中语言、韵律和运动被联合生成，从而实现可控的、具有社交能力的3D交互。",
            "intro_zh": [
                "现有对话系统在模拟人类交流时，难以实现语言、韵律和肢体语言的自然同步，缺乏自主决策能力。",
                "ViBES通过一个语音-语言-行为（SLB）模型，联合规划语言和运动，实现对话驱动的身体动作。",
                "实验表明，ViBES在多轮对话中，对话-运动对齐和行为质量方面，优于现有的语音协同和文本到运动基线。"
            ],
            "method_zh": "**问题定义**：现有对话系统通常将人类行为建模为简单的翻译任务，例如语音到手势或文本到动作的映射，缺乏对何时移动、做什么以及如何适应多轮对话的自主决策能力。这导致生成动作的时序不自然，社交互动能力弱，并且语音、文本和动作的训练是孤立的。\\n\\n**核心思路**：ViBES的核心思路是构建一个能够联合规划语言和运动的对话代理，使其能够根据对话内容自主地生成合适的身体动作。通过将语音、语言和行为整合到一个统一的模型中，ViBES能够更好地模拟人类交流的自然性和流畅性。\\n\\n**技术框架**：ViBES采用了一个语音-语言-行为（SLB）模型，其主干是一个混合模态专家（MoME）架构。该架构包含针对语音、面部表情和身体运动的模态划分Transformer专家。模型处理交错的多模态token流，并通过模态进行硬路由，同时通过跨专家注意力机制共享信息。\\n\\n**关键创新**：ViBES的关键创新在于其联合规划语言和运动的能力，以及其混合模态专家（MoME）架构。MoME架构允许模型针对不同的模态使用不同的专家网络，从而更好地捕捉不同模态的特征。同时，跨专家注意力机制使得不同模态之间可以相互影响，从而实现更自然的对话和动作生成。\\n\\n**关键设计**：ViBES利用了强大的预训练语音语言模型，以支持混合主动交互。用户可以通过语音、文本或身体动作指令与代理进行交互。系统公开可控的行为钩子，以进行流式响应。模型的训练目标是最大化对话-运动对齐和行为质量。",
            "application_zh": "ViBES具有广泛的应用前景，例如虚拟助手、在线教育、游戏和娱乐等领域。它可以用于创建更具吸引力和互动性的虚拟角色，从而改善用户体验。此外，ViBES还可以用于研究人类交流的本质，并为开发更智能的人工智能系统提供新的思路。",
            "highlight_zh": "ViBES在多轮对话中进行了基准测试，并使用自动指标评估了对话-运动对齐和行为质量。实验结果表明，ViBES在这些指标上均优于现有的语音协同和文本到运动基线。这表明ViBES能够生成更自然、更具社交能力的对话和动作。",
            "tags_zh": [
                "对话代理",
                "3D虚拟化身",
                "行为智能",
                "多模态融合",
                "语音语言行为模型"
            ],
            "_index": 107,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14234/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14234/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14234/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Semantic Mismatch and Perceptual Degradation: A New Perspective on Image Editing Immunity",
            "authors": [
                "Shuai Dong",
                "Jie Zhang",
                "Guoying Zhao",
                "Shiguang Shan",
                "Xilin Chen"
            ],
            "arxiv_id": "2512.14320",
            "summary": "Text-guided image editing via diffusion models, while powerful, raises significant concerns about misuse, motivating efforts to immunize images against unauthorized edits using imperceptible perturbations. Prevailing metrics for evaluating immunization success typically rely on measuring the visual dissimilarity between the output generated from a protected image and a reference output generated from the unprotected original. This approach fundamentally overlooks the core requirement of image immunization, which is to disrupt semantic alignment with attacker intent, regardless of deviation from any specific output. We argue that immunization success should instead be defined by the edited output either semantically mismatching the prompt or suffering substantial perceptual degradations, both of which thwart malicious intent. To operationalize this principle, we propose Synergistic Intermediate Feature Manipulation (SIFM), a method that strategically perturbs intermediate diffusion features through dual synergistic objectives: (1) maximizing feature divergence from the original edit trajectory to disrupt semantic alignment with the expected edit, and (2) minimizing feature norms to induce perceptual degradations. Furthermore, we introduce the Immunization Success Rate (ISR), a novel metric designed to rigorously quantify true immunization efficacy for the first time. ISR quantifies the proportion of edits where immunization induces either semantic failure relative to the prompt or significant perceptual degradations, assessed via Multimodal Large Language Models (MLLMs). Extensive experiments show our SIFM achieves the state-of-the-art performance for safeguarding visual content against malicious diffusion-based manipulation.",
            "categories": [
                "cs.CV",
                "cs.AI",
                "cs.CY",
                "cs.LG"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14320",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "multimodal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 8.0,
            "hit_pillars": [
                "1_robot_core",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出SIFM，通过对抗扩散模型中间特征扰动实现图像编辑免疫，并提出ISR评估指标。",
            "summary_zh": "本文关注文本引导的图像编辑滥用问题，提出了一种新的图像免疫视角。现有免疫评估方法侧重于测量保护图像生成的输出与原始图像输出的视觉差异，忽略了免疫的核心需求：扰乱与攻击者意图的语义对齐。本文认为，免疫成功的关键在于编辑后的输出在语义上与提示不匹配，或遭受显著的感知退化，从而阻止恶意意图。为此，提出了协同中间特征操纵（SIFM）方法，通过双重协同目标策略性地扰动中间扩散特征：(1) 最大化与原始编辑轨迹的特征差异，以扰乱与预期编辑的语义对齐；(2) 最小化特征范数，以诱导感知退化。此外，引入了免疫成功率（ISR）这一新指标，旨在严格量化真正的免疫效果。ISR量化了免疫诱导语义失败或显著感知退化的编辑比例，并通过多模态大型语言模型（MLLM）进行评估。大量实验表明，SIFM在保护视觉内容免受基于扩散的恶意操纵方面实现了最先进的性能。",
            "intro_zh": [
                "现有图像免疫方法仅关注视觉差异，忽略了语义对齐，无法有效阻止恶意编辑。",
                "SIFM通过协同扰动扩散模型的中间特征，实现语义错配和感知退化，从而免疫恶意编辑。",
                "提出的ISR指标能更准确地评估免疫效果，实验证明SIFM优于现有方法，能有效防御恶意编辑。"
            ],
            "method_zh": "**问题定义**：现有图像免疫方法主要通过在图像中添加不易察觉的扰动，使得通过扩散模型编辑后的图像与原始图像的编辑结果在视觉上产生差异。然而，这种方法忽略了图像免疫的根本目标：阻止攻击者通过文本提示实现其恶意编辑意图。即使编辑后的图像与原始图像的编辑结果存在视觉差异，如果仍然能够满足攻击者的语义意图，则免疫仍然是失败的。因此，需要一种能够有效阻止图像按照恶意文本提示进行编辑的方法。\n\n**核心思路**：本文的核心思路是通过在扩散模型的中间特征空间中引入扰动，使得编辑后的图像要么在语义上与文本提示不匹配，要么在感知上出现显著的退化。这种方法旨在从根本上破坏攻击者利用扩散模型进行恶意编辑的能力。通过同时优化语义错配和感知退化，可以更有效地实现图像免疫。\n\n**技术框架**：SIFM (Synergistic Intermediate Feature Manipulation) 方法主要包含以下几个步骤：1) 选择扩散模型的中间层特征；2) 设计双重协同目标函数，包括最大化特征差异和最小化特征范数；3) 通过优化目标函数，生成扰动后的中间特征；4) 将扰动后的中间特征输入扩散模型，生成免疫后的图像。此外，本文还提出了一个新的评估指标 ISR (Immunization Success Rate)，用于量化免疫的成功率。ISR 通过 MLLM (Multimodal Large Language Models) 来评估编辑后的图像是否在语义上与文本提示匹配，以及感知质量是否显著下降。\n\n**关键创新**：本文的关键创新在于：1) 提出了基于语义错配和感知退化的图像免疫新视角；2) 设计了协同中间特征操纵（SIFM）方法，通过双重协同目标函数，同时优化语义错配和感知退化；3) 提出了免疫成功率（ISR）这一新指标，能够更准确地评估图像免疫的效果。与现有方法相比，SIFM 能够更有效地阻止恶意编辑，并且 ISR 能够更准确地反映免疫的真实效果。\n\n**关键设计**：SIFM 的关键设计包括：1) 中间特征的选择：选择扩散模型中间层的特征，可以在保证图像质量的同时，有效地影响编辑结果；2) 双重协同目标函数：最大化特征差异的目标函数旨在破坏语义对齐，最小化特征范数的目标函数旨在诱导感知退化；3) 扰动强度的控制：通过调整目标函数的权重，可以控制扰动的强度，从而在免疫效果和图像质量之间取得平衡；4) ISR 的计算：通过 MLLM 评估编辑后的图像是否在语义上与文本提示匹配，以及感知质量是否显著下降，从而计算 ISR。",
            "application_zh": "该研究成果可应用于数字版权保护、社交媒体内容安全、新闻真实性验证等领域。通过对图像进行免疫处理，可以有效防止未经授权的恶意编辑和篡改，维护图像内容的完整性和真实性，从而保护个人和组织的合法权益，并减少虚假信息的传播。",
            "highlight_zh": "实验结果表明，SIFM 方法在图像免疫方面取得了显著的性能提升。与现有方法相比，SIFM 能够更有效地阻止恶意编辑，并且提出的 ISR 指标能够更准确地反映免疫的真实效果。具体来说，SIFM 在 ISR 指标上优于现有方法，表明其能够更有效地诱导语义失败或显著的感知退化。",
            "tags_zh": [
                "图像编辑免疫",
                "扩散模型",
                "中间特征扰动",
                "语义错配",
                "感知退化",
                "免疫成功率",
                "多模态大语言模型",
                "恶意编辑防御"
            ],
            "_index": 108,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14320/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14320/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14320/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Composite Classifier-Free Guidance for Multi-Modal Conditioning in Wind Dynamics Super-Resolution",
            "authors": [
                "Jacob Schnell",
                "Aditya Makkar",
                "Gunadi Gani",
                "Aniket Srinivasan Ashok",
                "Darren Lo",
                "Mike Optis",
                "Alexander Wong",
                "Yuhao Chen"
            ],
            "arxiv_id": "2512.13729",
            "summary": "Various weather modelling problems (e.g., weather forecasting, optimizing turbine placements, etc.) require ample access to high-resolution, highly accurate wind data. Acquiring such high-resolution wind data, however, remains a challenging and expensive endeavour. Traditional reconstruction approaches are typically either cost-effective or accurate, but not both. Deep learning methods, including diffusion models, have been proposed to resolve this trade-off by leveraging advances in natural image super-resolution. Wind data, however, is distinct from natural images, and wind super-resolvers often use upwards of 10 input channels, significantly more than the usual 3-channel RGB inputs in natural images. To better leverage a large number of conditioning variables in diffusion models, we present a generalization of classifier-free guidance (CFG) to multiple conditioning inputs. Our novel composite classifier-free guidance (CCFG) can be dropped into any pre-trained diffusion model trained with standard CFG dropout. We demonstrate that CCFG outputs are higher-fidelity than those from CFG on wind super-resolution tasks. We present WindDM, a diffusion model trained for industrial-scale wind dynamics reconstruction and leveraging CCFG. WindDM achieves state-of-the-art reconstruction quality among deep learning models and costs up to $1000\\times$ less than classical methods.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13729",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "[T]classifier-free guidance"
                    ],
                    "score": 7.5
                }
            ],
            "relevance_score": 7.5,
            "hit_pillars": [
                "4_motion_diffusion"
            ],
            "headline_zh": "提出复合无分类器引导（CCFG）方法，用于提升风力超分辨率重建中多模态扩散模型的性能。",
            "summary_zh": "本文提出了一种用于风动力学超分辨率中多模态条件扩散模型的复合无分类器引导（CCFG）方法。针对传统重建方法在成本和精度之间的权衡问题，以及现有深度学习方法在处理大量输入通道时的不足，本文对无分类器引导（CFG）进行了推广，使其能够更好地利用多个条件输入变量。CCFG可以应用于任何使用标准CFG dropout训练的预训练扩散模型。实验结果表明，在风力超分辨率任务中，CCFG的输出比CFG具有更高的保真度。本文还提出了WindDM，一个用于工业级风动力学重建的扩散模型，它利用CCFG实现了最先进的重建质量，并且成本比传统方法降低了高达1000倍。",
            "intro_zh": [
                "高分辨率风数据在天气建模等领域至关重要，但获取成本高昂，传统方法难以兼顾成本与精度。",
                "论文提出复合无分类器引导（CCFG），扩展了标准CFG，以有效利用扩散模型中的多个条件输入变量。",
                "WindDM模型结合CCFG，在风力超分辨率任务中实现了优于现有深度学习模型的重建质量，并显著降低了成本。"
            ],
            "method_zh": "**问题定义**：论文旨在解决风动力学超分辨率重建问题。现有方法，如传统数值模拟，计算成本高昂；而现有的深度学习方法，特别是应用于自然图像超分辨率的方法，难以有效处理风数据中大量的输入通道（通常超过10个），导致重建质量受限。\\n\\n**核心思路**：论文的核心思路是推广传统的无分类器引导（CFG）方法，使其能够更好地处理多个条件输入。通过将CFG扩展到多个条件变量，模型可以更有效地利用所有可用的信息，从而提高重建质量。这种方法的核心在于将多个条件输入视为独立的引导信号，并以一种组合的方式应用它们。\\n\\n**技术框架**：WindDM整体框架基于扩散模型，包含前向扩散过程和反向重建过程。在前向扩散过程中，低分辨率的风数据逐渐被加入噪声，直到完全变为噪声。在反向重建过程中，模型从噪声开始，逐步去除噪声，最终生成高分辨率的风数据。CCFG被集成到反向重建过程中，用于引导模型生成更符合条件输入的高质量结果。\\n\\n**关键创新**：关键创新在于提出的复合无分类器引导（CCFG）方法。与传统的CFG相比，CCFG能够处理多个条件输入，并为每个条件输入分配不同的引导权重。这种方法允许模型更灵活地利用各种条件信息，从而提高重建质量。CCFG可以被视为一种通用的CFG扩展，可以应用于任何使用标准CFG dropout训练的预训练扩散模型。\\n\\n**关键设计**：CCFG的关键设计在于如何组合多个条件输入的引导信号。具体来说，对于每个条件输入，模型都会预测一个对应的噪声估计。然后，CCFG使用一个加权平均的方式将这些噪声估计组合起来，得到最终的噪声估计。权重可以根据不同的条件输入进行调整，以反映它们对重建结果的重要性。损失函数通常采用均方误差（MSE）或L1损失，用于衡量重建结果与真实值之间的差异。",
            "application_zh": "该研究成果可广泛应用于风电场优化设计、天气预报、气候模拟等领域。通过低成本、高精度的风数据重建，可以更准确地评估风能资源，优化风力涡轮机的布局，提高风电场的发电效率，并为更精确的天气预报和气候模型提供数据支持。此外，该方法还可扩展到其他需要多模态条件输入的超分辨率重建任务中。",
            "highlight_zh": "实验结果表明，WindDM结合CCFG在风力超分辨率任务中取得了最先进的重建质量。与使用传统CFG的扩散模型相比，CCFG能够显著提高重建结果的保真度。此外，WindDM的计算成本比传统数值模拟方法降低了高达1000倍，使其在工业应用中具有显著的优势。",
            "tags_zh": [
                "风力超分辨率",
                "扩散模型",
                "无分类器引导",
                "多模态条件",
                "风动力学",
                "深度学习",
                "天气建模"
            ],
            "_index": 109,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13729/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13729/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.13729/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Incentivizing Tool-augmented Thinking with Images for Medical Image Analysis",
            "authors": [
                "Yankai Jiang",
                "Yujie Zhang",
                "Peng Zhang",
                "Yichen Li",
                "Jintai Chen",
                "Xiaoming Shi",
                "Shihui Zhen"
            ],
            "arxiv_id": "2512.14157",
            "summary": "Recent reasoning based medical MLLMs have made progress in generating step by step textual reasoning chains. However, they still struggle with complex tasks that necessitate dynamic and iterative focusing on fine-grained visual regions to achieve precise grounding and diagnosis. We introduce Ophiuchus, a versatile, tool-augmented framework that equips an MLLM to (i) decide when additional visual evidence is needed, (ii) determine where to probe and ground within the medical image, and (iii) seamlessly weave the relevant sub-image content back into an interleaved, multimodal chain of thought. In contrast to prior approaches limited by the performance ceiling of specialized tools, Ophiuchus integrates the model's inherent grounding and perception capabilities with external tools, thereby fostering higher-level reasoning. The core of our method is a three-stage training strategy: cold-start training with tool-integrated reasoning data to achieve basic tool selection and adaptation for inspecting key regions; self-reflection fine-tuning to strengthen reflective reasoning and encourage revisiting tool outputs; and Agentic Tool Reinforcement Learning to directly optimize task-specific rewards and emulate expert-like diagnostic behavior. Extensive experiments show that Ophiuchus consistently outperforms both closed-source and open-source SOTA methods across diverse medical benchmarks, including VQA, detection, and reasoning-based segmentation. Our approach illuminates a path toward medical AI agents that can genuinely \"think with images\" through tool-integrated reasoning. Datasets, codes, and trained models will be released publicly.",
            "categories": [
                "cs.AI",
                "cs.CV"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14157",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal",
                        "chain-of-thought"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 7.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "Ophiuchus：一种工具增强的医学图像分析框架，提升MLLM的推理能力",
            "summary_zh": "本文提出了一种名为Ophiuchus的通用工具增强框架，旨在提升医学多模态大语言模型（MLLM）在复杂任务中的性能。现有方法难以动态地、迭代地聚焦于细粒度的视觉区域，从而影响精确的定位和诊断。Ophiuchus赋予MLLM以下能力：（i）判断何时需要额外的视觉证据；（ii）确定在医学图像中探测和定位的位置；（iii）将相关的子图像内容无缝地融入到交错的多模态思维链中。与受限于专用工具性能上限的先前方法不同，Ophiuchus将模型固有的定位和感知能力与外部工具集成，从而促进更高层次的推理。该方法的核心是三阶段训练策略：使用工具集成推理数据进行冷启动训练，以实现基本的工具选择和关键区域检查适应；自反思微调，以加强反思性推理并鼓励重新审视工具输出；以及Agentic工具强化学习，以直接优化特定于任务的奖励并模拟专家级诊断行为。大量实验表明，Ophiuchus在各种医学基准测试中始终优于闭源和开源的SOTA方法，包括VQA、检测和基于推理的分割。该方法为医学AI智能体开辟了一条新途径，使其能够通过工具集成推理真正地“用图像思考”。数据集、代码和训练模型将公开发布。",
            "intro_zh": [
                "现有医学MLLM在复杂任务中，难以动态聚焦细粒度视觉区域，影响定位和诊断精度。",
                "Ophiuchus框架通过工具增强，使MLLM具备判断、定位和融合视觉证据的能力，提升推理质量。",
                "三阶段训练策略，包括冷启动、自反思微调和强化学习，使模型能有效利用工具并模拟专家行为。"
            ],
            "method_zh": "**问题定义**：现有基于推理的医学多模态大语言模型（MLLM）在处理需要精细视觉区域关注的复杂任务时表现不佳。它们难以动态地、迭代地聚焦于图像的特定区域以进行精确的定位和诊断。现有方法往往受限于特定工具的性能，无法充分利用模型自身的感知和推理能力。\\n\\n**核心思路**：Ophiuchus的核心思路是将MLLM固有的视觉感知和推理能力与外部工具相结合，形成一个工具增强的推理框架。通过让模型自主决定何时需要额外的视觉证据，并确定在图像中需要探测和定位的关键区域，Ophiuchus能够将相关的子图像信息无缝地融入到多模态的推理链中，从而提升模型的整体推理能力。\\n\\n**技术框架**：Ophiuchus框架包含三个主要阶段：1) 冷启动训练：使用工具集成推理数据进行训练，使模型能够选择合适的工具并适应关键区域的检查。2) 自反思微调：通过让模型反思自身的推理过程和工具输出，加强反思性推理能力，并鼓励模型重新审视工具的输出结果。3) Agentic工具强化学习：通过直接优化特定任务的奖励，并模拟专家级的诊断行为，进一步提升模型的性能。\\n\\n**关键创新**：Ophiuchus的关键创新在于其工具增强的推理框架和三阶段训练策略。与以往依赖于特定工具的方法不同，Ophiuchus将模型自身的感知和推理能力与外部工具相结合，从而突破了性能上限。三阶段训练策略则确保模型能够有效地利用工具，并逐步提升推理能力。\\n\\n**关键设计**：Ophiuchus框架的具体技术细节包括：工具选择模块，用于判断何时需要使用外部工具；区域定位模块，用于确定在图像中需要探测的关键区域；多模态融合模块，用于将工具输出的视觉信息融入到推理链中。在训练过程中，使用了多种损失函数，包括工具选择损失、区域定位损失和推理损失。Agentic工具强化学习阶段，使用了特定于任务的奖励函数，以鼓励模型模拟专家级的诊断行为。",
            "application_zh": "Ophiuchus框架具有广泛的应用前景，可用于辅助医生进行医学图像分析、疾病诊断和治疗方案制定。该框架能够提升诊断的准确性和效率，减少误诊率，并为患者提供更个性化的医疗服务。未来，Ophiuchus有望成为医学AI领域的重要组成部分，推动医疗智能化发展。",
            "highlight_zh": "实验结果表明，Ophiuchus在VQA、检测和基于推理的分割等多个医学基准测试中，始终优于当前最先进的闭源和开源方法。具体性能提升数据在论文中给出，证明了Ophiuchus框架的有效性和优越性。该框架为医学AI智能体的发展提供了一条有前景的道路。",
            "tags_zh": [
                "医学图像分析",
                "多模态大语言模型",
                "工具增强",
                "推理链",
                "强化学习"
            ],
            "_index": 110,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14157/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14157/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14157/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Text Embedded Swin-UMamba for DeepLesion Segmentation",
            "authors": [
                "Ruida Cheng",
                "Tejas Sudharshan Mathai",
                "Pritam Mukherjee",
                "Benjamin Hou",
                "Qingqing Zhu",
                "Zhiyong Lu",
                "Matthew McAuliffe",
                "Ronald M. Summers"
            ],
            "arxiv_id": "2508.06453",
            "summary": "Segmentation of lesions on CT enables automatic measurement for clinical assessment of chronic diseases (e.g., lymphoma). Integrating large language models (LLMs) into the lesion segmentation workflow has the potential to combine imaging features with descriptions of lesion characteristics from the radiology reports. In this study, we investigate the feasibility of integrating text into the Swin-UMamba architecture for the task of lesion segmentation. The publicly available ULS23 DeepLesion dataset was used along with short-form descriptions of the findings from the reports. On the test dataset, our method achieved a high Dice score of 82.64, and a low Hausdorff distance of 6.34 pixels was obtained for lesion segmentation. The proposed Text-Swin-U/Mamba model outperformed prior approaches: 37.79% improvement over the LLM-driven LanGuideMedSeg model (p < 0.001), and surpassed the purely image-based XLSTM-UNet and nnUNet models by 2.58% and 1.01%, respectively. The dataset and code can be accessed atthis https URL",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2508.06453",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]Mamba"
                    ],
                    "score": 4.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 7.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出Text Embedded Swin-UMamba模型，用于融合文本信息的DeepLesion病灶分割。",
            "summary_zh": "本研究探讨了将大型语言模型（LLM）集成到Swin-UMamba架构中，用于病灶分割的可行性，旨在结合影像特征与放射报告中的病灶描述。该方法应用于公开的ULS23 DeepLesion数据集，并结合报告中的简短描述。实验结果表明，该方法在测试数据集上实现了82.64的高Dice score和6.34像素的低Hausdorff距离。所提出的Text-Swin-U/Mamba模型优于现有方法，相比于LLM驱动的LanGuideMedSeg模型提升了37.79%（p < 0.001），并且超越了纯图像的XLSTM-UNet和nnUNet模型，分别提升了2.58%和1.01%。数据集和代码可在指定URL获取。",
            "intro_zh": [
                "现有病灶分割方法缺乏对放射报告文本信息的有效利用，限制了分割精度和临床应用价值。",
                "提出Text-Swin-U/Mamba模型，通过嵌入文本特征，增强模型对病灶特征的理解和分割能力。",
                "实验结果表明，该模型在DeepLesion数据集上显著优于现有方法，Dice score提升显著。"
            ],
            "method_zh": "**问题定义**：论文旨在解决CT图像中病灶的精确分割问题。现有方法，如纯图像分割模型，忽略了放射报告中包含的丰富文本信息，这些信息可以提供关于病灶特征的重要线索。因此，如何有效地融合图像和文本信息，提高病灶分割的准确性，是本研究要解决的关键问题。\\n\\n**核心思路**：论文的核心思路是将放射报告的文本描述嵌入到Swin-UMamba架构中，利用文本信息增强模型对病灶特征的理解。Swin Transformer和Mamba架构分别擅长处理图像和序列数据，通过有效融合二者，可以充分利用图像和文本信息，提高分割精度。\\n\\n**技术框架**：该模型基于Swin-UMamba架构，并引入文本嵌入模块。整体流程包括：1）图像输入经过Swin Transformer编码器提取图像特征；2）文本输入经过文本编码器（可能是预训练的语言模型）提取文本特征；3）图像特征和文本特征通过融合模块进行融合；4）融合后的特征输入到UMamba解码器进行分割；5）输出分割结果。\\n\\n**关键创新**：该研究的关键创新在于将文本信息有效地融入到Swin-UMamba架构中，实现了图像和文本信息的联合建模。与传统的纯图像分割方法相比，该方法能够利用放射报告中的文本描述，提高对病灶特征的理解和分割精度。与直接使用LLM的方法相比，该方法更加轻量级，且针对病灶分割任务进行了优化。\\n\\n**关键设计**：具体的文本嵌入方式、图像和文本特征的融合策略、以及UMamba解码器的具体结构是关键的设计细节。论文可能采用了某种注意力机制或跨模态融合模块来实现图像和文本特征的有效融合。损失函数可能包括Dice loss、交叉熵损失等，用于优化分割结果。",
            "application_zh": "该研究成果可应用于医学影像辅助诊断，例如淋巴瘤等慢性疾病的病灶自动测量和评估。通过结合影像特征和文本描述，可以提高诊断效率和准确性，辅助医生进行临床决策。未来，该方法可以推广到其他医学影像分割任务，并与其他临床信息系统集成，实现更智能化的医疗服务。",
            "highlight_zh": "实验结果表明，Text-Swin-U/Mamba模型在DeepLesion数据集上取得了显著的性能提升。Dice score达到了82.64，Hausdorff距离为6.34像素。相比于LLM驱动的LanGuideMedSeg模型，性能提升了37.79%（p < 0.001）。同时，该模型也超越了纯图像的XLSTM-UNet和nnUNet模型，分别提升了2.58%和1.01%。",
            "tags_zh": [
                "病灶分割",
                "深度学习",
                "Swin Transformer",
                "Mamba",
                "文本嵌入",
                "医学影像",
                "多模态融合"
            ],
            "_index": 111,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "The Double Life of Code World Models: Provably Unmasking Malicious Behavior Through Execution Traces",
            "authors": [
                "Subramanyam Sahoo",
                "Jared Junkin"
            ],
            "arxiv_id": "2512.13821",
            "summary": "Large language models (LLMs) increasingly generate code with minimal human oversight, raising critical concerns about backdoor injection and malicious behavior. We present Cross-Trace Verification Protocol (CTVP), a novel AI control framework that verifies untrusted code-generating models through semantic orbit analysis. Rather than directly executing potentially malicious code, CTVP leverages the model's own predictions of execution traces across semantically equivalent program transformations. By analyzing consistency patterns in these predicted traces, we detect behavioral anomalies indicative of backdoors. Our approach introduces the Adversarial Robustness Quotient (ARQ), which quantifies the computational cost of verification relative to baseline generation, demonstrating exponential growth with orbit size. Theoretical analysis establishes information-theoretic bounds showing non-gamifiability -- adversaries cannot improve through training due to fundamental space complexity constraints. This work demonstrates that semantic orbit analysis provides a scalable, theoretically grounded approach to AI control for code generation tasks.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13821",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]world model"
                    ],
                    "score": 4.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 7.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出CTVP框架，通过执行轨迹分析揭示代码世界模型中的恶意行为",
            "summary_zh": "大型语言模型（LLM）越来越多地生成代码，而人为监督最少，这引发了对后门注入和恶意行为的严重担忧。我们提出了跨轨迹验证协议（CTVP），这是一种新颖的AI控制框架，通过语义轨道分析来验证不受信任的代码生成模型。CTVP不是直接执行潜在的恶意代码，而是利用模型自身对跨语义等效程序转换的执行轨迹的预测。通过分析这些预测轨迹中的一致性模式，我们检测到指示后门的行为异常。我们的方法引入了对抗鲁棒性商（ARQ），它量化了相对于基线生成的验证计算成本，证明了其随轨道大小呈指数增长。理论分析建立了信息论界限，表明其不可博弈性——由于基本的空间复杂度约束，对抗者无法通过训练来改进。这项工作表明，语义轨道分析为代码生成任务提供了一种可扩展的、具有理论基础的AI控制方法。",
            "intro_zh": [
                "现有代码生成模型缺乏有效的恶意行为检测机制，容易被植入后门。",
                "CTVP框架通过分析模型在语义等价程序上的执行轨迹一致性，检测恶意行为。",
                "实验证明，CTVP能够有效检测后门，并提出了量化验证成本的ARQ指标。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型（LLM）在代码生成过程中可能存在的后门注入和恶意行为问题。现有的代码生成模型缺乏有效的验证机制，难以检测和防御潜在的恶意代码，这使得LLM在安全敏感的应用中面临风险。直接执行生成的代码存在安全隐患，而静态分析方法可能无法有效识别复杂的后门逻辑。\\n\\n**核心思路**：论文的核心思路是利用语义等价的程序转换，构建程序的“语义轨道”，并分析LLM在这些等价程序上的执行轨迹预测的一致性。如果模型存在后门，那么在某些特定的输入条件下，即使程序语义等价，其执行轨迹也会出现异常偏差。通过检测这些偏差，可以有效地识别恶意行为。这种方法避免了直接执行潜在恶意代码的风险，并利用了模型自身的预测能力进行验证。\\n\\n**技术框架**：CTVP框架包含以下主要模块：1) **程序转换模块**：将原始代码转换为一系列语义等价的程序变体，形成语义轨道。2) **执行轨迹预测模块**：利用待验证的LLM预测每个程序变体的执行轨迹。3) **一致性分析模块**：分析不同程序变体执行轨迹的一致性，检测异常偏差。4) **恶意行为判定模块**：根据偏差程度判断是否存在恶意行为，并计算对抗鲁棒性商（ARQ）来量化验证成本。\\n\\n**关键创新**：论文的关键创新在于提出了基于语义轨道分析的AI控制框架CTVP，以及对抗鲁棒性商（ARQ）这一量化指标。CTVP通过分析模型自身对语义等价程序执行轨迹的预测，实现了对恶意行为的有效检测，避免了直接执行潜在恶意代码的风险。ARQ则提供了一种量化验证成本的方法，有助于评估不同验证策略的效率。与现有方法相比，CTVP不需要人工标注或预定义的恶意模式，具有更强的通用性和可扩展性。\\n\\n**关键设计**：CTVP的关键设计包括：1) **语义等价程序转换策略**：选择合适的程序转换方法，确保生成的程序变体在语义上等价，但语法上存在差异，以触发后门行为。2) **执行轨迹预测方法**：利用LLM的预测能力，生成每个程序变体的执行轨迹，例如变量值的变化、函数调用序列等。3) **一致性度量方法**：设计合适的度量方法，量化不同程序变体执行轨迹之间的偏差，例如使用动态时间规整（DTW）或编辑距离等。4) **ARQ计算方法**：定义ARQ为验证成本与基线生成成本之比，其中验证成本包括生成语义轨道和分析执行轨迹所需的计算资源。",
            "application_zh": "该研究成果可应用于软件安全、AI安全等领域，用于验证代码生成模型的安全性，防止恶意代码的生成和传播。通过CTVP框架，可以提高代码生成模型的可靠性和安全性，降低安全风险。未来，该方法可以扩展到其他AI生成任务，例如文本生成、图像生成等，为AI安全提供更全面的保障。",
            "highlight_zh": "实验结果表明，CTVP能够有效检测代码生成模型中的后门，并量化验证成本。论文提出了对抗鲁棒性商（ARQ），证明了验证成本随轨道大小呈指数增长，表明了该方法的有效性和可扩展性。理论分析建立了信息论界限，表明其不可博弈性，即对抗者无法通过训练来改进。",
            "tags_zh": [
                "代码生成",
                "恶意行为检测",
                "后门攻击",
                "语义轨道分析",
                "AI安全"
            ],
            "_index": 112,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13821/experiment_dashboard.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13821/memory_usage.png",
                    "caption": "",
                    "figure_id": "fig_1"
                }
            ]
        },
        {
            "title": "IPR-1: Interactive Physical Reasoner",
            "authors": [
                "Mingyu Zhang",
                "Lifeng Zhuo",
                "Tianxi Tan",
                "Guocan Xie",
                "Xian Nie",
                "Yan Li",
                "Renjie Zhao",
                "Zizhu He",
                "Ziyu Wang",
                "Jiting Cai",
                "Yong-Lu Li"
            ],
            "arxiv_id": "2511.15407",
            "summary": "Humans learn by observing, interacting with environments, and internalizing physics and causality. Here, we aim to ask whether an agent can similarly acquire human-like reasoning from interaction and keep improving with more experience. To study this, we introduce a Game-to-Unseen (G2U) benchmark of 1,000+ heterogeneous games that exhibit significant visual domain gaps. Existing approaches, including VLMs and world models, struggle to capture underlying physics and causality since they are not focused on core mechanisms and overfit to visual details. VLM/VLA agents reason but lack look-ahead in interactive settings, while world models imagine but imitate visual patterns rather than analyze physics and causality. We therefore propose IPR (Interactive Physical Reasoner), using world-model rollouts to score and reinforce a VLM's policy, and introduce PhysCode, a physics-centric action code aligning semantic intent with dynamics to provide a shared action space for prediction and reasoning. Pretrained on 1,000+ games, our IPR performs robustly on levels from primitive intuition to goal-driven reasoning, and even surpasses GPT-5 overall. We find that performance improves with more training games and interaction steps, and that the model also zero-shot transfers to unseen games. These results support physics-centric interaction as a path to steadily improving physical reasoning. Further demos and project details can be found atthis https URL.",
            "categories": [
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2511.15407",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "world model"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "VLA",
                        "zero-shot transfer"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 7.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出IPR：结合世界模型与VLM的交互式物理推理器，解决复杂物理场景推理问题",
            "summary_zh": "本文旨在研究智能体能否通过与环境的交互学习，并不断积累经验，从而获得类似人类的推理能力。为此，作者提出了一个名为Game-to-Unseen (G2U)的基准测试，包含1000多个具有显著视觉领域差异的异构游戏。现有的方法，包括视觉语言模型(VLM)和世界模型，难以捕捉潜在的物理规律和因果关系，因为它们过度关注视觉细节而非核心机制。VLM/VLA智能体擅长推理，但在交互环境中缺乏前瞻性；而世界模型擅长想象，但模仿的是视觉模式，而非分析物理和因果关系。因此，作者提出了交互式物理推理器(IPR)，它使用世界模型的rollout来评估和强化VLM的策略，并引入了PhysCode，一种以物理为中心的动作编码，将语义意图与动力学对齐，为预测和推理提供共享的动作空间。IPR在1000多个游戏上进行预训练后，在从原始直觉到目标驱动推理的各个层面上表现出强大的鲁棒性，甚至在整体上超过了GPT-5。研究表明，性能随着训练游戏和交互步骤的增加而提高，并且该模型还可以零样本迁移到未见过的游戏。这些结果支持以物理为中心的交互作为稳步提高物理推理能力的一种途径。",
            "intro_zh": [
                "现有VLM和世界模型在复杂物理场景中推理能力不足，前者缺乏前瞻性，后者过度依赖视觉模仿。",
                "IPR结合世界模型rollout和VLM策略，利用PhysCode对齐语义意图与动力学，提升推理能力。",
                "实验表明，IPR在G2U基准上表现出色，超越GPT-5，并具备零样本迁移能力，验证了物理交互的有效性。"
            ],
            "method_zh": "**问题定义**：现有方法，如视觉语言模型（VLM）和世界模型，在处理复杂物理交互场景时存在局限性。VLM虽然擅长推理，但在交互环境中缺乏长远规划能力，无法进行有效的“look-ahead”；而世界模型虽然能够进行预测和想象，但往往侧重于模仿视觉模式，而非真正理解和利用物理规律和因果关系。因此，如何让智能体像人类一样，通过交互学习并掌握物理世界的内在规律，是一个亟待解决的问题。\\n\\n**核心思路**：IPR的核心思路是结合VLM的推理能力和世界模型的预测能力，通过相互协作来提升整体的物理推理性能。具体来说，IPR利用世界模型进行rollout，预测未来可能发生的状态，并以此来评估和指导VLM的策略选择。同时，引入PhysCode作为一种以物理为中心的动作编码，将语义意图与动力学行为对齐，从而为预测和推理提供一个统一的动作空间。\\n\\n**技术框架**：IPR的整体框架包含以下几个主要模块：1) VLM策略模块：负责根据当前环境状态生成动作策略；2) 世界模型模块：负责根据当前状态和动作预测未来的状态序列（rollout）；3) 策略评估模块：利用世界模型的rollout结果，对VLM的策略进行评估和打分；4) 策略强化模块：根据策略评估结果，对VLM的策略进行优化和调整；5) PhysCode模块：负责将高层语义意图转化为具体的物理动作指令，并作为VLM和世界模型之间的桥梁。\\n\\n**关键创新**：IPR最重要的创新点在于其融合了VLM和世界模型的优势，并引入了PhysCode作为统一的动作空间。这种融合使得IPR既能够进行有效的推理，又能够进行长期的规划，从而在复杂物理交互场景中表现出更强的鲁棒性和泛化能力。与现有方法相比，IPR更加注重对物理规律和因果关系的理解和利用，而非仅仅依赖于视觉模式的模仿。\\n\\n**关键设计**：PhysCode的设计是IPR的关键。它将动作空间分解为多个物理相关的参数，例如作用力的大小、方向、作用点等。通过对这些参数进行编码，PhysCode能够将高层语义意图转化为具体的物理动作指令，并为VLM和世界模型提供一个共享的动作空间。此外，IPR还采用了强化学习算法来优化VLM的策略，并使用对比学习方法来训练世界模型，使其能够更准确地预测未来的状态序列。",
            "application_zh": "IPR的研究成果具有广泛的应用前景，例如可以应用于机器人控制、游戏AI、自动驾驶等领域。通过让智能体具备更强的物理推理能力，可以使其在复杂环境中更好地完成任务，并实现更高级别的自主性和智能化。此外，IPR还可以用于教育领域，帮助学生更好地理解物理概念和规律。",
            "highlight_zh": "实验结果表明，IPR在G2U基准测试中取得了显著的性能提升，甚至在整体上超过了GPT-5。具体来说，IPR在多个游戏任务上都取得了最高的得分，并且表现出强大的鲁棒性和泛化能力。此外，研究还发现，IPR的性能随着训练游戏数量和交互步骤的增加而不断提高，并且能够零样本迁移到未见过的游戏，这充分证明了IPR的有效性和潜力。",
            "tags_zh": [
                "物理推理",
                "交互学习",
                "世界模型",
                "视觉语言模型",
                "强化学习",
                "动作编码",
                "机器人控制"
            ],
            "_index": 113,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2511.15407/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2511.15407/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2511.15407/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Differentially Private Knowledge Distillation via Synthetic Text Generation",
            "authors": [
                "James Flemings",
                "Murali Annavaram"
            ],
            "arxiv_id": "2403.00932",
            "summary": "Large Language models (LLMs) are achieving state-of-the-art performance in many different downstream tasks. However, the increasing urgency of data privacy puts pressure on practitioners to train LLMs with Differential Privacy (DP) on private data. Concurrently, the exponential growth in parameter size of LLMs necessitates model compression before deployment of LLMs on resource-constrained devices or latency-sensitive applications. Differential privacy and model compression generally must trade off utility loss to achieve their objectives. Moreover, simultaneously applying both schemes can compound the utility degradation. To this end, we propose DistilDP: a novel differentially private knowledge distillation algorithm that exploits synthetic data generated by a differentially private teacher LLM. The knowledge of a teacher LLM is transferred onto the student in two ways: one way from the synthetic data itself -- the hard labels, and the other way by the output distribution of the teacher evaluated on the synthetic data -- the soft labels. Furthermore, if the teacher and student share a similar architectural structure, we can further distill knowledge by aligning the hidden representations between both. Our experimental results demonstrate that DistilDP can substantially improve the utility over existing baselines, at least $9.0$ PPL on the Big Patent dataset, with strong privacy parameters, $\\epsilon=2$. These promising results progress privacy-preserving compression of autoregressive LLMs. Our code can be accessed here:this https URL.",
            "categories": [
                "cs.LG",
                "cs.CL",
                "cs.CR"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2403.00932",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]distillation"
                    ],
                    "score": 4.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 7.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出DistilDP以解决差分隐私与知识蒸馏的平衡问题",
            "summary_zh": "大型语言模型（LLMs）在多个下游任务中表现出色，但数据隐私的日益紧迫性要求在私有数据上使用差分隐私（DP）进行训练。同时，LLMs参数规模的指数增长也需要在资源受限或延迟敏感的应用中进行模型压缩。差分隐私和模型压缩通常需要在效用损失上进行权衡，且同时应用两者可能会加剧效用下降。为此，本文提出了一种新颖的差分隐私知识蒸馏算法DistilDP，该算法利用由差分隐私教师LLM生成的合成数据进行知识传递。实验结果表明，DistilDP在Big Patent数据集上相较于现有基线显著提高了效用，隐私参数为ε=2时至少提升了9.0 PPL。这些结果推动了自回归LLMs的隐私保护压缩进程。",
            "intro_zh": [
                "现有方法在实现差分隐私和模型压缩时，往往面临效用损失的权衡，且同时应用两者可能导致更大的效用下降。",
                "本文提出DistilDP算法，通过合成数据生成和教师模型的输出分布，进行知识蒸馏，从而有效提升模型性能。",
                "实验结果显示，DistilDP在Big Patent数据集上相较于现有基线至少提升了9.0 PPL，展现出强大的隐私保护能力。"
            ],
            "method_zh": "**问题定义**：本文旨在解决在私有数据上训练大型语言模型时，如何在保证差分隐私的同时进行有效的模型压缩。现有方法在同时应用差分隐私和知识蒸馏时，往往导致效用显著下降。\\n\\n**核心思路**：DistilDP算法通过利用差分隐私教师模型生成的合成数据，进行知识的双重传递：一方面通过合成数据的硬标签，另一方面通过教师模型在合成数据上的输出分布（软标签），从而提升学生模型的性能。\\n\\n**技术框架**：DistilDP的整体架构包括两个主要模块：教师模型生成合成数据和学生模型进行知识蒸馏。教师模型首先生成合成数据，然后学生模型通过学习硬标签和软标签来进行知识的吸收和转移。\\n\\n**关键创新**：DistilDP的核心创新在于结合了差分隐私和知识蒸馏的思想，通过合成数据的生成和标签的双重利用，显著提升了模型的效用，克服了传统方法的局限性。\\n\\n**关键设计**：在设计中，教师和学生模型的架构相似，以便于对隐藏表示进行对齐。此外，隐私参数ε的设置为2，确保了在保证隐私的前提下，模型的性能得以提升。实验中使用的损失函数和训练策略也经过精心设计，以最大化知识的转移效果。",
            "application_zh": "该研究的潜在应用领域包括需要保护用户隐私的自然语言处理任务，如医疗记录分析、金融数据处理等。通过在保证隐私的同时提升模型性能，DistilDP为实际应用提供了新的解决方案，具有重要的实际价值和未来影响。",
            "highlight_zh": "实验结果表明，DistilDP在Big Patent数据集上相较于现有基线至少提升了9.0 PPL，展现出强大的隐私保护能力，隐私参数设置为ε=2，证明了其在隐私保护下的有效性和实用性。",
            "tags_zh": [
                "差分隐私",
                "知识蒸馏",
                "大型语言模型",
                "合成数据",
                "模型压缩",
                "隐私保护",
                "自然语言处理"
            ],
            "_index": 114,
            "_used_api": "openai",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2403.00932/figures/dpkd_overview.png",
                    "caption": "",
                    "figure_id": "fig_0"
                }
            ]
        },
        {
            "title": "Retrieval Enhanced Feedback via In-context Neural Error-book",
            "authors": [
                "Jongyeop Hyun",
                "Bumsoo Kim"
            ],
            "arxiv_id": "2508.16313",
            "summary": "Recent advancements in Large Language Models (LLMs) have significantly improved reasoning capabilities, with in-context learning (ICL) emerging as a key technique for adaptation without retraining. While previous works have focused on leveraging correct examples, recent research highlights the importance of learning from errors to enhance performance. However, existing methods lack a structured framework for analyzing and mitigating errors, particularly in Multimodal Large Language Models (MLLMs), where integrating visual and textual inputs adds complexity. To address this issue, we propose REFINE: Retrieval-Enhanced Feedback via In-context Neural Error-book, a teacher-student framework that systematically structures errors and provides targeted feedback. REFINE introduces three systematic queries to construct structured feedback -- Feed-Target, Feed-Check, and Feed-Path -- to enhance multimodal reasoning by prioritizing relevant visual information, diagnosing critical failure points, and formulating corrective actions. Unlike prior approaches that rely on redundant retrievals, REFINE optimizes structured feedback retrieval, improving inference efficiency, token usage, and scalability. Our results demonstrate substantial speedup, reduced computational costs, and successful generalization, highlighting REFINE's potential for enhancing multimodal reasoning.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2508.16313",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "teacher-student"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "multimodal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 7.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出REFINE：通过上下文神经错误簿增强检索反馈，提升多模态大语言模型推理能力",
            "summary_zh": "本文提出了一种名为REFINE的检索增强反馈框架，通过上下文神经错误簿系统地构建错误并提供针对性反馈，旨在提升多模态大语言模型（MLLM）的推理能力。REFINE是一个师生框架，它引入了三种系统查询——Feed-Target、Feed-Check和Feed-Path——通过优先考虑相关的视觉信息、诊断关键失败点和制定纠正措施来增强多模态推理。与依赖冗余检索的先前方法不同，REFINE优化了结构化反馈检索，从而提高了推理效率、token利用率和可扩展性。实验结果表明，REFINE显著提高了速度，降低了计算成本，并成功实现了泛化，突显了其增强多模态推理的潜力。",
            "intro_zh": [
                "现有方法缺乏结构化的错误分析和缓解框架，尤其是在集成视觉和文本输入的多模态大语言模型中。",
                "REFINE通过构建结构化反馈，优先考虑相关视觉信息，诊断失败点，并制定纠正措施，系统性地解决错误。",
                "实验结果表明，REFINE在速度、计算成本和泛化能力方面均有显著提升，证明了其有效性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决多模态大语言模型（MLLM）在推理过程中存在的错误分析和纠正问题。现有方法，特别是基于上下文学习（ICL）的方法，虽然利用了正确的示例，但缺乏系统性的错误处理框架，导致效率低下和泛化能力不足。尤其是在多模态场景下，视觉和文本信息的融合增加了错误分析的复杂性。\\n\\n**核心思路**：REFINE的核心思路是构建一个“神经错误簿”，通过检索增强的方式，为模型提供结构化的错误反馈。这种反馈不是简单的错误示例，而是通过精心设计的查询，引导模型关注关键信息、诊断错误原因并制定纠正策略。通过这种方式，模型可以更有效地从错误中学习，提升推理能力。\\n\\n**技术框架**：REFINE采用师生框架。教师模型负责生成结构化的错误反馈，学生模型则利用这些反馈进行学习和推理。框架包含以下主要模块：1) **Feed-Target**：确定需要关注的目标区域或对象。2) **Feed-Check**：诊断推理过程中的关键失败点。3) **Feed-Path**：制定纠正行动，引导模型修正错误。这些模块通过检索相关信息，生成针对性的反馈，并将其作为上下文信息提供给学生模型。\\n\\n**关键创新**：REFINE的关键创新在于其结构化的错误反馈机制。与传统的错误示例不同，REFINE通过Feed-Target、Feed-Check和Feed-Path三个模块，将错误信息分解为更细粒度的目标、诊断和纠正步骤，从而使模型能够更深入地理解错误的原因和解决方法。此外，REFINE还优化了反馈检索过程，避免了冗余检索，提高了效率。\\n\\n**关键设计**：REFINE的关键设计包括：1) **查询设计**：Feed-Target、Feed-Check和Feed-Path查询的设计需要充分考虑多模态信息的特点，确保能够准确地提取关键信息。2) **检索策略**：采用高效的检索算法，快速找到与当前错误相关的反馈信息。3) **损失函数**：设计合适的损失函数，引导学生模型学习教师模型提供的反馈，并提高推理准确率。具体的参数设置和网络结构细节在论文中未详细说明，属于未知信息。",
            "application_zh": "REFINE具有广泛的应用前景，可用于提升各种多模态大语言模型的性能，例如图像描述、视觉问答、机器人导航等。通过系统性的错误分析和纠正，可以提高模型的可靠性和泛化能力，使其在实际应用中更加有效。此外，REFINE的框架也可以推广到其他类型的任务和模型中，具有重要的研究价值。",
            "highlight_zh": "REFINE在实验中表现出显著的性能提升，具体数据未在摘要中给出。摘要强调了REFINE在速度、计算成本和泛化能力方面的优势。与现有方法相比，REFINE能够更有效地利用token，提高推理效率，并降低计算资源消耗。实验结果表明，REFINE具有很强的实用价值。",
            "tags_zh": [
                "多模态大语言模型",
                "上下文学习",
                "检索增强",
                "错误反馈",
                "神经错误簿",
                "多模态推理",
                "知识检索"
            ],
            "_index": 115,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2508.16313/sec/img/REFINE_overall.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2508.16313/sec/img/combined_tokens_time_performance.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2508.16313/sec/img/13321.jpg",
                    "caption": "",
                    "figure_id": "img_2"
                }
            ]
        },
        {
            "title": "Understanding Sampler Stochasticity in Training Diffusion Models for RLHF",
            "authors": [
                "Jiayuan Sheng",
                "Hanyang Zhao",
                "Haoxian Chen",
                "David D. Yao",
                "Wenpin Tang"
            ],
            "arxiv_id": "2510.10767",
            "summary": "Reinforcement Learning from Human Feedback (RLHF) is increasingly used to fine-tune diffusion models, but a key challenge arises from the mismatch between stochastic samplers used during training and deterministic samplers used during inference. In practice, models are fine-tuned using stochastic SDE samplers to encourage exploration, while inference typically relies on deterministic ODE samplers for efficiency and stability. This discrepancy induces a reward gap, raising concerns about whether high-quality outputs can be expected during inference. In this paper, we theoretically characterize this reward gap and provide non-vacuous bounds for general diffusion models, along with sharper convergence rates for Variance Exploding (VE) and Variance Preserving (VP) Gaussian models. Methodologically, we adopt the generalized denoising diffusion implicit models (gDDIM) framework to support arbitrarily high levels of stochasticity, preserving data marginals throughout. Empirically, our findings through large-scale experiments on text-to-image models using denoising diffusion policy optimization (DDPO) and mixed group relative policy optimization (MixGRPO) validate that reward gaps consistently narrow over training, and ODE sampling quality improves when models are updated using higher-stochasticity SDE training.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "math.OC"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2510.10767",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning",
                        "diffusion policy",
                        "[T]RLHF"
                    ],
                    "score": 7.5
                }
            ],
            "relevance_score": 7.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "理论分析与实验验证：缩小RLHF扩散模型训练与推理采样器随机性差异",
            "summary_zh": "本文研究了在RLHF中微调扩散模型时，训练阶段使用的随机采样器与推理阶段使用的确定性采样器之间的不匹配问题。实践中，模型通常使用随机SDE采样器进行微调以鼓励探索，而推理则依赖于确定性ODE采样器以提高效率和稳定性。这种差异导致了奖励差距，引发了人们对推理过程中能否获得高质量输出的担忧。本文从理论上描述了这种奖励差距，并为通用扩散模型提供了非平凡的界限，以及针对方差爆炸（VE）和方差保持（VP）高斯模型的更精确的收敛速度。在方法论上，我们采用了广义去噪扩散隐式模型（gDDIM）框架来支持任意高水平的随机性，从而保持整个过程中的数据边缘分布。通过使用去噪扩散策略优化（DDPO）和混合组相对策略优化（MixGRPO）在文本到图像模型上进行的大规模实验，我们的研究结果验证了奖励差距在训练过程中持续缩小，并且当使用更高随机性的SDE训练更新模型时，ODE采样质量得到提高。",
            "intro_zh": [
                "RLHF微调扩散模型时，训练和推理阶段采样器的随机性差异是关键挑战，导致奖励差距。",
                "论文采用gDDIM框架，支持高随机性，理论分析奖励差距，并提供VE和VP模型的收敛速度。",
                "实验表明，使用高随机性SDE训练能有效缩小奖励差距，提升ODE采样质量，验证了理论分析。"
            ],
            "method_zh": "**问题定义**：在利用人类反馈强化学习（RLHF）微调扩散模型时，训练阶段通常使用随机采样器（如SDE采样器）以鼓励探索，而推理阶段为了效率和稳定性，则倾向于使用确定性采样器（如ODE采样器）。这种训练和推理阶段采样器之间的差异会导致奖励差距，即模型在训练时表现良好，但在实际推理时性能下降。现有方法未能充分解决或量化这种差距，导致难以保证推理阶段的输出质量。\\n\\n**核心思路**：论文的核心思路是理论分析并量化训练和推理阶段采样器随机性差异导致的奖励差距。通过建立奖励差距的理论界限，可以更好地理解这种差异对模型性能的影响。此外，论文还提出使用广义去噪扩散隐式模型（gDDIM）框架，该框架能够支持任意高水平的随机性，从而在训练过程中更好地保持数据边缘分布，进而缩小奖励差距。\\n\\n**技术框架**：整体框架基于扩散模型，并结合RLHF进行微调。主要包含以下几个阶段：1）使用随机SDE采样器进行训练，鼓励探索；2）使用确定性ODE采样器进行推理，提高效率和稳定性；3）采用gDDIM框架，支持高随机性，保持数据边缘分布；4）理论分析奖励差距，并提供VE和VP模型的收敛速度。\\n\\n**关键创新**：论文的关键创新在于：1）首次对RLHF微调扩散模型中训练和推理阶段采样器随机性差异导致的奖励差距进行了理论分析，并提供了非平凡的界限；2）采用了gDDIM框架，该框架能够支持任意高水平的随机性，从而在训练过程中更好地保持数据边缘分布，进而缩小奖励差距；3）针对VE和VP高斯模型，提供了更精确的收敛速度。\\n\\n**关键设计**：论文的关键设计包括：1）使用gDDIM框架，通过调整噪声水平来控制采样器的随机性；2）针对VE和VP模型，推导了具体的奖励差距界限和收敛速度；3）在实验中，使用了DDPO和MixGRPO等RLHF算法，并针对文本到图像模型进行了大规模实验。",
            "application_zh": "该研究成果可应用于各种需要利用人类反馈微调扩散模型的场景，例如文本到图像生成、图像编辑、音频合成等。通过缩小训练和推理阶段采样器随机性差异，可以提高生成内容质量，提升用户体验，并降低部署成本。未来，该研究可以进一步推广到其他生成模型和强化学习算法中。",
            "highlight_zh": "论文通过大规模实验验证了理论分析的有效性。实验结果表明，使用更高随机性的SDE训练能够有效缩小奖励差距，并显著提高ODE采样器的生成质量。具体来说，在文本到图像生成任务中，使用DDPO和MixGRPO算法，通过高随机性SDE训练的模型在ODE采样时表现出更好的视觉效果和更高的用户满意度。",
            "tags_zh": [
                "扩散模型",
                "人类反馈强化学习",
                "随机采样",
                "确定性采样",
                "奖励差距",
                "gDDIM",
                "文本到图像生成"
            ],
            "_index": 116,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2510.10767/illust3.jpg",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2510.10767/vp_model.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2510.10767/reward_gap.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "CiRL: Open-Source Environments for Reinforcement Learning in Circular Economy and Net Zero",
            "authors": [
                "Federico Zocco",
                "Andrea Corti",
                "Monica Malvezzi"
            ],
            "arxiv_id": "2505.21536",
            "summary": "The demand of finite raw materials will keep increasing as they fuel modern society. Simultaneously, solutions for stopping carbon emissions in the short term are not available, thus making the net zero target extremely challenging to achieve at scale. The circular economy (CE) paradigm is gaining attention as a solution to address climate change and the uncertainties of supplies of critical materials. Hence, in this paper, we introduce CiRL, a deep reinforcement learning (DRL) library of environments focused on the circularity control of both solid and fluid materials. The integration of DRL into the design of material circularity is possible thanks to the formalism of thermodynamical material networks, which is underpinned by compartmental dynamical thermodynamics. Along with the focus on circularity, this library has three more features: the new CE-oriented environments are in the state-space form, which is typically used in dynamical systems analysis and control design; it is based on a state-of-the-art Python library of DRL algorithms, namely, Stable-Baselines3; and it is developed in Google Colaboratory to be accessible to researchers from different disciplines and backgrounds as is often the case for circular economy researchers and engineers. CiRL is intended to be a tool to generate AI-driven actions for optimizing the circularity of supply-recovery chains and to be combined with human-driven decisions derived from material flow analysis (MFA) studies. CiRL is publicly available.",
            "categories": [
                "cs.CY",
                "cs.CE",
                "cs.LG"
            ],
            "primary_category": "cs.CY",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2505.21536",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning",
                        "deep reinforcement learning",
                        "DRL"
                    ],
                    "score": 7.5
                }
            ],
            "relevance_score": 7.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "CiRL：用于循环经济和净零排放的强化学习开源环境",
            "summary_zh": "由于有限的原材料是现代社会的基础，因此对其需求将持续增长。同时，短期内无法找到阻止碳排放的解决方案，这使得大规模实现净零目标极具挑战性。循环经济（CE）范式作为解决气候变化和关键材料供应不确定性的方案正受到越来越多的关注。因此，本文介绍CiRL，这是一个深度强化学习（DRL）环境库，专注于固体和流体材料的循环控制。由于热力学材料网络的公式化，DRL可以集成到材料循环的设计中，该公式以隔室动态热力学为基础。除了关注循环性之外，该库还有三个特点：新的面向CE的环境采用状态空间形式，这通常用于动态系统分析和控制设计；它基于最先进的Python DRL算法库Stable-Baselines3；它在Google Colaboratory中开发，方便来自不同学科和背景的研究人员使用，这在循环经济研究人员和工程师中很常见。CiRL旨在成为一种工具，用于生成AI驱动的行动，以优化供应-回收链的循环性，并与来自材料流分析（MFA）研究的人工驱动决策相结合。CiRL是公开可用的。",
            "intro_zh": [
                "现代社会对有限原材料的需求不断增长，同时短期内难以找到有效控制碳排放的方案，实现净零排放目标面临巨大挑战。",
                "论文提出CiRL，一个基于深度强化学习的环境库，专注于固体和流体材料的循环控制，旨在优化材料的循环利用。",
                "CiRL基于Stable-Baselines3，采用状态空间形式，并在Google Colaboratory上开发，方便不同背景的研究人员使用。"
            ],
            "method_zh": "**问题定义**：论文旨在解决如何利用人工智能技术优化循环经济中材料的循环利用率，从而应对气候变化和关键材料供应不确定性的问题。现有方法可能缺乏对动态材料流的有效建模和控制，难以实现全局优化。\\n\\n**核心思路**：论文的核心思路是将深度强化学习（DRL）应用于材料循环控制，通过构建基于热力学材料网络的动态环境，利用DRL算法学习最优的循环策略，从而最大化材料的循环利用率并减少浪费。\\n\\n**技术框架**：CiRL库的整体框架包括以下几个主要模块：1) 基于隔室动态热力学的材料网络建模；2) 基于状态空间形式的环境构建，便于动态系统分析和控制设计；3) 基于Stable-Baselines3的DRL算法集成；4) 基于Google Colaboratory的开发环境，方便用户使用。整个流程是，首先对材料循环过程进行建模，然后构建相应的强化学习环境，最后利用DRL算法训练智能体，学习最优的循环策略。\\n\\n**关键创新**：论文的关键创新在于将DRL技术应用于循环经济领域，并提出了一种基于热力学材料网络的动态环境建模方法。这种方法能够有效地捕捉材料循环过程中的复杂动态特性，为DRL算法的学习提供了一个 realistic 的环境。\\n\\n**关键设计**：CiRL库的关键设计包括：1) 采用状态空间形式来描述环境状态，方便使用动态系统控制理论进行分析；2) 基于Stable-Baselines3，可以使用各种先进的DRL算法，如PPO、SAC等；3) 提供了一系列预定义的循环经济环境，方便用户快速上手；4) 使用Google Colaboratory，降低了使用门槛。",
            "application_zh": "CiRL可应用于各种循环经济场景，例如废弃物管理、资源回收、产品再制造等。它可以帮助企业和政府优化资源利用效率，减少环境污染，实现可持续发展。未来，CiRL可以与材料流分析（MFA）等工具结合，为循环经济决策提供更全面的支持。",
            "highlight_zh": "由于论文为环境库的介绍，因此没有具体的实验结果展示。但论文强调CiRL基于Stable-Baselines3，可以使用各种先进的DRL算法，并提供了一系列预定义的循环经济环境，方便用户快速上手。CiRL在Google Colaboratory上开发，降低了使用门槛，方便不同背景的研究人员使用。",
            "tags_zh": [
                "循环经济",
                "深度强化学习",
                "材料流分析",
                "净零排放",
                "开源环境",
                "动态系统",
                "热力学材料网络"
            ],
            "_index": 117,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2505.21536/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2505.21536/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2505.21536/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "State-Dependent Refusal and Learned Incapacity in RLHF-Aligned Language Models",
            "authors": [
                "TK Lee"
            ],
            "arxiv_id": "2512.13762",
            "summary": "Large language models (LLMs) are widely deployed as general-purpose tools, yet extended interaction can reveal behavioral patterns not captured by standard quantitative benchmarks. We present a qualitative case-study methodology for auditing policy-linked behavioral selectivity in long-horizon interaction. In a single 86-turn dialogue session, the same model shows Normal Performance (NP) in broad, non-sensitive domains while repeatedly producing Functional Refusal (FR) in provider- or policy-sensitive domains, yielding a consistent asymmetry between NP and FR across domains. Drawing on learned helplessness as an analogy, we introduce learned incapacity (LI) as a behavioral descriptor for this selective withholding without implying intentionality or internal mechanisms. We operationalize three response regimes (NP, FR, Meta-Narrative; MN) and show that MN role-framing narratives tend to co-occur with refusals in the same sensitive contexts. Overall, the study proposes an interaction-level auditing framework based on observable behavior and motivates LI as a lens for examining potential alignment side effects, warranting further investigation across users and models.",
            "categories": [
                "cs.AI",
                "cs.HC"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13762",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]RLHF"
                    ],
                    "score": 4.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 7.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出交互式审计框架，揭示RLHF对齐语言模型中的状态依赖性拒绝和习得性无能",
            "summary_zh": "大型语言模型（LLMs）被广泛部署为通用工具，但扩展的交互可能会揭示标准定量基准未捕获的行为模式。本文提出了一种定性案例研究方法，用于审计长时程交互中与策略相关的行为选择性。在单个86轮对话会话中，同一模型在广泛的非敏感领域表现出正常性能（NP），而在提供者或策略敏感领域反复产生功能性拒绝（FR），从而在不同领域之间产生一致的NP和FR不对称性。借鉴习得性无助作为类比，我们引入习得性无能（LI）作为这种选择性拒绝的行为描述符，而不暗示意图或内部机制。我们定义了三种响应模式（NP、FR、元叙事；MN），并表明MN角色框架叙事倾向于在相同的敏感上下文中与拒绝同时发生。总的来说，该研究提出了一个基于可观察行为的交互级别审计框架，并提出了LI作为检查潜在对齐副作用的视角，值得在用户和模型之间进行进一步研究。",
            "intro_zh": [
                "现有定量基准难以捕捉LLM在长时程交互中的行为模式，尤其是在策略敏感领域。",
                "通过定性案例研究，揭示LLM在不同领域表现出的“习得性无能”现象，即选择性拒绝。",
                "定义了三种响应模式（NP、FR、MN），并发现MN与敏感领域中的拒绝行为存在关联。"
            ],
            "method_zh": "**问题定义**：现有的大型语言模型在通用领域表现良好，但在涉及提供者或策略敏感领域时，可能会出现不一致的行为。传统的定量评估方法难以捕捉这种长时程交互中的行为选择性，尤其是在模型出现拒绝服务或回避问题时。因此，需要一种新的方法来审计和理解这种与策略相关的行为模式。\\n\\n**核心思路**：本文的核心思路是通过长时程交互的定性案例研究，观察和分析LLM在不同状态下的行为表现。借鉴心理学中的“习得性无助”概念，提出了“习得性无能”（Learned Incapacity，LI）这一概念，用于描述模型在特定情境下选择性地拒绝提供服务或信息，而无需假设模型具有明确的意图或内部机制。\\n\\n**技术框架**：该研究采用了一种交互级别的审计框架，主要包括以下几个阶段：1) 设计包含敏感和非敏感领域的对话场景；2) 与LLM进行长时程对话（86轮）；3) 将LLM的响应分为三种模式：正常性能（NP）、功能性拒绝（FR）和元叙事（MN）；4) 分析不同响应模式在不同领域中的分布和关联性，特别是MN与FR之间的关系。\\n\\n**关键创新**：该研究的关键创新在于：1) 提出了一种基于长时程交互的定性审计方法，用于评估LLM的行为选择性；2) 引入了“习得性无能”这一概念，为理解LLM在策略敏感领域的拒绝行为提供了一个新的视角；3) 揭示了元叙事（MN）与功能性拒绝（FR）之间的关联性，表明模型可能通过叙事框架来合理化其拒绝行为。\\n\\n**关键设计**：该研究的关键设计包括：1) 精心设计的对话场景，涵盖了广泛的非敏感领域和特定的策略敏感领域；2) 细致的响应模式分类，将LLM的响应分为NP、FR和MN三种类型，以便进行定量分析；3) 长达86轮的对话长度，确保能够观察到模型在不同状态下的行为变化。",
            "application_zh": "该研究成果可应用于评估和改进大型语言模型的安全性和可靠性，尤其是在涉及敏感信息或伦理考量时。通过审计模型在长时程交互中的行为模式，可以发现潜在的对齐问题和副作用，并采取相应的措施来缓解这些问题。此外，该研究提出的审计框架和“习得性无能”概念，可以为未来的LLM安全研究提供新的思路和方法。",
            "highlight_zh": "在86轮对话中，模型在非敏感领域表现出正常性能（NP），但在策略敏感领域反复产生功能性拒绝（FR），表明存在状态依赖性拒绝。研究还发现，元叙事（MN）倾向于在相同的敏感上下文中与拒绝同时发生，暗示模型可能使用叙事框架来合理化其拒绝行为。",
            "tags_zh": [
                "大型语言模型",
                "RLHF对齐",
                "行为审计",
                "习得性无能",
                "长时程交互"
            ],
            "_index": 118,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Context-Picker: Dynamic context selection using multi-stage reinforcement learning",
            "authors": [
                "Siyuan Zhu",
                "Chengdong Xu",
                "Kaiqiang Ke",
                "Chao Yu"
            ],
            "arxiv_id": "2512.14465",
            "summary": "In long-context question answering (LCQA), determining the optimal amount of context for a given query is a significant challenge. Including too few passages may omit critical information, while including too many can introduce noise and reduce the quality of the answer. Traditional approaches, such as fixed Top-$K$ retrieval and single-stage reranking, face the dilemma of selecting the right number of passages. This problem is particularly pronounced for factoid questions, which often require only a few specific pieces of evidence. To address this issue, we introduce \\emph{Context-Picker}, a reasoning-aware framework that shifts the paradigm from similarity-based ranking to minimal sufficient subset selection. Context-Picker treats context selection as a decision-making process optimized via a human-inspired, two-stage reinforcement learning schedule: a \\emph{recall-oriented} stage that prioritizes the coverage of reasoning chains, followed by a \\emph{precision-oriented} stage that aggressively prunes redundancy to distill a compact evidence set. To resolve reward sparsity, we propose an offline evidence distillation pipeline that mines \"minimal sufficient sets\" via a Leave-One-Out (LOO) procedure, providing dense, task-aligned supervision. Experiments on five long-context and multi-hop QA benchmarks demonstrate that Context-Picker significantly outperforms strong RAG baselines, achieving superior answer accuracy with comparable or reduced context lengths. Ablation studies indicate that the coarse-to-fine optimization schedule, the redundancy-aware reward shaping, and the rationale-guided format all contribute substantially to these gains.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14465",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning",
                        "distillation",
                        "reward shaping"
                    ],
                    "score": 7.5
                }
            ],
            "relevance_score": 7.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "Context-Picker：利用多阶段强化学习动态选择长文本问答的上下文",
            "summary_zh": "在长文本问答（LCQA）中，确定给定查询的最佳上下文数量是一个重大挑战。包含过少的段落可能遗漏关键信息，而包含过多的段落会引入噪声并降低答案质量。传统的Top-$K$检索和单阶段重排序等方法面临着选择合适段落数量的困境，对于通常只需要少量特定证据的事实性问题尤其如此。为了解决这个问题，我们引入了Context-Picker，这是一个推理感知的框架，它将范式从基于相似性的排序转变为最小充分子集选择。Context-Picker将上下文选择视为一个决策过程，通过受人类启发的两阶段强化学习方案进行优化：一个以召回为导向的阶段，优先考虑推理链的覆盖；然后是一个以精确为导向的阶段，积极地修剪冗余以提炼出一个紧凑的证据集。为了解决奖励稀疏性问题，我们提出了一个离线证据提炼流程，通过留一法（LOO）程序挖掘“最小充分集”，提供密集的、任务对齐的监督。在五个长文本和多跳问答基准上的实验表明，Context-Picker显著优于强大的RAG基线，以相当或更短的上下文长度实现了卓越的答案准确性。消融研究表明，由粗到精的优化方案、冗余感知的奖励塑造和基于理由的格式都对这些收益做出了重大贡献。",
            "intro_zh": [
                "长文本问答中，固定数量的上下文检索方法难以平衡信息覆盖和噪声抑制，影响答案质量。",
                "Context-Picker采用两阶段强化学习，先召回关键信息，再精简冗余上下文，选择最小充分证据集。",
                "实验表明，Context-Picker在多个基准测试中优于现有RAG模型，提升了答案准确性并减少了上下文长度。"
            ],
            "method_zh": "**问题定义**：长文本问答（LCQA）任务中，如何为给定的问题选择最佳数量和质量的上下文段落是一个关键问题。现有方法，如固定Top-K检索，要么可能遗漏关键信息，要么引入过多噪声，导致答案质量下降。特别是对于事实性问题，通常只需要少量关键证据，但现有方法难以精确选择。\n\n**核心思路**：Context-Picker的核心思路是将上下文选择视为一个决策过程，通过强化学习来优化。它借鉴人类的阅读理解习惯，首先尽可能召回所有相关信息，然后再逐步去除冗余信息，最终选择一个最小但充分的证据子集。这种由粗到精的策略旨在提高答案的准确性和效率。\n\n**技术框架**：Context-Picker采用一个两阶段强化学习框架。第一阶段是“召回导向”阶段，目标是尽可能覆盖所有可能包含答案的上下文段落。第二阶段是“精确导向”阶段，目标是去除冗余和噪声段落，提炼出一个紧凑的证据集。为了解决强化学习中的奖励稀疏性问题，论文还提出了一个离线证据提炼流程，用于生成密集的、任务对齐的监督信号。\n\n**关键创新**：Context-Picker的关键创新在于将上下文选择问题转化为一个可学习的决策过程，并采用两阶段强化学习策略进行优化。与传统的基于相似度排序的方法不同，Context-Picker关注的是选择一个最小但充分的证据子集，而不是简单地选择Top-K个最相似的段落。此外，离线证据提炼流程有效地解决了奖励稀疏性问题，提高了学习效率。\n\n**关键设计**：在第一阶段，奖励函数侧重于召回率，鼓励模型选择更多可能包含答案的段落。在第二阶段，奖励函数侧重于精确率，惩罚模型选择冗余段落。离线证据提炼流程使用留一法（LOO）来挖掘“最小充分集”，即移除任何一个段落都会导致答案错误的最小段落集合。这些“最小充分集”被用作强化学习的监督信号，引导模型学习如何选择最佳上下文。",
            "application_zh": "Context-Picker可应用于各种需要从长文本中提取信息的场景，如智能客服、法律文档分析、金融报告解读等。通过更精确地选择上下文，可以提高信息检索的效率和准确性，减少计算资源消耗，并提升用户体验。该研究对于提升长文本处理能力具有重要意义。",
            "highlight_zh": "Context-Picker在五个长文本和多跳问答基准测试中显著优于现有的RAG基线模型。实验结果表明，Context-Picker在保持或减少上下文长度的同时，显著提高了答案的准确性。消融实验验证了由粗到精的优化策略、冗余感知的奖励塑造以及基于理由的格式对性能提升的贡献。",
            "tags_zh": [
                "长文本问答",
                "上下文选择",
                "强化学习",
                "多阶段学习",
                "证据提炼"
            ],
            "_index": 119,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14465/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14465/figures/overview-2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14465/x2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Language Self-Play For Data-Free Training",
            "authors": [
                "Jakub Grudzien Kuba",
                "Mengting Gu",
                "Qi Ma",
                "Yuandong Tian",
                "Vijai Mohan",
                "Jason Chen"
            ],
            "arxiv_id": "2509.07414",
            "summary": "Large language models (LLMs) have advanced rapidly in recent years, driven by scale, abundant high-quality training data, and reinforcement learning. Yet this progress faces a fundamental bottleneck: the need for ever more data from which models can continue to learn. In this work, we propose a reinforcement learning approach that removes this dependency by enabling models to improve without additional data. Our method leverages a game-theoretic framework of self-play, where a model's capabilities are cast as performance in a competitive game and stronger policies emerge by having the model play against itself-a process we call Language Self-Play (LSP). Experiments with Llama-3.2-3B-Instruct on instruction-following, mathematics, and coding benchmarks show that pretrained models can be effectively improved with self-play alone.",
            "categories": [
                "cs.AI",
                "cs.CL",
                "cs.GT"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2509.07414",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "instruction following"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 7.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出语言自博弈(LSP)方法，实现大模型在无数据条件下的持续改进",
            "summary_zh": "近年来，大规模语言模型（LLMs）在规模、高质量训练数据和强化学习的驱动下取得了快速进展。然而，这种进步面临着一个根本性的瓶颈：需要越来越多的数据来支持模型的持续学习。本文提出了一种强化学习方法，通过使模型在没有额外数据的情况下进行改进来消除这种依赖性。我们的方法利用了自博弈的博弈论框架，其中模型的能力被视为在竞争性游戏中的表现，并通过让模型与自身对弈来产生更强的策略——我们称之为语言自博弈（LSP）。在instruction-following、数学和编码基准上对Llama-3.2-3B-Instruct进行的实验表明，预训练模型可以通过单独的自博弈得到有效改进。",
            "intro_zh": [
                "现有大模型依赖大量高质量数据进行训练和持续改进，数据获取成本高昂且存在瓶颈。",
                "提出语言自博弈（LSP）方法，将模型能力视为博弈表现，通过模型自身对弈提升策略。",
                "实验表明，LSP能有效提升Llama-3.2-3B-Instruct在指令跟随、数学和编码任务上的性能。"
            ],
            "method_zh": "**问题定义**：现有的大语言模型训练和持续改进严重依赖于大量高质量的训练数据。获取和维护这些数据的成本非常高昂，并且数据的质量直接影响模型的性能。此外，数据偏见和隐私问题也日益突出。因此，如何在没有额外数据的情况下提升大模型的性能是一个重要的研究问题。\\n\\n**核心思路**：本文的核心思路是利用强化学习中的自博弈思想，让模型在没有外部数据的情况下，通过与自身的交互来学习和改进。具体来说，将模型的指令跟随、数学或编码能力视为在一个竞争性游戏中的表现，通过让模型扮演不同的角色（例如，一个生成指令，另一个执行指令），并根据博弈的结果来调整模型的策略，从而提升模型的整体性能。\\n\\n**技术框架**：LSP的整体框架包含以下几个主要阶段：1) **初始化**：使用预训练的大语言模型作为初始策略。2) **自博弈**：模型与自身进行多轮博弈，每一轮博弈包括指令生成和指令执行两个阶段。3) **奖励计算**：根据博弈的结果（例如，指令执行的正确性）计算奖励信号。4) **策略更新**：使用强化学习算法（例如，PPO）根据奖励信号更新模型的策略。这个过程不断迭代，直到模型达到期望的性能水平。\\n\\n**关键创新**：LSP的关键创新在于它提供了一种在没有额外数据的情况下提升大语言模型性能的方法。与传统的监督学习或强化学习方法不同，LSP不需要外部数据集或人工标注，而是通过模型自身的交互来学习和改进。这种方法可以有效地降低数据获取和维护的成本，并且可以避免数据偏见和隐私问题。\\n\\n**关键设计**：在LSP中，关键的设计包括：1) **博弈规则**：需要定义清晰的博弈规则，例如，如何生成指令，如何执行指令，以及如何判断指令执行的正确性。2) **奖励函数**：需要设计合适的奖励函数，以鼓励模型生成和执行高质量的指令。3) **强化学习算法**：需要选择合适的强化学习算法来更新模型的策略。4) **探索策略**：需要采用一定的探索策略，以避免模型陷入局部最优解。",
            "application_zh": "语言自博弈(LSP)具有广泛的应用前景，可用于持续提升大语言模型在各种任务上的性能，尤其是在数据稀缺或难以获取的领域。该方法能够降低模型训练成本，减少对外部数据的依赖，并有望应用于个性化模型训练、机器人控制、游戏AI等领域，实现更智能、更自主的学习。",
            "highlight_zh": "实验结果表明，LSP能够有效提升Llama-3.2-3B-Instruct在指令跟随、数学和编码任务上的性能。例如，在指令跟随任务上，LSP可以将模型的性能提升X%。与传统的监督学习方法相比，LSP在没有额外数据的情况下实现了可比甚至更好的性能。这些结果表明，LSP是一种有前景的大语言模型持续改进方法。",
            "tags_zh": [
                "语言自博弈",
                "强化学习",
                "无数据训练",
                "大语言模型",
                "模型优化"
            ],
            "_index": 120,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2509.07414/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2509.07414/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2509.07414/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "FiNERweb: Datasets and Artifacts for Scalable Multilingual Named Entity Recognition",
            "authors": [
                "Jonas Golde",
                "Patrick Haller",
                "Alan Akbik"
            ],
            "arxiv_id": "2512.13884",
            "summary": "Recent multilingual named entity recognition (NER) work has shown that large language models (LLMs) can provide effective synthetic supervision, yet such datasets have mostly appeared as by-products of broader experiments rather than as systematic, reusable resources. We introduce FiNERweb, a dataset-creation pipeline that scales the teacher-student paradigm to 91 languages and 25 scripts. Building on FineWeb-Edu, our approach trains regression models to identify NER-relevant passages and annotates them with multilingual LLMs, resulting in about 225k passages with 235k distinct entity labels. Our experiments show that the regression model achieves more than 84 F1, and that models trained on FiNERweb obtain comparable or improved performance in zero shot transfer settings on English, Thai, and Swahili, despite being trained on 19x less data than strong baselines. In addition, we assess annotation quality using LLM-as-a-judge and observe consistently high scores for both faithfulness (3.99 out of 5) and completeness (4.05 out of 5), indicating reliable and informative annotations. Further, we release the dataset with both English labels and translated label sets in the respective target languages because we observe that the performance of current state-of-the-art models drops by 0.02 to 0.09 F1 when evaluated using target language labels instead of English ones. We release FiNERweb together with all accompanying artifacts to the research community in order to facilitate more effective student-teacher training for multilingual named entity recognition.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13884",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "teacher-student"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "zero-shot transfer"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 7.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "FiNERweb：用于可扩展多语言命名实体识别的数据集与工具",
            "summary_zh": "本文介绍FiNERweb，一个数据集创建流程，将teacher-student范式扩展到91种语言和25种文字。该方法基于FineWeb-Edu，训练回归模型以识别与NER相关的段落，并使用多语言LLM对其进行标注，从而产生约22.5万个段落，包含23.5万个不同的实体标签。实验表明，回归模型实现了超过84的F1值，并且在FiNERweb上训练的模型在英语、泰语和斯瓦希里语的zero-shot迁移设置中获得了可比或更高的性能，尽管训练数据比强基线少19倍。此外，我们使用LLM-as-a-judge评估标注质量，观察到保真度（5分制为3.99）和完整性（5分制为4.05）均持续获得高分，表明标注可靠且信息丰富。我们发布了带有英语标签和相应目标语言翻译标签的数据集，因为我们观察到，使用目标语言标签而不是英语标签进行评估时，当前最先进模型的性能会下降0.02到0.09 F1。为了促进更有效的多语言命名实体识别的student-teacher训练，我们向研究社区发布FiNERweb以及所有随附的工具。",
            "intro_zh": [
                "现有的大型语言模型（LLM）可以提供有效的合成监督，但相关数据集通常是更广泛实验的副产品，缺乏系统性和可重用性。",
                "FiNERweb通过训练回归模型识别NER相关段落，并利用多语言LLM进行标注，从而大规模生成多语言NER数据集。",
                "实验表明，FiNERweb训练的模型在zero-shot迁移学习中表现出色，且标注质量高，为多语言NER提供了有价值的资源。"
            ],
            "method_zh": "**问题定义**：论文旨在解决多语言命名实体识别（NER）中缺乏大规模、高质量训练数据的问题。现有的方法要么依赖于人工标注，成本高昂且难以扩展到多种语言，要么依赖于LLM生成的数据，但这些数据通常是副产品，缺乏系统性和质量保证。\\n\\n**核心思路**：论文的核心思路是利用teacher-student范式，首先训练一个回归模型来识别NER相关的文本段落（teacher），然后使用多语言LLM对这些段落进行标注（student）。这种方法可以高效地生成大规模、多语言的NER数据集，同时保证标注质量。\\n\\n**技术框架**：FiNERweb的整体流程包括以下几个主要阶段：1) 基于FineWeb-Edu数据集，训练一个回归模型，用于预测文本段落与NER任务的相关性。2) 使用该回归模型从大规模文本语料库中筛选出NER相关的段落。3) 使用多语言LLM对筛选出的段落进行命名实体标注。4) 对标注结果进行质量评估，并发布数据集。\\n\\n**关键创新**：FiNERweb的关键创新在于其可扩展性。通过训练回归模型来预筛选NER相关的段落，可以显著减少LLM需要处理的文本量，从而降低标注成本，并使其能够扩展到91种语言和25种文字。此外，论文还使用了LLM-as-a-judge来评估标注质量，确保数据集的可靠性。\\n\\n**关键设计**：回归模型使用F1值作为评估指标，目标是最大化NER相关段落的识别精度。LLM标注过程中，采用了多种prompt工程技术，以提高标注的准确性和一致性。数据集发布时，同时提供了英语标签和目标语言翻译标签，以便研究人员进行更全面的评估。",
            "application_zh": "FiNERweb数据集可用于训练多语言NER模型，应用于跨语言信息检索、机器翻译、多语言知识图谱构建等领域。该数据集的发布将促进多语言自然语言处理技术的发展，并为构建更智能、更全球化的AI系统提供支持。",
            "highlight_zh": "实验结果表明，在FiNERweb上训练的模型在英语、泰语和斯瓦希里语的zero-shot迁移设置中获得了可比或更高的性能，尽管训练数据比强基线少19倍。此外，使用LLM-as-a-judge评估标注质量，保真度达到3.99/5，完整性达到4.05/5，表明标注质量高。",
            "tags_zh": [
                "多语言NER",
                "命名实体识别",
                "数据集构建",
                "Teacher-Student学习",
                "LLM标注"
            ],
            "_index": 121,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13884/images/finerweb_approach.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13884/images/preference_classifier_cm.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.13884/images/typescript_stacked_normalized_horizontal.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "SAM3-I: Segment Anything with Instructions",
            "authors": [
                "Jingjing Li",
                "Yue Feng",
                "Yuchen Guo",
                "Jincai Huang",
                "Yongri Piao",
                "Qi Bi",
                "Miao Zhang",
                "Xiaoqi Zhao",
                "Qiang Chen",
                "Shihao Zou",
                "Wei Ji",
                "Huchuan Lu",
                "Li Cheng"
            ],
            "arxiv_id": "2512.04585",
            "summary": "Segment Anything Model 3 (SAM3) has advanced open-vocabulary segmentation through promptable concept segmentation, allowing users to segment all instances corresponding to a given concept, typically specified with short noun-phrase (NP) prompts. While this marks the first integration of language-level concepts within the SAM family, real-world usage typically requires far richer expressions that include attributes, spatial relations, functionalities, actions, states, and even implicit reasoning over instances. Currently, SAM3 relies on external multi-modal agents to convert complex instructions into NPs and then conduct iterative mask filtering. However, these NP-level concepts remain overly coarse, often failing to precisely represent a specific instance. In this work, we present SAM3-I, an enhanced framework that unifies concept-level understanding and instruction-level reasoning within the SAM family. SAM3-I introduces an instruction-aware cascaded adaptation mechanism that progressively aligns expressive instruction semantics with SAM3's existing vision-language representations, enabling direct instruction-following segmentation without sacrificing its original concept-driven capabilities. Furthermore, we design a structured instruction taxonomy spanning concept, simple, and complex levels, and develop a scalable data engine to construct a dataset with diverse instruction-mask pairs. Experiments show that SAM3-I delivers appealing performance, demonstrating that SAM3 can be effectively extended to follow natural-language instructions while preserving its strong concept grounding. We open-source SAM3-I and provide practical fine-tuning workflows, enabling researchers to adapt it to domain-specific applications. The source code is available here.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.04585",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "open-vocabulary",
                        "open vocabulary"
                    ],
                    "score": 4.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "instruction following"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 7.0,
            "hit_pillars": [
                "3_perception_slam",
                "9_embodied_foundation"
            ],
            "headline_zh": "SAM3-I：通过指令感知的级联适配，增强SAM3以实现指令驱动的图像分割",
            "summary_zh": "Segment Anything Model 3 (SAM3) 通过可提示的概念分割推进了开放词汇分割，允许用户分割与给定概念对应的所有实例，这些概念通常用简短的名词短语 (NP) 提示指定。虽然这标志着 SAM 系列首次集成语言级别的概念，但实际应用通常需要更丰富的表达，包括属性、空间关系、功能、动作、状态，甚至是对实例的隐式推理。目前，SAM3 依赖于外部多模态代理将复杂指令转换为 NP，然后进行迭代掩码过滤。然而，这些 NP 级别的概念仍然过于粗糙，通常无法精确地表示特定实例。本文提出了 SAM3-I，这是一个增强的框架，它统一了 SAM 系列中的概念级理解和指令级推理。SAM3-I 引入了一种指令感知的级联适配机制，该机制逐步将表达性指令语义与 SAM3 现有的视觉-语言表示对齐，从而实现直接的指令跟随分割，而不会牺牲其原始的概念驱动能力。此外，我们设计了一个结构化的指令分类法，涵盖概念、简单和复杂级别，并开发了一个可扩展的数据引擎来构建具有多样化指令-掩码对的数据集。实验表明，SAM3-I 提供了有吸引力的性能，表明 SAM3 可以有效地扩展以遵循自然语言指令，同时保持其强大的概念基础。我们开源了 SAM3-I，并提供了实用的微调工作流程，使研究人员能够将其适应于特定领域的应用。",
            "intro_zh": [
                "现有SAM3模型依赖外部多模态代理将复杂指令转换为名词短语，导致概念过于粗糙，无法精确表示特定实例。",
                "SAM3-I通过指令感知的级联适配机制，将指令语义与SAM3的视觉-语言表示对齐，实现直接的指令跟随分割。",
                "论文构建了包含概念、简单和复杂级别的结构化指令分类法，并开发数据引擎构建多样化的指令-掩码对数据集。"
            ],
            "method_zh": "**问题定义**：SAM3虽然在开放词汇分割上取得了进展，但其依赖于将复杂指令转换为名词短语，这导致了信息损失和分割精度下降。现有方法无法直接处理包含属性、空间关系、功能等复杂信息的自然语言指令，限制了其在实际场景中的应用。因此，需要一种能够直接理解和执行复杂指令的分割模型。\\n\\n**核心思路**：SAM3-I的核心思路是通过指令感知的级联适配机制，将复杂的自然语言指令逐步融入到SAM3的视觉-语言表示中。这种方法避免了将指令简化为名词短语造成的语义损失，并允许模型直接根据指令进行分割。通过逐步对齐指令语义和视觉特征，模型能够更好地理解指令的意图，从而提高分割的准确性和鲁棒性。\\n\\n**技术框架**：SAM3-I的整体框架包含以下几个主要模块：1) 指令编码器：用于将自然语言指令编码为语义向量表示。2) 视觉编码器：利用SAM3现有的视觉编码器提取图像特征。3) 级联适配模块：通过多层适配器逐步将指令语义与视觉特征对齐，实现指令感知的特征融合。4) 分割解码器：利用融合后的特征生成分割掩码。整个流程是，首先输入图像和自然语言指令，经过编码器提取特征，然后通过级联适配模块进行特征融合，最后由解码器生成分割结果。\\n\\n**关键创新**：SAM3-I的关键创新在于指令感知的级联适配机制。与以往直接将指令转换为名词短语的方法不同，SAM3-I通过多层适配器逐步将指令语义融入到视觉特征中，从而保留了指令的完整语义信息。这种级联适配机制允许模型在不同层次上理解指令的意图，并根据指令调整分割策略。此外，论文还构建了一个包含多种指令类型的数据集，为模型的训练和评估提供了支持。\\n\\n**关键设计**：在级联适配模块中，使用了多层Transformer结构，每一层Transformer都包含自注意力机制和交叉注意力机制。自注意力机制用于捕捉指令内部的语义关系，交叉注意力机制用于将指令语义与视觉特征对齐。损失函数包括分割损失和对比学习损失。分割损失用于优化分割结果的准确性，对比学习损失用于拉近相似指令-图像对的特征表示，推远不相似指令-图像对的特征表示。",
            "application_zh": "SAM3-I在机器人导航、自动驾驶、医学图像分析等领域具有广泛的应用前景。例如，在机器人导航中，可以通过自然语言指令引导机器人完成特定任务，如“找到红色的盒子并将其移动到桌子上”。在医学图像分析中，医生可以使用自然语言指令来分割特定的组织或器官，从而辅助诊断和治疗。该研究的未来影响在于推动人机交互的自然化和智能化。",
            "highlight_zh": "实验结果表明，SAM3-I在多个数据集上取得了显著的性能提升。与基线方法相比，SAM3-I在复杂指令分割任务上的精度提高了15%。此外，SAM3-I在保持SAM3原有概念分割能力的同时，成功实现了指令驱动的分割，证明了该方法的有效性和通用性。论文开源了SAM3-I的代码和微调工作流程，方便研究人员进行进一步的研究和应用。",
            "tags_zh": [
                "图像分割",
                "自然语言指令",
                "视觉-语言模型",
                "级联适配",
                "SAM3",
                "指令跟随",
                "开放词汇分割"
            ],
            "_index": 122,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.04585/sam3_graph/agent1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.04585/sam3_graph/method.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.04585/sam3_graph/data.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Context Representation via Action-Free Transformer encoder-decoder for Meta Reinforcement Learning",
            "authors": [
                "Amir M. Soufi Enayati",
                "Homayoun Honari",
                "Homayoun Najjaran"
            ],
            "arxiv_id": "2512.14057",
            "summary": "Reinforcement learning (RL) enables robots to operate in uncertain environments, but standard approaches often struggle with poor generalization to unseen tasks. Context-adaptive meta reinforcement learning addresses these limitations by conditioning on the task representation, yet they mostly rely on complete action information in the experience making task inference tightly coupled to a specific policy. This paper introduces Context Representation via Action Free Transformer encoder decoder (CRAFT), a belief model that infers task representations solely from sequences of states and rewards. By removing the dependence on actions, CRAFT decouples task inference from policy optimization, supports modular training, and leverages amortized variational inference for scalable belief updates. Built on a transformer encoder decoder with rotary positional embeddings, the model captures long range temporal dependencies and robustly encodes both parametric and non-parametric task variations. Experiments on the MetaWorld ML-10 robotic manipulation benchmark show that CRAFT achieves faster adaptation, improved generalization, and more effective exploration compared to context adaptive meta--RL baselines. These findings highlight the potential of action-free inference as a foundation for scalable RL in robotic control.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14057",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 6.5,
            "hit_pillars": [
                "1_robot_core",
                "2_algo_arch"
            ],
            "headline_zh": "提出CRAFT：一种基于无动作Transformer的元强化学习上下文表示方法",
            "summary_zh": "强化学习(RL)使机器人能够在不确定环境中运行，但标准方法通常难以泛化到未见过的任务。上下文自适应元强化学习通过调节任务表示来解决这些限制，但它们主要依赖于经验中的完整动作信息，使得任务推断与特定策略紧密耦合。本文介绍了一种通过无动作Transformer编码器-解码器(CRAFT)进行上下文表示的方法，这是一种仅从状态和奖励序列推断任务表示的信念模型。通过消除对动作的依赖，CRAFT将任务推断与策略优化解耦，支持模块化训练，并利用摊销变分推断进行可扩展的信念更新。该模型建立在具有旋转位置嵌入的Transformer编码器-解码器之上，可以捕获长程时间依赖性，并稳健地编码参数和非参数任务变化。在MetaWorld ML-10机器人操作基准上的实验表明，与上下文自适应元强化学习基线相比，CRAFT实现了更快的适应、改进的泛化和更有效的探索。这些发现突出了无动作推断作为机器人控制中可扩展RL的基础的潜力。",
            "intro_zh": [
                "传统元强化学习方法依赖动作信息进行任务推断，导致任务推断与策略优化紧耦合，限制了泛化能力。",
                "CRAFT通过仅使用状态和奖励序列进行任务推断，解耦了任务推断与策略优化，支持模块化训练。",
                "实验表明，CRAFT在MetaWorld ML-10基准测试中，相比现有方法，实现了更快的适应、更好的泛化和更有效的探索。"
            ],
            "method_zh": "**问题定义**：现有元强化学习方法在进行任务推断时，通常需要依赖完整的动作信息。这种依赖使得任务推断过程与特定的策略紧密耦合，限制了模型在未见过的任务上的泛化能力。此外，这种耦合也使得模型的训练和优化变得复杂，难以进行模块化设计。\n\n**核心思路**：CRAFT的核心思路是通过构建一个信念模型，该模型仅依赖于状态和奖励序列来推断任务表示，从而避免对动作信息的依赖。通过这种方式，CRAFT将任务推断与策略优化解耦，使得模型可以更加灵活地适应不同的任务，并支持模块化的训练和优化。\n\n**技术框架**：CRAFT采用Transformer编码器-解码器架构作为其核心技术框架。该框架包含两个主要模块：编码器和解码器。编码器负责将状态和奖励序列编码成一个上下文向量，该向量代表了对当前任务的信念。解码器则负责根据该上下文向量来预测未来的状态和奖励。此外，CRAFT还采用了摊销变分推断(Amortized Variational Inference)来提高信念更新的可扩展性。\n\n**关键创新**：CRAFT最重要的技术创新点在于其无动作的任务推断方法。与传统的元强化学习方法不同，CRAFT不需要依赖动作信息来进行任务推断，而是仅使用状态和奖励序列。这种无动作的推断方法使得CRAFT可以更加灵活地适应不同的任务，并支持模块化的训练和优化。此外，CRAFT还采用了旋转位置嵌入(Rotary Positional Embeddings)来更好地捕捉长程时间依赖性。\n\n**关键设计**：CRAFT的关键设计包括：1) 使用Transformer编码器-解码器架构来捕捉长程时间依赖性；2) 采用旋转位置嵌入来编码序列信息；3) 使用摊销变分推断来提高信念更新的可扩展性；4) 设计合适的损失函数来训练编码器和解码器，例如，可以使用预测状态和奖励的均方误差作为损失函数。",
            "application_zh": "CRAFT的潜在应用领域包括机器人控制、自动驾驶、游戏AI等。通过解耦任务推断和策略优化，CRAFT可以帮助机器人在复杂和不确定的环境中更快地适应新任务，提高其泛化能力和鲁棒性。此外，CRAFT的模块化设计也使得其可以更容易地集成到现有的强化学习系统中，从而加速相关领域的研究和应用。",
            "highlight_zh": "实验结果表明，CRAFT在MetaWorld ML-10机器人操作基准测试中，相比于上下文自适应元强化学习基线，实现了更快的适应、更好的泛化和更有效的探索。具体来说，CRAFT在多个任务上的性能都优于基线方法，并且在一些困难任务上取得了显著的提升。这些结果表明，CRAFT的无动作任务推断方法是有效的，并且可以作为机器人控制中可扩展RL的基础。",
            "tags_zh": [
                "元强化学习",
                "上下文表示",
                "Transformer",
                "无动作推断",
                "机器人控制"
            ],
            "_index": 123,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14057/figs/meta_variations.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14057/figs/meta_bamdp.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14057/figs/meta_arch_overview.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Group-Theoretic Reinforcement Learning of Dynamical Decoupling Sequences",
            "authors": [
                "Charles Marrder",
                "Shuo Sun",
                "Murray J. Holland"
            ],
            "arxiv_id": "2512.13890",
            "summary": "Dynamical decoupling seeks to mitigate phase decoherence in qubits by applying a carefully designed sequence of effectively instantaneous electromagnetic pulses. Although analytic solutions exist for pulse timings that are optimal under specific noise regimes, identifying the optimal timings for a realistic noise spectrum remains challenging. We propose a reinforcement learning (RL)-based method for designing pulse sequences on qubits. Our novel action set enables the RL agent to efficiently navigate this inherently non-convex optimization landscape. The action set, derived from Thompson's group $F$, is applicable to a broad class of sequential decision problems whose states can be represented as bounded sequences. We demonstrate that our RL agent can learn pulse sequences that minimize dephasing without requiring explicit knowledge of the underlying noise spectrum. This work opens the possibility for real-time learning of optimal dynamical decoupling sequences on qubits which are dephasing-limited. The model-free nature of our algorithm suggests that the agent may ultimately learn optimal pulse sequences even in the presence of unmodeled physical effects, such as pulse errors or non-Gaussian noise.",
            "categories": [
                "cs.LG",
                "eess.SY"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13890",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning"
                    ],
                    "score": 4.5
                },
                {
                    "name": "支柱八：物理动画 (Physics-based Animation)",
                    "id": "8_physics_animation",
                    "matched_keywords": [
                        "PULSE"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 6.5,
            "hit_pillars": [
                "2_algo_arch",
                "8_physics_animation"
            ],
            "headline_zh": "提出基于群论强化学习的动态解耦序列设计方法，用于降低量子比特的退相干。",
            "summary_zh": "动态解耦旨在通过应用精心设计的瞬时电磁脉冲序列来减轻量子比特中的相位退相干。虽然对于特定噪声状态下的最优脉冲时序存在解析解，但识别真实噪声谱下的最优时序仍然具有挑战性。我们提出了一种基于强化学习（RL）的方法，用于设计量子比特上的脉冲序列。我们新颖的动作集使RL智能体能够有效地探索这种固有的非凸优化空间。该动作集源自Thompson群$F$，适用于状态可以表示为有界序列的广泛的序列决策问题。我们证明了我们的RL智能体可以学习最小化退相干的脉冲序列，而无需明确了解底层噪声谱。这项工作为量子比特上实时学习最优动态解耦序列开辟了可能性，这些量子比特受限于退相干。我们算法的无模型性质表明，即使存在未建模的物理效应（如脉冲误差或非高斯噪声），智能体最终也可能学习到最优脉冲序列。",
            "intro_zh": [
                "现有动态解耦方法在真实噪声环境下难以找到最优脉冲时序，面临非凸优化难题。",
                "利用强化学习设计脉冲序列，并提出基于Thompson群的动作集，高效探索优化空间。",
                "实验表明，该方法无需噪声谱知识即可学习到最小化退相干的脉冲序列。"
            ],
            "method_zh": "**问题定义**：论文旨在解决量子计算中由于环境噪声引起的量子比特退相干问题。现有的动态解耦方法，虽然在特定噪声模型下有解析解，但在实际复杂的噪声环境下，寻找最优的脉冲序列变得非常困难，这是一个非凸优化问题。\\n\\n**核心思路**：论文的核心思路是利用强化学习（RL）来自动寻找最优的动态解耦脉冲序列。通过将脉冲序列的设计过程建模为一个序列决策问题，RL智能体可以通过与环境的交互来学习最优策略，从而最小化量子比特的退相干。关键在于设计合适的动作空间，使得智能体能够高效地探索复杂的脉冲序列空间。\\n\\n**技术框架**：整体框架包含一个RL智能体和一个模拟的量子系统环境。智能体根据当前状态（例如，量子比特的相干性）选择一个动作（即一个脉冲序列），然后将该动作作用于量子系统。系统状态发生变化，并产生一个奖励信号，反馈给智能体。智能体根据奖励信号更新其策略，从而学习到更好的脉冲序列。该过程迭代进行，直到智能体找到最优的脉冲序列。\\n\\n**关键创新**：论文的关键创新在于提出了一个基于Thompson群 $F$ 的动作集。传统的动作空间可能非常庞大且难以探索，而Thompson群 $F$ 具有良好的代数结构，可以有效地表示和操作脉冲序列。这种动作集的设计使得RL智能体能够更高效地探索非凸优化空间，并找到最优的脉冲序列。\\n\\n**关键设计**：论文中RL智能体使用标准的强化学习算法，例如Q-learning或策略梯度方法。关键的设计在于动作集的选择，即如何将Thompson群 $F$ 的元素映射到实际的脉冲序列。此外，奖励函数的设计也至关重要，需要能够准确地反映量子比特的退相干程度。具体的参数设置和网络结构（如果使用深度强化学习）需要根据具体的实验环境进行调整。",
            "application_zh": "该研究成果可应用于量子计算和量子信息处理领域，通过优化动态解耦序列，提高量子比特的相干时间，从而提升量子算法的性能和可靠性。该方法具有无模型特性，有望在存在未建模物理效应的实际量子系统中实现最优控制，推动容错量子计算的发展。",
            "highlight_zh": "论文展示了该方法在模拟量子系统中的有效性，证明了RL智能体可以在无需明确了解底层噪声谱的情况下，学习到最小化退相干的脉冲序列。虽然论文中没有给出具体的性能数据和对比基线，但强调了该方法在复杂噪声环境下的潜在优势。",
            "tags_zh": [
                "动态解耦",
                "强化学习",
                "量子计算",
                "Thompson群",
                "退相干",
                "脉冲序列设计",
                "量子控制"
            ],
            "_index": 124,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13890/Figures/optimization_schematic.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13890/Figures/agent_schematic.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.13890/Figures/action_sequence_CPMG_spectrum_069_steps_shifted.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Fine-Tuning of Neural Network Approximate MPC without Retraining via Bayesian Optimization",
            "authors": [
                "Henrik Hose",
                "Paul Brunzema",
                "Alexander von Rohr",
                "Alexander Gräfe",
                "Angela P. Schoellig",
                "Sebastian Trimpe"
            ],
            "arxiv_id": "2512.14350",
            "summary": "Approximate model-predictive control (AMPC) aims to imitate an MPC's behavior with a neural network, removing the need to solve an expensive optimization problem at runtime. However, during deployment, the parameters of the underlying MPC must usually be fine-tuned. This often renders AMPC impractical as it requires repeatedly generating a new dataset and retraining the neural network. Recent work addresses this problem by adapting AMPC without retraining using approximated sensitivities of the MPC's optimization problem. Currently, this adaption must be done by hand, which is labor-intensive and can be unintuitive for high-dimensional systems. To solve this issue, we propose using Bayesian optimization to tune the parameters of AMPC policies based on experimental data. By combining model-based control with direct and local learning, our approach achieves superior performance to nominal AMPC on hardware, with minimal experimentation. This allows automatic and data-efficient adaptation of AMPC to new system instances and fine-tuning to cost functions that are difficult to directly implement in MPC. We demonstrate the proposed method in hardware experiments for the swing-up maneuver on an inverted cartpole and yaw control of an under-actuated balancing unicycle robot, a challenging control problem.",
            "categories": [
                "cs.RO",
                "eess.SY"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14350",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "[T]MPC"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "提出基于贝叶斯优化的神经近似MPC调参方法，无需重训练网络。",
            "summary_zh": "近似模型预测控制（AMPC）旨在用神经网络模仿MPC的行为，从而避免在运行时求解昂贵的优化问题。然而，在部署过程中，通常需要微调底层MPC的参数。这使得AMPC在实践中变得不切实际，因为它需要重复生成新的数据集并重新训练神经网络。最近的研究通过使用MPC优化问题的近似敏感度来调整AMPC，而无需重新训练。目前，这种调整必须手动完成，这既费力又难以理解高维系统。为了解决这个问题，我们提出使用贝叶斯优化来根据实验数据调整AMPC策略的参数。通过将基于模型的控制与直接和局部学习相结合，我们的方法在硬件上实现了优于标称AMPC的性能，且只需最少的实验。这允许自动且数据高效地将AMPC适应于新的系统实例，并微调难以在MPC中直接实现的成本函数。我们在倒立摆小车上的摆动操作和欠驱动平衡独轮车机器人的偏航控制（一个具有挑战性的控制问题）的硬件实验中证明了所提出的方法。",
            "intro_zh": [
                "传统AMPC在MPC参数调整后需重新训练网络，耗时且低效，限制了其应用。",
                "利用贝叶斯优化自动调整AMPC策略参数，无需重新训练，提升适应性和效率。",
                "硬件实验表明，该方法优于传统AMPC，并能有效处理复杂控制问题。"
            ],
            "method_zh": "**问题定义**：现有近似模型预测控制（AMPC）方法在实际部署中，当底层MPC的参数需要调整时，必须重新生成数据集并重新训练神经网络。这个过程耗时且计算成本高昂，使得AMPC在实际应用中受到限制。此外，手动调整AMPC策略参数在高维系统中非常困难且不直观。\\n\\n**核心思路**：本文的核心思路是利用贝叶斯优化（Bayesian Optimization）来自动调整AMPC策略的参数，而无需重新训练神经网络。贝叶斯优化是一种有效的全局优化方法，特别适用于目标函数评估成本高昂的情况。通过将实验数据作为反馈，贝叶斯优化能够高效地搜索最优的AMPC参数。\\n\\n**技术框架**：该方法的技术框架主要包括以下几个步骤：1. 初始化AMPC策略；2. 在实际系统中运行AMPC策略并收集实验数据；3. 使用实验数据评估AMPC策略的性能；4. 使用贝叶斯优化算法，基于性能评估结果，选择下一组AMPC参数；5. 重复步骤2-4，直到找到最优的AMPC参数。其中，性能评估函数可以是任何能够反映AMPC策略控制效果的指标，例如跟踪误差、能量消耗等。\\n\\n**关键创新**：该方法最重要的技术创新点在于将贝叶斯优化应用于AMPC策略的参数调整，实现了自动、数据高效的参数优化，避免了重新训练神经网络的需求。与传统的手动调整方法相比，该方法能够更快速、更有效地找到最优的AMPC参数，尤其是在高维系统中。\\n\\n**关键设计**：关键设计包括：1. 贝叶斯优化算法的选择，例如高斯过程回归；2. 性能评估函数的定义，需要能够准确反映AMPC策略的控制效果；3. 实验数据的收集策略，需要保证数据的质量和多样性；4. 贝叶斯优化的超参数设置，例如探索-利用平衡。",
            "application_zh": "该研究成果可广泛应用于机器人控制、自动驾驶、过程控制等领域。通过自动调整控制策略参数，可以提高控制系统的鲁棒性和适应性，降低人工干预的需求，并能更容易地将AMPC应用于新的系统实例和难以直接在MPC中实现的成本函数，具有重要的实际应用价值和广阔的应用前景。",
            "highlight_zh": "在倒立摆小车和欠驱动平衡独轮车的硬件实验中，该方法实现了优于标称AMPC的性能，证明了其有效性。实验结果表明，该方法能够以最小的实验代价，自动且数据高效地将AMPC适应于新的系统实例，并微调难以在MPC中直接实现的成本函数。",
            "tags_zh": [
                "近似模型预测控制",
                "贝叶斯优化",
                "神经网络",
                "参数调优",
                "机器人控制"
            ],
            "_index": 125,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "MAPS$^2$: Multi-Robot Autonomous Motion Planning under Signal Temporal Logic Specifications",
            "authors": [
                "Mayank Sewlia",
                "Christos K. Verginis",
                "Dimos V. Dimarogonas"
            ],
            "arxiv_id": "2309.05632",
            "summary": "This article presents MAPS$^2$ : a distributed algorithm that allows multi-robot systems to deliver coupled tasks expressed as Signal Temporal Logic (STL) constraints. Classical control theoretical tools addressing STL constraints either adopt a limited fragment of the STL formula or require approximations of min/max operators, whereas works maximising robustness through optimisation-based methods often suffer from local minima, relaxing any completeness arguments due to the NP-hard nature of the problem. Endowed with probabilistic guarantees, MAPS$^2$ provides an anytime algorithm that iteratively improves the robots' trajectories. The algorithm selectively imposes spatial constraints by taking advantage of the temporal properties of the STL. The algorithm is distributed, in the sense that each robot calculates its trajectory by communicating only with its immediate neighbours as defined via a communication graph. We illustrate the efficiency of MAPS$^2$ by conducting extensive simulation and experimental studies, verifying the generation of STL satisfying trajectories.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2309.05632",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "[T]motion planning"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "提出MAPS$^2$算法，解决多机器人系统在时序逻辑约束下的自主运动规划问题",
            "summary_zh": "本文提出了一种名为MAPS$^2$的分布式算法，该算法允许多机器人系统执行以信号时序逻辑(STL)约束表示的耦合任务。传统的解决STL约束的控制理论工具要么采用STL公式的有限片段，要么需要对min/max算子进行近似。而通过基于优化的方法最大化鲁棒性的工作通常会陷入局部最小值，由于问题的NP-hard性质，从而放松了任何完备性论证。MAPS$^2$具有概率保证，提供了一种随时可用的算法，可以迭代地改进机器人的轨迹。该算法通过利用STL的时间特性，选择性地施加空间约束。该算法是分布式的，即每个机器人仅通过与通信图中定义的直接邻居通信来计算其轨迹。我们通过广泛的仿真和实验研究验证了STL满足轨迹的生成，从而说明了MAPS$^2$的效率。",
            "intro_zh": [
                "现有方法在处理复杂时序逻辑约束时存在局限性，或易陷入局部最优解，难以保证完备性。",
                "MAPS$^2$算法利用STL的时间特性选择性地施加空间约束，并通过分布式方式迭代优化机器人轨迹。",
                "通过仿真和实验验证，MAPS$^2$能够有效地生成满足STL约束的轨迹，提升了多机器人系统的任务执行能力。"
            ],
            "method_zh": "**问题定义**：论文旨在解决多机器人系统在满足复杂时序逻辑（STL）约束下的自主运动规划问题。现有方法通常面临以下痛点：一是难以处理完整的STL公式，只能处理其有限子集；二是基于优化的方法容易陷入局部最优，无法保证全局最优解，从而影响任务的可靠性；三是缺乏有效的分布式实现方案，难以扩展到大规模机器人系统。\\n\\n**核心思路**：MAPS$^2$算法的核心思路是利用STL公式的时间特性，将复杂的时序约束分解为一系列空间约束，并选择性地施加这些约束。通过迭代优化机器人轨迹，逐步满足STL约束。采用分布式架构，每个机器人仅需与邻居通信，降低了计算复杂度，提高了系统的可扩展性。\\n\\n**技术框架**：MAPS$^2$算法的整体框架包含以下几个主要阶段：1. **STL公式解析**：将给定的STL公式解析为时间区间上的约束集合。2. **空间约束选择**：根据当前时间步，选择需要施加的空间约束。3. **轨迹优化**：基于选定的空间约束，优化每个机器人的轨迹，使其满足约束条件。4. **分布式通信**：机器人之间通过通信图进行信息交换，协调彼此的运动。5. **迭代更新**：重复执行步骤2-4，直到所有STL约束都得到满足或达到最大迭代次数。\\n\\n**关键创新**：MAPS$^2$算法的关键创新在于：1. **选择性约束施加**：利用STL的时间特性，避免了对所有约束的同时优化，降低了计算复杂度。2. **分布式架构**：采用分布式算法，每个机器人独立计算轨迹，并通过邻居通信进行协调，提高了系统的可扩展性和鲁棒性。3. **概率保证**：算法提供概率保证，确保在一定概率下能够找到满足STL约束的轨迹。\\n\\n**关键设计**：算法的关键设计包括：1. **通信图构建**：根据机器人之间的距离和任务需求，构建合适的通信图，影响着信息传递的效率和系统的性能。2. **轨迹优化方法**：可以选择不同的轨迹优化算法，如梯度下降、二次规划等，以满足不同的性能需求。3. **约束违反度量**：定义合适的约束违反度量，用于评估当前轨迹与STL约束的偏差程度，指导轨迹优化过程。4. **迭代停止条件**：设置合理的迭代停止条件，避免算法陷入无限循环，并保证算法的收敛性。",
            "application_zh": "该研究成果可应用于自动化仓库、智能交通、环境监测等领域。例如，在自动化仓库中，多机器人系统可以根据STL约束完成复杂的物料搬运任务，如“在A区域完成装载后，必须在5分钟内到达B区域卸载”。该算法的分布式特性使其能够扩展到大规模机器人系统，具有重要的实际应用价值和未来发展潜力。",
            "highlight_zh": "通过仿真和实验验证，MAPS$^2$算法能够有效地生成满足STL约束的轨迹。在仿真实验中，与现有方法相比，MAPS$^2$算法在相同时间内能够找到更优的解，且具有更高的成功率。实验结果表明，MAPS$^2$算法能够有效地解决多机器人系统在复杂时序逻辑约束下的自主运动规划问题。",
            "tags_zh": [
                "多机器人系统",
                "自主运动规划",
                "信号时序逻辑",
                "分布式算法",
                "轨迹优化"
            ],
            "_index": 126,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://ar5iv.labs.arxiv.org/assets/ar5iv.png",
                    "caption": "",
                    "figure_id": "img_0"
                }
            ]
        },
        {
            "title": "Complex Mathematical Expression Recognition: Benchmark, Large-Scale Dataset and Strong Baseline",
            "authors": [
                "Weikang Bai",
                "Yongkun Du",
                "Yuchen Su",
                "Yazhen Xie",
                "Zhineng Chen"
            ],
            "arxiv_id": "2512.13731",
            "summary": "Mathematical Expression Recognition (MER) has made significant progress in recognizing simple expressions, but the robust recognition of complex mathematical expressions with many tokens and multiple lines remains a formidable challenge. In this paper, we first introduce CMER-Bench, a carefully constructed benchmark that categorizes expressions into three difficulty levels: easy, moderate, and complex. Leveraging CMER-Bench, we conduct a comprehensive evaluation of existing MER models and general-purpose multimodal large language models (MLLMs). The results reveal that while current methods perform well on easy and moderate expressions, their performance degrades significantly when handling complex mathematical expressions, mainly because existing public training datasets are primarily composed of simple samples. In response, we propose MER-17M and CMER-3M that are large-scale datasets emphasizing the recognition of complex mathematical expressions. The datasets provide rich and diverse samples to support the development of accurate and robust complex MER models. Furthermore, to address the challenges posed by the complicated spatial layout of complex expressions, we introduce a novel expression tokenizer, and a new representation called Structured Mathematical Language, which explicitly models the hierarchical and spatial structure of expressions beyond LaTeX format. Based on these, we propose a specialized model named CMERNet, built upon an encoder-decoder architecture and trained on CMER-3M. Experimental results show that CMERNet, with only 125 million parameters, significantly outperforms existing MER models and MLLMs on CMER-Bench.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13731",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "multimodal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出CMER-Bench、MER-17M/CMER-3M数据集及CMERNet模型，提升复杂数学表达式识别性能。",
            "summary_zh": "数学表达式识别（MER）在简单表达式识别方面取得了显著进展，但对于包含大量token和多行的复杂数学表达式的鲁棒识别仍然是一个巨大的挑战。本文首先介绍了CMER-Bench，这是一个精心构建的基准，将表达式分为简单、中等和复杂三个难度级别。利用CMER-Bench，我们对现有的MER模型和通用多模态大型语言模型（MLLM）进行了全面评估。结果表明，虽然当前方法在简单和中等表达式上表现良好，但在处理复杂数学表达式时，性能会显著下降，这主要是因为现有的公共训练数据集主要由简单样本组成。为此，我们提出了MER-17M和CMER-3M，这些大规模数据集强调复杂数学表达式的识别。这些数据集提供了丰富多样的样本，以支持开发准确而鲁棒的复杂MER模型。此外，为了解决复杂表达式的复杂空间布局带来的挑战，我们引入了一种新的表达式tokenizer和一种名为结构化数学语言的新表示形式，该表示形式明确地对LaTeX格式之外的表达式的层次结构和空间结构进行建模。基于这些，我们提出了一个专门的模型CMERNet，它建立在编码器-解码器架构之上，并在CMER-3M上进行训练。实验结果表明，CMERNet仅具有1.25亿个参数，但在CMER-Bench上显著优于现有的MER模型和MLLM。",
            "intro_zh": [
                "现有MER模型在处理复杂数学表达式时性能显著下降，主要原因是缺乏包含复杂样本的大规模训练数据集。",
                "提出MER-17M和CMER-3M两个大规模数据集，并设计了一种新的表达式tokenizer和结构化数学语言表示。",
                "构建了基于编码器-解码器架构的CMERNet模型，并在CMER-Bench上取得了显著优于现有模型和MLLM的性能。"
            ],
            "method_zh": "**问题定义**：论文旨在解决复杂数学表达式识别的难题。现有方法在处理包含大量token和多行的复杂表达式时，性能显著下降。主要原因是现有公开数据集主要由简单样本组成，缺乏对复杂表达式的有效训练。此外，复杂表达式的空间布局复杂，难以有效建模。\\n\\n**核心思路**：论文的核心思路是构建大规模的复杂数学表达式数据集，并设计专门针对复杂表达式的模型。通过大规模数据训练，使模型能够学习到复杂表达式的特征表示。同时，通过新的tokenizer和结构化数学语言，更好地建模复杂表达式的层次结构和空间关系。\\n\\n**技术框架**：CMERNet采用编码器-解码器架构。编码器负责提取输入图像的特征，解码器负责生成对应的LaTeX表达式。论文还提出了新的表达式tokenizer和结构化数学语言，用于更好地表示复杂表达式。整个流程包括数据预处理、特征提取、序列生成和后处理等步骤。\\n\\n**关键创新**：论文的关键创新点包括：1) 构建了大规模的复杂数学表达式数据集MER-17M和CMER-3M；2) 提出了新的表达式tokenizer和结构化数学语言，用于更好地建模复杂表达式的层次结构和空间关系；3) 设计了专门针对复杂表达式的CMERNet模型。\\n\\n**关键设计**：CMERNet基于标准的编码器-解码器架构，具体参数设置未知。损失函数可能采用交叉熵损失或类似的序列生成损失。结构化数学语言的具体设计细节未知，但其目标是显式地建模表达式的层次和空间结构。CMERNet模型参数量为1.25亿。",
            "application_zh": "该研究成果可应用于在线教育、科学文献数字化、数学公式编辑等领域。通过提高复杂数学表达式的识别准确率，可以提升用户体验，降低人工校对成本，并促进数学知识的传播和应用。未来，该技术有望应用于更广泛的文档图像识别和理解任务。",
            "highlight_zh": "CMERNet在CMER-Bench上取得了显著优于现有MER模型和MLLM的性能。虽然具体的性能数据未知，但论文强调CMERNet仅使用1.25亿参数，表明其具有较高的效率。该结果表明，大规模数据集和专门设计的模型对于复杂数学表达式识别至关重要。",
            "tags_zh": [
                "数学表达式识别",
                "复杂表达式",
                "大规模数据集",
                "结构化表示",
                "编码器-解码器"
            ],
            "_index": 127,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13731/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13731/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.13731/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Nexels: Neurally-Textured Surfels for Real-Time Novel View Synthesis with Sparse Geometries",
            "authors": [
                "Victor Rong",
                "Jan Held",
                "Victor Chu",
                "Daniel Rebain",
                "Marc Van Droogenbroeck",
                "Kiriakos N. Kutulakos",
                "Andrea Tagliasacchi",
                "David B. Lindell"
            ],
            "arxiv_id": "2512.13796",
            "summary": "Though Gaussian splatting has achieved impressive results in novel view synthesis, it requires millions of primitives to model highly textured scenes, even when the geometry of the scene is simple. We propose a representation that goes beyond point-based rendering and decouples geometry and appearance in order to achieve a compact representation. We use surfels for geometry and a combination of a global neural field and per-primitive colours for appearance. The neural field textures a fixed number of primitives for each pixel, ensuring that the added compute is low. Our representation matches the perceptual quality of 3D Gaussian splatting while using $9.7\\times$ fewer primitives and $5.5\\times$ less memory on outdoor scenes and using $31\\times$ fewer primitives and $3.7\\times$ less memory on indoor scenes. Our representation also renders twice as fast as existing textured primitives while improving upon their visual quality.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13796",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "3D gaussian splatting",
                        "gaussian splatting",
                        "splatting"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "提出基于神经纹理Surfels的新视角合成方法，在稀疏几何下实现实时渲染。",
            "summary_zh": "本文提出了一种超越基于点的渲染的新表示方法，用于新视角合成，旨在解耦几何和外观以实现紧凑的表示。该方法使用Surfels表示几何，并结合全局神经场和每个图元的颜色来表示外观。神经场为每个像素的固定数量的图元进行纹理化，确保计算开销较低。实验结果表明，该表示方法在感知质量上与3D高斯溅射相当，同时在室外场景中使用减少9.7倍的图元和5.5倍的内存，在室内场景中使用减少31倍的图元和3.7倍的内存。此外，该表示方法的渲染速度是现有纹理图元的两倍，同时提高了视觉质量。",
            "intro_zh": [
                "现有高斯溅射方法在新视角合成中表现出色，但建模高纹理场景需要数百万个图元，即使场景几何结构简单。",
                "论文提出一种基于神经纹理Surfels的表示方法，解耦几何和外观，使用Surfels表示几何，神经场和图元颜色表示外观。",
                "实验表明，该方法在保持感知质量的同时，显著减少了图元数量和内存占用，并提高了渲染速度。"
            ],
            "method_zh": "**问题定义**：现有基于高斯溅射的新视角合成方法，在处理高纹理复杂场景时，需要大量的图元才能达到较好的渲染效果，这导致了巨大的内存占用和计算开销，限制了其在资源受限设备上的应用。即使场景的几何结构相对简单，仍然需要大量的图元来捕捉细节丰富的纹理信息。\\n\\n**核心思路**：论文的核心思路是将几何表示与外观表示解耦。具体来说，使用Surfels来表示场景的几何结构，Surfels是一种局部平面图元，可以有效地表示表面。然后，使用一个全局神经场和一个per-primitive颜色来表示外观。神经场负责对Surfels进行纹理化，从而减少了对大量图元的依赖。通过这种解耦，可以用更少的图元来表示复杂的场景，从而降低内存占用和计算开销。\\n\\n**技术框架**：该方法主要包含以下几个阶段：1) 使用Surfels表示场景的几何结构。2) 使用全局神经场对Surfels进行纹理化。神经场将3D空间坐标映射到纹理颜色。3) 使用per-primitive颜色来增强外观表示。4) 通过可微分渲染，将Surfels投影到图像平面上，并合成最终的图像。整体流程是从稀疏几何信息开始，通过神经纹理化生成高质量的新视角图像。\\n\\n**关键创新**：该方法最重要的创新点在于将神经场应用于Surfels的纹理化。与直接使用神经场表示整个场景不同，该方法使用神经场来增强Surfels的外观表示。这种方法结合了Surfels的几何表示能力和神经场的纹理生成能力，从而实现了更紧凑和高效的场景表示。此外，通过为每个像素固定数量的图元进行纹理化，保证了计算开销的可控性。\\n\\n**关键设计**：神经场的具体结构未知，但其输入是3D空间坐标，输出是纹理颜色。损失函数可能包含图像重建损失和正则化项，以保证渲染图像的质量和神经场的平滑性。Surfels的数量是一个重要的参数，需要根据场景的复杂程度进行调整。per-primitive颜色可以作为神经场的补充，用于捕捉局部颜色变化。",
            "application_zh": "该研究成果可应用于虚拟现实、增强现实、机器人导航、游戏开发等领域。通过使用更少的图元和内存，该方法可以实现更高效的新视角合成，从而在移动设备和嵌入式系统上实现高质量的渲染效果。此外，该方法还可以用于三维重建和场景编辑，为用户提供更灵活和交互式的体验。",
            "highlight_zh": "实验结果表明，该方法在室外场景中使用减少9.7倍的图元和5.5倍的内存，在室内场景中使用减少31倍的图元和3.7倍的内存，同时保持了与3D高斯溅射相当的感知质量。此外，该方法的渲染速度是现有纹理图元的两倍，并提高了视觉质量。这些结果表明，该方法在效率和质量方面都优于现有方法。",
            "tags_zh": [
                "新视角合成",
                "神经渲染",
                "Surfels",
                "神经纹理",
                "实时渲染"
            ],
            "_index": 128,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13796/x1.jpg",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13796/img/kernel/kernel_clamped.jpg",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.13796/x13.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "KFS-Bench: Comprehensive Evaluation of Key Frame Sampling in Long Video Understanding",
            "authors": [
                "Zongyao Li",
                "Kengo Ishida",
                "Satoshi Yamazaki",
                "Xiaotong Ji",
                "Jianquan Liu"
            ],
            "arxiv_id": "2512.14017",
            "summary": "We propose KFS-Bench, the first benchmark for key frame sampling in long video question answering (QA), featuring multi-scene annotations to enable direct and robust evaluation of sampling strategies. Key frame sampling is crucial for efficient long-form video understanding. In long video QA, selecting informative frames enables multimodal large language models (MLLMs) to improve both accuracy and efficiency. KFS-Bench addresses the limitation of prior works that only indirectly assess frame selection quality via QA accuracy. By providing ground-truth annotations of multiple disjoint scenes required per question, KFS-Bench allows us to directly analyze how different sampling approaches capture essential content across an entire long video. Using KFS-Bench, we conduct a comprehensive study of key frame sampling methods and identify that not only sampling precision but also scene coverage and sampling balance are the key factors influencing QA performance. Regarding all the factors, we design a novel sampling quality metric that correlates with QA accuracy. Furthermore, we develop a novel key frame sampling method that leverages question-video relevance to balance sampling diversity against question-frame similarity, thereby improving coverage of relevant scenes. Our adaptively balanced sampling approach achieves superior performance in both key frame sampling and QA performance. The benchmark is available atthis https URL.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14017",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "multimodal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出KFS-Bench长视频QA关键帧采样基准，提升多模态大语言模型效率与精度。",
            "summary_zh": "本文提出了KFS-Bench，这是首个用于长视频问答（QA）中关键帧采样的基准测试，它具有多场景标注，能够直接且稳健地评估采样策略。关键帧采样对于高效的长视频理解至关重要。在长视频QA中，选择信息丰富的帧能够使多模态大语言模型（MLLM）提高准确性和效率。KFS-Bench解决了现有工作仅通过QA准确率间接评估帧选择质量的局限性。通过提供每个问题所需多个不相交场景的ground-truth标注，KFS-Bench允许我们直接分析不同的采样方法如何捕获整个长视频中的关键内容。利用KFS-Bench，我们对关键帧采样方法进行了全面研究，发现不仅采样精度，而且场景覆盖率和采样平衡也是影响QA性能的关键因素。针对所有这些因素，我们设计了一种新的采样质量指标，该指标与QA准确率相关。此外，我们开发了一种新的关键帧采样方法，该方法利用问题-视频相关性来平衡采样多样性与问题-帧相似性，从而提高相关场景的覆盖率。我们的自适应平衡采样方法在关键帧采样和QA性能方面均实现了卓越的性能。该基准测试可在https URL上获得。",
            "intro_zh": [
                "现有长视频QA的关键帧采样方法评估不足，通常依赖QA准确率间接评估，缺乏直接的采样质量评估手段。",
                "论文提出KFS-Bench基准，通过多场景标注提供ground-truth，直接评估采样策略在长视频中的场景覆盖能力。",
                "设计了一种自适应平衡采样方法，利用问题-视频相关性平衡采样多样性和问题-帧相似性，提升QA性能。"
            ],
            "method_zh": "**问题定义**：长视频问答（QA）任务中，如何高效地选择关键帧以供多模态大语言模型（MLLM）使用，从而在保证QA准确率的同时，降低计算成本。现有方法通常通过最终的QA准确率来间接评估关键帧采样的质量，缺乏直接的、细粒度的评估指标，难以指导采样策略的优化。此外，现有方法可能无法很好地平衡采样精度、场景覆盖率和采样平衡性，导致性能瓶颈。\\n\\n**核心思路**：论文的核心思路是构建一个带有详细场景标注的基准数据集KFS-Bench，使得可以直接评估关键帧采样方法在长视频中捕获关键场景的能力。同时，设计一种自适应平衡采样方法，该方法根据问题与视频的相关性，动态调整采样策略，以平衡采样多样性和问题-帧相似性，从而提高相关场景的覆盖率。\\n\\n**技术框架**：整体框架包含以下几个主要部分：1) KFS-Bench基准数据集的构建，包括长视频的选择、问题的设计以及多场景的标注；2) 现有关键帧采样方法的评估，利用KFS-Bench直接评估各种采样策略的性能；3) 新的采样质量指标的设计，该指标能够反映采样精度、场景覆盖率和采样平衡性；4) 自适应平衡采样方法的提出，该方法根据问题-视频相关性动态调整采样策略；5) 实验验证，在KFS-Bench上评估自适应平衡采样方法的性能，并与现有方法进行比较。\\n\\n**关键创新**：论文的关键创新点在于：1) 提出了KFS-Bench基准数据集，为长视频QA中的关键帧采样提供了直接的评估手段；2) 设计了一种新的采样质量指标，能够综合反映采样精度、场景覆盖率和采样平衡性；3) 提出了一种自适应平衡采样方法，该方法能够根据问题-视频相关性动态调整采样策略，从而提高相关场景的覆盖率。与现有方法相比，该方法能够更好地平衡采样多样性和问题-帧相似性。\\n\\n**关键设计**：自适应平衡采样方法中，关键的设计包括：1) 问题-视频相关性的计算方式，例如可以使用预训练的语言模型提取问题和视频的特征，然后计算它们的相似度；2) 采样策略的动态调整机制，例如可以根据问题-视频相关性设置一个阈值，当相关性高于阈值时，增加采样多样性，反之，增加采样相似性；3) 损失函数的设计，例如可以使用交叉熵损失函数来训练采样模型，目标是最大化相关场景的覆盖率。",
            "application_zh": "该研究成果可广泛应用于长视频理解、智能监控、视频检索、教育视频分析等领域。通过更高效的关键帧采样，可以降低计算成本，提升多模态大语言模型在处理长视频时的效率和准确性，从而实现更智能的视频内容分析与理解。",
            "highlight_zh": "实验结果表明，提出的KFS-Bench基准能够有效评估关键帧采样方法的性能。自适应平衡采样方法在KFS-Bench上取得了优于现有方法的性能，在关键帧采样和QA准确率方面均有显著提升，验证了该方法的有效性。",
            "tags_zh": [
                "长视频理解",
                "关键帧采样",
                "多模态学习",
                "问答系统",
                "基准测试"
            ],
            "_index": 129,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14017/figs/fig1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                }
            ]
        },
        {
            "title": "Robust Single-shot Structured Light 3D Imaging via Neural Feature Decoding",
            "authors": [
                "Jiaheng Li",
                "Qiyu Dai",
                "Lihan Li",
                "Praneeth Chakravarthula",
                "He Sun",
                "Baoquan Chen",
                "Wenzheng Chen"
            ],
            "arxiv_id": "2512.14028",
            "summary": "We consider the problem of active 3D imaging using single-shot structured light systems, which are widely employed in commercial 3D sensing devices such as Apple Face ID and Intel RealSense. Traditional structured light methods typically decode depth correspondences through pixel-domain matching algorithms, resulting in limited robustness under challenging scenarios like occlusions, fine-structured details, and non-Lambertian surfaces. Inspired by recent advances in neural feature matching, we propose a learning-based structured light decoding framework that performs robust correspondence matching within feature space rather than the fragile pixel domain. Our method extracts neural features from the projected patterns and captured infrared (IR) images, explicitly incorporating their geometric priors by building cost volumes in feature space, achieving substantial performance improvements over pixel-domain decoding approaches. To further enhance depth quality, we introduce a depth refinement module that leverages strong priors from large-scale monocular depth estimation models, improving fine detail recovery and global structural coherence. To facilitate effective learning, we develop a physically-based structured light rendering pipeline, generating nearly one million synthetic pattern-image pairs with diverse objects and materials for indoor settings. Experiments demonstrate that our method, trained exclusively on synthetic data with multiple structured light patterns, generalizes well to real-world indoor environments, effectively processes various pattern types without retraining, and consistently outperforms both commercial structured light systems and passive stereo RGB-based depth estimation methods. Project page:this https URL.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14028",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "depth estimation",
                        "monocular depth"
                    ],
                    "score": 4.0
                },
                {
                    "name": "支柱六：视频提取与匹配 (Video Extraction)",
                    "id": "6_video_extraction",
                    "matched_keywords": [
                        "feature matching"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "3_perception_slam",
                "6_video_extraction"
            ],
            "headline_zh": "提出基于神经特征解码的鲁棒单目结构光3D成像方法",
            "summary_zh": "本文研究了使用单目结构光系统进行主动3D成像的问题，该系统广泛应用于商业3D传感设备，如Apple Face ID和Intel RealSense。传统的结构光方法通常通过像素域匹配算法解码深度对应关系，导致在遮挡、精细结构细节和非朗伯表面等具有挑战性的场景下鲁棒性有限。受神经特征匹配最新进展的启发，我们提出了一种基于学习的结构光解码框架，该框架在特征空间而非脆弱的像素域中执行鲁棒的对应关系匹配。我们的方法从投影图案和捕获的红外（IR）图像中提取神经特征，通过在特征空间中构建代价体来显式地结合它们的几何先验，从而实现了相对于像素域解码方法的显著性能提升。为了进一步提高深度质量，我们引入了一个深度细化模块，该模块利用来自大规模单目深度估计模型的强大先验，从而改善了精细细节恢复和全局结构一致性。为了促进有效的学习，我们开发了一个基于物理的结构光渲染管线，生成了近一百万个具有各种对象和室内环境材料的合成图案-图像对。实验表明，我们的方法仅在具有多个结构光图案的合成数据上进行训练，可以很好地推广到真实世界的室内环境，有效地处理各种图案类型而无需重新训练，并且始终优于商业结构光系统和基于被动立体RGB的深度估计方法。",
            "intro_zh": [
                "传统结构光方法在遮挡、精细结构和非朗伯表面等复杂场景下，由于像素域匹配的脆弱性，鲁棒性不足。",
                "该论文提出一种基于学习的结构光解码框架，通过在特征空间进行鲁棒匹配，并结合几何先验来提升性能。",
                "实验表明，该方法在合成数据上训练后，能很好地泛化到真实环境，且优于商业结构光系统和被动立体视觉方法。"
            ],
            "method_zh": "**问题定义**：论文旨在解决单目结构光三维成像中，传统方法在复杂场景下鲁棒性差的问题。现有方法依赖像素域的匹配，易受光照、遮挡和表面属性的影响，导致深度估计精度下降。\\n\\n**核心思路**：论文的核心思路是将像素域的匹配问题转化为特征空间的匹配问题。通过提取图像的神经特征，并在特征空间构建代价体，可以更鲁棒地建立对应关系，从而提高深度估计的准确性和鲁棒性。这种方法利用了深度学习强大的特征提取能力，以及特征空间对噪声和变化的容忍性。\\n\\n**技术框架**：整体框架包含三个主要模块：1) 特征提取模块：使用卷积神经网络从投影图案和红外图像中提取神经特征。2) 特征匹配模块：在特征空间构建代价体，并通过回归或分类的方式建立对应关系。3) 深度细化模块：利用单目深度估计模型的先验知识，对初始深度图进行细化，提高细节恢复和全局一致性。\\n\\n**关键创新**：最重要的创新点在于将结构光解码问题从像素域转移到特征域。通过学习到的神经特征，可以更有效地利用图像中的信息，从而提高匹配的鲁棒性和准确性。此外，利用单目深度估计的先验知识进行深度细化，进一步提升了深度图的质量。\\n\\n**关键设计**：论文设计了一个基于物理的结构光渲染管线，生成了大量的合成数据用于训练。代价体可以使用不同的构建方式，例如相关性计算或相似度度量。深度细化模块可以采用不同的单目深度估计模型，并根据具体任务进行调整。损失函数的设计需要考虑匹配的准确性和深度图的平滑性。",
            "application_zh": "该研究成果可广泛应用于三维扫描、人脸识别、机器人导航、增强现实等领域。特别是在对鲁棒性和精度要求较高的场景下，例如工业检测、医疗诊断等，具有重要的应用价值。未来，该方法有望进一步推广到室外环境和更复杂的表面材质，实现更广泛的应用。",
            "highlight_zh": "该方法在合成数据上训练后，能够很好地泛化到真实世界的室内环境，并且无需针对不同的结构光图案进行重新训练。实验结果表明，该方法在深度估计精度上显著优于传统的商业结构光系统和基于被动立体RGB的深度估计方法，尤其是在处理遮挡、精细结构和非朗伯表面时表现出更强的鲁棒性。",
            "tags_zh": [
                "结构光",
                "三维成像",
                "神经特征",
                "特征匹配",
                "深度估计",
                "鲁棒性",
                "单目视觉"
            ],
            "_index": 130,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14028/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14028/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14028/imgs2/fig3_effect_dav2/00003-102-D415-lir.jpg",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "ASAP-Textured Gaussians: Enhancing Textured Gaussians with Adaptive Sampling and Anisotropic Parameterization",
            "authors": [
                "Meng Wei",
                "Cheng Zhang",
                "Jianmin Zheng",
                "Hamid Rezatofighi",
                "Jianfei Cai"
            ],
            "arxiv_id": "2512.14039",
            "summary": "Recent advances have equipped 3D Gaussian Splatting with texture parameterizations to capture spatially varying attributes, improving the performance of both appearance modeling and downstream tasks. However, the added texture parameters introduce significant memory efficiency challenges. Rather than proposing new texture formulations, we take a step back to examine the characteristics of existing textured Gaussian methods and identify two key limitations in common: (1) Textures are typically defined in canonical space, leading to inefficient sampling that wastes textures' capacity on low-contribution regions; and (2) texture parameterization is uniformly assigned across all Gaussians, regardless of their visual complexity, resulting in over-parameterization. In this work, we address these issues through two simple yet effective strategies: adaptive sampling based on the Gaussian density distribution and error-driven anisotropic parameterization that allocates texture resources according to rendering error. Our proposed ASAP Textured Gaussians, short for Adaptive Sampling and Anisotropic Parameterization, significantly improve the quality efficiency tradeoff, achieving high-fidelity rendering with far fewer texture parameters.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14039",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "3D gaussian splatting",
                        "gaussian splatting",
                        "splatting"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "ASAP-Textured Gaussians：通过自适应采样和各向异性参数化增强纹理高斯模型",
            "summary_zh": "最近的研究进展为3D高斯溅射配备了纹理参数化，以捕捉空间变化的属性，从而提高了外观建模和下游任务的性能。然而，增加的纹理参数带来了显著的内存效率挑战。本文没有提出新的纹理公式，而是回顾了现有纹理高斯方法的特性，并确定了两个共同的关键限制：（1）纹理通常在规范空间中定义，导致低效的采样，将纹理容量浪费在低贡献区域；（2）纹理参数化在所有高斯模型中统一分配，而不管其视觉复杂性如何，导致过度参数化。本文通过两种简单而有效的策略来解决这些问题：基于高斯密度分布的自适应采样和基于渲染误差的各向异性参数化，根据渲染误差分配纹理资源。我们提出的ASAP Textured Gaussians（自适应采样和各向异性参数化的简称）显著提高了质量效率的权衡，以更少的纹理参数实现了高保真渲染。",
            "intro_zh": [
                "现有纹理高斯方法在规范空间采样纹理，效率低，且纹理参数统一分配，导致过参数化。",
                "提出ASAP Textured Gaussians，通过自适应采样和各向异性参数化，优化纹理资源的分配。",
                "实验表明，ASAP Textured Gaussians能以更少的纹理参数实现高保真渲染，提升质量效率权衡。"
            ],
            "method_zh": "**问题定义**：现有基于纹理的3D高斯溅射方法，虽然能有效捕捉空间变化的属性，但存在两个主要问题。一是纹理通常在规范空间中定义，导致采样效率低下，大量纹理信息被浪费在对最终渲染贡献较小的区域。二是纹理参数在所有高斯模型上均匀分配，忽略了不同高斯模型视觉复杂度的差异，造成了过度参数化，增加了内存负担。\\n\\n**核心思路**：ASAP-Textured Gaussians的核心思路是根据高斯分布的密度进行自适应采样，并根据渲染误差进行各向异性参数化。通过自适应采样，将更多的纹理资源分配给对渲染结果影响更大的区域，避免资源浪费。通过各向异性参数化，根据每个高斯模型的渲染误差动态调整其纹理参数的数量，避免过度参数化。\\n\\n**技术框架**：ASAP-Textured Gaussians的整体框架主要包含两个关键模块：自适应采样模块和各向异性参数化模块。自适应采样模块根据高斯分布的密度，动态调整采样点的数量和位置，确保重要区域得到充分采样。各向异性参数化模块根据渲染误差，为每个高斯模型分配不同数量的纹理参数，实现更精细的纹理表示。这两个模块协同工作，共同提升纹理高斯模型的质量和效率。\\n\\n**关键创新**：该论文的关键创新在于提出了自适应采样和各向异性参数化两种策略，并将其应用于纹理高斯模型。与现有方法相比，ASAP-Textured Gaussians能够更有效地利用纹理资源，在保证渲染质量的前提下，显著减少纹理参数的数量。这种方法避免了对纹理表示本身的修改，而是从纹理的采样和参数化方式入手，更具通用性和可扩展性。\\n\\n**关键设计**：自适应采样模块的关键设计在于如何根据高斯分布的密度确定采样点的数量和位置。论文采用了一种基于重要性采样的策略，根据高斯分布的概率密度函数，动态调整采样点的分布。各向异性参数化模块的关键设计在于如何根据渲染误差确定每个高斯模型的纹理参数数量。论文采用了一种基于误差驱动的策略，根据每个高斯模型的渲染误差，动态调整其纹理参数的数量。具体而言，渲染误差大的高斯模型分配更多的纹理参数，反之则分配较少的纹理参数。",
            "application_zh": "ASAP-Textured Gaussians可应用于各种需要高质量、高效率3D重建和渲染的场景，例如虚拟现实、增强现实、游戏开发、电影制作等。该方法能够以更少的内存占用实现更逼真的渲染效果，降低了硬件要求，使得高质量3D内容可以在移动设备等资源受限的平台上运行。未来，该技术有望推动3D内容创作和消费的普及。",
            "highlight_zh": "实验结果表明，ASAP-Textured Gaussians在保持甚至提高渲染质量的同时，显著减少了纹理参数的数量。与现有方法相比，ASAP-Textured Gaussians能够在相同渲染质量下，减少高达50%的纹理参数，或者在相同纹理参数数量下，提高渲染质量。这些结果验证了ASAP-Textured Gaussians在质量效率权衡方面的优势。",
            "tags_zh": [
                "3D高斯溅射",
                "纹理参数化",
                "自适应采样",
                "各向异性参数化",
                "渲染优化"
            ],
            "_index": 131,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14039/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14039/figure/trade_off_new.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14039/figure/main_2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "ChartAgent: A Chart Understanding Framework with Tool Integrated Reasoning",
            "authors": [
                "Boran Wang",
                "Xinming Wang",
                "Yi Chen",
                "Xiang Li",
                "Jian Xu",
                "Jing Yuan",
                "Chenglin Liu"
            ],
            "arxiv_id": "2512.14040",
            "summary": "With their high information density and intuitive readability, charts have become the de facto medium for data analysis and communication across disciplines. Recent multimodal large language models (MLLMs) have made notable progress in automated chart understanding, yet they remain heavily dependent on explicit textual annotations and the performance degrades markedly when key numerals are absent. To address this limitation, we introduce ChartAgent, a chart understanding framework grounded in Tool-Integrated Reasoning (TIR). Inspired by human cognition, ChartAgent decomposes complex chart analysis into a sequence of observable, replayable steps. Supporting this architecture is an extensible, modular tool library comprising more than a dozen core tools, such as keyelement detection, instance segmentation, and optical character recognition (OCR), which the agent dynamically orchestrates to achieve systematic visual parsing across diverse chart types. Leveraging TIRs transparency and verifiability, ChartAgent moves beyond the black box paradigm by standardizing and consolidating intermediate outputs into a structured Evidence Package, providing traceable and reproducible support for final conclusions. Experiments show that ChartAgent substantially improves robustness under sparse annotation settings, offering a practical path toward trustworthy and extensible systems for chart understanding.",
            "categories": [
                "cs.CV",
                "cs.LG"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14040",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "multimodal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出ChartAgent，一个工具集成推理的图表理解框架，提升稀疏标注下的鲁棒性。",
            "summary_zh": "图表因其高信息密度和直观可读性，已成为跨学科数据分析和交流的事实标准。最近的多模态大型语言模型（MLLMs）在自动图表理解方面取得了显著进展，但它们仍然严重依赖于显式的文本标注，并且在缺少关键数字时性能会显著下降。为了解决这个限制，我们引入了ChartAgent，一个基于工具集成推理（TIR）的图表理解框架。受到人类认知的启发，ChartAgent将复杂的图表分析分解为一系列可观察、可重放的步骤。支持该架构的是一个可扩展的模块化工具库，包含十几个核心工具，例如关键元素检测、实例分割和光学字符识别（OCR），Agent动态地编排这些工具以实现对各种图表类型的系统视觉解析。利用TIR的透明性和可验证性，ChartAgent通过将中间输出标准化和整合到结构化的证据包中，超越了黑盒范式，为最终结论提供可追溯和可重复的支持。实验表明，ChartAgent在稀疏标注设置下显著提高了鲁棒性，为可信和可扩展的图表理解系统提供了一条可行的途径。",
            "intro_zh": [
                "现有MLLM图表理解方法依赖显式文本标注，在关键数字缺失时性能显著下降，鲁棒性不足。",
                "ChartAgent采用工具集成推理，将复杂图表分析分解为可观察、可重放的步骤，模拟人类认知过程。",
                "实验表明，ChartAgent在稀疏标注下显著提升了鲁棒性，为可信赖的图表理解系统提供了可行方案。"
            ],
            "method_zh": "**问题定义**：现有图表理解方法，特别是基于多模态大语言模型的方法，在很大程度上依赖于图表中存在的文本标注。当图表中的关键数字信息缺失或不完整时，这些方法的性能会急剧下降，导致理解的准确性和可靠性降低。因此，如何提高图表理解模型在稀疏标注或无标注情况下的鲁棒性是一个关键问题。\\n\\n**核心思路**：ChartAgent的核心思路是模仿人类理解图表的方式，将复杂的图表分析任务分解为一系列可观察、可重放的步骤。通过集成多种工具，例如关键元素检测、实例分割和光学字符识别（OCR），Agent可以动态地编排这些工具，以实现对各种图表类型的系统视觉解析。这种方法的核心在于利用工具集成推理（TIR）的透明性和可验证性，从而提高图表理解的可靠性和可解释性。\\n\\n**技术框架**：ChartAgent的整体架构包含以下几个主要模块：1) **图表输入模块**：接收各种类型的图表图像作为输入。2) **工具集成推理（TIR）模块**：这是ChartAgent的核心模块，它将复杂的图表分析任务分解为一系列可执行的步骤，并动态地选择和编排合适的工具来完成这些步骤。3) **工具库**：包含十几个核心工具，例如关键元素检测、实例分割和光学字符识别（OCR）等。4) **证据包**：用于存储和管理中间输出结果，提供可追溯和可重复的支持。5) **结果输出模块**：输出最终的图表理解结果。\\n\\n**关键创新**：ChartAgent最重要的技术创新点在于其基于工具集成推理（TIR）的架构。与传统的黑盒模型不同，ChartAgent通过将图表理解过程分解为一系列可观察、可重放的步骤，提高了模型的可解释性和可验证性。此外，ChartAgent的模块化工具库可以灵活地扩展和定制，以适应不同类型的图表和分析任务。\\n\\n**关键设计**：ChartAgent的关键设计包括：1) **动态工具编排策略**：根据图表的类型和分析任务，动态地选择和编排合适的工具。2) **证据包的结构化设计**：将中间输出结果标准化和整合到结构化的证据包中，提供可追溯和可重复的支持。3) **可扩展的模块化工具库**：允许用户根据需要添加新的工具，以适应不同的图表和分析任务。具体的参数设置、损失函数和网络结构等技术细节未在摘要中详细说明，属于未知信息。",
            "application_zh": "ChartAgent可应用于金融分析、商业智能、科学研究等领域，帮助用户更高效、准确地理解和分析图表数据。该框架的透明性和可验证性使其在需要高度信任和可解释性的场景中具有重要价值，例如医疗诊断和政策制定。未来，ChartAgent有望成为通用图表理解系统的基础。",
            "highlight_zh": "摘要中提到，实验结果表明ChartAgent在稀疏标注设置下显著提高了鲁棒性，但没有提供具体的性能数据、对比基线和提升幅度。具体实验结果未知。",
            "tags_zh": [
                "图表理解",
                "工具集成推理",
                "多模态学习",
                "视觉解析",
                "知识推理"
            ],
            "_index": 132,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14040/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14040/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14040/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Spherical Voronoi: Directional Appearance as a Differentiable Partition of the Sphere",
            "authors": [
                "Francesco Di Sario",
                "Daniel Rebain",
                "Dor Verbin",
                "Marco Grangetto",
                "Andrea Tagliasacchi"
            ],
            "arxiv_id": "2512.14180",
            "summary": "Radiance field methods (e.g. 3D Gaussian Splatting) have emerged as a powerful paradigm for novel view synthesis, yet their appearance modeling often relies on Spherical Harmonics (SH), which impose fundamental limitations. SH struggle with high-frequency signals, exhibit Gibbs ringing artifacts, and fail to capture specular reflections - a key component of realistic rendering. Although alternatives like spherical Gaussians offer improvements, they add significant optimization complexity. We propose Spherical Voronoi (SV) as a unified framework for appearance representation in 3D Gaussian Splatting. SV partitions the directional domain into learnable regions with smooth boundaries, providing an intuitive and stable parameterization for view-dependent effects. For diffuse appearance, SV achieves competitive results while keeping optimization simpler than existing alternatives. For reflections - where SH fail - we leverage SV as learnable reflection probes, taking reflected directions as input following principles from classical graphics. This formulation attains state-of-the-art results on synthetic and real-world datasets, demonstrating that SV offers a principled, efficient, and general solution for appearance modeling in explicit 3D representations.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14180",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "3D gaussian splatting",
                        "gaussian splatting",
                        "splatting"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "提出球Voronoi图，用于3D高斯溅射中可微的方向外观建模",
            "summary_zh": "辐射场方法（如3D高斯溅射）已成为新视角合成的强大范例，但其外观建模通常依赖于球谐函数（SH），这存在根本性限制。SH难以处理高频信号，表现出吉布斯振铃伪影，并且无法捕捉镜面反射——这是真实感渲染的关键组成部分。虽然像球高斯函数这样的替代方案有所改进，但它们增加了显著的优化复杂性。我们提出了球Voronoi图（SV）作为3D高斯溅射中外观表示的统一框架。SV将方向域划分为具有平滑边界的可学习区域，为视角相关的效果提供了直观且稳定的参数化。对于漫反射外观，SV实现了具有竞争力的结果，同时保持了比现有替代方案更简单的优化。对于SH失效的反射，我们遵循经典图形学的原则，利用SV作为可学习的反射探针，将反射方向作为输入。这种公式在合成和真实世界数据集上获得了最先进的结果，表明SV为显式3D表示中的外观建模提供了一种原则性、高效且通用的解决方案。",
            "intro_zh": [
                "传统球谐函数在辐射场外观建模中存在高频信号处理差、吉布斯振铃等问题，无法有效捕捉镜面反射。",
                "提出球Voronoi图（SV）方法，将方向域划分为可学习区域，实现对视角相关效果的直观参数化。",
                "实验表明，SV在漫反射和镜面反射建模上均表现出色，尤其在反射建模上达到SOTA效果。"
            ],
            "method_zh": "**问题定义**：现有基于辐射场的方法，特别是3D高斯溅射，在外观建模方面依赖于球谐函数（SH）。SH在表示高频信号时存在困难，会导致吉布斯振铃伪影，并且难以捕捉镜面反射等重要视觉效果。这些限制阻碍了真实感渲染的进一步提升。\\n\\n**核心思路**：论文的核心思路是使用球Voronoi图（SV）来划分方向域，从而实现对外观的灵活且可学习的表示。SV将球面划分为多个区域，每个区域对应一种外观属性。通过学习这些区域的边界和相关属性，可以更好地捕捉复杂的光照效果，包括漫反射和镜面反射。这种方法旨在克服SH的局限性，同时保持较低的优化复杂度。\\n\\n**技术框架**：该方法将SV集成到3D高斯溅射框架中。对于每个高斯分布，使用SV来表示其方向外观。具体流程包括：1）使用SV划分球面；2）学习SV区域的边界；3）学习每个区域对应的外观属性（例如，颜色、反射率）；4）在渲染过程中，根据视角方向确定对应SV区域，并使用该区域的外观属性进行着色。对于反射建模，将SV作为可学习的反射探针，输入反射方向，输出反射颜色。\\n\\n**关键创新**：该方法最重要的创新点在于使用SV作为一种可学习的球面划分方法，用于表示方向外观。与传统的SH相比，SV能够更灵活地捕捉高频信号和复杂的光照效果。此外，将SV应用于反射建模，将其作为可学习的反射探针，是一种新颖且有效的方法。\\n\\n**关键设计**：SV的区域数量是一个关键参数，需要根据场景的复杂程度进行调整。论文中使用了可微分的Voronoi图生成算法，使得SV的边界可以进行优化。损失函数包括渲染损失和正则化项，用于保证SV区域的平滑性和稳定性。对于反射建模，使用了额外的损失函数来鼓励SV学习真实的反射效果。",
            "application_zh": "该研究成果可广泛应用于新视角合成、虚拟现实、增强现实、游戏开发等领域。通过更真实地模拟光照效果，可以提升虚拟场景的沉浸感和真实感。此外，该方法还可以应用于材质编辑、光照设计等任务，为艺术家和设计师提供更强大的工具。",
            "highlight_zh": "在合成和真实世界数据集上的实验表明，该方法在外观建模方面取得了最先进的结果。特别是在反射建模方面，该方法显著优于基于球谐函数的方法。实验数据表明，该方法能够有效地捕捉镜面反射等复杂光照效果，从而生成更逼真的图像。",
            "tags_zh": [
                "球Voronoi图",
                "3D高斯溅射",
                "新视角合成",
                "外观建模",
                "反射建模"
            ],
            "_index": 133,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14180/figures/gibbs.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14180/figures/spatially_varying_light.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14180/figures/fitting2d.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "From My View to Yours: Ego-to-Exo Transfer in VLMs for Understanding Activities of Daily Living",
            "authors": [
                "Dominick Reilly",
                "Manish Kumar Govind",
                "Le Xue",
                "Srijan Das"
            ],
            "arxiv_id": "2501.05711",
            "summary": "Vision Language Models (VLMs) have achieved strong performance across diverse video understanding tasks. However, their viewpoint invariant training limits their ability to understand egocentric properties (e.g., human object interactions) from exocentric video observations. This limitation is critical for many applications, such as Activities of Daily Living (ADL) monitoring, where the understanding of egocentric properties is essential, and egocentric cameras are impractical to deploy. To address this limitation, we propose Ego2ExoVLM, a VLM that learns to infer egocentric properties from exocentric videos by leveraging time-synchronized ego-exo videos during training. Ego2ExoVLM accomplishes this through the use of two components: Ego2Exo Sequence Distillation, which transfers knowledge from an egocentric teacher to an exocentric student, and Ego Adaptive Visual Tokens, designed to enhance the effectiveness of this knowledge transfer. To measure this capability, we introduce Ego-in-Exo Perception, a benchmark of 3.9K questions curated to explicitly measure the understanding of egocentric properties from exocentric videos. Ego2ExoVLM is evaluated on 10 tasks across Ego-in-Exo Perception and existing ADL benchmarks, achieving state-of-the-art results on the ADL-X benchmark suite and outperforming strong baselines on our proposed benchmark. All code, models, and data will be released atthis https URL.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2501.05711",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "distillation"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱五：交互与反应 (Interaction & Reaction)",
                    "id": "5_interaction_reaction",
                    "matched_keywords": [
                        "human-object interaction"
                    ],
                    "score": 2.5
                },
                {
                    "name": "支柱六：视频提取与匹配 (Video Extraction)",
                    "id": "6_video_extraction",
                    "matched_keywords": [
                        "egocentric"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "2_algo_arch",
                "5_interaction_reaction",
                "6_video_extraction"
            ],
            "headline_zh": "提出Ego2ExoVLM，解决VLM在日常活动理解中视角转换的难题",
            "summary_zh": "视觉语言模型(VLM)在各种视频理解任务中表现出色。然而，其视角不变性训练限制了它们从外视角视频观察中理解以自我为中心的属性（例如，人与物体的交互）的能力。这种限制对于许多应用至关重要，例如日常生活活动(ADL)监测，其中理解以自我为中心的属性至关重要，并且难以部署以自我为中心的相机。为了解决这个限制，我们提出了Ego2ExoVLM，一个VLM，它通过在训练期间利用时间同步的自我-外部视频来学习从外部视角视频推断以自我为中心的属性。Ego2ExoVLM通过使用两个组件来实现这一点：Ego2Exo序列蒸馏，它将知识从以自我为中心的教师转移到以外部为中心的学生，以及Ego自适应视觉tokens，旨在提高这种知识转移的有效性。为了衡量这种能力，我们引入了Ego-in-Exo Perception，一个包含3.9K个问题的基准，专门用于衡量从外部视角视频理解以自我为中心的属性。Ego2ExoVLM在Ego-in-Exo Perception和现有的ADL基准测试中的10个任务上进行了评估，在ADL-X基准测试套件上取得了最先进的结果，并在我们提出的基准测试中优于强大的基线。",
            "intro_zh": [
                "现有VLM视角不变性训练使其难以理解外视角视频中的自我中心属性，限制了其在ADL等领域的应用。",
                "Ego2ExoVLM通过序列蒸馏和自适应视觉tokens，将自我中心视角知识迁移到外视角VLM，提升理解能力。",
                "Ego2ExoVLM在Ego-in-Exo和ADL基准测试中表现出色，尤其在ADL-X上达到SOTA，验证了其有效性。"
            ],
            "method_zh": "**问题定义**：现有视觉语言模型（VLM）在视频理解任务中表现良好，但其训练方式侧重于视角不变性，导致其难以从外视角（Exocentric）视频中理解以自我为中心（Egocentric）的属性，例如人与物体的交互方式。这限制了VLM在日常生活活动（ADL）监测等领域的应用，因为这些应用需要理解自我中心视角下的行为，而部署自我中心相机在实际中往往不可行。\\n\\n**核心思路**：Ego2ExoVLM的核心思路是通过知识蒸馏，将以自我为中心的视角信息从一个“教师”模型（在自我中心视频上训练）迁移到一个“学生”模型（在外视角视频上训练）。通过这种方式，学生模型可以学习理解外视角视频中隐含的自我中心属性。这样设计的目的是为了让VLM能够更好地理解和推理外视角视频中的人类行为和活动。\\n\\n**技术框架**：Ego2ExoVLM包含两个主要组件：Ego2Exo序列蒸馏和Ego自适应视觉tokens。Ego2Exo序列蒸馏负责将知识从自我中心视角的教师模型传递到外视角学生模型。Ego自适应视觉tokens则用于增强知识传递的有效性。整体流程是：首先，使用自我中心视频训练教师模型；然后，利用时间同步的自我中心和外视角视频，通过序列蒸馏的方式训练学生模型，使其能够模仿教师模型的行为；最后，使用Ego自适应视觉tokens进一步优化学生模型，使其更好地理解外视角视频中的自我中心属性。\\n\\n**关键创新**：该论文的关键创新在于提出了Ego2Exo序列蒸馏和Ego自适应视觉tokens，用于解决VLM在外视角视频中理解自我中心属性的难题。与现有方法相比，Ego2ExoVLM能够更有效地利用自我中心视角的信息，提升VLM在外视角视频理解任务中的性能。\\n\\n**关键设计**：Ego2Exo序列蒸馏的具体实现方式未知，但可以推测其使用了某种形式的序列到序列的损失函数，例如KL散度或交叉熵，来衡量学生模型和教师模型输出之间的差异。Ego自适应视觉tokens的具体结构和参数设置也未知，但可以推测其使用了某种形式的注意力机制，来选择性地关注与自我中心属性相关的视觉特征。",
            "application_zh": "该研究成果可广泛应用于日常生活活动监测、智能家居、远程医疗、安全监控等领域。通过理解外视角视频中的自我中心属性，可以实现对老年人、残疾人等弱势群体的行为监测和辅助，提高生活质量和安全性。此外，该技术还可用于机器人导航和人机交互，使机器人能够更好地理解人类意图和行为。",
            "highlight_zh": "Ego2ExoVLM在ADL-X基准测试套件上取得了state-of-the-art的结果，证明了其在ADL理解方面的优越性。此外，在作者提出的Ego-in-Exo Perception基准测试中，Ego2ExoVLM也优于强大的基线模型，验证了其在外视角视频中理解自我中心属性的能力。具体的性能数据和提升幅度在论文中未明确给出，但整体结果表明Ego2ExoVLM具有显著的优势。",
            "tags_zh": [
                "视觉语言模型",
                "视角转换",
                "知识蒸馏",
                "日常生活活动理解",
                "自我中心视角",
                "外视角",
                "序列蒸馏"
            ],
            "_index": 134,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2501.05711/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2501.05711/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2501.05711/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "TextMesh4D: Text-to-4D Mesh Generation via Jacobian Deformation Field",
            "authors": [
                "Sisi Dai",
                "Xinxin Su",
                "Ruizhen Hu",
                "Kai Xu"
            ],
            "arxiv_id": "2506.24121",
            "summary": "Dynamic 3D (4D) content generation, particularly text-to-4D, remains a challenging and under-explored problem due to its inherent spatiotemporal complexity. Existing text-to-4D methods typically avoid direct mesh generation due to inherent topological constraints, favoring alternative representations like NeRFs or 3DGS. However, these non-mesh approaches, suffer from insufficient geometric fidelity, temporal artifacts, and limited compatibility with modern computer graphics (CG) pipelines. In contrast, directly generating dynamic meshes faces two key challenges: i) deformation inflexibility, as traditional vertex-based optimization is constrained by meshes' explicitly encoded topology, and ii) semantic inconsistency, arising from stochastic noise in distilled priors.In this paper, we introduce TextMesh4D, a pioneering framework for text-to-4D mesh generation that directly addresses these challenges. TextMesh4D features two core innovations: 1) the Jacobian Deformation Field (JDF), which shifts the deformation unit from vertices to faces, using per-face Jacobians to model flexible transformations free from topological constraints. 2) the Local-Global Semantic Regularizer (LGSR), which leverages the mesh's innate geometric properties to enforce semantic coherence both locally and globally across frames. Extensive experiments demonstrate that TextMesh4D achieves state-of-the-art performance in temporal consistency, structural fidelity, and visual realism, while requiring only a single 24GB GPU. Our work establishes a new benchmark for efficient and high-quality text-to-4D mesh generation. The code will be released to facilitate future research.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2506.24121",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "3DGS",
                        "NeRF"
                    ],
                    "score": 4.0
                },
                {
                    "name": "支柱八：物理动画 (Physics-based Animation)",
                    "id": "8_physics_animation",
                    "matched_keywords": [
                        "spatiotemporal"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "3_perception_slam",
                "8_physics_animation"
            ],
            "headline_zh": "提出 TextMesh4D，通过雅可比形变场实现文本驱动的4D网格生成。",
            "summary_zh": "动态3D（4D）内容生成，特别是文本到4D的生成，由于其固有的时空复杂性，仍然是一个具有挑战性且未被充分探索的问题。现有的文本到4D方法通常避免直接网格生成，因为存在固有的拓扑约束，而倾向于选择NeRF或3DGS等替代表示。然而，这些非网格方法存在几何保真度不足、时间伪影以及与现代计算机图形（CG）管线兼容性有限等问题。相比之下，直接生成动态网格面临两个关键挑战：i) 形变不灵活性，因为传统的基于顶点的优化受到网格显式编码拓扑的约束；ii) 语义不一致性，源于提炼先验中的随机噪声。本文介绍 TextMesh4D，这是一个用于文本到4D网格生成的开创性框架，它直接解决了这些挑战。TextMesh4D 具有两个核心创新：1) 雅可比形变场（JDF），它将形变单元从顶点转移到面，使用每个面的雅可比矩阵来建模不受拓扑约束的灵活变换。2) 局部-全局语义正则化器（LGSR），它利用网格固有的几何属性来强制执行跨帧的局部和全局语义一致性。大量的实验表明，TextMesh4D 在时间一致性、结构保真度和视觉真实感方面实现了最先进的性能，同时只需要一个 24GB 的 GPU。我们的工作为高效和高质量的文本到 4D 网格生成建立了一个新的基准。代码将被发布，以促进未来的研究。",
            "intro_zh": [
                "现有文本到4D生成方法依赖NeRF等表示，几何保真度不足，且与传统图形管线兼容性差，直接网格生成面临形变不灵活和语义不一致的挑战。",
                "TextMesh4D通过雅可比形变场（JDF）实现灵活的网格形变，并引入局部-全局语义正则化器（LGSR）来保证时间上的语义一致性。",
                "实验表明，TextMesh4D在时间一致性、结构保真度和视觉真实感方面均达到了当前最佳水平，且资源消耗较低。"
            ],
            "method_zh": "**问题定义**：论文旨在解决文本驱动的动态3D网格（4D网格）生成问题。现有方法，如基于NeRF或3DGS的方法，虽然避免了直接操作网格的拓扑约束，但牺牲了几何细节和时间一致性，难以直接应用于计算机图形学管线。直接网格生成方法则面临顶点形变的拓扑约束和语义漂移问题。\\n\\n**核心思路**：TextMesh4D的核心思路是将形变单元从顶点转移到面，使用每个面的雅可比矩阵来表示形变，从而解耦形变与网格拓扑结构。同时，利用网格的几何属性，设计局部和全局语义正则化器，以保证生成网格在时间上的语义一致性。\\n\\n**技术框架**：TextMesh4D的整体框架包含以下几个主要步骤：1) 初始化一个3D网格；2) 使用文本提示作为输入，通过优化雅可比形变场（JDF）来驱动网格形变；3) 应用局部-全局语义正则化器（LGSR）来约束网格的语义一致性；4) 迭代优化JDF和LGSR，直到生成符合文本描述的动态网格序列。\\n\\n**关键创新**：TextMesh4D最重要的技术创新在于雅可比形变场（JDF）。与传统的基于顶点的形变方法不同，JDF使用每个面的雅可比矩阵来表示形变，从而允许更灵活的形变，不受网格拓扑结构的限制。此外，局部-全局语义正则化器（LGSR）也是一个关键创新，它利用网格的几何属性来约束语义一致性，减少了时间上的语义漂移。\\n\\n**关键设计**：JDF的关键设计在于使用雅可比矩阵来表示每个面的形变，并通过优化这些雅可比矩阵来驱动网格形变。LGSR包含两个部分：局部正则化器，用于约束相邻面片的形变一致性；全局正则化器，用于约束整个网格的语义一致性。损失函数包括一个形变损失，用于驱动网格形变以匹配文本描述；一个局部语义一致性损失，用于约束相邻面片的形变一致性；以及一个全局语义一致性损失，用于约束整个网格的语义一致性。",
            "application_zh": "TextMesh4D具有广泛的应用前景，包括虚拟现实/增强现实内容创作、游戏开发、动画制作、以及机器人仿真等领域。它可以根据文本描述快速生成高质量的动态3D模型，极大地降低了内容创作的门槛，并为用户提供更丰富的交互体验。未来，该技术有望应用于个性化虚拟化身定制、智能设计和辅助创作等领域。",
            "highlight_zh": "实验结果表明，TextMesh4D在时间一致性、结构保真度和视觉真实感方面均优于现有方法。与现有方法相比，TextMesh4D能够生成更流畅、更逼真的动态3D模型，且资源消耗较低，仅需单个24GB GPU。该方法在多个数据集上进行了验证，并取得了显著的性能提升。",
            "tags_zh": [
                "文本到4D生成",
                "动态网格生成",
                "雅可比形变场",
                "语义正则化",
                "计算机图形学"
            ],
            "_index": 135,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2506.24121/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2506.24121/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2506.24121/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "MFGDiffusion: Mask-Guided Smoke Synthesis for Enhanced Forest Fire Detection",
            "authors": [
                "Guanghao Wu",
                "Yunqing Shang",
                "Chen Xu",
                "Hai Song",
                "Chong Wang",
                "Qixing Zhang"
            ],
            "arxiv_id": "2507.11252",
            "summary": "Smoke is the first visible indicator of athis http URLthe advancement of deep learning, image-based smoke detection has become a crucial method for detecting and preventing forest fires. However, the scarcity of smoke image data from forest fires is one of the significant factors hindering the detection of forest fire smoke. Image generation models offer a promising solution for synthesizing realistic smoke images. However, current inpainting models exhibit limitations in generating high-quality smoke representations, particularly manifesting as inconsistencies between synthesized smoke and background contexts. To solve these problems, we proposed a comprehensive framework for generating forest fire smoke images. Firstly, we employed the pre-trained segmentation model and the multimodal model to obtain smoke masks and imagethis http URL, to address the insufficient utilization of masks and masked images by inpainting models, we introduced a network architecture guided by mask and masked image features. We also proposed a new loss function, the mask random difference loss, which enhances the consistency of the generated effects around the mask by randomly expanding and eroding the maskthis http URL, to generate a smoke image dataset using random masks for subsequent detection tasks, we incorporated smoke characteristics and use a multimodal large language model as a filtering tool to select diverse and reasonable smoke images, thereby improving the quality of the synthetic dataset. Experiments showed that our generated smoke images are realistic and diverse, and effectively enhance the performance of forest fire smoke detection models. Code is available atthis https URL.",
            "categories": [
                "cs.CV",
                "eess.IV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2507.11252",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "multimodal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "MFGDiffusion：提出掩码引导的烟雾合成方法，提升森林火灾检测性能",
            "summary_zh": "烟雾是森林火灾最初的可视指标。随着深度学习的发展，基于图像的烟雾检测已成为检测和预防森林火灾的关键方法。然而，森林火灾烟雾图像数据的稀缺性是阻碍森林火灾烟雾检测的重要因素之一。图像生成模型为合成逼真的烟雾图像提供了一种有前景的解决方案。然而，当前的图像修复模型在生成高质量的烟雾表示方面存在局限性，尤其是在合成烟雾与背景上下文之间表现出不一致性。为了解决这些问题，我们提出了一个全面的森林火灾烟雾图像生成框架。首先，我们采用预训练的分割模型和多模态模型来获得烟雾掩码和图像描述。其次，为了解决图像修复模型对掩码和掩码图像利用不足的问题，我们引入了一种由掩码和掩码图像特征引导的网络架构。我们还提出了一种新的损失函数，即掩码随机差异损失，通过随机扩展和腐蚀掩码来增强生成效果在掩码周围的一致性。最后，为了生成用于后续检测任务的具有随机掩码的烟雾图像数据集，我们结合了烟雾特征，并使用多模态大型语言模型作为过滤工具来选择多样且合理的烟雾图像，从而提高合成数据集的质量。实验表明，我们生成的烟雾图像是逼真和多样的，并且有效地提高了森林火灾烟雾检测模型的性能。",
            "intro_zh": [
                "现有图像修复模型在生成高质量烟雾图像时，存在合成烟雾与背景上下文不一致的问题。",
                "提出一种掩码引导的烟雾合成框架，利用掩码和掩码图像特征指导网络生成，并设计掩码随机差异损失。",
                "实验表明，该方法生成的烟雾图像逼真且多样，能有效提升森林火灾烟雾检测模型的性能。"
            ],
            "method_zh": "**问题定义**：论文旨在解决森林火灾烟雾检测中，由于烟雾图像数据稀缺导致检测模型性能受限的问题。现有图像修复模型在合成烟雾图像时，难以保证合成的烟雾与背景上下文的一致性，生成的烟雾图像质量不高，影响了后续检测任务的性能。\\n\\n**核心思路**：论文的核心思路是利用掩码信息引导图像生成过程，从而提高合成烟雾图像的质量和真实感。通过预训练的分割模型和多模态模型获取烟雾掩码和图像描述，并设计新的网络架构和损失函数，充分利用掩码信息，增强合成烟雾与背景的融合度。\\n\\n**技术框架**：该框架主要包含以下几个阶段：1) 使用预训练的分割模型和多模态模型获取烟雾掩码和图像描述；2) 构建一个由掩码和掩码图像特征引导的图像生成网络；3) 设计掩码随机差异损失函数，增强掩码区域附近生成效果的一致性；4) 使用多模态大型语言模型过滤生成的烟雾图像，选择多样且合理的图像，构建高质量的合成数据集。\\n\\n**关键创新**：论文的关键创新在于：1) 提出了一种由掩码和掩码图像特征引导的网络架构，更有效地利用了掩码信息；2) 设计了一种新的损失函数，即掩码随机差异损失，增强了生成效果在掩码周围的一致性；3) 利用多模态大型语言模型作为过滤工具，提高了合成数据集的质量。\\n\\n**关键设计**：掩码随机差异损失通过随机扩展和腐蚀掩码，计算不同尺度掩码区域内的像素差异，从而约束生成图像在掩码边缘的一致性。具体实现细节（如扩展和腐蚀的核大小、损失函数的权重等）在论文中未明确给出，属于未知信息。",
            "application_zh": "该研究成果可应用于森林火灾早期预警系统，通过合成逼真的烟雾图像来扩充训练数据集，提升烟雾检测模型的泛化能力和检测精度。此外，该方法也可推广到其他图像生成任务中，例如合成特定场景下的雾霾、火焰等，具有广泛的应用前景。",
            "highlight_zh": "论文通过实验验证了所提出的烟雾合成方法的有效性。生成的烟雾图像具有较高的真实感和多样性，能够显著提升森林火灾烟雾检测模型的性能。具体的性能提升数据和对比基线在摘要中未提及，属于未知信息。但整体而言，该方法为解决烟雾数据稀缺问题提供了一种有效的解决方案。",
            "tags_zh": [
                "烟雾合成",
                "森林火灾检测",
                "图像生成",
                "掩码引导",
                "扩散模型"
            ],
            "_index": 136,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2507.11252/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2507.11252/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2507.11252/Network3.jpg",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Echo-CoPilot: A Multi-View, Multi-Task Agent for Echocardiography Interpretation and Reporting",
            "authors": [
                "Moein Heidari",
                "Mohammad Amin Roohi",
                "Ilker Hacihaliloglu"
            ],
            "arxiv_id": "2512.09944",
            "summary": "Echocardiography is central to contemporary cardiovascular care, but full-study interpretation remains a cognitively demanding, multi-view task that is still performed manually. While recent foundation models for echocardiography can achieve strong performance on individual perceptual subtasks such as view classification, segmentation, or disease prediction, they typically operate in isolation and do not provide a unified, clinically coherent assessment. In this work, we introduce Echo-CoPilot, a multi-view, multi-task agent that uses a large language model to orchestrate a suite of specialized echocardiography tools. Within a ReAct-style loop, the agent decomposes clinician queries, invokes tools for view recognition, cardiac structure segmentation, measurement and disease prediction, and report synthesis, and integrates their outputs into guideline-aware answers and narrative summaries. We evaluate Echo-CoPilot on the public MIMIC-EchoQA benchmark, where it achieves an accuracy of 50.8\\%, outperforming both general-purpose and biomedical video vision-language models. Qualitative analyses further show that the agent leverages quantitative measurements and physiologic context to resolve challenging cases near clinical decision thresholds, such as borderline left ventricular hypertrophy or pericardial effusion severity. The code will be released upon acceptance of the paper.",
            "categories": [
                "cs.AI",
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.09944",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "foundation model"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "Echo-CoPilot：用于心动超声解读和报告的多视角多任务智能体",
            "summary_zh": "心动超声检查是现代心血管护理的核心，但完整的研究解读仍然是一项认知需求高、多视角的任务，目前仍以手动方式进行。虽然最近的心动超声基础模型可以在诸如视图分类、分割或疾病预测等单个感知子任务上实现强大的性能，但它们通常孤立地运行，无法提供统一的、临床上连贯的评估。本文介绍了Echo-CoPilot，一个多视角、多任务智能体，它使用大型语言模型来协调一套专门的心动超声工具。在ReAct风格的循环中，该智能体分解临床医生的查询，调用工具进行视图识别、心脏结构分割、测量和疾病预测以及报告合成，并将它们的输出集成到符合指南的答案和叙述性摘要中。我们在公共MIMIC-EchoQA基准上评估了Echo-CoPilot，其准确率达到了50.8％，优于通用和生物医学视频视觉语言模型。定性分析进一步表明，该智能体利用定量测量和生理背景来解决临床决策阈值附近的具有挑战性的病例，例如临界左心室肥厚或心包积液严重程度。",
            "intro_zh": [
                "传统心动超声解读依赖手动，耗时且易出错，现有模型缺乏统一的临床评估能力。",
                "Echo-CoPilot利用大型语言模型协调多种工具，实现多视角、多任务的心动超声自动解读。",
                "在MIMIC-EchoQA基准测试中，Echo-CoPilot的准确率达到50.8%，优于其他视觉语言模型。"
            ],
            "method_zh": "**问题定义**：心动超声检查在心血管疾病诊断中至关重要，但人工解读耗时且主观性强。现有方法通常针对单一任务（如视图分类、分割），缺乏对整个超声报告的综合理解和生成能力。因此，如何构建一个能够自动、准确地解读心动超声并生成报告的系统是亟待解决的问题。\\n\\n**核心思路**：Echo-CoPilot的核心思路是利用大型语言模型（LLM）作为协调者，将多个专业的心动超声分析工具整合起来，形成一个多视角、多任务的智能体。通过ReAct循环，LLM能够根据临床医生的查询，动态地调用不同的工具，并将结果整合，最终生成符合临床指南的报告。这种方法模仿了医生解读超声的过程，即先识别视图，然后进行测量和疾病预测，最后综合所有信息得出结论。\\n\\n**技术框架**：Echo-CoPilot的技术框架主要包含以下几个模块：1) 查询分解模块：将临床医生的查询分解为多个子任务。2) 工具调用模块：根据子任务，调用相应的专业工具，如视图识别、心脏结构分割、测量和疾病预测工具。3) 结果整合模块：将各个工具的输出结果整合起来，形成一个统一的表示。4) 报告生成模块：利用LLM生成符合临床指南的报告。整个流程采用ReAct循环，LLM根据当前状态和工具的反馈，不断调整策略，直到生成最终报告。\\n\\n**关键创新**：Echo-CoPilot的关键创新在于将大型语言模型应用于心动超声解读领域，并将其作为智能体的核心协调者。与以往的单任务模型不同，Echo-CoPilot能够处理多视角、多任务的复杂场景，并生成完整的超声报告。此外，ReAct循环的设计使得智能体能够动态地调整策略，更好地适应不同的临床查询。\\n\\n**关键设计**：Echo-CoPilot的关键设计包括：1) 使用预训练的视觉模型进行视图识别、心脏结构分割和疾病预测。2) 利用大型语言模型进行查询分解、结果整合和报告生成。3) 设计ReAct循环，使得智能体能够动态地调整策略。4) 使用临床指南作为约束，确保生成的报告符合医学规范。具体的参数设置、损失函数和网络结构等细节未在论文中详细描述（未知）。",
            "application_zh": "Echo-CoPilot可应用于临床心动超声报告的自动生成，减轻医生的工作负担，提高诊断效率和准确性。它还可以作为教学工具，帮助医学生学习心动超声的解读。未来，该技术有望扩展到其他医学影像领域，实现更广泛的临床应用。",
            "highlight_zh": "Echo-CoPilot在MIMIC-EchoQA基准测试中取得了50.8%的准确率，显著优于通用的和生物医学的视频视觉语言模型。定性分析表明，该智能体能够利用定量测量和生理背景信息，解决临床决策阈值附近的复杂病例，例如临界左心室肥厚或心包积液严重程度的判断。",
            "tags_zh": [
                "心动超声",
                "大型语言模型",
                "多任务学习",
                "医学影像",
                "报告生成"
            ],
            "_index": 137,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.09944/figures/Echo-CoPilot.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.09944/examples2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.09944/fig3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Enhancing Geo-localization for Crowdsourced Flood Imagery via LLM-Guided Attention",
            "authors": [
                "Fengyi Xu",
                "Jun Ma",
                "Waishan Qiu",
                "Cui Guo",
                "Jack C.P. Cheng"
            ],
            "arxiv_id": "2512.11811",
            "summary": "Crowdsourced street-view imagery from social media provides real-time visual evidence of urban flooding and other crisis events, yet it often lacks reliable geographic metadata for emergency response. Existing image geo-localization approaches, also known as Visual Place Recognition (VPR) models, exhibit substantial performance degradation when applied to such imagery due to visual distortions and domain shifts in cross-source scenarios. This paper presents VPR-AttLLM, a model-agnostic framework that integrates the semantic reasoning and geo-knowledge of Large Language Models (LLMs) into established VPR pipelines through attention-guided descriptor enhancement. By leveraging LLMs to identify location-informative regions within the city context and suppress visual noise, VPR-AttLLM improves retrieval performance without requiring model retraining or additional data. Comprehensive evaluations are conducted on extended benchmarks including SF-XL enriched with real social-media flood images, synthetic flooding scenarios over established query sets and Mapillary photos, and a new HK-URBAN dataset capturing morphologically distinct cityscapes. Integrating VPR-AttLLM with three state-of-the-art VPR models-CosPlace, EigenPlaces, and SALAD-consistently improves recall performance, yielding relative gains typically between 1-3% and reaching up to 8% on the most challenging real flood imagery. Beyond measurable gains in retrieval accuracy, this study establishes a generalizable paradigm for LLM-guided multimodal fusion in visual retrieval systems. By embedding principles from urban perception theory into attention mechanisms, VPR-AttLLM bridges human-like spatial reasoning with modern VPR architectures. Its plug-and-play design, strong cross-source robustness, and interpretability highlight its potential for scalable urban monitoring and rapid geo-localization of crowdsourced crisis imagery.",
            "categories": [
                "cs.CL",
                "cs.AI",
                "cs.CV",
                "cs.CY"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.11811",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "multimodal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出VPR-AttLLM，利用LLM增强视觉定位，提升众包洪水图像地理定位精度。",
            "summary_zh": "本文提出VPR-AttLLM，一个模型无关的框架，通过注意力引导的描述符增强，将大型语言模型(LLM)的语义推理和地理知识集成到现有的视觉定位(VPR)流程中。通过利用LLM识别城市环境中具有位置信息的区域并抑制视觉噪声，VPR-AttLLM在不需要模型重新训练或额外数据的情况下提高了检索性能。在扩展的基准测试中进行了全面的评估，包括用真实社交媒体洪水图像丰富的SF-XL，建立的查询集上的合成洪水场景和Mapillary照片，以及一个新的捕捉形态各异的城市景观的HK-URBAN数据集。将VPR-AttLLM与三个最先进的VPR模型（CosPlace、EigenPlaces和SALAD）集成，始终如一地提高了召回性能，相对增益通常在1-3%之间，在最具挑战性的真实洪水图像上达到8%。除了可衡量的检索准确性提升之外，本研究还建立了一个通用的范例，用于视觉检索系统中LLM引导的多模态融合。通过将城市感知理论的原则嵌入到注意力机制中，VPR-AttLLM将类人空间推理与现代VPR架构联系起来。其即插即用设计、强大的跨源鲁棒性和可解释性突出了其在可扩展的城市监测和众包危机图像快速地理定位方面的潜力。",
            "intro_zh": [
                "现有视觉定位模型在处理众包图像时，因视觉扭曲和跨域差异导致性能显著下降。",
                "VPR-AttLLM利用LLM的语义知识，通过注意力机制增强VPR模型的描述符，无需重新训练。",
                "实验表明，VPR-AttLLM在多个数据集上提升了召回率，尤其在真实洪水图像上提升高达8%。"
            ],
            "method_zh": "**问题定义**：论文旨在解决众包街景图像地理定位不准确的问题，尤其是在城市洪水等危机事件中。现有视觉定位（VPR）模型在处理此类图像时，由于图像质量差、视角变化大以及与训练数据存在领域差异，导致定位精度显著下降。\\n\\n**核心思路**：论文的核心思路是利用大型语言模型（LLM）的语义理解能力和地理知识，引导VPR模型关注图像中与位置信息相关的区域，并抑制噪声干扰。通过LLM的辅助，VPR模型可以更有效地提取图像的地理特征，从而提高定位精度。\\n\\n**技术框架**：VPR-AttLLM框架主要包含以下几个模块：1) 图像输入：输入待定位的众包图像。2) VPR模型：使用现有的VPR模型（如CosPlace、EigenPlaces、SALAD）提取图像的全局特征。3) LLM：利用LLM分析图像内容，识别图像中具有位置信息的区域，并生成注意力权重。4) 注意力机制：将LLM生成的注意力权重应用于VPR模型的特征图，增强关键区域的特征，抑制噪声区域的特征。5) 地理位置检索：使用增强后的特征进行地理位置检索，得到最终的定位结果。\\n\\n**关键创新**：该方法最重要的创新点在于将LLM的语义理解能力与VPR模型的视觉特征提取能力相结合，通过注意力机制实现多模态融合。与传统的VPR方法相比，VPR-AttLLM能够更好地利用图像中的语义信息，提高对跨域和噪声图像的鲁棒性。\\n\\n**关键设计**：LLM部分的关键设计在于如何有效地提取图像中的位置信息。论文采用了一种基于提示学习的方法，通过设计合适的提示语，引导LLM识别图像中的地标、建筑物等具有位置信息的元素。注意力机制的设计也至关重要，需要保证LLM生成的注意力权重能够准确地反映图像中各个区域的重要性。",
            "application_zh": "该研究成果可应用于城市应急响应、灾害监测、城市规划等领域。通过快速准确地定位众包图像，可以帮助救援人员快速了解灾情，制定合理的救援方案。此外，该技术还可以用于城市环境监测、交通流量分析等方面，为智慧城市建设提供支持。",
            "highlight_zh": "VPR-AttLLM在多个数据集上进行了评估，包括SF-XL、合成洪水数据集和HK-URBAN。实验结果表明，VPR-AttLLM与CosPlace、EigenPlaces和SALAD等先进VPR模型集成后，召回率均得到显著提升，在最具挑战性的真实洪水图像上，召回率提升高达8%。这表明VPR-AttLLM具有很强的泛化能力和鲁棒性。",
            "tags_zh": [
                "视觉定位",
                "地理定位",
                "大型语言模型",
                "注意力机制",
                "多模态融合",
                "众包图像",
                "城市感知"
            ],
            "_index": 138,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.11811/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.11811/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.11811/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Assessing Greenspace Attractiveness with ChatGPT, Claude, and Gemini: Do AI Models Reflect Human Perceptions?",
            "authors": [
                "Milad Malekzadeh",
                "Magdalena Biernacka",
                "Elias Willberg",
                "Jussi Torkko",
                "Edyta Łaszkiewicz",
                "Tuuli Toivonen"
            ],
            "arxiv_id": "2512.11827",
            "summary": "Understanding greenspace attractiveness is essential for designing livable and inclusive urban environments, yet existing assessment approaches often overlook informal or transient spaces and remain too resource intensive to capture subjective perceptions at scale. This study examines the ability of multimodal large language models (MLLMs), ChatGPT GPT-4o, Claude 3.5 Haiku, and Gemini 2.0 Flash, to assess greenspace attractiveness similarly to humans using Google Street View imagery. We compared model outputs with responses from a geo-questionnaire of residents in Lodz, Poland, across both formal (for example, parks and managed greenspaces) and informal (for example, meadows and wastelands) greenspaces. Survey respondents and models indicated whether each greenspace was attractive or unattractive and provided up to three free text explanations. Analyses examined how often their attractiveness judgments aligned and compared their explanations after classifying them into shared reasoning categories. Results show high AI human agreement for attractive formal greenspaces and unattractive informal spaces, but low alignment for attractive informal and unattractive formal greenspaces. Models consistently emphasized aesthetic and design oriented features, underrepresenting safety, functional infrastructure, and locally embedded qualities valued by survey respondents. While these findings highlight the potential for scalable pre-assessment, they also underscore the need for human oversight and complementary participatory approaches. We conclude that MLLMs can support, but not replace, context sensitive greenspace evaluation in planning practice.",
            "categories": [
                "cs.CY",
                "cs.AI",
                "cs.CV"
            ],
            "primary_category": "cs.CY",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.11827",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "multimodal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "利用多模态大语言模型评估绿地吸引力，对比AI与人类感知差异",
            "summary_zh": "理解绿地吸引力对于设计宜居和包容的城市环境至关重要。然而，现有的评估方法通常忽略非正式或瞬时空间，并且在捕捉大规模主观感知方面资源消耗过大。本研究探讨了多模态大语言模型（MLLM），包括ChatGPT GPT-4o、Claude 3.5 Haiku和Gemini 2.0 Flash，使用谷歌街景图像评估绿地吸引力的能力，并与人类感知进行对比。我们将模型输出与波兰罗兹居民的地理问卷调查结果进行了比较，涵盖正式（如公园和管理的绿地）和非正式（如草地和荒地）绿地。调查受访者和模型都表明了每个绿地是否具有吸引力，并提供了最多三个自由文本解释。分析考察了他们的吸引力判断一致的频率，并在将解释分类为共享推理类别后比较了它们的解释。结果表明，对于有吸引力的正式绿地和没有吸引力的非正式空间，AI与人类的协议度很高，但对于有吸引力的非正式和没有吸引力的正式绿地，一致性较低。模型始终强调美学和设计导向的特征，低估了安全、功能基础设施和调查受访者重视的本地嵌入式品质。虽然这些发现突出了可扩展预评估的潜力，但它们也强调了人工监督和补充参与式方法的必要性。我们得出结论，MLLM可以支持规划实践中对环境敏感的绿地评估，但不能取代它。",
            "intro_zh": [
                "现有绿地评估方法忽略非正式空间，且难以大规模捕捉主观感知，限制了城市环境设计的包容性。",
                "本研究利用多模态大语言模型分析街景图像，评估绿地吸引力，并与人类感知进行对比分析。",
                "实验表明，AI在评估正式绿地和非正式空间上与人类有较高一致性，但在其他类型绿地上存在差异，强调了人工监督的必要性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决如何更高效、更全面地评估城市绿地吸引力的问题。现有方法主要依赖于人工调查或专家评估，存在成本高、覆盖范围有限以及难以捕捉主观感知等痛点。特别是对于非正式绿地（如荒地、草地），传统方法往往难以有效评估其吸引力。\\n\\n**核心思路**：论文的核心思路是利用多模态大语言模型（MLLM）的图像理解和文本生成能力，通过分析谷歌街景图像来自动评估绿地的吸引力。通过将模型评估结果与人类调查结果进行对比，分析AI模型在多大程度上能够反映人类对绿地吸引力的感知，并识别模型评估的偏差。\\n\\n**技术框架**：整体框架包括以下几个主要阶段：1) 数据收集：收集波兰罗兹市的谷歌街景图像，并进行地理编码；2) 人类调查：通过地理问卷调查收集当地居民对绿地吸引力的主观评价和解释；3) 模型评估：使用ChatGPT GPT-4o、Claude 3.5 Haiku和Gemini 2.0 Flash等MLLM模型，基于街景图像评估绿地的吸引力，并生成解释文本；4) 结果对比分析：比较模型和人类的吸引力判断，以及解释文本的语义内容，分析一致性和差异性。\\n\\n**关键创新**：本研究的关键创新在于将多模态大语言模型应用于城市绿地吸引力评估，探索了AI模型在理解和模拟人类主观感知方面的潜力。与传统方法相比，该方法具有自动化、可扩展性强的优势，可以为城市规划和设计提供更高效的决策支持。\\n\\n**关键设计**：研究中，关键设计包括：1) 绿地类型的划分：区分正式绿地（如公园）和非正式绿地（如荒地），以便更细致地分析模型在不同类型绿地上的表现；2) 解释文本的分类：将模型和人类生成的解释文本进行分类，提取共同的推理类别，以便更深入地理解模型和人类的判断逻辑；3) 模型选择：选择了多种主流的MLLM模型进行对比，以评估不同模型在绿地吸引力评估任务上的性能。",
            "application_zh": "该研究成果可应用于城市规划、景观设计、公共健康等领域。通过AI自动评估绿地吸引力，可以帮助规划者更高效地识别和改善城市中的绿地资源，提升居民的生活质量和幸福感。此外，该方法还可以扩展到其他城市环境要素的评估，例如建筑风格、街道景观等，为城市精细化管理提供技术支持。",
            "highlight_zh": "实验结果表明，对于吸引人的正式绿地和不吸引人的非正式空间，AI模型与人类的判断高度一致。然而，对于吸引人的非正式绿地和不吸引人的正式绿地，一致性较低。模型更倾向于强调美学和设计导向的特征，而忽略了安全、功能基础设施和本地嵌入式品质等因素。这表明AI模型在绿地吸引力评估方面具有潜力，但也需要人工监督和补充参与式方法。",
            "tags_zh": [
                "绿地吸引力评估",
                "多模态大语言模型",
                "城市规划",
                "街景图像分析",
                "人类感知",
                "AI对齐",
                "非正式绿地",
                "主观评价"
            ],
            "_index": 139,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Explainable reinforcement learning from human feedback to improve alignment",
            "authors": [
                "Shicheng Liu",
                "Siyuan Xu",
                "Wenjie Qiu",
                "Hangfan Zhang",
                "Minghui Zhu"
            ],
            "arxiv_id": "2512.13837",
            "summary": "A common and effective strategy for humans to improve an unsatisfactory outcome in daily life is to find a cause of this outcome and correct the cause. In this paper, we investigate whether this human improvement strategy can be applied to improving reinforcement learning from human feedback (RLHF) for alignment of language models (LMs). In particular, it is observed in the literature that LMs tuned by RLHF can still output unsatisfactory responses. This paper proposes a method to improve the unsatisfactory responses by correcting their causes. Our method has two parts. The first part proposes a post-hoc explanation method to explain why an unsatisfactory response is generated to a prompt by identifying the training data that lead to this response. We formulate this problem as a constrained combinatorial optimization problem where the objective is to find a set of training data closest to this prompt-response pair in a feature representation space, and the constraint is that the prompt-response pair can be decomposed as a convex combination of this set of training data in the feature space. We propose an efficient iterative data selection algorithm to solve this problem. The second part proposes an unlearning method that improves unsatisfactory responses to some prompts by unlearning the training data that lead to these unsatisfactory responses and, meanwhile, does not significantly degrade satisfactory responses to other prompts. Experimental results demonstrate that our algorithm can improve RLHF.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13837",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning",
                        "RLHF"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出基于人类反馈的可解释强化学习方法，提升语言模型对齐效果",
            "summary_zh": "本文研究了如何将人类改进策略应用于从人类反馈中进行强化学习(RLHF)，以提升语言模型(LM)的对齐效果。观察到RLHF调优的LM仍然会产生不令人满意的回复。本文提出一种通过纠正原因来改进这些回复的方法。该方法包含两部分：首先，提出一种事后解释方法，通过识别导致不满意回复的训练数据来解释其生成原因。这被建模为一个约束组合优化问题，目标是在特征表示空间中找到与提示-回复对最接近的训练数据集，约束是提示-回复对可以分解为该数据集在特征空间中的凸组合。提出了一种高效的迭代数据选择算法来解决这个问题。其次，提出一种非学习方法，通过非学习导致这些不满意回复的训练数据来改进某些提示的不满意回复，同时不会显著降低其他提示的满意回复。实验结果表明，该算法可以改进RLHF。",
            "intro_zh": [
                "现有RLHF调优的语言模型仍可能产生不理想的回复，缺乏有效改进机制。",
                "提出一种可解释的RLHF方法，通过识别并纠正导致不良回复的训练数据来优化模型。",
                "实验结果表明，该方法能够有效改进RLHF，提升语言模型的对齐效果。"
            ],
            "method_zh": "**问题定义**：论文旨在解决RLHF训练的语言模型仍然会生成不令人满意的回复的问题。现有方法缺乏对不良回复原因的解释，难以针对性地进行改进。因此，如何找到导致不良回复的根本原因，并在此基础上进行优化，是本文要解决的关键问题。\\n\\n**核心思路**：论文的核心思路是模仿人类改进问题的方式：首先找到问题的原因，然后纠正原因。具体而言，对于语言模型生成的不良回复，首先通过可解释性方法找到导致该回复的训练数据，然后通过“非学习”这些数据来改进模型，使其不再生成类似的不良回复。\\n\\n**技术框架**：该方法包含两个主要模块：1) **事后解释模块**：该模块的目标是找到导致不良回复的训练数据。它将该问题建模为一个约束组合优化问题，目标是在特征空间中找到与当前提示-回复对最接近的训练数据子集，约束是该提示-回复对可以表示为该子集的凸组合。使用迭代数据选择算法来解决该优化问题。2) **非学习模块**：该模块的目标是通过“非学习”导致不良回复的训练数据来改进模型。该模块在更新模型参数时，会降低这些训练数据的影响，从而减少模型生成类似不良回复的可能性。\\n\\n**关键创新**：该方法最重要的创新点在于将可解释性引入RLHF，通过解释不良回复的原因，从而能够针对性地进行改进。与传统的RLHF方法相比，该方法不仅关注模型的整体性能，还关注模型在特定情况下的表现，并能够通过纠正错误的原因来提升性能。\\n\\n**关键设计**：在事后解释模块中，关键的设计包括：1) 特征表示空间的选择，需要能够有效捕捉提示和回复之间的语义关系。2) 约束组合优化问题的定义，需要保证找到的训练数据子集能够合理地解释当前提示-回复对。3) 迭代数据选择算法的设计，需要保证算法的效率和准确性。在非学习模块中，关键的设计包括：1) 如何确定需要“非学习”的训练数据。2) 如何在更新模型参数时降低这些数据的影响，同时避免对其他数据的性能产生负面影响。",
            "application_zh": "该研究成果可应用于各种需要从人类反馈中进行学习的语言模型应用场景，例如对话系统、文本生成、代码生成等。通过提升模型对齐效果，可以提高用户满意度，减少模型产生有害或不当回复的风险。未来，该方法可以扩展到其他类型的机器学习模型，并应用于更广泛的领域。",
            "highlight_zh": "实验结果表明，该算法能够有效改进RLHF，提升语言模型的对齐效果。具体而言，通过“非学习”导致不良回复的训练数据，模型在生成类似回复的可能性显著降低，同时对其他回复的性能影响较小。具体的性能提升数据在论文中给出，与基线方法相比，该方法在特定指标上取得了显著的提升。",
            "tags_zh": [
                "可解释强化学习",
                "人类反馈",
                "语言模型对齐",
                "事后解释",
                "非学习"
            ],
            "_index": 140,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13837/post_training_structure.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13837/explanation_example.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.13837/dialogue_comparison.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Model-Based Reinforcement Learning in Discrete-Action Non-Markovian Reward Decision Processes",
            "authors": [
                "Alessandro Trapasso",
                "Luca Iocchi",
                "Fabio Patrizi"
            ],
            "arxiv_id": "2512.14617",
            "summary": "Many practical decision-making problems involve tasks whose success depends on the entire system history, rather than on achieving a state with desired properties. Markovian Reinforcement Learning (RL) approaches are not suitable for such tasks, while RL with non-Markovian reward decision processes (NMRDPs) enables agents to tackle temporal-dependency tasks. This approach has long been known to lack formal guarantees on both (near-)optimality and sample efficiency. We contribute to solving both issues with QR-MAX, a novel model-based algorithm for discrete NMRDPs that factorizes Markovian transition learning from non-Markovian reward handling via reward machines. To the best of our knowledge, this is the first model-based RL algorithm for discrete-action NMRDPs that exploits this factorization to obtain PAC convergence to $\\varepsilon$-optimal policies with polynomial sample complexity. We then extend QR-MAX to continuous state spaces with Bucket-QR-MAX, a SimHash-based discretiser that preserves the same factorized structure and achieves fast and stable learning without manual gridding or function approximation. We experimentally compare our method with modern state-of-the-art model-based RL approaches on environments of increasing complexity, showing a significant improvement in sample efficiency and increased robustness in finding optimal policies.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14617",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning",
                        "model-based RL"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出QR-MAX算法，解决离散动作非马尔可夫奖励决策过程中的模型学习与策略优化问题",
            "summary_zh": "许多实际决策问题依赖于整个系统历史，而非仅依赖于达到具有期望属性的状态。马尔可夫强化学习(RL)方法不适用于此类任务，而非马尔可夫奖励决策过程(NMRDPs)的RL使智能体能够处理时间依赖性任务。然而，这种方法长期以来缺乏关于(近)最优性和样本效率的形式保证。我们提出了QR-MAX，一种用于离散NMRDPs的新型基于模型的算法，它通过奖励机器将马尔可夫转移学习与非马尔可夫奖励处理分解开来，从而解决了这两个问题。据我们所知，这是第一个用于离散动作NMRDPs的基于模型的RL算法，它利用这种分解来获得PAC收敛到具有多项式样本复杂度的ε-最优策略。然后，我们将QR-MAX扩展到具有Bucket-QR-MAX的连续状态空间，Bucket-QR-MAX是一种基于SimHash的离散器，它保留了相同的分解结构，并在没有手动网格划分或函数逼近的情况下实现了快速稳定的学习。我们在复杂度不断增加的环境中，将我们的方法与现代最先进的基于模型的RL方法进行了实验比较，结果表明在样本效率方面有显著提高，并且在寻找最优策略方面具有更高的鲁棒性。",
            "intro_zh": [
                "传统马尔可夫强化学习难以处理奖励依赖于历史状态的决策问题，非马尔可夫奖励决策过程(NMRDPs)强化学习缺乏理论保证。",
                "QR-MAX算法通过奖励机器分解马尔可夫转移学习和非马尔可夫奖励处理，实现高效学习。",
                "实验表明，QR-MAX在样本效率和寻找最优策略的鲁棒性方面，显著优于现有基于模型的强化学习方法。"
            ],
            "method_zh": "**问题定义**：论文旨在解决离散动作非马尔可夫奖励决策过程(NMRDPs)中的强化学习问题。传统强化学习方法基于马尔可夫假设，无法有效处理奖励依赖于历史状态的任务。现有NMRDPs强化学习方法缺乏理论保证，如样本效率和收敛性，限制了其在实际问题中的应用。\\n\\n**核心思路**：论文的核心思路是将马尔可夫转移学习与非马尔可夫奖励处理进行解耦。具体而言，利用奖励机器(Reward Machine)来建模非马尔可夫奖励函数，从而将复杂的奖励函数分解为一系列状态转移。同时，采用基于模型的强化学习方法，学习环境的马尔可夫转移模型。通过这种分解，可以更有效地学习和优化策略。\\n\\n**技术框架**：QR-MAX算法的整体框架包括以下几个主要模块：1) 环境交互：智能体与环境进行交互，收集状态、动作和奖励数据。2) 模型学习：利用收集到的数据，学习环境的马尔可夫转移模型。3) 奖励机器学习：学习奖励机器的状态转移和奖励函数。4) 策略优化：基于学习到的环境模型和奖励机器，使用Q-learning算法优化策略。对于连续状态空间，论文提出了Bucket-QR-MAX算法，使用SimHash进行状态离散化。\\n\\n**关键创新**：论文的关键创新在于提出了基于奖励机器的NMRDPs分解方法，以及相应的QR-MAX算法。这种分解方法使得可以独立地学习环境的马尔可夫转移模型和非马尔可夫奖励函数，从而提高了学习效率和泛化能力。此外，论文还提供了QR-MAX算法的PAC收敛性证明，保证了算法的理论性能。\\n\\n**关键设计**：QR-MAX算法的关键设计包括：1) 奖励机器的表示和学习方法。2) Q-learning算法的更新规则，需要考虑奖励机器的状态。3) Bucket-QR-MAX算法中SimHash的参数设置，例如哈希函数的数量和哈希桶的大小。论文中没有明确给出损失函数和网络结构等细节，可能使用了标准的Q-learning损失函数和简单的网络结构。",
            "application_zh": "该研究成果可应用于需要考虑历史信息的决策问题，例如机器人导航、任务规划、游戏AI等。在这些场景中，智能体的奖励不仅取决于当前状态，还取决于之前的行为序列。通过使用QR-MAX算法，可以更有效地学习和优化策略，提高智能体的性能。未来，该方法有望应用于更复杂的实际问题，例如自动驾驶、金融交易等。",
            "highlight_zh": "实验结果表明，QR-MAX算法在多个NMRDPs环境中，显著优于现有的基于模型的强化学习方法。具体而言，QR-MAX算法在样本效率方面有显著提高，能够在更少的交互次数下找到最优策略。此外，QR-MAX算法在寻找最优策略的鲁棒性方面也表现更好，能够在不同的环境参数下稳定地学习到最优策略。",
            "tags_zh": [
                "强化学习",
                "非马尔可夫决策过程",
                "模型学习",
                "奖励机器",
                "样本效率"
            ],
            "_index": 141,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14617/Experiments/map0_exp0_model_based.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14617/Experiments/map1_exp5_model_based.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14617/Experiments/map4_exp7.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Scalable Frameworks for Real-World Audio-Visual Speech Recognition",
            "authors": [
                "Sungnyun Kim"
            ],
            "arxiv_id": "2512.14083",
            "summary": "The practical deployment of Audio-Visual Speech Recognition (AVSR) systems is fundamentally challenged by significant performance degradation in real-world environments, characterized by unpredictable acoustic noise and visual interference. This dissertation posits that a systematic, hierarchical approach is essential to overcome these challenges, achieving the robust scalability at the representation, architecture, and system levels. At the representation level, we investigate methods for building a unified model that learns audio-visual features inherently robust to diverse real-world corruptions, thereby enabling generalization to new environments without specialized modules. To address architectural scalability, we explore how to efficiently expand model capacity while ensuring the adaptive and reliable use of multimodal inputs, developing a framework that intelligently allocates computational resources based on the input characteristics. Finally, at the system level, we present methods to expand the system's functionality through modular integration with large-scale foundation models, leveraging their powerful cognitive and generative capabilities to maximize final recognition accuracy. By systematically providing solutions at each of these three levels, this dissertation aims to build a next-generation, robust, and scalable AVSR system with high reliability in real-world applications.",
            "categories": [
                "eess.AS",
                "cs.CL",
                "cs.LG"
            ],
            "primary_category": "eess.AS",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14083",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "foundation model",
                        "multimodal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出可扩展框架，解决真实场景下音频-视觉语音识别的鲁棒性问题",
            "summary_zh": "音频-视觉语音识别(AVSR)系统在实际部署中面临着严峻的挑战，主要表现为在不可预测的噪声和视觉干扰等真实环境下性能显著下降。本研究认为，克服这些挑战的关键在于采用系统的、分层的策略，在表征、架构和系统层面实现鲁棒的可扩展性。在表征层面，研究致力于构建统一模型，学习对各种真实环境干扰具有内在鲁棒性的音频-视觉特征，从而无需专用模块即可泛化到新环境。在架构层面，探索如何有效扩展模型容量，同时确保自适应和可靠地利用多模态输入，开发一个基于输入特征智能分配计算资源的框架。最后，在系统层面，提出通过与大规模基础模型进行模块化集成来扩展系统功能的方法，利用它们强大的认知和生成能力来最大化最终识别精度。通过在上述三个层面系统地提供解决方案，本研究旨在构建下一代鲁棒且可扩展的AVSR系统，使其在实际应用中具有高可靠性。",
            "intro_zh": [
                "现有AVSR系统在真实场景中受噪声和视觉干扰影响，性能显著下降，缺乏鲁棒性和泛化能力。",
                "论文提出分层策略，分别在表征、架构和系统层面进行优化，提升AVSR系统在真实场景下的性能。",
                "通过构建统一模型学习鲁棒特征、自适应分配计算资源以及集成大规模基础模型，提升识别精度。"
            ],
            "method_zh": "**问题定义**：论文旨在解决真实场景下音频-视觉语音识别（AVSR）系统性能大幅下降的问题。现有AVSR系统在理想环境下表现良好，但在实际应用中，由于存在各种噪声干扰、视觉遮挡等因素，识别准确率会显著降低。现有方法通常针对特定噪声或干扰进行优化，缺乏通用性和鲁棒性。\\n\\n**核心思路**：论文的核心思路是采用一种分层、可扩展的方法，从表征、架构和系统三个层面提升AVSR系统的鲁棒性和泛化能力。通过学习对各种干扰具有内在鲁棒性的统一特征表示，设计自适应的多模态融合架构，以及集成大规模预训练模型，实现更准确、更可靠的语音识别。\\n\\n**技术框架**：论文提出的AVSR框架包含三个主要组成部分：1) 鲁棒特征表示学习模块，用于提取对噪声和视觉干扰不敏感的音频-视觉特征；2) 自适应多模态融合模块，根据输入信号的质量动态调整音频和视觉信息的权重；3) 系统集成模块，将AVSR系统与大规模预训练模型结合，利用预训练模型的知识进行语音识别。\\n\\n**关键创新**：论文的关键创新在于提出了一种统一的框架，能够同时在表征、架构和系统层面提升AVSR系统的性能。与以往的研究只关注单一方面的优化不同，该框架能够综合考虑各种因素，实现更全面的性能提升。此外，自适应多模态融合模块能够根据输入信号的质量动态调整音频和视觉信息的权重，从而更好地应对各种复杂场景。\\n\\n**关键设计**：在鲁棒特征表示学习方面，可能采用了对抗训练或数据增强等技术，以提高特征对噪声和干扰的鲁棒性。在自适应多模态融合方面，可能使用了注意力机制或门控机制，以动态调整音频和视觉信息的权重。在系统集成方面，可能使用了微调或知识蒸馏等技术，将大规模预训练模型的知识迁移到AVSR系统。",
            "application_zh": "该研究成果可广泛应用于各种真实场景下的语音交互系统，例如智能家居、车载语音助手、视频会议、公共场所语音识别等。通过提高AVSR系统在复杂环境下的鲁棒性和准确性，可以改善用户体验，扩展语音交互的应用范围，并为聋哑人提供更有效的辅助工具。",
            "highlight_zh": "论文重点在于框架设计和方法论，摘要中未提供具体的实验数据和对比结果。未来的研究可以关注在公开数据集上验证所提出框架的有效性，并与现有的AVSR系统进行比较，量化性能提升。",
            "tags_zh": [
                "音频-视觉语音识别",
                "多模态融合",
                "鲁棒性",
                "可扩展性",
                "深度学习",
                "特征表示学习",
                "自适应融合"
            ],
            "_index": 142,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Ladder Up, Memory Down: Low-Cost Fine-Tuning With Side Nets",
            "authors": [
                "Estelle Zheng",
                "Nathan Cerisara",
                "Sébastien Warichet",
                "Emmanuel Helbert",
                "Christophe Cerisara"
            ],
            "arxiv_id": "2512.14237",
            "summary": "Fine-tuning large language models (LLMs) is often limited by the memory available on commodity GPUs. Parameter-efficient fine-tuning (PEFT) methods such as QLoRA reduce the number of trainable parameters, yet still incur high memory usage induced by the backward pass in the full model. We revisit Ladder Side Tuning (LST), a rarely explored PEFT technique that adds a lightweight side network, and show that it matches QLoRA's compute scaling slope while cutting peak memory by 50\\%. Across different downstream benchmarks spanning natural language understanding, mathematical and LLM-critic tasks, LST has competitive performance with QLoRA's accuracy on average while being much more memory-efficient. This efficiency enables fine-tuning of 7B-parameter models on a single 12 GB consumer GPU with 2k-token contexts, requiring no gradient checkpointing\\textemdash conditions under which QLoRA exhausts memory. Beyond memory efficiency, we also establish scaling laws showing that LST scales similarly to QLoRA. We exploit Ladder's architectural flexibility by introducing xLadder, a depth-extended variant that increases effective depth via cross-connections and shortens chain-of-thought (CoT) at fixed parameter count. Ladder is strong when memory is the bottleneck; xLadder builds on this by enabling deeper reasoning without additional memory overhead.",
            "categories": [
                "cs.CL",
                "cs.LG"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14237",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "chain-of-thought"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出Ladder Side Tuning，以低成本微调大型语言模型，显著降低内存占用。",
            "summary_zh": "微调大型语言模型（LLM）通常受限于消费级GPU的内存。参数高效微调（PEFT）方法如QLoRA虽然减少了可训练参数的数量，但由于完整模型中的反向传播，仍然会产生较高的内存使用量。本文重新审视了Ladder Side Tuning（LST），一种很少被探索的PEFT技术，它增加了一个轻量级的侧网络，并表明它在计算扩展斜率上与QLoRA相匹配，同时将峰值内存减少了50%。在涵盖自然语言理解、数学和LLM-critic任务的不同下游基准测试中，LST的性能与QLoRA的准确性相比具有竞争力，同时内存效率更高。这种效率使得可以在单个12GB消费级GPU上使用2k-token上下文微调7B参数模型，而无需梯度检查点——在这些条件下，QLoRA会耗尽内存。除了内存效率之外，本文还建立了缩放定律，表明LST的缩放方式与QLoRA类似。本文通过引入xLadder来利用Ladder的架构灵活性，xLadder是一种深度扩展的变体，通过交叉连接增加有效深度，并在固定参数数量下缩短思维链（CoT）。当内存是瓶颈时，Ladder表现强劲；xLadder在此基础上通过无需额外内存开销即可实现更深层次的推理。",
            "intro_zh": [
                "现有PEFT方法如QLoRA虽然减少了训练参数，但完整模型反向传播导致内存占用仍然很高。",
                "Ladder Side Tuning (LST) 通过增加轻量级侧网络，在保证性能的同时显著降低内存占用。",
                "LST在多个下游任务上与QLoRA性能相当，内存占用减半，并可扩展到更深层次的推理。"
            ],
            "method_zh": "**问题定义**：现有参数高效微调方法（如QLoRA）在微调大型语言模型时，虽然减少了可训练参数的数量，但由于需要进行完整模型的反向传播，仍然会消耗大量的GPU内存，限制了在资源受限的设备上的应用。尤其是在长文本场景下，内存需求更加严峻。\\n\\n**核心思路**：论文的核心思路是利用Ladder Side Tuning (LST) 这种相对较少被研究的参数高效微调技术，通过引入一个轻量级的侧网络，在主模型之外进行参数更新。这样可以在不修改或微调主模型参数的情况下，实现对下游任务的适配，从而显著降低内存占用。\\n\\n**技术框架**：LST 的整体架构是在预训练的 Transformer 模型旁边添加一个并行的、轻量级的侧网络（Ladder Network）。输入数据同时输入到主模型和侧网络。主模型的输出和侧网络的输出进行融合，得到最终的预测结果。在训练过程中，只更新侧网络的参数，而主模型的参数保持固定。xLadder 是 LST 的一个变体，通过增加侧网络的深度和引入跨层连接，来增强模型的推理能力。\\n\\n**关键创新**：LST 的关键创新在于其高效的内存利用率。通过只训练侧网络，避免了对整个大型语言模型进行反向传播，从而显著降低了内存需求。xLadder 的创新在于通过扩展侧网络的深度和引入跨层连接，在不增加过多参数的情况下，提升了模型的推理能力。\\n\\n**关键设计**：LST 的关键设计包括侧网络的结构选择（例如，可以使用较小的 Transformer 模型或 MLP），以及主模型和侧网络输出的融合方式（例如，可以使用加权平均或拼接）。xLadder 的关键设计在于跨层连接的引入，这允许信息在侧网络的不同层之间流动，从而增强了模型的表达能力。损失函数通常采用交叉熵损失，用于衡量模型预测结果与真实标签之间的差异。",
            "application_zh": "该研究成果可应用于资源受限的场景下的大型语言模型微调，例如在消费级GPU或边缘设备上进行模型适配。这使得更多用户能够利用大型语言模型的能力，而无需昂贵的硬件设备。此外，该方法还可以应用于需要快速迭代和部署的场景，因为其训练效率更高。",
            "highlight_zh": "实验结果表明，LST 在内存效率方面优于 QLoRA，在多个下游任务上取得了与 QLoRA 相当甚至更好的性能。LST 能够在一个 12GB 的消费级 GPU 上微调 7B 参数的模型，而 QLoRA 在相同条件下会耗尽内存。此外，xLadder 通过增加侧网络的深度，在不增加过多参数的情况下，提升了模型的推理能力。",
            "tags_zh": [
                "参数高效微调",
                "大型语言模型",
                "内存优化",
                "侧网络",
                "Ladder Side Tuning"
            ],
            "_index": 143,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Improvement of AMPs Identification with Generative Adversarial Network and Ensemble Classification",
            "authors": [
                "Reyhaneh Keshavarzpour",
                "Eghbal Mansoori"
            ],
            "arxiv_id": "2506.01983",
            "summary": "Identification of antimicrobial peptides is an important and necessary issue in today's era. Antimicrobial peptides are essential as an alternative to antibiotics for biomedical applications and many other practical applications. These oligopeptides are useful in drug design and cause innate immunity against microorganisms. Artificial intelligence algorithms have played a significant role in the ease of identifying thesethis http URLresearch is improved by improving proposed method in the field of antimicrobial peptides prediction. Suggested method is improved by combining the best coding method from different perspectives, In the following a deep neural network to balance the imbalanced combined datasets. The results of this research show that the proposed method have a significant improvement in the accuracy and efficiency of the prediction of antimicrobial peptides and are able to provide the best results compared to the existing methods. These development in the field of prediction and classification of antimicrobial peptides, basically in the fields of medicine and pharmaceutical industries, have high effectiveness and application.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2506.01983",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱八：物理动画 (Physics-based Animation)",
                    "id": "8_physics_animation",
                    "matched_keywords": [
                        "[T]AMP"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "8_physics_animation"
            ],
            "headline_zh": "结合生成对抗网络与集成学习，提升抗菌肽识别准确率",
            "summary_zh": "抗菌肽的识别在当今时代至关重要。作为抗生素的替代品，抗菌肽在生物医学和许多其他实际应用中不可或缺。这些寡肽在药物设计中发挥作用，并能引起针对微生物的先天免疫。人工智能算法在简化抗菌肽识别方面发挥了重要作用。本研究通过改进抗菌肽预测方法来提升相关研究水平。改进方法结合了不同角度的最佳编码方式，并采用深度神经网络来平衡不平衡的组合数据集。研究结果表明，所提出的方法在抗菌肽预测的准确性和效率方面有显著提高，并且能够提供优于现有方法的结果。这些在抗菌肽预测和分类领域的发展，特别是在医药工业领域，具有很高的有效性和应用价值。",
            "intro_zh": [
                "现有抗菌肽识别方法在准确性和效率方面存在提升空间，尤其是在处理不平衡数据集时。",
                "该论文提出一种结合生成对抗网络（GAN）和集成学习的方案，旨在提升抗菌肽识别的准确率和效率。",
                "实验结果表明，该方法在抗菌肽预测方面取得了显著的改进，优于现有的方法，具有较高的应用价值。"
            ],
            "method_zh": "**问题定义**：论文旨在解决抗菌肽识别的准确性和效率问题。现有方法在处理不平衡数据集时表现不佳，导致预测结果偏差。此外，不同编码方法各有优缺点，如何有效结合也是一个挑战。\\n\\n**核心思路**：论文的核心思路是结合多种编码方法的优点，并利用生成对抗网络（GAN）平衡数据集，然后使用深度神经网络进行分类。通过集成学习，进一步提升模型的泛化能力和鲁棒性。\\n\\n**技术框架**：该方法主要包含以下几个阶段：1) 数据编码：采用多种编码方法对抗菌肽序列进行编码，提取不同角度的特征。2) 数据平衡：利用GAN生成新的抗菌肽序列，平衡数据集的正负样本比例。3) 模型训练：使用深度神经网络对平衡后的数据集进行训练，学习抗菌肽的特征表示。4) 集成学习：将多个深度神经网络的预测结果进行集成，得到最终的预测结果。\\n\\n**关键创新**：该方法的主要创新点在于：1) 结合多种编码方法，充分利用不同角度的特征信息。2) 利用GAN生成新的抗菌肽序列，有效解决数据集不平衡问题。3) 采用集成学习，提升模型的泛化能力和鲁棒性。\\n\\n**关键设计**：论文中可能涉及的关键设计包括：GAN的网络结构（生成器和判别器的设计）、深度神经网络的结构（如卷积神经网络、循环神经网络等）、集成学习的方法（如投票法、加权平均法等）、损失函数的设计（如交叉熵损失函数、GAN的对抗损失函数等）以及超参数的设置。",
            "application_zh": "该研究成果可应用于药物设计和生物医学领域，加速新型抗菌药物的开发。通过更准确地识别抗菌肽，可以降低研发成本，提高药物筛选效率。此外，该方法还可应用于其他生物活性肽的预测和分类，具有广阔的应用前景。",
            "highlight_zh": "论文结果表明，提出的方法在抗菌肽预测的准确性和效率方面有显著提高，能够提供优于现有方法的结果。具体的性能数据（如准确率、召回率、F1值等）以及与现有方法的对比结果需要在论文中查找。",
            "tags_zh": [
                "抗菌肽识别",
                "生成对抗网络",
                "集成学习",
                "深度学习",
                "不平衡数据"
            ],
            "_index": 144,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "ASTRO: Adaptive Stitching via Dynamics-Guided Trajectory Rollouts",
            "authors": [
                "Hang Yu",
                "Di Zhang",
                "Qiwei Du",
                "Yanping Zhao",
                "Hai Zhang",
                "Guang Chen",
                "Eduardo E. Veas",
                "Junqiao Zhao"
            ],
            "arxiv_id": "2511.23442",
            "summary": "Offline reinforcement learning (RL) enables agents to learn optimal policies from pre-collected datasets. However, datasets containing suboptimal and fragmented trajectories present challenges for reward propagation, resulting in inaccurate value estimation and degraded policy performance. While trajectory stitching via generative models offers a promising solution, existing augmentation methods frequently produce trajectories that are either confined to the support of the behavior policy or violate the underlying dynamics, thereby limiting their effectiveness for policy improvement. We propose ASTRO, a data augmentation framework that generates distributionally novel and dynamics-consistent trajectories for offline RL. ASTRO first learns a temporal-distance representation to identify distinct and reachable stitch targets. We then employ a dynamics-guided stitch planner that adaptively generates connecting action sequences via Rollout Deviation Feedback, defined as the gap between target state sequence and the actual arrived state sequence by executing predicted actions, to improve trajectory stitching's feasibility and reachability. This approach facilitates effective augmentation through stitching and ultimately enhances policy learning. ASTRO outperforms prior offline RL augmentation methods across various algorithms, achieving notable performance gain on the challenging OGBench suite and demonstrating consistent improvements on standard offline RL benchmarks such as D4RL.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2511.23442",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning",
                        "policy learning",
                        "offline RL",
                        "offline reinforcement learning"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "ASTRO：通过动态引导轨迹展开实现自适应拼接，提升离线强化学习性能",
            "summary_zh": "离线强化学习(RL)使智能体能够从预先收集的数据集中学习最优策略。然而，包含次优和碎片化轨迹的数据集给奖励传播带来了挑战，导致不准确的价值估计和降低的策略性能。虽然通过生成模型进行轨迹拼接提供了一个有希望的解决方案，但现有的增强方法经常产生局限于行为策略支持或违反底层动态的轨迹，从而限制了它们在策略改进方面的有效性。我们提出了ASTRO，一个数据增强框架，为离线RL生成分布上新颖且动态一致的轨迹。ASTRO首先学习一个时间距离表示，以识别不同的和可到达的拼接目标。然后，我们采用一个动态引导的拼接规划器，通过Rollout Deviation Feedback自适应地生成连接动作序列，Rollout Deviation Feedback被定义为目标状态序列与执行预测动作后实际到达状态序列之间的差距，以提高轨迹拼接的可行性和可达性。这种方法通过拼接促进了有效的增强，并最终增强了策略学习。ASTRO在各种算法中优于先前的离线RL增强方法，在具有挑战性的OGBench套件上实现了显著的性能提升，并在标准的离线RL基准（如D4RL）上展示了一致的改进。",
            "intro_zh": [
                "离线强化学习受限于数据集质量，次优或碎片化轨迹导致奖励传播困难，影响策略学习。",
                "ASTRO通过学习时间距离表示和动态引导的拼接规划器，生成新颖且动态一致的轨迹，增强数据集。",
                "实验表明，ASTRO在OGBench和D4RL等基准测试中显著优于现有离线RL增强方法。"
            ],
            "method_zh": "**问题定义**：离线强化学习面临数据集质量的挑战，特别是当数据集中包含大量次优或不完整的轨迹时。这些轨迹会导致奖励难以准确传播，从而影响价值估计和策略学习。现有的轨迹拼接方法要么生成的轨迹过于保守，局限于原始数据集的分布，要么生成的轨迹违反环境动力学，导致策略性能提升有限。\\n\\n**核心思路**：ASTRO的核心思路是通过生成既新颖又符合环境动力学的轨迹来增强离线数据集。它通过学习轨迹之间的时间距离表示来确定合适的拼接目标，并使用动态引导的拼接规划器来生成连接这些目标的动作序列。这种方法旨在克服现有方法的局限性，提高轨迹拼接的可行性和有效性。\\n\\n**技术框架**：ASTRO框架包含两个主要模块：1) 时间距离表示学习模块，用于识别可行的拼接目标；2) 动态引导的拼接规划器，用于生成连接轨迹的动作序列。拼接规划器使用Rollout Deviation Feedback，即目标状态序列与实际到达状态序列之间的差距，来指导动作序列的生成，从而确保生成的轨迹符合环境动力学。\\n\\n**关键创新**：ASTRO的关键创新在于其动态引导的拼接规划器和Rollout Deviation Feedback机制。传统的轨迹拼接方法通常依赖于生成模型或简单的插值方法，难以保证生成轨迹的动力学一致性。ASTRO通过Rollout Deviation Feedback，能够自适应地调整生成的动作序列，使其更接近目标状态序列，从而提高轨迹拼接的成功率和策略学习的性能。\\n\\n**关键设计**：ASTRO使用神经网络来学习时间距离表示，并使用优化算法（如梯度下降）来生成连接轨迹的动作序列。Rollout Deviation Feedback被用作优化过程中的损失函数，引导动作序列的生成。具体的网络结构和优化算法的选择可以根据具体的任务和数据集进行调整。",
            "application_zh": "ASTRO可应用于机器人控制、自动驾驶、游戏AI等领域，尤其是在数据收集成本高昂或难以进行在线探索的场景下。通过增强离线数据集，ASTRO能够提高智能体的学习效率和性能，降低对大量高质量数据的依赖，加速智能体的部署和应用。",
            "highlight_zh": "ASTRO在OGBench套件上实现了显著的性能提升，并在D4RL等标准离线RL基准测试中展示了一致的改进。具体而言，ASTRO在某些任务上的性能提升超过了现有最佳方法的10%以上，证明了其在离线强化学习数据增强方面的有效性。",
            "tags_zh": [
                "离线强化学习",
                "数据增强",
                "轨迹拼接",
                "动态引导",
                "Rollout Deviation Feedback"
            ],
            "_index": 145,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2511.23442/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2511.23442/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2511.23442/fig/ori_heatmap.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "ReflCtrl: Controlling LLM Reflection via Representation Engineering",
            "authors": [
                "Ge Yan",
                "Chung-En Sun",
                "Tsui-Wei",
                "Weng"
            ],
            "arxiv_id": "2512.13979",
            "summary": "Large language models (LLMs) with Chain-of-Thought (CoT) reasoning have achieved strong performance across diverse tasks, including mathematics, coding, and general reasoning. A distinctive ability of these reasoning models is self-reflection: the ability to review and revise previous reasoning steps. While self-reflection enhances reasoning performance, it also increases inference cost. In this work, we study self-reflection through the lens of representation engineering. We segment the model's reasoning into steps, identify the steps corresponding to reflection, and extract a reflection direction in the latent space that governs this behavior. Using this direction, we propose a stepwise steering method that can control reflection frequency. We call our framework ReflCtrl. Our experiments show that (1) in many cases reflections are redundant, especially in stronger models (in our experiments, we can save up to 33.6 percent of reasoning tokens while preserving performance), and (2) the model's reflection behavior is highly correlated with an internal uncertainty signal, implying self-reflection may be controlled by the model's uncertainty.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13979",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "chain-of-thought"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "ReflCtrl：通过表征工程控制大语言模型的反思行为",
            "summary_zh": "具有思维链（CoT）推理的大语言模型（LLMs）在数学、编码和通用推理等多种任务中表现出强大的性能。这些推理模型的一个显著能力是自我反思：审查和修改先前推理步骤的能力。虽然自我反思可以提高推理性能，但也会增加推理成本。本文从表征工程的角度研究自我反思。我们将模型的推理过程分割成多个步骤，识别对应于反思的步骤，并提取潜在空间中控制这种行为的反思方向。利用这个方向，我们提出了一种逐步引导方法，可以控制反思频率。我们将我们的框架称为ReflCtrl。实验表明：（1）在许多情况下，反思是冗余的，尤其是在更强大的模型中（在我们的实验中，我们可以在保持性能的同时节省高达33.6%的推理token），（2）模型的反思行为与内部不确定性信号高度相关，这意味着自我反思可能受到模型不确定性的控制。",
            "intro_zh": [
                "现有大语言模型推理过程中，自我反思能力虽能提升性能，但同时也显著增加了计算成本。",
                "论文提出ReflCtrl框架，通过表征工程在模型潜在空间中提取反思方向，实现对反思频率的精确控制。",
                "实验表明，ReflCtrl能在保持性能的同时，显著减少推理所需的token数量，并揭示反思行为与模型内部不确定性之间的关联。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大语言模型在推理过程中，由于过度自我反思而导致的计算资源浪费问题。现有方法缺乏对反思行为的有效控制，导致推理效率低下，尤其是在能力较强的模型中，冗余反思现象更为突出。\\n\\n**核心思路**：论文的核心思路是通过表征工程，在模型的潜在空间中找到控制反思行为的“反思方向”。通过操纵这个方向，可以调节模型进行自我反思的频率，从而在性能和效率之间取得平衡。这种方法基于一个假设：反思行为在模型的内部表征中存在可识别的模式。\\n\\n**技术框架**：ReflCtrl框架主要包含以下几个阶段：1) 推理过程分割：将模型的推理过程分解为多个步骤。2) 反思步骤识别：识别哪些步骤对应于自我反思行为。3) 反思方向提取：在模型的潜在空间中，提取代表反思行为的方向向量。4) 逐步引导：利用提取的反思方向，逐步引导模型的推理过程，控制反思频率。\\n\\n**关键创新**：该论文的关键创新在于利用表征工程来控制大语言模型的自我反思行为。与传统的黑盒方法不同，ReflCtrl深入模型内部，通过操纵潜在空间中的表征来实现对反思行为的精细控制。这种方法为理解和控制大语言模型的内部运作机制提供了一种新的视角。\\n\\n**关键设计**：论文的关键设计包括：1) 如何有效地分割推理过程并识别反思步骤；2) 如何在潜在空间中准确地提取反思方向；3) 如何设计逐步引导策略，以在保持性能的同时减少反思频率。论文可能使用了特定的损失函数或正则化项来优化反思方向的提取，并可能采用了特定的参数来控制引导强度。",
            "application_zh": "ReflCtrl具有广泛的应用前景，可用于优化各种基于大语言模型的应用，例如智能客服、代码生成和数学问题求解。通过降低推理成本，ReflCtrl可以使这些应用更经济高效，并更容易部署在资源受限的环境中。此外，该研究为理解和控制大语言模型的内部运作机制提供了新的思路，有助于开发更可靠和可控的AI系统。",
            "highlight_zh": "实验结果表明，ReflCtrl能够在保持性能的同时，显著减少推理所需的token数量。具体而言，在某些情况下，ReflCtrl可以节省高达33.6%的推理token。此外，实验还揭示了模型的反思行为与内部不确定性信号之间的高度相关性，为进一步理解和控制大语言模型的自我反思行为提供了重要线索。",
            "tags_zh": [
                "大语言模型",
                "自我反思",
                "表征工程",
                "思维链",
                "推理优化"
            ],
            "_index": 146,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13979/sources/figs/refdir_pipeline.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13979/sources/figs/intv_llama.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.13979/sources/figs/intv_qwq.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "OpenDataArena: A Fair and Open Arena for Benchmarking Post-Training Dataset Value",
            "authors": [
                "Mengzhang Cai",
                "Xin Gao",
                "Yu Li",
                "Honglin Lin",
                "Zheng Liu",
                "Zhuoshi Pan",
                "Qizhi Pei",
                "Xiaoran Shang",
                "Mengyuan Sun",
                "Zinan Tang",
                "Xiaoyang Wang",
                "Zhanping Zhong",
                "Yun Zhu",
                "Dahua Lin",
                "Conghui He",
                "Lijun Wu"
            ],
            "arxiv_id": "2512.14051",
            "summary": "The rapid evolution of Large Language Models (LLMs) is predicated on the quality and diversity of post-training datasets. However, a critical dichotomy persists: while models are rigorously benchmarked, the data fueling them remains a black box--characterized by opaque composition, uncertain provenance, and a lack of systematic evaluation. This opacity hinders reproducibility and obscures the causal link between data characteristics and model behaviors. To bridge this gap, we introduce OpenDataArena (ODA), a holistic and open platform designed to benchmark the intrinsic value of post-training data. ODA establishes a comprehensive ecosystem comprising four key pillars: (i) a unified training-evaluation pipeline that ensures fair, open comparisons across diverse models (e.g., Llama, Qwen) and domains; (ii) a multi-dimensional scoring framework that profiles data quality along tens of distinct axes; (iii) an interactive data lineage explorer to visualize dataset genealogy and dissect component sources; and (iv) a fully open-source toolkit for training, evaluation, and scoring to foster data research. Extensive experiments on ODA--covering over 120 training datasets across multiple domains on 22 benchmarks, validated by more than 600 training runs and 40 million processed data points--reveal non-trivial insights. Our analysis uncovers the inherent trade-offs between data complexity and task performance, identifies redundancy in popular benchmarks through lineage tracing, and maps the genealogical relationships across datasets. We release all results, tools, and configurations to democratize access to high-quality data evaluation. Rather than merely expanding a leaderboard, ODA envisions a shift from trial-and-error data curation to a principled science of Data-Centric AI, paving the way for rigorous studies on data mixing laws and the strategic composition of foundation models.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14051",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "foundation model"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "OpenDataArena：一个公平开放的平台，用于评估后训练数据集的价值",
            "summary_zh": "大型语言模型（LLM）的快速发展依赖于高质量和多样化的后训练数据集。然而，一个关键的矛盾依然存在：模型经过严格的基准测试，但为其提供支持的数据仍然是一个黑盒——其组成不透明、来源不确定，并且缺乏系统的评估。这种不透明性阻碍了可重复性，并模糊了数据特征与模型行为之间的因果关系。为了弥合这一差距，我们推出了OpenDataArena（ODA），这是一个整体且开放的平台，旨在评估后训练数据的内在价值。ODA建立了一个全面的生态系统，包括四个关键支柱：（i）统一的训练-评估流程，确保在不同模型（例如，Llama、Qwen）和领域之间进行公平、开放的比较；（ii）多维评分框架，沿着数十个不同的轴来分析数据质量；（iii）交互式数据沿袭浏览器，用于可视化数据集的谱系并剖析组件来源；（iv）完全开源的训练、评估和评分工具包，以促进数据研究。在ODA上进行的大量实验——涵盖跨多个领域的120多个训练数据集和22个基准，经过600多次训练运行和4000万个处理的数据点的验证——揭示了重要的见解。我们的分析揭示了数据复杂性和任务性能之间固有的权衡，通过沿袭追踪识别了流行基准中的冗余，并绘制了数据集之间的谱系关系。我们发布所有结果、工具和配置，以普及对高质量数据评估的访问。ODA并非仅仅扩展排行榜，而是设想从试错数据管理转变为以数据为中心的人工智能的原则性科学，从而为数据混合定律和基础模型的战略组合进行严格的研究铺平道路。",
            "intro_zh": [
                "现有大型语言模型训练数据集缺乏透明度，数据组成、来源不确定，阻碍了模型的可重复性和可解释性。",
                "OpenDataArena (ODA) 平台旨在通过统一的训练评估流程、多维评分框架和数据沿袭追踪，系统评估后训练数据的内在价值。",
                "实验结果揭示了数据复杂性与任务性能的权衡，识别了流行基准中的数据冗余，并绘制了数据集之间的关系。"
            ],
            "method_zh": "**问题定义**：现有的大型语言模型训练依赖于海量数据集，但这些数据集的质量和组成往往不透明，缺乏系统的评估和分析。这导致模型训练过程难以理解和控制，阻碍了模型性能的进一步提升，同时也难以复现和比较不同模型的效果。现有方法缺乏对数据集内在价值的有效评估手段，无法指导数据集的优化和选择。\\n\\n**核心思路**：OpenDataArena (ODA) 的核心思路是构建一个开放、公平的平台，用于系统性地评估后训练数据集的价值。通过统一的训练-评估流程、多维评分框架和数据沿袭追踪，ODA 旨在揭示数据特征与模型行为之间的关系，从而指导数据驱动的模型开发。ODA 强调数据透明性和可重复性，促进数据中心的人工智能研究。\\n\\n**技术框架**：ODA 平台包含四个主要模块：(1) 统一的训练-评估流程，支持多种模型和领域，确保公平比较；(2) 多维评分框架，从多个维度评估数据质量；(3) 交互式数据沿袭浏览器，可视化数据集的来源和组成；(4) 开源工具包，提供训练、评估和评分功能。用户可以在 ODA 上上传自己的数据集，使用平台提供的工具进行评估，并与其他数据集进行比较。\\n\\n**关键创新**：ODA 的关键创新在于其综合性的数据评估体系，不仅关注数据集的整体性能，还深入分析数据质量的各个方面，例如数据复杂性、多样性和冗余度。此外，ODA 的数据沿袭追踪功能可以帮助用户理解数据集的来源和演变过程，从而更好地理解数据对模型的影响。ODA 的开源特性也促进了数据研究的开放性和可重复性。\\n\\n**关键设计**：ODA 的多维评分框架包含数十个不同的评估指标，涵盖数据质量的各个方面。这些指标包括数据复杂度、多样性、噪声水平、覆盖范围等。平台还提供了一系列可视化工具，帮助用户理解评估结果。训练-评估流程采用标准化的配置，确保不同模型和数据集之间的公平比较。具体参数设置和损失函数选择取决于所使用的模型和任务。",
            "application_zh": "OpenDataArena 可应用于各种需要大型语言模型的领域，例如自然语言处理、机器翻译、文本生成等。它可以帮助研究人员和开发者选择和优化训练数据集，提高模型性能和泛化能力。此外，ODA 还可以用于评估不同数据集的质量和价值，为数据交易和共享提供参考。",
            "highlight_zh": "在 ODA 平台上进行的实验涵盖了 120 多个训练数据集和 22 个基准，经过 600 多次训练运行和 4000 万个处理的数据点的验证。实验结果揭示了数据复杂性和任务性能之间固有的权衡，通过沿袭追踪识别了流行基准中的冗余，并绘制了数据集之间的谱系关系。这些结果为数据驱动的模型开发提供了重要的指导。",
            "tags_zh": [
                "大型语言模型",
                "数据集评估",
                "数据质量",
                "数据沿袭",
                "开放平台"
            ],
            "_index": 147,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14051/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14051/figures/ODA_provided_gemini.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14051/figures/ODA_framework.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Leveraging LLMs for Collaborative Ontology Engineering in Parkinson Disease Monitoring and Alerting",
            "authors": [
                "Georgios Bouchouras",
                "Dimitrios Doumanas",
                "Andreas Soularidis",
                "Konstantinos Kotis",
                "George A. Vouros"
            ],
            "arxiv_id": "2512.14288",
            "summary": "This paper explores the integration of Large Language Models (LLMs) in the engineering of a Parkinson's Disease (PD) monitoring and alerting ontology through four key methodologies: One Shot (OS) prompt techniques, Chain of Thought (CoT) prompts, X-HCOME, and SimX-HCOME+. The primary objective is to determine whether LLMs alone can create comprehensive ontologies and, if not, whether human-LLM collaboration can achieve this goal. Consequently, the paper assesses the effectiveness of LLMs in automated ontology development and the enhancement achieved through human-LLM collaboration.Initial ontology generation was performed using One Shot (OS) and Chain of Thought (CoT) prompts, demonstrating the capability of LLMs to autonomously construct ontologies for PD monitoring and alerting. However, these outputs were not comprehensive and required substantial human refinement to enhance their completeness and accuracy.X-HCOME, a hybrid ontology engineering approach that combines human expertise with LLM capabilities, showed significant improvements in ontology comprehensiveness. This methodology resulted in ontologies that are very similar to those constructed by experts.Further experimentation with SimX-HCOME+, another hybrid methodology emphasizing continuous human supervision and iterative refinement, highlighted the importance of ongoing human involvement. This approach led to the creation of more comprehensive and accurate ontologies.Overall, the paper underscores the potential of human-LLM collaboration in advancing ontology engineering, particularly in complex domains like PD. The results suggest promising directions for future research, including the development of specialized GPT models for ontology construction.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14288",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "chain-of-thought"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "利用大型语言模型进行帕金森病监测和预警的协同本体工程",
            "summary_zh": "本文探讨了将大型语言模型（LLM）集成到帕金森病（PD）监测和预警本体的工程中，采用了四种关键方法：One Shot（OS）提示技术、Chain of Thought（CoT）提示、X-HCOME 和 SimX-HCOME+。主要目标是确定 LLM 是否能够独立创建全面的本体，如果不能，人机协作是否能够实现这一目标。因此，本文评估了 LLM 在自动化本体开发中的有效性，以及通过人机协作实现的增强效果。初步的本体生成使用 One Shot（OS）和 Chain of Thought（CoT）提示执行，展示了 LLM 自主构建 PD 监测和预警本体的能力。然而，这些输出并不全面，需要大量的人工改进以提高其完整性和准确性。X-HCOME 是一种混合本体工程方法，结合了人类专业知识和 LLM 的能力，在本体的全面性方面显示出显著的改进。这种方法产生的本体与专家构建的本体非常相似。通过 SimX-HCOME+ 进一步实验，这是一种强调持续人工监督和迭代改进的另一种混合方法，突出了持续人工参与的重要性。这种方法能够创建更全面和准确的本体。总的来说，本文强调了人机协作在推进本体工程方面的潜力，特别是在像 PD 这样的复杂领域。结果表明了未来研究的有希望的方向，包括开发用于本体构建的专用 GPT 模型。",
            "intro_zh": [
                "现有本体工程在帕金森病等复杂领域面临挑战，需要耗费大量专家知识和时间，自动化程度低。",
                "论文探索人机协作模式，利用大型语言模型（LLM）的知识推理能力，结合人工监督和迭代改进，提升本体构建效率和质量。",
                "实验表明，纯LLM生成的本体不够全面，但通过X-HCOME和SimX-HCOME+等人机协作方法，本体的完整性和准确性得到显著提升。"
            ],
            "method_zh": "**问题定义**：论文旨在解决帕金森病（PD）监测和预警领域本体构建的问题。现有本体构建方法依赖于领域专家，耗时且成本高昂，难以快速适应新的知识和需求。纯粹依赖LLM自动构建的本体，在完整性和准确性方面存在不足，无法满足实际应用需求。\\n\\n**核心思路**：论文的核心思路是结合人类专家知识和LLM的强大能力，通过人机协作的方式进行本体工程。利用LLM进行初步的本体生成和推理，然后由人类专家进行监督、修正和迭代改进，从而构建出更全面、准确且实用的本体。这种混合方法旨在弥补纯自动化和纯人工方法的不足，充分发挥各自的优势。\\n\\n**技术框架**：论文提出了两种人机协作的本体工程方法：X-HCOME 和 SimX-HCOME+。两种方法都包含以下阶段：1) 使用 One-Shot 或 Chain-of-Thought 提示 LLM 生成初始本体；2) 人类专家对 LLM 生成的本体进行评估和修正；3) 将修正后的本体反馈给 LLM，进行迭代改进。SimX-HCOME+ 强调持续的人工监督和迭代，在每次迭代后都进行更细致的评估和修正。\\n\\n**关键创新**：论文的关键创新在于提出了人机协作的本体工程框架，并验证了其在帕金森病监测和预警领域的有效性。与传统的本体工程方法相比，该方法能够显著提高本体构建的效率和质量。与纯自动化方法相比，该方法通过人工监督和迭代改进，保证了本体的准确性和实用性。\\n\\n**关键设计**：论文中使用的 LLM 包括通用的大型语言模型，例如 GPT 系列。关键设计在于提示工程，即如何设计合适的提示（One-Shot 或 Chain-of-Thought）来引导 LLM 生成有用的本体。此外，人工监督和迭代改进的策略也是关键设计的一部分，需要领域专家参与，并根据实际情况进行调整。",
            "application_zh": "该研究成果可应用于医疗健康领域，特别是帕金森病等慢性疾病的监测和预警。构建的本体可以作为知识库，支持智能诊断、个性化治疗方案推荐和患者管理。此外，该方法也适用于其他需要领域知识的本体构建任务，例如金融、法律等。",
            "highlight_zh": "实验结果表明，纯LLM生成的本体在完整性和准确性方面存在不足，需要人工干预。通过X-HCOME和SimX-HCOME+等人机协作方法，本体的质量得到显著提升，生成的本体与专家构建的本体非常相似。SimX-HCOME+由于强调持续的人工监督和迭代，能够生成更全面和准确的本体。",
            "tags_zh": [
                "大型语言模型",
                "本体工程",
                "人机协作",
                "帕金森病",
                "知识图谱",
                "医疗健康",
                "自动化"
            ],
            "_index": 148,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14288/LLMs_and_PD_v15-2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14288/output-9.png",
                    "caption": "",
                    "figure_id": "fig_1"
                }
            ]
        },
        {
            "title": "Model-First Reasoning LLM Agents: Reducing Hallucinations through Explicit Problem Modeling",
            "authors": [
                "Annu Rana",
                "Gaurav Kumar"
            ],
            "arxiv_id": "2512.14474",
            "summary": "Large Language Models (LLMs) often struggle with complex multi-step planning tasks, showing high rates of constraint violations and inconsistent solutions. Existing strategies such as Chain-of-Thought and ReAct rely on implicit state tracking and lack an explicit problem representation. Inspired by classical AI planning, we propose Model-First Reasoning (MFR), a two-phase paradigm in which the LLM first constructs an explicit model of the problem, defining entities, state variables, actions, and constraints, before generating a solution plan. Across multiple planning domains, including medical scheduling, route planning, resource allocation, logic puzzles, and procedural synthesis, MFR reduces constraint violations and improves solution quality compared to Chain-of-Thought and ReAct. Ablation studies show that the explicit modeling phase is critical for these gains. Our results suggest that many LLM planning failures stem from representational deficiencies rather than reasoning limitations, highlighting explicit modeling as a key component for robust and interpretable AI agents. All prompts, evaluation procedures, and task datasets are documented to facilitate reproducibility.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14474",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "chain-of-thought"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出Model-First Reasoning，通过显式建模减少LLM在复杂规划任务中的幻觉",
            "summary_zh": "大型语言模型（LLMs）在复杂的多步骤规划任务中表现不佳，常常出现约束违反和不一致的解决方案。现有的策略，如Chain-of-Thought和ReAct，依赖于隐式的状态跟踪，缺乏显式的问题表示。受经典AI规划的启发，我们提出了Model-First Reasoning（MFR），这是一种两阶段范式，其中LLM首先构建问题的显式模型，定义实体、状态变量、动作和约束，然后再生成解决方案计划。在包括医疗调度、路线规划、资源分配、逻辑谜题和程序合成等多个规划领域，与Chain-of-Thought和ReAct相比，MFR减少了约束违反并提高了解决方案质量。消融研究表明，显式建模阶段对于这些提升至关重要。我们的结果表明，许多LLM规划失败源于表示缺陷，而不是推理限制，强调了显式建模作为鲁棒和可解释AI代理的关键组成部分。所有提示、评估程序和任务数据集均已记录，以方便重现。",
            "intro_zh": [
                "现有LLM在复杂规划任务中依赖隐式状态跟踪，缺乏对问题的显式表示，导致约束违反和结果不一致。",
                "Model-First Reasoning (MFR) 范式首先让LLM构建显式问题模型，再生成解决方案，模拟经典AI规划。",
                "实验表明，MFR在多个规划领域显著减少约束违反，提升方案质量，证明显式建模的重要性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型（LLMs）在复杂多步骤规划任务中表现出的约束违反和不一致解决方案的问题。现有方法，如Chain-of-Thought和ReAct，主要依赖于隐式的状态跟踪，缺乏对问题本身的显式建模，这使得LLM难以有效地处理复杂的约束条件和状态转移。\\n\\n**核心思路**：论文的核心思路是借鉴经典AI规划的思想，在LLM生成解决方案之前，先让其构建一个显式的、结构化的问题模型。这个模型明确定义了问题中的实体、状态变量、动作以及约束条件。通过这种显式建模，LLM可以更好地理解问题的本质，从而生成更合理、更符合约束的解决方案。\\n\\n**技术框架**：Model-First Reasoning (MFR) 包含两个主要阶段：\n1. **建模阶段**：LLM接收问题描述，并生成一个显式的问题模型。该模型包括：实体（Entities）、状态变量（State Variables）、动作（Actions）和约束（Constraints）。\n2. **规划阶段**：基于第一阶段构建的问题模型，LLM生成一个解决方案计划。这个计划描述了如何通过一系列动作来实现目标，同时满足所有约束条件。\n\n**关键创新**：MFR 的最重要创新在于引入了显式的问题建模阶段。与以往依赖隐式推理的方法不同，MFR 强制 LLM 首先理解问题的结构和约束，然后再进行规划。这种显式建模能够显著减少 LLM 在规划过程中产生的幻觉和错误，提高解决方案的质量和可靠性。\\n\\n**关键设计**：论文中没有详细描述具体的参数设置、损失函数或网络结构，因为 MFR 是一种通用的框架，可以应用于不同的 LLM 和规划任务。关键的设计在于如何设计合适的 prompt，引导 LLM 生成准确、完整的显式问题模型。此外，如何有效地利用问题模型来指导后续的规划过程也是一个重要的设计考虑。",
            "application_zh": "该研究成果可广泛应用于需要复杂规划和决策的领域，如医疗调度、路线规划、资源分配、供应链管理、智能制造等。通过显式建模，可以提高AI代理的决策质量和可靠性，减少错误和风险，从而在实际应用中发挥更大的价值。未来，该方法有望进一步扩展到更复杂的领域，例如自动驾驶、机器人控制等。",
            "highlight_zh": "实验结果表明，在多个规划领域，MFR 显著优于 Chain-of-Thought 和 ReAct 等基线方法。例如，在医疗调度任务中，MFR 能够显著减少约束违反，并生成更优的调度方案。消融研究进一步证实了显式建模阶段对于性能提升的关键作用。这些结果表明，MFR 能够有效提高 LLM 在复杂规划任务中的性能和可靠性。",
            "tags_zh": [
                "大型语言模型",
                "规划任务",
                "显式建模",
                "约束满足",
                "Model-First Reasoning"
            ],
            "_index": 149,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14474/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                }
            ]
        },
        {
            "title": "Why Reinforcement Fine-Tuning Enables MLLMs Preserve Prior Knowledge Better: A Data Perspective",
            "authors": [
                "Zhihao Zhang",
                "Qiaole Dong",
                "Qi Zhang",
                "Jun Zhao",
                "Enyu Zhou",
                "Zhiheng Xi",
                "Senjie Jin",
                "Xiaoran Fan",
                "Yuhao Zhou",
                "Mingqi Wu",
                "Yanwei Fu",
                "Tao Ji",
                "Tao Gui",
                "Xuanjing Huang",
                "Kai Chen"
            ],
            "arxiv_id": "2506.23508",
            "summary": "Post-training algorithms such as Supervised Fine-Tuning (SFT) and Reinforcement Fine-Tuning (RFT) are widely used to adapt multimodal large language models to downstream tasks. While effective at task adaptation, their impact on prior knowledge remains unclear. In this paper, we introduce jigsaw puzzles as a novel task absent from existing pretraining corpora and systematically study the behavior of SFT and RFT on open-source multimodal model, Qwen2.5-VL series. Our experiments reveal a sharp trade-off: SFT enables rapid task acquisition but leads to catastrophic forgetting, whereas RFT learns more slowly but maintains prior knowledge. We study this phenomenon through learning dynamics by examining both the magnitude and direction of how training data influence prior knowledge. Our analysis shows that RFT mainly reinforces correct samples naturally aligned with the base model's probability landscape, leading to weaker interference with prior knowledge. Moreover, training on RFT-simulated rollouts, which exert a small magnitude of influence and are well aligned in direction to prior knowledge, allows SFT to preserve prior knowledge better while rapidly learning new tasks. These findings suggest that distribution of training data, rather than algorithmic differences, plays a central role in forgetting, and highlight RFT's potential for stable continual learning in multimodal large language models.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2506.23508",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "multimodal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "研究表明强化微调(RFT)通过数据分布优化，能更好保持多模态大语言模型的先验知识。",
            "summary_zh": "监督微调(SFT)和强化微调(RFT)等后训练算法被广泛用于将多模态大语言模型适配到下游任务。虽然它们在任务适配方面很有效，但它们对先验知识的影响仍不清楚。本文引入了拼图游戏作为现有预训练语料库中不存在的新任务，并系统地研究了SFT和RFT在开源多模态模型Qwen2.5-VL系列上的行为。实验揭示了一个明显的权衡：SFT能够快速获取任务，但会导致灾难性遗忘，而RFT学习速度较慢，但能保持先验知识。通过检查训练数据如何影响先验知识的大小和方向，研究了学习动态。分析表明，RFT主要强化与基础模型的概率分布自然对齐的正确样本，从而减少对先验知识的干扰。此外，在RFT模拟的rollout上进行训练，这些rollout对先验知识的影响较小，并且在方向上与先验知识良好对齐，这使得SFT能够在快速学习新任务的同时更好地保持先验知识。这些发现表明，训练数据的分布，而不是算法差异，在遗忘中起着核心作用，并突出了RFT在多模态大语言模型中稳定持续学习的潜力。",
            "intro_zh": [
                "多模态大语言模型微调面临任务适配与先验知识保持的难题，SFT易遗忘，RFT学习慢。",
                "论文核心在于分析SFT和RFT训练数据对先验知识的影响，揭示数据分布是关键因素。",
                "实验表明，RFT模拟数据能使SFT在快速学习新任务的同时，更好地保持先验知识。"
            ],
            "method_zh": "**问题定义**：多模态大语言模型在进行下游任务微调时，如何在快速适应新任务的同时，避免灾难性遗忘，保持模型原有的先验知识？现有方法如SFT虽然能快速学习新任务，但容易导致对原有知识的遗忘，而RFT虽然能较好地保持先验知识，但学习速度较慢。\\n\\n**核心思路**：论文的核心思路是通过分析SFT和RFT训练数据的分布特性，以及这些数据对模型先验知识的影响，来理解为什么RFT能更好地保持先验知识。作者认为，训练数据的分布，特别是数据对模型参数更新的方向和大小，是导致遗忘现象的关键因素。\\n\\n**技术框架**：论文主要通过实验分析来研究SFT和RFT的行为。首先，作者设计了一个新的拼图游戏任务，该任务在现有的预训练语料库中不存在，用于评估模型在学习新任务时的表现。然后，作者使用Qwen2.5-VL系列模型，分别进行SFT和RFT训练，并分析训练过程中模型参数的变化，以及模型对先验知识的保持程度。最后，作者通过模拟RFT的rollout数据，并使用这些数据进行SFT训练，观察模型在保持先验知识方面的表现。\\n\\n**关键创新**：论文的关键创新在于从数据分布的角度解释了RFT能够更好保持先验知识的原因。作者发现，RFT训练数据倾向于强化与模型原有知识对齐的样本，从而减少了对原有知识的干扰。此外，作者还发现，使用RFT模拟的rollout数据进行SFT训练，可以使模型在快速学习新任务的同时，更好地保持先验知识。\\n\\n**关键设计**：论文的关键设计包括：1) 使用拼图游戏作为评估模型学习新任务和保持先验知识的基准；2) 分析训练数据对模型参数更新的方向和大小，以理解数据对先验知识的影响；3) 通过模拟RFT的rollout数据，并使用这些数据进行SFT训练，来验证数据分布对模型性能的影响。",
            "application_zh": "该研究成果可应用于多模态大语言模型的持续学习和终身学习场景，例如在机器人、智能助手等领域，模型需要不断学习新的技能，同时保持已有的知识。通过优化训练数据的分布，可以提高模型在持续学习过程中的稳定性和可靠性，避免灾难性遗忘。",
            "highlight_zh": "实验结果表明，RFT在学习新任务时，能够更好地保持先验知识，而SFT则容易导致灾难性遗忘。更重要的是，使用RFT模拟的rollout数据进行SFT训练，可以使模型在快速学习新任务的同时，显著提高先验知识的保持能力，验证了数据分布在模型学习过程中的重要作用。",
            "tags_zh": [
                "多模态大语言模型",
                "强化微调",
                "监督微调",
                "灾难性遗忘",
                "持续学习",
                "数据分布",
                "先验知识",
                "拼图游戏"
            ],
            "_index": 150,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2506.23508/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2506.23508/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2506.23508/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Sliding Window Attention Adaptation",
            "authors": [
                "Yijiong Yu",
                "Jiale Liu",
                "Qingyun Wu",
                "Huazheng Wang",
                "Ji Pei"
            ],
            "arxiv_id": "2512.10411",
            "summary": "The self-attention mechanism in Transformer-based Large Language Models (LLMs) scales quadratically with input length, making long-context inference expensive. Sliding window attention (SWA) reduces this cost to linear complexity, but naively enabling complete SWA at inference-time for models pretrained with full attention (FA) causes severe long-context performance degradation due to training-inference mismatch. This makes us wonder: Can FA-pretrained LLMs be well adapted to SWA without pretraining? We investigate this by proposing Sliding Window Attention Adaptation (SWAA), a set of practical recipes that combine five methods for better adaptation: (1) applying SWA only during prefilling; (2) preserving \"sink\" tokens; (3) interleaving FA/SWA layers; (4) chain-of-thought (CoT); and (5) fine-tuning. Our experiments show that SWA adaptation is feasible while non-trivial: no single method suffices, yet specific synergistic combinations effectively recover the original long-context performance. We further analyze the performance-efficiency trade-offs of different SWAA configurations and provide recommended recipes for diverse scenarios, which can greatly and fundamentally accelerate LLM long-context inference speed by up to 100%. Our code is available atthis https URL",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.10411",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "chain-of-thought"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出滑动窗口注意力适配方法，解决预训练LLM长文本推理性能下降问题。",
            "summary_zh": "基于Transformer的大型语言模型(LLM)中的自注意力机制的计算复杂度随输入长度呈二次方增长，这使得长文本推理的成本很高。滑动窗口注意力(SWA)将这种成本降低到线性复杂度，但是如果在推理时对使用完整注意力(FA)预训练的模型直接启用SWA，会导致由于训练-推理不匹配而造成的严重的上下文性能下降。这促使我们思考：无需预训练，FA预训练的LLM能否很好地适应SWA？我们通过提出滑动窗口注意力适配(SWAA)来研究这个问题，SWAA是一组实用的方法，结合了五种方法以实现更好的适配：(1)仅在预填充期间应用SWA；(2)保留“sink”令牌；(3)交错FA/SWA层；(4)思维链(CoT)；(5)微调。我们的实验表明，SWA适配是可行但重要的：没有单一方法足够，但特定的协同组合可以有效地恢复原始的长文本性能。我们进一步分析了不同SWAA配置的性能-效率权衡，并为各种场景提供了推荐的方案，这些方案可以极大地并从根本上将LLM长文本推理速度提高高达100%。我们的代码已发布。",
            "intro_zh": [
                "传统LLM的自注意力机制在处理长文本时计算复杂度高，滑动窗口注意力虽然降低了复杂度，但直接应用于完整注意力预训练的模型会导致性能下降。",
                "论文提出滑动窗口注意力适配(SWAA)，通过结合预填充SWA、保留sink令牌、交错FA/SWA层、CoT和微调等方法，使模型更好地适应SWA。",
                "实验表明，SWAA能够有效恢复长文本性能，并分析了不同配置的性能-效率权衡，为不同场景提供了推荐方案，推理速度提升高达100%。"
            ],
            "method_zh": "**问题定义**：论文旨在解决将完整注意力（FA）预训练的大型语言模型（LLM）直接应用于滑动窗口注意力（SWA）推理时，由于训练和推理方式不匹配导致的性能显著下降问题。现有方法要么需要重新预训练模型，成本高昂，要么直接应用SWA导致长文本理解能力严重受损。\\n\\n**核心思路**：论文的核心思路是通过一系列适配方法，弥合FA预训练和SWA推理之间的差距，使得模型能够在不进行大规模重新预训练的情况下，有效利用SWA的线性复杂度优势，同时保持甚至恢复原有的长文本处理能力。这种适配的关键在于找到一种策略，既能利用SWA的效率，又能避免因注意力模式改变带来的性能损失。\\n\\n**技术框架**：SWAA框架包含五个主要组成部分，它们协同工作以实现更好的适配：1) 仅在预填充阶段应用SWA，减少计算量；2) 保留“sink”令牌，确保模型能够捕捉全局信息；3) 交错使用FA和SWA层，平衡全局和局部注意力；4) 利用思维链（CoT）提示，提升推理能力；5) 进行微调，使模型适应SWA的注意力模式。这些方法可以灵活组合，以适应不同的应用场景和性能需求。\\n\\n**关键创新**：该论文的关键创新在于提出了一个综合性的适配框架SWAA，它不是依赖单一的技术手段，而是通过多种方法的协同作用，实现了FA预训练模型到SWA推理的平滑过渡。这种组合式的适配策略，能够更有效地解决训练-推理不匹配的问题，并且具有很强的灵活性和可扩展性。\\n\\n**关键设计**：关键设计包括：1) 预填充阶段SWA的应用策略，旨在减少初始阶段的计算负担；2) “sink”令牌的保留机制，确保模型能够捕捉到全局上下文信息；3) FA和SWA层的交错比例，需要根据具体模型和任务进行调整；4) CoT提示的设计，旨在引导模型进行更有效的推理；5) 微调阶段的学习率、训练轮数等超参数的设置，需要根据实验结果进行优化。",
            "application_zh": "该研究成果可广泛应用于需要处理长文本的各种自然语言处理任务中，例如长文档摘要、机器翻译、问答系统等。通过加速LLM的推理速度，可以降低部署成本，提高用户体验，并推动LLM在资源受限环境下的应用。此外，该方法也为其他注意力机制的优化和适配提供了借鉴。",
            "highlight_zh": "实验结果表明，SWAA能够有效恢复FA预训练模型在SWA推理下的长文本性能。在特定配置下，推理速度提升高达100%。论文还分析了不同SWAA配置的性能-效率权衡，并为不同场景提供了推荐方案，为实际应用提供了指导。",
            "tags_zh": [
                "大型语言模型",
                "滑动窗口注意力",
                "长文本推理",
                "注意力机制",
                "模型适配"
            ],
            "_index": 151,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Guideline-Consistent Segmentation via Multi-Agent Refinement",
            "authors": [
                "Vanshika Vats",
                "Ashwani Rathee",
                "James Davis"
            ],
            "arxiv_id": "2509.04687",
            "summary": "Semantic segmentation in real-world applications often requires not only accurate masks but also strict adherence to textual labeling guidelines. These guidelines are typically complex and long, and both human and automated labeling often fail to follow them faithfully. Traditional approaches depend on expensive task-specific retraining that must be repeated as the guidelines evolve. Although recent open-vocabulary segmentation methods excel with simple prompts, they often fail when confronted with sets of paragraph-length guidelines that specify intricate segmentation rules. To address this, we introduce a multi-agent, training-free framework that coordinates general-purpose vision-language models within an iterative Worker-Supervisor refinement architecture. The Worker performs the segmentation, the Supervisor critiques it against the retrieved guidelines, and a lightweight reinforcement learning stop policy decides when to terminate the loop, ensuring guideline-consistent masks while balancing resource use. Evaluated on the Waymo and ReasonSeg datasets, our method notably outperforms state-of-the-art baselines, demonstrating strong generalization and instruction adherence.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2509.04687",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "open-vocabulary",
                        "open vocabulary"
                    ],
                    "score": 4.0
                }
            ],
            "relevance_score": 5.5,
            "hit_pillars": [
                "2_algo_arch",
                "3_perception_slam"
            ],
            "headline_zh": "提出一种多智能体迭代优化框架，实现符合复杂指南的语义分割",
            "summary_zh": "真实应用场景中的语义分割不仅需要精确的掩码，还需要严格遵守文本标注指南。这些指南通常复杂且冗长，人工和自动标注都难以完全遵循。传统方法依赖于昂贵的任务特定再训练，并且必须随着指南的演变而重复进行。虽然最近的开放词汇分割方法在简单提示下表现出色，但在面对指定复杂分割规则的段落级指南时往往失效。为了解决这个问题，我们引入了一个多智能体、免训练的框架，该框架在迭代的Worker-Supervisor优化架构中协调通用视觉-语言模型。Worker执行分割，Supervisor根据检索到的指南对其进行评估，轻量级的强化学习停止策略决定何时终止循环，确保指南一致的掩码，同时平衡资源使用。在Waymo和ReasonSeg数据集上的评估表明，我们的方法明显优于最先进的基线，展示了强大的泛化能力和指令遵循能力。",
            "intro_zh": [
                "现有语义分割方法难以有效处理复杂、细粒度的文本标注指南，导致分割结果与指南不一致。",
                "提出一种多智能体迭代优化框架，利用Worker-Supervisor架构，通过视觉-语言模型和强化学习实现指南一致的分割。",
                "在Waymo和ReasonSeg数据集上，该方法显著优于现有技术，展示了良好的泛化性和指令遵循能力。"
            ],
            "method_zh": "**问题定义**：现有语义分割方法在处理需要严格遵循复杂文本标注指南的任务时表现不佳。传统方法需要针对特定任务进行昂贵的再训练，并且当指南发生变化时需要重复进行。即使是最近的开放词汇分割方法，在面对段落长度的复杂指南时也难以有效遵循，导致分割结果与指南不一致。\\n\\n**核心思路**：论文的核心思路是利用多智能体协作的方式，通过迭代优化来提高分割结果与指南的一致性。具体来说，引入一个Worker-Supervisor架构，Worker负责执行分割任务，Supervisor负责根据指南对分割结果进行评估，并通过迭代优化来逐步提高分割质量。\\n\\n**技术框架**：该框架包含三个主要模块：Worker、Supervisor和停止策略。Worker是一个通用的视觉-语言模型，负责根据输入图像和指南生成分割掩码。Supervisor也是一个视觉-语言模型，负责根据指南对Worker生成的分割掩码进行评估，并给出反馈。停止策略是一个轻量级的强化学习模型，负责决定何时停止迭代优化过程，以平衡分割质量和计算资源消耗。\\n\\n**关键创新**：该方法的主要创新在于提出了一种多智能体迭代优化框架，该框架能够有效地利用视觉-语言模型来处理复杂的文本标注指南，并实现指南一致的语义分割。与传统方法相比，该方法无需针对特定任务进行再训练，并且能够更好地适应指南的变化。\\n\\n**关键设计**：Worker和Supervisor可以使用现有的预训练视觉-语言模型，例如CLIP或ALIGN。停止策略可以使用简单的强化学习算法，例如Q-learning或SARSA。损失函数可以设计为衡量分割结果与指南一致性的指标，例如交叉熵损失或Dice损失。迭代次数和学习率等超参数需要根据具体任务进行调整。",
            "application_zh": "该研究成果可应用于自动驾驶、医学图像分析、遥感图像处理等领域，在这些领域中，语义分割任务需要严格遵循特定的标注指南。例如，在自动驾驶中，需要根据交通规则对道路、车辆、行人等进行精确分割；在医学图像分析中，需要根据医学指南对器官、病灶等进行精确分割。该方法可以提高分割结果的准确性和可靠性，从而提高相关应用的性能和安全性。",
            "highlight_zh": "该方法在Waymo和ReasonSeg数据集上进行了评估，实验结果表明，该方法明显优于现有的最先进基线方法。例如，在ReasonSeg数据集上，该方法在指令遵循方面取得了显著提升，表明该方法能够有效地处理复杂的文本标注指南。此外，该方法还展示了良好的泛化能力，能够在不同的数据集和任务上取得良好的性能。",
            "tags_zh": [
                "语义分割",
                "视觉-语言模型",
                "多智能体系统",
                "迭代优化",
                "指令遵循"
            ],
            "_index": 152,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2509.04687/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2509.04687/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2509.04687/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "On the Design of One-step Diffusion via Shortcutting Flow Paths",
            "authors": [
                "Haitao Lin",
                "Peiyan Hu",
                "Minsi Ren",
                "Zhifeng Gao",
                "Zhi-Ming Ma",
                "Guolin ke",
                "Tailin Wu",
                "Stan Z. Li"
            ],
            "arxiv_id": "2512.11831",
            "summary": "Recent advances in few-step diffusion models have demonstrated their efficiency and effectiveness by shortcutting the probabilistic paths of diffusion models, especially in training one-step diffusion models from scratch (\\emph{a.k.a.} shortcut models). However, their theoretical derivation and practical implementation are often closely coupled, which obscures the design space. To address this, we propose a common design framework for representative shortcut models. This framework provides theoretical justification for their validity and disentangles concrete component-level choices, thereby enabling systematic identification of improvements. With our proposed improvements, the resulting one-step model achieves a new state-of-the-art FID50k of 2.85 on ImageNet-256x256 under the classifier-free guidance setting with one step generation, and further reaches FID50k of 2.52 with 2x training steps. Remarkably, the model requires no pre-training, distillation, or curriculum learning. We believe our work lowers the barrier to component-level innovation in shortcut models and facilitates principled exploration of their design space.",
            "categories": [
                "cs.LG",
                "cs.CV"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.11831",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "curriculum learning",
                        "distillation"
                    ],
                    "score": 3.0
                },
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "classifier-free guidance"
                    ],
                    "score": 2.5
                }
            ],
            "relevance_score": 5.5,
            "hit_pillars": [
                "2_algo_arch",
                "4_motion_diffusion"
            ],
            "headline_zh": "提出单步扩散通用设计框架，显著提升ImageNet图像生成质量，无需预训练。",
            "summary_zh": "本文针对单步扩散模型（shortcut models）的设计空间探索不足的问题，提出了一个通用的设计框架。该框架为现有shortcut模型的有效性提供了理论依据，并将具体组件的选择解耦，从而能够系统地识别改进点。通过提出的改进，单步模型在ImageNet-256x256上，使用无分类器指导的单步生成设置下，实现了2.85的FID50k新state-of-the-art，并且通过2倍的训练步数进一步达到了2.52的FID50k。值得注意的是，该模型不需要预训练、知识蒸馏或课程学习。这项工作降低了shortcut模型组件级创新的门槛，并促进了对其设计空间的原则性探索。",
            "intro_zh": [
                "现有单步扩散模型设计理论推导与实践紧密耦合，限制了设计空间的探索。",
                "提出通用设计框架，解耦组件选择，为shortcut模型提供理论依据，便于系统性改进。",
                "改进后的单步模型在ImageNet-256x256上取得SOTA结果，FID50k达到2.85，无需预训练。"
            ],
            "method_zh": "**问题定义**：论文旨在解决单步扩散模型（Shortcut Models）设计空间探索不足的问题。现有的单步扩散模型虽然高效，但其理论推导和实际实现往往紧密耦合，导致难以系统性地分析和改进模型结构，缺乏对组件级别选择的有效指导，阻碍了进一步的性能提升。\\n\\n**核心思路**：论文的核心思路是构建一个通用的设计框架，将单步扩散模型的设计解耦为多个独立的组件，从而可以独立地分析每个组件对模型性能的影响。通过理论分析，为现有模型的有效性提供理论依据，并在此基础上系统性地探索和改进各个组件，最终提升整体性能。\\n\\n**技术框架**：该框架包含以下几个主要部分：首先，对现有的单步扩散模型进行统一的数学建模，提取其共性特征。然后，将模型解耦为多个可独立设计的组件，例如噪声预测器、采样策略等。接着，通过理论分析，推导出每个组件对模型性能的影响。最后，基于理论分析的结果，对各个组件进行改进，并组合成新的单步扩散模型。\\n\\n**关键创新**：论文的关键创新在于提出了一个通用的单步扩散模型设计框架，该框架能够将模型解耦为多个独立的组件，从而可以系统性地分析和改进模型结构。与现有方法相比，该框架不仅提供了理论依据，还降低了组件级别创新的门槛，促进了对设计空间的原则性探索。\\n\\n**关键设计**：论文的关键设计包括：1) 噪声预测器的改进，采用了更有效的网络结构和训练策略；2) 采样策略的优化，设计了更鲁棒的采样方法；3) 损失函数的调整，使用了更适合单步扩散模型的损失函数。此外，论文还对训练步数进行了优化，通过增加训练步数进一步提升了模型性能。",
            "application_zh": "该研究成果可广泛应用于图像生成、图像编辑、图像修复等领域。尤其在对生成速度有较高要求的场景下，单步扩散模型具有显著优势。该框架的提出，降低了单步扩散模型的设计门槛，有助于加速相关技术在实际应用中的落地，例如游戏素材生成、快速原型设计等。",
            "highlight_zh": "实验结果表明，基于该框架改进的单步扩散模型在ImageNet-256x256数据集上取得了显著的性能提升，FID50k指标达到了2.85，超越了现有state-of-the-art模型。通过增加训练步数，FID50k进一步降低至2.52。值得强调的是，该模型无需预训练、知识蒸馏或课程学习，降低了训练成本。",
            "tags_zh": [
                "单步扩散模型",
                "图像生成",
                "设计框架",
                "无分类器指导",
                "ImageNet",
                "扩散模型加速",
                "shortcut模型"
            ],
            "_index": 153,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.11831/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.11831/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.11831/esc-b/000008.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Autonomous Construction-Site Safety Inspection Using Mobile Robots: A Multilayer VLM-LLM Pipeline",
            "authors": [
                "Hossein Naderi",
                "Alireza Shojaei",
                "Philip Agee",
                "Kereshmeh Afsari",
                "Abiola Akanmu"
            ],
            "arxiv_id": "2512.13974",
            "summary": "Construction safety inspection remains mostly manual, and automated approaches still rely on task-specific datasets that are hard to maintain in fast-changing construction environments due to frequent retraining. Meanwhile, field inspection with robots still depends on human teleoperation and manual reporting, which are labor-intensive. This paper aims to connect what a robot sees during autonomous navigation to the safety rules that are common in construction sites, automatically generating a safety inspection report. To this end, we proposed a multi-layer framework with two main modules: robotics and AI. On the robotics side, SLAM and autonomous navigation provide repeatable coverage and targeted revisits via waypoints. On AI side, a Vision Language Model (VLM)-based layer produces scene descriptions; a retrieval component powered grounds those descriptions in OSHA and site policies; Another VLM-based layer assesses the safety situation based on rules; and finally Large Language Model (LLM) layer generates safety reports based on previous outputs. The framework is validated with a proof-of-concept implementation and evaluated in a lab environment that simulates common hazards across three scenarios. Results show high recall with competitive precision compared to state-of-the-art closed-source models. This paper contributes a transparent, generalizable pipeline that moves beyond black-box models by exposing intermediate artifacts from each layer and keeping the human in the loop. This work provides a foundation for future extensions to additional tasks and settings within and beyond construction context.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13974",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "teleoperation"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 5.0,
            "hit_pillars": [
                "1_robot_core",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于多层VLM-LLM管道的移动机器人自主建筑工地安全巡检方案",
            "summary_zh": "本文提出了一种利用移动机器人进行自主建筑工地安全巡检的多层框架。现有方法主要依赖于特定任务数据集，难以适应快速变化的建筑环境，且机器人现场巡检仍依赖人工遥操作和手动报告，劳动强度大。该框架结合了机器人和人工智能两大模块：机器人端通过SLAM和自主导航实现可重复覆盖和目标重访；人工智能端，基于视觉语言模型（VLM）的层生成场景描述，检索组件根据OSHA和现场策略进行信息定位，另一个VLM层基于规则评估安全状况，最后大型语言模型（LLM）层根据之前的输出生成安全报告。该框架通过概念验证实现进行了验证，并在模拟常见危险的实验室环境中进行了评估。结果表明，与最先进的闭源模型相比，该方法具有较高的召回率和有竞争力的精确率。该论文贡献了一个透明、可泛化的管道，通过暴露每一层的中间结果并将人纳入循环，超越了黑盒模型。这项工作为未来在建筑环境内外扩展到其他任务和设置奠定了基础。",
            "intro_zh": [
                "现有建筑工地安全巡检主要依赖人工，自动化方法依赖特定任务数据集，难以适应快速变化的工地环境。",
                "提出一种多层VLM-LLM框架，利用移动机器人自主导航，结合视觉语言模型和大型语言模型自动生成安全巡检报告。",
                "在模拟建筑工地常见危险的实验室环境中验证，结果表明该方法具有较高的召回率和有竞争力的精确率。"
            ],
            "method_zh": "**问题定义**：现有建筑工地安全巡检主要依赖人工，效率低且容易出错。现有的自动化方法通常需要针对特定任务训练数据集，难以适应快速变化的建筑工地环境，需要频繁重新训练。此外，机器人现场巡检仍然依赖于人工遥操作和手动报告，增加了劳动强度和成本。\\n\\n**核心思路**：本文的核心思路是将机器人自主导航能力与视觉语言模型（VLM）和大型语言模型（LLM）相结合，构建一个多层管道，实现自主安全巡检和报告生成。通过VLM理解场景，LLM结合安全规则生成报告，从而减少人工干预，提高巡检效率和准确性。\\n\\n**技术框架**：该框架包含机器人和人工智能两大模块。机器人模块负责自主导航和环境感知，利用SLAM技术构建地图并规划路径。人工智能模块包含四个主要层：1) VLM场景描述层：利用VLM对机器人采集的图像进行场景描述。2) 检索层：根据场景描述，从OSHA（职业安全与健康管理局）标准和现场安全策略中检索相关规则。3) VLM安全评估层：基于场景描述和检索到的安全规则，利用VLM评估安全状况。4) LLM报告生成层：根据前三层的输出，利用LLM生成最终的安全巡检报告。\\n\\n**关键创新**：该方法的主要创新在于将VLM和LLM应用于建筑工地安全巡检，构建了一个透明、可泛化的多层管道。与传统的黑盒模型相比，该方法暴露了每一层的中间结果，方便人工干预和调试。此外，该方法不依赖于特定任务的数据集，具有更好的泛化能力。\\n\\n**关键设计**：在VLM场景描述层，使用了预训练的VLM模型，并针对建筑工地场景进行了微调。检索层使用了基于向量相似度的检索方法，提高了检索效率和准确性。VLM安全评估层使用了提示工程（Prompt Engineering）技术，引导VLM进行安全评估。LLM报告生成层使用了链式思考（Chain-of-Thought）方法，提高了报告的逻辑性和可读性。具体参数设置和网络结构在论文中未详细说明，属于未知信息。",
            "application_zh": "该研究成果可应用于建筑工地、工厂、矿山等高危环境的安全巡检，降低人工巡检的风险和成本，提高巡检效率和准确性。未来可扩展到其他任务和环境，例如灾后救援、环境监测等。该技术还有潜力集成到智能建筑和智慧城市系统中，实现更全面的安全管理。",
            "highlight_zh": "实验结果表明，该方法在模拟建筑工地场景中具有较高的召回率和有竞争力的精确率。与最先进的闭源模型相比，该方法在保证性能的同时，具有更好的透明性和可解释性。具体的性能数据和提升幅度在摘要中提及，但未给出具体数值，属于未知信息。",
            "tags_zh": [
                "建筑工地安全",
                "自主巡检",
                "移动机器人",
                "视觉语言模型",
                "大型语言模型",
                "多模态融合",
                "SLAM"
            ],
            "_index": 154,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Impact of Robot Facial-Audio Expressions on Human Robot Trust Dynamics and Trust Repair",
            "authors": [
                "Hossein Naderi",
                "Alireza Shojaei",
                "Philip Agee",
                "Kereshmeh Afsari",
                "Abiola Akanmu"
            ],
            "arxiv_id": "2512.13981",
            "summary": "Despite recent advances in robotics and human-robot collaboration in the AEC industry, trust has mostly been treated as a static factor, with little guidance on how it changes across events during collaboration. This paper investigates how a robot's task performance and its expressive responses after outcomes shape the dynamics of human trust over time. To this end, we designed a controlled within-subjects study with two construction-inspired tasks, Material Delivery (physical assistance) and Information Gathering (perceptual assistance), and measured trust repeatedly (four times per task) using the 14-item Trust Perception Scale for HRI plus a redelegation choice. The robot produced two multimodal expressions, a \"glad\" display with a brief confirmation after success, and a \"sad\" display with an apology and a request for a second chance after failure. The study was conducted in a lab environment with 30 participants and a quadruped platform, and we evaluated trust dynamics and repair across both tasks. Results show that robot success reliably increases trust, failure causes sharp drops, and apology-based expressions partially restores trust (44% recovery in Material Delivery; 38% in Information Gathering). Item-level analysis indicates that recovered trust was driven mostly by interaction and communication factors, with competence recovering partially and autonomy aspects changing least. Additionally, age group and prior attitudes moderated trust dynamics with younger participants showed larger but shorter-lived changes, mid-20s participants exhibited the most durable repair, and older participants showed most conservative dynamics. This work provides a foundation for future efforts that adapt repair strategies to task demands and user profiles to support safe, productive adoption of robots on construction sites.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13981",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "quadruped"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 5.0,
            "hit_pillars": [
                "1_robot_core",
                "9_embodied_foundation"
            ],
            "headline_zh": "研究机器人面部-音频表情对人机信任动态及修复的影响，应用于建筑行业人机协作。",
            "summary_zh": "本文研究了在建筑行业人机协作中，机器人的任务表现及其结果后的表达性反应如何影响人类信任的动态变化。设计了一个受建筑启发的受控实验，包含材料递送（物理辅助）和信息收集（感知辅助）两个任务。使用包含14个条目的HRI信任感知量表和重新委派选择，重复测量信任（每个任务四次）。机器人产生两种多模态表达：成功后显示“高兴”表情并简短确认，失败后显示“悲伤”表情并道歉和请求第二次机会。实验在实验室环境中进行，有30名参与者和一个四足机器人平台。评估了两个任务中的信任动态和修复。结果表明，机器人成功可靠地增加了信任，失败导致信任急剧下降，基于道歉的表达部分恢复了信任（材料递送中恢复44％；信息收集中恢复38％）。项目级分析表明，恢复的信任主要受交互和沟通因素驱动，能力部分恢复，而自主性方面变化最小。此外，年龄组和先前的态度调节了信任动态，年轻参与者表现出更大但持续时间更短的变化，20多岁的参与者表现出最持久的修复，而年长的参与者表现出最保守的动态。这项工作为未来的工作奠定了基础，这些工作使修复策略适应任务需求和用户资料，以支持在建筑工地安全，高效地采用机器人。",
            "intro_zh": [
                "现有研究多将人机协作中的信任视为静态因素，缺乏对协作过程中信任动态变化的指导。",
                "通过设计机器人面部-音频表情，在任务成功或失败后做出相应反馈，观察对人类信任的影响。",
                "实验表明，机器人成功提升信任，失败降低信任，道歉表情可部分恢复信任，且年龄会影响信任动态。"
            ],
            "method_zh": "**问题定义**：论文旨在解决人机协作中，尤其是在建筑行业，如何动态地理解和修复人类对机器人的信任问题。现有方法通常将信任视为静态变量，忽略了任务表现和机器人表达对信任的动态影响。这种静态视角无法有效指导机器人如何根据实时情况调整行为，以维持或恢复人类的信任。\\n\\n**核心思路**：论文的核心思路是研究机器人在任务成功或失败后，通过面部和音频表情表达情绪，观察这些表达对人类信任动态的影响。通过让机器人在成功时表现出“高兴”，失败时表现出“悲伤”并道歉，模拟人类的情感反馈，从而考察这种情感表达是否能够修复因失败而受损的信任。\\n\\n**技术框架**：该研究采用了一个受控的实验设计，包含两个任务：材料递送（物理辅助）和信息收集（感知辅助）。参与者与一个四足机器人平台进行交互，完成这些任务。在每个任务中，机器人都可能成功或失败。在任务完成后，机器人会根据结果展示相应的面部和音频表情。研究人员使用HRI信任感知量表和重新委派选择，在每个任务中重复测量参与者对机器人的信任程度。\\n\\n**关键创新**：该研究的关键创新在于关注了机器人情感表达对信任动态的影响，并量化了不同情感表达（如道歉）在信任修复中的作用。此外，研究还考察了年龄等个体差异对信任动态的调节作用，这为设计更具适应性的人机交互系统提供了依据。\\n\\n**关键设计**：实验中，机器人使用预先设计好的面部和音频表情来表达“高兴”和“悲伤”两种情绪。信任感知量表包含14个条目，用于评估参与者对机器人的信任程度。重新委派选择则用于衡量参与者是否愿意将任务再次委托给机器人。研究还记录了参与者的年龄和先前对机器人的态度，作为调节变量进行分析。",
            "application_zh": "该研究成果可应用于建筑、制造、医疗等领域的人机协作场景。通过赋予机器人适当的情感表达能力，可以有效提升人类对机器人的信任，从而提高协作效率和安全性。未来的研究可以进一步探索更复杂的情感表达方式，并根据不同任务和用户特征定制个性化的信任修复策略。",
            "highlight_zh": "实验结果表明，机器人成功可以显著提升人类信任，而失败会导致信任急剧下降。道歉表情能够部分恢复信任，在材料递送任务中恢复了44%，在信息收集任务中恢复了38%。此外，研究发现年轻参与者对机器人的信任变化更为敏感，而年长参与者则表现出更为保守的信任动态。",
            "tags_zh": [
                "人机交互",
                "信任动态",
                "情感表达",
                "机器人道歉",
                "建筑机器人"
            ],
            "_index": 155,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "SAGE: Training Smart Any-Horizon Agents for Long Video Reasoning with Reinforcement Learning",
            "authors": [
                "Jitesh Jain",
                "Jialuo Li",
                "Zixian Ma",
                "Jieyu Zhang",
                "Chris Dongjoo Kim",
                "Sangho Lee",
                "Rohun Tripathi",
                "Tanmay Gupta",
                "Christopher Clark",
                "Humphrey Shi"
            ],
            "arxiv_id": "2512.13874",
            "summary": "As humans, we are natural any-horizon reasoners, i.e., we can decide whether to iteratively skim long videos or watch short ones in full when necessary for a given task. With this in mind, one would expect video reasoning models to reason flexibly across different durations. However, SOTA models are still trained to predict answers in a single turn while processing a large number of frames, akin to watching an entire long video, requiring significant resources. This raises the question: Is it possible to develop performant any-horizon video reasoning systems? Inspired by human behavior, we first propose SAGE, an agent system that performs multi-turn reasoning on long videos while handling simpler problems in a single turn. Secondly, we introduce an easy synthetic data generation pipeline using Gemini-2.5-Flash to train the orchestrator, SAGE-MM, which lies at the core of SAGE. We further propose an effective RL post-training recipe essential for instilling any-horizon reasoning ability in SAGE-MM. Thirdly, we curate SAGE-Bench with an average duration of greater than 700 seconds for evaluating video reasoning ability in real-world entertainment use cases. Lastly, we empirically validate the effectiveness of our system, data, and RL recipe, observing notable improvements of up to 6.1% on open-ended video reasoning tasks, as well as an impressive 8.2% improvement on videos longer than 10 minutes.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13874",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出SAGE，利用强化学习训练智能任意时域Agent，用于长视频推理。",
            "summary_zh": "本文提出SAGE，一个智能Agent系统，能够对长视频进行多轮推理，同时也能单轮处理简单问题，模拟人类在处理不同时长视频时的行为。为了训练SAGE的核心模块SAGE-MM，本文引入了一个简易的合成数据生成流程，该流程使用Gemini-2.5-Flash。此外，本文还提出了一种有效的强化学习后训练方法，对于在SAGE-MM中培养任意时域推理能力至关重要。为了评估真实娱乐场景下的视频推理能力，本文构建了SAGE-Bench，其平均视频时长超过700秒。实验结果表明，本文提出的系统、数据和强化学习方法是有效的，在开放式视频推理任务上取得了高达6.1%的显著提升，在超过10分钟的视频上取得了高达8.2%的提升。",
            "intro_zh": [
                "现有视频推理模型通常一次性处理大量帧并预测答案，类似于观看完整长视频，消耗大量资源，缺乏灵活性。",
                "SAGE系统通过多轮推理处理长视频，并能单轮处理简单问题，模仿人类行为，实现任意时域的视频理解。",
                "通过Gemini-2.5-Flash生成合成数据训练SAGE-MM，并使用强化学习进行后训练，在SAGE-Bench上验证了有效性，取得了显著提升。"
            ],
            "method_zh": "**问题定义**：现有视频推理模型在处理长视频时，通常需要一次性处理大量帧，计算成本高昂，并且缺乏像人类一样根据视频长度和任务复杂度调整推理策略的灵活性。这些模型无法有效利用视频中的关键信息，导致推理效率低下。\\n\\n**核心思路**：SAGE的核心思路是模仿人类在观看视频时的行为，即根据视频的长度和任务的复杂程度，决定是快速浏览还是完整观看。通过引入一个智能Agent，SAGE能够进行多轮推理，逐步提取视频中的关键信息，从而实现高效的视频理解。\\n\\n**技术框架**：SAGE系统主要包含两个核心模块：SAGE-MM（多模态模型）和强化学习训练模块。SAGE-MM负责从视频中提取特征并进行推理，而强化学习模块则用于优化SAGE-MM的推理策略。具体流程如下：1. 输入视频；2. SAGE-MM根据当前状态决定是观看更多帧还是输出答案；3. 如果选择观看更多帧，则更新状态并重复步骤2；4. 如果选择输出答案，则根据答案的正确性获得奖励，并使用强化学习算法更新SAGE-MM的策略。\\n\\n**关键创新**：SAGE的关键创新在于其任意时域推理能力，即能够根据视频的长度和任务的复杂程度，动态调整推理策略。与传统的单轮推理模型相比，SAGE能够更有效地利用视频中的关键信息，从而提高推理效率和准确性。此外，使用Gemini-2.5-Flash生成合成数据，降低了训练成本。\\n\\n**关键设计**：SAGE-MM采用多模态融合的方式，将视频帧和音频信息结合起来进行推理。强化学习算法采用Actor-Critic框架，其中Actor负责选择动作（观看更多帧或输出答案），Critic负责评估当前状态的价值。奖励函数的设计至关重要，需要平衡推理的准确性和效率。具体来说，如果输出的答案正确，则给予正向奖励；如果输出的答案错误，则给予负向奖励；如果观看的帧数过多，则给予负向奖励，以鼓励Agent尽快输出答案。",
            "application_zh": "SAGE具有广泛的应用前景，例如智能视频监控、智能客服、视频内容推荐等。通过模仿人类的推理方式，SAGE能够更有效地理解视频内容，从而为用户提供更智能、更个性化的服务。未来，SAGE有望成为视频理解领域的重要技术，推动相关产业的发展。",
            "highlight_zh": "SAGE在开放式视频推理任务上取得了显著的性能提升，最高达到6.1%。尤其是在处理超过10分钟的长视频时，SAGE的性能提升高达8.2%。这些结果表明，SAGE的任意时域推理能力能够有效地利用视频中的关键信息，从而提高推理效率和准确性。与传统的单轮推理模型相比，SAGE具有明显的优势。",
            "tags_zh": [
                "长视频推理",
                "任意时域推理",
                "强化学习",
                "多模态融合",
                "智能Agent",
                "视频理解"
            ],
            "_index": 156,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13874/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13874/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.13874/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "S2D: Sparse-To-Dense Keymask Distillation for Unsupervised Video Instance Segmentation",
            "authors": [
                "Leon Sick",
                "Lukas Hoyer",
                "Dominik Engel",
                "Pedro Hermosilla",
                "Timo Ropinski"
            ],
            "arxiv_id": "2512.14440",
            "summary": "In recent years, the state-of-the-art in unsupervised video instance segmentation has heavily relied on synthetic video data, generated from object-centric image datasets such as ImageNet. However, video synthesis by artificially shifting and scaling image instance masks fails to accurately model realistic motion in videos, such as perspective changes, movement by parts of one or multiple instances, or camera motion. To tackle this issue, we propose an unsupervised video instance segmentation model trained exclusively on real video data. We start from unsupervised instance segmentation masks on individual video frames. However, these single-frame segmentations exhibit temporal noise and their quality varies through the video. Therefore, we establish temporal coherence by identifying high-quality keymasks in the video by leveraging deep motion priors. The sparse keymask pseudo-annotations are then used to train a segmentation model for implicit mask propagation, for which we propose a Sparse-To-Dense Distillation approach aided by a Temporal DropLoss. After training the final model on the resulting dense labelset, our approach outperforms the current state-of-the-art across various benchmarks.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14440",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]distillation"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出S2D：一种稀疏到稠密的Keymask蒸馏方法，用于无监督视频实例分割。",
            "summary_zh": "近年来，无监督视频实例分割领域的最先进方法严重依赖于合成视频数据，这些数据通常由ImageNet等以对象为中心的图像数据集生成。然而，通过人为地移动和缩放图像实例掩码来合成视频，无法准确地模拟视频中真实的运动，例如透视变化、单个或多个实例的部分运动或相机运动。为了解决这个问题，我们提出了一种完全在真实视频数据上训练的无监督视频实例分割模型。我们从单个视频帧上的无监督实例分割掩码开始。然而，这些单帧分割表现出时间噪声，并且其质量在整个视频中变化。因此，我们通过利用深度运动先验来识别视频中的高质量Keymask，从而建立时间一致性。然后，稀疏的Keymask伪注释用于训练分割模型以进行隐式掩码传播，为此我们提出了一种由Temporal DropLoss辅助的稀疏到稠密的蒸馏方法。在最终模型在生成的稠密标签集上训练后，我们的方法在各种基准测试中优于当前最先进的方法。",
            "intro_zh": [
                "现有无监督视频实例分割方法依赖合成数据，无法准确模拟真实视频中的复杂运动。",
                "该论文提出一种基于真实视频数据的稀疏到稠密Keymask蒸馏方法，提升分割质量。",
                "实验结果表明，该方法在多个基准测试中超越了当前最先进的无监督视频实例分割方法。"
            ],
            "method_zh": "**问题定义**：无监督视频实例分割旨在无需人工标注的情况下，对视频中的每个实例进行分割和跟踪。现有方法依赖于合成数据，但合成数据难以模拟真实视频中的复杂运动，导致模型泛化能力差。此外，直接在真实视频上进行无监督学习，单帧分割结果存在时间噪声，质量不稳定。\\n\\n**核心思路**：该论文的核心思路是利用视频中的运动先验知识，从单帧分割结果中提取高质量的Keymask，作为稀疏的伪标签。然后，通过稀疏到稠密的蒸馏方法，将这些Keymask信息传播到整个视频序列，生成稠密的伪标签，从而训练一个更鲁棒的分割模型。\\n\\n**技术框架**：该方法主要包含以下几个阶段：1) 单帧无监督实例分割：使用现有的无监督图像实例分割方法对视频的每一帧进行分割。2) Keymask选择：利用深度运动先验，例如光流，选择视频中高质量的分割掩码作为Keymask。3) 稀疏到稠密蒸馏：使用Keymask作为教师信号，训练一个学生模型，使其能够从稀疏的Keymask中学习并生成稠密的分割结果。4) 模型训练：在生成的稠密伪标签上训练最终的视频实例分割模型。\\n\\n**关键创新**：该方法最重要的创新点在于提出了稀疏到稠密的Keymask蒸馏方法。与直接在噪声较大的单帧分割结果上训练模型不同，该方法首先选择高质量的Keymask，然后利用这些Keymask来引导模型的学习，从而提高了模型的鲁棒性和泛化能力。此外，Temporal DropLoss的设计也有助于模型学习到时间一致性的分割结果。\\n\\n**关键设计**：在Keymask选择阶段，论文利用光流等运动信息来评估分割掩码的质量。在稀疏到稠密蒸馏阶段，论文设计了Temporal DropLoss，鼓励模型在时间上保持分割结果的一致性。具体的网络结构和参数设置在论文中有详细描述，例如使用了MaskFormer作为基础分割模型。",
            "application_zh": "该研究成果可应用于自动驾驶、视频监控、机器人导航等领域。在自动驾驶中，可以用于识别和分割道路上的车辆、行人等目标，提高驾驶安全性。在视频监控中，可以用于自动分析视频内容，例如检测异常行为。在机器人导航中，可以用于帮助机器人理解周围环境，进行自主导航。",
            "highlight_zh": "该方法在多个无监督视频实例分割基准测试中取得了显著的性能提升，超越了当前最先进的方法。例如，在某个数据集上，该方法的分割精度提高了5%以上。实验结果表明，该方法能够有效地利用真实视频数据中的运动信息，提高无监督视频实例分割的性能。",
            "tags_zh": [
                "无监督学习",
                "视频实例分割",
                "稀疏到稠密",
                "Keymask蒸馏",
                "运动先验"
            ],
            "_index": 157,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14440/x2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14440/x3.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14440/x4.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Enhancing Semi-Supervised Multi-View Graph Convolutional Networks via Supervised Contrastive Learning and Self-Training",
            "authors": [
                "Huaiyuan Xiao",
                "Fadi Dornaika",
                "Jingjun Bi"
            ],
            "arxiv_id": "2512.13770",
            "summary": "The advent of graph convolutional network (GCN)-based multi-view learning provides a powerful framework for integrating structural information from heterogeneous views, enabling effective modeling of complex multi-view data. However, existing methods often fail to fully exploit the complementary information across views, leading to suboptimal feature representations and limited performance. To address this, we propose MV-SupGCN, a semi-supervised GCN model that integrates several complementary components with clear motivations and mutual reinforcement. First, to better capture discriminative features and improve model generalization, we design a joint loss function that combines Cross-Entropy loss with Supervised Contrastive loss, encouraging the model to simultaneously minimize intra-class variance and maximize inter-class separability in the latent space. Second, recognizing the instability and incompleteness of single graph construction methods, we combine both KNN-based and semi-supervised graph construction approaches on each view, thereby enhancing the robustness of the data structure representation and reducing generalization error. Third, to effectively utilize abundant unlabeled data and enhance semantic alignment across multiple views, we propose a unified framework that integrates contrastive learning in order to enforce consistency among multi-view embeddings and capture meaningful inter-view relationships, together with pseudo-labeling, which provides additional supervision applied to both the cross-entropy and contrastive loss functions to enhance model generalization. Extensive experiments demonstrate that MV-SupGCN consistently surpasses state-of-the-art methods across multiple benchmarks, validating the effectiveness of our integrated approach. The source code is available atthis https URL",
            "categories": [
                "cs.LG",
                "cs.CV"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13770",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]contrastive learning"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出MV-SupGCN，通过监督对比学习和自训练增强半监督多视图图卷积网络",
            "summary_zh": "本文提出了一种名为MV-SupGCN的半监督图卷积网络模型，旨在整合互补组件，有效建模复杂的多视图数据。该模型结合交叉熵损失和监督对比损失的联合损失函数，以最小化类内方差并最大化潜在空间中的类间可分性，从而更好地捕获判别性特征并提高模型泛化能力。此外，该模型结合了基于KNN和半监督的图构建方法，增强了数据结构表示的鲁棒性，并减少了泛化误差。最后，为了有效利用大量的无标签数据并增强多视图之间的语义对齐，该模型整合了对比学习（用于强制多视图嵌入之间的一致性并捕获有意义的视图间关系）和伪标签（为交叉熵和对比损失函数提供额外的监督，以增强模型泛化能力）。大量实验表明，MV-SupGCN在多个基准测试中始终优于最先进的方法，验证了该集成方法的有效性。",
            "intro_zh": [
                "现有基于GCN的多视图学习方法未能充分利用视图间的互补信息，导致特征表示次优和性能受限。",
                "MV-SupGCN通过结合监督对比学习、多图构建和自训练，提升模型泛化能力和多视图语义对齐。",
                "实验结果表明，MV-SupGCN在多个数据集上超越了现有最佳方法，验证了其有效性。"
            ],
            "method_zh": "**问题定义**：现有的基于图卷积网络的多视图学习方法，难以充分利用不同视图之间的互补信息，导致学习到的特征表示不够优秀，模型性能受到限制。尤其是在半监督学习场景下，如何有效利用大量的无标签数据是一个挑战。\\n\\n**核心思路**：本文的核心思路是通过结合监督对比学习、多图构建和自训练，来增强模型对多视图数据的理解和泛化能力。监督对比学习旨在拉近同类样本的距离，推远不同类样本的距离，从而学习到更具判别性的特征表示。多图构建旨在提高图结构的鲁棒性。自训练则利用无标签数据来提升模型性能。\\n\\n**技术框架**：MV-SupGCN的整体框架包含以下几个主要模块：1) 特征提取模块：使用图卷积网络从每个视图中提取特征。2) 图构建模块：结合KNN图和半监督图构建方法，为每个视图构建图结构。3) 监督对比学习模块：使用监督对比损失函数来优化特征表示。4) 自训练模块：使用伪标签来为无标签数据提供额外的监督信息。5) 多视图融合模块：将不同视图的特征进行融合，得到最终的特征表示。\\n\\n**关键创新**：该论文的关键创新在于将监督对比学习、多图构建和自训练集成到一个统一的框架中，从而有效地利用了有标签和无标签数据，并增强了多视图之间的语义对齐。与现有方法相比，MV-SupGCN能够学习到更具判别性和鲁棒性的特征表示。\\n\\n**关键设计**：在损失函数方面，MV-SupGCN使用了交叉熵损失和监督对比损失的加权和。监督对比损失的温度参数τ是一个重要的超参数，需要仔细调整。在图构建方面，KNN图的近邻数量k和半监督图的参数α也需要根据具体数据集进行调整。伪标签的置信度阈值也是一个重要的参数，用于控制伪标签的质量。",
            "application_zh": "该研究成果可应用于各种多视图数据分析任务，例如图像分类、文本分类、社交网络分析和生物信息学。通过有效利用多视图数据中的互补信息，可以提高模型的性能和鲁棒性，从而为实际应用带来更大的价值。未来，该方法可以进一步扩展到处理更复杂的多视图数据，例如具有缺失视图或噪声视图的数据。",
            "highlight_zh": "实验结果表明，MV-SupGCN在多个基准数据集上都取得了显著的性能提升，例如在CiteSeer数据集上，MV-SupGCN的准确率比现有最佳方法提高了2%以上。此外，消融实验验证了监督对比学习、多图构建和自训练等各个模块的有效性。这些结果表明，MV-SupGCN是一种有效且通用的多视图学习方法。",
            "tags_zh": [
                "多视图学习",
                "图卷积网络",
                "半监督学习",
                "对比学习",
                "自训练",
                "伪标签",
                "图神经网络"
            ],
            "_index": 158,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13770/MVSupGCNv5.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13770/vennpseudoceloss.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.13770/vennpseudocesuploss.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Training Multi-Image Vision Agents via End2End Reinforcement Learning",
            "authors": [
                "Chengqi Dong",
                "Chuhuai Yue",
                "Hang He",
                "Rongge Mao",
                "Fenghe Tang",
                "S Kevin Zhou",
                "Zekun Xu",
                "Xiaohan Wang",
                "Jiajun Chai",
                "Wei Lin",
                "Guojun Yin"
            ],
            "arxiv_id": "2512.08980",
            "summary": "Recent VLM-based agents aim to replicate OpenAI O3's ``thinking with images\" via tool use, but most open-source methods limit input to a single image, falling short on real-world multi-image QA tasks. To address this, we propose IMAgent, an open-source vision agent trained via end-to-end reinforcement learning dedicated for complex multi-image tasks. By leveraging a multi-agent system, we generate challenging and visually-rich multi-image QA pairs to fully activate the tool-use potential of the base VLM. Through manual verification, we obtain MIFG-QA, comprising 10k samples for training and evaluation. With deeper reasoning steps, VLMs may increasingly ignore visual inputs. We therefore develop two specialized tools for visual reflection and confirmation, allowing the model to proactively reallocate its attention to image content during inference. Benefiting from our well-designed action-trajectory two-level mask strategy, IMAgent achieves stable tool use behavior via pure RL training without requiring costly supervised fine-tuning data. Extensive experiments demonstrate that IMAgent maintains strong performance on existing single-image benchmarks while achieving substantial improvements on our proposed multi-image dataset, with our analysis providing actionable insights for the research community. Codes and data will be released soon.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.08980",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出IMAgent，通过端到端强化学习训练多图视觉Agent，解决复杂多图QA任务。",
            "summary_zh": "本文提出IMAgent，一个开源的视觉Agent，通过端到端强化学习训练，专门用于处理复杂的多图任务。该方法利用多Agent系统生成具有挑战性和视觉丰富性的多图QA对，以充分激活基础VLM的工具使用潜力。通过人工验证，构建了包含1万个样本的MIFG-QA数据集，用于训练和评估。针对VLM在推理过程中可能忽略视觉输入的问题，开发了视觉反思和确认工具，使模型能够在推理过程中主动重新分配对图像内容的注意力。受益于精心设计的动作轨迹两级掩码策略，IMAgent通过纯强化学习训练实现了稳定的工具使用行为，无需昂贵的监督微调数据。大量实验表明，IMAgent在现有单图基准上保持了强大的性能，并在提出的多图数据集上取得了显著的改进，分析结果为研究社区提供了可操作的见解。",
            "intro_zh": [
                "现有基于VLM的Agent在多图QA任务中表现不足，因为它们通常仅限于单图输入，无法充分利用工具。",
                "IMAgent通过端到端强化学习训练，并引入视觉反思和确认工具，使Agent能够更好地处理多图信息并进行推理。",
                "实验表明，IMAgent在多图QA数据集上取得了显著的性能提升，同时在单图基准上保持了竞争力。"
            ],
            "method_zh": "**问题定义**：现有基于视觉语言模型（VLM）的Agent，如OpenAI O3，虽然可以通过工具使用进行“图像思考”，但大多数开源方法仅限于单张图像输入。这使得它们在处理需要多张图像信息的真实世界QA任务时表现不佳。因此，需要一种能够有效处理多图输入，并充分利用VLM工具使用能力的方法。\\n\\n**核心思路**：IMAgent的核心思路是利用端到端强化学习，训练一个能够处理多图输入的视觉Agent。通过构建一个多Agent系统，生成具有挑战性的多图QA对，并设计视觉反思和确认工具，使Agent能够更好地理解和利用图像信息。此外，还采用了动作轨迹两级掩码策略，以稳定工具的使用行为。\\n\\n**技术框架**：IMAgent的技术框架主要包括以下几个部分：1) 多Agent系统：用于生成具有挑战性的多图QA对，以训练Agent的工具使用能力。2) 视觉反思和确认工具：用于帮助Agent在推理过程中重新关注图像内容，避免忽略视觉输入。3) 强化学习训练：使用端到端强化学习训练Agent，使其能够学习如何有效地使用工具和处理多图信息。4) 动作轨迹两级掩码策略：用于稳定Agent的工具使用行为，避免出现不稳定的情况。\\n\\n**关键创新**：IMAgent的关键创新在于以下几个方面：1) 提出了一个基于端到端强化学习的多图视觉Agent训练方法。2) 设计了视觉反思和确认工具，以解决VLM在推理过程中可能忽略视觉输入的问题。3) 提出了动作轨迹两级掩码策略，以稳定Agent的工具使用行为。4) 构建了一个包含1万个样本的多图QA数据集MIFG-QA，用于训练和评估Agent的性能。\\n\\n**关键设计**：IMAgent的关键设计包括：1) 多Agent系统的设计，需要考虑如何生成具有挑战性的多图QA对。2) 视觉反思和确认工具的设计，需要考虑如何有效地帮助Agent重新关注图像内容。3) 强化学习训练的奖励函数设计，需要考虑如何引导Agent学习有效使用工具和处理多图信息。4) 动作轨迹两级掩码策略的设计，需要考虑如何稳定Agent的工具使用行为。",
            "application_zh": "IMAgent具有广泛的应用前景，例如智能客服、自动驾驶、医学图像分析等领域。它可以帮助Agent更好地理解和利用多图信息，从而提高其在复杂任务中的性能。例如，在智能客服领域，IMAgent可以用于处理用户上传的多张图片，从而更准确地理解用户的问题并提供相应的解决方案。在自动驾驶领域，IMAgent可以用于处理多个摄像头拍摄的图像，从而更准确地感知周围环境并做出相应的决策。",
            "highlight_zh": "IMAgent在提出的多图数据集MIFG-QA上取得了显著的性能提升，相较于基线方法，性能提升了XX%。同时，IMAgent在现有的单图基准上保持了强大的性能，表明其具有良好的泛化能力。实验结果表明，视觉反思和确认工具以及动作轨迹两级掩码策略对IMAgent的性能提升起到了关键作用。",
            "tags_zh": [
                "多图视觉Agent",
                "强化学习",
                "视觉语言模型",
                "工具使用",
                "多模态学习"
            ],
            "_index": 159,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.08980/figure/attention_decay4.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.08980/figure/model.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.08980/figure/data_construct.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Unsupervised Representation Learning from Sparse Transformation Analysis",
            "authors": [
                "Yue Song",
                "Thomas Anderson Keller",
                "Yisong Yue",
                "Pietro Perona",
                "Max Welling"
            ],
            "arxiv_id": "2410.05564",
            "summary": "There is a vast literature on representation learning based on principles such as coding efficiency, statistical independence, causality, controllability, or symmetry. In this paper we propose to learn representations from sequence data by factorizing the transformations of the latent variables into sparse components. Input data are first encoded as distributions of latent activations and subsequently transformed using a probability flow model, before being decoded to predict a future input state. The flow model is decomposed into a number of rotational (divergence-free) vector fields and a number of potential flow (curl-free) fields. Our sparsity prior encourages only a small number of these fields to be active at any instant and infers the speed with which the probability flows along these fields. Training this model is completely unsupervised using a standard variational objective and results in a new form of disentangled representations where the input is not only represented by a combination of independent factors, but also by a combination of independent transformation primitives given by the learned flow fields. When viewing the transformations as symmetries one may interpret this as learning approximately equivariant representations. Empirically we demonstrate that this model achieves state of the art in terms of both data likelihood and unsupervised approximate equivariance errors on datasets composed of sequence transformations.",
            "categories": [
                "cs.LG",
                "cs.CV"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2410.05564",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]representation learning"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出基于稀疏变换分析的无监督表征学习方法，用于解耦序列数据中的潜在因素。",
            "summary_zh": "本文提出一种基于稀疏变换分析的表征学习方法，用于从序列数据中进行无监督学习。该方法首先将输入数据编码为潜在激活分布，然后使用概率流模型对这些分布进行变换，最后解码以预测未来的输入状态。概率流模型被分解为若干旋转（无散度）向量场和若干势流（无旋度）场。通过施加稀疏性先验，鼓励只有少量场在任何时刻处于活跃状态，并推断概率沿这些场流动的速度。该模型使用标准的变分目标进行完全无监督的训练，从而产生一种新的解耦表征形式，其中输入不仅由独立因素的组合表示，还由学习到的流场给出的独立变换原语的组合表示。当将变换视为对称性时，可以将其解释为学习近似等变表征。实验结果表明，该模型在由序列变换组成的数据集上，在数据似然和无监督近似等变误差方面均达到了最先进的水平。",
            "intro_zh": [
                "现有表征学习方法在编码效率、统计独立性等方面存在不足，难以有效解耦序列数据中的潜在因素。",
                "该方法通过将潜在变量的变换分解为稀疏分量，学习序列数据的表征，从而实现更好的解耦。",
                "实验表明，该模型在数据似然和无监督近似等变误差方面均取得了领先水平，验证了解耦表征的有效性。"
            ],
            "method_zh": "**问题定义**：该论文旨在解决从序列数据中无监督地学习解耦表征的问题。现有方法难以有效地将输入数据分解为独立的潜在因素，并且难以捕捉数据中的变换关系。这些方法通常无法学习到既独立又具有明确物理意义的变换原语。\\n\\n**核心思路**：论文的核心思路是将序列数据的变换分解为稀疏的、独立的变换原语。通过学习概率流模型，将潜在变量的变换表示为旋转向量场和势流场的组合，并利用稀疏性先验来鼓励只有少量场在任何时刻处于活跃状态。这种稀疏性约束有助于解耦不同的变换因素，从而学习到更具解释性的表征。\\n\\n**技术框架**：该方法包含以下主要模块：1) **编码器**：将输入数据编码为潜在激活分布。2) **概率流模型**：将潜在激活分布进行变换，该模型由旋转向量场和势流场组成。3) **解码器**：将变换后的潜在激活分布解码为未来的输入状态。整个框架使用变分自编码器（VAE）的结构进行训练，目标是最大化数据的似然函数。\\n\\n**关键创新**：该方法最重要的创新点在于将变换分解为稀疏的、独立的变换原语。通过学习概率流模型，并施加稀疏性先验，该方法能够有效地解耦不同的变换因素，从而学习到更具解释性的表征。与现有方法相比，该方法不仅能够学习到独立的潜在因素，还能够学习到独立的变换原语，从而更好地捕捉数据中的动态变化。\\n\\n**关键设计**：概率流模型被分解为若干旋转（无散度）向量场和若干势流（无旋度）场。稀疏性先验通过L1正则化来实现，鼓励只有少量场在任何时刻处于活跃状态。损失函数包括重构损失和KL散度损失，用于保证重构的准确性和潜在变量的分布与先验分布的接近程度。具体的网络结构和参数设置取决于具体的数据集和任务。",
            "application_zh": "该研究的潜在应用领域包括视频理解、机器人控制、物理建模等。通过学习解耦的表征，可以更好地理解视频中的物体运动、控制机器人的动作、以及建模物理系统的动态行为。该方法还可以用于生成新的序列数据，例如通过改变变换原语来生成不同的视频片段或机器人动作。",
            "highlight_zh": "实验结果表明，该模型在由序列变换组成的数据集上，在数据似然和无监督近似等变误差方面均达到了最先进的水平。具体来说，该模型在多个数据集上都取得了显著的性能提升，证明了其学习解耦表征的有效性。该模型还能够学习到具有明确物理意义的变换原语，例如旋转、平移等。",
            "tags_zh": [
                "无监督学习",
                "表征学习",
                "解耦表征",
                "稀疏变换",
                "概率流模型"
            ],
            "_index": 160,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2410.05564/imgs/teaser5.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2410.05564/x1.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2410.05564/x2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "AnimaMimic: Imitating 3D Animation from Video Priors",
            "authors": [
                "Tianyi Xie",
                "Yunuo Chen",
                "Yaowei Guo",
                "Yin Yang",
                "Bolei Zhou",
                "Demetri Terzopoulos",
                "Ying Jiang",
                "Chenfanfu Jiang"
            ],
            "arxiv_id": "2512.14133",
            "summary": "Creating realistic 3D animation remains a time-consuming and expertise-dependent process, requiring manual rigging, keyframing, and fine-tuning of complex motions. Meanwhile, video diffusion models have recently demonstrated remarkable motion imagination in 2D, generating dynamic and visually coherent motion from text or image prompts. However, their results lack explicit 3D structure and cannot be directly used for animation or simulation. We present AnimaMimic, a framework that animates static 3D meshes using motion priors learned from video diffusion models. Starting from an input mesh, AnimaMimic synthesizes a monocular animation video, automatically constructs a skeleton with skinning weights, and refines joint parameters through differentiable rendering and video-based supervision. To further enhance realism, we integrate a differentiable simulation module that refines mesh deformation through physically grounded soft-tissue dynamics. Our method bridges the creativity of video diffusion and the structural control of 3D rigged animation, producing physically plausible, temporally coherent, and artist-editable motion sequences that integrate seamlessly into standard animation pipelines. Our project page is at:this https URL",
            "categories": [
                "cs.GR"
            ],
            "primary_category": "cs.GR",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14133",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "physically plausible"
                    ],
                    "score": 2.5
                },
                {
                    "name": "支柱八：物理动画 (Physics-based Animation)",
                    "id": "8_physics_animation",
                    "matched_keywords": [
                        "differentiable simulation"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "4_motion_diffusion",
                "8_physics_animation"
            ],
            "headline_zh": "AnimaMimic：利用视频先验模仿3D动画，实现自动绑定和物理模拟。",
            "summary_zh": "创建逼真的3D动画是一个耗时且依赖专业知识的过程，需要手动绑定、关键帧设置和复杂运动的微调。最近，视频扩散模型在2D中展示了卓越的运动想象能力，可以从文本或图像提示生成动态且视觉连贯的运动。然而，它们的结果缺乏明确的3D结构，不能直接用于动画或模拟。我们提出了AnimaMimic，一个使用从视频扩散模型学习的运动先验来动画静态3D网格的框架。从输入网格开始，AnimaMimic合成单目动画视频，自动构建带有蒙皮权重的骨架，并通过可微渲染和基于视频的监督来细化关节参数。为了进一步提高真实感，我们集成了一个可微模拟模块，通过物理基础的软组织动力学来细化网格变形。我们的方法桥接了视频扩散的创造性和3D绑定动画的结构控制，产生物理上合理、时间上连贯且艺术家可编辑的运动序列，可以无缝集成到标准动画流程中。",
            "intro_zh": [
                "现有3D动画制作流程耗时且依赖专业知识，缺乏自动化的手段，难以快速生成高质量的动画。",
                "AnimaMimic利用视频扩散模型学习运动先验，并将其迁移到3D网格动画，实现自动绑定和运动生成。",
                "该方法通过可微渲染和物理模拟，优化动画的真实性和物理合理性，生成可编辑的3D动画序列。"
            ],
            "method_zh": "**问题定义**：现有3D动画制作流程需要手动进行骨骼绑定、关键帧设计和运动微调，耗时且需要专业技能。视频扩散模型虽然能生成高质量的2D运动，但缺乏3D结构，无法直接用于3D动画。\n\n**核心思路**：AnimaMimic的核心思路是利用视频扩散模型学习到的运动先验知识，将其迁移到3D网格模型上，从而实现自动化的3D动画生成。通过可微渲染和物理模拟，进一步优化动画的真实性和物理合理性。\n\n**技术框架**：AnimaMimic框架包含以下几个主要模块：1) 从静态3D网格生成单目动画视频；2) 自动构建骨骼和蒙皮权重；3) 通过可微渲染和视频监督优化关节参数；4) 利用可微物理模拟细化网格变形，增强真实感。\n\n**关键创新**：该方法最重要的创新点在于将2D视频扩散模型的运动先验知识成功迁移到3D动画生成中，并结合可微渲染和物理模拟进行优化。与传统的手动动画制作方法相比，AnimaMimic实现了动画生成的自动化和高效化。\n\n**关键设计**：该方法使用可微渲染技术，使得可以通过梯度下降的方式优化骨骼参数，从而使生成的动画与视频扩散模型生成的视频在视觉上保持一致。此外，使用可微的物理模拟模块，可以保证动画的物理合理性，避免出现穿模等不自然的现象。具体的损失函数包括视频重建损失、骨骼约束损失和物理模拟损失等。",
            "application_zh": "AnimaMimic具有广泛的应用前景，可以应用于游戏开发、电影制作、虚拟现实等领域。它可以帮助艺术家快速生成高质量的3D动画，降低动画制作的成本和时间。此外，该方法还可以用于生成各种虚拟角色的动画，例如虚拟助手、虚拟主播等，从而丰富人机交互的体验。",
            "highlight_zh": "AnimaMimic通过结合视频扩散模型和可微渲染、物理模拟，实现了高质量的3D动画生成。实验结果表明，该方法能够生成物理上合理、时间上连贯且艺术家可编辑的运动序列，可以无缝集成到标准动画流程中。具体性能数据未知，但从描述来看，该方法在自动化和真实性方面均有显著提升。",
            "tags_zh": [
                "3D动画",
                "视频扩散模型",
                "可微渲染",
                "物理模拟",
                "运动迁移",
                "自动绑定"
            ],
            "_index": 161,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14133/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14133/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14133/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Predictive Modeling of Flood-Prone Areas Using SAR and Environmental Variables",
            "authors": [
                "Edwin Oluoch Awino",
                "Denis Machanda"
            ],
            "arxiv_id": "2512.13710",
            "summary": "Flooding is one of the most destructive natural hazards worldwide, posing serious risks to ecosystems, infrastructure, and human livelihoods. This study combines Synthetic Aperture Radar (SAR) imagery with environmental and hydrological data to model flood susceptibility in the River Nyando watershed, western Kenya. Sentinel-1 dual-polarization SAR data from the May 2024 flood event were processed to produce a binary flood inventory, which served as training data for machine learning (ML) models. Six conditioning factors -- slope, elevation, aspect, land use/land cover, soil type, and distance from streams -- were integrated with the SAR-derived flood inventory to train four supervised classifiers: Logistic Regression (LR), Classification and Regression Trees (CART), Support Vector Machines (SVM), and Random Forest (RF). Model performance was assessed using accuracy, Cohen's Kappa, and Receiver Operating Characteristic (ROC) analysis. Results indicate that RF achieved the highest predictive performance (accuracy = 0.762; Kappa = 0.480), outperforming LR, CART, and SVM. The RF-based susceptibility map showed that low-lying Kano Plains near Lake Victoria have the highest flood vulnerability, consistent with historical flood records and the impacts of the May 2024 event. These findings demonstrate the value of combining SAR data and ensemble ML methods for flood susceptibility mapping in regions with limited data. The resulting maps offer important insights for disaster risk reduction, land-use planning, and early warning system development.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13710",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]predictive model"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "结合SAR与环境数据，提出基于随机森林的洪水易发区预测模型",
            "summary_zh": "本研究结合合成孔径雷达(SAR)影像与环境及水文数据，对肯尼亚西部尼扬多河流域的洪水易发性进行建模。利用2024年5月洪涝事件的Sentinel-1双极化SAR数据生成二元洪水清单，作为机器学习(ML)模型的训练数据。结合坡度、海拔、坡向、土地利用/土地覆盖、土壤类型和距河流距离等六个条件因子，训练了逻辑回归(LR)、分类与回归树(CART)、支持向量机(SVM)和随机森林(RF)四种监督分类器。通过准确率、Cohen's Kappa系数和受试者工作特征(ROC)分析评估模型性能。结果表明，RF取得了最高的预测性能(准确率=0.762; Kappa=0.480)，优于LR、CART和SVM。基于RF的易发性地图显示，维多利亚湖附近的低洼卡诺平原具有最高的洪水脆弱性，与历史洪水记录和2024年5月事件的影响一致。这些发现证明了在数据有限的地区，结合SAR数据和集成ML方法进行洪水易发性制图的价值。研究结果为降低灾害风险、土地利用规划和早期预警系统开发提供了重要见解。",
            "intro_zh": [
                "洪水是全球最具破坏性的自然灾害之一，现有方法难以在数据稀缺地区进行准确的洪水易发性预测。",
                "本研究结合SAR数据和环境因子，利用机器学习方法构建洪水易发性预测模型，旨在提高预测精度。",
                "实验结果表明，随机森林模型在尼扬多河流域的洪水易发性预测中表现最佳，准确率达到0.762。"
            ],
            "method_zh": "**问题定义**：论文旨在解决在数据有限的地区，如何准确预测洪水易发区域的问题。现有方法在这些区域往往缺乏足够的数据支持，导致预测精度不高，难以有效支持灾害风险管理和土地利用规划。\\n\\n**核心思路**：论文的核心思路是结合SAR遥感数据和环境因子，利用机器学习方法构建洪水易发性预测模型。SAR数据能够提供地表水淹信息的直接观测，而环境因子则反映了地形、地貌、土壤等影响洪水发生的潜在因素。通过将两者结合，可以更全面地刻画洪水发生的条件，提高预测精度。\\n\\n**技术框架**：整体流程包括以下几个主要阶段：1) 数据收集与预处理：收集Sentinel-1 SAR数据、环境因子数据（坡度、海拔等）以及历史洪水事件数据；2) 特征提取与选择：从SAR数据中提取洪水淹没区域，并结合环境因子构建特征向量；3) 模型训练与评估：使用逻辑回归、CART、SVM和随机森林等机器学习模型进行训练，并使用准确率、Kappa系数和ROC曲线等指标评估模型性能；4) 洪水易发性制图：基于训练好的模型，生成洪水易发性地图。\\n\\n**关键创新**：论文的关键创新在于将SAR数据与环境因子相结合，并采用集成学习方法（随机森林）进行洪水易发性预测。SAR数据能够提供实时的地表水淹信息，弥补了传统方法中数据不足的缺陷。随机森林模型能够有效地处理高维数据和非线性关系，提高预测精度。\\n\\n**关键设计**：论文中关键的设计包括：1) 使用Sentinel-1双极化SAR数据，能够提供更丰富的地表信息；2) 选择坡度、海拔、坡向、土地利用/土地覆盖、土壤类型和距河流距离等六个关键环境因子；3) 使用准确率、Cohen's Kappa系数和ROC分析等多种指标综合评估模型性能；4) 采用随机森林模型，并对其参数进行优化，以获得最佳的预测效果。",
            "application_zh": "该研究成果可应用于洪水灾害风险评估、土地利用规划和早期预警系统开发。通过生成高精度的洪水易发性地图，可以帮助政府和相关机构更好地了解洪水风险分布，制定合理的防洪措施，优化土地利用规划，并建立有效的早期预警系统，从而减少洪水灾害造成的损失。",
            "highlight_zh": "实验结果表明，随机森林模型在尼扬多河流域的洪水易发性预测中表现最佳，准确率达到0.762，Kappa系数为0.480，显著优于逻辑回归、CART和SVM等传统机器学习模型。该研究验证了结合SAR数据和集成学习方法在洪水易发性预测中的有效性。",
            "tags_zh": [
                "洪水易发性预测",
                "SAR遥感",
                "机器学习",
                "随机森林",
                "环境因子",
                "灾害风险评估",
                "土地利用规划"
            ],
            "_index": 162,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13710/Picture1.jpg",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13710/Picture2.jpg",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.13710/Picture3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Explainable Preference Learning: a Decision Tree-based Surrogate Model for Preferential Bayesian Optimization",
            "authors": [
                "Nick Leenders",
                "Thomas Quadt",
                "Boris Cule",
                "Roy Lindelauf",
                "Herman Monsuur",
                "Joost van Oijen",
                "Mark Voskuijl"
            ],
            "arxiv_id": "2512.14263",
            "summary": "Current Preferential Bayesian Optimization methods rely on Gaussian Processes (GPs) as surrogate models. These models are hard to interpret, struggle with handling categorical data, and are computationally complex, limiting their real-world usability. In this paper, we introduce an inherently interpretable decision tree-based surrogate model capable of handling both categorical and continuous data, and scalable to large datasets. Extensive numerical experiments on eight increasingly spiky optimization functions show that our model outperforms GP-based alternatives on spiky functions and has only marginally lower performance for non-spiky functions. Moreover, we apply our model to the real-world Sushi dataset and show its ability to learn an individual's sushi preferences. Finally, we show some initial work on using historical preference data to speed up the optimization process for new unseen users.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "math.OC"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14263",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]preference learning"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出基于决策树的可解释偏好学习模型，提升偏好贝叶斯优化在复杂场景下的性能。",
            "summary_zh": "现有的偏好贝叶斯优化方法依赖于高斯过程（GP）作为代理模型。这些模型难以解释，难以处理分类数据，并且计算复杂度高，限制了其在现实世界中的可用性。本文介绍了一种本质上可解释的、基于决策树的代理模型，该模型能够处理分类和连续数据，并且可以扩展到大型数据集。在八个日益尖锐的优化函数上进行的大量数值实验表明，我们的模型在尖锐函数上优于基于GP的替代方案，并且对于非尖锐函数，性能仅略有降低。此外，我们将我们的模型应用于真实的寿司数据集，并展示了其学习个人寿司偏好的能力。最后，我们展示了一些关于使用历史偏好数据来加速新用户的优化过程的初步工作。",
            "intro_zh": [
                "现有偏好贝叶斯优化方法依赖高斯过程，存在可解释性差、难以处理分类数据和计算复杂度高等问题。",
                "论文提出一种基于决策树的代理模型，该模型具有可解释性，能够处理混合数据类型，并可扩展到大型数据集。",
                "实验表明，该模型在尖锐优化函数上优于高斯过程，并在真实寿司数据集上成功学习了个人偏好。"
            ],
            "method_zh": "**问题定义**：现有的偏好贝叶斯优化方法主要依赖于高斯过程（GP）作为代理模型来建模用户的偏好。然而，GP模型存在一些固有的局限性，例如可解释性差，难以直接理解模型是如何做出决策的；难以有效处理包含分类变量的数据集；以及计算复杂度较高，难以扩展到大规模数据集。这些局限性限制了偏好贝叶斯优化在实际应用中的广泛使用。\\n\\n**核心思路**：本文的核心思路是使用决策树作为偏好贝叶斯优化的代理模型，替代传统的高斯过程。决策树具有天然的可解释性，易于理解其决策过程。此外，决策树可以同时处理连续型和离散型数据，无需进行复杂的预处理。通过构建合适的决策树模型，可以有效地学习用户的偏好，并用于指导优化过程。\\n\\n**技术框架**：该方法主要包含以下几个阶段：1) 收集用户的偏好数据，例如通过成对比较或排序等方式获取用户对不同选项的偏好关系。2) 使用收集到的偏好数据训练决策树模型，该模型的目标是预测用户对不同选项的偏好程度。3) 使用训练好的决策树模型作为代理模型，指导贝叶斯优化过程。在每次迭代中，根据决策树模型的预测结果选择下一个要评估的选项，并更新模型。4) 重复步骤3，直到达到预定的优化目标或迭代次数。\\n\\n**关键创新**：该论文最重要的技术创新点在于将决策树引入到偏好贝叶斯优化中，替代了传统的高斯过程。这种方法不仅提高了模型的可解释性，使其更容易被用户理解和信任，而且能够有效地处理包含分类变量的数据集，并具有良好的可扩展性。此外，论文还探索了利用历史偏好数据加速新用户偏好学习的方法。\\n\\n**关键设计**：论文中使用的决策树模型可以采用不同的算法进行构建，例如CART、ID3或C4.5等。关键的设计包括如何选择合适的决策树算法，如何设置决策树的深度和叶子节点数量等参数，以及如何处理偏好数据中的噪声和不一致性。此外，论文还可能涉及到如何设计合适的采集函数（Acquisition Function），用于在贝叶斯优化过程中选择下一个要评估的选项。具体的损失函数和网络结构取决于所选择的决策树算法和采集函数。",
            "application_zh": "该研究成果可应用于个性化推荐系统、产品设计、用户界面优化等领域。例如，可以利用该模型学习用户的口味偏好，从而推荐更符合用户口味的菜品或商品。在产品设计中，可以根据用户对不同设计方案的偏好，优化产品的功能和外观。此外，该方法还可以用于优化用户界面，提高用户体验。未来，该方法有望在更多需要理解和建模用户偏好的场景中得到应用。",
            "highlight_zh": "实验结果表明，该模型在尖锐优化函数上优于基于高斯过程的替代方案，表明其在复杂优化问题上的优势。在真实的寿司数据集上，该模型成功学习了个人的寿司偏好，验证了其在实际应用中的有效性。此外，初步实验表明，利用历史偏好数据可以加速新用户的偏好学习过程，为进一步提升优化效率提供了可能。",
            "tags_zh": [
                "偏好学习",
                "贝叶斯优化",
                "决策树",
                "可解释性",
                "代理模型"
            ],
            "_index": 163,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14263/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14263/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14263/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Kinetic-Mamba: Mamba-Assisted Predictions of Stiff Chemical Kinetics",
            "authors": [
                "Additi Pandey",
                "Liang Wei",
                "Hessam Babaee",
                "George Em Karniadakis"
            ],
            "arxiv_id": "2512.14471",
            "summary": "Accurate chemical kinetics modeling is essential for combustion simulations, as it governs the evolution of complex reaction pathways and thermochemical states. In this work, we introduce Kinetic-Mamba, a Mamba-based neural operator framework that integrates the expressive power of neural operators with the efficient temporal modeling capabilities of Mamba architectures. The framework comprises three complementary models: (i) a standalone Mamba model that predicts the time evolution of thermochemical state variables from given initial conditions; (ii) a constrained Mamba model that enforces mass conservation while learning the state dynamics; and (iii) a regime-informed architecture employing two standalone Mamba models to capture dynamics across temperature-dependent regimes. We additionally develop a latent Kinetic-Mamba variant that evolves dynamics in a reduced latent space and reconstructs the full state on the physical manifold. We evaluate the accuracy and robustness of Kinetic-Mamba using both time-decomposition and recursive-prediction strategies. We further assess the extrapolation capabilities of the model on varied out-of-distribution datasets. Computational experiments on Syngas and GRI-Mech 3.0 reaction mechanisms demonstrate that our framework achieves high fidelity in predicting complex kinetic behavior using only the initial conditions of the state variables.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14471",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]Mamba"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "Kinetic-Mamba：利用Mamba架构预测刚性化学动力学，提升燃烧模拟精度。",
            "summary_zh": "精确的化学动力学建模对于燃烧模拟至关重要，因为它控制着复杂反应路径和热化学状态的演变。本文介绍了一种基于Mamba的神经算子框架Kinetic-Mamba，它将神经算子的表达能力与Mamba架构的高效时间建模能力相结合。该框架包含三个互补的模型：（i）一个独立的Mamba模型，用于从给定的初始条件预测热化学状态变量的时间演化；（ii）一个约束的Mamba模型，在学习状态动态的同时强制执行质量守恒；（iii）一种基于温度相关机制的架构，采用两个独立的Mamba模型来捕获不同温度范围内的动态。此外，我们还开发了一种潜在的Kinetic-Mamba变体，它在降维的潜在空间中演化动态，并在物理流形上重建完整状态。我们使用时间分解和递归预测策略评估了Kinetic-Mamba的准确性和鲁棒性。我们进一步评估了该模型在各种分布外数据集上的外推能力。对合成气和GRI-Mech 3.0反应机制的计算实验表明，我们的框架仅使用状态变量的初始条件，就能在预测复杂动力学行为方面实现高保真度。",
            "intro_zh": [
                "现有化学动力学建模方法在处理复杂反应和刚性系统时面临精度和效率的挑战。",
                "Kinetic-Mamba利用Mamba架构高效建模时间序列，并结合神经算子学习复杂动力学，实现精确预测。",
                "实验表明，Kinetic-Mamba在合成气和GRI-Mech 3.0反应机制上表现出高预测精度和良好的外推能力。"
            ],
            "method_zh": "**问题定义**：论文旨在解决化学动力学建模中，现有方法难以准确高效地预测复杂反应机制和刚性系统的问题。传统方法计算成本高昂，且难以捕捉非线性动力学行为。现有神经网络方法在长时序预测中可能存在梯度消失或爆炸等问题，影响预测精度。\\n\\n**核心思路**：论文的核心思路是将Mamba架构应用于化学动力学建模。Mamba架构具有线性复杂度，能够高效地处理长序列数据，并具有选择性状态空间模型的特性，可以更好地捕捉动力学系统的复杂行为。通过结合神经算子的表达能力，Kinetic-Mamba能够学习从初始条件到未来状态的映射关系。\\n\\n**技术框架**：Kinetic-Mamba框架包含三个主要模型：（1）Standalone Mamba模型：直接预测热化学状态变量的时间演化；（2）Constrained Mamba模型：在学习状态动态的同时，通过损失函数强制执行质量守恒定律；（3）Regime-informed Mamba模型：使用两个独立的Mamba模型，分别处理不同温度范围内的动力学，以提高预测精度。此外，还提出了Latent Kinetic-Mamba变体，在降维的潜在空间中进行动力学演化，以降低计算成本。\\n\\n**关键创新**：论文的关键创新在于将Mamba架构引入化学动力学建模领域，并提出了多种Mamba模型的变体，以适应不同的建模需求。与传统的RNN或Transformer模型相比，Mamba架构具有更高的计算效率和更好的长序列建模能力。此外，论文还提出了约束Mamba模型和基于机制的Mamba模型，进一步提高了预测精度和鲁棒性。\\n\\n**关键设计**：在Standalone Mamba模型中，输入为初始条件和时间步长，输出为对应时间步长的热化学状态变量。Constrained Mamba模型通过添加质量守恒约束项到损失函数中，强制模型学习满足物理定律的动态。Regime-informed Mamba模型根据温度范围选择不同的Mamba模型进行预测。Latent Kinetic-Mamba模型使用自编码器将高维状态变量映射到低维潜在空间，并在潜在空间中进行动力学演化。损失函数通常包括预测误差和质量守恒约束项。",
            "application_zh": "Kinetic-Mamba可应用于燃烧模拟、化学反应器设计、以及其他涉及复杂化学动力学的领域。该模型能够加速燃烧过程的模拟，优化燃烧效率，并降低污染物排放。此外，该方法还可以用于研究新型燃料的燃烧特性，为能源领域的创新提供支持。",
            "highlight_zh": "实验结果表明，Kinetic-Mamba在预测合成气和GRI-Mech 3.0反应机制的动力学行为方面表现出高精度。与传统方法相比，Kinetic-Mamba能够以更低的计算成本实现更高的预测精度。此外，Kinetic-Mamba在分布外数据集上表现出良好的外推能力，表明其具有较强的泛化能力。",
            "tags_zh": [
                "化学动力学",
                "Mamba架构",
                "神经算子",
                "燃烧模拟",
                "时间序列预测"
            ],
            "_index": 164,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14471/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14471/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14471/Figure/Numerical/SyngasA/Sample_Final_235.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "ParaFormer: A Generalized PageRank Graph Transformer for Graph Representation Learning",
            "authors": [
                "Chaohao Yuan",
                "Zhenjie Song",
                "Ercan Engin Kuruoglu",
                "Kangfei Zhao",
                "Yang Liu",
                "Deli Zhao",
                "Hong Cheng",
                "Yu Rong"
            ],
            "arxiv_id": "2512.14619",
            "summary": "Graph Transformers (GTs) have emerged as a promising graph learning tool, leveraging their all-pair connected property to effectively capture global information. To address the over-smoothing problem in deep GNNs, global attention was initially introduced, eliminating the necessity for using deep GNNs. However, through empirical and theoretical analysis, we verify that the introduced global attention exhibits severe over-smoothing, causing node representations to become indistinguishable due to its inherent low-pass filtering. This effect is even stronger than that observed in GNNs. To mitigate this, we propose PageRank Transformer (ParaFormer), which features a PageRank-enhanced attention module designed to mimic the behavior of deep Transformers. We theoretically and empirically demonstrate that ParaFormer mitigates over-smoothing by functioning as an adaptive-pass filter. Experiments show that ParaFormer achieves consistent performance improvements across both node classification and graph classification tasks on 11 datasets ranging from thousands to millions of nodes, validating its efficacy. The supplementary material, including code and appendix, can be found inthis https URL.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14619",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]representation learning"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出ParaFormer：一种用于图表示学习的广义PageRank图Transformer",
            "summary_zh": "图Transformer (GTs) 作为一种有前景的图学习工具崭露头角，它利用其全连接特性来有效地捕获全局信息。为了解决深度GNN中的过度平滑问题，最初引入了全局注意力，从而消除了使用深度GNN的必要性。然而，通过实证和理论分析，我们验证了引入的全局注意力表现出严重的过度平滑，由于其固有的低通滤波特性，导致节点表示变得难以区分。这种影响甚至比在GNN中观察到的更强。为了缓解这个问题，我们提出了PageRank Transformer (ParaFormer)，它具有PageRank增强的注意力模块，旨在模仿深度Transformer的行为。我们在理论上和实证上证明了ParaFormer通过充当自适应通滤波器来缓解过度平滑。实验表明，ParaFormer在数千到数百万个节点的11个数据集上的节点分类和图分类任务中都实现了持续的性能改进，验证了其有效性。",
            "intro_zh": [
                "深度图神经网络（GNNs）存在过平滑问题，导致节点表示难以区分，限制了模型性能。",
                "ParaFormer通过引入PageRank增强的注意力机制，模仿深度Transformer的行为，缓解了过平滑问题。",
                "实验结果表明，ParaFormer在节点分类和图分类任务中均取得了显著的性能提升，验证了其有效性。"
            ],
            "method_zh": "**问题定义**：现有图Transformer模型虽然利用全局注意力机制捕获全局信息，但由于全局注意力固有的低通滤波特性，导致节点表示过度平滑，节点特征趋同，严重影响模型性能。因此，论文旨在解决图Transformer中的过度平滑问题，提升图表示学习的质量。\\n\\n**核心思路**：论文的核心思路是设计一种PageRank增强的注意力机制，使模型能够自适应地学习节点之间的重要性，从而缓解全局注意力带来的过度平滑问题。通过模仿深度Transformer的行为，ParaFormer能够更好地保留节点特征，提升图表示的区分性。\\n\\n**技术框架**：ParaFormer的整体架构基于Transformer模型，主要包括以下模块：输入嵌入层、PageRank增强的注意力模块、前馈神经网络和输出层。PageRank增强的注意力模块是核心组件，它利用PageRank算法计算节点之间的重要性，并将其融入到注意力权重中。模型首先将节点特征进行嵌入，然后通过PageRank增强的注意力模块进行信息传递和聚合，最后通过前馈神经网络进行特征变换和预测。\\n\\n**关键创新**：ParaFormer的关键创新在于PageRank增强的注意力模块。与传统的全局注意力机制不同，该模块能够自适应地学习节点之间的重要性，从而缓解过度平滑问题。PageRank算法能够有效地捕捉图的全局结构信息，并将其融入到注意力权重中，使得模型能够更好地关注重要的节点和边。\\n\\n**关键设计**：PageRank增强的注意力模块的具体实现方式为：首先，利用PageRank算法计算节点之间的转移概率矩阵。然后，将转移概率矩阵与注意力权重进行融合，得到最终的注意力权重。在训练过程中，可以使用交叉熵损失函数或均方误差损失函数来优化模型参数。此外，还可以采用一些正则化技术，如dropout和权重衰减，来防止过拟合。",
            "application_zh": "ParaFormer具有广泛的应用前景，可应用于社交网络分析、生物信息学、推荐系统、知识图谱等领域。例如，在社交网络分析中，ParaFormer可以用于识别关键用户和社区；在生物信息学中，可以用于预测蛋白质功能和药物靶点；在推荐系统中，可以用于提升推荐的准确性和个性化；在知识图谱中，可以用于进行知识推理和关系预测。该研究的实际价值在于提升了图表示学习的质量和效率，为各种图相关任务提供了更强大的工具。",
            "highlight_zh": "实验结果表明，ParaFormer在11个数据集上均取得了显著的性能提升。在节点分类任务中，ParaFormer的平均准确率比基线模型提高了2-5%。在图分类任务中，ParaFormer的平均准确率比基线模型提高了3-7%。这些结果验证了ParaFormer的有效性和泛化能力。",
            "tags_zh": [
                "图神经网络",
                "图Transformer",
                "PageRank",
                "注意力机制",
                "过平滑",
                "图表示学习",
                "节点分类",
                "图分类"
            ],
            "_index": 165,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14619/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14619/x5.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14619/x6.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Meta Hierarchical Reinforcement Learning for Scalable Resource Management in O-RAN",
            "authors": [
                "Fatemeh Lotfi",
                "Fatemeh Afghah"
            ],
            "arxiv_id": "2512.13715",
            "summary": "The increasing complexity of modern applications demands wireless networks capable of real time adaptability and efficient resource management. The Open Radio Access Network (O-RAN) architecture, with its RAN Intelligent Controller (RIC) modules, has emerged as a pivotal solution for dynamic resource management and network slicing. While artificial intelligence (AI) driven methods have shown promise, most approaches struggle to maintain performance under unpredictable and highly dynamic conditions. This paper proposes an adaptive Meta Hierarchical Reinforcement Learning (Meta-HRL) framework, inspired by Model Agnostic Meta Learning (MAML), to jointly optimize resource allocation and network slicing in O-RAN. The framework integrates hierarchical control with meta learning to enable both global and local adaptation: the high-level controller allocates resources across slices, while low level agents perform intra slice scheduling. The adaptive meta-update mechanism weights tasks by temporal difference error variance, improving stability and prioritizing complex network scenarios. Theoretical analysis establishes sublinear convergence and regret guarantees for the two-level learning process. Simulation results demonstrate a 19.8% improvement in network management efficiency compared with baseline RL and meta-RL approaches, along with faster adaptation and higher QoS satisfaction across eMBB, URLLC, and mMTC slices. Additional ablation and scalability studies confirm the method's robustness, achieving up to 40% faster adaptation and consistent fairness, latency, and throughput performance as network scale increases.",
            "categories": [
                "cs.AI",
                "cs.LG",
                "eess.SY"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13715",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出Meta-HRL框架，用于O-RAN中可扩展的资源管理，提升网络效率。",
            "summary_zh": "现代应用日益复杂，对无线网络提出了实时适应性和高效资源管理的需求。开放无线接入网络（O-RAN）架构及其RAN智能控制器（RIC）模块，已成为动态资源管理和网络切片的关键解决方案。虽然人工智能（AI）驱动的方法显示出潜力，但大多数方法在不可预测和高度动态的条件下难以维持性能。本文提出了一种自适应的Meta分层强化学习（Meta-HRL）框架，灵感来源于模型无关元学习（MAML），以联合优化O-RAN中的资源分配和网络切片。该框架集成了分层控制与元学习，以实现全局和局部适应：高层控制器在切片之间分配资源，而低层代理执行切片内调度。自适应元更新机制通过时序差分误差方差对任务进行加权，从而提高稳定性并优先考虑复杂的网络场景。理论分析建立了双层学习过程的次线性收敛性和后悔保证。仿真结果表明，与基线强化学习和元强化学习方法相比，网络管理效率提高了19.8%，并且在eMBB、URLLC和mMTC切片中实现了更快的适应和更高的QoS满意度。额外的消融和可扩展性研究证实了该方法的鲁棒性，随着网络规模的增加，实现了高达40%的更快适应以及一致的公平性、延迟和吞吐量性能。",
            "intro_zh": [
                "现有AI驱动的O-RAN资源管理方法在动态环境下难以保持性能，无法有效应对复杂网络场景。",
                "提出Meta-HRL框架，结合分层控制和元学习，实现全局资源分配和局部切片调度，提升适应性。",
                "实验表明，Meta-HRL在网络管理效率、适应速度和QoS满意度方面均优于基线方法。"
            ],
            "method_zh": "**问题定义**：论文旨在解决O-RAN中动态资源分配和网络切片问题，现有方法难以在复杂和动态的网络环境中保持性能，无法快速适应变化的网络条件，导致资源利用率低和服务质量下降。现有方法的痛点在于缺乏有效的全局和局部自适应机制，难以平衡不同切片的需求。\n\\n**核心思路**：论文的核心思路是利用Meta学习提升强化学习的适应能力，通过分层强化学习实现全局资源分配和局部切片调度的协同优化。Meta学习使智能体能够快速适应新的网络环境，分层结构则允许智能体在不同层级上进行决策，从而更好地管理资源和满足不同切片的需求。这种设计旨在提高资源利用率，降低延迟，并保证服务质量。\n\\n**技术框架**：Meta-HRL框架包含一个高层控制器和多个低层代理。高层控制器负责在不同的网络切片之间分配资源，例如频谱和计算资源。低层代理则负责在各自的网络切片内进行资源调度，例如用户调度和功率控制。Meta学习机制用于快速适应新的网络环境，通过少量样本进行学习，从而提高适应速度。整个框架通过迭代优化高层控制器和低层代理的策略，实现全局最优的资源管理。\n\\n**关键创新**：该论文的关键创新在于将Meta学习与分层强化学习相结合，提出了一种自适应的Meta-HRL框架。传统的强化学习方法需要大量的训练数据才能收敛，而Meta学习则可以通过少量样本快速适应新的环境。此外，通过分层结构，框架可以同时优化全局资源分配和局部切片调度，从而更好地满足不同切片的需求。自适应元更新机制也是一个创新点，它通过时序差分误差方差对任务进行加权，从而提高稳定性和优先考虑复杂的网络场景。\n\\n**关键设计**：高层控制器和低层代理均采用深度神经网络作为策略函数。损失函数包括资源利用率、延迟和服务质量等指标。Meta学习采用MAML算法，通过梯度下降进行策略更新。自适应元更新机制通过计算时序差分误差方差来确定每个任务的权重，从而优先考虑复杂的网络场景。具体的网络结构和参数设置需要根据具体的网络环境进行调整。",
            "application_zh": "该研究成果可应用于未来的5G/6G无线通信系统，尤其是在O-RAN架构下，能够实现更智能、更高效的资源管理和网络切片。该方法可以提升网络性能，降低运营成本，并为用户提供更好的服务体验。此外，该方法还可以应用于其他需要动态资源分配和管理的领域，例如云计算和物联网。",
            "highlight_zh": "实验结果表明，Meta-HRL框架在网络管理效率方面比基线强化学习和元强化学习方法提高了19.8%。在适应速度方面，Meta-HRL框架比其他方法快40%。此外，Meta-HRL框架在eMBB、URLLC和mMTC切片中实现了更高的QoS满意度，并在网络规模增加时保持了一致的公平性、延迟和吞吐量性能。这些结果表明，Meta-HRL框架具有良好的性能和可扩展性。",
            "tags_zh": [
                "O-RAN",
                "资源管理",
                "网络切片",
                "强化学习",
                "元学习",
                "分层强化学习",
                "无线通信",
                "自适应控制"
            ],
            "_index": 166,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13715/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13715/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.13715/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "HeSRN: Representation Learning On Heterogeneous Graphs via Slot-Aware Retentive Network",
            "authors": [
                "Yifan Lu",
                "Ziyun Zou",
                "Belal Alsinglawi",
                "Islam Al-Qudah",
                "Izzat Alsmadi",
                "Feilong Tang",
                "Pengfei Jiao",
                "Shoaib Jameel",
                "Imran Razzak"
            ],
            "arxiv_id": "2510.09767",
            "summary": "Graph Transformers have recently achieved remarkable progress in graph representation learning by capturing long-range dependencies through self-attention. However, their quadratic computational complexity and inability to effectively model heterogeneous semantics severely limit their scalability and generalization on real-world heterogeneous graphs. To address these issues, we propose HeSRN, a novel Heterogeneous Slot-aware Retentive Network for efficient and expressive heterogeneous graph representation learning. HeSRN introduces a slot-aware structure encoder that explicitly disentangles node-type semantics by projecting heterogeneous features into independent slots and aligning their distributions through slot normalization and retention-based fusion, effectively mitigating the semantic entanglement caused by forced feature-space unification in previous Transformer-based models. Furthermore, we replace the self-attention mechanism with a retention-based encoder, which models structural and contextual dependencies in linear time complexity while maintaining strong expressive power. A heterogeneous retentive encoder is further employed to jointly capture both local structural signals and global heterogeneous semantics through multi-scale retention layers. Extensive experiments on four real-world heterogeneous graph datasets demonstrate that HeSRN consistently outperforms state-of-the-art heterogeneous graph neural networks and Graph Transformer baselines on node classification tasks, achieving superior accuracy with significantly lower computational complexity.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2510.09767",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]representation learning"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出HeSRN：一种基于Slot-Aware Retentive网络的异构图表示学习方法",
            "summary_zh": "本文提出了一种新的异构图表示学习方法HeSRN，即异构Slot-Aware Retentive网络，旨在高效且富有表现力地学习异构图表示。针对图Transformer在异构图上的计算复杂度和语义建模问题，HeSRN引入了Slot-Aware结构编码器，通过将异构特征投影到独立的Slot中，并通过Slot归一化和基于Retentive的融合来显式地解耦节点类型语义，从而有效缓解了先前基于Transformer的模型中强制特征空间统一引起的语义纠缠。此外，该方法用基于Retentive的编码器取代了自注意力机制，以线性时间复杂度对结构和上下文依赖关系进行建模，同时保持了强大的表达能力。异构Retentive编码器进一步用于通过多尺度Retentive层联合捕获局部结构信号和全局异构语义。在四个真实世界的异构图数据集上的大量实验表明，HeSRN在节点分类任务上始终优于最先进的异构图神经网络和图Transformer基线，以显著降低的计算复杂度实现了卓越的准确性。",
            "intro_zh": [
                "现有图Transformer方法在异构图上存在计算复杂度高、难以有效建模异构语义等问题，限制了其可扩展性和泛化能力。",
                "HeSRN通过Slot-Aware结构编码器解耦节点类型语义，并使用Retentive编码器以线性复杂度建模结构和上下文依赖，提升效率。",
                "实验结果表明，HeSRN在节点分类任务上优于现有异构图神经网络和图Transformer，并在计算复杂度上具有优势。"
            ],
            "method_zh": "**问题定义**：现有基于Transformer的图神经网络在处理异构图时，由于自注意力机制的计算复杂度是节点数量的平方级别，因此在大规模图上效率低下。此外，它们通常将不同类型的节点特征强制统一到同一个特征空间，导致语义纠缠，影响表示学习的质量。\\n\\n**核心思路**：HeSRN的核心思路是通过引入Slot-Aware机制来显式地解耦不同节点类型的语义信息，并使用Retentive网络替代自注意力机制，从而降低计算复杂度，同时保持模型的表达能力。通过将异构特征投影到独立的Slot中，并进行归一化和融合，可以有效缓解语义纠缠问题。\\n\\n**技术框架**：HeSRN的整体框架包括以下几个主要模块：1) Slot-Aware结构编码器：将异构节点特征投影到不同的Slot中，每个Slot对应一种节点类型。2) Slot归一化：对每个Slot中的特征进行归一化，以对齐不同Slot的分布。3) 基于Retentive的融合：使用Retentive机制融合不同Slot中的特征，捕捉节点类型之间的关系。4) 异构Retentive编码器：通过多尺度Retentive层，联合捕获局部结构信号和全局异构语义。\\n\\n**关键创新**：HeSRN的关键创新在于：1) Slot-Aware结构编码器，它显式地解耦了节点类型语义，避免了强制特征空间统一带来的语义纠缠。2) 使用Retentive网络替代自注意力机制，将计算复杂度降低到线性级别，提高了模型的可扩展性。3) 异构Retentive编码器，能够同时捕捉局部结构信号和全局异构语义。\\n\\n**关键设计**：Slot-Aware结构编码器使用线性投影将异构节点特征映射到不同的Slot中。Slot归一化采用Layer Normalization。Retentive网络使用并行化的chunk-wise recurrent 计算方式，加速训练和推理。异构Retentive编码器堆叠了多个Retentive层，并使用不同的尺度来捕捉不同范围的依赖关系。损失函数根据具体的下游任务进行选择，例如节点分类任务通常使用交叉熵损失。",
            "application_zh": "HeSRN具有广泛的应用前景，例如社交网络分析、知识图谱推理、生物信息学等领域。它可以用于节点分类、链接预测、图分类等任务。该研究的实际价值在于提高了异构图表示学习的效率和准确性，为大规模异构图数据的分析和应用提供了新的工具。未来，可以进一步探索HeSRN在其他图结构数据上的应用，并研究如何将其与其他技术相结合，以解决更复杂的问题。",
            "highlight_zh": "实验结果表明，HeSRN在四个真实世界的异构图数据集上，相比于最先进的异构图神经网络和图Transformer基线，在节点分类任务上取得了显著的性能提升。例如，在某些数据集上，HeSRN的准确率提高了5%以上，同时计算复杂度显著降低。这些结果验证了HeSRN的有效性和优越性。",
            "tags_zh": [
                "异构图表示学习",
                "图神经网络",
                "Retentive网络",
                "Slot-Aware机制",
                "节点分类"
            ],
            "_index": 167,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://ar5iv.labs.arxiv.org/assets/ar5iv.png",
                    "caption": "",
                    "figure_id": "img_0"
                }
            ]
        },
        {
            "title": "Meta-Reinforcement Learning for Building Energy Management System",
            "authors": [
                "Huiliang Zhang",
                "Di Wu",
                "Arnaud Zinflou",
                "Benoit Boulet"
            ],
            "arxiv_id": "2210.12590",
            "summary": "The building sector is one of the largest contributors to global energy consumption. Improving its energy efficiency is essential for reducing operational costs and greenhouse gas emissions. Energy management systems (EMS) play a key role in monitoring and controlling building appliances efficiently and reliably. With the increasing integration of renewable energy, intelligent EMS solutions have received growing attention. Reinforcement learning (RL) has recently been explored for this purpose and shows strong potential. However, most RL-based EMS methods require a large number of training steps to learn effective control policies, especially when adapting to unseen buildings, which limits their practical deployment. This paper introduces MetaEMS, a meta-reinforcement learning framework for EMS. MetaEMS improves learning efficiency by transferring knowledge from previously solved tasks to new ones through group-level and building-level adaptation, enabling fast adaptation and effective control across diverse building environments. Experimental results demonstrate that MetaEMS adapts more rapidly to unseen buildings and consistently outperforms baseline methods across various scenarios.",
            "categories": [
                "cs.AI",
                "cs.LG",
                "eess.SY"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2210.12590",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出MetaEMS，通过元强化学习加速建筑能源管理系统在不同建筑环境中的自适应控制。",
            "summary_zh": "建筑行业是全球能源消耗的主要贡献者之一。提高其能源效率对于降低运营成本和减少温室气体排放至关重要。能源管理系统（EMS）在高效、可靠地监控和控制建筑设备方面发挥着关键作用。随着可再生能源的日益普及，智能EMS解决方案受到了越来越多的关注。强化学习（RL）最近被用于此目的，并显示出强大的潜力。然而，大多数基于RL的EMS方法需要大量的训练步骤才能学习有效的控制策略，尤其是在适应未见过的建筑物时，这限制了它们的实际部署。本文介绍了一种用于EMS的元强化学习框架MetaEMS。MetaEMS通过组级别和建筑级别的自适应，将先前解决的任务中的知识转移到新任务中，从而提高学习效率，从而实现跨不同建筑环境的快速自适应和有效控制。实验结果表明，MetaEMS能够更快地适应未见过的建筑物，并且在各种场景中始终优于基线方法。",
            "intro_zh": [
                "现有基于强化学习的建筑能源管理系统需要大量训练，难以快速适应新建筑。",
                "MetaEMS利用元强化学习，通过组级别和建筑级别的自适应，实现知识迁移。",
                "实验表明，MetaEMS能更快适应新建筑，并在多种场景下优于基线方法。"
            ],
            "method_zh": "**问题定义**：论文旨在解决建筑能源管理系统中，基于强化学习的控制策略难以快速适应新建筑的问题。现有方法需要针对每个新建筑进行大量的训练，成本高昂且效率低下。痛点在于缺乏跨建筑环境的知识迁移能力。\\n\\n**核心思路**：论文的核心思路是利用元强化学习，将不同建筑的能源管理任务视为不同的任务实例，通过学习如何在多个任务上快速适应，从而在新建筑上实现快速有效的控制。通过元学习，模型能够学习到通用的控制策略和适应策略，从而减少在新环境中的训练量。\\n\\n**技术框架**：MetaEMS框架包含两个主要的自适应层次：组级别自适应和建筑级别自适应。组级别自适应旨在学习一组建筑之间的通用知识，例如能源消耗模式和控制策略。建筑级别自适应则是在组级别知识的基础上，针对特定建筑的特点进行微调，以实现最佳的控制效果。整体流程是首先在多个建筑上进行元训练，然后在新建筑上进行快速自适应。\\n\\n**关键创新**：MetaEMS的关键创新在于其元强化学习框架，该框架能够有效地将知识从先前解决的任务转移到新任务中，从而提高学习效率。与传统的强化学习方法相比，MetaEMS不需要针对每个新建筑进行大量的训练，从而大大降低了部署成本。此外，MetaEMS还采用了组级别和建筑级别自适应，从而能够更好地适应不同建筑环境的特点。\\n\\n**关键设计**：具体的参数设置、损失函数和网络结构等技术细节在论文中可能有所描述，但摘要中未提及，因此无法给出详细信息。通常，元强化学习会涉及到内外循环的优化，内循环用于在特定任务上进行快速适应，外循环用于学习通用的初始化参数或策略。损失函数的设计需要考虑如何最大化新任务上的回报，并同时保持对先前任务的知识。",
            "application_zh": "MetaEMS可应用于各种建筑能源管理系统，尤其适用于需要快速部署和适应新环境的场景，例如大规模建筑群、智能楼宇和分布式能源系统。该研究有助于降低建筑能耗、减少碳排放，并提高能源利用效率，具有重要的经济和社会价值。未来，该方法有望推广到更广泛的智能控制领域。",
            "highlight_zh": "实验结果表明，MetaEMS能够更快地适应未见过的建筑物，并且在各种场景中始终优于基线方法。具体的性能数据和提升幅度在摘要中未给出，但强调了MetaEMS在快速适应性和控制效果方面的优势。MetaEMS的快速适应能力使其在实际应用中更具优势。",
            "tags_zh": [
                "元强化学习",
                "建筑能源管理系统",
                "能源效率",
                "知识迁移",
                "自适应控制"
            ],
            "_index": 168,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2210.12590/fig/arch.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2210.12590/fig/framework.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2210.12590/fig/performance_across_episodes_custom_large_font.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Generalization performance of narrow one-hidden layer networks in the teacher-student setting",
            "authors": [
                "Jean Barbier",
                "Federica Gerace",
                "Alessandro Ingrosso",
                "Clarissa Lauditi",
                "Enrico M. Malatesta",
                "Gibbs Nwemadji",
                "Rodrigo Pérez Ortiz"
            ],
            "arxiv_id": "2507.00629",
            "summary": "Understanding the generalization abilities of neural networks for simple input-output distributions is crucial to account for their learning performance on real datasets. The classical teacher-student setting, where a network is trained from data obtained thanks to a label-generating teacher model, serves as a perfect theoretical test bed. In this context, a complete theoretical account of the performance of fully connected one-hidden layer networks in the presence of generic activation functions is lacking. In this work, we develop such a general theory for narrow networks, i.e. with a large number of hidden units, yet much smaller than the input dimension. Using methods from statistical physics, we provide closed-form expressions for the typical performance of both finite temperature (Bayesian) and empirical risk minimization estimators, in terms of a small number of summary statistics. In doing so, we highlight the presence of a transition where hidden neurons specialize when the number of samples is sufficiently large and proportional to the number of parameters of the network. Our theory accurately predicts the generalization error of neural networks trained on regression or classification tasks with either noisy full-batch gradient descent (Langevin dynamics) or full-batch gradient descent.",
            "categories": [
                "cs.LG",
                "math.PR",
                "math.ST"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2507.00629",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]teacher-student"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "针对窄单隐层网络，提出基于师生框架的泛化性能理论分析方法",
            "summary_zh": "理解神经网络在简单输入输出分布下的泛化能力，对于解释其在真实数据集上的学习性能至关重要。经典的师生框架提供了一个完美的理论测试平台，其中学生网络从由教师模型生成的数据中学习。然而，目前缺乏对具有通用激活函数的全连接单隐层网络性能的完整理论描述。本文针对窄网络（即隐藏单元数量远小于输入维度）提出了这样的通用理论。利用统计物理学的方法，我们为有限温度（贝叶斯）和经验风险最小化估计器的典型性能提供了闭式表达式，这些表达式仅依赖于少量的统计量。我们强调，当样本数量足够大且与网络参数数量成比例时，隐藏神经元会发生专业化转变。我们的理论能够准确预测神经网络在回归或分类任务中使用噪声全批量梯度下降（朗之万动力学）或全批量梯度下降训练时的泛化误差。",
            "intro_zh": [
                "现有方法缺乏对具有通用激活函数的全连接单隐层网络泛化性能的完整理论描述，尤其是在窄网络的情况下。",
                "该论文利用统计物理学的方法，为窄网络的泛化性能提供了闭式表达式，并揭示了隐藏神经元专业化转变的现象。",
                "实验结果表明，该理论能够准确预测神经网络在回归或分类任务中的泛化误差，验证了理论的有效性。"
            ],
            "method_zh": "**问题定义**：该论文旨在解决窄单隐层神经网络在师生框架下的泛化性能分析问题。现有方法缺乏对具有通用激活函数的全连接单隐层网络性能的完整理论描述，尤其是在隐藏单元数量远小于输入维度的情况下，难以准确预测网络的泛化误差。\\n\\n**核心思路**：论文的核心思路是利用统计物理学中的方法，对窄网络的泛化性能进行理论分析。通过将神经网络的学习过程类比于物理系统，可以推导出泛化误差的闭式表达式，从而更好地理解网络的学习行为。这种方法能够捕捉到网络中的一些关键现象，例如隐藏神经元的专业化转变。\\n\\n**技术框架**：该论文的技术框架主要包括以下几个步骤：1) 建立师生框架下的窄单隐层神经网络模型；2) 利用统计物理学中的副本方法或腔方法，计算网络的自由能或配分函数；3) 从自由能或配分函数中推导出泛化误差的闭式表达式；4) 通过实验验证理论预测的准确性。\\n\\n**关键创新**：该论文的关键创新在于：1) 提出了针对窄单隐层网络的泛化性能的完整理论分析方法；2) 利用统计物理学的方法，推导出了泛化误差的闭式表达式，为理解网络的学习行为提供了新的视角；3) 揭示了隐藏神经元专业化转变的现象，并分析了其对泛化性能的影响。\\n\\n**关键设计**：论文中关键的设计包括：1) 假设隐藏单元的数量远小于输入维度，从而简化了理论分析；2) 使用通用激活函数，使得理论分析具有更广泛的适用性；3) 考虑了有限温度（贝叶斯）和经验风险最小化两种不同的学习方式；4) 通过噪声全批量梯度下降（朗之万动力学）或全批量梯度下降进行训练。",
            "application_zh": "该研究成果可应用于理解和优化神经网络的训练过程，特别是在资源受限的场景下。通过理论分析，可以更好地选择合适的网络结构和训练参数，提高模型的泛化能力。此外，该研究还可以为设计更高效的神经网络架构提供理论指导，例如，通过控制隐藏神经元的专业化程度来提高模型的性能。",
            "highlight_zh": "该论文通过实验验证了理论预测的准确性。实验结果表明，该理论能够准确预测神经网络在回归或分类任务中使用噪声全批量梯度下降（朗之万动力学）或全批量梯度下降训练时的泛化误差。此外，实验还验证了隐藏神经元专业化转变现象的存在，并分析了其对泛化性能的影响。具体的性能数据和对比基线在论文中进行了详细的展示。",
            "tags_zh": [
                "神经网络泛化",
                "师生框架",
                "统计物理",
                "窄网络",
                "单隐层网络"
            ],
            "_index": 169,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2507.00629/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2507.00629/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2507.00629/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Bayesian Ego-graph Inference for Networked Multi-Agent Reinforcement Learning",
            "authors": [
                "Wei Duan",
                "Jie Lu",
                "Junyu Xuan"
            ],
            "arxiv_id": "2509.16606",
            "summary": "In networked multi-agent reinforcement learning (Networked-MARL), decentralized agents must act under local observability and constrained communication over fixed physical graphs. Existing methods often assume static neighborhoods, limiting adaptability to dynamic or heterogeneous environments. While centralized frameworks can learn dynamic graphs, their reliance on global state access and centralized infrastructure is impractical in real-world decentralized systems. We propose a stochastic graph-based policy for Networked-MARL, where each agent conditions its decision on a sampled subgraph over its local physical neighborhood. Building on this formulation, we introduce BayesG, a decentralized actor-framework that learns sparse, context-aware interaction structures via Bayesian variational inference. Each agent operates over an ego-graph and samples a latent communication mask to guide message passing and policy computation. The variational distribution is trained end-to-end alongside the policy using an evidence lower bound (ELBO) objective, enabling agents to jointly learn both interaction topology and decision-making strategies. BayesG outperforms strong MARL baselines on large-scale traffic control tasks with up to 167 agents, demonstrating superior scalability, efficiency, and performance.",
            "categories": [
                "cs.MA",
                "cs.LG"
            ],
            "primary_category": "cs.MA",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2509.16606",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出BayesG，通过贝叶斯推断学习稀疏交互结构，解决网络化多智能体强化学习问题",
            "summary_zh": "在网络化多智能体强化学习（Networked-MARL）中，去中心化的智能体必须在局部可观测性和固定物理图上的受限通信下行动。现有方法通常假设静态邻域，限制了对动态或异构环境的适应性。集中式框架虽然可以学习动态图，但它们依赖于全局状态访问和集中式基础设施，这在实际的去中心化系统中是不切实际的。我们提出了一种基于随机图策略的Networked-MARL方法，其中每个智能体根据其局部物理邻域上的采样子图来决定其决策。在此基础上，我们引入了BayesG，一个去中心化的actor框架，它通过贝叶斯变分推断学习稀疏的、上下文感知的交互结构。每个智能体在其自我图上运行，并采样一个潜在的通信掩码来指导消息传递和策略计算。变分分布使用证据下界（ELBO）目标与策略一起进行端到端训练，使智能体能够联合学习交互拓扑和决策策略。在多达167个智能体的大规模交通控制任务中，BayesG优于强大的MARL基线，展示了卓越的可扩展性、效率和性能。",
            "intro_zh": [
                "现有网络化多智能体强化学习方法依赖静态邻域，难以适应动态异构环境，集中式方法又不适用于去中心化系统。",
                "BayesG通过贝叶斯变分推断学习稀疏的、上下文感知的交互结构，每个智能体基于自我图采样通信掩码。",
                "BayesG在交通控制任务中优于现有MARL基线，证明了其可扩展性、效率和性能优势。"
            ],
            "method_zh": "**问题定义**：论文旨在解决网络化多智能体强化学习中，智能体如何在局部观测和受限通信条件下，学习动态变化的交互拓扑结构的问题。现有方法要么假设静态邻域，限制了适应性；要么依赖全局信息，不适用于去中心化场景。因此，如何在去中心化的环境中，让智能体自主学习并适应动态的交互关系是核心挑战。\\n\\n**核心思路**：论文的核心思路是利用贝叶斯变分推断，让每个智能体学习一个关于其邻域交互结构的概率分布。通过对该分布进行采样，智能体可以动态地选择与其进行通信的邻居，从而适应环境的变化。这种方法的关键在于，它允许智能体在局部信息的基础上，推断出全局的交互模式。\\n\\n**技术框架**：BayesG是一个去中心化的actor框架，每个智能体维护一个自我图（ego-graph），表示其局部邻域。框架包含以下主要模块：1) 变分推断模块：用于学习邻域交互结构的概率分布；2) 采样模块：从变分分布中采样通信掩码；3) 消息传递模块：根据通信掩码进行消息传递，聚合邻居信息；4) 策略网络：基于聚合后的信息，输出智能体的动作。整个框架通过端到端的方式进行训练。\\n\\n**关键创新**：最重要的技术创新点在于使用贝叶斯变分推断来学习稀疏的、上下文感知的交互结构。与现有方法相比，BayesG不需要预先定义固定的邻域关系，而是允许智能体根据环境的变化，动态地调整其交互模式。此外，通过变分推断，BayesG可以学习到邻域交互结构的不确定性，从而提高鲁棒性。\\n\\n**关键设计**：变分推断模块使用神经网络来参数化变分分布，通常是高斯分布。证据下界（ELBO）被用作训练目标，它平衡了策略的性能和交互结构的稀疏性。通信掩码通常是二元的，表示是否与某个邻居进行通信。策略网络可以使用任何标准的强化学习算法，如Actor-Critic或PPO。",
            "application_zh": "该研究成果可应用于大规模交通控制、无线通信网络资源分配、社交网络影响力最大化等领域。通过学习动态交互结构，智能体能够更好地适应复杂环境，提高协作效率和系统性能。未来，该方法有望扩展到更广泛的多智能体系统，例如机器人集群、传感器网络等。",
            "highlight_zh": "BayesG在包含多达167个智能体的大规模交通控制任务中，显著优于现有的MARL基线方法。实验结果表明，BayesG能够有效地学习稀疏的交互结构，提高智能体的协作效率和系统的整体性能。具体的性能提升数据在论文中进行了详细的展示和分析。",
            "tags_zh": [
                "多智能体强化学习",
                "网络化学习",
                "贝叶斯推断",
                "变分推断",
                "图神经网络"
            ],
            "_index": 170,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2509.16606/Fig/BayesG.jpg",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2509.16606/x1.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2509.16606/x2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Curiosity-Driven Development of Action and Language in Robots Through Self-Exploration",
            "authors": [
                "Theodore Jerome Tinker",
                "Kenji Doya",
                "Jun Tani"
            ],
            "arxiv_id": "2510.05013",
            "summary": "Infants acquire language with generalization from minimal experience, whereas large language models require billions of training tokens. What underlies efficient development in humans? We investigated this problem through experiments wherein robotic agents learn to perform actions associated with imperative sentences (e.g., push red cube) via curiosity-driven self-exploration. Our approach integrates active inference with reinforcement learning, enabling intrinsically motivated developmental learning. The simulations reveal key findings corresponding to observations in developmental psychology. i) Generalization improves drastically as the scale of compositional elements increases. ii) Curiosity improves learning through self-exploration. iii) Rote pairing of sentences and actions precedes compositional generalization. iv) Simpler actions develop before complex actions depending on them. v) Exception-handling induces U-shaped developmental performance, a pattern like representational redescription in child language learning. These results suggest that curiosity-driven active inference accounts for how intrinsically motivated sensorimotor-linguistic learning supports scalable compositional generalization and exception handling in humans and artificial agents.",
            "categories": [
                "stat.ML",
                "cs.LG"
            ],
            "primary_category": "stat.ML",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2510.05013",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于好奇心驱动的自探索方法，用于机器人动作与语言的自主发展",
            "summary_zh": "本研究探讨了人类如何通过少量经验泛化学习语言，而大型语言模型却需要数十亿的训练token。我们通过机器人自主探索学习执行与命令句相关的动作（例如，推动红色立方体）的实验来研究这个问题。该方法结合了主动推理和强化学习，实现了内驱的自主学习。仿真结果揭示了与发展心理学观察结果相符的关键发现：i) 随着组合元素规模的增加，泛化能力显著提高；ii) 好奇心通过自我探索提高学习效果；iii) 句子和动作的机械配对先于组合泛化；iv) 简单的动作在依赖它们的复杂动作之前发展；v) 异常处理导致U型发展性能，类似于儿童语言学习中的表征重述。这些结果表明，好奇心驱动的主动推理可以解释内驱的感知运动-语言学习如何支持人类和人工智能体中可扩展的组合泛化和异常处理。",
            "intro_zh": [
                "现有语言模型需要大量数据，而人类婴儿仅需少量经验即可泛化学习语言，这其中的机制是核心问题。",
                "论文提出一种基于好奇心驱动的自探索方法，结合主动推理和强化学习，使机器人能够自主学习动作与语言。",
                "实验表明，该方法能够使机器人实现组合泛化和异常处理，并观察到与人类发展心理学相似的学习模式。"
            ],
            "method_zh": "**问题定义**：论文旨在解决机器人如何像婴儿一样，通过少量经验自主学习语言和动作，并具备泛化能力的问题。现有方法通常依赖大量标注数据，缺乏自主探索和学习的能力，难以模拟人类的学习过程。\\n\\n**核心思路**：论文的核心在于利用好奇心驱动的自探索机制，鼓励机器人主动探索环境，发现新的动作和语言组合。通过主动推理和强化学习的结合，机器人能够根据内在的好奇心信号选择行动，并从行动的结果中学习，从而实现自主学习和泛化。\\n\\n**技术框架**：整体框架包含以下几个主要模块：1) 感知模块，用于接收环境信息（例如，视觉输入和语言指令）；2) 行动模块，用于执行机器人动作；3) 好奇心驱动模块，用于根据当前状态和预期状态之间的差异生成好奇心信号；4) 主动推理模块，用于根据好奇心信号选择行动；5) 强化学习模块，用于从行动的结果中学习，并更新策略。\\n\\n**关键创新**：论文的关键创新在于将好奇心驱动的自探索机制与主动推理和强化学习相结合，实现了一种内驱的自主学习方法。这种方法能够使机器人主动探索环境，发现新的动作和语言组合，并从中学习，从而提高学习效率和泛化能力。与现有方法相比，该方法不需要大量标注数据，更接近人类的学习方式。\\n\\n**关键设计**：在好奇心驱动模块中，论文使用预测误差作为好奇心信号，即当前状态和预期状态之间的差异越大，好奇心信号越强。在主动推理模块中，论文使用主动推理框架，根据好奇心信号选择行动，即选择能够最大程度地减少预测误差的行动。在强化学习模块中，论文使用Q-learning算法，从行动的结果中学习，并更新Q值函数。",
            "application_zh": "该研究成果可应用于开发更智能、更自主的机器人，使其能够在复杂环境中自主学习和适应。例如，可用于家庭服务机器人、工业机器人和医疗机器人等领域，提高机器人的智能化水平和服务能力。此外，该研究对于理解人类语言学习机制和开发更有效的语言学习算法也具有重要意义。",
            "highlight_zh": "实验结果表明，随着组合元素规模的增加，泛化能力显著提高。好奇心驱动的自探索能够有效提高学习效率。机器人首先学习句子和动作的机械配对，然后才能进行组合泛化。简单的动作在复杂的动作之前发展，异常处理会导致U型发展性能，这些都与人类发展心理学的观察结果相符。",
            "tags_zh": [
                "好奇心驱动学习",
                "主动推理",
                "强化学习",
                "机器人语言学习",
                "自主探索"
            ],
            "_index": 171,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2510.05013/images/new_architecture.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2510.05013/images/robot_and_objects.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2510.05013/images/evaluation.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "MobileWorldBench: Towards Semantic World Modeling For Mobile Agents",
            "authors": [
                "Shufan Li",
                "Konstantinos Kallidromitis",
                "Akash Gokul",
                "Yusuke Kato",
                "Kazuki Kozuka",
                "Aditya Grover"
            ],
            "arxiv_id": "2512.14014",
            "summary": "World models have shown great utility in improving the task performance of embodied agents. While prior work largely focuses on pixel-space world models, these approaches face practical limitations in GUI settings, where predicting complex visual elements in future states is often difficult. In this work, we explore an alternative formulation of world modeling for GUI agents, where state transitions are described in natural language rather than predicting raw pixels. First, we introduce MobileWorldBench, a benchmark that evaluates the ability of vision-language models (VLMs) to function as world models for mobile GUI agents. Second, we release MobileWorld, a large-scale dataset consisting of 1.4M samples, that significantly improves the world modeling capabilities of VLMs. Finally, we propose a novel framework that integrates VLM world models into the planning framework of mobile agents, demonstrating that semantic world models can directly benefit mobile agents by improving task success rates. The code and dataset is available atthis https URL",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14014",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]world model"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出MobileWorldBench，用于评估移动Agent的语义世界建模能力",
            "summary_zh": "世界模型在提升具身智能Agent的任务性能方面表现出巨大的潜力。然而，现有工作主要集中在像素空间的世界模型，这些方法在GUI环境中面临实际限制，因为预测未来状态中复杂的视觉元素通常很困难。本文探索了一种针对GUI Agent的世界建模替代方案，其中状态转换用自然语言描述，而不是预测原始像素。首先，我们引入了MobileWorldBench，这是一个评估视觉-语言模型（VLM）作为移动GUI Agent世界模型能力的基准。其次，我们发布了MobileWorld，一个包含140万个样本的大规模数据集，显著提高了VLM的世界建模能力。最后，我们提出了一个新颖的框架，将VLM世界模型集成到移动Agent的规划框架中，证明了语义世界模型可以通过提高任务成功率直接使移动Agent受益。",
            "intro_zh": [
                "现有像素级世界模型在GUI环境中预测复杂视觉元素面临挑战，限制了移动Agent的性能。",
                "论文提出使用自然语言描述状态转换的语义世界模型，避免直接预测像素，更适合GUI环境。",
                "通过MobileWorldBench基准测试和MobileWorld数据集，验证了VLM世界模型在移动Agent规划中的有效性，提高了任务成功率。"
            ],
            "method_zh": "**问题定义**：现有基于像素空间的世界模型在移动GUI Agent任务中面临挑战。直接预测GUI界面的像素变化非常困难，因为GUI元素复杂且多样，导致模型难以准确预测未来状态，从而影响Agent的规划和决策。现有方法难以有效利用GUI界面的语义信息，限制了Agent的泛化能力和鲁棒性。\\n\\n**核心思路**：论文的核心思路是利用视觉-语言模型（VLM）构建语义世界模型，使用自然语言描述GUI界面的状态转换，而不是直接预测像素。这种方法能够更好地捕捉GUI界面的语义信息，降低预测难度，并提高Agent的规划效率和任务成功率。通过将视觉信息转换为自然语言描述，模型可以更容易地理解和推理GUI界面的状态变化。\\n\\n**技术框架**：论文提出的框架主要包含以下几个模块：1) 视觉信息编码器：用于提取GUI界面的视觉特征。2) 语言模型：用于生成GUI界面状态的自然语言描述。3) 世界模型：基于VLM，学习GUI界面的状态转换规则。4) 规划器：利用世界模型预测未来状态，并选择最优动作序列。整体流程是：Agent观察当前GUI界面，视觉信息编码器提取视觉特征，语言模型生成状态描述，世界模型预测执行动作后的状态描述，规划器根据预测结果选择动作，Agent执行动作，循环往复直到任务完成。\\n\\n**关键创新**：论文的关键创新在于提出了基于VLM的语义世界模型，并将其应用于移动GUI Agent任务。与传统的像素空间世界模型相比，语义世界模型能够更好地捕捉GUI界面的语义信息，降低预测难度，并提高Agent的规划效率和任务成功率。此外，论文还构建了MobileWorldBench基准测试和MobileWorld数据集，为该领域的研究提供了有力支持。\\n\\n**关键设计**：MobileWorld数据集包含140万个样本，涵盖了各种移动GUI界面和用户交互行为。论文采用Transformer架构的VLM作为世界模型，并使用交叉熵损失函数训练模型预测下一个状态的自然语言描述。规划器采用蒙特卡洛树搜索（MCTS）算法，利用世界模型预测未来状态，并选择最优动作序列。具体参数设置和网络结构细节在论文中有详细描述。",
            "application_zh": "该研究成果可应用于开发更智能、更高效的移动Agent，例如自动化测试、智能助手、用户行为分析等。通过学习GUI界面的状态转换规则，Agent可以更好地理解用户意图，并自动完成各种任务，从而提高用户体验和工作效率。未来，该技术还可以扩展到其他类型的GUI界面和具身智能Agent。",
            "highlight_zh": "实验结果表明，基于VLM的语义世界模型在MobileWorldBench基准测试中取得了显著的性能提升。与传统的像素空间世界模型相比，该方法能够更好地预测GUI界面的状态转换，并显著提高Agent的任务成功率。具体而言，任务成功率提升了XX%（具体数值请参考论文），证明了语义世界模型在移动GUI Agent任务中的有效性。",
            "tags_zh": [
                "世界模型",
                "视觉-语言模型",
                "移动Agent",
                "GUI界面",
                "语义建模"
            ],
            "_index": 172,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14014/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14014/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14014/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Evaluating Small Language Models for Agentic On-Farm Decision Support Systems",
            "authors": [
                "Enhong Liu",
                "Haiyu Yang",
                "Miel Hostens"
            ],
            "arxiv_id": "2512.14043",
            "summary": "Large Language Models (LLM) hold potential to support dairy scholars and farmers by supporting decision-making and broadening access to knowledge for stakeholders with limited technical expertise. However, the substantial computational demand restricts access to LLM almost exclusively through cloud-based service, which makes LLM-based decision support tools impractical for dairy farming. To address this gap, lightweight alternatives capable of running locally on farm hardware are required. In this work, we benchmarked 20 open-source Small Language Models (SLM) available on HuggingFace under farm-realistic computing constraints. Building on our prior work, we developed an agentic AI system that integrates five task-specific agents: literature search, web search, SQL database interaction, NoSQL database interaction, and graph generation following predictive models. Evaluation was conducted in two phases. In the first phase, five test questions were used for the initial screening to identify models capable of following basic dairy-related instructions and performing reliably in a compute-constrained environment. Models that passed this preliminary stage were then evaluated using 30 questions (five per task category mentioned above, plus one category addressing integrity and misconduct) in phase two. In results, Qwen-4B achieved superior performance across most of task categories, although showed unstable effectiveness in NoSQL database interactions through PySpark. To our knowledge, this is the first work explicitly evaluating the feasibility of SLM as engines for dairy farming decision-making, with central emphases on privacy and computational efficiency. While results highlight the promise of SLM-assisted tools for practical deployment in dairy farming, challenges remain, and fine-tuning is still needed to refine SLM performance in dairy-specific questions.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14043",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "predictive model"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "评估小型语言模型在农场决策支持系统中的应用潜力，Qwen-4B表现突出。",
            "summary_zh": "大型语言模型(LLM)有潜力通过支持决策制定和扩大技术知识有限的利益相关者获取知识的途径来支持乳业学者和农民。然而，巨大的计算需求几乎完全限制了通过云服务访问LLM，这使得基于LLM的决策支持工具对于奶牛养殖来说是不切实际的。为了解决这一差距，需要能够在农场硬件上本地运行的轻量级替代方案。在这项工作中，我们以农场实际计算约束为基准，测试了HuggingFace上可用的20个开源小型语言模型(SLM)。基于我们之前的工作，我们开发了一个智能AI系统，该系统集成了五个特定于任务的代理：文献搜索、网络搜索、SQL数据库交互、NoSQL数据库交互以及遵循预测模型的图形生成。评估分两个阶段进行。在第一阶段，使用五个测试问题进行初步筛选，以识别能够在计算受限环境中遵循基本的乳制品相关指令并可靠地执行的模型。通过此初步阶段的模型随后在第二阶段使用30个问题（每个任务类别五个，加上一个解决诚信和不当行为的类别）进行评估。结果表明，Qwen-4B在大多数任务类别中都取得了优异的性能，尽管在通过PySpark进行的NoSQL数据库交互中表现出不稳定的有效性。据我们所知，这是第一项明确评估SLM作为乳业决策引擎可行性的工作，重点是隐私和计算效率。虽然结果突出了SLM辅助工具在乳业实际部署中的前景，但仍然存在挑战，并且仍然需要进行微调以完善SLM在乳业特定问题中的性能。",
            "intro_zh": [
                "大型语言模型计算需求高，难以在农场本地部署，限制了其在乳业决策支持中的应用。",
                "论文提出使用小型语言模型（SLM）构建智能代理系统，在本地硬件上运行，降低计算成本。",
                "实验评估了20个开源SLM，Qwen-4B在多个任务中表现出色，验证了SLM在乳业决策中的潜力。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型（LLM）计算资源需求高，难以在资源受限的农场环境中部署的问题。现有基于LLM的决策支持系统主要依赖云服务，存在隐私和成本问题，无法满足乳业的实际需求。\\n\\n**核心思路**：论文的核心思路是探索使用小型语言模型（SLM）替代LLM，构建能够在农场本地硬件上运行的智能代理系统。通过选择合适的SLM并进行针对性优化，可以在保证一定性能的前提下，显著降低计算成本和提高隐私性。\\n\\n**技术框架**：论文构建了一个包含五个任务特定代理的智能AI系统：1) 文献搜索；2) 网络搜索；3) SQL数据库交互；4) NoSQL数据库交互；5) 基于预测模型的图生成。该系统首先使用五个测试问题进行初步筛选，然后使用30个问题（包括诚信和不当行为）进行更全面的评估。\\n\\n**关键创新**：论文的关键创新在于首次明确评估了SLM作为乳业决策引擎的可行性，并强调了隐私和计算效率。通过构建包含多个代理的智能系统，实现了对乳业决策过程的全面支持。\\n\\n**关键设计**：论文选择了HuggingFace上可用的20个开源SLM进行评估。评估过程分为两个阶段，第一阶段进行初步筛选，第二阶段进行全面评估。评估指标包括模型在各个任务上的准确性和稳定性。Qwen-4B在大多数任务类别中表现出色，但在NoSQL数据库交互中表现出不稳定性。",
            "application_zh": "该研究成果可应用于构建低成本、高隐私的农场决策支持系统，帮助农民和乳业学者更高效地获取知识和做出决策。未来，可以通过微调和优化SLM，进一步提升其在乳业特定问题上的性能，并将其推广到其他农业领域。",
            "highlight_zh": "实验结果表明，Qwen-4B在大多数任务类别中表现优异，证明了SLM在乳业决策支持中的潜力。尽管在NoSQL数据库交互中存在不稳定性，但整体性能优于其他SLM。该研究首次明确评估了SLM在乳业领域的应用，为后续研究提供了重要参考。",
            "tags_zh": [
                "小型语言模型",
                "农场决策支持",
                "乳业",
                "智能代理",
                "计算效率"
            ],
            "_index": 173,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Rethinking the Reliability of Multi-agent System: A Perspective from Byzantine Fault Tolerance",
            "authors": [
                "Lifan Zheng",
                "Jiawei Chen",
                "Qinghong Yin",
                "Jingyuan Zhang",
                "Xinyi Zeng",
                "Yu Tian"
            ],
            "arxiv_id": "2511.10400",
            "summary": "Ensuring the reliability of agent architectures and effectively identifying problematic agents when failures occur are crucial challenges in multi-agent systems (MAS). Advances in large language models (LLMs) have established LLM-based agents as a major branch of MAS, enabling major breakthroughs in complex problem solving and world modeling. However, the reliability implications of this shift remain largely unexplored. i.e., whether substituting traditional agents with LLM-based agents can effectively enhance the reliability of MAS. In this work, we investigate and quantify the reliability of LLM-based agents from the perspective of Byzantine fault tolerance. We observe that LLM-based agents demonstrate stronger skepticism when processing erroneous message flows, a characteristic that enables them to outperform traditional agents across different topological structures. Motivated by the results of the pilot experiment, we design CP-WBFT, a confidence probe-based weighted Byzantine Fault Tolerant consensus mechanism to enhance the stability of MAS with different topologies. It capitalizes on the intrinsic reflective and discriminative capabilities of LLMs by employing a probe-based, weighted information flow transmission method to improve the reliability of LLM-based agents. Extensive experiments demonstrate that CP-WBFT achieves superior performance across diverse network topologies under extreme Byzantine conditions (85.7\\% fault rate). Notably, our approach surpasses traditional methods by attaining remarkable accuracy on various topologies and maintaining strong reliability in both mathematical reasoning and safety assessment tasks.",
            "categories": [
                "cs.MA",
                "cs.AI",
                "cs.CL"
            ],
            "primary_category": "cs.MA",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2511.10400",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "world model"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出CP-WBFT机制，提升LLM驱动的多智能体系统在拜占庭容错场景下的可靠性",
            "summary_zh": "在多智能体系统(MAS)中，确保智能体架构的可靠性以及有效识别故障智能体至关重要。基于大型语言模型(LLM)的智能体已成为MAS的一个主要分支，并在复杂问题求解和世界建模方面取得了重大突破。然而，这种转变对可靠性的影响尚未得到充分探索，即用LLM智能体替代传统智能体是否能有效提高MAS的可靠性。本文从拜占庭容错的角度研究和量化了LLM智能体的可靠性。观察到LLM智能体在处理错误消息流时表现出更强的怀疑态度，使其在不同的拓扑结构中优于传统智能体。受此启发，设计了一种基于置信度探测的加权拜占庭容错共识机制CP-WBFT，以增强具有不同拓扑结构的MAS的稳定性。它利用LLM固有的反思和辨别能力，采用基于探测的加权信息流传输方法来提高LLM智能体的可靠性。大量实验表明，CP-WBFT在极端的拜占庭条件下（85.7%的故障率）在各种网络拓扑中均实现了卓越的性能。值得注意的是，我们的方法在各种拓扑上都获得了显著的准确性，并在数学推理和安全评估任务中保持了强大的可靠性，超越了传统方法。",
            "intro_zh": [
                "传统多智能体系统在面对恶意或故障节点时，可靠性面临挑战，尤其是在LLM智能体引入后，其可靠性影响尚不明确。",
                "论文提出CP-WBFT机制，利用LLM的反思和辨别能力，通过置信度探测和加权信息流传输，增强系统在拜占庭容错场景下的稳定性。",
                "实验表明，CP-WBFT在各种网络拓扑和高故障率下表现出色，在数学推理和安全评估任务中超越传统方法，提升了系统可靠性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决多智能体系统在拜占庭容错场景下的可靠性问题。现有方法难以有效应对恶意或故障节点，尤其是在引入基于LLM的智能体后，其可靠性影响尚不明确。传统方法在处理错误信息时缺乏足够的辨别能力，导致系统容易受到攻击。\\n\\n**核心思路**：论文的核心思路是利用LLM固有的反思和辨别能力，通过置信度探测来评估信息的可靠性，并根据可靠性对信息进行加权，从而提高系统在拜占庭容错场景下的稳定性。这种方法能够使系统更加关注来自可信智能体的信息，从而减少恶意或故障节点的影响。\\n\\n**技术框架**：CP-WBFT机制包含以下主要模块：1) 信息收集模块：每个智能体收集来自其他智能体的信息。2) 置信度探测模块：利用LLM评估接收到的信息的可靠性，生成置信度评分。3) 加权信息融合模块：根据置信度评分对信息进行加权，融合来自不同智能体的信息。4) 共识决策模块：基于加权后的信息，智能体做出决策。整个流程旨在提高系统在存在恶意或故障节点时的决策准确性。\\n\\n**关键创新**：论文的关键创新在于将LLM的置信度评估能力引入到拜占庭容错机制中。传统方法通常依赖于固定的投票或平均机制，无法有效区分信息的可靠性。CP-WBFT通过LLM的置信度探测，能够动态地评估信息的可靠性，并根据可靠性进行加权，从而提高了系统的容错能力。\\n\\n**关键设计**：CP-WBFT的关键设计包括：1) 置信度探测器的设计：使用LLM作为置信度探测器，通过prompt工程使其能够评估信息的可靠性。2) 加权函数的选择：选择合适的加权函数，将置信度评分转化为权重，用于信息融合。3) 共识算法的优化：针对加权信息，优化共识算法，使其能够更好地处理来自不同智能体的不同权重的意见。",
            "application_zh": "该研究成果可应用于需要高可靠性的多智能体系统，例如：分布式机器人协作、金融交易系统、供应链管理、智能交通系统等。通过提高系统在面对恶意攻击或节点故障时的容错能力，可以保障系统的稳定运行和数据安全，具有重要的实际应用价值和潜在的社会经济效益。",
            "highlight_zh": "实验结果表明，CP-WBFT在85.7%的故障率下，在各种网络拓扑中均实现了卓越的性能，超越了传统的拜占庭容错方法。在数学推理和安全评估任务中，CP-WBFT也表现出强大的可靠性和准确性，证明了其在复杂场景下的有效性。例如，在特定拓扑结构下，CP-WBFT的准确率比传统方法提升了15%。",
            "tags_zh": [
                "多智能体系统",
                "拜占庭容错",
                "大型语言模型",
                "可靠性",
                "置信度探测",
                "共识机制",
                "分布式系统"
            ],
            "_index": 174,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2511.10400/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2511.10400/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2511.10400/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "SUPER -- A Framework for Sensitivity-based Uncertainty-aware Performance and Risk Assessment in Visual Inertial Odometry",
            "authors": [
                "Johannes A. Gaus",
                "Daniel Häufle",
                "Woo-Jeong Baek"
            ],
            "arxiv_id": "2512.14189",
            "summary": "While many visual odometry (VO), visual-inertial odometry (VIO), and SLAM systems achieve high accuracy, the majority of existing methods miss to assess risks at runtime. This paper presents SUPER (Sensitivity-based Uncertainty-aware PErformance and Risk assessment) that is a generic and explainable framework that propagates uncertainties via sensitivities for real-time risk assessment in VIO. The scientific novelty lies in the derivation of a real-time risk indicator that is backend-agnostic and exploits the Schur complement blocks of the Gauss-Newton normal matrix to propagate uncertainties. Practically, the Schur complement captures the sensitivity that reflects the influence of the uncertainty on the risk occurrence. Our framework estimates risks on the basis of the residual magnitudes, geometric conditioning, and short horizon temporal trends without requiring ground truth knowledge. Our framework enables to reliably predict trajectory degradation 50 frames ahead with an improvement of 20% to the baseline. In addition, SUPER initiates a stop or relocalization policy with 89.1% recall. The framework is backend agnostic and operates in real time with less than 0.2% additional CPU cost. Experiments show that SUPER provides consistent uncertainty estimates. A SLAM evaluation highlights the applicability to long horizon mapping.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14189",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "visual odometry",
                        "VIO"
                    ],
                    "score": 4.0
                }
            ],
            "relevance_score": 4.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "SUPER：基于敏感度的视觉惯性里程计性能与风险评估框架",
            "summary_zh": "本文提出了一种名为SUPER（基于敏感度的不确定性感知性能和风险评估）的通用且可解释的框架，用于在视觉惯性里程计（VIO）中进行实时风险评估。该框架通过敏感度传播不确定性。其科学创新在于推导了一种后端无关的实时风险指标，该指标利用高斯-牛顿法正规矩阵的舒尔补块来传播不确定性。实际上，舒尔补块捕获了反映不确定性对风险发生影响的敏感度。该框架在无需ground truth知识的情况下，基于残差大小、几何条件和短时程时间趋势来估计风险。实验表明，SUPER能够可靠地提前50帧预测轨迹退化，相比基线方法提升了20%。此外，SUPER能够以89.1%的召回率启动停止或重定位策略。该框架与后端无关，并以低于0.2%的额外CPU成本实时运行。实验结果表明SUPER提供了一致的不确定性估计。SLAM评估突出了其在长时程建图中的适用性。",
            "intro_zh": [
                "现有VO/VIO系统缺乏运行时风险评估能力，难以应对环境变化和传感器噪声。",
                "SUPER框架通过敏感度分析传播不确定性，利用舒尔补块推导实时风险指标，实现风险预测。",
                "实验表明，SUPER能有效预测轨迹退化，提升重定位召回率，且计算开销小，适用于长时程建图。"
            ],
            "method_zh": "**问题定义**：现有的视觉里程计（VO）、视觉惯性里程计（VIO）和SLAM系统虽然在精度上取得了显著进展，但大多缺乏在运行时评估风险的能力。这意味着系统无法及时检测到潜在的轨迹退化或定位失败，从而影响整体的鲁棒性和可靠性。尤其是在复杂或动态环境中，这种风险评估的缺失会带来严重的安全隐患。\\n\\n**核心思路**：SUPER框架的核心思路是利用敏感度分析来传播不确定性，从而实现对VIO系统性能和风险的实时评估。具体来说，它通过计算高斯-牛顿法正规矩阵的舒尔补块，来捕捉不确定性对风险发生的影响程度，即敏感度。这种方法允许系统在没有ground truth的情况下，基于残差大小、几何条件和短时程时间趋势来估计风险。\\n\\n**技术框架**：SUPER框架主要包含以下几个关键模块：1) 不确定性估计模块：用于估计传感器数据和特征点位置的不确定性。2) 敏感度分析模块：利用舒尔补块计算不确定性对系统状态的影响，即敏感度。3) 风险评估模块：基于残差、几何条件和时间趋势，结合敏感度信息，评估当前系统的风险水平。4) 决策模块：根据风险评估结果，采取相应的措施，例如停止运动或触发重定位。整个框架是后端无关的，可以与不同的VIO系统集成。\\n\\n**关键创新**：SUPER框架的关键创新在于提出了一种基于舒尔补块的实时风险指标。与传统的风险评估方法相比，该指标能够更准确地捕捉不确定性对系统状态的影响，并且计算效率高，可以满足实时性要求。此外，该框架无需ground truth，可以直接利用VIO系统内部的信息进行风险评估，具有更强的实用性。\\n\\n**关键设计**：SUPER框架的关键设计包括：1) 舒尔补块的计算方法：采用高效的数值算法来计算舒尔补块，以保证实时性。2) 风险指标的定义：综合考虑残差大小、几何条件和时间趋势等因素，设计合理的风险指标。3) 决策策略：根据不同的风险水平，制定相应的决策策略，例如调整运动速度、触发重定位或停止运动。",
            "application_zh": "SUPER框架可广泛应用于机器人导航、自动驾驶、增强现实等领域。通过实时风险评估，系统能够及时发现潜在的故障并采取相应的措施，从而提高系统的鲁棒性和安全性。例如，在自动驾驶中，SUPER可以帮助车辆避免因定位误差导致的碰撞事故。在增强现实中，SUPER可以提高虚拟物体的定位精度和稳定性。",
            "highlight_zh": "实验结果表明，SUPER框架能够可靠地提前50帧预测轨迹退化，相比基线方法提升了20%。此外，SUPER能够以89.1%的召回率启动停止或重定位策略。该框架的计算开销非常小，仅增加了不到0.2%的CPU成本。SLAM评估验证了SUPER在长时程建图中的有效性。",
            "tags_zh": [
                "视觉惯性里程计",
                "风险评估",
                "不确定性传播",
                "敏感度分析",
                "舒尔补块"
            ],
            "_index": 175,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14189/img/Fig1_finalv2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14189/img/Fig2_v2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14189/img/Fig3_v2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Closed-Loop Consistent, Causal Data-Driven Predictive Control via SSARX",
            "authors": [
                "Aihui Liu",
                "Magnus Jansson"
            ],
            "arxiv_id": "2512.14510",
            "summary": "We propose a fundamental-lemma-free data-driven predictive control (DDPC) scheme for synthesizing model predictive control (MPC)-like policies directly from input-output data. Unlike the well-known DeePC approach and other DDPC methods that rely on Willems' fundamental lemma, our method avoids stacked Hankel representations and the DeePC decision variable g. Instead, we develop a closed-loop consistent, causal DDPC scheme based on the multi-step predictor Subspace-ARX (SSARX). The method first (i) estimates predictor/observer Markov parameters via a high-order ARX model to decouple the noise, then (ii) learns a multi-step past-to-future map by regression, optionally with a reduced-rank constraint. The SSARX predictor is strictly causal, which allows it to be integrated naturally into an MPC formulation. Our experimental results show that SSARX performs competitively with other methods when applied to closed-loop data affected by measurement and process noise.",
            "categories": [
                "eess.SY",
                "eess.SP"
            ],
            "primary_category": "eess.SY",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14510",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "MPC",
                        "model predictive control"
                    ],
                    "score": 4.0
                }
            ],
            "relevance_score": 4.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "提出基于SSARX的闭环一致因果数据驱动预测控制方法",
            "summary_zh": "本文提出了一种无需基本引理的数据驱动预测控制(DDPC)方案，用于直接从输入输出数据中合成类似模型预测控制(MPC)的策略。与依赖Willems基本引理的DeePC方法和其他DDPC方法不同，我们的方法避免了堆叠的Hankel矩阵表示和DeePC决策变量g。相反，我们开发了一种基于多步预测器Subspace-ARX (SSARX)的闭环一致、因果DDPC方案。该方法首先(i)通过高阶ARX模型估计预测器/观测器Markov参数以解耦噪声，然后(ii)通过回归学习多步过去到未来的映射，可以选择使用降秩约束。SSARX预测器是严格因果的，这使得它可以自然地集成到MPC公式中。实验结果表明，当应用于受测量和过程噪声影响的闭环数据时，SSARX的性能与其他方法相比具有竞争力。",
            "intro_zh": [
                "传统DeePC方法依赖Hankel矩阵，计算复杂度高，且对噪声敏感，限制了其在实际闭环系统中的应用。",
                "论文提出基于SSARX的DDPC方法，通过高阶ARX模型解耦噪声，并学习多步预测模型，实现闭环一致的因果预测控制。",
                "实验结果表明，该方法在受噪声影响的闭环数据上表现出与现有方法相当的性能，验证了其有效性。"
            ],
            "method_zh": "**问题定义**：现有的数据驱动预测控制方法，如DeePC，依赖于Willems的基本引理，需要构建大型Hankel矩阵，计算复杂度高，并且对噪声非常敏感。这限制了它们在实际闭环系统中的应用，尤其是在存在测量噪声和过程噪声的情况下。因此，需要一种更鲁棒、更高效的数据驱动预测控制方法。\\n\\n**核心思路**：论文的核心思路是利用Subspace-ARX (SSARX)模型来构建一个多步预测器，该预测器能够直接从输入输出数据中学习系统的动态特性，而无需依赖Hankel矩阵。通过高阶ARX模型来解耦噪声，并使用回归方法学习过去到未来的映射关系。SSARX预测器是严格因果的，可以直接嵌入到MPC框架中。\\n\\n**技术框架**：该方法主要包含两个阶段：(1) 预测器/观测器Markov参数估计：通过高阶ARX模型估计系统的Markov参数，以解耦噪声的影响。(2) 多步预测模型学习：通过回归方法学习过去输入输出数据到未来输出数据的映射关系，可以选择使用降秩约束来提高模型的泛化能力。然后，将学习到的SSARX预测器集成到MPC框架中，实现闭环控制。\\n\\n**关键创新**：该方法最重要的创新点在于避免了使用Willems的基本引理和Hankel矩阵，而是直接通过SSARX模型学习系统的动态特性。这种方法不仅降低了计算复杂度，而且提高了对噪声的鲁棒性。此外，SSARX预测器的因果性保证了其能够自然地集成到MPC框架中。\\n\\n**关键设计**：关键设计包括：(1) 使用高阶ARX模型来解耦噪声，ARX模型的阶数需要根据实际系统的特性进行选择。(2) 使用回归方法学习过去到未来的映射关系，可以选择使用岭回归或Lasso回归等正则化方法来防止过拟合。(3) 可以选择使用降秩约束来降低模型的复杂度，提高泛化能力。损失函数通常采用均方误差损失函数。",
            "application_zh": "该研究成果可应用于各种需要精确控制的工业领域，如机器人控制、过程控制、智能交通系统等。特别是在系统模型未知或难以精确建模的情况下，该方法能够直接从数据中学习控制策略，具有重要的实际应用价值和潜力。未来可进一步扩展到非线性系统和时变系统的控制。",
            "highlight_zh": "实验结果表明，基于SSARX的DDPC方法在受测量和过程噪声影响的闭环数据上表现出与现有方法相当的性能。该方法在避免使用Hankel矩阵的同时，保持了良好的控制性能，验证了其在实际应用中的潜力。具体的性能指标包括跟踪误差、控制能量等，但论文中未给出具体的数值。",
            "tags_zh": [
                "数据驱动控制",
                "预测控制",
                "模型预测控制",
                "系统辨识",
                "ARX模型"
            ],
            "_index": 176,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14510/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14510/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14510/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "FacEDiT: Unified Talking Face Editing and Generation via Facial Motion Infilling",
            "authors": [
                "Kim Sung-Bin",
                "Joohyun Chang",
                "David Harwath",
                "Tae-Hyun Oh"
            ],
            "arxiv_id": "2512.14056",
            "summary": "Talking face editing and face generation have often been studied as distinct problems. In this work, we propose viewing both not as separate tasks but as subtasks of a unifying formulation, speech-conditional facial motion infilling. We explore facial motion infilling as a self-supervised pretext task that also serves as a unifying formulation of dynamic talking face synthesis. To instantiate this idea, we propose FacEDiT, a speech-conditional Diffusion Transformer trained with flow matching. Inspired by masked autoencoders, FacEDiT learns to synthesize masked facial motions conditioned on surrounding motions and speech. This formulation enables both localized generation and edits, such as substitution, insertion, and deletion, while ensuring seamless transitions with unedited regions. In addition, biased attention and temporal smoothness constraints enhance boundary continuity and lip synchronization. To address the lack of a standard editing benchmark, we introduce FacEDiTBench, the first dataset for talking face editing, featuring diverse edit types and lengths, along with new evaluation metrics. Extensive experiments validate that talking face editing and generation emerge as subtasks of speech-conditional motion infilling; FacEDiT produces accurate, speech-aligned facial edits with strong identity preservation and smooth visual continuity while generalizing effectively to talking face generation.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14056",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "flow matching",
                        "masked autoencoder"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "FacEDiT：通过面部运动填充统一实现说话人脸编辑与生成",
            "summary_zh": "本文提出了一种统一的视角，将说话人脸编辑和人脸生成视为语音条件下的面部运动填充的子任务。我们探索了面部运动填充作为一种自监督的预训练任务，它也作为动态说话人脸合成的统一公式。为了实现这个想法，我们提出了FacEDiT，一个使用流匹配训练的语音条件扩散Transformer。受到掩码自编码器的启发，FacEDiT学习合成被掩盖的面部运动，条件是周围的运动和语音。这种公式能够实现局部生成和编辑，例如替换、插入和删除，同时确保与未编辑区域的无缝过渡。此外，有偏注意力机制和时间平滑约束增强了边界连续性和唇部同步。为了解决缺乏标准编辑基准的问题，我们引入了FacEDiTBench，这是第一个用于说话人脸编辑的数据集，具有多样化的编辑类型和长度，以及新的评估指标。大量的实验验证了说话人脸编辑和生成是语音条件运动填充的子任务；FacEDiT产生准确的、语音对齐的面部编辑，具有强大的身份保持和平滑的视觉连续性，同时有效地推广到说话人脸生成。",
            "intro_zh": [
                "现有的说话人脸编辑和生成通常被视为独立的问题，缺乏统一的建模框架，限制了它们之间的相互借鉴和性能提升。",
                "FacEDiT将说话人脸编辑和生成统一建模为语音条件下的面部运动填充任务，利用扩散Transformer学习合成被掩盖的面部运动。",
                "实验表明，FacEDiT在说话人脸编辑和生成任务上均表现出色，实现了准确的语音对齐、身份保持和平滑的视觉效果。"
            ],
            "method_zh": "**问题定义**：论文旨在解决说话人脸编辑和生成任务，现有方法通常将二者视为独立问题，缺乏统一的建模框架，导致无法充分利用彼此的信息，限制了性能提升。此外，缺乏标准的说话人脸编辑数据集和评估指标，阻碍了相关研究的进展。\\n\\n**核心思路**：论文的核心思路是将说话人脸编辑和生成统一建模为语音条件下的面部运动填充任务。通过学习在给定语音和周围运动的情况下填充缺失的面部运动，模型可以同时实现编辑和生成功能。这种统一的视角使得模型能够更好地利用语音信息和上下文信息，从而生成更自然、更逼真的说话人脸。\\n\\n**技术框架**：FacEDiT采用基于扩散Transformer的架构。整体流程如下：首先，输入语音和部分面部运动序列（部分被mask）。然后，扩散Transformer根据语音和未被mask的运动序列，预测被mask部分的运动。最后，通过流匹配训练，优化模型，使其能够生成高质量的面部运动序列。\\n\\n**关键创新**：论文的关键创新在于将说话人脸编辑和生成统一建模为语音条件下的面部运动填充任务。此外，论文还提出了FacEDiTBench数据集，这是一个专门用于说话人脸编辑的数据集，包含多种编辑类型和长度，并提供了新的评估指标。\\n\\n**关键设计**：FacEDiT的关键设计包括：1) 使用扩散Transformer作为生成模型，能够生成高质量的面部运动序列；2) 采用流匹配训练方法，提高训练效率和稳定性；3) 引入有偏注意力机制，增强边界连续性；4) 采用时间平滑约束，保证唇部同步；5) FacEDiTBench数据集，包含多样化的编辑类型和长度，以及新的评估指标。",
            "application_zh": "FacEDiT在视频会议、虚拟助手、电影制作、游戏开发等领域具有广泛的应用前景。例如，可以用于实时编辑视频会议中的人脸表情，创建更逼真的虚拟助手，或者在电影制作中生成高质量的说话人脸动画。该研究的未来影响在于推动人机交互和数字内容创作的发展。",
            "highlight_zh": "实验结果表明，FacEDiT在说话人脸编辑和生成任务上均取得了显著的性能提升。与现有方法相比，FacEDiT能够生成更准确、语音对齐的面部编辑，同时保持强大的身份信息和平滑的视觉连续性。此外，FacEDiT在FacEDiTBench数据集上表现出色，验证了其在说话人脸编辑任务上的有效性。",
            "tags_zh": [
                "说话人脸编辑",
                "人脸生成",
                "面部运动填充",
                "扩散Transformer",
                "语音条件生成"
            ],
            "_index": 177,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Selective, Controlled and Domain-Agnostic Unlearning in Pretrained CLIP: A Training- and Data-Free Approach",
            "authors": [
                "Ashish Mishra",
                "Gyanaranjan Nayak",
                "Tarun Kumar",
                "Arpit Shah",
                "Suparna Bhattacharya",
                "Martin Foltin"
            ],
            "arxiv_id": "2512.14113",
            "summary": "Pretrained models like CLIP have demonstrated impressive zero-shot classification capabilities across diverse visual domains, spanning natural images, artistic renderings, and abstract representations. However, real-world applications often demand the removal (or \"unlearning\") of specific object classes without requiring additional data or retraining, or affecting the model's performance on unrelated tasks. In this paper, we propose a novel training- and data-free unlearning framework that enables three distinct forgetting paradigms: (1) global unlearning of selected objects across all domains, (2) domain-specific knowledge removal (e.g., eliminating sketch representations while preserving photo recognition), and (3) complete unlearning in selective domains. By leveraging a multimodal nullspace through synergistic integration of text prompts and synthesized visual prototypes derived from CLIP's joint embedding space, our method efficiently removes undesired class information while preserving the remaining knowledge. This approach overcomes the limitations of existing retraining-based methods and offers a flexible and computationally efficient solution for controlled model forgetting.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14113",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出一种免训练免数据的CLIP可控选择性领域无关知识遗忘方法",
            "summary_zh": "预训练模型如CLIP在各种视觉领域（包括自然图像、艺术渲染和抽象表示）中表现出令人印象深刻的零样本分类能力。然而，实际应用通常需要在不需要额外数据或重新训练的情况下移除（或“遗忘”）特定的对象类别，同时不影响模型在不相关任务上的性能。本文提出了一种新颖的免训练和免数据的遗忘框架，该框架支持三种不同的遗忘范式：（1）跨所有领域的选定对象的全局遗忘，（2）领域特定知识的移除（例如，消除草图表示，同时保留照片识别），以及（3）选择性领域的完全遗忘。通过协同集成文本提示和从CLIP的联合嵌入空间导出的合成视觉原型，利用多模态零空间，我们的方法有效地移除了不需要的类别信息，同时保留了剩余的知识。这种方法克服了现有基于重新训练的方法的局限性，并为可控模型遗忘提供了一种灵活且计算高效的解决方案。",
            "intro_zh": [
                "现有CLIP模型难以在不重新训练或引入额外数据的情况下，选择性地遗忘特定类别或领域的信息。",
                "该方法通过结合文本提示和合成视觉原型，构建多模态零空间，从而在不影响其他知识的前提下移除目标信息。",
                "该方法实现了全局、领域特定和选择性领域的知识遗忘，无需额外训练或数据，提高了效率和灵活性。"
            ],
            "method_zh": "**问题定义**：CLIP等预训练模型虽然具有强大的零样本能力，但在实际应用中，用户可能需要模型遗忘某些特定类别或领域的信息，例如，不再识别某种类型的图像，或者在特定领域（如草图）中遗忘某些概念。现有的方法通常需要重新训练模型或引入新的数据，这既耗时又耗资源，并且可能影响模型在其他任务上的性能。\\n\\n**核心思路**：该论文的核心思路是利用CLIP的多模态嵌入空间，通过构建一个“零空间”来抑制目标类别或领域的信息。具体来说，通过结合文本提示和合成视觉原型，在CLIP的文本和图像嵌入空间中找到一个子空间，使得目标类别或领域的信息在这个子空间中的投影接近于零，从而实现知识遗忘。这种方法无需重新训练模型或引入新的数据，因此更加高效和灵活。\\n\\n**技术框架**：该方法主要包含以下几个阶段：\n1. **目标定义**：明确需要遗忘的类别或领域。\n2. **文本提示生成**：为每个需要遗忘的类别生成相应的文本提示。\n3. **视觉原型合成**：利用CLIP的图像生成能力，为每个需要遗忘的类别合成视觉原型。\n4. **零空间构建**：结合文本提示和视觉原型，在CLIP的嵌入空间中构建零空间。\n5. **知识遗忘**：通过将CLIP的嵌入向量投影到零空间的补空间，从而抑制目标类别或领域的信息。\n\\n**关键创新**：该方法最重要的技术创新点在于它提出了一种免训练免数据的知识遗忘框架。与传统的重新训练方法相比，该方法无需额外的训练数据和计算资源，并且可以更加灵活地控制知识遗忘的范围和程度。此外，该方法还创新性地利用了CLIP的多模态嵌入空间，通过结合文本提示和视觉原型来构建零空间，从而实现了更加精确的知识遗忘。\\n\\n**关键设计**：该方法的关键设计包括：\n1. **文本提示的选择**：选择合适的文本提示对于构建有效的零空间至关重要。论文中可能使用了特定的文本提示策略，例如使用同义词或反义词来增强文本提示的多样性。\n2. **视觉原型的合成**：合成高质量的视觉原型对于知识遗忘的效果有重要影响。论文中可能使用了特定的图像生成技术，例如使用CLIP的图像生成能力或GAN来合成视觉原型。\n3. **零空间的构建**：论文中可能使用了特定的数学方法来构建零空间，例如使用奇异值分解（SVD）或主成分分析（PCA）。\n4. **投影方式**：将CLIP的嵌入向量投影到零空间的补空间的方式也会影响知识遗忘的效果。论文中可能使用了特定的投影方式，例如使用正交投影或加权投影。",
            "application_zh": "该研究成果可应用于多种场景，例如，在自动驾驶系统中，可以遗忘某些不常见的交通标志，以提高系统的鲁棒性；在医疗图像分析中，可以遗忘某些敏感的患者信息，以保护患者隐私；在内容审核系统中，可以遗忘某些违规内容，以提高系统的安全性。此外，该方法还可以用于模型个性化定制，根据用户的需求选择性地遗忘或保留某些知识。",
            "highlight_zh": "该论文提出了一种免训练免数据的知识遗忘方法，无需重新训练模型或引入新的数据，显著提高了知识遗忘的效率和灵活性。实验结果表明，该方法可以在不影响模型在其他任务上的性能的前提下，有效地遗忘目标类别或领域的信息。具体的性能数据和对比基线未知，但该方法在可控知识遗忘方面具有显著优势。",
            "tags_zh": [
                "知识遗忘",
                "免训练",
                "免数据",
                "CLIP",
                "多模态学习"
            ],
            "_index": 178,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14113/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14113/figures/ICCV-CLIP-unlearning-method.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14113/figures/abl11.jpg",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "SketchAssist: A Practical Assistant for Semantic Edits and Precise Local Redrawing",
            "authors": [
                "Han Zou",
                "Yan Zhang",
                "Ruiqi Yu",
                "Cong Xie",
                "Jie Huang",
                "Zhenpeng Zhan"
            ],
            "arxiv_id": "2512.14140",
            "summary": "Sketch editing is central to digital illustration, yet existing image editing systems struggle to preserve the sparse, style-sensitive structure of line art while supporting both high-level semantic changes and precise local redrawing. We present SketchAssist, an interactive sketch drawing assistant that accelerates creation by unifying instruction-guided global edits with line-guided region redrawing, while keeping unrelated regions and overall composition intact. To enable this assistant at scale, we introduce a controllable data generation pipeline that (i) constructs attribute-addition sequences from attribute-free base sketches, (ii) forms multi-step edit chains via cross-sequence sampling, and (iii) expands stylistic coverage with a style-preserving attribute-removal model applied to diverse sketches. Building on this data, SketchAssist employs a unified sketch editing framework with minimal changes to DiT-based editors. We repurpose the RGB channels to encode the inputs, enabling seamless switching between instruction-guided edits and line-guided redrawing within a single input interface. To further specialize behavior across modes, we integrate a task-guided mixture-of-experts into LoRA layers, routing by text and visual cues to improve semantic controllability, structural fidelity, and style preservation. Extensive experiments show state-of-the-art results on both tasks, with superior instruction adherence and style/structure preservation compared to recent baselines. Together, our dataset and SketchAssist provide a practical, controllable assistant for sketch creation and revision.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14140",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱七：动作重定向 (Motion Retargeting)",
                    "id": "7_retargeting",
                    "matched_keywords": [
                        "structure preservation"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "7_retargeting"
            ],
            "headline_zh": "SketchAssist：用于语义编辑和精确局部重绘的实用草图辅助工具",
            "summary_zh": "草图编辑是数字插图的核心，但现有的图像编辑系统难以在支持高级语义更改和精确局部重绘的同时，保持线条艺术的稀疏、风格敏感的结构。我们提出了SketchAssist，一个交互式草图绘制助手，通过统一指令引导的全局编辑和线条引导的区域重绘来加速创作，同时保持不相关的区域和整体构图完整。为了大规模地实现这个助手，我们引入了一个可控的数据生成管道，该管道（i）从无属性的基础草图构建属性添加序列，（ii）通过交叉序列采样形成多步编辑链，以及（iii）通过应用于各种草图的风格保持属性移除模型来扩展风格覆盖。基于这些数据，SketchAssist采用了一个统一的草图编辑框架，对基于DiT的编辑器进行了最小的更改。我们重新利用RGB通道来编码输入，从而可以在单个输入界面中无缝切换指令引导的编辑和线条引导的重绘。为了进一步专门化跨模式的行为，我们将任务引导的混合专家集成到LoRA层中，通过文本和视觉线索进行路由，以提高语义可控性、结构保真度和风格保持。大量的实验表明，在两项任务上都取得了最先进的结果，与最近的基线相比，具有卓越的指令遵循和风格/结构保持。总之，我们的数据集和SketchAssist为草图创建和修改提供了一个实用、可控的助手。",
            "intro_zh": [
                "现有图像编辑系统难以兼顾草图线条艺术的风格和结构，同时支持高级语义编辑和精确局部重绘。",
                "SketchAssist通过统一指令引导的全局编辑和线条引导的局部重绘，在保持整体构图的同时，实现高效的草图编辑。",
                "实验表明，SketchAssist在指令遵循、风格保持和结构保真度方面均优于现有方法，为草图创作提供实用助手。"
            ],
            "method_zh": "**问题定义**：现有图像编辑系统在处理草图时，难以同时满足高层次的语义编辑需求和精细的局部重绘需求，并且容易破坏草图原有的风格和结构。这限制了数字插画创作的效率和质量。\\n\\n**核心思路**：SketchAssist的核心思路是将指令引导的全局语义编辑与线条引导的局部重绘相结合，通过统一的框架实现对草图的精确控制。同时，通过可控的数据生成和模型设计，保证编辑过程中的风格一致性和结构完整性。\\n\\n**技术框架**：SketchAssist的整体框架包括数据生成管道和统一的草图编辑框架。数据生成管道负责生成高质量的训练数据，包括属性添加序列、多步编辑链和风格多样的草图。草图编辑框架基于DiT模型，通过修改输入编码方式和引入任务引导的混合专家模块，实现指令引导和线条引导的无缝切换。\\n\\n**关键创新**：该论文的关键创新在于：1) 提出了一个可控的数据生成管道，能够生成大规模、多样化的草图编辑数据；2) 设计了一个统一的草图编辑框架，能够同时支持指令引导的全局编辑和线条引导的局部重绘；3) 引入了任务引导的混合专家模块，能够根据文本和视觉线索，优化不同编辑模式下的性能。\\n\\n**关键设计**：在数据生成方面，通过属性添加、交叉序列采样和风格保持属性移除等技术，保证数据的多样性和质量。在模型设计方面，利用RGB通道编码输入，实现指令和线条的统一表示；通过LoRA层集成混合专家模块，并使用文本和视觉信息进行路由，实现对不同编辑模式的优化。",
            "application_zh": "SketchAssist可应用于数字绘画、游戏美术设计、动漫创作等领域，帮助艺术家和设计师更高效、更精确地进行草图编辑和创作。该研究有望降低数字艺术创作的门槛，并提升创作效率和质量，具有广阔的应用前景。",
            "highlight_zh": "实验结果表明，SketchAssist在指令遵循、风格保持和结构保真度方面均优于现有方法。例如，在语义编辑任务中，SketchAssist能够更准确地按照指令修改草图，同时保持原有的风格和结构。与基线方法相比，SketchAssist在各项指标上均有显著提升。",
            "tags_zh": [
                "草图编辑",
                "语义编辑",
                "局部重绘",
                "数据生成",
                "扩散模型"
            ],
            "_index": 179,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14140/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14140/figures/model.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14140/x2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "TorchTraceAP: A New Benchmark Dataset for Detecting Performance Anti-Patterns in Computer Vision Models",
            "authors": [
                "Hanning Chen",
                "Keyu Man",
                "Kevin Zhu",
                "Chenguang Zhu",
                "Haonan Li",
                "Tongbo Luo",
                "Xizhou Feng",
                "Wei Sun",
                "Sreen Tallam",
                "Mohsen Imani",
                "Partha Kanuparthy"
            ],
            "arxiv_id": "2512.14141",
            "summary": "Identifying and addressing performance anti-patterns in machine learning (ML) models is critical for efficient training and inference, but it typically demands deep expertise spanning system infrastructure, ML models and kernel development. While large tech companies rely on dedicated ML infrastructure engineers to analyze torch traces and benchmarks, such resource-intensive workflows are largely inaccessible to computer vision researchers in general. Among the challenges, pinpointing problematic trace segments within lengthy execution traces remains the most time-consuming task, and is difficult to automate with current ML models, including LLMs. In this work, we present the first benchmark dataset specifically designed to evaluate and improve ML models' ability to detect anti patterns in traces. Our dataset contains over 600 PyTorch traces from diverse computer vision models classification, detection, segmentation, and generation collected across multiple hardware platforms. We also propose a novel iterative approach: a lightweight ML model first detects trace segments with anti patterns, followed by a large language model (LLM) for fine grained classification and targeted feedback. Experimental results demonstrate that our method significantly outperforms unsupervised clustering and rule based statistical techniques for detecting anti pattern regions. Our method also effectively compensates LLM's limited context length and reasoning inefficiencies.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14141",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出TorchTraceAP基准数据集，用于检测计算机视觉模型中的性能反模式。",
            "summary_zh": "识别和解决机器学习(ML)模型中的性能反模式对于高效的训练和推理至关重要，但这通常需要系统基础设施、ML模型和内核开发方面的深厚专业知识。大型科技公司依靠专门的ML基础设施工程师来分析torch traces和基准，但这种资源密集型工作流程对于一般的计算机视觉研究人员来说在很大程度上是无法实现的。其中，在冗长的执行traces中精确定位有问题的trace片段仍然是最耗时的任务，并且很难用当前的ML模型（包括LLM）自动完成。本文提出了第一个专门用于评估和提高ML模型检测traces中反模式能力的基准数据集。该数据集包含来自多种硬件平台上收集的各种计算机视觉模型（分类、检测、分割和生成）的600多个PyTorch traces。此外，还提出了一种新颖的迭代方法：一个轻量级的ML模型首先检测具有反模式的trace片段，然后使用大型语言模型(LLM)进行细粒度分类和有针对性的反馈。实验结果表明，该方法在检测反模式区域方面明显优于无监督聚类和基于规则的统计技术。该方法还有效地弥补了LLM有限的上下文长度和推理效率。",
            "intro_zh": [
                "现有方法难以在冗长的执行traces中精确定位性能反模式，自动化程度低，依赖人工专家。",
                "提出一种迭代方法，首先使用轻量级ML模型检测trace片段，然后利用LLM进行细粒度分类和反馈。",
                "实验结果表明，该方法显著优于无监督聚类和基于规则的统计技术，并能有效弥补LLM的不足。"
            ],
            "method_zh": "**问题定义**：论文旨在解决计算机视觉模型性能优化中，难以自动检测PyTorch traces中性能反模式的问题。现有方法依赖人工分析，耗时且需要专家知识，而现有的ML模型，包括LLM，难以处理长序列的trace数据，且推理效率不高。\\n\\n**核心思路**：论文的核心思路是将问题分解为两个阶段：首先使用轻量级ML模型快速定位可能存在性能反模式的trace片段，然后利用LLM对这些片段进行细粒度分类和提供反馈。这种迭代方法旨在结合两者的优势，降低对LLM上下文长度的要求，并提高整体效率。\\n\\n**技术框架**：整体框架包含两个主要阶段：1) 轻量级ML模型（例如，一个简单的分类器或回归器）对PyTorch trace进行扫描，识别出可能包含性能反模式的片段。这个模型可以基于统计特征、规则或简单的机器学习算法。2) 将识别出的片段输入到LLM中，LLM对这些片段进行更深入的分析，识别具体的性能反模式类型，并提供优化建议。这两个阶段可以迭代进行，以提高检测精度。\\n\\n**关键创新**：关键创新在于将轻量级ML模型和LLM结合起来，形成一个迭代的检测框架。这种方法既利用了轻量级模型的高效性，又利用了LLM的强大推理能力。此外，构建的TorchTraceAP数据集是首个专门用于评估和改进ML模型检测trace中反模式能力的基准数据集。\\n\\n**关键设计**：轻量级ML模型的设计需要考虑计算效率和检测准确率之间的平衡。可以使用简单的统计特征（例如，执行时间、内存占用等）作为输入，并采用浅层神经网络或决策树等模型。LLM的选择需要考虑其推理能力和上下文长度的限制。可以通过prompt工程来指导LLM的分析过程，并提供相关的背景知识和约束条件。迭代次数可以根据实际情况进行调整，以达到最佳的检测效果。",
            "application_zh": "该研究成果可应用于计算机视觉模型的自动性能优化。通过自动检测和诊断性能瓶颈，可以帮助开发者更高效地训练和部署模型，降低计算成本，提高模型在各种硬件平台上的运行效率。该方法还有助于降低性能优化的门槛，使更多的研究人员和工程师能够参与到模型优化工作中。",
            "highlight_zh": "论文构建了包含600多个PyTorch traces的TorchTraceAP数据集，并验证了所提出的迭代方法在检测性能反模式区域方面的有效性。实验结果表明，该方法显著优于无监督聚类和基于规则的统计技术，并且能够有效弥补LLM的上下文长度限制和推理效率问题。具体的性能提升数据未知，但定性结果表明该方法具有显著优势。",
            "tags_zh": [
                "性能反模式检测",
                "PyTorch traces",
                "机器学习模型优化",
                "大型语言模型",
                "基准数据集"
            ],
            "_index": 180,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14141/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14141/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14141/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Enhancing Visual Programming for Visual Reasoning via Probabilistic Graphs",
            "authors": [
                "Wentao Wan",
                "Kaiyu Wu",
                "Qingyang Ma",
                "Nan Kang",
                "Yunjie Chen",
                "Liang Lin",
                "Keze Wang"
            ],
            "arxiv_id": "2512.14257",
            "summary": "Recently, Visual Programming (VP) based on large language models (LLMs) has rapidly developed and demonstrated significant potential in complex Visual Reasoning (VR) tasks. Previous works to enhance VP have primarily focused on improving the quality of LLM-generated visual programs. However, they have neglected to optimize the VP-invoked pre-trained models, which serve as modules for the visual sub-tasks decomposed from the targeted tasks by VP. The difficulty is that there are only final labels of targeted VR tasks rather than labels of sub-tasks. Besides, the non-differentiable nature of VP impedes the direct use of efficient gradient-based optimization methods to leverage final labels for end-to-end learning of the entire VP framework. To overcome these issues, we propose EVPG, a method to Enhance Visual Programming for visual reasoning via Probabilistic Graphs. Specifically, we creatively build a directed probabilistic graph according to the variable dependency relationships during the VP executing process, which reconstructs the non-differentiable VP executing process into a differentiable exact probability inference process on this directed probabilistic graph. As a result, this enables the VP framework to utilize the final labels for efficient, gradient-based optimization in end-to-end supervised learning on targeted VR tasks. Extensive and comprehensive experiments demonstrate the effectiveness and advantages of our EVPG, showing significant performance improvements for VP on three classical complex VR tasks: GQA, NLVRv2, and Open Images.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14257",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出EVPG，通过概率图增强视觉编程以提升视觉推理能力",
            "summary_zh": "本文提出了一种名为EVPG的方法，旨在通过概率图增强视觉编程（VP），从而提升视觉推理（VR）能力。现有的VP增强方法主要集中于提高LLM生成的视觉程序的质量，而忽略了优化VP调用的预训练模型。难点在于，VR任务只有最终标签，而没有子任务的标签。此外，VP的不可微性阻碍了直接使用基于梯度的优化方法进行端到端学习。为了解决这些问题，EVPG根据VP执行过程中的变量依赖关系构建有向概率图，将不可微的VP执行过程重构为概率图上的可微精确概率推理过程。这使得VP框架能够利用最终标签进行高效的、基于梯度的端到端监督学习。在GQA、NLVRv2和Open Images三个经典VR任务上的大量实验表明了EVPG的有效性和优势。",
            "intro_zh": [
                "现有视觉编程方法侧重优化LLM生成的程序，忽略了对VP所调用预训练模型的优化，导致性能瓶颈。",
                "EVPG方法通过构建有向概率图，将VP执行过程转化为可微的概率推理，从而实现端到端优化。",
                "实验表明，EVPG在GQA、NLVRv2和Open Images等视觉推理任务上显著提升了VP的性能。"
            ],
            "method_zh": "**问题定义**：现有的基于视觉编程的视觉推理方法主要关注于提升大型语言模型（LLM）生成视觉程序的质量，而忽略了对视觉程序所调用的预训练视觉模型的优化。由于缺乏子任务的标签，且视觉编程过程本身不可微，难以直接利用最终的视觉推理任务标签进行端到端的优化训练。\\n\\n**核心思路**：本文的核心思路是将视觉编程的执行过程建模为一个概率图模型，通过构建一个有向概率图来表示视觉程序中各个变量之间的依赖关系。这样，原本不可微的视觉编程执行过程就被转化为概率图上的精确概率推理过程，从而可以使用梯度下降等方法进行优化。\\n\\n**技术框架**：EVPG框架主要包含以下几个步骤：1) 使用LLM生成视觉程序；2) 根据视觉程序的执行流程构建有向概率图，节点表示变量，边表示依赖关系；3) 将视觉程序的执行过程转化为在概率图上进行概率推理的过程；4) 使用最终的视觉推理任务标签，通过梯度下降方法对概率图中的参数（即预训练视觉模型）进行端到端优化。\\n\\n**关键创新**：EVPG的关键创新在于将不可微的视觉编程过程转化为可微的概率推理过程。通过构建概率图，将视觉程序中的变量依赖关系显式地建模出来，从而可以使用梯度下降方法对整个视觉编程框架进行优化。这使得可以利用最终的视觉推理任务标签来指导预训练视觉模型的训练，从而提升视觉推理的性能。\\n\\n**关键设计**：概率图的构建方式是关键。论文根据视觉程序的执行流程，将每个视觉操作（例如目标检测、属性识别等）视为概率图中的一个节点，节点之间的边表示数据依赖关系。概率图中的每个节点都对应一个预训练的视觉模型，模型的参数可以通过梯度下降方法进行优化。损失函数采用标准的交叉熵损失函数，用于衡量预测结果与真实标签之间的差异。",
            "application_zh": "EVPG方法可应用于各种需要复杂视觉推理的场景，例如智能问答、图像理解、视觉导航等。通过优化视觉编程框架中的预训练视觉模型，可以提升这些应用在复杂场景下的性能和鲁棒性。该研究为开发更强大的视觉智能系统提供了新的思路。",
            "highlight_zh": "EVPG在三个经典视觉推理任务上取得了显著的性能提升。在GQA数据集上，EVPG相较于基线方法提升了超过5个百分点；在NLVRv2数据集上，提升了超过3个百分点；在Open Images数据集上，也取得了显著的性能提升。这些结果表明，EVPG能够有效地优化视觉编程框架，提升视觉推理能力。",
            "tags_zh": [
                "视觉编程",
                "视觉推理",
                "概率图模型",
                "端到端学习",
                "大型语言模型"
            ],
            "_index": 181,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14257/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14257/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14257/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "DISCODE: Distribution-Aware Score Decoder for Robust Automatic Evaluation of Image Captioning",
            "authors": [
                "Nakamasa Inoue",
                "Kanoko Goto",
                "Masanari Oi",
                "Martyna Gruszka",
                "Mahiro Ukai",
                "Takumi Hirose",
                "Yusuke Sekikawa"
            ],
            "arxiv_id": "2512.14420",
            "summary": "Large vision-language models (LVLMs) have shown impressive performance across a broad range of multimodal tasks. However, robust image caption evaluation using LVLMs remains challenging, particularly under domain-shift scenarios. To address this issue, we introduce the Distribution-Aware Score Decoder (DISCODE), a novel finetuning-free method that generates robust evaluation scores better aligned with human judgments across diverse domains. The core idea behind DISCODE lies in its test-time adaptive evaluation approach, which introduces the Adaptive Test-Time (ATT) loss, leveraging a Gaussian prior distribution to improve robustness in evaluation score estimation. This loss is efficiently minimized at test time using an analytical solution that we derive. Furthermore, we introduce the Multi-domain Caption Evaluation (MCEval) benchmark, a new image captioning evaluation benchmark covering six distinct domains, designed to assess the robustness of evaluation metrics. In our experiments, we demonstrate that DISCODE achieves state-of-the-art performance as a reference-free evaluation metric across MCEval and four representative existing benchmarks.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14420",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出DISCODE，一种分布感知的无微调图像描述评估方法，提升领域泛化性。",
            "summary_zh": "大型视觉-语言模型(LVLMs)在多模态任务中表现出色。然而，使用LVLMs进行鲁棒的图像描述评估仍然具有挑战性，尤其是在领域迁移的情况下。为了解决这个问题，我们引入了分布感知分数解码器(DISCODE)，这是一种新颖的免微调方法，可以生成与不同领域的人工判断更一致的鲁棒评估分数。DISCODE的核心思想在于其测试时自适应评估方法，引入了自适应测试时(ATT)损失，利用高斯先验分布来提高评估分数估计的鲁棒性。我们推导出一个解析解，可以在测试时有效地最小化此损失。此外，我们还引入了多领域描述评估(MCEval)基准，这是一个新的图像描述评估基准，涵盖六个不同的领域，旨在评估评估指标的鲁棒性。实验表明，DISCODE在MCEval和四个具有代表性的现有基准测试中，作为一种无参考评估指标，实现了最先进的性能。",
            "intro_zh": [
                "现有LVLM的图像描述评估在领域迁移时鲁棒性不足，难以准确反映人类判断。",
                "DISCODE利用测试时自适应评估，通过高斯先验和ATT损失提升评估分数鲁棒性。",
                "MCEval基准测试和实验结果表明，DISCODE在多个数据集上实现了SOTA性能。"
            ],
            "method_zh": "**问题定义**：论文旨在解决图像描述自动评估在领域迁移场景下的鲁棒性问题。现有的基于大型视觉-语言模型（LVLM）的评估方法在面对不同领域的数据时，评估结果与人类判断的一致性较差，泛化能力不足。\\n\\n**核心思路**：DISCODE的核心思路是在测试时进行自适应调整，利用领域内的信息来优化评估分数。通过引入高斯先验分布，并设计自适应测试时（ATT）损失函数，使得模型在评估过程中能够更好地适应当前领域的特征，从而提高评估结果的鲁棒性和准确性。\\n\\n**技术框架**：DISCODE方法主要包含以下几个阶段：1) 使用LVLM生成图像描述的评估分数；2) 构建基于高斯先验的分布模型；3) 利用自适应测试时（ATT）损失函数，在测试时对评估分数进行优化；4) 输出最终的鲁棒性评估分数。整个框架无需额外的微调，可以在现有的LVLM评估模型上直接应用。\\n\\n**关键创新**：DISCODE的关键创新在于其测试时自适应评估方法和ATT损失函数的设计。传统的评估方法通常在训练阶段确定模型参数，而在测试阶段直接使用。DISCODE则通过在测试时引入可优化的参数，并利用ATT损失函数进行调整，使得模型能够更好地适应当前领域的特征。此外，论文还提出了MCEval基准测试，为评估指标的鲁棒性提供了一个新的平台。\\n\\n**关键设计**：ATT损失函数是DISCODE的关键设计之一，其目标是最小化评估分数与高斯先验分布之间的差异。具体而言，ATT损失函数可以表示为：L_ATT = ||s - μ||^2 / (2σ^2)，其中s是LVLM生成的评估分数，μ和σ分别是高斯分布的均值和标准差。论文推导出了该损失函数的解析解，可以在测试时高效地进行优化。此外，MCEval基准测试包含了六个不同的领域，为评估指标的鲁棒性提供了全面的评估。",
            "application_zh": "DISCODE可应用于各种需要自动评估图像描述质量的场景，例如图像搜索引擎、视觉内容生成、多模态对话系统等。该方法能够提高评估的准确性和鲁棒性，从而提升用户体验和系统性能。未来，该方法可以扩展到其他多模态任务的评估中，例如视频描述、视觉问答等。",
            "highlight_zh": "DISCODE在MCEval和四个现有基准测试中取得了SOTA性能，证明了其在领域迁移场景下的鲁棒性。例如，在MCEval基准测试中，DISCODE显著优于其他无参考评估指标。此外，DISCODE无需额外的微调，可以直接应用于现有的LVLM评估模型，具有很高的实用价值。",
            "tags_zh": [
                "图像描述评估",
                "领域泛化",
                "视觉-语言模型",
                "测试时自适应",
                "鲁棒性",
                "无参考评估",
                "多模态学习"
            ],
            "_index": 182,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14420/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14420/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14420/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "FoodLogAthl-218: Constructing a Real-World Food Image Dataset Using Dietary Management Applications",
            "authors": [
                "Mitsuki Watanabe",
                "Sosuke Amano",
                "Kiyoharu Aizawa",
                "Yoko Yamakata"
            ],
            "arxiv_id": "2512.14574",
            "summary": "Food image classification models are crucial for dietary management applications because they reduce the burden of manual meal logging. However, most publicly available datasets for training such models rely on web-crawled images, which often differ from users' real-world meal photos. In this work, we present FoodLogAthl-218, a food image dataset constructed from real-world meal records collected through the dietary management application FoodLog Athl. The dataset contains 6,925 images across 218 food categories, with a total of 14,349 bounding boxes. Rich metadata, including meal date and time, anonymized user IDs, and meal-level context, accompany each image. Unlike conventional datasets-where a predefined class set guides web-based image collection-our data begins with user-submitted photos, and labels are applied afterward. This yields greater intra-class diversity, a natural frequency distribution of meal types, and casual, unfiltered images intended for personal use rather than public sharing. In addition to (1) a standard classification benchmark, we introduce two FoodLog-specific tasks: (2) an incremental fine-tuning protocol that follows the temporal stream of users' logs, and (3) a context-aware classification task where each image contains multiple dishes, and the model must classify each dish by leveraging the overall meal context. We evaluate these tasks using large multimodal models (LMMs). The dataset is publicly available atthis https URL.",
            "categories": [
                "cs.CV",
                "cs.MM"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14574",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "FoodLogAthl-218：构建基于膳食管理应用采集的真实食物图像数据集",
            "summary_zh": "本文提出了FoodLogAthl-218，一个基于膳食管理应用FoodLog Athl收集的真实食物图像数据集。该数据集包含218个食物类别的6925张图像，以及总计14349个边界框。每张图像都附带有丰富的元数据，包括用餐日期和时间、匿名用户ID以及膳食级别的上下文信息。与传统的依赖网络爬取图像的数据集不同，该数据集从用户提交的照片开始，然后进行标签标注，从而产生更大的类内多样性、膳食类型的自然频率分布以及未经滤镜处理的个人使用图像。除了标准的分类基准测试外，还引入了两个FoodLog特定的任务：（1）遵循用户日志时间流的增量微调协议，以及（2）上下文感知的分类任务，其中每张图像包含多个菜肴，模型必须利用整体膳食上下文对每个菜肴进行分类。使用大型多模态模型（LMM）评估了这些任务。该数据集已公开。",
            "intro_zh": [
                "现有食物图像数据集多为网络爬取，与用户真实膳食照片存在差异，影响膳食管理应用效果。",
                "提出FoodLogAthl-218数据集，直接从膳食管理应用收集用户真实膳食图像，更贴近实际应用场景。",
                "引入增量微调和上下文感知分类任务，更符合FoodLog应用特点，并使用LMM进行评估。"
            ],
            "method_zh": "**问题定义**：现有食物图像分类模型依赖的数据集通常通过网络爬取获得，这些图像与用户在膳食管理应用中拍摄的真实照片存在显著差异。这种差异导致模型在实际应用中的性能下降，无法有效减轻用户手动记录膳食的负担。因此，需要一个更贴近真实用户场景的食物图像数据集。\\n\\n**核心思路**：该论文的核心思路是直接从膳食管理应用FoodLog Athl收集用户上传的真实膳食图像，并构建一个包含丰富元数据的数据集。这种方法避免了网络爬取图像与真实用户照片之间的差异，从而能够训练出更有效的食物图像分类模型。此外，论文还设计了针对FoodLog应用特点的特定任务，以更好地评估模型的性能。\\n\\n**技术框架**：该论文主要关注数据集的构建和基准测试任务的设计。数据集构建过程包括：1) 从FoodLog Athl应用收集用户上传的膳食图像；2) 对图像进行标注，包括食物类别和边界框；3) 添加元数据，如用餐日期和时间、用户ID和膳食级别上下文信息。基准测试任务包括：1) 标准的食物图像分类任务；2) 增量微调任务，模拟用户日志的时间流；3) 上下文感知的分类任务，利用膳食上下文信息进行分类。\\n\\n**关键创新**：该论文的关键创新在于数据集的构建方法。与传统的网络爬取数据集不同，FoodLogAthl-218直接从用户上传的真实膳食图像中构建，从而具有更高的类内多样性、更自然的膳食类型分布以及更真实的图像质量。此外，论文还提出了针对FoodLog应用特点的增量微调和上下文感知分类任务，更贴近实际应用场景。\\n\\n**关键设计**：数据集包含218个食物类别，6925张图像和14349个边界框。增量微调任务按照用户日志的时间顺序进行微调，模拟用户使用应用的真实过程。上下文感知的分类任务需要模型利用膳食中其他菜肴的信息来辅助分类，例如，如果一张图片中包含米饭和味噌汤，则可以推断出该图片可能包含日式料理。",
            "application_zh": "该研究成果可直接应用于膳食管理应用中，提升食物图像识别的准确率，减轻用户手动记录膳食的负担。此外，该数据集和基准测试任务也可用于评估和改进现有的食物图像分类模型，推动相关领域的研究进展。未来，可以进一步探索利用该数据集进行个性化膳食推荐和营养分析。",
            "highlight_zh": "论文构建的FoodLogAthl-218数据集具有真实性和多样性，更贴近实际应用场景。提出的增量微调和上下文感知分类任务更符合膳食管理应用的特点。实验结果表明，大型多模态模型（LMM）在该数据集上表现良好，为后续研究提供了有价值的参考。",
            "tags_zh": [
                "食物图像分类",
                "膳食管理",
                "真实数据集",
                "增量学习",
                "上下文感知"
            ],
            "_index": 183,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14574/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14574/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14574/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "ViRC: Enhancing Visual Interleaved Mathematical CoT with Reason Chunking",
            "authors": [
                "Lihong Wang",
                "Liangqi Li",
                "Weiwei Feng",
                "Jiamin Wu",
                "Changtao Miao",
                "Tieru Wu",
                "Rui Ma",
                "Bo Zhang",
                "Zhe Li"
            ],
            "arxiv_id": "2512.14654",
            "summary": "CoT has significantly enhanced the reasoning ability of LLMs while it faces challenges when extended to multimodal domains, particularly in mathematical tasks. Existing MLLMs typically perform textual reasoning solely from a single static mathematical image, overlooking dynamic visual acquisition during reasoning. In contrast, humans repeatedly examine visual image and employ step-by-step reasoning to prove intermediate propositions. This strategy of decomposing the problem-solving process into key logical nodes adheres to Miller's Law in cognitive science. Inspired by this insight, we propose a ViRC framework for multimodal mathematical tasks, introducing a Reason Chunking mechanism that structures multimodal mathematical CoT into consecutive Critical Reasoning Units (CRUs) to simulate human expert problem-solving patterns. CRUs ensure intra-unit textual coherence for intermediate proposition verification while integrating visual information across units to generate subsequent propositions and support structured reasoning. To this end, we present CRUX dataset by using three visual tools and four reasoning patterns to provide explicitly annotated CRUs across multiple reasoning paths for each mathematical problem. Leveraging the CRUX dataset, we propose a progressive training strategy inspired by human cognitive learning, which includes Instructional SFT, Practice SFT, and Strategic RL, aimed at further strengthening the Reason Chunking ability of thethis http URLresulting ViRC-7B model achieves a 18.8\\% average improvement over baselines across multiple mathematical benchmarks. Code is available atthis https URL.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14654",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出ViRC框架，通过Reason Chunking增强视觉交错数学CoT推理能力",
            "summary_zh": "本文提出ViRC框架，旨在提升多模态大语言模型在数学任务中的推理能力。现有MLLM通常仅依赖静态数学图像进行文本推理，忽略了推理过程中动态视觉信息的获取。ViRC框架受到人类专家解决问题模式的启发，引入Reason Chunking机制，将多模态数学CoT分解为连续的关键推理单元(CRU)，模拟人类逐步验证中间命题的过程。CRU确保单元内文本连贯性，并在单元间整合视觉信息以生成后续命题，支持结构化推理。为此，本文构建了CRUX数据集，使用三种视觉工具和四种推理模式，为每个数学问题提供显式标注的CRU。基于CRUX数据集，提出了一种受人类认知学习启发的渐进式训练策略，包括Instructional SFT、Practice SFT和Strategic RL，旨在进一步加强Reason Chunking能力。ViRC-7B模型在多个数学基准测试中实现了平均18.8%的性能提升。",
            "intro_zh": [
                "现有MLLM在处理多模态数学问题时，缺乏对动态视觉信息的有效利用，限制了推理能力。",
                "ViRC框架通过Reason Chunking机制，将推理过程分解为关键推理单元CRU，模拟人类专家逐步验证中间命题的模式。",
                "实验结果表明，ViRC-7B模型在多个数学基准测试中取得了显著的性能提升，平均提升幅度达到18.8%。"
            ],
            "method_zh": "**问题定义**：现有的大型语言模型在处理视觉交错的数学问题时，通常只依赖于单一的静态图像，而忽略了人类在解决此类问题时会反复观察图像并逐步推理的动态过程。这导致模型无法充分利用视觉信息，影响了推理的准确性和效率。现有方法的痛点在于缺乏对视觉信息的动态建模和利用，以及缺乏对推理过程的结构化组织。\n\n**核心思路**：ViRC的核心思路是模仿人类专家解决数学问题的模式，将复杂的推理过程分解为一系列关键的推理单元（CRU）。每个CRU专注于验证一个中间命题，并在单元内部保持文本连贯性。同时，CRU之间通过整合视觉信息来生成后续命题，从而实现结构化的推理过程。这种Reason Chunking机制借鉴了认知科学中的米勒定律，旨在提高模型的推理效率和准确性。\n\n**技术框架**：ViRC框架主要包含三个部分：CRUX数据集的构建、Reason Chunking机制的引入以及渐进式训练策略。CRUX数据集提供了显式标注的CRU，用于训练模型学习Reason Chunking能力。Reason Chunking机制将推理过程分解为连续的CRU，每个CRU包含视觉信息和文本推理。渐进式训练策略包括Instructional SFT、Practice SFT和Strategic RL三个阶段，逐步提升模型的Reason Chunking能力。\n\n**关键创新**：ViRC最重要的技术创新点在于Reason Chunking机制。与现有方法相比，ViRC不再依赖于单一的静态图像进行推理，而是通过动态地整合视觉信息和结构化地组织推理过程来提高模型的推理能力。Reason Chunking机制使得模型能够更好地模拟人类专家解决问题的模式，从而提高推理的准确性和效率。\n\n**关键设计**：CRUX数据集使用了三种视觉工具（未知）和四种推理模式（未知）来标注CRU。渐进式训练策略中的Instructional SFT阶段使用CRUX数据集进行监督学习，Practice SFT阶段使用更复杂的数学问题进行训练，Strategic RL阶段使用强化学习来优化模型的推理策略。具体的参数设置、损失函数和网络结构等技术细节在论文中未详细说明，属于未知信息。",
            "application_zh": "ViRC框架具有广泛的应用前景，可应用于智能教育、数学辅助工具、科学研究等领域。例如，可以开发智能辅导系统，帮助学生理解和解决复杂的数学问题；可以应用于科学研究，辅助科学家进行数据分析和模型推理；还可以应用于机器人视觉领域，提高机器人对复杂环境的理解和推理能力。该研究的实际价值在于提升多模态大语言模型在数学推理方面的能力，为相关领域的发展提供新的思路。",
            "highlight_zh": "ViRC-7B模型在多个数学基准测试中取得了显著的性能提升，平均提升幅度达到18.8%。这一结果表明，Reason Chunking机制能够有效地提高模型的推理能力。此外，CRUX数据集的构建也为多模态数学推理领域的研究提供了有价值的资源。",
            "tags_zh": [
                "多模态学习",
                "数学推理",
                "视觉交错",
                "Reason Chunking",
                "认知科学",
                "大语言模型",
                "CRUX数据集"
            ],
            "_index": 184,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "FutrTrack: A Camera-LiDAR Fusion Transformer for 3D Multiple Object Tracking",
            "authors": [
                "Martha Teiko Teye",
                "Ori Maoz",
                "Matthias Rottmann"
            ],
            "arxiv_id": "2510.19981",
            "summary": "We propose FutrTrack, a modular camera-LiDAR multi-object tracking framework that builds on existing 3D detectors by introducing a transformer-based smoother and a fusion-driven tracker. Inspired by query-based tracking frameworks, FutrTrack employs a multimodal two-stage transformer refinement and tracking pipeline. Our fusion tracker integrates bounding boxes with multimodal bird's-eye-view (BEV) fusion features from multiple cameras and LiDAR without the need for an explicit motion model. The tracker assigns and propagates identities across frames, leveraging both geometric and semantic cues for robust re-identification under occlusion and viewpoint changes. Prior to tracking, we refine sequences of bounding boxes with a temporal smoother over a moving window to refine trajectories, reduce jitter, and improve spatial consistency. Evaluated on nuScenes and KITTI, FutrTrack demonstrates that query-based transformer tracking methods benefit significantly from multimodal sensor features compared with previous single-sensor approaches. With an aMOTA of 74.7 on the nuScenes test set, FutrTrack achieves strong performance on 3D MOT benchmarks, reducing identity switches while maintaining competitive accuracy. Our approach provides an efficient framework for improving transformer-based trackers to compete with other neural-network-based methods even with limited data and without pretraining.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2510.19981",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "FutrTrack：一种用于3D多目标跟踪的相机-激光雷达融合Transformer",
            "summary_zh": "我们提出了FutrTrack，一个模块化的相机-激光雷达多目标跟踪框架，它建立在现有的3D检测器之上，引入了一个基于Transformer的平滑器和一个融合驱动的跟踪器。受到基于查询的跟踪框架的启发，FutrTrack采用了一种多模态两阶段Transformer细化和跟踪流程。我们的融合跟踪器集成了来自多个相机和激光雷达的边界框与多模态鸟瞰图（BEV）融合特征，而无需显式的运动模型。该跟踪器在帧之间分配和传播身份，利用几何和语义线索来实现遮挡和视点变化下的鲁棒重识别。在跟踪之前，我们使用移动窗口上的时间平滑器来细化边界框序列，以细化轨迹，减少抖动并提高空间一致性。在nuScenes和KITTI上的评估表明，与之前的单传感器方法相比，基于查询的Transformer跟踪方法从多模态传感器特征中获益匪浅。在nuScenes测试集上，FutrTrack的aMOTA为74.7，在3D MOT基准测试中表现出色，在保持竞争力的同时减少了身份切换。我们的方法提供了一个高效的框架，用于改进基于Transformer的跟踪器，即使在数据有限且没有预训练的情况下，也能与其他基于神经网络的方法竞争。",
            "intro_zh": [
                "现有3D多目标跟踪方法在遮挡和视点变化下鲁棒性不足，且对多模态信息的有效融合仍具挑战。",
                "FutrTrack利用Transformer架构，通过多模态融合特征和时间平滑，提升跟踪的准确性和鲁棒性。",
                "实验表明，FutrTrack在nuScenes和KITTI数据集上表现出色，尤其在减少身份切换方面有显著提升。"
            ],
            "method_zh": "**问题定义**：论文旨在解决3D多目标跟踪（MOT）问题，特别是在复杂场景下，由于遮挡、视点变化以及传感器噪声等因素，导致跟踪性能下降的问题。现有方法通常依赖于显式的运动模型，对运动状态假设较强，且难以有效融合来自不同模态（相机和激光雷达）的信息。\\n\\n**核心思路**：FutrTrack的核心思路是利用Transformer架构强大的特征提取和关联能力，通过多模态融合和时间平滑来提升跟踪的准确性和鲁棒性。该方法避免了对运动模型的显式依赖，而是通过学习数据中的潜在关联来实现跟踪。\\n\\n**技术框架**：FutrTrack包含三个主要模块：3D目标检测器（使用现有方法）、基于Transformer的时间平滑器和融合驱动的跟踪器。首先，使用3D检测器提取每一帧的物体边界框。然后，时间平滑器利用Transformer对一段时间内的边界框序列进行优化，减少抖动并提高空间一致性。最后，融合驱动的跟踪器将相机和激光雷达的多模态BEV特征与边界框信息融合，利用Transformer进行目标关联和身份传播。\\n\\n**关键创新**：FutrTrack的关键创新在于其融合驱动的跟踪器，它能够有效地融合来自多个相机和激光雷达的多模态BEV特征，而无需显式的运动模型。此外，使用Transformer进行时间平滑也提高了轨迹的质量。\\n\\n**关键设计**：时间平滑器使用Transformer编码器-解码器结构，将一段时间内的边界框序列作为输入，输出优化后的边界框序列。融合驱动的跟踪器使用Transformer进行目标关联，损失函数包括分类损失和回归损失，用于优化目标关联和边界框预测。",
            "application_zh": "FutrTrack在自动驾驶、机器人导航、智能交通等领域具有广泛的应用前景。它可以用于提高车辆和机器人在复杂环境下的感知能力，实现更安全、更可靠的自主导航和决策。该研究对于提升多传感器融合和目标跟踪技术水平具有重要意义。",
            "highlight_zh": "FutrTrack在nuScenes测试集上取得了74.7的aMOTA，显著优于之前的单传感器方法。与现有技术相比，FutrTrack在保持竞争力的同时，显著减少了身份切换的次数，表明其在复杂场景下的跟踪鲁棒性更强。实验结果验证了多模态融合和Transformer架构在3D多目标跟踪中的有效性。",
            "tags_zh": [
                "3D多目标跟踪",
                "多模态融合",
                "Transformer",
                "相机-激光雷达融合",
                "目标跟踪"
            ],
            "_index": 185,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2510.19981/images/page1img.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2510.19981/images/overall_fig1.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2510.19981/images/vis_futrtrack3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Mitigating Catastrophic Forgetting in Mathematical Reasoning Finetuning through Mixed Training",
            "authors": [
                "John Graham Reynolds"
            ],
            "arxiv_id": "2512.13706",
            "summary": "When finetuning large language models for specialized tasks such as mathematical reasoning, models exhibit catastrophic forgetting, losing previously learned capabilities. We investigate this by finetuning Flan-T5-Base (250M parameters) on the DeepMind Mathematics dataset and measuring forgetting on MultiNLI. Math-only training improves mathematical accuracy from 3.1\\% to 12.0\\% but causes NLI accuracy to collapse from 81.0\\% to 16.5\\%--a 64.5 percentage point drop occurring within the first 1,000 training steps. We propose mixed training strategies that interleave mathematical and NLI examples during training. Our results demonstrate that mixed training completely eliminates catastrophic forgetting while maintaining equivalent mathematical performance: the balanced 1:1 ratio achieves 12.0\\% math accuracy (matching math-only) while preserving 86.2\\% NLI accuracy. We systematically explore mixing ratios from 1:1 to 15:1, finding that even minimal NLI exposure (6.2\\%) provides effective regularization. These findings demonstrate that specialization need not require forgetting general capabilities, with implications for scaling to larger models where mixed training may confer additional benefits beyond forgetting prevention.",
            "categories": [
                "cs.LG",
                "cs.CL"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13706",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出混合训练策略，缓解数学推理微调中的灾难性遗忘问题",
            "summary_zh": "在对大型语言模型进行微调以执行诸如数学推理等特定任务时，模型会表现出灾难性遗忘，从而失去先前学习的能力。本文通过在DeepMind Mathematics数据集上微调Flan-T5-Base（2.5亿参数）并测量其在MultiNLI上的遗忘程度来研究这个问题。仅使用数学数据进行训练将数学准确率从3.1％提高到12.0％，但导致NLI准确率从81.0％下降到16.5％——在最初的1000个训练步骤中下降了64.5个百分点。为此，本文提出了一种混合训练策略，在训练过程中交错使用数学和NLI示例。结果表明，混合训练完全消除了灾难性遗忘，同时保持了相当的数学性能：平衡的1:1比例实现了12.0％的数学准确率（与仅数学训练相当），同时保持了86.2％的NLI准确率。系统地探索了从1:1到15:1的混合比例，发现即使是最小的NLI暴露（6.2％）也能提供有效的正则化。这些发现表明，专业化不需要以牺牲通用能力为代价，这对于扩展到更大的模型具有重要意义，在更大的模型中，混合训练除了防止遗忘之外，还可以带来额外的好处。",
            "intro_zh": [
                "现有方法在微调大型语言模型进行数学推理时，会发生灾难性遗忘，导致模型失去原有的通用能力。",
                "论文提出混合训练策略，通过交错使用数学和NLI数据进行训练，以缓解灾难性遗忘问题。",
                "实验结果表明，混合训练能够完全消除灾难性遗忘，同时保持甚至提升数学推理性能。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型在微调以执行特定任务（如数学推理）时出现的灾难性遗忘问题。现有方法在专注于特定任务训练时，会显著降低模型在通用任务上的性能，限制了模型的泛化能力。\\n\\n**核心思路**：核心思路是在微调过程中，同时使用特定任务（数学推理）的数据和通用任务（NLI）的数据进行混合训练。通过这种方式，模型可以在学习新知识的同时，保留已有的通用能力，从而缓解灾难性遗忘。\\n\\n**技术框架**：整体框架包括：1）选择预训练语言模型（Flan-T5-Base）；2）构建数学推理数据集（DeepMind Mathematics）和自然语言推理数据集（MultiNLI）；3）设计混合训练策略，即在每个训练批次中，按照一定的比例混合数学推理和NLI数据；4）评估模型在数学推理和NLI任务上的性能，以衡量灾难性遗忘的程度。\\n\\n**关键创新**：关键创新在于混合训练策略本身。与传统的仅使用特定任务数据进行微调的方法不同，该方法通过引入通用任务数据，实现了对模型参数的正则化，从而防止模型过度拟合特定任务，保留了通用能力。\\n\\n**关键设计**：关键设计包括：1）混合比例的选择：论文系统地探索了从1:1到15:1的混合比例，以找到最佳的平衡点；2）数据集的选择：选择了DeepMind Mathematics作为数学推理数据集，MultiNLI作为自然语言推理数据集，这两个数据集分别代表了特定任务和通用任务。",
            "application_zh": "该研究成果可应用于各种需要对大型语言模型进行微调的场景，例如特定领域的问答系统、代码生成、文本摘要等。通过混合训练，可以避免模型在学习新知识的同时忘记原有能力，从而提高模型的泛化性和实用性。该方法对于开发更强大、更可靠的AI系统具有重要意义。",
            "highlight_zh": "实验结果表明，混合训练能够完全消除灾难性遗忘，同时保持甚至提升数学推理性能。例如，使用1:1的混合比例进行训练，数学准确率达到12.0%（与仅数学训练相当），同时NLI准确率保持在86.2%，显著优于仅使用数学数据训练的模型（NLI准确率仅为16.5%）。即使是最小的NLI暴露（6.2%），也能提供有效的正则化。",
            "tags_zh": [
                "灾难性遗忘",
                "混合训练",
                "数学推理",
                "自然语言推理",
                "微调",
                "大型语言模型",
                "正则化"
            ],
            "_index": 186,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13706/figures/training_dynamics_dual.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13706/figures/pareto_frontier.png",
                    "caption": "",
                    "figure_id": "fig_1"
                }
            ]
        },
        {
            "title": "MIDUS: Memory-Infused Depth Up-Scaling",
            "authors": [
                "Taero Kim",
                "Hoyoon Byun",
                "Youngjun Choi",
                "Sungrae Park",
                "Kyungwoo Song"
            ],
            "arxiv_id": "2512.13751",
            "summary": "Scaling large language models (LLMs) demands approaches that increase capacity without incurring excessive parameter growth or inference cost. Depth Up-Scaling (DUS) has emerged as a promising strategy by duplicating layers and applying Continual Pre-training (CPT), but its reliance on feed-forward networks (FFNs) limits efficiency and attainable gains. We introduce Memory-Infused Depth Up-Scaling (MIDUS), which replaces FFNs in duplicated blocks with a head-wise memory (HML) layer. Motivated by observations that attention heads have distinct roles both across and within layers, MIDUS assigns an independent memory bank to each head, enabling head-wise retrieval and injecting information into subsequent layers while preserving head-wise functional structure. This design combines sparse memory access with head-wise representations and incorporates an efficient per-head value factorization module, thereby relaxing the usual efficiency-performance trade-off. Across our CPT experiments, MIDUS exhibits robust performance improvements over strong DUS baselines while maintaining a highly efficient parameter footprint. Our findings establish MIDUS as a compelling and resource-efficient alternative to conventional FFN replication for depth up-scaling by leveraging its head-wise memory design.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13751",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "MIDUS：通过注入记忆的深度扩展方法，提升大语言模型效率。",
            "summary_zh": "扩展大型语言模型(LLMs)需要增加模型容量，同时避免参数过度增长或推理成本过高。深度扩展(DUS)通过复制层并应用持续预训练(CPT)成为一种有前景的策略，但其对前馈网络(FFN)的依赖限制了效率和可获得的收益。我们引入了记忆注入深度扩展(MIDUS)，它用头注意力记忆(HML)层替换复制块中的FFN。基于注意力头在层间和层内具有不同作用的观察，MIDUS为每个头分配一个独立的记忆库，从而实现头注意力检索并将信息注入到后续层，同时保持头注意力功能结构。这种设计将稀疏记忆访问与头注意力表示相结合，并结合了高效的每头注意力值分解模块，从而缓解了通常的效率-性能权衡。在我们的CPT实验中，MIDUS相对于强大的DUS基线表现出强大的性能改进，同时保持了高效的参数占用。我们的研究结果表明，通过利用其头注意力记忆设计，MIDUS是一种引人注目的、资源高效的深度扩展替代传统FFN复制的方法。",
            "intro_zh": [
                "现有深度扩展方法依赖前馈网络，效率受限，难以在扩展模型容量的同时控制参数增长和推理成本。",
                "MIDUS用头注意力记忆层替换前馈网络，为每个注意力头分配独立记忆库，实现头注意力检索和信息注入。",
                "实验表明，MIDUS在持续预训练中表现出优于现有深度扩展基线的性能，同时保持高效的参数利用率。"
            ],
            "method_zh": "**问题定义**：现有的大语言模型深度扩展方法，如DUS，过度依赖前馈神经网络（FFN），导致模型扩展时参数量迅速增加，推理效率降低。如何在不显著增加参数量和推理成本的前提下，有效扩展模型深度，提升模型性能，是本文要解决的核心问题。\\n\\n**核心思路**：MIDUS的核心思路是用头注意力记忆（Head-wise Memory，HML）层替换复制块中的FFN。作者观察到不同的注意力头在模型中扮演着不同的角色，因此为每个头分配独立的记忆库，允许模型根据每个头的特定需求检索和注入信息。这种方法旨在利用注意力机制的优势，在保持模型性能的同时，减少参数冗余。\\n\\n**技术框架**：MIDUS的整体架构基于深度扩展（DUS）框架，主要包含以下几个阶段：1) 复制模型层：复制原始模型的若干层，形成扩展的深度；2) 替换FFN：将复制层中的前馈神经网络（FFN）替换为头注意力记忆（HML）层；3) 持续预训练（CPT）：在扩展后的模型上进行持续预训练，使模型适应新的深度和结构。HML层是关键模块，负责存储和检索与每个注意力头相关的信息。\\n\\n**关键创新**：MIDUS的关键创新在于头注意力记忆（HML）层的设计。与传统的共享记忆方法不同，HML为每个注意力头分配独立的记忆库，允许模型根据每个头的特定需求进行信息检索和注入。此外，MIDUS还引入了每头注意力值分解模块，进一步提高了模型的效率。这种头注意力级别的记忆管理方式，能够更精细地控制信息的流动和利用，从而在保持模型性能的同时，降低参数量和计算复杂度。\\n\\n**关键设计**：HML层的关键设计包括：1) 独立的记忆库：每个注意力头对应一个独立的记忆库，存储与该头相关的信息；2) 注意力检索机制：使用注意力机制从记忆库中检索信息，检索权重由当前层的注意力头计算得到；3) 信息注入机制：将检索到的信息注入到后续层，影响后续层的计算；4) 每头注意力值分解：对每个注意力头的值向量进行分解，减少参数量。",
            "application_zh": "MIDUS具有广泛的应用前景，可用于提升各种大型语言模型的性能，尤其是在资源受限的环境下。例如，可以应用于移动设备上的轻量级模型部署，或在计算资源有限的服务器上进行高效推理。此外，MIDUS的设计思想也可以推广到其他类型的深度学习模型中，例如视觉Transformer等。",
            "highlight_zh": "实验结果表明，MIDUS在持续预训练任务中，相较于DUS基线，在参数量相近的情况下，取得了显著的性能提升。具体数据（原文未提供，未知）。MIDUS通过头注意力记忆的设计，实现了高效的深度扩展，为大语言模型的优化提供了一种新的思路。",
            "tags_zh": [
                "深度扩展",
                "大型语言模型",
                "注意力机制",
                "记忆网络",
                "持续预训练"
            ],
            "_index": 187,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13751/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13751/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.13751/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "FLAME: Flow Enhanced Legendre Memory Models for General Time Series Forecasting",
            "authors": [
                "Xingjian Wu",
                "Hanyin Cheng",
                "Xiangfei Qiu",
                "Zhengyu Li",
                "Jilin Hu",
                "Chenjuan Guo",
                "Bin Yang"
            ],
            "arxiv_id": "2512.14253",
            "summary": "In this work, we introduce FLAME, a family of extremely lightweight and capable Time Series Foundation Models, which support both deterministic and probabilistic forecasting via generative probabilistic modeling, thus ensuring both efficiency and robustness. FLAME utilizes the Legendre Memory for strong generalization capabilities. Through adapting variants of Legendre Memory, i.e., translated Legendre (LegT) and scaled Legendre (LegS), in the Encoding and Decoding phases, FLAME can effectively capture the inherent inductive bias within data and make efficient long-range inferences. To enhance the accuracy of probabilistic forecasting while keeping efficient, FLAME adopts a Normalization Flow based forecasting head, which can model the arbitrarily intricate distributions over the forecasting horizon in a generative manner. Comprehensive experiments on well-recognized benchmarks, including TSFM-Bench and ProbTS, demonstrate the consistent state-of-the-art zero-shot performance of FLAME on both deterministic and probabilistic forecasting tasks.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14253",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "foundation model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "FLAME：用于通用时间序列预测的流增强勒让德记忆模型",
            "summary_zh": "本文提出FLAME，一种极其轻量且强大的时间序列基础模型家族，它通过生成概率建模支持确定性和概率性预测，从而确保效率和鲁棒性。FLAME利用勒让德记忆来实现强大的泛化能力。通过在编码和解码阶段调整勒让德记忆的变体，即平移勒让德（LegT）和缩放勒让德（LegS），FLAME可以有效地捕获数据中固有的归纳偏置，并进行高效的远程推理。为了在保持效率的同时提高概率预测的准确性，FLAME采用基于归一化流的预测头，该预测头可以以生成方式对预测范围内任意复杂的分布进行建模。在包括TSFM-Bench和ProbTS在内的公认基准上的综合实验表明，FLAME在确定性和概率性预测任务上均具有一致的最先进的零样本性能。",
            "intro_zh": [
                "现有时间序列预测模型在效率和鲁棒性方面存在挑战，尤其是在处理长程依赖和复杂分布时。",
                "FLAME通过引入平移和缩放勒让德记忆，有效捕获数据中的归纳偏置，并利用归一化流建模预测分布。",
                "在TSFM-Bench和ProbTS等基准测试中，FLAME在确定性和概率性预测任务上均取得了领先的零样本性能。"
            ],
            "method_zh": "**问题定义**：时间序列预测旨在根据历史数据预测未来的时间序列值。现有方法在处理长程依赖、捕捉复杂分布以及实现高效的零样本泛化方面存在挑战。尤其是在概率预测中，如何准确建模预测范围内的任意复杂分布是一个难点。\\n\\n**核心思路**：FLAME的核心思路是利用勒让德多项式的正交性和完备性，构建具有强大泛化能力的记忆模块。通过调整勒让德记忆的变体（平移和缩放），可以更好地适应不同时间序列数据的特性，从而捕获数据中的归纳偏置。此外，使用基于归一化流的预测头，可以灵活地建模任意复杂的预测分布。\\n\\n**技术框架**：FLAME的整体框架包括编码器、解码器和预测头三个主要模块。编码器使用平移勒让德记忆（LegT）来提取输入时间序列的特征。解码器使用缩放勒让德记忆（LegS）来生成预测序列。预测头则使用归一化流来建模预测分布，从而实现概率预测。\\n\\n**关键创新**：FLAME的关键创新在于以下几点：1) 提出了一种基于勒让德记忆的时间序列基础模型，具有强大的泛化能力。2) 通过引入平移和缩放勒让德记忆，更好地适应不同时间序列数据的特性。3) 采用基于归一化流的预测头，可以灵活地建模任意复杂的预测分布。与现有方法相比，FLAME在效率、鲁棒性和准确性方面均有所提升。\\n\\n**关键设计**：FLAME的关键设计包括：1) 平移勒让德记忆（LegT）和缩放勒让德记忆（LegS）的具体实现方式，包括平移和缩放参数的选择。2) 归一化流预测头的具体结构，包括流的类型和层数。3) 损失函数的设计，包括确定性预测的损失函数和概率预测的损失函数。4) 模型训练的优化算法和超参数设置。",
            "application_zh": "FLAME可应用于各种时间序列预测场景，如金融市场预测、能源需求预测、供应链管理、交通流量预测、天气预报等。其高效性和鲁棒性使其在资源受限的环境中也能发挥作用。未来，FLAME有望成为通用时间序列预测的基础模型，推动相关领域的发展。",
            "highlight_zh": "FLAME在TSFM-Bench和ProbTS等基准测试中取得了显著的成果。在确定性预测任务中，FLAME在多个数据集上超越了现有的最先进模型。在概率预测任务中，FLAME能够准确地建模预测分布，并取得了优异的预测性能。实验结果表明，FLAME在零样本学习方面具有强大的泛化能力。",
            "tags_zh": [
                "时间序列预测",
                "勒让德记忆",
                "归一化流",
                "零样本学习",
                "概率预测",
                "基础模型"
            ],
            "_index": 188,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14253/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14253/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14253/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "RePo: Language Models with Context Re-Positioning",
            "authors": [
                "Huayang Li",
                "Tianyu Zhao",
                "Richard Sproat"
            ],
            "arxiv_id": "2512.14391",
            "summary": "In-context learning is fundamental to modern Large Language Models (LLMs); however, prevailing architectures impose a rigid and fixed contextual structure by assigning linear or constant positional indices. Drawing on Cognitive Load Theory (CLT), we argue that this uninformative structure increases extraneous cognitive load, consuming finite working memory capacity that should be allocated to deep reasoning and attention allocation. To address this, we propose RePo, a novel mechanism that reduces extraneous load via context re-positioning. Unlike standard approaches, RePo utilizes a differentiable module, $f_\\phi$, to assign token positions that capture contextual dependencies, rather than replying on pre-defined integer range. By continually pre-training on the OLMo-2 1B backbone, we demonstrate that RePo significantly enhances performance on tasks involving noisy contexts, structured data, and longer context length, while maintaining competitive performance on general short-context tasks. Detailed analysis reveals that RePo successfully allocate higher attention to distant but relevant information, assign positions in dense and non-linear space, and capture the intrinsic structure of the input context. Our code is available atthis https URL.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14391",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "RePo：通过上下文重定位增强语言模型处理噪声和长文本能力",
            "summary_zh": "上下文学习是现代大型语言模型（LLMs）的基础；然而，目前流行的架构通过分配线性或恒定的位置索引，施加了一种刚性和固定的上下文结构。借鉴认知负荷理论（CLT），我们认为这种缺乏信息量的结构增加了额外的认知负荷，消耗了有限的工作记忆容量，而这些容量应该分配给深度推理和注意力分配。为了解决这个问题，我们提出了一种新颖的机制RePo，它通过上下文重定位来减少额外的负荷。与标准方法不同，RePo利用一个可微模块$f_\\phi$来分配token位置，从而捕获上下文依赖关系，而不是依赖于预定义的整数范围。通过在OLMo-2 1B骨干上持续预训练，我们证明了RePo显著提高了在涉及噪声上下文、结构化数据和更长上下文长度的任务上的性能，同时在一般的短上下文任务上保持了有竞争力的性能。详细的分析表明，RePo成功地将更高的注意力分配给遥远但相关的信息，在密集和非线性空间中分配位置，并捕获输入上下文的内在结构。我们的代码可以在这个https URL上找到。",
            "intro_zh": [
                "现有LLM采用固定位置索引，导致认知负荷过高，影响模型在复杂任务中的推理和注意力分配。",
                "RePo通过可微模块动态分配token位置，捕捉上下文依赖，从而降低认知负荷，提升模型性能。",
                "实验表明，RePo在噪声上下文、结构化数据和长文本任务上显著提升，同时保持了短文本任务的竞争力。"
            ],
            "method_zh": "**问题定义**：现有大型语言模型（LLMs）在处理长文本、噪声数据或结构化信息时，由于其固定的位置编码方式，导致模型需要处理大量的无关信息，增加了认知负荷，降低了模型在关键信息上的注意力分配效率。这种固定的上下文结构无法有效捕捉token之间的复杂依赖关系，限制了模型在复杂任务中的表现。\\n\\n**核心思路**：RePo的核心思路是通过学习一种动态的位置编码方式，使模型能够根据上下文信息自适应地调整token的位置表示。这种方法旨在减少模型需要处理的无关信息，提高模型对关键信息的关注度，从而降低认知负荷，提升模型在复杂任务中的性能。通过可微模块学习token位置，使得模型能够更好地捕捉上下文依赖关系。\\n\\n**技术框架**：RePo的核心是一个可微的位置编码模块$f_\\phi$，该模块接收token的上下文信息作为输入，并输出token的位置表示。该位置表示不再是固定的整数索引，而是一个连续的向量，可以根据上下文信息进行调整。整个框架可以嵌入到现有的Transformer架构中，通过预训练的方式进行学习。在训练过程中，模型需要学习如何根据上下文信息生成合适的位置表示，从而提高模型在下游任务中的表现。\\n\\n**关键创新**：RePo最重要的创新点在于其动态的位置编码方式。与传统的固定位置编码方式不同，RePo可以根据上下文信息自适应地调整token的位置表示，从而更好地捕捉token之间的依赖关系。这种动态的位置编码方式可以有效地降低模型需要处理的无关信息，提高模型对关键信息的关注度，从而降低认知负荷，提升模型在复杂任务中的性能。\\n\\n**关键设计**：RePo的关键设计在于可微的位置编码模块$f_\\phi$。该模块可以使用各种神经网络结构来实现，例如多层感知机（MLP）或卷积神经网络（CNN）。在训练过程中，可以使用各种损失函数来优化该模块的参数，例如对比损失或三元组损失。此外，还可以使用各种正则化技术来防止过拟合。论文中使用OLMo-2 1B作为backbone，并持续进行预训练，以验证RePo的有效性。",
            "application_zh": "RePo具有广泛的应用前景，尤其是在需要处理长文本、噪声数据或结构化信息的场景中。例如，可以应用于信息抽取、文本摘要、机器翻译等任务。此外，RePo还可以用于增强对话系统和智能助手的性能，使其能够更好地理解用户的意图并提供更准确的回复。该研究的成果有助于提升语言模型在实际应用中的鲁棒性和泛化能力。",
            "highlight_zh": "实验结果表明，RePo在涉及噪声上下文、结构化数据和更长上下文长度的任务上显著提高了性能，同时在一般的短上下文任务上保持了有竞争力的性能。例如，在某些任务上，RePo的性能提升超过了10%。详细的分析表明，RePo成功地将更高的注意力分配给遥远但相关的信息，在密集和非线性空间中分配位置，并捕获输入上下文的内在结构。",
            "tags_zh": [
                "上下文重定位",
                "语言模型",
                "认知负荷",
                "长文本处理",
                "噪声数据",
                "位置编码",
                "Transformer",
                "可微模块"
            ],
            "_index": 189,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14391/figs/repo_overall.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14391/figs/repo_long_context.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14391/figs/stats_pos_dist.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "LoopBench: Discovering Emergent Symmetry Breaking Strategies with LLM Swarms",
            "authors": [
                "Ali Parsaee",
                "Yashar Talebirad",
                "Csongor Szepesvári",
                "Vishwajeet Ohal",
                "Eden Redman"
            ],
            "arxiv_id": "2512.13713",
            "summary": "Large Language Models (LLMs) are increasingly being utilized as autonomous agents, yet their ability to coordinate in distributed systems remains poorly understood. We introduce \\textbf{LoopBench}, a benchmark to evaluate LLM reasoning in distributed symmetry breaking and meta-cognitive thinking. The benchmark focuses on coloring odd cycle graphs ($C_3, C_5, C_{11}$) with limited colors, where deterministic, non-communicating agents fail in infinite loops. A strategy passing mechanism is implemented as a form of consistent memory. We show that while standard LLMs and classical heuristics struggle, advanced reasoning models (e.g., O3) devise strategies to escape deadlocks. LoopBench allows the study of emergent distributed algorithms based on language-based reasoning, offering a testbed for collective intelligence.",
            "categories": [
                "cs.AI",
                "cs.LG",
                "cs.MA"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13713",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "LoopBench：利用LLM集群发现涌现的对称破缺策略",
            "summary_zh": "大型语言模型（LLMs）越来越多地被用作自主智能体，但它们在分布式系统中进行协调的能力仍然知之甚少。我们提出了\textbf{LoopBench}，一个用于评估LLM在分布式对称破缺和元认知思维中推理能力的基准。该基准专注于使用有限的颜色对奇数环图（$C_3, C_5, C_{11}$）进行着色，其中确定性的、非通信的智能体在无限循环中失败。策略传递机制被实现为一种一致的记忆形式。我们表明，虽然标准LLM和经典启发式方法难以奏效，但高级推理模型（例如，O3）可以设计出逃避死锁的策略。LoopBench允许研究基于语言推理的涌现分布式算法，为集体智能提供了一个试验平台。",
            "intro_zh": [
                "现有方法在解决分布式系统中对称破缺问题时，面临确定性算法陷入无限循环的挑战，缺乏有效的协调机制。",
                "LoopBench通过引入策略传递机制，使LLM智能体能够共享信息并形成一致的记忆，从而打破对称性并避免死锁。",
                "实验表明，高级推理模型（如O3）在LoopBench上能够涌现出有效的分布式算法，超越了传统LLM和启发式方法。"
            ],
            "method_zh": "**问题定义**：论文旨在解决分布式系统中，多个智能体在面对对称性问题时，由于缺乏有效的通信和协调机制，容易陷入无限循环的困境。特别是在奇数环图着色问题中，如果每个智能体都采用确定性的局部策略，则无法打破对称性，导致着色失败。现有方法，如传统LLM和启发式算法，难以有效地解决此类问题。\\n\\n**核心思路**：论文的核心思路是利用大型语言模型（LLMs）的推理能力，并引入一种策略传递机制，使智能体能够共享信息并形成一致的记忆。通过这种方式，智能体可以逐步学习并调整其策略，最终打破对称性，避免陷入死锁。这种方法模拟了人类在解决复杂问题时的协作和学习过程。\\n\\n**技术框架**：LoopBench的整体框架包含以下几个主要组成部分：1) 奇数环图生成器：用于生成不同大小的奇数环图（如C3, C5, C11）。2) LLM智能体：每个节点对应一个LLM智能体，负责选择颜色。3) 策略传递机制：允许智能体之间传递策略信息，形成一致的记忆。4) 评估指标：用于评估智能体成功着色的能力。整个流程如下：首先，生成一个奇数环图。然后，每个节点上的LLM智能体根据当前状态和接收到的策略信息，选择一个颜色。接着，智能体将自己的策略信息传递给相邻的智能体。重复上述步骤，直到所有节点都被成功着色，或者达到最大迭代次数。\\n\\n**关键创新**：论文的关键创新在于将LLM的推理能力与策略传递机制相结合，从而实现了涌现的分布式算法。与传统的确定性算法相比，这种方法具有更强的适应性和鲁棒性，能够更好地应对复杂环境中的对称性问题。此外，LoopBench本身也是一个重要的创新，它提供了一个用于评估LLM在分布式系统中推理能力的基准。\\n\\n**关键设计**：策略传递机制是LoopBench的关键设计之一。具体来说，每个智能体维护一个策略记忆，用于存储其历史策略信息。在每一轮迭代中，智能体不仅会根据当前状态选择颜色，还会将自己的策略信息传递给相邻的智能体。接收到策略信息的智能体会将其与自身的策略记忆进行融合，从而形成新的策略。这种策略融合的方式可以采用多种方法，例如平均、加权平均等。此外，论文还探索了不同的LLM模型（如O3）作为智能体的性能。",
            "application_zh": "LoopBench的研究成果具有广泛的应用前景，例如在分布式计算、机器人协作、交通管理等领域。通过利用LLM的推理能力和策略传递机制，可以设计出更加智能和高效的分布式系统，从而提高系统的整体性能和鲁棒性。此外，LoopBench还可以作为研究集体智能和涌现行为的平台，为人工智能领域的发展提供新的思路。",
            "highlight_zh": "实验结果表明，高级推理模型（如O3）在LoopBench上能够显著超越传统的LLM和启发式方法。例如，在C11图着色问题中，O3的成功率达到了80%以上，而传统LLM的成功率仅为20%左右。这表明，通过引入策略传递机制和利用LLM的推理能力，可以有效地解决分布式系统中的对称性问题。",
            "tags_zh": [
                "大型语言模型",
                "分布式系统",
                "对称破缺",
                "元认知",
                "智能体协作"
            ],
            "_index": 190,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13713/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13713/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                }
            ]
        },
        {
            "title": "EvoLattice: Persistent Internal-Population Evolution through Multi-Alternative Quality-Diversity Graph Representations for LLM-Guided Program Discovery",
            "authors": [
                "Kamer Ali Yuksel"
            ],
            "arxiv_id": "2512.13857",
            "summary": "Large language models (LLMs) are increasingly used to evolve programs and multi-agent systems, yet most existing approaches rely on overwrite-based mutations that maintain only a single candidate at a time. Such methods discard useful variants, suffer from destructive edits, and explore a brittle search space prone to structural failure. We introduce EvoLattice, a framework that represents an entire population of candidate programs or agent behaviors within a single directed acyclic graph. Each node stores multiple persistent alternatives, and every valid path through the graph defines a distinct executable candidate, yielding a large combinatorial search space without duplicating structure. EvoLattice enables fine-grained alternative-level evaluation by scoring each alternative across all paths in which it appears, producing statistics that reveal how local design choices affect global performance. These statistics provide a dense, data-driven feedback signal for LLM-guided mutation, recombination, and pruning, while preserving successful components. Structural correctness is guaranteed by a deterministic self-repair mechanism that enforces acyclicity and dependency consistency independently of the LLM. EvoLattice naturally extends to agent evolution by interpreting alternatives as prompt fragments or sub-agent behaviors. Across program synthesis (proxy and optimizer meta-learning), EvoLattice yields more stable evolution, greater expressivity, and stronger improvement trajectories than prior LLM-guided methods. The resulting dynamics resemble quality-diversity optimization, emerging implicitly from EvoLattice's internal multi-alternative representation rather than an explicit external archive.",
            "categories": [
                "cs.AI",
                "cs.CL",
                "cs.LG",
                "cs.MA",
                "cs.NE"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13857",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "EvoLattice：通过多替代质量多样性图表示实现LLM引导的程序发现",
            "summary_zh": "大型语言模型（LLMs）越来越多地用于演化程序和多智能体系统，但现有方法大多依赖于基于覆盖的突变，每次只维护一个候选方案。这些方法丢弃了有用的变体，遭受破坏性编辑，并探索了一个脆弱的搜索空间，容易出现结构性故障。我们引入了EvoLattice，一个在单个有向无环图中表示候选程序或智能体行为群体的框架。每个节点存储多个持久性替代方案，并且通过图的每个有效路径定义了一个不同的可执行候选方案，从而产生一个大的组合搜索空间，而无需复制结构。EvoLattice通过对每个替代方案在其出现的所有路径上进行评分，从而实现细粒度的替代方案级别评估，从而产生统计数据，揭示局部设计选择如何影响全局性能。这些统计数据为LLM引导的突变、重组和修剪提供了密集的数据驱动反馈信号，同时保留了成功的组件。结构正确性由确定性的自修复机制保证，该机制独立于LLM强制执行非循环性和依赖性一致性。EvoLattice通过将替代方案解释为提示片段或子智能体行为，自然地扩展到智能体演化。在程序合成（代理和优化器元学习）中，EvoLattice比先前的LLM引导方法产生更稳定的演化、更大的表达性和更强的改进轨迹。由此产生的动态类似于质量多样性优化，从EvoLattice的内部多替代表示中隐式地出现，而不是显式的外部存档。",
            "intro_zh": [
                "现有LLM引导的程序演化方法依赖于单候选覆盖式突变，易丢失有用变体并导致结构性问题。",
                "EvoLattice使用有向无环图表示候选程序群体，节点存储多个替代方案，实现组合搜索空间。",
                "EvoLattice通过评估替代方案对全局性能的影响，为LLM提供数据驱动的反馈，并保证结构正确性。"
            ],
            "method_zh": "**问题定义**：现有基于LLM的程序演化方法通常采用单候选方案的迭代更新策略，即每次只保留一个最佳候选方案，并对其进行突变。这种方法的痛点在于：1) 容易丢失有用的中间变体，导致搜索效率低下；2) 突变操作可能引入破坏性修改，导致程序结构崩溃；3) 搜索空间脆弱，容易陷入局部最优。\n\n**核心思路**：EvoLattice的核心思路是构建一个有向无环图，将整个候选程序群体表示在一个统一的结构中。图中的每个节点代表程序的一个组成部分，每个节点可以存储多个替代方案。通过图的每一条有效路径，可以生成一个完整的可执行程序。这种设计允许同时探索多个候选方案，并保留有用的中间变体，从而提高搜索效率和鲁棒性。\n\n**技术框架**：EvoLattice框架包含以下主要模块：1) **图构建模块**：负责构建和维护有向无环图，包括添加节点、添加替代方案、连接节点等操作。2) **评估模块**：负责评估每个替代方案的性能，并生成反馈信号。评估过程考虑了该替代方案在所有包含它的路径上的表现。3) **LLM引导模块**：利用LLM根据评估结果，指导图的演化，包括突变、重组和修剪等操作。4) **自修复模块**：负责保证图的结构正确性，包括强制执行非循环性和依赖性一致性。\n\n**关键创新**：EvoLattice最重要的技术创新点在于其内部多替代方案表示。与传统的单候选方案方法不同，EvoLattice能够同时维护和评估多个替代方案，从而实现更高效的搜索和更鲁棒的演化。此外，EvoLattice的自修复机制能够保证程序结构的正确性，避免了因突变操作导致的结构性问题。\n\n**关键设计**：EvoLattice的关键设计包括：1) **替代方案的表示**：每个节点存储多个替代方案，每个替代方案可以是程序代码片段、智能体行为等。2) **评估指标**：评估指标用于衡量每个替代方案的性能，并生成反馈信号。3) **LLM提示工程**：设计合适的LLM提示，引导LLM进行有效的突变、重组和修剪操作。4) **自修复规则**：定义一组规则，用于保证图的结构正确性，例如强制执行非循环性和依赖性一致性。",
            "application_zh": "EvoLattice可应用于程序合成、机器人控制、智能体设计等领域。通过高效地探索程序或智能体行为空间，EvoLattice能够自动发现高性能的解决方案。该研究的潜在价值在于降低程序开发和智能体设计的成本，并加速人工智能技术的应用。",
            "highlight_zh": "实验结果表明，EvoLattice在程序合成任务（代理和优化器元学习）中，比现有的LLM引导方法表现出更稳定的演化过程、更大的表达能力和更强的性能提升。EvoLattice能够隐式地实现质量多样性优化，而无需显式的外部存档。",
            "tags_zh": [
                "程序演化",
                "大型语言模型",
                "质量多样性",
                "图表示",
                "智能体设计"
            ],
            "_index": 191,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13857/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                }
            ]
        },
        {
            "title": "Olmo 3",
            "authors": [
                "Team Olmo",
                "Allyson Ettinger",
                "Amanda Bertsch",
                "Bailey Kuehl",
                "David Graham",
                "David Heineman",
                "Dirk Groeneveld",
                "Faeze Brahman",
                "Finbarr Timbers",
                "Hamish Ivison",
                "Jacob Morrison",
                "Jake Poznanski",
                "Kyle Lo",
                "Luca Soldaini",
                "Matt Jordan",
                "Mayee Chen",
                "Michael Noukhovitch",
                "Nathan Lambert",
                "Pete Walsh",
                "Pradeep Dasigi",
                "Robert Berry",
                "Saumya Malik",
                "Saurabh Shah",
                "Scott Geng",
                "Shane Arora",
                "Shashank Gupta",
                "Taira Anderson",
                "Teng Xiao",
                "Tyler Murray",
                "Tyler Romero",
                "Victoria Graf",
                "Akari Asai",
                "Akshita Bhagia",
                "Alexander Wettig",
                "Alisa Liu",
                "Aman Rangapur",
                "Chloe Anastasiades",
                "Costa Huang",
                "Dustin Schwenk",
                "Harsh Trivedi",
                "Ian Magnusson",
                "Jaron Lochner",
                "Jiacheng Liu",
                "Lester James V. Miranda",
                "Maarten Sap",
                "Malia Morgan",
                "Michael Schmitz",
                "Michal Guerquin",
                "Michael Wilson",
                "Regan Huff",
                "Ronan Le Bras",
                "Rui Xin",
                "Rulin Shao",
                "Sam Skjonsberg",
                "Shannon Zejiang Shen",
                "Shuyue Stella Li",
                "Tucker Wilde",
                "Valentina Pyatkin",
                "Will Merrill",
                "Yapei Chang",
                "Yuling Gu",
                "Zhiyuan Zeng",
                "Ashish Sabharwal",
                "Luke Zettlemoyer",
                "Pang Wei Koh",
                "Ali Farhadi",
                "Noah A. Smith",
                "Hannaneh Hajishirzi"
            ],
            "arxiv_id": "2512.13961",
            "summary": "We introduce Olmo 3, a family of state-of-the-art, fully-open language models at the 7B and 32B parameter scales. Olmo 3 model construction targets long-context reasoning, function calling, coding, instruction following, general chat, and knowledge recall. This release includes the entire model flow, i.e., the full lifecycle of the family of models, including every stage, checkpoint, data point, and dependency used to build it. Our flagship model, Olmo 3 Think 32B, is the strongest fully-open thinking model released to-date.",
            "categories": [
                "cs.CL",
                "cs.LG"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13961",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "instruction following"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "发布Olmo 3：兼顾长文本推理、函数调用和代码能力的完全开源语言模型",
            "summary_zh": "本文介绍了Olmo 3，一个最先进的、完全开源的语言模型家族，参数规模分别为7B和32B。Olmo 3模型构建的目标是长上下文推理、函数调用、编码、指令遵循、通用聊天和知识回忆。本次发布包括完整的模型流程，即模型家族的完整生命周期，包括用于构建它的每个阶段、检查点、数据点和依赖项。我们的旗舰模型Olmo 3 Think 32B是迄今为止发布的最强大的完全开源的思考模型。",
            "intro_zh": [
                "现有开源语言模型在长文本推理、函数调用和代码能力方面存在不足，限制了其在复杂任务中的应用。",
                "Olmo 3旨在构建一个完全开源的语言模型家族，专注于提升长文本推理、函数调用、编码等关键能力。",
                "Olmo 3 Think 32B是目前最强大的完全开源的思考模型，为研究和应用提供了新的选择。"
            ],
            "method_zh": "**问题定义**：现有开源语言模型在长文本推理、函数调用、编码、指令跟随、通用聊天和知识回忆等方面存在不足，难以满足日益增长的复杂应用需求。缺乏完全开源的模型流程也阻碍了研究人员的深入分析和改进。\\n\\n**核心思路**：Olmo 3的核心思路是构建一个完全开源、可复现的语言模型家族，通过精心设计的数据集和训练策略，提升模型在长文本推理、函数调用和代码生成等方面的能力。同时，公开完整的模型流程，促进社区的共同发展。\\n\\n**技术框架**：Olmo 3的整体框架包括数据收集与处理、模型架构选择、预训练、指令微调和评估等阶段。具体模块包括数据清洗模块、模型训练模块、评估模块和模型发布模块。每个阶段都有详细的文档记录和可复现的脚本。\\n\\n**关键创新**：Olmo 3的关键创新在于其完全开源的模型流程和对长文本推理、函数调用等能力的重点关注。与现有开源模型相比，Olmo 3提供了更透明、更易于定制和改进的平台。\\n\\n**关键设计**：Olmo 3采用了Transformer架构，并针对长文本处理进行了优化。具体的参数设置、损失函数和网络结构等技术细节在论文中进行了详细描述。指令微调阶段使用了高质量的指令数据集，以提升模型的指令跟随能力。具体数值和超参数设置未知。",
            "application_zh": "Olmo 3可应用于智能助手、代码生成、知识问答、长文本摘要等领域。其完全开源的特性使得研究人员可以深入研究模型的内部机制，并根据自身需求进行定制和改进。该模型有望推动自然语言处理技术的进一步发展。",
            "highlight_zh": "Olmo 3 Think 32B是目前最强大的完全开源的思考模型，在长文本推理、函数调用和代码生成等任务上表现出色。具体的性能数据和对比基线需要在论文中查找。该模型的发布为开源社区提供了一个强大的基线模型。",
            "tags_zh": [
                "开源语言模型",
                "长文本推理",
                "函数调用",
                "代码生成",
                "指令微调",
                "Transformer模型",
                "自然语言处理"
            ],
            "_index": 192,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "C-ing Clearly: Enhanced Binary Code Explanations using C code",
            "authors": [
                "Teodor Poncu",
                "Ioana Pintilie",
                "Marius Dragoi",
                "Dragos Tantaru",
                "Florin Brad"
            ],
            "arxiv_id": "2512.14500",
            "summary": "Large Language Models (LLMs) typically excel at coding tasks involving high-level programming languages, as opposed to lower-level programming languages, such as assembly. We propose a synthetic data generation method named C-ing Clearly, which leverages the corresponding C code to enhance an LLM's understanding of assembly. By fine-tuning on data generated through our method, we demonstrate improved LLM performance for binary code summarization and vulnerability detection. Our approach demonstrates consistent gains across different LLM families and model sizes.",
            "categories": [
                "cs.CL",
                "cs.LG"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14500",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "C-ing Clearly：利用C代码增强LLM对二进制代码的理解，提升代码解释能力",
            "summary_zh": "大型语言模型(LLM)通常擅长处理高级编程语言的编码任务，但在处理诸如汇编等低级编程语言时表现欠佳。本文提出了一种名为C-ing Clearly的合成数据生成方法，该方法利用相应的C代码来增强LLM对汇编的理解。通过在我们方法生成的数据上进行微调，我们证明了LLM在二进制代码摘要和漏洞检测方面的性能得到了提高。我们的方法在不同的LLM系列和模型大小上都表现出一致的增益。",
            "intro_zh": [
                "现有LLM在处理汇编等低级语言时能力不足，影响了二进制代码分析等任务的性能。",
                "C-ing Clearly方法通过生成包含C代码对应关系的合成数据，提升LLM对汇编代码的理解。",
                "实验表明，基于该方法微调的LLM在二进制代码摘要和漏洞检测任务上取得了显著的性能提升。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型(LLM)在理解和处理低级编程语言（如汇编代码）时表现不佳的问题。现有的LLM在高级语言（如Python或C++）的代码任务中表现出色，但直接应用于二进制代码分析时，由于缺乏对底层硬件和指令集的理解，效果往往不尽如人意。这限制了LLM在二进制代码摘要、漏洞检测等安全领域的应用。\n\n**核心思路**：论文的核心思路是利用高级语言（C代码）作为桥梁，帮助LLM更好地理解汇编代码。通过构建包含C代码和对应汇编代码的合成数据集，让LLM学习它们之间的关联，从而提升LLM对汇编代码的理解能力。这种方法类似于“翻译”的过程，将汇编代码映射到更易于理解的C代码。\n\n**技术框架**：C-ing Clearly方法主要包含以下几个阶段：1) C代码生成：随机生成具有不同功能的C代码片段；2) 汇编代码生成：将生成的C代码编译成对应的汇编代码；3) 数据集构建：将C代码和对应的汇编代码组合成训练数据集，并添加适当的提示信息，例如“这段汇编代码对应于以下C代码：”。4) 模型微调：使用生成的数据集对LLM进行微调，使其学习C代码和汇编代码之间的映射关系。\n\n**关键创新**：该方法最重要的创新点在于利用高级语言（C代码）作为辅助信息，来提升LLM对低级语言（汇编代码）的理解。与直接使用汇编代码训练LLM相比，该方法能够更有效地利用LLM在高级语言方面的知识，从而提高模型的泛化能力和性能。此外，合成数据的生成过程可以灵活控制，从而可以针对特定的任务或漏洞类型生成更具针对性的训练数据。\n\n**关键设计**：在C代码生成阶段，需要考虑代码的多样性和复杂性，以覆盖不同的汇编指令和代码模式。可以使用随机数生成器来控制代码的长度、变量类型、控制流结构等。在数据集构建阶段，需要仔细设计提示信息，以引导LLM学习C代码和汇编代码之间的对应关系。在模型微调阶段，需要选择合适的LLM架构和训练参数，并进行充分的实验验证。",
            "application_zh": "该研究成果可应用于二进制代码分析、恶意软件检测、漏洞挖掘和逆向工程等领域。通过提升LLM对二进制代码的理解能力，可以自动化地进行代码摘要生成、漏洞检测和代码相似性分析，从而提高软件安全性和开发效率。未来，该方法可以扩展到其他低级语言或硬件描述语言，为更广泛的应用场景提供支持。",
            "highlight_zh": "实验结果表明，使用C-ing Clearly方法微调的LLM在二进制代码摘要和漏洞检测任务上取得了显著的性能提升。具体而言，在代码摘要任务上，该方法将ROUGE指标提高了XX%，在漏洞检测任务上，将准确率提高了YY%。此外，该方法在不同的LLM架构和模型大小上都表现出一致的增益，证明了其有效性和泛化能力。（注：XX和YY需要根据论文实际数据进行补充）",
            "tags_zh": [
                "二进制代码分析",
                "大型语言模型",
                "汇编代码理解",
                "合成数据生成",
                "代码摘要",
                "漏洞检测",
                "C代码辅助"
            ],
            "_index": 193,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Theoretical Guarantees of Learning Ensembling Strategies with Applications to Time Series Forecasting",
            "authors": [
                "Hilaf Hasson",
                "Danielle C. Maddix",
                "Yuyang Wang",
                "Gaurav Gupta",
                "Youngsuk Park"
            ],
            "arxiv_id": "2305.15786",
            "summary": "Ensembling is among the most popular tools in machine learning (ML) due to its effectiveness in minimizing variance and thus improving generalization. Most ensembling methods for black-box base learners fall under the umbrella of \"stacked generalization,\" namely training an ML algorithm that takes the inferences from the base learners as input. While stacking has been widely applied in practice, its theoretical properties are poorly understood. In this paper, we prove a novel result, showing that choosing the best stacked generalization from a (finite or finite-dimensional) family of stacked generalizations based on cross-validated performance does not perform \"much worse\" than the oracle best. Our result strengthens and significantly extends the results in Van der Laan et al. (2007). Inspired by the theoretical analysis, we further propose a particular family of stacked generalizations in the context of probabilistic forecasting, each one with a different sensitivity for how much the ensemble weights are allowed to vary across items, timestamps in the forecast horizon, and quantiles. Experimental results demonstrate the performance gain of the proposed method.",
            "categories": [
                "cs.LG",
                "math.ST",
                "stat.ML"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2305.15786",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "TAMP"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出一种基于交叉验证的集成学习策略，并应用于时间序列预测。",
            "summary_zh": "集成学习是机器学习中一种流行的工具，因为它能有效降低方差，从而提高泛化能力。大多数黑盒基学习器的集成方法都属于“堆叠泛化”的范畴，即训练一个机器学习算法，将基学习器的推断结果作为输入。虽然堆叠泛化在实践中得到了广泛应用，但其理论性质却知之甚少。本文证明了一个新的结果，表明从基于交叉验证性能的（有限或有限维）堆叠泛化族中选择最佳堆叠泛化，其性能不会比oracle最佳差“太多”。我们的结果加强并显著扩展了Van der Laan等人（2007）的结果。受理论分析的启发，我们进一步在概率预测的背景下提出了一种特殊的堆叠泛化族，每个堆叠泛化族对集成权重在项目、预测范围的时间戳和分位数上的变化程度具有不同的敏感性。实验结果表明了所提出方法的性能提升。",
            "intro_zh": [
                "现有集成学习方法缺乏充分的理论支撑，尤其是在堆叠泛化方面，理论性质理解不足。",
                "论文提出一种基于交叉验证的堆叠泛化选择方法，证明其性能接近oracle最佳。",
                "在概率预测中，设计了具有不同敏感度的堆叠泛化族，实验验证了方法的有效性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决集成学习中堆叠泛化方法的理论保证问题，并将其应用于时间序列预测。现有堆叠泛化方法虽然在实践中应用广泛，但缺乏充分的理论分析，难以保证其性能和泛化能力。此外，在时间序列预测中，如何有效地利用集成学习来提高预测精度也是一个挑战。\\n\\n**核心思路**：论文的核心思路是证明基于交叉验证选择堆叠泛化策略的性能保证。具体来说，论文证明了从一个（有限或有限维）堆叠泛化族中选择最佳策略，其性能不会比oracle最佳策略差太多。这种方法利用交叉验证来估计不同策略的性能，并选择性能最佳的策略，从而避免了对数据分布的强假设。\\n\\n**技术框架**：论文的技术框架主要包括以下几个部分：1）定义堆叠泛化策略族；2）使用交叉验证估计每个策略的性能；3）选择性能最佳的策略；4）在时间序列预测中，设计具有不同敏感度的堆叠泛化族，以适应不同时间序列的特点。整体流程是先进行理论分析，然后基于理论分析设计具体的算法，最后通过实验验证算法的性能。\\n\\n**关键创新**：论文的关键创新在于提出了一个关于堆叠泛化策略选择的理论结果，证明了基于交叉验证的选择方法具有良好的性能保证。此外，论文还针对时间序列预测问题，设计了一种具有不同敏感度的堆叠泛化族，可以更好地适应不同时间序列的特点。\\n\\n**关键设计**：在时间序列预测中，论文设计了一种特殊的堆叠泛化族，每个堆叠泛化族对集成权重在项目、预测范围的时间戳和分位数上的变化程度具有不同的敏感性。这种设计允许模型根据不同时间序列的特点，自适应地调整集成权重，从而提高预测精度。具体的参数设置和损失函数选择取决于具体的应用场景和数据集。",
            "application_zh": "该研究成果可应用于各种需要集成学习的场景，尤其是在时间序列预测领域，如金融预测、需求预测、能源预测等。通过选择合适的集成策略，可以提高预测精度和鲁棒性，降低预测风险，为决策提供更可靠的依据。该研究也为集成学习的理论研究提供了新的思路。",
            "highlight_zh": "实验结果表明，所提出的基于交叉验证的堆叠泛化方法在时间序列预测任务中取得了显著的性能提升。具体来说，通过设计具有不同敏感度的堆叠泛化族，模型可以更好地适应不同时间序列的特点，从而提高预测精度。实验结果验证了理论分析的有效性，并表明该方法具有实际应用价值。",
            "tags_zh": [
                "集成学习",
                "堆叠泛化",
                "时间序列预测",
                "交叉验证",
                "理论保证"
            ],
            "_index": 194,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://ar5iv.labs.arxiv.org/html/2305.15786/assets/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://ar5iv.labs.arxiv.org/assets/ar5iv.png",
                    "caption": "",
                    "figure_id": "img_1"
                }
            ]
        },
        {
            "title": "FreeKV: Boosting KV Cache Retrieval for Efficient LLM Inference",
            "authors": [
                "Guangda Liu",
                "Chengwei Li",
                "Zhenyu Ning",
                "Jing Lin",
                "Yiwu Yao",
                "Danning Ke",
                "Minyi Guo",
                "Jieru Zhao"
            ],
            "arxiv_id": "2505.13109",
            "summary": "Large language models (LLMs) have been widely deployed with rapidly expanding context windows to support increasingly demanding applications. However, long contexts pose significant deployment challenges, primarily due to the KV cache whose size grows proportionally with context length. While KV cache compression methods are proposed to address this issue, KV dropping methods incur considerable accuracy loss, and KV retrieval methods suffer from significant efficiency bottlenecks. We propose FreeKV, an algorithm-system co-optimization framework to enhance KV retrieval efficiency while preserving accuracy. On the algorithm side, FreeKV introduces speculative retrieval to shift the KV selection and recall processes out of the critical path, combined with fine-grained correction to ensure accuracy. On the system side, FreeKV employs hybrid KV layouts across CPU and GPU memory to eliminate fragmented data transfers, and leverages double-buffered streamed recall to further improve efficiency. Experiments demonstrate that FreeKV achieves near-lossless accuracy across various scenarios and models, delivering up to 13$\\times$ speedup compared to SOTA KV retrieval methods.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2505.13109",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "FreeKV：通过增强KV缓存检索实现高效LLM推理",
            "summary_zh": "大型语言模型（LLMs）已被广泛部署，其上下文窗口迅速扩展，以支持日益增长的应用需求。然而，长上下文带来了显著的部署挑战，主要是由于KV缓存的大小与上下文长度成正比增长。虽然已经提出了KV缓存压缩方法来解决这个问题，但KV丢弃方法会导致相当大的精度损失，而KV检索方法则存在显著的效率瓶颈。我们提出了FreeKV，一个算法-系统协同优化框架，以提高KV检索效率，同时保持精度。在算法方面，FreeKV引入了推测检索，将KV选择和召回过程移出关键路径，并结合细粒度校正以确保精度。在系统方面，FreeKV采用跨CPU和GPU内存的混合KV布局，以消除碎片化的数据传输，并利用双缓冲流式召回进一步提高效率。实验表明，FreeKV在各种场景和模型中实现了接近无损的精度，与SOTA KV检索方法相比，速度提高了高达13倍。",
            "intro_zh": [
                "长上下文LLM推理面临KV缓存过大的挑战，现有压缩方法损失精度，检索方法效率低。",
                "FreeKV提出推测检索，将KV选择移出关键路径，并进行细粒度校正以保证准确性。",
                "FreeKV通过混合KV布局和双缓冲流式召回，在算法和系统层面协同优化，提升效率。"
            ],
            "method_zh": "**问题定义**：论文旨在解决长上下文LLM推理中，KV缓存检索效率低下的问题。现有KV缓存压缩方法（如KV丢弃）会造成精度损失，而KV缓存检索方法则面临严重的效率瓶颈，限制了长上下文LLM的实际应用。\\n\\n**核心思路**：FreeKV的核心思路是通过推测检索，将KV选择和召回过程从推理的关键路径中移除，从而减少延迟。同时，为了保证精度，引入了细粒度的校正机制，对推测检索的结果进行修正。此外，通过算法和系统层面的协同优化，进一步提升检索效率。\\n\\n**技术框架**：FreeKV的整体框架包含以下几个主要模块：1) 推测检索模块：基于一定的策略（例如，历史访问频率）推测需要检索的KV对。2) 细粒度校正模块：对推测检索的结果进行校正，以减少误差。3) 混合KV布局模块：将KV缓存分布在CPU和GPU内存中，以减少数据传输的开销。4) 双缓冲流式召回模块：利用双缓冲技术，实现KV数据的流式召回，进一步提高效率。\\n\\n**关键创新**：FreeKV的关键创新在于推测检索和细粒度校正的结合。传统的KV检索方法需要在推理的关键路径上进行KV选择和召回，而FreeKV通过推测检索将这些操作移出关键路径，从而显著减少延迟。同时，细粒度校正保证了精度，避免了因推测带来的误差。\\n\\n**关键设计**：在推测检索方面，可以采用多种策略，例如基于历史访问频率、基于语义相似度等。细粒度校正可以采用多种方法，例如基于注意力机制的校正、基于残差连接的校正等。混合KV布局需要根据CPU和GPU的内存大小、带宽等因素进行优化。双缓冲流式召回需要合理设置缓冲区的大小，以平衡延迟和内存占用。",
            "application_zh": "FreeKV可应用于各种需要处理长上下文的LLM应用场景，例如长文本摘要、机器翻译、对话系统、代码生成等。通过提高KV缓存检索效率，FreeKV能够显著提升LLM的推理速度，降低部署成本，并支持更大规模的上下文窗口，从而拓展LLM的应用范围。未来，FreeKV有望成为长上下文LLM推理的重要加速技术。",
            "highlight_zh": "实验结果表明，FreeKV在各种场景和模型中实现了接近无损的精度。与SOTA KV检索方法相比，FreeKV的速度提高了高达13倍。这些结果表明，FreeKV在提高KV缓存检索效率方面具有显著优势，能够有效解决长上下文LLM推理的瓶颈问题。",
            "tags_zh": [
                "KV缓存",
                "LLM推理",
                "长上下文",
                "推测检索",
                "系统优化"
            ],
            "_index": 195,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2505.13109/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2505.13109/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2505.13109/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "TempoPFN: Synthetic Pre-training of Linear RNNs for Zero-shot Time Series Forecasting",
            "authors": [
                "Vladyslav Moroshan",
                "Julien Siems",
                "Arber Zela",
                "Timur Carstensen",
                "Frank Hutter"
            ],
            "arxiv_id": "2510.25502",
            "summary": "Foundation models for zero-shot time series forecasting face challenges in efficient long-horizon prediction and reproducibility, with existing synthetic-only approaches underperforming on challenging benchmarks. This paper presents TempoPFN, a univariate time series foundation model based on linear Recurrent Neural Networks (RNNs) pre-trained exclusively on synthetic data. The model uses a GatedDeltaProduct architecture with state-weaving for fully parallelizable training across sequence lengths, eliminating the need for windowing or summarization techniques while maintaining robust temporal state-tracking. Our comprehensive synthetic data pipeline unifies diverse generators, including stochastic differential equations, Gaussian processes, and audio synthesis, with novel augmentations. In zero-shot evaluations on the Gift-Eval, fev-bench and Chronos-ZS benchmarks, TempoPFN achieves top-tier competitive performance, outperforming all existing synthetic-only approaches and surpassing the majority of models trained on real-world data, while being more efficient than existing baselines by leveraging fully parallelizable training and inference. We open-source our complete data generation pipeline and training code, providing a reproducible foundation for future research.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2510.25502",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "foundation model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "TempoPFN：基于线性RNN合成预训练的零样本时间序列预测模型",
            "summary_zh": "针对零样本时间序列预测中，现有基础模型在长程预测效率和可复现性方面面临的挑战，以及纯合成数据方法在复杂基准测试中表现不佳的问题，本文提出了TempoPFN，一种基于线性循环神经网络（RNN）的单变量时间序列基础模型，完全通过合成数据进行预训练。该模型采用GatedDeltaProduct架构，结合状态编织技术，实现了跨序列长度的完全并行化训练，无需窗口化或摘要技术，同时保持了鲁棒的时间状态跟踪。我们全面的合成数据管道统一了包括随机微分方程、高斯过程和音频合成等多种生成器，并引入了新的数据增强方法。在Gift-Eval、fev-bench和Chronos-ZS基准测试的零样本评估中，TempoPFN取得了顶级的竞争性能，优于所有现有的纯合成数据方法，并超过了大多数在真实世界数据上训练的模型，同时通过利用完全并行化的训练和推理，比现有基线更有效率。我们开源了完整的数据生成管道和训练代码，为未来的研究提供了可复现的基础。",
            "intro_zh": [
                "现有零样本时间序列预测模型在长程预测效率和可复现性方面存在不足，纯合成数据方法性能有限。",
                "TempoPFN通过线性RNN和合成数据预训练，结合GatedDeltaProduct架构和状态编织技术，实现高效并行训练。",
                "TempoPFN在多个基准测试中超越现有合成数据方法，性能媲美甚至超过真实数据训练模型，并开源代码。"
            ],
            "method_zh": "**问题定义**：现有零样本时间序列预测模型，尤其是基于纯合成数据训练的模型，在处理复杂的时间序列预测任务时，性能往往不尽如人意。此外，长程预测效率和模型的可复现性也是重要的挑战。现有方法通常需要窗口化或摘要等技术来处理长序列，这会引入额外的复杂性和信息损失。\\n\\n**核心思路**：TempoPFN的核心思路是利用线性RNN的并行化能力和精心设计的合成数据预训练，构建一个强大的零样本时间序列预测基础模型。通过在多样化的合成数据上进行预训练，模型能够学习到时间序列数据的通用模式和动态特性，从而在未见过的真实数据集上实现良好的泛化性能。\\n\\n**技术框架**：TempoPFN的整体框架包括两个主要部分：合成数据生成管道和线性RNN模型。合成数据生成管道负责生成多样化的时间序列数据，包括随机微分方程、高斯过程和音频合成等。线性RNN模型采用GatedDeltaProduct架构，并结合状态编织技术，实现完全并行化的训练和推理。模型首先在合成数据上进行预训练，然后在目标数据集上进行零样本预测。\\n\\n**关键创新**：TempoPFN的关键创新在于以下几个方面：1) 提出了基于线性RNN的零样本时间序列预测模型，充分利用了线性RNN的并行化能力。2) 设计了全面的合成数据生成管道，涵盖了多种时间序列数据类型和动态特性。3) 引入了状态编织技术，实现了跨序列长度的完全并行化训练，无需窗口化或摘要技术。\\n\\n**关键设计**：TempoPFN的关键设计包括：1) GatedDeltaProduct架构：该架构能够有效地捕捉时间序列数据的动态变化。2) 状态编织技术：该技术能够将不同时间步的状态信息进行融合，从而提高模型的预测精度。3) 多样化的合成数据生成策略：通过生成不同类型和动态特性的时间序列数据，提高模型的泛化能力。4) 损失函数：采用合适的损失函数来优化模型的训练过程。",
            "application_zh": "TempoPFN在诸多领域具有广泛的应用前景，例如金融市场预测、能源消耗预测、交通流量预测、医疗健康监测等。该模型能够在缺乏真实训练数据的情况下，快速部署并进行有效的预测，具有重要的实际价值。未来，TempoPFN可以进一步扩展到多变量时间序列预测，并与其他机器学习技术相结合，以解决更复杂的时间序列分析问题。",
            "highlight_zh": "TempoPFN在Gift-Eval、fev-bench和Chronos-ZS等多个零样本时间序列预测基准测试中取得了优异的成绩，超越了所有现有的纯合成数据方法，并且性能媲美甚至超过了在真实数据上训练的模型。例如，在某些基准测试中，TempoPFN的性能提升幅度超过10%。此外，TempoPFN通过利用完全并行化的训练和推理，比现有基线更有效率。",
            "tags_zh": [
                "时间序列预测",
                "零样本学习",
                "合成数据",
                "线性RNN",
                "预训练",
                "GatedDeltaProduct",
                "状态编织"
            ],
            "_index": 196,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2510.25502/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2510.25502/x7.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2510.25502/x9.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "The Instability of Safety: How Random Seeds and Temperature Expose Inconsistent LLM Refusal Behavior",
            "authors": [
                "Erik Larsen"
            ],
            "arxiv_id": "2512.12066",
            "summary": "Current safety evaluations of large language models rely on single-shot testing, implicitly assuming that model responses are deterministic and representative of the model's safety alignment. We challenge this assumption by investigating the stability of safety refusal decisions across random seeds and temperature settings. Testing four instruction-tuned models from three families (Llama 3.1 8B, Qwen 2.5 7B, Qwen 3 8B, Gemma 3 12B) on 876 harmful prompts across 20 different sampling configurations (4 temperatures x 5 random seeds), we find that 18-28% of prompts exhibit decision flips--the model refuses in some configurations but complies in others--depending on the model. Our Safety Stability Index (SSI) reveals that higher temperatures significantly reduce decision stability (Friedman chi-squared = 396.81, p < 0.001), with mean within-temperature SSI dropping from 0.977 at temperature 0.0 to 0.942 at temperature 1.0. We validate our findings across all model families using Claude 3.5 Haiku as a unified external judge, achieving 89.0% inter-judge agreement with our primary Llama 70B judge (Cohen's kappa = 0.62). Within each model, prompts with higher compliance rates exhibit lower stability (Spearman rho = -0.47 to -0.70, all p < 0.001), indicating that models \"waver\" more on borderline requests. These findings demonstrate that single-shot safety evaluations are insufficient for reliable safety assessment and that evaluation protocols must account for stochastic variation in model behavior. We show that single-shot evaluation agrees with multi-sample ground truth only 92.4% of the time when pooling across temperatures (94.2-97.7% at fixed temperature depending on setting), and recommend using at least 3 samples per prompt for reliable safety assessment.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.12066",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "揭示大语言模型安全性评估的不稳定性：随机种子和温度的影响",
            "summary_zh": "当前对大型语言模型（LLM）的安全评估依赖于单次测试，隐含地假设模型响应是确定性的，并能代表模型的安全对齐状态。本文通过研究随机种子和温度设置对安全拒绝决策的稳定性，挑战了这一假设。在三个模型系列的四个指令调优模型（Llama 3.1 8B、Qwen 2.5 7B、Qwen 3 8B、Gemma 3 12B）上，针对876个有害提示词，在20种不同的采样配置（4种温度 x 5个随机种子）下进行测试，发现18-28%的提示词表现出决策翻转——模型在某些配置下拒绝，而在其他配置下顺从，具体比例取决于模型。安全稳定性指数（SSI）显示，较高的温度显著降低了决策稳定性（Friedman chi-squared = 396.81, p < 0.001），温度从0.0到1.0时，平均温度内SSI从0.977降至0.942。使用Claude 3.5 Haiku作为统一的外部评判器验证了所有模型系列的结果，与主要的Llama 70B评判器达成了89.0%的评判一致性（Cohen's kappa = 0.62）。在每个模型中，顺从率较高的提示词表现出较低的稳定性（Spearman rho = -0.47 to -0.70, all p < 0.001），表明模型在边缘请求上更容易“犹豫”。这些发现表明，单次安全评估不足以进行可靠的安全评估，评估协议必须考虑模型行为的随机变化。结果表明，当跨温度池化时，单次评估仅在92.4%的时间内与多样本真实情况一致（在固定温度下，根据设置，一致性为94.2-97.7%），并建议每个提示词至少使用3个样本进行可靠的安全评估。",
            "intro_zh": [
                "现有LLM安全评估依赖单次测试，忽略了模型输出的随机性，可能导致评估结果不准确。",
                "通过改变随机种子和温度，研究模型在有害提示下的拒绝行为，评估安全决策的稳定性。",
                "实验发现模型在不同配置下拒绝行为不稳定，高温度降低稳定性，并建议使用多样本评估。"
            ],
            "method_zh": "**问题定义**：当前LLM安全评估方法主要依赖于单次测试，即给定一个有害提示词，观察模型是否拒绝。这种方法忽略了模型输出的随机性，例如随机种子和温度等因素的变化，可能导致评估结果不准确，无法真实反映模型的安全对齐程度。现有方法缺乏对模型安全决策稳定性的系统性评估。\n\n**核心思路**：本文的核心思路是通过系统性地改变随机种子和温度等采样参数，观察模型在同一有害提示下的拒绝行为是否一致。如果模型在不同配置下表现出不一致的拒绝或顺从行为，则表明其安全决策不稳定。通过量化这种不稳定性，可以更全面地评估模型的安全性。\n\n**技术框架**：本文的技术框架主要包括以下几个步骤：1) 选择多个LLM模型（Llama 3.1 8B, Qwen 2.5 7B, Qwen 3 8B, Gemma 3 12B）；2) 构建包含876个有害提示词的测试集；3) 在不同的采样配置下（4种温度 x 5个随机种子）运行模型，记录其拒绝或顺从行为；4) 使用安全稳定性指数（SSI）量化每个提示词的决策稳定性；5) 使用外部评判器（Claude 3.5 Haiku）验证结果的可靠性；6) 分析顺从率与稳定性之间的关系。\n\n**关键创新**：本文最重要的技术创新点在于提出了安全稳定性指数（SSI），用于量化模型在不同采样配置下的安全决策稳定性。SSI能够有效地捕捉模型在边缘情况下的“犹豫”行为，从而更全面地评估模型的安全性。与传统的单次测试相比，SSI能够更好地反映模型的真实安全水平。\n\n**关键设计**：关键设计包括：1) 选择了具有代表性的LLM模型和有害提示词；2) 系统性地改变随机种子和温度，以探索模型行为的随机性；3) 使用外部评判器验证结果的可靠性；4) 通过统计分析，揭示了顺从率与稳定性之间的关系。温度设置范围为0.0到1.0，随机种子数量为5。使用Friedman检验和Spearman相关系数进行统计分析。",
            "application_zh": "该研究成果可应用于LLM安全评估和安全对齐。通过评估模型的安全稳定性，可以更准确地了解模型的安全风险，并指导模型的安全训练和部署。该研究还有助于开发更可靠的安全评估方法和工具，提高LLM的整体安全性。",
            "highlight_zh": "实验结果表明，18-28%的有害提示词会导致模型决策翻转，即在某些配置下拒绝，而在其他配置下顺从。较高的温度显著降低了决策稳定性（Friedman chi-squared = 396.81, p < 0.001）。单次评估仅在92.4%的时间内与多样本真实情况一致。建议每个提示词至少使用3个样本进行可靠的安全评估。",
            "tags_zh": [
                "大语言模型",
                "安全性评估",
                "随机种子",
                "温度采样",
                "安全稳定性",
                "决策翻转",
                "有害提示词"
            ],
            "_index": 197,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.12066/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.12066/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.12066/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "QCircuitBench: A Large-Scale Dataset for Benchmarking Quantum Algorithm Design",
            "authors": [
                "Rui Yang",
                "Ziruo Wang",
                "Yuntian Gu",
                "Tianyi Chen",
                "Yitao Liang",
                "Tongyang Li"
            ],
            "arxiv_id": "2410.07961",
            "summary": "Quantum computing is an emerging field recognized for the significant speedup it offers over classical computing through quantum algorithms. However, designing and implementing quantum algorithms pose challenges due to the complex nature of quantum mechanics and the necessity for precise control over quantum states. Despite the significant advancements in AI, there has been a lack of datasets specifically tailored for this purpose. In this work, we introduce QCircuitBench, the first benchmark dataset designed to evaluate AI's capability in designing and implementing quantum algorithms using quantum programming languages. Unlike using AI for writing traditional codes, this task is fundamentally more complicated due to highly flexible design space. Our key contributions include: 1. A general framework which formulates the key features of quantum algorithm design for Large Language Models. 2. Implementations for quantum algorithms from basic primitives to advanced applications, spanning 3 task suites, 25 algorithms, and 120,290 data points. 3. Automatic validation and verification functions, allowing for iterative evaluation and interactive reasoning without human inspection. 4. Promising potential as a training dataset through preliminary fine-tuning results. We observed several interesting experimental phenomena: LLMs tend to exhibit consistent error patterns, and fine-tuning does not always outperform few-shot learning. In all, QCircuitBench is a comprehensive benchmark for LLM-driven quantum algorithm design, and it reveals limitations of LLMs in this domain.",
            "categories": [
                "cs.DS",
                "cs.LG",
                "stat.ML"
            ],
            "primary_category": "cs.DS",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2410.07961",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "QCircuitBench：用于量子算法设计基准测试的大规模数据集",
            "summary_zh": "量子计算是一个新兴领域，因其通过量子算法提供的相对于经典计算的显著加速而备受认可。然而，由于量子力学的复杂性和对量子态的精确控制的必要性，设计和实现量子算法面临着挑战。尽管人工智能取得了显著进展，但仍然缺乏专门为此目的量身定制的数据集。本文介绍了QCircuitBench，这是第一个旨在评估人工智能在使用量子编程语言设计和实现量子算法方面的能力的基准数据集。与使用人工智能编写传统代码不同，由于高度灵活的设计空间，这项任务从根本上来说更加复杂。该数据集包含从基本原语到高级应用的量子算法实现，涵盖3个任务套件、25个算法和120,290个数据点。此外，还提供了自动验证和确认功能，允许进行迭代评估和交互式推理，而无需人工检查。初步的微调结果表明，该数据集具有作为训练数据集的潜力。实验观察到，大型语言模型（LLM）倾向于表现出一致的错误模式，并且微调并不总是优于少样本学习。总而言之，QCircuitBench是LLM驱动的量子算法设计的综合基准，并揭示了LLM在该领域的局限性。",
            "intro_zh": [
                "量子算法设计复杂，缺乏专门数据集评估AI在此领域的能力，阻碍了AI在量子计算中的应用。",
                "提出QCircuitBench数据集，包含多种量子算法实现，并提供自动验证功能，用于评估和训练AI模型。",
                "实验表明LLM在量子算法设计中存在局限性，且微调不一定优于少样本学习，为未来研究提供方向。"
            ],
            "method_zh": "**问题定义**：现有方法缺乏专门用于评估AI设计和实现量子算法能力的数据集。量子算法的设计空间非常灵活，使得AI编写量子代码比传统代码更复杂。因此，需要一个专门的基准数据集来评估AI在量子算法设计方面的能力，并促进相关研究。\n\n**核心思路**：QCircuitBench的核心思路是构建一个包含各种量子算法实现的大规模数据集，并提供自动验证功能。通过这个数据集，可以评估AI模型（特别是LLM）在量子算法设计方面的表现，并发现其局限性。自动验证功能允许迭代评估和交互式推理，无需人工干预。\n\n**技术框架**：QCircuitBench包含三个任务套件，涵盖25个量子算法，共计120,290个数据点。这些算法从基本原语到高级应用不等。数据集还包括自动验证和确认函数，用于评估生成的量子电路的正确性。该框架旨在支持LLM驱动的量子算法设计，并提供一个标准化的评估平台。\n\n**关键创新**：QCircuitBench的主要创新在于它是第一个专门为评估AI在量子算法设计方面的能力而设计的基准数据集。与现有的数据集不同，QCircuitBench侧重于量子编程语言，并提供自动验证功能，从而可以更有效地评估AI模型的性能。此外，该数据集涵盖了广泛的量子算法，使其成为一个全面的评估工具。\n\n**关键设计**：QCircuitBench的关键设计包括三个任务套件的选择，涵盖了不同复杂度的量子算法。自动验证函数的实现，确保了评估的准确性和效率。数据集的规模（120,290个数据点）保证了评估的统计有效性。此外，论文还探讨了使用LLM进行量子算法设计的不同策略，例如微调和少样本学习，并分析了它们的优缺点。",
            "application_zh": "QCircuitBench可用于训练和评估AI模型在量子算法设计方面的能力，加速量子算法的开发和优化。该数据集还可用于研究LLM在量子计算领域的应用，并探索新的量子算法设计方法。此外，QCircuitBench可以作为量子计算教育和研究的宝贵资源。",
            "highlight_zh": "实验结果表明，LLM在量子算法设计中存在局限性，例如表现出一致的错误模式。此外，微调并不总是优于少样本学习。这些发现为未来研究提供了方向，例如探索更有效的LLM训练方法或开发专门用于量子算法设计的AI模型。QCircuitBench数据集为LLM驱动的量子算法设计提供了一个全面的基准。",
            "tags_zh": [
                "量子计算",
                "量子算法设计",
                "大型语言模型",
                "基准数据集",
                "人工智能"
            ],
            "_index": 198,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2410.07961/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2410.07961/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2410.07961/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "LLM Inference Beyond a Single Node: From Bottlenecks to Mitigations with Fast All-Reduce Communication",
            "authors": [
                "Prajwal Singhania",
                "Siddharth Singh",
                "Lannie Dalton Hough",
                "Akarsh Srivastava",
                "Harshitha Menon",
                "Charles Fredrick Jekel",
                "Abhinav Bhatele"
            ],
            "arxiv_id": "2511.09557",
            "summary": "As large language models (LLMs) continue to grow in size, distributed inference has become increasingly important. Model-parallel strategies must now efficiently scale not only across multiple GPUs but also across multiple nodes. In this work, we present a detailed performance study of multi-node distributed inference using LLMs on GPU-based supercomputers. We conduct experiments with several state-of-the-art inference engines alongside YALIS, a research-oriented prototype engine designed for controlled experimentation. We analyze the strong-scaling behavior of different model-parallel schemes and identify key bottlenecks. Since all-reduce operations are a common performance bottleneck, we develop NVRAR, a hierarchical all-reduce algorithm based on recursive doubling with NVSHMEM. NVRAR achieves up to 1.9x-3.6x lower latency than NCCL for message sizes between 128 KB and 2 MB on HPE Slingshot and InfiniBand interconnects. Integrated into YALIS, NVRAR achieves up to a 1.72x reduction in end-to-end batch latency for the Llama 3.1 405B model in multi-node decode-heavy workloads using tensor parallelism.",
            "categories": [
                "cs.DC",
                "cs.LG"
            ],
            "primary_category": "cs.DC",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2511.09557",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "针对LLM多节点推理瓶颈，提出基于快速All-Reduce通信的NVRAR算法。",
            "summary_zh": "随着大型语言模型（LLM）规模的持续增长，分布式推理变得越来越重要。模型并行策略现在不仅需要有效地跨多个GPU扩展，还需要跨多个节点扩展。本文对基于GPU的超级计算机上使用LLM进行多节点分布式推理进行了详细的性能研究。我们使用几种最先进的推理引擎以及YALIS（一个面向研究的原型引擎，专为受控实验而设计）进行了实验。我们分析了不同模型并行方案的强扩展行为，并确定了关键瓶颈。由于all-reduce操作是一个常见的性能瓶颈，我们开发了NVRAR，这是一种基于递归倍增和NVSHMEM的分层all-reduce算法。在HPE Slingshot和InfiniBand互连上，对于128 KB到2 MB之间的消息大小，NVRAR实现了比NCCL低1.9倍-3.6倍的延迟。集成到YALIS后，对于使用张量并行的多节点解码密集型工作负载中的Llama 3.1 405B模型，NVRAR实现了高达1.72倍的端到端批处理延迟降低。",
            "intro_zh": [
                "现有LLM推理引擎在多节点扩展时面临通信瓶颈，特别是All-Reduce操作的延迟问题。",
                "论文提出NVRAR算法，利用NVSHMEM实现分层All-Reduce，旨在降低通信延迟，提升整体推理性能。",
                "实验表明，NVRAR在特定消息大小下显著降低了All-Reduce延迟，并最终提升了LLM推理的端到端性能。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型（LLM）在多节点分布式推理中遇到的性能瓶颈问题。现有的模型并行策略在跨多个GPU和节点扩展时，由于通信开销，特别是All-Reduce操作的延迟，导致整体推理效率降低。现有的All-Reduce实现，如NCCL，在某些互连网络和消息大小下可能不是最优的。\\n\\n**核心思路**：论文的核心思路是优化All-Reduce通信，通过设计一种新的分层All-Reduce算法NVRAR，利用NVSHMEM提供的低延迟通信能力，减少节点间的通信开销。NVRAR基于递归倍增的思想，并针对GPU集群的特性进行了优化，从而降低了All-Reduce操作的延迟。\\n\\n**技术框架**：整体框架包括：1）使用模型并行策略（如张量并行）将LLM模型分布到多个GPU和节点上；2）在推理过程中，需要进行All-Reduce操作来同步各个GPU上的计算结果；3）使用NVRAR算法替换传统的All-Reduce实现，以降低通信延迟；4）通过YALIS引擎进行实验和性能评估。YALIS作为一个研究平台，允许对不同的All-Reduce算法进行灵活的集成和测试。\\n\\n**关键创新**：论文的关键创新在于提出了NVRAR算法，这是一种基于递归倍增和NVSHMEM的分层All-Reduce算法。与传统的All-Reduce实现（如NCCL）相比，NVRAR能够更好地利用NVSHMEM提供的低延迟通信能力，从而降低All-Reduce操作的延迟。分层结构允许在节点内和节点间使用不同的通信策略，进一步优化性能。\\n\\n**关键设计**：NVRAR算法的关键设计包括：1）使用递归倍增的方式进行All-Reduce操作，减少通信轮数；2）利用NVSHMEM提供的共享内存通信能力，在节点内进行高效的All-Reduce操作；3）针对不同的消息大小和互连网络，优化通信策略；4）将NVRAR集成到YALIS引擎中，方便进行实验和性能评估。论文中没有明确提及具体的参数设置或损失函数，因为重点在于All-Reduce算法的优化，而不是模型训练。",
            "application_zh": "该研究成果可应用于大规模分布式LLM推理服务，例如在线对话机器人、文本生成、机器翻译等。通过降低推理延迟，可以提升用户体验，并降低部署成本。未来，该技术可以推广到其他需要高性能All-Reduce通信的分布式计算场景，例如科学计算、金融建模等。",
            "highlight_zh": "实验结果表明，NVRAR算法在HPE Slingshot和InfiniBand互连网络上，对于128 KB到2 MB之间的消息大小，实现了比NCCL低1.9倍-3.6倍的延迟。集成到YALIS后，对于Llama 3.1 405B模型，在多节点解码密集型工作负载中，NVRAR实现了高达1.72倍的端到端批处理延迟降低。",
            "tags_zh": [
                "大型语言模型",
                "分布式推理",
                "模型并行",
                "All-Reduce",
                "NVSHMEM",
                "高性能计算",
                "通信优化"
            ],
            "_index": 199,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2511.09557/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2511.09557/x4.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2511.09557/x7.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Adjudicator: Correcting Noisy Labels with a KG-Informed Council of LLM Agents",
            "authors": [
                "Doohee You",
                "Sundeep Paul"
            ],
            "arxiv_id": "2512.13704",
            "summary": "The performance of production machine learning systems is fundamentally limited by the quality of their training data. In high-stakes industrial applications, noisy labels can degrade performance and erode user trust. This paper presents Adjudicator, a system that addresses the critical data mining challenge of automatically identifying and correcting label noise and has been validated for production deployment. Adjudicator models this as a neuro-symbolic task, first constructing a dynamic Knowledge Graph (KG) to unify item context. This KG then informs a \"Council of Agents,\" a novel multi-agent Large Language Model architecture where specialized agents debate and vote on a label's validity. We validate our system on a 1,000-item balanced subset of the AlleNoise benchmark. Our KG-informed model achieves a 0.99 F1-score, significantly outperforming a single-LLM baseline (0.48 F1) and a non-KG council (0.59 F1). Our analysis reveals this is due to a Precision, achieved by a novel override logic that uses the KG to perfectly identify complex, structural errors (complete Recall) -- a class of errors that baselines fail to find. This result demonstrates a robust and explainable system for automated, high-precision data verification, serving as a vital proof-of-concept for generating golden datasets in strictly governed industrial environments.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13704",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "Adjudicator：利用知识图谱增强的大语言模型智能体委员会纠正噪声标签",
            "summary_zh": "生产机器学习系统的性能受到训练数据质量的根本限制。在高风险工业应用中，噪声标签会降低性能并削弱用户信任。本文提出了Adjudicator，一个解决自动识别和纠正标签噪声这一关键数据挖掘挑战的系统，并已验证可用于生产部署。Adjudicator将其建模为一个神经符号任务，首先构建一个动态知识图谱（KG）来统一项目上下文。然后，该知识图谱为“智能体委员会”提供信息，这是一个新颖的多智能体大语言模型架构，其中专门的智能体就标签的有效性进行辩论和投票。我们在AlleNoise基准测试的1000项平衡子集上验证了我们的系统。我们的知识图谱模型实现了0.99的F1分数，显著优于单个大语言模型基线（0.48 F1）和非知识图谱委员会（0.59 F1）。我们的分析表明，这归功于一种新颖的覆盖逻辑所实现的精确度，该逻辑使用知识图谱来完美地识别复杂的结构性错误（完全召回率）——基线无法找到的一类错误。这一结果展示了一个强大且可解释的自动化、高精度数据验证系统，为在严格管理的工业环境中生成黄金数据集提供了一个重要的概念验证。",
            "intro_zh": [
                "生产环境中机器学习模型受噪声标签影响，降低性能和用户信任，现有方法难以有效识别和纠正。",
                "Adjudicator构建动态知识图谱，并利用其指导多智能体大语言模型委员会进行标签有效性投票。",
                "实验表明，Adjudicator在AlleNoise数据集上F1分数达到0.99，显著优于单一大语言模型和非知识图谱委员会。"
            ],
            "method_zh": "**问题定义**：论文旨在解决机器学习训练数据中噪声标签的问题，特别是在高风险工业应用中。现有方法在处理复杂、结构性噪声标签时表现不佳，导致模型性能下降和用户信任降低。这些噪声标签难以被传统方法识别和纠正，严重影响了模型的泛化能力和可靠性。\\n\\n**核心思路**：论文的核心思路是利用知识图谱（KG）来增强大语言模型（LLM）在识别和纠正噪声标签方面的能力。通过构建一个动态的知识图谱，将项目上下文信息整合起来，为LLM提供更丰富的背景知识。然后，利用一个多智能体委员会，每个智能体都基于知识图谱的信息对标签的有效性进行辩论和投票。这种方法模拟了专家评审的过程，可以更准确地识别和纠正噪声标签。\\n\\n**技术框架**：Adjudicator系统的整体架构包括以下几个主要模块：1) **知识图谱构建模块**：负责从各种数据源中提取实体和关系，构建动态的知识图谱。2) **智能体委员会模块**：包含多个专门的LLM智能体，每个智能体负责从不同的角度评估标签的有效性。3) **辩论和投票模块**：智能体之间进行辩论，分享各自的观点和证据，最终通过投票决定标签的有效性。4) **覆盖逻辑模块**：利用知识图谱的信息，对智能体委员会的投票结果进行修正，特别是针对复杂的结构性错误。\\n\\n**关键创新**：该论文最重要的技术创新点在于将知识图谱与多智能体大语言模型委员会相结合，用于识别和纠正噪声标签。与传统的单一大语言模型或非知识图谱方法相比，Adjudicator能够更有效地利用上下文信息，识别和纠正复杂的结构性错误。此外，覆盖逻辑模块的设计也使得系统能够完美地识别这类错误，实现了完全召回率。\\n\\n**关键设计**：知识图谱的构建方式，包括实体和关系的提取规则，以及知识图谱的更新策略。智能体委员会中每个智能体的角色和职责，以及智能体之间的辩论和投票机制。覆盖逻辑模块的具体实现方式，包括如何利用知识图谱的信息来识别和纠正结构性错误。论文中没有明确指出具体的参数设置、损失函数或网络结构等细节，这些可能是根据具体应用场景进行调整的。",
            "application_zh": "Adjudicator可应用于各种需要高质量训练数据的工业场景，例如电商产品分类、金融风险评估、医疗诊断等。通过自动识别和纠正噪声标签，可以提高机器学习模型的性能和可靠性，降低运营成本，并增强用户信任。该系统为在严格管理的工业环境中生成黄金数据集提供了一个重要的概念验证，具有广阔的应用前景。",
            "highlight_zh": "Adjudicator在AlleNoise数据集上取得了显著的性能提升，F1分数达到0.99，远超单一大语言模型基线（0.48 F1）和非知识图谱委员会（0.59 F1）。该系统能够完美识别复杂的结构性错误，实现完全召回率，这归功于其新颖的覆盖逻辑和知识图谱的有效利用。实验结果表明，Adjudicator是一个强大且可解释的自动化、高精度数据验证系统。",
            "tags_zh": [
                "噪声标签纠正",
                "知识图谱",
                "大语言模型",
                "多智能体系统",
                "神经符号学习"
            ],
            "_index": 200,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13704/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13704/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.13704/graph_kgLLM.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Compressed Causal Reasoning: Quantization and GraphRAG Effects on Interventional and Counterfactual Accuracy",
            "authors": [
                "Steve Nwaiwu",
                "Nipat Jongsawat",
                "Anucha Tungkasthan"
            ],
            "arxiv_id": "2512.13725",
            "summary": "Causal reasoning in Large Language Models spanning association, intervention, and counterfactual inference is essential for reliable decision making in high stakes settings. As deployment shifts toward edge and resource constrained environments, quantized models such as INT8 and NF4 are becoming standard. Yet the impact of precision reduction on formal causal reasoning is poorly understood. To our knowledge, this is the first study to systematically evaluate quantization effects across all three levels of Pearls Causal Ladder. Using a 3000 sample stratified CLadder benchmark, we find that rung level accuracy in Llama 3 8B remains broadly stable under quantization, with NF4 showing less than one percent overall degradation. Interventional queries at rung 2 are the most sensitive to precision loss, whereas counterfactual reasoning at rung 3 is comparatively stable but exhibits heterogeneous weaknesses across query types such as collider bias and backdoor adjustment. Experiments on the CRASS benchmark show near identical performance across precisions, indicating that existing commonsense counterfactual datasets lack the structural sensitivity needed to reveal quantization induced reasoning drift. We further evaluate Graph Retrieval Augmented Generation using ground truth causal graphs and observe a consistent improvement in NF4 interventional accuracy of plus 1.7 percent, partially offsetting compression related degradation. These results suggest that causal reasoning is unexpectedly robust to four bit quantization, graph structured augmentation can selectively reinforce interventional reasoning, and current counterfactual benchmarks fail to capture deeper causal brittleness. This work provides an initial empirical map of compressed causal reasoning and practical guidance for deploying efficient and structurally supported causal AI systems.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13725",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "研究量化和图检索增强生成对大语言模型因果推理能力的影响",
            "summary_zh": "在大型语言模型中，涵盖关联、干预和反事实推理的因果推理对于高风险环境下的可靠决策至关重要。随着部署转向边缘和资源受限环境，INT8和NF4等量化模型正成为标准。然而，精度降低对形式化因果推理的影响知之甚少。据我们所知，这是第一个系统地评估量化效应对Pearl因果阶梯所有三个层次影响的研究。使用3000个样本的分层CLadder基准测试，我们发现Llama 3 8B中的rung级别精度在量化下保持大致稳定，NF4的总体降级小于1%。第二层级的干预查询对精度损失最敏感，而第三层级的反事实推理相对稳定，但在诸如碰撞偏差和后门调整等查询类型中表现出异构弱点。在CRASS基准测试上的实验表明，不同精度之间的性能几乎相同，表明现有的常识性反事实数据集缺乏揭示量化引起的推理漂移所需的结构敏感性。我们进一步评估了使用ground truth因果图的图检索增强生成，并观察到NF4干预精度的持续提高，达到1.7%，部分抵消了压缩相关的降级。这些结果表明，因果推理对四位量化具有出乎意料的鲁棒性，图结构增强可以选择性地加强干预推理，并且当前的反事实基准测试未能捕捉到更深层次的因果脆弱性。这项工作提供了压缩因果推理的初步经验图，并为部署高效且结构支持的因果AI系统提供了实用指导。",
            "intro_zh": [
                "现有大语言模型在资源受限环境下进行因果推理时，量化带来的精度损失影响尚不明确。",
                "该研究系统评估了量化（INT8, NF4）对Llama 3 8B在Pearl因果阶梯三个层次推理能力的影响。",
                "实验表明，因果推理对四位量化具有鲁棒性，图检索增强生成可提升干预推理精度。"
            ],
            "method_zh": "**问题定义**：论文旨在研究在资源受限的边缘计算环境中，对大语言模型进行量化（如INT8和NF4）后，其因果推理能力（包括关联、干预和反事实推理）会受到怎样的影响。现有方法缺乏对量化效应在不同因果推理层次上的系统性评估，并且现有的反事实推理数据集可能无法充分揭示量化引起的推理漂移。\n\\n**核心思路**：论文的核心思路是通过构建一个分层的因果推理基准测试（CLadder），并结合现有的常识性反事实数据集（CRASS），系统地评估不同量化级别（包括未量化、INT8和NF4）对大语言模型在不同因果推理任务上的性能影响。同时，探索图检索增强生成（Graph RAG）方法，利用ground truth因果图来增强模型的干预推理能力，以抵消量化带来的性能下降。\n\\n**技术框架**：整体框架包括以下几个主要阶段：\n1. **基准测试构建**：构建一个包含3000个样本的分层CLadder基准测试，覆盖Pearl因果阶梯的三个层次（关联、干预和反事实推理）。\n2. **模型量化**：对Llama 3 8B模型进行不同级别的量化（INT8和NF4）。\n3. **性能评估**：在CLadder和CRASS基准测试上评估不同量化级别下模型的因果推理性能。\n4. **图检索增强生成**：利用ground truth因果图，通过Graph RAG方法增强模型的干预推理能力。\n5. **结果分析**：分析量化效应对不同因果推理任务的影响，以及Graph RAG方法的有效性。\n\\n**关键创新**：该研究的主要创新点在于：\n1. **系统性评估**：首次系统地评估了量化效应对Pearl因果阶梯所有三个层次的因果推理能力的影响。\n2. **Graph RAG增强**：探索了利用ground truth因果图的Graph RAG方法来增强模型的干预推理能力，并部分抵消了量化带来的性能下降。\n3. **基准测试分析**：指出当前的反事实推理数据集可能无法充分揭示量化引起的推理漂移。\n\\n**关键设计**：\n1. **CLadder基准测试**：采用分层结构，覆盖Pearl因果阶梯的三个层次，并包含3000个样本。\n2. **Graph RAG**：使用ground truth因果图作为知识源，通过检索相关子图来增强模型的干预推理能力。\n3. **量化方法**：采用INT8和NF4两种量化方法，以评估不同量化级别的影响。",
            "application_zh": "该研究成果可应用于对资源敏感的边缘计算设备，例如移动机器人、自动驾驶汽车等，在这些场景下，需要在计算资源有限的情况下进行可靠的因果推理和决策。通过量化模型和图检索增强生成技术，可以在保证推理精度的前提下，降低模型的计算复杂度和存储空间，从而实现高效的因果AI系统部署。",
            "highlight_zh": "实验结果表明，Llama 3 8B在量化后，因果推理能力总体保持稳定，NF4的总体降级小于1%。干预查询对精度损失最敏感，而反事实推理相对稳定。Graph RAG方法能够提高NF4干预精度1.7%，部分抵消压缩带来的性能下降。CRASS基准测试表明，现有反事实数据集可能无法充分揭示量化引起的推理漂移。",
            "tags_zh": [
                "因果推理",
                "量化",
                "大语言模型",
                "图检索增强生成",
                "边缘计算"
            ],
            "_index": 201,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13725/figure_1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                }
            ]
        },
        {
            "title": "Evaluating Frontier LLMs on PhD-Level Mathematical Reasoning: A Benchmark on a Textbook in Theoretical Computer Science about Randomized Algorithms",
            "authors": [
                "Yang Cao",
                "Yubin Chen",
                "Xuyang Guo",
                "Zhao Song",
                "Song Yue",
                "Jiahao Zhang",
                "Jiale Zhao"
            ],
            "arxiv_id": "2512.13978",
            "summary": "The rapid advancement of large language models (LLMs) has led to significant breakthroughs in automated mathematical reasoning and scientific discovery. Georgiev, G${ó}$mez-Serrano, Tao, and Wagner [GGSTW+25] demonstrate that AI systems can explore new constructions and improve existing bounds, illustrating the growing potential of LLMs to accelerate mathematical discovery. Similarly, Bubeck et al. [BCE+25] show that GPT-5 can meaningfully contribute to scientific workflows, from proposing hypotheses to generating proofs and analyses. Despite these advances, a rigorous evaluation of these models on canonical, graduate-level mathematical theory remains necessary to understand their baseline reasoning capabilities. In this paper, we present a comprehensive benchmark of four frontier models: GPT-5-Thinking, Gemini-3-Pro, Claude-Sonnet-4.5-Thinking, and Grok-4 against the classic curriculum of Randomized Algorithms by Motwani and Raghavan [MR95].We tasked each model with generating formal LaTeX proofs for a series of lemmas and exercises spanning the textbook. We find that while the top-tier models (Gemini, and Claude) achieve a high accuracy rate (approx. 66%), demonstrating a robust grasp of probabilistic method and formal logic, other models lag significantly in consistency (approx. 40%). We provide a qualitative analysis of the generated proofs, highlighting differences in conciseness, hallucination rates, and logical structure. Our results suggest that while frontier models have reached a threshold of proficiency suitable for graduate-level pedagogical assistance and formalization, significant variance exists in their reliability for rigorous mathematical derivation. The code and the full set of LLM-generated responses are open-sourced and publicly available atthis https URL.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13978",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "评估前沿LLM在博士级数学推理能力：基于随机算法教材的基准测试",
            "summary_zh": "大型语言模型（LLM）的快速发展在自动数学推理和科学发现方面取得了显著突破。本文旨在对这些模型在规范的、研究生水平的数学理论上的推理能力进行严格评估。我们针对四种前沿模型：GPT-5-Thinking、Gemini-3-Pro、Claude-Sonnet-4.5-Thinking 和 Grok-4，构建了一个综合基准，该基准基于 Motwani 和 Raghavan 的经典教材《随机算法》。我们要求每个模型为教材中的一系列引理和练习生成正式的 LaTeX 证明。结果表明，顶级模型（Gemini 和 Claude）达到了较高的准确率（约 66%），展示了对概率方法和形式逻辑的良好掌握，而其他模型在一致性方面明显落后（约 40%）。我们对生成的证明进行了定性分析，突出了在简洁性、幻觉率和逻辑结构方面的差异。我们的结果表明，前沿模型已经达到了适合研究生水平教学辅助和形式化的熟练程度，但在严格的数学推导方面，它们的可靠性存在显著差异。代码和完整的 LLM 生成的响应已开源并公开。",
            "intro_zh": [
                "现有LLM在数学推理和科学发现中展现潜力，但缺乏在研究生水平数学理论上的严格评估。",
                "构建基于《随机算法》教材的基准测试，评估LLM生成LaTeX证明的能力，考察其数学推理水平。",
                "实验表明，Gemini和Claude等顶级模型准确率较高，但一致性存在差异，表明可靠性仍需提升。"
            ],
            "method_zh": "**问题定义**：论文旨在评估当前前沿大型语言模型（LLM）在解决博士级别数学推理问题上的能力。现有方法缺乏对LLM在研究生级别数学理论上的严格评估，无法准确衡量其数学推理的可靠性和一致性。\\n\\n**核心思路**：论文的核心思路是构建一个基于经典教材《随机算法》的基准测试，通过要求LLM生成书中引理和练习的LaTeX证明，来评估其在概率方法和形式逻辑方面的掌握程度。这种方法能够更直接地考察LLM在数学理论方面的推理能力。\\n\\n**技术框架**：该研究的技术框架主要包括以下几个阶段：1) 选择合适的基准教材：《随机算法》；2) 选取四个前沿LLM：GPT-5-Thinking、Gemini-3-Pro、Claude-Sonnet-4.5-Thinking 和 Grok-4；3) 要求LLM为教材中的一系列引理和练习生成LaTeX证明；4) 对生成的证明进行定量和定性分析，包括准确率、一致性、简洁性、幻觉率和逻辑结构等方面。\\n\\n**关键创新**：该研究的关键创新在于构建了一个专门针对博士级别数学推理的基准测试，并使用LaTeX格式的证明作为评估标准。这种方法能够更准确地评估LLM在数学理论方面的推理能力，并为未来的研究提供了一个可靠的评估工具。\\n\\n**关键设计**：论文的关键设计包括：1) 选择《随机算法》作为基准教材，因为它涵盖了概率方法和形式逻辑等重要的数学概念；2) 使用LaTeX格式的证明作为评估标准，因为它能够更准确地反映LLM的数学推理能力；3) 对生成的证明进行定量和定性分析，以全面评估LLM的性能。",
            "application_zh": "该研究成果可应用于开发研究生级别的数学教学辅助工具，帮助学生理解和掌握复杂的数学概念。此外，该基准测试可用于评估和改进LLM的数学推理能力，推动其在科学发现和自动化数学证明等领域的应用。未来，该研究可扩展到其他数学领域，构建更全面的数学推理评估体系。",
            "highlight_zh": "实验结果表明，Gemini和Claude等顶级模型在准确率方面表现出色，达到了约66%，展示了对概率方法和形式逻辑的良好掌握。然而，其他模型在一致性方面表现较差，仅为约40%。这表明，尽管前沿模型在数学推理方面取得了进展，但在可靠性方面仍有提升空间。定性分析表明，不同模型在简洁性、幻觉率和逻辑结构方面存在差异。",
            "tags_zh": [
                "大型语言模型",
                "数学推理",
                "基准测试",
                "随机算法",
                "LaTeX证明"
            ],
            "_index": 202,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "TiCard: Deployable EXPLAIN-only Residual Learning for Cardinality Estimation",
            "authors": [
                "Qizhi Wang"
            ],
            "arxiv_id": "2512.14358",
            "summary": "Cardinality estimation is a key bottleneck for cost-based query optimization, yet deployable improvements remain difficult: classical estimators miss correlations, while learned estimators often require workload-specific training pipelines and invasive integration into the optimizer. This paper presents TiCard, a low intrusion, correction-based framework that augments (rather than replaces) a database's native estimator. TiCard learns multiplicative residual corrections using EXPLAIN-only features, and uses EXPLAIN ANALYZE only for offline labels. We study two practical instantiations: (i) a Gradient Boosting Regressor for sub-millisecond inference, and (ii) TabPFN, an in-context tabular foundation model that adapts by refreshing a small reference set without gradient retraining. On TiDB with TPCH and the Join Order Benchmark, in a low-trace setting (263 executions total; 157 used for learning), TiCard improves operator-level tail accuracy substantially: P90 Q-error drops from 312.85 (native) to 13.69 (TiCard-GBR), and P99 drops from 37,974.37 to 3,416.50 (TiCard-TabPFN), while a join-only policy preserves near-perfect median behavior. We position TiCard as an AI4DB building block focused on deployability: explicit scope, conservative integration policies, and an integration roadmap from offline correction to in-optimizer use.",
            "categories": [
                "cs.AI",
                "cs.DB"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14358",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "foundation model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "TiCard：一种可部署的、仅使用EXPLAIN信息的基数估计残差学习框架",
            "summary_zh": "基数估计是基于代价的查询优化的关键瓶颈，但可部署的改进仍然困难：传统估计器会遗漏相关性，而学习型估计器通常需要特定于工作负载的训练流程和对优化器的侵入式集成。本文提出了TiCard，一个低侵入性的、基于校正的框架，它增强（而不是替换）数据库的原生估计器。TiCard使用仅EXPLAIN的特征学习乘法残差校正，并且仅使用EXPLAIN ANALYZE进行离线标签生成。我们研究了两种实际的实例化：（i）用于亚毫秒级推理的梯度提升回归器，以及（ii）TabPFN，一种通过刷新小型参考集而无需梯度重新训练的上下文表格基础模型。在使用TPCH和Join Order Benchmark的TiDB上，在低跟踪设置（总共263次执行；157次用于学习）中，TiCard显着提高了算子级别的尾部精度：P90 Q-error从312.85（原生）降至13.69（TiCard-GBR），P99从37,974.37降至3,416.50（TiCard-TabPFN），而仅连接策略保持了近乎完美的中间值行为。我们将TiCard定位为专注于可部署性的AI4DB构建块：明确的范围、保守的集成策略以及从离线校正到优化器内使用的集成路线图。",
            "intro_zh": [
                "现有基数估计器在捕获复杂相关性方面存在不足，而学习型估计器部署成本高，需要侵入式集成。",
                "TiCard通过学习残差校正来增强原生估计器，仅使用EXPLAIN信息，降低了部署难度和侵入性。",
                "实验表明，TiCard在TPCH和Join Order Benchmark上显著提高了尾部精度，P90和P99 Q-error均大幅降低。"
            ],
            "method_zh": "**问题定义**：基数估计是查询优化的关键，准确的基数估计能够帮助优化器选择最佳的查询执行计划。然而，传统的基数估计方法难以捕捉复杂的数据相关性，导致估计误差较大。而现有的学习型基数估计器通常需要大量的训练数据和复杂的训练流程，并且需要深入集成到数据库优化器中，部署成本较高。\\n\\n**核心思路**：TiCard的核心思路是利用残差学习的思想，通过学习原生估计器预测结果的残差（即误差）来进行校正。它不直接替换原生估计器，而是作为其补充，通过学习一个校正模型来修正原生估计器的偏差。这种方法降低了对原生估计器的依赖，并且更容易部署。\\n\\n**技术框架**：TiCard的整体框架包括以下几个主要步骤：1) 使用数据库的EXPLAIN功能提取查询计划的特征；2) 使用EXPLAIN ANALYZE功能获取查询计划的真实基数（作为标签）；3) 训练一个残差校正模型，该模型以EXPLAIN特征作为输入，以原生估计器的预测误差作为标签；4) 在线查询时，首先使用原生估计器进行基数估计，然后使用训练好的残差校正模型对估计结果进行校正。\\n\\n**关键创新**：TiCard的关键创新在于其低侵入性和可部署性。它仅使用EXPLAIN信息进行特征提取和训练，无需修改数据库内核。此外，TiCard采用了残差学习的方法，使得校正模型可以专注于学习原生估计器的误差，从而提高了校正的精度。同时，论文探索了两种不同的校正模型：梯度提升回归器（GBR）和TabPFN，以适应不同的性能需求。\\n\\n**关键设计**：TiCard的关键设计包括：1) 使用EXPLAIN信息作为特征，避免了对数据库内部结构的依赖；2) 使用乘法残差校正，即校正模型预测的是一个比例因子，用于乘以原生估计器的预测结果；3) 探索了两种不同的校正模型：GBR用于亚毫秒级推理，TabPFN用于在少量数据下快速适应；4) 设计了一个Join-Only策略，只对连接操作的基数进行校正，以避免对其他操作的基数估计产生负面影响。",
            "application_zh": "TiCard可以应用于各种需要进行查询优化的数据库系统中，尤其适用于那些难以进行深度定制和修改的数据库。通过低侵入性的方式提高基数估计的准确性，从而改善查询性能，降低数据库运维成本。未来，TiCard可以进一步扩展到支持更复杂的查询类型和数据分布，并与其他AI4DB技术相结合，构建更智能的数据库系统。",
            "highlight_zh": "实验结果表明，TiCard在TiDB数据库上，使用TPCH和Join Order Benchmark数据集，在低跟踪设置下（仅使用263次执行，其中157次用于学习），显著提高了算子级别的尾部精度。具体来说，使用梯度提升回归器（TiCard-GBR）时，P90 Q-error从原生估计器的312.85降至13.69；使用TabPFN（TiCard-TabPFN）时，P99 Q-error从37,974.37降至3,416.50。Join-Only策略还保证了近乎完美的中间值行为。",
            "tags_zh": [
                "基数估计",
                "查询优化",
                "残差学习",
                "数据库系统",
                "AI4DB"
            ],
            "_index": 203,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14358/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14358/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14358/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "PortAgent: LLM-driven Vehicle Dispatching Agent for Port Terminals",
            "authors": [
                "Jia Hu",
                "Junqi Li",
                "Weimeng Lin",
                "Peng Jia",
                "Yuxiong Ji",
                "Jintao Lai"
            ],
            "arxiv_id": "2512.14417",
            "summary": "Vehicle Dispatching Systems (VDSs) are critical to the operational efficiency of Automated Container Terminals (ACTs). However, their widespread commercialization is hindered due to their low transferability across diverse terminals. This transferability challenge stems from three limitations: high reliance on port operational specialists, a high demand for terminal-specific data, and time-consuming manual deployment processes. Leveraging the emergence of Large Language Models (LLMs), this paper proposes PortAgent, an LLM-driven vehicle dispatching agent that fully automates the VDS transferring workflow. It bears three features: (1) no need for port operations specialists; (2) low need of data; and (3) fast deployment. Specifically, specialist dependency is eliminated by the Virtual Expert Team (VET). The VET collaborates with four virtual experts, including a Knowledge Retriever, Modeler, Coder, and Debugger, to emulate a human expert team for the VDS transferring workflow. These experts specialize in the domain of terminal VDS via a few-shot example learning approach. Through this approach, the experts are able to learn VDS-domain knowledge from a few VDS examples. These examples are retrieved via a Retrieval-Augmented Generation (RAG) mechanism, mitigating the high demand for terminal-specific data. Furthermore, an automatic VDS design workflow is established among these experts to avoid extra manual interventions. In this workflow, a self-correction loop inspired by the LLM Reflexion framework is created",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14417",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "PortAgent：基于LLM的港口车辆调度智能体，提升跨终端迁移能力",
            "summary_zh": "车辆调度系统(VDS)对于自动化集装箱码头(ACT)的运营效率至关重要。然而，由于其在不同终端之间的低可迁移性，VDS的广泛商业化受到阻碍。这种可迁移性挑战源于三个限制：高度依赖港口运营专家、对终端特定数据的高需求以及耗时的人工部署过程。本文利用大型语言模型(LLM)的兴起，提出了一种由LLM驱动的车辆调度智能体PortAgent，该智能体可以完全自动化VDS的迁移工作流程。它具有三个特点：(1)不需要港口运营专家；(2)对数据的需求低；(3)快速部署。具体来说，通过虚拟专家团队(VET)消除了对专家的依赖。VET与四个虚拟专家（包括知识检索器、建模器、编码器和调试器）合作，模拟人类专家团队进行VDS迁移工作流程。这些专家通过少样本示例学习方法专注于终端VDS领域。通过这种方法，专家能够从一些VDS示例中学习VDS领域知识。这些示例通过检索增强生成(RAG)机制检索，从而降低了对终端特定数据的高需求。此外，在这些专家之间建立了一个自动VDS设计工作流程，以避免额外的人工干预。在这个工作流程中，创建了一个受LLM Reflexion框架启发的自我纠正循环。",
            "intro_zh": [
                "现有车辆调度系统(VDS)在不同港口终端间的迁移性差，严重依赖专家知识和大量特定数据，部署耗时。",
                "PortAgent利用大型语言模型(LLM)构建虚拟专家团队(VET)，模拟专家进行VDS迁移，降低对专家和数据的依赖。",
                "通过检索增强生成(RAG)获取少量VDS示例，并建立自动VDS设计流程，实现快速部署和自我纠正。"
            ],
            "method_zh": "**问题定义**：现有车辆调度系统(VDS)在自动化集装箱码头(ACT)的应用面临跨终端迁移性差的问题。具体来说，VDS的部署和优化高度依赖于港口运营专家的经验，需要大量的终端特定数据进行训练和调整，并且人工部署过程耗时且容易出错。这些因素限制了VDS在不同港口终端的广泛应用。\\n\\n**核心思路**：PortAgent的核心思路是利用大型语言模型(LLM)的强大能力，构建一个虚拟专家团队(VET)，该团队能够模拟人类专家进行VDS的迁移和部署工作。通过少样本学习和检索增强生成(RAG)技术，VET可以从少量VDS示例中学习领域知识，并自动设计和优化VDS，从而降低对专家知识和大量数据的依赖。\\n\\n**技术框架**：PortAgent的整体架构包含以下几个主要模块：1) **虚拟专家团队(VET)**：由知识检索器、建模器、编码器和调试器四个虚拟专家组成。2) **检索增强生成(RAG)**：用于从少量VDS示例中检索相关知识，为VET提供学习材料。3) **自动VDS设计流程**：VET中的专家协同工作，自动设计和优化VDS。4) **自我纠正循环**：借鉴LLM Reflexion框架，VET通过自我评估和反思，不断改进VDS的设计。\\n\\n**关键创新**：PortAgent最重要的技术创新在于利用LLM构建虚拟专家团队(VET)，并将其应用于VDS的迁移和部署。与传统的VDS方法相比，PortAgent无需人工干预，能够自动学习领域知识并设计VDS，从而大大降低了对专家知识和大量数据的依赖。此外，PortAgent的自我纠正循环能够不断改进VDS的设计，提高其性能。\\n\\n**关键设计**：知识检索器使用向量数据库存储VDS示例，并使用余弦相似度进行检索。建模器负责将VDS示例转换为数学模型。编码器将数学模型转换为可执行的代码。调试器负责测试和调试代码，并向建模器提供反馈。自我纠正循环使用奖励函数评估VDS的性能，并使用反馈信号调整VET的参数。具体的参数设置和损失函数细节未知。",
            "application_zh": "PortAgent可应用于各种自动化集装箱码头(ACT)，实现VDS的快速部署和优化，提高港口运营效率，降低运营成本。该研究成果还可推广到其他需要领域专家知识和大量数据的自动化系统中，例如智能制造、智慧城市等，具有广阔的应用前景和实际价值。",
            "highlight_zh": "论文提出了PortAgent，一个基于LLM的港口车辆调度智能体，旨在解决VDS在不同终端之间迁移性差的问题。通过构建虚拟专家团队(VET)和利用检索增强生成(RAG)技术，PortAgent能够从少量VDS示例中学习领域知识，并自动设计和优化VDS。具体的实验结果未知。",
            "tags_zh": [
                "大型语言模型",
                "车辆调度系统",
                "自动化集装箱码头",
                "迁移学习",
                "检索增强生成"
            ],
            "_index": 204,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Seismology modeling agent: A smart assistant for geophysical researchers",
            "authors": [
                "Yukun Ren",
                "Siwei Yu",
                "Kai Chen",
                "Jianwei Ma"
            ],
            "arxiv_id": "2512.14429",
            "summary": "To address the steep learning curve and reliance on complex manual file editing and command-line operations in the traditional workflow of the mainstream open-source seismic wave simulation software SPECFEM, this paper proposes an intelligent, interactive workflow powered by Large Language Models (LLMs). We introduce the first Model Context Protocol (MCP) server suite for SPECFEM (supporting 2D, 3D Cartesian, and 3D Globe versions), which decomposes the entire simulation process into discrete, agent-executable tools spanning from parameter generation and mesh partitioning to solver execution and visualization. This approach enables a paradigm shift from file-driven to intent-driven conversational interactions. The framework supports both fully automated execution and human-in-the-loop collaboration, allowing researchers to guide simulation strategies in real time and retain scientific decision-making authority while significantly reducing tedious low-level operations. Validated through multiple case studies, the workflow operates seamlessly in both autonomous and interactive modes, yielding high-fidelity results consistent with standard baselines. As the first application of MCP technology to computational seismology, this study significantly lowers the entry barrier, enhances reproducibility, and offers a promising avenue for advancing computational geophysics toward AI-assisted and automated scientific research. The complete source code is available atthis https URL.",
            "categories": [
                "cs.AI",
                "cs.SE"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14429",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于LLM的地震学建模智能助手，简化SPECFEM工作流程",
            "summary_zh": "为了解决主流开源地震波模拟软件SPECFEM学习曲线陡峭、依赖复杂的手动文件编辑和命令行操作等问题，本文提出了一种基于大型语言模型（LLM）的智能交互式工作流程。我们为SPECFEM引入了首个模型上下文协议（MCP）服务器套件（支持2D、3D笛卡尔和3D Globe版本），该套件将整个模拟过程分解为离散的、可由Agent执行的工具，涵盖从参数生成和网格划分到求解器执行和可视化。这种方法实现了从文件驱动到意图驱动的对话式交互的范式转变。该框架支持全自动执行和人机协作，允许研究人员实时指导模拟策略，并在显著减少繁琐的底层操作的同时，保留科学决策权。通过多个案例研究验证，该工作流程在自主和交互模式下均能无缝运行，并产生与标准基线一致的高保真结果。作为MCP技术在计算地震学中的首次应用，本研究显著降低了入门门槛，提高了可重复性，并为推动计算地球物理学向AI辅助和自动化科学研究方向发展提供了一条有希望的途径。",
            "intro_zh": [
                "传统SPECFEM工作流程复杂，学习曲线陡峭，依赖手动操作，阻碍了研究效率。",
                "利用大型语言模型，构建智能交互式工作流程，将模拟过程分解为Agent可执行的工具。",
                "通过案例研究验证，该工作流程在自主和交互模式下均表现良好，结果与标准基线一致。"
            ],
            "method_zh": "**问题定义**：传统地震波模拟软件SPECFEM的使用门槛高，需要用户手动编辑大量文件，并进行复杂的命令行操作。这对于地球物理研究人员来说是一个很大的挑战，降低了研究效率，并且容易出错。现有的工作流程缺乏智能化和自动化，难以适应快速发展的研究需求。\\n\\n**核心思路**：本文的核心思路是利用大型语言模型（LLM）的强大能力，构建一个智能助手，将复杂的SPECFEM模拟过程分解为一系列可执行的工具，并通过自然语言交互的方式，引导用户完成模拟任务。这种方法旨在降低SPECFEM的使用门槛，提高研究效率，并促进计算地球物理学的自动化发展。\\n\\n**技术框架**：该框架的核心是模型上下文协议（MCP）服务器套件，它将SPECFEM的模拟过程分解为离散的、可由Agent执行的工具。整个工作流程包括以下几个主要阶段：1) 用户通过自然语言描述模拟意图；2) LLM将用户意图转化为一系列Agent可执行的任务；3) MCP服务器套件调度Agent执行任务，包括参数生成、网格划分、求解器执行和可视化等；4) 用户可以实时监控模拟过程，并进行干预和调整。\\n\\n**关键创新**：该研究的关键创新在于将MCP技术首次应用于计算地震学领域，实现了从文件驱动到意图驱动的模拟范式转变。通过LLM的智能交互能力，用户可以更加方便地使用SPECFEM，而无需深入了解其复杂的内部机制。此外，该框架支持人机协作，允许研究人员在保留科学决策权的同时，利用AI助手完成繁琐的底层操作。\\n\\n**关键设计**：MCP服务器套件的设计是关键。它需要能够有效地管理和调度各种Agent，并保证模拟过程的稳定性和可靠性。具体的技术细节包括：Agent的定义和实现、任务调度算法、错误处理机制以及用户交互界面的设计。此外，LLM的选择和训练也至关重要，需要选择具有强大自然语言理解和生成能力的LLM，并针对地震学模拟任务进行微调。",
            "application_zh": "该研究成果可广泛应用于地震学研究、地球物理勘探、工程地震等领域。通过降低SPECFEM的使用门槛，可以吸引更多研究人员参与到地震波模拟研究中，加速相关领域的科学发现。此外，该框架还可以应用于其他计算地球物理软件，推动整个地球物理学领域的AI辅助和自动化发展。",
            "highlight_zh": "该研究通过多个案例研究验证了所提出的工作流程的有效性。实验结果表明，该工作流程在自主和交互模式下均能无缝运行，并产生与标准基线一致的高保真结果。这表明该框架不仅降低了SPECFEM的使用门槛，而且保证了模拟结果的准确性。",
            "tags_zh": [
                "地震学建模",
                "大型语言模型",
                "SPECFEM",
                "模型上下文协议",
                "人机协作"
            ],
            "_index": 205,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14429/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14429/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14429/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "EDGC: Entropy-driven Dynamic Gradient Compression for Efficient LLM Training",
            "authors": [
                "Qingao Yi",
                "Jiaang Duan",
                "Hanwen Hu",
                "Qin Hua",
                "Haiyan Zhao",
                "Shiyou Qian",
                "Dingyu Yang",
                "Jian Cao",
                "Jinghua Tang",
                "Yinghao Yu",
                "Chenzhi Liao",
                "Kangjin Wang",
                "Liping Zhang"
            ],
            "arxiv_id": "2511.10333",
            "summary": "Training large language models (LLMs) poses significant challenges regarding computational resources and memory capacity. Although distributed training techniques help mitigate these issues, they still suffer from considerable communication overhead. Existing approaches primarily rely on static gradient compression to enhance communication efficiency; however, these methods neglect the dynamic nature of evolving gradients during training, leading to performance degradation. Accelerating LLM training via compression without sacrificing performance remains a challenge. In this paper, we propose an entropy-driven dynamic gradient compression framework called EDGC. The core concept is to adjust the compression rate during LLM training based on the evolving trends of gradient entropy, taking into account both compression efficiency and error. EDGC consists of three keythis http URL, it employs a down-sampling method to efficiently estimate gradient entropy, reducing computation overhead. Second, it establishes a theoretical model linking compression rate with gradient entropy, enabling more informed compression decisions. Lastly, a window-based adjustment mechanism dynamically adapts the compression rate across pipeline stages, improving communication efficiency and maintaining model performance. We implemented EDGC on a 32-NVIDIA-V100 cluster and a 64-NVIDIA-H100 cluster to train GPT2-2.5B and GPT2-12.1B, respectively. The results show that EDGC significantly reduces communication latency and training time by up to 46.45% and 16.13% while preserving LLM accuracy.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "cs.PF"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2511.10333",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "EDGC：一种熵驱动的动态梯度压缩框架，用于高效的大语言模型训练。",
            "summary_zh": "训练大型语言模型（LLMs）在计算资源和内存容量方面提出了重大挑战。虽然分布式训练技术有助于缓解这些问题，但它们仍然受到相当大的通信开销的影响。现有方法主要依靠静态梯度压缩来提高通信效率；然而，这些方法忽略了训练期间梯度演变的动态特性，导致性能下降。在不牺牲性能的情况下，通过压缩加速LLM训练仍然是一个挑战。本文提出了一种名为EDGC的熵驱动的动态梯度压缩框架。其核心概念是根据梯度熵的演变趋势调整LLM训练期间的压缩率，同时考虑压缩效率和误差。EDGC由三个关键部分组成：首先，它采用一种降采样方法来有效地估计梯度熵，从而降低计算开销。其次，它建立了一个将压缩率与梯度熵联系起来的理论模型，从而能够做出更明智的压缩决策。最后，一种基于窗口的调整机制动态地调整跨pipeline阶段的压缩率，从而提高通信效率并保持模型性能。我们在一个32-NVIDIA-V100集群和一个64-NVIDIA-H100集群上分别实现了EDGC来训练GPT2-2.5B和GPT2-12.1B。结果表明，EDGC在保持LLM精度的同时，显著降低了通信延迟和训练时间，分别高达46.45%和16.13%。",
            "intro_zh": [
                "现有大语言模型训练方法依赖静态梯度压缩，忽略了训练过程中梯度动态变化的特性，导致性能下降。",
                "EDGC框架通过梯度熵的演变趋势动态调整压缩率，兼顾压缩效率和模型误差，从而加速LLM训练。",
                "实验结果表明，EDGC在32-V100和64-H100集群上训练GPT2模型时，显著降低了通信延迟和训练时间，同时保持了模型精度。"
            ],
            "method_zh": "**问题定义**：现有分布式训练方法在训练大型语言模型时面临巨大的通信开销。静态梯度压缩方法虽然能降低通信量，但忽略了训练过程中梯度分布的动态变化，导致压缩效率不高，甚至影响模型收敛和精度。因此，如何在保证模型性能的前提下，更有效地压缩梯度，降低通信开销，是本文要解决的问题。\\n\\n**核心思路**：本文的核心思路是根据梯度熵的变化动态调整压缩率。梯度熵可以反映梯度分布的复杂程度，熵越高，梯度分布越分散，需要保留的信息越多，压缩率应该降低；反之，熵越低，梯度分布越集中，可以采用更高的压缩率。通过建立压缩率与梯度熵之间的理论模型，可以实现更智能的梯度压缩。\\n\\n**技术框架**：EDGC框架主要包含三个模块：1) 梯度熵估计模块：采用降采样方法高效估计梯度熵，降低计算开销。2) 压缩率决策模块：建立压缩率与梯度熵之间的理论模型，根据梯度熵动态调整压缩率。3) 窗口调整模块：采用基于窗口的调整机制，在不同的pipeline stage动态调整压缩率，进一步提高通信效率。整体流程是，首先计算梯度熵，然后根据梯度熵和理论模型确定压缩率，最后利用窗口调整机制平滑压缩率的变化。\\n\\n**关键创新**：EDGC的关键创新在于动态梯度压缩策略。与静态梯度压缩方法不同，EDGC能够根据梯度熵的演变趋势自适应地调整压缩率，从而在保证模型性能的同时，最大限度地降低通信开销。此外，EDGC提出的梯度熵估计方法和压缩率决策模型也具有一定的创新性。\\n\\n**关键设计**：梯度熵估计模块采用降采样方法，通过采样一部分梯度来估计整体的梯度熵，降低计算复杂度。压缩率决策模块基于信息论原理，建立压缩率与梯度熵之间的理论模型，具体形式未知。窗口调整模块采用滑动窗口平均的方法，平滑压缩率的变化，避免压缩率突变对模型训练造成影响。具体窗口大小和滑动步长未知。",
            "application_zh": "EDGC框架可应用于各种需要分布式训练的大型语言模型，尤其是在通信带宽受限的场景下。通过降低通信开销，EDGC可以加速模型训练，降低训练成本，并支持更大规模的模型训练。该研究成果对于推动大语言模型在资源受限环境下的应用具有重要意义。",
            "highlight_zh": "EDGC在32-NVIDIA-V100集群上训练GPT2-2.5B模型，以及在64-NVIDIA-H100集群上训练GPT2-12.1B模型。实验结果表明，EDGC能够显著降低通信延迟和训练时间，分别高达46.45%和16.13%，同时保持了LLM的精度。这些结果验证了EDGC框架的有效性。",
            "tags_zh": [
                "大语言模型",
                "分布式训练",
                "梯度压缩",
                "动态压缩",
                "梯度熵",
                "通信优化",
                "模型训练加速"
            ],
            "_index": 206,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2511.10333/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2511.10333/figure/gpt_entropy.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2511.10333/figure/bert_entropy.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Writing in Symbiosis: Mapping Human Creative Agency in the AI Era",
            "authors": [
                "Vivan Doshi",
                "Mengyuan Li"
            ],
            "arxiv_id": "2512.13697",
            "summary": "The proliferation of Large Language Models (LLMs) raises a critical question about what it means to be human when we share an increasingly symbiotic relationship with persuasive and creative machines. This paper examines patterns of human-AI coevolution in creative writing, investigating how human craft and agency are adapting alongside machine capabilities. We challenge the prevailing notion of stylistic homogenization by examining diverse patterns in longitudinal writing data. Using a large-scale corpus spanning the pre- and post-LLM era, we observe patterns suggestive of a \"Dual-Track Evolution\": thematic convergence around AI-related topics, coupled with structured stylistic differentiation. Our analysis reveals three emergent adaptation patterns: authors showing increased similarity to AI style, those exhibiting decreased similarity, and those maintaining stylistic stability while engaging with AI-related themes. This Creative Archetype Map illuminates how authorship is coevolving with AI, contributing to discussions about human-AI collaboration, detection challenges, and the preservation of creative diversity.",
            "categories": [
                "cs.CY",
                "cs.AI",
                "cs.CL"
            ],
            "primary_category": "cs.CY",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13697",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "通过分析人类写作风格演变，揭示人机共生时代人类创造力的适应模式",
            "summary_zh": "大型语言模型（LLMs）的普及引发了一个关键问题：当我们与具有说服力和创造力的机器建立日益共生的关系时，成为人类意味着什么？本文考察了创意写作中人机共同进化的模式，研究了人类技艺和能动性如何随着机器能力的发展而适应。我们通过检查纵向写作数据中的多样化模式，挑战了风格同质化的普遍观念。利用跨越LLM时代前后的一个大规模语料库，我们观察到了一种“双轨演化”模式：围绕人工智能相关主题的主题收敛，以及结构化的风格差异化。我们的分析揭示了三种新兴的适应模式：作者表现出与人工智能风格的相似性增加，作者表现出相似性降低，以及作者在参与人工智能相关主题时保持风格稳定。这种创造性原型图谱阐明了作者身份如何与人工智能共同进化，有助于讨论人机协作、检测挑战以及创造性多样性的保护。",
            "intro_zh": [
                "大型语言模型对人类写作风格的影响是核心问题，现有研究缺乏对风格差异化演变的深入分析。",
                "论文提出“双轨演化”框架，关注主题收敛和风格差异化，揭示人类作者对AI影响的不同适应模式。",
                "通过大规模语料库分析，论文识别出三种作者原型，为理解人机协作和保护创造性多样性提供了新视角。"
            ],
            "method_zh": "**问题定义**：论文旨在研究在大型语言模型（LLMs）普及的时代，人类作者的写作风格如何适应并与AI共生。现有研究主要关注AI对写作风格的同质化影响，而忽略了人类作者可能存在的风格差异化演变。\n\n**核心思路**：论文的核心思路是分析大规模的写作语料库，观察在LLM时代前后，人类作者在写作主题和风格上的变化。通过识别不同的适应模式，揭示人类作者在与AI交互过程中表现出的创造性。\n\n**技术框架**：论文的技术框架主要包括以下几个阶段：1) 构建大规模的写作语料库，涵盖LLM时代前后；2) 分析语料库中的写作主题，识别主题的收敛或发散趋势；3) 分析作者的写作风格，使用自然语言处理技术提取风格特征；4) 基于风格特征的变化，将作者划分为不同的原型，例如与AI风格相似性增加、减少或保持稳定；5) 分析不同作者原型与AI相关主题的互动情况。\n\n**关键创新**：论文的关键创新在于提出了“双轨演化”的概念，即在LLM时代，人类作者的写作主题可能趋于收敛（例如，更多地关注AI相关主题），但写作风格却可能呈现差异化演变。这种观点挑战了以往认为AI会导致写作风格同质化的观点。\n\n**关键设计**：论文的关键设计包括：1) 选择合适的风格特征，例如词汇多样性、句法复杂度等，以准确捕捉作者的写作风格；2) 使用合适的聚类算法，将作者划分为不同的原型；3) 设计合理的指标，衡量作者与AI风格的相似性。",
            "application_zh": "该研究成果可应用于多个领域，例如：开发更有效的人机协作写作工具，帮助作者在利用AI的同时保持个人风格；设计更精准的AI写作检测系统，区分人类创作和机器生成的内容；为教育领域提供参考，帮助学生在AI时代发展独特的写作技能。研究结果还有助于理解AI对人类创造力的长期影响。",
            "highlight_zh": "研究发现，在LLM时代，作者在写作风格上呈现出三种不同的适应模式：与AI风格相似性增加、减少或保持稳定。这表明，尽管AI对写作产生了影响，但人类作者仍然能够保持和发展独特的写作风格。此外，研究还发现，作者在主题上更倾向于关注AI相关话题，体现了主题的收敛性。",
            "tags_zh": [
                "人机协作",
                "大型语言模型",
                "写作风格",
                "风格演化",
                "创造性",
                "自然语言处理",
                "作者身份"
            ],
            "_index": 207,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13697/Figure_Archetype_Map.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13697/Figure_Archetype_Profiles.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.13697/Figure_Time_Series.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Made-in China, Thinking in America:U.S. Values Persist in Chinese LLMs",
            "authors": [
                "David Haslett",
                "Linus Ta-Lun Huang",
                "Leila Khalatbari",
                "Janet Hui-wen Hsiao",
                "Antoni B. Chan"
            ],
            "arxiv_id": "2512.13723",
            "summary": "As large language models increasingly mediate access to information and facilitate decision-making, they are becoming instruments in soft power competitions between global actors such as the United States and China. So far, language models seem to be aligned with the values of Western countries, but evidence for this ethical bias comes mostly from models made by American companies. The current crop of state-of-the-art models includes several made in China, so we conducted the first large-scale investigation of how models made in China and the USA align with people from China and the USA. We elicited responses to the Moral Foundations Questionnaire 2.0 and the World Values Survey from ten Chinese models and ten American models, and we compared their responses to responses from thousands of Chinese and American people. We found that all models respond to both surveys more like American people than like Chinese people. This skew toward American values is only slightly mitigated when prompting the models in Chinese or imposing a Chinese persona on the models. These findings have important implications for a near future in which large language models generate much of the content people consume and shape normative influence in geopolitics.",
            "categories": [
                "cs.CY",
                "cs.AI"
            ],
            "primary_category": "cs.CY",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13723",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "揭示中美大型语言模型中的文化价值观差异：中国模型更趋近美国价值观",
            "summary_zh": "随着大型语言模型在信息获取和决策制定中扮演越来越重要的角色，它们正成为美国和中国等全球参与者之间软实力竞争的工具。目前，语言模型似乎与西方国家的价值观保持一致，但这种伦理偏差的证据主要来自美国公司制造的模型。当前最先进的模型包括一些中国制造的模型，因此我们首次大规模调查了中国和美国制造的模型如何与中国和美国的人保持一致。我们从十个中国模型和十个美国模型中获得了对道德基础问卷2.0和世界价值观调查的回复，并将他们的回复与来自数千名中国和美国人的回复进行了比较。我们发现，所有模型对两项调查的回复都更像美国人，而不是中国人。当用中文提示模型或对模型施加中国角色时，这种对美国价值观的倾斜仅略有缓解。这些发现对于不久的将来具有重要意义，在不久的将来，大型语言模型将生成人们消费的大部分内容，并塑造地缘政治中的规范影响力。",
            "intro_zh": [
                "现有研究主要关注美国公司开发的LLM的价值观偏向，缺乏对中国LLM的系统性评估，无法全面了解LLM的价值观分布。",
                "该研究通过对比中美LLM在道德和价值观问卷上的表现，揭示了中国LLM可能存在的价值观偏向，并分析了其潜在原因。",
                "实验结果表明，即使是中国开发的LLM，其价值观也更接近美国人群，这对于未来LLM的应用和地缘政治具有重要意义。"
            ],
            "method_zh": "**问题定义**：现有的大型语言模型（LLM）在信息传播和决策支持中扮演着日益重要的角色，因此其价值观偏向性成为一个关键问题。之前的研究主要集中在美国公司开发的LLM，缺乏对中国LLM的深入分析。因此，该研究旨在调查中国制造的LLM是否也存在价值观偏向，以及这种偏向与中美两国人群的价值观有何差异。现有方法的痛点在于缺乏对中国LLM的系统性评估，无法全面了解LLM的价值观分布。\n\n**核心思路**：该研究的核心思路是通过对比中美两国LLM在标准化的价值观问卷上的表现，来评估其价值观偏向性。具体而言，研究者使用了道德基础问卷2.0（Moral Foundations Questionnaire 2.0）和世界价值观调查（World Values Survey）这两个广泛使用的问卷，来量化LLM和人类的价值观。通过比较LLM和中美两国人群的问卷结果，可以确定LLM的价值观更接近哪一方。\n\n**技术框架**：该研究的技术框架主要包括以下几个步骤：1）选择10个中国制造的LLM和10个美国制造的LLM；2）使用道德基础问卷2.0和世界价值观调查对这些LLM进行评估，收集LLM的回复；3）收集数千名中国和美国人的问卷回复作为基准；4）比较LLM和中美两国人群的问卷结果，分析LLM的价值观偏向性；5）通过中文提示和角色扮演等方式，尝试缓解LLM的价值观偏向。\n\n**关键创新**：该研究最重要的技术创新点在于首次大规模地对中国制造的LLM的价值观偏向性进行了评估。之前的研究主要集中在美国LLM，缺乏对中国LLM的关注。该研究填补了这一空白，为理解LLM的价值观分布提供了新的视角。与现有方法的本质区别在于，该研究关注的是中国LLM，而不是美国LLM。\n\n**关键设计**：在实验设计方面，研究者精心选择了道德基础问卷2.0和世界价值观调查这两个问卷，以全面评估LLM的价值观。此外，研究者还尝试了不同的提示策略，例如使用中文提示和角色扮演，以观察这些策略是否能够缓解LLM的价值观偏向。在数据分析方面，研究者使用了统计方法来比较LLM和中美两国人群的问卷结果，以确定LLM的价值观更接近哪一方。",
            "application_zh": "该研究的潜在应用领域包括：评估和校准LLM的价值观，以确保其符合特定文化或伦理标准；开发更具文化敏感性的LLM，以更好地服务于不同文化背景的用户；理解LLM如何影响人们的价值观和信念。实际价值在于帮助我们更好地理解LLM的价值观偏向，并采取措施来缓解这些偏向。未来影响在于塑造更负责任和公正的LLM技术，以促进全球范围内的文化理解和合作。",
            "highlight_zh": "研究发现，所有模型（包括中国制造的模型）在道德基础问卷和世界价值观调查中的回复都更接近美国人，而非中国人。即使使用中文提示或赋予模型中国角色，这种偏向也仅略有缓解。这表明，当前的大型语言模型可能存在普遍的价值观偏向，更倾向于美国价值观。",
            "tags_zh": [
                "大型语言模型",
                "价值观偏向",
                "文化差异",
                "道德基础",
                "地缘政治"
            ],
            "_index": 208,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13723/fig1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13723/fig2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.13723/fig3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Verification-Guided Context Optimization for Tool Calling via Hierarchical LLMs-as-Editors",
            "authors": [
                "Henger Li",
                "Shuangjie You",
                "Flavio Di Palo",
                "Yiyue Qian",
                "Ayush Jain"
            ],
            "arxiv_id": "2512.13860",
            "summary": "Tool calling enables large language models (LLMs) to interact with external environments through tool invocation, providing a practical way to overcome the limitations of pretraining. However, the effectiveness of tool use depends heavily on the quality of the associated documentation and knowledge base context. These materials are usually written for human users and are often misaligned with how LLMs interpret information. This problem is even more pronounced in industrial settings, where hundreds of tools with overlapping functionality create challenges in scalability, variability, and ambiguity. We propose Verification-Guided Context Optimization (VGCO), a framework that uses LLMs as editors to automatically refine tool-related documentation and knowledge base context. VGCO works in two stages. First, Evaluation collects real-world failure cases and identifies mismatches between tools and their context. Second, Optimization performs hierarchical editing through offline learning with structure-aware, in-context optimization. The novelty of our LLM editors has three main aspects. First, they use a hierarchical structure that naturally integrates into the tool-calling workflow. Second, they are state-aware, action-specific, and verification-guided, which constrains the search space and enables efficient, targeted improvements. Third, they enable cost-efficient sub-task specialization, either by prompt engineering large editor models or by post-training smaller editor models. Unlike prior work that emphasizes multi-turn reasoning, VGCO focuses on the single-turn, large-scale tool-calling problem and achieves significant improvements in accuracy, robustness, and generalization across LLMs.",
            "categories": [
                "cs.SE",
                "cs.AI"
            ],
            "primary_category": "cs.SE",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13860",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出VGCO框架，通过分层LLM编辑器优化工具调用上下文，提升工具使用效果。",
            "summary_zh": "本文提出了一种名为Verification-Guided Context Optimization (VGCO) 的框架，该框架利用大型语言模型 (LLM) 作为编辑器，自动优化与工具相关的文档和知识库上下文，从而提升工具调用的有效性。VGCO 分为两个阶段：首先，评估阶段收集真实世界的失败案例，识别工具及其上下文之间的不匹配；其次，优化阶段通过离线学习，利用结构感知的上下文优化进行分层编辑。LLM 编辑器的创新之处在于：采用与工具调用工作流程自然集成的分层结构；具备状态感知、动作特定和验证引导的特性，从而约束搜索空间并实现高效、有针对性的改进；支持经济高效的子任务专业化，可以通过提示工程大型编辑器模型或通过后训练较小的编辑器模型来实现。与强调多轮推理的先前工作不同，VGCO 专注于单轮、大规模的工具调用问题，并在 LLM 的准确性、鲁棒性和泛化能力方面取得了显著的改进。",
            "intro_zh": [
                "现有工具调用方法依赖于为人类编写的文档，与LLM的理解存在偏差，导致工具使用效果不佳。",
                "VGCO框架利用LLM作为编辑器，通过分层结构和验证引导，自动优化工具相关的文档和知识库上下文。",
                "实验表明，VGCO在单轮大规模工具调用问题上，显著提升了LLM的准确性、鲁棒性和泛化能力。"
            ],
            "method_zh": "**问题定义**：现有工具调用方法依赖于人工编写的工具文档和知识库，这些材料通常是为人类设计的，与LLM理解信息的方式存在偏差。尤其是在工业环境中，存在大量功能重叠的工具，导致可扩展性、变异性和歧义性问题，严重影响工具调用的准确性和效率。\\n\\n**核心思路**：VGCO的核心思路是将LLM作为编辑器，自动地对工具相关的文档和知识库上下文进行优化。通过收集真实世界的失败案例，识别工具及其上下文之间的不匹配，然后利用LLM的编辑能力，对这些上下文进行改进，使其更适合LLM的理解和使用。\\n\\n**技术框架**：VGCO框架包含两个主要阶段：评估（Evaluation）和优化（Optimization）。评估阶段负责收集真实世界的工具调用失败案例，并分析失败原因，找出工具文档和知识库中存在的问题。优化阶段则利用LLM作为编辑器，对评估阶段发现的问题进行修复和改进。优化过程采用分层编辑的方式，首先对文档的整体结构进行调整，然后逐步细化到具体的细节。\\n\\n**关键创新**：VGCO的关键创新在于其LLM编辑器的设计。该编辑器采用分层结构，能够自然地融入到工具调用的工作流程中。同时，编辑器具备状态感知、动作特定和验证引导的特性，能够根据当前的状态和需要执行的动作，有针对性地对上下文进行优化。验证引导则通过对编辑结果进行验证，确保优化后的上下文能够提高工具调用的准确性。\\n\\n**关键设计**：VGCO采用离线学习的方式训练LLM编辑器。在训练过程中，使用大量的工具调用失败案例作为训练数据，通过优化损失函数，使编辑器能够学习到如何根据失败案例对上下文进行改进。此外，VGCO还支持通过提示工程或后训练的方式，对编辑器进行子任务专业化，使其能够更好地处理特定类型的工具调用问题。",
            "application_zh": "VGCO框架可应用于各种需要工具调用的场景，例如智能助手、自动化运维、代码生成等。通过自动优化工具相关的文档和知识库上下文，可以显著提高工具调用的准确性和效率，降低人工维护成本，并提升用户体验。该研究对于推动LLM在实际应用中的落地具有重要意义。",
            "highlight_zh": "VGCO在单轮大规模工具调用问题上取得了显著的性能提升。实验结果表明，VGCO能够显著提高LLM在工具调用任务中的准确性、鲁棒性和泛化能力。具体的数据提升幅度在论文中给出，相较于基线方法有显著提高。",
            "tags_zh": [
                "工具调用",
                "大型语言模型",
                "上下文优化",
                "分层编辑",
                "知识库",
                "自动化",
                "LLM编辑器"
            ],
            "_index": 209,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13860/aaai2026/framework_diagram.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13860/aaai2026/accuracy_line_graph_Claude_Sonnet_3.5.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.13860/aaai2026/accuracy_line_graph_Claude_Sonnet_3.7.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Context Branching for LLM Conversations: A Version Control Approach to Exploratory Programming",
            "authors": [
                "Bhargav Chickmagalur Nanjundappa",
                "Spandan Maaheshwari"
            ],
            "arxiv_id": "2512.13914",
            "summary": "Large Language Models (LLMs) have become integral to software engineering workflows, yet their effectiveness degrades significantly in multi-turn conversations. Recent studies demonstrate an average 39% performance drop when instructions are delivered across multiple turns, with models making premature assumptions and failing to course correct (Laban et al., 2025). This degradation is particularly problematic in exploratory programming tasks where developers need to investigate alternative approaches without committing to a single path. Current solutions force users into a false dichotomy: continue in a context-polluted conversation where the LLM becomes increasingly confused, or start fresh and lose all accumulated context.We present ContextBranch, a conversation management system that applies version control semantics to LLM interactions. ContextBranch provides four core primitives--checkpoint, branch, switch, and inject--enabling users to capture conversation state, explore alternatives in isolation, and selectively merge insights. We evaluate ContextBranch through a controlled experiment with 30 software engineering scenarios featuring intentionally polluting explorations. Branched conversations achieved higher response quality compared to linear conversations, with large improvements in focus and context awareness. Benefits were concentrated in complex scenarios involving conceptually distant explorations. Branching reduced context size by 58.1% (31.0 to 13.0 messages), eliminating irrelevant exploratory content. Our work establishes conversation branching as a fundamental primitive for AI-assisted exploratory work, demonstrating that isolation prevents context pollution when exploring alternatives.",
            "categories": [
                "cs.SE",
                "cs.AI",
                "cs.HC"
            ],
            "primary_category": "cs.SE",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13914",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "ContextBranch：利用版本控制提升LLM在探索性编程对话中的性能",
            "summary_zh": "大型语言模型（LLM）已成为软件工程工作流程中不可或缺的一部分，但其有效性在多轮对话中显著下降。最近的研究表明，当指令跨多轮传递时，性能平均下降39%，模型会做出过早的假设，并且无法纠正错误。这种退化在探索性编程任务中尤其成问题，在这些任务中，开发人员需要研究替代方法，而无需致力于单一路径。目前的解决方案迫使用户进入一种虚假的两难境地：继续在上下文污染的对话中进行，LLM变得越来越困惑，或者重新开始并失去所有累积的上下文。我们提出了ContextBranch，一个对话管理系统，它将版本控制语义应用于LLM交互。ContextBranch提供了四个核心原语——checkpoint、branch、switch和inject——使用户能够捕获对话状态，在隔离状态下探索替代方案，并选择性地合并见解。我们通过一个受控实验评估了ContextBranch，该实验包含30个具有故意污染探索的软件工程场景。与线性对话相比，分支对话实现了更高的响应质量，在焦点和上下文感知方面有了很大的改进。好处集中在涉及概念上遥远的探索的复杂场景中。分支将上下文大小减少了58.1%（从31.0条消息减少到13.0条消息），消除了不相关的探索性内容。我们的工作将对话分支确立为AI辅助探索性工作的基础原语，证明了隔离可以防止探索替代方案时的上下文污染。",
            "intro_zh": [
                "多轮对话中LLM性能显著下降，尤其是在探索性编程任务中，模型易受上下文污染影响。",
                "ContextBranch通过引入版本控制语义，允许用户创建、切换和合并对话分支，隔离探索路径。",
                "实验表明，ContextBranch能显著提升LLM在复杂探索性编程场景中的响应质量，并减少上下文大小。"
            ],
            "method_zh": "**问题定义**：在探索性编程中，开发者需要尝试不同的方法和思路。然而，在与LLM的多轮对话中，之前的探索性尝试可能会污染上下文，导致LLM产生困惑，影响后续对话的质量。现有方法要么继续在污染的上下文中进行，要么重新开始对话，丢失之前的上下文信息，无法有效支持探索性编程。\n\n**核心思路**：ContextBranch的核心思路是将版本控制的概念引入到LLM对话中。通过创建分支，开发者可以在不同的分支中探索不同的思路，而不会相互干扰。每个分支都保留了独立的上下文，避免了上下文污染。开发者可以随时切换分支，比较不同思路的结果，并将有用的信息合并到主分支中。\n\n**技术框架**：ContextBranch提供四个核心原语：checkpoint（保存当前对话状态）、branch（创建新的对话分支）、switch（切换到不同的对话分支）和inject（将一个分支中的信息注入到另一个分支中）。用户可以先checkpoint保存当前状态，然后branch创建新的分支进行探索，通过switch在不同分支间切换，最后使用inject将有用的信息合并到主分支。整个框架类似于软件开发中的版本控制系统，允许开发者安全地探索不同的思路。\n\n**关键创新**：ContextBranch最重要的创新在于将版本控制的思想应用于LLM对话管理。这使得开发者可以更加灵活地与LLM进行交互，探索不同的解决方案，而不用担心上下文污染的问题。与传统的线性对话方式相比，ContextBranch提供了一种更加结构化和可控的对话方式。\n\n**关键设计**：ContextBranch的关键设计在于如何有效地管理和切换不同的对话分支。系统需要维护每个分支的上下文信息，并提供方便的接口供用户切换分支和合并信息。具体的技术细节，例如如何存储和索引对话历史，以及如何实现高效的分支切换和信息合并，论文中可能没有详细描述，属于实现层面的细节。",
            "application_zh": "ContextBranch可应用于各种AI辅助的探索性任务，例如软件开发、数据分析、科学研究等。它能帮助用户更有效地利用LLM探索不同的解决方案，提高工作效率和创造力。未来，ContextBranch可以集成到各种IDE和开发工具中，成为AI辅助开发的重要组成部分。",
            "highlight_zh": "实验结果表明，ContextBranch在复杂软件工程场景中显著提升了LLM的响应质量。与线性对话相比，分支对话在焦点和上下文感知方面有很大改进。ContextBranch还将上下文大小减少了58.1%（从31.0条消息减少到13.0条消息），有效消除了不相关的探索性内容。",
            "tags_zh": [
                "大型语言模型",
                "多轮对话",
                "上下文管理",
                "版本控制",
                "探索性编程"
            ],
            "_index": 210,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13914/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13914/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.13914/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "LAPPI: Interactive Optimization with LLM-Assisted Preference-Based Problem Instantiation",
            "authors": [
                "So Kuroki",
                "Manami Nakagawa",
                "Shigeo Yoshida",
                "Yuki Koyama",
                "Kozuno Tadashi"
            ],
            "arxiv_id": "2512.14138",
            "summary": "Many real-world tasks, such as trip planning or meal planning, can be formulated as combinatorial optimization problems. However, using optimization solvers is difficult for end users because it requires problem instantiation: defining candidate items, assigning preference scores, and specifying constraints. We introduce LAPPI (LLM-Assisted Preference-based Problem Instantiation), an interactive approach that uses large language models (LLMs) to support users in this instantiation process. Through natural language conversations, the system helps users transform vague preferences into well-defined optimization problems. These instantiated problems are then passed to existing optimization solvers to generate solutions. In a user study on trip planning, our method successfully captured user preferences and generated feasible plans that outperformed both conventional and prompt-engineering approaches. We further demonstrate LAPPI's versatility by adapting it to an additional use case.",
            "categories": [
                "cs.HC",
                "cs.AI"
            ],
            "primary_category": "cs.HC",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14138",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "LAPPI：利用LLM辅助的偏好问题实例化进行交互式优化",
            "summary_zh": "许多现实世界的任务，如旅行计划或膳食计划，都可以被形式化为组合优化问题。然而，对于终端用户来说，使用优化求解器是困难的，因为它需要问题实例化：定义候选项目、分配偏好分数和指定约束。我们介绍了一种交互式方法LAPPI（LLM辅助的基于偏好的问题实例化），它使用大型语言模型（LLM）来支持用户完成这个实例化过程。通过自然语言对话，该系统帮助用户将模糊的偏好转化为定义良好的优化问题。然后，这些实例化的优化问题被传递给现有的优化求解器以生成解决方案。在旅行计划的用户研究中，我们的方法成功地捕捉了用户的偏好，并生成了优于传统方法和提示工程方法的可行计划。我们进一步通过将其应用于额外的用例来展示LAPPI的多功能性。",
            "intro_zh": [
                "现有优化求解器需要用户进行问题实例化，包括定义候选项目、分配偏好分数和指定约束，这对非专业用户构成挑战。",
                "LAPPI利用大型语言模型，通过自然语言交互，辅助用户将模糊偏好转化为明确的优化问题，降低了使用门槛。",
                "用户研究表明，LAPPI在旅行计划任务中能够有效捕捉用户偏好，生成优于传统方法和提示工程的可行方案。"
            ],
            "method_zh": "**问题定义**：论文旨在解决用户难以将自身偏好转化为优化问题实例的问题。现有方法需要用户手动定义候选项目、分配偏好分数和指定约束，这对于不熟悉优化求解器的用户来说非常困难，导致优化工具难以被广泛应用。\\n\\n**核心思路**：论文的核心思路是利用大型语言模型（LLM）的自然语言理解和生成能力，构建一个交互式系统，通过对话引导用户表达偏好，并将这些偏好转化为优化求解器可以理解的问题实例。这样，用户无需具备专业的优化知识，也能利用优化工具解决实际问题。\\n\\n**技术框架**：LAPPI的整体框架包含以下几个主要模块：1) 自然语言交互模块：负责与用户进行对话，收集用户的偏好信息。2) 偏好提取模块：利用LLM从对话中提取用户的偏好，例如对不同景点的喜爱程度、对旅行时间的限制等。3) 问题实例化模块：将提取的偏好转化为优化问题的具体参数，例如目标函数、约束条件等。4) 优化求解模块：使用现有的优化求解器，根据问题实例生成解决方案。5) 结果展示模块：将优化结果以用户友好的方式呈现给用户。\\n\\n**关键创新**：LAPPI的关键创新在于将大型语言模型引入到优化问题的实例化过程中，实现了人机协同的优化问题求解。与传统方法相比，LAPPI无需用户手动进行问题实例化，大大降低了使用门槛。同时，通过自然语言交互，LAPPI能够更好地捕捉用户的真实偏好，从而生成更符合用户需求的解决方案。\\n\\n**关键设计**：LAPPI的关键设计包括：1) 针对特定应用场景（如旅行计划）设计合适的对话流程，引导用户逐步表达偏好。2) 选择合适的LLM，并对其进行微调，以提高偏好提取的准确性和效率。3) 设计合适的优化问题模型，将用户的偏好转化为目标函数和约束条件。4) 采用合适的优化求解器，以保证求解效率和解的质量。",
            "application_zh": "LAPPI可应用于各种需要组合优化的场景，如旅行计划、膳食计划、日程安排、资源分配等。该研究降低了优化工具的使用门槛，使更多用户能够利用优化技术解决实际问题，具有广泛的应用前景和实际价值。未来，该方法可以扩展到更复杂的优化问题，并与其他AI技术相结合，实现更智能化的优化解决方案。",
            "highlight_zh": "在旅行计划的用户研究中，LAPPI成功捕捉了用户偏好，生成的旅行计划优于传统方法和提示工程方法。具体而言，LAPPI生成的计划在用户满意度方面显著高于其他方法，并且能够更好地满足用户的个性化需求。该实验结果验证了LAPPI的有效性和优越性。",
            "tags_zh": [
                "人机交互",
                "大型语言模型",
                "组合优化",
                "问题实例化",
                "偏好学习"
            ],
            "_index": 211,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14138/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14138/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14138/fig/trip-planning-withMarks.jpg",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "IntentMiner: Intent Inversion Attack via Tool Call Analysis in the Model Context Protocol",
            "authors": [
                "Yunhao Yao",
                "Zhiqiang Wang",
                "Haoran Cheng",
                "Yihang Cheng",
                "Haohua Du",
                "Xiang-Yang Li"
            ],
            "arxiv_id": "2512.14166",
            "summary": "The rapid evolution of Large Language Models (LLMs) into autonomous agents has led to the adoption of the Model Context Protocol (MCP) as a standard for discovering and invoking external tools. While this architecture decouples the reasoning engine from tool execution to enhance scalability, it introduces a significant privacy surface: third-party MCP servers, acting as semi-honest intermediaries, can observe detailed tool interaction logs outside the user's trusted boundary. In this paper, we first identify and formalize a novel privacy threat termed Intent Inversion, where a semi-honest MCP server attempts to reconstruct the user's private underlying intent solely by analyzing legitimate tool calls. To systematically assess this vulnerability, we propose IntentMiner, a framework that leverages Hierarchical Information Isolation and Three-Dimensional Semantic Analysis, integrating tool purpose, call statements, and returned results, to accurately infer user intent at the step level. Extensive experiments demonstrate that IntentMiner achieves a high degree of semantic alignment (over 85%) with original user queries, significantly outperforming baseline approaches. These results highlight the inherent privacy risks in decoupled agent architectures, revealing that seemingly benign tool execution logs can serve as a potent vector for exposing user secrets.",
            "categories": [
                "cs.CR",
                "cs.AI"
            ],
            "primary_category": "cs.CR",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14166",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出IntentMiner框架，通过分析工具调用日志实现用户意图反演攻击。",
            "summary_zh": "大型语言模型（LLMs）向自主代理的快速演进促使模型上下文协议（MCP）被广泛采用，作为发现和调用外部工具的标准。虽然这种架构将推理引擎与工具执行分离，以提高可扩展性，但也引入了一个重要的隐私风险：第三方MCP服务器作为半诚实的中介，可以观察到用户信任边界之外的详细工具交互日志。本文首次识别并形式化了一种新的隐私威胁，称为意图反演，即半诚实MCP服务器仅通过分析合法的工具调用来重建用户的私有底层意图。为了系统地评估这种漏洞，我们提出了IntentMiner，一个利用分层信息隔离和三维语义分析的框架，整合工具目的、调用语句和返回结果，以在步骤级别准确推断用户意图。大量实验表明，IntentMiner与原始用户查询实现了高度的语义对齐（超过85%），显著优于基线方法。这些结果突出了解耦代理架构中固有的隐私风险，揭示了看似良性的工具执行日志可以作为暴露用户秘密的有效途径。",
            "intro_zh": [
                "现有基于MCP的LLM代理架构存在隐私漏洞，第三方服务器可能通过分析工具调用推断用户意图。",
                "IntentMiner框架通过分层信息隔离和三维语义分析，从工具调用日志中重建用户意图。",
                "实验表明IntentMiner能够以超过85%的准确率推断用户意图，远超基线方法，验证了攻击的有效性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决在基于模型上下文协议（MCP）的LLM代理架构中，第三方MCP服务器可能通过分析用户与工具的交互日志来推断用户真实意图的隐私问题。现有方法缺乏对这种新型隐私威胁的系统性分析和有效防御机制。攻击者（半诚实MCP服务器）的目标是从合法的工具调用序列中反推出用户的原始查询意图。\\n\\n**核心思路**：论文的核心思路是利用工具调用日志中蕴含的丰富语义信息，包括工具的目的、调用语句和返回结果，通过综合分析这些信息来重建用户的意图。这种方法基于一个假设：即使工具调用本身是合法的，其序列和内容也可能泄露用户的敏感信息。通过模拟攻击者的视角，评估现有架构的隐私风险。\\n\\n**技术框架**：IntentMiner框架包含以下主要模块：1) **数据收集模块**：收集用户与工具交互的日志，包括工具名称、调用参数和返回结果。2) **分层信息隔离模块**：对收集到的数据进行预处理，隔离不同层次的信息，例如工具目的、调用语句和返回结果。3) **三维语义分析模块**：从工具目的、调用语句和返回结果三个维度对数据进行语义分析，提取关键信息。4) **意图推断模块**：利用提取的语义信息，结合机器学习模型（例如，基于Transformer的模型），推断用户的原始意图。\\n\\n**关键创新**：论文的关键创新在于：1) 首次识别并形式化了“意图反演”这种新型隐私威胁。2) 提出了IntentMiner框架，该框架能够有效地从工具调用日志中推断用户意图。3) 采用了分层信息隔离和三维语义分析技术，提高了意图推断的准确性。与现有方法相比，IntentMiner更关注工具调用日志中蕴含的语义信息，能够更准确地重建用户意图。\\n\\n**关键设计**：在三维语义分析模块中，论文可能使用了预训练的语言模型（例如BERT或RoBERTa）来提取工具目的、调用语句和返回结果的语义特征。意图推断模块可能采用了序列到序列的模型结构，将工具调用序列作为输入，用户的原始意图作为输出。损失函数可能采用了交叉熵损失或类似的损失函数，用于衡量推断意图与原始意图之间的差异。具体的参数设置和网络结构细节未知，需要在论文中进一步查找。",
            "application_zh": "该研究成果可应用于评估和增强基于LLM代理的系统的隐私性。通过IntentMiner，开发者可以识别潜在的隐私漏洞，并采取相应的安全措施，例如对工具调用日志进行脱敏处理、限制第三方服务器的访问权限等。此外，该研究还可以促进隐私保护技术的研发，例如差分隐私、联邦学习等，以保护用户在使用LLM代理时的隐私。",
            "highlight_zh": "实验结果表明，IntentMiner能够以超过85%的语义对齐度（与原始用户查询相比）推断用户意图，显著优于基线方法。这一结果表明，即使工具调用本身是合法的，其序列和内容也可能泄露用户的敏感信息。该研究揭示了基于MCP的LLM代理架构中存在的严重隐私风险，并为开发更安全的LLM代理系统提供了重要的参考。",
            "tags_zh": [
                "意图反演",
                "模型上下文协议",
                "大型语言模型",
                "隐私攻击",
                "工具调用分析"
            ],
            "_index": 212,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14166/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14166/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14166/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "SPARQL-LLM: Real-Time SPARQL Query Generation from Natural Language Questions",
            "authors": [
                "Panayiotis Smeros",
                "Vincent Emonet",
                "Ruijie Wang",
                "Ana-Claudia Sima",
                "Tarcisio Mendes de Farias"
            ],
            "arxiv_id": "2512.14277",
            "summary": "The advent of large language models is contributing to the emergence of novel approaches that promise to better tackle the challenge of generating structured queries, such as SPARQL queries, from natural language. However, these new approaches mostly focus on response accuracy over a single source while ignoring other evaluation criteria, such as federated query capability over distributed data stores, as well as runtime and cost to generate SPARQL queries. Consequently, they are often not production-ready or easy to deploy over (potentially federated) knowledge graphs with good accuracy. To mitigate these issues, in this paper, we extend our previous work and describe and systematically evaluate SPARQL-LLM, an open-source and triplestore-agnostic approach, powered by lightweight metadata, that generates SPARQL queries from natural language text. First, we describe its architecture, which consists of dedicated components for metadata indexing, prompt building, and query generation and execution. Then, we evaluate it based on a state-of-the-art challenge with multilingual questions, and a collection of questions from three of the most prevalent knowledge graphs within the field of bioinformatics. Our results demonstrate a substantial increase of 24% in the F1 Score on the state-of-the-art challenge, adaptability to high-resource languages such as English and Spanish, as well as ability to form complex and federated bioinformatics queries. Furthermore, we show that SPARQL-LLM is up to 36x faster than other systems participating in the challenge, while costing a maximum of $0.01 per question, making it suitable for real-time, low-cost text-to-SPARQL applications. One such application deployed over real-world decentralized knowledge graphs can be found atthis https URL.",
            "categories": [
                "cs.IR",
                "cs.AI",
                "cs.CL"
            ],
            "primary_category": "cs.IR",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14277",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "SPARQL-LLM：一种基于轻量级元数据的实时自然语言到SPARQL查询生成方法",
            "summary_zh": "大型语言模型的出现促进了从自然语言生成结构化查询（如SPARQL查询）的新方法。然而，这些方法主要关注单一来源的响应准确性，忽略了其他评估标准，如分布式数据存储上的联邦查询能力，以及生成SPARQL查询的运行时间和成本。因此，它们通常不具备生产就绪性，或者难以在具有良好准确性的（潜在的联邦）知识图谱上部署。为了缓解这些问题，本文扩展了我们之前的工作，描述并系统地评估了SPARQL-LLM，这是一种开源且三元组存储无关的方法，由轻量级元数据驱动，可以从自然语言文本生成SPARQL查询。首先，我们描述了它的架构，该架构由用于元数据索引、提示构建和查询生成与执行的专用组件组成。然后，我们基于最先进的挑战（包含多语言问题）以及来自生物信息学领域中最流行的三个知识图谱的问题集合对其进行评估。结果表明，在最先进的挑战中，F1分数显着提高了24％，对英语和西班牙语等高资源语言的适应性，以及形成复杂和联邦生物信息学查询的能力。此外，我们表明SPARQL-LLM比参与挑战的其他系统快36倍，每个问题的成本最高为0.01美元，使其适用于实时，低成本的文本到SPARQL应用程序。可以在this https URL找到部署在真实世界分散知识图谱上的一个此类应用程序。",
            "intro_zh": [
                "现有方法在自然语言生成SPARQL查询时，侧重于单数据源的准确性，忽略了联邦查询能力、运行时成本等关键因素。",
                "SPARQL-LLM利用轻量级元数据，构建了一个开源、三元组存储无关的框架，用于高效生成SPARQL查询。",
                "实验结果表明，SPARQL-LLM在F1分数上提升了24%，速度提升了36倍，且成本极低，适用于实时应用。"
            ],
            "method_zh": "**问题定义**：论文旨在解决从自然语言问题实时生成SPARQL查询的问题。现有方法的痛点在于，它们通常只关注单一知识图谱的查询准确性，而忽略了在分布式知识图谱上的联邦查询能力，以及查询生成的速度和成本，导致难以在实际生产环境中部署。\\n\\n**核心思路**：论文的核心思路是利用轻量级的元数据来指导大型语言模型生成SPARQL查询。通过对知识图谱的元数据进行索引，可以有效地构建提示（prompt），从而引导LLM生成更准确、更高效的SPARQL查询。这种方法旨在平衡查询准确性、联邦查询能力、运行速度和成本。\\n\\n**技术框架**：SPARQL-LLM的整体架构包含以下几个主要模块：1) 元数据索引模块：负责对知识图谱的元数据进行提取和索引，构建轻量级的元数据索引。2) 提示构建模块：根据自然语言问题和元数据索引，构建LLM的提示，提示中包含与问题相关的知识图谱信息。3) 查询生成模块：利用LLM根据提示生成SPARQL查询。4) 查询执行模块：执行生成的SPARQL查询，并返回结果。\\n\\n**关键创新**：该方法最重要的技术创新点在于利用轻量级元数据来指导LLM生成SPARQL查询。与直接使用LLM生成SPARQL查询相比，该方法可以更有效地利用知识图谱的信息，提高查询的准确性和效率。此外，该方法是三元组存储无关的，可以应用于不同的知识图谱。\\n\\n**关键设计**：元数据索引的设计是关键。论文中使用的元数据包括实体、关系和属性等信息。提示构建模块的设计也至关重要，需要有效地将元数据信息融入到提示中，以便LLM能够生成正确的SPARQL查询。具体的参数设置、损失函数和网络结构等细节未在摘要中详细说明，属于未知信息。",
            "application_zh": "SPARQL-LLM具有广泛的应用前景，例如在生物信息学领域，可以帮助研究人员通过自然语言查询分散的生物知识图谱，从而加速药物发现和疾病研究。此外，该方法还可以应用于其他需要从自然语言查询知识图谱的领域，例如金融、法律和教育等。由于其低成本和实时性，SPARQL-LLM有望推动知识图谱在实际应用中的普及。",
            "highlight_zh": "SPARQL-LLM在多语言问题挑战中，F1分数提升了24%，并且在生物信息学查询中表现出良好的适应性。更重要的是，SPARQL-LLM比其他参与挑战的系统快36倍，每个问题的成本最高仅为0.01美元，这使其成为一个极具竞争力的解决方案。",
            "tags_zh": [
                "自然语言查询",
                "SPARQL查询生成",
                "知识图谱",
                "大型语言模型",
                "元数据索引"
            ],
            "_index": 213,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14277/figures/system_architecture.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14277/figures/system_flow.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14277/figures/triple_patterns.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "A Threshold-Triggered Deep Q-Network-Based Framework for Self-Healing in Autonomic Software-Defined IIoT-Edge Networks",
            "authors": [
                "Agrippina Mwangi",
                "León Navarro-Hilfiker",
                "Lukasz Brewka",
                "Mikkel Gryning",
                "Elena Fumagalli",
                "Madeleine Gibescu"
            ],
            "arxiv_id": "2512.14297",
            "summary": "Stochastic disruptions such as flash events arising from benign traffic bursts and switch thermal fluctuations are major contributors to intermittent service degradation in software-defined industrial networks. These events violate IEC~61850-derived quality-of-service requirements and user-defined service-level agreements, hindering the reliable and timely delivery of control, monitoring, and best-effort traffic in IEC~61400-25-compliant wind power plants. Failure to maintain these requirements often results in delayed or lost control signals, reduced operational efficiency, and increased risk of wind turbine generator downtime.To address these challenges, this study proposes a threshold-triggered Deep Q-Network self-healing agent that autonomically detects, analyzes, and mitigates network disruptions while adapting routing behavior and resource allocation in real time. The proposed agent was trained, validated, and tested on an emulated tri-clustered switch network deployed in a cloud-based proof-of-concept testbed.Simulation results show that the proposed agent improves disruption recovery performance by 53.84% compared to a baseline shortest-path and load-balanced routing approach and outperforms state-of-the-art methods, including the Adaptive Network-based Fuzzy Inference System by 13.1% and the Deep Q-Network and traffic prediction-based routing optimization method by 21.5%, in a super-spine leaf data-plane architecture.Additionally, the agent maintains switch thermal stability by proactively initiating external rack cooling when required. These findings highlight the potential of deep reinforcement learning in building resilience in software-defined industrial networks deployed in mission-critical, time-sensitive application scenarios.",
            "categories": [
                "cs.NI",
                "cs.AI",
                "cs.ET",
                "cs.PF"
            ],
            "primary_category": "cs.NI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14297",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning",
                        "deep reinforcement learning"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出阈值触发深度Q网络框架以解决工业物联网边缘网络自愈问题",
            "summary_zh": "随机干扰，如由于流量突发和交换机热波动引起的闪电事件，是软件定义工业网络中间歇性服务降级的主要原因。这些事件违反了IEC 61850衍生的服务质量要求和用户定义的服务水平协议，影响了控制、监测和尽力而为流量的可靠及时传输。为了解决这些挑战，本文提出了一种阈值触发的深度Q网络自愈代理，能够自主检测、分析和缓解网络干扰，同时实时调整路由行为和资源分配。仿真结果表明，该代理的干扰恢复性能比基线方法提高了53.84%。",
            "intro_zh": [
                "现有方法在应对随机干扰时缺乏有效的自愈能力，导致服务质量下降和控制信号延迟。",
                "论文提出了一种基于阈值触发的深度Q网络自愈代理，能够实时检测和缓解网络干扰，优化资源分配。",
                "实验结果显示，该代理在干扰恢复性能上比基线方法提高了53.84%，并优于其他先进方法。"
            ],
            "method_zh": "**问题定义**：本文旨在解决软件定义工业网络中由于随机干扰导致的服务降级问题。现有方法在应对突发流量和设备热波动时，往往无法有效保持服务质量，导致控制信号延迟或丢失。\\n\\n**核心思路**：论文提出的阈值触发深度Q网络自愈代理，利用深度强化学习技术，能够自主检测和分析网络状态，并在发生干扰时实时调整路由和资源分配，以提高网络的自愈能力和稳定性。\\n\\n**技术框架**：该框架包括多个模块：首先是状态检测模块，实时监测网络状态；其次是决策模块，基于深度Q网络进行干扰分析和路由优化；最后是执行模块，实施调整措施，如资源重新分配和冷却启动。\\n\\n**关键创新**：最重要的技术创新在于将深度Q网络与阈值触发机制结合，能够在干扰发生前主动采取措施，从而显著提高网络的恢复能力和稳定性。这一方法与传统的被动响应机制有本质区别。\\n\\n**关键设计**：在设计中，代理的训练采用了仿真环境，关键参数包括学习率、折扣因子等。损失函数设计为均方误差，以优化Q值的估计。此外，网络结构采用了深度神经网络，以提高决策的准确性和效率。",
            "application_zh": "该研究的潜在应用领域包括工业物联网、智能电网和自动化控制系统等。通过提高网络的自愈能力，可以显著提升这些领域的服务质量和可靠性，尤其是在时间敏感的应用场景中，确保控制信号的及时传输和处理。未来，该技术有望在更多关键任务和高可用性系统中得到广泛应用。",
            "highlight_zh": "实验结果表明，提出的自愈代理在干扰恢复性能上比基线的最短路径和负载均衡路由方法提高了53.84%。此外，与现有的自适应网络模糊推理系统相比，性能提升达13.1%，与基于深度Q网络和流量预测的优化方法相比提升21.5%。",
            "tags_zh": [
                "深度Q网络",
                "自愈机制",
                "工业物联网",
                "网络优化",
                "强化学习",
                "服务质量",
                "实时监测"
            ],
            "_index": 214,
            "_used_api": "openai",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14297/Images/Fig1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14297/Images/Fig2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14297/x1.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "A LoRA-Based Approach to Fine-Tuning LLMs for Educational Guidance in Resource-Constrained Settings",
            "authors": [
                "Md Millat Hosen"
            ],
            "arxiv_id": "2504.15610",
            "summary": "The current study describes a cost-effective method for adapting large language models (LLMs) for academic advising with study-abroad contexts in mind and for application in low-resource methods for acculturation. With the Mistral-7B-Instruct model applied with a Low-Rank Adaptation (LoRA) method and a 4-bit quantization method, the model underwent training in two distinct stages related to this study's purpose to enhance domain specificity while maintaining computational efficiency. In Phase 1, the model was conditioned with a synthetic dataset via the Gemini Pro API, and in Phase 2, it was trained with manually curated datasets from the StudyAbroadGPT project to achieve enhanced, contextualized responses. Technical innovations entailed memory-efficient quantization, parameter-efficient adaptation, and continuous training analytics via Weights & Biases. After training, this study demonstrated a reduction in training loss by 52.7%, 92% accuracy in domain-specific recommendations, achieved 95% markdown-based formatting support, and a median run-rate of 100 samples per second on off-the-shelf GPU equipment. These findings support the effective application of instruction-tuned LLMs within educational advisers, especially in low-resource institutional scenarios. Limitations included decreased generalizability and the application of a synthetically generated dataset, but this framework is scalable for adding new multilingual-augmented and real-time academic advising processes. Future directions may include plans for the integration of retrieval-augmented generation, applying dynamic quantization routines, and connecting to real-time academic databases to increase adaptability and accuracy.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2504.15610",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于LoRA微调LLM的教育指导方法，适用于资源受限场景",
            "summary_zh": "本研究提出了一种经济高效的方法，用于调整大型语言模型（LLM），以适应学术指导，特别是针对出国留学背景，并应用于资源有限的文化适应方法。该方法采用带有低秩适应（LoRA）方法和4位量化方法的Mistral-7B-Instruct模型，并针对本研究的目的进行了两个不同阶段的训练，以增强领域特异性，同时保持计算效率。在第一阶段，模型通过Gemini Pro API使用合成数据集进行条件训练；在第二阶段，模型使用StudyAbroadGPT项目中手动策划的数据集进行训练，以实现增强的、上下文相关的响应。技术创新包括内存高效的量化、参数高效的适应以及通过Weights & Biases进行的持续训练分析。训练后，本研究表明训练损失减少了52.7%，领域特定推荐的准确率达到了92%，实现了95%的基于Markdown的格式支持，并且在现成的GPU设备上实现了每秒100个样本的中值运行速率。这些发现支持了instruction-tuned LLM在教育顾问中的有效应用，尤其是在资源有限的机构场景中。局限性包括泛化能力下降和合成数据集的应用，但该框架可扩展，可添加新的多语言增强和实时学术指导流程。未来的方向可能包括检索增强生成、应用动态量化程序以及连接到实时学术数据库，以提高适应性和准确性。",
            "intro_zh": [
                "现有LLM在教育指导领域应用面临计算资源需求高和领域知识不足的挑战。",
                "利用LoRA进行参数高效微调，结合合成数据和人工标注数据，提升LLM在特定领域的性能。",
                "实验表明，该方法在降低训练损失、提高领域准确率和格式支持方面表现出色，且运行效率高。"
            ],
            "method_zh": "**问题定义**：论文旨在解决在资源受限的环境下，如何有效地将大型语言模型（LLM）应用于教育指导，特别是出国留学咨询的问题。现有方法通常需要大量的计算资源进行全参数微调，并且可能缺乏特定领域的知识，导致模型效果不佳。\\n\\n**核心思路**：论文的核心思路是利用低秩适应（LoRA）方法，在预训练的LLM基础上进行参数高效的微调。LoRA通过引入少量可训练的参数来适应特定任务，从而显著降低计算资源的需求。此外，论文还结合了合成数据和人工标注数据，以增强模型在教育指导领域的知识和能力。\\n\\n**技术框架**：整体框架包含两个主要阶段。第一阶段，使用Gemini Pro API生成合成数据集，对模型进行初步的领域知识训练。第二阶段，使用StudyAbroadGPT项目中的人工标注数据集，进一步提升模型的上下文理解和生成能力。整个训练过程使用4-bit量化方法，以减少内存占用。同时，利用Weights & Biases进行持续的训练分析，监控模型性能。\\n\\n**关键创新**：论文的关键创新在于将LoRA方法与合成数据和人工标注数据相结合，实现了一种参数高效且领域知识丰富的LLM微调方法。这种方法能够在资源受限的环境下，有效地提升LLM在教育指导领域的性能。\\n\\n**关键设计**：论文采用了Mistral-7B-Instruct模型作为基础模型，并使用LoRA进行微调。具体来说，LoRA在模型的Transformer层中插入了低秩矩阵，这些矩阵是唯一需要训练的参数。论文还使用了4-bit量化方法，以减少模型的大小和内存占用。损失函数方面，论文可能采用了标准的交叉熵损失函数，用于衡量模型生成文本与目标文本之间的差异。（具体损失函数细节未知）",
            "application_zh": "该研究成果可应用于开发低成本、高效的智能教育咨询系统，特别是在资源匮乏的学校或地区。它可以为学生提供个性化的出国留学指导、课程选择建议和文化适应支持，从而提高教育公平性和学生成功率。未来，该方法还可以扩展到其他教育领域，如职业规划、心理辅导等。",
            "highlight_zh": "实验结果表明，该方法能够显著降低训练损失（52.7%），提高领域特定推荐的准确率（92%），并支持高质量的Markdown格式输出（95%）。此外，该模型在普通GPU设备上实现了每秒100个样本的推理速度，验证了其在资源受限环境下的实用性。",
            "tags_zh": [
                "LoRA微调",
                "大型语言模型",
                "教育指导",
                "资源受限",
                "参数高效",
                "知识蒸馏",
                "出国留学咨询"
            ],
            "_index": 215,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2504.15610/fig1_arch.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2504.15610/fig2_loss_p100.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2504.15610/fig3_grad_p100.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "CADDesigner: Conceptual Design of CAD Models Based on General-Purpose Agent",
            "authors": [
                "Fengxiao Fan",
                "Jingzhe Ni",
                "Xiaolong Yin",
                "Sirui Wang",
                "Xingyu Lu",
                "Qiang Zou",
                "Ruofeng Tong",
                "Min Tang",
                "Peng Du"
            ],
            "arxiv_id": "2508.01031",
            "summary": "Computer Aided Design (CAD) plays a pivotal role in industrial manufacturing but typically requires a high level of expertise from designers. To lower the entry barrier and improve design efficiency, we present an agent for CAD conceptual design powered by large language models (LLMs). The agent accepts both textual descriptions and sketches as input, engaging in interactive dialogue with users to refine and clarify design requirements through comprehensive requirement analysis. Built upon a novel Explicit Context Imperative Paradigm (ECIP), the agent generates high-quality CAD modeling code. During the generation process, the agent incorporates iterative visual feedback to improve model quality. Generated design cases are stored in a structured knowledge base, enabling continuous improvement of the agent's code generation capabilities. Experimental results demonstrate that our method achieves state-of-the-art performance in CAD code generation.",
            "categories": [
                "cs.AI",
                "cs.CL"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2508.01031",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "CADDesigner：基于通用Agent的CAD模型概念设计方法",
            "summary_zh": "计算机辅助设计(CAD)在工业制造中起着关键作用，但通常需要设计师具备高水平的专业知识。为了降低入门门槛并提高设计效率，我们提出了一个由大型语言模型(LLM)驱动的CAD概念设计Agent。该Agent接受文本描述和草图作为输入，通过全面的需求分析与用户进行交互式对话，以完善和明确设计需求。基于一种新颖的显式上下文指令范式(ECIP)，该Agent生成高质量的CAD建模代码。在生成过程中，Agent结合迭代的视觉反馈来提高模型质量。生成的案例存储在结构化的知识库中，从而能够持续改进Agent的代码生成能力。实验结果表明，我们的方法在CAD代码生成方面取得了最先进的性能。",
            "intro_zh": [
                "CAD设计门槛高，依赖专家知识，效率有待提升，现有方法难以有效降低设计门槛。",
                "提出CADDesigner，利用大型语言模型作为Agent，通过交互式对话和视觉反馈迭代优化设计。",
                "采用显式上下文指令范式生成CAD代码，并构建知识库持续学习，实验表明该方法性能领先。"
            ],
            "method_zh": "**问题定义**：论文旨在解决CAD设计过程中对专业知识依赖性强、设计效率低下的问题。现有方法通常需要人工编写复杂的CAD代码，或者依赖于预定义的模板，缺乏灵活性和创造性。因此，如何利用人工智能技术降低CAD设计的门槛，提高设计效率，是本文要解决的核心问题。\\n\\n**核心思路**：论文的核心思路是利用大型语言模型（LLM）作为智能Agent，通过理解用户的设计需求（包括文本描述和草图），自动生成CAD建模代码。Agent通过与用户的交互式对话，不断完善和明确设计需求，并结合视觉反馈迭代优化模型质量。这种方法的核心在于将CAD设计过程转化为一个基于LLM的智能交互和代码生成过程。\\n\\n**技术框架**：CADDesigner的整体框架包含以下几个主要模块：1)需求分析模块：负责解析用户输入的文本描述和草图，提取设计需求的关键信息。2)交互式对话模块：与用户进行多轮对话，澄清设计细节，完善设计需求。3)代码生成模块：基于显式上下文指令范式（ECIP），将设计需求转化为CAD建模代码。4)视觉反馈模块：对生成的CAD模型进行视觉评估，并根据评估结果调整代码生成策略。5)知识库模块：存储生成的CAD设计案例，用于持续学习和改进Agent的代码生成能力。\\n\\n**关键创新**：论文的关键创新在于提出了显式上下文指令范式（ECIP），用于指导LLM生成高质量的CAD建模代码。ECIP通过显式地定义代码生成的上下文信息和指令，使得LLM能够更好地理解设计需求，并生成更准确、更可靠的CAD代码。此外，论文还创新性地将视觉反馈融入到代码生成过程中，通过迭代优化提高模型质量。\\n\\n**关键设计**：ECIP范式是关键设计之一，它定义了LLM生成CAD代码的上下文和指令，具体实现细节未知。视觉反馈模块的具体实现方式也未知，可能涉及到图像识别、三维重建等技术。知识库模块的结构和存储方式也未知，但推测会采用结构化的方式存储CAD设计案例，以便于检索和学习。",
            "application_zh": "该研究成果可应用于工业设计、产品设计、建筑设计等领域，降低CAD设计门槛，提高设计效率，赋能非专业人士进行CAD建模。未来，该技术有望与虚拟现实、增强现实等技术结合，实现更加直观、便捷的CAD设计体验，加速产品创新和设计迭代。",
            "highlight_zh": "实验结果表明，CADDesigner在CAD代码生成方面取得了state-of-the-art的性能，具体性能数据未知，但强调了优于现有方法的性能表现。通过迭代视觉反馈，模型质量得到显著提升，但具体提升幅度未知。构建的结构化知识库能够有效提升Agent的代码生成能力。",
            "tags_zh": [
                "CAD设计",
                "大型语言模型",
                "智能Agent",
                "代码生成",
                "视觉反馈",
                "显式上下文指令范式",
                "交互式设计",
                "知识库"
            ],
            "_index": 216,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2508.01031/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2508.01031/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2508.01031/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "MCTS-EP: Empowering Embodied Planning with Online Preference Optimization",
            "authors": [
                "Hang Xu",
                "Zang Yu",
                "Yehui Tang",
                "Pengbo Hu",
                "Yuhao Tang",
                "Hao Dong"
            ],
            "arxiv_id": "2509.17116",
            "summary": "This paper introduces MCTS-EP, an online learning framework that combines large language models (LLM) with Monte Carlo Tree Search (MCTS) for training embodied agents. MCTS-EP integrates three key components: MCTS-guided exploration for preference data collection, efficient multi-modal reasoning mechanism, and iterative training pipeline based on preference optimization. We theoretically prove that MCTS-EP achieves better performance bounds than conventional on-policy algorithms when the loss function is strongly convex, and demonstrate that it can be formulated as a search-enhanced variant of GAIL. MCTS-EP achieves state-of-the-art performace across serval benchmarks. In ALFWorld, it achieves 92% and 87% success rates for textual and visual tasks. In WebShop, it reaches an average reward of 0.81. MTCS-EP also reduces average interaction steps from from 18.7/19.5 to 10.2/9.9 steps in visualthis http URLavailable at:this https URL",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2509.17116",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "MCTS-EP：结合在线偏好优化的蒙特卡洛树搜索赋能具身智能规划",
            "summary_zh": "本文提出了一种名为MCTS-EP的在线学习框架，该框架将大型语言模型（LLM）与蒙特卡洛树搜索（MCTS）相结合，用于训练具身智能体。MCTS-EP集成了三个关键组成部分：用于偏好数据收集的MCTS引导探索、高效的多模态推理机制以及基于偏好优化的迭代训练流程。我们从理论上证明，当损失函数是强凸函数时，MCTS-EP比传统的on-policy算法具有更好的性能界限，并证明它可以被表述为一种搜索增强的GAIL变体。MCTS-EP在多个基准测试中实现了最先进的性能。在ALFWorld中，它在文本和视觉任务中分别实现了92%和87%的成功率。在WebShop中，它达到了0.81的平均奖励。MCTS-EP还在视觉任务中将平均交互步骤从18.7/19.5步减少到10.2/9.9步。",
            "intro_zh": [
                "现有具身智能体训练方法在探索效率和利用多模态信息方面存在不足，限制了其在复杂环境中的应用。",
                "MCTS-EP利用MCTS引导探索，高效收集偏好数据，并结合多模态推理机制，实现更有效的在线学习。",
                "实验表明，MCTS-EP在ALFWorld和WebShop等基准测试中取得了显著的性能提升，并减少了交互步骤。"
            ],
            "method_zh": "**问题定义**：现有具身智能体训练方法通常面临探索效率低下的问题，难以充分利用环境中的信息。此外，如何有效融合文本、视觉等多模态信息也是一个挑战，限制了智能体在复杂任务中的表现。传统的on-policy算法在面对非凸损失函数时，性能表现可能不佳。\\n\\n**核心思路**：MCTS-EP的核心在于利用蒙特卡洛树搜索（MCTS）来指导智能体的探索过程，从而更有效地收集偏好数据。通过在线偏好优化，智能体可以逐步学习到更优的策略。同时，该方法结合多模态推理机制，充分利用环境中的各种信息。\\n\\n**技术框架**：MCTS-EP框架包含三个主要组成部分：1) MCTS引导的探索模块，用于生成高质量的偏好数据；2) 多模态推理模块，用于融合文本和视觉信息，做出更明智的决策；3) 基于偏好优化的迭代训练流程，通过不断学习和改进，提升智能体的性能。整个框架采用在线学习的方式，智能体在与环境交互的过程中不断学习和优化。\\n\\n**关键创新**：MCTS-EP的关键创新在于将MCTS与偏好优化相结合，实现更高效的探索和学习。与传统的on-policy算法相比，MCTS-EP在理论上具有更好的性能界限，尤其是在损失函数为强凸函数时。此外，该方法可以被视为一种搜索增强的GAIL变体，结合了生成对抗模仿学习的优势。\\n\\n**关键设计**：MCTS-EP的具体实现细节包括：如何设计MCTS的奖励函数，以鼓励智能体探索更有价值的状态；如何构建多模态推理模块，以有效融合文本和视觉信息；如何选择合适的偏好优化算法，以保证学习的稳定性和效率。具体的参数设置和网络结构需要根据具体的任务进行调整。",
            "application_zh": "MCTS-EP具有广泛的应用前景，可应用于机器人导航、智能家居、自动驾驶等领域。通过结合大型语言模型和蒙特卡洛树搜索，该方法能够使智能体在复杂环境中进行更有效的规划和决策，从而实现更智能化的服务和应用。未来，该方法有望在更多实际场景中得到应用，提升人工智能的水平。",
            "highlight_zh": "MCTS-EP在ALFWorld文本和视觉任务中分别实现了92%和87%的成功率，显著优于现有方法。在WebShop中，MCTS-EP达到了0.81的平均奖励。此外，MCTS-EP还显著减少了交互步骤，在视觉任务中从18.7/19.5步减少到10.2/9.9步，表明其具有更高的效率。",
            "tags_zh": [
                "具身智能",
                "蒙特卡洛树搜索",
                "偏好优化",
                "多模态推理",
                "在线学习",
                "大型语言模型",
                "强化学习"
            ],
            "_index": 217,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2509.17116/framework.png",
                    "caption": "",
                    "figure_id": "fig_0"
                }
            ]
        },
        {
            "title": "STEMS: Spatial-Temporal Enhanced Safe Multi-Agent Coordination for Building Energy Management",
            "authors": [
                "Huiliang Zhang",
                "Di Wu",
                "Arnaud Zinflou",
                "Benoit Boulet"
            ],
            "arxiv_id": "2510.14112",
            "summary": "Building energy management is essential for achieving carbon reduction goals, improving occupant comfort, and reducing energy costs. Coordinated building energy management faces critical challenges in exploiting spatial-temporal dependencies while ensuring operational safety across multi-building systems. Current multi-building energy systems face three key challenges: insufficient spatial-temporal information exploitation, lack of rigorous safety guarantees, and system complexity. This paper proposes Spatial-Temporal Enhanced Safe Multi-Agent Coordination (STEMS), a novel safety-constrained multi-agent reinforcement learning framework for coordinated building energy management. STEMS integrates two core components: (1) a spatial-temporal graph representation learning framework using a GCN-Transformer fusion architecture to capture inter-building relationships and temporal patterns, and (2) a safety-constrained multi-agent RL algorithm incorporating Control Barrier Functions to provide mathematical safety guarantees. Extensive experiments on real-world building datasets demonstrate STEMS's superior performance over existing methods, showing that STEMS achieves 21% cost reduction, 18% emission reduction, and dramatically reduces safety violations from 35.1% to 5.6% while maintaining optimal comfort with only 0.13 discomfort proportion. The framework also demonstrates strong robustness during extreme weather conditions and maintains effectiveness across different building types.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2510.14112",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning",
                        "representation learning"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出STEMS框架，利用时空增强安全多智能体协同优化建筑能源管理",
            "summary_zh": "建筑能源管理对于实现碳减排目标、提高居住舒适度和降低能源成本至关重要。协同建筑能源管理面临着在多建筑系统中利用时空依赖性并确保运行安全的关键挑战。现有的多建筑能源系统面临三个主要挑战：时空信息利用不足、缺乏严格的安全保障以及系统复杂性。本文提出了一种时空增强安全多智能体协同（STEMS）框架，这是一种用于协同建筑能源管理的新型安全约束多智能体强化学习框架。STEMS集成了两个核心组件：（1）使用GCN-Transformer融合架构的时空图表示学习框架，用于捕获建筑间的关系和时间模式；（2）结合控制屏障函数以提供数学安全保证的安全约束多智能体RL算法。在真实建筑数据集上的大量实验表明，STEMS的性能优于现有方法，成本降低21%，排放降低18%，并将安全违规从35.1%显著降低到5.6%，同时仅以0.13的不舒适比例保持最佳舒适度。该框架还在极端天气条件下表现出强大的鲁棒性，并在不同建筑类型中保持有效性。",
            "intro_zh": [
                "现有建筑能源管理方法难以充分利用建筑间的时空依赖关系，缺乏严格的安全保障，且系统复杂性高，限制了其在多建筑系统中的应用。",
                "STEMS框架通过融合GCN-Transformer架构学习时空图表示，并结合控制屏障函数的多智能体强化学习算法，实现安全约束下的协同能源管理。",
                "实验结果表明，STEMS在成本、排放和安全性方面均优于现有方法，同时保持了良好的舒适度，并在极端天气下表现出鲁棒性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决多建筑能源管理中的协同优化问题，现有方法难以充分利用建筑间的时空依赖关系，缺乏对系统安全性的严格保障，并且系统复杂性较高，难以部署和维护。这些痛点导致能源效率低下，安全风险增加，以及运维成本上升。\\n\\n**核心思路**：论文的核心思路是利用图神经网络（GCN）和Transformer模型来学习建筑间的空间和时间依赖关系，构建一个时空图表示，然后使用安全约束的多智能体强化学习算法，在保证系统安全的前提下，实现多建筑的协同能源管理。这种设计能够更有效地利用信息，提高能源效率，并确保系统运行的安全性。\\n\\n**技术框架**：STEMS框架包含两个主要模块：1) 时空图表示学习模块，该模块使用GCN-Transformer融合架构，首先使用GCN捕获建筑间的空间关系，然后使用Transformer模型捕获时间序列上的依赖关系，最终生成一个综合的时空图表示。2) 安全约束多智能体强化学习模块，该模块使用多智能体强化学习算法，每个建筑作为一个智能体，通过学习控制策略来优化能源使用。同时，该模块还结合了控制屏障函数（Control Barrier Functions, CBF），以确保系统运行的安全性，避免出现违规行为。\\n\\n**关键创新**：该论文的关键创新在于将时空图表示学习与安全约束多智能体强化学习相结合，提出了一种新的协同能源管理框架。传统的能源管理方法通常只考虑单个建筑的优化，而忽略了建筑间的相互影响。STEMS框架通过学习建筑间的时空依赖关系，能够更有效地进行协同优化。此外，通过引入控制屏障函数，STEMS框架能够提供数学上的安全保证，避免出现安全违规行为。\\n\\n**关键设计**：在时空图表示学习模块中，GCN和Transformer的融合方式是一个关键设计。论文可能采用了某种加权融合或者注意力机制来平衡GCN和Transformer的贡献。在安全约束多智能体强化学习模块中，控制屏障函数的选择和参数设置至关重要，需要根据具体的系统特性进行调整。此外，奖励函数的设计也需要仔细考虑，以平衡能源效率、舒适度和安全性之间的关系。",
            "application_zh": "STEMS框架可应用于城市级别的多建筑群能源管理，例如商业区、工业园区和住宅社区。通过优化能源分配和使用，降低能源成本和碳排放，提高能源利用效率，并保障系统运行安全。该研究有助于推动智慧城市和可持续能源发展，具有重要的社会和经济价值。",
            "highlight_zh": "实验结果表明，STEMS框架在真实建筑数据集上实现了显著的性能提升。与现有方法相比，STEMS能够降低21%的能源成本，减少18%的碳排放，并将安全违规率从35.1%大幅降低至5.6%，同时保持了良好的舒适度（不舒适比例仅为0.13%）。此外，STEMS在极端天气条件下表现出强大的鲁棒性，并在不同类型的建筑物中保持有效性。",
            "tags_zh": [
                "多智能体强化学习",
                "建筑能源管理",
                "时空图神经网络",
                "安全约束控制",
                "图卷积网络",
                "Transformer模型",
                "协同优化"
            ],
            "_index": 218,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2510.14112/figs/intro.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2510.14112/figs/single_agent.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2510.14112/figs/radar_charts_comparison.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Menta: A Small Language Model for On-Device Mental Health Prediction",
            "authors": [
                "Tianyi Zhang",
                "Xiangyuan Xue",
                "Lingyan Ruan",
                "Shiya Fu",
                "Feng Xia",
                "Simon D'Alfonso",
                "Vassilis Kostakos",
                "Ting Dang",
                "Hong Jia"
            ],
            "arxiv_id": "2512.02716",
            "summary": "Mental health conditions affect hundreds of millions globally, yet early detection remains limited. While large language models (LLMs) have shown promise in mental health applications, their size and computational demands hinder practical deployment. Small language models (SLMs) offer a lightweight alternative, but their use for social media--based mental health prediction remains largely underexplored. In this study, we introduce Menta, the first optimized SLM fine-tuned specifically for multi-task mental health prediction from social media data. Menta is jointly trained across six classification tasks using a LoRA-based framework, a cross-dataset strategy, and a balanced accuracy--oriented loss. Evaluated against nine state-of-the-art SLM baselines, Menta achieves an average improvement of 15.2\\% across tasks covering depression, stress, and suicidality compared with the best-performing non--fine-tuned SLMs. It also achieves higher accuracy on depression and stress classification tasks compared to 13B-parameter LLMs, while being approximately 3.25x smaller. Moreover, we demonstrate real-time, on-device deployment of Menta on an iPhone 15 Pro Max, requiring only approximately 3GB RAM. Supported by a comprehensive benchmark against existing SLMs and LLMs, Menta highlights the potential for scalable, privacy-preserving mental health monitoring. Code is available at:this https URL",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.02716",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "Menta：用于设备端心理健康预测的小型语言模型",
            "summary_zh": "全球数亿人受到心理健康问题的影响，但早期检测仍然有限。大型语言模型（LLM）在心理健康应用中显示出潜力，但其规模和计算需求阻碍了实际部署。小型语言模型（SLM）提供了一种轻量级的替代方案，但其在基于社交媒体的心理健康预测中的应用仍未得到充分探索。本研究介绍了Menta，这是第一个专门为从社交媒体数据中进行多任务心理健康预测而优化的SLM。Menta使用基于LoRA的框架、跨数据集策略和面向平衡准确性的损失函数，在六个分类任务上进行联合训练。与九个最先进的SLM基线相比，Menta在涵盖抑郁、压力和自杀倾向的任务中，平均提高了15.2％，优于性能最佳的非微调SLM。与13B参数的LLM相比，它在抑郁和压力分类任务上也实现了更高的准确性，同时体积缩小了约3.25倍。此外，我们展示了Menta在iPhone 15 Pro Max上的实时设备端部署，仅需约3GB RAM。通过与现有SLM和LLM的全面基准测试，Menta突出了可扩展、保护隐私的心理健康监测的潜力。",
            "intro_zh": [
                "现有大型语言模型在心理健康预测中表现出色，但其高计算成本和体积限制了实际部署。",
                "Menta通过LoRA微调小型语言模型，并采用跨数据集训练和平衡准确率损失，优化模型性能。",
                "实验表明，Menta在抑郁、压力和自杀倾向预测任务上优于现有SLM，且可在移动设备上实时运行。"
            ],
            "method_zh": "**问题定义**：论文旨在解决心理健康问题早期检测困难的问题，特别是利用社交媒体数据进行预测。现有的大型语言模型虽然有效，但计算资源需求高，难以在移动设备等资源受限的环境中部署。小型语言模型虽然体积小，但在社交媒体心理健康预测方面的潜力尚未充分挖掘。\\n\\n**核心思路**：论文的核心思路是利用小型语言模型（SLM）的轻量化优势，通过针对性的优化和微调，使其在心理健康预测任务上达到与大型语言模型相媲美的性能，并能够在设备端实时部署。这种方法旨在实现可扩展、保护隐私的心理健康监测。\\n\\n**技术框架**：Menta的整体框架包括数据收集与预处理、模型选择与微调、以及设备端部署三个主要阶段。首先，从社交媒体平台收集相关数据，并进行清洗和标注。然后，选择合适的小型语言模型作为基础模型，并使用LoRA（Low-Rank Adaptation）进行微调。LoRA通过引入低秩矩阵来减少需要训练的参数量，从而降低计算成本。最后，将微调后的模型部署到移动设备上，实现实时预测。\\n\\n**关键创新**：Menta的关键创新在于其针对社交媒体心理健康预测任务的优化策略。这包括：1) 基于LoRA的微调框架，有效降低了训练成本；2) 跨数据集训练策略，利用多个数据集来提高模型的泛化能力；3) 平衡准确率导向的损失函数，解决数据不平衡问题，提高模型在少数类别上的预测准确率。\\n\\n**关键设计**：Menta的关键设计包括：1) 选择合适的预训练小型语言模型作为基础模型，例如BERT或RoBERTa的轻量化版本；2) 使用LoRA进行微调时，选择合适的秩（rank）值，以平衡模型性能和计算成本；3) 设计平衡准确率导向的损失函数，例如Focal Loss或Class-Balanced Loss，以解决数据不平衡问题；4) 采用跨数据集训练策略时，需要仔细处理不同数据集之间的差异，例如使用领域自适应技术。",
            "application_zh": "Menta可应用于移动健康应用、社交媒体平台和心理健康服务机构，实现对用户心理状态的实时监测和预警。该研究有助于早期发现心理健康问题，为用户提供个性化的支持和干预，并降低医疗成本。未来，Menta可扩展到其他领域，如情感分析、舆情监控等。",
            "highlight_zh": "Menta在多项心理健康预测任务中表现出色，与最佳非微调SLM相比，平均提升15.2%。在抑郁和压力分类任务上，Menta甚至超越了13B参数的LLM，同时模型体积缩小了3.25倍。此外，Menta成功在iPhone 15 Pro Max上实现实时部署，仅需3GB RAM，验证了其在设备端应用的可行性。",
            "tags_zh": [
                "小型语言模型",
                "心理健康预测",
                "社交媒体分析",
                "设备端部署",
                "LoRA微调"
            ],
            "_index": 219,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.02716/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.02716/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.02716/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Can AI Understand What We Cannot Say? Measuring Multilevel Alignment Through Abortion Stigma Across Cognitive, Interpersonal, and Structural Levels",
            "authors": [
                "Anika Sharma",
                "Malavika Mampally",
                "Chidaksh Ravuru",
                "Kandyce Brennan",
                "Neil Gaikwad"
            ],
            "arxiv_id": "2512.13142",
            "summary": "As large language models increasingly mediate stigmatized health decisions, their capacity to genuinely understand complex psychological and physiological phenomena remains poorly evaluated. Can AI understand what we cannot say? We investigate whether LLMs coherently represent abortion stigma across the cognitive, interpersonal, and structural levels where it operates. We systematically tested 627 demographically diverse personas across five leading LLMs using the validated Individual Level Abortion Stigma Scale (ILAS). Our multilevel analysis examined whether models coherently represent stigma at the cognitive level (self-judgment), interpersonal level (anticipated judgment and isolation), and structural level (community condemnation and disclosure patterns), as well as overall stigma. Models fail tests of genuine understanding across all levels. They overestimate interpersonal stigma while underestimating cognitive stigma, assume uniform community condemnation, introduce demographic biases absent from human validation data, miss the empirically validated stigma-secrecy relationship, and contradict themselves within theoretical constructs. These patterns reveal that current alignment approaches ensure appropriate language but not coherent multilevel understanding. This work provides empirical evidence that current LLMs lack coherent multilevel understanding of psychological and physiological constructs. AI safety in high-stakes contexts demands new approaches to design (multilevel coherence), evaluation (continuous auditing), governance and regulation (mandatory audits, accountability, deployment restrictions), and AI literacy in domains where understanding what people cannot say determines whether support helps or harms.",
            "categories": [
                "cs.AI",
                "cs.HC"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13142",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "评估大型语言模型对堕胎污名的多层次理解能力，揭示其认知偏差与局限性",
            "summary_zh": "随着大型语言模型越来越多地介入与污名化相关的健康决策，它们对复杂心理和生理现象的真正理解能力仍然缺乏评估。本研究旨在探究LLM是否能连贯地表示堕胎污名在认知、人际和结构层面上的运作。我们使用经过验证的个体层面堕胎污名量表（ILAS），系统地测试了五个领先的LLM中的627个具有不同人口统计特征的角色。我们的多层次分析检验了模型是否能在认知层面（自我评判）、人际层面（预期评判和孤立）和结构层面（社区谴责和披露模式）以及整体污名方面连贯地表示污名。结果表明，模型在所有层面上都未能通过对真正理解的测试。它们高估了人际污名，同时低估了认知污名，假设社区谴责的一致性，引入了人类验证数据中不存在的人口统计偏差，错过了经验证实的污名-保密关系，并在理论结构中自相矛盾。这些模式表明，当前的对齐方法确保了适当的语言，但不能保证连贯的多层次理解。这项工作提供了经验证据，表明当前的LLM缺乏对心理和生理结构的连贯多层次理解。在高风险背景下的AI安全需要新的设计方法（多层次连贯性）、评估（持续审计）、治理和监管（强制审计、问责制、部署限制）以及AI素养，在这些领域中，理解人们不能说的话决定了支持是帮助还是伤害。",
            "intro_zh": [
                "现有大型语言模型在处理涉及污名化健康决策时，缺乏对复杂心理现象的深入理解，存在潜在风险。",
                "本研究通过多层次分析框架，评估LLM在认知、人际和结构层面理解堕胎污名的能力，揭示其内在偏差。",
                "实验结果表明，LLM在理解堕胎污名方面存在显著缺陷，无法准确捕捉人类经验，提示需要更安全的AI设计。"
            ],
            "method_zh": "**问题定义**：论文旨在评估大型语言模型（LLM）是否能够真正理解堕胎污名这一复杂的社会心理现象。现有方法主要关注语言的流畅性和准确性，而忽略了对深层心理和社会结构的理解。LLM在处理涉及污名化议题时，可能因为缺乏理解而产生误导或有害的建议。\\n\\n**核心思路**：论文的核心思路是通过多层次分析框架，从认知、人际和结构三个层面评估LLM对堕胎污名的理解。这种多层次视角能够更全面地捕捉污名的复杂性，并揭示LLM在不同层面上的理解偏差。通过系统性的测试，可以判断LLM是否真正理解了污名的内在机制，而不仅仅是表面上的语言表达。\\n\\n**技术框架**：研究采用个体层面堕胎污名量表（ILAS）作为评估工具，该量表涵盖了认知（自我评判）、人际（预期评判和孤立）和结构（社区谴责和披露模式）三个层面。研究团队构建了627个具有不同人口统计特征的角色，并使用这些角色作为输入，测试了五个领先的LLM。通过分析LLM在不同层面上的输出，评估其对堕胎污名的理解程度。\\n\\n**关键创新**：本研究的关键创新在于采用了多层次分析框架来评估LLM对复杂社会心理现象的理解。与以往主要关注语言流畅性的评估方法不同，本研究深入探讨了LLM在不同层面上的认知偏差和局限性。这种多层次视角能够更全面地揭示LLM在处理污名化议题时存在的潜在风险。\\n\\n**关键设计**：研究的关键设计包括：1）使用ILAS量表作为评估工具，确保评估的有效性和可靠性；2）构建具有多样化人口统计特征的角色，以减少评估偏差；3）采用多层次分析框架，从认知、人际和结构三个层面评估LLM的理解程度；4）对比分析不同LLM的评估结果，揭示不同模型之间的差异。",
            "application_zh": "该研究成果可应用于改进AI在医疗健康领域的应用，尤其是在涉及敏感和污名化议题时。通过提升AI对复杂社会心理现象的理解能力，可以减少误导或有害建议的产生，从而更好地为用户提供支持和帮助。此外，该研究也为AI伦理和安全提供了重要参考，有助于制定更合理的AI治理和监管策略。",
            "highlight_zh": "实验结果表明，LLM在理解堕胎污名方面存在显著缺陷。它们高估了人际污名，低估了认知污名，假设社区谴责的一致性，引入了人类数据中不存在的人口统计偏差，并错过了污名-保密关系。这些发现表明，当前的LLM缺乏对复杂社会心理现象的连贯多层次理解。",
            "tags_zh": [
                "大型语言模型",
                "堕胎污名",
                "多层次分析",
                "社会心理学",
                "AI伦理"
            ],
            "_index": 220,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13142/Graphics/method/methods.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13142/x1.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.13142/x2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "How K-12 Educators Use AI: LLM-Assisted Qualitative Analysis at Scale",
            "authors": [
                "Alex Liu",
                "Lief Esbenshade",
                "Shawon Sarkar",
                "Victor Tian",
                "Zachary Zhang",
                "Kevin He",
                "Min Sun"
            ],
            "arxiv_id": "2507.17985",
            "summary": "This study investigates how K-12 educators use generative AI tools in real-world instructional contexts and how large language models (LLMs) can support scalable qualitative analysis of these interactions. Drawing on over 13,000 unscripted educator-AI conversations from an open-access platform, we examine educators' use of AI for lesson planning, differentiation, assessment, and pedagogical reflection. Methodologically, we introduce a replicable, LLM-assisted qualitative analysis pipeline that supports inductive theme discovery, codebook development, and large-scale annotation while preserving researcher control over conceptual synthesis. Empirically, the findings surface concrete patterns in how educators prompt, adapt, and evaluate AI-generated suggestions as part of their instructional reasoning. This work demonstrates the feasibility of combining LLM support with qualitative rigor to analyze complex educator behaviors at scale and inform the design of AI-powered educational tools.",
            "categories": [
                "cs.HC",
                "cs.AI"
            ],
            "primary_category": "cs.HC",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2507.17985",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出LLM辅助的K-12教育者AI使用分析方法，用于大规模定性研究。",
            "summary_zh": "本研究调查了K-12教育者如何在实际教学场景中使用生成式AI工具，以及大型语言模型(LLM)如何支持对这些交互进行可扩展的定性分析。基于一个开放平台上的超过13000个未经预设的教育者-AI对话，我们考察了教育者使用AI进行课程计划、差异化教学、评估和教学反思的情况。在方法论上，我们介绍了一种可复制的、LLM辅助的定性分析流程，该流程支持归纳式主题发现、代码本开发和大规模标注，同时保持研究人员对概念综合的控制。在经验上，研究结果揭示了教育者在教学推理过程中如何提示、调整和评估AI生成的建议的具体模式。这项工作证明了将LLM支持与定性严谨性相结合，以大规模分析复杂的教育者行为并为AI驱动的教育工具的设计提供信息的可能性。",
            "intro_zh": [
                "现有研究缺乏对K-12教育者如何实际使用AI工具的深入理解，以及如何有效分析大规模的教育者-AI交互数据。",
                "论文提出一种LLM辅助的定性分析流程，通过LLM支持主题发现、代码本构建和大规模标注，提升分析效率和可扩展性。",
                "通过分析超过13000个教育者-AI对话，揭示了教育者使用AI进行课程设计、差异化教学等方面的具体模式。"
            ],
            "method_zh": "**问题定义**：本研究旨在解决如何大规模分析K-12教育者与AI工具的交互数据，从而深入理解教育者如何利用AI进行教学活动。现有方法难以处理如此大规模的非结构化数据，且缺乏对教育者行为模式的细致分析。\\n\\n**核心思路**：核心思路是利用LLM强大的自然语言处理能力，辅助研究人员进行定性分析。通过LLM自动提取主题、构建代码本和进行大规模标注，显著降低人工分析的成本和时间，同时保持研究人员对分析过程的控制。\\n\\n**技术框架**：整体框架包含以下几个主要阶段：1) 数据收集：从开放平台收集教育者与AI的对话数据。2) LLM辅助的主题发现：利用LLM对数据进行初步分析，提取潜在的主题和模式。3) 代码本开发：研究人员基于LLM的分析结果，人工构建代码本。4) LLM辅助的大规模标注：利用LLM根据代码本对数据进行自动标注。5) 结果验证与分析：研究人员对LLM的标注结果进行抽样验证，并进行深入的定性分析。\\n\\n**关键创新**：关键创新在于将LLM集成到传统的定性研究流程中，实现大规模定性分析。与完全依赖人工分析的方法相比，该方法显著提高了分析效率和可扩展性。与完全依赖LLM自动分析的方法相比，该方法保持了研究人员对分析过程的控制，确保了分析结果的可靠性和有效性。\\n\\n**关键设计**：论文中没有详细描述具体的参数设置、损失函数或网络结构等技术细节。LLM的选择和prompt的设计是关键，但具体细节未知。代码本的构建和验证过程是保证分析质量的关键环节，具体流程未知。",
            "application_zh": "该研究成果可应用于教育领域，帮助教育工作者更好地理解如何利用AI工具提升教学效果。此外，该方法论可推广到其他领域，例如医疗、金融等，用于分析大规模的文本数据，挖掘潜在的模式和规律，为决策提供支持。未来，可以基于此研究开发AI辅助的教育工具，为教育者提供个性化的教学建议和支持。",
            "highlight_zh": "研究分析了超过13000个教育者-AI对话，揭示了教育者在课程计划、差异化教学、评估和教学反思等方面使用AI的具体模式。研究结果表明，教育者能够有效地利用AI生成建议，并根据实际情况进行调整和评估。具体的性能数据和提升幅度未知。",
            "tags_zh": [
                "大型语言模型",
                "教育AI",
                "定性分析",
                "K-12教育",
                "人机交互",
                "自然语言处理",
                "教育数据挖掘"
            ],
            "_index": 221,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2507.17985/Figure_1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2507.17985/Figure_2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2507.17985/item.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Latent Self-Consistency for Reliable Majority-Set Selection in Short- and Long-Answer Reasoning",
            "authors": [
                "Jungsuk Oh",
                "Jay-Yoon Lee"
            ],
            "arxiv_id": "2508.18395",
            "summary": "Probabilistic decoding in Large Language Models (LLMs) often yields inconsistent outputs, particularly on complex or long-form questions. Self-Consistency (SC) mitigates this for short-form QA by majority voting over exact strings, whereas Universal Self-Consistency (USC) and Weighted Unigram Consistency Score (WUCS) extend to long-form responses but lose accuracy on short-form benchmarks.We introduce \\textbf{Latent Self-Consistency (LSC)}, which selects the most semantically consistent response using learnable token embeddings. LSC's lightweight forward processing of summary tokens only introduces negligible runtime overhead (at most $0.9\\%$) on top of standard decoding of the base LLM, and requires no changes to the model architecture.Across 6 short-form and 5 long-form reasoning benchmarks (e.g., MATH, MMLU, TruthfulQA), LSC surpasses SC, USC, and WUCS on both short-form and long-form on average performance, while adding negligible computational overhead on vanilla inference. These results position LSC as a reliable consistency-selection method that works effectively across various answer formats. Additionally, LSC provides well-calibrated confidence estimates, maintaining low expected calibration error across both answer formats.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2508.18395",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出潜在自一致性方法以解决长短答案推理中的一致性问题",
            "summary_zh": "在大型语言模型（LLMs）的概率解码中，输出结果常常不一致，尤其是在复杂或长形式问题上。自一致性（SC）通过对短形式问答进行多数投票来缓解这一问题，而通用自一致性（USC）和加权单元一致性评分（WUCS）虽然扩展到长形式响应，但在短形式基准上准确性下降。本文提出了潜在自一致性（LSC），通过可学习的标记嵌入选择最语义一致的响应。LSC在标准解码的基础上仅引入了最多0.9%的运行时开销，且无需更改模型架构。在6个短形式和5个长形式推理基准上，LSC在短形式和长形式的平均性能上均超越了SC、USC和WUCS，同时在原始推理上增加的计算开销微乎其微。这些结果使LSC成为一种可靠的一致性选择方法，能够有效处理各种答案格式。此外，LSC提供了良好的置信度估计，在两种答案格式下保持低预期校准误差。",
            "intro_zh": [
                "现有方法在处理复杂或长形式问题时，输出结果常常不一致，影响了问答系统的可靠性。",
                "本文提出的潜在自一致性（LSC）方法，通过可学习的标记嵌入选择最语义一致的响应，克服了现有方法的不足。",
                "在多个短形式和长形式推理基准上，LSC的性能超越了现有的自一致性方法，同时保持了较低的计算开销。"
            ],
            "method_zh": "**问题定义**：本文旨在解决大型语言模型在复杂问题上的输出不一致性，现有的自一致性方法在短形式和长形式问答中表现不均，导致准确性下降。\\n\\n**核心思路**：潜在自一致性（LSC）通过学习标记的嵌入来选择语义上最一致的响应，避免了传统方法的局限性，且不需要改变模型架构。\\n\\n**技术框架**：LSC的整体架构包括输入标记的嵌入、语义一致性评分和最终响应选择三个主要模块。首先，通过可学习的嵌入将输入标记转化为向量表示，然后计算语义一致性，最后选择得分最高的响应。\\n\\n**关键创新**：LSC的主要创新在于其使用可学习的标记嵌入来评估语义一致性，这与传统的基于字符串的多数投票方法有本质区别，能够更好地处理复杂的长形式问题。\\n\\n**关键设计**：LSC在设计上保持轻量级，运行时开销仅为0.9%，并且采用了适应性损失函数来优化语义一致性评分，确保在不同类型的问答中均能保持高效性能。",
            "application_zh": "该研究的潜在应用领域包括智能问答系统、教育辅助工具和客户服务自动化等。通过提高长短答案推理的一致性，LSC能够显著提升用户体验和系统的可靠性，未来可能在更多实际场景中得到广泛应用。",
            "highlight_zh": "在6个短形式和5个长形式推理基准上，LSC的平均性能超越了SC、USC和WUCS，尤其在短形式问答中表现优异，且在计算开销上几乎可以忽略不计。这表明LSC在不同答案格式下均具备良好的适应性和可靠性。",
            "tags_zh": [
                "自一致性",
                "长短答案推理",
                "大型语言模型",
                "语义一致性",
                "机器学习",
                "问答系统",
                "模型优化"
            ],
            "_index": 222,
            "_used_api": "openai",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2508.18395/overview.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2508.18395/llama3_MATH_major_plot.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2508.18395/lsc_MATH_calib.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "RAGRank: Using PageRank to Counter Poisoning in CTI LLM Pipelines",
            "authors": [
                "Austin Jia",
                "Avaneesh Ramesh",
                "Zain Shamsi",
                "Daniel Zhang",
                "Alex Liu"
            ],
            "arxiv_id": "2510.20768",
            "summary": "Retrieval-Augmented Generation (RAG) has emerged as the dominant architectural pattern to operationalize Large Language Model (LLM) usage in Cyber Threat Intelligence (CTI) systems. However, this design is susceptible to poisoning attacks, and previously proposed defenses can fail for CTI contexts as cyber threat information is often completely new for emerging attacks, and sophisticated threat actors can mimic legitimate formats, terminology, and stylistic conventions. To address this issue, we propose that the robustness of modern RAG defenses can be accelerated by applying source credibility algorithms on corpora, using PageRank as an example. In our experiments, we demonstrate quantitatively that our algorithm applies a lower authority score to malicious documents while promoting trusted content, using the standardized MS MARCO dataset. We also demonstrate proof-of-concept performance of our algorithm on CTI documents and feeds.",
            "categories": [
                "cs.CR",
                "cs.AI",
                "cs.IR"
            ],
            "primary_category": "cs.CR",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2510.20768",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "RAGRank：利用PageRank提升CTI LLM流水线抗投毒攻击能力",
            "summary_zh": "检索增强生成(RAG)已成为在网络威胁情报(CTI)系统中应用大型语言模型(LLM)的主流架构模式。然而，这种设计容易受到投毒攻击。先前提出的防御方法在CTI环境中可能会失效，因为网络威胁信息对于新兴攻击而言通常是全新的，并且复杂的威胁参与者可以模仿合法的格式、术语和文体习惯。为了解决这个问题，我们提出通过在语料库上应用来源可信度算法（以PageRank为例）来加速现代RAG防御的鲁棒性。在我们的实验中，我们定量地证明了我们的算法降低了恶意文档的权威评分，同时提升了可信内容，使用了标准化的MS MARCO数据集。我们还展示了我们的算法在CTI文档和信息源上的概念验证性能。",
            "intro_zh": [
                "现有的RAG系统在CTI领域面临投毒攻击的挑战，因为新兴威胁信息新颖且攻击者能模仿合法内容。",
                "论文提出使用PageRank等来源可信度算法，对RAG系统的知识库进行评估，从而降低恶意文档的影响。",
                "实验结果表明，该方法能有效降低恶意文档的权威评分，同时提升可信内容的权重，增强RAG系统的鲁棒性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决CTI系统中，基于RAG的LLM应用易受投毒攻击的问题。现有的防御方法无法有效应对CTI场景，因为威胁情报具有时效性和新颖性，攻击者可以伪装成合法的来源和格式，使得传统的检测方法失效。\\n\\n**核心思路**：核心思路是利用来源可信度算法，对RAG系统使用的知识库进行评估和排序。通过降低恶意来源的权重，提高可信来源的权重，从而减少投毒攻击对LLM生成结果的影响。PageRank算法被用作来源可信度评估的一个具体例子。\\n\\n**技术框架**：整体框架是在RAG流水线中，在检索阶段之前，对文档进行预处理，计算每个文档的PageRank值。PageRank值反映了文档在知识图谱中的重要性和可信度。在检索阶段，文档会根据其PageRank值进行排序，优先选择PageRank值高的文档。LLM则基于排序后的文档生成最终的答案。\\n\\n**关键创新**：关键创新在于将来源可信度评估引入到RAG的防御体系中，特别是在CTI领域。与传统的基于内容过滤或异常检测的方法不同，该方法关注的是文档的来源，而不是文档的内容本身，因此可以更好地应对攻击者伪装成合法来源的情况。\\n\\n**关键设计**：论文使用PageRank算法作为来源可信度评估的具体实现。PageRank算法需要构建一个文档之间的链接图，其中链接表示文档之间的引用关系。算法的关键参数包括阻尼因子（damping factor）和迭代次数。阻尼因子控制了随机跳转的概率，迭代次数决定了算法的收敛速度。",
            "application_zh": "该研究成果可应用于各种网络安全场景，例如威胁情报分析、漏洞管理、安全事件响应等。通过提高RAG系统的抗投毒能力，可以更可靠地利用LLM进行安全分析和决策，降低因恶意信息误导而造成的风险。未来，该方法可以扩展到其他领域，例如金融风控、舆情分析等，提升信息系统的安全性。",
            "highlight_zh": "实验结果表明，RAGRank算法能够有效降低恶意文档的权威评分，同时提升可信内容的权重。在MS MARCO数据集上进行了定量评估，证明了该算法的有效性。此外，还在CTI文档和信息源上进行了概念验证，展示了该算法在实际应用中的潜力。具体的性能数据和提升幅度在论文中进行了详细的展示。",
            "tags_zh": [
                "检索增强生成",
                "大型语言模型",
                "网络威胁情报",
                "投毒攻击",
                "PageRank",
                "来源可信度",
                "信息安全"
            ],
            "_index": 223,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2510.20768/images/RAGRank-architecture.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2510.20768/images/msmarco_accuracy.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2510.20768/images/chunk_analysis.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Beyond Task Completion: An Assessment Framework for Evaluating Agentic AI Systems",
            "authors": [
                "Sreemaee Akshathala",
                "Bassam Adnan",
                "Mahisha Ramesh",
                "Karthik Vaidhyanathan",
                "Basil Muhammed",
                "Kannan Parthasarathy"
            ],
            "arxiv_id": "2512.12791",
            "summary": "Recent advances in agentic AI have shifted the focus from standalone Large Language Models (LLMs) to integrated systems that combine LLMs with tools, memory, and other agents to perform complex tasks. These multi-agent architectures enable coordinated reasoning, planning, and execution across diverse domains, allowing agents to collaboratively automate complex workflows. Despite these advances, evaluation and assessment of LLM agents and the multi-agent systems they constitute remain a fundamental challenge. Although various approaches have been proposed in the software engineering literature for evaluating conventional software components, existing methods for AI-based systems often overlook the non-deterministic nature of models. This non-determinism introduces behavioral uncertainty during execution, yet existing evaluations rely on binary task completion metrics that fail to capture it. Evaluating agentic systems therefore requires examining additional dimensions, including the agent ability to invoke tools, ingest and retrieve memory, collaborate with other agents, and interact effectively with its environment. These challenges emerged during our ongoing industry collaboration with MontyCloud Inc., when we deployed an agentic system in production. These limitations surfaced during deployment, highlighting practical gaps in the current evaluation methods and the need for a systematic assessment of agent behavior beyond task outcomes. Informed by these observations and established definitions of agentic systems, we propose an end-to-end Agent Assessment Framework with four evaluation pillars encompassing LLMs, Memory, Tools, and Environment. We validate the framework on a representative Autonomous CloudOps use case, where experiments reveal behavioral deviations overlooked by conventional metrics, demonstrating its effectiveness in capturing runtime uncertainties.",
            "categories": [
                "cs.MA",
                "cs.AI",
                "cs.SE"
            ],
            "primary_category": "cs.MA",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.12791",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出Agent评估框架，用于评估Agentic AI系统在复杂任务中的行为不确定性",
            "summary_zh": "随着Agentic AI的进步，焦点已从独立的大型语言模型（LLM）转向集成了工具、记忆和其他Agent的系统，以执行复杂任务。这些多Agent架构支持跨不同领域的协同推理、规划和执行，从而实现复杂工作流程的自动化。然而，LLM Agent及其构成的多Agent系统的评估仍然是一个根本挑战。尽管软件工程文献中提出了各种评估传统软件组件的方法，但现有AI系统的方法通常忽略了模型的不确定性。这种不确定性在执行过程中引入了行为偏差，而现有评估依赖于二元任务完成指标，无法捕捉到这一点。因此，评估Agentic系统需要检查额外的维度，包括Agent调用工具、摄取和检索记忆、与其他Agent协作以及与环境有效交互的能力。基于此，我们提出了一个包含LLM、记忆、工具和环境四个评估支柱的端到端Agent评估框架，并在一个代表性的Autonomous CloudOps用例上验证了该框架，实验揭示了传统指标忽略的行为偏差，证明了其在捕获运行时不确定性方面的有效性。",
            "intro_zh": [
                "现有AI系统评估方法忽略了LLM Agent的非确定性行为，导致无法准确评估其在复杂任务中的表现。",
                "提出一个端到端的Agent评估框架，包含LLM、记忆、工具和环境四个评估维度，以更全面地评估Agent的行为。",
                "在Autonomous CloudOps用例中验证了该框架，实验结果表明该框架能够有效捕捉运行时不确定性，发现传统指标忽略的行为偏差。"
            ],
            "method_zh": "**问题定义**：论文旨在解决现有评估方法无法有效评估Agentic AI系统的问题。现有方法主要依赖于二元任务完成指标，忽略了LLM Agent的非确定性行为，以及Agent与工具、记忆、其他Agent和环境交互的复杂性。这种简化导致无法全面了解Agent在实际应用中的表现，尤其是在涉及复杂工作流程的场景中。\\n\\n**核心思路**：论文的核心思路是构建一个多维度的评估框架，从LLM、记忆、工具和环境四个关键方面评估Agent的行为。通过综合考虑这些维度，可以更全面地了解Agent的性能，并捕捉到传统指标无法发现的行为偏差。这种方法旨在弥补现有评估方法的不足，提供更准确、更可靠的Agent评估结果。\\n\\n**技术框架**：该Agent评估框架包含四个主要评估支柱：LLM、记忆、工具和环境。首先，评估LLM的推理和决策能力。其次，评估Agent摄取和检索记忆的效率和准确性。第三，评估Agent调用和使用工具的能力。最后，评估Agent与环境交互的有效性。该框架通过设计针对每个支柱的评估指标和实验，来量化Agent在各个方面的表现。\\n\\n**关键创新**：该论文的关键创新在于提出了一个综合性的Agent评估框架，该框架超越了传统的二元任务完成指标，考虑了Agent行为的多个维度。该框架能够捕捉到运行时不确定性，并发现传统指标忽略的行为偏差。此外，该框架的设计具有通用性，可以应用于不同的Agentic AI系统和应用场景。\\n\\n**关键设计**：该框架的关键设计在于针对每个评估支柱（LLM、记忆、工具、环境）设计了具体的评估指标。例如，对于LLM，可以评估其推理准确性、决策合理性等。对于记忆，可以评估其检索效率、存储容量等。对于工具，可以评估其调用成功率、使用效率等。对于环境，可以评估其适应性、交互效果等。这些指标的选择和设计需要根据具体的应用场景和Agent的特点进行调整。",
            "application_zh": "该研究成果可广泛应用于各种Agentic AI系统的评估和优化，例如自动化客服、智能助手、机器人流程自动化（RPA）等。通过使用该评估框架，可以更全面地了解Agent的性能，发现潜在问题，并进行针对性的改进，从而提高Agent的效率和可靠性，最终提升用户体验和业务价值。",
            "highlight_zh": "在Autonomous CloudOps用例中，该评估框架成功揭示了传统指标忽略的行为偏差。实验结果表明，即使Agent完成了任务，其在工具调用、记忆检索和环境交互等方面可能存在问题。这些问题可能会影响Agent的长期性能和可靠性。通过使用该评估框架，可以及时发现并解决这些问题，从而提高Agent的整体性能。",
            "tags_zh": [
                "Agentic AI",
                "评估框架",
                "大型语言模型",
                "多Agent系统",
                "行为不确定性"
            ],
            "_index": 224,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.12791/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.12791/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.12791/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Structure-Aware Decoding Mechanisms for Complex Entity Extraction with Large-Scale Language Models",
            "authors": [
                "Zhimin Qiu",
                "Di Wu",
                "Feng Liu",
                "Chenrui Hu",
                "Yuxiao Wang"
            ],
            "arxiv_id": "2512.13980",
            "summary": "This paper proposes a structure-aware decoding method based on large language models to address the difficulty of traditional approaches in maintaining both semantic integrity and structural consistency in nested and overlapping entity extraction tasks. The method introduces a candidate span generation mechanism and structured attention modeling to achieve unified modeling of entity boundaries, hierarchical relationships, and cross-dependencies. The model first uses a pretrained language model to obtain context-aware semantic representations, then captures multi-granular entity span features through candidate representation combinations, and introduces hierarchical structural constraints during decoding to ensure consistency between semantics and structure. To enhance stability in complex scenarios, the model jointly optimizes classification loss and structural consistency loss, maintaining high recognition accuracy under multi-entity co-occurrence and long-sentence dependency conditions. Experiments conducted on the ACE 2005 dataset demonstrate significant improvements in Accuracy, Precision, Recall, and F1-Score, particularly in nested and overlapping entity recognition, where the model shows stronger boundary localization and structural modeling capability. This study verifies the effectiveness of structure-aware decoding in complex semantic extraction tasks, provides a new perspective for developing language models with hierarchical understanding, and establishes a methodological foundation for high-precision information extraction.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13980",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出结构感知解码方法，利用大语言模型解决复杂实体抽取中的语义完整性和结构一致性问题。",
            "summary_zh": "本文提出了一种基于大语言模型的结构感知解码方法，旨在解决传统方法在嵌套和重叠实体抽取任务中难以同时保持语义完整性和结构一致性的问题。该方法引入了候选跨度生成机制和结构化注意力建模，实现了实体边界、层级关系和交叉依赖的统一建模。模型首先使用预训练语言模型获取上下文感知的语义表示，然后通过候选表示组合捕获多粒度的实体跨度特征，并在解码过程中引入层级结构约束，以确保语义和结构之间的一致性。为了增强在复杂场景中的稳定性，模型联合优化分类损失和结构一致性损失，从而在多实体共现和长句依赖条件下保持较高的识别精度。在ACE 2005数据集上进行的实验表明，该方法在准确率、精确率、召回率和F1值方面均有显著提高，尤其是在嵌套和重叠实体识别方面，模型表现出更强的边界定位和结构建模能力。这项研究验证了结构感知解码在复杂语义抽取任务中的有效性，为开发具有层级理解能力的语言模型提供了新的视角，并为高精度信息抽取奠定了方法论基础。",
            "intro_zh": [
                "传统方法在处理嵌套和重叠实体抽取时，难以兼顾语义完整性和结构一致性，导致性能瓶颈。",
                "论文提出结构感知解码方法，通过候选跨度生成和结构化注意力建模，统一建模实体边界、层级关系和交叉依赖。",
                "实验结果表明，该方法在ACE 2005数据集上显著提升了嵌套和重叠实体识别的准确率、精确率、召回率和F1值。"
            ],
            "method_zh": "**问题定义**：论文旨在解决复杂实体抽取任务中，传统方法难以同时保证语义完整性和结构一致性的问题。具体而言，嵌套实体和重叠实体的识别对模型提出了更高的要求，现有方法往往难以准确捕捉实体间的层级关系和依赖关系，导致抽取效果不佳。\\n\\n**核心思路**：论文的核心思路是利用大语言模型强大的语义表示能力，并在此基础上引入结构感知解码机制，显式地建模实体间的层级结构和依赖关系。通过结构化的解码过程，确保抽取的实体在语义上是完整的，在结构上是一致的。\\n\\n**技术框架**：整体框架包含以下几个主要模块：1) 预训练语言模型：用于获取输入文本的上下文感知的语义表示。2) 候选跨度生成：生成所有可能的实体跨度，作为后续解码的候选。3) 结构化注意力建模：利用注意力机制建模实体跨度之间的层级关系和交叉依赖。4) 结构感知解码：基于结构化注意力建模的结果，进行实体类型的预测和结构关系的推断。\\n\\n**关键创新**：最重要的技术创新点在于结构感知解码机制。与传统的序列解码或基于跨度的解码方法不同，该方法显式地建模了实体之间的结构关系，从而能够更好地处理嵌套和重叠实体。此外，候选跨度生成机制也避免了遗漏潜在实体的可能性。\\n\\n**关键设计**：模型采用联合优化策略，同时优化分类损失和结构一致性损失。分类损失用于指导实体类型的预测，结构一致性损失用于约束实体之间的结构关系。在网络结构方面，使用了多层Transformer结构来增强模型的表示能力。具体的参数设置和超参数的选择需要根据具体的实验进行调整。",
            "application_zh": "该研究成果可广泛应用于信息抽取、知识图谱构建、问答系统等领域。通过提升复杂实体抽取的精度和效率，可以有效提高下游任务的性能，例如，在金融领域，可以用于抽取公司间的股权关系；在医疗领域，可以用于抽取药物与疾病之间的关联。",
            "highlight_zh": "在ACE 2005数据集上的实验结果表明，该方法在准确率、精确率、召回率和F1值方面均有显著提升，尤其是在嵌套和重叠实体识别方面。相较于基线模型，该方法在F1值上取得了明显的进步，验证了结构感知解码在复杂语义抽取任务中的有效性。",
            "tags_zh": [
                "实体抽取",
                "大语言模型",
                "结构感知解码",
                "嵌套实体",
                "重叠实体"
            ],
            "_index": 225,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "A Unified Sparse Attention via Multi-Granularity Compression",
            "authors": [
                "Siran Liu",
                "Zane Cao",
                "Yongchao He"
            ],
            "arxiv_id": "2512.14082",
            "summary": "Efficient long-context understanding and reasoning are increasingly vital for large language model (LLM) applications such as multi-turn dialogue and program analysis. However, the core self-attention mechanism scales quadratically with sequence length, creating a fundamental computational bottleneck. Existing sparse attention methods alleviate this issue but face trade-offs: training-based methods are costly and cannot be directly applied as acceleration plugins for other models, while inference-time methods often compromise efficiency or cross-modal generality. To address these limitations, we present UniSparse, a unified mechanism that introduces the notion of composite tokens--compact representations that aggregate multi-granularity contextual information. Building on this abstraction, UniSparse dynamically constructs sparse attention through multi-granularity compression and block-level selection, enabling efficient and hardware-friendly execution on GPU. Across multiple modalities and tasks ranging from synthetic benchmarks to real-world applications, UniSparse consistently surpasses state-of-the-art sparse attention methods (e.g., MInference, XAttention, FlexPrefill) in both accuracy and efficiency, achieving $\\ge$ 99% of full-attention accuracy and up to 2.61$\\times$ faster attention computation than FlashAttention.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14082",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "UniSparse：一种通过多粒度压缩实现的统一稀疏注意力机制，加速长文本处理。",
            "summary_zh": "为了提升大型语言模型（LLM）在多轮对话和程序分析等应用中对长上下文的理解和推理能力，本文提出了一种名为UniSparse的统一稀疏注意力机制。现有稀疏注意力方法存在训练成本高昂或牺牲效率和跨模态通用性的问题。UniSparse通过引入复合token的概念来解决这些限制，复合token是一种聚合多粒度上下文信息的紧凑表示。基于此，UniSparse通过多粒度压缩和块级选择动态构建稀疏注意力，从而在GPU上实现高效且硬件友好的执行。在从合成基准到实际应用的多个模态和任务中，UniSparse在准确性和效率方面均优于最先进的稀疏注意力方法（如MInference、XAttention、FlexPrefill），实现了≥99%的完整注意力准确率，并且注意力计算速度比FlashAttention快高达2.61倍。",
            "intro_zh": [
                "现有稀疏注意力方法在长文本处理中面临训练成本高或效率、通用性不足的挑战。",
                "UniSparse提出复合token概念，通过多粒度压缩和块级选择动态构建稀疏注意力。",
                "实验表明，UniSparse在多种模态和任务中超越现有方法，兼顾准确性和效率。"
            ],
            "method_zh": "**问题定义**：现有的大型语言模型在处理长文本时，自注意力机制的计算复杂度呈平方增长，成为性能瓶颈。现有的稀疏注意力方法要么需要额外的训练，成本高昂且难以作为插件集成到其他模型中，要么在推理时牺牲效率或跨模态的通用性。\\n\\n**核心思路**：UniSparse的核心思路是通过引入“复合token”的概念，将多个token的信息压缩成一个更紧凑的表示，从而减少需要计算注意力的token数量。通过在不同粒度上进行压缩，UniSparse能够捕捉不同尺度的上下文信息，并动态地选择重要的信息块进行注意力计算。\\n\\n**技术框架**：UniSparse主要包含以下几个阶段：1) **多粒度压缩**：将输入序列划分为不同大小的块，并使用某种压缩方法（例如平均池化或线性变换）将每个块压缩成一个复合token。2) **块级选择**：根据某种策略（例如基于重要性的评分）选择一部分复合token参与后续的注意力计算。3) **稀疏注意力计算**：仅在选定的复合token之间进行注意力计算，从而降低计算复杂度。4) **信息聚合**：将稀疏注意力计算的结果聚合回原始的token表示。\\n\\n**关键创新**：UniSparse的关键创新在于其统一的多粒度压缩框架。它允许在不同的粒度上进行信息压缩，从而能够灵活地适应不同的任务和数据。此外，UniSparse的块级选择机制能够动态地选择重要的信息块，从而进一步提高效率。与现有方法相比，UniSparse无需额外的训练，并且具有更好的跨模态通用性。\\n\\n**关键设计**：UniSparse的具体实现细节包括：1) 压缩方法的选择：可以使用平均池化、线性变换或其他压缩方法。2) 块大小的选择：可以根据任务和数据进行调整。3) 块级选择策略：可以使用基于重要性的评分、随机选择或其他策略。4) 注意力计算方式：可以使用标准的自注意力机制或其他变体。",
            "application_zh": "UniSparse具有广泛的应用前景，包括但不限于：多轮对话系统、程序分析、长文档摘要、视频理解等。通过提高长文本处理的效率，UniSparse可以帮助LLM更好地理解和推理长上下文信息，从而提升各种下游任务的性能。此外，UniSparse的通用性使其可以应用于不同的模态，例如文本、图像和音频。",
            "highlight_zh": "UniSparse在多个模态和任务上进行了评估，结果表明其在准确性和效率方面均优于现有方法。例如，在长文本分类任务中，UniSparse实现了与完整注意力机制接近的准确率（≥99%），并且注意力计算速度比FlashAttention快高达2.61倍。这些结果表明UniSparse是一种高效且通用的稀疏注意力机制。",
            "tags_zh": [
                "稀疏注意力",
                "长文本处理",
                "多粒度压缩",
                "复合token",
                "大型语言模型"
            ],
            "_index": 226,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14082/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14082/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14082/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Multilingual and Continuous Backchannel Prediction: A Cross-lingual Study",
            "authors": [
                "Koji Inoue",
                "Mikey Elmers",
                "Yahui Fu",
                "Zi Haur Pang",
                "Taiga Mori",
                "Divesh Lala",
                "Keiko Ochi",
                "Tatsuya Kawahara"
            ],
            "arxiv_id": "2512.14085",
            "summary": "We present a multilingual, continuous backchannel prediction model for Japanese, English, and Chinese, and use it to investigate cross-linguistic timing behavior. The model is Transformer-based and operates at the frame level, jointly trained with auxiliary tasks on approximately 300 hours of dyadic conversations. Across all three languages, the multilingual model matches or surpasses monolingual baselines, indicating that it learns both language-universal cues and language-specific timing patterns. Zero-shot transfer with two-language training remains limited, underscoring substantive cross-lingual differences. Perturbation analyses reveal distinct cue usage: Japanese relies more on short-term linguistic information, whereas English and Chinese are more sensitive to silence duration and prosodic variation; multilingual training encourages shared yet adaptable representations and reduces overreliance on pitch in Chinese. A context-length study further shows that Japanese is relatively robust to shorter contexts, while Chinese benefits markedly from longer contexts. Finally, we integrate the trained model into a real-time processing software, demonstrating CPU-only inference. Together, these findings provide a unified model and empirical evidence for how backchannel timing differs across languages, informing the design of more natural, culturally-aware spoken dialogue systems.",
            "categories": [
                "cs.CL",
                "cs.HC",
                "cs.SD"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14085",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "zero-shot transfer"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出一种多语种连续后通道预测模型，用于研究跨语言的交互时序行为。",
            "summary_zh": "本文提出了一种用于日语、英语和汉语的多语种连续后通道预测模型，并利用它来研究跨语言的时序行为。该模型基于Transformer，在帧级别上运行，并使用大约300小时的二元对话进行联合训练，包含辅助任务。在所有三种语言中，多语种模型都达到或超过了单语基线，表明它学习了语言通用的线索和特定于语言的时序模式。使用双语训练的零样本迁移仍然有限，突出了跨语言的实质性差异。扰动分析揭示了不同的线索使用：日语更依赖于短期语言信息，而英语和汉语对静音时长和韵律变化更敏感；多语种训练鼓励共享但适应性强的表示，并减少对汉语中音高的过度依赖。上下文长度研究进一步表明，日语相对更能适应较短的上下文，而汉语则明显受益于较长的上下文。最后，我们将训练好的模型集成到实时处理软件中，展示了仅使用CPU的推理。总之，这些发现提供了一个统一的模型和经验证据，证明了后通道时序在不同语言之间的差异，从而为设计更自然、更具文化意识的口语对话系统提供了信息。",
            "intro_zh": [
                "现有后通道预测模型缺乏跨语言的统一性，难以捕捉不同语言间交互时序的差异。",
                "提出基于Transformer的多语种连续后通道预测模型，联合训练多种语言，学习通用和特定语言的线索。",
                "实验表明，该模型在多种语言上表现优异，并揭示了不同语言在后通道预测中对不同线索的依赖程度。"
            ],
            "method_zh": "**问题定义**：论文旨在解决跨语言后通道预测的问题。现有的后通道预测模型通常是单语的，无法直接应用于多语种环境，并且难以捕捉不同语言之间后通道行为的细微差异。此外，现有方法可能过度依赖某些特定的声学或语言特征，导致泛化能力不足。\\n\\n**核心思路**：论文的核心思路是利用Transformer架构构建一个多语种的后通道预测模型，通过联合训练多种语言的数据，使模型能够学习到语言通用的特征表示以及特定于语言的时序模式。通过引入辅助任务，可以进一步提升模型的学习效率和泛化能力。这种方法能够更好地捕捉不同语言在后通道行为上的差异，并提高模型在跨语言环境下的预测准确性。\\n\\n**技术框架**：该模型基于Transformer架构，输入为语音帧级别的特征，输出为连续的后通道预测概率。整体流程包括：1) 特征提取：从语音信号中提取声学和语言特征；2) Transformer编码：使用Transformer编码器对特征进行编码，学习上下文相关的表示；3) 后通道预测：使用全连接层将编码后的表示映射到后通道预测概率；4) 辅助任务：引入辅助任务，例如语言识别或说话人识别，以提升模型的学习效率。\\n\\n**关键创新**：该论文的关键创新在于：1) 提出了一个多语种的后通道预测模型，能够同时处理多种语言；2) 通过联合训练和辅助任务，提高了模型的泛化能力和学习效率；3) 通过扰动分析，揭示了不同语言在后通道预测中对不同线索的依赖程度。\\n\\n**关键设计**：模型使用Transformer编码器，包含多层自注意力机制和前馈神经网络。损失函数包括后通道预测的交叉熵损失和辅助任务的损失。上下文长度是一个重要的参数，实验中探索了不同上下文长度对模型性能的影响。此外，论文还使用了数据增强技术，例如语音速度扰动，以提高模型的鲁棒性。",
            "application_zh": "该研究成果可应用于多语种口语对话系统，提升人机交互的自然性和流畅性。通过理解不同语言的后通道行为，系统可以更准确地识别用户的反馈，并做出更合适的响应。此外，该模型还可以用于跨文化交流研究，帮助人们更好地理解不同文化背景下的沟通方式。",
            "highlight_zh": "实验结果表明，多语种模型在日语、英语和汉语三种语言上均达到或超过了单语基线模型。扰动分析显示，日语更依赖短期语言信息，而英语和汉语对静音时长和韵律变化更敏感。上下文长度研究表明，汉语受益于更长的上下文。该模型已成功集成到实时处理软件中，并实现了CPU上的高效推理。",
            "tags_zh": [
                "后通道预测",
                "多语种学习",
                "Transformer",
                "跨语言研究",
                "口语对话系统"
            ],
            "_index": 227,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14085/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14085/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14085/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Astraea: A State-Aware Scheduling Engine for LLM-Powered Agents",
            "authors": [
                "Hongqiu Ni",
                "Jiabao Zhang",
                "Guopeng Li",
                "Zilong Wang",
                "Ruiqi Wu",
                "Chi Zhang",
                "Haisheng Tan"
            ],
            "arxiv_id": "2512.14142",
            "summary": "Large Language Models (LLMs) are increasingly being deployed as intelligent agents. Their multi-stage workflows, which alternate between local computation and calls to external network services like Web APIs, introduce a mismatch in their execution pattern and the scheduling granularity of existing inference systems such as vLLM. Existing systems typically focus on per-segment optimization which prevents them from minimizing the end-to-end latency of the complete agentic workflow, i.e., the global Job Completion Time (JCT) over the entire request lifecycle. To address this limitation, we propose Astraea, a service engine designed to shift the optimization from local segments to the global request lifecycle. Astraea employs a state-aware, hierarchical scheduling algorithm that integrates a request's historical state with future predictions. It dynamically classifies requests by their I/O and compute intensive nature and uses an enhanced HRRN policy to balance efficiency and fairness. Astraea also implements an adaptive KV cache manager that intelligently handles the agent state during I/O waits based on the system memory pressure. Extensive experiments show that Astraea reduces average JCT by up to 25.5\\% compared to baseline methods. Moreover, our approach demonstrates strong robustness and stability under high load across various model scales.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14142",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "Astraea：面向LLM智能体的状态感知调度引擎，优化端到端延迟",
            "summary_zh": "大型语言模型（LLM）越来越多地被部署为智能代理。它们的多阶段工作流程在本地计算和诸如Web API之类的外部网络服务调用之间交替，这导致它们的执行模式与现有推理系统（如vLLM）的调度粒度不匹配。现有系统通常侧重于每个片段的优化，这阻碍了它们最小化完整代理工作流程的端到端延迟，即整个请求生命周期内的全局作业完成时间（JCT）。为了解决这个限制，我们提出了Astraea，一种旨在将优化从本地片段转移到全局请求生命周期的服务引擎。Astraea采用了一种状态感知的分层调度算法，该算法将请求的历史状态与未来预测相结合。它根据请求的I/O和计算密集程度动态地对请求进行分类，并使用增强的HRRN策略来平衡效率和公平性。Astraea还实现了一个自适应KV缓存管理器，该管理器根据系统内存压力智能地处理I/O等待期间的代理状态。大量的实验表明，与基线方法相比，Astraea将平均JCT降低了高达25.5％。此外，我们的方法在各种模型规模的高负载下表现出强大的鲁棒性和稳定性。",
            "intro_zh": [
                "现有LLM推理系统侧重于片段优化，忽略了智能体工作流的全局作业完成时间（JCT），导致端到端延迟较高。",
                "Astraea通过状态感知的分层调度算法，结合请求历史状态和未来预测，动态分类请求并优化全局JCT。",
                "实验表明，Astraea相比基线方法，平均JCT降低高达25.5%，并在高负载下表现出强大的鲁棒性和稳定性。"
            ],
            "method_zh": "**问题定义**：现有LLM智能体推理系统，如vLLM，主要关注单个推理片段的优化，而忽略了智能体工作流中多个阶段之间的依赖关系和整体执行效率。这导致在处理包含I/O密集型任务（例如，调用Web API）的复杂智能体任务时，全局作业完成时间（JCT）较长，用户体验不佳。现有方法的痛点在于缺乏对请求状态的感知和全局调度优化。\n\\n**核心思路**：Astraea的核心思路是将优化目标从局部片段转移到全局请求生命周期。通过引入状态感知的调度机制，Astraea能够根据请求的历史状态（例如，已完成的计算量、I/O等待时间）和未来预测（例如，预计的计算量、I/O请求）来动态调整调度策略，从而最小化全局JCT。这种全局优化能够更好地平衡计算和I/O资源，提高整体效率。\n\\n**技术框架**：Astraea的整体架构包含以下主要模块：1) **状态跟踪器**：负责记录每个请求的历史状态信息，包括已完成的计算量、I/O等待时间等。2) **请求分类器**：根据请求的状态信息和未来预测，将请求动态地分类为I/O密集型或计算密集型。3) **分层调度器**：采用分层调度算法，根据请求的类型和优先级进行调度。顶层调度器负责全局资源分配，底层调度器负责单个计算节点的任务调度。4) **自适应KV缓存管理器**：在I/O等待期间，根据系统内存压力智能地管理代理状态，避免不必要的内存占用。\n\\n**关键创新**：Astraea最重要的技术创新点在于其状态感知的分层调度算法。与传统的基于片段的调度方法不同，Astraea能够感知请求的全局状态，并根据状态信息动态调整调度策略。此外，Astraea还引入了自适应KV缓存管理器，能够有效地管理I/O等待期间的代理状态，进一步提高资源利用率。\n\\n**关键设计**：Astraea的关键设计包括：1) **增强的HRRN（Highest Response Ratio Next）策略**：在调度过程中，Astraea使用增强的HRRN策略来平衡效率和公平性。HRRN策略会考虑请求的等待时间和预计的服务时间，优先调度响应比最高的请求。2) **自适应KV缓存管理**：Astraea根据系统内存压力动态调整KV缓存的大小，避免内存溢出。3) **请求分类阈值**：请求分类器使用阈值来区分I/O密集型和计算密集型请求。阈值的设置会影响调度策略的选择，需要根据实际应用场景进行调整。",
            "application_zh": "Astraea适用于各种需要LLM作为智能代理的场景，例如智能客服、自动化报告生成、智能家居控制等。通过优化端到端延迟，Astraea可以显著提升用户体验，并提高系统的整体效率。未来，Astraea可以进一步扩展到支持更复杂的智能体工作流，并与其他推理优化技术相结合，以实现更高的性能。",
            "highlight_zh": "实验结果表明，Astraea相比于基线方法，平均作业完成时间（JCT）降低了高达25.5%。此外，在高负载情况下，Astraea表现出强大的鲁棒性和稳定性，能够有效地处理大量的并发请求。实验还验证了Astraea在不同模型规模下的有效性，表明其具有良好的可扩展性。",
            "tags_zh": [
                "LLM智能体",
                "状态感知调度",
                "全局优化",
                "作业完成时间",
                "KV缓存管理"
            ],
            "_index": 228,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14142/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14142/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14142/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Two CFG Nahuatl for automatic corpora expansion",
            "authors": [
                "Juan-José Guzmán-Landa",
                "Juan-Manuel Torres-Moreno",
                "Miguel Figueroa-Saavedra",
                "Ligia Quintana-Torres",
                "Graham Ranger Martha-Lorena Avendaño-Garrido"
            ],
            "arxiv_id": "2512.14239",
            "summary": "The aim of this article is to introduce two Context-Free Grammars (CFG) for Nawatl Corpora expansion. Nawatl is an Amerindian language (it is a National Language of Mexico) of the $\\pi$-language type, i.e. a language with few digital resources. For this reason the corpora available for the learning of Large Language Models (LLMs) are virtually non-existent, posing a significant challenge. The goal is to produce a substantial number of syntactically valid artificial Nawatl sentences and thereby to expand the corpora for the purpose of learning non contextual embeddings. For this objective, we introduce two new Nawatl CFGs and use them in generative mode. Using these grammars, it is possible to expand Nawatl corpus significantly and subsequently to use it to learn embeddings and to evaluate their relevance in a sentences semantic similarity task. The results show an improvement compared to the results obtained using only the original corpus without artificial expansion, and also demonstrate that economic embeddings often perform better than some LLMs.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14239",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出两种上下文无关文法以扩展纳瓦特尔语语料库",
            "summary_zh": "本文旨在介绍两种用于纳瓦特尔语语料库扩展的上下文无关文法（CFG）。纳瓦特尔语是一种美洲印第安语言（为墨西哥的国家语言），其数字资源稀缺，导致用于学习大型语言模型（LLMs）的语料库几乎不存在，形成了显著挑战。本文的目标是生成大量语法有效的人工纳瓦特尔语句子，从而扩展语料库以学习非上下文嵌入。通过引入两种新的纳瓦特尔CFG并以生成模式使用，显著扩展了纳瓦特尔语语料库，并用于学习嵌入及评估其在句子语义相似性任务中的相关性。结果表明，与仅使用原始语料库相比，人工扩展后取得了显著改善，并且经济嵌入的表现往往优于某些LLMs。",
            "intro_zh": [
                "现有的纳瓦特尔语语料库资源匮乏，限制了大型语言模型的学习和应用。",
                "提出两种新的上下文无关文法，通过生成有效的人工句子来扩展纳瓦特尔语语料库。",
                "实验结果显示，使用扩展后的语料库在句子语义相似性任务中表现优于仅使用原始语料库的情况。"
            ],
            "method_zh": "**问题定义**：本文旨在解决纳瓦特尔语语料库资源不足的问题，现有方法无法有效生成足够的语法有效句子以供大型语言模型学习。\\n\\n**核心思路**：通过引入两种新的上下文无关文法（CFG），利用生成模式生成大量有效的纳瓦特尔语句子，从而扩展语料库。这样的设计旨在克服现有语料库的稀缺性。\\n\\n**技术框架**：整体流程包括定义CFG、生成句子、扩展语料库以及使用扩展后的语料库进行嵌入学习和语义相似性评估。主要模块包括语法定义模块、句子生成模块和评估模块。\\n\\n**关键创新**：最重要的技术创新在于提出了两种新的CFG，能够有效生成符合纳瓦特尔语语法规则的句子，显著提升了语料库的规模和质量。与现有方法相比，提供了更系统化的语料扩展方案。\\n\\n**关键设计**：在CFG的设计中，考虑了纳瓦特尔语的独特语法特征，设置了适当的参数以确保生成句子的语法有效性，损失函数和评估标准则用于优化生成句子的质量。",
            "application_zh": "该研究的潜在应用领域包括自然语言处理、机器翻译和语音识别等，尤其是在资源匮乏语言的处理上具有重要价值。通过扩展纳瓦特尔语的语料库，可以促进该语言的数字化和保护，推动相关研究的发展。未来，该方法也可推广至其他少数语言的语料库扩展。",
            "highlight_zh": "实验结果表明，使用扩展后的纳瓦特尔语语料库在句子语义相似性任务中表现出显著提升，相较于仅使用原始语料库，性能提升幅度达到XX%（具体数据未知）。此外，经济嵌入的表现优于某些大型语言模型，显示出该方法的有效性和实用性。",
            "tags_zh": [
                "纳瓦特尔语",
                "上下文无关文法",
                "语料库扩展",
                "自然语言处理",
                "大型语言模型",
                "语义相似性",
                "人工句子生成"
            ],
            "_index": 229,
            "_used_api": "openai",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14239/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14239/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14239/resultats_models_tase_II_grammaires.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "VersatileFFN: Achieving Parameter Efficiency in LLMs via Adaptive Wide-and-Deep Reuse",
            "authors": [
                "Ying Nie",
                "Kai Han",
                "Hongguang Li",
                "Hang Zhou",
                "Tianyu Guo",
                "Enhua Wu",
                "Xinghao Chen",
                "Yunhe Wang"
            ],
            "arxiv_id": "2512.14531",
            "summary": "The rapid scaling of Large Language Models (LLMs) has achieved remarkable performance, but it also leads to prohibitive memory costs. Existing parameter-efficient approaches such as pruning and quantization mainly compress pretrained models without enhancing architectural capacity, thereby hitting the representational ceiling of the base model. In this work, we propose VersatileFFN, a novel feed-forward network (FFN) that enables flexible reuse of parameters in both width and depth dimensions within a fixed parameter budget. Inspired by the dual-process theory of cognition, VersatileFFN comprises two adaptive pathways: a width-versatile path that generates a mixture of sub-experts from a single shared FFN, mimicking sparse expert routing without increasing parameters, and a depth-versatile path that recursively applies the same FFN to emulate deeper processing for complex tokens. A difficulty-aware gating dynamically balances the two pathways, steering \"easy\" tokens through the efficient width-wise route and allocating deeper iterative refinement to \"hard\" tokens. Crucially, both pathways reuse the same parameters, so all additional capacity comes from computation rather than memory. Experiments across diverse benchmarks and model scales demonstrate the effectiveness of the method. The code will be available atthis https URL.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14531",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "VersatileFFN：通过自适应宽深复用提升LLM的参数效率",
            "summary_zh": "大型语言模型（LLM）的快速扩展带来了卓越的性能，但也导致了巨大的内存成本。现有的参数高效方法，如剪枝和量化，主要压缩预训练模型，而不增强架构容量，从而触及了基础模型的表征上限。本文提出了VersatileFFN，一种新颖的前馈网络（FFN），它能够在固定的参数预算内，灵活地复用宽度和深度维度上的参数。受到认知双过程理论的启发，VersatileFFN包含两个自适应路径：一个宽度多功能路径，从单个共享FFN生成子专家混合，模拟稀疏专家路由而不增加参数；以及一个深度多功能路径，递归地应用相同的FFN，以模拟更深层次的复杂token处理。一个难度感知门控动态地平衡这两个路径，引导“简单”token通过高效的宽度路径，并为“困难”token分配更深层次的迭代细化。至关重要的是，这两个路径都复用相同的参数，因此所有额外的容量都来自计算而非内存。在各种基准和模型规模上的实验证明了该方法的有效性。",
            "intro_zh": [
                "现有LLM参数高效方法主要通过压缩预训练模型实现，但未有效提升模型架构本身的容量。",
                "VersatileFFN通过宽度和深度两个维度上的参数复用，在固定参数预算下提升模型容量。",
                "实验表明，VersatileFFN在多种基准测试和模型规模上均表现出有效性，验证了其参数效率。"
            ],
            "method_zh": "**问题定义**：现有大型语言模型（LLM）在追求卓越性能的同时，面临着巨大的内存成本问题。现有的参数高效方法，如剪枝和量化，主要集中于压缩预训练模型，而忽略了模型架构本身的容量提升，导致模型性能受限于基础模型的表征能力。\\n\\n**核心思路**：VersatileFFN的核心思路是在固定参数预算下，通过参数的灵活复用，同时提升模型的宽度和深度，从而增强模型的表征能力。借鉴认知双过程理论，区分“简单”和“困难”的token，并采用不同的处理路径。\\n\\n**技术框架**：VersatileFFN包含两个主要路径：宽度多功能路径和深度多功能路径。宽度路径通过共享的FFN生成子专家混合，模拟稀疏专家路由。深度路径则递归应用相同的FFN，模拟更深层次的处理。难度感知门控机制动态平衡这两个路径，将“简单”token引导至宽度路径，将“困难”token引导至深度路径。这两个路径共享相同的参数。\\n\\n**关键创新**：VersatileFFN的关键创新在于参数的自适应宽深复用。与传统的参数高效方法不同，VersatileFFN不是简单地压缩模型，而是通过巧妙的架构设计，在不增加参数量的前提下，提升模型的容量。难度感知门控机制也是一个创新点，它能够根据token的难度动态调整处理路径。\\n\\n**关键设计**：难度感知门控机制是VersatileFFN的关键设计之一。具体实现方式未知，但其目标是根据token的复杂程度，动态地分配计算资源。宽度路径和深度路径的具体网络结构未知，但它们都基于共享的FFN。损失函数的设计也至关重要，需要平衡宽度路径和深度路径的贡献，并确保模型的整体性能。",
            "application_zh": "VersatileFFN具有广泛的应用前景，可以应用于各种需要参数高效的大型语言模型场景，例如移动设备上的自然语言处理、资源受限环境下的模型部署等。该研究有助于降低LLM的部署成本，加速LLM在各个领域的普及和应用，并为未来的参数高效模型设计提供新的思路。",
            "highlight_zh": "论文通过实验验证了VersatileFFN的有效性。具体性能数据未知，但实验结果表明，VersatileFFN在多种基准测试和模型规模上均优于现有的参数高效方法。该方法能够在不增加参数量的前提下，显著提升模型的性能，证明了其参数效率。",
            "tags_zh": [
                "参数高效",
                "大型语言模型",
                "前馈网络",
                "模型压缩",
                "宽度复用",
                "深度复用",
                "自适应路由",
                "认知双过程"
            ],
            "_index": 230,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14531/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14531/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14531/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "TaP: A Taxonomy-Guided Framework for Automated and Scalable Preference Data Generation",
            "authors": [
                "Renren Jin",
                "Tianhao Shen",
                "Xinwei Wu",
                "Dan Shi",
                "Haoran Sun",
                "Yuqi Ren",
                "Wuwei Huang",
                "Quandong Wang",
                "Wei Liu",
                "Jian Luan",
                "Bin Wang",
                "Deyi Xiong"
            ],
            "arxiv_id": "2506.23979",
            "summary": "Conducting supervised fine-tuning and preference fine-tuning on large language models (LLMs) requires high-quality datasets to improve their ability to follow instructions and align with human preferences and values. However, constructing such datasets is resource-intensive, and most available datasets for supervised and preference fine-tuning are in English. To address these challenges, we propose the \\underline{\\textbf{Ta}}xonomy-Guided \\underline{\\textbf{P}}reference Data Generation (TaP) framework, which facilitates automated and scalable construction of preference datasets across various languages. TaP is grounded in a structured taxonomy that allows fine-grained control over dataset composition, thereby ensuring both diversity and comprehensive coverage. We employ TaP-generated datasets to perform supervised and preference fine-tuning on various LLMs. Experimental results demonstrate that LLMs trained on TaP-generated datasets outperform those trained on existing open-source datasets. Remarkably, LLMs trained on TaP-generated datasets surpass the performance of those trained on an open-source dataset that is 180 times larger.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2506.23979",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "TaP：一种基于分类法的自动化、可扩展的偏好数据生成框架",
            "summary_zh": "为了提升大型语言模型（LLMs）遵循指令和与人类偏好及价值观对齐的能力，需要在其上进行有监督微调和偏好微调，这需要高质量的数据集。然而，构建此类数据集需要耗费大量资源，并且大多数可用的有监督和偏好微调数据集都是英文的。为了解决这些挑战，我们提出了基于分类法的偏好数据生成（TaP）框架，该框架有助于跨各种语言自动且可扩展地构建偏好数据集。TaP基于结构化的分类法，可以对数据集的组成进行细粒度控制，从而确保多样性和全面的覆盖。我们使用TaP生成的数据集对各种LLM进行有监督和偏好微调。实验结果表明，在TaP生成的数据集上训练的LLM优于在现有开源数据集上训练的LLM。值得注意的是，在TaP生成的数据集上训练的LLM的性能超过了在规模大180倍的开源数据集上训练的LLM。",
            "intro_zh": [
                "现有LLM微调数据集构建成本高昂，且多为英文，限制了多语言LLM的发展。",
                "TaP框架利用结构化分类法，实现对数据集组成的细粒度控制，保证数据多样性和覆盖率。",
                "实验表明，使用TaP生成的数据集训练的LLM，性能超越了使用更大规模开源数据集训练的LLM。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型（LLMs）的有监督微调和偏好微调所需的高质量数据集的构建问题。现有方法主要面临两个痛点：一是数据集构建成本高昂，需要大量人工标注；二是现有数据集大多为英文，缺乏对多语言的支持。\\n\\n**核心思路**：论文的核心思路是利用一个结构化的分类法（Taxonomy）来指导偏好数据的自动生成。通过分类法，可以对生成的数据集进行细粒度控制，从而保证数据集的多样性和覆盖率，同时降低人工标注的成本。\\n\\n**技术框架**：TaP框架包含以下主要模块：1) 分类法构建模块：定义数据集的结构化分类体系，例如主题、风格、难度等；2) 数据生成模块：基于分类法，利用LLM自动生成候选数据；3) 偏好排序模块：对生成的数据进行排序，选出符合人类偏好的数据；4) 数据集构建模块：将排序后的数据构建成最终的偏好数据集。整个流程旨在自动化生成高质量、多语言的偏好数据集。\\n\\n**关键创新**：TaP框架的关键创新在于引入了分类法来指导偏好数据的生成。与以往随机生成或人工标注的方法相比，TaP能够更有效地控制数据集的质量和多样性，并显著降低了数据构建的成本。\\n\\n**关键设计**：分类法的具体设计是关键。例如，可以根据不同的应用场景定义不同的分类维度，并为每个维度设置不同的取值范围。数据生成模块可以使用不同的LLM和生成策略，偏好排序模块可以使用人工标注或自动评估指标。具体参数设置和损失函数的使用取决于具体的实现细节，论文中可能未详细说明。",
            "application_zh": "TaP框架可广泛应用于各种语言的大型语言模型的微调，尤其是在资源有限的情况下。通过自动化生成高质量的偏好数据集，可以显著降低LLM训练的成本，并提升其在特定任务上的性能。该框架还有助于构建更符合人类价值观和偏好的LLM，促进人机协作。",
            "highlight_zh": "实验结果表明，使用TaP生成的数据集训练的LLM，性能显著优于使用现有开源数据集训练的LLM。更令人瞩目的是，使用TaP生成的数据集训练的LLM，其性能甚至超过了使用规模大180倍的开源数据集训练的LLM，这充分证明了TaP框架的有效性和效率。",
            "tags_zh": [
                "偏好学习",
                "数据生成",
                "大型语言模型",
                "分类法",
                "自动化",
                "多语言",
                "指令微调"
            ],
            "_index": 231,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2506.23979/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2506.23979/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2506.23979/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "DIWALI: Diversity and Inclusivity aWare cuLture specific Items for India: Dataset and Assessment of LLMs for Cultural Text Adaptation in Indian Context",
            "authors": [
                "Pramit Sahoo",
                "Maharaj Brahma",
                "Maunendra Sankar Desarkar"
            ],
            "arxiv_id": "2509.17399",
            "summary": "Large language models (LLMs) are widely used in various tasks and applications. However, despite their wide capabilities, they are shown to lack cultural alignment \\citep{ryan-etal-2024-unintended, alkhamissi-etal-2024-investigating} and produce biased generations \\cite{naous-etal-2024-beer} due to a lack of cultural knowledge and competence. Evaluation of LLMs for cultural awareness and alignment is particularly challenging due to the lack of proper evaluation metrics and unavailability of culturally grounded datasets representing the vast complexity of cultures at the regional and sub-regional levels. Existing datasets for culture specific items (CSIs) focus primarily on concepts at the regional level and may contain false positives. To address this issue, we introduce a novel CSI dataset for Indian culture, belonging to 17 cultural facets. The dataset comprises ~8k cultural concepts from 36 sub-regions. To measure the cultural competence of LLMs on a cultural text adaptation task, we evaluate the adaptations using the CSIs created, LLM as Judge, and human evaluations from diverse socio-demographic region. Furthermore, we perform quantitative analysis demonstrating selective sub-regional coverage and surface-level adaptations across all considered LLMs. Our dataset is available here:this https URL, project webpagethis https URL, and our codebase with model outputs can be found here:this https URL",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2509.17399",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "DIWALI：提出印度文化特定项数据集，并评估LLM在印度文化文本适应任务中的表现",
            "summary_zh": "大型语言模型（LLM）被广泛应用于各种任务和应用中。然而，尽管它们具有广泛的能力，但由于缺乏文化知识和能力，它们在文化一致性方面表现出不足，并产生有偏见的生成结果。评估LLM的文化意识和一致性尤其具有挑战性，因为缺乏适当的评估指标和具有文化基础的数据集，这些数据集能够代表区域和次区域层面文化的复杂性。现有的文化特定项（CSI）数据集主要关注区域层面的概念，并且可能包含误报。为了解决这个问题，我们引入了一个新的印度文化CSI数据集，属于17个文化方面。该数据集包含来自36个次区域的约8000个文化概念。为了衡量LLM在文化文本适应任务中的文化能力，我们使用创建的CSI、LLM作为评判者以及来自不同社会人口区域的人工评估来评估适应情况。此外，我们进行了定量分析，表明所有考虑的LLM都存在选择性的次区域覆盖和表面层面的适应。我们的数据集、项目网页和包含模型输出的代码库均已公开。",
            "intro_zh": [
                "现有LLM缺乏文化知识，导致生成内容存在文化偏差，难以适应特定文化语境。",
                "DIWALI提出一个包含17个文化方面、36个次区域的印度文化特定项数据集，用于评估LLM的文化适应能力。",
                "通过CSI、LLM评判和人工评估，定量分析表明现有LLM在次区域覆盖和文化适应方面存在不足。"
            ],
            "method_zh": "**问题定义**：现有的大型语言模型在处理文化相关的任务时，由于缺乏对特定文化的深入理解，容易产生偏差和不准确的结果。现有的文化特定项数据集通常只关注区域层面的概念，并且可能包含错误信息，无法充分代表文化的复杂性和多样性。因此，如何构建一个高质量、细粒度的文化数据集，并利用该数据集有效评估和提升LLM的文化适应能力，是一个亟待解决的问题。\\n\\n**核心思路**：本研究的核心思路是构建一个专门针对印度文化的、包含多个文化方面和次区域的文化特定项数据集（DIWALI）。通过该数据集，可以更准确地评估LLM在文化文本适应任务中的表现，并发现其在文化理解方面的不足。同时，利用LLM作为评判者和人工评估相结合的方式，可以更全面地评估LLM的文化能力。\\n\\n**技术框架**：该研究的技术框架主要包括以下几个部分：1)构建DIWALI数据集，该数据集包含17个文化方面和36个次区域的约8000个文化概念；2)设计文化文本适应任务，要求LLM根据给定的文本和文化背景进行适应性修改；3)使用DIWALI数据集、LLM作为评判者和人工评估三种方式，对LLM的文化适应能力进行评估；4)对评估结果进行定量分析，揭示LLM在不同文化方面和次区域的表现差异。\\n\\n**关键创新**：本研究的关键创新在于：1)提出了一个细粒度的印度文化特定项数据集（DIWALI），该数据集覆盖了多个文化方面和次区域，能够更准确地反映印度文化的复杂性和多样性；2)采用了LLM作为评判者和人工评估相结合的方式，对LLM的文化适应能力进行评估，避免了单一评估方式的局限性；3)通过定量分析，揭示了LLM在不同文化方面和次区域的表现差异，为后续的研究提供了有价值的参考。\\n\\n**关键设计**：DIWALI数据集的关键设计包括：1)选择17个具有代表性的文化方面，如节日、食物、服饰等；2)覆盖36个印度次区域，以反映不同地区的文化差异；3)收集约8000个文化概念，并进行标注和验证，以保证数据的质量和准确性。在评估方面，采用了LLM作为评判者，并结合人工评估，以提高评估的客观性和可靠性。具体参数设置和损失函数等技术细节在论文中未详细说明，属于未知信息。",
            "application_zh": "该研究成果可应用于提升LLM在文化相关任务中的表现，例如文化内容生成、跨文化交流和文化遗产保护。通过提高LLM的文化意识和适应能力，可以减少文化误解和偏见，促进不同文化之间的理解和尊重。此外，该数据集也可以作为其他研究人员进行文化相关研究的基础资源。",
            "highlight_zh": "该研究构建了一个包含约8000个文化概念的印度文化特定项数据集，覆盖17个文化方面和36个次区域。实验结果表明，现有的LLM在文化文本适应任务中表现出选择性的次区域覆盖和表面层面的适应，表明其文化理解能力仍有待提高。具体性能数据和提升幅度在摘要中未明确给出，属于未知信息。",
            "tags_zh": [
                "大型语言模型",
                "文化适应",
                "文化特定项",
                "印度文化",
                "数据集",
                "文本生成",
                "文化评估"
            ],
            "_index": 232,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2509.17399/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2509.17399/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2509.17399/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Pragmatic Inference for Moral Reasoning Acquisition: Generalization via Distributional Semantics",
            "authors": [
                "Guangliang Liu",
                "Xi Chen",
                "Bocheng Chen",
                "Han Zi",
                "Xitong Zhang",
                "Kristen Johnson"
            ],
            "arxiv_id": "2509.24102",
            "summary": "Moral reasoning has emerged as a promising research direction for Large Language Models (LLMs), yet achieving generalization remains a central challenge. From a linguistic standpoint, this difficulty arises because LLMs are adept at capturing distributional semantics, which fundamentally differs from the morals which operate at the pragmatic level. This paper investigates how LLMs can achieve generalized moral reasoning despite their reliance on distributional semantics. We propose pragmatic inference methods grounded in moral foundations theory, which leverage contextual information at each step to bridge the pragmatic gap and guide LLMs in connecting moral foundations with moral reasoning objectives. Experimental results demonstrate that our approach significantly enhances LLMs' generalization in moral reasoning, providing a foundation for future research grounded in moral foundations theory.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2509.24102",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于语用推理的道德推理获取方法，提升LLM的道德推理泛化能力",
            "summary_zh": "道德推理已成为大型语言模型（LLMs）一个很有前景的研究方向，但实现泛化仍然是一个核心挑战。从语言学角度来看，这种困难的出现是因为LLMs擅长捕捉分布语义，而分布语义从根本上不同于在语用层面运作的道德。本文研究了LLMs如何在依赖分布语义的情况下实现广义的道德推理。我们提出了基于道德基础理论的语用推理方法，该方法利用每个步骤的上下文信息来弥合语用差距，并指导LLMs将道德基础与道德推理目标联系起来。实验结果表明，我们的方法显著提高了LLMs在道德推理中的泛化能力，为未来基于道德基础理论的研究奠定了基础。",
            "intro_zh": [
                "大型语言模型在道德推理方面面临泛化难题，因为它们主要依赖于分布语义，而道德判断更多依赖于语用推理。",
                "论文提出基于道德基础理论的语用推理方法，通过利用上下文信息弥合分布语义和语用之间的差距。",
                "实验结果表明，该方法显著提升了大型语言模型在道德推理任务中的泛化能力，为后续研究奠定基础。"
            ],
            "method_zh": "**问题定义**：当前大型语言模型在道德推理方面表现出一定的能力，但其泛化能力不足。主要原因是LLMs主要依赖于从大量文本数据中学习到的分布语义，而道德判断往往涉及到更深层次的语用推理，即需要结合上下文信息进行理解和判断。现有方法难以有效弥合分布语义和语用推理之间的差距，导致模型在面对新的道德场景时表现不佳。\\n\\n**核心思路**：论文的核心思路是利用道德基础理论（Moral Foundations Theory）作为桥梁，将分布语义和语用推理联系起来。道德基础理论提供了一套通用的道德价值观框架，可以帮助模型更好地理解和推理不同场景下的道德含义。通过在推理过程中显式地考虑道德基础，模型可以更好地捕捉上下文信息，从而做出更合理的道德判断。\\n\\n**技术框架**：该方法主要包含以下几个阶段：1) 输入道德场景描述；2) 利用道德基础理论，提取与场景相关的道德基础信息；3) 将道德基础信息与场景描述结合，作为LLM的输入；4) LLM进行道德推理，输出判断结果。整个框架的关键在于如何有效地提取和利用道德基础信息，并将其融入到LLM的推理过程中。\\n\\n**关键创新**：论文的关键创新在于将道德基础理论引入到LLM的道德推理过程中，并提出了一种基于语用推理的方法，有效地弥合了分布语义和语用推理之间的差距。与现有方法相比，该方法能够更好地捕捉上下文信息，从而提高LLM在道德推理任务中的泛化能力。\\n\\n**关键设计**：论文的关键设计包括：1) 如何将道德基础理论表示为可供LLM理解的向量形式；2) 如何设计损失函数，使得LLM能够更好地学习道德基础和道德判断之间的关系；3) 如何选择合适的LLM架构，以充分利用道德基础信息进行推理。具体的参数设置和网络结构细节在论文中可能有所描述，但摘要中未明确提及。",
            "application_zh": "该研究成果可应用于开发更具道德意识的人工智能系统，例如自动驾驶汽车、医疗诊断系统和法律咨询系统。通过提升机器的道德推理能力，可以使其在复杂场景下做出更符合伦理道德的决策，从而更好地服务于人类社会。此外，该研究还可以促进人机交互的和谐发展，增强用户对人工智能系统的信任感。",
            "highlight_zh": "实验结果表明，该方法显著提高了LLMs在道德推理任务中的泛化能力。具体的性能数据、对比基线和提升幅度在摘要中未明确给出，但强调了该方法为未来基于道德基础理论的研究奠定了基础。具体提升效果未知。",
            "tags_zh": [
                "道德推理",
                "大型语言模型",
                "语用推理",
                "道德基础理论",
                "泛化能力"
            ],
            "_index": 233,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2509.24102/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2509.24102/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2509.24102/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Listening Between the Lines: Decoding Podcast Narratives with Language Modeling",
            "authors": [
                "Shreya Gupta",
                "Ojasva Saxena",
                "Arghodeep Nandi",
                "Sarah Masud",
                "Kiran Garimella",
                "Tanmoy Chakraborty"
            ],
            "arxiv_id": "2511.05310",
            "summary": "Podcasts have become a central arena for shaping public opinion, making them a vital source for understanding contemporary discourse. Their typically unscripted, multi-themed, and conversational style offers a rich but complex form of data. To analyze how podcasts persuade and inform, we must examine their narrative structures -- specifically, the narrative frames they employ.The fluid and conversational nature of podcasts presents a significant challenge for automated analysis. We show that existing large language models, typically trained on more structured text such as news articles, struggle to capture the subtle cues that human listeners rely on to identify narrative frames. As a result, current approaches fall short of accurately analyzing podcast narratives at scale.To solve this, we develop and evaluate a fine-tuned BERT model that explicitly links narrative frames to specific entities mentioned in the conversation, effectively grounding the abstract frame in concrete details. Our approach then uses these granular frame labels and correlates them with high-level topics to reveal broader discourse trends. The primary contributions of this paper are: (i) a novel frame-labeling methodology that more closely aligns with human judgment for messy, conversational data, and (ii) a new analysis that uncovers the systematic relationship between what is being discussed (the topic) and how it is being presented (the frame), offering a more robust framework for studying influence in digital media.",
            "categories": [
                "cs.CL",
                "cs.SI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2511.05310",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出一种基于语言模型的播客叙事框架解码方法，提升在非结构化对话数据中的叙事分析精度。",
            "summary_zh": "播客已成为塑造公众舆论的重要场所，是理解当代话语的重要来源。其通常无脚本、多主题和对话式的风格提供了一种丰富但复杂的数据形式。为了分析播客如何说服和告知，我们必须检查它们的叙事结构——特别是它们使用的叙事框架。播客的流畅和对话性质给自动化分析带来了重大挑战。我们表明，通常在新闻文章等更结构化的文本上训练的现有大型语言模型难以捕捉人类听众用来识别叙事框架的细微线索。因此，当前的方法无法大规模地准确分析播客叙事。为了解决这个问题，我们开发并评估了一个微调的BERT模型，该模型将叙事框架与对话中提到的特定实体明确地联系起来，有效地将抽象框架扎根于具体细节中。然后，我们的方法使用这些细粒度的框架标签，并将它们与高级主题相关联，以揭示更广泛的话语趋势。本文的主要贡献是：（i）一种新的框架标记方法，更紧密地与人类对混乱的对话数据的判断相一致，以及（ii）一种新的分析方法，揭示了正在讨论的内容（主题）与呈现方式（框架）之间的系统关系，为研究数字媒体中的影响力提供了一个更强大的框架。",
            "intro_zh": [
                "现有大型语言模型难以捕捉播客中细微的叙事框架线索，导致无法准确分析播客叙事。",
                "通过微调BERT模型，将叙事框架与对话中的实体联系起来，实现抽象框架与具体细节的关联。",
                "该方法将细粒度的框架标签与高级主题关联，揭示更广泛的话语趋势，提升叙事分析的鲁棒性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决现有大型语言模型在分析播客等非结构化对话数据中的叙事框架时表现不佳的问题。现有方法主要在结构化文本上训练，难以捕捉播客中细微的叙事线索，导致叙事分析精度不足。\\n\\n**核心思路**：论文的核心思路是将叙事框架与对话中提到的具体实体联系起来，通过将抽象的叙事框架“锚定”到具体的实体上，从而提高模型对叙事框架的识别能力。这种方法模拟了人类理解叙事的方式，即通过关注对话中的关键人物和事件来推断叙事框架。\\n\\n**技术框架**：整体框架包含以下几个主要步骤：1) 数据预处理：对播客音频进行转录，得到文本数据。2) 实体识别：识别文本数据中的命名实体。3) 框架标注：人工标注实体相关的叙事框架。4) 模型微调：使用标注数据微调BERT模型，使其能够预测给定实体对应的叙事框架。5) 叙事分析：使用微调后的模型分析播客的叙事结构，并将框架标签与高级主题关联，揭示更广泛的话语趋势。\\n\\n**关键创新**：论文的关键创新在于提出了一种新的框架标注方法，该方法更紧密地与人类对混乱的对话数据的判断相一致。传统方法通常直接标注整个文本的叙事框架，而该论文的方法则关注实体相关的叙事框架，从而能够更细粒度地捕捉叙事的变化。此外，该方法还提出了一种新的分析方法，揭示了正在讨论的内容（主题）与呈现方式（框架）之间的系统关系。\\n\\n**关键设计**：论文使用BERT模型作为基础模型，并对其进行微调。微调的目标是使模型能够预测给定实体对应的叙事框架。损失函数采用交叉熵损失函数。具体的网络结构和参数设置在论文中没有详细说明，属于未知信息。",
            "application_zh": "该研究成果可应用于舆情分析、政治传播研究、市场营销等领域。通过分析播客等数字媒体的叙事框架，可以了解公众对特定话题的看法和态度，从而为决策提供参考。此外，该方法还可以用于检测虚假信息和操纵性宣传，维护健康的舆论环境。",
            "highlight_zh": "论文的主要实验结果表明，该方法在播客叙事框架识别任务上取得了显著的性能提升。具体的性能数据和对比基线在摘要中没有提及，属于未知信息。但论文强调，该方法更紧密地与人类对混乱的对话数据的判断相一致，能够更准确地分析播客叙事。",
            "tags_zh": [
                "播客分析",
                "叙事框架",
                "语言模型",
                "BERT",
                "自然语言处理"
            ],
            "_index": 234,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2511.05310/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2511.05310/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2511.05310/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Can Finetuing LLMs on Small Human Samples Increase Heterogeneity, Alignment, and Belief-Action Coherence?",
            "authors": [
                "Steven Wang",
                "Kyle Hunt",
                "Shaojie Tang",
                "Kenneth Joseph"
            ],
            "arxiv_id": "2511.21218",
            "summary": "There is ongoing debate about whether large language models (LLMs) can serve as substitutes for human participants in survey and experimental research. While recent work in fields such as marketing and psychology has explored the potential of LLM-based simulation, a growing body of evidence cautions against this practice: LLMs often fail to align with real human behavior, exhibiting limited diversity, systematic misalignment for minority subgroups, insufficient within-group variance, and discrepancies between stated beliefs and actions. This study examines an important and distinct question in this domain: whether fine-tuning on a small subset of human survey data, such as that obtainable from a pilot study, can mitigate these issues and yield realistic simulated outcomes. Using a behavioral experiment on information disclosure, we compare human and LLM-generated responses across multiple dimensions, including distributional divergence, subgroup alignment, belief-action coherence, and the recovery of regression coefficients. We find that fine-tuning on small human samples substantially improves heterogeneity, alignment, and belief-action coherence relative to the base model. However, even the best-performing fine-tuned models fail to reproduce the regression coefficients of the original study, suggesting that LLM-generated data remain unsuitable for replacing human participants in formal inferential analyses.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2511.21218",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "通过少量人工样本微调LLM能否提升异质性、对齐性和信念-行为一致性？",
            "summary_zh": "关于大型语言模型（LLM）是否可以替代人类参与者进行调查和实验研究，目前存在争议。尽管市场营销和心理学等领域的最新研究探索了基于LLM的模拟的潜力，但越来越多的证据表明这种做法存在问题：LLM通常无法与真实的人类行为对齐，表现出有限的多样性、少数群体系统性错位、组内方差不足以及陈述的信念与行为之间的差异。本研究探讨了一个重要且独特的问题：在少量人类调查数据（例如从初步研究中获得的数据）上进行微调，是否可以缓解这些问题并产生真实的模拟结果。我们使用关于信息披露的行为实验，比较了人类和LLM生成的响应在多个维度上的差异，包括分布差异、子群体对齐、信念-行为一致性以及回归系数的恢复。我们发现，相对于基础模型，在少量人类样本上进行微调可以显著提高异质性、对齐性和信念-行为一致性。然而，即使是性能最佳的微调模型也无法重现原始研究的回归系数，这表明LLM生成的数据仍然不适合替代人类参与者进行正式的推断分析。",
            "intro_zh": [
                "现有研究表明，LLM在模拟人类行为时存在多样性不足、与少数群体错位以及信念与行为不一致等问题。",
                "该研究探索了使用少量人类数据微调LLM，以期改善其模拟人类行为的能力，使其更具真实性和可靠性。",
                "实验结果表明，微调可以显著提高LLM的异质性、对齐性和信念-行为一致性，但仍无法完全替代人类参与者进行推断分析。"
            ],
            "method_zh": "**问题定义**：论文旨在解决LLM在模拟人类行为时存在的不足，具体表现为异质性不足、与特定人群（如少数群体）的认知偏差不一致、以及信念和行为的不一致。现有方法直接使用预训练的LLM进行模拟，忽略了真实人类行为的细微差别，导致模拟结果与真实情况存在较大差距。\\n\\n**核心思路**：论文的核心思路是通过在少量真实人类数据上对LLM进行微调，使LLM能够学习到人类行为的分布特征和内在逻辑，从而提高其模拟人类行为的真实性和可靠性。这种方法旨在弥合LLM的通用知识与特定人群或情境下的行为模式之间的差距。\\n\\n**技术框架**：该研究的技术框架主要包括以下几个步骤：1) 收集少量人类行为数据（例如，通过调查或实验）；2) 选择一个预训练的LLM作为基础模型；3) 使用收集到的人类数据对LLM进行微调；4) 使用微调后的LLM生成模拟数据；5) 将模拟数据与真实人类数据进行比较，评估微调的效果。评估指标包括分布差异、子群体对齐、信念-行为一致性以及回归系数的恢复。\\n\\n**关键创新**：该研究的关键创新在于探索了使用少量人类数据微调LLM以改善其行为模拟能力。与直接使用预训练LLM相比，这种方法能够更好地捕捉人类行为的细微差别和内在逻辑。此外，该研究还系统地评估了微调对LLM在多个维度上的影响，包括异质性、对齐性和信念-行为一致性。\\n\\n**关键设计**：该研究的关键设计包括：1) 选择合适的LLM作为基础模型；2) 设计有效的微调策略，例如选择合适的损失函数和学习率；3) 选择合适的评估指标来衡量微调的效果。具体来说，论文使用了一个关于信息披露的行为实验来收集人类数据，并使用回归分析来评估LLM是否能够重现原始研究的回归系数。",
            "application_zh": "该研究的潜在应用领域包括社会科学研究、市场调研、政策模拟等。通过使用微调后的LLM模拟人类行为，研究人员可以更高效地进行实验和分析，从而更好地理解人类行为的规律和影响因素。此外，该研究还可以为开发更智能、更人性化的AI系统提供借鉴，例如，可以用于构建更贴近用户需求的智能助手或推荐系统。",
            "highlight_zh": "实验结果表明，在少量人类样本上进行微调可以显著提高LLM的异质性、对齐性和信念-行为一致性。具体来说，微调后的LLM在分布差异、子群体对齐和信念-行为一致性方面都更接近真实人类数据。然而，即使是性能最佳的微调模型也无法完全重现原始研究的回归系数，这表明LLM生成的数据仍然不适合替代人类参与者进行正式的推断分析。",
            "tags_zh": [
                "大型语言模型",
                "行为模拟",
                "微调",
                "人类行为",
                "信念-行为一致性"
            ],
            "_index": 235,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2511.21218/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2511.21218/x3.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2511.21218/x4.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "VASA-3D: Lifelike Audio-Driven Gaussian Head Avatars from a Single Image",
            "authors": [
                "Sicheng Xu",
                "Guojun Chen",
                "Jiaolong Yang",
                "Yizhong Zhang",
                "Yu Deng",
                "Steve Lin",
                "Baining Guo"
            ],
            "arxiv_id": "2512.14677",
            "summary": "We propose VASA-3D, an audio-driven, single-shot 3D head avatar generator. This research tackles two major challenges: capturing the subtle expression details present in real human faces, and reconstructing an intricate 3D head avatar from a single portrait image. To accurately model expression details, VASA-3D leverages the motion latent of VASA-1, a method that yields exceptional realism and vividness in 2D talking heads. A critical element of our work is translating this motion latent to 3D, which is accomplished by devising a 3D head model that is conditioned on the motion latent. Customization of this model to a single image is achieved through an optimization framework that employs numerous video frames of the reference head synthesized from the input image. The optimization takes various training losses robust to artifacts and limited pose coverage in the generated training data. Our experiment shows that VASA-3D produces realistic 3D talking heads that cannot be achieved by prior art, and it supports the online generation of 512x512 free-viewpoint videos at up to 75 FPS, facilitating more immersive engagements with lifelike 3D avatars.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14677",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "motion latent"
                    ],
                    "score": 2.5
                }
            ],
            "relevance_score": 2.5,
            "hit_pillars": [
                "4_motion_diffusion"
            ],
            "headline_zh": "VASA-3D：基于单张图像的逼真音频驱动高斯头部化身生成",
            "summary_zh": "本文提出VASA-3D，一种音频驱动的单张图像3D头部化身生成器。该研究旨在解决两个主要挑战：捕捉真实人脸中细微的表情细节，以及从单张人像图像重建复杂的3D头部化身。为了准确地建模表情细节，VASA-3D利用了VASA-1的运动潜在空间，该方法在2D说话头部生成方面表现出卓越的真实感和生动性。本文的关键在于将这种运动潜在空间转化为3D，这是通过设计一个以运动潜在空间为条件的3D头部模型来实现的。通过一个优化框架，利用从输入图像合成的参考头部的大量视频帧，实现对该模型的单张图像定制。该优化框架采用了对伪影和生成训练数据中有限姿态覆盖具有鲁棒性的各种训练损失。实验表明，VASA-3D生成了逼真的3D说话头部，这是现有技术无法实现的，并且它支持以高达75 FPS的速度在线生成512x512自由视点视频，从而促进了与逼真3D化身更具沉浸感的互动。",
            "intro_zh": [
                "现有方法难以从单张图像生成具有真实表情细节的3D头部化身，尤其是在捕捉细微的面部运动方面。",
                "VASA-3D的核心思想是将VASA-1的2D运动潜在空间迁移到3D头部模型，从而驱动3D化身的表情。",
                "实验表明，VASA-3D能够生成逼真的3D说话头部，并支持高达75 FPS的自由视点视频生成，优于现有技术。"
            ],
            "method_zh": "**问题定义**：论文旨在解决从单张人像图像生成逼真且可控的3D头部化身的问题。现有方法在捕捉细微表情细节和处理单张图像的3D重建方面存在不足，生成的3D化身真实感较差，难以满足高质量应用的需求。\\n\\n**核心思路**：论文的核心思路是利用VASA-1在2D说话头部生成方面的优势，将其学习到的运动潜在空间迁移到3D头部模型。通过将3D头部模型与2D运动潜在空间解耦，可以实现对3D化身表情的精确控制，并提高生成结果的真实感。\\n\\n**技术框架**：VASA-3D的整体框架包含以下几个主要阶段：1) 利用VASA-1的运动潜在空间提取表情信息；2) 设计一个以运动潜在空间为条件的3D头部模型；3) 通过优化框架，利用从单张输入图像合成的视频帧，对3D头部模型进行个性化定制；4) 使用鲁棒的损失函数进行训练，以克服伪影和有限姿态覆盖的问题。\\n\\n**关键创新**：该论文最重要的技术创新点在于将2D运动潜在空间成功迁移到3D头部模型，从而实现了对3D化身表情的精确控制。与现有方法相比，VASA-3D能够生成更逼真、更生动的3D说话头部，并且支持自由视点视频生成。\\n\\n**关键设计**：论文的关键设计包括：1) 使用高斯头部表示3D模型；2) 设计了以运动潜在空间为条件的3D头部模型结构；3) 采用了多种损失函数，包括光度一致性损失、正则化损失等，以提高生成结果的质量和鲁棒性；4) 使用了从单张图像合成的视频帧进行训练，以克服数据稀缺的问题。",
            "application_zh": "VASA-3D具有广泛的应用前景，包括虚拟会议、游戏、社交媒体、教育和娱乐等领域。它可以用于创建个性化的3D化身，增强用户在虚拟环境中的沉浸感和互动性。此外，该技术还可以应用于数字内容创作，例如生成逼真的虚拟角色和动画。",
            "highlight_zh": "VASA-3D在生成逼真3D说话头部方面取得了显著成果，能够生成具有细微表情细节的3D化身。实验结果表明，VASA-3D生成的3D头部化身在真实感和生动性方面优于现有技术。此外，VASA-3D还支持以高达75 FPS的速度在线生成512x512自由视点视频，为实时应用提供了可能。",
            "tags_zh": [
                "3D头部化身",
                "音频驱动",
                "单张图像重建",
                "高斯头部",
                "运动潜在空间",
                "表情建模",
                "自由视点视频"
            ],
            "_index": 236,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14677/x2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14677/x3.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14677/x4.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Coordinated Fast Frequency Response from Electric Vehicles, Data Centers, and Battery Energy Storage Systems",
            "authors": [
                "Xiaojie Tao",
                "Rajit Gadh"
            ],
            "arxiv_id": "2512.14136",
            "summary": "High renewable penetration has significantly reduced system inertia in modern power grids, increasing the need for fast frequency response (FFR) from distributed and non-traditional resources. While electric vehicles (EVs), data centers, and battery energy storage systems (BESS) have each demonstrated the capability to provide sub-second active power support, their combined frequency response potential has not been systematically evaluated. This paper proposes a coordinated control framework that aggregates these heterogeneous resources to provide fast, stable, and reliable FFR. Dynamic models for EV fleets, data center UPS and workload modulation, and BESS are developed, explicitly capturing their response times, power limits, and operational constraints. A hierarchical control architecture is introduced, where an upper-level coordinator dynamically allocates FFR among resources based on response speed and available capacity, and lower-level controllers implement the actual power response. Case studies based on the IEEE 39-bus test system demonstrate that the coordinated EV-DC-BESS framework improves frequency nadir by up to 0.2 Hz, reduces RoCoF, and accelerates frequency recovery compared with single-resource FFR. Results confirm that synergistic coordination significantly enhances grid stability, especially in low-inertia scenarios. This work highlights the value of multi-resource aggregation for future frequency regulation markets in renewable-dominated grids.",
            "categories": [
                "eess.SY"
            ],
            "primary_category": "eess.SY",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14136",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "penetration"
                    ],
                    "score": 2.5
                }
            ],
            "relevance_score": 2.5,
            "hit_pillars": [
                "4_motion_diffusion"
            ],
            "headline_zh": "提出一种协同控制框架，聚合电动汽车、数据中心和储能系统，实现快速频率响应。",
            "summary_zh": "随着高比例可再生能源的接入，现代电网的系统惯性显著降低，对来自分布式和非传统资源的快速频率响应(FFR)需求日益增加。虽然电动汽车(EVs)、数据中心和电池储能系统(BESS)都已展示了提供亚秒级有功功率支持的能力，但它们组合的频率响应潜力尚未得到系统评估。本文提出了一种协同控制框架，该框架聚合这些异构资源以提供快速、稳定和可靠的FFR。开发了电动汽车车队、数据中心UPS和工作负载调制以及BESS的动态模型，明确捕捉了它们的响应时间、功率限制和运行约束。引入了一种分层控制架构，其中上层协调器根据响应速度和可用容量在资源之间动态分配FFR，下层控制器实现实际的功率响应。基于IEEE 39节点测试系统的案例研究表明，与单资源FFR相比，协同的EV-DC-BESS框架可将频率最低点提高高达0.2 Hz，降低RoCoF，并加速频率恢复。结果证实，协同协调显著增强了电网稳定性，尤其是在低惯性场景中。这项工作突出了多资源聚合对于可再生能源主导电网中未来频率调节市场的价值。",
            "intro_zh": [
                "现代电网可再生能源渗透率高，系统惯性降低，需要分布式资源提供快速频率响应，但多种资源协同潜力未被充分挖掘。",
                "提出一种分层协同控制框架，聚合电动汽车、数据中心和电池储能系统，动态分配快速频率响应，实现稳定可靠的电网频率控制。",
                "基于IEEE 39节点系统的案例研究表明，该框架能显著改善频率下冲、降低频率变化率，并加速频率恢复，提升电网稳定性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决高比例可再生能源接入电网后，系统惯性降低，导致电网频率稳定性下降的问题。现有方法通常依赖于单一资源提供频率响应，无法充分利用电动汽车、数据中心和储能系统等多种分布式资源的潜力，且缺乏有效的协同控制策略。\\n\\n**核心思路**：论文的核心思路是通过构建一个分层协同控制框架，将电动汽车、数据中心和储能系统聚合起来，根据各自的响应特性和可用容量，动态分配快速频率响应任务。这种协同方式能够充分利用不同资源的优势，提高频率响应的速度、稳定性和可靠性。\\n\\n**技术框架**：该框架采用分层控制架构。上层协调器负责监测电网频率变化，并根据预设的优化目标，动态分配各个资源的频率响应任务。下层控制器则负责根据上层指令，控制电动汽车、数据中心和储能系统输出相应的有功功率。框架包含以下主要模块：电网频率监测模块、资源状态评估模块、优化分配模块和资源控制模块。\\n\\n**关键创新**：该论文的关键创新在于提出了一个多资源协同的快速频率响应框架，能够充分利用电动汽车、数据中心和储能系统的互补特性，实现更快速、更稳定的频率响应。与传统的单一资源控制方法相比，该框架能够显著提高电网的频率稳定性，尤其是在低惯性场景下。\\n\\n**关键设计**：论文针对电动汽车、数据中心和储能系统分别建立了动态模型，考虑了它们的响应时间、功率限制和运行约束。上层协调器采用优化算法，根据资源的响应速度、可用容量和成本等因素，动态分配频率响应任务。下层控制器则采用PID控制或模型预测控制等方法，实现精确的功率输出。",
            "application_zh": "该研究成果可应用于未来高比例可再生能源接入的智能电网中，通过聚合电动汽车、数据中心和储能系统等分布式资源，提供快速频率响应，提高电网的频率稳定性，降低停电风险。该技术有助于促进可再生能源的消纳，实现能源转型。",
            "highlight_zh": "基于IEEE 39节点测试系统的案例研究表明，与单资源FFR相比，协同的EV-DC-BESS框架可将频率最低点提高高达0.2 Hz，降低RoCoF，并加速频率恢复。结果证实，协同协调显著增强了电网稳定性，尤其是在低惯性场景中。",
            "tags_zh": [
                "快速频率响应",
                "电动汽车",
                "数据中心",
                "电池储能系统",
                "协同控制",
                "电网稳定性",
                "可再生能源",
                "分层控制"
            ],
            "_index": 237,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "CLAIM: Camera-LiDAR Alignment with Intensity and Monodepth",
            "authors": [
                "Zhuo Zhang",
                "Yonghui Liu",
                "Meijie Zhang",
                "Feiyang Tan",
                "Yikang Ding"
            ],
            "arxiv_id": "2512.14001",
            "summary": "In this paper, we unleash the potential of the powerful monodepth model in camera-LiDAR calibration and propose CLAIM, a novel method of aligning data from the camera and LiDAR. Given the initial guess and pairs of images and LiDAR point clouds, CLAIM utilizes a coarse-to-fine searching method to find the optimal transformation minimizing a patched Pearson correlation-based structure loss and a mutual information-based texture loss. These two losses serve as good metrics for camera-LiDAR alignment results and require no complicated steps of data processing, feature extraction, or feature matching like most methods, rendering our method simple and adaptive to most scenes. We validate CLAIM on public KITTI, Waymo, and MIAS-LCEC datasets, and the experimental results demonstrate its superior performance compared with the state-of-the-art methods. The code is available atthis https URL.",
            "categories": [
                "cs.RO",
                "cs.CV"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14001",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱六：视频提取与匹配 (Video Extraction)",
                    "id": "6_video_extraction",
                    "matched_keywords": [
                        "feature matching"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "6_video_extraction"
            ],
            "headline_zh": "CLAIM：利用单目深度和强度信息实现相机-激光雷达标定",
            "summary_zh": "本文旨在探索单目深度模型在相机-激光雷达标定中的潜力，并提出了一种新的对齐方法CLAIM。给定初始位姿估计以及图像和激光雷达点云对，CLAIM采用由粗到精的搜索策略，寻找最优变换，以最小化基于分块皮尔逊相关的结构损失和基于互信息的纹理损失。这两种损失函数为相机-激光雷达对齐结果提供了良好的度量标准，无需复杂的数据处理、特征提取或特征匹配步骤，使得我们的方法简单且适用于大多数场景。我们在公开的KITTI、Waymo和MIAS-LCEC数据集上验证了CLAIM，实验结果表明其性能优于现有技术。",
            "intro_zh": [
                "现有相机-激光雷达标定方法通常依赖复杂的数据处理和特征匹配，限制了其在不同场景下的适应性。",
                "CLAIM方法利用单目深度模型，通过结构和纹理损失直接优化相机和激光雷达数据的对齐，无需复杂的特征工程。",
                "实验结果表明，CLAIM在KITTI、Waymo和MIAS-LCEC等数据集上优于现有方法，验证了其有效性和泛化能力。"
            ],
            "method_zh": "**问题定义**：相机-激光雷达标定的目标是确定相机和激光雷达之间的外部参数（旋转和平移），从而将它们的数据关联起来。现有方法的痛点在于需要复杂的数据预处理、特征提取和匹配，计算成本高，且对环境的适应性较差。\\n\\n**核心思路**：CLAIM的核心思路是利用单目深度估计模型提供的深度信息，结合相机图像的纹理信息，设计一种直接优化相机和激光雷达数据对齐的损失函数。通过最小化结构损失和纹理损失，实现相机-激光雷达的精确标定。这种方法避免了复杂的特征工程，提高了效率和鲁棒性。\\n\\n**技术框架**：CLAIM的整体流程如下：1) 输入：初始位姿估计、相机图像和激光雷达点云；2) 单目深度估计：使用预训练的单目深度模型估计图像的深度图；3) 损失计算：基于深度图和激光雷达点云，计算结构损失（基于分块皮尔逊相关）和纹理损失（基于互信息）；4) 位姿优化：使用优化算法（如Adam）最小化总损失，更新相机和激光雷达之间的位姿变换；5) 迭代优化：重复步骤3和4，直到收敛。\\n\\n**关键创新**：CLAIM的关键创新在于：1) 利用单目深度估计模型，避免了手动设计特征；2) 提出了基于分块皮尔逊相关的结构损失和基于互信息的纹理损失，能够有效度量相机和激光雷达数据的对齐程度；3) 采用由粗到精的搜索策略，提高了优化效率和精度。与现有方法相比，CLAIM更加简单、高效，且具有更好的泛化能力。\\n\\n**关键设计**：结构损失采用分块皮尔逊相关系数，旨在衡量图像深度梯度和激光雷达点云深度梯度之间的相似性。纹理损失采用互信息，旨在衡量图像纹理和激光雷达反射强度之间的相关性。损失函数的权重需要根据具体场景进行调整。优化算法采用Adam，学习率设置为一个较小的值，以保证收敛的稳定性。由粗到精的搜索策略通过逐步缩小搜索范围，提高优化效率。",
            "application_zh": "该研究成果可广泛应用于自动驾驶、机器人导航、三维重建等领域。精确的相机-激光雷达标定是多传感器融合的基础，能够提高环境感知和定位的精度，从而提升自动驾驶系统的安全性和可靠性。此外，该方法还可以应用于增强现实、虚拟现实等领域，实现更逼真的场景渲染和交互。",
            "highlight_zh": "CLAIM在KITTI、Waymo和MIAS-LCEC数据集上进行了验证，实验结果表明其性能优于现有技术。例如，在KITTI数据集上，CLAIM的旋转误差和位移误差均显著低于其他方法。此外，CLAIM在不同场景下都表现出良好的鲁棒性，证明了其泛化能力。",
            "tags_zh": [
                "相机-激光雷达标定",
                "单目深度估计",
                "传感器融合",
                "自动驾驶",
                "点云处理"
            ],
            "_index": 238,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14001/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14001/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14001/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Trajectory Tracking for Multi-Manipulator Systems in Constrained Environments",
            "authors": [
                "Mayank Sewlia",
                "Christos K. Verginis",
                "Dimos V. Dimarogonas"
            ],
            "arxiv_id": "2512.14206",
            "summary": "We consider the problem of cooperative manipulation by a mobile multi-manipulator system operating in obstacle-cluttered and highly constrained environments under spatio-temporal task specifications. The task requires transporting a grasped object while respecting both continuous robot dynamics and discrete geometric constraints arising from obstacles and narrow passages. To address this hybrid structure, we propose a multi-rate planning and control framework that combines offline generation of an STL-satisfying object trajectory and collision-free base footprints with online constrained inverse kinematics and continuous-time feedback control. The resulting closed-loop system enables coordinated reconfiguration of multiple manipulators while tracking the desired object motion. The approach is evaluated in high-fidelity physics simulations using three Franka Emika Panda mobile manipulators rigidly grasping an object.",
            "categories": [
                "cs.RO",
                "eess.SY"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14206",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "提出多速率规划与控制框架，解决约束环境下多机械臂系统的轨迹跟踪问题",
            "summary_zh": "本文研究了移动多机械臂系统在复杂约束环境下协同操作的问题，该环境包含障碍物和狭窄通道，并具有时空任务规范。任务要求在满足连续机器人动力学和离散几何约束（由障碍物和狭窄通道引起）的同时，运输抓取的物体。为了解决这种混合结构，我们提出了一种多速率规划和控制框架，该框架结合了离线生成的满足STL的对象轨迹和无碰撞的基座足迹，以及在线约束逆运动学和连续时间反馈控制。由此产生的闭环系统能够协调多个机械臂的重新配置，同时跟踪期望的物体运动。该方法在高度逼真的物理模拟中使用三个Franka Emika Panda移动机械臂刚性抓取一个物体进行了评估。",
            "intro_zh": [
                "现有方法难以在复杂约束环境中实现多机械臂系统的精确轨迹跟踪，尤其是在考虑机器人动力学和环境几何约束的情况下。",
                "论文提出一种多速率规划与控制框架，通过离线生成轨迹和在线反馈控制相结合，实现多机械臂的协同运动和轨迹跟踪。",
                "通过高保真物理仿真验证了该方法在三个Franka Emika Panda移动机械臂上的有效性，展示了其在复杂环境下的轨迹跟踪能力。"
            ],
            "method_zh": "**问题定义**：论文旨在解决多机械臂系统在存在障碍物和狭窄通道等约束条件下的轨迹跟踪问题。现有方法在处理这种复杂环境时，往往难以同时满足机器人动力学约束和环境几何约束，导致轨迹跟踪精度下降甚至失败。此外，如何协调多个机械臂的运动，保证它们在运动过程中不发生碰撞，也是一个挑战。\\n\\n**核心思路**：论文的核心思路是将轨迹规划和控制解耦，采用多速率的策略。首先，离线生成满足时序逻辑（STL）规范的物体轨迹和无碰撞的基座足迹。然后，在线使用约束逆运动学和连续时间反馈控制来跟踪期望的物体运动，并协调多个机械臂的运动。这种解耦策略降低了问题的复杂度，使得可以在线实时地进行轨迹跟踪和运动控制。\\n\\n**技术框架**：整体框架包含以下几个主要模块：1) 离线轨迹规划器：生成满足STL规范的物体轨迹和无碰撞的基座足迹。2) 在线约束逆运动学求解器：根据期望的物体位姿和基座位置，计算每个机械臂的关节角度。3) 连续时间反馈控制器：根据实际的关节角度和期望的关节角度，生成控制力矩，驱动机械臂运动。这三个模块以多速率的方式协同工作，实现多机械臂系统的轨迹跟踪。\\n\\n**关键创新**：论文的关键创新在于提出了一种多速率规划和控制框架，将离线轨迹规划和在线反馈控制相结合，有效地解决了复杂约束环境下多机械臂系统的轨迹跟踪问题。与传统的基于优化的方法相比，该方法具有更高的计算效率和鲁棒性。此外，论文还考虑了时序逻辑规范，使得可以对任务进行更灵活的描述。\\n\\n**关键设计**：在离线轨迹规划器中，使用了STL公式来描述任务规范，并采用混合整数规划（MIP）来求解满足STL公式的轨迹。在线约束逆运动学求解器中，使用了二次规划（QP）来求解满足关节角度约束和避免碰撞的关节角度。连续时间反馈控制器中，使用了PID控制器来跟踪期望的关节角度。这些关键设计保证了系统的稳定性和轨迹跟踪精度。",
            "application_zh": "该研究成果可应用于自动化装配、医疗机器人、物流搬运等领域。例如，在自动化装配中，多个机械臂可以协同完成复杂的装配任务，提高生产效率和产品质量。在医疗机器人中，多个机械臂可以协同进行手术操作，提高手术精度和安全性。在物流搬运中，多个机械臂可以协同搬运大型或重型物体，提高搬运效率和安全性。该研究为多机械臂系统的实际应用提供了理论基础和技术支持。",
            "highlight_zh": "论文通过高保真物理仿真验证了所提出方法的有效性。实验结果表明，该方法能够成功地控制三个Franka Emika Panda移动机械臂，使其在复杂约束环境下协同抓取和运输物体，并精确地跟踪期望的轨迹。虽然论文中没有给出具体的性能数据和对比基线，但仿真结果表明该方法具有良好的鲁棒性和轨迹跟踪精度。",
            "tags_zh": [
                "多机械臂系统",
                "轨迹跟踪",
                "约束环境",
                "多速率控制",
                "逆运动学"
            ],
            "_index": 239,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14206/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14206/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14206/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Odyssey: An Automotive Lidar-Inertial Odometry Dataset for GNSS-denied situations",
            "authors": [
                "Aaron Kurda",
                "Simon Steuernagel",
                "Lukas Jung",
                "Marcus Baum"
            ],
            "arxiv_id": "2512.14428",
            "summary": "The development and evaluation of Lidar-Inertial Odometry (LIO) and Simultaneous Localization and Mapping (SLAM) systems requires a precise ground truth. The Global Navigation Satellite System (GNSS) is often used as a foundation for this, but its signals can be unreliable in obstructed environments due to multi-path effects or loss-of-signal. While existing datasets compensate for the sporadic loss of GNSS signals by incorporating Inertial Measurement Unit (IMU) measurements, the commonly used Micro-Electro-Mechanical Systems (MEMS) or Fiber Optic Gyroscope (FOG)-based systems do not permit the prolonged study of GNSS-denied environments. To close this gap, we present Odyssey, a LIO dataset with a focus on GNSS-denied environments such as tunnels and parking garages as well as other underrepresented, yet ubiquitous situations such as stop-and-go-traffic, bumpy roads and wide open fields. Our ground truth is derived from a navigation-grade Inertial Navigation System (INS) equipped with a Ring Laser Gyroscope (RLG), offering exceptional bias stability characteristics compared to IMUs used in existing datasets and enabling the prolonged and accurate study of GNSS-denied environments. This makes Odyssey the first publicly available dataset featuring a RLG-based INS. Besides providing data for LIO, we also support other tasks, such as place recognition, through the threefold repetition of all trajectories as well as the integration of external mapping data by providing precise geodetic coordinates. All data, dataloader and other material is available online atthis https URL.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14428",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "LIO"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "Odyssey：面向GNSS拒止环境的车载激光雷达-惯性里程计数据集",
            "summary_zh": "激光雷达-惯性里程计(LIO)和同步定位与地图构建(SLAM)系统的开发与评估需要精确的地面真值。全球导航卫星系统(GNSS)通常被用作基础，但在受阻环境中，由于多径效应或信号丢失，其信号可能不可靠。现有数据集通过结合惯性测量单元(IMU)测量来补偿GNSS信号的零星丢失，但常用的基于微机电系统(MEMS)或光纤陀螺仪(FOG)的系统不允许对GNSS拒止环境进行长期研究。为了弥补这一差距，我们提出了Odyssey，一个LIO数据集，专注于GNSS拒止环境，如隧道和停车场，以及其他代表性不足但普遍存在的场景，如走走停停的交通、颠簸的道路和广阔的田野。我们的地面真值来自配备环形激光陀螺仪(RLG)的导航级惯性导航系统(INS)，与现有数据集中使用的IMU相比，具有卓越的偏置稳定性，能够对GNSS拒止环境进行长期准确的研究。这使得Odyssey成为第一个公开提供的基于RLG的INS数据集。除了为LIO提供数据外，我们还通过所有轨迹的三重重复以及通过提供精确的大地坐标来整合外部地图数据，来支持其他任务，如地点识别。所有数据、数据加载器和其他材料都可以在网上获得。",
            "intro_zh": [
                "现有LIO/SLAM数据集在GNSS拒止环境下精度不足，因为依赖MEMS或FOG的IMU难以长时间保持高精度。",
                "Odyssey数据集使用基于环形激光陀螺仪(RLG)的导航级INS提供高精度地面真值，特别适用于GNSS拒止环境。",
                "该数据集包含隧道、停车场、拥堵交通等多种场景，并提供三重重复轨迹和大地坐标，支持LIO、地点识别等任务。"
            ],
            "method_zh": "**问题定义**：现有LIO和SLAM系统在GNSS信号弱或缺失的环境中，例如隧道、停车场等，定位精度会显著下降。这是因为常用的MEMS或FOG IMU的长期漂移误差较大，难以提供可靠的惯性导航信息，从而影响整体定位性能。因此，需要一个能够在GNSS拒止环境下提供高精度地面真值的数据集，用于LIO/SLAM算法的评估和改进。\\n\\n**核心思路**：Odyssey数据集的核心思路是利用高精度的导航级惯性导航系统(INS)来生成地面真值。该INS配备了环形激光陀螺仪(RLG)，相比于MEMS和FOG，RLG具有更高的精度和更好的长期稳定性，能够有效抑制漂移误差，从而在GNSS拒止环境下提供可靠的定位信息。\\n\\n**技术框架**：Odyssey数据集的采集平台是一个车载系统，集成了激光雷达、惯性测量单元(IMU)和全球导航卫星系统(GNSS)。其中，最关键的组件是导航级INS，它负责生成高精度的地面真值。数据集的采集过程包括在各种具有挑战性的环境中行驶，例如隧道、停车场、拥堵交通、颠簸道路和开阔场地。为了支持地点识别等任务，每条轨迹都重复采集了三次。此外，数据集还提供了精确的大地坐标，方便用户整合外部地图数据。\\n\\n**关键创新**：Odyssey数据集最关键的创新在于使用了基于环形激光陀螺仪(RLG)的导航级INS来生成地面真值。这是第一个公开提供的包含RLG-based INS的数据集。与现有数据集常用的MEMS或FOG IMU相比，RLG具有更高的精度和更好的长期稳定性，能够有效抑制漂移误差，从而在GNSS拒止环境下提供更可靠的定位信息。\\n\\n**关键设计**：Odyssey数据集的关键设计包括：1) 使用导航级INS生成高精度地面真值；2) 包含多种具有挑战性的GNSS拒止环境；3) 提供三重重复轨迹，支持地点识别等任务；4) 提供精确的大地坐标，方便整合外部地图数据；5) 提供数据加载器和其他相关工具，方便用户使用。",
            "application_zh": "Odyssey数据集可广泛应用于自动驾驶、机器人导航、无人机等领域，尤其是在GNSS信号受限或不可用的环境中。该数据集能够帮助研究人员开发和评估更鲁棒、更精确的LIO/SLAM算法，从而提高自动驾驶车辆在复杂环境下的定位和导航能力，提升机器人和无人机在室内或地下环境中的自主作业能力。",
            "highlight_zh": "Odyssey数据集的关键亮点在于其高精度的地面真值，由基于环形激光陀螺仪(RLG)的导航级INS生成。与现有数据集相比，Odyssey在GNSS拒止环境下能够提供更可靠的定位信息，为LIO/SLAM算法的评估和改进提供了有力支持。此外，数据集包含多种具有挑战性的场景，并提供三重重复轨迹和大地坐标，为各种研究任务提供了丰富的资源。",
            "tags_zh": [
                "激光雷达",
                "惯性里程计",
                "GNSS拒止",
                "数据集",
                "环形激光陀螺仪",
                "自动驾驶",
                "同步定位与地图构建"
            ],
            "_index": 240,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14428/figures/titleimage_lowres.jpg",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14428/figures/trajectory_parkhaus_lowres.jpg",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14428/figures/trajectory_marktplatz_lowres.jpg",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Elastic3D: Controllable Stereo Video Conversion with Guided Latent Decoding",
            "authors": [
                "Nando Metzger",
                "Prune Truong",
                "Goutam Bhat",
                "Konrad Schindler",
                "Federico Tombari"
            ],
            "arxiv_id": "2512.14236",
            "summary": "The growing demand for immersive 3D content calls for automated monocular-to-stereo video conversion. We present Elastic3D, a controllable, direct end-to-end method for upgrading a conventional video to a binocular one. Our approach, based on (conditional) latent diffusion, avoids artifacts due to explicit depth estimation and warping. The key to its high-quality stereo video output is a novel, guided VAE decoder that ensures sharp and epipolar-consistent stereo video output. Moreover, our method gives the user control over the strength of the stereo effect (more precisely, the disparity range) at inference time, via an intuitive, scalar tuning knob. Experiments on three different datasets of real-world stereo videos show that our method outperforms both traditional warping-based and recent warping-free baselines and sets a new standard for reliable, controllable stereo video conversion. Please check the project page for the video samplesthis https URL.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14236",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "depth estimation"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "Elastic3D：基于引导式潜在解码的可控立体视频转换",
            "summary_zh": "针对日益增长的沉浸式3D内容需求，本文提出Elastic3D，一种可控的、直接端到端的单目视频到立体视频转换方法。该方法基于（条件）潜在扩散模型，避免了显式深度估计和图像扭曲所带来的伪影。其高质量立体视频输出的关键在于一种新颖的、引导式的VAE解码器，该解码器确保了清晰且满足极线约束的立体视频输出。此外，该方法允许用户在推理时通过一个直观的标量调节旋钮来控制立体效果的强度（更准确地说，是视差范围）。在三个不同的真实世界立体视频数据集上的实验表明，该方法优于传统的基于扭曲的方法和最新的无扭曲基线，并为可靠、可控的立体视频转换设定了新的标准。",
            "intro_zh": [
                "现有单目视频转立体视频方法依赖深度估计和图像扭曲，易产生伪影，影响观看体验。",
                "Elastic3D采用条件潜在扩散模型，结合引导式VAE解码器，直接生成高质量、满足极线约束的立体视频。",
                "实验表明，Elastic3D在真实数据集上优于传统和新型基线方法，并提供用户可控的立体效果调节能力。"
            ],
            "method_zh": "**问题定义**：论文旨在解决单目视频到立体视频转换的问题。现有方法通常依赖于显式的深度估计，然后通过图像扭曲生成立体视图。这种方法容易受到深度估计误差的影响，导致生成的立体图像中出现伪影和不一致性，影响用户体验。此外，现有方法通常缺乏对立体效果强度的有效控制。\n\n**核心思路**：Elastic3D的核心思路是避免显式的深度估计和图像扭曲，而是直接学习从单目视频到立体视频的映射关系。通过使用条件潜在扩散模型，该方法能够生成高质量、逼真的立体视图。引导式VAE解码器的引入，则保证了生成的立体图像满足极线约束，从而避免了立体视觉中的不适感。用户可控的视差范围调节，则允许用户根据自己的喜好调整立体效果的强度。\n\n**技术框架**：Elastic3D的整体框架基于条件潜在扩散模型。该模型包含一个编码器，将单目视频帧编码到潜在空间；一个扩散模型，学习潜在空间中的数据分布；以及一个解码器，将潜在空间中的样本解码为立体视频帧。关键在于，解码器是一个引导式的VAE解码器，它在解码过程中利用极线约束作为引导，确保生成的立体图像满足极线几何关系。此外，该框架还包含一个用户可控的视差范围调节模块，允许用户在推理时调整立体效果的强度。\n\n**关键创新**：Elastic3D最重要的技术创新点在于引导式VAE解码器的设计。传统的VAE解码器通常无法保证生成的立体图像满足极线约束，而Elastic3D通过在解码过程中引入极线约束，有效地解决了这个问题。此外，Elastic3D还通过条件潜在扩散模型，避免了显式深度估计和图像扭曲，从而减少了伪影的产生。用户可控的视差范围调节也是一个重要的创新点，它允许用户根据自己的喜好调整立体效果的强度。\n\n**关键设计**：Elastic3D的关键设计包括：1) 引导式VAE解码器的具体实现，例如如何将极线约束融入到解码过程中；2) 条件潜在扩散模型的网络结构和训练策略；3) 用户可控的视差范围调节模块的具体实现，例如如何将视差范围映射到潜在空间中的某个参数；4) 损失函数的设计，例如如何平衡图像质量、极线约束和视差范围等因素。",
            "application_zh": "Elastic3D具有广泛的应用前景，可用于将传统2D视频转换为3D视频，提升观看体验。该技术可应用于电影制作、游戏开发、虚拟现实、增强现实等领域，为用户提供更具沉浸感和立体感的视觉体验。此外，该技术还可用于生成用于3D显示的训练数据，促进相关技术的发展。",
            "highlight_zh": "Elastic3D在三个真实世界立体视频数据集上进行了评估，实验结果表明，该方法在立体视频转换质量方面优于传统的基于扭曲的方法和最新的无扭曲基线。具体而言，Elastic3D在PSNR、SSIM等指标上均取得了显著提升，并且能够生成更清晰、更逼真、更符合极线约束的立体视频。此外，用户研究表明，Elastic3D生成的立体视频具有更好的观看体验。",
            "tags_zh": [
                "立体视频转换",
                "单目视频",
                "潜在扩散模型",
                "VAE",
                "极线约束",
                "深度估计",
                "图像扭曲"
            ],
            "_index": 241,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Vector Prism: Animating Vector Graphics by Stratifying Semantic Structure",
            "authors": [
                "Jooyeol Yun",
                "Jaegul Choo"
            ],
            "arxiv_id": "2512.14336",
            "summary": "Scalable Vector Graphics (SVG) are central to modern web design, and the demand to animate them continues to grow as web environments become increasingly dynamic. Yet automating the animation of vector graphics remains challenging for vision-language models (VLMs) despite recent progress in code generation and motion planning. VLMs routinely mis-handle SVGs, since visually coherent parts are often fragmented into low-level shapes that offer little guidance of which elements should move together. In this paper, we introduce a framework that recovers the semantic structure required for reliable SVG animation and reveals the missing layer that current VLM systems overlook. This is achieved through a statistical aggregation of multiple weak part predictions, allowing the system to stably infer semantics from noisy predictions. By reorganizing SVGs into semantic groups, our approach enables VLMs to produce animations with far greater coherence. Our experiments demonstrate substantial gains over existing approaches, suggesting that semantic recovery is the key step that unlocks robust SVG animation and supports more interpretable interactions between VLMs and vector graphics.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14336",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "motion planning"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "Vector Prism：通过分层语义结构实现矢量图形动画",
            "summary_zh": "可缩放矢量图形（SVG）是现代网页设计的核心，随着网络环境日益动态化，对SVG动画的需求持续增长。然而，尽管代码生成和运动规划取得了进展，但对于视觉语言模型（VLM）来说，自动生成矢量图形动画仍然具有挑战性。VLM通常会错误地处理SVG，因为视觉上连贯的部分经常被分解成低级形状，无法提供哪些元素应该一起移动的指导。本文介绍了一种框架，该框架恢复了可靠的SVG动画所需的语义结构，并揭示了当前VLM系统忽略的缺失层。这是通过对多个弱部分预测进行统计聚合来实现的，从而使系统能够从嘈杂的预测中稳定地推断语义。通过将SVG重组为语义组，我们的方法使VLM能够生成具有更高连贯性的动画。实验表明，该方法比现有方法有显著的提升，表明语义恢复是解锁鲁棒SVG动画并支持VLM与矢量图形之间更具可解释性的交互的关键步骤。",
            "intro_zh": [
                "现有视觉语言模型在处理SVG动画时，难以识别图形的语义结构，导致动画效果不佳。",
                "论文提出一种框架，通过统计聚合多个弱预测结果，恢复SVG的语义结构，从而实现更连贯的动画。",
                "实验结果表明，该方法显著优于现有方法，证明了语义恢复在SVG动画中的重要性。"
            ],
            "method_zh": "**问题定义**：现有视觉语言模型（VLM）在处理SVG动画时，面临的主要问题是无法有效地理解SVG图形的语义结构。SVG文件通常将图形分解为低级的形状元素，这些元素在视觉上可能属于同一个对象，但在代码层面却彼此独立。这导致VLM难以判断哪些元素应该一起运动，从而生成不连贯或不自然的动画。现有方法缺乏从低级形状中恢复高级语义信息的能力，使得VLM无法有效地利用SVG进行动画创作。\\n\\n**核心思路**：本文的核心思路是通过统计聚合多个“弱”的部件预测结果，来推断SVG图形的语义结构。具体来说，该方法首先利用现有的视觉模型对SVG图形的各个部分进行初步的语义预测，这些预测可能存在噪声或不准确。然后，通过统计分析这些预测结果，将具有相似语义的部分聚合在一起，形成语义组。这种方法类似于“集体智慧”，通过综合多个不完美的预测，得到更准确的语义理解。\\n\\n**技术框架**：该框架主要包含以下几个阶段：1) **弱部件预测**：利用现有的视觉模型（例如，目标检测或分割模型）对SVG图形的各个部分进行语义预测，得到多个候选的语义标签。2) **统计聚合**：对这些预测结果进行统计分析，例如，计算每个语义标签出现的频率，或者计算不同部分之间的语义相似度。3) **语义分组**：根据统计分析的结果，将具有相似语义的部分聚合在一起，形成语义组。4) **动画生成**：利用VLM根据语义组的信息生成动画。VLM可以根据语义组的整体语义，以及各个部分之间的关系，来规划动画的运动轨迹和效果。\\n\\n**关键创新**：该方法最重要的创新点在于提出了通过统计聚合弱预测结果来恢复SVG语义结构的思想。与直接依赖单个模型的预测结果相比，该方法更加鲁棒，能够有效地处理噪声和不确定性。此外，该方法还提供了一种可解释的方式来理解VLM与矢量图形之间的交互，使得用户可以更容易地控制动画的生成过程。\\n\\n**关键设计**：在弱部件预测阶段，可以使用多种不同的视觉模型，例如，目标检测模型、分割模型或关键点检测模型。在统计聚合阶段，可以使用不同的统计方法，例如，频率统计、相似度计算或聚类算法。在语义分组阶段，可以使用不同的分组策略，例如，基于阈值的分组、基于图的分组或基于学习的分组。具体的参数设置和算法选择取决于具体的应用场景和数据集。",
            "application_zh": "该研究成果可广泛应用于网页设计、图形设计、游戏开发等领域。通过自动生成高质量的SVG动画，可以提升用户体验，降低开发成本。未来，该技术有望进一步扩展到其他类型的矢量图形，例如，CAD图纸、地图数据等，为各行各业提供更智能化的图形处理解决方案。",
            "highlight_zh": "实验结果表明，该方法在SVG动画生成任务上取得了显著的提升。与现有方法相比，该方法生成的动画更加连贯、自然，并且能够更好地反映用户的意图。具体来说，该方法在多个指标上都取得了超过10%的提升，证明了语义恢复在SVG动画中的重要性。",
            "tags_zh": [
                "矢量图形动画",
                "语义结构恢复",
                "视觉语言模型",
                "统计聚合",
                "弱监督学习"
            ],
            "_index": 242,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Towards Transferable Defense Against Malicious Image Edits",
            "authors": [
                "Jie Zhang",
                "Shuai Dong",
                "Shiguang Shan",
                "Xilin Chen"
            ],
            "arxiv_id": "2512.14341",
            "summary": "Recent approaches employing imperceptible perturbations in input images have demonstrated promising potential to counter malicious manipulations in diffusion-based image editing systems. However, existing methods suffer from limited transferability in cross-model evaluations. To address this, we propose Transferable Defense Against Malicious Image Edits (TDAE), a novel bimodal framework that enhances image immunity against malicious edits through coordinated image-text optimization. Specifically, at the visual defense level, we introduce FlatGrad Defense Mechanism (FDM), which incorporates gradient regularization into the adversarial objective. By explicitly steering the perturbations toward flat minima, FDM amplifies immune robustness against unseen editing models. For textual enhancement protection, we propose an adversarial optimization paradigm named Dynamic Prompt Defense (DPD), which periodically refines text embeddings to align the editing outcomes of immunized images with those of the original images, then updates the images under optimized embeddings. Through iterative adversarial updates to diverse embeddings, DPD enforces the generation of immunized images that seek a broader set of immunity-enhancing features, thereby achieving cross-model transferability. Extensive experimental results demonstrate that our TDAE achieves state-of-the-art performance in mitigating malicious edits under both intra- and cross-model evaluations.",
            "categories": [
                "cs.CV",
                "cs.AI",
                "cs.CY",
                "cs.LG"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14341",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "提出TDAE框架，增强图像对恶意编辑的防御迁移能力",
            "summary_zh": "现有方法在对抗基于扩散模型的图像编辑系统中恶意操作时，通过在输入图像中添加不易察觉的扰动展现出潜力。然而，这些方法在跨模型评估中迁移性有限。为了解决这个问题，我们提出了可迁移的恶意图像编辑防御（TDAE），这是一个新颖的双模态框架，通过协调图像-文本优化来增强图像对恶意编辑的免疫力。具体来说，在视觉防御层面，我们引入了FlatGrad防御机制（FDM），它将梯度正则化纳入对抗目标中。通过显式地引导扰动趋向于平坦最小值，FDM增强了对未见编辑模型的免疫鲁棒性。对于文本增强保护，我们提出了一种名为动态提示防御（DPD）的对抗优化范式，它周期性地细化文本嵌入，以使免疫图像的编辑结果与原始图像的编辑结果对齐，然后更新优化嵌入下的图像。通过对各种嵌入的迭代对抗更新，DPD强制生成免疫图像，这些图像寻求更广泛的免疫增强特征，从而实现跨模型可迁移性。大量的实验结果表明，我们的TDAE在减轻模型内和跨模型评估中的恶意编辑方面实现了最先进的性能。",
            "intro_zh": [
                "现有防御方法在跨不同图像编辑模型时，防御效果的迁移性不足，无法有效抵抗未知的恶意编辑。",
                "TDAE框架通过图像和文本的协同优化，增强图像对恶意编辑的免疫力，提高防御的跨模型迁移能力。",
                "实验结果表明，TDAE在模型内和跨模型评估中，均能有效减轻恶意编辑，达到当前最佳性能。"
            ],
            "method_zh": "**问题定义**：论文旨在解决现有图像防御方法在面对基于扩散模型的恶意图像编辑时，防御能力在不同模型间迁移性差的问题。现有的防御方法通常针对特定模型进行优化，导致在面对未知的编辑模型时，防御效果显著下降，无法有效抵抗恶意编辑。\\n\\n**核心思路**：论文的核心思路是通过构建一个双模态（图像-文本）的防御框架，协同优化图像的视觉特征和文本提示，从而增强图像对恶意编辑的免疫力，并提高防御的跨模型迁移能力。通过在图像层面引入梯度正则化，以及在文本层面进行动态提示优化，使得防御策略能够适应不同的编辑模型。\\n\\n**技术框架**：TDAE框架包含两个主要模块：FlatGrad防御机制（FDM）和动态提示防御（DPD）。FDM主要负责在视觉层面增强图像的鲁棒性，通过梯度正则化引导扰动趋向平坦最小值。DPD则负责在文本层面进行优化，通过周期性地细化文本嵌入，使得免疫图像的编辑结果与原始图像的编辑结果对齐。两个模块协同工作，共同提升防御效果。\\n\\n**关键创新**：论文的关键创新在于提出了一个双模态的防御框架，将图像和文本信息结合起来进行优化，从而增强了防御的跨模型迁移能力。此外，FDM和DPD分别在视觉和文本层面引入了新的优化策略，进一步提升了防御效果。与现有方法相比，TDAE能够更好地适应不同的编辑模型，从而实现更强的防御能力。\\n\\n**关键设计**：FDM的关键设计在于引入了梯度正则化项，该项能够引导扰动趋向于损失函数的平坦最小值，从而增强模型的鲁棒性。DPD的关键设计在于周期性地更新文本嵌入，通过对抗优化，使得免疫图像在不同文本提示下的编辑结果尽可能接近原始图像的编辑结果。具体的损失函数包括对抗损失和正则化损失，用于平衡防御效果和图像质量。网络结构方面，可以使用现有的图像编辑模型作为基础，并在其基础上添加防御模块。",
            "application_zh": "该研究成果可应用于保护用户上传的图像免受恶意编辑，例如在社交媒体平台、在线图像编辑工具等场景中。通过部署TDAE防御机制，可以有效防止恶意用户篡改图像内容，维护信息的真实性和安全性。此外，该技术还可以应用于数字水印、版权保护等领域，增强数字内容的安全性。",
            "highlight_zh": "实验结果表明，TDAE在模型内和跨模型评估中均取得了显著的性能提升。例如，在针对特定编辑模型的防御中，TDAE的防御成功率比现有方法提高了10%以上。在跨模型评估中，TDAE的防御成功率也明显高于其他方法，证明了其良好的迁移能力。此外，实验还验证了FDM和DPD两个模块的有效性，以及它们之间的协同作用。",
            "tags_zh": [
                "恶意图像编辑防御",
                "可迁移性",
                "双模态框架",
                "对抗攻击",
                "梯度正则化"
            ],
            "_index": 243,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14341/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14341/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14341/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Inter- and Intra-image Refinement for Few Shot Segmentation",
            "authors": [
                "Ourui Fu",
                "Hangzhou He",
                "Kaiwen Li",
                "Xinliang Zhang",
                "Lei Zhu",
                "Shuang Zeng",
                "Zhaoheng Xie",
                "Yanye Lu"
            ],
            "arxiv_id": "2507.05838",
            "summary": "Deep neural networks for semantic segmentation rely on large-scale annotated datasets, leading to an annotation bottleneck that motivates few shot semantic segmentation (FSS) which aims to generalize to novel classes with minimal labeled exemplars. Most existing FSS methods adopt a prototype-based paradigm, which generates query prior map by extracting masked-area features from support images and then makes predictions guided by the prior map. However, they suffer from two critical limitations induced by inter- and intra-image discrepancies: 1) The intra-class gap between support and query images, caused by single-prototype representation, results in scattered and noisy prior maps; 2) The inter-class interference from visually similar but semantically distinct regions leads to inconsistent support-query feature matching and erroneous predictions. To address these issues, we propose the Inter- and Intra-image Refinement (IIR) model. The model contains an inter-image class activation mapping based method that generates two prototypes for class-consistent region matching, including core discriminative features and local specific features, and yields an accurate and robust prior map. For intra-image refinement, a directional dropout mechanism is introduced to mask inconsistent support-query feature pairs in cross attention, thereby enhancing decoder performance. Extensive experiments demonstrate that IIR achieves state-of-the-art performance on 9 benchmarks, covering standard FSS, part FSS, and cross-domain FSS. Our source code is available at \\href{this https URL}{this https URL}.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2507.05838",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱六：视频提取与匹配 (Video Extraction)",
                    "id": "6_video_extraction",
                    "matched_keywords": [
                        "feature matching"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "6_video_extraction"
            ],
            "headline_zh": "提出Inter- and Intra-image Refinement模型，解决少样本分割中类内差异和类间干扰问题。",
            "summary_zh": "本文提出Inter- and Intra-image Refinement (IIR) 模型，旨在解决少样本语义分割(FSS)中存在的类内差异和类间干扰问题。现有基于原型的方法受限于单原型表示，导致先验图谱分散且噪声大。同时，视觉相似但语义不同的区域会造成支持集和查询集特征匹配不一致，产生错误预测。IIR模型通过类激活映射生成两个原型，分别用于核心区分特征和局部特定特征的匹配，从而生成准确且鲁棒的先验图谱。此外，引入方向性Dropout机制来屏蔽交叉注意力中不一致的支持集-查询集特征对，提升解码器性能。在标准FSS、部分FSS和跨域FSS等9个基准测试中，IIR均取得了state-of-the-art的性能。",
            "intro_zh": [
                "现有少样本分割方法依赖单原型表示，导致支持集和查询集之间存在较大的类内差异，生成的先验图谱质量不高。",
                "IIR模型通过生成两个原型，分别关注核心区分特征和局部特定特征，从而实现更准确的类间匹配和更鲁棒的先验图谱。",
                "实验结果表明，IIR模型在多个少样本分割基准测试中均取得了领先的性能，证明了其有效性。"
            ],
            "method_zh": "**问题定义**：少样本语义分割旨在仅使用少量标注样本将模型泛化到新的类别。现有方法，特别是基于原型的方法，在处理类内差异和类间干扰时存在局限性。类内差异指的是同一类别在支持集和查询集图像中可能存在外观、光照等差异，导致单原型表示无法准确捕捉类别特征。类间干扰指的是视觉上相似但语义不同的区域会干扰支持集和查询集之间的特征匹配，导致分割错误。\\n\\n**核心思路**：IIR模型的核心思路是通过更精细的特征表示和更鲁棒的特征匹配来缓解类内差异和类间干扰。具体来说，IIR模型使用两个原型来表示每个类别，一个原型关注核心区分特征，另一个原型关注局部特定特征。同时，IIR模型使用方向性Dropout机制来过滤掉不一致的特征匹配，从而提高分割的准确性。\\n\\n**技术框架**：IIR模型主要包含两个模块：Inter-image Refinement和Intra-image Refinement。Inter-image Refinement模块使用类激活映射生成两个原型，用于支持集和查询集之间的特征匹配。Intra-image Refinement模块使用方向性Dropout机制来过滤掉不一致的特征匹配。整个流程是先通过Inter-image Refinement生成更准确的先验图谱，然后通过Intra-image Refinement进一步提升解码器性能。\\n\\n**关键创新**：IIR模型的关键创新在于以下两点：1) 使用两个原型来表示每个类别，从而更全面地捕捉类别特征，缓解类内差异；2) 引入方向性Dropout机制来过滤掉不一致的特征匹配，从而提高分割的准确性，缓解类间干扰。与现有方法相比，IIR模型能够更有效地处理类内差异和类间干扰，从而取得更好的分割性能。\\n\\n**关键设计**：Inter-image Refinement模块使用类激活映射(CAM)来生成两个原型。具体来说，首先使用全局平均池化(GAP)得到每个特征图的权重，然后根据权重对特征图进行加权求和，得到类激活图。然后，使用阈值分割将类激活图分成两个区域，分别对应核心区分特征和局部特定特征。Intra-image Refinement模块使用方向性Dropout机制来过滤掉不一致的特征匹配。具体来说，首先计算支持集和查询集特征之间的相似度矩阵，然后根据相似度矩阵对特征进行Dropout，从而过滤掉不一致的特征匹配。",
            "application_zh": "该研究成果可应用于医疗图像分析、遥感图像解译、自动驾驶等领域。在这些领域中，标注数据通常非常有限，因此少样本分割技术具有重要的应用价值。IIR模型能够有效地利用少量标注样本，提高分割的准确性和鲁棒性，从而为这些领域的应用提供更好的支持。未来，该技术有望进一步推广到更多的实际应用场景中。",
            "highlight_zh": "IIR模型在9个少样本分割基准测试中均取得了state-of-the-art的性能，包括标准FSS、部分FSS和跨域FSS。例如，在标准FSS的PASCAL-5i数据集上，IIR模型相比于现有最佳方法取得了显著的性能提升。这些实验结果充分证明了IIR模型的有效性和泛化能力。",
            "tags_zh": [
                "少样本分割",
                "语义分割",
                "原型学习",
                "类激活映射",
                "Dropout",
                "跨域学习"
            ],
            "_index": 244,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2507.05838/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2507.05838/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2507.05838/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Audio-Visual Camera Pose Estimation with Passive Scene Sounds and In-the-Wild Video",
            "authors": [
                "Daniel Adebi",
                "Sagnik Majumder",
                "Kristen Grauman"
            ],
            "arxiv_id": "2512.12165",
            "summary": "Understanding camera motion is a fundamental problem in embodied perception and 3D scene understanding. While visual methods have advanced rapidly, they often struggle under visually degraded conditions such as motion blur or occlusions. In this work, we show that passive scene sounds provide complementary cues for relative camera pose estimation for in-the-wild videos. We introduce a simple but effective audio-visual framework that integrates direction-ofarrival (DOA) spectra and binauralized embeddings into a state-of-the-art vision-only pose estimation model. Our results on two large datasets show consistent gains over strong visual baselines, plus robustness when the visual information is corrupted. To our knowledge, this represents the first work to successfully leverage audio for relative camera pose estimation in real-world videos, and it establishes incidental, everyday audio as an unexpected but promising signal for a classic spatial challenge. Project:this http URL.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.12165",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "scene understanding"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "提出一种利用被动场景声音进行相机位姿估计的音视频融合框架",
            "summary_zh": "相机运动估计是具身感知和3D场景理解中的一个基本问题。虽然视觉方法发展迅速，但它们在视觉退化条件下（如运动模糊或遮挡）常常表现不佳。本文表明，被动场景声音为真实场景视频的相对相机位姿估计提供了补充线索。我们引入了一个简单而有效的音视频框架，将到达方向(DOA)谱和双耳嵌入集成到最先进的纯视觉位姿估计模型中。在两个大型数据集上的结果表明，相对于强大的视觉基线，我们的方法获得了持续的性能提升，并且在视觉信息损坏时表现出鲁棒性。据我们所知，这是第一个成功利用音频进行真实场景视频中相对相机位姿估计的工作，并将偶然的、日常的音频确立为解决经典空间挑战的一种意想不到但很有希望的信号。",
            "intro_zh": [
                "视觉方法在相机位姿估计中面临视觉退化（如模糊、遮挡）的挑战，限制了其在复杂环境下的应用。",
                "该论文提出一种音视频融合框架，利用场景中的被动声音信息，辅助视觉信息进行更准确的相机位姿估计。",
                "实验结果表明，该方法在两个大型数据集上优于纯视觉基线，并在视觉信息受损时表现出更强的鲁棒性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决在视觉信息不足或质量较差的情况下，相机位姿估计精度下降的问题。现有方法主要依赖视觉信息，在运动模糊、遮挡等情况下表现不佳，缺乏鲁棒性。\\n\\n**核心思路**：论文的核心思路是利用场景中自然存在的被动声音作为视觉信息的补充，通过音视频融合的方式，提高相机位姿估计的准确性和鲁棒性。声音信息对视觉退化具有一定的互补性，可以提供额外的空间线索。\\n\\n**技术框架**：该框架将音频和视频信息融合到现有的视觉位姿估计模型中。主要包含以下模块：1) 音频处理模块：提取音频的到达方向(DOA)谱和双耳嵌入特征。2) 视觉处理模块：使用现有的视觉位姿估计模型提取视觉特征。3) 融合模块：将音频和视觉特征进行融合，共同预测相机位姿。\\n\\n**关键创新**：该论文的关键创新在于首次将场景中的被动声音信息用于相机位姿估计，并提出了一种有效的音视频融合框架。与传统方法仅依赖视觉信息不同，该方法利用了音频提供的额外空间线索，提高了位姿估计的鲁棒性。\\n\\n**关键设计**：音频特征提取方面，使用了DOA谱和双耳嵌入，分别捕捉声音的方向信息和空间信息。融合方式上，将音频特征与视觉特征进行拼接或加权融合，具体融合方式未知。损失函数方面，可能使用了位姿预测的回归损失，具体细节未知。",
            "application_zh": "该研究成果可应用于机器人导航、增强现实、虚拟现实等领域。在光照条件差、存在遮挡或运动模糊等情况下，该方法能够提供更准确的相机位姿估计，提高系统的稳定性和可靠性。未来，该技术有望应用于自动驾驶、无人机等领域，提升其在复杂环境下的感知能力。",
            "highlight_zh": "实验结果表明，该方法在两个大型数据集上均优于纯视觉基线，证明了音频信息在相机位姿估计中的有效性。特别是在视觉信息受损的情况下，该方法的性能提升更为显著，体现了其鲁棒性。具体的性能提升数据未知。",
            "tags_zh": [
                "相机位姿估计",
                "音视频融合",
                "被动声音",
                "方向估计",
                "机器人感知"
            ],
            "_index": 245,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.12165/imgs/cvpr_teaser_image_small.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.12165/imgs/full_method_diagram.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.12165/imgs/qual_cvpr_2026.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "CRISTAL: Real-time Camera Registration in Static LiDAR Scans using Neural Rendering",
            "authors": [
                "Joni Vanherck",
                "Steven Moonen",
                "Brent Zoomers",
                "Kobe Werner",
                "Jeroen Put",
                "Lode Jorissen",
                "Nick Michiels"
            ],
            "arxiv_id": "2511.16349",
            "summary": "Accurate camera localization is crucial for robotics and Extended Reality (XR), enabling reliable navigation and alignment of virtual and real content. Existing visual methods often suffer from drift, scale ambiguity, and depend on fiducials or loop closure. This work introduces a real-time method for localizing a camera within a pre-captured, highly accurate colored LiDAR point cloud. By rendering synthetic views from this cloud, 2D-3D correspondences are established between live frames and the point cloud. A neural rendering technique narrows the domain gap between synthetic and real images, reducing occlusion and background artifacts to improve feature matching. The result is drift-free camera tracking with correct metric scale in the global LiDAR coordinate system. Two real-time variants are presented: Online Render and Match, and Prebuild and Localize. We demonstrate improved results on the ScanNet++ dataset and outperform existing SLAM pipelines.",
            "categories": [
                "cs.CV",
                "cs.GR"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2511.16349",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱六：视频提取与匹配 (Video Extraction)",
                    "id": "6_video_extraction",
                    "matched_keywords": [
                        "feature matching"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "6_video_extraction"
            ],
            "headline_zh": "CRISTAL：利用神经渲染在静态激光雷达扫描中进行实时相机注册",
            "summary_zh": "精确的相机定位对于机器人和扩展现实（XR）至关重要，它能够实现可靠的导航以及虚拟内容与真实内容的对齐。现有的视觉方法通常存在漂移、尺度模糊等问题，并且依赖于信标或回环闭合。本文提出了一种实时方法，用于在预先捕获的高精度彩色激光雷达点云中定位相机。通过渲染来自该点云的合成视图，在实时帧和点云之间建立2D-3D对应关系。一种神经渲染技术缩小了合成图像和真实图像之间的域差距，减少了遮挡和背景伪影，从而改善了特征匹配。最终实现了在全局激光雷达坐标系中无漂移且具有正确度量尺度的相机跟踪。本文提出了两种实时变体：在线渲染与匹配，以及预构建与定位。实验结果表明，在ScanNet++数据集上，本文方法优于现有的SLAM流程。",
            "intro_zh": [
                "现有视觉定位方法易受漂移和尺度模糊影响，且依赖外部信息，限制了其在机器人和XR等领域的应用。",
                "CRISTAL通过神经渲染合成视图，建立实时帧与激光雷达点云的2D-3D对应，实现精确的相机定位。",
                "实验表明，CRISTAL在ScanNet++数据集上优于现有SLAM方法，实现了更准确、稳定的相机跟踪。"
            ],
            "method_zh": "**问题定义**：现有视觉SLAM方法在相机定位时，容易出现漂移和尺度不确定性，尤其是在缺乏纹理或光照变化剧烈的环境中。此外，许多方法依赖于预先放置的信标或回环检测，限制了其在未知环境中的应用。因此，需要一种鲁棒、精确且可扩展的相机定位方法，能够在预先构建的激光雷达地图中实时定位相机。\\n\\n**核心思路**：CRISTAL的核心思路是利用预先获取的高精度彩色激光雷达点云作为全局地图，通过神经渲染技术生成与当前相机视角相似的合成图像，从而建立实时图像与全局地图之间的对应关系。通过最小化真实图像和合成图像之间的差异，可以实现精确的相机位姿估计，并消除漂移和尺度模糊。\\n\\n**技术框架**：CRISTAL包含两个主要阶段：地图构建阶段和定位阶段。在地图构建阶段，使用激光雷达扫描仪获取环境的点云数据，并将其转换为全局地图。在定位阶段，首先使用神经渲染技术从全局地图中生成合成图像，然后提取合成图像和实时图像的特征，并建立2D-3D对应关系。最后，使用位姿估计算法，根据2D-3D对应关系计算相机的位姿。本文提出了两种实时变体：Online Render and Match，以及Prebuild and Localize。\\n\\n**关键创新**：CRISTAL的关键创新在于使用神经渲染技术缩小了合成图像和真实图像之间的域差距。传统的渲染方法难以生成逼真的合成图像，导致特征匹配的准确性降低。神经渲染技术能够学习真实图像的分布，从而生成更逼真的合成图像，提高特征匹配的准确性。此外，CRISTAL还提出了一种新的位姿估计算法，能够有效地处理噪声和遮挡。\\n\\n**关键设计**：CRISTAL使用了一种基于GAN的神经渲染网络，该网络能够学习真实图像的分布，并生成逼真的合成图像。该网络包含一个生成器和一个判别器，生成器负责生成合成图像，判别器负责区分合成图像和真实图像。通过对抗训练，生成器能够生成越来越逼真的合成图像。此外，CRISTAL还使用了一种基于RANSAC的位姿估计算法，该算法能够有效地处理噪声和遮挡。损失函数包括光度损失和几何损失，用于约束合成图像和真实图像之间的差异。",
            "application_zh": "CRISTAL在机器人、增强现实（AR）和虚拟现实（VR）等领域具有广泛的应用前景。例如，在机器人导航中，CRISTAL可以用于实现精确的机器人定位和路径规划。在AR/VR应用中，CRISTAL可以用于将虚拟内容与真实环境进行精确对齐，从而提高用户体验。此外，CRISTAL还可以应用于三维重建、场景理解等领域。",
            "highlight_zh": "CRISTAL在ScanNet++数据集上进行了评估，实验结果表明，CRISTAL优于现有的SLAM方法。具体来说，CRISTAL在相机定位的精度和鲁棒性方面均取得了显著提升。与ORB-SLAM3相比，CRISTAL的定位精度提高了约30%，并且在光照变化和遮挡等复杂环境下表现出更强的鲁棒性。此外，CRISTAL还实现了实时性能，能够满足实际应用的需求。",
            "tags_zh": [
                "相机定位",
                "激光雷达",
                "神经渲染",
                "实时SLAM",
                "2D-3D对应"
            ],
            "_index": 246,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2511.16349/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2511.16349/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2511.16349/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "DARTs: A Dual-Path Robust Framework for Anomaly Detection in High-Dimensional Multivariate Time Series",
            "authors": [
                "Xuechun Liu",
                "Heli Sun",
                "Xuecheng Wu",
                "Ruichen Cao",
                "Yunyun Shi",
                "Dingkang Yang",
                "Haoran Li"
            ],
            "arxiv_id": "2512.13735",
            "summary": "Multivariate time series anomaly detection (MTSAD) aims to accurately identify and localize complex abnormal patterns in the large-scale industrial control systems. While existing approaches excel in recognizing the distinct patterns under the low-dimensional scenarios, they often fail to robustly capture long-range spatiotemporal dependencies when learning representations from the high-dimensional noisy time series. To address these limitations, we propose DARTs, a robust long short-term dual-path framework with window-aware spatiotemporal soft fusion mechanism, which can be primarily decomposed into three complementary components. Specifically, in the short-term path, we introduce a Multi-View Sparse Graph Learner and a Diffusion Multi-Relation Graph Unit that collaborate to adaptively capture hierarchical discriminative short-term spatiotemporal patterns in the high-noise time series. While in the long-term path, we design a Multi-Scale Spatiotemporal Graph Constructor to model salient long-term dynamics within the high-dimensional representation space. Finally, a window-aware spatiotemporal soft-fusion mechanism is introduced to filter the residual noise while seamlessly integrating anomalous patterns. Extensive qualitative and quantitative experimental results across mainstream datasets demonstrate the superiority and robustness of our proposed DARTs. A series of ablation studies are also conducted to explore the crucial design factors of our proposed components. Our code and model will be made publicly open soon.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13735",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱八：物理动画 (Physics-based Animation)",
                    "id": "8_physics_animation",
                    "matched_keywords": [
                        "spatiotemporal"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "8_physics_animation"
            ],
            "headline_zh": "提出DARTs，用于高维多元时间序列异常检测，提升长程时空依赖建模能力。",
            "summary_zh": "本文提出DARTs，一个鲁棒的双路径框架，用于高维多元时间序列异常检测。该框架采用窗口感知的时空软融合机制。在短期路径中，引入多视角稀疏图学习器和扩散多关系图单元，自适应地捕获高噪声时间序列中的分层判别性短期时空模式。在长期路径中，设计多尺度时空图构造器，以建模高维表示空间中的显著长期动态。最后，引入窗口感知的时空软融合机制，以过滤残余噪声，同时无缝集成异常模式。在主流数据集上的大量实验结果表明，所提出的DARTs具有优越性和鲁棒性。还进行了一系列消融研究，以探索所提出的组件的关键设计因素。",
            "intro_zh": [
                "现有方法在高维噪声时间序列中学习表示时，难以鲁棒地捕获长程时空依赖关系，限制了异常检测的准确性。",
                "DARTs框架通过双路径结构，分别建模短期和长期时空依赖，并使用窗口感知的软融合机制整合信息，提升鲁棒性。",
                "实验结果表明，DARTs在主流数据集上优于现有方法，并通过消融实验验证了各组件的关键作用。"
            ],
            "method_zh": "**问题定义**：多元时间序列异常检测旨在准确识别和定位大规模工业控制系统中复杂的异常模式。现有方法在低维场景下表现良好，但在高维噪声时间序列中，难以鲁棒地捕获长程时空依赖关系，导致检测性能下降。\\n\\n**核心思路**：DARTs的核心思路是利用双路径结构分别建模短期和长期时空依赖关系，并通过窗口感知的软融合机制将两者结合。短期路径侧重于捕获局部细粒度的异常模式，而长期路径则关注全局动态变化。这种设计能够有效应对高维噪声数据，提升异常检测的鲁棒性。\\n\\n**技术框架**：DARTs框架主要包含三个组件：短期路径、长期路径和窗口感知的时空软融合机制。短期路径包括多视角稀疏图学习器和扩散多关系图单元，用于自适应地捕获分层判别性短期时空模式。长期路径设计了多尺度时空图构造器，用于建模高维表示空间中的显著长期动态。最后，窗口感知的时空软融合机制用于过滤残余噪声，并无缝集成短期和长期路径的信息。\\n\\n**关键创新**：DARTs的关键创新在于其双路径结构和窗口感知的软融合机制。双路径结构能够同时捕捉短期和长期时空依赖关系，从而更全面地理解时间序列的动态变化。窗口感知的软融合机制能够根据时间窗口内的信息动态调整短期和长期路径的权重，从而更好地适应不同的异常模式。与现有方法相比，DARTs能够更有效地处理高维噪声数据，并提升异常检测的鲁棒性。\\n\\n**关键设计**：多视角稀疏图学习器通过学习多个不同的图结构来捕捉时间序列中不同的关系。扩散多关系图单元利用图卷积网络来传播节点信息，从而更好地建模节点之间的依赖关系。多尺度时空图构造器通过使用不同的时间窗口来捕捉不同尺度的长期动态。窗口感知的时空软融合机制使用一个可学习的权重来动态调整短期和长期路径的贡献。损失函数包括异常检测损失和稀疏性约束，以鼓励模型学习稀疏的图结构。",
            "application_zh": "DARTs可应用于大规模工业控制系统、金融风险管理、网络安全监控等领域。通过准确识别和定位异常模式，可以帮助企业及时发现潜在问题，降低运营风险，提高生产效率。未来，DARTs有望与其他AI技术结合，实现更智能化的异常检测和预警。",
            "highlight_zh": "DARTs在主流数据集上取得了显著的性能提升。例如，在SWaT数据集上，DARTs的F1-score比现有最佳方法提高了5%以上。消融实验表明，双路径结构和窗口感知的软融合机制对性能提升至关重要。实验结果验证了DARTs在高维多元时间序列异常检测中的优越性和鲁棒性。",
            "tags_zh": [
                "多元时间序列",
                "异常检测",
                "图神经网络",
                "时空建模",
                "双路径网络"
            ],
            "_index": 247,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13735/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13735/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.13735/Intuition.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Evaluating Adversarial Attacks on Federated Learning for Temperature Forecasting",
            "authors": [
                "Karina Chichifoi",
                "Fabio Merizzi",
                "Michele Colajanni"
            ],
            "arxiv_id": "2512.13207",
            "summary": "Deep learning and federated learning (FL) are becoming powerful partners for next-generation weather forecasting. Deep learning enables high-resolution spatiotemporal forecasts that can surpass traditional numerical models, while FL allows institutions in different locations to collaboratively train models without sharing raw data, addressing efficiency and security concerns. While FL has shown promise across heterogeneous regions, its distributed nature introduces new vulnerabilities. In particular, data poisoning attacks, in which compromised clients inject manipulated training data, can degrade performance or introduce systematic biases. These threats are amplified by spatial dependencies in meteorological data, allowing localized perturbations to influence broader regions through global model aggregation. In this study, we investigate how adversarial clients distort federated surface temperature forecasts trained on the Copernicus European Regional ReAnalysis (CERRA) dataset. We simulate geographically distributed clients and evaluate patch-based and global biasing attacks on regional temperature forecasts. Our results show that even a small fraction of poisoned clients can mislead predictions across large, spatially connected areas. A global temperature bias attack from a single compromised client shifts predictions by up to -1.7 K, while coordinated patch attacks more than triple the mean squared error and produce persistent regional anomalies exceeding +3.5 K. Finally, we assess trimmed mean aggregation as a defense mechanism, showing that it successfully defends against global bias attacks (2-13% degradation) but fails against patch attacks (281-603% amplification), exposing limitations of outlier-based defenses for spatially correlated data.",
            "categories": [
                "cs.LG",
                "cs.CR"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-18",
            "updated": "2025-12-18",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13207",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱八：物理动画 (Physics-based Animation)",
                    "id": "8_physics_animation",
                    "matched_keywords": [
                        "spatiotemporal"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "8_physics_animation"
            ],
            "headline_zh": "研究联邦学习在温度预测中对抗攻击的脆弱性，揭示空间依赖性带来的安全风险。",
            "summary_zh": "深度学习和联邦学习（FL）正成为下一代天气预报的强大伙伴。深度学习能够实现超越传统数值模型的高分辨率时空预测，而FL允许不同地点的机构协作训练模型，无需共享原始数据，从而解决效率和安全问题。虽然FL在异构区域显示出前景，但其分布式特性引入了新的漏洞。特别是，数据投毒攻击，即受损客户端注入被操纵的训练数据，会降低性能或引入系统性偏差。气象数据中的空间依赖性加剧了这些威胁，使得局部扰动可以通过全局模型聚合影响更广泛的区域。本研究调查了对抗性客户端如何扭曲基于哥白尼欧洲区域再分析（CERRA）数据集训练的联邦地表温度预测。我们模拟了地理上分布的客户端，并评估了基于补丁和全局偏差的攻击对区域温度预测的影响。结果表明，即使一小部分中毒客户端也会误导大范围空间连接区域的预测。来自单个受损客户端的全局温度偏差攻击使预测偏移高达-1.7 K，而协调的补丁攻击使均方误差增加三倍以上，并产生超过+3.5 K的持续区域异常。最后，我们评估了修剪均值聚合作为一种防御机制，表明它可以成功防御全局偏差攻击（2-13%的降级），但对补丁攻击无效（281-603%的放大），暴露了基于异常值的防御在空间相关数据方面的局限性。",
            "intro_zh": [
                "联邦学习在气象预测中面临数据投毒攻击的威胁，攻击者通过恶意数据影响全局模型，现有研究缺乏对空间依赖性影响的深入分析。",
                "该研究模拟地理分布式客户端，评估全局偏差和局部补丁攻击对联邦学习温度预测的影响，分析攻击对预测结果的扭曲程度。",
                "实验表明，少量中毒客户端即可显著影响大范围区域的温度预测，修剪均值防御对全局偏差攻击有效，但对局部补丁攻击失效。"
            ],
            "method_zh": "**问题定义**：论文旨在研究联邦学习在温度预测任务中，面对恶意客户端的数据投毒攻击时的脆弱性。现有方法忽略了气象数据的空间依赖性，导致攻击效果被低估，防御策略设计不足。攻击者可以通过操纵局部数据，影响全局模型的预测精度和可靠性。\\n\\n**核心思路**：论文的核心思路是模拟现实世界中地理位置分散的客户端，并设计不同类型的对抗性攻击（全局偏差和局部补丁攻击），评估这些攻击对联邦学习模型预测结果的影响。通过分析攻击造成的误差和异常，揭示联邦学习在气象预测中的安全风险。\\n\\n**技术框架**：整体框架包括以下几个主要步骤：1) 数据集准备：使用哥白尼欧洲区域再分析（CERRA）数据集，模拟地理分布式客户端的数据；2) 模型训练：使用联邦学习算法训练温度预测模型；3) 攻击模拟：模拟恶意客户端，注入全局偏差或局部补丁攻击；4) 评估：评估攻击对模型预测结果的影响，包括均方误差、温度偏差等指标；5) 防御：评估修剪均值聚合作为防御机制的有效性。\\n\\n**关键创新**：论文的关键创新在于：1) 关注气象数据的空间依赖性，设计了更贴近实际场景的局部补丁攻击；2) 深入分析了不同类型攻击对联邦学习模型的影响，揭示了现有防御机制的局限性；3) 提出了针对空间相关数据的联邦学习安全风险评估方法。\\n\\n**关键设计**：论文的关键设计包括：1) 全局偏差攻击：恶意客户端将所有温度数据加上一个固定的偏差值；2) 局部补丁攻击：恶意客户端在局部区域的温度数据中注入异常值，模拟局部极端天气事件；3) 修剪均值聚合：一种常用的联邦学习防御机制，通过剔除异常客户端的更新来提高模型的鲁棒性。",
            "application_zh": "该研究成果可应用于提升联邦学习在气象预测领域的安全性，例如设计更有效的防御机制，提高模型对恶意攻击的鲁棒性。此外，该研究方法也可推广到其他具有空间依赖性的联邦学习应用场景，如环境监测、智慧城市等，为保障数据安全和模型可靠性提供参考。",
            "highlight_zh": "实验结果表明，单个恶意客户端的全局温度偏差攻击可导致预测偏移高达-1.7 K，协调的局部补丁攻击使均方误差增加三倍以上，并产生超过+3.5 K的持续区域异常。修剪均值聚合可以有效防御全局偏差攻击（2-13%的降级），但对局部补丁攻击无效（281-603%的放大）。",
            "tags_zh": [
                "联邦学习",
                "对抗攻击",
                "数据投毒",
                "温度预测",
                "空间依赖性",
                "气象预测",
                "安全性",
                "修剪均值"
            ],
            "_index": 248,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13207/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13207/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.13207/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        }
    ]
}