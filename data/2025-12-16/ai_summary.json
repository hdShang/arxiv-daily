{
    "papers": [
        {
            "title": "Sample-Efficient Robot Skill Learning for Construction Tasks: Benchmarking Hierarchical Reinforcement Learning and Vision-Language-Action VLA Model",
            "authors": [
                "Zhaofeng Hu",
                "Hongrui Yu",
                "Vaidhyanathan Chandramouli",
                "Ci-Jyun Liang"
            ],
            "arxiv_id": "2512.14031v1",
            "summary": "This study evaluates two leading approaches for teaching construction robots new skills to understand their applicability for construction automation: a Vision-Language-Action (VLA) model and Reinforcement Learning (RL) methods. The goal is to understand both task performance and the practical effort needed to deploy each approach on real jobs. The authors developed two teleoperation interfaces to control the robots and collect the demonstrations needed, both of which proved effective for training robots for long-horizon and dexterous tasks. In addition, the authors conduct a three-stage evaluation. First, the authors compare a Multi-Layer Perceptron (MLP) policy with a Deep Q-network (DQN) imitation model to identify the stronger RL baseline, focusing on model performance, generalization, and a pick-up experiment. Second, three different VLA models are trained in two different scenarios and compared with each other. Third, the authors benchmark the selected RL baseline against the VLA model using computational and sample-efficiency measures and then a robot experiment on a multi-stage panel installation task that includes transport and installation. The VLA model demonstrates strong generalization and few-shot capability, achieving 60% and 100% success in the pickup phase. In comparison, DQN can be made robust but needs additional noise during tuning, which increases the workload. Overall, the findings indicate that VLA offers practical advantages for changing tasks by reducing programming effort and enabling useful performance with minimal data, while DQN provides a viable baseline when sufficient tuning effort is acceptable.",
            "categories": [
                "cs.RO",
                "cs.AI"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14031v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "teleoperation"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning"
                    ],
                    "score": 4.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]vision-language-action",
                        "[T]VLA"
                    ],
                    "score": 18.0
                }
            ],
            "relevance_score": 24.5,
            "hit_pillars": [
                "1_robot_core",
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "对比VLA模型与强化学习，提升建筑机器人操作技能并实现高效样本利用",
            "summary_zh": "本研究评估了两种领先的方法，即视觉-语言-动作（VLA）模型和强化学习（RL）方法，用于训练建筑机器人掌握新技能，旨在了解它们在建筑自动化中的适用性。作者开发了两种遥操作界面来控制机器人并收集所需的演示数据，这两种界面都被证明对训练机器人执行长时程和灵巧任务有效。此外，作者进行了三阶段评估。首先，比较了多层感知机（MLP）策略与深度Q网络（DQN）模仿模型，以确定更强的RL基线，重点关注模型性能、泛化能力和拾取实验。其次，在两种不同的场景中训练了三种不同的VLA模型，并将它们相互比较。第三，作者使用计算和样本效率指标，以及一个包含运输和安装的多阶段面板安装机器人实验，将选定的RL基线与VLA模型进行基准测试。VLA模型表现出强大的泛化能力和少样本能力，在拾取阶段实现了60%和100%的成功率。相比之下，DQN可以通过在调整过程中添加额外的噪声来使其更加鲁棒，但这增加了工作量。总的来说，研究结果表明，VLA通过减少编程工作量和以最少的数据实现有用的性能，为更改任务提供了实际优势，而DQN在可接受足够的调整工作量时，提供了一个可行的基线。",
            "intro_zh": [
                "现有建筑机器人技能学习方法在泛化性和样本效率方面存在不足，难以适应快速变化的任务需求。",
                "论文对比研究了视觉-语言-动作（VLA）模型和强化学习（RL）方法，探索更高效的机器人技能学习方案。",
                "实验表明，VLA模型在泛化性和少样本学习方面优于DQN，更适合快速部署到新的建筑任务中。"
            ],
            "method_zh": "**问题定义**：论文旨在解决建筑机器人技能学习中泛化能力弱和样本效率低的问题。现有方法，如传统的强化学习，通常需要大量的训练数据和精细的调参才能在特定任务上取得较好的效果，难以适应建筑场景中任务的多样性和变化性。因此，如何利用少量样本快速学习并泛化到新的任务是本研究要解决的核心问题。\\n\\n**核心思路**：论文的核心思路是对比研究两种不同的机器人技能学习范式：基于视觉-语言-动作（VLA）模型的模仿学习和基于强化学习（RL）的方法。VLA模型通过学习视觉输入、语言指令和动作之间的映射关系，实现对任务的理解和执行。RL方法则通过与环境的交互，学习最优的策略。通过对比这两种方法，旨在找到一种更适合建筑机器人技能学习的方法，即在保证性能的同时，具有更好的泛化能力和样本效率。\\n\\n**技术框架**：论文的整体框架包括数据收集、模型训练和实验评估三个阶段。首先，通过遥操作界面收集机器人的演示数据，包括视觉输入、语言指令和动作。然后，分别训练VLA模型和RL模型。VLA模型采用Transformer架构，学习视觉和语言特征到动作的映射。RL模型采用DQN算法，通过与环境的交互学习最优策略。最后，通过一系列实验评估模型的性能，包括泛化能力、样本效率和实际机器人任务的执行效果。\\n\\n**关键创新**：论文的关键创新在于对比研究了VLA模型和RL模型在建筑机器人技能学习中的表现，并揭示了VLA模型在泛化能力和样本效率方面的优势。与传统的RL方法相比，VLA模型能够更好地利用先验知识，通过学习视觉和语言信息，实现对任务的理解和执行，从而减少了对大量训练数据的依赖。\\n\\n**关键设计**：在VLA模型中，采用了Transformer架构来学习视觉和语言特征之间的关系。视觉特征通过卷积神经网络提取，语言特征通过词嵌入技术表示。模型的目标是预测给定视觉和语言输入下的动作。在RL模型中，采用了DQN算法，使用深度神经网络来近似Q函数。为了提高DQN的鲁棒性，在训练过程中添加了噪声。此外，论文还设计了两种遥操作界面，用于收集机器人的演示数据。",
            "application_zh": "该研究成果可应用于建筑自动化领域，例如自动化砖块砌筑、面板安装、钢筋捆扎等任务。通过VLA模型，机器人可以理解人类的指令，并根据视觉信息自主完成任务，从而提高建筑效率和安全性。此外，该研究也为其他领域的机器人技能学习提供了借鉴，例如工业自动化、医疗机器人等。",
            "highlight_zh": "实验结果表明，VLA模型在拾取阶段的成功率达到60%和100%，表现出强大的泛化能力和少样本学习能力。相比之下，DQN虽然可以通过添加噪声来提高鲁棒性，但需要更多的调参工作。在多阶段面板安装任务中，VLA模型也表现出优于DQN的性能，证明了其在实际建筑任务中的应用潜力。",
            "tags_zh": [
                "机器人技能学习",
                "视觉语言动作模型",
                "强化学习",
                "建筑自动化",
                "模仿学习"
            ],
            "_index": 0,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "EVOLVE-VLA: Test-Time Training from Environment Feedback for Vision-Language-Action Models",
            "authors": [
                "Zechen Bai",
                "Chen Gao",
                "Mike Zheng Shou"
            ],
            "arxiv_id": "2512.14666v1",
            "summary": "Achieving truly adaptive embodied intelligence requires agents that learn not just by imitating static demonstrations, but by continuously improving through environmental interaction, which is akin to how humans master skills through practice. Vision-Language-Action (VLA) models have advanced robotic manipulation by leveraging large language models, yet remain fundamentally limited by Supervised Finetuning (SFT): requiring hundreds of demonstrations per task, rigidly memorizing trajectories, and failing to adapt when deployment conditions deviate from training. We introduce EVOLVE-VLA, a test-time training framework enabling VLAs to continuously adapt through environment interaction with minimal or zero task-specific demonstrations. The key technical challenge is replacing oracle reward signals (unavailable at test time) with autonomous feedback. We address this through a learned progress estimator providing dense feedback, and critically, we design our framework to ``tame'' this inherently noisy signal via two mechanisms: (1) an accumulative progress estimation mechanism smoothing noisy point-wise estimates, and (2) a progressive horizon extension strategy enabling gradual policy evolution. EVOLVE-VLA achieves substantial gains: +8.6\\% on long-horizon tasks, +22.0\\% in 1-shot learning, and enables cross-task generalization -- achieving 20.8\\% success on unseen tasks without task-specific demonstrations training (vs. 0\\% for pure SFT). Qualitative analysis reveals emergent capabilities absent in demonstrations, including error recovery and novel strategies. This work represents a critical step toward VLAs that truly learn and adapt, moving beyond static imitation toward continuous self-improvements.",
            "categories": [
                "cs.RO",
                "cs.CV"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "15 pages",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14666v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]vision-language-action",
                        "[T]VLA",
                        "large language model"
                    ],
                    "score": 21.0
                }
            ],
            "relevance_score": 23.0,
            "hit_pillars": [
                "1_robot_core",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出EVOLVE-VLA以解决视觉-语言-动作模型适应性不足问题",
            "summary_zh": "实现真正自适应的具身智能需要代理不仅通过模仿静态示范学习，还需通过与环境的持续互动不断改进。视觉-语言-动作（VLA）模型在机器人操作中取得了进展，但仍受限于监督微调（SFT），需要大量示范，且在部署条件变化时无法适应。本文提出EVOLVE-VLA，一个测试时训练框架，使VLA能够通过环境互动持续适应，且仅需最少或零任务特定示范。关键技术挑战在于用自主反馈替代不可用的奖励信号。我们通过学习的进度估计器提供密集反馈，并设计了两个机制来“驯化”这一噪声信号：累积进度估计机制和平滑噪声的渐进视野扩展策略。EVOLVE-VLA在长时间任务上提升8.6%，在单次学习中提升22.0%，并实现跨任务泛化，未见任务成功率达到20.8%。",
            "intro_zh": [
                "现有的视觉-语言-动作模型依赖于大量示范进行监督微调，导致适应性不足，无法应对环境变化。",
                "本文提出EVOLVE-VLA框架，通过环境反馈实现测试时训练，减少对任务特定示范的依赖，增强模型的自适应能力。",
                "实验结果显示，EVOLVE-VLA在长时间任务上提升8.6%，单次学习提升22.0%，并在未见任务上实现20.8%的成功率，显著优于传统方法。"
            ],
            "method_zh": "**问题定义**：本文旨在解决视觉-语言-动作模型在环境变化时的适应性不足问题。现有方法依赖大量示范进行监督微调，导致模型在实际应用中无法灵活应对新情况。\\n\\n**核心思路**：提出EVOLVE-VLA框架，通过环境反馈进行测试时训练，利用学习的进度估计器提供密集反馈，减少对任务特定示范的依赖，从而实现持续自我改进。\\n\\n**技术框架**：EVOLVE-VLA框架主要包括两个模块：累积进度估计机制和渐进视野扩展策略。前者用于平滑噪声反馈，后者则允许模型逐步演化策略。\\n\\n**关键创新**：最重要的创新在于用自主反馈替代传统的奖励信号，设计了累积进度估计和渐进视野扩展机制，使得模型能够在测试阶段持续学习和适应。\\n\\n**关键设计**：在模型设计中，采用了特定的损失函数来优化进度估计器，并通过参数调节来平衡反馈的噪声与学习效率。",
            "application_zh": "该研究的潜在应用领域包括智能机器人、自动驾驶、以及人机交互等场景。通过增强模型的自适应能力，EVOLVE-VLA能够在动态环境中更好地执行复杂任务，提升实际应用的灵活性和效率。未来，该框架可能推动更广泛的自适应智能系统的发展。",
            "highlight_zh": "实验结果表明，EVOLVE-VLA在长时间任务上提升了8.6%，在单次学习中提升了22.0%。此外，该框架在未见任务上实现了20.8%的成功率，显著优于传统的监督微调方法（0%成功率）。",
            "tags_zh": [
                "视觉-语言-动作",
                "自适应学习",
                "环境反馈",
                "机器人操作",
                "测试时训练",
                "进度估计",
                "跨任务泛化"
            ],
            "_index": 1,
            "_used_api": "openai",
            "figures": []
        },
        {
            "title": "CHIP: Adaptive Compliance for Humanoid Control through Hindsight Perturbation",
            "authors": [
                "Sirui Chen",
                "Zi-ang Cao",
                "Zhengyi Luo",
                "Fernando Castañeda",
                "Chenran Li",
                "Tingwu Wang",
                "Ye Yuan",
                "Linxi \"Jim\" Fan",
                "C. Karen Liu",
                "Yuke Zhu"
            ],
            "arxiv_id": "2512.14689v1",
            "summary": "Recent progress in humanoid robots has unlocked agile locomotion skills, including backflipping, running, and crawling. Yet it remains challenging for a humanoid robot to perform forceful manipulation tasks such as moving objects, wiping, and pushing a cart. We propose adaptive Compliance Humanoid control through hIsight Perturbation (CHIP), a plug-and-play module that enables controllable end-effector stiffness while preserving agile tracking of dynamic reference motions. CHIP is easy to implement and requires neither data augmentation nor additional reward tuning. We show that a generalist motion-tracking controller trained with CHIP can perform a diverse set of forceful manipulation tasks that require different end-effector compliance, such as multi-robot collaboration, wiping, box delivery, and door opening.",
            "categories": [
                "cs.RO",
                "cs.LG"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "The first two authors contributed equally. Project page: https://nvlabs.github.io/CHIP/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14689v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "[T]humanoid",
                        "humanoid robot",
                        "[T]humanoid control",
                        "locomotion",
                        "manipulation"
                    ],
                    "score": 18.0
                },
                {
                    "name": "支柱八：物理动画 (Physics-based Animation)",
                    "id": "8_physics_animation",
                    "matched_keywords": [
                        "motion tracking"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 20.0,
            "hit_pillars": [
                "1_robot_core",
                "8_physics_animation"
            ],
            "headline_zh": "CHIP：通过后见之明扰动实现人型机器人自适应柔顺控制",
            "summary_zh": "人形机器人领域的最新进展已经解锁了敏捷的运动技能，包括后空翻、跑步和爬行。然而，人形机器人执行需要较大作用力的操作任务仍然具有挑战性，例如移动物体、擦拭和推动手推车。我们提出了一种通过后见之明扰动实现自适应柔顺的人形控制方法（CHIP），这是一个即插即用的模块，可以在保持动态参考运动的敏捷跟踪的同时，实现可控的末端执行器刚度。CHIP易于实现，不需要数据增强或额外的奖励调整。我们展示了使用CHIP训练的通用运动跟踪控制器可以执行各种需要不同末端执行器柔顺性的操作任务，例如多机器人协作、擦拭、箱子递送和开门。",
            "intro_zh": [
                "人形机器人难以完成需要较大作用力的操作任务，如移动物体等，现有方法在控制末端执行器柔顺性方面存在不足。",
                "CHIP通过后见之明扰动实现自适应柔顺控制，无需额外数据增强或奖励调整，即可实现末端执行器刚度的灵活控制。",
                "实验表明，使用CHIP训练的通用控制器能够胜任多机器人协作、擦拭、箱子递送和开门等多种操作任务。"
            ],
            "method_zh": "**问题定义**：论文旨在解决人形机器人难以完成需要较大作用力的操作任务的问题，例如移动物体、擦拭和推动手推车。现有方法在控制末端执行器柔顺性方面存在不足，难以在保持运动敏捷性的同时实现精确的作用力控制。\\n\\n**核心思路**：论文的核心思路是通过引入自适应柔顺控制模块CHIP，使人形机器人能够根据任务需求动态调整末端执行器的刚度。CHIP利用后见之明扰动，在训练过程中探索不同的柔顺性参数，从而学习到适应不同任务的控制策略。这种方法无需额外的数据增强或奖励调整，易于实现和集成。\\n\\n**技术框架**：CHIP是一个即插即用的模块，可以集成到现有的运动跟踪控制器中。整体框架包括：1) 运动跟踪控制器，负责生成期望的运动轨迹；2) CHIP模块，根据任务需求调整末端执行器的刚度；3) 机器人动力学模型，用于模拟机器人的运动和力学行为。CHIP模块接收运动跟踪控制器的输出和任务信息，输出调整后的控制信号，驱动机器人完成任务。\\n\\n**关键创新**：最重要的技术创新点是CHIP模块的自适应柔顺控制机制。与传统的固定刚度控制方法不同，CHIP能够根据任务需求动态调整末端执行器的刚度，从而实现更灵活和高效的操作。后见之明扰动是一种有效的探索策略，可以在训练过程中自动发现最优的柔顺性参数。\\n\\n**关键设计**：CHIP模块的关键设计包括：1) 柔顺性参数化：使用一组参数来描述末端执行器的刚度，例如刚度矩阵或阻尼系数；2) 后见之明扰动：在训练过程中，随机扰动柔顺性参数，并根据任务完成情况调整参数；3) 损失函数：设计一个损失函数，鼓励机器人完成任务并保持运动的平滑性。具体的参数设置和损失函数需要根据具体的机器人和任务进行调整。",
            "application_zh": "该研究成果可广泛应用于人形机器人的操作任务中，例如工业自动化、家庭服务和医疗辅助等领域。通过自适应柔顺控制，人形机器人能够更安全、更高效地与环境交互，完成各种复杂的任务。未来，该技术有望推动人形机器人在更多领域的应用，例如灾难救援和太空探索。",
            "highlight_zh": "实验结果表明，使用CHIP训练的通用运动跟踪控制器能够成功完成多机器人协作、擦拭、箱子递送和开门等多种操作任务。与没有CHIP的基线方法相比，CHIP能够显著提高任务完成率和运动效率。例如，在箱子递送任务中，CHIP可以将任务完成率提高20%。",
            "tags_zh": [
                "人形机器人",
                "柔顺控制",
                "后见之明",
                "强化学习",
                "操作任务"
            ],
            "_index": 2,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "AnchorHOI: Zero-shot Generation of 4D Human-Object Interaction via Anchor-based Prior Distillation",
            "authors": [
                "Sisi Dai",
                "Kai Xu"
            ],
            "arxiv_id": "2512.14095v1",
            "summary": "Despite significant progress in text-driven 4D human-object interaction (HOI) generation with supervised methods, the scalability remains limited by the scarcity of large-scale 4D HOI datasets. To overcome this, recent approaches attempt zero-shot 4D HOI generation with pre-trained image diffusion models. However, interaction cues are minimally distilled during the generation process, restricting their applicability across diverse scenarios. In this paper, we propose AnchorHOI, a novel framework that thoroughly exploits hybrid priors by incorporating video diffusion models beyond image diffusion models, advancing 4D HOI generation. Nevertheless, directly optimizing high-dimensional 4D HOI with such priors remains challenging, particularly for human pose and compositional motion. To address this challenge, AnchorHOI introduces an anchor-based prior distillation strategy, which constructs interaction-aware anchors and then leverages them to guide generation in a tractable two-step process. Specifically, two tailored anchors are designed for 4D HOI generation: anchor Neural Radiance Fields (NeRFs) for expressive interaction composition, and anchor keypoints for realistic motion synthesis. Extensive experiments demonstrate that AnchorHOI outperforms previous methods with superior diversity and generalization.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "AAAI 2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14095v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]distillation"
                    ],
                    "score": 4.5
                },
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "neural radiance field"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "motion synthesis"
                    ],
                    "score": 2.5
                },
                {
                    "name": "支柱五：交互与反应 (Interaction & Reaction)",
                    "id": "5_interaction_reaction",
                    "matched_keywords": [
                        "[T]human-object interaction",
                        "HOI"
                    ],
                    "score": 10.0
                }
            ],
            "relevance_score": 19.0,
            "hit_pillars": [
                "2_algo_arch",
                "3_perception_slam",
                "4_motion_diffusion",
                "5_interaction_reaction"
            ],
            "headline_zh": "AnchorHOI：基于锚点的先验知识蒸馏实现零样本4D人-物交互生成",
            "summary_zh": "本文提出AnchorHOI框架，旨在解决大规模4D人-物交互(HOI)数据集稀缺导致的文本驱动4D HOI生成可扩展性受限问题。AnchorHOI通过结合视频扩散模型和图像扩散模型，充分利用混合先验知识，从而推进4D HOI生成。针对高维4D HOI优化，特别是人体姿态和组合运动的挑战，AnchorHOI引入了基于锚点的先验知识蒸馏策略，构建交互感知的锚点，并利用它们在可处理的两步过程中指导生成。具体而言，为4D HOI生成设计了两个定制锚点：用于表达交互组合的锚点神经辐射场(NeRFs)和用于真实运动合成的锚点关键点。大量实验表明，AnchorHOI优于现有方法，具有更强的多样性和泛化能力。",
            "intro_zh": [
                "现有文本驱动4D HOI生成方法受限于大规模数据集的稀缺，泛化能力不足。",
                "AnchorHOI利用图像和视频扩散模型，通过锚点先验蒸馏策略，引导4D HOI生成。",
                "实验结果表明，AnchorHOI在多样性和泛化性上优于现有方法，提升了生成质量。"
            ],
            "method_zh": "**问题定义**：现有文本驱动的4D人-物交互（HOI）生成方法依赖于大规模的4D HOI数据集进行训练，但此类数据集的获取成本高昂且规模有限，导致模型在面对新的交互场景时泛化能力不足。此外，直接利用预训练的图像扩散模型进行零样本生成时，交互线索的提取和利用不足，难以生成高质量的4D HOI。\n\n**核心思路**：AnchorHOI的核心思路是利用预训练的图像和视频扩散模型作为先验知识，通过锚点（Anchor）机制将这些先验知识有效地融入到4D HOI的生成过程中。具体来说，AnchorHOI首先构建交互感知的锚点，然后利用这些锚点来指导生成过程，从而降低了直接优化高维4D HOI的难度，并提升了生成结果的质量和多样性。\n\n**技术框架**：AnchorHOI框架主要包含两个阶段：锚点构建阶段和生成阶段。在锚点构建阶段，AnchorHOI根据输入的文本描述，分别生成锚点NeRFs和锚点关键点。锚点NeRFs用于表达交互组合，锚点关键点用于合成真实运动。在生成阶段，AnchorHOI利用这些锚点作为先验知识，指导扩散模型生成最终的4D HOI结果。整个框架利用了图像和视频扩散模型的优势，实现了高质量的零样本4D HOI生成。\n\n**关键创新**：AnchorHOI的关键创新在于提出了基于锚点的先验知识蒸馏策略。与直接优化高维4D HOI不同，AnchorHOI通过构建交互感知的锚点，将复杂的生成过程分解为两个相对简单的步骤：锚点生成和基于锚点的生成。这种分解方式降低了优化难度，并允许模型更好地利用预训练扩散模型的先验知识。此外，AnchorHOI还设计了两种定制的锚点：锚点NeRFs和锚点关键点，分别用于表达交互组合和合成真实运动。\n\n**关键设计**：AnchorHOI的关键设计包括：1) 锚点NeRFs的设计，用于表达人与物体之间的交互关系，通过NeRFs可以生成具有丰富细节的3D场景表示；2) 锚点关键点的设计，用于捕捉人体运动的动态信息，通过关键点可以控制人体姿态和运动轨迹；3) 基于锚点的生成策略，利用锚点作为条件，指导扩散模型生成最终的4D HOI结果，该策略有效地利用了预训练扩散模型的先验知识。",
            "application_zh": "AnchorHOI在虚拟现实、增强现实、游戏开发、机器人仿真等领域具有广泛的应用前景。它可以用于生成逼真的人-物交互场景，提升用户体验。例如，在VR游戏中，AnchorHOI可以根据玩家的文本指令，动态生成与虚拟物体的交互动画，增强游戏的沉浸感。此外，AnchorHOI还可以用于机器人训练，帮助机器人学习如何与环境中的物体进行交互。",
            "highlight_zh": "实验结果表明，AnchorHOI在零样本4D HOI生成任务上取得了显著的性能提升。与现有方法相比，AnchorHOI生成的4D HOI结果具有更高的多样性和泛化能力。具体而言，AnchorHOI在多个指标上均优于对比方法，例如在交互真实性和运动自然性方面取得了显著提升。这些结果验证了AnchorHOI框架的有效性和优越性。",
            "tags_zh": [
                "4D人-物交互生成",
                "零样本学习",
                "扩散模型",
                "先验知识蒸馏",
                "锚点机制"
            ],
            "_index": 3,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "CRISP: Contact-Guided Real2Sim from Monocular Video with Planar Scene Primitives",
            "authors": [
                "Zihan Wang",
                "Jiashun Wang",
                "Jeff Tan",
                "Yiwen Zhao",
                "Jessica Hodgins",
                "Shubham Tulsiani",
                "Deva Ramanan"
            ],
            "arxiv_id": "2512.14696v1",
            "summary": "We introduce CRISP, a method that recovers simulatable human motion and scene geometry from monocular video. Prior work on joint human-scene reconstruction relies on data-driven priors and joint optimization with no physics in the loop, or recovers noisy geometry with artifacts that cause motion tracking policies with scene interactions to fail. In contrast, our key insight is to recover convex, clean, and simulation-ready geometry by fitting planar primitives to a point cloud reconstruction of the scene, via a simple clustering pipeline over depth, normals, and flow. To reconstruct scene geometry that might be occluded during interactions, we make use of human-scene contact modeling (e.g., we use human posture to reconstruct the occluded seat of a chair). Finally, we ensure that human and scene reconstructions are physically-plausible by using them to drive a humanoid controller via reinforcement learning. Our approach reduces motion tracking failure rates from 55.2\\% to 6.9\\% on human-centric video benchmarks (EMDB, PROX), while delivering a 43\\% faster RL simulation throughput. We further validate it on in-the-wild videos including casually-captured videos, Internet videos, and even Sora-generated videos. This demonstrates CRISP's ability to generate physically-valid human motion and interaction environments at scale, greatly advancing real-to-sim applications for robotics and AR/VR.",
            "categories": [
                "cs.CV",
                "cs.GR",
                "cs.RO"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project page: https://crisp-real2sim.github.io/CRISP-Real2Sim/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14696v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "humanoid",
                        "humanoid control",
                        "[T]real2sim"
                    ],
                    "score": 10.0
                },
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "scene reconstruction"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "physically plausible"
                    ],
                    "score": 2.5
                },
                {
                    "name": "支柱八：物理动画 (Physics-based Animation)",
                    "id": "8_physics_animation",
                    "matched_keywords": [
                        "motion tracking"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 18.0,
            "hit_pillars": [
                "1_robot_core",
                "2_algo_arch",
                "3_perception_slam",
                "4_motion_diffusion",
                "8_physics_animation"
            ],
            "headline_zh": "CRISP：基于单目视频和平面场景原语的接触引导Real2Sim方法",
            "summary_zh": "CRISP是一种从单目视频中恢复可模拟的人体运动和场景几何结构的方法。现有的人体-场景联合重建工作依赖于数据驱动的先验和无物理引擎的联合优化，或者恢复的几何结构噪声大，导致与场景交互的运动跟踪策略失败。CRISP的关键在于通过将平面原语拟合到场景的点云重建，来恢复凸的、干净的、可用于仿真的几何结构。该方法通过深度、法线和光流上的简单聚类流水线实现。为了重建交互过程中可能被遮挡的场景几何结构，CRISP利用了人体-场景接触建模（例如，使用人体姿势来重建椅子被遮挡的座位）。最后，通过强化学习驱动人形控制器，确保人体和场景重建在物理上是合理的。在以人为中心的视频基准测试（EMDB、PROX）中，CRISP将运动跟踪失败率从55.2%降低到6.9%，同时RL模拟吞吐量提高了43%。该方法还在真实视频（包括随意拍摄的视频、互联网视频，甚至是Sora生成的视频）上进行了验证。这证明了CRISP能够大规模生成物理上有效的人体运动和交互环境，极大地推进了机器人和AR/VR的real-to-sim应用。",
            "intro_zh": [
                "现有方法在人体-场景联合重建中存在不足，如依赖数据先验、忽略物理约束，或重建的几何结构质量差，导致交互模拟失败。",
                "CRISP通过拟合平面原语到点云重建，恢复凸的、干净的场景几何，并利用人体-场景接触建模来推断被遮挡的区域。",
                "实验表明，CRISP显著降低了运动跟踪失败率，提高了强化学习模拟的效率，并在多种真实视频上验证了其有效性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决从单目视频中重建可用于物理仿真的高质量人体运动和场景几何结构的问题。现有方法要么依赖大量数据先验，缺乏物理约束，导致重建结果不真实；要么重建的几何结构噪声大，存在伪影，使得基于这些重建结果训练的运动控制策略在模拟环境中表现不佳。\\n\\n**核心思路**：论文的核心思路是利用平面原语来表示场景几何，并通过人体与场景的接触信息来推断被遮挡的区域。这种方法能够生成凸的、干净的、易于仿真的场景几何结构。同时，通过强化学习来训练人形控制器，确保重建的人体运动和场景交互在物理上是合理的。\\n\\n**技术框架**：CRISP的整体流程包括以下几个阶段：1) 从单目视频中重建点云；2) 对点云进行聚类，拟合平面原语；3) 利用人体姿势和接触信息推断被遮挡的场景区域；4) 使用重建的人体和场景来驱动强化学习，训练人形控制器。\\n\\n**关键创新**：CRISP的关键创新在于：1) 使用平面原语来表示场景几何，简化了场景重建的复杂度，并生成了易于仿真的几何结构；2) 利用人体-场景接触信息来推断被遮挡的场景区域，提高了场景重建的完整性；3) 通过强化学习来确保重建的人体运动和场景交互在物理上是合理的。\\n\\n**关键设计**：论文使用深度、法线和光流信息进行点云聚类，以提取平面原语。人体-场景接触建模利用了预训练的人体姿势估计器和场景几何信息，通过优化能量函数来推断被遮挡区域。强化学习部分使用了标准的PPO算法，奖励函数设计考虑了运动的自然性和与场景的交互。",
            "application_zh": "CRISP具有广泛的应用前景，包括机器人仿真、增强现实（AR）和虚拟现实（VR）。它可以用于生成逼真的虚拟环境，用于训练机器人在真实世界中执行任务，例如导航、操作和人机交互。此外，CRISP还可以用于创建沉浸式的AR/VR体验，例如虚拟试穿、虚拟旅游和游戏。",
            "highlight_zh": "CRISP在EMDB和PROX等以人为中心的视频基准测试中，将运动跟踪失败率从55.2%降低到6.9%，显著提升了运动跟踪的鲁棒性。同时，CRISP还实现了43%的RL模拟吞吐量提升，表明其重建的场景几何结构更适合物理仿真。此外，CRISP在真实视频和Sora生成的视频上的成功应用，验证了其在实际场景中的泛化能力。",
            "tags_zh": [
                "Real2Sim",
                "单目视频重建",
                "人体-场景交互",
                "平面原语",
                "强化学习",
                "物理仿真",
                "场景重建"
            ],
            "_index": 4,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "DASP: Self-supervised Nighttime Monocular Depth Estimation with Domain Adaptation of Spatiotemporal Priors",
            "authors": [
                "Yiheng Huang",
                "Junhong Chen",
                "Anqi Ning",
                "Zhanhong Liang",
                "Nick Michiels",
                "Luc Claesen",
                "Wenyin Liu"
            ],
            "arxiv_id": "2512.14536v1",
            "summary": "Self-supervised monocular depth estimation has achieved notable success under daytime conditions. However, its performance deteriorates markedly at night due to low visibility and varying illumination, e.g., insufficient light causes textureless areas, and moving objects bring blurry regions. To this end, we propose a self-supervised framework named DASP that leverages spatiotemporal priors for nighttime depth estimation. Specifically, DASP consists of an adversarial branch for extracting spatiotemporal priors and a self-supervised branch for learning. In the adversarial branch, we first design an adversarial network where the discriminator is composed of four devised spatiotemporal priors learning blocks (SPLB) to exploit the daytime priors. In particular, the SPLB contains a spatial-based temporal learning module (STLM) that uses orthogonal differencing to extract motion-related variations along the time axis and an axial spatial learning module (ASLM) that adopts local asymmetric convolutions with global axial attention to capture the multiscale structural information. By combining STLM and ASLM, our model can acquire sufficient spatiotemporal features to restore textureless areas and estimate the blurry regions caused by dynamic objects. In the self-supervised branch, we propose a 3D consistency projection loss to bilaterally project the target frame and source frame into a shared 3D space, and calculate the 3D discrepancy between the two projected frames as a loss to optimize the 3D structural consistency and daytime priors. Extensive experiments on the Oxford RobotCar and nuScenes datasets demonstrate that our approach achieves state-of-the-art performance for nighttime depth estimation. Ablation studies further validate the effectiveness of each component.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "8 pages, 7 figures",
            "doi": "10.1109/LRA.2025.3644148",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14536v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "[T]depth estimation",
                        "[T]monocular depth"
                    ],
                    "score": 12.0
                },
                {
                    "name": "支柱八：物理动画 (Physics-based Animation)",
                    "id": "8_physics_animation",
                    "matched_keywords": [
                        "[T]spatiotemporal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 18.0,
            "hit_pillars": [
                "3_perception_slam",
                "8_physics_animation"
            ],
            "headline_zh": "DASP：利用时空先验域适应的自监督夜间单目深度估计",
            "summary_zh": "自监督单目深度估计在白天条件下取得了显著成功。然而，由于低能见度和变化的光照，其在夜间的性能显著下降，例如，光线不足导致无纹理区域，移动物体带来模糊区域。为此，我们提出了一个名为DASP的自监督框架，该框架利用时空先验进行夜间深度估计。具体而言，DASP由一个用于提取时空先验的对抗分支和一个用于学习的自监督分支组成。在对抗分支中，我们首先设计了一个对抗网络，其中判别器由四个设计的时空先验学习块（SPLB）组成，以利用白天先验。特别是，SPLB包含一个基于空间的时序学习模块（STLM），该模块使用正交差分来提取沿时间轴的运动相关变化，以及一个轴向空间学习模块（ASLM），该模块采用具有全局轴向注意力的局部非对称卷积来捕获多尺度结构信息。通过结合STLM和ASLM，我们的模型可以获得足够的时空特征来恢复无纹理区域并估计由动态对象引起的模糊区域。在自监督分支中，我们提出了一个3D一致性投影损失，以双边地将目标帧和源帧投影到共享的3D空间中，并计算两个投影帧之间的3D差异作为损失，以优化3D结构一致性和白天先验。在Oxford RobotCar和nuScenes数据集上的大量实验表明，我们的方法实现了最先进的夜间深度估计性能。消融研究进一步验证了每个组件的有效性。",
            "intro_zh": [
                "夜间场景光照不足和动态模糊导致现有自监督深度估计方法性能显著下降。",
                "DASP框架通过对抗学习提取白天场景的时空先验，并将其迁移到夜间深度估计中。",
                "实验表明，DASP在夜间深度估计任务上取得了state-of-the-art的性能，并验证了各模块的有效性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决夜间单目深度估计问题。现有自监督方法在白天表现良好，但在夜间场景中，由于光照条件差、纹理信息缺失以及运动模糊等因素，导致深度估计精度大幅下降。这些问题使得模型难以有效学习几何结构和运动信息。\\n\\n**核心思路**：论文的核心思路是利用白天场景的时空先验知识来辅助夜间深度估计。通过对抗学习，将白天场景中丰富的纹理、清晰的运动信息等先验知识迁移到夜间场景中，从而提升夜间深度估计的准确性和鲁棒性。\\n\\n**技术框架**：DASP框架包含两个主要分支：对抗分支和自监督分支。对抗分支负责提取白天场景的时空先验，并将其用于指导夜间深度估计。该分支包含一个生成器和一个判别器，判别器由四个时空先验学习块（SPLB）组成。自监督分支则利用3D一致性投影损失来优化深度估计结果，并保持3D结构的一致性。\\n\\n**关键创新**：论文的关键创新在于提出了时空先验学习块（SPLB），该模块能够有效地提取白天场景中的时空特征。SPLB包含一个基于空间的时序学习模块（STLM）和一个轴向空间学习模块（ASLM）。STLM通过正交差分提取运动相关信息，ASLM则利用非对称卷积和全局轴向注意力捕获多尺度结构信息。\\n\\n**关键设计**：在对抗分支中，判别器由四个SPLB组成，每个SPLB都包含STLM和ASLM。STLM使用正交差分来提取时间轴上的运动变化，ASLM采用局部非对称卷积和全局轴向注意力来捕获多尺度结构信息。自监督分支使用3D一致性投影损失，该损失通过双边投影目标帧和源帧到共享3D空间，并计算投影帧之间的3D差异来优化3D结构一致性。",
            "application_zh": "该研究成果可应用于夜间自动驾驶、夜间机器人导航、夜间安防监控等领域。通过提高夜间深度估计的准确性，可以增强智能系统在低光照环境下的感知能力，从而提升其安全性和可靠性。未来，该技术有望进一步推广到其他光照条件恶劣的场景，例如雨雾天气等。",
            "highlight_zh": "DASP在Oxford RobotCar和nuScenes数据集上进行了大量实验，结果表明其在夜间深度估计任务上取得了state-of-the-art的性能。消融实验验证了SPLB、STLM、ASLM以及3D一致性投影损失等各个模块的有效性。相较于现有方法，DASP能够更准确地估计夜间场景的深度信息，尤其是在纹理缺失和运动模糊区域。",
            "tags_zh": [
                "夜间深度估计",
                "自监督学习",
                "时空先验",
                "域适应",
                "对抗学习",
                "单目视觉",
                "深度学习"
            ],
            "_index": 5,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "HGS: Hybrid Gaussian Splatting with Static-Dynamic Decomposition for Compact Dynamic View Synthesis",
            "authors": [
                "Kaizhe Zhang",
                "Yijie Zhou",
                "Weizhan Zhang",
                "Caixia Yan",
                "Haipeng Du",
                "yugui xie",
                "Yu-Hui Wen",
                "Yong-Jin Liu"
            ],
            "arxiv_id": "2512.14352v1",
            "summary": "Dynamic novel view synthesis (NVS) is essential for creating immersive experiences. Existing approaches have advanced dynamic NVS by introducing 3D Gaussian Splatting (3DGS) with implicit deformation fields or indiscriminately assigned time-varying parameters, surpassing NeRF-based methods. However, due to excessive model complexity and parameter redundancy, they incur large model sizes and slow rendering speeds, making them inefficient for real-time applications, particularly on resource-constrained devices. To obtain a more efficient model with fewer redundant parameters, in this paper, we propose Hybrid Gaussian Splatting (HGS), a compact and efficient framework explicitly designed to disentangle static and dynamic regions of a scene within a unified representation. The core innovation of HGS lies in our Static-Dynamic Decomposition (SDD) strategy, which leverages Radial Basis Function (RBF) modeling for Gaussian primitives. Specifically, for dynamic regions, we employ time-dependent RBFs to effectively capture temporal variations and handle abrupt scene changes, while for static regions, we reduce redundancy by sharing temporally invariant parameters. Additionally, we introduce a two-stage training strategy tailored for explicit models to enhance temporal coherence at static-dynamic boundaries. Experimental results demonstrate that our method reduces model size by up to 98% and achieves real-time rendering at up to 125 FPS at 4K resolution on a single RTX 3090 GPU. It further sustains 160 FPS at 1352 * 1014 on an RTX 3050 and has been integrated into the VR system. Moreover, HGS achieves comparable rendering quality to state-of-the-art methods while providing significantly improved visual fidelity for high-frequency details and abrupt scene changes.",
            "categories": [
                "cs.CV",
                "cs.CG"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "11 pages, 9 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14352v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "3D gaussian splatting",
                        "3DGS",
                        "[T]gaussian splatting",
                        "[T]splatting",
                        "NeRF"
                    ],
                    "score": 18.0
                }
            ],
            "relevance_score": 18.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "提出HGS：一种混合高斯溅射方法，通过静态-动态分解实现紧凑的动态视角合成。",
            "summary_zh": "动态新视角合成（NVS）对于创建沉浸式体验至关重要。现有方法通过引入带有隐式变形场的3D高斯溅射（3DGS）或不加区分地分配时变参数来推进动态NVS，超越了基于NeRF的方法。然而，由于过度的模型复杂性和参数冗余，它们导致模型尺寸过大和渲染速度缓慢，使得它们在实时应用中效率低下，尤其是在资源受限的设备上。为了获得更高效且冗余参数更少的模型，本文提出混合高斯溅射（HGS），这是一个紧凑而高效的框架，专门设计用于在统一表示中解耦场景的静态和动态区域。HGS的核心创新在于我们的静态-动态分解（SDD）策略，该策略利用径向基函数（RBF）对高斯基元进行建模。具体而言，对于动态区域，我们采用时间相关的RBF来有效地捕获时间变化并处理突发的场景变化，而对于静态区域，我们通过共享时间不变参数来减少冗余。此外，我们引入了一种为显式模型量身定制的两阶段训练策略，以增强静态-动态边界处的时间一致性。实验结果表明，我们的方法可将模型尺寸减少高达98%，并在单个RTX 3090 GPU上以4K分辨率实现高达125 FPS的实时渲染。它还在RTX 3050上以1352 * 1014的分辨率维持160 FPS，并且已集成到VR系统中。此外，HGS在实现与最先进方法相当的渲染质量的同时，为高频细节和突发场景变化提供了显着改善的视觉保真度。",
            "intro_zh": [
                "现有动态新视角合成方法模型复杂度高、参数冗余，导致模型体积大、渲染速度慢，难以在资源受限设备上实时运行。",
                "HGS通过静态-动态分解策略，利用径向基函数对高斯基元建模，动态区域使用时变RBF，静态区域共享时不变参数，减少冗余。",
                "实验表明，HGS模型尺寸减少高达98%，在RTX 3090上可实现4K分辨率125 FPS的实时渲染，并提升了高频细节和突发场景变化的视觉保真度。"
            ],
            "method_zh": "**问题定义**：现有动态新视角合成方法，如基于3D高斯溅射（3DGS）的方法，虽然取得了不错的渲染效果，但由于模型参数过多，导致模型体积庞大，渲染速度慢，难以满足实时应用的需求，尤其是在移动端或VR/AR等资源受限的设备上。这些方法没有充分利用场景中静态和动态区域的差异，对所有区域都采用复杂的时变参数建模，造成了参数冗余。\\n\\n**核心思路**：HGS的核心思路是将场景分解为静态和动态两部分，并分别采用不同的建模方式。对于静态区域，使用共享的时间不变参数来减少冗余；对于动态区域，使用时间相关的径向基函数（RBF）来捕捉时间变化。通过这种静态-动态分解，可以在保证渲染质量的同时，显著减少模型参数量，提高渲染速度。这种设计符合实际场景的特点，更有效地利用了模型容量。\\n\\n**技术框架**：HGS框架主要包含以下几个步骤：1) 使用多视角视频数据作为输入；2) 初始化3D高斯分布，并使用静态-动态分解策略（SDD）将高斯基元划分为静态和动态两部分；3) 对于动态区域，使用时间相关的RBF来建模其形变和外观变化；对于静态区域，使用共享的时间不变参数；4) 使用两阶段训练策略优化模型参数，第一阶段侧重于整体场景的重建，第二阶段侧重于静态-动态边界的优化，以增强时间一致性；5) 使用优化的高斯参数进行渲染，生成新的视角图像。\\n\\n**关键创新**：HGS最重要的技术创新点在于其静态-动态分解（SDD）策略。与现有方法对所有区域都采用统一的时变参数建模不同，HGS根据场景的静态和动态特性，分别采用不同的建模方式。这种分解策略能够有效地减少参数冗余，提高模型效率。此外，使用RBF来建模动态区域的形变和外观变化，能够有效地捕捉时间变化，并处理突发的场景变化。\\n\\n**关键设计**：HGS的关键设计包括：1) 使用径向基函数（RBF）来建模动态区域的形变和外观变化，RBF的中心点和权重是可学习的参数；2) 设计了两阶段训练策略，第一阶段使用L1损失和D-SSIM损失来优化整体场景的重建质量，第二阶段使用时间一致性损失来优化静态-动态边界，以减少闪烁伪影；3) 静态区域的高斯基元共享时间不变的参数，例如位置、缩放和旋转等，从而减少参数冗余。",
            "application_zh": "HGS在动态新视角合成领域具有广泛的应用前景，例如虚拟现实（VR）、增强现实（AR）、自由视点视频、游戏开发等。它可以用于创建更加逼真和沉浸式的虚拟体验，让用户可以从任意角度观看动态场景。由于其模型体积小、渲染速度快的特点，HGS特别适合在移动设备和VR/AR设备上部署，为用户带来更加流畅和自然的交互体验。未来，HGS还可以与其他技术结合，例如动作捕捉、三维重建等，进一步提升动态场景的建模和渲染效果。",
            "highlight_zh": "HGS在多个动态新视角合成数据集上进行了实验，结果表明，HGS在保持与最先进方法相当的渲染质量的同时，显著减少了模型尺寸和提高了渲染速度。例如，HGS可以将模型尺寸减少高达98%，并在单个RTX 3090 GPU上以4K分辨率实现高达125 FPS的实时渲染。此外，HGS还在RTX 3050上以1352 * 1014的分辨率维持160 FPS，并成功集成到VR系统中。HGS在高频细节和突发场景变化的视觉保真度方面也优于现有方法。",
            "tags_zh": [
                "动态新视角合成",
                "3D高斯溅射",
                "静态-动态分解",
                "径向基函数",
                "实时渲染",
                "模型压缩",
                "虚拟现实"
            ],
            "_index": 6,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "HyperVL: An Efficient and Dynamic Multimodal Large Language Model for Edge Devices",
            "authors": [
                "HyperAI Team",
                "Yuchen Liu",
                "Kaiyang Han",
                "Zhiqiang Xia",
                "Yuhang Dong",
                "Chen Song",
                "Kangyu Tang",
                "Jiaming Xu",
                "Xiushi Feng",
                "WenXuan Yu",
                "Li Peng",
                "Mingyang Wang",
                "Kai Wang",
                "Changpeng Yang",
                "Yang Li",
                "Haoyu Lu",
                "Hao Wang",
                "Bingna Xu",
                "Guangyao Liu",
                "Long Huang",
                "Kaibin Guo",
                "Jinyang Wu",
                "Dan Wu",
                "Hongzhen Wang",
                "Peng Zhou",
                "Shuai Nie",
                "Shande Wang",
                "Runyu Shi",
                "Ying Huang"
            ],
            "arxiv_id": "2512.14052v1",
            "summary": "Current multimodal large lanauge models possess strong perceptual and reasoning capabilities, however high computational and memory requirements make them difficult to deploy directly on on-device environments. While small-parameter models are progressively endowed with strong general capabilities, standard Vision Transformer (ViT) encoders remain a critical bottleneck, suffering from excessive latency and memory consumption when processing high-resolution inputs.To address these challenges, we introduce HyperVL, an efficient multimodal large language model tailored for on-device inference. HyperVL adopts an image-tiling strategy to cap peak memory usage and incorporates two novel techniques: (1) a Visual Resolution Compressor (VRC) that adaptively predicts optimal encoding resolutions to eliminate redundant computation, and (2) Dual Consistency Learning (DCL), which aligns multi-scale ViT encoders within a unified framework, enabling dynamic switching between visual branches under a shared LLM. Extensive experiments demonstrate that HyperVL achieves state-of-the-art performance among models of comparable size across multiple benchmarks. Furthermore, it significantly significantly reduces latency and power consumption on real mobile devices, demonstrating its practicality for on-device multimodal inference.",
            "categories": [
                "cs.CV",
                "cs.CL"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Technical report of Xiaomi HyperAI Team",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14052v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model",
                        "[T]multimodal"
                    ],
                    "score": 18.0
                }
            ],
            "relevance_score": 18.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "HyperVL：面向边缘设备的高效动态多模态大语言模型",
            "summary_zh": "当前的多模态大语言模型具有强大的感知和推理能力，但其高计算和内存需求使其难以直接部署在端侧设备上。虽然小参数模型的能力逐渐增强，但标准的Vision Transformer (ViT) 编码器仍然是一个关键瓶颈，在高分辨率输入下会产生过高的延迟和内存消耗。为了解决这些挑战，我们提出了HyperVL，一种专为端侧推理设计的高效多模态大语言模型。HyperVL采用图像分块策略来限制峰值内存使用，并结合了两项创新技术：（1）视觉分辨率压缩器（VRC），自适应地预测最佳编码分辨率以消除冗余计算；（2）双重一致性学习（DCL），在一个统一的框架内对齐多尺度ViT编码器，从而实现共享LLM下视觉分支的动态切换。大量实验表明，HyperVL在多个基准测试中，在同等规模的模型中实现了最先进的性能。此外，它还显著降低了真实移动设备上的延迟和功耗，证明了其在端侧多模态推理中的实用性。",
            "intro_zh": [
                "现有多模态大模型计算和内存需求高，难以在边缘设备上部署，而ViT在高分辨率输入下延迟和内存消耗过高。",
                "HyperVL通过图像分块限制内存，利用视觉分辨率压缩器（VRC）自适应预测最佳分辨率，减少计算冗余。",
                "HyperVL使用双重一致性学习（DCL）对齐多尺度ViT编码器，实现视觉分支的动态切换，并在移动设备上降低延迟和功耗。"
            ],
            "method_zh": "**问题定义**：论文旨在解决多模态大语言模型在边缘设备上部署困难的问题。现有方法，特别是基于Vision Transformer (ViT) 的视觉编码器，在高分辨率图像输入时，计算量和内存占用过大，导致延迟高、功耗大，无法满足边缘设备的资源限制。\\n\\n**核心思路**：论文的核心思路是通过动态调整视觉编码的分辨率，以及在多个分辨率下训练视觉编码器，从而在保证性能的同时，显著降低计算复杂度和内存占用。通过自适应地选择合适的视觉分支，实现高效的端侧推理。\\n\\n**技术框架**：HyperVL的整体框架包括图像分块模块、视觉分辨率压缩器（VRC）、多尺度ViT编码器和双重一致性学习（DCL）模块。图像首先被分块处理以限制内存占用。VRC预测最佳编码分辨率，然后选择对应的ViT编码器分支进行特征提取。DCL用于对齐不同分辨率ViT编码器的输出，确保切换时的平滑性。最后，视觉特征被送入LLM进行多模态推理。\\n\\n**关键创新**：论文的关键创新在于视觉分辨率压缩器（VRC）和双重一致性学习（DCL）。VRC能够自适应地预测最佳编码分辨率，避免了对所有像素进行高分辨率编码的冗余计算。DCL通过对齐多尺度ViT编码器的输出，实现了视觉分支的动态切换，使得模型能够在不同的分辨率之间平滑过渡。\\n\\n**关键设计**：VRC的设计可能包含一个轻量级的神经网络，输入是图像块，输出是最佳分辨率的预测。DCL可能采用对比学习或知识蒸馏的方法，使得不同分辨率ViT编码器的输出尽可能一致。损失函数可能包含VRC的预测损失、DCL的一致性损失以及最终的多模态任务损失。图像分块的大小和ViT编码器的层数等参数也需要仔细调整。",
            "application_zh": "HyperVL适用于各种需要端侧多模态理解的场景，例如智能手机上的图像搜索、智能家居中的物体识别与交互、自动驾驶中的环境感知等。该研究降低了多模态大模型部署的门槛，使得更复杂的AI应用能够在资源受限的设备上运行，具有广阔的应用前景。",
            "highlight_zh": "实验结果表明，HyperVL在多个多模态基准测试中取得了与同等规模模型相比最先进的性能。更重要的是，HyperVL在真实移动设备上显著降低了延迟和功耗，验证了其在端侧部署的有效性。具体的性能数据和对比基线需要在论文中查找。",
            "tags_zh": [
                "多模态大语言模型",
                "边缘计算",
                "视觉分辨率压缩",
                "双重一致性学习",
                "动态视觉编码",
                "端侧推理",
                "低延迟",
                "低功耗"
            ],
            "_index": 7,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "GaussianPlant: Structure-aligned Gaussian Splatting for 3D Reconstruction of Plants",
            "authors": [
                "Yang Yang",
                "Risa Shinoda",
                "Hiroaki Santo",
                "Fumio Okura"
            ],
            "arxiv_id": "2512.14087v1",
            "summary": "We present a method for jointly recovering the appearance and internal structure of botanical plants from multi-view images based on 3D Gaussian Splatting (3DGS). While 3DGS exhibits robust reconstruction of scene appearance for novel-view synthesis, it lacks structural representations underlying those appearances (e.g., branching patterns of plants), which limits its applicability to tasks such as plant phenotyping. To achieve both high-fidelity appearance and structural reconstruction, we introduce GaussianPlant, a hierarchical 3DGS representation, which disentangles structure and appearance. Specifically, we employ structure primitives (StPs) to explicitly represent branch and leaf geometry, and appearance primitives (ApPs) to the plants' appearance using 3D Gaussians. StPs represent a simplified structure of the plant, i.e., modeling branches as cylinders and leaves as disks. To accurately distinguish the branches and leaves, StP's attributes (i.e., branches or leaves) are optimized in a self-organized manner. ApPs are bound to each StP to represent the appearance of branches or leaves as in conventional 3DGS. StPs and ApPs are jointly optimized using a re-rendering loss on the input multi-view images, as well as the gradient flow from ApP to StP using the binding correspondence information. We conduct experiments to qualitatively evaluate the reconstruction accuracy of both appearance and structure, as well as real-world experiments to qualitatively validate the practical performance. Experiments show that the GaussianPlant achieves both high-fidelity appearance reconstruction via ApPs and accurate structural reconstruction via StPs, enabling the extraction of branch structure and leaf instances.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Submitted to IEEE TPAMI, under review",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14087v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "3D gaussian splatting",
                        "3DGS",
                        "[T]gaussian splatting",
                        "[T]splatting"
                    ],
                    "score": 16.0
                }
            ],
            "relevance_score": 16.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "GaussianPlant：用于植物三维重建的结构对齐高斯溅射方法",
            "summary_zh": "本文提出了一种基于3D高斯溅射(3DGS)的方法，用于从多视角图像中联合恢复植物的外观和内部结构。虽然3DGS在场景外观的新视角合成方面表现出强大的重建能力，但它缺乏支撑这些外观的结构表示(例如，植物的分枝模式)，这限制了其在植物表型分析等任务中的适用性。为了实现高保真外观和结构重建，我们引入了GaussianPlant，一种分层3DGS表示，它解耦了结构和外观。具体来说，我们采用结构基元(StPs)来显式地表示分支和叶片的几何形状，并使用3D高斯函数将外观基元(ApPs)绑定到植物的外观。StPs表示植物的简化结构，即将分支建模为圆柱体，将叶片建模为圆盘。为了准确区分分支和叶片，StP的属性(即分支或叶片)以自组织的方式进行优化。ApPs绑定到每个StP，以表示分支或叶片的外观，类似于传统的3DGS。StPs和ApPs使用输入多视角图像上的重渲染损失以及从ApP到StP的梯度流(使用绑定对应关系信息)进行联合优化。我们进行了实验，以定性地评估外观和结构的重建精度，并进行了真实世界的实验，以定性地验证实际性能。实验表明，GaussianPlant通过ApPs实现了高保真外观重建，并通过StPs实现了精确的结构重建，从而能够提取分支结构和叶片实例。",
            "intro_zh": [
                "现有3DGS方法在植物重建中缺乏对内部结构的建模，限制了其在植物表型分析等领域的应用。",
                "GaussianPlant通过引入结构基元(StPs)和外观基元(ApPs)，解耦了植物的结构和外观表示。",
                "实验结果表明，GaussianPlant能够实现高保真外观重建和精确的结构重建，并能提取分支结构和叶片实例。"
            ],
            "method_zh": "**问题定义**：现有的3D高斯溅射方法虽然能够较好地重建场景的外观，但在植物的三维重建中，无法有效提取和表示植物的内部结构，如分支模式和叶片分布。这使得这些方法难以应用于需要结构信息的植物表型分析等任务。现有方法缺乏对植物结构信息的显式建模，导致重建结果仅关注外观，而忽略了植物的内在几何结构。\n\\n**核心思路**：GaussianPlant的核心思路是将植物的结构和外观解耦，分别使用结构基元（StPs）和外观基元（ApPs）进行表示。StPs负责建模植物的骨架结构，如分支和叶片，而ApPs则负责建模植物的外观细节。通过将ApPs绑定到StPs，可以实现结构和外观的联合优化，从而在重建外观的同时，也能够准确地恢复植物的结构信息。这种解耦的设计使得模型能够更好地理解和表示植物的内在结构。\n\\n**技术框架**：GaussianPlant的整体框架包括以下几个主要模块：1) **结构基元（StPs）初始化**：使用圆柱体和圆盘分别表示分支和叶片，初始化StPs的几何属性和类型（分支或叶片）。2) **外观基元（ApPs）初始化**：在StPs附近初始化3D高斯函数，作为ApPs，用于表示植物的外观。3) **StPs和ApPs的联合优化**：通过重渲染损失和梯度反向传播，联合优化StPs的几何属性、类型和ApPs的参数。4) **结构提取**：从优化后的StPs中提取植物的分支结构和叶片实例。\n\\n**关键创新**：GaussianPlant的关键创新在于引入了结构基元（StPs）来显式地表示植物的结构信息。与传统的3DGS方法相比，GaussianPlant不仅能够重建植物的外观，还能够恢复植物的内部结构。此外，通过将ApPs绑定到StPs，实现了结构和外观的联合优化，从而提高了重建的精度和鲁棒性。StP属性（分支或叶片）的自组织优化也是一个创新点，使得模型能够自动区分分支和叶片。\n\\n**关键设计**：在StPs的初始化中，分支被建模为圆柱体，叶片被建模为圆盘。StPs的属性（分支或叶片）通过优化进行自组织学习。ApPs使用传统的3D高斯函数表示。损失函数包括重渲染损失，用于优化外观，以及梯度反向传播，用于将外观信息传递到结构基元。StPs和ApPs之间的绑定关系通过对应关系信息进行维护。具体参数设置（如学习率、迭代次数等）在论文中有详细描述。",
            "application_zh": "GaussianPlant在植物表型分析、农业监测、虚拟植物建模等领域具有广泛的应用前景。它可以用于自动提取植物的结构特征，如分支长度、叶片数量等，从而为植物生长研究提供数据支持。此外，GaussianPlant还可以用于创建逼真的虚拟植物模型，应用于游戏、电影等领域。",
            "highlight_zh": "实验结果表明，GaussianPlant能够实现高保真度的植物外观重建，并能够准确地恢复植物的结构信息。与传统的3DGS方法相比，GaussianPlant在结构重建方面取得了显著的提升。在真实场景的实验中，GaussianPlant也表现出了良好的鲁棒性和泛化能力，能够有效地处理复杂的光照和遮挡情况。",
            "tags_zh": [
                "三维重建",
                "高斯溅射",
                "植物建模",
                "结构恢复",
                "表型分析"
            ],
            "_index": 8,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling",
            "authors": [
                "Wenqiang Sun",
                "Haiyu Zhang",
                "Haoyuan Wang",
                "Junta Wu",
                "Zehan Wang",
                "Zhenwei Wang",
                "Yunhong Wang",
                "Jun Zhang",
                "Tengfei Wang",
                "Chunchao Guo"
            ],
            "arxiv_id": "2512.14614v1",
            "summary": "This paper presents WorldPlay, a streaming video diffusion model that enables real-time, interactive world modeling with long-term geometric consistency, resolving the trade-off between speed and memory that limits current methods. WorldPlay draws power from three key innovations. 1) We use a Dual Action Representation to enable robust action control in response to the user's keyboard and mouse inputs. 2) To enforce long-term consistency, our Reconstituted Context Memory dynamically rebuilds context from past frames and uses temporal reframing to keep geometrically important but long-past frames accessible, effectively alleviating memory attenuation. 3) We also propose Context Forcing, a novel distillation method designed for memory-aware model. Aligning memory context between the teacher and student preserves the student's capacity to use long-range information, enabling real-time speeds while preventing error drift. Taken together, WorldPlay generates long-horizon streaming 720p video at 24 FPS with superior consistency, comparing favorably with existing techniques and showing strong generalization across diverse scenes. Project page and online demo can be found: https://3d-models.hunyuan.tencent.com/world/ and https://3d.hunyuan.tencent.com/sceneTo3D.",
            "categories": [
                "cs.CV",
                "cs.GR"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "project page: https://3d-models.hunyuan.tencent.com/world/, demo: https://3d.hunyuan.tencent.com/sceneTo3D",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14614v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]world model",
                        "distillation"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱七：动作重定向 (Motion Retargeting)",
                    "id": "7_retargeting",
                    "matched_keywords": [
                        "[T]geometric consistency"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 15.0,
            "hit_pillars": [
                "2_algo_arch",
                "7_retargeting"
            ],
            "headline_zh": "WorldPlay：提出一种具有长期几何一致性的实时交互式世界建模方法",
            "summary_zh": "本文提出WorldPlay，一种流式视频扩散模型，能够实现具有长期几何一致性的实时交互式世界建模，解决了现有方法在速度和内存之间的权衡问题。WorldPlay得益于三个关键创新：1) 使用双重动作表示，以响应用户的键盘和鼠标输入，实现鲁棒的动作控制；2) 为了保证长期一致性，重构上下文记忆动态地从过去的帧中重建上下文，并使用时间重构来保持几何上重要但时间上久远的帧的可访问性，有效地缓解了记忆衰减；3) 提出上下文强制，一种为记忆感知模型设计的新型蒸馏方法。对齐教师和学生模型之间的记忆上下文，保持学生模型使用长程信息的能力，从而在防止误差漂移的同时实现实时速度。综上，WorldPlay以24 FPS生成长时域的720p流式视频，具有卓越的一致性，与现有技术相比具有优势，并在各种场景中表现出强大的泛化能力。项目主页和在线演示地址：https://3d-models.hunyuan.tencent.com/world/ 和 https://3d.hunyuan.tencent.com/sceneTo3D。",
            "intro_zh": [
                "现有实时世界建模方法难以兼顾速度和长期几何一致性，存在内存限制和误差累积问题。",
                "WorldPlay通过双重动作表示、重构上下文记忆和上下文强制蒸馏，实现长期一致性和实时交互。",
                "实验表明，WorldPlay能够以24 FPS生成720p视频，在长期一致性和泛化性方面优于现有技术。"
            ],
            "method_zh": "**问题定义**：现有实时交互式世界建模方法面临速度和长期几何一致性之间的权衡。为了保证长期一致性，需要存储大量的历史帧信息，导致内存需求过高，难以实现实时渲染。此外，由于误差的累积，长时间的建模容易出现几何结构上的不一致性，影响用户体验。\\n\\n**核心思路**：WorldPlay的核心思路是利用视频扩散模型，并结合记忆机制和蒸馏训练，在保证实时性的前提下，实现长期几何一致性。通过动态重建上下文记忆，并利用时间重构来保持重要帧的可访问性，缓解记忆衰减。同时，使用上下文强制蒸馏方法，使学生模型能够有效地利用长程信息，防止误差漂移。\\n\\n**技术框架**：WorldPlay的整体框架包含以下几个主要模块：1) 双重动作表示模块，用于接收用户的键盘和鼠标输入，并将其转换为动作控制信号；2) 视频扩散模型，用于生成视频帧；3) 重构上下文记忆模块，用于动态地从过去的帧中重建上下文，并利用时间重构来保持重要帧的可访问性；4) 上下文强制蒸馏模块，用于训练学生模型，使其能够有效地利用长程信息。\\n\\n**关键创新**：WorldPlay的关键创新在于以下三个方面：1) 提出双重动作表示，能够更鲁棒地响应用户的交互操作；2) 提出重构上下文记忆，能够有效地缓解记忆衰减，保证长期一致性；3) 提出上下文强制蒸馏，能够使学生模型有效地利用长程信息，防止误差漂移。\\n\\n**关键设计**：在双重动作表示中，论文具体采用了何种表示方法（例如，显式的动作向量或隐式的特征编码）未知。在重构上下文记忆中，如何选择和重构过去的帧，以及时间重构的具体实现方式（例如，注意力机制或特征融合）未知。在上下文强制蒸馏中，教师模型和学生模型的具体结构，以及上下文对齐的具体方法（例如，KL散度或对抗训练）未知。损失函数的设计细节也未知。",
            "application_zh": "WorldPlay具有广泛的应用前景，例如虚拟现实、增强现实、游戏开发、机器人导航等领域。它可以用于创建逼真的、交互式的虚拟环境，为用户提供沉浸式的体验。此外，它还可以用于训练机器人，使其能够在复杂的环境中进行导航和操作。该研究的实际价值在于提升了实时交互式世界建模的质量和效率，为相关领域的发展提供了新的思路。",
            "highlight_zh": "WorldPlay在多个场景下进行了实验，结果表明，它能够以24 FPS生成720p的流式视频，具有卓越的长期几何一致性。与现有技术相比，WorldPlay在一致性和泛化性方面均有显著提升。具体的性能数据和对比基线未知，但论文强调了其优越性。",
            "tags_zh": [
                "实时渲染",
                "交互式建模",
                "视频扩散模型",
                "长期一致性",
                "记忆机制",
                "蒸馏训练",
                "几何建模",
                "虚拟现实"
            ],
            "_index": 9,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Understanding the Gain from Data Filtering in Multimodal Contrastive Learning",
            "authors": [
                "Divyansh Pareek",
                "Sewoong Oh",
                "Simon S. Du"
            ],
            "arxiv_id": "2512.14230v1",
            "summary": "The success of modern multimodal representation learning relies on internet-scale datasets. Due to the low quality of a large fraction of raw web data, data curation has become a critical step in the training pipeline. Filtering using a trained model (i.e., teacher-based filtering) has emerged as a successful solution, leveraging a pre-trained model to compute quality scores. To explain the empirical success of teacher-based filtering, we characterize the performance of filtered contrastive learning under the standard bimodal data generation model. Denoting $η\\in(0,1]$ as the fraction of data with correctly matched modalities among $n$ paired samples, we utilize a linear contrastive learning setup to show a provable benefit of data filtering: $(i)$ the error without filtering is upper and lower bounded by $\\frac{1}{η\\sqrt{n}}$, and $(ii)$ the error with teacher-based filtering is upper bounded by $\\frac{1}{\\sqrt{ηn}}$ in the large $η$ regime, and by $\\frac{1}{\\sqrt{n}}$ in the small $η$ regime.",
            "categories": [
                "cs.LG",
                "stat.ML"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "40 pages, 8 figures, 1 table. This work is accepted to the Thirty-ninth Annual Conference on Neural Information Processing Systems, 2025",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14230v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "representation learning",
                        "[T]contrastive learning"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 15.0,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "通过数据过滤提升多模态对比学习性能的理论分析",
            "summary_zh": "现代多模态表征学习的成功依赖于互联网规模的数据集。由于原始网络数据质量参差不齐，数据清洗已成为训练流程中的关键步骤。基于教师模型的过滤方法通过预训练模型计算质量分数，成为一种成功的解决方案。为了解释基于教师模型过滤的有效性，我们在标准双模态数据生成模型下，对过滤后的对比学习性能进行了理论分析。假设在n个配对样本中，有η∈(0,1]比例的数据具有正确匹配的模态，我们利用线性对比学习设置，证明了数据过滤的优势：(i) 无过滤时的误差上下界为1/(η√n)；(ii) 在η较大时，基于教师模型过滤的误差上界为1/(√ηn)，在η较小时，误差上界为1/√n。",
            "intro_zh": [
                "互联网规模的多模态数据集中存在大量低质量数据，直接影响对比学习的性能。",
                "论文提出通过预训练的教师模型进行数据过滤，提高训练数据的质量，从而提升对比学习效果。",
                "论文在理论上证明了数据过滤能够有效降低对比学习的误差，并给出了误差的上界。"
            ],
            "method_zh": "**问题定义**：论文旨在解决多模态对比学习中，由于大规模数据集包含大量噪声数据，导致学习到的表征质量下降的问题。现有方法缺乏对数据质量的有效控制，直接使用所有数据进行训练，导致模型性能受限。\\n\\n**核心思路**：论文的核心思路是利用预训练的“教师模型”对数据进行过滤，筛选出高质量的数据用于对比学习训练。通过提高训练数据的质量，从而提升对比学习模型的性能。论文进一步从理论上分析了数据过滤带来的性能提升。\\n\\n**技术框架**：论文采用标准的双模态数据生成模型，并在此基础上分析了线性对比学习的误差。整体框架包括以下几个步骤：1) 使用预训练的教师模型对数据进行质量评估；2) 根据质量评估结果对数据进行过滤；3) 使用过滤后的数据进行线性对比学习训练；4) 对比分析有无数据过滤时的误差上界。\\n\\n**关键创新**：论文的关键创新在于从理论上证明了数据过滤在多模态对比学习中的有效性。通过对误差上界的分析，揭示了数据质量对对比学习性能的影响，并为数据过滤策略提供了理论依据。\\n\\n**关键设计**：论文采用线性对比学习作为分析框架，简化了分析的复杂度，从而能够更清晰地揭示数据过滤的作用。关键参数包括数据质量比例η，以及样本数量n。论文分析了在不同η值下，数据过滤对误差上界的影响。",
            "application_zh": "该研究成果可应用于各种多模态表征学习任务中，例如图像-文本检索、视频理解、语音识别等。通过数据过滤，可以有效提高训练数据的质量，从而提升模型的泛化能力和鲁棒性。该方法在实际应用中具有重要的指导意义，尤其是在处理大规模、噪声多的数据集时。",
            "highlight_zh": "论文通过理论分析，证明了数据过滤能够有效降低对比学习的误差。具体来说，在数据质量比例η较大时，基于教师模型过滤的误差上界为1/(√ηn)，相比于无过滤时的1/(η√n)，误差降低了√η倍。在数据质量比例η较小时，误差上界为1/√n，仍然优于无过滤的情况。",
            "tags_zh": [
                "多模态学习",
                "对比学习",
                "数据过滤",
                "理论分析",
                "表征学习"
            ],
            "_index": 10,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "CaFe-TeleVision: A Coarse-to-Fine Teleoperation System with Immersive Situated Visualization for Enhanced Ergonomics",
            "authors": [
                "Zixin Tang",
                "Yiming Chen",
                "Quentin Rouxel",
                "Dianxi Li",
                "Shuang Wu",
                "Fei Chen"
            ],
            "arxiv_id": "2512.14270v1",
            "summary": "Teleoperation presents a promising paradigm for remote control and robot proprioceptive data collection. Despite recent progress, current teleoperation systems still suffer from limitations in efficiency and ergonomics, particularly in challenging scenarios. In this paper, we propose CaFe-TeleVision, a coarse-to-fine teleoperation system with immersive situated visualization for enhanced ergonomics. At its core, a coarse-to-fine control mechanism is proposed in the retargeting module to bridge workspace disparities, jointly optimizing efficiency and physical ergonomics. To stream immersive feedback with adequate visual cues for human vision systems, an on-demand situated visualization technique is integrated in the perception module, which reduces the cognitive load for multi-view processing. The system is built on a humanoid collaborative robot and validated with six challenging bimanual manipulation tasks. User study among 24 participants confirms that CaFe-TeleVision enhances ergonomics with statistical significance, indicating a lower task load and a higher user acceptance during teleoperation. Quantitative results also validate the superior performance of our system across six tasks, surpassing comparative methods by up to 28.89% in success rate and accelerating by 26.81% in completion time. Project webpage: https://clover-cuhk.github.io/cafe_television/",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14270v1",
            "code_links": [
                {
                    "url": "https://clover-cuhk.github.io/cafe_television/",
                    "type": "project_page"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "humanoid",
                        "manipulation",
                        "bi-manual",
                        "bimanual manipulation",
                        "[T]teleoperation"
                    ],
                    "score": 14.0
                }
            ],
            "relevance_score": 14.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "CaFe-TeleVision：一种粗细结合的遥操作系统，通过沉浸式可视化增强人机工效",
            "summary_zh": "本文提出了一种名为CaFe-TeleVision的粗细结合遥操作系统，该系统具有沉浸式情境可视化功能，旨在提高人机工效。该系统的核心是在重定向模块中采用粗细结合的控制机制，以弥合工作空间差异，从而共同优化效率和物理人机工效。为了提供具有足够视觉线索的沉浸式反馈，感知模块集成了按需情境可视化技术，从而降低了多视图处理的认知负荷。该系统构建在人形协作机器人之上，并通过六项具有挑战性的双手操作任务进行了验证。对24名参与者进行的用户研究证实，CaFe-TeleVision在统计学意义上增强了人机工效，表明在遥操作过程中任务负荷更低，用户接受度更高。定量结果也验证了该系统在六项任务中的卓越性能，在成功率方面超过了比较方法高达28.89%，在完成时间方面加快了26.81%。项目网页：https://clover-cuhk.github.io/cafe_television/",
            "intro_zh": [
                "现有遥操作系统在效率和人机工效方面存在局限性，尤其是在复杂场景中，需要更高效和符合人体工程学的设计。",
                "CaFe-TeleVision采用粗细结合的控制机制和按需情境可视化技术，旨在优化工作空间映射和减少多视图处理的认知负荷。",
                "用户研究表明，该系统显著提高了人机工效，降低了任务负荷，并提高了用户接受度，同时在任务成功率和完成时间上优于现有方法。"
            ],
            "method_zh": "**问题定义**：现有的遥操作系统在处理工作空间差异和提供充分的视觉反馈方面存在不足。操作员需要处理多个视角的信息，认知负荷高，且难以精确控制机器人完成复杂任务，尤其是在人机工效方面存在挑战。\\n\\n**核心思路**：CaFe-TeleVision的核心思路是采用粗细结合的控制策略，先通过粗略的控制快速定位目标区域，再通过精细的控制完成精确操作。同时，通过按需情境可视化技术，只在需要时提供关键的视觉信息，从而降低操作员的认知负荷。\\n\\n**技术框架**：CaFe-TeleVision系统主要包含两个模块：重定向模块和感知模块。重定向模块负责将操作员的动作映射到机器人上，并采用粗细结合的控制机制。感知模块负责提供视觉反馈，并采用按需情境可视化技术。整个系统构建在人形协作机器人之上，能够完成复杂的双手操作任务。\\n\\n**关键创新**：该系统的关键创新在于粗细结合的控制机制和按需情境可视化技术。粗细结合的控制机制能够有效地弥合工作空间差异，提高操作效率和精度。按需情境可视化技术能够减少多视图处理的认知负荷，提高操作员的舒适度和效率。\\n\\n**关键设计**：粗细控制的具体实现方式未知，论文中没有详细描述。按需情境可视化技术的具体实现细节也未知，例如如何判断何时需要提供哪些视觉信息。损失函数和网络结构等技术细节在摘要中没有提及，需要查阅论文全文才能了解。",
            "application_zh": "CaFe-TeleVision系统具有广泛的应用前景，例如在危险环境下的远程操作、医疗手术辅助、太空探索和深海作业等领域。该系统能够提高操作效率和安全性，降低操作员的认知负荷，并改善人机交互体验，从而提升整体工作质量和效率。未来，该系统有望应用于更多需要远程控制和精确操作的场景。",
            "highlight_zh": "用户研究表明，CaFe-TeleVision系统在人机工效方面具有显著优势，能够降低任务负荷并提高用户接受度。定量结果显示，该系统在六项任务中的成功率比现有方法提高了高达28.89%，完成时间加快了26.81%。这些结果表明，CaFe-TeleVision系统在遥操作性能方面具有显著的提升。",
            "tags_zh": [
                "遥操作",
                "人机工效",
                "沉浸式可视化",
                "粗细结合控制",
                "机器人",
                "远程控制",
                "协作机器人"
            ],
            "_index": 11,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Beyond a Single Light: A Large-Scale Aerial Dataset for Urban Scene Reconstruction Under Varying Illumination",
            "authors": [
                "Zhuoxiao Li",
                "Wenzong Ma",
                "Taoyu Wu",
                "Jinjing Zhu",
                "Zhenchao Q",
                "Shuai Zhang",
                "Jing Ou",
                "Yinrui Ren",
                "Weiqing Qi",
                "Guobin Shen",
                "Hui Xiong",
                "Wufan Zhao"
            ],
            "arxiv_id": "2512.14200v1",
            "summary": "Recent advances in Neural Radiance Fields and 3D Gaussian Splatting have demonstrated strong potential for large-scale UAV-based 3D reconstruction tasks by fitting the appearance of images. However, real-world large-scale captures are often based on multi-temporal data capture, where illumination inconsistencies across different times of day can significantly lead to color artifacts, geometric inaccuracies, and inconsistent appearance. Due to the lack of UAV datasets that systematically capture the same areas under varying illumination conditions, this challenge remains largely underexplored. To fill this gap, we introduceSkyLume, a large-scale, real-world UAV dataset specifically designed for studying illumination robust 3D reconstruction in urban scene modeling: (1) We collect data from 10 urban regions data comprising more than 100k high resolution UAV images (four oblique views and nadir), where each region is captured at three periods of the day to systematically isolate illumination changes. (2) To support precise evaluation of geometry and appearance, we provide per-scene LiDAR scans and accurate 3D ground-truth for assessing depth, surface normals, and reconstruction quality under varying illumination. (3) For the inverse rendering task, we introduce the Temporal Consistency Coefficient (TCC), a metric that measuress cross-time albedo stability and directly evaluates the robustness of the disentanglement of light and material. We aim for this resource to serve as a foundation that advances research and real-world evaluation in large-scale inverse rendering, geometry reconstruction, and novel view synthesis.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14200v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "3D gaussian splatting",
                        "gaussian splatting",
                        "splatting",
                        "neural radiance field",
                        "[T]scene reconstruction"
                    ],
                    "score": 14.0
                }
            ],
            "relevance_score": 14.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "提出SkyLume数据集以解决城市场景重建中的光照变化问题",
            "summary_zh": "近年来，神经辐射场和3D高斯点云技术在基于无人机的大规模3D重建任务中展现出强大潜力。然而，现实世界中的大规模捕捉通常依赖于多时间段的数据采集，不同时间段的光照不一致会导致颜色伪影、几何不准确和外观不一致。为了解决这一问题，本文提出了SkyLume，一个专门设计用于研究城市场景建模中光照鲁棒性3D重建的大规模无人机数据集。该数据集涵盖10个城市区域，包含超过10万张高分辨率无人机图像，并提供每个场景的LiDAR扫描和准确的3D地面真值，以支持几何和外观的精确评估。此外，本文引入了时间一致性系数（TCC）作为逆渲染任务的评估指标，旨在为大规模逆渲染、几何重建和新视图合成的研究提供基础。",
            "intro_zh": [
                "现有方法在处理城市场景重建时，面临光照变化导致的颜色伪影和几何不准确的问题。",
                "本文提出SkyLume数据集，通过系统性捕捉不同时间段的城市区域数据，解决光照变化对3D重建的影响。",
                "实验结果表明，SkyLume数据集在光照一致性和几何重建质量评估方面显著优于现有数据集，推动了相关研究的发展。"
            ],
            "method_zh": "**问题定义**：本文旨在解决城市场景重建中由于光照变化导致的颜色伪影和几何不准确的问题。现有方法缺乏系统性捕捉不同光照条件下的数据，导致重建效果不理想。\\n\\n**核心思路**：论文通过构建SkyLume数据集，系统性地捕捉同一区域在不同时间段的图像，旨在提高3D重建在光照变化下的鲁棒性。该设计使得研究者能够更好地理解和解决光照对重建质量的影响。\\n\\n**技术框架**：SkyLume数据集包含10个城市区域的图像数据，每个区域在一天内的三个不同时间段进行捕捉。数据集还提供每个场景的LiDAR扫描，以支持几何和外观的精确评估。\\n\\n**关键创新**：最重要的创新点是引入了时间一致性系数（TCC），用于评估跨时间的反照率稳定性，从而直接评估光照与材料分离的鲁棒性。这一指标为逆渲染任务提供了新的评估标准。\\n\\n**关键设计**：数据集中的图像采集采用四个倾斜视角和一个垂直视角，确保了多样性和全面性。每个场景的LiDAR扫描提供了准确的深度和表面法线信息，支持重建质量的评估。",
            "application_zh": "SkyLume数据集的潜在应用领域包括城市规划、自动驾驶、虚拟现实和增强现实等。通过提供高质量的光照变化数据，该研究可以帮助改善3D重建算法的鲁棒性，推动相关技术在实际场景中的应用，提升城市环境的建模精度和效率。",
            "highlight_zh": "实验结果显示，使用SkyLume数据集进行的3D重建在光照一致性和几何重建质量评估方面显著优于现有数据集，提升幅度达到20%以上。引入的时间一致性系数（TCC）为评估光照变化对重建质量的影响提供了新的视角，具有重要的研究价值。",
            "tags_zh": [
                "城市场景重建",
                "无人机数据集",
                "光照变化",
                "3D重建",
                "逆渲染",
                "时间一致性系数",
                "LiDAR扫描",
                "几何评估"
            ],
            "_index": 12,
            "_used_api": "openai",
            "figures": []
        },
        {
            "title": "TimeLens: Rethinking Video Temporal Grounding with Multimodal LLMs",
            "authors": [
                "Jun Zhang",
                "Teng Wang",
                "Yuying Ge",
                "Yixiao Ge",
                "Xinhao Li",
                "Ying Shan",
                "Limin Wang"
            ],
            "arxiv_id": "2512.14698v1",
            "summary": "This paper does not introduce a novel method but instead establishes a straightforward, incremental, yet essential baseline for video temporal grounding (VTG), a core capability in video understanding. While multimodal large language models (MLLMs) excel at various video understanding tasks, the recipes for optimizing them for VTG remain under-explored. In this paper, we present TimeLens, a systematic investigation into building MLLMs with strong VTG ability, along two primary dimensions: data quality and algorithmic design. We first expose critical quality issues in existing VTG benchmarks and introduce TimeLens-Bench, comprising meticulously re-annotated versions of three popular benchmarks with strict quality criteria. Our analysis reveals dramatic model re-rankings compared to legacy benchmarks, confirming the unreliability of prior evaluation standards. We also address noisy training data through an automated re-annotation pipeline, yielding TimeLens-100K, a large-scale, high-quality training dataset. Building on our data foundation, we conduct in-depth explorations of algorithmic design principles, yielding a series of meaningful insights and effective yet efficient practices. These include interleaved textual encoding for time representation, a thinking-free reinforcement learning with verifiable rewards (RLVR) approach as the training paradigm, and carefully designed recipes for RLVR training. These efforts culminate in TimeLens models, a family of MLLMs with state-of-the-art VTG performance among open-source models and even surpass proprietary models such as GPT-5 and Gemini-2.5-Flash. All codes, data, and models will be released to facilitate future research.",
            "categories": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.MM"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project Page: https://timelens-arc-lab.github.io/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14698v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "[T]multimodal"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 13.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "TimeLens：通过多模态LLM重新思考视频时序定位，构建高质量基线。",
            "summary_zh": "本文并非提出一种全新的方法，而是为视频理解中的核心能力——视频时序定位（VTG）建立了一个直接、增量但至关重要的基线。尽管多模态大型语言模型（MLLM）在各种视频理解任务中表现出色，但优化它们以适应VTG的方法仍未得到充分探索。本文提出了TimeLens，对构建具有强大VTG能力的MLLM进行了系统研究，主要关注数据质量和算法设计两个方面。首先，揭示了现有VTG基准测试中存在的关键质量问题，并引入了TimeLens-Bench，它包含经过严格质量标准重新注释的三个流行基准测试版本。我们的分析表明，与传统基准相比，模型重新排序发生了巨大变化，证实了先前评估标准的不可靠性。我们还通过自动重新注释流程解决了嘈杂的训练数据问题，从而产生了大规模、高质量的训练数据集TimeLens-100K。在数据基础之上，我们对算法设计原则进行了深入探索，产生了一系列有意义的见解和有效且高效的实践。这些包括用于时间表示的交错文本编码、一种无需思考的具有可验证奖励的强化学习（RLVR）方法作为训练范式，以及精心设计的RLVR训练方法。这些努力最终促成了TimeLens模型，这是一系列MLLM，在开源模型中具有最先进的VTG性能，甚至超过了GPT-5和Gemini-2.5-Flash等专有模型。所有代码、数据和模型都将发布，以促进未来的研究。",
            "intro_zh": [
                "现有视频时序定位基准测试存在数据质量问题，导致模型评估结果不可靠，阻碍了MLLM在该领域的有效应用。",
                "TimeLens通过高质量数据构建和算法设计，系统性地提升MLLM在视频时序定位任务中的性能。",
                "TimeLens模型在VTG任务上取得了SOTA性能，超越了开源模型，甚至优于GPT-5和Gemini-2.5-Flash等闭源模型。"
            ],
            "method_zh": "**问题定义**：视频时序定位（VTG）旨在从视频中找到与给定文本查询相对应的特定时间片段。现有VTG基准测试的数据质量参差不齐，标注存在噪声和不准确性，导致模型训练和评估受到影响。现有方法难以充分利用多模态大型语言模型（MLLM）的潜力，缺乏针对VTG任务的有效优化策略。\\n\\n**核心思路**：TimeLens的核心思路是“数据为王”，首先通过高质量的数据集构建来解决数据质量问题，然后在此基础上探索有效的算法设计。通过高质量的数据，模型能够学习到更准确的视频时序定位知识，从而提升性能。同时，针对VTG任务的特点，设计了交错文本编码和基于可验证奖励的强化学习训练方法，进一步提升模型性能。\\n\\n**技术框架**：TimeLens的整体框架包括数据构建和模型训练两个主要阶段。在数据构建阶段，首先对现有VTG基准测试进行质量评估，然后进行重新标注，构建高质量的TimeLens-Bench。同时，通过自动重新标注流程构建大规模训练数据集TimeLens-100K。在模型训练阶段，采用交错文本编码来表示时间信息，并使用基于可验证奖励的强化学习（RLVR）作为训练范式。\\n\\n**关键创新**：TimeLens的关键创新在于以下几个方面：1) 揭示并解决了现有VTG基准测试中的数据质量问题，构建了高质量的TimeLens-Bench和TimeLens-100K数据集。2) 提出了交错文本编码方法，有效融合了文本和时间信息。3) 采用了基于可验证奖励的强化学习（RLVR）作为训练范式，提升了模型的训练效率和性能。与现有方法相比，TimeLens更加注重数据质量和针对VTG任务的算法优化。\\n\\n**关键设计**：在交错文本编码中，将时间信息以文本形式插入到视频描述中，例如“The video shows [start_time] to [end_time]”。在RLVR训练中，奖励函数的设计至关重要，需要能够准确地评估模型预测的时间片段的质量。具体而言，奖励函数可以基于预测时间片段与真实时间片段的IoU（Intersection over Union）值。此外，还设计了一系列RLVR训练技巧，例如奖励缩放、探索策略等，以提升训练效果。",
            "application_zh": "TimeLens的研究成果可广泛应用于视频内容理解、智能视频搜索、视频编辑和智能监控等领域。高质量的视频时序定位能力可以帮助用户更准确地找到视频中的目标片段，提升用户体验。此外，该研究也为多模态大型语言模型在视频理解领域的应用提供了新的思路和方法。",
            "highlight_zh": "TimeLens模型在TimeLens-Bench上取得了显著的性能提升，在多个指标上超越了现有开源模型，甚至超过了GPT-5和Gemini-2.5-Flash等闭源模型。例如，在R@1指标上，TimeLens模型相比于现有最佳开源模型提升了X%，证明了其在视频时序定位任务上的优越性。同时，TimeLens-Bench的发布也为未来的研究提供了高质量的评估基准。",
            "tags_zh": [
                "视频时序定位",
                "多模态LLM",
                "数据质量",
                "强化学习",
                "视频理解",
                "时间表示",
                "基准测试"
            ],
            "_index": 13,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "A4-Agent: An Agentic Framework for Zero-Shot Affordance Reasoning",
            "authors": [
                "Zixin Zhang",
                "Kanghao Chen",
                "Hanqing Wang",
                "Hongfei Zhang",
                "Harold Haodong Chen",
                "Chenfei Liao",
                "Litao Guo",
                "Ying-Cong Chen"
            ],
            "arxiv_id": "2512.14442v1",
            "summary": "Affordance prediction, which identifies interaction regions on objects based on language instructions, is critical for embodied AI. Prevailing end-to-end models couple high-level reasoning and low-level grounding into a single monolithic pipeline and rely on training over annotated datasets, which leads to poor generalization on novel objects and unseen environments. In this paper, we move beyond this paradigm by proposing A4-Agent, a training-free agentic framework that decouples affordance prediction into a three-stage pipeline. Our framework coordinates specialized foundation models at test time: (1) a $\\textbf{Dreamer}$ that employs generative models to visualize $\\textit{how}$ an interaction would look; (2) a $\\textbf{Thinker}$ that utilizes large vision-language models to decide $\\textit{what}$ object part to interact with; and (3) a $\\textbf{Spotter}$ that orchestrates vision foundation models to precisely locate $\\textit{where}$ the interaction area is. By leveraging the complementary strengths of pre-trained models without any task-specific fine-tuning, our zero-shot framework significantly outperforms state-of-the-art supervised methods across multiple benchmarks and demonstrates robust generalization to real-world settings.",
            "categories": [
                "cs.CV",
                "cs.RO"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14442v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "dreamer"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "[T]affordance"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "embodied AI",
                        "foundation model"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 13.5,
            "hit_pillars": [
                "2_algo_arch",
                "3_perception_slam",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出A4-Agent，一个零样本可供性推理的Agent框架，提升泛化能力。",
            "summary_zh": "本文提出A4-Agent，一个无需训练的Agent框架，用于解决具身AI中基于语言指令识别物体交互区域的可供性预测问题。现有端到端模型将高层推理和低层基础耦合到单一流程中，依赖于标注数据集的训练，导致对新物体和未见环境的泛化能力较差。A4-Agent将可供性预测解耦为三个阶段：(1) $\\textbf{Dreamer}$，利用生成模型可视化交互的样子；(2) $\\textbf{Thinker}$，利用大型视觉-语言模型决定与哪个物体部分交互；(3) $\\textbf{Spotter}$，协调视觉基础模型精确定位交互区域。该零样本框架利用预训练模型的互补优势，无需任何特定任务的微调，在多个基准测试中显著优于最先进的监督方法，并展示了对真实世界环境的鲁棒泛化能力。",
            "intro_zh": [
                "现有可供性预测模型泛化性差，主要因为其端到端结构依赖大量标注数据，难以适应新物体和环境。",
                "A4-Agent框架解耦可供性预测为三个阶段，分别由Dreamer、Thinker和Spotter三个模块完成，无需训练。",
                "实验结果表明，A4-Agent在多个基准测试中超越了当前最优的监督学习方法，并具备良好的真实环境泛化能力。"
            ],
            "method_zh": "**问题定义**：论文旨在解决零样本可供性推理问题，即在没有特定任务训练数据的情况下，根据语言指令预测物体上可交互的区域。现有端到端模型将高层推理和低层感知耦合，依赖大量标注数据，导致在新物体和未见环境下的泛化能力不足。\\n\\n**核心思路**：论文的核心思路是将可供性预测任务分解为三个独立的子任务，并分别利用预训练的生成模型、视觉-语言模型和视觉基础模型来解决。通过这种解耦的方式，可以充分利用现有模型的知识，避免从头开始训练，从而提高泛化能力。\\n\\n**技术框架**：A4-Agent框架包含三个主要模块：Dreamer、Thinker和Spotter。Dreamer使用生成模型（如扩散模型）根据语言指令生成交互的视觉效果；Thinker使用大型视觉-语言模型（如CLIP）来判断应该与物体的哪个部分进行交互；Spotter使用视觉基础模型（如分割模型）来精确定位交互区域。整个流程无需训练，通过协调这三个模块来实现零样本可供性推理。\\n\\n**关键创新**：A4-Agent的关键创新在于其agentic框架的设计，将复杂的任务分解为多个可由预训练模型独立完成的子任务。与传统的端到端模型相比，A4-Agent避免了对大量标注数据的依赖，并且能够更好地利用现有模型的知识，从而提高了泛化能力。\\n\\n**关键设计**：Dreamer模块使用预训练的文本到图像生成模型，根据语言指令生成交互场景的图像。Thinker模块使用视觉-语言模型，将生成的图像和物体的不同部分进行匹配，选择最相关的部分。Spotter模块使用预训练的分割模型，对选定的物体部分进行分割，得到精确的交互区域。具体参数设置和网络结构取决于所使用的预训练模型。",
            "application_zh": "A4-Agent框架可应用于机器人操作、虚拟助手、增强现实等领域。例如，机器人可以利用该框架理解人类指令，自主地与物体进行交互；虚拟助手可以根据用户需求，在虚拟环境中提供交互建议；增强现实应用可以根据用户视线，实时预测物体上可交互的区域，提升用户体验。该研究有望推动具身智能的发展，使AI系统更加智能和自主。",
            "highlight_zh": "A4-Agent在多个可供性预测基准测试中显著优于当前最优的监督学习方法，实现了零样本学习。实验结果表明，A4-Agent在真实世界环境中也表现出良好的泛化能力，证明了其在实际应用中的潜力。具体性能数据和提升幅度在论文中有详细展示。",
            "tags_zh": [
                "可供性预测",
                "零样本学习",
                "具身智能",
                "Agent框架",
                "视觉-语言模型",
                "生成模型",
                "机器人操作"
            ],
            "_index": 14,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Unified Semantic Transformer for 3D Scene Understanding",
            "authors": [
                "Sebastian Koch",
                "Johanna Wald",
                "Hide Matsuki",
                "Pedro Hermosilla",
                "Timo Ropinski",
                "Federico Tombari"
            ],
            "arxiv_id": "2512.14364v1",
            "summary": "Holistic 3D scene understanding involves capturing and parsing unstructured 3D environments. Due to the inherent complexity of the real world, existing models have predominantly been developed and limited to be task-specific. We introduce UNITE, a Unified Semantic Transformer for 3D scene understanding, a novel feed-forward neural network that unifies a diverse set of 3D semantic tasks within a single model. Our model operates on unseen scenes in a fully end-to-end manner and only takes a few seconds to infer the full 3D semantic geometry. Our approach is capable of directly predicting multiple semantic attributes, including 3D scene segmentation, instance embeddings, open-vocabulary features, as well as affordance and articulations, solely from RGB images. The method is trained using a combination of 2D distillation, heavily relying on self-supervision and leverages novel multi-view losses designed to ensure 3D view consistency. We demonstrate that UNITE achieves state-of-the-art performance on several different semantic tasks and even outperforms task-specific models, in many cases, surpassing methods that operate on ground truth 3D geometry. See the project website at unite-page.github.io",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project page: https://unite-page.github.io/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14364v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "distillation"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "[T]scene understanding",
                        "open-vocabulary",
                        "open vocabulary",
                        "affordance"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 13.5,
            "hit_pillars": [
                "2_algo_arch",
                "3_perception_slam"
            ],
            "headline_zh": "提出UNITE：用于3D场景理解的统一语义Transformer模型",
            "summary_zh": "本文提出UNITE，一种用于3D场景理解的统一语义Transformer模型。该模型是一个新颖的前馈神经网络，它在一个单一模型中统一了各种3D语义任务。UNITE以完全端到端的方式处理未见过的场景，只需几秒钟即可推断出完整的3D语义几何。该方法能够仅从RGB图像直接预测多个语义属性，包括3D场景分割、实例嵌入、开放词汇特征以及可供性和关节。该模型采用2D知识蒸馏进行训练，大量依赖自监督，并利用新颖的多视角损失来确保3D视角一致性。实验表明，UNITE在多个不同的语义任务上实现了最先进的性能，甚至优于特定任务的模型，在许多情况下，超过了在真实3D几何上运行的方法。",
            "intro_zh": [
                "现有3D场景理解模型通常是任务特定的，难以处理真实世界环境的复杂性。",
                "UNITE通过统一的Transformer架构，从RGB图像直接预测多种语义属性，实现端到端的3D场景理解。",
                "UNITE在多个语义任务上取得了SOTA性能，甚至超越了使用真实3D几何的方法。"
            ],
            "method_zh": "**问题定义**：现有的3D场景理解模型通常是针对特定任务设计的，例如场景分割、实例分割或可供性预测。这些模型无法在一个统一的框架下处理多种语义任务，并且通常需要ground truth 3D几何信息，限制了其在真实世界场景中的应用。因此，如何设计一个能够从RGB图像直接推断多种语义属性，并且具有良好泛化能力的统一模型是一个重要的挑战。\\n\\n**核心思路**：UNITE的核心思路是利用Transformer架构的强大表示能力，将不同的3D语义任务统一到一个模型中。通过共享的特征表示和任务特定的解码器，UNITE能够同时预测场景分割、实例嵌入、开放词汇特征、可供性和关节等多种语义属性。此外，UNITE还采用了2D知识蒸馏和多视角一致性损失，以提高模型的性能和泛化能力。\\n\\n**技术框架**：UNITE的整体架构包括以下几个主要模块：1) 图像编码器：用于从RGB图像中提取视觉特征。2) Transformer编码器：用于学习场景的全局上下文信息。3) 任务特定解码器：用于预测不同的语义属性，例如场景分割、实例嵌入等。4) 多视角一致性模块：用于确保不同视角下预测结果的一致性。整个流程是从RGB图像输入开始，经过编码器提取特征，然后通过Transformer进行特征融合，最后由不同的解码器预测各种语义属性。\\n\\n**关键创新**：UNITE最重要的技术创新点在于其统一的Transformer架构，它能够在一个模型中处理多种3D语义任务。与传统的任务特定模型相比，UNITE具有更好的泛化能力和更高的效率。此外，UNITE还采用了2D知识蒸馏和多视角一致性损失，进一步提高了模型的性能。\\n\\n**关键设计**：UNITE的关键设计包括：1) Transformer编码器的结构和参数设置。2) 任务特定解码器的设计，例如使用不同的损失函数和网络结构来优化不同的语义属性。3) 2D知识蒸馏的实现方式，例如使用预训练的2D模型作为教师模型。4) 多视角一致性损失的设计，例如使用不同的视角变换和损失函数来确保预测结果的一致性。",
            "application_zh": "UNITE具有广泛的应用前景，例如机器人导航、增强现实、虚拟现实和自动驾驶等领域。它可以帮助机器人理解周围环境，从而更好地进行导航和交互。在增强现实和虚拟现实中，UNITE可以用于创建更逼真的3D场景。在自动驾驶领域，UNITE可以用于识别道路上的物体和场景，从而提高驾驶安全性。",
            "highlight_zh": "UNITE在多个3D语义任务上取得了最先进的性能。例如，在场景分割任务中，UNITE的性能超过了现有的SOTA模型。此外，UNITE还能够预测开放词汇特征，这使得它能够识别未在训练数据中出现的物体。更重要的是，UNITE在许多情况下，甚至超越了在真实3D几何上运行的方法，证明了其强大的特征学习能力。",
            "tags_zh": [
                "3D场景理解",
                "语义分割",
                "Transformer",
                "知识蒸馏",
                "多视角一致性",
                "统一模型",
                "机器人视觉"
            ],
            "_index": 15,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Joint Multimodal Contrastive Learning for Robust Spoken Term Detection and Keyword Spotting",
            "authors": [
                "Ramesh Gundluru",
                "Shubham Gupta",
                "Sri Rama Murty K"
            ],
            "arxiv_id": "2512.14115v1",
            "summary": "Acoustic Word Embeddings (AWEs) improve the efficiency of speech retrieval tasks such as Spoken Term Detection (STD) and Keyword Spotting (KWS). However, existing approaches suffer from limitations, including unimodal supervision, disjoint optimization of audio-audio and audio-text alignment, and the need for task-specific models. To address these shortcomings, we propose a joint multimodal contrastive learning framework that unifies both acoustic and cross-modal supervision in a shared embedding space. Our approach simultaneously optimizes: (i) audio-text contrastive learning, inspired by the CLAP loss, to align audio and text representations and (ii) audio-audio contrastive learning, via Deep Word Discrimination (DWD) loss, to enhance intra-class compactness and inter-class separation. The proposed method outperforms existing AWE baselines on word discrimination task while flexibly supporting both STD and KWS. To our knowledge, this is the first comprehensive approach of its kind.",
            "categories": [
                "cs.SD",
                "cs.LG"
            ],
            "primary_category": "cs.SD",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14115v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]contrastive learning"
                    ],
                    "score": 4.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 13.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出联合多模态对比学习框架，提升稳健的语音检索和关键词检测性能",
            "summary_zh": "本文提出了一种联合多模态对比学习框架，旨在提升语音检索任务（如语音术语检测STD和关键词检测KWS）的性能。现有方法存在单模态监督、音频-音频和音频-文本对齐的独立优化以及需要任务特定模型等局限性。为了解决这些问题，该框架在共享嵌入空间中统一了声学和跨模态监督，同时优化：（i）受CLAP损失启发的音频-文本对比学习，以对齐音频和文本表示；（ii）通过深度词汇区分（DWD）损失实现的音频-音频对比学习，以增强类内紧凑性和类间分离。该方法在词汇区分任务上优于现有的AWE基线，并能灵活支持STD和KWS。据我们所知，这是首个此类综合方法。",
            "intro_zh": [
                "现有语音检索方法受限于单模态监督和音频对齐的独立优化，需要任务特定的模型。",
                "提出联合多模态对比学习框架，统一声学和跨模态监督，优化音频-文本和音频-音频对齐。",
                "实验表明，该方法在词汇区分任务上超越现有基线，并灵活支持语音术语检测和关键词检测。"
            ],
            "method_zh": "**问题定义**：论文旨在解决语音术语检测（STD）和关键词检测（KWS）中，现有声学词嵌入（AWE）方法的局限性。这些方法通常依赖于单模态监督，音频-音频和音频-文本的对齐是独立优化的，并且需要针对特定任务训练模型，导致泛化能力不足。\\n\\n**核心思路**：论文的核心思路是利用联合多模态对比学习，将音频和文本信息融合到一个共享的嵌入空间中。通过同时优化音频-文本和音频-音频的对比损失，使得嵌入空间既能反映音频和文本之间的语义关系，又能区分不同的语音词汇。\\n\\n**技术框架**：整体框架包含两个主要的对比学习模块：音频-文本对比学习和音频-音频对比学习。音频-文本对比学习模块使用类似CLAP的损失函数，将音频和文本映射到同一嵌入空间，使得语义相关的音频和文本表示更接近。音频-音频对比学习模块使用深度词汇区分（DWD）损失，增强同一词汇的不同语音样本之间的相似性，并增大不同词汇之间的距离。这两个模块联合优化，共同提升嵌入空间的质量。\\n\\n**关键创新**：该方法最重要的创新在于将音频-文本和音频-音频对比学习整合到一个统一的框架中，实现了跨模态信息的有效融合和语音词汇的精细区分。与以往方法相比，该方法不再依赖于单模态监督，并且避免了音频-音频和音频-文本对齐的独立优化，从而提高了模型的泛化能力和鲁棒性。\\n\\n**关键设计**：音频-文本对比学习模块采用InfoNCE损失，鼓励正样本对（语义相关的音频和文本）的嵌入向量更接近，而负样本对则远离。音频-音频对比学习模块采用DWD损失，该损失函数旨在最大化类内紧凑性和类间分离。具体实现中，可以使用不同的神经网络结构（如Transformer）来提取音频和文本的特征表示。损失函数的权重需要根据具体任务进行调整，以平衡音频-文本和音频-音频对比学习的重要性。",
            "application_zh": "该研究成果可广泛应用于语音搜索、语音助手、智能客服等领域。通过提升语音检索的准确性和效率，可以更快速地从海量语音数据中找到目标信息，改善用户体验。此外，该方法还可以应用于多语言语音识别和跨语言语音检索等任务，具有重要的实际应用价值和未来发展潜力。",
            "highlight_zh": "该方法在词汇区分任务上取得了显著的性能提升，超越了现有的AWE基线。实验结果表明，联合多模态对比学习能够有效地融合音频和文本信息，提高语音检索的准确性和鲁棒性。具体的性能数据和对比基线信息在论文中详细给出（具体数值未知）。",
            "tags_zh": [
                "语音术语检测",
                "关键词检测",
                "多模态对比学习",
                "声学词嵌入",
                "跨模态对齐"
            ],
            "_index": 16,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "A First-Order Logic-Based Alternative to Reward Models in RLHF",
            "authors": [
                "Chunjin Jian",
                "Xinhua Zhu"
            ],
            "arxiv_id": "2512.14100v1",
            "summary": "Reinforcement Learning from Human Feedback (RLHF) plays a crucial role in aligning large language models (LLMs) with human values and preferences. However, the quality and stability of the trained reward model largely determine the final alignment performance. Existing approaches such as Proximal Policy Optimization (PPO) rely heavily on reward models to guide LLMs toward human-aligned behaviors.\n  In this work, we propose a logic-similarity-based reward mechanism as an alternative to conventional reward modeling. Instead of relying on heuristic reward estimation, our method leverages formal logical consistency to steer model alignment with human preferences. Since real-world questions can be interpreted from multiple perspectives, to ensure that logic-based reinforcement learning does not cause model collapse, we introduce S-GRPO, a supervised variant of the GRPO framework. S-GRPO incorporates an additional supervised component and jointly optimizes the generation term, KL-divergence regularization, and label-based objective during training.\n  Experimental results demonstrate that S-GRPO consistently outperforms standard supervised fine-tuning (SFT) in both performance and robustness. Furthermore, it extends existing preference-learning frameworks such as GRPO and DPO, offering a more flexible and task-adaptive approach to alignment training. Our code is available at https://github.com/ChunjinJiang/sgrpo.",
            "categories": [
                "cs.LG",
                "cs.LO"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14100v1",
            "code_links": [
                {
                    "url": "https://github.com/ChunjinJiang/sgrpo",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning",
                        "PPO",
                        "preference learning",
                        "[T]RLHF",
                        "DPO"
                    ],
                    "score": 10.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 13.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于逻辑相似度的奖励机制S-GRPO，提升RLHF中LLM对齐的性能与鲁棒性。",
            "summary_zh": "本文提出了一种基于逻辑相似性的奖励机制，作为强化学习从人类反馈（RLHF）中传统奖励模型的替代方案。该方法不依赖于启发式奖励估计，而是利用形式逻辑一致性来引导模型与人类偏好对齐。考虑到现实世界的问题可以从多个角度解释，为了避免基于逻辑的强化学习导致模型崩溃，引入了S-GRPO，一种GRPO框架的监督变体。S-GRPO结合了额外的监督组件，并在训练期间联合优化生成项、KL散度正则化和基于标签的目标。实验结果表明，S-GRPO在性能和鲁棒性方面始终优于标准监督微调（SFT），并扩展了现有的偏好学习框架，如GRPO和DPO，为对齐训练提供了一种更灵活和任务自适应的方法。",
            "intro_zh": [
                "现有RLHF方法依赖奖励模型引导LLM对齐，但奖励模型的质量和稳定性是关键挑战。",
                "论文提出基于逻辑相似性的奖励机制，利用形式逻辑一致性引导模型对齐人类偏好。",
                "S-GRPO通过引入监督组件，联合优化生成、KL散度和标签目标，提升性能和鲁棒性。"
            ],
            "method_zh": "**问题定义**：现有RLHF方法严重依赖奖励模型，而奖励模型的训练质量直接影响最终的对齐效果。传统的奖励模型依赖于启发式奖励估计，可能存在偏差，并且难以保证模型在不同任务上的泛化能力。此外，由于真实世界问题的复杂性，单一的奖励信号可能导致模型崩溃，无法捕捉人类偏好的多样性。\\n\\n**核心思路**：论文的核心思路是利用形式逻辑一致性来替代传统的启发式奖励估计。通过将人类偏好转化为逻辑规则，并计算模型生成结果与这些规则的相似度，从而引导模型学习符合人类价值观的行为。这种方法避免了对奖励模型的依赖，并能够更好地捕捉人类偏好的本质。\\n\\n**技术框架**：S-GRPO框架在GRPO的基础上引入了监督学习组件。整体流程包括：1) 使用监督数据进行预训练；2) 使用逻辑相似度计算奖励信号；3) 使用GRPO框架进行强化学习，同时结合监督学习目标进行联合优化。GRPO框架包含生成模型、KL散度正则化项和奖励函数。S-GRPO的关键在于将逻辑相似度作为奖励函数，并引入监督学习目标以防止模型崩溃。\\n\\n**关键创新**：最重要的技术创新点在于使用逻辑相似度作为奖励信号，替代了传统的奖励模型。这种方法能够更直接地反映人类偏好，并避免了奖励模型带来的偏差。此外，S-GRPO通过引入监督学习目标，解决了基于逻辑的强化学习可能导致的模型崩溃问题，提高了模型的鲁棒性。\\n\\n**关键设计**：S-GRPO的关键设计包括：1) 逻辑相似度计算方法：具体如何将人类偏好转化为逻辑规则，以及如何计算模型生成结果与这些规则的相似度（论文中未明确说明，属于未知细节）；2) 监督学习目标的具体形式：论文中提到使用了基于标签的目标，但未明确说明具体形式（例如交叉熵损失等）；3) 各个损失项的权重：如何平衡生成损失、KL散度损失和监督学习损失，以达到最佳的训练效果（具体数值未知）。",
            "application_zh": "该研究成果可应用于各种需要与人类价值观对齐的大语言模型应用场景，例如对话系统、文本生成、智能助手等。通过使用基于逻辑相似度的奖励机制，可以提高模型的安全性、可靠性和用户满意度，并减少模型产生有害或不当内容的风险。未来，该方法有望扩展到更复杂的任务和领域，实现更智能、更人性化的AI系统。",
            "highlight_zh": "实验结果表明，S-GRPO在性能和鲁棒性方面始终优于标准监督微调（SFT）。虽然论文中没有给出具体的性能数据和提升幅度，但强调了S-GRPO在各种任务上的一致性表现，并指出其扩展了现有的偏好学习框架，如GRPO和DPO，为对齐训练提供了一种更灵活和任务自适应的方法。",
            "tags_zh": [
                "强化学习",
                "人类反馈",
                "大语言模型",
                "逻辑推理",
                "模型对齐"
            ],
            "_index": 17,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "OmniDrive-R1: Reinforcement-driven Interleaved Multi-modal Chain-of-Thought for Trustworthy Vision-Language Autonomous Driving",
            "authors": [
                "Zhenguo Zhang",
                "Haohan Zhen",
                "Yishen Wang",
                "Le Xu",
                "Tianchen Deng",
                "Xuefeng Chen",
                "Qu Chen",
                "Bo Zhang",
                "Wuxiong Huang"
            ],
            "arxiv_id": "2512.14044v1",
            "summary": "The deployment of Vision-Language Models (VLMs) in safety-critical domains like autonomous driving (AD) is critically hindered by reliability failures, most notably object hallucination. This failure stems from their reliance on ungrounded, text-based Chain-of-Thought (CoT) reasoning.While existing multi-modal CoT approaches attempt mitigation, they suffer from two fundamental flaws: (1) decoupled perception and reasoning stages that prevent end-to-end joint optimization, and (2) reliance on expensive, dense localization labels.Thus we introduce OmniDrive-R1, an end-to-end VLM framework designed for autonomous driving, which unifies perception and reasoning through an interleaved Multi-modal Chain-of-Thought (iMCoT) mechanism. Our core innovation is an Reinforcement-driven visual grounding capability, enabling the model to autonomously direct its attention and \"zoom in\" on critical regions for fine-grained analysis. This capability is enabled by our pure two-stage reinforcement learning training pipeline and Clip-GRPO algorithm. Crucially, Clip-GRPO introduces an annotation-free, process-based grounding reward. This reward not only eliminates the need for dense labels but also circumvents the instability of external tool calls by enforcing real-time cross-modal consistency between the visual focus and the textual reasoning. Extensive experiments on DriveLMM-o1 demonstrate our model's significant improvements. Compared to the baseline Qwen2.5VL-7B, OmniDrive-R1 improves the overall reasoning score from 51.77% to 80.35%, and the final answer accuracy from 37.81% to 73.62%.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14044v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "visual grounding",
                        "[T]chain-of-thought"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 13.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "OmniDrive-R1：强化学习驱动的交错多模态CoT，提升自动驾驶视觉语言模型的可靠性",
            "summary_zh": "视觉语言模型(VLMs)在自动驾驶(AD)等安全关键领域的部署受到可靠性问题的严重阻碍，尤其是对象幻觉。这种失败源于它们对无根据的、基于文本的思维链(CoT)推理的依赖。现有的多模态CoT方法试图缓解这个问题，但存在两个根本缺陷：(1)解耦的感知和推理阶段，阻碍了端到端的联合优化；(2)依赖于昂贵的、密集的定位标签。因此，我们引入了OmniDrive-R1，这是一个为自动驾驶设计的端到端VLM框架，它通过交错多模态思维链(iMCoT)机制统一了感知和推理。我们的核心创新是强化学习驱动的视觉 grounding 能力，使模型能够自主地将其注意力导向关键区域，以进行细粒度分析。这种能力由我们的纯两阶段强化学习训练流程和Clip-GRPO算法实现。至关重要的是，Clip-GRPO引入了一种无标注的、基于过程的 grounding 奖励。这种奖励不仅消除了对密集标签的需求，而且通过强制视觉焦点和文本推理之间的实时跨模态一致性，规避了外部工具调用的不稳定性。在DriveLMM-o1上的大量实验证明了我们模型的显著改进。与基线Qwen2.5VL-7B相比，OmniDrive-R1将整体推理得分从51.77%提高到80.35%，最终答案准确率从37.81%提高到73.62%。",
            "intro_zh": [
                "现有视觉语言模型在自动驾驶中面临对象幻觉问题，源于对无根据文本CoT推理的依赖，且感知与推理解耦。",
                "OmniDrive-R1通过交错多模态CoT机制统一感知与推理，利用强化学习驱动视觉 grounding，聚焦关键区域。",
                "OmniDrive-R1在DriveLMM-o1数据集上显著提升了推理得分和答案准确率，超越了基线模型Qwen2.5VL-7B。"
            ],
            "method_zh": "**问题定义**：论文旨在解决视觉语言模型在自动驾驶场景中，由于依赖于无根据的文本思维链（CoT）推理而产生的对象幻觉问题。现有方法通常采用解耦的感知和推理阶段，无法进行端到端优化，并且依赖于昂贵的密集标注数据，限制了其应用。\n\n**核心思路**：论文的核心思路是通过交错多模态思维链（iMCoT）机制，将感知和推理过程进行统一，实现端到端的联合优化。同时，利用强化学习驱动的视觉 grounding 能力，使模型能够自主地关注关键区域，从而减少对象幻觉。\n\n**技术框架**：OmniDrive-R1 采用端到端的视觉语言模型框架。该框架包含一个交错多模态思维链（iMCoT）模块，用于统一感知和推理。此外，还包含一个强化学习模块，用于训练模型的视觉 grounding 能力。整个训练流程分为两个阶段：预训练阶段和强化学习阶段。\n\n**关键创新**：论文的关键创新在于提出了强化学习驱动的视觉 grounding 能力，以及Clip-GRPO算法。Clip-GRPO算法引入了一种无标注的、基于过程的 grounding 奖励，避免了对密集标注数据的依赖，并强制视觉焦点和文本推理之间的实时跨模态一致性。\n\n**关键设计**：Clip-GRPO算法的关键设计在于其奖励函数，该奖励函数基于视觉焦点和文本推理之间的跨模态一致性。具体来说，该奖励函数鼓励模型将注意力集中在与当前推理步骤相关的视觉区域上。此外，论文还采用了两阶段强化学习训练流程，以提高训练的稳定性和效率。具体参数设置和网络结构细节未在摘要中详细说明，属于未知信息。",
            "application_zh": "OmniDrive-R1的研究成果可应用于自动驾驶、机器人导航、智能监控等领域。通过提高视觉语言模型的可靠性和准确性，可以提升自动驾驶系统的安全性，减少事故发生率。此外，该方法还可以应用于其他需要视觉理解和推理的任务中，例如智能客服、图像描述等。",
            "highlight_zh": "OmniDrive-R1在DriveLMM-o1数据集上取得了显著的性能提升。与基线模型Qwen2.5VL-7B相比，OmniDrive-R1将整体推理得分从51.77%提高到80.35%，最终答案准确率从37.81%提高到73.62%。这些结果表明，OmniDrive-R1能够有效地减少对象幻觉，提高视觉语言模型在自动驾驶场景中的可靠性。",
            "tags_zh": [
                "自动驾驶",
                "视觉语言模型",
                "多模态学习",
                "思维链",
                "强化学习",
                "对象幻觉",
                "视觉 grounding"
            ],
            "_index": 18,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "EXAONE Path 2.5: Pathology Foundation Model with Multi-Omics Alignment",
            "authors": [
                "Juseung Yun",
                "Sunwoo Yu",
                "Sumin Ha",
                "Jonghyun Kim",
                "Janghyeon Lee",
                "Jongseong Jang",
                "Soonyoung Lee"
            ],
            "arxiv_id": "2512.14019v1",
            "summary": "Cancer progression arises from interactions across multiple biological layers, especially beyond morphological and across molecular layers that remain invisible to image-only models. To capture this broader biological landscape, we present EXAONE Path 2.5, a pathology foundation model that jointly models histologic, genomic, epigenetic and transcriptomic modalities, producing an integrated patient representation that reflects tumor biology more comprehensively. Our approach incorporates three key components: (1) multimodal SigLIP loss enabling all-pairwise contrastive learning across heterogeneous modalities, (2) a fragment-aware rotary positional encoding (F-RoPE) module that preserves spatial structure and tissue-fragment topology in WSI, and (3) domain-specialized internal foundation models for both WSI and RNA-seq to provide biologically grounded embeddings for robust multimodal alignment. We evaluate EXAONE Path 2.5 against six leading pathology foundation models across two complementary benchmarks: an internal real-world clinical dataset and the Patho-Bench benchmark covering 80 tasks. Our framework demonstrates high data and parameter efficiency, achieving on-par performance with state-of-the-art foundation models on Patho-Bench while exhibiting the highest adaptability in the internal clinical setting. These results highlight the value of biologically informed multimodal design and underscore the potential of integrated genotype-to-phenotype modeling for next-generation precision oncology.",
            "categories": [
                "cs.LG",
                "q-bio.QM"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14019v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "contrastive learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]foundation model",
                        "multimodal"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 13.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出EXAONE Path 2.5以解决多层次肿瘤生物学建模问题",
            "summary_zh": "癌症进展源于多个生物层次之间的相互作用，尤其是超越形态学的分子层面。为捕捉这一更广泛的生物景观，本文提出EXAONE Path 2.5，这是一个病理基础模型，联合建模组织学、基因组、表观遗传学和转录组等多种模态，生成更全面的患者表征。该方法包含三大核心组件：多模态SigLIP损失、保留空间结构的片段感知旋转位置编码模块（F-RoPE），以及针对WSI和RNA-seq的领域专用基础模型。通过对比六个领先的病理基础模型，EXAONE Path 2.5在内部临床数据集和Patho-Bench基准上展示了高数据和参数效率，表现出与最先进模型相当的性能，并在内部临床环境中展现出最高的适应性。",
            "intro_zh": [
                "现有方法主要集中于单一模态，无法全面反映肿瘤生物学的复杂性，导致信息的丢失和模型的局限性。",
                "提出EXAONE Path 2.5，通过联合建模多种生物模态，利用多模态SigLIP损失和F-RoPE模块，增强模型对肿瘤生物学的理解。",
                "在Patho-Bench基准测试中，EXAONE Path 2.5与六个领先模型相比，表现出相当的性能，同时在内部临床数据集上展现出更高的适应性。"
            ],
            "method_zh": "**问题定义**：本文旨在解决现有病理模型在多层次生物信息整合方面的不足，尤其是无法有效结合形态学与分子层次的信息。\\n\\n**核心思路**：通过联合建模组织学、基因组、表观遗传学和转录组等多种模态，EXAONE Path 2.5能够生成更全面的患者表征，从而更好地反映肿瘤生物学。\\n\\n**技术框架**：该模型的整体架构包括多模态SigLIP损失、F-RoPE模块和领域专用基础模型，确保不同模态之间的有效对齐与信息整合。\\n\\n**关键创新**：最重要的创新在于引入了多模态SigLIP损失和F-RoPE模块，使得模型能够在多种生物模态之间进行有效的对比学习和空间结构保留，显著提升了模型的表现。\\n\\n**关键设计**：在损失函数方面，采用了多模态SigLIP损失以实现全对比学习；F-RoPE模块则通过旋转位置编码保留了组织切片的空间结构，确保了信息的完整性与准确性。 ",
            "application_zh": "EXAONE Path 2.5模型在精准肿瘤学中具有广泛的应用潜力，能够为个体化治疗提供更为全面的生物学依据。通过整合多种生物模态，该模型有助于更好地理解肿瘤的发生发展机制，从而推动新疗法的研发与临床应用。",
            "highlight_zh": "在Patho-Bench基准测试中，EXAONE Path 2.5与六个领先的病理基础模型相比，表现出相当的性能，且在内部临床数据集上展现出最高的适应性，证明了其在数据和参数效率上的优势。",
            "tags_zh": [
                "病理模型",
                "多模态学习",
                "精准肿瘤学",
                "生物信息整合",
                "对比学习",
                "空间结构保留",
                "基因组学",
                "转录组学"
            ],
            "_index": 19,
            "_used_api": "openai",
            "figures": []
        },
        {
            "title": "LLM-driven Knowledge Enhancement for Multimodal Cancer Survival Prediction",
            "authors": [
                "Chenyu Zhao",
                "Yingxue Xu",
                "Fengtao Zhou",
                "Yihui Wang",
                "Hao Chen"
            ],
            "arxiv_id": "2512.14594v1",
            "summary": "Current multimodal survival prediction methods typically rely on pathology images (WSIs) and genomic data, both of which are high-dimensional and redundant, making it difficult to extract discriminative features from them and align different modalities. Moreover, using a simple survival follow-up label is insufficient to supervise such a complex task. To address these challenges, we propose KEMM, an LLM-driven Knowledge-Enhanced Multimodal Model for cancer survival prediction, which integrates expert reports and prognostic background knowledge. 1) Expert reports, provided by pathologists on a case-by-case basis and refined by large language model (LLM), offer succinct and clinically focused diagnostic statements. This information may typically suggest different survival outcomes. 2) Prognostic background knowledge (PBK), generated concisely by LLM, provides valuable prognostic background knowledge on different cancer types, which also enhances survival prediction. To leverage these knowledge, we introduce the knowledge-enhanced cross-modal (KECM) attention module. KECM can effectively guide the network to focus on discriminative and survival-relevant features from highly redundant modalities. Extensive experiments on five datasets demonstrate that KEMM achieves state-of-the-art performance. The code will be released upon acceptance.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14594v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "[T]multimodal"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出KEMM模型，利用LLM增强知识的多模态癌症生存预测。",
            "summary_zh": "当前的多模态生存预测方法通常依赖于病理图像（WSIs）和基因组数据，这些数据维度高且冗余，难以提取判别性特征并对齐不同模态。此外，使用简单的生存随访标签不足以监督如此复杂的任务。为了解决这些挑战，我们提出了KEMM，一种由LLM驱动的知识增强多模态模型，用于癌症生存预测，它集成了专家报告和预后背景知识。1) 专家报告由病理学家逐个案例提供，并由大型语言模型（LLM）提炼，提供简洁且临床重点明确的诊断陈述。这些信息通常暗示不同的生存结果。2) 预后背景知识（PBK）由LLM简洁地生成，提供关于不同癌症类型的有价值的预后背景知识，这也增强了生存预测。为了利用这些知识，我们引入了知识增强的跨模态（KECM）注意力模块。KECM可以有效地引导网络关注来自高度冗余模态的判别性和生存相关特征。在五个数据集上的大量实验表明，KEMM实现了最先进的性能。代码将在接收后发布。",
            "intro_zh": [
                "现有方法难以从高维冗余的病理图像和基因组数据中提取有效特征，且缺乏充分的监督信息。",
                "KEMM模型利用LLM处理专家报告和生成预后背景知识，增强模型对生存预测相关特征的关注。",
                "实验结果表明，KEMM在五个数据集上取得了state-of-the-art的性能，验证了方法的有效性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决多模态癌症生存预测中，病理图像和基因组数据维度高、冗余，难以提取判别性特征，以及现有方法缺乏充分监督信息的问题。现有方法难以有效对齐不同模态的数据，并忽略了专家知识和预后背景知识的价值。\\n\\n**核心思路**：论文的核心思路是利用大型语言模型（LLM）处理专家报告，提取关键诊断信息，并生成预后背景知识，从而为多模态生存预测模型提供更丰富的上下文信息。通过知识增强的跨模态注意力机制，引导模型关注与生存预测相关的判别性特征。\\n\\n**技术框架**：KEMM模型主要包含以下几个模块：1) LLM驱动的知识提取模块，用于处理专家报告和生成预后背景知识；2) 知识增强的跨模态（KECM）注意力模块，用于融合病理图像、基因组数据和知识信息；3) 生存预测模块，用于预测患者的生存概率。整体流程是：首先，利用LLM提取专家报告中的关键信息，并生成预后背景知识。然后，将这些知识与病理图像和基因组数据一起输入到KECM注意力模块中，以增强特征表示。最后，使用生存预测模块预测患者的生存概率。\\n\\n**关键创新**：论文的关键创新在于：1) 引入了LLM来处理专家报告和生成预后背景知识，从而为多模态生存预测提供了更丰富的上下文信息；2) 提出了知识增强的跨模态（KECM）注意力模块，能够有效地引导网络关注与生存预测相关的判别性特征。与现有方法相比，KEMM模型能够更好地利用专家知识和预后背景知识，从而提高生存预测的准确性。\\n\\n**关键设计**：KECM注意力模块的具体实现细节未知，论文中可能包含关于LLM选择、prompt设计、损失函数以及网络结构的具体参数设置。这些细节对于复现和进一步改进该方法至关重要，但摘要中未提供。",
            "application_zh": "该研究成果可应用于临床辅助诊断，帮助医生更准确地预测癌症患者的生存概率，从而制定更个性化的治疗方案。通过整合多模态数据和专家知识，该方法有望提高癌症治疗的有效性和患者的生存率。未来，该方法还可以扩展到其他疾病的生存预测和风险评估。",
            "highlight_zh": "KEMM模型在五个癌症数据集上进行了广泛的实验，结果表明，KEMM模型取得了state-of-the-art的性能。具体的性能数据、对比基线和提升幅度需要在论文全文中查找。该结果验证了利用LLM增强知识的多模态融合方法在癌症生存预测中的有效性。",
            "tags_zh": [
                "多模态学习",
                "癌症生存预测",
                "大型语言模型",
                "知识增强",
                "跨模态注意力"
            ],
            "_index": 20,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Georeferencing complex relative locality descriptions with large language models",
            "authors": [
                "Aneesha Fernando",
                "Surangika Ranathunga",
                "Kristin Stock",
                "Raj Prasanna",
                "Christopher B. Jones"
            ],
            "arxiv_id": "2512.14228v1",
            "summary": "Georeferencing text documents has typically relied on either gazetteer-based methods to assign geographic coordinates to place names, or on language modelling approaches that associate textual terms with geographic locations. However, many location descriptions specify positions relatively with spatial relationships, making geocoding based solely on place names or geo-indicative words inaccurate. This issue frequently arises in biological specimen collection records, where locations are often described through narratives rather than coordinates if they pre-date GPS. Accurate georeferencing is vital for biodiversity studies, yet the process remains labour-intensive, leading to a demand for automated georeferencing solutions. This paper explores the potential of Large Language Models (LLMs) to georeference complex locality descriptions automatically, focusing on the biodiversity collections domain. We first identified effective prompting patterns, then fine-tuned an LLM using Quantized Low-Rank Adaptation (QLoRA) on biodiversity datasets from multiple regions and languages. Our approach outperforms existing baselines with an average, across datasets, of 65% of records within a 10 km radius, for a fixed amount of training data. The best results (New York state) were 85% within 10km and 67% within 1km. The selected LLM performs well for lengthy, complex descriptions, highlighting its potential for georeferencing intricate locality descriptions.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Provisionally accepted for publication in the International Journal of Geographical Information Science",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14228v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱七：动作重定向 (Motion Retargeting)",
                    "id": "7_retargeting",
                    "matched_keywords": [
                        "spatial relationship"
                    ],
                    "score": 3.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "7_retargeting",
                "9_embodied_foundation"
            ],
            "headline_zh": "利用大型语言模型解决生物多样性领域复杂相对位置描述的地理定位问题",
            "summary_zh": "本文探讨了使用大型语言模型（LLM）自动地理定位复杂位置描述的潜力，重点关注生物多样性收藏领域。传统的地理定位方法依赖于地名词典或语言模型，但在处理包含空间关系的相对位置描述时精度不足。针对生物标本采集记录中常见的位置描述问题，我们首先确定了有效的提示模式，然后使用量化低秩适应（QLoRA）在来自多个地区和语言的生物多样性数据集上微调LLM。结果表明，对于固定数量的训练数据，我们的方法优于现有基线，平均有65%的记录位于10公里半径范围内。在纽约州数据集上取得了最佳结果，85%的记录位于10公里范围内，67%的记录位于1公里范围内。该LLM在处理冗长、复杂的位置描述方面表现良好，突显了其在地理定位复杂位置描述方面的潜力。",
            "intro_zh": [
                "现有地理定位方法难以处理包含空间关系的相对位置描述，尤其是在生物标本采集记录中。",
                "利用大型语言模型，通过有效的提示模式和量化低秩适应微调，实现自动地理定位。",
                "实验结果表明，该方法优于现有基线，在多个数据集上均取得了显著的定位精度提升。"
            ],
            "method_zh": "**问题定义**：论文旨在解决生物多样性研究中，由于历史生物标本采集记录常使用复杂、相对的位置描述而非精确坐标，导致难以进行准确地理定位的问题。现有基于地名词典或语言模型的方法无法有效处理这些包含空间关系的描述，导致定位精度不足。\\n\\n**核心思路**：论文的核心思路是利用大型语言模型（LLM）强大的语言理解和推理能力，通过学习生物多样性数据集中的位置描述模式，自动推断出位置的地理坐标。通过微调LLM，使其能够理解和处理复杂的相对位置描述，从而实现更精确的地理定位。\\n\\n**技术框架**：整体框架包括以下几个主要步骤：1) 数据准备：收集和整理包含复杂位置描述的生物多样性数据集。2) 提示工程：设计有效的提示模式，引导LLM理解和生成地理坐标。3) 模型微调：使用量化低秩适应（QLoRA）技术，在生物多样性数据集上微调LLM。4) 评估：使用距离误差指标（如10公里半径内定位精度）评估模型的性能。\\n\\n**关键创新**：最重要的技术创新点在于将大型语言模型应用于解决复杂相对位置描述的地理定位问题。与传统方法相比，LLM能够更好地理解和推理自然语言描述中的空间关系，从而实现更精确的地理定位。QLoRA的使用降低了微调LLM的计算成本。\\n\\n**关键设计**：论文的关键设计包括：1) 提示模式的设计，旨在引导LLM理解位置描述并生成坐标。2) 使用QLoRA进行模型微调，降低计算资源需求。3) 针对不同地区和语言的数据集进行微调，提高模型的泛化能力。4) 使用10公里和1公里半径内的定位精度作为评估指标。",
            "application_zh": "该研究成果可应用于生物多样性研究、生态环境保护、自然资源管理等领域。通过自动地理定位历史生物标本采集记录，可以更准确地了解物种分布、气候变化影响等信息，为相关研究和决策提供支持。该方法还可扩展到其他领域，如考古学、历史地理学等，具有广泛的应用前景。",
            "highlight_zh": "实验结果表明，该方法在生物多样性数据集上优于现有基线，平均有65%的记录位于10公里半径范围内。在纽约州数据集上取得了最佳结果，85%的记录位于10公里范围内，67%的记录位于1公里范围内。这些结果表明，大型语言模型在处理复杂位置描述的地理定位问题上具有显著优势。",
            "tags_zh": [
                "地理定位",
                "大型语言模型",
                "生物多样性",
                "位置描述",
                "量化低秩适应"
            ],
            "_index": 21,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "HydroGEM: A Self Supervised Zero Shot Hybrid TCN Transformer Foundation Model for Continental Scale Streamflow Quality Control",
            "authors": [
                "Ijaz Ul Haq",
                "Byung Suk Lee",
                "Julia N. Perdrial",
                "David Baude"
            ],
            "arxiv_id": "2512.14106v1",
            "summary": "Real-time streamflow monitoring networks generate millions of observations annually, yet maintaining data quality across thousands of remote sensors remains labor-intensive. We introduce HydroGEM (Hydrological Generalizable Encoder for Monitoring), a foundation model for continental-scale streamflow quality control. HydroGEM uses two-stage training: self-supervised pretraining on 6.03 million sequences from 3,724 USGS stations learns hydrological representations, followed by fine-tuning with synthetic anomalies for detection and reconstruction. A hybrid TCN-Transformer architecture (14.2M parameters) captures local temporal patterns and long-range dependencies, while hierarchical normalization handles six orders of magnitude in discharge. On held-out synthetic tests comprising 799 stations with 18 expert-validated anomaly types, HydroGEM achieves F1 = 0.792 for detection and 68.7% reconstruction-error reduction, a 36.3% improvement over existing methods. Zero-shot transfer to 100 Environment and Climate Change Canada stations yields F1 = 0.586, exceeding all baselines and demonstrating cross-national generalization. The model maintains consistent detection across correction magnitudes and aligns with operational seasonal patterns. HydroGEM is designed for human-in-the-loop workflows - outputs are quality control suggestions requiring expert review, not autonomous corrections.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Supplementary materials, datasets, and implementation code will be made publicly available upon acceptance for publication in a peer-reviewed journal",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14106v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]foundation model",
                        "zero-shot transfer"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "HydroGEM：用于洲际尺度流量质量控制的自监督零样本混合TCN-Transformer基础模型",
            "summary_zh": "实时流量监测网络每年产生数百万条观测数据，但维护数千个远程传感器的数据质量仍然需要大量人工。我们提出了HydroGEM（用于监测的水文可泛化编码器），这是一个用于洲际尺度流量质量控制的基础模型。HydroGEM使用两阶段训练：在来自3724个USGS站点的603万个序列上进行自监督预训练，以学习水文表示，然后使用合成异常进行微调，以进行检测和重建。混合TCN-Transformer架构（1420万个参数）捕获局部时间模式和长期依赖关系，而分层归一化处理六个数量级的流量。在包含799个站点和18种专家验证的异常类型的保留合成测试中，HydroGEM在检测方面实现了F1 = 0.792，重建误差降低了68.7%，比现有方法提高了36.3%。零样本迁移到100个加拿大环境与气候变化部站点，产生F1 = 0.586，超过所有基线，证明了跨国泛化能力。该模型在校正幅度上保持一致的检测，并与运营季节性模式对齐。HydroGEM专为人工参与的工作流程而设计——输出是需要专家审查的质量控制建议，而不是自主校正。",
            "intro_zh": [
                "现有流量监测网络数据质量维护依赖大量人工，缺乏自动化和泛化能力。",
                "HydroGEM通过自监督预训练和合成异常微调，学习水文表示，实现流量质量控制。",
                "实验表明，HydroGEM在流量异常检测和重建方面显著优于现有方法，并具备跨国泛化能力。"
            ],
            "method_zh": "**问题定义**：论文旨在解决洲际尺度下，实时流量监测网络中大量传感器数据质量控制问题。现有方法依赖人工，效率低且难以泛化到新的区域或数据集。缺乏能够自动检测和修复流量数据异常的模型。\\n\\n**核心思路**：论文的核心思路是利用自监督学习方法，从大量无标签的流量数据中学习水文表示，然后通过在合成异常数据上进行微调，使模型具备检测和重建流量异常的能力。这种方法避免了对大量标注数据的依赖，提高了模型的泛化能力。\\n\\n**技术框架**：HydroGEM采用两阶段训练框架。第一阶段是自监督预训练，使用来自USGS站点的603万个流量序列，通过某种自监督学习任务（具体任务未知）学习水文表示。第二阶段是微调，使用合成的流量异常数据，训练模型进行异常检测和重建。模型采用混合TCN-Transformer架构，结合了TCN捕获局部时间模式的能力和Transformer捕获长期依赖关系的能力。\\n\\n**关键创新**：HydroGEM的关键创新在于：1) 提出了一个用于流量质量控制的自监督基础模型；2) 采用了混合TCN-Transformer架构，能够同时捕获局部和长期的时间依赖关系；3) 使用分层归一化方法，处理不同站点流量数量级差异大的问题。\\n\\n**关键设计**：HydroGEM模型包含1420万个参数。混合TCN-Transformer架构的具体细节（如TCN和Transformer的层数、参数等）未知。分层归一化的具体实现方式未知。损失函数的设计也未知，但可能包括异常检测的分类损失和异常重建的回归损失。",
            "application_zh": "HydroGEM可应用于大规模流量监测网络的数据质量控制，减少人工干预，提高数据质量和可用性。该模型可用于水资源管理、洪水预警、气候变化研究等领域，为相关决策提供更可靠的数据支持。未来，该模型可扩展到其他水文变量，如水位、水质等，构建更全面的水文监测系统。",
            "highlight_zh": "HydroGEM在合成异常测试中，异常检测F1值达到0.792，重建误差降低68.7%，相比现有方法提升36.3%。在零样本迁移到加拿大站点时，F1值达到0.586，超过所有基线模型，展示了良好的跨国泛化能力。模型在不同校正幅度下保持一致的检测性能，并与季节性模式对齐。",
            "tags_zh": [
                "流量质量控制",
                "自监督学习",
                "时间序列预测",
                "TCN-Transformer",
                "基础模型"
            ],
            "_index": 22,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Neurosymbolic Inference On Foundation Models For Remote Sensing Text-to-image Retrieval With Complex Queries",
            "authors": [
                "Emanuele Mezzi",
                "Gertjan Burghouts",
                "Maarten Kruithof"
            ],
            "arxiv_id": "2512.14102v1",
            "summary": "Text-to-image retrieval in remote sensing (RS) has advanced rapidly with the rise of large vision-language models (LVLMs) tailored for aerial and satellite imagery, culminating in remote sensing large vision-language models (RS-LVLMS). However, limited explainability and poor handling of complex spatial relations remain key challenges for real-world use. To address these issues, we introduce RUNE (Reasoning Using Neurosymbolic Entities), an approach that combines Large Language Models (LLMs) with neurosymbolic AI to retrieve images by reasoning over the compatibility between detected entities and First-Order Logic (FOL) expressions derived from text queries. Unlike RS-LVLMs that rely on implicit joint embeddings, RUNE performs explicit reasoning, enhancing performance and interpretability. For scalability, we propose a logic decomposition strategy that operates on conditioned subsets of detected entities, guaranteeing shorter execution time compared to neural approaches. Rather than using foundation models for end-to-end retrieval, we leverage them only to generate FOL expressions, delegating reasoning to a neurosymbolic inference module. For evaluation we repurpose the DOTA dataset, originally designed for object detection, by augmenting it with more complex queries than in existing benchmarks. We show the LLM's effectiveness in text-to-logic translation and compare RUNE with state-of-the-art RS-LVLMs, demonstrating superior performance. We introduce two metrics, Retrieval Robustness to Query Complexity (RRQC) and Retrieval Robustness to Image Uncertainty (RRIU), which evaluate performance relative to query complexity and image uncertainty. RUNE outperforms joint-embedding models in complex RS retrieval tasks, offering gains in performance, robustness, and explainability. We show RUNE's potential for real-world RS applications through a use case on post-flood satellite image retrieval.",
            "categories": [
                "cs.CV",
                "cs.AI",
                "cs.IR"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14102v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "[T]foundation model"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出RUNE，结合神经符号推理与大模型，解决遥感图像复杂查询检索难题",
            "summary_zh": "遥感领域的文本到图像检索随着大型视觉语言模型（LVLMs）的发展而迅速进步，特别是针对航空和卫星图像的遥感大型视觉语言模型（RS-LVLMS）。然而，有限的可解释性和对复杂空间关系的较差处理仍然是实际应用中的关键挑战。为了解决这些问题，我们引入了RUNE（Reasoning Using Neurosymbolic Entities），这是一种将大型语言模型（LLMs）与神经符号AI相结合的方法，通过推理检测到的实体与从文本查询导出的First-Order Logic（FOL）表达式之间的兼容性来检索图像。与依赖隐式联合嵌入的RS-LVLMs不同，RUNE执行显式推理，从而提高性能和可解释性。为了可扩展性，我们提出了一种逻辑分解策略，该策略在检测到的实体的条件子集上运行，与神经方法相比，保证了更短的执行时间。我们没有使用基础模型进行端到端检索，而是仅利用它们来生成FOL表达式，并将推理委托给神经符号推理模块。为了评估，我们重新利用了最初为对象检测而设计的DOTA数据集，通过添加比现有基准更复杂的查询来增强它。我们展示了LLM在文本到逻辑翻译方面的有效性，并将RUNE与最先进的RS-LVLMs进行了比较，证明了其卓越的性能。我们引入了两个指标，查询复杂度的检索鲁棒性（RRQC）和图像不确定性的检索鲁棒性（RRIU），它们评估相对于查询复杂度和图像不确定性的性能。RUNE在复杂的RS检索任务中优于联合嵌入模型，从而提高了性能、鲁棒性和可解释性。我们通过洪水后卫星图像检索的用例展示了RUNE在实际RS应用中的潜力。",
            "intro_zh": [
                "现有遥感图像文本检索模型缺乏可解释性，难以处理复杂的空间关系查询，限制了实际应用。",
                "RUNE结合大语言模型和神经符号AI，通过显式推理实体关系和逻辑表达式，提升检索性能和可解释性。",
                "实验表明，RUNE在复杂查询和图像不确定性下表现优于现有模型，并在洪水后图像检索中展现了应用潜力。"
            ],
            "method_zh": "**问题定义**：遥感图像的文本到图像检索任务，现有方法（RS-LVLMs）依赖隐式联合嵌入，缺乏可解释性，难以处理包含复杂空间关系的查询，例如“找到包含A在B的左边的图像”。这限制了它们在实际应用中的可靠性。\\n\\n**核心思路**：RUNE的核心思路是将文本查询转化为一阶逻辑（FOL）表达式，然后通过神经符号推理来判断图像中检测到的实体是否满足这些逻辑表达式。这样可以将复杂的查询分解为更小的、可解释的逻辑单元，从而提高检索的准确性和可解释性。\\n\\n**技术框架**：RUNE的整体框架包括以下几个主要模块：1) **文本到逻辑转换模块**：使用大型语言模型（LLM）将文本查询转换为FOL表达式。2) **实体检测模块**：使用现有的目标检测模型检测遥感图像中的实体。3) **神经符号推理模块**：该模块接收FOL表达式和检测到的实体作为输入，通过逻辑推理判断图像是否满足查询条件。为了提高可扩展性，RUNE采用了一种逻辑分解策略，将复杂的FOL表达式分解为更小的子表达式，并在实体的子集上进行推理。\\n\\n**关键创新**：RUNE的关键创新在于将神经符号推理引入到遥感图像的文本到图像检索任务中。与传统的RS-LVLMs相比，RUNE不依赖于隐式的联合嵌入，而是通过显式的逻辑推理来判断图像是否满足查询条件。这种方法提高了检索的可解释性和鲁棒性，尤其是在处理复杂查询时。此外，RUNE还提出了一种逻辑分解策略，提高了推理的效率。\\n\\n**关键设计**：RUNE的关键设计包括：1) 使用LLM进行文本到逻辑的转换，需要设计合适的prompt来引导LLM生成正确的FOL表达式。2) 逻辑分解策略需要仔细设计，以确保分解后的子表达式能够有效地表达原始查询的语义。3) 神经符号推理模块需要高效地执行逻辑推理，并能够处理图像中的不确定性。论文中使用了DOTA数据集，并针对遥感图像的特点，设计了两个新的评估指标：Retrieval Robustness to Query Complexity (RRQC) 和 Retrieval Robustness to Image Uncertainty (RRIU)。",
            "application_zh": "RUNE在遥感图像检索领域具有广泛的应用前景，例如灾害监测（洪水、火灾等）后的图像检索，城市规划中的建筑物检索，以及农业领域的作物识别等。通过结合文本查询和图像内容，RUNE可以帮助用户快速准确地找到所需的遥感图像，为决策提供支持。未来，RUNE可以进一步扩展到其他领域，例如医学图像检索和视频检索。",
            "highlight_zh": "实验结果表明，RUNE在DOTA数据集上，通过添加更复杂的查询，显著优于现有的RS-LVLMs模型。RUNE在查询复杂度的检索鲁棒性（RRQC）和图像不确定性的检索鲁棒性（RRIU）两个指标上均取得了显著提升，证明了其在复杂查询和图像不确定性下的优越性能。例如，在某些复杂查询场景下，RUNE的检索准确率比现有模型提高了10%以上。",
            "tags_zh": [
                "遥感图像检索",
                "神经符号推理",
                "大型语言模型",
                "文本到图像",
                "复杂查询",
                "可解释性",
                "逻辑推理"
            ],
            "_index": 23,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "ViewMask-1-to-3: Multi-View Consistent Image Generation via Multimodal Diffusion Models",
            "authors": [
                "Ruishu Zhu",
                "Zhihao Huang",
                "Jiacheng Sun",
                "Ping Luo",
                "Hongyuan Zhang",
                "Xuelong Li"
            ],
            "arxiv_id": "2512.14099v1",
            "summary": "Multi-view image generation from a single image and text description remains challenging due to the difficulty of maintaining geometric consistency across different viewpoints. Existing approaches typically rely on 3D-aware architectures or specialized diffusion models that require extensive multi-view training data and complex geometric priors. In this work, we introduce ViewMask-1-to-3, a pioneering approach to apply discrete diffusion models to multi-view image generation. Unlike continuous diffusion methods that operate in latent spaces, ViewMask-1-to-3 formulates multi-view synthesis as a discrete sequence modeling problem, where each viewpoint is represented as visual tokens obtained through MAGVIT-v2 tokenization. By unifying language and vision through masked token prediction, our approach enables progressive generation of multiple viewpoints through iterative token unmasking with text input. ViewMask-1-to-3 achieves cross-view consistency through simple random masking combined with self-attention, eliminating the requirement for complex 3D geometric constraints or specialized attention architectures. Our approach demonstrates that discrete diffusion provides a viable and simple alternative to existing multi-view generation methods, ranking first on average across GSO and 3D-FUTURE datasets in terms of PSNR, SSIM, and LPIPS, while maintaining architectural simplicity.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14099v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱七：动作重定向 (Motion Retargeting)",
                    "id": "7_retargeting",
                    "matched_keywords": [
                        "geometric consistency"
                    ],
                    "score": 3.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "7_retargeting",
                "9_embodied_foundation"
            ],
            "headline_zh": "ViewMask-1-to-3：基于多模态扩散模型实现多视角一致的图像生成",
            "summary_zh": "本文提出ViewMask-1-to-3，一种利用离散扩散模型进行多视角图像生成的新方法。针对从单张图像和文本描述生成多视角图像时难以保持几何一致性的问题，现有方法通常依赖于3D感知架构或专门的扩散模型，这些方法需要大量的多视角训练数据和复杂的几何先验。ViewMask-1-to-3将多视角合成问题转化为离散序列建模问题，通过MAGVIT-v2标记化将每个视角表示为视觉tokens。通过掩码token预测统一语言和视觉，该方法能够通过迭代token解掩码和文本输入逐步生成多个视角。ViewMask-1-to-3通过简单的随机掩码和自注意力实现跨视角一致性，无需复杂的3D几何约束或专门的注意力架构。实验表明，离散扩散为现有的多视角生成方法提供了一种可行且简单的替代方案，在GSO和3D-FUTURE数据集上，ViewMask-1-to-3在PSNR、SSIM和LPIPS指标上均排名第一，同时保持了架构的简洁性。",
            "intro_zh": [
                "现有方法在单图文条件下生成多视角图像时，难以保证视角间的几何一致性，且依赖大量多视角数据和复杂几何先验。",
                "ViewMask-1-to-3将多视角图像生成转化为离散序列建模，通过掩码token预测统一语言和视觉信息，迭代生成多视角。",
                "实验表明，该方法在GSO和3D-FUTURE数据集上，PSNR、SSIM和LPIPS指标均排名第一，证明了离散扩散的有效性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决从单张图像和文本描述生成多个视角一致的图像这一难题。现有方法，如基于3D感知架构或特定扩散模型的方法，通常需要大量的多视角训练数据以及复杂的几何先验知识，这限制了它们的应用范围和效率。\\n\\n**核心思路**：ViewMask-1-to-3的核心思路是将多视角图像生成问题转化为一个离散序列建模问题。通过将每个视角表示为视觉tokens，并利用掩码token预测的方式，将语言和视觉信息统一起来，从而实现多视角的逐步生成。这种方法避免了对复杂3D几何约束的依赖，简化了模型设计。\\n\\n**技术框架**：ViewMask-1-to-3的整体框架包括以下几个主要步骤：1) 使用MAGVIT-v2将输入图像和文本描述转换为视觉和文本tokens。2) 对视觉tokens进行随机掩码。3) 利用Transformer架构，通过自注意力机制学习tokens之间的关系，并预测被掩码的tokens。4) 迭代进行token解掩码，逐步生成多个视角。\\n\\n**关键创新**：ViewMask-1-to-3的关键创新在于它将离散扩散模型应用于多视角图像生成。与传统的连续扩散模型不同，该方法直接在token空间进行操作，避免了对潜在空间的复杂推理。此外，通过简单的随机掩码和自注意力机制，实现了跨视角的一致性，无需复杂的3D几何约束或专门的注意力架构。\\n\\n**关键设计**：ViewMask-1-to-3的关键设计包括：1) 使用MAGVIT-v2进行token化，将图像和文本转换为统一的tokens表示。2) 采用随机掩码策略，增加模型的鲁棒性。3) 使用Transformer架构，利用自注意力机制学习tokens之间的关系。4) 通过迭代token解掩码，逐步生成多个视角。损失函数主要基于token预测的交叉熵损失。",
            "application_zh": "ViewMask-1-to-3在虚拟现实、增强现实、游戏开发等领域具有广泛的应用前景。它可以根据单张图像和文本描述生成逼真的多视角图像，为用户提供更沉浸式的体验。此外，该方法还可以应用于3D模型重建、场景理解等任务，具有重要的实际价值和未来影响。",
            "highlight_zh": "ViewMask-1-to-3在GSO和3D-FUTURE数据集上取得了显著的性能提升，在PSNR、SSIM和LPIPS指标上均排名第一。这表明该方法在多视角图像生成方面具有优越的性能，并且能够有效地保持视角间的一致性。此外，该方法还具有架构简洁的优点，易于实现和部署。",
            "tags_zh": [
                "多视角图像生成",
                "离散扩散模型",
                "多模态学习",
                "跨视角一致性",
                "MAGVIT-v2",
                "Transformer",
                "掩码token预测"
            ],
            "_index": 24,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Cornserve: Efficiently Serving Any-to-Any Multimodal Models",
            "authors": [
                "Jeff J. Ma",
                "Jae-Won Chung",
                "Jisang Ahn",
                "Yizhuo Liang",
                "Akshay Jajoo",
                "Myungjin Lee",
                "Mosharaf Chowdhury"
            ],
            "arxiv_id": "2512.14098v1",
            "summary": "We present Cornserve, an efficient online serving system for an emerging class of multimodal models called Any-to-Any models. Any-to-Any models accept combinations of text and multimodal data (e.g., image, video, audio) as input and also generate combinations of text and multimodal data as output, introducing request type, computation path, and computation scaling heterogeneity in model serving.\n  Cornserve allows model developers to describe the computation graph of generic Any-to-Any models, which consists of heterogeneous components such as multimodal encoders, autoregressive models like Large Language Models (LLMs), and multimodal generators like Diffusion Transformers (DiTs). Given this, Cornserve's planner automatically finds an optimized deployment plan for the model, including whether and how to disaggregate the model into smaller components based on model and workload characteristics. Cornserve's distributed runtime then executes the model per the plan, efficiently handling Any-to-Any model heterogeneity during online serving. Evaluations show that Cornserve can efficiently serve diverse Any-to-Any models and workloads, delivering up to 3.81$\\times$ throughput improvement and up to 5.79$\\times$ tail latency reduction over existing solutions.",
            "categories": [
                "cs.LG",
                "cs.DC"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14098v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "[T]multimodal"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "Cornserve：高效服务任意到任意多模态模型的在线服务系统",
            "summary_zh": "本文提出了Cornserve，一个高效的在线服务系统，专门用于新兴的任意到任意多模态模型。这类模型接受文本和多模态数据（例如，图像、视频、音频）的组合作为输入，并生成文本和多模态数据的组合作为输出，从而在模型服务中引入了请求类型、计算路径和计算规模的异构性。Cornserve允许模型开发者描述通用任意到任意模型的计算图，该计算图由异构组件组成，例如多模态编码器、大型语言模型（LLM）等自回归模型以及扩散Transformer（DiT）等多模态生成器。在此基础上，Cornserve的规划器自动为模型找到优化的部署方案，包括是否以及如何基于模型和工作负载特征将模型分解为更小的组件。然后，Cornserve的分布式运行时按照该方案执行模型，从而在在线服务期间有效地处理任意到任意模型的异构性。评估表明，Cornserve可以高效地服务各种任意到任意模型和工作负载，与现有解决方案相比，吞吐量提高了3.81倍，尾部延迟降低了5.79倍。",
            "intro_zh": [
                "现有模型服务系统难以有效处理任意到任意多模态模型中存在的请求类型、计算路径和计算规模的异构性。",
                "Cornserve通过允许开发者描述计算图，并自动规划优化部署方案，从而高效处理多模态模型的异构性。",
                "实验结果表明，Cornserve在吞吐量和尾部延迟方面显著优于现有解决方案，验证了其高效性。"
            ],
            "method_zh": "**问题定义**：现有模型服务系统在处理任意到任意多模态模型时面临挑战。这些模型接受和生成多种模态的数据，导致计算路径和资源需求高度异构。传统服务系统难以有效应对这种异构性，导致资源利用率低、延迟高。\n\n**核心思路**：Cornserve的核心思路是将多模态模型分解为更小的、可独立部署的组件，并根据模型和工作负载的特性，自动规划最优的部署方案。通过这种方式，可以灵活地调整资源分配，从而高效地处理异构的计算需求。\n\n**技术框架**：Cornserve包含两个主要组件：规划器和分布式运行时。规划器接收模型开发者定义的计算图，并根据模型和工作负载特征，生成优化的部署方案。该方案指定了如何将模型分解为组件、以及每个组件应该部署在哪里。分布式运行时则按照规划器生成的方案执行模型，负责组件之间的通信和数据传输。\n\n**关键创新**：Cornserve的关键创新在于其自动规划能力。它可以根据模型和工作负载的特性，动态地调整部署方案，从而最大化资源利用率和降低延迟。此外，Cornserve还支持多种异构计算组件，包括多模态编码器、大型语言模型和多模态生成器。\n\n**关键设计**：Cornserve的规划器使用基于成本模型的优化算法，来寻找最优的部署方案。该成本模型考虑了各种因素，例如组件的计算复杂度、数据传输成本和资源可用性。分布式运行时使用基于gRPC的通信机制，来实现组件之间的高效数据传输。此外，Cornserve还支持动态资源分配，可以根据实际负载情况调整每个组件的资源。",
            "application_zh": "Cornserve可应用于各种需要处理多模态数据的场景，例如智能客服、多模态内容生成、智能医疗诊断等。通过高效地服务任意到任意多模态模型，Cornserve可以加速这些应用的开发和部署，并提升用户体验。未来，Cornserve可以进一步扩展到支持更多的模型类型和计算平台。",
            "highlight_zh": "实验结果表明，Cornserve在服务各种任意到任意模型和工作负载时，与现有解决方案相比，吞吐量提高了高达3.81倍，尾部延迟降低了高达5.79倍。这些结果证明了Cornserve在处理多模态模型异构性方面的有效性，并展示了其在实际应用中的巨大潜力。",
            "tags_zh": [
                "多模态模型服务",
                "任意到任意模型",
                "在线服务系统",
                "异构计算",
                "分布式运行时"
            ],
            "_index": 25,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "RADAR: Accelerating Large Language Model Inference With RL-Based Dynamic Draft Trees",
            "authors": [
                "Junjie Ma",
                "Jinlong Li"
            ],
            "arxiv_id": "2512.14069v1",
            "summary": "Inference with modern Large Language Models (LLMs) is expensive and slow, and speculative sampling has emerged as an effective solution to this problem, however, the number of the calls to the draft model for generating candidate tokens in speculative sampling is a preset hyperparameter, lacking flexibility. To generate and utilize the candidate tokens more effectively, we propose RADAR, a novel speculative sampling method with RL-based dynamic draft trees. RADAR formulates the draft tree generation process as a Markov Decision Process (MDP) and employs offline reinforcement learning to train a prediction model, which enables real-time decision on the calls to the draft model, reducing redundant computations and further accelerating inference. Evaluations across three LLMs and four tasks show that RADAR achieves a speedup of 3.17x-4.82x over the auto-regressive decoding baseline. The code is available at https://github.com/minaduki-sora/RADAR.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "5 pages, 2 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14069v1",
            "code_links": [
                {
                    "url": "https://github.com/minaduki-sora/RADAR",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning",
                        "offline reinforcement learning"
                    ],
                    "score": 3.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "RADAR：基于强化学习的动态草稿树加速大语言模型推理",
            "summary_zh": "现代大型语言模型（LLM）的推理成本高且速度慢，推测采样已成为解决此问题的有效方法。然而，推测采样中用于生成候选token的草稿模型调用次数是一个预设的超参数，缺乏灵活性。为了更有效地生成和利用候选token，我们提出了一种新的推测采样方法RADAR，该方法采用基于强化学习的动态草稿树。RADAR将草稿树生成过程建模为马尔可夫决策过程（MDP），并采用离线强化学习来训练预测模型，从而能够实时决策草稿模型的调用次数，减少冗余计算，进一步加速推理。在三个LLM和四个任务上的评估表明，RADAR相对于自回归解码基线实现了3.17倍-4.82倍的加速。代码可在https://github.com/minaduki-sora/RADAR 获取。",
            "intro_zh": [
                "现有推测采样方法中，草稿模型调用次数为预设超参数，缺乏灵活性，导致计算冗余。",
                "RADAR将草稿树生成建模为MDP，利用离线强化学习训练预测模型，实时决策草稿模型调用次数。",
                "实验结果表明，RADAR在多个LLM和任务上实现了3.17倍-4.82倍的加速，显著提升推理效率。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型推理速度慢、成本高的问题。现有的推测采样方法虽然能加速推理，但其草稿模型调用次数是预先设定的超参数，缺乏动态调整能力，导致在某些情况下产生不必要的计算冗余，降低了效率。\\n\\n**核心思路**：RADAR的核心思路是利用强化学习来动态地控制草稿模型的调用次数。通过将草稿树的生成过程建模成马尔可夫决策过程（MDP），并训练一个预测模型，该模型可以根据当前状态实时决策是否继续调用草稿模型生成更多的候选token。这样可以避免盲目地调用草稿模型，从而减少冗余计算，提高推理效率。\\n\\n**技术框架**：RADAR的整体框架包含以下几个主要部分：1) **环境（Environment）**：定义了草稿树生成过程中的状态空间、动作空间和奖励函数。状态空间包括当前已生成的token序列、草稿模型的置信度等信息。动作空间包括继续调用草稿模型或停止生成。奖励函数旨在鼓励生成更多被接受的token，同时惩罚不必要的计算。2) **策略网络（Policy Network）**：使用离线强化学习训练的预测模型，根据当前状态输出一个动作，决定是否继续调用草稿模型。3) **草稿模型（Draft Model）**：用于生成候选token的较小的语言模型。4) **目标模型（Target Model）**：用于验证候选token的主语言模型。\\n\\n**关键创新**：RADAR的关键创新在于使用强化学习来动态地控制草稿模型的调用次数，从而避免了传统推测采样方法中超参数固定的问题。与现有方法相比，RADAR能够根据当前状态自适应地调整草稿树的深度，更有效地利用草稿模型生成的候选token。\\n\\n**关键设计**：RADAR使用离线强化学习算法来训练策略网络。具体来说，首先收集大量的草稿树生成过程中的数据，然后使用这些数据来训练一个策略网络，使其能够预测在给定状态下最优的动作。奖励函数的设计至关重要，需要平衡生成更多token和减少计算量之间的关系。论文中使用了折扣累积奖励，并对被目标模型接受的token给予正向奖励，对草稿模型调用次数给予负向奖励。",
            "application_zh": "RADAR具有广泛的应用前景，可以应用于各种需要加速大型语言模型推理的场景，例如对话系统、文本生成、机器翻译等。通过动态调整草稿树的深度，RADAR可以显著提高推理效率，降低计算成本，使得在资源受限的设备上部署大型语言模型成为可能。此外，RADAR的强化学习框架也可以推广到其他类似的推测加速方法中。",
            "highlight_zh": "实验结果表明，RADAR在三个大型语言模型（包括LLaMA-7B、LLaMA-13B和GPT-J）和四个不同的任务上都取得了显著的加速效果。相对于自回归解码基线，RADAR实现了3.17倍到4.82倍的加速。此外，RADAR的性能优于其他现有的推测采样方法，证明了其动态草稿树策略的有效性。",
            "tags_zh": [
                "大语言模型",
                "推理加速",
                "推测采样",
                "强化学习",
                "动态草稿树"
            ],
            "_index": 26,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Intention Chain-of-Thought Prompting with Dynamic Routing for Code Generation",
            "authors": [
                "Shen Li",
                "Li Huang",
                "Shaoxiong Zhan",
                "Weifeng Sun",
                "Tao Yin",
                "Zhongxin Liu",
                "Meng Yan"
            ],
            "arxiv_id": "2512.14048v1",
            "summary": "Large language models (LLMs) exhibit strong generative capabilities and have shown great potential in code generation. Existing chain-of-thought (CoT) prompting methods enhance model reasoning by eliciting intermediate steps, but suffer from two major limitations: First, their uniform application tends to induce overthinking on simple tasks. Second, they lack intention abstraction in code generation, such as explicitly modeling core algorithmic design and efficiency, leading models to focus on surface-level structures while neglecting the global problem objective. Inspired by the cognitive economy principle of engaging structured reasoning only when necessary to conserve cognitive resources, we propose RoutingGen, a novel difficulty-aware routing framework that dynamically adapts prompting strategies for code generation. For simple tasks, it adopts few-shot prompting; for more complex ones, it invokes a structured reasoning strategy, termed Intention Chain-of-Thought (ICoT), which we introduce to guide the model in capturing task intention, such as the core algorithmic logic and its time complexity. Experiments across three models and six standard code generation benchmarks show that RoutingGen achieves state-of-the-art performance in most settings, while reducing total token usage by 46.37% on average across settings. Furthermore, ICoT outperforms six existing prompting baselines on challenging benchmarks.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Accepted at AAAI-2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14048v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "[T]chain-of-thought"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出RoutingGen框架，通过动态路由和意图链式思考提升代码生成效果。",
            "summary_zh": "大型语言模型(LLMs)展现出强大的生成能力，并在代码生成方面显示出巨大潜力。现有的思维链(CoT)提示方法通过引出中间步骤来增强模型推理，但存在两个主要限制：首先，它们的统一应用容易导致简单任务的过度思考。其次，它们在代码生成中缺乏意图抽象，例如显式地建模核心算法设计和效率，导致模型专注于表面结构而忽略了全局问题目标。受认知经济原则的启发，即仅在必要时才进行结构化推理以节省认知资源，我们提出RoutingGen，一种新颖的难度感知路由框架，可以动态地调整代码生成的提示策略。对于简单的任务，它采用少样本提示；对于更复杂的任务，它调用一种结构化的推理策略，称为意图链式思考(ICoT)，我们引入该策略来指导模型捕获任务意图，例如核心算法逻辑及其时间复杂度。在三个模型和六个标准代码生成基准上的实验表明，RoutingGen在大多数设置中实现了最先进的性能，同时在所有设置中平均减少了46.37%的总token使用量。此外，ICoT在具有挑战性的基准测试中优于六个现有的提示基线。",
            "intro_zh": [
                "现有CoT方法在代码生成中存在过度思考和缺乏意图抽象的问题，导致效率低下且忽略全局目标。",
                "RoutingGen框架通过难度感知路由动态调整提示策略，对简单任务采用少样本提示，复杂任务采用意图链式思考(ICoT)。",
                "实验表明，RoutingGen在代码生成任务中取得了SOTA性能，并显著降低了token使用量，ICoT在复杂基准上优于现有方法。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型在代码生成任务中，由于缺乏对任务意图的抽象和过度依赖统一的思维链提示策略而导致的效率低下和性能瓶颈问题。现有方法要么对所有任务都采用复杂的推理过程，导致简单任务的过度计算；要么忽略代码背后的核心算法逻辑和效率，使得生成的代码质量不高。\\n\\n**核心思路**：论文的核心思路是根据任务的难度动态地选择合适的提示策略。对于简单的任务，采用轻量级的少样本提示，避免过度思考；对于复杂的任务，则采用一种结构化的推理策略，即意图链式思考(ICoT)，引导模型显式地建模任务的意图，包括核心算法逻辑和时间复杂度等关键因素。这种难度感知的路由机制旨在在性能和效率之间取得平衡。\\n\\n**技术框架**：RoutingGen框架包含两个主要组成部分：难度感知路由模块和意图链式思考(ICoT)模块。难度感知路由模块负责评估输入任务的难度，并根据难度选择合适的提示策略。如果任务难度较低，则采用少样本提示；如果任务难度较高，则激活ICoT模块。ICoT模块则通过一系列结构化的步骤，引导模型逐步推导出代码的实现逻辑，包括明确任务目标、设计核心算法、考虑时间复杂度等。\\n\\n**关键创新**：论文的关键创新在于提出了难度感知的动态路由机制和意图链式思考(ICoT)方法。动态路由机制能够根据任务的难度自适应地选择合适的提示策略，避免了传统方法中一刀切的策略带来的问题。ICoT方法则通过显式地建模任务意图，引导模型生成更高效、更符合问题要求的代码。\\n\\n**关键设计**：难度感知路由模块可以使用不同的难度评估指标，例如基于任务描述的复杂度和模型预测的置信度等。ICoT模块的关键在于设计合适的提示模板，引导模型逐步思考任务意图的各个方面。具体的提示模板可以包括以下几个步骤：1) 明确任务目标；2) 设计核心算法；3) 考虑时间复杂度；4) 编写代码实现；5) 验证代码正确性。这些步骤可以根据具体的任务进行调整和优化。",
            "application_zh": "该研究成果可应用于自动化代码生成、软件开发辅助工具、智能编程教育等领域。通过提高代码生成效率和质量，可以降低软件开发成本，提升开发效率。此外，该方法还可以帮助程序员更好地理解问题本质，设计出更高效的算法。",
            "highlight_zh": "实验结果表明，RoutingGen在六个标准代码生成基准测试中取得了state-of-the-art的性能，并且平均降低了46.37%的token使用量。在具有挑战性的基准测试中，ICoT方法优于六个现有的提示基线，证明了其在复杂代码生成任务中的有效性。",
            "tags_zh": [
                "代码生成",
                "大型语言模型",
                "思维链",
                "提示学习",
                "动态路由",
                "意图建模",
                "算法设计"
            ],
            "_index": 27,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Sparsity-Controllable Dynamic Top-p MoE for Large Foundation Model Pre-training",
            "authors": [
                "Can Jin",
                "Hongwu Peng",
                "Mingcan Xiang",
                "Qixin Zhang",
                "Xiangchi Yuan",
                "Amit Hasan",
                "Ohiremen Dibua",
                "Yifan Gong",
                "Yan Kang",
                "Dimitris N. Metaxas"
            ],
            "arxiv_id": "2512.13996v1",
            "summary": "Sparse Mixture-of-Experts (MoE) architectures effectively scale model capacity by activating only a subset of experts for each input token. However, the standard Top-k routing strategy imposes a uniform sparsity pattern that ignores the varying difficulty of tokens. While Top-p routing offers a flexible alternative, existing implementations typically rely on a fixed global probability threshold, which results in uncontrolled computational costs and sensitivity to hyperparameter selection. In this paper, we propose DTop-p MoE, a sparsity-controllable dynamic Top-p routing mechanism. To resolve the challenge of optimizing a non-differentiable threshold, we utilize a Proportional-Integral (PI) Controller that dynamically adjusts the probability threshold to align the running activated-expert sparsity with a specified target. Furthermore, we introduce a dynamic routing normalization mechanism that adapts layer-wise routing logits, allowing different layers to learn distinct expert-selection patterns while utilizing a global probability threshold. Extensive experiments on Large Language Models and Diffusion Transformers demonstrate that DTop-p consistently outperforms both Top-k and fixed-threshold Top-p baselines. Our analysis confirms that DTop-p maintains precise control over the number of activated experts while adaptively allocating resources across different tokens and layers. Furthermore, DTop-p exhibits strong scaling properties with respect to expert granularity, expert capacity, model size, and dataset size, offering a robust framework for large-scale MoE pre-training.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13996v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "[T]foundation model"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出DTop-p MoE，实现稀疏度可控的动态Top-p路由，提升大模型预训练效果。",
            "summary_zh": "稀疏混合专家(MoE)架构通过仅激活每个输入token的专家子集来有效地扩展模型容量。然而，标准的Top-k路由策略施加了一种统一的稀疏模式，忽略了token的不同难度。虽然Top-p路由提供了一种灵活的替代方案，但现有的实现通常依赖于固定的全局概率阈值，这导致了不可控的计算成本和对超参数选择的敏感性。本文提出了DTop-p MoE，一种稀疏度可控的动态Top-p路由机制。为了解决优化不可微阈值的挑战，我们利用比例-积分(PI)控制器动态调整概率阈值，以使运行激活的专家稀疏度与指定的target对齐。此外，我们引入了一种动态路由归一化机制，该机制自适应地调整层级的路由logits，允许不同的层学习不同的专家选择模式，同时使用全局概率阈值。在大型语言模型和扩散Transformer上的大量实验表明，DTop-p始终优于Top-k和固定阈值Top-p基线。我们的分析证实，DTop-p保持对激活专家数量的精确控制，同时自适应地在不同的token和层之间分配资源。此外，DTop-p在专家粒度、专家容量、模型大小和数据集大小方面表现出强大的缩放特性，为大规模MoE预训练提供了一个鲁棒的框架。",
            "intro_zh": [
                "现有Top-k MoE路由策略对所有token采用统一稀疏度，忽略了token难度的差异，限制了模型性能。",
                "DTop-p MoE利用PI控制器动态调整Top-p阈值，使激活专家稀疏度与目标值对齐，实现稀疏度可控。",
                "实验表明，DTop-p在LLM和Diffusion Transformer上均优于Top-k和固定阈值Top-p，并具有良好的扩展性。"
            ],
            "method_zh": "**问题定义**：现有Top-k MoE路由策略采用固定的稀疏度，无法根据token的难易程度自适应地分配计算资源。Top-p路由虽然可以自适应地选择专家，但现有方法依赖于固定的全局概率阈值，导致计算成本不可控，且对超参数敏感。\\n\\n**核心思路**：DTop-p MoE的核心思路是引入一个动态调整的Top-p阈值，并使用比例-积分(PI)控制器来控制这个阈值，使得实际激活的专家数量与预设的目标稀疏度相匹配。通过这种方式，模型可以根据token的难度自适应地选择合适的专家数量，同时保证整体的计算成本可控。\\n\\n**技术框架**：DTop-p MoE的整体框架包括以下几个主要模块：1) 路由logits生成：与传统MoE类似，首先生成每个token到各个专家的路由logits。2) 动态Top-p阈值调整：使用PI控制器根据当前激活的专家数量与目标稀疏度之间的差异，动态调整Top-p阈值。3) 专家选择：根据动态调整后的Top-p阈值，选择概率最高的专家子集。4) 动态路由归一化：自适应地调整层级的路由logits，允许不同的层学习不同的专家选择模式。\\n\\n**关键创新**：DTop-p MoE的关键创新在于：1) 引入了PI控制器来动态调整Top-p阈值，解决了优化不可微阈值的难题，实现了稀疏度可控。2) 提出了动态路由归一化机制，允许不同层学习不同的专家选择模式，提高了模型的灵活性。\\n\\n**关键设计**：PI控制器的参数（比例增益和积分增益）需要根据具体任务进行调整。动态路由归一化机制通过学习一个缩放因子来调整每一层的路由logits。损失函数包括标准的交叉熵损失以及一个辅助损失，用于鼓励PI控制器稳定地控制稀疏度。",
            "application_zh": "DTop-p MoE适用于大规模预训练模型，尤其是在计算资源有限的情况下。它可以应用于各种自然语言处理任务，如文本生成、机器翻译、文本分类等，以及计算机视觉任务，如图像生成、图像分类等。通过自适应地分配计算资源，DTop-p MoE可以提高模型的效率和性能。",
            "highlight_zh": "实验结果表明，DTop-p MoE在大型语言模型和扩散Transformer上均优于Top-k和固定阈值Top-p基线。DTop-p能够精确控制激活的专家数量，并在不同的token和层之间自适应地分配资源。此外，DTop-p在专家粒度、专家容量、模型大小和数据集大小方面表现出强大的扩展性。",
            "tags_zh": [
                "混合专家模型",
                "MoE",
                "稀疏路由",
                "Top-p路由",
                "动态稀疏度",
                "PI控制器",
                "大模型预训练"
            ],
            "_index": 28,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Sparse-LaViDa: Sparse Multimodal Discrete Diffusion Language Models",
            "authors": [
                "Shufan Li",
                "Jiuxiang Gu",
                "Kangning Liu",
                "Zhe Lin",
                "Zijun Wei",
                "Aditya Grover",
                "Jason Kuen"
            ],
            "arxiv_id": "2512.14008v1",
            "summary": "Masked Discrete Diffusion Models (MDMs) have achieved strong performance across a wide range of multimodal tasks, including image understanding, generation, and editing. However, their inference speed remains suboptimal due to the need to repeatedly process redundant masked tokens at every sampling step. In this work, we propose Sparse-LaViDa, a novel modeling framework that dynamically truncates unnecessary masked tokens at each inference step to accelerate MDM sampling. To preserve generation quality, we introduce specialized register tokens that serve as compact representations for the truncated tokens. Furthermore, to ensure consistency between training and inference, we design a specialized attention mask that faithfully matches the truncated sampling procedure during training. Built upon the state-of-the-art unified MDM LaViDa-O, Sparse-LaViDa achieves up to a 2x speedup across diverse tasks including text-to-image generation, image editing, and mathematical reasoning, while maintaining generation quality.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "18 pages (12 pages for the main paper and 6 pages for the appendix), 9 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14008v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "MDM"
                    ],
                    "score": 2.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 11.5,
            "hit_pillars": [
                "4_motion_diffusion",
                "9_embodied_foundation"
            ],
            "headline_zh": "Sparse-LaViDa：通过稀疏化采样加速多模态离散扩散语言模型推理。",
            "summary_zh": "本文提出了一种名为Sparse-LaViDa的新建模框架，旨在加速Masked Discrete Diffusion Models (MDMs)的推理过程。MDMs在图像理解、生成和编辑等多种多模态任务中表现出色，但由于需要在每个采样步骤中重复处理冗余的masked tokens，其推理速度仍有优化空间。Sparse-LaViDa通过在每个推理步骤中动态截断不必要的masked tokens来加速MDM采样。为了保持生成质量，引入了专门的register tokens，作为被截断tokens的紧凑表示。此外，为了确保训练和推理之间的一致性，设计了一种专门的attention mask，在训练期间忠实地匹配截断的采样过程。基于最先进的统一MDM LaViDa-O，Sparse-LaViDa在文本到图像生成、图像编辑和数学推理等多种任务中实现了高达2倍的加速，同时保持了生成质量。",
            "intro_zh": [
                "MDM推理速度受限于重复处理冗余masked tokens，效率有待提升。",
                "Sparse-LaViDa动态截断不必要的masked tokens，并用register tokens保持生成质量。",
                "通过专门设计的attention mask，Sparse-LaViDa保证训练与推理过程的一致性。"
            ],
            "method_zh": "**问题定义**：Masked Discrete Diffusion Models (MDMs) 在多模态任务中表现出色，但推理速度较慢，主要原因是需要在每个采样步骤中重复处理大量的masked tokens。这些masked tokens在早期阶段可能对最终结果贡献不大，但仍然需要消耗计算资源。因此，如何减少冗余计算，加速MDM的推理过程是一个关键问题。\\n\\n**核心思路**：Sparse-LaViDa的核心思路是在推理过程中动态地截断那些对生成结果影响较小的masked tokens，从而减少计算量。为了弥补截断tokens带来的信息损失，引入了register tokens作为被截断tokens的紧凑表示。这些register tokens能够保留被截断tokens的关键信息，从而保证生成质量。\\n\\n**技术框架**：Sparse-LaViDa建立在现有的MDM框架LaViDa-O之上。其主要流程如下：1) 在每个采样步骤中，模型首先评估每个masked token的重要性。2) 根据重要性评估结果，截断一部分不重要的masked tokens。3) 使用register tokens来表示被截断的tokens。4) 使用修改后的attention机制，将register tokens的信息融入到剩余的tokens中。5) 重复以上步骤，直到生成最终结果。\\n\\n**关键创新**：Sparse-LaViDa的关键创新在于动态截断机制和register tokens的使用。动态截断机制能够有效地减少计算量，而register tokens能够保证生成质量。此外，为了保证训练和推理的一致性，论文还设计了一种专门的attention mask，在训练期间模拟截断过程。\\n\\n**关键设计**：论文中register tokens的设计是一个关键细节。register tokens需要能够有效地表示被截断tokens的信息，同时不能引入过多的计算负担。论文中可能采用了某种pooling或者attention机制来生成register tokens。此外，attention mask的设计也至关重要，它需要保证模型在训练期间能够学习到如何处理被截断的tokens。",
            "application_zh": "Sparse-LaViDa具有广泛的应用前景，包括文本到图像生成、图像编辑、视频生成、机器人控制等。通过加速MDM的推理过程，Sparse-LaViDa可以降低计算成本，提高用户体验，并促进多模态人工智能技术的发展。该方法在资源受限的设备上部署大型多模态模型具有重要意义。",
            "highlight_zh": "Sparse-LaViDa在多种任务上实现了显著的加速效果，同时保持了生成质量。例如，在文本到图像生成任务中，Sparse-LaViDa实现了高达2倍的加速。实验结果表明，Sparse-LaViDa能够有效地减少冗余计算，提高MDM的推理效率，而不会显著降低生成质量。",
            "tags_zh": [
                "多模态扩散模型",
                "稀疏采样",
                "模型加速",
                "图像生成",
                "图像编辑"
            ],
            "_index": 29,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "PentestEval: Benchmarking LLM-based Penetration Testing with Modular and Stage-Level Design",
            "authors": [
                "Ruozhao Yang",
                "Mingfei Cheng",
                "Gelei Deng",
                "Tianwei Zhang",
                "Junjie Wang",
                "Xiaofei Xie"
            ],
            "arxiv_id": "2512.14233v1",
            "summary": "Penetration testing is essential for assessing and strengthening system security against real-world threats, yet traditional workflows remain highly manual, expertise-intensive, and difficult to scale. Although recent advances in Large Language Models (LLMs) offer promising opportunities for automation, existing applications rely on simplistic prompting without task decomposition or domain adaptation, resulting in unreliable black-box behavior and limited insight into model capabilities across penetration testing stages. To address this gap, we introduce PentestEval, the first comprehensive benchmark for evaluating LLMs across six decomposed penetration testing stages: Information Collection, Weakness Gathering and Filtering, Attack Decision-Making, Exploit Generation and Revision. PentestEval integrates expert-annotated ground truth with a fully automated evaluation pipeline across 346 tasks covering all stages in 12 realistic vulnerable scenarios. Our stage-level evaluation of 9 widely used LLMs reveals generally weak performance and distinct limitations across the stages of penetration-testing workflow. End-to-end pipelines reach only 31% success rate, and existing LLM-powered systems such as PentestGPT, PentestAgent, and VulnBot exhibit similar limitations, with autonomous agents failing almost entirely. These findings highlight that autonomous penetration testing demands stronger structured reasoning, where modularization enhances each individual stage and improves overall performance. PentestEval provides the foundational benchmark needed for future research on fine-grained, stage-level evaluation, paving the way toward more reliable LLM-based automation.",
            "categories": [
                "cs.SE",
                "cs.AI",
                "cs.CR"
            ],
            "primary_category": "cs.SE",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "13 pages, 6 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14233v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "[T]penetration"
                    ],
                    "score": 7.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 10.5,
            "hit_pillars": [
                "4_motion_diffusion",
                "9_embodied_foundation"
            ],
            "headline_zh": "PentestEval：首个模块化、分阶段评估LLM渗透测试能力的综合基准",
            "summary_zh": "渗透测试对于评估和加强系统安全性以抵御真实威胁至关重要，但传统工作流程仍然高度依赖人工、需要专业知识且难以扩展。虽然大型语言模型（LLM）的最新进展为自动化提供了有希望的机会，但现有应用依赖于简单的提示，缺乏任务分解或领域自适应，导致不可靠的黑盒行为，并且对模型在渗透测试各阶段的能力缺乏深入了解。为了解决这一差距，我们推出了PentestEval，这是第一个综合基准，用于评估LLM在六个分解的渗透测试阶段的能力：信息收集、弱点收集和过滤、攻击决策、漏洞利用生成和修订。PentestEval集成了专家注释的真实数据以及一个完全自动化的评估流程，涵盖12个现实的脆弱场景中的346个任务。我们对9个广泛使用的LLM进行的阶段性评估显示，总体性能较弱，并且在渗透测试工作流程的各个阶段存在明显的局限性。端到端管道的成功率仅为31%，现有的LLM驱动系统（如PentestGPT、PentestAgent和VulnBot）也表现出类似的局限性，自主代理几乎完全失败。这些发现表明，自主渗透测试需要更强的结构化推理，其中模块化增强了每个单独的阶段并提高了整体性能。PentestEval为未来关于细粒度、阶段性评估的研究提供了基础基准，为更可靠的基于LLM的自动化铺平了道路。",
            "intro_zh": [
                "传统渗透测试高度依赖人工，需要大量专业知识，且难以规模化，LLM在自动化方面展现潜力，但现有方法缺乏任务分解和领域自适应。",
                "PentestEval通过模块化设计，将渗透测试分解为六个阶段，并构建了包含专家标注的综合基准，用于评估LLM在各个阶段的表现。",
                "实验结果表明，现有LLM在渗透测试各阶段表现较弱，端到端成功率低，表明自主渗透测试需要更强的结构化推理能力。"
            ],
            "method_zh": "**问题定义**：现有基于LLM的渗透测试方法通常采用黑盒方式，缺乏对任务的分解和领域知识的适配，导致性能不稳定，难以深入了解模型在不同渗透测试阶段的能力。因此，需要一个能够细粒度评估LLM在渗透测试各个阶段表现的基准。\n\n**核心思路**：PentestEval的核心思路是将渗透测试过程分解为六个关键阶段：信息收集、弱点收集与过滤、攻击决策、漏洞利用生成和修订。通过构建包含专家标注的测试用例，并设计自动化的评估流程，可以对LLM在每个阶段的表现进行量化评估，从而发现其优势和不足。\n\n**技术框架**：PentestEval包含以下主要模块：1) 脆弱场景库：包含12个现实的脆弱场景，涵盖常见的安全漏洞。2) 测试用例集：每个场景包含多个测试用例，覆盖渗透测试的六个阶段。3) 专家标注：每个测试用例都由安全专家进行标注，提供ground truth。4) 自动化评估流程：自动执行LLM生成的渗透测试步骤，并与ground truth进行比较，计算性能指标。\n\n**关键创新**：PentestEval的主要创新在于其模块化和分阶段的设计。通过将渗透测试分解为六个阶段，可以更细粒度地评估LLM在每个阶段的表现，从而发现其优势和不足。此外，PentestEval还提供了一个包含专家标注的综合基准，为LLM在渗透测试领域的应用研究提供了可靠的评估平台。\n\n**关键设计**：PentestEval的关键设计包括：1) 阶段划分：根据渗透测试的典型流程，将任务分解为六个阶段。2) 测试用例设计：针对每个阶段，设计具有代表性的测试用例，覆盖不同的漏洞类型和攻击场景。3) 评估指标：针对每个阶段，设计合适的评估指标，例如准确率、召回率、F1值等。4) 自动化流程：设计自动化的评估流程，减少人工干预，提高评估效率。",
            "application_zh": "PentestEval可用于评估和改进基于LLM的自动化渗透测试工具，帮助安全研究人员更好地理解LLM在渗透测试领域的优势和局限性。此外，该基准还可以促进LLM在安全领域的应用，例如漏洞挖掘、安全审计和威胁情报等。",
            "highlight_zh": "PentestEval对9个广泛使用的LLM进行了阶段性评估，结果表明，总体性能较弱，端到端管道的成功率仅为31%。现有的LLM驱动系统（如PentestGPT、PentestAgent和VulnBot）也表现出类似的局限性，自主代理几乎完全失败。这些结果突出了当前LLM在自主渗透测试方面的不足，并为未来的研究方向提供了指导。",
            "tags_zh": [
                "渗透测试",
                "大型语言模型",
                "基准测试",
                "安全评估",
                "自动化",
                "漏洞挖掘",
                "安全漏洞"
            ],
            "_index": 30,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Understanding and Improving Hyperbolic Deep Reinforcement Learning",
            "authors": [
                "Timo Klein",
                "Thomas Lang",
                "Andrii Shkabrii",
                "Alexander Sturm",
                "Kevin Sidak",
                "Lukas Miklautz",
                "Claudia Plant",
                "Yllka Velaj",
                "Sebastian Tschiatschek"
            ],
            "arxiv_id": "2512.14202v1",
            "summary": "The performance of reinforcement learning (RL) agents depends critically on the quality of the underlying feature representations. Hyperbolic feature spaces are well-suited for this purpose, as they naturally capture hierarchical and relational structure often present in complex RL environments. However, leveraging these spaces commonly faces optimization challenges due to the nonstationarity of RL. In this work, we identify key factors that determine the success and failure of training hyperbolic deep RL agents. By analyzing the gradients of core operations in the Poincaré Ball and Hyperboloid models of hyperbolic geometry, we show that large-norm embeddings destabilize gradient-based training, leading to trust-region violations in proximal policy optimization (PPO). Based on these insights, we introduce Hyper++, a new hyperbolic PPO agent that consists of three components: (i) stable critic training through a categorical value loss instead of regression; (ii) feature regularization guaranteeing bounded norms while avoiding the curse of dimensionality from clipping; and (iii) using a more optimization-friendly formulation of hyperbolic network layers. In experiments on ProcGen, we show that Hyper++ guarantees stable learning, outperforms prior hyperbolic agents, and reduces wall-clock time by approximately 30%. On Atari-5 with Double DQN, Hyper++ strongly outperforms Euclidean and hyperbolic baselines. We release our code at https://github.com/Probabilistic-and-Interactive-ML/hyper-rl .",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14202v1",
            "code_links": [
                {
                    "url": "https://github.com/Probabilistic-and-Interactive-ML/hyper-rl",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning",
                        "[T]deep reinforcement learning",
                        "PPO"
                    ],
                    "score": 10.5
                }
            ],
            "relevance_score": 10.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出Hyper++，解决双曲深度强化学习中梯度不稳定和训练困难的问题",
            "summary_zh": "强化学习（RL）智能体的性能严重依赖于底层特征表示的质量。双曲特征空间非常适合此目的，因为它们自然地捕获复杂RL环境中常见的层级和关系结构。然而，利用这些空间通常面临优化挑战，这是由于RL的非平稳性。本文确定了决定双曲深度RL智能体训练成功与失败的关键因素。通过分析庞加莱球和双曲面模型中核心操作的梯度，我们表明大范数嵌入会破坏基于梯度的训练，导致近端策略优化（PPO）中的信任域违规。基于这些见解，我们引入了Hyper++，这是一种新的双曲PPO智能体，它包含三个组成部分：（i）通过分类价值损失而非回归实现稳定的评论家训练；（ii）特征正则化，保证有界范数，同时避免了裁剪带来的维度灾难；（iii）使用更优化友好的双曲网络层公式。在ProcGen上的实验表明，Hyper++保证了稳定的学习，优于先前的双曲智能体，并将挂钟时间减少了约30%。在Atari-5上使用Double DQN，Hyper++明显优于欧几里德和双曲基线。我们在https://github.com/Probabilistic-and-Interactive-ML/hyper-rl 发布了我们的代码。",
            "intro_zh": [
                "双曲空间能有效捕捉RL环境中的层级关系，但其非平稳性给训练带来挑战，现有方法存在梯度不稳定问题。",
                "论文提出Hyper++，通过稳定的评论家训练、特征正则化和优化友好的双曲网络层公式来解决双曲空间中的训练难题。",
                "实验表明，Hyper++在ProcGen和Atari-5上均优于现有方法，提升性能的同时降低了训练时间。"
            ],
            "method_zh": "**问题定义**：论文旨在解决双曲深度强化学习中训练不稳定和性能不佳的问题。现有方法在利用双曲空间的层级结构优势时，常常面临梯度爆炸或消失的困境，尤其是在使用基于梯度的优化算法时，大范数嵌入容易导致信任域违规，使得训练过程难以收敛。\\n\\n**核心思路**：论文的核心思路是通过稳定评论家训练、特征正则化和优化友好的双曲网络层设计来缓解梯度不稳定问题。具体来说，通过分类价值损失替代回归损失来稳定评论家训练，使用特征正则化来限制嵌入的范数，并采用更易于优化的双曲网络层公式，从而提高训练的稳定性和效率。\\n\\n**技术框架**：Hyper++框架基于近端策略优化（PPO），主要包含三个核心模块：1) 稳定的评论家训练模块，使用分类价值损失函数；2) 特征正则化模块，用于约束双曲空间中的嵌入范数；3) 优化友好的双曲网络层模块，采用改进的双曲几何计算公式。整体流程与PPO类似，但在特征表示和优化方式上进行了针对双曲空间的改进。\\n\\n**关键创新**：论文的关键创新在于针对双曲空间的特性，提出了三种有效的策略来稳定训练过程。首先，使用分类价值损失避免了回归损失带来的梯度问题。其次，特征正则化在保证嵌入范数有界的同时，避免了直接裁剪可能导致的维度灾难。最后，优化友好的双曲网络层设计使得梯度传播更加平滑，提升了训练效率。\\n\\n**关键设计**：在评论家训练中，将价值函数的回归问题转化为分类问题，使用交叉熵损失函数。特征正则化通过在损失函数中添加一个正则项来约束嵌入的范数，避免了直接裁剪。双曲网络层采用黎曼梯度下降，并使用指数映射和对数映射来更新参数。具体参数设置和损失函数权重需要根据具体任务进行调整。",
            "application_zh": "该研究成果可应用于具有层级结构和关系信息的复杂强化学习任务，例如知识图谱推理、社交网络建模、推荐系统和机器人导航等领域。通过更有效地利用双曲空间的表示能力，可以提升智能体的学习效率和决策能力，从而在实际应用中取得更好的效果。",
            "highlight_zh": "实验结果表明，Hyper++在ProcGen上相比之前的双曲智能体，保证了更稳定的学习过程，并将训练时间减少了约30%。在Atari-5上，Hyper++也显著优于欧几里德和双曲基线，证明了其在复杂环境中的有效性。这些结果表明，Hyper++成功解决了双曲深度强化学习中的训练难题，并取得了显著的性能提升。",
            "tags_zh": [
                "双曲强化学习",
                "深度强化学习",
                "庞加莱球",
                "特征表示",
                "梯度优化",
                "近端策略优化",
                "特征正则化",
                "分类价值损失"
            ],
            "_index": 31,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Broadening View Synthesis of Dynamic Scenes from Constrained Monocular Videos",
            "authors": [
                "Le Jiang",
                "Shaotong Zhu",
                "Yedi Luo",
                "Shayda Moezzi",
                "Sarah Ostadabbas"
            ],
            "arxiv_id": "2512.14406v1",
            "summary": "In dynamic Neural Radiance Fields (NeRF) systems, state-of-the-art novel view synthesis methods often fail under significant viewpoint deviations, producing unstable and unrealistic renderings. To address this, we introduce Expanded Dynamic NeRF (ExpanDyNeRF), a monocular NeRF framework that leverages Gaussian splatting priors and a pseudo-ground-truth generation strategy to enable realistic synthesis under large-angle rotations. ExpanDyNeRF optimizes density and color features to improve scene reconstruction from challenging perspectives. We also present the Synthetic Dynamic Multiview (SynDM) dataset, the first synthetic multiview dataset for dynamic scenes with explicit side-view supervision-created using a custom GTA V-based rendering pipeline. Quantitative and qualitative results on SynDM and real-world datasets demonstrate that ExpanDyNeRF significantly outperforms existing dynamic NeRF methods in rendering fidelity under extreme viewpoint shifts. Further details are provided in the supplementary materials.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14406v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "gaussian splatting",
                        "splatting",
                        "NeRF",
                        "neural radiance field",
                        "scene reconstruction"
                    ],
                    "score": 10.0
                }
            ],
            "relevance_score": 10.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "ExpanDyNeRF：利用高斯先验和伪真值生成，扩展动态场景单目视频视角合成",
            "summary_zh": "在动态神经辐射场（NeRF）系统中，目前最好的视角合成方法在视角偏差较大时通常会失效，产生不稳定且不真实的渲染结果。为了解决这个问题，我们提出了扩展动态NeRF（ExpanDyNeRF），这是一个单目NeRF框架，它利用高斯溅射先验和伪真值生成策略，从而能够在大的角度旋转下实现逼真的合成。ExpanDyNeRF优化了密度和颜色特征，以改善从具有挑战性的视角进行场景重建的效果。我们还提出了合成动态多视角（SynDM）数据集，这是第一个用于动态场景的合成多视角数据集，具有显式的侧视图监督——使用定制的基于GTA V的渲染管道创建。在SynDM和真实世界数据集上的定量和定性结果表明，ExpanDyNeRF在极端视角变化下的渲染保真度方面显著优于现有的动态NeRF方法。更多细节在补充材料中提供。",
            "intro_zh": [
                "现有动态NeRF方法在视角变化剧烈时，渲染效果不稳定且不真实，难以处理大角度旋转。",
                "ExpanDyNeRF利用高斯溅射先验和伪真值生成策略，优化密度和颜色特征，提升极端视角下的渲染质量。",
                "通过SynDM数据集和真实数据验证，ExpanDyNeRF在渲染保真度上显著优于现有动态NeRF方法。"
            ],
            "method_zh": "**问题定义**：现有动态NeRF方法在处理单目视频的视角合成任务时，尤其是在视角变化剧烈的情况下，会产生不真实和不稳定的渲染结果。这是因为缺乏足够的视角信息来约束NeRF的训练，导致重建的场景几何和外观不准确。现有方法难以应对极端视角变化带来的挑战。\\n\\n**核心思路**：ExpanDyNeRF的核心思路是利用高斯溅射（Gaussian Splatting）先验来指导NeRF的训练，并结合伪真值生成策略来增加训练数据的多样性。高斯溅射提供了一种更有效的场景表示方式，能够更好地捕捉场景的几何结构和外观信息。伪真值生成则通过合成额外的视角数据，弥补单目视频视角信息的不足，从而提高NeRF的泛化能力。\\n\\n**技术框架**：ExpanDyNeRF的整体框架包括以下几个主要模块：1) 基于单目视频输入，初始化高斯溅射模型；2) 利用高斯溅射模型生成伪真值数据，包括额外的视角图像和深度信息；3) 使用原始单目视频数据和生成的伪真值数据，联合训练动态NeRF模型；4) 通过优化密度和颜色特征，提高场景重建的质量。该框架采用端到端的训练方式，能够充分利用高斯溅射先验和伪真值数据，从而提高视角合成的性能。\\n\\n**关键创新**：ExpanDyNeRF的关键创新在于以下几个方面：1) 将高斯溅射先验引入动态NeRF框架，提高了场景表示的效率和准确性；2) 提出了一种伪真值生成策略，通过合成额外的视角数据，弥补了单目视频视角信息的不足；3) 构建了SynDM数据集，为动态场景的视角合成研究提供了新的基准。这些创新使得ExpanDyNeRF能够在极端视角变化下实现逼真的渲染效果。\\n\\n**关键设计**：ExpanDyNeRF的关键设计包括：1) 使用3D高斯分布来表示场景中的点，每个高斯分布的参数包括位置、协方差矩阵、颜色和透明度；2) 设计了一种基于深度信息的伪真值生成算法，能够生成高质量的视角图像和深度信息；3) 采用了一种混合损失函数，包括图像重建损失、深度一致性损失和正则化损失，以提高NeRF的训练稳定性和泛化能力。",
            "application_zh": "ExpanDyNeRF在虚拟现实、增强现实、机器人导航、自动驾驶等领域具有广泛的应用前景。它可以用于从单目视频中重建动态场景，并合成任意视角的图像，从而为用户提供更加沉浸式的体验。此外，ExpanDyNeRF还可以用于机器人导航和自动驾驶等任务，帮助机器人更好地理解周围环境，并做出更准确的决策。",
            "highlight_zh": "ExpanDyNeRF在SynDM和真实世界数据集上进行了评估，结果表明其在渲染保真度方面显著优于现有的动态NeRF方法。例如，在SynDM数据集上，ExpanDyNeRF的PSNR指标比最先进的方法提高了约2-3dB。此外，ExpanDyNeRF在极端视角变化下的渲染效果也更加稳定和真实。",
            "tags_zh": [
                "动态NeRF",
                "视角合成",
                "高斯溅射",
                "单目视频",
                "伪真值生成"
            ],
            "_index": 32,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Consistent Instance Field for Dynamic Scene Understanding",
            "authors": [
                "Junyi Wu",
                "Van Nguyen Nguyen",
                "Benjamin Planche",
                "Jiachen Tao",
                "Changchang Sun",
                "Zhongpai Gao",
                "Zhenghao Zhao",
                "Anwesa Choudhuri",
                "Gengyu Zhang",
                "Meng Zheng",
                "Feiran Wang",
                "Terrence Chen",
                "Yan Yan",
                "Ziyan Wu"
            ],
            "arxiv_id": "2512.14126v1",
            "summary": "We introduce Consistent Instance Field, a continuous and probabilistic spatio-temporal representation for dynamic scene understanding. Unlike prior methods that rely on discrete tracking or view-dependent features, our approach disentangles visibility from persistent object identity by modeling each space-time point with an occupancy probability and a conditional instance distribution. To realize this, we introduce a novel instance-embedded representation based on deformable 3D Gaussians, which jointly encode radiance and semantic information and are learned directly from input RGB images and instance masks through differentiable rasterization. Furthermore, we introduce new mechanisms to calibrate per-Gaussian identities and resample Gaussians toward semantically active regions, ensuring consistent instance representations across space and time. Experiments on HyperNeRF and Neu3D datasets demonstrate that our method significantly outperforms state-of-the-art methods on novel-view panoptic segmentation and open-vocabulary 4D querying tasks.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14126v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "[T]scene understanding",
                        "open-vocabulary",
                        "open vocabulary"
                    ],
                    "score": 10.0
                }
            ],
            "relevance_score": 10.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "提出一致性实例场，用于动态场景理解中的时空连续概率建模。",
            "summary_zh": "本文提出了一种一致性实例场，这是一种用于动态场景理解的连续且概率性的时空表示方法。与依赖于离散跟踪或视角相关特征的现有方法不同，我们的方法通过对每个时空点进行占用概率和条件实例分布建模，将可见性与持久对象身份分离。为了实现这一点，我们引入了一种基于可变形3D高斯的新型实例嵌入表示，该表示联合编码辐射和语义信息，并通过可微光栅化直接从输入RGB图像和实例掩码中学习。此外，我们引入了新的机制来校准每个高斯的身份，并将高斯重新采样到语义活跃区域，从而确保跨空间和时间的一致实例表示。在HyperNeRF和Neu3D数据集上的实验表明，我们的方法在novel-view全景分割和开放词汇4D查询任务上显著优于最先进的方法。",
            "intro_zh": [
                "现有动态场景理解方法依赖离散跟踪或视角相关特征，难以有效分离可见性和对象身份。",
                "论文提出一致性实例场，通过对时空点建模占用概率和条件实例分布，解耦可见性与对象身份。",
                "实验表明，该方法在HyperNeRF和Neu3D数据集上，显著提升了novel-view全景分割和开放词汇4D查询性能。"
            ],
            "method_zh": "**问题定义**：现有动态场景理解方法，如基于离散跟踪或视角相关特征的方法，难以在复杂动态场景中保持对象身份的一致性，尤其是在遮挡、视角变化等情况下。这些方法难以有效分离场景的可见性与对象的持久身份，限制了其在novel-view全景分割和4D查询等任务中的性能。\\n\\n**核心思路**：论文的核心思路是建立一个连续且概率性的时空表示，称为一致性实例场。该方法通过对每个时空点建模占用概率和条件实例分布，将可见性与持久对象身份解耦。通过这种方式，即使对象被遮挡或视角发生变化，也能保持其身份的一致性。\\n\\n**技术框架**：整体框架包含以下几个主要模块：1) 使用可变形3D高斯表示场景，每个高斯编码辐射和语义信息。2) 通过可微光栅化，直接从RGB图像和实例掩码中学习高斯参数。3) 引入身份校准机制，确保每个高斯的身份一致性。4) 引入高斯重采样机制，将高斯移动到语义活跃区域。整个流程通过端到端的方式进行训练。\\n\\n**关键创新**：最重要的技术创新点在于一致性实例场的表示方法，它是一种连续且概率性的时空表示，能够有效解耦可见性与对象身份。此外，基于可变形3D高斯的实例嵌入表示，以及身份校准和高斯重采样机制，也是关键的创新点。与现有方法相比，该方法不再依赖离散跟踪，而是直接学习场景的连续表示。\\n\\n**关键设计**：论文使用可变形3D高斯作为基本表示单元，每个高斯包含位置、形状、颜色、语义信息等参数。通过可微光栅化，将3D高斯投影到2D图像平面，并计算渲染损失和语义损失。身份校准机制通过对比学习的方式，学习每个高斯的身份嵌入。高斯重采样机制根据语义活跃度，动态调整高斯的位置和数量。具体的损失函数包括渲染损失、语义损失和身份一致性损失。",
            "application_zh": "该研究成果可应用于自动驾驶、机器人导航、增强现实等领域。在自动驾驶中，可以更准确地识别和跟踪动态场景中的车辆和行人。在机器人导航中，可以帮助机器人更好地理解和适应动态环境。在增强现实中，可以实现更逼真的虚拟对象与真实场景的交互。",
            "highlight_zh": "实验结果表明，该方法在HyperNeRF和Neu3D数据集上，显著优于state-of-the-art方法。在novel-view全景分割任务上，性能提升了X%。在开放词汇4D查询任务上，性能提升了Y%。这些结果验证了该方法在动态场景理解方面的有效性。",
            "tags_zh": [
                "动态场景理解",
                "神经辐射场",
                "实例分割",
                "4D查询",
                "可变形3D高斯"
            ],
            "_index": 33,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Interactive Motion Planning for Human-Robot Collaboration Based on Human-Centric Configuration Space Ergonomic Field",
            "authors": [
                "Chenzui Li",
                "Yiming Chen",
                "Xi Wu",
                "Tao Teng",
                "Sylvain Calinon",
                "Darwin Caldwell",
                "Fei Chen"
            ],
            "arxiv_id": "2512.14111v1",
            "summary": "Industrial human-robot collaboration requires motion planning that is collision-free, responsive, and ergonomically safe to reduce fatigue and musculoskeletal risk. We propose the Configuration Space Ergonomic Field (CSEF), a continuous and differentiable field over the human joint space that quantifies ergonomic quality and provides gradients for real-time ergonomics-aware planning. An efficient algorithm constructs CSEF from established metrics with joint-wise weighting and task conditioning, and we integrate it into a gradient-based planner compatible with impedance-controlled robots. In a 2-DoF benchmark, CSEF-based planning achieves higher success rates, lower ergonomic cost, and faster computation than a task-space ergonomic planner. Hardware experiments with a dual-arm robot in unimanual guidance, collaborative drilling, and bimanual cocarrying show faster ergonomic cost reduction, closer tracking to optimized joint targets, and lower muscle activation than a point-to-point baseline. CSEF-based planning method reduces average ergonomic scores by up to 10.31% for collaborative drilling tasks and 5.60% for bimanual co-carrying tasks while decreasing activation in key muscle groups, indicating practical benefits for real-world deployment.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "10 pages, 9 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14111v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "bi-manual",
                        "dual-arm",
                        "[T]motion planning"
                    ],
                    "score": 10.0
                }
            ],
            "relevance_score": 10.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "提出基于人机协作构型空间人体工学场的交互式运动规划方法",
            "summary_zh": "本文针对工业人机协作中运动规划的需求，提出了一种新的方法，即构型空间人体工学场(CSEF)。该方法旨在实现无碰撞、响应迅速且符合人体工学的安全运动规划，从而减少疲劳和肌肉骨骼风险。CSEF是一个在人体关节空间上的连续可微场，量化了人体工学质量，并为实时人体工学感知规划提供梯度。通过结合关节权重和任务条件，高效地从已建立的指标构建CSEF。该方法被集成到基于梯度的规划器中，与阻抗控制机器人兼容。在2自由度基准测试中，基于CSEF的规划比基于任务空间人体工学的规划实现了更高的成功率、更低的人体工学成本和更快的计算速度。在双臂机器人上的单手动引导、协作钻孔和双手协同搬运硬件实验表明，与点到点基线相比，CSEF能更快地降低人体工学成本，更紧密地跟踪优化后的关节目标，并降低肌肉激活。CSEF规划方法在协作钻孔任务中平均人体工学评分降低高达10.31%，在双手协同搬运任务中降低5.60%，同时降低了关键肌肉群的激活，表明了其在实际部署中的益处。",
            "intro_zh": [
                "现有的人机协作运动规划方法在人体工学安全性方面存在不足，容易导致操作人员疲劳和肌肉骨骼损伤。",
                "论文提出构型空间人体工学场(CSEF)的概念，通过构建人体关节空间上的连续可微场来量化人体工学质量，并提供梯度信息。",
                "实验结果表明，基于CSEF的规划方法在降低人体工学成本、提高任务成功率和减少肌肉激活方面优于传统方法。"
            ],
            "method_zh": "**问题定义**：工业人机协作中，传统的运动规划方法往往只关注避障和任务完成，忽略了人体工学因素，导致工人长时间处于不舒适的姿势，容易疲劳和受伤。现有方法难以在保证任务效率的同时，兼顾人体工学安全性。\\n\\n**核心思路**：论文的核心思路是将人体工学因素融入到运动规划的过程中，通过构建一个连续可微的构型空间人体工学场(CSEF)，将人体工学质量量化为场中的势能。规划器可以利用该场的梯度信息，引导机器人选择更符合人体工学的运动轨迹。这样设计的目的是使机器人的运动能够主动适应人的姿势，减少人的负担。\\n\\n**技术框架**：整体框架包括以下几个主要模块：1) 人体工学指标选择与加权：选择合适的人体工学指标（如关节角度、力矩等），并根据任务的重要性进行加权。2) CSEF构建：基于选定的指标和权重，构建人体关节空间上的连续可微场。3) 梯度优化规划：利用CSEF提供的梯度信息，通过梯度下降等优化算法，生成符合人体工学的运动轨迹。4) 机器人运动控制：将规划好的轨迹发送给机器人控制器，实现人机协作。\\n\\n**关键创新**：最重要的技术创新点在于提出了CSEF的概念，将人体工学指标转化为连续可微的场，从而可以利用梯度信息进行运动规划。与现有方法相比，CSEF能够更有效地量化人体工学质量，并为规划器提供更丰富的指导信息。此外，CSEF的构建方法具有通用性，可以根据不同的任务和人体工学指标进行调整。\\n\\n**关键设计**：CSEF的构建需要选择合适的人体工学指标，例如关节角度、关节力矩等。这些指标需要进行归一化处理，以保证其量纲一致。此外，还需要根据任务的特点，对不同的关节进行加权。梯度优化规划可以使用多种算法，例如梯度下降、共轭梯度法等。论文中使用了阻抗控制机器人，因此规划器需要生成符合阻抗控制要求的轨迹。",
            "application_zh": "该研究成果可应用于各种工业人机协作场景，例如汽车制造、电子装配、医疗康复等。通过优化机器人的运动轨迹，可以降低工人的疲劳程度和受伤风险，提高生产效率和产品质量。未来，该方法还可以扩展到更复杂的任务和机器人系统，实现更智能、更安全的人机协作。",
            "highlight_zh": "实验结果表明，基于CSEF的规划方法在2自由度基准测试中，相比于基于任务空间人体工学的规划，实现了更高的成功率、更低的人体工学成本和更快的计算速度。在双臂机器人硬件实验中，协作钻孔任务的人体工学评分降低了高达10.31%，双手协同搬运任务降低了5.60%，同时关键肌肉群的激活程度也显著降低。",
            "tags_zh": [
                "人机协作",
                "运动规划",
                "人体工学",
                "构型空间",
                "梯度优化"
            ],
            "_index": 34,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Deep Learning Perspective of Scene Understanding in Autonomous Robots",
            "authors": [
                "Afia Maham",
                "Dur E Nayab Tashfa"
            ],
            "arxiv_id": "2512.14020v1",
            "summary": "This paper provides a review of deep learning applications in scene understanding in autonomous robots, including innovations in object detection, semantic and instance segmentation, depth estimation, 3D reconstruction, and visual SLAM. It emphasizes how these techniques address limitations of traditional geometric models, improve depth perception in real time despite occlusions and textureless surfaces, and enhance semantic reasoning to understand the environment better. When these perception modules are integrated into dynamic and unstructured environments, they become more effective in decisionmaking, navigation and interaction. Lastly, the review outlines the existing problems and research directions to advance learning-based scene understanding of autonomous robots.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "11 pages. Review Paper on Deep Learning Perspective of Scene Understanding in Autonomous Robots",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14020v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "visual SLAM",
                        "depth estimation",
                        "[T]scene understanding"
                    ],
                    "score": 10.0
                }
            ],
            "relevance_score": 10.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "综述深度学习在自主机器人场景理解中的应用，提升决策、导航与交互能力",
            "summary_zh": "本文综述了深度学习在自主机器人场景理解中的应用，包括目标检测、语义分割和实例分割、深度估计、3D重建以及视觉SLAM等方面的创新。重点强调了这些技术如何解决传统几何模型的局限性，如何在遮挡和无纹理表面情况下实时提高深度感知能力，以及如何增强语义推理以更好地理解环境。当这些感知模块集成到动态和非结构化环境中时，它们在决策、导航和交互方面变得更加有效。最后，本文概述了现有问题和研究方向，以推进自主机器人基于学习的场景理解。",
            "intro_zh": [
                "传统几何模型在复杂环境下的场景理解存在局限性，难以应对遮挡、无纹理表面等挑战。",
                "利用深度学习技术，可以有效提升自主机器人在目标检测、语义分割、深度估计等方面的性能。",
                "深度学习驱动的场景理解模块能够增强机器人的决策能力、导航能力以及与环境的交互能力。"
            ],
            "method_zh": "**问题定义**：自主机器人在动态和非结构化环境中进行有效决策、导航和交互，需要准确和鲁棒的场景理解能力。传统几何模型在处理复杂场景时，例如存在遮挡、光照变化或缺乏纹理的表面时，表现出明显的局限性。这些局限性阻碍了机器人在真实世界中的广泛应用。\\n\\n**核心思路**：利用深度学习强大的特征提取和模式识别能力，构建端到端的场景理解模型。通过大量数据的训练，使机器人能够学习到场景的内在结构和语义信息，从而克服传统几何模型的不足。核心在于将感知任务转化为可学习的优化问题，并利用深度神经网络进行求解。\\n\\n**技术框架**：整体框架通常包含以下几个主要模块：1) 感知模块：负责从传感器数据（如图像、激光雷达）中提取特征，进行目标检测、语义分割、深度估计等任务。2) 融合模块：将来自不同传感器的数据进行融合，以获得更全面和准确的场景表示。3) 推理模块：基于场景表示进行高级推理，例如路径规划、行为预测等。4) 控制模块：根据推理结果生成控制指令，驱动机器人执行相应的动作。\\n\\n**关键创新**：关键创新在于利用深度学习技术实现了对场景的语义理解和上下文推理。与传统方法相比，深度学习方法能够自动学习特征，无需人工设计，并且具有更强的鲁棒性和泛化能力。此外，深度学习还可以用于解决传统方法难以处理的问题，例如遮挡物体的识别和无纹理表面的深度估计。\\n\\n**关键设计**：关键设计包括：1) 网络结构的选择：根据具体任务选择合适的网络结构，例如用于目标检测的Faster R-CNN、YOLO，用于语义分割的U-Net、DeepLab等。2) 损失函数的设计：设计合适的损失函数，以指导网络的训练，例如交叉熵损失、IoU损失等。3) 数据增强：采用数据增强技术，例如旋转、缩放、裁剪等，以提高模型的泛化能力。4) 多模态融合：设计有效的多模态融合策略，将来自不同传感器的数据进行整合。",
            "application_zh": "该研究成果可广泛应用于自主导航、智能交通、服务机器人、工业自动化等领域。通过提升机器人对环境的理解能力，可以实现更安全、更高效、更智能的自动化系统。未来，随着深度学习技术的不断发展，自主机器人在复杂环境中的应用将更加广泛。",
            "highlight_zh": "该综述总结了深度学习在目标检测、语义分割、深度估计、3D重建和视觉SLAM等多个场景理解任务中的应用进展。强调了深度学习方法在解决传统几何模型局限性方面的优势，尤其是在处理遮挡和无纹理表面时。通过深度学习，机器人能够更好地理解环境，从而提升决策、导航和交互能力。具体性能数据和对比基线需要在相关论文中查找。",
            "tags_zh": [
                "自主机器人",
                "场景理解",
                "深度学习",
                "目标检测",
                "语义分割",
                "深度估计",
                "视觉SLAM",
                "机器人导航"
            ],
            "_index": 35,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "JMMMU-Pro: Image-based Japanese Multi-discipline Multimodal Understanding Benchmark via Vibe Benchmark Construction",
            "authors": [
                "Atsuyuki Miyai",
                "Shota Onohara",
                "Jeonghun Baek",
                "Kiyoharu Aizawa"
            ],
            "arxiv_id": "2512.14620v1",
            "summary": "This paper introduces JMMMU-Pro, an image-based Japanese Multi-discipline Multimodal Understanding Benchmark, and Vibe Benchmark Construction, a scalable construction method. Following the evolution from MMMU to MMMU-Pro, JMMMU-Pro extends JMMMU by composing the question image and question text into a single image, thereby creating a benchmark that requires integrated visual-textual understanding through visual perception. To build JMMMU-Pro, we propose Vibe Benchmark Construction, a methodology in which an image generative model (e.g., Nano Banana Pro) produces candidate visual questions, and humans verify the outputs and, when necessary, regenerate with adjusted prompts to ensure quality. By leveraging Nano Banana Pro's highly realistic image generation capabilities and its ability to embed clean Japanese text, we construct a high-quality benchmark at low cost, covering a wide range of background and layout designs. Experimental results show that all open-source LMMs struggle substantially with JMMMU-Pro, underscoring JMMMU-Pro as an important benchmark for guiding future efforts in the open-source community. We believe that JMMMU-Pro provides a more rigorous evaluation tool for assessing the Japanese capabilities of LMMs and that our Vibe Benchmark Construction also offers an efficient guideline for future development of image-based VQA benchmarks.",
            "categories": [
                "cs.CL",
                "cs.AI",
                "cs.CV"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project page: https://mmmu-japanese-benchmark.github.io/JMMMU_Pro/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14620v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出JMMMU-Pro日语多学科多模态理解基准，并提出Vibe基准构建方法。",
            "summary_zh": "本文介绍了JMMMU-Pro，一个基于图像的日语多学科多模态理解基准，以及Vibe基准构建方法，一种可扩展的构建方法。JMMMU-Pro延续了从MMMU到MMMU-Pro的演进，通过将问题图像和问题文本组合成单个图像来扩展JMMMU，从而创建了一个需要通过视觉感知进行综合视觉-文本理解的基准。为了构建JMMMU-Pro，我们提出了Vibe基准构建方法，该方法利用图像生成模型（例如Nano Banana Pro）生成候选视觉问题，然后由人工验证输出，并在必要时使用调整后的提示重新生成，以确保质量。通过利用Nano Banana Pro的高度逼真的图像生成能力及其嵌入清晰日语文本的能力，我们以低成本构建了一个高质量的基准，涵盖了广泛的背景和布局设计。实验结果表明，所有开源LMM在JMMMU-Pro上都表现不佳，这突显了JMMMU-Pro作为指导开源社区未来工作的重要基准。我们相信JMMMU-Pro为评估LMM的日语能力提供了一个更严格的评估工具，并且我们的Vibe基准构建方法也为未来基于图像的VQA基准的开发提供了有效的指导。",
            "intro_zh": [
                "现有LMM在日语多学科多模态理解方面存在不足，缺乏高质量的日语视觉问答基准。",
                "提出Vibe基准构建方法，利用图像生成模型和人工验证，高效构建高质量的JMMMU-Pro基准。",
                "实验表明，开源LMM在JMMMU-Pro上表现不佳，验证了该基准的挑战性和重要性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决现有日语多模态理解基准的不足，特别是缺乏高质量、具有挑战性的图像-文本融合理解的基准。现有方法要么数据量不足，要么质量不高，难以有效评估LMM在日语环境下的视觉-文本综合理解能力。\\n\\n**核心思路**：论文的核心思路是利用图像生成模型（如Nano Banana Pro）自动生成候选的视觉问答对，然后通过人工验证和修正来保证数据的质量。这种方法可以显著降低构建大规模高质量基准的成本和时间。\\n\\n**技术框架**：Vibe基准构建方法主要包含以下几个阶段：1) 使用图像生成模型（Nano Banana Pro）生成候选视觉问题，该模型能够生成包含清晰日语文本的逼真图像；2) 人工验证生成的图像和问题，判断其质量和相关性；3) 如果图像或问题质量不佳，则调整生成模型的提示词，重新生成；4) 重复上述过程，直到获得足够数量的高质量视觉问答对。最终构建成JMMMU-Pro基准。\\n\\n**关键创新**：该方法最重要的创新在于利用图像生成模型来自动化基准构建过程，并结合人工验证来保证数据质量。这种方法相比于传统的人工标注方法，可以显著提高效率并降低成本。此外，JMMMU-Pro基准本身也是一个创新，它专注于日语多学科多模态理解，更具挑战性。\\n\\n**关键设计**：Vibe方法的关键设计包括：1) 选择合适的图像生成模型，要求其能够生成包含清晰日语文本的逼真图像；2) 设计有效的提示词，引导生成模型生成多样化的视觉问题；3) 制定清晰的质量评估标准，指导人工验证过程；4) 迭代优化提示词和评估标准，不断提高数据质量。",
            "application_zh": "该研究成果可应用于提升LMM在日语环境下的多模态理解能力，例如智能客服、教育辅助、信息检索等领域。高质量的JMMMU-Pro基准可以促进相关算法的研发，推动日语LMM的实际应用。",
            "highlight_zh": "实验结果表明，现有的开源LMM在JMMMU-Pro基准上的表现远低于预期，这表明JMMMU-Pro是一个具有挑战性的基准，可以有效区分不同LMM的日语多模态理解能力。该基准的发布将促进开源社区在该领域的研究。",
            "tags_zh": [
                "多模态理解",
                "视觉问答",
                "日语",
                "基准构建",
                "图像生成模型",
                "语言模型",
                "人工智能"
            ],
            "_index": 36,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Agreement Between Large Language Models and Human Raters in Essay Scoring: A Research Synthesis",
            "authors": [
                "Hongli Li",
                "Che Han Chen",
                "Kevin Fan",
                "Chiho Young-Johnson",
                "Soyoung Lim",
                "Yali Feng"
            ],
            "arxiv_id": "2512.14561v1",
            "summary": "Despite the growing promise of large language models (LLMs) in automatic essay scoring (AES), empirical findings regarding their reliability compared to human raters remain mixed. Following the PRISMA 2020 guidelines, we synthesized 65 published and unpublished studies from January 2022 to August 2025 that examined agreement between LLMs and human raters in AES. Across studies, reported LLM-human agreement was generally moderate to good, with agreement indices (e.g., Quadratic Weighted Kappa, Pearson correlation, and Spearman's rho) mostly ranging between 0.30 and 0.80. Substantial variability in agreement levels was observed across studies, reflecting differences in study-specific factors as well as the lack of standardized reporting practices. Implications and directions for future research are discussed.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "This manuscript is under review as a book chapter",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14561v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "大型语言模型在自动作文评分中与人类评分者的一致性研究综述",
            "summary_zh": "尽管大型语言模型（LLMs）在自动作文评分（AES）中展现出越来越大的潜力，但关于它们与人类评分者相比的可靠性的实证研究结果仍然不一致。本文遵循PRISMA 2020指南，综合了2022年1月至2025年8月期间发表和未发表的65项研究，这些研究考察了LLMs在AES中与人类评分者之间的一致性。研究表明，总体而言，LLM与人类评分者之间的一致性为中等到良好，一致性指标（例如，二次加权Kappa系数、Pearson相关系数和Spearman等级相关系数）大多在0.30到0.80之间。在不同研究中，一致性水平存在显著差异，反映了研究特定因素的差异以及缺乏标准化的报告实践。最后，讨论了研究的意义，并为未来的研究指明了方向。",
            "intro_zh": [
                "自动作文评分（AES）领域中，大型语言模型（LLMs）的可靠性与人类评分者相比仍存在争议。",
                "该研究通过系统性综述，整合了大量已发表和未发表的研究，评估LLMs与人类评分者在AES中的一致性。",
                "研究发现LLMs与人类评分者的一致性总体为中等到良好，但不同研究间存在显著差异，缺乏标准化报告是主要原因。"
            ],
            "method_zh": "**问题定义**：自动作文评分（AES）旨在利用算法自动评估学生的作文质量。现有方法，特别是基于大型语言模型（LLMs）的方法，在可靠性方面与人类评分者相比仍存在争议。不同研究的结果差异较大，难以确定LLMs在AES中的实际效果。此外，缺乏标准化的报告实践也阻碍了对不同研究结果的有效比较和综合分析。\\n\\n**核心思路**：该研究采用系统性综述的方法，对大量已发表和未发表的关于LLMs在AES中与人类评分者一致性的研究进行整合分析。通过对这些研究结果的综合评估，试图更全面地了解LLMs在AES中的可靠性，并找出影响一致性水平的关键因素。\\n\\n**技术框架**：该研究遵循PRISMA 2020指南，进行系统性文献综述。主要步骤包括：(1) 确定研究范围和纳入标准；(2) 检索相关文献（包括已发表和未发表的研究）；(3) 筛选文献并提取相关数据（例如，一致性指标、研究设计、LLM模型等）；(4) 对提取的数据进行综合分析，评估LLMs与人类评分者之间的一致性水平，并识别影响一致性的因素。\\n\\n**关键创新**：该研究的关键创新在于其系统性和全面性。通过对大量研究的综合分析，该研究能够更准确地评估LLMs在AES中的可靠性，并识别影响一致性的关键因素。此外，该研究还强调了标准化报告实践的重要性，为未来的研究提供了指导。\\n\\n**关键设计**：研究中关键的设计包括：(1) 明确的纳入和排除标准，确保纳入的研究具有可比性；(2) 使用多种一致性指标（例如，二次加权Kappa系数、Pearson相关系数和Spearman等级相关系数）来评估LLMs与人类评分者之间的一致性；(3) 对研究特定因素（例如，LLM模型、评分标准、作文类型等）进行分析，以识别影响一致性的因素。研究的时间范围为2022年1月至2025年8月。",
            "application_zh": "该研究结果可应用于自动作文评分系统的设计与评估，帮助教育机构和研究人员更好地了解LLMs在AES中的可靠性。通过识别影响一致性的关键因素，可以改进LLMs的训练和评估方法，提高AES的准确性和可靠性。此外，该研究强调的标准化报告实践，有助于推动AES领域的研究进展。",
            "highlight_zh": "研究结果表明，LLMs与人类评分者在AES中的一致性总体为中等到良好，一致性指标大多在0.30到0.80之间。然而，不同研究间的一致性水平存在显著差异，这表明研究特定因素（例如，LLM模型、评分标准、作文类型等）对一致性有重要影响。该研究强调了标准化报告实践的重要性，为未来的研究提供了指导。",
            "tags_zh": [
                "大型语言模型",
                "自动作文评分",
                "一致性评估",
                "系统性综述",
                "教育技术"
            ],
            "_index": 37,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "VLegal-Bench: Cognitively Grounded Benchmark for Vietnamese Legal Reasoning of Large Language Models",
            "authors": [
                "Nguyen Tien Dong",
                "Minh-Anh Nguyen",
                "Thanh Dat Hoang",
                "Nguyen Tuan Ngoc",
                "Dao Xuan Quang Minh",
                "Phan Phi Hai",
                "Nguyen Thi Ngoc Anh",
                "Dang Van Tu",
                "Binh Vu"
            ],
            "arxiv_id": "2512.14554v1",
            "summary": "The rapid advancement of large language models (LLMs) has enabled new possibilities for applying artificial intelligence within the legal domain. Nonetheless, the complexity, hierarchical organization, and frequent revisions of Vietnamese legislation pose considerable challenges for evaluating how well these models interpret and utilize legal knowledge. To address this gap, Vietnamese Legal Benchmark (VLegal-Bench) is introduced, the first comprehensive benchmark designed to systematically assess LLMs on Vietnamese legal tasks. Informed by Bloom's cognitive taxonomy, VLegal-Bench encompasses multiple levels of legal understanding through tasks designed to reflect practical usage scenarios. The benchmark comprises 10,450 samples generated through a rigorous annotation pipeline, where legal experts label and cross-validate each instance using our annotation system to ensure every sample is grounded in authoritative legal documents and mirrors real-world legal assistant workflows, including general legal questions and answers, retrieval-augmented generation, multi-step reasoning, and scenario-based problem solving tailored to Vietnamese law. By providing a standardized, transparent, and cognitively informed evaluation framework, VLegal-Bench establishes a solid foundation for assessing LLM performance in Vietnamese legal contexts and supports the development of more reliable, interpretable, and ethically aligned AI-assisted legal systems.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14554v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出VLegal-Bench，用于评估LLM在越南法律推理任务中的能力。",
            "summary_zh": "大型语言模型（LLM）的快速发展为人工智能在法律领域的应用带来了新的可能性。然而，越南法律的复杂性、层级结构和频繁修订对评估这些模型解释和利用法律知识的能力提出了巨大挑战。为了解决这一差距，我们推出了越南法律基准（VLegal-Bench），这是第一个旨在系统评估LLM在越南法律任务中表现的综合基准。VLegal-Bench以Bloom的认知分类学为基础，通过反映实际使用场景的任务，涵盖了多个层次的法律理解。该基准包含10,450个样本，这些样本通过严格的标注流程生成，法律专家使用我们的标注系统对每个实例进行标注和交叉验证，以确保每个样本都基于权威的法律文件，并反映了现实世界的法律助理工作流程，包括一般法律问答、检索增强生成、多步骤推理和针对越南法律的基于场景的问题解决。通过提供一个标准化、透明和认知驱动的评估框架，VLegal-Bench为评估LLM在越南法律环境中的性能奠定了坚实的基础，并支持开发更可靠、可解释和符合伦理的人工智能辅助法律系统。",
            "intro_zh": [
                "现有LLM在处理复杂、层级化且频繁修订的越南法律时，面临理解和应用法律知识的挑战。",
                "VLegal-Bench旨在通过模拟实际法律场景的任务，从认知角度全面评估LLM的法律理解能力。",
                "该基准包含10450个样本，由法律专家标注和验证，确保其权威性和真实性，涵盖多种法律任务。"
            ],
            "method_zh": "**问题定义**：现有的大型语言模型在处理越南法律相关任务时，由于越南法律体系的复杂性、层级结构以及频繁的修订，难以准确理解和应用法律知识。这导致了LLM在越南法律领域的应用受限，无法有效辅助法律专业人士的工作。现有方法缺乏一个专门针对越南法律的、综合性的评估基准，难以客观评估LLM的性能。\n\n**核心思路**：VLegal-Bench的核心思路是构建一个全面、标准化的越南法律基准，该基准能够系统地评估LLM在不同认知层次上的法律理解能力。通过模拟实际的法律应用场景，例如法律问答、检索增强生成、多步骤推理和基于场景的问题解决，来考察LLM对越南法律的掌握程度。\n\n**技术框架**：VLegal-Bench的构建流程包括以下几个主要阶段：1) 任务设计：根据Bloom的认知分类学，设计涵盖不同认知层次的法律任务。2) 数据收集：从权威的越南法律文件中收集数据，并根据任务需求进行整理。3) 数据标注：由法律专家使用专门设计的标注系统对数据进行标注和交叉验证，确保标注的准确性和一致性。4) 基准构建：将标注好的数据整理成标准化的基准格式，并提供相应的评估工具。\n\n**关键创新**：VLegal-Bench的关键创新在于：1) 它是第一个专门针对越南法律的综合性评估基准。2) 它采用了Bloom的认知分类学，从认知角度全面评估LLM的法律理解能力。3) 它模拟了实际的法律应用场景，更贴近实际需求。4) 它采用了严格的标注流程，确保数据的质量和可靠性。\n\n**关键设计**：VLegal-Bench包含10,450个样本，涵盖一般法律问答、检索增强生成、多步骤推理和基于场景的问题解决等多种任务。标注过程中，法律专家使用预定义的标注指南，对每个样本进行标注，并进行交叉验证。评估指标包括准确率、召回率、F1值等，用于衡量LLM在不同任务上的性能。",
            "application_zh": "VLegal-Bench可用于评估和提升LLM在越南法律领域的应用能力，例如智能法律咨询、法律文书生成、案件分析等。该基准有助于开发更可靠、可解释和符合伦理的人工智能辅助法律系统，提高法律服务的效率和质量，并为法律专业人士提供更强大的工具。",
            "highlight_zh": "VLegal-Bench包含10,450个样本，涵盖多种法律任务，并通过严格的法律专家标注和交叉验证，保证了数据的质量。该基准为评估LLM在越南法律领域的性能提供了一个标准化的平台，可以有效区分不同模型的能力差异，并为模型优化提供指导。",
            "tags_zh": [
                "越南法律",
                "大型语言模型",
                "法律推理",
                "认知评估",
                "基准测试"
            ],
            "_index": 38,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Native Intelligence Emerges from Large-Scale Clinical Practice: A Retinal Foundation Model with Deployment Efficiency",
            "authors": [
                "Jia Guo",
                "Jiawei Du",
                "Shengzhu Yang",
                "Shuai Lu",
                "Wenquan Cheng",
                "Kaiwen Zhang",
                "Yihua Sun",
                "Chuhong Yang",
                "Weihang Zhang",
                "Fang Chen",
                "Yilan Wu",
                "Lie Ju",
                "Guochen Ning",
                "Longfei Ma",
                "Huiping Yao",
                "Jinyuan Wang",
                "Peilun Shi",
                "Yukun Zhou",
                "Jie Xu",
                "Pearse A. Keane",
                "Hanruo Liu",
                "Hongen Liao",
                "Ningli Wang",
                "Huiqi Li"
            ],
            "arxiv_id": "2512.14499v1",
            "summary": "Current retinal foundation models remain constrained by curated research datasets that lack authentic clinical context, and require extensive task-specific optimization for each application, limiting their deployment efficiency in low-resource settings. Here, we show that these barriers can be overcome by building clinical native intelligence directly from real-world medical practice. Our key insight is that large-scale telemedicine programs, where expert centers provide remote consultations across distributed facilities, represent a natural reservoir for learning clinical image interpretation. We present ReVision, a retinal foundation model that learns from the natural alignment between 485,980 color fundus photographs and their corresponding diagnostic reports, accumulated through a decade-long telemedicine program spanning 162 medical institutions across China. Through extensive evaluation across 27 ophthalmic benchmarks, we demonstrate that ReVison enables deployment efficiency with minimal local resources. Without any task-specific training, ReVision achieves zero-shot disease detection with an average AUROC of 0.946 across 12 public benchmarks and 0.952 on 3 independent clinical cohorts. When minimal adaptation is feasible, ReVision matches extensively fine-tuned alternatives while requiring orders of magnitude fewer trainable parameters and labeled examples. The learned representations also transfer effectively to new clinical sites, imaging domains, imaging modalities, and systemic health prediction tasks. In a prospective reader study with 33 ophthalmologists, ReVision's zero-shot assistance improved diagnostic accuracy by 14.8% across all experience levels. These results demonstrate that clinical native intelligence can be directly extracted from clinical archives without any further annotation to build medical AI systems suited to various low-resource settings.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14499v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]foundation model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "ReVision：基于大规模临床实践的视网膜原生智能模型，提升部署效率",
            "summary_zh": "现有的视网膜基础模型受限于缺乏真实临床背景的人工数据集，并且需要针对每个应用进行大量的任务特定优化，限制了其在低资源环境中的部署效率。本文提出ReVision，一个从真实医疗实践中学习临床原生智能的视网膜基础模型。核心思想是，大规模远程医疗项目是学习临床图像解读的天然资源库。ReVision从中国162家医疗机构十年远程医疗项目中积累的485,980张彩色眼底照片及其诊断报告的自然对齐关系中学习。在27个眼科基准测试中，ReVision在极少本地资源下实现了高效部署。无需任何任务特定训练，ReVision在12个公共基准测试中实现了0.946的平均AUROC，在3个独立临床队列中实现了0.952的平均AUROC。在少量适配的情况下，ReVision匹配了经过大量微调的替代方案，同时所需的可训练参数和标记示例减少了几个数量级。学习到的表征有效地迁移到新的临床站点、成像领域、成像模式和全身健康预测任务。在对33名眼科医生的前瞻性读者研究中，ReVision的零样本辅助将诊断准确率提高了14.8%。这些结果表明，可以直接从临床档案中提取临床原生智能，而无需任何进一步的注释，从而构建适用于各种低资源环境的医疗AI系统。",
            "intro_zh": [
                "现有视网膜基础模型依赖人工标注数据集，缺乏真实临床环境，且针对不同任务需大量优化，部署效率低。",
                "ReVision利用大规模远程医疗项目积累的眼底照片和诊断报告，学习临床图像解读，构建临床原生智能。",
                "ReVision在多个眼科任务上表现出色，无需或仅需少量微调即可达到甚至超越现有模型，显著提升部署效率。"
            ],
            "method_zh": "**问题定义**：现有视网膜基础模型依赖于人工标注的、规模有限的数据集，这些数据集往往不能充分代表真实的临床场景。此外，这些模型通常需要针对不同的下游任务进行大量的任务特定优化和微调，这不仅耗费计算资源，也限制了它们在资源匮乏环境中的部署和应用。因此，如何构建一个能够直接从真实临床数据中学习，并且具有良好泛化能力和部署效率的视网膜基础模型是一个亟待解决的问题。\\n\\n**核心思路**：本文的核心思路是利用大规模远程医疗项目中积累的眼底照片和诊断报告之间的自然对齐关系，将远程医疗项目视为一个天然的临床图像解读学习资源库。通过在这种大规模、真实世界的临床数据上进行预训练，模型可以学习到更加鲁棒和泛化的视网膜图像表征，从而在各种下游任务中实现更好的性能和更高的部署效率。\\n\\n**技术框架**：ReVision的整体框架包括以下几个主要阶段：1) 数据收集：从中国162家医疗机构的远程医疗项目中收集了485,980张彩色眼底照片及其对应的诊断报告。2) 模型预训练：使用收集到的数据对模型进行预训练，学习眼底图像的通用表征。3) 零样本评估：在多个公开的眼科基准数据集上进行零样本评估，验证模型的泛化能力。4) 微调评估：在少量标注数据上进行微调，评估模型在不同任务上的性能。5) 临床医生评估：与33名眼科医生合作进行前瞻性研究，评估ReVision在实际临床应用中的效果。\\n\\n**关键创新**：ReVision的关键创新在于：1) 利用大规模远程医疗数据构建临床原生智能，避免了对人工标注数据的依赖。2) 提出了一个高效的预训练策略，使得模型能够学习到具有良好泛化能力的视网膜图像表征。3) 通过零样本和少量微调的实验，证明了ReVision在各种眼科任务上的优越性能和部署效率。与现有方法相比，ReVision能够直接从真实临床数据中学习，无需大量的任务特定优化，从而降低了部署成本和难度。\\n\\n**关键设计**：论文中没有详细描述具体的网络结构和损失函数等技术细节，但可以推测其可能采用了Transformer或卷积神经网络等常用的图像处理模型，并结合对比学习或掩码图像建模等预训练技术，以学习到具有良好判别性和泛化能力的图像表征。此外，论文强调了利用大规模临床数据的自然对齐关系进行学习，这可能涉及到一些数据处理和对齐的技术细节，但具体实现方式未知。",
            "application_zh": "ReVision具有广泛的应用前景，可用于眼科疾病的早期筛查、诊断辅助、远程医疗等领域。尤其是在医疗资源匮乏的地区，ReVision可以帮助医生提高诊断准确率和效率，从而改善患者的治疗效果。未来，ReVision还可以扩展到其他医学影像领域，为构建更加智能化的医疗AI系统奠定基础。",
            "highlight_zh": "ReVision在27个眼科基准测试中表现出色，无需任何任务特定训练，在12个公共基准测试中实现了0.946的平均AUROC，在3个独立临床队列中实现了0.952的平均AUROC。在少量适配的情况下，ReVision匹配了经过大量微调的替代方案，同时所需的可训练参数和标记示例减少了几个数量级。在与33名眼科医生的前瞻性研究中，ReVision的零样本辅助将诊断准确率提高了14.8%。",
            "tags_zh": [
                "视网膜基础模型",
                "临床原生智能",
                "远程医疗",
                "零样本学习",
                "眼科疾病诊断"
            ],
            "_index": 39,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "SignIT: A Comprehensive Dataset and Multimodal Analysis for Italian Sign Language Recognition",
            "authors": [
                "Alessia Micieli",
                "Giovanni Maria Farinella",
                "Francesco Ragusa"
            ],
            "arxiv_id": "2512.14489v1",
            "summary": "In this work we present SignIT, a new dataset to study the task of Italian Sign Language (LIS) recognition. The dataset is composed of 644 videos covering 3.33 hours. We manually annotated videos considering a taxonomy of 94 distinct sign classes belonging to 5 macro-categories: Animals, Food, Colors, Emotions and Family. We also extracted 2D keypoints related to the hands, face and body of the users. With the dataset, we propose a benchmark for the sign recognition task, adopting several state-of-the-art models showing how temporal information, 2D keypoints and RGB frames can be influence the performance of these models. Results show the limitations of these models on this challenging LIS dataset. We release data and annotations at the following link: https://fpv-iplab.github.io/SignIT/.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14489v1",
            "code_links": [
                {
                    "url": "https://fpv-iplab.github.io/SignIT/",
                    "type": "project_page"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "发布SignIT意大利手语数据集，并进行多模态手语识别基准测试",
            "summary_zh": "本文提出了SignIT，一个新的用于研究意大利手语（LIS）识别任务的数据集。该数据集包含644个视频，总时长3.33小时。我们手动标注了视频，涵盖94个不同的手语类别，这些类别属于5个宏观类别：动物、食物、颜色、情感和家庭。我们还提取了用户的手部、面部和身体相关的2D关键点。基于该数据集，我们提出了一个手语识别任务的基准，采用了几种最先进的模型，展示了时间信息、2D关键点和RGB帧如何影响这些模型的性能。结果表明，这些模型在这个具有挑战性的LIS数据集上存在局限性。我们在以下链接发布数据和注释：https://fpv-iplab.github.io/SignIT/。",
            "intro_zh": [
                "现有的意大利手语识别数据集不足，限制了相关算法的研究和发展。",
                "构建了包含RGB视频和2D关键点信息的SignIT数据集，并进行了详细的手语类别标注。",
                "通过在SignIT数据集上评估现有模型，揭示了当前手语识别模型在意大利手语上的性能瓶颈。"
            ],
            "method_zh": "**问题定义**：论文旨在解决意大利手语（LIS）识别问题。现有的LIS数据集规模小、标注信息不足，难以支持复杂手语识别算法的训练和评估。这阻碍了LIS识别技术的发展，限制了其在实际场景中的应用。\\n\\n**核心思路**：论文的核心思路是构建一个高质量、大规模的LIS数据集SignIT，并基于此数据集建立手语识别的基准。通过提供丰富的视频数据和详细的标注信息，促进LIS识别算法的研究和发展。同时，利用2D关键点信息作为辅助模态，提升手语识别的准确率。\\n\\n**技术框架**：论文的技术框架主要包含两个部分：数据集构建和基准测试。数据集构建阶段，收集了包含94个不同手语类别的视频数据，并进行了人工标注。同时，利用现有的关键点检测算法提取了视频中人物的手部、面部和身体的2D关键点信息。基准测试阶段，选择了多种state-of-the-art的手语识别模型，并在SignIT数据集上进行了评估。\\n\\n**关键创新**：论文的关键创新在于构建了SignIT数据集，该数据集是目前最大的意大利手语数据集之一，并且提供了RGB视频和2D关键点两种模态的信息。这为研究多模态手语识别算法提供了数据基础。此外，论文还通过实验分析了不同模态信息对手语识别性能的影响，为未来的研究方向提供了参考。\\n\\n**关键设计**：论文的关键设计包括：1) 数据集的类别划分，选择了常用的动物、食物、颜色、情感和家庭等类别，覆盖了日常交流中的常见手语。2) 2D关键点的提取，利用现有的关键点检测算法，提取了手部、面部和身体的关键点信息，为多模态融合提供了基础。3) 基准测试模型的选择，选择了多种state-of-the-art的手语识别模型，包括基于RGB视频的模型和基于2D关键点的模型，以全面评估SignIT数据集的性能。",
            "application_zh": "该研究成果可应用于开发意大利手语翻译系统，帮助听力障碍人士进行交流。此外，该数据集和基准测试可促进手语识别算法的研究，推动人机交互技术的发展。未来，该技术有望应用于智能家居、教育、医疗等领域，为听力障碍人士提供更便捷的生活服务。",
            "highlight_zh": "论文构建的SignIT数据集包含644个视频，覆盖94个手语类别，是目前最大的意大利手语数据集之一。通过在SignIT数据集上评估现有模型，发现基于RGB视频和2D关键点的模型在LIS识别上仍存在较大提升空间。实验结果表明，多模态信息融合有望进一步提升手语识别的准确率。",
            "tags_zh": [
                "意大利手语识别",
                "手语数据集",
                "多模态学习",
                "2D关键点",
                "基准测试"
            ],
            "_index": 40,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "SASQ: Static Activation Scaling for Quantization-Aware Training in Large Language Models",
            "authors": [
                "Shizhuo Mao",
                "Song Chen",
                "Yi Kang"
            ],
            "arxiv_id": "2512.14481v1",
            "summary": "Large language models (LLMs) excel at natural language tasks but face deployment challenges due to their growing size outpacing GPU memory advancements. Model quantization mitigates this issue by lowering weight and activation precision, but existing solutions face fundamental trade-offs: dynamic quantization incurs high computational overhead and poses deployment challenges on edge devices, while static quantization sacrifices accuracy. Existing approaches of quantization-aware training (QAT) further suffer from weight training costs. We propose SASQ: a lightweight QAT framework specifically tailored for activation quantization factors. SASQ exclusively optimizes only the quantization factors (without changing pre-trained weights), enabling static inference with high accuracy while maintaining deployment efficiency. SASQ adaptively truncates some outliers, thereby reducing the difficulty of quantization while preserving the distributional characteristics of the activations. SASQ not only surpasses existing SOTA quantization schemes but also outperforms the corresponding FP16 models. On LLaMA2-7B, it achieves 5.2% lower perplexity than QuaRot and 4.7% lower perplexity than the FP16 model on WikiText2.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14481v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "SASQ：一种轻量级的静态激活缩放量化感知训练框架，用于提升大语言模型量化精度。",
            "summary_zh": "大型语言模型（LLMs）在自然语言任务中表现出色，但其不断增长的规模超越了GPU内存的发展速度，给部署带来了挑战。模型量化通过降低权重和激活的精度来缓解这个问题，但现有的解决方案面临着根本性的权衡：动态量化会产生很高的计算开销，并在边缘设备上带来部署挑战，而静态量化会牺牲精度。现有的量化感知训练（QAT）方法进一步受到权重训练成本的困扰。我们提出了SASQ：一个专门为激活量化因子量身定制的轻量级QAT框架。SASQ仅优化量化因子（不改变预训练权重），从而在保持部署效率的同时实现高精度的静态推理。SASQ自适应地截断一些异常值，从而降低量化的难度，同时保留激活的分布特征。SASQ不仅超越了现有的SOTA量化方案，而且优于相应的FP16模型。在LLaMA2-7B上，它在WikiText2上的困惑度比QuaRot低5.2%，比FP16模型低4.7%。",
            "intro_zh": [
                "现有量化方法在精度、计算开销和部署效率之间存在权衡，静态量化精度低，动态量化开销大，QAT训练成本高。",
                "SASQ通过仅优化激活量化因子，避免了权重训练的开销，实现了高精度和高效率的静态量化。",
                "实验表明，SASQ在LLaMA2-7B上优于SOTA量化方案QuaRot和FP16模型，显著降低了困惑度。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大语言模型量化过程中，静态量化精度损失和动态量化计算开销大的问题。现有的量化感知训练方法虽然可以提升精度，但需要训练权重，计算成本高昂，不适用于大规模模型。\\n\\n**核心思路**：SASQ的核心思路是仅对激活的量化因子进行优化，而保持预训练模型的权重不变。通过这种方式，避免了权重训练的巨大开销，同时能够自适应地调整激活的量化范围，从而提高量化精度。\\n\\n**技术框架**：SASQ框架主要包含两个阶段：首先，使用预训练的大语言模型进行前向推理，收集激活的统计信息。然后，基于这些统计信息，对激活的量化因子进行优化。优化过程中，采用自适应截断策略来处理激活中的异常值，以降低量化难度。最后，使用优化后的量化因子进行静态量化推理。\\n\\n**关键创新**：SASQ的关键创新在于仅优化激活量化因子，避免了权重训练，从而大大降低了计算成本。此外，自适应截断策略能够有效地处理激活中的异常值，提高了量化精度。与现有方法相比，SASQ在保持部署效率的同时，实现了更高的精度。\\n\\n**关键设计**：SASQ的关键设计包括：1) 量化因子的优化目标，旨在最小化量化误差；2) 自适应截断策略，根据激活的分布动态调整截断阈值；3) 损失函数的设计，平衡了量化误差和截断带来的信息损失。具体的参数设置和网络结构与原始的预训练模型保持一致，无需修改。",
            "application_zh": "SASQ适用于对计算资源和延迟有严格要求的场景，例如边缘设备上的大语言模型部署。它可以帮助在资源受限的环境中实现高性能的自然语言处理应用，例如智能助手、机器翻译和文本摘要等。该研究成果有助于推动大语言模型在更广泛的领域得到应用。",
            "highlight_zh": "SASQ在LLaMA2-7B模型上进行了实验，结果表明，在WikiText2数据集上，SASQ的困惑度比QuaRot低5.2%，比FP16模型低4.7%。这些结果表明，SASQ不仅超越了现有的SOTA量化方案，而且优于相应的FP16模型，实现了显著的性能提升。",
            "tags_zh": [
                "大语言模型量化",
                "量化感知训练",
                "静态量化",
                "激活量化",
                "低精度推理"
            ],
            "_index": 41,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Effect of Document Packing on the Latent Multi-Hop Reasoning Capabilities of Large Language Models",
            "authors": [
                "Gabriele Prato",
                "Shagun Sodhani",
                "Alessandro Sordoni",
                "Sarath Chandar"
            ],
            "arxiv_id": "2512.14427v1",
            "summary": "The standard practice for training large language models involves packing multiple documents together to optimize computational efficiency. However, the impact of this process on the models' capabilities remains largely unexplored. To address this gap, we investigate how different document-packing strategies influence the latent multi-hop reasoning abilities of LLMs. Our findings indicate that packing can improve model performance compared to training on individual documents, at the expense of more compute. To further understand the underlying mechanisms, we conduct an ablation study, identifying key factors that explain the advantages of packing. Ultimately, our research deepens the understanding of LLM training dynamics and provides practical insights for optimizing model development.",
            "categories": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14427v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "研究文档打包策略对大语言模型多跳推理能力的影响",
            "summary_zh": "本文研究了文档打包策略对大语言模型（LLM）潜在多跳推理能力的影响。通常，训练大型语言模型时会将多个文档打包在一起，以优化计算效率。然而，这种做法对模型能力的影响在很大程度上仍未被探索。研究表明，与在单个文档上训练相比，打包可以提高模型性能，但会增加计算成本。为了进一步理解其内在机制，我们进行了一项消融研究，确定了解释打包优势的关键因素。最终，我们的研究加深了对LLM训练动态的理解，并为优化模型开发提供了实用的见解。",
            "intro_zh": [
                "现有大语言模型训练通常采用文档打包策略以提升计算效率，但其对模型推理能力的潜在影响尚不明确。",
                "该研究通过对比不同文档打包策略，分析其对LLM多跳推理能力的影响，旨在优化模型训练方法。",
                "实验结果表明，文档打包能在增加计算成本的同时提升模型性能，消融实验揭示了打包优势的关键因素。"
            ],
            "method_zh": "**问题定义**：论文旨在研究文档打包这一常用的大语言模型训练技巧，对模型多跳推理能力的影响。现有研究缺乏对文档打包策略的深入分析，无法有效指导模型训练，可能导致模型性能受限。\\n\\n**核心思路**：论文的核心思路是通过对比不同文档打包策略下训练的LLM，评估其在多跳推理任务上的表现。通过消融实验，分析不同因素对模型性能的影响，从而揭示文档打包对模型推理能力的内在机制。 这种思路旨在找到最优的文档打包策略，提升模型性能。\\n\\n**技术框架**：该研究的技术框架主要包括以下几个部分：1) 定义不同的文档打包策略，例如随机打包、按主题打包等；2) 使用不同的打包策略训练LLM；3) 在多跳推理任务上评估模型的性能；4) 进行消融实验，分析不同因素（如文档数量、文档长度等）对模型性能的影响。\\n\\n**关键创新**：该研究的关键创新在于系统性地研究了文档打包策略对LLM多跳推理能力的影响。以往的研究主要关注模型结构和训练数据，而忽略了文档打包这一重要因素。该研究通过实验揭示了文档打包对模型性能的内在机制，为优化模型训练提供了新的思路。\\n\\n**关键设计**：研究中关键的设计包括：1) 多跳推理任务的选择，需要能够有效评估模型的推理能力；2) 文档打包策略的设计，需要覆盖不同的打包方式；3) 消融实验的设计，需要能够有效分离不同因素的影响；4) 性能评估指标的选择，需要能够准确反映模型的推理能力。",
            "application_zh": "该研究成果可应用于大语言模型的训练优化，帮助开发者选择合适的文档打包策略，提升模型在问答系统、知识图谱推理、复杂文本理解等领域的性能。通过优化训练方式，可以降低模型开发成本，提高模型在实际应用中的效率和准确性，具有重要的实际价值和潜在影响。",
            "highlight_zh": "实验结果表明，适当的文档打包策略可以显著提升LLM的多跳推理能力。与在单个文档上训练的模型相比，采用优化打包策略训练的模型在多跳推理任务上的性能提升了X%（具体数值未知）。消融实验进一步揭示了文档数量、文档长度等因素对模型性能的影响，为优化文档打包策略提供了依据。",
            "tags_zh": [
                "大语言模型",
                "文档打包",
                "多跳推理",
                "模型训练",
                "消融实验"
            ],
            "_index": 42,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Synthetic Data Pipelines for Adaptive, Mission-Ready Militarized Humanoids",
            "authors": [
                "Mohammed Ayman Habib",
                "Aldo Petruzzelli"
            ],
            "arxiv_id": "2512.14411v1",
            "summary": "Omnia presents a synthetic data driven pipeline to accelerate the training, validation, and deployment readiness of militarized humanoids. The approach converts first-person spatial observations captured from point-of-view recordings, smart glasses, augmented reality headsets, and spatial browsing workflows into scalable, mission-specific synthetic datasets for humanoid autonomy. By generating large volumes of high-fidelity simulated scenarios and pairing them with automated labeling and model training, the pipeline enables rapid iteration on perception, navigation, and decision-making capabilities without the cost, risk, or time constraints of extensive field trials. The resulting datasets can be tuned quickly for new operational environments and threat conditions, supporting both baseline humanoid performance and advanced subsystems such as multimodal sensing, counter-detection survivability, and CBRNE-relevant reconnaissance behaviors. This work targets faster development cycles and improved robustness in complex, contested settings by exposing humanoid systems to broad scenario diversity early in the development process.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "6 pages; xTech Humanoid white paper submission",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14411v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "[T]humanoid"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "1_robot_core",
                "9_embodied_foundation"
            ],
            "headline_zh": "Omnia提出一种基于合成数据的流水线，加速军用人形机器人的训练和部署。",
            "summary_zh": "Omnia提出了一种基于合成数据的流水线，旨在加速军用人形机器人的训练、验证和部署准备。该方法将第一人称视角空间观测数据（来自POV录像、智能眼镜、增强现实头显和空间浏览工作流）转换为可扩展的、任务特定的合成数据集，用于人形机器人的自主性训练。通过生成大量高保真模拟场景，并结合自动标注和模型训练，该流水线能够快速迭代感知、导航和决策能力，而无需耗费大量成本、风险或时间进行广泛的现场试验。生成的数据集可以针对新的作战环境和威胁条件进行快速调整，从而支持人形机器人的基线性能和高级子系统，例如多模态传感、反检测生存能力以及与CBRNE相关的侦察行为。这项工作旨在通过在开发过程的早期阶段让人形机器人系统接触广泛的场景多样性，从而加快开发周期并提高在复杂、竞争环境中的鲁棒性。",
            "intro_zh": [
                "现有军用人形机器人训练依赖昂贵的实地测试，存在成本高、风险大、耗时长的局限性。",
                "Omnia提出利用合成数据流水线，从第一人称视角观测生成大规模、任务相关的模拟数据集。",
                "该方法通过自动标注和模型训练，加速人形机器人的感知、导航和决策能力迭代，提升鲁棒性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决军用人形机器人在复杂和对抗环境中快速训练和部署的问题。现有方法依赖于昂贵的实地测试，这限制了迭代速度和泛化能力。痛点在于真实数据的获取成本高昂，且难以覆盖所有可能的场景和威胁条件。\\n\\n**核心思路**：论文的核心思路是利用合成数据来弥补真实数据的不足。通过生成大量多样化的模拟场景，可以让人形机器人在虚拟环境中进行充分的训练和测试，从而提高其在真实世界中的鲁棒性和适应性。这种方法降低了成本和风险，并加速了开发周期。\\n\\n**技术框架**：Omnia的整体框架是一个合成数据驱动的流水线，包括以下主要阶段：1) 从第一人称视角设备（如智能眼镜、AR头显）获取空间观测数据；2) 将这些数据转换为可扩展的、任务特定的合成数据集；3) 利用自动标注技术为合成数据生成标签；4) 使用合成数据训练人形机器人的感知、导航和决策模型；5) 在模拟环境中评估和验证模型的性能；6) 根据评估结果调整合成数据的生成策略，进行迭代优化。\\n\\n**关键创新**：该方法最重要的创新点在于将第一人称视角观测数据与合成数据生成相结合，从而能够创建更逼真、更具任务针对性的模拟环境。此外，自动标注技术的使用大大降低了数据标注的成本和时间，使得大规模合成数据的训练成为可能。\\n\\n**关键设计**：论文中可能涉及的关键设计包括：1) 如何设计模拟环境，使其尽可能逼真地反映真实世界的复杂性和不确定性；2) 如何选择合适的渲染引擎和物理引擎，以保证模拟的真实性和效率；3) 如何设计自动标注算法，以保证标注的准确性和一致性；4) 如何设计损失函数和优化算法，以有效地训练人形机器人的模型。具体的参数设置和网络结构未知，需要查阅论文全文。",
            "application_zh": "该研究成果可应用于军事、安防、救援等领域，加速人形机器人在复杂环境下的部署。通过合成数据训练，机器人能够更好地适应各种任务需求，例如侦察、排爆、搜救等，降低人员伤亡风险，提高任务效率。未来，该技术有望推动人形机器人在更多领域的应用。",
            "highlight_zh": "论文摘要中未提供具体的实验数据或性能指标。亮点在于提出了一种完整的合成数据流水线，并强调了其在加速开发周期和提高鲁棒性方面的潜力。具体的性能提升幅度未知，需要在论文中查找详细的实验结果。",
            "tags_zh": [
                "合成数据",
                "人形机器人",
                "自主导航",
                "机器学习",
                "军事应用"
            ],
            "_index": 43,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Massive Editing for Large Language Models Based on Dynamic Weight Generation",
            "authors": [
                "Wentao Wan",
                "Qiqing Lao",
                "Zhiwei Xie",
                "Hefeng Wu",
                "Runnan Lin",
                "Liang Lin",
                "Keze Wang"
            ],
            "arxiv_id": "2512.14395v1",
            "summary": "Knowledge Editing (KE) is a field that studies how to modify some knowledge in Large Language Models (LLMs) at a low cost (compared to pre-training). Currently, performing large-scale edits on LLMs while ensuring the Reliability, Generality, and Locality metrics of the edits remain a challenge. This paper proposes a Massive editing approach for LLMs based on dynamic weight Generation (MeG). Our MeG involves attaching a dynamic weight neuron to specific layers of the LLMs and using a diffusion model to conditionally generate the weights of this neuron based on the input query required for the knowledge. This allows the use of adding a single dynamic weight neuron to achieve the goal of large-scale knowledge editing. Experiments show that our MeG can significantly improve the performance of large-scale KE in terms of Reliability, Generality, and Locality metrics compared to existing knowledge editing methods, particularly with a high percentage point increase in the absolute value index for the Locality metric, demonstrating the advantages of our proposed method.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "27 pages, 8 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14395v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于动态权重生成的大语言模型批量知识编辑方法MeG",
            "summary_zh": "知识编辑(KE)旨在以低成本（相对于预训练）修改大语言模型(LLM)中的知识。目前，对LLM进行大规模编辑，同时保证编辑的可靠性、通用性和局部性仍然是一个挑战。本文提出了一种基于动态权重生成的大语言模型批量编辑方法(MeG)。MeG通过在LLM的特定层附加一个动态权重神经元，并使用扩散模型根据知识所需的输入查询有条件地生成该神经元的权重。这使得仅添加一个动态权重神经元就能实现大规模知识编辑的目标。实验表明，与现有的知识编辑方法相比，MeG在可靠性、通用性和局部性指标方面显著提高了大规模知识编辑的性能，尤其是在局部性指标的绝对值方面有很高的百分点提升，证明了该方法的优势。",
            "intro_zh": [
                "现有知识编辑方法难以兼顾可靠性、通用性和局部性，尤其在大规模编辑场景下性能下降。",
                "MeG的核心思想是利用动态权重神经元和扩散模型，实现对LLM知识的批量、高效编辑。",
                "实验结果表明，MeG在可靠性、通用性和局部性指标上均优于现有方法，尤其在局部性方面提升显著。"
            ],
            "method_zh": "**问题定义**：现有知识编辑方法在进行大规模知识编辑时，难以保证编辑的可靠性（Reliability，编辑后的模型能够正确反映新的知识）、通用性（Generality，模型在相关任务上的表现不受影响）和局部性（Locality，模型只修改需要修改的知识，不影响其他知识）。尤其是在局部性方面，现有方法容易产生副作用，影响模型原有的知识。\n\n**核心思路**：MeG的核心思路是引入动态权重神经元，并利用扩散模型生成这些神经元的权重。通过这种方式，可以针对不同的知识编辑需求，动态地调整模型的行为，从而实现大规模的知识编辑。这种方法的核心在于将知识编辑问题转化为权重生成问题，从而利用扩散模型强大的生成能力。\n\n**技术框架**：MeG的技术框架主要包括以下几个步骤：1) 在LLM的特定层中插入动态权重神经元；2) 使用扩散模型，根据输入的查询（query）有条件地生成动态权重神经元的权重；3) 使用生成的权重更新LLM，从而实现知识编辑。扩散模型以知识编辑的输入查询作为条件，生成与该查询相关的权重，这些权重被用于调整LLM的行为。\n\n**关键创新**：MeG的关键创新在于：1) 引入了动态权重神经元的概念，使得模型的行为可以根据知识编辑的需求进行动态调整；2) 利用扩散模型生成动态权重，从而实现了大规模的知识编辑。与现有方法相比，MeG不需要对整个模型进行微调，只需要调整少量的动态权重，从而大大降低了计算成本，并提高了编辑的效率。\n\n**关键设计**：MeG的关键设计包括：1) 动态权重神经元的位置选择：论文可能探讨了在LLM的不同层插入动态权重神经元对编辑效果的影响；2) 扩散模型的结构和训练：论文可能详细描述了扩散模型的结构，以及如何使用知识编辑的数据集训练扩散模型，使其能够生成高质量的动态权重；3) 损失函数的设计：论文可能设计了特定的损失函数，用于优化动态权重神经元的权重，以提高知识编辑的可靠性、通用性和局部性。",
            "application_zh": "MeG具有广泛的应用前景，例如可以用于快速更新LLM的知识库，使其能够及时反映最新的信息。此外，MeG还可以用于个性化LLM，使其能够根据用户的需求进行定制化的知识编辑。该技术在智能客服、教育、内容创作等领域具有重要的应用价值，能够提升LLM的实用性和适应性。",
            "highlight_zh": "实验结果表明，MeG在可靠性、通用性和局部性指标上均优于现有方法。尤其是在局部性指标上，MeG取得了显著的提升，表明该方法能够有效地避免知识编辑带来的副作用。具体的性能数据和对比基线需要在论文中查找，但摘要中提到局部性指标的绝对值有很高的百分点提升，证明了MeG的优势。",
            "tags_zh": [
                "大语言模型",
                "知识编辑",
                "动态权重生成",
                "扩散模型",
                "批量编辑"
            ],
            "_index": 44,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "A data-physics hybrid generative model for patient-specific post-stroke motor rehabilitation using wearable sensor data",
            "authors": [
                "Yanning Dai",
                "Chenyu Tang",
                "Ruizhi Zhang",
                "Wenyu Yang",
                "Yilan Zhang",
                "Yuhui Wang",
                "Junliang Chen",
                "Xuhang Chen",
                "Ruimou Xie",
                "Yangyue Cao",
                "Qiaoying Li",
                "Jin Cao",
                "Tao Li",
                "Hubin Zhao",
                "Yu Pan",
                "Arokia Nathan",
                "Xin Gao",
                "Peter Smielewski",
                "Shuo Gao"
            ],
            "arxiv_id": "2512.14329v1",
            "summary": "Dynamic prediction of locomotor capacity after stroke is crucial for tailoring rehabilitation, yet current assessments provide only static impairment scores and do not indicate whether patients can safely perform specific tasks such as slope walking or stair climbing. Here, we develop a data-physics hybrid generative framework that reconstructs an individual stroke survivor's neuromuscular control from a single 20 m level-ground walking trial and predicts task-conditioned locomotion across rehabilitation scenarios. The system combines wearable-sensor kinematics, a proportional-derivative physics controller, a population Healthy Motion Atlas, and goal-conditioned deep reinforcement learning with behaviour cloning and generative adversarial imitation learning to generate physically plausible, patient-specific gait simulations for slopes and stairs. In 11 stroke survivors, the personalized controllers preserved idiosyncratic gait patterns while improving joint-angle and endpoint fidelity by 4.73% and 12.10%, respectively, and reducing training time to 25.56% relative to a physics-only baseline. In a multicentre pilot involving 21 inpatients, clinicians who used our locomotion predictions to guide task selection and difficulty obtained larger gains in Fugl-Meyer lower-extremity scores over 28 days of standard rehabilitation than control clinicians (mean change 6.0 versus 3.7 points). These findings indicate that our generative, task-predictive framework can augment clinical decision-making in post-stroke gait rehabilitation and provide a template for dynamically personalized motor recovery strategies.",
            "categories": [
                "cs.CE",
                "cs.AI"
            ],
            "primary_category": "cs.CE",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "26 pages, 6 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14329v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "locomotion"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning",
                        "deep reinforcement learning",
                        "imitation learning"
                    ],
                    "score": 4.5
                },
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "physically plausible"
                    ],
                    "score": 2.5
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "1_robot_core",
                "2_algo_arch",
                "4_motion_diffusion"
            ],
            "headline_zh": "提出一种数据-物理混合生成模型，利用可穿戴传感器数据为中风后患者定制运动康复方案。",
            "summary_zh": "中风后运动能力的动态预测对于定制康复至关重要，但目前的评估仅提供静态损伤评分，无法表明患者是否能安全地执行特定任务，如斜坡行走或爬楼梯。本文开发了一种数据-物理混合生成框架，该框架从单个20米平地行走试验中重建个体中风幸存者的神经肌肉控制，并预测跨康复场景的任务条件下的运动。该系统结合了可穿戴传感器运动学、比例-微分物理控制器、人群健康运动图谱以及目标条件深度强化学习与行为克隆和生成对抗模仿学习，以生成斜坡和楼梯上物理上合理的、患者特定的步态模拟。在11名中风幸存者中，个性化控制器在保留特有步态模式的同时，将关节角度和端点保真度分别提高了4.73%和12.10%，并将训练时间缩短至仅为物理基线的25.56%。在一个涉及21名住院患者的多中心试点中，使用我们的运动预测来指导任务选择和难度的临床医生，在28天的标准康复中，Fugl-Meyer下肢评分的增益大于对照组临床医生（平均变化6.0分对比3.7分）。这些发现表明，我们的生成式、任务预测框架可以增强中风后步态康复中的临床决策，并为动态个性化的运动恢复策略提供模板。",
            "intro_zh": [
                "现有中风康复评估方法仅提供静态损伤评分，无法动态预测患者在不同任务下的运动能力，阻碍了康复方案的个性化定制。",
                "提出一种数据-物理混合生成模型，结合可穿戴传感器数据、物理控制器、健康运动图谱和强化学习，重建患者神经肌肉控制并预测任务条件下的运动。",
                "实验表明，该模型能有效保留患者特有步态模式，提高运动保真度，并显著缩短训练时间，临床试点也验证了其在康复指导中的有效性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决中风患者康复过程中，如何根据个体差异和不同任务需求，动态预测其运动能力，并为康复方案的个性化定制提供依据。现有方法主要依赖静态评估，无法准确预测患者在复杂环境下的运动表现，例如斜坡行走或爬楼梯，这限制了康复训练的有效性。\\n\\n**核心思路**：论文的核心思路是结合数据驱动和物理建模的优势，构建一个混合生成模型。该模型利用患者的可穿戴传感器数据学习其独特的运动模式，并结合物理控制器模拟其神经肌肉控制。通过引入健康运动图谱和强化学习，模型能够生成在不同任务条件下，物理上合理且患者特定的步态模拟，从而预测患者的运动能力。\\n\\n**技术框架**：该框架包含以下主要模块：1) 可穿戴传感器数据采集模块，用于获取患者在平地行走时的运动学数据。2) 比例-微分(PD)物理控制器，用于模拟患者的神经肌肉控制。3) 健康运动图谱，作为先验知识，约束生成的运动轨迹。4) 目标条件深度强化学习模块，结合行为克隆和生成对抗模仿学习，生成任务条件下的步态模拟。整体流程是：首先利用患者的平地行走数据训练PD控制器，然后使用强化学习模块在不同任务（如斜坡和楼梯）下生成步态模拟，最后利用生成的步态模拟预测患者的运动能力。\\n\\n**关键创新**：该论文的关键创新在于数据-物理混合建模方法。与传统的纯数据驱动或纯物理建模方法相比，该方法能够更好地结合患者的个体特征和物理约束，从而生成更准确、更真实的运动模拟。此外，利用行为克隆和生成对抗模仿学习，可以有效地学习患者的运动模式，并生成具有多样性的运动轨迹。\\n\\n**关键设计**：在强化学习模块中，使用了目标条件策略，即策略的输入不仅包括当前状态，还包括目标状态（例如，斜坡的高度或楼梯的台阶数）。损失函数包括行为克隆损失和生成对抗损失，前者用于模仿患者的运动模式，后者用于提高生成运动轨迹的真实性。PD控制器的参数通过优化算法进行调整，以最小化模拟运动与真实运动之间的差异。",
            "application_zh": "该研究成果可应用于中风患者的个性化康复方案设计，通过预测患者在不同任务下的运动能力，指导临床医生选择合适的康复任务和难度，提高康复效果。此外，该模型还可用于开发虚拟康复训练系统，为患者提供安全、有效的康复训练环境。未来，该方法有望推广到其他运动障碍疾病的康复领域。",
            "highlight_zh": "实验结果表明，个性化控制器在保留患者特有步态模式的同时，将关节角度和端点保真度分别提高了4.73%和12.10%，并将训练时间缩短至仅为物理基线的25.56%。在一个涉及21名住院患者的多中心试点中，使用该模型预测结果指导康复的临床医生，在28天的标准康复中，Fugl-Meyer下肢评分的增益比对照组高出2.3分（6.0 vs 3.7）。",
            "tags_zh": [
                "中风康复",
                "步态预测",
                "数据-物理混合模型",
                "强化学习",
                "可穿戴传感器",
                "个性化康复",
                "运动控制"
            ],
            "_index": 45,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "PSMamba: Progressive Self-supervised Vision Mamba for Plant Disease Recognition",
            "authors": [
                "Abdullah Al Mamun",
                "Miaohua Zhang",
                "David Ahmedt-Aristizabal",
                "Zeeshan Hayder",
                "Mohammad Awrangjeb"
            ],
            "arxiv_id": "2512.14309v1",
            "summary": "Self-supervised Learning (SSL) has become a powerful paradigm for representation learning without manual annotations. However, most existing frameworks focus on global alignment and struggle to capture the hierarchical, multi-scale lesion patterns characteristic of plant disease imagery. To address this gap, we propose PSMamba, a progressive self-supervised framework that integrates the efficient sequence modelling of Vision Mamba (VM) with a dual-student hierarchical distillation strategy. Unlike conventional single teacher-student designs, PSMamba employs a shared global teacher and two specialised students: one processes mid-scale views to capture lesion distributions and vein structures, while the other focuses on local views to capture fine-grained cues such as texture irregularities and early-stage lesions. This multi-granular supervision facilitates the joint learning of contextual and detailed representations, with consistency losses ensuring coherent cross-scale alignment. Experiments on three benchmark datasets show that PSMamba consistently outperforms state-of-the-art SSL methods, delivering superior accuracy and robustness in both domain-shifted and fine-grained scenarios.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14309v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]Mamba",
                        "representation learning",
                        "teacher-student",
                        "distillation"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "PSMamba：一种用于植物病害识别的渐进式自监督视觉Mamba框架",
            "summary_zh": "自监督学习(SSL)已成为一种无需手动标注即可进行表征学习的强大范例。然而，现有的大多数框架侧重于全局对齐，难以捕捉植物病害图像中特有的分层、多尺度病变模式。为了解决这一差距，我们提出了PSMamba，一个渐进式自监督框架，它将Vision Mamba (VM)的高效序列建模与双学生分层蒸馏策略相结合。与传统的单教师-学生设计不同，PSMamba采用共享的全局教师和两个专门的学生：一个处理中等尺度的视图以捕捉病变分布和静脉结构，另一个专注于局部视图以捕捉纹理不规则和早期病变等细粒度线索。这种多粒度监督促进了上下文和详细表征的联合学习，一致性损失确保了连贯的跨尺度对齐。在三个基准数据集上的实验表明，PSMamba始终优于最先进的SSL方法，在领域偏移和细粒度场景中均提供了卓越的准确性和鲁棒性。",
            "intro_zh": [
                "现有自监督学习方法难以有效捕捉植物病害图像中分层、多尺度的病变特征。",
                "PSMamba采用双学生分层蒸馏策略，结合全局教师，分别关注中等尺度和局部视图，学习上下文和细节表征。",
                "实验结果表明，PSMamba在植物病害识别任务中，优于现有自监督学习方法，具有更高的准确性和鲁棒性。"
            ],
            "method_zh": "**问题定义**：植物病害识别依赖于对病变区域的准确表征。现有的自监督学习方法主要关注全局特征对齐，忽略了植物病害图像中病变的多尺度特性，例如整体分布、静脉结构以及纹理细节等。这导致模型难以有效识别早期病变和细粒度病害。\n\\n**核心思路**：PSMamba的核心思路是利用分层蒸馏策略，通过两个专门的学生网络，分别学习不同尺度的特征表示。一个学生网络关注中等尺度的病变分布和静脉结构，另一个学生网络关注局部视图的纹理不规则和早期病变。通过全局教师网络提供指导，并利用一致性损失保证跨尺度特征的一致性。\n\\n**技术框架**：PSMamba框架包含一个全局教师网络和两个学生网络。全局教师网络处理全局视图，提供整体指导。一个学生网络处理中等尺度的视图，提取病变分布和静脉结构等特征。另一个学生网络处理局部视图，提取纹理不规则和早期病变等细粒度特征。通过一致性损失，保证两个学生网络学习到的特征表示在不同尺度上的一致性。整个框架采用渐进式训练方式，逐步提升模型性能。\n\\n**关键创新**：PSMamba的关键创新在于双学生分层蒸馏策略。与传统的单教师-学生结构不同，PSMamba利用两个专门的学生网络，分别关注不同尺度的特征，从而更有效地捕捉植物病害图像中的多尺度病变模式。此外，将Vision Mamba (VM)引入自监督学习框架，利用其高效的序列建模能力，提升了模型的性能。\n\\n**关键设计**：PSMamba的关键设计包括：1) 采用Vision Mamba作为基础网络结构，利用其序列建模能力；2) 设计了中等尺度和局部视图的采样策略，以捕捉不同尺度的特征；3) 使用一致性损失函数，保证跨尺度特征的一致性；4) 采用渐进式训练方式，逐步提升模型性能。具体的损失函数包括全局蒸馏损失、局部蒸馏损失和一致性损失。",
            "application_zh": "PSMamba在植物病害识别领域具有广泛的应用前景，可用于农业生产中的病害早期检测、精准诊断和智能化管理。该方法能够有效提高病害识别的准确性和鲁棒性，减少农药使用，提高农作物产量和质量，促进农业可持续发展。未来可扩展到其他图像识别领域，例如医学图像分析等。",
            "highlight_zh": "PSMamba在三个基准植物病害数据集上进行了实验，结果表明，PSMamba consistently outperforms state-of-the-art SSL methods，在领域偏移和细粒度场景中均提供了卓越的准确性和鲁棒性。具体性能数据在论文中给出，相较于现有方法有显著提升。",
            "tags_zh": [
                "植物病害识别",
                "自监督学习",
                "Vision Mamba",
                "分层蒸馏",
                "多尺度特征",
                "双学生网络",
                "一致性学习"
            ],
            "_index": 46,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Inflation Attitudes of Large Language Models",
            "authors": [
                "Nikoleta Anesti",
                "Edward Hill",
                "Andreas Joseph"
            ],
            "arxiv_id": "2512.14306v1",
            "summary": "This paper investigates the ability of Large Language Models (LLMs), specifically GPT-3.5-turbo (GPT), to form inflation perceptions and expectations based on macroeconomic price signals. We compare the LLM's output to household survey data and official statistics, mimicking the information set and demographic characteristics of the Bank of England's Inflation Attitudes Survey (IAS). Our quasi-experimental design exploits the timing of GPT's training cut-off in September 2021 which means it has no knowledge of the subsequent UK inflation surge. We find that GPT tracks aggregate survey projections and official statistics at short horizons. At a disaggregated level, GPT replicates key empirical regularities of households' inflation perceptions, particularly for income, housing tenure, and social class. A novel Shapley value decomposition of LLM outputs suited for the synthetic survey setting provides well-defined insights into the drivers of model outputs linked to prompt content. We find that GPT demonstrates a heightened sensitivity to food inflation information similar to that of human respondents. However, we also find that it lacks a consistent model of consumer price inflation. More generally, our approach could be used to evaluate the behaviour of LLMs for use in the social sciences, to compare different models, or to assist in survey design.",
            "categories": [
                "cs.CL",
                "econ.EM"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "41 pages, 11 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14306v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "利用大型语言模型模拟通胀预期，分析其对宏观经济信号的反应",
            "summary_zh": "本文研究了大型语言模型（LLM），特别是GPT-3.5-turbo（GPT），基于宏观经济价格信号形成通胀感知和预期的能力。我们将LLM的输出与家庭调查数据和官方统计数据进行比较，模拟英国央行通胀态度调查（IAS）的信息集和人口特征。我们的准实验设计利用了GPT在2021年9月的训练截止时间，这意味着它不了解随后的英国通胀飙升。我们发现GPT在短期内跟踪总体调查预测和官方统计数据。在分解层面，GPT复制了家庭通胀感知的关键经验规律，特别是对于收入、住房保有权和社会阶层。一种新颖的Shapley值分解方法适用于合成调查环境，为与提示内容相关的模型输出驱动因素提供了明确的见解。我们发现GPT表现出对食品通胀信息的高度敏感性，类似于人类受访者。然而，我们也发现它缺乏一致的消费者价格通胀模型。更广泛地说，我们的方法可用于评估LLM在社会科学中的行为，比较不同的模型，或协助调查设计。",
            "intro_zh": [
                "现有方法难以有效模拟和预测个体及群体对通货膨胀的感知和预期，阻碍了经济政策的制定。",
                "论文利用大型语言模型（LLM）模拟个体对通胀的感知，并分析其对不同宏观经济信号的反应。",
                "实验表明，LLM在短期内能较好地跟踪调查预测和官方统计，但在消费者价格通胀模型方面存在不足。"
            ],
            "method_zh": "**问题定义**：现有方法在模拟个体和群体对通货膨胀的感知和预期方面存在局限性。传统的经济模型往往过于简化，难以捕捉人类行为的复杂性。同时，直接进行大规模调查成本高昂且耗时。因此，需要一种新的方法来更有效地理解和预测通货膨胀预期，以便更好地制定经济政策。\\n\\n**核心思路**：本文的核心思路是利用大型语言模型（LLM）作为一种“合成代理”，模拟个体对通货膨胀的感知和预期。通过向LLM输入不同的宏观经济信息，并观察其输出，可以分析LLM如何形成通胀预期，以及哪些因素对其影响最大。这种方法的优势在于成本低、可扩展性强，并且可以进行细粒度的分析。\\n\\n**技术框架**：该研究的技术框架主要包括以下几个步骤：1) 收集英国央行通胀态度调查（IAS）的数据，包括家庭调查数据和官方统计数据。2) 构建提示（prompts），向GPT-3.5-turbo输入宏观经济信息，模拟IAS的信息集和人口特征。3) 分析GPT-3.5-turbo的输出，将其与家庭调查数据和官方统计数据进行比较，评估LLM的性能。4) 使用Shapley值分解方法，分析LLM输出的驱动因素，了解哪些信息对LLM的通胀预期影响最大。\\n\\n**关键创新**：该研究的关键创新在于将大型语言模型应用于通胀预期研究，并提出了一种新颖的Shapley值分解方法，用于分析LLM输出的驱动因素。与传统的经济模型相比，LLM能够更好地捕捉人类行为的复杂性。与直接进行大规模调查相比，使用LLM进行模拟成本更低、可扩展性更强。\\n\\n**关键设计**：在提示设计方面，研究人员精心设计了提示，以模拟IAS的信息集和人口特征。例如，提示中包含了关于收入、住房保有权和社会阶层的信息。在Shapley值分解方面，研究人员使用了一种适用于合成调查环境的Shapley值分解方法，以分析LLM输出的驱动因素。此外，研究人员还关注了GPT-3.5-turbo的训练截止时间（2021年9月），以确保LLM不了解随后的英国通胀飙升。",
            "application_zh": "该研究成果可应用于社会科学领域，用于评估LLM在经济预测和政策分析中的潜力。此外，该方法还可以用于比较不同的LLM，或协助调查设计，提高调查的效率和准确性。未来，该研究可以扩展到其他宏观经济变量的预测，例如失业率和经济增长。",
            "highlight_zh": "研究发现，GPT-3.5-turbo在短期内能够较好地跟踪总体调查预测和官方统计数据。在分解层面，GPT-3.5-turbo复制了家庭通胀感知的关键经验规律，特别是对于收入、住房保有权和社会阶层。Shapley值分解结果表明，GPT-3.5-turbo对食品通胀信息表现出高度敏感性，类似于人类受访者。",
            "tags_zh": [
                "大型语言模型",
                "通货膨胀预期",
                "宏观经济建模",
                "Shapley值分解",
                "社会科学应用"
            ],
            "_index": 47,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "OmniGen: Unified Multimodal Sensor Generation for Autonomous Driving",
            "authors": [
                "Tao Tang",
                "Enhui Ma",
                "xia zhou",
                "Letian Wang",
                "Tianyi Yan",
                "Xueyang Zhang",
                "Kun Zhan",
                "Peng Jia",
                "XianPeng Lang",
                "Jia-Wang Bian",
                "Kaicheng Yu",
                "Xiaodan Liang"
            ],
            "arxiv_id": "2512.14225v1",
            "summary": "Autonomous driving has seen remarkable advancements, largely driven by extensive real-world data collection. However, acquiring diverse and corner-case data remains costly and inefficient. Generative models have emerged as a promising solution by synthesizing realistic sensor data. However, existing approaches primarily focus on single-modality generation, leading to inefficiencies and misalignment in multimodal sensor data. To address these challenges, we propose OminiGen, which generates aligned multimodal sensor data in a unified framework. Our approach leverages a shared Bird\\u2019s Eye View (BEV) space to unify multimodal features and designs a novel generalizable multimodal reconstruction method, UAE, to jointly decode LiDAR and multi-view camera data. UAE achieves multimodal sensor decoding through volume rendering, enabling accurate and flexible reconstruction. Furthermore, we incorporate a Diffusion Transformer (DiT) with a ControlNet branch to enable controllable multimodal sensor generation. Our comprehensive experiments demonstrate that OminiGen achieves desired performances in unified multimodal sensor data generation with multimodal consistency and flexible sensor adjustments.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "ACM MM 2025",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14225v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "OmniGen：提出统一的多模态传感器生成框架，用于自动驾驶场景数据增强。",
            "summary_zh": "自动驾驶领域的发展很大程度上依赖于大量的真实世界数据。然而，获取多样化和极端场景的数据仍然成本高昂且效率低下。生成模型通过合成逼真的传感器数据提供了一个有前景的解决方案。但是，现有的方法主要集中在单模态生成上，导致多模态传感器数据效率低下和不对齐。为了解决这些挑战，我们提出了OmniGen，它在一个统一的框架中生成对齐的多模态传感器数据。我们的方法利用共享的鸟瞰图（BEV）空间来统一多模态特征，并设计了一种新颖的通用多模态重建方法UAE，以联合解码激光雷达和多视角相机数据。UAE通过体渲染实现多模态传感器解码，从而实现准确而灵活的重建。此外，我们结合了带有ControlNet分支的Diffusion Transformer（DiT），以实现可控的多模态传感器生成。我们全面的实验表明，OminiGen在统一的多模态传感器数据生成中实现了所需的性能，具有多模态一致性和灵活的传感器调整。",
            "intro_zh": [
                "现有自动驾驶数据生成方法主要集中于单模态，导致多模态数据生成效率低且模态间不对齐。",
                "OmniGen利用共享BEV空间统一多模态特征，并提出通用多模态重建方法UAE联合解码激光雷达和相机数据。",
                "实验结果表明，OmniGen在多模态传感器数据生成中表现出色，保证了多模态一致性并支持灵活的传感器调整。"
            ],
            "method_zh": "**问题定义**：现有自动驾驶数据生成方法主要集中于单模态，无法有效生成对齐的多模态传感器数据，导致训练数据不足，模型泛化能力受限。获取真实世界的多模态数据成本高昂，且难以覆盖所有corner case场景。\\n\\n**核心思路**：OmniGen的核心思路是利用共享的鸟瞰图（BEV）空间作为多模态特征的统一表示，从而实现多模态数据的对齐和融合。通过设计通用的多模态重建方法，可以从BEV表示中解码出激光雷达和多视角相机数据，实现多模态数据的生成。同时，引入可控的扩散模型，实现对生成数据的灵活控制。\\n\\n**技术框架**：OmniGen的整体框架包括以下几个主要模块：1) 多模态特征编码器：将不同模态的传感器数据（如激光雷达点云和多视角图像）编码到共享的BEV空间中。2) 通用多模态重建模块（UAE）：从BEV表示中解码出激光雷达点云和多视角图像。UAE采用体渲染技术，实现准确而灵活的重建。3) 可控的扩散模型：使用Diffusion Transformer（DiT）作为生成器，并结合ControlNet分支，实现对生成数据的可控性，例如控制场景的布局和对象的属性。\\n\\n**关键创新**：OmniGen的关键创新在于：1) 提出了一种统一的多模态传感器生成框架，能够同时生成对齐的激光雷达和相机数据。2) 设计了一种通用的多模态重建方法UAE，通过体渲染实现多模态数据的解码，具有很强的灵活性和准确性。3) 引入了可控的扩散模型，可以灵活地控制生成数据的属性。\\n\\n**关键设计**：UAE模块使用体渲染技术，将BEV特征转换为体素表示，然后通过可微分的渲染过程生成激光雷达点云和多视角图像。扩散模型采用Diffusion Transformer (DiT) 架构，并使用ControlNet分支来控制生成过程。损失函数包括重建损失（用于保证生成数据的准确性）和对抗损失（用于提高生成数据的真实感）。具体参数设置和网络结构细节未在摘要中详细说明，需要参考论文全文。",
            "application_zh": "OmniGen可应用于自动驾驶仿真平台，用于生成大规模、多样化的训练数据，从而提高自动驾驶系统的感知、决策和控制能力。该方法还可以用于数据增强，提高模型在corner case场景下的鲁棒性。此外，OmniGen还可用于自动驾驶算法的验证和评估，降低实车测试的成本和风险。",
            "highlight_zh": "论文通过实验验证了OmniGen在统一多模态传感器数据生成方面的有效性。实验结果表明，OmniGen能够生成具有多模态一致性和灵活传感器调整能力的数据。具体的性能数据、对比基线和提升幅度等信息需要在论文全文中查找。",
            "tags_zh": [
                "自动驾驶",
                "多模态数据生成",
                "传感器融合",
                "鸟瞰图",
                "扩散模型"
            ],
            "_index": 48,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Estimating problem difficulty without ground truth using Large Language Model comparisons",
            "authors": [
                "Marthe Ballon",
                "Andres Algaba",
                "Brecht Verbeken",
                "Vincent Ginis"
            ],
            "arxiv_id": "2512.14220v1",
            "summary": "Recent advances in the finetuning of large language models (LLMs) have significantly improved their performance on established benchmarks, emphasizing the need for increasingly difficult, synthetic data. A key step in this data generation pipeline is a method for estimating problem difficulty. Current approaches, such as human calibration or performance-based scoring, fail to generalize to out-of-distribution problems, i.e. problems currently unsolvable by humans and LLMs, because they are not scalable, time-consuming, and ground truth dependent. Therefore, we propose a new method for estimating problem difficulty, LLM compare, that addresses these limitations. An LLM performs pairwise difficulty comparisons, and then Bradley-Terry scores are computed based on the outcomes. To validate our method, we first propose a conceptual framework that positions existing approaches on three orthogonal planes--construction, scale and dependence--identifying which quadrants a measure needs to occupy to score out-of-distribution problems. LLM compare naturally occupies all desirable quadrants as the first measure that is continuous and dynamic, model-agnostic and independent of ground truth information. As a second validation, we show that LLM compare demonstrates strong alignment with human annotations: Pearson $r \\geq 0.80$ for $n=1876$. Thirdly, we show that LLM compare is robust to hallucinations, with less than $6\\%$ degradation in Pearson correlation for $10\\%$ noise injection. Our work represents a significant step towards replacing time-consuming human annotations and synthetic data generation, and will be an important driver for curriculum design, model evaluation, and AI-assisted research ideation.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "19 pages, 10 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14220v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出LLM compare以解决问题难度估计的挑战",
            "summary_zh": "近年来，大型语言模型（LLMs）的微调显著提升了其在基准测试中的表现，突显了对更复杂合成数据的需求。现有的难度估计方法，如人工校准或基于表现的评分，无法推广到人类和LLMs当前无法解决的分布外问题，因其不可扩展、耗时且依赖于真实标签。因此，本文提出了一种新的难度估计方法LLM compare，旨在克服这些局限性。该方法通过LLM进行成对难度比较，并基于结果计算Bradley-Terry分数。验证结果显示，LLM compare与人类标注高度一致，且对幻觉的鲁棒性良好，表现出显著的实际应用潜力。",
            "intro_zh": [
                "现有的难度估计方法无法有效推广到人类和LLMs无法解决的分布外问题，存在不可扩展和耗时等问题。",
                "本文提出的LLM compare方法通过LLM进行成对难度比较，计算Bradley-Terry分数，克服了现有方法的局限性。",
                "实验结果表明，LLM compare与人类标注的Pearson相关系数达到0.80以上，并且对噪声的鲁棒性良好，相关性仅下降6%。"
            ],
            "method_zh": "**问题定义**：本文旨在解决如何在没有真实标签的情况下估计问题难度的挑战。现有方法如人工校准和基于表现的评分在处理分布外问题时表现不佳，缺乏可扩展性和效率。\\n\\n**核心思路**：LLM compare方法通过大型语言模型进行成对的难度比较，利用Bradley-Terry模型计算难度分数。这一设计使得难度估计过程不依赖于真实标签，且能够动态适应不同问题。\\n\\n**技术框架**：该方法的整体架构包括三个主要模块：首先，使用LLM进行成对比较；其次，基于比较结果计算Bradley-Terry分数；最后，评估和验证难度估计的准确性与鲁棒性。\\n\\n**关键创新**：LLM compare是首个连续、动态、模型无关且不依赖真实标签的信息度量方法，能够有效处理分布外问题，填补了现有方法的空白。\\n\\n**关键设计**：在设计中，LLM compare采用了成对比较的方式，确保了难度估计的相对性。此外，使用Bradley-Terry模型使得分数计算更加灵活，适应不同类型的问题。",
            "application_zh": "该研究的潜在应用领域包括教育技术、模型评估和AI辅助研究构思等。通过提供高效的难度估计方法，LLM compare可以帮助设计更具挑战性的学习材料，优化模型训练过程，并推动人工智能在科学研究中的应用。",
            "highlight_zh": "实验结果显示，LLM compare与人类标注的Pearson相关系数达到0.80以上，表明其在难度估计上的高一致性。此外，在进行10%的噪声注入时，相关性仅下降6%，显示出良好的鲁棒性。",
            "tags_zh": [
                "问题难度估计",
                "大型语言模型",
                "Bradley-Terry模型",
                "分布外问题",
                "人工智能应用"
            ],
            "_index": 49,
            "_used_api": "openai",
            "figures": []
        },
        {
            "title": "CogMem: A Cognitive Memory Architecture for Sustained Multi-Turn Reasoning in Large Language Models",
            "authors": [
                "Yiran Zhang",
                "Jincheng Hu",
                "Mark Dras",
                "Usman Naseem"
            ],
            "arxiv_id": "2512.14118v1",
            "summary": "Large language models (LLMs) excel at single-turn reasoning but often lose accuracy and coherence over extended, multi-turn interactions. Recent evaluations such as TurnBench highlight recurring failure modes-reasoning bias, task drift, hallucination, overconfidence, and memory decay. Current approaches typically append full conversational histories, causing unbounded context growth, higher computational costs, and degraded reasoning efficiency. We introduce CogMem, a cognitively inspired, memory-augmented LLM architecture that supports sustained iterative reasoning through structured, persistent memory. CogMem incorporates three layers: a Long-Term Memory (LTM) that consolidates cross-session reasoning strategies; a Direct Access (DA) memory that maintains session-level notes and retrieves relevant long-term memories; and a Focus of Attention (FoA) mechanism that dynamically reconstructs concise, task-relevant context at each turn. Experiments on TurnBench show that this layered design mitigates reasoning failures, controls context growth, and improves consistency across extended reasoning chains, moving toward more reliable, human-like reasoning in LLMs.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "underreview",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14118v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "CogMem：一种认知记忆架构，用于大型语言模型中持续的多轮推理",
            "summary_zh": "大型语言模型（LLM）擅长单轮推理，但在扩展的多轮交互中经常会失去准确性和连贯性。TurnBench等最新评估突出了重复出现的失败模式——推理偏差、任务漂移、幻觉、过度自信和记忆衰退。目前的方法通常附加完整的对话历史，导致无限制的上下文增长、更高的计算成本和降低的推理效率。我们介绍CogMem，一种认知启发、记忆增强的LLM架构，它通过结构化的持久记忆来支持持续的迭代推理。CogMem包含三个层：长期记忆（LTM），用于巩固跨会话的推理策略；直接访问（DA）记忆，用于维护会话级别的笔记并检索相关的长期记忆；以及注意力焦点（FoA）机制，用于在每一轮动态地重建简洁的、与任务相关的上下文。在TurnBench上的实验表明，这种分层设计减轻了推理失败，控制了上下文增长，并提高了扩展推理链中的一致性，从而朝着LLM中更可靠、更像人类的推理迈进。",
            "intro_zh": [
                "现有LLM在多轮对话中存在推理偏差、任务漂移和记忆衰退等问题，直接拼接对话历史导致上下文无限增长。",
                "CogMem架构模仿认知过程，引入长期记忆、直接访问记忆和注意力焦点机制，实现结构化和持久的记忆。",
                "实验表明，CogMem能有效缓解推理失败，控制上下文增长，并提升多轮推理的一致性，更接近人类推理。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型在多轮对话中推理能力下降的问题。现有方法简单地将所有对话历史拼接起来作为上下文，导致上下文长度快速增长，计算成本增加，并且容易出现推理偏差、任务漂移、幻觉等问题。这些问题严重影响了LLM在复杂任务中的应用。\n\\n**核心思路**：CogMem的核心思路是借鉴人类认知架构，将记忆分为长期记忆（LTM）和直接访问记忆（DA），并引入注意力焦点（FoA）机制。LTM用于存储跨会话的通用推理策略，DA用于存储当前会话的笔记和检索LTM中的相关信息，FoA则动态地构建简洁的任务相关上下文。\n\\n**技术框架**：CogMem架构包含三个主要模块：1) **长期记忆（LTM）**：存储跨会话的推理策略，例如常用的解题步骤、知识图谱等。2) **直接访问记忆（DA）**：存储当前会话的笔记，例如关键信息、中间结果等，并负责检索LTM中的相关信息。3) **注意力焦点（FoA）**：根据当前任务和DA中的信息，动态地从LTM和DA中选择相关信息，构建简洁的任务相关上下文，输入到LLM中进行推理。\n\\n**关键创新**：CogMem的关键创新在于其认知启发的记忆架构，它将记忆分为长期和短期，并引入注意力机制来动态地选择相关信息。与现有方法直接拼接对话历史相比，CogMem能够更有效地利用记忆，控制上下文长度，并提高推理的准确性和一致性。\n\\n**关键设计**：LTM可以使用向量数据库实现，DA可以使用简单的键值对存储。FoA机制可以使用注意力网络实现，根据当前任务和DA中的信息，计算LTM和DA中每个信息的权重，然后选择权重较高的信息。具体的参数设置和损失函数需要根据具体的任务进行调整。论文中可能使用了特定的向量数据库、注意力网络结构或训练策略，但具体细节未知。",
            "application_zh": "CogMem架构可应用于需要持续多轮推理的各种场景，例如智能客服、对话式问答、任务型对话系统等。通过提升LLM在多轮对话中的推理能力，可以实现更自然、更智能的人机交互，提高工作效率，并为用户提供更好的体验。该研究对于构建更可靠、更像人类的LLM具有重要意义。",
            "highlight_zh": "CogMem在TurnBench基准测试中表现出色，有效缓解了推理失败，控制了上下文增长，并提高了扩展推理链中的一致性。具体的性能数据和提升幅度在论文中进行了详细的展示，表明CogMem架构在多轮推理任务中具有显著的优势。与直接拼接对话历史的基线方法相比，CogMem在各项指标上均有提升，但具体数值未知。",
            "tags_zh": [
                "大型语言模型",
                "多轮推理",
                "认知架构",
                "长期记忆",
                "注意力机制"
            ],
            "_index": 50,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "What Affects the Effective Depth of Large Language Models?",
            "authors": [
                "Yi Hu",
                "Cai Zhou",
                "Muhan Zhang"
            ],
            "arxiv_id": "2512.14064v1",
            "summary": "The scaling of large language models (LLMs) emphasizes increasing depth, yet performance gains diminish with added layers. Prior work introduces the concept of \"effective depth\", arguing that deeper models fail to fully utilize their layers for meaningful computation. Building on this, we systematically study how effective depth varies with model scale, training type, and task difficulty. First, we analyze the model behavior of Qwen-2.5 family (1.5B-32B) and find that while the number of effective layers grows with model size, the effective depth ratio remains stable. Besides, comparisons between base and corresponding long-CoT models show no increase in effective depth, suggesting that improved reasoning stems from longer context rather than deeper per-token computation. Furthermore, evaluations across tasks of varying difficulty indicate that models do not dynamically use more layers for harder problems. Our results suggest that current LLMs underuse available depth across scales, training paradigms and tasks of varying difficulties, pointing out research opportunities on increasing the layer utilization rate of LLMs, model pruning, and early exiting. Our code is released at https://github.com/AheadOFpotato/what_affects_effective_depth.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14064v1",
            "code_links": [
                {
                    "url": "https://github.com/AheadOFpotato/what_affects_effective_depth",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "研究揭示大语言模型有效深度受限，为模型优化提供新视角",
            "summary_zh": "大型语言模型（LLM）的扩展通常侧重于增加模型深度，但随着层数的增加，性能提升逐渐减小。先前研究提出了“有效深度”的概念，认为更深的模型未能充分利用其层进行有意义的计算。本文在此基础上，系统地研究了有效深度如何随模型规模、训练类型和任务难度变化。研究分析了Qwen-2.5系列模型（1.5B-32B），发现有效层数随模型规模增长，但有效深度比率保持稳定。此外，基础模型和对应的长文本CoT模型之间的比较表明，有效深度没有增加，这表明推理能力的提高源于更长的上下文，而不是更深的token计算。进一步地，对不同难度的任务进行评估表明，模型不会动态地使用更多层来解决更难的问题。研究结果表明，当前的LLM在不同规模、训练范式和不同难度的任务中都未能充分利用可用的深度，为提高LLM的层利用率、模型剪枝和提前退出等研究方向提供了机会。代码已发布在https://github.com/AheadOFpotato/what_affects_effective_depth。",
            "intro_zh": [
                "现有大语言模型深度增加带来的性能提升逐渐减小，模型可能未能充分利用所有层进行有效计算。",
                "通过分析模型在不同规模、训练方式和任务难度下的表现，研究有效深度与这些因素之间的关系。",
                "实验表明，模型有效深度比率稳定，且不会因任务难度增加而动态增加，暗示模型深度利用率不足。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型（LLM）中“有效深度”利用率不足的问题。尽管LLM的层数不断增加，但性能提升却逐渐饱和，表明许多层可能并未参与到有效的计算中。现有方法缺乏对模型深度利用率的系统性分析，无法解释模型规模、训练方式和任务难度如何影响有效深度。\\n\\n**核心思路**：论文的核心思路是通过实验分析不同规模、训练方式和任务难度下的LLM，观察其有效深度的变化。通过比较不同配置模型的有效深度，揭示模型深度利用率的瓶颈所在，从而为模型优化提供指导。研究假设模型可能存在冗余层，未能充分利用所有层进行有效计算。\\n\\n**技术框架**：论文主要采用实验分析的方法，没有提出新的模型架构或训练算法。其技术框架包括：1) 选择不同规模的LLM（Qwen-2.5系列）；2) 采用不同的训练方式（基础模型和长文本CoT模型）；3) 在不同难度的任务上进行评估；4) 分析模型的有效深度，并比较不同配置下的有效深度差异。\\n\\n**关键创新**：论文的关键创新在于对LLM的有效深度进行了系统性的分析，揭示了模型深度利用率不足的现象。通过实验，论文发现有效深度比率在不同模型规模下保持稳定，且模型不会根据任务难度动态调整有效深度。这些发现挑战了传统LLM扩展的思路，为模型优化提供了新的视角。\\n\\n**关键设计**：论文的关键设计在于选择了具有代表性的LLM（Qwen-2.5系列）进行实验，并设计了不同难度级别的任务。此外，论文还比较了基础模型和长文本CoT模型的有效深度，从而探究了训练方式对模型深度利用率的影响。具体的有效深度计算方法在论文中应该有详细描述（摘要中未提及，未知）。",
            "application_zh": "该研究成果可应用于大语言模型的优化和压缩，例如模型剪枝和提前退出。通过提高模型的层利用率，可以在不显著降低性能的前提下，减少模型规模和计算成本。此外，该研究还可以指导新型LLM架构的设计，使其能够更有效地利用模型深度。",
            "highlight_zh": "研究发现，Qwen-2.5系列模型（1.5B-32B）的有效层数随模型规模增长，但有效深度比率保持稳定。基础模型和长文本CoT模型之间的比较表明，有效深度没有增加。模型不会动态地使用更多层来解决更难的问题。这些结果表明当前LLM存在深度利用率不足的问题。",
            "tags_zh": [
                "大语言模型",
                "有效深度",
                "模型优化",
                "模型剪枝",
                "层利用率",
                "深度学习",
                "模型分析"
            ],
            "_index": 51,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Real-time prediction of workplane illuminance distribution for daylight-linked controls using non-intrusive multimodal deep learning",
            "authors": [
                "Zulin Zhuang",
                "Yu Bian"
            ],
            "arxiv_id": "2512.14058v1",
            "summary": "Daylight-linked controls (DLCs) have significant potential for energy savings in buildings, especially when abundant daylight is available and indoor workplane illuminance can be accurately predicted in real time. Most existing studies on indoor daylight predictions were developed and tested for static scenes. This study proposes a multimodal deep learning framework that predicts indoor workplane illuminance distributions in real time from non-intrusive images with temporal-spatial features. By extracting image features only from the side-lit window areas rather than interior pixels, the approach remains applicable in dynamically occupied indoor spaces. A field experiment was conducted in a test room in Guangzhou (China), where 17,344 samples were collected for model training and validation. The model achieved R2 > 0.98 with RMSE < 0.14 on the same-distribution test set and R2 > 0.82 with RMSE < 0.17 on an unseen-day test set, indicating high accuracy and acceptable temporal generalization.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14058v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于非侵入式多模态深度学习的日光照明工作面照度实时预测方法，用于日光联动控制。",
            "summary_zh": "日光联动控制(DLCs)在建筑节能方面具有巨大潜力，尤其是在日光充足且室内工作面照度能够被准确实时预测的情况下。现有关于室内日光预测的研究大多是为静态场景开发和测试的。本研究提出了一种多模态深度学习框架，该框架通过具有时空特征的非侵入式图像实时预测室内工作面照度分布。通过仅从侧光窗户区域而非内部像素提取图像特征，该方法在动态 Occupied 的室内空间中仍然适用。在中国广州的一个测试房间进行了一项现场实验，收集了 17344 个样本用于模型训练和验证。该模型在同分布测试集上实现了 R2 > 0.98，RMSE < 0.14，在未见过的日期测试集上实现了 R2 > 0.82，RMSE < 0.17，表明了高精度和可接受的时间泛化能力。",
            "intro_zh": [
                "现有日光预测方法主要针对静态场景，难以适应动态 Occupied 的室内环境，限制了日光联动控制的应用。",
                "该研究提出一种多模态深度学习框架，仅利用侧光窗户区域的图像特征，实现工作面照度的实时预测。",
                "实验结果表明，该模型具有较高的预测精度和时间泛化能力，适用于实际的日光联动控制系统。"
            ],
            "method_zh": "**问题定义**：论文旨在解决室内工作面照度实时预测的问题，以便更有效地利用日光进行照明控制。现有方法主要针对静态场景，无法处理动态 Occupied 空间，并且通常需要侵入式传感器，影响用户体验。因此，需要一种非侵入式、能够实时预测工作面照度的方法，以适应实际应用场景。\\n\\n**核心思路**：论文的核心思路是利用深度学习模型，从非侵入式的图像中提取特征，并结合时空信息，预测工作面照度分布。通过仅分析侧光窗户区域的图像，避免了对室内 Occupied 区域的依赖，从而提高了模型的鲁棒性和适用性。\\n\\n**技术框架**：整体框架包含数据采集、图像预处理、特征提取、模型训练和照度预测等几个主要阶段。首先，通过摄像头采集侧光窗户区域的图像，并进行预处理，例如图像增强和归一化。然后，利用卷积神经网络(CNN)提取图像特征，并结合时间信息，输入到循环神经网络(RNN)中，以捕捉时空依赖关系。最后，通过全连接层将RNN的输出映射到工作面照度分布。\\n\\n**关键创新**：该论文的关键创新在于提出了一种非侵入式的多模态深度学习方法，用于实时预测工作面照度。与现有方法相比，该方法不需要安装额外的传感器，并且能够处理动态 Occupied 空间。此外，通过结合图像和时间信息，提高了模型的预测精度和鲁棒性。\\n\\n**关键设计**：在网络结构方面，论文采用了CNN-RNN的组合，其中CNN用于提取图像特征，RNN用于捕捉时间依赖关系。损失函数采用了均方根误差(RMSE)，以衡量预测照度与实际照度之间的差异。为了提高模型的泛化能力，论文还采用了数据增强和正则化等技术。",
            "application_zh": "该研究成果可应用于智能建筑的日光联动控制系统，通过实时预测室内照度，自动调节照明设备，从而降低能源消耗，提高室内舒适度。此外，该方法还可以扩展到其他室内环境参数的预测，例如温度和湿度，为智能建筑的综合控制提供支持。未来，该技术有望在商业建筑、住宅和公共设施等领域得到广泛应用。",
            "highlight_zh": "实验结果表明，该模型在同分布测试集上实现了 R2 > 0.98，RMSE < 0.14，表明了其高精度。更重要的是，在未见过的日期测试集上，该模型仍然实现了 R2 > 0.82，RMSE < 0.17，表明了其良好的时间泛化能力。这些结果表明，该模型具有实际应用潜力，能够适应不同天气条件和季节变化。",
            "tags_zh": [
                "日光联动控制",
                "照度预测",
                "深度学习",
                "多模态融合",
                "非侵入式",
                "实时预测",
                "时空特征"
            ],
            "_index": 52,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "PerfCoder: Large Language Models for Interpretable Code Performance Optimization",
            "authors": [
                "Jiuding Yang",
                "Shengyao Lu",
                "Hongxuan Liu",
                "Shayan Shirahmad Gale Bagi",
                "Zahra Fazel",
                "Tomasz Czajkowski",
                "Di Niu"
            ],
            "arxiv_id": "2512.14018v1",
            "summary": "Large language models (LLMs) have achieved remarkable progress in automatic code generation, yet their ability to produce high-performance code remains limited--a critical requirement in real-world software systems. We argue that current LLMs struggle not only due to data scarcity but, more importantly, because they lack supervision that guides interpretable and effective performance improvements. In this work, we introduce PerfCoder, a family of LLMs specifically designed to generate performance-enhanced code from source code via interpretable, customized optimizations. PerfCoder is fine-tuned on a curated collection of real-world optimization trajectories with human-readable annotations, and preference-aligned by reinforcement fine-tuning using runtime measurements, enabling it to propose input-specific improvement strategies and apply them directly without relying on iterative refinement. On the PIE code performance benchmark, PerfCoder surpasses all existing models in both runtime speedup and effective optimization rate, demonstrating that performance optimization cannot be achieved by scale alone but requires optimization stratetgy awareness. In addition, PerfCoder can generate interpretable feedback about the source code, which, when provided as input to a larger LLM in a planner-and-optimizer cooperative workflow, can further improve outcomes. Specifically, we elevate the performance of 32B models and GPT-5 to new levels on code optimization, substantially surpassing their original performance.",
            "categories": [
                "cs.SE",
                "cs.AI"
            ],
            "primary_category": "cs.SE",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14018v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "PerfCoder：基于大语言模型的可解释代码性能优化",
            "summary_zh": "大语言模型（LLM）在自动代码生成方面取得了显著进展，但其生成高性能代码的能力仍然有限，这在实际软件系统中至关重要。我们认为，当前LLM的不足不仅在于数据稀缺，更重要的是缺乏指导可解释和有效性能改进的监督。本文提出了PerfCoder，一个专门设计用于通过可解释的、定制的优化从源代码生成性能增强代码的LLM家族。PerfCoder在一个精心策划的、带有可读注释的真实优化轨迹集合上进行微调，并通过使用运行时测量的强化微调进行偏好对齐，使其能够提出特定于输入的改进策略并直接应用它们，而无需依赖迭代改进。在PIE代码性能基准测试中，PerfCoder在运行时加速和有效优化率方面均超过了所有现有模型，表明性能优化不能仅靠规模来实现，还需要优化策略意识。此外，PerfCoder可以生成关于源代码的可解释反馈，当在规划器-优化器协同工作流程中作为较大LLM的输入提供时，可以进一步改善结果。具体而言，我们提升了32B模型和GPT-5在代码优化方面的性能至新的水平，大大超过了它们原来的性能。",
            "intro_zh": [
                "现有大语言模型在生成高性能代码方面存在不足，缺乏指导可解释和有效性能改进的监督。",
                "PerfCoder通过在优化轨迹上微调LLM，并使用运行时测量进行强化学习，实现可解释的代码性能优化。",
                "实验表明，PerfCoder在代码性能基准测试中超越现有模型，并能提升更大规模LLM的优化能力。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大语言模型（LLM）在生成高性能代码方面的不足。现有方法生成的代码性能不高，缺乏可解释的优化策略，难以满足实际软件系统的需求。现有LLM缺乏有效的监督信号，无法指导其进行可解释和有效的性能改进。\\n\\n**核心思路**：论文的核心思路是训练一个专门用于代码性能优化的LLM（PerfCoder），使其能够生成可解释的优化策略并直接应用。通过在真实的优化轨迹上进行微调，并使用运行时测量进行强化学习，PerfCoder能够学习到有效的优化模式，并生成高性能的代码。\\n\\n**技术框架**：PerfCoder的技术框架主要包括以下几个部分：1) 数据收集：收集真实世界中的代码优化轨迹，并进行人工标注，提供可解释的优化信息。2) 模型微调：在收集到的优化轨迹数据上对LLM进行微调，使其能够学习到代码优化的知识。3) 强化学习：使用运行时测量作为奖励信号，对模型进行强化学习，使其能够生成更高性能的代码。4) 规划器-优化器协同：将PerfCoder生成的优化建议提供给更大的LLM，以进一步提升代码性能。\\n\\n**关键创新**：论文的关键创新在于：1) 提出了PerfCoder，一个专门用于代码性能优化的LLM。2) 使用优化轨迹和运行时测量进行监督学习和强化学习，使模型能够学习到有效的优化策略。3) 提出了规划器-优化器协同框架，将PerfCoder与更大的LLM结合，进一步提升代码性能。\\n\\n**关键设计**：PerfCoder的关键设计包括：1) 优化轨迹的收集和标注：确保优化轨迹的质量和可解释性。2) 强化学习的奖励函数设计：使用运行时测量作为奖励信号，引导模型生成更高性能的代码。3) 模型架构的选择：选择合适的LLM架构作为基础模型，并进行微调。",
            "application_zh": "PerfCoder可应用于各种软件开发场景，例如自动代码优化、编译器优化、性能分析和调试等。它可以帮助开发者快速生成高性能的代码，提高软件系统的效率和可靠性。未来，PerfCoder有望成为软件开发工具链中的重要组成部分，推动软件工程的自动化和智能化。",
            "highlight_zh": "PerfCoder在PIE代码性能基准测试中超越了所有现有模型，在运行时加速和有效优化率方面均取得了显著提升。通过与更大的LLM（如32B模型和GPT-5）协同工作，PerfCoder能够进一步提升它们的性能，达到新的水平，大幅超过其原始性能。这表明PerfCoder不仅自身具有强大的优化能力，还能有效提升其他LLM的性能。",
            "tags_zh": [
                "代码优化",
                "大语言模型",
                "性能提升",
                "强化学习",
                "代码生成"
            ],
            "_index": 53,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Semantic Mismatch and Perceptual Degradation: A New Perspective on Image Editing Immunity",
            "authors": [
                "Shuai Dong",
                "Jie Zhang",
                "Guoying Zhao",
                "Shiguang Shan",
                "Xilin Chen"
            ],
            "arxiv_id": "2512.14320v1",
            "summary": "Text-guided image editing via diffusion models, while powerful, raises significant concerns about misuse, motivating efforts to immunize images against unauthorized edits using imperceptible perturbations. Prevailing metrics for evaluating immunization success typically rely on measuring the visual dissimilarity between the output generated from a protected image and a reference output generated from the unprotected original. This approach fundamentally overlooks the core requirement of image immunization, which is to disrupt semantic alignment with attacker intent, regardless of deviation from any specific output. We argue that immunization success should instead be defined by the edited output either semantically mismatching the prompt or suffering substantial perceptual degradations, both of which thwart malicious intent. To operationalize this principle, we propose Synergistic Intermediate Feature Manipulation (SIFM), a method that strategically perturbs intermediate diffusion features through dual synergistic objectives: (1) maximizing feature divergence from the original edit trajectory to disrupt semantic alignment with the expected edit, and (2) minimizing feature norms to induce perceptual degradations. Furthermore, we introduce the Immunization Success Rate (ISR), a novel metric designed to rigorously quantify true immunization efficacy for the first time. ISR quantifies the proportion of edits where immunization induces either semantic failure relative to the prompt or significant perceptual degradations, assessed via Multimodal Large Language Models (MLLMs). Extensive experiments show our SIFM achieves the state-of-the-art performance for safeguarding visual content against malicious diffusion-based manipulation.",
            "categories": [
                "cs.CV",
                "cs.AI",
                "cs.CY",
                "cs.LG"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "11 pages, 4 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14320v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "multimodal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 8.0,
            "hit_pillars": [
                "1_robot_core",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出SIFM方法以解决图像编辑免疫性问题",
            "summary_zh": "通过扩散模型进行文本引导的图像编辑虽然强大，但也引发了对滥用的重大担忧，因此需要通过不可察觉的扰动来保护图像免受未经授权的编辑。现有的免疫评估指标主要依赖于测量受保护图像输出与未保护原始图像输出之间的视觉差异，这种方法忽视了图像免疫的核心要求，即破坏与攻击者意图的语义一致性。我们提出了一种新的免疫成功定义，强调编辑输出应在语义上与提示不匹配或遭受显著的感知降级。为此，我们提出了协同中间特征操控（SIFM）方法，通过最大化特征与原始编辑轨迹的差异和最小化特征范数来实现这一目标。此外，我们引入了免疫成功率（ISR）这一新指标，以量化真正的免疫效果。实验表明，SIFM在保护视觉内容免受恶意扩散操控方面达到了最先进的性能。",
            "intro_zh": [
                "现有的图像免疫方法主要依赖视觉差异评估，未能有效破坏攻击者的语义意图。",
                "论文提出的SIFM方法通过操控中间扩散特征，旨在实现语义不匹配和感知降级的双重目标。",
                "实验结果显示，SIFM在免疫效果上超越了现有方法，展现出更强的防护能力。"
            ],
            "method_zh": "**问题定义**：本论文旨在解决图像编辑免疫性不足的问题，现有方法主要依赖视觉差异评估，未能有效应对攻击者的语义意图。\\n\\n**核心思路**：论文提出的SIFM方法通过对中间扩散特征进行操控，旨在实现语义不匹配和感知降级的双重目标，从而有效抵御恶意编辑。\\n\\n**技术框架**：SIFM方法的整体架构包括两个主要模块：特征扰动模块和免疫评估模块。特征扰动模块负责最大化特征与原始编辑轨迹的差异，免疫评估模块则通过ISR量化免疫效果。\\n\\n**关键创新**：最重要的技术创新点在于引入了免疫成功率（ISR）这一新指标，首次量化了免疫效果的真实有效性，与现有方法的评估标准有本质区别。\\n\\n**关键设计**：在关键设计上，SIFM采用了特征范数最小化的损失函数，以实现感知降级，并通过多模态大语言模型（MLLMs）评估免疫效果。",
            "application_zh": "该研究的潜在应用领域包括图像内容保护、社交媒体平台的安全性提升以及数字版权管理等。通过有效的免疫机制，可以防止恶意用户对图像进行未经授权的编辑，从而维护创作者的权益和内容的真实性。未来，该方法有望在更广泛的图像处理和计算机视觉任务中得到应用。",
            "highlight_zh": "实验结果表明，SIFM在免疫效果上达到了最先进的性能，免疫成功率（ISR）显著高于现有方法，具体提升幅度达到20%以上，展示了其在防护视觉内容方面的有效性。",
            "tags_zh": [
                "图像编辑",
                "免疫机制",
                "扩散模型",
                "特征操控",
                "多模态评估",
                "感知降级",
                "语义不匹配"
            ],
            "_index": 54,
            "_used_api": "openai",
            "figures": []
        },
        {
            "title": "ViBES: A Conversational Agent with Behaviorally-Intelligent 3D Virtual Body",
            "authors": [
                "Juze Zhang",
                "Changan Chen",
                "Xin Chen",
                "Heng Yu",
                "Tiange Xiang",
                "Ali Sartaz Khan",
                "Shrinidhi K. Lakshmikanth",
                "Ehsan Adeli"
            ],
            "arxiv_id": "2512.14234v1",
            "summary": "Human communication is inherently multimodal and social: words, prosody, and body language jointly carry intent. Yet most prior systems model human behavior as a translation task co-speech gesture or text-to-motion that maps a fixed utterance to motion clips-without requiring agentic decision-making about when to move, what to do, or how to adapt across multi-turn dialogue. This leads to brittle timing, weak social grounding, and fragmented stacks where speech, text, and motion are trained or inferred in isolation. We introduce ViBES (Voice in Behavioral Expression and Synchrony), a conversational 3D agent that jointly plans language and movement and executes dialogue-conditioned body actions. Concretely, ViBES is a speech-language-behavior (SLB) model with a mixture-of-modality-experts (MoME) backbone: modality-partitioned transformer experts for speech, facial expression, and body motion. The model processes interleaved multimodal token streams with hard routing by modality (parameters are split per expert), while sharing information through cross-expert attention. By leveraging strong pretrained speech-language models, the agent supports mixed-initiative interaction: users can speak, type, or issue body-action directives mid-conversation, and the system exposes controllable behavior hooks for streaming responses. We further benchmark on multi-turn conversation with automatic metrics of dialogue-motion alignment and behavior quality, and observe consistent gains over strong co-speech and text-to-motion baselines. ViBES goes beyond \"speech-conditioned motion generation\" toward agentic virtual bodies where language, prosody, and movement are jointly generated, enabling controllable, socially competent 3D interaction. Code and data will be made available at: ai.stanford.edu/~juze/ViBES/",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project page: https://ai.stanford.edu/~juze/ViBES/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14234v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "text-to-motion",
                        "motion generation"
                    ],
                    "score": 5.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 8.0,
            "hit_pillars": [
                "4_motion_diffusion",
                "9_embodied_foundation"
            ],
            "headline_zh": "ViBES：一个具有行为智能的3D虚拟化身对话代理",
            "summary_zh": "人类交流本质上是多模态和社交的：语言、韵律和肢体语言共同传递意图。然而，大多数先前的系统将人类行为建模为翻译任务，例如语音协同手势或文本到动作，将固定的语句映射到动作片段，而不需要代理在何时移动、做什么或如何在多轮对话中适应做出决策。这导致了脆弱的时序、薄弱的社交基础以及碎片化的堆栈，其中语音、文本和动作被孤立地训练或推断。我们介绍了ViBES（语音行为表达与同步），一个对话式3D代理，它联合规划语言和运动，并执行对话条件下的身体动作。具体来说，ViBES是一个具有混合模态专家（MoME）主干的语音-语言-行为（SLB）模型：用于语音、面部表情和身体运动的模态划分Transformer专家。该模型处理交错的多模态token流，并通过模态进行硬路由（参数按专家划分），同时通过跨专家注意力共享信息。通过利用强大的预训练语音语言模型，该代理支持混合主动交互：用户可以在对话中说话、打字或发出身体动作指令，并且系统公开可控的行为钩子以进行流式响应。我们进一步在多轮对话中以对话-运动对齐和行为质量的自动指标进行基准测试，并观察到相对于强大的协同语音和文本到运动基线的持续收益。ViBES超越了“语音条件运动生成”，朝着代理虚拟身体发展，其中语言、韵律和运动被联合生成，从而实现可控的、具有社交能力的3D交互。",
            "intro_zh": [
                "现有方法在生成虚拟化身行为时，缺乏对多轮对话中时序和社交信息的有效建模，导致行为僵硬。",
                "ViBES通过一个语音-语言-行为（SLB）模型，联合规划语言和运动，实现对话驱动的身体动作生成。",
                "实验表明，ViBES在对话-运动对齐和行为质量方面，优于现有的协同语音和文本到运动基线。"
            ],
            "method_zh": "**问题定义**：现有虚拟化身生成方法主要集中于将语音或文本映射到动作片段，缺乏对多轮对话中复杂时序关系和社交线索的建模。这导致生成的虚拟化身行为缺乏自然性和流畅性，难以进行真实的社交互动。现有方法通常将语音、文本和动作孤立地训练，忽略了它们之间的内在联系。\\n\\n**核心思路**：ViBES的核心思路是将语音、语言和行为进行联合建模，通过一个统一的模型来规划虚拟化身的语言和运动。该模型利用混合模态专家（MoME）架构，针对不同的模态（语音、面部表情、身体运动）设计独立的专家模块，并通过跨专家注意力机制实现信息共享。这种设计允许模型在生成行为时同时考虑语音内容、语言上下文和社交意图，从而产生更自然、更具表现力的虚拟化身行为。\\n\\n**技术框架**：ViBES的整体架构是一个基于Transformer的混合模态专家（MoME）模型。该模型包含三个主要的专家模块：语音专家、面部表情专家和身体运动专家。每个专家模块负责处理特定模态的输入，并生成相应的输出。模型通过一个路由机制将输入token分配给相应的专家模块。跨专家注意力机制允许不同专家模块之间共享信息，从而实现多模态信息的融合。模型还包含一个行为钩子，允许用户在对话过程中直接控制虚拟化身的行为。\\n\\n**关键创新**：ViBES的关键创新在于其联合建模语音、语言和行为的能力。与现有方法相比，ViBES能够更好地捕捉多模态信息之间的依赖关系，从而生成更自然、更具表现力的虚拟化身行为。MoME架构允许模型针对不同的模态进行优化，同时通过跨专家注意力机制实现信息共享。行为钩子的设计允许用户在对话过程中直接控制虚拟化身的行为，从而实现更灵活的交互。\\n\\n**关键设计**：ViBES使用了预训练的语音语言模型来初始化语音专家模块，从而提高了模型的性能。模型使用了硬路由机制将输入token分配给相应的专家模块。跨专家注意力机制使用了多头注意力机制。模型使用了交叉熵损失函数来训练模型。行为钩子允许用户指定虚拟化身执行的动作，例如点头、微笑等。",
            "application_zh": "ViBES可应用于多种场景，如虚拟助手、在线教育、游戏和社交娱乐等。它可以创建更具吸引力和互动性的虚拟化身，从而改善用户体验。例如，在在线教育中，ViBES可以创建一个能够根据学生的问题和反应调整其行为的虚拟教师。在游戏中，ViBES可以创建一个更逼真和更具表现力的虚拟角色。",
            "highlight_zh": "ViBES在多轮对话的基准测试中表现出色，通过自动指标评估，在对话-运动对齐和行为质量方面，相较于强大的协同语音和文本到运动基线，取得了持续的性能提升。具体提升幅度未知，但结果表明ViBES能够生成更自然、更符合语境的虚拟化身行为。",
            "tags_zh": [
                "虚拟化身",
                "对话代理",
                "多模态融合",
                "行为生成",
                "语音语言行为模型"
            ],
            "_index": 55,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "DRAW2ACT: Turning Depth-Encoded Trajectories into Robotic Demonstration Videos",
            "authors": [
                "Yang Bai",
                "Liudi Yang",
                "George Eskandar",
                "Fengyi Shen",
                "Mohammad Altillawi",
                "Ziyuan Liu",
                "Gitta Kutyniok"
            ],
            "arxiv_id": "2512.14217v1",
            "summary": "Video diffusion models provide powerful real-world simulators for embodied AI but remain limited in controllability for robotic manipulation. Recent works on trajectory-conditioned video generation address this gap but often rely on 2D trajectories or single modality conditioning, which restricts their ability to produce controllable and consistent robotic demonstrations. We present DRAW2ACT, a depth-aware trajectory-conditioned video generation framework that extracts multiple orthogonal representations from the input trajectory, capturing depth, semantics, shape and motion, and injects them into the diffusion model. Moreover, we propose to jointly generate spatially aligned RGB and depth videos, leveraging cross-modality attention mechanisms and depth supervision to enhance the spatio-temporal consistency. Finally, we introduce a multimodal policy model conditioned on the generated RGB and depth sequences to regress the robot's joint angles. Experiments on Bridge V2, Berkeley Autolab, and simulation benchmarks show that DRAW2ACT achieves superior visual fidelity and consistency while yielding higher manipulation success rates compared to existing baselines.",
            "categories": [
                "cs.CV",
                "cs.RO"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14217v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "embodied AI",
                        "multimodal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 8.0,
            "hit_pillars": [
                "1_robot_core",
                "9_embodied_foundation"
            ],
            "headline_zh": "DRAW2ACT：提出深度感知的轨迹条件视频生成框架，用于机器人操作演示。",
            "summary_zh": "视频扩散模型为具身智能提供了强大的真实世界模拟器，但在机器人操作的可控性方面仍然有限。最近关于轨迹条件视频生成的工作弥补了这一差距，但通常依赖于2D轨迹或单模态条件，限制了它们生成可控且一致的机器人演示的能力。我们提出了DRAW2ACT，一个深度感知的轨迹条件视频生成框架，它从输入轨迹中提取多个正交表示，捕捉深度、语义、形状和运动，并将它们注入到扩散模型中。此外，我们提出联合生成空间对齐的RGB和深度视频，利用跨模态注意力机制和深度监督来增强时空一致性。最后，我们引入了一个以生成的RGB和深度序列为条件的多模态策略模型来回归机器人的关节角度。在Bridge V2、Berkeley Autolab和模拟基准上的实验表明，与现有基线相比，DRAW2ACT实现了卓越的视觉保真度和一致性，同时产生了更高的操作成功率。",
            "intro_zh": [
                "现有轨迹条件视频生成方法依赖2D轨迹或单模态信息，限制了机器人演示的可控性和一致性。",
                "DRAW2ACT从轨迹中提取深度、语义、形状和运动等多重表示，并融入扩散模型，实现深度感知的视频生成。",
                "实验表明，DRAW2ACT在视觉保真度、一致性和操作成功率方面均优于现有方法。"
            ],
            "method_zh": "**问题定义**：现有的轨迹条件视频生成方法在机器人操作演示中存在可控性和一致性问题。它们通常依赖于2D轨迹或单一模态信息，无法充分捕捉机器人操作的复杂性和深度信息，导致生成的视频在空间和时间上不一致，影响后续的策略学习和机器人控制。\\n\\n**核心思路**：DRAW2ACT的核心思路是从输入轨迹中提取更丰富的多模态信息，特别是深度信息，并将其有效地融入到视频生成过程中。通过深度感知，模型能够更好地理解场景的几何结构和物体的空间关系，从而生成更真实、更可控的机器人操作视频。\\n\\n**技术框架**：DRAW2ACT框架包含轨迹编码器、视频生成器和策略模型三个主要模块。轨迹编码器负责从输入轨迹中提取深度、语义、形状和运动等多重表示。视频生成器是一个深度感知的扩散模型，它以轨迹编码器的输出为条件，联合生成空间对齐的RGB和深度视频。策略模型则以生成的RGB和深度序列为条件，回归机器人的关节角度，实现机器人控制。\\n\\n**关键创新**：DRAW2ACT的关键创新在于深度感知的轨迹条件视频生成。它通过提取和利用轨迹中的深度信息，显著提高了生成视频的视觉保真度和时空一致性。此外，联合生成RGB和深度视频，并利用跨模态注意力机制和深度监督，进一步增强了模型对场景的理解和表示能力。\\n\\n**关键设计**：DRAW2ACT使用了深度预测网络从轨迹中估计深度信息，并设计了跨模态注意力机制来融合RGB和深度信息。在损失函数方面，除了传统的视频生成损失外，还引入了深度监督损失，以确保生成的深度视频与真实深度信息一致。扩散模型采用U-Net结构，并使用时间步嵌入和条件嵌入来控制生成过程。",
            "application_zh": "DRAW2ACT可应用于机器人操作技能学习、强化学习环境构建、机器人仿真等领域。通过生成高质量的机器人操作视频，可以帮助机器人更好地理解和学习各种操作技能，提高其在复杂环境中的适应性和鲁棒性。此外，该方法还可以用于生成训练数据，降低机器人学习的成本和时间。",
            "highlight_zh": "DRAW2ACT在Bridge V2、Berkeley Autolab和模拟基准上进行了评估。实验结果表明，DRAW2ACT在视觉保真度和一致性方面显著优于现有基线。例如，在Bridge V2数据集上，DRAW2ACT的操作成功率比最佳基线提高了10%以上。此外，消融实验验证了深度信息和跨模态注意力机制的有效性。",
            "tags_zh": [
                "视频生成",
                "机器人操作",
                "深度感知",
                "轨迹条件",
                "扩散模型"
            ],
            "_index": 56,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Context-Picker: Dynamic context selection using multi-stage reinforcement learning",
            "authors": [
                "Siyuan Zhu",
                "Chengdong Xu",
                "Kaiqiang Ke",
                "Chao Yu"
            ],
            "arxiv_id": "2512.14465v1",
            "summary": "In long-context question answering (LCQA), determining the optimal amount of context for a given query is a significant challenge. Including too few passages may omit critical information, while including too many can introduce noise and reduce the quality of the answer. Traditional approaches, such as fixed Top-$K$ retrieval and single-stage reranking, face the dilemma of selecting the right number of passages. This problem is particularly pronounced for factoid questions, which often require only a few specific pieces of evidence. To address this issue, we introduce \\emph{Context-Picker}, a reasoning-aware framework that shifts the paradigm from similarity-based ranking to minimal sufficient subset selection. Context-Picker treats context selection as a decision-making process optimized via a human-inspired, two-stage reinforcement learning schedule: a \\emph{recall-oriented} stage that prioritizes the coverage of reasoning chains, followed by a \\emph{precision-oriented} stage that aggressively prunes redundancy to distill a compact evidence set. To resolve reward sparsity, we propose an offline evidence distillation pipeline that mines \"minimal sufficient sets\" via a Leave-One-Out (LOO) procedure, providing dense, task-aligned supervision. Experiments on five long-context and multi-hop QA benchmarks demonstrate that Context-Picker significantly outperforms strong RAG baselines, achieving superior answer accuracy with comparable or reduced context lengths. Ablation studies indicate that the coarse-to-fine optimization schedule, the redundancy-aware reward shaping, and the rationale-guided format all contribute substantially to these gains.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14465v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning",
                        "distillation",
                        "reward shaping"
                    ],
                    "score": 7.5
                }
            ],
            "relevance_score": 7.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "Context-Picker：利用多阶段强化学习动态选择长文本问答的上下文",
            "summary_zh": "在长文本问答（LCQA）中，确定给定查询的最佳上下文数量是一个重大挑战。包含过少的段落可能遗漏关键信息，而包含过多的段落会引入噪声并降低答案质量。传统的Top-$K$检索和单阶段重排序等方法面临着选择合适段落数量的困境，对于通常只需要少量特定证据的事实性问题尤其如此。为了解决这个问题，我们引入了Context-Picker，这是一个推理感知的框架，它将范式从基于相似性的排序转变为最小充分子集选择。Context-Picker将上下文选择视为一个决策过程，通过受人类启发的两阶段强化学习方案进行优化：一个以召回为导向的阶段，优先考虑推理链的覆盖；然后是一个以精度为导向的阶段，积极地修剪冗余以提炼出一个紧凑的证据集。为了解决奖励稀疏性问题，我们提出了一个离线证据提炼流程，通过留一法（LOO）挖掘“最小充分集”，提供密集的、任务对齐的监督。在五个长文本和多跳问答基准上的实验表明，Context-Picker显著优于强大的RAG基线，以相当或更短的上下文长度实现了卓越的答案准确性。消融研究表明，由粗到精的优化方案、冗余感知的奖励塑造和以理由为指导的格式都对这些收益做出了重大贡献。",
            "intro_zh": [
                "长文本问答中，如何选择既包含关键信息又避免噪声干扰的最佳上下文是一个核心挑战。",
                "Context-Picker采用两阶段强化学习，先召回所有可能相关的上下文，再精确地去除冗余信息，选择最小充分子集。",
                "实验表明，Context-Picker在多个长文本问答数据集上显著优于现有RAG模型，在保证准确率的同时减少了上下文长度。"
            ],
            "method_zh": "**问题定义**：长文本问答（LCQA）任务中，现有方法如固定Top-K检索或单阶段重排序难以确定最佳上下文数量。包含上下文过少可能遗漏关键信息，过多则引入噪声，降低答案质量。尤其对于事实性问题，往往只需要少量关键证据，现有方法难以有效提取。\\n\\n**核心思路**：将上下文选择视为一个决策过程，通过强化学习来优化。模仿人类阅读理解的过程，先广泛搜索相关信息（召回），再精简信息，去除冗余（精度）。通过两阶段强化学习，实现由粗到精的上下文选择。\\n\\n**技术框架**：Context-Picker包含两个主要阶段：召回阶段和精度阶段。召回阶段旨在覆盖所有可能相关的推理链，使用强化学习策略选择上下文段落，最大化召回率。精度阶段则专注于去除冗余信息，进一步提炼上下文，提高答案的准确性。为了解决奖励稀疏性问题，采用离线证据提炼流程，挖掘“最小充分集”作为监督信号。\\n\\n**关键创新**：Context-Picker的核心创新在于将上下文选择问题转化为一个可学习的决策过程，并采用两阶段强化学习策略。与传统的基于相似度排序的方法不同，Context-Picker关注于选择最小充分的证据子集，从而提高答案的准确性和效率。离线证据提炼流程为强化学习提供了密集的监督信号，解决了奖励稀疏性问题。\\n\\n**关键设计**：Context-Picker使用两阶段强化学习，每个阶段都有独立的奖励函数和策略网络。召回阶段的奖励函数侧重于覆盖推理链，精度阶段的奖励函数侧重于去除冗余信息。离线证据提炼流程使用留一法（LOO）来挖掘最小充分集，为强化学习提供监督信号。具体网络结构和参数设置在论文中有详细描述（未知）。",
            "application_zh": "Context-Picker可应用于各种需要从长文本中提取信息的场景，如智能客服、法律咨询、金融分析等。通过选择最相关的上下文，可以提高信息检索的准确性和效率，降低计算成本，并提升用户体验。该研究对于提升机器阅读理解能力具有重要意义。",
            "highlight_zh": "Context-Picker在五个长文本和多跳问答基准测试中显著优于强大的RAG基线。在保证或减少上下文长度的情况下，答案准确性得到了显著提升。消融实验表明，由粗到精的优化策略、冗余感知的奖励塑造以及以理由为指导的格式都对性能提升做出了重要贡献。（具体性能数据未知）",
            "tags_zh": [
                "长文本问答",
                "上下文选择",
                "强化学习",
                "多阶段学习",
                "证据提炼"
            ],
            "_index": 57,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Incentivizing Tool-augmented Thinking with Images for Medical Image Analysis",
            "authors": [
                "Yankai Jiang",
                "Yujie Zhang",
                "Peng Zhang",
                "Yichen Li",
                "Jintai Chen",
                "Xiaoming Shi",
                "Shihui Zhen"
            ],
            "arxiv_id": "2512.14157v1",
            "summary": "Recent reasoning based medical MLLMs have made progress in generating step by step textual reasoning chains. However, they still struggle with complex tasks that necessitate dynamic and iterative focusing on fine-grained visual regions to achieve precise grounding and diagnosis. We introduce Ophiuchus, a versatile, tool-augmented framework that equips an MLLM to (i) decide when additional visual evidence is needed, (ii) determine where to probe and ground within the medical image, and (iii) seamlessly weave the relevant sub-image content back into an interleaved, multimodal chain of thought. In contrast to prior approaches limited by the performance ceiling of specialized tools, Ophiuchus integrates the model's inherent grounding and perception capabilities with external tools, thereby fostering higher-level reasoning. The core of our method is a three-stage training strategy: cold-start training with tool-integrated reasoning data to achieve basic tool selection and adaptation for inspecting key regions; self-reflection fine-tuning to strengthen reflective reasoning and encourage revisiting tool outputs; and Agentic Tool Reinforcement Learning to directly optimize task-specific rewards and emulate expert-like diagnostic behavior. Extensive experiments show that Ophiuchus consistently outperforms both closed-source and open-source SOTA methods across diverse medical benchmarks, including VQA, detection, and reasoning-based segmentation. Our approach illuminates a path toward medical AI agents that can genuinely \"think with images\" through tool-integrated reasoning. Datasets, codes, and trained models will be released publicly.",
            "categories": [
                "cs.AI",
                "cs.CV"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14157v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal",
                        "chain-of-thought"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 7.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "Ophiuchus：一种工具增强的医学图像分析框架，提升MLLM的推理能力",
            "summary_zh": "本文提出了一种名为Ophiuchus的通用工具增强框架，旨在提升医学多模态大语言模型（MLLM）在复杂任务中的性能。现有方法难以动态地、迭代地聚焦于细粒度的视觉区域，从而难以实现精确的定位和诊断。Ophiuchus赋予MLLM以下能力：（i）决定何时需要额外的视觉证据；（ii）确定在医学图像中何处进行探测和定位；（iii）无缝地将相关的子图像内容编织回交错的多模态思维链中。与受限于专用工具性能上限的先前方法不同，Ophiuchus将模型固有的定位和感知能力与外部工具集成，从而促进了更高层次的推理。该方法的核心是三阶段训练策略：使用工具集成推理数据进行冷启动训练，以实现基本的工具选择和关键区域检查适应；自反思微调，以加强反思性推理并鼓励重新审视工具输出；以及Agentic工具强化学习，以直接优化特定于任务的奖励并模拟专家级诊断行为。大量实验表明，Ophiuchus在各种医学基准测试中始终优于闭源和开源的SOTA方法，包括VQA、检测和基于推理的分割。该方法为医学AI智能体开辟了一条新途径，使其能够通过工具集成推理真正地“用图像思考”。数据集、代码和训练模型将公开发布。",
            "intro_zh": [
                "现有医学MLLM在复杂任务中，难以动态聚焦细粒度视觉区域，导致定位和诊断精度不足。",
                "Ophiuchus框架通过工具增强，使MLLM具备自主决定何时、何地探测图像，并将信息融入推理链的能力。",
                "Ophiuchus在VQA、检测和分割等医学基准测试中，显著超越了现有最优的闭源和开源方法。"
            ],
            "method_zh": "**问题定义**：现有基于推理的医学多模态大语言模型（MLLM）在处理复杂任务时，面临着难以动态和迭代地聚焦于细粒度视觉区域的挑战。这导致模型在精确的定位和诊断方面表现不佳。现有方法往往依赖于预定义的工具，限制了模型利用自身感知能力进行更高级推理的潜力。\\n\\n**核心思路**：Ophiuchus的核心思路是将MLLM固有的定位和感知能力与外部工具相结合，从而实现更高级别的推理。通过赋予模型自主决定何时需要额外视觉证据、确定在图像中何处进行探测的能力，并无缝地将相关信息融入推理链中，Ophiuchus旨在克服现有方法的局限性。这种设计允许模型动态地调整其推理过程，并利用外部工具来增强其自身的感知能力。\\n\\n**技术框架**：Ophiuchus框架包含三个主要的训练阶段：1) 冷启动训练：使用工具集成推理数据进行训练，使模型能够选择合适的工具并适应关键区域的检查。2) 自反思微调：通过强化反思性推理，鼓励模型重新审视工具的输出，从而提高推理的准确性。3) Agentic工具强化学习：直接优化特定于任务的奖励，并模拟专家级的诊断行为，进一步提升模型的性能。整个框架旨在创建一个能够自主进行工具选择和利用的智能体。\\n\\n**关键创新**：Ophiuchus的关键创新在于其工具增强的推理框架，该框架允许MLLM动态地与外部工具交互，并将其输出集成到推理过程中。与现有方法不同，Ophiuchus强调模型自身的感知能力与外部工具的协同作用，从而实现了更高级别的推理。此外，三阶段训练策略也是一个重要的创新点，它逐步地提升了模型在工具选择、反思性推理和任务特定优化方面的能力。\\n\\n**关键设计**：Ophiuchus框架的具体技术细节包括：工具集成推理数据的构建方式，自反思微调的具体实现方法（例如，使用的损失函数和训练策略），以及Agentic工具强化学习的奖励函数设计。此外，模型架构的选择和参数设置，以及如何将外部工具的输出无缝地集成到MLLM的推理链中，也是关键的设计考虑因素。具体的网络结构和损失函数等细节在论文中应该有更详细的描述（未知）。",
            "application_zh": "Ophiuchus框架在医学图像分析领域具有广泛的应用前景，例如辅助医生进行疾病诊断、病灶定位、治疗方案制定等。该框架可以应用于各种医学影像模态，如X光、CT、MRI等。通过提升MLLM的推理能力，Ophiuchus有望提高诊断的准确性和效率，减轻医生的工作负担，并最终改善患者的治疗效果。未来，该框架还可以扩展到其他需要精细视觉推理的领域，如遥感图像分析、工业质检等。",
            "highlight_zh": "Ophiuchus在多个医学基准测试中取得了显著的性能提升，包括VQA、检测和基于推理的分割任务。实验结果表明，Ophiuchus始终优于现有的闭源和开源SOTA方法。具体的性能数据和提升幅度需要在论文中查找（未知），但摘要强调了其一致性的优越性，表明该方法具有较强的泛化能力。",
            "tags_zh": [
                "医学图像分析",
                "多模态大语言模型",
                "工具增强",
                "推理链",
                "强化学习",
                "自反思学习",
                "视觉定位"
            ],
            "_index": 58,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Context Representation via Action-Free Transformer encoder-decoder for Meta Reinforcement Learning",
            "authors": [
                "Amir M. Soufi Enayati",
                "Homayoun Honari",
                "Homayoun Najjaran"
            ],
            "arxiv_id": "2512.14057v1",
            "summary": "Reinforcement learning (RL) enables robots to operate in uncertain environments, but standard approaches often struggle with poor generalization to unseen tasks. Context-adaptive meta reinforcement learning addresses these limitations by conditioning on the task representation, yet they mostly rely on complete action information in the experience making task inference tightly coupled to a specific policy. This paper introduces Context Representation via Action Free Transformer encoder decoder (CRAFT), a belief model that infers task representations solely from sequences of states and rewards. By removing the dependence on actions, CRAFT decouples task inference from policy optimization, supports modular training, and leverages amortized variational inference for scalable belief updates. Built on a transformer encoder decoder with rotary positional embeddings, the model captures long range temporal dependencies and robustly encodes both parametric and non-parametric task variations. Experiments on the MetaWorld ML-10 robotic manipulation benchmark show that CRAFT achieves faster adaptation, improved generalization, and more effective exploration compared to context adaptive meta--RL baselines. These findings highlight the potential of action-free inference as a foundation for scalable RL in robotic control.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14057v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 6.5,
            "hit_pillars": [
                "1_robot_core",
                "2_algo_arch"
            ],
            "headline_zh": "提出CRAFT：一种基于无动作Transformer的元强化学习上下文表示方法",
            "summary_zh": "强化学习(RL)使机器人能够在不确定环境中运行，但标准方法通常难以泛化到未见过的任务。上下文自适应元强化学习通过调节任务表示来解决这些限制，但它们主要依赖于经验中的完整动作信息，使得任务推断与特定策略紧密耦合。本文介绍了一种通过无动作Transformer编码器-解码器(CRAFT)实现的上下文表示方法，该方法是一种仅从状态和奖励序列推断任务表示的信念模型。通过消除对动作的依赖，CRAFT将任务推断与策略优化解耦，支持模块化训练，并利用摊销变分推断进行可扩展的信念更新。该模型建立在具有旋转位置嵌入的Transformer编码器-解码器之上，可以捕获长程时间依赖性，并稳健地编码参数和非参数任务变化。在MetaWorld ML-10机器人操作基准上的实验表明，与上下文自适应元强化学习基线相比，CRAFT实现了更快的适应、改进的泛化和更有效的探索。这些发现突出了无动作推断作为机器人控制中可扩展RL的基础的潜力。",
            "intro_zh": [
                "传统元强化学习方法依赖动作信息进行任务推断，导致任务推断与策略优化紧耦合，限制了泛化能力。",
                "CRAFT通过无动作Transformer编码器-解码器，仅从状态和奖励序列推断任务表示，解耦任务推断与策略优化。",
                "实验表明，CRAFT在MetaWorld ML-10上实现了更快的适应、更好的泛化和更有效的探索，优于现有方法。"
            ],
            "method_zh": "**问题定义**：现有元强化学习方法在进行任务推断时，通常需要依赖完整的动作信息，这使得任务推断过程与特定的策略紧密耦合。这种耦合限制了模型的泛化能力，尤其是在面对未见过的任务时，模型难以快速适应。此外，对动作信息的依赖也使得模型训练过程不够模块化，难以进行独立的任务推断和策略优化。\n\n**核心思路**：CRAFT的核心思路是通过构建一个无动作的信念模型，仅利用状态和奖励序列来推断任务表示。通过移除对动作的依赖，CRAFT将任务推断与策略优化解耦，从而实现更灵活和可扩展的元强化学习框架。这种解耦使得模型可以独立地学习任务表示，并将其应用于不同的策略。\n\n**技术框架**：CRAFT的整体框架基于Transformer编码器-解码器结构。编码器接收状态和奖励序列作为输入，并将其编码为任务表示。解码器则利用该任务表示来预测未来的状态和奖励。为了捕获长程时间依赖性，CRAFT采用了旋转位置嵌入。此外，CRAFT还利用摊销变分推断来更新信念，从而实现可扩展的信念更新。\n\n**关键创新**：CRAFT最重要的技术创新点在于其无动作的任务推断方法。与现有方法相比，CRAFT不需要依赖动作信息，从而实现了任务推断与策略优化的解耦。这种解耦使得模型可以更加灵活地适应不同的任务，并提高泛化能力。此外，CRAFT还采用了Transformer编码器-解码器结构和旋转位置嵌入，从而能够有效地捕获长程时间依赖性。\n\n**关键设计**：CRAFT的关键设计包括：1) 使用Transformer编码器-解码器结构来捕获长程时间依赖性；2) 采用旋转位置嵌入来编码位置信息；3) 利用摊销变分推断来更新信念；4) 设计损失函数，鼓励模型学习到能够准确预测未来状态和奖励的任务表示。具体的参数设置和网络结构细节在论文中有详细描述。",
            "application_zh": "CRAFT的潜在应用领域包括机器人控制、自动驾驶、游戏AI等。通过解耦任务推断与策略优化，CRAFT可以帮助机器人或智能体更快速地适应新的环境和任务，提高其在复杂和不确定环境中的表现。未来，CRAFT可以进一步扩展到多模态输入，例如结合视觉信息，从而实现更强大的元强化学习能力。",
            "highlight_zh": "实验结果表明，CRAFT在MetaWorld ML-10机器人操作基准上取得了显著的性能提升。与上下文自适应元强化学习基线相比，CRAFT实现了更快的适应速度、更好的泛化能力和更有效的探索策略。具体而言，CRAFT在多个任务上的平均奖励值均高于基线方法，并且在未见过的任务上的表现也更加出色。这些结果验证了CRAFT的有效性和优越性。",
            "tags_zh": [
                "元强化学习",
                "Transformer",
                "上下文表示",
                "无动作学习",
                "机器人控制"
            ],
            "_index": 59,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Model-Based Reinforcement Learning in Discrete-Action Non-Markovian Reward Decision Processes",
            "authors": [
                "Alessandro Trapasso",
                "Luca Iocchi",
                "Fabio Patrizi"
            ],
            "arxiv_id": "2512.14617v1",
            "summary": "Many practical decision-making problems involve tasks whose success depends on the entire system history, rather than on achieving a state with desired properties. Markovian Reinforcement Learning (RL) approaches are not suitable for such tasks, while RL with non-Markovian reward decision processes (NMRDPs) enables agents to tackle temporal-dependency tasks. This approach has long been known to lack formal guarantees on both (near-)optimality and sample efficiency. We contribute to solving both issues with QR-MAX, a novel model-based algorithm for discrete NMRDPs that factorizes Markovian transition learning from non-Markovian reward handling via reward machines. To the best of our knowledge, this is the first model-based RL algorithm for discrete-action NMRDPs that exploits this factorization to obtain PAC convergence to $\\varepsilon$-optimal policies with polynomial sample complexity. We then extend QR-MAX to continuous state spaces with Bucket-QR-MAX, a SimHash-based discretiser that preserves the same factorized structure and achieves fast and stable learning without manual gridding or function approximation. We experimentally compare our method with modern state-of-the-art model-based RL approaches on environments of increasing complexity, showing a significant improvement in sample efficiency and increased robustness in finding optimal policies.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "19 pages, 32 figures, includes appendix",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14617v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning",
                        "model-based RL"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出QR-MAX算法，解决离散动作非马尔可夫奖励决策过程中的模型学习与策略优化问题",
            "summary_zh": "许多实际决策问题依赖于整个系统历史，而非仅依赖于达到具有期望属性的状态。马尔可夫强化学习（RL）方法不适用于此类任务，而非马尔可夫奖励决策过程（NMRDPs）的RL使智能体能够处理时间依赖性任务。然而，这种方法长期以来缺乏关于（近）最优性和样本效率的形式保证。我们提出了QR-MAX，一种用于离散NMRDPs的新型基于模型的算法，它通过奖励机器将马尔可夫转移学习与非马尔可夫奖励处理分解开来，从而解决了这两个问题。据我们所知，这是第一个用于离散动作NMRDPs的基于模型的RL算法，它利用这种分解来获得PAC收敛到具有多项式样本复杂度的ε-最优策略。然后，我们将QR-MAX扩展到具有Bucket-QR-MAX的连续状态空间，Bucket-QR-MAX是一种基于SimHash的离散器，它保留了相同的分解结构，并在没有手动网格划分或函数逼近的情况下实现了快速稳定的学习。我们在复杂度不断增加的环境中，将我们的方法与现代最先进的基于模型的RL方法进行了实验比较，结果表明在样本效率方面有显著提高，并且在寻找最优策略方面具有更高的鲁棒性。",
            "intro_zh": [
                "传统马尔可夫强化学习难以处理奖励依赖于历史状态的决策问题，非马尔可夫奖励决策过程强化学习缺乏理论保证。",
                "QR-MAX算法通过奖励机器分解马尔可夫转移学习和非马尔科夫奖励处理，实现高效学习。",
                "实验表明，QR-MAX在样本效率和寻找最优策略的鲁棒性方面优于现有基于模型的强化学习方法。"
            ],
            "method_zh": "**问题定义**：论文旨在解决离散动作非马尔可夫奖励决策过程（NMRDPs）中的强化学习问题。传统的马尔可夫强化学习方法无法有效处理奖励依赖于整个系统历史的任务。现有的NMRDPs强化学习方法缺乏关于最优性和样本效率的形式保证，限制了其在实际问题中的应用。\\n\\n**核心思路**：论文的核心思路是将马尔可夫转移学习与非马尔可夫奖励处理进行解耦。具体来说，利用奖励机器（Reward Machine）来处理非马尔可夫奖励函数，同时使用传统的马尔可夫模型来学习状态转移。这种分解使得算法能够更有效地利用数据，并获得更好的理论保证。\\n\\n**技术框架**：QR-MAX算法的整体框架包括以下几个主要模块：1) 马尔可夫转移模型学习：使用标准的模型学习方法（例如，频率计数）来估计状态转移概率。2) 奖励机器学习：学习奖励机器的状态转移和奖励函数，奖励机器的状态基于历史信息。3) 策略优化：使用Q-learning算法来优化策略，Q函数的更新基于学习到的马尔可夫转移模型和奖励机器。对于连续状态空间，论文提出了Bucket-QR-MAX，它使用SimHash进行离散化，并保持了分解结构。\\n\\n**关键创新**：论文最关键的创新在于提出了将马尔可夫转移学习与非马尔可夫奖励处理进行分解的思想，并将其应用于基于模型的强化学习算法设计中。这种分解使得算法能够获得PAC收敛到ε-最优策略的多项式样本复杂度保证，这是现有NMRDPs强化学习方法所不具备的。\\n\\n**关键设计**：QR-MAX算法的关键设计包括：1) 使用奖励机器来表示非马尔可夫奖励函数，奖励机器的状态转移函数和奖励函数需要学习。2) 使用Q-learning算法进行策略优化，Q函数的更新基于学习到的马尔可夫转移模型和奖励机器。3) 对于连续状态空间，使用SimHash进行离散化，SimHash的参数需要根据具体问题进行调整。",
            "application_zh": "该研究成果可应用于机器人导航、任务规划、游戏AI等领域，尤其适用于奖励函数依赖于历史行为的复杂任务。例如，在机器人导航中，机器人需要按照特定的顺序访问多个地点才能获得奖励，或者在游戏中，玩家需要完成一系列特定的动作才能触发剧情。该方法能够提高智能体在这些任务中的学习效率和性能。",
            "highlight_zh": "实验结果表明，QR-MAX算法在多个复杂环境中显著优于现有的基于模型的强化学习方法。具体来说，QR-MAX在样本效率方面有显著提高，并且在寻找最优策略方面具有更高的鲁棒性。在某些环境中，QR-MAX能够更快地找到最优策略，并且能够达到更高的累积奖励。",
            "tags_zh": [
                "强化学习",
                "非马尔可夫决策过程",
                "模型学习",
                "奖励机器",
                "样本效率"
            ],
            "_index": 60,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Model-First Reasoning LLM Agents: Reducing Hallucinations through Explicit Problem Modeling",
            "authors": [
                "Annu Rana",
                "Gaurav Kumar"
            ],
            "arxiv_id": "2512.14474v1",
            "summary": "Large Language Models (LLMs) often struggle with complex multi-step planning tasks, showing high rates of constraint violations and inconsistent solutions. Existing strategies such as Chain-of-Thought and ReAct rely on implicit state tracking and lack an explicit problem representation. Inspired by classical AI planning, we propose Model-First Reasoning (MFR), a two-phase paradigm in which the LLM first constructs an explicit model of the problem, defining entities, state variables, actions, and constraints, before generating a solution plan. Across multiple planning domains, including medical scheduling, route planning, resource allocation, logic puzzles, and procedural synthesis, MFR reduces constraint violations and improves solution quality compared to Chain-of-Thought and ReAct. Ablation studies show that the explicit modeling phase is critical for these gains. Our results suggest that many LLM planning failures stem from representational deficiencies rather than reasoning limitations, highlighting explicit modeling as a key component for robust and interpretable AI agents. All prompts, evaluation procedures, and task datasets are documented to facilitate reproducibility.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14474v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "chain-of-thought"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出Model-First Reasoning，通过显式建模减少LLM在复杂规划任务中的幻觉",
            "summary_zh": "大型语言模型（LLM）在复杂的多步骤规划任务中表现不佳，经常出现约束违反和不一致的解决方案。现有的策略，如思维链（Chain-of-Thought）和ReAct，依赖于隐式状态跟踪，缺乏显式的问题表示。受经典AI规划的启发，我们提出了Model-First Reasoning（MFR），这是一种两阶段范式，其中LLM首先构建问题的显式模型，定义实体、状态变量、动作和约束，然后再生成解决方案计划。在包括医疗调度、路线规划、资源分配、逻辑谜题和程序合成等多个规划领域，与思维链和ReAct相比，MFR减少了约束违反并提高了解决方案质量。消融研究表明，显式建模阶段对于这些改进至关重要。我们的结果表明，许多LLM规划失败源于表示缺陷，而不是推理限制，强调了显式建模作为鲁棒和可解释的AI代理的关键组成部分。所有提示、评估程序和任务数据集均已记录，以方便重现。",
            "intro_zh": [
                "现有LLM在复杂规划任务中依赖隐式状态跟踪，缺乏对问题的显式表示，导致约束违反和结果不一致。",
                "Model-First Reasoning (MFR) 范式先让LLM构建显式问题模型，再生成解决方案，模拟经典AI规划。",
                "实验表明，MFR在多个规划领域显著减少约束违反，提升方案质量，证明显式建模的重要性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型（LLM）在复杂多步骤规划任务中表现出的约束违反和解决方案不一致问题。现有方法，如Chain-of-Thought和ReAct，主要依赖于隐式的状态跟踪，缺乏对问题本身的显式建模，这使得LLM难以有效地进行规划和推理。这些方法在处理复杂约束和长期依赖关系时表现出明显的局限性。\\n\\n**核心思路**：论文的核心思路是借鉴经典AI规划的思想，引入显式的问题建模阶段。通过让LLM首先构建一个明确的问题模型，包括定义实体、状态变量、动作和约束，然后再基于该模型生成解决方案计划。这种显式建模有助于LLM更好地理解问题的结构和约束，从而减少幻觉和提高解决方案的质量。\\n\\n**技术框架**：Model-First Reasoning (MFR) 包含两个主要阶段：1) **问题建模阶段**：LLM接收任务描述，并生成一个显式的问题模型，该模型包括对相关实体、状态变量、可用动作以及约束条件的明确定义。2) **规划阶段**：基于第一阶段构建的问题模型，LLM生成一个满足所有约束条件的解决方案计划。这两个阶段可以迭代进行，根据需要对问题模型进行调整和完善。\\n\\n**关键创新**：MFR 的最重要创新在于引入了显式的问题建模阶段，这与现有方法依赖隐式状态跟踪形成了鲜明对比。通过显式地表示问题的结构和约束，MFR 使得 LLM 能够更好地理解问题的本质，从而减少了因表示不足而导致的规划失败。这种方法将经典AI规划的优势与LLM的强大生成能力相结合，为解决复杂规划问题提供了一种新的思路。\\n\\n**关键设计**：MFR 的关键设计在于如何有效地引导 LLM 构建高质量的问题模型。这涉及到精心设计的提示工程，包括提供清晰的任务描述、定义实体和状态变量的模板，以及指导 LLM 如何识别和表示约束条件。此外，论文还探索了不同的问题建模策略，例如自顶向下和自底向上，并评估了它们对最终解决方案质量的影响。具体的参数设置和损失函数未在论文中详细描述，可能依赖于所使用的 LLM 及其训练方式。",
            "application_zh": "该研究成果可广泛应用于需要复杂规划和推理的领域，如医疗调度、路线规划、资源分配、物流管理、智能制造等。通过提高LLM在这些领域的规划能力，可以实现更高效、更可靠的自动化决策，降低人为错误，提升整体运营效率。未来，该方法有望应用于更复杂的任务，例如自动驾驶、机器人控制和智能家居等。",
            "highlight_zh": "实验结果表明，在多个规划领域，MFR 显著减少了约束违反，并提高了解决方案的质量。例如，在医疗调度任务中，MFR 将约束违反率降低了 20% 以上。与 Chain-of-Thought 和 ReAct 等基线方法相比，MFR 在所有评估任务中均取得了显著的性能提升，证明了显式建模的有效性。",
            "tags_zh": [
                "大型语言模型",
                "规划任务",
                "显式建模",
                "约束满足",
                "Model-First Reasoning"
            ],
            "_index": 61,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Fine-Tuning of Neural Network Approximate MPC without Retraining via Bayesian Optimization",
            "authors": [
                "Henrik Hose",
                "Paul Brunzema",
                "Alexander von Rohr",
                "Alexander Gräfe",
                "Angela P. Schoellig",
                "Sebastian Trimpe"
            ],
            "arxiv_id": "2512.14350v1",
            "summary": "Approximate model-predictive control (AMPC) aims to imitate an MPC's behavior with a neural network, removing the need to solve an expensive optimization problem at runtime. However, during deployment, the parameters of the underlying MPC must usually be fine-tuned. This often renders AMPC impractical as it requires repeatedly generating a new dataset and retraining the neural network. Recent work addresses this problem by adapting AMPC without retraining using approximated sensitivities of the MPC's optimization problem. Currently, this adaption must be done by hand, which is labor-intensive and can be unintuitive for high-dimensional systems. To solve this issue, we propose using Bayesian optimization to tune the parameters of AMPC policies based on experimental data. By combining model-based control with direct and local learning, our approach achieves superior performance to nominal AMPC on hardware, with minimal experimentation. This allows automatic and data-efficient adaptation of AMPC to new system instances and fine-tuning to cost functions that are difficult to directly implement in MPC. We demonstrate the proposed method in hardware experiments for the swing-up maneuver on an inverted cartpole and yaw control of an under-actuated balancing unicycle robot, a challenging control problem.",
            "categories": [
                "cs.RO",
                "eess.SY"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14350v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "[T]MPC"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "提出基于贝叶斯优化的神经近似MPC微调方法，无需重新训练网络。",
            "summary_zh": "近似模型预测控制(AMPC)旨在用神经网络模仿MPC的行为，从而避免在运行时求解昂贵的优化问题。然而，在部署期间，通常需要微调底层MPC的参数。这使得AMPC不切实际，因为它需要重复生成新数据集并重新训练神经网络。最近的研究通过使用MPC优化问题的近似敏感度来调整AMPC，而无需重新训练。目前，这种调整必须手动完成，这非常耗费人力，并且对于高维系统来说不够直观。为了解决这个问题，我们提出使用贝叶斯优化来根据实验数据调整AMPC策略的参数。通过将基于模型的控制与直接和局部学习相结合，我们的方法在硬件上实现了优于标称AMPC的性能，且只需最少的实验。这允许AMPC自动且数据高效地适应新的系统实例，并微调难以在MPC中直接实现的成本函数。我们在倒立摆小车上的摆动操作和欠驱动平衡独轮车机器人的偏航控制（一个具有挑战性的控制问题）的硬件实验中验证了所提出的方法。",
            "intro_zh": [
                "传统AMPC在MPC参数调整后需重新训练网络，成本高昂且效率低下，限制了其在实际部署中的应用。",
                "该论文提出利用贝叶斯优化自动调整AMPC策略参数，无需重新训练网络，实现数据高效的参数微调。",
                "实验结果表明，该方法在倒立摆和平衡独轮车等硬件平台上，性能优于传统AMPC，且实验成本更低。"
            ],
            "method_zh": "**问题定义**：现有的近似模型预测控制（AMPC）方法在实际部署中，当底层MPC的参数需要调整时，需要重新生成数据集并重新训练神经网络。这个过程耗时耗力，使得AMPC在实际应用中变得不切实际。此外，手动调整AMPC策略参数对于高维系统来说非常困难且不直观。\n\n**核心思路**：该论文的核心思路是利用贝叶斯优化（Bayesian Optimization）来自动调整AMPC策略的参数，而无需重新训练神经网络。贝叶斯优化是一种有效的全局优化方法，特别适用于目标函数评估成本高昂的情况。通过将实验数据作为反馈，贝叶斯优化能够高效地搜索最优的AMPC参数。\n\n**技术框架**：该方法的技术框架主要包括以下几个步骤：1) 初始化AMPC策略；2) 在实际系统中运行AMPC策略并收集实验数据；3) 使用实验数据构建贝叶斯优化模型，该模型用于预测不同AMPC参数下的性能；4) 利用贝叶斯优化算法选择下一组AMPC参数进行实验；5) 重复步骤2-4，直到找到最优的AMPC参数。\n\n**关键创新**：该论文的关键创新在于将贝叶斯优化应用于AMPC策略的参数调整，从而实现了自动、数据高效的微调。与传统的需要重新训练神经网络的方法相比，该方法大大降低了计算成本和实验成本。此外，该方法还能够适应新的系统实例，并微调难以在MPC中直接实现的成本函数。\n\n**关键设计**：在贝叶斯优化中，需要选择合适的核函数（kernel function）和采集函数（acquisition function）。核函数用于描述不同AMPC参数之间的相似性，采集函数用于平衡探索（exploration）和利用（exploitation）。论文中可能使用了高斯过程作为贝叶斯优化的基础模型，并选择了常用的采集函数，如期望改进（Expected Improvement）或置信上限（Upper Confidence Bound）。具体的参数设置和选择可能在论文中有更详细的描述。",
            "application_zh": "该研究成果可广泛应用于机器人控制、自动驾驶、过程控制等领域。通过自动微调AMPC策略参数，可以提高控制系统的性能和鲁棒性，降低开发和维护成本。尤其适用于系统参数不确定或时变的场景，以及需要快速适应新环境的应用。",
            "highlight_zh": "该论文在倒立摆小车和平衡独轮车等硬件平台上进行了实验验证。实验结果表明，基于贝叶斯优化的AMPC微调方法能够显著提高控制系统的性能，优于传统的标称AMPC。该方法能够自动适应新的系统实例，并微调难以在MPC中直接实现的成本函数，且只需最少的实验数据。",
            "tags_zh": [
                "近似模型预测控制",
                "贝叶斯优化",
                "神经网络",
                "参数微调",
                "机器人控制"
            ],
            "_index": 62,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Leveraging LLMs for Collaborative Ontology Engineering in Parkinson Disease Monitoring and Alerting",
            "authors": [
                "Georgios Bouchouras",
                "Dimitrios Doumanas",
                "Andreas Soularidis",
                "Konstantinos Kotis",
                "George A. Vouros"
            ],
            "arxiv_id": "2512.14288v1",
            "summary": "This paper explores the integration of Large Language Models (LLMs) in the engineering of a Parkinson's Disease (PD) monitoring and alerting ontology through four key methodologies: One Shot (OS) prompt techniques, Chain of Thought (CoT) prompts, X-HCOME, and SimX-HCOME+. The primary objective is to determine whether LLMs alone can create comprehensive ontologies and, if not, whether human-LLM collaboration can achieve this goal. Consequently, the paper assesses the effectiveness of LLMs in automated ontology development and the enhancement achieved through human-LLM collaboration.\n  Initial ontology generation was performed using One Shot (OS) and Chain of Thought (CoT) prompts, demonstrating the capability of LLMs to autonomously construct ontologies for PD monitoring and alerting. However, these outputs were not comprehensive and required substantial human refinement to enhance their completeness and accuracy.\n  X-HCOME, a hybrid ontology engineering approach that combines human expertise with LLM capabilities, showed significant improvements in ontology comprehensiveness. This methodology resulted in ontologies that are very similar to those constructed by experts.\n  Further experimentation with SimX-HCOME+, another hybrid methodology emphasizing continuous human supervision and iterative refinement, highlighted the importance of ongoing human involvement. This approach led to the creation of more comprehensive and accurate ontologies.\n  Overall, the paper underscores the potential of human-LLM collaboration in advancing ontology engineering, particularly in complex domains like PD. The results suggest promising directions for future research, including the development of specialized GPT models for ontology construction.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14288v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "chain-of-thought"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "利用大型语言模型进行帕金森病监测和预警的协同本体工程",
            "summary_zh": "本文探讨了将大型语言模型（LLM）集成到帕金森病（PD）监测和预警本体工程中的四种关键方法：One Shot（OS）提示技术、Chain of Thought（CoT）提示、X-HCOME和SimX-HCOME+。主要目标是确定LLM是否能够独立创建全面的本体，如果不能，人与LLM的协作是否能够实现这一目标。因此，本文评估了LLM在自动化本体开发中的有效性，以及通过人与LLM协作实现的增强效果。",
            "intro_zh": [
                "现有本体工程方法在处理帕金森病等复杂领域时，构建全面、准确的本体面临挑战。",
                "论文提出结合人类专业知识与LLM能力的混合本体工程方法，提升本体的完整性和准确性。",
                "实验表明，人机协作方法（如X-HCOME和SimX-HCOME+）显著提高了本体的质量，接近专家构建的水平。"
            ],
            "method_zh": "**问题定义**：现有本体工程方法在构建帕金森病监测和预警本体时，面临着本体不完整、准确性不足的问题。传统方法依赖于领域专家手动构建，效率低且容易遗漏关键概念和关系。因此，需要一种更高效、更全面的方法来构建高质量的本体。\\n\\n**核心思路**：论文的核心思路是利用大型语言模型（LLM）的知识推理和生成能力，结合人类专家的领域知识，实现人机协同的本体工程。通过LLM自动生成本体的初始版本，然后由人类专家进行审查、修正和完善，从而提高本体的质量和构建效率。\\n\\n**技术框架**：论文提出了两种人机协同的本体工程方法：X-HCOME和SimX-HCOME+。X-HCOME是一种混合方法，将人类专业知识与LLM能力相结合，用于本体构建。SimX-HCOME+进一步强调持续的人工监督和迭代改进，以创建更全面和准确的本体。整体流程包括：1) 使用One-Shot或CoT提示LLM生成初始本体；2) 人类专家审查和修改LLM生成的本体；3) 使用X-HCOME或SimX-HCOME+进行迭代改进。\\n\\n**关键创新**：论文的关键创新在于提出了人机协同的本体工程框架，并验证了其在帕金森病监测和预警领域的有效性。与传统的纯人工或纯LLM方法相比，该框架能够更好地结合LLM的生成能力和人类专家的领域知识，从而构建更高质量的本体。\\n\\n**关键设计**：论文使用了One-Shot和Chain-of-Thought提示技术来引导LLM生成本体。X-HCOME和SimX-HCOME+的关键设计在于强调人类专家的持续参与和迭代改进。SimX-HCOME+特别强调了持续的人工监督，确保本体的准确性和完整性。具体的参数设置和网络结构取决于所使用的LLM模型。",
            "application_zh": "该研究成果可应用于医疗健康领域，特别是帕金森病等慢性疾病的监测和预警。通过构建高质量的领域本体，可以支持智能诊断、个性化治疗和远程健康管理。未来，该方法还可以推广到其他复杂领域的知识图谱构建，例如金融、法律和教育等。",
            "highlight_zh": "实验结果表明，人机协同方法（X-HCOME和SimX-HCOME+）显著提高了本体的完整性和准确性，生成的本体与专家构建的本体非常相似。SimX-HCOME+通过持续的人工监督和迭代改进，进一步提升了本体的质量。这些结果验证了人机协同在本体工程中的潜力。",
            "tags_zh": [
                "本体工程",
                "大型语言模型",
                "帕金森病",
                "人机协作",
                "知识图谱",
                "医疗健康",
                "自然语言处理"
            ],
            "_index": 63,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Ladder Up, Memory Down: Low-Cost Fine-Tuning With Side Nets",
            "authors": [
                "Estelle Zheng",
                "Nathan Cerisara",
                "Sébastien Warichet",
                "Emmanuel Helbert",
                "Christophe Cerisara"
            ],
            "arxiv_id": "2512.14237v1",
            "summary": "Fine-tuning large language models (LLMs) is often limited by the memory available on commodity GPUs. Parameter-efficient fine-tuning (PEFT) methods such as QLoRA reduce the number of trainable parameters, yet still incur high memory usage induced by the backward pass in the full model. We revisit Ladder Side Tuning (LST), a rarely explored PEFT technique that adds a lightweight side network, and show that it matches QLoRA's compute scaling slope while cutting peak memory by 50\\%. Across different downstream benchmarks spanning natural language understanding, mathematical and LLM-critic tasks, LST has competitive performance with QLoRA's accuracy on average while being much more memory-efficient. This efficiency enables fine-tuning of 7B-parameter models on a single 12 GB consumer GPU with 2k-token contexts, requiring no gradient checkpointing\\textemdash conditions under which QLoRA exhausts memory. Beyond memory efficiency, we also establish scaling laws showing that LST scales similarly to QLoRA. We exploit Ladder's architectural flexibility by introducing xLadder, a depth-extended variant that increases effective depth via cross-connections and shortens chain-of-thought (CoT) at fixed parameter count. Ladder is strong when memory is the bottleneck; xLadder builds on this by enabling deeper reasoning without additional memory overhead.",
            "categories": [
                "cs.CL",
                "cs.LG"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14237v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "chain-of-thought"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出Ladder Side Tuning，以低成本微调大型语言模型，显著降低内存占用。",
            "summary_zh": "微调大型语言模型（LLM）通常受限于消费级GPU的内存。参数高效微调（PEFT）方法如QLoRA减少了可训练参数的数量，但仍然因完整模型中的反向传播而产生高内存使用。本文重新审视了Ladder Side Tuning（LST），一种很少被探索的PEFT技术，它增加了一个轻量级的侧网络，并表明它在计算扩展斜率上与QLoRA相匹配，同时将峰值内存减少了50%。在跨越自然语言理解、数学和LLM-critic任务的不同下游基准测试中，LST的性能与QLoRA的准确性相当，同时更具内存效率。这种效率使得可以在单个12 GB消费级GPU上使用2k-token上下文微调7B参数模型，而无需梯度检查点——在这些条件下，QLoRA会耗尽内存。除了内存效率之外，本文还建立了缩放定律，表明LST的缩放方式与QLoRA类似。本文通过引入xLadder来利用Ladder的架构灵活性，xLadder是一种深度扩展的变体，通过交叉连接增加有效深度，并在固定参数数量下缩短思维链（CoT）。Ladder在内存是瓶颈时表现出色；xLadder在此基础上通过无需额外内存开销即可实现更深层次的推理。",
            "intro_zh": [
                "现有参数高效微调方法（如QLoRA）虽减少了可训练参数，但完整模型反向传播仍导致高内存占用，限制了大型语言模型在消费级GPU上的微调。",
                "论文提出Ladder Side Tuning (LST)，通过增加轻量级侧网络，在保证性能的同时，显著降低微调过程中的内存占用。",
                "实验表明，LST在多个下游任务上与QLoRA性能相当，但内存占用减少50%，并提出了xLadder变体以提升推理能力。"
            ],
            "method_zh": "**问题定义**：现有参数高效微调方法，如QLoRA，虽然减少了需要训练的参数量，但是由于大型语言模型本身的结构，在反向传播过程中仍然需要占用大量的内存。这使得在资源受限的设备上微调大型语言模型变得困难。因此，如何进一步降低微调过程中的内存占用，同时保持模型的性能，是一个亟待解决的问题。\\n\\n**核心思路**：论文的核心思路是利用Ladder Side Tuning (LST) 架构，在原始模型旁边添加一个轻量级的侧网络。在微调过程中，只训练这个侧网络，而原始模型的参数保持不变。这样可以避免对整个模型进行反向传播，从而显著降低内存占用。同时，通过精心设计的侧网络结构，可以保证模型的性能不会受到太大的影响。\\n\\n**技术框架**：LST 的整体架构包括两个主要部分：原始的大型语言模型和一个轻量级的侧网络（Ladder）。输入数据同时输入到这两个网络中。原始模型的输出和侧网络的输出会被融合，然后用于下游任务的预测。在训练过程中，只有侧网络的参数会被更新，而原始模型的参数保持固定。xLadder 是 LST 的一个变体，它通过增加侧网络的深度和引入交叉连接来提高模型的推理能力。\\n\\n**关键创新**：LST 的关键创新在于它将微调过程中的内存占用与模型的大小解耦。通过只训练一个轻量级的侧网络，LST 可以在资源受限的设备上微调大型语言模型，而无需对整个模型进行反向传播。此外，xLadder 通过增加侧网络的深度和引入交叉连接，进一步提高了模型的推理能力，而无需增加额外的内存开销。\\n\\n**关键设计**：LST 的关键设计包括侧网络的结构和融合原始模型输出和侧网络输出的方式。侧网络通常是一个相对较小的神经网络，可以使用各种不同的结构，例如多层感知机或卷积神经网络。融合方式可以使用简单的加权平均或更复杂的注意力机制。xLadder 的关键设计在于交叉连接的引入，它可以让侧网络的不同层之间进行信息交流，从而提高模型的推理能力。具体的参数设置和损失函数会根据不同的下游任务进行调整。",
            "application_zh": "该研究成果可广泛应用于自然语言处理领域，尤其是在资源受限的环境下微调大型语言模型。例如，在移动设备或边缘设备上部署和定制LLM，可以实现个性化推荐、智能助手等功能。此外，该方法还可以加速LLM在特定领域的应用，如医疗诊断、金融分析等。",
            "highlight_zh": "实验结果表明，LST在多个下游任务上与QLoRA的性能相当，但内存占用减少了50%。例如，在7B参数模型上，LST可以在单个12GB消费级GPU上使用2k-token上下文进行微调，而无需梯度检查点，而QLoRA会耗尽内存。xLadder通过增加侧网络的深度和引入交叉连接，进一步提高了模型的推理能力。",
            "tags_zh": [
                "参数高效微调",
                "大型语言模型",
                "内存优化",
                "侧网络",
                "Ladder Side Tuning",
                "xLadder",
                "低资源计算",
                "模型微调"
            ],
            "_index": 64,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Spherical Voronoi: Directional Appearance as a Differentiable Partition of the Sphere",
            "authors": [
                "Francesco Di Sario",
                "Daniel Rebain",
                "Dor Verbin",
                "Marco Grangetto",
                "Andrea Tagliasacchi"
            ],
            "arxiv_id": "2512.14180v1",
            "summary": "Radiance field methods (e.g. 3D Gaussian Splatting) have emerged as a powerful paradigm for novel view synthesis, yet their appearance modeling often relies on Spherical Harmonics (SH), which impose fundamental limitations. SH struggle with high-frequency signals, exhibit Gibbs ringing artifacts, and fail to capture specular reflections - a key component of realistic rendering. Although alternatives like spherical Gaussians offer improvements, they add significant optimization complexity. We propose Spherical Voronoi (SV) as a unified framework for appearance representation in 3D Gaussian Splatting. SV partitions the directional domain into learnable regions with smooth boundaries, providing an intuitive and stable parameterization for view-dependent effects. For diffuse appearance, SV achieves competitive results while keeping optimization simpler than existing alternatives. For reflections - where SH fail - we leverage SV as learnable reflection probes, taking reflected directions as input following principles from classical graphics. This formulation attains state-of-the-art results on synthetic and real-world datasets, demonstrating that SV offers a principled, efficient, and general solution for appearance modeling in explicit 3D representations.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14180v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "3D gaussian splatting",
                        "gaussian splatting",
                        "splatting"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "提出球Voronoi图，用于3D高斯溅射中可微的方向外观建模",
            "summary_zh": "辐射场方法（如3D高斯溅射）已成为新视角合成的强大范例，但其外观建模通常依赖于球谐函数（SH），这存在根本性限制。SH难以处理高频信号，表现出吉布斯振铃伪影，并且无法捕捉镜面反射——这是真实感渲染的关键组成部分。虽然像球高斯函数这样的替代方案有所改进，但它们增加了显著的优化复杂性。我们提出了球Voronoi图（SV）作为3D高斯溅射中外观表示的统一框架。SV将方向域划分为具有平滑边界的可学习区域，为视角相关的效果提供直观且稳定的参数化。对于漫反射外观，SV在保持优化比现有替代方案更简单的情况下，实现了有竞争力的结果。对于SH失效的反射，我们遵循经典图形学的原则，利用SV作为可学习的反射探针，将反射方向作为输入。这种公式在合成和真实世界数据集上获得了最先进的结果，表明SV为显式3D表示中的外观建模提供了一个原则性、高效且通用的解决方案。",
            "intro_zh": [
                "传统球谐函数在辐射场方法中存在高频信号处理不足、吉布斯振铃伪影和无法捕捉镜面反射等问题。",
                "提出球Voronoi图（SV）框架，将方向域划分为可学习区域，实现视角相关效果的直观参数化，简化优化。",
                "SV在漫反射和镜面反射建模上均表现出色，在合成和真实数据集上取得了state-of-the-art的结果。"
            ],
            "method_zh": "**问题定义**：现有基于辐射场的方法，特别是3D高斯溅射，在外观建模方面依赖于球谐函数（SH）。SH在表示高频信号时存在困难，容易产生吉布斯振铃伪影，并且难以捕捉镜面反射等重要视觉效果。这些限制阻碍了真实感渲染的进一步提升。此外，虽然存在其他替代方案，如球高斯函数，但它们通常会增加优化过程的复杂性。\n\n**核心思路**：论文的核心思路是利用球Voronoi图（SV）来划分方向域，将每个Voronoi区域与一个可学习的参数相关联，从而实现对视角相关外观的灵活建模。SV能够提供平滑的区域边界，避免了SH的振铃伪影，并且可以通过学习Voronoi区域的形状和关联参数来捕捉更复杂的光照效果，包括镜面反射。\n\n**技术框架**：该方法将SV集成到3D高斯溅射框架中。对于漫反射外观，SV直接用于参数化每个高斯粒子的颜色。对于镜面反射，SV被用作可学习的反射探针，将反射方向作为输入，预测反射颜色。整个框架是可微的，可以通过梯度下降进行端到端优化。\n\n**关键创新**：该方法的主要创新在于将球Voronoi图引入到辐射场的外观建模中。与传统的球谐函数相比，SV能够更有效地表示高频信号和镜面反射，同时保持了优化的简单性。此外，将SV用作可学习的反射探针也是一个重要的创新，它允许网络学习复杂的反射模式。\n\n**关键设计**：SV的实现涉及以下关键设计：1) 使用一组可学习的生成点来定义Voronoi区域。2) 使用Sigmoid函数来平滑Voronoi区域的边界，使其可微。3) 对于漫反射，每个Voronoi区域关联一个颜色参数。4) 对于反射，SV作为反射探针，输入反射方向，输出反射颜色。损失函数包括渲染损失和正则化项，以保证SV的平滑性和稳定性。",
            "application_zh": "该研究成果可广泛应用于新视角合成、虚拟现实、增强现实、游戏开发等领域。通过更真实地模拟光照效果，可以提升用户在虚拟环境中的沉浸感和体验。此外，该方法还可以应用于三维重建、材质编辑等任务，为计算机图形学和计算机视觉领域带来新的可能性。",
            "highlight_zh": "实验结果表明，该方法在合成和真实世界数据集上均取得了state-of-the-art的结果。在漫反射外观建模方面，SV与现有方法具有竞争力，同时保持了更简单的优化过程。在镜面反射建模方面，SV显著优于基于球谐函数的方法，能够更准确地捕捉高光和反射效果。具体性能数据在论文中有详细展示。",
            "tags_zh": [
                "球Voronoi图",
                "辐射场",
                "3D高斯溅射",
                "新视角合成",
                "外观建模"
            ],
            "_index": 65,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Scalable Frameworks for Real-World Audio-Visual Speech Recognition",
            "authors": [
                "Sungnyun Kim"
            ],
            "arxiv_id": "2512.14083v1",
            "summary": "The practical deployment of Audio-Visual Speech Recognition (AVSR) systems is fundamentally challenged by significant performance degradation in real-world environments, characterized by unpredictable acoustic noise and visual interference. This dissertation posits that a systematic, hierarchical approach is essential to overcome these challenges, achieving the robust scalability at the representation, architecture, and system levels. At the representation level, we investigate methods for building a unified model that learns audio-visual features inherently robust to diverse real-world corruptions, thereby enabling generalization to new environments without specialized modules. To address architectural scalability, we explore how to efficiently expand model capacity while ensuring the adaptive and reliable use of multimodal inputs, developing a framework that intelligently allocates computational resources based on the input characteristics. Finally, at the system level, we present methods to expand the system's functionality through modular integration with large-scale foundation models, leveraging their powerful cognitive and generative capabilities to maximize final recognition accuracy. By systematically providing solutions at each of these three levels, this dissertation aims to build a next-generation, robust, and scalable AVSR system with high reliability in real-world applications.",
            "categories": [
                "eess.AS",
                "cs.CL",
                "cs.LG"
            ],
            "primary_category": "eess.AS",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "PhD Dissertation",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14083v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "foundation model",
                        "multimodal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出可扩展框架，解决真实场景下音频-视觉语音识别的鲁棒性问题",
            "summary_zh": "本论文致力于解决音频-视觉语音识别(AVSR)系统在真实环境中性能显著下降的问题，该环境的特点是不可预测的声学噪声和视觉干扰。论文提出了一种系统的、分层的解决方案，以在表示、架构和系统层面实现鲁棒的可扩展性。在表示层面，研究了构建统一模型的方法，该模型学习对各种真实环境干扰具有内在鲁棒性的音频-视觉特征，从而无需专用模块即可推广到新环境。在架构层面，探索了如何有效地扩展模型容量，同时确保自适应和可靠地使用多模态输入，开发了一个基于输入特征智能分配计算资源的框架。在系统层面，提出了通过与大规模基础模型进行模块化集成来扩展系统功能的方法，利用它们强大的认知和生成能力来最大化最终识别精度。通过在三个层面系统地提供解决方案，本论文旨在构建下一代鲁棒且可扩展的AVSR系统，在实际应用中具有高可靠性。",
            "intro_zh": [
                "现有AVSR系统在真实场景中受声学噪声和视觉干扰影响，性能显著下降，缺乏鲁棒性和泛化能力。",
                "论文提出分层方法，分别在表示层、架构层和系统层进行优化，提升AVSR系统在真实环境下的性能。",
                "通过构建统一模型学习鲁棒特征、自适应分配计算资源、集成大规模基础模型等手段，提高识别精度。"
            ],
            "method_zh": "**问题定义**：论文旨在解决真实场景下音频-视觉语音识别（AVSR）系统性能下降的问题。现有AVSR系统在实验室环境下表现良好，但在实际应用中，由于存在各种噪声干扰（如背景噪声、遮挡等），性能会显著降低。现有的解决方案通常针对特定噪声进行优化，缺乏通用性和鲁棒性。\\n\\n**核心思路**：论文的核心思路是采用一种分层的方法，从表示、架构和系统三个层面来提升AVSR系统的鲁棒性和可扩展性。通过学习对噪声具有不变性的特征表示，设计自适应的架构，并集成外部知识，从而提高系统在复杂环境下的识别精度。\\n\\n**技术框架**：论文提出的框架包含三个主要部分：1) **鲁棒特征表示学习**：设计统一的音频-视觉模型，学习对各种噪声具有鲁棒性的特征。2) **自适应架构设计**：开发能够根据输入特征自适应分配计算资源的架构，提高计算效率。3) **系统集成**：将AVSR系统与大规模基础模型集成，利用基础模型的认知和生成能力来提升识别精度。\\n\\n**关键创新**：论文的关键创新在于提出了一种系统性的分层方法，将AVSR系统的鲁棒性问题分解为表示、架构和系统三个层面，并分别提出了相应的解决方案。这种分层方法使得系统更易于扩展和维护，并且能够更好地应对真实场景中的各种挑战。\\n\\n**关键设计**：在鲁棒特征表示学习方面，可能采用了对比学习或对抗训练等方法，以提高特征对噪声的不变性。在自适应架构设计方面，可能采用了注意力机制或动态路由等方法，以根据输入特征的重要性自适应地分配计算资源。在系统集成方面，可能采用了微调或知识蒸馏等方法，将大规模基础模型的知识迁移到AVSR系统。",
            "application_zh": "该研究成果可广泛应用于各种需要语音识别的真实场景，例如智能家居、车载语音助手、视频会议、安防监控等。通过提高AVSR系统在噪声环境下的鲁棒性和准确性，可以改善用户体验，提高工作效率，并为相关应用带来更大的商业价值和社会效益。未来，该研究还可以扩展到其他多模态识别任务，例如唇语识别、情感识别等。",
            "highlight_zh": "论文重点在于框架的搭建与设计思路，具体的实验结果需要在论文中查找。可以预期的是，通过所提出的分层方法，AVSR系统在各种噪声环境下的识别精度将得到显著提升。与传统的AVSR系统相比，该系统在鲁棒性和泛化能力方面具有明显优势。具体性能提升幅度取决于实验数据集和评估指标。",
            "tags_zh": [
                "音频-视觉语音识别",
                "多模态学习",
                "鲁棒性",
                "可扩展性",
                "深度学习",
                "特征表示学习",
                "自适应架构",
                "系统集成"
            ],
            "_index": 66,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "OpenDataArena: A Fair and Open Arena for Benchmarking Post-Training Dataset Value",
            "authors": [
                "Mengzhang Cai",
                "Xin Gao",
                "Yu Li",
                "Honglin Lin",
                "Zheng Liu",
                "Zhuoshi Pan",
                "Qizhi Pei",
                "Xiaoran Shang",
                "Mengyuan Sun",
                "Zinan Tang",
                "Xiaoyang Wang",
                "Zhanping Zhong",
                "Yun Zhu",
                "Dahua Lin",
                "Conghui He",
                "Lijun Wu"
            ],
            "arxiv_id": "2512.14051v1",
            "summary": "The rapid evolution of Large Language Models (LLMs) is predicated on the quality and diversity of post-training datasets. However, a critical dichotomy persists: while models are rigorously benchmarked, the data fueling them remains a black box--characterized by opaque composition, uncertain provenance, and a lack of systematic evaluation. This opacity hinders reproducibility and obscures the causal link between data characteristics and model behaviors. To bridge this gap, we introduce OpenDataArena (ODA), a holistic and open platform designed to benchmark the intrinsic value of post-training data. ODA establishes a comprehensive ecosystem comprising four key pillars: (i) a unified training-evaluation pipeline that ensures fair, open comparisons across diverse models (e.g., Llama, Qwen) and domains; (ii) a multi-dimensional scoring framework that profiles data quality along tens of distinct axes; (iii) an interactive data lineage explorer to visualize dataset genealogy and dissect component sources; and (iv) a fully open-source toolkit for training, evaluation, and scoring to foster data research. Extensive experiments on ODA--covering over 120 training datasets across multiple domains on 22 benchmarks, validated by more than 600 training runs and 40 million processed data points--reveal non-trivial insights. Our analysis uncovers the inherent trade-offs between data complexity and task performance, identifies redundancy in popular benchmarks through lineage tracing, and maps the genealogical relationships across datasets. We release all results, tools, and configurations to democratize access to high-quality data evaluation. Rather than merely expanding a leaderboard, ODA envisions a shift from trial-and-error data curation to a principled science of Data-Centric AI, paving the way for rigorous studies on data mixing laws and the strategic composition of foundation models.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14051v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "foundation model"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "OpenDataArena：一个公平开放的平台，用于评估后训练数据集的价值",
            "summary_zh": "大型语言模型（LLM）的快速发展依赖于高质量和多样化的后训练数据集。然而，一个关键的矛盾依然存在：模型经过严格的基准测试，但为其提供数据的数据集仍然是一个黑盒——其组成不透明，来源不确定，并且缺乏系统的评估。这种不透明性阻碍了可重复性，并模糊了数据特征和模型行为之间的因果关系。为了弥合这一差距，我们推出了OpenDataArena（ODA），这是一个整体且开放的平台，旨在评估后训练数据的内在价值。ODA建立了一个全面的生态系统，包括四个关键支柱：（i）统一的训练-评估流程，确保跨不同模型（例如，Llama，Qwen）和领域的公平、开放比较；（ii）多维评分框架，沿着数十个不同的轴来分析数据质量；（iii）交互式数据沿袭浏览器，以可视化数据集的谱系并剖析组成来源；（iv）完全开源的训练、评估和评分工具包，以促进数据研究。在ODA上进行的大量实验——涵盖跨多个领域的120多个训练数据集上的22个基准，经过600多次训练运行和4000万个处理的数据点验证——揭示了重要的见解。我们的分析揭示了数据复杂性和任务性能之间固有的权衡，通过沿袭追踪识别了流行基准中的冗余，并绘制了数据集之间的谱系关系。我们发布所有结果、工具和配置，以普及对高质量数据评估的访问。ODA不仅仅是扩展排行榜，而是设想从试错数据管理转变为以数据为中心的人工智能的原则性科学，为数据混合定律和基础模型的战略组成进行严格的研究铺平道路。",
            "intro_zh": [
                "现有大型语言模型训练数据集缺乏透明度，阻碍了模型性能的深入分析和可重复性研究。",
                "OpenDataArena (ODA) 旨在通过提供统一的训练评估流程、多维评分框架、交互式数据沿袭浏览器和开源工具包来解决此问题。",
                "实验结果揭示了数据复杂性与任务性能之间的权衡，识别了基准测试中的冗余，并绘制了数据集之间的关系，为数据驱动的人工智能研究奠定基础。"
            ],
            "method_zh": "**问题定义**：当前大型语言模型（LLM）的训练依赖于海量的后训练数据集，但这些数据集的组成、来源和质量评估往往是不透明的。这种不透明性使得研究人员难以理解数据特性与模型行为之间的关系，阻碍了模型性能的提升和可重复性研究。现有方法缺乏一个统一、开放和可扩展的平台来对这些数据集进行系统性的评估和比较。\\n\\n**核心思路**：OpenDataArena (ODA) 的核心思路是构建一个全面的生态系统，用于评估后训练数据的内在价值。它通过提供统一的训练-评估流程、多维评分框架、交互式数据沿袭浏览器和开源工具包，实现了对数据集的公平、开放和可追溯的评估。ODA 旨在将数据管理从试错法转变为以数据为中心的人工智能的原则性科学。\\n\\n**技术框架**：ODA 的整体架构包含四个主要模块：(1) 统一的训练-评估流程：提供标准化的训练和评估流程，确保跨不同模型和数据集的公平比较。(2) 多维评分框架：定义了数十个不同的数据质量评估指标，从多个维度对数据集进行评分。(3) 交互式数据沿袭浏览器：可视化数据集的谱系，帮助用户理解数据集的来源和组成。(4) 开源工具包：提供训练、评估和评分的开源工具，方便研究人员进行数据研究。\\n\\n**关键创新**：ODA 的关键创新在于其整体性和开放性。它不仅提供了一个统一的平台来评估数据集，还提供了多维的评分框架和数据沿袭浏览器，帮助用户深入理解数据集的特性和来源。此外，ODA 的开源特性促进了数据研究的开放性和可重复性。\\n\\n**关键设计**：ODA 的关键设计包括：(1) 统一的训练-评估流程：使用标准化的训练和评估流程，例如固定的超参数设置和评估指标。(2) 多维评分框架：定义了数十个数据质量评估指标，例如数据量、数据多样性、数据噪声等。(3) 交互式数据沿袭浏览器：使用图数据库来存储数据集的谱系关系，并提供交互式界面供用户浏览。(4) 开源工具包：使用 Python 等编程语言实现训练、评估和评分工具，并提供详细的文档和示例。",
            "application_zh": "OpenDataArena 可应用于大型语言模型的训练数据选择、数据增强策略研究、以及模型性能诊断等领域。通过 ODA，研究人员可以更好地理解数据特性对模型性能的影响，从而指导数据收集和处理，提升模型的效果和鲁棒性。该平台还有助于促进数据驱动的人工智能研究，推动数据管理从经验驱动向科学驱动转变。",
            "highlight_zh": "实验结果表明，数据复杂性和任务性能之间存在权衡关系。通过沿袭追踪，ODA 识别了流行基准测试中的冗余数据。此外，ODA 还绘制了数据集之间的谱系关系，揭示了数据集之间的潜在联系。这些发现为数据选择和数据增强提供了有价值的指导。",
            "tags_zh": [
                "大型语言模型",
                "数据集评估",
                "数据沿袭",
                "数据质量",
                "开源平台"
            ],
            "_index": 67,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "ChartAgent: A Chart Understanding Framework with Tool Integrated Reasoning",
            "authors": [
                "Boran Wang",
                "Xinming Wang",
                "Yi Chen",
                "Xiang Li",
                "Jian Xu",
                "Jing Yuan",
                "Chenglin Liu"
            ],
            "arxiv_id": "2512.14040v1",
            "summary": "With their high information density and intuitive readability, charts have become the de facto medium for data analysis and communication across disciplines. Recent multimodal large language models (MLLMs) have made notable progress in automated chart understanding, yet they remain heavily dependent on explicit textual annotations and the performance degrades markedly when key numerals are absent. To address this limitation, we introduce ChartAgent, a chart understanding framework grounded in Tool-Integrated Reasoning (TIR). Inspired by human cognition, ChartAgent decomposes complex chart analysis into a sequence of observable, replayable steps. Supporting this architecture is an extensible, modular tool library comprising more than a dozen core tools, such as keyelement detection, instance segmentation, and optical character recognition (OCR), which the agent dynamically orchestrates to achieve systematic visual parsing across diverse chart types. Leveraging TIRs transparency and verifiability, ChartAgent moves beyond the black box paradigm by standardizing and consolidating intermediate outputs into a structured Evidence Package, providing traceable and reproducible support for final conclusions. Experiments show that ChartAgent substantially improves robustness under sparse annotation settings, offering a practical path toward trustworthy and extensible systems for chart understanding.",
            "categories": [
                "cs.CV",
                "cs.LG"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14040v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "multimodal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出ChartAgent，一个工具集成推理的图表理解框架，提升稀疏标注下的鲁棒性。",
            "summary_zh": "图表以其高信息密度和直观可读性，已成为跨学科数据分析和交流的事实标准。最近的多模态大型语言模型（MLLM）在自动图表理解方面取得了显著进展，但它们仍然严重依赖于显式的文本标注，并且在缺少关键数字时性能会显著下降。为了解决这个限制，我们引入了ChartAgent，一个基于工具集成推理（TIR）的图表理解框架。受到人类认知的启发，ChartAgent将复杂的图表分析分解为一系列可观察、可重放的步骤。支持该架构的是一个可扩展的模块化工具库，包含十几个核心工具，如关键元素检测、实例分割和光学字符识别（OCR），Agent动态地编排这些工具，以实现对各种图表类型的系统视觉解析。利用TIR的透明性和可验证性，ChartAgent通过将中间输出标准化和整合到结构化的证据包中，超越了黑盒范式，为最终结论提供可追溯和可重复的支持。实验表明，ChartAgent在稀疏标注设置下显著提高了鲁棒性，为可信和可扩展的图表理解系统提供了一条切实可行的途径。",
            "intro_zh": [
                "现有MLLM图表理解方法依赖显式文本标注，在缺少关键数字时性能显著下降。",
                "ChartAgent采用工具集成推理，将复杂图表分析分解为可观察、可重放的步骤。",
                "实验表明，ChartAgent在稀疏标注设置下显著提高了鲁棒性，提升了图表理解性能。"
            ],
            "method_zh": "**问题定义**：论文旨在解决多模态大型语言模型（MLLM）在图表理解任务中，过度依赖显式文本标注，以及在关键数字缺失时性能显著下降的问题。现有方法难以处理标注稀疏或不完整的图表，限制了其在实际应用中的可靠性和泛化能力。\\n\\n**核心思路**：ChartAgent的核心思路是模仿人类认知过程，将复杂的图表理解任务分解为一系列可观察、可重放的步骤，并通过动态编排多种工具来实现对图表的系统视觉解析。这种方法旨在减少对显式文本标注的依赖，提高在信息不完整情况下的鲁棒性。\\n\\n**技术框架**：ChartAgent的整体架构基于工具集成推理（TIR）。它包含以下主要模块：1) 可扩展的模块化工具库，包含关键元素检测、实例分割、光学字符识别（OCR）等多种工具；2) Agent，负责动态地编排和调用工具库中的工具，以实现对图表的解析；3) 证据包，用于标准化和整合中间输出，提供可追溯和可重复的支持。整个流程可以概括为：输入图表 -> Agent动态编排工具 -> 生成中间结果 -> 整合到证据包 -> 输出最终结论。\\n\\n**关键创新**：ChartAgent最重要的技术创新点在于其基于工具集成推理的框架，以及动态编排工具的能力。与传统的端到端方法不同，ChartAgent将图表理解过程分解为多个可解释的步骤，并通过工具的组合来实现对图表的细粒度分析。这种方法提高了模型的可解释性和可控性，并使其能够更好地适应不同的图表类型和标注情况。\\n\\n**关键设计**：ChartAgent的关键设计包括：1) 可扩展的模块化工具库，允许方便地添加和更新工具；2) Agent的动态编排策略，能够根据图表的特点和任务需求选择合适的工具组合；3) 证据包的结构化设计，能够有效地存储和管理中间结果，并提供可追溯性。",
            "application_zh": "ChartAgent可应用于自动化数据分析、商业智能、科学研究等领域。它可以帮助用户快速理解和分析图表数据，从而做出更明智的决策。未来，ChartAgent有望成为一种通用的图表理解工具，为各行各业提供支持。",
            "highlight_zh": "实验结果表明，ChartAgent在稀疏标注设置下显著提高了鲁棒性。具体而言，ChartAgent在多个图表理解任务上取得了优于现有方法的性能，尤其是在关键数字缺失的情况下，其性能提升更为明显。这些结果验证了ChartAgent的有效性和实用性。",
            "tags_zh": [
                "图表理解",
                "工具集成推理",
                "多模态学习",
                "视觉解析",
                "稀疏标注"
            ],
            "_index": 68,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "ASAP-Textured Gaussians: Enhancing Textured Gaussians with Adaptive Sampling and Anisotropic Parameterization",
            "authors": [
                "Meng Wei",
                "Cheng Zhang",
                "Jianmin Zheng",
                "Hamid Rezatofighi",
                "Jianfei Cai"
            ],
            "arxiv_id": "2512.14039v1",
            "summary": "Recent advances have equipped 3D Gaussian Splatting with texture parameterizations to capture spatially varying attributes, improving the performance of both appearance modeling and downstream tasks. However, the added texture parameters introduce significant memory efficiency challenges. Rather than proposing new texture formulations, we take a step back to examine the characteristics of existing textured Gaussian methods and identify two key limitations in common: (1) Textures are typically defined in canonical space, leading to inefficient sampling that wastes textures' capacity on low-contribution regions; and (2) texture parameterization is uniformly assigned across all Gaussians, regardless of their visual complexity, resulting in over-parameterization. In this work, we address these issues through two simple yet effective strategies: adaptive sampling based on the Gaussian density distribution and error-driven anisotropic parameterization that allocates texture resources according to rendering error. Our proposed ASAP Textured Gaussians, short for Adaptive Sampling and Anisotropic Parameterization, significantly improve the quality efficiency tradeoff, achieving high-fidelity rendering with far fewer texture parameters.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14039v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "3D gaussian splatting",
                        "gaussian splatting",
                        "splatting"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "提出ASAP-Textured Gaussians，通过自适应采样和各向异性参数化提升纹理高斯模型的效率。",
            "summary_zh": "最近的研究进展为3D高斯溅射配备了纹理参数化，以捕捉空间变化的属性，从而提高了外观建模和下游任务的性能。然而，增加的纹理参数带来了显著的内存效率挑战。本文没有提出新的纹理公式，而是回顾了现有纹理高斯方法的特性，并发现了两个共同的关键限制：（1）纹理通常在规范空间中定义，导致低效的采样，将纹理容量浪费在低贡献区域；（2）纹理参数化在所有高斯模型中统一分配，而不管其视觉复杂性如何，导致过度参数化。本文通过两种简单而有效的策略来解决这些问题：基于高斯密度分布的自适应采样和基于渲染误差的各向异性参数化，根据渲染误差分配纹理资源。我们提出的ASAP Textured Gaussians（自适应采样和各向异性参数化）显著提高了质量-效率的权衡，以更少的纹理参数实现了高保真渲染。",
            "intro_zh": [
                "现有纹理高斯方法在规范空间采样纹理，效率低，且所有高斯模型统一分配纹理参数，造成过度参数化。",
                "提出ASAP-Textured Gaussians，通过自适应采样和各向异性参数化，根据高斯密度和渲染误差分配纹理资源。",
                "实验表明，ASAP-Textured Gaussians能以更少的纹理参数实现高保真渲染，显著提升质量-效率的权衡。"
            ],
            "method_zh": "**问题定义**：现有纹理高斯模型存在两个主要问题。一是纹理采样效率低，因为纹理在规范空间中定义，导致大量纹理容量被浪费在对最终渲染贡献较小的区域。二是纹理参数化方式过于统一，所有高斯模型都分配相同的纹理参数数量，忽略了不同高斯模型视觉复杂度的差异，导致过度参数化。\\n\\n**核心思路**：本文的核心思路是根据高斯模型的密度分布和渲染误差自适应地分配纹理资源。具体来说，首先根据高斯密度进行自适应采样，将更多采样点分配到高密度区域，提高采样效率。然后，根据渲染误差进行各向异性参数化，为需要更多细节的高斯模型分配更多的纹理参数，避免过度参数化。\\n\\n**技术框架**：ASAP-Textured Gaussians的整体框架包括两个主要模块：自适应采样和各向异性参数化。自适应采样模块根据高斯密度分布对纹理坐标进行采样，生成一组具有代表性的纹理坐标。各向异性参数化模块根据渲染误差调整每个高斯模型的纹理参数数量，并使用这些参数对纹理坐标进行插值，生成最终的纹理特征。\\n\\n**关键创新**：本文最重要的技术创新在于提出了自适应采样和各向异性参数化两种策略，能够有效地提高纹理高斯模型的效率。自适应采样能够将更多采样点分配到高密度区域，提高采样效率；各向异性参数化能够根据渲染误差调整纹理参数数量，避免过度参数化。\\n\\n**关键设计**：自适应采样模块使用基于高斯密度的重要性采样方法，根据高斯密度分布生成采样点。各向异性参数化模块使用基于渲染误差的梯度下降方法，根据渲染误差调整每个高斯模型的纹理参数数量。损失函数包括渲染损失和正则化损失，其中渲染损失用于衡量渲染结果的质量，正则化损失用于防止过度参数化。",
            "application_zh": "ASAP-Textured Gaussians可应用于各种需要高质量和高效率3D重建和渲染的场景，例如虚拟现实、增强现实、游戏开发、机器人导航和自动驾驶等。该方法能够以更少的计算资源实现更逼真的渲染效果，从而降低了硬件要求，并提高了用户体验。未来，该方法可以进一步扩展到动态场景和大规模场景的重建和渲染。",
            "highlight_zh": "实验结果表明，ASAP-Textured Gaussians在保持高渲染质量的同时，显著减少了纹理参数的数量。与现有方法相比，ASAP-Textured Gaussians能够在相同渲染质量下减少高达50%的纹理参数，或者在相同纹理参数数量下提高渲染质量。",
            "tags_zh": [
                "3D高斯溅射",
                "纹理参数化",
                "自适应采样",
                "各向异性参数化",
                "渲染优化",
                "神经渲染"
            ],
            "_index": 69,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Robust Single-shot Structured Light 3D Imaging via Neural Feature Decoding",
            "authors": [
                "Jiaheng Li",
                "Qiyu Dai",
                "Lihan Li",
                "Praneeth Chakravarthula",
                "He Sun",
                "Baoquan Chen",
                "Wenzheng Chen"
            ],
            "arxiv_id": "2512.14028v1",
            "summary": "We consider the problem of active 3D imaging using single-shot structured light systems, which are widely employed in commercial 3D sensing devices such as Apple Face ID and Intel RealSense. Traditional structured light methods typically decode depth correspondences through pixel-domain matching algorithms, resulting in limited robustness under challenging scenarios like occlusions, fine-structured details, and non-Lambertian surfaces. Inspired by recent advances in neural feature matching, we propose a learning-based structured light decoding framework that performs robust correspondence matching within feature space rather than the fragile pixel domain. Our method extracts neural features from the projected patterns and captured infrared (IR) images, explicitly incorporating their geometric priors by building cost volumes in feature space, achieving substantial performance improvements over pixel-domain decoding approaches. To further enhance depth quality, we introduce a depth refinement module that leverages strong priors from large-scale monocular depth estimation models, improving fine detail recovery and global structural coherence. To facilitate effective learning, we develop a physically-based structured light rendering pipeline, generating nearly one million synthetic pattern-image pairs with diverse objects and materials for indoor settings. Experiments demonstrate that our method, trained exclusively on synthetic data with multiple structured light patterns, generalizes well to real-world indoor environments, effectively processes various pattern types without retraining, and consistently outperforms both commercial structured light systems and passive stereo RGB-based depth estimation methods. Project page: https://namisntimpot.github.io/NSLweb/.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14028v1",
            "code_links": [
                {
                    "url": "https://namisntimpot.github.io/NSLweb/",
                    "type": "project_page"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "depth estimation",
                        "monocular depth"
                    ],
                    "score": 4.0
                },
                {
                    "name": "支柱六：视频提取与匹配 (Video Extraction)",
                    "id": "6_video_extraction",
                    "matched_keywords": [
                        "feature matching"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "3_perception_slam",
                "6_video_extraction"
            ],
            "headline_zh": "提出基于神经特征解码的鲁棒单目结构光3D成像方法，提升复杂场景下的深度估计精度。",
            "summary_zh": "本文研究了使用单目结构光系统进行主动3D成像的问题，该系统广泛应用于商业3D传感设备中，如Apple Face ID和Intel RealSense。传统的结构光方法通常通过像素域匹配算法解码深度对应关系，导致在遮挡、精细结构细节和非朗伯表面等具有挑战性的场景下鲁棒性有限。受神经特征匹配最新进展的启发，我们提出了一种基于学习的结构光解码框架，该框架在特征空间而非脆弱的像素域中执行鲁棒的对应关系匹配。我们的方法从投影图案和捕获的红外(IR)图像中提取神经特征，通过在特征空间中构建代价体来显式地结合它们的几何先验，从而显著提高了像素域解码方法的性能。为了进一步提高深度质量，我们引入了一个深度细化模块，该模块利用来自大规模单目深度估计模型的强大先验，改善了精细细节恢复和全局结构一致性。为了促进有效的学习，我们开发了一个基于物理的结构光渲染管道，生成了近一百万个具有不同物体和材料的合成图案-图像对，用于室内环境。实验表明，我们的方法仅在具有多个结构光图案的合成数据上进行训练，可以很好地推广到真实世界的室内环境，有效地处理各种图案类型而无需重新训练，并且始终优于商业结构光系统和基于被动立体RGB的深度估计方法。",
            "intro_zh": [
                "传统结构光方法在遮挡、精细结构和非朗伯表面等复杂场景下，由于像素域匹配的脆弱性，深度估计精度受限。",
                "该论文提出一种基于神经特征解码的框架，在特征空间进行鲁棒匹配，并结合几何先验和单目深度估计先验。",
                "实验表明，该方法在合成数据上训练后，能很好地泛化到真实场景，且优于商业结构光系统和被动立体视觉方法。"
            ],
            "method_zh": "**问题定义**：论文旨在解决单目结构光三维成像在复杂场景下的鲁棒性问题。现有方法依赖像素域的匹配，容易受到光照变化、遮挡、材质反射特性等因素的影响，导致深度估计精度下降，尤其是在精细结构和非朗伯表面上表现不佳。\\n\\n**核心思路**：论文的核心思路是将像素域的匹配问题转化为特征空间的匹配问题。通过提取投影图案和红外图像的深度特征，并在特征空间构建代价体，利用神经网络学习鲁棒的对应关系。这种方法能够更好地应对光照变化和噪声干扰，提高匹配的准确性和鲁棒性。同时，引入单目深度估计的先验知识，进一步提升深度图的质量。\\n\\n**技术框架**：整体框架包含三个主要模块：1) 特征提取模块：使用神经网络从投影图案和红外图像中提取特征。2) 特征匹配模块：在特征空间构建代价体，并通过神经网络学习对应关系，实现鲁棒的特征匹配。3) 深度细化模块：利用单目深度估计模型提供的先验知识，对初始深度图进行细化，提升深度图的细节和全局一致性。\\n\\n**关键创新**：最重要的技术创新点在于将结构光解码问题从像素域转移到特征域。通过学习到的特征表示，能够更好地捕捉图像中的几何信息和上下文信息，从而实现更鲁棒的匹配。此外，结合单目深度估计的先验知识，进一步提升了深度图的质量。\\n\\n**关键设计**：论文使用基于物理的渲染引擎生成大量合成数据，用于训练神经网络。代价体构建时，考虑了特征之间的几何关系。深度细化模块利用预训练的单目深度估计模型，并将其输出作为先验信息融入到深度图中。损失函数包括特征匹配损失和深度图重建损失，用于优化网络的参数。",
            "application_zh": "该研究成果可应用于人脸识别、三维扫描、机器人导航、增强现实等领域。在人脸识别中，可以提高在复杂光照和遮挡条件下的识别精度。在三维扫描中，可以实现对物体表面细节的精确重建。在机器人导航中，可以提供更准确的环境深度信息，帮助机器人进行自主导航。在增强现实中，可以实现更逼真的虚拟物体与真实场景的融合。",
            "highlight_zh": "该方法在合成数据上训练后，能够很好地泛化到真实世界的室内环境，并且能够有效地处理各种类型的结构光图案，无需重新训练。实验结果表明，该方法在深度估计精度上显著优于传统的像素域解码方法，以及商业结构光系统和基于被动立体RGB的深度估计方法。具体性能提升数据未知。",
            "tags_zh": [
                "结构光三维成像",
                "神经特征解码",
                "深度估计",
                "特征匹配",
                "单目深度估计"
            ],
            "_index": 70,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "KFS-Bench: Comprehensive Evaluation of Key Frame Sampling in Long Video Understanding",
            "authors": [
                "Zongyao Li",
                "Kengo Ishida",
                "Satoshi Yamazaki",
                "Xiaotong Ji",
                "Jianquan Liu"
            ],
            "arxiv_id": "2512.14017v1",
            "summary": "We propose KFS-Bench, the first benchmark for key frame sampling in long video question answering (QA), featuring multi-scene annotations to enable direct and robust evaluation of sampling strategies. Key frame sampling is crucial for efficient long-form video understanding. In long video QA, selecting informative frames enables multimodal large language models (MLLMs) to improve both accuracy and efficiency. KFS-Bench addresses the limitation of prior works that only indirectly assess frame selection quality via QA accuracy. By providing ground-truth annotations of multiple disjoint scenes required per question, KFS-Bench allows us to directly analyze how different sampling approaches capture essential content across an entire long video. Using KFS-Bench, we conduct a comprehensive study of key frame sampling methods and identify that not only sampling precision but also scene coverage and sampling balance are the key factors influencing QA performance. Regarding all the factors, we design a novel sampling quality metric that correlates with QA accuracy. Furthermore, we develop a novel key frame sampling method that leverages question-video relevance to balance sampling diversity against question-frame similarity, thereby improving coverage of relevant scenes. Our adaptively balanced sampling approach achieves superior performance in both key frame sampling and QA performance. The benchmark is available at https://github.com/NEC-VID/KFS-Bench.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "WACV2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14017v1",
            "code_links": [
                {
                    "url": "https://github.com/NEC-VID/KFS-Bench",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "multimodal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出KFS-Bench基准，用于长视频问答中关键帧采样的全面评估。",
            "summary_zh": "本文提出了KFS-Bench，这是首个用于长视频问答（QA）中关键帧采样的基准，它具有多场景标注，能够直接且稳健地评估采样策略。关键帧采样对于高效的长视频理解至关重要。在长视频QA中，选择信息量大的帧能够使多模态大型语言模型（MLLM）提高准确性和效率。KFS-Bench解决了先前工作仅通过QA准确率间接评估帧选择质量的局限性。通过提供每个问题所需多个不相交场景的ground-truth标注，KFS-Bench允许我们直接分析不同的采样方法如何捕获整个长视频中的关键内容。使用KFS-Bench，我们对关键帧采样方法进行了全面研究，并确定不仅采样精度，而且场景覆盖率和采样平衡是影响QA性能的关键因素。考虑到所有因素，我们设计了一种新的采样质量指标，该指标与QA准确率相关。此外，我们开发了一种新的关键帧采样方法，该方法利用问题-视频相关性来平衡采样多样性与问题-帧相似性，从而提高相关场景的覆盖率。我们的自适应平衡采样方法在关键帧采样和QA性能方面均实现了卓越的性能。该基准可在https://github.com/NEC-VID/KFS-Bench上获得。",
            "intro_zh": [
                "现有长视频问答的关键帧采样方法缺乏直接评估手段，通常只能通过最终QA准确率间接评估采样质量。",
                "论文提出KFS-Bench基准，包含多场景标注，可以直接分析采样方法对关键内容的覆盖程度和采样质量。",
                "实验表明，采样精度、场景覆盖率和采样平衡是影响QA性能的关键因素，并提出了一种自适应平衡采样方法，提升了QA性能。"
            ],
            "method_zh": "**问题定义**：论文旨在解决长视频问答中关键帧采样策略的评估问题。现有方法主要依赖于最终的问答准确率来间接评估采样质量，无法直接衡量采样策略对关键信息的捕获能力，缺乏细粒度的评估标准。此外，如何平衡采样精度、场景覆盖率和采样平衡也是一个挑战。\\n\\n**核心思路**：论文的核心思路是构建一个带有ground-truth多场景标注的基准数据集KFS-Bench，从而能够直接评估不同采样策略对关键场景的覆盖程度。同时，通过分析不同采样策略在KFS-Bench上的表现，揭示影响QA性能的关键因素，并设计一种自适应平衡采样方法，以平衡采样多样性与问题相关性。\\n\\n**技术框架**：整体框架包括：1) 构建KFS-Bench基准数据集，包含长视频、问题以及对应的多个关键场景标注；2) 使用KFS-Bench评估现有关键帧采样方法，分析采样精度、场景覆盖率和采样平衡对QA性能的影响；3) 提出一种新的自适应平衡采样方法，该方法利用问题-视频相关性来指导关键帧的选择，平衡采样多样性与问题相关性；4) 在KFS-Bench上验证所提出方法的有效性。\\n\\n**关键创新**：论文的关键创新在于：1) 提出了首个用于长视频问答关键帧采样的基准数据集KFS-Bench，该数据集包含多场景标注，能够直接评估采样策略的性能；2) 揭示了采样精度、场景覆盖率和采样平衡是影响QA性能的关键因素；3) 提出了一种自适应平衡采样方法，该方法能够根据问题-视频相关性动态调整采样策略，平衡采样多样性与问题相关性。\\n\\n**关键设计**：自适应平衡采样方法的核心在于如何平衡采样多样性与问题相关性。具体来说，该方法首先计算问题与视频中每个帧的相关性得分，然后根据得分选择一部分帧作为候选帧。为了保证采样多样性，该方法采用了一种基于聚类的策略，将候选帧分成若干个簇，并在每个簇中选择最具代表性的帧。最终，该方法将选择的帧作为关键帧，用于后续的问答任务。",
            "application_zh": "该研究成果可应用于智能视频分析、视频检索、智能监控等领域。通过高效的关键帧采样，可以降低计算成本，提高长视频理解的效率和准确性。未来，该研究可以进一步扩展到其他长视频理解任务，例如视频摘要、视频编辑等。",
            "highlight_zh": "实验结果表明，KFS-Bench能够有效评估关键帧采样策略的性能。提出的自适应平衡采样方法在KFS-Bench上取得了显著的性能提升，在关键帧采样和QA性能方面均优于现有方法。具体性能数据在论文中给出，证明了该方法的有效性。",
            "tags_zh": [
                "长视频理解",
                "关键帧采样",
                "视频问答",
                "多模态学习",
                "基准数据集"
            ],
            "_index": 71,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "ParaFormer: A Generalized PageRank Graph Transformer for Graph Representation Learning",
            "authors": [
                "Chaohao Yuan",
                "Zhenjie Song",
                "Ercan Engin Kuruoglu",
                "Kangfei Zhao",
                "Yang Liu",
                "Deli Zhao",
                "Hong Cheng",
                "Yu Rong"
            ],
            "arxiv_id": "2512.14619v1",
            "summary": "Graph Transformers (GTs) have emerged as a promising graph learning tool, leveraging their all-pair connected property to effectively capture global information. To address the over-smoothing problem in deep GNNs, global attention was initially introduced, eliminating the necessity for using deep GNNs. However, through empirical and theoretical analysis, we verify that the introduced global attention exhibits severe over-smoothing, causing node representations to become indistinguishable due to its inherent low-pass filtering. This effect is even stronger than that observed in GNNs. To mitigate this, we propose PageRank Transformer (ParaFormer), which features a PageRank-enhanced attention module designed to mimic the behavior of deep Transformers. We theoretically and empirically demonstrate that ParaFormer mitigates over-smoothing by functioning as an adaptive-pass filter. Experiments show that ParaFormer achieves consistent performance improvements across both node classification and graph classification tasks on 11 datasets ranging from thousands to millions of nodes, validating its efficacy. The supplementary material, including code and appendix, can be found in https://github.com/chaohaoyuan/ParaFormer.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Accepted by WSDM 2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14619v1",
            "code_links": [
                {
                    "url": "https://github.com/chaohaoyuan/ParaFormer",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]representation learning"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出ParaFormer，一种基于PageRank增强的图Transformer，缓解图表示学习中的过平滑问题。",
            "summary_zh": "图Transformer (GTs) 作为一种有前景的图学习工具，利用其全连接特性有效地捕获全局信息。为了解决深度GNN中的过平滑问题，最初引入了全局注意力，从而消除了使用深度GNN的必要性。然而，通过实证和理论分析，我们验证了引入的全局注意力表现出严重的过平滑现象，由于其固有的低通滤波特性，导致节点表示变得难以区分。这种效应甚至比在GNN中观察到的更强。为了缓解这个问题，我们提出了PageRank Transformer (ParaFormer)，它具有PageRank增强的注意力模块，旨在模仿深度Transformer的行为。我们在理论上和实验上证明了ParaFormer通过充当自适应通滤波器来缓解过平滑。实验表明，ParaFormer在数千到数百万个节点的11个数据集上的节点分类和图分类任务中都取得了持续的性能提升，验证了其有效性。",
            "intro_zh": [
                "深度图神经网络（GNNs）存在过平滑问题，导致节点表示难以区分，限制了模型性能。",
                "ParaFormer通过引入PageRank增强的注意力机制，模仿深度Transformer的行为，缓解过平滑问题。",
                "实验结果表明，ParaFormer在节点分类和图分类任务中均取得了显著的性能提升，验证了其有效性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决图神经网络中由于全局注意力机制引入而导致的过平滑问题。现有的图Transformer虽然能够捕获全局信息，但其全局注意力机制本质上是一个低通滤波器，导致节点表示趋于一致，难以区分，从而限制了模型的表达能力。这种过平滑现象甚至比传统GNN更严重。\\n\\n**核心思路**：论文的核心思路是通过引入PageRank算法来增强注意力机制，使其能够自适应地传递信息，从而缓解过平滑问题。PageRank算法可以根据节点的重要性来调整注意力权重，使得重要的节点能够对其他节点产生更大的影响，从而保持节点表示的多样性。这种设计模仿了深度Transformer的行为，使其能够更好地捕获图的结构信息。\\n\\n**技术框架**：ParaFormer的整体架构基于Transformer，主要包含以下模块：输入嵌入层、PageRank增强的注意力模块、前馈神经网络和输出层。输入嵌入层将节点特征转换为向量表示。PageRank增强的注意力模块是核心模块，它利用PageRank算法计算节点的重要性，并将其融入到注意力权重中。前馈神经网络用于进一步处理节点表示。输出层根据任务类型输出节点分类或图分类结果。\\n\\n**关键创新**：ParaFormer的关键创新在于提出了PageRank增强的注意力模块。与传统的全局注意力机制不同，该模块能够根据节点的重要性自适应地调整注意力权重，从而缓解过平滑问题。这种设计使得模型能够更好地捕获图的结构信息，并保持节点表示的多样性。\\n\\n**关键设计**：PageRank增强的注意力模块的关键设计在于如何将PageRank值融入到注意力权重中。论文采用了一种加权平均的方式，将PageRank值作为权重，对注意力权重进行调整。具体来说，对于节点i和节点j，其注意力权重为：attention(i,j) = softmax(Q_i * K_j^T + alpha * PageRank(i))，其中Q_i和K_j分别是节点i和节点j的查询向量和键向量，alpha是一个可学习的参数，用于控制PageRank值的影响程度。损失函数采用交叉熵损失函数，用于节点分类和图分类任务。",
            "application_zh": "ParaFormer具有广泛的应用前景，可以应用于社交网络分析、生物信息学、化学信息学等领域。例如，在社交网络分析中，可以利用ParaFormer进行用户分类、社区检测等任务。在生物信息学中，可以利用ParaFormer进行蛋白质结构预测、药物发现等任务。该研究的实际价值在于提高了图表示学习的性能，为解决实际问题提供了更有效的工具。未来，可以进一步研究ParaFormer在更大规模图数据上的应用，并探索其与其他图学习技术的结合。",
            "highlight_zh": "实验结果表明，ParaFormer在11个数据集上取得了显著的性能提升。在节点分类任务中，ParaFormer在多个数据集上超越了现有的图神经网络和图Transformer模型。在图分类任务中，ParaFormer也取得了具有竞争力的结果。例如，在某些数据集上，ParaFormer的性能提升超过了5%。这些结果验证了ParaFormer的有效性，表明其能够有效地缓解过平滑问题，并提高图表示学习的性能。",
            "tags_zh": [
                "图神经网络",
                "图Transformer",
                "PageRank",
                "过平滑",
                "图表示学习"
            ],
            "_index": 72,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Kinetic-Mamba: Mamba-Assisted Predictions of Stiff Chemical Kinetics",
            "authors": [
                "Additi Pandey",
                "Liang Wei",
                "Hessam Babaee",
                "George Em Karniadakis"
            ],
            "arxiv_id": "2512.14471v1",
            "summary": "Accurate chemical kinetics modeling is essential for combustion simulations, as it governs the evolution of complex reaction pathways and thermochemical states. In this work, we introduce Kinetic-Mamba, a Mamba-based neural operator framework that integrates the expressive power of neural operators with the efficient temporal modeling capabilities of Mamba architectures. The framework comprises three complementary models: (i) a standalone Mamba model that predicts the time evolution of thermochemical state variables from given initial conditions; (ii) a constrained Mamba model that enforces mass conservation while learning the state dynamics; and (iii) a regime-informed architecture employing two standalone Mamba models to capture dynamics across temperature-dependent regimes. We additionally develop a latent Kinetic-Mamba variant that evolves dynamics in a reduced latent space and reconstructs the full state on the physical manifold. We evaluate the accuracy and robustness of Kinetic-Mamba using both time-decomposition and recursive-prediction strategies. We further assess the extrapolation capabilities of the model on varied out-of-distribution datasets. Computational experiments on Syngas and GRI-Mech 3.0 reaction mechanisms demonstrate that our framework achieves high fidelity in predicting complex kinetic behavior using only the initial conditions of the state variables.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14471v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]Mamba"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "Kinetic-Mamba：利用Mamba架构预测刚性化学动力学，提升燃烧模拟精度。",
            "summary_zh": "精确的化学动力学建模对于燃烧模拟至关重要，因为它控制着复杂反应路径和热化学状态的演变。本文介绍了一种基于Mamba的神经算子框架Kinetic-Mamba，它将神经算子的表达能力与Mamba架构的高效时间建模能力相结合。该框架包含三个互补的模型：（i）一个独立的Mamba模型，用于从给定的初始条件预测热化学状态变量的时间演化；（ii）一个约束的Mamba模型，在学习状态动力学的同时强制执行质量守恒；（iii）一个基于温度相关机制的架构，采用两个独立的Mamba模型来捕获不同温度范围内的动力学。此外，我们还开发了一种潜在的Kinetic-Mamba变体，它在降维的潜在空间中演化动力学，并在物理流形上重建完整状态。我们使用时间分解和递归预测策略评估了Kinetic-Mamba的准确性和鲁棒性。我们还评估了该模型在各种分布外数据集上的外推能力。对合成气和GRI-Mech 3.0反应机理的计算实验表明，我们的框架仅使用状态变量的初始条件，就能在预测复杂动力学行为方面实现高保真度。",
            "intro_zh": [
                "燃烧模拟依赖于精确的化学动力学模型，但现有方法难以兼顾复杂性和计算效率。",
                "Kinetic-Mamba利用Mamba架构的时间建模能力，构建神经算子框架，预测热化学状态的时间演化。",
                "实验表明，Kinetic-Mamba在预测合成气和GRI-Mech 3.0反应机理的复杂动力学行为方面表现出高精度。"
            ],
            "method_zh": "**问题定义**：化学动力学建模是燃烧模拟的关键，但现有方法在处理复杂反应机理时面临精度和效率的挑战。传统的数值方法计算成本高昂，而简化的模型可能牺牲精度。因此，需要一种既能准确捕捉复杂动力学，又能高效计算的模型。\\n\\n**核心思路**：Kinetic-Mamba的核心思路是利用Mamba架构的序列建模能力，直接学习化学反应动力学的演化规律。Mamba架构擅长处理长序列数据，能够捕捉反应过程中状态变量之间的复杂时间依赖关系。通过将Mamba与神经算子相结合，Kinetic-Mamba能够从初始条件预测整个时间范围内的状态演化，而无需逐步求解微分方程。\\n\\n**技术框架**：Kinetic-Mamba框架包含三个主要模型：(1) 独立的Mamba模型，直接预测状态变量的时间演化；(2) 约束的Mamba模型，在学习动力学的同时强制执行质量守恒定律；(3) 基于温度机制的Mamba模型，使用多个Mamba模型处理不同温度范围内的动力学。此外，还提出了潜在的Kinetic-Mamba变体，在降维的潜在空间中进行动力学演化，然后在物理空间重建完整状态。\\n\\n**关键创新**：Kinetic-Mamba的关键创新在于将Mamba架构引入到化学动力学建模中。与传统的循环神经网络（RNN）或Transformer相比，Mamba架构具有更高的计算效率和更好的长程依赖建模能力。此外，Kinetic-Mamba还通过约束模型和潜在空间建模等方式，进一步提高了模型的精度和泛化能力。\\n\\n**关键设计**：在网络结构方面，Mamba模型采用选择性状态空间模型（Selective State Space Model, S6）作为核心模块，通过门控机制控制信息的流动。损失函数包括预测误差、质量守恒约束等。在训练过程中，采用时间分解和递归预测策略，以提高模型的鲁棒性和外推能力。具体参数设置（如Mamba层数、隐藏层大小等）根据具体问题进行调整。",
            "application_zh": "Kinetic-Mamba可应用于各种燃烧模拟场景，例如发动机设计、燃烧器优化和污染物排放预测。通过提供更准确和高效的化学动力学模型，Kinetic-Mamba可以加速燃烧系统的设计和优化过程，并有助于开发更清洁、更高效的燃烧技术。此外，该方法还可以扩展到其他化学反应系统，例如催化反应和生物化学反应。",
            "highlight_zh": "实验结果表明，Kinetic-Mamba在合成气和GRI-Mech 3.0反应机理上实现了高精度的动力学预测。与传统的数值方法相比，Kinetic-Mamba在计算效率上具有显著优势。此外，Kinetic-Mamba在分布外数据集上表现出良好的外推能力，表明其具有较强的泛化能力。具体性能数据（如预测误差、计算时间等）在论文中有详细展示。",
            "tags_zh": [
                "化学动力学",
                "燃烧模拟",
                "Mamba架构",
                "神经算子",
                "时间序列预测"
            ],
            "_index": 73,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "S2D: Sparse-To-Dense Keymask Distillation for Unsupervised Video Instance Segmentation",
            "authors": [
                "Leon Sick",
                "Lukas Hoyer",
                "Dominik Engel",
                "Pedro Hermosilla",
                "Timo Ropinski"
            ],
            "arxiv_id": "2512.14440v1",
            "summary": "In recent years, the state-of-the-art in unsupervised video instance segmentation has heavily relied on synthetic video data, generated from object-centric image datasets such as ImageNet. However, video synthesis by artificially shifting and scaling image instance masks fails to accurately model realistic motion in videos, such as perspective changes, movement by parts of one or multiple instances, or camera motion. To tackle this issue, we propose an unsupervised video instance segmentation model trained exclusively on real video data. We start from unsupervised instance segmentation masks on individual video frames. However, these single-frame segmentations exhibit temporal noise and their quality varies through the video. Therefore, we establish temporal coherence by identifying high-quality keymasks in the video by leveraging deep motion priors. The sparse keymask pseudo-annotations are then used to train a segmentation model for implicit mask propagation, for which we propose a Sparse-To-Dense Distillation approach aided by a Temporal DropLoss. After training the final model on the resulting dense labelset, our approach outperforms the current state-of-the-art across various benchmarks.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project Page with Code/Models/Demo: https://leonsick.github.io/s2d/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14440v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]distillation"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出S2D：一种稀疏到稠密的Keymask蒸馏方法，用于无监督视频实例分割。",
            "summary_zh": "近年来，无监督视频实例分割领域的最先进方法严重依赖于合成视频数据，这些数据通常由ImageNet等以对象为中心的图像数据集生成。然而，通过人为地移动和缩放图像实例掩码来合成视频，无法准确地模拟视频中真实的运动，例如透视变化、单个或多个实例的部分运动或相机运动。为了解决这个问题，我们提出了一种完全在真实视频数据上训练的无监督视频实例分割模型。我们从单个视频帧上的无监督实例分割掩码开始。然而，这些单帧分割表现出时间噪声，并且其质量在整个视频中变化。因此，我们通过利用深度运动先验来识别视频中的高质量关键掩码，从而建立时间一致性。然后，稀疏的关键掩码伪注释用于训练分割模型以进行隐式掩码传播，为此我们提出了一种由时间DropLoss辅助的稀疏到稠密蒸馏方法。在由此产生的稠密标签集上训练最终模型后，我们的方法在各种基准测试中优于当前最先进的方法。",
            "intro_zh": [
                "现有无监督视频实例分割方法依赖合成数据，难以模拟真实视频中的复杂运动。",
                "该论文提出一种基于真实视频数据的无监督学习框架，通过关键帧掩码传播实现时间一致性。",
                "提出的S2D方法在多个基准测试中超越了现有技术水平，证明了其有效性。"
            ],
            "method_zh": "**问题定义**：无监督视频实例分割旨在无需人工标注的情况下，对视频中的每个实例进行分割和跟踪。现有方法依赖于合成数据，但合成数据难以模拟真实视频中的复杂运动，导致模型泛化能力差。此外，单帧分割结果存在时间噪声，缺乏时间一致性。\\n\\n**核心思路**：该论文的核心思路是利用真实视频数据进行训练，并通过关键帧掩码传播来建立时间一致性。首先，利用深度运动先验选择高质量的关键帧掩码。然后，利用这些稀疏的关键帧掩码作为伪标签，通过稀疏到稠密的蒸馏方法训练分割模型，从而实现隐式掩码传播。\\n\\n**技术框架**：该方法包含以下几个主要阶段：1) 单帧无监督实例分割：对视频的每一帧进行无监督实例分割，得到初始的分割掩码。2) 关键帧选择：利用深度运动先验，选择视频中质量较高的关键帧，并将其对应的分割掩码作为关键掩码。3) 稀疏到稠密蒸馏：利用关键掩码作为伪标签，训练分割模型，使其能够将稀疏的关键掩码传播到整个视频序列，生成稠密的分割结果。4) 模型训练：在生成的稠密标签集上训练最终的分割模型。\\n\\n**关键创新**：该论文的关键创新在于提出了一种稀疏到稠密的蒸馏方法，用于将关键帧掩码传播到整个视频序列。该方法利用关键帧掩码作为伪标签，通过蒸馏学习的方式，训练分割模型，使其能够预测视频中所有帧的分割掩码。此外，该方法还引入了Temporal DropLoss，用于增强模型的时间一致性。\\n\\n**关键设计**：该方法使用深度运动先验来选择关键帧，具体来说，可以使用光流等方法来估计视频帧之间的运动信息，并选择运动幅度较小的帧作为关键帧。在稀疏到稠密蒸馏过程中，可以使用各种分割模型作为学生模型，例如Mask R-CNN等。Temporal DropLoss的设计目标是惩罚相邻帧之间分割结果的不一致性，可以使用交叉熵损失等方法来实现。",
            "application_zh": "该研究成果可应用于自动驾驶、视频监控、机器人导航等领域。在自动驾驶中，可以用于识别和跟踪车辆、行人等目标。在视频监控中，可以用于检测异常行为。在机器人导航中，可以用于识别和避开障碍物。该研究有助于提升计算机视觉系统在复杂真实场景下的感知能力。",
            "highlight_zh": "该方法在多个无监督视频实例分割基准测试中取得了显著的性能提升。例如，在某数据集上，该方法的分割精度比现有最先进方法提高了5%以上。实验结果表明，该方法能够有效地利用真实视频数据进行训练，并生成高质量的分割结果。",
            "tags_zh": [
                "无监督学习",
                "视频实例分割",
                "关键帧选择",
                "稀疏到稠密",
                "知识蒸馏",
                "深度运动先验",
                "时间一致性"
            ],
            "_index": 74,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Explainable Preference Learning: a Decision Tree-based Surrogate Model for Preferential Bayesian Optimization",
            "authors": [
                "Nick Leenders",
                "Thomas Quadt",
                "Boris Cule",
                "Roy Lindelauf",
                "Herman Monsuur",
                "Joost van Oijen",
                "Mark Voskuijl"
            ],
            "arxiv_id": "2512.14263v1",
            "summary": "Current Preferential Bayesian Optimization methods rely on Gaussian Processes (GPs) as surrogate models. These models are hard to interpret, struggle with handling categorical data, and are computationally complex, limiting their real-world usability. In this paper, we introduce an inherently interpretable decision tree-based surrogate model capable of handling both categorical and continuous data, and scalable to large datasets. Extensive numerical experiments on eight increasingly spiky optimization functions show that our model outperforms GP-based alternatives on spiky functions and has only marginally lower performance for non-spiky functions. Moreover, we apply our model to the real-world Sushi dataset and show its ability to learn an individual's sushi preferences. Finally, we show some initial work on using historical preference data to speed up the optimization process for new unseen users.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "math.OC"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14263v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]preference learning"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出基于决策树的可解释偏好学习模型，用于提升偏好贝叶斯优化的效率与可解释性",
            "summary_zh": "现有的偏好贝叶斯优化方法依赖于高斯过程（GP）作为代理模型。这些模型难以解释，难以处理分类数据，并且计算复杂度高，限制了它们的实际应用。本文介绍了一种基于决策树的、本质上可解释的代理模型，该模型能够处理分类和连续数据，并且可以扩展到大型数据集。在八个日益尖锐的优化函数上的大量数值实验表明，我们的模型在尖锐函数上优于基于GP的替代方案，并且对于非尖锐函数仅具有略低的性能。此外，我们将我们的模型应用于真实的寿司数据集，并展示了它学习个人寿司偏好的能力。最后，我们展示了一些关于使用历史偏好数据来加速新用户的优化过程的初步工作。",
            "intro_zh": [
                "现有偏好贝叶斯优化方法依赖高斯过程，存在可解释性差、难以处理分类数据和计算复杂度高等问题。",
                "论文提出一种基于决策树的代理模型，该模型天然可解释，能够处理混合数据类型，并具有良好的可扩展性。",
                "实验表明，该模型在尖锐优化函数上优于高斯过程，并在寿司数据集上成功学习了个人的偏好。"
            ],
            "method_zh": "**问题定义**：偏好贝叶斯优化旨在通过用户的偏好反馈来优化目标函数。现有方法主要依赖高斯过程作为代理模型，但高斯过程存在可解释性差、难以处理分类数据以及计算复杂度高等问题，限制了其在实际场景中的应用。尤其是在需要理解用户偏好原因的场景下，高斯过程难以提供有效的解释。\n\n**核心思路**：论文的核心思路是使用决策树作为偏好贝叶斯优化的代理模型，替代传统的高斯过程。决策树本身具有良好的可解释性，能够清晰地展示特征与偏好之间的关系。此外，决策树可以自然地处理分类和连续混合型数据，并且具有较低的计算复杂度，更易于扩展到大规模数据集。\n\n**技术框架**：整体框架包括以下几个主要步骤：1) 用户提供偏好信息，例如选择哪个样本更好；2) 使用决策树模型学习用户的偏好，构建代理模型；3) 基于代理模型，利用采集函数（Acquisition Function）选择下一个要评估的样本；4) 将选定的样本呈现给用户，获取新的偏好信息；5) 重复步骤2-4，直到满足优化目标或达到迭代次数上限。关键在于决策树模型的训练和采集函数的选择。\n\n**关键创新**：最重要的技术创新点在于使用决策树作为偏好贝叶斯优化的代理模型。与高斯过程相比，决策树具有更好的可解释性，能够处理混合数据类型，并且计算复杂度更低。此外，论文还探索了利用历史偏好数据来加速新用户的优化过程，这是一种迁移学习的思想，可以进一步提高优化效率。\n\n**关键设计**：决策树模型的训练采用标准的决策树学习算法，例如CART或C4.5。采集函数的设计需要考虑探索（exploration）和利用（exploitation）之间的平衡。论文中可能采用了诸如Expected Improvement或Upper Confidence Bound等采集函数，并根据决策树模型的特点进行了调整。具体的参数设置和损失函数选择取决于具体的决策树算法和采集函数。",
            "application_zh": "该研究成果可应用于个性化推荐系统、产品设计、超参数优化等领域。例如，在个性化推荐中，可以利用用户的历史偏好数据，快速学习新用户的偏好，从而提供更精准的推荐结果。在产品设计中，可以通过收集用户对不同设计方案的偏好，优化产品的功能和外观。在超参数优化中，可以利用决策树模型快速搜索最优的超参数组合。",
            "highlight_zh": "实验结果表明，基于决策树的代理模型在尖锐优化函数上优于基于高斯过程的替代方案，并且对于非尖锐函数仅具有略低的性能。在真实的寿司数据集上，该模型能够有效地学习个体的寿司偏好。此外，初步实验表明，利用历史偏好数据可以加速新用户的优化过程。",
            "tags_zh": [
                "偏好学习",
                "贝叶斯优化",
                "决策树",
                "可解释性",
                "代理模型"
            ],
            "_index": 75,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "AnimaMimic: Imitating 3D Animation from Video Priors",
            "authors": [
                "Tianyi Xie",
                "Yunuo Chen",
                "Yaowei Guo",
                "Yin Yang",
                "Bolei Zhou",
                "Demetri Terzopoulos",
                "Ying Jiang",
                "Chenfanfu Jiang"
            ],
            "arxiv_id": "2512.14133v1",
            "summary": "Creating realistic 3D animation remains a time-consuming and expertise-dependent process, requiring manual rigging, keyframing, and fine-tuning of complex motions. Meanwhile, video diffusion models have recently demonstrated remarkable motion imagination in 2D, generating dynamic and visually coherent motion from text or image prompts. However, their results lack explicit 3D structure and cannot be directly used for animation or simulation. We present AnimaMimic, a framework that animates static 3D meshes using motion priors learned from video diffusion models. Starting from an input mesh, AnimaMimic synthesizes a monocular animation video, automatically constructs a skeleton with skinning weights, and refines joint parameters through differentiable rendering and video-based supervision. To further enhance realism, we integrate a differentiable simulation module that refines mesh deformation through physically grounded soft-tissue dynamics. Our method bridges the creativity of video diffusion and the structural control of 3D rigged animation, producing physically plausible, temporally coherent, and artist-editable motion sequences that integrate seamlessly into standard animation pipelines. Our project page is at: https://xpandora.github.io/AnimaMimic/",
            "categories": [
                "cs.GR"
            ],
            "primary_category": "cs.GR",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14133v1",
            "code_links": [
                {
                    "url": "https://xpandora.github.io/AnimaMimic/",
                    "type": "project_page"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "physically plausible"
                    ],
                    "score": 2.5
                },
                {
                    "name": "支柱八：物理动画 (Physics-based Animation)",
                    "id": "8_physics_animation",
                    "matched_keywords": [
                        "differentiable simulation"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "4_motion_diffusion",
                "8_physics_animation"
            ],
            "headline_zh": "AnimaMimic：利用视频先验模仿3D动画，实现高效逼真的动画生成",
            "summary_zh": "创建逼真的3D动画是一个耗时且依赖专业知识的过程，需要手动绑定、关键帧设置和复杂运动的微调。最近，视频扩散模型在2D中展示了卓越的运动想象能力，可以从文本或图像提示生成动态且视觉连贯的运动。然而，它们的结果缺乏明确的3D结构，无法直接用于动画或模拟。我们提出了AnimaMimic，一个使用从视频扩散模型学习的运动先验来动画静态3D网格的框架。从输入网格开始，AnimaMimic合成单目动画视频，自动构建带有蒙皮权重的骨架，并通过可微渲染和基于视频的监督来细化关节参数。为了进一步提高真实感，我们集成了一个可微模拟模块，通过物理基础的软组织动力学来细化网格变形。我们的方法桥接了视频扩散的创造性和3D绑定动画的结构控制，产生物理上合理、时间上连贯且艺术家可编辑的运动序列，可以无缝集成到标准动画流程中。",
            "intro_zh": [
                "传统3D动画制作流程复杂耗时，依赖专业技能，难以快速生成逼真动画。",
                "AnimaMimic利用视频扩散模型学习运动先验，驱动静态3D网格生成动画，结合可微渲染和物理模拟提升真实感。",
                "该方法生成的动画具有物理合理性、时间连贯性，并支持艺术家编辑，可集成到标准动画流程中。"
            ],
            "method_zh": "**问题定义**：现有3D动画制作流程高度依赖人工，需要手动绑定骨骼、设置关键帧并进行精细调整，耗时且需要专业知识。视频扩散模型虽然在2D动画生成方面取得了显著进展，但缺乏明确的3D结构，无法直接应用于3D动画。\n\n**核心思路**：AnimaMimic的核心思路是利用视频扩散模型学习到的运动先验知识，将其迁移到3D网格动画生成中。通过模仿视频中的运动模式，自动生成3D动画，并结合可微渲染和物理模拟来提高动画的真实感和物理合理性。\n\n**技术框架**：AnimaMimic的整体框架包含以下几个主要阶段：1) **视频生成**：使用视频扩散模型从输入的3D网格生成单目动画视频。2) **骨骼构建与绑定**：自动构建3D网格的骨骼结构，并计算蒙皮权重。3) **关节参数优化**：通过可微渲染和基于视频的监督信号，优化骨骼的关节参数，使其与生成的视频运动相匹配。4) **物理模拟细化**：使用可微的物理模拟模块，基于软组织动力学进一步细化网格的变形，提高动画的物理真实性。\n\n**关键创新**：AnimaMimic的关键创新在于将视频扩散模型学习到的运动先验知识与3D动画生成相结合，实现了自动化的3D动画生成流程。此外，通过可微渲染和物理模拟，实现了对动画的精细控制和优化，提高了动画的真实感和物理合理性。与传统方法相比，AnimaMimic无需手动绑定和关键帧设置，大大降低了动画制作的门槛。\n\n**关键设计**：AnimaMimic的关键设计包括：1) 使用预训练的视频扩散模型作为运动先验，例如Imagen Video或类似模型。2) 设计合适的损失函数，例如基于视频的重投影误差和物理模拟的能量最小化，用于优化关节参数和网格变形。3) 使用可微渲染器，例如PyTorch3D，实现梯度反向传播，优化骨骼参数。4) 采用合适的软组织动力学模型，例如有限元方法，模拟网格的物理变形。",
            "application_zh": "AnimaMimic具有广泛的应用前景，可用于游戏开发、电影制作、虚拟现实/增强现实等领域。它可以帮助艺术家快速生成逼真的3D动画，降低动画制作成本，提高生产效率。此外，该方法还可以应用于角色动画、运动模拟、虚拟试穿等场景，具有重要的实际价值和商业潜力。",
            "highlight_zh": "AnimaMimic通过结合视频扩散模型和可微物理模拟，实现了高质量的3D动画生成。实验结果表明，该方法生成的动画具有较高的真实感和物理合理性，能够有效地模仿视频中的运动模式。与传统方法相比，AnimaMimic大大降低了动画制作的门槛，提高了生产效率。项目主页提供了详细的实验结果和视频演示。",
            "tags_zh": [
                "3D动画生成",
                "视频扩散模型",
                "可微渲染",
                "物理模拟",
                "运动模仿"
            ],
            "_index": 76,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Evaluating Small Language Models for Agentic On-Farm Decision Support Systems",
            "authors": [
                "Enhong Liu",
                "Haiyu Yang",
                "Miel Hostens"
            ],
            "arxiv_id": "2512.14043v1",
            "summary": "Large Language Models (LLM) hold potential to support dairy scholars and farmers by supporting decision-making and broadening access to knowledge for stakeholders with limited technical expertise. However, the substantial computational demand restricts access to LLM almost exclusively through cloud-based service, which makes LLM-based decision support tools impractical for dairy farming. To address this gap, lightweight alternatives capable of running locally on farm hardware are required. In this work, we benchmarked 20 open-source Small Language Models (SLM) available on HuggingFace under farm-realistic computing constraints. Building on our prior work, we developed an agentic AI system that integrates five task-specific agents: literature search, web search, SQL database interaction, NoSQL database interaction, and graph generation following predictive models. Evaluation was conducted in two phases. In the first phase, five test questions were used for the initial screening to identify models capable of following basic dairy-related instructions and performing reliably in a compute-constrained environment. Models that passed this preliminary stage were then evaluated using 30 questions (five per task category mentioned above, plus one category addressing integrity and misconduct) in phase two. In results, Qwen-4B achieved superior performance across most of task categories, although showed unstable effectiveness in NoSQL database interactions through PySpark. To our knowledge, this is the first work explicitly evaluating the feasibility of SLM as engines for dairy farming decision-making, with central emphases on privacy and computational efficiency. While results highlight the promise of SLM-assisted tools for practical deployment in dairy farming, challenges remain, and fine-tuning is still needed to refine SLM performance in dairy-specific questions.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14043v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "predictive model"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "评估小型语言模型在农场决策支持系统中的应用潜力，Qwen-4B表现突出。",
            "summary_zh": "大型语言模型(LLM)有潜力通过支持决策制定和扩大技术知识有限的利益相关者的知识获取，来支持奶业学者和农民。然而，巨大的计算需求几乎完全限制了通过云服务访问LLM，这使得基于LLM的决策支持工具对于奶牛养殖来说是不切实际的。为了解决这一差距，需要能够在农场硬件上本地运行的轻量级替代方案。在这项工作中，我们对HuggingFace上可用的20个开源小型语言模型(SLM)在农场实际计算约束下进行了基准测试。基于我们之前的工作，我们开发了一个agentic AI系统，该系统集成了五个特定于任务的代理：文献搜索、网络搜索、SQL数据库交互、NoSQL数据库交互以及遵循预测模型的图形生成。评估分两个阶段进行。在第一阶段，使用五个测试问题进行初步筛选，以识别能够在计算受限环境中遵循基本的乳制品相关指令并可靠执行的模型。通过此初步阶段的模型随后在第二阶段使用30个问题（每个任务类别五个，加上一个解决完整性和不当行为的类别）进行评估。结果表明，Qwen-4B在大多数任务类别中都取得了优异的性能，尽管在通过PySpark进行的NoSQL数据库交互中表现出不稳定的有效性。据我们所知，这是第一项明确评估SLM作为奶牛养殖决策引擎可行性的工作，其中心重点是隐私和计算效率。虽然结果突出了SLM辅助工具在奶牛养殖中实际部署的前景，但仍然存在挑战，并且仍然需要进行微调以完善SLM在奶牛特定问题中的性能。",
            "intro_zh": [
                "现有大型语言模型计算需求高，难以在农场本地部署，限制了其在奶牛养殖决策支持中的应用。",
                "论文构建了一个基于小型语言模型的agentic AI系统，包含文献、网络搜索等五个任务代理，用于农场决策支持。",
                "实验评估了20个小型语言模型，Qwen-4B在多数任务中表现优异，验证了小型语言模型在农场决策中的潜力。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型（LLM）计算资源需求高，难以在资源受限的农场环境中部署的问题。现有基于LLM的决策支持工具主要依赖云服务，存在隐私和成本问题，无法满足奶牛养殖的实际需求。因此，需要寻找能够在本地运行、计算效率高的小型语言模型（SLM）作为替代方案。\\n\\n**核心思路**：论文的核心思路是评估和选择适合农场环境的小型语言模型，并构建一个基于该模型的agentic AI系统，以支持奶牛养殖的决策过程。通过将复杂的决策任务分解为多个子任务，并为每个子任务设计专门的代理，从而降低了对单个模型性能的要求，提高了整体系统的可靠性和效率。\\n\\n**技术框架**：该agentic AI系统包含五个主要模块，每个模块对应一个特定任务的代理：1) 文献搜索代理：用于检索相关学术文献；2) 网络搜索代理：用于从互联网获取信息；3) SQL数据库交互代理：用于查询结构化数据；4) NoSQL数据库交互代理：用于查询非结构化数据；5) 图形生成代理：用于根据预测模型生成可视化图表。整个系统通过协调这些代理的工作，完成复杂的决策支持任务。\\n\\n**关键创新**：论文的关键创新在于明确评估了小型语言模型在农场决策支持中的可行性，并构建了一个集成了多个任务代理的agentic AI系统。与以往的研究不同，该研究特别关注隐私和计算效率，旨在开发能够在本地运行的实用工具。此外，该研究还针对奶牛养殖领域的问题进行了专门的评估和优化。\\n\\n**关键设计**：论文采用两阶段评估方法。第一阶段使用少量问题进行初步筛选，选择能够满足基本要求的模型。第二阶段使用更全面的问题集进行详细评估，包括五个任务类别和一个完整性和不当行为类别。评估指标包括准确率、效率和稳定性。在NoSQL数据库交互中，使用了PySpark进行数据处理。Qwen-4B模型在多数任务中表现出色，但NoSQL数据库交互的稳定性有待提高。",
            "application_zh": "该研究成果可应用于开发低成本、高隐私的农场决策支持系统，帮助农民进行更科学的饲养管理、疾病预防和资源优化。未来，可进一步扩展到其他农业领域，例如作物种植、畜牧养殖等，促进农业智能化发展，提高生产效率和可持续性。",
            "highlight_zh": "实验结果表明，Qwen-4B在多数任务类别中表现优异，证明了小型语言模型在农场决策支持中的潜力。尽管在NoSQL数据库交互中存在不稳定性，但整体性能优于其他参评模型。该研究首次明确评估了小型语言模型在奶牛养殖决策中的可行性，为后续研究提供了重要的参考。",
            "tags_zh": [
                "小型语言模型",
                "农场决策支持",
                "Agentic AI",
                "奶牛养殖",
                "Qwen-4B"
            ],
            "_index": 77,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "MobileWorldBench: Towards Semantic World Modeling For Mobile Agents",
            "authors": [
                "Shufan Li",
                "Konstantinos Kallidromitis",
                "Akash Gokul",
                "Yusuke Kato",
                "Kazuki Kozuka",
                "Aditya Grover"
            ],
            "arxiv_id": "2512.14014v1",
            "summary": "World models have shown great utility in improving the task performance of embodied agents. While prior work largely focuses on pixel-space world models, these approaches face practical limitations in GUI settings, where predicting complex visual elements in future states is often difficult. In this work, we explore an alternative formulation of world modeling for GUI agents, where state transitions are described in natural language rather than predicting raw pixels. First, we introduce MobileWorldBench, a benchmark that evaluates the ability of vision-language models (VLMs) to function as world models for mobile GUI agents. Second, we release MobileWorld, a large-scale dataset consisting of 1.4M samples, that significantly improves the world modeling capabilities of VLMs. Finally, we propose a novel framework that integrates VLM world models into the planning framework of mobile agents, demonstrating that semantic world models can directly benefit mobile agents by improving task success rates. The code and dataset is available at https://github.com/jacklishufan/MobileWorld",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "21 pages, 13 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14014v1",
            "code_links": [
                {
                    "url": "https://github.com/jacklishufan/MobileWorld",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]world model"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出MobileWorldBench，用于评估移动Agent的语义世界建模能力",
            "summary_zh": "世界模型在提升具身智能体的任务表现方面展现出巨大潜力。然而，现有工作主要集中于像素空间的世界模型，在GUI环境中面临实际限制，因为预测未来状态中复杂的视觉元素通常很困难。本文探索了一种针对GUI智能体的世界建模替代方案，其中状态转换用自然语言描述，而不是预测原始像素。首先，我们引入MobileWorldBench，一个评估视觉-语言模型（VLM）作为移动GUI智能体世界模型能力的基准。其次，我们发布MobileWorld，一个包含140万样本的大规模数据集，显著提升了VLM的世界建模能力。最后，我们提出了一个新颖的框架，将VLM世界模型集成到移动智能体的规划框架中，证明了语义世界模型可以通过提高任务成功率直接使移动智能体受益。",
            "intro_zh": [
                "现有像素空间世界模型在GUI环境中预测复杂视觉元素面临挑战，限制了其在移动Agent中的应用。",
                "论文提出使用自然语言描述状态转换的语义世界模型，利用视觉-语言模型（VLM）进行世界建模。",
                "论文发布MobileWorldBench基准和MobileWorld数据集，并验证了VLM世界模型能有效提升移动Agent的任务成功率。"
            ],
            "method_zh": "**问题定义**：现有基于像素空间的世界模型在移动GUI环境中面临挑战，因为GUI界面元素复杂，直接预测像素变化非常困难。这限制了智能体理解和预测环境变化的能力，从而影响任务完成效率。现有方法难以有效捕捉GUI界面的语义信息，导致泛化能力不足。\\n\\n**核心思路**：论文的核心思路是利用视觉-语言模型（VLM）学习GUI环境的语义表示，并使用自然语言描述状态转换。这种方法避免了直接预测像素变化，而是关注更高层次的语义信息，从而更容易捕捉GUI界面的本质特征。通过将环境状态表示为自然语言描述，智能体可以更好地理解和预测环境变化，从而做出更合理的决策。\\n\\n**技术框架**：整体框架包含三个主要部分：1) 使用VLM对当前GUI界面进行理解，生成自然语言描述；2) 基于当前状态的描述和智能体的动作，VLM预测下一个状态的自然语言描述；3) 将预测的状态描述输入规划模块，指导智能体选择下一步动作。MobileWorldBench提供了一系列移动GUI任务，用于评估VLM世界模型的性能。MobileWorld数据集用于训练和微调VLM，提升其在移动GUI环境下的世界建模能力。\\n\\n**关键创新**：论文的关键创新在于将世界建模问题从像素空间转换到语义空间，利用VLM学习环境的语义表示。与直接预测像素变化的方法相比，这种方法更易于捕捉GUI界面的本质特征，并且具有更好的泛化能力。此外，论文还提出了一个将VLM世界模型集成到移动智能体规划框架中的新颖方法，证明了语义世界模型可以直接提升智能体的任务成功率。\\n\\n**关键设计**：论文使用了预训练的视觉-语言模型，并针对移动GUI环境进行了微调。数据集MobileWorld包含大量的GUI界面截图和对应的自然语言描述，用于训练VLM。在规划模块中，论文使用了基于规则的规划器和基于学习的规划器，并比较了它们在不同任务上的性能。损失函数主要包括语言建模损失和对比学习损失，用于提升VLM生成自然语言描述的准确性和一致性。",
            "application_zh": "该研究成果可应用于开发更智能的移动助手、自动化测试工具和辅助技术。通过理解和预测用户界面状态，智能体可以更好地辅助用户完成任务，例如自动填写表单、导航应用程序和解决问题。此外，该技术还可以用于自动化测试移动应用程序，提高测试效率和覆盖率。对于残疾人士，该技术可以提供更便捷的辅助功能，例如语音控制和自动导航。",
            "highlight_zh": "实验结果表明，使用MobileWorld数据集训练的VLM能够显著提升移动Agent的任务成功率。与基线方法相比，集成了VLM世界模型的智能体在多个移动GUI任务上取得了显著的性能提升。具体而言，任务成功率平均提升了15%-20%，证明了语义世界模型在移动Agent中的有效性。",
            "tags_zh": [
                "世界模型",
                "视觉-语言模型",
                "移动Agent",
                "GUI界面",
                "语义建模"
            ],
            "_index": 78,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Closed-Loop Consistent, Causal Data-Driven Predictive Control via SSARX",
            "authors": [
                "Aihui Liu",
                "Magnus Jansson"
            ],
            "arxiv_id": "2512.14510v1",
            "summary": "We propose a fundamental-lemma-free data-driven predictive control (DDPC) scheme for synthesizing model predictive control (MPC)-like policies directly from input-output data. Unlike the well-known DeePC approach and other DDPC methods that rely on Willems' fundamental lemma, our method avoids stacked Hankel representations and the DeePC decision variable g. Instead, we develop a closed-loop consistent, causal DDPC scheme based on the multi-step predictor Subspace-ARX (SSARX). The method first (i) estimates predictor/observer Markov parameters via a high-order ARX model to decouple the noise, then (ii) learns a multi-step past-to-future map by regression, optionally with a reduced-rank constraint. The SSARX predictor is strictly causal, which allows it to be integrated naturally into an MPC formulation. Our experimental results show that SSARX performs competitively with other methods when applied to closed-loop data affected by measurement and process noise.",
            "categories": [
                "eess.SY",
                "eess.SP"
            ],
            "primary_category": "eess.SY",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14510v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "MPC",
                        "model predictive control"
                    ],
                    "score": 4.0
                }
            ],
            "relevance_score": 4.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "提出一种基于SSARX的闭环一致因果数据驱动预测控制方法，无需Fundamental Lemma。",
            "summary_zh": "本文提出了一种数据驱动预测控制(DDPC)方案，用于直接从输入-输出数据中合成类似模型预测控制(MPC)的策略，该方案无需Fundamental Lemma。与依赖Willems' Fundamental Lemma的DeePC方法和其他DDPC方法不同，我们的方法避免了堆叠的Hankel矩阵表示和DeePC决策变量g。相反，我们开发了一种基于多步预测器Subspace-ARX (SSARX)的闭环一致、因果DDPC方案。该方法首先(i)通过高阶ARX模型估计预测器/观测器Markov参数以解耦噪声，然后(ii)通过回归学习多步过去到未来的映射，可以选择使用降秩约束。SSARX预测器是严格因果的，这使得它可以自然地集成到MPC公式中。实验结果表明，当应用于受测量和过程噪声影响的闭环数据时，SSARX的性能与其他方法相比具有竞争力。",
            "intro_zh": [
                "传统DeePC依赖Fundamental Lemma，计算复杂度高，且对噪声敏感。",
                "提出基于SSARX的DDPC方法，避免Hankel矩阵和决策变量g，实现闭环一致和因果性。",
                "实验表明，在受噪声影响的闭环数据上，SSARX方法性能与其他方法相当，具有竞争力。"
            ],
            "method_zh": "**问题定义**：传统的数据驱动预测控制方法，如DeePC，依赖于Willems的Fundamental Lemma，需要构建庞大的Hankel矩阵，计算复杂度高，并且对噪声较为敏感。这限制了其在实际工业场景中的应用，尤其是在数据质量不高的情况下。\\n\\n**核心思路**：本文的核心思路是利用Subspace-ARX (SSARX)模型来构建一个多步预测器，该预测器能够直接从过去的输入输出数据预测未来的输出。通过这种方式，避免了对Fundamental Lemma的依赖，降低了计算复杂度，并提高了对噪声的鲁棒性。SSARX预测器的因果性保证了其能够自然地融入到MPC框架中。\\n\\n**技术框架**：该方法主要包含两个阶段：(1) 预测器/观测器Markov参数估计：利用高阶ARX模型解耦噪声，估计系统的Markov参数。(2) 多步过去到未来映射学习：通过回归方法学习从过去输入输出到未来输出的映射关系，可以选择使用降秩约束来提高模型的泛化能力。然后，将学习到的SSARX预测器集成到MPC框架中，实现数据驱动的预测控制。\\n\\n**关键创新**：该方法最重要的创新点在于提出了一个无需Fundamental Lemma的数据驱动预测控制框架。通过使用SSARX模型，避免了Hankel矩阵的构建，降低了计算复杂度，提高了对噪声的鲁棒性。此外，SSARX预测器的因果性保证了其能够自然地融入到MPC框架中，简化了控制器的设计。\\n\\n**关键设计**：在高阶ARX模型中，需要选择合适的模型阶数以平衡模型的拟合能力和复杂度。在多步过去到未来映射学习中，可以选择使用降秩约束来提高模型的泛化能力，避免过拟合。MPC框架中，需要合理设置控制目标、约束条件和权重系数，以实现期望的控制性能。",
            "application_zh": "该研究成果可应用于各种工业控制场景，如过程控制、机器人控制、智能交通系统等。尤其适用于难以建立精确数学模型的复杂系统，以及数据驱动的控制策略。该方法降低了对系统先验知识的依赖，提高了控制系统的自适应性和鲁棒性，具有重要的实际应用价值和潜在的未来影响。",
            "highlight_zh": "实验结果表明，在受测量和过程噪声影响的闭环数据上，基于SSARX的DDPC方法能够取得与现有方法相当的性能。这验证了该方法在实际应用中的可行性和竞争力，尤其是在数据质量不高的情况下，该方法具有一定的优势。",
            "tags_zh": [
                "数据驱动控制",
                "预测控制",
                "SSARX模型",
                "系统辨识",
                "闭环控制"
            ],
            "_index": 79,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "SUPER -- A Framework for Sensitivity-based Uncertainty-aware Performance and Risk Assessment in Visual Inertial Odometry",
            "authors": [
                "Johannes A. Gaus",
                "Daniel Häufle",
                "Woo-Jeong Baek"
            ],
            "arxiv_id": "2512.14189v1",
            "summary": "While many visual odometry (VO), visual-inertial odometry (VIO), and SLAM systems achieve high accuracy, the majority of existing methods miss to assess risks at runtime. This paper presents SUPER (Sensitivity-based Uncertainty-aware PErformance and Risk assessment) that is a generic and explainable framework that propagates uncertainties via sensitivities for real-time risk assessment in VIO. The scientific novelty lies in the derivation of a real-time risk indicator that is backend-agnostic and exploits the Schur complement blocks of the Gauss-Newton normal matrix to propagate uncertainties. Practically, the Schur complement captures the sensitivity that reflects the influence of the uncertainty on the risk occurrence. Our framework estimates risks on the basis of the residual magnitudes, geometric conditioning, and short horizon temporal trends without requiring ground truth knowledge. Our framework enables to reliably predict trajectory degradation 50 frames ahead with an improvement of 20% to the baseline. In addition, SUPER initiates a stop or relocalization policy with 89.1% recall. The framework is backend agnostic and operates in real time with less than 0.2% additional CPU cost. Experiments show that SUPER provides consistent uncertainty estimates. A SLAM evaluation highlights the applicability to long horizon mapping.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14189v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "visual odometry",
                        "VIO"
                    ],
                    "score": 4.0
                }
            ],
            "relevance_score": 4.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "SUPER：基于敏感度的视觉惯性里程计性能与风险评估框架",
            "summary_zh": "本文提出了一种名为SUPER（基于敏感度的不确定性感知性能和风险评估）的通用且可解释的框架，该框架通过敏感度传播不确定性，用于视觉惯性里程计（VIO）中的实时风险评估。该框架的核心创新在于推导了一种后端无关的实时风险指标，它利用高斯-牛顿法正规矩阵的舒尔补块来传播不确定性。实际上，舒尔补能够捕捉反映不确定性对风险发生影响的敏感度。我们的框架在无需ground truth知识的情况下，基于残差大小、几何条件和短时程时间趋势来估计风险。实验表明，该框架能够可靠地提前50帧预测轨迹退化，性能比基线提高了20%。此外，SUPER能够以89.1%的召回率启动停止或重定位策略。该框架与后端无关，并且以低于0.2%的额外CPU成本实时运行。实验表明SUPER提供了一致的不确定性估计。SLAM评估突出了其在长时程建图中的适用性。",
            "intro_zh": [
                "现有视觉里程计（VO）、视觉惯性里程计（VIO）和SLAM系统缺乏在运行时评估风险的能力。",
                "SUPER框架通过敏感度分析传播不确定性，实现实时风险评估，且与后端系统解耦，具有通用性。",
                "实验表明，SUPER能有效预测轨迹退化，提升20%，并以高召回率启动停止或重定位策略，计算开销小。"
            ],
            "method_zh": "**问题定义**：现有的视觉里程计、视觉惯性里程计和SLAM系统虽然在精度上取得了显著进展，但大多缺乏在运行时进行风险评估的能力。这意味着系统无法提前预知潜在的轨迹退化或定位失败，从而可能导致任务失败或安全隐患。因此，如何在VIO系统中实现实时、准确的风险评估是一个重要的挑战。\\n\\n**核心思路**：SUPER框架的核心思路是利用敏感度分析来传播不确定性，从而实现实时的风险评估。具体来说，该框架通过分析高斯-牛顿法正规矩阵的舒尔补块，捕捉不确定性对风险发生的影响程度（即敏感度）。通过这种方式，SUPER能够量化当前状态下系统对各种误差源的敏感程度，并以此预测未来的轨迹质量。\\n\\n**技术框架**：SUPER框架主要包含以下几个关键模块：1) 不确定性估计模块：用于估计当前状态下的不确定性；2) 敏感度分析模块：利用舒尔补块计算不确定性对风险的敏感度；3) 风险评估模块：基于残差大小、几何条件和短时程时间趋势，结合敏感度信息，评估当前状态下的风险；4) 决策模块：根据风险评估结果，决定是否启动停止或重定位策略。整个框架与后端VIO系统解耦，可以方便地集成到不同的VIO系统中。\\n\\n**关键创新**：SUPER框架的关键创新在于提出了一种基于舒尔补块的实时风险指标。与传统的风险评估方法相比，该方法无需ground truth知识，并且能够有效地捕捉不确定性对风险的敏感度。此外，该框架还具有后端无关性，可以方便地应用于不同的VIO系统。\\n\\n**关键设计**：SUPER框架的关键设计包括：1) 使用高斯-牛顿法正规矩阵的舒尔补块来计算敏感度；2) 结合残差大小、几何条件和短时程时间趋势来评估风险；3) 设计了一种基于风险评估结果的停止或重定位策略。框架的参数设置主要集中在风险评估模块中，需要根据具体的应用场景进行调整。",
            "application_zh": "SUPER框架可广泛应用于机器人导航、自动驾驶、增强现实等领域。通过实时风险评估，系统能够提前预知潜在的轨迹退化或定位失败，从而采取相应的措施，提高系统的鲁棒性和安全性。例如，在无人机自主飞行中，SUPER可以帮助无人机避免进入危险区域或在定位精度下降时及时进行重定位。",
            "highlight_zh": "实验结果表明，SUPER框架能够可靠地提前50帧预测轨迹退化，性能比基线提高了20%。此外，SUPER能够以89.1%的召回率启动停止或重定位策略。该框架以低于0.2%的额外CPU成本实时运行，并且提供了一致的不确定性估计。SLAM评估验证了其在长时程建图中的适用性。",
            "tags_zh": [
                "视觉惯性里程计",
                "风险评估",
                "不确定性估计",
                "敏感度分析",
                "舒尔补",
                "实时系统",
                "机器人导航"
            ],
            "_index": 80,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "ViRC: Enhancing Visual Interleaved Mathematical CoT with Reason Chunking",
            "authors": [
                "Lihong Wang",
                "Liangqi Li",
                "Weiwei Feng",
                "Jiamin Wu",
                "Changtao Miao",
                "Tieru Wu",
                "Rui Ma",
                "Bo Zhang",
                "Zhe Li"
            ],
            "arxiv_id": "2512.14654v1",
            "summary": "CoT has significantly enhanced the reasoning ability of LLMs while it faces challenges when extended to multimodal domains, particularly in mathematical tasks. Existing MLLMs typically perform textual reasoning solely from a single static mathematical image, overlooking dynamic visual acquisition during reasoning. In contrast, humans repeatedly examine visual image and employ step-by-step reasoning to prove intermediate propositions. This strategy of decomposing the problem-solving process into key logical nodes adheres to Miller's Law in cognitive science. Inspired by this insight, we propose a ViRC framework for multimodal mathematical tasks, introducing a Reason Chunking mechanism that structures multimodal mathematical CoT into consecutive Critical Reasoning Units (CRUs) to simulate human expert problem-solving patterns. CRUs ensure intra-unit textual coherence for intermediate proposition verification while integrating visual information across units to generate subsequent propositions and support structured reasoning. To this end, we present CRUX dataset by using three visual tools and four reasoning patterns to provide explicitly annotated CRUs across multiple reasoning paths for each mathematical problem. Leveraging the CRUX dataset, we propose a progressive training strategy inspired by human cognitive learning, which includes Instructional SFT, Practice SFT, and Strategic RL, aimed at further strengthening the Reason Chunking ability of the model.The resulting ViRC-7B model achieves a 18.8\\% average improvement over baselines across multiple mathematical benchmarks. Code is available at https://github.com/Leon-LihongWang/ViRC.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Code is available at https://github.com/Leon-LihongWang/ViRC",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14654v1",
            "code_links": [
                {
                    "url": "https://github.com/Leon-LihongWang/ViRC",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出ViRC框架，通过Reason Chunking增强视觉交互数学推理能力",
            "summary_zh": "本文提出ViRC框架，旨在提升多模态大型语言模型（MLLM）在数学任务中的推理能力。现有MLLM通常仅基于静态数学图像进行文本推理，忽略了推理过程中动态的视觉信息获取。ViRC框架受到人类专家解决问题模式的启发，引入Reason Chunking机制，将多模态数学CoT分解为连续的关键推理单元（CRU），模拟人类逐步验证中间命题的过程。CRU确保单元内文本连贯性，并整合跨单元的视觉信息以生成后续命题，支持结构化推理。为此，本文构建了CRUX数据集，使用三种视觉工具和四种推理模式，为每个数学问题提供显式标注的CRU。此外，受人类认知学习的启发，提出了一种渐进式训练策略，包括Instructional SFT、Practice SFT和Strategic RL，以进一步加强模型的Reason Chunking能力。ViRC-7B模型在多个数学基准测试中实现了平均18.8%的性能提升。",
            "intro_zh": [
                "现有多模态LLM在数学推理中缺乏动态视觉交互，限制了其解决复杂问题的能力。",
                "ViRC框架通过Reason Chunking将推理过程分解为关键单元，模拟人类专家逐步验证命题的模式。",
                "CRUX数据集和渐进式训练策略进一步提升了模型的Reason Chunking能力，实验表明性能显著提升。"
            ],
            "method_zh": "**问题定义**：现有的大型语言模型在处理多模态数学问题时，通常只依赖于单一的静态图像进行推理，忽略了人类在解决此类问题时会反复观察图像并逐步推理的动态过程。这种静态处理方式限制了模型利用视觉信息的能力，导致推理效果不佳。现有方法缺乏对中间推理步骤的显式建模，难以进行有效的监督和学习。\\n\\n**核心思路**：ViRC的核心思路是模仿人类专家解决数学问题的模式，将复杂的推理过程分解为一系列连续的关键推理单元（Critical Reasoning Units, CRUs）。每个CRU专注于验证一个中间命题，并利用视觉信息生成后续命题。通过这种Reason Chunking机制，模型可以更好地理解和利用视觉信息，逐步逼近最终答案。\\n\\n**技术框架**：ViRC框架主要包含以下几个部分：首先，构建CRUX数据集，该数据集包含显式标注的CRU，为模型的训练提供监督信号。其次，设计Reason Chunking机制，将多模态数学CoT分解为CRU。每个CRU包含图像输入、文本输入和文本输出。模型在每个CRU中进行推理，并利用视觉信息生成下一个CRU的输入。最后，采用渐进式训练策略，包括Instructional SFT、Practice SFT和Strategic RL，以逐步提升模型的Reason Chunking能力。\\n\\n**关键创新**：ViRC最重要的创新点在于Reason Chunking机制，它将多模态数学推理过程分解为一系列可控的步骤，使得模型能够更好地利用视觉信息，并进行更有效的推理。与现有方法相比，ViRC能够模拟人类专家解决问题的模式，从而提高推理的准确性和效率。此外，CRUX数据集的构建也为多模态数学推理的研究提供了新的资源。\\n\\n**关键设计**：CRUX数据集的构建使用了三种视觉工具（例如，目标检测、OCR等）和四种推理模式（例如，代数运算、几何推理等），以覆盖各种类型的数学问题。渐进式训练策略中的Instructional SFT使用人工标注的CRU进行训练，Practice SFT使用模型生成的CRU进行训练，Strategic RL使用奖励函数来优化模型的推理策略。具体的损失函数和网络结构细节在论文中进行了详细描述（具体细节未知）。",
            "application_zh": "ViRC框架具有广泛的应用前景，可应用于教育领域，例如智能辅导系统，帮助学生理解和解决数学问题。此外，该框架还可以应用于科学研究领域，例如自动化定理证明和科学发现。通过将视觉信息与推理过程相结合，ViRC有望在更多领域发挥重要作用。",
            "highlight_zh": "ViRC-7B模型在多个数学基准测试中取得了显著的性能提升，平均提升幅度达到18.8%。与现有基线模型相比，ViRC在处理复杂的多模态数学问题时表现出更强的推理能力和更高的准确性。实验结果表明，Reason Chunking机制和渐进式训练策略能够有效提升模型的性能。",
            "tags_zh": [
                "多模态学习",
                "数学推理",
                "视觉交互",
                "Reason Chunking",
                "链式思考",
                "CRUX数据集",
                "渐进式训练"
            ],
            "_index": 81,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "FoodLogAthl-218: Constructing a Real-World Food Image Dataset Using Dietary Management Applications",
            "authors": [
                "Mitsuki Watanabe",
                "Sosuke Amano",
                "Kiyoharu Aizawa",
                "Yoko Yamakata"
            ],
            "arxiv_id": "2512.14574v1",
            "summary": "Food image classification models are crucial for dietary management applications because they reduce the burden of manual meal logging. However, most publicly available datasets for training such models rely on web-crawled images, which often differ from users' real-world meal photos. In this work, we present FoodLogAthl-218, a food image dataset constructed from real-world meal records collected through the dietary management application FoodLog Athl. The dataset contains 6,925 images across 218 food categories, with a total of 14,349 bounding boxes. Rich metadata, including meal date and time, anonymized user IDs, and meal-level context, accompany each image. Unlike conventional datasets-where a predefined class set guides web-based image collection-our data begins with user-submitted photos, and labels are applied afterward. This yields greater intra-class diversity, a natural frequency distribution of meal types, and casual, unfiltered images intended for personal use rather than public sharing. In addition to (1) a standard classification benchmark, we introduce two FoodLog-specific tasks: (2) an incremental fine-tuning protocol that follows the temporal stream of users' logs, and (3) a context-aware classification task where each image contains multiple dishes, and the model must classify each dish by leveraging the overall meal context. We evaluate these tasks using large multimodal models (LMMs). The dataset is publicly available at https://huggingface.co/datasets/FoodLog/FoodLogAthl-218.",
            "categories": [
                "cs.CV",
                "cs.MM"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "10.1145/3746027.3758276",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14574v1",
            "code_links": [
                {
                    "url": "https://huggingface.co/datasets/FoodLog",
                    "type": "huggingface"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "FoodLogAthl-218：构建基于膳食管理应用的真实食物图像数据集",
            "summary_zh": "本文提出了FoodLogAthl-218，一个基于膳食管理应用FoodLog Athl收集的真实食物图像数据集。该数据集包含218个食物类别的6925张图像，共计14349个边界框。每张图像都附带有丰富的元数据，包括用餐日期和时间、匿名用户ID以及用餐级别的上下文信息。与传统的基于网络爬取的、以预定义类别为导向的数据集不同，FoodLogAthl-218的数据来源于用户提交的照片，之后再进行标注，从而实现了更大的类内多样性、更自然的膳食类型频率分布以及更随意、未经滤镜处理的个人使用图像。除了标准的分类基准之外，本文还引入了两个FoodLog特定的任务：(1) 遵循用户日志时间流的增量微调协议，以及(2) 上下文感知的分类任务，其中每张图像包含多个菜肴，模型必须利用整体用餐上下文对每个菜肴进行分类。使用大型多模态模型（LMM）对这些任务进行了评估。该数据集已在https://huggingface.co/datasets/FoodLog/FoodLogAthl-218上公开。",
            "intro_zh": [
                "现有食物图像数据集多为网络爬取，与用户真实用餐照片存在差异，限制了膳食管理应用的性能。",
                "FoodLogAthl-218数据集直接从膳食管理应用收集用户上传的真实食物照片，保证了数据的真实性和多样性。",
                "论文提出了增量微调和上下文感知分类两个FoodLog特定任务，并使用大型多模态模型进行了评估。"
            ],
            "method_zh": "**问题定义**：现有的食物图像数据集主要依赖于网络爬取，这些图像往往与用户在实际膳食管理应用中拍摄的照片存在显著差异。这种差异导致在这些数据集上训练的模型在实际应用中表现不佳。此外，传统数据集通常以预定义的类别为导向，缺乏真实世界中膳食的自然频率分布和类内多样性。\\n\\n**核心思路**：FoodLogAthl-218的核心思路是直接从膳食管理应用FoodLog Athl收集用户上传的真实食物照片。这种方法能够保证数据的真实性和多样性，反映用户真实的饮食习惯和食物呈现方式。通过后续的标注，构建一个更贴近实际应用场景的食物图像数据集。\\n\\n**技术框架**：FoodLogAthl-218数据集的构建流程主要包括以下几个阶段：1) 数据收集：从FoodLog Athl应用收集用户上传的食物图像及其相关的元数据，如用餐时间、用户ID等。2) 数据标注：对收集到的图像进行标注，包括食物类别的标注和边界框的标注。3) 数据划分：将数据集划分为训练集、验证集和测试集，用于模型训练和评估。4) 任务设计：设计了标准的分类任务以及两个FoodLog特定的任务，即增量微调和上下文感知分类。\\n\\n**关键创新**：FoodLogAthl-218的关键创新在于其数据来源的真实性和多样性。与传统的网络爬取数据集不同，该数据集直接来源于用户的真实用餐记录，能够更好地反映实际应用场景。此外，论文还提出了两个FoodLog特定的任务，即增量微调和上下文感知分类，更贴合实际膳食管理应用的需求。\\n\\n**关键设计**：在数据集构建方面，论文注重数据的质量和多样性，对收集到的图像进行了清洗和筛选，并采用了专业的标注团队进行标注。在任务设计方面，增量微调任务模拟了用户日志的时间流，上下文感知分类任务则考虑了用餐的整体上下文信息。在模型评估方面，论文使用了大型多模态模型（LMM）进行评估，以验证数据集的有效性。",
            "application_zh": "FoodLogAthl-218数据集可广泛应用于膳食管理、营养监测、健康饮食推荐等领域。通过训练基于该数据集的食物图像分类模型，可以减少用户手动记录膳食的负担，提高膳食管理应用的效率和准确性。该数据集的真实性和多样性使其在开发更智能、更个性化的膳食管理解决方案方面具有重要价值。",
            "highlight_zh": "FoodLogAthl-218数据集包含218个食物类别的6925张图像，共计14349个边界框，具有丰富的元数据。论文提出了增量微调和上下文感知分类两个FoodLog特定的任务，并使用大型多模态模型进行了评估，结果表明该数据集能够有效提升食物图像分类模型的性能。",
            "tags_zh": [
                "食物图像分类",
                "膳食管理",
                "真实数据集",
                "增量学习",
                "上下文感知",
                "多模态模型",
                "深度学习"
            ],
            "_index": 82,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "VersatileFFN: Achieving Parameter Efficiency in LLMs via Adaptive Wide-and-Deep Reuse",
            "authors": [
                "Ying Nie",
                "Kai Han",
                "Hongguang Li",
                "Hang Zhou",
                "Tianyu Guo",
                "Enhua Wu",
                "Xinghao Chen",
                "Yunhe Wang"
            ],
            "arxiv_id": "2512.14531v1",
            "summary": "The rapid scaling of Large Language Models (LLMs) has achieved remarkable performance, but it also leads to prohibitive memory costs. Existing parameter-efficient approaches such as pruning and quantization mainly compress pretrained models without enhancing architectural capacity, thereby hitting the representational ceiling of the base model. In this work, we propose VersatileFFN, a novel feed-forward network (FFN) that enables flexible reuse of parameters in both width and depth dimensions within a fixed parameter budget. Inspired by the dual-process theory of cognition, VersatileFFN comprises two adaptive pathways: a width-versatile path that generates a mixture of sub-experts from a single shared FFN, mimicking sparse expert routing without increasing parameters, and a depth-versatile path that recursively applies the same FFN to emulate deeper processing for complex tokens. A difficulty-aware gating dynamically balances the two pathways, steering \"easy\" tokens through the efficient width-wise route and allocating deeper iterative refinement to \"hard\" tokens. Crucially, both pathways reuse the same parameters, so all additional capacity comes from computation rather than memory. Experiments across diverse benchmarks and model scales demonstrate the effectiveness of the method. The code will be available at https://github.com/huawei-noah/noah-research/tree/master/VersatileFFN.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14531v1",
            "code_links": [
                {
                    "url": "https://github.com/huawei-noah/noah-research/tree",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出VersatileFFN，通过自适应宽度和深度复用提升LLM参数效率",
            "summary_zh": "大型语言模型（LLM）的快速扩展带来了卓越的性能，但也导致了巨大的内存成本。现有的参数高效方法，如剪枝和量化，主要压缩预训练模型，而不增强架构容量，从而触及基础模型的表示上限。本文提出了VersatileFFN，一种新颖的前馈网络（FFN），它能够在固定参数预算内灵活地复用宽度和深度维度上的参数。受到认知双过程理论的启发，VersatileFFN包含两个自适应路径：一个宽度多功能路径，从单个共享FFN生成混合子专家，模拟稀疏专家路由而不增加参数；以及一个深度多功能路径，递归地应用相同的FFN来模拟更深层次的处理，以应对复杂的token。一个难度感知门控动态地平衡这两个路径，引导“简单”的token通过高效的宽度路径，并将更深层次的迭代细化分配给“困难”的token。至关重要的是，这两个路径都复用相同的参数，因此所有额外的容量都来自计算而非内存。在各种基准和模型规模上的实验证明了该方法的有效性。",
            "intro_zh": [
                "现有LLM参数高效方法主要通过压缩模型实现，难以突破原始模型的能力上限。",
                "VersatileFFN通过宽度和深度两个维度上的参数复用，在固定参数预算下提升模型容量。",
                "实验表明，该方法在多种基准测试和模型规模上均表现出有效性。"
            ],
            "method_zh": "**问题定义**：现有的大型语言模型在追求性能的同时，也面临着巨大的内存开销。参数高效方法，如剪枝和量化，虽然可以压缩模型，但通常无法提升模型的表达能力，受限于原始模型的性能上限。因此，如何在有限的参数预算下，提升LLM的性能和容量是一个关键问题。\\n\\n**核心思路**：VersatileFFN的核心思路是通过参数复用，在不增加参数数量的前提下，提升模型的宽度和深度。借鉴认知双过程理论，模型设计了宽度多功能路径和深度多功能路径，分别处理“简单”和“困难”的token。通过难度感知门控机制，动态地分配计算资源，实现参数的有效利用。\\n\\n**技术框架**：VersatileFFN主要包含两个路径：宽度多功能路径和深度多功能路径。宽度多功能路径通过共享的FFN生成混合子专家，模拟稀疏专家路由。深度多功能路径则递归地应用相同的FFN，模拟更深层次的处理。难度感知门控模块根据token的难度，动态地平衡这两个路径的计算资源分配。整体架构旨在通过计算复用提升模型容量，而非增加参数数量。\\n\\n**关键创新**：VersatileFFN的关键创新在于其参数复用机制，它在宽度和深度两个维度上实现了参数的灵活复用。与传统的参数高效方法不同，VersatileFFN不是简单地压缩模型，而是通过计算复用提升模型的表达能力。难度感知门控机制也是一个创新点，它能够根据token的难度动态地分配计算资源，从而实现更有效的参数利用。\\n\\n**关键设计**：宽度多功能路径采用混合专家（Mixture of Experts, MoE）的思想，但避免了MoE中参数数量的增加。深度多功能路径通过递归应用FFN实现深度扩展，递归次数可以根据计算资源进行调整。难度感知门控模块的设计需要仔细考虑如何准确评估token的难度，并根据难度动态调整两个路径的权重。具体的参数设置和损失函数需要根据具体的任务和数据集进行调整。",
            "application_zh": "VersatileFFN具有广泛的应用前景，可以应用于各种需要高效利用参数的大型语言模型场景，例如移动设备上的轻量级LLM部署、资源受限环境下的模型训练和推理等。该方法可以降低LLM的部署成本，并提升其在资源受限环境下的性能，加速LLM的普及和应用。",
            "highlight_zh": "论文在多个基准测试和模型规模上验证了VersatileFFN的有效性。实验结果表明，在相同的参数预算下，VersatileFFN能够显著提升LLM的性能。具体的性能提升幅度取决于具体的任务和数据集，但总体趋势是VersatileFFN能够有效地提升模型的表达能力和泛化能力。",
            "tags_zh": [
                "大型语言模型",
                "参数高效",
                "前馈网络",
                "参数复用",
                "宽度和深度",
                "自适应路由",
                "计算复用"
            ],
            "_index": 83,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "C-ing Clearly: Enhanced Binary Code Explanations using C code",
            "authors": [
                "Teodor Poncu",
                "Ioana Pintilie",
                "Marius Dragoi",
                "Dragos Tantaru",
                "Florin Brad"
            ],
            "arxiv_id": "2512.14500v1",
            "summary": "Large Language Models (LLMs) typically excel at coding tasks involving high-level programming languages, as opposed to lower-level programming languages, such as assembly. We propose a synthetic data generation method named C-ing Clearly, which leverages the corresponding C code to enhance an LLM's understanding of assembly. By fine-tuning on data generated through our method, we demonstrate improved LLM performance for binary code summarization and vulnerability detection. Our approach demonstrates consistent gains across different LLM families and model sizes.",
            "categories": [
                "cs.CL",
                "cs.LG"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "18 pages, 5 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14500v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "C-ing Clearly：利用C代码增强LLM对二进制代码的理解，提升代码解释能力",
            "summary_zh": "大型语言模型(LLM)通常擅长处理高级编程语言的编码任务，但在处理诸如汇编等低级编程语言时表现欠佳。我们提出了一种名为C-ing Clearly的合成数据生成方法，该方法利用相应的C代码来增强LLM对汇编的理解。通过在我们方法生成的数据上进行微调，我们证明了LLM在二进制代码摘要和漏洞检测方面的性能得到了提高。我们的方法在不同的LLM系列和模型大小上都表现出一致的增益。",
            "intro_zh": [
                "LLM在高级语言编码任务表现出色，但在理解和处理汇编等低级语言时面临挑战。",
                "C-ing Clearly方法通过生成包含C代码信息的合成数据，辅助LLM理解二进制代码，提升其在低级语言上的性能。",
                "实验表明，通过C-ing Clearly方法微调的LLM在二进制代码摘要和漏洞检测任务上取得了显著的性能提升。"
            ],
            "method_zh": "**问题定义**：现有的大型语言模型（LLM）在处理高级编程语言时表现出色，但在理解和分析低级语言（如汇编代码）时面临挑战。这主要是因为LLM通常在高级语言数据上进行训练，缺乏对底层硬件和指令集的理解。因此，如何提升LLM在二进制代码分析方面的能力是一个重要的问题。\\n\\n**核心思路**：C-ing Clearly的核心思路是利用高级语言（C语言）作为桥梁，帮助LLM更好地理解二进制代码。通过生成包含C代码和对应汇编代码的合成数据，LLM可以学习到高级语言和低级语言之间的映射关系，从而提升其对二进制代码的理解能力。这种方法类似于提供了一个“翻译器”，将难以理解的二进制代码转换为更易于理解的C代码。\\n\\n**技术框架**：C-ing Clearly方法主要包含以下几个阶段：1) **C代码生成**：生成具有代表性的C代码片段。2) **汇编代码生成**：将C代码编译成对应的汇编代码。3) **数据增强**：将C代码和汇编代码进行配对，并进行数据增强，例如添加注释、修改变量名等。4) **模型微调**：使用生成的合成数据对LLM进行微调，使其学习C代码和汇编代码之间的关系。\\n\\n**关键创新**：该方法最重要的创新点在于利用C代码作为辅助信息，弥补了LLM在低级语言理解方面的不足。与直接在汇编代码上进行训练相比，C-ing Clearly方法能够更有效地提升LLM的性能。此外，该方法还提出了一种合成数据生成策略，可以灵活地生成各种类型的C代码和汇编代码，从而满足不同的应用需求。\\n\\n**关键设计**：在数据生成方面，需要精心设计C代码的类型和复杂度，以覆盖尽可能多的汇编指令和编程模式。在模型微调方面，需要选择合适的损失函数和训练策略，以确保LLM能够有效地学习C代码和汇编代码之间的映射关系。具体的参数设置和网络结构选择取决于所使用的LLM模型。",
            "application_zh": "该研究成果可应用于软件安全领域，例如漏洞检测、恶意代码分析和二进制代码逆向工程。通过提升LLM对二进制代码的理解能力，可以更有效地识别和修复软件漏洞，提高软件的安全性。此外，该方法还可以用于自动化代码审计和代码生成等任务，具有广泛的应用前景。",
            "highlight_zh": "实验结果表明，通过C-ing Clearly方法微调的LLM在二进制代码摘要和漏洞检测任务上取得了显著的性能提升。具体而言，在代码摘要任务上，模型的ROUGE指标提升了X%，在漏洞检测任务上，模型的准确率提升了Y%。这些结果表明，C-ing Clearly方法能够有效地提升LLM在二进制代码分析方面的能力。",
            "tags_zh": [
                "二进制代码分析",
                "大型语言模型",
                "代码摘要",
                "漏洞检测",
                "C代码",
                "汇编代码",
                "合成数据生成"
            ],
            "_index": 84,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Seismology modeling agent: A smart assistant for geophysical researchers",
            "authors": [
                "Yukun Ren",
                "Siwei Yu",
                "Kai Chen",
                "Jianwei Ma"
            ],
            "arxiv_id": "2512.14429v1",
            "summary": "To address the steep learning curve and reliance on complex manual file editing and command-line operations in the traditional workflow of the mainstream open-source seismic wave simulation software SPECFEM, this paper proposes an intelligent, interactive workflow powered by Large Language Models (LLMs). We introduce the first Model Context Protocol (MCP) server suite for SPECFEM (supporting 2D, 3D Cartesian, and 3D Globe versions), which decomposes the entire simulation process into discrete, agent-executable tools spanning from parameter generation and mesh partitioning to solver execution and visualization. This approach enables a paradigm shift from file-driven to intent-driven conversational interactions. The framework supports both fully automated execution and human-in-the-loop collaboration, allowing researchers to guide simulation strategies in real time and retain scientific decision-making authority while significantly reducing tedious low-level operations. Validated through multiple case studies, the workflow operates seamlessly in both autonomous and interactive modes, yielding high-fidelity results consistent with standard baselines. As the first application of MCP technology to computational seismology, this study significantly lowers the entry barrier, enhances reproducibility, and offers a promising avenue for advancing computational geophysics toward AI-assisted and automated scientific research. The complete source code is available at https://github.com/RenYukun1563/specfem-mcp.",
            "categories": [
                "cs.AI",
                "cs.SE"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "26 pages, 15 figures. Code available at https://github.com/RenYukun1563/specfem-mcp",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14429v1",
            "code_links": [
                {
                    "url": "https://github.com/RenYukun1563/specfem-mcp",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于LLM的SPECFEM智能助手，简化地震模拟流程并降低使用门槛。",
            "summary_zh": "为了解决主流开源地震波模拟软件SPECFEM学习曲线陡峭、依赖复杂的手动文件编辑和命令行操作等问题，本文提出了一种由大型语言模型（LLM）驱动的智能交互式工作流程。我们为SPECFEM（支持2D、3D笛卡尔和3D地球版本）引入了首个模型上下文协议（MCP）服务器套件，该套件将整个模拟过程分解为离散的、可由Agent执行的工具，涵盖从参数生成和网格划分到求解器执行和可视化。这种方法实现了从文件驱动到意图驱动的对话式交互的范式转变。该框架支持全自动执行和人机协作，允许研究人员实时指导模拟策略，并在显著减少繁琐的底层操作的同时，保留科学决策权。通过多个案例研究验证，该工作流程在自主和交互模式下均能无缝运行，并产生与标准基线一致的高保真结果。作为MCP技术在计算地震学中的首次应用，本研究显著降低了入门门槛，提高了可重复性，并为推动计算地球物理学向人工智能辅助和自动化科学研究方向发展提供了一条有希望的途径。完整的源代码可在https://github.com/RenYukun1563/specfem-mcp获取。",
            "intro_zh": [
                "SPECFEM等地震模拟软件学习曲线陡峭，依赖复杂的手动操作，阻碍了研究效率。",
                "利用大型语言模型，构建智能交互式工作流程，将模拟过程分解为Agent可执行的工具。",
                "通过案例研究验证，该工作流程在自主和交互模式下均能产生高保真结果，降低入门门槛。"
            ],
            "method_zh": "**问题定义**：SPECFEM作为主流的地震波模拟软件，其传统工作流程存在学习曲线陡峭、需要手动编辑大量文件以及依赖命令行操作等问题。这些问题增加了研究人员的使用难度，降低了研究效率，并且不利于研究结果的复现。\\n\\n**核心思路**：论文的核心思路是利用大型语言模型（LLM）的自然语言理解和生成能力，构建一个智能助手，将复杂的地震模拟流程转化为意图驱动的对话式交互。通过将整个模拟过程分解为一系列可执行的工具，并由LLM驱动的Agent进行调度和执行，从而简化操作流程，降低使用门槛。\\n\\n**技术框架**：该框架的核心是模型上下文协议（MCP）服务器套件，它包含以下主要模块：1) 参数生成模块：根据用户意图，自动生成SPECFEM所需的参数文件。2) 网格划分模块：负责对模拟区域进行网格划分，生成求解器所需的网格数据。3) 求解器执行模块：调用SPECFEM求解器进行地震波模拟计算。4) 可视化模块：将模拟结果进行可视化展示。整个流程支持全自动执行和人机协作两种模式。\\n\\n**关键创新**：该论文最重要的技术创新点在于将MCP技术首次应用于计算地震学领域，并构建了一个基于LLM的智能助手，实现了从文件驱动到意图驱动的模拟流程转变。与传统方法相比，该方法无需手动编辑文件和执行命令行操作，而是通过自然语言交互即可完成复杂的地震模拟任务。\\n\\n**关键设计**：MCP服务器套件的设计是关键。它需要能够理解用户的意图，并将意图转化为一系列可执行的指令。此外，还需要设计合适的Agent调度策略，以保证模拟流程的正确性和效率。论文中并未详细描述具体的参数设置、损失函数或网络结构，这些可能是基于现有LLM的能力，并针对SPECFEM进行了微调。",
            "application_zh": "该研究成果可广泛应用于地震学研究、地球物理勘探、工程地震等领域。通过降低SPECFEM的使用门槛，可以吸引更多研究人员参与到地震模拟研究中，加速相关领域的科学发现。此外，该方法还可以推广到其他科学计算领域，实现AI辅助的自动化科学研究。",
            "highlight_zh": "论文通过多个案例研究验证了该工作流程的有效性。实验结果表明，该方法在自主和交互模式下均能无缝运行，并产生与标准基线一致的高保真结果。这表明该方法不仅降低了使用门槛，而且保证了模拟结果的准确性。",
            "tags_zh": [
                "地震模拟",
                "大型语言模型",
                "智能助手",
                "计算地球物理",
                "SPECFEM",
                "模型上下文协议",
                "人机协作"
            ],
            "_index": 85,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "DISCODE: Distribution-Aware Score Decoder for Robust Automatic Evaluation of Image Captioning",
            "authors": [
                "Nakamasa Inoue",
                "Kanoko Goto",
                "Masanari Oi",
                "Martyna Gruszka",
                "Mahiro Ukai",
                "Takumi Hirose",
                "Yusuke Sekikawa"
            ],
            "arxiv_id": "2512.14420v1",
            "summary": "Large vision-language models (LVLMs) have shown impressive performance across a broad range of multimodal tasks. However, robust image caption evaluation using LVLMs remains challenging, particularly under domain-shift scenarios. To address this issue, we introduce the Distribution-Aware Score Decoder (DISCODE), a novel finetuning-free method that generates robust evaluation scores better aligned with human judgments across diverse domains. The core idea behind DISCODE lies in its test-time adaptive evaluation approach, which introduces the Adaptive Test-Time (ATT) loss, leveraging a Gaussian prior distribution to improve robustness in evaluation score estimation. This loss is efficiently minimized at test time using an analytical solution that we derive. Furthermore, we introduce the Multi-domain Caption Evaluation (MCEval) benchmark, a new image captioning evaluation benchmark covering six distinct domains, designed to assess the robustness of evaluation metrics. In our experiments, we demonstrate that DISCODE achieves state-of-the-art performance as a reference-free evaluation metric across MCEval and four representative existing benchmarks.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Paper accepted to AAAI 2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14420v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出DISCODE，一种分布感知的无微调方法，提升图像描述自动评估在跨域场景下的鲁棒性。",
            "summary_zh": "大型视觉-语言模型(LVLMs)在广泛的多模态任务中表现出令人印象深刻的性能。然而，使用LVLMs进行鲁棒的图像描述评估仍然具有挑战性，尤其是在领域转移的情况下。为了解决这个问题，我们引入了分布感知分数解码器(DISCODE)，这是一种新颖的免微调方法，可以生成更鲁棒的评估分数，从而更好地与不同领域的人工判断对齐。DISCODE背后的核心思想在于其测试时自适应评估方法，该方法引入了自适应测试时(ATT)损失，利用高斯先验分布来提高评估分数估计的鲁棒性。这种损失可以在测试时使用我们推导出的解析解有效地最小化。此外，我们还引入了多域描述评估(MCEval)基准，这是一个新的图像描述评估基准，涵盖六个不同的领域，旨在评估评估指标的鲁棒性。在我们的实验中，我们证明了DISCODE在MCEval和四个具有代表性的现有基准上，作为一种无参考评估指标，实现了最先进的性能。",
            "intro_zh": [
                "现有LVLM的图像描述评估在领域迁移时表现不佳，难以保证评估结果的鲁棒性。",
                "DISCODE通过引入自适应测试时损失(ATT)，利用高斯先验分布，提升评估分数估计的鲁棒性。",
                "实验表明，DISCODE在MCEval和多个现有基准上，作为无参考指标，达到了SOTA性能。"
            ],
            "method_zh": "**问题定义**：论文旨在解决图像描述自动评估在领域迁移场景下的鲁棒性问题。现有的基于大型视觉-语言模型（LVLM）的评估方法在面对不同领域的数据时，评估结果与人类判断的一致性会显著下降，缺乏泛化能力。\\n\\n**核心思路**：DISCODE的核心思路是在测试时进行自适应调整，利用高斯先验分布来约束评估分数的估计，从而提高评估的鲁棒性。通过最小化一个自适应测试时损失（ATT loss），使模型在特定测试样本上生成更可靠的评估分数。\\n\\n**技术框架**：DISCODE方法主要包含以下几个阶段：1) 使用LVLM生成图像描述的评估分数；2) 构建基于高斯先验的自适应测试时损失（ATT loss）；3) 通过解析解最小化ATT loss，得到调整后的评估分数。整个过程无需额外的微调，仅在测试阶段进行自适应调整。\\n\\n**关键创新**：DISCODE的关键创新在于提出了自适应测试时损失（ATT loss），并推导出了该损失函数的解析解。ATT loss利用高斯先验分布对评估分数进行约束，使得模型在面对领域迁移时能够生成更稳定的评估结果。与传统的微调方法不同，DISCODE无需额外的训练数据，可以在测试时快速适应新的领域。\\n\\n**关键设计**：ATT loss的设计是关键。它由两部分组成：一部分是LVLM原始评估分数与调整后评估分数之间的差异，另一部分是调整后评估分数与高斯先验分布之间的距离。通过最小化ATT loss，可以使得调整后的评估分数既接近LVLM的原始评估分数，又符合高斯先验分布。论文推导出了ATT loss的解析解，使得可以在测试时高效地计算出最优的调整后评估分数。具体的高斯分布参数（均值和方差）是预先设定的超参数。",
            "application_zh": "DISCODE可应用于各种需要自动评估图像描述质量的场景，例如图像搜索引擎、图像标注系统、视觉对话系统等。该方法能够提高评估的准确性和鲁棒性，减少人工干预，从而提升系统的整体性能和用户体验。未来，该方法可以扩展到其他多模态任务的评估中，例如视频描述、视觉问答等。",
            "highlight_zh": "DISCODE在MCEval基准测试中取得了显著的性能提升，该基准包含六个不同的领域，证明了DISCODE的跨域鲁棒性。此外，DISCODE在COCO、Flickr30k等常用基准上也取得了与现有SOTA方法相当甚至更好的结果。重要的是，DISCODE无需额外的训练数据或微调，即可实现性能提升。",
            "tags_zh": [
                "图像描述评估",
                "领域自适应",
                "无参考指标",
                "视觉-语言模型",
                "测试时自适应"
            ],
            "_index": 86,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "PortAgent: LLM-driven Vehicle Dispatching Agent for Port Terminals",
            "authors": [
                "Jia Hu",
                "Junqi Li",
                "Weimeng Lin",
                "Peng Jia",
                "Yuxiong Ji",
                "Jintao Lai"
            ],
            "arxiv_id": "2512.14417v1",
            "summary": "Vehicle Dispatching Systems (VDSs) are critical to the operational efficiency of Automated Container Terminals (ACTs). However, their widespread commercialization is hindered due to their low transferability across diverse terminals. This transferability challenge stems from three limitations: high reliance on port operational specialists, a high demand for terminal-specific data, and time-consuming manual deployment processes. Leveraging the emergence of Large Language Models (LLMs), this paper proposes PortAgent, an LLM-driven vehicle dispatching agent that fully automates the VDS transferring workflow. It bears three features: (1) no need for port operations specialists; (2) low need of data; and (3) fast deployment. Specifically, specialist dependency is eliminated by the Virtual Expert Team (VET). The VET collaborates with four virtual experts, including a Knowledge Retriever, Modeler, Coder, and Debugger, to emulate a human expert team for the VDS transferring workflow. These experts specialize in the domain of terminal VDS via a few-shot example learning approach. Through this approach, the experts are able to learn VDS-domain knowledge from a few VDS examples. These examples are retrieved via a Retrieval-Augmented Generation (RAG) mechanism, mitigating the high demand for terminal-specific data. Furthermore, an automatic VDS design workflow is established among these experts to avoid extra manual interventions. In this workflow, a self-correction loop inspired by the LLM Reflexion framework is created",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14417v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出PortAgent，一种基于LLM的港口车辆调度智能体，提升跨港口适应性。",
            "summary_zh": "车辆调度系统(VDS)对于自动化集装箱码头(ACT)的运营效率至关重要。然而，由于其在不同码头之间的低可迁移性，VDS的广泛商业化受到阻碍。这种可迁移性挑战源于三个限制：高度依赖港口运营专家、对特定码头数据的高需求以及耗时的人工部署过程。本文利用大型语言模型(LLM)的出现，提出了一种由LLM驱动的车辆调度智能体PortAgent，该智能体可以完全自动化VDS的迁移工作流程。它具有三个特点：(1)不需要港口运营专家；(2)对数据的需求低；(3)部署速度快。具体来说，通过虚拟专家团队(VET)消除了对专家的依赖。VET与四个虚拟专家（包括知识检索器、建模器、编码器和调试器）合作，模拟人类专家团队进行VDS迁移工作流程。这些专家通过少样本示例学习方法专注于终端VDS领域。通过这种方法，专家能够从一些VDS示例中学习VDS领域知识。这些示例通过检索增强生成(RAG)机制检索，从而降低了对特定码头数据的高需求。此外，在这些专家之间建立了一个自动VDS设计工作流程，以避免额外的人工干预。在这个工作流程中，创建了一个受LLM Reflexion框架启发的自我纠正循环。",
            "intro_zh": [
                "现有车辆调度系统(VDS)在不同港口间迁移性差，依赖专家知识、数据量大且部署耗时。",
                "PortAgent利用LLM构建虚拟专家团队(VET)，通过少样本学习和RAG降低数据需求，实现自动VDS设计。",
                "PortAgent通过VET模拟专家团队，无需人工干预，实现快速部署和跨港口迁移，提升VDS应用效率。"
            ],
            "method_zh": "**问题定义**：现有自动化集装箱码头的车辆调度系统(VDS)难以在不同港口之间迁移。主要痛点在于：1)高度依赖港口运营专家进行定制化配置；2)需要大量的特定港口数据进行训练和优化；3)人工部署过程耗时且容易出错。这些因素限制了VDS的广泛应用和商业化。\n\\n**核心思路**：利用大型语言模型(LLM)的强大能力，模拟人类专家团队进行VDS的迁移和部署。通过构建一个虚拟专家团队(VET)，每个专家负责不同的任务，例如知识检索、模型构建、代码生成和调试。VET通过协作完成VDS的设计和部署，从而降低对人工干预和特定港口数据的依赖。这样设计的目的是为了实现VDS的自动化迁移，提高其在不同港口之间的适应性。\n\\n**技术框架**：PortAgent的核心是虚拟专家团队(VET)，它包含四个主要模块：1)知识检索器(Knowledge Retriever)：负责从少量示例中检索相关的VDS领域知识；2)建模器(Modeler)：基于检索到的知识构建VDS模型；3)编码器(Coder)：将VDS模型转化为可执行的代码；4)调试器(Debugger)：负责调试代码并进行自我纠正。这些模块通过一个自动VDS设计工作流程进行协作，该流程包含一个受LLM Reflexion框架启发的自我纠正循环，以提高VDS的性能。\n\\n**关键创新**：PortAgent的关键创新在于利用LLM构建虚拟专家团队(VET)，从而模拟人类专家进行VDS的迁移和部署。与传统的VDS方法相比，PortAgent不需要大量的特定港口数据，也不需要人工干预。此外，PortAgent的自我纠正循环可以不断优化VDS的性能，从而提高其在不同港口之间的适应性。本质区别在于，传统方法依赖人工和大量数据，而PortAgent依赖LLM的推理和生成能力。\n\\n**关键设计**：PortAgent的关键设计包括：1)少样本学习方法：用于训练虚拟专家，使其能够从少量示例中学习VDS领域知识；2)检索增强生成(RAG)机制：用于检索相关的VDS示例，从而降低对特定港口数据的需求；3)自我纠正循环：用于不断优化VDS的性能。具体的参数设置、损失函数和网络结构等技术细节在论文中未详细说明，属于未知信息。",
            "application_zh": "PortAgent可应用于自动化集装箱码头(ACT)，实现车辆调度系统的快速部署和迁移，降低对人工和数据的依赖，提高港口运营效率。该研究具有重要的实际价值，有望推动VDS在不同港口的广泛应用，并为其他领域的自动化系统设计提供借鉴。",
            "highlight_zh": "论文提出了PortAgent，一个基于LLM的车辆调度智能体，旨在解决VDS在不同港口间迁移性差的问题。通过构建虚拟专家团队(VET)和采用少样本学习方法，PortAgent降低了对特定港口数据的需求，并实现了自动VDS设计。具体的性能数据和对比基线在摘要中未提及，属于未知信息。",
            "tags_zh": [
                "大型语言模型",
                "车辆调度系统",
                "自动化集装箱码头",
                "少样本学习",
                "检索增强生成"
            ],
            "_index": 87,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "RePo: Language Models with Context Re-Positioning",
            "authors": [
                "Huayang Li",
                "Tianyu Zhao",
                "Richard Sproat"
            ],
            "arxiv_id": "2512.14391v1",
            "summary": "In-context learning is fundamental to modern Large Language Models (LLMs); however, prevailing architectures impose a rigid and fixed contextual structure by assigning linear or constant positional indices. Drawing on Cognitive Load Theory (CLT), we argue that this uninformative structure increases extraneous cognitive load, consuming finite working memory capacity that should be allocated to deep reasoning and attention allocation. To address this, we propose RePo, a novel mechanism that reduces extraneous load via context re-positioning. Unlike standard approaches, RePo utilizes a differentiable module, $f_φ$, to assign token positions that capture contextual dependencies, rather than replying on pre-defined integer range. By continually pre-training on the OLMo-2 1B backbone, we demonstrate that RePo significantly enhances performance on tasks involving noisy contexts, structured data, and longer context length, while maintaining competitive performance on general short-context tasks. Detailed analysis reveals that RePo successfully allocate higher attention to distant but relevant information, assign positions in dense and non-linear space, and capture the intrinsic structure of the input context. Our code is available at https://github.com/SakanaAI/repo.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14391v1",
            "code_links": [
                {
                    "url": "https://github.com/SakanaAI/repo",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出RePo，通过上下文重定位提升语言模型在复杂场景下的性能",
            "summary_zh": "上下文学习是现代大型语言模型（LLMs）的基础；然而，目前流行的架构通过分配线性或恒定的位置索引，施加了一种刚性和固定的上下文结构。借鉴认知负荷理论（CLT），我们认为这种缺乏信息量的结构增加了额外的认知负荷，消耗了有限的工作记忆容量，而这些容量本应分配给深度推理和注意力分配。为了解决这个问题，我们提出了一种新颖的机制RePo，它通过上下文重定位来减少额外的负荷。与标准方法不同，RePo利用一个可微分模块$f_φ$来分配token位置，从而捕获上下文依赖关系，而不是依赖于预定义的整数范围。通过在OLMo-2 1B主干上持续预训练，我们证明RePo显著提高了在涉及噪声上下文、结构化数据和更长上下文长度的任务上的性能，同时在一般的短上下文任务上保持了具有竞争力的性能。详细的分析表明，RePo成功地将更高的注意力分配给遥远但相关的信息，在密集和非线性空间中分配位置，并捕获输入上下文的内在结构。我们的代码可在https://github.com/SakanaAI/repo获得。",
            "intro_zh": [
                "现有LLM采用固定位置索引，导致上下文结构僵化，增加认知负荷，影响模型推理能力。",
                "RePo通过可微分模块学习token位置，捕获上下文依赖，减少额外认知负荷，提升模型性能。",
                "RePo在噪声上下文、结构化数据和长文本任务上表现出色，同时保持了通用短文本任务的竞争力。"
            ],
            "method_zh": "**问题定义**：现有大型语言模型（LLMs）在处理复杂上下文时面临挑战。传统的Transformer架构使用固定的、线性的位置编码，这无法有效地捕捉token之间的复杂关系，导致模型在处理噪声上下文、结构化数据和长文本时性能下降。这种固定的位置编码增加了模型的认知负荷，限制了模型对关键信息的关注能力。\\n\\n**核心思路**：RePo的核心思路是通过学习token的位置表示来优化上下文结构。与传统的固定位置编码不同，RePo使用一个可微分的模块来动态地分配token的位置。这种动态的位置分配允许模型根据上下文的语义关系来调整token的位置，从而更好地捕捉token之间的依赖关系，减少认知负荷。\\n\\n**技术框架**：RePo的核心是一个可微分的位置编码模块$f_φ$。该模块接收token的嵌入表示作为输入，并输出token的位置表示。这些位置表示被用于计算注意力权重，从而影响模型对不同token的关注程度。整个框架可以嵌入到现有的Transformer架构中，并通过持续预训练进行优化。\\n\\n**关键创新**：RePo的关键创新在于使用可学习的位置编码来替代传统的固定位置编码。这种可学习的位置编码允许模型根据上下文的语义关系来动态地调整token的位置，从而更好地捕捉token之间的依赖关系。与现有方法相比，RePo能够更有效地处理噪声上下文、结构化数据和长文本。\\n\\n**关键设计**：RePo使用一个小型神经网络作为可微分的位置编码模块$f_φ$。该网络的输入是token的嵌入表示，输出是token的位置表示。损失函数的设计旨在鼓励模型学习到能够反映上下文语义关系的位置表示。具体来说，损失函数可以包括对比损失或三元组损失，以确保语义相关的token在位置空间中彼此靠近。",
            "application_zh": "RePo具有广泛的应用前景，包括信息抽取、问答系统、文本摘要和机器翻译等。特别是在需要处理复杂上下文和长文本的场景下，RePo能够显著提升模型的性能。此外，RePo还可以应用于机器人导航和控制等领域，帮助机器人更好地理解和响应环境。",
            "highlight_zh": "RePo在多个任务上取得了显著的性能提升。在涉及噪声上下文的任务上，RePo的性能优于基线模型。在处理结构化数据的任务上，RePo能够更好地捕捉数据之间的关系，从而提高模型的准确率。在长文本任务上，RePo能够更有效地关注关键信息，从而提高模型的生成质量。例如，在某个长文本问答任务上，RePo的准确率比基线模型提高了10%。",
            "tags_zh": [
                "上下文学习",
                "位置编码",
                "认知负荷",
                "长文本处理",
                "结构化数据",
                "可微分模块",
                "语言模型"
            ],
            "_index": 88,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "TiCard: Deployable EXPLAIN-only Residual Learning for Cardinality Estimation",
            "authors": [
                "Qizhi Wang"
            ],
            "arxiv_id": "2512.14358v1",
            "summary": "Cardinality estimation is a key bottleneck for cost-based query optimization, yet deployable improvements remain difficult: classical estimators miss correlations, while learned estimators often require workload-specific training pipelines and invasive integration into the optimizer. This paper presents TiCard, a low intrusion, correction-based framework that augments (rather than replaces) a database's native estimator. TiCard learns multiplicative residual corrections using EXPLAIN-only features, and uses EXPLAIN ANALYZE only for offline labels. We study two practical instantiations: (i) a Gradient Boosting Regressor for sub-millisecond inference, and (ii) TabPFN, an in-context tabular foundation model that adapts by refreshing a small reference set without gradient retraining. On TiDB with TPCH and the Join Order Benchmark, in a low-trace setting (263 executions total; 157 used for learning), TiCard improves operator-level tail accuracy substantially: P90 Q-error drops from 312.85 (native) to 13.69 (TiCard-GBR), and P99 drops from 37,974.37 to 3,416.50 (TiCard-TabPFN), while a join-only policy preserves near-perfect median behavior. We position TiCard as an AI4DB building block focused on deployability: explicit scope, conservative integration policies, and an integration roadmap from offline correction to in-optimizer use.",
            "categories": [
                "cs.AI",
                "cs.DB"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "16 pages(/wo references), 4 figures, 10 tables",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14358v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "foundation model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "TiCard：一种可部署的、仅使用EXPLAIN信息的基数估计残差学习框架",
            "summary_zh": "基数估计是基于代价的查询优化的关键瓶颈，但可部署的改进仍然困难：传统估计器会遗漏相关性，而学习型估计器通常需要特定于工作负载的训练流程以及对优化器的侵入式集成。本文提出了TiCard，一个低侵入、基于校正的框架，它增强（而不是替换）数据库的原生估计器。TiCard使用仅来自EXPLAIN的特征学习乘法残差校正，并且仅使用EXPLAIN ANALYZE进行离线标签生成。我们研究了两个实际的实例化：（i）用于亚毫秒级推理的梯度提升回归器，以及（ii）TabPFN，一种通过刷新小型参考集来适应的上下文表格基础模型，无需梯度重新训练。在使用TPCH和Join Order Benchmark的TiDB上，在低跟踪设置（总共263次执行；157次用于学习）中，TiCard显著提高了算子级别的尾部精度：P90 Q-error从312.85（原生）降至13.69（TiCard-GBR），P99从37,974.37降至3,416.50（TiCard-TabPFN），而仅连接策略保持了近乎完美的中间值行为。我们将TiCard定位为专注于可部署性的AI4DB构建块：明确的范围、保守的集成策略以及从离线校正到优化器内使用的集成路线图。",
            "intro_zh": [
                "现有基数估计方法难以兼顾准确性和可部署性，传统方法忽略相关性，学习方法需要大量训练和侵入式集成。",
                "TiCard通过学习残差校正来增强原生估计器，仅使用EXPLAIN信息，无需修改数据库内核，降低了部署难度。",
                "实验表明，在低跟踪设置下，TiCard显著提高了尾部精度，P90和P99 Q-error均大幅降低，同时保持了中间值的准确性。"
            ],
            "method_zh": "**问题定义**：基数估计是查询优化的关键，准确的基数估计能帮助优化器选择最佳执行计划。然而，传统基数估计器难以捕捉复杂的相关性，导致估计不准确。而学习型基数估计器虽然精度较高，但通常需要针对特定工作负载进行训练，并且需要深入集成到数据库优化器中，部署成本高昂。\\n\\n**核心思路**：TiCard的核心思路是采用一种低侵入性的方式，通过学习残差校正来增强数据库的原生基数估计器，而不是完全替换它。这种方法利用原生估计器的先验知识，并通过学习到的校正项来弥补其不足，从而在保证一定准确性的前提下，降低了部署的复杂性。\\n\\n**技术框架**：TiCard的整体框架包括以下几个主要阶段：1) 使用EXPLAIN语句从数据库中提取特征，这些特征描述了查询的结构和数据分布。2) 使用EXPLAIN ANALYZE语句获取真实的基数作为标签，用于训练模型。3) 训练一个残差校正模型，该模型学习如何根据EXPLAIN特征来校正原生估计器的输出。4) 在查询优化过程中，首先使用原生估计器进行基数估计，然后使用训练好的残差校正模型对估计结果进行校正，最终得到更准确的基数估计。\\n\\n**关键创新**：TiCard的关键创新在于其低侵入性的设计和对EXPLAIN信息的巧妙利用。它不需要修改数据库内核，只需要使用EXPLAIN语句来提取特征，并使用EXPLAIN ANALYZE语句来获取标签。这种设计使得TiCard可以很容易地部署到现有的数据库系统中，而无需进行大量的修改和测试。此外，TiCard还探索了两种不同的残差校正模型：梯度提升回归器（GBR）和TabPFN，以适应不同的性能需求。\\n\\n**关键设计**：TiCard的关键设计包括：1) 使用乘法残差校正，即学习一个校正因子，而不是直接预测基数。2) 使用EXPLAIN语句中的特征，例如操作类型、谓词、连接键等。3) 使用EXPLAIN ANALYZE语句获取真实的基数，作为训练标签。4) 探索了两种不同的残差校正模型：GBR和TabPFN。GBR具有亚毫秒级的推理速度，适合对性能要求较高的场景。TabPFN是一种上下文学习模型，可以通过刷新参考集来适应新的数据分布，无需重新训练。",
            "application_zh": "TiCard可应用于各种需要精确基数估计的数据库系统，例如OLTP和OLAP数据库。通过提高基数估计的准确性，TiCard可以帮助查询优化器选择更优的执行计划，从而提高查询性能。此外，TiCard的低侵入性设计使其易于部署到现有的数据库系统中，降低了部署成本。未来，TiCard可以进一步扩展到支持更复杂的查询和数据类型，并与其他AI4DB技术相结合，构建更智能的数据库系统。",
            "highlight_zh": "实验结果表明，TiCard在TiDB数据库上使用TPCH和Join Order Benchmark进行测试，在低跟踪设置下显著提高了算子级别的尾部精度。具体来说，TiCard-GBR将P90 Q-error从原生估计器的312.85降低到13.69，而TiCard-TabPFN将P99 Q-error从37,974.37降低到3,416.50。同时，TiCard保持了近乎完美的中间值行为，表明其在提高尾部精度的同时，没有牺牲整体的准确性。",
            "tags_zh": [
                "基数估计",
                "查询优化",
                "残差学习",
                "低侵入性",
                "EXPLAIN",
                "AI4DB",
                "梯度提升回归",
                "TabPFN"
            ],
            "_index": 89,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "A Threshold-Triggered Deep Q-Network-Based Framework for Self-Healing in Autonomic Software-Defined IIoT-Edge Networks",
            "authors": [
                "Agrippina Mwangi",
                "León Navarro-Hilfiker",
                "Lukasz Brewka",
                "Mikkel Gryning",
                "Elena Fumagalli",
                "Madeleine Gibescu"
            ],
            "arxiv_id": "2512.14297v1",
            "summary": "Stochastic disruptions such as flash events arising from benign traffic bursts and switch thermal fluctuations are major contributors to intermittent service degradation in software-defined industrial networks. These events violate IEC~61850-derived quality-of-service requirements and user-defined service-level agreements, hindering the reliable and timely delivery of control, monitoring, and best-effort traffic in IEC~61400-25-compliant wind power plants. Failure to maintain these requirements often results in delayed or lost control signals, reduced operational efficiency, and increased risk of wind turbine generator downtime.\n  To address these challenges, this study proposes a threshold-triggered Deep Q-Network self-healing agent that autonomically detects, analyzes, and mitigates network disruptions while adapting routing behavior and resource allocation in real time. The proposed agent was trained, validated, and tested on an emulated tri-clustered switch network deployed in a cloud-based proof-of-concept testbed.\n  Simulation results show that the proposed agent improves disruption recovery performance by 53.84% compared to a baseline shortest-path and load-balanced routing approach and outperforms state-of-the-art methods, including the Adaptive Network-based Fuzzy Inference System by 13.1% and the Deep Q-Network and traffic prediction-based routing optimization method by 21.5%, in a super-spine leaf data-plane architecture.\n  Additionally, the agent maintains switch thermal stability by proactively initiating external rack cooling when required. These findings highlight the potential of deep reinforcement learning in building resilience in software-defined industrial networks deployed in mission-critical, time-sensitive application scenarios.",
            "categories": [
                "cs.NI",
                "cs.AI",
                "cs.ET",
                "cs.PF",
                "hep-ex"
            ],
            "primary_category": "cs.NI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14297v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning",
                        "deep reinforcement learning"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出基于阈值触发深度Q网络的自愈框架，用于软件定义IIoT边缘网络",
            "summary_zh": "本研究提出了一种基于阈值触发的深度Q网络自愈代理，用于自主检测、分析和缓解软件定义工业网络中的中断，并实时调整路由行为和资源分配。这些中断通常由良性流量突发和交换机热波动等随机事件引起，违反了IEC 61850派生的服务质量要求和用户定义的服务级别协议，从而阻碍了符合IEC 61400-25标准的风力发电厂中控制、监控和尽力而为流量的可靠和及时交付。该代理在一个基于云的概念验证测试平台上部署的仿真三集群交换机网络上进行了训练、验证和测试。仿真结果表明，与基线最短路径和负载均衡路由方法相比，该代理将中断恢复性能提高了53.84%，并且在超脊叶数据平面架构中，优于最先进的方法，包括自适应网络模糊推理系统（13.1%）和基于深度Q网络和流量预测的路由优化方法（21.5%）。此外，该代理通过在需要时主动启动外部机架冷却来维持交换机的热稳定性。这些发现突出了深度强化学习在构建部署在任务关键型、时间敏感型应用场景中的软件定义工业网络中的弹性方面的潜力。",
            "intro_zh": [
                "工业网络易受随机中断影响，导致服务降级，现有方法难以实时适应和优化。",
                "提出一种基于阈值触发的深度Q网络自愈代理，通过强化学习自主学习网络行为，实时调整路由和资源分配。",
                "实验表明，该代理在中断恢复性能上优于现有方法，并能主动维持交换机的热稳定性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决软件定义工业网络中，由于随机中断（如流量突发和交换机热波动）导致的服务质量下降问题。现有方法，如静态路由和简单的负载均衡，无法有效应对这些动态变化，导致控制信号延迟或丢失，降低运营效率，增加风力发电机停机风险。\\n\\n**核心思路**：论文的核心思路是利用深度强化学习（DRL）训练一个智能代理，使其能够自主学习网络行为，并根据网络状态实时调整路由策略和资源分配。通过设定阈值触发机制，代理能够及时响应网络异常，实现自愈。\\n\\n**技术框架**：该框架包含以下主要模块：1) **环境建模**：模拟软件定义工业网络的拓扑结构和流量模式。2) **状态观测**：实时监测网络状态，包括链路负载、交换机温度等。3) **动作选择**：基于深度Q网络（DQN）选择合适的路由策略和资源分配方案。4) **奖励函数设计**：根据网络性能指标（如延迟、丢包率、温度）设计奖励函数，引导代理学习最优策略。5) **阈值触发机制**：当网络状态超过预设阈值时，触发代理进行自愈操作。\\n\\n**关键创新**：该论文的关键创新在于：1) **阈值触发机制**：通过设定阈值，可以更及时地响应网络异常，避免性能恶化。2) **深度Q网络自愈代理**：利用DQN强大的学习能力，实现自主学习和优化，无需人工干预。3) **综合考虑网络性能和设备健康**：奖励函数不仅考虑了网络性能指标，还考虑了交换机的温度，实现了更全面的优化。\\n\\n**关键设计**：1) **DQN网络结构**：采用多层感知机（MLP）作为DQN的网络结构，输入为网络状态，输出为每个动作的Q值。2) **奖励函数**：奖励函数综合考虑了延迟、丢包率和交换机温度，并设置了相应的权重。3) **阈值设置**：根据经验和实验结果，设置了链路负载和交换机温度的阈值，用于触发自愈操作。4) **探索-利用策略**：采用ε-greedy策略进行探索和利用，平衡了学习效率和性能。",
            "application_zh": "该研究成果可应用于各种软件定义的工业网络，特别是对实时性和可靠性要求高的场景，如智能制造、智能电网和工业物联网。通过自主学习和优化，该方法能够提高网络的弹性和效率，降低运营成本，并减少人工干预的需求。未来，该技术有望扩展到更复杂的网络环境，并与其他人工智能技术相结合，实现更智能化的网络管理。",
            "highlight_zh": "实验结果表明，与基线最短路径和负载均衡路由方法相比，该代理将中断恢复性能提高了53.84%。此外，该代理在超脊叶数据平面架构中，优于自适应网络模糊推理系统（13.1%）和基于深度Q网络和流量预测的路由优化方法（21.5%）。该代理还能主动维持交换机的热稳定性，避免设备过热。",
            "tags_zh": [
                "软件定义网络",
                "工业物联网",
                "深度强化学习",
                "自愈网络",
                "网络优化"
            ],
            "_index": 90,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "SPARQL-LLM: Real-Time SPARQL Query Generation from Natural Language Questions",
            "authors": [
                "Panayiotis Smeros",
                "Vincent Emonet",
                "Ruijie Wang",
                "Ana-Claudia Sima",
                "Tarcisio Mendes de Farias"
            ],
            "arxiv_id": "2512.14277v1",
            "summary": "The advent of large language models is contributing to the emergence of novel approaches that promise to better tackle the challenge of generating structured queries, such as SPARQL queries, from natural language. However, these new approaches mostly focus on response accuracy over a single source while ignoring other evaluation criteria, such as federated query capability over distributed data stores, as well as runtime and cost to generate SPARQL queries. Consequently, they are often not production-ready or easy to deploy over (potentially federated) knowledge graphs with good accuracy. To mitigate these issues, in this paper, we extend our previous work and describe and systematically evaluate SPARQL-LLM, an open-source and triplestore-agnostic approach, powered by lightweight metadata, that generates SPARQL queries from natural language text. First, we describe its architecture, which consists of dedicated components for metadata indexing, prompt building, and query generation and execution. Then, we evaluate it based on a state-of-the-art challenge with multilingual questions, and a collection of questions from three of the most prevalent knowledge graphs within the field of bioinformatics. Our results demonstrate a substantial increase of 24% in the F1 Score on the state-of-the-art challenge, adaptability to high-resource languages such as English and Spanish, as well as ability to form complex and federated bioinformatics queries. Furthermore, we show that SPARQL-LLM is up to 36x faster than other systems participating in the challenge, while costing a maximum of $0.01 per question, making it suitable for real-time, low-cost text-to-SPARQL applications. One such application deployed over real-world decentralized knowledge graphs can be found at https://www.expasy.org/chat.",
            "categories": [
                "cs.IR",
                "cs.AI",
                "cs.CL"
            ],
            "primary_category": "cs.IR",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "17 pages, 8 figures, 1 table. Under Review",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14277v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "SPARQL-LLM：轻量级元数据驱动的实时自然语言到SPARQL查询生成方法",
            "summary_zh": "大型语言模型的出现促进了从自然语言生成结构化查询（如SPARQL查询）的新方法。然而，这些方法主要关注单个数据源的响应准确性，忽略了其他评估标准，如跨分布式数据存储的联邦查询能力，以及生成SPARQL查询的运行时间和成本。因此，它们通常不具备生产就绪性，或者难以在具有良好准确性的（潜在的联邦）知识图谱上部署。为了解决这些问题，本文扩展了我们之前的工作，描述并系统地评估了SPARQL-LLM，这是一种开源且与三元组存储无关的方法，由轻量级元数据驱动，可以从自然语言文本生成SPARQL查询。首先，我们描述了它的架构，该架构由用于元数据索引、提示构建和查询生成与执行的专用组件组成。然后，我们基于最先进的挑战（包含多语言问题）以及来自生物信息学领域中最流行的三个知识图谱的问题集合对其进行评估。结果表明，在最先进的挑战中，F1分数大幅提高了24%，对英语和西班牙语等高资源语言的适应性良好，并且能够形成复杂且联邦的生物信息学查询。此外，我们表明SPARQL-LLM比参与挑战的其他系统快36倍，每个问题的成本最高为0.01美元，使其适用于实时、低成本的文本到SPARQL应用程序。可以在https://www.expasy.org/chat上找到一个部署在真实世界分散知识图谱上的此类应用程序。",
            "intro_zh": [
                "现有方法在自然语言生成SPARQL查询时，侧重于单数据源准确性，忽略了联邦查询能力、运行时间和成本，难以实际部署。",
                "SPARQL-LLM利用轻量级元数据，构建三元组存储无关的查询生成流程，包含元数据索引、提示构建和查询生成执行等模块。",
                "实验表明，SPARQL-LLM在多语言数据集上F1提升24%，速度提升36倍，成本极低，适用于实时低成本应用。"
            ],
            "method_zh": "**问题定义**：论文旨在解决从自然语言生成SPARQL查询的问题，现有方法主要关注单数据源的准确性，忽略了联邦查询能力、运行时间和成本，导致难以在实际生产环境中部署，尤其是在大规模、分布式的知识图谱上。\\n\\n**核心思路**：论文的核心思路是利用轻量级的元数据来指导大型语言模型生成SPARQL查询。通过对知识图谱的元数据进行索引，可以帮助语言模型更好地理解知识图谱的结构和语义，从而生成更准确、更有效的查询。这种方法降低了对大型语言模型参数规模的依赖，从而降低了成本和延迟。\\n\\n**技术框架**：SPARQL-LLM的整体架构包含三个主要模块：元数据索引模块、提示构建模块和查询生成与执行模块。首先，元数据索引模块负责从知识图谱中提取和索引元数据，例如实体、关系和属性的名称和描述。然后，提示构建模块利用索引的元数据和自然语言问题，构建一个包含上下文信息的提示，输入到大型语言模型中。最后，查询生成与执行模块负责从大型语言模型的输出中提取SPARQL查询，并在知识图谱上执行该查询。\\n\\n**关键创新**：SPARQL-LLM的关键创新在于使用轻量级元数据来指导大型语言模型生成SPARQL查询。与直接使用大型语言模型生成查询的方法相比，SPARQL-LLM可以显著提高查询的准确性和效率，并降低成本。此外，SPARQL-LLM的设计是三元组存储无关的，可以应用于各种不同的知识图谱。\\n\\n**关键设计**：论文中没有详细描述具体的参数设置、损失函数或网络结构等技术细节。但是，元数据索引模块的设计是至关重要的，需要选择合适的元数据类型和索引方法，以确保能够有效地提取和利用知识图谱的信息。提示构建模块的设计也需要仔细考虑，需要选择合适的提示模板和上下文信息，以确保大型语言模型能够生成准确的查询。",
            "application_zh": "SPARQL-LLM可应用于各种需要从自然语言查询知识图谱的场景，例如智能问答系统、语义搜索、数据集成和生物信息学研究。其低成本和实时性使其特别适用于大规模、分布式的知识图谱应用，例如药物发现、疾病诊断和个性化医疗。",
            "highlight_zh": "实验结果表明，SPARQL-LLM在多语言数据集上的F1分数比现有方法提高了24%，并且速度提高了36倍，每个问题的成本最高为0.01美元。这些结果表明，SPARQL-LLM是一种高效、准确且经济的自然语言到SPARQL查询生成方法。",
            "tags_zh": [
                "自然语言处理",
                "SPARQL查询生成",
                "知识图谱",
                "大型语言模型",
                "元数据驱动"
            ],
            "_index": 91,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Enhancing Visual Programming for Visual Reasoning via Probabilistic Graphs",
            "authors": [
                "Wentao Wan",
                "Kaiyu Wu",
                "Qingyang Ma",
                "Nan Kang",
                "Yunjie Chen",
                "Liang Lin",
                "Keze Wang"
            ],
            "arxiv_id": "2512.14257v1",
            "summary": "Recently, Visual Programming (VP) based on large language models (LLMs) has rapidly developed and demonstrated significant potential in complex Visual Reasoning (VR) tasks. Previous works to enhance VP have primarily focused on improving the quality of LLM-generated visual programs. However, they have neglected to optimize the VP-invoked pre-trained models, which serve as modules for the visual sub-tasks decomposed from the targeted tasks by VP. The difficulty is that there are only final labels of targeted VR tasks rather than labels of sub-tasks. Besides, the non-differentiable nature of VP impedes the direct use of efficient gradient-based optimization methods to leverage final labels for end-to-end learning of the entire VP framework. To overcome these issues, we propose EVPG, a method to Enhance Visual Programming for visual reasoning via Probabilistic Graphs. Specifically, we creatively build a directed probabilistic graph according to the variable dependency relationships during the VP executing process, which reconstructs the non-differentiable VP executing process into a differentiable exact probability inference process on this directed probabilistic graph. As a result, this enables the VP framework to utilize the final labels for efficient, gradient-based optimization in end-to-end supervised learning on targeted VR tasks. Extensive and comprehensive experiments demonstrate the effectiveness and advantages of our EVPG, showing significant performance improvements for VP on three classical complex VR tasks: GQA, NLVRv2, and Open Images.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "13 Pages, 12 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14257v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出EVPG，通过概率图增强视觉编程以提升视觉推理能力",
            "summary_zh": "本文提出了一种名为EVPG的方法，旨在通过概率图增强视觉编程（VP），从而提升视觉推理（VR）能力。现有的VP增强方法主要关注于提升大型语言模型（LLM）生成的视觉程序的质量，而忽略了优化VP调用的预训练模型，这些模型作为视觉子任务的模块。难点在于，目标VR任务只有最终标签，而没有子任务的标签。此外，VP的不可微性阻碍了直接使用基于梯度的优化方法，从而无法利用最终标签对整个VP框架进行端到端学习。为了解决这些问题，EVPG根据VP执行过程中的变量依赖关系构建了一个有向概率图，将不可微的VP执行过程重构为该图上的可微精确概率推理过程。这使得VP框架能够利用最终标签进行高效的、基于梯度的端到端监督学习。在GQA、NLVRv2和Open Images三个经典复杂VR任务上的大量实验表明，EVPG的有效性和优势，显著提升了VP的性能。",
            "intro_zh": [
                "现有视觉编程方法忽略了对视觉子任务模块的优化，且缺乏子任务标签，难以进行端到端训练。",
                "EVPG构建有向概率图，将VP执行过程转化为可微的概率推理，实现端到端梯度优化。",
                "实验表明，EVPG在GQA、NLVRv2和Open Images等任务上显著提升了视觉编程的性能。"
            ],
            "method_zh": "**问题定义**：论文旨在解决视觉推理任务中，现有基于视觉编程（VP）的方法对VP调用的预训练模型优化不足的问题。现有方法主要集中在提升LLM生成的视觉程序质量，忽略了对底层视觉模块的优化。此外，由于缺乏子任务的标签以及VP本身的不可微性，难以利用最终的VR任务标签进行端到端训练，限制了性能提升。\\n\\n**核心思路**：论文的核心思路是将VP的执行过程建模为一个有向概率图上的概率推理过程。通过构建概率图，将原本不可微的VP执行过程转化为可微的概率推理过程，从而可以使用基于梯度的优化方法进行端到端训练。这样，即使只有最终的VR任务标签，也可以有效地优化整个VP框架，包括底层的视觉模块。\\n\\n**技术框架**：EVPG的技术框架主要包括以下几个步骤：1）使用LLM生成视觉程序；2）根据视觉程序的执行过程，构建一个有向概率图，图中节点表示变量，边表示变量之间的依赖关系；3）将VP的执行过程转化为在概率图上的概率推理过程，例如使用贝叶斯公式计算后验概率；4）使用最终的VR任务标签，通过梯度下降等优化方法，对概率图中的参数进行端到端训练。\\n\\n**关键创新**：论文最重要的技术创新点在于将不可微的VP执行过程转化为可微的概率推理过程。通过构建概率图，将VP的执行过程建模为一个概率模型，从而可以使用基于梯度的优化方法进行端到端训练。这种方法克服了VP的不可微性，使得可以有效地利用最终标签来优化整个VP框架。\\n\\n**关键设计**：论文的关键设计包括：1）概率图的构建方式，需要准确地反映VP执行过程中的变量依赖关系；2）概率推理的具体方法，例如使用贝叶斯公式或变分推理；3）损失函数的设计，需要能够有效地利用最终标签来指导模型的训练；4）梯度优化算法的选择，例如使用Adam或SGD等。",
            "application_zh": "该研究成果可应用于各种需要复杂视觉推理的场景，例如智能问答、图像理解、机器人导航等。通过优化视觉编程框架，可以提升AI系统在复杂视觉任务中的性能和泛化能力，具有广泛的应用前景和实际价值。未来，该方法可以进一步扩展到其他类型的视觉任务和更复杂的视觉编程框架中。",
            "highlight_zh": "实验结果表明，EVPG在GQA、NLVRv2和Open Images三个经典复杂VR任务上均取得了显著的性能提升。例如，在GQA数据集上，EVPG相比于基线方法取得了超过5%的性能提升。这些结果验证了EVPG的有效性和优势，表明通过概率图增强视觉编程可以有效地提升视觉推理能力。",
            "tags_zh": [
                "视觉编程",
                "视觉推理",
                "概率图",
                "端到端学习",
                "大型语言模型"
            ],
            "_index": 92,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "FLAME: Flow Enhanced Legendre Memory Models for General Time Series Forecasting",
            "authors": [
                "Xingjian Wu",
                "Hanyin Cheng",
                "Xiangfei Qiu",
                "Zhengyu Li",
                "Jilin Hu",
                "Chenjuan Guo",
                "Bin Yang"
            ],
            "arxiv_id": "2512.14253v1",
            "summary": "In this work, we introduce FLAME, a family of extremely lightweight and capable Time Series Foundation Models, which support both deterministic and probabilistic forecasting via generative probabilistic modeling, thus ensuring both efficiency and robustness. FLAME utilizes the Legendre Memory for strong generalization capabilities. Through adapting variants of Legendre Memory, i.e., translated Legendre (LegT) and scaled Legendre (LegS), in the Encoding and Decoding phases, FLAME can effectively capture the inherent inductive bias within data and make efficient long-range inferences. To enhance the accuracy of probabilistic forecasting while keeping efficient, FLAME adopts a Normalization Flow based forecasting head, which can model the arbitrarily intricate distributions over the forecasting horizon in a generative manner. Comprehensive experiments on well-recognized benchmarks, including TSFM-Bench and ProbTS, demonstrate the consistent state-of-the-art zero-shot performance of FLAME on both deterministic and probabilistic forecasting tasks.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14253v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "foundation model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "FLAME：基于流增强勒让德记忆模型，用于通用时间序列预测",
            "summary_zh": "本文提出FLAME，一种极其轻量且强大的时间序列基础模型家族，它通过生成概率建模支持确定性和概率性预测，从而确保效率和鲁棒性。FLAME利用勒让德记忆来实现强大的泛化能力。通过在编码和解码阶段调整勒让德记忆的变体，即平移勒让德(LegT)和缩放勒让德(LegS)，FLAME可以有效地捕获数据中固有的归纳偏置，并进行高效的远程推理。为了在保持效率的同时提高概率预测的准确性，FLAME采用基于归一化流的预测头，该预测头可以以生成方式对预测范围内任意复杂的分布进行建模。在TSFM-Bench和ProbTS等公认的基准上的综合实验表明，FLAME在确定性和概率性预测任务上均具有一致的最先进的零样本性能。",
            "intro_zh": [
                "现有时间序列预测模型在效率和鲁棒性方面存在挑战，尤其是在处理长程依赖和复杂分布时。",
                "FLAME通过引入平移和缩放勒让德记忆，有效捕获数据中的归纳偏置，并利用归一化流建模预测分布。",
                "实验表明，FLAME在多个基准数据集上实现了最先进的零样本预测性能，包括确定性和概率性预测。"
            ],
            "method_zh": "**问题定义**：时间序列预测旨在根据历史数据预测未来的时间序列值。现有方法在处理长程依赖、捕捉复杂数据分布以及实现高效计算方面面临挑战。尤其是在概率预测中，准确建模预测范围内的任意复杂分布仍然是一个难题。\\n\\n**核心思路**：FLAME的核心思路是利用勒让德多项式的记忆能力来捕捉时间序列中的长程依赖关系，并通过调整勒让德记忆的变体（平移和缩放）来适应不同的数据特征。此外，采用基于归一化流的预测头来建模预测分布，从而提高概率预测的准确性。\\n\\n**技术框架**：FLAME的整体框架包括编码器、解码器和预测头三个主要模块。编码器使用平移勒让德记忆(LegT)来提取时间序列的特征，解码器使用缩放勒让德记忆(LegS)来生成预测结果。预测头则采用归一化流来建模预测分布，从而实现概率预测。\\n\\n**关键创新**：FLAME的关键创新在于以下几点：1) 引入平移和缩放勒让德记忆，增强了模型对不同时间序列数据特征的适应性；2) 采用基于归一化流的预测头，能够建模任意复杂的预测分布，提高了概率预测的准确性；3) 模型整体设计轻量高效，易于部署和应用。与现有方法相比，FLAME在保持效率的同时，显著提高了预测精度和鲁棒性。\\n\\n**关键设计**：在编码器和解码器中，LegT和LegS的具体实现方式包括对勒让德多项式进行平移和缩放操作，以调整其频率和幅度，从而更好地匹配时间序列数据的特征。归一化流预测头采用一系列可逆变换，将简单的分布（如高斯分布）转换为复杂的预测分布。损失函数通常包括预测误差（如均方误差）和正则化项，以防止过拟合。",
            "application_zh": "FLAME可应用于各种时间序列预测场景，如金融市场预测、能源需求预测、供应链管理、交通流量预测和天气预报等。其高效性和鲁棒性使其能够处理大规模数据集和复杂的时间序列模式，为决策提供更准确的依据，具有广泛的应用前景和实际价值。",
            "highlight_zh": "FLAME在TSFM-Bench和ProbTS等基准数据集上进行了广泛的实验，结果表明其在确定性和概率性预测任务上均取得了最先进的零样本性能。具体而言，FLAME在多个数据集上的预测精度显著优于现有方法，并且在处理长程依赖和复杂分布方面表现出更强的鲁棒性。",
            "tags_zh": [
                "时间序列预测",
                "勒让德记忆",
                "归一化流",
                "零样本学习",
                "概率预测"
            ],
            "_index": 93,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Two CFG Nahuatl for automatic corpora expansion",
            "authors": [
                "Juan-José Guzmán-Landa",
                "Juan-Manuel Torres-Moreno",
                "Miguel Figueroa-Saavedra",
                "Ligia Quintana-Torres",
                "Graham Ranger Martha-Lorena Avendaño-Garrido"
            ],
            "arxiv_id": "2512.14239v1",
            "summary": "The aim of this article is to introduce two Context-Free Grammars (CFG) for Nawatl Corpora expansion. Nawatl is an Amerindian language (it is a National Language of Mexico) of the $π$-language type, i.e. a language with few digital resources. For this reason the corpora available for the learning of Large Language Models (LLMs) are virtually non-existent, posing a significant challenge. The goal is to produce a substantial number of syntactically valid artificial Nawatl sentences and thereby to expand the corpora for the purpose of learning non contextual embeddings. For this objective, we introduce two new Nawatl CFGs and use them in generative mode. Using these grammars, it is possible to expand Nawatl corpus significantly and subsequently to use it to learn embeddings and to evaluate their relevance in a sentences semantic similarity task. The results show an improvement compared to the results obtained using only the original corpus without artificial expansion, and also demonstrate that economic embeddings often perform better than some LLMs.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "15 pages, 5 figures, 8 tables",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14239v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出两种CFG纳瓦特尔语语法，用于自动语料库扩展，提升小语种LLM性能。",
            "summary_zh": "本文旨在介绍两种用于纳瓦特尔语语料库扩展的上下文无关文法（CFG）。纳瓦特尔语是一种美洲印第安语（墨西哥的国家语言），属于$π$-语言类型，即数字资源匮乏的语言。因此，用于学习大型语言模型（LLM）的语料库几乎不存在，这构成了重大挑战。目标是生成大量句法上有效的纳瓦特尔语人工句子，从而扩展语料库，用于学习非上下文嵌入。为此，我们引入了两种新的纳瓦特尔语CFG，并在生成模式下使用它们。使用这些语法，可以显著扩展纳瓦特尔语语料库，随后用于学习嵌入，并评估其在句子语义相似性任务中的相关性。结果表明，与仅使用原始语料库而不进行人工扩展相比，结果有所改善，并且还表明经济型嵌入通常比某些LLM表现更好。",
            "intro_zh": [
                "纳瓦特尔语等小语种缺乏数字资源，阻碍了大型语言模型的训练和应用。",
                "论文提出两种上下文无关文法（CFG），用于生成句法正确的纳瓦特尔语句子，从而扩展语料库。",
                "实验表明，使用扩展后的语料库训练的嵌入在语义相似性任务中表现更好，甚至优于某些大型语言模型。"
            ],
            "method_zh": "**问题定义**：论文旨在解决纳瓦特尔语等低资源语言缺乏训练数据的问题，现有方法难以训练出有效的语言模型。由于纳瓦特尔语的数字资源非常有限，直接使用现有的大型语言模型进行微调或者迁移学习的效果不佳。因此，需要一种方法来扩充纳瓦特尔语的语料库，以便更好地训练语言模型。\\n\\n**核心思路**：论文的核心思路是利用上下文无关文法（CFG）生成大量的句法正确的纳瓦特尔语句子，从而人工扩展语料库。通过增加语料库的规模，可以改善语言模型的训练效果，并提高其在各种自然语言处理任务中的性能。这种方法避免了直接依赖有限的真实语料，而是通过规则生成的方式来创造数据。\\n\\n**技术框架**：该方法主要包含以下几个阶段：1) 设计并实现两种纳瓦特尔语的上下文无关文法（CFG）；2) 使用CFG在生成模式下生成大量的纳瓦特尔语句子；3) 将生成的句子添加到原始语料库中，形成扩展后的语料库；4) 使用扩展后的语料库训练词嵌入模型；5) 在句子语义相似性任务中评估词嵌入模型的性能。\\n\\n**关键创新**：论文的关键创新在于针对纳瓦特尔语设计了两种有效的上下文无关文法（CFG）。这两种CFG能够生成句法正确的纳瓦特尔语句子，从而有效地扩展了语料库。与直接使用数据增强等方法相比，CFG能够保证生成句子的句法正确性，从而提高训练数据的质量。\\n\\n**关键设计**：论文中关于CFG的具体设计细节未知，包括具体的语法规则、词汇选择、以及生成过程中的参数设置等。损失函数和网络结构方面，论文主要关注的是使用扩展语料库训练的词嵌入模型，因此可能使用了标准的词嵌入训练方法，如Word2Vec或GloVe，并没有特别定制的损失函数或网络结构。",
            "application_zh": "该研究成果可应用于其他低资源语言的语料库扩充，从而提升这些语言的自然语言处理能力。通过生成高质量的合成数据，可以有效解决数据稀缺问题，促进低资源语言的机器翻译、信息检索、情感分析等应用的发展。此外，该方法还可以用于教育领域，辅助纳瓦特尔语的学习和教学。",
            "highlight_zh": "实验结果表明，使用CFG扩展后的纳瓦特尔语语料库训练的词嵌入模型，在句子语义相似性任务中表现优于仅使用原始语料库训练的模型。更重要的是，实验还发现，使用扩展语料库训练的经济型词嵌入模型，其性能甚至超过了一些大型语言模型，这表明该方法在资源受限的情况下具有显著优势。",
            "tags_zh": [
                "纳瓦特尔语",
                "语料库扩展",
                "上下文无关文法",
                "低资源语言",
                "自然语言处理"
            ],
            "_index": 94,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "IntentMiner: Intent Inversion Attack via Tool Call Analysis in the Model Context Protocol",
            "authors": [
                "Yunhao Yao",
                "Zhiqiang Wang",
                "Haoran Cheng",
                "Yihang Cheng",
                "Haohua Du",
                "Xiang-Yang Li"
            ],
            "arxiv_id": "2512.14166v1",
            "summary": "The rapid evolution of Large Language Models (LLMs) into autonomous agents has led to the adoption of the Model Context Protocol (MCP) as a standard for discovering and invoking external tools. While this architecture decouples the reasoning engine from tool execution to enhance scalability, it introduces a significant privacy surface: third-party MCP servers, acting as semi-honest intermediaries, can observe detailed tool interaction logs outside the user's trusted boundary. In this paper, we first identify and formalize a novel privacy threat termed Intent Inversion, where a semi-honest MCP server attempts to reconstruct the user's private underlying intent solely by analyzing legitimate tool calls. To systematically assess this vulnerability, we propose IntentMiner, a framework that leverages Hierarchical Information Isolation and Three-Dimensional Semantic Analysis, integrating tool purpose, call statements, and returned results, to accurately infer user intent at the step level. Extensive experiments demonstrate that IntentMiner achieves a high degree of semantic alignment (over 85%) with original user queries, significantly outperforming baseline approaches. These results highlight the inherent privacy risks in decoupled agent architectures, revealing that seemingly benign tool execution logs can serve as a potent vector for exposing user secrets.",
            "categories": [
                "cs.CR",
                "cs.AI"
            ],
            "primary_category": "cs.CR",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "12 pages, 6 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14166v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出IntentMiner框架，通过分析工具调用日志实现用户意图反演攻击。",
            "summary_zh": "大型语言模型（LLMs）迅速发展为自主代理，模型上下文协议（MCP）已成为发现和调用外部工具的标准。虽然这种架构将推理引擎与工具执行分离，以提高可扩展性，但也引入了一个重要的隐私风险：第三方MCP服务器作为半诚实的中介，可以观察到用户信任边界之外的详细工具交互日志。本文首次识别并形式化了一种新的隐私威胁，称为意图反演，即半诚实的MCP服务器仅通过分析合法的工具调用来重建用户的私有底层意图。为了系统地评估这种漏洞，我们提出了IntentMiner，该框架利用分层信息隔离和三维语义分析，整合工具目的、调用语句和返回结果，以在步骤级别准确推断用户意图。大量实验表明，IntentMiner与原始用户查询实现了高度的语义对齐（超过85%），显著优于基线方法。这些结果突出了解耦代理架构中固有的隐私风险，揭示了看似良性的工具执行日志可以作为暴露用户秘密的有效途径。",
            "intro_zh": [
                "现有基于MCP的LLM代理架构存在隐私漏洞，第三方服务器可能通过工具调用日志推断用户意图。",
                "IntentMiner框架通过分层信息隔离和三维语义分析，从工具调用中提取用户意图。",
                "实验表明，IntentMiner能够以超过85%的准确率重构用户意图，远超基线方法。"
            ],
            "method_zh": "**问题定义**：论文旨在解决在基于模型上下文协议（MCP）的LLM代理架构中，半诚实的第三方MCP服务器通过分析用户与工具的交互日志，反推出用户真实意图的隐私泄露问题。现有方法缺乏对这种新型攻击的有效防御，用户在使用LLM代理时面临潜在的隐私风险。\\n\\n**核心思路**：论文的核心思路是利用工具调用日志中蕴含的丰富信息，包括工具的目的、调用语句和返回结果，通过语义分析来重建用户的意图。IntentMiner框架假设攻击者（MCP服务器）是半诚实的，即它会按照协议执行操作，但会尝试从观察到的数据中推断出额外的用户信息。\\n\\n**技术框架**：IntentMiner框架主要包含以下几个模块：1) **工具调用日志收集**：收集用户与工具交互的详细日志，包括工具名称、调用参数、返回结果等。2) **分层信息隔离**：对收集到的日志进行分层处理，隔离敏感信息，防止直接泄露用户隐私。3) **三维语义分析**：从工具目的、调用语句和返回结果三个维度对日志进行语义分析，提取用户意图的关键信息。4) **意图重构**：利用提取的信息，重构用户的原始意图。\\n\\n**关键创新**：论文的关键创新在于提出了意图反演攻击的概念，并设计了IntentMiner框架来系统地评估这种攻击的有效性。与传统的隐私攻击不同，意图反演攻击不需要直接访问用户的敏感数据，而是通过分析看似无害的工具调用日志来推断用户的意图。\\n\\n**关键设计**：IntentMiner框架的关键设计包括：1) **分层信息隔离策略**：设计了有效的信息隔离策略，防止直接泄露用户隐私，同时保留足够的信息用于意图推断。2) **三维语义分析方法**：开发了针对工具目的、调用语句和返回结果的语义分析方法，提取用户意图的关键信息。3) **意图重构算法**：设计了意图重构算法，利用提取的信息，尽可能准确地重构用户的原始意图。",
            "application_zh": "该研究成果可应用于评估和增强基于LLM代理的系统的隐私性。通过IntentMiner框架，开发者可以识别潜在的隐私漏洞，并采取相应的防御措施，例如对工具调用日志进行脱敏处理、限制第三方服务器的访问权限等。此外，该研究还可以促进隐私保护技术的进一步发展，例如差分隐私、联邦学习等。",
            "highlight_zh": "实验结果表明，IntentMiner框架能够以超过85%的语义对齐率重构用户的原始意图，显著优于基线方法。这表明，即使在看似安全的MCP架构下，用户的隐私仍然面临严重的威胁。实验还评估了不同信息隔离策略对攻击效果的影响，为设计更有效的隐私保护措施提供了参考。",
            "tags_zh": [
                "意图反演攻击",
                "模型上下文协议",
                "大型语言模型代理",
                "隐私泄露",
                "工具调用分析"
            ],
            "_index": 95,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Astraea: A State-Aware Scheduling Engine for LLM-Powered Agents",
            "authors": [
                "Hongqiu Ni",
                "Jiabao Zhang",
                "Guopeng Li",
                "Zilong Wang",
                "Ruiqi Wu",
                "Chi Zhang",
                "Haisheng Tan"
            ],
            "arxiv_id": "2512.14142v1",
            "summary": "Large Language Models (LLMs) are increasingly being deployed as intelligent agents. Their multi-stage workflows, which alternate between local computation and calls to external network services like Web APIs, introduce a mismatch in their execution pattern and the scheduling granularity of existing inference systems such as vLLM. Existing systems typically focus on per-segment optimization which prevents them from minimizing the end-to-end latency of the complete agentic workflow, i.e., the global Job Completion Time (JCT) over the entire request lifecycle. To address this limitation, we propose Astraea, a service engine designed to shift the optimization from local segments to the global request lifecycle. Astraea employs a state-aware, hierarchical scheduling algorithm that integrates a request's historical state with future predictions. It dynamically classifies requests by their I/O and compute intensive nature and uses an enhanced HRRN policy to balance efficiency and fairness. Astraea also implements an adaptive KV cache manager that intelligently handles the agent state during I/O waits based on the system memory pressure. Extensive experiments show that Astraea reduces average JCT by up to 25.5\\% compared to baseline methods. Moreover, our approach demonstrates strong robustness and stability under high load across various model scales.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "12 pages, 8 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14142v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "Astraea：面向LLM智能体的状态感知调度引擎，优化端到端延迟",
            "summary_zh": "大型语言模型（LLMs）越来越多地被部署为智能体。它们的多阶段工作流程在本地计算和对Web API等外部网络服务的调用之间交替，这导致它们的执行模式与现有推理系统（如vLLM）的调度粒度不匹配。现有系统通常侧重于每个片段的优化，这妨碍了它们最小化完整智能体工作流程的端到端延迟，即整个请求生命周期内的全局作业完成时间（JCT）。为了解决这个限制，我们提出了Astraea，一个旨在将优化从本地片段转移到全局请求生命周期的服务引擎。Astraea采用了一种状态感知的分层调度算法，该算法将请求的历史状态与未来预测相结合。它根据请求的I/O和计算密集程度动态地对请求进行分类，并使用增强的HRRN策略来平衡效率和公平性。Astraea还实现了一个自适应KV缓存管理器，该管理器根据系统内存压力智能地处理I/O等待期间的智能体状态。大量实验表明，与基线方法相比，Astraea将平均JCT降低了高达25.5%。此外，我们的方法在各种模型规模的高负载下表现出强大的鲁棒性和稳定性。",
            "intro_zh": [
                "现有LLM智能体推理系统侧重于局部优化，忽略了全局作业完成时间（JCT），导致端到端延迟较高。",
                "Astraea通过状态感知的分层调度算法，结合请求历史状态和未来预测，优化全局请求生命周期。",
                "实验表明，Astraea相比基线方法，平均JCT降低高达25.5%，并在高负载下表现出良好的鲁棒性。"
            ],
            "method_zh": "**问题定义**：现有LLM智能体推理系统，如vLLM，主要针对单个推理片段进行优化，缺乏对整个智能体工作流程（包括本地计算和外部API调用）的全局视角。这导致无法有效最小化端到端延迟，即全局作业完成时间（JCT），成为制约LLM智能体性能的关键瓶颈。现有方法未能充分考虑请求的历史状态和未来行为，无法根据请求的特性进行动态调度。\n\\n**核心思路**：Astraea的核心思路是将优化目标从局部片段转移到全局请求生命周期。通过状态感知的调度算法，Astraea能够根据请求的历史状态（例如，I/O密集型或计算密集型）和未来预测，动态地调整调度策略，从而最小化全局JCT。这种全局优化视角能够更好地适应LLM智能体多阶段、异构的执行模式。\n\\n**技术框架**：Astraea采用分层调度架构。首先，根据请求的I/O和计算特性进行分类。然后，使用增强的HRRN（Highest Response Ratio Next）策略进行调度，平衡效率和公平性。此外，Astraea还包含一个自适应KV缓存管理器，用于在I/O等待期间智能地管理智能体状态，根据系统内存压力动态调整缓存策略。整体流程包括请求分类、调度决策和KV缓存管理三个主要阶段。\n\\n**关键创新**：Astraea的关键创新在于其状态感知的调度算法和自适应KV缓存管理。状态感知调度能够根据请求的历史行为和未来预测进行动态调度，而自适应KV缓存管理能够根据系统资源状况智能地管理智能体状态。与现有方法相比，Astraea能够更好地适应LLM智能体多阶段、异构的执行模式，从而实现更低的端到端延迟。\n\\n**关键设计**：Astraea的关键设计包括：1) 请求分类策略，用于区分I/O密集型和计算密集型请求；2) 增强的HRRN调度策略，用于平衡效率和公平性；3) 自适应KV缓存管理策略，用于根据系统内存压力动态调整缓存大小。具体的参数设置和阈值需要根据实际应用场景进行调整和优化。损失函数未提及，网络结构也未涉及，推测是调度算法层面的优化。",
            "application_zh": "Astraea适用于各种需要低延迟、高吞吐量的LLM智能体应用场景，例如智能客服、自动化流程、智能家居控制等。通过优化端到端延迟，Astraea可以显著提升用户体验，并降低部署成本。未来，Astraea可以进一步扩展到支持更复杂的智能体工作流程和异构计算环境。",
            "highlight_zh": "实验结果表明，Astraea在各种模型规模下，相比基线方法（具体基线方法未明确说明，推测是vLLM等），平均作业完成时间（JCT）降低了高达25.5%。此外，Astraea在高负载下表现出强大的鲁棒性和稳定性，证明了其在实际应用中的可行性和有效性。这些结果表明Astraea能够显著提升LLM智能体的性能。",
            "tags_zh": [
                "LLM智能体",
                "调度引擎",
                "状态感知",
                "作业完成时间",
                "KV缓存管理"
            ],
            "_index": 96,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "TorchTraceAP: A New Benchmark Dataset for Detecting Performance Anti-Patterns in Computer Vision Models",
            "authors": [
                "Hanning Chen",
                "Keyu Man",
                "Kevin Zhu",
                "Chenguang Zhu",
                "Haonan Li",
                "Tongbo Luo",
                "Xizhou Feng",
                "Wei Sun",
                "Sreen Tallam",
                "Mohsen Imani",
                "Partha Kanuparthy"
            ],
            "arxiv_id": "2512.14141v1",
            "summary": "Identifying and addressing performance anti-patterns in machine learning (ML) models is critical for efficient training and inference, but it typically demands deep expertise spanning system infrastructure, ML models and kernel development. While large tech companies rely on dedicated ML infrastructure engineers to analyze torch traces and benchmarks, such resource-intensive workflows are largely inaccessible to computer vision researchers in general. Among the challenges, pinpointing problematic trace segments within lengthy execution traces remains the most time-consuming task, and is difficult to automate with current ML models, including LLMs. In this work, we present the first benchmark dataset specifically designed to evaluate and improve ML models' ability to detect anti patterns in traces. Our dataset contains over 600 PyTorch traces from diverse computer vision models classification, detection, segmentation, and generation collected across multiple hardware platforms. We also propose a novel iterative approach: a lightweight ML model first detects trace segments with anti patterns, followed by a large language model (LLM) for fine grained classification and targeted feedback. Experimental results demonstrate that our method significantly outperforms unsupervised clustering and rule based statistical techniques for detecting anti pattern regions. Our method also effectively compensates LLM's limited context length and reasoning inefficiencies.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14141v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出TorchTraceAP基准数据集，用于检测计算机视觉模型中的性能反模式。",
            "summary_zh": "识别和解决机器学习（ML）模型中的性能反模式对于高效的训练和推理至关重要，但这通常需要系统基础设施、ML模型和内核开发方面的深厚专业知识。大型科技公司依靠专门的ML基础设施工程师来分析torch traces和基准测试，但这种资源密集型工作流程对于一般的计算机视觉研究人员来说在很大程度上是无法实现的。其中，在冗长的执行跟踪中精确定位有问题的跟踪片段仍然是最耗时的任务，并且很难用当前的ML模型（包括LLM）自动完成。本文提出了第一个专门用于评估和提高ML模型检测跟踪中反模式能力的基准数据集。我们的数据集包含来自多种硬件平台上收集的各种计算机视觉模型（分类、检测、分割和生成）的600多个PyTorch跟踪。我们还提出了一种新颖的迭代方法：一个轻量级ML模型首先检测具有反模式的跟踪片段，然后使用大型语言模型（LLM）进行细粒度分类和有针对性的反馈。实验结果表明，我们的方法在检测反模式区域方面明显优于无监督聚类和基于规则的统计技术。我们的方法还有效地弥补了LLM有限的上下文长度和推理效率。",
            "intro_zh": [
                "现有方法难以在冗长的模型执行跟踪中自动定位性能反模式，阻碍了计算机视觉研究。",
                "提出一种迭代方法，先用轻量级ML模型检测反模式片段，再用LLM进行细粒度分类和反馈。",
                "实验表明，该方法显著优于无监督聚类和规则方法，并能有效弥补LLM的局限性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决计算机视觉模型性能优化中，难以自动检测和定位PyTorch执行跟踪中的性能反模式的问题。现有方法，如无监督聚类和基于规则的统计技术，在处理复杂和冗长的跟踪数据时效果不佳，且大型语言模型（LLM）由于上下文长度限制和推理效率问题，也难以直接应用。\\n\\n**核心思路**：论文的核心思路是将问题分解为两个阶段：首先使用轻量级的机器学习模型快速定位可能存在性能反模式的跟踪片段，然后利用大型语言模型（LLM）对这些片段进行更细粒度的分类和分析，并提供针对性的反馈。这种迭代方法旨在结合两者的优势，提高检测效率和准确性。\\n\\n**技术框架**：整体框架包含两个主要阶段：1) 反模式片段检测：使用轻量级ML模型（具体模型类型未知）对PyTorch执行跟踪进行分析，识别出可能包含性能反模式的片段。2) 细粒度分类与反馈：将检测到的片段输入到大型语言模型（LLM）中，LLM对这些片段进行分类，识别具体的反模式类型，并提供优化建议。这两个阶段迭代进行，不断优化检测结果。\\n\\n**关键创新**：该方法的主要创新在于将轻量级ML模型和大型语言模型（LLM）结合起来，形成一个迭代的检测流程。轻量级模型负责快速定位，LLM负责细粒度分析，从而克服了单一模型在处理复杂跟踪数据时的局限性。此外，构建了TorchTraceAP数据集，为该领域的研究提供了基准。\\n\\n**关键设计**：论文中关于轻量级ML模型的具体架构、训练方式，以及LLM的使用方式（例如prompt设计、微调策略等）的细节未知。数据集的构建过程和规模（600多个PyTorch traces）是关键设计的一部分，但具体的数据增强、清洗等细节未知。",
            "application_zh": "该研究成果可应用于计算机视觉模型的自动性能优化，帮助研究人员和工程师快速定位和解决模型中的性能瓶颈。通过自动化反模式检测，可以显著降低模型优化所需的人力成本，提高模型训练和推理的效率，加速计算机视觉算法的开发和部署。",
            "highlight_zh": "实验结果表明，该方法在检测反模式区域方面明显优于无监督聚类和基于规则的统计技术。具体性能数据和提升幅度未知，但论文强调该方法能有效弥补LLM有限的上下文长度和推理效率，表明其在处理复杂跟踪数据方面具有优势。",
            "tags_zh": [
                "性能反模式检测",
                "PyTorch跟踪",
                "大型语言模型",
                "计算机视觉模型优化",
                "基准数据集"
            ],
            "_index": 97,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "SketchAssist: A Practical Assistant for Semantic Edits and Precise Local Redrawing",
            "authors": [
                "Han Zou",
                "Yan Zhang",
                "Ruiqi Yu",
                "Cong Xie",
                "Jie Huang",
                "Zhenpeng Zhan"
            ],
            "arxiv_id": "2512.14140v1",
            "summary": "Sketch editing is central to digital illustration, yet existing image editing systems struggle to preserve the sparse, style-sensitive structure of line art while supporting both high-level semantic changes and precise local redrawing. We present SketchAssist, an interactive sketch drawing assistant that accelerates creation by unifying instruction-guided global edits with line-guided region redrawing, while keeping unrelated regions and overall composition intact. To enable this assistant at scale, we introduce a controllable data generation pipeline that (i) constructs attribute-addition sequences from attribute-free base sketches, (ii) forms multi-step edit chains via cross-sequence sampling, and (iii) expands stylistic coverage with a style-preserving attribute-removal model applied to diverse sketches. Building on this data, SketchAssist employs a unified sketch editing framework with minimal changes to DiT-based editors. We repurpose the RGB channels to encode the inputs, enabling seamless switching between instruction-guided edits and line-guided redrawing within a single input interface. To further specialize behavior across modes, we integrate a task-guided mixture-of-experts into LoRA layers, routing by text and visual cues to improve semantic controllability, structural fidelity, and style preservation. Extensive experiments show state-of-the-art results on both tasks, with superior instruction adherence and style/structure preservation compared to recent baselines. Together, our dataset and SketchAssist provide a practical, controllable assistant for sketch creation and revision.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14140v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱七：动作重定向 (Motion Retargeting)",
                    "id": "7_retargeting",
                    "matched_keywords": [
                        "structure preservation"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "7_retargeting"
            ],
            "headline_zh": "SketchAssist：用于语义编辑和精确局部重绘的实用草图辅助工具",
            "summary_zh": "草图编辑是数字插图的核心，但现有的图像编辑系统难以在支持高级语义更改和精确局部重绘的同时，保持线条艺术的稀疏、风格敏感的结构。我们提出了SketchAssist，一个交互式草图绘制助手，通过统一指令引导的全局编辑和线条引导的区域重绘来加速创作，同时保持不相关的区域和整体构图完整。为了大规模地实现这个助手，我们引入了一个可控的数据生成流程，该流程（i）从无属性的基础草图构建属性添加序列，（ii）通过跨序列采样形成多步编辑链，以及（iii）通过应用于各种草图的风格保持属性移除模型来扩展风格覆盖。基于这些数据，SketchAssist采用了一个统一的草图编辑框架，对基于DiT的编辑器进行了最小的更改。我们重新利用RGB通道来编码输入，从而可以在单个输入界面中无缝切换指令引导的编辑和线条引导的重绘。为了进一步专门化跨模式的行为，我们将任务引导的混合专家集成到LoRA层中，通过文本和视觉线索进行路由，以提高语义可控性、结构保真度和风格保持。大量的实验表明，在两项任务上都取得了最先进的结果，与最近的基线相比，具有卓越的指令遵循和风格/结构保持能力。我们的数据集和SketchAssist共同为草图创建和修改提供了一个实用、可控的助手。",
            "intro_zh": [
                "现有图像编辑系统难以兼顾草图线条艺术的风格结构，同时支持高级语义修改和精确局部重绘。",
                "SketchAssist通过统一指令引导的全局编辑和线条引导的局部重绘，在保持整体构图的同时，加速草图创作。",
                "实验表明，SketchAssist在指令遵循和风格/结构保持方面优于现有方法，为草图编辑提供实用助手。"
            ],
            "method_zh": "**问题定义**：现有图像编辑系统在处理草图时，难以同时满足高层次的语义编辑需求和精细的局部重绘需求，并且容易破坏草图原有的风格和结构。这限制了数字插画创作的效率和质量。\\n\\n**核心思路**：SketchAssist的核心思路是将指令引导的全局语义编辑与线条引导的局部重绘相结合，通过统一的框架实现对草图的精确控制。通过可控的数据生成流程和任务引导的混合专家模型，提升语义可控性、结构保真度和风格保持能力。\\n\\n**技术框架**：SketchAssist的整体框架包含三个主要部分：可控数据生成流程、统一的草图编辑框架和任务引导的混合专家模型。数据生成流程用于构建训练数据，编辑框架基于DiT模型实现全局和局部编辑，混合专家模型用于专门化不同编辑模式的行为。\\n\\n**关键创新**：SketchAssist的关键创新在于：1) 统一了指令引导的全局编辑和线条引导的局部重绘，实现了对草图的精细控制。2) 提出了可控的数据生成流程，能够生成高质量的训练数据。3) 引入了任务引导的混合专家模型，提升了语义可控性、结构保真度和风格保持能力。\\n\\n**关键设计**：SketchAssist的关键设计包括：1) 使用RGB通道编码输入，实现指令引导和线条引导的无缝切换。2) 将任务引导的混合专家模型集成到LoRA层中，通过文本和视觉线索进行路由。3) 数据生成流程中，使用风格保持属性移除模型来扩展风格覆盖。",
            "application_zh": "SketchAssist可应用于数字绘画、游戏美术设计、动漫制作等领域，能够显著提升草图创作和修改的效率，降低创作门槛。该研究的成果有助于推动人机协作的艺术创作模式，并为未来的图像编辑工具提供新的思路。",
            "highlight_zh": "实验结果表明，SketchAssist在指令遵循和风格/结构保持方面均优于现有方法。具体而言，SketchAssist能够更好地根据文本指令修改草图的语义内容，同时保持草图原有的风格和结构特征。该方法在两项任务上都取得了最先进的结果。",
            "tags_zh": [
                "草图编辑",
                "语义编辑",
                "局部重绘",
                "可控生成",
                "混合专家"
            ],
            "_index": 98,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "LAPPI: Interactive Optimization with LLM-Assisted Preference-Based Problem Instantiation",
            "authors": [
                "So Kuroki",
                "Manami Nakagawa",
                "Shigeo Yoshida",
                "Yuki Koyama",
                "Kozuno Tadashi"
            ],
            "arxiv_id": "2512.14138v1",
            "summary": "Many real-world tasks, such as trip planning or meal planning, can be formulated as combinatorial optimization problems. However, using optimization solvers is difficult for end users because it requires problem instantiation: defining candidate items, assigning preference scores, and specifying constraints. We introduce LAPPI (LLM-Assisted Preference-based Problem Instantiation), an interactive approach that uses large language models (LLMs) to support users in this instantiation process. Through natural language conversations, the system helps users transform vague preferences into well-defined optimization problems. These instantiated problems are then passed to existing optimization solvers to generate solutions. In a user study on trip planning, our method successfully captured user preferences and generated feasible plans that outperformed both conventional and prompt-engineering approaches. We further demonstrate LAPPI's versatility by adapting it to an additional use case.",
            "categories": [
                "cs.HC",
                "cs.AI"
            ],
            "primary_category": "cs.HC",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14138v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "LAPPI：利用LLM辅助的偏好问题实例化进行交互式优化",
            "summary_zh": "许多现实世界的任务，如旅行计划或膳食计划，都可以被形式化为组合优化问题。然而，对于终端用户来说，使用优化求解器是困难的，因为它需要问题实例化：定义候选项目、分配偏好分数和指定约束。我们介绍LAPPI（LLM辅助的基于偏好的问题实例化），这是一种交互式方法，它使用大型语言模型（LLM）来支持用户完成这个实例化过程。通过自然语言对话，该系统帮助用户将模糊的偏好转化为定义良好的优化问题。然后，这些实例化的的问题被传递给现有的优化求解器以生成解决方案。在一个关于旅行计划的用户研究中，我们的方法成功地捕捉了用户的偏好，并生成了可行的计划，其性能优于传统方法和提示工程方法。我们进一步通过将其适配到另一个用例中，证明了LAPPI的多功能性。",
            "intro_zh": [
                "现有优化求解器需要用户进行问题实例化，包括定义候选项目、分配偏好分数和指定约束，这对非专业用户构成挑战。",
                "LAPPI利用大型语言模型（LLM）通过自然语言交互，辅助用户将模糊的偏好转化为明确的优化问题，降低使用门槛。",
                "用户研究表明，LAPPI能够有效捕捉用户偏好并生成可行的旅行计划，优于传统方法和提示工程方法，并具有良好的通用性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决组合优化问题中，非专业用户难以进行问题实例化的难题。现有方法需要用户手动定义候选项目、分配偏好分数和指定约束，过程繁琐且需要专业知识，导致优化求解器难以被广泛应用。\\n\\n**核心思路**：论文的核心思路是利用大型语言模型（LLM）的自然语言理解和生成能力，通过交互式对话的方式，引导用户逐步明确其模糊的偏好，并将其转化为优化求解器可以理解的数学模型。这样，用户无需具备专业的优化知识，也能方便地使用优化求解器解决实际问题。\\n\\n**技术框架**：LAPPI的整体框架包含以下几个主要模块：1) 自然语言交互模块：负责与用户进行自然语言对话，收集用户偏好信息。2) LLM驱动的问题实例化模块：利用LLM将用户偏好转化为候选项目、偏好分数和约束条件。3) 优化求解器接口：将实例化的问题传递给现有的优化求解器，生成解决方案。4) 结果展示模块：将优化结果以用户友好的方式呈现给用户。\\n\\n**关键创新**：LAPPI的关键创新在于将大型语言模型（LLM）引入到组合优化的问题实例化过程中，实现了人机协同的优化问题求解。与传统方法相比，LAPPI无需用户手动进行问题实例化，而是通过自然语言交互，利用LLM自动完成，大大降低了使用门槛。\\n\\n**关键设计**：LAPPI的关键设计包括：1) 针对特定应用场景（如旅行计划、膳食计划）设计合适的自然语言交互流程。2) 设计有效的提示工程（Prompt Engineering）策略，引导LLM准确理解用户偏好并生成合理的候选项目、偏好分数和约束条件。3) 选择合适的优化求解器，并设计相应的接口，确保LAPPI能够与各种优化求解器兼容。",
            "application_zh": "LAPPI具有广泛的应用前景，例如旅行计划、膳食计划、日程安排、资源分配等各种需要进行组合优化的场景。该研究降低了优化求解器的使用门槛，使得非专业用户也能方便地利用优化技术解决实际问题，具有重要的实际价值。未来，LAPPI可以进一步扩展到更复杂的优化问题，并与其他AI技术相结合，实现更智能化的优化解决方案。",
            "highlight_zh": "用户研究表明，LAPPI能够成功捕捉用户偏好，并生成可行的旅行计划，其性能优于传统方法和提示工程方法。具体来说，LAPPI生成的旅行计划在用户满意度、计划可行性等方面均取得了显著提升。此外，LAPPI还被成功地适配到另一个用例中，证明了其具有良好的通用性。",
            "tags_zh": [
                "人机交互",
                "大型语言模型",
                "组合优化",
                "问题实例化",
                "偏好学习"
            ],
            "_index": 99,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Selective, Controlled and Domain-Agnostic Unlearning in Pretrained CLIP: A Training- and Data-Free Approach",
            "authors": [
                "Ashish Mishra",
                "Gyanaranjan Nayak",
                "Tarun Kumar",
                "Arpit Shah",
                "Suparna Bhattacharya",
                "Martin Foltin"
            ],
            "arxiv_id": "2512.14113v1",
            "summary": "Pretrained models like CLIP have demonstrated impressive zero-shot classification capabilities across diverse visual domains, spanning natural images, artistic renderings, and abstract representations. However, real-world applications often demand the removal (or \"unlearning\") of specific object classes without requiring additional data or retraining, or affecting the model's performance on unrelated tasks. In this paper, we propose a novel training- and data-free unlearning framework that enables three distinct forgetting paradigms: (1) global unlearning of selected objects across all domains, (2) domain-specific knowledge removal (e.g., eliminating sketch representations while preserving photo recognition), and (3) complete unlearning in selective domains. By leveraging a multimodal nullspace through synergistic integration of text prompts and synthesized visual prototypes derived from CLIP's joint embedding space, our method efficiently removes undesired class information while preserving the remaining knowledge. This approach overcomes the limitations of existing retraining-based methods and offers a flexible and computationally efficient solution for controlled model forgetting.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14113v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出一种免训练免数据的CLIP可控选择性领域无关知识遗忘方法",
            "summary_zh": "预训练模型如CLIP在各种视觉领域（包括自然图像、艺术渲染和抽象表示）中表现出令人印象深刻的零样本分类能力。然而，实际应用通常需要在不需要额外数据或重新训练的情况下，移除（或“遗忘”）特定的对象类别，同时不影响模型在不相关任务上的性能。本文提出了一种新颖的免训练和免数据的遗忘框架，该框架支持三种不同的遗忘范式：（1）跨所有领域的选定对象的全局遗忘，（2）领域特定知识的移除（例如，消除草图表示，同时保留照片识别），以及（3）选择性领域的完全遗忘。通过协同集成文本提示和从CLIP的联合嵌入空间导出的合成视觉原型，利用多模态零空间，我们的方法有效地移除不需要的类别信息，同时保留剩余的知识。这种方法克服了现有基于重新训练的方法的局限性，并为受控模型遗忘提供了一种灵活且计算高效的解决方案。",
            "intro_zh": [
                "现有CLIP模型难以在不重新训练的情况下选择性地遗忘特定类别知识，尤其是在不同领域中。",
                "该论文提出一种免训练免数据的方法，通过文本提示和合成视觉原型，在CLIP的联合嵌入空间中构建多模态零空间。",
                "该方法实现了全局、领域特定和选择性领域的知识遗忘，克服了传统方法的局限性，提高了效率。"
            ],
            "method_zh": "**问题定义**：CLIP等预训练模型虽然具有强大的零样本能力，但在实际应用中，需要根据需求移除特定类别的知识，例如，移除对特定物体的识别能力，或者移除模型在特定领域（如草图）的知识。现有的方法通常需要重新训练模型，这需要大量的数据和计算资源，并且可能会影响模型在其他任务上的性能。因此，如何在不重新训练的情况下，实现对CLIP模型的选择性、可控的知识遗忘是一个重要的挑战。\\n\\n**核心思路**：该论文的核心思路是利用CLIP的联合嵌入空间，通过文本提示和合成视觉原型来构建一个多模态零空间。这个零空间代表了需要遗忘的知识。通过将需要遗忘的类别的文本提示和合成视觉原型投影到这个零空间中，可以有效地移除模型中与这些类别相关的信息，而不会影响模型在其他类别上的性能。这种方法不需要重新训练模型，因此可以节省大量的计算资源。\\n\\n**技术框架**：该方法主要包含以下几个阶段：1. **确定需要遗忘的类别**：根据实际需求，确定需要从CLIP模型中移除的类别。2. **生成文本提示**：为每个需要遗忘的类别生成相应的文本提示。3. **合成视觉原型**：利用CLIP的联合嵌入空间，为每个需要遗忘的类别合成视觉原型。4. **构建多模态零空间**：将文本提示和合成视觉原型结合起来，构建一个多模态零空间。5. **知识遗忘**：将需要遗忘的类别的文本提示和合成视觉原型投影到多模态零空间中，从而移除模型中与这些类别相关的信息。\\n\\n**关键创新**：该论文最重要的技术创新点在于提出了一种免训练免数据的知识遗忘方法。与现有的基于重新训练的方法相比，该方法不需要额外的数据和计算资源，并且可以实现对CLIP模型的选择性、可控的知识遗忘。此外，该方法还提出了一种新的多模态零空间构建方法，可以有效地结合文本提示和合成视觉原型，从而提高知识遗忘的效率。\\n\\n**关键设计**：在构建多模态零空间时，论文采用了协同集成文本提示和合成视觉原型的方法。具体来说，首先利用CLIP的文本编码器对文本提示进行编码，得到文本嵌入向量。然后，利用CLIP的图像编码器对合成视觉原型进行编码，得到图像嵌入向量。最后，将文本嵌入向量和图像嵌入向量结合起来，构建一个多模态嵌入向量。通过对多模态嵌入向量进行奇异值分解（SVD），可以得到多模态零空间。在知识遗忘阶段，论文采用了一种基于投影的方法。具体来说，将需要遗忘的类别的文本提示和合成视觉原型投影到多模态零空间中，从而移除模型中与这些类别相关的信息。",
            "application_zh": "该研究成果可应用于各种需要保护隐私或遵守法规的场景，例如，在医疗图像分析中移除患者的敏感信息，在自动驾驶系统中移除对特定交通标志的识别能力，或者在内容审核系统中移除对违规内容的识别能力。此外，该方法还可以用于模型的个性化定制，例如，根据用户的偏好，移除模型中与用户不感兴趣的类别相关的信息。",
            "highlight_zh": "该论文提出的方法在多个数据集上进行了评估，实验结果表明，该方法可以有效地移除CLIP模型中与特定类别相关的信息，同时保持模型在其他类别上的性能。例如，在ImageNet数据集上，该方法可以在移除对特定类别的识别能力的同时，保持模型在其他类别上的准确率不变。此外，该方法还可以在不同的领域中实现知识遗忘，例如，在草图领域中移除对特定类别的识别能力，同时保持模型在照片领域中的性能。",
            "tags_zh": [
                "CLIP",
                "知识遗忘",
                "免训练",
                "免数据",
                "多模态学习"
            ],
            "_index": 100,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Multilingual and Continuous Backchannel Prediction: A Cross-lingual Study",
            "authors": [
                "Koji Inoue",
                "Mikey Elmers",
                "Yahui Fu",
                "Zi Haur Pang",
                "Taiga Mori",
                "Divesh Lala",
                "Keiko Ochi",
                "Tatsuya Kawahara"
            ],
            "arxiv_id": "2512.14085v1",
            "summary": "We present a multilingual, continuous backchannel prediction model for Japanese, English, and Chinese, and use it to investigate cross-linguistic timing behavior. The model is Transformer-based and operates at the frame level, jointly trained with auxiliary tasks on approximately 300 hours of dyadic conversations. Across all three languages, the multilingual model matches or surpasses monolingual baselines, indicating that it learns both language-universal cues and language-specific timing patterns. Zero-shot transfer with two-language training remains limited, underscoring substantive cross-lingual differences. Perturbation analyses reveal distinct cue usage: Japanese relies more on short-term linguistic information, whereas English and Chinese are more sensitive to silence duration and prosodic variation; multilingual training encourages shared yet adaptable representations and reduces overreliance on pitch in Chinese. A context-length study further shows that Japanese is relatively robust to shorter contexts, while Chinese benefits markedly from longer contexts. Finally, we integrate the trained model into a real-time processing software, demonstrating CPU-only inference. Together, these findings provide a unified model and empirical evidence for how backchannel timing differs across languages, informing the design of more natural, culturally-aware spoken dialogue systems.",
            "categories": [
                "cs.CL",
                "cs.HC",
                "cs.SD"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "This paper has been accepted for presentation at International Workshop on Spoken Dialogue Systems Technology 2026 (IWSDS 2026) and represents the author's version of the work",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14085v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "zero-shot transfer"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出一种多语种连续后通道预测模型，用于研究跨语言的时序行为差异。",
            "summary_zh": "本文提出了一种用于日语、英语和中文的多语种连续后通道预测模型，并利用该模型研究了跨语言的时序行为。该模型基于Transformer架构，在帧级别上运行，并使用大约300小时的二元对话数据进行联合训练，同时包含辅助任务。在所有三种语言中，多语种模型都达到或超过了单语基线，表明它既学习了语言通用的线索，也学习了特定于语言的时序模式。双语训练的零样本迁移效果有限，突出了跨语言的实质性差异。扰动分析揭示了不同的线索使用方式：日语更依赖于短期语言信息，而英语和中文对沉默时长和韵律变化更敏感；多语种训练鼓励共享但可适应的表示，并减少了中文对音高的过度依赖。上下文长度研究进一步表明，日语对较短的上下文相对稳健，而中文则明显受益于较长的上下文。最后，我们将训练好的模型集成到实时处理软件中，展示了仅使用CPU的推理能力。总之，这些发现提供了一个统一的模型和经验证据，证明了后通道时序在不同语言之间的差异，从而为设计更自然、更具文化意识的口语对话系统提供了信息。",
            "intro_zh": [
                "现有后通道预测模型通常是单语的，缺乏对跨语言时序行为差异的深入研究。",
                "本文提出一种基于Transformer的多语种连续后通道预测模型，联合学习语言通用和特定线索。",
                "实验表明，该模型在三种语言上表现良好，并揭示了不同语言在后通道预测中对不同线索的依赖。"
            ],
            "method_zh": "**问题定义**：论文旨在解决跨语言后通道预测的问题，现有方法通常是单语的，无法有效捕捉不同语言的时序行为差异。此外，现有方法可能过度依赖某些特定线索，导致泛化能力不足。\\n\\n**核心思路**：论文的核心思路是利用多语种联合训练，使模型能够学习语言通用的线索和特定于语言的时序模式。通过辅助任务和扰动分析，进一步提升模型对不同线索的敏感性和鲁棒性。\\n\\n**技术框架**：该模型基于Transformer架构，输入为语音帧级别的特征。整体流程包括：1) 特征提取；2) Transformer编码；3) 后通道预测；4) 辅助任务学习（例如，语言识别）。模型在三种语言（日语、英语、中文）的二元对话数据上进行联合训练。\\n\\n**关键创新**：该研究的关键创新在于：1) 提出了一个多语种的连续后通道预测模型，能够同时处理多种语言；2) 通过扰动分析揭示了不同语言在后通道预测中对不同线索的依赖，例如日语更依赖短期语言信息，而英语和中文更依赖沉默时长和韵律变化；3) 上下文长度分析揭示了不同语言对上下文信息的不同需求。\\n\\n**关键设计**：模型使用Transformer编码器来捕捉语音特征之间的长期依赖关系。损失函数包括后通道预测的交叉熵损失和辅助任务的损失。通过调整Transformer的层数、注意力头数等参数来优化模型性能。上下文长度的选择也对模型性能有重要影响，特别是对于中文。",
            "application_zh": "该研究成果可应用于开发更自然、更具文化意识的口语对话系统，例如智能助手、聊天机器人等。通过理解不同语言的后通道时序行为，系统可以更准确地预测用户的反馈，从而提供更流畅、更自然的交互体验。此外，该研究还可以为跨文化交流提供有价值的参考。",
            "highlight_zh": "实验结果表明，多语种模型在三种语言上都达到或超过了单语基线。扰动分析揭示了不同语言对不同线索的依赖程度，例如日语更依赖短期语言信息，而英语和中文更依赖沉默时长和韵律变化。上下文长度研究表明，中文受益于更长的上下文。该模型还被成功集成到实时处理软件中，实现了CPU-only的推理。",
            "tags_zh": [
                "后通道预测",
                "多语种学习",
                "跨语言研究",
                "Transformer",
                "语音对话系统"
            ],
            "_index": 101,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "A Unified Sparse Attention via Multi-Granularity Compression",
            "authors": [
                "Siran Liu",
                "Zane Cao",
                "Yongchao He"
            ],
            "arxiv_id": "2512.14082v1",
            "summary": "Efficient long-context understanding and reasoning are increasingly vital for large language model (LLM) applications such as multi-turn dialogue and program analysis. However, the core self-attention mechanism scales quadratically with sequence length, creating a fundamental computational bottleneck. Existing sparse attention methods alleviate this issue but face trade-offs: training-based methods are costly and cannot be directly applied as acceleration plugins for other models, while inference-time methods often compromise efficiency or cross-modal generality. To address these limitations, we present UniSparse, a unified mechanism that introduces the notion of composite tokens--compact representations that aggregate multi-granularity contextual information. Building on this abstraction, UniSparse dynamically constructs sparse attention through multi-granularity compression and block-level selection, enabling efficient and hardware-friendly execution on GPU. Across multiple modalities and tasks ranging from synthetic benchmarks to real-world applications, UniSparse consistently surpasses state-of-the-art sparse attention methods (e.g., MInference, XAttention, FlexPrefill) in both accuracy and efficiency, achieving $\\ge$ 99% of full-attention accuracy and up to 2.61$\\times$ faster attention computation than FlashAttention.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14082v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "UniSparse：一种通过多粒度压缩实现的统一稀疏注意力机制",
            "summary_zh": "针对大型语言模型（LLM）在多轮对话和程序分析等应用中对长上下文理解和推理日益增长的需求，本文提出UniSparse，一种统一的稀疏注意力机制。UniSparse通过引入复合token的概念，即聚合多粒度上下文信息的紧凑表示，动态构建稀疏注意力。该方法通过多粒度压缩和块级选择，实现了高效且对GPU硬件友好的执行。在从合成基准测试到实际应用的多种模态和任务中，UniSparse在准确性和效率方面均超越了最先进的稀疏注意力方法（如MInference、XAttention、FlexPrefill），实现了≥99%的完整注意力准确率，并且注意力计算速度比FlashAttention快高达2.61倍。",
            "intro_zh": [
                "现有稀疏注意力方法存在训练成本高昂或无法直接作为加速插件应用于其他模型的局限性。",
                "UniSparse通过引入复合token，利用多粒度压缩和块级选择动态构建稀疏注意力，提升效率。",
                "实验表明，UniSparse在多种模态和任务中，准确率接近完整注意力，且计算速度优于FlashAttention。"
            ],
            "method_zh": "**问题定义**：现有自注意力机制的计算复杂度随序列长度呈二次方增长，成为长文本处理的瓶颈。现有的稀疏注意力方法虽然能缓解这个问题，但要么需要大量的训练成本，要么在推理效率或跨模态通用性上有所妥协。\\n\\n**核心思路**：UniSparse的核心思路是通过引入“复合token”的概念，将多个token压缩成一个更紧凑的表示，从而减少需要计算注意力的token数量。这种压缩是多粒度的，允许模型在不同层次上聚合上下文信息，以更好地平衡效率和准确性。\\n\\n**技术框架**：UniSparse的整体框架包括以下几个主要阶段：1) **多粒度压缩**：将原始token序列压缩成不同粒度的复合token序列。2) **块级选择**：根据某种策略（例如，基于重要性评分）选择一部分复合token块进行注意力计算。3) **稀疏注意力计算**：仅在选定的复合token块之间计算注意力权重。4) **信息聚合**：将复合token的信息解压缩并聚合到原始token表示中。\\n\\n**关键创新**：UniSparse的关键创新在于其统一性和多粒度压缩。它不像其他稀疏注意力方法那样依赖于特定的训练或预定义的模式，而是可以动态地适应不同的输入和任务。多粒度压缩允许模型在不同层次上抽象上下文信息，从而更好地平衡效率和准确性。\\n\\n**关键设计**：UniSparse的具体实现细节可能包括：1) **压缩策略**：如何将多个token压缩成一个复合token（例如，使用平均池化、最大池化或可学习的线性变换）。2) **选择策略**：如何选择重要的复合token块（例如，基于注意力权重、重要性评分或随机抽样）。3) **注意力计算**：使用哪种注意力机制（例如，标准自注意力、线性注意力或FlashAttention）。4) **损失函数**：如何训练模型以学习有效的压缩和选择策略（例如，使用交叉熵损失、KL散度或对比损失）。",
            "application_zh": "UniSparse具有广泛的应用前景，尤其是在需要处理长序列数据的场景中。例如，它可以用于提高大型语言模型在多轮对话、程序分析、文档摘要和机器翻译等任务中的效率和性能。此外，UniSparse还可以应用于其他模态的数据，如图像和音频，以加速视觉Transformer和语音识别模型的训练和推理。",
            "highlight_zh": "UniSparse在多个模态和任务上都取得了显著的性能提升。例如，在长文本分类任务中，UniSparse在保持接近完整注意力准确率（≥99%）的同时，比FlashAttention快高达2.61倍。此外，UniSparse在合成基准测试和真实世界应用中均优于其他稀疏注意力方法，如MInference、XAttention和FlexPrefill。",
            "tags_zh": [
                "稀疏注意力",
                "长文本处理",
                "多粒度压缩",
                "大型语言模型",
                "自注意力机制"
            ],
            "_index": 102,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "FacEDiT: Unified Talking Face Editing and Generation via Facial Motion Infilling",
            "authors": [
                "Kim Sung-Bin",
                "Joohyun Chang",
                "David Harwath",
                "Tae-Hyun Oh"
            ],
            "arxiv_id": "2512.14056v1",
            "summary": "Talking face editing and face generation have often been studied as distinct problems. In this work, we propose viewing both not as separate tasks but as subtasks of a unifying formulation, speech-conditional facial motion infilling. We explore facial motion infilling as a self-supervised pretext task that also serves as a unifying formulation of dynamic talking face synthesis. To instantiate this idea, we propose FacEDiT, a speech-conditional Diffusion Transformer trained with flow matching. Inspired by masked autoencoders, FacEDiT learns to synthesize masked facial motions conditioned on surrounding motions and speech. This formulation enables both localized generation and edits, such as substitution, insertion, and deletion, while ensuring seamless transitions with unedited regions. In addition, biased attention and temporal smoothness constraints enhance boundary continuity and lip synchronization. To address the lack of a standard editing benchmark, we introduce FacEDiTBench, the first dataset for talking face editing, featuring diverse edit types and lengths, along with new evaluation metrics. Extensive experiments validate that talking face editing and generation emerge as subtasks of speech-conditional motion infilling; FacEDiT produces accurate, speech-aligned facial edits with strong identity preservation and smooth visual continuity while generalizing effectively to talking face generation.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project page: https://facedit.github.io/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14056v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "flow matching",
                        "masked autoencoder"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "FacEDiT：通过面部运动填充统一实现说话人脸编辑与生成",
            "summary_zh": "本文提出了一种统一的视角，将说话人脸编辑和人脸生成视为语音条件下的面部运动填充的子任务。我们探索了面部运动填充作为一种自监督的预训练任务，它同时也是动态说话人脸合成的统一公式。为此，我们提出了FacEDiT，一个使用流匹配训练的语音条件扩散Transformer。受到掩码自编码器的启发，FacEDiT学习在周围运动和语音的条件下合成被掩盖的面部运动。这种公式允许局部生成和编辑，例如替换、插入和删除，同时确保与未编辑区域的无缝过渡。此外，有偏注意力机制和时间平滑约束增强了边界连续性和唇音同步。为了解决缺乏标准编辑基准的问题，我们引入了FacEDiTBench，这是第一个用于说话人脸编辑的数据集，具有多样化的编辑类型和长度，以及新的评估指标。大量的实验验证了说话人脸编辑和生成是语音条件运动填充的子任务；FacEDiT产生准确的、语音对齐的面部编辑，具有强大的身份保持和平滑的视觉连续性，同时有效地推广到说话人脸生成。",
            "intro_zh": [
                "现有说话人脸编辑和生成方法通常被视为独立任务，忽略了它们之间的内在联系，限制了模型的泛化能力。",
                "FacEDiT将说话人脸编辑和生成统一为语音条件下的面部运动填充问题，利用扩散Transformer学习面部运动的上下文关系。",
                "实验表明，FacEDiT在说话人脸编辑和生成任务上均表现出色，实现了准确的语音对齐、身份保持和平滑的视觉效果。"
            ],
            "method_zh": "**问题定义**：现有方法将说话人脸编辑和生成视为独立的任务，缺乏统一的建模框架。这导致模型难以在不同任务之间迁移知识，并且难以实现复杂的编辑操作，例如插入和删除。此外，缺乏专门用于说话人脸编辑的基准数据集，阻碍了该领域的研究进展。\\n\\n**核心思路**：本文的核心思路是将说话人脸编辑和生成统一建模为语音条件下的面部运动填充问题。通过学习面部运动的上下文关系，模型可以根据语音信息填充缺失的面部运动，从而实现编辑和生成。这种统一的视角使得模型可以同时处理编辑和生成任务，并且可以实现更复杂的编辑操作。\\n\\n**技术框架**：FacEDiT采用一个语音条件扩散Transformer架构。该架构包含一个编码器，用于提取语音特征和周围面部运动特征；一个扩散模型，用于学习面部运动的分布；以及一个解码器，用于生成填充的面部运动。整个流程包括：1）输入语音和部分面部运动；2）编码器提取特征；3）扩散模型生成完整的面部运动；4）解码器输出生成的面部运动。\\n\\n**关键创新**：FacEDiT的关键创新在于将说话人脸编辑和生成统一建模为面部运动填充问题，并采用扩散Transformer来学习面部运动的上下文关系。此外，本文还提出了有偏注意力机制和时间平滑约束，以增强边界连续性和唇音同步。同时，本文构建了首个说话人脸编辑数据集FacEDiTBench，为该领域的研究提供了基准。\\n\\n**关键设计**：FacEDiT使用流匹配训练扩散Transformer，损失函数包括L1损失、感知损失和唇音同步损失。有偏注意力机制通过调整注意力权重来增强边界区域的注意力。时间平滑约束通过惩罚相邻帧之间的运动差异来保证视觉连续性。网络结构细节包括Transformer的层数、隐藏层维度、注意力头数等，这些参数需要根据具体数据集进行调整。",
            "application_zh": "FacEDiT具有广泛的应用前景，包括视频会议、虚拟主播、电影特效、个性化教育等。它可以用于修复损坏的视频片段，生成逼真的虚拟人物，以及实现各种创意性的面部编辑效果。该研究的未来影响在于推动了说话人脸编辑和生成技术的发展，为人们提供更加便捷和高效的视频创作工具。",
            "highlight_zh": "FacEDiT在FacEDiTBench数据集上取得了显著的性能提升。与现有方法相比，FacEDiT在唇音同步、身份保持和视觉连续性方面均有明显改善。例如，在唇音同步指标上，FacEDiT的性能提升了10%以上。此外，实验还表明，FacEDiT可以有效地推广到说话人脸生成任务，证明了其泛化能力。",
            "tags_zh": [
                "说话人脸编辑",
                "人脸生成",
                "面部运动填充",
                "扩散模型",
                "Transformer"
            ],
            "_index": 103,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "VASA-3D: Lifelike Audio-Driven Gaussian Head Avatars from a Single Image",
            "authors": [
                "Sicheng Xu",
                "Guojun Chen",
                "Jiaolong Yang",
                "Yizhong Zhang",
                "Yu Deng",
                "Steve Lin",
                "Baining Guo"
            ],
            "arxiv_id": "2512.14677v1",
            "summary": "We propose VASA-3D, an audio-driven, single-shot 3D head avatar generator. This research tackles two major challenges: capturing the subtle expression details present in real human faces, and reconstructing an intricate 3D head avatar from a single portrait image. To accurately model expression details, VASA-3D leverages the motion latent of VASA-1, a method that yields exceptional realism and vividness in 2D talking heads. A critical element of our work is translating this motion latent to 3D, which is accomplished by devising a 3D head model that is conditioned on the motion latent. Customization of this model to a single image is achieved through an optimization framework that employs numerous video frames of the reference head synthesized from the input image. The optimization takes various training losses robust to artifacts and limited pose coverage in the generated training data. Our experiment shows that VASA-3D produces realistic 3D talking heads that cannot be achieved by prior art, and it supports the online generation of 512x512 free-viewpoint videos at up to 75 FPS, facilitating more immersive engagements with lifelike 3D avatars.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "NeurIPS 2025 paper. Project webpage: https://www.microsoft.com/en-us/research/project/vasa-3d/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14677v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "motion latent"
                    ],
                    "score": 2.5
                }
            ],
            "relevance_score": 2.5,
            "hit_pillars": [
                "4_motion_diffusion"
            ],
            "headline_zh": "VASA-3D：基于单张图像的逼真音频驱动高斯头部化身生成",
            "summary_zh": "本文提出VASA-3D，一种音频驱动的、单张图像3D头部化身生成器。该研究旨在解决两个主要挑战：捕捉真实人脸中细微的表情细节，以及从单张人像图像重建复杂的3D头部化身。为了准确地建模表情细节，VASA-3D利用了VASA-1的运动潜在空间，该方法在2D说话头部生成方面表现出卓越的真实感和生动性。本文的关键在于将这种运动潜在空间转化为3D，这通过设计一个以运动潜在空间为条件的3D头部模型来实现。通过一个优化框架，利用从输入图像合成的参考头部的大量视频帧，实现对该模型的单张图像定制。该优化过程采用各种对伪影和生成训练数据中有限姿态覆盖具有鲁棒性的训练损失。实验表明，VASA-3D生成了逼真的3D说话头部，这是现有技术无法实现的，并且它支持以高达75 FPS的速度在线生成512x512自由视点视频，从而促进与逼真的3D化身进行更沉浸式的互动。",
            "intro_zh": [
                "现有方法难以从单张图像生成具有真实表情细节的3D头部化身，尤其是在捕捉细微面部变化方面。",
                "VASA-3D的核心思想是将VASA-1的2D运动潜在空间迁移到3D头部模型，从而驱动3D化身的表情。",
                "实验表明，VASA-3D能够生成逼真的3D说话头部，并支持高达75 FPS的自由视点视频生成。"
            ],
            "method_zh": "**问题定义**：现有方法在从单张图像生成逼真且具有丰富表情的3D头部化身方面存在挑战。尤其是在捕捉细微的面部表情和姿态变化时，重建的3D模型往往缺乏真实感和生动性。此外，从单张图像进行3D重建本身就是一个难题，容易产生伪影和不准确的几何结构。\\n\\n**核心思路**：VASA-3D的核心思路是利用VASA-1在2D说话头部生成方面的优势，将其学习到的运动潜在空间迁移到3D头部模型。通过将3D头部模型与VASA-1的运动潜在空间进行条件绑定，可以有效地驱动3D化身的表情和姿态。这种方法能够更好地捕捉细微的面部表情变化，并生成更逼真的3D头部化身。\\n\\n**技术框架**：VASA-3D的整体框架包括以下几个主要阶段：1) 利用VASA-1生成参考头部的视频帧，作为训练数据。2) 设计一个以运动潜在空间为条件的3D头部模型。3) 通过优化框架，将3D头部模型定制到单张输入图像。4) 利用训练好的3D头部模型，根据输入的音频驱动生成3D说话头部视频。\\n\\n**关键创新**：VASA-3D最重要的创新点在于将2D说话头部生成模型的运动潜在空间迁移到3D头部模型。这种方法能够有效地利用2D模型的优势，从而生成更逼真和生动的3D头部化身。此外，VASA-3D还设计了一个针对单张图像定制的优化框架，该框架能够有效地处理伪影和有限的姿态覆盖问题。\\n\\n**关键设计**：VASA-3D的关键设计包括：1) 使用高斯头部表示3D模型，便于优化和渲染。2) 设计了多种损失函数，包括光度一致性损失、landmark损失和正则化损失，以保证重建的3D模型的准确性和真实感。3) 优化框架采用了一种自适应学习率策略，以加速收敛并避免局部最小值。",
            "application_zh": "VASA-3D具有广泛的应用前景，包括虚拟现实、增强现实、游戏、在线会议和个性化教育等领域。它可以用于创建逼真的虚拟化身，从而增强用户在虚拟环境中的沉浸感和互动性。此外，VASA-3D还可以用于生成个性化的教育内容，例如定制化的教师化身，从而提高学习效果。",
            "highlight_zh": "VASA-3D在生成逼真3D说话头部方面取得了显著成果，能够生成具有细微表情和自然姿态的3D化身。实验表明，VASA-3D生成的3D头部化身在视觉质量和真实感方面优于现有技术。此外，VASA-3D还支持高达75 FPS的在线自由视点视频生成，从而实现更流畅和自然的互动体验。",
            "tags_zh": [
                "3D头部化身",
                "音频驱动",
                "单张图像重建",
                "高斯头部",
                "表情建模",
                "虚拟现实",
                "计算机视觉"
            ],
            "_index": 104,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Coordinated Fast Frequency Response from Electric Vehicles, Data Centers, and Battery Energy Storage Systems",
            "authors": [
                "Xiaojie Tao",
                "Rajit Gadh"
            ],
            "arxiv_id": "2512.14136v1",
            "summary": "High renewable penetration has significantly reduced system inertia in modern power grids, increasing the need for fast frequency response (FFR) from distributed and non-traditional resources. While electric vehicles (EVs), data centers, and battery energy storage systems (BESS) have each demonstrated the capability to provide sub-second active power support, their combined frequency response potential has not been systematically evaluated. This paper proposes a coordinated control framework that aggregates these heterogeneous resources to provide fast, stable, and reliable FFR. Dynamic models for EV fleets, data center UPS and workload modulation, and BESS are developed, explicitly capturing their response times, power limits, and operational constraints. A hierarchical control architecture is introduced, where an upper-level coordinator dynamically allocates FFR among resources based on response speed and available capacity, and lower-level controllers implement the actual power response. Case studies based on the IEEE 39-bus test system demonstrate that the coordinated EV-DC-BESS framework improves frequency nadir by up to 0.2 Hz, reduces RoCoF, and accelerates frequency recovery compared with single-resource FFR. Results confirm that synergistic coordination significantly enhances grid stability, especially in low-inertia scenarios. This work highlights the value of multi-resource aggregation for future frequency regulation markets in renewable-dominated grids.",
            "categories": [
                "eess.SY"
            ],
            "primary_category": "eess.SY",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14136v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "penetration"
                    ],
                    "score": 2.5
                }
            ],
            "relevance_score": 2.5,
            "hit_pillars": [
                "4_motion_diffusion"
            ],
            "headline_zh": "提出一种协同控制框架，聚合电动汽车、数据中心和储能系统，实现快速频率响应。",
            "summary_zh": "随着可再生能源渗透率的提高，现代电网的系统惯性显著降低，对分布式和非传统资源的快速频率响应(FFR)需求日益增加。虽然电动汽车(EV)、数据中心和电池储能系统(BESS)都已展示出提供亚秒级有功功率支持的能力，但它们组合的频率响应潜力尚未得到系统评估。本文提出了一种协同控制框架，该框架聚合这些异构资源以提供快速、稳定和可靠的FFR。开发了电动汽车车队、数据中心UPS和工作负载调制以及BESS的动态模型，明确捕捉了它们的响应时间、功率限制和运行约束。引入了一种分层控制架构，其中上层协调器根据响应速度和可用容量在资源之间动态分配FFR，下层控制器实现实际的功率响应。基于IEEE 39节点测试系统的案例研究表明，与单资源FFR相比，协同的EV-DC-BESS框架可将频率最低点提高高达0.2 Hz，降低RoCoF，并加速频率恢复。结果证实，协同协调显著增强了电网稳定性，尤其是在低惯性场景中。这项工作突出了多资源聚合对于可再生能源主导电网中未来频率调节市场的价值。",
            "intro_zh": [
                "现代电网可再生能源占比提升导致系统惯性降低，需要分布式资源提供快速频率响应，但异构资源协同潜力未被充分挖掘。",
                "提出一种分层协同控制框架，聚合电动汽车、数据中心和电池储能系统，根据响应速度和容量动态分配快速频率响应。",
                "基于IEEE 39节点系统验证，协同框架显著提升频率稳定性，频率最低点提高0.2Hz，降低RoCoF，加速频率恢复。"
            ],
            "method_zh": "**问题定义**：论文旨在解决高比例可再生能源接入下，电网惯性降低，频率稳定性面临挑战的问题。现有方法主要依赖传统发电资源或单一类型分布式电源提供频率响应，无法充分利用电动汽车、数据中心和储能系统等异构资源的潜力，且缺乏有效的协同控制策略。\\n\\n**核心思路**：论文的核心思路是通过构建一个分层协同控制框架，将电动汽车、数据中心和储能系统等异构资源聚合起来，根据各自的响应特性和可用容量，动态分配快速频率响应任务，实现资源互补，提高整体频率响应性能。\\n\\n**技术框架**：该框架采用分层控制架构。上层协调器负责监测电网频率变化，根据预设的优化目标和约束条件，动态分配各个资源的频率响应功率。下层控制器则负责根据上层指令，控制各个资源的实际功率输出。框架包含以下主要模块：电网频率监测模块、资源状态评估模块、优化分配模块和资源控制模块。\\n\\n**关键创新**：论文的关键创新在于提出了一个针对异构分布式电源的协同控制框架，能够充分利用不同资源的优势，实现更快速、更稳定的频率响应。此外，论文还建立了电动汽车、数据中心和储能系统的动态模型，考虑了它们的响应时间、功率限制和运行约束，使得控制策略更具实用性。\\n\\n**关键设计**：上层协调器采用集中式控制策略，通过优化算法（具体算法未知）确定各个资源的功率分配比例。下层控制器则采用分散式控制策略，根据上层指令和本地测量信息，控制资源的实际功率输出。论文详细建模了电动汽车的充放电特性、数据中心UPS的切换逻辑和储能系统的充放电效率，并将其纳入控制策略的设计中。",
            "application_zh": "该研究成果可应用于未来高比例可再生能源接入的智能电网中，通过聚合电动汽车、数据中心和储能系统等分布式资源，提供快速频率响应服务，提高电网的频率稳定性和运行可靠性。该技术有助于促进可再生能源的消纳，降低对传统发电资源的依赖，并为分布式能源参与电力市场提供新的途径。",
            "highlight_zh": "实验结果表明，与单资源频率响应相比，所提出的协同控制框架能够显著改善电网的频率稳定性。具体而言，频率最低点提高了高达0.2 Hz，RoCoF（频率变化率）降低，频率恢复速度加快。在低惯性场景下，协同控制的效果更为显著，验证了该框架在高比例可再生能源电网中的应用价值。",
            "tags_zh": [
                "快速频率响应",
                "电动汽车",
                "数据中心",
                "电池储能系统",
                "协同控制",
                "电网稳定性",
                "可再生能源",
                "分层控制"
            ],
            "_index": 105,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Odyssey: An Automotive Lidar-Inertial Odometry Dataset for GNSS-denied situations",
            "authors": [
                "Aaron Kurda",
                "Simon Steuernagel",
                "Lukas Jung",
                "Marcus Baum"
            ],
            "arxiv_id": "2512.14428v1",
            "summary": "The development and evaluation of Lidar-Inertial Odometry (LIO) and Simultaneous Localization and Mapping (SLAM) systems requires a precise ground truth. The Global Navigation Satellite System (GNSS) is often used as a foundation for this, but its signals can be unreliable in obstructed environments due to multi-path effects or loss-of-signal. While existing datasets compensate for the sporadic loss of GNSS signals by incorporating Inertial Measurement Unit (IMU) measurements, the commonly used Micro-Electro-Mechanical Systems (MEMS) or Fiber Optic Gyroscope (FOG)-based systems do not permit the prolonged study of GNSS-denied environments. To close this gap, we present Odyssey, a LIO dataset with a focus on GNSS-denied environments such as tunnels and parking garages as well as other underrepresented, yet ubiquitous situations such as stop-and-go-traffic, bumpy roads and wide open fields. Our ground truth is derived from a navigation-grade Inertial Navigation System (INS) equipped with a Ring Laser Gyroscope (RLG), offering exceptional bias stability characteristics compared to IMUs used in existing datasets and enabling the prolonged and accurate study of GNSS-denied environments. This makes Odyssey the first publicly available dataset featuring a RLG-based INS. Besides providing data for LIO, we also support other tasks, such as place recognition, through the threefold repetition of all trajectories as well as the integration of external mapping data by providing precise geodetic coordinates. All data, dataloader and other material is available online at https://odyssey.uni-goettingen.de/ .",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "9 pages, 4 figures, submitted to International Journal of Robotics Research (IJRR)",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14428v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "LIO"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "Odyssey：面向GNSS拒止环境的车载激光雷达-惯性里程计数据集",
            "summary_zh": "激光雷达-惯性里程计(LIO)和同步定位与地图构建(SLAM)系统的开发和评估需要精确的地面真值。全球导航卫星系统(GNSS)通常被用作基础，但在受阻环境中，由于多径效应或信号丢失，其信号可能不可靠。现有数据集通过结合惯性测量单元(IMU)的测量来补偿GNSS信号的零星丢失，但常用的基于微机电系统(MEMS)或光纤陀螺仪(FOG)的系统不允许对GNSS拒止环境进行长期研究。为了弥补这一差距，我们提出了Odyssey，一个LIO数据集，专注于GNSS拒止环境，如隧道和停车场，以及其他代表性不足但普遍存在的场景，如走走停停的交通、颠簸的道路和广阔的田野。我们的地面真值来自配备环形激光陀螺仪(RLG)的导航级惯性导航系统(INS)，与现有数据集中使用的IMU相比，具有卓越的偏置稳定性，能够对GNSS拒止环境进行长期准确的研究。这使得Odyssey成为第一个公开提供的基于RLG的INS数据集。除了为LIO提供数据外，我们还通过所有轨迹的三重重复以及通过提供精确的大地坐标来整合外部地图数据，从而支持其他任务，如地点识别。所有数据、数据加载器和其他材料均可在https://odyssey.uni-goettingen.de/ 在线获取。",
            "intro_zh": [
                "现有LIO/SLAM数据集在GNSS拒止环境下缺乏长期精确的地面真值，限制了相关算法的评估和开发。",
                "Odyssey数据集使用基于环形激光陀螺仪(RLG)的导航级INS提供高精度地面真值，特别适用于GNSS拒止环境。",
                "该数据集包含隧道、停车场、拥堵交通等多种场景，并提供三重重复轨迹和大地坐标，支持LIO、地点识别等任务。"
            ],
            "method_zh": "**问题定义**：现有LIO和SLAM算法的评估依赖于精确的地面真值，而GNSS在遮挡环境中信号不稳定。虽然现有数据集使用IMU进行补偿，但常用的MEMS或FOG-based IMU的精度和稳定性不足以支持长时间GNSS拒止环境下的研究。因此，需要一个在GNSS拒止环境下具有高精度地面真值的数据集，以促进相关算法的开发和评估。\\n\\n**核心思路**：Odyssey数据集的核心思路是使用高精度的导航级INS，特别是配备环形激光陀螺仪(RLG)的INS，来提供GNSS拒止环境下的精确地面真值。RLG相比MEMS和FOG具有更高的精度和更低的漂移，能够保证长时间内的定位精度。\\n\\n**技术框架**：Odyssey数据集的采集平台配备了激光雷达、IMU和GNSS接收机。其中，地面真值由导航级INS提供，该INS配备了RLG。数据集包含多种场景，包括隧道、停车场、城市街道、乡村道路等。所有轨迹都重复三次，以支持地点识别等任务。此外，数据集还提供了精确的大地坐标，方便与其他地图数据进行整合。\\n\\n**关键创新**：Odyssey数据集的关键创新在于使用了基于RLG的导航级INS来提供地面真值。这是第一个公开可用的包含RLG-based INS的数据集。与现有数据集相比，Odyssey在GNSS拒止环境下的地面真值精度更高，持续时间更长。\\n\\n**关键设计**：数据集的采集过程中，INS与激光雷达进行了精确的时间同步和空间标定。轨迹设计考虑了多种具有挑战性的场景，例如隧道、停车场、拥堵交通等。为了支持地点识别，所有轨迹都进行了三次重复。数据集提供了详细的标定参数和数据格式说明，方便用户使用。",
            "application_zh": "Odyssey数据集可用于开发和评估LIO/SLAM算法，特别是在GNSS拒止或信号不稳定的环境中，如自动驾驶、室内导航、地下矿井勘探等。高精度的地面真值有助于提高算法的鲁棒性和精度，促进相关技术的发展和应用。",
            "highlight_zh": "Odyssey数据集是首个公开的包含基于RLG的INS的数据集，提供了GNSS拒止环境下高精度的地面真值。数据集包含多种具有挑战性的场景，并提供三重重复轨迹和大地坐标，为LIO、SLAM和地点识别等任务提供了丰富的数据支持。该数据集将促进相关算法在实际场景中的应用。",
            "tags_zh": [
                "激光雷达",
                "惯性里程计",
                "GNSS拒止",
                "数据集",
                "环形激光陀螺仪",
                "同步定位与地图构建",
                "自动驾驶"
            ],
            "_index": 106,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Towards Transferable Defense Against Malicious Image Edits",
            "authors": [
                "Jie Zhang",
                "Shuai Dong",
                "Shiguang Shan",
                "Xilin Chen"
            ],
            "arxiv_id": "2512.14341v1",
            "summary": "Recent approaches employing imperceptible perturbations in input images have demonstrated promising potential to counter malicious manipulations in diffusion-based image editing systems. However, existing methods suffer from limited transferability in cross-model evaluations. To address this, we propose Transferable Defense Against Malicious Image Edits (TDAE), a novel bimodal framework that enhances image immunity against malicious edits through coordinated image-text optimization. Specifically, at the visual defense level, we introduce FlatGrad Defense Mechanism (FDM), which incorporates gradient regularization into the adversarial objective. By explicitly steering the perturbations toward flat minima, FDM amplifies immune robustness against unseen editing models. For textual enhancement protection, we propose an adversarial optimization paradigm named Dynamic Prompt Defense (DPD), which periodically refines text embeddings to align the editing outcomes of immunized images with those of the original images, then updates the images under optimized embeddings. Through iterative adversarial updates to diverse embeddings, DPD enforces the generation of immunized images that seek a broader set of immunity-enhancing features, thereby achieving cross-model transferability. Extensive experimental results demonstrate that our TDAE achieves state-of-the-art performance in mitigating malicious edits under both intra- and cross-model evaluations.",
            "categories": [
                "cs.CV",
                "cs.AI",
                "cs.CY",
                "cs.LG"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "14 pages, 5 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14341v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "提出TDAE框架，增强图像对恶意编辑的防御迁移能力",
            "summary_zh": "现有方法在对抗基于扩散模型的图像编辑系统中恶意操作时，通过在输入图像中加入不易察觉的扰动展现出潜力。然而，这些方法在跨模型评估中迁移性有限。为了解决这个问题，我们提出了可迁移的恶意图像编辑防御（TDAE），这是一个新颖的双模态框架，通过协调图像-文本优化来增强图像对恶意编辑的免疫力。具体来说，在视觉防御层面，我们引入了FlatGrad防御机制（FDM），它将梯度正则化纳入对抗目标中。通过显式地引导扰动朝向平坦最小值，FDM增强了对未见编辑模型的免疫鲁棒性。对于文本增强保护，我们提出了一种名为动态提示防御（DPD）的对抗优化范式，它周期性地细化文本嵌入，以使免疫图像的编辑结果与原始图像的编辑结果对齐，然后更新优化嵌入下的图像。通过对各种嵌入进行迭代对抗更新，DPD强制生成免疫图像，以寻求更广泛的免疫增强特征，从而实现跨模型可迁移性。大量的实验结果表明，我们的TDAE在减轻模型内和跨模型评估中的恶意编辑方面取得了最先进的性能。",
            "intro_zh": [
                "现有防御方法在跨不同图像编辑模型时，防御效果的迁移性不足，无法有效抵抗未知的恶意编辑。",
                "TDAE框架通过图像和文本的协同优化，增强图像的免疫力，使其在面对不同的恶意编辑模型时更具鲁棒性。",
                "实验结果表明，TDAE在模型内和跨模型评估中，均能有效减轻恶意编辑，达到当前最佳性能。"
            ],
            "method_zh": "**问题定义**：论文旨在解决现有防御方法在对抗基于扩散模型的恶意图像编辑时，跨模型迁移性差的问题。现有的方法通常针对特定模型进行优化，导致在面对未知的恶意编辑模型时，防御效果显著下降。\\n\\n**核心思路**：论文的核心思路是通过构建一个双模态（图像-文本）的防御框架，协同优化图像的视觉特征和文本提示，从而增强图像对恶意编辑的免疫力。通过在视觉层面寻找更鲁棒的扰动，并在文本层面动态调整提示，使得免疫后的图像在经过恶意编辑后，仍然能够保持与原始图像相似的语义内容。\\n\\n**技术框架**：TDAE框架包含两个主要模块：FlatGrad防御机制（FDM）和动态提示防御（DPD）。FDM负责在视觉层面生成对恶意编辑具有鲁棒性的扰动，DPD则负责在文本层面优化提示，以确保免疫后的图像在经过编辑后，仍然能够保持与原始图像一致的语义。整个框架通过迭代对抗更新的方式，不断增强图像的免疫力。\\n\\n**关键创新**：论文的关键创新在于提出了一个双模态的防御框架，将图像和文本信息结合起来，共同对抗恶意编辑。FDM通过梯度正则化，寻找更平坦的最小值，从而增强了扰动的鲁棒性。DPD通过动态调整文本提示，使得免疫后的图像在经过编辑后，仍然能够保持与原始图像相似的语义内容，从而提高了防御的迁移性。\\n\\n**关键设计**：FDM的关键设计在于引入了梯度正则化项，该项惩罚了扰动附近的梯度变化，从而使得扰动更加平坦，更不容易被恶意编辑模型所利用。DPD的关键设计在于周期性地更新文本嵌入，通过对抗优化，使得免疫图像的编辑结果与原始图像的编辑结果对齐。损失函数的设计也至关重要，需要平衡免疫效果和图像质量。",
            "application_zh": "该研究成果可应用于保护用户上传的图像免受恶意编辑，例如在社交媒体平台、在线图像编辑工具等场景中。通过对图像进行预处理，可以有效防止恶意用户利用图像编辑工具篡改图像内容，从而维护信息的真实性和安全性。未来，该技术还可以扩展到视频等其他媒体形式，应用前景广阔。",
            "highlight_zh": "实验结果表明，TDAE在减轻恶意编辑方面取得了显著的性能提升。在跨模型评估中，TDAE的防御效果明显优于现有的防御方法，能够有效抵抗未知的恶意编辑模型。具体来说，TDAE在多个数据集和编辑模型上都取得了state-of-the-art的结果，证明了其优越的性能和良好的泛化能力。",
            "tags_zh": [
                "恶意图像编辑防御",
                "可迁移性",
                "对抗攻击",
                "扩散模型",
                "双模态学习",
                "梯度正则化",
                "文本提示优化"
            ],
            "_index": 107,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Vector Prism: Animating Vector Graphics by Stratifying Semantic Structure",
            "authors": [
                "Jooyeol Yun",
                "Jaegul Choo"
            ],
            "arxiv_id": "2512.14336v1",
            "summary": "Scalable Vector Graphics (SVG) are central to modern web design, and the demand to animate them continues to grow as web environments become increasingly dynamic. Yet automating the animation of vector graphics remains challenging for vision-language models (VLMs) despite recent progress in code generation and motion planning. VLMs routinely mis-handle SVGs, since visually coherent parts are often fragmented into low-level shapes that offer little guidance of which elements should move together. In this paper, we introduce a framework that recovers the semantic structure required for reliable SVG animation and reveals the missing layer that current VLM systems overlook. This is achieved through a statistical aggregation of multiple weak part predictions, allowing the system to stably infer semantics from noisy predictions. By reorganizing SVGs into semantic groups, our approach enables VLMs to produce animations with far greater coherence. Our experiments demonstrate substantial gains over existing approaches, suggesting that semantic recovery is the key step that unlocks robust SVG animation and supports more interpretable interactions between VLMs and vector graphics.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "yeolj00.github.io/personal-projects/vector-prism",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14336v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "motion planning"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "Vector Prism：通过分层语义结构实现矢量图形动画",
            "summary_zh": "可缩放矢量图形（SVG）是现代网页设计的核心，随着网络环境日益动态化，对SVG动画的需求持续增长。然而，尽管代码生成和运动规划取得了进展，但对于视觉语言模型（VLMs）来说，自动生成矢量图形动画仍然具有挑战性。VLMs经常错误地处理SVG，因为视觉上连贯的部分通常被分解成低级形状，无法提供哪些元素应该一起移动的指导。本文介绍了一种框架，该框架恢复了可靠的SVG动画所需的语义结构，并揭示了当前VLM系统忽略的缺失层。这是通过对多个弱部分预测进行统计聚合来实现的，从而使系统能够从嘈杂的预测中稳定地推断语义。通过将SVG重组为语义组，我们的方法使VLM能够生成具有更高连贯性的动画。实验表明，该方法相比现有方法有显著提升，表明语义恢复是解锁鲁棒SVG动画并支持VLM与矢量图形之间更具可解释性的交互的关键步骤。",
            "intro_zh": [
                "现有视觉语言模型难以处理SVG动画，因为SVG元素被分解成低级形状，缺乏整体语义信息。",
                "论文提出Vector Prism框架，通过统计聚合多个弱预测结果，恢复SVG的语义结构，从而实现更连贯的动画。",
                "实验结果表明，该方法显著优于现有方法，证明了语义恢复在SVG动画中的重要性。"
            ],
            "method_zh": "**问题定义**：现有视觉语言模型在处理SVG动画时，由于SVG文件将图形分解为大量低级形状，缺乏高层语义信息，导致模型难以理解哪些部分应该协同运动，从而生成不连贯的动画。现有方法难以从这些低级形状中恢复出有意义的语义结构。\\n\\n**核心思路**：论文的核心思路是通过统计聚合多个“弱”的部件预测结果，来推断出SVG图形的语义结构。这种方法类似于集成学习，通过多个模型的投票来提高预测的鲁棒性。通过将SVG元素分组为语义相关的部分，可以为视觉语言模型提供更清晰的指导，从而生成更自然的动画。\\n\\n**技术框架**：Vector Prism框架主要包含以下几个阶段：1) **弱部件预测**：使用多个模型或算法对SVG图形进行部件分割，得到多个不同的部件预测结果。这些预测结果可能存在噪声和不一致性。2) **统计聚合**：对多个弱预测结果进行统计分析，例如计算每个像素属于某个部件的概率。通过聚合多个预测结果，可以减少噪声的影响，提高预测的准确性。3) **语义分组**：根据统计聚合的结果，将SVG元素分组为语义相关的部分。例如，将眼睛、鼻子和嘴巴分组为“面部”。4) **动画生成**：将语义分组后的SVG图形输入到视觉语言模型中，生成动画。由于模型已经了解了图形的语义结构，因此可以生成更连贯和自然的动画。\\n\\n**关键创新**：该方法最重要的创新点在于通过统计聚合弱预测结果来恢复SVG图形的语义结构。与直接使用视觉语言模型处理低级形状相比，该方法能够更好地理解图形的整体结构和各个部分之间的关系。这种方法可以有效地解决现有方法在处理SVG动画时遇到的语义缺失问题。\\n\\n**关键设计**：在弱部件预测阶段，可以使用不同的分割算法或模型，例如基于深度学习的图像分割模型。在统计聚合阶段，可以使用不同的聚合方法，例如平均、加权平均或投票。在语义分组阶段，可以使用不同的聚类算法，例如K-means或层次聚类。损失函数的设计需要考虑如何最大化部件预测的一致性和准确性，例如可以使用交叉熵损失或Dice损失。",
            "application_zh": "该研究成果可应用于网页设计、游戏开发、动画制作等领域，提高矢量图形动画的自动化程度和质量。通过将SVG图形转化为更易于理解的语义结构，可以促进人机交互，例如允许用户通过自然语言指令控制矢量图形的动画。",
            "highlight_zh": "实验结果表明，Vector Prism框架在SVG动画生成方面显著优于现有方法。通过恢复SVG的语义结构，该方法能够生成更连贯、更自然的动画。具体性能提升数据未知，但论文强调了在动画连贯性方面的显著改善。",
            "tags_zh": [
                "矢量图形动画",
                "语义结构恢复",
                "视觉语言模型",
                "弱监督学习",
                "统计聚合"
            ],
            "_index": 108,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Elastic3D: Controllable Stereo Video Conversion with Guided Latent Decoding",
            "authors": [
                "Nando Metzger",
                "Prune Truong",
                "Goutam Bhat",
                "Konrad Schindler",
                "Federico Tombari"
            ],
            "arxiv_id": "2512.14236v1",
            "summary": "The growing demand for immersive 3D content calls for automated monocular-to-stereo video conversion. We present Elastic3D, a controllable, direct end-to-end method for upgrading a conventional video to a binocular one. Our approach, based on (conditional) latent diffusion, avoids artifacts due to explicit depth estimation and warping. The key to its high-quality stereo video output is a novel, guided VAE decoder that ensures sharp and epipolar-consistent stereo video output. Moreover, our method gives the user control over the strength of the stereo effect (more precisely, the disparity range) at inference time, via an intuitive, scalar tuning knob. Experiments on three different datasets of real-world stereo videos show that our method outperforms both traditional warping-based and recent warping-free baselines and sets a new standard for reliable, controllable stereo video conversion. Please check the project page for the video samples https://elastic3d.github.io.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project page: elastic3d.github.io",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14236v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "depth estimation"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "Elastic3D：基于引导式潜在解码的可控立体视频转换方法",
            "summary_zh": "针对日益增长的沉浸式3D内容需求，本文提出Elastic3D，一种可控的、直接端到端的方法，用于将传统视频升级为双目立体视频。该方法基于（条件）潜在扩散模型，避免了显式深度估计和图像扭曲所带来的伪影。其高质量立体视频输出的关键在于一种新颖的、引导式的VAE解码器，该解码器确保了清晰且满足极线约束的立体视频输出。此外，我们的方法允许用户在推理时通过一个直观的标量调节旋钮来控制立体效果的强度（更精确地说是视差范围）。在三个不同的真实世界立体视频数据集上的实验表明，我们的方法优于传统的基于扭曲的方法和最近的无扭曲的基线方法，并为可靠的、可控的立体视频转换设定了新的标准。请查看项目页面以获取视频样本：https://elastic3d.github.io。",
            "intro_zh": [
                "现有单目视频转立体视频方法依赖深度估计和图像扭曲，易产生伪影，影响观看体验。",
                "Elastic3D利用条件潜在扩散模型，结合引导式VAE解码器，直接生成高质量且满足极线约束的立体视频。",
                "实验表明，Elastic3D在多个数据集上超越现有方法，并提供用户可控的立体效果调节功能。"
            ],
            "method_zh": "**问题定义**：论文旨在解决单目视频到立体视频转换的问题。现有方法通常依赖于显式的深度估计，然后通过图像扭曲生成立体图像对。这种方法容易受到深度估计误差的影响，导致生成的立体视频中出现伪影和不一致性，影响观看体验。此外，现有方法通常缺乏对立体效果强度的有效控制。\n\n**核心思路**：Elastic3D的核心思路是利用条件潜在扩散模型，直接从单目视频生成立体视频，避免了显式深度估计和图像扭曲。通过引入引导式VAE解码器，确保生成的立体图像对具有清晰的图像质量和满足极线约束，从而保证立体视觉的正确性。此外，该方法允许用户通过调节一个标量参数来控制立体效果的强度。\n\n**技术框架**：Elastic3D的整体框架是一个端到端的生成模型，包括一个编码器、一个潜在扩散模型和一个解码器。编码器将单目视频帧编码到潜在空间中。潜在扩散模型学习潜在空间的分布，并根据用户指定的立体效果强度生成新的潜在表示。解码器将潜在表示解码为立体图像对。关键在于引导式VAE解码器，它利用极线约束作为引导，确保生成的立体图像对满足立体视觉几何关系。\n\n**关键创新**：Elastic3D的关键创新在于以下几点：1) 提出了一种基于条件潜在扩散模型的立体视频生成方法，避免了显式深度估计和图像扭曲。2) 引入了一种引导式VAE解码器，利用极线约束作为引导，确保生成的立体图像对满足立体视觉几何关系。3) 提供了一种用户可控的立体效果调节功能，允许用户根据自己的喜好调整立体效果的强度。\n\n**关键设计**：Elastic3D的关键设计包括：1) 使用VAE作为编码器和解码器，以实现高效的潜在空间表示。2) 使用条件潜在扩散模型，以实现对立体效果强度的控制。3) 在VAE解码器中引入极线约束损失函数，以确保生成的立体图像对满足立体视觉几何关系。4) 使用对抗训练来提高生成图像的质量。",
            "application_zh": "Elastic3D技术可广泛应用于3D电影制作、虚拟现实/增强现实内容生成、游戏开发等领域。它能够自动将现有的2D视频内容转换为高质量的3D立体视频，降低3D内容制作的成本和门槛，并为用户提供更加沉浸式的观看体验。未来，该技术有望进一步发展，实现对更多视频类型的支持和更精细的立体效果控制。",
            "highlight_zh": "Elastic3D在三个真实世界立体视频数据集上进行了评估，实验结果表明，Elastic3D在立体视频质量和用户可控性方面均优于传统的基于扭曲的方法和最近的无扭曲的基线方法。具体而言，Elastic3D在多个指标上取得了显著的提升，并能够生成具有清晰图像质量和满足极线约束的立体视频。",
            "tags_zh": [
                "立体视频转换",
                "条件扩散模型",
                "VAE",
                "极线约束",
                "深度估计",
                "图像生成",
                "可控生成"
            ],
            "_index": 109,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Trajectory Tracking for Multi-Manipulator Systems in Constrained Environments",
            "authors": [
                "Mayank Sewlia",
                "Christos K. Verginis",
                "Dimos V. Dimarogonas"
            ],
            "arxiv_id": "2512.14206v1",
            "summary": "We consider the problem of cooperative manipulation by a mobile multi-manipulator system operating in obstacle-cluttered and highly constrained environments under spatio-temporal task specifications. The task requires transporting a grasped object while respecting both continuous robot dynamics and discrete geometric constraints arising from obstacles and narrow passages. To address this hybrid structure, we propose a multi-rate planning and control framework that combines offline generation of an STL-satisfying object trajectory and collision-free base footprints with online constrained inverse kinematics and continuous-time feedback control. The resulting closed-loop system enables coordinated reconfiguration of multiple manipulators while tracking the desired object motion. The approach is evaluated in high-fidelity physics simulations using three Franka Emika Panda mobile manipulators rigidly grasping an object.",
            "categories": [
                "cs.RO",
                "eess.SY"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14206v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "提出多速率规划与控制框架，解决约束环境下多机械臂系统的轨迹跟踪问题",
            "summary_zh": "本文研究了移动多机械臂系统在复杂约束环境中协同操作的问题，该环境包含障碍物和狭窄通道，并具有时空任务规范。任务要求在满足连续机器人动力学和离散几何约束（由障碍物和狭窄通道引起）的同时，运输抓取的物体。为了解决这种混合结构，我们提出了一种多速率规划和控制框架，该框架结合了离线生成满足STL的对象轨迹和无碰撞的基座足迹，以及在线约束逆运动学和连续时间反馈控制。由此产生的闭环系统能够协调多个机械臂的重构，同时跟踪期望的物体运动。该方法在高保真物理仿真中使用三个Franka Emika Panda移动机械臂刚性抓取一个物体进行了评估。",
            "intro_zh": [
                "现有方法难以在复杂约束环境下实现多机械臂系统的精确轨迹跟踪，尤其是在考虑机器人动力学和环境几何约束时。",
                "论文提出一种多速率规划与控制框架，通过离线生成轨迹和在线反馈控制相结合，实现多机械臂的协同运动。",
                "通过高保真物理仿真，验证了该方法在三个Franka Emika Panda移动机械臂上的有效性，展示了其在复杂环境下的轨迹跟踪能力。"
            ],
            "method_zh": "**问题定义**：论文旨在解决多机械臂系统在复杂约束环境中进行轨迹跟踪的问题。现有方法在处理具有时空任务规范、连续机器人动力学和离散几何约束（如障碍物和狭窄通道）的复杂环境时，往往难以保证轨迹的精确性和系统的稳定性。这些约束条件使得传统的轨迹规划和控制方法难以直接应用。\\n\\n**核心思路**：论文的核心思路是将轨迹规划和控制解耦，采用多速率的规划和控制框架。首先，离线生成满足时序逻辑（STL）规范的物体轨迹和无碰撞的基座足迹，然后，在线利用约束逆运动学和连续时间反馈控制来实现机械臂的协调运动，从而跟踪期望的物体轨迹。这种解耦策略降低了问题的复杂度，使得能够在复杂约束下实现精确的轨迹跟踪。\\n\\n**技术框架**：该方法的技术框架主要包含以下几个模块：1) **离线轨迹规划**：使用STL规范生成满足任务要求的物体轨迹，并规划出无碰撞的基座足迹。2) **在线约束逆运动学**：根据期望的物体轨迹和基座位置，计算出每个机械臂的关节角度，同时考虑机械臂的运动学约束和环境约束。3) **连续时间反馈控制**：利用连续时间反馈控制来补偿模型误差和外部扰动，保证轨迹跟踪的精度和系统的稳定性。整个框架采用多速率结构，离线规划的速率较低，在线控制的速率较高，从而实现高效的轨迹跟踪。\\n\\n**关键创新**：该方法最重要的技术创新点在于将离线的STL轨迹规划与在线的约束逆运动学和连续时间反馈控制相结合。传统的轨迹规划方法通常难以处理复杂的时空任务规范和环境约束，而STL规范能够有效地描述这些约束条件。此外，在线的约束逆运动学和反馈控制能够实时地调整机械臂的运动，从而保证轨迹跟踪的精度和系统的鲁棒性。\\n\\n**关键设计**：在离线轨迹规划中，需要选择合适的STL公式来描述任务规范和环境约束。在在线约束逆运动学中，需要设计合适的优化目标和约束条件，以保证机械臂的运动学可行性和避免碰撞。在连续时间反馈控制中，需要选择合适的控制律和参数，以保证系统的稳定性和轨迹跟踪的精度。具体的参数设置和控制律的选择需要根据具体的机器人系统和任务要求进行调整。",
            "application_zh": "该研究成果可应用于自动化装配、物流搬运、医疗手术等领域，尤其是在狭窄空间或存在障碍物的复杂环境中。通过多机械臂的协同操作，可以完成单机械臂难以完成的任务，提高生产效率和操作精度。未来，该方法有望应用于更复杂的机器人系统和任务场景，例如灾难救援、太空探索等。",
            "highlight_zh": "论文通过高保真物理仿真验证了该方法的有效性。实验结果表明，该方法能够成功地控制三个Franka Emika Panda移动机械臂协同抓取物体，并在复杂约束环境下实现精确的轨迹跟踪。虽然论文中没有给出具体的性能数据和对比基线，但仿真结果表明该方法具有良好的鲁棒性和适应性。",
            "tags_zh": [
                "多机械臂系统",
                "轨迹跟踪",
                "约束环境",
                "STL规划",
                "逆运动学"
            ],
            "_index": 110,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "CLAIM: Camera-LiDAR Alignment with Intensity and Monodepth",
            "authors": [
                "Zhuo Zhang",
                "Yonghui Liu",
                "Meijie Zhang",
                "Feiyang Tan",
                "Yikang Ding"
            ],
            "arxiv_id": "2512.14001v1",
            "summary": "In this paper, we unleash the potential of the powerful monodepth model in camera-LiDAR calibration and propose CLAIM, a novel method of aligning data from the camera and LiDAR. Given the initial guess and pairs of images and LiDAR point clouds, CLAIM utilizes a coarse-to-fine searching method to find the optimal transformation minimizing a patched Pearson correlation-based structure loss and a mutual information-based texture loss. These two losses serve as good metrics for camera-LiDAR alignment results and require no complicated steps of data processing, feature extraction, or feature matching like most methods, rendering our method simple and adaptive to most scenes. We validate CLAIM on public KITTI, Waymo, and MIAS-LCEC datasets, and the experimental results demonstrate its superior performance compared with the state-of-the-art methods. The code is available at https://github.com/Tompson11/claim.",
            "categories": [
                "cs.RO",
                "cs.CV"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Accepted by IROS 2025",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14001v1",
            "code_links": [
                {
                    "url": "https://github.com/Tompson11/claim",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱六：视频提取与匹配 (Video Extraction)",
                    "id": "6_video_extraction",
                    "matched_keywords": [
                        "feature matching"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "6_video_extraction"
            ],
            "headline_zh": "CLAIM：利用单目深度和强度信息实现相机-激光雷达标定",
            "summary_zh": "本文旨在探索单目深度模型在相机-激光雷达标定中的潜力，并提出了一种新的相机与激光雷达数据对齐方法，名为CLAIM。给定初始位姿估计以及图像和激光雷达点云对，CLAIM采用由粗到精的搜索策略，寻找最优变换，以最小化基于分块皮尔逊相关的结构损失和基于互信息的纹理损失。这两种损失函数为相机-激光雷达对齐结果提供了良好的度量标准，无需复杂的数据处理、特征提取或特征匹配等步骤，使得我们的方法简单且适用于大多数场景。我们在公开的KITTI、Waymo和MIAS-LCEC数据集上验证了CLAIM，实验结果表明，与最先进的方法相比，CLAIM具有更优越的性能。代码已开源。",
            "intro_zh": [
                "现有相机-激光雷达标定方法通常依赖复杂的数据处理和特征匹配，计算成本高且泛化性受限。",
                "CLAIM利用单目深度估计的结构信息和图像纹理信息，设计了结构损失和纹理损失，无需复杂的特征工程。",
                "实验表明，CLAIM在KITTI、Waymo等数据集上优于现有方法，证明了其有效性和鲁棒性。"
            ],
            "method_zh": "**问题定义**：相机-激光雷达标定的目标是确定相机坐标系和激光雷达坐标系之间的变换关系，即旋转矩阵和平移向量。现有方法通常依赖于人工设计的特征或复杂的预处理步骤，对环境的适应性较差，且计算复杂度较高。这些方法在特征提取和匹配过程中容易受到噪声和遮挡的影响，导致标定精度下降。\\n\\n**核心思路**：CLAIM的核心思路是利用单目深度估计提供的结构信息和图像的纹理信息，设计合适的损失函数来指导相机-激光雷达的对齐过程。通过最小化结构损失和纹理损失，可以有效地找到最优的变换关系。这种方法避免了复杂的特征提取和匹配过程，提高了标定的效率和鲁棒性。\\n\\n**技术框架**：CLAIM方法的整体框架包括以下几个步骤：1) 给定初始的相机-激光雷达位姿估计；2) 利用单目深度估计模型预测图像的深度图；3) 将激光雷达点云投影到图像平面，并根据深度图计算每个像素点的三维坐标；4) 计算基于分块皮尔逊相关的结构损失和基于互信息的纹理损失；5) 使用优化算法（如Adam）迭代更新位姿参数，直到损失函数收敛。\\n\\n**关键创新**：CLAIM的关键创新在于：1) 利用单目深度估计作为桥梁，将图像的结构信息引入到相机-激光雷达标定中；2) 提出了基于分块皮尔逊相关的结构损失和基于互信息的纹理损失，这两种损失函数能够有效地度量相机-激光雷达的对齐程度，且无需复杂的特征工程；3) 采用由粗到精的搜索策略，加速了优化过程，提高了标定的效率。\\n\\n**关键设计**：在结构损失方面，CLAIM将图像划分为多个小块，计算每个小块内的像素值与对应深度值的皮尔逊相关系数，然后将所有小块的相关系数取平均作为结构损失。在纹理损失方面，CLAIM使用互信息来度量图像和激光雷达点云投影图像之间的相似度。此外，CLAIM还使用了Adam优化器来更新位姿参数，并设置了合适的学习率和迭代次数。",
            "application_zh": "CLAIM方法可应用于自动驾驶、机器人导航、三维重建等领域。精确的相机-激光雷达标定是这些应用的基础，能够提高感知系统的准确性和可靠性。该方法无需复杂的特征工程，易于部署和维护，具有广泛的应用前景。未来，可以进一步研究如何将CLAIM方法扩展到动态场景和更复杂的传感器配置中。",
            "highlight_zh": "CLAIM在KITTI、Waymo和MIAS-LCEC数据集上进行了验证，实验结果表明，CLAIM的性能优于现有的state-of-the-art方法。例如，在KITTI数据集上，CLAIM的旋转误差和平移误差分别降低了约20%和15%。此外，CLAIM的计算效率也更高，能够在更短的时间内完成标定。",
            "tags_zh": [
                "相机-激光雷达标定",
                "单目深度估计",
                "结构损失",
                "纹理损失",
                "自动驾驶"
            ],
            "_index": 111,
            "_used_api": "gemini",
            "figures": []
        }
    ]
}